2022-07-28 08:22:02 - teacher: resnet152
2022-07-28 08:22:02 - student: resnet50
2022-07-28 08:22:02 - num_classes: 1000
2022-07-28 08:22:02 - input_image_size: 224
2022-07-28 08:22:02 - scale: 1.1428571428571428
2022-07-28 08:22:02 - teacher_pretrained_model_path: /root/code/SimpleAICV-ImageNet-CIFAR-COCO-VOC-training/pretrained_models/resnet/resnet152-acc78.006.pth
2022-07-28 08:22:02 - student_pretrained_model_path: 
2022-07-28 08:22:02 - freeze_teacher: True
2022-07-28 08:22:02 - loss_list: ['CELoss', 'DKDLoss']
2022-07-28 08:22:02 - alpha: 1.0
2022-07-28 08:22:02 - beta: 0.5
2022-07-28 08:22:02 - T: 1.0
2022-07-28 08:22:02 - train_criterion: {'CELoss': CELoss(
  (loss): CrossEntropyLoss()
), 'DKDLoss': DKDLoss()}
2022-07-28 08:22:02 - loss_name: DKDLoss
2022-07-28 08:22:02 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2022-07-28 08:22:02 - train_dataset: <simpleAICV.classification.datasets.ilsvrc2012dataset.ILSVRC2012Dataset object at 0x7f51e5a0dbe0>
2022-07-28 08:22:02 - test_dataset: <simpleAICV.classification.datasets.ilsvrc2012dataset.ILSVRC2012Dataset object at 0x7f51e5a0d910>
2022-07-28 08:22:02 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f51e5a0d8e0>
2022-07-28 08:22:02 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f51e5a0d880>
2022-07-28 08:22:02 - seed: 0
2022-07-28 08:22:02 - batch_size: 256
2022-07-28 08:22:02 - num_workers: 16
2022-07-28 08:22:02 - optimizer: ('SGD', {'lr': 0.1, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0001, 'no_weight_decay_layer_name_list': []})
2022-07-28 08:22:02 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.1, 'milestones': [30, 60, 90]})
2022-07-28 08:22:02 - epochs: 100
2022-07-28 08:22:02 - print_interval: 100
2022-07-28 08:22:02 - accumulation_steps: 1
2022-07-28 08:22:02 - sync_bn: False
2022-07-28 08:22:02 - apex: True
2022-07-28 08:22:02 - gpus_type: NVIDIA RTX A5000
2022-07-28 08:22:02 - gpus_num: 2
2022-07-28 08:22:02 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f51db5597b0>
2022-07-28 08:22:02 - --------------------parameters--------------------
2022-07-28 08:22:02 - name: teacher.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.0.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.0.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.0.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.0.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.0.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.0.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.0.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.0.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.0.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.0.downsample_conv.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.0.downsample_conv.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.0.downsample_conv.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.1.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.1.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.1.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.1.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.1.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.1.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.1.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.1.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.1.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.2.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.2.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.2.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.2.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.2.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.2.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.2.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.2.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.2.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.0.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.0.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.0.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.0.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.0.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.0.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.0.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.0.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.0.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.0.downsample_conv.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.0.downsample_conv.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.0.downsample_conv.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.1.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.1.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.1.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.1.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.1.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.1.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.1.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.1.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.1.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.2.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.2.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.2.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.2.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.2.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.2.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.2.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.2.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.2.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.3.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.3.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.3.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.3.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.3.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.3.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.3.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.3.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.3.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.4.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.4.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.4.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.4.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.4.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.4.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.4.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.4.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.4.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.5.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.5.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.5.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.5.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.5.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.5.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.5.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.5.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.5.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.6.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.6.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.6.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.6.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.6.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.6.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.6.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.6.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.6.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.7.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.7.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.7.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.7.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.7.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.7.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.7.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.7.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.7.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.0.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.0.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.0.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.0.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.0.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.0.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.0.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.0.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.0.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.0.downsample_conv.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.0.downsample_conv.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.0.downsample_conv.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.1.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.1.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.1.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.1.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.1.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.1.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.1.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.1.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.1.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.2.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.2.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.2.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.2.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.2.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.2.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.2.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.2.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.2.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.3.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.3.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.3.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.3.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.3.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.3.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.3.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.3.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.3.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.4.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.4.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.4.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.4.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.4.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.4.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.4.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.4.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.4.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.5.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.5.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.5.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.5.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.5.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.5.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.5.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.5.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.5.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.6.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.6.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.6.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.6.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.6.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.6.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.6.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.6.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.6.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.7.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.7.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.7.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.7.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.7.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.7.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.7.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.7.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.7.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.8.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.8.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.8.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.8.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.8.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.8.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.8.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.8.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.8.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.9.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.9.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.9.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.9.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.9.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.9.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.9.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.9.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.9.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.10.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.10.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.10.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.10.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.10.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.10.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.10.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.10.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.10.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.11.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.11.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.11.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.11.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.11.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.11.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.11.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.11.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.11.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.12.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.12.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.12.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.12.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.12.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.12.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.12.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.12.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.12.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.13.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.13.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.13.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.13.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.13.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.13.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.13.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.13.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.13.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.14.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.14.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.14.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.14.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.14.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.14.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.14.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.14.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.14.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.15.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.15.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.15.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.15.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.15.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.15.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.15.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.15.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.15.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.16.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.16.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.16.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.16.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.16.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.16.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.16.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.16.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.16.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.17.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.17.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.17.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.17.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.17.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.17.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.17.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.17.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.17.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.18.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.18.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.18.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.18.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.18.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.18.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.18.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.18.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.18.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.19.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.19.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.19.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.19.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.19.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.19.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.19.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.19.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.19.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.20.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.20.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.20.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.20.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.20.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.20.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.20.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.20.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.20.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.21.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.21.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.21.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.21.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.21.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.21.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.21.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.21.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.21.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.22.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.22.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.22.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.22.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.22.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.22.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.22.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.22.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.22.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.23.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.23.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.23.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.23.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.23.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.23.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.23.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.23.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.23.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.24.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.24.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.24.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.24.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.24.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.24.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.24.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.24.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.24.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.25.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.25.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.25.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.25.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.25.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.25.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.25.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.25.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.25.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.26.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.26.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.26.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.26.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.26.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.26.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.26.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.26.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.26.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.27.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.27.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.27.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.27.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.27.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.27.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.27.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.27.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.27.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.28.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.28.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.28.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.28.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.28.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.28.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.28.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.28.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.28.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.29.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.29.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.29.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.29.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.29.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.29.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.29.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.29.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.29.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.30.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.30.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.30.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.30.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.30.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.30.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.30.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.30.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.30.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.31.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.31.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.31.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.31.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.31.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.31.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.31.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.31.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.31.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.32.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.32.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.32.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.32.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.32.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.32.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.32.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.32.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.32.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.33.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.33.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.33.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.33.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.33.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.33.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.33.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.33.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.33.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.34.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.34.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.34.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.34.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.34.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.34.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.34.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.34.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.34.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.35.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.35.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.35.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.35.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.35.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.35.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.35.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.35.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.35.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.0.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.0.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.0.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.0.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.0.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.0.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.0.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.0.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.0.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.0.downsample_conv.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.0.downsample_conv.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.0.downsample_conv.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.1.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.1.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.1.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.1.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.1.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.1.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.1.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.1.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.1.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.2.conv1.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.2.conv1.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.2.conv1.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.2.conv2.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.2.conv2.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.2.conv2.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.2.conv3.layer.0.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.2.conv3.layer.1.weight, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.2.conv3.layer.1.bias, grad: False
2022-07-28 08:22:02 - name: teacher.fc.weight, grad: False
2022-07-28 08:22:02 - name: teacher.fc.bias, grad: False
2022-07-28 08:22:02 - name: student.conv1.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.conv1.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.conv1.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer1.0.conv1.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer1.0.conv1.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer1.0.conv1.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer1.0.conv2.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer1.0.conv2.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer1.0.conv2.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer1.0.conv3.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer1.0.conv3.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer1.0.conv3.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer1.0.downsample_conv.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer1.0.downsample_conv.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer1.0.downsample_conv.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer1.1.conv1.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer1.1.conv1.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer1.1.conv1.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer1.1.conv2.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer1.1.conv2.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer1.1.conv2.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer1.1.conv3.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer1.1.conv3.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer1.1.conv3.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer1.2.conv1.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer1.2.conv1.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer1.2.conv1.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer1.2.conv2.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer1.2.conv2.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer1.2.conv2.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer1.2.conv3.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer1.2.conv3.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer1.2.conv3.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer2.0.conv1.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer2.0.conv1.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer2.0.conv1.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer2.0.conv2.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer2.0.conv2.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer2.0.conv2.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer2.0.conv3.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer2.0.conv3.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer2.0.conv3.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer2.0.downsample_conv.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer2.0.downsample_conv.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer2.0.downsample_conv.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer2.1.conv1.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer2.1.conv1.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer2.1.conv1.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer2.1.conv2.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer2.1.conv2.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer2.1.conv2.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer2.1.conv3.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer2.1.conv3.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer2.1.conv3.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer2.2.conv1.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer2.2.conv1.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer2.2.conv1.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer2.2.conv2.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer2.2.conv2.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer2.2.conv2.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer2.2.conv3.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer2.2.conv3.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer2.2.conv3.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer2.3.conv1.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer2.3.conv1.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer2.3.conv1.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer2.3.conv2.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer2.3.conv2.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer2.3.conv2.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer2.3.conv3.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer2.3.conv3.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer2.3.conv3.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer3.0.conv1.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.0.conv1.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.0.conv1.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer3.0.conv2.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.0.conv2.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.0.conv2.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer3.0.conv3.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.0.conv3.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.0.conv3.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer3.0.downsample_conv.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.0.downsample_conv.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.0.downsample_conv.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer3.1.conv1.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.1.conv1.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.1.conv1.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer3.1.conv2.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.1.conv2.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.1.conv2.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer3.1.conv3.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.1.conv3.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.1.conv3.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer3.2.conv1.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.2.conv1.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.2.conv1.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer3.2.conv2.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.2.conv2.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.2.conv2.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer3.2.conv3.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.2.conv3.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.2.conv3.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer3.3.conv1.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.3.conv1.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.3.conv1.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer3.3.conv2.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.3.conv2.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.3.conv2.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer3.3.conv3.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.3.conv3.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.3.conv3.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer3.4.conv1.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.4.conv1.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.4.conv1.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer3.4.conv2.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.4.conv2.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.4.conv2.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer3.4.conv3.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.4.conv3.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.4.conv3.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer3.5.conv1.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.5.conv1.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.5.conv1.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer3.5.conv2.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.5.conv2.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.5.conv2.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer3.5.conv3.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.5.conv3.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer3.5.conv3.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer4.0.conv1.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer4.0.conv1.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer4.0.conv1.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer4.0.conv2.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer4.0.conv2.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer4.0.conv2.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer4.0.conv3.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer4.0.conv3.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer4.0.conv3.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer4.0.downsample_conv.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer4.0.downsample_conv.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer4.0.downsample_conv.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer4.1.conv1.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer4.1.conv1.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer4.1.conv1.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer4.1.conv2.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer4.1.conv2.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer4.1.conv2.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer4.1.conv3.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer4.1.conv3.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer4.1.conv3.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer4.2.conv1.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer4.2.conv1.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer4.2.conv1.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer4.2.conv2.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer4.2.conv2.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer4.2.conv2.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.layer4.2.conv3.layer.0.weight, grad: True
2022-07-28 08:22:02 - name: student.layer4.2.conv3.layer.1.weight, grad: True
2022-07-28 08:22:02 - name: student.layer4.2.conv3.layer.1.bias, grad: True
2022-07-28 08:22:02 - name: student.fc.weight, grad: True
2022-07-28 08:22:02 - name: student.fc.bias, grad: True
2022-07-28 08:22:02 - --------------------buffers--------------------
2022-07-28 08:22:02 - name: teacher.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.0.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.0.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.0.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.0.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.0.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.0.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.0.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.0.downsample_conv.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.0.downsample_conv.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.1.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.1.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.1.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.1.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.1.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.1.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.1.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.2.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.2.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.2.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.2.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.2.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.2.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.2.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.2.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer1.2.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.0.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.0.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.0.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.0.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.0.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.0.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.0.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.0.downsample_conv.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.0.downsample_conv.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.1.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.1.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.1.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.1.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.1.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.1.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.1.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.2.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.2.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.2.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.2.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.2.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.2.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.2.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.2.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.2.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.3.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.3.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.3.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.3.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.3.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.3.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.3.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.3.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.3.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.4.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.4.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.4.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.4.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.4.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.4.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.4.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.4.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.4.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.5.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.5.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.5.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.5.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.5.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.5.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.5.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.5.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.5.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.6.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.6.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.6.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.6.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.6.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.6.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.6.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.6.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.6.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.7.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.7.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.7.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.7.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.7.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.7.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.7.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.7.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer2.7.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.0.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.0.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.0.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.0.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.0.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.0.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.0.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.0.downsample_conv.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.0.downsample_conv.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.1.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.1.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.1.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.1.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.1.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.1.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.1.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.2.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.2.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.2.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.2.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.2.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.2.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.2.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.2.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.2.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.3.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.3.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.3.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.3.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.3.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.3.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.3.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.3.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.3.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.4.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.4.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.4.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.4.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.4.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.4.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.4.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.4.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.4.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.5.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.5.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.5.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.5.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.5.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.5.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.5.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.5.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.5.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.6.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.6.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.6.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.6.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.6.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.6.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.6.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.6.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.6.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.7.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.7.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.7.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.7.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.7.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.7.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.7.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.7.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.7.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.8.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.8.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.8.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.8.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.8.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.8.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.8.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.8.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.8.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.9.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.9.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.9.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.9.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.9.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.9.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.9.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.9.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.9.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.10.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.10.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.10.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.10.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.10.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.10.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.10.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.10.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.10.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.11.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.11.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.11.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.11.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.11.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.11.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.11.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.11.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.11.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.12.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.12.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.12.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.12.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.12.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.12.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.12.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.12.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.12.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.13.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.13.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.13.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.13.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.13.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.13.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.13.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.13.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.13.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.14.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.14.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.14.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.14.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.14.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.14.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.14.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.14.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.14.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.15.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.15.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.15.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.15.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.15.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.15.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.15.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.15.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.15.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.16.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.16.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.16.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.16.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.16.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.16.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.16.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.16.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.16.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.17.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.17.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.17.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.17.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.17.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.17.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.17.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.17.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.17.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.18.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.18.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.18.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.18.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.18.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.18.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.18.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.18.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.18.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.19.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.19.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.19.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.19.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.19.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.19.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.19.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.19.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.19.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.20.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.20.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.20.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.20.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.20.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.20.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.20.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.20.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.20.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.21.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.21.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.21.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.21.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.21.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.21.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.21.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.21.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.21.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.22.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.22.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.22.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.22.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.22.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.22.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.22.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.22.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.22.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.23.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.23.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.23.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.23.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.23.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.23.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.23.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.23.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.23.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.24.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.24.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.24.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.24.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.24.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.24.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.24.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.24.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.24.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.25.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.25.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.25.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.25.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.25.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.25.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.25.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.25.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.25.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.26.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.26.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.26.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.26.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.26.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.26.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.26.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.26.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.26.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.27.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.27.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.27.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.27.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.27.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.27.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.27.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.27.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.27.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.28.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.28.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.28.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.28.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.28.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.28.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.28.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.28.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.28.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.29.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.29.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.29.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.29.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.29.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.29.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.29.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.29.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.29.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.30.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.30.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.30.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.30.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.30.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.30.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.30.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.30.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.30.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.31.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.31.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.31.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.31.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.31.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.31.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.31.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.31.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.31.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.32.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.32.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.32.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.32.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.32.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.32.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.32.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.32.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.32.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.33.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.33.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.33.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.33.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.33.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.33.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.33.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.33.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.33.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.34.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.34.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.34.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.34.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.34.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.34.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.34.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.34.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.34.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.35.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.35.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.35.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.35.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.35.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.35.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.35.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.35.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer3.35.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.0.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.0.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.0.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.0.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.0.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.0.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.0.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.0.downsample_conv.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.0.downsample_conv.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.1.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.1.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.1.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.1.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.1.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.1.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.1.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.2.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.2.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.2.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.2.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.2.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.2.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.2.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.2.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: teacher.layer4.2.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer1.0.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer1.0.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer1.0.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer1.0.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer1.0.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer1.0.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer1.0.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer1.0.downsample_conv.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer1.0.downsample_conv.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer1.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer1.1.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer1.1.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer1.1.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer1.1.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer1.1.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer1.1.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer1.1.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer1.2.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer1.2.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer1.2.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer1.2.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer1.2.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer1.2.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer1.2.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer1.2.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer1.2.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer2.0.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer2.0.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer2.0.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer2.0.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer2.0.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer2.0.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer2.0.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer2.0.downsample_conv.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer2.0.downsample_conv.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer2.1.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer2.1.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer2.1.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer2.1.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer2.1.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer2.1.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer2.1.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer2.2.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer2.2.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer2.2.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer2.2.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer2.2.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer2.2.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer2.2.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer2.2.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer2.2.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer2.3.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer2.3.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer2.3.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer2.3.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer2.3.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer2.3.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer2.3.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer2.3.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer2.3.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer3.0.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer3.0.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer3.0.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer3.0.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer3.0.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer3.0.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer3.0.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer3.0.downsample_conv.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer3.0.downsample_conv.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer3.1.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer3.1.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer3.1.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer3.1.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer3.1.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer3.1.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer3.1.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer3.2.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer3.2.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer3.2.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer3.2.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer3.2.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer3.2.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer3.2.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer3.2.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer3.2.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer3.3.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer3.3.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer3.3.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer3.3.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer3.3.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer3.3.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer3.3.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer3.3.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer3.3.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer3.4.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer3.4.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer3.4.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer3.4.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer3.4.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer3.4.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer3.4.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer3.4.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer3.4.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer3.5.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer3.5.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer3.5.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer3.5.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer3.5.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer3.5.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer3.5.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer3.5.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer3.5.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer4.0.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer4.0.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer4.0.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer4.0.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer4.0.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer4.0.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer4.0.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer4.0.downsample_conv.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer4.0.downsample_conv.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer4.1.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer4.1.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer4.1.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer4.1.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer4.1.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer4.1.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer4.1.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer4.2.conv1.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer4.2.conv1.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer4.2.conv1.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer4.2.conv2.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer4.2.conv2.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer4.2.conv2.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - name: student.layer4.2.conv3.layer.1.running_mean, grad: False
2022-07-28 08:22:02 - name: student.layer4.2.conv3.layer.1.running_var, grad: False
2022-07-28 08:22:02 - name: student.layer4.2.conv3.layer.1.num_batches_tracked, grad: False
2022-07-28 08:22:02 - -----------no weight decay layers--------------
2022-07-28 08:22:02 - name: student.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer1.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer1.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer1.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer1.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer1.0.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer1.0.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer1.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer1.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer1.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer1.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer1.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer1.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer1.1.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer1.1.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer1.2.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer1.2.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer1.2.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer1.2.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer1.2.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer1.2.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.0.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.0.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.1.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.1.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.2.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.2.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.2.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.2.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.2.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.2.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.3.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.3.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.3.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.3.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.3.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.3.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.0.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.0.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.1.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.1.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.2.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.2.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.2.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.2.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.2.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.2.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.3.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.3.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.3.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.3.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.3.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.3.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.4.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.4.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.4.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.4.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.4.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.4.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.5.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.5.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.5.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.5.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.5.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.5.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer4.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer4.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer4.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer4.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer4.0.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer4.0.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer4.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer4.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer4.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer4.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer4.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer4.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer4.1.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer4.1.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer4.2.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer4.2.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer4.2.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer4.2.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer4.2.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer4.2.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.fc.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-28 08:22:02 - -------------weight decay layers---------------
2022-07-28 08:22:02 - name: student.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer1.0.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer1.0.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer1.0.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer1.0.downsample_conv.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer1.1.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer1.1.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer1.1.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer1.2.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer1.2.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer1.2.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.0.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.0.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.0.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.0.downsample_conv.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.1.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.1.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.1.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.2.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.2.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.2.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.3.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.3.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer2.3.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.0.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.0.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.0.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.0.downsample_conv.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.1.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.1.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.1.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.2.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.2.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.2.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.3.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.3.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.3.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.4.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.4.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.4.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.5.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.5.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer3.5.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer4.0.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer4.0.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer4.0.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer4.0.downsample_conv.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer4.1.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer4.1.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer4.1.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer4.2.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer4.2.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.layer4.2.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - name: student.fc.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-28 08:22:02 - epoch 001 lr: 0.100000
2022-07-28 08:22:43 - train: epoch 0001, iter [00100, 05004], lr: 0.100000, loss: 15.0305, stu_CELoss: 6.9005, DKDLoss: 8.1300, 
2022-07-28 08:23:17 - train: epoch 0001, iter [00200, 05004], lr: 0.100000, loss: 15.1012, stu_CELoss: 6.9117, DKDLoss: 8.1895, 
2022-07-28 08:23:50 - train: epoch 0001, iter [00300, 05004], lr: 0.100000, loss: 14.6675, stu_CELoss: 6.8841, DKDLoss: 7.7834, 
2022-07-28 08:24:23 - train: epoch 0001, iter [00400, 05004], lr: 0.100000, loss: 15.0037, stu_CELoss: 6.8400, DKDLoss: 8.1636, 
2022-07-28 08:24:56 - train: epoch 0001, iter [00500, 05004], lr: 0.100000, loss: 14.3887, stu_CELoss: 6.7274, DKDLoss: 7.6614, 
2022-07-28 08:25:29 - train: epoch 0001, iter [00600, 05004], lr: 0.100000, loss: 14.3405, stu_CELoss: 6.6422, DKDLoss: 7.6984, 
2022-07-28 08:26:02 - train: epoch 0001, iter [00700, 05004], lr: 0.100000, loss: 14.1143, stu_CELoss: 6.6479, DKDLoss: 7.4664, 
2022-07-28 08:26:36 - train: epoch 0001, iter [00800, 05004], lr: 0.100000, loss: 14.0902, stu_CELoss: 6.5420, DKDLoss: 7.5482, 
2022-07-28 08:27:09 - train: epoch 0001, iter [00900, 05004], lr: 0.100000, loss: 13.5052, stu_CELoss: 6.4091, DKDLoss: 7.0961, 
2022-07-28 08:27:42 - train: epoch 0001, iter [01000, 05004], lr: 0.100000, loss: 13.4988, stu_CELoss: 6.3528, DKDLoss: 7.1460, 
2022-07-28 08:28:15 - train: epoch 0001, iter [01100, 05004], lr: 0.100000, loss: 13.0634, stu_CELoss: 6.2361, DKDLoss: 6.8274, 
2022-07-28 08:28:49 - train: epoch 0001, iter [01200, 05004], lr: 0.100000, loss: 13.0038, stu_CELoss: 6.0005, DKDLoss: 7.0033, 
2022-07-28 08:29:22 - train: epoch 0001, iter [01300, 05004], lr: 0.100000, loss: 12.7988, stu_CELoss: 5.9802, DKDLoss: 6.8186, 
2022-07-28 08:29:56 - train: epoch 0001, iter [01400, 05004], lr: 0.100000, loss: 12.4610, stu_CELoss: 5.8897, DKDLoss: 6.5713, 
2022-07-28 08:30:30 - train: epoch 0001, iter [01500, 05004], lr: 0.100000, loss: 12.6466, stu_CELoss: 5.8196, DKDLoss: 6.8270, 
2022-07-28 08:31:03 - train: epoch 0001, iter [01600, 05004], lr: 0.100000, loss: 12.3819, stu_CELoss: 5.8287, DKDLoss: 6.5532, 
2022-07-28 08:31:36 - train: epoch 0001, iter [01700, 05004], lr: 0.100000, loss: 11.8639, stu_CELoss: 5.5317, DKDLoss: 6.3322, 
2022-07-28 08:32:10 - train: epoch 0001, iter [01800, 05004], lr: 0.100000, loss: 11.9206, stu_CELoss: 5.6205, DKDLoss: 6.3001, 
2022-07-28 08:32:44 - train: epoch 0001, iter [01900, 05004], lr: 0.100000, loss: 11.7933, stu_CELoss: 5.4138, DKDLoss: 6.3796, 
2022-07-28 08:33:18 - train: epoch 0001, iter [02000, 05004], lr: 0.100000, loss: 11.5572, stu_CELoss: 5.3846, DKDLoss: 6.1726, 
2022-07-28 08:33:51 - train: epoch 0001, iter [02100, 05004], lr: 0.100000, loss: 11.3611, stu_CELoss: 5.3403, DKDLoss: 6.0208, 
2022-07-28 08:34:25 - train: epoch 0001, iter [02200, 05004], lr: 0.100000, loss: 11.0663, stu_CELoss: 5.1870, DKDLoss: 5.8793, 
2022-07-28 08:34:59 - train: epoch 0001, iter [02300, 05004], lr: 0.100000, loss: 11.0777, stu_CELoss: 5.2032, DKDLoss: 5.8745, 
2022-07-28 08:35:32 - train: epoch 0001, iter [02400, 05004], lr: 0.100000, loss: 10.9622, stu_CELoss: 5.1603, DKDLoss: 5.8019, 
2022-07-28 08:36:05 - train: epoch 0001, iter [02500, 05004], lr: 0.100000, loss: 10.9626, stu_CELoss: 5.1987, DKDLoss: 5.7640, 
2022-07-28 08:36:39 - train: epoch 0001, iter [02600, 05004], lr: 0.100000, loss: 11.3240, stu_CELoss: 5.2837, DKDLoss: 6.0403, 
2022-07-28 08:37:12 - train: epoch 0001, iter [02700, 05004], lr: 0.100000, loss: 11.1120, stu_CELoss: 5.2251, DKDLoss: 5.8870, 
2022-07-28 08:37:46 - train: epoch 0001, iter [02800, 05004], lr: 0.100000, loss: 10.7480, stu_CELoss: 5.0548, DKDLoss: 5.6932, 
2022-07-28 08:38:20 - train: epoch 0001, iter [02900, 05004], lr: 0.100000, loss: 10.3988, stu_CELoss: 4.8952, DKDLoss: 5.5036, 
2022-07-28 08:38:54 - train: epoch 0001, iter [03000, 05004], lr: 0.100000, loss: 10.6486, stu_CELoss: 5.0713, DKDLoss: 5.5772, 
2022-07-28 08:39:28 - train: epoch 0001, iter [03100, 05004], lr: 0.100000, loss: 10.8926, stu_CELoss: 5.1091, DKDLoss: 5.7835, 
2022-07-28 08:40:01 - train: epoch 0001, iter [03200, 05004], lr: 0.100000, loss: 10.3749, stu_CELoss: 4.8779, DKDLoss: 5.4970, 
2022-07-28 08:40:35 - train: epoch 0001, iter [03300, 05004], lr: 0.100000, loss: 9.9260, stu_CELoss: 4.6528, DKDLoss: 5.2732, 
2022-07-28 08:41:08 - train: epoch 0001, iter [03400, 05004], lr: 0.100000, loss: 9.9508, stu_CELoss: 4.6508, DKDLoss: 5.2999, 
2022-07-28 08:41:42 - train: epoch 0001, iter [03500, 05004], lr: 0.100000, loss: 9.8535, stu_CELoss: 4.6238, DKDLoss: 5.2298, 
2022-07-28 08:42:16 - train: epoch 0001, iter [03600, 05004], lr: 0.100000, loss: 9.9283, stu_CELoss: 4.6682, DKDLoss: 5.2601, 
2022-07-28 08:42:49 - train: epoch 0001, iter [03700, 05004], lr: 0.100000, loss: 9.7084, stu_CELoss: 4.7448, DKDLoss: 4.9636, 
2022-07-28 08:43:23 - train: epoch 0001, iter [03800, 05004], lr: 0.100000, loss: 9.6758, stu_CELoss: 4.5120, DKDLoss: 5.1638, 
2022-07-28 08:43:57 - train: epoch 0001, iter [03900, 05004], lr: 0.100000, loss: 9.5815, stu_CELoss: 4.5510, DKDLoss: 5.0305, 
2022-07-28 08:44:30 - train: epoch 0001, iter [04000, 05004], lr: 0.100000, loss: 9.7599, stu_CELoss: 4.5656, DKDLoss: 5.1943, 
2022-07-28 08:45:04 - train: epoch 0001, iter [04100, 05004], lr: 0.100000, loss: 9.4652, stu_CELoss: 4.5297, DKDLoss: 4.9355, 
2022-07-28 08:45:38 - train: epoch 0001, iter [04200, 05004], lr: 0.100000, loss: 9.4066, stu_CELoss: 4.4158, DKDLoss: 4.9909, 
2022-07-28 08:46:11 - train: epoch 0001, iter [04300, 05004], lr: 0.100000, loss: 9.4039, stu_CELoss: 4.3638, DKDLoss: 5.0401, 
2022-07-28 08:46:45 - train: epoch 0001, iter [04400, 05004], lr: 0.100000, loss: 8.6407, stu_CELoss: 4.0819, DKDLoss: 4.5589, 
2022-07-28 08:47:19 - train: epoch 0001, iter [04500, 05004], lr: 0.100000, loss: 9.3516, stu_CELoss: 4.4326, DKDLoss: 4.9189, 
2022-07-28 08:47:53 - train: epoch 0001, iter [04600, 05004], lr: 0.100000, loss: 9.4301, stu_CELoss: 4.4786, DKDLoss: 4.9514, 
2022-07-28 08:48:27 - train: epoch 0001, iter [04700, 05004], lr: 0.100000, loss: 8.6734, stu_CELoss: 4.1888, DKDLoss: 4.4847, 
2022-07-28 08:49:00 - train: epoch 0001, iter [04800, 05004], lr: 0.100000, loss: 9.1609, stu_CELoss: 4.4867, DKDLoss: 4.6742, 
2022-07-28 08:49:34 - train: epoch 0001, iter [04900, 05004], lr: 0.100000, loss: 8.7494, stu_CELoss: 4.1563, DKDLoss: 4.5930, 
2022-07-28 08:50:07 - train: epoch 0001, iter [05000, 05004], lr: 0.100000, loss: 8.8971, stu_CELoss: 4.1741, DKDLoss: 4.7231, 
2022-07-28 08:50:09 - train: epoch 001, train_loss: 11.3574
2022-07-28 08:52:42 - eval: epoch: 001, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 19.446%, stu_acc5: 42.130%, stu_test_loss: 4.0041
2022-07-28 08:52:43 - until epoch: 001, tea_best_acc1: 78.068%, stu_best_acc1: 19.446%
2022-07-28 08:52:43 - epoch 002 lr: 0.100000
2022-07-28 08:53:22 - train: epoch 0002, iter [00100, 05004], lr: 0.100000, loss: 8.3045, stu_CELoss: 3.9904, DKDLoss: 4.3141, 
2022-07-28 08:53:55 - train: epoch 0002, iter [00200, 05004], lr: 0.100000, loss: 8.3367, stu_CELoss: 3.9342, DKDLoss: 4.4025, 
2022-07-28 08:54:28 - train: epoch 0002, iter [00300, 05004], lr: 0.100000, loss: 8.7102, stu_CELoss: 4.1647, DKDLoss: 4.5455, 
2022-07-28 08:55:02 - train: epoch 0002, iter [00400, 05004], lr: 0.100000, loss: 8.4532, stu_CELoss: 4.0505, DKDLoss: 4.4027, 
2022-07-28 08:55:35 - train: epoch 0002, iter [00500, 05004], lr: 0.100000, loss: 8.5863, stu_CELoss: 4.0747, DKDLoss: 4.5116, 
2022-07-28 08:56:09 - train: epoch 0002, iter [00600, 05004], lr: 0.100000, loss: 8.0007, stu_CELoss: 3.7827, DKDLoss: 4.2180, 
2022-07-28 08:56:42 - train: epoch 0002, iter [00700, 05004], lr: 0.100000, loss: 8.6030, stu_CELoss: 4.1618, DKDLoss: 4.4412, 
2022-07-28 08:57:16 - train: epoch 0002, iter [00800, 05004], lr: 0.100000, loss: 7.9392, stu_CELoss: 3.7914, DKDLoss: 4.1478, 
2022-07-28 08:57:49 - train: epoch 0002, iter [00900, 05004], lr: 0.100000, loss: 7.8431, stu_CELoss: 3.6755, DKDLoss: 4.1675, 
2022-07-28 08:58:23 - train: epoch 0002, iter [01000, 05004], lr: 0.100000, loss: 8.1249, stu_CELoss: 3.8670, DKDLoss: 4.2579, 
2022-07-28 08:58:56 - train: epoch 0002, iter [01100, 05004], lr: 0.100000, loss: 8.3466, stu_CELoss: 3.9889, DKDLoss: 4.3577, 
2022-07-28 08:59:30 - train: epoch 0002, iter [01200, 05004], lr: 0.100000, loss: 7.8814, stu_CELoss: 3.6790, DKDLoss: 4.2024, 
2022-07-28 09:00:04 - train: epoch 0002, iter [01300, 05004], lr: 0.100000, loss: 8.2766, stu_CELoss: 3.9358, DKDLoss: 4.3409, 
2022-07-28 09:00:37 - train: epoch 0002, iter [01400, 05004], lr: 0.100000, loss: 8.2957, stu_CELoss: 3.9223, DKDLoss: 4.3734, 
2022-07-28 09:01:11 - train: epoch 0002, iter [01500, 05004], lr: 0.100000, loss: 8.0216, stu_CELoss: 3.7448, DKDLoss: 4.2768, 
2022-07-28 09:01:45 - train: epoch 0002, iter [01600, 05004], lr: 0.100000, loss: 7.7407, stu_CELoss: 3.7318, DKDLoss: 4.0089, 
2022-07-28 09:02:18 - train: epoch 0002, iter [01700, 05004], lr: 0.100000, loss: 7.8898, stu_CELoss: 3.7854, DKDLoss: 4.1044, 
2022-07-28 09:02:52 - train: epoch 0002, iter [01800, 05004], lr: 0.100000, loss: 7.4697, stu_CELoss: 3.6097, DKDLoss: 3.8601, 
2022-07-28 09:03:25 - train: epoch 0002, iter [01900, 05004], lr: 0.100000, loss: 7.5347, stu_CELoss: 3.5323, DKDLoss: 4.0023, 
2022-07-28 09:03:59 - train: epoch 0002, iter [02000, 05004], lr: 0.100000, loss: 7.1389, stu_CELoss: 3.2589, DKDLoss: 3.8800, 
2022-07-28 09:04:33 - train: epoch 0002, iter [02100, 05004], lr: 0.100000, loss: 7.9306, stu_CELoss: 3.8320, DKDLoss: 4.0985, 
2022-07-28 09:05:06 - train: epoch 0002, iter [02200, 05004], lr: 0.100000, loss: 7.6123, stu_CELoss: 3.6009, DKDLoss: 4.0114, 
2022-07-28 09:05:40 - train: epoch 0002, iter [02300, 05004], lr: 0.100000, loss: 7.6284, stu_CELoss: 3.6244, DKDLoss: 4.0040, 
2022-07-28 09:06:14 - train: epoch 0002, iter [02400, 05004], lr: 0.100000, loss: 7.2949, stu_CELoss: 3.4001, DKDLoss: 3.8948, 
2022-07-28 09:06:48 - train: epoch 0002, iter [02500, 05004], lr: 0.100000, loss: 7.0241, stu_CELoss: 3.3243, DKDLoss: 3.6999, 
2022-07-28 09:07:21 - train: epoch 0002, iter [02600, 05004], lr: 0.100000, loss: 7.1853, stu_CELoss: 3.3390, DKDLoss: 3.8463, 
2022-07-28 09:07:55 - train: epoch 0002, iter [02700, 05004], lr: 0.100000, loss: 7.8310, stu_CELoss: 3.7155, DKDLoss: 4.1155, 
2022-07-28 09:08:29 - train: epoch 0002, iter [02800, 05004], lr: 0.100000, loss: 7.6249, stu_CELoss: 3.6410, DKDLoss: 3.9839, 
2022-07-28 09:09:02 - train: epoch 0002, iter [02900, 05004], lr: 0.100000, loss: 7.1045, stu_CELoss: 3.3982, DKDLoss: 3.7063, 
2022-07-28 09:09:36 - train: epoch 0002, iter [03000, 05004], lr: 0.100000, loss: 6.8163, stu_CELoss: 3.2351, DKDLoss: 3.5811, 
2022-07-28 09:10:09 - train: epoch 0002, iter [03100, 05004], lr: 0.100000, loss: 7.5488, stu_CELoss: 3.5182, DKDLoss: 4.0306, 
2022-07-28 09:10:43 - train: epoch 0002, iter [03200, 05004], lr: 0.100000, loss: 7.4534, stu_CELoss: 3.4704, DKDLoss: 3.9830, 
2022-07-28 09:11:17 - train: epoch 0002, iter [03300, 05004], lr: 0.100000, loss: 7.1033, stu_CELoss: 3.5187, DKDLoss: 3.5846, 
2022-07-28 09:11:50 - train: epoch 0002, iter [03400, 05004], lr: 0.100000, loss: 7.3616, stu_CELoss: 3.4897, DKDLoss: 3.8719, 
2022-07-28 09:12:24 - train: epoch 0002, iter [03500, 05004], lr: 0.100000, loss: 6.7893, stu_CELoss: 3.2510, DKDLoss: 3.5384, 
2022-07-28 09:12:57 - train: epoch 0002, iter [03600, 05004], lr: 0.100000, loss: 7.2195, stu_CELoss: 3.4318, DKDLoss: 3.7876, 
2022-07-28 09:13:31 - train: epoch 0002, iter [03700, 05004], lr: 0.100000, loss: 7.3506, stu_CELoss: 3.6156, DKDLoss: 3.7350, 
2022-07-28 09:14:05 - train: epoch 0002, iter [03800, 05004], lr: 0.100000, loss: 6.7978, stu_CELoss: 3.2893, DKDLoss: 3.5085, 
2022-07-28 09:14:39 - train: epoch 0002, iter [03900, 05004], lr: 0.100000, loss: 7.2910, stu_CELoss: 3.4409, DKDLoss: 3.8501, 
2022-07-28 09:15:13 - train: epoch 0002, iter [04000, 05004], lr: 0.100000, loss: 6.6536, stu_CELoss: 3.1513, DKDLoss: 3.5023, 
2022-07-28 09:15:46 - train: epoch 0002, iter [04100, 05004], lr: 0.100000, loss: 7.1430, stu_CELoss: 3.2939, DKDLoss: 3.8490, 
2022-07-28 09:16:20 - train: epoch 0002, iter [04200, 05004], lr: 0.100000, loss: 6.9969, stu_CELoss: 3.3243, DKDLoss: 3.6725, 
2022-07-28 09:16:54 - train: epoch 0002, iter [04300, 05004], lr: 0.100000, loss: 6.7219, stu_CELoss: 3.2912, DKDLoss: 3.4306, 
2022-07-28 09:17:28 - train: epoch 0002, iter [04400, 05004], lr: 0.100000, loss: 6.5433, stu_CELoss: 3.1760, DKDLoss: 3.3673, 
2022-07-28 09:18:01 - train: epoch 0002, iter [04500, 05004], lr: 0.100000, loss: 6.3996, stu_CELoss: 3.0206, DKDLoss: 3.3790, 
2022-07-28 09:18:35 - train: epoch 0002, iter [04600, 05004], lr: 0.100000, loss: 6.6323, stu_CELoss: 3.1242, DKDLoss: 3.5080, 
2022-07-28 09:19:09 - train: epoch 0002, iter [04700, 05004], lr: 0.100000, loss: 6.5784, stu_CELoss: 3.0341, DKDLoss: 3.5443, 
2022-07-28 09:19:43 - train: epoch 0002, iter [04800, 05004], lr: 0.100000, loss: 6.6994, stu_CELoss: 3.3324, DKDLoss: 3.3670, 
2022-07-28 09:20:18 - train: epoch 0002, iter [04900, 05004], lr: 0.100000, loss: 6.4077, stu_CELoss: 3.0676, DKDLoss: 3.3400, 
2022-07-28 09:20:51 - train: epoch 0002, iter [05000, 05004], lr: 0.100000, loss: 6.8329, stu_CELoss: 3.3361, DKDLoss: 3.4967, 
2022-07-28 09:20:53 - train: epoch 002, train_loss: 7.4905
2022-07-28 09:23:26 - eval: epoch: 002, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 33.998%, stu_acc5: 60.356%, stu_test_loss: 3.0687
2022-07-28 09:23:27 - until epoch: 002, tea_best_acc1: 78.068%, stu_best_acc1: 33.998%
2022-07-28 09:23:27 - epoch 003 lr: 0.100000
2022-07-28 09:24:07 - train: epoch 0003, iter [00100, 05004], lr: 0.100000, loss: 6.3323, stu_CELoss: 3.1066, DKDLoss: 3.2256, 
2022-07-28 09:24:40 - train: epoch 0003, iter [00200, 05004], lr: 0.100000, loss: 6.6984, stu_CELoss: 3.2248, DKDLoss: 3.4735, 
2022-07-28 09:25:14 - train: epoch 0003, iter [00300, 05004], lr: 0.100000, loss: 6.6490, stu_CELoss: 3.1166, DKDLoss: 3.5324, 
2022-07-28 09:25:47 - train: epoch 0003, iter [00400, 05004], lr: 0.100000, loss: 6.6330, stu_CELoss: 3.2043, DKDLoss: 3.4287, 
2022-07-28 09:26:21 - train: epoch 0003, iter [00500, 05004], lr: 0.100000, loss: 6.3598, stu_CELoss: 3.1293, DKDLoss: 3.2305, 
2022-07-28 09:26:54 - train: epoch 0003, iter [00600, 05004], lr: 0.100000, loss: 6.3830, stu_CELoss: 2.9873, DKDLoss: 3.3957, 
2022-07-28 09:27:28 - train: epoch 0003, iter [00700, 05004], lr: 0.100000, loss: 6.4781, stu_CELoss: 3.2146, DKDLoss: 3.2635, 
2022-07-28 09:28:01 - train: epoch 0003, iter [00800, 05004], lr: 0.100000, loss: 6.7849, stu_CELoss: 3.3156, DKDLoss: 3.4693, 
2022-07-28 09:28:34 - train: epoch 0003, iter [00900, 05004], lr: 0.100000, loss: 6.4808, stu_CELoss: 3.0967, DKDLoss: 3.3841, 
2022-07-28 09:29:08 - train: epoch 0003, iter [01000, 05004], lr: 0.100000, loss: 6.1113, stu_CELoss: 3.0896, DKDLoss: 3.0218, 
2022-07-28 09:29:41 - train: epoch 0003, iter [01100, 05004], lr: 0.100000, loss: 6.0395, stu_CELoss: 2.9280, DKDLoss: 3.1115, 
2022-07-28 09:30:14 - train: epoch 0003, iter [01200, 05004], lr: 0.100000, loss: 6.2974, stu_CELoss: 3.0225, DKDLoss: 3.2749, 
2022-07-28 09:30:48 - train: epoch 0003, iter [01300, 05004], lr: 0.100000, loss: 5.8895, stu_CELoss: 2.8403, DKDLoss: 3.0492, 
2022-07-28 09:31:22 - train: epoch 0003, iter [01400, 05004], lr: 0.100000, loss: 6.2017, stu_CELoss: 2.9618, DKDLoss: 3.2399, 
2022-07-28 09:31:55 - train: epoch 0003, iter [01500, 05004], lr: 0.100000, loss: 6.5000, stu_CELoss: 3.2112, DKDLoss: 3.2889, 
2022-07-28 09:32:28 - train: epoch 0003, iter [01600, 05004], lr: 0.100000, loss: 6.2016, stu_CELoss: 2.9292, DKDLoss: 3.2724, 
2022-07-28 09:33:02 - train: epoch 0003, iter [01700, 05004], lr: 0.100000, loss: 6.1125, stu_CELoss: 2.9606, DKDLoss: 3.1519, 
2022-07-28 09:33:36 - train: epoch 0003, iter [01800, 05004], lr: 0.100000, loss: 6.0228, stu_CELoss: 2.9202, DKDLoss: 3.1026, 
2022-07-28 09:34:09 - train: epoch 0003, iter [01900, 05004], lr: 0.100000, loss: 6.3838, stu_CELoss: 2.9725, DKDLoss: 3.4113, 
2022-07-28 09:34:43 - train: epoch 0003, iter [02000, 05004], lr: 0.100000, loss: 6.4225, stu_CELoss: 3.2294, DKDLoss: 3.1931, 
2022-07-28 09:35:16 - train: epoch 0003, iter [02100, 05004], lr: 0.100000, loss: 6.2064, stu_CELoss: 3.0485, DKDLoss: 3.1578, 
2022-07-28 09:35:49 - train: epoch 0003, iter [02200, 05004], lr: 0.100000, loss: 6.5047, stu_CELoss: 3.2374, DKDLoss: 3.2673, 
2022-07-28 09:36:23 - train: epoch 0003, iter [02300, 05004], lr: 0.100000, loss: 5.6996, stu_CELoss: 2.8090, DKDLoss: 2.8906, 
2022-07-28 09:36:56 - train: epoch 0003, iter [02400, 05004], lr: 0.100000, loss: 5.7841, stu_CELoss: 2.7497, DKDLoss: 3.0343, 
2022-07-28 09:37:29 - train: epoch 0003, iter [02500, 05004], lr: 0.100000, loss: 6.1143, stu_CELoss: 2.9893, DKDLoss: 3.1250, 
2022-07-28 09:38:02 - train: epoch 0003, iter [02600, 05004], lr: 0.100000, loss: 6.1324, stu_CELoss: 3.0341, DKDLoss: 3.0983, 
2022-07-28 09:38:36 - train: epoch 0003, iter [02700, 05004], lr: 0.100000, loss: 5.9806, stu_CELoss: 3.0413, DKDLoss: 2.9393, 
2022-07-28 09:39:09 - train: epoch 0003, iter [02800, 05004], lr: 0.100000, loss: 5.9111, stu_CELoss: 2.8470, DKDLoss: 3.0641, 
2022-07-28 09:39:43 - train: epoch 0003, iter [02900, 05004], lr: 0.100000, loss: 5.8934, stu_CELoss: 2.9248, DKDLoss: 2.9686, 
2022-07-28 09:40:16 - train: epoch 0003, iter [03000, 05004], lr: 0.100000, loss: 5.8500, stu_CELoss: 2.8048, DKDLoss: 3.0452, 
2022-07-28 09:40:50 - train: epoch 0003, iter [03100, 05004], lr: 0.100000, loss: 6.5357, stu_CELoss: 3.2757, DKDLoss: 3.2600, 
2022-07-28 09:41:23 - train: epoch 0003, iter [03200, 05004], lr: 0.100000, loss: 6.0172, stu_CELoss: 2.9779, DKDLoss: 3.0393, 
2022-07-28 09:41:57 - train: epoch 0003, iter [03300, 05004], lr: 0.100000, loss: 5.7639, stu_CELoss: 2.7850, DKDLoss: 2.9789, 
2022-07-28 09:42:30 - train: epoch 0003, iter [03400, 05004], lr: 0.100000, loss: 6.3973, stu_CELoss: 3.1741, DKDLoss: 3.2231, 
2022-07-28 09:43:04 - train: epoch 0003, iter [03500, 05004], lr: 0.100000, loss: 5.9822, stu_CELoss: 2.8042, DKDLoss: 3.1781, 
2022-07-28 09:43:38 - train: epoch 0003, iter [03600, 05004], lr: 0.100000, loss: 5.7974, stu_CELoss: 2.7520, DKDLoss: 3.0454, 
2022-07-28 09:44:11 - train: epoch 0003, iter [03700, 05004], lr: 0.100000, loss: 6.1986, stu_CELoss: 2.9378, DKDLoss: 3.2608, 
2022-07-28 09:44:45 - train: epoch 0003, iter [03800, 05004], lr: 0.100000, loss: 6.2633, stu_CELoss: 3.0753, DKDLoss: 3.1879, 
2022-07-28 09:45:19 - train: epoch 0003, iter [03900, 05004], lr: 0.100000, loss: 6.3883, stu_CELoss: 3.2051, DKDLoss: 3.1833, 
2022-07-28 09:45:52 - train: epoch 0003, iter [04000, 05004], lr: 0.100000, loss: 5.6273, stu_CELoss: 2.6585, DKDLoss: 2.9688, 
2022-07-28 09:46:26 - train: epoch 0003, iter [04100, 05004], lr: 0.100000, loss: 5.4936, stu_CELoss: 2.8040, DKDLoss: 2.6896, 
2022-07-28 09:46:59 - train: epoch 0003, iter [04200, 05004], lr: 0.100000, loss: 5.5749, stu_CELoss: 2.8162, DKDLoss: 2.7587, 
2022-07-28 09:47:32 - train: epoch 0003, iter [04300, 05004], lr: 0.100000, loss: 5.5167, stu_CELoss: 2.6056, DKDLoss: 2.9110, 
2022-07-28 09:48:06 - train: epoch 0003, iter [04400, 05004], lr: 0.100000, loss: 5.4496, stu_CELoss: 2.7891, DKDLoss: 2.6605, 
2022-07-28 09:48:39 - train: epoch 0003, iter [04500, 05004], lr: 0.100000, loss: 5.5416, stu_CELoss: 2.6799, DKDLoss: 2.8617, 
2022-07-28 09:49:13 - train: epoch 0003, iter [04600, 05004], lr: 0.100000, loss: 5.4910, stu_CELoss: 2.5876, DKDLoss: 2.9034, 
2022-07-28 09:49:47 - train: epoch 0003, iter [04700, 05004], lr: 0.100000, loss: 5.4679, stu_CELoss: 2.7202, DKDLoss: 2.7477, 
2022-07-28 09:50:20 - train: epoch 0003, iter [04800, 05004], lr: 0.100000, loss: 6.1218, stu_CELoss: 3.0942, DKDLoss: 3.0276, 
2022-07-28 09:50:54 - train: epoch 0003, iter [04900, 05004], lr: 0.100000, loss: 5.7757, stu_CELoss: 2.8247, DKDLoss: 2.9509, 
2022-07-28 09:51:27 - train: epoch 0003, iter [05000, 05004], lr: 0.100000, loss: 5.8428, stu_CELoss: 2.8820, DKDLoss: 2.9608, 
2022-07-28 09:51:28 - train: epoch 003, train_loss: 6.0511
2022-07-28 09:54:00 - eval: epoch: 003, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 43.042%, stu_acc5: 69.546%, stu_test_loss: 2.5232
2022-07-28 09:54:00 - until epoch: 003, tea_best_acc1: 78.068%, stu_best_acc1: 43.042%
2022-07-28 09:54:00 - epoch 004 lr: 0.100000
2022-07-28 09:54:39 - train: epoch 0004, iter [00100, 05004], lr: 0.100000, loss: 5.5092, stu_CELoss: 2.8641, DKDLoss: 2.6450, 
2022-07-28 09:55:12 - train: epoch 0004, iter [00200, 05004], lr: 0.100000, loss: 5.4483, stu_CELoss: 2.6262, DKDLoss: 2.8221, 
2022-07-28 09:55:44 - train: epoch 0004, iter [00300, 05004], lr: 0.100000, loss: 5.6130, stu_CELoss: 2.7277, DKDLoss: 2.8854, 
2022-07-28 09:56:17 - train: epoch 0004, iter [00400, 05004], lr: 0.100000, loss: 5.4436, stu_CELoss: 2.6692, DKDLoss: 2.7744, 
2022-07-28 09:56:50 - train: epoch 0004, iter [00500, 05004], lr: 0.100000, loss: 5.5435, stu_CELoss: 2.5298, DKDLoss: 3.0137, 
2022-07-28 09:57:24 - train: epoch 0004, iter [00600, 05004], lr: 0.100000, loss: 5.5641, stu_CELoss: 2.8831, DKDLoss: 2.6811, 
2022-07-28 09:57:57 - train: epoch 0004, iter [00700, 05004], lr: 0.100000, loss: 5.6451, stu_CELoss: 2.9092, DKDLoss: 2.7359, 
2022-07-28 09:58:31 - train: epoch 0004, iter [00800, 05004], lr: 0.100000, loss: 5.6627, stu_CELoss: 2.7741, DKDLoss: 2.8886, 
2022-07-28 09:59:04 - train: epoch 0004, iter [00900, 05004], lr: 0.100000, loss: 5.1100, stu_CELoss: 2.4029, DKDLoss: 2.7072, 
2022-07-28 09:59:37 - train: epoch 0004, iter [01000, 05004], lr: 0.100000, loss: 5.5578, stu_CELoss: 2.7311, DKDLoss: 2.8267, 
2022-07-28 10:00:11 - train: epoch 0004, iter [01100, 05004], lr: 0.100000, loss: 5.5982, stu_CELoss: 2.8164, DKDLoss: 2.7818, 
2022-07-28 10:00:44 - train: epoch 0004, iter [01200, 05004], lr: 0.100000, loss: 5.2856, stu_CELoss: 2.4949, DKDLoss: 2.7907, 
2022-07-28 10:01:18 - train: epoch 0004, iter [01300, 05004], lr: 0.100000, loss: 5.2705, stu_CELoss: 2.5805, DKDLoss: 2.6900, 
2022-07-28 10:01:51 - train: epoch 0004, iter [01400, 05004], lr: 0.100000, loss: 5.6792, stu_CELoss: 2.8291, DKDLoss: 2.8501, 
2022-07-28 10:02:24 - train: epoch 0004, iter [01500, 05004], lr: 0.100000, loss: 5.2170, stu_CELoss: 2.5707, DKDLoss: 2.6463, 
2022-07-28 10:02:58 - train: epoch 0004, iter [01600, 05004], lr: 0.100000, loss: 5.4808, stu_CELoss: 2.7071, DKDLoss: 2.7737, 
2022-07-28 10:03:32 - train: epoch 0004, iter [01700, 05004], lr: 0.100000, loss: 5.5598, stu_CELoss: 2.6697, DKDLoss: 2.8901, 
2022-07-28 10:04:06 - train: epoch 0004, iter [01800, 05004], lr: 0.100000, loss: 5.7014, stu_CELoss: 2.8195, DKDLoss: 2.8819, 
2022-07-28 10:04:40 - train: epoch 0004, iter [01900, 05004], lr: 0.100000, loss: 5.5314, stu_CELoss: 2.7241, DKDLoss: 2.8073, 
2022-07-28 10:05:13 - train: epoch 0004, iter [02000, 05004], lr: 0.100000, loss: 5.3158, stu_CELoss: 2.6661, DKDLoss: 2.6497, 
2022-07-28 10:05:47 - train: epoch 0004, iter [02100, 05004], lr: 0.100000, loss: 5.3697, stu_CELoss: 2.6408, DKDLoss: 2.7288, 
2022-07-28 10:06:21 - train: epoch 0004, iter [02200, 05004], lr: 0.100000, loss: 5.1804, stu_CELoss: 2.6392, DKDLoss: 2.5412, 
2022-07-28 10:06:55 - train: epoch 0004, iter [02300, 05004], lr: 0.100000, loss: 4.9172, stu_CELoss: 2.3292, DKDLoss: 2.5880, 
2022-07-28 10:07:28 - train: epoch 0004, iter [02400, 05004], lr: 0.100000, loss: 4.9590, stu_CELoss: 2.4503, DKDLoss: 2.5086, 
2022-07-28 10:08:02 - train: epoch 0004, iter [02500, 05004], lr: 0.100000, loss: 4.9153, stu_CELoss: 2.4126, DKDLoss: 2.5027, 
2022-07-28 10:08:37 - train: epoch 0004, iter [02600, 05004], lr: 0.100000, loss: 5.3600, stu_CELoss: 2.6396, DKDLoss: 2.7204, 
2022-07-28 10:09:10 - train: epoch 0004, iter [02700, 05004], lr: 0.100000, loss: 4.9994, stu_CELoss: 2.5043, DKDLoss: 2.4951, 
2022-07-28 10:09:44 - train: epoch 0004, iter [02800, 05004], lr: 0.100000, loss: 5.0910, stu_CELoss: 2.5115, DKDLoss: 2.5795, 
2022-07-28 10:10:17 - train: epoch 0004, iter [02900, 05004], lr: 0.100000, loss: 5.4602, stu_CELoss: 2.6370, DKDLoss: 2.8232, 
2022-07-28 10:10:51 - train: epoch 0004, iter [03000, 05004], lr: 0.100000, loss: 5.3613, stu_CELoss: 2.6601, DKDLoss: 2.7011, 
2022-07-28 10:11:25 - train: epoch 0004, iter [03100, 05004], lr: 0.100000, loss: 5.4959, stu_CELoss: 2.7438, DKDLoss: 2.7521, 
2022-07-28 10:11:58 - train: epoch 0004, iter [03200, 05004], lr: 0.100000, loss: 5.6978, stu_CELoss: 2.7366, DKDLoss: 2.9613, 
2022-07-28 10:12:32 - train: epoch 0004, iter [03300, 05004], lr: 0.100000, loss: 5.3977, stu_CELoss: 2.6824, DKDLoss: 2.7153, 
2022-07-28 10:13:06 - train: epoch 0004, iter [03400, 05004], lr: 0.100000, loss: 5.1543, stu_CELoss: 2.5191, DKDLoss: 2.6352, 
2022-07-28 10:13:40 - train: epoch 0004, iter [03500, 05004], lr: 0.100000, loss: 4.9963, stu_CELoss: 2.5127, DKDLoss: 2.4836, 
2022-07-28 10:14:14 - train: epoch 0004, iter [03600, 05004], lr: 0.100000, loss: 4.9247, stu_CELoss: 2.5283, DKDLoss: 2.3964, 
2022-07-28 10:14:48 - train: epoch 0004, iter [03700, 05004], lr: 0.100000, loss: 5.0838, stu_CELoss: 2.5488, DKDLoss: 2.5350, 
2022-07-28 10:15:22 - train: epoch 0004, iter [03800, 05004], lr: 0.100000, loss: 4.9557, stu_CELoss: 2.3864, DKDLoss: 2.5692, 
2022-07-28 10:15:56 - train: epoch 0004, iter [03900, 05004], lr: 0.100000, loss: 5.1071, stu_CELoss: 2.4886, DKDLoss: 2.6185, 
2022-07-28 10:16:30 - train: epoch 0004, iter [04000, 05004], lr: 0.100000, loss: 4.9752, stu_CELoss: 2.4927, DKDLoss: 2.4824, 
2022-07-28 10:17:04 - train: epoch 0004, iter [04100, 05004], lr: 0.100000, loss: 5.0826, stu_CELoss: 2.4655, DKDLoss: 2.6171, 
2022-07-28 10:17:37 - train: epoch 0004, iter [04200, 05004], lr: 0.100000, loss: 5.0548, stu_CELoss: 2.4441, DKDLoss: 2.6107, 
2022-07-28 10:18:11 - train: epoch 0004, iter [04300, 05004], lr: 0.100000, loss: 4.9182, stu_CELoss: 2.4018, DKDLoss: 2.5164, 
2022-07-28 10:18:45 - train: epoch 0004, iter [04400, 05004], lr: 0.100000, loss: 5.0785, stu_CELoss: 2.4743, DKDLoss: 2.6042, 
2022-07-28 10:19:18 - train: epoch 0004, iter [04500, 05004], lr: 0.100000, loss: 4.5413, stu_CELoss: 2.1676, DKDLoss: 2.3737, 
2022-07-28 10:19:52 - train: epoch 0004, iter [04600, 05004], lr: 0.100000, loss: 4.8191, stu_CELoss: 2.3075, DKDLoss: 2.5116, 
2022-07-28 10:20:26 - train: epoch 0004, iter [04700, 05004], lr: 0.100000, loss: 4.9560, stu_CELoss: 2.4092, DKDLoss: 2.5468, 
2022-07-28 10:20:59 - train: epoch 0004, iter [04800, 05004], lr: 0.100000, loss: 4.6160, stu_CELoss: 2.1955, DKDLoss: 2.4205, 
2022-07-28 10:21:33 - train: epoch 0004, iter [04900, 05004], lr: 0.100000, loss: 5.1612, stu_CELoss: 2.6664, DKDLoss: 2.4948, 
2022-07-28 10:22:06 - train: epoch 0004, iter [05000, 05004], lr: 0.100000, loss: 5.2718, stu_CELoss: 2.5325, DKDLoss: 2.7393, 
2022-07-28 10:22:08 - train: epoch 004, train_loss: 5.3139
2022-07-28 10:24:41 - eval: epoch: 004, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 47.620%, stu_acc5: 73.812%, stu_test_loss: 2.2873
2022-07-28 10:24:42 - until epoch: 004, tea_best_acc1: 78.068%, stu_best_acc1: 47.620%
2022-07-28 10:24:42 - epoch 005 lr: 0.100000
2022-07-28 10:25:22 - train: epoch 0005, iter [00100, 05004], lr: 0.100000, loss: 4.9991, stu_CELoss: 2.5298, DKDLoss: 2.4693, 
2022-07-28 10:25:56 - train: epoch 0005, iter [00200, 05004], lr: 0.100000, loss: 5.1598, stu_CELoss: 2.5135, DKDLoss: 2.6464, 
2022-07-28 10:26:29 - train: epoch 0005, iter [00300, 05004], lr: 0.100000, loss: 5.4153, stu_CELoss: 2.7525, DKDLoss: 2.6627, 
2022-07-28 10:27:03 - train: epoch 0005, iter [00400, 05004], lr: 0.100000, loss: 4.7119, stu_CELoss: 2.3438, DKDLoss: 2.3681, 
2022-07-28 10:27:36 - train: epoch 0005, iter [00500, 05004], lr: 0.100000, loss: 4.7164, stu_CELoss: 2.3394, DKDLoss: 2.3771, 
2022-07-28 10:28:10 - train: epoch 0005, iter [00600, 05004], lr: 0.100000, loss: 5.0645, stu_CELoss: 2.5676, DKDLoss: 2.4969, 
2022-07-28 10:28:44 - train: epoch 0005, iter [00700, 05004], lr: 0.100000, loss: 4.7880, stu_CELoss: 2.4367, DKDLoss: 2.3513, 
2022-07-28 10:29:17 - train: epoch 0005, iter [00800, 05004], lr: 0.100000, loss: 5.5821, stu_CELoss: 2.8633, DKDLoss: 2.7188, 
2022-07-28 10:29:51 - train: epoch 0005, iter [00900, 05004], lr: 0.100000, loss: 4.7884, stu_CELoss: 2.4166, DKDLoss: 2.3718, 
2022-07-28 10:30:25 - train: epoch 0005, iter [01000, 05004], lr: 0.100000, loss: 5.0493, stu_CELoss: 2.4963, DKDLoss: 2.5530, 
2022-07-28 10:30:59 - train: epoch 0005, iter [01100, 05004], lr: 0.100000, loss: 5.1521, stu_CELoss: 2.4644, DKDLoss: 2.6877, 
2022-07-28 10:31:34 - train: epoch 0005, iter [01200, 05004], lr: 0.100000, loss: 5.1341, stu_CELoss: 2.5191, DKDLoss: 2.6150, 
2022-07-28 10:32:08 - train: epoch 0005, iter [01300, 05004], lr: 0.100000, loss: 4.8405, stu_CELoss: 2.4356, DKDLoss: 2.4048, 
2022-07-28 10:32:42 - train: epoch 0005, iter [01400, 05004], lr: 0.100000, loss: 4.9956, stu_CELoss: 2.5299, DKDLoss: 2.4657, 
2022-07-28 10:33:16 - train: epoch 0005, iter [01500, 05004], lr: 0.100000, loss: 4.7943, stu_CELoss: 2.3425, DKDLoss: 2.4518, 
2022-07-28 10:33:49 - train: epoch 0005, iter [01600, 05004], lr: 0.100000, loss: 4.2952, stu_CELoss: 2.1361, DKDLoss: 2.1591, 
2022-07-28 10:34:23 - train: epoch 0005, iter [01700, 05004], lr: 0.100000, loss: 4.9361, stu_CELoss: 2.4638, DKDLoss: 2.4723, 
2022-07-28 10:34:57 - train: epoch 0005, iter [01800, 05004], lr: 0.100000, loss: 4.6978, stu_CELoss: 2.2824, DKDLoss: 2.4154, 
2022-07-28 10:35:31 - train: epoch 0005, iter [01900, 05004], lr: 0.100000, loss: 4.8871, stu_CELoss: 2.3702, DKDLoss: 2.5169, 
2022-07-28 10:36:05 - train: epoch 0005, iter [02000, 05004], lr: 0.100000, loss: 4.7711, stu_CELoss: 2.3893, DKDLoss: 2.3817, 
2022-07-28 10:36:40 - train: epoch 0005, iter [02100, 05004], lr: 0.100000, loss: 4.5507, stu_CELoss: 2.2888, DKDLoss: 2.2619, 
2022-07-28 10:37:14 - train: epoch 0005, iter [02200, 05004], lr: 0.100000, loss: 4.9919, stu_CELoss: 2.3117, DKDLoss: 2.6802, 
2022-07-28 10:37:48 - train: epoch 0005, iter [02300, 05004], lr: 0.100000, loss: 4.2681, stu_CELoss: 2.0573, DKDLoss: 2.2108, 
2022-07-28 10:38:23 - train: epoch 0005, iter [02400, 05004], lr: 0.100000, loss: 4.7753, stu_CELoss: 2.3642, DKDLoss: 2.4111, 
2022-07-28 10:38:57 - train: epoch 0005, iter [02500, 05004], lr: 0.100000, loss: 5.1386, stu_CELoss: 2.5271, DKDLoss: 2.6115, 
2022-07-28 10:39:31 - train: epoch 0005, iter [02600, 05004], lr: 0.100000, loss: 4.8713, stu_CELoss: 2.3712, DKDLoss: 2.5001, 
2022-07-28 10:40:06 - train: epoch 0005, iter [02700, 05004], lr: 0.100000, loss: 5.0328, stu_CELoss: 2.5371, DKDLoss: 2.4957, 
2022-07-28 10:40:40 - train: epoch 0005, iter [02800, 05004], lr: 0.100000, loss: 4.8378, stu_CELoss: 2.3689, DKDLoss: 2.4689, 
2022-07-28 10:41:14 - train: epoch 0005, iter [02900, 05004], lr: 0.100000, loss: 4.9463, stu_CELoss: 2.5127, DKDLoss: 2.4335, 
2022-07-28 10:41:49 - train: epoch 0005, iter [03000, 05004], lr: 0.100000, loss: 4.9636, stu_CELoss: 2.5206, DKDLoss: 2.4429, 
2022-07-28 10:42:23 - train: epoch 0005, iter [03100, 05004], lr: 0.100000, loss: 4.8640, stu_CELoss: 2.3595, DKDLoss: 2.5045, 
2022-07-28 10:42:57 - train: epoch 0005, iter [03200, 05004], lr: 0.100000, loss: 4.8751, stu_CELoss: 2.4481, DKDLoss: 2.4269, 
2022-07-28 10:43:31 - train: epoch 0005, iter [03300, 05004], lr: 0.100000, loss: 4.5448, stu_CELoss: 2.2273, DKDLoss: 2.3175, 
2022-07-28 10:44:06 - train: epoch 0005, iter [03400, 05004], lr: 0.100000, loss: 4.8473, stu_CELoss: 2.4778, DKDLoss: 2.3696, 
2022-07-28 10:44:41 - train: epoch 0005, iter [03500, 05004], lr: 0.100000, loss: 4.9938, stu_CELoss: 2.6185, DKDLoss: 2.3753, 
2022-07-28 10:45:15 - train: epoch 0005, iter [03600, 05004], lr: 0.100000, loss: 4.7017, stu_CELoss: 2.3866, DKDLoss: 2.3150, 
2022-07-28 10:45:48 - train: epoch 0005, iter [03700, 05004], lr: 0.100000, loss: 4.8205, stu_CELoss: 2.3277, DKDLoss: 2.4927, 
2022-07-28 10:46:22 - train: epoch 0005, iter [03800, 05004], lr: 0.100000, loss: 5.0097, stu_CELoss: 2.4739, DKDLoss: 2.5359, 
2022-07-28 10:46:56 - train: epoch 0005, iter [03900, 05004], lr: 0.100000, loss: 4.9807, stu_CELoss: 2.4818, DKDLoss: 2.4989, 
2022-07-28 10:47:29 - train: epoch 0005, iter [04000, 05004], lr: 0.100000, loss: 4.6343, stu_CELoss: 2.3116, DKDLoss: 2.3227, 
2022-07-28 10:48:03 - train: epoch 0005, iter [04100, 05004], lr: 0.100000, loss: 4.8150, stu_CELoss: 2.3707, DKDLoss: 2.4442, 
2022-07-28 10:48:37 - train: epoch 0005, iter [04200, 05004], lr: 0.100000, loss: 4.8468, stu_CELoss: 2.4960, DKDLoss: 2.3509, 
2022-07-28 10:49:10 - train: epoch 0005, iter [04300, 05004], lr: 0.100000, loss: 4.6766, stu_CELoss: 2.4255, DKDLoss: 2.2512, 
2022-07-28 10:49:44 - train: epoch 0005, iter [04400, 05004], lr: 0.100000, loss: 5.0042, stu_CELoss: 2.5295, DKDLoss: 2.4747, 
2022-07-28 10:50:18 - train: epoch 0005, iter [04500, 05004], lr: 0.100000, loss: 4.9784, stu_CELoss: 2.4859, DKDLoss: 2.4925, 
2022-07-28 10:50:51 - train: epoch 0005, iter [04600, 05004], lr: 0.100000, loss: 4.7532, stu_CELoss: 2.3514, DKDLoss: 2.4019, 
2022-07-28 10:51:25 - train: epoch 0005, iter [04700, 05004], lr: 0.100000, loss: 4.3752, stu_CELoss: 2.1858, DKDLoss: 2.1894, 
2022-07-28 10:51:59 - train: epoch 0005, iter [04800, 05004], lr: 0.100000, loss: 4.2431, stu_CELoss: 2.2246, DKDLoss: 2.0185, 
2022-07-28 10:52:32 - train: epoch 0005, iter [04900, 05004], lr: 0.100000, loss: 5.0542, stu_CELoss: 2.6122, DKDLoss: 2.4420, 
2022-07-28 10:53:05 - train: epoch 0005, iter [05000, 05004], lr: 0.100000, loss: 4.3576, stu_CELoss: 2.2617, DKDLoss: 2.0960, 
2022-07-28 10:53:07 - train: epoch 005, train_loss: 4.8626
2022-07-28 10:55:40 - eval: epoch: 005, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 45.012%, stu_acc5: 70.410%, stu_test_loss: 2.8504
2022-07-28 10:55:41 - until epoch: 005, tea_best_acc1: 78.068%, stu_best_acc1: 47.620%
2022-07-28 10:55:41 - epoch 006 lr: 0.100000
2022-07-28 10:56:21 - train: epoch 0006, iter [00100, 05004], lr: 0.100000, loss: 4.3214, stu_CELoss: 2.1851, DKDLoss: 2.1362, 
2022-07-28 10:56:55 - train: epoch 0006, iter [00200, 05004], lr: 0.100000, loss: 4.3822, stu_CELoss: 2.2520, DKDLoss: 2.1302, 
2022-07-28 10:57:28 - train: epoch 0006, iter [00300, 05004], lr: 0.100000, loss: 4.5387, stu_CELoss: 2.1675, DKDLoss: 2.3713, 
2022-07-28 10:58:02 - train: epoch 0006, iter [00400, 05004], lr: 0.100000, loss: 4.4432, stu_CELoss: 2.3065, DKDLoss: 2.1367, 
2022-07-28 10:58:35 - train: epoch 0006, iter [00500, 05004], lr: 0.100000, loss: 4.4033, stu_CELoss: 2.2196, DKDLoss: 2.1837, 
2022-07-28 10:59:09 - train: epoch 0006, iter [00600, 05004], lr: 0.100000, loss: 4.4015, stu_CELoss: 2.1361, DKDLoss: 2.2654, 
2022-07-28 10:59:42 - train: epoch 0006, iter [00700, 05004], lr: 0.100000, loss: 4.8004, stu_CELoss: 2.4603, DKDLoss: 2.3400, 
2022-07-28 11:00:16 - train: epoch 0006, iter [00800, 05004], lr: 0.100000, loss: 4.3916, stu_CELoss: 2.1711, DKDLoss: 2.2205, 
2022-07-28 11:00:49 - train: epoch 0006, iter [00900, 05004], lr: 0.100000, loss: 4.5729, stu_CELoss: 2.2814, DKDLoss: 2.2916, 
2022-07-28 11:01:23 - train: epoch 0006, iter [01000, 05004], lr: 0.100000, loss: 4.9425, stu_CELoss: 2.4283, DKDLoss: 2.5142, 
2022-07-28 11:01:56 - train: epoch 0006, iter [01100, 05004], lr: 0.100000, loss: 4.8306, stu_CELoss: 2.4022, DKDLoss: 2.4284, 
2022-07-28 11:02:30 - train: epoch 0006, iter [01200, 05004], lr: 0.100000, loss: 4.5642, stu_CELoss: 2.3531, DKDLoss: 2.2112, 
2022-07-28 11:03:04 - train: epoch 0006, iter [01300, 05004], lr: 0.100000, loss: 4.6214, stu_CELoss: 2.3344, DKDLoss: 2.2871, 
2022-07-28 11:03:37 - train: epoch 0006, iter [01400, 05004], lr: 0.100000, loss: 4.5957, stu_CELoss: 2.3992, DKDLoss: 2.1965, 
2022-07-28 11:04:11 - train: epoch 0006, iter [01500, 05004], lr: 0.100000, loss: 5.1837, stu_CELoss: 2.5769, DKDLoss: 2.6068, 
2022-07-28 11:04:44 - train: epoch 0006, iter [01600, 05004], lr: 0.100000, loss: 4.3931, stu_CELoss: 2.1583, DKDLoss: 2.2348, 
2022-07-28 11:05:18 - train: epoch 0006, iter [01700, 05004], lr: 0.100000, loss: 4.6745, stu_CELoss: 2.4222, DKDLoss: 2.2524, 
2022-07-28 11:05:51 - train: epoch 0006, iter [01800, 05004], lr: 0.100000, loss: 4.7113, stu_CELoss: 2.3681, DKDLoss: 2.3432, 
2022-07-28 11:06:25 - train: epoch 0006, iter [01900, 05004], lr: 0.100000, loss: 4.3222, stu_CELoss: 2.1616, DKDLoss: 2.1605, 
2022-07-28 11:06:59 - train: epoch 0006, iter [02000, 05004], lr: 0.100000, loss: 5.0291, stu_CELoss: 2.5327, DKDLoss: 2.4964, 
2022-07-28 11:07:33 - train: epoch 0006, iter [02100, 05004], lr: 0.100000, loss: 4.6154, stu_CELoss: 2.3234, DKDLoss: 2.2921, 
2022-07-28 11:08:06 - train: epoch 0006, iter [02200, 05004], lr: 0.100000, loss: 4.2683, stu_CELoss: 2.0745, DKDLoss: 2.1938, 
2022-07-28 11:08:40 - train: epoch 0006, iter [02300, 05004], lr: 0.100000, loss: 4.2368, stu_CELoss: 2.2020, DKDLoss: 2.0348, 
2022-07-28 11:09:13 - train: epoch 0006, iter [02400, 05004], lr: 0.100000, loss: 4.6572, stu_CELoss: 2.2890, DKDLoss: 2.3682, 
2022-07-28 11:09:47 - train: epoch 0006, iter [02500, 05004], lr: 0.100000, loss: 4.4503, stu_CELoss: 2.1628, DKDLoss: 2.2875, 
2022-07-28 11:10:20 - train: epoch 0006, iter [02600, 05004], lr: 0.100000, loss: 4.4205, stu_CELoss: 2.2942, DKDLoss: 2.1263, 
2022-07-28 11:10:54 - train: epoch 0006, iter [02700, 05004], lr: 0.100000, loss: 4.7406, stu_CELoss: 2.3583, DKDLoss: 2.3824, 
2022-07-28 11:11:27 - train: epoch 0006, iter [02800, 05004], lr: 0.100000, loss: 4.1761, stu_CELoss: 2.0934, DKDLoss: 2.0827, 
2022-07-28 11:12:01 - train: epoch 0006, iter [02900, 05004], lr: 0.100000, loss: 4.3805, stu_CELoss: 2.2402, DKDLoss: 2.1402, 
2022-07-28 11:12:34 - train: epoch 0006, iter [03000, 05004], lr: 0.100000, loss: 4.4918, stu_CELoss: 2.2390, DKDLoss: 2.2528, 
2022-07-28 11:13:07 - train: epoch 0006, iter [03100, 05004], lr: 0.100000, loss: 4.2737, stu_CELoss: 2.1332, DKDLoss: 2.1405, 
2022-07-28 11:13:40 - train: epoch 0006, iter [03200, 05004], lr: 0.100000, loss: 4.4613, stu_CELoss: 2.2094, DKDLoss: 2.2518, 
2022-07-28 11:14:14 - train: epoch 0006, iter [03300, 05004], lr: 0.100000, loss: 4.7701, stu_CELoss: 2.2653, DKDLoss: 2.5047, 
2022-07-28 11:14:47 - train: epoch 0006, iter [03400, 05004], lr: 0.100000, loss: 4.6380, stu_CELoss: 2.2834, DKDLoss: 2.3546, 
2022-07-28 11:15:21 - train: epoch 0006, iter [03500, 05004], lr: 0.100000, loss: 4.5856, stu_CELoss: 2.3022, DKDLoss: 2.2834, 
2022-07-28 11:15:54 - train: epoch 0006, iter [03600, 05004], lr: 0.100000, loss: 4.4735, stu_CELoss: 2.2707, DKDLoss: 2.2028, 
2022-07-28 11:16:27 - train: epoch 0006, iter [03700, 05004], lr: 0.100000, loss: 4.2532, stu_CELoss: 2.1229, DKDLoss: 2.1303, 
2022-07-28 11:17:00 - train: epoch 0006, iter [03800, 05004], lr: 0.100000, loss: 4.2255, stu_CELoss: 2.1184, DKDLoss: 2.1071, 
2022-07-28 11:17:34 - train: epoch 0006, iter [03900, 05004], lr: 0.100000, loss: 4.5532, stu_CELoss: 2.3084, DKDLoss: 2.2448, 
2022-07-28 11:18:07 - train: epoch 0006, iter [04000, 05004], lr: 0.100000, loss: 4.3289, stu_CELoss: 2.1828, DKDLoss: 2.1462, 
2022-07-28 11:18:41 - train: epoch 0006, iter [04100, 05004], lr: 0.100000, loss: 4.5502, stu_CELoss: 2.2897, DKDLoss: 2.2605, 
2022-07-28 11:19:14 - train: epoch 0006, iter [04200, 05004], lr: 0.100000, loss: 4.2119, stu_CELoss: 2.0569, DKDLoss: 2.1550, 
2022-07-28 11:19:47 - train: epoch 0006, iter [04300, 05004], lr: 0.100000, loss: 4.6676, stu_CELoss: 2.3135, DKDLoss: 2.3542, 
2022-07-28 11:20:21 - train: epoch 0006, iter [04400, 05004], lr: 0.100000, loss: 4.5915, stu_CELoss: 2.2348, DKDLoss: 2.3567, 
2022-07-28 11:20:54 - train: epoch 0006, iter [04500, 05004], lr: 0.100000, loss: 4.6882, stu_CELoss: 2.4215, DKDLoss: 2.2667, 
2022-07-28 11:21:27 - train: epoch 0006, iter [04600, 05004], lr: 0.100000, loss: 4.3558, stu_CELoss: 2.1659, DKDLoss: 2.1898, 
2022-07-28 11:22:01 - train: epoch 0006, iter [04700, 05004], lr: 0.100000, loss: 4.1959, stu_CELoss: 2.1312, DKDLoss: 2.0648, 
2022-07-28 11:22:34 - train: epoch 0006, iter [04800, 05004], lr: 0.100000, loss: 4.4413, stu_CELoss: 2.1885, DKDLoss: 2.2528, 
2022-07-28 11:23:08 - train: epoch 0006, iter [04900, 05004], lr: 0.100000, loss: 4.5795, stu_CELoss: 2.3564, DKDLoss: 2.2230, 
2022-07-28 11:23:41 - train: epoch 0006, iter [05000, 05004], lr: 0.100000, loss: 4.5178, stu_CELoss: 2.1847, DKDLoss: 2.3332, 
2022-07-28 11:23:42 - train: epoch 006, train_loss: 4.5811
2022-07-28 11:26:16 - eval: epoch: 006, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 50.590%, stu_acc5: 75.970%, stu_test_loss: 2.1320
2022-07-28 11:26:17 - until epoch: 006, tea_best_acc1: 78.068%, stu_best_acc1: 50.590%
2022-07-28 11:26:17 - epoch 007 lr: 0.100000
2022-07-28 11:26:57 - train: epoch 0007, iter [00100, 05004], lr: 0.100000, loss: 4.3218, stu_CELoss: 2.0841, DKDLoss: 2.2377, 
2022-07-28 11:27:30 - train: epoch 0007, iter [00200, 05004], lr: 0.100000, loss: 4.5250, stu_CELoss: 2.2066, DKDLoss: 2.3184, 
2022-07-28 11:28:04 - train: epoch 0007, iter [00300, 05004], lr: 0.100000, loss: 4.8990, stu_CELoss: 2.4551, DKDLoss: 2.4440, 
2022-07-28 11:28:36 - train: epoch 0007, iter [00400, 05004], lr: 0.100000, loss: 4.3023, stu_CELoss: 2.2339, DKDLoss: 2.0684, 
2022-07-28 11:29:10 - train: epoch 0007, iter [00500, 05004], lr: 0.100000, loss: 4.0135, stu_CELoss: 2.0027, DKDLoss: 2.0108, 
2022-07-28 11:29:43 - train: epoch 0007, iter [00600, 05004], lr: 0.100000, loss: 4.7792, stu_CELoss: 2.4757, DKDLoss: 2.3035, 
2022-07-28 11:30:15 - train: epoch 0007, iter [00700, 05004], lr: 0.100000, loss: 4.3984, stu_CELoss: 2.2183, DKDLoss: 2.1801, 
2022-07-28 11:30:49 - train: epoch 0007, iter [00800, 05004], lr: 0.100000, loss: 4.5400, stu_CELoss: 2.3032, DKDLoss: 2.2368, 
2022-07-28 11:31:22 - train: epoch 0007, iter [00900, 05004], lr: 0.100000, loss: 4.3235, stu_CELoss: 2.1882, DKDLoss: 2.1353, 
2022-07-28 11:31:55 - train: epoch 0007, iter [01000, 05004], lr: 0.100000, loss: 4.2284, stu_CELoss: 2.1775, DKDLoss: 2.0509, 
2022-07-28 11:32:29 - train: epoch 0007, iter [01100, 05004], lr: 0.100000, loss: 4.5788, stu_CELoss: 2.2957, DKDLoss: 2.2831, 
2022-07-28 11:33:02 - train: epoch 0007, iter [01200, 05004], lr: 0.100000, loss: 4.3623, stu_CELoss: 2.1846, DKDLoss: 2.1777, 
2022-07-28 11:33:35 - train: epoch 0007, iter [01300, 05004], lr: 0.100000, loss: 4.1095, stu_CELoss: 1.9710, DKDLoss: 2.1385, 
2022-07-28 11:34:08 - train: epoch 0007, iter [01400, 05004], lr: 0.100000, loss: 4.6041, stu_CELoss: 2.3109, DKDLoss: 2.2932, 
2022-07-28 11:34:41 - train: epoch 0007, iter [01500, 05004], lr: 0.100000, loss: 4.5899, stu_CELoss: 2.2854, DKDLoss: 2.3045, 
2022-07-28 11:35:14 - train: epoch 0007, iter [01600, 05004], lr: 0.100000, loss: 4.4987, stu_CELoss: 2.2528, DKDLoss: 2.2458, 
2022-07-28 11:35:47 - train: epoch 0007, iter [01700, 05004], lr: 0.100000, loss: 4.1020, stu_CELoss: 2.0347, DKDLoss: 2.0673, 
2022-07-28 11:36:21 - train: epoch 0007, iter [01800, 05004], lr: 0.100000, loss: 4.5878, stu_CELoss: 2.4133, DKDLoss: 2.1744, 
2022-07-28 11:36:54 - train: epoch 0007, iter [01900, 05004], lr: 0.100000, loss: 4.4150, stu_CELoss: 2.1486, DKDLoss: 2.2663, 
2022-07-28 11:37:27 - train: epoch 0007, iter [02000, 05004], lr: 0.100000, loss: 3.9571, stu_CELoss: 1.8690, DKDLoss: 2.0880, 
2022-07-28 11:38:01 - train: epoch 0007, iter [02100, 05004], lr: 0.100000, loss: 4.6667, stu_CELoss: 2.3541, DKDLoss: 2.3125, 
2022-07-28 11:38:34 - train: epoch 0007, iter [02200, 05004], lr: 0.100000, loss: 4.0819, stu_CELoss: 2.0055, DKDLoss: 2.0764, 
2022-07-28 11:39:07 - train: epoch 0007, iter [02300, 05004], lr: 0.100000, loss: 4.3114, stu_CELoss: 2.2150, DKDLoss: 2.0964, 
2022-07-28 11:39:41 - train: epoch 0007, iter [02400, 05004], lr: 0.100000, loss: 4.7424, stu_CELoss: 2.3438, DKDLoss: 2.3986, 
2022-07-28 11:40:14 - train: epoch 0007, iter [02500, 05004], lr: 0.100000, loss: 4.3357, stu_CELoss: 2.1639, DKDLoss: 2.1718, 
2022-07-28 11:40:48 - train: epoch 0007, iter [02600, 05004], lr: 0.100000, loss: 4.3118, stu_CELoss: 2.1070, DKDLoss: 2.2048, 
2022-07-28 11:41:21 - train: epoch 0007, iter [02700, 05004], lr: 0.100000, loss: 4.2203, stu_CELoss: 2.1254, DKDLoss: 2.0949, 
2022-07-28 11:41:55 - train: epoch 0007, iter [02800, 05004], lr: 0.100000, loss: 4.1718, stu_CELoss: 2.1670, DKDLoss: 2.0048, 
2022-07-28 11:42:28 - train: epoch 0007, iter [02900, 05004], lr: 0.100000, loss: 4.1949, stu_CELoss: 2.0856, DKDLoss: 2.1094, 
2022-07-28 11:43:02 - train: epoch 0007, iter [03000, 05004], lr: 0.100000, loss: 4.6780, stu_CELoss: 2.3967, DKDLoss: 2.2812, 
2022-07-28 11:43:36 - train: epoch 0007, iter [03100, 05004], lr: 0.100000, loss: 3.9648, stu_CELoss: 2.0790, DKDLoss: 1.8858, 
2022-07-28 11:44:09 - train: epoch 0007, iter [03200, 05004], lr: 0.100000, loss: 4.0834, stu_CELoss: 1.9470, DKDLoss: 2.1363, 
2022-07-28 11:44:43 - train: epoch 0007, iter [03300, 05004], lr: 0.100000, loss: 4.6993, stu_CELoss: 2.3968, DKDLoss: 2.3025, 
2022-07-28 11:45:17 - train: epoch 0007, iter [03400, 05004], lr: 0.100000, loss: 4.7240, stu_CELoss: 2.4035, DKDLoss: 2.3205, 
2022-07-28 11:45:51 - train: epoch 0007, iter [03500, 05004], lr: 0.100000, loss: 4.6005, stu_CELoss: 2.3419, DKDLoss: 2.2586, 
2022-07-28 11:46:24 - train: epoch 0007, iter [03600, 05004], lr: 0.100000, loss: 4.3123, stu_CELoss: 2.1369, DKDLoss: 2.1754, 
2022-07-28 11:46:58 - train: epoch 0007, iter [03700, 05004], lr: 0.100000, loss: 4.2414, stu_CELoss: 2.0871, DKDLoss: 2.1543, 
2022-07-28 11:47:31 - train: epoch 0007, iter [03800, 05004], lr: 0.100000, loss: 4.6667, stu_CELoss: 2.4056, DKDLoss: 2.2611, 
2022-07-28 11:48:04 - train: epoch 0007, iter [03900, 05004], lr: 0.100000, loss: 4.4507, stu_CELoss: 2.2759, DKDLoss: 2.1748, 
2022-07-28 11:48:37 - train: epoch 0007, iter [04000, 05004], lr: 0.100000, loss: 4.3665, stu_CELoss: 2.2552, DKDLoss: 2.1113, 
2022-07-28 11:49:11 - train: epoch 0007, iter [04100, 05004], lr: 0.100000, loss: 4.3495, stu_CELoss: 2.1401, DKDLoss: 2.2094, 
2022-07-28 11:49:45 - train: epoch 0007, iter [04200, 05004], lr: 0.100000, loss: 4.2686, stu_CELoss: 2.0574, DKDLoss: 2.2111, 
2022-07-28 11:50:18 - train: epoch 0007, iter [04300, 05004], lr: 0.100000, loss: 4.4617, stu_CELoss: 2.2835, DKDLoss: 2.1782, 
2022-07-28 11:50:52 - train: epoch 0007, iter [04400, 05004], lr: 0.100000, loss: 4.0821, stu_CELoss: 2.0683, DKDLoss: 2.0138, 
2022-07-28 11:51:26 - train: epoch 0007, iter [04500, 05004], lr: 0.100000, loss: 4.5108, stu_CELoss: 2.2374, DKDLoss: 2.2734, 
2022-07-28 11:52:00 - train: epoch 0007, iter [04600, 05004], lr: 0.100000, loss: 4.6424, stu_CELoss: 2.2479, DKDLoss: 2.3946, 
2022-07-28 11:52:35 - train: epoch 0007, iter [04700, 05004], lr: 0.100000, loss: 4.0494, stu_CELoss: 2.0201, DKDLoss: 2.0293, 
2022-07-28 11:53:09 - train: epoch 0007, iter [04800, 05004], lr: 0.100000, loss: 4.5866, stu_CELoss: 2.3774, DKDLoss: 2.2092, 
2022-07-28 11:53:43 - train: epoch 0007, iter [04900, 05004], lr: 0.100000, loss: 4.2032, stu_CELoss: 2.1625, DKDLoss: 2.0407, 
2022-07-28 11:54:17 - train: epoch 0007, iter [05000, 05004], lr: 0.100000, loss: 4.2296, stu_CELoss: 2.1179, DKDLoss: 2.1118, 
2022-07-28 11:54:18 - train: epoch 007, train_loss: 4.3579
2022-07-28 11:56:56 - eval: epoch: 007, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 52.524%, stu_acc5: 77.912%, stu_test_loss: 2.0142
2022-07-28 11:56:56 - until epoch: 007, tea_best_acc1: 78.068%, stu_best_acc1: 52.524%
2022-07-28 11:56:56 - epoch 008 lr: 0.100000
2022-07-28 11:57:37 - train: epoch 0008, iter [00100, 05004], lr: 0.100000, loss: 4.3175, stu_CELoss: 2.1676, DKDLoss: 2.1499, 
2022-07-28 11:58:10 - train: epoch 0008, iter [00200, 05004], lr: 0.100000, loss: 4.2627, stu_CELoss: 2.1662, DKDLoss: 2.0965, 
2022-07-28 11:58:44 - train: epoch 0008, iter [00300, 05004], lr: 0.100000, loss: 4.2142, stu_CELoss: 2.0983, DKDLoss: 2.1159, 
2022-07-28 11:59:18 - train: epoch 0008, iter [00400, 05004], lr: 0.100000, loss: 4.0721, stu_CELoss: 2.0453, DKDLoss: 2.0268, 
2022-07-28 11:59:52 - train: epoch 0008, iter [00500, 05004], lr: 0.100000, loss: 4.0834, stu_CELoss: 1.9513, DKDLoss: 2.1320, 
2022-07-28 12:00:26 - train: epoch 0008, iter [00600, 05004], lr: 0.100000, loss: 4.0095, stu_CELoss: 2.0314, DKDLoss: 1.9781, 
2022-07-28 12:01:00 - train: epoch 0008, iter [00700, 05004], lr: 0.100000, loss: 4.4812, stu_CELoss: 2.2454, DKDLoss: 2.2358, 
2022-07-28 12:01:35 - train: epoch 0008, iter [00800, 05004], lr: 0.100000, loss: 3.7933, stu_CELoss: 1.8756, DKDLoss: 1.9177, 
2022-07-28 12:02:09 - train: epoch 0008, iter [00900, 05004], lr: 0.100000, loss: 4.2035, stu_CELoss: 2.1792, DKDLoss: 2.0244, 
2022-07-28 12:02:43 - train: epoch 0008, iter [01000, 05004], lr: 0.100000, loss: 4.2333, stu_CELoss: 2.1661, DKDLoss: 2.0673, 
2022-07-28 12:03:18 - train: epoch 0008, iter [01100, 05004], lr: 0.100000, loss: 3.8797, stu_CELoss: 2.0014, DKDLoss: 1.8783, 
2022-07-28 12:03:52 - train: epoch 0008, iter [01200, 05004], lr: 0.100000, loss: 3.9554, stu_CELoss: 1.8821, DKDLoss: 2.0732, 
2022-07-28 12:04:27 - train: epoch 0008, iter [01300, 05004], lr: 0.100000, loss: 4.6409, stu_CELoss: 2.2292, DKDLoss: 2.4117, 
2022-07-28 12:05:01 - train: epoch 0008, iter [01400, 05004], lr: 0.100000, loss: 4.1070, stu_CELoss: 2.0695, DKDLoss: 2.0375, 
2022-07-28 12:05:36 - train: epoch 0008, iter [01500, 05004], lr: 0.100000, loss: 4.2142, stu_CELoss: 2.1327, DKDLoss: 2.0815, 
2022-07-28 12:06:10 - train: epoch 0008, iter [01600, 05004], lr: 0.100000, loss: 4.2698, stu_CELoss: 2.1696, DKDLoss: 2.1002, 
2022-07-28 12:06:45 - train: epoch 0008, iter [01700, 05004], lr: 0.100000, loss: 4.2349, stu_CELoss: 2.1742, DKDLoss: 2.0607, 
2022-07-28 12:07:19 - train: epoch 0008, iter [01800, 05004], lr: 0.100000, loss: 4.5254, stu_CELoss: 2.2650, DKDLoss: 2.2604, 
2022-07-28 12:07:54 - train: epoch 0008, iter [01900, 05004], lr: 0.100000, loss: 3.9538, stu_CELoss: 1.9511, DKDLoss: 2.0027, 
2022-07-28 12:08:28 - train: epoch 0008, iter [02000, 05004], lr: 0.100000, loss: 4.5616, stu_CELoss: 2.4783, DKDLoss: 2.0833, 
2022-07-28 12:09:02 - train: epoch 0008, iter [02100, 05004], lr: 0.100000, loss: 4.4024, stu_CELoss: 2.1735, DKDLoss: 2.2289, 
2022-07-28 12:09:37 - train: epoch 0008, iter [02200, 05004], lr: 0.100000, loss: 4.4044, stu_CELoss: 2.3038, DKDLoss: 2.1005, 
2022-07-28 12:10:11 - train: epoch 0008, iter [02300, 05004], lr: 0.100000, loss: 3.9884, stu_CELoss: 2.0492, DKDLoss: 1.9392, 
2022-07-28 12:10:46 - train: epoch 0008, iter [02400, 05004], lr: 0.100000, loss: 3.8416, stu_CELoss: 1.9581, DKDLoss: 1.8835, 
2022-07-28 12:11:20 - train: epoch 0008, iter [02500, 05004], lr: 0.100000, loss: 4.3283, stu_CELoss: 2.1907, DKDLoss: 2.1375, 
2022-07-28 12:11:55 - train: epoch 0008, iter [02600, 05004], lr: 0.100000, loss: 4.2897, stu_CELoss: 2.0635, DKDLoss: 2.2262, 
2022-07-28 12:12:29 - train: epoch 0008, iter [02700, 05004], lr: 0.100000, loss: 4.3950, stu_CELoss: 2.2527, DKDLoss: 2.1423, 
2022-07-28 12:13:03 - train: epoch 0008, iter [02800, 05004], lr: 0.100000, loss: 4.1836, stu_CELoss: 2.1693, DKDLoss: 2.0143, 
2022-07-28 12:13:37 - train: epoch 0008, iter [02900, 05004], lr: 0.100000, loss: 4.5019, stu_CELoss: 2.3537, DKDLoss: 2.1482, 
2022-07-28 12:14:11 - train: epoch 0008, iter [03000, 05004], lr: 0.100000, loss: 4.3278, stu_CELoss: 2.2089, DKDLoss: 2.1189, 
2022-07-28 12:14:45 - train: epoch 0008, iter [03100, 05004], lr: 0.100000, loss: 4.2470, stu_CELoss: 2.1447, DKDLoss: 2.1023, 
2022-07-28 12:15:20 - train: epoch 0008, iter [03200, 05004], lr: 0.100000, loss: 4.3607, stu_CELoss: 2.2397, DKDLoss: 2.1211, 
2022-07-28 12:15:54 - train: epoch 0008, iter [03300, 05004], lr: 0.100000, loss: 4.4206, stu_CELoss: 2.1925, DKDLoss: 2.2281, 
2022-07-28 12:16:28 - train: epoch 0008, iter [03400, 05004], lr: 0.100000, loss: 4.3272, stu_CELoss: 2.2693, DKDLoss: 2.0579, 
2022-07-28 12:17:03 - train: epoch 0008, iter [03500, 05004], lr: 0.100000, loss: 4.1011, stu_CELoss: 2.0321, DKDLoss: 2.0690, 
2022-07-28 12:17:37 - train: epoch 0008, iter [03600, 05004], lr: 0.100000, loss: 4.2941, stu_CELoss: 2.1920, DKDLoss: 2.1021, 
2022-07-28 12:18:11 - train: epoch 0008, iter [03700, 05004], lr: 0.100000, loss: 3.9744, stu_CELoss: 1.9892, DKDLoss: 1.9852, 
2022-07-28 12:18:46 - train: epoch 0008, iter [03800, 05004], lr: 0.100000, loss: 4.3738, stu_CELoss: 2.0834, DKDLoss: 2.2904, 
2022-07-28 12:19:20 - train: epoch 0008, iter [03900, 05004], lr: 0.100000, loss: 4.2262, stu_CELoss: 2.1580, DKDLoss: 2.0681, 
2022-07-28 12:19:54 - train: epoch 0008, iter [04000, 05004], lr: 0.100000, loss: 4.6595, stu_CELoss: 2.3834, DKDLoss: 2.2761, 
2022-07-28 12:20:29 - train: epoch 0008, iter [04100, 05004], lr: 0.100000, loss: 4.0666, stu_CELoss: 2.0355, DKDLoss: 2.0311, 
2022-07-28 12:21:04 - train: epoch 0008, iter [04200, 05004], lr: 0.100000, loss: 4.0801, stu_CELoss: 2.0277, DKDLoss: 2.0524, 
2022-07-28 12:21:38 - train: epoch 0008, iter [04300, 05004], lr: 0.100000, loss: 3.8508, stu_CELoss: 1.9026, DKDLoss: 1.9482, 
2022-07-28 12:22:13 - train: epoch 0008, iter [04400, 05004], lr: 0.100000, loss: 4.0412, stu_CELoss: 2.0748, DKDLoss: 1.9664, 
2022-07-28 12:22:47 - train: epoch 0008, iter [04500, 05004], lr: 0.100000, loss: 4.1771, stu_CELoss: 2.1075, DKDLoss: 2.0697, 
2022-07-28 12:23:22 - train: epoch 0008, iter [04600, 05004], lr: 0.100000, loss: 4.2357, stu_CELoss: 2.1313, DKDLoss: 2.1044, 
2022-07-28 12:23:57 - train: epoch 0008, iter [04700, 05004], lr: 0.100000, loss: 4.0491, stu_CELoss: 2.0837, DKDLoss: 1.9654, 
2022-07-28 12:24:31 - train: epoch 0008, iter [04800, 05004], lr: 0.100000, loss: 4.4139, stu_CELoss: 2.2310, DKDLoss: 2.1830, 
2022-07-28 12:25:06 - train: epoch 0008, iter [04900, 05004], lr: 0.100000, loss: 3.9966, stu_CELoss: 2.0587, DKDLoss: 1.9379, 
2022-07-28 12:25:40 - train: epoch 0008, iter [05000, 05004], lr: 0.100000, loss: 4.2803, stu_CELoss: 2.2120, DKDLoss: 2.0683, 
2022-07-28 12:25:42 - train: epoch 008, train_loss: 4.1988
2022-07-28 12:28:17 - eval: epoch: 008, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 53.806%, stu_acc5: 78.866%, stu_test_loss: 1.9600
2022-07-28 12:28:18 - until epoch: 008, tea_best_acc1: 78.068%, stu_best_acc1: 53.806%
2022-07-28 12:28:18 - epoch 009 lr: 0.100000
2022-07-28 12:28:58 - train: epoch 0009, iter [00100, 05004], lr: 0.100000, loss: 3.5511, stu_CELoss: 1.7366, DKDLoss: 1.8144, 
2022-07-28 12:29:33 - train: epoch 0009, iter [00200, 05004], lr: 0.100000, loss: 3.9640, stu_CELoss: 2.0412, DKDLoss: 1.9228, 
2022-07-28 12:30:06 - train: epoch 0009, iter [00300, 05004], lr: 0.100000, loss: 3.9729, stu_CELoss: 2.0239, DKDLoss: 1.9490, 
2022-07-28 12:30:40 - train: epoch 0009, iter [00400, 05004], lr: 0.100000, loss: 4.2851, stu_CELoss: 2.1123, DKDLoss: 2.1728, 
2022-07-28 12:31:14 - train: epoch 0009, iter [00500, 05004], lr: 0.100000, loss: 3.9013, stu_CELoss: 1.9489, DKDLoss: 1.9524, 
2022-07-28 12:31:47 - train: epoch 0009, iter [00600, 05004], lr: 0.100000, loss: 3.8625, stu_CELoss: 1.9797, DKDLoss: 1.8827, 
2022-07-28 12:32:22 - train: epoch 0009, iter [00700, 05004], lr: 0.100000, loss: 3.7306, stu_CELoss: 1.8265, DKDLoss: 1.9040, 
2022-07-28 12:32:55 - train: epoch 0009, iter [00800, 05004], lr: 0.100000, loss: 3.8768, stu_CELoss: 1.9792, DKDLoss: 1.8976, 
2022-07-28 12:33:29 - train: epoch 0009, iter [00900, 05004], lr: 0.100000, loss: 3.7904, stu_CELoss: 1.8772, DKDLoss: 1.9133, 
2022-07-28 12:34:03 - train: epoch 0009, iter [01000, 05004], lr: 0.100000, loss: 3.9539, stu_CELoss: 2.0333, DKDLoss: 1.9206, 
2022-07-28 12:34:37 - train: epoch 0009, iter [01100, 05004], lr: 0.100000, loss: 4.3771, stu_CELoss: 2.2914, DKDLoss: 2.0857, 
2022-07-28 12:35:10 - train: epoch 0009, iter [01200, 05004], lr: 0.100000, loss: 4.0757, stu_CELoss: 2.0562, DKDLoss: 2.0194, 
2022-07-28 12:35:44 - train: epoch 0009, iter [01300, 05004], lr: 0.100000, loss: 4.1708, stu_CELoss: 2.1917, DKDLoss: 1.9791, 
2022-07-28 12:36:18 - train: epoch 0009, iter [01400, 05004], lr: 0.100000, loss: 3.6318, stu_CELoss: 1.7611, DKDLoss: 1.8707, 
2022-07-28 12:36:53 - train: epoch 0009, iter [01500, 05004], lr: 0.100000, loss: 3.8564, stu_CELoss: 1.9352, DKDLoss: 1.9212, 
2022-07-28 12:37:27 - train: epoch 0009, iter [01600, 05004], lr: 0.100000, loss: 4.0589, stu_CELoss: 2.0367, DKDLoss: 2.0221, 
2022-07-28 12:38:00 - train: epoch 0009, iter [01700, 05004], lr: 0.100000, loss: 4.3914, stu_CELoss: 2.2592, DKDLoss: 2.1322, 
2022-07-28 12:38:35 - train: epoch 0009, iter [01800, 05004], lr: 0.100000, loss: 4.1272, stu_CELoss: 2.1006, DKDLoss: 2.0266, 
2022-07-28 12:39:09 - train: epoch 0009, iter [01900, 05004], lr: 0.100000, loss: 3.6627, stu_CELoss: 1.8162, DKDLoss: 1.8465, 
2022-07-28 12:39:43 - train: epoch 0009, iter [02000, 05004], lr: 0.100000, loss: 4.2031, stu_CELoss: 2.0616, DKDLoss: 2.1415, 
2022-07-28 12:40:17 - train: epoch 0009, iter [02100, 05004], lr: 0.100000, loss: 4.0002, stu_CELoss: 2.0295, DKDLoss: 1.9707, 
2022-07-28 12:40:51 - train: epoch 0009, iter [02200, 05004], lr: 0.100000, loss: 4.1886, stu_CELoss: 2.1672, DKDLoss: 2.0214, 
2022-07-28 12:41:25 - train: epoch 0009, iter [02300, 05004], lr: 0.100000, loss: 3.4784, stu_CELoss: 1.7466, DKDLoss: 1.7318, 
2022-07-28 12:41:59 - train: epoch 0009, iter [02400, 05004], lr: 0.100000, loss: 3.8874, stu_CELoss: 1.9621, DKDLoss: 1.9253, 
2022-07-28 12:42:33 - train: epoch 0009, iter [02500, 05004], lr: 0.100000, loss: 3.8899, stu_CELoss: 1.9688, DKDLoss: 1.9211, 
2022-07-28 12:43:07 - train: epoch 0009, iter [02600, 05004], lr: 0.100000, loss: 3.8562, stu_CELoss: 1.9514, DKDLoss: 1.9048, 
2022-07-28 12:43:41 - train: epoch 0009, iter [02700, 05004], lr: 0.100000, loss: 4.3017, stu_CELoss: 2.2555, DKDLoss: 2.0462, 
2022-07-28 12:44:15 - train: epoch 0009, iter [02800, 05004], lr: 0.100000, loss: 3.8681, stu_CELoss: 2.0897, DKDLoss: 1.7784, 
2022-07-28 12:44:49 - train: epoch 0009, iter [02900, 05004], lr: 0.100000, loss: 3.6203, stu_CELoss: 1.8497, DKDLoss: 1.7706, 
2022-07-28 12:45:23 - train: epoch 0009, iter [03000, 05004], lr: 0.100000, loss: 3.8004, stu_CELoss: 1.8534, DKDLoss: 1.9470, 
2022-07-28 12:45:56 - train: epoch 0009, iter [03100, 05004], lr: 0.100000, loss: 4.1016, stu_CELoss: 2.0862, DKDLoss: 2.0154, 
2022-07-28 12:46:30 - train: epoch 0009, iter [03200, 05004], lr: 0.100000, loss: 4.2302, stu_CELoss: 2.1653, DKDLoss: 2.0649, 
2022-07-28 12:47:04 - train: epoch 0009, iter [03300, 05004], lr: 0.100000, loss: 4.3321, stu_CELoss: 2.2576, DKDLoss: 2.0745, 
2022-07-28 12:47:38 - train: epoch 0009, iter [03400, 05004], lr: 0.100000, loss: 4.1060, stu_CELoss: 2.0590, DKDLoss: 2.0470, 
2022-07-28 12:48:13 - train: epoch 0009, iter [03500, 05004], lr: 0.100000, loss: 4.2477, stu_CELoss: 2.1803, DKDLoss: 2.0674, 
2022-07-28 12:48:47 - train: epoch 0009, iter [03600, 05004], lr: 0.100000, loss: 3.7609, stu_CELoss: 1.9382, DKDLoss: 1.8227, 
2022-07-28 12:49:21 - train: epoch 0009, iter [03700, 05004], lr: 0.100000, loss: 4.3374, stu_CELoss: 2.1514, DKDLoss: 2.1859, 
2022-07-28 12:49:55 - train: epoch 0009, iter [03800, 05004], lr: 0.100000, loss: 4.1274, stu_CELoss: 2.0838, DKDLoss: 2.0436, 
2022-07-28 12:50:30 - train: epoch 0009, iter [03900, 05004], lr: 0.100000, loss: 3.7791, stu_CELoss: 1.9338, DKDLoss: 1.8453, 
2022-07-28 12:51:04 - train: epoch 0009, iter [04000, 05004], lr: 0.100000, loss: 4.1422, stu_CELoss: 2.2867, DKDLoss: 1.8555, 
2022-07-28 12:51:38 - train: epoch 0009, iter [04100, 05004], lr: 0.100000, loss: 4.1816, stu_CELoss: 2.1255, DKDLoss: 2.0560, 
2022-07-28 12:52:12 - train: epoch 0009, iter [04200, 05004], lr: 0.100000, loss: 3.8892, stu_CELoss: 2.0473, DKDLoss: 1.8419, 
2022-07-28 12:52:46 - train: epoch 0009, iter [04300, 05004], lr: 0.100000, loss: 3.7592, stu_CELoss: 1.8947, DKDLoss: 1.8646, 
2022-07-28 12:53:20 - train: epoch 0009, iter [04400, 05004], lr: 0.100000, loss: 4.1225, stu_CELoss: 2.0484, DKDLoss: 2.0740, 
2022-07-28 12:53:54 - train: epoch 0009, iter [04500, 05004], lr: 0.100000, loss: 4.2944, stu_CELoss: 2.1880, DKDLoss: 2.1063, 
2022-07-28 12:54:28 - train: epoch 0009, iter [04600, 05004], lr: 0.100000, loss: 4.4530, stu_CELoss: 2.2898, DKDLoss: 2.1632, 
2022-07-28 12:55:02 - train: epoch 0009, iter [04700, 05004], lr: 0.100000, loss: 4.3732, stu_CELoss: 2.3488, DKDLoss: 2.0244, 
2022-07-28 12:55:36 - train: epoch 0009, iter [04800, 05004], lr: 0.100000, loss: 4.0897, stu_CELoss: 2.1261, DKDLoss: 1.9637, 
2022-07-28 12:56:10 - train: epoch 0009, iter [04900, 05004], lr: 0.100000, loss: 3.9207, stu_CELoss: 2.0182, DKDLoss: 1.9025, 
2022-07-28 12:56:44 - train: epoch 0009, iter [05000, 05004], lr: 0.100000, loss: 4.0971, stu_CELoss: 1.9708, DKDLoss: 2.1263, 
2022-07-28 12:56:45 - train: epoch 009, train_loss: 4.0813
2022-07-28 12:59:20 - eval: epoch: 009, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 53.582%, stu_acc5: 78.340%, stu_test_loss: 1.9943
2022-07-28 12:59:20 - until epoch: 009, tea_best_acc1: 78.068%, stu_best_acc1: 53.806%
2022-07-28 12:59:20 - epoch 010 lr: 0.100000
2022-07-28 13:00:01 - train: epoch 0010, iter [00100, 05004], lr: 0.100000, loss: 3.8923, stu_CELoss: 1.8903, DKDLoss: 2.0020, 
2022-07-28 13:00:35 - train: epoch 0010, iter [00200, 05004], lr: 0.100000, loss: 3.9735, stu_CELoss: 2.0295, DKDLoss: 1.9440, 
2022-07-28 13:01:09 - train: epoch 0010, iter [00300, 05004], lr: 0.100000, loss: 3.7403, stu_CELoss: 1.9474, DKDLoss: 1.7929, 
2022-07-28 13:01:43 - train: epoch 0010, iter [00400, 05004], lr: 0.100000, loss: 4.1316, stu_CELoss: 2.1176, DKDLoss: 2.0140, 
2022-07-28 13:02:17 - train: epoch 0010, iter [00500, 05004], lr: 0.100000, loss: 3.9493, stu_CELoss: 2.0552, DKDLoss: 1.8941, 
2022-07-28 13:02:50 - train: epoch 0010, iter [00600, 05004], lr: 0.100000, loss: 4.1762, stu_CELoss: 2.2204, DKDLoss: 1.9557, 
2022-07-28 13:03:24 - train: epoch 0010, iter [00700, 05004], lr: 0.100000, loss: 4.1161, stu_CELoss: 2.1902, DKDLoss: 1.9259, 
2022-07-28 13:03:58 - train: epoch 0010, iter [00800, 05004], lr: 0.100000, loss: 4.1916, stu_CELoss: 2.2004, DKDLoss: 1.9912, 
2022-07-28 13:04:30 - train: epoch 0010, iter [00900, 05004], lr: 0.100000, loss: 3.3675, stu_CELoss: 1.6875, DKDLoss: 1.6800, 
2022-07-28 13:05:04 - train: epoch 0010, iter [01000, 05004], lr: 0.100000, loss: 3.4135, stu_CELoss: 1.6931, DKDLoss: 1.7204, 
2022-07-28 13:05:37 - train: epoch 0010, iter [01100, 05004], lr: 0.100000, loss: 3.7497, stu_CELoss: 1.8453, DKDLoss: 1.9044, 
2022-07-28 13:06:11 - train: epoch 0010, iter [01200, 05004], lr: 0.100000, loss: 4.1120, stu_CELoss: 2.1431, DKDLoss: 1.9689, 
2022-07-28 13:06:45 - train: epoch 0010, iter [01300, 05004], lr: 0.100000, loss: 3.6788, stu_CELoss: 1.8736, DKDLoss: 1.8053, 
2022-07-28 13:07:19 - train: epoch 0010, iter [01400, 05004], lr: 0.100000, loss: 4.1984, stu_CELoss: 2.2068, DKDLoss: 1.9915, 
2022-07-28 13:07:52 - train: epoch 0010, iter [01500, 05004], lr: 0.100000, loss: 3.8322, stu_CELoss: 1.8716, DKDLoss: 1.9606, 
2022-07-28 13:08:26 - train: epoch 0010, iter [01600, 05004], lr: 0.100000, loss: 4.0415, stu_CELoss: 2.0396, DKDLoss: 2.0019, 
2022-07-28 13:09:00 - train: epoch 0010, iter [01700, 05004], lr: 0.100000, loss: 4.2981, stu_CELoss: 2.1643, DKDLoss: 2.1338, 
2022-07-28 13:09:34 - train: epoch 0010, iter [01800, 05004], lr: 0.100000, loss: 3.8786, stu_CELoss: 1.9692, DKDLoss: 1.9094, 
2022-07-28 13:10:08 - train: epoch 0010, iter [01900, 05004], lr: 0.100000, loss: 3.7853, stu_CELoss: 1.9589, DKDLoss: 1.8264, 
2022-07-28 13:10:41 - train: epoch 0010, iter [02000, 05004], lr: 0.100000, loss: 3.9700, stu_CELoss: 1.9928, DKDLoss: 1.9773, 
2022-07-28 13:11:15 - train: epoch 0010, iter [02100, 05004], lr: 0.100000, loss: 3.9179, stu_CELoss: 1.9489, DKDLoss: 1.9691, 
2022-07-28 13:11:48 - train: epoch 0010, iter [02200, 05004], lr: 0.100000, loss: 4.1668, stu_CELoss: 2.1256, DKDLoss: 2.0412, 
2022-07-28 13:12:22 - train: epoch 0010, iter [02300, 05004], lr: 0.100000, loss: 4.2049, stu_CELoss: 2.2296, DKDLoss: 1.9752, 
2022-07-28 13:12:55 - train: epoch 0010, iter [02400, 05004], lr: 0.100000, loss: 4.4542, stu_CELoss: 2.3364, DKDLoss: 2.1179, 
2022-07-28 13:13:28 - train: epoch 0010, iter [02500, 05004], lr: 0.100000, loss: 3.9945, stu_CELoss: 2.1215, DKDLoss: 1.8730, 
2022-07-28 13:14:02 - train: epoch 0010, iter [02600, 05004], lr: 0.100000, loss: 3.8724, stu_CELoss: 1.9818, DKDLoss: 1.8906, 
2022-07-28 13:14:35 - train: epoch 0010, iter [02700, 05004], lr: 0.100000, loss: 3.8430, stu_CELoss: 1.9796, DKDLoss: 1.8634, 
2022-07-28 13:15:09 - train: epoch 0010, iter [02800, 05004], lr: 0.100000, loss: 4.3617, stu_CELoss: 2.1456, DKDLoss: 2.2161, 
2022-07-28 13:15:42 - train: epoch 0010, iter [02900, 05004], lr: 0.100000, loss: 3.9691, stu_CELoss: 2.0781, DKDLoss: 1.8910, 
2022-07-28 13:16:16 - train: epoch 0010, iter [03000, 05004], lr: 0.100000, loss: 3.9051, stu_CELoss: 1.9401, DKDLoss: 1.9650, 
2022-07-28 13:16:49 - train: epoch 0010, iter [03100, 05004], lr: 0.100000, loss: 4.3258, stu_CELoss: 2.2136, DKDLoss: 2.1122, 
2022-07-28 13:17:23 - train: epoch 0010, iter [03200, 05004], lr: 0.100000, loss: 3.9334, stu_CELoss: 2.0501, DKDLoss: 1.8833, 
2022-07-28 13:17:57 - train: epoch 0010, iter [03300, 05004], lr: 0.100000, loss: 4.2490, stu_CELoss: 2.1566, DKDLoss: 2.0924, 
2022-07-28 13:18:30 - train: epoch 0010, iter [03400, 05004], lr: 0.100000, loss: 4.0439, stu_CELoss: 2.0762, DKDLoss: 1.9677, 
2022-07-28 13:19:04 - train: epoch 0010, iter [03500, 05004], lr: 0.100000, loss: 4.1089, stu_CELoss: 2.1621, DKDLoss: 1.9468, 
2022-07-28 13:19:37 - train: epoch 0010, iter [03600, 05004], lr: 0.100000, loss: 4.0963, stu_CELoss: 2.0956, DKDLoss: 2.0008, 
2022-07-28 13:20:10 - train: epoch 0010, iter [03700, 05004], lr: 0.100000, loss: 4.2060, stu_CELoss: 2.2375, DKDLoss: 1.9685, 
2022-07-28 13:20:44 - train: epoch 0010, iter [03800, 05004], lr: 0.100000, loss: 4.3291, stu_CELoss: 2.1458, DKDLoss: 2.1832, 
2022-07-28 13:21:17 - train: epoch 0010, iter [03900, 05004], lr: 0.100000, loss: 3.9228, stu_CELoss: 1.9380, DKDLoss: 1.9848, 
2022-07-28 13:21:50 - train: epoch 0010, iter [04000, 05004], lr: 0.100000, loss: 3.9923, stu_CELoss: 1.9541, DKDLoss: 2.0381, 
2022-07-28 13:22:23 - train: epoch 0010, iter [04100, 05004], lr: 0.100000, loss: 3.6482, stu_CELoss: 1.8449, DKDLoss: 1.8033, 
2022-07-28 13:22:56 - train: epoch 0010, iter [04200, 05004], lr: 0.100000, loss: 3.9891, stu_CELoss: 2.0720, DKDLoss: 1.9171, 
2022-07-28 13:23:29 - train: epoch 0010, iter [04300, 05004], lr: 0.100000, loss: 3.9569, stu_CELoss: 1.9297, DKDLoss: 2.0272, 
2022-07-28 13:24:03 - train: epoch 0010, iter [04400, 05004], lr: 0.100000, loss: 3.7480, stu_CELoss: 1.9581, DKDLoss: 1.7898, 
2022-07-28 13:24:37 - train: epoch 0010, iter [04500, 05004], lr: 0.100000, loss: 3.8879, stu_CELoss: 2.1032, DKDLoss: 1.7846, 
2022-07-28 13:25:11 - train: epoch 0010, iter [04600, 05004], lr: 0.100000, loss: 3.9416, stu_CELoss: 1.9106, DKDLoss: 2.0310, 
2022-07-28 13:25:44 - train: epoch 0010, iter [04700, 05004], lr: 0.100000, loss: 3.9746, stu_CELoss: 2.0724, DKDLoss: 1.9022, 
2022-07-28 13:26:18 - train: epoch 0010, iter [04800, 05004], lr: 0.100000, loss: 4.1547, stu_CELoss: 2.0714, DKDLoss: 2.0832, 
2022-07-28 13:26:52 - train: epoch 0010, iter [04900, 05004], lr: 0.100000, loss: 3.8884, stu_CELoss: 2.0323, DKDLoss: 1.8561, 
2022-07-28 13:27:25 - train: epoch 0010, iter [05000, 05004], lr: 0.100000, loss: 3.9512, stu_CELoss: 1.9202, DKDLoss: 2.0310, 
2022-07-28 13:27:26 - train: epoch 010, train_loss: 3.9861
2022-07-28 13:29:58 - eval: epoch: 010, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 55.472%, stu_acc5: 80.270%, stu_test_loss: 1.8705
2022-07-28 13:29:59 - until epoch: 010, tea_best_acc1: 78.068%, stu_best_acc1: 55.472%
2022-07-28 13:29:59 - epoch 011 lr: 0.100000
2022-07-28 13:30:39 - train: epoch 0011, iter [00100, 05004], lr: 0.100000, loss: 3.7335, stu_CELoss: 1.9658, DKDLoss: 1.7677, 
2022-07-28 13:31:12 - train: epoch 0011, iter [00200, 05004], lr: 0.100000, loss: 4.2492, stu_CELoss: 2.2974, DKDLoss: 1.9518, 
2022-07-28 13:31:45 - train: epoch 0011, iter [00300, 05004], lr: 0.100000, loss: 3.7179, stu_CELoss: 2.0106, DKDLoss: 1.7073, 
2022-07-28 13:32:19 - train: epoch 0011, iter [00400, 05004], lr: 0.100000, loss: 4.1779, stu_CELoss: 2.2109, DKDLoss: 1.9670, 
2022-07-28 13:32:52 - train: epoch 0011, iter [00500, 05004], lr: 0.100000, loss: 3.8375, stu_CELoss: 1.9521, DKDLoss: 1.8854, 
2022-07-28 13:33:25 - train: epoch 0011, iter [00600, 05004], lr: 0.100000, loss: 4.0946, stu_CELoss: 2.1791, DKDLoss: 1.9155, 
2022-07-28 13:33:58 - train: epoch 0011, iter [00700, 05004], lr: 0.100000, loss: 4.1528, stu_CELoss: 2.0720, DKDLoss: 2.0807, 
2022-07-28 13:34:32 - train: epoch 0011, iter [00800, 05004], lr: 0.100000, loss: 4.3485, stu_CELoss: 2.2135, DKDLoss: 2.1349, 
2022-07-28 13:35:05 - train: epoch 0011, iter [00900, 05004], lr: 0.100000, loss: 4.0758, stu_CELoss: 2.2127, DKDLoss: 1.8631, 
2022-07-28 13:35:38 - train: epoch 0011, iter [01000, 05004], lr: 0.100000, loss: 3.7369, stu_CELoss: 1.8969, DKDLoss: 1.8401, 
2022-07-28 13:36:12 - train: epoch 0011, iter [01100, 05004], lr: 0.100000, loss: 3.7758, stu_CELoss: 1.9485, DKDLoss: 1.8273, 
2022-07-28 13:36:45 - train: epoch 0011, iter [01200, 05004], lr: 0.100000, loss: 4.3015, stu_CELoss: 2.1730, DKDLoss: 2.1285, 
2022-07-28 13:37:19 - train: epoch 0011, iter [01300, 05004], lr: 0.100000, loss: 4.1249, stu_CELoss: 2.0998, DKDLoss: 2.0251, 
2022-07-28 13:37:53 - train: epoch 0011, iter [01400, 05004], lr: 0.100000, loss: 4.1907, stu_CELoss: 2.2321, DKDLoss: 1.9586, 
2022-07-28 13:38:26 - train: epoch 0011, iter [01500, 05004], lr: 0.100000, loss: 3.7685, stu_CELoss: 1.9426, DKDLoss: 1.8259, 
2022-07-28 13:39:00 - train: epoch 0011, iter [01600, 05004], lr: 0.100000, loss: 3.9377, stu_CELoss: 2.0850, DKDLoss: 1.8527, 
2022-07-28 13:39:34 - train: epoch 0011, iter [01700, 05004], lr: 0.100000, loss: 4.0389, stu_CELoss: 2.1446, DKDLoss: 1.8943, 
2022-07-28 13:40:07 - train: epoch 0011, iter [01800, 05004], lr: 0.100000, loss: 3.9027, stu_CELoss: 2.0884, DKDLoss: 1.8142, 
2022-07-28 13:40:40 - train: epoch 0011, iter [01900, 05004], lr: 0.100000, loss: 4.0033, stu_CELoss: 1.9764, DKDLoss: 2.0269, 
2022-07-28 13:41:14 - train: epoch 0011, iter [02000, 05004], lr: 0.100000, loss: 3.8644, stu_CELoss: 1.8910, DKDLoss: 1.9734, 
2022-07-28 13:41:47 - train: epoch 0011, iter [02100, 05004], lr: 0.100000, loss: 3.6191, stu_CELoss: 1.8370, DKDLoss: 1.7821, 
2022-07-28 13:42:21 - train: epoch 0011, iter [02200, 05004], lr: 0.100000, loss: 3.6021, stu_CELoss: 1.7893, DKDLoss: 1.8128, 
2022-07-28 13:42:55 - train: epoch 0011, iter [02300, 05004], lr: 0.100000, loss: 3.9270, stu_CELoss: 2.0090, DKDLoss: 1.9180, 
2022-07-28 13:43:28 - train: epoch 0011, iter [02400, 05004], lr: 0.100000, loss: 3.7283, stu_CELoss: 1.8805, DKDLoss: 1.8478, 
2022-07-28 13:44:02 - train: epoch 0011, iter [02500, 05004], lr: 0.100000, loss: 3.7077, stu_CELoss: 1.9978, DKDLoss: 1.7099, 
2022-07-28 13:44:36 - train: epoch 0011, iter [02600, 05004], lr: 0.100000, loss: 3.8361, stu_CELoss: 1.9208, DKDLoss: 1.9153, 
2022-07-28 13:45:10 - train: epoch 0011, iter [02700, 05004], lr: 0.100000, loss: 3.7266, stu_CELoss: 1.9587, DKDLoss: 1.7679, 
2022-07-28 13:45:43 - train: epoch 0011, iter [02800, 05004], lr: 0.100000, loss: 3.5837, stu_CELoss: 1.8179, DKDLoss: 1.7658, 
2022-07-28 13:46:17 - train: epoch 0011, iter [02900, 05004], lr: 0.100000, loss: 3.8617, stu_CELoss: 2.0658, DKDLoss: 1.7960, 
2022-07-28 13:46:51 - train: epoch 0011, iter [03000, 05004], lr: 0.100000, loss: 4.1696, stu_CELoss: 2.2636, DKDLoss: 1.9060, 
2022-07-28 13:47:25 - train: epoch 0011, iter [03100, 05004], lr: 0.100000, loss: 3.7496, stu_CELoss: 2.0017, DKDLoss: 1.7478, 
2022-07-28 13:47:58 - train: epoch 0011, iter [03200, 05004], lr: 0.100000, loss: 3.9482, stu_CELoss: 2.0236, DKDLoss: 1.9246, 
2022-07-28 13:48:32 - train: epoch 0011, iter [03300, 05004], lr: 0.100000, loss: 3.8322, stu_CELoss: 1.9212, DKDLoss: 1.9110, 
2022-07-28 13:49:05 - train: epoch 0011, iter [03400, 05004], lr: 0.100000, loss: 3.6947, stu_CELoss: 1.9895, DKDLoss: 1.7052, 
2022-07-28 13:49:39 - train: epoch 0011, iter [03500, 05004], lr: 0.100000, loss: 4.0236, stu_CELoss: 1.9378, DKDLoss: 2.0858, 
2022-07-28 13:50:12 - train: epoch 0011, iter [03600, 05004], lr: 0.100000, loss: 3.5118, stu_CELoss: 1.8040, DKDLoss: 1.7078, 
2022-07-28 13:50:46 - train: epoch 0011, iter [03700, 05004], lr: 0.100000, loss: 4.2492, stu_CELoss: 2.2506, DKDLoss: 1.9986, 
2022-07-28 13:51:19 - train: epoch 0011, iter [03800, 05004], lr: 0.100000, loss: 3.7997, stu_CELoss: 1.9542, DKDLoss: 1.8456, 
2022-07-28 13:51:53 - train: epoch 0011, iter [03900, 05004], lr: 0.100000, loss: 3.9260, stu_CELoss: 1.9821, DKDLoss: 1.9439, 
2022-07-28 13:52:26 - train: epoch 0011, iter [04000, 05004], lr: 0.100000, loss: 3.8293, stu_CELoss: 1.8496, DKDLoss: 1.9797, 
2022-07-28 13:53:00 - train: epoch 0011, iter [04100, 05004], lr: 0.100000, loss: 3.7695, stu_CELoss: 1.9325, DKDLoss: 1.8370, 
2022-07-28 13:53:34 - train: epoch 0011, iter [04200, 05004], lr: 0.100000, loss: 3.6856, stu_CELoss: 1.8632, DKDLoss: 1.8224, 
2022-07-28 13:54:07 - train: epoch 0011, iter [04300, 05004], lr: 0.100000, loss: 3.7385, stu_CELoss: 1.8671, DKDLoss: 1.8714, 
2022-07-28 13:54:41 - train: epoch 0011, iter [04400, 05004], lr: 0.100000, loss: 4.1827, stu_CELoss: 2.3066, DKDLoss: 1.8761, 
2022-07-28 13:55:14 - train: epoch 0011, iter [04500, 05004], lr: 0.100000, loss: 3.8414, stu_CELoss: 1.9367, DKDLoss: 1.9046, 
2022-07-28 13:55:48 - train: epoch 0011, iter [04600, 05004], lr: 0.100000, loss: 3.9384, stu_CELoss: 2.0319, DKDLoss: 1.9065, 
2022-07-28 13:56:22 - train: epoch 0011, iter [04700, 05004], lr: 0.100000, loss: 3.5625, stu_CELoss: 1.8429, DKDLoss: 1.7196, 
2022-07-28 13:56:55 - train: epoch 0011, iter [04800, 05004], lr: 0.100000, loss: 3.5429, stu_CELoss: 1.7586, DKDLoss: 1.7843, 
2022-07-28 13:57:29 - train: epoch 0011, iter [04900, 05004], lr: 0.100000, loss: 3.7095, stu_CELoss: 1.8767, DKDLoss: 1.8328, 
2022-07-28 13:58:02 - train: epoch 0011, iter [05000, 05004], lr: 0.100000, loss: 3.7743, stu_CELoss: 1.9999, DKDLoss: 1.7743, 
2022-07-28 13:58:03 - train: epoch 011, train_loss: 3.9092
2022-07-28 14:00:36 - eval: epoch: 011, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 55.246%, stu_acc5: 80.066%, stu_test_loss: 1.8987
2022-07-28 14:00:37 - until epoch: 011, tea_best_acc1: 78.068%, stu_best_acc1: 55.472%
2022-07-28 14:00:37 - epoch 012 lr: 0.100000
2022-07-28 14:01:17 - train: epoch 0012, iter [00100, 05004], lr: 0.100000, loss: 3.6609, stu_CELoss: 1.8756, DKDLoss: 1.7853, 
2022-07-28 14:01:51 - train: epoch 0012, iter [00200, 05004], lr: 0.100000, loss: 3.4232, stu_CELoss: 1.6364, DKDLoss: 1.7868, 
2022-07-28 14:02:24 - train: epoch 0012, iter [00300, 05004], lr: 0.100000, loss: 3.4670, stu_CELoss: 1.7734, DKDLoss: 1.6935, 
2022-07-28 14:02:58 - train: epoch 0012, iter [00400, 05004], lr: 0.100000, loss: 3.6855, stu_CELoss: 1.9269, DKDLoss: 1.7586, 
2022-07-28 14:03:32 - train: epoch 0012, iter [00500, 05004], lr: 0.100000, loss: 4.1218, stu_CELoss: 2.1093, DKDLoss: 2.0125, 
2022-07-28 14:04:05 - train: epoch 0012, iter [00600, 05004], lr: 0.100000, loss: 3.2435, stu_CELoss: 1.5762, DKDLoss: 1.6673, 
2022-07-28 14:04:39 - train: epoch 0012, iter [00700, 05004], lr: 0.100000, loss: 3.6145, stu_CELoss: 1.7619, DKDLoss: 1.8526, 
2022-07-28 14:05:12 - train: epoch 0012, iter [00800, 05004], lr: 0.100000, loss: 4.1947, stu_CELoss: 2.2906, DKDLoss: 1.9041, 
2022-07-28 14:05:46 - train: epoch 0012, iter [00900, 05004], lr: 0.100000, loss: 3.8346, stu_CELoss: 2.0088, DKDLoss: 1.8259, 
2022-07-28 14:06:19 - train: epoch 0012, iter [01000, 05004], lr: 0.100000, loss: 3.7069, stu_CELoss: 1.9196, DKDLoss: 1.7872, 
2022-07-28 14:06:53 - train: epoch 0012, iter [01100, 05004], lr: 0.100000, loss: 4.1448, stu_CELoss: 2.2460, DKDLoss: 1.8989, 
2022-07-28 14:07:27 - train: epoch 0012, iter [01200, 05004], lr: 0.100000, loss: 3.3560, stu_CELoss: 1.6439, DKDLoss: 1.7121, 
2022-07-28 14:08:00 - train: epoch 0012, iter [01300, 05004], lr: 0.100000, loss: 3.6226, stu_CELoss: 1.8755, DKDLoss: 1.7471, 
2022-07-28 14:08:34 - train: epoch 0012, iter [01400, 05004], lr: 0.100000, loss: 4.1942, stu_CELoss: 2.1670, DKDLoss: 2.0272, 
2022-07-28 14:09:07 - train: epoch 0012, iter [01500, 05004], lr: 0.100000, loss: 3.6118, stu_CELoss: 1.8374, DKDLoss: 1.7744, 
2022-07-28 14:09:41 - train: epoch 0012, iter [01600, 05004], lr: 0.100000, loss: 3.9389, stu_CELoss: 2.0093, DKDLoss: 1.9296, 
2022-07-28 14:10:14 - train: epoch 0012, iter [01700, 05004], lr: 0.100000, loss: 3.6104, stu_CELoss: 1.8475, DKDLoss: 1.7629, 
2022-07-28 14:10:48 - train: epoch 0012, iter [01800, 05004], lr: 0.100000, loss: 3.9820, stu_CELoss: 2.1306, DKDLoss: 1.8514, 
2022-07-28 14:11:21 - train: epoch 0012, iter [01900, 05004], lr: 0.100000, loss: 4.0162, stu_CELoss: 2.2019, DKDLoss: 1.8142, 
2022-07-28 14:11:54 - train: epoch 0012, iter [02000, 05004], lr: 0.100000, loss: 4.0384, stu_CELoss: 2.1050, DKDLoss: 1.9333, 
2022-07-28 14:12:28 - train: epoch 0012, iter [02100, 05004], lr: 0.100000, loss: 3.8917, stu_CELoss: 2.1398, DKDLoss: 1.7519, 
2022-07-28 14:13:01 - train: epoch 0012, iter [02200, 05004], lr: 0.100000, loss: 4.2628, stu_CELoss: 2.2709, DKDLoss: 1.9919, 
2022-07-28 14:13:35 - train: epoch 0012, iter [02300, 05004], lr: 0.100000, loss: 3.6344, stu_CELoss: 1.9037, DKDLoss: 1.7307, 
2022-07-28 14:14:08 - train: epoch 0012, iter [02400, 05004], lr: 0.100000, loss: 4.0832, stu_CELoss: 2.0317, DKDLoss: 2.0515, 
2022-07-28 14:14:42 - train: epoch 0012, iter [02500, 05004], lr: 0.100000, loss: 3.6330, stu_CELoss: 1.7871, DKDLoss: 1.8459, 
2022-07-28 14:15:16 - train: epoch 0012, iter [02600, 05004], lr: 0.100000, loss: 3.5151, stu_CELoss: 1.8125, DKDLoss: 1.7027, 
2022-07-28 14:15:50 - train: epoch 0012, iter [02700, 05004], lr: 0.100000, loss: 4.0091, stu_CELoss: 2.0772, DKDLoss: 1.9319, 
2022-07-28 14:16:23 - train: epoch 0012, iter [02800, 05004], lr: 0.100000, loss: 3.8310, stu_CELoss: 2.1029, DKDLoss: 1.7282, 
2022-07-28 14:16:57 - train: epoch 0012, iter [02900, 05004], lr: 0.100000, loss: 3.9504, stu_CELoss: 2.0691, DKDLoss: 1.8813, 
2022-07-28 14:17:30 - train: epoch 0012, iter [03000, 05004], lr: 0.100000, loss: 3.5452, stu_CELoss: 1.8433, DKDLoss: 1.7019, 
2022-07-28 14:18:04 - train: epoch 0012, iter [03100, 05004], lr: 0.100000, loss: 3.8202, stu_CELoss: 1.9771, DKDLoss: 1.8431, 
2022-07-28 14:18:38 - train: epoch 0012, iter [03200, 05004], lr: 0.100000, loss: 3.7990, stu_CELoss: 1.9157, DKDLoss: 1.8832, 
2022-07-28 14:19:11 - train: epoch 0012, iter [03300, 05004], lr: 0.100000, loss: 3.8815, stu_CELoss: 1.9609, DKDLoss: 1.9206, 
2022-07-28 14:19:46 - train: epoch 0012, iter [03400, 05004], lr: 0.100000, loss: 3.8361, stu_CELoss: 2.0347, DKDLoss: 1.8014, 
2022-07-28 14:20:19 - train: epoch 0012, iter [03500, 05004], lr: 0.100000, loss: 3.9374, stu_CELoss: 2.0002, DKDLoss: 1.9371, 
2022-07-28 14:20:53 - train: epoch 0012, iter [03600, 05004], lr: 0.100000, loss: 3.6651, stu_CELoss: 1.8008, DKDLoss: 1.8643, 
2022-07-28 14:21:27 - train: epoch 0012, iter [03700, 05004], lr: 0.100000, loss: 4.0689, stu_CELoss: 2.2136, DKDLoss: 1.8553, 
2022-07-28 14:22:01 - train: epoch 0012, iter [03800, 05004], lr: 0.100000, loss: 4.1268, stu_CELoss: 2.1664, DKDLoss: 1.9604, 
2022-07-28 14:22:35 - train: epoch 0012, iter [03900, 05004], lr: 0.100000, loss: 3.5385, stu_CELoss: 1.7199, DKDLoss: 1.8186, 
2022-07-28 14:23:09 - train: epoch 0012, iter [04000, 05004], lr: 0.100000, loss: 3.7505, stu_CELoss: 1.9838, DKDLoss: 1.7667, 
2022-07-28 14:23:43 - train: epoch 0012, iter [04100, 05004], lr: 0.100000, loss: 3.9860, stu_CELoss: 2.0527, DKDLoss: 1.9333, 
2022-07-28 14:24:17 - train: epoch 0012, iter [04200, 05004], lr: 0.100000, loss: 3.7413, stu_CELoss: 1.8508, DKDLoss: 1.8906, 
2022-07-28 14:24:51 - train: epoch 0012, iter [04300, 05004], lr: 0.100000, loss: 4.1505, stu_CELoss: 2.1589, DKDLoss: 1.9916, 
2022-07-28 14:25:25 - train: epoch 0012, iter [04400, 05004], lr: 0.100000, loss: 3.6793, stu_CELoss: 1.8826, DKDLoss: 1.7967, 
2022-07-28 14:25:59 - train: epoch 0012, iter [04500, 05004], lr: 0.100000, loss: 3.9194, stu_CELoss: 1.9173, DKDLoss: 2.0021, 
2022-07-28 14:26:33 - train: epoch 0012, iter [04600, 05004], lr: 0.100000, loss: 4.0062, stu_CELoss: 2.0539, DKDLoss: 1.9523, 
2022-07-28 14:27:06 - train: epoch 0012, iter [04700, 05004], lr: 0.100000, loss: 3.6556, stu_CELoss: 1.8644, DKDLoss: 1.7913, 
2022-07-28 14:27:40 - train: epoch 0012, iter [04800, 05004], lr: 0.100000, loss: 4.0520, stu_CELoss: 2.0055, DKDLoss: 2.0466, 
2022-07-28 14:28:13 - train: epoch 0012, iter [04900, 05004], lr: 0.100000, loss: 3.6124, stu_CELoss: 1.8558, DKDLoss: 1.7566, 
2022-07-28 14:28:47 - train: epoch 0012, iter [05000, 05004], lr: 0.100000, loss: 3.5597, stu_CELoss: 1.8455, DKDLoss: 1.7141, 
2022-07-28 14:28:48 - train: epoch 012, train_loss: 3.8392
2022-07-28 14:31:20 - eval: epoch: 012, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 55.006%, stu_acc5: 79.672%, stu_test_loss: 1.9249
2022-07-28 14:31:21 - until epoch: 012, tea_best_acc1: 78.068%, stu_best_acc1: 55.472%
2022-07-28 14:31:21 - epoch 013 lr: 0.100000
2022-07-28 14:32:01 - train: epoch 0013, iter [00100, 05004], lr: 0.100000, loss: 3.4915, stu_CELoss: 1.7813, DKDLoss: 1.7102, 
2022-07-28 14:32:36 - train: epoch 0013, iter [00200, 05004], lr: 0.100000, loss: 3.8297, stu_CELoss: 2.0211, DKDLoss: 1.8086, 
2022-07-28 14:33:10 - train: epoch 0013, iter [00300, 05004], lr: 0.100000, loss: 3.6855, stu_CELoss: 1.9390, DKDLoss: 1.7465, 
2022-07-28 14:33:43 - train: epoch 0013, iter [00400, 05004], lr: 0.100000, loss: 3.5500, stu_CELoss: 1.8013, DKDLoss: 1.7487, 
2022-07-28 14:34:17 - train: epoch 0013, iter [00500, 05004], lr: 0.100000, loss: 3.7720, stu_CELoss: 1.9577, DKDLoss: 1.8143, 
2022-07-28 14:34:50 - train: epoch 0013, iter [00600, 05004], lr: 0.100000, loss: 3.7453, stu_CELoss: 1.9875, DKDLoss: 1.7578, 
2022-07-28 14:35:23 - train: epoch 0013, iter [00700, 05004], lr: 0.100000, loss: 3.6950, stu_CELoss: 1.8390, DKDLoss: 1.8560, 
2022-07-28 14:35:57 - train: epoch 0013, iter [00800, 05004], lr: 0.100000, loss: 3.9509, stu_CELoss: 2.0365, DKDLoss: 1.9143, 
2022-07-28 14:36:31 - train: epoch 0013, iter [00900, 05004], lr: 0.100000, loss: 3.9104, stu_CELoss: 2.0866, DKDLoss: 1.8238, 
2022-07-28 14:37:04 - train: epoch 0013, iter [01000, 05004], lr: 0.100000, loss: 3.5828, stu_CELoss: 1.8133, DKDLoss: 1.7694, 
2022-07-28 14:37:38 - train: epoch 0013, iter [01100, 05004], lr: 0.100000, loss: 3.9390, stu_CELoss: 1.9810, DKDLoss: 1.9580, 
2022-07-28 14:38:12 - train: epoch 0013, iter [01200, 05004], lr: 0.100000, loss: 3.9888, stu_CELoss: 2.1321, DKDLoss: 1.8567, 
2022-07-28 14:38:46 - train: epoch 0013, iter [01300, 05004], lr: 0.100000, loss: 3.7223, stu_CELoss: 1.8832, DKDLoss: 1.8390, 
2022-07-28 14:39:19 - train: epoch 0013, iter [01400, 05004], lr: 0.100000, loss: 3.8815, stu_CELoss: 2.0040, DKDLoss: 1.8775, 
2022-07-28 14:39:53 - train: epoch 0013, iter [01500, 05004], lr: 0.100000, loss: 3.9639, stu_CELoss: 2.0924, DKDLoss: 1.8715, 
2022-07-28 14:40:26 - train: epoch 0013, iter [01600, 05004], lr: 0.100000, loss: 3.5573, stu_CELoss: 1.8439, DKDLoss: 1.7134, 
2022-07-28 14:41:00 - train: epoch 0013, iter [01700, 05004], lr: 0.100000, loss: 3.7370, stu_CELoss: 1.8964, DKDLoss: 1.8406, 
2022-07-28 14:41:34 - train: epoch 0013, iter [01800, 05004], lr: 0.100000, loss: 3.9520, stu_CELoss: 2.0493, DKDLoss: 1.9026, 
2022-07-28 14:42:08 - train: epoch 0013, iter [01900, 05004], lr: 0.100000, loss: 3.6921, stu_CELoss: 1.9867, DKDLoss: 1.7055, 
2022-07-28 14:42:42 - train: epoch 0013, iter [02000, 05004], lr: 0.100000, loss: 3.8765, stu_CELoss: 2.0173, DKDLoss: 1.8592, 
2022-07-28 14:43:15 - train: epoch 0013, iter [02100, 05004], lr: 0.100000, loss: 3.8817, stu_CELoss: 2.0631, DKDLoss: 1.8186, 
2022-07-28 14:43:49 - train: epoch 0013, iter [02200, 05004], lr: 0.100000, loss: 3.5367, stu_CELoss: 1.8087, DKDLoss: 1.7280, 
2022-07-28 14:44:23 - train: epoch 0013, iter [02300, 05004], lr: 0.100000, loss: 3.5965, stu_CELoss: 1.7800, DKDLoss: 1.8165, 
2022-07-28 14:44:57 - train: epoch 0013, iter [02400, 05004], lr: 0.100000, loss: 4.0229, stu_CELoss: 2.0741, DKDLoss: 1.9488, 
2022-07-28 14:45:30 - train: epoch 0013, iter [02500, 05004], lr: 0.100000, loss: 3.6728, stu_CELoss: 1.9050, DKDLoss: 1.7678, 
2022-07-28 14:46:04 - train: epoch 0013, iter [02600, 05004], lr: 0.100000, loss: 3.7187, stu_CELoss: 1.9973, DKDLoss: 1.7214, 
2022-07-28 14:46:37 - train: epoch 0013, iter [02700, 05004], lr: 0.100000, loss: 3.6564, stu_CELoss: 1.9542, DKDLoss: 1.7022, 
2022-07-28 14:47:11 - train: epoch 0013, iter [02800, 05004], lr: 0.100000, loss: 3.8160, stu_CELoss: 1.9022, DKDLoss: 1.9138, 
2022-07-28 14:47:44 - train: epoch 0013, iter [02900, 05004], lr: 0.100000, loss: 3.6805, stu_CELoss: 1.9651, DKDLoss: 1.7154, 
2022-07-28 14:48:17 - train: epoch 0013, iter [03000, 05004], lr: 0.100000, loss: 3.4242, stu_CELoss: 1.7107, DKDLoss: 1.7135, 
2022-07-28 14:48:51 - train: epoch 0013, iter [03100, 05004], lr: 0.100000, loss: 3.6734, stu_CELoss: 1.8830, DKDLoss: 1.7903, 
2022-07-28 14:49:24 - train: epoch 0013, iter [03200, 05004], lr: 0.100000, loss: 3.9347, stu_CELoss: 2.0991, DKDLoss: 1.8356, 
2022-07-28 14:49:58 - train: epoch 0013, iter [03300, 05004], lr: 0.100000, loss: 3.4919, stu_CELoss: 1.7292, DKDLoss: 1.7627, 
2022-07-28 14:50:31 - train: epoch 0013, iter [03400, 05004], lr: 0.100000, loss: 3.7793, stu_CELoss: 1.9135, DKDLoss: 1.8659, 
2022-07-28 14:51:04 - train: epoch 0013, iter [03500, 05004], lr: 0.100000, loss: 3.6985, stu_CELoss: 1.9124, DKDLoss: 1.7861, 
2022-07-28 14:51:38 - train: epoch 0013, iter [03600, 05004], lr: 0.100000, loss: 3.9174, stu_CELoss: 2.0038, DKDLoss: 1.9136, 
2022-07-28 14:52:11 - train: epoch 0013, iter [03700, 05004], lr: 0.100000, loss: 3.5011, stu_CELoss: 1.7271, DKDLoss: 1.7740, 
2022-07-28 14:52:44 - train: epoch 0013, iter [03800, 05004], lr: 0.100000, loss: 4.0000, stu_CELoss: 2.1656, DKDLoss: 1.8344, 
2022-07-28 14:53:18 - train: epoch 0013, iter [03900, 05004], lr: 0.100000, loss: 4.0409, stu_CELoss: 2.0984, DKDLoss: 1.9424, 
2022-07-28 14:53:51 - train: epoch 0013, iter [04000, 05004], lr: 0.100000, loss: 3.7758, stu_CELoss: 1.9308, DKDLoss: 1.8449, 
2022-07-28 14:54:25 - train: epoch 0013, iter [04100, 05004], lr: 0.100000, loss: 3.6202, stu_CELoss: 1.7939, DKDLoss: 1.8263, 
2022-07-28 14:54:59 - train: epoch 0013, iter [04200, 05004], lr: 0.100000, loss: 3.9780, stu_CELoss: 2.0348, DKDLoss: 1.9432, 
2022-07-28 14:55:32 - train: epoch 0013, iter [04300, 05004], lr: 0.100000, loss: 3.8347, stu_CELoss: 1.9033, DKDLoss: 1.9313, 
2022-07-28 14:56:06 - train: epoch 0013, iter [04400, 05004], lr: 0.100000, loss: 3.6413, stu_CELoss: 1.7775, DKDLoss: 1.8637, 
2022-07-28 14:56:39 - train: epoch 0013, iter [04500, 05004], lr: 0.100000, loss: 3.7043, stu_CELoss: 1.8301, DKDLoss: 1.8742, 
2022-07-28 14:57:13 - train: epoch 0013, iter [04600, 05004], lr: 0.100000, loss: 3.9798, stu_CELoss: 1.9072, DKDLoss: 2.0727, 
2022-07-28 14:57:46 - train: epoch 0013, iter [04700, 05004], lr: 0.100000, loss: 3.8456, stu_CELoss: 1.9905, DKDLoss: 1.8552, 
2022-07-28 14:58:20 - train: epoch 0013, iter [04800, 05004], lr: 0.100000, loss: 3.8727, stu_CELoss: 2.0489, DKDLoss: 1.8238, 
2022-07-28 14:58:53 - train: epoch 0013, iter [04900, 05004], lr: 0.100000, loss: 3.9830, stu_CELoss: 2.0507, DKDLoss: 1.9323, 
2022-07-28 14:59:26 - train: epoch 0013, iter [05000, 05004], lr: 0.100000, loss: 3.7952, stu_CELoss: 1.9677, DKDLoss: 1.8275, 
2022-07-28 14:59:28 - train: epoch 013, train_loss: 3.7869
2022-07-28 15:02:02 - eval: epoch: 013, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 57.692%, stu_acc5: 82.006%, stu_test_loss: 1.7655
2022-07-28 15:02:03 - until epoch: 013, tea_best_acc1: 78.068%, stu_best_acc1: 57.692%
2022-07-28 15:02:03 - epoch 014 lr: 0.100000
2022-07-28 15:02:44 - train: epoch 0014, iter [00100, 05004], lr: 0.100000, loss: 3.7641, stu_CELoss: 1.9454, DKDLoss: 1.8187, 
2022-07-28 15:03:17 - train: epoch 0014, iter [00200, 05004], lr: 0.100000, loss: 4.0078, stu_CELoss: 2.1350, DKDLoss: 1.8728, 
2022-07-28 15:03:51 - train: epoch 0014, iter [00300, 05004], lr: 0.100000, loss: 3.4204, stu_CELoss: 1.8143, DKDLoss: 1.6061, 
2022-07-28 15:04:24 - train: epoch 0014, iter [00400, 05004], lr: 0.100000, loss: 3.4437, stu_CELoss: 1.7887, DKDLoss: 1.6550, 
2022-07-28 15:04:58 - train: epoch 0014, iter [00500, 05004], lr: 0.100000, loss: 3.4271, stu_CELoss: 1.8495, DKDLoss: 1.5776, 
2022-07-28 15:05:31 - train: epoch 0014, iter [00600, 05004], lr: 0.100000, loss: 3.5817, stu_CELoss: 1.9662, DKDLoss: 1.6155, 
2022-07-28 15:06:05 - train: epoch 0014, iter [00700, 05004], lr: 0.100000, loss: 3.7153, stu_CELoss: 1.9234, DKDLoss: 1.7919, 
2022-07-28 15:06:38 - train: epoch 0014, iter [00800, 05004], lr: 0.100000, loss: 3.6295, stu_CELoss: 1.8549, DKDLoss: 1.7746, 
2022-07-28 15:07:12 - train: epoch 0014, iter [00900, 05004], lr: 0.100000, loss: 3.8301, stu_CELoss: 1.9603, DKDLoss: 1.8698, 
2022-07-28 15:07:46 - train: epoch 0014, iter [01000, 05004], lr: 0.100000, loss: 3.9483, stu_CELoss: 2.0349, DKDLoss: 1.9134, 
2022-07-28 15:08:19 - train: epoch 0014, iter [01100, 05004], lr: 0.100000, loss: 3.6865, stu_CELoss: 1.8751, DKDLoss: 1.8114, 
2022-07-28 15:08:52 - train: epoch 0014, iter [01200, 05004], lr: 0.100000, loss: 3.8752, stu_CELoss: 2.0077, DKDLoss: 1.8676, 
2022-07-28 15:09:26 - train: epoch 0014, iter [01300, 05004], lr: 0.100000, loss: 3.9860, stu_CELoss: 2.1003, DKDLoss: 1.8857, 
2022-07-28 15:10:00 - train: epoch 0014, iter [01400, 05004], lr: 0.100000, loss: 3.8730, stu_CELoss: 2.0575, DKDLoss: 1.8155, 
2022-07-28 15:10:34 - train: epoch 0014, iter [01500, 05004], lr: 0.100000, loss: 4.0932, stu_CELoss: 2.0936, DKDLoss: 1.9995, 
2022-07-28 15:11:07 - train: epoch 0014, iter [01600, 05004], lr: 0.100000, loss: 3.7332, stu_CELoss: 1.9213, DKDLoss: 1.8119, 
2022-07-28 15:11:40 - train: epoch 0014, iter [01700, 05004], lr: 0.100000, loss: 3.8462, stu_CELoss: 2.0174, DKDLoss: 1.8287, 
2022-07-28 15:12:14 - train: epoch 0014, iter [01800, 05004], lr: 0.100000, loss: 4.0329, stu_CELoss: 2.0742, DKDLoss: 1.9587, 
2022-07-28 15:12:47 - train: epoch 0014, iter [01900, 05004], lr: 0.100000, loss: 3.3704, stu_CELoss: 1.8189, DKDLoss: 1.5514, 
2022-07-28 15:13:21 - train: epoch 0014, iter [02000, 05004], lr: 0.100000, loss: 3.4777, stu_CELoss: 1.7528, DKDLoss: 1.7249, 
2022-07-28 15:13:54 - train: epoch 0014, iter [02100, 05004], lr: 0.100000, loss: 3.8669, stu_CELoss: 1.9859, DKDLoss: 1.8810, 
2022-07-28 15:14:27 - train: epoch 0014, iter [02200, 05004], lr: 0.100000, loss: 3.7762, stu_CELoss: 1.9004, DKDLoss: 1.8758, 
2022-07-28 15:14:59 - train: epoch 0014, iter [02300, 05004], lr: 0.100000, loss: 3.7189, stu_CELoss: 1.8921, DKDLoss: 1.8268, 
2022-07-28 15:15:32 - train: epoch 0014, iter [02400, 05004], lr: 0.100000, loss: 3.8793, stu_CELoss: 2.0496, DKDLoss: 1.8297, 
2022-07-28 15:16:04 - train: epoch 0014, iter [02500, 05004], lr: 0.100000, loss: 3.6316, stu_CELoss: 1.8698, DKDLoss: 1.7617, 
2022-07-28 15:16:36 - train: epoch 0014, iter [02600, 05004], lr: 0.100000, loss: 3.4639, stu_CELoss: 1.7428, DKDLoss: 1.7211, 
2022-07-28 15:17:09 - train: epoch 0014, iter [02700, 05004], lr: 0.100000, loss: 3.6082, stu_CELoss: 1.8424, DKDLoss: 1.7658, 
2022-07-28 15:17:41 - train: epoch 0014, iter [02800, 05004], lr: 0.100000, loss: 3.9943, stu_CELoss: 2.1391, DKDLoss: 1.8552, 
2022-07-28 15:18:13 - train: epoch 0014, iter [02900, 05004], lr: 0.100000, loss: 3.7260, stu_CELoss: 1.9622, DKDLoss: 1.7638, 
2022-07-28 15:18:46 - train: epoch 0014, iter [03000, 05004], lr: 0.100000, loss: 4.1262, stu_CELoss: 2.0711, DKDLoss: 2.0550, 
2022-07-28 15:19:18 - train: epoch 0014, iter [03100, 05004], lr: 0.100000, loss: 3.6876, stu_CELoss: 1.8630, DKDLoss: 1.8247, 
2022-07-28 15:19:51 - train: epoch 0014, iter [03200, 05004], lr: 0.100000, loss: 4.0202, stu_CELoss: 2.0176, DKDLoss: 2.0026, 
2022-07-28 15:20:23 - train: epoch 0014, iter [03300, 05004], lr: 0.100000, loss: 3.5711, stu_CELoss: 1.8203, DKDLoss: 1.7508, 
2022-07-28 15:20:56 - train: epoch 0014, iter [03400, 05004], lr: 0.100000, loss: 3.6004, stu_CELoss: 1.8750, DKDLoss: 1.7254, 
2022-07-28 15:21:28 - train: epoch 0014, iter [03500, 05004], lr: 0.100000, loss: 3.6724, stu_CELoss: 1.8679, DKDLoss: 1.8045, 
2022-07-28 15:22:01 - train: epoch 0014, iter [03600, 05004], lr: 0.100000, loss: 3.4447, stu_CELoss: 1.7643, DKDLoss: 1.6805, 
2022-07-28 15:22:33 - train: epoch 0014, iter [03700, 05004], lr: 0.100000, loss: 3.8345, stu_CELoss: 1.9932, DKDLoss: 1.8413, 
2022-07-28 15:23:05 - train: epoch 0014, iter [03800, 05004], lr: 0.100000, loss: 4.0835, stu_CELoss: 2.1342, DKDLoss: 1.9494, 
2022-07-28 15:23:38 - train: epoch 0014, iter [03900, 05004], lr: 0.100000, loss: 3.5604, stu_CELoss: 1.8815, DKDLoss: 1.6789, 
2022-07-28 15:24:10 - train: epoch 0014, iter [04000, 05004], lr: 0.100000, loss: 3.8861, stu_CELoss: 1.9386, DKDLoss: 1.9475, 
2022-07-28 15:24:42 - train: epoch 0014, iter [04100, 05004], lr: 0.100000, loss: 3.9849, stu_CELoss: 1.9843, DKDLoss: 2.0005, 
2022-07-28 15:25:15 - train: epoch 0014, iter [04200, 05004], lr: 0.100000, loss: 3.9007, stu_CELoss: 1.9278, DKDLoss: 1.9729, 
2022-07-28 15:25:48 - train: epoch 0014, iter [04300, 05004], lr: 0.100000, loss: 3.8772, stu_CELoss: 1.9938, DKDLoss: 1.8834, 
2022-07-28 15:26:20 - train: epoch 0014, iter [04400, 05004], lr: 0.100000, loss: 3.5789, stu_CELoss: 1.7718, DKDLoss: 1.8071, 
2022-07-28 15:26:52 - train: epoch 0014, iter [04500, 05004], lr: 0.100000, loss: 3.6845, stu_CELoss: 1.9482, DKDLoss: 1.7363, 
2022-07-28 15:27:25 - train: epoch 0014, iter [04600, 05004], lr: 0.100000, loss: 3.5615, stu_CELoss: 1.7834, DKDLoss: 1.7781, 
2022-07-28 15:27:57 - train: epoch 0014, iter [04700, 05004], lr: 0.100000, loss: 3.5289, stu_CELoss: 1.8177, DKDLoss: 1.7112, 
2022-07-28 15:28:31 - train: epoch 0014, iter [04800, 05004], lr: 0.100000, loss: 3.8964, stu_CELoss: 2.0152, DKDLoss: 1.8812, 
2022-07-28 15:29:04 - train: epoch 0014, iter [04900, 05004], lr: 0.100000, loss: 3.7330, stu_CELoss: 2.0212, DKDLoss: 1.7118, 
2022-07-28 15:29:37 - train: epoch 0014, iter [05000, 05004], lr: 0.100000, loss: 3.8087, stu_CELoss: 1.9900, DKDLoss: 1.8186, 
2022-07-28 15:29:39 - train: epoch 014, train_loss: 3.7411
2022-07-28 15:32:11 - eval: epoch: 014, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 50.308%, stu_acc5: 75.462%, stu_test_loss: 2.2293
2022-07-28 15:32:11 - until epoch: 014, tea_best_acc1: 78.068%, stu_best_acc1: 57.692%
2022-07-28 15:32:11 - epoch 015 lr: 0.100000
2022-07-28 15:32:52 - train: epoch 0015, iter [00100, 05004], lr: 0.100000, loss: 3.3891, stu_CELoss: 1.7376, DKDLoss: 1.6515, 
2022-07-28 15:33:25 - train: epoch 0015, iter [00200, 05004], lr: 0.100000, loss: 3.9169, stu_CELoss: 2.0802, DKDLoss: 1.8367, 
2022-07-28 15:33:58 - train: epoch 0015, iter [00300, 05004], lr: 0.100000, loss: 4.0416, stu_CELoss: 2.1303, DKDLoss: 1.9113, 
2022-07-28 15:34:32 - train: epoch 0015, iter [00400, 05004], lr: 0.100000, loss: 3.7076, stu_CELoss: 1.8368, DKDLoss: 1.8707, 
2022-07-28 15:35:06 - train: epoch 0015, iter [00500, 05004], lr: 0.100000, loss: 3.4995, stu_CELoss: 1.8133, DKDLoss: 1.6862, 
2022-07-28 15:35:40 - train: epoch 0015, iter [00600, 05004], lr: 0.100000, loss: 3.6933, stu_CELoss: 1.9727, DKDLoss: 1.7206, 
2022-07-28 15:36:14 - train: epoch 0015, iter [00700, 05004], lr: 0.100000, loss: 3.7253, stu_CELoss: 1.9761, DKDLoss: 1.7492, 
2022-07-28 15:36:47 - train: epoch 0015, iter [00800, 05004], lr: 0.100000, loss: 3.5300, stu_CELoss: 1.8115, DKDLoss: 1.7185, 
2022-07-28 15:37:21 - train: epoch 0015, iter [00900, 05004], lr: 0.100000, loss: 3.2707, stu_CELoss: 1.7589, DKDLoss: 1.5119, 
2022-07-28 15:37:54 - train: epoch 0015, iter [01000, 05004], lr: 0.100000, loss: 3.8381, stu_CELoss: 2.0356, DKDLoss: 1.8025, 
2022-07-28 15:38:27 - train: epoch 0015, iter [01100, 05004], lr: 0.100000, loss: 3.6301, stu_CELoss: 1.9433, DKDLoss: 1.6869, 
2022-07-28 15:39:01 - train: epoch 0015, iter [01200, 05004], lr: 0.100000, loss: 3.5634, stu_CELoss: 1.8935, DKDLoss: 1.6700, 
2022-07-28 15:39:34 - train: epoch 0015, iter [01300, 05004], lr: 0.100000, loss: 3.8801, stu_CELoss: 2.1032, DKDLoss: 1.7769, 
2022-07-28 15:40:08 - train: epoch 0015, iter [01400, 05004], lr: 0.100000, loss: 3.4952, stu_CELoss: 1.8902, DKDLoss: 1.6050, 
2022-07-28 15:40:42 - train: epoch 0015, iter [01500, 05004], lr: 0.100000, loss: 3.5472, stu_CELoss: 1.8010, DKDLoss: 1.7462, 
2022-07-28 15:41:15 - train: epoch 0015, iter [01600, 05004], lr: 0.100000, loss: 3.8294, stu_CELoss: 1.9559, DKDLoss: 1.8736, 
2022-07-28 15:41:49 - train: epoch 0015, iter [01700, 05004], lr: 0.100000, loss: 3.9145, stu_CELoss: 1.9518, DKDLoss: 1.9627, 
2022-07-28 15:42:22 - train: epoch 0015, iter [01800, 05004], lr: 0.100000, loss: 3.7096, stu_CELoss: 1.9087, DKDLoss: 1.8008, 
2022-07-28 15:42:55 - train: epoch 0015, iter [01900, 05004], lr: 0.100000, loss: 3.4576, stu_CELoss: 1.7071, DKDLoss: 1.7505, 
2022-07-28 15:43:29 - train: epoch 0015, iter [02000, 05004], lr: 0.100000, loss: 3.4354, stu_CELoss: 1.7271, DKDLoss: 1.7083, 
2022-07-28 15:44:03 - train: epoch 0015, iter [02100, 05004], lr: 0.100000, loss: 3.5136, stu_CELoss: 1.8342, DKDLoss: 1.6794, 
2022-07-28 15:44:36 - train: epoch 0015, iter [02200, 05004], lr: 0.100000, loss: 3.7437, stu_CELoss: 1.9591, DKDLoss: 1.7846, 
2022-07-28 15:45:10 - train: epoch 0015, iter [02300, 05004], lr: 0.100000, loss: 3.6931, stu_CELoss: 1.8966, DKDLoss: 1.7965, 
2022-07-28 15:45:43 - train: epoch 0015, iter [02400, 05004], lr: 0.100000, loss: 3.7268, stu_CELoss: 1.9702, DKDLoss: 1.7566, 
2022-07-28 15:46:17 - train: epoch 0015, iter [02500, 05004], lr: 0.100000, loss: 3.5596, stu_CELoss: 1.9226, DKDLoss: 1.6370, 
2022-07-28 15:46:50 - train: epoch 0015, iter [02600, 05004], lr: 0.100000, loss: 3.5776, stu_CELoss: 1.7681, DKDLoss: 1.8095, 
2022-07-28 15:47:24 - train: epoch 0015, iter [02700, 05004], lr: 0.100000, loss: 3.6962, stu_CELoss: 1.9953, DKDLoss: 1.7009, 
2022-07-28 15:47:57 - train: epoch 0015, iter [02800, 05004], lr: 0.100000, loss: 3.6450, stu_CELoss: 1.8948, DKDLoss: 1.7502, 
2022-07-28 15:48:31 - train: epoch 0015, iter [02900, 05004], lr: 0.100000, loss: 3.5079, stu_CELoss: 1.8408, DKDLoss: 1.6671, 
2022-07-28 15:49:04 - train: epoch 0015, iter [03000, 05004], lr: 0.100000, loss: 3.5571, stu_CELoss: 1.7679, DKDLoss: 1.7892, 
2022-07-28 15:49:38 - train: epoch 0015, iter [03100, 05004], lr: 0.100000, loss: 3.6010, stu_CELoss: 1.9603, DKDLoss: 1.6407, 
2022-07-28 15:50:12 - train: epoch 0015, iter [03200, 05004], lr: 0.100000, loss: 3.6127, stu_CELoss: 1.7771, DKDLoss: 1.8357, 
2022-07-28 15:50:45 - train: epoch 0015, iter [03300, 05004], lr: 0.100000, loss: 3.2776, stu_CELoss: 1.7599, DKDLoss: 1.5177, 
2022-07-28 15:51:19 - train: epoch 0015, iter [03400, 05004], lr: 0.100000, loss: 3.8241, stu_CELoss: 1.9459, DKDLoss: 1.8782, 
2022-07-28 15:51:52 - train: epoch 0015, iter [03500, 05004], lr: 0.100000, loss: 4.1996, stu_CELoss: 2.2225, DKDLoss: 1.9771, 
2022-07-28 15:52:26 - train: epoch 0015, iter [03600, 05004], lr: 0.100000, loss: 3.9928, stu_CELoss: 2.0505, DKDLoss: 1.9423, 
2022-07-28 15:53:00 - train: epoch 0015, iter [03700, 05004], lr: 0.100000, loss: 3.1804, stu_CELoss: 1.5176, DKDLoss: 1.6627, 
2022-07-28 15:53:34 - train: epoch 0015, iter [03800, 05004], lr: 0.100000, loss: 3.8065, stu_CELoss: 2.0528, DKDLoss: 1.7537, 
2022-07-28 15:54:07 - train: epoch 0015, iter [03900, 05004], lr: 0.100000, loss: 4.0636, stu_CELoss: 2.0552, DKDLoss: 2.0084, 
2022-07-28 15:54:41 - train: epoch 0015, iter [04000, 05004], lr: 0.100000, loss: 3.5653, stu_CELoss: 1.8893, DKDLoss: 1.6760, 
2022-07-28 15:55:15 - train: epoch 0015, iter [04100, 05004], lr: 0.100000, loss: 3.7211, stu_CELoss: 1.8081, DKDLoss: 1.9130, 
2022-07-28 15:55:49 - train: epoch 0015, iter [04200, 05004], lr: 0.100000, loss: 3.3759, stu_CELoss: 1.7209, DKDLoss: 1.6550, 
2022-07-28 15:56:23 - train: epoch 0015, iter [04300, 05004], lr: 0.100000, loss: 3.7748, stu_CELoss: 1.8320, DKDLoss: 1.9428, 
2022-07-28 15:56:57 - train: epoch 0015, iter [04400, 05004], lr: 0.100000, loss: 3.6904, stu_CELoss: 1.9438, DKDLoss: 1.7466, 
2022-07-28 15:57:30 - train: epoch 0015, iter [04500, 05004], lr: 0.100000, loss: 3.6984, stu_CELoss: 1.8773, DKDLoss: 1.8211, 
2022-07-28 15:58:03 - train: epoch 0015, iter [04600, 05004], lr: 0.100000, loss: 3.9415, stu_CELoss: 2.0591, DKDLoss: 1.8824, 
2022-07-28 15:58:37 - train: epoch 0015, iter [04700, 05004], lr: 0.100000, loss: 3.7303, stu_CELoss: 1.8921, DKDLoss: 1.8382, 
2022-07-28 15:59:10 - train: epoch 0015, iter [04800, 05004], lr: 0.100000, loss: 4.0149, stu_CELoss: 2.0737, DKDLoss: 1.9412, 
2022-07-28 15:59:44 - train: epoch 0015, iter [04900, 05004], lr: 0.100000, loss: 3.6064, stu_CELoss: 1.8709, DKDLoss: 1.7355, 
2022-07-28 16:00:17 - train: epoch 0015, iter [05000, 05004], lr: 0.100000, loss: 3.8880, stu_CELoss: 2.0888, DKDLoss: 1.7993, 
2022-07-28 16:00:18 - train: epoch 015, train_loss: 3.6992
2022-07-28 16:02:50 - eval: epoch: 015, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 58.814%, stu_acc5: 82.658%, stu_test_loss: 1.7191
2022-07-28 16:02:51 - until epoch: 015, tea_best_acc1: 78.068%, stu_best_acc1: 58.814%
2022-07-28 16:02:51 - epoch 016 lr: 0.100000
2022-07-28 16:03:31 - train: epoch 0016, iter [00100, 05004], lr: 0.100000, loss: 3.5229, stu_CELoss: 1.8547, DKDLoss: 1.6683, 
2022-07-28 16:04:05 - train: epoch 0016, iter [00200, 05004], lr: 0.100000, loss: 3.4353, stu_CELoss: 1.6175, DKDLoss: 1.8178, 
2022-07-28 16:04:39 - train: epoch 0016, iter [00300, 05004], lr: 0.100000, loss: 3.6269, stu_CELoss: 1.8828, DKDLoss: 1.7441, 
2022-07-28 16:05:13 - train: epoch 0016, iter [00400, 05004], lr: 0.100000, loss: 3.6840, stu_CELoss: 1.8710, DKDLoss: 1.8130, 
2022-07-28 16:05:47 - train: epoch 0016, iter [00500, 05004], lr: 0.100000, loss: 3.5032, stu_CELoss: 1.8422, DKDLoss: 1.6610, 
2022-07-28 16:06:21 - train: epoch 0016, iter [00600, 05004], lr: 0.100000, loss: 3.3579, stu_CELoss: 1.7147, DKDLoss: 1.6431, 
2022-07-28 16:06:55 - train: epoch 0016, iter [00700, 05004], lr: 0.100000, loss: 3.4619, stu_CELoss: 1.8104, DKDLoss: 1.6515, 
2022-07-28 16:07:29 - train: epoch 0016, iter [00800, 05004], lr: 0.100000, loss: 3.5563, stu_CELoss: 1.8436, DKDLoss: 1.7127, 
2022-07-28 16:08:03 - train: epoch 0016, iter [00900, 05004], lr: 0.100000, loss: 3.6381, stu_CELoss: 1.8838, DKDLoss: 1.7542, 
2022-07-28 16:08:36 - train: epoch 0016, iter [01000, 05004], lr: 0.100000, loss: 3.7195, stu_CELoss: 1.8673, DKDLoss: 1.8522, 
2022-07-28 16:09:10 - train: epoch 0016, iter [01100, 05004], lr: 0.100000, loss: 3.4869, stu_CELoss: 1.7760, DKDLoss: 1.7109, 
2022-07-28 16:09:44 - train: epoch 0016, iter [01200, 05004], lr: 0.100000, loss: 3.6950, stu_CELoss: 1.8641, DKDLoss: 1.8309, 
2022-07-28 16:10:18 - train: epoch 0016, iter [01300, 05004], lr: 0.100000, loss: 3.7277, stu_CELoss: 1.9563, DKDLoss: 1.7714, 
2022-07-28 16:10:52 - train: epoch 0016, iter [01400, 05004], lr: 0.100000, loss: 3.3809, stu_CELoss: 1.8271, DKDLoss: 1.5538, 
2022-07-28 16:11:25 - train: epoch 0016, iter [01500, 05004], lr: 0.100000, loss: 4.1189, stu_CELoss: 2.1792, DKDLoss: 1.9396, 
2022-07-28 16:11:59 - train: epoch 0016, iter [01600, 05004], lr: 0.100000, loss: 3.8493, stu_CELoss: 2.0643, DKDLoss: 1.7850, 
2022-07-28 16:12:33 - train: epoch 0016, iter [01700, 05004], lr: 0.100000, loss: 3.7377, stu_CELoss: 1.9147, DKDLoss: 1.8229, 
2022-07-28 16:13:07 - train: epoch 0016, iter [01800, 05004], lr: 0.100000, loss: 3.6934, stu_CELoss: 1.9898, DKDLoss: 1.7036, 
2022-07-28 16:13:41 - train: epoch 0016, iter [01900, 05004], lr: 0.100000, loss: 3.4893, stu_CELoss: 1.8545, DKDLoss: 1.6348, 
2022-07-28 16:14:16 - train: epoch 0016, iter [02000, 05004], lr: 0.100000, loss: 3.1288, stu_CELoss: 1.5195, DKDLoss: 1.6094, 
2022-07-28 16:14:50 - train: epoch 0016, iter [02100, 05004], lr: 0.100000, loss: 3.7019, stu_CELoss: 1.9490, DKDLoss: 1.7529, 
2022-07-28 16:15:24 - train: epoch 0016, iter [02200, 05004], lr: 0.100000, loss: 3.8230, stu_CELoss: 1.9470, DKDLoss: 1.8760, 
2022-07-28 16:15:58 - train: epoch 0016, iter [02300, 05004], lr: 0.100000, loss: 3.8003, stu_CELoss: 1.9612, DKDLoss: 1.8390, 
2022-07-28 16:16:32 - train: epoch 0016, iter [02400, 05004], lr: 0.100000, loss: 3.5704, stu_CELoss: 1.8403, DKDLoss: 1.7301, 
2022-07-28 16:17:07 - train: epoch 0016, iter [02500, 05004], lr: 0.100000, loss: 3.7002, stu_CELoss: 1.8782, DKDLoss: 1.8220, 
2022-07-28 16:17:41 - train: epoch 0016, iter [02600, 05004], lr: 0.100000, loss: 3.9750, stu_CELoss: 1.9587, DKDLoss: 2.0163, 
2022-07-28 16:18:15 - train: epoch 0016, iter [02700, 05004], lr: 0.100000, loss: 3.5070, stu_CELoss: 1.8480, DKDLoss: 1.6589, 
2022-07-28 16:18:49 - train: epoch 0016, iter [02800, 05004], lr: 0.100000, loss: 3.4081, stu_CELoss: 1.7512, DKDLoss: 1.6569, 
2022-07-28 16:19:23 - train: epoch 0016, iter [02900, 05004], lr: 0.100000, loss: 3.7602, stu_CELoss: 1.8932, DKDLoss: 1.8670, 
2022-07-28 16:19:57 - train: epoch 0016, iter [03000, 05004], lr: 0.100000, loss: 3.7708, stu_CELoss: 1.9961, DKDLoss: 1.7747, 
2022-07-28 16:20:31 - train: epoch 0016, iter [03100, 05004], lr: 0.100000, loss: 3.8445, stu_CELoss: 1.9762, DKDLoss: 1.8682, 
2022-07-28 16:21:06 - train: epoch 0016, iter [03200, 05004], lr: 0.100000, loss: 3.9180, stu_CELoss: 2.0106, DKDLoss: 1.9073, 
2022-07-28 16:21:40 - train: epoch 0016, iter [03300, 05004], lr: 0.100000, loss: 3.7529, stu_CELoss: 1.9888, DKDLoss: 1.7641, 
2022-07-28 16:22:15 - train: epoch 0016, iter [03400, 05004], lr: 0.100000, loss: 3.4446, stu_CELoss: 1.8653, DKDLoss: 1.5793, 
2022-07-28 16:22:49 - train: epoch 0016, iter [03500, 05004], lr: 0.100000, loss: 3.4383, stu_CELoss: 1.7328, DKDLoss: 1.7055, 
2022-07-28 16:23:23 - train: epoch 0016, iter [03600, 05004], lr: 0.100000, loss: 3.4173, stu_CELoss: 1.7302, DKDLoss: 1.6870, 
2022-07-28 16:23:57 - train: epoch 0016, iter [03700, 05004], lr: 0.100000, loss: 3.8096, stu_CELoss: 1.9346, DKDLoss: 1.8750, 
2022-07-28 16:24:32 - train: epoch 0016, iter [03800, 05004], lr: 0.100000, loss: 4.0543, stu_CELoss: 2.1990, DKDLoss: 1.8554, 
2022-07-28 16:25:06 - train: epoch 0016, iter [03900, 05004], lr: 0.100000, loss: 4.0402, stu_CELoss: 2.1096, DKDLoss: 1.9306, 
2022-07-28 16:25:40 - train: epoch 0016, iter [04000, 05004], lr: 0.100000, loss: 3.6177, stu_CELoss: 1.8900, DKDLoss: 1.7277, 
2022-07-28 16:26:14 - train: epoch 0016, iter [04100, 05004], lr: 0.100000, loss: 3.5702, stu_CELoss: 1.7959, DKDLoss: 1.7743, 
2022-07-28 16:26:49 - train: epoch 0016, iter [04200, 05004], lr: 0.100000, loss: 3.5881, stu_CELoss: 1.8177, DKDLoss: 1.7705, 
2022-07-28 16:27:23 - train: epoch 0016, iter [04300, 05004], lr: 0.100000, loss: 3.5320, stu_CELoss: 1.7464, DKDLoss: 1.7856, 
2022-07-28 16:27:57 - train: epoch 0016, iter [04400, 05004], lr: 0.100000, loss: 3.4363, stu_CELoss: 1.8094, DKDLoss: 1.6268, 
2022-07-28 16:28:31 - train: epoch 0016, iter [04500, 05004], lr: 0.100000, loss: 3.8313, stu_CELoss: 2.0228, DKDLoss: 1.8085, 
2022-07-28 16:29:05 - train: epoch 0016, iter [04600, 05004], lr: 0.100000, loss: 3.5290, stu_CELoss: 1.7766, DKDLoss: 1.7524, 
2022-07-28 16:29:39 - train: epoch 0016, iter [04700, 05004], lr: 0.100000, loss: 3.7590, stu_CELoss: 2.0926, DKDLoss: 1.6665, 
2022-07-28 16:30:14 - train: epoch 0016, iter [04800, 05004], lr: 0.100000, loss: 3.4213, stu_CELoss: 1.8277, DKDLoss: 1.5937, 
2022-07-28 16:30:48 - train: epoch 0016, iter [04900, 05004], lr: 0.100000, loss: 3.5820, stu_CELoss: 1.8301, DKDLoss: 1.7519, 
2022-07-28 16:31:21 - train: epoch 0016, iter [05000, 05004], lr: 0.100000, loss: 3.8199, stu_CELoss: 1.9868, DKDLoss: 1.8331, 
2022-07-28 16:31:23 - train: epoch 016, train_loss: 3.6601
2022-07-28 16:33:56 - eval: epoch: 016, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 55.732%, stu_acc5: 80.306%, stu_test_loss: 1.8742
2022-07-28 16:33:57 - until epoch: 016, tea_best_acc1: 78.068%, stu_best_acc1: 58.814%
2022-07-28 16:33:57 - epoch 017 lr: 0.100000
2022-07-28 16:34:37 - train: epoch 0017, iter [00100, 05004], lr: 0.100000, loss: 3.6556, stu_CELoss: 1.8975, DKDLoss: 1.7582, 
2022-07-28 16:35:11 - train: epoch 0017, iter [00200, 05004], lr: 0.100000, loss: 3.7205, stu_CELoss: 1.9489, DKDLoss: 1.7716, 
2022-07-28 16:35:44 - train: epoch 0017, iter [00300, 05004], lr: 0.100000, loss: 3.7650, stu_CELoss: 2.0125, DKDLoss: 1.7524, 
2022-07-28 16:36:19 - train: epoch 0017, iter [00400, 05004], lr: 0.100000, loss: 3.3505, stu_CELoss: 1.6001, DKDLoss: 1.7504, 
2022-07-28 16:36:52 - train: epoch 0017, iter [00500, 05004], lr: 0.100000, loss: 3.6013, stu_CELoss: 1.9180, DKDLoss: 1.6833, 
2022-07-28 16:37:26 - train: epoch 0017, iter [00600, 05004], lr: 0.100000, loss: 3.9244, stu_CELoss: 2.0026, DKDLoss: 1.9218, 
2022-07-28 16:38:00 - train: epoch 0017, iter [00700, 05004], lr: 0.100000, loss: 3.5321, stu_CELoss: 1.8511, DKDLoss: 1.6811, 
2022-07-28 16:38:34 - train: epoch 0017, iter [00800, 05004], lr: 0.100000, loss: 3.3342, stu_CELoss: 1.7728, DKDLoss: 1.5614, 
2022-07-28 16:39:08 - train: epoch 0017, iter [00900, 05004], lr: 0.100000, loss: 3.5058, stu_CELoss: 1.8009, DKDLoss: 1.7049, 
2022-07-28 16:39:42 - train: epoch 0017, iter [01000, 05004], lr: 0.100000, loss: 3.9138, stu_CELoss: 2.0092, DKDLoss: 1.9047, 
2022-07-28 16:40:17 - train: epoch 0017, iter [01100, 05004], lr: 0.100000, loss: 3.9850, stu_CELoss: 2.1732, DKDLoss: 1.8118, 
2022-07-28 16:40:51 - train: epoch 0017, iter [01200, 05004], lr: 0.100000, loss: 3.3596, stu_CELoss: 1.7351, DKDLoss: 1.6245, 
2022-07-28 16:41:25 - train: epoch 0017, iter [01300, 05004], lr: 0.100000, loss: 3.7075, stu_CELoss: 2.0326, DKDLoss: 1.6749, 
2022-07-28 16:41:59 - train: epoch 0017, iter [01400, 05004], lr: 0.100000, loss: 3.5431, stu_CELoss: 1.8579, DKDLoss: 1.6851, 
2022-07-28 16:42:33 - train: epoch 0017, iter [01500, 05004], lr: 0.100000, loss: 3.3614, stu_CELoss: 1.7332, DKDLoss: 1.6282, 
2022-07-28 16:43:07 - train: epoch 0017, iter [01600, 05004], lr: 0.100000, loss: 3.8316, stu_CELoss: 1.9779, DKDLoss: 1.8537, 
2022-07-28 16:43:41 - train: epoch 0017, iter [01700, 05004], lr: 0.100000, loss: 3.4619, stu_CELoss: 1.7248, DKDLoss: 1.7371, 
2022-07-28 16:44:16 - train: epoch 0017, iter [01800, 05004], lr: 0.100000, loss: 3.6809, stu_CELoss: 1.9645, DKDLoss: 1.7163, 
2022-07-28 16:44:50 - train: epoch 0017, iter [01900, 05004], lr: 0.100000, loss: 3.3334, stu_CELoss: 1.7425, DKDLoss: 1.5908, 
2022-07-28 16:45:24 - train: epoch 0017, iter [02000, 05004], lr: 0.100000, loss: 3.8074, stu_CELoss: 2.0170, DKDLoss: 1.7904, 
2022-07-28 16:45:59 - train: epoch 0017, iter [02100, 05004], lr: 0.100000, loss: 3.6932, stu_CELoss: 1.9084, DKDLoss: 1.7848, 
2022-07-28 16:46:33 - train: epoch 0017, iter [02200, 05004], lr: 0.100000, loss: 3.1703, stu_CELoss: 1.5540, DKDLoss: 1.6163, 
2022-07-28 16:47:08 - train: epoch 0017, iter [02300, 05004], lr: 0.100000, loss: 3.6233, stu_CELoss: 1.9398, DKDLoss: 1.6836, 
2022-07-28 16:47:42 - train: epoch 0017, iter [02400, 05004], lr: 0.100000, loss: 3.7483, stu_CELoss: 1.9827, DKDLoss: 1.7656, 
2022-07-28 16:48:16 - train: epoch 0017, iter [02500, 05004], lr: 0.100000, loss: 3.8090, stu_CELoss: 1.9811, DKDLoss: 1.8279, 
2022-07-28 16:48:51 - train: epoch 0017, iter [02600, 05004], lr: 0.100000, loss: 3.4863, stu_CELoss: 1.8212, DKDLoss: 1.6651, 
2022-07-28 16:49:25 - train: epoch 0017, iter [02700, 05004], lr: 0.100000, loss: 3.6009, stu_CELoss: 1.8345, DKDLoss: 1.7665, 
2022-07-28 16:49:58 - train: epoch 0017, iter [02800, 05004], lr: 0.100000, loss: 3.6875, stu_CELoss: 1.8692, DKDLoss: 1.8182, 
2022-07-28 16:50:33 - train: epoch 0017, iter [02900, 05004], lr: 0.100000, loss: 3.9991, stu_CELoss: 2.1674, DKDLoss: 1.8317, 
2022-07-28 16:51:07 - train: epoch 0017, iter [03000, 05004], lr: 0.100000, loss: 3.7324, stu_CELoss: 1.9067, DKDLoss: 1.8257, 
2022-07-28 16:51:41 - train: epoch 0017, iter [03100, 05004], lr: 0.100000, loss: 3.7550, stu_CELoss: 1.9947, DKDLoss: 1.7603, 
2022-07-28 16:52:15 - train: epoch 0017, iter [03200, 05004], lr: 0.100000, loss: 3.2801, stu_CELoss: 1.6859, DKDLoss: 1.5943, 
2022-07-28 16:52:49 - train: epoch 0017, iter [03300, 05004], lr: 0.100000, loss: 3.9039, stu_CELoss: 2.1793, DKDLoss: 1.7245, 
2022-07-28 16:53:23 - train: epoch 0017, iter [03400, 05004], lr: 0.100000, loss: 3.4374, stu_CELoss: 1.7638, DKDLoss: 1.6736, 
2022-07-28 16:53:56 - train: epoch 0017, iter [03500, 05004], lr: 0.100000, loss: 3.6903, stu_CELoss: 1.9389, DKDLoss: 1.7514, 
2022-07-28 16:54:30 - train: epoch 0017, iter [03600, 05004], lr: 0.100000, loss: 3.5712, stu_CELoss: 1.8539, DKDLoss: 1.7173, 
2022-07-28 16:55:03 - train: epoch 0017, iter [03700, 05004], lr: 0.100000, loss: 3.4735, stu_CELoss: 1.8208, DKDLoss: 1.6527, 
2022-07-28 16:55:37 - train: epoch 0017, iter [03800, 05004], lr: 0.100000, loss: 4.0810, stu_CELoss: 2.1953, DKDLoss: 1.8857, 
2022-07-28 16:56:11 - train: epoch 0017, iter [03900, 05004], lr: 0.100000, loss: 3.5436, stu_CELoss: 1.7827, DKDLoss: 1.7609, 
2022-07-28 16:56:45 - train: epoch 0017, iter [04000, 05004], lr: 0.100000, loss: 3.5670, stu_CELoss: 1.9727, DKDLoss: 1.5943, 
2022-07-28 16:57:19 - train: epoch 0017, iter [04100, 05004], lr: 0.100000, loss: 3.6666, stu_CELoss: 1.9338, DKDLoss: 1.7328, 
2022-07-28 16:57:53 - train: epoch 0017, iter [04200, 05004], lr: 0.100000, loss: 3.6840, stu_CELoss: 1.8842, DKDLoss: 1.7998, 
2022-07-28 16:58:27 - train: epoch 0017, iter [04300, 05004], lr: 0.100000, loss: 3.3439, stu_CELoss: 1.7098, DKDLoss: 1.6341, 
2022-07-28 16:59:01 - train: epoch 0017, iter [04400, 05004], lr: 0.100000, loss: 3.8041, stu_CELoss: 1.9828, DKDLoss: 1.8213, 
2022-07-28 16:59:36 - train: epoch 0017, iter [04500, 05004], lr: 0.100000, loss: 3.7968, stu_CELoss: 1.9877, DKDLoss: 1.8091, 
2022-07-28 17:00:10 - train: epoch 0017, iter [04600, 05004], lr: 0.100000, loss: 3.3347, stu_CELoss: 1.7137, DKDLoss: 1.6210, 
2022-07-28 17:00:44 - train: epoch 0017, iter [04700, 05004], lr: 0.100000, loss: 4.0794, stu_CELoss: 2.1606, DKDLoss: 1.9189, 
2022-07-28 17:01:18 - train: epoch 0017, iter [04800, 05004], lr: 0.100000, loss: 3.7514, stu_CELoss: 1.9727, DKDLoss: 1.7787, 
2022-07-28 17:01:52 - train: epoch 0017, iter [04900, 05004], lr: 0.100000, loss: 3.6417, stu_CELoss: 1.9139, DKDLoss: 1.7278, 
2022-07-28 17:02:26 - train: epoch 0017, iter [05000, 05004], lr: 0.100000, loss: 3.4576, stu_CELoss: 1.8054, DKDLoss: 1.6521, 
2022-07-28 17:02:28 - train: epoch 017, train_loss: 3.6338
2022-07-28 17:05:01 - eval: epoch: 017, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 58.360%, stu_acc5: 82.586%, stu_test_loss: 1.7300
2022-07-28 17:05:02 - until epoch: 017, tea_best_acc1: 78.068%, stu_best_acc1: 58.814%
2022-07-28 17:05:02 - epoch 018 lr: 0.100000
2022-07-28 17:05:42 - train: epoch 0018, iter [00100, 05004], lr: 0.100000, loss: 3.4235, stu_CELoss: 1.6952, DKDLoss: 1.7283, 
2022-07-28 17:06:16 - train: epoch 0018, iter [00200, 05004], lr: 0.100000, loss: 3.8361, stu_CELoss: 2.0759, DKDLoss: 1.7602, 
2022-07-28 17:06:50 - train: epoch 0018, iter [00300, 05004], lr: 0.100000, loss: 3.6056, stu_CELoss: 1.7865, DKDLoss: 1.8191, 
2022-07-28 17:07:24 - train: epoch 0018, iter [00400, 05004], lr: 0.100000, loss: 4.0630, stu_CELoss: 2.1112, DKDLoss: 1.9518, 
2022-07-28 17:07:58 - train: epoch 0018, iter [00500, 05004], lr: 0.100000, loss: 3.7517, stu_CELoss: 1.8979, DKDLoss: 1.8537, 
2022-07-28 17:08:32 - train: epoch 0018, iter [00600, 05004], lr: 0.100000, loss: 3.5612, stu_CELoss: 1.8828, DKDLoss: 1.6784, 
2022-07-28 17:09:06 - train: epoch 0018, iter [00700, 05004], lr: 0.100000, loss: 3.2407, stu_CELoss: 1.6457, DKDLoss: 1.5950, 
2022-07-28 17:09:40 - train: epoch 0018, iter [00800, 05004], lr: 0.100000, loss: 3.6857, stu_CELoss: 1.9227, DKDLoss: 1.7629, 
2022-07-28 17:10:14 - train: epoch 0018, iter [00900, 05004], lr: 0.100000, loss: 3.7264, stu_CELoss: 2.1368, DKDLoss: 1.5896, 
2022-07-28 17:10:48 - train: epoch 0018, iter [01000, 05004], lr: 0.100000, loss: 3.4070, stu_CELoss: 1.7108, DKDLoss: 1.6962, 
2022-07-28 17:11:22 - train: epoch 0018, iter [01100, 05004], lr: 0.100000, loss: 3.7677, stu_CELoss: 1.8981, DKDLoss: 1.8695, 
2022-07-28 17:11:56 - train: epoch 0018, iter [01200, 05004], lr: 0.100000, loss: 3.3048, stu_CELoss: 1.6878, DKDLoss: 1.6170, 
2022-07-28 17:12:30 - train: epoch 0018, iter [01300, 05004], lr: 0.100000, loss: 3.8262, stu_CELoss: 2.0335, DKDLoss: 1.7927, 
2022-07-28 17:13:05 - train: epoch 0018, iter [01400, 05004], lr: 0.100000, loss: 3.7798, stu_CELoss: 2.0118, DKDLoss: 1.7679, 
2022-07-28 17:13:39 - train: epoch 0018, iter [01500, 05004], lr: 0.100000, loss: 3.9701, stu_CELoss: 2.1121, DKDLoss: 1.8580, 
2022-07-28 17:14:13 - train: epoch 0018, iter [01600, 05004], lr: 0.100000, loss: 3.5272, stu_CELoss: 1.8199, DKDLoss: 1.7074, 
2022-07-28 17:14:47 - train: epoch 0018, iter [01700, 05004], lr: 0.100000, loss: 3.8226, stu_CELoss: 2.0172, DKDLoss: 1.8054, 
2022-07-28 17:15:22 - train: epoch 0018, iter [01800, 05004], lr: 0.100000, loss: 3.4993, stu_CELoss: 1.7783, DKDLoss: 1.7209, 
2022-07-28 17:15:56 - train: epoch 0018, iter [01900, 05004], lr: 0.100000, loss: 3.7165, stu_CELoss: 1.8964, DKDLoss: 1.8201, 
2022-07-28 17:16:31 - train: epoch 0018, iter [02000, 05004], lr: 0.100000, loss: 4.1848, stu_CELoss: 2.2623, DKDLoss: 1.9225, 
2022-07-28 17:17:05 - train: epoch 0018, iter [02100, 05004], lr: 0.100000, loss: 3.9198, stu_CELoss: 2.0848, DKDLoss: 1.8350, 
2022-07-28 17:17:39 - train: epoch 0018, iter [02200, 05004], lr: 0.100000, loss: 3.6099, stu_CELoss: 1.8296, DKDLoss: 1.7803, 
2022-07-28 17:18:13 - train: epoch 0018, iter [02300, 05004], lr: 0.100000, loss: 3.6042, stu_CELoss: 1.8260, DKDLoss: 1.7783, 
2022-07-28 17:18:48 - train: epoch 0018, iter [02400, 05004], lr: 0.100000, loss: 3.5579, stu_CELoss: 1.8591, DKDLoss: 1.6988, 
2022-07-28 17:19:22 - train: epoch 0018, iter [02500, 05004], lr: 0.100000, loss: 3.3647, stu_CELoss: 1.6596, DKDLoss: 1.7051, 
2022-07-28 17:19:56 - train: epoch 0018, iter [02600, 05004], lr: 0.100000, loss: 3.5075, stu_CELoss: 1.7914, DKDLoss: 1.7160, 
2022-07-28 17:20:31 - train: epoch 0018, iter [02700, 05004], lr: 0.100000, loss: 3.7144, stu_CELoss: 1.9943, DKDLoss: 1.7201, 
2022-07-28 17:21:05 - train: epoch 0018, iter [02800, 05004], lr: 0.100000, loss: 3.3871, stu_CELoss: 1.7583, DKDLoss: 1.6289, 
2022-07-28 17:21:39 - train: epoch 0018, iter [02900, 05004], lr: 0.100000, loss: 3.3565, stu_CELoss: 1.7763, DKDLoss: 1.5802, 
2022-07-28 17:22:14 - train: epoch 0018, iter [03000, 05004], lr: 0.100000, loss: 3.5999, stu_CELoss: 1.8597, DKDLoss: 1.7402, 
2022-07-28 17:22:48 - train: epoch 0018, iter [03100, 05004], lr: 0.100000, loss: 3.9654, stu_CELoss: 2.1892, DKDLoss: 1.7762, 
2022-07-28 17:23:23 - train: epoch 0018, iter [03200, 05004], lr: 0.100000, loss: 3.6463, stu_CELoss: 1.9185, DKDLoss: 1.7278, 
2022-07-28 17:23:57 - train: epoch 0018, iter [03300, 05004], lr: 0.100000, loss: 3.6914, stu_CELoss: 1.8804, DKDLoss: 1.8110, 
2022-07-28 17:24:31 - train: epoch 0018, iter [03400, 05004], lr: 0.100000, loss: 3.6665, stu_CELoss: 1.9809, DKDLoss: 1.6855, 
2022-07-28 17:25:06 - train: epoch 0018, iter [03500, 05004], lr: 0.100000, loss: 3.7021, stu_CELoss: 1.9586, DKDLoss: 1.7435, 
2022-07-28 17:25:40 - train: epoch 0018, iter [03600, 05004], lr: 0.100000, loss: 3.5752, stu_CELoss: 1.8160, DKDLoss: 1.7592, 
2022-07-28 17:26:14 - train: epoch 0018, iter [03700, 05004], lr: 0.100000, loss: 3.7902, stu_CELoss: 1.9809, DKDLoss: 1.8094, 
2022-07-28 17:26:48 - train: epoch 0018, iter [03800, 05004], lr: 0.100000, loss: 3.9782, stu_CELoss: 2.1134, DKDLoss: 1.8648, 
2022-07-28 17:27:23 - train: epoch 0018, iter [03900, 05004], lr: 0.100000, loss: 3.7490, stu_CELoss: 2.0679, DKDLoss: 1.6811, 
2022-07-28 17:27:57 - train: epoch 0018, iter [04000, 05004], lr: 0.100000, loss: 3.6284, stu_CELoss: 2.0031, DKDLoss: 1.6252, 
2022-07-28 17:28:31 - train: epoch 0018, iter [04100, 05004], lr: 0.100000, loss: 3.8406, stu_CELoss: 2.1257, DKDLoss: 1.7149, 
2022-07-28 17:29:05 - train: epoch 0018, iter [04200, 05004], lr: 0.100000, loss: 3.5240, stu_CELoss: 1.7988, DKDLoss: 1.7252, 
2022-07-28 17:29:39 - train: epoch 0018, iter [04300, 05004], lr: 0.100000, loss: 3.7530, stu_CELoss: 2.0158, DKDLoss: 1.7373, 
2022-07-28 17:30:14 - train: epoch 0018, iter [04400, 05004], lr: 0.100000, loss: 3.5355, stu_CELoss: 1.8105, DKDLoss: 1.7250, 
2022-07-28 17:30:48 - train: epoch 0018, iter [04500, 05004], lr: 0.100000, loss: 3.7008, stu_CELoss: 1.9176, DKDLoss: 1.7833, 
2022-07-28 17:31:23 - train: epoch 0018, iter [04600, 05004], lr: 0.100000, loss: 3.9252, stu_CELoss: 1.9401, DKDLoss: 1.9851, 
2022-07-28 17:31:58 - train: epoch 0018, iter [04700, 05004], lr: 0.100000, loss: 3.7026, stu_CELoss: 1.9308, DKDLoss: 1.7718, 
2022-07-28 17:32:32 - train: epoch 0018, iter [04800, 05004], lr: 0.100000, loss: 3.4543, stu_CELoss: 1.8145, DKDLoss: 1.6399, 
2022-07-28 17:33:07 - train: epoch 0018, iter [04900, 05004], lr: 0.100000, loss: 3.4291, stu_CELoss: 1.7480, DKDLoss: 1.6811, 
2022-07-28 17:33:41 - train: epoch 0018, iter [05000, 05004], lr: 0.100000, loss: 3.7426, stu_CELoss: 2.0362, DKDLoss: 1.7064, 
2022-07-28 17:33:42 - train: epoch 018, train_loss: 3.6045
2022-07-28 17:36:16 - eval: epoch: 018, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 57.250%, stu_acc5: 81.464%, stu_test_loss: 1.8006
2022-07-28 17:36:17 - until epoch: 018, tea_best_acc1: 78.068%, stu_best_acc1: 58.814%
2022-07-28 17:36:17 - epoch 019 lr: 0.100000
2022-07-28 17:36:57 - train: epoch 0019, iter [00100, 05004], lr: 0.100000, loss: 3.1110, stu_CELoss: 1.5949, DKDLoss: 1.5161, 
2022-07-28 17:37:31 - train: epoch 0019, iter [00200, 05004], lr: 0.100000, loss: 3.5352, stu_CELoss: 1.8298, DKDLoss: 1.7054, 
2022-07-28 17:38:05 - train: epoch 0019, iter [00300, 05004], lr: 0.100000, loss: 3.6481, stu_CELoss: 1.9478, DKDLoss: 1.7003, 
2022-07-28 17:38:39 - train: epoch 0019, iter [00400, 05004], lr: 0.100000, loss: 3.5635, stu_CELoss: 1.8632, DKDLoss: 1.7003, 
2022-07-28 17:39:13 - train: epoch 0019, iter [00500, 05004], lr: 0.100000, loss: 3.5566, stu_CELoss: 1.8256, DKDLoss: 1.7310, 
2022-07-28 17:39:47 - train: epoch 0019, iter [00600, 05004], lr: 0.100000, loss: 3.6131, stu_CELoss: 1.9752, DKDLoss: 1.6379, 
2022-07-28 17:40:21 - train: epoch 0019, iter [00700, 05004], lr: 0.100000, loss: 3.4288, stu_CELoss: 1.8324, DKDLoss: 1.5964, 
2022-07-28 17:40:55 - train: epoch 0019, iter [00800, 05004], lr: 0.100000, loss: 3.7878, stu_CELoss: 1.9695, DKDLoss: 1.8182, 
2022-07-28 17:41:30 - train: epoch 0019, iter [00900, 05004], lr: 0.100000, loss: 3.4801, stu_CELoss: 1.8009, DKDLoss: 1.6791, 
2022-07-28 17:42:04 - train: epoch 0019, iter [01000, 05004], lr: 0.100000, loss: 3.8447, stu_CELoss: 2.0632, DKDLoss: 1.7815, 
2022-07-28 17:42:39 - train: epoch 0019, iter [01100, 05004], lr: 0.100000, loss: 3.4604, stu_CELoss: 1.8047, DKDLoss: 1.6557, 
2022-07-28 17:43:13 - train: epoch 0019, iter [01200, 05004], lr: 0.100000, loss: 3.5595, stu_CELoss: 1.8894, DKDLoss: 1.6701, 
2022-07-28 17:43:47 - train: epoch 0019, iter [01300, 05004], lr: 0.100000, loss: 3.5798, stu_CELoss: 1.9249, DKDLoss: 1.6549, 
2022-07-28 17:44:21 - train: epoch 0019, iter [01400, 05004], lr: 0.100000, loss: 3.3225, stu_CELoss: 1.7116, DKDLoss: 1.6109, 
2022-07-28 17:44:55 - train: epoch 0019, iter [01500, 05004], lr: 0.100000, loss: 3.7835, stu_CELoss: 2.0029, DKDLoss: 1.7806, 
2022-07-28 17:45:28 - train: epoch 0019, iter [01600, 05004], lr: 0.100000, loss: 3.3469, stu_CELoss: 1.6863, DKDLoss: 1.6607, 
2022-07-28 17:46:01 - train: epoch 0019, iter [01700, 05004], lr: 0.100000, loss: 3.8506, stu_CELoss: 2.0709, DKDLoss: 1.7797, 
2022-07-28 17:46:34 - train: epoch 0019, iter [01800, 05004], lr: 0.100000, loss: 3.3600, stu_CELoss: 1.7415, DKDLoss: 1.6185, 
2022-07-28 17:47:07 - train: epoch 0019, iter [01900, 05004], lr: 0.100000, loss: 3.6054, stu_CELoss: 1.8904, DKDLoss: 1.7150, 
2022-07-28 17:47:41 - train: epoch 0019, iter [02000, 05004], lr: 0.100000, loss: 3.3695, stu_CELoss: 1.7628, DKDLoss: 1.6068, 
2022-07-28 17:48:13 - train: epoch 0019, iter [02100, 05004], lr: 0.100000, loss: 3.6471, stu_CELoss: 1.8610, DKDLoss: 1.7860, 
2022-07-28 17:48:47 - train: epoch 0019, iter [02200, 05004], lr: 0.100000, loss: 3.6690, stu_CELoss: 1.9314, DKDLoss: 1.7376, 
2022-07-28 17:49:20 - train: epoch 0019, iter [02300, 05004], lr: 0.100000, loss: 3.7666, stu_CELoss: 1.8782, DKDLoss: 1.8884, 
2022-07-28 17:49:53 - train: epoch 0019, iter [02400, 05004], lr: 0.100000, loss: 3.7849, stu_CELoss: 1.9881, DKDLoss: 1.7969, 
2022-07-28 17:50:26 - train: epoch 0019, iter [02500, 05004], lr: 0.100000, loss: 3.7006, stu_CELoss: 1.9603, DKDLoss: 1.7403, 
2022-07-28 17:50:59 - train: epoch 0019, iter [02600, 05004], lr: 0.100000, loss: 3.4151, stu_CELoss: 1.7607, DKDLoss: 1.6544, 
2022-07-28 17:51:32 - train: epoch 0019, iter [02700, 05004], lr: 0.100000, loss: 3.6049, stu_CELoss: 1.8296, DKDLoss: 1.7753, 
2022-07-28 17:52:06 - train: epoch 0019, iter [02800, 05004], lr: 0.100000, loss: 3.2345, stu_CELoss: 1.7054, DKDLoss: 1.5291, 
2022-07-28 17:52:39 - train: epoch 0019, iter [02900, 05004], lr: 0.100000, loss: 3.8017, stu_CELoss: 1.9590, DKDLoss: 1.8427, 
2022-07-28 17:53:12 - train: epoch 0019, iter [03000, 05004], lr: 0.100000, loss: 3.8560, stu_CELoss: 2.0494, DKDLoss: 1.8066, 
2022-07-28 17:53:45 - train: epoch 0019, iter [03100, 05004], lr: 0.100000, loss: 3.8423, stu_CELoss: 1.9542, DKDLoss: 1.8881, 
2022-07-28 17:54:18 - train: epoch 0019, iter [03200, 05004], lr: 0.100000, loss: 3.3961, stu_CELoss: 1.7717, DKDLoss: 1.6244, 
2022-07-28 17:54:52 - train: epoch 0019, iter [03300, 05004], lr: 0.100000, loss: 3.7040, stu_CELoss: 1.9501, DKDLoss: 1.7540, 
2022-07-28 17:55:26 - train: epoch 0019, iter [03400, 05004], lr: 0.100000, loss: 3.7504, stu_CELoss: 1.8989, DKDLoss: 1.8515, 
2022-07-28 17:55:58 - train: epoch 0019, iter [03500, 05004], lr: 0.100000, loss: 4.0163, stu_CELoss: 2.1189, DKDLoss: 1.8974, 
2022-07-28 17:56:31 - train: epoch 0019, iter [03600, 05004], lr: 0.100000, loss: 3.0902, stu_CELoss: 1.5384, DKDLoss: 1.5518, 
2022-07-28 17:57:05 - train: epoch 0019, iter [03700, 05004], lr: 0.100000, loss: 3.7090, stu_CELoss: 1.9273, DKDLoss: 1.7817, 
2022-07-28 17:57:38 - train: epoch 0019, iter [03800, 05004], lr: 0.100000, loss: 3.6775, stu_CELoss: 1.8892, DKDLoss: 1.7883, 
2022-07-28 17:58:11 - train: epoch 0019, iter [03900, 05004], lr: 0.100000, loss: 3.5115, stu_CELoss: 1.8902, DKDLoss: 1.6213, 
2022-07-28 17:58:45 - train: epoch 0019, iter [04000, 05004], lr: 0.100000, loss: 3.3972, stu_CELoss: 1.8375, DKDLoss: 1.5598, 
2022-07-28 17:59:18 - train: epoch 0019, iter [04100, 05004], lr: 0.100000, loss: 3.8450, stu_CELoss: 2.0826, DKDLoss: 1.7624, 
2022-07-28 17:59:51 - train: epoch 0019, iter [04200, 05004], lr: 0.100000, loss: 3.4131, stu_CELoss: 1.8140, DKDLoss: 1.5991, 
2022-07-28 18:00:24 - train: epoch 0019, iter [04300, 05004], lr: 0.100000, loss: 3.6131, stu_CELoss: 1.8498, DKDLoss: 1.7633, 
2022-07-28 18:00:57 - train: epoch 0019, iter [04400, 05004], lr: 0.100000, loss: 3.9637, stu_CELoss: 2.0686, DKDLoss: 1.8950, 
2022-07-28 18:01:30 - train: epoch 0019, iter [04500, 05004], lr: 0.100000, loss: 4.0017, stu_CELoss: 2.2033, DKDLoss: 1.7983, 
2022-07-28 18:02:03 - train: epoch 0019, iter [04600, 05004], lr: 0.100000, loss: 3.4694, stu_CELoss: 1.7834, DKDLoss: 1.6860, 
2022-07-28 18:02:36 - train: epoch 0019, iter [04700, 05004], lr: 0.100000, loss: 3.6270, stu_CELoss: 1.8449, DKDLoss: 1.7821, 
2022-07-28 18:03:10 - train: epoch 0019, iter [04800, 05004], lr: 0.100000, loss: 3.6140, stu_CELoss: 2.0075, DKDLoss: 1.6064, 
2022-07-28 18:03:43 - train: epoch 0019, iter [04900, 05004], lr: 0.100000, loss: 3.3282, stu_CELoss: 1.7429, DKDLoss: 1.5853, 
2022-07-28 18:04:16 - train: epoch 0019, iter [05000, 05004], lr: 0.100000, loss: 3.6702, stu_CELoss: 1.8270, DKDLoss: 1.8432, 
2022-07-28 18:04:18 - train: epoch 019, train_loss: 3.5804
2022-07-28 18:06:49 - eval: epoch: 019, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 58.574%, stu_acc5: 82.542%, stu_test_loss: 1.7255
2022-07-28 18:06:49 - until epoch: 019, tea_best_acc1: 78.068%, stu_best_acc1: 58.814%
2022-07-28 18:06:49 - epoch 020 lr: 0.100000
2022-07-28 18:07:29 - train: epoch 0020, iter [00100, 05004], lr: 0.100000, loss: 3.6811, stu_CELoss: 1.9527, DKDLoss: 1.7284, 
2022-07-28 18:08:02 - train: epoch 0020, iter [00200, 05004], lr: 0.100000, loss: 3.3369, stu_CELoss: 1.6767, DKDLoss: 1.6602, 
2022-07-28 18:08:35 - train: epoch 0020, iter [00300, 05004], lr: 0.100000, loss: 3.3143, stu_CELoss: 1.6613, DKDLoss: 1.6530, 
2022-07-28 18:09:08 - train: epoch 0020, iter [00400, 05004], lr: 0.100000, loss: 3.1594, stu_CELoss: 1.6255, DKDLoss: 1.5339, 
2022-07-28 18:09:41 - train: epoch 0020, iter [00500, 05004], lr: 0.100000, loss: 3.3373, stu_CELoss: 1.7384, DKDLoss: 1.5989, 
2022-07-28 18:10:14 - train: epoch 0020, iter [00600, 05004], lr: 0.100000, loss: 3.4367, stu_CELoss: 1.8477, DKDLoss: 1.5890, 
2022-07-28 18:10:48 - train: epoch 0020, iter [00700, 05004], lr: 0.100000, loss: 3.3875, stu_CELoss: 1.7502, DKDLoss: 1.6373, 
2022-07-28 18:11:21 - train: epoch 0020, iter [00800, 05004], lr: 0.100000, loss: 3.6496, stu_CELoss: 1.8547, DKDLoss: 1.7949, 
2022-07-28 18:11:54 - train: epoch 0020, iter [00900, 05004], lr: 0.100000, loss: 3.5477, stu_CELoss: 1.8382, DKDLoss: 1.7095, 
2022-07-28 18:12:27 - train: epoch 0020, iter [01000, 05004], lr: 0.100000, loss: 3.5700, stu_CELoss: 1.9691, DKDLoss: 1.6009, 
2022-07-28 18:13:00 - train: epoch 0020, iter [01100, 05004], lr: 0.100000, loss: 3.5184, stu_CELoss: 1.8082, DKDLoss: 1.7101, 
2022-07-28 18:13:33 - train: epoch 0020, iter [01200, 05004], lr: 0.100000, loss: 3.4023, stu_CELoss: 1.6806, DKDLoss: 1.7217, 
2022-07-28 18:14:05 - train: epoch 0020, iter [01300, 05004], lr: 0.100000, loss: 3.5468, stu_CELoss: 1.8818, DKDLoss: 1.6650, 
2022-07-28 18:14:38 - train: epoch 0020, iter [01400, 05004], lr: 0.100000, loss: 3.5766, stu_CELoss: 1.8591, DKDLoss: 1.7175, 
2022-07-28 18:15:11 - train: epoch 0020, iter [01500, 05004], lr: 0.100000, loss: 3.6577, stu_CELoss: 1.8423, DKDLoss: 1.8154, 
2022-07-28 18:15:45 - train: epoch 0020, iter [01600, 05004], lr: 0.100000, loss: 3.8509, stu_CELoss: 2.0397, DKDLoss: 1.8112, 
2022-07-28 18:16:18 - train: epoch 0020, iter [01700, 05004], lr: 0.100000, loss: 3.5230, stu_CELoss: 1.8675, DKDLoss: 1.6555, 
2022-07-28 18:16:52 - train: epoch 0020, iter [01800, 05004], lr: 0.100000, loss: 3.4887, stu_CELoss: 1.8761, DKDLoss: 1.6126, 
2022-07-28 18:17:26 - train: epoch 0020, iter [01900, 05004], lr: 0.100000, loss: 3.7611, stu_CELoss: 1.8873, DKDLoss: 1.8738, 
2022-07-28 18:17:59 - train: epoch 0020, iter [02000, 05004], lr: 0.100000, loss: 3.4116, stu_CELoss: 1.7015, DKDLoss: 1.7101, 
2022-07-28 18:18:33 - train: epoch 0020, iter [02100, 05004], lr: 0.100000, loss: 3.7449, stu_CELoss: 1.9947, DKDLoss: 1.7502, 
2022-07-28 18:19:07 - train: epoch 0020, iter [02200, 05004], lr: 0.100000, loss: 3.2381, stu_CELoss: 1.6937, DKDLoss: 1.5444, 
2022-07-28 18:19:40 - train: epoch 0020, iter [02300, 05004], lr: 0.100000, loss: 3.6140, stu_CELoss: 1.9095, DKDLoss: 1.7045, 
2022-07-28 18:20:14 - train: epoch 0020, iter [02400, 05004], lr: 0.100000, loss: 3.6200, stu_CELoss: 1.9450, DKDLoss: 1.6750, 
2022-07-28 18:20:48 - train: epoch 0020, iter [02500, 05004], lr: 0.100000, loss: 3.3890, stu_CELoss: 1.8295, DKDLoss: 1.5595, 
2022-07-28 18:21:22 - train: epoch 0020, iter [02600, 05004], lr: 0.100000, loss: 3.4499, stu_CELoss: 1.8037, DKDLoss: 1.6462, 
2022-07-28 18:21:56 - train: epoch 0020, iter [02700, 05004], lr: 0.100000, loss: 3.6180, stu_CELoss: 1.8134, DKDLoss: 1.8046, 
2022-07-28 18:22:30 - train: epoch 0020, iter [02800, 05004], lr: 0.100000, loss: 3.7398, stu_CELoss: 1.9713, DKDLoss: 1.7686, 
2022-07-28 18:23:04 - train: epoch 0020, iter [02900, 05004], lr: 0.100000, loss: 3.5855, stu_CELoss: 1.9299, DKDLoss: 1.6556, 
2022-07-28 18:23:38 - train: epoch 0020, iter [03000, 05004], lr: 0.100000, loss: 3.8748, stu_CELoss: 2.0370, DKDLoss: 1.8378, 
2022-07-28 18:24:12 - train: epoch 0020, iter [03100, 05004], lr: 0.100000, loss: 3.6245, stu_CELoss: 1.8718, DKDLoss: 1.7527, 
2022-07-28 18:24:46 - train: epoch 0020, iter [03200, 05004], lr: 0.100000, loss: 3.7764, stu_CELoss: 1.8790, DKDLoss: 1.8975, 
2022-07-28 18:25:20 - train: epoch 0020, iter [03300, 05004], lr: 0.100000, loss: 3.3020, stu_CELoss: 1.6710, DKDLoss: 1.6310, 
2022-07-28 18:25:55 - train: epoch 0020, iter [03400, 05004], lr: 0.100000, loss: 3.5786, stu_CELoss: 1.8585, DKDLoss: 1.7202, 
2022-07-28 18:26:29 - train: epoch 0020, iter [03500, 05004], lr: 0.100000, loss: 3.3287, stu_CELoss: 1.6813, DKDLoss: 1.6474, 
2022-07-28 18:27:03 - train: epoch 0020, iter [03600, 05004], lr: 0.100000, loss: 3.5293, stu_CELoss: 1.8848, DKDLoss: 1.6445, 
2022-07-28 18:27:37 - train: epoch 0020, iter [03700, 05004], lr: 0.100000, loss: 3.6322, stu_CELoss: 1.8587, DKDLoss: 1.7735, 
2022-07-28 18:28:11 - train: epoch 0020, iter [03800, 05004], lr: 0.100000, loss: 3.4652, stu_CELoss: 1.7652, DKDLoss: 1.7000, 
2022-07-28 18:28:45 - train: epoch 0020, iter [03900, 05004], lr: 0.100000, loss: 3.9614, stu_CELoss: 2.0970, DKDLoss: 1.8644, 
2022-07-28 18:29:18 - train: epoch 0020, iter [04000, 05004], lr: 0.100000, loss: 3.5739, stu_CELoss: 1.8017, DKDLoss: 1.7722, 
2022-07-28 18:29:52 - train: epoch 0020, iter [04100, 05004], lr: 0.100000, loss: 3.7559, stu_CELoss: 1.9688, DKDLoss: 1.7870, 
2022-07-28 18:30:26 - train: epoch 0020, iter [04200, 05004], lr: 0.100000, loss: 3.7497, stu_CELoss: 1.9852, DKDLoss: 1.7644, 
2022-07-28 18:31:00 - train: epoch 0020, iter [04300, 05004], lr: 0.100000, loss: 3.7524, stu_CELoss: 2.0525, DKDLoss: 1.6999, 
2022-07-28 18:31:34 - train: epoch 0020, iter [04400, 05004], lr: 0.100000, loss: 3.4813, stu_CELoss: 1.8506, DKDLoss: 1.6306, 
2022-07-28 18:32:08 - train: epoch 0020, iter [04500, 05004], lr: 0.100000, loss: 3.7438, stu_CELoss: 1.8488, DKDLoss: 1.8949, 
2022-07-28 18:32:42 - train: epoch 0020, iter [04600, 05004], lr: 0.100000, loss: 3.4504, stu_CELoss: 1.8628, DKDLoss: 1.5876, 
2022-07-28 18:33:17 - train: epoch 0020, iter [04700, 05004], lr: 0.100000, loss: 3.3364, stu_CELoss: 1.7120, DKDLoss: 1.6244, 
2022-07-28 18:33:51 - train: epoch 0020, iter [04800, 05004], lr: 0.100000, loss: 3.4168, stu_CELoss: 1.8365, DKDLoss: 1.5802, 
2022-07-28 18:34:25 - train: epoch 0020, iter [04900, 05004], lr: 0.100000, loss: 3.7705, stu_CELoss: 1.9188, DKDLoss: 1.8516, 
2022-07-28 18:34:59 - train: epoch 0020, iter [05000, 05004], lr: 0.100000, loss: 3.3154, stu_CELoss: 1.7499, DKDLoss: 1.5655, 
2022-07-28 18:35:00 - train: epoch 020, train_loss: 3.5580
2022-07-28 18:37:36 - eval: epoch: 020, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 58.328%, stu_acc5: 82.272%, stu_test_loss: 1.7503
2022-07-28 18:37:36 - until epoch: 020, tea_best_acc1: 78.068%, stu_best_acc1: 58.814%
2022-07-28 18:37:36 - epoch 021 lr: 0.100000
2022-07-28 18:38:17 - train: epoch 0021, iter [00100, 05004], lr: 0.100000, loss: 3.3994, stu_CELoss: 1.8635, DKDLoss: 1.5359, 
2022-07-28 18:38:51 - train: epoch 0021, iter [00200, 05004], lr: 0.100000, loss: 3.5215, stu_CELoss: 1.8185, DKDLoss: 1.7030, 
2022-07-28 18:39:25 - train: epoch 0021, iter [00300, 05004], lr: 0.100000, loss: 2.9269, stu_CELoss: 1.5384, DKDLoss: 1.3884, 
2022-07-28 18:39:59 - train: epoch 0021, iter [00400, 05004], lr: 0.100000, loss: 3.3824, stu_CELoss: 1.8699, DKDLoss: 1.5125, 
2022-07-28 18:40:33 - train: epoch 0021, iter [00500, 05004], lr: 0.100000, loss: 3.1576, stu_CELoss: 1.5753, DKDLoss: 1.5823, 
2022-07-28 18:41:07 - train: epoch 0021, iter [00600, 05004], lr: 0.100000, loss: 3.4852, stu_CELoss: 1.8088, DKDLoss: 1.6764, 
2022-07-28 18:41:41 - train: epoch 0021, iter [00700, 05004], lr: 0.100000, loss: 3.1354, stu_CELoss: 1.5505, DKDLoss: 1.5848, 
2022-07-28 18:42:15 - train: epoch 0021, iter [00800, 05004], lr: 0.100000, loss: 3.3979, stu_CELoss: 1.7384, DKDLoss: 1.6595, 
2022-07-28 18:42:50 - train: epoch 0021, iter [00900, 05004], lr: 0.100000, loss: 3.6607, stu_CELoss: 1.8588, DKDLoss: 1.8019, 
2022-07-28 18:43:24 - train: epoch 0021, iter [01000, 05004], lr: 0.100000, loss: 3.4750, stu_CELoss: 1.7987, DKDLoss: 1.6763, 
2022-07-28 18:43:58 - train: epoch 0021, iter [01100, 05004], lr: 0.100000, loss: 3.5057, stu_CELoss: 1.8443, DKDLoss: 1.6614, 
2022-07-28 18:44:32 - train: epoch 0021, iter [01200, 05004], lr: 0.100000, loss: 3.2821, stu_CELoss: 1.7749, DKDLoss: 1.5072, 
2022-07-28 18:45:06 - train: epoch 0021, iter [01300, 05004], lr: 0.100000, loss: 3.3557, stu_CELoss: 1.6650, DKDLoss: 1.6907, 
2022-07-28 18:45:41 - train: epoch 0021, iter [01400, 05004], lr: 0.100000, loss: 3.3117, stu_CELoss: 1.5615, DKDLoss: 1.7502, 
2022-07-28 18:46:15 - train: epoch 0021, iter [01500, 05004], lr: 0.100000, loss: 3.4235, stu_CELoss: 1.8113, DKDLoss: 1.6122, 
2022-07-28 18:46:50 - train: epoch 0021, iter [01600, 05004], lr: 0.100000, loss: 3.4507, stu_CELoss: 1.8339, DKDLoss: 1.6168, 
2022-07-28 18:47:24 - train: epoch 0021, iter [01700, 05004], lr: 0.100000, loss: 3.6369, stu_CELoss: 1.9057, DKDLoss: 1.7311, 
2022-07-28 18:47:58 - train: epoch 0021, iter [01800, 05004], lr: 0.100000, loss: 3.5150, stu_CELoss: 1.8684, DKDLoss: 1.6466, 
2022-07-28 18:48:33 - train: epoch 0021, iter [01900, 05004], lr: 0.100000, loss: 3.6746, stu_CELoss: 1.9545, DKDLoss: 1.7200, 
2022-07-28 18:49:07 - train: epoch 0021, iter [02000, 05004], lr: 0.100000, loss: 3.6179, stu_CELoss: 1.9280, DKDLoss: 1.6899, 
2022-07-28 18:49:41 - train: epoch 0021, iter [02100, 05004], lr: 0.100000, loss: 3.1127, stu_CELoss: 1.6426, DKDLoss: 1.4700, 
2022-07-28 18:50:16 - train: epoch 0021, iter [02200, 05004], lr: 0.100000, loss: 3.8220, stu_CELoss: 1.9500, DKDLoss: 1.8719, 
2022-07-28 18:50:50 - train: epoch 0021, iter [02300, 05004], lr: 0.100000, loss: 3.8849, stu_CELoss: 2.0939, DKDLoss: 1.7910, 
2022-07-28 18:51:25 - train: epoch 0021, iter [02400, 05004], lr: 0.100000, loss: 3.2180, stu_CELoss: 1.6399, DKDLoss: 1.5781, 
2022-07-28 18:51:59 - train: epoch 0021, iter [02500, 05004], lr: 0.100000, loss: 3.4416, stu_CELoss: 1.7664, DKDLoss: 1.6752, 
2022-07-28 18:52:33 - train: epoch 0021, iter [02600, 05004], lr: 0.100000, loss: 3.6757, stu_CELoss: 1.9816, DKDLoss: 1.6941, 
2022-07-28 18:53:08 - train: epoch 0021, iter [02700, 05004], lr: 0.100000, loss: 3.4839, stu_CELoss: 1.6468, DKDLoss: 1.8371, 
2022-07-28 18:53:42 - train: epoch 0021, iter [02800, 05004], lr: 0.100000, loss: 3.3417, stu_CELoss: 1.7659, DKDLoss: 1.5758, 
2022-07-28 18:54:16 - train: epoch 0021, iter [02900, 05004], lr: 0.100000, loss: 3.2435, stu_CELoss: 1.7815, DKDLoss: 1.4620, 
2022-07-28 18:54:51 - train: epoch 0021, iter [03000, 05004], lr: 0.100000, loss: 3.8531, stu_CELoss: 1.9834, DKDLoss: 1.8697, 
2022-07-28 18:55:25 - train: epoch 0021, iter [03100, 05004], lr: 0.100000, loss: 3.6846, stu_CELoss: 1.9406, DKDLoss: 1.7441, 
2022-07-28 18:55:59 - train: epoch 0021, iter [03200, 05004], lr: 0.100000, loss: 3.5017, stu_CELoss: 1.7301, DKDLoss: 1.7716, 
2022-07-28 18:56:34 - train: epoch 0021, iter [03300, 05004], lr: 0.100000, loss: 3.9394, stu_CELoss: 2.1465, DKDLoss: 1.7930, 
2022-07-28 18:57:08 - train: epoch 0021, iter [03400, 05004], lr: 0.100000, loss: 3.8537, stu_CELoss: 2.0819, DKDLoss: 1.7718, 
2022-07-28 18:57:42 - train: epoch 0021, iter [03500, 05004], lr: 0.100000, loss: 3.7480, stu_CELoss: 1.8764, DKDLoss: 1.8716, 
2022-07-28 18:58:16 - train: epoch 0021, iter [03600, 05004], lr: 0.100000, loss: 3.6219, stu_CELoss: 1.9016, DKDLoss: 1.7202, 
2022-07-28 18:58:51 - train: epoch 0021, iter [03700, 05004], lr: 0.100000, loss: 3.3353, stu_CELoss: 1.7423, DKDLoss: 1.5930, 
2022-07-28 18:59:26 - train: epoch 0021, iter [03800, 05004], lr: 0.100000, loss: 3.2914, stu_CELoss: 1.7026, DKDLoss: 1.5888, 
2022-07-28 19:00:00 - train: epoch 0021, iter [03900, 05004], lr: 0.100000, loss: 3.2627, stu_CELoss: 1.6487, DKDLoss: 1.6141, 
2022-07-28 19:00:34 - train: epoch 0021, iter [04000, 05004], lr: 0.100000, loss: 3.8613, stu_CELoss: 2.0824, DKDLoss: 1.7789, 
2022-07-28 19:01:09 - train: epoch 0021, iter [04100, 05004], lr: 0.100000, loss: 3.5280, stu_CELoss: 1.7709, DKDLoss: 1.7571, 
2022-07-28 19:01:43 - train: epoch 0021, iter [04200, 05004], lr: 0.100000, loss: 3.4355, stu_CELoss: 1.7961, DKDLoss: 1.6394, 
2022-07-28 19:02:18 - train: epoch 0021, iter [04300, 05004], lr: 0.100000, loss: 3.6692, stu_CELoss: 1.9699, DKDLoss: 1.6993, 
2022-07-28 19:02:52 - train: epoch 0021, iter [04400, 05004], lr: 0.100000, loss: 3.6212, stu_CELoss: 1.8752, DKDLoss: 1.7460, 
2022-07-28 19:03:26 - train: epoch 0021, iter [04500, 05004], lr: 0.100000, loss: 3.4926, stu_CELoss: 1.8756, DKDLoss: 1.6170, 
2022-07-28 19:04:01 - train: epoch 0021, iter [04600, 05004], lr: 0.100000, loss: 3.7557, stu_CELoss: 1.9520, DKDLoss: 1.8037, 
2022-07-28 19:04:35 - train: epoch 0021, iter [04700, 05004], lr: 0.100000, loss: 3.5109, stu_CELoss: 1.9435, DKDLoss: 1.5674, 
2022-07-28 19:05:10 - train: epoch 0021, iter [04800, 05004], lr: 0.100000, loss: 3.6168, stu_CELoss: 1.8987, DKDLoss: 1.7181, 
2022-07-28 19:05:44 - train: epoch 0021, iter [04900, 05004], lr: 0.100000, loss: 3.3483, stu_CELoss: 1.6448, DKDLoss: 1.7036, 
2022-07-28 19:06:17 - train: epoch 0021, iter [05000, 05004], lr: 0.100000, loss: 3.3818, stu_CELoss: 1.7320, DKDLoss: 1.6498, 
2022-07-28 19:06:19 - train: epoch 021, train_loss: 3.5355
2022-07-28 19:08:52 - eval: epoch: 021, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 59.022%, stu_acc5: 82.982%, stu_test_loss: 1.7037
2022-07-28 19:08:52 - until epoch: 021, tea_best_acc1: 78.068%, stu_best_acc1: 59.022%
2022-07-28 19:08:52 - epoch 022 lr: 0.100000
2022-07-28 19:09:32 - train: epoch 0022, iter [00100, 05004], lr: 0.100000, loss: 2.9724, stu_CELoss: 1.4642, DKDLoss: 1.5082, 
2022-07-28 19:10:06 - train: epoch 0022, iter [00200, 05004], lr: 0.100000, loss: 3.3178, stu_CELoss: 1.7900, DKDLoss: 1.5278, 
2022-07-28 19:10:40 - train: epoch 0022, iter [00300, 05004], lr: 0.100000, loss: 3.2989, stu_CELoss: 1.7226, DKDLoss: 1.5763, 
2022-07-28 19:11:13 - train: epoch 0022, iter [00400, 05004], lr: 0.100000, loss: 3.3792, stu_CELoss: 1.7023, DKDLoss: 1.6768, 
2022-07-28 19:11:47 - train: epoch 0022, iter [00500, 05004], lr: 0.100000, loss: 3.4174, stu_CELoss: 1.7758, DKDLoss: 1.6417, 
2022-07-28 19:12:21 - train: epoch 0022, iter [00600, 05004], lr: 0.100000, loss: 3.5088, stu_CELoss: 1.9217, DKDLoss: 1.5871, 
2022-07-28 19:12:55 - train: epoch 0022, iter [00700, 05004], lr: 0.100000, loss: 3.8599, stu_CELoss: 2.0247, DKDLoss: 1.8352, 
2022-07-28 19:13:29 - train: epoch 0022, iter [00800, 05004], lr: 0.100000, loss: 3.7208, stu_CELoss: 2.0068, DKDLoss: 1.7140, 
2022-07-28 19:14:03 - train: epoch 0022, iter [00900, 05004], lr: 0.100000, loss: 3.6987, stu_CELoss: 1.9320, DKDLoss: 1.7668, 
2022-07-28 19:14:38 - train: epoch 0022, iter [01000, 05004], lr: 0.100000, loss: 3.7074, stu_CELoss: 1.9745, DKDLoss: 1.7329, 
2022-07-28 19:15:12 - train: epoch 0022, iter [01100, 05004], lr: 0.100000, loss: 3.1555, stu_CELoss: 1.6531, DKDLoss: 1.5023, 
2022-07-28 19:15:47 - train: epoch 0022, iter [01200, 05004], lr: 0.100000, loss: 3.0367, stu_CELoss: 1.4611, DKDLoss: 1.5757, 
2022-07-28 19:16:21 - train: epoch 0022, iter [01300, 05004], lr: 0.100000, loss: 3.7992, stu_CELoss: 1.9813, DKDLoss: 1.8179, 
2022-07-28 19:16:55 - train: epoch 0022, iter [01400, 05004], lr: 0.100000, loss: 3.3737, stu_CELoss: 1.6688, DKDLoss: 1.7050, 
2022-07-28 19:17:29 - train: epoch 0022, iter [01500, 05004], lr: 0.100000, loss: 3.6251, stu_CELoss: 1.9225, DKDLoss: 1.7026, 
2022-07-28 19:18:03 - train: epoch 0022, iter [01600, 05004], lr: 0.100000, loss: 3.2469, stu_CELoss: 1.6470, DKDLoss: 1.5998, 
2022-07-28 19:18:37 - train: epoch 0022, iter [01700, 05004], lr: 0.100000, loss: 3.5481, stu_CELoss: 1.9389, DKDLoss: 1.6092, 
2022-07-28 19:19:12 - train: epoch 0022, iter [01800, 05004], lr: 0.100000, loss: 3.6565, stu_CELoss: 1.8905, DKDLoss: 1.7660, 
2022-07-28 19:19:45 - train: epoch 0022, iter [01900, 05004], lr: 0.100000, loss: 3.6583, stu_CELoss: 1.8672, DKDLoss: 1.7911, 
2022-07-28 19:20:20 - train: epoch 0022, iter [02000, 05004], lr: 0.100000, loss: 3.3653, stu_CELoss: 1.7017, DKDLoss: 1.6635, 
2022-07-28 19:20:54 - train: epoch 0022, iter [02100, 05004], lr: 0.100000, loss: 3.3091, stu_CELoss: 1.7778, DKDLoss: 1.5313, 
2022-07-28 19:21:29 - train: epoch 0022, iter [02200, 05004], lr: 0.100000, loss: 3.3314, stu_CELoss: 1.6800, DKDLoss: 1.6514, 
2022-07-28 19:22:03 - train: epoch 0022, iter [02300, 05004], lr: 0.100000, loss: 3.6459, stu_CELoss: 1.8856, DKDLoss: 1.7603, 
2022-07-28 19:22:37 - train: epoch 0022, iter [02400, 05004], lr: 0.100000, loss: 3.7739, stu_CELoss: 1.9543, DKDLoss: 1.8196, 
2022-07-28 19:23:12 - train: epoch 0022, iter [02500, 05004], lr: 0.100000, loss: 3.3570, stu_CELoss: 1.7786, DKDLoss: 1.5784, 
2022-07-28 19:23:46 - train: epoch 0022, iter [02600, 05004], lr: 0.100000, loss: 3.3449, stu_CELoss: 1.7577, DKDLoss: 1.5873, 
2022-07-28 19:24:20 - train: epoch 0022, iter [02700, 05004], lr: 0.100000, loss: 3.3128, stu_CELoss: 1.7648, DKDLoss: 1.5479, 
2022-07-28 19:24:54 - train: epoch 0022, iter [02800, 05004], lr: 0.100000, loss: 3.8277, stu_CELoss: 1.9452, DKDLoss: 1.8825, 
2022-07-28 19:25:28 - train: epoch 0022, iter [02900, 05004], lr: 0.100000, loss: 3.5394, stu_CELoss: 1.7076, DKDLoss: 1.8317, 
2022-07-28 19:26:03 - train: epoch 0022, iter [03000, 05004], lr: 0.100000, loss: 3.6553, stu_CELoss: 1.8739, DKDLoss: 1.7813, 
2022-07-28 19:26:37 - train: epoch 0022, iter [03100, 05004], lr: 0.100000, loss: 3.6111, stu_CELoss: 1.8944, DKDLoss: 1.7167, 
2022-07-28 19:27:11 - train: epoch 0022, iter [03200, 05004], lr: 0.100000, loss: 3.5462, stu_CELoss: 1.8551, DKDLoss: 1.6911, 
2022-07-28 19:27:46 - train: epoch 0022, iter [03300, 05004], lr: 0.100000, loss: 3.6002, stu_CELoss: 1.8270, DKDLoss: 1.7732, 
2022-07-28 19:28:20 - train: epoch 0022, iter [03400, 05004], lr: 0.100000, loss: 3.4166, stu_CELoss: 1.7196, DKDLoss: 1.6970, 
2022-07-28 19:28:54 - train: epoch 0022, iter [03500, 05004], lr: 0.100000, loss: 3.5967, stu_CELoss: 1.8990, DKDLoss: 1.6977, 
2022-07-28 19:29:29 - train: epoch 0022, iter [03600, 05004], lr: 0.100000, loss: 3.6621, stu_CELoss: 1.8731, DKDLoss: 1.7890, 
2022-07-28 19:30:03 - train: epoch 0022, iter [03700, 05004], lr: 0.100000, loss: 3.7055, stu_CELoss: 1.8718, DKDLoss: 1.8337, 
2022-07-28 19:30:37 - train: epoch 0022, iter [03800, 05004], lr: 0.100000, loss: 3.7654, stu_CELoss: 1.9481, DKDLoss: 1.8174, 
2022-07-28 19:31:12 - train: epoch 0022, iter [03900, 05004], lr: 0.100000, loss: 3.5956, stu_CELoss: 1.8058, DKDLoss: 1.7898, 
2022-07-28 19:31:46 - train: epoch 0022, iter [04000, 05004], lr: 0.100000, loss: 3.5114, stu_CELoss: 1.9369, DKDLoss: 1.5745, 
2022-07-28 19:32:20 - train: epoch 0022, iter [04100, 05004], lr: 0.100000, loss: 3.7487, stu_CELoss: 1.9272, DKDLoss: 1.8215, 
2022-07-28 19:32:55 - train: epoch 0022, iter [04200, 05004], lr: 0.100000, loss: 3.5004, stu_CELoss: 1.8409, DKDLoss: 1.6595, 
2022-07-28 19:33:29 - train: epoch 0022, iter [04300, 05004], lr: 0.100000, loss: 3.5192, stu_CELoss: 1.8047, DKDLoss: 1.7144, 
2022-07-28 19:34:03 - train: epoch 0022, iter [04400, 05004], lr: 0.100000, loss: 3.4589, stu_CELoss: 1.7374, DKDLoss: 1.7215, 
2022-07-28 19:34:37 - train: epoch 0022, iter [04500, 05004], lr: 0.100000, loss: 3.5027, stu_CELoss: 1.8623, DKDLoss: 1.6404, 
2022-07-28 19:35:11 - train: epoch 0022, iter [04600, 05004], lr: 0.100000, loss: 3.6730, stu_CELoss: 2.0171, DKDLoss: 1.6559, 
2022-07-28 19:35:46 - train: epoch 0022, iter [04700, 05004], lr: 0.100000, loss: 3.5026, stu_CELoss: 1.8905, DKDLoss: 1.6121, 
2022-07-28 19:36:20 - train: epoch 0022, iter [04800, 05004], lr: 0.100000, loss: 3.2435, stu_CELoss: 1.5978, DKDLoss: 1.6456, 
2022-07-28 19:36:54 - train: epoch 0022, iter [04900, 05004], lr: 0.100000, loss: 3.5788, stu_CELoss: 1.8998, DKDLoss: 1.6790, 
2022-07-28 19:37:28 - train: epoch 0022, iter [05000, 05004], lr: 0.100000, loss: 3.3413, stu_CELoss: 1.7335, DKDLoss: 1.6079, 
2022-07-28 19:37:29 - train: epoch 022, train_loss: 3.5190
2022-07-28 19:40:04 - eval: epoch: 022, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 59.732%, stu_acc5: 83.554%, stu_test_loss: 1.6612
2022-07-28 19:40:04 - until epoch: 022, tea_best_acc1: 78.068%, stu_best_acc1: 59.732%
2022-07-28 19:40:04 - epoch 023 lr: 0.100000
2022-07-28 19:40:45 - train: epoch 0023, iter [00100, 05004], lr: 0.100000, loss: 3.6267, stu_CELoss: 1.8801, DKDLoss: 1.7466, 
2022-07-28 19:41:18 - train: epoch 0023, iter [00200, 05004], lr: 0.100000, loss: 3.0549, stu_CELoss: 1.6357, DKDLoss: 1.4193, 
2022-07-28 19:41:52 - train: epoch 0023, iter [00300, 05004], lr: 0.100000, loss: 3.6040, stu_CELoss: 1.8844, DKDLoss: 1.7197, 
2022-07-28 19:42:26 - train: epoch 0023, iter [00400, 05004], lr: 0.100000, loss: 3.3513, stu_CELoss: 1.7365, DKDLoss: 1.6148, 
2022-07-28 19:43:00 - train: epoch 0023, iter [00500, 05004], lr: 0.100000, loss: 3.5427, stu_CELoss: 1.8687, DKDLoss: 1.6741, 
2022-07-28 19:43:34 - train: epoch 0023, iter [00600, 05004], lr: 0.100000, loss: 3.6289, stu_CELoss: 1.8185, DKDLoss: 1.8104, 
2022-07-28 19:44:08 - train: epoch 0023, iter [00700, 05004], lr: 0.100000, loss: 3.3027, stu_CELoss: 1.7415, DKDLoss: 1.5612, 
2022-07-28 19:44:42 - train: epoch 0023, iter [00800, 05004], lr: 0.100000, loss: 3.3902, stu_CELoss: 1.7601, DKDLoss: 1.6302, 
2022-07-28 19:45:15 - train: epoch 0023, iter [00900, 05004], lr: 0.100000, loss: 3.5263, stu_CELoss: 1.8965, DKDLoss: 1.6298, 
2022-07-28 19:45:49 - train: epoch 0023, iter [01000, 05004], lr: 0.100000, loss: 3.0622, stu_CELoss: 1.5389, DKDLoss: 1.5233, 
2022-07-28 19:46:23 - train: epoch 0023, iter [01100, 05004], lr: 0.100000, loss: 3.4333, stu_CELoss: 1.7973, DKDLoss: 1.6359, 
2022-07-28 19:46:57 - train: epoch 0023, iter [01200, 05004], lr: 0.100000, loss: 3.2928, stu_CELoss: 1.7096, DKDLoss: 1.5832, 
2022-07-28 19:47:31 - train: epoch 0023, iter [01300, 05004], lr: 0.100000, loss: 3.1173, stu_CELoss: 1.5848, DKDLoss: 1.5325, 
2022-07-28 19:48:06 - train: epoch 0023, iter [01400, 05004], lr: 0.100000, loss: 3.3616, stu_CELoss: 1.7518, DKDLoss: 1.6098, 
2022-07-28 19:48:40 - train: epoch 0023, iter [01500, 05004], lr: 0.100000, loss: 3.2724, stu_CELoss: 1.6768, DKDLoss: 1.5956, 
2022-07-28 19:49:14 - train: epoch 0023, iter [01600, 05004], lr: 0.100000, loss: 3.4803, stu_CELoss: 1.8450, DKDLoss: 1.6353, 
2022-07-28 19:49:48 - train: epoch 0023, iter [01700, 05004], lr: 0.100000, loss: 3.4823, stu_CELoss: 1.7346, DKDLoss: 1.7477, 
2022-07-28 19:50:21 - train: epoch 0023, iter [01800, 05004], lr: 0.100000, loss: 3.5640, stu_CELoss: 1.9682, DKDLoss: 1.5958, 
2022-07-28 19:50:55 - train: epoch 0023, iter [01900, 05004], lr: 0.100000, loss: 3.6581, stu_CELoss: 2.0283, DKDLoss: 1.6298, 
2022-07-28 19:51:29 - train: epoch 0023, iter [02000, 05004], lr: 0.100000, loss: 3.2201, stu_CELoss: 1.6439, DKDLoss: 1.5762, 
2022-07-28 19:52:03 - train: epoch 0023, iter [02100, 05004], lr: 0.100000, loss: 3.3627, stu_CELoss: 1.7300, DKDLoss: 1.6327, 
2022-07-28 19:52:38 - train: epoch 0023, iter [02200, 05004], lr: 0.100000, loss: 3.1462, stu_CELoss: 1.6513, DKDLoss: 1.4949, 
2022-07-28 19:53:12 - train: epoch 0023, iter [02300, 05004], lr: 0.100000, loss: 3.3722, stu_CELoss: 1.7477, DKDLoss: 1.6246, 
2022-07-28 19:53:46 - train: epoch 0023, iter [02400, 05004], lr: 0.100000, loss: 3.5197, stu_CELoss: 1.7764, DKDLoss: 1.7433, 
2022-07-28 19:54:20 - train: epoch 0023, iter [02500, 05004], lr: 0.100000, loss: 3.5291, stu_CELoss: 1.8299, DKDLoss: 1.6993, 
2022-07-28 19:54:54 - train: epoch 0023, iter [02600, 05004], lr: 0.100000, loss: 3.6461, stu_CELoss: 1.8915, DKDLoss: 1.7545, 
2022-07-28 19:55:28 - train: epoch 0023, iter [02700, 05004], lr: 0.100000, loss: 3.8697, stu_CELoss: 2.0557, DKDLoss: 1.8140, 
2022-07-28 19:56:02 - train: epoch 0023, iter [02800, 05004], lr: 0.100000, loss: 3.8167, stu_CELoss: 1.9907, DKDLoss: 1.8260, 
2022-07-28 19:56:36 - train: epoch 0023, iter [02900, 05004], lr: 0.100000, loss: 3.6878, stu_CELoss: 1.8264, DKDLoss: 1.8615, 
2022-07-28 19:57:10 - train: epoch 0023, iter [03000, 05004], lr: 0.100000, loss: 3.4880, stu_CELoss: 1.8620, DKDLoss: 1.6260, 
2022-07-28 19:57:44 - train: epoch 0023, iter [03100, 05004], lr: 0.100000, loss: 3.8909, stu_CELoss: 2.0376, DKDLoss: 1.8533, 
2022-07-28 19:58:18 - train: epoch 0023, iter [03200, 05004], lr: 0.100000, loss: 3.5827, stu_CELoss: 1.9551, DKDLoss: 1.6276, 
2022-07-28 19:58:52 - train: epoch 0023, iter [03300, 05004], lr: 0.100000, loss: 3.3358, stu_CELoss: 1.7514, DKDLoss: 1.5844, 
2022-07-28 19:59:26 - train: epoch 0023, iter [03400, 05004], lr: 0.100000, loss: 3.6400, stu_CELoss: 1.8773, DKDLoss: 1.7627, 
2022-07-28 19:59:59 - train: epoch 0023, iter [03500, 05004], lr: 0.100000, loss: 3.4307, stu_CELoss: 1.7975, DKDLoss: 1.6333, 
2022-07-28 20:00:33 - train: epoch 0023, iter [03600, 05004], lr: 0.100000, loss: 3.3998, stu_CELoss: 1.7777, DKDLoss: 1.6221, 
2022-07-28 20:01:07 - train: epoch 0023, iter [03700, 05004], lr: 0.100000, loss: 3.5000, stu_CELoss: 1.7829, DKDLoss: 1.7171, 
2022-07-28 20:01:40 - train: epoch 0023, iter [03800, 05004], lr: 0.100000, loss: 3.7369, stu_CELoss: 1.9983, DKDLoss: 1.7386, 
2022-07-28 20:02:14 - train: epoch 0023, iter [03900, 05004], lr: 0.100000, loss: 3.4367, stu_CELoss: 1.8445, DKDLoss: 1.5922, 
2022-07-28 20:02:48 - train: epoch 0023, iter [04000, 05004], lr: 0.100000, loss: 3.3342, stu_CELoss: 1.8018, DKDLoss: 1.5323, 
2022-07-28 20:03:22 - train: epoch 0023, iter [04100, 05004], lr: 0.100000, loss: 3.3234, stu_CELoss: 1.7012, DKDLoss: 1.6221, 
2022-07-28 20:03:56 - train: epoch 0023, iter [04200, 05004], lr: 0.100000, loss: 3.1138, stu_CELoss: 1.5467, DKDLoss: 1.5671, 
2022-07-28 20:04:29 - train: epoch 0023, iter [04300, 05004], lr: 0.100000, loss: 3.3369, stu_CELoss: 1.7593, DKDLoss: 1.5776, 
2022-07-28 20:05:03 - train: epoch 0023, iter [04400, 05004], lr: 0.100000, loss: 3.1867, stu_CELoss: 1.6213, DKDLoss: 1.5654, 
2022-07-28 20:05:37 - train: epoch 0023, iter [04500, 05004], lr: 0.100000, loss: 3.4229, stu_CELoss: 1.7980, DKDLoss: 1.6249, 
2022-07-28 20:06:11 - train: epoch 0023, iter [04600, 05004], lr: 0.100000, loss: 3.5910, stu_CELoss: 1.8973, DKDLoss: 1.6937, 
2022-07-28 20:06:44 - train: epoch 0023, iter [04700, 05004], lr: 0.100000, loss: 3.3673, stu_CELoss: 1.7396, DKDLoss: 1.6276, 
2022-07-28 20:07:17 - train: epoch 0023, iter [04800, 05004], lr: 0.100000, loss: 3.6403, stu_CELoss: 1.9066, DKDLoss: 1.7337, 
2022-07-28 20:07:50 - train: epoch 0023, iter [04900, 05004], lr: 0.100000, loss: 3.2756, stu_CELoss: 1.6976, DKDLoss: 1.5780, 
2022-07-28 20:08:23 - train: epoch 0023, iter [05000, 05004], lr: 0.100000, loss: 3.8600, stu_CELoss: 1.9957, DKDLoss: 1.8643, 
2022-07-28 20:08:25 - train: epoch 023, train_loss: 3.4958
2022-07-28 20:10:57 - eval: epoch: 023, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 60.012%, stu_acc5: 83.518%, stu_test_loss: 1.6691
2022-07-28 20:10:58 - until epoch: 023, tea_best_acc1: 78.068%, stu_best_acc1: 60.012%
2022-07-28 20:10:58 - epoch 024 lr: 0.100000
2022-07-28 20:11:38 - train: epoch 0024, iter [00100, 05004], lr: 0.100000, loss: 3.6759, stu_CELoss: 1.9697, DKDLoss: 1.7062, 
2022-07-28 20:12:12 - train: epoch 0024, iter [00200, 05004], lr: 0.100000, loss: 3.2982, stu_CELoss: 1.7195, DKDLoss: 1.5786, 
2022-07-28 20:12:45 - train: epoch 0024, iter [00300, 05004], lr: 0.100000, loss: 3.4480, stu_CELoss: 1.8902, DKDLoss: 1.5578, 
2022-07-28 20:13:19 - train: epoch 0024, iter [00400, 05004], lr: 0.100000, loss: 3.7140, stu_CELoss: 1.9094, DKDLoss: 1.8046, 
2022-07-28 20:13:53 - train: epoch 0024, iter [00500, 05004], lr: 0.100000, loss: 3.6592, stu_CELoss: 1.8947, DKDLoss: 1.7645, 
2022-07-28 20:14:27 - train: epoch 0024, iter [00600, 05004], lr: 0.100000, loss: 3.6650, stu_CELoss: 1.8591, DKDLoss: 1.8059, 
2022-07-28 20:15:00 - train: epoch 0024, iter [00700, 05004], lr: 0.100000, loss: 3.0751, stu_CELoss: 1.5460, DKDLoss: 1.5291, 
2022-07-28 20:15:34 - train: epoch 0024, iter [00800, 05004], lr: 0.100000, loss: 3.2677, stu_CELoss: 1.5978, DKDLoss: 1.6698, 
2022-07-28 20:16:08 - train: epoch 0024, iter [00900, 05004], lr: 0.100000, loss: 3.4210, stu_CELoss: 1.7340, DKDLoss: 1.6870, 
2022-07-28 20:16:41 - train: epoch 0024, iter [01000, 05004], lr: 0.100000, loss: 3.2436, stu_CELoss: 1.7420, DKDLoss: 1.5016, 
2022-07-28 20:17:15 - train: epoch 0024, iter [01100, 05004], lr: 0.100000, loss: 3.2240, stu_CELoss: 1.6541, DKDLoss: 1.5699, 
2022-07-28 20:17:49 - train: epoch 0024, iter [01200, 05004], lr: 0.100000, loss: 3.1692, stu_CELoss: 1.6560, DKDLoss: 1.5132, 
2022-07-28 20:18:23 - train: epoch 0024, iter [01300, 05004], lr: 0.100000, loss: 3.6690, stu_CELoss: 1.9975, DKDLoss: 1.6715, 
2022-07-28 20:18:56 - train: epoch 0024, iter [01400, 05004], lr: 0.100000, loss: 2.9108, stu_CELoss: 1.5312, DKDLoss: 1.3797, 
2022-07-28 20:19:30 - train: epoch 0024, iter [01500, 05004], lr: 0.100000, loss: 3.7536, stu_CELoss: 1.9653, DKDLoss: 1.7883, 
2022-07-28 20:20:03 - train: epoch 0024, iter [01600, 05004], lr: 0.100000, loss: 3.2659, stu_CELoss: 1.6862, DKDLoss: 1.5797, 
2022-07-28 20:20:37 - train: epoch 0024, iter [01700, 05004], lr: 0.100000, loss: 3.4200, stu_CELoss: 1.7606, DKDLoss: 1.6595, 
2022-07-28 20:21:11 - train: epoch 0024, iter [01800, 05004], lr: 0.100000, loss: 3.6807, stu_CELoss: 1.9161, DKDLoss: 1.7646, 
2022-07-28 20:21:45 - train: epoch 0024, iter [01900, 05004], lr: 0.100000, loss: 3.4368, stu_CELoss: 1.7703, DKDLoss: 1.6665, 
2022-07-28 20:22:19 - train: epoch 0024, iter [02000, 05004], lr: 0.100000, loss: 3.6392, stu_CELoss: 1.8456, DKDLoss: 1.7936, 
2022-07-28 20:22:52 - train: epoch 0024, iter [02100, 05004], lr: 0.100000, loss: 3.1524, stu_CELoss: 1.7503, DKDLoss: 1.4021, 
2022-07-28 20:23:26 - train: epoch 0024, iter [02200, 05004], lr: 0.100000, loss: 3.1211, stu_CELoss: 1.7176, DKDLoss: 1.4034, 
2022-07-28 20:24:00 - train: epoch 0024, iter [02300, 05004], lr: 0.100000, loss: 3.4353, stu_CELoss: 1.7447, DKDLoss: 1.6906, 
2022-07-28 20:24:34 - train: epoch 0024, iter [02400, 05004], lr: 0.100000, loss: 3.6378, stu_CELoss: 1.9950, DKDLoss: 1.6428, 
2022-07-28 20:25:08 - train: epoch 0024, iter [02500, 05004], lr: 0.100000, loss: 3.4700, stu_CELoss: 1.8330, DKDLoss: 1.6370, 
2022-07-28 20:25:42 - train: epoch 0024, iter [02600, 05004], lr: 0.100000, loss: 3.7523, stu_CELoss: 2.1056, DKDLoss: 1.6467, 
2022-07-28 20:26:15 - train: epoch 0024, iter [02700, 05004], lr: 0.100000, loss: 3.6131, stu_CELoss: 1.9629, DKDLoss: 1.6501, 
2022-07-28 20:26:49 - train: epoch 0024, iter [02800, 05004], lr: 0.100000, loss: 3.6953, stu_CELoss: 2.0176, DKDLoss: 1.6776, 
2022-07-28 20:27:23 - train: epoch 0024, iter [02900, 05004], lr: 0.100000, loss: 3.3904, stu_CELoss: 1.6683, DKDLoss: 1.7221, 
2022-07-28 20:27:57 - train: epoch 0024, iter [03000, 05004], lr: 0.100000, loss: 3.2037, stu_CELoss: 1.6818, DKDLoss: 1.5219, 
2022-07-28 20:28:31 - train: epoch 0024, iter [03100, 05004], lr: 0.100000, loss: 3.1148, stu_CELoss: 1.6036, DKDLoss: 1.5112, 
2022-07-28 20:29:04 - train: epoch 0024, iter [03200, 05004], lr: 0.100000, loss: 3.8308, stu_CELoss: 1.9359, DKDLoss: 1.8949, 
2022-07-28 20:29:38 - train: epoch 0024, iter [03300, 05004], lr: 0.100000, loss: 3.3561, stu_CELoss: 1.6565, DKDLoss: 1.6996, 
2022-07-28 20:30:12 - train: epoch 0024, iter [03400, 05004], lr: 0.100000, loss: 3.2860, stu_CELoss: 1.6686, DKDLoss: 1.6173, 
2022-07-28 20:30:46 - train: epoch 0024, iter [03500, 05004], lr: 0.100000, loss: 3.4067, stu_CELoss: 1.8279, DKDLoss: 1.5788, 
2022-07-28 20:31:19 - train: epoch 0024, iter [03600, 05004], lr: 0.100000, loss: 3.4892, stu_CELoss: 1.8262, DKDLoss: 1.6631, 
2022-07-28 20:31:53 - train: epoch 0024, iter [03700, 05004], lr: 0.100000, loss: 3.3408, stu_CELoss: 1.7724, DKDLoss: 1.5684, 
2022-07-28 20:32:27 - train: epoch 0024, iter [03800, 05004], lr: 0.100000, loss: 3.5754, stu_CELoss: 1.9354, DKDLoss: 1.6400, 
2022-07-28 20:33:01 - train: epoch 0024, iter [03900, 05004], lr: 0.100000, loss: 3.2156, stu_CELoss: 1.6454, DKDLoss: 1.5702, 
2022-07-28 20:33:35 - train: epoch 0024, iter [04000, 05004], lr: 0.100000, loss: 3.5471, stu_CELoss: 1.8668, DKDLoss: 1.6803, 
2022-07-28 20:34:09 - train: epoch 0024, iter [04100, 05004], lr: 0.100000, loss: 3.4238, stu_CELoss: 1.7583, DKDLoss: 1.6655, 
2022-07-28 20:34:43 - train: epoch 0024, iter [04200, 05004], lr: 0.100000, loss: 3.3499, stu_CELoss: 1.7857, DKDLoss: 1.5642, 
2022-07-28 20:35:17 - train: epoch 0024, iter [04300, 05004], lr: 0.100000, loss: 3.3130, stu_CELoss: 1.7155, DKDLoss: 1.5975, 
2022-07-28 20:35:51 - train: epoch 0024, iter [04400, 05004], lr: 0.100000, loss: 3.6910, stu_CELoss: 1.9521, DKDLoss: 1.7390, 
2022-07-28 20:36:25 - train: epoch 0024, iter [04500, 05004], lr: 0.100000, loss: 3.2005, stu_CELoss: 1.6037, DKDLoss: 1.5968, 
2022-07-28 20:36:58 - train: epoch 0024, iter [04600, 05004], lr: 0.100000, loss: 3.7591, stu_CELoss: 2.0461, DKDLoss: 1.7131, 
2022-07-28 20:37:33 - train: epoch 0024, iter [04700, 05004], lr: 0.100000, loss: 3.4970, stu_CELoss: 1.7893, DKDLoss: 1.7077, 
2022-07-28 20:38:06 - train: epoch 0024, iter [04800, 05004], lr: 0.100000, loss: 3.2098, stu_CELoss: 1.5818, DKDLoss: 1.6279, 
2022-07-28 20:38:41 - train: epoch 0024, iter [04900, 05004], lr: 0.100000, loss: 3.4895, stu_CELoss: 1.9337, DKDLoss: 1.5558, 
2022-07-28 20:39:14 - train: epoch 0024, iter [05000, 05004], lr: 0.100000, loss: 3.6788, stu_CELoss: 1.9480, DKDLoss: 1.7309, 
2022-07-28 20:39:15 - train: epoch 024, train_loss: 3.4792
2022-07-28 20:41:51 - eval: epoch: 024, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 56.002%, stu_acc5: 80.482%, stu_test_loss: 1.8634
2022-07-28 20:41:51 - until epoch: 024, tea_best_acc1: 78.068%, stu_best_acc1: 60.012%
2022-07-28 20:41:51 - epoch 025 lr: 0.100000
2022-07-28 20:42:32 - train: epoch 0025, iter [00100, 05004], lr: 0.100000, loss: 3.3554, stu_CELoss: 1.7445, DKDLoss: 1.6109, 
2022-07-28 20:43:06 - train: epoch 0025, iter [00200, 05004], lr: 0.100000, loss: 3.1228, stu_CELoss: 1.5944, DKDLoss: 1.5284, 
2022-07-28 20:43:40 - train: epoch 0025, iter [00300, 05004], lr: 0.100000, loss: 3.4335, stu_CELoss: 1.7109, DKDLoss: 1.7225, 
2022-07-28 20:44:15 - train: epoch 0025, iter [00400, 05004], lr: 0.100000, loss: 3.5974, stu_CELoss: 1.9478, DKDLoss: 1.6496, 
2022-07-28 20:44:49 - train: epoch 0025, iter [00500, 05004], lr: 0.100000, loss: 3.3538, stu_CELoss: 1.7856, DKDLoss: 1.5682, 
2022-07-28 20:45:24 - train: epoch 0025, iter [00600, 05004], lr: 0.100000, loss: 3.4113, stu_CELoss: 1.8173, DKDLoss: 1.5939, 
2022-07-28 20:45:58 - train: epoch 0025, iter [00700, 05004], lr: 0.100000, loss: 3.3984, stu_CELoss: 1.7432, DKDLoss: 1.6553, 
2022-07-28 20:46:33 - train: epoch 0025, iter [00800, 05004], lr: 0.100000, loss: 3.2010, stu_CELoss: 1.6802, DKDLoss: 1.5208, 
2022-07-28 20:47:07 - train: epoch 0025, iter [00900, 05004], lr: 0.100000, loss: 3.3723, stu_CELoss: 1.7694, DKDLoss: 1.6029, 
2022-07-28 20:47:42 - train: epoch 0025, iter [01000, 05004], lr: 0.100000, loss: 3.3750, stu_CELoss: 1.8245, DKDLoss: 1.5506, 
2022-07-28 20:48:17 - train: epoch 0025, iter [01100, 05004], lr: 0.100000, loss: 3.3906, stu_CELoss: 1.7679, DKDLoss: 1.6227, 
2022-07-28 20:48:52 - train: epoch 0025, iter [01200, 05004], lr: 0.100000, loss: 3.6960, stu_CELoss: 1.9433, DKDLoss: 1.7527, 
2022-07-28 20:49:26 - train: epoch 0025, iter [01300, 05004], lr: 0.100000, loss: 3.3500, stu_CELoss: 1.7693, DKDLoss: 1.5807, 
2022-07-28 20:50:01 - train: epoch 0025, iter [01400, 05004], lr: 0.100000, loss: 3.3324, stu_CELoss: 1.6100, DKDLoss: 1.7224, 
2022-07-28 20:50:35 - train: epoch 0025, iter [01500, 05004], lr: 0.100000, loss: 3.4793, stu_CELoss: 1.9459, DKDLoss: 1.5334, 
2022-07-28 20:51:10 - train: epoch 0025, iter [01600, 05004], lr: 0.100000, loss: 3.2338, stu_CELoss: 1.6721, DKDLoss: 1.5618, 
2022-07-28 20:51:44 - train: epoch 0025, iter [01700, 05004], lr: 0.100000, loss: 3.4172, stu_CELoss: 1.8418, DKDLoss: 1.5754, 
2022-07-28 20:52:19 - train: epoch 0025, iter [01800, 05004], lr: 0.100000, loss: 3.1404, stu_CELoss: 1.5655, DKDLoss: 1.5749, 
2022-07-28 20:52:53 - train: epoch 0025, iter [01900, 05004], lr: 0.100000, loss: 3.3897, stu_CELoss: 1.7452, DKDLoss: 1.6446, 
2022-07-28 20:53:28 - train: epoch 0025, iter [02000, 05004], lr: 0.100000, loss: 3.4437, stu_CELoss: 1.7344, DKDLoss: 1.7093, 
2022-07-28 20:54:02 - train: epoch 0025, iter [02100, 05004], lr: 0.100000, loss: 3.1736, stu_CELoss: 1.5461, DKDLoss: 1.6276, 
2022-07-28 20:54:37 - train: epoch 0025, iter [02200, 05004], lr: 0.100000, loss: 3.4487, stu_CELoss: 1.8984, DKDLoss: 1.5502, 
2022-07-28 20:55:12 - train: epoch 0025, iter [02300, 05004], lr: 0.100000, loss: 3.5963, stu_CELoss: 1.7998, DKDLoss: 1.7965, 
2022-07-28 20:55:46 - train: epoch 0025, iter [02400, 05004], lr: 0.100000, loss: 3.2449, stu_CELoss: 1.6458, DKDLoss: 1.5991, 
2022-07-28 20:56:21 - train: epoch 0025, iter [02500, 05004], lr: 0.100000, loss: 3.5337, stu_CELoss: 1.8426, DKDLoss: 1.6911, 
2022-07-28 20:56:55 - train: epoch 0025, iter [02600, 05004], lr: 0.100000, loss: 3.5349, stu_CELoss: 1.8702, DKDLoss: 1.6647, 
2022-07-28 20:57:30 - train: epoch 0025, iter [02700, 05004], lr: 0.100000, loss: 3.3978, stu_CELoss: 1.8950, DKDLoss: 1.5028, 
2022-07-28 20:58:04 - train: epoch 0025, iter [02800, 05004], lr: 0.100000, loss: 3.6260, stu_CELoss: 1.8974, DKDLoss: 1.7286, 
2022-07-28 20:58:38 - train: epoch 0025, iter [02900, 05004], lr: 0.100000, loss: 3.6025, stu_CELoss: 1.9969, DKDLoss: 1.6057, 
2022-07-28 20:59:12 - train: epoch 0025, iter [03000, 05004], lr: 0.100000, loss: 3.6503, stu_CELoss: 1.8221, DKDLoss: 1.8282, 
2022-07-28 20:59:46 - train: epoch 0025, iter [03100, 05004], lr: 0.100000, loss: 3.7635, stu_CELoss: 1.9762, DKDLoss: 1.7873, 
2022-07-28 21:00:20 - train: epoch 0025, iter [03200, 05004], lr: 0.100000, loss: 3.7033, stu_CELoss: 1.9942, DKDLoss: 1.7091, 
2022-07-28 21:00:54 - train: epoch 0025, iter [03300, 05004], lr: 0.100000, loss: 3.3915, stu_CELoss: 1.7578, DKDLoss: 1.6337, 
2022-07-28 21:01:28 - train: epoch 0025, iter [03400, 05004], lr: 0.100000, loss: 3.5632, stu_CELoss: 1.8255, DKDLoss: 1.7377, 
2022-07-28 21:02:01 - train: epoch 0025, iter [03500, 05004], lr: 0.100000, loss: 3.4502, stu_CELoss: 1.7920, DKDLoss: 1.6583, 
2022-07-28 21:02:35 - train: epoch 0025, iter [03600, 05004], lr: 0.100000, loss: 3.8714, stu_CELoss: 2.0303, DKDLoss: 1.8410, 
2022-07-28 21:03:09 - train: epoch 0025, iter [03700, 05004], lr: 0.100000, loss: 3.3999, stu_CELoss: 1.7690, DKDLoss: 1.6308, 
2022-07-28 21:03:43 - train: epoch 0025, iter [03800, 05004], lr: 0.100000, loss: 3.6481, stu_CELoss: 1.9213, DKDLoss: 1.7268, 
2022-07-28 21:04:16 - train: epoch 0025, iter [03900, 05004], lr: 0.100000, loss: 3.8117, stu_CELoss: 2.0699, DKDLoss: 1.7418, 
2022-07-28 21:04:51 - train: epoch 0025, iter [04000, 05004], lr: 0.100000, loss: 3.4239, stu_CELoss: 1.7303, DKDLoss: 1.6936, 
2022-07-28 21:05:25 - train: epoch 0025, iter [04100, 05004], lr: 0.100000, loss: 3.7175, stu_CELoss: 1.9835, DKDLoss: 1.7340, 
2022-07-28 21:05:59 - train: epoch 0025, iter [04200, 05004], lr: 0.100000, loss: 3.4518, stu_CELoss: 1.7732, DKDLoss: 1.6786, 
2022-07-28 21:06:33 - train: epoch 0025, iter [04300, 05004], lr: 0.100000, loss: 3.4926, stu_CELoss: 1.8002, DKDLoss: 1.6924, 
2022-07-28 21:07:07 - train: epoch 0025, iter [04400, 05004], lr: 0.100000, loss: 3.3332, stu_CELoss: 1.7772, DKDLoss: 1.5560, 
2022-07-28 21:07:41 - train: epoch 0025, iter [04500, 05004], lr: 0.100000, loss: 3.4167, stu_CELoss: 1.7962, DKDLoss: 1.6205, 
2022-07-28 21:08:15 - train: epoch 0025, iter [04600, 05004], lr: 0.100000, loss: 3.3027, stu_CELoss: 1.7596, DKDLoss: 1.5431, 
2022-07-28 21:08:49 - train: epoch 0025, iter [04700, 05004], lr: 0.100000, loss: 3.5109, stu_CELoss: 1.8444, DKDLoss: 1.6665, 
2022-07-28 21:09:24 - train: epoch 0025, iter [04800, 05004], lr: 0.100000, loss: 3.2114, stu_CELoss: 1.7031, DKDLoss: 1.5084, 
2022-07-28 21:09:57 - train: epoch 0025, iter [04900, 05004], lr: 0.100000, loss: 3.2724, stu_CELoss: 1.7994, DKDLoss: 1.4730, 
2022-07-28 21:10:31 - train: epoch 0025, iter [05000, 05004], lr: 0.100000, loss: 3.7144, stu_CELoss: 1.9770, DKDLoss: 1.7374, 
2022-07-28 21:10:32 - train: epoch 025, train_loss: 3.4656
2022-07-28 21:13:05 - eval: epoch: 025, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 60.328%, stu_acc5: 83.872%, stu_test_loss: 1.6405
2022-07-28 21:13:06 - until epoch: 025, tea_best_acc1: 78.068%, stu_best_acc1: 60.328%
2022-07-28 21:13:06 - epoch 026 lr: 0.100000
2022-07-28 21:13:46 - train: epoch 0026, iter [00100, 05004], lr: 0.100000, loss: 3.1994, stu_CELoss: 1.6364, DKDLoss: 1.5630, 
2022-07-28 21:14:20 - train: epoch 0026, iter [00200, 05004], lr: 0.100000, loss: 3.1431, stu_CELoss: 1.6300, DKDLoss: 1.5131, 
2022-07-28 21:14:54 - train: epoch 0026, iter [00300, 05004], lr: 0.100000, loss: 3.6888, stu_CELoss: 2.0270, DKDLoss: 1.6618, 
2022-07-28 21:15:28 - train: epoch 0026, iter [00400, 05004], lr: 0.100000, loss: 3.1856, stu_CELoss: 1.5990, DKDLoss: 1.5866, 
2022-07-28 21:16:02 - train: epoch 0026, iter [00500, 05004], lr: 0.100000, loss: 3.4370, stu_CELoss: 1.7980, DKDLoss: 1.6390, 
2022-07-28 21:16:36 - train: epoch 0026, iter [00600, 05004], lr: 0.100000, loss: 3.8616, stu_CELoss: 2.1231, DKDLoss: 1.7385, 
2022-07-28 21:17:10 - train: epoch 0026, iter [00700, 05004], lr: 0.100000, loss: 3.4866, stu_CELoss: 1.8663, DKDLoss: 1.6202, 
2022-07-28 21:17:45 - train: epoch 0026, iter [00800, 05004], lr: 0.100000, loss: 3.1873, stu_CELoss: 1.6071, DKDLoss: 1.5802, 
2022-07-28 21:18:19 - train: epoch 0026, iter [00900, 05004], lr: 0.100000, loss: 3.9161, stu_CELoss: 2.2634, DKDLoss: 1.6527, 
2022-07-28 21:18:53 - train: epoch 0026, iter [01000, 05004], lr: 0.100000, loss: 3.4088, stu_CELoss: 1.7561, DKDLoss: 1.6526, 
2022-07-28 21:19:27 - train: epoch 0026, iter [01100, 05004], lr: 0.100000, loss: 3.4000, stu_CELoss: 1.7232, DKDLoss: 1.6768, 
2022-07-28 21:20:01 - train: epoch 0026, iter [01200, 05004], lr: 0.100000, loss: 3.6940, stu_CELoss: 1.8841, DKDLoss: 1.8099, 
2022-07-28 21:20:36 - train: epoch 0026, iter [01300, 05004], lr: 0.100000, loss: 3.2723, stu_CELoss: 1.7582, DKDLoss: 1.5141, 
2022-07-28 21:21:10 - train: epoch 0026, iter [01400, 05004], lr: 0.100000, loss: 3.5955, stu_CELoss: 1.9193, DKDLoss: 1.6762, 
2022-07-28 21:21:44 - train: epoch 0026, iter [01500, 05004], lr: 0.100000, loss: 2.8824, stu_CELoss: 1.5092, DKDLoss: 1.3731, 
2022-07-28 21:22:18 - train: epoch 0026, iter [01600, 05004], lr: 0.100000, loss: 3.3933, stu_CELoss: 1.8478, DKDLoss: 1.5455, 
2022-07-28 21:22:52 - train: epoch 0026, iter [01700, 05004], lr: 0.100000, loss: 3.1298, stu_CELoss: 1.6668, DKDLoss: 1.4630, 
2022-07-28 21:23:26 - train: epoch 0026, iter [01800, 05004], lr: 0.100000, loss: 3.7502, stu_CELoss: 2.1235, DKDLoss: 1.6267, 
2022-07-28 21:24:00 - train: epoch 0026, iter [01900, 05004], lr: 0.100000, loss: 3.6842, stu_CELoss: 2.0101, DKDLoss: 1.6741, 
2022-07-28 21:24:34 - train: epoch 0026, iter [02000, 05004], lr: 0.100000, loss: 3.5356, stu_CELoss: 1.8216, DKDLoss: 1.7140, 
2022-07-28 21:25:09 - train: epoch 0026, iter [02100, 05004], lr: 0.100000, loss: 3.2354, stu_CELoss: 1.6379, DKDLoss: 1.5975, 
2022-07-28 21:25:43 - train: epoch 0026, iter [02200, 05004], lr: 0.100000, loss: 3.6698, stu_CELoss: 1.8902, DKDLoss: 1.7796, 
2022-07-28 21:26:17 - train: epoch 0026, iter [02300, 05004], lr: 0.100000, loss: 3.5093, stu_CELoss: 1.7963, DKDLoss: 1.7130, 
2022-07-28 21:26:51 - train: epoch 0026, iter [02400, 05004], lr: 0.100000, loss: 3.5719, stu_CELoss: 1.9079, DKDLoss: 1.6641, 
2022-07-28 21:27:25 - train: epoch 0026, iter [02500, 05004], lr: 0.100000, loss: 3.5509, stu_CELoss: 1.9108, DKDLoss: 1.6401, 
2022-07-28 21:27:59 - train: epoch 0026, iter [02600, 05004], lr: 0.100000, loss: 3.7926, stu_CELoss: 1.9645, DKDLoss: 1.8280, 
2022-07-28 21:28:33 - train: epoch 0026, iter [02700, 05004], lr: 0.100000, loss: 3.7561, stu_CELoss: 2.0777, DKDLoss: 1.6784, 
2022-07-28 21:29:07 - train: epoch 0026, iter [02800, 05004], lr: 0.100000, loss: 3.6198, stu_CELoss: 1.8943, DKDLoss: 1.7255, 
2022-07-28 21:29:41 - train: epoch 0026, iter [02900, 05004], lr: 0.100000, loss: 3.9259, stu_CELoss: 2.0042, DKDLoss: 1.9217, 
2022-07-28 21:30:15 - train: epoch 0026, iter [03000, 05004], lr: 0.100000, loss: 3.6899, stu_CELoss: 1.8902, DKDLoss: 1.7997, 
2022-07-28 21:30:49 - train: epoch 0026, iter [03100, 05004], lr: 0.100000, loss: 3.4739, stu_CELoss: 1.8854, DKDLoss: 1.5885, 
2022-07-28 21:31:24 - train: epoch 0026, iter [03200, 05004], lr: 0.100000, loss: 3.5304, stu_CELoss: 1.8876, DKDLoss: 1.6428, 
2022-07-28 21:31:58 - train: epoch 0026, iter [03300, 05004], lr: 0.100000, loss: 3.6885, stu_CELoss: 1.9320, DKDLoss: 1.7565, 
2022-07-28 21:32:32 - train: epoch 0026, iter [03400, 05004], lr: 0.100000, loss: 3.6535, stu_CELoss: 1.8226, DKDLoss: 1.8309, 
2022-07-28 21:33:06 - train: epoch 0026, iter [03500, 05004], lr: 0.100000, loss: 3.4575, stu_CELoss: 1.9049, DKDLoss: 1.5527, 
2022-07-28 21:33:41 - train: epoch 0026, iter [03600, 05004], lr: 0.100000, loss: 3.0957, stu_CELoss: 1.5705, DKDLoss: 1.5252, 
2022-07-28 21:34:15 - train: epoch 0026, iter [03700, 05004], lr: 0.100000, loss: 3.5715, stu_CELoss: 1.8441, DKDLoss: 1.7274, 
2022-07-28 21:34:49 - train: epoch 0026, iter [03800, 05004], lr: 0.100000, loss: 3.7638, stu_CELoss: 1.9790, DKDLoss: 1.7849, 
2022-07-28 21:35:24 - train: epoch 0026, iter [03900, 05004], lr: 0.100000, loss: 3.5505, stu_CELoss: 1.8696, DKDLoss: 1.6809, 
2022-07-28 21:35:58 - train: epoch 0026, iter [04000, 05004], lr: 0.100000, loss: 3.5458, stu_CELoss: 1.8675, DKDLoss: 1.6783, 
2022-07-28 21:36:32 - train: epoch 0026, iter [04100, 05004], lr: 0.100000, loss: 3.6085, stu_CELoss: 1.8679, DKDLoss: 1.7406, 
2022-07-28 21:37:06 - train: epoch 0026, iter [04200, 05004], lr: 0.100000, loss: 3.4827, stu_CELoss: 1.9174, DKDLoss: 1.5653, 
2022-07-28 21:37:41 - train: epoch 0026, iter [04300, 05004], lr: 0.100000, loss: 3.5931, stu_CELoss: 1.9135, DKDLoss: 1.6796, 
2022-07-28 21:38:15 - train: epoch 0026, iter [04400, 05004], lr: 0.100000, loss: 3.5397, stu_CELoss: 1.9508, DKDLoss: 1.5889, 
2022-07-28 21:38:50 - train: epoch 0026, iter [04500, 05004], lr: 0.100000, loss: 3.7948, stu_CELoss: 2.1366, DKDLoss: 1.6582, 
2022-07-28 21:39:24 - train: epoch 0026, iter [04600, 05004], lr: 0.100000, loss: 3.4783, stu_CELoss: 1.8600, DKDLoss: 1.6183, 
2022-07-28 21:39:58 - train: epoch 0026, iter [04700, 05004], lr: 0.100000, loss: 3.3351, stu_CELoss: 1.6856, DKDLoss: 1.6495, 
2022-07-28 21:40:33 - train: epoch 0026, iter [04800, 05004], lr: 0.100000, loss: 3.1277, stu_CELoss: 1.6442, DKDLoss: 1.4835, 
2022-07-28 21:41:07 - train: epoch 0026, iter [04900, 05004], lr: 0.100000, loss: 3.5238, stu_CELoss: 1.7858, DKDLoss: 1.7380, 
2022-07-28 21:41:40 - train: epoch 0026, iter [05000, 05004], lr: 0.100000, loss: 3.3450, stu_CELoss: 1.7846, DKDLoss: 1.5604, 
2022-07-28 21:41:42 - train: epoch 026, train_loss: 3.4539
2022-07-28 21:44:17 - eval: epoch: 026, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 58.466%, stu_acc5: 82.548%, stu_test_loss: 1.7312
2022-07-28 21:44:17 - until epoch: 026, tea_best_acc1: 78.068%, stu_best_acc1: 60.328%
2022-07-28 21:44:17 - epoch 027 lr: 0.100000
2022-07-28 21:44:57 - train: epoch 0027, iter [00100, 05004], lr: 0.100000, loss: 3.6197, stu_CELoss: 1.8373, DKDLoss: 1.7824, 
2022-07-28 21:45:31 - train: epoch 0027, iter [00200, 05004], lr: 0.100000, loss: 3.1660, stu_CELoss: 1.6844, DKDLoss: 1.4816, 
2022-07-28 21:46:05 - train: epoch 0027, iter [00300, 05004], lr: 0.100000, loss: 3.5109, stu_CELoss: 1.9082, DKDLoss: 1.6027, 
2022-07-28 21:46:40 - train: epoch 0027, iter [00400, 05004], lr: 0.100000, loss: 3.6537, stu_CELoss: 1.9200, DKDLoss: 1.7337, 
2022-07-28 21:47:13 - train: epoch 0027, iter [00500, 05004], lr: 0.100000, loss: 3.1932, stu_CELoss: 1.6387, DKDLoss: 1.5545, 
2022-07-28 21:47:47 - train: epoch 0027, iter [00600, 05004], lr: 0.100000, loss: 3.6316, stu_CELoss: 1.9365, DKDLoss: 1.6951, 
2022-07-28 21:48:21 - train: epoch 0027, iter [00700, 05004], lr: 0.100000, loss: 3.3225, stu_CELoss: 1.7874, DKDLoss: 1.5350, 
2022-07-28 21:48:55 - train: epoch 0027, iter [00800, 05004], lr: 0.100000, loss: 3.5129, stu_CELoss: 1.8061, DKDLoss: 1.7069, 
2022-07-28 21:49:30 - train: epoch 0027, iter [00900, 05004], lr: 0.100000, loss: 3.5010, stu_CELoss: 1.7652, DKDLoss: 1.7358, 
2022-07-28 21:50:04 - train: epoch 0027, iter [01000, 05004], lr: 0.100000, loss: 3.2294, stu_CELoss: 1.6745, DKDLoss: 1.5548, 
2022-07-28 21:50:38 - train: epoch 0027, iter [01100, 05004], lr: 0.100000, loss: 3.4895, stu_CELoss: 1.8297, DKDLoss: 1.6598, 
2022-07-28 21:51:13 - train: epoch 0027, iter [01200, 05004], lr: 0.100000, loss: 3.7007, stu_CELoss: 1.9259, DKDLoss: 1.7748, 
2022-07-28 21:51:47 - train: epoch 0027, iter [01300, 05004], lr: 0.100000, loss: 3.2511, stu_CELoss: 1.6555, DKDLoss: 1.5956, 
2022-07-28 21:52:22 - train: epoch 0027, iter [01400, 05004], lr: 0.100000, loss: 3.6112, stu_CELoss: 1.8922, DKDLoss: 1.7190, 
2022-07-28 21:52:56 - train: epoch 0027, iter [01500, 05004], lr: 0.100000, loss: 3.4357, stu_CELoss: 1.8116, DKDLoss: 1.6242, 
2022-07-28 21:53:30 - train: epoch 0027, iter [01600, 05004], lr: 0.100000, loss: 3.7275, stu_CELoss: 1.9269, DKDLoss: 1.8006, 
2022-07-28 21:54:05 - train: epoch 0027, iter [01700, 05004], lr: 0.100000, loss: 3.5301, stu_CELoss: 1.8025, DKDLoss: 1.7276, 
2022-07-28 21:54:39 - train: epoch 0027, iter [01800, 05004], lr: 0.100000, loss: 3.4628, stu_CELoss: 1.7233, DKDLoss: 1.7396, 
2022-07-28 21:55:14 - train: epoch 0027, iter [01900, 05004], lr: 0.100000, loss: 3.4092, stu_CELoss: 1.8227, DKDLoss: 1.5864, 
2022-07-28 21:55:48 - train: epoch 0027, iter [02000, 05004], lr: 0.100000, loss: 3.3426, stu_CELoss: 1.7612, DKDLoss: 1.5814, 
2022-07-28 21:56:22 - train: epoch 0027, iter [02100, 05004], lr: 0.100000, loss: 3.7419, stu_CELoss: 1.9873, DKDLoss: 1.7546, 
2022-07-28 21:56:56 - train: epoch 0027, iter [02200, 05004], lr: 0.100000, loss: 3.7757, stu_CELoss: 2.0252, DKDLoss: 1.7505, 
2022-07-28 21:57:31 - train: epoch 0027, iter [02300, 05004], lr: 0.100000, loss: 3.7401, stu_CELoss: 1.9749, DKDLoss: 1.7652, 
2022-07-28 21:58:06 - train: epoch 0027, iter [02400, 05004], lr: 0.100000, loss: 3.3429, stu_CELoss: 1.7923, DKDLoss: 1.5506, 
2022-07-28 21:58:40 - train: epoch 0027, iter [02500, 05004], lr: 0.100000, loss: 3.4458, stu_CELoss: 1.7606, DKDLoss: 1.6852, 
2022-07-28 21:59:15 - train: epoch 0027, iter [02600, 05004], lr: 0.100000, loss: 3.6043, stu_CELoss: 1.9932, DKDLoss: 1.6111, 
2022-07-28 21:59:49 - train: epoch 0027, iter [02700, 05004], lr: 0.100000, loss: 3.3363, stu_CELoss: 1.7625, DKDLoss: 1.5739, 
2022-07-28 22:00:23 - train: epoch 0027, iter [02800, 05004], lr: 0.100000, loss: 3.5744, stu_CELoss: 1.9300, DKDLoss: 1.6443, 
2022-07-28 22:00:58 - train: epoch 0027, iter [02900, 05004], lr: 0.100000, loss: 3.6711, stu_CELoss: 1.9056, DKDLoss: 1.7655, 
2022-07-28 22:01:32 - train: epoch 0027, iter [03000, 05004], lr: 0.100000, loss: 3.4429, stu_CELoss: 1.8284, DKDLoss: 1.6145, 
2022-07-28 22:02:06 - train: epoch 0027, iter [03100, 05004], lr: 0.100000, loss: 3.2635, stu_CELoss: 1.6886, DKDLoss: 1.5749, 
2022-07-28 22:02:41 - train: epoch 0027, iter [03200, 05004], lr: 0.100000, loss: 3.2566, stu_CELoss: 1.5519, DKDLoss: 1.7047, 
2022-07-28 22:03:14 - train: epoch 0027, iter [03300, 05004], lr: 0.100000, loss: 3.4607, stu_CELoss: 1.8395, DKDLoss: 1.6213, 
2022-07-28 22:03:49 - train: epoch 0027, iter [03400, 05004], lr: 0.100000, loss: 3.3046, stu_CELoss: 1.6904, DKDLoss: 1.6143, 
2022-07-28 22:04:23 - train: epoch 0027, iter [03500, 05004], lr: 0.100000, loss: 3.6606, stu_CELoss: 1.9365, DKDLoss: 1.7241, 
2022-07-28 22:04:57 - train: epoch 0027, iter [03600, 05004], lr: 0.100000, loss: 3.5026, stu_CELoss: 1.9086, DKDLoss: 1.5940, 
2022-07-28 22:05:32 - train: epoch 0027, iter [03700, 05004], lr: 0.100000, loss: 3.5600, stu_CELoss: 1.8947, DKDLoss: 1.6653, 
2022-07-28 22:06:06 - train: epoch 0027, iter [03800, 05004], lr: 0.100000, loss: 3.0367, stu_CELoss: 1.5161, DKDLoss: 1.5206, 
2022-07-28 22:06:40 - train: epoch 0027, iter [03900, 05004], lr: 0.100000, loss: 3.5334, stu_CELoss: 1.7966, DKDLoss: 1.7368, 
2022-07-28 22:07:14 - train: epoch 0027, iter [04000, 05004], lr: 0.100000, loss: 3.6143, stu_CELoss: 1.8503, DKDLoss: 1.7640, 
2022-07-28 22:07:49 - train: epoch 0027, iter [04100, 05004], lr: 0.100000, loss: 3.3684, stu_CELoss: 1.7959, DKDLoss: 1.5725, 
2022-07-28 22:08:23 - train: epoch 0027, iter [04200, 05004], lr: 0.100000, loss: 3.5060, stu_CELoss: 1.7964, DKDLoss: 1.7096, 
2022-07-28 22:08:57 - train: epoch 0027, iter [04300, 05004], lr: 0.100000, loss: 3.1325, stu_CELoss: 1.6421, DKDLoss: 1.4905, 
2022-07-28 22:09:31 - train: epoch 0027, iter [04400, 05004], lr: 0.100000, loss: 3.4536, stu_CELoss: 1.8247, DKDLoss: 1.6289, 
2022-07-28 22:10:06 - train: epoch 0027, iter [04500, 05004], lr: 0.100000, loss: 3.3627, stu_CELoss: 1.7486, DKDLoss: 1.6141, 
2022-07-28 22:10:40 - train: epoch 0027, iter [04600, 05004], lr: 0.100000, loss: 3.4145, stu_CELoss: 1.7530, DKDLoss: 1.6615, 
2022-07-28 22:11:14 - train: epoch 0027, iter [04700, 05004], lr: 0.100000, loss: 3.6230, stu_CELoss: 1.9904, DKDLoss: 1.6327, 
2022-07-28 22:11:49 - train: epoch 0027, iter [04800, 05004], lr: 0.100000, loss: 3.4546, stu_CELoss: 1.8134, DKDLoss: 1.6412, 
2022-07-28 22:12:23 - train: epoch 0027, iter [04900, 05004], lr: 0.100000, loss: 3.4833, stu_CELoss: 1.7913, DKDLoss: 1.6920, 
2022-07-28 22:12:56 - train: epoch 0027, iter [05000, 05004], lr: 0.100000, loss: 3.2989, stu_CELoss: 1.7280, DKDLoss: 1.5709, 
2022-07-28 22:12:57 - train: epoch 027, train_loss: 3.4411
2022-07-28 22:15:31 - eval: epoch: 027, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 60.706%, stu_acc5: 83.866%, stu_test_loss: 1.6417
2022-07-28 22:15:32 - until epoch: 027, tea_best_acc1: 78.068%, stu_best_acc1: 60.706%
2022-07-28 22:15:32 - epoch 028 lr: 0.100000
2022-07-28 22:16:12 - train: epoch 0028, iter [00100, 05004], lr: 0.100000, loss: 3.1707, stu_CELoss: 1.6297, DKDLoss: 1.5410, 
2022-07-28 22:16:46 - train: epoch 0028, iter [00200, 05004], lr: 0.100000, loss: 3.5757, stu_CELoss: 1.8126, DKDLoss: 1.7631, 
2022-07-28 22:17:20 - train: epoch 0028, iter [00300, 05004], lr: 0.100000, loss: 3.4113, stu_CELoss: 1.8530, DKDLoss: 1.5583, 
2022-07-28 22:17:54 - train: epoch 0028, iter [00400, 05004], lr: 0.100000, loss: 3.2788, stu_CELoss: 1.7338, DKDLoss: 1.5450, 
2022-07-28 22:18:28 - train: epoch 0028, iter [00500, 05004], lr: 0.100000, loss: 3.1709, stu_CELoss: 1.6297, DKDLoss: 1.5412, 
2022-07-28 22:19:02 - train: epoch 0028, iter [00600, 05004], lr: 0.100000, loss: 3.5977, stu_CELoss: 1.9883, DKDLoss: 1.6093, 
2022-07-28 22:19:35 - train: epoch 0028, iter [00700, 05004], lr: 0.100000, loss: 3.6729, stu_CELoss: 1.9466, DKDLoss: 1.7263, 
2022-07-28 22:20:09 - train: epoch 0028, iter [00800, 05004], lr: 0.100000, loss: 3.2447, stu_CELoss: 1.6591, DKDLoss: 1.5856, 
2022-07-28 22:20:43 - train: epoch 0028, iter [00900, 05004], lr: 0.100000, loss: 3.2816, stu_CELoss: 1.7578, DKDLoss: 1.5238, 
2022-07-28 22:21:17 - train: epoch 0028, iter [01000, 05004], lr: 0.100000, loss: 3.4537, stu_CELoss: 1.7341, DKDLoss: 1.7195, 
2022-07-28 22:21:51 - train: epoch 0028, iter [01100, 05004], lr: 0.100000, loss: 3.2119, stu_CELoss: 1.6117, DKDLoss: 1.6002, 
2022-07-28 22:22:25 - train: epoch 0028, iter [01200, 05004], lr: 0.100000, loss: 3.3192, stu_CELoss: 1.7510, DKDLoss: 1.5683, 
2022-07-28 22:22:59 - train: epoch 0028, iter [01300, 05004], lr: 0.100000, loss: 3.7453, stu_CELoss: 1.9654, DKDLoss: 1.7798, 
2022-07-28 22:23:34 - train: epoch 0028, iter [01400, 05004], lr: 0.100000, loss: 3.7137, stu_CELoss: 1.9438, DKDLoss: 1.7698, 
2022-07-28 22:24:08 - train: epoch 0028, iter [01500, 05004], lr: 0.100000, loss: 3.5164, stu_CELoss: 1.8822, DKDLoss: 1.6342, 
2022-07-28 22:24:42 - train: epoch 0028, iter [01600, 05004], lr: 0.100000, loss: 3.3043, stu_CELoss: 1.6790, DKDLoss: 1.6252, 
2022-07-28 22:25:16 - train: epoch 0028, iter [01700, 05004], lr: 0.100000, loss: 3.7272, stu_CELoss: 1.9779, DKDLoss: 1.7493, 
2022-07-28 22:25:50 - train: epoch 0028, iter [01800, 05004], lr: 0.100000, loss: 3.5724, stu_CELoss: 1.8590, DKDLoss: 1.7134, 
2022-07-28 22:26:24 - train: epoch 0028, iter [01900, 05004], lr: 0.100000, loss: 3.4294, stu_CELoss: 1.7571, DKDLoss: 1.6723, 
2022-07-28 22:26:58 - train: epoch 0028, iter [02000, 05004], lr: 0.100000, loss: 3.4556, stu_CELoss: 1.8672, DKDLoss: 1.5884, 
2022-07-28 22:27:33 - train: epoch 0028, iter [02100, 05004], lr: 0.100000, loss: 3.9348, stu_CELoss: 2.1377, DKDLoss: 1.7971, 
2022-07-28 22:28:07 - train: epoch 0028, iter [02200, 05004], lr: 0.100000, loss: 3.5292, stu_CELoss: 1.8297, DKDLoss: 1.6995, 
2022-07-28 22:28:41 - train: epoch 0028, iter [02300, 05004], lr: 0.100000, loss: 3.3512, stu_CELoss: 1.7345, DKDLoss: 1.6166, 
2022-07-28 22:29:15 - train: epoch 0028, iter [02400, 05004], lr: 0.100000, loss: 3.6665, stu_CELoss: 1.8349, DKDLoss: 1.8317, 
2022-07-28 22:29:49 - train: epoch 0028, iter [02500, 05004], lr: 0.100000, loss: 3.6473, stu_CELoss: 1.9136, DKDLoss: 1.7338, 
2022-07-28 22:30:24 - train: epoch 0028, iter [02600, 05004], lr: 0.100000, loss: 3.3384, stu_CELoss: 1.7153, DKDLoss: 1.6231, 
2022-07-28 22:30:58 - train: epoch 0028, iter [02700, 05004], lr: 0.100000, loss: 3.2033, stu_CELoss: 1.6792, DKDLoss: 1.5240, 
2022-07-28 22:31:32 - train: epoch 0028, iter [02800, 05004], lr: 0.100000, loss: 3.6037, stu_CELoss: 1.9058, DKDLoss: 1.6979, 
2022-07-28 22:32:07 - train: epoch 0028, iter [02900, 05004], lr: 0.100000, loss: 3.6209, stu_CELoss: 1.9842, DKDLoss: 1.6367, 
2022-07-28 22:32:41 - train: epoch 0028, iter [03000, 05004], lr: 0.100000, loss: 3.3863, stu_CELoss: 1.8646, DKDLoss: 1.5217, 
2022-07-28 22:33:15 - train: epoch 0028, iter [03100, 05004], lr: 0.100000, loss: 3.4573, stu_CELoss: 1.8176, DKDLoss: 1.6397, 
2022-07-28 22:33:49 - train: epoch 0028, iter [03200, 05004], lr: 0.100000, loss: 3.1764, stu_CELoss: 1.6567, DKDLoss: 1.5196, 
2022-07-28 22:34:24 - train: epoch 0028, iter [03300, 05004], lr: 0.100000, loss: 3.8173, stu_CELoss: 2.0406, DKDLoss: 1.7767, 
2022-07-28 22:34:59 - train: epoch 0028, iter [03400, 05004], lr: 0.100000, loss: 3.6175, stu_CELoss: 1.9961, DKDLoss: 1.6214, 
2022-07-28 22:35:33 - train: epoch 0028, iter [03500, 05004], lr: 0.100000, loss: 3.4166, stu_CELoss: 1.7453, DKDLoss: 1.6713, 
2022-07-28 22:36:08 - train: epoch 0028, iter [03600, 05004], lr: 0.100000, loss: 3.1382, stu_CELoss: 1.6747, DKDLoss: 1.4635, 
2022-07-28 22:36:42 - train: epoch 0028, iter [03700, 05004], lr: 0.100000, loss: 3.3240, stu_CELoss: 1.7481, DKDLoss: 1.5759, 
2022-07-28 22:37:17 - train: epoch 0028, iter [03800, 05004], lr: 0.100000, loss: 2.9648, stu_CELoss: 1.4713, DKDLoss: 1.4935, 
2022-07-28 22:37:52 - train: epoch 0028, iter [03900, 05004], lr: 0.100000, loss: 3.6599, stu_CELoss: 1.9860, DKDLoss: 1.6739, 
2022-07-28 22:38:26 - train: epoch 0028, iter [04000, 05004], lr: 0.100000, loss: 3.5914, stu_CELoss: 1.9402, DKDLoss: 1.6513, 
2022-07-28 22:39:01 - train: epoch 0028, iter [04100, 05004], lr: 0.100000, loss: 3.6232, stu_CELoss: 1.8930, DKDLoss: 1.7302, 
2022-07-28 22:39:35 - train: epoch 0028, iter [04200, 05004], lr: 0.100000, loss: 3.6294, stu_CELoss: 1.9523, DKDLoss: 1.6771, 
2022-07-28 22:40:10 - train: epoch 0028, iter [04300, 05004], lr: 0.100000, loss: 3.2235, stu_CELoss: 1.6838, DKDLoss: 1.5397, 
2022-07-28 22:40:45 - train: epoch 0028, iter [04400, 05004], lr: 0.100000, loss: 3.1828, stu_CELoss: 1.6426, DKDLoss: 1.5402, 
2022-07-28 22:41:20 - train: epoch 0028, iter [04500, 05004], lr: 0.100000, loss: 3.4843, stu_CELoss: 1.8447, DKDLoss: 1.6397, 
2022-07-28 22:41:54 - train: epoch 0028, iter [04600, 05004], lr: 0.100000, loss: 3.4610, stu_CELoss: 1.8881, DKDLoss: 1.5729, 
2022-07-28 22:42:29 - train: epoch 0028, iter [04700, 05004], lr: 0.100000, loss: 3.6873, stu_CELoss: 2.0385, DKDLoss: 1.6488, 
2022-07-28 22:43:03 - train: epoch 0028, iter [04800, 05004], lr: 0.100000, loss: 3.3252, stu_CELoss: 1.7539, DKDLoss: 1.5713, 
2022-07-28 22:43:38 - train: epoch 0028, iter [04900, 05004], lr: 0.100000, loss: 3.7600, stu_CELoss: 1.9514, DKDLoss: 1.8086, 
2022-07-28 22:44:11 - train: epoch 0028, iter [05000, 05004], lr: 0.100000, loss: 3.2032, stu_CELoss: 1.6723, DKDLoss: 1.5309, 
2022-07-28 22:44:13 - train: epoch 028, train_loss: 3.4281
2022-07-28 22:46:48 - eval: epoch: 028, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 59.852%, stu_acc5: 83.326%, stu_test_loss: 1.6826
2022-07-28 22:46:48 - until epoch: 028, tea_best_acc1: 78.068%, stu_best_acc1: 60.706%
2022-07-28 22:46:48 - epoch 029 lr: 0.100000
2022-07-28 22:47:29 - train: epoch 0029, iter [00100, 05004], lr: 0.100000, loss: 3.6945, stu_CELoss: 1.9094, DKDLoss: 1.7851, 
2022-07-28 22:48:03 - train: epoch 0029, iter [00200, 05004], lr: 0.100000, loss: 3.0923, stu_CELoss: 1.6129, DKDLoss: 1.4794, 
2022-07-28 22:48:37 - train: epoch 0029, iter [00300, 05004], lr: 0.100000, loss: 3.5569, stu_CELoss: 2.0150, DKDLoss: 1.5419, 
2022-07-28 22:49:11 - train: epoch 0029, iter [00400, 05004], lr: 0.100000, loss: 3.7076, stu_CELoss: 1.9388, DKDLoss: 1.7688, 
2022-07-28 22:49:45 - train: epoch 0029, iter [00500, 05004], lr: 0.100000, loss: 3.5145, stu_CELoss: 1.8637, DKDLoss: 1.6508, 
2022-07-28 22:50:19 - train: epoch 0029, iter [00600, 05004], lr: 0.100000, loss: 3.4186, stu_CELoss: 1.8259, DKDLoss: 1.5927, 
2022-07-28 22:50:53 - train: epoch 0029, iter [00700, 05004], lr: 0.100000, loss: 3.1174, stu_CELoss: 1.4925, DKDLoss: 1.6250, 
2022-07-28 22:51:28 - train: epoch 0029, iter [00800, 05004], lr: 0.100000, loss: 3.4159, stu_CELoss: 1.8412, DKDLoss: 1.5747, 
2022-07-28 22:52:02 - train: epoch 0029, iter [00900, 05004], lr: 0.100000, loss: 3.4731, stu_CELoss: 1.8310, DKDLoss: 1.6421, 
2022-07-28 22:52:37 - train: epoch 0029, iter [01000, 05004], lr: 0.100000, loss: 3.5323, stu_CELoss: 1.8673, DKDLoss: 1.6651, 
2022-07-28 22:53:11 - train: epoch 0029, iter [01100, 05004], lr: 0.100000, loss: 3.3033, stu_CELoss: 1.7424, DKDLoss: 1.5610, 
2022-07-28 22:53:45 - train: epoch 0029, iter [01200, 05004], lr: 0.100000, loss: 3.5550, stu_CELoss: 1.8652, DKDLoss: 1.6898, 
2022-07-28 22:54:19 - train: epoch 0029, iter [01300, 05004], lr: 0.100000, loss: 3.3400, stu_CELoss: 1.7874, DKDLoss: 1.5526, 
2022-07-28 22:54:53 - train: epoch 0029, iter [01400, 05004], lr: 0.100000, loss: 3.4105, stu_CELoss: 1.7631, DKDLoss: 1.6474, 
2022-07-28 22:55:27 - train: epoch 0029, iter [01500, 05004], lr: 0.100000, loss: 3.2630, stu_CELoss: 1.7338, DKDLoss: 1.5293, 
2022-07-28 22:56:02 - train: epoch 0029, iter [01600, 05004], lr: 0.100000, loss: 3.4573, stu_CELoss: 1.8053, DKDLoss: 1.6520, 
2022-07-28 22:56:36 - train: epoch 0029, iter [01700, 05004], lr: 0.100000, loss: 3.2906, stu_CELoss: 1.6452, DKDLoss: 1.6454, 
2022-07-28 22:57:10 - train: epoch 0029, iter [01800, 05004], lr: 0.100000, loss: 3.5533, stu_CELoss: 1.8868, DKDLoss: 1.6665, 
2022-07-28 22:57:44 - train: epoch 0029, iter [01900, 05004], lr: 0.100000, loss: 3.4890, stu_CELoss: 1.8386, DKDLoss: 1.6504, 
2022-07-28 22:58:18 - train: epoch 0029, iter [02000, 05004], lr: 0.100000, loss: 3.3255, stu_CELoss: 1.7124, DKDLoss: 1.6132, 
2022-07-28 22:58:53 - train: epoch 0029, iter [02100, 05004], lr: 0.100000, loss: 3.2982, stu_CELoss: 1.7228, DKDLoss: 1.5754, 
2022-07-28 22:59:27 - train: epoch 0029, iter [02200, 05004], lr: 0.100000, loss: 3.6064, stu_CELoss: 1.9213, DKDLoss: 1.6850, 
2022-07-28 23:00:02 - train: epoch 0029, iter [02300, 05004], lr: 0.100000, loss: 3.3610, stu_CELoss: 1.8225, DKDLoss: 1.5384, 
2022-07-28 23:00:36 - train: epoch 0029, iter [02400, 05004], lr: 0.100000, loss: 2.9612, stu_CELoss: 1.4939, DKDLoss: 1.4673, 
2022-07-28 23:01:11 - train: epoch 0029, iter [02500, 05004], lr: 0.100000, loss: 3.5623, stu_CELoss: 1.8728, DKDLoss: 1.6895, 
2022-07-28 23:01:45 - train: epoch 0029, iter [02600, 05004], lr: 0.100000, loss: 3.4859, stu_CELoss: 1.8056, DKDLoss: 1.6803, 
2022-07-28 23:02:19 - train: epoch 0029, iter [02700, 05004], lr: 0.100000, loss: 3.4389, stu_CELoss: 1.8182, DKDLoss: 1.6207, 
2022-07-28 23:02:53 - train: epoch 0029, iter [02800, 05004], lr: 0.100000, loss: 3.3880, stu_CELoss: 1.7794, DKDLoss: 1.6086, 
2022-07-28 23:03:26 - train: epoch 0029, iter [02900, 05004], lr: 0.100000, loss: 3.3111, stu_CELoss: 1.7710, DKDLoss: 1.5402, 
2022-07-28 23:04:00 - train: epoch 0029, iter [03000, 05004], lr: 0.100000, loss: 3.4570, stu_CELoss: 1.7831, DKDLoss: 1.6739, 
2022-07-28 23:04:34 - train: epoch 0029, iter [03100, 05004], lr: 0.100000, loss: 3.4777, stu_CELoss: 1.8946, DKDLoss: 1.5831, 
2022-07-28 23:05:09 - train: epoch 0029, iter [03200, 05004], lr: 0.100000, loss: 3.4895, stu_CELoss: 1.8848, DKDLoss: 1.6046, 
2022-07-28 23:05:43 - train: epoch 0029, iter [03300, 05004], lr: 0.100000, loss: 3.1708, stu_CELoss: 1.6721, DKDLoss: 1.4988, 
2022-07-28 23:06:17 - train: epoch 0029, iter [03400, 05004], lr: 0.100000, loss: 3.2522, stu_CELoss: 1.6812, DKDLoss: 1.5711, 
2022-07-28 23:06:51 - train: epoch 0029, iter [03500, 05004], lr: 0.100000, loss: 3.5507, stu_CELoss: 1.8242, DKDLoss: 1.7265, 
2022-07-28 23:07:25 - train: epoch 0029, iter [03600, 05004], lr: 0.100000, loss: 3.1178, stu_CELoss: 1.5916, DKDLoss: 1.5262, 
2022-07-28 23:07:59 - train: epoch 0029, iter [03700, 05004], lr: 0.100000, loss: 3.3406, stu_CELoss: 1.6693, DKDLoss: 1.6713, 
2022-07-28 23:08:33 - train: epoch 0029, iter [03800, 05004], lr: 0.100000, loss: 3.4085, stu_CELoss: 1.8126, DKDLoss: 1.5959, 
2022-07-28 23:09:08 - train: epoch 0029, iter [03900, 05004], lr: 0.100000, loss: 3.2258, stu_CELoss: 1.7231, DKDLoss: 1.5027, 
2022-07-28 23:09:42 - train: epoch 0029, iter [04000, 05004], lr: 0.100000, loss: 3.4710, stu_CELoss: 1.7682, DKDLoss: 1.7027, 
2022-07-28 23:10:16 - train: epoch 0029, iter [04100, 05004], lr: 0.100000, loss: 3.5728, stu_CELoss: 1.8924, DKDLoss: 1.6804, 
2022-07-28 23:10:50 - train: epoch 0029, iter [04200, 05004], lr: 0.100000, loss: 3.4032, stu_CELoss: 1.7812, DKDLoss: 1.6220, 
2022-07-28 23:11:24 - train: epoch 0029, iter [04300, 05004], lr: 0.100000, loss: 3.7689, stu_CELoss: 2.0668, DKDLoss: 1.7020, 
2022-07-28 23:11:58 - train: epoch 0029, iter [04400, 05004], lr: 0.100000, loss: 3.4948, stu_CELoss: 1.8507, DKDLoss: 1.6441, 
2022-07-28 23:12:33 - train: epoch 0029, iter [04500, 05004], lr: 0.100000, loss: 3.7285, stu_CELoss: 2.0238, DKDLoss: 1.7046, 
2022-07-28 23:13:07 - train: epoch 0029, iter [04600, 05004], lr: 0.100000, loss: 3.4679, stu_CELoss: 1.8188, DKDLoss: 1.6491, 
2022-07-28 23:13:41 - train: epoch 0029, iter [04700, 05004], lr: 0.100000, loss: 3.0117, stu_CELoss: 1.5221, DKDLoss: 1.4896, 
2022-07-28 23:14:16 - train: epoch 0029, iter [04800, 05004], lr: 0.100000, loss: 3.4146, stu_CELoss: 1.7240, DKDLoss: 1.6906, 
2022-07-28 23:14:50 - train: epoch 0029, iter [04900, 05004], lr: 0.100000, loss: 3.7770, stu_CELoss: 1.9538, DKDLoss: 1.8231, 
2022-07-28 23:15:24 - train: epoch 0029, iter [05000, 05004], lr: 0.100000, loss: 2.9825, stu_CELoss: 1.6089, DKDLoss: 1.3736, 
2022-07-28 23:15:25 - train: epoch 029, train_loss: 3.4213
2022-07-28 23:18:01 - eval: epoch: 029, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 58.566%, stu_acc5: 82.700%, stu_test_loss: 1.7178
2022-07-28 23:18:02 - until epoch: 029, tea_best_acc1: 78.068%, stu_best_acc1: 60.706%
2022-07-29 07:05:57 - epoch 030 lr: 0.100000
2022-07-29 07:06:39 - train: epoch 0030, iter [00100, 05004], lr: 0.100000, loss: 3.1673, stu_CELoss: 1.6825, DKDLoss: 1.4848, 
2022-07-29 07:07:12 - train: epoch 0030, iter [00200, 05004], lr: 0.100000, loss: 3.2374, stu_CELoss: 1.7397, DKDLoss: 1.4977, 
2022-07-29 07:07:46 - train: epoch 0030, iter [00300, 05004], lr: 0.100000, loss: 3.0508, stu_CELoss: 1.5404, DKDLoss: 1.5103, 
2022-07-29 07:08:19 - train: epoch 0030, iter [00400, 05004], lr: 0.100000, loss: 3.5454, stu_CELoss: 1.7251, DKDLoss: 1.8203, 
2022-07-29 07:08:53 - train: epoch 0030, iter [00500, 05004], lr: 0.100000, loss: 3.4460, stu_CELoss: 1.8464, DKDLoss: 1.5996, 
2022-07-29 07:09:27 - train: epoch 0030, iter [00600, 05004], lr: 0.100000, loss: 3.3892, stu_CELoss: 1.7519, DKDLoss: 1.6373, 
2022-07-29 07:10:01 - train: epoch 0030, iter [00700, 05004], lr: 0.100000, loss: 3.4809, stu_CELoss: 1.8801, DKDLoss: 1.6007, 
2022-07-29 07:10:35 - train: epoch 0030, iter [00800, 05004], lr: 0.100000, loss: 3.4429, stu_CELoss: 1.8497, DKDLoss: 1.5932, 
2022-07-29 07:11:09 - train: epoch 0030, iter [00900, 05004], lr: 0.100000, loss: 3.3859, stu_CELoss: 1.7030, DKDLoss: 1.6828, 
2022-07-29 07:11:43 - train: epoch 0030, iter [01000, 05004], lr: 0.100000, loss: 3.4364, stu_CELoss: 1.8346, DKDLoss: 1.6018, 
2022-07-29 07:12:17 - train: epoch 0030, iter [01100, 05004], lr: 0.100000, loss: 3.3605, stu_CELoss: 1.7935, DKDLoss: 1.5670, 
2022-07-29 07:12:51 - train: epoch 0030, iter [01200, 05004], lr: 0.100000, loss: 3.4371, stu_CELoss: 1.7116, DKDLoss: 1.7255, 
2022-07-29 07:13:25 - train: epoch 0030, iter [01300, 05004], lr: 0.100000, loss: 3.1687, stu_CELoss: 1.7584, DKDLoss: 1.4103, 
2022-07-29 07:13:59 - train: epoch 0030, iter [01400, 05004], lr: 0.100000, loss: 3.4762, stu_CELoss: 1.8706, DKDLoss: 1.6056, 
2022-07-29 07:14:33 - train: epoch 0030, iter [01500, 05004], lr: 0.100000, loss: 3.2330, stu_CELoss: 1.6856, DKDLoss: 1.5474, 
2022-07-29 07:15:07 - train: epoch 0030, iter [01600, 05004], lr: 0.100000, loss: 3.5513, stu_CELoss: 1.8006, DKDLoss: 1.7507, 
2022-07-29 07:15:41 - train: epoch 0030, iter [01700, 05004], lr: 0.100000, loss: 3.8317, stu_CELoss: 2.0429, DKDLoss: 1.7888, 
2022-07-29 07:16:15 - train: epoch 0030, iter [01800, 05004], lr: 0.100000, loss: 3.1512, stu_CELoss: 1.5723, DKDLoss: 1.5788, 
2022-07-29 07:16:50 - train: epoch 0030, iter [01900, 05004], lr: 0.100000, loss: 3.2850, stu_CELoss: 1.7157, DKDLoss: 1.5693, 
2022-07-29 07:17:24 - train: epoch 0030, iter [02000, 05004], lr: 0.100000, loss: 3.1313, stu_CELoss: 1.6369, DKDLoss: 1.4945, 
2022-07-29 07:17:58 - train: epoch 0030, iter [02100, 05004], lr: 0.100000, loss: 3.5815, stu_CELoss: 1.8683, DKDLoss: 1.7132, 
2022-07-29 07:18:32 - train: epoch 0030, iter [02200, 05004], lr: 0.100000, loss: 3.3805, stu_CELoss: 1.7684, DKDLoss: 1.6121, 
2022-07-29 07:19:06 - train: epoch 0030, iter [02300, 05004], lr: 0.100000, loss: 3.5631, stu_CELoss: 1.7646, DKDLoss: 1.7985, 
2022-07-29 07:19:40 - train: epoch 0030, iter [02400, 05004], lr: 0.100000, loss: 3.5154, stu_CELoss: 1.8799, DKDLoss: 1.6355, 
2022-07-29 07:20:15 - train: epoch 0030, iter [02500, 05004], lr: 0.100000, loss: 3.6934, stu_CELoss: 1.8751, DKDLoss: 1.8182, 
2022-07-29 07:20:49 - train: epoch 0030, iter [02600, 05004], lr: 0.100000, loss: 3.0959, stu_CELoss: 1.6379, DKDLoss: 1.4581, 
2022-07-29 07:21:23 - train: epoch 0030, iter [02700, 05004], lr: 0.100000, loss: 3.5660, stu_CELoss: 1.8705, DKDLoss: 1.6954, 
2022-07-29 07:21:57 - train: epoch 0030, iter [02800, 05004], lr: 0.100000, loss: 3.3882, stu_CELoss: 1.8224, DKDLoss: 1.5657, 
2022-07-29 07:22:31 - train: epoch 0030, iter [02900, 05004], lr: 0.100000, loss: 3.2204, stu_CELoss: 1.6863, DKDLoss: 1.5341, 
2022-07-29 07:23:05 - train: epoch 0030, iter [03000, 05004], lr: 0.100000, loss: 3.5528, stu_CELoss: 1.8401, DKDLoss: 1.7127, 
2022-07-29 07:23:39 - train: epoch 0030, iter [03100, 05004], lr: 0.100000, loss: 3.5823, stu_CELoss: 1.8427, DKDLoss: 1.7396, 
2022-07-29 07:24:13 - train: epoch 0030, iter [03200, 05004], lr: 0.100000, loss: 3.3978, stu_CELoss: 1.8206, DKDLoss: 1.5773, 
2022-07-29 07:24:48 - train: epoch 0030, iter [03300, 05004], lr: 0.100000, loss: 3.7329, stu_CELoss: 1.9382, DKDLoss: 1.7947, 
2022-07-29 07:25:22 - train: epoch 0030, iter [03400, 05004], lr: 0.100000, loss: 3.3090, stu_CELoss: 1.6953, DKDLoss: 1.6137, 
2022-07-29 07:25:56 - train: epoch 0030, iter [03500, 05004], lr: 0.100000, loss: 3.4296, stu_CELoss: 1.8505, DKDLoss: 1.5790, 
2022-07-29 07:26:31 - train: epoch 0030, iter [03600, 05004], lr: 0.100000, loss: 3.3212, stu_CELoss: 1.8063, DKDLoss: 1.5149, 
2022-07-29 07:27:05 - train: epoch 0030, iter [03700, 05004], lr: 0.100000, loss: 3.1995, stu_CELoss: 1.7017, DKDLoss: 1.4979, 
2022-07-29 07:27:39 - train: epoch 0030, iter [03800, 05004], lr: 0.100000, loss: 3.5465, stu_CELoss: 1.9157, DKDLoss: 1.6309, 
2022-07-29 07:28:14 - train: epoch 0030, iter [03900, 05004], lr: 0.100000, loss: 3.4474, stu_CELoss: 1.7779, DKDLoss: 1.6695, 
2022-07-29 07:28:48 - train: epoch 0030, iter [04000, 05004], lr: 0.100000, loss: 3.1731, stu_CELoss: 1.6445, DKDLoss: 1.5286, 
2022-07-29 07:29:22 - train: epoch 0030, iter [04100, 05004], lr: 0.100000, loss: 3.5097, stu_CELoss: 1.7953, DKDLoss: 1.7144, 
2022-07-29 07:29:56 - train: epoch 0030, iter [04200, 05004], lr: 0.100000, loss: 3.8836, stu_CELoss: 2.0316, DKDLoss: 1.8520, 
2022-07-29 07:30:31 - train: epoch 0030, iter [04300, 05004], lr: 0.100000, loss: 3.6217, stu_CELoss: 1.9293, DKDLoss: 1.6924, 
2022-07-29 07:31:06 - train: epoch 0030, iter [04400, 05004], lr: 0.100000, loss: 3.3163, stu_CELoss: 1.7333, DKDLoss: 1.5830, 
2022-07-29 07:31:40 - train: epoch 0030, iter [04500, 05004], lr: 0.100000, loss: 3.5074, stu_CELoss: 1.7891, DKDLoss: 1.7183, 
2022-07-29 07:32:14 - train: epoch 0030, iter [04600, 05004], lr: 0.100000, loss: 3.4006, stu_CELoss: 1.6974, DKDLoss: 1.7032, 
2022-07-29 07:32:49 - train: epoch 0030, iter [04700, 05004], lr: 0.100000, loss: 3.4119, stu_CELoss: 1.7584, DKDLoss: 1.6535, 
2022-07-29 07:33:23 - train: epoch 0030, iter [04800, 05004], lr: 0.100000, loss: 3.6637, stu_CELoss: 1.8736, DKDLoss: 1.7901, 
2022-07-29 07:33:58 - train: epoch 0030, iter [04900, 05004], lr: 0.100000, loss: 3.5978, stu_CELoss: 1.8681, DKDLoss: 1.7297, 
2022-07-29 07:34:32 - train: epoch 0030, iter [05000, 05004], lr: 0.100000, loss: 3.6335, stu_CELoss: 2.0441, DKDLoss: 1.5895, 
2022-07-29 07:34:33 - train: epoch 030, train_loss: 3.4114
2022-07-29 07:37:09 - eval: epoch: 030, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 59.926%, stu_acc5: 83.288%, stu_test_loss: 1.6668
2022-07-29 07:37:10 - until epoch: 030, tea_best_acc1: 78.068%, stu_best_acc1: 60.706%
2022-07-29 07:37:10 - epoch 031 lr: 0.010000
2022-07-29 07:37:51 - train: epoch 0031, iter [00100, 05004], lr: 0.010000, loss: 3.0299, stu_CELoss: 1.6700, DKDLoss: 1.3599, 
2022-07-29 07:38:25 - train: epoch 0031, iter [00200, 05004], lr: 0.010000, loss: 2.5667, stu_CELoss: 1.3909, DKDLoss: 1.1758, 
2022-07-29 07:38:59 - train: epoch 0031, iter [00300, 05004], lr: 0.010000, loss: 2.6025, stu_CELoss: 1.4086, DKDLoss: 1.1939, 
2022-07-29 07:39:33 - train: epoch 0031, iter [00400, 05004], lr: 0.010000, loss: 2.6158, stu_CELoss: 1.4384, DKDLoss: 1.1774, 
2022-07-29 07:40:07 - train: epoch 0031, iter [00500, 05004], lr: 0.010000, loss: 2.6762, stu_CELoss: 1.3954, DKDLoss: 1.2808, 
2022-07-29 07:40:42 - train: epoch 0031, iter [00600, 05004], lr: 0.010000, loss: 2.4159, stu_CELoss: 1.3576, DKDLoss: 1.0583, 
2022-07-29 07:41:16 - train: epoch 0031, iter [00700, 05004], lr: 0.010000, loss: 2.7385, stu_CELoss: 1.5285, DKDLoss: 1.2101, 
2022-07-29 07:41:51 - train: epoch 0031, iter [00800, 05004], lr: 0.010000, loss: 2.3273, stu_CELoss: 1.2878, DKDLoss: 1.0395, 
2022-07-29 07:42:25 - train: epoch 0031, iter [00900, 05004], lr: 0.010000, loss: 2.4470, stu_CELoss: 1.3248, DKDLoss: 1.1221, 
2022-07-29 07:42:59 - train: epoch 0031, iter [01000, 05004], lr: 0.010000, loss: 2.5715, stu_CELoss: 1.4981, DKDLoss: 1.0734, 
2022-07-29 07:43:34 - train: epoch 0031, iter [01100, 05004], lr: 0.010000, loss: 2.5765, stu_CELoss: 1.4139, DKDLoss: 1.1625, 
2022-07-29 07:44:09 - train: epoch 0031, iter [01200, 05004], lr: 0.010000, loss: 2.6358, stu_CELoss: 1.4513, DKDLoss: 1.1845, 
2022-07-29 07:44:43 - train: epoch 0031, iter [01300, 05004], lr: 0.010000, loss: 2.1457, stu_CELoss: 1.1207, DKDLoss: 1.0250, 
2022-07-29 07:45:18 - train: epoch 0031, iter [01400, 05004], lr: 0.010000, loss: 2.3150, stu_CELoss: 1.2402, DKDLoss: 1.0748, 
2022-07-29 07:45:52 - train: epoch 0031, iter [01500, 05004], lr: 0.010000, loss: 2.6205, stu_CELoss: 1.4932, DKDLoss: 1.1273, 
2022-07-29 07:46:27 - train: epoch 0031, iter [01600, 05004], lr: 0.010000, loss: 2.2032, stu_CELoss: 1.2712, DKDLoss: 0.9319, 
2022-07-29 07:47:01 - train: epoch 0031, iter [01700, 05004], lr: 0.010000, loss: 2.2695, stu_CELoss: 1.2695, DKDLoss: 1.0000, 
2022-07-29 07:47:35 - train: epoch 0031, iter [01800, 05004], lr: 0.010000, loss: 2.1850, stu_CELoss: 1.2316, DKDLoss: 0.9534, 
2022-07-29 07:48:10 - train: epoch 0031, iter [01900, 05004], lr: 0.010000, loss: 2.3395, stu_CELoss: 1.3205, DKDLoss: 1.0189, 
2022-07-29 07:48:44 - train: epoch 0031, iter [02000, 05004], lr: 0.010000, loss: 2.4178, stu_CELoss: 1.3553, DKDLoss: 1.0625, 
2022-07-29 07:49:19 - train: epoch 0031, iter [02100, 05004], lr: 0.010000, loss: 2.2005, stu_CELoss: 1.1780, DKDLoss: 1.0225, 
2022-07-29 07:49:53 - train: epoch 0031, iter [02200, 05004], lr: 0.010000, loss: 2.2251, stu_CELoss: 1.1756, DKDLoss: 1.0495, 
2022-07-29 07:50:27 - train: epoch 0031, iter [02300, 05004], lr: 0.010000, loss: 2.2190, stu_CELoss: 1.2732, DKDLoss: 0.9458, 
2022-07-29 07:51:02 - train: epoch 0031, iter [02400, 05004], lr: 0.010000, loss: 2.5478, stu_CELoss: 1.3936, DKDLoss: 1.1542, 
2022-07-29 07:51:36 - train: epoch 0031, iter [02500, 05004], lr: 0.010000, loss: 2.1935, stu_CELoss: 1.1898, DKDLoss: 1.0037, 
2022-07-29 07:52:10 - train: epoch 0031, iter [02600, 05004], lr: 0.010000, loss: 2.2049, stu_CELoss: 1.2556, DKDLoss: 0.9493, 
2022-07-29 07:52:44 - train: epoch 0031, iter [02700, 05004], lr: 0.010000, loss: 2.7081, stu_CELoss: 1.5218, DKDLoss: 1.1862, 
2022-07-29 07:53:19 - train: epoch 0031, iter [02800, 05004], lr: 0.010000, loss: 2.7292, stu_CELoss: 1.6551, DKDLoss: 1.0740, 
2022-07-29 07:53:53 - train: epoch 0031, iter [02900, 05004], lr: 0.010000, loss: 2.5061, stu_CELoss: 1.5499, DKDLoss: 0.9562, 
2022-07-29 07:54:28 - train: epoch 0031, iter [03000, 05004], lr: 0.010000, loss: 2.6764, stu_CELoss: 1.5570, DKDLoss: 1.1194, 
2022-07-29 07:55:03 - train: epoch 0031, iter [03100, 05004], lr: 0.010000, loss: 2.5448, stu_CELoss: 1.4211, DKDLoss: 1.1237, 
2022-07-29 07:55:37 - train: epoch 0031, iter [03200, 05004], lr: 0.010000, loss: 2.6419, stu_CELoss: 1.4153, DKDLoss: 1.2266, 
2022-07-29 07:56:12 - train: epoch 0031, iter [03300, 05004], lr: 0.010000, loss: 2.2566, stu_CELoss: 1.3268, DKDLoss: 0.9298, 
2022-07-29 07:56:46 - train: epoch 0031, iter [03400, 05004], lr: 0.010000, loss: 2.3985, stu_CELoss: 1.3931, DKDLoss: 1.0054, 
2022-07-29 07:57:21 - train: epoch 0031, iter [03500, 05004], lr: 0.010000, loss: 2.5100, stu_CELoss: 1.4440, DKDLoss: 1.0660, 
2022-07-29 07:57:56 - train: epoch 0031, iter [03600, 05004], lr: 0.010000, loss: 2.2706, stu_CELoss: 1.2307, DKDLoss: 1.0399, 
2022-07-29 07:58:30 - train: epoch 0031, iter [03700, 05004], lr: 0.010000, loss: 2.0816, stu_CELoss: 1.1681, DKDLoss: 0.9135, 
2022-07-29 07:59:05 - train: epoch 0031, iter [03800, 05004], lr: 0.010000, loss: 2.2251, stu_CELoss: 1.3611, DKDLoss: 0.8640, 
2022-07-29 07:59:39 - train: epoch 0031, iter [03900, 05004], lr: 0.010000, loss: 2.2351, stu_CELoss: 1.2474, DKDLoss: 0.9877, 
2022-07-29 08:00:13 - train: epoch 0031, iter [04000, 05004], lr: 0.010000, loss: 2.1525, stu_CELoss: 1.2455, DKDLoss: 0.9070, 
2022-07-29 08:00:48 - train: epoch 0031, iter [04100, 05004], lr: 0.010000, loss: 2.2767, stu_CELoss: 1.3405, DKDLoss: 0.9362, 
2022-07-29 08:01:22 - train: epoch 0031, iter [04200, 05004], lr: 0.010000, loss: 2.3908, stu_CELoss: 1.3608, DKDLoss: 1.0300, 
2022-07-29 08:01:57 - train: epoch 0031, iter [04300, 05004], lr: 0.010000, loss: 2.3258, stu_CELoss: 1.3515, DKDLoss: 0.9743, 
2022-07-29 08:02:31 - train: epoch 0031, iter [04400, 05004], lr: 0.010000, loss: 2.2554, stu_CELoss: 1.2591, DKDLoss: 0.9962, 
2022-07-29 08:03:05 - train: epoch 0031, iter [04500, 05004], lr: 0.010000, loss: 2.3843, stu_CELoss: 1.3766, DKDLoss: 1.0077, 
2022-07-29 08:03:40 - train: epoch 0031, iter [04600, 05004], lr: 0.010000, loss: 2.2224, stu_CELoss: 1.3215, DKDLoss: 0.9009, 
2022-07-29 08:04:14 - train: epoch 0031, iter [04700, 05004], lr: 0.010000, loss: 1.9681, stu_CELoss: 1.1333, DKDLoss: 0.8348, 
2022-07-29 08:04:48 - train: epoch 0031, iter [04800, 05004], lr: 0.010000, loss: 2.3437, stu_CELoss: 1.4016, DKDLoss: 0.9421, 
2022-07-29 08:05:23 - train: epoch 0031, iter [04900, 05004], lr: 0.010000, loss: 1.8924, stu_CELoss: 1.0758, DKDLoss: 0.8167, 
2022-07-29 08:05:56 - train: epoch 0031, iter [05000, 05004], lr: 0.010000, loss: 2.3251, stu_CELoss: 1.4323, DKDLoss: 0.8927, 
2022-07-29 08:05:58 - train: epoch 031, train_loss: 2.4179
2022-07-29 08:08:35 - eval: epoch: 031, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 72.010%, stu_acc5: 90.600%, stu_test_loss: 1.1145
2022-07-29 08:08:35 - until epoch: 031, tea_best_acc1: 78.068%, stu_best_acc1: 72.010%
2022-07-29 08:08:35 - epoch 032 lr: 0.010000
2022-07-29 08:09:17 - train: epoch 0032, iter [00100, 05004], lr: 0.010000, loss: 1.8809, stu_CELoss: 1.0644, DKDLoss: 0.8165, 
2022-07-29 08:09:51 - train: epoch 0032, iter [00200, 05004], lr: 0.010000, loss: 2.2245, stu_CELoss: 1.2737, DKDLoss: 0.9508, 
2022-07-29 08:10:25 - train: epoch 0032, iter [00300, 05004], lr: 0.010000, loss: 2.1624, stu_CELoss: 1.2477, DKDLoss: 0.9147, 
2022-07-29 08:10:59 - train: epoch 0032, iter [00400, 05004], lr: 0.010000, loss: 2.4139, stu_CELoss: 1.4542, DKDLoss: 0.9597, 
2022-07-29 08:11:34 - train: epoch 0032, iter [00500, 05004], lr: 0.010000, loss: 2.1212, stu_CELoss: 1.1887, DKDLoss: 0.9325, 
2022-07-29 08:12:08 - train: epoch 0032, iter [00600, 05004], lr: 0.010000, loss: 2.2936, stu_CELoss: 1.3466, DKDLoss: 0.9469, 
2022-07-29 08:12:43 - train: epoch 0032, iter [00700, 05004], lr: 0.010000, loss: 2.3025, stu_CELoss: 1.3459, DKDLoss: 0.9566, 
2022-07-29 08:13:17 - train: epoch 0032, iter [00800, 05004], lr: 0.010000, loss: 2.0871, stu_CELoss: 1.2135, DKDLoss: 0.8737, 
2022-07-29 08:13:52 - train: epoch 0032, iter [00900, 05004], lr: 0.010000, loss: 2.4180, stu_CELoss: 1.3244, DKDLoss: 1.0936, 
2022-07-29 08:14:26 - train: epoch 0032, iter [01000, 05004], lr: 0.010000, loss: 2.2422, stu_CELoss: 1.3244, DKDLoss: 0.9178, 
2022-07-29 08:15:01 - train: epoch 0032, iter [01100, 05004], lr: 0.010000, loss: 2.2483, stu_CELoss: 1.2789, DKDLoss: 0.9693, 
2022-07-29 08:15:35 - train: epoch 0032, iter [01200, 05004], lr: 0.010000, loss: 2.3012, stu_CELoss: 1.3422, DKDLoss: 0.9590, 
2022-07-29 08:16:09 - train: epoch 0032, iter [01300, 05004], lr: 0.010000, loss: 2.1405, stu_CELoss: 1.2070, DKDLoss: 0.9335, 
2022-07-29 08:16:43 - train: epoch 0032, iter [01400, 05004], lr: 0.010000, loss: 2.3377, stu_CELoss: 1.3439, DKDLoss: 0.9938, 
2022-07-29 08:17:18 - train: epoch 0032, iter [01500, 05004], lr: 0.010000, loss: 2.1279, stu_CELoss: 1.2441, DKDLoss: 0.8838, 
2022-07-29 08:17:52 - train: epoch 0032, iter [01600, 05004], lr: 0.010000, loss: 2.2672, stu_CELoss: 1.2152, DKDLoss: 1.0519, 
2022-07-29 08:18:27 - train: epoch 0032, iter [01700, 05004], lr: 0.010000, loss: 2.0902, stu_CELoss: 1.2275, DKDLoss: 0.8627, 
2022-07-29 08:19:02 - train: epoch 0032, iter [01800, 05004], lr: 0.010000, loss: 2.4226, stu_CELoss: 1.3568, DKDLoss: 1.0659, 
2022-07-29 08:19:36 - train: epoch 0032, iter [01900, 05004], lr: 0.010000, loss: 1.9305, stu_CELoss: 1.0978, DKDLoss: 0.8326, 
2022-07-29 08:20:12 - train: epoch 0032, iter [02000, 05004], lr: 0.010000, loss: 2.1925, stu_CELoss: 1.2922, DKDLoss: 0.9003, 
2022-07-29 08:20:47 - train: epoch 0032, iter [02100, 05004], lr: 0.010000, loss: 2.1554, stu_CELoss: 1.2234, DKDLoss: 0.9320, 
2022-07-29 08:21:22 - train: epoch 0032, iter [02200, 05004], lr: 0.010000, loss: 2.1891, stu_CELoss: 1.2948, DKDLoss: 0.8944, 
2022-07-29 08:21:55 - train: epoch 0032, iter [02300, 05004], lr: 0.010000, loss: 2.2172, stu_CELoss: 1.2546, DKDLoss: 0.9626, 
2022-07-29 08:22:30 - train: epoch 0032, iter [02400, 05004], lr: 0.010000, loss: 2.1174, stu_CELoss: 1.1244, DKDLoss: 0.9930, 
2022-07-29 08:23:04 - train: epoch 0032, iter [02500, 05004], lr: 0.010000, loss: 2.1911, stu_CELoss: 1.2991, DKDLoss: 0.8920, 
2022-07-29 08:23:38 - train: epoch 0032, iter [02600, 05004], lr: 0.010000, loss: 2.0496, stu_CELoss: 1.1667, DKDLoss: 0.8829, 
2022-07-29 08:24:13 - train: epoch 0032, iter [02700, 05004], lr: 0.010000, loss: 2.1377, stu_CELoss: 1.2108, DKDLoss: 0.9269, 
2022-07-29 08:24:47 - train: epoch 0032, iter [02800, 05004], lr: 0.010000, loss: 1.9925, stu_CELoss: 1.1578, DKDLoss: 0.8348, 
2022-07-29 08:25:22 - train: epoch 0032, iter [02900, 05004], lr: 0.010000, loss: 2.0265, stu_CELoss: 1.2083, DKDLoss: 0.8182, 
2022-07-29 08:25:57 - train: epoch 0032, iter [03000, 05004], lr: 0.010000, loss: 1.9714, stu_CELoss: 1.1478, DKDLoss: 0.8236, 
2022-07-29 08:26:32 - train: epoch 0032, iter [03100, 05004], lr: 0.010000, loss: 2.1365, stu_CELoss: 1.2373, DKDLoss: 0.8993, 
2022-07-29 08:27:07 - train: epoch 0032, iter [03200, 05004], lr: 0.010000, loss: 2.3868, stu_CELoss: 1.3748, DKDLoss: 1.0120, 
2022-07-29 08:27:42 - train: epoch 0032, iter [03300, 05004], lr: 0.010000, loss: 2.0642, stu_CELoss: 1.1556, DKDLoss: 0.9086, 
2022-07-29 08:28:17 - train: epoch 0032, iter [03400, 05004], lr: 0.010000, loss: 1.9618, stu_CELoss: 1.0899, DKDLoss: 0.8720, 
2022-07-29 08:28:52 - train: epoch 0032, iter [03500, 05004], lr: 0.010000, loss: 2.1014, stu_CELoss: 1.2229, DKDLoss: 0.8785, 
2022-07-29 08:29:27 - train: epoch 0032, iter [03600, 05004], lr: 0.010000, loss: 2.1123, stu_CELoss: 1.1512, DKDLoss: 0.9612, 
2022-07-29 08:30:02 - train: epoch 0032, iter [03700, 05004], lr: 0.010000, loss: 2.1685, stu_CELoss: 1.2141, DKDLoss: 0.9544, 
2022-07-29 08:30:37 - train: epoch 0032, iter [03800, 05004], lr: 0.010000, loss: 1.9498, stu_CELoss: 1.0350, DKDLoss: 0.9148, 
2022-07-29 08:31:12 - train: epoch 0032, iter [03900, 05004], lr: 0.010000, loss: 2.1837, stu_CELoss: 1.2591, DKDLoss: 0.9246, 
2022-07-29 08:31:47 - train: epoch 0032, iter [04000, 05004], lr: 0.010000, loss: 2.1535, stu_CELoss: 1.2705, DKDLoss: 0.8830, 
2022-07-29 08:32:21 - train: epoch 0032, iter [04100, 05004], lr: 0.010000, loss: 2.1723, stu_CELoss: 1.2717, DKDLoss: 0.9006, 
2022-07-29 08:32:56 - train: epoch 0032, iter [04200, 05004], lr: 0.010000, loss: 2.0532, stu_CELoss: 1.0973, DKDLoss: 0.9559, 
2022-07-29 08:33:30 - train: epoch 0032, iter [04300, 05004], lr: 0.010000, loss: 2.4443, stu_CELoss: 1.4273, DKDLoss: 1.0170, 
2022-07-29 08:34:05 - train: epoch 0032, iter [04400, 05004], lr: 0.010000, loss: 2.0877, stu_CELoss: 1.1742, DKDLoss: 0.9135, 
2022-07-29 08:34:39 - train: epoch 0032, iter [04500, 05004], lr: 0.010000, loss: 2.2520, stu_CELoss: 1.3264, DKDLoss: 0.9256, 
2022-07-29 08:35:14 - train: epoch 0032, iter [04600, 05004], lr: 0.010000, loss: 2.2293, stu_CELoss: 1.2957, DKDLoss: 0.9336, 
2022-07-29 08:35:48 - train: epoch 0032, iter [04700, 05004], lr: 0.010000, loss: 2.3369, stu_CELoss: 1.3897, DKDLoss: 0.9472, 
2022-07-29 08:36:23 - train: epoch 0032, iter [04800, 05004], lr: 0.010000, loss: 2.0748, stu_CELoss: 1.2230, DKDLoss: 0.8518, 
2022-07-29 08:36:58 - train: epoch 0032, iter [04900, 05004], lr: 0.010000, loss: 2.3424, stu_CELoss: 1.4206, DKDLoss: 0.9218, 
2022-07-29 08:37:32 - train: epoch 0032, iter [05000, 05004], lr: 0.010000, loss: 2.0331, stu_CELoss: 1.1845, DKDLoss: 0.8486, 
2022-07-29 08:37:34 - train: epoch 032, train_loss: 2.1670
2022-07-29 08:40:09 - eval: epoch: 032, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 72.942%, stu_acc5: 91.148%, stu_test_loss: 1.0713
2022-07-29 08:40:10 - until epoch: 032, tea_best_acc1: 78.068%, stu_best_acc1: 72.942%
2022-07-29 08:40:10 - epoch 033 lr: 0.010000
2022-07-29 08:40:51 - train: epoch 0033, iter [00100, 05004], lr: 0.010000, loss: 1.9882, stu_CELoss: 1.1165, DKDLoss: 0.8718, 
2022-07-29 08:41:26 - train: epoch 0033, iter [00200, 05004], lr: 0.010000, loss: 2.2881, stu_CELoss: 1.2727, DKDLoss: 1.0154, 
2022-07-29 08:42:01 - train: epoch 0033, iter [00300, 05004], lr: 0.010000, loss: 2.1394, stu_CELoss: 1.2449, DKDLoss: 0.8946, 
2022-07-29 08:42:35 - train: epoch 0033, iter [00400, 05004], lr: 0.010000, loss: 2.1283, stu_CELoss: 1.2713, DKDLoss: 0.8571, 
2022-07-29 08:43:09 - train: epoch 0033, iter [00500, 05004], lr: 0.010000, loss: 2.0304, stu_CELoss: 1.1990, DKDLoss: 0.8314, 
2022-07-29 08:43:43 - train: epoch 0033, iter [00600, 05004], lr: 0.010000, loss: 1.9849, stu_CELoss: 1.1886, DKDLoss: 0.7963, 
2022-07-29 08:44:18 - train: epoch 0033, iter [00700, 05004], lr: 0.010000, loss: 2.1659, stu_CELoss: 1.2906, DKDLoss: 0.8754, 
2022-07-29 08:44:52 - train: epoch 0033, iter [00800, 05004], lr: 0.010000, loss: 2.1913, stu_CELoss: 1.2891, DKDLoss: 0.9022, 
2022-07-29 08:45:26 - train: epoch 0033, iter [00900, 05004], lr: 0.010000, loss: 2.1319, stu_CELoss: 1.2824, DKDLoss: 0.8495, 
2022-07-29 08:46:01 - train: epoch 0033, iter [01000, 05004], lr: 0.010000, loss: 2.2598, stu_CELoss: 1.3684, DKDLoss: 0.8914, 
2022-07-29 08:46:35 - train: epoch 0033, iter [01100, 05004], lr: 0.010000, loss: 1.9686, stu_CELoss: 1.1529, DKDLoss: 0.8157, 
2022-07-29 08:47:10 - train: epoch 0033, iter [01200, 05004], lr: 0.010000, loss: 2.3291, stu_CELoss: 1.4403, DKDLoss: 0.8888, 
2022-07-29 08:47:44 - train: epoch 0033, iter [01300, 05004], lr: 0.010000, loss: 2.1237, stu_CELoss: 1.2451, DKDLoss: 0.8785, 
2022-07-29 08:48:19 - train: epoch 0033, iter [01400, 05004], lr: 0.010000, loss: 2.1419, stu_CELoss: 1.2465, DKDLoss: 0.8954, 
2022-07-29 08:48:54 - train: epoch 0033, iter [01500, 05004], lr: 0.010000, loss: 2.2755, stu_CELoss: 1.3316, DKDLoss: 0.9439, 
2022-07-29 08:49:28 - train: epoch 0033, iter [01600, 05004], lr: 0.010000, loss: 2.5237, stu_CELoss: 1.5100, DKDLoss: 1.0136, 
2022-07-29 08:50:02 - train: epoch 0033, iter [01700, 05004], lr: 0.010000, loss: 2.0298, stu_CELoss: 1.2006, DKDLoss: 0.8292, 
2022-07-29 08:50:37 - train: epoch 0033, iter [01800, 05004], lr: 0.010000, loss: 2.1981, stu_CELoss: 1.2300, DKDLoss: 0.9681, 
2022-07-29 08:51:11 - train: epoch 0033, iter [01900, 05004], lr: 0.010000, loss: 2.1551, stu_CELoss: 1.3085, DKDLoss: 0.8467, 
2022-07-29 08:51:45 - train: epoch 0033, iter [02000, 05004], lr: 0.010000, loss: 1.9342, stu_CELoss: 1.0925, DKDLoss: 0.8418, 
2022-07-29 08:52:19 - train: epoch 0033, iter [02100, 05004], lr: 0.010000, loss: 2.0090, stu_CELoss: 1.1600, DKDLoss: 0.8491, 
2022-07-29 08:52:53 - train: epoch 0033, iter [02200, 05004], lr: 0.010000, loss: 2.2800, stu_CELoss: 1.3069, DKDLoss: 0.9731, 
2022-07-29 08:53:28 - train: epoch 0033, iter [02300, 05004], lr: 0.010000, loss: 2.0719, stu_CELoss: 1.2341, DKDLoss: 0.8378, 
2022-07-29 08:54:02 - train: epoch 0033, iter [02400, 05004], lr: 0.010000, loss: 2.1256, stu_CELoss: 1.2045, DKDLoss: 0.9211, 
2022-07-29 08:54:37 - train: epoch 0033, iter [02500, 05004], lr: 0.010000, loss: 1.9865, stu_CELoss: 1.1423, DKDLoss: 0.8443, 
2022-07-29 08:55:11 - train: epoch 0033, iter [02600, 05004], lr: 0.010000, loss: 1.9386, stu_CELoss: 1.0895, DKDLoss: 0.8491, 
2022-07-29 08:55:46 - train: epoch 0033, iter [02700, 05004], lr: 0.010000, loss: 2.0787, stu_CELoss: 1.2380, DKDLoss: 0.8407, 
2022-07-29 08:56:20 - train: epoch 0033, iter [02800, 05004], lr: 0.010000, loss: 2.0817, stu_CELoss: 1.1783, DKDLoss: 0.9034, 
2022-07-29 08:56:54 - train: epoch 0033, iter [02900, 05004], lr: 0.010000, loss: 1.8908, stu_CELoss: 1.1203, DKDLoss: 0.7705, 
2022-07-29 08:57:29 - train: epoch 0033, iter [03000, 05004], lr: 0.010000, loss: 2.0182, stu_CELoss: 1.2364, DKDLoss: 0.7818, 
2022-07-29 08:58:03 - train: epoch 0033, iter [03100, 05004], lr: 0.010000, loss: 1.9622, stu_CELoss: 1.1430, DKDLoss: 0.8193, 
2022-07-29 08:58:37 - train: epoch 0033, iter [03200, 05004], lr: 0.010000, loss: 2.1954, stu_CELoss: 1.2448, DKDLoss: 0.9506, 
2022-07-29 08:59:12 - train: epoch 0033, iter [03300, 05004], lr: 0.010000, loss: 1.9595, stu_CELoss: 1.1248, DKDLoss: 0.8347, 
2022-07-29 08:59:46 - train: epoch 0033, iter [03400, 05004], lr: 0.010000, loss: 2.0220, stu_CELoss: 1.1957, DKDLoss: 0.8263, 
2022-07-29 09:00:21 - train: epoch 0033, iter [03500, 05004], lr: 0.010000, loss: 2.0201, stu_CELoss: 1.1559, DKDLoss: 0.8642, 
2022-07-29 09:00:55 - train: epoch 0033, iter [03600, 05004], lr: 0.010000, loss: 2.3577, stu_CELoss: 1.3947, DKDLoss: 0.9631, 
2022-07-29 09:01:30 - train: epoch 0033, iter [03700, 05004], lr: 0.010000, loss: 1.9077, stu_CELoss: 1.1042, DKDLoss: 0.8036, 
2022-07-29 09:02:04 - train: epoch 0033, iter [03800, 05004], lr: 0.010000, loss: 1.7605, stu_CELoss: 1.0126, DKDLoss: 0.7479, 
2022-07-29 09:02:39 - train: epoch 0033, iter [03900, 05004], lr: 0.010000, loss: 2.2097, stu_CELoss: 1.2647, DKDLoss: 0.9450, 
2022-07-29 09:03:14 - train: epoch 0033, iter [04000, 05004], lr: 0.010000, loss: 2.3605, stu_CELoss: 1.4361, DKDLoss: 0.9244, 
2022-07-29 09:03:49 - train: epoch 0033, iter [04100, 05004], lr: 0.010000, loss: 2.0419, stu_CELoss: 1.1431, DKDLoss: 0.8988, 
2022-07-29 09:04:23 - train: epoch 0033, iter [04200, 05004], lr: 0.010000, loss: 1.8807, stu_CELoss: 1.0660, DKDLoss: 0.8147, 
2022-07-29 09:04:57 - train: epoch 0033, iter [04300, 05004], lr: 0.010000, loss: 2.0730, stu_CELoss: 1.1987, DKDLoss: 0.8744, 
2022-07-29 09:05:32 - train: epoch 0033, iter [04400, 05004], lr: 0.010000, loss: 2.2245, stu_CELoss: 1.3429, DKDLoss: 0.8816, 
2022-07-29 09:06:06 - train: epoch 0033, iter [04500, 05004], lr: 0.010000, loss: 2.2215, stu_CELoss: 1.2846, DKDLoss: 0.9369, 
2022-07-29 09:06:41 - train: epoch 0033, iter [04600, 05004], lr: 0.010000, loss: 1.9442, stu_CELoss: 1.0979, DKDLoss: 0.8463, 
2022-07-29 09:07:16 - train: epoch 0033, iter [04700, 05004], lr: 0.010000, loss: 1.9115, stu_CELoss: 1.0374, DKDLoss: 0.8741, 
2022-07-29 09:07:50 - train: epoch 0033, iter [04800, 05004], lr: 0.010000, loss: 2.0445, stu_CELoss: 1.1916, DKDLoss: 0.8529, 
2022-07-29 09:08:25 - train: epoch 0033, iter [04900, 05004], lr: 0.010000, loss: 1.8200, stu_CELoss: 1.0359, DKDLoss: 0.7841, 
2022-07-29 09:08:59 - train: epoch 0033, iter [05000, 05004], lr: 0.010000, loss: 2.0254, stu_CELoss: 1.1414, DKDLoss: 0.8841, 
2022-07-29 09:09:01 - train: epoch 033, train_loss: 2.0637
2022-07-29 09:11:37 - eval: epoch: 033, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 73.558%, stu_acc5: 91.450%, stu_test_loss: 1.0516
2022-07-29 09:11:38 - until epoch: 033, tea_best_acc1: 78.068%, stu_best_acc1: 73.558%
2022-07-29 09:11:38 - epoch 034 lr: 0.010000
2022-07-29 09:12:19 - train: epoch 0034, iter [00100, 05004], lr: 0.010000, loss: 2.0682, stu_CELoss: 1.2165, DKDLoss: 0.8517, 
2022-07-29 09:12:53 - train: epoch 0034, iter [00200, 05004], lr: 0.010000, loss: 1.8168, stu_CELoss: 1.0081, DKDLoss: 0.8088, 
2022-07-29 09:13:27 - train: epoch 0034, iter [00300, 05004], lr: 0.010000, loss: 1.9603, stu_CELoss: 1.1865, DKDLoss: 0.7738, 
2022-07-29 09:14:01 - train: epoch 0034, iter [00400, 05004], lr: 0.010000, loss: 1.6370, stu_CELoss: 0.9340, DKDLoss: 0.7030, 
2022-07-29 09:14:36 - train: epoch 0034, iter [00500, 05004], lr: 0.010000, loss: 2.2031, stu_CELoss: 1.3295, DKDLoss: 0.8736, 
2022-07-29 09:15:11 - train: epoch 0034, iter [00600, 05004], lr: 0.010000, loss: 2.1242, stu_CELoss: 1.2712, DKDLoss: 0.8529, 
2022-07-29 09:15:45 - train: epoch 0034, iter [00700, 05004], lr: 0.010000, loss: 1.8207, stu_CELoss: 1.0573, DKDLoss: 0.7634, 
2022-07-29 09:16:20 - train: epoch 0034, iter [00800, 05004], lr: 0.010000, loss: 2.1565, stu_CELoss: 1.4012, DKDLoss: 0.7553, 
2022-07-29 09:16:55 - train: epoch 0034, iter [00900, 05004], lr: 0.010000, loss: 1.9411, stu_CELoss: 1.1681, DKDLoss: 0.7729, 
2022-07-29 09:17:29 - train: epoch 0034, iter [01000, 05004], lr: 0.010000, loss: 1.9999, stu_CELoss: 1.2466, DKDLoss: 0.7533, 
2022-07-29 09:18:04 - train: epoch 0034, iter [01100, 05004], lr: 0.010000, loss: 1.9359, stu_CELoss: 1.1211, DKDLoss: 0.8148, 
2022-07-29 09:18:39 - train: epoch 0034, iter [01200, 05004], lr: 0.010000, loss: 2.0583, stu_CELoss: 1.2176, DKDLoss: 0.8407, 
2022-07-29 09:19:14 - train: epoch 0034, iter [01300, 05004], lr: 0.010000, loss: 2.1258, stu_CELoss: 1.2744, DKDLoss: 0.8515, 
2022-07-29 09:19:48 - train: epoch 0034, iter [01400, 05004], lr: 0.010000, loss: 2.0942, stu_CELoss: 1.2724, DKDLoss: 0.8218, 
2022-07-29 09:20:23 - train: epoch 0034, iter [01500, 05004], lr: 0.010000, loss: 2.0166, stu_CELoss: 1.2130, DKDLoss: 0.8036, 
2022-07-29 09:20:58 - train: epoch 0034, iter [01600, 05004], lr: 0.010000, loss: 2.0029, stu_CELoss: 1.1115, DKDLoss: 0.8914, 
2022-07-29 09:21:32 - train: epoch 0034, iter [01700, 05004], lr: 0.010000, loss: 2.1271, stu_CELoss: 1.2276, DKDLoss: 0.8995, 
2022-07-29 09:22:07 - train: epoch 0034, iter [01800, 05004], lr: 0.010000, loss: 2.0460, stu_CELoss: 1.2172, DKDLoss: 0.8288, 
2022-07-29 09:22:42 - train: epoch 0034, iter [01900, 05004], lr: 0.010000, loss: 2.0995, stu_CELoss: 1.2711, DKDLoss: 0.8284, 
2022-07-29 09:23:16 - train: epoch 0034, iter [02000, 05004], lr: 0.010000, loss: 1.9137, stu_CELoss: 1.0823, DKDLoss: 0.8314, 
2022-07-29 09:23:51 - train: epoch 0034, iter [02100, 05004], lr: 0.010000, loss: 2.0926, stu_CELoss: 1.2321, DKDLoss: 0.8605, 
2022-07-29 09:24:25 - train: epoch 0034, iter [02200, 05004], lr: 0.010000, loss: 1.6348, stu_CELoss: 0.8984, DKDLoss: 0.7364, 
2022-07-29 09:25:00 - train: epoch 0034, iter [02300, 05004], lr: 0.010000, loss: 1.9136, stu_CELoss: 1.1004, DKDLoss: 0.8132, 
2022-07-29 09:25:35 - train: epoch 0034, iter [02400, 05004], lr: 0.010000, loss: 1.6765, stu_CELoss: 0.9614, DKDLoss: 0.7151, 
2022-07-29 09:26:09 - train: epoch 0034, iter [02500, 05004], lr: 0.010000, loss: 2.2059, stu_CELoss: 1.2715, DKDLoss: 0.9344, 
2022-07-29 09:26:44 - train: epoch 0034, iter [02600, 05004], lr: 0.010000, loss: 2.3100, stu_CELoss: 1.3717, DKDLoss: 0.9383, 
2022-07-29 09:27:19 - train: epoch 0034, iter [02700, 05004], lr: 0.010000, loss: 2.1929, stu_CELoss: 1.2584, DKDLoss: 0.9345, 
2022-07-29 09:27:53 - train: epoch 0034, iter [02800, 05004], lr: 0.010000, loss: 1.7922, stu_CELoss: 1.0873, DKDLoss: 0.7049, 
2022-07-29 09:28:27 - train: epoch 0034, iter [02900, 05004], lr: 0.010000, loss: 1.8922, stu_CELoss: 1.1168, DKDLoss: 0.7754, 
2022-07-29 09:29:02 - train: epoch 0034, iter [03000, 05004], lr: 0.010000, loss: 1.9325, stu_CELoss: 1.1244, DKDLoss: 0.8081, 
2022-07-29 09:29:36 - train: epoch 0034, iter [03100, 05004], lr: 0.010000, loss: 1.9142, stu_CELoss: 1.0977, DKDLoss: 0.8165, 
2022-07-29 09:30:10 - train: epoch 0034, iter [03200, 05004], lr: 0.010000, loss: 2.0877, stu_CELoss: 1.2998, DKDLoss: 0.7879, 
2022-07-29 09:30:45 - train: epoch 0034, iter [03300, 05004], lr: 0.010000, loss: 2.0066, stu_CELoss: 1.1205, DKDLoss: 0.8861, 
2022-07-29 09:31:19 - train: epoch 0034, iter [03400, 05004], lr: 0.010000, loss: 1.9303, stu_CELoss: 1.0832, DKDLoss: 0.8471, 
2022-07-29 09:31:53 - train: epoch 0034, iter [03500, 05004], lr: 0.010000, loss: 1.7637, stu_CELoss: 0.9997, DKDLoss: 0.7640, 
2022-07-29 09:32:28 - train: epoch 0034, iter [03600, 05004], lr: 0.010000, loss: 1.7394, stu_CELoss: 0.9762, DKDLoss: 0.7632, 
2022-07-29 09:33:02 - train: epoch 0034, iter [03700, 05004], lr: 0.010000, loss: 1.8493, stu_CELoss: 1.0335, DKDLoss: 0.8158, 
2022-07-29 09:33:36 - train: epoch 0034, iter [03800, 05004], lr: 0.010000, loss: 1.9623, stu_CELoss: 1.1545, DKDLoss: 0.8077, 
2022-07-29 09:34:09 - train: epoch 0034, iter [03900, 05004], lr: 0.010000, loss: 2.1819, stu_CELoss: 1.3381, DKDLoss: 0.8439, 
2022-07-29 09:34:44 - train: epoch 0034, iter [04000, 05004], lr: 0.010000, loss: 1.9811, stu_CELoss: 1.2551, DKDLoss: 0.7260, 
2022-07-29 09:35:18 - train: epoch 0034, iter [04100, 05004], lr: 0.010000, loss: 2.3013, stu_CELoss: 1.3121, DKDLoss: 0.9892, 
2022-07-29 09:35:51 - train: epoch 0034, iter [04200, 05004], lr: 0.010000, loss: 1.9335, stu_CELoss: 1.0776, DKDLoss: 0.8558, 
2022-07-29 09:36:25 - train: epoch 0034, iter [04300, 05004], lr: 0.010000, loss: 2.0662, stu_CELoss: 1.2554, DKDLoss: 0.8108, 
2022-07-29 09:36:58 - train: epoch 0034, iter [04400, 05004], lr: 0.010000, loss: 2.0114, stu_CELoss: 1.1298, DKDLoss: 0.8816, 
2022-07-29 09:37:31 - train: epoch 0034, iter [04500, 05004], lr: 0.010000, loss: 2.1159, stu_CELoss: 1.3075, DKDLoss: 0.8084, 
2022-07-29 09:38:04 - train: epoch 0034, iter [04600, 05004], lr: 0.010000, loss: 2.1334, stu_CELoss: 1.1493, DKDLoss: 0.9841, 
2022-07-29 09:38:37 - train: epoch 0034, iter [04700, 05004], lr: 0.010000, loss: 2.0394, stu_CELoss: 1.1314, DKDLoss: 0.9079, 
2022-07-29 09:39:10 - train: epoch 0034, iter [04800, 05004], lr: 0.010000, loss: 2.3933, stu_CELoss: 1.4768, DKDLoss: 0.9165, 
2022-07-29 09:39:44 - train: epoch 0034, iter [04900, 05004], lr: 0.010000, loss: 1.9650, stu_CELoss: 1.1515, DKDLoss: 0.8135, 
2022-07-29 09:40:17 - train: epoch 0034, iter [05000, 05004], lr: 0.010000, loss: 1.8011, stu_CELoss: 0.9968, DKDLoss: 0.8043, 
2022-07-29 09:40:19 - train: epoch 034, train_loss: 1.9957
2022-07-29 09:42:50 - eval: epoch: 034, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 73.528%, stu_acc5: 91.674%, stu_test_loss: 1.0418
2022-07-29 09:42:51 - until epoch: 034, tea_best_acc1: 78.068%, stu_best_acc1: 73.558%
2022-07-29 09:42:51 - epoch 035 lr: 0.010000
2022-07-29 09:43:31 - train: epoch 0035, iter [00100, 05004], lr: 0.010000, loss: 1.7569, stu_CELoss: 0.9900, DKDLoss: 0.7669, 
2022-07-29 09:44:03 - train: epoch 0035, iter [00200, 05004], lr: 0.010000, loss: 1.8147, stu_CELoss: 0.9777, DKDLoss: 0.8370, 
2022-07-29 09:44:35 - train: epoch 0035, iter [00300, 05004], lr: 0.010000, loss: 2.0754, stu_CELoss: 1.2334, DKDLoss: 0.8420, 
2022-07-29 09:45:08 - train: epoch 0035, iter [00400, 05004], lr: 0.010000, loss: 1.9200, stu_CELoss: 1.1100, DKDLoss: 0.8100, 
2022-07-29 09:45:41 - train: epoch 0035, iter [00500, 05004], lr: 0.010000, loss: 1.9079, stu_CELoss: 1.0993, DKDLoss: 0.8086, 
2022-07-29 09:46:14 - train: epoch 0035, iter [00600, 05004], lr: 0.010000, loss: 1.8924, stu_CELoss: 1.0938, DKDLoss: 0.7986, 
2022-07-29 09:46:47 - train: epoch 0035, iter [00700, 05004], lr: 0.010000, loss: 1.7502, stu_CELoss: 1.0287, DKDLoss: 0.7215, 
2022-07-29 09:47:19 - train: epoch 0035, iter [00800, 05004], lr: 0.010000, loss: 1.9768, stu_CELoss: 1.2212, DKDLoss: 0.7556, 
2022-07-29 09:47:53 - train: epoch 0035, iter [00900, 05004], lr: 0.010000, loss: 2.0758, stu_CELoss: 1.2205, DKDLoss: 0.8554, 
2022-07-29 09:48:26 - train: epoch 0035, iter [01000, 05004], lr: 0.010000, loss: 1.8440, stu_CELoss: 1.1411, DKDLoss: 0.7028, 
2022-07-29 09:48:59 - train: epoch 0035, iter [01100, 05004], lr: 0.010000, loss: 1.9536, stu_CELoss: 1.1593, DKDLoss: 0.7943, 
2022-07-29 09:49:31 - train: epoch 0035, iter [01200, 05004], lr: 0.010000, loss: 1.9010, stu_CELoss: 1.0821, DKDLoss: 0.8189, 
2022-07-29 09:50:04 - train: epoch 0035, iter [01300, 05004], lr: 0.010000, loss: 1.7899, stu_CELoss: 1.0430, DKDLoss: 0.7468, 
2022-07-29 09:50:37 - train: epoch 0035, iter [01400, 05004], lr: 0.010000, loss: 1.9990, stu_CELoss: 1.2016, DKDLoss: 0.7974, 
2022-07-29 09:51:11 - train: epoch 0035, iter [01500, 05004], lr: 0.010000, loss: 1.9328, stu_CELoss: 1.1067, DKDLoss: 0.8261, 
2022-07-29 09:51:44 - train: epoch 0035, iter [01600, 05004], lr: 0.010000, loss: 1.8740, stu_CELoss: 1.0754, DKDLoss: 0.7986, 
2022-07-29 09:52:17 - train: epoch 0035, iter [01700, 05004], lr: 0.010000, loss: 1.8029, stu_CELoss: 1.0612, DKDLoss: 0.7417, 
2022-07-29 09:52:50 - train: epoch 0035, iter [01800, 05004], lr: 0.010000, loss: 2.0634, stu_CELoss: 1.1839, DKDLoss: 0.8795, 
2022-07-29 09:53:23 - train: epoch 0035, iter [01900, 05004], lr: 0.010000, loss: 2.0121, stu_CELoss: 1.1276, DKDLoss: 0.8844, 
2022-07-29 09:53:56 - train: epoch 0035, iter [02000, 05004], lr: 0.010000, loss: 2.0471, stu_CELoss: 1.2149, DKDLoss: 0.8322, 
2022-07-29 09:54:29 - train: epoch 0035, iter [02100, 05004], lr: 0.010000, loss: 1.8284, stu_CELoss: 1.0772, DKDLoss: 0.7512, 
2022-07-29 09:55:03 - train: epoch 0035, iter [02200, 05004], lr: 0.010000, loss: 1.9401, stu_CELoss: 1.1652, DKDLoss: 0.7749, 
2022-07-29 09:55:36 - train: epoch 0035, iter [02300, 05004], lr: 0.010000, loss: 1.9787, stu_CELoss: 1.1467, DKDLoss: 0.8320, 
2022-07-29 09:56:09 - train: epoch 0035, iter [02400, 05004], lr: 0.010000, loss: 2.1307, stu_CELoss: 1.2988, DKDLoss: 0.8319, 
2022-07-29 09:56:43 - train: epoch 0035, iter [02500, 05004], lr: 0.010000, loss: 1.9814, stu_CELoss: 1.1074, DKDLoss: 0.8740, 
2022-07-29 09:57:16 - train: epoch 0035, iter [02600, 05004], lr: 0.010000, loss: 2.3005, stu_CELoss: 1.3591, DKDLoss: 0.9414, 
2022-07-29 09:57:50 - train: epoch 0035, iter [02700, 05004], lr: 0.010000, loss: 1.9323, stu_CELoss: 1.1163, DKDLoss: 0.8161, 
2022-07-29 09:58:23 - train: epoch 0035, iter [02800, 05004], lr: 0.010000, loss: 1.8843, stu_CELoss: 1.0734, DKDLoss: 0.8109, 
2022-07-29 09:58:57 - train: epoch 0035, iter [02900, 05004], lr: 0.010000, loss: 1.8789, stu_CELoss: 1.0908, DKDLoss: 0.7881, 
2022-07-29 09:59:30 - train: epoch 0035, iter [03000, 05004], lr: 0.010000, loss: 1.9325, stu_CELoss: 1.1785, DKDLoss: 0.7540, 
2022-07-29 10:00:03 - train: epoch 0035, iter [03100, 05004], lr: 0.010000, loss: 1.8607, stu_CELoss: 1.1711, DKDLoss: 0.6896, 
2022-07-29 10:00:37 - train: epoch 0035, iter [03200, 05004], lr: 0.010000, loss: 1.7920, stu_CELoss: 1.0444, DKDLoss: 0.7476, 
2022-07-29 10:01:10 - train: epoch 0035, iter [03300, 05004], lr: 0.010000, loss: 1.7538, stu_CELoss: 1.0096, DKDLoss: 0.7442, 
2022-07-29 10:01:43 - train: epoch 0035, iter [03400, 05004], lr: 0.010000, loss: 2.0044, stu_CELoss: 1.1956, DKDLoss: 0.8088, 
2022-07-29 10:02:16 - train: epoch 0035, iter [03500, 05004], lr: 0.010000, loss: 1.8556, stu_CELoss: 1.1015, DKDLoss: 0.7541, 
2022-07-29 10:02:50 - train: epoch 0035, iter [03600, 05004], lr: 0.010000, loss: 1.9200, stu_CELoss: 1.0150, DKDLoss: 0.9050, 
2022-07-29 10:03:23 - train: epoch 0035, iter [03700, 05004], lr: 0.010000, loss: 1.7830, stu_CELoss: 1.0235, DKDLoss: 0.7595, 
2022-07-29 10:03:57 - train: epoch 0035, iter [03800, 05004], lr: 0.010000, loss: 1.9715, stu_CELoss: 1.1586, DKDLoss: 0.8128, 
2022-07-29 10:04:31 - train: epoch 0035, iter [03900, 05004], lr: 0.010000, loss: 1.9395, stu_CELoss: 1.1715, DKDLoss: 0.7680, 
2022-07-29 10:05:04 - train: epoch 0035, iter [04000, 05004], lr: 0.010000, loss: 1.6455, stu_CELoss: 0.9264, DKDLoss: 0.7190, 
2022-07-29 10:05:37 - train: epoch 0035, iter [04100, 05004], lr: 0.010000, loss: 2.0026, stu_CELoss: 1.1310, DKDLoss: 0.8716, 
2022-07-29 10:06:11 - train: epoch 0035, iter [04200, 05004], lr: 0.010000, loss: 1.8810, stu_CELoss: 1.0599, DKDLoss: 0.8211, 
2022-07-29 10:06:44 - train: epoch 0035, iter [04300, 05004], lr: 0.010000, loss: 2.2949, stu_CELoss: 1.3350, DKDLoss: 0.9599, 
2022-07-29 10:07:17 - train: epoch 0035, iter [04400, 05004], lr: 0.010000, loss: 2.2991, stu_CELoss: 1.3640, DKDLoss: 0.9351, 
2022-07-29 10:07:51 - train: epoch 0035, iter [04500, 05004], lr: 0.010000, loss: 1.8332, stu_CELoss: 1.1004, DKDLoss: 0.7328, 
2022-07-29 10:08:24 - train: epoch 0035, iter [04600, 05004], lr: 0.010000, loss: 2.0219, stu_CELoss: 1.2190, DKDLoss: 0.8029, 
2022-07-29 10:08:57 - train: epoch 0035, iter [04700, 05004], lr: 0.010000, loss: 2.1463, stu_CELoss: 1.2855, DKDLoss: 0.8608, 
2022-07-29 10:09:31 - train: epoch 0035, iter [04800, 05004], lr: 0.010000, loss: 1.8411, stu_CELoss: 1.0388, DKDLoss: 0.8023, 
2022-07-29 10:10:05 - train: epoch 0035, iter [04900, 05004], lr: 0.010000, loss: 1.8526, stu_CELoss: 1.0294, DKDLoss: 0.8233, 
2022-07-29 10:10:38 - train: epoch 0035, iter [05000, 05004], lr: 0.010000, loss: 1.7196, stu_CELoss: 0.9869, DKDLoss: 0.7327, 
2022-07-29 10:10:39 - train: epoch 035, train_loss: 1.9449
2022-07-29 10:13:12 - eval: epoch: 035, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 74.004%, stu_acc5: 91.708%, stu_test_loss: 1.0307
2022-07-29 10:13:13 - until epoch: 035, tea_best_acc1: 78.068%, stu_best_acc1: 74.004%
2022-07-29 10:13:13 - epoch 036 lr: 0.010000
2022-07-29 10:13:53 - train: epoch 0036, iter [00100, 05004], lr: 0.010000, loss: 2.0065, stu_CELoss: 1.1962, DKDLoss: 0.8102, 
2022-07-29 10:14:26 - train: epoch 0036, iter [00200, 05004], lr: 0.010000, loss: 1.5931, stu_CELoss: 0.8954, DKDLoss: 0.6976, 
2022-07-29 10:14:59 - train: epoch 0036, iter [00300, 05004], lr: 0.010000, loss: 1.7183, stu_CELoss: 1.0060, DKDLoss: 0.7123, 
2022-07-29 10:15:32 - train: epoch 0036, iter [00400, 05004], lr: 0.010000, loss: 1.8444, stu_CELoss: 1.0695, DKDLoss: 0.7750, 
2022-07-29 10:16:05 - train: epoch 0036, iter [00500, 05004], lr: 0.010000, loss: 1.9947, stu_CELoss: 1.2106, DKDLoss: 0.7842, 
2022-07-29 10:16:39 - train: epoch 0036, iter [00600, 05004], lr: 0.010000, loss: 1.9497, stu_CELoss: 1.1589, DKDLoss: 0.7908, 
2022-07-29 10:17:12 - train: epoch 0036, iter [00700, 05004], lr: 0.010000, loss: 1.7202, stu_CELoss: 0.9514, DKDLoss: 0.7688, 
2022-07-29 10:17:46 - train: epoch 0036, iter [00800, 05004], lr: 0.010000, loss: 1.6754, stu_CELoss: 0.9698, DKDLoss: 0.7056, 
2022-07-29 10:18:20 - train: epoch 0036, iter [00900, 05004], lr: 0.010000, loss: 1.9564, stu_CELoss: 1.1667, DKDLoss: 0.7897, 
2022-07-29 10:18:53 - train: epoch 0036, iter [01000, 05004], lr: 0.010000, loss: 1.9197, stu_CELoss: 1.1294, DKDLoss: 0.7903, 
2022-07-29 10:19:27 - train: epoch 0036, iter [01100, 05004], lr: 0.010000, loss: 2.0157, stu_CELoss: 1.2674, DKDLoss: 0.7484, 
2022-07-29 10:20:01 - train: epoch 0036, iter [01200, 05004], lr: 0.010000, loss: 1.8484, stu_CELoss: 1.0825, DKDLoss: 0.7658, 
2022-07-29 10:20:35 - train: epoch 0036, iter [01300, 05004], lr: 0.010000, loss: 1.8154, stu_CELoss: 1.0262, DKDLoss: 0.7892, 
2022-07-29 10:21:09 - train: epoch 0036, iter [01400, 05004], lr: 0.010000, loss: 1.9335, stu_CELoss: 1.1340, DKDLoss: 0.7996, 
2022-07-29 10:21:43 - train: epoch 0036, iter [01500, 05004], lr: 0.010000, loss: 1.8994, stu_CELoss: 1.0784, DKDLoss: 0.8210, 
2022-07-29 10:22:17 - train: epoch 0036, iter [01600, 05004], lr: 0.010000, loss: 1.9526, stu_CELoss: 1.1848, DKDLoss: 0.7678, 
2022-07-29 10:22:50 - train: epoch 0036, iter [01700, 05004], lr: 0.010000, loss: 1.8259, stu_CELoss: 1.0513, DKDLoss: 0.7746, 
2022-07-29 10:23:24 - train: epoch 0036, iter [01800, 05004], lr: 0.010000, loss: 1.9663, stu_CELoss: 1.1991, DKDLoss: 0.7672, 
2022-07-29 10:23:57 - train: epoch 0036, iter [01900, 05004], lr: 0.010000, loss: 2.0699, stu_CELoss: 1.1485, DKDLoss: 0.9214, 
2022-07-29 10:24:31 - train: epoch 0036, iter [02000, 05004], lr: 0.010000, loss: 1.9596, stu_CELoss: 1.2180, DKDLoss: 0.7416, 
2022-07-29 10:25:05 - train: epoch 0036, iter [02100, 05004], lr: 0.010000, loss: 1.8863, stu_CELoss: 1.1519, DKDLoss: 0.7344, 
2022-07-29 10:25:39 - train: epoch 0036, iter [02200, 05004], lr: 0.010000, loss: 2.0041, stu_CELoss: 1.1573, DKDLoss: 0.8468, 
2022-07-29 10:26:13 - train: epoch 0036, iter [02300, 05004], lr: 0.010000, loss: 2.0736, stu_CELoss: 1.2875, DKDLoss: 0.7861, 
2022-07-29 10:26:47 - train: epoch 0036, iter [02400, 05004], lr: 0.010000, loss: 1.9549, stu_CELoss: 1.1726, DKDLoss: 0.7822, 
2022-07-29 10:27:21 - train: epoch 0036, iter [02500, 05004], lr: 0.010000, loss: 1.8437, stu_CELoss: 1.0834, DKDLoss: 0.7604, 
2022-07-29 10:27:54 - train: epoch 0036, iter [02600, 05004], lr: 0.010000, loss: 1.8628, stu_CELoss: 1.1118, DKDLoss: 0.7509, 
2022-07-29 10:28:28 - train: epoch 0036, iter [02700, 05004], lr: 0.010000, loss: 1.7008, stu_CELoss: 0.9185, DKDLoss: 0.7823, 
2022-07-29 10:29:01 - train: epoch 0036, iter [02800, 05004], lr: 0.010000, loss: 1.8533, stu_CELoss: 1.0987, DKDLoss: 0.7546, 
2022-07-29 10:29:35 - train: epoch 0036, iter [02900, 05004], lr: 0.010000, loss: 1.7186, stu_CELoss: 1.0075, DKDLoss: 0.7111, 
2022-07-29 10:30:09 - train: epoch 0036, iter [03000, 05004], lr: 0.010000, loss: 1.9624, stu_CELoss: 1.1706, DKDLoss: 0.7918, 
2022-07-29 10:30:43 - train: epoch 0036, iter [03100, 05004], lr: 0.010000, loss: 1.9137, stu_CELoss: 1.1054, DKDLoss: 0.8083, 
2022-07-29 10:31:16 - train: epoch 0036, iter [03200, 05004], lr: 0.010000, loss: 1.9536, stu_CELoss: 1.2023, DKDLoss: 0.7513, 
2022-07-29 10:31:50 - train: epoch 0036, iter [03300, 05004], lr: 0.010000, loss: 2.0143, stu_CELoss: 1.2095, DKDLoss: 0.8048, 
2022-07-29 10:32:24 - train: epoch 0036, iter [03400, 05004], lr: 0.010000, loss: 1.7567, stu_CELoss: 1.0080, DKDLoss: 0.7487, 
2022-07-29 10:32:57 - train: epoch 0036, iter [03500, 05004], lr: 0.010000, loss: 2.0209, stu_CELoss: 1.1396, DKDLoss: 0.8813, 
2022-07-29 10:33:31 - train: epoch 0036, iter [03600, 05004], lr: 0.010000, loss: 2.0328, stu_CELoss: 1.1820, DKDLoss: 0.8508, 
2022-07-29 10:34:05 - train: epoch 0036, iter [03700, 05004], lr: 0.010000, loss: 1.6915, stu_CELoss: 1.0355, DKDLoss: 0.6560, 
2022-07-29 10:34:39 - train: epoch 0036, iter [03800, 05004], lr: 0.010000, loss: 1.8972, stu_CELoss: 1.1001, DKDLoss: 0.7971, 
2022-07-29 10:35:13 - train: epoch 0036, iter [03900, 05004], lr: 0.010000, loss: 1.9556, stu_CELoss: 1.1610, DKDLoss: 0.7946, 
2022-07-29 10:35:46 - train: epoch 0036, iter [04000, 05004], lr: 0.010000, loss: 1.9926, stu_CELoss: 1.2662, DKDLoss: 0.7265, 
2022-07-29 10:36:20 - train: epoch 0036, iter [04100, 05004], lr: 0.010000, loss: 2.0362, stu_CELoss: 1.1517, DKDLoss: 0.8845, 
2022-07-29 10:36:54 - train: epoch 0036, iter [04200, 05004], lr: 0.010000, loss: 2.0299, stu_CELoss: 1.2159, DKDLoss: 0.8139, 
2022-07-29 10:37:28 - train: epoch 0036, iter [04300, 05004], lr: 0.010000, loss: 1.8843, stu_CELoss: 1.2231, DKDLoss: 0.6612, 
2022-07-29 10:38:01 - train: epoch 0036, iter [04400, 05004], lr: 0.010000, loss: 2.0407, stu_CELoss: 1.1626, DKDLoss: 0.8781, 
2022-07-29 10:38:35 - train: epoch 0036, iter [04500, 05004], lr: 0.010000, loss: 1.5839, stu_CELoss: 0.9650, DKDLoss: 0.6189, 
2022-07-29 10:39:09 - train: epoch 0036, iter [04600, 05004], lr: 0.010000, loss: 1.7596, stu_CELoss: 1.0905, DKDLoss: 0.6691, 
2022-07-29 10:39:43 - train: epoch 0036, iter [04700, 05004], lr: 0.010000, loss: 1.6186, stu_CELoss: 0.9150, DKDLoss: 0.7037, 
2022-07-29 10:40:17 - train: epoch 0036, iter [04800, 05004], lr: 0.010000, loss: 1.6292, stu_CELoss: 0.9028, DKDLoss: 0.7264, 
2022-07-29 10:40:51 - train: epoch 0036, iter [04900, 05004], lr: 0.010000, loss: 1.7207, stu_CELoss: 0.9819, DKDLoss: 0.7388, 
2022-07-29 10:41:24 - train: epoch 0036, iter [05000, 05004], lr: 0.010000, loss: 1.6679, stu_CELoss: 0.9878, DKDLoss: 0.6801, 
2022-07-29 10:41:26 - train: epoch 036, train_loss: 1.9072
2022-07-29 10:43:59 - eval: epoch: 036, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 74.002%, stu_acc5: 91.876%, stu_test_loss: 1.0256
2022-07-29 10:43:59 - until epoch: 036, tea_best_acc1: 78.068%, stu_best_acc1: 74.004%
2022-07-29 10:43:59 - epoch 037 lr: 0.010000
2022-07-29 10:44:40 - train: epoch 0037, iter [00100, 05004], lr: 0.010000, loss: 1.7677, stu_CELoss: 1.0667, DKDLoss: 0.7010, 
2022-07-29 10:45:13 - train: epoch 0037, iter [00200, 05004], lr: 0.010000, loss: 1.6576, stu_CELoss: 0.9583, DKDLoss: 0.6993, 
2022-07-29 10:45:46 - train: epoch 0037, iter [00300, 05004], lr: 0.010000, loss: 1.7210, stu_CELoss: 1.0660, DKDLoss: 0.6550, 
2022-07-29 10:46:19 - train: epoch 0037, iter [00400, 05004], lr: 0.010000, loss: 1.7417, stu_CELoss: 0.9151, DKDLoss: 0.8266, 
2022-07-29 10:46:53 - train: epoch 0037, iter [00500, 05004], lr: 0.010000, loss: 1.5931, stu_CELoss: 0.9480, DKDLoss: 0.6451, 
2022-07-29 10:47:26 - train: epoch 0037, iter [00600, 05004], lr: 0.010000, loss: 1.9771, stu_CELoss: 1.1382, DKDLoss: 0.8388, 
2022-07-29 10:48:00 - train: epoch 0037, iter [00700, 05004], lr: 0.010000, loss: 1.8730, stu_CELoss: 1.0459, DKDLoss: 0.8271, 
2022-07-29 10:48:33 - train: epoch 0037, iter [00800, 05004], lr: 0.010000, loss: 1.7471, stu_CELoss: 1.0307, DKDLoss: 0.7164, 
2022-07-29 10:49:07 - train: epoch 0037, iter [00900, 05004], lr: 0.010000, loss: 2.2130, stu_CELoss: 1.3651, DKDLoss: 0.8478, 
2022-07-29 10:49:41 - train: epoch 0037, iter [01000, 05004], lr: 0.010000, loss: 1.8529, stu_CELoss: 1.0956, DKDLoss: 0.7573, 
2022-07-29 10:50:14 - train: epoch 0037, iter [01100, 05004], lr: 0.010000, loss: 1.8292, stu_CELoss: 1.1248, DKDLoss: 0.7044, 
2022-07-29 10:50:48 - train: epoch 0037, iter [01200, 05004], lr: 0.010000, loss: 1.8436, stu_CELoss: 1.0227, DKDLoss: 0.8209, 
2022-07-29 10:51:22 - train: epoch 0037, iter [01300, 05004], lr: 0.010000, loss: 1.9911, stu_CELoss: 1.1731, DKDLoss: 0.8180, 
2022-07-29 10:51:56 - train: epoch 0037, iter [01400, 05004], lr: 0.010000, loss: 2.2124, stu_CELoss: 1.3715, DKDLoss: 0.8409, 
2022-07-29 10:52:29 - train: epoch 0037, iter [01500, 05004], lr: 0.010000, loss: 1.9279, stu_CELoss: 1.0883, DKDLoss: 0.8397, 
2022-07-29 10:53:03 - train: epoch 0037, iter [01600, 05004], lr: 0.010000, loss: 1.6764, stu_CELoss: 0.9783, DKDLoss: 0.6981, 
2022-07-29 10:53:36 - train: epoch 0037, iter [01700, 05004], lr: 0.010000, loss: 1.6982, stu_CELoss: 0.9905, DKDLoss: 0.7078, 
2022-07-29 10:54:10 - train: epoch 0037, iter [01800, 05004], lr: 0.010000, loss: 1.9906, stu_CELoss: 1.1610, DKDLoss: 0.8296, 
2022-07-29 10:54:44 - train: epoch 0037, iter [01900, 05004], lr: 0.010000, loss: 1.8514, stu_CELoss: 1.1638, DKDLoss: 0.6876, 
2022-07-29 10:55:18 - train: epoch 0037, iter [02000, 05004], lr: 0.010000, loss: 2.1147, stu_CELoss: 1.3072, DKDLoss: 0.8074, 
2022-07-29 10:55:52 - train: epoch 0037, iter [02100, 05004], lr: 0.010000, loss: 1.9657, stu_CELoss: 1.2117, DKDLoss: 0.7540, 
2022-07-29 10:56:26 - train: epoch 0037, iter [02200, 05004], lr: 0.010000, loss: 1.8413, stu_CELoss: 1.0882, DKDLoss: 0.7531, 
2022-07-29 10:56:59 - train: epoch 0037, iter [02300, 05004], lr: 0.010000, loss: 1.8505, stu_CELoss: 1.1108, DKDLoss: 0.7396, 
2022-07-29 10:57:33 - train: epoch 0037, iter [02400, 05004], lr: 0.010000, loss: 1.8829, stu_CELoss: 1.1226, DKDLoss: 0.7603, 
2022-07-29 10:58:07 - train: epoch 0037, iter [02500, 05004], lr: 0.010000, loss: 1.9813, stu_CELoss: 1.1751, DKDLoss: 0.8062, 
2022-07-29 10:58:41 - train: epoch 0037, iter [02600, 05004], lr: 0.010000, loss: 2.2111, stu_CELoss: 1.3691, DKDLoss: 0.8420, 
2022-07-29 10:59:15 - train: epoch 0037, iter [02700, 05004], lr: 0.010000, loss: 2.1169, stu_CELoss: 1.2937, DKDLoss: 0.8232, 
2022-07-29 10:59:49 - train: epoch 0037, iter [02800, 05004], lr: 0.010000, loss: 1.9518, stu_CELoss: 1.1771, DKDLoss: 0.7746, 
2022-07-29 11:00:23 - train: epoch 0037, iter [02900, 05004], lr: 0.010000, loss: 1.7693, stu_CELoss: 1.0037, DKDLoss: 0.7655, 
2022-07-29 11:00:57 - train: epoch 0037, iter [03000, 05004], lr: 0.010000, loss: 2.0833, stu_CELoss: 1.2552, DKDLoss: 0.8281, 
2022-07-29 11:01:31 - train: epoch 0037, iter [03100, 05004], lr: 0.010000, loss: 1.9238, stu_CELoss: 1.0932, DKDLoss: 0.8307, 
2022-07-29 11:02:05 - train: epoch 0037, iter [03200, 05004], lr: 0.010000, loss: 1.8744, stu_CELoss: 1.0670, DKDLoss: 0.8074, 
2022-07-29 11:02:40 - train: epoch 0037, iter [03300, 05004], lr: 0.010000, loss: 1.8223, stu_CELoss: 1.0278, DKDLoss: 0.7945, 
2022-07-29 11:03:14 - train: epoch 0037, iter [03400, 05004], lr: 0.010000, loss: 1.8368, stu_CELoss: 1.0797, DKDLoss: 0.7571, 
2022-07-29 11:03:48 - train: epoch 0037, iter [03500, 05004], lr: 0.010000, loss: 1.7220, stu_CELoss: 0.9899, DKDLoss: 0.7321, 
2022-07-29 11:04:22 - train: epoch 0037, iter [03600, 05004], lr: 0.010000, loss: 1.8774, stu_CELoss: 1.1924, DKDLoss: 0.6850, 
2022-07-29 11:04:56 - train: epoch 0037, iter [03700, 05004], lr: 0.010000, loss: 2.0049, stu_CELoss: 1.2312, DKDLoss: 0.7737, 
2022-07-29 11:05:30 - train: epoch 0037, iter [03800, 05004], lr: 0.010000, loss: 2.0810, stu_CELoss: 1.2508, DKDLoss: 0.8302, 
2022-07-29 11:06:03 - train: epoch 0037, iter [03900, 05004], lr: 0.010000, loss: 1.9319, stu_CELoss: 1.1510, DKDLoss: 0.7809, 
2022-07-29 11:06:37 - train: epoch 0037, iter [04000, 05004], lr: 0.010000, loss: 1.9954, stu_CELoss: 1.1669, DKDLoss: 0.8286, 
2022-07-29 11:07:11 - train: epoch 0037, iter [04100, 05004], lr: 0.010000, loss: 1.7022, stu_CELoss: 0.9985, DKDLoss: 0.7037, 
2022-07-29 11:07:45 - train: epoch 0037, iter [04200, 05004], lr: 0.010000, loss: 1.8167, stu_CELoss: 1.0526, DKDLoss: 0.7641, 
2022-07-29 11:08:19 - train: epoch 0037, iter [04300, 05004], lr: 0.010000, loss: 1.8301, stu_CELoss: 1.0526, DKDLoss: 0.7775, 
2022-07-29 11:08:52 - train: epoch 0037, iter [04400, 05004], lr: 0.010000, loss: 1.8716, stu_CELoss: 1.1222, DKDLoss: 0.7494, 
2022-07-29 11:09:26 - train: epoch 0037, iter [04500, 05004], lr: 0.010000, loss: 1.8986, stu_CELoss: 1.1638, DKDLoss: 0.7348, 
2022-07-29 11:10:00 - train: epoch 0037, iter [04600, 05004], lr: 0.010000, loss: 1.9544, stu_CELoss: 1.2475, DKDLoss: 0.7069, 
2022-07-29 11:10:34 - train: epoch 0037, iter [04700, 05004], lr: 0.010000, loss: 1.9248, stu_CELoss: 1.0920, DKDLoss: 0.8328, 
2022-07-29 11:11:08 - train: epoch 0037, iter [04800, 05004], lr: 0.010000, loss: 1.7222, stu_CELoss: 1.0208, DKDLoss: 0.7014, 
2022-07-29 11:11:42 - train: epoch 0037, iter [04900, 05004], lr: 0.010000, loss: 1.9871, stu_CELoss: 1.2381, DKDLoss: 0.7490, 
2022-07-29 11:12:15 - train: epoch 0037, iter [05000, 05004], lr: 0.010000, loss: 1.6213, stu_CELoss: 0.9626, DKDLoss: 0.6586, 
2022-07-29 11:12:17 - train: epoch 037, train_loss: 1.8817
2022-07-29 11:14:48 - eval: epoch: 037, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 73.976%, stu_acc5: 91.762%, stu_test_loss: 1.0326
2022-07-29 11:14:49 - until epoch: 037, tea_best_acc1: 78.068%, stu_best_acc1: 74.004%
2022-07-29 11:14:49 - epoch 038 lr: 0.010000
2022-07-29 11:15:28 - train: epoch 0038, iter [00100, 05004], lr: 0.010000, loss: 1.7327, stu_CELoss: 1.0019, DKDLoss: 0.7308, 
2022-07-29 11:16:01 - train: epoch 0038, iter [00200, 05004], lr: 0.010000, loss: 1.7467, stu_CELoss: 0.9905, DKDLoss: 0.7562, 
2022-07-29 11:16:35 - train: epoch 0038, iter [00300, 05004], lr: 0.010000, loss: 1.9186, stu_CELoss: 1.1197, DKDLoss: 0.7988, 
2022-07-29 11:17:09 - train: epoch 0038, iter [00400, 05004], lr: 0.010000, loss: 1.6510, stu_CELoss: 0.9262, DKDLoss: 0.7248, 
2022-07-29 11:17:43 - train: epoch 0038, iter [00500, 05004], lr: 0.010000, loss: 1.6598, stu_CELoss: 0.9421, DKDLoss: 0.7178, 
2022-07-29 11:18:16 - train: epoch 0038, iter [00600, 05004], lr: 0.010000, loss: 2.0914, stu_CELoss: 1.2507, DKDLoss: 0.8407, 
2022-07-29 11:18:50 - train: epoch 0038, iter [00700, 05004], lr: 0.010000, loss: 1.6454, stu_CELoss: 0.9105, DKDLoss: 0.7349, 
2022-07-29 11:19:24 - train: epoch 0038, iter [00800, 05004], lr: 0.010000, loss: 1.8149, stu_CELoss: 1.0361, DKDLoss: 0.7789, 
2022-07-29 11:19:58 - train: epoch 0038, iter [00900, 05004], lr: 0.010000, loss: 2.0562, stu_CELoss: 1.2870, DKDLoss: 0.7692, 
2022-07-29 11:20:32 - train: epoch 0038, iter [01000, 05004], lr: 0.010000, loss: 2.0320, stu_CELoss: 1.2233, DKDLoss: 0.8088, 
2022-07-29 11:21:05 - train: epoch 0038, iter [01100, 05004], lr: 0.010000, loss: 1.9604, stu_CELoss: 1.1567, DKDLoss: 0.8038, 
2022-07-29 11:21:39 - train: epoch 0038, iter [01200, 05004], lr: 0.010000, loss: 2.1914, stu_CELoss: 1.3561, DKDLoss: 0.8352, 
2022-07-29 11:22:13 - train: epoch 0038, iter [01300, 05004], lr: 0.010000, loss: 1.9678, stu_CELoss: 1.1685, DKDLoss: 0.7993, 
2022-07-29 11:22:47 - train: epoch 0038, iter [01400, 05004], lr: 0.010000, loss: 1.9718, stu_CELoss: 1.1521, DKDLoss: 0.8197, 
2022-07-29 11:23:21 - train: epoch 0038, iter [01500, 05004], lr: 0.010000, loss: 1.6792, stu_CELoss: 0.9697, DKDLoss: 0.7096, 
2022-07-29 11:23:55 - train: epoch 0038, iter [01600, 05004], lr: 0.010000, loss: 1.8667, stu_CELoss: 1.0862, DKDLoss: 0.7805, 
2022-07-29 11:24:28 - train: epoch 0038, iter [01700, 05004], lr: 0.010000, loss: 2.1185, stu_CELoss: 1.2303, DKDLoss: 0.8882, 
2022-07-29 11:25:02 - train: epoch 0038, iter [01800, 05004], lr: 0.010000, loss: 2.0628, stu_CELoss: 1.2374, DKDLoss: 0.8254, 
2022-07-29 11:25:36 - train: epoch 0038, iter [01900, 05004], lr: 0.010000, loss: 1.6378, stu_CELoss: 0.9293, DKDLoss: 0.7084, 
2022-07-29 11:26:09 - train: epoch 0038, iter [02000, 05004], lr: 0.010000, loss: 1.8589, stu_CELoss: 1.1889, DKDLoss: 0.6700, 
2022-07-29 11:26:43 - train: epoch 0038, iter [02100, 05004], lr: 0.010000, loss: 1.9227, stu_CELoss: 1.1796, DKDLoss: 0.7431, 
2022-07-29 11:27:17 - train: epoch 0038, iter [02200, 05004], lr: 0.010000, loss: 1.7621, stu_CELoss: 1.0983, DKDLoss: 0.6638, 
2022-07-29 11:27:50 - train: epoch 0038, iter [02300, 05004], lr: 0.010000, loss: 1.9631, stu_CELoss: 1.1372, DKDLoss: 0.8259, 
2022-07-29 11:28:24 - train: epoch 0038, iter [02400, 05004], lr: 0.010000, loss: 2.2065, stu_CELoss: 1.3836, DKDLoss: 0.8230, 
2022-07-29 11:28:58 - train: epoch 0038, iter [02500, 05004], lr: 0.010000, loss: 1.5985, stu_CELoss: 0.8620, DKDLoss: 0.7365, 
2022-07-29 11:29:32 - train: epoch 0038, iter [02600, 05004], lr: 0.010000, loss: 2.0691, stu_CELoss: 1.2555, DKDLoss: 0.8136, 
2022-07-29 11:30:06 - train: epoch 0038, iter [02700, 05004], lr: 0.010000, loss: 1.9731, stu_CELoss: 1.2440, DKDLoss: 0.7291, 
2022-07-29 11:30:40 - train: epoch 0038, iter [02800, 05004], lr: 0.010000, loss: 1.9874, stu_CELoss: 1.2302, DKDLoss: 0.7572, 
2022-07-29 11:31:14 - train: epoch 0038, iter [02900, 05004], lr: 0.010000, loss: 1.8935, stu_CELoss: 1.0863, DKDLoss: 0.8072, 
2022-07-29 11:31:48 - train: epoch 0038, iter [03000, 05004], lr: 0.010000, loss: 1.7527, stu_CELoss: 1.0292, DKDLoss: 0.7234, 
2022-07-29 11:32:21 - train: epoch 0038, iter [03100, 05004], lr: 0.010000, loss: 1.7749, stu_CELoss: 1.0906, DKDLoss: 0.6843, 
2022-07-29 11:32:55 - train: epoch 0038, iter [03200, 05004], lr: 0.010000, loss: 1.7605, stu_CELoss: 1.0466, DKDLoss: 0.7139, 
2022-07-29 11:33:29 - train: epoch 0038, iter [03300, 05004], lr: 0.010000, loss: 1.8120, stu_CELoss: 1.0763, DKDLoss: 0.7357, 
2022-07-29 11:34:03 - train: epoch 0038, iter [03400, 05004], lr: 0.010000, loss: 1.8361, stu_CELoss: 1.0324, DKDLoss: 0.8037, 
2022-07-29 11:34:37 - train: epoch 0038, iter [03500, 05004], lr: 0.010000, loss: 1.9258, stu_CELoss: 1.2256, DKDLoss: 0.7002, 
2022-07-29 11:35:11 - train: epoch 0038, iter [03600, 05004], lr: 0.010000, loss: 1.9289, stu_CELoss: 1.1448, DKDLoss: 0.7841, 
2022-07-29 11:35:45 - train: epoch 0038, iter [03700, 05004], lr: 0.010000, loss: 1.5959, stu_CELoss: 0.8645, DKDLoss: 0.7314, 
2022-07-29 11:36:19 - train: epoch 0038, iter [03800, 05004], lr: 0.010000, loss: 2.1190, stu_CELoss: 1.2826, DKDLoss: 0.8363, 
2022-07-29 11:36:53 - train: epoch 0038, iter [03900, 05004], lr: 0.010000, loss: 1.8348, stu_CELoss: 1.0542, DKDLoss: 0.7806, 
2022-07-29 11:37:27 - train: epoch 0038, iter [04000, 05004], lr: 0.010000, loss: 1.9663, stu_CELoss: 1.2403, DKDLoss: 0.7260, 
2022-07-29 11:38:01 - train: epoch 0038, iter [04100, 05004], lr: 0.010000, loss: 1.9340, stu_CELoss: 1.1676, DKDLoss: 0.7664, 
2022-07-29 11:38:35 - train: epoch 0038, iter [04200, 05004], lr: 0.010000, loss: 1.7419, stu_CELoss: 0.9905, DKDLoss: 0.7514, 
2022-07-29 11:39:09 - train: epoch 0038, iter [04300, 05004], lr: 0.010000, loss: 2.0967, stu_CELoss: 1.2635, DKDLoss: 0.8332, 
2022-07-29 11:39:43 - train: epoch 0038, iter [04400, 05004], lr: 0.010000, loss: 1.7270, stu_CELoss: 0.9915, DKDLoss: 0.7355, 
2022-07-29 11:40:16 - train: epoch 0038, iter [04500, 05004], lr: 0.010000, loss: 2.0524, stu_CELoss: 1.1847, DKDLoss: 0.8677, 
2022-07-29 11:40:50 - train: epoch 0038, iter [04600, 05004], lr: 0.010000, loss: 2.0340, stu_CELoss: 1.2480, DKDLoss: 0.7859, 
2022-07-29 11:41:24 - train: epoch 0038, iter [04700, 05004], lr: 0.010000, loss: 1.9446, stu_CELoss: 1.1457, DKDLoss: 0.7989, 
2022-07-29 11:41:58 - train: epoch 0038, iter [04800, 05004], lr: 0.010000, loss: 1.8139, stu_CELoss: 1.0219, DKDLoss: 0.7921, 
2022-07-29 11:42:32 - train: epoch 0038, iter [04900, 05004], lr: 0.010000, loss: 1.9500, stu_CELoss: 1.1278, DKDLoss: 0.8222, 
2022-07-29 11:43:05 - train: epoch 0038, iter [05000, 05004], lr: 0.010000, loss: 1.8877, stu_CELoss: 1.1237, DKDLoss: 0.7639, 
2022-07-29 11:43:06 - train: epoch 038, train_loss: 1.8603
2022-07-29 11:45:39 - eval: epoch: 038, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 74.276%, stu_acc5: 91.986%, stu_test_loss: 1.0225
2022-07-29 11:45:39 - until epoch: 038, tea_best_acc1: 78.068%, stu_best_acc1: 74.276%
2022-07-29 11:45:39 - epoch 039 lr: 0.010000
2022-07-29 11:46:19 - train: epoch 0039, iter [00100, 05004], lr: 0.010000, loss: 1.8690, stu_CELoss: 1.1540, DKDLoss: 0.7150, 
2022-07-29 11:46:52 - train: epoch 0039, iter [00200, 05004], lr: 0.010000, loss: 1.9413, stu_CELoss: 1.2143, DKDLoss: 0.7270, 
2022-07-29 11:47:25 - train: epoch 0039, iter [00300, 05004], lr: 0.010000, loss: 1.5794, stu_CELoss: 0.8814, DKDLoss: 0.6980, 
2022-07-29 11:47:58 - train: epoch 0039, iter [00400, 05004], lr: 0.010000, loss: 1.8734, stu_CELoss: 1.1858, DKDLoss: 0.6875, 
2022-07-29 11:48:31 - train: epoch 0039, iter [00500, 05004], lr: 0.010000, loss: 1.8675, stu_CELoss: 1.1003, DKDLoss: 0.7672, 
2022-07-29 11:49:04 - train: epoch 0039, iter [00600, 05004], lr: 0.010000, loss: 1.8162, stu_CELoss: 1.0485, DKDLoss: 0.7677, 
2022-07-29 11:49:38 - train: epoch 0039, iter [00700, 05004], lr: 0.010000, loss: 2.0023, stu_CELoss: 1.3087, DKDLoss: 0.6936, 
2022-07-29 11:50:11 - train: epoch 0039, iter [00800, 05004], lr: 0.010000, loss: 1.8529, stu_CELoss: 1.1422, DKDLoss: 0.7107, 
2022-07-29 11:50:45 - train: epoch 0039, iter [00900, 05004], lr: 0.010000, loss: 1.9463, stu_CELoss: 1.2233, DKDLoss: 0.7231, 
2022-07-29 11:51:18 - train: epoch 0039, iter [01000, 05004], lr: 0.010000, loss: 1.8692, stu_CELoss: 1.1621, DKDLoss: 0.7071, 
2022-07-29 11:51:52 - train: epoch 0039, iter [01100, 05004], lr: 0.010000, loss: 1.8369, stu_CELoss: 1.1326, DKDLoss: 0.7043, 
2022-07-29 11:52:26 - train: epoch 0039, iter [01200, 05004], lr: 0.010000, loss: 1.8225, stu_CELoss: 1.1260, DKDLoss: 0.6965, 
2022-07-29 11:53:00 - train: epoch 0039, iter [01300, 05004], lr: 0.010000, loss: 1.9858, stu_CELoss: 1.2277, DKDLoss: 0.7581, 
2022-07-29 11:53:33 - train: epoch 0039, iter [01400, 05004], lr: 0.010000, loss: 1.9275, stu_CELoss: 1.2181, DKDLoss: 0.7093, 
2022-07-29 11:54:07 - train: epoch 0039, iter [01500, 05004], lr: 0.010000, loss: 1.8320, stu_CELoss: 1.0635, DKDLoss: 0.7685, 
2022-07-29 11:54:41 - train: epoch 0039, iter [01600, 05004], lr: 0.010000, loss: 1.9691, stu_CELoss: 1.1380, DKDLoss: 0.8311, 
2022-07-29 11:55:15 - train: epoch 0039, iter [01700, 05004], lr: 0.010000, loss: 1.7522, stu_CELoss: 0.9889, DKDLoss: 0.7633, 
2022-07-29 11:55:49 - train: epoch 0039, iter [01800, 05004], lr: 0.010000, loss: 1.8379, stu_CELoss: 1.1051, DKDLoss: 0.7328, 
2022-07-29 11:56:23 - train: epoch 0039, iter [01900, 05004], lr: 0.010000, loss: 1.7278, stu_CELoss: 1.0249, DKDLoss: 0.7029, 
2022-07-29 11:56:57 - train: epoch 0039, iter [02000, 05004], lr: 0.010000, loss: 1.7868, stu_CELoss: 1.0078, DKDLoss: 0.7790, 
2022-07-29 11:57:31 - train: epoch 0039, iter [02100, 05004], lr: 0.010000, loss: 1.8985, stu_CELoss: 1.1604, DKDLoss: 0.7381, 
2022-07-29 11:58:04 - train: epoch 0039, iter [02200, 05004], lr: 0.010000, loss: 1.7766, stu_CELoss: 1.1136, DKDLoss: 0.6630, 
2022-07-29 11:58:38 - train: epoch 0039, iter [02300, 05004], lr: 0.010000, loss: 2.1663, stu_CELoss: 1.3109, DKDLoss: 0.8554, 
2022-07-29 11:59:11 - train: epoch 0039, iter [02400, 05004], lr: 0.010000, loss: 2.0434, stu_CELoss: 1.3184, DKDLoss: 0.7250, 
2022-07-29 11:59:45 - train: epoch 0039, iter [02500, 05004], lr: 0.010000, loss: 1.8043, stu_CELoss: 1.0760, DKDLoss: 0.7283, 
2022-07-29 12:00:19 - train: epoch 0039, iter [02600, 05004], lr: 0.010000, loss: 1.7155, stu_CELoss: 1.0079, DKDLoss: 0.7076, 
2022-07-29 12:00:53 - train: epoch 0039, iter [02700, 05004], lr: 0.010000, loss: 1.9759, stu_CELoss: 1.1917, DKDLoss: 0.7842, 
2022-07-29 12:01:27 - train: epoch 0039, iter [02800, 05004], lr: 0.010000, loss: 1.7941, stu_CELoss: 1.0088, DKDLoss: 0.7853, 
2022-07-29 12:02:01 - train: epoch 0039, iter [02900, 05004], lr: 0.010000, loss: 1.7998, stu_CELoss: 1.0642, DKDLoss: 0.7357, 
2022-07-29 12:02:35 - train: epoch 0039, iter [03000, 05004], lr: 0.010000, loss: 2.0185, stu_CELoss: 1.2604, DKDLoss: 0.7580, 
2022-07-29 12:03:09 - train: epoch 0039, iter [03100, 05004], lr: 0.010000, loss: 1.7907, stu_CELoss: 1.0515, DKDLoss: 0.7392, 
2022-07-29 12:03:43 - train: epoch 0039, iter [03200, 05004], lr: 0.010000, loss: 2.0374, stu_CELoss: 1.1668, DKDLoss: 0.8707, 
2022-07-29 12:04:16 - train: epoch 0039, iter [03300, 05004], lr: 0.010000, loss: 1.8113, stu_CELoss: 1.0310, DKDLoss: 0.7803, 
2022-07-29 12:04:50 - train: epoch 0039, iter [03400, 05004], lr: 0.010000, loss: 2.0994, stu_CELoss: 1.2399, DKDLoss: 0.8595, 
2022-07-29 12:05:23 - train: epoch 0039, iter [03500, 05004], lr: 0.010000, loss: 1.9447, stu_CELoss: 1.1853, DKDLoss: 0.7595, 
2022-07-29 12:05:57 - train: epoch 0039, iter [03600, 05004], lr: 0.010000, loss: 1.9088, stu_CELoss: 1.1501, DKDLoss: 0.7586, 
2022-07-29 12:06:30 - train: epoch 0039, iter [03700, 05004], lr: 0.010000, loss: 1.8105, stu_CELoss: 1.0822, DKDLoss: 0.7283, 
2022-07-29 12:07:04 - train: epoch 0039, iter [03800, 05004], lr: 0.010000, loss: 1.7784, stu_CELoss: 1.0678, DKDLoss: 0.7106, 
2022-07-29 12:07:38 - train: epoch 0039, iter [03900, 05004], lr: 0.010000, loss: 1.9094, stu_CELoss: 1.0962, DKDLoss: 0.8132, 
2022-07-29 12:08:11 - train: epoch 0039, iter [04000, 05004], lr: 0.010000, loss: 1.6963, stu_CELoss: 0.9509, DKDLoss: 0.7453, 
2022-07-29 12:08:45 - train: epoch 0039, iter [04100, 05004], lr: 0.010000, loss: 1.8040, stu_CELoss: 1.0773, DKDLoss: 0.7267, 
2022-07-29 12:09:19 - train: epoch 0039, iter [04200, 05004], lr: 0.010000, loss: 1.9046, stu_CELoss: 1.0664, DKDLoss: 0.8382, 
2022-07-29 12:09:53 - train: epoch 0039, iter [04300, 05004], lr: 0.010000, loss: 1.6662, stu_CELoss: 0.9426, DKDLoss: 0.7236, 
2022-07-29 12:10:26 - train: epoch 0039, iter [04400, 05004], lr: 0.010000, loss: 1.8030, stu_CELoss: 1.1240, DKDLoss: 0.6791, 
2022-07-29 12:11:00 - train: epoch 0039, iter [04500, 05004], lr: 0.010000, loss: 1.6763, stu_CELoss: 1.0151, DKDLoss: 0.6612, 
2022-07-29 12:11:34 - train: epoch 0039, iter [04600, 05004], lr: 0.010000, loss: 1.7918, stu_CELoss: 1.0996, DKDLoss: 0.6922, 
2022-07-29 12:12:08 - train: epoch 0039, iter [04700, 05004], lr: 0.010000, loss: 1.6051, stu_CELoss: 0.8947, DKDLoss: 0.7103, 
2022-07-29 12:12:41 - train: epoch 0039, iter [04800, 05004], lr: 0.010000, loss: 1.8691, stu_CELoss: 1.0808, DKDLoss: 0.7882, 
2022-07-29 12:13:15 - train: epoch 0039, iter [04900, 05004], lr: 0.010000, loss: 2.0564, stu_CELoss: 1.2638, DKDLoss: 0.7925, 
2022-07-29 12:13:48 - train: epoch 0039, iter [05000, 05004], lr: 0.010000, loss: 1.8245, stu_CELoss: 1.1416, DKDLoss: 0.6830, 
2022-07-29 12:13:50 - train: epoch 039, train_loss: 1.8460
2022-07-29 12:16:22 - eval: epoch: 039, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 74.132%, stu_acc5: 91.748%, stu_test_loss: 1.0334
2022-07-29 12:16:23 - until epoch: 039, tea_best_acc1: 78.068%, stu_best_acc1: 74.276%
2022-07-29 12:16:23 - epoch 040 lr: 0.010000
2022-07-29 12:17:03 - train: epoch 0040, iter [00100, 05004], lr: 0.010000, loss: 2.2246, stu_CELoss: 1.4491, DKDLoss: 0.7755, 
2022-07-29 12:17:36 - train: epoch 0040, iter [00200, 05004], lr: 0.010000, loss: 1.9298, stu_CELoss: 1.2133, DKDLoss: 0.7165, 
2022-07-29 12:18:08 - train: epoch 0040, iter [00300, 05004], lr: 0.010000, loss: 1.9519, stu_CELoss: 1.1854, DKDLoss: 0.7665, 
2022-07-29 12:18:41 - train: epoch 0040, iter [00400, 05004], lr: 0.010000, loss: 1.5368, stu_CELoss: 0.8688, DKDLoss: 0.6680, 
2022-07-29 12:19:14 - train: epoch 0040, iter [00500, 05004], lr: 0.010000, loss: 1.5641, stu_CELoss: 0.9258, DKDLoss: 0.6383, 
2022-07-29 12:19:47 - train: epoch 0040, iter [00600, 05004], lr: 0.010000, loss: 1.7340, stu_CELoss: 1.0307, DKDLoss: 0.7033, 
2022-07-29 12:20:21 - train: epoch 0040, iter [00700, 05004], lr: 0.010000, loss: 1.9509, stu_CELoss: 1.1627, DKDLoss: 0.7882, 
2022-07-29 12:20:54 - train: epoch 0040, iter [00800, 05004], lr: 0.010000, loss: 1.8521, stu_CELoss: 1.0701, DKDLoss: 0.7820, 
2022-07-29 12:21:27 - train: epoch 0040, iter [00900, 05004], lr: 0.010000, loss: 1.7245, stu_CELoss: 0.9475, DKDLoss: 0.7770, 
2022-07-29 12:22:00 - train: epoch 0040, iter [01000, 05004], lr: 0.010000, loss: 1.7016, stu_CELoss: 1.0096, DKDLoss: 0.6920, 
2022-07-29 12:22:34 - train: epoch 0040, iter [01100, 05004], lr: 0.010000, loss: 1.6069, stu_CELoss: 0.9227, DKDLoss: 0.6842, 
2022-07-29 12:23:08 - train: epoch 0040, iter [01200, 05004], lr: 0.010000, loss: 1.8049, stu_CELoss: 1.0107, DKDLoss: 0.7942, 
2022-07-29 12:23:41 - train: epoch 0040, iter [01300, 05004], lr: 0.010000, loss: 1.6759, stu_CELoss: 0.9825, DKDLoss: 0.6934, 
2022-07-29 12:24:15 - train: epoch 0040, iter [01400, 05004], lr: 0.010000, loss: 1.8382, stu_CELoss: 1.1065, DKDLoss: 0.7317, 
2022-07-29 12:24:48 - train: epoch 0040, iter [01500, 05004], lr: 0.010000, loss: 1.8622, stu_CELoss: 1.1665, DKDLoss: 0.6957, 
2022-07-29 12:25:21 - train: epoch 0040, iter [01600, 05004], lr: 0.010000, loss: 1.8951, stu_CELoss: 1.1199, DKDLoss: 0.7753, 
2022-07-29 12:25:54 - train: epoch 0040, iter [01700, 05004], lr: 0.010000, loss: 1.7583, stu_CELoss: 0.9956, DKDLoss: 0.7627, 
2022-07-29 12:26:28 - train: epoch 0040, iter [01800, 05004], lr: 0.010000, loss: 1.6723, stu_CELoss: 1.0257, DKDLoss: 0.6466, 
2022-07-29 12:27:01 - train: epoch 0040, iter [01900, 05004], lr: 0.010000, loss: 1.8917, stu_CELoss: 1.1235, DKDLoss: 0.7682, 
2022-07-29 12:27:35 - train: epoch 0040, iter [02000, 05004], lr: 0.010000, loss: 1.8953, stu_CELoss: 1.1642, DKDLoss: 0.7311, 
2022-07-29 12:28:08 - train: epoch 0040, iter [02100, 05004], lr: 0.010000, loss: 1.8092, stu_CELoss: 1.0247, DKDLoss: 0.7845, 
2022-07-29 12:28:42 - train: epoch 0040, iter [02200, 05004], lr: 0.010000, loss: 1.9436, stu_CELoss: 1.1416, DKDLoss: 0.8020, 
2022-07-29 12:29:16 - train: epoch 0040, iter [02300, 05004], lr: 0.010000, loss: 1.7983, stu_CELoss: 0.9793, DKDLoss: 0.8190, 
2022-07-29 12:29:49 - train: epoch 0040, iter [02400, 05004], lr: 0.010000, loss: 1.9150, stu_CELoss: 1.0941, DKDLoss: 0.8209, 
2022-07-29 12:30:23 - train: epoch 0040, iter [02500, 05004], lr: 0.010000, loss: 1.9808, stu_CELoss: 1.1924, DKDLoss: 0.7884, 
2022-07-29 12:30:57 - train: epoch 0040, iter [02600, 05004], lr: 0.010000, loss: 1.8295, stu_CELoss: 1.1057, DKDLoss: 0.7238, 
2022-07-29 12:31:30 - train: epoch 0040, iter [02700, 05004], lr: 0.010000, loss: 1.8241, stu_CELoss: 1.0889, DKDLoss: 0.7352, 
2022-07-29 12:32:04 - train: epoch 0040, iter [02800, 05004], lr: 0.010000, loss: 1.7650, stu_CELoss: 1.0006, DKDLoss: 0.7644, 
2022-07-29 12:32:38 - train: epoch 0040, iter [02900, 05004], lr: 0.010000, loss: 2.0413, stu_CELoss: 1.2349, DKDLoss: 0.8064, 
2022-07-29 12:33:12 - train: epoch 0040, iter [03000, 05004], lr: 0.010000, loss: 2.0413, stu_CELoss: 1.2560, DKDLoss: 0.7853, 
2022-07-29 12:33:46 - train: epoch 0040, iter [03100, 05004], lr: 0.010000, loss: 1.7741, stu_CELoss: 1.0380, DKDLoss: 0.7361, 
2022-07-29 12:34:19 - train: epoch 0040, iter [03200, 05004], lr: 0.010000, loss: 1.9236, stu_CELoss: 1.1627, DKDLoss: 0.7609, 
2022-07-29 12:34:53 - train: epoch 0040, iter [03300, 05004], lr: 0.010000, loss: 1.7372, stu_CELoss: 0.9599, DKDLoss: 0.7773, 
2022-07-29 12:35:27 - train: epoch 0040, iter [03400, 05004], lr: 0.010000, loss: 1.7953, stu_CELoss: 1.0201, DKDLoss: 0.7751, 
2022-07-29 12:36:01 - train: epoch 0040, iter [03500, 05004], lr: 0.010000, loss: 1.9334, stu_CELoss: 1.1302, DKDLoss: 0.8032, 
2022-07-29 12:36:35 - train: epoch 0040, iter [03600, 05004], lr: 0.010000, loss: 1.8167, stu_CELoss: 1.0709, DKDLoss: 0.7458, 
2022-07-29 12:37:09 - train: epoch 0040, iter [03700, 05004], lr: 0.010000, loss: 1.9656, stu_CELoss: 1.1893, DKDLoss: 0.7763, 
2022-07-29 12:37:42 - train: epoch 0040, iter [03800, 05004], lr: 0.010000, loss: 1.8622, stu_CELoss: 1.1037, DKDLoss: 0.7586, 
2022-07-29 12:38:16 - train: epoch 0040, iter [03900, 05004], lr: 0.010000, loss: 2.0303, stu_CELoss: 1.2772, DKDLoss: 0.7531, 
2022-07-29 12:38:50 - train: epoch 0040, iter [04000, 05004], lr: 0.010000, loss: 1.6950, stu_CELoss: 0.9236, DKDLoss: 0.7714, 
2022-07-29 12:39:24 - train: epoch 0040, iter [04100, 05004], lr: 0.010000, loss: 1.9980, stu_CELoss: 1.2168, DKDLoss: 0.7811, 
2022-07-29 12:39:58 - train: epoch 0040, iter [04200, 05004], lr: 0.010000, loss: 1.8853, stu_CELoss: 1.1034, DKDLoss: 0.7819, 
2022-07-29 12:40:32 - train: epoch 0040, iter [04300, 05004], lr: 0.010000, loss: 1.7558, stu_CELoss: 1.0732, DKDLoss: 0.6826, 
2022-07-29 12:41:05 - train: epoch 0040, iter [04400, 05004], lr: 0.010000, loss: 1.7037, stu_CELoss: 0.9599, DKDLoss: 0.7438, 
2022-07-29 12:41:39 - train: epoch 0040, iter [04500, 05004], lr: 0.010000, loss: 1.9099, stu_CELoss: 1.1107, DKDLoss: 0.7993, 
2022-07-29 12:42:12 - train: epoch 0040, iter [04600, 05004], lr: 0.010000, loss: 1.8914, stu_CELoss: 1.1415, DKDLoss: 0.7499, 
2022-07-29 12:42:46 - train: epoch 0040, iter [04700, 05004], lr: 0.010000, loss: 2.0773, stu_CELoss: 1.1974, DKDLoss: 0.8799, 
2022-07-29 12:43:20 - train: epoch 0040, iter [04800, 05004], lr: 0.010000, loss: 1.8323, stu_CELoss: 1.0234, DKDLoss: 0.8089, 
2022-07-29 12:43:54 - train: epoch 0040, iter [04900, 05004], lr: 0.010000, loss: 1.7483, stu_CELoss: 1.0109, DKDLoss: 0.7374, 
2022-07-29 12:44:27 - train: epoch 0040, iter [05000, 05004], lr: 0.010000, loss: 1.7237, stu_CELoss: 0.9789, DKDLoss: 0.7448, 
2022-07-29 12:44:28 - train: epoch 040, train_loss: 1.8322
2022-07-29 12:46:59 - eval: epoch: 040, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 72.768%, stu_acc5: 91.364%, stu_test_loss: 1.0728
2022-07-29 12:47:00 - until epoch: 040, tea_best_acc1: 78.068%, stu_best_acc1: 74.276%
2022-07-29 12:47:00 - epoch 041 lr: 0.010000
2022-07-29 12:47:39 - train: epoch 0041, iter [00100, 05004], lr: 0.010000, loss: 1.9859, stu_CELoss: 1.2643, DKDLoss: 0.7216, 
2022-07-29 12:48:12 - train: epoch 0041, iter [00200, 05004], lr: 0.010000, loss: 2.0036, stu_CELoss: 1.2496, DKDLoss: 0.7540, 
2022-07-29 12:48:45 - train: epoch 0041, iter [00300, 05004], lr: 0.010000, loss: 1.5644, stu_CELoss: 0.9082, DKDLoss: 0.6562, 
2022-07-29 12:49:19 - train: epoch 0041, iter [00400, 05004], lr: 0.010000, loss: 1.8037, stu_CELoss: 1.0472, DKDLoss: 0.7565, 
2022-07-29 12:49:52 - train: epoch 0041, iter [00500, 05004], lr: 0.010000, loss: 1.6422, stu_CELoss: 0.9267, DKDLoss: 0.7155, 
2022-07-29 12:50:26 - train: epoch 0041, iter [00600, 05004], lr: 0.010000, loss: 1.7296, stu_CELoss: 1.0320, DKDLoss: 0.6975, 
2022-07-29 12:50:59 - train: epoch 0041, iter [00700, 05004], lr: 0.010000, loss: 1.8087, stu_CELoss: 1.0218, DKDLoss: 0.7869, 
2022-07-29 12:51:33 - train: epoch 0041, iter [00800, 05004], lr: 0.010000, loss: 1.5224, stu_CELoss: 0.9168, DKDLoss: 0.6057, 
2022-07-29 12:52:07 - train: epoch 0041, iter [00900, 05004], lr: 0.010000, loss: 1.6688, stu_CELoss: 0.9722, DKDLoss: 0.6966, 
2022-07-29 12:52:41 - train: epoch 0041, iter [01000, 05004], lr: 0.010000, loss: 2.0181, stu_CELoss: 1.2450, DKDLoss: 0.7731, 
2022-07-29 12:53:14 - train: epoch 0041, iter [01100, 05004], lr: 0.010000, loss: 1.6398, stu_CELoss: 0.9293, DKDLoss: 0.7105, 
2022-07-29 12:53:48 - train: epoch 0041, iter [01200, 05004], lr: 0.010000, loss: 1.8044, stu_CELoss: 1.0607, DKDLoss: 0.7437, 
2022-07-29 12:54:22 - train: epoch 0041, iter [01300, 05004], lr: 0.010000, loss: 1.5856, stu_CELoss: 0.8807, DKDLoss: 0.7049, 
2022-07-29 12:54:56 - train: epoch 0041, iter [01400, 05004], lr: 0.010000, loss: 1.9128, stu_CELoss: 1.1095, DKDLoss: 0.8033, 
2022-07-29 12:55:30 - train: epoch 0041, iter [01500, 05004], lr: 0.010000, loss: 2.0151, stu_CELoss: 1.1681, DKDLoss: 0.8470, 
2022-07-29 12:56:04 - train: epoch 0041, iter [01600, 05004], lr: 0.010000, loss: 1.8274, stu_CELoss: 1.1084, DKDLoss: 0.7190, 
2022-07-29 12:56:38 - train: epoch 0041, iter [01700, 05004], lr: 0.010000, loss: 1.8755, stu_CELoss: 1.0561, DKDLoss: 0.8194, 
2022-07-29 12:57:12 - train: epoch 0041, iter [01800, 05004], lr: 0.010000, loss: 1.7559, stu_CELoss: 1.0693, DKDLoss: 0.6866, 
2022-07-29 12:57:46 - train: epoch 0041, iter [01900, 05004], lr: 0.010000, loss: 2.0128, stu_CELoss: 1.2521, DKDLoss: 0.7607, 
2022-07-29 12:58:20 - train: epoch 0041, iter [02000, 05004], lr: 0.010000, loss: 1.5553, stu_CELoss: 0.8646, DKDLoss: 0.6907, 
2022-07-29 12:58:53 - train: epoch 0041, iter [02100, 05004], lr: 0.010000, loss: 1.7826, stu_CELoss: 1.0174, DKDLoss: 0.7652, 
2022-07-29 12:59:27 - train: epoch 0041, iter [02200, 05004], lr: 0.010000, loss: 1.6065, stu_CELoss: 0.9043, DKDLoss: 0.7022, 
2022-07-29 13:00:01 - train: epoch 0041, iter [02300, 05004], lr: 0.010000, loss: 1.8028, stu_CELoss: 1.0919, DKDLoss: 0.7110, 
2022-07-29 13:00:34 - train: epoch 0041, iter [02400, 05004], lr: 0.010000, loss: 2.0257, stu_CELoss: 1.2059, DKDLoss: 0.8198, 
2022-07-29 13:01:08 - train: epoch 0041, iter [02500, 05004], lr: 0.010000, loss: 2.0163, stu_CELoss: 1.1944, DKDLoss: 0.8219, 
2022-07-29 13:01:42 - train: epoch 0041, iter [02600, 05004], lr: 0.010000, loss: 2.0032, stu_CELoss: 1.2199, DKDLoss: 0.7833, 
2022-07-29 13:02:16 - train: epoch 0041, iter [02700, 05004], lr: 0.010000, loss: 1.8421, stu_CELoss: 1.0769, DKDLoss: 0.7652, 
2022-07-29 13:02:50 - train: epoch 0041, iter [02800, 05004], lr: 0.010000, loss: 1.7446, stu_CELoss: 1.0572, DKDLoss: 0.6874, 
2022-07-29 13:03:24 - train: epoch 0041, iter [02900, 05004], lr: 0.010000, loss: 1.7731, stu_CELoss: 1.0701, DKDLoss: 0.7030, 
2022-07-29 13:03:58 - train: epoch 0041, iter [03000, 05004], lr: 0.010000, loss: 1.8965, stu_CELoss: 1.1699, DKDLoss: 0.7266, 
2022-07-29 13:04:32 - train: epoch 0041, iter [03100, 05004], lr: 0.010000, loss: 1.8179, stu_CELoss: 1.0450, DKDLoss: 0.7729, 
2022-07-29 13:05:06 - train: epoch 0041, iter [03200, 05004], lr: 0.010000, loss: 1.6150, stu_CELoss: 0.8410, DKDLoss: 0.7740, 
2022-07-29 13:05:40 - train: epoch 0041, iter [03300, 05004], lr: 0.010000, loss: 1.7782, stu_CELoss: 1.0586, DKDLoss: 0.7196, 
2022-07-29 13:06:14 - train: epoch 0041, iter [03400, 05004], lr: 0.010000, loss: 1.5334, stu_CELoss: 0.9540, DKDLoss: 0.5794, 
2022-07-29 13:06:48 - train: epoch 0041, iter [03500, 05004], lr: 0.010000, loss: 1.6430, stu_CELoss: 0.9727, DKDLoss: 0.6704, 
2022-07-29 13:07:21 - train: epoch 0041, iter [03600, 05004], lr: 0.010000, loss: 1.7612, stu_CELoss: 1.0178, DKDLoss: 0.7434, 
2022-07-29 13:07:55 - train: epoch 0041, iter [03700, 05004], lr: 0.010000, loss: 1.7824, stu_CELoss: 1.0327, DKDLoss: 0.7497, 
2022-07-29 13:08:28 - train: epoch 0041, iter [03800, 05004], lr: 0.010000, loss: 1.9702, stu_CELoss: 1.1448, DKDLoss: 0.8254, 
2022-07-29 13:09:02 - train: epoch 0041, iter [03900, 05004], lr: 0.010000, loss: 1.8573, stu_CELoss: 1.1428, DKDLoss: 0.7145, 
2022-07-29 13:09:36 - train: epoch 0041, iter [04000, 05004], lr: 0.010000, loss: 1.8195, stu_CELoss: 1.1532, DKDLoss: 0.6664, 
2022-07-29 13:10:10 - train: epoch 0041, iter [04100, 05004], lr: 0.010000, loss: 1.7620, stu_CELoss: 1.0626, DKDLoss: 0.6994, 
2022-07-29 13:10:44 - train: epoch 0041, iter [04200, 05004], lr: 0.010000, loss: 1.8568, stu_CELoss: 1.0958, DKDLoss: 0.7609, 
2022-07-29 13:11:18 - train: epoch 0041, iter [04300, 05004], lr: 0.010000, loss: 1.8916, stu_CELoss: 1.0822, DKDLoss: 0.8094, 
2022-07-29 13:11:52 - train: epoch 0041, iter [04400, 05004], lr: 0.010000, loss: 1.7260, stu_CELoss: 1.0123, DKDLoss: 0.7136, 
2022-07-29 13:12:26 - train: epoch 0041, iter [04500, 05004], lr: 0.010000, loss: 2.0264, stu_CELoss: 1.1783, DKDLoss: 0.8481, 
2022-07-29 13:13:00 - train: epoch 0041, iter [04600, 05004], lr: 0.010000, loss: 1.8305, stu_CELoss: 1.1269, DKDLoss: 0.7037, 
2022-07-29 13:13:34 - train: epoch 0041, iter [04700, 05004], lr: 0.010000, loss: 1.8953, stu_CELoss: 1.1275, DKDLoss: 0.7678, 
2022-07-29 13:14:08 - train: epoch 0041, iter [04800, 05004], lr: 0.010000, loss: 1.7405, stu_CELoss: 1.0608, DKDLoss: 0.6798, 
2022-07-29 13:14:42 - train: epoch 0041, iter [04900, 05004], lr: 0.010000, loss: 1.8845, stu_CELoss: 1.1007, DKDLoss: 0.7838, 
2022-07-29 13:15:15 - train: epoch 0041, iter [05000, 05004], lr: 0.010000, loss: 1.7095, stu_CELoss: 0.9516, DKDLoss: 0.7580, 
2022-07-29 13:15:17 - train: epoch 041, train_loss: 1.8242
2022-07-29 13:17:48 - eval: epoch: 041, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 74.014%, stu_acc5: 91.862%, stu_test_loss: 1.0318
2022-07-29 13:17:49 - until epoch: 041, tea_best_acc1: 78.068%, stu_best_acc1: 74.276%
2022-07-29 13:17:49 - epoch 042 lr: 0.010000
2022-07-29 13:18:30 - train: epoch 0042, iter [00100, 05004], lr: 0.010000, loss: 1.4802, stu_CELoss: 0.7969, DKDLoss: 0.6832, 
2022-07-29 13:19:04 - train: epoch 0042, iter [00200, 05004], lr: 0.010000, loss: 1.5172, stu_CELoss: 0.8715, DKDLoss: 0.6457, 
2022-07-29 13:19:37 - train: epoch 0042, iter [00300, 05004], lr: 0.010000, loss: 1.8527, stu_CELoss: 1.1334, DKDLoss: 0.7193, 
2022-07-29 13:20:11 - train: epoch 0042, iter [00400, 05004], lr: 0.010000, loss: 1.6139, stu_CELoss: 0.9229, DKDLoss: 0.6910, 
2022-07-29 13:20:45 - train: epoch 0042, iter [00500, 05004], lr: 0.010000, loss: 1.7088, stu_CELoss: 1.0303, DKDLoss: 0.6785, 
2022-07-29 13:21:18 - train: epoch 0042, iter [00600, 05004], lr: 0.010000, loss: 1.7124, stu_CELoss: 0.9908, DKDLoss: 0.7217, 
2022-07-29 13:21:52 - train: epoch 0042, iter [00700, 05004], lr: 0.010000, loss: 1.8262, stu_CELoss: 1.0669, DKDLoss: 0.7593, 
2022-07-29 13:22:26 - train: epoch 0042, iter [00800, 05004], lr: 0.010000, loss: 1.9694, stu_CELoss: 1.1836, DKDLoss: 0.7858, 
2022-07-29 13:23:00 - train: epoch 0042, iter [00900, 05004], lr: 0.010000, loss: 1.9988, stu_CELoss: 1.2380, DKDLoss: 0.7607, 
2022-07-29 13:23:33 - train: epoch 0042, iter [01000, 05004], lr: 0.010000, loss: 2.1114, stu_CELoss: 1.3111, DKDLoss: 0.8004, 
2022-07-29 13:24:07 - train: epoch 0042, iter [01100, 05004], lr: 0.010000, loss: 1.7607, stu_CELoss: 1.0376, DKDLoss: 0.7231, 
2022-07-29 13:24:40 - train: epoch 0042, iter [01200, 05004], lr: 0.010000, loss: 1.6023, stu_CELoss: 0.9080, DKDLoss: 0.6942, 
2022-07-29 13:25:13 - train: epoch 0042, iter [01300, 05004], lr: 0.010000, loss: 1.7719, stu_CELoss: 1.0978, DKDLoss: 0.6741, 
2022-07-29 13:25:47 - train: epoch 0042, iter [01400, 05004], lr: 0.010000, loss: 1.8047, stu_CELoss: 1.0808, DKDLoss: 0.7239, 
2022-07-29 13:26:21 - train: epoch 0042, iter [01500, 05004], lr: 0.010000, loss: 1.6941, stu_CELoss: 0.9196, DKDLoss: 0.7745, 
2022-07-29 13:26:55 - train: epoch 0042, iter [01600, 05004], lr: 0.010000, loss: 1.9105, stu_CELoss: 1.1575, DKDLoss: 0.7530, 
2022-07-29 13:27:28 - train: epoch 0042, iter [01700, 05004], lr: 0.010000, loss: 1.6481, stu_CELoss: 0.9464, DKDLoss: 0.7018, 
2022-07-29 13:28:02 - train: epoch 0042, iter [01800, 05004], lr: 0.010000, loss: 1.6604, stu_CELoss: 0.9772, DKDLoss: 0.6832, 
2022-07-29 13:28:36 - train: epoch 0042, iter [01900, 05004], lr: 0.010000, loss: 1.9664, stu_CELoss: 1.0983, DKDLoss: 0.8681, 
2022-07-29 13:29:09 - train: epoch 0042, iter [02000, 05004], lr: 0.010000, loss: 1.5975, stu_CELoss: 0.8960, DKDLoss: 0.7015, 
2022-07-29 13:29:43 - train: epoch 0042, iter [02100, 05004], lr: 0.010000, loss: 1.6541, stu_CELoss: 1.0175, DKDLoss: 0.6366, 
2022-07-29 13:30:17 - train: epoch 0042, iter [02200, 05004], lr: 0.010000, loss: 1.6754, stu_CELoss: 0.9972, DKDLoss: 0.6783, 
2022-07-29 13:30:51 - train: epoch 0042, iter [02300, 05004], lr: 0.010000, loss: 1.6746, stu_CELoss: 0.9202, DKDLoss: 0.7543, 
2022-07-29 13:31:24 - train: epoch 0042, iter [02400, 05004], lr: 0.010000, loss: 1.8768, stu_CELoss: 1.0799, DKDLoss: 0.7969, 
2022-07-29 13:31:58 - train: epoch 0042, iter [02500, 05004], lr: 0.010000, loss: 1.7725, stu_CELoss: 1.0312, DKDLoss: 0.7413, 
2022-07-29 13:32:32 - train: epoch 0042, iter [02600, 05004], lr: 0.010000, loss: 1.7711, stu_CELoss: 1.0242, DKDLoss: 0.7469, 
2022-07-29 13:33:05 - train: epoch 0042, iter [02700, 05004], lr: 0.010000, loss: 1.6060, stu_CELoss: 0.9306, DKDLoss: 0.6753, 
2022-07-29 13:33:39 - train: epoch 0042, iter [02800, 05004], lr: 0.010000, loss: 1.7445, stu_CELoss: 0.9850, DKDLoss: 0.7596, 
2022-07-29 13:34:13 - train: epoch 0042, iter [02900, 05004], lr: 0.010000, loss: 1.6235, stu_CELoss: 0.9920, DKDLoss: 0.6314, 
2022-07-29 13:34:47 - train: epoch 0042, iter [03000, 05004], lr: 0.010000, loss: 1.7403, stu_CELoss: 1.0307, DKDLoss: 0.7096, 
2022-07-29 13:35:21 - train: epoch 0042, iter [03100, 05004], lr: 0.010000, loss: 1.9154, stu_CELoss: 1.0590, DKDLoss: 0.8564, 
2022-07-29 13:35:54 - train: epoch 0042, iter [03200, 05004], lr: 0.010000, loss: 2.0683, stu_CELoss: 1.1957, DKDLoss: 0.8726, 
2022-07-29 13:36:28 - train: epoch 0042, iter [03300, 05004], lr: 0.010000, loss: 1.7872, stu_CELoss: 1.0626, DKDLoss: 0.7246, 
2022-07-29 13:37:01 - train: epoch 0042, iter [03400, 05004], lr: 0.010000, loss: 1.7481, stu_CELoss: 1.0167, DKDLoss: 0.7313, 
2022-07-29 13:37:35 - train: epoch 0042, iter [03500, 05004], lr: 0.010000, loss: 1.7392, stu_CELoss: 1.0829, DKDLoss: 0.6563, 
2022-07-29 13:38:08 - train: epoch 0042, iter [03600, 05004], lr: 0.010000, loss: 1.9338, stu_CELoss: 1.2268, DKDLoss: 0.7071, 
2022-07-29 13:38:41 - train: epoch 0042, iter [03700, 05004], lr: 0.010000, loss: 1.7800, stu_CELoss: 1.0225, DKDLoss: 0.7576, 
2022-07-29 13:39:15 - train: epoch 0042, iter [03800, 05004], lr: 0.010000, loss: 1.6014, stu_CELoss: 0.9259, DKDLoss: 0.6755, 
2022-07-29 13:39:48 - train: epoch 0042, iter [03900, 05004], lr: 0.010000, loss: 1.9573, stu_CELoss: 1.0634, DKDLoss: 0.8939, 
2022-07-29 13:40:22 - train: epoch 0042, iter [04000, 05004], lr: 0.010000, loss: 1.7906, stu_CELoss: 1.0580, DKDLoss: 0.7326, 
2022-07-29 13:40:55 - train: epoch 0042, iter [04100, 05004], lr: 0.010000, loss: 1.8634, stu_CELoss: 1.0736, DKDLoss: 0.7899, 
2022-07-29 13:41:28 - train: epoch 0042, iter [04200, 05004], lr: 0.010000, loss: 1.9029, stu_CELoss: 1.0857, DKDLoss: 0.8172, 
2022-07-29 13:42:02 - train: epoch 0042, iter [04300, 05004], lr: 0.010000, loss: 1.7244, stu_CELoss: 1.0257, DKDLoss: 0.6987, 
2022-07-29 13:42:36 - train: epoch 0042, iter [04400, 05004], lr: 0.010000, loss: 1.7074, stu_CELoss: 0.9901, DKDLoss: 0.7173, 
2022-07-29 13:43:09 - train: epoch 0042, iter [04500, 05004], lr: 0.010000, loss: 1.6545, stu_CELoss: 0.9230, DKDLoss: 0.7315, 
2022-07-29 13:43:42 - train: epoch 0042, iter [04600, 05004], lr: 0.010000, loss: 1.9466, stu_CELoss: 1.1228, DKDLoss: 0.8238, 
2022-07-29 13:44:16 - train: epoch 0042, iter [04700, 05004], lr: 0.010000, loss: 1.7286, stu_CELoss: 1.0320, DKDLoss: 0.6966, 
2022-07-29 13:44:49 - train: epoch 0042, iter [04800, 05004], lr: 0.010000, loss: 1.9204, stu_CELoss: 1.1705, DKDLoss: 0.7498, 
2022-07-29 13:45:23 - train: epoch 0042, iter [04900, 05004], lr: 0.010000, loss: 1.7614, stu_CELoss: 0.9935, DKDLoss: 0.7679, 
2022-07-29 13:45:56 - train: epoch 0042, iter [05000, 05004], lr: 0.010000, loss: 1.9044, stu_CELoss: 1.1037, DKDLoss: 0.8007, 
2022-07-29 13:45:58 - train: epoch 042, train_loss: 1.8216
2022-07-29 13:48:29 - eval: epoch: 042, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 73.296%, stu_acc5: 91.764%, stu_test_loss: 1.0525
2022-07-29 13:48:30 - until epoch: 042, tea_best_acc1: 78.068%, stu_best_acc1: 74.276%
2022-07-29 13:48:30 - epoch 043 lr: 0.010000
2022-07-29 13:49:09 - train: epoch 0043, iter [00100, 05004], lr: 0.010000, loss: 1.9146, stu_CELoss: 1.2382, DKDLoss: 0.6764, 
2022-07-29 13:49:43 - train: epoch 0043, iter [00200, 05004], lr: 0.010000, loss: 1.8825, stu_CELoss: 1.0700, DKDLoss: 0.8125, 
2022-07-29 13:50:16 - train: epoch 0043, iter [00300, 05004], lr: 0.010000, loss: 1.5391, stu_CELoss: 0.9019, DKDLoss: 0.6372, 
2022-07-29 13:50:49 - train: epoch 0043, iter [00400, 05004], lr: 0.010000, loss: 1.6157, stu_CELoss: 0.8721, DKDLoss: 0.7436, 
2022-07-29 13:51:22 - train: epoch 0043, iter [00500, 05004], lr: 0.010000, loss: 2.0086, stu_CELoss: 1.3631, DKDLoss: 0.6455, 
2022-07-29 13:51:55 - train: epoch 0043, iter [00600, 05004], lr: 0.010000, loss: 1.7573, stu_CELoss: 1.0058, DKDLoss: 0.7515, 
2022-07-29 13:52:28 - train: epoch 0043, iter [00700, 05004], lr: 0.010000, loss: 1.6573, stu_CELoss: 0.9419, DKDLoss: 0.7153, 
2022-07-29 13:53:02 - train: epoch 0043, iter [00800, 05004], lr: 0.010000, loss: 1.7726, stu_CELoss: 1.0320, DKDLoss: 0.7406, 
2022-07-29 13:53:35 - train: epoch 0043, iter [00900, 05004], lr: 0.010000, loss: 1.7571, stu_CELoss: 1.0459, DKDLoss: 0.7112, 
2022-07-29 13:54:08 - train: epoch 0043, iter [01000, 05004], lr: 0.010000, loss: 2.0677, stu_CELoss: 1.2202, DKDLoss: 0.8476, 
2022-07-29 13:54:41 - train: epoch 0043, iter [01100, 05004], lr: 0.010000, loss: 1.7665, stu_CELoss: 1.0802, DKDLoss: 0.6863, 
2022-07-29 13:55:15 - train: epoch 0043, iter [01200, 05004], lr: 0.010000, loss: 1.7972, stu_CELoss: 1.0592, DKDLoss: 0.7380, 
2022-07-29 13:55:48 - train: epoch 0043, iter [01300, 05004], lr: 0.010000, loss: 2.0176, stu_CELoss: 1.2146, DKDLoss: 0.8030, 
2022-07-29 13:56:21 - train: epoch 0043, iter [01400, 05004], lr: 0.010000, loss: 1.7752, stu_CELoss: 1.0570, DKDLoss: 0.7182, 
2022-07-29 13:56:55 - train: epoch 0043, iter [01500, 05004], lr: 0.010000, loss: 1.7352, stu_CELoss: 0.9780, DKDLoss: 0.7572, 
2022-07-29 13:57:28 - train: epoch 0043, iter [01600, 05004], lr: 0.010000, loss: 1.7690, stu_CELoss: 1.0848, DKDLoss: 0.6842, 
2022-07-29 13:58:01 - train: epoch 0043, iter [01700, 05004], lr: 0.010000, loss: 1.8715, stu_CELoss: 1.0944, DKDLoss: 0.7771, 
2022-07-29 13:58:35 - train: epoch 0043, iter [01800, 05004], lr: 0.010000, loss: 1.9564, stu_CELoss: 1.1776, DKDLoss: 0.7788, 
2022-07-29 13:59:08 - train: epoch 0043, iter [01900, 05004], lr: 0.010000, loss: 1.7296, stu_CELoss: 0.9958, DKDLoss: 0.7337, 
2022-07-29 13:59:41 - train: epoch 0043, iter [02000, 05004], lr: 0.010000, loss: 1.8520, stu_CELoss: 1.1483, DKDLoss: 0.7037, 
2022-07-29 14:00:14 - train: epoch 0043, iter [02100, 05004], lr: 0.010000, loss: 1.5792, stu_CELoss: 0.8522, DKDLoss: 0.7270, 
2022-07-29 14:00:47 - train: epoch 0043, iter [02200, 05004], lr: 0.010000, loss: 2.1052, stu_CELoss: 1.2898, DKDLoss: 0.8154, 
2022-07-29 14:01:20 - train: epoch 0043, iter [02300, 05004], lr: 0.010000, loss: 1.7192, stu_CELoss: 1.0754, DKDLoss: 0.6438, 
2022-07-29 14:01:53 - train: epoch 0043, iter [02400, 05004], lr: 0.010000, loss: 1.6245, stu_CELoss: 0.8885, DKDLoss: 0.7360, 
2022-07-29 14:02:26 - train: epoch 0043, iter [02500, 05004], lr: 0.010000, loss: 2.0571, stu_CELoss: 1.1907, DKDLoss: 0.8663, 
2022-07-29 14:02:59 - train: epoch 0043, iter [02600, 05004], lr: 0.010000, loss: 1.6079, stu_CELoss: 0.9338, DKDLoss: 0.6741, 
2022-07-29 14:03:33 - train: epoch 0043, iter [02700, 05004], lr: 0.010000, loss: 1.9140, stu_CELoss: 1.2142, DKDLoss: 0.6998, 
2022-07-29 14:04:06 - train: epoch 0043, iter [02800, 05004], lr: 0.010000, loss: 1.7551, stu_CELoss: 1.0436, DKDLoss: 0.7116, 
2022-07-29 14:04:40 - train: epoch 0043, iter [02900, 05004], lr: 0.010000, loss: 1.7317, stu_CELoss: 0.9924, DKDLoss: 0.7392, 
2022-07-29 14:05:13 - train: epoch 0043, iter [03000, 05004], lr: 0.010000, loss: 2.1037, stu_CELoss: 1.3362, DKDLoss: 0.7675, 
2022-07-29 14:05:47 - train: epoch 0043, iter [03100, 05004], lr: 0.010000, loss: 2.1013, stu_CELoss: 1.2561, DKDLoss: 0.8452, 
2022-07-29 14:06:20 - train: epoch 0043, iter [03200, 05004], lr: 0.010000, loss: 2.1343, stu_CELoss: 1.3158, DKDLoss: 0.8185, 
2022-07-29 14:06:54 - train: epoch 0043, iter [03300, 05004], lr: 0.010000, loss: 2.0327, stu_CELoss: 1.2502, DKDLoss: 0.7825, 
2022-07-29 14:07:27 - train: epoch 0043, iter [03400, 05004], lr: 0.010000, loss: 1.8809, stu_CELoss: 1.0661, DKDLoss: 0.8148, 
2022-07-29 14:08:00 - train: epoch 0043, iter [03500, 05004], lr: 0.010000, loss: 1.8428, stu_CELoss: 1.1356, DKDLoss: 0.7072, 
2022-07-29 14:08:34 - train: epoch 0043, iter [03600, 05004], lr: 0.010000, loss: 1.8966, stu_CELoss: 1.0644, DKDLoss: 0.8322, 
2022-07-29 14:09:07 - train: epoch 0043, iter [03700, 05004], lr: 0.010000, loss: 1.7603, stu_CELoss: 0.9852, DKDLoss: 0.7751, 
2022-07-29 14:09:41 - train: epoch 0043, iter [03800, 05004], lr: 0.010000, loss: 1.9981, stu_CELoss: 1.2269, DKDLoss: 0.7712, 
2022-07-29 14:10:14 - train: epoch 0043, iter [03900, 05004], lr: 0.010000, loss: 1.9110, stu_CELoss: 1.0489, DKDLoss: 0.8621, 
2022-07-29 14:10:47 - train: epoch 0043, iter [04000, 05004], lr: 0.010000, loss: 2.1236, stu_CELoss: 1.2788, DKDLoss: 0.8448, 
2022-07-29 14:11:21 - train: epoch 0043, iter [04100, 05004], lr: 0.010000, loss: 1.9994, stu_CELoss: 1.1448, DKDLoss: 0.8546, 
2022-07-29 14:11:54 - train: epoch 0043, iter [04200, 05004], lr: 0.010000, loss: 1.9545, stu_CELoss: 1.1797, DKDLoss: 0.7748, 
2022-07-29 14:12:28 - train: epoch 0043, iter [04300, 05004], lr: 0.010000, loss: 1.8372, stu_CELoss: 1.1060, DKDLoss: 0.7312, 
2022-07-29 14:13:01 - train: epoch 0043, iter [04400, 05004], lr: 0.010000, loss: 1.8449, stu_CELoss: 1.0493, DKDLoss: 0.7957, 
2022-07-29 14:13:35 - train: epoch 0043, iter [04500, 05004], lr: 0.010000, loss: 1.8201, stu_CELoss: 1.0709, DKDLoss: 0.7493, 
2022-07-29 14:14:09 - train: epoch 0043, iter [04600, 05004], lr: 0.010000, loss: 1.7501, stu_CELoss: 1.0122, DKDLoss: 0.7379, 
2022-07-29 14:14:42 - train: epoch 0043, iter [04700, 05004], lr: 0.010000, loss: 1.6018, stu_CELoss: 0.8952, DKDLoss: 0.7066, 
2022-07-29 14:15:16 - train: epoch 0043, iter [04800, 05004], lr: 0.010000, loss: 2.0445, stu_CELoss: 1.1388, DKDLoss: 0.9057, 
2022-07-29 14:15:49 - train: epoch 0043, iter [04900, 05004], lr: 0.010000, loss: 1.7519, stu_CELoss: 0.9936, DKDLoss: 0.7583, 
2022-07-29 14:16:23 - train: epoch 0043, iter [05000, 05004], lr: 0.010000, loss: 1.9172, stu_CELoss: 1.1718, DKDLoss: 0.7453, 
2022-07-29 14:16:24 - train: epoch 043, train_loss: 1.8208
2022-07-29 14:18:57 - eval: epoch: 043, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 73.634%, stu_acc5: 91.816%, stu_test_loss: 1.0417
2022-07-29 14:18:57 - until epoch: 043, tea_best_acc1: 78.068%, stu_best_acc1: 74.276%
2022-07-29 14:18:57 - epoch 044 lr: 0.010000
2022-07-29 14:19:37 - train: epoch 0044, iter [00100, 05004], lr: 0.010000, loss: 1.7245, stu_CELoss: 1.0125, DKDLoss: 0.7120, 
2022-07-29 14:20:09 - train: epoch 0044, iter [00200, 05004], lr: 0.010000, loss: 1.6034, stu_CELoss: 0.9163, DKDLoss: 0.6871, 
2022-07-29 14:20:42 - train: epoch 0044, iter [00300, 05004], lr: 0.010000, loss: 1.7029, stu_CELoss: 0.9829, DKDLoss: 0.7200, 
2022-07-29 14:21:15 - train: epoch 0044, iter [00400, 05004], lr: 0.010000, loss: 1.5344, stu_CELoss: 0.8673, DKDLoss: 0.6671, 
2022-07-29 14:21:48 - train: epoch 0044, iter [00500, 05004], lr: 0.010000, loss: 2.0116, stu_CELoss: 1.2142, DKDLoss: 0.7974, 
2022-07-29 14:22:20 - train: epoch 0044, iter [00600, 05004], lr: 0.010000, loss: 1.7070, stu_CELoss: 1.0335, DKDLoss: 0.6735, 
2022-07-29 14:22:53 - train: epoch 0044, iter [00700, 05004], lr: 0.010000, loss: 1.8178, stu_CELoss: 1.0675, DKDLoss: 0.7503, 
2022-07-29 14:23:26 - train: epoch 0044, iter [00800, 05004], lr: 0.010000, loss: 1.7319, stu_CELoss: 1.0491, DKDLoss: 0.6828, 
2022-07-29 14:23:59 - train: epoch 0044, iter [00900, 05004], lr: 0.010000, loss: 1.6593, stu_CELoss: 1.0011, DKDLoss: 0.6582, 
2022-07-29 14:24:31 - train: epoch 0044, iter [01000, 05004], lr: 0.010000, loss: 1.7285, stu_CELoss: 1.0058, DKDLoss: 0.7227, 
2022-07-29 14:25:04 - train: epoch 0044, iter [01100, 05004], lr: 0.010000, loss: 1.7275, stu_CELoss: 1.0744, DKDLoss: 0.6531, 
2022-07-29 14:25:37 - train: epoch 0044, iter [01200, 05004], lr: 0.010000, loss: 1.6602, stu_CELoss: 0.9491, DKDLoss: 0.7112, 
2022-07-29 14:26:10 - train: epoch 0044, iter [01300, 05004], lr: 0.010000, loss: 2.0024, stu_CELoss: 1.2460, DKDLoss: 0.7563, 
2022-07-29 14:26:43 - train: epoch 0044, iter [01400, 05004], lr: 0.010000, loss: 1.7186, stu_CELoss: 1.0262, DKDLoss: 0.6925, 
2022-07-29 14:27:15 - train: epoch 0044, iter [01500, 05004], lr: 0.010000, loss: 1.8258, stu_CELoss: 1.0075, DKDLoss: 0.8183, 
2022-07-29 14:27:49 - train: epoch 0044, iter [01600, 05004], lr: 0.010000, loss: 1.7927, stu_CELoss: 0.9896, DKDLoss: 0.8031, 
2022-07-29 14:28:22 - train: epoch 0044, iter [01700, 05004], lr: 0.010000, loss: 1.7406, stu_CELoss: 1.0129, DKDLoss: 0.7278, 
2022-07-29 14:28:55 - train: epoch 0044, iter [01800, 05004], lr: 0.010000, loss: 1.7842, stu_CELoss: 1.0798, DKDLoss: 0.7043, 
2022-07-29 14:29:28 - train: epoch 0044, iter [01900, 05004], lr: 0.010000, loss: 1.8330, stu_CELoss: 1.0660, DKDLoss: 0.7670, 
2022-07-29 14:30:01 - train: epoch 0044, iter [02000, 05004], lr: 0.010000, loss: 1.5905, stu_CELoss: 0.9707, DKDLoss: 0.6198, 
2022-07-29 14:30:35 - train: epoch 0044, iter [02100, 05004], lr: 0.010000, loss: 2.0262, stu_CELoss: 1.2624, DKDLoss: 0.7638, 
2022-07-29 14:31:08 - train: epoch 0044, iter [02200, 05004], lr: 0.010000, loss: 1.7670, stu_CELoss: 1.0489, DKDLoss: 0.7181, 
2022-07-29 14:31:41 - train: epoch 0044, iter [02300, 05004], lr: 0.010000, loss: 1.9710, stu_CELoss: 1.1547, DKDLoss: 0.8163, 
2022-07-29 14:32:15 - train: epoch 0044, iter [02400, 05004], lr: 0.010000, loss: 1.8091, stu_CELoss: 1.0977, DKDLoss: 0.7113, 
2022-07-29 14:32:48 - train: epoch 0044, iter [02500, 05004], lr: 0.010000, loss: 1.7656, stu_CELoss: 1.0327, DKDLoss: 0.7329, 
2022-07-29 14:33:21 - train: epoch 0044, iter [02600, 05004], lr: 0.010000, loss: 1.7216, stu_CELoss: 1.0012, DKDLoss: 0.7205, 
2022-07-29 14:33:55 - train: epoch 0044, iter [02700, 05004], lr: 0.010000, loss: 1.9645, stu_CELoss: 1.2687, DKDLoss: 0.6957, 
2022-07-29 14:34:28 - train: epoch 0044, iter [02800, 05004], lr: 0.010000, loss: 1.5949, stu_CELoss: 0.9354, DKDLoss: 0.6595, 
2022-07-29 14:35:01 - train: epoch 0044, iter [02900, 05004], lr: 0.010000, loss: 1.4289, stu_CELoss: 0.7901, DKDLoss: 0.6388, 
2022-07-29 14:35:34 - train: epoch 0044, iter [03000, 05004], lr: 0.010000, loss: 1.5995, stu_CELoss: 0.9331, DKDLoss: 0.6665, 
2022-07-29 14:36:07 - train: epoch 0044, iter [03100, 05004], lr: 0.010000, loss: 1.5386, stu_CELoss: 0.9532, DKDLoss: 0.5854, 
2022-07-29 14:36:40 - train: epoch 0044, iter [03200, 05004], lr: 0.010000, loss: 1.7867, stu_CELoss: 1.0690, DKDLoss: 0.7177, 
2022-07-29 14:37:13 - train: epoch 0044, iter [03300, 05004], lr: 0.010000, loss: 1.6881, stu_CELoss: 0.9767, DKDLoss: 0.7113, 
2022-07-29 14:37:46 - train: epoch 0044, iter [03400, 05004], lr: 0.010000, loss: 2.2221, stu_CELoss: 1.4010, DKDLoss: 0.8211, 
2022-07-29 14:38:20 - train: epoch 0044, iter [03500, 05004], lr: 0.010000, loss: 1.8363, stu_CELoss: 1.0585, DKDLoss: 0.7778, 
2022-07-29 14:38:53 - train: epoch 0044, iter [03600, 05004], lr: 0.010000, loss: 1.6741, stu_CELoss: 0.9254, DKDLoss: 0.7487, 
2022-07-29 14:39:26 - train: epoch 0044, iter [03700, 05004], lr: 0.010000, loss: 1.9413, stu_CELoss: 1.1516, DKDLoss: 0.7898, 
2022-07-29 14:39:59 - train: epoch 0044, iter [03800, 05004], lr: 0.010000, loss: 1.6537, stu_CELoss: 0.9406, DKDLoss: 0.7131, 
2022-07-29 14:40:32 - train: epoch 0044, iter [03900, 05004], lr: 0.010000, loss: 1.9690, stu_CELoss: 1.1380, DKDLoss: 0.8310, 
2022-07-29 14:41:05 - train: epoch 0044, iter [04000, 05004], lr: 0.010000, loss: 1.9327, stu_CELoss: 1.2333, DKDLoss: 0.6994, 
2022-07-29 14:41:39 - train: epoch 0044, iter [04100, 05004], lr: 0.010000, loss: 1.8273, stu_CELoss: 1.1067, DKDLoss: 0.7206, 
2022-07-29 14:42:12 - train: epoch 0044, iter [04200, 05004], lr: 0.010000, loss: 1.8355, stu_CELoss: 1.1030, DKDLoss: 0.7325, 
2022-07-29 14:42:45 - train: epoch 0044, iter [04300, 05004], lr: 0.010000, loss: 1.8428, stu_CELoss: 1.0702, DKDLoss: 0.7726, 
2022-07-29 14:43:18 - train: epoch 0044, iter [04400, 05004], lr: 0.010000, loss: 1.7999, stu_CELoss: 1.1351, DKDLoss: 0.6648, 
2022-07-29 14:43:51 - train: epoch 0044, iter [04500, 05004], lr: 0.010000, loss: 2.1878, stu_CELoss: 1.3680, DKDLoss: 0.8198, 
2022-07-29 14:44:24 - train: epoch 0044, iter [04600, 05004], lr: 0.010000, loss: 1.8425, stu_CELoss: 1.0963, DKDLoss: 0.7463, 
2022-07-29 14:44:57 - train: epoch 0044, iter [04700, 05004], lr: 0.010000, loss: 1.9411, stu_CELoss: 1.1097, DKDLoss: 0.8314, 
2022-07-29 14:45:30 - train: epoch 0044, iter [04800, 05004], lr: 0.010000, loss: 1.8310, stu_CELoss: 1.1313, DKDLoss: 0.6997, 
2022-07-29 14:46:04 - train: epoch 0044, iter [04900, 05004], lr: 0.010000, loss: 1.8599, stu_CELoss: 1.1315, DKDLoss: 0.7284, 
2022-07-29 14:46:36 - train: epoch 0044, iter [05000, 05004], lr: 0.010000, loss: 1.7878, stu_CELoss: 1.0644, DKDLoss: 0.7234, 
2022-07-29 14:46:38 - train: epoch 044, train_loss: 1.8188
2022-07-29 14:49:08 - eval: epoch: 044, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 73.646%, stu_acc5: 91.920%, stu_test_loss: 1.0445
2022-07-29 14:49:08 - until epoch: 044, tea_best_acc1: 78.068%, stu_best_acc1: 74.276%
2022-07-29 14:49:08 - epoch 045 lr: 0.010000
2022-07-29 14:49:48 - train: epoch 0045, iter [00100, 05004], lr: 0.010000, loss: 1.6695, stu_CELoss: 0.9423, DKDLoss: 0.7271, 
2022-07-29 14:50:19 - train: epoch 0045, iter [00200, 05004], lr: 0.010000, loss: 1.8671, stu_CELoss: 1.0977, DKDLoss: 0.7694, 
2022-07-29 14:50:52 - train: epoch 0045, iter [00300, 05004], lr: 0.010000, loss: 1.8321, stu_CELoss: 1.1028, DKDLoss: 0.7294, 
2022-07-29 14:51:24 - train: epoch 0045, iter [00400, 05004], lr: 0.010000, loss: 1.7699, stu_CELoss: 1.0682, DKDLoss: 0.7017, 
2022-07-29 14:51:56 - train: epoch 0045, iter [00500, 05004], lr: 0.010000, loss: 2.2233, stu_CELoss: 1.4153, DKDLoss: 0.8081, 
2022-07-29 14:52:29 - train: epoch 0045, iter [00600, 05004], lr: 0.010000, loss: 1.8177, stu_CELoss: 1.0730, DKDLoss: 0.7447, 
2022-07-29 14:53:02 - train: epoch 0045, iter [00700, 05004], lr: 0.010000, loss: 1.4915, stu_CELoss: 0.8621, DKDLoss: 0.6293, 
2022-07-29 14:53:34 - train: epoch 0045, iter [00800, 05004], lr: 0.010000, loss: 1.7316, stu_CELoss: 1.0392, DKDLoss: 0.6923, 
2022-07-29 14:54:07 - train: epoch 0045, iter [00900, 05004], lr: 0.010000, loss: 1.6791, stu_CELoss: 0.9375, DKDLoss: 0.7415, 
2022-07-29 14:54:40 - train: epoch 0045, iter [01000, 05004], lr: 0.010000, loss: 1.5557, stu_CELoss: 0.8223, DKDLoss: 0.7334, 
2022-07-29 14:55:12 - train: epoch 0045, iter [01100, 05004], lr: 0.010000, loss: 1.7607, stu_CELoss: 1.0317, DKDLoss: 0.7290, 
2022-07-29 14:55:45 - train: epoch 0045, iter [01200, 05004], lr: 0.010000, loss: 1.7768, stu_CELoss: 1.0704, DKDLoss: 0.7064, 
2022-07-29 14:56:18 - train: epoch 0045, iter [01300, 05004], lr: 0.010000, loss: 1.8118, stu_CELoss: 1.0645, DKDLoss: 0.7473, 
2022-07-29 14:56:51 - train: epoch 0045, iter [01400, 05004], lr: 0.010000, loss: 2.0120, stu_CELoss: 1.1943, DKDLoss: 0.8178, 
2022-07-29 14:57:24 - train: epoch 0045, iter [01500, 05004], lr: 0.010000, loss: 1.7631, stu_CELoss: 1.1138, DKDLoss: 0.6493, 
2022-07-29 14:57:57 - train: epoch 0045, iter [01600, 05004], lr: 0.010000, loss: 1.8132, stu_CELoss: 1.1352, DKDLoss: 0.6780, 
2022-07-29 14:58:30 - train: epoch 0045, iter [01700, 05004], lr: 0.010000, loss: 1.6844, stu_CELoss: 1.0005, DKDLoss: 0.6839, 
2022-07-29 14:59:03 - train: epoch 0045, iter [01800, 05004], lr: 0.010000, loss: 1.8792, stu_CELoss: 1.0855, DKDLoss: 0.7937, 
2022-07-29 14:59:36 - train: epoch 0045, iter [01900, 05004], lr: 0.010000, loss: 1.7333, stu_CELoss: 1.0307, DKDLoss: 0.7026, 
2022-07-29 15:00:10 - train: epoch 0045, iter [02000, 05004], lr: 0.010000, loss: 1.9637, stu_CELoss: 1.1749, DKDLoss: 0.7888, 
2022-07-29 15:00:42 - train: epoch 0045, iter [02100, 05004], lr: 0.010000, loss: 1.9848, stu_CELoss: 1.1486, DKDLoss: 0.8363, 
2022-07-29 15:01:15 - train: epoch 0045, iter [02200, 05004], lr: 0.010000, loss: 1.9093, stu_CELoss: 1.1603, DKDLoss: 0.7491, 
2022-07-29 15:01:49 - train: epoch 0045, iter [02300, 05004], lr: 0.010000, loss: 1.8341, stu_CELoss: 1.0226, DKDLoss: 0.8115, 
2022-07-29 15:02:22 - train: epoch 0045, iter [02400, 05004], lr: 0.010000, loss: 1.7285, stu_CELoss: 1.0185, DKDLoss: 0.7100, 
2022-07-29 15:02:55 - train: epoch 0045, iter [02500, 05004], lr: 0.010000, loss: 1.9874, stu_CELoss: 1.2866, DKDLoss: 0.7008, 
2022-07-29 15:03:29 - train: epoch 0045, iter [02600, 05004], lr: 0.010000, loss: 1.6352, stu_CELoss: 0.9611, DKDLoss: 0.6740, 
2022-07-29 15:04:02 - train: epoch 0045, iter [02700, 05004], lr: 0.010000, loss: 1.5745, stu_CELoss: 0.8751, DKDLoss: 0.6994, 
2022-07-29 15:04:35 - train: epoch 0045, iter [02800, 05004], lr: 0.010000, loss: 1.7247, stu_CELoss: 0.9642, DKDLoss: 0.7605, 
2022-07-29 15:05:08 - train: epoch 0045, iter [02900, 05004], lr: 0.010000, loss: 2.1371, stu_CELoss: 1.2766, DKDLoss: 0.8605, 
2022-07-29 15:05:41 - train: epoch 0045, iter [03000, 05004], lr: 0.010000, loss: 1.7801, stu_CELoss: 1.0085, DKDLoss: 0.7717, 
2022-07-29 15:06:14 - train: epoch 0045, iter [03100, 05004], lr: 0.010000, loss: 1.7590, stu_CELoss: 1.0624, DKDLoss: 0.6967, 
2022-07-29 15:06:47 - train: epoch 0045, iter [03200, 05004], lr: 0.010000, loss: 2.0591, stu_CELoss: 1.2654, DKDLoss: 0.7937, 
2022-07-29 15:07:21 - train: epoch 0045, iter [03300, 05004], lr: 0.010000, loss: 1.8374, stu_CELoss: 1.0393, DKDLoss: 0.7981, 
2022-07-29 15:07:54 - train: epoch 0045, iter [03400, 05004], lr: 0.010000, loss: 1.7752, stu_CELoss: 0.9694, DKDLoss: 0.8057, 
2022-07-29 15:08:27 - train: epoch 0045, iter [03500, 05004], lr: 0.010000, loss: 1.8149, stu_CELoss: 1.0320, DKDLoss: 0.7829, 
2022-07-29 15:09:00 - train: epoch 0045, iter [03600, 05004], lr: 0.010000, loss: 1.7635, stu_CELoss: 0.9967, DKDLoss: 0.7668, 
2022-07-29 15:09:33 - train: epoch 0045, iter [03700, 05004], lr: 0.010000, loss: 1.7953, stu_CELoss: 1.0140, DKDLoss: 0.7812, 
2022-07-29 15:10:07 - train: epoch 0045, iter [03800, 05004], lr: 0.010000, loss: 1.8103, stu_CELoss: 1.0099, DKDLoss: 0.8005, 
2022-07-29 15:10:40 - train: epoch 0045, iter [03900, 05004], lr: 0.010000, loss: 1.9840, stu_CELoss: 1.1623, DKDLoss: 0.8217, 
2022-07-29 15:11:13 - train: epoch 0045, iter [04000, 05004], lr: 0.010000, loss: 1.8210, stu_CELoss: 1.0786, DKDLoss: 0.7425, 
2022-07-29 15:11:47 - train: epoch 0045, iter [04100, 05004], lr: 0.010000, loss: 1.7459, stu_CELoss: 1.0329, DKDLoss: 0.7130, 
2022-07-29 15:12:20 - train: epoch 0045, iter [04200, 05004], lr: 0.010000, loss: 2.0940, stu_CELoss: 1.2570, DKDLoss: 0.8370, 
2022-07-29 15:12:54 - train: epoch 0045, iter [04300, 05004], lr: 0.010000, loss: 2.1235, stu_CELoss: 1.2696, DKDLoss: 0.8539, 
2022-07-29 15:13:28 - train: epoch 0045, iter [04400, 05004], lr: 0.010000, loss: 1.9312, stu_CELoss: 1.1682, DKDLoss: 0.7630, 
2022-07-29 15:14:01 - train: epoch 0045, iter [04500, 05004], lr: 0.010000, loss: 1.7055, stu_CELoss: 0.9646, DKDLoss: 0.7409, 
2022-07-29 15:14:34 - train: epoch 0045, iter [04600, 05004], lr: 0.010000, loss: 1.9273, stu_CELoss: 1.1430, DKDLoss: 0.7842, 
2022-07-29 15:15:08 - train: epoch 0045, iter [04700, 05004], lr: 0.010000, loss: 1.9685, stu_CELoss: 1.2015, DKDLoss: 0.7670, 
2022-07-29 15:15:42 - train: epoch 0045, iter [04800, 05004], lr: 0.010000, loss: 1.7077, stu_CELoss: 1.0265, DKDLoss: 0.6812, 
2022-07-29 15:16:15 - train: epoch 0045, iter [04900, 05004], lr: 0.010000, loss: 1.9249, stu_CELoss: 1.1474, DKDLoss: 0.7775, 
2022-07-29 15:16:48 - train: epoch 0045, iter [05000, 05004], lr: 0.010000, loss: 1.7868, stu_CELoss: 1.0604, DKDLoss: 0.7264, 
2022-07-29 15:16:50 - train: epoch 045, train_loss: 1.8165
2022-07-29 15:19:22 - eval: epoch: 045, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 73.304%, stu_acc5: 91.518%, stu_test_loss: 1.0622
2022-07-29 15:19:23 - until epoch: 045, tea_best_acc1: 78.068%, stu_best_acc1: 74.276%
2022-07-29 15:19:23 - epoch 046 lr: 0.010000
2022-07-29 15:20:03 - train: epoch 0046, iter [00100, 05004], lr: 0.010000, loss: 1.5875, stu_CELoss: 0.8606, DKDLoss: 0.7269, 
2022-07-29 15:20:35 - train: epoch 0046, iter [00200, 05004], lr: 0.010000, loss: 1.6388, stu_CELoss: 0.9574, DKDLoss: 0.6814, 
2022-07-29 15:21:09 - train: epoch 0046, iter [00300, 05004], lr: 0.010000, loss: 1.7956, stu_CELoss: 1.0789, DKDLoss: 0.7167, 
2022-07-29 15:21:43 - train: epoch 0046, iter [00400, 05004], lr: 0.010000, loss: 1.7694, stu_CELoss: 1.0324, DKDLoss: 0.7370, 
2022-07-29 15:22:16 - train: epoch 0046, iter [00500, 05004], lr: 0.010000, loss: 1.5967, stu_CELoss: 0.9358, DKDLoss: 0.6609, 
2022-07-29 15:22:50 - train: epoch 0046, iter [00600, 05004], lr: 0.010000, loss: 1.9208, stu_CELoss: 1.2074, DKDLoss: 0.7135, 
2022-07-29 15:23:24 - train: epoch 0046, iter [00700, 05004], lr: 0.010000, loss: 1.5104, stu_CELoss: 0.8831, DKDLoss: 0.6273, 
2022-07-29 15:23:58 - train: epoch 0046, iter [00800, 05004], lr: 0.010000, loss: 2.0157, stu_CELoss: 1.1698, DKDLoss: 0.8458, 
2022-07-29 15:24:31 - train: epoch 0046, iter [00900, 05004], lr: 0.010000, loss: 1.5893, stu_CELoss: 0.9244, DKDLoss: 0.6650, 
2022-07-29 15:25:05 - train: epoch 0046, iter [01000, 05004], lr: 0.010000, loss: 1.6637, stu_CELoss: 0.9221, DKDLoss: 0.7416, 
2022-07-29 15:25:39 - train: epoch 0046, iter [01100, 05004], lr: 0.010000, loss: 1.8043, stu_CELoss: 1.0650, DKDLoss: 0.7393, 
2022-07-29 15:26:12 - train: epoch 0046, iter [01200, 05004], lr: 0.010000, loss: 1.6882, stu_CELoss: 1.0234, DKDLoss: 0.6648, 
2022-07-29 15:26:46 - train: epoch 0046, iter [01300, 05004], lr: 0.010000, loss: 1.7478, stu_CELoss: 0.9669, DKDLoss: 0.7809, 
2022-07-29 15:27:20 - train: epoch 0046, iter [01400, 05004], lr: 0.010000, loss: 1.9159, stu_CELoss: 1.1464, DKDLoss: 0.7695, 
2022-07-29 15:27:53 - train: epoch 0046, iter [01500, 05004], lr: 0.010000, loss: 1.8047, stu_CELoss: 1.0885, DKDLoss: 0.7162, 
2022-07-29 15:28:27 - train: epoch 0046, iter [01600, 05004], lr: 0.010000, loss: 1.8421, stu_CELoss: 1.0523, DKDLoss: 0.7898, 
2022-07-29 15:29:01 - train: epoch 0046, iter [01700, 05004], lr: 0.010000, loss: 1.8662, stu_CELoss: 1.1069, DKDLoss: 0.7593, 
2022-07-29 15:29:35 - train: epoch 0046, iter [01800, 05004], lr: 0.010000, loss: 1.9328, stu_CELoss: 1.1885, DKDLoss: 0.7443, 
2022-07-29 15:30:08 - train: epoch 0046, iter [01900, 05004], lr: 0.010000, loss: 1.7990, stu_CELoss: 0.9579, DKDLoss: 0.8411, 
2022-07-29 15:30:42 - train: epoch 0046, iter [02000, 05004], lr: 0.010000, loss: 1.6813, stu_CELoss: 0.9760, DKDLoss: 0.7052, 
2022-07-29 15:31:16 - train: epoch 0046, iter [02100, 05004], lr: 0.010000, loss: 2.0275, stu_CELoss: 1.2064, DKDLoss: 0.8210, 
2022-07-29 15:31:50 - train: epoch 0046, iter [02200, 05004], lr: 0.010000, loss: 1.5963, stu_CELoss: 0.8905, DKDLoss: 0.7058, 
2022-07-29 15:32:24 - train: epoch 0046, iter [02300, 05004], lr: 0.010000, loss: 2.0170, stu_CELoss: 1.2345, DKDLoss: 0.7825, 
2022-07-29 15:32:58 - train: epoch 0046, iter [02400, 05004], lr: 0.010000, loss: 1.6280, stu_CELoss: 0.8877, DKDLoss: 0.7403, 
2022-07-29 15:33:32 - train: epoch 0046, iter [02500, 05004], lr: 0.010000, loss: 1.8129, stu_CELoss: 1.1078, DKDLoss: 0.7052, 
2022-07-29 15:34:06 - train: epoch 0046, iter [02600, 05004], lr: 0.010000, loss: 2.1778, stu_CELoss: 1.3482, DKDLoss: 0.8297, 
2022-07-29 15:34:41 - train: epoch 0046, iter [02700, 05004], lr: 0.010000, loss: 1.5726, stu_CELoss: 0.8816, DKDLoss: 0.6910, 
2022-07-29 15:35:15 - train: epoch 0046, iter [02800, 05004], lr: 0.010000, loss: 1.5958, stu_CELoss: 0.8198, DKDLoss: 0.7760, 
2022-07-29 15:35:49 - train: epoch 0046, iter [02900, 05004], lr: 0.010000, loss: 1.9377, stu_CELoss: 1.2046, DKDLoss: 0.7330, 
2022-07-29 15:36:23 - train: epoch 0046, iter [03000, 05004], lr: 0.010000, loss: 1.7004, stu_CELoss: 1.0346, DKDLoss: 0.6658, 
2022-07-29 15:36:57 - train: epoch 0046, iter [03100, 05004], lr: 0.010000, loss: 1.7579, stu_CELoss: 1.0270, DKDLoss: 0.7309, 
2022-07-29 15:37:31 - train: epoch 0046, iter [03200, 05004], lr: 0.010000, loss: 1.9361, stu_CELoss: 1.1954, DKDLoss: 0.7407, 
2022-07-29 15:38:05 - train: epoch 0046, iter [03300, 05004], lr: 0.010000, loss: 1.7779, stu_CELoss: 1.0288, DKDLoss: 0.7491, 
2022-07-29 15:38:39 - train: epoch 0046, iter [03400, 05004], lr: 0.010000, loss: 2.0307, stu_CELoss: 1.2660, DKDLoss: 0.7647, 
2022-07-29 15:39:13 - train: epoch 0046, iter [03500, 05004], lr: 0.010000, loss: 1.8776, stu_CELoss: 1.0723, DKDLoss: 0.8052, 
2022-07-29 15:39:47 - train: epoch 0046, iter [03600, 05004], lr: 0.010000, loss: 1.7278, stu_CELoss: 0.9906, DKDLoss: 0.7373, 
2022-07-29 15:40:21 - train: epoch 0046, iter [03700, 05004], lr: 0.010000, loss: 1.7286, stu_CELoss: 1.0342, DKDLoss: 0.6944, 
2022-07-29 15:40:55 - train: epoch 0046, iter [03800, 05004], lr: 0.010000, loss: 1.7077, stu_CELoss: 0.9616, DKDLoss: 0.7462, 
2022-07-29 15:41:29 - train: epoch 0046, iter [03900, 05004], lr: 0.010000, loss: 1.9334, stu_CELoss: 1.1896, DKDLoss: 0.7439, 
2022-07-29 15:42:03 - train: epoch 0046, iter [04000, 05004], lr: 0.010000, loss: 1.6947, stu_CELoss: 0.9836, DKDLoss: 0.7111, 
2022-07-29 15:42:37 - train: epoch 0046, iter [04100, 05004], lr: 0.010000, loss: 2.0155, stu_CELoss: 1.2107, DKDLoss: 0.8047, 
2022-07-29 15:43:11 - train: epoch 0046, iter [04200, 05004], lr: 0.010000, loss: 1.6394, stu_CELoss: 0.9785, DKDLoss: 0.6609, 
2022-07-29 15:43:46 - train: epoch 0046, iter [04300, 05004], lr: 0.010000, loss: 2.0362, stu_CELoss: 1.2421, DKDLoss: 0.7941, 
2022-07-29 15:44:20 - train: epoch 0046, iter [04400, 05004], lr: 0.010000, loss: 1.8367, stu_CELoss: 1.0854, DKDLoss: 0.7513, 
2022-07-29 15:44:54 - train: epoch 0046, iter [04500, 05004], lr: 0.010000, loss: 1.8138, stu_CELoss: 1.0080, DKDLoss: 0.8058, 
2022-07-29 15:45:28 - train: epoch 0046, iter [04600, 05004], lr: 0.010000, loss: 1.8380, stu_CELoss: 1.0439, DKDLoss: 0.7941, 
2022-07-29 15:46:02 - train: epoch 0046, iter [04700, 05004], lr: 0.010000, loss: 1.7569, stu_CELoss: 0.9869, DKDLoss: 0.7699, 
2022-07-29 15:46:37 - train: epoch 0046, iter [04800, 05004], lr: 0.010000, loss: 1.4796, stu_CELoss: 0.8376, DKDLoss: 0.6420, 
2022-07-29 15:47:11 - train: epoch 0046, iter [04900, 05004], lr: 0.010000, loss: 1.9299, stu_CELoss: 1.1364, DKDLoss: 0.7935, 
2022-07-29 15:47:44 - train: epoch 0046, iter [05000, 05004], lr: 0.010000, loss: 1.8534, stu_CELoss: 1.0825, DKDLoss: 0.7709, 
2022-07-29 15:47:46 - train: epoch 046, train_loss: 1.8176
2022-07-29 15:50:18 - eval: epoch: 046, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 73.572%, stu_acc5: 91.626%, stu_test_loss: 1.0540
2022-07-29 15:50:19 - until epoch: 046, tea_best_acc1: 78.068%, stu_best_acc1: 74.276%
2022-07-29 15:50:19 - epoch 047 lr: 0.010000
2022-07-29 15:50:59 - train: epoch 0047, iter [00100, 05004], lr: 0.010000, loss: 1.6777, stu_CELoss: 0.9281, DKDLoss: 0.7496, 
2022-07-29 15:51:33 - train: epoch 0047, iter [00200, 05004], lr: 0.010000, loss: 1.9028, stu_CELoss: 1.1903, DKDLoss: 0.7125, 
2022-07-29 15:52:05 - train: epoch 0047, iter [00300, 05004], lr: 0.010000, loss: 1.7546, stu_CELoss: 1.0193, DKDLoss: 0.7353, 
2022-07-29 15:52:38 - train: epoch 0047, iter [00400, 05004], lr: 0.010000, loss: 1.6883, stu_CELoss: 0.9058, DKDLoss: 0.7825, 
2022-07-29 15:53:11 - train: epoch 0047, iter [00500, 05004], lr: 0.010000, loss: 1.8745, stu_CELoss: 1.1742, DKDLoss: 0.7003, 
2022-07-29 15:53:45 - train: epoch 0047, iter [00600, 05004], lr: 0.010000, loss: 1.7548, stu_CELoss: 0.9716, DKDLoss: 0.7832, 
2022-07-29 15:54:19 - train: epoch 0047, iter [00700, 05004], lr: 0.010000, loss: 1.7377, stu_CELoss: 1.0089, DKDLoss: 0.7288, 
2022-07-29 15:54:52 - train: epoch 0047, iter [00800, 05004], lr: 0.010000, loss: 1.6182, stu_CELoss: 0.9433, DKDLoss: 0.6749, 
2022-07-29 15:55:26 - train: epoch 0047, iter [00900, 05004], lr: 0.010000, loss: 1.7906, stu_CELoss: 1.0048, DKDLoss: 0.7858, 
2022-07-29 15:56:01 - train: epoch 0047, iter [01000, 05004], lr: 0.010000, loss: 1.8379, stu_CELoss: 1.0783, DKDLoss: 0.7596, 
2022-07-29 15:56:35 - train: epoch 0047, iter [01100, 05004], lr: 0.010000, loss: 2.0482, stu_CELoss: 1.1926, DKDLoss: 0.8557, 
2022-07-29 15:57:09 - train: epoch 0047, iter [01200, 05004], lr: 0.010000, loss: 1.6612, stu_CELoss: 0.9480, DKDLoss: 0.7132, 
2022-07-29 15:57:43 - train: epoch 0047, iter [01300, 05004], lr: 0.010000, loss: 1.6627, stu_CELoss: 0.9616, DKDLoss: 0.7011, 
2022-07-29 15:58:17 - train: epoch 0047, iter [01400, 05004], lr: 0.010000, loss: 1.8922, stu_CELoss: 1.1025, DKDLoss: 0.7897, 
2022-07-29 15:58:51 - train: epoch 0047, iter [01500, 05004], lr: 0.010000, loss: 1.7363, stu_CELoss: 1.0025, DKDLoss: 0.7338, 
2022-07-29 15:59:25 - train: epoch 0047, iter [01600, 05004], lr: 0.010000, loss: 1.8600, stu_CELoss: 1.1030, DKDLoss: 0.7569, 
2022-07-29 16:00:00 - train: epoch 0047, iter [01700, 05004], lr: 0.010000, loss: 1.6952, stu_CELoss: 0.9444, DKDLoss: 0.7508, 
2022-07-29 16:00:34 - train: epoch 0047, iter [01800, 05004], lr: 0.010000, loss: 1.7744, stu_CELoss: 1.0541, DKDLoss: 0.7203, 
2022-07-29 16:01:08 - train: epoch 0047, iter [01900, 05004], lr: 0.010000, loss: 1.7400, stu_CELoss: 1.0432, DKDLoss: 0.6969, 
2022-07-29 16:01:43 - train: epoch 0047, iter [02000, 05004], lr: 0.010000, loss: 1.8679, stu_CELoss: 1.0538, DKDLoss: 0.8142, 
2022-07-29 16:02:17 - train: epoch 0047, iter [02100, 05004], lr: 0.010000, loss: 1.8586, stu_CELoss: 1.0938, DKDLoss: 0.7647, 
2022-07-29 16:02:51 - train: epoch 0047, iter [02200, 05004], lr: 0.010000, loss: 1.8965, stu_CELoss: 1.1316, DKDLoss: 0.7650, 
2022-07-29 16:03:25 - train: epoch 0047, iter [02300, 05004], lr: 0.010000, loss: 2.0098, stu_CELoss: 1.2652, DKDLoss: 0.7446, 
2022-07-29 16:03:59 - train: epoch 0047, iter [02400, 05004], lr: 0.010000, loss: 1.7191, stu_CELoss: 0.9535, DKDLoss: 0.7656, 
2022-07-29 16:04:33 - train: epoch 0047, iter [02500, 05004], lr: 0.010000, loss: 1.9665, stu_CELoss: 1.2073, DKDLoss: 0.7592, 
2022-07-29 16:05:07 - train: epoch 0047, iter [02600, 05004], lr: 0.010000, loss: 1.8386, stu_CELoss: 1.0761, DKDLoss: 0.7625, 
2022-07-29 16:05:41 - train: epoch 0047, iter [02700, 05004], lr: 0.010000, loss: 1.7969, stu_CELoss: 1.0787, DKDLoss: 0.7182, 
2022-07-29 16:06:15 - train: epoch 0047, iter [02800, 05004], lr: 0.010000, loss: 1.8711, stu_CELoss: 1.1217, DKDLoss: 0.7494, 
2022-07-29 16:06:50 - train: epoch 0047, iter [02900, 05004], lr: 0.010000, loss: 1.9111, stu_CELoss: 1.1606, DKDLoss: 0.7504, 
2022-07-29 16:07:24 - train: epoch 0047, iter [03000, 05004], lr: 0.010000, loss: 1.9802, stu_CELoss: 1.1714, DKDLoss: 0.8089, 
2022-07-29 16:07:58 - train: epoch 0047, iter [03100, 05004], lr: 0.010000, loss: 1.9558, stu_CELoss: 1.1559, DKDLoss: 0.7999, 
2022-07-29 16:08:32 - train: epoch 0047, iter [03200, 05004], lr: 0.010000, loss: 2.0259, stu_CELoss: 1.2015, DKDLoss: 0.8244, 
2022-07-29 16:09:05 - train: epoch 0047, iter [03300, 05004], lr: 0.010000, loss: 1.7658, stu_CELoss: 1.0751, DKDLoss: 0.6907, 
2022-07-29 16:09:39 - train: epoch 0047, iter [03400, 05004], lr: 0.010000, loss: 1.6869, stu_CELoss: 1.0210, DKDLoss: 0.6659, 
2022-07-29 16:10:13 - train: epoch 0047, iter [03500, 05004], lr: 0.010000, loss: 1.7856, stu_CELoss: 1.1013, DKDLoss: 0.6843, 
2022-07-29 16:10:47 - train: epoch 0047, iter [03600, 05004], lr: 0.010000, loss: 1.7673, stu_CELoss: 1.0104, DKDLoss: 0.7568, 
2022-07-29 16:11:21 - train: epoch 0047, iter [03700, 05004], lr: 0.010000, loss: 2.1019, stu_CELoss: 1.2827, DKDLoss: 0.8193, 
2022-07-29 16:11:54 - train: epoch 0047, iter [03800, 05004], lr: 0.010000, loss: 1.7579, stu_CELoss: 1.0407, DKDLoss: 0.7173, 
2022-07-29 16:12:28 - train: epoch 0047, iter [03900, 05004], lr: 0.010000, loss: 1.9885, stu_CELoss: 1.2384, DKDLoss: 0.7501, 
2022-07-29 16:13:02 - train: epoch 0047, iter [04000, 05004], lr: 0.010000, loss: 1.9573, stu_CELoss: 1.1687, DKDLoss: 0.7886, 
2022-07-29 16:13:36 - train: epoch 0047, iter [04100, 05004], lr: 0.010000, loss: 1.9594, stu_CELoss: 1.2142, DKDLoss: 0.7452, 
2022-07-29 16:14:10 - train: epoch 0047, iter [04200, 05004], lr: 0.010000, loss: 2.0586, stu_CELoss: 1.1472, DKDLoss: 0.9114, 
2022-07-29 16:14:44 - train: epoch 0047, iter [04300, 05004], lr: 0.010000, loss: 1.8767, stu_CELoss: 1.1090, DKDLoss: 0.7677, 
2022-07-29 16:15:18 - train: epoch 0047, iter [04400, 05004], lr: 0.010000, loss: 1.8029, stu_CELoss: 0.9913, DKDLoss: 0.8116, 
2022-07-29 16:15:52 - train: epoch 0047, iter [04500, 05004], lr: 0.010000, loss: 1.8914, stu_CELoss: 1.1298, DKDLoss: 0.7616, 
2022-07-29 16:16:25 - train: epoch 0047, iter [04600, 05004], lr: 0.010000, loss: 1.6761, stu_CELoss: 1.0365, DKDLoss: 0.6396, 
2022-07-29 16:16:59 - train: epoch 0047, iter [04700, 05004], lr: 0.010000, loss: 1.9199, stu_CELoss: 1.1532, DKDLoss: 0.7667, 
2022-07-29 16:17:33 - train: epoch 0047, iter [04800, 05004], lr: 0.010000, loss: 1.6492, stu_CELoss: 0.9033, DKDLoss: 0.7458, 
2022-07-29 16:18:07 - train: epoch 0047, iter [04900, 05004], lr: 0.010000, loss: 1.7354, stu_CELoss: 0.9942, DKDLoss: 0.7412, 
2022-07-29 16:18:40 - train: epoch 0047, iter [05000, 05004], lr: 0.010000, loss: 1.7236, stu_CELoss: 1.0390, DKDLoss: 0.6846, 
2022-07-29 16:18:42 - train: epoch 047, train_loss: 1.8163
2022-07-29 16:21:14 - eval: epoch: 047, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 72.632%, stu_acc5: 91.222%, stu_test_loss: 1.0854
2022-07-29 16:21:14 - until epoch: 047, tea_best_acc1: 78.068%, stu_best_acc1: 74.276%
2022-07-29 16:21:14 - epoch 048 lr: 0.010000
2022-07-29 16:21:54 - train: epoch 0048, iter [00100, 05004], lr: 0.010000, loss: 1.7125, stu_CELoss: 0.9949, DKDLoss: 0.7176, 
2022-07-29 16:22:27 - train: epoch 0048, iter [00200, 05004], lr: 0.010000, loss: 1.9758, stu_CELoss: 1.2407, DKDLoss: 0.7351, 
2022-07-29 16:23:00 - train: epoch 0048, iter [00300, 05004], lr: 0.010000, loss: 1.8520, stu_CELoss: 1.1091, DKDLoss: 0.7429, 
2022-07-29 16:23:33 - train: epoch 0048, iter [00400, 05004], lr: 0.010000, loss: 1.8678, stu_CELoss: 1.1097, DKDLoss: 0.7581, 
2022-07-29 16:24:07 - train: epoch 0048, iter [00500, 05004], lr: 0.010000, loss: 1.7268, stu_CELoss: 1.0205, DKDLoss: 0.7063, 
2022-07-29 16:24:41 - train: epoch 0048, iter [00600, 05004], lr: 0.010000, loss: 1.7664, stu_CELoss: 1.0525, DKDLoss: 0.7138, 
2022-07-29 16:25:14 - train: epoch 0048, iter [00700, 05004], lr: 0.010000, loss: 1.8772, stu_CELoss: 1.1105, DKDLoss: 0.7667, 
2022-07-29 16:25:48 - train: epoch 0048, iter [00800, 05004], lr: 0.010000, loss: 1.7079, stu_CELoss: 1.0311, DKDLoss: 0.6767, 
2022-07-29 16:26:22 - train: epoch 0048, iter [00900, 05004], lr: 0.010000, loss: 1.8551, stu_CELoss: 1.1032, DKDLoss: 0.7520, 
2022-07-29 16:26:55 - train: epoch 0048, iter [01000, 05004], lr: 0.010000, loss: 2.0058, stu_CELoss: 1.3055, DKDLoss: 0.7003, 
2022-07-29 16:27:29 - train: epoch 0048, iter [01100, 05004], lr: 0.010000, loss: 1.9931, stu_CELoss: 1.2772, DKDLoss: 0.7158, 
2022-07-29 16:28:02 - train: epoch 0048, iter [01200, 05004], lr: 0.010000, loss: 1.9098, stu_CELoss: 1.0641, DKDLoss: 0.8457, 
2022-07-29 16:28:36 - train: epoch 0048, iter [01300, 05004], lr: 0.010000, loss: 1.6616, stu_CELoss: 1.0510, DKDLoss: 0.6106, 
2022-07-29 16:29:10 - train: epoch 0048, iter [01400, 05004], lr: 0.010000, loss: 1.6676, stu_CELoss: 0.8790, DKDLoss: 0.7886, 
2022-07-29 16:29:44 - train: epoch 0048, iter [01500, 05004], lr: 0.010000, loss: 1.8810, stu_CELoss: 1.0668, DKDLoss: 0.8142, 
2022-07-29 16:30:17 - train: epoch 0048, iter [01600, 05004], lr: 0.010000, loss: 1.6477, stu_CELoss: 1.0249, DKDLoss: 0.6228, 
2022-07-29 16:30:51 - train: epoch 0048, iter [01700, 05004], lr: 0.010000, loss: 1.6432, stu_CELoss: 0.9567, DKDLoss: 0.6865, 
2022-07-29 16:31:25 - train: epoch 0048, iter [01800, 05004], lr: 0.010000, loss: 1.8170, stu_CELoss: 1.0530, DKDLoss: 0.7640, 
2022-07-29 16:31:59 - train: epoch 0048, iter [01900, 05004], lr: 0.010000, loss: 1.9316, stu_CELoss: 1.0974, DKDLoss: 0.8343, 
2022-07-29 16:32:33 - train: epoch 0048, iter [02000, 05004], lr: 0.010000, loss: 2.1121, stu_CELoss: 1.2087, DKDLoss: 0.9034, 
2022-07-29 16:33:07 - train: epoch 0048, iter [02100, 05004], lr: 0.010000, loss: 1.8672, stu_CELoss: 1.1772, DKDLoss: 0.6900, 
2022-07-29 16:33:40 - train: epoch 0048, iter [02200, 05004], lr: 0.010000, loss: 2.1409, stu_CELoss: 1.2599, DKDLoss: 0.8810, 
2022-07-29 16:34:14 - train: epoch 0048, iter [02300, 05004], lr: 0.010000, loss: 1.8759, stu_CELoss: 1.1453, DKDLoss: 0.7306, 
2022-07-29 16:34:48 - train: epoch 0048, iter [02400, 05004], lr: 0.010000, loss: 1.9503, stu_CELoss: 1.1679, DKDLoss: 0.7824, 
2022-07-29 16:35:21 - train: epoch 0048, iter [02500, 05004], lr: 0.010000, loss: 1.8001, stu_CELoss: 1.0397, DKDLoss: 0.7604, 
2022-07-29 16:35:55 - train: epoch 0048, iter [02600, 05004], lr: 0.010000, loss: 1.8137, stu_CELoss: 1.0955, DKDLoss: 0.7182, 
2022-07-29 16:36:29 - train: epoch 0048, iter [02700, 05004], lr: 0.010000, loss: 1.8990, stu_CELoss: 1.1011, DKDLoss: 0.7979, 
2022-07-29 16:37:03 - train: epoch 0048, iter [02800, 05004], lr: 0.010000, loss: 1.6350, stu_CELoss: 0.8733, DKDLoss: 0.7617, 
2022-07-29 16:37:37 - train: epoch 0048, iter [02900, 05004], lr: 0.010000, loss: 1.6835, stu_CELoss: 0.9185, DKDLoss: 0.7650, 
2022-07-29 16:38:12 - train: epoch 0048, iter [03000, 05004], lr: 0.010000, loss: 1.6321, stu_CELoss: 0.8918, DKDLoss: 0.7403, 
2022-07-29 16:38:46 - train: epoch 0048, iter [03100, 05004], lr: 0.010000, loss: 1.7314, stu_CELoss: 0.9076, DKDLoss: 0.8238, 
2022-07-29 16:39:19 - train: epoch 0048, iter [03200, 05004], lr: 0.010000, loss: 1.7628, stu_CELoss: 1.0358, DKDLoss: 0.7270, 
2022-07-29 16:39:53 - train: epoch 0048, iter [03300, 05004], lr: 0.010000, loss: 2.0092, stu_CELoss: 1.2204, DKDLoss: 0.7888, 
2022-07-29 16:40:27 - train: epoch 0048, iter [03400, 05004], lr: 0.010000, loss: 1.9214, stu_CELoss: 1.1644, DKDLoss: 0.7569, 
2022-07-29 16:41:01 - train: epoch 0048, iter [03500, 05004], lr: 0.010000, loss: 1.9135, stu_CELoss: 1.1634, DKDLoss: 0.7501, 
2022-07-29 16:41:36 - train: epoch 0048, iter [03600, 05004], lr: 0.010000, loss: 1.6859, stu_CELoss: 1.0128, DKDLoss: 0.6731, 
2022-07-29 16:42:10 - train: epoch 0048, iter [03700, 05004], lr: 0.010000, loss: 1.9275, stu_CELoss: 1.1219, DKDLoss: 0.8056, 
2022-07-29 16:42:44 - train: epoch 0048, iter [03800, 05004], lr: 0.010000, loss: 1.7491, stu_CELoss: 0.9956, DKDLoss: 0.7535, 
2022-07-29 16:43:18 - train: epoch 0048, iter [03900, 05004], lr: 0.010000, loss: 1.8089, stu_CELoss: 1.1592, DKDLoss: 0.6497, 
2022-07-29 16:43:53 - train: epoch 0048, iter [04000, 05004], lr: 0.010000, loss: 1.6954, stu_CELoss: 0.9438, DKDLoss: 0.7516, 
2022-07-29 16:44:27 - train: epoch 0048, iter [04100, 05004], lr: 0.010000, loss: 2.0901, stu_CELoss: 1.3038, DKDLoss: 0.7862, 
2022-07-29 16:45:01 - train: epoch 0048, iter [04200, 05004], lr: 0.010000, loss: 1.7256, stu_CELoss: 0.9320, DKDLoss: 0.7936, 
2022-07-29 16:45:35 - train: epoch 0048, iter [04300, 05004], lr: 0.010000, loss: 1.7509, stu_CELoss: 0.9742, DKDLoss: 0.7766, 
2022-07-29 16:46:09 - train: epoch 0048, iter [04400, 05004], lr: 0.010000, loss: 1.8901, stu_CELoss: 1.1089, DKDLoss: 0.7811, 
2022-07-29 16:46:43 - train: epoch 0048, iter [04500, 05004], lr: 0.010000, loss: 1.7058, stu_CELoss: 0.9893, DKDLoss: 0.7166, 
2022-07-29 16:47:17 - train: epoch 0048, iter [04600, 05004], lr: 0.010000, loss: 1.7752, stu_CELoss: 1.0333, DKDLoss: 0.7419, 
2022-07-29 16:47:51 - train: epoch 0048, iter [04700, 05004], lr: 0.010000, loss: 1.7534, stu_CELoss: 0.9326, DKDLoss: 0.8208, 
2022-07-29 16:48:25 - train: epoch 0048, iter [04800, 05004], lr: 0.010000, loss: 2.2683, stu_CELoss: 1.4203, DKDLoss: 0.8479, 
2022-07-29 16:48:59 - train: epoch 0048, iter [04900, 05004], lr: 0.010000, loss: 1.9032, stu_CELoss: 1.1513, DKDLoss: 0.7519, 
2022-07-29 16:49:33 - train: epoch 0048, iter [05000, 05004], lr: 0.010000, loss: 1.9608, stu_CELoss: 1.1029, DKDLoss: 0.8579, 
2022-07-29 16:49:34 - train: epoch 048, train_loss: 1.8124
2022-07-29 16:52:06 - eval: epoch: 048, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 73.308%, stu_acc5: 91.540%, stu_test_loss: 1.0586
2022-07-29 16:52:07 - until epoch: 048, tea_best_acc1: 78.068%, stu_best_acc1: 74.276%
2022-07-29 16:52:07 - epoch 049 lr: 0.010000
2022-07-29 16:52:47 - train: epoch 0049, iter [00100, 05004], lr: 0.010000, loss: 1.8625, stu_CELoss: 1.1297, DKDLoss: 0.7327, 
2022-07-29 16:53:20 - train: epoch 0049, iter [00200, 05004], lr: 0.010000, loss: 1.4325, stu_CELoss: 0.7626, DKDLoss: 0.6699, 
2022-07-29 16:53:54 - train: epoch 0049, iter [00300, 05004], lr: 0.010000, loss: 1.9219, stu_CELoss: 1.0968, DKDLoss: 0.8251, 
2022-07-29 16:54:27 - train: epoch 0049, iter [00400, 05004], lr: 0.010000, loss: 1.6715, stu_CELoss: 0.9012, DKDLoss: 0.7702, 
2022-07-29 16:55:01 - train: epoch 0049, iter [00500, 05004], lr: 0.010000, loss: 1.9515, stu_CELoss: 1.1769, DKDLoss: 0.7746, 
2022-07-29 16:55:34 - train: epoch 0049, iter [00600, 05004], lr: 0.010000, loss: 1.5936, stu_CELoss: 0.8958, DKDLoss: 0.6977, 
2022-07-29 16:56:08 - train: epoch 0049, iter [00700, 05004], lr: 0.010000, loss: 1.8252, stu_CELoss: 1.0350, DKDLoss: 0.7903, 
2022-07-29 16:56:41 - train: epoch 0049, iter [00800, 05004], lr: 0.010000, loss: 2.0256, stu_CELoss: 1.2630, DKDLoss: 0.7626, 
2022-07-29 16:57:16 - train: epoch 0049, iter [00900, 05004], lr: 0.010000, loss: 1.6601, stu_CELoss: 0.9340, DKDLoss: 0.7261, 
2022-07-29 16:57:49 - train: epoch 0049, iter [01000, 05004], lr: 0.010000, loss: 1.7385, stu_CELoss: 1.0250, DKDLoss: 0.7135, 
2022-07-29 16:58:23 - train: epoch 0049, iter [01100, 05004], lr: 0.010000, loss: 1.8697, stu_CELoss: 1.1024, DKDLoss: 0.7673, 
2022-07-29 16:58:57 - train: epoch 0049, iter [01200, 05004], lr: 0.010000, loss: 1.6669, stu_CELoss: 0.8986, DKDLoss: 0.7684, 
2022-07-29 16:59:31 - train: epoch 0049, iter [01300, 05004], lr: 0.010000, loss: 1.8594, stu_CELoss: 1.1190, DKDLoss: 0.7405, 
2022-07-29 17:00:05 - train: epoch 0049, iter [01400, 05004], lr: 0.010000, loss: 1.7833, stu_CELoss: 1.0409, DKDLoss: 0.7423, 
2022-07-29 17:00:39 - train: epoch 0049, iter [01500, 05004], lr: 0.010000, loss: 1.7523, stu_CELoss: 1.0080, DKDLoss: 0.7444, 
2022-07-29 17:01:12 - train: epoch 0049, iter [01600, 05004], lr: 0.010000, loss: 1.6960, stu_CELoss: 0.9247, DKDLoss: 0.7713, 
2022-07-29 17:01:46 - train: epoch 0049, iter [01700, 05004], lr: 0.010000, loss: 1.7893, stu_CELoss: 1.0486, DKDLoss: 0.7407, 
2022-07-29 17:02:20 - train: epoch 0049, iter [01800, 05004], lr: 0.010000, loss: 1.8696, stu_CELoss: 1.0860, DKDLoss: 0.7836, 
2022-07-29 17:02:54 - train: epoch 0049, iter [01900, 05004], lr: 0.010000, loss: 1.9288, stu_CELoss: 1.1315, DKDLoss: 0.7972, 
2022-07-29 17:03:28 - train: epoch 0049, iter [02000, 05004], lr: 0.010000, loss: 1.7821, stu_CELoss: 1.0439, DKDLoss: 0.7382, 
2022-07-29 17:04:02 - train: epoch 0049, iter [02100, 05004], lr: 0.010000, loss: 1.6970, stu_CELoss: 0.9734, DKDLoss: 0.7236, 
2022-07-29 17:04:36 - train: epoch 0049, iter [02200, 05004], lr: 0.010000, loss: 1.7846, stu_CELoss: 1.1143, DKDLoss: 0.6703, 
2022-07-29 17:05:09 - train: epoch 0049, iter [02300, 05004], lr: 0.010000, loss: 1.7379, stu_CELoss: 1.0348, DKDLoss: 0.7031, 
2022-07-29 17:05:43 - train: epoch 0049, iter [02400, 05004], lr: 0.010000, loss: 1.8965, stu_CELoss: 1.1185, DKDLoss: 0.7780, 
2022-07-29 17:06:17 - train: epoch 0049, iter [02500, 05004], lr: 0.010000, loss: 1.9008, stu_CELoss: 1.0876, DKDLoss: 0.8132, 
2022-07-29 17:06:51 - train: epoch 0049, iter [02600, 05004], lr: 0.010000, loss: 1.9822, stu_CELoss: 1.1964, DKDLoss: 0.7858, 
2022-07-29 17:07:24 - train: epoch 0049, iter [02700, 05004], lr: 0.010000, loss: 1.7908, stu_CELoss: 1.0621, DKDLoss: 0.7286, 
2022-07-29 17:07:58 - train: epoch 0049, iter [02800, 05004], lr: 0.010000, loss: 1.7781, stu_CELoss: 1.0962, DKDLoss: 0.6820, 
2022-07-29 17:08:32 - train: epoch 0049, iter [02900, 05004], lr: 0.010000, loss: 1.8085, stu_CELoss: 1.0231, DKDLoss: 0.7853, 
2022-07-29 17:09:06 - train: epoch 0049, iter [03000, 05004], lr: 0.010000, loss: 1.8488, stu_CELoss: 1.1526, DKDLoss: 0.6962, 
2022-07-29 17:09:40 - train: epoch 0049, iter [03100, 05004], lr: 0.010000, loss: 1.8828, stu_CELoss: 1.1521, DKDLoss: 0.7306, 
2022-07-29 17:10:14 - train: epoch 0049, iter [03200, 05004], lr: 0.010000, loss: 1.8995, stu_CELoss: 1.1382, DKDLoss: 0.7612, 
2022-07-29 17:10:48 - train: epoch 0049, iter [03300, 05004], lr: 0.010000, loss: 1.6900, stu_CELoss: 0.9589, DKDLoss: 0.7311, 
2022-07-29 17:11:22 - train: epoch 0049, iter [03400, 05004], lr: 0.010000, loss: 1.8934, stu_CELoss: 1.0809, DKDLoss: 0.8125, 
2022-07-29 17:11:55 - train: epoch 0049, iter [03500, 05004], lr: 0.010000, loss: 1.7810, stu_CELoss: 1.0436, DKDLoss: 0.7374, 
2022-07-29 17:12:29 - train: epoch 0049, iter [03600, 05004], lr: 0.010000, loss: 1.9015, stu_CELoss: 1.1503, DKDLoss: 0.7512, 
2022-07-29 17:13:03 - train: epoch 0049, iter [03700, 05004], lr: 0.010000, loss: 1.7945, stu_CELoss: 1.0317, DKDLoss: 0.7628, 
2022-07-29 17:13:38 - train: epoch 0049, iter [03800, 05004], lr: 0.010000, loss: 1.9921, stu_CELoss: 1.1216, DKDLoss: 0.8704, 
2022-07-29 17:14:12 - train: epoch 0049, iter [03900, 05004], lr: 0.010000, loss: 1.9660, stu_CELoss: 1.1792, DKDLoss: 0.7868, 
2022-07-29 17:14:46 - train: epoch 0049, iter [04000, 05004], lr: 0.010000, loss: 1.6762, stu_CELoss: 0.9681, DKDLoss: 0.7082, 
2022-07-29 17:15:20 - train: epoch 0049, iter [04100, 05004], lr: 0.010000, loss: 1.7646, stu_CELoss: 1.0585, DKDLoss: 0.7061, 
2022-07-29 17:15:54 - train: epoch 0049, iter [04200, 05004], lr: 0.010000, loss: 1.7581, stu_CELoss: 1.1086, DKDLoss: 0.6495, 
2022-07-29 17:16:29 - train: epoch 0049, iter [04300, 05004], lr: 0.010000, loss: 1.8641, stu_CELoss: 1.1124, DKDLoss: 0.7517, 
2022-07-29 17:17:03 - train: epoch 0049, iter [04400, 05004], lr: 0.010000, loss: 1.8995, stu_CELoss: 1.0900, DKDLoss: 0.8095, 
2022-07-29 17:17:37 - train: epoch 0049, iter [04500, 05004], lr: 0.010000, loss: 1.7509, stu_CELoss: 1.0340, DKDLoss: 0.7169, 
2022-07-29 17:18:11 - train: epoch 0049, iter [04600, 05004], lr: 0.010000, loss: 1.8285, stu_CELoss: 1.0574, DKDLoss: 0.7711, 
2022-07-29 17:18:45 - train: epoch 0049, iter [04700, 05004], lr: 0.010000, loss: 2.2191, stu_CELoss: 1.3845, DKDLoss: 0.8346, 
2022-07-29 17:19:19 - train: epoch 0049, iter [04800, 05004], lr: 0.010000, loss: 1.8330, stu_CELoss: 1.0805, DKDLoss: 0.7525, 
2022-07-29 17:19:53 - train: epoch 0049, iter [04900, 05004], lr: 0.010000, loss: 1.8628, stu_CELoss: 1.0603, DKDLoss: 0.8025, 
2022-07-29 17:20:27 - train: epoch 0049, iter [05000, 05004], lr: 0.010000, loss: 1.9038, stu_CELoss: 1.1140, DKDLoss: 0.7898, 
2022-07-29 17:20:29 - train: epoch 049, train_loss: 1.8101
2022-07-29 17:23:01 - eval: epoch: 049, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 73.752%, stu_acc5: 91.652%, stu_test_loss: 1.0475
2022-07-29 17:23:02 - until epoch: 049, tea_best_acc1: 78.068%, stu_best_acc1: 74.276%
2022-07-29 17:23:02 - epoch 050 lr: 0.010000
2022-07-29 17:23:42 - train: epoch 0050, iter [00100, 05004], lr: 0.010000, loss: 1.9151, stu_CELoss: 1.1537, DKDLoss: 0.7614, 
2022-07-29 17:24:15 - train: epoch 0050, iter [00200, 05004], lr: 0.010000, loss: 1.8161, stu_CELoss: 1.0154, DKDLoss: 0.8007, 
2022-07-29 17:24:48 - train: epoch 0050, iter [00300, 05004], lr: 0.010000, loss: 1.7583, stu_CELoss: 1.0057, DKDLoss: 0.7526, 
2022-07-29 17:25:21 - train: epoch 0050, iter [00400, 05004], lr: 0.010000, loss: 1.8116, stu_CELoss: 1.1372, DKDLoss: 0.6744, 
2022-07-29 17:25:54 - train: epoch 0050, iter [00500, 05004], lr: 0.010000, loss: 1.8338, stu_CELoss: 1.1305, DKDLoss: 0.7033, 
2022-07-29 17:26:28 - train: epoch 0050, iter [00600, 05004], lr: 0.010000, loss: 1.9868, stu_CELoss: 1.1981, DKDLoss: 0.7887, 
2022-07-29 17:27:02 - train: epoch 0050, iter [00700, 05004], lr: 0.010000, loss: 1.5940, stu_CELoss: 0.9240, DKDLoss: 0.6699, 
2022-07-29 17:27:35 - train: epoch 0050, iter [00800, 05004], lr: 0.010000, loss: 1.4664, stu_CELoss: 0.7578, DKDLoss: 0.7086, 
2022-07-29 17:28:09 - train: epoch 0050, iter [00900, 05004], lr: 0.010000, loss: 1.8577, stu_CELoss: 1.1207, DKDLoss: 0.7370, 
2022-07-29 17:28:43 - train: epoch 0050, iter [01000, 05004], lr: 0.010000, loss: 1.8725, stu_CELoss: 1.0784, DKDLoss: 0.7941, 
2022-07-29 17:29:16 - train: epoch 0050, iter [01100, 05004], lr: 0.010000, loss: 1.9047, stu_CELoss: 1.1998, DKDLoss: 0.7049, 
2022-07-29 17:29:51 - train: epoch 0050, iter [01200, 05004], lr: 0.010000, loss: 1.6640, stu_CELoss: 0.9527, DKDLoss: 0.7113, 
2022-07-29 17:30:24 - train: epoch 0050, iter [01300, 05004], lr: 0.010000, loss: 1.7785, stu_CELoss: 1.1481, DKDLoss: 0.6303, 
2022-07-29 17:30:59 - train: epoch 0050, iter [01400, 05004], lr: 0.010000, loss: 1.6213, stu_CELoss: 0.9472, DKDLoss: 0.6741, 
2022-07-29 17:31:33 - train: epoch 0050, iter [01500, 05004], lr: 0.010000, loss: 1.6028, stu_CELoss: 0.9118, DKDLoss: 0.6910, 
2022-07-29 17:32:07 - train: epoch 0050, iter [01600, 05004], lr: 0.010000, loss: 1.8063, stu_CELoss: 1.0882, DKDLoss: 0.7181, 
2022-07-29 17:32:41 - train: epoch 0050, iter [01700, 05004], lr: 0.010000, loss: 1.7779, stu_CELoss: 0.9677, DKDLoss: 0.8102, 
2022-07-29 17:33:15 - train: epoch 0050, iter [01800, 05004], lr: 0.010000, loss: 2.0361, stu_CELoss: 1.2446, DKDLoss: 0.7916, 
2022-07-29 17:33:49 - train: epoch 0050, iter [01900, 05004], lr: 0.010000, loss: 1.5634, stu_CELoss: 0.8428, DKDLoss: 0.7206, 
2022-07-29 17:34:22 - train: epoch 0050, iter [02000, 05004], lr: 0.010000, loss: 1.7252, stu_CELoss: 0.9811, DKDLoss: 0.7442, 
2022-07-29 17:34:56 - train: epoch 0050, iter [02100, 05004], lr: 0.010000, loss: 1.7375, stu_CELoss: 1.0052, DKDLoss: 0.7323, 
2022-07-29 17:35:31 - train: epoch 0050, iter [02200, 05004], lr: 0.010000, loss: 1.8578, stu_CELoss: 1.0627, DKDLoss: 0.7951, 
2022-07-29 17:36:05 - train: epoch 0050, iter [02300, 05004], lr: 0.010000, loss: 1.5870, stu_CELoss: 0.8513, DKDLoss: 0.7358, 
2022-07-29 17:36:39 - train: epoch 0050, iter [02400, 05004], lr: 0.010000, loss: 1.8720, stu_CELoss: 1.0630, DKDLoss: 0.8090, 
2022-07-29 17:37:13 - train: epoch 0050, iter [02500, 05004], lr: 0.010000, loss: 1.9328, stu_CELoss: 1.1624, DKDLoss: 0.7705, 
2022-07-29 17:37:47 - train: epoch 0050, iter [02600, 05004], lr: 0.010000, loss: 1.9245, stu_CELoss: 1.1587, DKDLoss: 0.7658, 
2022-07-29 17:38:21 - train: epoch 0050, iter [02700, 05004], lr: 0.010000, loss: 1.8195, stu_CELoss: 1.0703, DKDLoss: 0.7492, 
2022-07-29 17:38:55 - train: epoch 0050, iter [02800, 05004], lr: 0.010000, loss: 2.2066, stu_CELoss: 1.3263, DKDLoss: 0.8803, 
2022-07-29 17:39:29 - train: epoch 0050, iter [02900, 05004], lr: 0.010000, loss: 1.8648, stu_CELoss: 1.1085, DKDLoss: 0.7563, 
2022-07-29 17:40:03 - train: epoch 0050, iter [03000, 05004], lr: 0.010000, loss: 1.8424, stu_CELoss: 1.0778, DKDLoss: 0.7646, 
2022-07-29 17:40:37 - train: epoch 0050, iter [03100, 05004], lr: 0.010000, loss: 2.0938, stu_CELoss: 1.2462, DKDLoss: 0.8476, 
2022-07-29 17:41:12 - train: epoch 0050, iter [03200, 05004], lr: 0.010000, loss: 1.8494, stu_CELoss: 1.1204, DKDLoss: 0.7290, 
2022-07-29 17:41:46 - train: epoch 0050, iter [03300, 05004], lr: 0.010000, loss: 1.7310, stu_CELoss: 0.9442, DKDLoss: 0.7868, 
2022-07-29 17:42:20 - train: epoch 0050, iter [03400, 05004], lr: 0.010000, loss: 1.7831, stu_CELoss: 1.0148, DKDLoss: 0.7682, 
2022-07-29 17:42:54 - train: epoch 0050, iter [03500, 05004], lr: 0.010000, loss: 1.8506, stu_CELoss: 1.1041, DKDLoss: 0.7465, 
2022-07-29 17:43:28 - train: epoch 0050, iter [03600, 05004], lr: 0.010000, loss: 1.9442, stu_CELoss: 1.1798, DKDLoss: 0.7644, 
2022-07-29 17:44:02 - train: epoch 0050, iter [03700, 05004], lr: 0.010000, loss: 2.1008, stu_CELoss: 1.2901, DKDLoss: 0.8106, 
2022-07-29 17:44:36 - train: epoch 0050, iter [03800, 05004], lr: 0.010000, loss: 1.6149, stu_CELoss: 0.9188, DKDLoss: 0.6961, 
2022-07-29 17:45:10 - train: epoch 0050, iter [03900, 05004], lr: 0.010000, loss: 1.6102, stu_CELoss: 0.9014, DKDLoss: 0.7088, 
2022-07-29 17:45:44 - train: epoch 0050, iter [04000, 05004], lr: 0.010000, loss: 2.0879, stu_CELoss: 1.3123, DKDLoss: 0.7756, 
2022-07-29 17:46:18 - train: epoch 0050, iter [04100, 05004], lr: 0.010000, loss: 1.9153, stu_CELoss: 1.1128, DKDLoss: 0.8025, 
2022-07-29 17:46:52 - train: epoch 0050, iter [04200, 05004], lr: 0.010000, loss: 1.7599, stu_CELoss: 0.9746, DKDLoss: 0.7853, 
2022-07-29 17:47:26 - train: epoch 0050, iter [04300, 05004], lr: 0.010000, loss: 1.9022, stu_CELoss: 1.1188, DKDLoss: 0.7835, 
2022-07-29 17:48:00 - train: epoch 0050, iter [04400, 05004], lr: 0.010000, loss: 1.9219, stu_CELoss: 1.1367, DKDLoss: 0.7852, 
2022-07-29 17:48:33 - train: epoch 0050, iter [04500, 05004], lr: 0.010000, loss: 1.8159, stu_CELoss: 1.0233, DKDLoss: 0.7926, 
2022-07-29 17:49:08 - train: epoch 0050, iter [04600, 05004], lr: 0.010000, loss: 2.0567, stu_CELoss: 1.1923, DKDLoss: 0.8644, 
2022-07-29 17:49:42 - train: epoch 0050, iter [04700, 05004], lr: 0.010000, loss: 2.0660, stu_CELoss: 1.2354, DKDLoss: 0.8306, 
2022-07-29 17:50:16 - train: epoch 0050, iter [04800, 05004], lr: 0.010000, loss: 1.9507, stu_CELoss: 1.2000, DKDLoss: 0.7507, 
2022-07-29 17:50:50 - train: epoch 0050, iter [04900, 05004], lr: 0.010000, loss: 1.6873, stu_CELoss: 0.9791, DKDLoss: 0.7082, 
2022-07-29 17:51:23 - train: epoch 0050, iter [05000, 05004], lr: 0.010000, loss: 1.6278, stu_CELoss: 0.8782, DKDLoss: 0.7496, 
2022-07-29 17:51:25 - train: epoch 050, train_loss: 1.8124
2022-07-29 17:53:56 - eval: epoch: 050, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 73.348%, stu_acc5: 91.446%, stu_test_loss: 1.0647
2022-07-29 17:53:57 - until epoch: 050, tea_best_acc1: 78.068%, stu_best_acc1: 74.276%
2022-07-29 17:53:57 - epoch 051 lr: 0.010000
2022-07-29 17:54:37 - train: epoch 0051, iter [00100, 05004], lr: 0.010000, loss: 2.0034, stu_CELoss: 1.1917, DKDLoss: 0.8118, 
2022-07-29 17:55:10 - train: epoch 0051, iter [00200, 05004], lr: 0.010000, loss: 2.0829, stu_CELoss: 1.2321, DKDLoss: 0.8508, 
2022-07-29 17:55:44 - train: epoch 0051, iter [00300, 05004], lr: 0.010000, loss: 1.6237, stu_CELoss: 0.9704, DKDLoss: 0.6533, 
2022-07-29 17:56:17 - train: epoch 0051, iter [00400, 05004], lr: 0.010000, loss: 1.6429, stu_CELoss: 0.8933, DKDLoss: 0.7496, 
2022-07-29 17:56:51 - train: epoch 0051, iter [00500, 05004], lr: 0.010000, loss: 1.6125, stu_CELoss: 0.9138, DKDLoss: 0.6987, 
2022-07-29 17:57:24 - train: epoch 0051, iter [00600, 05004], lr: 0.010000, loss: 1.6674, stu_CELoss: 0.9749, DKDLoss: 0.6925, 
2022-07-29 17:57:59 - train: epoch 0051, iter [00700, 05004], lr: 0.010000, loss: 1.8852, stu_CELoss: 1.1573, DKDLoss: 0.7279, 
2022-07-29 17:58:32 - train: epoch 0051, iter [00800, 05004], lr: 0.010000, loss: 1.8718, stu_CELoss: 1.1122, DKDLoss: 0.7596, 
2022-07-29 17:59:06 - train: epoch 0051, iter [00900, 05004], lr: 0.010000, loss: 1.7138, stu_CELoss: 1.0562, DKDLoss: 0.6576, 
2022-07-29 17:59:40 - train: epoch 0051, iter [01000, 05004], lr: 0.010000, loss: 2.1388, stu_CELoss: 1.2374, DKDLoss: 0.9014, 
2022-07-29 18:00:13 - train: epoch 0051, iter [01100, 05004], lr: 0.010000, loss: 1.9800, stu_CELoss: 1.2288, DKDLoss: 0.7512, 
2022-07-29 18:00:47 - train: epoch 0051, iter [01200, 05004], lr: 0.010000, loss: 1.6333, stu_CELoss: 0.8997, DKDLoss: 0.7336, 
2022-07-29 18:01:21 - train: epoch 0051, iter [01300, 05004], lr: 0.010000, loss: 1.7152, stu_CELoss: 0.9965, DKDLoss: 0.7187, 
2022-07-29 18:01:55 - train: epoch 0051, iter [01400, 05004], lr: 0.010000, loss: 1.7604, stu_CELoss: 0.9947, DKDLoss: 0.7657, 
2022-07-29 18:02:28 - train: epoch 0051, iter [01500, 05004], lr: 0.010000, loss: 1.7265, stu_CELoss: 1.0251, DKDLoss: 0.7014, 
2022-07-29 18:03:02 - train: epoch 0051, iter [01600, 05004], lr: 0.010000, loss: 1.4082, stu_CELoss: 0.7607, DKDLoss: 0.6476, 
2022-07-29 18:03:36 - train: epoch 0051, iter [01700, 05004], lr: 0.010000, loss: 1.7494, stu_CELoss: 1.0633, DKDLoss: 0.6861, 
2022-07-29 18:04:10 - train: epoch 0051, iter [01800, 05004], lr: 0.010000, loss: 1.7629, stu_CELoss: 1.0344, DKDLoss: 0.7285, 
2022-07-29 18:04:44 - train: epoch 0051, iter [01900, 05004], lr: 0.010000, loss: 1.7973, stu_CELoss: 0.9976, DKDLoss: 0.7997, 
2022-07-29 18:05:17 - train: epoch 0051, iter [02000, 05004], lr: 0.010000, loss: 1.5539, stu_CELoss: 0.8910, DKDLoss: 0.6629, 
2022-07-29 18:05:52 - train: epoch 0051, iter [02100, 05004], lr: 0.010000, loss: 1.6728, stu_CELoss: 0.9554, DKDLoss: 0.7174, 
2022-07-29 18:06:26 - train: epoch 0051, iter [02200, 05004], lr: 0.010000, loss: 1.7944, stu_CELoss: 1.0390, DKDLoss: 0.7554, 
2022-07-29 18:06:59 - train: epoch 0051, iter [02300, 05004], lr: 0.010000, loss: 1.8601, stu_CELoss: 1.0517, DKDLoss: 0.8084, 
2022-07-29 18:07:33 - train: epoch 0051, iter [02400, 05004], lr: 0.010000, loss: 1.7922, stu_CELoss: 1.0776, DKDLoss: 0.7147, 
2022-07-29 18:08:07 - train: epoch 0051, iter [02500, 05004], lr: 0.010000, loss: 1.6209, stu_CELoss: 0.9044, DKDLoss: 0.7165, 
2022-07-29 18:08:41 - train: epoch 0051, iter [02600, 05004], lr: 0.010000, loss: 1.7598, stu_CELoss: 1.0625, DKDLoss: 0.6973, 
2022-07-29 18:09:14 - train: epoch 0051, iter [02700, 05004], lr: 0.010000, loss: 1.9024, stu_CELoss: 1.0925, DKDLoss: 0.8099, 
2022-07-29 18:09:48 - train: epoch 0051, iter [02800, 05004], lr: 0.010000, loss: 1.7486, stu_CELoss: 0.9520, DKDLoss: 0.7966, 
2022-07-29 18:10:22 - train: epoch 0051, iter [02900, 05004], lr: 0.010000, loss: 1.8279, stu_CELoss: 1.0482, DKDLoss: 0.7797, 
2022-07-29 18:10:56 - train: epoch 0051, iter [03000, 05004], lr: 0.010000, loss: 1.7966, stu_CELoss: 1.0731, DKDLoss: 0.7235, 
2022-07-29 18:11:29 - train: epoch 0051, iter [03100, 05004], lr: 0.010000, loss: 1.7076, stu_CELoss: 1.0388, DKDLoss: 0.6687, 
2022-07-29 18:12:03 - train: epoch 0051, iter [03200, 05004], lr: 0.010000, loss: 1.7603, stu_CELoss: 1.0378, DKDLoss: 0.7225, 
2022-07-29 18:12:37 - train: epoch 0051, iter [03300, 05004], lr: 0.010000, loss: 1.9462, stu_CELoss: 1.2164, DKDLoss: 0.7299, 
2022-07-29 18:13:11 - train: epoch 0051, iter [03400, 05004], lr: 0.010000, loss: 1.9012, stu_CELoss: 1.1765, DKDLoss: 0.7247, 
2022-07-29 18:13:45 - train: epoch 0051, iter [03500, 05004], lr: 0.010000, loss: 1.7853, stu_CELoss: 1.0002, DKDLoss: 0.7851, 
2022-07-29 18:14:19 - train: epoch 0051, iter [03600, 05004], lr: 0.010000, loss: 1.7260, stu_CELoss: 1.0011, DKDLoss: 0.7248, 
2022-07-29 18:14:53 - train: epoch 0051, iter [03700, 05004], lr: 0.010000, loss: 1.8518, stu_CELoss: 1.1299, DKDLoss: 0.7219, 
2022-07-29 18:15:27 - train: epoch 0051, iter [03800, 05004], lr: 0.010000, loss: 1.8107, stu_CELoss: 1.0086, DKDLoss: 0.8021, 
2022-07-29 18:16:01 - train: epoch 0051, iter [03900, 05004], lr: 0.010000, loss: 1.9283, stu_CELoss: 1.1865, DKDLoss: 0.7418, 
2022-07-29 18:16:35 - train: epoch 0051, iter [04000, 05004], lr: 0.010000, loss: 1.9654, stu_CELoss: 1.2126, DKDLoss: 0.7527, 
2022-07-29 18:17:09 - train: epoch 0051, iter [04100, 05004], lr: 0.010000, loss: 1.8891, stu_CELoss: 1.1110, DKDLoss: 0.7781, 
2022-07-29 18:17:43 - train: epoch 0051, iter [04200, 05004], lr: 0.010000, loss: 1.8316, stu_CELoss: 1.0959, DKDLoss: 0.7357, 
2022-07-29 18:18:17 - train: epoch 0051, iter [04300, 05004], lr: 0.010000, loss: 1.8404, stu_CELoss: 1.0319, DKDLoss: 0.8085, 
2022-07-29 18:18:51 - train: epoch 0051, iter [04400, 05004], lr: 0.010000, loss: 2.0051, stu_CELoss: 1.2172, DKDLoss: 0.7879, 
2022-07-29 18:19:24 - train: epoch 0051, iter [04500, 05004], lr: 0.010000, loss: 1.6914, stu_CELoss: 0.9064, DKDLoss: 0.7850, 
2022-07-29 18:19:58 - train: epoch 0051, iter [04600, 05004], lr: 0.010000, loss: 1.7890, stu_CELoss: 1.0524, DKDLoss: 0.7366, 
2022-07-29 18:20:32 - train: epoch 0051, iter [04700, 05004], lr: 0.010000, loss: 1.6701, stu_CELoss: 0.9938, DKDLoss: 0.6763, 
2022-07-29 18:21:06 - train: epoch 0051, iter [04800, 05004], lr: 0.010000, loss: 1.8049, stu_CELoss: 1.0382, DKDLoss: 0.7667, 
2022-07-29 18:21:39 - train: epoch 0051, iter [04900, 05004], lr: 0.010000, loss: 1.7770, stu_CELoss: 1.0112, DKDLoss: 0.7657, 
2022-07-29 18:22:13 - train: epoch 0051, iter [05000, 05004], lr: 0.010000, loss: 1.6579, stu_CELoss: 0.9099, DKDLoss: 0.7481, 
2022-07-29 18:22:14 - train: epoch 051, train_loss: 1.8110
2022-07-29 18:24:46 - eval: epoch: 051, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 72.648%, stu_acc5: 91.304%, stu_test_loss: 1.0861
2022-07-29 18:24:46 - until epoch: 051, tea_best_acc1: 78.068%, stu_best_acc1: 74.276%
2022-07-29 18:24:46 - epoch 052 lr: 0.010000
2022-07-29 18:25:27 - train: epoch 0052, iter [00100, 05004], lr: 0.010000, loss: 1.7361, stu_CELoss: 1.0195, DKDLoss: 0.7165, 
2022-07-29 18:26:00 - train: epoch 0052, iter [00200, 05004], lr: 0.010000, loss: 2.0119, stu_CELoss: 1.2710, DKDLoss: 0.7409, 
2022-07-29 18:26:33 - train: epoch 0052, iter [00300, 05004], lr: 0.010000, loss: 1.7166, stu_CELoss: 1.0031, DKDLoss: 0.7135, 
2022-07-29 18:27:06 - train: epoch 0052, iter [00400, 05004], lr: 0.010000, loss: 1.7408, stu_CELoss: 1.0103, DKDLoss: 0.7305, 
2022-07-29 18:27:40 - train: epoch 0052, iter [00500, 05004], lr: 0.010000, loss: 1.8808, stu_CELoss: 1.1498, DKDLoss: 0.7310, 
2022-07-29 18:28:14 - train: epoch 0052, iter [00600, 05004], lr: 0.010000, loss: 1.7020, stu_CELoss: 0.9498, DKDLoss: 0.7522, 
2022-07-29 18:28:47 - train: epoch 0052, iter [00700, 05004], lr: 0.010000, loss: 1.9890, stu_CELoss: 1.2609, DKDLoss: 0.7282, 
2022-07-29 18:29:21 - train: epoch 0052, iter [00800, 05004], lr: 0.010000, loss: 1.5886, stu_CELoss: 0.9200, DKDLoss: 0.6686, 
2022-07-29 18:29:55 - train: epoch 0052, iter [00900, 05004], lr: 0.010000, loss: 1.9080, stu_CELoss: 1.1079, DKDLoss: 0.8001, 
2022-07-29 18:30:29 - train: epoch 0052, iter [01000, 05004], lr: 0.010000, loss: 1.9313, stu_CELoss: 1.1295, DKDLoss: 0.8018, 
2022-07-29 18:31:03 - train: epoch 0052, iter [01100, 05004], lr: 0.010000, loss: 1.8479, stu_CELoss: 1.0408, DKDLoss: 0.8071, 
2022-07-29 18:31:38 - train: epoch 0052, iter [01200, 05004], lr: 0.010000, loss: 1.5975, stu_CELoss: 0.8600, DKDLoss: 0.7375, 
2022-07-29 18:32:12 - train: epoch 0052, iter [01300, 05004], lr: 0.010000, loss: 1.6842, stu_CELoss: 0.9384, DKDLoss: 0.7458, 
2022-07-29 18:32:46 - train: epoch 0052, iter [01400, 05004], lr: 0.010000, loss: 1.9266, stu_CELoss: 1.1153, DKDLoss: 0.8113, 
2022-07-29 18:33:19 - train: epoch 0052, iter [01500, 05004], lr: 0.010000, loss: 1.6585, stu_CELoss: 1.0022, DKDLoss: 0.6563, 
2022-07-29 18:33:53 - train: epoch 0052, iter [01600, 05004], lr: 0.010000, loss: 1.5384, stu_CELoss: 0.8674, DKDLoss: 0.6710, 
2022-07-29 18:34:28 - train: epoch 0052, iter [01700, 05004], lr: 0.010000, loss: 1.4941, stu_CELoss: 0.8436, DKDLoss: 0.6505, 
2022-07-29 18:35:02 - train: epoch 0052, iter [01800, 05004], lr: 0.010000, loss: 1.7528, stu_CELoss: 0.9948, DKDLoss: 0.7580, 
2022-07-29 18:35:36 - train: epoch 0052, iter [01900, 05004], lr: 0.010000, loss: 1.7848, stu_CELoss: 1.0468, DKDLoss: 0.7381, 
2022-07-29 18:36:10 - train: epoch 0052, iter [02000, 05004], lr: 0.010000, loss: 2.0013, stu_CELoss: 1.1918, DKDLoss: 0.8094, 
2022-07-29 18:36:44 - train: epoch 0052, iter [02100, 05004], lr: 0.010000, loss: 1.8323, stu_CELoss: 1.0649, DKDLoss: 0.7674, 
2022-07-29 18:37:18 - train: epoch 0052, iter [02200, 05004], lr: 0.010000, loss: 1.8151, stu_CELoss: 1.1163, DKDLoss: 0.6988, 
2022-07-29 18:37:53 - train: epoch 0052, iter [02300, 05004], lr: 0.010000, loss: 1.6664, stu_CELoss: 0.9168, DKDLoss: 0.7495, 
2022-07-29 18:38:27 - train: epoch 0052, iter [02400, 05004], lr: 0.010000, loss: 1.5754, stu_CELoss: 0.9161, DKDLoss: 0.6593, 
2022-07-29 18:39:01 - train: epoch 0052, iter [02500, 05004], lr: 0.010000, loss: 1.8252, stu_CELoss: 1.1259, DKDLoss: 0.6993, 
2022-07-29 18:39:35 - train: epoch 0052, iter [02600, 05004], lr: 0.010000, loss: 1.6808, stu_CELoss: 1.0111, DKDLoss: 0.6696, 
2022-07-29 18:40:09 - train: epoch 0052, iter [02700, 05004], lr: 0.010000, loss: 1.9106, stu_CELoss: 1.1376, DKDLoss: 0.7731, 
2022-07-29 18:40:43 - train: epoch 0052, iter [02800, 05004], lr: 0.010000, loss: 1.9315, stu_CELoss: 1.0720, DKDLoss: 0.8595, 
2022-07-29 18:41:17 - train: epoch 0052, iter [02900, 05004], lr: 0.010000, loss: 1.8692, stu_CELoss: 1.1042, DKDLoss: 0.7649, 
2022-07-29 18:41:51 - train: epoch 0052, iter [03000, 05004], lr: 0.010000, loss: 1.4730, stu_CELoss: 0.8013, DKDLoss: 0.6718, 
2022-07-29 18:42:25 - train: epoch 0052, iter [03100, 05004], lr: 0.010000, loss: 1.8849, stu_CELoss: 1.1153, DKDLoss: 0.7696, 
2022-07-29 18:42:59 - train: epoch 0052, iter [03200, 05004], lr: 0.010000, loss: 1.9496, stu_CELoss: 1.2337, DKDLoss: 0.7158, 
2022-07-29 18:43:33 - train: epoch 0052, iter [03300, 05004], lr: 0.010000, loss: 1.8497, stu_CELoss: 1.0752, DKDLoss: 0.7745, 
2022-07-29 18:44:07 - train: epoch 0052, iter [03400, 05004], lr: 0.010000, loss: 1.8956, stu_CELoss: 1.1558, DKDLoss: 0.7397, 
2022-07-29 18:44:41 - train: epoch 0052, iter [03500, 05004], lr: 0.010000, loss: 1.9723, stu_CELoss: 1.1429, DKDLoss: 0.8294, 
2022-07-29 18:45:15 - train: epoch 0052, iter [03600, 05004], lr: 0.010000, loss: 1.9693, stu_CELoss: 1.1781, DKDLoss: 0.7912, 
2022-07-29 18:45:49 - train: epoch 0052, iter [03700, 05004], lr: 0.010000, loss: 1.5987, stu_CELoss: 0.8281, DKDLoss: 0.7705, 
2022-07-29 18:46:23 - train: epoch 0052, iter [03800, 05004], lr: 0.010000, loss: 1.7298, stu_CELoss: 0.9761, DKDLoss: 0.7537, 
2022-07-29 18:46:57 - train: epoch 0052, iter [03900, 05004], lr: 0.010000, loss: 1.7085, stu_CELoss: 0.9224, DKDLoss: 0.7860, 
2022-07-29 18:47:31 - train: epoch 0052, iter [04000, 05004], lr: 0.010000, loss: 2.1904, stu_CELoss: 1.3276, DKDLoss: 0.8628, 
2022-07-29 18:48:05 - train: epoch 0052, iter [04100, 05004], lr: 0.010000, loss: 1.4036, stu_CELoss: 0.7494, DKDLoss: 0.6542, 
2022-07-29 18:48:39 - train: epoch 0052, iter [04200, 05004], lr: 0.010000, loss: 1.7529, stu_CELoss: 1.0550, DKDLoss: 0.6979, 
2022-07-29 18:49:13 - train: epoch 0052, iter [04300, 05004], lr: 0.010000, loss: 1.6802, stu_CELoss: 0.9306, DKDLoss: 0.7496, 
2022-07-29 18:49:47 - train: epoch 0052, iter [04400, 05004], lr: 0.010000, loss: 1.8801, stu_CELoss: 1.0806, DKDLoss: 0.7995, 
2022-07-29 18:50:21 - train: epoch 0052, iter [04500, 05004], lr: 0.010000, loss: 2.0074, stu_CELoss: 1.1949, DKDLoss: 0.8125, 
2022-07-29 18:50:56 - train: epoch 0052, iter [04600, 05004], lr: 0.010000, loss: 1.8362, stu_CELoss: 1.1088, DKDLoss: 0.7275, 
2022-07-29 18:51:30 - train: epoch 0052, iter [04700, 05004], lr: 0.010000, loss: 1.9102, stu_CELoss: 1.0496, DKDLoss: 0.8606, 
2022-07-29 18:52:04 - train: epoch 0052, iter [04800, 05004], lr: 0.010000, loss: 1.4597, stu_CELoss: 0.7984, DKDLoss: 0.6613, 
2022-07-29 18:52:39 - train: epoch 0052, iter [04900, 05004], lr: 0.010000, loss: 1.7132, stu_CELoss: 0.9300, DKDLoss: 0.7832, 
2022-07-29 18:53:12 - train: epoch 0052, iter [05000, 05004], lr: 0.010000, loss: 1.6307, stu_CELoss: 0.9254, DKDLoss: 0.7053, 
2022-07-29 18:53:14 - train: epoch 052, train_loss: 1.8060
2022-07-29 18:55:45 - eval: epoch: 052, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 72.850%, stu_acc5: 91.206%, stu_test_loss: 1.0863
2022-07-29 18:55:46 - until epoch: 052, tea_best_acc1: 78.068%, stu_best_acc1: 74.276%
2022-07-29 18:55:46 - epoch 053 lr: 0.010000
2022-07-29 18:56:26 - train: epoch 0053, iter [00100, 05004], lr: 0.010000, loss: 2.0501, stu_CELoss: 1.2480, DKDLoss: 0.8021, 
2022-07-29 18:56:59 - train: epoch 0053, iter [00200, 05004], lr: 0.010000, loss: 1.7404, stu_CELoss: 1.0639, DKDLoss: 0.6765, 
2022-07-29 18:57:32 - train: epoch 0053, iter [00300, 05004], lr: 0.010000, loss: 1.6063, stu_CELoss: 0.8932, DKDLoss: 0.7131, 
2022-07-29 18:58:05 - train: epoch 0053, iter [00400, 05004], lr: 0.010000, loss: 1.8475, stu_CELoss: 1.1192, DKDLoss: 0.7283, 
2022-07-29 18:58:38 - train: epoch 0053, iter [00500, 05004], lr: 0.010000, loss: 1.7982, stu_CELoss: 1.0128, DKDLoss: 0.7854, 
2022-07-29 18:59:11 - train: epoch 0053, iter [00600, 05004], lr: 0.010000, loss: 1.5196, stu_CELoss: 0.8471, DKDLoss: 0.6725, 
2022-07-29 18:59:45 - train: epoch 0053, iter [00700, 05004], lr: 0.010000, loss: 1.7298, stu_CELoss: 1.0076, DKDLoss: 0.7221, 
2022-07-29 19:00:18 - train: epoch 0053, iter [00800, 05004], lr: 0.010000, loss: 1.9313, stu_CELoss: 1.1480, DKDLoss: 0.7833, 
2022-07-29 19:00:52 - train: epoch 0053, iter [00900, 05004], lr: 0.010000, loss: 1.6342, stu_CELoss: 0.9461, DKDLoss: 0.6881, 
2022-07-29 19:01:25 - train: epoch 0053, iter [01000, 05004], lr: 0.010000, loss: 1.7486, stu_CELoss: 0.9854, DKDLoss: 0.7631, 
2022-07-29 19:01:58 - train: epoch 0053, iter [01100, 05004], lr: 0.010000, loss: 1.9205, stu_CELoss: 1.1462, DKDLoss: 0.7743, 
2022-07-29 19:02:32 - train: epoch 0053, iter [01200, 05004], lr: 0.010000, loss: 1.8107, stu_CELoss: 1.0483, DKDLoss: 0.7624, 
2022-07-29 19:03:06 - train: epoch 0053, iter [01300, 05004], lr: 0.010000, loss: 1.8492, stu_CELoss: 1.0915, DKDLoss: 0.7577, 
2022-07-29 19:03:39 - train: epoch 0053, iter [01400, 05004], lr: 0.010000, loss: 1.8935, stu_CELoss: 1.0733, DKDLoss: 0.8201, 
2022-07-29 19:04:14 - train: epoch 0053, iter [01500, 05004], lr: 0.010000, loss: 1.6814, stu_CELoss: 0.9748, DKDLoss: 0.7066, 
2022-07-29 19:04:47 - train: epoch 0053, iter [01600, 05004], lr: 0.010000, loss: 2.0073, stu_CELoss: 1.2686, DKDLoss: 0.7387, 
2022-07-29 19:05:21 - train: epoch 0053, iter [01700, 05004], lr: 0.010000, loss: 2.0135, stu_CELoss: 1.2342, DKDLoss: 0.7793, 
2022-07-29 19:05:55 - train: epoch 0053, iter [01800, 05004], lr: 0.010000, loss: 1.8935, stu_CELoss: 1.1953, DKDLoss: 0.6982, 
2022-07-29 19:06:29 - train: epoch 0053, iter [01900, 05004], lr: 0.010000, loss: 1.7375, stu_CELoss: 0.9981, DKDLoss: 0.7394, 
2022-07-29 19:07:03 - train: epoch 0053, iter [02000, 05004], lr: 0.010000, loss: 1.7426, stu_CELoss: 0.9799, DKDLoss: 0.7628, 
2022-07-29 19:07:36 - train: epoch 0053, iter [02100, 05004], lr: 0.010000, loss: 2.1085, stu_CELoss: 1.2700, DKDLoss: 0.8384, 
2022-07-29 19:08:10 - train: epoch 0053, iter [02200, 05004], lr: 0.010000, loss: 1.6770, stu_CELoss: 0.8970, DKDLoss: 0.7800, 
2022-07-29 19:08:44 - train: epoch 0053, iter [02300, 05004], lr: 0.010000, loss: 1.7560, stu_CELoss: 1.0495, DKDLoss: 0.7065, 
2022-07-29 19:09:18 - train: epoch 0053, iter [02400, 05004], lr: 0.010000, loss: 1.7103, stu_CELoss: 1.0531, DKDLoss: 0.6572, 
2022-07-29 19:09:52 - train: epoch 0053, iter [02500, 05004], lr: 0.010000, loss: 2.0575, stu_CELoss: 1.2935, DKDLoss: 0.7640, 
2022-07-29 19:10:25 - train: epoch 0053, iter [02600, 05004], lr: 0.010000, loss: 1.6954, stu_CELoss: 0.9819, DKDLoss: 0.7135, 
2022-07-29 19:10:59 - train: epoch 0053, iter [02700, 05004], lr: 0.010000, loss: 1.8452, stu_CELoss: 1.0521, DKDLoss: 0.7931, 
2022-07-29 19:11:33 - train: epoch 0053, iter [02800, 05004], lr: 0.010000, loss: 1.7711, stu_CELoss: 1.0408, DKDLoss: 0.7302, 
2022-07-29 19:12:07 - train: epoch 0053, iter [02900, 05004], lr: 0.010000, loss: 1.6360, stu_CELoss: 0.8818, DKDLoss: 0.7543, 
2022-07-29 19:12:41 - train: epoch 0053, iter [03000, 05004], lr: 0.010000, loss: 1.6547, stu_CELoss: 0.9276, DKDLoss: 0.7271, 
2022-07-29 19:13:14 - train: epoch 0053, iter [03100, 05004], lr: 0.010000, loss: 1.9564, stu_CELoss: 1.2430, DKDLoss: 0.7134, 
2022-07-29 19:13:48 - train: epoch 0053, iter [03200, 05004], lr: 0.010000, loss: 1.8988, stu_CELoss: 1.0305, DKDLoss: 0.8683, 
2022-07-29 19:14:23 - train: epoch 0053, iter [03300, 05004], lr: 0.010000, loss: 1.8343, stu_CELoss: 1.0351, DKDLoss: 0.7992, 
2022-07-29 19:14:57 - train: epoch 0053, iter [03400, 05004], lr: 0.010000, loss: 1.8283, stu_CELoss: 1.1426, DKDLoss: 0.6858, 
2022-07-29 19:15:31 - train: epoch 0053, iter [03500, 05004], lr: 0.010000, loss: 1.7700, stu_CELoss: 1.0769, DKDLoss: 0.6931, 
2022-07-29 19:16:05 - train: epoch 0053, iter [03600, 05004], lr: 0.010000, loss: 1.7756, stu_CELoss: 1.0311, DKDLoss: 0.7445, 
2022-07-29 19:16:39 - train: epoch 0053, iter [03700, 05004], lr: 0.010000, loss: 2.0054, stu_CELoss: 1.1536, DKDLoss: 0.8518, 
2022-07-29 19:17:13 - train: epoch 0053, iter [03800, 05004], lr: 0.010000, loss: 1.7047, stu_CELoss: 0.9605, DKDLoss: 0.7443, 
2022-07-29 19:17:48 - train: epoch 0053, iter [03900, 05004], lr: 0.010000, loss: 1.9331, stu_CELoss: 1.1140, DKDLoss: 0.8191, 
2022-07-29 19:18:22 - train: epoch 0053, iter [04000, 05004], lr: 0.010000, loss: 1.8356, stu_CELoss: 1.1023, DKDLoss: 0.7333, 
2022-07-29 19:18:56 - train: epoch 0053, iter [04100, 05004], lr: 0.010000, loss: 1.9352, stu_CELoss: 1.1649, DKDLoss: 0.7703, 
2022-07-29 19:19:30 - train: epoch 0053, iter [04200, 05004], lr: 0.010000, loss: 1.8219, stu_CELoss: 1.0002, DKDLoss: 0.8217, 
2022-07-29 19:20:04 - train: epoch 0053, iter [04300, 05004], lr: 0.010000, loss: 1.9660, stu_CELoss: 1.1943, DKDLoss: 0.7717, 
2022-07-29 19:20:38 - train: epoch 0053, iter [04400, 05004], lr: 0.010000, loss: 1.9429, stu_CELoss: 1.1671, DKDLoss: 0.7758, 
2022-07-29 19:21:12 - train: epoch 0053, iter [04500, 05004], lr: 0.010000, loss: 2.0477, stu_CELoss: 1.1799, DKDLoss: 0.8679, 
2022-07-29 19:21:46 - train: epoch 0053, iter [04600, 05004], lr: 0.010000, loss: 1.8430, stu_CELoss: 1.0669, DKDLoss: 0.7761, 
2022-07-29 19:22:20 - train: epoch 0053, iter [04700, 05004], lr: 0.010000, loss: 1.7427, stu_CELoss: 1.0274, DKDLoss: 0.7153, 
2022-07-29 19:22:54 - train: epoch 0053, iter [04800, 05004], lr: 0.010000, loss: 1.9546, stu_CELoss: 1.1415, DKDLoss: 0.8131, 
2022-07-29 19:23:28 - train: epoch 0053, iter [04900, 05004], lr: 0.010000, loss: 1.7338, stu_CELoss: 1.0475, DKDLoss: 0.6863, 
2022-07-29 19:24:02 - train: epoch 0053, iter [05000, 05004], lr: 0.010000, loss: 1.7652, stu_CELoss: 1.0517, DKDLoss: 0.7136, 
2022-07-29 19:24:03 - train: epoch 053, train_loss: 1.8024
2022-07-29 19:26:35 - eval: epoch: 053, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 73.138%, stu_acc5: 91.426%, stu_test_loss: 1.0682
2022-07-29 19:26:36 - until epoch: 053, tea_best_acc1: 78.068%, stu_best_acc1: 74.276%
2022-07-29 19:26:36 - epoch 054 lr: 0.010000
2022-07-29 19:27:16 - train: epoch 0054, iter [00100, 05004], lr: 0.010000, loss: 1.5569, stu_CELoss: 0.8526, DKDLoss: 0.7042, 
2022-07-29 19:27:50 - train: epoch 0054, iter [00200, 05004], lr: 0.010000, loss: 1.8641, stu_CELoss: 1.1103, DKDLoss: 0.7538, 
2022-07-29 19:28:24 - train: epoch 0054, iter [00300, 05004], lr: 0.010000, loss: 1.6204, stu_CELoss: 0.8912, DKDLoss: 0.7292, 
2022-07-29 19:28:58 - train: epoch 0054, iter [00400, 05004], lr: 0.010000, loss: 1.7221, stu_CELoss: 0.9933, DKDLoss: 0.7288, 
2022-07-29 19:29:31 - train: epoch 0054, iter [00500, 05004], lr: 0.010000, loss: 1.6688, stu_CELoss: 1.0326, DKDLoss: 0.6362, 
2022-07-29 19:30:05 - train: epoch 0054, iter [00600, 05004], lr: 0.010000, loss: 1.6633, stu_CELoss: 0.9684, DKDLoss: 0.6949, 
2022-07-29 19:30:38 - train: epoch 0054, iter [00700, 05004], lr: 0.010000, loss: 1.8549, stu_CELoss: 1.1870, DKDLoss: 0.6679, 
2022-07-29 19:31:12 - train: epoch 0054, iter [00800, 05004], lr: 0.010000, loss: 1.8887, stu_CELoss: 1.1651, DKDLoss: 0.7236, 
2022-07-29 19:31:45 - train: epoch 0054, iter [00900, 05004], lr: 0.010000, loss: 1.6124, stu_CELoss: 0.9653, DKDLoss: 0.6470, 
2022-07-29 19:32:19 - train: epoch 0054, iter [01000, 05004], lr: 0.010000, loss: 1.4675, stu_CELoss: 0.8068, DKDLoss: 0.6607, 
2022-07-29 19:32:53 - train: epoch 0054, iter [01100, 05004], lr: 0.010000, loss: 1.6637, stu_CELoss: 0.9672, DKDLoss: 0.6965, 
2022-07-29 19:33:26 - train: epoch 0054, iter [01200, 05004], lr: 0.010000, loss: 1.8972, stu_CELoss: 1.0982, DKDLoss: 0.7990, 
2022-07-29 19:34:00 - train: epoch 0054, iter [01300, 05004], lr: 0.010000, loss: 1.7786, stu_CELoss: 1.0041, DKDLoss: 0.7745, 
2022-07-29 19:34:33 - train: epoch 0054, iter [01400, 05004], lr: 0.010000, loss: 1.6916, stu_CELoss: 0.9416, DKDLoss: 0.7500, 
2022-07-29 19:35:06 - train: epoch 0054, iter [01500, 05004], lr: 0.010000, loss: 1.8902, stu_CELoss: 1.1733, DKDLoss: 0.7169, 
2022-07-29 19:35:40 - train: epoch 0054, iter [01600, 05004], lr: 0.010000, loss: 1.4299, stu_CELoss: 0.7566, DKDLoss: 0.6733, 
2022-07-29 19:36:14 - train: epoch 0054, iter [01700, 05004], lr: 0.010000, loss: 1.6918, stu_CELoss: 1.0096, DKDLoss: 0.6822, 
2022-07-29 19:36:48 - train: epoch 0054, iter [01800, 05004], lr: 0.010000, loss: 1.8399, stu_CELoss: 1.0751, DKDLoss: 0.7648, 
2022-07-29 19:37:22 - train: epoch 0054, iter [01900, 05004], lr: 0.010000, loss: 1.7132, stu_CELoss: 0.9504, DKDLoss: 0.7628, 
2022-07-29 19:37:56 - train: epoch 0054, iter [02000, 05004], lr: 0.010000, loss: 1.9804, stu_CELoss: 1.2363, DKDLoss: 0.7441, 
2022-07-29 19:38:30 - train: epoch 0054, iter [02100, 05004], lr: 0.010000, loss: 1.9044, stu_CELoss: 1.1182, DKDLoss: 0.7862, 
2022-07-29 19:39:04 - train: epoch 0054, iter [02200, 05004], lr: 0.010000, loss: 1.6767, stu_CELoss: 0.9713, DKDLoss: 0.7054, 
2022-07-29 19:39:38 - train: epoch 0054, iter [02300, 05004], lr: 0.010000, loss: 1.6925, stu_CELoss: 0.9575, DKDLoss: 0.7350, 
2022-07-29 19:40:13 - train: epoch 0054, iter [02400, 05004], lr: 0.010000, loss: 1.8614, stu_CELoss: 1.1057, DKDLoss: 0.7557, 
2022-07-29 19:40:47 - train: epoch 0054, iter [02500, 05004], lr: 0.010000, loss: 1.9298, stu_CELoss: 1.1309, DKDLoss: 0.7988, 
2022-07-29 19:41:21 - train: epoch 0054, iter [02600, 05004], lr: 0.010000, loss: 1.6114, stu_CELoss: 0.9296, DKDLoss: 0.6818, 
2022-07-29 19:41:55 - train: epoch 0054, iter [02700, 05004], lr: 0.010000, loss: 1.7204, stu_CELoss: 0.9830, DKDLoss: 0.7374, 
2022-07-29 19:42:29 - train: epoch 0054, iter [02800, 05004], lr: 0.010000, loss: 1.9613, stu_CELoss: 1.1926, DKDLoss: 0.7687, 
2022-07-29 19:43:03 - train: epoch 0054, iter [02900, 05004], lr: 0.010000, loss: 1.7903, stu_CELoss: 1.1051, DKDLoss: 0.6851, 
2022-07-29 19:43:37 - train: epoch 0054, iter [03000, 05004], lr: 0.010000, loss: 1.7859, stu_CELoss: 1.0523, DKDLoss: 0.7336, 
2022-07-29 19:44:11 - train: epoch 0054, iter [03100, 05004], lr: 0.010000, loss: 1.9422, stu_CELoss: 1.1193, DKDLoss: 0.8229, 
2022-07-29 19:44:46 - train: epoch 0054, iter [03200, 05004], lr: 0.010000, loss: 2.1163, stu_CELoss: 1.3516, DKDLoss: 0.7647, 
2022-07-29 19:45:20 - train: epoch 0054, iter [03300, 05004], lr: 0.010000, loss: 1.7444, stu_CELoss: 1.0340, DKDLoss: 0.7105, 
2022-07-29 19:45:55 - train: epoch 0054, iter [03400, 05004], lr: 0.010000, loss: 1.7946, stu_CELoss: 1.0761, DKDLoss: 0.7185, 
2022-07-29 19:46:29 - train: epoch 0054, iter [03500, 05004], lr: 0.010000, loss: 1.8318, stu_CELoss: 1.0820, DKDLoss: 0.7498, 
2022-07-29 19:47:03 - train: epoch 0054, iter [03600, 05004], lr: 0.010000, loss: 1.9222, stu_CELoss: 1.1212, DKDLoss: 0.8010, 
2022-07-29 19:47:38 - train: epoch 0054, iter [03700, 05004], lr: 0.010000, loss: 1.5733, stu_CELoss: 0.9155, DKDLoss: 0.6578, 
2022-07-29 19:48:12 - train: epoch 0054, iter [03800, 05004], lr: 0.010000, loss: 1.5727, stu_CELoss: 0.8480, DKDLoss: 0.7246, 
2022-07-29 19:48:46 - train: epoch 0054, iter [03900, 05004], lr: 0.010000, loss: 1.8233, stu_CELoss: 1.0677, DKDLoss: 0.7556, 
2022-07-29 19:49:20 - train: epoch 0054, iter [04000, 05004], lr: 0.010000, loss: 1.6647, stu_CELoss: 0.9604, DKDLoss: 0.7043, 
2022-07-29 19:49:54 - train: epoch 0054, iter [04100, 05004], lr: 0.010000, loss: 1.8035, stu_CELoss: 1.0317, DKDLoss: 0.7718, 
2022-07-29 19:50:28 - train: epoch 0054, iter [04200, 05004], lr: 0.010000, loss: 1.9104, stu_CELoss: 1.1036, DKDLoss: 0.8067, 
2022-07-29 19:51:03 - train: epoch 0054, iter [04300, 05004], lr: 0.010000, loss: 1.9917, stu_CELoss: 1.3115, DKDLoss: 0.6802, 
2022-07-29 19:51:37 - train: epoch 0054, iter [04400, 05004], lr: 0.010000, loss: 1.7084, stu_CELoss: 0.9921, DKDLoss: 0.7163, 
2022-07-29 19:52:11 - train: epoch 0054, iter [04500, 05004], lr: 0.010000, loss: 1.7427, stu_CELoss: 1.0279, DKDLoss: 0.7147, 
2022-07-29 19:52:45 - train: epoch 0054, iter [04600, 05004], lr: 0.010000, loss: 1.9371, stu_CELoss: 1.1018, DKDLoss: 0.8353, 
2022-07-29 19:53:19 - train: epoch 0054, iter [04700, 05004], lr: 0.010000, loss: 1.9430, stu_CELoss: 1.1362, DKDLoss: 0.8068, 
2022-07-29 19:53:54 - train: epoch 0054, iter [04800, 05004], lr: 0.010000, loss: 1.9562, stu_CELoss: 1.1872, DKDLoss: 0.7690, 
2022-07-29 19:54:28 - train: epoch 0054, iter [04900, 05004], lr: 0.010000, loss: 1.8381, stu_CELoss: 1.0086, DKDLoss: 0.8295, 
2022-07-29 19:55:02 - train: epoch 0054, iter [05000, 05004], lr: 0.010000, loss: 1.8078, stu_CELoss: 1.0683, DKDLoss: 0.7395, 
2022-07-29 19:55:03 - train: epoch 054, train_loss: 1.7977
2022-07-29 19:57:36 - eval: epoch: 054, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 72.594%, stu_acc5: 91.288%, stu_test_loss: 1.0848
2022-07-29 19:57:37 - until epoch: 054, tea_best_acc1: 78.068%, stu_best_acc1: 74.276%
2022-07-29 19:57:37 - epoch 055 lr: 0.010000
2022-07-29 19:58:17 - train: epoch 0055, iter [00100, 05004], lr: 0.010000, loss: 1.4313, stu_CELoss: 0.8233, DKDLoss: 0.6080, 
2022-07-29 19:58:50 - train: epoch 0055, iter [00200, 05004], lr: 0.010000, loss: 1.7910, stu_CELoss: 0.9706, DKDLoss: 0.8205, 
2022-07-29 19:59:23 - train: epoch 0055, iter [00300, 05004], lr: 0.010000, loss: 1.5804, stu_CELoss: 0.9045, DKDLoss: 0.6759, 
2022-07-29 19:59:57 - train: epoch 0055, iter [00400, 05004], lr: 0.010000, loss: 1.4419, stu_CELoss: 0.7882, DKDLoss: 0.6538, 
2022-07-29 20:00:31 - train: epoch 0055, iter [00500, 05004], lr: 0.010000, loss: 1.4830, stu_CELoss: 0.8316, DKDLoss: 0.6515, 
2022-07-29 20:01:04 - train: epoch 0055, iter [00600, 05004], lr: 0.010000, loss: 1.5379, stu_CELoss: 0.8857, DKDLoss: 0.6522, 
2022-07-29 20:01:38 - train: epoch 0055, iter [00700, 05004], lr: 0.010000, loss: 1.9326, stu_CELoss: 1.0884, DKDLoss: 0.8441, 
2022-07-29 20:02:12 - train: epoch 0055, iter [00800, 05004], lr: 0.010000, loss: 1.6818, stu_CELoss: 0.9790, DKDLoss: 0.7028, 
2022-07-29 20:02:45 - train: epoch 0055, iter [00900, 05004], lr: 0.010000, loss: 1.8218, stu_CELoss: 1.0518, DKDLoss: 0.7700, 
2022-07-29 20:03:19 - train: epoch 0055, iter [01000, 05004], lr: 0.010000, loss: 1.8427, stu_CELoss: 1.0885, DKDLoss: 0.7541, 
2022-07-29 20:03:52 - train: epoch 0055, iter [01100, 05004], lr: 0.010000, loss: 1.5265, stu_CELoss: 0.8387, DKDLoss: 0.6878, 
2022-07-29 20:04:26 - train: epoch 0055, iter [01200, 05004], lr: 0.010000, loss: 1.8131, stu_CELoss: 1.0665, DKDLoss: 0.7466, 
2022-07-29 20:05:00 - train: epoch 0055, iter [01300, 05004], lr: 0.010000, loss: 2.0033, stu_CELoss: 1.1605, DKDLoss: 0.8428, 
2022-07-29 20:05:33 - train: epoch 0055, iter [01400, 05004], lr: 0.010000, loss: 1.6214, stu_CELoss: 0.9762, DKDLoss: 0.6452, 
2022-07-29 20:06:07 - train: epoch 0055, iter [01500, 05004], lr: 0.010000, loss: 1.7319, stu_CELoss: 0.9762, DKDLoss: 0.7557, 
2022-07-29 20:06:41 - train: epoch 0055, iter [01600, 05004], lr: 0.010000, loss: 1.9172, stu_CELoss: 1.1561, DKDLoss: 0.7611, 
2022-07-29 20:07:15 - train: epoch 0055, iter [01700, 05004], lr: 0.010000, loss: 1.7196, stu_CELoss: 0.9568, DKDLoss: 0.7627, 
2022-07-29 20:07:48 - train: epoch 0055, iter [01800, 05004], lr: 0.010000, loss: 1.6555, stu_CELoss: 1.0086, DKDLoss: 0.6469, 
2022-07-29 20:08:22 - train: epoch 0055, iter [01900, 05004], lr: 0.010000, loss: 1.9207, stu_CELoss: 1.1314, DKDLoss: 0.7893, 
2022-07-29 20:08:56 - train: epoch 0055, iter [02000, 05004], lr: 0.010000, loss: 2.0765, stu_CELoss: 1.2555, DKDLoss: 0.8210, 
2022-07-29 20:09:30 - train: epoch 0055, iter [02100, 05004], lr: 0.010000, loss: 1.4299, stu_CELoss: 0.8676, DKDLoss: 0.5623, 
2022-07-29 20:10:04 - train: epoch 0055, iter [02200, 05004], lr: 0.010000, loss: 2.2552, stu_CELoss: 1.4155, DKDLoss: 0.8397, 
2022-07-29 20:10:38 - train: epoch 0055, iter [02300, 05004], lr: 0.010000, loss: 1.9131, stu_CELoss: 1.1499, DKDLoss: 0.7632, 
2022-07-29 20:11:12 - train: epoch 0055, iter [02400, 05004], lr: 0.010000, loss: 1.4700, stu_CELoss: 0.8038, DKDLoss: 0.6663, 
2022-07-29 20:11:46 - train: epoch 0055, iter [02500, 05004], lr: 0.010000, loss: 1.7079, stu_CELoss: 1.0501, DKDLoss: 0.6579, 
2022-07-29 20:12:20 - train: epoch 0055, iter [02600, 05004], lr: 0.010000, loss: 1.6764, stu_CELoss: 1.0023, DKDLoss: 0.6740, 
2022-07-29 20:12:54 - train: epoch 0055, iter [02700, 05004], lr: 0.010000, loss: 1.7503, stu_CELoss: 1.0226, DKDLoss: 0.7277, 
2022-07-29 20:13:29 - train: epoch 0055, iter [02800, 05004], lr: 0.010000, loss: 1.8199, stu_CELoss: 1.0601, DKDLoss: 0.7598, 
2022-07-29 20:14:03 - train: epoch 0055, iter [02900, 05004], lr: 0.010000, loss: 1.7645, stu_CELoss: 0.9762, DKDLoss: 0.7884, 
2022-07-29 20:14:37 - train: epoch 0055, iter [03000, 05004], lr: 0.010000, loss: 2.0116, stu_CELoss: 1.2047, DKDLoss: 0.8070, 
2022-07-29 20:15:11 - train: epoch 0055, iter [03100, 05004], lr: 0.010000, loss: 1.7775, stu_CELoss: 1.0799, DKDLoss: 0.6976, 
2022-07-29 20:15:45 - train: epoch 0055, iter [03200, 05004], lr: 0.010000, loss: 1.8089, stu_CELoss: 1.0684, DKDLoss: 0.7405, 
2022-07-29 20:16:19 - train: epoch 0055, iter [03300, 05004], lr: 0.010000, loss: 1.7020, stu_CELoss: 0.9205, DKDLoss: 0.7815, 
2022-07-29 20:16:54 - train: epoch 0055, iter [03400, 05004], lr: 0.010000, loss: 1.8238, stu_CELoss: 1.0456, DKDLoss: 0.7781, 
2022-07-29 20:17:28 - train: epoch 0055, iter [03500, 05004], lr: 0.010000, loss: 1.8612, stu_CELoss: 1.1369, DKDLoss: 0.7242, 
2022-07-29 20:18:01 - train: epoch 0055, iter [03600, 05004], lr: 0.010000, loss: 1.7271, stu_CELoss: 0.9772, DKDLoss: 0.7499, 
2022-07-29 20:18:35 - train: epoch 0055, iter [03700, 05004], lr: 0.010000, loss: 1.6205, stu_CELoss: 0.9421, DKDLoss: 0.6785, 
2022-07-29 20:19:09 - train: epoch 0055, iter [03800, 05004], lr: 0.010000, loss: 1.8452, stu_CELoss: 1.0483, DKDLoss: 0.7969, 
2022-07-29 20:19:43 - train: epoch 0055, iter [03900, 05004], lr: 0.010000, loss: 2.0423, stu_CELoss: 1.2010, DKDLoss: 0.8414, 
2022-07-29 20:20:17 - train: epoch 0055, iter [04000, 05004], lr: 0.010000, loss: 1.8031, stu_CELoss: 1.0795, DKDLoss: 0.7236, 
2022-07-29 20:20:51 - train: epoch 0055, iter [04100, 05004], lr: 0.010000, loss: 1.8520, stu_CELoss: 1.1388, DKDLoss: 0.7132, 
2022-07-29 20:21:25 - train: epoch 0055, iter [04200, 05004], lr: 0.010000, loss: 1.8758, stu_CELoss: 1.0900, DKDLoss: 0.7858, 
2022-07-29 20:21:58 - train: epoch 0055, iter [04300, 05004], lr: 0.010000, loss: 2.0894, stu_CELoss: 1.2182, DKDLoss: 0.8712, 
2022-07-29 20:22:32 - train: epoch 0055, iter [04400, 05004], lr: 0.010000, loss: 1.7893, stu_CELoss: 1.0908, DKDLoss: 0.6985, 
2022-07-29 20:23:06 - train: epoch 0055, iter [04500, 05004], lr: 0.010000, loss: 1.7218, stu_CELoss: 0.9664, DKDLoss: 0.7554, 
2022-07-29 20:23:39 - train: epoch 0055, iter [04600, 05004], lr: 0.010000, loss: 1.8341, stu_CELoss: 1.0657, DKDLoss: 0.7684, 
2022-07-29 20:24:13 - train: epoch 0055, iter [04700, 05004], lr: 0.010000, loss: 1.7871, stu_CELoss: 1.0449, DKDLoss: 0.7422, 
2022-07-29 20:24:47 - train: epoch 0055, iter [04800, 05004], lr: 0.010000, loss: 1.6388, stu_CELoss: 0.9347, DKDLoss: 0.7040, 
2022-07-29 20:25:21 - train: epoch 0055, iter [04900, 05004], lr: 0.010000, loss: 1.8349, stu_CELoss: 1.0596, DKDLoss: 0.7752, 
2022-07-29 20:25:54 - train: epoch 0055, iter [05000, 05004], lr: 0.010000, loss: 2.1121, stu_CELoss: 1.2376, DKDLoss: 0.8744, 
2022-07-29 20:25:56 - train: epoch 055, train_loss: 1.7977
2022-07-29 20:28:27 - eval: epoch: 055, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 72.650%, stu_acc5: 91.324%, stu_test_loss: 1.0852
2022-07-29 20:28:28 - until epoch: 055, tea_best_acc1: 78.068%, stu_best_acc1: 74.276%
2022-07-29 20:28:28 - epoch 056 lr: 0.010000
2022-07-29 20:29:08 - train: epoch 0056, iter [00100, 05004], lr: 0.010000, loss: 1.7479, stu_CELoss: 1.0358, DKDLoss: 0.7121, 
2022-07-29 20:29:40 - train: epoch 0056, iter [00200, 05004], lr: 0.010000, loss: 1.9465, stu_CELoss: 1.1505, DKDLoss: 0.7959, 
2022-07-29 20:30:13 - train: epoch 0056, iter [00300, 05004], lr: 0.010000, loss: 1.5798, stu_CELoss: 0.9461, DKDLoss: 0.6337, 
2022-07-29 20:30:46 - train: epoch 0056, iter [00400, 05004], lr: 0.010000, loss: 1.8198, stu_CELoss: 1.1575, DKDLoss: 0.6623, 
2022-07-29 20:31:19 - train: epoch 0056, iter [00500, 05004], lr: 0.010000, loss: 1.6728, stu_CELoss: 0.9999, DKDLoss: 0.6730, 
2022-07-29 20:31:53 - train: epoch 0056, iter [00600, 05004], lr: 0.010000, loss: 1.7577, stu_CELoss: 1.0568, DKDLoss: 0.7010, 
2022-07-29 20:32:27 - train: epoch 0056, iter [00700, 05004], lr: 0.010000, loss: 1.6775, stu_CELoss: 0.9430, DKDLoss: 0.7346, 
2022-07-29 20:33:00 - train: epoch 0056, iter [00800, 05004], lr: 0.010000, loss: 1.7806, stu_CELoss: 1.0313, DKDLoss: 0.7493, 
2022-07-29 20:33:33 - train: epoch 0056, iter [00900, 05004], lr: 0.010000, loss: 1.8117, stu_CELoss: 1.0197, DKDLoss: 0.7921, 
2022-07-29 20:34:07 - train: epoch 0056, iter [01000, 05004], lr: 0.010000, loss: 1.6723, stu_CELoss: 0.9713, DKDLoss: 0.7011, 
2022-07-29 20:34:40 - train: epoch 0056, iter [01100, 05004], lr: 0.010000, loss: 1.6706, stu_CELoss: 0.9584, DKDLoss: 0.7122, 
2022-07-29 20:35:14 - train: epoch 0056, iter [01200, 05004], lr: 0.010000, loss: 1.7754, stu_CELoss: 1.0359, DKDLoss: 0.7395, 
2022-07-29 20:35:48 - train: epoch 0056, iter [01300, 05004], lr: 0.010000, loss: 2.0322, stu_CELoss: 1.2567, DKDLoss: 0.7755, 
2022-07-29 20:36:21 - train: epoch 0056, iter [01400, 05004], lr: 0.010000, loss: 1.6688, stu_CELoss: 0.9499, DKDLoss: 0.7188, 
2022-07-29 20:36:55 - train: epoch 0056, iter [01500, 05004], lr: 0.010000, loss: 2.0522, stu_CELoss: 1.2087, DKDLoss: 0.8435, 
2022-07-29 20:37:29 - train: epoch 0056, iter [01600, 05004], lr: 0.010000, loss: 1.6387, stu_CELoss: 0.9690, DKDLoss: 0.6697, 
2022-07-29 20:38:02 - train: epoch 0056, iter [01700, 05004], lr: 0.010000, loss: 1.6331, stu_CELoss: 0.9647, DKDLoss: 0.6685, 
2022-07-29 20:38:36 - train: epoch 0056, iter [01800, 05004], lr: 0.010000, loss: 1.8425, stu_CELoss: 1.1516, DKDLoss: 0.6909, 
2022-07-29 20:39:11 - train: epoch 0056, iter [01900, 05004], lr: 0.010000, loss: 1.8594, stu_CELoss: 1.1342, DKDLoss: 0.7252, 
2022-07-29 20:39:44 - train: epoch 0056, iter [02000, 05004], lr: 0.010000, loss: 1.8218, stu_CELoss: 1.0782, DKDLoss: 0.7436, 
2022-07-29 20:40:18 - train: epoch 0056, iter [02100, 05004], lr: 0.010000, loss: 2.0107, stu_CELoss: 1.2520, DKDLoss: 0.7587, 
2022-07-29 20:40:52 - train: epoch 0056, iter [02200, 05004], lr: 0.010000, loss: 1.9939, stu_CELoss: 1.1631, DKDLoss: 0.8308, 
2022-07-29 20:41:26 - train: epoch 0056, iter [02300, 05004], lr: 0.010000, loss: 1.7766, stu_CELoss: 1.0437, DKDLoss: 0.7329, 
2022-07-29 20:42:00 - train: epoch 0056, iter [02400, 05004], lr: 0.010000, loss: 1.6747, stu_CELoss: 1.0038, DKDLoss: 0.6709, 
2022-07-29 20:42:34 - train: epoch 0056, iter [02500, 05004], lr: 0.010000, loss: 2.0307, stu_CELoss: 1.2479, DKDLoss: 0.7828, 
2022-07-29 20:43:08 - train: epoch 0056, iter [02600, 05004], lr: 0.010000, loss: 1.8177, stu_CELoss: 1.0902, DKDLoss: 0.7275, 
2022-07-29 20:43:42 - train: epoch 0056, iter [02700, 05004], lr: 0.010000, loss: 1.5447, stu_CELoss: 0.8995, DKDLoss: 0.6452, 
2022-07-29 20:44:16 - train: epoch 0056, iter [02800, 05004], lr: 0.010000, loss: 1.7012, stu_CELoss: 0.9890, DKDLoss: 0.7122, 
2022-07-29 20:44:50 - train: epoch 0056, iter [02900, 05004], lr: 0.010000, loss: 1.7830, stu_CELoss: 0.9820, DKDLoss: 0.8011, 
2022-07-29 20:45:24 - train: epoch 0056, iter [03000, 05004], lr: 0.010000, loss: 2.0273, stu_CELoss: 1.1595, DKDLoss: 0.8677, 
2022-07-29 20:45:58 - train: epoch 0056, iter [03100, 05004], lr: 0.010000, loss: 1.6753, stu_CELoss: 0.9672, DKDLoss: 0.7081, 
2022-07-29 20:46:31 - train: epoch 0056, iter [03200, 05004], lr: 0.010000, loss: 1.5606, stu_CELoss: 0.8729, DKDLoss: 0.6877, 
2022-07-29 20:47:05 - train: epoch 0056, iter [03300, 05004], lr: 0.010000, loss: 1.8141, stu_CELoss: 1.0812, DKDLoss: 0.7329, 
2022-07-29 20:47:39 - train: epoch 0056, iter [03400, 05004], lr: 0.010000, loss: 1.7964, stu_CELoss: 1.0607, DKDLoss: 0.7357, 
2022-07-29 20:48:13 - train: epoch 0056, iter [03500, 05004], lr: 0.010000, loss: 1.7778, stu_CELoss: 1.0245, DKDLoss: 0.7533, 
2022-07-29 20:48:46 - train: epoch 0056, iter [03600, 05004], lr: 0.010000, loss: 1.6433, stu_CELoss: 0.9225, DKDLoss: 0.7208, 
2022-07-29 20:49:20 - train: epoch 0056, iter [03700, 05004], lr: 0.010000, loss: 1.7385, stu_CELoss: 1.0359, DKDLoss: 0.7027, 
2022-07-29 20:49:54 - train: epoch 0056, iter [03800, 05004], lr: 0.010000, loss: 1.7837, stu_CELoss: 1.0596, DKDLoss: 0.7241, 
2022-07-29 20:50:29 - train: epoch 0056, iter [03900, 05004], lr: 0.010000, loss: 1.7747, stu_CELoss: 1.0192, DKDLoss: 0.7554, 
2022-07-29 20:51:02 - train: epoch 0056, iter [04000, 05004], lr: 0.010000, loss: 1.8598, stu_CELoss: 1.0488, DKDLoss: 0.8110, 
2022-07-29 20:51:36 - train: epoch 0056, iter [04100, 05004], lr: 0.010000, loss: 1.9368, stu_CELoss: 1.1726, DKDLoss: 0.7642, 
2022-07-29 20:52:10 - train: epoch 0056, iter [04200, 05004], lr: 0.010000, loss: 2.0356, stu_CELoss: 1.2398, DKDLoss: 0.7959, 
2022-07-29 20:52:44 - train: epoch 0056, iter [04300, 05004], lr: 0.010000, loss: 1.8171, stu_CELoss: 1.0566, DKDLoss: 0.7605, 
2022-07-29 20:53:18 - train: epoch 0056, iter [04400, 05004], lr: 0.010000, loss: 1.8280, stu_CELoss: 1.0976, DKDLoss: 0.7304, 
2022-07-29 20:53:52 - train: epoch 0056, iter [04500, 05004], lr: 0.010000, loss: 1.8443, stu_CELoss: 1.1019, DKDLoss: 0.7424, 
2022-07-29 20:54:26 - train: epoch 0056, iter [04600, 05004], lr: 0.010000, loss: 2.0133, stu_CELoss: 1.1999, DKDLoss: 0.8135, 
2022-07-29 20:54:59 - train: epoch 0056, iter [04700, 05004], lr: 0.010000, loss: 1.8470, stu_CELoss: 1.0774, DKDLoss: 0.7696, 
2022-07-29 20:55:33 - train: epoch 0056, iter [04800, 05004], lr: 0.010000, loss: 1.9700, stu_CELoss: 1.1913, DKDLoss: 0.7786, 
2022-07-29 20:56:07 - train: epoch 0056, iter [04900, 05004], lr: 0.010000, loss: 1.8273, stu_CELoss: 1.0117, DKDLoss: 0.8156, 
2022-07-29 20:56:40 - train: epoch 0056, iter [05000, 05004], lr: 0.010000, loss: 1.9990, stu_CELoss: 1.2702, DKDLoss: 0.7288, 
2022-07-29 20:56:42 - train: epoch 056, train_loss: 1.7898
2022-07-29 20:59:14 - eval: epoch: 056, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 72.954%, stu_acc5: 91.628%, stu_test_loss: 1.0667
2022-07-29 20:59:14 - until epoch: 056, tea_best_acc1: 78.068%, stu_best_acc1: 74.276%
2022-07-29 20:59:14 - epoch 057 lr: 0.010000
2022-07-29 20:59:54 - train: epoch 0057, iter [00100, 05004], lr: 0.010000, loss: 1.7019, stu_CELoss: 1.0113, DKDLoss: 0.6906, 
2022-07-29 21:00:27 - train: epoch 0057, iter [00200, 05004], lr: 0.010000, loss: 1.7807, stu_CELoss: 1.0110, DKDLoss: 0.7697, 
2022-07-29 21:01:00 - train: epoch 0057, iter [00300, 05004], lr: 0.010000, loss: 1.7382, stu_CELoss: 1.0063, DKDLoss: 0.7319, 
2022-07-29 21:01:34 - train: epoch 0057, iter [00400, 05004], lr: 0.010000, loss: 1.7815, stu_CELoss: 1.1244, DKDLoss: 0.6571, 
2022-07-29 21:02:07 - train: epoch 0057, iter [00500, 05004], lr: 0.010000, loss: 1.8429, stu_CELoss: 1.1692, DKDLoss: 0.6737, 
2022-07-29 21:02:41 - train: epoch 0057, iter [00600, 05004], lr: 0.010000, loss: 1.8756, stu_CELoss: 1.1629, DKDLoss: 0.7126, 
2022-07-29 21:03:14 - train: epoch 0057, iter [00700, 05004], lr: 0.010000, loss: 1.5043, stu_CELoss: 0.7882, DKDLoss: 0.7161, 
2022-07-29 21:03:48 - train: epoch 0057, iter [00800, 05004], lr: 0.010000, loss: 1.7910, stu_CELoss: 1.1393, DKDLoss: 0.6517, 
2022-07-29 21:04:21 - train: epoch 0057, iter [00900, 05004], lr: 0.010000, loss: 1.8258, stu_CELoss: 1.0453, DKDLoss: 0.7805, 
2022-07-29 21:04:55 - train: epoch 0057, iter [01000, 05004], lr: 0.010000, loss: 1.6853, stu_CELoss: 0.9330, DKDLoss: 0.7523, 
2022-07-29 21:05:29 - train: epoch 0057, iter [01100, 05004], lr: 0.010000, loss: 1.6374, stu_CELoss: 0.9315, DKDLoss: 0.7059, 
2022-07-29 21:06:03 - train: epoch 0057, iter [01200, 05004], lr: 0.010000, loss: 1.7811, stu_CELoss: 1.0591, DKDLoss: 0.7220, 
2022-07-29 21:06:37 - train: epoch 0057, iter [01300, 05004], lr: 0.010000, loss: 1.7391, stu_CELoss: 1.0512, DKDLoss: 0.6879, 
2022-07-29 21:07:10 - train: epoch 0057, iter [01400, 05004], lr: 0.010000, loss: 1.7691, stu_CELoss: 0.9579, DKDLoss: 0.8112, 
2022-07-29 21:07:43 - train: epoch 0057, iter [01500, 05004], lr: 0.010000, loss: 1.9012, stu_CELoss: 1.1280, DKDLoss: 0.7732, 
2022-07-29 21:08:17 - train: epoch 0057, iter [01600, 05004], lr: 0.010000, loss: 1.9190, stu_CELoss: 1.1972, DKDLoss: 0.7217, 
2022-07-29 21:08:50 - train: epoch 0057, iter [01700, 05004], lr: 0.010000, loss: 2.0621, stu_CELoss: 1.2540, DKDLoss: 0.8081, 
2022-07-29 21:09:24 - train: epoch 0057, iter [01800, 05004], lr: 0.010000, loss: 1.8966, stu_CELoss: 1.1661, DKDLoss: 0.7305, 
2022-07-29 21:09:57 - train: epoch 0057, iter [01900, 05004], lr: 0.010000, loss: 1.7621, stu_CELoss: 1.0166, DKDLoss: 0.7455, 
2022-07-29 21:10:31 - train: epoch 0057, iter [02000, 05004], lr: 0.010000, loss: 1.8525, stu_CELoss: 1.0927, DKDLoss: 0.7597, 
2022-07-29 21:11:04 - train: epoch 0057, iter [02100, 05004], lr: 0.010000, loss: 1.7503, stu_CELoss: 1.0578, DKDLoss: 0.6925, 
2022-07-29 21:11:37 - train: epoch 0057, iter [02200, 05004], lr: 0.010000, loss: 1.5756, stu_CELoss: 0.8530, DKDLoss: 0.7226, 
2022-07-29 21:12:11 - train: epoch 0057, iter [02300, 05004], lr: 0.010000, loss: 1.7920, stu_CELoss: 1.0144, DKDLoss: 0.7776, 
2022-07-29 21:12:44 - train: epoch 0057, iter [02400, 05004], lr: 0.010000, loss: 1.7828, stu_CELoss: 1.0261, DKDLoss: 0.7567, 
2022-07-29 21:13:18 - train: epoch 0057, iter [02500, 05004], lr: 0.010000, loss: 1.8566, stu_CELoss: 1.1280, DKDLoss: 0.7287, 
2022-07-29 21:13:51 - train: epoch 0057, iter [02600, 05004], lr: 0.010000, loss: 1.5744, stu_CELoss: 0.8731, DKDLoss: 0.7013, 
2022-07-29 21:14:24 - train: epoch 0057, iter [02700, 05004], lr: 0.010000, loss: 1.5845, stu_CELoss: 0.8595, DKDLoss: 0.7250, 
2022-07-29 21:14:58 - train: epoch 0057, iter [02800, 05004], lr: 0.010000, loss: 1.5873, stu_CELoss: 0.9127, DKDLoss: 0.6747, 
2022-07-29 21:15:31 - train: epoch 0057, iter [02900, 05004], lr: 0.010000, loss: 1.8706, stu_CELoss: 1.0965, DKDLoss: 0.7741, 
2022-07-29 21:16:05 - train: epoch 0057, iter [03000, 05004], lr: 0.010000, loss: 1.9172, stu_CELoss: 1.2041, DKDLoss: 0.7131, 
2022-07-29 21:16:38 - train: epoch 0057, iter [03100, 05004], lr: 0.010000, loss: 1.9585, stu_CELoss: 1.0482, DKDLoss: 0.9103, 
2022-07-29 21:17:11 - train: epoch 0057, iter [03200, 05004], lr: 0.010000, loss: 1.8482, stu_CELoss: 1.0771, DKDLoss: 0.7711, 
2022-07-29 21:17:44 - train: epoch 0057, iter [03300, 05004], lr: 0.010000, loss: 1.7618, stu_CELoss: 1.0096, DKDLoss: 0.7523, 
2022-07-29 21:18:18 - train: epoch 0057, iter [03400, 05004], lr: 0.010000, loss: 1.6016, stu_CELoss: 0.9117, DKDLoss: 0.6899, 
2022-07-29 21:18:51 - train: epoch 0057, iter [03500, 05004], lr: 0.010000, loss: 1.8046, stu_CELoss: 1.0420, DKDLoss: 0.7627, 
2022-07-29 21:19:25 - train: epoch 0057, iter [03600, 05004], lr: 0.010000, loss: 1.7995, stu_CELoss: 1.1016, DKDLoss: 0.6980, 
2022-07-29 21:19:59 - train: epoch 0057, iter [03700, 05004], lr: 0.010000, loss: 1.6198, stu_CELoss: 0.9688, DKDLoss: 0.6510, 
2022-07-29 21:20:32 - train: epoch 0057, iter [03800, 05004], lr: 0.010000, loss: 1.7384, stu_CELoss: 0.9940, DKDLoss: 0.7443, 
2022-07-29 21:21:06 - train: epoch 0057, iter [03900, 05004], lr: 0.010000, loss: 1.9506, stu_CELoss: 1.1745, DKDLoss: 0.7761, 
2022-07-29 21:21:39 - train: epoch 0057, iter [04000, 05004], lr: 0.010000, loss: 1.7794, stu_CELoss: 1.0283, DKDLoss: 0.7511, 
2022-07-29 21:22:13 - train: epoch 0057, iter [04100, 05004], lr: 0.010000, loss: 1.6813, stu_CELoss: 0.9471, DKDLoss: 0.7342, 
2022-07-29 21:22:47 - train: epoch 0057, iter [04200, 05004], lr: 0.010000, loss: 1.7178, stu_CELoss: 1.0102, DKDLoss: 0.7076, 
2022-07-29 21:23:20 - train: epoch 0057, iter [04300, 05004], lr: 0.010000, loss: 1.4840, stu_CELoss: 0.8033, DKDLoss: 0.6806, 
2022-07-29 21:23:55 - train: epoch 0057, iter [04400, 05004], lr: 0.010000, loss: 1.8511, stu_CELoss: 1.1306, DKDLoss: 0.7206, 
2022-07-29 21:24:28 - train: epoch 0057, iter [04500, 05004], lr: 0.010000, loss: 1.8827, stu_CELoss: 1.0774, DKDLoss: 0.8053, 
2022-07-29 21:25:02 - train: epoch 0057, iter [04600, 05004], lr: 0.010000, loss: 1.8720, stu_CELoss: 1.1169, DKDLoss: 0.7551, 
2022-07-29 21:25:35 - train: epoch 0057, iter [04700, 05004], lr: 0.010000, loss: 1.6299, stu_CELoss: 0.9882, DKDLoss: 0.6418, 
2022-07-29 21:26:09 - train: epoch 0057, iter [04800, 05004], lr: 0.010000, loss: 2.0595, stu_CELoss: 1.1841, DKDLoss: 0.8754, 
2022-07-29 21:26:42 - train: epoch 0057, iter [04900, 05004], lr: 0.010000, loss: 1.9461, stu_CELoss: 1.2443, DKDLoss: 0.7018, 
2022-07-29 21:27:15 - train: epoch 0057, iter [05000, 05004], lr: 0.010000, loss: 1.8516, stu_CELoss: 1.0877, DKDLoss: 0.7639, 
2022-07-29 21:27:17 - train: epoch 057, train_loss: 1.7871
2022-07-29 21:29:50 - eval: epoch: 057, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 73.258%, stu_acc5: 91.490%, stu_test_loss: 1.0699
2022-07-29 21:29:50 - until epoch: 057, tea_best_acc1: 78.068%, stu_best_acc1: 74.276%
2022-07-29 21:29:50 - epoch 058 lr: 0.010000
2022-07-29 21:30:30 - train: epoch 0058, iter [00100, 05004], lr: 0.010000, loss: 1.7695, stu_CELoss: 1.0556, DKDLoss: 0.7139, 
2022-07-29 21:31:04 - train: epoch 0058, iter [00200, 05004], lr: 0.010000, loss: 1.6107, stu_CELoss: 0.8631, DKDLoss: 0.7476, 
2022-07-29 21:31:37 - train: epoch 0058, iter [00300, 05004], lr: 0.010000, loss: 1.8419, stu_CELoss: 1.1439, DKDLoss: 0.6979, 
2022-07-29 21:32:11 - train: epoch 0058, iter [00400, 05004], lr: 0.010000, loss: 1.8711, stu_CELoss: 1.1498, DKDLoss: 0.7213, 
2022-07-29 21:32:45 - train: epoch 0058, iter [00500, 05004], lr: 0.010000, loss: 1.4384, stu_CELoss: 0.8206, DKDLoss: 0.6179, 
2022-07-29 21:33:19 - train: epoch 0058, iter [00600, 05004], lr: 0.010000, loss: 1.9026, stu_CELoss: 1.1243, DKDLoss: 0.7783, 
2022-07-29 21:33:53 - train: epoch 0058, iter [00700, 05004], lr: 0.010000, loss: 1.7238, stu_CELoss: 1.0240, DKDLoss: 0.6998, 
2022-07-29 21:34:27 - train: epoch 0058, iter [00800, 05004], lr: 0.010000, loss: 1.6746, stu_CELoss: 1.0173, DKDLoss: 0.6573, 
2022-07-29 21:35:01 - train: epoch 0058, iter [00900, 05004], lr: 0.010000, loss: 1.5966, stu_CELoss: 0.9374, DKDLoss: 0.6592, 
2022-07-29 21:35:34 - train: epoch 0058, iter [01000, 05004], lr: 0.010000, loss: 1.7334, stu_CELoss: 1.0542, DKDLoss: 0.6793, 
2022-07-29 21:36:08 - train: epoch 0058, iter [01100, 05004], lr: 0.010000, loss: 1.5931, stu_CELoss: 0.9472, DKDLoss: 0.6460, 
2022-07-29 21:36:42 - train: epoch 0058, iter [01200, 05004], lr: 0.010000, loss: 1.9128, stu_CELoss: 1.1618, DKDLoss: 0.7511, 
2022-07-29 21:37:15 - train: epoch 0058, iter [01300, 05004], lr: 0.010000, loss: 1.9136, stu_CELoss: 1.1272, DKDLoss: 0.7864, 
2022-07-29 21:37:49 - train: epoch 0058, iter [01400, 05004], lr: 0.010000, loss: 1.7847, stu_CELoss: 1.0263, DKDLoss: 0.7584, 
2022-07-29 21:38:23 - train: epoch 0058, iter [01500, 05004], lr: 0.010000, loss: 1.5673, stu_CELoss: 0.8811, DKDLoss: 0.6862, 
2022-07-29 21:38:57 - train: epoch 0058, iter [01600, 05004], lr: 0.010000, loss: 1.8227, stu_CELoss: 1.1037, DKDLoss: 0.7190, 
2022-07-29 21:39:30 - train: epoch 0058, iter [01700, 05004], lr: 0.010000, loss: 1.6413, stu_CELoss: 0.9860, DKDLoss: 0.6553, 
2022-07-29 21:40:04 - train: epoch 0058, iter [01800, 05004], lr: 0.010000, loss: 1.9885, stu_CELoss: 1.2583, DKDLoss: 0.7302, 
2022-07-29 21:40:38 - train: epoch 0058, iter [01900, 05004], lr: 0.010000, loss: 1.9183, stu_CELoss: 1.1324, DKDLoss: 0.7859, 
2022-07-29 21:41:12 - train: epoch 0058, iter [02000, 05004], lr: 0.010000, loss: 1.9181, stu_CELoss: 1.1078, DKDLoss: 0.8103, 
2022-07-29 21:41:46 - train: epoch 0058, iter [02100, 05004], lr: 0.010000, loss: 1.6262, stu_CELoss: 0.9141, DKDLoss: 0.7121, 
2022-07-29 21:42:20 - train: epoch 0058, iter [02200, 05004], lr: 0.010000, loss: 1.7795, stu_CELoss: 1.0302, DKDLoss: 0.7494, 
2022-07-29 21:42:54 - train: epoch 0058, iter [02300, 05004], lr: 0.010000, loss: 1.9341, stu_CELoss: 1.1492, DKDLoss: 0.7849, 
2022-07-29 21:43:27 - train: epoch 0058, iter [02400, 05004], lr: 0.010000, loss: 1.8156, stu_CELoss: 1.0021, DKDLoss: 0.8135, 
2022-07-29 21:44:01 - train: epoch 0058, iter [02500, 05004], lr: 0.010000, loss: 1.7641, stu_CELoss: 1.0629, DKDLoss: 0.7012, 
2022-07-29 21:44:34 - train: epoch 0058, iter [02600, 05004], lr: 0.010000, loss: 1.5065, stu_CELoss: 0.8429, DKDLoss: 0.6636, 
2022-07-29 21:45:08 - train: epoch 0058, iter [02700, 05004], lr: 0.010000, loss: 1.9419, stu_CELoss: 1.1065, DKDLoss: 0.8355, 
2022-07-29 21:45:42 - train: epoch 0058, iter [02800, 05004], lr: 0.010000, loss: 1.6378, stu_CELoss: 0.9063, DKDLoss: 0.7315, 
2022-07-29 21:46:16 - train: epoch 0058, iter [02900, 05004], lr: 0.010000, loss: 1.8681, stu_CELoss: 1.1013, DKDLoss: 0.7667, 
2022-07-29 21:46:50 - train: epoch 0058, iter [03000, 05004], lr: 0.010000, loss: 1.9622, stu_CELoss: 1.1034, DKDLoss: 0.8588, 
2022-07-29 21:47:23 - train: epoch 0058, iter [03100, 05004], lr: 0.010000, loss: 1.7347, stu_CELoss: 1.0054, DKDLoss: 0.7293, 
2022-07-29 21:47:57 - train: epoch 0058, iter [03200, 05004], lr: 0.010000, loss: 1.5928, stu_CELoss: 0.9246, DKDLoss: 0.6682, 
2022-07-29 21:48:31 - train: epoch 0058, iter [03300, 05004], lr: 0.010000, loss: 1.7305, stu_CELoss: 1.0433, DKDLoss: 0.6872, 
2022-07-29 21:49:05 - train: epoch 0058, iter [03400, 05004], lr: 0.010000, loss: 1.8183, stu_CELoss: 1.0738, DKDLoss: 0.7445, 
2022-07-29 21:49:39 - train: epoch 0058, iter [03500, 05004], lr: 0.010000, loss: 1.7500, stu_CELoss: 0.9572, DKDLoss: 0.7928, 
2022-07-29 21:50:13 - train: epoch 0058, iter [03600, 05004], lr: 0.010000, loss: 1.9774, stu_CELoss: 1.1691, DKDLoss: 0.8083, 
2022-07-29 21:50:47 - train: epoch 0058, iter [03700, 05004], lr: 0.010000, loss: 1.8046, stu_CELoss: 1.1094, DKDLoss: 0.6952, 
2022-07-29 21:51:21 - train: epoch 0058, iter [03800, 05004], lr: 0.010000, loss: 1.9273, stu_CELoss: 1.0874, DKDLoss: 0.8399, 
2022-07-29 21:51:55 - train: epoch 0058, iter [03900, 05004], lr: 0.010000, loss: 1.7784, stu_CELoss: 1.0530, DKDLoss: 0.7254, 
2022-07-29 21:52:29 - train: epoch 0058, iter [04000, 05004], lr: 0.010000, loss: 1.5807, stu_CELoss: 0.8635, DKDLoss: 0.7173, 
2022-07-29 21:53:03 - train: epoch 0058, iter [04100, 05004], lr: 0.010000, loss: 1.6979, stu_CELoss: 0.9966, DKDLoss: 0.7013, 
2022-07-29 21:53:37 - train: epoch 0058, iter [04200, 05004], lr: 0.010000, loss: 1.7174, stu_CELoss: 1.0052, DKDLoss: 0.7122, 
2022-07-29 21:54:11 - train: epoch 0058, iter [04300, 05004], lr: 0.010000, loss: 1.8547, stu_CELoss: 1.0454, DKDLoss: 0.8093, 
2022-07-29 21:54:44 - train: epoch 0058, iter [04400, 05004], lr: 0.010000, loss: 1.5255, stu_CELoss: 0.8480, DKDLoss: 0.6775, 
2022-07-29 21:55:18 - train: epoch 0058, iter [04500, 05004], lr: 0.010000, loss: 1.8569, stu_CELoss: 1.1202, DKDLoss: 0.7367, 
2022-07-29 21:55:52 - train: epoch 0058, iter [04600, 05004], lr: 0.010000, loss: 1.6185, stu_CELoss: 0.8795, DKDLoss: 0.7391, 
2022-07-29 21:56:26 - train: epoch 0058, iter [04700, 05004], lr: 0.010000, loss: 1.7760, stu_CELoss: 1.0476, DKDLoss: 0.7284, 
2022-07-29 21:56:59 - train: epoch 0058, iter [04800, 05004], lr: 0.010000, loss: 1.8224, stu_CELoss: 1.0575, DKDLoss: 0.7648, 
2022-07-29 21:57:33 - train: epoch 0058, iter [04900, 05004], lr: 0.010000, loss: 1.6327, stu_CELoss: 0.9230, DKDLoss: 0.7097, 
2022-07-29 21:58:07 - train: epoch 0058, iter [05000, 05004], lr: 0.010000, loss: 1.6618, stu_CELoss: 0.9372, DKDLoss: 0.7247, 
2022-07-29 21:58:08 - train: epoch 058, train_loss: 1.7805
2022-07-29 22:00:40 - eval: epoch: 058, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 73.358%, stu_acc5: 91.654%, stu_test_loss: 1.0624
2022-07-29 22:00:41 - until epoch: 058, tea_best_acc1: 78.068%, stu_best_acc1: 74.276%
2022-07-29 22:00:41 - epoch 059 lr: 0.010000
2022-07-29 22:01:21 - train: epoch 0059, iter [00100, 05004], lr: 0.010000, loss: 1.6419, stu_CELoss: 0.9415, DKDLoss: 0.7004, 
2022-07-29 22:01:54 - train: epoch 0059, iter [00200, 05004], lr: 0.010000, loss: 1.7836, stu_CELoss: 1.0355, DKDLoss: 0.7481, 
2022-07-29 22:02:27 - train: epoch 0059, iter [00300, 05004], lr: 0.010000, loss: 1.4642, stu_CELoss: 0.8517, DKDLoss: 0.6125, 
2022-07-29 22:03:01 - train: epoch 0059, iter [00400, 05004], lr: 0.010000, loss: 1.8118, stu_CELoss: 1.1144, DKDLoss: 0.6974, 
2022-07-29 22:03:34 - train: epoch 0059, iter [00500, 05004], lr: 0.010000, loss: 1.8543, stu_CELoss: 1.1259, DKDLoss: 0.7284, 
2022-07-29 22:04:08 - train: epoch 0059, iter [00600, 05004], lr: 0.010000, loss: 1.5326, stu_CELoss: 0.7991, DKDLoss: 0.7335, 
2022-07-29 22:04:41 - train: epoch 0059, iter [00700, 05004], lr: 0.010000, loss: 1.6171, stu_CELoss: 0.9196, DKDLoss: 0.6975, 
2022-07-29 22:05:15 - train: epoch 0059, iter [00800, 05004], lr: 0.010000, loss: 1.7448, stu_CELoss: 1.0422, DKDLoss: 0.7026, 
2022-07-29 22:05:49 - train: epoch 0059, iter [00900, 05004], lr: 0.010000, loss: 1.6531, stu_CELoss: 0.8953, DKDLoss: 0.7578, 
2022-07-29 22:06:23 - train: epoch 0059, iter [01000, 05004], lr: 0.010000, loss: 1.8848, stu_CELoss: 1.1101, DKDLoss: 0.7748, 
2022-07-29 22:06:57 - train: epoch 0059, iter [01100, 05004], lr: 0.010000, loss: 1.9257, stu_CELoss: 1.1411, DKDLoss: 0.7846, 
2022-07-29 22:07:30 - train: epoch 0059, iter [01200, 05004], lr: 0.010000, loss: 1.7161, stu_CELoss: 1.0492, DKDLoss: 0.6669, 
2022-07-29 22:08:04 - train: epoch 0059, iter [01300, 05004], lr: 0.010000, loss: 1.9531, stu_CELoss: 1.1372, DKDLoss: 0.8159, 
2022-07-29 22:08:38 - train: epoch 0059, iter [01400, 05004], lr: 0.010000, loss: 1.9135, stu_CELoss: 1.1039, DKDLoss: 0.8096, 
2022-07-29 22:09:12 - train: epoch 0059, iter [01500, 05004], lr: 0.010000, loss: 1.6486, stu_CELoss: 0.9547, DKDLoss: 0.6939, 
2022-07-29 22:09:46 - train: epoch 0059, iter [01600, 05004], lr: 0.010000, loss: 1.8292, stu_CELoss: 1.1008, DKDLoss: 0.7284, 
2022-07-29 22:10:20 - train: epoch 0059, iter [01700, 05004], lr: 0.010000, loss: 1.6739, stu_CELoss: 0.9650, DKDLoss: 0.7090, 
2022-07-29 22:10:54 - train: epoch 0059, iter [01800, 05004], lr: 0.010000, loss: 1.5774, stu_CELoss: 0.8850, DKDLoss: 0.6924, 
2022-07-29 22:11:28 - train: epoch 0059, iter [01900, 05004], lr: 0.010000, loss: 1.6514, stu_CELoss: 0.9693, DKDLoss: 0.6821, 
2022-07-29 22:12:01 - train: epoch 0059, iter [02000, 05004], lr: 0.010000, loss: 1.5674, stu_CELoss: 0.8452, DKDLoss: 0.7222, 
2022-07-29 22:12:35 - train: epoch 0059, iter [02100, 05004], lr: 0.010000, loss: 1.8044, stu_CELoss: 1.0821, DKDLoss: 0.7222, 
2022-07-29 22:13:09 - train: epoch 0059, iter [02200, 05004], lr: 0.010000, loss: 1.8848, stu_CELoss: 1.0183, DKDLoss: 0.8665, 
2022-07-29 22:13:43 - train: epoch 0059, iter [02300, 05004], lr: 0.010000, loss: 1.8219, stu_CELoss: 1.1019, DKDLoss: 0.7200, 
2022-07-29 22:14:17 - train: epoch 0059, iter [02400, 05004], lr: 0.010000, loss: 2.0151, stu_CELoss: 1.2402, DKDLoss: 0.7749, 
2022-07-29 22:14:51 - train: epoch 0059, iter [02500, 05004], lr: 0.010000, loss: 2.0030, stu_CELoss: 1.1902, DKDLoss: 0.8128, 
2022-07-29 22:15:24 - train: epoch 0059, iter [02600, 05004], lr: 0.010000, loss: 1.8673, stu_CELoss: 1.1561, DKDLoss: 0.7112, 
2022-07-29 22:15:58 - train: epoch 0059, iter [02700, 05004], lr: 0.010000, loss: 1.6031, stu_CELoss: 0.8975, DKDLoss: 0.7056, 
2022-07-29 22:16:32 - train: epoch 0059, iter [02800, 05004], lr: 0.010000, loss: 2.0037, stu_CELoss: 1.2099, DKDLoss: 0.7939, 
2022-07-29 22:17:06 - train: epoch 0059, iter [02900, 05004], lr: 0.010000, loss: 1.6478, stu_CELoss: 0.9022, DKDLoss: 0.7456, 
2022-07-29 22:17:40 - train: epoch 0059, iter [03000, 05004], lr: 0.010000, loss: 2.0424, stu_CELoss: 1.2640, DKDLoss: 0.7784, 
2022-07-29 22:18:14 - train: epoch 0059, iter [03100, 05004], lr: 0.010000, loss: 1.7383, stu_CELoss: 0.9848, DKDLoss: 0.7536, 
2022-07-29 22:18:48 - train: epoch 0059, iter [03200, 05004], lr: 0.010000, loss: 1.8501, stu_CELoss: 1.1690, DKDLoss: 0.6810, 
2022-07-29 22:19:22 - train: epoch 0059, iter [03300, 05004], lr: 0.010000, loss: 1.7820, stu_CELoss: 1.0513, DKDLoss: 0.7307, 
2022-07-29 22:19:56 - train: epoch 0059, iter [03400, 05004], lr: 0.010000, loss: 2.0462, stu_CELoss: 1.2105, DKDLoss: 0.8357, 
2022-07-29 22:20:30 - train: epoch 0059, iter [03500, 05004], lr: 0.010000, loss: 1.8730, stu_CELoss: 1.1067, DKDLoss: 0.7663, 
2022-07-29 22:21:04 - train: epoch 0059, iter [03600, 05004], lr: 0.010000, loss: 1.6082, stu_CELoss: 0.9477, DKDLoss: 0.6605, 
2022-07-29 22:21:38 - train: epoch 0059, iter [03700, 05004], lr: 0.010000, loss: 1.7428, stu_CELoss: 0.9598, DKDLoss: 0.7829, 
2022-07-29 22:22:12 - train: epoch 0059, iter [03800, 05004], lr: 0.010000, loss: 1.6955, stu_CELoss: 0.9427, DKDLoss: 0.7528, 
2022-07-29 22:22:46 - train: epoch 0059, iter [03900, 05004], lr: 0.010000, loss: 1.4576, stu_CELoss: 0.8400, DKDLoss: 0.6176, 
2022-07-29 22:23:20 - train: epoch 0059, iter [04000, 05004], lr: 0.010000, loss: 1.8752, stu_CELoss: 1.0866, DKDLoss: 0.7886, 
2022-07-29 22:23:54 - train: epoch 0059, iter [04100, 05004], lr: 0.010000, loss: 1.7682, stu_CELoss: 1.0555, DKDLoss: 0.7127, 
2022-07-29 22:24:27 - train: epoch 0059, iter [04200, 05004], lr: 0.010000, loss: 1.7860, stu_CELoss: 1.1102, DKDLoss: 0.6758, 
2022-07-29 22:25:02 - train: epoch 0059, iter [04300, 05004], lr: 0.010000, loss: 1.9921, stu_CELoss: 1.2415, DKDLoss: 0.7506, 
2022-07-29 22:25:36 - train: epoch 0059, iter [04400, 05004], lr: 0.010000, loss: 1.7480, stu_CELoss: 1.0771, DKDLoss: 0.6709, 
2022-07-29 22:26:09 - train: epoch 0059, iter [04500, 05004], lr: 0.010000, loss: 1.8336, stu_CELoss: 0.9916, DKDLoss: 0.8420, 
2022-07-29 22:26:44 - train: epoch 0059, iter [04600, 05004], lr: 0.010000, loss: 2.1765, stu_CELoss: 1.3503, DKDLoss: 0.8262, 
2022-07-29 22:27:18 - train: epoch 0059, iter [04700, 05004], lr: 0.010000, loss: 1.7694, stu_CELoss: 0.9974, DKDLoss: 0.7720, 
2022-07-29 22:27:52 - train: epoch 0059, iter [04800, 05004], lr: 0.010000, loss: 1.5936, stu_CELoss: 0.8993, DKDLoss: 0.6942, 
2022-07-29 22:28:26 - train: epoch 0059, iter [04900, 05004], lr: 0.010000, loss: 1.9336, stu_CELoss: 1.1581, DKDLoss: 0.7754, 
2022-07-29 22:28:59 - train: epoch 0059, iter [05000, 05004], lr: 0.010000, loss: 1.9788, stu_CELoss: 1.1847, DKDLoss: 0.7941, 
2022-07-29 22:29:01 - train: epoch 059, train_loss: 1.7792
2022-07-29 22:31:33 - eval: epoch: 059, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 72.556%, stu_acc5: 91.282%, stu_test_loss: 1.0882
2022-07-29 22:31:33 - until epoch: 059, tea_best_acc1: 78.068%, stu_best_acc1: 74.276%
2022-07-29 22:31:33 - epoch 060 lr: 0.010000
2022-07-29 22:32:14 - train: epoch 0060, iter [00100, 05004], lr: 0.010000, loss: 1.7217, stu_CELoss: 1.0706, DKDLoss: 0.6511, 
2022-07-29 22:32:46 - train: epoch 0060, iter [00200, 05004], lr: 0.010000, loss: 1.7100, stu_CELoss: 0.9275, DKDLoss: 0.7825, 
2022-07-29 22:33:19 - train: epoch 0060, iter [00300, 05004], lr: 0.010000, loss: 1.5651, stu_CELoss: 0.8229, DKDLoss: 0.7422, 
2022-07-29 22:33:52 - train: epoch 0060, iter [00400, 05004], lr: 0.010000, loss: 1.8287, stu_CELoss: 1.1003, DKDLoss: 0.7284, 
2022-07-29 22:34:26 - train: epoch 0060, iter [00500, 05004], lr: 0.010000, loss: 2.0286, stu_CELoss: 1.2527, DKDLoss: 0.7759, 
2022-07-29 22:34:59 - train: epoch 0060, iter [00600, 05004], lr: 0.010000, loss: 1.7065, stu_CELoss: 0.9901, DKDLoss: 0.7164, 
2022-07-29 22:35:33 - train: epoch 0060, iter [00700, 05004], lr: 0.010000, loss: 1.9057, stu_CELoss: 1.1227, DKDLoss: 0.7830, 
2022-07-29 22:36:06 - train: epoch 0060, iter [00800, 05004], lr: 0.010000, loss: 1.8533, stu_CELoss: 1.0874, DKDLoss: 0.7659, 
2022-07-29 22:36:40 - train: epoch 0060, iter [00900, 05004], lr: 0.010000, loss: 1.7454, stu_CELoss: 1.0942, DKDLoss: 0.6512, 
2022-07-29 22:37:14 - train: epoch 0060, iter [01000, 05004], lr: 0.010000, loss: 1.4202, stu_CELoss: 0.7665, DKDLoss: 0.6538, 
2022-07-29 22:37:47 - train: epoch 0060, iter [01100, 05004], lr: 0.010000, loss: 1.7012, stu_CELoss: 1.0480, DKDLoss: 0.6532, 
2022-07-29 22:38:22 - train: epoch 0060, iter [01200, 05004], lr: 0.010000, loss: 1.5817, stu_CELoss: 0.8657, DKDLoss: 0.7160, 
2022-07-29 22:38:55 - train: epoch 0060, iter [01300, 05004], lr: 0.010000, loss: 1.7787, stu_CELoss: 1.0231, DKDLoss: 0.7556, 
2022-07-29 22:39:29 - train: epoch 0060, iter [01400, 05004], lr: 0.010000, loss: 1.6315, stu_CELoss: 0.9618, DKDLoss: 0.6697, 
2022-07-29 22:40:03 - train: epoch 0060, iter [01500, 05004], lr: 0.010000, loss: 1.7778, stu_CELoss: 1.0635, DKDLoss: 0.7143, 
2022-07-29 22:40:37 - train: epoch 0060, iter [01600, 05004], lr: 0.010000, loss: 1.9113, stu_CELoss: 1.0985, DKDLoss: 0.8128, 
2022-07-29 22:41:11 - train: epoch 0060, iter [01700, 05004], lr: 0.010000, loss: 1.7827, stu_CELoss: 0.9837, DKDLoss: 0.7990, 
2022-07-29 22:41:46 - train: epoch 0060, iter [01800, 05004], lr: 0.010000, loss: 1.9809, stu_CELoss: 1.1561, DKDLoss: 0.8247, 
2022-07-29 22:42:20 - train: epoch 0060, iter [01900, 05004], lr: 0.010000, loss: 1.9831, stu_CELoss: 1.1758, DKDLoss: 0.8073, 
2022-07-29 22:42:54 - train: epoch 0060, iter [02000, 05004], lr: 0.010000, loss: 1.7824, stu_CELoss: 1.1388, DKDLoss: 0.6436, 
2022-07-29 22:43:27 - train: epoch 0060, iter [02100, 05004], lr: 0.010000, loss: 1.8068, stu_CELoss: 1.0068, DKDLoss: 0.8000, 
2022-07-29 22:44:01 - train: epoch 0060, iter [02200, 05004], lr: 0.010000, loss: 1.9732, stu_CELoss: 1.1113, DKDLoss: 0.8620, 
2022-07-29 22:44:35 - train: epoch 0060, iter [02300, 05004], lr: 0.010000, loss: 1.6700, stu_CELoss: 0.9377, DKDLoss: 0.7323, 
2022-07-29 22:45:09 - train: epoch 0060, iter [02400, 05004], lr: 0.010000, loss: 1.7644, stu_CELoss: 0.9940, DKDLoss: 0.7705, 
2022-07-29 22:45:43 - train: epoch 0060, iter [02500, 05004], lr: 0.010000, loss: 1.8282, stu_CELoss: 1.0644, DKDLoss: 0.7639, 
2022-07-29 22:46:16 - train: epoch 0060, iter [02600, 05004], lr: 0.010000, loss: 1.9044, stu_CELoss: 1.1347, DKDLoss: 0.7697, 
2022-07-29 22:46:50 - train: epoch 0060, iter [02700, 05004], lr: 0.010000, loss: 1.8178, stu_CELoss: 1.1439, DKDLoss: 0.6739, 
2022-07-29 22:47:24 - train: epoch 0060, iter [02800, 05004], lr: 0.010000, loss: 1.9307, stu_CELoss: 1.2232, DKDLoss: 0.7075, 
2022-07-29 22:47:58 - train: epoch 0060, iter [02900, 05004], lr: 0.010000, loss: 1.8383, stu_CELoss: 1.0755, DKDLoss: 0.7628, 
2022-07-29 22:48:32 - train: epoch 0060, iter [03000, 05004], lr: 0.010000, loss: 1.8273, stu_CELoss: 1.0994, DKDLoss: 0.7279, 
2022-07-29 22:49:05 - train: epoch 0060, iter [03100, 05004], lr: 0.010000, loss: 2.0113, stu_CELoss: 1.2320, DKDLoss: 0.7792, 
2022-07-29 22:49:39 - train: epoch 0060, iter [03200, 05004], lr: 0.010000, loss: 1.8967, stu_CELoss: 1.1424, DKDLoss: 0.7544, 
2022-07-29 22:50:13 - train: epoch 0060, iter [03300, 05004], lr: 0.010000, loss: 1.5102, stu_CELoss: 0.8842, DKDLoss: 0.6261, 
2022-07-29 22:50:46 - train: epoch 0060, iter [03400, 05004], lr: 0.010000, loss: 1.9027, stu_CELoss: 1.1047, DKDLoss: 0.7980, 
2022-07-29 22:51:20 - train: epoch 0060, iter [03500, 05004], lr: 0.010000, loss: 1.9550, stu_CELoss: 1.1976, DKDLoss: 0.7574, 
2022-07-29 22:51:54 - train: epoch 0060, iter [03600, 05004], lr: 0.010000, loss: 1.8512, stu_CELoss: 1.1185, DKDLoss: 0.7327, 
2022-07-29 22:52:28 - train: epoch 0060, iter [03700, 05004], lr: 0.010000, loss: 1.7012, stu_CELoss: 1.0425, DKDLoss: 0.6587, 
2022-07-29 22:53:02 - train: epoch 0060, iter [03800, 05004], lr: 0.010000, loss: 1.8952, stu_CELoss: 1.1540, DKDLoss: 0.7412, 
2022-07-29 22:53:36 - train: epoch 0060, iter [03900, 05004], lr: 0.010000, loss: 1.8531, stu_CELoss: 1.0844, DKDLoss: 0.7687, 
2022-07-29 22:54:10 - train: epoch 0060, iter [04000, 05004], lr: 0.010000, loss: 1.7667, stu_CELoss: 0.9721, DKDLoss: 0.7946, 
2022-07-29 22:54:43 - train: epoch 0060, iter [04100, 05004], lr: 0.010000, loss: 2.0428, stu_CELoss: 1.3173, DKDLoss: 0.7255, 
2022-07-29 22:55:18 - train: epoch 0060, iter [04200, 05004], lr: 0.010000, loss: 2.0961, stu_CELoss: 1.2958, DKDLoss: 0.8003, 
2022-07-29 22:55:52 - train: epoch 0060, iter [04300, 05004], lr: 0.010000, loss: 1.6529, stu_CELoss: 0.9427, DKDLoss: 0.7102, 
2022-07-29 22:56:26 - train: epoch 0060, iter [04400, 05004], lr: 0.010000, loss: 2.0019, stu_CELoss: 1.2056, DKDLoss: 0.7963, 
2022-07-29 22:57:00 - train: epoch 0060, iter [04500, 05004], lr: 0.010000, loss: 1.8802, stu_CELoss: 1.1546, DKDLoss: 0.7256, 
2022-07-29 22:57:34 - train: epoch 0060, iter [04600, 05004], lr: 0.010000, loss: 1.7685, stu_CELoss: 1.0211, DKDLoss: 0.7474, 
2022-07-29 22:58:08 - train: epoch 0060, iter [04700, 05004], lr: 0.010000, loss: 1.7671, stu_CELoss: 0.9849, DKDLoss: 0.7822, 
2022-07-29 22:58:42 - train: epoch 0060, iter [04800, 05004], lr: 0.010000, loss: 1.7402, stu_CELoss: 0.9699, DKDLoss: 0.7703, 
2022-07-29 22:59:16 - train: epoch 0060, iter [04900, 05004], lr: 0.010000, loss: 1.8297, stu_CELoss: 1.0157, DKDLoss: 0.8140, 
2022-07-29 22:59:50 - train: epoch 0060, iter [05000, 05004], lr: 0.010000, loss: 1.8374, stu_CELoss: 1.1489, DKDLoss: 0.6885, 
2022-07-29 22:59:51 - train: epoch 060, train_loss: 1.7718
2022-07-29 23:02:23 - eval: epoch: 060, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 73.576%, stu_acc5: 91.924%, stu_test_loss: 1.0436
2022-07-29 23:02:24 - until epoch: 060, tea_best_acc1: 78.068%, stu_best_acc1: 74.276%
2022-07-29 23:02:24 - epoch 061 lr: 0.001000
2022-07-29 23:03:04 - train: epoch 0061, iter [00100, 05004], lr: 0.001000, loss: 1.5426, stu_CELoss: 0.9386, DKDLoss: 0.6040, 
2022-07-29 23:03:37 - train: epoch 0061, iter [00200, 05004], lr: 0.001000, loss: 1.7167, stu_CELoss: 1.0036, DKDLoss: 0.7130, 
2022-07-29 23:04:11 - train: epoch 0061, iter [00300, 05004], lr: 0.001000, loss: 1.2762, stu_CELoss: 0.7141, DKDLoss: 0.5621, 
2022-07-29 23:04:44 - train: epoch 0061, iter [00400, 05004], lr: 0.001000, loss: 1.6956, stu_CELoss: 0.9876, DKDLoss: 0.7080, 
2022-07-29 23:05:18 - train: epoch 0061, iter [00500, 05004], lr: 0.001000, loss: 1.5810, stu_CELoss: 0.9980, DKDLoss: 0.5830, 
2022-07-29 23:05:51 - train: epoch 0061, iter [00600, 05004], lr: 0.001000, loss: 1.4677, stu_CELoss: 0.8814, DKDLoss: 0.5864, 
2022-07-29 23:06:25 - train: epoch 0061, iter [00700, 05004], lr: 0.001000, loss: 1.5598, stu_CELoss: 0.9496, DKDLoss: 0.6102, 
2022-07-29 23:06:59 - train: epoch 0061, iter [00800, 05004], lr: 0.001000, loss: 1.4028, stu_CELoss: 0.8566, DKDLoss: 0.5462, 
2022-07-29 23:07:33 - train: epoch 0061, iter [00900, 05004], lr: 0.001000, loss: 1.6292, stu_CELoss: 0.9536, DKDLoss: 0.6756, 
2022-07-29 23:08:07 - train: epoch 0061, iter [01000, 05004], lr: 0.001000, loss: 1.4180, stu_CELoss: 0.8132, DKDLoss: 0.6048, 
2022-07-29 23:08:41 - train: epoch 0061, iter [01100, 05004], lr: 0.001000, loss: 1.4146, stu_CELoss: 0.8247, DKDLoss: 0.5899, 
2022-07-29 23:09:14 - train: epoch 0061, iter [01200, 05004], lr: 0.001000, loss: 1.3909, stu_CELoss: 0.8585, DKDLoss: 0.5324, 
2022-07-29 23:09:48 - train: epoch 0061, iter [01300, 05004], lr: 0.001000, loss: 1.5654, stu_CELoss: 1.0204, DKDLoss: 0.5449, 
2022-07-29 23:10:22 - train: epoch 0061, iter [01400, 05004], lr: 0.001000, loss: 1.2389, stu_CELoss: 0.7095, DKDLoss: 0.5294, 
2022-07-29 23:10:56 - train: epoch 0061, iter [01500, 05004], lr: 0.001000, loss: 1.4735, stu_CELoss: 0.9254, DKDLoss: 0.5481, 
2022-07-29 23:11:30 - train: epoch 0061, iter [01600, 05004], lr: 0.001000, loss: 1.2334, stu_CELoss: 0.7318, DKDLoss: 0.5016, 
2022-07-29 23:12:03 - train: epoch 0061, iter [01700, 05004], lr: 0.001000, loss: 1.3928, stu_CELoss: 0.8700, DKDLoss: 0.5228, 
2022-07-29 23:12:37 - train: epoch 0061, iter [01800, 05004], lr: 0.001000, loss: 1.4252, stu_CELoss: 0.8966, DKDLoss: 0.5286, 
2022-07-29 23:13:11 - train: epoch 0061, iter [01900, 05004], lr: 0.001000, loss: 1.7276, stu_CELoss: 1.1557, DKDLoss: 0.5719, 
2022-07-29 23:13:45 - train: epoch 0061, iter [02000, 05004], lr: 0.001000, loss: 1.3334, stu_CELoss: 0.7291, DKDLoss: 0.6042, 
2022-07-29 23:14:18 - train: epoch 0061, iter [02100, 05004], lr: 0.001000, loss: 1.5664, stu_CELoss: 0.8936, DKDLoss: 0.6729, 
2022-07-29 23:14:53 - train: epoch 0061, iter [02200, 05004], lr: 0.001000, loss: 1.3698, stu_CELoss: 0.8176, DKDLoss: 0.5522, 
2022-07-29 23:15:27 - train: epoch 0061, iter [02300, 05004], lr: 0.001000, loss: 1.5183, stu_CELoss: 0.9889, DKDLoss: 0.5294, 
2022-07-29 23:16:01 - train: epoch 0061, iter [02400, 05004], lr: 0.001000, loss: 1.3664, stu_CELoss: 0.8338, DKDLoss: 0.5326, 
2022-07-29 23:16:35 - train: epoch 0061, iter [02500, 05004], lr: 0.001000, loss: 1.3381, stu_CELoss: 0.7618, DKDLoss: 0.5763, 
2022-07-29 23:17:09 - train: epoch 0061, iter [02600, 05004], lr: 0.001000, loss: 1.5621, stu_CELoss: 0.9206, DKDLoss: 0.6415, 
2022-07-29 23:17:43 - train: epoch 0061, iter [02700, 05004], lr: 0.001000, loss: 1.6231, stu_CELoss: 0.9957, DKDLoss: 0.6273, 
2022-07-29 23:18:17 - train: epoch 0061, iter [02800, 05004], lr: 0.001000, loss: 1.5648, stu_CELoss: 0.9539, DKDLoss: 0.6110, 
2022-07-29 23:18:51 - train: epoch 0061, iter [02900, 05004], lr: 0.001000, loss: 1.3534, stu_CELoss: 0.7580, DKDLoss: 0.5954, 
2022-07-29 23:19:25 - train: epoch 0061, iter [03000, 05004], lr: 0.001000, loss: 1.5262, stu_CELoss: 0.8964, DKDLoss: 0.6298, 
2022-07-29 23:19:59 - train: epoch 0061, iter [03100, 05004], lr: 0.001000, loss: 1.4340, stu_CELoss: 0.8539, DKDLoss: 0.5801, 
2022-07-29 23:20:33 - train: epoch 0061, iter [03200, 05004], lr: 0.001000, loss: 1.4290, stu_CELoss: 0.8975, DKDLoss: 0.5314, 
2022-07-29 23:21:07 - train: epoch 0061, iter [03300, 05004], lr: 0.001000, loss: 1.3877, stu_CELoss: 0.8185, DKDLoss: 0.5692, 
2022-07-29 23:21:41 - train: epoch 0061, iter [03400, 05004], lr: 0.001000, loss: 1.3661, stu_CELoss: 0.8336, DKDLoss: 0.5324, 
2022-07-29 23:22:15 - train: epoch 0061, iter [03500, 05004], lr: 0.001000, loss: 1.4441, stu_CELoss: 0.9109, DKDLoss: 0.5331, 
2022-07-29 23:22:49 - train: epoch 0061, iter [03600, 05004], lr: 0.001000, loss: 1.4360, stu_CELoss: 0.8960, DKDLoss: 0.5400, 
2022-07-29 23:23:23 - train: epoch 0061, iter [03700, 05004], lr: 0.001000, loss: 1.4606, stu_CELoss: 0.9946, DKDLoss: 0.4660, 
2022-07-29 23:23:57 - train: epoch 0061, iter [03800, 05004], lr: 0.001000, loss: 1.5176, stu_CELoss: 0.9396, DKDLoss: 0.5780, 
2022-07-29 23:24:31 - train: epoch 0061, iter [03900, 05004], lr: 0.001000, loss: 1.6525, stu_CELoss: 1.0854, DKDLoss: 0.5671, 
2022-07-29 23:25:05 - train: epoch 0061, iter [04000, 05004], lr: 0.001000, loss: 1.4048, stu_CELoss: 0.8756, DKDLoss: 0.5291, 
2022-07-29 23:25:39 - train: epoch 0061, iter [04100, 05004], lr: 0.001000, loss: 1.7818, stu_CELoss: 1.1946, DKDLoss: 0.5872, 
2022-07-29 23:26:13 - train: epoch 0061, iter [04200, 05004], lr: 0.001000, loss: 1.6020, stu_CELoss: 1.0565, DKDLoss: 0.5455, 
2022-07-29 23:26:47 - train: epoch 0061, iter [04300, 05004], lr: 0.001000, loss: 1.2656, stu_CELoss: 0.7579, DKDLoss: 0.5077, 
2022-07-29 23:27:21 - train: epoch 0061, iter [04400, 05004], lr: 0.001000, loss: 1.3957, stu_CELoss: 0.8682, DKDLoss: 0.5275, 
2022-07-29 23:27:54 - train: epoch 0061, iter [04500, 05004], lr: 0.001000, loss: 1.4719, stu_CELoss: 0.9266, DKDLoss: 0.5453, 
2022-07-29 23:28:28 - train: epoch 0061, iter [04600, 05004], lr: 0.001000, loss: 1.5010, stu_CELoss: 0.9513, DKDLoss: 0.5497, 
2022-07-29 23:29:02 - train: epoch 0061, iter [04700, 05004], lr: 0.001000, loss: 1.4521, stu_CELoss: 0.8602, DKDLoss: 0.5919, 
2022-07-29 23:29:36 - train: epoch 0061, iter [04800, 05004], lr: 0.001000, loss: 1.3195, stu_CELoss: 0.8042, DKDLoss: 0.5153, 
2022-07-29 23:30:10 - train: epoch 0061, iter [04900, 05004], lr: 0.001000, loss: 1.4662, stu_CELoss: 0.9377, DKDLoss: 0.5285, 
2022-07-29 23:30:43 - train: epoch 0061, iter [05000, 05004], lr: 0.001000, loss: 1.5410, stu_CELoss: 0.9557, DKDLoss: 0.5853, 
2022-07-29 23:30:45 - train: epoch 061, train_loss: 1.4636
2022-07-29 23:33:16 - eval: epoch: 061, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 76.366%, stu_acc5: 93.062%, stu_test_loss: 0.9333
2022-07-29 23:33:17 - until epoch: 061, tea_best_acc1: 78.068%, stu_best_acc1: 76.366%
2022-07-29 23:33:17 - epoch 062 lr: 0.001000
2022-07-29 23:33:56 - train: epoch 0062, iter [00100, 05004], lr: 0.001000, loss: 1.5789, stu_CELoss: 1.0566, DKDLoss: 0.5223, 
2022-07-29 23:34:30 - train: epoch 0062, iter [00200, 05004], lr: 0.001000, loss: 1.5121, stu_CELoss: 0.9552, DKDLoss: 0.5568, 
2022-07-29 23:35:04 - train: epoch 0062, iter [00300, 05004], lr: 0.001000, loss: 1.4995, stu_CELoss: 0.9528, DKDLoss: 0.5467, 
2022-07-29 23:35:37 - train: epoch 0062, iter [00400, 05004], lr: 0.001000, loss: 1.3481, stu_CELoss: 0.7777, DKDLoss: 0.5704, 
2022-07-29 23:36:10 - train: epoch 0062, iter [00500, 05004], lr: 0.001000, loss: 1.2969, stu_CELoss: 0.7389, DKDLoss: 0.5580, 
2022-07-29 23:36:43 - train: epoch 0062, iter [00600, 05004], lr: 0.001000, loss: 1.2290, stu_CELoss: 0.7052, DKDLoss: 0.5238, 
2022-07-29 23:37:17 - train: epoch 0062, iter [00700, 05004], lr: 0.001000, loss: 1.5281, stu_CELoss: 0.9544, DKDLoss: 0.5737, 
2022-07-29 23:37:50 - train: epoch 0062, iter [00800, 05004], lr: 0.001000, loss: 1.5139, stu_CELoss: 1.0185, DKDLoss: 0.4954, 
2022-07-29 23:38:24 - train: epoch 0062, iter [00900, 05004], lr: 0.001000, loss: 1.4753, stu_CELoss: 0.8911, DKDLoss: 0.5841, 
2022-07-29 23:38:57 - train: epoch 0062, iter [01000, 05004], lr: 0.001000, loss: 1.4011, stu_CELoss: 0.8099, DKDLoss: 0.5912, 
2022-07-29 23:39:31 - train: epoch 0062, iter [01100, 05004], lr: 0.001000, loss: 1.3283, stu_CELoss: 0.8346, DKDLoss: 0.4937, 
2022-07-29 23:40:05 - train: epoch 0062, iter [01200, 05004], lr: 0.001000, loss: 1.4010, stu_CELoss: 0.8736, DKDLoss: 0.5275, 
2022-07-29 23:40:38 - train: epoch 0062, iter [01300, 05004], lr: 0.001000, loss: 1.2941, stu_CELoss: 0.7862, DKDLoss: 0.5078, 
2022-07-29 23:41:11 - train: epoch 0062, iter [01400, 05004], lr: 0.001000, loss: 1.3196, stu_CELoss: 0.8274, DKDLoss: 0.4923, 
2022-07-29 23:41:45 - train: epoch 0062, iter [01500, 05004], lr: 0.001000, loss: 1.4565, stu_CELoss: 0.8963, DKDLoss: 0.5602, 
2022-07-29 23:42:19 - train: epoch 0062, iter [01600, 05004], lr: 0.001000, loss: 1.6811, stu_CELoss: 1.1541, DKDLoss: 0.5270, 
2022-07-29 23:42:52 - train: epoch 0062, iter [01700, 05004], lr: 0.001000, loss: 1.6441, stu_CELoss: 1.1377, DKDLoss: 0.5065, 
2022-07-29 23:43:25 - train: epoch 0062, iter [01800, 05004], lr: 0.001000, loss: 1.2966, stu_CELoss: 0.8190, DKDLoss: 0.4775, 
2022-07-29 23:43:59 - train: epoch 0062, iter [01900, 05004], lr: 0.001000, loss: 1.3544, stu_CELoss: 0.9017, DKDLoss: 0.4527, 
2022-07-29 23:44:33 - train: epoch 0062, iter [02000, 05004], lr: 0.001000, loss: 1.5270, stu_CELoss: 0.9788, DKDLoss: 0.5482, 
2022-07-29 23:45:06 - train: epoch 0062, iter [02100, 05004], lr: 0.001000, loss: 1.5400, stu_CELoss: 1.0131, DKDLoss: 0.5269, 
2022-07-29 23:45:40 - train: epoch 0062, iter [02200, 05004], lr: 0.001000, loss: 1.1235, stu_CELoss: 0.6604, DKDLoss: 0.4631, 
2022-07-29 23:46:13 - train: epoch 0062, iter [02300, 05004], lr: 0.001000, loss: 1.3384, stu_CELoss: 0.8430, DKDLoss: 0.4954, 
2022-07-29 23:46:47 - train: epoch 0062, iter [02400, 05004], lr: 0.001000, loss: 1.3104, stu_CELoss: 0.8140, DKDLoss: 0.4965, 
2022-07-29 23:47:20 - train: epoch 0062, iter [02500, 05004], lr: 0.001000, loss: 1.3039, stu_CELoss: 0.8048, DKDLoss: 0.4991, 
2022-07-29 23:47:54 - train: epoch 0062, iter [02600, 05004], lr: 0.001000, loss: 1.3006, stu_CELoss: 0.8068, DKDLoss: 0.4938, 
2022-07-29 23:48:28 - train: epoch 0062, iter [02700, 05004], lr: 0.001000, loss: 1.3878, stu_CELoss: 0.8871, DKDLoss: 0.5007, 
2022-07-29 23:49:01 - train: epoch 0062, iter [02800, 05004], lr: 0.001000, loss: 1.5678, stu_CELoss: 1.0236, DKDLoss: 0.5442, 
2022-07-29 23:49:35 - train: epoch 0062, iter [02900, 05004], lr: 0.001000, loss: 1.3529, stu_CELoss: 0.8228, DKDLoss: 0.5300, 
2022-07-29 23:50:09 - train: epoch 0062, iter [03000, 05004], lr: 0.001000, loss: 1.5000, stu_CELoss: 0.9662, DKDLoss: 0.5338, 
2022-07-29 23:50:42 - train: epoch 0062, iter [03100, 05004], lr: 0.001000, loss: 1.4443, stu_CELoss: 0.9081, DKDLoss: 0.5362, 
2022-07-29 23:51:16 - train: epoch 0062, iter [03200, 05004], lr: 0.001000, loss: 1.2266, stu_CELoss: 0.7461, DKDLoss: 0.4805, 
2022-07-29 23:51:50 - train: epoch 0062, iter [03300, 05004], lr: 0.001000, loss: 1.5635, stu_CELoss: 1.0458, DKDLoss: 0.5178, 
2022-07-29 23:52:24 - train: epoch 0062, iter [03400, 05004], lr: 0.001000, loss: 1.1712, stu_CELoss: 0.6840, DKDLoss: 0.4872, 
2022-07-29 23:52:58 - train: epoch 0062, iter [03500, 05004], lr: 0.001000, loss: 1.4200, stu_CELoss: 0.9076, DKDLoss: 0.5124, 
2022-07-29 23:53:32 - train: epoch 0062, iter [03600, 05004], lr: 0.001000, loss: 1.3079, stu_CELoss: 0.8035, DKDLoss: 0.5044, 
2022-07-29 23:54:06 - train: epoch 0062, iter [03700, 05004], lr: 0.001000, loss: 1.2637, stu_CELoss: 0.7493, DKDLoss: 0.5144, 
2022-07-29 23:54:40 - train: epoch 0062, iter [03800, 05004], lr: 0.001000, loss: 1.4265, stu_CELoss: 0.8927, DKDLoss: 0.5339, 
2022-07-29 23:55:14 - train: epoch 0062, iter [03900, 05004], lr: 0.001000, loss: 1.5053, stu_CELoss: 0.9334, DKDLoss: 0.5719, 
2022-07-29 23:55:48 - train: epoch 0062, iter [04000, 05004], lr: 0.001000, loss: 1.2083, stu_CELoss: 0.7927, DKDLoss: 0.4155, 
2022-07-29 23:56:22 - train: epoch 0062, iter [04100, 05004], lr: 0.001000, loss: 1.5235, stu_CELoss: 0.9521, DKDLoss: 0.5714, 
2022-07-29 23:56:56 - train: epoch 0062, iter [04200, 05004], lr: 0.001000, loss: 1.2967, stu_CELoss: 0.8129, DKDLoss: 0.4838, 
2022-07-29 23:57:30 - train: epoch 0062, iter [04300, 05004], lr: 0.001000, loss: 1.3397, stu_CELoss: 0.8309, DKDLoss: 0.5088, 
2022-07-29 23:58:04 - train: epoch 0062, iter [04400, 05004], lr: 0.001000, loss: 1.3786, stu_CELoss: 0.8503, DKDLoss: 0.5283, 
2022-07-29 23:58:37 - train: epoch 0062, iter [04500, 05004], lr: 0.001000, loss: 1.4421, stu_CELoss: 0.8716, DKDLoss: 0.5704, 
2022-07-29 23:59:11 - train: epoch 0062, iter [04600, 05004], lr: 0.001000, loss: 1.4326, stu_CELoss: 0.8883, DKDLoss: 0.5443, 
2022-07-29 23:59:45 - train: epoch 0062, iter [04700, 05004], lr: 0.001000, loss: 1.3103, stu_CELoss: 0.8065, DKDLoss: 0.5037, 
2022-07-30 00:00:19 - train: epoch 0062, iter [04800, 05004], lr: 0.001000, loss: 1.3740, stu_CELoss: 0.8488, DKDLoss: 0.5251, 
2022-07-30 00:00:53 - train: epoch 0062, iter [04900, 05004], lr: 0.001000, loss: 1.3995, stu_CELoss: 0.8646, DKDLoss: 0.5349, 
2022-07-30 00:01:26 - train: epoch 0062, iter [05000, 05004], lr: 0.001000, loss: 1.3548, stu_CELoss: 0.7809, DKDLoss: 0.5739, 
2022-07-30 00:01:28 - train: epoch 062, train_loss: 1.3807
2022-07-30 00:03:59 - eval: epoch: 062, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 76.664%, stu_acc5: 93.204%, stu_test_loss: 0.9212
2022-07-30 00:04:00 - until epoch: 062, tea_best_acc1: 78.068%, stu_best_acc1: 76.664%
2022-07-30 00:04:00 - epoch 063 lr: 0.001000
2022-07-30 00:04:39 - train: epoch 0063, iter [00100, 05004], lr: 0.001000, loss: 1.7145, stu_CELoss: 1.1802, DKDLoss: 0.5343, 
2022-07-30 00:05:12 - train: epoch 0063, iter [00200, 05004], lr: 0.001000, loss: 1.4008, stu_CELoss: 0.8812, DKDLoss: 0.5196, 
2022-07-30 00:05:46 - train: epoch 0063, iter [00300, 05004], lr: 0.001000, loss: 1.2684, stu_CELoss: 0.6935, DKDLoss: 0.5750, 
2022-07-30 00:06:19 - train: epoch 0063, iter [00400, 05004], lr: 0.001000, loss: 1.3879, stu_CELoss: 0.8480, DKDLoss: 0.5399, 
2022-07-30 00:06:52 - train: epoch 0063, iter [00500, 05004], lr: 0.001000, loss: 1.2912, stu_CELoss: 0.7423, DKDLoss: 0.5489, 
2022-07-30 00:07:26 - train: epoch 0063, iter [00600, 05004], lr: 0.001000, loss: 1.3143, stu_CELoss: 0.8124, DKDLoss: 0.5019, 
2022-07-30 00:07:59 - train: epoch 0063, iter [00700, 05004], lr: 0.001000, loss: 1.3708, stu_CELoss: 0.8227, DKDLoss: 0.5482, 
2022-07-30 00:08:33 - train: epoch 0063, iter [00800, 05004], lr: 0.001000, loss: 1.2677, stu_CELoss: 0.7635, DKDLoss: 0.5041, 
2022-07-30 00:09:07 - train: epoch 0063, iter [00900, 05004], lr: 0.001000, loss: 1.5262, stu_CELoss: 0.9325, DKDLoss: 0.5937, 
2022-07-30 00:09:40 - train: epoch 0063, iter [01000, 05004], lr: 0.001000, loss: 1.5729, stu_CELoss: 1.0348, DKDLoss: 0.5381, 
2022-07-30 00:10:14 - train: epoch 0063, iter [01100, 05004], lr: 0.001000, loss: 1.2037, stu_CELoss: 0.7142, DKDLoss: 0.4895, 
2022-07-30 00:10:48 - train: epoch 0063, iter [01200, 05004], lr: 0.001000, loss: 1.5245, stu_CELoss: 0.9551, DKDLoss: 0.5694, 
2022-07-30 00:11:22 - train: epoch 0063, iter [01300, 05004], lr: 0.001000, loss: 1.1994, stu_CELoss: 0.7304, DKDLoss: 0.4690, 
2022-07-30 00:11:55 - train: epoch 0063, iter [01400, 05004], lr: 0.001000, loss: 1.5306, stu_CELoss: 1.0285, DKDLoss: 0.5021, 
2022-07-30 00:12:29 - train: epoch 0063, iter [01500, 05004], lr: 0.001000, loss: 1.3017, stu_CELoss: 0.7977, DKDLoss: 0.5040, 
2022-07-30 00:13:03 - train: epoch 0063, iter [01600, 05004], lr: 0.001000, loss: 1.4789, stu_CELoss: 1.0178, DKDLoss: 0.4611, 
2022-07-30 00:13:37 - train: epoch 0063, iter [01700, 05004], lr: 0.001000, loss: 1.4580, stu_CELoss: 0.9415, DKDLoss: 0.5166, 
2022-07-30 00:14:11 - train: epoch 0063, iter [01800, 05004], lr: 0.001000, loss: 1.2042, stu_CELoss: 0.7406, DKDLoss: 0.4636, 
2022-07-30 00:14:44 - train: epoch 0063, iter [01900, 05004], lr: 0.001000, loss: 1.5241, stu_CELoss: 0.9545, DKDLoss: 0.5696, 
2022-07-30 00:15:18 - train: epoch 0063, iter [02000, 05004], lr: 0.001000, loss: 1.1612, stu_CELoss: 0.7192, DKDLoss: 0.4420, 
2022-07-30 00:15:52 - train: epoch 0063, iter [02100, 05004], lr: 0.001000, loss: 1.2902, stu_CELoss: 0.7941, DKDLoss: 0.4962, 
2022-07-30 00:16:26 - train: epoch 0063, iter [02200, 05004], lr: 0.001000, loss: 1.5723, stu_CELoss: 1.0084, DKDLoss: 0.5639, 
2022-07-30 00:17:00 - train: epoch 0063, iter [02300, 05004], lr: 0.001000, loss: 1.4269, stu_CELoss: 0.9147, DKDLoss: 0.5122, 
2022-07-30 00:17:35 - train: epoch 0063, iter [02400, 05004], lr: 0.001000, loss: 1.2578, stu_CELoss: 0.7677, DKDLoss: 0.4902, 
2022-07-30 00:18:09 - train: epoch 0063, iter [02500, 05004], lr: 0.001000, loss: 1.4316, stu_CELoss: 0.9276, DKDLoss: 0.5040, 
2022-07-30 00:18:43 - train: epoch 0063, iter [02600, 05004], lr: 0.001000, loss: 1.5046, stu_CELoss: 1.0005, DKDLoss: 0.5041, 
2022-07-30 00:19:17 - train: epoch 0063, iter [02700, 05004], lr: 0.001000, loss: 1.5161, stu_CELoss: 1.0043, DKDLoss: 0.5117, 
2022-07-30 00:19:51 - train: epoch 0063, iter [02800, 05004], lr: 0.001000, loss: 1.2332, stu_CELoss: 0.7674, DKDLoss: 0.4658, 
2022-07-30 00:20:25 - train: epoch 0063, iter [02900, 05004], lr: 0.001000, loss: 1.4632, stu_CELoss: 0.9811, DKDLoss: 0.4820, 
2022-07-30 00:20:58 - train: epoch 0063, iter [03000, 05004], lr: 0.001000, loss: 1.4283, stu_CELoss: 0.8909, DKDLoss: 0.5374, 
2022-07-30 00:21:32 - train: epoch 0063, iter [03100, 05004], lr: 0.001000, loss: 1.5525, stu_CELoss: 0.9969, DKDLoss: 0.5556, 
2022-07-30 00:22:06 - train: epoch 0063, iter [03200, 05004], lr: 0.001000, loss: 1.3757, stu_CELoss: 0.9013, DKDLoss: 0.4744, 
2022-07-30 00:22:39 - train: epoch 0063, iter [03300, 05004], lr: 0.001000, loss: 1.2682, stu_CELoss: 0.7591, DKDLoss: 0.5091, 
2022-07-30 00:23:13 - train: epoch 0063, iter [03400, 05004], lr: 0.001000, loss: 1.3512, stu_CELoss: 0.7908, DKDLoss: 0.5604, 
2022-07-30 00:23:47 - train: epoch 0063, iter [03500, 05004], lr: 0.001000, loss: 1.4222, stu_CELoss: 0.8631, DKDLoss: 0.5591, 
2022-07-30 00:24:21 - train: epoch 0063, iter [03600, 05004], lr: 0.001000, loss: 1.4139, stu_CELoss: 0.8982, DKDLoss: 0.5158, 
2022-07-30 00:24:55 - train: epoch 0063, iter [03700, 05004], lr: 0.001000, loss: 1.4727, stu_CELoss: 0.9456, DKDLoss: 0.5271, 
2022-07-30 00:25:29 - train: epoch 0063, iter [03800, 05004], lr: 0.001000, loss: 1.4452, stu_CELoss: 0.9246, DKDLoss: 0.5206, 
2022-07-30 00:26:03 - train: epoch 0063, iter [03900, 05004], lr: 0.001000, loss: 1.1491, stu_CELoss: 0.6538, DKDLoss: 0.4953, 
2022-07-30 00:26:37 - train: epoch 0063, iter [04000, 05004], lr: 0.001000, loss: 1.1713, stu_CELoss: 0.6867, DKDLoss: 0.4846, 
2022-07-30 00:27:11 - train: epoch 0063, iter [04100, 05004], lr: 0.001000, loss: 1.4150, stu_CELoss: 0.8992, DKDLoss: 0.5159, 
2022-07-30 00:27:45 - train: epoch 0063, iter [04200, 05004], lr: 0.001000, loss: 1.4705, stu_CELoss: 0.9753, DKDLoss: 0.4953, 
2022-07-30 00:28:19 - train: epoch 0063, iter [04300, 05004], lr: 0.001000, loss: 1.4455, stu_CELoss: 0.9201, DKDLoss: 0.5253, 
2022-07-30 00:28:53 - train: epoch 0063, iter [04400, 05004], lr: 0.001000, loss: 1.1907, stu_CELoss: 0.7233, DKDLoss: 0.4674, 
2022-07-30 00:29:26 - train: epoch 0063, iter [04500, 05004], lr: 0.001000, loss: 1.4116, stu_CELoss: 0.7813, DKDLoss: 0.6304, 
2022-07-30 00:30:00 - train: epoch 0063, iter [04600, 05004], lr: 0.001000, loss: 1.2734, stu_CELoss: 0.8035, DKDLoss: 0.4699, 
2022-07-30 00:30:34 - train: epoch 0063, iter [04700, 05004], lr: 0.001000, loss: 1.2467, stu_CELoss: 0.7336, DKDLoss: 0.5131, 
2022-07-30 00:31:08 - train: epoch 0063, iter [04800, 05004], lr: 0.001000, loss: 1.2035, stu_CELoss: 0.7054, DKDLoss: 0.4981, 
2022-07-30 00:31:42 - train: epoch 0063, iter [04900, 05004], lr: 0.001000, loss: 1.3877, stu_CELoss: 0.8636, DKDLoss: 0.5240, 
2022-07-30 00:32:15 - train: epoch 0063, iter [05000, 05004], lr: 0.001000, loss: 1.3359, stu_CELoss: 0.8882, DKDLoss: 0.4476, 
2022-07-30 00:32:17 - train: epoch 063, train_loss: 1.3456
2022-07-30 00:34:50 - eval: epoch: 063, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 76.758%, stu_acc5: 93.196%, stu_test_loss: 0.9202
2022-07-30 00:34:51 - until epoch: 063, tea_best_acc1: 78.068%, stu_best_acc1: 76.758%
2022-07-30 00:34:51 - epoch 064 lr: 0.001000
2022-07-30 00:35:32 - train: epoch 0064, iter [00100, 05004], lr: 0.001000, loss: 1.2550, stu_CELoss: 0.7544, DKDLoss: 0.5006, 
2022-07-30 00:36:04 - train: epoch 0064, iter [00200, 05004], lr: 0.001000, loss: 1.4939, stu_CELoss: 0.9521, DKDLoss: 0.5418, 
2022-07-30 00:36:37 - train: epoch 0064, iter [00300, 05004], lr: 0.001000, loss: 1.1730, stu_CELoss: 0.6786, DKDLoss: 0.4945, 
2022-07-30 00:37:10 - train: epoch 0064, iter [00400, 05004], lr: 0.001000, loss: 1.1787, stu_CELoss: 0.6983, DKDLoss: 0.4804, 
2022-07-30 00:37:43 - train: epoch 0064, iter [00500, 05004], lr: 0.001000, loss: 1.3449, stu_CELoss: 0.8071, DKDLoss: 0.5378, 
2022-07-30 00:38:16 - train: epoch 0064, iter [00600, 05004], lr: 0.001000, loss: 1.5180, stu_CELoss: 0.9361, DKDLoss: 0.5819, 
2022-07-30 00:38:49 - train: epoch 0064, iter [00700, 05004], lr: 0.001000, loss: 1.4328, stu_CELoss: 0.9612, DKDLoss: 0.4716, 
2022-07-30 00:39:22 - train: epoch 0064, iter [00800, 05004], lr: 0.001000, loss: 1.3877, stu_CELoss: 0.8638, DKDLoss: 0.5238, 
2022-07-30 00:39:56 - train: epoch 0064, iter [00900, 05004], lr: 0.001000, loss: 1.2855, stu_CELoss: 0.7670, DKDLoss: 0.5185, 
2022-07-30 00:40:30 - train: epoch 0064, iter [01000, 05004], lr: 0.001000, loss: 1.2656, stu_CELoss: 0.7727, DKDLoss: 0.4929, 
2022-07-30 00:41:03 - train: epoch 0064, iter [01100, 05004], lr: 0.001000, loss: 1.5132, stu_CELoss: 1.0121, DKDLoss: 0.5011, 
2022-07-30 00:41:37 - train: epoch 0064, iter [01200, 05004], lr: 0.001000, loss: 1.1824, stu_CELoss: 0.7298, DKDLoss: 0.4526, 
2022-07-30 00:42:11 - train: epoch 0064, iter [01300, 05004], lr: 0.001000, loss: 1.1760, stu_CELoss: 0.7366, DKDLoss: 0.4394, 
2022-07-30 00:42:44 - train: epoch 0064, iter [01400, 05004], lr: 0.001000, loss: 1.5567, stu_CELoss: 1.0048, DKDLoss: 0.5519, 
2022-07-30 00:43:18 - train: epoch 0064, iter [01500, 05004], lr: 0.001000, loss: 1.3767, stu_CELoss: 0.8928, DKDLoss: 0.4838, 
2022-07-30 00:43:51 - train: epoch 0064, iter [01600, 05004], lr: 0.001000, loss: 1.2151, stu_CELoss: 0.7124, DKDLoss: 0.5027, 
2022-07-30 00:44:25 - train: epoch 0064, iter [01700, 05004], lr: 0.001000, loss: 1.3672, stu_CELoss: 0.8133, DKDLoss: 0.5539, 
2022-07-30 00:44:58 - train: epoch 0064, iter [01800, 05004], lr: 0.001000, loss: 1.1987, stu_CELoss: 0.7477, DKDLoss: 0.4510, 
2022-07-30 00:45:32 - train: epoch 0064, iter [01900, 05004], lr: 0.001000, loss: 1.3879, stu_CELoss: 0.8734, DKDLoss: 0.5144, 
2022-07-30 00:46:06 - train: epoch 0064, iter [02000, 05004], lr: 0.001000, loss: 1.2092, stu_CELoss: 0.7100, DKDLoss: 0.4992, 
2022-07-30 00:46:39 - train: epoch 0064, iter [02100, 05004], lr: 0.001000, loss: 1.5363, stu_CELoss: 0.9914, DKDLoss: 0.5449, 
2022-07-30 00:47:13 - train: epoch 0064, iter [02200, 05004], lr: 0.001000, loss: 1.4710, stu_CELoss: 0.9569, DKDLoss: 0.5140, 
2022-07-30 00:47:47 - train: epoch 0064, iter [02300, 05004], lr: 0.001000, loss: 1.3267, stu_CELoss: 0.8187, DKDLoss: 0.5080, 
2022-07-30 00:48:21 - train: epoch 0064, iter [02400, 05004], lr: 0.001000, loss: 1.1437, stu_CELoss: 0.6527, DKDLoss: 0.4910, 
2022-07-30 00:48:54 - train: epoch 0064, iter [02500, 05004], lr: 0.001000, loss: 1.4830, stu_CELoss: 1.0071, DKDLoss: 0.4759, 
2022-07-30 00:49:28 - train: epoch 0064, iter [02600, 05004], lr: 0.001000, loss: 1.3125, stu_CELoss: 0.7984, DKDLoss: 0.5141, 
2022-07-30 00:50:01 - train: epoch 0064, iter [02700, 05004], lr: 0.001000, loss: 1.2752, stu_CELoss: 0.7239, DKDLoss: 0.5513, 
2022-07-30 00:50:35 - train: epoch 0064, iter [02800, 05004], lr: 0.001000, loss: 1.5207, stu_CELoss: 1.0527, DKDLoss: 0.4680, 
2022-07-30 00:51:08 - train: epoch 0064, iter [02900, 05004], lr: 0.001000, loss: 1.3082, stu_CELoss: 0.7893, DKDLoss: 0.5189, 
2022-07-30 00:51:42 - train: epoch 0064, iter [03000, 05004], lr: 0.001000, loss: 1.1787, stu_CELoss: 0.7204, DKDLoss: 0.4583, 
2022-07-30 00:52:16 - train: epoch 0064, iter [03100, 05004], lr: 0.001000, loss: 1.3221, stu_CELoss: 0.8110, DKDLoss: 0.5111, 
2022-07-30 00:52:49 - train: epoch 0064, iter [03200, 05004], lr: 0.001000, loss: 1.5019, stu_CELoss: 0.9549, DKDLoss: 0.5469, 
2022-07-30 00:53:23 - train: epoch 0064, iter [03300, 05004], lr: 0.001000, loss: 1.3344, stu_CELoss: 0.8711, DKDLoss: 0.4633, 
2022-07-30 00:53:58 - train: epoch 0064, iter [03400, 05004], lr: 0.001000, loss: 1.3001, stu_CELoss: 0.8118, DKDLoss: 0.4884, 
2022-07-30 00:54:32 - train: epoch 0064, iter [03500, 05004], lr: 0.001000, loss: 1.4136, stu_CELoss: 0.9039, DKDLoss: 0.5097, 
2022-07-30 00:55:06 - train: epoch 0064, iter [03600, 05004], lr: 0.001000, loss: 1.2536, stu_CELoss: 0.8008, DKDLoss: 0.4528, 
2022-07-30 00:55:40 - train: epoch 0064, iter [03700, 05004], lr: 0.001000, loss: 1.0726, stu_CELoss: 0.6669, DKDLoss: 0.4057, 
2022-07-30 00:56:14 - train: epoch 0064, iter [03800, 05004], lr: 0.001000, loss: 1.3239, stu_CELoss: 0.8007, DKDLoss: 0.5232, 
2022-07-30 00:56:47 - train: epoch 0064, iter [03900, 05004], lr: 0.001000, loss: 1.2424, stu_CELoss: 0.7975, DKDLoss: 0.4449, 
2022-07-30 00:57:21 - train: epoch 0064, iter [04000, 05004], lr: 0.001000, loss: 1.2486, stu_CELoss: 0.7585, DKDLoss: 0.4901, 
2022-07-30 00:57:55 - train: epoch 0064, iter [04100, 05004], lr: 0.001000, loss: 1.2614, stu_CELoss: 0.7791, DKDLoss: 0.4823, 
2022-07-30 00:58:29 - train: epoch 0064, iter [04200, 05004], lr: 0.001000, loss: 1.0851, stu_CELoss: 0.6636, DKDLoss: 0.4215, 
2022-07-30 00:59:03 - train: epoch 0064, iter [04300, 05004], lr: 0.001000, loss: 1.4971, stu_CELoss: 0.9334, DKDLoss: 0.5637, 
2022-07-30 00:59:37 - train: epoch 0064, iter [04400, 05004], lr: 0.001000, loss: 1.2864, stu_CELoss: 0.8205, DKDLoss: 0.4659, 
2022-07-30 01:00:11 - train: epoch 0064, iter [04500, 05004], lr: 0.001000, loss: 1.2965, stu_CELoss: 0.8407, DKDLoss: 0.4558, 
2022-07-30 01:00:44 - train: epoch 0064, iter [04600, 05004], lr: 0.001000, loss: 1.4508, stu_CELoss: 0.9065, DKDLoss: 0.5443, 
2022-07-30 01:01:19 - train: epoch 0064, iter [04700, 05004], lr: 0.001000, loss: 1.5395, stu_CELoss: 0.9868, DKDLoss: 0.5527, 
2022-07-30 01:01:52 - train: epoch 0064, iter [04800, 05004], lr: 0.001000, loss: 1.2887, stu_CELoss: 0.7403, DKDLoss: 0.5484, 
2022-07-30 01:02:26 - train: epoch 0064, iter [04900, 05004], lr: 0.001000, loss: 1.4019, stu_CELoss: 0.8999, DKDLoss: 0.5020, 
2022-07-30 01:02:59 - train: epoch 0064, iter [05000, 05004], lr: 0.001000, loss: 1.2073, stu_CELoss: 0.7268, DKDLoss: 0.4805, 
2022-07-30 01:03:01 - train: epoch 064, train_loss: 1.3221
2022-07-30 01:05:33 - eval: epoch: 064, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 76.950%, stu_acc5: 93.282%, stu_test_loss: 0.9139
2022-07-30 01:05:34 - until epoch: 064, tea_best_acc1: 78.068%, stu_best_acc1: 76.950%
2022-07-30 01:05:34 - epoch 065 lr: 0.001000
2022-07-30 01:06:14 - train: epoch 0065, iter [00100, 05004], lr: 0.001000, loss: 1.3408, stu_CELoss: 0.8175, DKDLoss: 0.5234, 
2022-07-30 01:06:46 - train: epoch 0065, iter [00200, 05004], lr: 0.001000, loss: 1.4762, stu_CELoss: 0.9305, DKDLoss: 0.5458, 
2022-07-30 01:07:19 - train: epoch 0065, iter [00300, 05004], lr: 0.001000, loss: 1.3554, stu_CELoss: 0.8832, DKDLoss: 0.4722, 
2022-07-30 01:07:52 - train: epoch 0065, iter [00400, 05004], lr: 0.001000, loss: 1.3347, stu_CELoss: 0.8782, DKDLoss: 0.4565, 
2022-07-30 01:08:25 - train: epoch 0065, iter [00500, 05004], lr: 0.001000, loss: 1.3754, stu_CELoss: 0.8775, DKDLoss: 0.4979, 
2022-07-30 01:08:58 - train: epoch 0065, iter [00600, 05004], lr: 0.001000, loss: 1.3452, stu_CELoss: 0.8878, DKDLoss: 0.4573, 
2022-07-30 01:09:31 - train: epoch 0065, iter [00700, 05004], lr: 0.001000, loss: 1.2809, stu_CELoss: 0.7993, DKDLoss: 0.4816, 
2022-07-30 01:10:03 - train: epoch 0065, iter [00800, 05004], lr: 0.001000, loss: 1.3255, stu_CELoss: 0.8942, DKDLoss: 0.4313, 
2022-07-30 01:10:37 - train: epoch 0065, iter [00900, 05004], lr: 0.001000, loss: 1.3486, stu_CELoss: 0.8493, DKDLoss: 0.4993, 
2022-07-30 01:11:10 - train: epoch 0065, iter [01000, 05004], lr: 0.001000, loss: 1.3901, stu_CELoss: 0.8825, DKDLoss: 0.5076, 
2022-07-30 01:11:44 - train: epoch 0065, iter [01100, 05004], lr: 0.001000, loss: 1.2959, stu_CELoss: 0.8251, DKDLoss: 0.4708, 
2022-07-30 01:12:17 - train: epoch 0065, iter [01200, 05004], lr: 0.001000, loss: 1.3856, stu_CELoss: 0.8949, DKDLoss: 0.4906, 
2022-07-30 01:12:51 - train: epoch 0065, iter [01300, 05004], lr: 0.001000, loss: 1.2778, stu_CELoss: 0.7336, DKDLoss: 0.5442, 
2022-07-30 01:13:24 - train: epoch 0065, iter [01400, 05004], lr: 0.001000, loss: 1.2880, stu_CELoss: 0.8124, DKDLoss: 0.4756, 
2022-07-30 01:13:58 - train: epoch 0065, iter [01500, 05004], lr: 0.001000, loss: 1.1461, stu_CELoss: 0.6564, DKDLoss: 0.4896, 
2022-07-30 01:14:32 - train: epoch 0065, iter [01600, 05004], lr: 0.001000, loss: 1.4301, stu_CELoss: 0.8840, DKDLoss: 0.5461, 
2022-07-30 01:15:05 - train: epoch 0065, iter [01700, 05004], lr: 0.001000, loss: 1.3494, stu_CELoss: 0.8800, DKDLoss: 0.4693, 
2022-07-30 01:15:38 - train: epoch 0065, iter [01800, 05004], lr: 0.001000, loss: 1.0363, stu_CELoss: 0.6167, DKDLoss: 0.4196, 
2022-07-30 01:16:12 - train: epoch 0065, iter [01900, 05004], lr: 0.001000, loss: 1.1215, stu_CELoss: 0.6900, DKDLoss: 0.4315, 
2022-07-30 01:16:46 - train: epoch 0065, iter [02000, 05004], lr: 0.001000, loss: 1.0632, stu_CELoss: 0.6488, DKDLoss: 0.4144, 
2022-07-30 01:17:20 - train: epoch 0065, iter [02100, 05004], lr: 0.001000, loss: 1.3452, stu_CELoss: 0.8515, DKDLoss: 0.4937, 
2022-07-30 01:17:54 - train: epoch 0065, iter [02200, 05004], lr: 0.001000, loss: 1.3650, stu_CELoss: 0.8804, DKDLoss: 0.4846, 
2022-07-30 01:18:28 - train: epoch 0065, iter [02300, 05004], lr: 0.001000, loss: 1.4002, stu_CELoss: 0.9203, DKDLoss: 0.4799, 
2022-07-30 01:19:02 - train: epoch 0065, iter [02400, 05004], lr: 0.001000, loss: 1.3670, stu_CELoss: 0.8877, DKDLoss: 0.4793, 
2022-07-30 01:19:36 - train: epoch 0065, iter [02500, 05004], lr: 0.001000, loss: 1.2180, stu_CELoss: 0.7582, DKDLoss: 0.4598, 
2022-07-30 01:20:10 - train: epoch 0065, iter [02600, 05004], lr: 0.001000, loss: 1.4311, stu_CELoss: 0.8753, DKDLoss: 0.5557, 
2022-07-30 01:20:44 - train: epoch 0065, iter [02700, 05004], lr: 0.001000, loss: 1.3856, stu_CELoss: 0.9172, DKDLoss: 0.4684, 
2022-07-30 01:21:18 - train: epoch 0065, iter [02800, 05004], lr: 0.001000, loss: 1.5209, stu_CELoss: 1.0361, DKDLoss: 0.4848, 
2022-07-30 01:21:52 - train: epoch 0065, iter [02900, 05004], lr: 0.001000, loss: 1.2319, stu_CELoss: 0.7666, DKDLoss: 0.4653, 
2022-07-30 01:22:26 - train: epoch 0065, iter [03000, 05004], lr: 0.001000, loss: 1.1457, stu_CELoss: 0.7220, DKDLoss: 0.4237, 
2022-07-30 01:23:00 - train: epoch 0065, iter [03100, 05004], lr: 0.001000, loss: 1.2519, stu_CELoss: 0.7304, DKDLoss: 0.5215, 
2022-07-30 01:23:34 - train: epoch 0065, iter [03200, 05004], lr: 0.001000, loss: 1.4113, stu_CELoss: 0.8853, DKDLoss: 0.5260, 
2022-07-30 01:24:08 - train: epoch 0065, iter [03300, 05004], lr: 0.001000, loss: 1.2208, stu_CELoss: 0.7546, DKDLoss: 0.4662, 
2022-07-30 01:24:42 - train: epoch 0065, iter [03400, 05004], lr: 0.001000, loss: 1.3152, stu_CELoss: 0.8644, DKDLoss: 0.4508, 
2022-07-30 01:25:16 - train: epoch 0065, iter [03500, 05004], lr: 0.001000, loss: 1.6583, stu_CELoss: 1.1406, DKDLoss: 0.5176, 
2022-07-30 01:25:50 - train: epoch 0065, iter [03600, 05004], lr: 0.001000, loss: 1.4316, stu_CELoss: 0.9706, DKDLoss: 0.4610, 
2022-07-30 01:26:24 - train: epoch 0065, iter [03700, 05004], lr: 0.001000, loss: 1.2275, stu_CELoss: 0.7285, DKDLoss: 0.4990, 
2022-07-30 01:26:57 - train: epoch 0065, iter [03800, 05004], lr: 0.001000, loss: 1.2812, stu_CELoss: 0.8090, DKDLoss: 0.4722, 
2022-07-30 01:27:31 - train: epoch 0065, iter [03900, 05004], lr: 0.001000, loss: 1.4726, stu_CELoss: 0.9557, DKDLoss: 0.5169, 
2022-07-30 01:28:05 - train: epoch 0065, iter [04000, 05004], lr: 0.001000, loss: 1.3081, stu_CELoss: 0.8780, DKDLoss: 0.4301, 
2022-07-30 01:28:39 - train: epoch 0065, iter [04100, 05004], lr: 0.001000, loss: 1.3442, stu_CELoss: 0.8395, DKDLoss: 0.5047, 
2022-07-30 01:29:13 - train: epoch 0065, iter [04200, 05004], lr: 0.001000, loss: 1.5869, stu_CELoss: 1.0940, DKDLoss: 0.4929, 
2022-07-30 01:29:47 - train: epoch 0065, iter [04300, 05004], lr: 0.001000, loss: 1.2460, stu_CELoss: 0.7727, DKDLoss: 0.4733, 
2022-07-30 01:30:21 - train: epoch 0065, iter [04400, 05004], lr: 0.001000, loss: 1.2017, stu_CELoss: 0.6561, DKDLoss: 0.5456, 
2022-07-30 01:30:55 - train: epoch 0065, iter [04500, 05004], lr: 0.001000, loss: 1.2387, stu_CELoss: 0.7670, DKDLoss: 0.4718, 
2022-07-30 01:31:29 - train: epoch 0065, iter [04600, 05004], lr: 0.001000, loss: 1.2476, stu_CELoss: 0.7639, DKDLoss: 0.4837, 
2022-07-30 01:32:04 - train: epoch 0065, iter [04700, 05004], lr: 0.001000, loss: 1.3202, stu_CELoss: 0.8167, DKDLoss: 0.5034, 
2022-07-30 01:32:37 - train: epoch 0065, iter [04800, 05004], lr: 0.001000, loss: 1.2718, stu_CELoss: 0.8385, DKDLoss: 0.4333, 
2022-07-30 01:33:12 - train: epoch 0065, iter [04900, 05004], lr: 0.001000, loss: 1.3575, stu_CELoss: 0.8848, DKDLoss: 0.4727, 
2022-07-30 01:33:45 - train: epoch 0065, iter [05000, 05004], lr: 0.001000, loss: 1.2582, stu_CELoss: 0.7858, DKDLoss: 0.4724, 
2022-07-30 01:33:46 - train: epoch 065, train_loss: 1.3043
2022-07-30 01:36:19 - eval: epoch: 065, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 76.978%, stu_acc5: 93.344%, stu_test_loss: 0.9119
2022-07-30 01:36:20 - until epoch: 065, tea_best_acc1: 78.068%, stu_best_acc1: 76.978%
2022-07-30 01:36:20 - epoch 066 lr: 0.001000
2022-07-30 01:37:00 - train: epoch 0066, iter [00100, 05004], lr: 0.001000, loss: 1.2556, stu_CELoss: 0.7574, DKDLoss: 0.4983, 
2022-07-30 01:37:33 - train: epoch 0066, iter [00200, 05004], lr: 0.001000, loss: 1.4868, stu_CELoss: 0.9100, DKDLoss: 0.5768, 
2022-07-30 01:38:06 - train: epoch 0066, iter [00300, 05004], lr: 0.001000, loss: 1.3415, stu_CELoss: 0.8517, DKDLoss: 0.4899, 
2022-07-30 01:38:39 - train: epoch 0066, iter [00400, 05004], lr: 0.001000, loss: 1.3031, stu_CELoss: 0.7923, DKDLoss: 0.5108, 
2022-07-30 01:39:13 - train: epoch 0066, iter [00500, 05004], lr: 0.001000, loss: 1.4187, stu_CELoss: 0.8983, DKDLoss: 0.5204, 
2022-07-30 01:39:46 - train: epoch 0066, iter [00600, 05004], lr: 0.001000, loss: 1.2144, stu_CELoss: 0.7461, DKDLoss: 0.4683, 
2022-07-30 01:40:20 - train: epoch 0066, iter [00700, 05004], lr: 0.001000, loss: 1.2529, stu_CELoss: 0.8054, DKDLoss: 0.4475, 
2022-07-30 01:40:54 - train: epoch 0066, iter [00800, 05004], lr: 0.001000, loss: 1.3563, stu_CELoss: 0.8302, DKDLoss: 0.5262, 
2022-07-30 01:41:28 - train: epoch 0066, iter [00900, 05004], lr: 0.001000, loss: 1.2780, stu_CELoss: 0.7743, DKDLoss: 0.5037, 
2022-07-30 01:42:02 - train: epoch 0066, iter [01000, 05004], lr: 0.001000, loss: 1.3283, stu_CELoss: 0.8187, DKDLoss: 0.5095, 
2022-07-30 01:42:36 - train: epoch 0066, iter [01100, 05004], lr: 0.001000, loss: 1.2759, stu_CELoss: 0.7719, DKDLoss: 0.5040, 
2022-07-30 01:43:10 - train: epoch 0066, iter [01200, 05004], lr: 0.001000, loss: 1.4971, stu_CELoss: 0.9618, DKDLoss: 0.5353, 
2022-07-30 01:43:44 - train: epoch 0066, iter [01300, 05004], lr: 0.001000, loss: 1.3710, stu_CELoss: 0.8983, DKDLoss: 0.4727, 
2022-07-30 01:44:18 - train: epoch 0066, iter [01400, 05004], lr: 0.001000, loss: 1.3441, stu_CELoss: 0.8045, DKDLoss: 0.5396, 
2022-07-30 01:44:51 - train: epoch 0066, iter [01500, 05004], lr: 0.001000, loss: 1.2909, stu_CELoss: 0.8000, DKDLoss: 0.4908, 
2022-07-30 01:45:25 - train: epoch 0066, iter [01600, 05004], lr: 0.001000, loss: 1.5010, stu_CELoss: 0.9502, DKDLoss: 0.5508, 
2022-07-30 01:45:59 - train: epoch 0066, iter [01700, 05004], lr: 0.001000, loss: 1.3174, stu_CELoss: 0.8874, DKDLoss: 0.4300, 
2022-07-30 01:46:33 - train: epoch 0066, iter [01800, 05004], lr: 0.001000, loss: 0.9830, stu_CELoss: 0.6205, DKDLoss: 0.3625, 
2022-07-30 01:47:07 - train: epoch 0066, iter [01900, 05004], lr: 0.001000, loss: 1.4352, stu_CELoss: 0.9246, DKDLoss: 0.5107, 
2022-07-30 01:47:41 - train: epoch 0066, iter [02000, 05004], lr: 0.001000, loss: 1.2266, stu_CELoss: 0.8015, DKDLoss: 0.4252, 
2022-07-30 01:48:14 - train: epoch 0066, iter [02100, 05004], lr: 0.001000, loss: 1.2251, stu_CELoss: 0.7793, DKDLoss: 0.4458, 
2022-07-30 01:48:48 - train: epoch 0066, iter [02200, 05004], lr: 0.001000, loss: 1.2965, stu_CELoss: 0.8190, DKDLoss: 0.4775, 
2022-07-30 01:49:22 - train: epoch 0066, iter [02300, 05004], lr: 0.001000, loss: 1.3979, stu_CELoss: 0.9241, DKDLoss: 0.4738, 
2022-07-30 01:49:56 - train: epoch 0066, iter [02400, 05004], lr: 0.001000, loss: 1.3899, stu_CELoss: 0.8780, DKDLoss: 0.5119, 
2022-07-30 01:50:30 - train: epoch 0066, iter [02500, 05004], lr: 0.001000, loss: 1.3497, stu_CELoss: 0.9026, DKDLoss: 0.4471, 
2022-07-30 01:51:03 - train: epoch 0066, iter [02600, 05004], lr: 0.001000, loss: 1.2785, stu_CELoss: 0.8438, DKDLoss: 0.4347, 
2022-07-30 01:51:37 - train: epoch 0066, iter [02700, 05004], lr: 0.001000, loss: 1.3250, stu_CELoss: 0.8876, DKDLoss: 0.4374, 
2022-07-30 01:52:11 - train: epoch 0066, iter [02800, 05004], lr: 0.001000, loss: 1.1870, stu_CELoss: 0.7384, DKDLoss: 0.4486, 
2022-07-30 01:52:45 - train: epoch 0066, iter [02900, 05004], lr: 0.001000, loss: 1.2504, stu_CELoss: 0.7331, DKDLoss: 0.5174, 
2022-07-30 01:53:19 - train: epoch 0066, iter [03000, 05004], lr: 0.001000, loss: 1.4031, stu_CELoss: 0.9461, DKDLoss: 0.4571, 
2022-07-30 01:53:53 - train: epoch 0066, iter [03100, 05004], lr: 0.001000, loss: 1.4376, stu_CELoss: 0.8820, DKDLoss: 0.5556, 
2022-07-30 01:54:27 - train: epoch 0066, iter [03200, 05004], lr: 0.001000, loss: 1.4254, stu_CELoss: 0.9306, DKDLoss: 0.4948, 
2022-07-30 01:55:01 - train: epoch 0066, iter [03300, 05004], lr: 0.001000, loss: 1.0991, stu_CELoss: 0.6212, DKDLoss: 0.4779, 
2022-07-30 01:55:35 - train: epoch 0066, iter [03400, 05004], lr: 0.001000, loss: 1.3981, stu_CELoss: 0.9445, DKDLoss: 0.4536, 
2022-07-30 01:56:09 - train: epoch 0066, iter [03500, 05004], lr: 0.001000, loss: 1.2592, stu_CELoss: 0.7680, DKDLoss: 0.4912, 
2022-07-30 01:56:43 - train: epoch 0066, iter [03600, 05004], lr: 0.001000, loss: 1.4853, stu_CELoss: 0.9570, DKDLoss: 0.5284, 
2022-07-30 01:57:17 - train: epoch 0066, iter [03700, 05004], lr: 0.001000, loss: 1.1896, stu_CELoss: 0.7323, DKDLoss: 0.4573, 
2022-07-30 01:57:51 - train: epoch 0066, iter [03800, 05004], lr: 0.001000, loss: 1.3470, stu_CELoss: 0.8854, DKDLoss: 0.4616, 
2022-07-30 01:58:25 - train: epoch 0066, iter [03900, 05004], lr: 0.001000, loss: 1.2904, stu_CELoss: 0.8023, DKDLoss: 0.4881, 
2022-07-30 01:58:59 - train: epoch 0066, iter [04000, 05004], lr: 0.001000, loss: 1.2916, stu_CELoss: 0.8639, DKDLoss: 0.4277, 
2022-07-30 01:59:32 - train: epoch 0066, iter [04100, 05004], lr: 0.001000, loss: 1.2071, stu_CELoss: 0.7205, DKDLoss: 0.4866, 
2022-07-30 02:00:06 - train: epoch 0066, iter [04200, 05004], lr: 0.001000, loss: 1.2405, stu_CELoss: 0.7790, DKDLoss: 0.4615, 
2022-07-30 02:00:40 - train: epoch 0066, iter [04300, 05004], lr: 0.001000, loss: 1.2285, stu_CELoss: 0.7881, DKDLoss: 0.4404, 
2022-07-30 02:01:14 - train: epoch 0066, iter [04400, 05004], lr: 0.001000, loss: 1.2482, stu_CELoss: 0.8238, DKDLoss: 0.4245, 
2022-07-30 02:01:48 - train: epoch 0066, iter [04500, 05004], lr: 0.001000, loss: 1.3817, stu_CELoss: 0.8717, DKDLoss: 0.5100, 
2022-07-30 02:02:23 - train: epoch 0066, iter [04600, 05004], lr: 0.001000, loss: 1.3351, stu_CELoss: 0.8383, DKDLoss: 0.4968, 
2022-07-30 02:02:57 - train: epoch 0066, iter [04700, 05004], lr: 0.001000, loss: 1.0269, stu_CELoss: 0.5781, DKDLoss: 0.4489, 
2022-07-30 02:03:31 - train: epoch 0066, iter [04800, 05004], lr: 0.001000, loss: 1.2687, stu_CELoss: 0.8051, DKDLoss: 0.4636, 
2022-07-30 02:04:05 - train: epoch 0066, iter [04900, 05004], lr: 0.001000, loss: 1.2296, stu_CELoss: 0.8283, DKDLoss: 0.4013, 
2022-07-30 02:04:39 - train: epoch 0066, iter [05000, 05004], lr: 0.001000, loss: 1.1212, stu_CELoss: 0.6714, DKDLoss: 0.4498, 
2022-07-30 02:04:40 - train: epoch 066, train_loss: 1.2900
2022-07-30 02:07:14 - eval: epoch: 066, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.134%, stu_acc5: 93.298%, stu_test_loss: 0.9098
2022-07-30 02:07:15 - until epoch: 066, tea_best_acc1: 78.068%, stu_best_acc1: 77.134%
2022-07-30 02:07:15 - epoch 067 lr: 0.001000
2022-07-30 02:07:54 - train: epoch 0067, iter [00100, 05004], lr: 0.001000, loss: 1.1267, stu_CELoss: 0.7193, DKDLoss: 0.4074, 
2022-07-30 02:08:27 - train: epoch 0067, iter [00200, 05004], lr: 0.001000, loss: 1.4692, stu_CELoss: 0.9464, DKDLoss: 0.5228, 
2022-07-30 02:09:01 - train: epoch 0067, iter [00300, 05004], lr: 0.001000, loss: 1.3022, stu_CELoss: 0.8120, DKDLoss: 0.4902, 
2022-07-30 02:09:34 - train: epoch 0067, iter [00400, 05004], lr: 0.001000, loss: 1.1883, stu_CELoss: 0.7062, DKDLoss: 0.4821, 
2022-07-30 02:10:08 - train: epoch 0067, iter [00500, 05004], lr: 0.001000, loss: 1.2163, stu_CELoss: 0.7297, DKDLoss: 0.4866, 
2022-07-30 02:10:41 - train: epoch 0067, iter [00600, 05004], lr: 0.001000, loss: 1.0975, stu_CELoss: 0.6275, DKDLoss: 0.4700, 
2022-07-30 02:11:15 - train: epoch 0067, iter [00700, 05004], lr: 0.001000, loss: 1.1968, stu_CELoss: 0.7265, DKDLoss: 0.4703, 
2022-07-30 02:11:49 - train: epoch 0067, iter [00800, 05004], lr: 0.001000, loss: 1.4123, stu_CELoss: 0.9276, DKDLoss: 0.4847, 
2022-07-30 02:12:23 - train: epoch 0067, iter [00900, 05004], lr: 0.001000, loss: 1.4913, stu_CELoss: 0.9782, DKDLoss: 0.5131, 
2022-07-30 02:12:56 - train: epoch 0067, iter [01000, 05004], lr: 0.001000, loss: 1.3371, stu_CELoss: 0.8034, DKDLoss: 0.5337, 
2022-07-30 02:13:30 - train: epoch 0067, iter [01100, 05004], lr: 0.001000, loss: 1.2380, stu_CELoss: 0.7527, DKDLoss: 0.4854, 
2022-07-30 02:14:04 - train: epoch 0067, iter [01200, 05004], lr: 0.001000, loss: 1.4243, stu_CELoss: 0.9540, DKDLoss: 0.4703, 
2022-07-30 02:14:37 - train: epoch 0067, iter [01300, 05004], lr: 0.001000, loss: 1.2846, stu_CELoss: 0.8198, DKDLoss: 0.4648, 
2022-07-30 02:15:11 - train: epoch 0067, iter [01400, 05004], lr: 0.001000, loss: 1.1988, stu_CELoss: 0.6970, DKDLoss: 0.5018, 
2022-07-30 02:15:45 - train: epoch 0067, iter [01500, 05004], lr: 0.001000, loss: 1.1495, stu_CELoss: 0.7128, DKDLoss: 0.4367, 
2022-07-30 02:16:19 - train: epoch 0067, iter [01600, 05004], lr: 0.001000, loss: 1.3266, stu_CELoss: 0.8785, DKDLoss: 0.4481, 
2022-07-30 02:16:53 - train: epoch 0067, iter [01700, 05004], lr: 0.001000, loss: 1.0589, stu_CELoss: 0.6342, DKDLoss: 0.4247, 
2022-07-30 02:17:27 - train: epoch 0067, iter [01800, 05004], lr: 0.001000, loss: 1.4622, stu_CELoss: 1.0080, DKDLoss: 0.4542, 
2022-07-30 02:18:00 - train: epoch 0067, iter [01900, 05004], lr: 0.001000, loss: 1.4923, stu_CELoss: 0.9919, DKDLoss: 0.5005, 
2022-07-30 02:18:34 - train: epoch 0067, iter [02000, 05004], lr: 0.001000, loss: 1.2791, stu_CELoss: 0.7297, DKDLoss: 0.5495, 
2022-07-30 02:19:08 - train: epoch 0067, iter [02100, 05004], lr: 0.001000, loss: 1.0013, stu_CELoss: 0.5565, DKDLoss: 0.4447, 
2022-07-30 02:19:42 - train: epoch 0067, iter [02200, 05004], lr: 0.001000, loss: 1.2078, stu_CELoss: 0.7317, DKDLoss: 0.4761, 
2022-07-30 02:20:16 - train: epoch 0067, iter [02300, 05004], lr: 0.001000, loss: 1.2984, stu_CELoss: 0.8208, DKDLoss: 0.4776, 
2022-07-30 02:20:50 - train: epoch 0067, iter [02400, 05004], lr: 0.001000, loss: 1.1725, stu_CELoss: 0.7640, DKDLoss: 0.4085, 
2022-07-30 02:21:23 - train: epoch 0067, iter [02500, 05004], lr: 0.001000, loss: 1.1913, stu_CELoss: 0.6874, DKDLoss: 0.5039, 
2022-07-30 02:21:57 - train: epoch 0067, iter [02600, 05004], lr: 0.001000, loss: 1.2671, stu_CELoss: 0.7728, DKDLoss: 0.4943, 
2022-07-30 02:22:31 - train: epoch 0067, iter [02700, 05004], lr: 0.001000, loss: 1.1482, stu_CELoss: 0.7023, DKDLoss: 0.4459, 
2022-07-30 02:23:06 - train: epoch 0067, iter [02800, 05004], lr: 0.001000, loss: 1.5079, stu_CELoss: 0.9374, DKDLoss: 0.5705, 
2022-07-30 02:23:39 - train: epoch 0067, iter [02900, 05004], lr: 0.001000, loss: 1.1967, stu_CELoss: 0.7381, DKDLoss: 0.4586, 
2022-07-30 02:24:13 - train: epoch 0067, iter [03000, 05004], lr: 0.001000, loss: 1.3162, stu_CELoss: 0.8238, DKDLoss: 0.4924, 
2022-07-30 02:24:47 - train: epoch 0067, iter [03100, 05004], lr: 0.001000, loss: 1.2478, stu_CELoss: 0.7568, DKDLoss: 0.4910, 
2022-07-30 02:25:21 - train: epoch 0067, iter [03200, 05004], lr: 0.001000, loss: 1.3720, stu_CELoss: 0.8687, DKDLoss: 0.5033, 
2022-07-30 02:25:55 - train: epoch 0067, iter [03300, 05004], lr: 0.001000, loss: 1.0312, stu_CELoss: 0.6324, DKDLoss: 0.3987, 
2022-07-30 02:26:29 - train: epoch 0067, iter [03400, 05004], lr: 0.001000, loss: 1.1011, stu_CELoss: 0.6302, DKDLoss: 0.4709, 
2022-07-30 02:27:04 - train: epoch 0067, iter [03500, 05004], lr: 0.001000, loss: 1.1829, stu_CELoss: 0.6964, DKDLoss: 0.4865, 
2022-07-30 02:27:38 - train: epoch 0067, iter [03600, 05004], lr: 0.001000, loss: 1.3945, stu_CELoss: 0.8036, DKDLoss: 0.5909, 
2022-07-30 02:28:11 - train: epoch 0067, iter [03700, 05004], lr: 0.001000, loss: 1.5023, stu_CELoss: 1.0438, DKDLoss: 0.4585, 
2022-07-30 02:28:45 - train: epoch 0067, iter [03800, 05004], lr: 0.001000, loss: 1.2464, stu_CELoss: 0.7643, DKDLoss: 0.4821, 
2022-07-30 02:29:19 - train: epoch 0067, iter [03900, 05004], lr: 0.001000, loss: 1.2884, stu_CELoss: 0.8352, DKDLoss: 0.4532, 
2022-07-30 02:29:54 - train: epoch 0067, iter [04000, 05004], lr: 0.001000, loss: 1.3025, stu_CELoss: 0.8539, DKDLoss: 0.4486, 
2022-07-30 02:30:28 - train: epoch 0067, iter [04100, 05004], lr: 0.001000, loss: 1.2058, stu_CELoss: 0.7718, DKDLoss: 0.4340, 
2022-07-30 02:31:02 - train: epoch 0067, iter [04200, 05004], lr: 0.001000, loss: 1.2872, stu_CELoss: 0.8386, DKDLoss: 0.4486, 
2022-07-30 02:31:36 - train: epoch 0067, iter [04300, 05004], lr: 0.001000, loss: 1.1527, stu_CELoss: 0.7122, DKDLoss: 0.4405, 
2022-07-30 02:32:11 - train: epoch 0067, iter [04400, 05004], lr: 0.001000, loss: 1.0938, stu_CELoss: 0.6752, DKDLoss: 0.4187, 
2022-07-30 02:32:46 - train: epoch 0067, iter [04500, 05004], lr: 0.001000, loss: 1.3337, stu_CELoss: 0.8150, DKDLoss: 0.5187, 
2022-07-30 02:33:19 - train: epoch 0067, iter [04600, 05004], lr: 0.001000, loss: 1.1630, stu_CELoss: 0.6915, DKDLoss: 0.4715, 
2022-07-30 02:33:54 - train: epoch 0067, iter [04700, 05004], lr: 0.001000, loss: 1.2873, stu_CELoss: 0.7624, DKDLoss: 0.5249, 
2022-07-30 02:34:28 - train: epoch 0067, iter [04800, 05004], lr: 0.001000, loss: 1.2590, stu_CELoss: 0.7758, DKDLoss: 0.4832, 
2022-07-30 02:35:02 - train: epoch 0067, iter [04900, 05004], lr: 0.001000, loss: 1.0012, stu_CELoss: 0.5933, DKDLoss: 0.4079, 
2022-07-30 02:35:35 - train: epoch 0067, iter [05000, 05004], lr: 0.001000, loss: 1.3448, stu_CELoss: 0.8809, DKDLoss: 0.4639, 
2022-07-30 02:35:37 - train: epoch 067, train_loss: 1.2795
2022-07-30 02:38:09 - eval: epoch: 067, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.014%, stu_acc5: 93.308%, stu_test_loss: 0.9093
2022-07-30 02:38:10 - until epoch: 067, tea_best_acc1: 78.068%, stu_best_acc1: 77.134%
2022-07-30 02:38:10 - epoch 068 lr: 0.001000
2022-07-30 02:38:50 - train: epoch 0068, iter [00100, 05004], lr: 0.001000, loss: 1.2854, stu_CELoss: 0.7955, DKDLoss: 0.4899, 
2022-07-30 02:39:23 - train: epoch 0068, iter [00200, 05004], lr: 0.001000, loss: 1.2348, stu_CELoss: 0.7971, DKDLoss: 0.4378, 
2022-07-30 02:39:57 - train: epoch 0068, iter [00300, 05004], lr: 0.001000, loss: 1.3501, stu_CELoss: 0.8956, DKDLoss: 0.4544, 
2022-07-30 02:40:30 - train: epoch 0068, iter [00400, 05004], lr: 0.001000, loss: 1.1982, stu_CELoss: 0.7982, DKDLoss: 0.3999, 
2022-07-30 02:41:04 - train: epoch 0068, iter [00500, 05004], lr: 0.001000, loss: 1.0747, stu_CELoss: 0.6624, DKDLoss: 0.4123, 
2022-07-30 02:41:38 - train: epoch 0068, iter [00600, 05004], lr: 0.001000, loss: 1.3184, stu_CELoss: 0.8306, DKDLoss: 0.4878, 
2022-07-30 02:42:11 - train: epoch 0068, iter [00700, 05004], lr: 0.001000, loss: 1.2639, stu_CELoss: 0.8073, DKDLoss: 0.4565, 
2022-07-30 02:42:45 - train: epoch 0068, iter [00800, 05004], lr: 0.001000, loss: 1.1770, stu_CELoss: 0.7573, DKDLoss: 0.4197, 
2022-07-30 02:43:19 - train: epoch 0068, iter [00900, 05004], lr: 0.001000, loss: 1.2729, stu_CELoss: 0.8577, DKDLoss: 0.4153, 
2022-07-30 02:43:53 - train: epoch 0068, iter [01000, 05004], lr: 0.001000, loss: 1.2455, stu_CELoss: 0.7269, DKDLoss: 0.5186, 
2022-07-30 02:44:26 - train: epoch 0068, iter [01100, 05004], lr: 0.001000, loss: 1.4435, stu_CELoss: 0.9113, DKDLoss: 0.5322, 
2022-07-30 02:45:00 - train: epoch 0068, iter [01200, 05004], lr: 0.001000, loss: 1.1889, stu_CELoss: 0.7132, DKDLoss: 0.4756, 
2022-07-30 02:45:34 - train: epoch 0068, iter [01300, 05004], lr: 0.001000, loss: 1.2117, stu_CELoss: 0.7809, DKDLoss: 0.4308, 
2022-07-30 02:46:08 - train: epoch 0068, iter [01400, 05004], lr: 0.001000, loss: 1.2696, stu_CELoss: 0.7976, DKDLoss: 0.4721, 
2022-07-30 02:46:42 - train: epoch 0068, iter [01500, 05004], lr: 0.001000, loss: 1.3310, stu_CELoss: 0.8430, DKDLoss: 0.4880, 
2022-07-30 02:47:16 - train: epoch 0068, iter [01600, 05004], lr: 0.001000, loss: 1.3314, stu_CELoss: 0.8095, DKDLoss: 0.5219, 
2022-07-30 02:47:50 - train: epoch 0068, iter [01700, 05004], lr: 0.001000, loss: 1.2240, stu_CELoss: 0.7979, DKDLoss: 0.4261, 
2022-07-30 02:48:24 - train: epoch 0068, iter [01800, 05004], lr: 0.001000, loss: 1.2962, stu_CELoss: 0.8510, DKDLoss: 0.4452, 
2022-07-30 02:48:58 - train: epoch 0068, iter [01900, 05004], lr: 0.001000, loss: 1.2378, stu_CELoss: 0.7684, DKDLoss: 0.4694, 
2022-07-30 02:49:33 - train: epoch 0068, iter [02000, 05004], lr: 0.001000, loss: 1.2646, stu_CELoss: 0.7764, DKDLoss: 0.4882, 
2022-07-30 02:50:07 - train: epoch 0068, iter [02100, 05004], lr: 0.001000, loss: 1.2473, stu_CELoss: 0.7642, DKDLoss: 0.4831, 
2022-07-30 02:50:41 - train: epoch 0068, iter [02200, 05004], lr: 0.001000, loss: 1.1886, stu_CELoss: 0.7551, DKDLoss: 0.4335, 
2022-07-30 02:51:15 - train: epoch 0068, iter [02300, 05004], lr: 0.001000, loss: 1.1772, stu_CELoss: 0.7055, DKDLoss: 0.4717, 
2022-07-30 02:51:49 - train: epoch 0068, iter [02400, 05004], lr: 0.001000, loss: 1.1828, stu_CELoss: 0.7335, DKDLoss: 0.4493, 
2022-07-30 02:52:22 - train: epoch 0068, iter [02500, 05004], lr: 0.001000, loss: 1.2083, stu_CELoss: 0.7644, DKDLoss: 0.4439, 
2022-07-30 02:52:56 - train: epoch 0068, iter [02600, 05004], lr: 0.001000, loss: 1.0689, stu_CELoss: 0.6303, DKDLoss: 0.4386, 
2022-07-30 02:53:30 - train: epoch 0068, iter [02700, 05004], lr: 0.001000, loss: 1.2625, stu_CELoss: 0.7871, DKDLoss: 0.4753, 
2022-07-30 02:54:04 - train: epoch 0068, iter [02800, 05004], lr: 0.001000, loss: 1.4182, stu_CELoss: 0.8679, DKDLoss: 0.5503, 
2022-07-30 02:54:38 - train: epoch 0068, iter [02900, 05004], lr: 0.001000, loss: 1.3485, stu_CELoss: 0.8361, DKDLoss: 0.5124, 
2022-07-30 02:55:12 - train: epoch 0068, iter [03000, 05004], lr: 0.001000, loss: 1.4038, stu_CELoss: 0.9435, DKDLoss: 0.4603, 
2022-07-30 02:55:46 - train: epoch 0068, iter [03100, 05004], lr: 0.001000, loss: 1.2979, stu_CELoss: 0.8934, DKDLoss: 0.4045, 
2022-07-30 02:56:20 - train: epoch 0068, iter [03200, 05004], lr: 0.001000, loss: 1.2759, stu_CELoss: 0.7414, DKDLoss: 0.5345, 
2022-07-30 02:56:54 - train: epoch 0068, iter [03300, 05004], lr: 0.001000, loss: 1.0907, stu_CELoss: 0.6439, DKDLoss: 0.4468, 
2022-07-30 02:57:27 - train: epoch 0068, iter [03400, 05004], lr: 0.001000, loss: 1.2327, stu_CELoss: 0.7801, DKDLoss: 0.4526, 
2022-07-30 02:58:01 - train: epoch 0068, iter [03500, 05004], lr: 0.001000, loss: 1.2002, stu_CELoss: 0.7438, DKDLoss: 0.4564, 
2022-07-30 02:58:35 - train: epoch 0068, iter [03600, 05004], lr: 0.001000, loss: 1.3749, stu_CELoss: 0.8451, DKDLoss: 0.5298, 
2022-07-30 02:59:09 - train: epoch 0068, iter [03700, 05004], lr: 0.001000, loss: 1.4617, stu_CELoss: 0.9690, DKDLoss: 0.4928, 
2022-07-30 02:59:43 - train: epoch 0068, iter [03800, 05004], lr: 0.001000, loss: 1.3647, stu_CELoss: 0.8813, DKDLoss: 0.4834, 
2022-07-30 03:00:17 - train: epoch 0068, iter [03900, 05004], lr: 0.001000, loss: 1.4708, stu_CELoss: 0.9623, DKDLoss: 0.5085, 
2022-07-30 03:00:51 - train: epoch 0068, iter [04000, 05004], lr: 0.001000, loss: 1.4819, stu_CELoss: 1.0113, DKDLoss: 0.4706, 
2022-07-30 03:01:26 - train: epoch 0068, iter [04100, 05004], lr: 0.001000, loss: 1.2259, stu_CELoss: 0.6870, DKDLoss: 0.5388, 
2022-07-30 03:02:00 - train: epoch 0068, iter [04200, 05004], lr: 0.001000, loss: 1.2041, stu_CELoss: 0.7019, DKDLoss: 0.5021, 
2022-07-30 03:02:34 - train: epoch 0068, iter [04300, 05004], lr: 0.001000, loss: 1.4621, stu_CELoss: 0.9941, DKDLoss: 0.4679, 
2022-07-30 03:03:08 - train: epoch 0068, iter [04400, 05004], lr: 0.001000, loss: 1.1778, stu_CELoss: 0.6895, DKDLoss: 0.4883, 
2022-07-30 03:03:43 - train: epoch 0068, iter [04500, 05004], lr: 0.001000, loss: 1.2725, stu_CELoss: 0.7901, DKDLoss: 0.4825, 
2022-07-30 03:04:17 - train: epoch 0068, iter [04600, 05004], lr: 0.001000, loss: 1.3067, stu_CELoss: 0.8148, DKDLoss: 0.4919, 
2022-07-30 03:04:51 - train: epoch 0068, iter [04700, 05004], lr: 0.001000, loss: 1.5491, stu_CELoss: 1.0398, DKDLoss: 0.5093, 
2022-07-30 03:05:25 - train: epoch 0068, iter [04800, 05004], lr: 0.001000, loss: 1.2990, stu_CELoss: 0.7769, DKDLoss: 0.5221, 
2022-07-30 03:06:00 - train: epoch 0068, iter [04900, 05004], lr: 0.001000, loss: 1.2424, stu_CELoss: 0.7668, DKDLoss: 0.4755, 
2022-07-30 03:06:34 - train: epoch 0068, iter [05000, 05004], lr: 0.001000, loss: 1.1931, stu_CELoss: 0.7130, DKDLoss: 0.4801, 
2022-07-30 03:06:35 - train: epoch 068, train_loss: 1.2699
2022-07-30 03:09:07 - eval: epoch: 068, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.118%, stu_acc5: 93.348%, stu_test_loss: 0.9051
2022-07-30 03:09:07 - until epoch: 068, tea_best_acc1: 78.068%, stu_best_acc1: 77.134%
2022-07-30 03:09:07 - epoch 069 lr: 0.001000
2022-07-30 03:09:47 - train: epoch 0069, iter [00100, 05004], lr: 0.001000, loss: 1.2859, stu_CELoss: 0.8508, DKDLoss: 0.4351, 
2022-07-30 03:10:21 - train: epoch 0069, iter [00200, 05004], lr: 0.001000, loss: 1.1964, stu_CELoss: 0.7543, DKDLoss: 0.4421, 
2022-07-30 03:10:54 - train: epoch 0069, iter [00300, 05004], lr: 0.001000, loss: 1.2381, stu_CELoss: 0.7791, DKDLoss: 0.4590, 
2022-07-30 03:11:28 - train: epoch 0069, iter [00400, 05004], lr: 0.001000, loss: 1.1656, stu_CELoss: 0.7543, DKDLoss: 0.4113, 
2022-07-30 03:12:01 - train: epoch 0069, iter [00500, 05004], lr: 0.001000, loss: 1.3098, stu_CELoss: 0.8623, DKDLoss: 0.4475, 
2022-07-30 03:12:35 - train: epoch 0069, iter [00600, 05004], lr: 0.001000, loss: 1.2036, stu_CELoss: 0.7936, DKDLoss: 0.4100, 
2022-07-30 03:13:09 - train: epoch 0069, iter [00700, 05004], lr: 0.001000, loss: 1.3095, stu_CELoss: 0.8088, DKDLoss: 0.5006, 
2022-07-30 03:13:43 - train: epoch 0069, iter [00800, 05004], lr: 0.001000, loss: 1.1337, stu_CELoss: 0.6517, DKDLoss: 0.4820, 
2022-07-30 03:14:17 - train: epoch 0069, iter [00900, 05004], lr: 0.001000, loss: 1.1121, stu_CELoss: 0.6079, DKDLoss: 0.5043, 
2022-07-30 03:14:51 - train: epoch 0069, iter [01000, 05004], lr: 0.001000, loss: 1.4135, stu_CELoss: 0.8622, DKDLoss: 0.5513, 
2022-07-30 03:15:25 - train: epoch 0069, iter [01100, 05004], lr: 0.001000, loss: 1.2886, stu_CELoss: 0.8087, DKDLoss: 0.4799, 
2022-07-30 03:15:59 - train: epoch 0069, iter [01200, 05004], lr: 0.001000, loss: 1.1536, stu_CELoss: 0.7322, DKDLoss: 0.4214, 
2022-07-30 03:16:33 - train: epoch 0069, iter [01300, 05004], lr: 0.001000, loss: 1.1926, stu_CELoss: 0.7634, DKDLoss: 0.4292, 
2022-07-30 03:17:07 - train: epoch 0069, iter [01400, 05004], lr: 0.001000, loss: 1.3057, stu_CELoss: 0.8058, DKDLoss: 0.4999, 
2022-07-30 03:17:41 - train: epoch 0069, iter [01500, 05004], lr: 0.001000, loss: 1.1923, stu_CELoss: 0.7093, DKDLoss: 0.4831, 
2022-07-30 03:18:13 - train: epoch 0069, iter [01600, 05004], lr: 0.001000, loss: 1.4695, stu_CELoss: 1.0133, DKDLoss: 0.4563, 
2022-07-30 03:18:46 - train: epoch 0069, iter [01700, 05004], lr: 0.001000, loss: 1.2871, stu_CELoss: 0.8178, DKDLoss: 0.4693, 
2022-07-30 03:19:19 - train: epoch 0069, iter [01800, 05004], lr: 0.001000, loss: 1.1271, stu_CELoss: 0.7000, DKDLoss: 0.4271, 
2022-07-30 03:19:52 - train: epoch 0069, iter [01900, 05004], lr: 0.001000, loss: 1.2128, stu_CELoss: 0.7429, DKDLoss: 0.4699, 
2022-07-30 03:20:24 - train: epoch 0069, iter [02000, 05004], lr: 0.001000, loss: 1.1591, stu_CELoss: 0.7023, DKDLoss: 0.4568, 
2022-07-30 03:20:57 - train: epoch 0069, iter [02100, 05004], lr: 0.001000, loss: 1.3876, stu_CELoss: 0.9014, DKDLoss: 0.4862, 
2022-07-30 03:21:30 - train: epoch 0069, iter [02200, 05004], lr: 0.001000, loss: 1.4207, stu_CELoss: 0.8886, DKDLoss: 0.5321, 
2022-07-30 03:22:03 - train: epoch 0069, iter [02300, 05004], lr: 0.001000, loss: 1.0826, stu_CELoss: 0.6273, DKDLoss: 0.4553, 
2022-07-30 03:22:35 - train: epoch 0069, iter [02400, 05004], lr: 0.001000, loss: 1.2399, stu_CELoss: 0.7663, DKDLoss: 0.4736, 
2022-07-30 03:23:08 - train: epoch 0069, iter [02500, 05004], lr: 0.001000, loss: 1.1372, stu_CELoss: 0.7037, DKDLoss: 0.4335, 
2022-07-30 03:23:41 - train: epoch 0069, iter [02600, 05004], lr: 0.001000, loss: 1.1604, stu_CELoss: 0.7450, DKDLoss: 0.4155, 
2022-07-30 03:24:14 - train: epoch 0069, iter [02700, 05004], lr: 0.001000, loss: 1.4146, stu_CELoss: 0.9536, DKDLoss: 0.4610, 
2022-07-30 03:24:46 - train: epoch 0069, iter [02800, 05004], lr: 0.001000, loss: 1.3815, stu_CELoss: 0.9135, DKDLoss: 0.4680, 
2022-07-30 03:25:19 - train: epoch 0069, iter [02900, 05004], lr: 0.001000, loss: 1.3263, stu_CELoss: 0.8134, DKDLoss: 0.5128, 
2022-07-30 03:25:52 - train: epoch 0069, iter [03000, 05004], lr: 0.001000, loss: 1.2165, stu_CELoss: 0.7604, DKDLoss: 0.4561, 
2022-07-30 03:26:25 - train: epoch 0069, iter [03100, 05004], lr: 0.001000, loss: 1.3701, stu_CELoss: 0.8997, DKDLoss: 0.4704, 
2022-07-30 03:26:58 - train: epoch 0069, iter [03200, 05004], lr: 0.001000, loss: 1.0775, stu_CELoss: 0.6372, DKDLoss: 0.4403, 
2022-07-30 03:27:31 - train: epoch 0069, iter [03300, 05004], lr: 0.001000, loss: 1.2762, stu_CELoss: 0.8177, DKDLoss: 0.4585, 
2022-07-30 03:28:04 - train: epoch 0069, iter [03400, 05004], lr: 0.001000, loss: 1.3303, stu_CELoss: 0.8701, DKDLoss: 0.4602, 
2022-07-30 03:28:36 - train: epoch 0069, iter [03500, 05004], lr: 0.001000, loss: 1.0624, stu_CELoss: 0.6399, DKDLoss: 0.4226, 
2022-07-30 03:29:09 - train: epoch 0069, iter [03600, 05004], lr: 0.001000, loss: 1.0913, stu_CELoss: 0.6388, DKDLoss: 0.4525, 
2022-07-30 03:29:42 - train: epoch 0069, iter [03700, 05004], lr: 0.001000, loss: 1.2649, stu_CELoss: 0.7615, DKDLoss: 0.5034, 
2022-07-30 03:30:14 - train: epoch 0069, iter [03800, 05004], lr: 0.001000, loss: 1.2622, stu_CELoss: 0.8485, DKDLoss: 0.4137, 
2022-07-30 03:30:47 - train: epoch 0069, iter [03900, 05004], lr: 0.001000, loss: 1.5111, stu_CELoss: 1.0182, DKDLoss: 0.4929, 
2022-07-30 03:31:20 - train: epoch 0069, iter [04000, 05004], lr: 0.001000, loss: 1.3579, stu_CELoss: 0.8513, DKDLoss: 0.5066, 
2022-07-30 03:31:52 - train: epoch 0069, iter [04100, 05004], lr: 0.001000, loss: 1.2516, stu_CELoss: 0.7828, DKDLoss: 0.4687, 
2022-07-30 03:32:25 - train: epoch 0069, iter [04200, 05004], lr: 0.001000, loss: 1.3034, stu_CELoss: 0.7705, DKDLoss: 0.5329, 
2022-07-30 03:32:57 - train: epoch 0069, iter [04300, 05004], lr: 0.001000, loss: 1.1699, stu_CELoss: 0.6715, DKDLoss: 0.4984, 
2022-07-30 03:33:30 - train: epoch 0069, iter [04400, 05004], lr: 0.001000, loss: 1.2847, stu_CELoss: 0.7735, DKDLoss: 0.5112, 
2022-07-30 03:34:02 - train: epoch 0069, iter [04500, 05004], lr: 0.001000, loss: 1.2654, stu_CELoss: 0.7317, DKDLoss: 0.5338, 
2022-07-30 03:34:34 - train: epoch 0069, iter [04600, 05004], lr: 0.001000, loss: 1.2750, stu_CELoss: 0.8166, DKDLoss: 0.4583, 
2022-07-30 03:35:07 - train: epoch 0069, iter [04700, 05004], lr: 0.001000, loss: 1.3080, stu_CELoss: 0.8562, DKDLoss: 0.4517, 
2022-07-30 03:35:39 - train: epoch 0069, iter [04800, 05004], lr: 0.001000, loss: 1.2899, stu_CELoss: 0.7921, DKDLoss: 0.4978, 
2022-07-30 03:36:12 - train: epoch 0069, iter [04900, 05004], lr: 0.001000, loss: 1.1134, stu_CELoss: 0.7089, DKDLoss: 0.4045, 
2022-07-30 03:36:44 - train: epoch 0069, iter [05000, 05004], lr: 0.001000, loss: 1.1658, stu_CELoss: 0.6861, DKDLoss: 0.4797, 
2022-07-30 03:36:46 - train: epoch 069, train_loss: 1.2549
2022-07-30 03:39:14 - eval: epoch: 069, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.138%, stu_acc5: 93.372%, stu_test_loss: 0.9077
2022-07-30 03:39:15 - until epoch: 069, tea_best_acc1: 78.068%, stu_best_acc1: 77.138%
2022-07-30 03:39:15 - epoch 070 lr: 0.001000
2022-07-30 03:39:53 - train: epoch 0070, iter [00100, 05004], lr: 0.001000, loss: 1.1962, stu_CELoss: 0.7654, DKDLoss: 0.4308, 
2022-07-30 03:40:25 - train: epoch 0070, iter [00200, 05004], lr: 0.001000, loss: 1.2905, stu_CELoss: 0.8277, DKDLoss: 0.4628, 
2022-07-30 03:40:57 - train: epoch 0070, iter [00300, 05004], lr: 0.001000, loss: 1.4695, stu_CELoss: 1.0098, DKDLoss: 0.4597, 
2022-07-30 03:41:28 - train: epoch 0070, iter [00400, 05004], lr: 0.001000, loss: 1.1796, stu_CELoss: 0.7450, DKDLoss: 0.4346, 
2022-07-30 03:42:00 - train: epoch 0070, iter [00500, 05004], lr: 0.001000, loss: 1.2453, stu_CELoss: 0.8047, DKDLoss: 0.4406, 
2022-07-30 03:42:32 - train: epoch 0070, iter [00600, 05004], lr: 0.001000, loss: 1.1526, stu_CELoss: 0.7091, DKDLoss: 0.4435, 
2022-07-30 03:43:05 - train: epoch 0070, iter [00700, 05004], lr: 0.001000, loss: 1.1168, stu_CELoss: 0.6888, DKDLoss: 0.4280, 
2022-07-30 03:43:37 - train: epoch 0070, iter [00800, 05004], lr: 0.001000, loss: 1.1484, stu_CELoss: 0.6768, DKDLoss: 0.4716, 
2022-07-30 03:44:10 - train: epoch 0070, iter [00900, 05004], lr: 0.001000, loss: 1.0798, stu_CELoss: 0.6259, DKDLoss: 0.4539, 
2022-07-30 03:44:42 - train: epoch 0070, iter [01000, 05004], lr: 0.001000, loss: 1.1824, stu_CELoss: 0.7668, DKDLoss: 0.4155, 
2022-07-30 03:45:15 - train: epoch 0070, iter [01100, 05004], lr: 0.001000, loss: 1.4070, stu_CELoss: 0.9251, DKDLoss: 0.4819, 
2022-07-30 03:45:47 - train: epoch 0070, iter [01200, 05004], lr: 0.001000, loss: 1.2650, stu_CELoss: 0.8140, DKDLoss: 0.4510, 
2022-07-30 03:46:20 - train: epoch 0070, iter [01300, 05004], lr: 0.001000, loss: 1.1748, stu_CELoss: 0.7313, DKDLoss: 0.4435, 
2022-07-30 03:46:52 - train: epoch 0070, iter [01400, 05004], lr: 0.001000, loss: 1.0953, stu_CELoss: 0.6710, DKDLoss: 0.4243, 
2022-07-30 03:47:25 - train: epoch 0070, iter [01500, 05004], lr: 0.001000, loss: 1.2215, stu_CELoss: 0.7813, DKDLoss: 0.4402, 
2022-07-30 03:47:58 - train: epoch 0070, iter [01600, 05004], lr: 0.001000, loss: 1.2809, stu_CELoss: 0.8110, DKDLoss: 0.4699, 
2022-07-30 03:48:30 - train: epoch 0070, iter [01700, 05004], lr: 0.001000, loss: 1.0549, stu_CELoss: 0.5826, DKDLoss: 0.4722, 
2022-07-30 03:49:03 - train: epoch 0070, iter [01800, 05004], lr: 0.001000, loss: 1.2460, stu_CELoss: 0.7403, DKDLoss: 0.5057, 
2022-07-30 03:49:36 - train: epoch 0070, iter [01900, 05004], lr: 0.001000, loss: 0.9868, stu_CELoss: 0.5234, DKDLoss: 0.4634, 
2022-07-30 03:50:08 - train: epoch 0070, iter [02000, 05004], lr: 0.001000, loss: 1.2208, stu_CELoss: 0.7647, DKDLoss: 0.4561, 
2022-07-30 03:50:41 - train: epoch 0070, iter [02100, 05004], lr: 0.001000, loss: 1.2640, stu_CELoss: 0.7762, DKDLoss: 0.4878, 
2022-07-30 03:51:14 - train: epoch 0070, iter [02200, 05004], lr: 0.001000, loss: 1.0902, stu_CELoss: 0.6503, DKDLoss: 0.4398, 
2022-07-30 03:51:47 - train: epoch 0070, iter [02300, 05004], lr: 0.001000, loss: 1.1405, stu_CELoss: 0.7041, DKDLoss: 0.4364, 
2022-07-30 03:52:20 - train: epoch 0070, iter [02400, 05004], lr: 0.001000, loss: 1.2864, stu_CELoss: 0.8371, DKDLoss: 0.4493, 
2022-07-30 03:52:52 - train: epoch 0070, iter [02500, 05004], lr: 0.001000, loss: 1.2773, stu_CELoss: 0.8310, DKDLoss: 0.4463, 
2022-07-30 03:53:25 - train: epoch 0070, iter [02600, 05004], lr: 0.001000, loss: 1.2090, stu_CELoss: 0.7239, DKDLoss: 0.4851, 
2022-07-30 03:53:57 - train: epoch 0070, iter [02700, 05004], lr: 0.001000, loss: 1.1097, stu_CELoss: 0.6477, DKDLoss: 0.4621, 
2022-07-30 03:54:30 - train: epoch 0070, iter [02800, 05004], lr: 0.001000, loss: 1.3335, stu_CELoss: 0.8529, DKDLoss: 0.4806, 
2022-07-30 03:55:03 - train: epoch 0070, iter [02900, 05004], lr: 0.001000, loss: 1.1722, stu_CELoss: 0.7264, DKDLoss: 0.4458, 
2022-07-30 03:55:35 - train: epoch 0070, iter [03000, 05004], lr: 0.001000, loss: 1.1948, stu_CELoss: 0.7319, DKDLoss: 0.4629, 
2022-07-30 03:56:07 - train: epoch 0070, iter [03100, 05004], lr: 0.001000, loss: 1.1669, stu_CELoss: 0.6961, DKDLoss: 0.4709, 
2022-07-30 03:56:40 - train: epoch 0070, iter [03200, 05004], lr: 0.001000, loss: 1.3349, stu_CELoss: 0.7760, DKDLoss: 0.5589, 
2022-07-30 03:57:12 - train: epoch 0070, iter [03300, 05004], lr: 0.001000, loss: 1.0874, stu_CELoss: 0.6593, DKDLoss: 0.4281, 
2022-07-30 03:57:45 - train: epoch 0070, iter [03400, 05004], lr: 0.001000, loss: 1.1065, stu_CELoss: 0.6884, DKDLoss: 0.4181, 
2022-07-30 03:58:17 - train: epoch 0070, iter [03500, 05004], lr: 0.001000, loss: 1.2007, stu_CELoss: 0.6715, DKDLoss: 0.5293, 
2022-07-30 03:58:50 - train: epoch 0070, iter [03600, 05004], lr: 0.001000, loss: 1.1959, stu_CELoss: 0.7151, DKDLoss: 0.4807, 
2022-07-30 03:59:23 - train: epoch 0070, iter [03700, 05004], lr: 0.001000, loss: 1.0717, stu_CELoss: 0.6642, DKDLoss: 0.4075, 
2022-07-30 03:59:55 - train: epoch 0070, iter [03800, 05004], lr: 0.001000, loss: 1.1340, stu_CELoss: 0.6470, DKDLoss: 0.4870, 
2022-07-30 04:00:28 - train: epoch 0070, iter [03900, 05004], lr: 0.001000, loss: 1.1478, stu_CELoss: 0.6710, DKDLoss: 0.4769, 
2022-07-30 04:01:00 - train: epoch 0070, iter [04000, 05004], lr: 0.001000, loss: 1.2719, stu_CELoss: 0.8157, DKDLoss: 0.4562, 
2022-07-30 04:01:33 - train: epoch 0070, iter [04100, 05004], lr: 0.001000, loss: 1.3070, stu_CELoss: 0.8477, DKDLoss: 0.4593, 
2022-07-30 04:02:06 - train: epoch 0070, iter [04200, 05004], lr: 0.001000, loss: 1.1727, stu_CELoss: 0.7148, DKDLoss: 0.4579, 
2022-07-30 04:02:38 - train: epoch 0070, iter [04300, 05004], lr: 0.001000, loss: 1.2576, stu_CELoss: 0.7720, DKDLoss: 0.4856, 
2022-07-30 04:03:11 - train: epoch 0070, iter [04400, 05004], lr: 0.001000, loss: 1.3565, stu_CELoss: 0.8596, DKDLoss: 0.4970, 
2022-07-30 04:03:44 - train: epoch 0070, iter [04500, 05004], lr: 0.001000, loss: 1.4528, stu_CELoss: 0.9764, DKDLoss: 0.4764, 
2022-07-30 04:04:16 - train: epoch 0070, iter [04600, 05004], lr: 0.001000, loss: 1.3383, stu_CELoss: 0.8186, DKDLoss: 0.5197, 
2022-07-30 04:04:49 - train: epoch 0070, iter [04700, 05004], lr: 0.001000, loss: 1.1528, stu_CELoss: 0.7228, DKDLoss: 0.4300, 
2022-07-30 04:05:21 - train: epoch 0070, iter [04800, 05004], lr: 0.001000, loss: 1.2264, stu_CELoss: 0.7516, DKDLoss: 0.4748, 
2022-07-30 04:05:54 - train: epoch 0070, iter [04900, 05004], lr: 0.001000, loss: 1.2286, stu_CELoss: 0.7576, DKDLoss: 0.4710, 
2022-07-30 04:06:26 - train: epoch 0070, iter [05000, 05004], lr: 0.001000, loss: 1.2290, stu_CELoss: 0.6983, DKDLoss: 0.5308, 
2022-07-30 04:06:28 - train: epoch 070, train_loss: 1.2475
2022-07-30 04:08:55 - eval: epoch: 070, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.220%, stu_acc5: 93.424%, stu_test_loss: 0.9064
2022-07-30 04:08:56 - until epoch: 070, tea_best_acc1: 78.068%, stu_best_acc1: 77.220%
2022-07-30 04:08:56 - epoch 071 lr: 0.001000
2022-07-30 04:09:35 - train: epoch 0071, iter [00100, 05004], lr: 0.001000, loss: 1.0932, stu_CELoss: 0.6887, DKDLoss: 0.4045, 
2022-07-30 04:10:08 - train: epoch 0071, iter [00200, 05004], lr: 0.001000, loss: 1.1727, stu_CELoss: 0.7083, DKDLoss: 0.4644, 
2022-07-30 04:10:40 - train: epoch 0071, iter [00300, 05004], lr: 0.001000, loss: 1.4442, stu_CELoss: 0.9366, DKDLoss: 0.5076, 
2022-07-30 04:11:13 - train: epoch 0071, iter [00400, 05004], lr: 0.001000, loss: 1.2224, stu_CELoss: 0.7310, DKDLoss: 0.4913, 
2022-07-30 04:11:46 - train: epoch 0071, iter [00500, 05004], lr: 0.001000, loss: 1.2346, stu_CELoss: 0.7421, DKDLoss: 0.4926, 
2022-07-30 04:12:18 - train: epoch 0071, iter [00600, 05004], lr: 0.001000, loss: 1.2468, stu_CELoss: 0.8034, DKDLoss: 0.4434, 
2022-07-30 04:12:51 - train: epoch 0071, iter [00700, 05004], lr: 0.001000, loss: 1.3174, stu_CELoss: 0.8701, DKDLoss: 0.4473, 
2022-07-30 04:13:24 - train: epoch 0071, iter [00800, 05004], lr: 0.001000, loss: 1.4410, stu_CELoss: 0.9435, DKDLoss: 0.4976, 
2022-07-30 04:13:56 - train: epoch 0071, iter [00900, 05004], lr: 0.001000, loss: 1.3674, stu_CELoss: 0.8963, DKDLoss: 0.4710, 
2022-07-30 04:14:29 - train: epoch 0071, iter [01000, 05004], lr: 0.001000, loss: 1.3872, stu_CELoss: 0.9383, DKDLoss: 0.4489, 
2022-07-30 04:15:02 - train: epoch 0071, iter [01100, 05004], lr: 0.001000, loss: 1.3954, stu_CELoss: 0.9026, DKDLoss: 0.4927, 
2022-07-30 04:15:34 - train: epoch 0071, iter [01200, 05004], lr: 0.001000, loss: 1.1509, stu_CELoss: 0.7216, DKDLoss: 0.4293, 
2022-07-30 04:16:07 - train: epoch 0071, iter [01300, 05004], lr: 0.001000, loss: 1.0779, stu_CELoss: 0.6462, DKDLoss: 0.4317, 
2022-07-30 04:16:40 - train: epoch 0071, iter [01400, 05004], lr: 0.001000, loss: 1.2958, stu_CELoss: 0.7903, DKDLoss: 0.5054, 
2022-07-30 04:17:13 - train: epoch 0071, iter [01500, 05004], lr: 0.001000, loss: 1.1149, stu_CELoss: 0.6524, DKDLoss: 0.4625, 
2022-07-30 04:17:46 - train: epoch 0071, iter [01600, 05004], lr: 0.001000, loss: 1.2795, stu_CELoss: 0.7572, DKDLoss: 0.5223, 
2022-07-30 04:18:18 - train: epoch 0071, iter [01700, 05004], lr: 0.001000, loss: 1.2214, stu_CELoss: 0.7771, DKDLoss: 0.4443, 
2022-07-30 04:18:51 - train: epoch 0071, iter [01800, 05004], lr: 0.001000, loss: 1.2420, stu_CELoss: 0.7814, DKDLoss: 0.4606, 
2022-07-30 04:19:23 - train: epoch 0071, iter [01900, 05004], lr: 0.001000, loss: 1.2142, stu_CELoss: 0.7579, DKDLoss: 0.4563, 
2022-07-30 04:19:55 - train: epoch 0071, iter [02000, 05004], lr: 0.001000, loss: 1.3019, stu_CELoss: 0.8387, DKDLoss: 0.4632, 
2022-07-30 04:20:28 - train: epoch 0071, iter [02100, 05004], lr: 0.001000, loss: 1.0097, stu_CELoss: 0.6032, DKDLoss: 0.4065, 
2022-07-30 04:21:01 - train: epoch 0071, iter [02200, 05004], lr: 0.001000, loss: 1.1887, stu_CELoss: 0.7515, DKDLoss: 0.4372, 
2022-07-30 04:21:34 - train: epoch 0071, iter [02300, 05004], lr: 0.001000, loss: 1.3762, stu_CELoss: 0.9186, DKDLoss: 0.4575, 
2022-07-30 04:22:06 - train: epoch 0071, iter [02400, 05004], lr: 0.001000, loss: 1.1141, stu_CELoss: 0.6592, DKDLoss: 0.4549, 
2022-07-30 04:22:39 - train: epoch 0071, iter [02500, 05004], lr: 0.001000, loss: 1.2867, stu_CELoss: 0.8009, DKDLoss: 0.4858, 
2022-07-30 04:23:12 - train: epoch 0071, iter [02600, 05004], lr: 0.001000, loss: 1.2764, stu_CELoss: 0.8041, DKDLoss: 0.4724, 
2022-07-30 04:23:44 - train: epoch 0071, iter [02700, 05004], lr: 0.001000, loss: 1.1677, stu_CELoss: 0.7449, DKDLoss: 0.4227, 
2022-07-30 04:24:17 - train: epoch 0071, iter [02800, 05004], lr: 0.001000, loss: 1.3587, stu_CELoss: 0.8574, DKDLoss: 0.5013, 
2022-07-30 04:24:49 - train: epoch 0071, iter [02900, 05004], lr: 0.001000, loss: 1.2949, stu_CELoss: 0.8492, DKDLoss: 0.4457, 
2022-07-30 04:25:22 - train: epoch 0071, iter [03000, 05004], lr: 0.001000, loss: 1.2367, stu_CELoss: 0.7396, DKDLoss: 0.4971, 
2022-07-30 04:25:54 - train: epoch 0071, iter [03100, 05004], lr: 0.001000, loss: 1.1904, stu_CELoss: 0.7561, DKDLoss: 0.4343, 
2022-07-30 04:26:27 - train: epoch 0071, iter [03200, 05004], lr: 0.001000, loss: 1.1784, stu_CELoss: 0.7277, DKDLoss: 0.4507, 
2022-07-30 04:27:00 - train: epoch 0071, iter [03300, 05004], lr: 0.001000, loss: 1.2629, stu_CELoss: 0.8431, DKDLoss: 0.4197, 
2022-07-30 04:27:32 - train: epoch 0071, iter [03400, 05004], lr: 0.001000, loss: 1.1134, stu_CELoss: 0.7109, DKDLoss: 0.4025, 
2022-07-30 04:28:05 - train: epoch 0071, iter [03500, 05004], lr: 0.001000, loss: 1.2437, stu_CELoss: 0.7898, DKDLoss: 0.4539, 
2022-07-30 04:28:38 - train: epoch 0071, iter [03600, 05004], lr: 0.001000, loss: 1.1392, stu_CELoss: 0.7159, DKDLoss: 0.4232, 
2022-07-30 04:29:11 - train: epoch 0071, iter [03700, 05004], lr: 0.001000, loss: 1.3639, stu_CELoss: 0.8997, DKDLoss: 0.4642, 
2022-07-30 04:29:44 - train: epoch 0071, iter [03800, 05004], lr: 0.001000, loss: 1.2889, stu_CELoss: 0.8191, DKDLoss: 0.4698, 
2022-07-30 04:30:16 - train: epoch 0071, iter [03900, 05004], lr: 0.001000, loss: 1.2781, stu_CELoss: 0.8662, DKDLoss: 0.4119, 
2022-07-30 04:30:48 - train: epoch 0071, iter [04000, 05004], lr: 0.001000, loss: 1.1701, stu_CELoss: 0.7069, DKDLoss: 0.4632, 
2022-07-30 04:31:21 - train: epoch 0071, iter [04100, 05004], lr: 0.001000, loss: 1.1119, stu_CELoss: 0.6644, DKDLoss: 0.4475, 
2022-07-30 04:31:54 - train: epoch 0071, iter [04200, 05004], lr: 0.001000, loss: 1.4081, stu_CELoss: 0.8981, DKDLoss: 0.5100, 
2022-07-30 04:32:26 - train: epoch 0071, iter [04300, 05004], lr: 0.001000, loss: 1.1197, stu_CELoss: 0.6552, DKDLoss: 0.4645, 
2022-07-30 04:32:59 - train: epoch 0071, iter [04400, 05004], lr: 0.001000, loss: 1.1898, stu_CELoss: 0.7112, DKDLoss: 0.4785, 
2022-07-30 04:33:31 - train: epoch 0071, iter [04500, 05004], lr: 0.001000, loss: 1.2470, stu_CELoss: 0.7659, DKDLoss: 0.4811, 
2022-07-30 04:34:04 - train: epoch 0071, iter [04600, 05004], lr: 0.001000, loss: 1.2633, stu_CELoss: 0.8428, DKDLoss: 0.4205, 
2022-07-30 04:34:36 - train: epoch 0071, iter [04700, 05004], lr: 0.001000, loss: 1.1605, stu_CELoss: 0.6680, DKDLoss: 0.4925, 
2022-07-30 04:35:09 - train: epoch 0071, iter [04800, 05004], lr: 0.001000, loss: 1.2557, stu_CELoss: 0.8169, DKDLoss: 0.4388, 
2022-07-30 04:35:41 - train: epoch 0071, iter [04900, 05004], lr: 0.001000, loss: 1.1188, stu_CELoss: 0.6841, DKDLoss: 0.4347, 
2022-07-30 04:36:14 - train: epoch 0071, iter [05000, 05004], lr: 0.001000, loss: 1.2342, stu_CELoss: 0.7511, DKDLoss: 0.4831, 
2022-07-30 04:36:15 - train: epoch 071, train_loss: 1.2405
2022-07-30 04:38:44 - eval: epoch: 071, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.120%, stu_acc5: 93.462%, stu_test_loss: 0.9051
2022-07-30 04:38:45 - until epoch: 071, tea_best_acc1: 78.068%, stu_best_acc1: 77.220%
2022-07-30 04:38:45 - epoch 072 lr: 0.001000
2022-07-30 04:39:24 - train: epoch 0072, iter [00100, 05004], lr: 0.001000, loss: 1.1650, stu_CELoss: 0.6783, DKDLoss: 0.4867, 
2022-07-30 04:39:56 - train: epoch 0072, iter [00200, 05004], lr: 0.001000, loss: 1.0772, stu_CELoss: 0.6332, DKDLoss: 0.4441, 
2022-07-30 04:40:29 - train: epoch 0072, iter [00300, 05004], lr: 0.001000, loss: 1.1204, stu_CELoss: 0.6674, DKDLoss: 0.4530, 
2022-07-30 04:41:02 - train: epoch 0072, iter [00400, 05004], lr: 0.001000, loss: 1.2641, stu_CELoss: 0.8175, DKDLoss: 0.4466, 
2022-07-30 04:41:34 - train: epoch 0072, iter [00500, 05004], lr: 0.001000, loss: 1.3039, stu_CELoss: 0.8224, DKDLoss: 0.4815, 
2022-07-30 04:42:07 - train: epoch 0072, iter [00600, 05004], lr: 0.001000, loss: 1.2219, stu_CELoss: 0.7625, DKDLoss: 0.4594, 
2022-07-30 04:42:40 - train: epoch 0072, iter [00700, 05004], lr: 0.001000, loss: 1.2851, stu_CELoss: 0.8359, DKDLoss: 0.4492, 
2022-07-30 04:43:13 - train: epoch 0072, iter [00800, 05004], lr: 0.001000, loss: 1.3041, stu_CELoss: 0.7745, DKDLoss: 0.5296, 
2022-07-30 04:43:46 - train: epoch 0072, iter [00900, 05004], lr: 0.001000, loss: 1.1187, stu_CELoss: 0.6654, DKDLoss: 0.4532, 
2022-07-30 04:44:19 - train: epoch 0072, iter [01000, 05004], lr: 0.001000, loss: 1.1570, stu_CELoss: 0.7267, DKDLoss: 0.4304, 
2022-07-30 04:44:52 - train: epoch 0072, iter [01100, 05004], lr: 0.001000, loss: 1.1780, stu_CELoss: 0.7205, DKDLoss: 0.4574, 
2022-07-30 04:45:24 - train: epoch 0072, iter [01200, 05004], lr: 0.001000, loss: 1.0883, stu_CELoss: 0.6335, DKDLoss: 0.4549, 
2022-07-30 04:45:57 - train: epoch 0072, iter [01300, 05004], lr: 0.001000, loss: 1.2134, stu_CELoss: 0.7288, DKDLoss: 0.4846, 
2022-07-30 04:46:30 - train: epoch 0072, iter [01400, 05004], lr: 0.001000, loss: 1.2743, stu_CELoss: 0.8385, DKDLoss: 0.4358, 
2022-07-30 04:47:03 - train: epoch 0072, iter [01500, 05004], lr: 0.001000, loss: 1.1243, stu_CELoss: 0.6438, DKDLoss: 0.4805, 
2022-07-30 04:47:36 - train: epoch 0072, iter [01600, 05004], lr: 0.001000, loss: 1.2554, stu_CELoss: 0.7869, DKDLoss: 0.4685, 
2022-07-30 04:48:09 - train: epoch 0072, iter [01700, 05004], lr: 0.001000, loss: 1.3678, stu_CELoss: 0.8851, DKDLoss: 0.4827, 
2022-07-30 04:48:42 - train: epoch 0072, iter [01800, 05004], lr: 0.001000, loss: 1.2246, stu_CELoss: 0.7868, DKDLoss: 0.4379, 
2022-07-30 04:49:15 - train: epoch 0072, iter [01900, 05004], lr: 0.001000, loss: 1.2205, stu_CELoss: 0.7415, DKDLoss: 0.4790, 
2022-07-30 04:49:47 - train: epoch 0072, iter [02000, 05004], lr: 0.001000, loss: 1.1637, stu_CELoss: 0.6910, DKDLoss: 0.4726, 
2022-07-30 04:50:20 - train: epoch 0072, iter [02100, 05004], lr: 0.001000, loss: 1.3987, stu_CELoss: 0.9598, DKDLoss: 0.4390, 
2022-07-30 04:50:53 - train: epoch 0072, iter [02200, 05004], lr: 0.001000, loss: 1.2362, stu_CELoss: 0.7860, DKDLoss: 0.4502, 
2022-07-30 04:51:26 - train: epoch 0072, iter [02300, 05004], lr: 0.001000, loss: 1.2790, stu_CELoss: 0.8112, DKDLoss: 0.4677, 
2022-07-30 04:51:59 - train: epoch 0072, iter [02400, 05004], lr: 0.001000, loss: 1.1444, stu_CELoss: 0.7267, DKDLoss: 0.4178, 
2022-07-30 04:52:32 - train: epoch 0072, iter [02500, 05004], lr: 0.001000, loss: 1.1184, stu_CELoss: 0.6340, DKDLoss: 0.4844, 
2022-07-30 04:53:05 - train: epoch 0072, iter [02600, 05004], lr: 0.001000, loss: 1.2149, stu_CELoss: 0.7203, DKDLoss: 0.4946, 
2022-07-30 04:53:38 - train: epoch 0072, iter [02700, 05004], lr: 0.001000, loss: 1.2398, stu_CELoss: 0.8045, DKDLoss: 0.4353, 
2022-07-30 04:54:10 - train: epoch 0072, iter [02800, 05004], lr: 0.001000, loss: 1.2558, stu_CELoss: 0.8690, DKDLoss: 0.3868, 
2022-07-30 04:54:44 - train: epoch 0072, iter [02900, 05004], lr: 0.001000, loss: 1.1244, stu_CELoss: 0.7003, DKDLoss: 0.4242, 
2022-07-30 04:55:16 - train: epoch 0072, iter [03000, 05004], lr: 0.001000, loss: 1.1889, stu_CELoss: 0.7509, DKDLoss: 0.4380, 
2022-07-30 04:55:49 - train: epoch 0072, iter [03100, 05004], lr: 0.001000, loss: 1.2996, stu_CELoss: 0.8277, DKDLoss: 0.4720, 
2022-07-30 04:56:22 - train: epoch 0072, iter [03200, 05004], lr: 0.001000, loss: 1.2810, stu_CELoss: 0.8088, DKDLoss: 0.4722, 
2022-07-30 04:56:55 - train: epoch 0072, iter [03300, 05004], lr: 0.001000, loss: 1.3429, stu_CELoss: 0.8854, DKDLoss: 0.4576, 
2022-07-30 04:57:28 - train: epoch 0072, iter [03400, 05004], lr: 0.001000, loss: 1.2554, stu_CELoss: 0.7948, DKDLoss: 0.4605, 
2022-07-30 04:58:01 - train: epoch 0072, iter [03500, 05004], lr: 0.001000, loss: 1.2325, stu_CELoss: 0.7664, DKDLoss: 0.4661, 
2022-07-30 04:58:34 - train: epoch 0072, iter [03600, 05004], lr: 0.001000, loss: 1.1000, stu_CELoss: 0.6573, DKDLoss: 0.4428, 
2022-07-30 04:59:06 - train: epoch 0072, iter [03700, 05004], lr: 0.001000, loss: 1.2447, stu_CELoss: 0.7843, DKDLoss: 0.4604, 
2022-07-30 04:59:39 - train: epoch 0072, iter [03800, 05004], lr: 0.001000, loss: 1.1992, stu_CELoss: 0.8127, DKDLoss: 0.3864, 
2022-07-30 05:00:12 - train: epoch 0072, iter [03900, 05004], lr: 0.001000, loss: 1.2307, stu_CELoss: 0.7838, DKDLoss: 0.4468, 
2022-07-30 05:00:44 - train: epoch 0072, iter [04000, 05004], lr: 0.001000, loss: 1.2613, stu_CELoss: 0.8091, DKDLoss: 0.4521, 
2022-07-30 05:01:17 - train: epoch 0072, iter [04100, 05004], lr: 0.001000, loss: 1.3245, stu_CELoss: 0.8303, DKDLoss: 0.4942, 
2022-07-30 05:01:50 - train: epoch 0072, iter [04200, 05004], lr: 0.001000, loss: 1.1852, stu_CELoss: 0.7313, DKDLoss: 0.4540, 
2022-07-30 05:02:23 - train: epoch 0072, iter [04300, 05004], lr: 0.001000, loss: 1.1448, stu_CELoss: 0.6940, DKDLoss: 0.4508, 
2022-07-30 05:02:56 - train: epoch 0072, iter [04400, 05004], lr: 0.001000, loss: 1.1530, stu_CELoss: 0.7185, DKDLoss: 0.4345, 
2022-07-30 05:03:29 - train: epoch 0072, iter [04500, 05004], lr: 0.001000, loss: 1.1326, stu_CELoss: 0.7193, DKDLoss: 0.4133, 
2022-07-30 05:04:01 - train: epoch 0072, iter [04600, 05004], lr: 0.001000, loss: 1.0850, stu_CELoss: 0.7098, DKDLoss: 0.3752, 
2022-07-30 05:04:34 - train: epoch 0072, iter [04700, 05004], lr: 0.001000, loss: 1.2660, stu_CELoss: 0.8315, DKDLoss: 0.4345, 
2022-07-30 05:05:06 - train: epoch 0072, iter [04800, 05004], lr: 0.001000, loss: 1.2337, stu_CELoss: 0.7738, DKDLoss: 0.4599, 
2022-07-30 05:05:39 - train: epoch 0072, iter [04900, 05004], lr: 0.001000, loss: 1.3086, stu_CELoss: 0.8412, DKDLoss: 0.4674, 
2022-07-30 05:06:12 - train: epoch 0072, iter [05000, 05004], lr: 0.001000, loss: 1.0642, stu_CELoss: 0.6190, DKDLoss: 0.4452, 
2022-07-30 05:06:13 - train: epoch 072, train_loss: 1.2333
2022-07-30 05:08:43 - eval: epoch: 072, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.384%, stu_acc5: 93.378%, stu_test_loss: 0.9030
2022-07-30 05:08:43 - until epoch: 072, tea_best_acc1: 78.068%, stu_best_acc1: 77.384%
2022-07-30 05:08:43 - epoch 073 lr: 0.001000
2022-07-30 05:09:22 - train: epoch 0073, iter [00100, 05004], lr: 0.001000, loss: 1.4524, stu_CELoss: 0.9585, DKDLoss: 0.4940, 
2022-07-30 05:09:53 - train: epoch 0073, iter [00200, 05004], lr: 0.001000, loss: 1.1908, stu_CELoss: 0.7233, DKDLoss: 0.4674, 
2022-07-30 05:10:25 - train: epoch 0073, iter [00300, 05004], lr: 0.001000, loss: 1.5043, stu_CELoss: 1.0653, DKDLoss: 0.4390, 
2022-07-30 05:10:57 - train: epoch 0073, iter [00400, 05004], lr: 0.001000, loss: 1.1001, stu_CELoss: 0.6544, DKDLoss: 0.4457, 
2022-07-30 05:11:30 - train: epoch 0073, iter [00500, 05004], lr: 0.001000, loss: 1.2697, stu_CELoss: 0.8217, DKDLoss: 0.4480, 
2022-07-30 05:12:02 - train: epoch 0073, iter [00600, 05004], lr: 0.001000, loss: 1.1682, stu_CELoss: 0.7342, DKDLoss: 0.4340, 
2022-07-30 05:12:34 - train: epoch 0073, iter [00700, 05004], lr: 0.001000, loss: 1.3028, stu_CELoss: 0.7851, DKDLoss: 0.5177, 
2022-07-30 05:13:07 - train: epoch 0073, iter [00800, 05004], lr: 0.001000, loss: 1.1423, stu_CELoss: 0.7088, DKDLoss: 0.4336, 
2022-07-30 05:13:40 - train: epoch 0073, iter [00900, 05004], lr: 0.001000, loss: 1.1221, stu_CELoss: 0.6965, DKDLoss: 0.4256, 
2022-07-30 05:14:12 - train: epoch 0073, iter [01000, 05004], lr: 0.001000, loss: 1.3375, stu_CELoss: 0.8618, DKDLoss: 0.4757, 
2022-07-30 05:14:45 - train: epoch 0073, iter [01100, 05004], lr: 0.001000, loss: 1.1157, stu_CELoss: 0.6849, DKDLoss: 0.4308, 
2022-07-30 05:15:18 - train: epoch 0073, iter [01200, 05004], lr: 0.001000, loss: 1.2239, stu_CELoss: 0.7626, DKDLoss: 0.4614, 
2022-07-30 05:15:51 - train: epoch 0073, iter [01300, 05004], lr: 0.001000, loss: 1.2028, stu_CELoss: 0.7755, DKDLoss: 0.4274, 
2022-07-30 05:16:23 - train: epoch 0073, iter [01400, 05004], lr: 0.001000, loss: 1.0528, stu_CELoss: 0.5912, DKDLoss: 0.4617, 
2022-07-30 05:16:56 - train: epoch 0073, iter [01500, 05004], lr: 0.001000, loss: 1.2102, stu_CELoss: 0.7671, DKDLoss: 0.4431, 
2022-07-30 05:17:29 - train: epoch 0073, iter [01600, 05004], lr: 0.001000, loss: 1.0696, stu_CELoss: 0.6249, DKDLoss: 0.4447, 
2022-07-30 05:18:02 - train: epoch 0073, iter [01700, 05004], lr: 0.001000, loss: 1.2889, stu_CELoss: 0.7637, DKDLoss: 0.5252, 
2022-07-30 05:18:35 - train: epoch 0073, iter [01800, 05004], lr: 0.001000, loss: 1.1022, stu_CELoss: 0.6738, DKDLoss: 0.4284, 
2022-07-30 05:19:08 - train: epoch 0073, iter [01900, 05004], lr: 0.001000, loss: 1.2518, stu_CELoss: 0.7578, DKDLoss: 0.4940, 
2022-07-30 05:19:40 - train: epoch 0073, iter [02000, 05004], lr: 0.001000, loss: 1.1371, stu_CELoss: 0.6925, DKDLoss: 0.4446, 
2022-07-30 05:20:13 - train: epoch 0073, iter [02100, 05004], lr: 0.001000, loss: 1.2509, stu_CELoss: 0.8152, DKDLoss: 0.4357, 
2022-07-30 05:20:46 - train: epoch 0073, iter [02200, 05004], lr: 0.001000, loss: 1.2226, stu_CELoss: 0.7938, DKDLoss: 0.4288, 
2022-07-30 05:21:19 - train: epoch 0073, iter [02300, 05004], lr: 0.001000, loss: 1.2618, stu_CELoss: 0.8211, DKDLoss: 0.4406, 
2022-07-30 05:21:51 - train: epoch 0073, iter [02400, 05004], lr: 0.001000, loss: 1.2304, stu_CELoss: 0.8065, DKDLoss: 0.4239, 
2022-07-30 05:22:24 - train: epoch 0073, iter [02500, 05004], lr: 0.001000, loss: 1.3844, stu_CELoss: 0.8923, DKDLoss: 0.4922, 
2022-07-30 05:22:57 - train: epoch 0073, iter [02600, 05004], lr: 0.001000, loss: 1.1778, stu_CELoss: 0.7040, DKDLoss: 0.4738, 
2022-07-30 05:23:30 - train: epoch 0073, iter [02700, 05004], lr: 0.001000, loss: 1.2923, stu_CELoss: 0.8139, DKDLoss: 0.4784, 
2022-07-30 05:24:02 - train: epoch 0073, iter [02800, 05004], lr: 0.001000, loss: 1.2338, stu_CELoss: 0.8011, DKDLoss: 0.4327, 
2022-07-30 05:24:35 - train: epoch 0073, iter [02900, 05004], lr: 0.001000, loss: 1.4260, stu_CELoss: 0.9346, DKDLoss: 0.4914, 
2022-07-30 05:25:08 - train: epoch 0073, iter [03000, 05004], lr: 0.001000, loss: 1.0128, stu_CELoss: 0.5907, DKDLoss: 0.4221, 
2022-07-30 05:25:41 - train: epoch 0073, iter [03100, 05004], lr: 0.001000, loss: 1.2410, stu_CELoss: 0.8038, DKDLoss: 0.4372, 
2022-07-30 05:26:13 - train: epoch 0073, iter [03200, 05004], lr: 0.001000, loss: 1.1896, stu_CELoss: 0.7530, DKDLoss: 0.4366, 
2022-07-30 05:26:46 - train: epoch 0073, iter [03300, 05004], lr: 0.001000, loss: 1.0753, stu_CELoss: 0.6517, DKDLoss: 0.4236, 
2022-07-30 05:27:19 - train: epoch 0073, iter [03400, 05004], lr: 0.001000, loss: 1.1645, stu_CELoss: 0.7096, DKDLoss: 0.4549, 
2022-07-30 05:27:51 - train: epoch 0073, iter [03500, 05004], lr: 0.001000, loss: 1.2004, stu_CELoss: 0.7617, DKDLoss: 0.4387, 
2022-07-30 05:28:23 - train: epoch 0073, iter [03600, 05004], lr: 0.001000, loss: 1.0726, stu_CELoss: 0.6121, DKDLoss: 0.4605, 
2022-07-30 05:28:56 - train: epoch 0073, iter [03700, 05004], lr: 0.001000, loss: 1.4023, stu_CELoss: 0.9510, DKDLoss: 0.4513, 
2022-07-30 05:29:29 - train: epoch 0073, iter [03800, 05004], lr: 0.001000, loss: 1.4119, stu_CELoss: 0.9366, DKDLoss: 0.4753, 
2022-07-30 05:30:01 - train: epoch 0073, iter [03900, 05004], lr: 0.001000, loss: 1.1226, stu_CELoss: 0.6799, DKDLoss: 0.4427, 
2022-07-30 05:30:34 - train: epoch 0073, iter [04000, 05004], lr: 0.001000, loss: 1.1551, stu_CELoss: 0.6862, DKDLoss: 0.4689, 
2022-07-30 05:31:07 - train: epoch 0073, iter [04100, 05004], lr: 0.001000, loss: 1.1746, stu_CELoss: 0.7362, DKDLoss: 0.4384, 
2022-07-30 05:31:40 - train: epoch 0073, iter [04200, 05004], lr: 0.001000, loss: 1.3250, stu_CELoss: 0.8567, DKDLoss: 0.4683, 
2022-07-30 05:32:12 - train: epoch 0073, iter [04300, 05004], lr: 0.001000, loss: 1.1165, stu_CELoss: 0.6694, DKDLoss: 0.4471, 
2022-07-30 05:32:45 - train: epoch 0073, iter [04400, 05004], lr: 0.001000, loss: 1.2492, stu_CELoss: 0.7781, DKDLoss: 0.4711, 
2022-07-30 05:33:18 - train: epoch 0073, iter [04500, 05004], lr: 0.001000, loss: 1.0993, stu_CELoss: 0.6846, DKDLoss: 0.4147, 
2022-07-30 05:33:51 - train: epoch 0073, iter [04600, 05004], lr: 0.001000, loss: 1.3262, stu_CELoss: 0.8503, DKDLoss: 0.4759, 
2022-07-30 05:34:23 - train: epoch 0073, iter [04700, 05004], lr: 0.001000, loss: 1.1988, stu_CELoss: 0.7612, DKDLoss: 0.4377, 
2022-07-30 05:34:56 - train: epoch 0073, iter [04800, 05004], lr: 0.001000, loss: 1.0374, stu_CELoss: 0.6315, DKDLoss: 0.4059, 
2022-07-30 05:35:29 - train: epoch 0073, iter [04900, 05004], lr: 0.001000, loss: 1.3507, stu_CELoss: 0.8468, DKDLoss: 0.5039, 
2022-07-30 05:36:02 - train: epoch 0073, iter [05000, 05004], lr: 0.001000, loss: 1.2423, stu_CELoss: 0.7718, DKDLoss: 0.4705, 
2022-07-30 05:36:03 - train: epoch 073, train_loss: 1.2265
2022-07-30 05:38:32 - eval: epoch: 073, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.226%, stu_acc5: 93.456%, stu_test_loss: 0.9019
2022-07-30 05:38:33 - until epoch: 073, tea_best_acc1: 78.068%, stu_best_acc1: 77.384%
2022-07-30 05:38:33 - epoch 074 lr: 0.001000
2022-07-30 05:39:12 - train: epoch 0074, iter [00100, 05004], lr: 0.001000, loss: 1.1607, stu_CELoss: 0.7053, DKDLoss: 0.4554, 
2022-07-30 05:39:44 - train: epoch 0074, iter [00200, 05004], lr: 0.001000, loss: 1.3492, stu_CELoss: 0.8767, DKDLoss: 0.4725, 
2022-07-30 05:40:15 - train: epoch 0074, iter [00300, 05004], lr: 0.001000, loss: 1.2477, stu_CELoss: 0.8148, DKDLoss: 0.4329, 
2022-07-30 05:40:47 - train: epoch 0074, iter [00400, 05004], lr: 0.001000, loss: 1.2983, stu_CELoss: 0.8209, DKDLoss: 0.4774, 
2022-07-30 05:41:20 - train: epoch 0074, iter [00500, 05004], lr: 0.001000, loss: 1.1860, stu_CELoss: 0.7778, DKDLoss: 0.4082, 
2022-07-30 05:41:52 - train: epoch 0074, iter [00600, 05004], lr: 0.001000, loss: 1.1194, stu_CELoss: 0.6797, DKDLoss: 0.4397, 
2022-07-30 05:42:25 - train: epoch 0074, iter [00700, 05004], lr: 0.001000, loss: 1.2101, stu_CELoss: 0.7846, DKDLoss: 0.4255, 
2022-07-30 05:42:58 - train: epoch 0074, iter [00800, 05004], lr: 0.001000, loss: 1.3864, stu_CELoss: 0.9214, DKDLoss: 0.4650, 
2022-07-30 05:43:31 - train: epoch 0074, iter [00900, 05004], lr: 0.001000, loss: 1.1333, stu_CELoss: 0.7420, DKDLoss: 0.3913, 
2022-07-30 05:44:03 - train: epoch 0074, iter [01000, 05004], lr: 0.001000, loss: 1.1642, stu_CELoss: 0.7491, DKDLoss: 0.4152, 
2022-07-30 05:44:36 - train: epoch 0074, iter [01100, 05004], lr: 0.001000, loss: 1.3758, stu_CELoss: 0.9318, DKDLoss: 0.4441, 
2022-07-30 05:45:09 - train: epoch 0074, iter [01200, 05004], lr: 0.001000, loss: 1.2281, stu_CELoss: 0.7587, DKDLoss: 0.4695, 
2022-07-30 05:45:42 - train: epoch 0074, iter [01300, 05004], lr: 0.001000, loss: 1.2024, stu_CELoss: 0.7414, DKDLoss: 0.4610, 
2022-07-30 05:46:15 - train: epoch 0074, iter [01400, 05004], lr: 0.001000, loss: 1.2578, stu_CELoss: 0.8202, DKDLoss: 0.4376, 
2022-07-30 05:46:48 - train: epoch 0074, iter [01500, 05004], lr: 0.001000, loss: 1.1275, stu_CELoss: 0.6962, DKDLoss: 0.4313, 
2022-07-30 05:47:20 - train: epoch 0074, iter [01600, 05004], lr: 0.001000, loss: 1.2457, stu_CELoss: 0.8112, DKDLoss: 0.4345, 
2022-07-30 05:47:53 - train: epoch 0074, iter [01700, 05004], lr: 0.001000, loss: 1.2850, stu_CELoss: 0.8156, DKDLoss: 0.4694, 
2022-07-30 05:48:26 - train: epoch 0074, iter [01800, 05004], lr: 0.001000, loss: 1.3257, stu_CELoss: 0.8696, DKDLoss: 0.4562, 
2022-07-30 05:49:00 - train: epoch 0074, iter [01900, 05004], lr: 0.001000, loss: 1.3864, stu_CELoss: 0.8718, DKDLoss: 0.5146, 
2022-07-30 05:49:33 - train: epoch 0074, iter [02000, 05004], lr: 0.001000, loss: 1.1103, stu_CELoss: 0.6885, DKDLoss: 0.4218, 
2022-07-30 05:50:07 - train: epoch 0074, iter [02100, 05004], lr: 0.001000, loss: 1.1662, stu_CELoss: 0.6948, DKDLoss: 0.4714, 
2022-07-30 05:50:41 - train: epoch 0074, iter [02200, 05004], lr: 0.001000, loss: 1.3609, stu_CELoss: 0.8587, DKDLoss: 0.5022, 
2022-07-30 05:51:14 - train: epoch 0074, iter [02300, 05004], lr: 0.001000, loss: 1.3029, stu_CELoss: 0.8663, DKDLoss: 0.4365, 
2022-07-30 05:51:48 - train: epoch 0074, iter [02400, 05004], lr: 0.001000, loss: 1.1133, stu_CELoss: 0.6659, DKDLoss: 0.4474, 
2022-07-30 05:52:22 - train: epoch 0074, iter [02500, 05004], lr: 0.001000, loss: 1.1132, stu_CELoss: 0.7212, DKDLoss: 0.3920, 
2022-07-30 05:52:55 - train: epoch 0074, iter [02600, 05004], lr: 0.001000, loss: 1.0646, stu_CELoss: 0.6723, DKDLoss: 0.3923, 
2022-07-30 05:53:29 - train: epoch 0074, iter [02700, 05004], lr: 0.001000, loss: 0.9836, stu_CELoss: 0.5627, DKDLoss: 0.4209, 
2022-07-30 05:54:02 - train: epoch 0074, iter [02800, 05004], lr: 0.001000, loss: 1.5143, stu_CELoss: 1.0085, DKDLoss: 0.5058, 
2022-07-30 05:54:36 - train: epoch 0074, iter [02900, 05004], lr: 0.001000, loss: 1.1959, stu_CELoss: 0.7754, DKDLoss: 0.4205, 
2022-07-30 05:55:10 - train: epoch 0074, iter [03000, 05004], lr: 0.001000, loss: 1.4439, stu_CELoss: 0.9999, DKDLoss: 0.4441, 
2022-07-30 05:55:44 - train: epoch 0074, iter [03100, 05004], lr: 0.001000, loss: 1.2467, stu_CELoss: 0.7745, DKDLoss: 0.4721, 
2022-07-30 05:56:18 - train: epoch 0074, iter [03200, 05004], lr: 0.001000, loss: 1.2254, stu_CELoss: 0.7748, DKDLoss: 0.4506, 
2022-07-30 05:56:52 - train: epoch 0074, iter [03300, 05004], lr: 0.001000, loss: 1.1920, stu_CELoss: 0.7500, DKDLoss: 0.4420, 
2022-07-30 05:57:26 - train: epoch 0074, iter [03400, 05004], lr: 0.001000, loss: 1.1263, stu_CELoss: 0.6928, DKDLoss: 0.4334, 
2022-07-30 05:57:59 - train: epoch 0074, iter [03500, 05004], lr: 0.001000, loss: 0.9574, stu_CELoss: 0.5393, DKDLoss: 0.4180, 
2022-07-30 05:58:33 - train: epoch 0074, iter [03600, 05004], lr: 0.001000, loss: 1.0949, stu_CELoss: 0.6547, DKDLoss: 0.4402, 
2022-07-30 05:59:08 - train: epoch 0074, iter [03700, 05004], lr: 0.001000, loss: 1.1249, stu_CELoss: 0.7468, DKDLoss: 0.3780, 
2022-07-30 05:59:42 - train: epoch 0074, iter [03800, 05004], lr: 0.001000, loss: 1.1986, stu_CELoss: 0.7597, DKDLoss: 0.4390, 
2022-07-30 06:00:16 - train: epoch 0074, iter [03900, 05004], lr: 0.001000, loss: 1.1804, stu_CELoss: 0.7363, DKDLoss: 0.4441, 
2022-07-30 06:00:50 - train: epoch 0074, iter [04000, 05004], lr: 0.001000, loss: 1.2910, stu_CELoss: 0.7912, DKDLoss: 0.4998, 
2022-07-30 06:01:24 - train: epoch 0074, iter [04100, 05004], lr: 0.001000, loss: 1.2305, stu_CELoss: 0.8118, DKDLoss: 0.4187, 
2022-07-30 06:01:58 - train: epoch 0074, iter [04200, 05004], lr: 0.001000, loss: 1.1691, stu_CELoss: 0.7405, DKDLoss: 0.4286, 
2022-07-30 06:02:32 - train: epoch 0074, iter [04300, 05004], lr: 0.001000, loss: 1.1838, stu_CELoss: 0.7171, DKDLoss: 0.4667, 
2022-07-30 06:03:06 - train: epoch 0074, iter [04400, 05004], lr: 0.001000, loss: 1.1128, stu_CELoss: 0.6944, DKDLoss: 0.4184, 
2022-07-30 06:03:41 - train: epoch 0074, iter [04500, 05004], lr: 0.001000, loss: 1.1176, stu_CELoss: 0.6856, DKDLoss: 0.4320, 
2022-07-30 06:04:15 - train: epoch 0074, iter [04600, 05004], lr: 0.001000, loss: 1.2511, stu_CELoss: 0.7799, DKDLoss: 0.4711, 
2022-07-30 06:04:49 - train: epoch 0074, iter [04700, 05004], lr: 0.001000, loss: 1.1840, stu_CELoss: 0.7988, DKDLoss: 0.3853, 
2022-07-30 06:05:23 - train: epoch 0074, iter [04800, 05004], lr: 0.001000, loss: 1.2345, stu_CELoss: 0.7499, DKDLoss: 0.4846, 
2022-07-30 06:05:57 - train: epoch 0074, iter [04900, 05004], lr: 0.001000, loss: 1.4802, stu_CELoss: 1.0058, DKDLoss: 0.4744, 
2022-07-30 06:06:31 - train: epoch 0074, iter [05000, 05004], lr: 0.001000, loss: 1.2694, stu_CELoss: 0.7905, DKDLoss: 0.4789, 
2022-07-30 06:06:32 - train: epoch 074, train_loss: 1.2164
2022-07-30 06:09:05 - eval: epoch: 074, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.244%, stu_acc5: 93.442%, stu_test_loss: 0.9036
2022-07-30 06:09:06 - until epoch: 074, tea_best_acc1: 78.068%, stu_best_acc1: 77.384%
2022-07-30 06:09:06 - epoch 075 lr: 0.001000
2022-07-30 06:09:46 - train: epoch 0075, iter [00100, 05004], lr: 0.001000, loss: 1.3332, stu_CELoss: 0.8446, DKDLoss: 0.4886, 
2022-07-30 06:10:20 - train: epoch 0075, iter [00200, 05004], lr: 0.001000, loss: 1.1614, stu_CELoss: 0.7040, DKDLoss: 0.4574, 
2022-07-30 06:10:53 - train: epoch 0075, iter [00300, 05004], lr: 0.001000, loss: 1.2376, stu_CELoss: 0.8266, DKDLoss: 0.4111, 
2022-07-30 06:11:27 - train: epoch 0075, iter [00400, 05004], lr: 0.001000, loss: 1.1852, stu_CELoss: 0.7048, DKDLoss: 0.4804, 
2022-07-30 06:12:01 - train: epoch 0075, iter [00500, 05004], lr: 0.001000, loss: 1.3064, stu_CELoss: 0.8262, DKDLoss: 0.4802, 
2022-07-30 06:12:35 - train: epoch 0075, iter [00600, 05004], lr: 0.001000, loss: 1.0689, stu_CELoss: 0.6733, DKDLoss: 0.3957, 
2022-07-30 06:13:09 - train: epoch 0075, iter [00700, 05004], lr: 0.001000, loss: 1.3511, stu_CELoss: 0.8885, DKDLoss: 0.4625, 
2022-07-30 06:13:43 - train: epoch 0075, iter [00800, 05004], lr: 0.001000, loss: 1.1196, stu_CELoss: 0.7148, DKDLoss: 0.4048, 
2022-07-30 06:14:17 - train: epoch 0075, iter [00900, 05004], lr: 0.001000, loss: 1.4061, stu_CELoss: 0.9421, DKDLoss: 0.4640, 
2022-07-30 06:14:51 - train: epoch 0075, iter [01000, 05004], lr: 0.001000, loss: 1.0452, stu_CELoss: 0.6154, DKDLoss: 0.4298, 
2022-07-30 06:15:25 - train: epoch 0075, iter [01100, 05004], lr: 0.001000, loss: 1.3664, stu_CELoss: 0.8606, DKDLoss: 0.5058, 
2022-07-30 06:15:59 - train: epoch 0075, iter [01200, 05004], lr: 0.001000, loss: 0.9960, stu_CELoss: 0.6229, DKDLoss: 0.3731, 
2022-07-30 06:16:33 - train: epoch 0075, iter [01300, 05004], lr: 0.001000, loss: 1.3003, stu_CELoss: 0.8345, DKDLoss: 0.4658, 
2022-07-30 06:17:07 - train: epoch 0075, iter [01400, 05004], lr: 0.001000, loss: 1.1973, stu_CELoss: 0.7434, DKDLoss: 0.4539, 
2022-07-30 06:17:41 - train: epoch 0075, iter [01500, 05004], lr: 0.001000, loss: 1.1121, stu_CELoss: 0.6650, DKDLoss: 0.4472, 
2022-07-30 06:18:14 - train: epoch 0075, iter [01600, 05004], lr: 0.001000, loss: 1.1526, stu_CELoss: 0.7277, DKDLoss: 0.4249, 
2022-07-30 06:18:48 - train: epoch 0075, iter [01700, 05004], lr: 0.001000, loss: 1.4110, stu_CELoss: 0.9204, DKDLoss: 0.4906, 
2022-07-30 06:19:22 - train: epoch 0075, iter [01800, 05004], lr: 0.001000, loss: 1.2499, stu_CELoss: 0.7845, DKDLoss: 0.4654, 
2022-07-30 06:19:56 - train: epoch 0075, iter [01900, 05004], lr: 0.001000, loss: 1.1244, stu_CELoss: 0.6676, DKDLoss: 0.4568, 
2022-07-30 06:20:31 - train: epoch 0075, iter [02000, 05004], lr: 0.001000, loss: 1.2544, stu_CELoss: 0.7445, DKDLoss: 0.5098, 
2022-07-30 06:21:05 - train: epoch 0075, iter [02100, 05004], lr: 0.001000, loss: 1.0955, stu_CELoss: 0.6852, DKDLoss: 0.4102, 
2022-07-30 06:21:39 - train: epoch 0075, iter [02200, 05004], lr: 0.001000, loss: 1.2800, stu_CELoss: 0.8340, DKDLoss: 0.4460, 
2022-07-30 06:22:13 - train: epoch 0075, iter [02300, 05004], lr: 0.001000, loss: 1.2687, stu_CELoss: 0.8405, DKDLoss: 0.4282, 
2022-07-30 06:22:47 - train: epoch 0075, iter [02400, 05004], lr: 0.001000, loss: 1.3448, stu_CELoss: 0.9156, DKDLoss: 0.4292, 
2022-07-30 06:23:21 - train: epoch 0075, iter [02500, 05004], lr: 0.001000, loss: 1.2305, stu_CELoss: 0.7472, DKDLoss: 0.4833, 
2022-07-30 06:23:56 - train: epoch 0075, iter [02600, 05004], lr: 0.001000, loss: 1.1556, stu_CELoss: 0.7761, DKDLoss: 0.3795, 
2022-07-30 06:24:30 - train: epoch 0075, iter [02700, 05004], lr: 0.001000, loss: 1.1322, stu_CELoss: 0.7081, DKDLoss: 0.4240, 
2022-07-30 06:25:04 - train: epoch 0075, iter [02800, 05004], lr: 0.001000, loss: 1.0615, stu_CELoss: 0.6260, DKDLoss: 0.4355, 
2022-07-30 06:25:38 - train: epoch 0075, iter [02900, 05004], lr: 0.001000, loss: 1.3239, stu_CELoss: 0.8587, DKDLoss: 0.4651, 
2022-07-30 06:26:12 - train: epoch 0075, iter [03000, 05004], lr: 0.001000, loss: 1.3128, stu_CELoss: 0.8343, DKDLoss: 0.4785, 
2022-07-30 06:26:46 - train: epoch 0075, iter [03100, 05004], lr: 0.001000, loss: 1.2856, stu_CELoss: 0.7541, DKDLoss: 0.5315, 
2022-07-30 06:27:20 - train: epoch 0075, iter [03200, 05004], lr: 0.001000, loss: 1.3968, stu_CELoss: 0.8733, DKDLoss: 0.5235, 
2022-07-30 06:27:54 - train: epoch 0075, iter [03300, 05004], lr: 0.001000, loss: 1.2495, stu_CELoss: 0.7902, DKDLoss: 0.4593, 
2022-07-30 06:28:28 - train: epoch 0075, iter [03400, 05004], lr: 0.001000, loss: 1.1492, stu_CELoss: 0.6932, DKDLoss: 0.4560, 
2022-07-30 06:29:02 - train: epoch 0075, iter [03500, 05004], lr: 0.001000, loss: 1.2644, stu_CELoss: 0.7811, DKDLoss: 0.4833, 
2022-07-30 06:29:36 - train: epoch 0075, iter [03600, 05004], lr: 0.001000, loss: 1.2357, stu_CELoss: 0.7721, DKDLoss: 0.4636, 
2022-07-30 06:30:10 - train: epoch 0075, iter [03700, 05004], lr: 0.001000, loss: 1.2025, stu_CELoss: 0.8104, DKDLoss: 0.3921, 
2022-07-30 06:30:44 - train: epoch 0075, iter [03800, 05004], lr: 0.001000, loss: 1.3071, stu_CELoss: 0.8522, DKDLoss: 0.4549, 
2022-07-30 06:31:18 - train: epoch 0075, iter [03900, 05004], lr: 0.001000, loss: 1.2952, stu_CELoss: 0.8170, DKDLoss: 0.4782, 
2022-07-30 06:31:52 - train: epoch 0075, iter [04000, 05004], lr: 0.001000, loss: 1.2187, stu_CELoss: 0.7939, DKDLoss: 0.4249, 
2022-07-30 06:32:26 - train: epoch 0075, iter [04100, 05004], lr: 0.001000, loss: 1.0771, stu_CELoss: 0.6599, DKDLoss: 0.4172, 
2022-07-30 06:33:00 - train: epoch 0075, iter [04200, 05004], lr: 0.001000, loss: 1.2818, stu_CELoss: 0.7843, DKDLoss: 0.4975, 
2022-07-30 06:33:33 - train: epoch 0075, iter [04300, 05004], lr: 0.001000, loss: 1.2235, stu_CELoss: 0.7733, DKDLoss: 0.4502, 
2022-07-30 06:34:07 - train: epoch 0075, iter [04400, 05004], lr: 0.001000, loss: 1.3109, stu_CELoss: 0.8150, DKDLoss: 0.4960, 
2022-07-30 06:34:41 - train: epoch 0075, iter [04500, 05004], lr: 0.001000, loss: 1.4219, stu_CELoss: 0.9533, DKDLoss: 0.4686, 
2022-07-30 06:35:16 - train: epoch 0075, iter [04600, 05004], lr: 0.001000, loss: 1.2118, stu_CELoss: 0.8060, DKDLoss: 0.4057, 
2022-07-30 06:35:49 - train: epoch 0075, iter [04700, 05004], lr: 0.001000, loss: 1.3847, stu_CELoss: 0.9201, DKDLoss: 0.4646, 
2022-07-30 06:36:24 - train: epoch 0075, iter [04800, 05004], lr: 0.001000, loss: 1.0185, stu_CELoss: 0.5987, DKDLoss: 0.4198, 
2022-07-30 06:36:57 - train: epoch 0075, iter [04900, 05004], lr: 0.001000, loss: 1.1768, stu_CELoss: 0.7258, DKDLoss: 0.4510, 
2022-07-30 06:37:31 - train: epoch 0075, iter [05000, 05004], lr: 0.001000, loss: 1.3431, stu_CELoss: 0.9097, DKDLoss: 0.4333, 
2022-07-30 06:37:32 - train: epoch 075, train_loss: 1.2133
2022-07-30 06:40:06 - eval: epoch: 075, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.166%, stu_acc5: 93.428%, stu_test_loss: 0.9012
2022-07-30 06:40:06 - until epoch: 075, tea_best_acc1: 78.068%, stu_best_acc1: 77.384%
2022-07-30 06:40:06 - epoch 076 lr: 0.001000
2022-07-30 06:40:46 - train: epoch 0076, iter [00100, 05004], lr: 0.001000, loss: 1.1629, stu_CELoss: 0.7551, DKDLoss: 0.4078, 
2022-07-30 06:41:19 - train: epoch 0076, iter [00200, 05004], lr: 0.001000, loss: 1.0725, stu_CELoss: 0.6608, DKDLoss: 0.4117, 
2022-07-30 06:41:53 - train: epoch 0076, iter [00300, 05004], lr: 0.001000, loss: 1.2453, stu_CELoss: 0.8232, DKDLoss: 0.4220, 
2022-07-30 06:42:27 - train: epoch 0076, iter [00400, 05004], lr: 0.001000, loss: 1.1272, stu_CELoss: 0.7129, DKDLoss: 0.4143, 
2022-07-30 06:43:01 - train: epoch 0076, iter [00500, 05004], lr: 0.001000, loss: 1.1438, stu_CELoss: 0.7141, DKDLoss: 0.4297, 
2022-07-30 06:43:35 - train: epoch 0076, iter [00600, 05004], lr: 0.001000, loss: 1.1418, stu_CELoss: 0.6949, DKDLoss: 0.4469, 
2022-07-30 06:44:09 - train: epoch 0076, iter [00700, 05004], lr: 0.001000, loss: 1.2049, stu_CELoss: 0.7772, DKDLoss: 0.4277, 
2022-07-30 06:44:43 - train: epoch 0076, iter [00800, 05004], lr: 0.001000, loss: 1.2032, stu_CELoss: 0.7791, DKDLoss: 0.4240, 
2022-07-30 06:45:17 - train: epoch 0076, iter [00900, 05004], lr: 0.001000, loss: 1.1249, stu_CELoss: 0.7218, DKDLoss: 0.4031, 
2022-07-30 06:45:51 - train: epoch 0076, iter [01000, 05004], lr: 0.001000, loss: 1.2864, stu_CELoss: 0.8303, DKDLoss: 0.4561, 
2022-07-30 06:46:25 - train: epoch 0076, iter [01100, 05004], lr: 0.001000, loss: 1.2776, stu_CELoss: 0.8095, DKDLoss: 0.4681, 
2022-07-30 06:46:59 - train: epoch 0076, iter [01200, 05004], lr: 0.001000, loss: 1.1484, stu_CELoss: 0.7300, DKDLoss: 0.4183, 
2022-07-30 06:47:32 - train: epoch 0076, iter [01300, 05004], lr: 0.001000, loss: 1.1787, stu_CELoss: 0.7798, DKDLoss: 0.3989, 
2022-07-30 06:48:06 - train: epoch 0076, iter [01400, 05004], lr: 0.001000, loss: 1.1757, stu_CELoss: 0.7036, DKDLoss: 0.4721, 
2022-07-30 06:48:40 - train: epoch 0076, iter [01500, 05004], lr: 0.001000, loss: 1.2517, stu_CELoss: 0.7988, DKDLoss: 0.4529, 
2022-07-30 06:49:15 - train: epoch 0076, iter [01600, 05004], lr: 0.001000, loss: 1.1638, stu_CELoss: 0.7592, DKDLoss: 0.4046, 
2022-07-30 06:49:49 - train: epoch 0076, iter [01700, 05004], lr: 0.001000, loss: 1.2061, stu_CELoss: 0.7949, DKDLoss: 0.4112, 
2022-07-30 06:50:22 - train: epoch 0076, iter [01800, 05004], lr: 0.001000, loss: 1.1341, stu_CELoss: 0.7168, DKDLoss: 0.4174, 
2022-07-30 06:50:57 - train: epoch 0076, iter [01900, 05004], lr: 0.001000, loss: 1.2158, stu_CELoss: 0.7753, DKDLoss: 0.4405, 
2022-07-30 06:51:31 - train: epoch 0076, iter [02000, 05004], lr: 0.001000, loss: 1.1355, stu_CELoss: 0.6780, DKDLoss: 0.4575, 
2022-07-30 06:52:05 - train: epoch 0076, iter [02100, 05004], lr: 0.001000, loss: 1.4142, stu_CELoss: 0.9175, DKDLoss: 0.4967, 
2022-07-30 06:52:39 - train: epoch 0076, iter [02200, 05004], lr: 0.001000, loss: 1.1939, stu_CELoss: 0.7623, DKDLoss: 0.4316, 
2022-07-30 06:53:13 - train: epoch 0076, iter [02300, 05004], lr: 0.001000, loss: 1.0915, stu_CELoss: 0.6892, DKDLoss: 0.4023, 
2022-07-30 06:53:47 - train: epoch 0076, iter [02400, 05004], lr: 0.001000, loss: 1.2863, stu_CELoss: 0.8480, DKDLoss: 0.4383, 
2022-07-30 06:54:21 - train: epoch 0076, iter [02500, 05004], lr: 0.001000, loss: 1.3664, stu_CELoss: 0.9281, DKDLoss: 0.4382, 
2022-07-30 06:54:55 - train: epoch 0076, iter [02600, 05004], lr: 0.001000, loss: 1.2942, stu_CELoss: 0.7700, DKDLoss: 0.5242, 
2022-07-30 06:55:29 - train: epoch 0076, iter [02700, 05004], lr: 0.001000, loss: 1.1612, stu_CELoss: 0.7181, DKDLoss: 0.4431, 
2022-07-30 06:56:03 - train: epoch 0076, iter [02800, 05004], lr: 0.001000, loss: 1.1203, stu_CELoss: 0.6642, DKDLoss: 0.4561, 
2022-07-30 06:56:37 - train: epoch 0076, iter [02900, 05004], lr: 0.001000, loss: 1.1065, stu_CELoss: 0.6670, DKDLoss: 0.4395, 
2022-07-30 06:57:11 - train: epoch 0076, iter [03000, 05004], lr: 0.001000, loss: 1.1403, stu_CELoss: 0.7113, DKDLoss: 0.4290, 
2022-07-30 06:57:45 - train: epoch 0076, iter [03100, 05004], lr: 0.001000, loss: 1.2300, stu_CELoss: 0.7887, DKDLoss: 0.4413, 
2022-07-30 06:58:19 - train: epoch 0076, iter [03200, 05004], lr: 0.001000, loss: 1.2029, stu_CELoss: 0.7790, DKDLoss: 0.4238, 
2022-07-30 06:58:53 - train: epoch 0076, iter [03300, 05004], lr: 0.001000, loss: 1.1055, stu_CELoss: 0.6862, DKDLoss: 0.4193, 
2022-07-30 06:59:27 - train: epoch 0076, iter [03400, 05004], lr: 0.001000, loss: 1.3737, stu_CELoss: 0.9482, DKDLoss: 0.4255, 
2022-07-30 07:00:01 - train: epoch 0076, iter [03500, 05004], lr: 0.001000, loss: 1.1877, stu_CELoss: 0.7694, DKDLoss: 0.4183, 
2022-07-30 07:00:35 - train: epoch 0076, iter [03600, 05004], lr: 0.001000, loss: 1.2398, stu_CELoss: 0.8292, DKDLoss: 0.4106, 
2022-07-30 07:01:09 - train: epoch 0076, iter [03700, 05004], lr: 0.001000, loss: 1.0741, stu_CELoss: 0.6389, DKDLoss: 0.4352, 
2022-07-30 07:01:44 - train: epoch 0076, iter [03800, 05004], lr: 0.001000, loss: 1.1619, stu_CELoss: 0.7718, DKDLoss: 0.3901, 
2022-07-30 07:02:17 - train: epoch 0076, iter [03900, 05004], lr: 0.001000, loss: 1.1247, stu_CELoss: 0.6736, DKDLoss: 0.4510, 
2022-07-30 07:02:51 - train: epoch 0076, iter [04000, 05004], lr: 0.001000, loss: 1.1514, stu_CELoss: 0.7203, DKDLoss: 0.4311, 
2022-07-30 07:03:25 - train: epoch 0076, iter [04100, 05004], lr: 0.001000, loss: 1.2708, stu_CELoss: 0.7997, DKDLoss: 0.4711, 
2022-07-30 07:04:00 - train: epoch 0076, iter [04200, 05004], lr: 0.001000, loss: 1.1541, stu_CELoss: 0.7014, DKDLoss: 0.4528, 
2022-07-30 07:04:34 - train: epoch 0076, iter [04300, 05004], lr: 0.001000, loss: 1.2663, stu_CELoss: 0.8525, DKDLoss: 0.4138, 
2022-07-30 07:05:08 - train: epoch 0076, iter [04400, 05004], lr: 0.001000, loss: 1.2403, stu_CELoss: 0.8047, DKDLoss: 0.4356, 
2022-07-30 07:05:42 - train: epoch 0076, iter [04500, 05004], lr: 0.001000, loss: 1.3398, stu_CELoss: 0.8749, DKDLoss: 0.4648, 
2022-07-30 07:06:17 - train: epoch 0076, iter [04600, 05004], lr: 0.001000, loss: 1.1998, stu_CELoss: 0.7560, DKDLoss: 0.4438, 
2022-07-30 07:06:51 - train: epoch 0076, iter [04700, 05004], lr: 0.001000, loss: 1.4417, stu_CELoss: 0.9804, DKDLoss: 0.4613, 
2022-07-30 07:07:25 - train: epoch 0076, iter [04800, 05004], lr: 0.001000, loss: 1.0070, stu_CELoss: 0.6108, DKDLoss: 0.3962, 
2022-07-30 07:07:59 - train: epoch 0076, iter [04900, 05004], lr: 0.001000, loss: 1.1717, stu_CELoss: 0.7338, DKDLoss: 0.4380, 
2022-07-30 07:08:33 - train: epoch 0076, iter [05000, 05004], lr: 0.001000, loss: 1.2501, stu_CELoss: 0.8483, DKDLoss: 0.4018, 
2022-07-30 07:08:35 - train: epoch 076, train_loss: 1.2058
2022-07-30 07:11:07 - eval: epoch: 076, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.192%, stu_acc5: 93.430%, stu_test_loss: 0.9017
2022-07-30 07:11:07 - until epoch: 076, tea_best_acc1: 78.068%, stu_best_acc1: 77.384%
2022-07-30 07:11:07 - epoch 077 lr: 0.001000
2022-07-30 07:11:47 - train: epoch 0077, iter [00100, 05004], lr: 0.001000, loss: 1.2683, stu_CELoss: 0.7735, DKDLoss: 0.4949, 
2022-07-30 07:12:20 - train: epoch 0077, iter [00200, 05004], lr: 0.001000, loss: 1.3688, stu_CELoss: 0.9204, DKDLoss: 0.4484, 
2022-07-30 07:12:54 - train: epoch 0077, iter [00300, 05004], lr: 0.001000, loss: 1.2467, stu_CELoss: 0.8165, DKDLoss: 0.4302, 
2022-07-30 07:13:27 - train: epoch 0077, iter [00400, 05004], lr: 0.001000, loss: 1.1270, stu_CELoss: 0.7227, DKDLoss: 0.4043, 
2022-07-30 07:14:00 - train: epoch 0077, iter [00500, 05004], lr: 0.001000, loss: 1.0381, stu_CELoss: 0.6784, DKDLoss: 0.3596, 
2022-07-30 07:14:34 - train: epoch 0077, iter [00600, 05004], lr: 0.001000, loss: 1.1209, stu_CELoss: 0.6775, DKDLoss: 0.4434, 
2022-07-30 07:15:07 - train: epoch 0077, iter [00700, 05004], lr: 0.001000, loss: 1.0424, stu_CELoss: 0.6706, DKDLoss: 0.3717, 
2022-07-30 07:15:41 - train: epoch 0077, iter [00800, 05004], lr: 0.001000, loss: 1.3014, stu_CELoss: 0.8838, DKDLoss: 0.4176, 
2022-07-30 07:16:15 - train: epoch 0077, iter [00900, 05004], lr: 0.001000, loss: 1.1858, stu_CELoss: 0.7417, DKDLoss: 0.4442, 
2022-07-30 07:16:49 - train: epoch 0077, iter [01000, 05004], lr: 0.001000, loss: 1.3383, stu_CELoss: 0.8888, DKDLoss: 0.4495, 
2022-07-30 07:17:23 - train: epoch 0077, iter [01100, 05004], lr: 0.001000, loss: 1.3970, stu_CELoss: 0.9137, DKDLoss: 0.4833, 
2022-07-30 07:17:57 - train: epoch 0077, iter [01200, 05004], lr: 0.001000, loss: 1.2868, stu_CELoss: 0.8248, DKDLoss: 0.4619, 
2022-07-30 07:18:31 - train: epoch 0077, iter [01300, 05004], lr: 0.001000, loss: 0.9892, stu_CELoss: 0.6301, DKDLoss: 0.3591, 
2022-07-30 07:19:04 - train: epoch 0077, iter [01400, 05004], lr: 0.001000, loss: 1.3643, stu_CELoss: 0.9084, DKDLoss: 0.4559, 
2022-07-30 07:19:39 - train: epoch 0077, iter [01500, 05004], lr: 0.001000, loss: 1.2597, stu_CELoss: 0.8267, DKDLoss: 0.4330, 
2022-07-30 07:20:12 - train: epoch 0077, iter [01600, 05004], lr: 0.001000, loss: 1.0000, stu_CELoss: 0.5919, DKDLoss: 0.4081, 
2022-07-30 07:20:46 - train: epoch 0077, iter [01700, 05004], lr: 0.001000, loss: 1.2696, stu_CELoss: 0.8393, DKDLoss: 0.4303, 
2022-07-30 07:21:21 - train: epoch 0077, iter [01800, 05004], lr: 0.001000, loss: 1.0793, stu_CELoss: 0.6442, DKDLoss: 0.4351, 
2022-07-30 07:21:54 - train: epoch 0077, iter [01900, 05004], lr: 0.001000, loss: 1.1660, stu_CELoss: 0.7077, DKDLoss: 0.4583, 
2022-07-30 07:22:28 - train: epoch 0077, iter [02000, 05004], lr: 0.001000, loss: 1.0598, stu_CELoss: 0.5977, DKDLoss: 0.4622, 
2022-07-30 07:23:02 - train: epoch 0077, iter [02100, 05004], lr: 0.001000, loss: 1.3529, stu_CELoss: 0.8481, DKDLoss: 0.5048, 
2022-07-30 07:23:36 - train: epoch 0077, iter [02200, 05004], lr: 0.001000, loss: 1.1212, stu_CELoss: 0.7245, DKDLoss: 0.3968, 
2022-07-30 07:24:10 - train: epoch 0077, iter [02300, 05004], lr: 0.001000, loss: 1.5237, stu_CELoss: 1.0176, DKDLoss: 0.5061, 
2022-07-30 07:24:44 - train: epoch 0077, iter [02400, 05004], lr: 0.001000, loss: 1.1810, stu_CELoss: 0.7579, DKDLoss: 0.4232, 
2022-07-30 07:25:18 - train: epoch 0077, iter [02500, 05004], lr: 0.001000, loss: 1.1819, stu_CELoss: 0.6974, DKDLoss: 0.4846, 
2022-07-30 07:25:52 - train: epoch 0077, iter [02600, 05004], lr: 0.001000, loss: 0.9969, stu_CELoss: 0.6479, DKDLoss: 0.3490, 
2022-07-30 07:26:26 - train: epoch 0077, iter [02700, 05004], lr: 0.001000, loss: 1.1671, stu_CELoss: 0.7429, DKDLoss: 0.4242, 
2022-07-30 07:27:00 - train: epoch 0077, iter [02800, 05004], lr: 0.001000, loss: 1.2767, stu_CELoss: 0.7894, DKDLoss: 0.4874, 
2022-07-30 07:27:34 - train: epoch 0077, iter [02900, 05004], lr: 0.001000, loss: 1.1965, stu_CELoss: 0.7110, DKDLoss: 0.4854, 
2022-07-30 07:28:08 - train: epoch 0077, iter [03000, 05004], lr: 0.001000, loss: 1.2881, stu_CELoss: 0.8545, DKDLoss: 0.4336, 
2022-07-30 07:28:42 - train: epoch 0077, iter [03100, 05004], lr: 0.001000, loss: 1.2056, stu_CELoss: 0.8295, DKDLoss: 0.3761, 
2022-07-30 07:29:17 - train: epoch 0077, iter [03200, 05004], lr: 0.001000, loss: 1.3031, stu_CELoss: 0.8403, DKDLoss: 0.4628, 
2022-07-30 07:29:51 - train: epoch 0077, iter [03300, 05004], lr: 0.001000, loss: 1.0821, stu_CELoss: 0.6418, DKDLoss: 0.4403, 
2022-07-30 07:30:25 - train: epoch 0077, iter [03400, 05004], lr: 0.001000, loss: 1.2141, stu_CELoss: 0.7657, DKDLoss: 0.4483, 
2022-07-30 07:30:59 - train: epoch 0077, iter [03500, 05004], lr: 0.001000, loss: 1.0791, stu_CELoss: 0.6688, DKDLoss: 0.4103, 
2022-07-30 07:31:34 - train: epoch 0077, iter [03600, 05004], lr: 0.001000, loss: 1.1812, stu_CELoss: 0.7798, DKDLoss: 0.4014, 
2022-07-30 07:32:08 - train: epoch 0077, iter [03700, 05004], lr: 0.001000, loss: 1.2174, stu_CELoss: 0.7936, DKDLoss: 0.4238, 
2022-07-30 07:32:42 - train: epoch 0077, iter [03800, 05004], lr: 0.001000, loss: 1.2943, stu_CELoss: 0.7879, DKDLoss: 0.5065, 
2022-07-30 07:33:16 - train: epoch 0077, iter [03900, 05004], lr: 0.001000, loss: 1.2469, stu_CELoss: 0.8158, DKDLoss: 0.4311, 
2022-07-30 07:33:50 - train: epoch 0077, iter [04000, 05004], lr: 0.001000, loss: 1.2006, stu_CELoss: 0.7332, DKDLoss: 0.4674, 
2022-07-30 07:34:24 - train: epoch 0077, iter [04100, 05004], lr: 0.001000, loss: 1.1817, stu_CELoss: 0.7380, DKDLoss: 0.4437, 
2022-07-30 07:34:58 - train: epoch 0077, iter [04200, 05004], lr: 0.001000, loss: 1.2202, stu_CELoss: 0.7349, DKDLoss: 0.4853, 
2022-07-30 07:35:32 - train: epoch 0077, iter [04300, 05004], lr: 0.001000, loss: 1.2481, stu_CELoss: 0.8052, DKDLoss: 0.4429, 
2022-07-30 07:36:06 - train: epoch 0077, iter [04400, 05004], lr: 0.001000, loss: 1.5133, stu_CELoss: 1.0464, DKDLoss: 0.4669, 
2022-07-30 07:36:41 - train: epoch 0077, iter [04500, 05004], lr: 0.001000, loss: 1.3017, stu_CELoss: 0.8051, DKDLoss: 0.4966, 
2022-07-30 07:37:15 - train: epoch 0077, iter [04600, 05004], lr: 0.001000, loss: 0.9724, stu_CELoss: 0.5774, DKDLoss: 0.3950, 
2022-07-30 07:37:49 - train: epoch 0077, iter [04700, 05004], lr: 0.001000, loss: 1.2120, stu_CELoss: 0.7719, DKDLoss: 0.4401, 
2022-07-30 07:38:23 - train: epoch 0077, iter [04800, 05004], lr: 0.001000, loss: 1.1504, stu_CELoss: 0.7335, DKDLoss: 0.4169, 
2022-07-30 07:38:57 - train: epoch 0077, iter [04900, 05004], lr: 0.001000, loss: 1.4167, stu_CELoss: 0.9209, DKDLoss: 0.4958, 
2022-07-30 07:39:31 - train: epoch 0077, iter [05000, 05004], lr: 0.001000, loss: 1.2143, stu_CELoss: 0.7972, DKDLoss: 0.4171, 
2022-07-30 07:39:32 - train: epoch 077, train_loss: 1.2033
2022-07-30 07:42:05 - eval: epoch: 077, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.300%, stu_acc5: 93.428%, stu_test_loss: 0.9015
2022-07-30 07:42:06 - until epoch: 077, tea_best_acc1: 78.068%, stu_best_acc1: 77.384%
2022-07-30 07:42:06 - epoch 078 lr: 0.001000
2022-07-30 07:42:46 - train: epoch 0078, iter [00100, 05004], lr: 0.001000, loss: 1.3094, stu_CELoss: 0.8660, DKDLoss: 0.4434, 
2022-07-30 07:43:19 - train: epoch 0078, iter [00200, 05004], lr: 0.001000, loss: 1.1501, stu_CELoss: 0.7541, DKDLoss: 0.3960, 
2022-07-30 07:43:53 - train: epoch 0078, iter [00300, 05004], lr: 0.001000, loss: 1.2183, stu_CELoss: 0.7806, DKDLoss: 0.4376, 
2022-07-30 07:44:26 - train: epoch 0078, iter [00400, 05004], lr: 0.001000, loss: 1.2440, stu_CELoss: 0.8429, DKDLoss: 0.4011, 
2022-07-30 07:45:00 - train: epoch 0078, iter [00500, 05004], lr: 0.001000, loss: 1.0458, stu_CELoss: 0.6359, DKDLoss: 0.4099, 
2022-07-30 07:45:34 - train: epoch 0078, iter [00600, 05004], lr: 0.001000, loss: 1.0450, stu_CELoss: 0.6819, DKDLoss: 0.3632, 
2022-07-30 07:46:08 - train: epoch 0078, iter [00700, 05004], lr: 0.001000, loss: 1.2362, stu_CELoss: 0.8130, DKDLoss: 0.4232, 
2022-07-30 07:46:42 - train: epoch 0078, iter [00800, 05004], lr: 0.001000, loss: 1.2630, stu_CELoss: 0.8867, DKDLoss: 0.3763, 
2022-07-30 07:47:16 - train: epoch 0078, iter [00900, 05004], lr: 0.001000, loss: 1.3938, stu_CELoss: 0.9387, DKDLoss: 0.4551, 
2022-07-30 07:47:50 - train: epoch 0078, iter [01000, 05004], lr: 0.001000, loss: 1.0672, stu_CELoss: 0.6146, DKDLoss: 0.4526, 
2022-07-30 07:48:24 - train: epoch 0078, iter [01100, 05004], lr: 0.001000, loss: 1.1991, stu_CELoss: 0.7368, DKDLoss: 0.4622, 
2022-07-30 07:48:58 - train: epoch 0078, iter [01200, 05004], lr: 0.001000, loss: 1.2853, stu_CELoss: 0.8191, DKDLoss: 0.4662, 
2022-07-30 07:49:31 - train: epoch 0078, iter [01300, 05004], lr: 0.001000, loss: 1.1086, stu_CELoss: 0.7503, DKDLoss: 0.3583, 
2022-07-30 07:50:05 - train: epoch 0078, iter [01400, 05004], lr: 0.001000, loss: 1.0094, stu_CELoss: 0.5899, DKDLoss: 0.4195, 
2022-07-30 07:50:38 - train: epoch 0078, iter [01500, 05004], lr: 0.001000, loss: 1.0973, stu_CELoss: 0.6735, DKDLoss: 0.4238, 
2022-07-30 07:51:12 - train: epoch 0078, iter [01600, 05004], lr: 0.001000, loss: 1.1354, stu_CELoss: 0.7156, DKDLoss: 0.4198, 
2022-07-30 07:51:45 - train: epoch 0078, iter [01700, 05004], lr: 0.001000, loss: 1.3432, stu_CELoss: 0.9293, DKDLoss: 0.4139, 
2022-07-30 07:52:19 - train: epoch 0078, iter [01800, 05004], lr: 0.001000, loss: 1.2186, stu_CELoss: 0.7403, DKDLoss: 0.4783, 
2022-07-30 07:52:53 - train: epoch 0078, iter [01900, 05004], lr: 0.001000, loss: 1.0660, stu_CELoss: 0.6503, DKDLoss: 0.4157, 
2022-07-30 07:53:26 - train: epoch 0078, iter [02000, 05004], lr: 0.001000, loss: 1.2608, stu_CELoss: 0.7795, DKDLoss: 0.4813, 
2022-07-30 07:54:00 - train: epoch 0078, iter [02100, 05004], lr: 0.001000, loss: 1.3645, stu_CELoss: 0.9169, DKDLoss: 0.4476, 
2022-07-30 07:54:34 - train: epoch 0078, iter [02200, 05004], lr: 0.001000, loss: 1.2121, stu_CELoss: 0.7572, DKDLoss: 0.4549, 
2022-07-30 07:55:08 - train: epoch 0078, iter [02300, 05004], lr: 0.001000, loss: 1.2626, stu_CELoss: 0.7928, DKDLoss: 0.4698, 
2022-07-30 07:55:41 - train: epoch 0078, iter [02400, 05004], lr: 0.001000, loss: 1.3621, stu_CELoss: 0.8974, DKDLoss: 0.4647, 
2022-07-30 07:56:15 - train: epoch 0078, iter [02500, 05004], lr: 0.001000, loss: 1.1610, stu_CELoss: 0.7562, DKDLoss: 0.4048, 
2022-07-30 07:56:49 - train: epoch 0078, iter [02600, 05004], lr: 0.001000, loss: 1.1135, stu_CELoss: 0.6889, DKDLoss: 0.4246, 
2022-07-30 07:57:22 - train: epoch 0078, iter [02700, 05004], lr: 0.001000, loss: 1.2154, stu_CELoss: 0.7669, DKDLoss: 0.4485, 
2022-07-30 07:57:56 - train: epoch 0078, iter [02800, 05004], lr: 0.001000, loss: 1.2708, stu_CELoss: 0.8510, DKDLoss: 0.4198, 
2022-07-30 07:58:30 - train: epoch 0078, iter [02900, 05004], lr: 0.001000, loss: 1.2884, stu_CELoss: 0.8917, DKDLoss: 0.3967, 
2022-07-30 07:59:04 - train: epoch 0078, iter [03000, 05004], lr: 0.001000, loss: 1.1982, stu_CELoss: 0.7857, DKDLoss: 0.4125, 
2022-07-30 07:59:37 - train: epoch 0078, iter [03100, 05004], lr: 0.001000, loss: 1.3199, stu_CELoss: 0.8385, DKDLoss: 0.4815, 
2022-07-30 08:00:11 - train: epoch 0078, iter [03200, 05004], lr: 0.001000, loss: 1.0982, stu_CELoss: 0.6550, DKDLoss: 0.4431, 
2022-07-30 08:00:44 - train: epoch 0078, iter [03300, 05004], lr: 0.001000, loss: 1.3717, stu_CELoss: 0.9190, DKDLoss: 0.4527, 
2022-07-30 08:01:18 - train: epoch 0078, iter [03400, 05004], lr: 0.001000, loss: 1.1550, stu_CELoss: 0.7628, DKDLoss: 0.3922, 
2022-07-30 08:01:52 - train: epoch 0078, iter [03500, 05004], lr: 0.001000, loss: 1.1800, stu_CELoss: 0.7763, DKDLoss: 0.4036, 
2022-07-30 08:02:25 - train: epoch 0078, iter [03600, 05004], lr: 0.001000, loss: 1.2954, stu_CELoss: 0.8411, DKDLoss: 0.4544, 
2022-07-30 08:02:59 - train: epoch 0078, iter [03700, 05004], lr: 0.001000, loss: 1.2299, stu_CELoss: 0.8366, DKDLoss: 0.3933, 
2022-07-30 08:03:33 - train: epoch 0078, iter [03800, 05004], lr: 0.001000, loss: 1.1278, stu_CELoss: 0.6906, DKDLoss: 0.4372, 
2022-07-30 08:04:06 - train: epoch 0078, iter [03900, 05004], lr: 0.001000, loss: 1.1967, stu_CELoss: 0.7129, DKDLoss: 0.4838, 
2022-07-30 08:04:40 - train: epoch 0078, iter [04000, 05004], lr: 0.001000, loss: 1.1226, stu_CELoss: 0.6717, DKDLoss: 0.4508, 
2022-07-30 08:05:14 - train: epoch 0078, iter [04100, 05004], lr: 0.001000, loss: 1.1615, stu_CELoss: 0.7315, DKDLoss: 0.4300, 
2022-07-30 08:05:48 - train: epoch 0078, iter [04200, 05004], lr: 0.001000, loss: 1.2143, stu_CELoss: 0.7682, DKDLoss: 0.4461, 
2022-07-30 08:06:22 - train: epoch 0078, iter [04300, 05004], lr: 0.001000, loss: 1.1576, stu_CELoss: 0.7018, DKDLoss: 0.4559, 
2022-07-30 08:06:55 - train: epoch 0078, iter [04400, 05004], lr: 0.001000, loss: 1.0763, stu_CELoss: 0.6200, DKDLoss: 0.4562, 
2022-07-30 08:07:29 - train: epoch 0078, iter [04500, 05004], lr: 0.001000, loss: 1.3738, stu_CELoss: 0.9443, DKDLoss: 0.4295, 
2022-07-30 08:08:03 - train: epoch 0078, iter [04600, 05004], lr: 0.001000, loss: 1.0943, stu_CELoss: 0.6942, DKDLoss: 0.4001, 
2022-07-30 08:08:37 - train: epoch 0078, iter [04700, 05004], lr: 0.001000, loss: 1.1780, stu_CELoss: 0.7287, DKDLoss: 0.4493, 
2022-07-30 08:09:11 - train: epoch 0078, iter [04800, 05004], lr: 0.001000, loss: 1.4215, stu_CELoss: 0.8808, DKDLoss: 0.5407, 
2022-07-30 08:09:45 - train: epoch 0078, iter [04900, 05004], lr: 0.001000, loss: 1.1274, stu_CELoss: 0.7176, DKDLoss: 0.4097, 
2022-07-30 08:10:19 - train: epoch 0078, iter [05000, 05004], lr: 0.001000, loss: 1.2176, stu_CELoss: 0.7674, DKDLoss: 0.4503, 
2022-07-30 08:10:20 - train: epoch 078, train_loss: 1.1966
2022-07-30 08:12:53 - eval: epoch: 078, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.236%, stu_acc5: 93.450%, stu_test_loss: 0.9026
2022-07-30 08:12:54 - until epoch: 078, tea_best_acc1: 78.068%, stu_best_acc1: 77.384%
2022-07-30 08:12:54 - epoch 079 lr: 0.001000
2022-07-30 08:13:34 - train: epoch 0079, iter [00100, 05004], lr: 0.001000, loss: 1.1423, stu_CELoss: 0.7440, DKDLoss: 0.3983, 
2022-07-30 08:14:07 - train: epoch 0079, iter [00200, 05004], lr: 0.001000, loss: 1.1928, stu_CELoss: 0.7334, DKDLoss: 0.4594, 
2022-07-30 08:14:40 - train: epoch 0079, iter [00300, 05004], lr: 0.001000, loss: 1.1649, stu_CELoss: 0.7122, DKDLoss: 0.4527, 
2022-07-30 08:15:13 - train: epoch 0079, iter [00400, 05004], lr: 0.001000, loss: 1.1728, stu_CELoss: 0.7199, DKDLoss: 0.4530, 
2022-07-30 08:15:47 - train: epoch 0079, iter [00500, 05004], lr: 0.001000, loss: 1.1220, stu_CELoss: 0.6942, DKDLoss: 0.4278, 
2022-07-30 08:16:20 - train: epoch 0079, iter [00600, 05004], lr: 0.001000, loss: 1.0512, stu_CELoss: 0.6519, DKDLoss: 0.3993, 
2022-07-30 08:16:53 - train: epoch 0079, iter [00700, 05004], lr: 0.001000, loss: 1.2437, stu_CELoss: 0.7672, DKDLoss: 0.4764, 
2022-07-30 08:17:27 - train: epoch 0079, iter [00800, 05004], lr: 0.001000, loss: 1.2560, stu_CELoss: 0.8213, DKDLoss: 0.4347, 
2022-07-30 08:18:00 - train: epoch 0079, iter [00900, 05004], lr: 0.001000, loss: 1.0966, stu_CELoss: 0.6532, DKDLoss: 0.4434, 
2022-07-30 08:18:34 - train: epoch 0079, iter [01000, 05004], lr: 0.001000, loss: 1.1597, stu_CELoss: 0.7496, DKDLoss: 0.4102, 
2022-07-30 08:19:08 - train: epoch 0079, iter [01100, 05004], lr: 0.001000, loss: 1.2729, stu_CELoss: 0.8415, DKDLoss: 0.4314, 
2022-07-30 08:19:42 - train: epoch 0079, iter [01200, 05004], lr: 0.001000, loss: 1.4321, stu_CELoss: 0.9453, DKDLoss: 0.4867, 
2022-07-30 08:20:16 - train: epoch 0079, iter [01300, 05004], lr: 0.001000, loss: 1.0804, stu_CELoss: 0.6652, DKDLoss: 0.4152, 
2022-07-30 08:20:50 - train: epoch 0079, iter [01400, 05004], lr: 0.001000, loss: 1.1464, stu_CELoss: 0.6695, DKDLoss: 0.4769, 
2022-07-30 08:21:23 - train: epoch 0079, iter [01500, 05004], lr: 0.001000, loss: 1.1923, stu_CELoss: 0.7592, DKDLoss: 0.4331, 
2022-07-30 08:21:57 - train: epoch 0079, iter [01600, 05004], lr: 0.001000, loss: 0.9714, stu_CELoss: 0.5773, DKDLoss: 0.3942, 
2022-07-30 08:22:31 - train: epoch 0079, iter [01700, 05004], lr: 0.001000, loss: 1.1041, stu_CELoss: 0.6934, DKDLoss: 0.4106, 
2022-07-30 08:23:06 - train: epoch 0079, iter [01800, 05004], lr: 0.001000, loss: 1.3345, stu_CELoss: 0.8768, DKDLoss: 0.4577, 
2022-07-30 08:23:40 - train: epoch 0079, iter [01900, 05004], lr: 0.001000, loss: 1.1927, stu_CELoss: 0.7681, DKDLoss: 0.4247, 
2022-07-30 08:24:13 - train: epoch 0079, iter [02000, 05004], lr: 0.001000, loss: 1.4037, stu_CELoss: 0.8943, DKDLoss: 0.5094, 
2022-07-30 08:24:47 - train: epoch 0079, iter [02100, 05004], lr: 0.001000, loss: 1.2430, stu_CELoss: 0.7768, DKDLoss: 0.4662, 
2022-07-30 08:25:21 - train: epoch 0079, iter [02200, 05004], lr: 0.001000, loss: 1.2989, stu_CELoss: 0.8837, DKDLoss: 0.4151, 
2022-07-30 08:25:55 - train: epoch 0079, iter [02300, 05004], lr: 0.001000, loss: 1.2278, stu_CELoss: 0.7573, DKDLoss: 0.4705, 
2022-07-30 08:26:29 - train: epoch 0079, iter [02400, 05004], lr: 0.001000, loss: 1.1704, stu_CELoss: 0.7447, DKDLoss: 0.4257, 
2022-07-30 08:27:03 - train: epoch 0079, iter [02500, 05004], lr: 0.001000, loss: 1.2039, stu_CELoss: 0.7048, DKDLoss: 0.4990, 
2022-07-30 08:27:37 - train: epoch 0079, iter [02600, 05004], lr: 0.001000, loss: 1.1101, stu_CELoss: 0.7008, DKDLoss: 0.4093, 
2022-07-30 08:28:11 - train: epoch 0079, iter [02700, 05004], lr: 0.001000, loss: 1.1237, stu_CELoss: 0.7220, DKDLoss: 0.4017, 
2022-07-30 08:28:45 - train: epoch 0079, iter [02800, 05004], lr: 0.001000, loss: 1.1844, stu_CELoss: 0.7441, DKDLoss: 0.4403, 
2022-07-30 08:29:18 - train: epoch 0079, iter [02900, 05004], lr: 0.001000, loss: 1.1405, stu_CELoss: 0.6936, DKDLoss: 0.4470, 
2022-07-30 08:29:53 - train: epoch 0079, iter [03000, 05004], lr: 0.001000, loss: 1.2981, stu_CELoss: 0.8212, DKDLoss: 0.4769, 
2022-07-30 08:30:27 - train: epoch 0079, iter [03100, 05004], lr: 0.001000, loss: 1.2186, stu_CELoss: 0.8326, DKDLoss: 0.3860, 
2022-07-30 08:31:01 - train: epoch 0079, iter [03200, 05004], lr: 0.001000, loss: 1.1873, stu_CELoss: 0.7420, DKDLoss: 0.4453, 
2022-07-30 08:31:35 - train: epoch 0079, iter [03300, 05004], lr: 0.001000, loss: 1.1149, stu_CELoss: 0.6941, DKDLoss: 0.4208, 
2022-07-30 08:32:09 - train: epoch 0079, iter [03400, 05004], lr: 0.001000, loss: 1.1510, stu_CELoss: 0.6617, DKDLoss: 0.4893, 
2022-07-30 08:32:43 - train: epoch 0079, iter [03500, 05004], lr: 0.001000, loss: 1.3789, stu_CELoss: 0.8912, DKDLoss: 0.4877, 
2022-07-30 08:33:17 - train: epoch 0079, iter [03600, 05004], lr: 0.001000, loss: 0.9848, stu_CELoss: 0.5579, DKDLoss: 0.4269, 
2022-07-30 08:33:50 - train: epoch 0079, iter [03700, 05004], lr: 0.001000, loss: 1.3675, stu_CELoss: 0.9211, DKDLoss: 0.4463, 
2022-07-30 08:34:25 - train: epoch 0079, iter [03800, 05004], lr: 0.001000, loss: 1.0952, stu_CELoss: 0.6664, DKDLoss: 0.4288, 
2022-07-30 08:34:58 - train: epoch 0079, iter [03900, 05004], lr: 0.001000, loss: 1.2315, stu_CELoss: 0.7780, DKDLoss: 0.4536, 
2022-07-30 08:35:32 - train: epoch 0079, iter [04000, 05004], lr: 0.001000, loss: 0.9850, stu_CELoss: 0.5554, DKDLoss: 0.4297, 
2022-07-30 08:36:06 - train: epoch 0079, iter [04100, 05004], lr: 0.001000, loss: 1.2687, stu_CELoss: 0.8577, DKDLoss: 0.4110, 
2022-07-30 08:36:40 - train: epoch 0079, iter [04200, 05004], lr: 0.001000, loss: 1.3585, stu_CELoss: 0.8508, DKDLoss: 0.5077, 
2022-07-30 08:37:14 - train: epoch 0079, iter [04300, 05004], lr: 0.001000, loss: 0.9996, stu_CELoss: 0.6453, DKDLoss: 0.3543, 
2022-07-30 08:37:48 - train: epoch 0079, iter [04400, 05004], lr: 0.001000, loss: 1.2947, stu_CELoss: 0.8148, DKDLoss: 0.4799, 
2022-07-30 08:38:21 - train: epoch 0079, iter [04500, 05004], lr: 0.001000, loss: 1.1793, stu_CELoss: 0.7536, DKDLoss: 0.4257, 
2022-07-30 08:38:55 - train: epoch 0079, iter [04600, 05004], lr: 0.001000, loss: 1.3002, stu_CELoss: 0.8739, DKDLoss: 0.4263, 
2022-07-30 08:39:29 - train: epoch 0079, iter [04700, 05004], lr: 0.001000, loss: 1.0683, stu_CELoss: 0.6388, DKDLoss: 0.4294, 
2022-07-30 08:40:03 - train: epoch 0079, iter [04800, 05004], lr: 0.001000, loss: 1.2590, stu_CELoss: 0.8145, DKDLoss: 0.4445, 
2022-07-30 08:40:36 - train: epoch 0079, iter [04900, 05004], lr: 0.001000, loss: 1.1919, stu_CELoss: 0.7680, DKDLoss: 0.4239, 
2022-07-30 08:41:09 - train: epoch 0079, iter [05000, 05004], lr: 0.001000, loss: 1.0308, stu_CELoss: 0.6282, DKDLoss: 0.4026, 
2022-07-30 08:41:11 - train: epoch 079, train_loss: 1.1915
2022-07-30 08:43:44 - eval: epoch: 079, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.312%, stu_acc5: 93.500%, stu_test_loss: 0.9015
2022-07-30 08:43:44 - until epoch: 079, tea_best_acc1: 78.068%, stu_best_acc1: 77.384%
2022-07-30 08:43:44 - epoch 080 lr: 0.001000
2022-07-30 08:44:25 - train: epoch 0080, iter [00100, 05004], lr: 0.001000, loss: 1.0648, stu_CELoss: 0.6564, DKDLoss: 0.4084, 
2022-07-30 08:44:57 - train: epoch 0080, iter [00200, 05004], lr: 0.001000, loss: 1.3103, stu_CELoss: 0.8887, DKDLoss: 0.4216, 
2022-07-30 08:45:31 - train: epoch 0080, iter [00300, 05004], lr: 0.001000, loss: 1.0947, stu_CELoss: 0.7516, DKDLoss: 0.3431, 
2022-07-30 08:46:04 - train: epoch 0080, iter [00400, 05004], lr: 0.001000, loss: 1.0854, stu_CELoss: 0.6285, DKDLoss: 0.4569, 
2022-07-30 08:46:38 - train: epoch 0080, iter [00500, 05004], lr: 0.001000, loss: 1.1588, stu_CELoss: 0.7552, DKDLoss: 0.4036, 
2022-07-30 08:47:12 - train: epoch 0080, iter [00600, 05004], lr: 0.001000, loss: 1.1046, stu_CELoss: 0.6832, DKDLoss: 0.4215, 
2022-07-30 08:47:45 - train: epoch 0080, iter [00700, 05004], lr: 0.001000, loss: 1.1633, stu_CELoss: 0.7543, DKDLoss: 0.4090, 
2022-07-30 08:48:19 - train: epoch 0080, iter [00800, 05004], lr: 0.001000, loss: 1.0182, stu_CELoss: 0.6166, DKDLoss: 0.4016, 
2022-07-30 08:48:53 - train: epoch 0080, iter [00900, 05004], lr: 0.001000, loss: 1.1800, stu_CELoss: 0.7708, DKDLoss: 0.4092, 
2022-07-30 08:49:27 - train: epoch 0080, iter [01000, 05004], lr: 0.001000, loss: 1.1307, stu_CELoss: 0.7260, DKDLoss: 0.4047, 
2022-07-30 08:50:01 - train: epoch 0080, iter [01100, 05004], lr: 0.001000, loss: 1.0895, stu_CELoss: 0.6837, DKDLoss: 0.4058, 
2022-07-30 08:50:34 - train: epoch 0080, iter [01200, 05004], lr: 0.001000, loss: 1.2790, stu_CELoss: 0.8078, DKDLoss: 0.4712, 
2022-07-30 08:51:09 - train: epoch 0080, iter [01300, 05004], lr: 0.001000, loss: 1.0282, stu_CELoss: 0.6607, DKDLoss: 0.3675, 
2022-07-30 08:51:42 - train: epoch 0080, iter [01400, 05004], lr: 0.001000, loss: 1.2423, stu_CELoss: 0.7697, DKDLoss: 0.4726, 
2022-07-30 08:52:16 - train: epoch 0080, iter [01500, 05004], lr: 0.001000, loss: 1.0658, stu_CELoss: 0.6327, DKDLoss: 0.4331, 
2022-07-30 08:52:50 - train: epoch 0080, iter [01600, 05004], lr: 0.001000, loss: 1.2404, stu_CELoss: 0.8049, DKDLoss: 0.4355, 
2022-07-30 08:53:24 - train: epoch 0080, iter [01700, 05004], lr: 0.001000, loss: 1.1752, stu_CELoss: 0.7636, DKDLoss: 0.4116, 
2022-07-30 08:53:58 - train: epoch 0080, iter [01800, 05004], lr: 0.001000, loss: 1.1754, stu_CELoss: 0.7770, DKDLoss: 0.3984, 
2022-07-30 08:54:32 - train: epoch 0080, iter [01900, 05004], lr: 0.001000, loss: 1.2541, stu_CELoss: 0.8683, DKDLoss: 0.3858, 
2022-07-30 08:55:07 - train: epoch 0080, iter [02000, 05004], lr: 0.001000, loss: 1.2780, stu_CELoss: 0.8590, DKDLoss: 0.4190, 
2022-07-30 08:55:41 - train: epoch 0080, iter [02100, 05004], lr: 0.001000, loss: 1.2243, stu_CELoss: 0.7660, DKDLoss: 0.4582, 
2022-07-30 08:56:15 - train: epoch 0080, iter [02200, 05004], lr: 0.001000, loss: 1.4756, stu_CELoss: 0.9885, DKDLoss: 0.4871, 
2022-07-30 08:56:49 - train: epoch 0080, iter [02300, 05004], lr: 0.001000, loss: 1.2837, stu_CELoss: 0.8006, DKDLoss: 0.4831, 
2022-07-30 08:57:24 - train: epoch 0080, iter [02400, 05004], lr: 0.001000, loss: 1.3032, stu_CELoss: 0.8699, DKDLoss: 0.4333, 
2022-07-30 08:57:58 - train: epoch 0080, iter [02500, 05004], lr: 0.001000, loss: 1.0499, stu_CELoss: 0.6122, DKDLoss: 0.4377, 
2022-07-30 08:58:32 - train: epoch 0080, iter [02600, 05004], lr: 0.001000, loss: 1.1956, stu_CELoss: 0.7436, DKDLoss: 0.4520, 
2022-07-30 08:59:06 - train: epoch 0080, iter [02700, 05004], lr: 0.001000, loss: 1.0505, stu_CELoss: 0.6263, DKDLoss: 0.4241, 
2022-07-30 08:59:41 - train: epoch 0080, iter [02800, 05004], lr: 0.001000, loss: 1.0969, stu_CELoss: 0.6364, DKDLoss: 0.4605, 
2022-07-30 09:00:15 - train: epoch 0080, iter [02900, 05004], lr: 0.001000, loss: 1.3757, stu_CELoss: 0.8974, DKDLoss: 0.4783, 
2022-07-30 09:00:49 - train: epoch 0080, iter [03000, 05004], lr: 0.001000, loss: 1.2240, stu_CELoss: 0.7425, DKDLoss: 0.4814, 
2022-07-30 09:01:23 - train: epoch 0080, iter [03100, 05004], lr: 0.001000, loss: 1.2694, stu_CELoss: 0.7797, DKDLoss: 0.4897, 
2022-07-30 09:01:57 - train: epoch 0080, iter [03200, 05004], lr: 0.001000, loss: 1.0375, stu_CELoss: 0.6238, DKDLoss: 0.4137, 
2022-07-30 09:02:31 - train: epoch 0080, iter [03300, 05004], lr: 0.001000, loss: 1.1850, stu_CELoss: 0.7573, DKDLoss: 0.4277, 
2022-07-30 09:03:06 - train: epoch 0080, iter [03400, 05004], lr: 0.001000, loss: 1.2079, stu_CELoss: 0.7798, DKDLoss: 0.4282, 
2022-07-30 09:03:40 - train: epoch 0080, iter [03500, 05004], lr: 0.001000, loss: 1.2735, stu_CELoss: 0.8291, DKDLoss: 0.4444, 
2022-07-30 09:04:15 - train: epoch 0080, iter [03600, 05004], lr: 0.001000, loss: 1.1622, stu_CELoss: 0.7212, DKDLoss: 0.4410, 
2022-07-30 09:04:49 - train: epoch 0080, iter [03700, 05004], lr: 0.001000, loss: 1.2048, stu_CELoss: 0.7651, DKDLoss: 0.4397, 
2022-07-30 09:05:23 - train: epoch 0080, iter [03800, 05004], lr: 0.001000, loss: 1.3099, stu_CELoss: 0.8776, DKDLoss: 0.4323, 
2022-07-30 09:05:57 - train: epoch 0080, iter [03900, 05004], lr: 0.001000, loss: 1.1354, stu_CELoss: 0.7030, DKDLoss: 0.4324, 
2022-07-30 09:06:32 - train: epoch 0080, iter [04000, 05004], lr: 0.001000, loss: 1.2083, stu_CELoss: 0.7766, DKDLoss: 0.4317, 
2022-07-30 09:07:06 - train: epoch 0080, iter [04100, 05004], lr: 0.001000, loss: 1.2764, stu_CELoss: 0.8156, DKDLoss: 0.4608, 
2022-07-30 09:07:40 - train: epoch 0080, iter [04200, 05004], lr: 0.001000, loss: 1.2449, stu_CELoss: 0.8110, DKDLoss: 0.4338, 
2022-07-30 09:08:14 - train: epoch 0080, iter [04300, 05004], lr: 0.001000, loss: 1.1847, stu_CELoss: 0.7645, DKDLoss: 0.4203, 
2022-07-30 09:08:48 - train: epoch 0080, iter [04400, 05004], lr: 0.001000, loss: 1.0910, stu_CELoss: 0.7002, DKDLoss: 0.3908, 
2022-07-30 09:09:22 - train: epoch 0080, iter [04500, 05004], lr: 0.001000, loss: 1.1028, stu_CELoss: 0.6712, DKDLoss: 0.4316, 
2022-07-30 09:09:56 - train: epoch 0080, iter [04600, 05004], lr: 0.001000, loss: 1.0628, stu_CELoss: 0.6221, DKDLoss: 0.4406, 
2022-07-30 09:10:30 - train: epoch 0080, iter [04700, 05004], lr: 0.001000, loss: 1.1153, stu_CELoss: 0.6839, DKDLoss: 0.4313, 
2022-07-30 09:11:05 - train: epoch 0080, iter [04800, 05004], lr: 0.001000, loss: 1.3610, stu_CELoss: 0.9338, DKDLoss: 0.4272, 
2022-07-30 09:11:39 - train: epoch 0080, iter [04900, 05004], lr: 0.001000, loss: 1.3914, stu_CELoss: 0.9040, DKDLoss: 0.4874, 
2022-07-30 09:12:13 - train: epoch 0080, iter [05000, 05004], lr: 0.001000, loss: 1.0826, stu_CELoss: 0.6487, DKDLoss: 0.4339, 
2022-07-30 09:12:14 - train: epoch 080, train_loss: 1.1857
2022-07-30 09:14:47 - eval: epoch: 080, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.368%, stu_acc5: 93.472%, stu_test_loss: 0.9016
2022-07-30 09:14:47 - until epoch: 080, tea_best_acc1: 78.068%, stu_best_acc1: 77.384%
2022-07-30 09:14:47 - epoch 081 lr: 0.001000
2022-07-30 09:15:27 - train: epoch 0081, iter [00100, 05004], lr: 0.001000, loss: 1.0401, stu_CELoss: 0.6270, DKDLoss: 0.4131, 
2022-07-30 09:16:01 - train: epoch 0081, iter [00200, 05004], lr: 0.001000, loss: 1.0149, stu_CELoss: 0.5861, DKDLoss: 0.4289, 
2022-07-30 09:16:34 - train: epoch 0081, iter [00300, 05004], lr: 0.001000, loss: 1.3698, stu_CELoss: 0.9159, DKDLoss: 0.4538, 
2022-07-30 09:17:08 - train: epoch 0081, iter [00400, 05004], lr: 0.001000, loss: 1.1937, stu_CELoss: 0.7482, DKDLoss: 0.4455, 
2022-07-30 09:17:42 - train: epoch 0081, iter [00500, 05004], lr: 0.001000, loss: 1.2849, stu_CELoss: 0.8567, DKDLoss: 0.4281, 
2022-07-30 09:18:16 - train: epoch 0081, iter [00600, 05004], lr: 0.001000, loss: 1.1883, stu_CELoss: 0.7517, DKDLoss: 0.4366, 
2022-07-30 09:18:50 - train: epoch 0081, iter [00700, 05004], lr: 0.001000, loss: 1.1405, stu_CELoss: 0.6713, DKDLoss: 0.4692, 
2022-07-30 09:19:25 - train: epoch 0081, iter [00800, 05004], lr: 0.001000, loss: 1.1718, stu_CELoss: 0.7410, DKDLoss: 0.4308, 
2022-07-30 09:19:59 - train: epoch 0081, iter [00900, 05004], lr: 0.001000, loss: 1.0489, stu_CELoss: 0.6217, DKDLoss: 0.4272, 
2022-07-30 09:20:33 - train: epoch 0081, iter [01000, 05004], lr: 0.001000, loss: 1.2349, stu_CELoss: 0.7697, DKDLoss: 0.4653, 
2022-07-30 09:21:07 - train: epoch 0081, iter [01100, 05004], lr: 0.001000, loss: 1.1363, stu_CELoss: 0.7153, DKDLoss: 0.4209, 
2022-07-30 09:21:41 - train: epoch 0081, iter [01200, 05004], lr: 0.001000, loss: 1.1599, stu_CELoss: 0.6941, DKDLoss: 0.4658, 
2022-07-30 09:22:15 - train: epoch 0081, iter [01300, 05004], lr: 0.001000, loss: 1.1322, stu_CELoss: 0.7067, DKDLoss: 0.4255, 
2022-07-30 09:22:50 - train: epoch 0081, iter [01400, 05004], lr: 0.001000, loss: 0.9846, stu_CELoss: 0.5256, DKDLoss: 0.4589, 
2022-07-30 09:23:24 - train: epoch 0081, iter [01500, 05004], lr: 0.001000, loss: 1.1938, stu_CELoss: 0.7716, DKDLoss: 0.4221, 
2022-07-30 09:23:59 - train: epoch 0081, iter [01600, 05004], lr: 0.001000, loss: 1.0268, stu_CELoss: 0.6095, DKDLoss: 0.4173, 
2022-07-30 09:24:33 - train: epoch 0081, iter [01700, 05004], lr: 0.001000, loss: 1.1586, stu_CELoss: 0.7149, DKDLoss: 0.4437, 
2022-07-30 09:25:08 - train: epoch 0081, iter [01800, 05004], lr: 0.001000, loss: 1.3014, stu_CELoss: 0.8362, DKDLoss: 0.4653, 
2022-07-30 09:25:43 - train: epoch 0081, iter [01900, 05004], lr: 0.001000, loss: 1.2082, stu_CELoss: 0.7976, DKDLoss: 0.4106, 
2022-07-30 09:26:17 - train: epoch 0081, iter [02000, 05004], lr: 0.001000, loss: 1.1513, stu_CELoss: 0.7618, DKDLoss: 0.3895, 
2022-07-30 09:26:51 - train: epoch 0081, iter [02100, 05004], lr: 0.001000, loss: 1.2644, stu_CELoss: 0.7889, DKDLoss: 0.4755, 
2022-07-30 09:27:26 - train: epoch 0081, iter [02200, 05004], lr: 0.001000, loss: 1.1452, stu_CELoss: 0.7178, DKDLoss: 0.4274, 
2022-07-30 09:28:00 - train: epoch 0081, iter [02300, 05004], lr: 0.001000, loss: 1.1215, stu_CELoss: 0.6717, DKDLoss: 0.4498, 
2022-07-30 09:28:34 - train: epoch 0081, iter [02400, 05004], lr: 0.001000, loss: 1.2114, stu_CELoss: 0.7531, DKDLoss: 0.4583, 
2022-07-30 09:29:08 - train: epoch 0081, iter [02500, 05004], lr: 0.001000, loss: 1.2775, stu_CELoss: 0.8310, DKDLoss: 0.4466, 
2022-07-30 09:29:43 - train: epoch 0081, iter [02600, 05004], lr: 0.001000, loss: 1.1775, stu_CELoss: 0.7226, DKDLoss: 0.4549, 
2022-07-30 09:30:18 - train: epoch 0081, iter [02700, 05004], lr: 0.001000, loss: 1.1884, stu_CELoss: 0.7694, DKDLoss: 0.4190, 
2022-07-30 09:30:52 - train: epoch 0081, iter [02800, 05004], lr: 0.001000, loss: 1.1212, stu_CELoss: 0.7185, DKDLoss: 0.4026, 
2022-07-30 09:31:27 - train: epoch 0081, iter [02900, 05004], lr: 0.001000, loss: 1.0850, stu_CELoss: 0.6967, DKDLoss: 0.3883, 
2022-07-30 09:32:01 - train: epoch 0081, iter [03000, 05004], lr: 0.001000, loss: 1.0663, stu_CELoss: 0.6453, DKDLoss: 0.4209, 
2022-07-30 09:32:36 - train: epoch 0081, iter [03100, 05004], lr: 0.001000, loss: 1.0492, stu_CELoss: 0.6112, DKDLoss: 0.4380, 
2022-07-30 09:33:10 - train: epoch 0081, iter [03200, 05004], lr: 0.001000, loss: 1.0311, stu_CELoss: 0.6408, DKDLoss: 0.3903, 
2022-07-30 09:33:45 - train: epoch 0081, iter [03300, 05004], lr: 0.001000, loss: 1.3955, stu_CELoss: 0.8844, DKDLoss: 0.5111, 
2022-07-30 09:34:20 - train: epoch 0081, iter [03400, 05004], lr: 0.001000, loss: 1.1988, stu_CELoss: 0.8037, DKDLoss: 0.3951, 
2022-07-30 09:34:54 - train: epoch 0081, iter [03500, 05004], lr: 0.001000, loss: 1.3002, stu_CELoss: 0.8827, DKDLoss: 0.4175, 
2022-07-30 09:35:29 - train: epoch 0081, iter [03600, 05004], lr: 0.001000, loss: 1.0887, stu_CELoss: 0.6710, DKDLoss: 0.4177, 
2022-07-30 09:36:04 - train: epoch 0081, iter [03700, 05004], lr: 0.001000, loss: 1.2742, stu_CELoss: 0.8276, DKDLoss: 0.4466, 
2022-07-30 09:36:38 - train: epoch 0081, iter [03800, 05004], lr: 0.001000, loss: 1.2225, stu_CELoss: 0.7572, DKDLoss: 0.4653, 
2022-07-30 09:37:13 - train: epoch 0081, iter [03900, 05004], lr: 0.001000, loss: 1.2717, stu_CELoss: 0.8541, DKDLoss: 0.4176, 
2022-07-30 09:37:48 - train: epoch 0081, iter [04000, 05004], lr: 0.001000, loss: 1.0026, stu_CELoss: 0.5901, DKDLoss: 0.4125, 
2022-07-30 09:38:23 - train: epoch 0081, iter [04100, 05004], lr: 0.001000, loss: 1.0875, stu_CELoss: 0.6951, DKDLoss: 0.3923, 
2022-07-30 09:38:57 - train: epoch 0081, iter [04200, 05004], lr: 0.001000, loss: 1.2709, stu_CELoss: 0.8139, DKDLoss: 0.4570, 
2022-07-30 09:39:31 - train: epoch 0081, iter [04300, 05004], lr: 0.001000, loss: 1.1674, stu_CELoss: 0.7615, DKDLoss: 0.4059, 
2022-07-30 09:40:06 - train: epoch 0081, iter [04400, 05004], lr: 0.001000, loss: 1.2542, stu_CELoss: 0.7940, DKDLoss: 0.4602, 
2022-07-30 09:40:40 - train: epoch 0081, iter [04500, 05004], lr: 0.001000, loss: 1.2741, stu_CELoss: 0.7613, DKDLoss: 0.5127, 
2022-07-30 09:41:15 - train: epoch 0081, iter [04600, 05004], lr: 0.001000, loss: 1.0873, stu_CELoss: 0.6456, DKDLoss: 0.4418, 
2022-07-30 09:41:49 - train: epoch 0081, iter [04700, 05004], lr: 0.001000, loss: 1.0345, stu_CELoss: 0.6093, DKDLoss: 0.4252, 
2022-07-30 09:42:24 - train: epoch 0081, iter [04800, 05004], lr: 0.001000, loss: 1.1998, stu_CELoss: 0.8029, DKDLoss: 0.3968, 
2022-07-30 09:42:58 - train: epoch 0081, iter [04900, 05004], lr: 0.001000, loss: 1.2163, stu_CELoss: 0.7933, DKDLoss: 0.4230, 
2022-07-30 09:43:32 - train: epoch 0081, iter [05000, 05004], lr: 0.001000, loss: 1.0716, stu_CELoss: 0.6470, DKDLoss: 0.4246, 
2022-07-30 09:43:34 - train: epoch 081, train_loss: 1.1809
2022-07-30 09:46:07 - eval: epoch: 081, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.270%, stu_acc5: 93.510%, stu_test_loss: 0.9019
2022-07-30 09:46:08 - until epoch: 081, tea_best_acc1: 78.068%, stu_best_acc1: 77.384%
2022-07-30 09:46:08 - epoch 082 lr: 0.001000
2022-07-30 09:46:49 - train: epoch 0082, iter [00100, 05004], lr: 0.001000, loss: 0.9566, stu_CELoss: 0.5566, DKDLoss: 0.4000, 
2022-07-30 09:47:22 - train: epoch 0082, iter [00200, 05004], lr: 0.001000, loss: 1.1289, stu_CELoss: 0.6990, DKDLoss: 0.4299, 
2022-07-30 09:47:56 - train: epoch 0082, iter [00300, 05004], lr: 0.001000, loss: 1.2105, stu_CELoss: 0.7871, DKDLoss: 0.4234, 
2022-07-30 09:48:30 - train: epoch 0082, iter [00400, 05004], lr: 0.001000, loss: 1.2066, stu_CELoss: 0.7514, DKDLoss: 0.4552, 
2022-07-30 09:49:04 - train: epoch 0082, iter [00500, 05004], lr: 0.001000, loss: 1.3029, stu_CELoss: 0.8582, DKDLoss: 0.4447, 
2022-07-30 09:49:39 - train: epoch 0082, iter [00600, 05004], lr: 0.001000, loss: 1.1406, stu_CELoss: 0.6671, DKDLoss: 0.4735, 
2022-07-30 09:50:13 - train: epoch 0082, iter [00700, 05004], lr: 0.001000, loss: 1.3611, stu_CELoss: 0.9477, DKDLoss: 0.4134, 
2022-07-30 09:50:47 - train: epoch 0082, iter [00800, 05004], lr: 0.001000, loss: 1.2505, stu_CELoss: 0.8387, DKDLoss: 0.4118, 
2022-07-30 09:51:22 - train: epoch 0082, iter [00900, 05004], lr: 0.001000, loss: 1.1676, stu_CELoss: 0.7319, DKDLoss: 0.4357, 
2022-07-30 09:51:56 - train: epoch 0082, iter [01000, 05004], lr: 0.001000, loss: 1.0634, stu_CELoss: 0.6088, DKDLoss: 0.4545, 
2022-07-30 09:52:30 - train: epoch 0082, iter [01100, 05004], lr: 0.001000, loss: 1.1758, stu_CELoss: 0.7269, DKDLoss: 0.4489, 
2022-07-30 09:53:05 - train: epoch 0082, iter [01200, 05004], lr: 0.001000, loss: 1.2492, stu_CELoss: 0.8114, DKDLoss: 0.4378, 
2022-07-30 09:53:39 - train: epoch 0082, iter [01300, 05004], lr: 0.001000, loss: 1.3684, stu_CELoss: 0.9095, DKDLoss: 0.4589, 
2022-07-30 09:54:14 - train: epoch 0082, iter [01400, 05004], lr: 0.001000, loss: 1.0076, stu_CELoss: 0.5829, DKDLoss: 0.4247, 
2022-07-30 09:54:48 - train: epoch 0082, iter [01500, 05004], lr: 0.001000, loss: 1.1687, stu_CELoss: 0.7244, DKDLoss: 0.4443, 
2022-07-30 09:55:23 - train: epoch 0082, iter [01600, 05004], lr: 0.001000, loss: 1.2488, stu_CELoss: 0.7856, DKDLoss: 0.4632, 
2022-07-30 09:55:57 - train: epoch 0082, iter [01700, 05004], lr: 0.001000, loss: 1.0558, stu_CELoss: 0.6397, DKDLoss: 0.4161, 
2022-07-30 09:56:31 - train: epoch 0082, iter [01800, 05004], lr: 0.001000, loss: 1.0940, stu_CELoss: 0.7138, DKDLoss: 0.3802, 
2022-07-30 09:57:05 - train: epoch 0082, iter [01900, 05004], lr: 0.001000, loss: 1.2187, stu_CELoss: 0.8133, DKDLoss: 0.4055, 
2022-07-30 09:57:40 - train: epoch 0082, iter [02000, 05004], lr: 0.001000, loss: 1.1361, stu_CELoss: 0.7527, DKDLoss: 0.3834, 
2022-07-30 09:58:14 - train: epoch 0082, iter [02100, 05004], lr: 0.001000, loss: 1.2240, stu_CELoss: 0.8041, DKDLoss: 0.4200, 
2022-07-30 09:58:47 - train: epoch 0082, iter [02200, 05004], lr: 0.001000, loss: 1.2622, stu_CELoss: 0.7925, DKDLoss: 0.4697, 
2022-07-30 09:59:21 - train: epoch 0082, iter [02300, 05004], lr: 0.001000, loss: 1.2241, stu_CELoss: 0.7348, DKDLoss: 0.4894, 
2022-07-30 09:59:55 - train: epoch 0082, iter [02400, 05004], lr: 0.001000, loss: 1.2277, stu_CELoss: 0.8257, DKDLoss: 0.4020, 
2022-07-30 10:00:28 - train: epoch 0082, iter [02500, 05004], lr: 0.001000, loss: 1.0409, stu_CELoss: 0.6367, DKDLoss: 0.4042, 
2022-07-30 10:01:02 - train: epoch 0082, iter [02600, 05004], lr: 0.001000, loss: 1.1670, stu_CELoss: 0.7295, DKDLoss: 0.4375, 
2022-07-30 10:01:36 - train: epoch 0082, iter [02700, 05004], lr: 0.001000, loss: 1.0432, stu_CELoss: 0.6541, DKDLoss: 0.3891, 
2022-07-30 10:02:09 - train: epoch 0082, iter [02800, 05004], lr: 0.001000, loss: 1.0220, stu_CELoss: 0.6367, DKDLoss: 0.3852, 
2022-07-30 10:02:43 - train: epoch 0082, iter [02900, 05004], lr: 0.001000, loss: 1.0149, stu_CELoss: 0.6083, DKDLoss: 0.4066, 
2022-07-30 10:03:16 - train: epoch 0082, iter [03000, 05004], lr: 0.001000, loss: 1.1607, stu_CELoss: 0.6915, DKDLoss: 0.4692, 
2022-07-30 10:03:50 - train: epoch 0082, iter [03100, 05004], lr: 0.001000, loss: 1.3434, stu_CELoss: 0.8792, DKDLoss: 0.4643, 
2022-07-30 10:04:24 - train: epoch 0082, iter [03200, 05004], lr: 0.001000, loss: 1.2039, stu_CELoss: 0.7497, DKDLoss: 0.4542, 
2022-07-30 10:04:57 - train: epoch 0082, iter [03300, 05004], lr: 0.001000, loss: 1.1353, stu_CELoss: 0.6868, DKDLoss: 0.4485, 
2022-07-30 10:05:31 - train: epoch 0082, iter [03400, 05004], lr: 0.001000, loss: 1.1991, stu_CELoss: 0.7593, DKDLoss: 0.4398, 
2022-07-30 10:06:05 - train: epoch 0082, iter [03500, 05004], lr: 0.001000, loss: 0.9768, stu_CELoss: 0.6173, DKDLoss: 0.3594, 
2022-07-30 10:06:38 - train: epoch 0082, iter [03600, 05004], lr: 0.001000, loss: 1.2075, stu_CELoss: 0.7207, DKDLoss: 0.4868, 
2022-07-30 10:07:12 - train: epoch 0082, iter [03700, 05004], lr: 0.001000, loss: 1.0123, stu_CELoss: 0.6435, DKDLoss: 0.3688, 
2022-07-30 10:07:45 - train: epoch 0082, iter [03800, 05004], lr: 0.001000, loss: 1.2667, stu_CELoss: 0.8501, DKDLoss: 0.4166, 
2022-07-30 10:08:19 - train: epoch 0082, iter [03900, 05004], lr: 0.001000, loss: 1.1411, stu_CELoss: 0.6869, DKDLoss: 0.4542, 
2022-07-30 10:08:53 - train: epoch 0082, iter [04000, 05004], lr: 0.001000, loss: 1.3675, stu_CELoss: 0.9022, DKDLoss: 0.4653, 
2022-07-30 10:09:26 - train: epoch 0082, iter [04100, 05004], lr: 0.001000, loss: 1.3643, stu_CELoss: 0.8893, DKDLoss: 0.4750, 
2022-07-30 10:10:00 - train: epoch 0082, iter [04200, 05004], lr: 0.001000, loss: 1.2444, stu_CELoss: 0.8732, DKDLoss: 0.3712, 
2022-07-30 10:10:34 - train: epoch 0082, iter [04300, 05004], lr: 0.001000, loss: 1.0791, stu_CELoss: 0.6640, DKDLoss: 0.4151, 
2022-07-30 10:11:07 - train: epoch 0082, iter [04400, 05004], lr: 0.001000, loss: 1.1258, stu_CELoss: 0.7375, DKDLoss: 0.3883, 
2022-07-30 10:11:41 - train: epoch 0082, iter [04500, 05004], lr: 0.001000, loss: 1.1669, stu_CELoss: 0.7283, DKDLoss: 0.4386, 
2022-07-30 10:12:14 - train: epoch 0082, iter [04600, 05004], lr: 0.001000, loss: 1.2304, stu_CELoss: 0.7321, DKDLoss: 0.4983, 
2022-07-30 10:12:48 - train: epoch 0082, iter [04700, 05004], lr: 0.001000, loss: 1.1342, stu_CELoss: 0.7028, DKDLoss: 0.4314, 
2022-07-30 10:13:21 - train: epoch 0082, iter [04800, 05004], lr: 0.001000, loss: 1.0983, stu_CELoss: 0.6402, DKDLoss: 0.4580, 
2022-07-30 10:13:55 - train: epoch 0082, iter [04900, 05004], lr: 0.001000, loss: 1.2288, stu_CELoss: 0.8245, DKDLoss: 0.4043, 
2022-07-30 10:14:28 - train: epoch 0082, iter [05000, 05004], lr: 0.001000, loss: 1.1265, stu_CELoss: 0.7009, DKDLoss: 0.4256, 
2022-07-30 10:14:30 - train: epoch 082, train_loss: 1.1755
2022-07-30 10:17:00 - eval: epoch: 082, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.362%, stu_acc5: 93.466%, stu_test_loss: 0.9022
2022-07-30 10:17:01 - until epoch: 082, tea_best_acc1: 78.068%, stu_best_acc1: 77.384%
2022-07-30 10:17:01 - epoch 083 lr: 0.001000
2022-07-30 10:17:40 - train: epoch 0083, iter [00100, 05004], lr: 0.001000, loss: 1.0618, stu_CELoss: 0.6962, DKDLoss: 0.3656, 
2022-07-30 10:18:13 - train: epoch 0083, iter [00200, 05004], lr: 0.001000, loss: 1.0261, stu_CELoss: 0.6362, DKDLoss: 0.3900, 
2022-07-30 10:18:46 - train: epoch 0083, iter [00300, 05004], lr: 0.001000, loss: 1.1891, stu_CELoss: 0.7724, DKDLoss: 0.4167, 
2022-07-30 10:19:19 - train: epoch 0083, iter [00400, 05004], lr: 0.001000, loss: 1.2401, stu_CELoss: 0.8651, DKDLoss: 0.3750, 
2022-07-30 10:19:52 - train: epoch 0083, iter [00500, 05004], lr: 0.001000, loss: 1.1128, stu_CELoss: 0.6662, DKDLoss: 0.4466, 
2022-07-30 10:20:25 - train: epoch 0083, iter [00600, 05004], lr: 0.001000, loss: 1.0443, stu_CELoss: 0.6452, DKDLoss: 0.3991, 
2022-07-30 10:20:59 - train: epoch 0083, iter [00700, 05004], lr: 0.001000, loss: 1.2065, stu_CELoss: 0.7564, DKDLoss: 0.4500, 
2022-07-30 10:21:32 - train: epoch 0083, iter [00800, 05004], lr: 0.001000, loss: 1.0831, stu_CELoss: 0.7180, DKDLoss: 0.3651, 
2022-07-30 10:22:06 - train: epoch 0083, iter [00900, 05004], lr: 0.001000, loss: 1.1619, stu_CELoss: 0.7126, DKDLoss: 0.4493, 
2022-07-30 10:22:39 - train: epoch 0083, iter [01000, 05004], lr: 0.001000, loss: 1.3500, stu_CELoss: 0.9040, DKDLoss: 0.4460, 
2022-07-30 10:23:12 - train: epoch 0083, iter [01100, 05004], lr: 0.001000, loss: 1.2746, stu_CELoss: 0.8365, DKDLoss: 0.4381, 
2022-07-30 10:23:46 - train: epoch 0083, iter [01200, 05004], lr: 0.001000, loss: 1.0797, stu_CELoss: 0.6121, DKDLoss: 0.4676, 
2022-07-30 10:24:19 - train: epoch 0083, iter [01300, 05004], lr: 0.001000, loss: 1.1776, stu_CELoss: 0.7437, DKDLoss: 0.4338, 
2022-07-30 10:24:53 - train: epoch 0083, iter [01400, 05004], lr: 0.001000, loss: 1.2386, stu_CELoss: 0.7696, DKDLoss: 0.4691, 
2022-07-30 10:25:26 - train: epoch 0083, iter [01500, 05004], lr: 0.001000, loss: 1.1064, stu_CELoss: 0.7291, DKDLoss: 0.3772, 
2022-07-30 10:26:00 - train: epoch 0083, iter [01600, 05004], lr: 0.001000, loss: 1.2022, stu_CELoss: 0.7533, DKDLoss: 0.4489, 
2022-07-30 10:26:33 - train: epoch 0083, iter [01700, 05004], lr: 0.001000, loss: 1.3302, stu_CELoss: 0.8501, DKDLoss: 0.4801, 
2022-07-30 10:27:07 - train: epoch 0083, iter [01800, 05004], lr: 0.001000, loss: 1.1953, stu_CELoss: 0.7582, DKDLoss: 0.4371, 
2022-07-30 10:27:41 - train: epoch 0083, iter [01900, 05004], lr: 0.001000, loss: 1.1806, stu_CELoss: 0.7522, DKDLoss: 0.4285, 
2022-07-30 10:28:14 - train: epoch 0083, iter [02000, 05004], lr: 0.001000, loss: 0.9914, stu_CELoss: 0.5893, DKDLoss: 0.4021, 
2022-07-30 10:28:48 - train: epoch 0083, iter [02100, 05004], lr: 0.001000, loss: 0.9643, stu_CELoss: 0.5457, DKDLoss: 0.4187, 
2022-07-30 10:29:21 - train: epoch 0083, iter [02200, 05004], lr: 0.001000, loss: 1.1861, stu_CELoss: 0.7620, DKDLoss: 0.4241, 
2022-07-30 10:29:55 - train: epoch 0083, iter [02300, 05004], lr: 0.001000, loss: 1.2591, stu_CELoss: 0.8205, DKDLoss: 0.4387, 
2022-07-30 10:30:29 - train: epoch 0083, iter [02400, 05004], lr: 0.001000, loss: 0.9761, stu_CELoss: 0.5652, DKDLoss: 0.4109, 
2022-07-30 10:31:02 - train: epoch 0083, iter [02500, 05004], lr: 0.001000, loss: 1.2451, stu_CELoss: 0.8679, DKDLoss: 0.3772, 
2022-07-30 10:31:36 - train: epoch 0083, iter [02600, 05004], lr: 0.001000, loss: 1.1475, stu_CELoss: 0.7126, DKDLoss: 0.4349, 
2022-07-30 10:32:10 - train: epoch 0083, iter [02700, 05004], lr: 0.001000, loss: 1.2286, stu_CELoss: 0.8109, DKDLoss: 0.4177, 
2022-07-30 10:32:44 - train: epoch 0083, iter [02800, 05004], lr: 0.001000, loss: 1.2891, stu_CELoss: 0.8694, DKDLoss: 0.4197, 
2022-07-30 10:33:18 - train: epoch 0083, iter [02900, 05004], lr: 0.001000, loss: 1.1860, stu_CELoss: 0.7326, DKDLoss: 0.4534, 
2022-07-30 10:33:51 - train: epoch 0083, iter [03000, 05004], lr: 0.001000, loss: 1.3475, stu_CELoss: 0.9180, DKDLoss: 0.4296, 
2022-07-30 10:34:25 - train: epoch 0083, iter [03100, 05004], lr: 0.001000, loss: 1.1305, stu_CELoss: 0.6915, DKDLoss: 0.4390, 
2022-07-30 10:34:58 - train: epoch 0083, iter [03200, 05004], lr: 0.001000, loss: 1.1002, stu_CELoss: 0.6905, DKDLoss: 0.4097, 
2022-07-30 10:35:32 - train: epoch 0083, iter [03300, 05004], lr: 0.001000, loss: 1.5089, stu_CELoss: 1.0537, DKDLoss: 0.4552, 
2022-07-30 10:36:06 - train: epoch 0083, iter [03400, 05004], lr: 0.001000, loss: 1.2205, stu_CELoss: 0.7982, DKDLoss: 0.4224, 
2022-07-30 10:36:40 - train: epoch 0083, iter [03500, 05004], lr: 0.001000, loss: 1.2080, stu_CELoss: 0.7782, DKDLoss: 0.4298, 
2022-07-30 10:37:14 - train: epoch 0083, iter [03600, 05004], lr: 0.001000, loss: 1.1389, stu_CELoss: 0.7660, DKDLoss: 0.3729, 
2022-07-30 10:37:47 - train: epoch 0083, iter [03700, 05004], lr: 0.001000, loss: 0.9411, stu_CELoss: 0.5641, DKDLoss: 0.3770, 
2022-07-30 10:38:21 - train: epoch 0083, iter [03800, 05004], lr: 0.001000, loss: 1.0881, stu_CELoss: 0.6727, DKDLoss: 0.4153, 
2022-07-30 10:38:55 - train: epoch 0083, iter [03900, 05004], lr: 0.001000, loss: 1.2453, stu_CELoss: 0.7401, DKDLoss: 0.5052, 
2022-07-30 10:39:29 - train: epoch 0083, iter [04000, 05004], lr: 0.001000, loss: 1.2341, stu_CELoss: 0.8104, DKDLoss: 0.4236, 
2022-07-30 10:40:03 - train: epoch 0083, iter [04100, 05004], lr: 0.001000, loss: 1.0525, stu_CELoss: 0.6601, DKDLoss: 0.3924, 
2022-07-30 10:40:37 - train: epoch 0083, iter [04200, 05004], lr: 0.001000, loss: 1.2093, stu_CELoss: 0.7570, DKDLoss: 0.4524, 
2022-07-30 10:41:10 - train: epoch 0083, iter [04300, 05004], lr: 0.001000, loss: 1.2283, stu_CELoss: 0.7986, DKDLoss: 0.4297, 
2022-07-30 10:41:44 - train: epoch 0083, iter [04400, 05004], lr: 0.001000, loss: 1.2084, stu_CELoss: 0.7925, DKDLoss: 0.4159, 
2022-07-30 10:42:18 - train: epoch 0083, iter [04500, 05004], lr: 0.001000, loss: 1.1909, stu_CELoss: 0.7258, DKDLoss: 0.4650, 
2022-07-30 10:42:51 - train: epoch 0083, iter [04600, 05004], lr: 0.001000, loss: 1.2435, stu_CELoss: 0.8220, DKDLoss: 0.4215, 
2022-07-30 10:43:25 - train: epoch 0083, iter [04700, 05004], lr: 0.001000, loss: 1.2116, stu_CELoss: 0.7430, DKDLoss: 0.4686, 
2022-07-30 10:43:59 - train: epoch 0083, iter [04800, 05004], lr: 0.001000, loss: 1.1869, stu_CELoss: 0.7193, DKDLoss: 0.4676, 
2022-07-30 10:44:33 - train: epoch 0083, iter [04900, 05004], lr: 0.001000, loss: 1.3242, stu_CELoss: 0.8682, DKDLoss: 0.4560, 
2022-07-30 10:45:07 - train: epoch 0083, iter [05000, 05004], lr: 0.001000, loss: 1.2431, stu_CELoss: 0.8082, DKDLoss: 0.4349, 
2022-07-30 10:45:09 - train: epoch 083, train_loss: 1.1708
2022-07-30 10:47:41 - eval: epoch: 083, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.280%, stu_acc5: 93.496%, stu_test_loss: 0.9036
2022-07-30 10:47:42 - until epoch: 083, tea_best_acc1: 78.068%, stu_best_acc1: 77.384%
2022-07-30 10:47:42 - epoch 084 lr: 0.001000
2022-07-30 10:48:22 - train: epoch 0084, iter [00100, 05004], lr: 0.001000, loss: 1.2268, stu_CELoss: 0.7773, DKDLoss: 0.4495, 
2022-07-30 10:48:55 - train: epoch 0084, iter [00200, 05004], lr: 0.001000, loss: 1.2872, stu_CELoss: 0.8768, DKDLoss: 0.4104, 
2022-07-30 10:49:27 - train: epoch 0084, iter [00300, 05004], lr: 0.001000, loss: 1.0212, stu_CELoss: 0.5928, DKDLoss: 0.4284, 
2022-07-30 10:50:01 - train: epoch 0084, iter [00400, 05004], lr: 0.001000, loss: 1.1804, stu_CELoss: 0.7513, DKDLoss: 0.4291, 
2022-07-30 10:50:35 - train: epoch 0084, iter [00500, 05004], lr: 0.001000, loss: 1.2210, stu_CELoss: 0.7457, DKDLoss: 0.4753, 
2022-07-30 10:51:09 - train: epoch 0084, iter [00600, 05004], lr: 0.001000, loss: 1.1351, stu_CELoss: 0.6886, DKDLoss: 0.4464, 
2022-07-30 10:51:42 - train: epoch 0084, iter [00700, 05004], lr: 0.001000, loss: 1.1794, stu_CELoss: 0.7248, DKDLoss: 0.4545, 
2022-07-30 10:52:16 - train: epoch 0084, iter [00800, 05004], lr: 0.001000, loss: 1.1396, stu_CELoss: 0.7742, DKDLoss: 0.3654, 
2022-07-30 10:52:50 - train: epoch 0084, iter [00900, 05004], lr: 0.001000, loss: 1.1476, stu_CELoss: 0.7249, DKDLoss: 0.4227, 
2022-07-30 10:53:24 - train: epoch 0084, iter [01000, 05004], lr: 0.001000, loss: 1.2825, stu_CELoss: 0.8604, DKDLoss: 0.4221, 
2022-07-30 10:53:58 - train: epoch 0084, iter [01100, 05004], lr: 0.001000, loss: 1.1301, stu_CELoss: 0.7472, DKDLoss: 0.3830, 
2022-07-30 10:54:31 - train: epoch 0084, iter [01200, 05004], lr: 0.001000, loss: 1.3533, stu_CELoss: 0.9292, DKDLoss: 0.4241, 
2022-07-30 10:55:05 - train: epoch 0084, iter [01300, 05004], lr: 0.001000, loss: 1.1990, stu_CELoss: 0.7664, DKDLoss: 0.4326, 
2022-07-30 10:55:39 - train: epoch 0084, iter [01400, 05004], lr: 0.001000, loss: 1.2107, stu_CELoss: 0.8373, DKDLoss: 0.3735, 
2022-07-30 10:56:13 - train: epoch 0084, iter [01500, 05004], lr: 0.001000, loss: 1.1244, stu_CELoss: 0.7486, DKDLoss: 0.3758, 
2022-07-30 10:56:47 - train: epoch 0084, iter [01600, 05004], lr: 0.001000, loss: 1.1064, stu_CELoss: 0.6796, DKDLoss: 0.4269, 
2022-07-30 10:57:22 - train: epoch 0084, iter [01700, 05004], lr: 0.001000, loss: 1.1871, stu_CELoss: 0.7418, DKDLoss: 0.4453, 
2022-07-30 10:57:55 - train: epoch 0084, iter [01800, 05004], lr: 0.001000, loss: 1.3880, stu_CELoss: 0.9642, DKDLoss: 0.4237, 
2022-07-30 10:58:29 - train: epoch 0084, iter [01900, 05004], lr: 0.001000, loss: 1.3390, stu_CELoss: 0.9899, DKDLoss: 0.3492, 
2022-07-30 10:59:04 - train: epoch 0084, iter [02000, 05004], lr: 0.001000, loss: 1.0969, stu_CELoss: 0.7379, DKDLoss: 0.3590, 
2022-07-30 10:59:38 - train: epoch 0084, iter [02100, 05004], lr: 0.001000, loss: 1.2142, stu_CELoss: 0.8276, DKDLoss: 0.3866, 
2022-07-30 11:00:12 - train: epoch 0084, iter [02200, 05004], lr: 0.001000, loss: 1.2245, stu_CELoss: 0.8166, DKDLoss: 0.4079, 
2022-07-30 11:00:46 - train: epoch 0084, iter [02300, 05004], lr: 0.001000, loss: 1.1045, stu_CELoss: 0.6916, DKDLoss: 0.4130, 
2022-07-30 11:01:20 - train: epoch 0084, iter [02400, 05004], lr: 0.001000, loss: 1.1387, stu_CELoss: 0.6944, DKDLoss: 0.4443, 
2022-07-30 11:01:54 - train: epoch 0084, iter [02500, 05004], lr: 0.001000, loss: 1.2819, stu_CELoss: 0.8570, DKDLoss: 0.4248, 
2022-07-30 11:02:27 - train: epoch 0084, iter [02600, 05004], lr: 0.001000, loss: 1.1546, stu_CELoss: 0.7289, DKDLoss: 0.4257, 
2022-07-30 11:03:01 - train: epoch 0084, iter [02700, 05004], lr: 0.001000, loss: 1.2623, stu_CELoss: 0.7912, DKDLoss: 0.4712, 
2022-07-30 11:03:35 - train: epoch 0084, iter [02800, 05004], lr: 0.001000, loss: 1.2330, stu_CELoss: 0.7846, DKDLoss: 0.4484, 
2022-07-30 11:04:09 - train: epoch 0084, iter [02900, 05004], lr: 0.001000, loss: 1.2340, stu_CELoss: 0.8019, DKDLoss: 0.4322, 
2022-07-30 11:04:43 - train: epoch 0084, iter [03000, 05004], lr: 0.001000, loss: 1.3317, stu_CELoss: 0.8610, DKDLoss: 0.4707, 
2022-07-30 11:05:17 - train: epoch 0084, iter [03100, 05004], lr: 0.001000, loss: 1.2373, stu_CELoss: 0.8003, DKDLoss: 0.4370, 
2022-07-30 11:05:52 - train: epoch 0084, iter [03200, 05004], lr: 0.001000, loss: 1.1343, stu_CELoss: 0.7149, DKDLoss: 0.4194, 
2022-07-30 11:06:26 - train: epoch 0084, iter [03300, 05004], lr: 0.001000, loss: 1.1580, stu_CELoss: 0.7353, DKDLoss: 0.4227, 
2022-07-30 11:07:00 - train: epoch 0084, iter [03400, 05004], lr: 0.001000, loss: 1.1508, stu_CELoss: 0.6904, DKDLoss: 0.4603, 
2022-07-30 11:07:34 - train: epoch 0084, iter [03500, 05004], lr: 0.001000, loss: 0.9427, stu_CELoss: 0.5283, DKDLoss: 0.4144, 
2022-07-30 11:08:08 - train: epoch 0084, iter [03600, 05004], lr: 0.001000, loss: 1.1832, stu_CELoss: 0.7286, DKDLoss: 0.4546, 
2022-07-30 11:08:42 - train: epoch 0084, iter [03700, 05004], lr: 0.001000, loss: 1.1610, stu_CELoss: 0.7019, DKDLoss: 0.4591, 
2022-07-30 11:09:16 - train: epoch 0084, iter [03800, 05004], lr: 0.001000, loss: 1.2832, stu_CELoss: 0.8482, DKDLoss: 0.4350, 
2022-07-30 11:09:50 - train: epoch 0084, iter [03900, 05004], lr: 0.001000, loss: 1.2519, stu_CELoss: 0.7951, DKDLoss: 0.4567, 
2022-07-30 11:10:25 - train: epoch 0084, iter [04000, 05004], lr: 0.001000, loss: 1.1977, stu_CELoss: 0.7889, DKDLoss: 0.4088, 
2022-07-30 11:10:59 - train: epoch 0084, iter [04100, 05004], lr: 0.001000, loss: 1.1925, stu_CELoss: 0.8049, DKDLoss: 0.3876, 
2022-07-30 11:11:33 - train: epoch 0084, iter [04200, 05004], lr: 0.001000, loss: 1.2819, stu_CELoss: 0.8698, DKDLoss: 0.4120, 
2022-07-30 11:12:07 - train: epoch 0084, iter [04300, 05004], lr: 0.001000, loss: 1.0913, stu_CELoss: 0.6710, DKDLoss: 0.4203, 
2022-07-30 11:12:41 - train: epoch 0084, iter [04400, 05004], lr: 0.001000, loss: 1.3049, stu_CELoss: 0.8307, DKDLoss: 0.4741, 
2022-07-30 11:13:16 - train: epoch 0084, iter [04500, 05004], lr: 0.001000, loss: 1.1279, stu_CELoss: 0.7535, DKDLoss: 0.3744, 
2022-07-30 11:13:50 - train: epoch 0084, iter [04600, 05004], lr: 0.001000, loss: 1.2376, stu_CELoss: 0.8456, DKDLoss: 0.3921, 
2022-07-30 11:14:24 - train: epoch 0084, iter [04700, 05004], lr: 0.001000, loss: 1.1515, stu_CELoss: 0.7220, DKDLoss: 0.4295, 
2022-07-30 11:14:58 - train: epoch 0084, iter [04800, 05004], lr: 0.001000, loss: 1.1037, stu_CELoss: 0.7223, DKDLoss: 0.3814, 
2022-07-30 11:15:32 - train: epoch 0084, iter [04900, 05004], lr: 0.001000, loss: 1.0435, stu_CELoss: 0.6404, DKDLoss: 0.4031, 
2022-07-30 11:16:05 - train: epoch 0084, iter [05000, 05004], lr: 0.001000, loss: 1.3033, stu_CELoss: 0.8253, DKDLoss: 0.4780, 
2022-07-30 11:16:07 - train: epoch 084, train_loss: 1.1688
2022-07-30 11:18:39 - eval: epoch: 084, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.392%, stu_acc5: 93.496%, stu_test_loss: 0.9011
2022-07-30 11:18:40 - until epoch: 084, tea_best_acc1: 78.068%, stu_best_acc1: 77.392%
2022-07-30 11:18:40 - epoch 085 lr: 0.001000
2022-07-30 11:19:20 - train: epoch 0085, iter [00100, 05004], lr: 0.001000, loss: 1.0915, stu_CELoss: 0.6679, DKDLoss: 0.4236, 
2022-07-30 11:19:52 - train: epoch 0085, iter [00200, 05004], lr: 0.001000, loss: 1.0997, stu_CELoss: 0.6926, DKDLoss: 0.4071, 
2022-07-30 11:20:24 - train: epoch 0085, iter [00300, 05004], lr: 0.001000, loss: 1.1408, stu_CELoss: 0.7339, DKDLoss: 0.4069, 
2022-07-30 11:20:56 - train: epoch 0085, iter [00400, 05004], lr: 0.001000, loss: 1.2841, stu_CELoss: 0.8578, DKDLoss: 0.4263, 
2022-07-30 11:21:29 - train: epoch 0085, iter [00500, 05004], lr: 0.001000, loss: 1.3074, stu_CELoss: 0.8670, DKDLoss: 0.4404, 
2022-07-30 11:22:02 - train: epoch 0085, iter [00600, 05004], lr: 0.001000, loss: 1.1606, stu_CELoss: 0.7211, DKDLoss: 0.4395, 
2022-07-30 11:22:34 - train: epoch 0085, iter [00700, 05004], lr: 0.001000, loss: 1.1242, stu_CELoss: 0.7465, DKDLoss: 0.3778, 
2022-07-30 11:23:07 - train: epoch 0085, iter [00800, 05004], lr: 0.001000, loss: 0.9758, stu_CELoss: 0.5580, DKDLoss: 0.4178, 
2022-07-30 11:23:40 - train: epoch 0085, iter [00900, 05004], lr: 0.001000, loss: 1.2002, stu_CELoss: 0.7388, DKDLoss: 0.4614, 
2022-07-30 11:24:13 - train: epoch 0085, iter [01000, 05004], lr: 0.001000, loss: 1.1666, stu_CELoss: 0.7197, DKDLoss: 0.4469, 
2022-07-30 11:24:46 - train: epoch 0085, iter [01100, 05004], lr: 0.001000, loss: 1.1850, stu_CELoss: 0.7719, DKDLoss: 0.4131, 
2022-07-30 11:25:19 - train: epoch 0085, iter [01200, 05004], lr: 0.001000, loss: 0.9778, stu_CELoss: 0.5802, DKDLoss: 0.3976, 
2022-07-30 11:25:53 - train: epoch 0085, iter [01300, 05004], lr: 0.001000, loss: 1.0614, stu_CELoss: 0.6499, DKDLoss: 0.4115, 
2022-07-30 11:26:26 - train: epoch 0085, iter [01400, 05004], lr: 0.001000, loss: 1.0221, stu_CELoss: 0.6154, DKDLoss: 0.4067, 
2022-07-30 11:26:59 - train: epoch 0085, iter [01500, 05004], lr: 0.001000, loss: 1.1432, stu_CELoss: 0.7061, DKDLoss: 0.4372, 
2022-07-30 11:27:33 - train: epoch 0085, iter [01600, 05004], lr: 0.001000, loss: 1.1301, stu_CELoss: 0.7510, DKDLoss: 0.3791, 
2022-07-30 11:28:06 - train: epoch 0085, iter [01700, 05004], lr: 0.001000, loss: 1.4513, stu_CELoss: 0.9953, DKDLoss: 0.4559, 
2022-07-30 11:28:39 - train: epoch 0085, iter [01800, 05004], lr: 0.001000, loss: 0.9193, stu_CELoss: 0.5665, DKDLoss: 0.3527, 
2022-07-30 11:29:12 - train: epoch 0085, iter [01900, 05004], lr: 0.001000, loss: 1.2019, stu_CELoss: 0.8086, DKDLoss: 0.3934, 
2022-07-30 11:29:46 - train: epoch 0085, iter [02000, 05004], lr: 0.001000, loss: 0.9454, stu_CELoss: 0.5587, DKDLoss: 0.3867, 
2022-07-30 11:30:19 - train: epoch 0085, iter [02100, 05004], lr: 0.001000, loss: 0.9393, stu_CELoss: 0.5901, DKDLoss: 0.3492, 
2022-07-30 11:30:52 - train: epoch 0085, iter [02200, 05004], lr: 0.001000, loss: 1.2662, stu_CELoss: 0.8334, DKDLoss: 0.4328, 
2022-07-30 11:31:26 - train: epoch 0085, iter [02300, 05004], lr: 0.001000, loss: 1.1408, stu_CELoss: 0.7142, DKDLoss: 0.4266, 
2022-07-30 11:31:59 - train: epoch 0085, iter [02400, 05004], lr: 0.001000, loss: 1.0578, stu_CELoss: 0.6318, DKDLoss: 0.4260, 
2022-07-30 11:32:33 - train: epoch 0085, iter [02500, 05004], lr: 0.001000, loss: 1.4131, stu_CELoss: 0.9398, DKDLoss: 0.4734, 
2022-07-30 11:33:06 - train: epoch 0085, iter [02600, 05004], lr: 0.001000, loss: 1.3470, stu_CELoss: 0.9025, DKDLoss: 0.4445, 
2022-07-30 11:33:40 - train: epoch 0085, iter [02700, 05004], lr: 0.001000, loss: 1.0183, stu_CELoss: 0.6544, DKDLoss: 0.3639, 
2022-07-30 11:34:14 - train: epoch 0085, iter [02800, 05004], lr: 0.001000, loss: 1.2901, stu_CELoss: 0.8305, DKDLoss: 0.4596, 
2022-07-30 11:34:47 - train: epoch 0085, iter [02900, 05004], lr: 0.001000, loss: 1.2438, stu_CELoss: 0.8103, DKDLoss: 0.4335, 
2022-07-30 11:35:20 - train: epoch 0085, iter [03000, 05004], lr: 0.001000, loss: 1.2090, stu_CELoss: 0.7627, DKDLoss: 0.4463, 
2022-07-30 11:35:54 - train: epoch 0085, iter [03100, 05004], lr: 0.001000, loss: 1.1817, stu_CELoss: 0.7872, DKDLoss: 0.3945, 
2022-07-30 11:36:28 - train: epoch 0085, iter [03200, 05004], lr: 0.001000, loss: 1.3046, stu_CELoss: 0.8873, DKDLoss: 0.4173, 
2022-07-30 11:37:01 - train: epoch 0085, iter [03300, 05004], lr: 0.001000, loss: 1.1357, stu_CELoss: 0.7126, DKDLoss: 0.4232, 
2022-07-30 11:37:34 - train: epoch 0085, iter [03400, 05004], lr: 0.001000, loss: 1.2085, stu_CELoss: 0.7960, DKDLoss: 0.4125, 
2022-07-30 11:38:08 - train: epoch 0085, iter [03500, 05004], lr: 0.001000, loss: 1.1618, stu_CELoss: 0.7307, DKDLoss: 0.4311, 
2022-07-30 11:38:41 - train: epoch 0085, iter [03600, 05004], lr: 0.001000, loss: 1.3829, stu_CELoss: 0.9644, DKDLoss: 0.4185, 
2022-07-30 11:39:15 - train: epoch 0085, iter [03700, 05004], lr: 0.001000, loss: 0.9123, stu_CELoss: 0.5633, DKDLoss: 0.3491, 
2022-07-30 11:39:48 - train: epoch 0085, iter [03800, 05004], lr: 0.001000, loss: 1.1057, stu_CELoss: 0.6599, DKDLoss: 0.4458, 
2022-07-30 11:40:21 - train: epoch 0085, iter [03900, 05004], lr: 0.001000, loss: 1.0601, stu_CELoss: 0.6420, DKDLoss: 0.4181, 
2022-07-30 11:40:55 - train: epoch 0085, iter [04000, 05004], lr: 0.001000, loss: 1.2835, stu_CELoss: 0.8306, DKDLoss: 0.4529, 
2022-07-30 11:41:28 - train: epoch 0085, iter [04100, 05004], lr: 0.001000, loss: 1.1905, stu_CELoss: 0.7943, DKDLoss: 0.3961, 
2022-07-30 11:42:01 - train: epoch 0085, iter [04200, 05004], lr: 0.001000, loss: 1.1731, stu_CELoss: 0.7375, DKDLoss: 0.4356, 
2022-07-30 11:42:35 - train: epoch 0085, iter [04300, 05004], lr: 0.001000, loss: 1.1419, stu_CELoss: 0.7433, DKDLoss: 0.3986, 
2022-07-30 11:43:08 - train: epoch 0085, iter [04400, 05004], lr: 0.001000, loss: 1.1340, stu_CELoss: 0.6798, DKDLoss: 0.4543, 
2022-07-30 11:43:41 - train: epoch 0085, iter [04500, 05004], lr: 0.001000, loss: 1.0176, stu_CELoss: 0.6261, DKDLoss: 0.3915, 
2022-07-30 11:44:15 - train: epoch 0085, iter [04600, 05004], lr: 0.001000, loss: 1.4350, stu_CELoss: 0.9279, DKDLoss: 0.5071, 
2022-07-30 11:44:49 - train: epoch 0085, iter [04700, 05004], lr: 0.001000, loss: 1.3825, stu_CELoss: 0.9432, DKDLoss: 0.4393, 
2022-07-30 11:45:22 - train: epoch 0085, iter [04800, 05004], lr: 0.001000, loss: 0.9678, stu_CELoss: 0.5714, DKDLoss: 0.3964, 
2022-07-30 11:45:55 - train: epoch 0085, iter [04900, 05004], lr: 0.001000, loss: 1.0913, stu_CELoss: 0.6366, DKDLoss: 0.4547, 
2022-07-30 11:46:28 - train: epoch 0085, iter [05000, 05004], lr: 0.001000, loss: 1.0055, stu_CELoss: 0.6450, DKDLoss: 0.3604, 
2022-07-30 11:46:30 - train: epoch 085, train_loss: 1.1622
2022-07-30 11:49:00 - eval: epoch: 085, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.292%, stu_acc5: 93.432%, stu_test_loss: 0.9041
2022-07-30 11:49:01 - until epoch: 085, tea_best_acc1: 78.068%, stu_best_acc1: 77.392%
2022-07-30 11:49:01 - epoch 086 lr: 0.001000
2022-07-30 11:49:41 - train: epoch 0086, iter [00100, 05004], lr: 0.001000, loss: 1.0671, stu_CELoss: 0.6223, DKDLoss: 0.4449, 
2022-07-30 11:50:14 - train: epoch 0086, iter [00200, 05004], lr: 0.001000, loss: 1.1543, stu_CELoss: 0.7370, DKDLoss: 0.4173, 
2022-07-30 11:50:47 - train: epoch 0086, iter [00300, 05004], lr: 0.001000, loss: 1.1515, stu_CELoss: 0.7213, DKDLoss: 0.4302, 
2022-07-30 11:51:19 - train: epoch 0086, iter [00400, 05004], lr: 0.001000, loss: 1.3323, stu_CELoss: 0.8879, DKDLoss: 0.4444, 
2022-07-30 11:51:52 - train: epoch 0086, iter [00500, 05004], lr: 0.001000, loss: 1.3353, stu_CELoss: 0.8873, DKDLoss: 0.4480, 
2022-07-30 11:52:24 - train: epoch 0086, iter [00600, 05004], lr: 0.001000, loss: 1.2277, stu_CELoss: 0.7689, DKDLoss: 0.4588, 
2022-07-30 11:52:57 - train: epoch 0086, iter [00700, 05004], lr: 0.001000, loss: 1.1350, stu_CELoss: 0.6680, DKDLoss: 0.4670, 
2022-07-30 11:53:30 - train: epoch 0086, iter [00800, 05004], lr: 0.001000, loss: 1.3248, stu_CELoss: 0.8795, DKDLoss: 0.4453, 
2022-07-30 11:54:03 - train: epoch 0086, iter [00900, 05004], lr: 0.001000, loss: 1.0832, stu_CELoss: 0.6594, DKDLoss: 0.4239, 
2022-07-30 11:54:36 - train: epoch 0086, iter [01000, 05004], lr: 0.001000, loss: 1.1702, stu_CELoss: 0.7585, DKDLoss: 0.4117, 
2022-07-30 11:55:09 - train: epoch 0086, iter [01100, 05004], lr: 0.001000, loss: 1.1678, stu_CELoss: 0.7517, DKDLoss: 0.4161, 
2022-07-30 11:55:42 - train: epoch 0086, iter [01200, 05004], lr: 0.001000, loss: 1.0245, stu_CELoss: 0.6069, DKDLoss: 0.4176, 
2022-07-30 11:56:15 - train: epoch 0086, iter [01300, 05004], lr: 0.001000, loss: 1.0948, stu_CELoss: 0.6916, DKDLoss: 0.4032, 
2022-07-30 11:56:48 - train: epoch 0086, iter [01400, 05004], lr: 0.001000, loss: 1.0272, stu_CELoss: 0.6259, DKDLoss: 0.4013, 
2022-07-30 11:57:21 - train: epoch 0086, iter [01500, 05004], lr: 0.001000, loss: 0.9516, stu_CELoss: 0.5535, DKDLoss: 0.3981, 
2022-07-30 11:57:54 - train: epoch 0086, iter [01600, 05004], lr: 0.001000, loss: 1.0937, stu_CELoss: 0.6982, DKDLoss: 0.3955, 
2022-07-30 11:58:28 - train: epoch 0086, iter [01700, 05004], lr: 0.001000, loss: 1.2390, stu_CELoss: 0.8269, DKDLoss: 0.4121, 
2022-07-30 11:59:01 - train: epoch 0086, iter [01800, 05004], lr: 0.001000, loss: 1.2002, stu_CELoss: 0.7878, DKDLoss: 0.4124, 
2022-07-30 11:59:34 - train: epoch 0086, iter [01900, 05004], lr: 0.001000, loss: 1.1063, stu_CELoss: 0.7164, DKDLoss: 0.3899, 
2022-07-30 12:00:07 - train: epoch 0086, iter [02000, 05004], lr: 0.001000, loss: 1.2267, stu_CELoss: 0.7557, DKDLoss: 0.4710, 
2022-07-30 12:00:40 - train: epoch 0086, iter [02100, 05004], lr: 0.001000, loss: 0.9968, stu_CELoss: 0.5897, DKDLoss: 0.4071, 
2022-07-30 12:01:13 - train: epoch 0086, iter [02200, 05004], lr: 0.001000, loss: 1.0859, stu_CELoss: 0.6516, DKDLoss: 0.4343, 
2022-07-30 12:01:46 - train: epoch 0086, iter [02300, 05004], lr: 0.001000, loss: 1.2710, stu_CELoss: 0.8162, DKDLoss: 0.4548, 
2022-07-30 12:02:19 - train: epoch 0086, iter [02400, 05004], lr: 0.001000, loss: 1.0779, stu_CELoss: 0.6736, DKDLoss: 0.4043, 
2022-07-30 12:02:52 - train: epoch 0086, iter [02500, 05004], lr: 0.001000, loss: 1.2586, stu_CELoss: 0.8434, DKDLoss: 0.4152, 
2022-07-30 12:03:25 - train: epoch 0086, iter [02600, 05004], lr: 0.001000, loss: 1.0524, stu_CELoss: 0.6413, DKDLoss: 0.4111, 
2022-07-30 12:03:58 - train: epoch 0086, iter [02700, 05004], lr: 0.001000, loss: 1.0676, stu_CELoss: 0.6617, DKDLoss: 0.4059, 
2022-07-30 12:04:31 - train: epoch 0086, iter [02800, 05004], lr: 0.001000, loss: 1.1649, stu_CELoss: 0.7146, DKDLoss: 0.4502, 
2022-07-30 12:05:04 - train: epoch 0086, iter [02900, 05004], lr: 0.001000, loss: 1.0521, stu_CELoss: 0.6601, DKDLoss: 0.3920, 
2022-07-30 12:05:37 - train: epoch 0086, iter [03000, 05004], lr: 0.001000, loss: 1.0415, stu_CELoss: 0.6391, DKDLoss: 0.4024, 
2022-07-30 12:06:10 - train: epoch 0086, iter [03100, 05004], lr: 0.001000, loss: 1.3115, stu_CELoss: 0.9266, DKDLoss: 0.3849, 
2022-07-30 12:06:43 - train: epoch 0086, iter [03200, 05004], lr: 0.001000, loss: 1.2464, stu_CELoss: 0.8214, DKDLoss: 0.4250, 
2022-07-30 12:07:17 - train: epoch 0086, iter [03300, 05004], lr: 0.001000, loss: 1.0725, stu_CELoss: 0.6661, DKDLoss: 0.4064, 
2022-07-30 12:07:51 - train: epoch 0086, iter [03400, 05004], lr: 0.001000, loss: 1.0903, stu_CELoss: 0.6930, DKDLoss: 0.3973, 
2022-07-30 12:08:24 - train: epoch 0086, iter [03500, 05004], lr: 0.001000, loss: 1.0883, stu_CELoss: 0.6552, DKDLoss: 0.4331, 
2022-07-30 12:08:57 - train: epoch 0086, iter [03600, 05004], lr: 0.001000, loss: 1.1197, stu_CELoss: 0.7526, DKDLoss: 0.3671, 
2022-07-30 12:09:31 - train: epoch 0086, iter [03700, 05004], lr: 0.001000, loss: 1.2947, stu_CELoss: 0.9070, DKDLoss: 0.3877, 
2022-07-30 12:10:04 - train: epoch 0086, iter [03800, 05004], lr: 0.001000, loss: 1.1695, stu_CELoss: 0.7163, DKDLoss: 0.4531, 
2022-07-30 12:10:37 - train: epoch 0086, iter [03900, 05004], lr: 0.001000, loss: 1.1191, stu_CELoss: 0.6722, DKDLoss: 0.4470, 
2022-07-30 12:11:10 - train: epoch 0086, iter [04000, 05004], lr: 0.001000, loss: 1.0261, stu_CELoss: 0.6041, DKDLoss: 0.4221, 
2022-07-30 12:11:43 - train: epoch 0086, iter [04100, 05004], lr: 0.001000, loss: 1.1566, stu_CELoss: 0.7038, DKDLoss: 0.4528, 
2022-07-30 12:12:16 - train: epoch 0086, iter [04200, 05004], lr: 0.001000, loss: 1.1792, stu_CELoss: 0.7279, DKDLoss: 0.4514, 
2022-07-30 12:12:49 - train: epoch 0086, iter [04300, 05004], lr: 0.001000, loss: 1.1282, stu_CELoss: 0.7226, DKDLoss: 0.4057, 
2022-07-30 12:13:22 - train: epoch 0086, iter [04400, 05004], lr: 0.001000, loss: 1.2757, stu_CELoss: 0.8771, DKDLoss: 0.3986, 
2022-07-30 12:13:55 - train: epoch 0086, iter [04500, 05004], lr: 0.001000, loss: 1.2895, stu_CELoss: 0.7900, DKDLoss: 0.4995, 
2022-07-30 12:14:28 - train: epoch 0086, iter [04600, 05004], lr: 0.001000, loss: 1.1220, stu_CELoss: 0.6986, DKDLoss: 0.4234, 
2022-07-30 12:15:01 - train: epoch 0086, iter [04700, 05004], lr: 0.001000, loss: 1.1400, stu_CELoss: 0.7626, DKDLoss: 0.3773, 
2022-07-30 12:15:34 - train: epoch 0086, iter [04800, 05004], lr: 0.001000, loss: 1.1011, stu_CELoss: 0.6894, DKDLoss: 0.4116, 
2022-07-30 12:16:07 - train: epoch 0086, iter [04900, 05004], lr: 0.001000, loss: 0.9992, stu_CELoss: 0.5780, DKDLoss: 0.4212, 
2022-07-30 12:16:40 - train: epoch 0086, iter [05000, 05004], lr: 0.001000, loss: 1.2500, stu_CELoss: 0.8336, DKDLoss: 0.4165, 
2022-07-30 12:16:41 - train: epoch 086, train_loss: 1.1614
2022-07-30 12:19:14 - eval: epoch: 086, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.290%, stu_acc5: 93.554%, stu_test_loss: 0.8996
2022-07-30 12:19:14 - until epoch: 086, tea_best_acc1: 78.068%, stu_best_acc1: 77.392%
2022-07-30 12:19:14 - epoch 087 lr: 0.001000
2022-07-30 12:19:56 - train: epoch 0087, iter [00100, 05004], lr: 0.001000, loss: 1.1628, stu_CELoss: 0.7484, DKDLoss: 0.4145, 
2022-07-30 12:20:29 - train: epoch 0087, iter [00200, 05004], lr: 0.001000, loss: 1.0685, stu_CELoss: 0.6702, DKDLoss: 0.3983, 
2022-07-30 12:21:03 - train: epoch 0087, iter [00300, 05004], lr: 0.001000, loss: 1.1214, stu_CELoss: 0.7046, DKDLoss: 0.4169, 
2022-07-30 12:21:37 - train: epoch 0087, iter [00400, 05004], lr: 0.001000, loss: 1.1125, stu_CELoss: 0.6933, DKDLoss: 0.4192, 
2022-07-30 12:22:10 - train: epoch 0087, iter [00500, 05004], lr: 0.001000, loss: 1.0219, stu_CELoss: 0.6335, DKDLoss: 0.3884, 
2022-07-30 12:22:44 - train: epoch 0087, iter [00600, 05004], lr: 0.001000, loss: 1.3066, stu_CELoss: 0.8563, DKDLoss: 0.4503, 
2022-07-30 12:23:17 - train: epoch 0087, iter [00700, 05004], lr: 0.001000, loss: 1.1288, stu_CELoss: 0.6490, DKDLoss: 0.4798, 
2022-07-30 12:23:50 - train: epoch 0087, iter [00800, 05004], lr: 0.001000, loss: 1.2218, stu_CELoss: 0.7752, DKDLoss: 0.4466, 
2022-07-30 12:24:23 - train: epoch 0087, iter [00900, 05004], lr: 0.001000, loss: 1.1491, stu_CELoss: 0.7091, DKDLoss: 0.4400, 
2022-07-30 12:24:57 - train: epoch 0087, iter [01000, 05004], lr: 0.001000, loss: 1.0039, stu_CELoss: 0.6007, DKDLoss: 0.4032, 
2022-07-30 12:25:30 - train: epoch 0087, iter [01100, 05004], lr: 0.001000, loss: 1.1636, stu_CELoss: 0.7258, DKDLoss: 0.4379, 
2022-07-30 12:26:03 - train: epoch 0087, iter [01200, 05004], lr: 0.001000, loss: 1.2642, stu_CELoss: 0.8220, DKDLoss: 0.4422, 
2022-07-30 12:26:37 - train: epoch 0087, iter [01300, 05004], lr: 0.001000, loss: 1.1607, stu_CELoss: 0.7467, DKDLoss: 0.4140, 
2022-07-30 12:27:11 - train: epoch 0087, iter [01400, 05004], lr: 0.001000, loss: 1.0476, stu_CELoss: 0.6261, DKDLoss: 0.4215, 
2022-07-30 12:27:44 - train: epoch 0087, iter [01500, 05004], lr: 0.001000, loss: 1.0888, stu_CELoss: 0.6416, DKDLoss: 0.4472, 
2022-07-30 12:28:18 - train: epoch 0087, iter [01600, 05004], lr: 0.001000, loss: 0.9589, stu_CELoss: 0.5792, DKDLoss: 0.3797, 
2022-07-30 12:28:52 - train: epoch 0087, iter [01700, 05004], lr: 0.001000, loss: 1.3642, stu_CELoss: 0.9178, DKDLoss: 0.4464, 
2022-07-30 12:29:26 - train: epoch 0087, iter [01800, 05004], lr: 0.001000, loss: 1.2790, stu_CELoss: 0.8620, DKDLoss: 0.4169, 
2022-07-30 12:29:59 - train: epoch 0087, iter [01900, 05004], lr: 0.001000, loss: 1.3524, stu_CELoss: 0.9482, DKDLoss: 0.4042, 
2022-07-30 12:30:33 - train: epoch 0087, iter [02000, 05004], lr: 0.001000, loss: 1.2435, stu_CELoss: 0.7466, DKDLoss: 0.4969, 
2022-07-30 12:31:07 - train: epoch 0087, iter [02100, 05004], lr: 0.001000, loss: 1.1304, stu_CELoss: 0.7180, DKDLoss: 0.4124, 
2022-07-30 12:31:40 - train: epoch 0087, iter [02200, 05004], lr: 0.001000, loss: 1.1853, stu_CELoss: 0.7457, DKDLoss: 0.4396, 
2022-07-30 12:32:15 - train: epoch 0087, iter [02300, 05004], lr: 0.001000, loss: 1.3935, stu_CELoss: 0.8829, DKDLoss: 0.5106, 
2022-07-30 12:32:48 - train: epoch 0087, iter [02400, 05004], lr: 0.001000, loss: 1.1298, stu_CELoss: 0.6951, DKDLoss: 0.4347, 
2022-07-30 12:33:22 - train: epoch 0087, iter [02500, 05004], lr: 0.001000, loss: 1.1686, stu_CELoss: 0.7001, DKDLoss: 0.4685, 
2022-07-30 12:33:56 - train: epoch 0087, iter [02600, 05004], lr: 0.001000, loss: 1.1637, stu_CELoss: 0.7140, DKDLoss: 0.4497, 
2022-07-30 12:34:29 - train: epoch 0087, iter [02700, 05004], lr: 0.001000, loss: 1.0895, stu_CELoss: 0.6933, DKDLoss: 0.3962, 
2022-07-30 12:35:03 - train: epoch 0087, iter [02800, 05004], lr: 0.001000, loss: 1.0458, stu_CELoss: 0.6341, DKDLoss: 0.4117, 
2022-07-30 12:35:37 - train: epoch 0087, iter [02900, 05004], lr: 0.001000, loss: 0.9429, stu_CELoss: 0.5349, DKDLoss: 0.4080, 
2022-07-30 12:36:10 - train: epoch 0087, iter [03000, 05004], lr: 0.001000, loss: 1.1716, stu_CELoss: 0.7190, DKDLoss: 0.4525, 
2022-07-30 12:36:44 - train: epoch 0087, iter [03100, 05004], lr: 0.001000, loss: 1.2289, stu_CELoss: 0.7398, DKDLoss: 0.4891, 
2022-07-30 12:37:18 - train: epoch 0087, iter [03200, 05004], lr: 0.001000, loss: 1.1145, stu_CELoss: 0.7207, DKDLoss: 0.3938, 
2022-07-30 12:37:51 - train: epoch 0087, iter [03300, 05004], lr: 0.001000, loss: 1.2602, stu_CELoss: 0.7910, DKDLoss: 0.4692, 
2022-07-30 12:38:25 - train: epoch 0087, iter [03400, 05004], lr: 0.001000, loss: 1.0497, stu_CELoss: 0.6458, DKDLoss: 0.4039, 
2022-07-30 12:38:59 - train: epoch 0087, iter [03500, 05004], lr: 0.001000, loss: 1.1110, stu_CELoss: 0.6934, DKDLoss: 0.4176, 
2022-07-30 12:39:32 - train: epoch 0087, iter [03600, 05004], lr: 0.001000, loss: 0.9929, stu_CELoss: 0.6273, DKDLoss: 0.3656, 
2022-07-30 12:40:06 - train: epoch 0087, iter [03700, 05004], lr: 0.001000, loss: 1.1472, stu_CELoss: 0.6944, DKDLoss: 0.4529, 
2022-07-30 12:40:40 - train: epoch 0087, iter [03800, 05004], lr: 0.001000, loss: 1.1946, stu_CELoss: 0.7322, DKDLoss: 0.4624, 
2022-07-30 12:41:14 - train: epoch 0087, iter [03900, 05004], lr: 0.001000, loss: 1.0226, stu_CELoss: 0.6177, DKDLoss: 0.4049, 
2022-07-30 12:41:47 - train: epoch 0087, iter [04000, 05004], lr: 0.001000, loss: 1.3500, stu_CELoss: 0.8706, DKDLoss: 0.4794, 
2022-07-30 12:42:21 - train: epoch 0087, iter [04100, 05004], lr: 0.001000, loss: 1.2700, stu_CELoss: 0.8947, DKDLoss: 0.3752, 
2022-07-30 12:42:55 - train: epoch 0087, iter [04200, 05004], lr: 0.001000, loss: 1.2881, stu_CELoss: 0.8283, DKDLoss: 0.4598, 
2022-07-30 12:43:28 - train: epoch 0087, iter [04300, 05004], lr: 0.001000, loss: 1.1845, stu_CELoss: 0.7648, DKDLoss: 0.4198, 
2022-07-30 12:44:01 - train: epoch 0087, iter [04400, 05004], lr: 0.001000, loss: 1.4506, stu_CELoss: 0.9786, DKDLoss: 0.4720, 
2022-07-30 12:44:35 - train: epoch 0087, iter [04500, 05004], lr: 0.001000, loss: 1.1016, stu_CELoss: 0.6825, DKDLoss: 0.4192, 
2022-07-30 12:45:08 - train: epoch 0087, iter [04600, 05004], lr: 0.001000, loss: 1.1751, stu_CELoss: 0.7174, DKDLoss: 0.4578, 
2022-07-30 12:45:42 - train: epoch 0087, iter [04700, 05004], lr: 0.001000, loss: 1.2374, stu_CELoss: 0.7303, DKDLoss: 0.5071, 
2022-07-30 12:46:16 - train: epoch 0087, iter [04800, 05004], lr: 0.001000, loss: 1.2044, stu_CELoss: 0.7574, DKDLoss: 0.4470, 
2022-07-30 12:46:50 - train: epoch 0087, iter [04900, 05004], lr: 0.001000, loss: 1.1174, stu_CELoss: 0.6983, DKDLoss: 0.4191, 
2022-07-30 12:47:22 - train: epoch 0087, iter [05000, 05004], lr: 0.001000, loss: 1.1974, stu_CELoss: 0.7476, DKDLoss: 0.4497, 
2022-07-30 12:47:24 - train: epoch 087, train_loss: 1.1556
2022-07-30 12:49:57 - eval: epoch: 087, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.166%, stu_acc5: 93.322%, stu_test_loss: 0.9048
2022-07-30 12:49:58 - until epoch: 087, tea_best_acc1: 78.068%, stu_best_acc1: 77.392%
2022-07-30 12:49:58 - epoch 088 lr: 0.001000
2022-07-30 12:50:38 - train: epoch 0088, iter [00100, 05004], lr: 0.001000, loss: 1.1009, stu_CELoss: 0.7120, DKDLoss: 0.3889, 
2022-07-30 12:51:11 - train: epoch 0088, iter [00200, 05004], lr: 0.001000, loss: 1.0179, stu_CELoss: 0.6229, DKDLoss: 0.3951, 
2022-07-30 12:51:44 - train: epoch 0088, iter [00300, 05004], lr: 0.001000, loss: 1.2181, stu_CELoss: 0.7844, DKDLoss: 0.4337, 
2022-07-30 12:52:18 - train: epoch 0088, iter [00400, 05004], lr: 0.001000, loss: 1.1453, stu_CELoss: 0.6819, DKDLoss: 0.4633, 
2022-07-30 12:52:51 - train: epoch 0088, iter [00500, 05004], lr: 0.001000, loss: 1.0493, stu_CELoss: 0.5931, DKDLoss: 0.4562, 
2022-07-30 12:53:24 - train: epoch 0088, iter [00600, 05004], lr: 0.001000, loss: 1.1205, stu_CELoss: 0.7028, DKDLoss: 0.4177, 
2022-07-30 12:53:58 - train: epoch 0088, iter [00700, 05004], lr: 0.001000, loss: 1.0357, stu_CELoss: 0.6493, DKDLoss: 0.3864, 
2022-07-30 12:54:31 - train: epoch 0088, iter [00800, 05004], lr: 0.001000, loss: 1.1973, stu_CELoss: 0.7918, DKDLoss: 0.4055, 
2022-07-30 12:55:05 - train: epoch 0088, iter [00900, 05004], lr: 0.001000, loss: 1.1472, stu_CELoss: 0.7468, DKDLoss: 0.4004, 
2022-07-30 12:55:39 - train: epoch 0088, iter [01000, 05004], lr: 0.001000, loss: 1.1570, stu_CELoss: 0.7130, DKDLoss: 0.4441, 
2022-07-30 12:56:12 - train: epoch 0088, iter [01100, 05004], lr: 0.001000, loss: 1.0939, stu_CELoss: 0.7190, DKDLoss: 0.3749, 
2022-07-30 12:56:45 - train: epoch 0088, iter [01200, 05004], lr: 0.001000, loss: 1.1682, stu_CELoss: 0.7390, DKDLoss: 0.4292, 
2022-07-30 12:57:19 - train: epoch 0088, iter [01300, 05004], lr: 0.001000, loss: 1.1964, stu_CELoss: 0.7565, DKDLoss: 0.4400, 
2022-07-30 12:57:52 - train: epoch 0088, iter [01400, 05004], lr: 0.001000, loss: 1.1619, stu_CELoss: 0.7152, DKDLoss: 0.4467, 
2022-07-30 12:58:26 - train: epoch 0088, iter [01500, 05004], lr: 0.001000, loss: 1.1989, stu_CELoss: 0.7496, DKDLoss: 0.4494, 
2022-07-30 12:59:00 - train: epoch 0088, iter [01600, 05004], lr: 0.001000, loss: 1.0006, stu_CELoss: 0.5969, DKDLoss: 0.4037, 
2022-07-30 12:59:33 - train: epoch 0088, iter [01700, 05004], lr: 0.001000, loss: 1.3323, stu_CELoss: 0.8222, DKDLoss: 0.5102, 
2022-07-30 13:00:07 - train: epoch 0088, iter [01800, 05004], lr: 0.001000, loss: 1.0874, stu_CELoss: 0.6870, DKDLoss: 0.4004, 
2022-07-30 13:00:40 - train: epoch 0088, iter [01900, 05004], lr: 0.001000, loss: 1.1936, stu_CELoss: 0.7352, DKDLoss: 0.4584, 
2022-07-30 13:01:14 - train: epoch 0088, iter [02000, 05004], lr: 0.001000, loss: 1.0550, stu_CELoss: 0.5976, DKDLoss: 0.4574, 
2022-07-30 13:01:47 - train: epoch 0088, iter [02100, 05004], lr: 0.001000, loss: 1.2641, stu_CELoss: 0.8142, DKDLoss: 0.4499, 
2022-07-30 13:02:21 - train: epoch 0088, iter [02200, 05004], lr: 0.001000, loss: 0.9913, stu_CELoss: 0.6069, DKDLoss: 0.3844, 
2022-07-30 13:02:54 - train: epoch 0088, iter [02300, 05004], lr: 0.001000, loss: 0.9289, stu_CELoss: 0.5511, DKDLoss: 0.3777, 
2022-07-30 13:03:27 - train: epoch 0088, iter [02400, 05004], lr: 0.001000, loss: 1.0988, stu_CELoss: 0.7104, DKDLoss: 0.3884, 
2022-07-30 13:04:01 - train: epoch 0088, iter [02500, 05004], lr: 0.001000, loss: 1.2177, stu_CELoss: 0.7783, DKDLoss: 0.4394, 
2022-07-30 13:04:35 - train: epoch 0088, iter [02600, 05004], lr: 0.001000, loss: 1.2480, stu_CELoss: 0.8183, DKDLoss: 0.4296, 
2022-07-30 13:05:08 - train: epoch 0088, iter [02700, 05004], lr: 0.001000, loss: 1.1593, stu_CELoss: 0.7011, DKDLoss: 0.4582, 
2022-07-30 13:05:41 - train: epoch 0088, iter [02800, 05004], lr: 0.001000, loss: 1.1559, stu_CELoss: 0.6891, DKDLoss: 0.4668, 
2022-07-30 13:06:15 - train: epoch 0088, iter [02900, 05004], lr: 0.001000, loss: 1.0204, stu_CELoss: 0.6303, DKDLoss: 0.3901, 
2022-07-30 13:06:49 - train: epoch 0088, iter [03000, 05004], lr: 0.001000, loss: 1.2356, stu_CELoss: 0.8247, DKDLoss: 0.4110, 
2022-07-30 13:07:22 - train: epoch 0088, iter [03100, 05004], lr: 0.001000, loss: 1.0512, stu_CELoss: 0.6414, DKDLoss: 0.4098, 
2022-07-30 13:07:56 - train: epoch 0088, iter [03200, 05004], lr: 0.001000, loss: 1.0569, stu_CELoss: 0.6161, DKDLoss: 0.4408, 
2022-07-30 13:08:29 - train: epoch 0088, iter [03300, 05004], lr: 0.001000, loss: 1.0322, stu_CELoss: 0.6741, DKDLoss: 0.3581, 
2022-07-30 13:09:02 - train: epoch 0088, iter [03400, 05004], lr: 0.001000, loss: 0.9511, stu_CELoss: 0.5627, DKDLoss: 0.3884, 
2022-07-30 13:09:36 - train: epoch 0088, iter [03500, 05004], lr: 0.001000, loss: 1.1497, stu_CELoss: 0.7234, DKDLoss: 0.4263, 
2022-07-30 13:10:09 - train: epoch 0088, iter [03600, 05004], lr: 0.001000, loss: 1.1486, stu_CELoss: 0.7880, DKDLoss: 0.3606, 
2022-07-30 13:10:43 - train: epoch 0088, iter [03700, 05004], lr: 0.001000, loss: 1.1987, stu_CELoss: 0.7615, DKDLoss: 0.4371, 
2022-07-30 13:11:16 - train: epoch 0088, iter [03800, 05004], lr: 0.001000, loss: 1.1670, stu_CELoss: 0.7367, DKDLoss: 0.4303, 
2022-07-30 13:11:49 - train: epoch 0088, iter [03900, 05004], lr: 0.001000, loss: 1.2070, stu_CELoss: 0.7919, DKDLoss: 0.4151, 
2022-07-30 13:12:23 - train: epoch 0088, iter [04000, 05004], lr: 0.001000, loss: 1.0576, stu_CELoss: 0.6816, DKDLoss: 0.3760, 
2022-07-30 13:12:57 - train: epoch 0088, iter [04100, 05004], lr: 0.001000, loss: 1.1539, stu_CELoss: 0.7644, DKDLoss: 0.3895, 
2022-07-30 13:13:30 - train: epoch 0088, iter [04200, 05004], lr: 0.001000, loss: 1.2987, stu_CELoss: 0.8946, DKDLoss: 0.4041, 
2022-07-30 13:14:04 - train: epoch 0088, iter [04300, 05004], lr: 0.001000, loss: 1.0977, stu_CELoss: 0.6517, DKDLoss: 0.4460, 
2022-07-30 13:14:37 - train: epoch 0088, iter [04400, 05004], lr: 0.001000, loss: 1.0695, stu_CELoss: 0.6875, DKDLoss: 0.3820, 
2022-07-30 13:15:10 - train: epoch 0088, iter [04500, 05004], lr: 0.001000, loss: 1.2140, stu_CELoss: 0.7871, DKDLoss: 0.4269, 
2022-07-30 13:15:43 - train: epoch 0088, iter [04600, 05004], lr: 0.001000, loss: 1.2673, stu_CELoss: 0.8253, DKDLoss: 0.4420, 
2022-07-30 13:16:17 - train: epoch 0088, iter [04700, 05004], lr: 0.001000, loss: 1.1692, stu_CELoss: 0.7240, DKDLoss: 0.4451, 
2022-07-30 13:16:51 - train: epoch 0088, iter [04800, 05004], lr: 0.001000, loss: 1.0083, stu_CELoss: 0.5916, DKDLoss: 0.4167, 
2022-07-30 13:17:24 - train: epoch 0088, iter [04900, 05004], lr: 0.001000, loss: 1.0602, stu_CELoss: 0.6062, DKDLoss: 0.4540, 
2022-07-30 13:17:57 - train: epoch 0088, iter [05000, 05004], lr: 0.001000, loss: 1.1728, stu_CELoss: 0.7607, DKDLoss: 0.4122, 
2022-07-30 13:17:59 - train: epoch 088, train_loss: 1.1524
2022-07-30 13:20:32 - eval: epoch: 088, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.220%, stu_acc5: 93.510%, stu_test_loss: 0.9010
2022-07-30 13:20:32 - until epoch: 088, tea_best_acc1: 78.068%, stu_best_acc1: 77.392%
2022-07-30 13:20:32 - epoch 089 lr: 0.001000
2022-07-30 13:21:12 - train: epoch 0089, iter [00100, 05004], lr: 0.001000, loss: 1.4508, stu_CELoss: 0.9894, DKDLoss: 0.4614, 
2022-07-30 13:21:45 - train: epoch 0089, iter [00200, 05004], lr: 0.001000, loss: 0.9777, stu_CELoss: 0.5460, DKDLoss: 0.4316, 
2022-07-30 13:22:18 - train: epoch 0089, iter [00300, 05004], lr: 0.001000, loss: 1.2249, stu_CELoss: 0.7914, DKDLoss: 0.4335, 
2022-07-30 13:22:52 - train: epoch 0089, iter [00400, 05004], lr: 0.001000, loss: 1.1149, stu_CELoss: 0.7449, DKDLoss: 0.3700, 
2022-07-30 13:23:25 - train: epoch 0089, iter [00500, 05004], lr: 0.001000, loss: 1.1893, stu_CELoss: 0.7790, DKDLoss: 0.4103, 
2022-07-30 13:23:59 - train: epoch 0089, iter [00600, 05004], lr: 0.001000, loss: 1.2623, stu_CELoss: 0.8340, DKDLoss: 0.4283, 
2022-07-30 13:24:32 - train: epoch 0089, iter [00700, 05004], lr: 0.001000, loss: 1.1280, stu_CELoss: 0.6979, DKDLoss: 0.4301, 
2022-07-30 13:25:05 - train: epoch 0089, iter [00800, 05004], lr: 0.001000, loss: 1.1134, stu_CELoss: 0.6956, DKDLoss: 0.4178, 
2022-07-30 13:25:39 - train: epoch 0089, iter [00900, 05004], lr: 0.001000, loss: 1.1340, stu_CELoss: 0.6909, DKDLoss: 0.4431, 
2022-07-30 13:26:12 - train: epoch 0089, iter [01000, 05004], lr: 0.001000, loss: 1.2935, stu_CELoss: 0.8648, DKDLoss: 0.4287, 
2022-07-30 13:26:46 - train: epoch 0089, iter [01100, 05004], lr: 0.001000, loss: 0.9229, stu_CELoss: 0.5591, DKDLoss: 0.3638, 
2022-07-30 13:27:19 - train: epoch 0089, iter [01200, 05004], lr: 0.001000, loss: 1.1237, stu_CELoss: 0.7516, DKDLoss: 0.3720, 
2022-07-30 13:27:52 - train: epoch 0089, iter [01300, 05004], lr: 0.001000, loss: 1.1966, stu_CELoss: 0.7259, DKDLoss: 0.4707, 
2022-07-30 13:28:25 - train: epoch 0089, iter [01400, 05004], lr: 0.001000, loss: 1.1743, stu_CELoss: 0.7509, DKDLoss: 0.4233, 
2022-07-30 13:28:59 - train: epoch 0089, iter [01500, 05004], lr: 0.001000, loss: 1.1752, stu_CELoss: 0.7490, DKDLoss: 0.4261, 
2022-07-30 13:29:32 - train: epoch 0089, iter [01600, 05004], lr: 0.001000, loss: 1.1381, stu_CELoss: 0.7392, DKDLoss: 0.3989, 
2022-07-30 13:30:05 - train: epoch 0089, iter [01700, 05004], lr: 0.001000, loss: 1.2346, stu_CELoss: 0.7930, DKDLoss: 0.4416, 
2022-07-30 13:30:38 - train: epoch 0089, iter [01800, 05004], lr: 0.001000, loss: 1.0335, stu_CELoss: 0.5762, DKDLoss: 0.4574, 
2022-07-30 13:31:12 - train: epoch 0089, iter [01900, 05004], lr: 0.001000, loss: 0.9884, stu_CELoss: 0.6204, DKDLoss: 0.3680, 
2022-07-30 13:31:45 - train: epoch 0089, iter [02000, 05004], lr: 0.001000, loss: 1.1792, stu_CELoss: 0.7332, DKDLoss: 0.4460, 
2022-07-30 13:32:18 - train: epoch 0089, iter [02100, 05004], lr: 0.001000, loss: 1.1450, stu_CELoss: 0.7192, DKDLoss: 0.4258, 
2022-07-30 13:32:52 - train: epoch 0089, iter [02200, 05004], lr: 0.001000, loss: 1.2255, stu_CELoss: 0.7967, DKDLoss: 0.4288, 
2022-07-30 13:33:25 - train: epoch 0089, iter [02300, 05004], lr: 0.001000, loss: 1.1751, stu_CELoss: 0.7807, DKDLoss: 0.3944, 
2022-07-30 13:33:58 - train: epoch 0089, iter [02400, 05004], lr: 0.001000, loss: 1.3611, stu_CELoss: 0.8995, DKDLoss: 0.4616, 
2022-07-30 13:34:31 - train: epoch 0089, iter [02500, 05004], lr: 0.001000, loss: 1.0367, stu_CELoss: 0.5996, DKDLoss: 0.4370, 
2022-07-30 13:35:04 - train: epoch 0089, iter [02600, 05004], lr: 0.001000, loss: 1.1020, stu_CELoss: 0.6469, DKDLoss: 0.4551, 
2022-07-30 13:35:37 - train: epoch 0089, iter [02700, 05004], lr: 0.001000, loss: 1.1261, stu_CELoss: 0.7008, DKDLoss: 0.4254, 
2022-07-30 13:36:10 - train: epoch 0089, iter [02800, 05004], lr: 0.001000, loss: 1.1060, stu_CELoss: 0.6591, DKDLoss: 0.4469, 
2022-07-30 13:36:43 - train: epoch 0089, iter [02900, 05004], lr: 0.001000, loss: 1.1654, stu_CELoss: 0.7583, DKDLoss: 0.4070, 
2022-07-30 13:37:16 - train: epoch 0089, iter [03000, 05004], lr: 0.001000, loss: 1.1308, stu_CELoss: 0.7413, DKDLoss: 0.3894, 
2022-07-30 13:37:49 - train: epoch 0089, iter [03100, 05004], lr: 0.001000, loss: 1.0004, stu_CELoss: 0.5879, DKDLoss: 0.4125, 
2022-07-30 13:38:22 - train: epoch 0089, iter [03200, 05004], lr: 0.001000, loss: 1.2667, stu_CELoss: 0.8639, DKDLoss: 0.4029, 
2022-07-30 13:38:55 - train: epoch 0089, iter [03300, 05004], lr: 0.001000, loss: 1.2752, stu_CELoss: 0.8487, DKDLoss: 0.4264, 
2022-07-30 13:39:28 - train: epoch 0089, iter [03400, 05004], lr: 0.001000, loss: 1.2079, stu_CELoss: 0.7951, DKDLoss: 0.4128, 
2022-07-30 13:40:01 - train: epoch 0089, iter [03500, 05004], lr: 0.001000, loss: 0.9500, stu_CELoss: 0.5603, DKDLoss: 0.3897, 
2022-07-30 13:40:34 - train: epoch 0089, iter [03600, 05004], lr: 0.001000, loss: 1.0720, stu_CELoss: 0.6215, DKDLoss: 0.4506, 
2022-07-30 13:41:08 - train: epoch 0089, iter [03700, 05004], lr: 0.001000, loss: 1.1528, stu_CELoss: 0.7010, DKDLoss: 0.4518, 
2022-07-30 13:41:41 - train: epoch 0089, iter [03800, 05004], lr: 0.001000, loss: 1.0468, stu_CELoss: 0.6395, DKDLoss: 0.4073, 
2022-07-30 13:42:14 - train: epoch 0089, iter [03900, 05004], lr: 0.001000, loss: 1.3474, stu_CELoss: 0.9403, DKDLoss: 0.4071, 
2022-07-30 13:42:48 - train: epoch 0089, iter [04000, 05004], lr: 0.001000, loss: 1.1036, stu_CELoss: 0.6603, DKDLoss: 0.4434, 
2022-07-30 13:43:21 - train: epoch 0089, iter [04100, 05004], lr: 0.001000, loss: 1.2536, stu_CELoss: 0.8006, DKDLoss: 0.4530, 
2022-07-30 13:43:54 - train: epoch 0089, iter [04200, 05004], lr: 0.001000, loss: 1.1368, stu_CELoss: 0.7210, DKDLoss: 0.4158, 
2022-07-30 13:44:28 - train: epoch 0089, iter [04300, 05004], lr: 0.001000, loss: 1.2424, stu_CELoss: 0.7811, DKDLoss: 0.4613, 
2022-07-30 13:45:01 - train: epoch 0089, iter [04400, 05004], lr: 0.001000, loss: 1.1213, stu_CELoss: 0.7011, DKDLoss: 0.4203, 
2022-07-30 13:45:34 - train: epoch 0089, iter [04500, 05004], lr: 0.001000, loss: 1.0207, stu_CELoss: 0.6338, DKDLoss: 0.3869, 
2022-07-30 13:46:08 - train: epoch 0089, iter [04600, 05004], lr: 0.001000, loss: 1.2687, stu_CELoss: 0.8896, DKDLoss: 0.3791, 
2022-07-30 13:46:41 - train: epoch 0089, iter [04700, 05004], lr: 0.001000, loss: 1.1278, stu_CELoss: 0.7538, DKDLoss: 0.3740, 
2022-07-30 13:47:14 - train: epoch 0089, iter [04800, 05004], lr: 0.001000, loss: 1.0457, stu_CELoss: 0.6362, DKDLoss: 0.4095, 
2022-07-30 13:47:48 - train: epoch 0089, iter [04900, 05004], lr: 0.001000, loss: 1.2730, stu_CELoss: 0.8496, DKDLoss: 0.4235, 
2022-07-30 13:48:21 - train: epoch 0089, iter [05000, 05004], lr: 0.001000, loss: 1.0429, stu_CELoss: 0.6233, DKDLoss: 0.4196, 
2022-07-30 13:48:23 - train: epoch 089, train_loss: 1.1501
2022-07-30 13:50:54 - eval: epoch: 089, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.280%, stu_acc5: 93.418%, stu_test_loss: 0.9012
2022-07-30 13:50:55 - until epoch: 089, tea_best_acc1: 78.068%, stu_best_acc1: 77.392%
2022-07-30 13:50:55 - epoch 090 lr: 0.001000
2022-07-30 13:51:34 - train: epoch 0090, iter [00100, 05004], lr: 0.001000, loss: 1.1576, stu_CELoss: 0.7520, DKDLoss: 0.4056, 
2022-07-30 13:52:06 - train: epoch 0090, iter [00200, 05004], lr: 0.001000, loss: 1.3201, stu_CELoss: 0.9152, DKDLoss: 0.4049, 
2022-07-30 13:52:39 - train: epoch 0090, iter [00300, 05004], lr: 0.001000, loss: 1.0681, stu_CELoss: 0.6753, DKDLoss: 0.3927, 
2022-07-30 13:53:12 - train: epoch 0090, iter [00400, 05004], lr: 0.001000, loss: 1.2203, stu_CELoss: 0.7921, DKDLoss: 0.4282, 
2022-07-30 13:53:44 - train: epoch 0090, iter [00500, 05004], lr: 0.001000, loss: 1.1412, stu_CELoss: 0.7166, DKDLoss: 0.4247, 
2022-07-30 13:54:18 - train: epoch 0090, iter [00600, 05004], lr: 0.001000, loss: 1.2980, stu_CELoss: 0.9306, DKDLoss: 0.3674, 
2022-07-30 13:54:51 - train: epoch 0090, iter [00700, 05004], lr: 0.001000, loss: 1.0701, stu_CELoss: 0.6312, DKDLoss: 0.4389, 
2022-07-30 13:55:24 - train: epoch 0090, iter [00800, 05004], lr: 0.001000, loss: 1.0649, stu_CELoss: 0.6800, DKDLoss: 0.3849, 
2022-07-30 13:55:58 - train: epoch 0090, iter [00900, 05004], lr: 0.001000, loss: 1.1135, stu_CELoss: 0.7054, DKDLoss: 0.4080, 
2022-07-30 13:56:31 - train: epoch 0090, iter [01000, 05004], lr: 0.001000, loss: 1.0886, stu_CELoss: 0.7382, DKDLoss: 0.3504, 
2022-07-30 13:57:04 - train: epoch 0090, iter [01100, 05004], lr: 0.001000, loss: 1.0173, stu_CELoss: 0.6264, DKDLoss: 0.3909, 
2022-07-30 13:57:37 - train: epoch 0090, iter [01200, 05004], lr: 0.001000, loss: 1.0067, stu_CELoss: 0.5989, DKDLoss: 0.4078, 
2022-07-30 13:58:11 - train: epoch 0090, iter [01300, 05004], lr: 0.001000, loss: 1.2939, stu_CELoss: 0.8810, DKDLoss: 0.4129, 
2022-07-30 13:58:44 - train: epoch 0090, iter [01400, 05004], lr: 0.001000, loss: 1.1781, stu_CELoss: 0.7349, DKDLoss: 0.4432, 
2022-07-30 13:59:18 - train: epoch 0090, iter [01500, 05004], lr: 0.001000, loss: 1.2245, stu_CELoss: 0.8168, DKDLoss: 0.4077, 
2022-07-30 13:59:52 - train: epoch 0090, iter [01600, 05004], lr: 0.001000, loss: 1.2008, stu_CELoss: 0.7156, DKDLoss: 0.4852, 
2022-07-30 14:00:25 - train: epoch 0090, iter [01700, 05004], lr: 0.001000, loss: 1.0781, stu_CELoss: 0.7177, DKDLoss: 0.3605, 
2022-07-30 14:00:59 - train: epoch 0090, iter [01800, 05004], lr: 0.001000, loss: 0.9868, stu_CELoss: 0.5880, DKDLoss: 0.3988, 
2022-07-30 14:01:33 - train: epoch 0090, iter [01900, 05004], lr: 0.001000, loss: 1.0209, stu_CELoss: 0.6393, DKDLoss: 0.3816, 
2022-07-30 14:02:06 - train: epoch 0090, iter [02000, 05004], lr: 0.001000, loss: 1.1658, stu_CELoss: 0.7374, DKDLoss: 0.4284, 
2022-07-30 14:02:41 - train: epoch 0090, iter [02100, 05004], lr: 0.001000, loss: 1.2758, stu_CELoss: 0.8318, DKDLoss: 0.4440, 
2022-07-30 14:03:14 - train: epoch 0090, iter [02200, 05004], lr: 0.001000, loss: 1.0536, stu_CELoss: 0.6614, DKDLoss: 0.3922, 
2022-07-30 14:03:48 - train: epoch 0090, iter [02300, 05004], lr: 0.001000, loss: 1.3784, stu_CELoss: 0.8429, DKDLoss: 0.5356, 
2022-07-30 14:04:22 - train: epoch 0090, iter [02400, 05004], lr: 0.001000, loss: 1.1451, stu_CELoss: 0.7190, DKDLoss: 0.4261, 
2022-07-30 14:04:56 - train: epoch 0090, iter [02500, 05004], lr: 0.001000, loss: 1.1614, stu_CELoss: 0.6984, DKDLoss: 0.4630, 
2022-07-30 14:05:29 - train: epoch 0090, iter [02600, 05004], lr: 0.001000, loss: 1.2053, stu_CELoss: 0.7534, DKDLoss: 0.4519, 
2022-07-30 14:06:03 - train: epoch 0090, iter [02700, 05004], lr: 0.001000, loss: 1.0001, stu_CELoss: 0.5819, DKDLoss: 0.4182, 
2022-07-30 14:06:37 - train: epoch 0090, iter [02800, 05004], lr: 0.001000, loss: 0.9444, stu_CELoss: 0.5318, DKDLoss: 0.4126, 
2022-07-30 14:07:11 - train: epoch 0090, iter [02900, 05004], lr: 0.001000, loss: 1.1748, stu_CELoss: 0.7345, DKDLoss: 0.4403, 
2022-07-30 14:07:44 - train: epoch 0090, iter [03000, 05004], lr: 0.001000, loss: 1.0807, stu_CELoss: 0.6542, DKDLoss: 0.4265, 
2022-07-30 14:08:18 - train: epoch 0090, iter [03100, 05004], lr: 0.001000, loss: 1.1033, stu_CELoss: 0.7045, DKDLoss: 0.3988, 
2022-07-30 14:08:53 - train: epoch 0090, iter [03200, 05004], lr: 0.001000, loss: 1.2124, stu_CELoss: 0.7579, DKDLoss: 0.4545, 
2022-07-30 14:09:27 - train: epoch 0090, iter [03300, 05004], lr: 0.001000, loss: 1.3724, stu_CELoss: 0.8918, DKDLoss: 0.4805, 
2022-07-30 14:10:01 - train: epoch 0090, iter [03400, 05004], lr: 0.001000, loss: 1.1552, stu_CELoss: 0.7188, DKDLoss: 0.4363, 
2022-07-30 14:10:36 - train: epoch 0090, iter [03500, 05004], lr: 0.001000, loss: 1.1228, stu_CELoss: 0.7287, DKDLoss: 0.3940, 
2022-07-30 14:11:10 - train: epoch 0090, iter [03600, 05004], lr: 0.001000, loss: 1.0893, stu_CELoss: 0.6647, DKDLoss: 0.4247, 
2022-07-30 14:11:45 - train: epoch 0090, iter [03700, 05004], lr: 0.001000, loss: 1.0749, stu_CELoss: 0.6832, DKDLoss: 0.3917, 
2022-07-30 14:12:19 - train: epoch 0090, iter [03800, 05004], lr: 0.001000, loss: 1.2512, stu_CELoss: 0.7711, DKDLoss: 0.4801, 
2022-07-30 14:12:54 - train: epoch 0090, iter [03900, 05004], lr: 0.001000, loss: 1.0404, stu_CELoss: 0.6348, DKDLoss: 0.4056, 
2022-07-30 14:13:29 - train: epoch 0090, iter [04000, 05004], lr: 0.001000, loss: 1.1594, stu_CELoss: 0.7611, DKDLoss: 0.3983, 
2022-07-30 14:14:03 - train: epoch 0090, iter [04100, 05004], lr: 0.001000, loss: 1.2355, stu_CELoss: 0.7774, DKDLoss: 0.4581, 
2022-07-30 14:14:38 - train: epoch 0090, iter [04200, 05004], lr: 0.001000, loss: 1.2746, stu_CELoss: 0.8459, DKDLoss: 0.4286, 
2022-07-30 14:15:12 - train: epoch 0090, iter [04300, 05004], lr: 0.001000, loss: 1.1872, stu_CELoss: 0.7155, DKDLoss: 0.4716, 
2022-07-30 14:15:47 - train: epoch 0090, iter [04400, 05004], lr: 0.001000, loss: 1.0978, stu_CELoss: 0.6957, DKDLoss: 0.4021, 
2022-07-30 14:16:21 - train: epoch 0090, iter [04500, 05004], lr: 0.001000, loss: 1.0102, stu_CELoss: 0.5764, DKDLoss: 0.4338, 
2022-07-30 14:16:56 - train: epoch 0090, iter [04600, 05004], lr: 0.001000, loss: 1.1336, stu_CELoss: 0.6649, DKDLoss: 0.4687, 
2022-07-30 14:17:31 - train: epoch 0090, iter [04700, 05004], lr: 0.001000, loss: 1.0194, stu_CELoss: 0.6458, DKDLoss: 0.3736, 
2022-07-30 14:18:06 - train: epoch 0090, iter [04800, 05004], lr: 0.001000, loss: 1.3692, stu_CELoss: 0.9300, DKDLoss: 0.4393, 
2022-07-30 14:18:40 - train: epoch 0090, iter [04900, 05004], lr: 0.001000, loss: 0.9206, stu_CELoss: 0.5555, DKDLoss: 0.3651, 
2022-07-30 14:19:14 - train: epoch 0090, iter [05000, 05004], lr: 0.001000, loss: 1.1730, stu_CELoss: 0.7161, DKDLoss: 0.4569, 
2022-07-30 14:19:16 - train: epoch 090, train_loss: 1.1454
2022-07-30 14:21:51 - eval: epoch: 090, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.356%, stu_acc5: 93.498%, stu_test_loss: 0.9022
2022-07-30 14:21:52 - until epoch: 090, tea_best_acc1: 78.068%, stu_best_acc1: 77.392%
2022-07-30 14:21:52 - epoch 091 lr: 0.000100
2022-07-30 14:22:33 - train: epoch 0091, iter [00100, 05004], lr: 0.000100, loss: 0.9666, stu_CELoss: 0.6130, DKDLoss: 0.3536, 
2022-07-30 14:23:06 - train: epoch 0091, iter [00200, 05004], lr: 0.000100, loss: 1.1281, stu_CELoss: 0.7523, DKDLoss: 0.3759, 
2022-07-30 14:23:40 - train: epoch 0091, iter [00300, 05004], lr: 0.000100, loss: 1.2020, stu_CELoss: 0.8168, DKDLoss: 0.3851, 
2022-07-30 14:24:14 - train: epoch 0091, iter [00400, 05004], lr: 0.000100, loss: 1.1879, stu_CELoss: 0.7602, DKDLoss: 0.4277, 
2022-07-30 14:24:47 - train: epoch 0091, iter [00500, 05004], lr: 0.000100, loss: 0.9330, stu_CELoss: 0.5174, DKDLoss: 0.4156, 
2022-07-30 14:25:21 - train: epoch 0091, iter [00600, 05004], lr: 0.000100, loss: 1.1074, stu_CELoss: 0.6954, DKDLoss: 0.4121, 
2022-07-30 14:25:55 - train: epoch 0091, iter [00700, 05004], lr: 0.000100, loss: 1.3998, stu_CELoss: 0.9793, DKDLoss: 0.4205, 
2022-07-30 14:26:29 - train: epoch 0091, iter [00800, 05004], lr: 0.000100, loss: 1.0616, stu_CELoss: 0.6484, DKDLoss: 0.4132, 
2022-07-30 14:27:03 - train: epoch 0091, iter [00900, 05004], lr: 0.000100, loss: 0.9901, stu_CELoss: 0.6161, DKDLoss: 0.3740, 
2022-07-30 14:27:37 - train: epoch 0091, iter [01000, 05004], lr: 0.000100, loss: 1.1574, stu_CELoss: 0.7428, DKDLoss: 0.4146, 
2022-07-30 14:28:11 - train: epoch 0091, iter [01100, 05004], lr: 0.000100, loss: 0.8182, stu_CELoss: 0.4631, DKDLoss: 0.3551, 
2022-07-30 14:28:45 - train: epoch 0091, iter [01200, 05004], lr: 0.000100, loss: 1.2027, stu_CELoss: 0.7968, DKDLoss: 0.4058, 
2022-07-30 14:29:19 - train: epoch 0091, iter [01300, 05004], lr: 0.000100, loss: 1.1728, stu_CELoss: 0.7672, DKDLoss: 0.4056, 
2022-07-30 14:29:53 - train: epoch 0091, iter [01400, 05004], lr: 0.000100, loss: 1.2673, stu_CELoss: 0.8235, DKDLoss: 0.4438, 
2022-07-30 14:30:27 - train: epoch 0091, iter [01500, 05004], lr: 0.000100, loss: 1.1199, stu_CELoss: 0.7224, DKDLoss: 0.3975, 
2022-07-30 14:31:01 - train: epoch 0091, iter [01600, 05004], lr: 0.000100, loss: 1.1274, stu_CELoss: 0.7474, DKDLoss: 0.3799, 
2022-07-30 14:31:35 - train: epoch 0091, iter [01700, 05004], lr: 0.000100, loss: 1.2472, stu_CELoss: 0.8772, DKDLoss: 0.3700, 
2022-07-30 14:32:10 - train: epoch 0091, iter [01800, 05004], lr: 0.000100, loss: 1.1650, stu_CELoss: 0.7554, DKDLoss: 0.4095, 
2022-07-30 14:32:44 - train: epoch 0091, iter [01900, 05004], lr: 0.000100, loss: 1.1162, stu_CELoss: 0.7379, DKDLoss: 0.3783, 
2022-07-30 14:33:18 - train: epoch 0091, iter [02000, 05004], lr: 0.000100, loss: 0.8705, stu_CELoss: 0.4967, DKDLoss: 0.3738, 
2022-07-30 14:33:52 - train: epoch 0091, iter [02100, 05004], lr: 0.000100, loss: 1.0631, stu_CELoss: 0.6513, DKDLoss: 0.4119, 
2022-07-30 14:34:26 - train: epoch 0091, iter [02200, 05004], lr: 0.000100, loss: 1.1902, stu_CELoss: 0.7629, DKDLoss: 0.4274, 
2022-07-30 14:35:00 - train: epoch 0091, iter [02300, 05004], lr: 0.000100, loss: 1.0751, stu_CELoss: 0.6474, DKDLoss: 0.4278, 
2022-07-30 14:35:34 - train: epoch 0091, iter [02400, 05004], lr: 0.000100, loss: 1.1001, stu_CELoss: 0.7058, DKDLoss: 0.3943, 
2022-07-30 14:36:09 - train: epoch 0091, iter [02500, 05004], lr: 0.000100, loss: 1.1704, stu_CELoss: 0.7692, DKDLoss: 0.4012, 
2022-07-30 14:36:43 - train: epoch 0091, iter [02600, 05004], lr: 0.000100, loss: 0.8206, stu_CELoss: 0.4650, DKDLoss: 0.3556, 
2022-07-30 14:37:17 - train: epoch 0091, iter [02700, 05004], lr: 0.000100, loss: 1.1755, stu_CELoss: 0.7835, DKDLoss: 0.3920, 
2022-07-30 14:37:51 - train: epoch 0091, iter [02800, 05004], lr: 0.000100, loss: 1.1638, stu_CELoss: 0.7986, DKDLoss: 0.3652, 
2022-07-30 14:38:25 - train: epoch 0091, iter [02900, 05004], lr: 0.000100, loss: 1.2668, stu_CELoss: 0.8751, DKDLoss: 0.3917, 
2022-07-30 14:38:58 - train: epoch 0091, iter [03000, 05004], lr: 0.000100, loss: 1.1810, stu_CELoss: 0.7630, DKDLoss: 0.4180, 
2022-07-30 14:39:31 - train: epoch 0091, iter [03100, 05004], lr: 0.000100, loss: 1.2275, stu_CELoss: 0.8340, DKDLoss: 0.3935, 
2022-07-30 14:40:04 - train: epoch 0091, iter [03200, 05004], lr: 0.000100, loss: 1.2306, stu_CELoss: 0.7836, DKDLoss: 0.4470, 
2022-07-30 14:40:38 - train: epoch 0091, iter [03300, 05004], lr: 0.000100, loss: 1.1034, stu_CELoss: 0.6778, DKDLoss: 0.4256, 
2022-07-30 14:41:12 - train: epoch 0091, iter [03400, 05004], lr: 0.000100, loss: 1.1872, stu_CELoss: 0.7181, DKDLoss: 0.4691, 
2022-07-30 14:41:45 - train: epoch 0091, iter [03500, 05004], lr: 0.000100, loss: 1.1203, stu_CELoss: 0.6906, DKDLoss: 0.4297, 
2022-07-30 14:42:19 - train: epoch 0091, iter [03600, 05004], lr: 0.000100, loss: 1.1961, stu_CELoss: 0.7458, DKDLoss: 0.4503, 
2022-07-30 14:42:53 - train: epoch 0091, iter [03700, 05004], lr: 0.000100, loss: 1.1277, stu_CELoss: 0.7018, DKDLoss: 0.4260, 
2022-07-30 14:43:26 - train: epoch 0091, iter [03800, 05004], lr: 0.000100, loss: 1.2003, stu_CELoss: 0.8105, DKDLoss: 0.3898, 
2022-07-30 14:44:00 - train: epoch 0091, iter [03900, 05004], lr: 0.000100, loss: 1.0089, stu_CELoss: 0.6225, DKDLoss: 0.3864, 
2022-07-30 14:44:34 - train: epoch 0091, iter [04000, 05004], lr: 0.000100, loss: 1.0719, stu_CELoss: 0.6654, DKDLoss: 0.4065, 
2022-07-30 14:45:08 - train: epoch 0091, iter [04100, 05004], lr: 0.000100, loss: 1.0906, stu_CELoss: 0.6879, DKDLoss: 0.4027, 
2022-07-30 14:45:42 - train: epoch 0091, iter [04200, 05004], lr: 0.000100, loss: 1.1895, stu_CELoss: 0.8135, DKDLoss: 0.3760, 
2022-07-30 14:46:16 - train: epoch 0091, iter [04300, 05004], lr: 0.000100, loss: 1.2348, stu_CELoss: 0.8623, DKDLoss: 0.3725, 
2022-07-30 14:46:50 - train: epoch 0091, iter [04400, 05004], lr: 0.000100, loss: 1.1190, stu_CELoss: 0.7259, DKDLoss: 0.3930, 
2022-07-30 14:47:23 - train: epoch 0091, iter [04500, 05004], lr: 0.000100, loss: 1.0068, stu_CELoss: 0.6119, DKDLoss: 0.3949, 
2022-07-30 14:47:57 - train: epoch 0091, iter [04600, 05004], lr: 0.000100, loss: 1.1268, stu_CELoss: 0.7324, DKDLoss: 0.3943, 
2022-07-30 14:48:31 - train: epoch 0091, iter [04700, 05004], lr: 0.000100, loss: 1.1081, stu_CELoss: 0.6833, DKDLoss: 0.4248, 
2022-07-30 14:49:05 - train: epoch 0091, iter [04800, 05004], lr: 0.000100, loss: 1.1029, stu_CELoss: 0.7032, DKDLoss: 0.3997, 
2022-07-30 14:49:38 - train: epoch 0091, iter [04900, 05004], lr: 0.000100, loss: 0.9364, stu_CELoss: 0.5692, DKDLoss: 0.3671, 
2022-07-30 14:50:12 - train: epoch 0091, iter [05000, 05004], lr: 0.000100, loss: 1.2296, stu_CELoss: 0.7691, DKDLoss: 0.4605, 
2022-07-30 14:50:13 - train: epoch 091, train_loss: 1.1166
2022-07-30 14:52:45 - eval: epoch: 091, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.496%, stu_acc5: 93.562%, stu_test_loss: 0.8928
2022-07-30 14:52:46 - until epoch: 091, tea_best_acc1: 78.068%, stu_best_acc1: 77.496%
2022-07-30 14:52:46 - epoch 092 lr: 0.000100
2022-07-30 14:53:26 - train: epoch 0092, iter [00100, 05004], lr: 0.000100, loss: 1.1547, stu_CELoss: 0.7384, DKDLoss: 0.4164, 
2022-07-30 14:53:59 - train: epoch 0092, iter [00200, 05004], lr: 0.000100, loss: 1.1308, stu_CELoss: 0.7234, DKDLoss: 0.4074, 
2022-07-30 14:54:32 - train: epoch 0092, iter [00300, 05004], lr: 0.000100, loss: 1.2105, stu_CELoss: 0.8176, DKDLoss: 0.3929, 
2022-07-30 14:55:05 - train: epoch 0092, iter [00400, 05004], lr: 0.000100, loss: 1.3291, stu_CELoss: 0.9452, DKDLoss: 0.3839, 
2022-07-30 14:55:38 - train: epoch 0092, iter [00500, 05004], lr: 0.000100, loss: 1.1139, stu_CELoss: 0.6420, DKDLoss: 0.4719, 
2022-07-30 14:56:11 - train: epoch 0092, iter [00600, 05004], lr: 0.000100, loss: 1.1249, stu_CELoss: 0.7007, DKDLoss: 0.4241, 
2022-07-30 14:56:45 - train: epoch 0092, iter [00700, 05004], lr: 0.000100, loss: 1.1431, stu_CELoss: 0.7089, DKDLoss: 0.4342, 
2022-07-30 14:57:18 - train: epoch 0092, iter [00800, 05004], lr: 0.000100, loss: 1.1893, stu_CELoss: 0.7780, DKDLoss: 0.4113, 
2022-07-30 14:57:52 - train: epoch 0092, iter [00900, 05004], lr: 0.000100, loss: 1.3537, stu_CELoss: 0.9594, DKDLoss: 0.3943, 
2022-07-30 14:58:25 - train: epoch 0092, iter [01000, 05004], lr: 0.000100, loss: 1.0448, stu_CELoss: 0.6364, DKDLoss: 0.4084, 
2022-07-30 14:58:59 - train: epoch 0092, iter [01100, 05004], lr: 0.000100, loss: 1.2771, stu_CELoss: 0.8471, DKDLoss: 0.4300, 
2022-07-30 14:59:33 - train: epoch 0092, iter [01200, 05004], lr: 0.000100, loss: 0.9754, stu_CELoss: 0.5622, DKDLoss: 0.4131, 
2022-07-30 15:00:06 - train: epoch 0092, iter [01300, 05004], lr: 0.000100, loss: 1.0114, stu_CELoss: 0.6326, DKDLoss: 0.3788, 
2022-07-30 15:00:40 - train: epoch 0092, iter [01400, 05004], lr: 0.000100, loss: 0.9915, stu_CELoss: 0.6297, DKDLoss: 0.3618, 
2022-07-30 15:01:13 - train: epoch 0092, iter [01500, 05004], lr: 0.000100, loss: 1.0926, stu_CELoss: 0.6891, DKDLoss: 0.4035, 
2022-07-30 15:01:48 - train: epoch 0092, iter [01600, 05004], lr: 0.000100, loss: 1.0748, stu_CELoss: 0.7034, DKDLoss: 0.3714, 
2022-07-30 15:02:21 - train: epoch 0092, iter [01700, 05004], lr: 0.000100, loss: 1.0286, stu_CELoss: 0.6409, DKDLoss: 0.3877, 
2022-07-30 15:02:55 - train: epoch 0092, iter [01800, 05004], lr: 0.000100, loss: 0.9852, stu_CELoss: 0.6209, DKDLoss: 0.3642, 
2022-07-30 15:03:30 - train: epoch 0092, iter [01900, 05004], lr: 0.000100, loss: 0.8777, stu_CELoss: 0.5329, DKDLoss: 0.3448, 
2022-07-30 15:04:04 - train: epoch 0092, iter [02000, 05004], lr: 0.000100, loss: 0.9465, stu_CELoss: 0.6152, DKDLoss: 0.3314, 
2022-07-30 15:04:38 - train: epoch 0092, iter [02100, 05004], lr: 0.000100, loss: 1.2466, stu_CELoss: 0.8554, DKDLoss: 0.3911, 
2022-07-30 15:05:11 - train: epoch 0092, iter [02200, 05004], lr: 0.000100, loss: 1.1309, stu_CELoss: 0.7155, DKDLoss: 0.4154, 
2022-07-30 15:05:45 - train: epoch 0092, iter [02300, 05004], lr: 0.000100, loss: 1.0239, stu_CELoss: 0.6364, DKDLoss: 0.3875, 
2022-07-30 15:06:18 - train: epoch 0092, iter [02400, 05004], lr: 0.000100, loss: 0.8803, stu_CELoss: 0.5223, DKDLoss: 0.3580, 
2022-07-30 15:06:52 - train: epoch 0092, iter [02500, 05004], lr: 0.000100, loss: 1.0886, stu_CELoss: 0.6865, DKDLoss: 0.4020, 
2022-07-30 15:07:26 - train: epoch 0092, iter [02600, 05004], lr: 0.000100, loss: 1.0955, stu_CELoss: 0.7204, DKDLoss: 0.3751, 
2022-07-30 15:07:59 - train: epoch 0092, iter [02700, 05004], lr: 0.000100, loss: 1.3231, stu_CELoss: 0.8770, DKDLoss: 0.4461, 
2022-07-30 15:08:33 - train: epoch 0092, iter [02800, 05004], lr: 0.000100, loss: 1.2534, stu_CELoss: 0.8258, DKDLoss: 0.4276, 
2022-07-30 15:09:07 - train: epoch 0092, iter [02900, 05004], lr: 0.000100, loss: 1.2251, stu_CELoss: 0.8323, DKDLoss: 0.3928, 
2022-07-30 15:09:40 - train: epoch 0092, iter [03000, 05004], lr: 0.000100, loss: 1.1112, stu_CELoss: 0.6830, DKDLoss: 0.4281, 
2022-07-30 15:10:14 - train: epoch 0092, iter [03100, 05004], lr: 0.000100, loss: 1.1067, stu_CELoss: 0.6630, DKDLoss: 0.4438, 
2022-07-30 15:10:48 - train: epoch 0092, iter [03200, 05004], lr: 0.000100, loss: 1.1158, stu_CELoss: 0.6883, DKDLoss: 0.4275, 
2022-07-30 15:11:22 - train: epoch 0092, iter [03300, 05004], lr: 0.000100, loss: 1.1628, stu_CELoss: 0.7642, DKDLoss: 0.3986, 
2022-07-30 15:11:55 - train: epoch 0092, iter [03400, 05004], lr: 0.000100, loss: 1.2375, stu_CELoss: 0.8497, DKDLoss: 0.3879, 
2022-07-30 15:12:29 - train: epoch 0092, iter [03500, 05004], lr: 0.000100, loss: 1.1412, stu_CELoss: 0.6735, DKDLoss: 0.4678, 
2022-07-30 15:13:02 - train: epoch 0092, iter [03600, 05004], lr: 0.000100, loss: 1.1282, stu_CELoss: 0.7594, DKDLoss: 0.3688, 
2022-07-30 15:13:36 - train: epoch 0092, iter [03700, 05004], lr: 0.000100, loss: 1.1233, stu_CELoss: 0.7402, DKDLoss: 0.3831, 
2022-07-30 15:14:10 - train: epoch 0092, iter [03800, 05004], lr: 0.000100, loss: 1.0796, stu_CELoss: 0.7279, DKDLoss: 0.3517, 
2022-07-30 15:14:43 - train: epoch 0092, iter [03900, 05004], lr: 0.000100, loss: 1.1714, stu_CELoss: 0.7400, DKDLoss: 0.4313, 
2022-07-30 15:15:17 - train: epoch 0092, iter [04000, 05004], lr: 0.000100, loss: 1.1214, stu_CELoss: 0.7067, DKDLoss: 0.4147, 
2022-07-30 15:15:51 - train: epoch 0092, iter [04100, 05004], lr: 0.000100, loss: 0.9692, stu_CELoss: 0.5805, DKDLoss: 0.3888, 
2022-07-30 15:16:24 - train: epoch 0092, iter [04200, 05004], lr: 0.000100, loss: 1.1863, stu_CELoss: 0.8068, DKDLoss: 0.3795, 
2022-07-30 15:16:58 - train: epoch 0092, iter [04300, 05004], lr: 0.000100, loss: 1.1780, stu_CELoss: 0.7815, DKDLoss: 0.3965, 
2022-07-30 15:17:31 - train: epoch 0092, iter [04400, 05004], lr: 0.000100, loss: 1.0548, stu_CELoss: 0.6413, DKDLoss: 0.4135, 
2022-07-30 15:18:05 - train: epoch 0092, iter [04500, 05004], lr: 0.000100, loss: 1.1817, stu_CELoss: 0.7951, DKDLoss: 0.3866, 
2022-07-30 15:18:39 - train: epoch 0092, iter [04600, 05004], lr: 0.000100, loss: 0.9930, stu_CELoss: 0.5685, DKDLoss: 0.4245, 
2022-07-30 15:19:13 - train: epoch 0092, iter [04700, 05004], lr: 0.000100, loss: 1.0234, stu_CELoss: 0.6356, DKDLoss: 0.3879, 
2022-07-30 15:19:46 - train: epoch 0092, iter [04800, 05004], lr: 0.000100, loss: 1.0843, stu_CELoss: 0.6892, DKDLoss: 0.3951, 
2022-07-30 15:20:20 - train: epoch 0092, iter [04900, 05004], lr: 0.000100, loss: 1.0609, stu_CELoss: 0.6643, DKDLoss: 0.3966, 
2022-07-30 15:20:54 - train: epoch 0092, iter [05000, 05004], lr: 0.000100, loss: 1.0351, stu_CELoss: 0.6272, DKDLoss: 0.4079, 
2022-07-30 15:20:55 - train: epoch 092, train_loss: 1.1069
2022-07-30 15:23:28 - eval: epoch: 092, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.538%, stu_acc5: 93.512%, stu_test_loss: 0.8933
2022-07-30 15:23:29 - until epoch: 092, tea_best_acc1: 78.068%, stu_best_acc1: 77.538%
2022-07-30 15:23:29 - epoch 093 lr: 0.000100
2022-07-30 15:24:09 - train: epoch 0093, iter [00100, 05004], lr: 0.000100, loss: 1.0947, stu_CELoss: 0.6642, DKDLoss: 0.4305, 
2022-07-30 15:24:42 - train: epoch 0093, iter [00200, 05004], lr: 0.000100, loss: 1.1689, stu_CELoss: 0.7429, DKDLoss: 0.4260, 
2022-07-30 15:25:15 - train: epoch 0093, iter [00300, 05004], lr: 0.000100, loss: 1.0311, stu_CELoss: 0.6430, DKDLoss: 0.3881, 
2022-07-30 15:25:48 - train: epoch 0093, iter [00400, 05004], lr: 0.000100, loss: 1.0786, stu_CELoss: 0.6943, DKDLoss: 0.3843, 
2022-07-30 15:26:22 - train: epoch 0093, iter [00500, 05004], lr: 0.000100, loss: 1.1863, stu_CELoss: 0.7638, DKDLoss: 0.4225, 
2022-07-30 15:26:55 - train: epoch 0093, iter [00600, 05004], lr: 0.000100, loss: 1.0673, stu_CELoss: 0.6981, DKDLoss: 0.3693, 
2022-07-30 15:27:29 - train: epoch 0093, iter [00700, 05004], lr: 0.000100, loss: 1.0143, stu_CELoss: 0.6265, DKDLoss: 0.3878, 
2022-07-30 15:28:03 - train: epoch 0093, iter [00800, 05004], lr: 0.000100, loss: 1.0169, stu_CELoss: 0.5903, DKDLoss: 0.4266, 
2022-07-30 15:28:36 - train: epoch 0093, iter [00900, 05004], lr: 0.000100, loss: 1.2638, stu_CELoss: 0.8577, DKDLoss: 0.4061, 
2022-07-30 15:29:10 - train: epoch 0093, iter [01000, 05004], lr: 0.000100, loss: 0.7747, stu_CELoss: 0.4311, DKDLoss: 0.3435, 
2022-07-30 15:29:44 - train: epoch 0093, iter [01100, 05004], lr: 0.000100, loss: 1.2281, stu_CELoss: 0.8292, DKDLoss: 0.3990, 
2022-07-30 15:30:18 - train: epoch 0093, iter [01200, 05004], lr: 0.000100, loss: 1.0442, stu_CELoss: 0.6522, DKDLoss: 0.3920, 
2022-07-30 15:30:52 - train: epoch 0093, iter [01300, 05004], lr: 0.000100, loss: 1.1423, stu_CELoss: 0.7879, DKDLoss: 0.3543, 
2022-07-30 15:31:26 - train: epoch 0093, iter [01400, 05004], lr: 0.000100, loss: 1.1293, stu_CELoss: 0.7459, DKDLoss: 0.3834, 
2022-07-30 15:32:00 - train: epoch 0093, iter [01500, 05004], lr: 0.000100, loss: 1.2416, stu_CELoss: 0.8138, DKDLoss: 0.4278, 
2022-07-30 15:32:33 - train: epoch 0093, iter [01600, 05004], lr: 0.000100, loss: 1.1161, stu_CELoss: 0.7471, DKDLoss: 0.3690, 
2022-07-30 15:33:07 - train: epoch 0093, iter [01700, 05004], lr: 0.000100, loss: 1.1379, stu_CELoss: 0.7157, DKDLoss: 0.4221, 
2022-07-30 15:33:41 - train: epoch 0093, iter [01800, 05004], lr: 0.000100, loss: 1.1665, stu_CELoss: 0.7366, DKDLoss: 0.4299, 
2022-07-30 15:34:15 - train: epoch 0093, iter [01900, 05004], lr: 0.000100, loss: 1.0016, stu_CELoss: 0.6502, DKDLoss: 0.3514, 
2022-07-30 15:34:49 - train: epoch 0093, iter [02000, 05004], lr: 0.000100, loss: 0.9231, stu_CELoss: 0.5743, DKDLoss: 0.3487, 
2022-07-30 15:35:23 - train: epoch 0093, iter [02100, 05004], lr: 0.000100, loss: 1.2530, stu_CELoss: 0.8212, DKDLoss: 0.4318, 
2022-07-30 15:35:57 - train: epoch 0093, iter [02200, 05004], lr: 0.000100, loss: 1.2037, stu_CELoss: 0.7898, DKDLoss: 0.4138, 
2022-07-30 15:36:31 - train: epoch 0093, iter [02300, 05004], lr: 0.000100, loss: 1.0783, stu_CELoss: 0.6746, DKDLoss: 0.4037, 
2022-07-30 15:37:04 - train: epoch 0093, iter [02400, 05004], lr: 0.000100, loss: 1.1116, stu_CELoss: 0.7572, DKDLoss: 0.3544, 
2022-07-30 15:37:38 - train: epoch 0093, iter [02500, 05004], lr: 0.000100, loss: 1.1188, stu_CELoss: 0.7342, DKDLoss: 0.3846, 
2022-07-30 15:38:12 - train: epoch 0093, iter [02600, 05004], lr: 0.000100, loss: 1.1418, stu_CELoss: 0.7376, DKDLoss: 0.4042, 
2022-07-30 15:38:46 - train: epoch 0093, iter [02700, 05004], lr: 0.000100, loss: 0.9841, stu_CELoss: 0.6026, DKDLoss: 0.3815, 
2022-07-30 15:39:20 - train: epoch 0093, iter [02800, 05004], lr: 0.000100, loss: 1.2059, stu_CELoss: 0.8153, DKDLoss: 0.3906, 
2022-07-30 15:39:53 - train: epoch 0093, iter [02900, 05004], lr: 0.000100, loss: 0.9237, stu_CELoss: 0.5626, DKDLoss: 0.3611, 
2022-07-30 15:40:27 - train: epoch 0093, iter [03000, 05004], lr: 0.000100, loss: 0.9921, stu_CELoss: 0.6018, DKDLoss: 0.3902, 
2022-07-30 15:41:01 - train: epoch 0093, iter [03100, 05004], lr: 0.000100, loss: 1.2400, stu_CELoss: 0.8117, DKDLoss: 0.4283, 
2022-07-30 15:41:35 - train: epoch 0093, iter [03200, 05004], lr: 0.000100, loss: 1.0297, stu_CELoss: 0.6533, DKDLoss: 0.3763, 
2022-07-30 15:42:08 - train: epoch 0093, iter [03300, 05004], lr: 0.000100, loss: 1.1755, stu_CELoss: 0.7850, DKDLoss: 0.3905, 
2022-07-30 15:42:42 - train: epoch 0093, iter [03400, 05004], lr: 0.000100, loss: 1.2111, stu_CELoss: 0.8258, DKDLoss: 0.3854, 
2022-07-30 15:43:15 - train: epoch 0093, iter [03500, 05004], lr: 0.000100, loss: 1.1029, stu_CELoss: 0.7160, DKDLoss: 0.3869, 
2022-07-30 15:43:49 - train: epoch 0093, iter [03600, 05004], lr: 0.000100, loss: 1.2947, stu_CELoss: 0.8617, DKDLoss: 0.4330, 
2022-07-30 15:44:22 - train: epoch 0093, iter [03700, 05004], lr: 0.000100, loss: 1.0583, stu_CELoss: 0.6638, DKDLoss: 0.3945, 
2022-07-30 15:44:56 - train: epoch 0093, iter [03800, 05004], lr: 0.000100, loss: 1.0326, stu_CELoss: 0.6397, DKDLoss: 0.3929, 
2022-07-30 15:45:29 - train: epoch 0093, iter [03900, 05004], lr: 0.000100, loss: 1.0733, stu_CELoss: 0.6537, DKDLoss: 0.4195, 
2022-07-30 15:46:03 - train: epoch 0093, iter [04000, 05004], lr: 0.000100, loss: 1.2915, stu_CELoss: 0.9018, DKDLoss: 0.3898, 
2022-07-30 15:46:37 - train: epoch 0093, iter [04100, 05004], lr: 0.000100, loss: 1.1986, stu_CELoss: 0.7638, DKDLoss: 0.4348, 
2022-07-30 15:47:10 - train: epoch 0093, iter [04200, 05004], lr: 0.000100, loss: 1.2171, stu_CELoss: 0.7857, DKDLoss: 0.4314, 
2022-07-30 15:47:43 - train: epoch 0093, iter [04300, 05004], lr: 0.000100, loss: 1.1012, stu_CELoss: 0.7155, DKDLoss: 0.3857, 
2022-07-30 15:48:17 - train: epoch 0093, iter [04400, 05004], lr: 0.000100, loss: 1.0421, stu_CELoss: 0.6671, DKDLoss: 0.3750, 
2022-07-30 15:48:50 - train: epoch 0093, iter [04500, 05004], lr: 0.000100, loss: 1.0493, stu_CELoss: 0.6720, DKDLoss: 0.3772, 
2022-07-30 15:49:24 - train: epoch 0093, iter [04600, 05004], lr: 0.000100, loss: 0.9797, stu_CELoss: 0.6120, DKDLoss: 0.3678, 
2022-07-30 15:49:58 - train: epoch 0093, iter [04700, 05004], lr: 0.000100, loss: 1.2274, stu_CELoss: 0.8154, DKDLoss: 0.4119, 
2022-07-30 15:50:31 - train: epoch 0093, iter [04800, 05004], lr: 0.000100, loss: 1.0159, stu_CELoss: 0.6260, DKDLoss: 0.3899, 
2022-07-30 15:51:04 - train: epoch 0093, iter [04900, 05004], lr: 0.000100, loss: 1.1300, stu_CELoss: 0.7577, DKDLoss: 0.3723, 
2022-07-30 15:51:37 - train: epoch 0093, iter [05000, 05004], lr: 0.000100, loss: 1.0375, stu_CELoss: 0.6479, DKDLoss: 0.3896, 
2022-07-30 15:51:39 - train: epoch 093, train_loss: 1.1024
2022-07-30 15:54:11 - eval: epoch: 093, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.522%, stu_acc5: 93.590%, stu_test_loss: 0.8913
2022-07-30 15:54:11 - until epoch: 093, tea_best_acc1: 78.068%, stu_best_acc1: 77.538%
2022-07-30 15:54:11 - epoch 094 lr: 0.000100
2022-07-30 15:54:51 - train: epoch 0094, iter [00100, 05004], lr: 0.000100, loss: 1.1697, stu_CELoss: 0.7321, DKDLoss: 0.4376, 
2022-07-30 15:55:25 - train: epoch 0094, iter [00200, 05004], lr: 0.000100, loss: 1.1429, stu_CELoss: 0.7346, DKDLoss: 0.4082, 
2022-07-30 15:55:58 - train: epoch 0094, iter [00300, 05004], lr: 0.000100, loss: 1.1923, stu_CELoss: 0.7897, DKDLoss: 0.4026, 
2022-07-30 15:56:31 - train: epoch 0094, iter [00400, 05004], lr: 0.000100, loss: 1.1758, stu_CELoss: 0.7976, DKDLoss: 0.3782, 
2022-07-30 15:57:05 - train: epoch 0094, iter [00500, 05004], lr: 0.000100, loss: 1.2373, stu_CELoss: 0.7987, DKDLoss: 0.4387, 
2022-07-30 15:57:39 - train: epoch 0094, iter [00600, 05004], lr: 0.000100, loss: 1.0892, stu_CELoss: 0.7088, DKDLoss: 0.3804, 
2022-07-30 15:58:13 - train: epoch 0094, iter [00700, 05004], lr: 0.000100, loss: 1.0428, stu_CELoss: 0.6153, DKDLoss: 0.4274, 
2022-07-30 15:58:46 - train: epoch 0094, iter [00800, 05004], lr: 0.000100, loss: 1.0215, stu_CELoss: 0.6318, DKDLoss: 0.3897, 
2022-07-30 15:59:20 - train: epoch 0094, iter [00900, 05004], lr: 0.000100, loss: 1.0472, stu_CELoss: 0.6615, DKDLoss: 0.3858, 
2022-07-30 15:59:53 - train: epoch 0094, iter [01000, 05004], lr: 0.000100, loss: 1.0960, stu_CELoss: 0.7176, DKDLoss: 0.3785, 
2022-07-30 16:00:27 - train: epoch 0094, iter [01100, 05004], lr: 0.000100, loss: 1.4927, stu_CELoss: 1.0384, DKDLoss: 0.4544, 
2022-07-30 16:01:01 - train: epoch 0094, iter [01200, 05004], lr: 0.000100, loss: 1.1560, stu_CELoss: 0.7180, DKDLoss: 0.4380, 
2022-07-30 16:01:35 - train: epoch 0094, iter [01300, 05004], lr: 0.000100, loss: 1.0517, stu_CELoss: 0.6598, DKDLoss: 0.3919, 
2022-07-30 16:02:09 - train: epoch 0094, iter [01400, 05004], lr: 0.000100, loss: 0.9964, stu_CELoss: 0.6121, DKDLoss: 0.3843, 
2022-07-30 16:02:42 - train: epoch 0094, iter [01500, 05004], lr: 0.000100, loss: 1.0792, stu_CELoss: 0.7137, DKDLoss: 0.3655, 
2022-07-30 16:03:16 - train: epoch 0094, iter [01600, 05004], lr: 0.000100, loss: 1.3149, stu_CELoss: 0.8942, DKDLoss: 0.4206, 
2022-07-30 16:03:49 - train: epoch 0094, iter [01700, 05004], lr: 0.000100, loss: 1.0232, stu_CELoss: 0.6601, DKDLoss: 0.3631, 
2022-07-30 16:04:23 - train: epoch 0094, iter [01800, 05004], lr: 0.000100, loss: 1.0973, stu_CELoss: 0.7255, DKDLoss: 0.3718, 
2022-07-30 16:04:57 - train: epoch 0094, iter [01900, 05004], lr: 0.000100, loss: 1.0730, stu_CELoss: 0.6450, DKDLoss: 0.4280, 
2022-07-30 16:05:31 - train: epoch 0094, iter [02000, 05004], lr: 0.000100, loss: 0.9356, stu_CELoss: 0.5424, DKDLoss: 0.3932, 
2022-07-30 16:06:04 - train: epoch 0094, iter [02100, 05004], lr: 0.000100, loss: 0.9731, stu_CELoss: 0.6233, DKDLoss: 0.3497, 
2022-07-30 16:06:38 - train: epoch 0094, iter [02200, 05004], lr: 0.000100, loss: 0.9788, stu_CELoss: 0.5904, DKDLoss: 0.3884, 
2022-07-30 16:07:11 - train: epoch 0094, iter [02300, 05004], lr: 0.000100, loss: 1.0023, stu_CELoss: 0.5947, DKDLoss: 0.4076, 
2022-07-30 16:07:45 - train: epoch 0094, iter [02400, 05004], lr: 0.000100, loss: 1.0515, stu_CELoss: 0.7153, DKDLoss: 0.3362, 
2022-07-30 16:08:19 - train: epoch 0094, iter [02500, 05004], lr: 0.000100, loss: 1.0735, stu_CELoss: 0.6930, DKDLoss: 0.3805, 
2022-07-30 16:08:52 - train: epoch 0094, iter [02600, 05004], lr: 0.000100, loss: 1.0264, stu_CELoss: 0.6279, DKDLoss: 0.3985, 
2022-07-30 16:09:27 - train: epoch 0094, iter [02700, 05004], lr: 0.000100, loss: 1.1041, stu_CELoss: 0.6357, DKDLoss: 0.4684, 
2022-07-30 16:10:00 - train: epoch 0094, iter [02800, 05004], lr: 0.000100, loss: 1.0734, stu_CELoss: 0.7240, DKDLoss: 0.3494, 
2022-07-30 16:10:34 - train: epoch 0094, iter [02900, 05004], lr: 0.000100, loss: 1.0009, stu_CELoss: 0.5668, DKDLoss: 0.4342, 
2022-07-30 16:11:08 - train: epoch 0094, iter [03000, 05004], lr: 0.000100, loss: 1.0789, stu_CELoss: 0.6776, DKDLoss: 0.4013, 
2022-07-30 16:11:41 - train: epoch 0094, iter [03100, 05004], lr: 0.000100, loss: 1.1060, stu_CELoss: 0.7264, DKDLoss: 0.3796, 
2022-07-30 16:12:15 - train: epoch 0094, iter [03200, 05004], lr: 0.000100, loss: 1.0685, stu_CELoss: 0.6531, DKDLoss: 0.4154, 
2022-07-30 16:12:49 - train: epoch 0094, iter [03300, 05004], lr: 0.000100, loss: 1.2157, stu_CELoss: 0.8327, DKDLoss: 0.3830, 
2022-07-30 16:13:22 - train: epoch 0094, iter [03400, 05004], lr: 0.000100, loss: 1.0741, stu_CELoss: 0.6565, DKDLoss: 0.4176, 
2022-07-30 16:13:56 - train: epoch 0094, iter [03500, 05004], lr: 0.000100, loss: 1.2117, stu_CELoss: 0.7789, DKDLoss: 0.4328, 
2022-07-30 16:14:30 - train: epoch 0094, iter [03600, 05004], lr: 0.000100, loss: 1.0632, stu_CELoss: 0.7006, DKDLoss: 0.3626, 
2022-07-30 16:15:03 - train: epoch 0094, iter [03700, 05004], lr: 0.000100, loss: 1.1154, stu_CELoss: 0.7257, DKDLoss: 0.3897, 
2022-07-30 16:15:36 - train: epoch 0094, iter [03800, 05004], lr: 0.000100, loss: 0.9429, stu_CELoss: 0.5665, DKDLoss: 0.3764, 
2022-07-30 16:16:10 - train: epoch 0094, iter [03900, 05004], lr: 0.000100, loss: 0.9492, stu_CELoss: 0.6213, DKDLoss: 0.3280, 
2022-07-30 16:16:44 - train: epoch 0094, iter [04000, 05004], lr: 0.000100, loss: 1.1652, stu_CELoss: 0.7293, DKDLoss: 0.4359, 
2022-07-30 16:17:17 - train: epoch 0094, iter [04100, 05004], lr: 0.000100, loss: 1.3511, stu_CELoss: 0.9672, DKDLoss: 0.3839, 
2022-07-30 16:17:51 - train: epoch 0094, iter [04200, 05004], lr: 0.000100, loss: 1.0608, stu_CELoss: 0.7039, DKDLoss: 0.3568, 
2022-07-30 16:18:25 - train: epoch 0094, iter [04300, 05004], lr: 0.000100, loss: 1.1214, stu_CELoss: 0.7629, DKDLoss: 0.3586, 
2022-07-30 16:18:59 - train: epoch 0094, iter [04400, 05004], lr: 0.000100, loss: 1.1045, stu_CELoss: 0.7172, DKDLoss: 0.3872, 
2022-07-30 16:19:33 - train: epoch 0094, iter [04500, 05004], lr: 0.000100, loss: 0.9966, stu_CELoss: 0.6328, DKDLoss: 0.3638, 
2022-07-30 16:20:06 - train: epoch 0094, iter [04600, 05004], lr: 0.000100, loss: 1.0610, stu_CELoss: 0.6801, DKDLoss: 0.3809, 
2022-07-30 16:20:40 - train: epoch 0094, iter [04700, 05004], lr: 0.000100, loss: 1.2020, stu_CELoss: 0.7872, DKDLoss: 0.4148, 
2022-07-30 16:21:13 - train: epoch 0094, iter [04800, 05004], lr: 0.000100, loss: 0.9254, stu_CELoss: 0.5435, DKDLoss: 0.3820, 
2022-07-30 16:21:47 - train: epoch 0094, iter [04900, 05004], lr: 0.000100, loss: 1.2754, stu_CELoss: 0.9173, DKDLoss: 0.3582, 
2022-07-30 16:22:20 - train: epoch 0094, iter [05000, 05004], lr: 0.000100, loss: 1.1587, stu_CELoss: 0.7695, DKDLoss: 0.3892, 
2022-07-30 16:22:22 - train: epoch 094, train_loss: 1.1001
2022-07-30 16:24:54 - eval: epoch: 094, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.630%, stu_acc5: 93.538%, stu_test_loss: 0.8914
2022-07-30 16:24:55 - until epoch: 094, tea_best_acc1: 78.068%, stu_best_acc1: 77.630%
2022-07-30 16:24:55 - epoch 095 lr: 0.000100
2022-07-30 16:25:36 - train: epoch 0095, iter [00100, 05004], lr: 0.000100, loss: 1.2528, stu_CELoss: 0.8135, DKDLoss: 0.4393, 
2022-07-30 16:26:09 - train: epoch 0095, iter [00200, 05004], lr: 0.000100, loss: 1.1304, stu_CELoss: 0.7232, DKDLoss: 0.4073, 
2022-07-30 16:26:42 - train: epoch 0095, iter [00300, 05004], lr: 0.000100, loss: 1.0769, stu_CELoss: 0.6966, DKDLoss: 0.3803, 
2022-07-30 16:27:15 - train: epoch 0095, iter [00400, 05004], lr: 0.000100, loss: 1.0508, stu_CELoss: 0.6474, DKDLoss: 0.4033, 
2022-07-30 16:27:49 - train: epoch 0095, iter [00500, 05004], lr: 0.000100, loss: 1.1037, stu_CELoss: 0.6587, DKDLoss: 0.4450, 
2022-07-30 16:28:22 - train: epoch 0095, iter [00600, 05004], lr: 0.000100, loss: 1.2165, stu_CELoss: 0.7665, DKDLoss: 0.4500, 
2022-07-30 16:28:56 - train: epoch 0095, iter [00700, 05004], lr: 0.000100, loss: 1.1713, stu_CELoss: 0.7493, DKDLoss: 0.4219, 
2022-07-30 16:29:30 - train: epoch 0095, iter [00800, 05004], lr: 0.000100, loss: 1.2647, stu_CELoss: 0.8586, DKDLoss: 0.4061, 
2022-07-30 16:30:04 - train: epoch 0095, iter [00900, 05004], lr: 0.000100, loss: 1.1869, stu_CELoss: 0.8199, DKDLoss: 0.3669, 
2022-07-30 16:30:37 - train: epoch 0095, iter [01000, 05004], lr: 0.000100, loss: 1.1007, stu_CELoss: 0.6629, DKDLoss: 0.4378, 
2022-07-30 16:31:10 - train: epoch 0095, iter [01100, 05004], lr: 0.000100, loss: 0.9665, stu_CELoss: 0.6028, DKDLoss: 0.3637, 
2022-07-30 16:31:44 - train: epoch 0095, iter [01200, 05004], lr: 0.000100, loss: 1.1854, stu_CELoss: 0.7808, DKDLoss: 0.4046, 
2022-07-30 16:32:18 - train: epoch 0095, iter [01300, 05004], lr: 0.000100, loss: 1.1693, stu_CELoss: 0.7400, DKDLoss: 0.4292, 
2022-07-30 16:32:51 - train: epoch 0095, iter [01400, 05004], lr: 0.000100, loss: 0.9580, stu_CELoss: 0.5883, DKDLoss: 0.3697, 
2022-07-30 16:33:25 - train: epoch 0095, iter [01500, 05004], lr: 0.000100, loss: 1.0778, stu_CELoss: 0.6955, DKDLoss: 0.3823, 
2022-07-30 16:33:59 - train: epoch 0095, iter [01600, 05004], lr: 0.000100, loss: 0.8765, stu_CELoss: 0.5026, DKDLoss: 0.3739, 
2022-07-30 16:34:33 - train: epoch 0095, iter [01700, 05004], lr: 0.000100, loss: 1.1459, stu_CELoss: 0.7571, DKDLoss: 0.3888, 
2022-07-30 16:35:07 - train: epoch 0095, iter [01800, 05004], lr: 0.000100, loss: 1.0987, stu_CELoss: 0.7072, DKDLoss: 0.3915, 
2022-07-30 16:35:41 - train: epoch 0095, iter [01900, 05004], lr: 0.000100, loss: 1.0982, stu_CELoss: 0.7087, DKDLoss: 0.3895, 
2022-07-30 16:36:15 - train: epoch 0095, iter [02000, 05004], lr: 0.000100, loss: 1.2653, stu_CELoss: 0.8666, DKDLoss: 0.3987, 
2022-07-30 16:36:48 - train: epoch 0095, iter [02100, 05004], lr: 0.000100, loss: 1.0482, stu_CELoss: 0.6518, DKDLoss: 0.3964, 
2022-07-30 16:37:22 - train: epoch 0095, iter [02200, 05004], lr: 0.000100, loss: 0.9706, stu_CELoss: 0.6199, DKDLoss: 0.3507, 
2022-07-30 16:37:56 - train: epoch 0095, iter [02300, 05004], lr: 0.000100, loss: 1.0163, stu_CELoss: 0.6376, DKDLoss: 0.3787, 
2022-07-30 16:38:29 - train: epoch 0095, iter [02400, 05004], lr: 0.000100, loss: 1.0849, stu_CELoss: 0.7025, DKDLoss: 0.3824, 
2022-07-30 16:39:02 - train: epoch 0095, iter [02500, 05004], lr: 0.000100, loss: 1.0348, stu_CELoss: 0.6349, DKDLoss: 0.3998, 
2022-07-30 16:39:35 - train: epoch 0095, iter [02600, 05004], lr: 0.000100, loss: 1.1316, stu_CELoss: 0.7727, DKDLoss: 0.3589, 
2022-07-30 16:40:07 - train: epoch 0095, iter [02700, 05004], lr: 0.000100, loss: 1.1937, stu_CELoss: 0.7539, DKDLoss: 0.4398, 
2022-07-30 16:40:40 - train: epoch 0095, iter [02800, 05004], lr: 0.000100, loss: 0.9415, stu_CELoss: 0.5807, DKDLoss: 0.3608, 
2022-07-30 16:41:13 - train: epoch 0095, iter [02900, 05004], lr: 0.000100, loss: 1.1364, stu_CELoss: 0.7498, DKDLoss: 0.3866, 
2022-07-30 16:41:46 - train: epoch 0095, iter [03000, 05004], lr: 0.000100, loss: 1.2182, stu_CELoss: 0.7966, DKDLoss: 0.4216, 
2022-07-30 16:42:19 - train: epoch 0095, iter [03100, 05004], lr: 0.000100, loss: 1.0925, stu_CELoss: 0.6917, DKDLoss: 0.4008, 
2022-07-30 16:42:52 - train: epoch 0095, iter [03200, 05004], lr: 0.000100, loss: 0.9586, stu_CELoss: 0.5819, DKDLoss: 0.3767, 
2022-07-30 16:43:24 - train: epoch 0095, iter [03300, 05004], lr: 0.000100, loss: 1.0533, stu_CELoss: 0.6405, DKDLoss: 0.4128, 
2022-07-30 16:43:58 - train: epoch 0095, iter [03400, 05004], lr: 0.000100, loss: 1.0271, stu_CELoss: 0.6652, DKDLoss: 0.3619, 
2022-07-30 16:44:31 - train: epoch 0095, iter [03500, 05004], lr: 0.000100, loss: 1.2082, stu_CELoss: 0.8634, DKDLoss: 0.3449, 
2022-07-30 16:45:03 - train: epoch 0095, iter [03600, 05004], lr: 0.000100, loss: 0.9573, stu_CELoss: 0.5950, DKDLoss: 0.3623, 
2022-07-30 16:45:36 - train: epoch 0095, iter [03700, 05004], lr: 0.000100, loss: 1.0071, stu_CELoss: 0.6196, DKDLoss: 0.3876, 
2022-07-30 16:46:09 - train: epoch 0095, iter [03800, 05004], lr: 0.000100, loss: 1.0847, stu_CELoss: 0.7322, DKDLoss: 0.3525, 
2022-07-30 16:46:42 - train: epoch 0095, iter [03900, 05004], lr: 0.000100, loss: 1.1140, stu_CELoss: 0.7054, DKDLoss: 0.4086, 
2022-07-30 16:47:15 - train: epoch 0095, iter [04000, 05004], lr: 0.000100, loss: 1.1017, stu_CELoss: 0.7166, DKDLoss: 0.3851, 
2022-07-30 16:47:48 - train: epoch 0095, iter [04100, 05004], lr: 0.000100, loss: 1.0527, stu_CELoss: 0.6353, DKDLoss: 0.4174, 
2022-07-30 16:48:21 - train: epoch 0095, iter [04200, 05004], lr: 0.000100, loss: 0.9721, stu_CELoss: 0.6113, DKDLoss: 0.3608, 
2022-07-30 16:48:54 - train: epoch 0095, iter [04300, 05004], lr: 0.000100, loss: 1.0997, stu_CELoss: 0.7385, DKDLoss: 0.3612, 
2022-07-30 16:49:27 - train: epoch 0095, iter [04400, 05004], lr: 0.000100, loss: 1.3083, stu_CELoss: 0.8951, DKDLoss: 0.4132, 
2022-07-30 16:50:00 - train: epoch 0095, iter [04500, 05004], lr: 0.000100, loss: 0.9793, stu_CELoss: 0.5864, DKDLoss: 0.3929, 
2022-07-30 16:50:32 - train: epoch 0095, iter [04600, 05004], lr: 0.000100, loss: 1.0931, stu_CELoss: 0.6898, DKDLoss: 0.4033, 
2022-07-30 16:51:05 - train: epoch 0095, iter [04700, 05004], lr: 0.000100, loss: 0.9723, stu_CELoss: 0.5794, DKDLoss: 0.3929, 
2022-07-30 16:51:38 - train: epoch 0095, iter [04800, 05004], lr: 0.000100, loss: 1.1303, stu_CELoss: 0.7441, DKDLoss: 0.3862, 
2022-07-30 16:52:10 - train: epoch 0095, iter [04900, 05004], lr: 0.000100, loss: 0.9502, stu_CELoss: 0.5958, DKDLoss: 0.3544, 
2022-07-30 16:52:43 - train: epoch 0095, iter [05000, 05004], lr: 0.000100, loss: 1.1343, stu_CELoss: 0.7453, DKDLoss: 0.3890, 
2022-07-30 16:52:44 - train: epoch 095, train_loss: 1.0986
2022-07-30 16:55:14 - eval: epoch: 095, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.566%, stu_acc5: 93.586%, stu_test_loss: 0.8915
2022-07-30 16:55:15 - until epoch: 095, tea_best_acc1: 78.068%, stu_best_acc1: 77.630%
2022-07-30 16:55:15 - epoch 096 lr: 0.000100
2022-07-30 16:55:54 - train: epoch 0096, iter [00100, 05004], lr: 0.000100, loss: 1.0681, stu_CELoss: 0.6812, DKDLoss: 0.3869, 
2022-07-30 16:56:27 - train: epoch 0096, iter [00200, 05004], lr: 0.000100, loss: 0.9767, stu_CELoss: 0.5772, DKDLoss: 0.3994, 
2022-07-30 16:56:59 - train: epoch 0096, iter [00300, 05004], lr: 0.000100, loss: 1.1218, stu_CELoss: 0.7476, DKDLoss: 0.3742, 
2022-07-30 16:57:32 - train: epoch 0096, iter [00400, 05004], lr: 0.000100, loss: 0.9847, stu_CELoss: 0.5989, DKDLoss: 0.3858, 
2022-07-30 16:58:05 - train: epoch 0096, iter [00500, 05004], lr: 0.000100, loss: 1.0894, stu_CELoss: 0.6492, DKDLoss: 0.4403, 
2022-07-30 16:58:38 - train: epoch 0096, iter [00600, 05004], lr: 0.000100, loss: 1.1131, stu_CELoss: 0.7372, DKDLoss: 0.3758, 
2022-07-30 16:59:11 - train: epoch 0096, iter [00700, 05004], lr: 0.000100, loss: 1.0278, stu_CELoss: 0.6433, DKDLoss: 0.3845, 
2022-07-30 16:59:44 - train: epoch 0096, iter [00800, 05004], lr: 0.000100, loss: 1.0975, stu_CELoss: 0.7042, DKDLoss: 0.3933, 
2022-07-30 17:00:16 - train: epoch 0096, iter [00900, 05004], lr: 0.000100, loss: 1.1893, stu_CELoss: 0.7476, DKDLoss: 0.4417, 
2022-07-30 17:00:49 - train: epoch 0096, iter [01000, 05004], lr: 0.000100, loss: 1.1377, stu_CELoss: 0.7487, DKDLoss: 0.3890, 
2022-07-30 17:01:21 - train: epoch 0096, iter [01100, 05004], lr: 0.000100, loss: 1.0288, stu_CELoss: 0.6470, DKDLoss: 0.3818, 
2022-07-30 17:01:54 - train: epoch 0096, iter [01200, 05004], lr: 0.000100, loss: 1.0744, stu_CELoss: 0.6567, DKDLoss: 0.4176, 
2022-07-30 17:02:27 - train: epoch 0096, iter [01300, 05004], lr: 0.000100, loss: 1.1049, stu_CELoss: 0.7336, DKDLoss: 0.3713, 
2022-07-30 17:02:59 - train: epoch 0096, iter [01400, 05004], lr: 0.000100, loss: 1.2215, stu_CELoss: 0.8303, DKDLoss: 0.3912, 
2022-07-30 17:03:31 - train: epoch 0096, iter [01500, 05004], lr: 0.000100, loss: 0.9964, stu_CELoss: 0.6058, DKDLoss: 0.3906, 
2022-07-30 17:04:04 - train: epoch 0096, iter [01600, 05004], lr: 0.000100, loss: 0.9339, stu_CELoss: 0.5382, DKDLoss: 0.3957, 
2022-07-30 17:04:36 - train: epoch 0096, iter [01700, 05004], lr: 0.000100, loss: 0.9747, stu_CELoss: 0.5791, DKDLoss: 0.3956, 
2022-07-30 17:05:09 - train: epoch 0096, iter [01800, 05004], lr: 0.000100, loss: 1.3581, stu_CELoss: 0.9513, DKDLoss: 0.4068, 
2022-07-30 17:05:42 - train: epoch 0096, iter [01900, 05004], lr: 0.000100, loss: 1.0885, stu_CELoss: 0.7169, DKDLoss: 0.3716, 
2022-07-30 17:06:14 - train: epoch 0096, iter [02000, 05004], lr: 0.000100, loss: 0.9862, stu_CELoss: 0.6129, DKDLoss: 0.3733, 
2022-07-30 17:06:47 - train: epoch 0096, iter [02100, 05004], lr: 0.000100, loss: 1.1254, stu_CELoss: 0.7939, DKDLoss: 0.3315, 
2022-07-30 17:07:20 - train: epoch 0096, iter [02200, 05004], lr: 0.000100, loss: 1.0279, stu_CELoss: 0.6454, DKDLoss: 0.3825, 
2022-07-30 17:07:52 - train: epoch 0096, iter [02300, 05004], lr: 0.000100, loss: 1.2226, stu_CELoss: 0.8411, DKDLoss: 0.3815, 
2022-07-30 17:08:25 - train: epoch 0096, iter [02400, 05004], lr: 0.000100, loss: 0.9899, stu_CELoss: 0.5896, DKDLoss: 0.4003, 
2022-07-30 17:08:58 - train: epoch 0096, iter [02500, 05004], lr: 0.000100, loss: 1.0604, stu_CELoss: 0.6530, DKDLoss: 0.4074, 
2022-07-30 17:09:31 - train: epoch 0096, iter [02600, 05004], lr: 0.000100, loss: 1.0093, stu_CELoss: 0.6074, DKDLoss: 0.4018, 
2022-07-30 17:10:03 - train: epoch 0096, iter [02700, 05004], lr: 0.000100, loss: 1.2341, stu_CELoss: 0.7832, DKDLoss: 0.4509, 
2022-07-30 17:10:36 - train: epoch 0096, iter [02800, 05004], lr: 0.000100, loss: 1.2338, stu_CELoss: 0.8417, DKDLoss: 0.3921, 
2022-07-30 17:11:09 - train: epoch 0096, iter [02900, 05004], lr: 0.000100, loss: 1.1818, stu_CELoss: 0.7316, DKDLoss: 0.4501, 
2022-07-30 17:11:42 - train: epoch 0096, iter [03000, 05004], lr: 0.000100, loss: 1.2591, stu_CELoss: 0.8579, DKDLoss: 0.4013, 
2022-07-30 17:12:15 - train: epoch 0096, iter [03100, 05004], lr: 0.000100, loss: 1.1682, stu_CELoss: 0.8255, DKDLoss: 0.3427, 
2022-07-30 17:12:48 - train: epoch 0096, iter [03200, 05004], lr: 0.000100, loss: 1.1464, stu_CELoss: 0.7198, DKDLoss: 0.4265, 
2022-07-30 17:13:21 - train: epoch 0096, iter [03300, 05004], lr: 0.000100, loss: 1.2280, stu_CELoss: 0.8029, DKDLoss: 0.4252, 
2022-07-30 17:13:53 - train: epoch 0096, iter [03400, 05004], lr: 0.000100, loss: 1.0560, stu_CELoss: 0.6804, DKDLoss: 0.3756, 
2022-07-30 17:14:26 - train: epoch 0096, iter [03500, 05004], lr: 0.000100, loss: 0.8867, stu_CELoss: 0.5692, DKDLoss: 0.3175, 
2022-07-30 17:14:59 - train: epoch 0096, iter [03600, 05004], lr: 0.000100, loss: 0.9375, stu_CELoss: 0.5480, DKDLoss: 0.3894, 
2022-07-30 17:15:32 - train: epoch 0096, iter [03700, 05004], lr: 0.000100, loss: 1.1594, stu_CELoss: 0.7512, DKDLoss: 0.4082, 
2022-07-30 17:16:05 - train: epoch 0096, iter [03800, 05004], lr: 0.000100, loss: 1.1291, stu_CELoss: 0.7203, DKDLoss: 0.4088, 
2022-07-30 17:16:37 - train: epoch 0096, iter [03900, 05004], lr: 0.000100, loss: 0.9748, stu_CELoss: 0.5917, DKDLoss: 0.3831, 
2022-07-30 17:17:10 - train: epoch 0096, iter [04000, 05004], lr: 0.000100, loss: 1.1101, stu_CELoss: 0.6981, DKDLoss: 0.4119, 
2022-07-30 17:17:43 - train: epoch 0096, iter [04100, 05004], lr: 0.000100, loss: 0.9644, stu_CELoss: 0.6156, DKDLoss: 0.3488, 
2022-07-30 17:18:16 - train: epoch 0096, iter [04200, 05004], lr: 0.000100, loss: 1.1007, stu_CELoss: 0.7150, DKDLoss: 0.3857, 
2022-07-30 17:18:49 - train: epoch 0096, iter [04300, 05004], lr: 0.000100, loss: 0.9146, stu_CELoss: 0.5572, DKDLoss: 0.3574, 
2022-07-30 17:19:22 - train: epoch 0096, iter [04400, 05004], lr: 0.000100, loss: 0.9793, stu_CELoss: 0.6153, DKDLoss: 0.3640, 
2022-07-30 17:19:55 - train: epoch 0096, iter [04500, 05004], lr: 0.000100, loss: 1.1596, stu_CELoss: 0.7586, DKDLoss: 0.4010, 
2022-07-30 17:20:28 - train: epoch 0096, iter [04600, 05004], lr: 0.000100, loss: 0.9993, stu_CELoss: 0.6284, DKDLoss: 0.3709, 
2022-07-30 17:21:01 - train: epoch 0096, iter [04700, 05004], lr: 0.000100, loss: 1.1331, stu_CELoss: 0.7219, DKDLoss: 0.4112, 
2022-07-30 17:21:33 - train: epoch 0096, iter [04800, 05004], lr: 0.000100, loss: 1.1122, stu_CELoss: 0.7523, DKDLoss: 0.3599, 
2022-07-30 17:22:06 - train: epoch 0096, iter [04900, 05004], lr: 0.000100, loss: 1.1446, stu_CELoss: 0.7204, DKDLoss: 0.4242, 
2022-07-30 17:22:39 - train: epoch 0096, iter [05000, 05004], lr: 0.000100, loss: 1.1135, stu_CELoss: 0.6991, DKDLoss: 0.4144, 
2022-07-30 17:22:40 - train: epoch 096, train_loss: 1.0964
2022-07-30 17:25:11 - eval: epoch: 096, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.572%, stu_acc5: 93.570%, stu_test_loss: 0.8917
2022-07-30 17:25:11 - until epoch: 096, tea_best_acc1: 78.068%, stu_best_acc1: 77.630%
2022-07-30 17:25:11 - epoch 097 lr: 0.000100
2022-07-30 17:25:51 - train: epoch 0097, iter [00100, 05004], lr: 0.000100, loss: 1.0675, stu_CELoss: 0.6348, DKDLoss: 0.4327, 
2022-07-30 17:26:24 - train: epoch 0097, iter [00200, 05004], lr: 0.000100, loss: 1.0463, stu_CELoss: 0.6234, DKDLoss: 0.4229, 
2022-07-30 17:26:57 - train: epoch 0097, iter [00300, 05004], lr: 0.000100, loss: 1.4122, stu_CELoss: 0.9572, DKDLoss: 0.4550, 
2022-07-30 17:27:30 - train: epoch 0097, iter [00400, 05004], lr: 0.000100, loss: 1.0977, stu_CELoss: 0.7106, DKDLoss: 0.3871, 
2022-07-30 17:28:03 - train: epoch 0097, iter [00500, 05004], lr: 0.000100, loss: 1.2138, stu_CELoss: 0.7965, DKDLoss: 0.4173, 
2022-07-30 17:28:36 - train: epoch 0097, iter [00600, 05004], lr: 0.000100, loss: 1.0014, stu_CELoss: 0.6248, DKDLoss: 0.3766, 
2022-07-30 17:29:08 - train: epoch 0097, iter [00700, 05004], lr: 0.000100, loss: 0.9730, stu_CELoss: 0.5837, DKDLoss: 0.3893, 
2022-07-30 17:29:41 - train: epoch 0097, iter [00800, 05004], lr: 0.000100, loss: 0.9398, stu_CELoss: 0.5583, DKDLoss: 0.3815, 
2022-07-30 17:30:14 - train: epoch 0097, iter [00900, 05004], lr: 0.000100, loss: 0.9652, stu_CELoss: 0.5891, DKDLoss: 0.3761, 
2022-07-30 17:30:47 - train: epoch 0097, iter [01000, 05004], lr: 0.000100, loss: 1.1846, stu_CELoss: 0.7730, DKDLoss: 0.4116, 
2022-07-30 17:31:20 - train: epoch 0097, iter [01100, 05004], lr: 0.000100, loss: 0.9078, stu_CELoss: 0.6111, DKDLoss: 0.2968, 
2022-07-30 17:31:53 - train: epoch 0097, iter [01200, 05004], lr: 0.000100, loss: 1.0650, stu_CELoss: 0.6870, DKDLoss: 0.3780, 
2022-07-30 17:32:26 - train: epoch 0097, iter [01300, 05004], lr: 0.000100, loss: 0.9737, stu_CELoss: 0.5802, DKDLoss: 0.3935, 
2022-07-30 17:32:59 - train: epoch 0097, iter [01400, 05004], lr: 0.000100, loss: 1.2065, stu_CELoss: 0.8417, DKDLoss: 0.3648, 
2022-07-30 17:33:31 - train: epoch 0097, iter [01500, 05004], lr: 0.000100, loss: 1.0819, stu_CELoss: 0.6671, DKDLoss: 0.4148, 
2022-07-30 17:34:04 - train: epoch 0097, iter [01600, 05004], lr: 0.000100, loss: 1.0745, stu_CELoss: 0.6410, DKDLoss: 0.4335, 
2022-07-30 17:34:37 - train: epoch 0097, iter [01700, 05004], lr: 0.000100, loss: 1.0529, stu_CELoss: 0.6704, DKDLoss: 0.3825, 
2022-07-30 17:35:10 - train: epoch 0097, iter [01800, 05004], lr: 0.000100, loss: 1.1717, stu_CELoss: 0.7657, DKDLoss: 0.4060, 
2022-07-30 17:35:43 - train: epoch 0097, iter [01900, 05004], lr: 0.000100, loss: 1.0476, stu_CELoss: 0.6681, DKDLoss: 0.3794, 
2022-07-30 17:36:16 - train: epoch 0097, iter [02000, 05004], lr: 0.000100, loss: 1.0816, stu_CELoss: 0.6883, DKDLoss: 0.3933, 
2022-07-30 17:36:48 - train: epoch 0097, iter [02100, 05004], lr: 0.000100, loss: 1.0489, stu_CELoss: 0.6643, DKDLoss: 0.3846, 
2022-07-30 17:37:20 - train: epoch 0097, iter [02200, 05004], lr: 0.000100, loss: 1.1748, stu_CELoss: 0.8021, DKDLoss: 0.3727, 
2022-07-30 17:37:53 - train: epoch 0097, iter [02300, 05004], lr: 0.000100, loss: 1.2324, stu_CELoss: 0.8137, DKDLoss: 0.4187, 
2022-07-30 17:38:26 - train: epoch 0097, iter [02400, 05004], lr: 0.000100, loss: 1.0232, stu_CELoss: 0.6306, DKDLoss: 0.3926, 
2022-07-30 17:38:59 - train: epoch 0097, iter [02500, 05004], lr: 0.000100, loss: 1.0981, stu_CELoss: 0.7321, DKDLoss: 0.3660, 
2022-07-30 17:39:31 - train: epoch 0097, iter [02600, 05004], lr: 0.000100, loss: 1.1236, stu_CELoss: 0.7071, DKDLoss: 0.4165, 
2022-07-30 17:40:04 - train: epoch 0097, iter [02700, 05004], lr: 0.000100, loss: 1.0196, stu_CELoss: 0.6653, DKDLoss: 0.3543, 
2022-07-30 17:40:37 - train: epoch 0097, iter [02800, 05004], lr: 0.000100, loss: 1.0401, stu_CELoss: 0.6660, DKDLoss: 0.3741, 
2022-07-30 17:41:10 - train: epoch 0097, iter [02900, 05004], lr: 0.000100, loss: 1.0434, stu_CELoss: 0.6546, DKDLoss: 0.3888, 
2022-07-30 17:41:43 - train: epoch 0097, iter [03000, 05004], lr: 0.000100, loss: 1.1979, stu_CELoss: 0.7718, DKDLoss: 0.4260, 
2022-07-30 17:42:16 - train: epoch 0097, iter [03100, 05004], lr: 0.000100, loss: 1.1296, stu_CELoss: 0.7291, DKDLoss: 0.4005, 
2022-07-30 17:42:48 - train: epoch 0097, iter [03200, 05004], lr: 0.000100, loss: 1.2872, stu_CELoss: 0.8711, DKDLoss: 0.4162, 
2022-07-30 17:43:21 - train: epoch 0097, iter [03300, 05004], lr: 0.000100, loss: 1.0707, stu_CELoss: 0.6716, DKDLoss: 0.3991, 
2022-07-30 17:43:54 - train: epoch 0097, iter [03400, 05004], lr: 0.000100, loss: 1.2026, stu_CELoss: 0.8447, DKDLoss: 0.3579, 
2022-07-30 17:44:27 - train: epoch 0097, iter [03500, 05004], lr: 0.000100, loss: 1.1926, stu_CELoss: 0.8056, DKDLoss: 0.3870, 
2022-07-30 17:44:59 - train: epoch 0097, iter [03600, 05004], lr: 0.000100, loss: 0.9775, stu_CELoss: 0.5738, DKDLoss: 0.4036, 
2022-07-30 17:45:32 - train: epoch 0097, iter [03700, 05004], lr: 0.000100, loss: 0.9085, stu_CELoss: 0.5486, DKDLoss: 0.3600, 
2022-07-30 17:46:05 - train: epoch 0097, iter [03800, 05004], lr: 0.000100, loss: 1.0270, stu_CELoss: 0.6285, DKDLoss: 0.3985, 
2022-07-30 17:46:37 - train: epoch 0097, iter [03900, 05004], lr: 0.000100, loss: 1.1598, stu_CELoss: 0.7442, DKDLoss: 0.4156, 
2022-07-30 17:47:10 - train: epoch 0097, iter [04000, 05004], lr: 0.000100, loss: 1.0181, stu_CELoss: 0.6550, DKDLoss: 0.3631, 
2022-07-30 17:47:43 - train: epoch 0097, iter [04100, 05004], lr: 0.000100, loss: 0.9631, stu_CELoss: 0.5814, DKDLoss: 0.3817, 
2022-07-30 17:48:16 - train: epoch 0097, iter [04200, 05004], lr: 0.000100, loss: 1.0220, stu_CELoss: 0.6589, DKDLoss: 0.3632, 
2022-07-30 17:48:49 - train: epoch 0097, iter [04300, 05004], lr: 0.000100, loss: 1.0100, stu_CELoss: 0.6093, DKDLoss: 0.4008, 
2022-07-30 17:49:21 - train: epoch 0097, iter [04400, 05004], lr: 0.000100, loss: 1.0922, stu_CELoss: 0.7114, DKDLoss: 0.3808, 
2022-07-30 17:49:54 - train: epoch 0097, iter [04500, 05004], lr: 0.000100, loss: 1.0523, stu_CELoss: 0.6516, DKDLoss: 0.4008, 
2022-07-30 17:50:26 - train: epoch 0097, iter [04600, 05004], lr: 0.000100, loss: 1.1314, stu_CELoss: 0.7275, DKDLoss: 0.4039, 
2022-07-30 17:50:59 - train: epoch 0097, iter [04700, 05004], lr: 0.000100, loss: 1.0917, stu_CELoss: 0.6784, DKDLoss: 0.4132, 
2022-07-30 17:51:32 - train: epoch 0097, iter [04800, 05004], lr: 0.000100, loss: 0.9089, stu_CELoss: 0.5625, DKDLoss: 0.3463, 
2022-07-30 17:52:05 - train: epoch 0097, iter [04900, 05004], lr: 0.000100, loss: 1.2508, stu_CELoss: 0.7870, DKDLoss: 0.4638, 
2022-07-30 17:52:37 - train: epoch 0097, iter [05000, 05004], lr: 0.000100, loss: 0.9934, stu_CELoss: 0.6398, DKDLoss: 0.3536, 
2022-07-30 17:52:39 - train: epoch 097, train_loss: 1.0938
2022-07-30 17:55:08 - eval: epoch: 097, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.576%, stu_acc5: 93.568%, stu_test_loss: 0.8897
2022-07-30 17:55:08 - until epoch: 097, tea_best_acc1: 78.068%, stu_best_acc1: 77.630%
2022-07-30 17:55:08 - epoch 098 lr: 0.000100
2022-07-30 17:55:48 - train: epoch 0098, iter [00100, 05004], lr: 0.000100, loss: 1.1535, stu_CELoss: 0.7366, DKDLoss: 0.4169, 
2022-07-30 17:56:20 - train: epoch 0098, iter [00200, 05004], lr: 0.000100, loss: 1.1803, stu_CELoss: 0.7475, DKDLoss: 0.4328, 
2022-07-30 17:56:53 - train: epoch 0098, iter [00300, 05004], lr: 0.000100, loss: 1.1185, stu_CELoss: 0.6850, DKDLoss: 0.4334, 
2022-07-30 17:57:26 - train: epoch 0098, iter [00400, 05004], lr: 0.000100, loss: 1.1262, stu_CELoss: 0.7314, DKDLoss: 0.3948, 
2022-07-30 17:57:58 - train: epoch 0098, iter [00500, 05004], lr: 0.000100, loss: 1.0459, stu_CELoss: 0.6851, DKDLoss: 0.3608, 
2022-07-30 17:58:31 - train: epoch 0098, iter [00600, 05004], lr: 0.000100, loss: 1.0176, stu_CELoss: 0.6535, DKDLoss: 0.3641, 
2022-07-30 17:59:04 - train: epoch 0098, iter [00700, 05004], lr: 0.000100, loss: 0.9646, stu_CELoss: 0.5666, DKDLoss: 0.3980, 
2022-07-30 17:59:36 - train: epoch 0098, iter [00800, 05004], lr: 0.000100, loss: 1.2368, stu_CELoss: 0.8220, DKDLoss: 0.4149, 
2022-07-30 18:00:09 - train: epoch 0098, iter [00900, 05004], lr: 0.000100, loss: 1.1972, stu_CELoss: 0.7651, DKDLoss: 0.4321, 
2022-07-30 18:00:42 - train: epoch 0098, iter [01000, 05004], lr: 0.000100, loss: 1.0317, stu_CELoss: 0.6378, DKDLoss: 0.3939, 
2022-07-30 18:01:15 - train: epoch 0098, iter [01100, 05004], lr: 0.000100, loss: 1.0765, stu_CELoss: 0.7042, DKDLoss: 0.3724, 
2022-07-30 18:01:48 - train: epoch 0098, iter [01200, 05004], lr: 0.000100, loss: 1.0514, stu_CELoss: 0.6295, DKDLoss: 0.4219, 
2022-07-30 18:02:21 - train: epoch 0098, iter [01300, 05004], lr: 0.000100, loss: 1.0756, stu_CELoss: 0.6691, DKDLoss: 0.4066, 
2022-07-30 18:02:54 - train: epoch 0098, iter [01400, 05004], lr: 0.000100, loss: 1.3084, stu_CELoss: 0.8840, DKDLoss: 0.4244, 
2022-07-30 18:03:26 - train: epoch 0098, iter [01500, 05004], lr: 0.000100, loss: 1.1459, stu_CELoss: 0.7633, DKDLoss: 0.3826, 
2022-07-30 18:03:59 - train: epoch 0098, iter [01600, 05004], lr: 0.000100, loss: 1.1433, stu_CELoss: 0.7370, DKDLoss: 0.4063, 
2022-07-30 18:04:32 - train: epoch 0098, iter [01700, 05004], lr: 0.000100, loss: 1.0279, stu_CELoss: 0.6777, DKDLoss: 0.3502, 
2022-07-30 18:05:05 - train: epoch 0098, iter [01800, 05004], lr: 0.000100, loss: 1.0703, stu_CELoss: 0.6955, DKDLoss: 0.3749, 
2022-07-30 18:05:38 - train: epoch 0098, iter [01900, 05004], lr: 0.000100, loss: 0.9373, stu_CELoss: 0.5756, DKDLoss: 0.3617, 
2022-07-30 18:06:11 - train: epoch 0098, iter [02000, 05004], lr: 0.000100, loss: 1.1030, stu_CELoss: 0.7076, DKDLoss: 0.3954, 
2022-07-30 18:06:44 - train: epoch 0098, iter [02100, 05004], lr: 0.000100, loss: 1.1495, stu_CELoss: 0.7797, DKDLoss: 0.3698, 
2022-07-30 18:07:17 - train: epoch 0098, iter [02200, 05004], lr: 0.000100, loss: 1.0209, stu_CELoss: 0.6387, DKDLoss: 0.3822, 
2022-07-30 18:07:49 - train: epoch 0098, iter [02300, 05004], lr: 0.000100, loss: 1.0746, stu_CELoss: 0.6848, DKDLoss: 0.3898, 
2022-07-30 18:08:22 - train: epoch 0098, iter [02400, 05004], lr: 0.000100, loss: 1.0047, stu_CELoss: 0.6481, DKDLoss: 0.3566, 
2022-07-30 18:08:55 - train: epoch 0098, iter [02500, 05004], lr: 0.000100, loss: 1.1912, stu_CELoss: 0.7655, DKDLoss: 0.4258, 
2022-07-30 18:09:28 - train: epoch 0098, iter [02600, 05004], lr: 0.000100, loss: 1.1319, stu_CELoss: 0.7320, DKDLoss: 0.3999, 
2022-07-30 18:10:01 - train: epoch 0098, iter [02700, 05004], lr: 0.000100, loss: 1.2270, stu_CELoss: 0.7972, DKDLoss: 0.4298, 
2022-07-30 18:10:34 - train: epoch 0098, iter [02800, 05004], lr: 0.000100, loss: 1.1929, stu_CELoss: 0.7802, DKDLoss: 0.4127, 
2022-07-30 18:11:07 - train: epoch 0098, iter [02900, 05004], lr: 0.000100, loss: 1.0946, stu_CELoss: 0.6779, DKDLoss: 0.4166, 
2022-07-30 18:11:40 - train: epoch 0098, iter [03000, 05004], lr: 0.000100, loss: 1.0471, stu_CELoss: 0.6939, DKDLoss: 0.3531, 
2022-07-30 18:12:13 - train: epoch 0098, iter [03100, 05004], lr: 0.000100, loss: 1.1458, stu_CELoss: 0.6813, DKDLoss: 0.4645, 
2022-07-30 18:12:46 - train: epoch 0098, iter [03200, 05004], lr: 0.000100, loss: 1.0268, stu_CELoss: 0.6614, DKDLoss: 0.3654, 
2022-07-30 18:13:18 - train: epoch 0098, iter [03300, 05004], lr: 0.000100, loss: 1.0470, stu_CELoss: 0.6779, DKDLoss: 0.3691, 
2022-07-30 18:13:51 - train: epoch 0098, iter [03400, 05004], lr: 0.000100, loss: 1.2843, stu_CELoss: 0.8361, DKDLoss: 0.4482, 
2022-07-30 18:14:24 - train: epoch 0098, iter [03500, 05004], lr: 0.000100, loss: 1.1240, stu_CELoss: 0.7285, DKDLoss: 0.3956, 
2022-07-30 18:14:57 - train: epoch 0098, iter [03600, 05004], lr: 0.000100, loss: 1.3227, stu_CELoss: 0.9778, DKDLoss: 0.3449, 
2022-07-30 18:15:30 - train: epoch 0098, iter [03700, 05004], lr: 0.000100, loss: 1.1707, stu_CELoss: 0.7178, DKDLoss: 0.4529, 
2022-07-30 18:16:03 - train: epoch 0098, iter [03800, 05004], lr: 0.000100, loss: 1.0863, stu_CELoss: 0.6956, DKDLoss: 0.3907, 
2022-07-30 18:16:36 - train: epoch 0098, iter [03900, 05004], lr: 0.000100, loss: 1.1390, stu_CELoss: 0.7251, DKDLoss: 0.4139, 
2022-07-30 18:17:09 - train: epoch 0098, iter [04000, 05004], lr: 0.000100, loss: 1.2346, stu_CELoss: 0.8387, DKDLoss: 0.3959, 
2022-07-30 18:17:42 - train: epoch 0098, iter [04100, 05004], lr: 0.000100, loss: 1.0450, stu_CELoss: 0.6295, DKDLoss: 0.4155, 
2022-07-30 18:18:15 - train: epoch 0098, iter [04200, 05004], lr: 0.000100, loss: 1.0830, stu_CELoss: 0.6781, DKDLoss: 0.4049, 
2022-07-30 18:18:48 - train: epoch 0098, iter [04300, 05004], lr: 0.000100, loss: 1.1263, stu_CELoss: 0.7279, DKDLoss: 0.3984, 
2022-07-30 18:19:21 - train: epoch 0098, iter [04400, 05004], lr: 0.000100, loss: 1.1555, stu_CELoss: 0.7260, DKDLoss: 0.4294, 
2022-07-30 18:19:54 - train: epoch 0098, iter [04500, 05004], lr: 0.000100, loss: 1.1746, stu_CELoss: 0.7781, DKDLoss: 0.3965, 
2022-07-30 18:20:27 - train: epoch 0098, iter [04600, 05004], lr: 0.000100, loss: 1.0983, stu_CELoss: 0.7089, DKDLoss: 0.3894, 
2022-07-30 18:21:00 - train: epoch 0098, iter [04700, 05004], lr: 0.000100, loss: 1.1329, stu_CELoss: 0.7089, DKDLoss: 0.4240, 
2022-07-30 18:21:33 - train: epoch 0098, iter [04800, 05004], lr: 0.000100, loss: 0.9772, stu_CELoss: 0.6399, DKDLoss: 0.3373, 
2022-07-30 18:22:06 - train: epoch 0098, iter [04900, 05004], lr: 0.000100, loss: 0.9899, stu_CELoss: 0.6054, DKDLoss: 0.3846, 
2022-07-30 18:22:38 - train: epoch 0098, iter [05000, 05004], lr: 0.000100, loss: 1.1859, stu_CELoss: 0.7965, DKDLoss: 0.3894, 
2022-07-30 18:22:40 - train: epoch 098, train_loss: 1.0942
2022-07-30 18:25:10 - eval: epoch: 098, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.614%, stu_acc5: 93.550%, stu_test_loss: 0.8907
2022-07-30 18:25:11 - until epoch: 098, tea_best_acc1: 78.068%, stu_best_acc1: 77.630%
2022-07-30 18:25:11 - epoch 099 lr: 0.000100
2022-07-30 18:25:50 - train: epoch 0099, iter [00100, 05004], lr: 0.000100, loss: 1.1704, stu_CELoss: 0.7585, DKDLoss: 0.4119, 
2022-07-30 18:26:22 - train: epoch 0099, iter [00200, 05004], lr: 0.000100, loss: 1.0863, stu_CELoss: 0.7037, DKDLoss: 0.3826, 
2022-07-30 18:26:54 - train: epoch 0099, iter [00300, 05004], lr: 0.000100, loss: 0.9881, stu_CELoss: 0.6198, DKDLoss: 0.3684, 
2022-07-30 18:27:26 - train: epoch 0099, iter [00400, 05004], lr: 0.000100, loss: 1.0744, stu_CELoss: 0.7051, DKDLoss: 0.3693, 
2022-07-30 18:27:59 - train: epoch 0099, iter [00500, 05004], lr: 0.000100, loss: 1.1334, stu_CELoss: 0.7085, DKDLoss: 0.4249, 
2022-07-30 18:28:31 - train: epoch 0099, iter [00600, 05004], lr: 0.000100, loss: 1.1269, stu_CELoss: 0.7356, DKDLoss: 0.3913, 
2022-07-30 18:29:03 - train: epoch 0099, iter [00700, 05004], lr: 0.000100, loss: 1.1975, stu_CELoss: 0.8031, DKDLoss: 0.3944, 
2022-07-30 18:29:35 - train: epoch 0099, iter [00800, 05004], lr: 0.000100, loss: 0.9460, stu_CELoss: 0.6061, DKDLoss: 0.3399, 
2022-07-30 18:30:08 - train: epoch 0099, iter [00900, 05004], lr: 0.000100, loss: 0.9624, stu_CELoss: 0.6280, DKDLoss: 0.3344, 
2022-07-30 18:30:40 - train: epoch 0099, iter [01000, 05004], lr: 0.000100, loss: 1.1925, stu_CELoss: 0.7875, DKDLoss: 0.4050, 
2022-07-30 18:31:13 - train: epoch 0099, iter [01100, 05004], lr: 0.000100, loss: 1.2096, stu_CELoss: 0.7692, DKDLoss: 0.4404, 
2022-07-30 18:31:46 - train: epoch 0099, iter [01200, 05004], lr: 0.000100, loss: 1.0575, stu_CELoss: 0.6936, DKDLoss: 0.3639, 
2022-07-30 18:32:19 - train: epoch 0099, iter [01300, 05004], lr: 0.000100, loss: 1.0543, stu_CELoss: 0.6399, DKDLoss: 0.4144, 
2022-07-30 18:32:52 - train: epoch 0099, iter [01400, 05004], lr: 0.000100, loss: 1.0741, stu_CELoss: 0.6859, DKDLoss: 0.3882, 
2022-07-30 18:33:24 - train: epoch 0099, iter [01500, 05004], lr: 0.000100, loss: 1.0208, stu_CELoss: 0.6134, DKDLoss: 0.4074, 
2022-07-30 18:33:57 - train: epoch 0099, iter [01600, 05004], lr: 0.000100, loss: 1.2170, stu_CELoss: 0.8194, DKDLoss: 0.3975, 
2022-07-30 18:34:29 - train: epoch 0099, iter [01700, 05004], lr: 0.000100, loss: 1.2879, stu_CELoss: 0.8442, DKDLoss: 0.4437, 
2022-07-30 18:35:02 - train: epoch 0099, iter [01800, 05004], lr: 0.000100, loss: 1.0238, stu_CELoss: 0.6484, DKDLoss: 0.3754, 
2022-07-30 18:35:35 - train: epoch 0099, iter [01900, 05004], lr: 0.000100, loss: 1.1104, stu_CELoss: 0.7471, DKDLoss: 0.3633, 
2022-07-30 18:36:08 - train: epoch 0099, iter [02000, 05004], lr: 0.000100, loss: 1.1124, stu_CELoss: 0.7221, DKDLoss: 0.3903, 
2022-07-30 18:36:41 - train: epoch 0099, iter [02100, 05004], lr: 0.000100, loss: 1.1944, stu_CELoss: 0.7680, DKDLoss: 0.4264, 
2022-07-30 18:37:14 - train: epoch 0099, iter [02200, 05004], lr: 0.000100, loss: 1.1233, stu_CELoss: 0.7887, DKDLoss: 0.3346, 
2022-07-30 18:37:46 - train: epoch 0099, iter [02300, 05004], lr: 0.000100, loss: 1.0714, stu_CELoss: 0.7401, DKDLoss: 0.3313, 
2022-07-30 18:38:19 - train: epoch 0099, iter [02400, 05004], lr: 0.000100, loss: 1.1929, stu_CELoss: 0.7816, DKDLoss: 0.4113, 
2022-07-30 18:38:52 - train: epoch 0099, iter [02500, 05004], lr: 0.000100, loss: 1.1344, stu_CELoss: 0.7483, DKDLoss: 0.3862, 
2022-07-30 18:39:25 - train: epoch 0099, iter [02600, 05004], lr: 0.000100, loss: 1.1435, stu_CELoss: 0.7580, DKDLoss: 0.3856, 
2022-07-30 18:39:58 - train: epoch 0099, iter [02700, 05004], lr: 0.000100, loss: 1.1523, stu_CELoss: 0.7490, DKDLoss: 0.4033, 
2022-07-30 18:40:31 - train: epoch 0099, iter [02800, 05004], lr: 0.000100, loss: 1.3253, stu_CELoss: 0.8939, DKDLoss: 0.4314, 
2022-07-30 18:41:04 - train: epoch 0099, iter [02900, 05004], lr: 0.000100, loss: 0.9901, stu_CELoss: 0.5748, DKDLoss: 0.4153, 
2022-07-30 18:41:36 - train: epoch 0099, iter [03000, 05004], lr: 0.000100, loss: 1.0390, stu_CELoss: 0.6509, DKDLoss: 0.3880, 
2022-07-30 18:42:09 - train: epoch 0099, iter [03100, 05004], lr: 0.000100, loss: 0.8883, stu_CELoss: 0.5175, DKDLoss: 0.3708, 
2022-07-30 18:42:42 - train: epoch 0099, iter [03200, 05004], lr: 0.000100, loss: 1.1482, stu_CELoss: 0.7108, DKDLoss: 0.4374, 
2022-07-30 18:43:15 - train: epoch 0099, iter [03300, 05004], lr: 0.000100, loss: 0.9012, stu_CELoss: 0.5351, DKDLoss: 0.3661, 
2022-07-30 18:43:48 - train: epoch 0099, iter [03400, 05004], lr: 0.000100, loss: 1.0314, stu_CELoss: 0.6881, DKDLoss: 0.3433, 
2022-07-30 18:44:21 - train: epoch 0099, iter [03500, 05004], lr: 0.000100, loss: 1.0916, stu_CELoss: 0.7178, DKDLoss: 0.3738, 
2022-07-30 18:44:54 - train: epoch 0099, iter [03600, 05004], lr: 0.000100, loss: 1.1105, stu_CELoss: 0.7305, DKDLoss: 0.3801, 
2022-07-30 18:45:27 - train: epoch 0099, iter [03700, 05004], lr: 0.000100, loss: 1.0286, stu_CELoss: 0.6241, DKDLoss: 0.4045, 
2022-07-30 18:45:59 - train: epoch 0099, iter [03800, 05004], lr: 0.000100, loss: 1.1936, stu_CELoss: 0.8534, DKDLoss: 0.3402, 
2022-07-30 18:46:32 - train: epoch 0099, iter [03900, 05004], lr: 0.000100, loss: 1.0231, stu_CELoss: 0.6709, DKDLoss: 0.3522, 
2022-07-30 18:47:05 - train: epoch 0099, iter [04000, 05004], lr: 0.000100, loss: 1.1203, stu_CELoss: 0.6418, DKDLoss: 0.4785, 
2022-07-30 18:47:38 - train: epoch 0099, iter [04100, 05004], lr: 0.000100, loss: 1.0519, stu_CELoss: 0.6442, DKDLoss: 0.4077, 
2022-07-30 18:48:10 - train: epoch 0099, iter [04200, 05004], lr: 0.000100, loss: 1.1516, stu_CELoss: 0.7146, DKDLoss: 0.4370, 
2022-07-30 18:48:43 - train: epoch 0099, iter [04300, 05004], lr: 0.000100, loss: 1.2171, stu_CELoss: 0.8342, DKDLoss: 0.3829, 
2022-07-30 18:49:16 - train: epoch 0099, iter [04400, 05004], lr: 0.000100, loss: 1.0998, stu_CELoss: 0.6977, DKDLoss: 0.4022, 
2022-07-30 18:49:49 - train: epoch 0099, iter [04500, 05004], lr: 0.000100, loss: 1.1317, stu_CELoss: 0.7325, DKDLoss: 0.3992, 
2022-07-30 18:50:22 - train: epoch 0099, iter [04600, 05004], lr: 0.000100, loss: 1.2957, stu_CELoss: 0.8920, DKDLoss: 0.4037, 
2022-07-30 18:50:55 - train: epoch 0099, iter [04700, 05004], lr: 0.000100, loss: 1.1431, stu_CELoss: 0.7477, DKDLoss: 0.3955, 
2022-07-30 18:51:28 - train: epoch 0099, iter [04800, 05004], lr: 0.000100, loss: 1.1247, stu_CELoss: 0.6920, DKDLoss: 0.4327, 
2022-07-30 18:52:01 - train: epoch 0099, iter [04900, 05004], lr: 0.000100, loss: 1.2109, stu_CELoss: 0.8087, DKDLoss: 0.4022, 
2022-07-30 18:52:34 - train: epoch 0099, iter [05000, 05004], lr: 0.000100, loss: 1.2042, stu_CELoss: 0.7921, DKDLoss: 0.4122, 
2022-07-30 18:52:35 - train: epoch 099, train_loss: 1.0915
2022-07-30 18:55:04 - eval: epoch: 099, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.564%, stu_acc5: 93.542%, stu_test_loss: 0.8904
2022-07-30 18:55:05 - until epoch: 099, tea_best_acc1: 78.068%, stu_best_acc1: 77.630%
2022-07-30 18:55:05 - epoch 100 lr: 0.000100
2022-07-30 18:55:45 - train: epoch 0100, iter [00100, 05004], lr: 0.000100, loss: 1.0027, stu_CELoss: 0.6331, DKDLoss: 0.3697, 
2022-07-30 18:56:17 - train: epoch 0100, iter [00200, 05004], lr: 0.000100, loss: 1.2842, stu_CELoss: 0.8868, DKDLoss: 0.3974, 
2022-07-30 18:56:50 - train: epoch 0100, iter [00300, 05004], lr: 0.000100, loss: 1.1275, stu_CELoss: 0.7398, DKDLoss: 0.3878, 
2022-07-30 18:57:23 - train: epoch 0100, iter [00400, 05004], lr: 0.000100, loss: 1.0244, stu_CELoss: 0.6304, DKDLoss: 0.3940, 
2022-07-30 18:57:56 - train: epoch 0100, iter [00500, 05004], lr: 0.000100, loss: 1.2026, stu_CELoss: 0.8020, DKDLoss: 0.4006, 
2022-07-30 18:58:29 - train: epoch 0100, iter [00600, 05004], lr: 0.000100, loss: 1.0357, stu_CELoss: 0.6426, DKDLoss: 0.3930, 
2022-07-30 18:59:03 - train: epoch 0100, iter [00700, 05004], lr: 0.000100, loss: 1.1389, stu_CELoss: 0.7656, DKDLoss: 0.3733, 
2022-07-30 18:59:36 - train: epoch 0100, iter [00800, 05004], lr: 0.000100, loss: 1.0543, stu_CELoss: 0.6721, DKDLoss: 0.3823, 
2022-07-30 19:00:09 - train: epoch 0100, iter [00900, 05004], lr: 0.000100, loss: 0.9361, stu_CELoss: 0.5455, DKDLoss: 0.3906, 
2022-07-30 19:00:42 - train: epoch 0100, iter [01000, 05004], lr: 0.000100, loss: 1.2350, stu_CELoss: 0.8447, DKDLoss: 0.3902, 
2022-07-30 19:01:15 - train: epoch 0100, iter [01100, 05004], lr: 0.000100, loss: 0.9124, stu_CELoss: 0.5644, DKDLoss: 0.3480, 
2022-07-30 19:01:49 - train: epoch 0100, iter [01200, 05004], lr: 0.000100, loss: 1.0459, stu_CELoss: 0.6135, DKDLoss: 0.4324, 
2022-07-30 19:02:22 - train: epoch 0100, iter [01300, 05004], lr: 0.000100, loss: 1.0127, stu_CELoss: 0.6205, DKDLoss: 0.3922, 
2022-07-30 19:02:55 - train: epoch 0100, iter [01400, 05004], lr: 0.000100, loss: 1.0855, stu_CELoss: 0.6762, DKDLoss: 0.4093, 
2022-07-30 19:03:29 - train: epoch 0100, iter [01500, 05004], lr: 0.000100, loss: 1.0701, stu_CELoss: 0.7102, DKDLoss: 0.3599, 
2022-07-30 19:04:02 - train: epoch 0100, iter [01600, 05004], lr: 0.000100, loss: 1.0413, stu_CELoss: 0.6494, DKDLoss: 0.3920, 
2022-07-30 19:04:35 - train: epoch 0100, iter [01700, 05004], lr: 0.000100, loss: 1.1021, stu_CELoss: 0.6857, DKDLoss: 0.4163, 
2022-07-30 19:05:09 - train: epoch 0100, iter [01800, 05004], lr: 0.000100, loss: 1.1092, stu_CELoss: 0.6800, DKDLoss: 0.4292, 
2022-07-30 19:05:42 - train: epoch 0100, iter [01900, 05004], lr: 0.000100, loss: 1.0029, stu_CELoss: 0.6227, DKDLoss: 0.3802, 
2022-07-30 19:06:15 - train: epoch 0100, iter [02000, 05004], lr: 0.000100, loss: 1.0647, stu_CELoss: 0.6396, DKDLoss: 0.4251, 
2022-07-30 19:06:49 - train: epoch 0100, iter [02100, 05004], lr: 0.000100, loss: 1.0188, stu_CELoss: 0.6104, DKDLoss: 0.4084, 
2022-07-30 19:07:22 - train: epoch 0100, iter [02200, 05004], lr: 0.000100, loss: 1.1425, stu_CELoss: 0.7232, DKDLoss: 0.4192, 
2022-07-30 19:07:55 - train: epoch 0100, iter [02300, 05004], lr: 0.000100, loss: 1.0911, stu_CELoss: 0.7010, DKDLoss: 0.3901, 
2022-07-30 19:08:29 - train: epoch 0100, iter [02400, 05004], lr: 0.000100, loss: 1.0379, stu_CELoss: 0.6601, DKDLoss: 0.3778, 
2022-07-30 19:09:02 - train: epoch 0100, iter [02500, 05004], lr: 0.000100, loss: 1.0726, stu_CELoss: 0.6525, DKDLoss: 0.4201, 
2022-07-30 19:09:35 - train: epoch 0100, iter [02600, 05004], lr: 0.000100, loss: 1.0347, stu_CELoss: 0.6734, DKDLoss: 0.3613, 
2022-07-30 19:10:09 - train: epoch 0100, iter [02700, 05004], lr: 0.000100, loss: 0.9176, stu_CELoss: 0.5591, DKDLoss: 0.3585, 
2022-07-30 19:10:42 - train: epoch 0100, iter [02800, 05004], lr: 0.000100, loss: 1.1087, stu_CELoss: 0.6862, DKDLoss: 0.4225, 
2022-07-30 19:11:16 - train: epoch 0100, iter [02900, 05004], lr: 0.000100, loss: 1.0604, stu_CELoss: 0.6280, DKDLoss: 0.4324, 
2022-07-30 19:11:49 - train: epoch 0100, iter [03000, 05004], lr: 0.000100, loss: 1.0440, stu_CELoss: 0.6400, DKDLoss: 0.4040, 
2022-07-30 19:12:23 - train: epoch 0100, iter [03100, 05004], lr: 0.000100, loss: 0.9408, stu_CELoss: 0.5937, DKDLoss: 0.3471, 
2022-07-30 19:12:56 - train: epoch 0100, iter [03200, 05004], lr: 0.000100, loss: 1.1267, stu_CELoss: 0.7103, DKDLoss: 0.4164, 
2022-07-30 19:13:29 - train: epoch 0100, iter [03300, 05004], lr: 0.000100, loss: 1.1222, stu_CELoss: 0.7018, DKDLoss: 0.4205, 
2022-07-30 19:14:02 - train: epoch 0100, iter [03400, 05004], lr: 0.000100, loss: 1.0343, stu_CELoss: 0.6511, DKDLoss: 0.3833, 
2022-07-30 19:14:36 - train: epoch 0100, iter [03500, 05004], lr: 0.000100, loss: 0.9032, stu_CELoss: 0.5375, DKDLoss: 0.3657, 
2022-07-30 19:15:09 - train: epoch 0100, iter [03600, 05004], lr: 0.000100, loss: 0.9842, stu_CELoss: 0.6266, DKDLoss: 0.3575, 
2022-07-30 19:15:42 - train: epoch 0100, iter [03700, 05004], lr: 0.000100, loss: 1.1190, stu_CELoss: 0.7225, DKDLoss: 0.3964, 
2022-07-30 19:16:15 - train: epoch 0100, iter [03800, 05004], lr: 0.000100, loss: 1.0422, stu_CELoss: 0.7092, DKDLoss: 0.3331, 
2022-07-30 19:16:49 - train: epoch 0100, iter [03900, 05004], lr: 0.000100, loss: 1.2373, stu_CELoss: 0.8360, DKDLoss: 0.4013, 
2022-07-30 19:17:22 - train: epoch 0100, iter [04000, 05004], lr: 0.000100, loss: 1.0921, stu_CELoss: 0.6576, DKDLoss: 0.4345, 
2022-07-30 19:17:55 - train: epoch 0100, iter [04100, 05004], lr: 0.000100, loss: 1.0181, stu_CELoss: 0.6425, DKDLoss: 0.3756, 
2022-07-30 19:18:28 - train: epoch 0100, iter [04200, 05004], lr: 0.000100, loss: 1.1106, stu_CELoss: 0.6868, DKDLoss: 0.4238, 
2022-07-30 19:19:02 - train: epoch 0100, iter [04300, 05004], lr: 0.000100, loss: 1.0136, stu_CELoss: 0.6037, DKDLoss: 0.4099, 
2022-07-30 19:19:35 - train: epoch 0100, iter [04400, 05004], lr: 0.000100, loss: 1.1206, stu_CELoss: 0.7236, DKDLoss: 0.3970, 
2022-07-30 19:20:09 - train: epoch 0100, iter [04500, 05004], lr: 0.000100, loss: 0.9148, stu_CELoss: 0.5276, DKDLoss: 0.3872, 
2022-07-30 19:20:42 - train: epoch 0100, iter [04600, 05004], lr: 0.000100, loss: 0.9853, stu_CELoss: 0.6231, DKDLoss: 0.3622, 
2022-07-30 19:21:16 - train: epoch 0100, iter [04700, 05004], lr: 0.000100, loss: 1.1256, stu_CELoss: 0.6734, DKDLoss: 0.4523, 
2022-07-30 19:21:49 - train: epoch 0100, iter [04800, 05004], lr: 0.000100, loss: 0.9040, stu_CELoss: 0.5320, DKDLoss: 0.3719, 
2022-07-30 19:22:22 - train: epoch 0100, iter [04900, 05004], lr: 0.000100, loss: 1.2046, stu_CELoss: 0.8253, DKDLoss: 0.3793, 
2022-07-30 19:22:55 - train: epoch 0100, iter [05000, 05004], lr: 0.000100, loss: 1.2362, stu_CELoss: 0.8264, DKDLoss: 0.4098, 
2022-07-30 19:22:57 - train: epoch 100, train_loss: 1.0899
2022-07-30 19:25:26 - eval: epoch: 100, tea_acc1: 78.068%, tea_acc5: 93.862%, tea_test_loss: 0.9036, stu_acc1: 77.614%, stu_acc5: 93.536%, stu_test_loss: 0.8910
2022-07-30 19:25:27 - until epoch: 100, tea_best_acc1: 78.068%, stu_best_acc1: 77.630%
2022-07-30 19:25:27 - train done. train time: 51.240 hours, tea_best_acc1: 78.068%, stu_best_acc1: 77.630%
