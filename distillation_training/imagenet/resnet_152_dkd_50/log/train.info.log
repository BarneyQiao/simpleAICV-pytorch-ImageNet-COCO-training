2022-05-03 10:09:36 - train: epoch 0080, iter [01500, 05004], lr: 0.001000, loss: 1.2591, stu_CELoss: 0.8151 DKDLoss: 0.4440 
2022-05-03 10:10:10 - train: epoch 0080, iter [01600, 05004], lr: 0.001000, loss: 1.2703, stu_CELoss: 0.8067 DKDLoss: 0.4636 
2022-05-03 10:10:43 - train: epoch 0080, iter [01700, 05004], lr: 0.001000, loss: 1.5827, stu_CELoss: 1.0993 DKDLoss: 0.4834 
2022-05-03 10:11:17 - train: epoch 0080, iter [01800, 05004], lr: 0.001000, loss: 1.2565, stu_CELoss: 0.8238 DKDLoss: 0.4326 
2022-05-03 10:11:51 - train: epoch 0080, iter [01900, 05004], lr: 0.001000, loss: 1.4545, stu_CELoss: 0.9804 DKDLoss: 0.4741 
2022-05-03 10:12:25 - train: epoch 0080, iter [02000, 05004], lr: 0.001000, loss: 1.2491, stu_CELoss: 0.8425 DKDLoss: 0.4066 
2022-05-03 10:12:59 - train: epoch 0080, iter [02100, 05004], lr: 0.001000, loss: 1.4228, stu_CELoss: 0.9759 DKDLoss: 0.4469 
2022-05-03 10:13:33 - train: epoch 0080, iter [02200, 05004], lr: 0.001000, loss: 1.1950, stu_CELoss: 0.7131 DKDLoss: 0.4819 
2022-05-03 10:14:06 - train: epoch 0080, iter [02300, 05004], lr: 0.001000, loss: 1.2786, stu_CELoss: 0.8408 DKDLoss: 0.4378 
2022-05-03 10:14:40 - train: epoch 0080, iter [02400, 05004], lr: 0.001000, loss: 1.4895, stu_CELoss: 1.0193 DKDLoss: 0.4701 
2022-05-03 10:15:14 - train: epoch 0080, iter [02500, 05004], lr: 0.001000, loss: 1.3205, stu_CELoss: 0.8845 DKDLoss: 0.4360 
2022-05-03 10:15:48 - train: epoch 0080, iter [02600, 05004], lr: 0.001000, loss: 1.2753, stu_CELoss: 0.8550 DKDLoss: 0.4203 
2022-05-03 10:16:22 - train: epoch 0080, iter [02700, 05004], lr: 0.001000, loss: 1.2512, stu_CELoss: 0.7824 DKDLoss: 0.4688 
2022-05-03 10:16:55 - train: epoch 0080, iter [02800, 05004], lr: 0.001000, loss: 1.3113, stu_CELoss: 0.8594 DKDLoss: 0.4519 
2022-05-03 10:17:29 - train: epoch 0080, iter [02900, 05004], lr: 0.001000, loss: 1.2990, stu_CELoss: 0.8706 DKDLoss: 0.4284 
2022-05-03 10:18:03 - train: epoch 0080, iter [03000, 05004], lr: 0.001000, loss: 1.2705, stu_CELoss: 0.7739 DKDLoss: 0.4965 
2022-05-03 10:18:36 - train: epoch 0080, iter [03100, 05004], lr: 0.001000, loss: 1.2069, stu_CELoss: 0.7385 DKDLoss: 0.4684 
2022-05-03 10:19:10 - train: epoch 0080, iter [03200, 05004], lr: 0.001000, loss: 1.0993, stu_CELoss: 0.6939 DKDLoss: 0.4054 
2022-05-03 10:19:44 - train: epoch 0080, iter [03300, 05004], lr: 0.001000, loss: 1.3275, stu_CELoss: 0.9412 DKDLoss: 0.3863 
2022-05-03 10:20:17 - train: epoch 0080, iter [03400, 05004], lr: 0.001000, loss: 1.3663, stu_CELoss: 0.9370 DKDLoss: 0.4293 
2022-05-03 10:20:51 - train: epoch 0080, iter [03500, 05004], lr: 0.001000, loss: 1.2144, stu_CELoss: 0.7810 DKDLoss: 0.4334 
2022-05-03 10:21:25 - train: epoch 0080, iter [03600, 05004], lr: 0.001000, loss: 1.2907, stu_CELoss: 0.8332 DKDLoss: 0.4574 
2022-05-03 10:21:59 - train: epoch 0080, iter [03700, 05004], lr: 0.001000, loss: 1.2648, stu_CELoss: 0.7935 DKDLoss: 0.4713 
2022-05-03 10:22:33 - train: epoch 0080, iter [03800, 05004], lr: 0.001000, loss: 1.3279, stu_CELoss: 0.8972 DKDLoss: 0.4306 
2022-05-03 10:23:07 - train: epoch 0080, iter [03900, 05004], lr: 0.001000, loss: 1.2766, stu_CELoss: 0.8083 DKDLoss: 0.4684 
2022-05-03 10:23:41 - train: epoch 0080, iter [04000, 05004], lr: 0.001000, loss: 1.4299, stu_CELoss: 0.9719 DKDLoss: 0.4581 
2022-05-03 10:24:14 - train: epoch 0080, iter [04100, 05004], lr: 0.001000, loss: 1.3895, stu_CELoss: 0.9328 DKDLoss: 0.4567 
2022-05-03 10:24:48 - train: epoch 0080, iter [04200, 05004], lr: 0.001000, loss: 1.2530, stu_CELoss: 0.7990 DKDLoss: 0.4540 
2022-05-03 10:25:22 - train: epoch 0080, iter [04300, 05004], lr: 0.001000, loss: 1.4396, stu_CELoss: 0.9742 DKDLoss: 0.4653 
2022-05-03 10:25:56 - train: epoch 0080, iter [04400, 05004], lr: 0.001000, loss: 1.2145, stu_CELoss: 0.7351 DKDLoss: 0.4795 
2022-05-03 10:26:30 - train: epoch 0080, iter [04500, 05004], lr: 0.001000, loss: 1.2077, stu_CELoss: 0.7657 DKDLoss: 0.4421 
2022-05-03 10:27:03 - train: epoch 0080, iter [04600, 05004], lr: 0.001000, loss: 1.3602, stu_CELoss: 0.8734 DKDLoss: 0.4868 
2022-05-03 10:27:37 - train: epoch 0080, iter [04700, 05004], lr: 0.001000, loss: 1.3112, stu_CELoss: 0.8517 DKDLoss: 0.4594 
2022-05-03 10:28:11 - train: epoch 0080, iter [04800, 05004], lr: 0.001000, loss: 1.3594, stu_CELoss: 0.9329 DKDLoss: 0.4264 
2022-05-03 10:28:45 - train: epoch 0080, iter [04900, 05004], lr: 0.001000, loss: 1.4216, stu_CELoss: 0.9678 DKDLoss: 0.4537 
2022-05-03 10:29:19 - train: epoch 0080, iter [05000, 05004], lr: 0.001000, loss: 1.2240, stu_CELoss: 0.7849 DKDLoss: 0.4391 
2022-05-03 10:29:21 - train: epoch 080, train_loss: 1.3094
2022-05-03 10:31:52 - eval: epoch: 080, tea_acc1: 78.330%, tea_acc5: 94.064%, tea_test_loss: 0.8657, stu_acc1: 77.238%, stu_acc5: 93.582%, stu_test_loss: 0.8984
2022-05-03 10:31:53 - until epoch: 080, tea_best_acc1: 78.330%, stu_best_acc1: 77.238%
2022-05-03 10:31:53 - epoch 081 lr: 0.0010000000000000002
2022-05-03 10:32:32 - train: epoch 0081, iter [00100, 05004], lr: 0.001000, loss: 1.1726, stu_CELoss: 0.7473 DKDLoss: 0.4253 
2022-05-03 10:33:06 - train: epoch 0081, iter [00200, 05004], lr: 0.001000, loss: 1.2225, stu_CELoss: 0.7693 DKDLoss: 0.4531 
2022-05-03 10:33:39 - train: epoch 0081, iter [00300, 05004], lr: 0.001000, loss: 1.2153, stu_CELoss: 0.7799 DKDLoss: 0.4354 
2022-05-03 10:34:12 - train: epoch 0081, iter [00400, 05004], lr: 0.001000, loss: 1.3160, stu_CELoss: 0.8635 DKDLoss: 0.4525 
2022-05-03 10:34:46 - train: epoch 0081, iter [00500, 05004], lr: 0.001000, loss: 1.5561, stu_CELoss: 1.0818 DKDLoss: 0.4742 
2022-05-03 10:35:19 - train: epoch 0081, iter [00600, 05004], lr: 0.001000, loss: 1.3096, stu_CELoss: 0.8430 DKDLoss: 0.4666 
2022-05-03 10:35:53 - train: epoch 0081, iter [00700, 05004], lr: 0.001000, loss: 1.3779, stu_CELoss: 0.9074 DKDLoss: 0.4705 
2022-05-03 10:36:27 - train: epoch 0081, iter [00800, 05004], lr: 0.001000, loss: 1.2906, stu_CELoss: 0.8537 DKDLoss: 0.4369 
2022-05-03 10:37:00 - train: epoch 0081, iter [00900, 05004], lr: 0.001000, loss: 1.3657, stu_CELoss: 0.9032 DKDLoss: 0.4625 
2022-05-03 10:37:34 - train: epoch 0081, iter [01000, 05004], lr: 0.001000, loss: 1.0994, stu_CELoss: 0.6805 DKDLoss: 0.4189 
2022-05-03 10:38:07 - train: epoch 0081, iter [01100, 05004], lr: 0.001000, loss: 1.3154, stu_CELoss: 0.8444 DKDLoss: 0.4709 
2022-05-03 10:38:41 - train: epoch 0081, iter [01200, 05004], lr: 0.001000, loss: 1.3405, stu_CELoss: 0.9286 DKDLoss: 0.4119 
2022-05-03 10:39:15 - train: epoch 0081, iter [01300, 05004], lr: 0.001000, loss: 1.2837, stu_CELoss: 0.8387 DKDLoss: 0.4450 
2022-05-03 10:39:48 - train: epoch 0081, iter [01400, 05004], lr: 0.001000, loss: 1.1152, stu_CELoss: 0.7190 DKDLoss: 0.3962 
2022-05-03 10:40:21 - train: epoch 0081, iter [01500, 05004], lr: 0.001000, loss: 1.3084, stu_CELoss: 0.8883 DKDLoss: 0.4200 
2022-05-03 10:40:55 - train: epoch 0081, iter [01600, 05004], lr: 0.001000, loss: 1.1512, stu_CELoss: 0.6913 DKDLoss: 0.4599 
2022-05-03 10:41:29 - train: epoch 0081, iter [01700, 05004], lr: 0.001000, loss: 1.2415, stu_CELoss: 0.8389 DKDLoss: 0.4026 
2022-05-03 10:42:03 - train: epoch 0081, iter [01800, 05004], lr: 0.001000, loss: 1.1906, stu_CELoss: 0.7290 DKDLoss: 0.4616 
2022-05-03 10:42:36 - train: epoch 0081, iter [01900, 05004], lr: 0.001000, loss: 1.2478, stu_CELoss: 0.8370 DKDLoss: 0.4108 
2022-05-03 10:43:10 - train: epoch 0081, iter [02000, 05004], lr: 0.001000, loss: 1.3013, stu_CELoss: 0.9059 DKDLoss: 0.3954 
2022-05-03 10:43:44 - train: epoch 0081, iter [02100, 05004], lr: 0.001000, loss: 1.4030, stu_CELoss: 0.9641 DKDLoss: 0.4388 
2022-05-03 10:44:17 - train: epoch 0081, iter [02200, 05004], lr: 0.001000, loss: 1.2453, stu_CELoss: 0.8410 DKDLoss: 0.4043 
2022-05-03 10:44:51 - train: epoch 0081, iter [02300, 05004], lr: 0.001000, loss: 1.1889, stu_CELoss: 0.7619 DKDLoss: 0.4269 
2022-05-03 10:45:25 - train: epoch 0081, iter [02400, 05004], lr: 0.001000, loss: 1.2625, stu_CELoss: 0.8464 DKDLoss: 0.4161 
2022-05-03 10:45:59 - train: epoch 0081, iter [02500, 05004], lr: 0.001000, loss: 1.4010, stu_CELoss: 0.9241 DKDLoss: 0.4769 
2022-05-03 10:46:33 - train: epoch 0081, iter [02600, 05004], lr: 0.001000, loss: 1.4335, stu_CELoss: 0.9250 DKDLoss: 0.5085 
2022-05-03 10:47:07 - train: epoch 0081, iter [02700, 05004], lr: 0.001000, loss: 1.2555, stu_CELoss: 0.8361 DKDLoss: 0.4194 
2022-05-03 10:47:41 - train: epoch 0081, iter [02800, 05004], lr: 0.001000, loss: 1.3856, stu_CELoss: 0.9162 DKDLoss: 0.4694 
2022-05-03 10:48:14 - train: epoch 0081, iter [02900, 05004], lr: 0.001000, loss: 1.3528, stu_CELoss: 0.9155 DKDLoss: 0.4373 
2022-05-03 10:48:48 - train: epoch 0081, iter [03000, 05004], lr: 0.001000, loss: 1.3128, stu_CELoss: 0.9121 DKDLoss: 0.4007 
2022-05-03 10:49:22 - train: epoch 0081, iter [03100, 05004], lr: 0.001000, loss: 1.2975, stu_CELoss: 0.8420 DKDLoss: 0.4555 
2022-05-03 10:49:56 - train: epoch 0081, iter [03200, 05004], lr: 0.001000, loss: 1.1467, stu_CELoss: 0.7381 DKDLoss: 0.4086 
2022-05-03 10:50:29 - train: epoch 0081, iter [03300, 05004], lr: 0.001000, loss: 1.5148, stu_CELoss: 1.0007 DKDLoss: 0.5141 
2022-05-03 10:51:03 - train: epoch 0081, iter [03400, 05004], lr: 0.001000, loss: 1.4267, stu_CELoss: 1.0198 DKDLoss: 0.4070 
2022-05-03 10:51:37 - train: epoch 0081, iter [03500, 05004], lr: 0.001000, loss: 1.4140, stu_CELoss: 0.9402 DKDLoss: 0.4738 
2022-05-03 10:52:11 - train: epoch 0081, iter [03600, 05004], lr: 0.001000, loss: 1.0146, stu_CELoss: 0.6076 DKDLoss: 0.4069 
2022-05-03 10:52:45 - train: epoch 0081, iter [03700, 05004], lr: 0.001000, loss: 1.4069, stu_CELoss: 0.9684 DKDLoss: 0.4384 
2022-05-03 10:53:19 - train: epoch 0081, iter [03800, 05004], lr: 0.001000, loss: 1.2320, stu_CELoss: 0.8338 DKDLoss: 0.3982 
2022-05-03 10:53:53 - train: epoch 0081, iter [03900, 05004], lr: 0.001000, loss: 1.4090, stu_CELoss: 0.9354 DKDLoss: 0.4736 
2022-05-03 10:54:27 - train: epoch 0081, iter [04000, 05004], lr: 0.001000, loss: 1.2825, stu_CELoss: 0.8061 DKDLoss: 0.4764 
2022-05-03 10:55:01 - train: epoch 0081, iter [04100, 05004], lr: 0.001000, loss: 1.2438, stu_CELoss: 0.8160 DKDLoss: 0.4278 
2022-05-03 10:55:35 - train: epoch 0081, iter [04200, 05004], lr: 0.001000, loss: 1.4459, stu_CELoss: 0.9565 DKDLoss: 0.4894 
2022-05-03 10:56:09 - train: epoch 0081, iter [04300, 05004], lr: 0.001000, loss: 1.5236, stu_CELoss: 1.0165 DKDLoss: 0.5071 
2022-05-03 10:56:43 - train: epoch 0081, iter [04400, 05004], lr: 0.001000, loss: 1.2621, stu_CELoss: 0.8048 DKDLoss: 0.4573 
2022-05-03 10:57:16 - train: epoch 0081, iter [04500, 05004], lr: 0.001000, loss: 1.2694, stu_CELoss: 0.7806 DKDLoss: 0.4889 
2022-05-03 10:57:50 - train: epoch 0081, iter [04600, 05004], lr: 0.001000, loss: 1.2357, stu_CELoss: 0.8024 DKDLoss: 0.4333 
2022-05-03 10:58:24 - train: epoch 0081, iter [04700, 05004], lr: 0.001000, loss: 1.5376, stu_CELoss: 1.1044 DKDLoss: 0.4332 
2022-05-03 10:58:58 - train: epoch 0081, iter [04800, 05004], lr: 0.001000, loss: 1.4389, stu_CELoss: 0.9983 DKDLoss: 0.4406 
2022-05-03 10:59:32 - train: epoch 0081, iter [04900, 05004], lr: 0.001000, loss: 1.0931, stu_CELoss: 0.6793 DKDLoss: 0.4138 
2022-05-03 11:00:05 - train: epoch 0081, iter [05000, 05004], lr: 0.001000, loss: 1.2794, stu_CELoss: 0.8520 DKDLoss: 0.4274 
2022-05-03 11:00:07 - train: epoch 081, train_loss: 1.3053
2022-05-03 11:02:38 - eval: epoch: 081, tea_acc1: 78.330%, tea_acc5: 94.064%, tea_test_loss: 0.8657, stu_acc1: 77.180%, stu_acc5: 93.556%, stu_test_loss: 0.8999
2022-05-03 11:02:39 - until epoch: 081, tea_best_acc1: 78.330%, stu_best_acc1: 77.238%
2022-05-03 11:02:39 - epoch 082 lr: 0.0010000000000000002
2022-05-03 11:03:19 - train: epoch 0082, iter [00100, 05004], lr: 0.001000, loss: 1.1324, stu_CELoss: 0.7313 DKDLoss: 0.4011 
2022-05-03 11:03:52 - train: epoch 0082, iter [00200, 05004], lr: 0.001000, loss: 1.3348, stu_CELoss: 0.9401 DKDLoss: 0.3947 
2022-05-03 11:04:25 - train: epoch 0082, iter [00300, 05004], lr: 0.001000, loss: 1.4353, stu_CELoss: 0.9655 DKDLoss: 0.4698 
2022-05-03 11:04:58 - train: epoch 0082, iter [00400, 05004], lr: 0.001000, loss: 1.4282, stu_CELoss: 0.9421 DKDLoss: 0.4861 
2022-05-03 11:05:32 - train: epoch 0082, iter [00500, 05004], lr: 0.001000, loss: 1.3123, stu_CELoss: 0.9062 DKDLoss: 0.4061 
2022-05-03 11:06:05 - train: epoch 0082, iter [00600, 05004], lr: 0.001000, loss: 1.2629, stu_CELoss: 0.8145 DKDLoss: 0.4484 
2022-05-03 11:06:39 - train: epoch 0082, iter [00700, 05004], lr: 0.001000, loss: 1.4579, stu_CELoss: 1.0350 DKDLoss: 0.4229 
2022-05-03 11:07:12 - train: epoch 0082, iter [00800, 05004], lr: 0.001000, loss: 1.4500, stu_CELoss: 0.9999 DKDLoss: 0.4501 
2022-05-03 11:07:46 - train: epoch 0082, iter [00900, 05004], lr: 0.001000, loss: 1.4363, stu_CELoss: 0.9293 DKDLoss: 0.5069 
2022-05-03 11:08:19 - train: epoch 0082, iter [01000, 05004], lr: 0.001000, loss: 1.2150, stu_CELoss: 0.7552 DKDLoss: 0.4598 
2022-05-03 11:08:53 - train: epoch 0082, iter [01100, 05004], lr: 0.001000, loss: 1.5507, stu_CELoss: 1.1234 DKDLoss: 0.4273 
2022-05-03 11:09:27 - train: epoch 0082, iter [01200, 05004], lr: 0.001000, loss: 1.2660, stu_CELoss: 0.8161 DKDLoss: 0.4500 
2022-05-03 11:10:00 - train: epoch 0082, iter [01300, 05004], lr: 0.001000, loss: 1.3739, stu_CELoss: 0.9228 DKDLoss: 0.4511 
2022-05-03 11:10:34 - train: epoch 0082, iter [01400, 05004], lr: 0.001000, loss: 1.4181, stu_CELoss: 0.9827 DKDLoss: 0.4354 
2022-05-03 11:11:08 - train: epoch 0082, iter [01500, 05004], lr: 0.001000, loss: 1.3670, stu_CELoss: 0.8810 DKDLoss: 0.4860 
2022-05-03 11:11:42 - train: epoch 0082, iter [01600, 05004], lr: 0.001000, loss: 1.4083, stu_CELoss: 0.9891 DKDLoss: 0.4192 
2022-05-03 11:12:16 - train: epoch 0082, iter [01700, 05004], lr: 0.001000, loss: 1.2482, stu_CELoss: 0.7991 DKDLoss: 0.4491 
2022-05-03 11:12:49 - train: epoch 0082, iter [01800, 05004], lr: 0.001000, loss: 1.0209, stu_CELoss: 0.6193 DKDLoss: 0.4016 
2022-05-03 11:13:24 - train: epoch 0082, iter [01900, 05004], lr: 0.001000, loss: 1.3380, stu_CELoss: 0.8489 DKDLoss: 0.4891 
2022-05-03 11:13:57 - train: epoch 0082, iter [02000, 05004], lr: 0.001000, loss: 1.1340, stu_CELoss: 0.7170 DKDLoss: 0.4170 
2022-05-03 11:14:31 - train: epoch 0082, iter [02100, 05004], lr: 0.001000, loss: 1.3075, stu_CELoss: 0.8890 DKDLoss: 0.4184 
2022-05-03 11:15:05 - train: epoch 0082, iter [02200, 05004], lr: 0.001000, loss: 1.4650, stu_CELoss: 0.9677 DKDLoss: 0.4973 
2022-05-03 11:15:39 - train: epoch 0082, iter [02300, 05004], lr: 0.001000, loss: 1.2492, stu_CELoss: 0.7819 DKDLoss: 0.4674 
2022-05-03 11:16:13 - train: epoch 0082, iter [02400, 05004], lr: 0.001000, loss: 1.3225, stu_CELoss: 0.8913 DKDLoss: 0.4313 
2022-05-03 11:16:47 - train: epoch 0082, iter [02500, 05004], lr: 0.001000, loss: 1.0712, stu_CELoss: 0.6478 DKDLoss: 0.4234 
2022-05-03 11:17:21 - train: epoch 0082, iter [02600, 05004], lr: 0.001000, loss: 1.1729, stu_CELoss: 0.7018 DKDLoss: 0.4711 
2022-05-03 11:17:55 - train: epoch 0082, iter [02700, 05004], lr: 0.001000, loss: 1.3490, stu_CELoss: 0.9085 DKDLoss: 0.4405 
2022-05-03 11:18:29 - train: epoch 0082, iter [02800, 05004], lr: 0.001000, loss: 1.2279, stu_CELoss: 0.8429 DKDLoss: 0.3850 
2022-05-03 11:19:03 - train: epoch 0082, iter [02900, 05004], lr: 0.001000, loss: 1.1790, stu_CELoss: 0.7674 DKDLoss: 0.4116 
2022-05-03 11:19:36 - train: epoch 0082, iter [03000, 05004], lr: 0.001000, loss: 1.4670, stu_CELoss: 0.9869 DKDLoss: 0.4802 
2022-05-03 11:20:10 - train: epoch 0082, iter [03100, 05004], lr: 0.001000, loss: 1.3279, stu_CELoss: 0.8352 DKDLoss: 0.4927 
2022-05-03 11:20:45 - train: epoch 0082, iter [03200, 05004], lr: 0.001000, loss: 1.4173, stu_CELoss: 0.9921 DKDLoss: 0.4252 
2022-05-03 11:21:18 - train: epoch 0082, iter [03300, 05004], lr: 0.001000, loss: 1.2968, stu_CELoss: 0.8714 DKDLoss: 0.4254 
2022-05-03 11:21:53 - train: epoch 0082, iter [03400, 05004], lr: 0.001000, loss: 1.2730, stu_CELoss: 0.8474 DKDLoss: 0.4256 
2022-05-03 11:22:27 - train: epoch 0082, iter [03500, 05004], lr: 0.001000, loss: 1.2603, stu_CELoss: 0.8232 DKDLoss: 0.4371 
2022-05-03 11:23:00 - train: epoch 0082, iter [03600, 05004], lr: 0.001000, loss: 1.2419, stu_CELoss: 0.8005 DKDLoss: 0.4414 
2022-05-03 11:23:35 - train: epoch 0082, iter [03700, 05004], lr: 0.001000, loss: 1.0217, stu_CELoss: 0.6478 DKDLoss: 0.3739 
2022-05-03 11:24:09 - train: epoch 0082, iter [03800, 05004], lr: 0.001000, loss: 1.3607, stu_CELoss: 0.8906 DKDLoss: 0.4701 
2022-05-03 11:24:42 - train: epoch 0082, iter [03900, 05004], lr: 0.001000, loss: 1.3202, stu_CELoss: 0.8988 DKDLoss: 0.4213 
2022-05-03 11:25:16 - train: epoch 0082, iter [04000, 05004], lr: 0.001000, loss: 1.3861, stu_CELoss: 0.9308 DKDLoss: 0.4552 
2022-05-03 11:25:50 - train: epoch 0082, iter [04100, 05004], lr: 0.001000, loss: 1.2497, stu_CELoss: 0.8183 DKDLoss: 0.4314 
2022-05-03 11:26:24 - train: epoch 0082, iter [04200, 05004], lr: 0.001000, loss: 1.4593, stu_CELoss: 1.0179 DKDLoss: 0.4414 
2022-05-03 11:26:58 - train: epoch 0082, iter [04300, 05004], lr: 0.001000, loss: 1.1414, stu_CELoss: 0.7117 DKDLoss: 0.4297 
2022-05-03 11:27:31 - train: epoch 0082, iter [04400, 05004], lr: 0.001000, loss: 1.2696, stu_CELoss: 0.8332 DKDLoss: 0.4364 
2022-05-03 11:28:05 - train: epoch 0082, iter [04500, 05004], lr: 0.001000, loss: 1.1743, stu_CELoss: 0.7414 DKDLoss: 0.4329 
2022-05-03 11:28:39 - train: epoch 0082, iter [04600, 05004], lr: 0.001000, loss: 1.5159, stu_CELoss: 1.0173 DKDLoss: 0.4985 
2022-05-03 11:29:12 - train: epoch 0082, iter [04700, 05004], lr: 0.001000, loss: 1.2169, stu_CELoss: 0.7655 DKDLoss: 0.4514 
2022-05-03 11:29:46 - train: epoch 0082, iter [04800, 05004], lr: 0.001000, loss: 1.0828, stu_CELoss: 0.6508 DKDLoss: 0.4320 
2022-05-03 11:30:20 - train: epoch 0082, iter [04900, 05004], lr: 0.001000, loss: 1.2087, stu_CELoss: 0.7879 DKDLoss: 0.4207 
2022-05-03 11:30:53 - train: epoch 0082, iter [05000, 05004], lr: 0.001000, loss: 1.2437, stu_CELoss: 0.8129 DKDLoss: 0.4308 
2022-05-03 11:30:55 - train: epoch 082, train_loss: 1.3010
2022-05-03 11:33:26 - eval: epoch: 082, tea_acc1: 78.330%, tea_acc5: 94.064%, tea_test_loss: 0.8657, stu_acc1: 77.244%, stu_acc5: 93.590%, stu_test_loss: 0.9005
2022-05-03 11:33:27 - until epoch: 082, tea_best_acc1: 78.330%, stu_best_acc1: 77.244%
2022-05-03 11:33:27 - epoch 083 lr: 0.0010000000000000002
2022-05-03 11:34:07 - train: epoch 0083, iter [00100, 05004], lr: 0.001000, loss: 1.2509, stu_CELoss: 0.8400 DKDLoss: 0.4109 
2022-05-03 11:34:40 - train: epoch 0083, iter [00200, 05004], lr: 0.001000, loss: 1.2200, stu_CELoss: 0.8097 DKDLoss: 0.4103 
2022-05-03 11:35:13 - train: epoch 0083, iter [00300, 05004], lr: 0.001000, loss: 1.3152, stu_CELoss: 0.8803 DKDLoss: 0.4349 
2022-05-03 11:35:47 - train: epoch 0083, iter [00400, 05004], lr: 0.001000, loss: 1.3799, stu_CELoss: 0.9269 DKDLoss: 0.4531 
2022-05-03 11:36:20 - train: epoch 0083, iter [00500, 05004], lr: 0.001000, loss: 1.3631, stu_CELoss: 0.9132 DKDLoss: 0.4498 
2022-05-03 11:36:53 - train: epoch 0083, iter [00600, 05004], lr: 0.001000, loss: 1.2661, stu_CELoss: 0.8158 DKDLoss: 0.4503 
2022-05-03 11:37:27 - train: epoch 0083, iter [00700, 05004], lr: 0.001000, loss: 1.2274, stu_CELoss: 0.8152 DKDLoss: 0.4121 
2022-05-03 11:38:00 - train: epoch 0083, iter [00800, 05004], lr: 0.001000, loss: 1.2928, stu_CELoss: 0.8393 DKDLoss: 0.4535 
2022-05-03 11:38:33 - train: epoch 0083, iter [00900, 05004], lr: 0.001000, loss: 1.4437, stu_CELoss: 0.9616 DKDLoss: 0.4821 
2022-05-03 11:39:07 - train: epoch 0083, iter [01000, 05004], lr: 0.001000, loss: 1.2191, stu_CELoss: 0.7874 DKDLoss: 0.4317 
2022-05-03 11:39:40 - train: epoch 0083, iter [01100, 05004], lr: 0.001000, loss: 1.3543, stu_CELoss: 0.9204 DKDLoss: 0.4339 
2022-05-03 11:40:13 - train: epoch 0083, iter [01200, 05004], lr: 0.001000, loss: 1.2724, stu_CELoss: 0.8193 DKDLoss: 0.4531 
2022-05-03 11:40:46 - train: epoch 0083, iter [01300, 05004], lr: 0.001000, loss: 1.3306, stu_CELoss: 0.8473 DKDLoss: 0.4833 
2022-05-03 11:41:20 - train: epoch 0083, iter [01400, 05004], lr: 0.001000, loss: 1.4986, stu_CELoss: 1.0208 DKDLoss: 0.4778 
2022-05-03 11:41:54 - train: epoch 0083, iter [01500, 05004], lr: 0.001000, loss: 1.2435, stu_CELoss: 0.8449 DKDLoss: 0.3986 
2022-05-03 11:42:27 - train: epoch 0083, iter [01600, 05004], lr: 0.001000, loss: 1.2579, stu_CELoss: 0.7888 DKDLoss: 0.4692 
2022-05-03 11:43:01 - train: epoch 0083, iter [01700, 05004], lr: 0.001000, loss: 1.1928, stu_CELoss: 0.7567 DKDLoss: 0.4361 
2022-05-03 11:43:34 - train: epoch 0083, iter [01800, 05004], lr: 0.001000, loss: 1.3352, stu_CELoss: 0.8716 DKDLoss: 0.4636 
2022-05-03 11:44:08 - train: epoch 0083, iter [01900, 05004], lr: 0.001000, loss: 1.3849, stu_CELoss: 0.9376 DKDLoss: 0.4472 
2022-05-03 11:44:42 - train: epoch 0083, iter [02000, 05004], lr: 0.001000, loss: 1.0401, stu_CELoss: 0.6135 DKDLoss: 0.4265 
2022-05-03 11:45:15 - train: epoch 0083, iter [02100, 05004], lr: 0.001000, loss: 1.2808, stu_CELoss: 0.8098 DKDLoss: 0.4710 
2022-05-03 11:45:48 - train: epoch 0083, iter [02200, 05004], lr: 0.001000, loss: 1.3035, stu_CELoss: 0.9117 DKDLoss: 0.3918 
2022-05-03 11:46:22 - train: epoch 0083, iter [02300, 05004], lr: 0.001000, loss: 1.3944, stu_CELoss: 0.9319 DKDLoss: 0.4625 
2022-05-03 11:46:56 - train: epoch 0083, iter [02400, 05004], lr: 0.001000, loss: 1.3337, stu_CELoss: 0.8624 DKDLoss: 0.4714 
2022-05-03 11:47:30 - train: epoch 0083, iter [02500, 05004], lr: 0.001000, loss: 1.2710, stu_CELoss: 0.8829 DKDLoss: 0.3881 
2022-05-03 11:48:04 - train: epoch 0083, iter [02600, 05004], lr: 0.001000, loss: 1.1948, stu_CELoss: 0.7773 DKDLoss: 0.4175 
2022-05-03 11:48:38 - train: epoch 0083, iter [02700, 05004], lr: 0.001000, loss: 1.3017, stu_CELoss: 0.8846 DKDLoss: 0.4171 
2022-05-03 11:49:11 - train: epoch 0083, iter [02800, 05004], lr: 0.001000, loss: 1.2171, stu_CELoss: 0.7765 DKDLoss: 0.4406 
2022-05-03 11:49:45 - train: epoch 0083, iter [02900, 05004], lr: 0.001000, loss: 1.4119, stu_CELoss: 0.9912 DKDLoss: 0.4207 
2022-05-03 11:50:19 - train: epoch 0083, iter [03000, 05004], lr: 0.001000, loss: 1.3038, stu_CELoss: 0.8711 DKDLoss: 0.4327 
2022-05-03 11:50:53 - train: epoch 0083, iter [03100, 05004], lr: 0.001000, loss: 1.2187, stu_CELoss: 0.8238 DKDLoss: 0.3949 
2022-05-03 11:51:27 - train: epoch 0083, iter [03200, 05004], lr: 0.001000, loss: 1.3132, stu_CELoss: 0.8952 DKDLoss: 0.4181 
2022-05-03 11:52:01 - train: epoch 0083, iter [03300, 05004], lr: 0.001000, loss: 1.5890, stu_CELoss: 1.0700 DKDLoss: 0.5190 
2022-05-03 11:52:35 - train: epoch 0083, iter [03400, 05004], lr: 0.001000, loss: 1.2659, stu_CELoss: 0.8042 DKDLoss: 0.4617 
2022-05-03 11:53:08 - train: epoch 0083, iter [03500, 05004], lr: 0.001000, loss: 1.3327, stu_CELoss: 0.8960 DKDLoss: 0.4367 
2022-05-03 11:53:42 - train: epoch 0083, iter [03600, 05004], lr: 0.001000, loss: 1.3072, stu_CELoss: 0.8627 DKDLoss: 0.4445 
2022-05-03 11:54:16 - train: epoch 0083, iter [03700, 05004], lr: 0.001000, loss: 1.2505, stu_CELoss: 0.8190 DKDLoss: 0.4315 
2022-05-03 11:54:50 - train: epoch 0083, iter [03800, 05004], lr: 0.001000, loss: 1.3340, stu_CELoss: 0.9047 DKDLoss: 0.4293 
2022-05-03 11:55:24 - train: epoch 0083, iter [03900, 05004], lr: 0.001000, loss: 1.4173, stu_CELoss: 0.8850 DKDLoss: 0.5324 
2022-05-03 11:55:58 - train: epoch 0083, iter [04000, 05004], lr: 0.001000, loss: 1.3268, stu_CELoss: 0.8503 DKDLoss: 0.4765 
2022-05-03 11:56:32 - train: epoch 0083, iter [04100, 05004], lr: 0.001000, loss: 1.3213, stu_CELoss: 0.8522 DKDLoss: 0.4691 
2022-05-03 11:57:06 - train: epoch 0083, iter [04200, 05004], lr: 0.001000, loss: 1.4941, stu_CELoss: 1.0035 DKDLoss: 0.4906 
2022-05-03 11:57:40 - train: epoch 0083, iter [04300, 05004], lr: 0.001000, loss: 1.3638, stu_CELoss: 0.8645 DKDLoss: 0.4993 
2022-05-03 11:58:14 - train: epoch 0083, iter [04400, 05004], lr: 0.001000, loss: 1.4025, stu_CELoss: 0.9607 DKDLoss: 0.4417 
2022-05-03 11:58:48 - train: epoch 0083, iter [04500, 05004], lr: 0.001000, loss: 1.2772, stu_CELoss: 0.8598 DKDLoss: 0.4174 
2022-05-03 11:59:22 - train: epoch 0083, iter [04600, 05004], lr: 0.001000, loss: 1.3472, stu_CELoss: 0.8843 DKDLoss: 0.4629 
2022-05-03 11:59:56 - train: epoch 0083, iter [04700, 05004], lr: 0.001000, loss: 1.5153, stu_CELoss: 1.0683 DKDLoss: 0.4470 
2022-05-03 12:00:30 - train: epoch 0083, iter [04800, 05004], lr: 0.001000, loss: 1.3177, stu_CELoss: 0.8208 DKDLoss: 0.4969 
2022-05-03 12:01:04 - train: epoch 0083, iter [04900, 05004], lr: 0.001000, loss: 1.2916, stu_CELoss: 0.8171 DKDLoss: 0.4745 
2022-05-03 12:01:37 - train: epoch 0083, iter [05000, 05004], lr: 0.001000, loss: 1.2564, stu_CELoss: 0.7851 DKDLoss: 0.4713 
2022-05-03 12:01:39 - train: epoch 083, train_loss: 1.2993
2022-05-03 12:04:10 - eval: epoch: 083, tea_acc1: 78.330%, tea_acc5: 94.064%, tea_test_loss: 0.8657, stu_acc1: 77.196%, stu_acc5: 93.554%, stu_test_loss: 0.8984
2022-05-03 12:04:10 - until epoch: 083, tea_best_acc1: 78.330%, stu_best_acc1: 77.244%
2022-05-03 12:04:10 - epoch 084 lr: 0.0010000000000000002
2022-05-03 12:04:51 - train: epoch 0084, iter [00100, 05004], lr: 0.001000, loss: 1.2253, stu_CELoss: 0.8209 DKDLoss: 0.4045 
2022-05-03 12:05:24 - train: epoch 0084, iter [00200, 05004], lr: 0.001000, loss: 1.2147, stu_CELoss: 0.7857 DKDLoss: 0.4290 
2022-05-03 12:05:57 - train: epoch 0084, iter [00300, 05004], lr: 0.001000, loss: 1.2006, stu_CELoss: 0.7682 DKDLoss: 0.4324 
2022-05-03 12:06:31 - train: epoch 0084, iter [00400, 05004], lr: 0.001000, loss: 1.2293, stu_CELoss: 0.8095 DKDLoss: 0.4198 
2022-05-03 12:07:04 - train: epoch 0084, iter [00500, 05004], lr: 0.001000, loss: 1.3906, stu_CELoss: 0.9072 DKDLoss: 0.4833 
2022-05-03 12:07:38 - train: epoch 0084, iter [00600, 05004], lr: 0.001000, loss: 1.3263, stu_CELoss: 0.8984 DKDLoss: 0.4278 
2022-05-03 12:08:11 - train: epoch 0084, iter [00700, 05004], lr: 0.001000, loss: 1.4099, stu_CELoss: 0.9594 DKDLoss: 0.4506 
2022-05-03 12:08:45 - train: epoch 0084, iter [00800, 05004], lr: 0.001000, loss: 1.4513, stu_CELoss: 0.9912 DKDLoss: 0.4600 
2022-05-03 12:09:18 - train: epoch 0084, iter [00900, 05004], lr: 0.001000, loss: 1.3141, stu_CELoss: 0.8509 DKDLoss: 0.4631 
2022-05-03 12:09:52 - train: epoch 0084, iter [01000, 05004], lr: 0.001000, loss: 1.3730, stu_CELoss: 0.9477 DKDLoss: 0.4252 
2022-05-03 12:10:25 - train: epoch 0084, iter [01100, 05004], lr: 0.001000, loss: 1.1743, stu_CELoss: 0.7551 DKDLoss: 0.4193 
2022-05-03 12:10:59 - train: epoch 0084, iter [01200, 05004], lr: 0.001000, loss: 1.4297, stu_CELoss: 0.9581 DKDLoss: 0.4716 
2022-05-03 12:11:33 - train: epoch 0084, iter [01300, 05004], lr: 0.001000, loss: 1.2019, stu_CELoss: 0.7764 DKDLoss: 0.4255 
2022-05-03 12:12:06 - train: epoch 0084, iter [01400, 05004], lr: 0.001000, loss: 1.2041, stu_CELoss: 0.7702 DKDLoss: 0.4339 
2022-05-03 12:12:40 - train: epoch 0084, iter [01500, 05004], lr: 0.001000, loss: 1.1753, stu_CELoss: 0.7212 DKDLoss: 0.4541 
2022-05-03 12:13:13 - train: epoch 0084, iter [01600, 05004], lr: 0.001000, loss: 1.2526, stu_CELoss: 0.8011 DKDLoss: 0.4516 
2022-05-03 12:13:48 - train: epoch 0084, iter [01700, 05004], lr: 0.001000, loss: 1.3269, stu_CELoss: 0.8625 DKDLoss: 0.4644 
2022-05-03 12:14:22 - train: epoch 0084, iter [01800, 05004], lr: 0.001000, loss: 1.4205, stu_CELoss: 0.9587 DKDLoss: 0.4618 
2022-05-03 12:14:55 - train: epoch 0084, iter [01900, 05004], lr: 0.001000, loss: 1.5470, stu_CELoss: 1.0621 DKDLoss: 0.4848 
2022-05-03 12:15:29 - train: epoch 0084, iter [02000, 05004], lr: 0.001000, loss: 1.0632, stu_CELoss: 0.7003 DKDLoss: 0.3629 
2022-05-03 12:16:03 - train: epoch 0084, iter [02100, 05004], lr: 0.001000, loss: 1.2638, stu_CELoss: 0.8386 DKDLoss: 0.4252 
2022-05-03 12:16:37 - train: epoch 0084, iter [02200, 05004], lr: 0.001000, loss: 1.2451, stu_CELoss: 0.8187 DKDLoss: 0.4264 
2022-05-03 12:17:11 - train: epoch 0084, iter [02300, 05004], lr: 0.001000, loss: 1.2268, stu_CELoss: 0.8100 DKDLoss: 0.4169 
2022-05-03 12:17:45 - train: epoch 0084, iter [02400, 05004], lr: 0.001000, loss: 1.1808, stu_CELoss: 0.7834 DKDLoss: 0.3974 
2022-05-03 12:18:19 - train: epoch 0084, iter [02500, 05004], lr: 0.001000, loss: 1.3774, stu_CELoss: 0.9120 DKDLoss: 0.4653 
2022-05-03 12:18:52 - train: epoch 0084, iter [02600, 05004], lr: 0.001000, loss: 1.3505, stu_CELoss: 0.9508 DKDLoss: 0.3997 
2022-05-03 12:19:26 - train: epoch 0084, iter [02700, 05004], lr: 0.001000, loss: 1.2859, stu_CELoss: 0.8906 DKDLoss: 0.3953 
2022-05-03 12:20:00 - train: epoch 0084, iter [02800, 05004], lr: 0.001000, loss: 1.4189, stu_CELoss: 0.9715 DKDLoss: 0.4474 
2022-05-03 12:20:34 - train: epoch 0084, iter [02900, 05004], lr: 0.001000, loss: 1.2510, stu_CELoss: 0.8468 DKDLoss: 0.4041 
2022-05-03 12:21:08 - train: epoch 0084, iter [03000, 05004], lr: 0.001000, loss: 1.2534, stu_CELoss: 0.8058 DKDLoss: 0.4476 
2022-05-03 12:21:42 - train: epoch 0084, iter [03100, 05004], lr: 0.001000, loss: 1.2843, stu_CELoss: 0.8494 DKDLoss: 0.4349 
2022-05-03 12:22:16 - train: epoch 0084, iter [03200, 05004], lr: 0.001000, loss: 1.3535, stu_CELoss: 0.8936 DKDLoss: 0.4599 
2022-05-03 12:22:50 - train: epoch 0084, iter [03300, 05004], lr: 0.001000, loss: 1.3721, stu_CELoss: 0.8553 DKDLoss: 0.5168 
2022-05-03 12:23:24 - train: epoch 0084, iter [03400, 05004], lr: 0.001000, loss: 1.3244, stu_CELoss: 0.9278 DKDLoss: 0.3966 
2022-05-03 12:23:58 - train: epoch 0084, iter [03500, 05004], lr: 0.001000, loss: 1.2396, stu_CELoss: 0.8024 DKDLoss: 0.4371 
2022-05-03 12:24:32 - train: epoch 0084, iter [03600, 05004], lr: 0.001000, loss: 1.3816, stu_CELoss: 0.9685 DKDLoss: 0.4131 
2022-05-03 12:25:06 - train: epoch 0084, iter [03700, 05004], lr: 0.001000, loss: 1.4030, stu_CELoss: 0.9445 DKDLoss: 0.4585 
2022-05-03 12:25:40 - train: epoch 0084, iter [03800, 05004], lr: 0.001000, loss: 1.4237, stu_CELoss: 0.9708 DKDLoss: 0.4529 
2022-05-03 12:26:14 - train: epoch 0084, iter [03900, 05004], lr: 0.001000, loss: 1.2189, stu_CELoss: 0.7610 DKDLoss: 0.4578 
2022-05-03 12:26:48 - train: epoch 0084, iter [04000, 05004], lr: 0.001000, loss: 1.1498, stu_CELoss: 0.7289 DKDLoss: 0.4209 
2022-05-03 12:27:22 - train: epoch 0084, iter [04100, 05004], lr: 0.001000, loss: 1.1601, stu_CELoss: 0.7503 DKDLoss: 0.4098 
2022-05-03 12:27:56 - train: epoch 0084, iter [04200, 05004], lr: 0.001000, loss: 1.3757, stu_CELoss: 0.9475 DKDLoss: 0.4282 
2022-05-03 12:28:29 - train: epoch 0084, iter [04300, 05004], lr: 0.001000, loss: 1.2630, stu_CELoss: 0.8259 DKDLoss: 0.4371 
2022-05-03 12:29:03 - train: epoch 0084, iter [04400, 05004], lr: 0.001000, loss: 1.5742, stu_CELoss: 1.0536 DKDLoss: 0.5206 
2022-05-03 12:29:37 - train: epoch 0084, iter [04500, 05004], lr: 0.001000, loss: 1.3005, stu_CELoss: 0.8774 DKDLoss: 0.4231 
2022-05-03 12:30:11 - train: epoch 0084, iter [04600, 05004], lr: 0.001000, loss: 1.3515, stu_CELoss: 0.9076 DKDLoss: 0.4439 
2022-05-03 12:30:45 - train: epoch 0084, iter [04700, 05004], lr: 0.001000, loss: 1.3304, stu_CELoss: 0.9414 DKDLoss: 0.3889 
2022-05-03 12:31:19 - train: epoch 0084, iter [04800, 05004], lr: 0.001000, loss: 1.2189, stu_CELoss: 0.7941 DKDLoss: 0.4248 
2022-05-03 12:31:53 - train: epoch 0084, iter [04900, 05004], lr: 0.001000, loss: 1.3214, stu_CELoss: 0.8798 DKDLoss: 0.4416 
2022-05-03 12:32:26 - train: epoch 0084, iter [05000, 05004], lr: 0.001000, loss: 1.2002, stu_CELoss: 0.7690 DKDLoss: 0.4313 
2022-05-03 12:32:28 - train: epoch 084, train_loss: 1.2925
2022-05-03 12:34:59 - eval: epoch: 084, tea_acc1: 78.330%, tea_acc5: 94.064%, tea_test_loss: 0.8657, stu_acc1: 77.228%, stu_acc5: 93.514%, stu_test_loss: 0.8962
2022-05-03 12:35:00 - until epoch: 084, tea_best_acc1: 78.330%, stu_best_acc1: 77.244%
2022-05-03 12:35:00 - epoch 085 lr: 0.0010000000000000002
2022-05-03 12:35:40 - train: epoch 0085, iter [00100, 05004], lr: 0.001000, loss: 1.1227, stu_CELoss: 0.6843 DKDLoss: 0.4384 
2022-05-03 12:36:13 - train: epoch 0085, iter [00200, 05004], lr: 0.001000, loss: 1.2624, stu_CELoss: 0.8535 DKDLoss: 0.4089 
2022-05-03 12:36:46 - train: epoch 0085, iter [00300, 05004], lr: 0.001000, loss: 1.2458, stu_CELoss: 0.7995 DKDLoss: 0.4464 
2022-05-03 12:37:20 - train: epoch 0085, iter [00400, 05004], lr: 0.001000, loss: 1.1831, stu_CELoss: 0.7301 DKDLoss: 0.4530 
2022-05-03 12:37:53 - train: epoch 0085, iter [00500, 05004], lr: 0.001000, loss: 1.3625, stu_CELoss: 0.9315 DKDLoss: 0.4310 
2022-05-03 12:38:26 - train: epoch 0085, iter [00600, 05004], lr: 0.001000, loss: 1.1395, stu_CELoss: 0.7162 DKDLoss: 0.4234 
2022-05-03 12:38:59 - train: epoch 0085, iter [00700, 05004], lr: 0.001000, loss: 1.4061, stu_CELoss: 1.0061 DKDLoss: 0.4001 
2022-05-03 12:39:33 - train: epoch 0085, iter [00800, 05004], lr: 0.001000, loss: 1.1068, stu_CELoss: 0.6303 DKDLoss: 0.4765 
2022-05-03 12:40:06 - train: epoch 0085, iter [00900, 05004], lr: 0.001000, loss: 1.2886, stu_CELoss: 0.8590 DKDLoss: 0.4296 
2022-05-03 12:40:40 - train: epoch 0085, iter [01000, 05004], lr: 0.001000, loss: 1.2029, stu_CELoss: 0.7632 DKDLoss: 0.4397 
2022-05-03 12:41:13 - train: epoch 0085, iter [01100, 05004], lr: 0.001000, loss: 1.2071, stu_CELoss: 0.7854 DKDLoss: 0.4217 
2022-05-03 12:41:47 - train: epoch 0085, iter [01200, 05004], lr: 0.001000, loss: 1.1053, stu_CELoss: 0.6941 DKDLoss: 0.4112 
2022-05-03 12:42:20 - train: epoch 0085, iter [01300, 05004], lr: 0.001000, loss: 1.2318, stu_CELoss: 0.7900 DKDLoss: 0.4418 
2022-05-03 12:42:54 - train: epoch 0085, iter [01400, 05004], lr: 0.001000, loss: 1.1686, stu_CELoss: 0.7415 DKDLoss: 0.4271 
2022-05-03 12:43:27 - train: epoch 0085, iter [01500, 05004], lr: 0.001000, loss: 1.3858, stu_CELoss: 0.9532 DKDLoss: 0.4326 
2022-05-03 12:44:01 - train: epoch 0085, iter [01600, 05004], lr: 0.001000, loss: 1.3155, stu_CELoss: 0.8354 DKDLoss: 0.4801 
2022-05-03 12:44:34 - train: epoch 0085, iter [01700, 05004], lr: 0.001000, loss: 1.4695, stu_CELoss: 1.0437 DKDLoss: 0.4258 
2022-05-03 12:45:08 - train: epoch 0085, iter [01800, 05004], lr: 0.001000, loss: 0.9993, stu_CELoss: 0.5934 DKDLoss: 0.4058 
2022-05-03 12:45:41 - train: epoch 0085, iter [01900, 05004], lr: 0.001000, loss: 1.0705, stu_CELoss: 0.6596 DKDLoss: 0.4109 
2022-05-03 12:46:15 - train: epoch 0085, iter [02000, 05004], lr: 0.001000, loss: 1.1722, stu_CELoss: 0.7092 DKDLoss: 0.4630 
2022-05-03 12:46:49 - train: epoch 0085, iter [02100, 05004], lr: 0.001000, loss: 1.0713, stu_CELoss: 0.7074 DKDLoss: 0.3639 
2022-05-03 12:47:22 - train: epoch 0085, iter [02200, 05004], lr: 0.001000, loss: 1.3446, stu_CELoss: 0.8808 DKDLoss: 0.4638 
2022-05-03 12:47:56 - train: epoch 0085, iter [02300, 05004], lr: 0.001000, loss: 1.1943, stu_CELoss: 0.7992 DKDLoss: 0.3951 
2022-05-03 12:48:30 - train: epoch 0085, iter [02400, 05004], lr: 0.001000, loss: 1.2723, stu_CELoss: 0.8712 DKDLoss: 0.4011 
2022-05-03 12:49:04 - train: epoch 0085, iter [02500, 05004], lr: 0.001000, loss: 1.3976, stu_CELoss: 0.9454 DKDLoss: 0.4522 
2022-05-03 12:49:38 - train: epoch 0085, iter [02600, 05004], lr: 0.001000, loss: 1.3605, stu_CELoss: 0.9096 DKDLoss: 0.4508 
2022-05-03 12:50:11 - train: epoch 0085, iter [02700, 05004], lr: 0.001000, loss: 1.1558, stu_CELoss: 0.7903 DKDLoss: 0.3655 
2022-05-03 12:50:45 - train: epoch 0085, iter [02800, 05004], lr: 0.001000, loss: 1.4291, stu_CELoss: 1.0056 DKDLoss: 0.4236 
2022-05-03 12:51:19 - train: epoch 0085, iter [02900, 05004], lr: 0.001000, loss: 1.3157, stu_CELoss: 0.9136 DKDLoss: 0.4022 
2022-05-03 12:51:53 - train: epoch 0085, iter [03000, 05004], lr: 0.001000, loss: 1.5519, stu_CELoss: 0.9912 DKDLoss: 0.5607 
2022-05-03 12:52:27 - train: epoch 0085, iter [03100, 05004], lr: 0.001000, loss: 1.1378, stu_CELoss: 0.7435 DKDLoss: 0.3942 
2022-05-03 12:53:00 - train: epoch 0085, iter [03200, 05004], lr: 0.001000, loss: 1.2735, stu_CELoss: 0.8424 DKDLoss: 0.4311 
2022-05-03 12:53:34 - train: epoch 0085, iter [03300, 05004], lr: 0.001000, loss: 1.4859, stu_CELoss: 1.0225 DKDLoss: 0.4634 
2022-05-03 12:54:08 - train: epoch 0085, iter [03400, 05004], lr: 0.001000, loss: 1.3491, stu_CELoss: 0.9410 DKDLoss: 0.4081 
2022-05-03 12:54:42 - train: epoch 0085, iter [03500, 05004], lr: 0.001000, loss: 1.4472, stu_CELoss: 0.9619 DKDLoss: 0.4854 
2022-05-03 12:55:16 - train: epoch 0085, iter [03600, 05004], lr: 0.001000, loss: 1.3254, stu_CELoss: 0.9135 DKDLoss: 0.4119 
2022-05-03 12:55:50 - train: epoch 0085, iter [03700, 05004], lr: 0.001000, loss: 1.0034, stu_CELoss: 0.6344 DKDLoss: 0.3690 
2022-05-03 12:56:23 - train: epoch 0085, iter [03800, 05004], lr: 0.001000, loss: 1.3155, stu_CELoss: 0.8882 DKDLoss: 0.4273 
2022-05-03 12:56:57 - train: epoch 0085, iter [03900, 05004], lr: 0.001000, loss: 1.2955, stu_CELoss: 0.9070 DKDLoss: 0.3885 
2022-05-03 12:57:31 - train: epoch 0085, iter [04000, 05004], lr: 0.001000, loss: 1.5049, stu_CELoss: 1.0871 DKDLoss: 0.4177 
2022-05-03 12:58:05 - train: epoch 0085, iter [04100, 05004], lr: 0.001000, loss: 1.3677, stu_CELoss: 0.9778 DKDLoss: 0.3899 
2022-05-03 12:58:38 - train: epoch 0085, iter [04200, 05004], lr: 0.001000, loss: 1.3063, stu_CELoss: 0.8768 DKDLoss: 0.4295 
2022-05-03 12:59:12 - train: epoch 0085, iter [04300, 05004], lr: 0.001000, loss: 1.2506, stu_CELoss: 0.8248 DKDLoss: 0.4258 
2022-05-03 12:59:46 - train: epoch 0085, iter [04400, 05004], lr: 0.001000, loss: 1.1083, stu_CELoss: 0.6808 DKDLoss: 0.4275 
2022-05-03 13:00:19 - train: epoch 0085, iter [04500, 05004], lr: 0.001000, loss: 1.1653, stu_CELoss: 0.7456 DKDLoss: 0.4197 
2022-05-03 13:00:53 - train: epoch 0085, iter [04600, 05004], lr: 0.001000, loss: 1.4201, stu_CELoss: 0.8983 DKDLoss: 0.5218 
2022-05-03 13:01:27 - train: epoch 0085, iter [04700, 05004], lr: 0.001000, loss: 1.4765, stu_CELoss: 1.0093 DKDLoss: 0.4672 
2022-05-03 13:02:01 - train: epoch 0085, iter [04800, 05004], lr: 0.001000, loss: 1.1243, stu_CELoss: 0.7287 DKDLoss: 0.3957 
2022-05-03 13:02:35 - train: epoch 0085, iter [04900, 05004], lr: 0.001000, loss: 1.2255, stu_CELoss: 0.7734 DKDLoss: 0.4521 
2022-05-03 13:03:08 - train: epoch 0085, iter [05000, 05004], lr: 0.001000, loss: 1.1039, stu_CELoss: 0.7366 DKDLoss: 0.3673 
2022-05-03 13:03:10 - train: epoch 085, train_loss: 1.2849
2022-05-03 13:05:41 - eval: epoch: 085, tea_acc1: 78.330%, tea_acc5: 94.064%, tea_test_loss: 0.8657, stu_acc1: 77.224%, stu_acc5: 93.550%, stu_test_loss: 0.8973
2022-05-03 13:05:42 - until epoch: 085, tea_best_acc1: 78.330%, stu_best_acc1: 77.244%
2022-05-03 13:05:42 - epoch 086 lr: 0.0010000000000000002
2022-05-03 13:06:22 - train: epoch 0086, iter [00100, 05004], lr: 0.001000, loss: 1.2431, stu_CELoss: 0.8036 DKDLoss: 0.4395 
2022-05-03 13:06:56 - train: epoch 0086, iter [00200, 05004], lr: 0.001000, loss: 1.2238, stu_CELoss: 0.7962 DKDLoss: 0.4276 
2022-05-03 13:07:29 - train: epoch 0086, iter [00300, 05004], lr: 0.001000, loss: 1.3827, stu_CELoss: 0.9604 DKDLoss: 0.4223 
2022-05-03 13:08:02 - train: epoch 0086, iter [00400, 05004], lr: 0.001000, loss: 1.2928, stu_CELoss: 0.8589 DKDLoss: 0.4339 
2022-05-03 13:08:36 - train: epoch 0086, iter [00500, 05004], lr: 0.001000, loss: 1.1877, stu_CELoss: 0.7501 DKDLoss: 0.4376 
2022-05-03 13:09:09 - train: epoch 0086, iter [00600, 05004], lr: 0.001000, loss: 1.3205, stu_CELoss: 0.8767 DKDLoss: 0.4438 
2022-05-03 13:09:43 - train: epoch 0086, iter [00700, 05004], lr: 0.001000, loss: 1.2261, stu_CELoss: 0.7517 DKDLoss: 0.4745 
2022-05-03 13:10:17 - train: epoch 0086, iter [00800, 05004], lr: 0.001000, loss: 1.2039, stu_CELoss: 0.7720 DKDLoss: 0.4319 
2022-05-03 13:10:50 - train: epoch 0086, iter [00900, 05004], lr: 0.001000, loss: 1.2980, stu_CELoss: 0.8279 DKDLoss: 0.4701 
2022-05-03 13:11:24 - train: epoch 0086, iter [01000, 05004], lr: 0.001000, loss: 1.3051, stu_CELoss: 0.8259 DKDLoss: 0.4792 
2022-05-03 13:11:57 - train: epoch 0086, iter [01100, 05004], lr: 0.001000, loss: 1.3869, stu_CELoss: 0.9606 DKDLoss: 0.4263 
2022-05-03 13:12:31 - train: epoch 0086, iter [01200, 05004], lr: 0.001000, loss: 1.2142, stu_CELoss: 0.7843 DKDLoss: 0.4299 
2022-05-03 13:13:04 - train: epoch 0086, iter [01300, 05004], lr: 0.001000, loss: 1.3202, stu_CELoss: 0.9250 DKDLoss: 0.3953 
2022-05-03 13:13:38 - train: epoch 0086, iter [01400, 05004], lr: 0.001000, loss: 1.2123, stu_CELoss: 0.7970 DKDLoss: 0.4152 
2022-05-03 13:14:11 - train: epoch 0086, iter [01500, 05004], lr: 0.001000, loss: 1.1370, stu_CELoss: 0.7253 DKDLoss: 0.4117 
2022-05-03 13:14:45 - train: epoch 0086, iter [01600, 05004], lr: 0.001000, loss: 1.3759, stu_CELoss: 0.9203 DKDLoss: 0.4556 
2022-05-03 13:15:19 - train: epoch 0086, iter [01700, 05004], lr: 0.001000, loss: 1.3839, stu_CELoss: 0.9437 DKDLoss: 0.4402 
2022-05-03 13:15:52 - train: epoch 0086, iter [01800, 05004], lr: 0.001000, loss: 1.1335, stu_CELoss: 0.7172 DKDLoss: 0.4163 
2022-05-03 13:16:26 - train: epoch 0086, iter [01900, 05004], lr: 0.001000, loss: 1.1447, stu_CELoss: 0.7343 DKDLoss: 0.4104 
2022-05-03 13:17:00 - train: epoch 0086, iter [02000, 05004], lr: 0.001000, loss: 1.2907, stu_CELoss: 0.7814 DKDLoss: 0.5093 
2022-05-03 13:17:33 - train: epoch 0086, iter [02100, 05004], lr: 0.001000, loss: 1.1393, stu_CELoss: 0.7476 DKDLoss: 0.3917 
2022-05-03 13:18:07 - train: epoch 0086, iter [02200, 05004], lr: 0.001000, loss: 1.2019, stu_CELoss: 0.7808 DKDLoss: 0.4212 
2022-05-03 13:18:40 - train: epoch 0086, iter [02300, 05004], lr: 0.001000, loss: 1.2815, stu_CELoss: 0.8684 DKDLoss: 0.4131 
2022-05-03 13:19:14 - train: epoch 0086, iter [02400, 05004], lr: 0.001000, loss: 1.2577, stu_CELoss: 0.8758 DKDLoss: 0.3819 
2022-05-03 13:19:48 - train: epoch 0086, iter [02500, 05004], lr: 0.001000, loss: 1.2324, stu_CELoss: 0.8474 DKDLoss: 0.3850 
2022-05-03 13:20:22 - train: epoch 0086, iter [02600, 05004], lr: 0.001000, loss: 1.4780, stu_CELoss: 1.0121 DKDLoss: 0.4659 
2022-05-03 13:20:56 - train: epoch 0086, iter [02700, 05004], lr: 0.001000, loss: 1.3571, stu_CELoss: 0.8774 DKDLoss: 0.4796 
2022-05-03 13:21:30 - train: epoch 0086, iter [02800, 05004], lr: 0.001000, loss: 1.2703, stu_CELoss: 0.8885 DKDLoss: 0.3818 
2022-05-03 13:22:03 - train: epoch 0086, iter [02900, 05004], lr: 0.001000, loss: 1.2298, stu_CELoss: 0.8382 DKDLoss: 0.3917 
2022-05-03 13:22:37 - train: epoch 0086, iter [03000, 05004], lr: 0.001000, loss: 1.1982, stu_CELoss: 0.8105 DKDLoss: 0.3877 
2022-05-03 13:23:11 - train: epoch 0086, iter [03100, 05004], lr: 0.001000, loss: 1.2596, stu_CELoss: 0.8230 DKDLoss: 0.4366 
2022-05-03 13:23:45 - train: epoch 0086, iter [03200, 05004], lr: 0.001000, loss: 1.4738, stu_CELoss: 0.9984 DKDLoss: 0.4754 
2022-05-03 13:24:19 - train: epoch 0086, iter [03300, 05004], lr: 0.001000, loss: 1.2045, stu_CELoss: 0.7502 DKDLoss: 0.4543 
2022-05-03 13:24:53 - train: epoch 0086, iter [03400, 05004], lr: 0.001000, loss: 1.1439, stu_CELoss: 0.7427 DKDLoss: 0.4012 
2022-05-03 13:25:27 - train: epoch 0086, iter [03500, 05004], lr: 0.001000, loss: 1.2001, stu_CELoss: 0.7719 DKDLoss: 0.4282 
2022-05-03 13:26:01 - train: epoch 0086, iter [03600, 05004], lr: 0.001000, loss: 1.2237, stu_CELoss: 0.7964 DKDLoss: 0.4273 
2022-05-03 13:26:35 - train: epoch 0086, iter [03700, 05004], lr: 0.001000, loss: 1.2449, stu_CELoss: 0.8123 DKDLoss: 0.4325 
2022-05-03 13:27:09 - train: epoch 0086, iter [03800, 05004], lr: 0.001000, loss: 1.3125, stu_CELoss: 0.8687 DKDLoss: 0.4439 
2022-05-03 13:27:43 - train: epoch 0086, iter [03900, 05004], lr: 0.001000, loss: 1.2107, stu_CELoss: 0.7929 DKDLoss: 0.4177 
2022-05-03 13:28:17 - train: epoch 0086, iter [04000, 05004], lr: 0.001000, loss: 1.3999, stu_CELoss: 0.9412 DKDLoss: 0.4588 
2022-05-03 13:28:51 - train: epoch 0086, iter [04100, 05004], lr: 0.001000, loss: 1.1287, stu_CELoss: 0.7366 DKDLoss: 0.3921 
2022-05-03 13:29:25 - train: epoch 0086, iter [04200, 05004], lr: 0.001000, loss: 1.3147, stu_CELoss: 0.8864 DKDLoss: 0.4284 
2022-05-03 13:29:59 - train: epoch 0086, iter [04300, 05004], lr: 0.001000, loss: 1.3924, stu_CELoss: 0.9202 DKDLoss: 0.4722 
2022-05-03 13:30:33 - train: epoch 0086, iter [04400, 05004], lr: 0.001000, loss: 1.4243, stu_CELoss: 0.9899 DKDLoss: 0.4343 
2022-05-03 13:31:07 - train: epoch 0086, iter [04500, 05004], lr: 0.001000, loss: 1.2096, stu_CELoss: 0.7810 DKDLoss: 0.4286 
2022-05-03 13:31:41 - train: epoch 0086, iter [04600, 05004], lr: 0.001000, loss: 1.2412, stu_CELoss: 0.8267 DKDLoss: 0.4144 
2022-05-03 13:32:15 - train: epoch 0086, iter [04700, 05004], lr: 0.001000, loss: 1.3343, stu_CELoss: 0.8917 DKDLoss: 0.4426 
2022-05-03 13:32:49 - train: epoch 0086, iter [04800, 05004], lr: 0.001000, loss: 1.2187, stu_CELoss: 0.7971 DKDLoss: 0.4216 
2022-05-03 13:33:23 - train: epoch 0086, iter [04900, 05004], lr: 0.001000, loss: 1.2754, stu_CELoss: 0.8098 DKDLoss: 0.4656 
2022-05-03 13:33:56 - train: epoch 0086, iter [05000, 05004], lr: 0.001000, loss: 1.2788, stu_CELoss: 0.8654 DKDLoss: 0.4134 
2022-05-03 13:33:58 - train: epoch 086, train_loss: 1.2822
2022-05-03 13:36:29 - eval: epoch: 086, tea_acc1: 78.330%, tea_acc5: 94.064%, tea_test_loss: 0.8657, stu_acc1: 77.262%, stu_acc5: 93.524%, stu_test_loss: 0.8986
2022-05-03 13:36:29 - until epoch: 086, tea_best_acc1: 78.330%, stu_best_acc1: 77.262%
2022-05-03 13:36:29 - epoch 087 lr: 0.0010000000000000002
2022-05-03 13:37:10 - train: epoch 0087, iter [00100, 05004], lr: 0.001000, loss: 1.3532, stu_CELoss: 0.9200 DKDLoss: 0.4331 
2022-05-03 13:37:42 - train: epoch 0087, iter [00200, 05004], lr: 0.001000, loss: 1.1563, stu_CELoss: 0.7111 DKDLoss: 0.4452 
2022-05-03 13:38:16 - train: epoch 0087, iter [00300, 05004], lr: 0.001000, loss: 1.2696, stu_CELoss: 0.8452 DKDLoss: 0.4244 
2022-05-03 13:38:49 - train: epoch 0087, iter [00400, 05004], lr: 0.001000, loss: 1.4190, stu_CELoss: 1.0308 DKDLoss: 0.3882 
2022-05-03 13:39:22 - train: epoch 0087, iter [00500, 05004], lr: 0.001000, loss: 1.2008, stu_CELoss: 0.7892 DKDLoss: 0.4116 
2022-05-03 13:39:55 - train: epoch 0087, iter [00600, 05004], lr: 0.001000, loss: 1.3445, stu_CELoss: 0.9029 DKDLoss: 0.4416 
2022-05-03 13:40:29 - train: epoch 0087, iter [00700, 05004], lr: 0.001000, loss: 1.3369, stu_CELoss: 0.7782 DKDLoss: 0.5586 
2022-05-03 13:41:02 - train: epoch 0087, iter [00800, 05004], lr: 0.001000, loss: 1.3187, stu_CELoss: 0.8628 DKDLoss: 0.4560 
2022-05-03 13:41:36 - train: epoch 0087, iter [00900, 05004], lr: 0.001000, loss: 1.3688, stu_CELoss: 0.9206 DKDLoss: 0.4481 
2022-05-03 13:42:10 - train: epoch 0087, iter [01000, 05004], lr: 0.001000, loss: 1.2507, stu_CELoss: 0.8328 DKDLoss: 0.4179 
2022-05-03 13:42:43 - train: epoch 0087, iter [01100, 05004], lr: 0.001000, loss: 1.2156, stu_CELoss: 0.7750 DKDLoss: 0.4406 
2022-05-03 13:43:17 - train: epoch 0087, iter [01200, 05004], lr: 0.001000, loss: 1.0928, stu_CELoss: 0.6827 DKDLoss: 0.4101 
2022-05-03 13:43:51 - train: epoch 0087, iter [01300, 05004], lr: 0.001000, loss: 1.3037, stu_CELoss: 0.8449 DKDLoss: 0.4587 
2022-05-03 13:44:24 - train: epoch 0087, iter [01400, 05004], lr: 0.001000, loss: 1.2826, stu_CELoss: 0.8362 DKDLoss: 0.4465 
2022-05-03 13:44:57 - train: epoch 0087, iter [01500, 05004], lr: 0.001000, loss: 1.1868, stu_CELoss: 0.7726 DKDLoss: 0.4142 
2022-05-03 13:45:31 - train: epoch 0087, iter [01600, 05004], lr: 0.001000, loss: 1.2007, stu_CELoss: 0.7814 DKDLoss: 0.4193 
2022-05-03 13:46:04 - train: epoch 0087, iter [01700, 05004], lr: 0.001000, loss: 1.5165, stu_CELoss: 1.0556 DKDLoss: 0.4609 
2022-05-03 13:46:38 - train: epoch 0087, iter [01800, 05004], lr: 0.001000, loss: 1.2955, stu_CELoss: 0.8611 DKDLoss: 0.4344 
2022-05-03 13:47:11 - train: epoch 0087, iter [01900, 05004], lr: 0.001000, loss: 1.3362, stu_CELoss: 0.8876 DKDLoss: 0.4487 
2022-05-03 13:47:45 - train: epoch 0087, iter [02000, 05004], lr: 0.001000, loss: 1.4482, stu_CELoss: 1.0236 DKDLoss: 0.4246 
2022-05-03 13:48:19 - train: epoch 0087, iter [02100, 05004], lr: 0.001000, loss: 1.1690, stu_CELoss: 0.7745 DKDLoss: 0.3945 
2022-05-03 13:48:53 - train: epoch 0087, iter [02200, 05004], lr: 0.001000, loss: 1.3674, stu_CELoss: 0.9091 DKDLoss: 0.4584 
2022-05-03 13:49:26 - train: epoch 0087, iter [02300, 05004], lr: 0.001000, loss: 1.3816, stu_CELoss: 0.9018 DKDLoss: 0.4798 
2022-05-03 13:50:00 - train: epoch 0087, iter [02400, 05004], lr: 0.001000, loss: 1.3311, stu_CELoss: 0.8482 DKDLoss: 0.4829 
2022-05-03 13:50:33 - train: epoch 0087, iter [02500, 05004], lr: 0.001000, loss: 1.3296, stu_CELoss: 0.9155 DKDLoss: 0.4141 
2022-05-03 13:51:07 - train: epoch 0087, iter [02600, 05004], lr: 0.001000, loss: 1.0824, stu_CELoss: 0.7104 DKDLoss: 0.3721 
2022-05-03 13:51:41 - train: epoch 0087, iter [02700, 05004], lr: 0.001000, loss: 0.9844, stu_CELoss: 0.5603 DKDLoss: 0.4241 
2022-05-03 13:52:14 - train: epoch 0087, iter [02800, 05004], lr: 0.001000, loss: 1.1798, stu_CELoss: 0.7278 DKDLoss: 0.4519 
2022-05-03 13:52:48 - train: epoch 0087, iter [02900, 05004], lr: 0.001000, loss: 1.1147, stu_CELoss: 0.7189 DKDLoss: 0.3958 
2022-05-03 13:53:22 - train: epoch 0087, iter [03000, 05004], lr: 0.001000, loss: 1.3418, stu_CELoss: 0.9006 DKDLoss: 0.4412 
2022-05-03 13:53:56 - train: epoch 0087, iter [03100, 05004], lr: 0.001000, loss: 1.2873, stu_CELoss: 0.8175 DKDLoss: 0.4698 
2022-05-03 13:54:29 - train: epoch 0087, iter [03200, 05004], lr: 0.001000, loss: 1.3396, stu_CELoss: 0.8243 DKDLoss: 0.5153 
2022-05-03 13:55:03 - train: epoch 0087, iter [03300, 05004], lr: 0.001000, loss: 1.2302, stu_CELoss: 0.8467 DKDLoss: 0.3835 
2022-05-03 13:55:37 - train: epoch 0087, iter [03400, 05004], lr: 0.001000, loss: 1.4112, stu_CELoss: 0.9438 DKDLoss: 0.4674 
2022-05-03 13:56:11 - train: epoch 0087, iter [03500, 05004], lr: 0.001000, loss: 1.2064, stu_CELoss: 0.7799 DKDLoss: 0.4265 
2022-05-03 13:56:45 - train: epoch 0087, iter [03600, 05004], lr: 0.001000, loss: 1.1487, stu_CELoss: 0.7287 DKDLoss: 0.4201 
2022-05-03 13:57:19 - train: epoch 0087, iter [03700, 05004], lr: 0.001000, loss: 1.2299, stu_CELoss: 0.8063 DKDLoss: 0.4236 
2022-05-03 13:57:52 - train: epoch 0087, iter [03800, 05004], lr: 0.001000, loss: 1.2288, stu_CELoss: 0.8272 DKDLoss: 0.4015 
2022-05-03 13:58:26 - train: epoch 0087, iter [03900, 05004], lr: 0.001000, loss: 1.1935, stu_CELoss: 0.7587 DKDLoss: 0.4348 
2022-05-03 13:59:00 - train: epoch 0087, iter [04000, 05004], lr: 0.001000, loss: 1.2679, stu_CELoss: 0.7908 DKDLoss: 0.4771 
2022-05-03 13:59:34 - train: epoch 0087, iter [04100, 05004], lr: 0.001000, loss: 1.2474, stu_CELoss: 0.8489 DKDLoss: 0.3985 
2022-05-03 14:00:08 - train: epoch 0087, iter [04200, 05004], lr: 0.001000, loss: 1.3063, stu_CELoss: 0.8431 DKDLoss: 0.4633 
2022-05-03 14:00:41 - train: epoch 0087, iter [04300, 05004], lr: 0.001000, loss: 1.1166, stu_CELoss: 0.7310 DKDLoss: 0.3856 
2022-05-03 14:01:15 - train: epoch 0087, iter [04400, 05004], lr: 0.001000, loss: 1.2478, stu_CELoss: 0.7859 DKDLoss: 0.4619 
2022-05-03 14:01:49 - train: epoch 0087, iter [04500, 05004], lr: 0.001000, loss: 1.0609, stu_CELoss: 0.6703 DKDLoss: 0.3905 
2022-05-03 14:02:23 - train: epoch 0087, iter [04600, 05004], lr: 0.001000, loss: 1.3439, stu_CELoss: 0.8653 DKDLoss: 0.4785 
2022-05-03 14:02:57 - train: epoch 0087, iter [04700, 05004], lr: 0.001000, loss: 1.1773, stu_CELoss: 0.7369 DKDLoss: 0.4403 
2022-05-03 14:03:31 - train: epoch 0087, iter [04800, 05004], lr: 0.001000, loss: 1.2956, stu_CELoss: 0.8814 DKDLoss: 0.4143 
2022-05-03 14:04:05 - train: epoch 0087, iter [04900, 05004], lr: 0.001000, loss: 1.3302, stu_CELoss: 0.8540 DKDLoss: 0.4762 
2022-05-03 14:04:38 - train: epoch 0087, iter [05000, 05004], lr: 0.001000, loss: 1.3386, stu_CELoss: 0.9175 DKDLoss: 0.4212 
2022-05-03 14:04:40 - train: epoch 087, train_loss: 1.2777
2022-05-03 14:07:11 - eval: epoch: 087, tea_acc1: 78.330%, tea_acc5: 94.064%, tea_test_loss: 0.8657, stu_acc1: 77.302%, stu_acc5: 93.622%, stu_test_loss: 0.8933
2022-05-03 14:07:12 - until epoch: 087, tea_best_acc1: 78.330%, stu_best_acc1: 77.302%
2022-05-03 14:07:12 - epoch 088 lr: 0.0010000000000000002
2022-05-03 14:07:52 - train: epoch 0088, iter [00100, 05004], lr: 0.001000, loss: 1.2537, stu_CELoss: 0.7997 DKDLoss: 0.4540 
2022-05-03 14:08:25 - train: epoch 0088, iter [00200, 05004], lr: 0.001000, loss: 1.2061, stu_CELoss: 0.7597 DKDLoss: 0.4464 
2022-05-03 14:08:58 - train: epoch 0088, iter [00300, 05004], lr: 0.001000, loss: 1.3277, stu_CELoss: 0.9145 DKDLoss: 0.4132 
2022-05-03 14:09:31 - train: epoch 0088, iter [00400, 05004], lr: 0.001000, loss: 1.2763, stu_CELoss: 0.8566 DKDLoss: 0.4197 
2022-05-03 14:10:05 - train: epoch 0088, iter [00500, 05004], lr: 0.001000, loss: 1.2718, stu_CELoss: 0.8415 DKDLoss: 0.4303 
2022-05-03 14:10:38 - train: epoch 0088, iter [00600, 05004], lr: 0.001000, loss: 1.1582, stu_CELoss: 0.7439 DKDLoss: 0.4143 
2022-05-03 14:11:12 - train: epoch 0088, iter [00700, 05004], lr: 0.001000, loss: 1.1333, stu_CELoss: 0.6952 DKDLoss: 0.4381 
2022-05-03 14:11:45 - train: epoch 0088, iter [00800, 05004], lr: 0.001000, loss: 1.3171, stu_CELoss: 0.8740 DKDLoss: 0.4432 
2022-05-03 14:12:19 - train: epoch 0088, iter [00900, 05004], lr: 0.001000, loss: 1.2734, stu_CELoss: 0.8599 DKDLoss: 0.4135 
2022-05-03 14:12:53 - train: epoch 0088, iter [01000, 05004], lr: 0.001000, loss: 1.2755, stu_CELoss: 0.8146 DKDLoss: 0.4609 
2022-05-03 14:13:27 - train: epoch 0088, iter [01100, 05004], lr: 0.001000, loss: 1.0979, stu_CELoss: 0.6626 DKDLoss: 0.4353 
2022-05-03 14:14:00 - train: epoch 0088, iter [01200, 05004], lr: 0.001000, loss: 1.4034, stu_CELoss: 0.9692 DKDLoss: 0.4342 
2022-05-03 14:14:34 - train: epoch 0088, iter [01300, 05004], lr: 0.001000, loss: 1.2199, stu_CELoss: 0.7810 DKDLoss: 0.4389 
2022-05-03 14:15:08 - train: epoch 0088, iter [01400, 05004], lr: 0.001000, loss: 1.1153, stu_CELoss: 0.7459 DKDLoss: 0.3693 
2022-05-03 14:15:42 - train: epoch 0088, iter [01500, 05004], lr: 0.001000, loss: 1.2429, stu_CELoss: 0.8899 DKDLoss: 0.3530 
2022-05-03 14:16:15 - train: epoch 0088, iter [01600, 05004], lr: 0.001000, loss: 1.1901, stu_CELoss: 0.7624 DKDLoss: 0.4277 
2022-05-03 14:16:49 - train: epoch 0088, iter [01700, 05004], lr: 0.001000, loss: 1.1883, stu_CELoss: 0.7381 DKDLoss: 0.4502 
2022-05-03 14:17:23 - train: epoch 0088, iter [01800, 05004], lr: 0.001000, loss: 1.2126, stu_CELoss: 0.7919 DKDLoss: 0.4207 
2022-05-03 14:17:57 - train: epoch 0088, iter [01900, 05004], lr: 0.001000, loss: 1.3073, stu_CELoss: 0.8644 DKDLoss: 0.4428 
2022-05-03 14:18:31 - train: epoch 0088, iter [02000, 05004], lr: 0.001000, loss: 1.2177, stu_CELoss: 0.7933 DKDLoss: 0.4244 
2022-05-03 14:19:04 - train: epoch 0088, iter [02100, 05004], lr: 0.001000, loss: 1.3006, stu_CELoss: 0.8818 DKDLoss: 0.4188 
2022-05-03 14:19:38 - train: epoch 0088, iter [02200, 05004], lr: 0.001000, loss: 1.2908, stu_CELoss: 0.8302 DKDLoss: 0.4606 
2022-05-03 14:20:12 - train: epoch 0088, iter [02300, 05004], lr: 0.001000, loss: 1.2197, stu_CELoss: 0.8055 DKDLoss: 0.4142 
2022-05-03 14:20:46 - train: epoch 0088, iter [02400, 05004], lr: 0.001000, loss: 1.3982, stu_CELoss: 0.9510 DKDLoss: 0.4472 
2022-05-03 14:21:20 - train: epoch 0088, iter [02500, 05004], lr: 0.001000, loss: 1.3141, stu_CELoss: 0.9178 DKDLoss: 0.3963 
2022-05-03 14:21:54 - train: epoch 0088, iter [02600, 05004], lr: 0.001000, loss: 1.2230, stu_CELoss: 0.7686 DKDLoss: 0.4544 
2022-05-03 14:22:28 - train: epoch 0088, iter [02700, 05004], lr: 0.001000, loss: 1.3814, stu_CELoss: 0.9606 DKDLoss: 0.4208 
2022-05-03 14:23:02 - train: epoch 0088, iter [02800, 05004], lr: 0.001000, loss: 1.4633, stu_CELoss: 1.0030 DKDLoss: 0.4603 
2022-05-03 14:23:36 - train: epoch 0088, iter [02900, 05004], lr: 0.001000, loss: 1.3459, stu_CELoss: 0.8995 DKDLoss: 0.4465 
2022-05-03 14:24:10 - train: epoch 0088, iter [03000, 05004], lr: 0.001000, loss: 1.4516, stu_CELoss: 1.0015 DKDLoss: 0.4500 
2022-05-03 14:24:44 - train: epoch 0088, iter [03100, 05004], lr: 0.001000, loss: 1.3348, stu_CELoss: 0.9394 DKDLoss: 0.3954 
2022-05-03 14:25:18 - train: epoch 0088, iter [03200, 05004], lr: 0.001000, loss: 1.2012, stu_CELoss: 0.7879 DKDLoss: 0.4133 
2022-05-03 14:25:52 - train: epoch 0088, iter [03300, 05004], lr: 0.001000, loss: 1.0739, stu_CELoss: 0.7304 DKDLoss: 0.3435 
2022-05-03 14:26:26 - train: epoch 0088, iter [03400, 05004], lr: 0.001000, loss: 1.0862, stu_CELoss: 0.6821 DKDLoss: 0.4041 
2022-05-03 14:27:00 - train: epoch 0088, iter [03500, 05004], lr: 0.001000, loss: 1.2136, stu_CELoss: 0.7874 DKDLoss: 0.4261 
2022-05-03 14:27:33 - train: epoch 0088, iter [03600, 05004], lr: 0.001000, loss: 1.2972, stu_CELoss: 0.8357 DKDLoss: 0.4615 
2022-05-03 14:28:07 - train: epoch 0088, iter [03700, 05004], lr: 0.001000, loss: 1.3819, stu_CELoss: 0.9221 DKDLoss: 0.4598 
2022-05-03 14:28:42 - train: epoch 0088, iter [03800, 05004], lr: 0.001000, loss: 1.3296, stu_CELoss: 0.8927 DKDLoss: 0.4368 
2022-05-03 14:29:16 - train: epoch 0088, iter [03900, 05004], lr: 0.001000, loss: 1.3260, stu_CELoss: 0.8859 DKDLoss: 0.4401 
2022-05-03 14:29:50 - train: epoch 0088, iter [04000, 05004], lr: 0.001000, loss: 1.1728, stu_CELoss: 0.7914 DKDLoss: 0.3814 
2022-05-03 14:30:24 - train: epoch 0088, iter [04100, 05004], lr: 0.001000, loss: 1.2320, stu_CELoss: 0.8619 DKDLoss: 0.3701 
2022-05-03 14:30:57 - train: epoch 0088, iter [04200, 05004], lr: 0.001000, loss: 1.4043, stu_CELoss: 0.9549 DKDLoss: 0.4495 
2022-05-03 14:31:31 - train: epoch 0088, iter [04300, 05004], lr: 0.001000, loss: 1.1934, stu_CELoss: 0.7845 DKDLoss: 0.4089 
2022-05-03 14:32:05 - train: epoch 0088, iter [04400, 05004], lr: 0.001000, loss: 1.1785, stu_CELoss: 0.7917 DKDLoss: 0.3868 
2022-05-03 14:32:39 - train: epoch 0088, iter [04500, 05004], lr: 0.001000, loss: 1.2729, stu_CELoss: 0.7971 DKDLoss: 0.4757 
2022-05-03 14:33:13 - train: epoch 0088, iter [04600, 05004], lr: 0.001000, loss: 1.3736, stu_CELoss: 0.9690 DKDLoss: 0.4046 
2022-05-03 14:33:47 - train: epoch 0088, iter [04700, 05004], lr: 0.001000, loss: 1.4532, stu_CELoss: 0.9463 DKDLoss: 0.5069 
2022-05-03 14:34:21 - train: epoch 0088, iter [04800, 05004], lr: 0.001000, loss: 1.2621, stu_CELoss: 0.8115 DKDLoss: 0.4505 
2022-05-03 14:34:55 - train: epoch 0088, iter [04900, 05004], lr: 0.001000, loss: 1.0961, stu_CELoss: 0.6769 DKDLoss: 0.4192 
2022-05-03 14:35:28 - train: epoch 0088, iter [05000, 05004], lr: 0.001000, loss: 1.3179, stu_CELoss: 0.9498 DKDLoss: 0.3682 
2022-05-03 14:35:30 - train: epoch 088, train_loss: 1.2731
2022-05-03 14:38:01 - eval: epoch: 088, tea_acc1: 78.330%, tea_acc5: 94.064%, tea_test_loss: 0.8657, stu_acc1: 77.408%, stu_acc5: 93.554%, stu_test_loss: 0.8934
2022-05-03 14:38:02 - until epoch: 088, tea_best_acc1: 78.330%, stu_best_acc1: 77.408%
2022-05-03 14:38:02 - epoch 089 lr: 0.0010000000000000002
2022-05-03 14:38:42 - train: epoch 0089, iter [00100, 05004], lr: 0.001000, loss: 1.2273, stu_CELoss: 0.8278 DKDLoss: 0.3995 
2022-05-03 14:39:15 - train: epoch 0089, iter [00200, 05004], lr: 0.001000, loss: 1.1412, stu_CELoss: 0.7727 DKDLoss: 0.3685 
2022-05-03 14:39:49 - train: epoch 0089, iter [00300, 05004], lr: 0.001000, loss: 1.3851, stu_CELoss: 0.9214 DKDLoss: 0.4636 
2022-05-03 14:40:22 - train: epoch 0089, iter [00400, 05004], lr: 0.001000, loss: 1.2167, stu_CELoss: 0.8213 DKDLoss: 0.3955 
2022-05-03 14:40:56 - train: epoch 0089, iter [00500, 05004], lr: 0.001000, loss: 1.2671, stu_CELoss: 0.8417 DKDLoss: 0.4254 
2022-05-03 14:41:30 - train: epoch 0089, iter [00600, 05004], lr: 0.001000, loss: 1.1698, stu_CELoss: 0.7601 DKDLoss: 0.4096 
2022-05-03 14:42:03 - train: epoch 0089, iter [00700, 05004], lr: 0.001000, loss: 1.3201, stu_CELoss: 0.8712 DKDLoss: 0.4489 
2022-05-03 14:42:37 - train: epoch 0089, iter [00800, 05004], lr: 0.001000, loss: 1.5203, stu_CELoss: 1.0389 DKDLoss: 0.4815 
2022-05-03 14:43:11 - train: epoch 0089, iter [00900, 05004], lr: 0.001000, loss: 1.1021, stu_CELoss: 0.7138 DKDLoss: 0.3883 
2022-05-03 14:43:44 - train: epoch 0089, iter [01000, 05004], lr: 0.001000, loss: 1.1442, stu_CELoss: 0.7319 DKDLoss: 0.4122 
2022-05-03 14:44:18 - train: epoch 0089, iter [01100, 05004], lr: 0.001000, loss: 1.2103, stu_CELoss: 0.8047 DKDLoss: 0.4057 
2022-05-03 14:44:52 - train: epoch 0089, iter [01200, 05004], lr: 0.001000, loss: 1.2179, stu_CELoss: 0.7794 DKDLoss: 0.4385 
2022-05-03 14:45:25 - train: epoch 0089, iter [01300, 05004], lr: 0.001000, loss: 1.1725, stu_CELoss: 0.8036 DKDLoss: 0.3689 
2022-05-03 14:45:59 - train: epoch 0089, iter [01400, 05004], lr: 0.001000, loss: 1.2462, stu_CELoss: 0.7865 DKDLoss: 0.4597 
2022-05-03 14:46:33 - train: epoch 0089, iter [01500, 05004], lr: 0.001000, loss: 1.3550, stu_CELoss: 0.9312 DKDLoss: 0.4238 
2022-05-03 14:47:07 - train: epoch 0089, iter [01600, 05004], lr: 0.001000, loss: 1.1876, stu_CELoss: 0.7788 DKDLoss: 0.4088 
2022-05-03 14:47:41 - train: epoch 0089, iter [01700, 05004], lr: 0.001000, loss: 1.3409, stu_CELoss: 0.9241 DKDLoss: 0.4167 
2022-05-03 14:48:14 - train: epoch 0089, iter [01800, 05004], lr: 0.001000, loss: 1.1457, stu_CELoss: 0.7382 DKDLoss: 0.4075 
2022-05-03 14:48:48 - train: epoch 0089, iter [01900, 05004], lr: 0.001000, loss: 1.1719, stu_CELoss: 0.7549 DKDLoss: 0.4171 
2022-05-03 14:49:22 - train: epoch 0089, iter [02000, 05004], lr: 0.001000, loss: 1.1133, stu_CELoss: 0.6837 DKDLoss: 0.4296 
2022-05-03 14:49:56 - train: epoch 0089, iter [02100, 05004], lr: 0.001000, loss: 1.2017, stu_CELoss: 0.7920 DKDLoss: 0.4097 
2022-05-03 14:50:29 - train: epoch 0089, iter [02200, 05004], lr: 0.001000, loss: 1.3820, stu_CELoss: 0.9214 DKDLoss: 0.4606 
2022-05-03 14:51:03 - train: epoch 0089, iter [02300, 05004], lr: 0.001000, loss: 1.2974, stu_CELoss: 0.8656 DKDLoss: 0.4318 
2022-05-03 14:51:37 - train: epoch 0089, iter [02400, 05004], lr: 0.001000, loss: 1.3163, stu_CELoss: 0.8466 DKDLoss: 0.4697 
2022-05-03 14:52:11 - train: epoch 0089, iter [02500, 05004], lr: 0.001000, loss: 1.5120, stu_CELoss: 0.9766 DKDLoss: 0.5354 
2022-05-03 14:52:44 - train: epoch 0089, iter [02600, 05004], lr: 0.001000, loss: 1.1493, stu_CELoss: 0.7205 DKDLoss: 0.4288 
2022-05-03 14:53:18 - train: epoch 0089, iter [02700, 05004], lr: 0.001000, loss: 1.1048, stu_CELoss: 0.7005 DKDLoss: 0.4044 
2022-05-03 14:53:52 - train: epoch 0089, iter [02800, 05004], lr: 0.001000, loss: 1.2400, stu_CELoss: 0.8288 DKDLoss: 0.4112 
2022-05-03 14:54:25 - train: epoch 0089, iter [02900, 05004], lr: 0.001000, loss: 1.2924, stu_CELoss: 0.8590 DKDLoss: 0.4334 
2022-05-03 14:54:59 - train: epoch 0089, iter [03000, 05004], lr: 0.001000, loss: 1.1518, stu_CELoss: 0.7492 DKDLoss: 0.4026 
2022-05-03 14:55:33 - train: epoch 0089, iter [03100, 05004], lr: 0.001000, loss: 1.2366, stu_CELoss: 0.8710 DKDLoss: 0.3656 
2022-05-03 14:56:07 - train: epoch 0089, iter [03200, 05004], lr: 0.001000, loss: 1.3050, stu_CELoss: 0.8466 DKDLoss: 0.4584 
2022-05-03 14:56:42 - train: epoch 0089, iter [03300, 05004], lr: 0.001000, loss: 1.3516, stu_CELoss: 0.9006 DKDLoss: 0.4510 
2022-05-03 14:57:16 - train: epoch 0089, iter [03400, 05004], lr: 0.001000, loss: 1.4745, stu_CELoss: 1.0367 DKDLoss: 0.4378 
2022-05-03 14:57:50 - train: epoch 0089, iter [03500, 05004], lr: 0.001000, loss: 1.0388, stu_CELoss: 0.6441 DKDLoss: 0.3946 
2022-05-03 14:58:24 - train: epoch 0089, iter [03600, 05004], lr: 0.001000, loss: 1.3382, stu_CELoss: 0.9062 DKDLoss: 0.4320 
2022-05-03 14:58:58 - train: epoch 0089, iter [03700, 05004], lr: 0.001000, loss: 1.3462, stu_CELoss: 0.9049 DKDLoss: 0.4413 
2022-05-03 14:59:31 - train: epoch 0089, iter [03800, 05004], lr: 0.001000, loss: 1.2209, stu_CELoss: 0.8259 DKDLoss: 0.3950 
2022-05-03 15:00:06 - train: epoch 0089, iter [03900, 05004], lr: 0.001000, loss: 1.3411, stu_CELoss: 0.9264 DKDLoss: 0.4147 
2022-05-03 15:00:39 - train: epoch 0089, iter [04000, 05004], lr: 0.001000, loss: 1.2318, stu_CELoss: 0.8083 DKDLoss: 0.4235 
2022-05-03 15:01:13 - train: epoch 0089, iter [04100, 05004], lr: 0.001000, loss: 1.4909, stu_CELoss: 1.0310 DKDLoss: 0.4599 
2022-05-03 15:01:47 - train: epoch 0089, iter [04200, 05004], lr: 0.001000, loss: 1.3693, stu_CELoss: 0.9436 DKDLoss: 0.4257 
2022-05-03 15:02:20 - train: epoch 0089, iter [04300, 05004], lr: 0.001000, loss: 1.3342, stu_CELoss: 0.8851 DKDLoss: 0.4492 
2022-05-03 15:02:54 - train: epoch 0089, iter [04400, 05004], lr: 0.001000, loss: 1.3265, stu_CELoss: 0.8760 DKDLoss: 0.4504 
2022-05-03 15:03:29 - train: epoch 0089, iter [04500, 05004], lr: 0.001000, loss: 1.1612, stu_CELoss: 0.7215 DKDLoss: 0.4397 
2022-05-03 15:04:03 - train: epoch 0089, iter [04600, 05004], lr: 0.001000, loss: 1.0987, stu_CELoss: 0.7116 DKDLoss: 0.3870 
2022-05-03 15:04:37 - train: epoch 0089, iter [04700, 05004], lr: 0.001000, loss: 1.2763, stu_CELoss: 0.8611 DKDLoss: 0.4152 
2022-05-03 15:05:10 - train: epoch 0089, iter [04800, 05004], lr: 0.001000, loss: 1.2024, stu_CELoss: 0.8108 DKDLoss: 0.3916 
2022-05-03 15:05:44 - train: epoch 0089, iter [04900, 05004], lr: 0.001000, loss: 1.3576, stu_CELoss: 0.8974 DKDLoss: 0.4603 
2022-05-03 15:06:18 - train: epoch 0089, iter [05000, 05004], lr: 0.001000, loss: 1.1652, stu_CELoss: 0.7410 DKDLoss: 0.4242 
2022-05-03 15:06:19 - train: epoch 089, train_loss: 1.2677
2022-05-03 15:08:51 - eval: epoch: 089, tea_acc1: 78.330%, tea_acc5: 94.064%, tea_test_loss: 0.8657, stu_acc1: 77.184%, stu_acc5: 93.506%, stu_test_loss: 0.8988
2022-05-03 15:08:52 - until epoch: 089, tea_best_acc1: 78.330%, stu_best_acc1: 77.408%
2022-05-03 15:08:52 - epoch 090 lr: 0.0010000000000000002
2022-05-03 15:09:32 - train: epoch 0090, iter [00100, 05004], lr: 0.001000, loss: 1.2844, stu_CELoss: 0.8400 DKDLoss: 0.4444 
2022-05-03 15:10:06 - train: epoch 0090, iter [00200, 05004], lr: 0.001000, loss: 1.1516, stu_CELoss: 0.7079 DKDLoss: 0.4437 
2022-05-03 15:10:40 - train: epoch 0090, iter [00300, 05004], lr: 0.001000, loss: 1.1186, stu_CELoss: 0.7083 DKDLoss: 0.4103 
2022-05-03 15:11:14 - train: epoch 0090, iter [00400, 05004], lr: 0.001000, loss: 1.2054, stu_CELoss: 0.8344 DKDLoss: 0.3710 
2022-05-03 15:11:48 - train: epoch 0090, iter [00500, 05004], lr: 0.001000, loss: 1.2158, stu_CELoss: 0.8022 DKDLoss: 0.4136 
2022-05-03 15:12:21 - train: epoch 0090, iter [00600, 05004], lr: 0.001000, loss: 1.6401, stu_CELoss: 1.2150 DKDLoss: 0.4251 
2022-05-03 15:12:55 - train: epoch 0090, iter [00700, 05004], lr: 0.001000, loss: 1.2456, stu_CELoss: 0.8162 DKDLoss: 0.4294 
2022-05-03 15:13:29 - train: epoch 0090, iter [00800, 05004], lr: 0.001000, loss: 1.3447, stu_CELoss: 0.9523 DKDLoss: 0.3924 
2022-05-03 15:14:03 - train: epoch 0090, iter [00900, 05004], lr: 0.001000, loss: 1.2125, stu_CELoss: 0.7840 DKDLoss: 0.4286 
2022-05-03 15:14:37 - train: epoch 0090, iter [01000, 05004], lr: 0.001000, loss: 1.1717, stu_CELoss: 0.7691 DKDLoss: 0.4027 
2022-05-03 15:15:12 - train: epoch 0090, iter [01100, 05004], lr: 0.001000, loss: 1.3226, stu_CELoss: 0.9095 DKDLoss: 0.4131 
2022-05-03 15:15:46 - train: epoch 0090, iter [01200, 05004], lr: 0.001000, loss: 1.2384, stu_CELoss: 0.8131 DKDLoss: 0.4253 
2022-05-03 15:16:20 - train: epoch 0090, iter [01300, 05004], lr: 0.001000, loss: 1.2945, stu_CELoss: 0.8464 DKDLoss: 0.4480 
2022-05-03 15:16:54 - train: epoch 0090, iter [01400, 05004], lr: 0.001000, loss: 1.1789, stu_CELoss: 0.7923 DKDLoss: 0.3866 
2022-05-03 15:17:28 - train: epoch 0090, iter [01500, 05004], lr: 0.001000, loss: 1.4493, stu_CELoss: 0.9895 DKDLoss: 0.4598 
2022-05-03 15:18:02 - train: epoch 0090, iter [01600, 05004], lr: 0.001000, loss: 1.2349, stu_CELoss: 0.8244 DKDLoss: 0.4104 
2022-05-03 15:18:35 - train: epoch 0090, iter [01700, 05004], lr: 0.001000, loss: 1.1635, stu_CELoss: 0.7765 DKDLoss: 0.3870 
2022-05-03 15:19:09 - train: epoch 0090, iter [01800, 05004], lr: 0.001000, loss: 1.2057, stu_CELoss: 0.8233 DKDLoss: 0.3823 
2022-05-03 15:19:43 - train: epoch 0090, iter [01900, 05004], lr: 0.001000, loss: 1.1986, stu_CELoss: 0.7977 DKDLoss: 0.4009 
2022-05-03 15:20:17 - train: epoch 0090, iter [02000, 05004], lr: 0.001000, loss: 1.2580, stu_CELoss: 0.8076 DKDLoss: 0.4505 
2022-05-03 15:20:51 - train: epoch 0090, iter [02100, 05004], lr: 0.001000, loss: 1.2693, stu_CELoss: 0.8449 DKDLoss: 0.4244 
2022-05-03 15:21:24 - train: epoch 0090, iter [02200, 05004], lr: 0.001000, loss: 1.3445, stu_CELoss: 0.9042 DKDLoss: 0.4403 
2022-05-03 15:21:59 - train: epoch 0090, iter [02300, 05004], lr: 0.001000, loss: 1.5166, stu_CELoss: 1.0793 DKDLoss: 0.4372 
2022-05-03 15:22:33 - train: epoch 0090, iter [02400, 05004], lr: 0.001000, loss: 1.2220, stu_CELoss: 0.8119 DKDLoss: 0.4100 
2022-05-03 15:23:07 - train: epoch 0090, iter [02500, 05004], lr: 0.001000, loss: 1.3029, stu_CELoss: 0.8801 DKDLoss: 0.4227 
2022-05-03 15:23:41 - train: epoch 0090, iter [02600, 05004], lr: 0.001000, loss: 1.2209, stu_CELoss: 0.8045 DKDLoss: 0.4165 
2022-05-03 15:24:16 - train: epoch 0090, iter [02700, 05004], lr: 0.001000, loss: 1.2085, stu_CELoss: 0.8289 DKDLoss: 0.3795 
2022-05-03 15:24:50 - train: epoch 0090, iter [02800, 05004], lr: 0.001000, loss: 1.3188, stu_CELoss: 0.8829 DKDLoss: 0.4359 
2022-05-03 15:25:24 - train: epoch 0090, iter [02900, 05004], lr: 0.001000, loss: 1.3452, stu_CELoss: 0.9374 DKDLoss: 0.4078 
2022-05-03 15:25:59 - train: epoch 0090, iter [03000, 05004], lr: 0.001000, loss: 1.4089, stu_CELoss: 0.9732 DKDLoss: 0.4357 
2022-05-03 15:26:33 - train: epoch 0090, iter [03100, 05004], lr: 0.001000, loss: 1.0665, stu_CELoss: 0.6653 DKDLoss: 0.4012 
2022-05-03 15:27:08 - train: epoch 0090, iter [03200, 05004], lr: 0.001000, loss: 1.0665, stu_CELoss: 0.6791 DKDLoss: 0.3874 
2022-05-03 15:27:42 - train: epoch 0090, iter [03300, 05004], lr: 0.001000, loss: 1.3299, stu_CELoss: 0.8997 DKDLoss: 0.4301 
2022-05-03 15:28:17 - train: epoch 0090, iter [03400, 05004], lr: 0.001000, loss: 1.1974, stu_CELoss: 0.7949 DKDLoss: 0.4025 
2022-05-03 15:28:51 - train: epoch 0090, iter [03500, 05004], lr: 0.001000, loss: 1.3083, stu_CELoss: 0.8699 DKDLoss: 0.4384 
2022-05-03 15:29:25 - train: epoch 0090, iter [03600, 05004], lr: 0.001000, loss: 1.1760, stu_CELoss: 0.7633 DKDLoss: 0.4127 
2022-05-03 15:30:00 - train: epoch 0090, iter [03700, 05004], lr: 0.001000, loss: 1.1679, stu_CELoss: 0.7392 DKDLoss: 0.4287 
2022-05-03 15:30:34 - train: epoch 0090, iter [03800, 05004], lr: 0.001000, loss: 1.2581, stu_CELoss: 0.8166 DKDLoss: 0.4415 
2022-05-03 15:31:08 - train: epoch 0090, iter [03900, 05004], lr: 0.001000, loss: 1.2033, stu_CELoss: 0.7899 DKDLoss: 0.4133 
2022-05-03 15:31:42 - train: epoch 0090, iter [04000, 05004], lr: 0.001000, loss: 1.2468, stu_CELoss: 0.8219 DKDLoss: 0.4249 
2022-05-03 15:32:16 - train: epoch 0090, iter [04100, 05004], lr: 0.001000, loss: 1.4190, stu_CELoss: 0.9571 DKDLoss: 0.4619 
2022-05-03 15:32:51 - train: epoch 0090, iter [04200, 05004], lr: 0.001000, loss: 1.4294, stu_CELoss: 0.9933 DKDLoss: 0.4362 
2022-05-03 15:33:25 - train: epoch 0090, iter [04300, 05004], lr: 0.001000, loss: 1.3271, stu_CELoss: 0.8471 DKDLoss: 0.4801 
2022-05-03 15:33:59 - train: epoch 0090, iter [04400, 05004], lr: 0.001000, loss: 1.2954, stu_CELoss: 0.8674 DKDLoss: 0.4280 
2022-05-03 15:34:33 - train: epoch 0090, iter [04500, 05004], lr: 0.001000, loss: 1.3340, stu_CELoss: 0.8576 DKDLoss: 0.4765 
2022-05-03 15:35:07 - train: epoch 0090, iter [04600, 05004], lr: 0.001000, loss: 1.1785, stu_CELoss: 0.7738 DKDLoss: 0.4047 
2022-05-03 15:35:41 - train: epoch 0090, iter [04700, 05004], lr: 0.001000, loss: 1.2481, stu_CELoss: 0.8271 DKDLoss: 0.4210 
2022-05-03 15:36:15 - train: epoch 0090, iter [04800, 05004], lr: 0.001000, loss: 1.3789, stu_CELoss: 0.9135 DKDLoss: 0.4655 
2022-05-03 15:36:50 - train: epoch 0090, iter [04900, 05004], lr: 0.001000, loss: 1.1926, stu_CELoss: 0.7901 DKDLoss: 0.4024 
2022-05-03 15:37:24 - train: epoch 0090, iter [05000, 05004], lr: 0.001000, loss: 1.1080, stu_CELoss: 0.7103 DKDLoss: 0.3976 
2022-05-03 15:37:25 - train: epoch 090, train_loss: 1.2672
2022-05-03 15:39:58 - eval: epoch: 090, tea_acc1: 78.330%, tea_acc5: 94.064%, tea_test_loss: 0.8657, stu_acc1: 77.380%, stu_acc5: 93.616%, stu_test_loss: 0.8965
2022-05-03 15:39:58 - until epoch: 090, tea_best_acc1: 78.330%, stu_best_acc1: 77.408%
2022-05-03 15:39:58 - epoch 091 lr: 0.00010000000000000003
2022-05-03 15:40:39 - train: epoch 0091, iter [00100, 05004], lr: 0.000100, loss: 1.2126, stu_CELoss: 0.8004 DKDLoss: 0.4122 
2022-05-03 15:41:12 - train: epoch 0091, iter [00200, 05004], lr: 0.000100, loss: 1.2939, stu_CELoss: 0.8939 DKDLoss: 0.4000 
2022-05-03 15:41:45 - train: epoch 0091, iter [00300, 05004], lr: 0.000100, loss: 1.2806, stu_CELoss: 0.8635 DKDLoss: 0.4171 
2022-05-03 15:42:19 - train: epoch 0091, iter [00400, 05004], lr: 0.000100, loss: 1.2488, stu_CELoss: 0.8207 DKDLoss: 0.4282 
2022-05-03 15:42:53 - train: epoch 0091, iter [00500, 05004], lr: 0.000100, loss: 1.0946, stu_CELoss: 0.6669 DKDLoss: 0.4278 
2022-05-03 15:43:26 - train: epoch 0091, iter [00600, 05004], lr: 0.000100, loss: 1.4401, stu_CELoss: 0.9972 DKDLoss: 0.4429 
2022-05-03 15:43:59 - train: epoch 0091, iter [00700, 05004], lr: 0.000100, loss: 1.4185, stu_CELoss: 1.0032 DKDLoss: 0.4153 
2022-05-03 15:44:33 - train: epoch 0091, iter [00800, 05004], lr: 0.000100, loss: 1.1854, stu_CELoss: 0.7991 DKDLoss: 0.3862 
2022-05-03 15:45:06 - train: epoch 0091, iter [00900, 05004], lr: 0.000100, loss: 1.2337, stu_CELoss: 0.8442 DKDLoss: 0.3895 
2022-05-03 15:45:39 - train: epoch 0091, iter [01000, 05004], lr: 0.000100, loss: 1.0273, stu_CELoss: 0.6228 DKDLoss: 0.4045 
2022-05-03 15:46:12 - train: epoch 0091, iter [01100, 05004], lr: 0.000100, loss: 1.1187, stu_CELoss: 0.7285 DKDLoss: 0.3902 
2022-05-03 15:46:45 - train: epoch 0091, iter [01200, 05004], lr: 0.000100, loss: 1.3635, stu_CELoss: 0.9911 DKDLoss: 0.3724 
2022-05-03 15:47:19 - train: epoch 0091, iter [01300, 05004], lr: 0.000100, loss: 1.2482, stu_CELoss: 0.8169 DKDLoss: 0.4313 
2022-05-03 15:47:52 - train: epoch 0091, iter [01400, 05004], lr: 0.000100, loss: 1.2749, stu_CELoss: 0.9064 DKDLoss: 0.3685 
2022-05-03 15:48:26 - train: epoch 0091, iter [01500, 05004], lr: 0.000100, loss: 1.2400, stu_CELoss: 0.8088 DKDLoss: 0.4312 
2022-05-03 15:48:59 - train: epoch 0091, iter [01600, 05004], lr: 0.000100, loss: 1.1518, stu_CELoss: 0.7618 DKDLoss: 0.3900 
2022-05-03 15:49:33 - train: epoch 0091, iter [01700, 05004], lr: 0.000100, loss: 1.2061, stu_CELoss: 0.8048 DKDLoss: 0.4013 
2022-05-03 15:50:07 - train: epoch 0091, iter [01800, 05004], lr: 0.000100, loss: 1.4091, stu_CELoss: 0.9501 DKDLoss: 0.4590 
2022-05-03 15:50:41 - train: epoch 0091, iter [01900, 05004], lr: 0.000100, loss: 1.2041, stu_CELoss: 0.8517 DKDLoss: 0.3523 
2022-05-03 15:51:15 - train: epoch 0091, iter [02000, 05004], lr: 0.000100, loss: 0.9705, stu_CELoss: 0.5903 DKDLoss: 0.3802 
2022-05-03 15:51:49 - train: epoch 0091, iter [02100, 05004], lr: 0.000100, loss: 1.0872, stu_CELoss: 0.7066 DKDLoss: 0.3806 
2022-05-03 15:52:23 - train: epoch 0091, iter [02200, 05004], lr: 0.000100, loss: 1.4213, stu_CELoss: 0.9628 DKDLoss: 0.4584 
2022-05-03 15:52:57 - train: epoch 0091, iter [02300, 05004], lr: 0.000100, loss: 1.2359, stu_CELoss: 0.8373 DKDLoss: 0.3986 
2022-05-03 15:53:31 - train: epoch 0091, iter [02400, 05004], lr: 0.000100, loss: 1.1233, stu_CELoss: 0.7004 DKDLoss: 0.4229 
2022-05-03 15:54:06 - train: epoch 0091, iter [02500, 05004], lr: 0.000100, loss: 1.3395, stu_CELoss: 0.9379 DKDLoss: 0.4016 
2022-05-03 15:54:40 - train: epoch 0091, iter [02600, 05004], lr: 0.000100, loss: 1.1318, stu_CELoss: 0.7555 DKDLoss: 0.3762 
2022-05-03 15:55:14 - train: epoch 0091, iter [02700, 05004], lr: 0.000100, loss: 1.2565, stu_CELoss: 0.8503 DKDLoss: 0.4062 
2022-05-03 15:55:48 - train: epoch 0091, iter [02800, 05004], lr: 0.000100, loss: 1.2262, stu_CELoss: 0.7813 DKDLoss: 0.4449 
2022-05-03 15:56:21 - train: epoch 0091, iter [02900, 05004], lr: 0.000100, loss: 1.4023, stu_CELoss: 1.0225 DKDLoss: 0.3798 
2022-05-03 15:56:54 - train: epoch 0091, iter [03000, 05004], lr: 0.000100, loss: 1.3271, stu_CELoss: 0.9001 DKDLoss: 0.4270 
2022-05-03 15:57:28 - train: epoch 0091, iter [03100, 05004], lr: 0.000100, loss: 1.1335, stu_CELoss: 0.7264 DKDLoss: 0.4071 
2022-05-03 15:58:02 - train: epoch 0091, iter [03200, 05004], lr: 0.000100, loss: 1.2723, stu_CELoss: 0.8144 DKDLoss: 0.4579 
2022-05-03 15:58:36 - train: epoch 0091, iter [03300, 05004], lr: 0.000100, loss: 1.2084, stu_CELoss: 0.7993 DKDLoss: 0.4092 
2022-05-03 15:59:10 - train: epoch 0091, iter [03400, 05004], lr: 0.000100, loss: 1.2078, stu_CELoss: 0.7662 DKDLoss: 0.4417 
2022-05-03 15:59:44 - train: epoch 0091, iter [03500, 05004], lr: 0.000100, loss: 1.0738, stu_CELoss: 0.6830 DKDLoss: 0.3908 
2022-05-03 16:00:19 - train: epoch 0091, iter [03600, 05004], lr: 0.000100, loss: 1.2312, stu_CELoss: 0.7819 DKDLoss: 0.4492 
2022-05-03 16:00:53 - train: epoch 0091, iter [03700, 05004], lr: 0.000100, loss: 1.3352, stu_CELoss: 0.8774 DKDLoss: 0.4578 
2022-05-03 16:01:27 - train: epoch 0091, iter [03800, 05004], lr: 0.000100, loss: 1.1153, stu_CELoss: 0.7462 DKDLoss: 0.3691 
2022-05-03 16:02:01 - train: epoch 0091, iter [03900, 05004], lr: 0.000100, loss: 1.2625, stu_CELoss: 0.8868 DKDLoss: 0.3757 
2022-05-03 16:02:35 - train: epoch 0091, iter [04000, 05004], lr: 0.000100, loss: 1.2039, stu_CELoss: 0.7767 DKDLoss: 0.4272 
2022-05-03 16:03:09 - train: epoch 0091, iter [04100, 05004], lr: 0.000100, loss: 1.3335, stu_CELoss: 0.9082 DKDLoss: 0.4253 
2022-05-03 16:03:44 - train: epoch 0091, iter [04200, 05004], lr: 0.000100, loss: 1.2598, stu_CELoss: 0.8497 DKDLoss: 0.4101 
2022-05-03 16:04:18 - train: epoch 0091, iter [04300, 05004], lr: 0.000100, loss: 1.1507, stu_CELoss: 0.7449 DKDLoss: 0.4058 
2022-05-03 16:04:52 - train: epoch 0091, iter [04400, 05004], lr: 0.000100, loss: 1.1012, stu_CELoss: 0.7126 DKDLoss: 0.3886 
2022-05-03 16:05:26 - train: epoch 0091, iter [04500, 05004], lr: 0.000100, loss: 1.1897, stu_CELoss: 0.8143 DKDLoss: 0.3754 
2022-05-03 16:06:00 - train: epoch 0091, iter [04600, 05004], lr: 0.000100, loss: 1.2856, stu_CELoss: 0.8829 DKDLoss: 0.4027 
2022-05-03 16:06:34 - train: epoch 0091, iter [04700, 05004], lr: 0.000100, loss: 1.2220, stu_CELoss: 0.8332 DKDLoss: 0.3888 
2022-05-03 16:07:08 - train: epoch 0091, iter [04800, 05004], lr: 0.000100, loss: 1.1530, stu_CELoss: 0.7917 DKDLoss: 0.3612 
2022-05-03 16:07:42 - train: epoch 0091, iter [04900, 05004], lr: 0.000100, loss: 1.1265, stu_CELoss: 0.7277 DKDLoss: 0.3988 
2022-05-03 16:08:15 - train: epoch 0091, iter [05000, 05004], lr: 0.000100, loss: 1.3821, stu_CELoss: 0.9814 DKDLoss: 0.4008 
2022-05-03 16:08:17 - train: epoch 091, train_loss: 1.2257
2022-05-03 16:10:44 - eval: epoch: 091, tea_acc1: 78.330%, tea_acc5: 94.064%, tea_test_loss: 0.8657, stu_acc1: 77.562%, stu_acc5: 93.760%, stu_test_loss: 0.8849
2022-05-03 16:10:45 - until epoch: 091, tea_best_acc1: 78.330%, stu_best_acc1: 77.562%
2022-05-03 16:10:45 - epoch 092 lr: 0.00010000000000000003
2022-05-03 16:11:25 - train: epoch 0092, iter [00100, 05004], lr: 0.000100, loss: 1.1077, stu_CELoss: 0.7156 DKDLoss: 0.3921 
2022-05-03 16:11:57 - train: epoch 0092, iter [00200, 05004], lr: 0.000100, loss: 1.3015, stu_CELoss: 0.9242 DKDLoss: 0.3773 
2022-05-03 16:12:30 - train: epoch 0092, iter [00300, 05004], lr: 0.000100, loss: 1.1831, stu_CELoss: 0.7992 DKDLoss: 0.3840 
2022-05-03 16:13:03 - train: epoch 0092, iter [00400, 05004], lr: 0.000100, loss: 1.0712, stu_CELoss: 0.6616 DKDLoss: 0.4097 
2022-05-03 16:13:36 - train: epoch 0092, iter [00500, 05004], lr: 0.000100, loss: 1.1424, stu_CELoss: 0.7406 DKDLoss: 0.4018 
2022-05-03 16:14:08 - train: epoch 0092, iter [00600, 05004], lr: 0.000100, loss: 1.2737, stu_CELoss: 0.8162 DKDLoss: 0.4575 
2022-05-03 16:14:41 - train: epoch 0092, iter [00700, 05004], lr: 0.000100, loss: 1.2543, stu_CELoss: 0.8310 DKDLoss: 0.4233 
2022-05-03 16:15:14 - train: epoch 0092, iter [00800, 05004], lr: 0.000100, loss: 1.3052, stu_CELoss: 0.8990 DKDLoss: 0.4062 
2022-05-03 16:15:46 - train: epoch 0092, iter [00900, 05004], lr: 0.000100, loss: 1.3567, stu_CELoss: 0.9438 DKDLoss: 0.4129 
2022-05-03 16:16:18 - train: epoch 0092, iter [01000, 05004], lr: 0.000100, loss: 1.1350, stu_CELoss: 0.7194 DKDLoss: 0.4156 
2022-05-03 16:16:51 - train: epoch 0092, iter [01100, 05004], lr: 0.000100, loss: 1.0634, stu_CELoss: 0.7242 DKDLoss: 0.3392 
2022-05-03 16:17:24 - train: epoch 0092, iter [01200, 05004], lr: 0.000100, loss: 1.0530, stu_CELoss: 0.6955 DKDLoss: 0.3575 
2022-05-03 16:17:57 - train: epoch 0092, iter [01300, 05004], lr: 0.000100, loss: 1.2181, stu_CELoss: 0.8366 DKDLoss: 0.3815 
2022-05-03 16:18:30 - train: epoch 0092, iter [01400, 05004], lr: 0.000100, loss: 1.1095, stu_CELoss: 0.7198 DKDLoss: 0.3897 
2022-05-03 16:19:02 - train: epoch 0092, iter [01500, 05004], lr: 0.000100, loss: 1.2133, stu_CELoss: 0.7782 DKDLoss: 0.4352 
2022-05-03 16:19:35 - train: epoch 0092, iter [01600, 05004], lr: 0.000100, loss: 1.2185, stu_CELoss: 0.7811 DKDLoss: 0.4374 
2022-05-03 16:20:08 - train: epoch 0092, iter [01700, 05004], lr: 0.000100, loss: 1.2033, stu_CELoss: 0.8060 DKDLoss: 0.3974 
2022-05-03 16:20:40 - train: epoch 0092, iter [01800, 05004], lr: 0.000100, loss: 1.1828, stu_CELoss: 0.7690 DKDLoss: 0.4138 
2022-05-03 16:21:12 - train: epoch 0092, iter [01900, 05004], lr: 0.000100, loss: 1.2181, stu_CELoss: 0.8102 DKDLoss: 0.4080 
2022-05-03 16:21:44 - train: epoch 0092, iter [02000, 05004], lr: 0.000100, loss: 1.0623, stu_CELoss: 0.7019 DKDLoss: 0.3604 
2022-05-03 16:22:17 - train: epoch 0092, iter [02100, 05004], lr: 0.000100, loss: 1.2613, stu_CELoss: 0.8754 DKDLoss: 0.3859 
2022-05-03 16:22:49 - train: epoch 0092, iter [02200, 05004], lr: 0.000100, loss: 1.2205, stu_CELoss: 0.7628 DKDLoss: 0.4576 
2022-05-03 16:23:23 - train: epoch 0092, iter [02300, 05004], lr: 0.000100, loss: 1.2797, stu_CELoss: 0.9021 DKDLoss: 0.3776 
2022-05-03 16:23:56 - train: epoch 0092, iter [02400, 05004], lr: 0.000100, loss: 1.3090, stu_CELoss: 0.8858 DKDLoss: 0.4233 
2022-05-03 16:24:29 - train: epoch 0092, iter [02500, 05004], lr: 0.000100, loss: 1.1581, stu_CELoss: 0.7367 DKDLoss: 0.4215 
2022-05-03 16:25:03 - train: epoch 0092, iter [02600, 05004], lr: 0.000100, loss: 1.2696, stu_CELoss: 0.8499 DKDLoss: 0.4197 
2022-05-03 16:25:36 - train: epoch 0092, iter [02700, 05004], lr: 0.000100, loss: 1.2096, stu_CELoss: 0.8389 DKDLoss: 0.3707 
2022-05-03 16:26:09 - train: epoch 0092, iter [02800, 05004], lr: 0.000100, loss: 1.1431, stu_CELoss: 0.7851 DKDLoss: 0.3580 
2022-05-03 16:26:42 - train: epoch 0092, iter [02900, 05004], lr: 0.000100, loss: 1.3228, stu_CELoss: 0.9190 DKDLoss: 0.4038 
2022-05-03 16:27:15 - train: epoch 0092, iter [03000, 05004], lr: 0.000100, loss: 1.3191, stu_CELoss: 0.8653 DKDLoss: 0.4537 
2022-05-03 16:27:49 - train: epoch 0092, iter [03100, 05004], lr: 0.000100, loss: 1.3194, stu_CELoss: 0.8746 DKDLoss: 0.4448 
2022-05-03 16:28:22 - train: epoch 0092, iter [03200, 05004], lr: 0.000100, loss: 1.2210, stu_CELoss: 0.7962 DKDLoss: 0.4247 
2022-05-03 16:28:56 - train: epoch 0092, iter [03300, 05004], lr: 0.000100, loss: 1.3406, stu_CELoss: 0.9499 DKDLoss: 0.3906 
2022-05-03 16:29:29 - train: epoch 0092, iter [03400, 05004], lr: 0.000100, loss: 1.1599, stu_CELoss: 0.7749 DKDLoss: 0.3851 
2022-05-03 16:30:02 - train: epoch 0092, iter [03500, 05004], lr: 0.000100, loss: 1.0438, stu_CELoss: 0.6501 DKDLoss: 0.3938 
2022-05-03 16:30:35 - train: epoch 0092, iter [03600, 05004], lr: 0.000100, loss: 1.0657, stu_CELoss: 0.6396 DKDLoss: 0.4262 
2022-05-03 16:31:09 - train: epoch 0092, iter [03700, 05004], lr: 0.000100, loss: 1.1314, stu_CELoss: 0.7392 DKDLoss: 0.3922 
2022-05-03 16:31:43 - train: epoch 0092, iter [03800, 05004], lr: 0.000100, loss: 1.1234, stu_CELoss: 0.7975 DKDLoss: 0.3260 
2022-05-03 16:32:16 - train: epoch 0092, iter [03900, 05004], lr: 0.000100, loss: 1.2463, stu_CELoss: 0.8477 DKDLoss: 0.3987 
2022-05-03 16:32:49 - train: epoch 0092, iter [04000, 05004], lr: 0.000100, loss: 1.3651, stu_CELoss: 0.9271 DKDLoss: 0.4380 
2022-05-03 16:33:23 - train: epoch 0092, iter [04100, 05004], lr: 0.000100, loss: 1.2206, stu_CELoss: 0.8005 DKDLoss: 0.4201 
2022-05-03 16:33:57 - train: epoch 0092, iter [04200, 05004], lr: 0.000100, loss: 1.2118, stu_CELoss: 0.7957 DKDLoss: 0.4161 
2022-05-03 16:34:30 - train: epoch 0092, iter [04300, 05004], lr: 0.000100, loss: 1.1183, stu_CELoss: 0.6883 DKDLoss: 0.4300 
2022-05-03 16:35:04 - train: epoch 0092, iter [04400, 05004], lr: 0.000100, loss: 1.3287, stu_CELoss: 0.8781 DKDLoss: 0.4506 
2022-05-03 16:35:38 - train: epoch 0092, iter [04500, 05004], lr: 0.000100, loss: 1.0682, stu_CELoss: 0.7013 DKDLoss: 0.3669 
2022-05-03 16:36:12 - train: epoch 0092, iter [04600, 05004], lr: 0.000100, loss: 1.2403, stu_CELoss: 0.8693 DKDLoss: 0.3710 
2022-05-03 16:36:45 - train: epoch 0092, iter [04700, 05004], lr: 0.000100, loss: 1.1070, stu_CELoss: 0.7122 DKDLoss: 0.3948 
2022-05-03 16:37:19 - train: epoch 0092, iter [04800, 05004], lr: 0.000100, loss: 1.1018, stu_CELoss: 0.7204 DKDLoss: 0.3814 
2022-05-03 16:37:53 - train: epoch 0092, iter [04900, 05004], lr: 0.000100, loss: 1.1336, stu_CELoss: 0.7212 DKDLoss: 0.4124 
2022-05-03 16:38:27 - train: epoch 0092, iter [05000, 05004], lr: 0.000100, loss: 1.2301, stu_CELoss: 0.8502 DKDLoss: 0.3799 
2022-05-03 16:38:28 - train: epoch 092, train_loss: 1.2145
2022-05-03 16:41:01 - eval: epoch: 092, tea_acc1: 78.330%, tea_acc5: 94.064%, tea_test_loss: 0.8657, stu_acc1: 77.618%, stu_acc5: 93.722%, stu_test_loss: 0.8850
2022-05-03 16:41:02 - until epoch: 092, tea_best_acc1: 78.330%, stu_best_acc1: 77.618%
2022-05-03 16:41:02 - epoch 093 lr: 0.00010000000000000003
2022-05-03 16:41:42 - train: epoch 0093, iter [00100, 05004], lr: 0.000100, loss: 1.1881, stu_CELoss: 0.7803 DKDLoss: 0.4079 
2022-05-03 16:42:16 - train: epoch 0093, iter [00200, 05004], lr: 0.000100, loss: 1.1020, stu_CELoss: 0.7268 DKDLoss: 0.3752 
2022-05-03 16:42:49 - train: epoch 0093, iter [00300, 05004], lr: 0.000100, loss: 1.3000, stu_CELoss: 0.8841 DKDLoss: 0.4160 
2022-05-03 16:43:23 - train: epoch 0093, iter [00400, 05004], lr: 0.000100, loss: 1.2616, stu_CELoss: 0.8214 DKDLoss: 0.4402 
2022-05-03 16:43:56 - train: epoch 0093, iter [00500, 05004], lr: 0.000100, loss: 1.2768, stu_CELoss: 0.8593 DKDLoss: 0.4176 
2022-05-03 16:44:30 - train: epoch 0093, iter [00600, 05004], lr: 0.000100, loss: 1.1127, stu_CELoss: 0.7236 DKDLoss: 0.3891 
2022-05-03 16:45:03 - train: epoch 0093, iter [00700, 05004], lr: 0.000100, loss: 1.1311, stu_CELoss: 0.7431 DKDLoss: 0.3880 
2022-05-03 16:45:37 - train: epoch 0093, iter [00800, 05004], lr: 0.000100, loss: 1.0949, stu_CELoss: 0.7358 DKDLoss: 0.3591 
2022-05-03 16:46:10 - train: epoch 0093, iter [00900, 05004], lr: 0.000100, loss: 1.3908, stu_CELoss: 1.0267 DKDLoss: 0.3640 
2022-05-03 16:46:44 - train: epoch 0093, iter [01000, 05004], lr: 0.000100, loss: 0.9963, stu_CELoss: 0.6076 DKDLoss: 0.3887 
2022-05-03 16:47:18 - train: epoch 0093, iter [01100, 05004], lr: 0.000100, loss: 1.0999, stu_CELoss: 0.6906 DKDLoss: 0.4092 
2022-05-03 16:47:52 - train: epoch 0093, iter [01200, 05004], lr: 0.000100, loss: 1.0859, stu_CELoss: 0.7466 DKDLoss: 0.3393 
2022-05-03 16:48:26 - train: epoch 0093, iter [01300, 05004], lr: 0.000100, loss: 1.0831, stu_CELoss: 0.6980 DKDLoss: 0.3851 
2022-05-03 16:48:59 - train: epoch 0093, iter [01400, 05004], lr: 0.000100, loss: 1.4176, stu_CELoss: 1.0436 DKDLoss: 0.3740 
2022-05-03 16:49:33 - train: epoch 0093, iter [01500, 05004], lr: 0.000100, loss: 1.3570, stu_CELoss: 0.9127 DKDLoss: 0.4443 
2022-05-03 16:50:07 - train: epoch 0093, iter [01600, 05004], lr: 0.000100, loss: 1.4087, stu_CELoss: 0.9545 DKDLoss: 0.4541 
2022-05-03 16:50:40 - train: epoch 0093, iter [01700, 05004], lr: 0.000100, loss: 1.3663, stu_CELoss: 0.9286 DKDLoss: 0.4377 
2022-05-03 16:51:14 - train: epoch 0093, iter [01800, 05004], lr: 0.000100, loss: 1.1778, stu_CELoss: 0.7662 DKDLoss: 0.4117 
2022-05-03 16:51:48 - train: epoch 0093, iter [01900, 05004], lr: 0.000100, loss: 1.2095, stu_CELoss: 0.7685 DKDLoss: 0.4409 
2022-05-03 16:52:22 - train: epoch 0093, iter [02000, 05004], lr: 0.000100, loss: 1.0519, stu_CELoss: 0.6682 DKDLoss: 0.3837 
2022-05-03 16:52:56 - train: epoch 0093, iter [02100, 05004], lr: 0.000100, loss: 0.9876, stu_CELoss: 0.5977 DKDLoss: 0.3899 
2022-05-03 16:53:29 - train: epoch 0093, iter [02200, 05004], lr: 0.000100, loss: 1.2152, stu_CELoss: 0.8410 DKDLoss: 0.3741 
2022-05-03 16:54:03 - train: epoch 0093, iter [02300, 05004], lr: 0.000100, loss: 1.2229, stu_CELoss: 0.8232 DKDLoss: 0.3997 
2022-05-03 16:54:37 - train: epoch 0093, iter [02400, 05004], lr: 0.000100, loss: 1.2798, stu_CELoss: 0.8758 DKDLoss: 0.4040 
2022-05-03 16:55:11 - train: epoch 0093, iter [02500, 05004], lr: 0.000100, loss: 1.3480, stu_CELoss: 0.8744 DKDLoss: 0.4737 
2022-05-03 16:55:44 - train: epoch 0093, iter [02600, 05004], lr: 0.000100, loss: 1.3387, stu_CELoss: 0.8908 DKDLoss: 0.4480 
2022-05-03 16:56:17 - train: epoch 0093, iter [02700, 05004], lr: 0.000100, loss: 1.1226, stu_CELoss: 0.7348 DKDLoss: 0.3878 
2022-05-03 16:56:51 - train: epoch 0093, iter [02800, 05004], lr: 0.000100, loss: 1.2038, stu_CELoss: 0.8228 DKDLoss: 0.3810 
2022-05-03 16:57:24 - train: epoch 0093, iter [02900, 05004], lr: 0.000100, loss: 1.1105, stu_CELoss: 0.7159 DKDLoss: 0.3946 
2022-05-03 16:57:57 - train: epoch 0093, iter [03000, 05004], lr: 0.000100, loss: 1.1041, stu_CELoss: 0.7602 DKDLoss: 0.3439 
2022-05-03 16:58:31 - train: epoch 0093, iter [03100, 05004], lr: 0.000100, loss: 1.1775, stu_CELoss: 0.8230 DKDLoss: 0.3545 
2022-05-03 16:59:04 - train: epoch 0093, iter [03200, 05004], lr: 0.000100, loss: 1.0916, stu_CELoss: 0.6867 DKDLoss: 0.4049 
2022-05-03 16:59:38 - train: epoch 0093, iter [03300, 05004], lr: 0.000100, loss: 1.1915, stu_CELoss: 0.7614 DKDLoss: 0.4301 
2022-05-03 17:00:11 - train: epoch 0093, iter [03400, 05004], lr: 0.000100, loss: 1.3549, stu_CELoss: 0.9104 DKDLoss: 0.4445 
2022-05-03 17:00:45 - train: epoch 0093, iter [03500, 05004], lr: 0.000100, loss: 1.0479, stu_CELoss: 0.6543 DKDLoss: 0.3936 
2022-05-03 17:01:19 - train: epoch 0093, iter [03600, 05004], lr: 0.000100, loss: 1.3469, stu_CELoss: 0.9421 DKDLoss: 0.4048 
2022-05-03 17:01:52 - train: epoch 0093, iter [03700, 05004], lr: 0.000100, loss: 1.3042, stu_CELoss: 0.8536 DKDLoss: 0.4505 
2022-05-03 17:02:25 - train: epoch 0093, iter [03800, 05004], lr: 0.000100, loss: 1.1926, stu_CELoss: 0.7953 DKDLoss: 0.3973 
2022-05-03 17:02:57 - train: epoch 0093, iter [03900, 05004], lr: 0.000100, loss: 1.1834, stu_CELoss: 0.7951 DKDLoss: 0.3883 
2022-05-03 17:03:30 - train: epoch 0093, iter [04000, 05004], lr: 0.000100, loss: 1.2199, stu_CELoss: 0.8219 DKDLoss: 0.3980 
2022-05-03 17:04:03 - train: epoch 0093, iter [04100, 05004], lr: 0.000100, loss: 1.3457, stu_CELoss: 0.9225 DKDLoss: 0.4232 
2022-05-03 17:04:36 - train: epoch 0093, iter [04200, 05004], lr: 0.000100, loss: 1.2719, stu_CELoss: 0.8473 DKDLoss: 0.4246 
2022-05-03 17:05:09 - train: epoch 0093, iter [04300, 05004], lr: 0.000100, loss: 1.2738, stu_CELoss: 0.8444 DKDLoss: 0.4294 
2022-05-03 17:05:42 - train: epoch 0093, iter [04400, 05004], lr: 0.000100, loss: 1.2248, stu_CELoss: 0.8201 DKDLoss: 0.4047 
2022-05-03 17:06:15 - train: epoch 0093, iter [04500, 05004], lr: 0.000100, loss: 1.1929, stu_CELoss: 0.8003 DKDLoss: 0.3926 
2022-05-03 17:06:49 - train: epoch 0093, iter [04600, 05004], lr: 0.000100, loss: 1.1925, stu_CELoss: 0.7912 DKDLoss: 0.4013 
2022-05-03 17:07:22 - train: epoch 0093, iter [04700, 05004], lr: 0.000100, loss: 1.6354, stu_CELoss: 1.1711 DKDLoss: 0.4642 
2022-05-03 17:07:55 - train: epoch 0093, iter [04800, 05004], lr: 0.000100, loss: 1.1668, stu_CELoss: 0.7610 DKDLoss: 0.4058 
2022-05-03 17:08:28 - train: epoch 0093, iter [04900, 05004], lr: 0.000100, loss: 1.1409, stu_CELoss: 0.8039 DKDLoss: 0.3370 
2022-05-03 17:09:01 - train: epoch 0093, iter [05000, 05004], lr: 0.000100, loss: 1.1196, stu_CELoss: 0.7231 DKDLoss: 0.3965 
2022-05-03 17:09:03 - train: epoch 093, train_loss: 1.2089
2022-05-03 17:11:33 - eval: epoch: 093, tea_acc1: 78.330%, tea_acc5: 94.064%, tea_test_loss: 0.8657, stu_acc1: 77.590%, stu_acc5: 93.730%, stu_test_loss: 0.8823
2022-05-03 17:11:33 - until epoch: 093, tea_best_acc1: 78.330%, stu_best_acc1: 77.618%
2022-05-03 17:11:33 - epoch 094 lr: 0.00010000000000000003
2022-05-03 17:12:13 - train: epoch 0094, iter [00100, 05004], lr: 0.000100, loss: 1.2072, stu_CELoss: 0.7785 DKDLoss: 0.4288 
2022-05-03 17:12:45 - train: epoch 0094, iter [00200, 05004], lr: 0.000100, loss: 1.1901, stu_CELoss: 0.7781 DKDLoss: 0.4120 
2022-05-03 17:13:17 - train: epoch 0094, iter [00300, 05004], lr: 0.000100, loss: 1.3233, stu_CELoss: 0.8935 DKDLoss: 0.4299 
2022-05-03 17:13:49 - train: epoch 0094, iter [00400, 05004], lr: 0.000100, loss: 1.4203, stu_CELoss: 1.0558 DKDLoss: 0.3644 
2022-05-03 17:14:22 - train: epoch 0094, iter [00500, 05004], lr: 0.000100, loss: 1.0882, stu_CELoss: 0.7219 DKDLoss: 0.3663 
2022-05-03 17:14:54 - train: epoch 0094, iter [00600, 05004], lr: 0.000100, loss: 1.0673, stu_CELoss: 0.6872 DKDLoss: 0.3802 
2022-05-03 17:15:27 - train: epoch 0094, iter [00700, 05004], lr: 0.000100, loss: 1.2686, stu_CELoss: 0.8310 DKDLoss: 0.4376 
2022-05-03 17:16:00 - train: epoch 0094, iter [00800, 05004], lr: 0.000100, loss: 1.1161, stu_CELoss: 0.6869 DKDLoss: 0.4293 
2022-05-03 17:16:34 - train: epoch 0094, iter [00900, 05004], lr: 0.000100, loss: 1.1355, stu_CELoss: 0.7367 DKDLoss: 0.3989 
2022-05-03 17:17:07 - train: epoch 0094, iter [01000, 05004], lr: 0.000100, loss: 1.2794, stu_CELoss: 0.8778 DKDLoss: 0.4016 
2022-05-03 17:17:40 - train: epoch 0094, iter [01100, 05004], lr: 0.000100, loss: 1.1889, stu_CELoss: 0.8108 DKDLoss: 0.3781 
2022-05-03 17:18:13 - train: epoch 0094, iter [01200, 05004], lr: 0.000100, loss: 1.2352, stu_CELoss: 0.8377 DKDLoss: 0.3975 
2022-05-03 17:18:47 - train: epoch 0094, iter [01300, 05004], lr: 0.000100, loss: 1.2311, stu_CELoss: 0.8386 DKDLoss: 0.3925 
2022-05-03 17:19:20 - train: epoch 0094, iter [01400, 05004], lr: 0.000100, loss: 1.1096, stu_CELoss: 0.7203 DKDLoss: 0.3893 
2022-05-03 17:19:53 - train: epoch 0094, iter [01500, 05004], lr: 0.000100, loss: 1.3068, stu_CELoss: 0.9411 DKDLoss: 0.3656 
2022-05-03 17:20:26 - train: epoch 0094, iter [01600, 05004], lr: 0.000100, loss: 1.5893, stu_CELoss: 1.2142 DKDLoss: 0.3750 
2022-05-03 17:20:59 - train: epoch 0094, iter [01700, 05004], lr: 0.000100, loss: 1.1694, stu_CELoss: 0.7791 DKDLoss: 0.3902 
2022-05-03 17:21:33 - train: epoch 0094, iter [01800, 05004], lr: 0.000100, loss: 1.1554, stu_CELoss: 0.7532 DKDLoss: 0.4023 
2022-05-03 17:22:07 - train: epoch 0094, iter [01900, 05004], lr: 0.000100, loss: 1.2168, stu_CELoss: 0.8260 DKDLoss: 0.3908 
2022-05-03 17:22:40 - train: epoch 0094, iter [02000, 05004], lr: 0.000100, loss: 0.9867, stu_CELoss: 0.6276 DKDLoss: 0.3591 
2022-05-03 17:23:14 - train: epoch 0094, iter [02100, 05004], lr: 0.000100, loss: 1.1132, stu_CELoss: 0.7737 DKDLoss: 0.3395 
2022-05-03 17:23:48 - train: epoch 0094, iter [02200, 05004], lr: 0.000100, loss: 1.1230, stu_CELoss: 0.7048 DKDLoss: 0.4182 
2022-05-03 17:24:22 - train: epoch 0094, iter [02300, 05004], lr: 0.000100, loss: 1.0852, stu_CELoss: 0.6528 DKDLoss: 0.4324 
2022-05-03 17:24:56 - train: epoch 0094, iter [02400, 05004], lr: 0.000100, loss: 1.2081, stu_CELoss: 0.7974 DKDLoss: 0.4107 
2022-05-03 17:25:30 - train: epoch 0094, iter [02500, 05004], lr: 0.000100, loss: 1.1605, stu_CELoss: 0.7436 DKDLoss: 0.4169 
2022-05-03 17:26:04 - train: epoch 0094, iter [02600, 05004], lr: 0.000100, loss: 1.1043, stu_CELoss: 0.7206 DKDLoss: 0.3837 
2022-05-03 17:26:38 - train: epoch 0094, iter [02700, 05004], lr: 0.000100, loss: 1.0838, stu_CELoss: 0.7166 DKDLoss: 0.3672 
2022-05-03 17:27:12 - train: epoch 0094, iter [02800, 05004], lr: 0.000100, loss: 1.1022, stu_CELoss: 0.7402 DKDLoss: 0.3620 
2022-05-03 17:27:46 - train: epoch 0094, iter [02900, 05004], lr: 0.000100, loss: 1.1853, stu_CELoss: 0.8168 DKDLoss: 0.3685 
2022-05-03 17:28:20 - train: epoch 0094, iter [03000, 05004], lr: 0.000100, loss: 1.0995, stu_CELoss: 0.6880 DKDLoss: 0.4116 
2022-05-03 17:28:54 - train: epoch 0094, iter [03100, 05004], lr: 0.000100, loss: 1.3883, stu_CELoss: 0.9800 DKDLoss: 0.4083 
2022-05-03 17:29:28 - train: epoch 0094, iter [03200, 05004], lr: 0.000100, loss: 1.1809, stu_CELoss: 0.7878 DKDLoss: 0.3931 
2022-05-03 17:30:02 - train: epoch 0094, iter [03300, 05004], lr: 0.000100, loss: 1.1900, stu_CELoss: 0.8143 DKDLoss: 0.3757 
2022-05-03 17:30:36 - train: epoch 0094, iter [03400, 05004], lr: 0.000100, loss: 1.3482, stu_CELoss: 0.9528 DKDLoss: 0.3954 
2022-05-03 17:31:10 - train: epoch 0094, iter [03500, 05004], lr: 0.000100, loss: 1.4081, stu_CELoss: 0.9854 DKDLoss: 0.4226 
2022-05-03 17:31:44 - train: epoch 0094, iter [03600, 05004], lr: 0.000100, loss: 1.2014, stu_CELoss: 0.7875 DKDLoss: 0.4139 
2022-05-03 17:32:18 - train: epoch 0094, iter [03700, 05004], lr: 0.000100, loss: 1.3909, stu_CELoss: 0.9663 DKDLoss: 0.4247 
2022-05-03 17:32:51 - train: epoch 0094, iter [03800, 05004], lr: 0.000100, loss: 1.1895, stu_CELoss: 0.8077 DKDLoss: 0.3818 
2022-05-03 17:33:26 - train: epoch 0094, iter [03900, 05004], lr: 0.000100, loss: 1.1446, stu_CELoss: 0.7762 DKDLoss: 0.3685 
2022-05-03 17:34:00 - train: epoch 0094, iter [04000, 05004], lr: 0.000100, loss: 1.2536, stu_CELoss: 0.8772 DKDLoss: 0.3763 
2022-05-03 17:34:34 - train: epoch 0094, iter [04100, 05004], lr: 0.000100, loss: 1.4692, stu_CELoss: 1.0470 DKDLoss: 0.4222 
2022-05-03 17:35:08 - train: epoch 0094, iter [04200, 05004], lr: 0.000100, loss: 1.0445, stu_CELoss: 0.6687 DKDLoss: 0.3758 
2022-05-03 17:35:42 - train: epoch 0094, iter [04300, 05004], lr: 0.000100, loss: 1.2962, stu_CELoss: 0.9273 DKDLoss: 0.3689 
2022-05-03 17:36:16 - train: epoch 0094, iter [04400, 05004], lr: 0.000100, loss: 1.3461, stu_CELoss: 0.9157 DKDLoss: 0.4304 
2022-05-03 17:36:50 - train: epoch 0094, iter [04500, 05004], lr: 0.000100, loss: 1.2128, stu_CELoss: 0.8347 DKDLoss: 0.3781 
2022-05-03 17:37:24 - train: epoch 0094, iter [04600, 05004], lr: 0.000100, loss: 1.2787, stu_CELoss: 0.8529 DKDLoss: 0.4258 
2022-05-03 17:37:58 - train: epoch 0094, iter [04700, 05004], lr: 0.000100, loss: 1.2008, stu_CELoss: 0.8273 DKDLoss: 0.3735 
2022-05-03 17:38:32 - train: epoch 0094, iter [04800, 05004], lr: 0.000100, loss: 1.1141, stu_CELoss: 0.7129 DKDLoss: 0.4012 
2022-05-03 17:39:06 - train: epoch 0094, iter [04900, 05004], lr: 0.000100, loss: 1.2110, stu_CELoss: 0.8098 DKDLoss: 0.4012 
2022-05-03 17:39:39 - train: epoch 0094, iter [05000, 05004], lr: 0.000100, loss: 1.0960, stu_CELoss: 0.6906 DKDLoss: 0.4055 
2022-05-03 17:39:41 - train: epoch 094, train_loss: 1.2109
2022-05-03 17:42:14 - eval: epoch: 094, tea_acc1: 78.330%, tea_acc5: 94.064%, tea_test_loss: 0.8657, stu_acc1: 77.652%, stu_acc5: 93.736%, stu_test_loss: 0.8831
2022-05-03 17:42:14 - until epoch: 094, tea_best_acc1: 78.330%, stu_best_acc1: 77.652%
2022-05-03 17:42:14 - epoch 095 lr: 0.00010000000000000003
2022-05-03 17:42:55 - train: epoch 0095, iter [00100, 05004], lr: 0.000100, loss: 1.0914, stu_CELoss: 0.7060 DKDLoss: 0.3854 
2022-05-03 17:43:27 - train: epoch 0095, iter [00200, 05004], lr: 0.000100, loss: 1.1615, stu_CELoss: 0.7722 DKDLoss: 0.3894 
2022-05-03 17:44:00 - train: epoch 0095, iter [00300, 05004], lr: 0.000100, loss: 1.0322, stu_CELoss: 0.6424 DKDLoss: 0.3897 
2022-05-03 17:44:33 - train: epoch 0095, iter [00400, 05004], lr: 0.000100, loss: 1.1836, stu_CELoss: 0.7928 DKDLoss: 0.3908 
2022-05-03 17:45:06 - train: epoch 0095, iter [00500, 05004], lr: 0.000100, loss: 1.3121, stu_CELoss: 0.8749 DKDLoss: 0.4373 
2022-05-03 17:45:40 - train: epoch 0095, iter [00600, 05004], lr: 0.000100, loss: 1.2476, stu_CELoss: 0.8197 DKDLoss: 0.4279 
2022-05-03 17:46:13 - train: epoch 0095, iter [00700, 05004], lr: 0.000100, loss: 1.3320, stu_CELoss: 0.9117 DKDLoss: 0.4203 
2022-05-03 17:46:46 - train: epoch 0095, iter [00800, 05004], lr: 0.000100, loss: 1.1860, stu_CELoss: 0.7801 DKDLoss: 0.4059 
2022-05-03 17:47:19 - train: epoch 0095, iter [00900, 05004], lr: 0.000100, loss: 1.2826, stu_CELoss: 0.8487 DKDLoss: 0.4339 
2022-05-03 17:47:51 - train: epoch 0095, iter [01000, 05004], lr: 0.000100, loss: 1.0384, stu_CELoss: 0.6494 DKDLoss: 0.3889 
2022-05-03 17:48:24 - train: epoch 0095, iter [01100, 05004], lr: 0.000100, loss: 1.2041, stu_CELoss: 0.8040 DKDLoss: 0.4001 
2022-05-03 17:48:58 - train: epoch 0095, iter [01200, 05004], lr: 0.000100, loss: 1.1416, stu_CELoss: 0.7621 DKDLoss: 0.3795 
2022-05-03 17:49:31 - train: epoch 0095, iter [01300, 05004], lr: 0.000100, loss: 1.2647, stu_CELoss: 0.8259 DKDLoss: 0.4388 
2022-05-03 17:50:04 - train: epoch 0095, iter [01400, 05004], lr: 0.000100, loss: 1.1155, stu_CELoss: 0.7727 DKDLoss: 0.3428 
2022-05-03 17:50:37 - train: epoch 0095, iter [01500, 05004], lr: 0.000100, loss: 1.0882, stu_CELoss: 0.6803 DKDLoss: 0.4080 
2022-05-03 17:51:11 - train: epoch 0095, iter [01600, 05004], lr: 0.000100, loss: 0.9005, stu_CELoss: 0.5373 DKDLoss: 0.3632 
2022-05-03 17:51:44 - train: epoch 0095, iter [01700, 05004], lr: 0.000100, loss: 1.2298, stu_CELoss: 0.8207 DKDLoss: 0.4092 
2022-05-03 17:52:17 - train: epoch 0095, iter [01800, 05004], lr: 0.000100, loss: 1.3170, stu_CELoss: 0.8786 DKDLoss: 0.4384 
2022-05-03 17:52:51 - train: epoch 0095, iter [01900, 05004], lr: 0.000100, loss: 1.1876, stu_CELoss: 0.7619 DKDLoss: 0.4257 
2022-05-03 17:53:24 - train: epoch 0095, iter [02000, 05004], lr: 0.000100, loss: 1.3942, stu_CELoss: 1.0136 DKDLoss: 0.3806 
2022-05-03 17:53:57 - train: epoch 0095, iter [02100, 05004], lr: 0.000100, loss: 1.1864, stu_CELoss: 0.7696 DKDLoss: 0.4169 
2022-05-03 17:54:31 - train: epoch 0095, iter [02200, 05004], lr: 0.000100, loss: 1.1286, stu_CELoss: 0.7033 DKDLoss: 0.4253 
2022-05-03 17:55:05 - train: epoch 0095, iter [02300, 05004], lr: 0.000100, loss: 0.9992, stu_CELoss: 0.6795 DKDLoss: 0.3196 
2022-05-03 17:55:38 - train: epoch 0095, iter [02400, 05004], lr: 0.000100, loss: 1.1553, stu_CELoss: 0.7406 DKDLoss: 0.4147 
2022-05-03 17:56:11 - train: epoch 0095, iter [02500, 05004], lr: 0.000100, loss: 1.1233, stu_CELoss: 0.7368 DKDLoss: 0.3865 
2022-05-03 17:56:45 - train: epoch 0095, iter [02600, 05004], lr: 0.000100, loss: 1.2188, stu_CELoss: 0.8019 DKDLoss: 0.4169 
2022-05-03 17:57:18 - train: epoch 0095, iter [02700, 05004], lr: 0.000100, loss: 1.2604, stu_CELoss: 0.8816 DKDLoss: 0.3788 
2022-05-03 17:57:51 - train: epoch 0095, iter [02800, 05004], lr: 0.000100, loss: 1.0621, stu_CELoss: 0.6893 DKDLoss: 0.3727 
2022-05-03 17:58:25 - train: epoch 0095, iter [02900, 05004], lr: 0.000100, loss: 1.4140, stu_CELoss: 0.9656 DKDLoss: 0.4485 
2022-05-03 17:58:58 - train: epoch 0095, iter [03000, 05004], lr: 0.000100, loss: 1.4048, stu_CELoss: 0.9467 DKDLoss: 0.4582 
2022-05-03 17:59:32 - train: epoch 0095, iter [03100, 05004], lr: 0.000100, loss: 1.0699, stu_CELoss: 0.7106 DKDLoss: 0.3593 
2022-05-03 18:00:05 - train: epoch 0095, iter [03200, 05004], lr: 0.000100, loss: 1.1802, stu_CELoss: 0.8303 DKDLoss: 0.3499 
2022-05-03 18:00:39 - train: epoch 0095, iter [03300, 05004], lr: 0.000100, loss: 1.1416, stu_CELoss: 0.7543 DKDLoss: 0.3873 
2022-05-03 18:01:13 - train: epoch 0095, iter [03400, 05004], lr: 0.000100, loss: 1.1562, stu_CELoss: 0.7865 DKDLoss: 0.3697 
2022-05-03 18:01:47 - train: epoch 0095, iter [03500, 05004], lr: 0.000100, loss: 1.1021, stu_CELoss: 0.7505 DKDLoss: 0.3515 
2022-05-03 18:02:21 - train: epoch 0095, iter [03600, 05004], lr: 0.000100, loss: 1.0189, stu_CELoss: 0.6539 DKDLoss: 0.3650 
2022-05-03 18:02:55 - train: epoch 0095, iter [03700, 05004], lr: 0.000100, loss: 1.2774, stu_CELoss: 0.9004 DKDLoss: 0.3770 
2022-05-03 18:03:29 - train: epoch 0095, iter [03800, 05004], lr: 0.000100, loss: 1.1714, stu_CELoss: 0.7587 DKDLoss: 0.4128 
2022-05-03 18:04:03 - train: epoch 0095, iter [03900, 05004], lr: 0.000100, loss: 1.2202, stu_CELoss: 0.7663 DKDLoss: 0.4539 
2022-05-03 18:04:37 - train: epoch 0095, iter [04000, 05004], lr: 0.000100, loss: 1.0629, stu_CELoss: 0.6909 DKDLoss: 0.3720 
2022-05-03 18:05:11 - train: epoch 0095, iter [04100, 05004], lr: 0.000100, loss: 1.0700, stu_CELoss: 0.6710 DKDLoss: 0.3990 
2022-05-03 18:05:45 - train: epoch 0095, iter [04200, 05004], lr: 0.000100, loss: 1.1368, stu_CELoss: 0.7421 DKDLoss: 0.3947 
2022-05-03 18:06:18 - train: epoch 0095, iter [04300, 05004], lr: 0.000100, loss: 1.1900, stu_CELoss: 0.8255 DKDLoss: 0.3644 
2022-05-03 18:06:51 - train: epoch 0095, iter [04400, 05004], lr: 0.000100, loss: 1.2937, stu_CELoss: 0.8672 DKDLoss: 0.4265 
2022-05-03 18:07:24 - train: epoch 0095, iter [04500, 05004], lr: 0.000100, loss: 1.0872, stu_CELoss: 0.6877 DKDLoss: 0.3995 
2022-05-03 18:07:57 - train: epoch 0095, iter [04600, 05004], lr: 0.000100, loss: 1.3443, stu_CELoss: 0.8943 DKDLoss: 0.4500 
2022-05-03 18:08:31 - train: epoch 0095, iter [04700, 05004], lr: 0.000100, loss: 1.1038, stu_CELoss: 0.6647 DKDLoss: 0.4390 
2022-05-03 18:09:04 - train: epoch 0095, iter [04800, 05004], lr: 0.000100, loss: 0.9935, stu_CELoss: 0.6289 DKDLoss: 0.3646 
2022-05-03 18:09:38 - train: epoch 0095, iter [04900, 05004], lr: 0.000100, loss: 1.0112, stu_CELoss: 0.6431 DKDLoss: 0.3681 
2022-05-03 18:10:11 - train: epoch 0095, iter [05000, 05004], lr: 0.000100, loss: 1.2355, stu_CELoss: 0.8561 DKDLoss: 0.3794 
2022-05-03 18:10:13 - train: epoch 095, train_loss: 1.2004
2022-05-03 18:12:45 - eval: epoch: 095, tea_acc1: 78.330%, tea_acc5: 94.064%, tea_test_loss: 0.8657, stu_acc1: 77.626%, stu_acc5: 93.762%, stu_test_loss: 0.8834
2022-05-03 18:12:45 - until epoch: 095, tea_best_acc1: 78.330%, stu_best_acc1: 77.652%
2022-05-03 18:12:45 - epoch 096 lr: 0.00010000000000000003
2022-05-03 18:13:27 - train: epoch 0096, iter [00100, 05004], lr: 0.000100, loss: 1.3160, stu_CELoss: 0.9150 DKDLoss: 0.4010 
2022-05-03 18:14:00 - train: epoch 0096, iter [00200, 05004], lr: 0.000100, loss: 1.2075, stu_CELoss: 0.8142 DKDLoss: 0.3933 
2022-05-03 18:14:34 - train: epoch 0096, iter [00300, 05004], lr: 0.000100, loss: 1.1279, stu_CELoss: 0.7172 DKDLoss: 0.4106 
2022-05-03 18:15:07 - train: epoch 0096, iter [00400, 05004], lr: 0.000100, loss: 1.0729, stu_CELoss: 0.7085 DKDLoss: 0.3644 
2022-05-03 18:15:40 - train: epoch 0096, iter [00500, 05004], lr: 0.000100, loss: 1.0221, stu_CELoss: 0.6763 DKDLoss: 0.3459 
2022-05-03 18:16:13 - train: epoch 0096, iter [00600, 05004], lr: 0.000100, loss: 1.3328, stu_CELoss: 0.8676 DKDLoss: 0.4651 
2022-05-03 18:16:45 - train: epoch 0096, iter [00700, 05004], lr: 0.000100, loss: 1.0646, stu_CELoss: 0.6799 DKDLoss: 0.3847 
2022-05-03 18:17:18 - train: epoch 0096, iter [00800, 05004], lr: 0.000100, loss: 1.2053, stu_CELoss: 0.7842 DKDLoss: 0.4211 
2022-05-03 18:17:51 - train: epoch 0096, iter [00900, 05004], lr: 0.000100, loss: 1.2921, stu_CELoss: 0.8862 DKDLoss: 0.4059 
2022-05-03 18:18:24 - train: epoch 0096, iter [01000, 05004], lr: 0.000100, loss: 1.2121, stu_CELoss: 0.8627 DKDLoss: 0.3494 
2022-05-03 18:18:57 - train: epoch 0096, iter [01100, 05004], lr: 0.000100, loss: 1.1659, stu_CELoss: 0.7817 DKDLoss: 0.3841 
2022-05-03 18:19:30 - train: epoch 0096, iter [01200, 05004], lr: 0.000100, loss: 1.0697, stu_CELoss: 0.7338 DKDLoss: 0.3359 
2022-05-03 18:20:02 - train: epoch 0096, iter [01300, 05004], lr: 0.000100, loss: 1.2033, stu_CELoss: 0.8385 DKDLoss: 0.3648 
2022-05-03 18:20:35 - train: epoch 0096, iter [01400, 05004], lr: 0.000100, loss: 1.1038, stu_CELoss: 0.7612 DKDLoss: 0.3426 
2022-05-03 18:21:08 - train: epoch 0096, iter [01500, 05004], lr: 0.000100, loss: 1.2398, stu_CELoss: 0.8306 DKDLoss: 0.4092 
2022-05-03 18:21:41 - train: epoch 0096, iter [01600, 05004], lr: 0.000100, loss: 1.0171, stu_CELoss: 0.6281 DKDLoss: 0.3890 
2022-05-03 18:22:13 - train: epoch 0096, iter [01700, 05004], lr: 0.000100, loss: 1.0480, stu_CELoss: 0.6727 DKDLoss: 0.3753 
2022-05-03 18:22:45 - train: epoch 0096, iter [01800, 05004], lr: 0.000100, loss: 1.2575, stu_CELoss: 0.8346 DKDLoss: 0.4229 
2022-05-03 18:23:18 - train: epoch 0096, iter [01900, 05004], lr: 0.000100, loss: 1.2353, stu_CELoss: 0.8501 DKDLoss: 0.3852 
2022-05-03 18:23:51 - train: epoch 0096, iter [02000, 05004], lr: 0.000100, loss: 1.2540, stu_CELoss: 0.8059 DKDLoss: 0.4481 
2022-05-03 18:24:24 - train: epoch 0096, iter [02100, 05004], lr: 0.000100, loss: 1.2987, stu_CELoss: 0.9601 DKDLoss: 0.3386 
2022-05-03 18:24:57 - train: epoch 0096, iter [02200, 05004], lr: 0.000100, loss: 0.9405, stu_CELoss: 0.5654 DKDLoss: 0.3751 
2022-05-03 18:25:30 - train: epoch 0096, iter [02300, 05004], lr: 0.000100, loss: 1.1677, stu_CELoss: 0.7946 DKDLoss: 0.3732 
2022-05-03 18:26:03 - train: epoch 0096, iter [02400, 05004], lr: 0.000100, loss: 1.1760, stu_CELoss: 0.8273 DKDLoss: 0.3487 
2022-05-03 18:26:36 - train: epoch 0096, iter [02500, 05004], lr: 0.000100, loss: 1.1602, stu_CELoss: 0.7848 DKDLoss: 0.3753 
2022-05-03 18:27:09 - train: epoch 0096, iter [02600, 05004], lr: 0.000100, loss: 1.1840, stu_CELoss: 0.7901 DKDLoss: 0.3939 
2022-05-03 18:27:42 - train: epoch 0096, iter [02700, 05004], lr: 0.000100, loss: 1.2389, stu_CELoss: 0.8347 DKDLoss: 0.4042 
2022-05-03 18:28:15 - train: epoch 0096, iter [02800, 05004], lr: 0.000100, loss: 1.2388, stu_CELoss: 0.8163 DKDLoss: 0.4225 
2022-05-03 18:28:48 - train: epoch 0096, iter [02900, 05004], lr: 0.000100, loss: 1.3276, stu_CELoss: 0.9142 DKDLoss: 0.4135 
2022-05-03 18:29:21 - train: epoch 0096, iter [03000, 05004], lr: 0.000100, loss: 1.2277, stu_CELoss: 0.8499 DKDLoss: 0.3778 
2022-05-03 18:29:54 - train: epoch 0096, iter [03100, 05004], lr: 0.000100, loss: 1.3139, stu_CELoss: 0.9138 DKDLoss: 0.4001 
2022-05-03 18:30:28 - train: epoch 0096, iter [03200, 05004], lr: 0.000100, loss: 1.2114, stu_CELoss: 0.7758 DKDLoss: 0.4356 
2022-05-03 18:31:01 - train: epoch 0096, iter [03300, 05004], lr: 0.000100, loss: 1.3479, stu_CELoss: 0.8988 DKDLoss: 0.4491 
2022-05-03 18:31:34 - train: epoch 0096, iter [03400, 05004], lr: 0.000100, loss: 1.1176, stu_CELoss: 0.7022 DKDLoss: 0.4154 
2022-05-03 18:32:08 - train: epoch 0096, iter [03500, 05004], lr: 0.000100, loss: 1.1867, stu_CELoss: 0.8184 DKDLoss: 0.3683 
2022-05-03 18:32:42 - train: epoch 0096, iter [03600, 05004], lr: 0.000100, loss: 1.1572, stu_CELoss: 0.7208 DKDLoss: 0.4364 
2022-05-03 18:33:15 - train: epoch 0096, iter [03700, 05004], lr: 0.000100, loss: 1.2229, stu_CELoss: 0.7980 DKDLoss: 0.4249 
2022-05-03 18:33:49 - train: epoch 0096, iter [03800, 05004], lr: 0.000100, loss: 1.0878, stu_CELoss: 0.7423 DKDLoss: 0.3455 
2022-05-03 18:34:23 - train: epoch 0096, iter [03900, 05004], lr: 0.000100, loss: 1.0969, stu_CELoss: 0.7424 DKDLoss: 0.3546 
2022-05-03 18:34:56 - train: epoch 0096, iter [04000, 05004], lr: 0.000100, loss: 1.2210, stu_CELoss: 0.8555 DKDLoss: 0.3655 
2022-05-03 18:35:30 - train: epoch 0096, iter [04100, 05004], lr: 0.000100, loss: 1.1917, stu_CELoss: 0.7954 DKDLoss: 0.3963 
2022-05-03 18:36:04 - train: epoch 0096, iter [04200, 05004], lr: 0.000100, loss: 1.2861, stu_CELoss: 0.8246 DKDLoss: 0.4615 
2022-05-03 18:36:37 - train: epoch 0096, iter [04300, 05004], lr: 0.000100, loss: 0.9325, stu_CELoss: 0.5650 DKDLoss: 0.3674 
2022-05-03 18:37:11 - train: epoch 0096, iter [04400, 05004], lr: 0.000100, loss: 1.1564, stu_CELoss: 0.8173 DKDLoss: 0.3391 
2022-05-03 18:37:45 - train: epoch 0096, iter [04500, 05004], lr: 0.000100, loss: 1.0866, stu_CELoss: 0.6846 DKDLoss: 0.4020 
2022-05-03 18:38:19 - train: epoch 0096, iter [04600, 05004], lr: 0.000100, loss: 1.1325, stu_CELoss: 0.7945 DKDLoss: 0.3380 
2022-05-03 18:38:53 - train: epoch 0096, iter [04700, 05004], lr: 0.000100, loss: 1.1971, stu_CELoss: 0.8314 DKDLoss: 0.3657 
2022-05-03 18:39:27 - train: epoch 0096, iter [04800, 05004], lr: 0.000100, loss: 1.2757, stu_CELoss: 0.8839 DKDLoss: 0.3918 
2022-05-03 18:40:01 - train: epoch 0096, iter [04900, 05004], lr: 0.000100, loss: 1.4248, stu_CELoss: 0.9361 DKDLoss: 0.4886 
2022-05-03 18:40:34 - train: epoch 0096, iter [05000, 05004], lr: 0.000100, loss: 1.0217, stu_CELoss: 0.6525 DKDLoss: 0.3692 
2022-05-03 18:40:36 - train: epoch 096, train_loss: 1.2032
2022-05-03 18:43:08 - eval: epoch: 096, tea_acc1: 78.330%, tea_acc5: 94.064%, tea_test_loss: 0.8657, stu_acc1: 77.744%, stu_acc5: 93.746%, stu_test_loss: 0.8812
2022-05-03 18:43:09 - until epoch: 096, tea_best_acc1: 78.330%, stu_best_acc1: 77.744%
2022-05-03 18:43:09 - epoch 097 lr: 0.00010000000000000003
2022-05-03 18:43:48 - train: epoch 0097, iter [00100, 05004], lr: 0.000100, loss: 1.3298, stu_CELoss: 0.8771 DKDLoss: 0.4526 
2022-05-03 18:44:21 - train: epoch 0097, iter [00200, 05004], lr: 0.000100, loss: 1.2435, stu_CELoss: 0.8253 DKDLoss: 0.4182 
2022-05-03 18:44:55 - train: epoch 0097, iter [00300, 05004], lr: 0.000100, loss: 1.1921, stu_CELoss: 0.8489 DKDLoss: 0.3432 
2022-05-03 18:45:28 - train: epoch 0097, iter [00400, 05004], lr: 0.000100, loss: 1.3918, stu_CELoss: 0.9635 DKDLoss: 0.4284 
2022-05-03 18:46:01 - train: epoch 0097, iter [00500, 05004], lr: 0.000100, loss: 1.4291, stu_CELoss: 0.9713 DKDLoss: 0.4578 
2022-05-03 18:46:35 - train: epoch 0097, iter [00600, 05004], lr: 0.000100, loss: 1.3884, stu_CELoss: 0.9963 DKDLoss: 0.3921 
2022-05-03 18:47:08 - train: epoch 0097, iter [00700, 05004], lr: 0.000100, loss: 1.1052, stu_CELoss: 0.7125 DKDLoss: 0.3926 
2022-05-03 18:47:42 - train: epoch 0097, iter [00800, 05004], lr: 0.000100, loss: 0.9925, stu_CELoss: 0.6412 DKDLoss: 0.3513 
2022-05-03 18:48:15 - train: epoch 0097, iter [00900, 05004], lr: 0.000100, loss: 1.1557, stu_CELoss: 0.7733 DKDLoss: 0.3825 
2022-05-03 18:48:49 - train: epoch 0097, iter [01000, 05004], lr: 0.000100, loss: 1.4288, stu_CELoss: 1.0161 DKDLoss: 0.4127 
2022-05-03 18:49:23 - train: epoch 0097, iter [01100, 05004], lr: 0.000100, loss: 1.2187, stu_CELoss: 0.8506 DKDLoss: 0.3681 
2022-05-03 18:49:56 - train: epoch 0097, iter [01200, 05004], lr: 0.000100, loss: 1.1604, stu_CELoss: 0.7258 DKDLoss: 0.4346 
2022-05-03 18:50:30 - train: epoch 0097, iter [01300, 05004], lr: 0.000100, loss: 1.2057, stu_CELoss: 0.8202 DKDLoss: 0.3854 
2022-05-03 18:51:04 - train: epoch 0097, iter [01400, 05004], lr: 0.000100, loss: 1.3384, stu_CELoss: 0.9392 DKDLoss: 0.3992 
2022-05-03 18:51:38 - train: epoch 0097, iter [01500, 05004], lr: 0.000100, loss: 1.0649, stu_CELoss: 0.6479 DKDLoss: 0.4169 
2022-05-03 18:52:11 - train: epoch 0097, iter [01600, 05004], lr: 0.000100, loss: 1.1597, stu_CELoss: 0.8022 DKDLoss: 0.3575 
2022-05-03 18:52:45 - train: epoch 0097, iter [01700, 05004], lr: 0.000100, loss: 1.0233, stu_CELoss: 0.6875 DKDLoss: 0.3358 
2022-05-03 18:53:19 - train: epoch 0097, iter [01800, 05004], lr: 0.000100, loss: 1.2718, stu_CELoss: 0.8972 DKDLoss: 0.3747 
2022-05-03 18:53:53 - train: epoch 0097, iter [01900, 05004], lr: 0.000100, loss: 1.1612, stu_CELoss: 0.7717 DKDLoss: 0.3895 
2022-05-03 18:54:27 - train: epoch 0097, iter [02000, 05004], lr: 0.000100, loss: 1.0687, stu_CELoss: 0.7060 DKDLoss: 0.3628 
2022-05-03 18:55:00 - train: epoch 0097, iter [02100, 05004], lr: 0.000100, loss: 1.2795, stu_CELoss: 0.8142 DKDLoss: 0.4653 
2022-05-03 18:55:34 - train: epoch 0097, iter [02200, 05004], lr: 0.000100, loss: 1.1550, stu_CELoss: 0.8070 DKDLoss: 0.3480 
2022-05-03 18:56:07 - train: epoch 0097, iter [02300, 05004], lr: 0.000100, loss: 1.3430, stu_CELoss: 1.0000 DKDLoss: 0.3430 
2022-05-03 18:56:41 - train: epoch 0097, iter [02400, 05004], lr: 0.000100, loss: 1.0096, stu_CELoss: 0.6397 DKDLoss: 0.3699 
2022-05-03 18:57:15 - train: epoch 0097, iter [02500, 05004], lr: 0.000100, loss: 1.0985, stu_CELoss: 0.7188 DKDLoss: 0.3797 
2022-05-03 18:57:48 - train: epoch 0097, iter [02600, 05004], lr: 0.000100, loss: 1.4087, stu_CELoss: 0.9858 DKDLoss: 0.4230 
2022-05-03 18:58:22 - train: epoch 0097, iter [02700, 05004], lr: 0.000100, loss: 1.1917, stu_CELoss: 0.8114 DKDLoss: 0.3804 
2022-05-03 18:58:55 - train: epoch 0097, iter [02800, 05004], lr: 0.000100, loss: 1.1100, stu_CELoss: 0.7415 DKDLoss: 0.3685 
2022-05-03 18:59:29 - train: epoch 0097, iter [02900, 05004], lr: 0.000100, loss: 1.0505, stu_CELoss: 0.7124 DKDLoss: 0.3381 
2022-05-03 19:00:03 - train: epoch 0097, iter [03000, 05004], lr: 0.000100, loss: 1.2497, stu_CELoss: 0.8191 DKDLoss: 0.4306 
2022-05-03 19:00:36 - train: epoch 0097, iter [03100, 05004], lr: 0.000100, loss: 1.1769, stu_CELoss: 0.7763 DKDLoss: 0.4007 
2022-05-03 19:01:10 - train: epoch 0097, iter [03200, 05004], lr: 0.000100, loss: 1.2932, stu_CELoss: 0.8878 DKDLoss: 0.4054 
2022-05-03 19:01:44 - train: epoch 0097, iter [03300, 05004], lr: 0.000100, loss: 1.3990, stu_CELoss: 0.9655 DKDLoss: 0.4336 
2022-05-03 19:02:17 - train: epoch 0097, iter [03400, 05004], lr: 0.000100, loss: 1.2121, stu_CELoss: 0.8065 DKDLoss: 0.4057 
2022-05-03 19:02:51 - train: epoch 0097, iter [03500, 05004], lr: 0.000100, loss: 1.3170, stu_CELoss: 0.9459 DKDLoss: 0.3712 
2022-05-03 19:03:24 - train: epoch 0097, iter [03600, 05004], lr: 0.000100, loss: 1.1940, stu_CELoss: 0.7720 DKDLoss: 0.4220 
2022-05-03 19:03:58 - train: epoch 0097, iter [03700, 05004], lr: 0.000100, loss: 0.9767, stu_CELoss: 0.6306 DKDLoss: 0.3461 
2022-05-03 19:04:32 - train: epoch 0097, iter [03800, 05004], lr: 0.000100, loss: 1.0117, stu_CELoss: 0.6655 DKDLoss: 0.3462 
2022-05-03 19:05:05 - train: epoch 0097, iter [03900, 05004], lr: 0.000100, loss: 1.3137, stu_CELoss: 0.9109 DKDLoss: 0.4028 
2022-05-03 19:05:39 - train: epoch 0097, iter [04000, 05004], lr: 0.000100, loss: 1.1840, stu_CELoss: 0.8347 DKDLoss: 0.3493 
2022-05-03 19:06:13 - train: epoch 0097, iter [04100, 05004], lr: 0.000100, loss: 1.2377, stu_CELoss: 0.8473 DKDLoss: 0.3904 
2022-05-03 19:06:47 - train: epoch 0097, iter [04200, 05004], lr: 0.000100, loss: 1.1167, stu_CELoss: 0.7872 DKDLoss: 0.3294 
2022-05-03 19:07:21 - train: epoch 0097, iter [04300, 05004], lr: 0.000100, loss: 1.1481, stu_CELoss: 0.7440 DKDLoss: 0.4041 
2022-05-03 19:07:55 - train: epoch 0097, iter [04400, 05004], lr: 0.000100, loss: 1.2592, stu_CELoss: 0.8800 DKDLoss: 0.3792 
2022-05-03 19:08:28 - train: epoch 0097, iter [04500, 05004], lr: 0.000100, loss: 1.3552, stu_CELoss: 0.9772 DKDLoss: 0.3779 
2022-05-03 19:09:03 - train: epoch 0097, iter [04600, 05004], lr: 0.000100, loss: 1.2831, stu_CELoss: 0.8670 DKDLoss: 0.4161 
2022-05-03 19:09:37 - train: epoch 0097, iter [04700, 05004], lr: 0.000100, loss: 1.1729, stu_CELoss: 0.7584 DKDLoss: 0.4145 
2022-05-03 19:10:11 - train: epoch 0097, iter [04800, 05004], lr: 0.000100, loss: 1.1603, stu_CELoss: 0.7890 DKDLoss: 0.3714 
2022-05-03 19:10:45 - train: epoch 0097, iter [04900, 05004], lr: 0.000100, loss: 1.2661, stu_CELoss: 0.8881 DKDLoss: 0.3780 
2022-05-03 19:11:18 - train: epoch 0097, iter [05000, 05004], lr: 0.000100, loss: 1.0864, stu_CELoss: 0.7118 DKDLoss: 0.3746 
2022-05-03 19:11:20 - train: epoch 097, train_loss: 1.2002
2022-05-03 19:13:51 - eval: epoch: 097, tea_acc1: 78.330%, tea_acc5: 94.064%, tea_test_loss: 0.8657, stu_acc1: 77.666%, stu_acc5: 93.704%, stu_test_loss: 0.8815
2022-05-03 19:13:51 - until epoch: 097, tea_best_acc1: 78.330%, stu_best_acc1: 77.744%
2022-05-03 19:13:51 - epoch 098 lr: 0.00010000000000000003
2022-05-03 19:14:33 - train: epoch 0098, iter [00100, 05004], lr: 0.000100, loss: 1.1723, stu_CELoss: 0.7773 DKDLoss: 0.3950 
2022-05-03 19:15:06 - train: epoch 0098, iter [00200, 05004], lr: 0.000100, loss: 1.2655, stu_CELoss: 0.8762 DKDLoss: 0.3893 
2022-05-03 19:15:40 - train: epoch 0098, iter [00300, 05004], lr: 0.000100, loss: 1.1665, stu_CELoss: 0.7587 DKDLoss: 0.4078 
2022-05-03 19:16:13 - train: epoch 0098, iter [00400, 05004], lr: 0.000100, loss: 1.1990, stu_CELoss: 0.7916 DKDLoss: 0.4074 
2022-05-03 19:16:46 - train: epoch 0098, iter [00500, 05004], lr: 0.000100, loss: 1.1459, stu_CELoss: 0.8023 DKDLoss: 0.3437 
2022-05-03 19:17:19 - train: epoch 0098, iter [00600, 05004], lr: 0.000100, loss: 1.2706, stu_CELoss: 0.8251 DKDLoss: 0.4456 
2022-05-03 19:17:52 - train: epoch 0098, iter [00700, 05004], lr: 0.000100, loss: 1.2432, stu_CELoss: 0.8092 DKDLoss: 0.4340 
2022-05-03 19:18:25 - train: epoch 0098, iter [00800, 05004], lr: 0.000100, loss: 1.2742, stu_CELoss: 0.8577 DKDLoss: 0.4165 
2022-05-03 19:18:58 - train: epoch 0098, iter [00900, 05004], lr: 0.000100, loss: 1.4271, stu_CELoss: 1.0133 DKDLoss: 0.4138 
2022-05-03 19:19:32 - train: epoch 0098, iter [01000, 05004], lr: 0.000100, loss: 0.9502, stu_CELoss: 0.5849 DKDLoss: 0.3653 
2022-05-03 19:20:06 - train: epoch 0098, iter [01100, 05004], lr: 0.000100, loss: 1.1266, stu_CELoss: 0.7626 DKDLoss: 0.3639 
2022-05-03 19:20:39 - train: epoch 0098, iter [01200, 05004], lr: 0.000100, loss: 1.1584, stu_CELoss: 0.7729 DKDLoss: 0.3855 
2022-05-03 19:21:13 - train: epoch 0098, iter [01300, 05004], lr: 0.000100, loss: 1.2033, stu_CELoss: 0.8196 DKDLoss: 0.3837 
2022-05-03 19:21:46 - train: epoch 0098, iter [01400, 05004], lr: 0.000100, loss: 1.3722, stu_CELoss: 0.9406 DKDLoss: 0.4316 
2022-05-03 19:22:19 - train: epoch 0098, iter [01500, 05004], lr: 0.000100, loss: 1.2588, stu_CELoss: 0.8473 DKDLoss: 0.4115 
2022-05-03 19:22:52 - train: epoch 0098, iter [01600, 05004], lr: 0.000100, loss: 1.2593, stu_CELoss: 0.8916 DKDLoss: 0.3677 
2022-05-03 19:23:26 - train: epoch 0098, iter [01700, 05004], lr: 0.000100, loss: 1.2367, stu_CELoss: 0.8731 DKDLoss: 0.3636 
2022-05-03 19:24:00 - train: epoch 0098, iter [01800, 05004], lr: 0.000100, loss: 1.2099, stu_CELoss: 0.8528 DKDLoss: 0.3572 
2022-05-03 19:24:33 - train: epoch 0098, iter [01900, 05004], lr: 0.000100, loss: 1.1113, stu_CELoss: 0.7486 DKDLoss: 0.3626 
2022-05-03 19:25:07 - train: epoch 0098, iter [02000, 05004], lr: 0.000100, loss: 1.2568, stu_CELoss: 0.8705 DKDLoss: 0.3862 
2022-05-03 19:25:40 - train: epoch 0098, iter [02100, 05004], lr: 0.000100, loss: 1.4051, stu_CELoss: 0.9733 DKDLoss: 0.4318 
2022-05-03 19:26:14 - train: epoch 0098, iter [02200, 05004], lr: 0.000100, loss: 1.2292, stu_CELoss: 0.7990 DKDLoss: 0.4302 
2022-05-03 19:26:47 - train: epoch 0098, iter [02300, 05004], lr: 0.000100, loss: 1.1087, stu_CELoss: 0.7484 DKDLoss: 0.3603 
2022-05-03 19:27:20 - train: epoch 0098, iter [02400, 05004], lr: 0.000100, loss: 1.1222, stu_CELoss: 0.7526 DKDLoss: 0.3697 
2022-05-03 19:27:54 - train: epoch 0098, iter [02500, 05004], lr: 0.000100, loss: 1.3179, stu_CELoss: 0.9107 DKDLoss: 0.4073 
2022-05-03 19:28:27 - train: epoch 0098, iter [02600, 05004], lr: 0.000100, loss: 1.2365, stu_CELoss: 0.8310 DKDLoss: 0.4054 
2022-05-03 19:29:01 - train: epoch 0098, iter [02700, 05004], lr: 0.000100, loss: 1.0226, stu_CELoss: 0.6568 DKDLoss: 0.3658 
2022-05-03 19:29:34 - train: epoch 0098, iter [02800, 05004], lr: 0.000100, loss: 1.2516, stu_CELoss: 0.8610 DKDLoss: 0.3906 
2022-05-03 19:30:08 - train: epoch 0098, iter [02900, 05004], lr: 0.000100, loss: 1.1549, stu_CELoss: 0.7791 DKDLoss: 0.3759 
2022-05-03 19:30:42 - train: epoch 0098, iter [03000, 05004], lr: 0.000100, loss: 1.0071, stu_CELoss: 0.6568 DKDLoss: 0.3503 
2022-05-03 19:31:15 - train: epoch 0098, iter [03100, 05004], lr: 0.000100, loss: 1.2397, stu_CELoss: 0.7832 DKDLoss: 0.4565 
2022-05-03 19:31:48 - train: epoch 0098, iter [03200, 05004], lr: 0.000100, loss: 1.0827, stu_CELoss: 0.7044 DKDLoss: 0.3783 
2022-05-03 19:32:21 - train: epoch 0098, iter [03300, 05004], lr: 0.000100, loss: 1.1353, stu_CELoss: 0.7646 DKDLoss: 0.3707 
2022-05-03 19:32:54 - train: epoch 0098, iter [03400, 05004], lr: 0.000100, loss: 1.0532, stu_CELoss: 0.6228 DKDLoss: 0.4304 
2022-05-03 19:33:28 - train: epoch 0098, iter [03500, 05004], lr: 0.000100, loss: 1.1228, stu_CELoss: 0.7375 DKDLoss: 0.3853 
2022-05-03 19:34:01 - train: epoch 0098, iter [03600, 05004], lr: 0.000100, loss: 1.3435, stu_CELoss: 0.9167 DKDLoss: 0.4269 
2022-05-03 19:34:35 - train: epoch 0098, iter [03700, 05004], lr: 0.000100, loss: 1.2143, stu_CELoss: 0.8045 DKDLoss: 0.4098 
2022-05-03 19:35:08 - train: epoch 0098, iter [03800, 05004], lr: 0.000100, loss: 1.3028, stu_CELoss: 0.8791 DKDLoss: 0.4236 
2022-05-03 19:35:41 - train: epoch 0098, iter [03900, 05004], lr: 0.000100, loss: 1.1770, stu_CELoss: 0.8030 DKDLoss: 0.3740 
2022-05-03 19:36:17 - train: epoch 0098, iter [04000, 05004], lr: 0.000100, loss: 1.3853, stu_CELoss: 0.9689 DKDLoss: 0.4164 
2022-05-03 19:36:51 - train: epoch 0098, iter [04100, 05004], lr: 0.000100, loss: 1.1811, stu_CELoss: 0.7708 DKDLoss: 0.4103 
2022-05-03 19:37:25 - train: epoch 0098, iter [04200, 05004], lr: 0.000100, loss: 1.3057, stu_CELoss: 0.8903 DKDLoss: 0.4154 
2022-05-03 19:37:58 - train: epoch 0098, iter [04300, 05004], lr: 0.000100, loss: 1.0516, stu_CELoss: 0.7013 DKDLoss: 0.3503 
2022-05-03 19:38:32 - train: epoch 0098, iter [04400, 05004], lr: 0.000100, loss: 1.2542, stu_CELoss: 0.8736 DKDLoss: 0.3805 
2022-05-03 19:39:05 - train: epoch 0098, iter [04500, 05004], lr: 0.000100, loss: 1.1598, stu_CELoss: 0.7853 DKDLoss: 0.3745 
2022-05-03 19:39:38 - train: epoch 0098, iter [04600, 05004], lr: 0.000100, loss: 1.2159, stu_CELoss: 0.8367 DKDLoss: 0.3792 
2022-05-03 19:40:12 - train: epoch 0098, iter [04700, 05004], lr: 0.000100, loss: 1.4259, stu_CELoss: 0.9952 DKDLoss: 0.4307 
2022-05-03 19:40:46 - train: epoch 0098, iter [04800, 05004], lr: 0.000100, loss: 1.2595, stu_CELoss: 0.8136 DKDLoss: 0.4459 
2022-05-03 19:41:20 - train: epoch 0098, iter [04900, 05004], lr: 0.000100, loss: 1.2368, stu_CELoss: 0.8260 DKDLoss: 0.4107 
2022-05-03 19:41:53 - train: epoch 0098, iter [05000, 05004], lr: 0.000100, loss: 1.1003, stu_CELoss: 0.7560 DKDLoss: 0.3443 
2022-05-03 19:41:54 - train: epoch 098, train_loss: 1.1983
2022-05-03 19:44:27 - eval: epoch: 098, tea_acc1: 78.330%, tea_acc5: 94.064%, tea_test_loss: 0.8657, stu_acc1: 77.684%, stu_acc5: 93.708%, stu_test_loss: 0.8818
2022-05-03 19:44:27 - until epoch: 098, tea_best_acc1: 78.330%, stu_best_acc1: 77.744%
2022-05-03 19:44:27 - epoch 099 lr: 0.00010000000000000003
2022-05-03 19:45:08 - train: epoch 0099, iter [00100, 05004], lr: 0.000100, loss: 1.2262, stu_CELoss: 0.8020 DKDLoss: 0.4242 
2022-05-03 19:45:41 - train: epoch 0099, iter [00200, 05004], lr: 0.000100, loss: 1.1227, stu_CELoss: 0.7128 DKDLoss: 0.4099 
2022-05-03 19:46:14 - train: epoch 0099, iter [00300, 05004], lr: 0.000100, loss: 0.9943, stu_CELoss: 0.6176 DKDLoss: 0.3767 
2022-05-03 19:46:47 - train: epoch 0099, iter [00400, 05004], lr: 0.000100, loss: 1.1944, stu_CELoss: 0.7917 DKDLoss: 0.4027 
2022-05-03 19:47:20 - train: epoch 0099, iter [00500, 05004], lr: 0.000100, loss: 1.3305, stu_CELoss: 0.9249 DKDLoss: 0.4055 
2022-05-03 19:47:53 - train: epoch 0099, iter [00600, 05004], lr: 0.000100, loss: 1.2601, stu_CELoss: 0.8202 DKDLoss: 0.4399 
2022-05-03 19:48:27 - train: epoch 0099, iter [00700, 05004], lr: 0.000100, loss: 1.1469, stu_CELoss: 0.7417 DKDLoss: 0.4053 
2022-05-03 19:49:00 - train: epoch 0099, iter [00800, 05004], lr: 0.000100, loss: 1.3911, stu_CELoss: 0.9518 DKDLoss: 0.4393 
2022-05-03 19:49:33 - train: epoch 0099, iter [00900, 05004], lr: 0.000100, loss: 1.1789, stu_CELoss: 0.8215 DKDLoss: 0.3574 
2022-05-03 19:50:06 - train: epoch 0099, iter [01000, 05004], lr: 0.000100, loss: 1.0299, stu_CELoss: 0.6073 DKDLoss: 0.4226 
2022-05-03 19:50:40 - train: epoch 0099, iter [01100, 05004], lr: 0.000100, loss: 1.1386, stu_CELoss: 0.6965 DKDLoss: 0.4421 
2022-05-03 19:51:14 - train: epoch 0099, iter [01200, 05004], lr: 0.000100, loss: 1.0666, stu_CELoss: 0.6644 DKDLoss: 0.4021 
2022-05-03 19:51:47 - train: epoch 0099, iter [01300, 05004], lr: 0.000100, loss: 1.1013, stu_CELoss: 0.6998 DKDLoss: 0.4015 
2022-05-03 19:52:20 - train: epoch 0099, iter [01400, 05004], lr: 0.000100, loss: 1.1423, stu_CELoss: 0.7753 DKDLoss: 0.3670 
2022-05-03 19:52:53 - train: epoch 0099, iter [01500, 05004], lr: 0.000100, loss: 1.1756, stu_CELoss: 0.7355 DKDLoss: 0.4401 
2022-05-03 19:53:25 - train: epoch 0099, iter [01600, 05004], lr: 0.000100, loss: 1.3421, stu_CELoss: 0.9144 DKDLoss: 0.4278 
2022-05-03 19:53:58 - train: epoch 0099, iter [01700, 05004], lr: 0.000100, loss: 1.1480, stu_CELoss: 0.7293 DKDLoss: 0.4186 
2022-05-03 19:54:31 - train: epoch 0099, iter [01800, 05004], lr: 0.000100, loss: 1.0894, stu_CELoss: 0.7238 DKDLoss: 0.3655 
2022-05-03 19:55:04 - train: epoch 0099, iter [01900, 05004], lr: 0.000100, loss: 1.3830, stu_CELoss: 0.9404 DKDLoss: 0.4425 
2022-05-03 19:55:37 - train: epoch 0099, iter [02000, 05004], lr: 0.000100, loss: 1.0699, stu_CELoss: 0.6846 DKDLoss: 0.3854 
2022-05-03 19:56:09 - train: epoch 0099, iter [02100, 05004], lr: 0.000100, loss: 1.0323, stu_CELoss: 0.6431 DKDLoss: 0.3891 
2022-05-03 19:56:42 - train: epoch 0099, iter [02200, 05004], lr: 0.000100, loss: 1.1705, stu_CELoss: 0.7828 DKDLoss: 0.3876 
2022-05-03 19:57:15 - train: epoch 0099, iter [02300, 05004], lr: 0.000100, loss: 1.3053, stu_CELoss: 0.8894 DKDLoss: 0.4159 
2022-05-03 19:57:48 - train: epoch 0099, iter [02400, 05004], lr: 0.000100, loss: 1.3174, stu_CELoss: 0.8939 DKDLoss: 0.4235 
2022-05-03 19:58:22 - train: epoch 0099, iter [02500, 05004], lr: 0.000100, loss: 1.0281, stu_CELoss: 0.6596 DKDLoss: 0.3685 
2022-05-03 19:58:55 - train: epoch 0099, iter [02600, 05004], lr: 0.000100, loss: 1.0915, stu_CELoss: 0.7165 DKDLoss: 0.3749 
2022-05-03 19:59:28 - train: epoch 0099, iter [02700, 05004], lr: 0.000100, loss: 1.2914, stu_CELoss: 0.8961 DKDLoss: 0.3953 
2022-05-03 20:00:01 - train: epoch 0099, iter [02800, 05004], lr: 0.000100, loss: 1.2551, stu_CELoss: 0.8842 DKDLoss: 0.3709 
2022-05-03 20:00:34 - train: epoch 0099, iter [02900, 05004], lr: 0.000100, loss: 1.0173, stu_CELoss: 0.6419 DKDLoss: 0.3755 
2022-05-03 20:01:07 - train: epoch 0099, iter [03000, 05004], lr: 0.000100, loss: 1.2728, stu_CELoss: 0.8609 DKDLoss: 0.4119 
2022-05-03 20:01:41 - train: epoch 0099, iter [03100, 05004], lr: 0.000100, loss: 1.0392, stu_CELoss: 0.7079 DKDLoss: 0.3313 
2022-05-03 20:02:14 - train: epoch 0099, iter [03200, 05004], lr: 0.000100, loss: 1.2998, stu_CELoss: 0.8922 DKDLoss: 0.4076 
2022-05-03 20:02:47 - train: epoch 0099, iter [03300, 05004], lr: 0.000100, loss: 1.1382, stu_CELoss: 0.7748 DKDLoss: 0.3634 
2022-05-03 20:03:21 - train: epoch 0099, iter [03400, 05004], lr: 0.000100, loss: 1.0958, stu_CELoss: 0.7404 DKDLoss: 0.3555 
2022-05-03 20:03:54 - train: epoch 0099, iter [03500, 05004], lr: 0.000100, loss: 1.1498, stu_CELoss: 0.7769 DKDLoss: 0.3729 
2022-05-03 20:04:27 - train: epoch 0099, iter [03600, 05004], lr: 0.000100, loss: 1.1519, stu_CELoss: 0.7997 DKDLoss: 0.3522 
2022-05-03 20:05:00 - train: epoch 0099, iter [03700, 05004], lr: 0.000100, loss: 1.0272, stu_CELoss: 0.6796 DKDLoss: 0.3476 
2022-05-03 20:05:34 - train: epoch 0099, iter [03800, 05004], lr: 0.000100, loss: 1.2414, stu_CELoss: 0.8992 DKDLoss: 0.3422 
2022-05-03 20:06:07 - train: epoch 0099, iter [03900, 05004], lr: 0.000100, loss: 1.2580, stu_CELoss: 0.8638 DKDLoss: 0.3942 
2022-05-03 20:06:41 - train: epoch 0099, iter [04000, 05004], lr: 0.000100, loss: 1.2420, stu_CELoss: 0.8244 DKDLoss: 0.4176 
2022-05-03 20:07:14 - train: epoch 0099, iter [04100, 05004], lr: 0.000100, loss: 1.0073, stu_CELoss: 0.5815 DKDLoss: 0.4258 
2022-05-03 20:07:48 - train: epoch 0099, iter [04200, 05004], lr: 0.000100, loss: 1.3232, stu_CELoss: 0.8682 DKDLoss: 0.4549 
2022-05-03 20:08:21 - train: epoch 0099, iter [04300, 05004], lr: 0.000100, loss: 1.2014, stu_CELoss: 0.8182 DKDLoss: 0.3832 
2022-05-03 20:08:55 - train: epoch 0099, iter [04400, 05004], lr: 0.000100, loss: 1.0794, stu_CELoss: 0.7069 DKDLoss: 0.3725 
2022-05-03 20:09:29 - train: epoch 0099, iter [04500, 05004], lr: 0.000100, loss: 1.4109, stu_CELoss: 0.9980 DKDLoss: 0.4128 
2022-05-03 20:10:02 - train: epoch 0099, iter [04600, 05004], lr: 0.000100, loss: 1.3049, stu_CELoss: 0.8867 DKDLoss: 0.4182 
2022-05-03 20:10:36 - train: epoch 0099, iter [04700, 05004], lr: 0.000100, loss: 1.1549, stu_CELoss: 0.7526 DKDLoss: 0.4023 
2022-05-03 20:11:09 - train: epoch 0099, iter [04800, 05004], lr: 0.000100, loss: 1.2706, stu_CELoss: 0.8283 DKDLoss: 0.4423 
2022-05-03 20:11:42 - train: epoch 0099, iter [04900, 05004], lr: 0.000100, loss: 1.3572, stu_CELoss: 0.9691 DKDLoss: 0.3881 
2022-05-03 20:12:16 - train: epoch 0099, iter [05000, 05004], lr: 0.000100, loss: 1.3807, stu_CELoss: 0.9482 DKDLoss: 0.4325 
2022-05-03 20:12:17 - train: epoch 099, train_loss: 1.1946
2022-05-03 20:14:47 - eval: epoch: 099, tea_acc1: 78.330%, tea_acc5: 94.064%, tea_test_loss: 0.8657, stu_acc1: 77.648%, stu_acc5: 93.774%, stu_test_loss: 0.8822
2022-05-03 20:14:48 - until epoch: 099, tea_best_acc1: 78.330%, stu_best_acc1: 77.744%
2022-05-03 20:14:48 - epoch 100 lr: 0.00010000000000000003
2022-05-03 20:15:28 - train: epoch 0100, iter [00100, 05004], lr: 0.000100, loss: 1.2907, stu_CELoss: 0.9543 DKDLoss: 0.3364 
2022-05-03 20:16:01 - train: epoch 0100, iter [00200, 05004], lr: 0.000100, loss: 1.3144, stu_CELoss: 0.8729 DKDLoss: 0.4415 
2022-05-03 20:16:33 - train: epoch 0100, iter [00300, 05004], lr: 0.000100, loss: 1.1652, stu_CELoss: 0.7683 DKDLoss: 0.3969 
2022-05-03 20:17:05 - train: epoch 0100, iter [00400, 05004], lr: 0.000100, loss: 1.0647, stu_CELoss: 0.7135 DKDLoss: 0.3511 
2022-05-03 20:17:38 - train: epoch 0100, iter [00500, 05004], lr: 0.000100, loss: 1.0797, stu_CELoss: 0.7096 DKDLoss: 0.3701 
2022-05-03 20:18:11 - train: epoch 0100, iter [00600, 05004], lr: 0.000100, loss: 1.2320, stu_CELoss: 0.8518 DKDLoss: 0.3802 
2022-05-03 20:18:44 - train: epoch 0100, iter [00700, 05004], lr: 0.000100, loss: 1.0036, stu_CELoss: 0.6514 DKDLoss: 0.3522 
2022-05-03 20:19:17 - train: epoch 0100, iter [00800, 05004], lr: 0.000100, loss: 0.9990, stu_CELoss: 0.6512 DKDLoss: 0.3478 
2022-05-03 20:19:49 - train: epoch 0100, iter [00900, 05004], lr: 0.000100, loss: 1.1777, stu_CELoss: 0.7822 DKDLoss: 0.3955 
2022-05-03 20:20:22 - train: epoch 0100, iter [01000, 05004], lr: 0.000100, loss: 1.2132, stu_CELoss: 0.8249 DKDLoss: 0.3883 
2022-05-03 20:20:55 - train: epoch 0100, iter [01100, 05004], lr: 0.000100, loss: 1.0196, stu_CELoss: 0.6369 DKDLoss: 0.3827 
2022-05-03 20:21:28 - train: epoch 0100, iter [01200, 05004], lr: 0.000100, loss: 1.2606, stu_CELoss: 0.8585 DKDLoss: 0.4020 
2022-05-03 20:22:01 - train: epoch 0100, iter [01300, 05004], lr: 0.000100, loss: 1.1865, stu_CELoss: 0.7809 DKDLoss: 0.4057 
2022-05-03 20:22:34 - train: epoch 0100, iter [01400, 05004], lr: 0.000100, loss: 1.2639, stu_CELoss: 0.8735 DKDLoss: 0.3904 
2022-05-03 20:23:08 - train: epoch 0100, iter [01500, 05004], lr: 0.000100, loss: 1.2459, stu_CELoss: 0.8017 DKDLoss: 0.4442 
2022-05-03 20:23:41 - train: epoch 0100, iter [01600, 05004], lr: 0.000100, loss: 1.2052, stu_CELoss: 0.7952 DKDLoss: 0.4100 
2022-05-03 20:24:15 - train: epoch 0100, iter [01700, 05004], lr: 0.000100, loss: 1.1401, stu_CELoss: 0.7575 DKDLoss: 0.3826 
2022-05-03 20:24:49 - train: epoch 0100, iter [01800, 05004], lr: 0.000100, loss: 1.2294, stu_CELoss: 0.8115 DKDLoss: 0.4179 
2022-05-03 20:25:22 - train: epoch 0100, iter [01900, 05004], lr: 0.000100, loss: 1.2712, stu_CELoss: 0.8777 DKDLoss: 0.3935 
2022-05-03 20:25:56 - train: epoch 0100, iter [02000, 05004], lr: 0.000100, loss: 1.3288, stu_CELoss: 0.9330 DKDLoss: 0.3959 
2022-05-03 20:26:30 - train: epoch 0100, iter [02100, 05004], lr: 0.000100, loss: 1.2798, stu_CELoss: 0.8512 DKDLoss: 0.4286 
2022-05-03 20:27:04 - train: epoch 0100, iter [02200, 05004], lr: 0.000100, loss: 1.3020, stu_CELoss: 0.8835 DKDLoss: 0.4184 
2022-05-03 20:27:37 - train: epoch 0100, iter [02300, 05004], lr: 0.000100, loss: 1.1588, stu_CELoss: 0.8152 DKDLoss: 0.3436 
2022-05-03 20:28:10 - train: epoch 0100, iter [02400, 05004], lr: 0.000100, loss: 1.3419, stu_CELoss: 0.9083 DKDLoss: 0.4336 
2022-05-03 20:28:43 - train: epoch 0100, iter [02500, 05004], lr: 0.000100, loss: 1.1908, stu_CELoss: 0.7493 DKDLoss: 0.4416 
2022-05-03 20:29:17 - train: epoch 0100, iter [02600, 05004], lr: 0.000100, loss: 1.0926, stu_CELoss: 0.7587 DKDLoss: 0.3338 
2022-05-03 20:29:50 - train: epoch 0100, iter [02700, 05004], lr: 0.000100, loss: 1.2838, stu_CELoss: 0.8695 DKDLoss: 0.4143 
2022-05-03 20:30:23 - train: epoch 0100, iter [02800, 05004], lr: 0.000100, loss: 1.0705, stu_CELoss: 0.6913 DKDLoss: 0.3792 
2022-05-03 20:30:57 - train: epoch 0100, iter [02900, 05004], lr: 0.000100, loss: 1.1408, stu_CELoss: 0.7712 DKDLoss: 0.3696 
2022-05-03 20:31:30 - train: epoch 0100, iter [03000, 05004], lr: 0.000100, loss: 1.2632, stu_CELoss: 0.8746 DKDLoss: 0.3886 
2022-05-03 20:32:04 - train: epoch 0100, iter [03100, 05004], lr: 0.000100, loss: 1.1954, stu_CELoss: 0.7977 DKDLoss: 0.3976 
2022-05-03 20:32:37 - train: epoch 0100, iter [03200, 05004], lr: 0.000100, loss: 1.3909, stu_CELoss: 0.9793 DKDLoss: 0.4116 
2022-05-03 20:33:11 - train: epoch 0100, iter [03300, 05004], lr: 0.000100, loss: 1.1667, stu_CELoss: 0.7820 DKDLoss: 0.3848 
2022-05-03 20:33:44 - train: epoch 0100, iter [03400, 05004], lr: 0.000100, loss: 1.2323, stu_CELoss: 0.8059 DKDLoss: 0.4264 
2022-05-03 20:34:17 - train: epoch 0100, iter [03500, 05004], lr: 0.000100, loss: 1.0622, stu_CELoss: 0.6938 DKDLoss: 0.3684 
2022-05-03 20:34:51 - train: epoch 0100, iter [03600, 05004], lr: 0.000100, loss: 1.2242, stu_CELoss: 0.8516 DKDLoss: 0.3727 
2022-05-03 20:35:24 - train: epoch 0100, iter [03700, 05004], lr: 0.000100, loss: 1.0753, stu_CELoss: 0.6795 DKDLoss: 0.3957 
2022-05-03 20:35:58 - train: epoch 0100, iter [03800, 05004], lr: 0.000100, loss: 1.1212, stu_CELoss: 0.7404 DKDLoss: 0.3808 
2022-05-03 20:36:31 - train: epoch 0100, iter [03900, 05004], lr: 0.000100, loss: 0.9544, stu_CELoss: 0.5835 DKDLoss: 0.3710 
2022-05-03 20:37:05 - train: epoch 0100, iter [04000, 05004], lr: 0.000100, loss: 1.0494, stu_CELoss: 0.6389 DKDLoss: 0.4105 
2022-05-03 20:37:38 - train: epoch 0100, iter [04100, 05004], lr: 0.000100, loss: 1.2528, stu_CELoss: 0.8406 DKDLoss: 0.4122 
2022-05-03 20:38:12 - train: epoch 0100, iter [04200, 05004], lr: 0.000100, loss: 1.1903, stu_CELoss: 0.8073 DKDLoss: 0.3830 
2022-05-03 20:38:45 - train: epoch 0100, iter [04300, 05004], lr: 0.000100, loss: 1.0892, stu_CELoss: 0.6856 DKDLoss: 0.4036 
2022-05-03 20:39:18 - train: epoch 0100, iter [04400, 05004], lr: 0.000100, loss: 1.3221, stu_CELoss: 0.9400 DKDLoss: 0.3821 
2022-05-03 20:39:52 - train: epoch 0100, iter [04500, 05004], lr: 0.000100, loss: 1.1283, stu_CELoss: 0.6929 DKDLoss: 0.4354 
2022-05-03 20:40:25 - train: epoch 0100, iter [04600, 05004], lr: 0.000100, loss: 1.0445, stu_CELoss: 0.6676 DKDLoss: 0.3770 
2022-05-03 20:40:58 - train: epoch 0100, iter [04700, 05004], lr: 0.000100, loss: 1.2012, stu_CELoss: 0.7977 DKDLoss: 0.4036 
2022-05-03 20:41:32 - train: epoch 0100, iter [04800, 05004], lr: 0.000100, loss: 1.0514, stu_CELoss: 0.6736 DKDLoss: 0.3778 
2022-05-03 20:42:05 - train: epoch 0100, iter [04900, 05004], lr: 0.000100, loss: 1.1929, stu_CELoss: 0.7716 DKDLoss: 0.4212 
2022-05-03 20:42:38 - train: epoch 0100, iter [05000, 05004], lr: 0.000100, loss: 1.1732, stu_CELoss: 0.7766 DKDLoss: 0.3966 
2022-05-03 20:42:40 - train: epoch 100, train_loss: 1.1958
2022-05-03 20:45:11 - eval: epoch: 100, tea_acc1: 78.330%, tea_acc5: 94.064%, tea_test_loss: 0.8657, stu_acc1: 77.674%, stu_acc5: 93.736%, stu_test_loss: 0.8819
2022-05-03 20:45:12 - until epoch: 100, tea_best_acc1: 78.330%, stu_best_acc1: 77.744%
2022-05-03 20:45:12 - train done. train time: 49.433 hours, tea_best_acc1: 78.330%, stu_best_acc1: 77.744%
