2022-07-30 19:33:20 - teacher: resnet152
2022-07-30 19:33:20 - student: resnet50
2022-07-30 19:33:20 - num_classes: 1000
2022-07-30 19:33:20 - input_image_size: 224
2022-07-30 19:33:20 - scale: 1.1428571428571428
2022-07-30 19:33:20 - teacher_pretrained_model_path: /root/code/SimpleAICV-ImageNet-CIFAR-COCO-VOC-training/pretrained_models/resnet/resnet152-acc78.006.pth
2022-07-30 19:33:20 - student_pretrained_model_path: 
2022-07-30 19:33:20 - freeze_teacher: False
2022-07-30 19:33:20 - loss_list: ['CELoss', 'DMLLoss']
2022-07-30 19:33:20 - alpha: 1.0
2022-07-30 19:33:20 - beta: 0.5
2022-07-30 19:33:20 - T: 1.0
2022-07-30 19:33:20 - train_criterion: {'CELoss': CELoss(
  (loss): CrossEntropyLoss()
), 'DMLLoss': DMLLoss()}
2022-07-30 19:33:20 - loss_name: DMLLoss
2022-07-30 19:33:20 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2022-07-30 19:33:20 - train_dataset: <simpleAICV.classification.datasets.ilsvrc2012dataset.ILSVRC2012Dataset object at 0x7fdf74e04be0>
2022-07-30 19:33:20 - test_dataset: <simpleAICV.classification.datasets.ilsvrc2012dataset.ILSVRC2012Dataset object at 0x7fdf74e04910>
2022-07-30 19:33:20 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7fdf74e048e0>
2022-07-30 19:33:20 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7fdf74e04880>
2022-07-30 19:33:20 - seed: 0
2022-07-30 19:33:20 - batch_size: 256
2022-07-30 19:33:20 - num_workers: 16
2022-07-30 19:33:20 - optimizer: ('SGD', {'lr': 0.1, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0001, 'no_weight_decay_layer_name_list': []})
2022-07-30 19:33:20 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.1, 'milestones': [30, 60, 90]})
2022-07-30 19:33:20 - epochs: 100
2022-07-30 19:33:20 - print_interval: 100
2022-07-30 19:33:20 - accumulation_steps: 1
2022-07-30 19:33:20 - sync_bn: False
2022-07-30 19:33:20 - apex: True
2022-07-30 19:33:20 - gpus_type: NVIDIA RTX A5000
2022-07-30 19:33:20 - gpus_num: 2
2022-07-30 19:33:20 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7fdf69eb95f0>
2022-07-30 19:33:20 - --------------------parameters--------------------
2022-07-30 19:33:20 - name: teacher.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer1.0.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer1.0.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer1.0.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer1.0.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer1.0.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer1.0.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer1.0.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer1.0.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer1.0.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer1.0.downsample_conv.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer1.0.downsample_conv.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer1.0.downsample_conv.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer1.1.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer1.1.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer1.1.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer1.1.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer1.1.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer1.1.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer1.1.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer1.1.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer1.1.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer1.2.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer1.2.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer1.2.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer1.2.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer1.2.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer1.2.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer1.2.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer1.2.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer1.2.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.0.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.0.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.0.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.0.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.0.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.0.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.0.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.0.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.0.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.0.downsample_conv.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.0.downsample_conv.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.0.downsample_conv.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.1.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.1.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.1.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.1.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.1.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.1.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.1.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.1.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.1.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.2.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.2.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.2.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.2.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.2.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.2.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.2.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.2.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.2.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.3.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.3.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.3.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.3.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.3.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.3.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.3.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.3.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.3.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.4.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.4.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.4.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.4.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.4.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.4.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.4.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.4.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.4.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.5.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.5.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.5.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.5.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.5.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.5.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.5.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.5.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.5.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.6.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.6.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.6.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.6.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.6.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.6.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.6.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.6.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.6.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.7.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.7.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.7.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.7.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.7.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.7.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.7.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.7.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer2.7.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.0.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.0.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.0.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.0.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.0.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.0.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.0.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.0.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.0.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.0.downsample_conv.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.0.downsample_conv.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.0.downsample_conv.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.1.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.1.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.1.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.1.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.1.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.1.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.1.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.1.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.1.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.2.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.2.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.2.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.2.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.2.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.2.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.2.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.2.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.2.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.3.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.3.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.3.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.3.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.3.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.3.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.3.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.3.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.3.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.4.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.4.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.4.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.4.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.4.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.4.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.4.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.4.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.4.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.5.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.5.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.5.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.5.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.5.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.5.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.5.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.5.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.5.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.6.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.6.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.6.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.6.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.6.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.6.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.6.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.6.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.6.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.7.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.7.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.7.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.7.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.7.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.7.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.7.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.7.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.7.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.8.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.8.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.8.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.8.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.8.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.8.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.8.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.8.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.8.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.9.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.9.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.9.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.9.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.9.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.9.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.9.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.9.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.9.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.10.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.10.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.10.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.10.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.10.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.10.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.10.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.10.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.10.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.11.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.11.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.11.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.11.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.11.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.11.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.11.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.11.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.11.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.12.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.12.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.12.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.12.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.12.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.12.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.12.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.12.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.12.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.13.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.13.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.13.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.13.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.13.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.13.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.13.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.13.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.13.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.14.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.14.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.14.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.14.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.14.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.14.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.14.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.14.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.14.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.15.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.15.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.15.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.15.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.15.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.15.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.15.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.15.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.15.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.16.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.16.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.16.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.16.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.16.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.16.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.16.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.16.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.16.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.17.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.17.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.17.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.17.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.17.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.17.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.17.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.17.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.17.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.18.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.18.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.18.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.18.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.18.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.18.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.18.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.18.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.18.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.19.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.19.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.19.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.19.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.19.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.19.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.19.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.19.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.19.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.20.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.20.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.20.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.20.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.20.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.20.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.20.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.20.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.20.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.21.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.21.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.21.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.21.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.21.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.21.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.21.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.21.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.21.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.22.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.22.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.22.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.22.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.22.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.22.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.22.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.22.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.22.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.23.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.23.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.23.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.23.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.23.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.23.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.23.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.23.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.23.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.24.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.24.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.24.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.24.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.24.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.24.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.24.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.24.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.24.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.25.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.25.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.25.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.25.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.25.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.25.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.25.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.25.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.25.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.26.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.26.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.26.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.26.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.26.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.26.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.26.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.26.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.26.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.27.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.27.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.27.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.27.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.27.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.27.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.27.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.27.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.27.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.28.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.28.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.28.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.28.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.28.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.28.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.28.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.28.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.28.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.29.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.29.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.29.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.29.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.29.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.29.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.29.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.29.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.29.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.30.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.30.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.30.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.30.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.30.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.30.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.30.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.30.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.30.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.31.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.31.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.31.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.31.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.31.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.31.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.31.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.31.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.31.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.32.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.32.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.32.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.32.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.32.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.32.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.32.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.32.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.32.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.33.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.33.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.33.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.33.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.33.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.33.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.33.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.33.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.33.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.34.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.34.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.34.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.34.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.34.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.34.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.34.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.34.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.34.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.35.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.35.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.35.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.35.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.35.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.35.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.35.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.35.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer3.35.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer4.0.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer4.0.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer4.0.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer4.0.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer4.0.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer4.0.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer4.0.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer4.0.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer4.0.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer4.0.downsample_conv.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer4.0.downsample_conv.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer4.0.downsample_conv.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer4.1.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer4.1.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer4.1.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer4.1.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer4.1.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer4.1.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer4.1.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer4.1.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer4.1.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer4.2.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer4.2.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer4.2.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer4.2.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer4.2.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer4.2.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.layer4.2.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer4.2.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: teacher.layer4.2.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: teacher.fc.weight, grad: True
2022-07-30 19:33:20 - name: teacher.fc.bias, grad: True
2022-07-30 19:33:20 - name: student.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer1.0.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer1.0.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer1.0.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer1.0.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer1.0.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer1.0.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer1.0.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer1.0.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer1.0.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer1.0.downsample_conv.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer1.0.downsample_conv.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer1.0.downsample_conv.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer1.1.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer1.1.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer1.1.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer1.1.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer1.1.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer1.1.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer1.1.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer1.1.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer1.1.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer1.2.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer1.2.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer1.2.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer1.2.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer1.2.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer1.2.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer1.2.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer1.2.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer1.2.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer2.0.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer2.0.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer2.0.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer2.0.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer2.0.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer2.0.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer2.0.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer2.0.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer2.0.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer2.0.downsample_conv.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer2.0.downsample_conv.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer2.0.downsample_conv.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer2.1.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer2.1.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer2.1.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer2.1.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer2.1.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer2.1.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer2.1.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer2.1.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer2.1.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer2.2.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer2.2.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer2.2.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer2.2.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer2.2.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer2.2.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer2.2.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer2.2.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer2.2.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer2.3.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer2.3.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer2.3.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer2.3.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer2.3.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer2.3.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer2.3.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer2.3.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer2.3.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer3.0.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.0.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.0.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer3.0.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.0.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.0.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer3.0.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.0.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.0.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer3.0.downsample_conv.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.0.downsample_conv.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.0.downsample_conv.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer3.1.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.1.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.1.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer3.1.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.1.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.1.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer3.1.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.1.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.1.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer3.2.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.2.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.2.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer3.2.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.2.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.2.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer3.2.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.2.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.2.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer3.3.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.3.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.3.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer3.3.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.3.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.3.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer3.3.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.3.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.3.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer3.4.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.4.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.4.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer3.4.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.4.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.4.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer3.4.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.4.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.4.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer3.5.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.5.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.5.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer3.5.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.5.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.5.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer3.5.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.5.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer3.5.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer4.0.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer4.0.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer4.0.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer4.0.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer4.0.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer4.0.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer4.0.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer4.0.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer4.0.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer4.0.downsample_conv.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer4.0.downsample_conv.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer4.0.downsample_conv.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer4.1.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer4.1.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer4.1.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer4.1.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer4.1.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer4.1.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer4.1.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer4.1.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer4.1.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer4.2.conv1.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer4.2.conv1.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer4.2.conv1.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer4.2.conv2.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer4.2.conv2.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer4.2.conv2.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.layer4.2.conv3.layer.0.weight, grad: True
2022-07-30 19:33:20 - name: student.layer4.2.conv3.layer.1.weight, grad: True
2022-07-30 19:33:20 - name: student.layer4.2.conv3.layer.1.bias, grad: True
2022-07-30 19:33:20 - name: student.fc.weight, grad: True
2022-07-30 19:33:20 - name: student.fc.bias, grad: True
2022-07-30 19:33:20 - --------------------buffers--------------------
2022-07-30 19:33:20 - name: teacher.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer1.0.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer1.0.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer1.0.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer1.0.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer1.0.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer1.0.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer1.0.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer1.0.downsample_conv.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer1.0.downsample_conv.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer1.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer1.1.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer1.1.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer1.1.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer1.1.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer1.1.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer1.1.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer1.1.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer1.2.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer1.2.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer1.2.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer1.2.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer1.2.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer1.2.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer1.2.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer1.2.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer1.2.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.0.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.0.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.0.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.0.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.0.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.0.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.0.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.0.downsample_conv.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.0.downsample_conv.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.1.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.1.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.1.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.1.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.1.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.1.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.1.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.2.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.2.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.2.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.2.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.2.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.2.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.2.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.2.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.2.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.3.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.3.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.3.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.3.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.3.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.3.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.3.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.3.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.3.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.4.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.4.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.4.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.4.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.4.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.4.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.4.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.4.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.4.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.5.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.5.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.5.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.5.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.5.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.5.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.5.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.5.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.5.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.6.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.6.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.6.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.6.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.6.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.6.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.6.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.6.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.6.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.7.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.7.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.7.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.7.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.7.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.7.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.7.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.7.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer2.7.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.0.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.0.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.0.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.0.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.0.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.0.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.0.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.0.downsample_conv.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.0.downsample_conv.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.1.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.1.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.1.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.1.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.1.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.1.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.1.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.2.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.2.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.2.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.2.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.2.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.2.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.2.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.2.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.2.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.3.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.3.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.3.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.3.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.3.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.3.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.3.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.3.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.3.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.4.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.4.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.4.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.4.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.4.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.4.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.4.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.4.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.4.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.5.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.5.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.5.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.5.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.5.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.5.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.5.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.5.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.5.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.6.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.6.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.6.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.6.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.6.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.6.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.6.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.6.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.6.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.7.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.7.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.7.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.7.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.7.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.7.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.7.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.7.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.7.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.8.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.8.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.8.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.8.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.8.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.8.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.8.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.8.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.8.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.9.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.9.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.9.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.9.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.9.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.9.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.9.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.9.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.9.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.10.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.10.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.10.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.10.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.10.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.10.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.10.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.10.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.10.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.11.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.11.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.11.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.11.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.11.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.11.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.11.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.11.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.11.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.12.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.12.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.12.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.12.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.12.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.12.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.12.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.12.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.12.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.13.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.13.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.13.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.13.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.13.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.13.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.13.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.13.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.13.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.14.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.14.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.14.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.14.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.14.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.14.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.14.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.14.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.14.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.15.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.15.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.15.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.15.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.15.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.15.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.15.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.15.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.15.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.16.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.16.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.16.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.16.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.16.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.16.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.16.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.16.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.16.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.17.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.17.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.17.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.17.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.17.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.17.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.17.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.17.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.17.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.18.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.18.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.18.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.18.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.18.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.18.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.18.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.18.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.18.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.19.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.19.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.19.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.19.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.19.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.19.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.19.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.19.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.19.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.20.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.20.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.20.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.20.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.20.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.20.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.20.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.20.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.20.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.21.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.21.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.21.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.21.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.21.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.21.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.21.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.21.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.21.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.22.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.22.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.22.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.22.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.22.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.22.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.22.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.22.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.22.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.23.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.23.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.23.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.23.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.23.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.23.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.23.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.23.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.23.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.24.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.24.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.24.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.24.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.24.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.24.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.24.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.24.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.24.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.25.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.25.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.25.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.25.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.25.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.25.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.25.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.25.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.25.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.26.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.26.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.26.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.26.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.26.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.26.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.26.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.26.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.26.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.27.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.27.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.27.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.27.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.27.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.27.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.27.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.27.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.27.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.28.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.28.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.28.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.28.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.28.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.28.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.28.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.28.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.28.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.29.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.29.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.29.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.29.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.29.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.29.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.29.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.29.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.29.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.30.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.30.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.30.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.30.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.30.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.30.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.30.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.30.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.30.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.31.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.31.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.31.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.31.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.31.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.31.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.31.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.31.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.31.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.32.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.32.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.32.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.32.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.32.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.32.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.32.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.32.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.32.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.33.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.33.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.33.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.33.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.33.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.33.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.33.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.33.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.33.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.34.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.34.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.34.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.34.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.34.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.34.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.34.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.34.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.34.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.35.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.35.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.35.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.35.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.35.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.35.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.35.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.35.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer3.35.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer4.0.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer4.0.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer4.0.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer4.0.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer4.0.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer4.0.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer4.0.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer4.0.downsample_conv.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer4.0.downsample_conv.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer4.1.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer4.1.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer4.1.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer4.1.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer4.1.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer4.1.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer4.1.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer4.2.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer4.2.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer4.2.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer4.2.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer4.2.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer4.2.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: teacher.layer4.2.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: teacher.layer4.2.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: teacher.layer4.2.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer1.0.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer1.0.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer1.0.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer1.0.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer1.0.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer1.0.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer1.0.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer1.0.downsample_conv.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer1.0.downsample_conv.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer1.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer1.1.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer1.1.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer1.1.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer1.1.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer1.1.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer1.1.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer1.1.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer1.2.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer1.2.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer1.2.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer1.2.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer1.2.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer1.2.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer1.2.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer1.2.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer1.2.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer2.0.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer2.0.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer2.0.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer2.0.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer2.0.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer2.0.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer2.0.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer2.0.downsample_conv.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer2.0.downsample_conv.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer2.1.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer2.1.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer2.1.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer2.1.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer2.1.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer2.1.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer2.1.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer2.2.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer2.2.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer2.2.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer2.2.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer2.2.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer2.2.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer2.2.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer2.2.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer2.2.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer2.3.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer2.3.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer2.3.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer2.3.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer2.3.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer2.3.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer2.3.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer2.3.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer2.3.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer3.0.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer3.0.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer3.0.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer3.0.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer3.0.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer3.0.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer3.0.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer3.0.downsample_conv.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer3.0.downsample_conv.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer3.1.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer3.1.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer3.1.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer3.1.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer3.1.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer3.1.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer3.1.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer3.2.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer3.2.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer3.2.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer3.2.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer3.2.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer3.2.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer3.2.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer3.2.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer3.2.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer3.3.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer3.3.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer3.3.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer3.3.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer3.3.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer3.3.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer3.3.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer3.3.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer3.3.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer3.4.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer3.4.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer3.4.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer3.4.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer3.4.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer3.4.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer3.4.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer3.4.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer3.4.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer3.5.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer3.5.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer3.5.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer3.5.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer3.5.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer3.5.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer3.5.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer3.5.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer3.5.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer4.0.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer4.0.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer4.0.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer4.0.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer4.0.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer4.0.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer4.0.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer4.0.downsample_conv.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer4.0.downsample_conv.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer4.1.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer4.1.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer4.1.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer4.1.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer4.1.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer4.1.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer4.1.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer4.2.conv1.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer4.2.conv1.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer4.2.conv1.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer4.2.conv2.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer4.2.conv2.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer4.2.conv2.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - name: student.layer4.2.conv3.layer.1.running_mean, grad: False
2022-07-30 19:33:20 - name: student.layer4.2.conv3.layer.1.running_var, grad: False
2022-07-30 19:33:20 - name: student.layer4.2.conv3.layer.1.num_batches_tracked, grad: False
2022-07-30 19:33:20 - -----------no weight decay layers--------------
2022-07-30 19:33:20 - name: teacher.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer1.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer1.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer1.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer1.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer1.0.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer1.0.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer1.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer1.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer1.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer1.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer1.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer1.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer1.1.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer1.1.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer1.2.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer1.2.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer1.2.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer1.2.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer1.2.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer1.2.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.0.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.0.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.1.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.1.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.2.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.2.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.2.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.2.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.2.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.2.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.3.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.3.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.3.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.3.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.3.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.3.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.4.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.4.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.4.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.4.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.4.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.4.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.5.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.5.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.5.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.5.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.5.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.5.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.6.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.6.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.6.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.6.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.6.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.6.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.7.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.7.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.7.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.7.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.7.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.7.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.0.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.0.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.1.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.1.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.2.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.2.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.2.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.2.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.2.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.2.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.3.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.3.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.3.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.3.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.3.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.3.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.4.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.4.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.4.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.4.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.4.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.4.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.5.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.5.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.5.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.5.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.5.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.5.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.6.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.6.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.6.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.6.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.6.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.6.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.7.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.7.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.7.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.7.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.7.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.7.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.8.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.8.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.8.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.8.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.8.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.8.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.9.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.9.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.9.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.9.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.9.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.9.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.10.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.10.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.10.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.10.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.10.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.10.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.11.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.11.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.11.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.11.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.11.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.11.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.12.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.12.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.12.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.12.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.12.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.12.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.13.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.13.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.13.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.13.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.13.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.13.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.14.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.14.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.14.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.14.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.14.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.14.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.15.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.15.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.15.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.15.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.15.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.15.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.16.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.16.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.16.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.16.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.16.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.16.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.17.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.17.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.17.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.17.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.17.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.17.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.18.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.18.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.18.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.18.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.18.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.18.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.19.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.19.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.19.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.19.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.19.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.19.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.20.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.20.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.20.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.20.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.20.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.20.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.21.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.21.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.21.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.21.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.21.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.21.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.22.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.22.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.22.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.22.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.22.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.22.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.23.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.23.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.23.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.23.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.23.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.23.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.24.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.24.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.24.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.24.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.24.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.24.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.25.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.25.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.25.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.25.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.25.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.25.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.26.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.26.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.26.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.26.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.26.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.26.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.27.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.27.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.27.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.27.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.27.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.27.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.28.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.28.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.28.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.28.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.28.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.28.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.29.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.29.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.29.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.29.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.29.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.29.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.30.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.30.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.30.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.30.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.30.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.30.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.31.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.31.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.31.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.31.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.31.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.31.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.32.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.32.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.32.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.32.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.32.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.32.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.33.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.33.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.33.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.33.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.33.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.33.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.34.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.34.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.34.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.34.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.34.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.34.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.35.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.35.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.35.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.35.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.35.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.35.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer4.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer4.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer4.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer4.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer4.0.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer4.0.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer4.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer4.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer4.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer4.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer4.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer4.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer4.1.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer4.1.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer4.2.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer4.2.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer4.2.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer4.2.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer4.2.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer4.2.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.fc.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer1.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer1.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer1.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer1.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer1.0.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer1.0.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer1.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer1.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer1.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer1.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer1.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer1.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer1.1.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer1.1.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer1.2.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer1.2.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer1.2.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer1.2.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer1.2.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer1.2.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.0.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.0.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.1.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.1.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.2.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.2.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.2.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.2.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.2.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.2.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.3.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.3.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.3.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.3.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.3.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.3.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.0.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.0.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.1.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.1.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.2.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.2.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.2.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.2.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.2.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.2.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.3.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.3.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.3.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.3.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.3.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.3.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.4.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.4.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.4.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.4.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.4.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.4.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.5.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.5.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.5.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.5.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.5.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.5.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer4.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer4.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer4.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer4.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer4.0.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer4.0.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer4.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer4.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer4.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer4.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer4.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer4.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer4.1.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer4.1.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer4.2.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer4.2.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer4.2.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer4.2.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer4.2.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer4.2.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.fc.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-30 19:33:20 - -------------weight decay layers---------------
2022-07-30 19:33:20 - name: teacher.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer1.0.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer1.0.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer1.0.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer1.0.downsample_conv.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer1.1.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer1.1.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer1.1.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer1.2.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer1.2.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer1.2.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.0.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.0.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.0.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.0.downsample_conv.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.1.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.1.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.1.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.2.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.2.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.2.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.3.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.3.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.3.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.4.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.4.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.4.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.5.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.5.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.5.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.6.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.6.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.6.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.7.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.7.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer2.7.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.0.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.0.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.0.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.0.downsample_conv.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.1.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.1.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.1.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.2.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.2.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.2.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.3.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.3.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.3.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.4.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.4.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.4.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.5.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.5.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.5.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.6.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.6.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.6.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.7.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.7.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.7.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.8.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.8.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.8.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.9.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.9.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.9.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.10.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.10.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.10.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.11.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.11.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.11.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.12.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.12.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.12.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.13.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.13.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.13.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.14.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.14.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.14.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.15.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.15.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.15.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.16.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.16.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.16.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.17.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.17.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.17.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.18.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.18.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.18.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.19.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.19.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.19.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.20.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.20.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.20.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.21.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.21.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.21.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.22.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.22.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.22.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.23.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.23.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.23.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.24.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.24.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.24.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.25.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.25.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.25.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.26.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.26.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.26.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.27.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.27.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.27.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.28.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.28.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.28.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.29.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.29.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.29.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.30.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.30.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.30.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.31.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.31.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.31.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.32.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.32.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.32.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.33.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.33.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.33.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.34.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.34.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.34.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.35.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.35.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer3.35.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer4.0.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer4.0.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer4.0.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer4.0.downsample_conv.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer4.1.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer4.1.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer4.1.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer4.2.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer4.2.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.layer4.2.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: teacher.fc.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer1.0.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer1.0.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer1.0.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer1.0.downsample_conv.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer1.1.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer1.1.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer1.1.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer1.2.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer1.2.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer1.2.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.0.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.0.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.0.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.0.downsample_conv.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.1.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.1.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.1.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.2.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.2.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.2.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.3.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.3.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer2.3.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.0.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.0.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.0.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.0.downsample_conv.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.1.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.1.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.1.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.2.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.2.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.2.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.3.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.3.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.3.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.4.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.4.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.4.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.5.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.5.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer3.5.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer4.0.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer4.0.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer4.0.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer4.0.downsample_conv.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer4.1.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer4.1.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer4.1.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer4.2.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer4.2.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.layer4.2.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - name: student.fc.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-30 19:33:20 - epoch 001 lr: 0.100000
2022-07-30 19:34:24 - train: epoch 0001, iter [00100, 05004], lr: 0.100000, loss: 12.0796, tea_CELoss: 4.5260, stu_CELoss: 6.9059, DMLLoss: 0.6477, 
2022-07-30 19:35:22 - train: epoch 0001, iter [00200, 05004], lr: 0.100000, loss: 11.4252, tea_CELoss: 3.8049, stu_CELoss: 6.9037, DMLLoss: 0.7166, 
2022-07-30 19:36:19 - train: epoch 0001, iter [00300, 05004], lr: 0.100000, loss: 11.3603, tea_CELoss: 3.7540, stu_CELoss: 6.8723, DMLLoss: 0.7339, 
2022-07-30 19:37:16 - train: epoch 0001, iter [00400, 05004], lr: 0.100000, loss: 11.0781, tea_CELoss: 3.3762, stu_CELoss: 6.8503, DMLLoss: 0.8516, 
2022-07-30 19:38:14 - train: epoch 0001, iter [00500, 05004], lr: 0.100000, loss: 11.1213, tea_CELoss: 3.6465, stu_CELoss: 6.7927, DMLLoss: 0.6821, 
2022-07-30 19:39:11 - train: epoch 0001, iter [00600, 05004], lr: 0.100000, loss: 10.8575, tea_CELoss: 3.3770, stu_CELoss: 6.6883, DMLLoss: 0.7921, 
2022-07-30 19:40:08 - train: epoch 0001, iter [00700, 05004], lr: 0.100000, loss: 10.8696, tea_CELoss: 3.2612, stu_CELoss: 6.6955, DMLLoss: 0.9129, 
2022-07-30 19:41:05 - train: epoch 0001, iter [00800, 05004], lr: 0.100000, loss: 10.7300, tea_CELoss: 3.2218, stu_CELoss: 6.6160, DMLLoss: 0.8922, 
2022-07-30 19:42:03 - train: epoch 0001, iter [00900, 05004], lr: 0.100000, loss: 10.6550, tea_CELoss: 3.2984, stu_CELoss: 6.5072, DMLLoss: 0.8494, 
2022-07-30 19:43:00 - train: epoch 0001, iter [01000, 05004], lr: 0.100000, loss: 10.6894, tea_CELoss: 3.2365, stu_CELoss: 6.5536, DMLLoss: 0.8993, 
2022-07-30 19:43:58 - train: epoch 0001, iter [01100, 05004], lr: 0.100000, loss: 10.5973, tea_CELoss: 3.4507, stu_CELoss: 6.4407, DMLLoss: 0.7059, 
2022-07-30 19:44:55 - train: epoch 0001, iter [01200, 05004], lr: 0.100000, loss: 10.3021, tea_CELoss: 3.0484, stu_CELoss: 6.3591, DMLLoss: 0.8946, 
2022-07-30 19:45:52 - train: epoch 0001, iter [01300, 05004], lr: 0.100000, loss: 10.2741, tea_CELoss: 2.9856, stu_CELoss: 6.3466, DMLLoss: 0.9420, 
2022-07-30 19:46:50 - train: epoch 0001, iter [01400, 05004], lr: 0.100000, loss: 10.2207, tea_CELoss: 3.0807, stu_CELoss: 6.2741, DMLLoss: 0.8660, 
2022-07-30 19:47:47 - train: epoch 0001, iter [01500, 05004], lr: 0.100000, loss: 9.8999, tea_CELoss: 2.9383, stu_CELoss: 6.1359, DMLLoss: 0.8258, 
2022-07-30 19:48:45 - train: epoch 0001, iter [01600, 05004], lr: 0.100000, loss: 10.1619, tea_CELoss: 3.1606, stu_CELoss: 6.1875, DMLLoss: 0.8138, 
2022-07-30 19:49:42 - train: epoch 0001, iter [01700, 05004], lr: 0.100000, loss: 9.7125, tea_CELoss: 2.8855, stu_CELoss: 5.9690, DMLLoss: 0.8580, 
2022-07-30 19:50:40 - train: epoch 0001, iter [01800, 05004], lr: 0.100000, loss: 9.8181, tea_CELoss: 2.9647, stu_CELoss: 5.9174, DMLLoss: 0.9361, 
2022-07-30 19:51:37 - train: epoch 0001, iter [01900, 05004], lr: 0.100000, loss: 9.6129, tea_CELoss: 2.8187, stu_CELoss: 5.8843, DMLLoss: 0.9099, 
2022-07-30 19:52:34 - train: epoch 0001, iter [02000, 05004], lr: 0.100000, loss: 9.5836, tea_CELoss: 2.9766, stu_CELoss: 5.7715, DMLLoss: 0.8355, 
2022-07-30 19:53:32 - train: epoch 0001, iter [02100, 05004], lr: 0.100000, loss: 9.4276, tea_CELoss: 2.9106, stu_CELoss: 5.6135, DMLLoss: 0.9035, 
2022-07-30 19:54:29 - train: epoch 0001, iter [02200, 05004], lr: 0.100000, loss: 9.2813, tea_CELoss: 2.8031, stu_CELoss: 5.5818, DMLLoss: 0.8964, 
2022-07-30 19:55:26 - train: epoch 0001, iter [02300, 05004], lr: 0.100000, loss: 9.3084, tea_CELoss: 2.8479, stu_CELoss: 5.5609, DMLLoss: 0.8995, 
2022-07-30 19:56:24 - train: epoch 0001, iter [02400, 05004], lr: 0.100000, loss: 9.3252, tea_CELoss: 2.9564, stu_CELoss: 5.5201, DMLLoss: 0.8487, 
2022-07-30 19:57:21 - train: epoch 0001, iter [02500, 05004], lr: 0.100000, loss: 9.1390, tea_CELoss: 2.8550, stu_CELoss: 5.4195, DMLLoss: 0.8645, 
2022-07-30 19:58:18 - train: epoch 0001, iter [02600, 05004], lr: 0.100000, loss: 9.3346, tea_CELoss: 2.9041, stu_CELoss: 5.5531, DMLLoss: 0.8774, 
2022-07-30 19:59:16 - train: epoch 0001, iter [02700, 05004], lr: 0.100000, loss: 9.2790, tea_CELoss: 2.9326, stu_CELoss: 5.4889, DMLLoss: 0.8575, 
2022-07-30 20:00:13 - train: epoch 0001, iter [02800, 05004], lr: 0.100000, loss: 8.9477, tea_CELoss: 2.6647, stu_CELoss: 5.3307, DMLLoss: 0.9523, 
2022-07-30 20:01:10 - train: epoch 0001, iter [02900, 05004], lr: 0.100000, loss: 8.7755, tea_CELoss: 2.7971, stu_CELoss: 5.1758, DMLLoss: 0.8026, 
2022-07-30 20:02:08 - train: epoch 0001, iter [03000, 05004], lr: 0.100000, loss: 8.9701, tea_CELoss: 2.8152, stu_CELoss: 5.3151, DMLLoss: 0.8398, 
2022-07-30 20:03:05 - train: epoch 0001, iter [03100, 05004], lr: 0.100000, loss: 9.0023, tea_CELoss: 2.8584, stu_CELoss: 5.3000, DMLLoss: 0.8439, 
2022-07-30 20:04:02 - train: epoch 0001, iter [03200, 05004], lr: 0.100000, loss: 8.8657, tea_CELoss: 2.7916, stu_CELoss: 5.2081, DMLLoss: 0.8661, 
2022-07-30 20:05:00 - train: epoch 0001, iter [03300, 05004], lr: 0.100000, loss: 8.5866, tea_CELoss: 2.6792, stu_CELoss: 5.0247, DMLLoss: 0.8826, 
2022-07-30 20:05:57 - train: epoch 0001, iter [03400, 05004], lr: 0.100000, loss: 8.5511, tea_CELoss: 2.8443, stu_CELoss: 4.9380, DMLLoss: 0.7688, 
2022-07-30 20:06:55 - train: epoch 0001, iter [03500, 05004], lr: 0.100000, loss: 8.5033, tea_CELoss: 2.6197, stu_CELoss: 4.9466, DMLLoss: 0.9371, 
2022-07-30 20:07:52 - train: epoch 0001, iter [03600, 05004], lr: 0.100000, loss: 8.5621, tea_CELoss: 2.6308, stu_CELoss: 5.0555, DMLLoss: 0.8758, 
2022-07-30 20:08:49 - train: epoch 0001, iter [03700, 05004], lr: 0.100000, loss: 8.6892, tea_CELoss: 2.8352, stu_CELoss: 4.9742, DMLLoss: 0.8797, 
2022-07-30 20:09:47 - train: epoch 0001, iter [03800, 05004], lr: 0.100000, loss: 8.3299, tea_CELoss: 2.6275, stu_CELoss: 4.8036, DMLLoss: 0.8987, 
2022-07-30 20:10:44 - train: epoch 0001, iter [03900, 05004], lr: 0.100000, loss: 8.4694, tea_CELoss: 2.8114, stu_CELoss: 4.8533, DMLLoss: 0.8047, 
2022-07-30 20:11:42 - train: epoch 0001, iter [04000, 05004], lr: 0.100000, loss: 8.3505, tea_CELoss: 2.6556, stu_CELoss: 4.8547, DMLLoss: 0.8402, 
2022-07-30 20:12:39 - train: epoch 0001, iter [04100, 05004], lr: 0.100000, loss: 8.5393, tea_CELoss: 2.8032, stu_CELoss: 4.8224, DMLLoss: 0.9137, 
2022-07-30 20:13:36 - train: epoch 0001, iter [04200, 05004], lr: 0.100000, loss: 8.1064, tea_CELoss: 2.5102, stu_CELoss: 4.6428, DMLLoss: 0.9534, 
2022-07-30 20:14:34 - train: epoch 0001, iter [04300, 05004], lr: 0.100000, loss: 7.9465, tea_CELoss: 2.4514, stu_CELoss: 4.6437, DMLLoss: 0.8514, 
2022-07-30 20:15:31 - train: epoch 0001, iter [04400, 05004], lr: 0.100000, loss: 7.7273, tea_CELoss: 2.4279, stu_CELoss: 4.4416, DMLLoss: 0.8578, 
2022-07-30 20:16:28 - train: epoch 0001, iter [04500, 05004], lr: 0.100000, loss: 8.1552, tea_CELoss: 2.6540, stu_CELoss: 4.6601, DMLLoss: 0.8411, 
2022-07-30 20:17:26 - train: epoch 0001, iter [04600, 05004], lr: 0.100000, loss: 8.2630, tea_CELoss: 2.7013, stu_CELoss: 4.7096, DMLLoss: 0.8520, 
2022-07-30 20:18:23 - train: epoch 0001, iter [04700, 05004], lr: 0.100000, loss: 7.7717, tea_CELoss: 2.5677, stu_CELoss: 4.3822, DMLLoss: 0.8219, 
2022-07-30 20:19:21 - train: epoch 0001, iter [04800, 05004], lr: 0.100000, loss: 8.4453, tea_CELoss: 2.7931, stu_CELoss: 4.7530, DMLLoss: 0.8992, 
2022-07-30 20:20:18 - train: epoch 0001, iter [04900, 05004], lr: 0.100000, loss: 7.8014, tea_CELoss: 2.5254, stu_CELoss: 4.4007, DMLLoss: 0.8754, 
2022-07-30 20:21:15 - train: epoch 0001, iter [05000, 05004], lr: 0.100000, loss: 7.6787, tea_CELoss: 2.3817, stu_CELoss: 4.4020, DMLLoss: 0.8950, 
2022-07-30 20:21:18 - train: epoch 001, train_loss: 9.3979
2022-07-30 20:23:47 - eval: epoch: 001, tea_acc1: 54.760%, tea_acc5: 78.898%, tea_test_loss: 2.2928, stu_acc1: 16.368%, stu_acc5: 36.476%, stu_test_loss: 4.2920
2022-07-30 20:23:48 - until epoch: 001, tea_best_acc1: 54.760%, stu_best_acc1: 16.368%
2022-07-30 20:23:48 - epoch 002 lr: 0.100000
2022-07-30 20:24:52 - train: epoch 0002, iter [00100, 05004], lr: 0.100000, loss: 7.4195, tea_CELoss: 2.2842, stu_CELoss: 4.2144, DMLLoss: 0.9210, 
2022-07-30 20:25:50 - train: epoch 0002, iter [00200, 05004], lr: 0.100000, loss: 7.3336, tea_CELoss: 2.3943, stu_CELoss: 4.1615, DMLLoss: 0.7778, 
2022-07-30 20:26:47 - train: epoch 0002, iter [00300, 05004], lr: 0.100000, loss: 7.6478, tea_CELoss: 2.4639, stu_CELoss: 4.3011, DMLLoss: 0.8828, 
2022-07-30 20:27:45 - train: epoch 0002, iter [00400, 05004], lr: 0.100000, loss: 7.6385, tea_CELoss: 2.5817, stu_CELoss: 4.2897, DMLLoss: 0.7671, 
2022-07-30 20:28:42 - train: epoch 0002, iter [00500, 05004], lr: 0.100000, loss: 7.4728, tea_CELoss: 2.4471, stu_CELoss: 4.1737, DMLLoss: 0.8519, 
2022-07-30 20:29:40 - train: epoch 0002, iter [00600, 05004], lr: 0.100000, loss: 7.2577, tea_CELoss: 2.2959, stu_CELoss: 4.0861, DMLLoss: 0.8757, 
2022-07-30 20:30:38 - train: epoch 0002, iter [00700, 05004], lr: 0.100000, loss: 7.7075, tea_CELoss: 2.6207, stu_CELoss: 4.3234, DMLLoss: 0.7634, 
2022-07-30 20:31:35 - train: epoch 0002, iter [00800, 05004], lr: 0.100000, loss: 7.1363, tea_CELoss: 2.3992, stu_CELoss: 3.9432, DMLLoss: 0.7939, 
2022-07-30 20:32:33 - train: epoch 0002, iter [00900, 05004], lr: 0.100000, loss: 6.9216, tea_CELoss: 2.2405, stu_CELoss: 3.8639, DMLLoss: 0.8172, 
2022-07-30 20:33:30 - train: epoch 0002, iter [01000, 05004], lr: 0.100000, loss: 7.3619, tea_CELoss: 2.4789, stu_CELoss: 4.1027, DMLLoss: 0.7802, 
2022-07-30 20:34:28 - train: epoch 0002, iter [01100, 05004], lr: 0.100000, loss: 7.5042, tea_CELoss: 2.4766, stu_CELoss: 4.1941, DMLLoss: 0.8335, 
2022-07-30 20:35:25 - train: epoch 0002, iter [01200, 05004], lr: 0.100000, loss: 6.9547, tea_CELoss: 2.2578, stu_CELoss: 3.8863, DMLLoss: 0.8106, 
2022-07-30 20:36:23 - train: epoch 0002, iter [01300, 05004], lr: 0.100000, loss: 7.0816, tea_CELoss: 2.3199, stu_CELoss: 3.9455, DMLLoss: 0.8162, 
2022-07-30 20:37:21 - train: epoch 0002, iter [01400, 05004], lr: 0.100000, loss: 7.4032, tea_CELoss: 2.4498, stu_CELoss: 4.1388, DMLLoss: 0.8145, 
2022-07-30 20:38:18 - train: epoch 0002, iter [01500, 05004], lr: 0.100000, loss: 7.0052, tea_CELoss: 2.2919, stu_CELoss: 3.9009, DMLLoss: 0.8124, 
2022-07-30 20:39:16 - train: epoch 0002, iter [01600, 05004], lr: 0.100000, loss: 7.0224, tea_CELoss: 2.2817, stu_CELoss: 3.8838, DMLLoss: 0.8569, 
2022-07-30 20:40:14 - train: epoch 0002, iter [01700, 05004], lr: 0.100000, loss: 7.1237, tea_CELoss: 2.3984, stu_CELoss: 3.9375, DMLLoss: 0.7877, 
2022-07-30 20:41:12 - train: epoch 0002, iter [01800, 05004], lr: 0.100000, loss: 7.0183, tea_CELoss: 2.4280, stu_CELoss: 3.8349, DMLLoss: 0.7553, 
2022-07-30 20:42:09 - train: epoch 0002, iter [01900, 05004], lr: 0.100000, loss: 6.5201, tea_CELoss: 2.1113, stu_CELoss: 3.6371, DMLLoss: 0.7717, 
2022-07-30 20:43:07 - train: epoch 0002, iter [02000, 05004], lr: 0.100000, loss: 6.3334, tea_CELoss: 2.1280, stu_CELoss: 3.4618, DMLLoss: 0.7436, 
2022-07-30 20:44:04 - train: epoch 0002, iter [02100, 05004], lr: 0.100000, loss: 6.9980, tea_CELoss: 2.3919, stu_CELoss: 3.8234, DMLLoss: 0.7827, 
2022-07-30 20:45:01 - train: epoch 0002, iter [02200, 05004], lr: 0.100000, loss: 6.7797, tea_CELoss: 2.3170, stu_CELoss: 3.6845, DMLLoss: 0.7783, 
2022-07-30 20:45:59 - train: epoch 0002, iter [02300, 05004], lr: 0.100000, loss: 6.8509, tea_CELoss: 2.2784, stu_CELoss: 3.7359, DMLLoss: 0.8365, 
2022-07-30 20:46:56 - train: epoch 0002, iter [02400, 05004], lr: 0.100000, loss: 6.4479, tea_CELoss: 2.1810, stu_CELoss: 3.5281, DMLLoss: 0.7387, 
2022-07-30 20:47:54 - train: epoch 0002, iter [02500, 05004], lr: 0.100000, loss: 6.3414, tea_CELoss: 2.1944, stu_CELoss: 3.4455, DMLLoss: 0.7015, 
2022-07-30 20:48:51 - train: epoch 0002, iter [02600, 05004], lr: 0.100000, loss: 6.3802, tea_CELoss: 2.1423, stu_CELoss: 3.4740, DMLLoss: 0.7638, 
2022-07-30 20:49:49 - train: epoch 0002, iter [02700, 05004], lr: 0.100000, loss: 7.0240, tea_CELoss: 2.4275, stu_CELoss: 3.8450, DMLLoss: 0.7515, 
2022-07-30 20:50:46 - train: epoch 0002, iter [02800, 05004], lr: 0.100000, loss: 6.8170, tea_CELoss: 2.3842, stu_CELoss: 3.6679, DMLLoss: 0.7648, 
2022-07-30 20:51:44 - train: epoch 0002, iter [02900, 05004], lr: 0.100000, loss: 6.5785, tea_CELoss: 2.2782, stu_CELoss: 3.5796, DMLLoss: 0.7206, 
2022-07-30 20:52:41 - train: epoch 0002, iter [03000, 05004], lr: 0.100000, loss: 6.1994, tea_CELoss: 2.0860, stu_CELoss: 3.3745, DMLLoss: 0.7389, 
2022-07-30 20:53:39 - train: epoch 0002, iter [03100, 05004], lr: 0.100000, loss: 6.5384, tea_CELoss: 2.2083, stu_CELoss: 3.5644, DMLLoss: 0.7657, 
2022-07-30 20:54:36 - train: epoch 0002, iter [03200, 05004], lr: 0.100000, loss: 6.6525, tea_CELoss: 2.2490, stu_CELoss: 3.6172, DMLLoss: 0.7863, 
2022-07-30 20:55:34 - train: epoch 0002, iter [03300, 05004], lr: 0.100000, loss: 6.6872, tea_CELoss: 2.3870, stu_CELoss: 3.5774, DMLLoss: 0.7228, 
2022-07-30 20:56:32 - train: epoch 0002, iter [03400, 05004], lr: 0.100000, loss: 6.7098, tea_CELoss: 2.2619, stu_CELoss: 3.6551, DMLLoss: 0.7928, 
2022-07-30 20:57:29 - train: epoch 0002, iter [03500, 05004], lr: 0.100000, loss: 6.3174, tea_CELoss: 2.1626, stu_CELoss: 3.4250, DMLLoss: 0.7298, 
2022-07-30 20:58:27 - train: epoch 0002, iter [03600, 05004], lr: 0.100000, loss: 6.4270, tea_CELoss: 2.2711, stu_CELoss: 3.4542, DMLLoss: 0.7017, 
2022-07-30 20:59:24 - train: epoch 0002, iter [03700, 05004], lr: 0.100000, loss: 6.7149, tea_CELoss: 2.3385, stu_CELoss: 3.6675, DMLLoss: 0.7089, 
2022-07-30 21:00:22 - train: epoch 0002, iter [03800, 05004], lr: 0.100000, loss: 6.1964, tea_CELoss: 2.2819, stu_CELoss: 3.2799, DMLLoss: 0.6345, 
2022-07-30 21:01:19 - train: epoch 0002, iter [03900, 05004], lr: 0.100000, loss: 6.5539, tea_CELoss: 2.3247, stu_CELoss: 3.5256, DMLLoss: 0.7035, 
2022-07-30 21:02:17 - train: epoch 0002, iter [04000, 05004], lr: 0.100000, loss: 6.1105, tea_CELoss: 2.0476, stu_CELoss: 3.3015, DMLLoss: 0.7614, 
2022-07-30 21:03:15 - train: epoch 0002, iter [04100, 05004], lr: 0.100000, loss: 6.3301, tea_CELoss: 2.2139, stu_CELoss: 3.4169, DMLLoss: 0.6993, 
2022-07-30 21:04:12 - train: epoch 0002, iter [04200, 05004], lr: 0.100000, loss: 6.4224, tea_CELoss: 2.3164, stu_CELoss: 3.4502, DMLLoss: 0.6557, 
2022-07-30 21:05:10 - train: epoch 0002, iter [04300, 05004], lr: 0.100000, loss: 6.1198, tea_CELoss: 2.1721, stu_CELoss: 3.2712, DMLLoss: 0.6765, 
2022-07-30 21:06:08 - train: epoch 0002, iter [04400, 05004], lr: 0.100000, loss: 6.0993, tea_CELoss: 2.1673, stu_CELoss: 3.2511, DMLLoss: 0.6810, 
2022-07-30 21:07:06 - train: epoch 0002, iter [04500, 05004], lr: 0.100000, loss: 5.9006, tea_CELoss: 1.9970, stu_CELoss: 3.1808, DMLLoss: 0.7228, 
2022-07-30 21:08:03 - train: epoch 0002, iter [04600, 05004], lr: 0.100000, loss: 6.0806, tea_CELoss: 2.1433, stu_CELoss: 3.2422, DMLLoss: 0.6951, 
2022-07-30 21:09:01 - train: epoch 0002, iter [04700, 05004], lr: 0.100000, loss: 5.7401, tea_CELoss: 2.0213, stu_CELoss: 3.0683, DMLLoss: 0.6506, 
2022-07-30 21:09:58 - train: epoch 0002, iter [04800, 05004], lr: 0.100000, loss: 6.4619, tea_CELoss: 2.2927, stu_CELoss: 3.4414, DMLLoss: 0.7278, 
2022-07-30 21:10:56 - train: epoch 0002, iter [04900, 05004], lr: 0.100000, loss: 5.9013, tea_CELoss: 2.0957, stu_CELoss: 3.1573, DMLLoss: 0.6483, 
2022-07-30 21:11:53 - train: epoch 0002, iter [05000, 05004], lr: 0.100000, loss: 6.3495, tea_CELoss: 2.2687, stu_CELoss: 3.4014, DMLLoss: 0.6794, 
2022-07-30 21:11:56 - train: epoch 002, train_loss: 6.7829
2022-07-30 21:14:26 - eval: epoch: 002, tea_acc1: 53.758%, tea_acc5: 78.794%, tea_test_loss: 2.0851, stu_acc1: 34.694%, stu_acc5: 60.740%, stu_test_loss: nan
2022-07-30 21:14:27 - until epoch: 002, tea_best_acc1: 54.760%, stu_best_acc1: 34.694%
2022-07-30 21:14:27 - epoch 003 lr: 0.100000
2022-07-30 21:15:31 - train: epoch 0003, iter [00100, 05004], lr: 0.100000, loss: 6.0897, tea_CELoss: 2.2504, stu_CELoss: 3.2075, DMLLoss: 0.6317, 
2022-07-30 21:16:28 - train: epoch 0003, iter [00200, 05004], lr: 0.100000, loss: 6.1054, tea_CELoss: 2.1075, stu_CELoss: 3.2892, DMLLoss: 0.7087, 
2022-07-30 21:17:26 - train: epoch 0003, iter [00300, 05004], lr: 0.100000, loss: 5.9818, tea_CELoss: 2.0906, stu_CELoss: 3.2312, DMLLoss: 0.6601, 
2022-07-30 21:18:23 - train: epoch 0003, iter [00400, 05004], lr: 0.100000, loss: 6.2006, tea_CELoss: 2.2191, stu_CELoss: 3.2948, DMLLoss: 0.6867, 
2022-07-30 21:19:21 - train: epoch 0003, iter [00500, 05004], lr: 0.100000, loss: 6.0252, tea_CELoss: 2.2194, stu_CELoss: 3.1690, DMLLoss: 0.6369, 
2022-07-30 21:20:18 - train: epoch 0003, iter [00600, 05004], lr: 0.100000, loss: 5.6705, tea_CELoss: 1.9672, stu_CELoss: 3.0185, DMLLoss: 0.6847, 
2022-07-30 21:21:15 - train: epoch 0003, iter [00700, 05004], lr: 0.100000, loss: 6.1903, tea_CELoss: 2.2491, stu_CELoss: 3.2996, DMLLoss: 0.6415, 
2022-07-30 21:22:13 - train: epoch 0003, iter [00800, 05004], lr: 0.100000, loss: 6.3424, tea_CELoss: 2.1817, stu_CELoss: 3.4164, DMLLoss: 0.7443, 
2022-07-30 21:23:11 - train: epoch 0003, iter [00900, 05004], lr: 0.100000, loss: 5.8251, tea_CELoss: 2.1181, stu_CELoss: 3.0530, DMLLoss: 0.6541, 
2022-07-30 21:24:08 - train: epoch 0003, iter [01000, 05004], lr: 0.100000, loss: 6.2000, tea_CELoss: 2.3157, stu_CELoss: 3.2176, DMLLoss: 0.6667, 
2022-07-30 21:25:06 - train: epoch 0003, iter [01100, 05004], lr: 0.100000, loss: 5.7735, tea_CELoss: 2.0334, stu_CELoss: 3.0497, DMLLoss: 0.6904, 
2022-07-30 21:26:03 - train: epoch 0003, iter [01200, 05004], lr: 0.100000, loss: 5.8958, tea_CELoss: 2.1353, stu_CELoss: 3.1116, DMLLoss: 0.6489, 
2022-07-30 21:27:01 - train: epoch 0003, iter [01300, 05004], lr: 0.100000, loss: 5.4986, tea_CELoss: 2.0280, stu_CELoss: 2.8681, DMLLoss: 0.6025, 
2022-07-30 21:27:59 - train: epoch 0003, iter [01400, 05004], lr: 0.100000, loss: 5.5972, tea_CELoss: 2.0203, stu_CELoss: 2.9876, DMLLoss: 0.5893, 
2022-07-30 21:28:56 - train: epoch 0003, iter [01500, 05004], lr: 0.100000, loss: 6.2247, tea_CELoss: 2.2800, stu_CELoss: 3.3229, DMLLoss: 0.6219, 
2022-07-30 21:29:54 - train: epoch 0003, iter [01600, 05004], lr: 0.100000, loss: 5.5761, tea_CELoss: 1.9358, stu_CELoss: 2.9493, DMLLoss: 0.6909, 
2022-07-30 21:30:52 - train: epoch 0003, iter [01700, 05004], lr: 0.100000, loss: 5.6715, tea_CELoss: 2.0679, stu_CELoss: 2.9713, DMLLoss: 0.6323, 
2022-07-30 21:31:50 - train: epoch 0003, iter [01800, 05004], lr: 0.100000, loss: 5.7875, tea_CELoss: 2.1456, stu_CELoss: 2.9906, DMLLoss: 0.6513, 
2022-07-30 21:32:47 - train: epoch 0003, iter [01900, 05004], lr: 0.100000, loss: 5.6779, tea_CELoss: 2.0974, stu_CELoss: 2.9555, DMLLoss: 0.6250, 
2022-07-30 21:33:45 - train: epoch 0003, iter [02000, 05004], lr: 0.100000, loss: 6.2414, tea_CELoss: 2.3241, stu_CELoss: 3.2947, DMLLoss: 0.6227, 
2022-07-30 21:34:43 - train: epoch 0003, iter [02100, 05004], lr: 0.100000, loss: 5.7779, tea_CELoss: 2.1638, stu_CELoss: 3.0151, DMLLoss: 0.5990, 
2022-07-30 21:35:40 - train: epoch 0003, iter [02200, 05004], lr: 0.100000, loss: 6.4234, tea_CELoss: 2.4403, stu_CELoss: 3.3515, DMLLoss: 0.6315, 
2022-07-30 21:36:38 - train: epoch 0003, iter [02300, 05004], lr: 0.100000, loss: 5.5831, tea_CELoss: 2.1102, stu_CELoss: 2.8667, DMLLoss: 0.6061, 
2022-07-30 21:37:35 - train: epoch 0003, iter [02400, 05004], lr: 0.100000, loss: 5.4168, tea_CELoss: 2.0101, stu_CELoss: 2.8542, DMLLoss: 0.5525, 
2022-07-30 21:38:33 - train: epoch 0003, iter [02500, 05004], lr: 0.100000, loss: 5.9011, tea_CELoss: 2.1387, stu_CELoss: 3.1135, DMLLoss: 0.6489, 
2022-07-30 21:39:30 - train: epoch 0003, iter [02600, 05004], lr: 0.100000, loss: 5.8503, tea_CELoss: 2.1839, stu_CELoss: 3.0536, DMLLoss: 0.6128, 
2022-07-30 21:40:28 - train: epoch 0003, iter [02700, 05004], lr: 0.100000, loss: 6.2125, tea_CELoss: 2.3424, stu_CELoss: 3.2078, DMLLoss: 0.6623, 
2022-07-30 21:41:26 - train: epoch 0003, iter [02800, 05004], lr: 0.100000, loss: 5.6595, tea_CELoss: 2.0562, stu_CELoss: 2.9753, DMLLoss: 0.6280, 
2022-07-30 21:42:23 - train: epoch 0003, iter [02900, 05004], lr: 0.100000, loss: 5.7566, tea_CELoss: 2.1626, stu_CELoss: 2.9915, DMLLoss: 0.6026, 
2022-07-30 21:43:21 - train: epoch 0003, iter [03000, 05004], lr: 0.100000, loss: 5.5303, tea_CELoss: 2.0719, stu_CELoss: 2.8809, DMLLoss: 0.5774, 
2022-07-30 21:44:18 - train: epoch 0003, iter [03100, 05004], lr: 0.100000, loss: 6.2614, tea_CELoss: 2.3531, stu_CELoss: 3.2605, DMLLoss: 0.6478, 
2022-07-30 21:45:16 - train: epoch 0003, iter [03200, 05004], lr: 0.100000, loss: 5.8419, tea_CELoss: 2.2204, stu_CELoss: 3.0121, DMLLoss: 0.6094, 
2022-07-30 21:46:14 - train: epoch 0003, iter [03300, 05004], lr: 0.100000, loss: 5.5565, tea_CELoss: 1.9973, stu_CELoss: 2.9468, DMLLoss: 0.6124, 
2022-07-30 21:47:11 - train: epoch 0003, iter [03400, 05004], lr: 0.100000, loss: 6.0277, tea_CELoss: 2.3168, stu_CELoss: 3.1009, DMLLoss: 0.6100, 
2022-07-30 21:48:09 - train: epoch 0003, iter [03500, 05004], lr: 0.100000, loss: 5.4482, tea_CELoss: 2.0336, stu_CELoss: 2.7989, DMLLoss: 0.6157, 
2022-07-30 21:49:06 - train: epoch 0003, iter [03600, 05004], lr: 0.100000, loss: 5.2834, tea_CELoss: 1.9474, stu_CELoss: 2.7550, DMLLoss: 0.5809, 
2022-07-30 21:50:04 - train: epoch 0003, iter [03700, 05004], lr: 0.100000, loss: 5.7255, tea_CELoss: 2.1256, stu_CELoss: 2.9885, DMLLoss: 0.6115, 
2022-07-30 21:51:01 - train: epoch 0003, iter [03800, 05004], lr: 0.100000, loss: 5.9460, tea_CELoss: 2.1954, stu_CELoss: 3.1429, DMLLoss: 0.6077, 
2022-07-30 21:51:59 - train: epoch 0003, iter [03900, 05004], lr: 0.100000, loss: 6.2126, tea_CELoss: 2.4188, stu_CELoss: 3.2434, DMLLoss: 0.5504, 
2022-07-30 21:52:56 - train: epoch 0003, iter [04000, 05004], lr: 0.100000, loss: 5.0624, tea_CELoss: 1.9177, stu_CELoss: 2.5779, DMLLoss: 0.5668, 
2022-07-30 21:53:54 - train: epoch 0003, iter [04100, 05004], lr: 0.100000, loss: 5.6409, tea_CELoss: 2.1882, stu_CELoss: 2.9202, DMLLoss: 0.5325, 
2022-07-30 21:54:52 - train: epoch 0003, iter [04200, 05004], lr: 0.100000, loss: 5.5498, tea_CELoss: 2.1625, stu_CELoss: 2.8560, DMLLoss: 0.5313, 
2022-07-30 21:55:49 - train: epoch 0003, iter [04300, 05004], lr: 0.100000, loss: 4.9709, tea_CELoss: 1.8192, stu_CELoss: 2.5471, DMLLoss: 0.6046, 
2022-07-30 21:56:47 - train: epoch 0003, iter [04400, 05004], lr: 0.100000, loss: 5.4594, tea_CELoss: 2.0342, stu_CELoss: 2.8325, DMLLoss: 0.5928, 
2022-07-30 21:57:44 - train: epoch 0003, iter [04500, 05004], lr: 0.100000, loss: 5.2724, tea_CELoss: 1.9844, stu_CELoss: 2.7230, DMLLoss: 0.5650, 
2022-07-30 21:58:42 - train: epoch 0003, iter [04600, 05004], lr: 0.100000, loss: 5.2863, tea_CELoss: 1.9997, stu_CELoss: 2.7220, DMLLoss: 0.5646, 
2022-07-30 21:59:39 - train: epoch 0003, iter [04700, 05004], lr: 0.100000, loss: 5.5113, tea_CELoss: 2.0964, stu_CELoss: 2.8501, DMLLoss: 0.5648, 
2022-07-30 22:00:37 - train: epoch 0003, iter [04800, 05004], lr: 0.100000, loss: 5.9682, tea_CELoss: 2.3163, stu_CELoss: 3.0775, DMLLoss: 0.5744, 
2022-07-30 22:01:34 - train: epoch 0003, iter [04900, 05004], lr: 0.100000, loss: 5.6147, tea_CELoss: 2.1397, stu_CELoss: 2.9183, DMLLoss: 0.5568, 
2022-07-30 22:02:32 - train: epoch 0003, iter [05000, 05004], lr: 0.100000, loss: 5.6178, tea_CELoss: 2.1064, stu_CELoss: 2.8725, DMLLoss: 0.6389, 
2022-07-30 22:02:35 - train: epoch 003, train_loss: 5.7280
2022-07-30 22:05:05 - eval: epoch: 003, tea_acc1: 57.786%, tea_acc5: 81.914%, tea_test_loss: 1.8472, stu_acc1: 41.824%, stu_acc5: 67.724%, stu_test_loss: 2.8670
2022-07-30 22:05:06 - until epoch: 003, tea_best_acc1: 57.786%, stu_best_acc1: 41.824%
2022-07-30 22:05:06 - epoch 004 lr: 0.100000
2022-07-30 22:06:10 - train: epoch 0004, iter [00100, 05004], lr: 0.100000, loss: 5.8701, tea_CELoss: 2.2866, stu_CELoss: 3.0006, DMLLoss: 0.5829, 
2022-07-30 22:07:08 - train: epoch 0004, iter [00200, 05004], lr: 0.100000, loss: 4.9764, tea_CELoss: 1.8841, stu_CELoss: 2.5214, DMLLoss: 0.5709, 
2022-07-30 22:08:06 - train: epoch 0004, iter [00300, 05004], lr: 0.100000, loss: 5.3325, tea_CELoss: 2.0006, stu_CELoss: 2.7426, DMLLoss: 0.5893, 
2022-07-30 22:09:04 - train: epoch 0004, iter [00400, 05004], lr: 0.100000, loss: 5.3255, tea_CELoss: 2.0582, stu_CELoss: 2.7297, DMLLoss: 0.5377, 
2022-07-30 22:10:01 - train: epoch 0004, iter [00500, 05004], lr: 0.100000, loss: 5.1395, tea_CELoss: 1.8963, stu_CELoss: 2.6386, DMLLoss: 0.6046, 
2022-07-30 22:10:59 - train: epoch 0004, iter [00600, 05004], lr: 0.100000, loss: 5.9845, tea_CELoss: 2.2576, stu_CELoss: 3.0905, DMLLoss: 0.6364, 
2022-07-30 22:11:57 - train: epoch 0004, iter [00700, 05004], lr: 0.100000, loss: 5.7902, tea_CELoss: 2.2308, stu_CELoss: 2.9877, DMLLoss: 0.5718, 
2022-07-30 22:12:54 - train: epoch 0004, iter [00800, 05004], lr: 0.100000, loss: 5.4064, tea_CELoss: 1.9858, stu_CELoss: 2.8224, DMLLoss: 0.5982, 
2022-07-30 22:13:52 - train: epoch 0004, iter [00900, 05004], lr: 0.100000, loss: 4.7020, tea_CELoss: 1.6724, stu_CELoss: 2.4662, DMLLoss: 0.5634, 
2022-07-30 22:14:50 - train: epoch 0004, iter [01000, 05004], lr: 0.100000, loss: 5.2883, tea_CELoss: 1.9911, stu_CELoss: 2.7213, DMLLoss: 0.5759, 
2022-07-30 22:15:48 - train: epoch 0004, iter [01100, 05004], lr: 0.100000, loss: 5.6172, tea_CELoss: 2.1761, stu_CELoss: 2.8930, DMLLoss: 0.5481, 
2022-07-30 22:16:45 - train: epoch 0004, iter [01200, 05004], lr: 0.100000, loss: 4.9490, tea_CELoss: 1.8578, stu_CELoss: 2.5364, DMLLoss: 0.5548, 
2022-07-30 22:17:43 - train: epoch 0004, iter [01300, 05004], lr: 0.100000, loss: 5.1425, tea_CELoss: 1.9740, stu_CELoss: 2.6093, DMLLoss: 0.5592, 
2022-07-30 22:18:41 - train: epoch 0004, iter [01400, 05004], lr: 0.100000, loss: 5.3921, tea_CELoss: 2.1132, stu_CELoss: 2.7661, DMLLoss: 0.5128, 
2022-07-30 22:19:38 - train: epoch 0004, iter [01500, 05004], lr: 0.100000, loss: 5.0705, tea_CELoss: 1.9095, stu_CELoss: 2.6226, DMLLoss: 0.5384, 
2022-07-30 22:20:36 - train: epoch 0004, iter [01600, 05004], lr: 0.100000, loss: 5.2933, tea_CELoss: 2.0518, stu_CELoss: 2.7088, DMLLoss: 0.5328, 
2022-07-30 22:21:34 - train: epoch 0004, iter [01700, 05004], lr: 0.100000, loss: 5.1275, tea_CELoss: 1.9474, stu_CELoss: 2.6136, DMLLoss: 0.5665, 
2022-07-30 22:22:31 - train: epoch 0004, iter [01800, 05004], lr: 0.100000, loss: 5.7166, tea_CELoss: 2.2477, stu_CELoss: 2.9148, DMLLoss: 0.5541, 
2022-07-30 22:23:29 - train: epoch 0004, iter [01900, 05004], lr: 0.100000, loss: 5.2171, tea_CELoss: 1.9572, stu_CELoss: 2.7012, DMLLoss: 0.5587, 
2022-07-30 22:24:26 - train: epoch 0004, iter [02000, 05004], lr: 0.100000, loss: 5.5334, tea_CELoss: 2.1288, stu_CELoss: 2.8107, DMLLoss: 0.5939, 
2022-07-30 22:25:23 - train: epoch 0004, iter [02100, 05004], lr: 0.100000, loss: 5.0587, tea_CELoss: 2.0028, stu_CELoss: 2.5768, DMLLoss: 0.4791, 
2022-07-30 22:26:20 - train: epoch 0004, iter [02200, 05004], lr: 0.100000, loss: 5.5108, tea_CELoss: 2.1981, stu_CELoss: 2.7615, DMLLoss: 0.5512, 
2022-07-30 22:27:18 - train: epoch 0004, iter [02300, 05004], lr: 0.100000, loss: 4.7692, tea_CELoss: 1.7420, stu_CELoss: 2.4719, DMLLoss: 0.5553, 
2022-07-30 22:28:15 - train: epoch 0004, iter [02400, 05004], lr: 0.100000, loss: 4.8607, tea_CELoss: 1.8990, stu_CELoss: 2.4664, DMLLoss: 0.4953, 
2022-07-30 22:29:12 - train: epoch 0004, iter [02500, 05004], lr: 0.100000, loss: 4.8548, tea_CELoss: 1.9271, stu_CELoss: 2.4100, DMLLoss: 0.5178, 
2022-07-30 22:30:10 - train: epoch 0004, iter [02600, 05004], lr: 0.100000, loss: 5.3114, tea_CELoss: 2.0855, stu_CELoss: 2.6940, DMLLoss: 0.5320, 
2022-07-30 22:31:07 - train: epoch 0004, iter [02700, 05004], lr: 0.100000, loss: 5.0527, tea_CELoss: 1.9889, stu_CELoss: 2.5595, DMLLoss: 0.5043, 
2022-07-30 22:32:05 - train: epoch 0004, iter [02800, 05004], lr: 0.100000, loss: 5.0506, tea_CELoss: 1.9474, stu_CELoss: 2.5851, DMLLoss: 0.5182, 
2022-07-30 22:33:03 - train: epoch 0004, iter [02900, 05004], lr: 0.100000, loss: 5.3638, tea_CELoss: 2.0553, stu_CELoss: 2.7010, DMLLoss: 0.6075, 
2022-07-30 22:34:00 - train: epoch 0004, iter [03000, 05004], lr: 0.100000, loss: 5.2785, tea_CELoss: 2.0814, stu_CELoss: 2.6893, DMLLoss: 0.5078, 
2022-07-30 22:34:58 - train: epoch 0004, iter [03100, 05004], lr: 0.100000, loss: 5.3330, tea_CELoss: 2.0996, stu_CELoss: 2.6997, DMLLoss: 0.5337, 
2022-07-30 22:35:55 - train: epoch 0004, iter [03200, 05004], lr: 0.100000, loss: 5.3142, tea_CELoss: 2.0665, stu_CELoss: 2.7210, DMLLoss: 0.5267, 
2022-07-30 22:36:53 - train: epoch 0004, iter [03300, 05004], lr: 0.100000, loss: 5.2930, tea_CELoss: 2.0614, stu_CELoss: 2.6885, DMLLoss: 0.5431, 
2022-07-30 22:37:50 - train: epoch 0004, iter [03400, 05004], lr: 0.100000, loss: 5.1805, tea_CELoss: 2.0201, stu_CELoss: 2.6354, DMLLoss: 0.5250, 
2022-07-30 22:38:48 - train: epoch 0004, iter [03500, 05004], lr: 0.100000, loss: 5.1066, tea_CELoss: 2.0272, stu_CELoss: 2.5252, DMLLoss: 0.5542, 
2022-07-30 22:39:45 - train: epoch 0004, iter [03600, 05004], lr: 0.100000, loss: 5.0926, tea_CELoss: 2.0190, stu_CELoss: 2.5845, DMLLoss: 0.4892, 
2022-07-30 22:40:43 - train: epoch 0004, iter [03700, 05004], lr: 0.100000, loss: 5.2198, tea_CELoss: 1.9572, stu_CELoss: 2.6972, DMLLoss: 0.5654, 
2022-07-30 22:41:40 - train: epoch 0004, iter [03800, 05004], lr: 0.100000, loss: 4.7195, tea_CELoss: 1.7992, stu_CELoss: 2.4083, DMLLoss: 0.5120, 
2022-07-30 22:42:37 - train: epoch 0004, iter [03900, 05004], lr: 0.100000, loss: 4.9347, tea_CELoss: 1.8997, stu_CELoss: 2.5176, DMLLoss: 0.5174, 
2022-07-30 22:43:35 - train: epoch 0004, iter [04000, 05004], lr: 0.100000, loss: 4.7996, tea_CELoss: 1.8179, stu_CELoss: 2.4602, DMLLoss: 0.5215, 
2022-07-30 22:44:33 - train: epoch 0004, iter [04100, 05004], lr: 0.100000, loss: 4.9599, tea_CELoss: 1.9434, stu_CELoss: 2.5407, DMLLoss: 0.4757, 
2022-07-30 22:45:31 - train: epoch 0004, iter [04200, 05004], lr: 0.100000, loss: 4.7497, tea_CELoss: 1.8744, stu_CELoss: 2.3778, DMLLoss: 0.4975, 
2022-07-30 22:46:28 - train: epoch 0004, iter [04300, 05004], lr: 0.100000, loss: 4.7412, tea_CELoss: 1.8435, stu_CELoss: 2.3699, DMLLoss: 0.5278, 
2022-07-30 22:47:26 - train: epoch 0004, iter [04400, 05004], lr: 0.100000, loss: 4.9823, tea_CELoss: 1.8727, stu_CELoss: 2.5728, DMLLoss: 0.5368, 
2022-07-30 22:48:24 - train: epoch 0004, iter [04500, 05004], lr: 0.100000, loss: 4.2393, tea_CELoss: 1.6152, stu_CELoss: 2.1597, DMLLoss: 0.4644, 
2022-07-30 22:49:21 - train: epoch 0004, iter [04600, 05004], lr: 0.100000, loss: 4.6634, tea_CELoss: 1.8300, stu_CELoss: 2.3517, DMLLoss: 0.4817, 
2022-07-30 22:50:19 - train: epoch 0004, iter [04700, 05004], lr: 0.100000, loss: 4.9784, tea_CELoss: 1.9029, stu_CELoss: 2.5463, DMLLoss: 0.5292, 
2022-07-30 22:51:16 - train: epoch 0004, iter [04800, 05004], lr: 0.100000, loss: 4.5201, tea_CELoss: 1.7249, stu_CELoss: 2.2874, DMLLoss: 0.5079, 
2022-07-30 22:52:14 - train: epoch 0004, iter [04900, 05004], lr: 0.100000, loss: 5.2102, tea_CELoss: 2.0731, stu_CELoss: 2.6233, DMLLoss: 0.5138, 
2022-07-30 22:53:12 - train: epoch 0004, iter [05000, 05004], lr: 0.100000, loss: 5.0423, tea_CELoss: 1.9169, stu_CELoss: 2.5850, DMLLoss: 0.5404, 
2022-07-30 22:53:14 - train: epoch 004, train_loss: 5.2070
2022-07-30 22:55:46 - eval: epoch: 004, tea_acc1: 57.648%, tea_acc5: 82.072%, tea_test_loss: 1.8106, stu_acc1: 46.426%, stu_acc5: 72.618%, stu_test_loss: 2.3549
2022-07-30 22:55:47 - until epoch: 004, tea_best_acc1: 57.786%, stu_best_acc1: 46.426%
2022-07-30 22:55:47 - epoch 005 lr: 0.100000
2022-07-30 22:56:50 - train: epoch 0005, iter [00100, 05004], lr: 0.100000, loss: 5.2716, tea_CELoss: 2.0709, stu_CELoss: 2.6782, DMLLoss: 0.5225, 
2022-07-30 22:57:48 - train: epoch 0005, iter [00200, 05004], lr: 0.100000, loss: 5.0827, tea_CELoss: 2.0106, stu_CELoss: 2.5532, DMLLoss: 0.5189, 
2022-07-30 22:58:45 - train: epoch 0005, iter [00300, 05004], lr: 0.100000, loss: 5.4749, tea_CELoss: 2.1322, stu_CELoss: 2.7908, DMLLoss: 0.5519, 
2022-07-30 22:59:42 - train: epoch 0005, iter [00400, 05004], lr: 0.100000, loss: 4.9126, tea_CELoss: 1.9495, stu_CELoss: 2.4395, DMLLoss: 0.5237, 
2022-07-30 23:00:39 - train: epoch 0005, iter [00500, 05004], lr: 0.100000, loss: 4.7714, tea_CELoss: 1.8773, stu_CELoss: 2.3969, DMLLoss: 0.4972, 
2022-07-30 23:01:37 - train: epoch 0005, iter [00600, 05004], lr: 0.100000, loss: 5.0964, tea_CELoss: 2.0419, stu_CELoss: 2.5446, DMLLoss: 0.5099, 
2022-07-30 23:02:34 - train: epoch 0005, iter [00700, 05004], lr: 0.100000, loss: 5.0833, tea_CELoss: 2.0134, stu_CELoss: 2.5815, DMLLoss: 0.4884, 
2022-07-30 23:03:31 - train: epoch 0005, iter [00800, 05004], lr: 0.100000, loss: 5.5648, tea_CELoss: 2.1936, stu_CELoss: 2.8194, DMLLoss: 0.5519, 
2022-07-30 23:04:29 - train: epoch 0005, iter [00900, 05004], lr: 0.100000, loss: 4.8484, tea_CELoss: 1.9371, stu_CELoss: 2.3868, DMLLoss: 0.5245, 
2022-07-30 23:05:26 - train: epoch 0005, iter [01000, 05004], lr: 0.100000, loss: 5.0721, tea_CELoss: 2.0571, stu_CELoss: 2.5466, DMLLoss: 0.4683, 
2022-07-30 23:06:23 - train: epoch 0005, iter [01100, 05004], lr: 0.100000, loss: 4.9838, tea_CELoss: 1.8968, stu_CELoss: 2.5536, DMLLoss: 0.5334, 
2022-07-30 23:07:21 - train: epoch 0005, iter [01200, 05004], lr: 0.100000, loss: 5.0054, tea_CELoss: 1.9464, stu_CELoss: 2.5378, DMLLoss: 0.5213, 
2022-07-30 23:08:18 - train: epoch 0005, iter [01300, 05004], lr: 0.100000, loss: 4.6833, tea_CELoss: 1.8887, stu_CELoss: 2.3203, DMLLoss: 0.4743, 
2022-07-30 23:09:15 - train: epoch 0005, iter [01400, 05004], lr: 0.100000, loss: 4.9660, tea_CELoss: 1.9736, stu_CELoss: 2.5160, DMLLoss: 0.4765, 
2022-07-30 23:10:13 - train: epoch 0005, iter [01500, 05004], lr: 0.100000, loss: 4.7443, tea_CELoss: 1.8380, stu_CELoss: 2.4000, DMLLoss: 0.5063, 
2022-07-30 23:11:10 - train: epoch 0005, iter [01600, 05004], lr: 0.100000, loss: 4.3121, tea_CELoss: 1.7360, stu_CELoss: 2.2024, DMLLoss: 0.3737, 
2022-07-30 23:12:07 - train: epoch 0005, iter [01700, 05004], lr: 0.100000, loss: 5.2985, tea_CELoss: 2.1470, stu_CELoss: 2.6233, DMLLoss: 0.5282, 
2022-07-30 23:13:05 - train: epoch 0005, iter [01800, 05004], lr: 0.100000, loss: 4.7395, tea_CELoss: 1.7879, stu_CELoss: 2.3896, DMLLoss: 0.5620, 
2022-07-30 23:14:02 - train: epoch 0005, iter [01900, 05004], lr: 0.100000, loss: 4.7741, tea_CELoss: 1.8835, stu_CELoss: 2.4158, DMLLoss: 0.4747, 
2022-07-30 23:14:59 - train: epoch 0005, iter [02000, 05004], lr: 0.100000, loss: 4.9527, tea_CELoss: 1.9540, stu_CELoss: 2.4841, DMLLoss: 0.5146, 
2022-07-30 23:15:56 - train: epoch 0005, iter [02100, 05004], lr: 0.100000, loss: 4.6769, tea_CELoss: 1.8609, stu_CELoss: 2.3438, DMLLoss: 0.4722, 
2022-07-30 23:16:54 - train: epoch 0005, iter [02200, 05004], lr: 0.100000, loss: 4.7802, tea_CELoss: 1.8411, stu_CELoss: 2.4346, DMLLoss: 0.5045, 
2022-07-30 23:17:51 - train: epoch 0005, iter [02300, 05004], lr: 0.100000, loss: 4.4462, tea_CELoss: 1.7273, stu_CELoss: 2.1915, DMLLoss: 0.5274, 
2022-07-30 23:18:48 - train: epoch 0005, iter [02400, 05004], lr: 0.100000, loss: 4.7992, tea_CELoss: 1.8836, stu_CELoss: 2.4324, DMLLoss: 0.4833, 
2022-07-30 23:19:46 - train: epoch 0005, iter [02500, 05004], lr: 0.100000, loss: 4.9935, tea_CELoss: 1.9840, stu_CELoss: 2.5424, DMLLoss: 0.4671, 
2022-07-30 23:20:43 - train: epoch 0005, iter [02600, 05004], lr: 0.100000, loss: 4.8233, tea_CELoss: 1.8649, stu_CELoss: 2.4560, DMLLoss: 0.5024, 
2022-07-30 23:21:40 - train: epoch 0005, iter [02700, 05004], lr: 0.100000, loss: 4.8887, tea_CELoss: 1.9411, stu_CELoss: 2.4597, DMLLoss: 0.4879, 
2022-07-30 23:22:38 - train: epoch 0005, iter [02800, 05004], lr: 0.100000, loss: 4.8498, tea_CELoss: 1.8528, stu_CELoss: 2.4594, DMLLoss: 0.5376, 
2022-07-30 23:23:35 - train: epoch 0005, iter [02900, 05004], lr: 0.100000, loss: 5.0072, tea_CELoss: 2.0225, stu_CELoss: 2.5013, DMLLoss: 0.4835, 
2022-07-30 23:24:32 - train: epoch 0005, iter [03000, 05004], lr: 0.100000, loss: 4.9233, tea_CELoss: 1.9574, stu_CELoss: 2.4830, DMLLoss: 0.4830, 
2022-07-30 23:25:29 - train: epoch 0005, iter [03100, 05004], lr: 0.100000, loss: 4.9184, tea_CELoss: 1.9112, stu_CELoss: 2.5155, DMLLoss: 0.4917, 
2022-07-30 23:26:27 - train: epoch 0005, iter [03200, 05004], lr: 0.100000, loss: 4.9889, tea_CELoss: 1.9721, stu_CELoss: 2.5358, DMLLoss: 0.4810, 
2022-07-30 23:27:24 - train: epoch 0005, iter [03300, 05004], lr: 0.100000, loss: 4.6529, tea_CELoss: 1.8992, stu_CELoss: 2.2793, DMLLoss: 0.4744, 
2022-07-30 23:28:22 - train: epoch 0005, iter [03400, 05004], lr: 0.100000, loss: 4.9341, tea_CELoss: 2.0262, stu_CELoss: 2.4534, DMLLoss: 0.4545, 
2022-07-30 23:29:19 - train: epoch 0005, iter [03500, 05004], lr: 0.100000, loss: 5.2472, tea_CELoss: 2.1325, stu_CELoss: 2.6059, DMLLoss: 0.5089, 
2022-07-30 23:30:17 - train: epoch 0005, iter [03600, 05004], lr: 0.100000, loss: 5.0610, tea_CELoss: 1.9764, stu_CELoss: 2.5551, DMLLoss: 0.5295, 
2022-07-30 23:31:14 - train: epoch 0005, iter [03700, 05004], lr: 0.100000, loss: 4.7592, tea_CELoss: 1.9357, stu_CELoss: 2.3855, DMLLoss: 0.4380, 
2022-07-30 23:32:11 - train: epoch 0005, iter [03800, 05004], lr: 0.100000, loss: 4.8722, tea_CELoss: 1.9120, stu_CELoss: 2.4524, DMLLoss: 0.5078, 
2022-07-30 23:33:09 - train: epoch 0005, iter [03900, 05004], lr: 0.100000, loss: 5.1228, tea_CELoss: 2.0898, stu_CELoss: 2.5418, DMLLoss: 0.4911, 
2022-07-30 23:34:06 - train: epoch 0005, iter [04000, 05004], lr: 0.100000, loss: 4.9552, tea_CELoss: 2.0000, stu_CELoss: 2.4507, DMLLoss: 0.5045, 
2022-07-30 23:35:03 - train: epoch 0005, iter [04100, 05004], lr: 0.100000, loss: 4.8510, tea_CELoss: 2.0255, stu_CELoss: 2.3902, DMLLoss: 0.4353, 
2022-07-30 23:36:01 - train: epoch 0005, iter [04200, 05004], lr: 0.100000, loss: 5.0991, tea_CELoss: 2.0927, stu_CELoss: 2.5507, DMLLoss: 0.4557, 
2022-07-30 23:36:58 - train: epoch 0005, iter [04300, 05004], lr: 0.100000, loss: 4.9649, tea_CELoss: 2.0122, stu_CELoss: 2.4688, DMLLoss: 0.4839, 
2022-07-30 23:37:55 - train: epoch 0005, iter [04400, 05004], lr: 0.100000, loss: 5.1985, tea_CELoss: 2.1183, stu_CELoss: 2.6087, DMLLoss: 0.4715, 
2022-07-30 23:38:53 - train: epoch 0005, iter [04500, 05004], lr: 0.100000, loss: 4.9621, tea_CELoss: 1.9861, stu_CELoss: 2.4766, DMLLoss: 0.4995, 
2022-07-30 23:39:50 - train: epoch 0005, iter [04600, 05004], lr: 0.100000, loss: 4.6043, tea_CELoss: 1.8918, stu_CELoss: 2.2842, DMLLoss: 0.4283, 
2022-07-30 23:40:47 - train: epoch 0005, iter [04700, 05004], lr: 0.100000, loss: 4.4981, tea_CELoss: 1.7931, stu_CELoss: 2.2398, DMLLoss: 0.4652, 
2022-07-30 23:41:45 - train: epoch 0005, iter [04800, 05004], lr: 0.100000, loss: 4.7284, tea_CELoss: 1.9799, stu_CELoss: 2.3027, DMLLoss: 0.4457, 
2022-07-30 23:42:42 - train: epoch 0005, iter [04900, 05004], lr: 0.100000, loss: 5.5049, tea_CELoss: 2.2003, stu_CELoss: 2.7299, DMLLoss: 0.5748, 
2022-07-30 23:43:39 - train: epoch 0005, iter [05000, 05004], lr: 0.100000, loss: 4.7459, tea_CELoss: 1.9053, stu_CELoss: 2.3457, DMLLoss: 0.4949, 
2022-07-30 23:43:42 - train: epoch 005, train_loss: 4.9016
2022-07-30 23:46:12 - eval: epoch: 005, tea_acc1: 57.278%, tea_acc5: 81.680%, tea_test_loss: 1.8024, stu_acc1: 50.508%, stu_acc5: 76.842%, stu_test_loss: 2.1167
2022-07-30 23:46:13 - until epoch: 005, tea_best_acc1: 57.786%, stu_best_acc1: 50.508%
2022-07-30 23:46:13 - epoch 006 lr: 0.100000
2022-07-30 23:47:16 - train: epoch 0006, iter [00100, 05004], lr: 0.100000, loss: 4.5616, tea_CELoss: 1.7844, stu_CELoss: 2.2919, DMLLoss: 0.4853, 
2022-07-30 23:48:14 - train: epoch 0006, iter [00200, 05004], lr: 0.100000, loss: 4.8178, tea_CELoss: 1.9472, stu_CELoss: 2.3897, DMLLoss: 0.4810, 
2022-07-30 23:49:11 - train: epoch 0006, iter [00300, 05004], lr: 0.100000, loss: 4.4795, tea_CELoss: 1.6975, stu_CELoss: 2.2376, DMLLoss: 0.5444, 
2022-07-30 23:50:09 - train: epoch 0006, iter [00400, 05004], lr: 0.100000, loss: 4.7406, tea_CELoss: 1.9221, stu_CELoss: 2.3527, DMLLoss: 0.4659, 
2022-07-30 23:51:06 - train: epoch 0006, iter [00500, 05004], lr: 0.100000, loss: 4.4764, tea_CELoss: 1.8122, stu_CELoss: 2.2016, DMLLoss: 0.4625, 
2022-07-30 23:52:03 - train: epoch 0006, iter [00600, 05004], lr: 0.100000, loss: 4.5198, tea_CELoss: 1.8191, stu_CELoss: 2.2365, DMLLoss: 0.4641, 
2022-07-30 23:53:01 - train: epoch 0006, iter [00700, 05004], lr: 0.100000, loss: 5.0889, tea_CELoss: 2.0459, stu_CELoss: 2.5624, DMLLoss: 0.4806, 
2022-07-30 23:53:58 - train: epoch 0006, iter [00800, 05004], lr: 0.100000, loss: 4.4247, tea_CELoss: 1.7466, stu_CELoss: 2.2393, DMLLoss: 0.4388, 
2022-07-30 23:54:56 - train: epoch 0006, iter [00900, 05004], lr: 0.100000, loss: 4.5900, tea_CELoss: 1.8692, stu_CELoss: 2.2288, DMLLoss: 0.4920, 
2022-07-30 23:55:53 - train: epoch 0006, iter [01000, 05004], lr: 0.100000, loss: 4.8077, tea_CELoss: 1.9131, stu_CELoss: 2.4036, DMLLoss: 0.4910, 
2022-07-30 23:56:51 - train: epoch 0006, iter [01100, 05004], lr: 0.100000, loss: 4.8612, tea_CELoss: 1.9267, stu_CELoss: 2.4396, DMLLoss: 0.4949, 
2022-07-30 23:57:48 - train: epoch 0006, iter [01200, 05004], lr: 0.100000, loss: 4.7951, tea_CELoss: 1.9353, stu_CELoss: 2.3589, DMLLoss: 0.5009, 
2022-07-30 23:58:46 - train: epoch 0006, iter [01300, 05004], lr: 0.100000, loss: 4.6516, tea_CELoss: 1.8738, stu_CELoss: 2.3310, DMLLoss: 0.4468, 
2022-07-30 23:59:44 - train: epoch 0006, iter [01400, 05004], lr: 0.100000, loss: 4.9840, tea_CELoss: 1.9911, stu_CELoss: 2.4701, DMLLoss: 0.5228, 
2022-07-31 00:00:41 - train: epoch 0006, iter [01500, 05004], lr: 0.100000, loss: 5.1703, tea_CELoss: 2.0620, stu_CELoss: 2.6349, DMLLoss: 0.4733, 
2022-07-31 00:01:39 - train: epoch 0006, iter [01600, 05004], lr: 0.100000, loss: 4.3549, tea_CELoss: 1.7320, stu_CELoss: 2.1503, DMLLoss: 0.4727, 
2022-07-31 00:02:36 - train: epoch 0006, iter [01700, 05004], lr: 0.100000, loss: 5.0550, tea_CELoss: 2.0585, stu_CELoss: 2.5142, DMLLoss: 0.4822, 
2022-07-31 00:03:34 - train: epoch 0006, iter [01800, 05004], lr: 0.100000, loss: 4.7438, tea_CELoss: 1.9452, stu_CELoss: 2.3314, DMLLoss: 0.4672, 
2022-07-31 00:04:31 - train: epoch 0006, iter [01900, 05004], lr: 0.100000, loss: 4.4096, tea_CELoss: 1.7771, stu_CELoss: 2.1977, DMLLoss: 0.4349, 
2022-07-31 00:05:29 - train: epoch 0006, iter [02000, 05004], lr: 0.100000, loss: 5.0050, tea_CELoss: 2.0063, stu_CELoss: 2.5143, DMLLoss: 0.4845, 
2022-07-31 00:06:26 - train: epoch 0006, iter [02100, 05004], lr: 0.100000, loss: 4.7488, tea_CELoss: 1.9718, stu_CELoss: 2.3313, DMLLoss: 0.4458, 
2022-07-31 00:07:24 - train: epoch 0006, iter [02200, 05004], lr: 0.100000, loss: 4.2869, tea_CELoss: 1.7474, stu_CELoss: 2.1241, DMLLoss: 0.4154, 
2022-07-31 00:08:21 - train: epoch 0006, iter [02300, 05004], lr: 0.100000, loss: 4.5720, tea_CELoss: 1.8867, stu_CELoss: 2.2614, DMLLoss: 0.4239, 
2022-07-31 00:09:19 - train: epoch 0006, iter [02400, 05004], lr: 0.100000, loss: 4.7925, tea_CELoss: 1.9083, stu_CELoss: 2.3777, DMLLoss: 0.5065, 
2022-07-31 00:10:16 - train: epoch 0006, iter [02500, 05004], lr: 0.100000, loss: 4.5128, tea_CELoss: 1.8439, stu_CELoss: 2.2183, DMLLoss: 0.4505, 
2022-07-31 00:11:14 - train: epoch 0006, iter [02600, 05004], lr: 0.100000, loss: 4.6682, tea_CELoss: 1.9542, stu_CELoss: 2.2852, DMLLoss: 0.4288, 
2022-07-31 00:12:12 - train: epoch 0006, iter [02700, 05004], lr: 0.100000, loss: 4.7792, tea_CELoss: 1.9687, stu_CELoss: 2.3966, DMLLoss: 0.4140, 
2022-07-31 00:13:09 - train: epoch 0006, iter [02800, 05004], lr: 0.100000, loss: 4.2254, tea_CELoss: 1.7042, stu_CELoss: 2.0467, DMLLoss: 0.4745, 
2022-07-31 00:14:07 - train: epoch 0006, iter [02900, 05004], lr: 0.100000, loss: 4.6834, tea_CELoss: 1.8953, stu_CELoss: 2.3114, DMLLoss: 0.4767, 
2022-07-31 00:15:04 - train: epoch 0006, iter [03000, 05004], lr: 0.100000, loss: 4.5546, tea_CELoss: 1.8181, stu_CELoss: 2.2322, DMLLoss: 0.5043, 
2022-07-31 00:16:02 - train: epoch 0006, iter [03100, 05004], lr: 0.100000, loss: 4.6467, tea_CELoss: 1.8081, stu_CELoss: 2.2968, DMLLoss: 0.5419, 
2022-07-31 00:16:59 - train: epoch 0006, iter [03200, 05004], lr: 0.100000, loss: 4.4788, tea_CELoss: 1.8349, stu_CELoss: 2.1931, DMLLoss: 0.4508, 
2022-07-31 00:17:57 - train: epoch 0006, iter [03300, 05004], lr: 0.100000, loss: 4.4938, tea_CELoss: 1.7803, stu_CELoss: 2.2669, DMLLoss: 0.4466, 
2022-07-31 00:18:54 - train: epoch 0006, iter [03400, 05004], lr: 0.100000, loss: 4.6990, tea_CELoss: 1.9271, stu_CELoss: 2.3060, DMLLoss: 0.4660, 
2022-07-31 00:19:52 - train: epoch 0006, iter [03500, 05004], lr: 0.100000, loss: 4.6046, tea_CELoss: 1.8995, stu_CELoss: 2.2681, DMLLoss: 0.4370, 
2022-07-31 00:20:50 - train: epoch 0006, iter [03600, 05004], lr: 0.100000, loss: 4.6134, tea_CELoss: 1.9100, stu_CELoss: 2.2502, DMLLoss: 0.4532, 
2022-07-31 00:21:47 - train: epoch 0006, iter [03700, 05004], lr: 0.100000, loss: 4.4488, tea_CELoss: 1.8848, stu_CELoss: 2.1808, DMLLoss: 0.3831, 
2022-07-31 00:22:45 - train: epoch 0006, iter [03800, 05004], lr: 0.100000, loss: 4.3941, tea_CELoss: 1.7541, stu_CELoss: 2.1671, DMLLoss: 0.4730, 
2022-07-31 00:23:42 - train: epoch 0006, iter [03900, 05004], lr: 0.100000, loss: 4.6111, tea_CELoss: 1.8927, stu_CELoss: 2.2940, DMLLoss: 0.4244, 
2022-07-31 00:24:40 - train: epoch 0006, iter [04000, 05004], lr: 0.100000, loss: 4.6306, tea_CELoss: 1.9394, stu_CELoss: 2.2127, DMLLoss: 0.4786, 
2022-07-31 00:25:38 - train: epoch 0006, iter [04100, 05004], lr: 0.100000, loss: 4.5229, tea_CELoss: 1.8324, stu_CELoss: 2.2514, DMLLoss: 0.4392, 
2022-07-31 00:26:35 - train: epoch 0006, iter [04200, 05004], lr: 0.100000, loss: 4.3175, tea_CELoss: 1.8097, stu_CELoss: 2.0906, DMLLoss: 0.4172, 
2022-07-31 00:27:33 - train: epoch 0006, iter [04300, 05004], lr: 0.100000, loss: 4.6601, tea_CELoss: 1.8409, stu_CELoss: 2.3495, DMLLoss: 0.4696, 
2022-07-31 00:28:31 - train: epoch 0006, iter [04400, 05004], lr: 0.100000, loss: 4.6314, tea_CELoss: 1.8483, stu_CELoss: 2.2892, DMLLoss: 0.4938, 
2022-07-31 00:29:28 - train: epoch 0006, iter [04500, 05004], lr: 0.100000, loss: 4.8537, tea_CELoss: 1.9607, stu_CELoss: 2.4654, DMLLoss: 0.4276, 
2022-07-31 00:30:26 - train: epoch 0006, iter [04600, 05004], lr: 0.100000, loss: 4.3900, tea_CELoss: 1.8180, stu_CELoss: 2.1753, DMLLoss: 0.3967, 
2022-07-31 00:31:23 - train: epoch 0006, iter [04700, 05004], lr: 0.100000, loss: 4.7234, tea_CELoss: 1.9745, stu_CELoss: 2.2759, DMLLoss: 0.4730, 
2022-07-31 00:32:21 - train: epoch 0006, iter [04800, 05004], lr: 0.100000, loss: 4.6251, tea_CELoss: 1.9279, stu_CELoss: 2.2537, DMLLoss: 0.4435, 
2022-07-31 00:33:18 - train: epoch 0006, iter [04900, 05004], lr: 0.100000, loss: 4.7119, tea_CELoss: 1.9738, stu_CELoss: 2.3404, DMLLoss: 0.3977, 
2022-07-31 00:34:16 - train: epoch 0006, iter [05000, 05004], lr: 0.100000, loss: 4.5157, tea_CELoss: 1.8137, stu_CELoss: 2.2254, DMLLoss: 0.4766, 
2022-07-31 00:34:19 - train: epoch 006, train_loss: 4.7062
2022-07-31 00:36:49 - eval: epoch: 006, tea_acc1: 58.198%, tea_acc5: 82.386%, tea_test_loss: 1.7597, stu_acc1: 48.482%, stu_acc5: 73.184%, stu_test_loss: 2.6753
2022-07-31 00:36:50 - until epoch: 006, tea_best_acc1: 58.198%, stu_best_acc1: 50.508%
2022-07-31 00:36:50 - epoch 007 lr: 0.100000
2022-07-31 00:37:54 - train: epoch 0007, iter [00100, 05004], lr: 0.100000, loss: 4.2652, tea_CELoss: 1.7177, stu_CELoss: 2.1084, DMLLoss: 0.4391, 
2022-07-31 00:38:52 - train: epoch 0007, iter [00200, 05004], lr: 0.100000, loss: 4.5274, tea_CELoss: 1.8798, stu_CELoss: 2.1883, DMLLoss: 0.4592, 
2022-07-31 00:39:49 - train: epoch 0007, iter [00300, 05004], lr: 0.100000, loss: 5.0183, tea_CELoss: 2.0247, stu_CELoss: 2.5021, DMLLoss: 0.4914, 
2022-07-31 00:40:47 - train: epoch 0007, iter [00400, 05004], lr: 0.100000, loss: 4.6959, tea_CELoss: 1.9253, stu_CELoss: 2.3205, DMLLoss: 0.4501, 
2022-07-31 00:41:44 - train: epoch 0007, iter [00500, 05004], lr: 0.100000, loss: 4.0427, tea_CELoss: 1.6547, stu_CELoss: 2.0107, DMLLoss: 0.3773, 
2022-07-31 00:42:41 - train: epoch 0007, iter [00600, 05004], lr: 0.100000, loss: 5.1033, tea_CELoss: 2.1010, stu_CELoss: 2.4832, DMLLoss: 0.5191, 
2022-07-31 00:43:39 - train: epoch 0007, iter [00700, 05004], lr: 0.100000, loss: 4.5243, tea_CELoss: 1.8653, stu_CELoss: 2.2441, DMLLoss: 0.4149, 
2022-07-31 00:44:36 - train: epoch 0007, iter [00800, 05004], lr: 0.100000, loss: 4.6932, tea_CELoss: 1.9144, stu_CELoss: 2.2996, DMLLoss: 0.4791, 
2022-07-31 00:45:34 - train: epoch 0007, iter [00900, 05004], lr: 0.100000, loss: 4.5790, tea_CELoss: 1.8414, stu_CELoss: 2.2570, DMLLoss: 0.4806, 
2022-07-31 00:46:31 - train: epoch 0007, iter [01000, 05004], lr: 0.100000, loss: 4.3859, tea_CELoss: 1.7557, stu_CELoss: 2.1795, DMLLoss: 0.4506, 
2022-07-31 00:47:29 - train: epoch 0007, iter [01100, 05004], lr: 0.100000, loss: 4.7157, tea_CELoss: 1.9224, stu_CELoss: 2.3261, DMLLoss: 0.4672, 
2022-07-31 00:48:26 - train: epoch 0007, iter [01200, 05004], lr: 0.100000, loss: 4.4864, tea_CELoss: 1.8356, stu_CELoss: 2.2183, DMLLoss: 0.4325, 
2022-07-31 00:49:24 - train: epoch 0007, iter [01300, 05004], lr: 0.100000, loss: 4.0083, tea_CELoss: 1.6699, stu_CELoss: 1.9194, DMLLoss: 0.4190, 
2022-07-31 00:50:21 - train: epoch 0007, iter [01400, 05004], lr: 0.100000, loss: 4.7582, tea_CELoss: 1.9426, stu_CELoss: 2.3521, DMLLoss: 0.4635, 
2022-07-31 00:51:19 - train: epoch 0007, iter [01500, 05004], lr: 0.100000, loss: 4.8342, tea_CELoss: 1.9918, stu_CELoss: 2.3726, DMLLoss: 0.4698, 
2022-07-31 00:52:16 - train: epoch 0007, iter [01600, 05004], lr: 0.100000, loss: 4.5517, tea_CELoss: 1.8215, stu_CELoss: 2.2770, DMLLoss: 0.4532, 
2022-07-31 00:53:14 - train: epoch 0007, iter [01700, 05004], lr: 0.100000, loss: 4.3696, tea_CELoss: 1.7218, stu_CELoss: 2.1445, DMLLoss: 0.5033, 
2022-07-31 00:54:11 - train: epoch 0007, iter [01800, 05004], lr: 0.100000, loss: 4.8870, tea_CELoss: 2.0142, stu_CELoss: 2.4106, DMLLoss: 0.4622, 
2022-07-31 00:55:09 - train: epoch 0007, iter [01900, 05004], lr: 0.100000, loss: 4.3306, tea_CELoss: 1.7936, stu_CELoss: 2.1166, DMLLoss: 0.4204, 
2022-07-31 00:56:06 - train: epoch 0007, iter [02000, 05004], lr: 0.100000, loss: 4.0313, tea_CELoss: 1.6275, stu_CELoss: 1.9382, DMLLoss: 0.4656, 
2022-07-31 00:57:04 - train: epoch 0007, iter [02100, 05004], lr: 0.100000, loss: 4.8529, tea_CELoss: 1.9639, stu_CELoss: 2.4124, DMLLoss: 0.4766, 
2022-07-31 00:58:01 - train: epoch 0007, iter [02200, 05004], lr: 0.100000, loss: 4.3063, tea_CELoss: 1.7772, stu_CELoss: 2.1010, DMLLoss: 0.4281, 
2022-07-31 00:58:59 - train: epoch 0007, iter [02300, 05004], lr: 0.100000, loss: 4.7690, tea_CELoss: 1.9707, stu_CELoss: 2.3204, DMLLoss: 0.4779, 
2022-07-31 00:59:56 - train: epoch 0007, iter [02400, 05004], lr: 0.100000, loss: 4.8766, tea_CELoss: 2.0153, stu_CELoss: 2.4303, DMLLoss: 0.4310, 
2022-07-31 01:00:54 - train: epoch 0007, iter [02500, 05004], lr: 0.100000, loss: 4.6656, tea_CELoss: 1.8896, stu_CELoss: 2.2974, DMLLoss: 0.4786, 
2022-07-31 01:01:51 - train: epoch 0007, iter [02600, 05004], lr: 0.100000, loss: 4.4373, tea_CELoss: 1.7686, stu_CELoss: 2.2446, DMLLoss: 0.4241, 
2022-07-31 01:02:48 - train: epoch 0007, iter [02700, 05004], lr: 0.100000, loss: 4.3688, tea_CELoss: 1.7879, stu_CELoss: 2.1614, DMLLoss: 0.4195, 
2022-07-31 01:03:46 - train: epoch 0007, iter [02800, 05004], lr: 0.100000, loss: 4.4386, tea_CELoss: 1.8175, stu_CELoss: 2.2006, DMLLoss: 0.4205, 
2022-07-31 01:04:44 - train: epoch 0007, iter [02900, 05004], lr: 0.100000, loss: 4.3417, tea_CELoss: 1.8019, stu_CELoss: 2.1027, DMLLoss: 0.4371, 
2022-07-31 01:05:41 - train: epoch 0007, iter [03000, 05004], lr: 0.100000, loss: 4.8998, tea_CELoss: 2.0712, stu_CELoss: 2.4081, DMLLoss: 0.4204, 
2022-07-31 01:06:39 - train: epoch 0007, iter [03100, 05004], lr: 0.100000, loss: 4.2323, tea_CELoss: 1.7718, stu_CELoss: 2.0530, DMLLoss: 0.4075, 
2022-07-31 01:07:36 - train: epoch 0007, iter [03200, 05004], lr: 0.100000, loss: 4.1139, tea_CELoss: 1.6438, stu_CELoss: 2.0115, DMLLoss: 0.4586, 
2022-07-31 01:08:34 - train: epoch 0007, iter [03300, 05004], lr: 0.100000, loss: 4.8416, tea_CELoss: 1.9840, stu_CELoss: 2.3897, DMLLoss: 0.4679, 
2022-07-31 01:09:31 - train: epoch 0007, iter [03400, 05004], lr: 0.100000, loss: 4.8480, tea_CELoss: 1.9936, stu_CELoss: 2.3845, DMLLoss: 0.4699, 
2022-07-31 01:10:28 - train: epoch 0007, iter [03500, 05004], lr: 0.100000, loss: 4.8257, tea_CELoss: 2.0355, stu_CELoss: 2.3561, DMLLoss: 0.4342, 
2022-07-31 01:11:25 - train: epoch 0007, iter [03600, 05004], lr: 0.100000, loss: 4.5197, tea_CELoss: 1.8446, stu_CELoss: 2.2064, DMLLoss: 0.4687, 
2022-07-31 01:12:23 - train: epoch 0007, iter [03700, 05004], lr: 0.100000, loss: 4.3119, tea_CELoss: 1.7412, stu_CELoss: 2.1347, DMLLoss: 0.4359, 
2022-07-31 01:13:20 - train: epoch 0007, iter [03800, 05004], lr: 0.100000, loss: 5.0672, tea_CELoss: 2.0776, stu_CELoss: 2.5201, DMLLoss: 0.4695, 
2022-07-31 01:14:17 - train: epoch 0007, iter [03900, 05004], lr: 0.100000, loss: 4.7089, tea_CELoss: 1.9453, stu_CELoss: 2.2920, DMLLoss: 0.4716, 
2022-07-31 01:15:14 - train: epoch 0007, iter [04000, 05004], lr: 0.100000, loss: 4.7895, tea_CELoss: 1.9923, stu_CELoss: 2.3390, DMLLoss: 0.4582, 
2022-07-31 01:16:11 - train: epoch 0007, iter [04100, 05004], lr: 0.100000, loss: 4.3926, tea_CELoss: 1.8116, stu_CELoss: 2.1482, DMLLoss: 0.4328, 
2022-07-31 01:17:08 - train: epoch 0007, iter [04200, 05004], lr: 0.100000, loss: 4.2237, tea_CELoss: 1.7430, stu_CELoss: 2.0707, DMLLoss: 0.4100, 
2022-07-31 01:18:05 - train: epoch 0007, iter [04300, 05004], lr: 0.100000, loss: 4.7343, tea_CELoss: 1.9757, stu_CELoss: 2.3085, DMLLoss: 0.4500, 
2022-07-31 01:19:02 - train: epoch 0007, iter [04400, 05004], lr: 0.100000, loss: 4.3021, tea_CELoss: 1.7349, stu_CELoss: 2.1216, DMLLoss: 0.4456, 
2022-07-31 01:20:00 - train: epoch 0007, iter [04500, 05004], lr: 0.100000, loss: 4.7453, tea_CELoss: 2.0142, stu_CELoss: 2.2981, DMLLoss: 0.4331, 
2022-07-31 01:20:56 - train: epoch 0007, iter [04600, 05004], lr: 0.100000, loss: 4.5487, tea_CELoss: 1.8765, stu_CELoss: 2.2275, DMLLoss: 0.4446, 
2022-07-31 01:21:53 - train: epoch 0007, iter [04700, 05004], lr: 0.100000, loss: 4.2210, tea_CELoss: 1.6937, stu_CELoss: 2.0747, DMLLoss: 0.4525, 
2022-07-31 01:22:51 - train: epoch 0007, iter [04800, 05004], lr: 0.100000, loss: 4.8653, tea_CELoss: 2.0444, stu_CELoss: 2.3816, DMLLoss: 0.4392, 
2022-07-31 01:23:48 - train: epoch 0007, iter [04900, 05004], lr: 0.100000, loss: 4.4984, tea_CELoss: 1.8849, stu_CELoss: 2.1843, DMLLoss: 0.4293, 
2022-07-31 01:24:45 - train: epoch 0007, iter [05000, 05004], lr: 0.100000, loss: 4.4399, tea_CELoss: 1.8663, stu_CELoss: 2.1634, DMLLoss: 0.4102, 
2022-07-31 01:24:47 - train: epoch 007, train_loss: 4.5715
2022-07-31 01:27:20 - eval: epoch: 007, tea_acc1: 60.702%, tea_acc5: 84.210%, tea_test_loss: 1.6344, stu_acc1: 53.992%, stu_acc5: 78.752%, stu_test_loss: 1.9695
2022-07-31 01:27:21 - until epoch: 007, tea_best_acc1: 60.702%, stu_best_acc1: 53.992%
2022-07-31 01:27:21 - epoch 008 lr: 0.100000
2022-07-31 01:28:25 - train: epoch 0008, iter [00100, 05004], lr: 0.100000, loss: 4.4127, tea_CELoss: 1.7536, stu_CELoss: 2.2325, DMLLoss: 0.4267, 
2022-07-31 01:29:22 - train: epoch 0008, iter [00200, 05004], lr: 0.100000, loss: 4.6732, tea_CELoss: 1.9246, stu_CELoss: 2.3002, DMLLoss: 0.4484, 
2022-07-31 01:30:19 - train: epoch 0008, iter [00300, 05004], lr: 0.100000, loss: 4.5390, tea_CELoss: 1.8404, stu_CELoss: 2.2382, DMLLoss: 0.4604, 
2022-07-31 01:31:16 - train: epoch 0008, iter [00400, 05004], lr: 0.100000, loss: 4.2268, tea_CELoss: 1.6857, stu_CELoss: 2.1135, DMLLoss: 0.4276, 
2022-07-31 01:32:14 - train: epoch 0008, iter [00500, 05004], lr: 0.100000, loss: 4.1763, tea_CELoss: 1.6994, stu_CELoss: 2.0473, DMLLoss: 0.4297, 
2022-07-31 01:33:11 - train: epoch 0008, iter [00600, 05004], lr: 0.100000, loss: 4.1915, tea_CELoss: 1.7303, stu_CELoss: 2.0544, DMLLoss: 0.4068, 
2022-07-31 01:34:08 - train: epoch 0008, iter [00700, 05004], lr: 0.100000, loss: 4.5527, tea_CELoss: 1.8197, stu_CELoss: 2.2450, DMLLoss: 0.4881, 
2022-07-31 01:35:05 - train: epoch 0008, iter [00800, 05004], lr: 0.100000, loss: 3.9826, tea_CELoss: 1.6478, stu_CELoss: 1.9209, DMLLoss: 0.4139, 
2022-07-31 01:36:02 - train: epoch 0008, iter [00900, 05004], lr: 0.100000, loss: 4.3824, tea_CELoss: 1.7896, stu_CELoss: 2.1934, DMLLoss: 0.3995, 
2022-07-31 01:36:59 - train: epoch 0008, iter [01000, 05004], lr: 0.100000, loss: 4.6421, tea_CELoss: 1.9367, stu_CELoss: 2.2537, DMLLoss: 0.4517, 
2022-07-31 01:37:56 - train: epoch 0008, iter [01100, 05004], lr: 0.100000, loss: 4.3230, tea_CELoss: 1.8050, stu_CELoss: 2.0614, DMLLoss: 0.4567, 
2022-07-31 01:38:53 - train: epoch 0008, iter [01200, 05004], lr: 0.100000, loss: 3.8047, tea_CELoss: 1.5333, stu_CELoss: 1.8540, DMLLoss: 0.4173, 
2022-07-31 01:39:50 - train: epoch 0008, iter [01300, 05004], lr: 0.100000, loss: 4.4128, tea_CELoss: 1.7609, stu_CELoss: 2.2024, DMLLoss: 0.4496, 
2022-07-31 01:40:47 - train: epoch 0008, iter [01400, 05004], lr: 0.100000, loss: 4.4004, tea_CELoss: 1.7813, stu_CELoss: 2.1953, DMLLoss: 0.4239, 
2022-07-31 01:41:44 - train: epoch 0008, iter [01500, 05004], lr: 0.100000, loss: 4.5727, tea_CELoss: 1.9287, stu_CELoss: 2.1976, DMLLoss: 0.4464, 
2022-07-31 01:42:42 - train: epoch 0008, iter [01600, 05004], lr: 0.100000, loss: 4.4507, tea_CELoss: 1.8301, stu_CELoss: 2.1937, DMLLoss: 0.4268, 
2022-07-31 01:43:39 - train: epoch 0008, iter [01700, 05004], lr: 0.100000, loss: 4.5338, tea_CELoss: 1.8518, stu_CELoss: 2.2454, DMLLoss: 0.4366, 
2022-07-31 01:44:36 - train: epoch 0008, iter [01800, 05004], lr: 0.100000, loss: 4.6874, tea_CELoss: 1.8888, stu_CELoss: 2.2997, DMLLoss: 0.4990, 
2022-07-31 01:45:33 - train: epoch 0008, iter [01900, 05004], lr: 0.100000, loss: 4.1119, tea_CELoss: 1.6816, stu_CELoss: 2.0327, DMLLoss: 0.3976, 
2022-07-31 01:46:30 - train: epoch 0008, iter [02000, 05004], lr: 0.100000, loss: 5.1341, tea_CELoss: 2.1707, stu_CELoss: 2.4931, DMLLoss: 0.4704, 
2022-07-31 01:47:27 - train: epoch 0008, iter [02100, 05004], lr: 0.100000, loss: 4.5168, tea_CELoss: 1.8267, stu_CELoss: 2.2361, DMLLoss: 0.4540, 
2022-07-31 01:48:24 - train: epoch 0008, iter [02200, 05004], lr: 0.100000, loss: 4.8164, tea_CELoss: 2.0411, stu_CELoss: 2.3058, DMLLoss: 0.4696, 
2022-07-31 01:49:21 - train: epoch 0008, iter [02300, 05004], lr: 0.100000, loss: 4.2793, tea_CELoss: 1.7800, stu_CELoss: 2.0895, DMLLoss: 0.4098, 
2022-07-31 01:50:18 - train: epoch 0008, iter [02400, 05004], lr: 0.100000, loss: 4.1149, tea_CELoss: 1.7375, stu_CELoss: 1.9715, DMLLoss: 0.4060, 
2022-07-31 01:51:16 - train: epoch 0008, iter [02500, 05004], lr: 0.100000, loss: 4.4486, tea_CELoss: 1.8293, stu_CELoss: 2.2302, DMLLoss: 0.3891, 
2022-07-31 01:52:13 - train: epoch 0008, iter [02600, 05004], lr: 0.100000, loss: 4.3375, tea_CELoss: 1.7769, stu_CELoss: 2.1076, DMLLoss: 0.4530, 
2022-07-31 01:53:10 - train: epoch 0008, iter [02700, 05004], lr: 0.100000, loss: 4.7266, tea_CELoss: 1.9349, stu_CELoss: 2.3480, DMLLoss: 0.4436, 
2022-07-31 01:54:07 - train: epoch 0008, iter [02800, 05004], lr: 0.100000, loss: 4.5976, tea_CELoss: 1.9222, stu_CELoss: 2.2332, DMLLoss: 0.4423, 
2022-07-31 01:55:04 - train: epoch 0008, iter [02900, 05004], lr: 0.100000, loss: 4.6967, tea_CELoss: 1.9637, stu_CELoss: 2.3080, DMLLoss: 0.4250, 
2022-07-31 01:56:01 - train: epoch 0008, iter [03000, 05004], lr: 0.100000, loss: 4.9093, tea_CELoss: 2.0630, stu_CELoss: 2.3832, DMLLoss: 0.4632, 
2022-07-31 01:56:58 - train: epoch 0008, iter [03100, 05004], lr: 0.100000, loss: 4.4415, tea_CELoss: 1.8559, stu_CELoss: 2.1888, DMLLoss: 0.3968, 
2022-07-31 01:57:55 - train: epoch 0008, iter [03200, 05004], lr: 0.100000, loss: 4.7024, tea_CELoss: 1.9825, stu_CELoss: 2.2832, DMLLoss: 0.4367, 
2022-07-31 01:58:52 - train: epoch 0008, iter [03300, 05004], lr: 0.100000, loss: 4.5287, tea_CELoss: 1.8702, stu_CELoss: 2.2473, DMLLoss: 0.4112, 
2022-07-31 01:59:49 - train: epoch 0008, iter [03400, 05004], lr: 0.100000, loss: 4.7737, tea_CELoss: 1.9742, stu_CELoss: 2.3521, DMLLoss: 0.4474, 
2022-07-31 02:00:46 - train: epoch 0008, iter [03500, 05004], lr: 0.100000, loss: 4.4072, tea_CELoss: 1.8173, stu_CELoss: 2.1212, DMLLoss: 0.4687, 
2022-07-31 02:01:43 - train: epoch 0008, iter [03600, 05004], lr: 0.100000, loss: 4.5895, tea_CELoss: 1.9121, stu_CELoss: 2.2469, DMLLoss: 0.4305, 
2022-07-31 02:02:40 - train: epoch 0008, iter [03700, 05004], lr: 0.100000, loss: 4.2404, tea_CELoss: 1.7650, stu_CELoss: 2.0738, DMLLoss: 0.4016, 
2022-07-31 02:03:37 - train: epoch 0008, iter [03800, 05004], lr: 0.100000, loss: 4.3549, tea_CELoss: 1.7432, stu_CELoss: 2.1638, DMLLoss: 0.4478, 
2022-07-31 02:04:34 - train: epoch 0008, iter [03900, 05004], lr: 0.100000, loss: 4.6280, tea_CELoss: 1.9549, stu_CELoss: 2.2350, DMLLoss: 0.4381, 
2022-07-31 02:05:31 - train: epoch 0008, iter [04000, 05004], lr: 0.100000, loss: 4.8969, tea_CELoss: 2.0296, stu_CELoss: 2.4136, DMLLoss: 0.4537, 
2022-07-31 02:06:28 - train: epoch 0008, iter [04100, 05004], lr: 0.100000, loss: 4.2458, tea_CELoss: 1.7657, stu_CELoss: 2.0700, DMLLoss: 0.4100, 
2022-07-31 02:07:25 - train: epoch 0008, iter [04200, 05004], lr: 0.100000, loss: 4.3709, tea_CELoss: 1.8555, stu_CELoss: 2.0988, DMLLoss: 0.4166, 
2022-07-31 02:08:21 - train: epoch 0008, iter [04300, 05004], lr: 0.100000, loss: 3.9757, tea_CELoss: 1.6368, stu_CELoss: 1.9448, DMLLoss: 0.3940, 
2022-07-31 02:09:18 - train: epoch 0008, iter [04400, 05004], lr: 0.100000, loss: 4.5042, tea_CELoss: 1.8652, stu_CELoss: 2.2065, DMLLoss: 0.4325, 
2022-07-31 02:10:15 - train: epoch 0008, iter [04500, 05004], lr: 0.100000, loss: 4.4038, tea_CELoss: 1.8346, stu_CELoss: 2.1763, DMLLoss: 0.3929, 
2022-07-31 02:11:12 - train: epoch 0008, iter [04600, 05004], lr: 0.100000, loss: 4.4315, tea_CELoss: 1.8051, stu_CELoss: 2.1415, DMLLoss: 0.4850, 
2022-07-31 02:12:09 - train: epoch 0008, iter [04700, 05004], lr: 0.100000, loss: 4.4471, tea_CELoss: 1.8442, stu_CELoss: 2.1541, DMLLoss: 0.4488, 
2022-07-31 02:13:06 - train: epoch 0008, iter [04800, 05004], lr: 0.100000, loss: 4.5083, tea_CELoss: 1.8532, stu_CELoss: 2.2302, DMLLoss: 0.4248, 
2022-07-31 02:14:03 - train: epoch 0008, iter [04900, 05004], lr: 0.100000, loss: 4.3385, tea_CELoss: 1.8264, stu_CELoss: 2.0934, DMLLoss: 0.4187, 
2022-07-31 02:15:00 - train: epoch 0008, iter [05000, 05004], lr: 0.100000, loss: 4.5496, tea_CELoss: 1.9333, stu_CELoss: 2.2164, DMLLoss: 0.3999, 
2022-07-31 02:15:03 - train: epoch 008, train_loss: 4.4721
2022-07-31 02:17:35 - eval: epoch: 008, tea_acc1: 60.890%, tea_acc5: 84.436%, tea_test_loss: 1.6185, stu_acc1: 54.064%, stu_acc5: 79.166%, stu_test_loss: 1.9508
2022-07-31 02:17:36 - until epoch: 008, tea_best_acc1: 60.890%, stu_best_acc1: 54.064%
2022-07-31 02:17:36 - epoch 009 lr: 0.100000
2022-07-31 02:18:39 - train: epoch 0009, iter [00100, 05004], lr: 0.100000, loss: 3.7848, tea_CELoss: 1.5351, stu_CELoss: 1.8465, DMLLoss: 0.4032, 
2022-07-31 02:19:36 - train: epoch 0009, iter [00200, 05004], lr: 0.100000, loss: 4.4151, tea_CELoss: 1.8695, stu_CELoss: 2.1302, DMLLoss: 0.4154, 
2022-07-31 02:20:34 - train: epoch 0009, iter [00300, 05004], lr: 0.100000, loss: 4.2929, tea_CELoss: 1.7585, stu_CELoss: 2.0897, DMLLoss: 0.4448, 
2022-07-31 02:21:31 - train: epoch 0009, iter [00400, 05004], lr: 0.100000, loss: 4.7322, tea_CELoss: 2.0017, stu_CELoss: 2.2790, DMLLoss: 0.4515, 
2022-07-31 02:22:28 - train: epoch 0009, iter [00500, 05004], lr: 0.100000, loss: 3.9258, tea_CELoss: 1.6005, stu_CELoss: 1.9027, DMLLoss: 0.4225, 
2022-07-31 02:23:25 - train: epoch 0009, iter [00600, 05004], lr: 0.100000, loss: 4.1710, tea_CELoss: 1.6975, stu_CELoss: 2.0691, DMLLoss: 0.4044, 
2022-07-31 02:24:22 - train: epoch 0009, iter [00700, 05004], lr: 0.100000, loss: 3.9579, tea_CELoss: 1.6402, stu_CELoss: 1.8870, DMLLoss: 0.4308, 
2022-07-31 02:25:19 - train: epoch 0009, iter [00800, 05004], lr: 0.100000, loss: 4.1331, tea_CELoss: 1.7141, stu_CELoss: 2.0115, DMLLoss: 0.4075, 
2022-07-31 02:26:16 - train: epoch 0009, iter [00900, 05004], lr: 0.100000, loss: 4.0404, tea_CELoss: 1.6652, stu_CELoss: 1.9788, DMLLoss: 0.3964, 
2022-07-31 02:27:13 - train: epoch 0009, iter [01000, 05004], lr: 0.100000, loss: 4.2906, tea_CELoss: 1.8153, stu_CELoss: 2.0692, DMLLoss: 0.4061, 
2022-07-31 02:28:10 - train: epoch 0009, iter [01100, 05004], lr: 0.100000, loss: 4.6500, tea_CELoss: 1.9451, stu_CELoss: 2.2764, DMLLoss: 0.4285, 
2022-07-31 02:29:08 - train: epoch 0009, iter [01200, 05004], lr: 0.100000, loss: 4.3662, tea_CELoss: 1.7966, stu_CELoss: 2.1210, DMLLoss: 0.4487, 
2022-07-31 02:30:05 - train: epoch 0009, iter [01300, 05004], lr: 0.100000, loss: 4.8248, tea_CELoss: 2.0028, stu_CELoss: 2.3304, DMLLoss: 0.4917, 
2022-07-31 02:31:02 - train: epoch 0009, iter [01400, 05004], lr: 0.100000, loss: 3.7934, tea_CELoss: 1.6072, stu_CELoss: 1.8113, DMLLoss: 0.3750, 
2022-07-31 02:31:59 - train: epoch 0009, iter [01500, 05004], lr: 0.100000, loss: 4.1194, tea_CELoss: 1.7031, stu_CELoss: 1.9984, DMLLoss: 0.4178, 
2022-07-31 02:32:56 - train: epoch 0009, iter [01600, 05004], lr: 0.100000, loss: 4.2777, tea_CELoss: 1.7673, stu_CELoss: 2.0548, DMLLoss: 0.4557, 
2022-07-31 02:33:53 - train: epoch 0009, iter [01700, 05004], lr: 0.100000, loss: 4.6005, tea_CELoss: 1.9180, stu_CELoss: 2.2618, DMLLoss: 0.4208, 
2022-07-31 02:34:51 - train: epoch 0009, iter [01800, 05004], lr: 0.100000, loss: 4.3097, tea_CELoss: 1.8204, stu_CELoss: 2.1187, DMLLoss: 0.3707, 
2022-07-31 02:35:48 - train: epoch 0009, iter [01900, 05004], lr: 0.100000, loss: 3.9447, tea_CELoss: 1.5941, stu_CELoss: 1.9143, DMLLoss: 0.4364, 
2022-07-31 02:36:45 - train: epoch 0009, iter [02000, 05004], lr: 0.100000, loss: 4.1209, tea_CELoss: 1.6752, stu_CELoss: 2.0159, DMLLoss: 0.4298, 
2022-07-31 02:37:42 - train: epoch 0009, iter [02100, 05004], lr: 0.100000, loss: 4.5979, tea_CELoss: 1.9461, stu_CELoss: 2.2329, DMLLoss: 0.4189, 
2022-07-31 02:38:39 - train: epoch 0009, iter [02200, 05004], lr: 0.100000, loss: 4.6098, tea_CELoss: 1.9005, stu_CELoss: 2.2576, DMLLoss: 0.4516, 
2022-07-31 02:39:36 - train: epoch 0009, iter [02300, 05004], lr: 0.100000, loss: 3.8155, tea_CELoss: 1.5914, stu_CELoss: 1.8321, DMLLoss: 0.3920, 
2022-07-31 02:40:33 - train: epoch 0009, iter [02400, 05004], lr: 0.100000, loss: 4.3098, tea_CELoss: 1.8567, stu_CELoss: 2.0389, DMLLoss: 0.4142, 
2022-07-31 02:41:30 - train: epoch 0009, iter [02500, 05004], lr: 0.100000, loss: 4.1128, tea_CELoss: 1.7276, stu_CELoss: 2.0032, DMLLoss: 0.3820, 
2022-07-31 02:42:27 - train: epoch 0009, iter [02600, 05004], lr: 0.100000, loss: 4.3275, tea_CELoss: 1.7803, stu_CELoss: 2.0830, DMLLoss: 0.4642, 
2022-07-31 02:43:24 - train: epoch 0009, iter [02700, 05004], lr: 0.100000, loss: 4.5493, tea_CELoss: 1.9262, stu_CELoss: 2.2247, DMLLoss: 0.3984, 
2022-07-31 02:44:21 - train: epoch 0009, iter [02800, 05004], lr: 0.100000, loss: 4.5825, tea_CELoss: 1.9341, stu_CELoss: 2.2290, DMLLoss: 0.4193, 
2022-07-31 02:45:18 - train: epoch 0009, iter [02900, 05004], lr: 0.100000, loss: 3.8498, tea_CELoss: 1.5683, stu_CELoss: 1.8660, DMLLoss: 0.4155, 
2022-07-31 02:46:15 - train: epoch 0009, iter [03000, 05004], lr: 0.100000, loss: 3.8648, tea_CELoss: 1.5985, stu_CELoss: 1.8594, DMLLoss: 0.4069, 
2022-07-31 02:47:12 - train: epoch 0009, iter [03100, 05004], lr: 0.100000, loss: 4.2538, tea_CELoss: 1.7891, stu_CELoss: 2.0596, DMLLoss: 0.4051, 
2022-07-31 02:48:09 - train: epoch 0009, iter [03200, 05004], lr: 0.100000, loss: 4.5190, tea_CELoss: 1.8858, stu_CELoss: 2.1607, DMLLoss: 0.4725, 
2022-07-31 02:49:06 - train: epoch 0009, iter [03300, 05004], lr: 0.100000, loss: 4.7713, tea_CELoss: 2.0220, stu_CELoss: 2.3080, DMLLoss: 0.4414, 
2022-07-31 02:50:03 - train: epoch 0009, iter [03400, 05004], lr: 0.100000, loss: 4.1955, tea_CELoss: 1.7355, stu_CELoss: 2.0491, DMLLoss: 0.4109, 
2022-07-31 02:51:00 - train: epoch 0009, iter [03500, 05004], lr: 0.100000, loss: 4.6331, tea_CELoss: 1.9592, stu_CELoss: 2.2499, DMLLoss: 0.4240, 
2022-07-31 02:51:57 - train: epoch 0009, iter [03600, 05004], lr: 0.100000, loss: 4.0311, tea_CELoss: 1.6727, stu_CELoss: 1.9533, DMLLoss: 0.4051, 
2022-07-31 02:52:54 - train: epoch 0009, iter [03700, 05004], lr: 0.100000, loss: 4.4229, tea_CELoss: 1.7945, stu_CELoss: 2.2017, DMLLoss: 0.4267, 
2022-07-31 02:53:51 - train: epoch 0009, iter [03800, 05004], lr: 0.100000, loss: 4.3964, tea_CELoss: 1.9258, stu_CELoss: 2.0958, DMLLoss: 0.3748, 
2022-07-31 02:54:48 - train: epoch 0009, iter [03900, 05004], lr: 0.100000, loss: 4.1450, tea_CELoss: 1.7101, stu_CELoss: 2.0338, DMLLoss: 0.4011, 
2022-07-31 02:55:44 - train: epoch 0009, iter [04000, 05004], lr: 0.100000, loss: 4.8274, tea_CELoss: 2.0918, stu_CELoss: 2.3242, DMLLoss: 0.4114, 
2022-07-31 02:56:42 - train: epoch 0009, iter [04100, 05004], lr: 0.100000, loss: 4.5867, tea_CELoss: 1.9102, stu_CELoss: 2.2742, DMLLoss: 0.4023, 
2022-07-31 02:57:39 - train: epoch 0009, iter [04200, 05004], lr: 0.100000, loss: 4.3057, tea_CELoss: 1.8364, stu_CELoss: 2.0487, DMLLoss: 0.4206, 
2022-07-31 02:58:36 - train: epoch 0009, iter [04300, 05004], lr: 0.100000, loss: 3.8385, tea_CELoss: 1.6028, stu_CELoss: 1.8550, DMLLoss: 0.3808, 
2022-07-31 02:59:33 - train: epoch 0009, iter [04400, 05004], lr: 0.100000, loss: 4.5837, tea_CELoss: 1.9564, stu_CELoss: 2.1891, DMLLoss: 0.4382, 
2022-07-31 03:00:29 - train: epoch 0009, iter [04500, 05004], lr: 0.100000, loss: 4.5885, tea_CELoss: 1.9434, stu_CELoss: 2.2147, DMLLoss: 0.4304, 
2022-07-31 03:01:26 - train: epoch 0009, iter [04600, 05004], lr: 0.100000, loss: 4.8165, tea_CELoss: 2.0618, stu_CELoss: 2.3128, DMLLoss: 0.4419, 
2022-07-31 03:02:23 - train: epoch 0009, iter [04700, 05004], lr: 0.100000, loss: 4.9347, tea_CELoss: 2.0661, stu_CELoss: 2.4240, DMLLoss: 0.4445, 
2022-07-31 03:03:20 - train: epoch 0009, iter [04800, 05004], lr: 0.100000, loss: 4.5130, tea_CELoss: 1.9026, stu_CELoss: 2.1866, DMLLoss: 0.4238, 
2022-07-31 03:04:17 - train: epoch 0009, iter [04900, 05004], lr: 0.100000, loss: 4.4762, tea_CELoss: 1.9132, stu_CELoss: 2.1543, DMLLoss: 0.4086, 
2022-07-31 03:05:14 - train: epoch 0009, iter [05000, 05004], lr: 0.100000, loss: 4.0564, tea_CELoss: 1.7098, stu_CELoss: 1.9369, DMLLoss: 0.4096, 
2022-07-31 03:05:17 - train: epoch 009, train_loss: 4.3929
2022-07-31 03:07:49 - eval: epoch: 009, tea_acc1: 59.166%, tea_acc5: 83.016%, tea_test_loss: 1.7180, stu_acc1: 54.828%, stu_acc5: 79.338%, stu_test_loss: 1.9541
2022-07-31 03:07:50 - until epoch: 009, tea_best_acc1: 60.890%, stu_best_acc1: 54.828%
2022-07-31 03:07:50 - epoch 010 lr: 0.100000
2022-07-31 03:08:54 - train: epoch 0010, iter [00100, 05004], lr: 0.100000, loss: 3.9036, tea_CELoss: 1.6349, stu_CELoss: 1.8515, DMLLoss: 0.4171, 
2022-07-31 03:09:51 - train: epoch 0010, iter [00200, 05004], lr: 0.100000, loss: 4.3651, tea_CELoss: 1.8268, stu_CELoss: 2.1288, DMLLoss: 0.4095, 
2022-07-31 03:10:48 - train: epoch 0010, iter [00300, 05004], lr: 0.100000, loss: 4.3394, tea_CELoss: 1.8300, stu_CELoss: 2.1051, DMLLoss: 0.4043, 
2022-07-31 03:11:45 - train: epoch 0010, iter [00400, 05004], lr: 0.100000, loss: 4.6183, tea_CELoss: 1.9671, stu_CELoss: 2.2251, DMLLoss: 0.4260, 
2022-07-31 03:12:42 - train: epoch 0010, iter [00500, 05004], lr: 0.100000, loss: 4.3133, tea_CELoss: 1.8149, stu_CELoss: 2.0937, DMLLoss: 0.4047, 
2022-07-31 03:13:39 - train: epoch 0010, iter [00600, 05004], lr: 0.100000, loss: 4.7447, tea_CELoss: 2.0143, stu_CELoss: 2.3225, DMLLoss: 0.4079, 
2022-07-31 03:14:36 - train: epoch 0010, iter [00700, 05004], lr: 0.100000, loss: 4.6622, tea_CELoss: 1.9680, stu_CELoss: 2.2304, DMLLoss: 0.4639, 
2022-07-31 03:15:33 - train: epoch 0010, iter [00800, 05004], lr: 0.100000, loss: 4.4880, tea_CELoss: 1.9244, stu_CELoss: 2.1230, DMLLoss: 0.4405, 
2022-07-31 03:16:30 - train: epoch 0010, iter [00900, 05004], lr: 0.100000, loss: 3.8569, tea_CELoss: 1.5934, stu_CELoss: 1.8686, DMLLoss: 0.3948, 
2022-07-31 03:17:27 - train: epoch 0010, iter [01000, 05004], lr: 0.100000, loss: 3.9148, tea_CELoss: 1.5312, stu_CELoss: 1.9238, DMLLoss: 0.4598, 
2022-07-31 03:18:24 - train: epoch 0010, iter [01100, 05004], lr: 0.100000, loss: 4.1187, tea_CELoss: 1.6571, stu_CELoss: 2.0083, DMLLoss: 0.4533, 
2022-07-31 03:19:22 - train: epoch 0010, iter [01200, 05004], lr: 0.100000, loss: 4.3528, tea_CELoss: 1.8417, stu_CELoss: 2.1093, DMLLoss: 0.4017, 
2022-07-31 03:20:19 - train: epoch 0010, iter [01300, 05004], lr: 0.100000, loss: 4.1088, tea_CELoss: 1.7635, stu_CELoss: 1.9637, DMLLoss: 0.3816, 
2022-07-31 03:21:16 - train: epoch 0010, iter [01400, 05004], lr: 0.100000, loss: 4.5595, tea_CELoss: 1.9748, stu_CELoss: 2.1733, DMLLoss: 0.4114, 
2022-07-31 03:22:13 - train: epoch 0010, iter [01500, 05004], lr: 0.100000, loss: 3.8525, tea_CELoss: 1.5779, stu_CELoss: 1.8670, DMLLoss: 0.4076, 
2022-07-31 03:23:10 - train: epoch 0010, iter [01600, 05004], lr: 0.100000, loss: 4.4171, tea_CELoss: 1.8365, stu_CELoss: 2.1661, DMLLoss: 0.4146, 
2022-07-31 03:24:07 - train: epoch 0010, iter [01700, 05004], lr: 0.100000, loss: 4.6389, tea_CELoss: 1.9353, stu_CELoss: 2.2909, DMLLoss: 0.4127, 
2022-07-31 03:25:04 - train: epoch 0010, iter [01800, 05004], lr: 0.100000, loss: 4.2226, tea_CELoss: 1.7399, stu_CELoss: 2.0751, DMLLoss: 0.4076, 
2022-07-31 03:26:01 - train: epoch 0010, iter [01900, 05004], lr: 0.100000, loss: 4.1808, tea_CELoss: 1.7692, stu_CELoss: 2.0121, DMLLoss: 0.3994, 
2022-07-31 03:26:58 - train: epoch 0010, iter [02000, 05004], lr: 0.100000, loss: 4.4084, tea_CELoss: 1.8588, stu_CELoss: 2.1176, DMLLoss: 0.4321, 
2022-07-31 03:27:56 - train: epoch 0010, iter [02100, 05004], lr: 0.100000, loss: 4.0183, tea_CELoss: 1.7058, stu_CELoss: 1.9010, DMLLoss: 0.4115, 
2022-07-31 03:28:53 - train: epoch 0010, iter [02200, 05004], lr: 0.100000, loss: 4.3847, tea_CELoss: 1.8670, stu_CELoss: 2.1261, DMLLoss: 0.3917, 
2022-07-31 03:29:50 - train: epoch 0010, iter [02300, 05004], lr: 0.100000, loss: 4.7397, tea_CELoss: 2.0560, stu_CELoss: 2.2558, DMLLoss: 0.4279, 
2022-07-31 03:30:47 - train: epoch 0010, iter [02400, 05004], lr: 0.100000, loss: 4.9339, tea_CELoss: 2.0850, stu_CELoss: 2.4030, DMLLoss: 0.4460, 
2022-07-31 03:31:44 - train: epoch 0010, iter [02500, 05004], lr: 0.100000, loss: 4.3579, tea_CELoss: 1.8596, stu_CELoss: 2.1298, DMLLoss: 0.3685, 
2022-07-31 03:32:41 - train: epoch 0010, iter [02600, 05004], lr: 0.100000, loss: 4.4568, tea_CELoss: 1.8230, stu_CELoss: 2.2200, DMLLoss: 0.4139, 
2022-07-31 03:33:38 - train: epoch 0010, iter [02700, 05004], lr: 0.100000, loss: 4.0833, tea_CELoss: 1.7656, stu_CELoss: 1.9176, DMLLoss: 0.4001, 
2022-07-31 03:34:35 - train: epoch 0010, iter [02800, 05004], lr: 0.100000, loss: 4.3148, tea_CELoss: 1.7847, stu_CELoss: 2.1053, DMLLoss: 0.4247, 
2022-07-31 03:35:32 - train: epoch 0010, iter [02900, 05004], lr: 0.100000, loss: 4.4410, tea_CELoss: 1.8867, stu_CELoss: 2.1330, DMLLoss: 0.4213, 
2022-07-31 03:36:29 - train: epoch 0010, iter [03000, 05004], lr: 0.100000, loss: 4.0479, tea_CELoss: 1.7015, stu_CELoss: 1.9626, DMLLoss: 0.3838, 
2022-07-31 03:37:26 - train: epoch 0010, iter [03100, 05004], lr: 0.100000, loss: 4.7466, tea_CELoss: 2.0645, stu_CELoss: 2.2557, DMLLoss: 0.4264, 
2022-07-31 03:38:24 - train: epoch 0010, iter [03200, 05004], lr: 0.100000, loss: 4.5009, tea_CELoss: 1.8975, stu_CELoss: 2.1642, DMLLoss: 0.4392, 
2022-07-31 03:39:21 - train: epoch 0010, iter [03300, 05004], lr: 0.100000, loss: 4.7040, tea_CELoss: 1.9633, stu_CELoss: 2.3164, DMLLoss: 0.4243, 
2022-07-31 03:40:18 - train: epoch 0010, iter [03400, 05004], lr: 0.100000, loss: 4.6904, tea_CELoss: 1.9911, stu_CELoss: 2.2692, DMLLoss: 0.4300, 
2022-07-31 03:41:15 - train: epoch 0010, iter [03500, 05004], lr: 0.100000, loss: 4.7011, tea_CELoss: 2.0334, stu_CELoss: 2.2550, DMLLoss: 0.4126, 
2022-07-31 03:42:12 - train: epoch 0010, iter [03600, 05004], lr: 0.100000, loss: 4.5856, tea_CELoss: 1.8956, stu_CELoss: 2.2057, DMLLoss: 0.4843, 
2022-07-31 03:43:09 - train: epoch 0010, iter [03700, 05004], lr: 0.100000, loss: 4.7321, tea_CELoss: 2.0309, stu_CELoss: 2.2569, DMLLoss: 0.4443, 
2022-07-31 03:44:06 - train: epoch 0010, iter [03800, 05004], lr: 0.100000, loss: 4.4233, tea_CELoss: 1.8685, stu_CELoss: 2.1725, DMLLoss: 0.3822, 
2022-07-31 03:45:03 - train: epoch 0010, iter [03900, 05004], lr: 0.100000, loss: 4.0438, tea_CELoss: 1.7304, stu_CELoss: 1.9311, DMLLoss: 0.3823, 
2022-07-31 03:46:01 - train: epoch 0010, iter [04000, 05004], lr: 0.100000, loss: 4.1144, tea_CELoss: 1.7273, stu_CELoss: 1.9953, DMLLoss: 0.3918, 
2022-07-31 03:46:58 - train: epoch 0010, iter [04100, 05004], lr: 0.100000, loss: 3.9179, tea_CELoss: 1.6522, stu_CELoss: 1.8772, DMLLoss: 0.3885, 
2022-07-31 03:47:55 - train: epoch 0010, iter [04200, 05004], lr: 0.100000, loss: 4.2358, tea_CELoss: 1.7848, stu_CELoss: 2.0271, DMLLoss: 0.4239, 
2022-07-31 03:48:52 - train: epoch 0010, iter [04300, 05004], lr: 0.100000, loss: 4.1367, tea_CELoss: 1.7529, stu_CELoss: 2.0155, DMLLoss: 0.3683, 
2022-07-31 03:49:50 - train: epoch 0010, iter [04400, 05004], lr: 0.100000, loss: 4.2538, tea_CELoss: 1.8098, stu_CELoss: 2.0603, DMLLoss: 0.3838, 
2022-07-31 03:50:47 - train: epoch 0010, iter [04500, 05004], lr: 0.100000, loss: 4.5459, tea_CELoss: 1.9484, stu_CELoss: 2.1870, DMLLoss: 0.4105, 
2022-07-31 03:51:44 - train: epoch 0010, iter [04600, 05004], lr: 0.100000, loss: 4.0751, tea_CELoss: 1.7240, stu_CELoss: 1.9683, DMLLoss: 0.3829, 
2022-07-31 03:52:41 - train: epoch 0010, iter [04700, 05004], lr: 0.100000, loss: 4.2852, tea_CELoss: 1.8563, stu_CELoss: 2.0590, DMLLoss: 0.3700, 
2022-07-31 03:53:38 - train: epoch 0010, iter [04800, 05004], lr: 0.100000, loss: 4.0384, tea_CELoss: 1.6902, stu_CELoss: 1.9579, DMLLoss: 0.3903, 
2022-07-31 03:54:35 - train: epoch 0010, iter [04900, 05004], lr: 0.100000, loss: 4.3690, tea_CELoss: 1.8107, stu_CELoss: 2.1362, DMLLoss: 0.4221, 
2022-07-31 03:55:32 - train: epoch 0010, iter [05000, 05004], lr: 0.100000, loss: 3.9331, tea_CELoss: 1.6382, stu_CELoss: 1.9069, DMLLoss: 0.3880, 
2022-07-31 03:55:35 - train: epoch 010, train_loss: 4.3378
2022-07-31 03:58:07 - eval: epoch: 010, tea_acc1: 60.048%, tea_acc5: 83.754%, tea_test_loss: 1.6644, stu_acc1: 56.074%, stu_acc5: 80.702%, stu_test_loss: 1.8427
2022-07-31 03:58:08 - until epoch: 010, tea_best_acc1: 60.890%, stu_best_acc1: 56.074%
2022-07-31 03:58:08 - epoch 011 lr: 0.100000
2022-07-31 03:59:12 - train: epoch 0011, iter [00100, 05004], lr: 0.100000, loss: 4.2697, tea_CELoss: 1.7683, stu_CELoss: 2.0975, DMLLoss: 0.4038, 
2022-07-31 04:00:09 - train: epoch 0011, iter [00200, 05004], lr: 0.100000, loss: 4.7449, tea_CELoss: 2.0414, stu_CELoss: 2.3013, DMLLoss: 0.4021, 
2022-07-31 04:01:07 - train: epoch 0011, iter [00300, 05004], lr: 0.100000, loss: 4.5416, tea_CELoss: 1.9451, stu_CELoss: 2.1756, DMLLoss: 0.4209, 
2022-07-31 04:02:04 - train: epoch 0011, iter [00400, 05004], lr: 0.100000, loss: 4.6886, tea_CELoss: 1.9775, stu_CELoss: 2.2545, DMLLoss: 0.4566, 
2022-07-31 04:03:01 - train: epoch 0011, iter [00500, 05004], lr: 0.100000, loss: 3.9611, tea_CELoss: 1.6522, stu_CELoss: 1.8779, DMLLoss: 0.4310, 
2022-07-31 04:03:58 - train: epoch 0011, iter [00600, 05004], lr: 0.100000, loss: 4.7391, tea_CELoss: 2.0021, stu_CELoss: 2.2963, DMLLoss: 0.4406, 
2022-07-31 04:04:56 - train: epoch 0011, iter [00700, 05004], lr: 0.100000, loss: 4.4523, tea_CELoss: 1.8574, stu_CELoss: 2.1712, DMLLoss: 0.4237, 
2022-07-31 04:05:53 - train: epoch 0011, iter [00800, 05004], lr: 0.100000, loss: 4.5806, tea_CELoss: 1.9721, stu_CELoss: 2.2188, DMLLoss: 0.3897, 
2022-07-31 04:06:50 - train: epoch 0011, iter [00900, 05004], lr: 0.100000, loss: 4.6643, tea_CELoss: 1.9409, stu_CELoss: 2.3196, DMLLoss: 0.4038, 
2022-07-31 04:07:48 - train: epoch 0011, iter [01000, 05004], lr: 0.100000, loss: 4.0906, tea_CELoss: 1.7298, stu_CELoss: 1.9486, DMLLoss: 0.4122, 
2022-07-31 04:08:45 - train: epoch 0011, iter [01100, 05004], lr: 0.100000, loss: 4.1258, tea_CELoss: 1.7674, stu_CELoss: 1.9736, DMLLoss: 0.3848, 
2022-07-31 04:09:42 - train: epoch 0011, iter [01200, 05004], lr: 0.100000, loss: 4.4984, tea_CELoss: 1.9181, stu_CELoss: 2.2194, DMLLoss: 0.3609, 
2022-07-31 04:10:40 - train: epoch 0011, iter [01300, 05004], lr: 0.100000, loss: 4.3331, tea_CELoss: 1.8683, stu_CELoss: 2.0567, DMLLoss: 0.4081, 
2022-07-31 04:11:37 - train: epoch 0011, iter [01400, 05004], lr: 0.100000, loss: 4.6810, tea_CELoss: 2.0113, stu_CELoss: 2.2712, DMLLoss: 0.3986, 
2022-07-31 04:12:34 - train: epoch 0011, iter [01500, 05004], lr: 0.100000, loss: 4.1830, tea_CELoss: 1.7157, stu_CELoss: 2.0673, DMLLoss: 0.4000, 
2022-07-31 04:13:32 - train: epoch 0011, iter [01600, 05004], lr: 0.100000, loss: 4.5833, tea_CELoss: 1.9167, stu_CELoss: 2.2227, DMLLoss: 0.4439, 
2022-07-31 04:14:29 - train: epoch 0011, iter [01700, 05004], lr: 0.100000, loss: 4.5845, tea_CELoss: 1.9423, stu_CELoss: 2.2139, DMLLoss: 0.4284, 
2022-07-31 04:15:26 - train: epoch 0011, iter [01800, 05004], lr: 0.100000, loss: 4.4674, tea_CELoss: 1.9074, stu_CELoss: 2.1807, DMLLoss: 0.3793, 
2022-07-31 04:16:23 - train: epoch 0011, iter [01900, 05004], lr: 0.100000, loss: 4.1296, tea_CELoss: 1.6967, stu_CELoss: 2.0265, DMLLoss: 0.4064, 
2022-07-31 04:17:20 - train: epoch 0011, iter [02000, 05004], lr: 0.100000, loss: 4.0245, tea_CELoss: 1.6994, stu_CELoss: 1.9495, DMLLoss: 0.3757, 
2022-07-31 04:18:18 - train: epoch 0011, iter [02100, 05004], lr: 0.100000, loss: 4.0390, tea_CELoss: 1.7253, stu_CELoss: 1.9373, DMLLoss: 0.3764, 
2022-07-31 04:19:15 - train: epoch 0011, iter [02200, 05004], lr: 0.100000, loss: 3.9573, tea_CELoss: 1.6423, stu_CELoss: 1.9043, DMLLoss: 0.4107, 
2022-07-31 04:20:12 - train: epoch 0011, iter [02300, 05004], lr: 0.100000, loss: 4.3582, tea_CELoss: 1.8654, stu_CELoss: 2.1145, DMLLoss: 0.3782, 
2022-07-31 04:21:09 - train: epoch 0011, iter [02400, 05004], lr: 0.100000, loss: 3.9079, tea_CELoss: 1.6891, stu_CELoss: 1.8704, DMLLoss: 0.3483, 
2022-07-31 04:22:07 - train: epoch 0011, iter [02500, 05004], lr: 0.100000, loss: 4.4762, tea_CELoss: 1.8843, stu_CELoss: 2.1731, DMLLoss: 0.4188, 
2022-07-31 04:23:04 - train: epoch 0011, iter [02600, 05004], lr: 0.100000, loss: 4.0889, tea_CELoss: 1.6643, stu_CELoss: 1.9924, DMLLoss: 0.4323, 
2022-07-31 04:24:01 - train: epoch 0011, iter [02700, 05004], lr: 0.100000, loss: 4.1211, tea_CELoss: 1.7078, stu_CELoss: 2.0340, DMLLoss: 0.3794, 
2022-07-31 04:24:58 - train: epoch 0011, iter [02800, 05004], lr: 0.100000, loss: 3.8451, tea_CELoss: 1.6108, stu_CELoss: 1.8646, DMLLoss: 0.3697, 
2022-07-31 04:25:55 - train: epoch 0011, iter [02900, 05004], lr: 0.100000, loss: 4.5552, tea_CELoss: 1.9405, stu_CELoss: 2.1853, DMLLoss: 0.4295, 
2022-07-31 04:26:52 - train: epoch 0011, iter [03000, 05004], lr: 0.100000, loss: 5.0077, tea_CELoss: 2.1546, stu_CELoss: 2.4290, DMLLoss: 0.4241, 
2022-07-31 04:27:49 - train: epoch 0011, iter [03100, 05004], lr: 0.100000, loss: 4.1686, tea_CELoss: 1.7930, stu_CELoss: 1.9719, DMLLoss: 0.4037, 
2022-07-31 04:28:46 - train: epoch 0011, iter [03200, 05004], lr: 0.100000, loss: 4.2613, tea_CELoss: 1.8566, stu_CELoss: 2.0313, DMLLoss: 0.3735, 
2022-07-31 04:29:43 - train: epoch 0011, iter [03300, 05004], lr: 0.100000, loss: 4.2424, tea_CELoss: 1.7882, stu_CELoss: 2.0473, DMLLoss: 0.4069, 
2022-07-31 04:30:40 - train: epoch 0011, iter [03400, 05004], lr: 0.100000, loss: 4.2527, tea_CELoss: 1.8596, stu_CELoss: 2.0397, DMLLoss: 0.3534, 
2022-07-31 04:31:38 - train: epoch 0011, iter [03500, 05004], lr: 0.100000, loss: 4.0974, tea_CELoss: 1.6969, stu_CELoss: 1.9787, DMLLoss: 0.4218, 
2022-07-31 04:32:35 - train: epoch 0011, iter [03600, 05004], lr: 0.100000, loss: 3.8203, tea_CELoss: 1.6208, stu_CELoss: 1.8263, DMLLoss: 0.3732, 
2022-07-31 04:33:32 - train: epoch 0011, iter [03700, 05004], lr: 0.100000, loss: 4.6392, tea_CELoss: 2.0453, stu_CELoss: 2.2146, DMLLoss: 0.3794, 
2022-07-31 04:34:29 - train: epoch 0011, iter [03800, 05004], lr: 0.100000, loss: 4.2075, tea_CELoss: 1.8110, stu_CELoss: 2.0304, DMLLoss: 0.3660, 
2022-07-31 04:35:26 - train: epoch 0011, iter [03900, 05004], lr: 0.100000, loss: 4.2909, tea_CELoss: 1.8183, stu_CELoss: 2.0627, DMLLoss: 0.4100, 
2022-07-31 04:36:23 - train: epoch 0011, iter [04000, 05004], lr: 0.100000, loss: 3.8738, tea_CELoss: 1.5499, stu_CELoss: 1.8681, DMLLoss: 0.4558, 
2022-07-31 04:37:20 - train: epoch 0011, iter [04100, 05004], lr: 0.100000, loss: 4.0538, tea_CELoss: 1.6922, stu_CELoss: 1.9606, DMLLoss: 0.4010, 
2022-07-31 04:38:18 - train: epoch 0011, iter [04200, 05004], lr: 0.100000, loss: 3.9320, tea_CELoss: 1.6647, stu_CELoss: 1.8778, DMLLoss: 0.3895, 
2022-07-31 04:39:15 - train: epoch 0011, iter [04300, 05004], lr: 0.100000, loss: 4.0844, tea_CELoss: 1.6608, stu_CELoss: 1.9939, DMLLoss: 0.4297, 
2022-07-31 04:40:12 - train: epoch 0011, iter [04400, 05004], lr: 0.100000, loss: 4.8678, tea_CELoss: 2.0599, stu_CELoss: 2.3682, DMLLoss: 0.4397, 
2022-07-31 04:41:09 - train: epoch 0011, iter [04500, 05004], lr: 0.100000, loss: 4.3004, tea_CELoss: 1.7730, stu_CELoss: 2.0971, DMLLoss: 0.4302, 
2022-07-31 04:42:06 - train: epoch 0011, iter [04600, 05004], lr: 0.100000, loss: 4.3482, tea_CELoss: 1.9081, stu_CELoss: 2.0706, DMLLoss: 0.3695, 
2022-07-31 04:43:04 - train: epoch 0011, iter [04700, 05004], lr: 0.100000, loss: 4.1210, tea_CELoss: 1.7172, stu_CELoss: 1.9727, DMLLoss: 0.4311, 
2022-07-31 04:44:01 - train: epoch 0011, iter [04800, 05004], lr: 0.100000, loss: 3.6586, tea_CELoss: 1.5199, stu_CELoss: 1.7490, DMLLoss: 0.3898, 
2022-07-31 04:44:58 - train: epoch 0011, iter [04900, 05004], lr: 0.100000, loss: 3.9238, tea_CELoss: 1.6764, stu_CELoss: 1.8683, DMLLoss: 0.3791, 
2022-07-31 04:45:55 - train: epoch 0011, iter [05000, 05004], lr: 0.100000, loss: 4.1416, tea_CELoss: 1.7237, stu_CELoss: 2.0453, DMLLoss: 0.3725, 
2022-07-31 04:45:58 - train: epoch 011, train_loss: 4.2901
2022-07-31 04:48:31 - eval: epoch: 011, tea_acc1: 61.560%, tea_acc5: 84.732%, tea_test_loss: 1.5916, stu_acc1: 57.536%, stu_acc5: 81.850%, stu_test_loss: 1.7850
2022-07-31 04:48:33 - until epoch: 011, tea_best_acc1: 61.560%, stu_best_acc1: 57.536%
2022-07-31 04:48:33 - epoch 012 lr: 0.100000
2022-07-31 04:49:36 - train: epoch 0012, iter [00100, 05004], lr: 0.100000, loss: 4.0284, tea_CELoss: 1.7026, stu_CELoss: 1.9145, DMLLoss: 0.4112, 
2022-07-31 04:50:33 - train: epoch 0012, iter [00200, 05004], lr: 0.100000, loss: 3.7145, tea_CELoss: 1.5292, stu_CELoss: 1.7498, DMLLoss: 0.4355, 
2022-07-31 04:51:30 - train: epoch 0012, iter [00300, 05004], lr: 0.100000, loss: 3.9139, tea_CELoss: 1.6283, stu_CELoss: 1.9106, DMLLoss: 0.3750, 
2022-07-31 04:52:28 - train: epoch 0012, iter [00400, 05004], lr: 0.100000, loss: 4.1550, tea_CELoss: 1.7947, stu_CELoss: 2.0096, DMLLoss: 0.3507, 
2022-07-31 04:53:25 - train: epoch 0012, iter [00500, 05004], lr: 0.100000, loss: 4.5403, tea_CELoss: 1.9614, stu_CELoss: 2.1397, DMLLoss: 0.4392, 
2022-07-31 04:54:22 - train: epoch 0012, iter [00600, 05004], lr: 0.100000, loss: 3.6793, tea_CELoss: 1.5133, stu_CELoss: 1.7450, DMLLoss: 0.4211, 
2022-07-31 04:55:20 - train: epoch 0012, iter [00700, 05004], lr: 0.100000, loss: 3.8641, tea_CELoss: 1.5928, stu_CELoss: 1.8456, DMLLoss: 0.4257, 
2022-07-31 04:56:17 - train: epoch 0012, iter [00800, 05004], lr: 0.100000, loss: 4.8545, tea_CELoss: 2.0790, stu_CELoss: 2.3590, DMLLoss: 0.4165, 
2022-07-31 04:57:14 - train: epoch 0012, iter [00900, 05004], lr: 0.100000, loss: 4.3105, tea_CELoss: 1.8927, stu_CELoss: 2.0336, DMLLoss: 0.3843, 
2022-07-31 04:58:12 - train: epoch 0012, iter [01000, 05004], lr: 0.100000, loss: 3.8799, tea_CELoss: 1.6453, stu_CELoss: 1.8849, DMLLoss: 0.3497, 
2022-07-31 04:59:09 - train: epoch 0012, iter [01100, 05004], lr: 0.100000, loss: 4.6764, tea_CELoss: 2.0281, stu_CELoss: 2.2456, DMLLoss: 0.4026, 
2022-07-31 05:00:06 - train: epoch 0012, iter [01200, 05004], lr: 0.100000, loss: 3.6677, tea_CELoss: 1.5337, stu_CELoss: 1.7077, DMLLoss: 0.4262, 
2022-07-31 05:01:03 - train: epoch 0012, iter [01300, 05004], lr: 0.100000, loss: 3.9557, tea_CELoss: 1.6699, stu_CELoss: 1.9048, DMLLoss: 0.3811, 
2022-07-31 05:02:01 - train: epoch 0012, iter [01400, 05004], lr: 0.100000, loss: 4.5682, tea_CELoss: 1.9535, stu_CELoss: 2.1947, DMLLoss: 0.4200, 
2022-07-31 05:02:58 - train: epoch 0012, iter [01500, 05004], lr: 0.100000, loss: 4.1003, tea_CELoss: 1.7306, stu_CELoss: 1.9861, DMLLoss: 0.3836, 
2022-07-31 05:03:55 - train: epoch 0012, iter [01600, 05004], lr: 0.100000, loss: 4.0628, tea_CELoss: 1.7219, stu_CELoss: 1.9534, DMLLoss: 0.3875, 
2022-07-31 05:04:52 - train: epoch 0012, iter [01700, 05004], lr: 0.100000, loss: 3.9409, tea_CELoss: 1.6628, stu_CELoss: 1.8982, DMLLoss: 0.3799, 
2022-07-31 05:05:49 - train: epoch 0012, iter [01800, 05004], lr: 0.100000, loss: 4.3359, tea_CELoss: 1.8420, stu_CELoss: 2.1015, DMLLoss: 0.3923, 
2022-07-31 05:06:47 - train: epoch 0012, iter [01900, 05004], lr: 0.100000, loss: 4.5259, tea_CELoss: 1.9477, stu_CELoss: 2.1629, DMLLoss: 0.4153, 
2022-07-31 05:07:44 - train: epoch 0012, iter [02000, 05004], lr: 0.100000, loss: 4.3415, tea_CELoss: 1.8247, stu_CELoss: 2.1034, DMLLoss: 0.4133, 
2022-07-31 05:08:41 - train: epoch 0012, iter [02100, 05004], lr: 0.100000, loss: 4.6033, tea_CELoss: 1.9645, stu_CELoss: 2.2211, DMLLoss: 0.4177, 
2022-07-31 05:09:38 - train: epoch 0012, iter [02200, 05004], lr: 0.100000, loss: 4.7557, tea_CELoss: 1.9923, stu_CELoss: 2.3153, DMLLoss: 0.4482, 
2022-07-31 05:10:35 - train: epoch 0012, iter [02300, 05004], lr: 0.100000, loss: 4.1997, tea_CELoss: 1.7891, stu_CELoss: 1.9980, DMLLoss: 0.4125, 
2022-07-31 05:11:33 - train: epoch 0012, iter [02400, 05004], lr: 0.100000, loss: 4.3431, tea_CELoss: 1.8236, stu_CELoss: 2.0826, DMLLoss: 0.4369, 
2022-07-31 05:12:30 - train: epoch 0012, iter [02500, 05004], lr: 0.100000, loss: 3.8392, tea_CELoss: 1.5798, stu_CELoss: 1.8078, DMLLoss: 0.4515, 
2022-07-31 05:13:27 - train: epoch 0012, iter [02600, 05004], lr: 0.100000, loss: 3.9074, tea_CELoss: 1.6739, stu_CELoss: 1.8442, DMLLoss: 0.3893, 
2022-07-31 05:14:24 - train: epoch 0012, iter [02700, 05004], lr: 0.100000, loss: 4.2952, tea_CELoss: 1.8030, stu_CELoss: 2.0684, DMLLoss: 0.4239, 
2022-07-31 05:15:22 - train: epoch 0012, iter [02800, 05004], lr: 0.100000, loss: 4.3958, tea_CELoss: 1.8339, stu_CELoss: 2.1740, DMLLoss: 0.3878, 
2022-07-31 05:16:19 - train: epoch 0012, iter [02900, 05004], lr: 0.100000, loss: 4.4590, tea_CELoss: 1.9377, stu_CELoss: 2.1218, DMLLoss: 0.3996, 
2022-07-31 05:17:16 - train: epoch 0012, iter [03000, 05004], lr: 0.100000, loss: 4.0071, tea_CELoss: 1.7009, stu_CELoss: 1.8903, DMLLoss: 0.4159, 
2022-07-31 05:18:13 - train: epoch 0012, iter [03100, 05004], lr: 0.100000, loss: 4.2644, tea_CELoss: 1.7753, stu_CELoss: 2.0578, DMLLoss: 0.4312, 
2022-07-31 05:19:10 - train: epoch 0012, iter [03200, 05004], lr: 0.100000, loss: 4.0430, tea_CELoss: 1.7174, stu_CELoss: 1.9413, DMLLoss: 0.3843, 
2022-07-31 05:20:08 - train: epoch 0012, iter [03300, 05004], lr: 0.100000, loss: 4.3029, tea_CELoss: 1.8299, stu_CELoss: 2.0562, DMLLoss: 0.4167, 
2022-07-31 05:21:05 - train: epoch 0012, iter [03400, 05004], lr: 0.100000, loss: 4.2152, tea_CELoss: 1.8396, stu_CELoss: 2.0278, DMLLoss: 0.3478, 
2022-07-31 05:22:02 - train: epoch 0012, iter [03500, 05004], lr: 0.100000, loss: 4.2942, tea_CELoss: 1.8500, stu_CELoss: 2.0105, DMLLoss: 0.4338, 
2022-07-31 05:22:59 - train: epoch 0012, iter [03600, 05004], lr: 0.100000, loss: 3.9879, tea_CELoss: 1.6497, stu_CELoss: 1.9593, DMLLoss: 0.3788, 
2022-07-31 05:23:57 - train: epoch 0012, iter [03700, 05004], lr: 0.100000, loss: 4.6405, tea_CELoss: 1.9802, stu_CELoss: 2.2321, DMLLoss: 0.4281, 
2022-07-31 05:24:54 - train: epoch 0012, iter [03800, 05004], lr: 0.100000, loss: 4.5271, tea_CELoss: 1.9760, stu_CELoss: 2.1657, DMLLoss: 0.3855, 
2022-07-31 05:25:51 - train: epoch 0012, iter [03900, 05004], lr: 0.100000, loss: 3.7185, tea_CELoss: 1.5219, stu_CELoss: 1.8095, DMLLoss: 0.3871, 
2022-07-31 05:26:49 - train: epoch 0012, iter [04000, 05004], lr: 0.100000, loss: 4.4739, tea_CELoss: 1.9441, stu_CELoss: 2.1187, DMLLoss: 0.4111, 
2022-07-31 05:27:46 - train: epoch 0012, iter [04100, 05004], lr: 0.100000, loss: 4.3725, tea_CELoss: 1.9172, stu_CELoss: 2.0567, DMLLoss: 0.3986, 
2022-07-31 05:28:44 - train: epoch 0012, iter [04200, 05004], lr: 0.100000, loss: 4.0236, tea_CELoss: 1.7263, stu_CELoss: 1.9384, DMLLoss: 0.3590, 
2022-07-31 05:29:41 - train: epoch 0012, iter [04300, 05004], lr: 0.100000, loss: 4.6230, tea_CELoss: 2.0056, stu_CELoss: 2.1990, DMLLoss: 0.4184, 
2022-07-31 05:30:39 - train: epoch 0012, iter [04400, 05004], lr: 0.100000, loss: 4.1185, tea_CELoss: 1.7838, stu_CELoss: 1.9631, DMLLoss: 0.3716, 
2022-07-31 05:31:36 - train: epoch 0012, iter [04500, 05004], lr: 0.100000, loss: 4.0030, tea_CELoss: 1.6454, stu_CELoss: 1.9721, DMLLoss: 0.3855, 
2022-07-31 05:32:33 - train: epoch 0012, iter [04600, 05004], lr: 0.100000, loss: 4.3187, tea_CELoss: 1.8872, stu_CELoss: 2.0636, DMLLoss: 0.3679, 
2022-07-31 05:33:31 - train: epoch 0012, iter [04700, 05004], lr: 0.100000, loss: 3.9664, tea_CELoss: 1.7364, stu_CELoss: 1.8708, DMLLoss: 0.3592, 
2022-07-31 05:34:28 - train: epoch 0012, iter [04800, 05004], lr: 0.100000, loss: 4.3695, tea_CELoss: 1.8646, stu_CELoss: 2.0874, DMLLoss: 0.4174, 
2022-07-31 05:35:26 - train: epoch 0012, iter [04900, 05004], lr: 0.100000, loss: 3.8768, tea_CELoss: 1.6581, stu_CELoss: 1.8472, DMLLoss: 0.3716, 
2022-07-31 05:36:23 - train: epoch 0012, iter [05000, 05004], lr: 0.100000, loss: 4.1391, tea_CELoss: 1.7808, stu_CELoss: 1.9910, DMLLoss: 0.3673, 
2022-07-31 05:36:26 - train: epoch 012, train_loss: 4.2443
2022-07-31 05:38:57 - eval: epoch: 012, tea_acc1: 61.554%, tea_acc5: 84.746%, tea_test_loss: 1.5977, stu_acc1: 56.932%, stu_acc5: 81.068%, stu_test_loss: 1.8297
2022-07-31 05:38:58 - until epoch: 012, tea_best_acc1: 61.560%, stu_best_acc1: 57.536%
2022-07-31 05:38:58 - epoch 013 lr: 0.100000
2022-07-31 05:40:02 - train: epoch 0013, iter [00100, 05004], lr: 0.100000, loss: 3.6800, tea_CELoss: 1.4930, stu_CELoss: 1.7742, DMLLoss: 0.4128, 
2022-07-31 05:40:59 - train: epoch 0013, iter [00200, 05004], lr: 0.100000, loss: 4.1603, tea_CELoss: 1.7847, stu_CELoss: 1.9805, DMLLoss: 0.3951, 
2022-07-31 05:41:56 - train: epoch 0013, iter [00300, 05004], lr: 0.100000, loss: 4.2357, tea_CELoss: 1.8348, stu_CELoss: 2.0286, DMLLoss: 0.3722, 
2022-07-31 05:42:53 - train: epoch 0013, iter [00400, 05004], lr: 0.100000, loss: 4.0248, tea_CELoss: 1.7602, stu_CELoss: 1.8616, DMLLoss: 0.4030, 
2022-07-31 05:43:50 - train: epoch 0013, iter [00500, 05004], lr: 0.100000, loss: 4.1229, tea_CELoss: 1.7583, stu_CELoss: 1.9563, DMLLoss: 0.4083, 
2022-07-31 05:44:47 - train: epoch 0013, iter [00600, 05004], lr: 0.100000, loss: 4.3699, tea_CELoss: 1.8805, stu_CELoss: 2.1022, DMLLoss: 0.3872, 
2022-07-31 05:45:44 - train: epoch 0013, iter [00700, 05004], lr: 0.100000, loss: 3.9729, tea_CELoss: 1.6825, stu_CELoss: 1.8882, DMLLoss: 0.4021, 
2022-07-31 05:46:41 - train: epoch 0013, iter [00800, 05004], lr: 0.100000, loss: 4.5279, tea_CELoss: 1.9362, stu_CELoss: 2.1690, DMLLoss: 0.4227, 
2022-07-31 05:47:38 - train: epoch 0013, iter [00900, 05004], lr: 0.100000, loss: 4.4845, tea_CELoss: 1.9655, stu_CELoss: 2.1297, DMLLoss: 0.3894, 
2022-07-31 05:48:36 - train: epoch 0013, iter [01000, 05004], lr: 0.100000, loss: 3.9846, tea_CELoss: 1.6976, stu_CELoss: 1.8764, DMLLoss: 0.4106, 
2022-07-31 05:49:33 - train: epoch 0013, iter [01100, 05004], lr: 0.100000, loss: 4.2928, tea_CELoss: 1.8147, stu_CELoss: 2.0273, DMLLoss: 0.4509, 
2022-07-31 05:50:30 - train: epoch 0013, iter [01200, 05004], lr: 0.100000, loss: 4.5870, tea_CELoss: 1.9817, stu_CELoss: 2.1767, DMLLoss: 0.4286, 
2022-07-31 05:51:27 - train: epoch 0013, iter [01300, 05004], lr: 0.100000, loss: 4.0700, tea_CELoss: 1.7307, stu_CELoss: 1.9113, DMLLoss: 0.4279, 
2022-07-31 05:52:24 - train: epoch 0013, iter [01400, 05004], lr: 0.100000, loss: 4.0737, tea_CELoss: 1.6851, stu_CELoss: 1.9977, DMLLoss: 0.3910, 
2022-07-31 05:53:21 - train: epoch 0013, iter [01500, 05004], lr: 0.100000, loss: 4.3859, tea_CELoss: 1.8376, stu_CELoss: 2.0964, DMLLoss: 0.4519, 
2022-07-31 05:54:18 - train: epoch 0013, iter [01600, 05004], lr: 0.100000, loss: 4.2376, tea_CELoss: 1.8407, stu_CELoss: 1.9834, DMLLoss: 0.4136, 
2022-07-31 05:55:15 - train: epoch 0013, iter [01700, 05004], lr: 0.100000, loss: 4.0450, tea_CELoss: 1.6554, stu_CELoss: 1.9842, DMLLoss: 0.4054, 
2022-07-31 05:56:12 - train: epoch 0013, iter [01800, 05004], lr: 0.100000, loss: 4.2950, tea_CELoss: 1.8068, stu_CELoss: 2.0831, DMLLoss: 0.4051, 
2022-07-31 05:57:09 - train: epoch 0013, iter [01900, 05004], lr: 0.100000, loss: 4.3509, tea_CELoss: 1.8988, stu_CELoss: 2.0563, DMLLoss: 0.3958, 
2022-07-31 05:58:07 - train: epoch 0013, iter [02000, 05004], lr: 0.100000, loss: 4.3109, tea_CELoss: 1.7788, stu_CELoss: 2.0846, DMLLoss: 0.4474, 
2022-07-31 05:59:04 - train: epoch 0013, iter [02100, 05004], lr: 0.100000, loss: 4.4834, tea_CELoss: 1.9446, stu_CELoss: 2.1534, DMLLoss: 0.3854, 
2022-07-31 06:00:01 - train: epoch 0013, iter [02200, 05004], lr: 0.100000, loss: 3.9207, tea_CELoss: 1.6298, stu_CELoss: 1.9282, DMLLoss: 0.3627, 
2022-07-31 06:00:58 - train: epoch 0013, iter [02300, 05004], lr: 0.100000, loss: 3.9758, tea_CELoss: 1.6747, stu_CELoss: 1.9117, DMLLoss: 0.3894, 
2022-07-31 06:01:55 - train: epoch 0013, iter [02400, 05004], lr: 0.100000, loss: 4.3509, tea_CELoss: 1.8489, stu_CELoss: 2.1117, DMLLoss: 0.3904, 
2022-07-31 06:02:52 - train: epoch 0013, iter [02500, 05004], lr: 0.100000, loss: 4.1825, tea_CELoss: 1.7457, stu_CELoss: 2.0653, DMLLoss: 0.3715, 
2022-07-31 06:03:49 - train: epoch 0013, iter [02600, 05004], lr: 0.100000, loss: 4.1608, tea_CELoss: 1.8062, stu_CELoss: 1.9857, DMLLoss: 0.3689, 
2022-07-31 06:04:46 - train: epoch 0013, iter [02700, 05004], lr: 0.100000, loss: 4.2569, tea_CELoss: 1.7759, stu_CELoss: 2.0302, DMLLoss: 0.4507, 
2022-07-31 06:05:43 - train: epoch 0013, iter [02800, 05004], lr: 0.100000, loss: 4.1605, tea_CELoss: 1.7553, stu_CELoss: 2.0135, DMLLoss: 0.3917, 
2022-07-31 06:06:40 - train: epoch 0013, iter [02900, 05004], lr: 0.100000, loss: 4.2212, tea_CELoss: 1.7891, stu_CELoss: 2.0393, DMLLoss: 0.3929, 
2022-07-31 06:07:37 - train: epoch 0013, iter [03000, 05004], lr: 0.100000, loss: 3.8351, tea_CELoss: 1.5958, stu_CELoss: 1.8492, DMLLoss: 0.3902, 
2022-07-31 06:08:35 - train: epoch 0013, iter [03100, 05004], lr: 0.100000, loss: 4.0115, tea_CELoss: 1.7257, stu_CELoss: 1.9044, DMLLoss: 0.3814, 
2022-07-31 06:09:32 - train: epoch 0013, iter [03200, 05004], lr: 0.100000, loss: 4.3792, tea_CELoss: 1.8400, stu_CELoss: 2.1651, DMLLoss: 0.3742, 
2022-07-31 06:10:29 - train: epoch 0013, iter [03300, 05004], lr: 0.100000, loss: 3.9152, tea_CELoss: 1.6494, stu_CELoss: 1.8581, DMLLoss: 0.4077, 
2022-07-31 06:11:26 - train: epoch 0013, iter [03400, 05004], lr: 0.100000, loss: 4.0264, tea_CELoss: 1.7337, stu_CELoss: 1.9416, DMLLoss: 0.3511, 
2022-07-31 06:12:23 - train: epoch 0013, iter [03500, 05004], lr: 0.100000, loss: 4.0159, tea_CELoss: 1.7560, stu_CELoss: 1.8774, DMLLoss: 0.3825, 
2022-07-31 06:13:20 - train: epoch 0013, iter [03600, 05004], lr: 0.100000, loss: 4.5196, tea_CELoss: 1.9215, stu_CELoss: 2.1566, DMLLoss: 0.4415, 
2022-07-31 06:14:17 - train: epoch 0013, iter [03700, 05004], lr: 0.100000, loss: 3.6633, tea_CELoss: 1.5765, stu_CELoss: 1.7312, DMLLoss: 0.3556, 
2022-07-31 06:15:14 - train: epoch 0013, iter [03800, 05004], lr: 0.100000, loss: 4.6761, tea_CELoss: 1.9990, stu_CELoss: 2.2704, DMLLoss: 0.4067, 
2022-07-31 06:16:11 - train: epoch 0013, iter [03900, 05004], lr: 0.100000, loss: 4.5095, tea_CELoss: 1.9115, stu_CELoss: 2.2070, DMLLoss: 0.3910, 
2022-07-31 06:17:09 - train: epoch 0013, iter [04000, 05004], lr: 0.100000, loss: 4.0664, tea_CELoss: 1.7437, stu_CELoss: 1.9385, DMLLoss: 0.3842, 
2022-07-31 06:18:06 - train: epoch 0013, iter [04100, 05004], lr: 0.100000, loss: 3.9097, tea_CELoss: 1.6815, stu_CELoss: 1.8358, DMLLoss: 0.3923, 
2022-07-31 06:19:03 - train: epoch 0013, iter [04200, 05004], lr: 0.100000, loss: 4.2826, tea_CELoss: 1.8217, stu_CELoss: 2.0803, DMLLoss: 0.3805, 
2022-07-31 06:20:01 - train: epoch 0013, iter [04300, 05004], lr: 0.100000, loss: 4.1535, tea_CELoss: 1.7823, stu_CELoss: 1.9761, DMLLoss: 0.3952, 
2022-07-31 06:20:58 - train: epoch 0013, iter [04400, 05004], lr: 0.100000, loss: 4.0909, tea_CELoss: 1.7330, stu_CELoss: 1.9501, DMLLoss: 0.4077, 
2022-07-31 06:21:55 - train: epoch 0013, iter [04500, 05004], lr: 0.100000, loss: 3.8589, tea_CELoss: 1.6742, stu_CELoss: 1.8398, DMLLoss: 0.3449, 
2022-07-31 06:22:53 - train: epoch 0013, iter [04600, 05004], lr: 0.100000, loss: 4.1344, tea_CELoss: 1.7414, stu_CELoss: 1.9832, DMLLoss: 0.4098, 
2022-07-31 06:23:50 - train: epoch 0013, iter [04700, 05004], lr: 0.100000, loss: 4.2835, tea_CELoss: 1.8248, stu_CELoss: 2.0866, DMLLoss: 0.3722, 
2022-07-31 06:24:47 - train: epoch 0013, iter [04800, 05004], lr: 0.100000, loss: 4.3016, tea_CELoss: 1.8532, stu_CELoss: 2.0814, DMLLoss: 0.3670, 
2022-07-31 06:25:44 - train: epoch 0013, iter [04900, 05004], lr: 0.100000, loss: 4.6151, tea_CELoss: 1.9831, stu_CELoss: 2.2235, DMLLoss: 0.4085, 
2022-07-31 06:26:41 - train: epoch 0013, iter [05000, 05004], lr: 0.100000, loss: 4.2168, tea_CELoss: 1.7442, stu_CELoss: 2.0023, DMLLoss: 0.4703, 
2022-07-31 06:26:44 - train: epoch 013, train_loss: 4.2107
2022-07-31 06:29:16 - eval: epoch: 013, tea_acc1: 60.630%, tea_acc5: 83.960%, tea_test_loss: 1.6540, stu_acc1: 57.896%, stu_acc5: 81.876%, stu_test_loss: 1.7754
2022-07-31 06:29:17 - until epoch: 013, tea_best_acc1: 61.560%, stu_best_acc1: 57.896%
2022-07-31 06:29:17 - epoch 014 lr: 0.100000
2022-07-31 06:30:20 - train: epoch 0014, iter [00100, 05004], lr: 0.100000, loss: 4.2428, tea_CELoss: 1.7945, stu_CELoss: 2.0315, DMLLoss: 0.4167, 
2022-07-31 06:31:18 - train: epoch 0014, iter [00200, 05004], lr: 0.100000, loss: 4.4756, tea_CELoss: 1.9259, stu_CELoss: 2.1694, DMLLoss: 0.3804, 
2022-07-31 06:32:15 - train: epoch 0014, iter [00300, 05004], lr: 0.100000, loss: 3.9640, tea_CELoss: 1.7409, stu_CELoss: 1.8627, DMLLoss: 0.3604, 
2022-07-31 06:33:13 - train: epoch 0014, iter [00400, 05004], lr: 0.100000, loss: 3.9027, tea_CELoss: 1.6825, stu_CELoss: 1.8723, DMLLoss: 0.3479, 
2022-07-31 06:34:10 - train: epoch 0014, iter [00500, 05004], lr: 0.100000, loss: 4.0501, tea_CELoss: 1.7656, stu_CELoss: 1.9214, DMLLoss: 0.3631, 
2022-07-31 06:35:07 - train: epoch 0014, iter [00600, 05004], lr: 0.100000, loss: 4.4393, tea_CELoss: 1.9311, stu_CELoss: 2.0706, DMLLoss: 0.4376, 
2022-07-31 06:36:04 - train: epoch 0014, iter [00700, 05004], lr: 0.100000, loss: 3.9551, tea_CELoss: 1.6738, stu_CELoss: 1.9351, DMLLoss: 0.3462, 
2022-07-31 06:37:01 - train: epoch 0014, iter [00800, 05004], lr: 0.100000, loss: 3.9309, tea_CELoss: 1.6462, stu_CELoss: 1.8687, DMLLoss: 0.4160, 
2022-07-31 06:37:58 - train: epoch 0014, iter [00900, 05004], lr: 0.100000, loss: 4.0351, tea_CELoss: 1.7384, stu_CELoss: 1.9216, DMLLoss: 0.3752, 
2022-07-31 06:38:56 - train: epoch 0014, iter [01000, 05004], lr: 0.100000, loss: 4.4695, tea_CELoss: 1.8467, stu_CELoss: 2.1826, DMLLoss: 0.4402, 
2022-07-31 06:39:53 - train: epoch 0014, iter [01100, 05004], lr: 0.100000, loss: 4.2056, tea_CELoss: 1.7610, stu_CELoss: 2.0176, DMLLoss: 0.4270, 
2022-07-31 06:40:50 - train: epoch 0014, iter [01200, 05004], lr: 0.100000, loss: 4.5345, tea_CELoss: 1.9916, stu_CELoss: 2.1666, DMLLoss: 0.3763, 
2022-07-31 06:41:48 - train: epoch 0014, iter [01300, 05004], lr: 0.100000, loss: 4.4949, tea_CELoss: 1.9126, stu_CELoss: 2.1841, DMLLoss: 0.3982, 
2022-07-31 06:42:45 - train: epoch 0014, iter [01400, 05004], lr: 0.100000, loss: 4.3223, tea_CELoss: 1.8669, stu_CELoss: 2.0911, DMLLoss: 0.3643, 
2022-07-31 06:43:42 - train: epoch 0014, iter [01500, 05004], lr: 0.100000, loss: 4.5541, tea_CELoss: 1.9816, stu_CELoss: 2.1551, DMLLoss: 0.4174, 
2022-07-31 06:44:40 - train: epoch 0014, iter [01600, 05004], lr: 0.100000, loss: 4.1977, tea_CELoss: 1.7561, stu_CELoss: 2.0461, DMLLoss: 0.3956, 
2022-07-31 06:45:37 - train: epoch 0014, iter [01700, 05004], lr: 0.100000, loss: 4.2957, tea_CELoss: 1.8584, stu_CELoss: 2.0874, DMLLoss: 0.3499, 
2022-07-31 06:46:34 - train: epoch 0014, iter [01800, 05004], lr: 0.100000, loss: 4.5365, tea_CELoss: 1.9029, stu_CELoss: 2.1573, DMLLoss: 0.4763, 
2022-07-31 06:47:32 - train: epoch 0014, iter [01900, 05004], lr: 0.100000, loss: 4.0420, tea_CELoss: 1.6692, stu_CELoss: 1.9718, DMLLoss: 0.4011, 
2022-07-31 06:48:29 - train: epoch 0014, iter [02000, 05004], lr: 0.100000, loss: 4.0002, tea_CELoss: 1.6598, stu_CELoss: 1.9294, DMLLoss: 0.4109, 
2022-07-31 06:49:26 - train: epoch 0014, iter [02100, 05004], lr: 0.100000, loss: 4.2196, tea_CELoss: 1.8202, stu_CELoss: 2.0185, DMLLoss: 0.3810, 
2022-07-31 06:50:23 - train: epoch 0014, iter [02200, 05004], lr: 0.100000, loss: 4.0318, tea_CELoss: 1.7036, stu_CELoss: 1.9543, DMLLoss: 0.3740, 
2022-07-31 06:51:21 - train: epoch 0014, iter [02300, 05004], lr: 0.100000, loss: 4.1314, tea_CELoss: 1.6833, stu_CELoss: 2.0482, DMLLoss: 0.3999, 
2022-07-31 06:52:18 - train: epoch 0014, iter [02400, 05004], lr: 0.100000, loss: 4.2679, tea_CELoss: 1.8768, stu_CELoss: 2.0093, DMLLoss: 0.3817, 
2022-07-31 06:53:15 - train: epoch 0014, iter [02500, 05004], lr: 0.100000, loss: 4.0017, tea_CELoss: 1.6671, stu_CELoss: 1.9420, DMLLoss: 0.3926, 
2022-07-31 06:54:13 - train: epoch 0014, iter [02600, 05004], lr: 0.100000, loss: 3.8076, tea_CELoss: 1.6077, stu_CELoss: 1.7811, DMLLoss: 0.4188, 
2022-07-31 06:55:10 - train: epoch 0014, iter [02700, 05004], lr: 0.100000, loss: 4.0092, tea_CELoss: 1.7144, stu_CELoss: 1.8564, DMLLoss: 0.4384, 
2022-07-31 06:56:07 - train: epoch 0014, iter [02800, 05004], lr: 0.100000, loss: 4.5386, tea_CELoss: 1.9644, stu_CELoss: 2.2050, DMLLoss: 0.3692, 
2022-07-31 06:57:05 - train: epoch 0014, iter [02900, 05004], lr: 0.100000, loss: 4.2256, tea_CELoss: 1.8431, stu_CELoss: 1.9825, DMLLoss: 0.4001, 
2022-07-31 06:58:02 - train: epoch 0014, iter [03000, 05004], lr: 0.100000, loss: 4.2797, tea_CELoss: 1.8645, stu_CELoss: 2.0290, DMLLoss: 0.3862, 
2022-07-31 06:59:00 - train: epoch 0014, iter [03100, 05004], lr: 0.100000, loss: 3.9979, tea_CELoss: 1.7179, stu_CELoss: 1.8980, DMLLoss: 0.3820, 
2022-07-31 06:59:57 - train: epoch 0014, iter [03200, 05004], lr: 0.100000, loss: 4.1008, tea_CELoss: 1.8005, stu_CELoss: 1.9702, DMLLoss: 0.3300, 
2022-07-31 07:00:54 - train: epoch 0014, iter [03300, 05004], lr: 0.100000, loss: 3.7060, tea_CELoss: 1.6035, stu_CELoss: 1.7670, DMLLoss: 0.3355, 
2022-07-31 07:01:52 - train: epoch 0014, iter [03400, 05004], lr: 0.100000, loss: 4.1025, tea_CELoss: 1.7680, stu_CELoss: 1.9636, DMLLoss: 0.3709, 
2022-07-31 07:02:49 - train: epoch 0014, iter [03500, 05004], lr: 0.100000, loss: 4.0521, tea_CELoss: 1.7123, stu_CELoss: 1.9590, DMLLoss: 0.3808, 
2022-07-31 07:03:47 - train: epoch 0014, iter [03600, 05004], lr: 0.100000, loss: 3.7300, tea_CELoss: 1.5575, stu_CELoss: 1.8020, DMLLoss: 0.3705, 
2022-07-31 07:04:44 - train: epoch 0014, iter [03700, 05004], lr: 0.100000, loss: 4.1726, tea_CELoss: 1.8052, stu_CELoss: 2.0051, DMLLoss: 0.3623, 
2022-07-31 07:05:41 - train: epoch 0014, iter [03800, 05004], lr: 0.100000, loss: 4.5289, tea_CELoss: 1.9497, stu_CELoss: 2.1592, DMLLoss: 0.4200, 
2022-07-31 07:06:39 - train: epoch 0014, iter [03900, 05004], lr: 0.100000, loss: 4.3094, tea_CELoss: 1.8874, stu_CELoss: 2.0459, DMLLoss: 0.3761, 
2022-07-31 07:07:36 - train: epoch 0014, iter [04000, 05004], lr: 0.100000, loss: 4.3714, tea_CELoss: 1.8801, stu_CELoss: 2.0670, DMLLoss: 0.4244, 
2022-07-31 07:08:33 - train: epoch 0014, iter [04100, 05004], lr: 0.100000, loss: 4.3861, tea_CELoss: 1.8684, stu_CELoss: 2.0787, DMLLoss: 0.4390, 
2022-07-31 07:09:31 - train: epoch 0014, iter [04200, 05004], lr: 0.100000, loss: 3.9622, tea_CELoss: 1.6609, stu_CELoss: 1.9251, DMLLoss: 0.3762, 
2022-07-31 07:10:28 - train: epoch 0014, iter [04300, 05004], lr: 0.100000, loss: 4.4132, tea_CELoss: 1.8682, stu_CELoss: 2.1578, DMLLoss: 0.3873, 
2022-07-31 07:11:26 - train: epoch 0014, iter [04400, 05004], lr: 0.100000, loss: 4.0799, tea_CELoss: 1.7879, stu_CELoss: 1.8911, DMLLoss: 0.4009, 
2022-07-31 07:12:23 - train: epoch 0014, iter [04500, 05004], lr: 0.100000, loss: 4.1046, tea_CELoss: 1.7293, stu_CELoss: 1.9933, DMLLoss: 0.3819, 
2022-07-31 07:13:21 - train: epoch 0014, iter [04600, 05004], lr: 0.100000, loss: 3.8633, tea_CELoss: 1.6343, stu_CELoss: 1.8432, DMLLoss: 0.3858, 
2022-07-31 07:14:18 - train: epoch 0014, iter [04700, 05004], lr: 0.100000, loss: 4.0581, tea_CELoss: 1.7490, stu_CELoss: 1.8884, DMLLoss: 0.4207, 
2022-07-31 07:15:16 - train: epoch 0014, iter [04800, 05004], lr: 0.100000, loss: 4.3001, tea_CELoss: 1.8787, stu_CELoss: 2.0370, DMLLoss: 0.3843, 
2022-07-31 07:16:13 - train: epoch 0014, iter [04900, 05004], lr: 0.100000, loss: 4.2469, tea_CELoss: 1.8778, stu_CELoss: 1.9829, DMLLoss: 0.3863, 
2022-07-31 07:17:10 - train: epoch 0014, iter [05000, 05004], lr: 0.100000, loss: 4.3937, tea_CELoss: 1.8857, stu_CELoss: 2.0818, DMLLoss: 0.4263, 
2022-07-31 07:17:13 - train: epoch 014, train_loss: 4.1845
2022-07-31 07:19:47 - eval: epoch: 014, tea_acc1: 61.414%, tea_acc5: 84.656%, tea_test_loss: 1.5983, stu_acc1: 56.818%, stu_acc5: 81.126%, stu_test_loss: 1.8312
2022-07-31 07:19:47 - until epoch: 014, tea_best_acc1: 61.560%, stu_best_acc1: 57.896%
2022-07-31 07:19:47 - epoch 015 lr: 0.100000
2022-07-31 07:20:51 - train: epoch 0015, iter [00100, 05004], lr: 0.100000, loss: 3.8620, tea_CELoss: 1.5945, stu_CELoss: 1.8218, DMLLoss: 0.4457, 
2022-07-31 07:21:48 - train: epoch 0015, iter [00200, 05004], lr: 0.100000, loss: 4.4246, tea_CELoss: 1.8904, stu_CELoss: 2.1243, DMLLoss: 0.4099, 
2022-07-31 07:22:46 - train: epoch 0015, iter [00300, 05004], lr: 0.100000, loss: 4.4461, tea_CELoss: 1.8337, stu_CELoss: 2.1750, DMLLoss: 0.4374, 
2022-07-31 07:23:44 - train: epoch 0015, iter [00400, 05004], lr: 0.100000, loss: 4.0329, tea_CELoss: 1.7393, stu_CELoss: 1.9155, DMLLoss: 0.3782, 
2022-07-31 07:24:41 - train: epoch 0015, iter [00500, 05004], lr: 0.100000, loss: 3.9008, tea_CELoss: 1.6517, stu_CELoss: 1.8947, DMLLoss: 0.3543, 
2022-07-31 07:25:39 - train: epoch 0015, iter [00600, 05004], lr: 0.100000, loss: 4.3325, tea_CELoss: 1.8944, stu_CELoss: 2.0513, DMLLoss: 0.3868, 
2022-07-31 07:26:36 - train: epoch 0015, iter [00700, 05004], lr: 0.100000, loss: 4.3511, tea_CELoss: 1.8592, stu_CELoss: 2.0701, DMLLoss: 0.4219, 
2022-07-31 07:27:34 - train: epoch 0015, iter [00800, 05004], lr: 0.100000, loss: 3.9804, tea_CELoss: 1.6705, stu_CELoss: 1.8773, DMLLoss: 0.4326, 
2022-07-31 07:28:31 - train: epoch 0015, iter [00900, 05004], lr: 0.100000, loss: 3.9575, tea_CELoss: 1.6779, stu_CELoss: 1.8913, DMLLoss: 0.3883, 
2022-07-31 07:29:28 - train: epoch 0015, iter [01000, 05004], lr: 0.100000, loss: 4.1216, tea_CELoss: 1.7941, stu_CELoss: 1.9249, DMLLoss: 0.4027, 
2022-07-31 07:30:25 - train: epoch 0015, iter [01100, 05004], lr: 0.100000, loss: 4.1398, tea_CELoss: 1.7802, stu_CELoss: 1.9965, DMLLoss: 0.3630, 
2022-07-31 07:31:23 - train: epoch 0015, iter [01200, 05004], lr: 0.100000, loss: 4.3441, tea_CELoss: 1.9073, stu_CELoss: 2.0290, DMLLoss: 0.4078, 
2022-07-31 07:32:20 - train: epoch 0015, iter [01300, 05004], lr: 0.100000, loss: 4.5528, tea_CELoss: 1.9440, stu_CELoss: 2.2333, DMLLoss: 0.3754, 
2022-07-31 07:33:17 - train: epoch 0015, iter [01400, 05004], lr: 0.100000, loss: 3.9472, tea_CELoss: 1.6546, stu_CELoss: 1.9000, DMLLoss: 0.3926, 
2022-07-31 07:34:15 - train: epoch 0015, iter [01500, 05004], lr: 0.100000, loss: 4.0804, tea_CELoss: 1.7921, stu_CELoss: 1.9098, DMLLoss: 0.3785, 
2022-07-31 07:35:12 - train: epoch 0015, iter [01600, 05004], lr: 0.100000, loss: 4.3146, tea_CELoss: 1.8520, stu_CELoss: 2.0359, DMLLoss: 0.4266, 
2022-07-31 07:36:09 - train: epoch 0015, iter [01700, 05004], lr: 0.100000, loss: 4.3175, tea_CELoss: 1.8384, stu_CELoss: 2.0686, DMLLoss: 0.4106, 
2022-07-31 07:37:07 - train: epoch 0015, iter [01800, 05004], lr: 0.100000, loss: 4.1199, tea_CELoss: 1.7340, stu_CELoss: 2.0002, DMLLoss: 0.3857, 
2022-07-31 07:38:04 - train: epoch 0015, iter [01900, 05004], lr: 0.100000, loss: 3.7577, tea_CELoss: 1.6128, stu_CELoss: 1.7562, DMLLoss: 0.3887, 
2022-07-31 07:39:01 - train: epoch 0015, iter [02000, 05004], lr: 0.100000, loss: 3.7663, tea_CELoss: 1.6403, stu_CELoss: 1.7463, DMLLoss: 0.3797, 
2022-07-31 07:39:58 - train: epoch 0015, iter [02100, 05004], lr: 0.100000, loss: 4.1515, tea_CELoss: 1.7980, stu_CELoss: 1.9644, DMLLoss: 0.3890, 
2022-07-31 07:40:55 - train: epoch 0015, iter [02200, 05004], lr: 0.100000, loss: 4.2449, tea_CELoss: 1.7994, stu_CELoss: 2.0373, DMLLoss: 0.4082, 
2022-07-31 07:41:52 - train: epoch 0015, iter [02300, 05004], lr: 0.100000, loss: 4.0494, tea_CELoss: 1.7111, stu_CELoss: 1.9327, DMLLoss: 0.4055, 
2022-07-31 07:42:49 - train: epoch 0015, iter [02400, 05004], lr: 0.100000, loss: 4.2115, tea_CELoss: 1.8117, stu_CELoss: 1.9955, DMLLoss: 0.4043, 
2022-07-31 07:43:46 - train: epoch 0015, iter [02500, 05004], lr: 0.100000, loss: 4.2344, tea_CELoss: 1.8922, stu_CELoss: 1.9704, DMLLoss: 0.3718, 
2022-07-31 07:44:43 - train: epoch 0015, iter [02600, 05004], lr: 0.100000, loss: 3.8646, tea_CELoss: 1.5999, stu_CELoss: 1.8542, DMLLoss: 0.4105, 
2022-07-31 07:45:40 - train: epoch 0015, iter [02700, 05004], lr: 0.100000, loss: 4.3237, tea_CELoss: 1.8862, stu_CELoss: 2.0883, DMLLoss: 0.3492, 
2022-07-31 07:46:37 - train: epoch 0015, iter [02800, 05004], lr: 0.100000, loss: 4.0715, tea_CELoss: 1.7416, stu_CELoss: 1.9458, DMLLoss: 0.3840, 
2022-07-31 07:47:34 - train: epoch 0015, iter [02900, 05004], lr: 0.100000, loss: 4.1217, tea_CELoss: 1.7431, stu_CELoss: 1.9948, DMLLoss: 0.3838, 
2022-07-31 07:48:31 - train: epoch 0015, iter [03000, 05004], lr: 0.100000, loss: 3.6489, tea_CELoss: 1.5652, stu_CELoss: 1.7251, DMLLoss: 0.3586, 
2022-07-31 07:49:28 - train: epoch 0015, iter [03100, 05004], lr: 0.100000, loss: 4.2398, tea_CELoss: 1.7942, stu_CELoss: 2.0619, DMLLoss: 0.3837, 
2022-07-31 07:50:25 - train: epoch 0015, iter [03200, 05004], lr: 0.100000, loss: 3.9671, tea_CELoss: 1.6896, stu_CELoss: 1.8841, DMLLoss: 0.3935, 
2022-07-31 07:51:22 - train: epoch 0015, iter [03300, 05004], lr: 0.100000, loss: 3.9645, tea_CELoss: 1.6627, stu_CELoss: 1.9115, DMLLoss: 0.3902, 
2022-07-31 07:52:19 - train: epoch 0015, iter [03400, 05004], lr: 0.100000, loss: 3.9553, tea_CELoss: 1.6667, stu_CELoss: 1.9104, DMLLoss: 0.3782, 
2022-07-31 07:53:17 - train: epoch 0015, iter [03500, 05004], lr: 0.100000, loss: 4.4510, tea_CELoss: 1.9445, stu_CELoss: 2.0896, DMLLoss: 0.4169, 
2022-07-31 07:54:14 - train: epoch 0015, iter [03600, 05004], lr: 0.100000, loss: 4.3881, tea_CELoss: 1.8861, stu_CELoss: 2.1144, DMLLoss: 0.3876, 
2022-07-31 07:55:11 - train: epoch 0015, iter [03700, 05004], lr: 0.100000, loss: 3.3219, tea_CELoss: 1.3898, stu_CELoss: 1.5716, DMLLoss: 0.3604, 
2022-07-31 07:56:08 - train: epoch 0015, iter [03800, 05004], lr: 0.100000, loss: 4.2190, tea_CELoss: 1.8570, stu_CELoss: 1.9979, DMLLoss: 0.3641, 
2022-07-31 07:57:05 - train: epoch 0015, iter [03900, 05004], lr: 0.100000, loss: 4.2562, tea_CELoss: 1.7963, stu_CELoss: 2.0420, DMLLoss: 0.4180, 
2022-07-31 07:58:02 - train: epoch 0015, iter [04000, 05004], lr: 0.100000, loss: 4.2044, tea_CELoss: 1.8040, stu_CELoss: 2.0268, DMLLoss: 0.3736, 
2022-07-31 07:58:59 - train: epoch 0015, iter [04100, 05004], lr: 0.100000, loss: 3.9895, tea_CELoss: 1.6710, stu_CELoss: 1.8930, DMLLoss: 0.4255, 
2022-07-31 07:59:56 - train: epoch 0015, iter [04200, 05004], lr: 0.100000, loss: 3.8894, tea_CELoss: 1.7048, stu_CELoss: 1.8255, DMLLoss: 0.3591, 
2022-07-31 08:00:53 - train: epoch 0015, iter [04300, 05004], lr: 0.100000, loss: 3.8377, tea_CELoss: 1.6174, stu_CELoss: 1.8560, DMLLoss: 0.3642, 
2022-07-31 08:01:50 - train: epoch 0015, iter [04400, 05004], lr: 0.100000, loss: 4.1162, tea_CELoss: 1.8027, stu_CELoss: 1.9955, DMLLoss: 0.3179, 
2022-07-31 08:02:47 - train: epoch 0015, iter [04500, 05004], lr: 0.100000, loss: 4.1223, tea_CELoss: 1.7986, stu_CELoss: 1.9243, DMLLoss: 0.3994, 
2022-07-31 08:03:44 - train: epoch 0015, iter [04600, 05004], lr: 0.100000, loss: 4.2875, tea_CELoss: 1.8609, stu_CELoss: 2.0363, DMLLoss: 0.3903, 
2022-07-31 08:04:41 - train: epoch 0015, iter [04700, 05004], lr: 0.100000, loss: 4.1640, tea_CELoss: 1.8402, stu_CELoss: 1.9343, DMLLoss: 0.3895, 
2022-07-31 08:05:38 - train: epoch 0015, iter [04800, 05004], lr: 0.100000, loss: 4.3773, tea_CELoss: 1.9104, stu_CELoss: 2.0770, DMLLoss: 0.3899, 
2022-07-31 08:06:36 - train: epoch 0015, iter [04900, 05004], lr: 0.100000, loss: 4.1544, tea_CELoss: 1.7995, stu_CELoss: 1.9420, DMLLoss: 0.4129, 
2022-07-31 08:07:33 - train: epoch 0015, iter [05000, 05004], lr: 0.100000, loss: 4.4222, tea_CELoss: 1.9622, stu_CELoss: 2.0697, DMLLoss: 0.3903, 
2022-07-31 08:07:36 - train: epoch 015, train_loss: 4.1596
2022-07-31 08:10:08 - eval: epoch: 015, tea_acc1: 59.956%, tea_acc5: 83.404%, tea_test_loss: 1.6753, stu_acc1: 58.232%, stu_acc5: 81.980%, stu_test_loss: 1.7862
2022-07-31 08:10:09 - until epoch: 015, tea_best_acc1: 61.560%, stu_best_acc1: 58.232%
2022-07-31 08:10:09 - epoch 016 lr: 0.100000
2022-07-31 08:11:12 - train: epoch 0016, iter [00100, 05004], lr: 0.100000, loss: 3.9550, tea_CELoss: 1.6798, stu_CELoss: 1.8736, DMLLoss: 0.4016, 
2022-07-31 08:12:10 - train: epoch 0016, iter [00200, 05004], lr: 0.100000, loss: 3.6697, tea_CELoss: 1.5404, stu_CELoss: 1.7292, DMLLoss: 0.4000, 
2022-07-31 08:13:08 - train: epoch 0016, iter [00300, 05004], lr: 0.100000, loss: 4.1350, tea_CELoss: 1.7434, stu_CELoss: 1.9627, DMLLoss: 0.4290, 
2022-07-31 08:14:05 - train: epoch 0016, iter [00400, 05004], lr: 0.100000, loss: 4.1255, tea_CELoss: 1.7355, stu_CELoss: 1.9752, DMLLoss: 0.4148, 
2022-07-31 08:15:02 - train: epoch 0016, iter [00500, 05004], lr: 0.100000, loss: 4.0262, tea_CELoss: 1.7189, stu_CELoss: 1.9273, DMLLoss: 0.3800, 
2022-07-31 08:16:00 - train: epoch 0016, iter [00600, 05004], lr: 0.100000, loss: 3.8390, tea_CELoss: 1.6185, stu_CELoss: 1.8188, DMLLoss: 0.4018, 
2022-07-31 08:16:57 - train: epoch 0016, iter [00700, 05004], lr: 0.100000, loss: 3.9165, tea_CELoss: 1.6636, stu_CELoss: 1.8852, DMLLoss: 0.3676, 
2022-07-31 08:17:55 - train: epoch 0016, iter [00800, 05004], lr: 0.100000, loss: 4.0744, tea_CELoss: 1.7727, stu_CELoss: 1.8829, DMLLoss: 0.4188, 
2022-07-31 08:18:53 - train: epoch 0016, iter [00900, 05004], lr: 0.100000, loss: 4.1267, tea_CELoss: 1.7684, stu_CELoss: 1.9941, DMLLoss: 0.3642, 
2022-07-31 08:19:50 - train: epoch 0016, iter [01000, 05004], lr: 0.100000, loss: 4.1889, tea_CELoss: 1.7579, stu_CELoss: 1.9974, DMLLoss: 0.4336, 
2022-07-31 08:20:48 - train: epoch 0016, iter [01100, 05004], lr: 0.100000, loss: 4.1096, tea_CELoss: 1.7681, stu_CELoss: 1.9478, DMLLoss: 0.3938, 
2022-07-31 08:21:46 - train: epoch 0016, iter [01200, 05004], lr: 0.100000, loss: 3.9916, tea_CELoss: 1.6637, stu_CELoss: 1.9087, DMLLoss: 0.4192, 
2022-07-31 08:22:44 - train: epoch 0016, iter [01300, 05004], lr: 0.100000, loss: 4.2338, tea_CELoss: 1.8463, stu_CELoss: 1.9849, DMLLoss: 0.4026, 
2022-07-31 08:23:41 - train: epoch 0016, iter [01400, 05004], lr: 0.100000, loss: 4.0524, tea_CELoss: 1.7421, stu_CELoss: 1.9315, DMLLoss: 0.3788, 
2022-07-31 08:24:39 - train: epoch 0016, iter [01500, 05004], lr: 0.100000, loss: 4.6698, tea_CELoss: 1.9991, stu_CELoss: 2.2741, DMLLoss: 0.3966, 
2022-07-31 08:25:37 - train: epoch 0016, iter [01600, 05004], lr: 0.100000, loss: 4.6357, tea_CELoss: 2.0547, stu_CELoss: 2.1594, DMLLoss: 0.4217, 
2022-07-31 08:26:35 - train: epoch 0016, iter [01700, 05004], lr: 0.100000, loss: 4.1396, tea_CELoss: 1.7531, stu_CELoss: 1.9646, DMLLoss: 0.4219, 
2022-07-31 08:27:32 - train: epoch 0016, iter [01800, 05004], lr: 0.100000, loss: 4.3959, tea_CELoss: 1.9020, stu_CELoss: 2.0894, DMLLoss: 0.4045, 
2022-07-31 08:28:30 - train: epoch 0016, iter [01900, 05004], lr: 0.100000, loss: 4.1137, tea_CELoss: 1.7464, stu_CELoss: 1.9960, DMLLoss: 0.3712, 
2022-07-31 08:29:28 - train: epoch 0016, iter [02000, 05004], lr: 0.100000, loss: 3.2286, tea_CELoss: 1.3598, stu_CELoss: 1.5246, DMLLoss: 0.3442, 
2022-07-31 08:30:26 - train: epoch 0016, iter [02100, 05004], lr: 0.100000, loss: 4.2299, tea_CELoss: 1.8120, stu_CELoss: 2.0180, DMLLoss: 0.3999, 
2022-07-31 08:31:23 - train: epoch 0016, iter [02200, 05004], lr: 0.100000, loss: 4.1410, tea_CELoss: 1.7437, stu_CELoss: 2.0013, DMLLoss: 0.3959, 
2022-07-31 08:32:21 - train: epoch 0016, iter [02300, 05004], lr: 0.100000, loss: 4.2354, tea_CELoss: 1.8223, stu_CELoss: 2.0301, DMLLoss: 0.3830, 
2022-07-31 08:33:19 - train: epoch 0016, iter [02400, 05004], lr: 0.100000, loss: 4.1552, tea_CELoss: 1.7814, stu_CELoss: 1.9500, DMLLoss: 0.4238, 
2022-07-31 08:34:17 - train: epoch 0016, iter [02500, 05004], lr: 0.100000, loss: 4.2017, tea_CELoss: 1.7980, stu_CELoss: 2.0028, DMLLoss: 0.4009, 
2022-07-31 08:35:14 - train: epoch 0016, iter [02600, 05004], lr: 0.100000, loss: 4.3763, tea_CELoss: 1.8818, stu_CELoss: 2.0844, DMLLoss: 0.4101, 
2022-07-31 08:36:12 - train: epoch 0016, iter [02700, 05004], lr: 0.100000, loss: 4.1321, tea_CELoss: 1.8136, stu_CELoss: 1.9247, DMLLoss: 0.3938, 
2022-07-31 08:37:10 - train: epoch 0016, iter [02800, 05004], lr: 0.100000, loss: 3.8102, tea_CELoss: 1.6713, stu_CELoss: 1.7989, DMLLoss: 0.3401, 
2022-07-31 08:38:07 - train: epoch 0016, iter [02900, 05004], lr: 0.100000, loss: 4.0288, tea_CELoss: 1.7287, stu_CELoss: 1.9206, DMLLoss: 0.3795, 
2022-07-31 08:39:05 - train: epoch 0016, iter [03000, 05004], lr: 0.100000, loss: 4.4676, tea_CELoss: 1.8851, stu_CELoss: 2.1457, DMLLoss: 0.4368, 
2022-07-31 08:40:02 - train: epoch 0016, iter [03100, 05004], lr: 0.100000, loss: 4.2891, tea_CELoss: 1.8673, stu_CELoss: 2.0509, DMLLoss: 0.3710, 
2022-07-31 08:41:00 - train: epoch 0016, iter [03200, 05004], lr: 0.100000, loss: 4.2506, tea_CELoss: 1.8155, stu_CELoss: 2.0207, DMLLoss: 0.4145, 
2022-07-31 08:41:57 - train: epoch 0016, iter [03300, 05004], lr: 0.100000, loss: 4.3042, tea_CELoss: 1.8775, stu_CELoss: 2.0550, DMLLoss: 0.3717, 
2022-07-31 08:42:55 - train: epoch 0016, iter [03400, 05004], lr: 0.100000, loss: 4.1852, tea_CELoss: 1.7934, stu_CELoss: 1.9915, DMLLoss: 0.4003, 
2022-07-31 08:43:53 - train: epoch 0016, iter [03500, 05004], lr: 0.100000, loss: 3.9595, tea_CELoss: 1.6862, stu_CELoss: 1.8843, DMLLoss: 0.3890, 
2022-07-31 08:44:50 - train: epoch 0016, iter [03600, 05004], lr: 0.100000, loss: 3.8849, tea_CELoss: 1.6418, stu_CELoss: 1.8524, DMLLoss: 0.3907, 
2022-07-31 08:45:48 - train: epoch 0016, iter [03700, 05004], lr: 0.100000, loss: 4.1009, tea_CELoss: 1.7290, stu_CELoss: 2.0048, DMLLoss: 0.3671, 
2022-07-31 08:46:46 - train: epoch 0016, iter [03800, 05004], lr: 0.100000, loss: 4.6858, tea_CELoss: 2.0911, stu_CELoss: 2.2061, DMLLoss: 0.3886, 
2022-07-31 08:47:44 - train: epoch 0016, iter [03900, 05004], lr: 0.100000, loss: 4.3290, tea_CELoss: 1.8824, stu_CELoss: 2.0589, DMLLoss: 0.3877, 
2022-07-31 08:48:41 - train: epoch 0016, iter [04000, 05004], lr: 0.100000, loss: 4.2417, tea_CELoss: 1.8322, stu_CELoss: 2.0248, DMLLoss: 0.3847, 
2022-07-31 08:49:39 - train: epoch 0016, iter [04100, 05004], lr: 0.100000, loss: 3.8790, tea_CELoss: 1.6261, stu_CELoss: 1.8800, DMLLoss: 0.3729, 
2022-07-31 08:50:36 - train: epoch 0016, iter [04200, 05004], lr: 0.100000, loss: 3.9643, tea_CELoss: 1.6546, stu_CELoss: 1.9316, DMLLoss: 0.3780, 
2022-07-31 08:51:34 - train: epoch 0016, iter [04300, 05004], lr: 0.100000, loss: 3.7632, tea_CELoss: 1.6173, stu_CELoss: 1.7737, DMLLoss: 0.3721, 
2022-07-31 08:52:32 - train: epoch 0016, iter [04400, 05004], lr: 0.100000, loss: 4.1018, tea_CELoss: 1.7484, stu_CELoss: 1.9266, DMLLoss: 0.4268, 
2022-07-31 08:53:29 - train: epoch 0016, iter [04500, 05004], lr: 0.100000, loss: 4.3223, tea_CELoss: 1.8980, stu_CELoss: 2.0661, DMLLoss: 0.3582, 
2022-07-31 08:54:27 - train: epoch 0016, iter [04600, 05004], lr: 0.100000, loss: 3.8173, tea_CELoss: 1.5933, stu_CELoss: 1.8127, DMLLoss: 0.4113, 
2022-07-31 08:55:25 - train: epoch 0016, iter [04700, 05004], lr: 0.100000, loss: 4.6031, tea_CELoss: 2.0074, stu_CELoss: 2.2076, DMLLoss: 0.3881, 
2022-07-31 08:56:22 - train: epoch 0016, iter [04800, 05004], lr: 0.100000, loss: 4.1244, tea_CELoss: 1.7906, stu_CELoss: 1.9568, DMLLoss: 0.3770, 
2022-07-31 08:57:20 - train: epoch 0016, iter [04900, 05004], lr: 0.100000, loss: 4.2028, tea_CELoss: 1.7315, stu_CELoss: 2.0473, DMLLoss: 0.4241, 
2022-07-31 08:58:18 - train: epoch 0016, iter [05000, 05004], lr: 0.100000, loss: 4.2771, tea_CELoss: 1.8807, stu_CELoss: 2.0049, DMLLoss: 0.3915, 
2022-07-31 08:58:21 - train: epoch 016, train_loss: 4.1358
2022-07-31 09:00:53 - eval: epoch: 016, tea_acc1: 62.884%, tea_acc5: 85.530%, tea_test_loss: 1.5384, stu_acc1: 58.500%, stu_acc5: 82.458%, stu_test_loss: 1.7425
2022-07-31 09:00:55 - until epoch: 016, tea_best_acc1: 62.884%, stu_best_acc1: 58.500%
2022-07-31 09:00:55 - epoch 017 lr: 0.100000
2022-07-31 09:01:58 - train: epoch 0017, iter [00100, 05004], lr: 0.100000, loss: 4.1384, tea_CELoss: 1.7899, stu_CELoss: 1.9681, DMLLoss: 0.3804, 
2022-07-31 09:02:55 - train: epoch 0017, iter [00200, 05004], lr: 0.100000, loss: 4.3316, tea_CELoss: 1.8777, stu_CELoss: 2.0477, DMLLoss: 0.4061, 
2022-07-31 09:03:53 - train: epoch 0017, iter [00300, 05004], lr: 0.100000, loss: 4.5976, tea_CELoss: 1.9587, stu_CELoss: 2.2434, DMLLoss: 0.3955, 
2022-07-31 09:04:50 - train: epoch 0017, iter [00400, 05004], lr: 0.100000, loss: 3.6150, tea_CELoss: 1.4924, stu_CELoss: 1.7168, DMLLoss: 0.4058, 
2022-07-31 09:05:48 - train: epoch 0017, iter [00500, 05004], lr: 0.100000, loss: 4.0764, tea_CELoss: 1.7829, stu_CELoss: 1.9330, DMLLoss: 0.3606, 
2022-07-31 09:06:45 - train: epoch 0017, iter [00600, 05004], lr: 0.100000, loss: 4.4471, tea_CELoss: 1.8922, stu_CELoss: 2.1591, DMLLoss: 0.3959, 
2022-07-31 09:07:43 - train: epoch 0017, iter [00700, 05004], lr: 0.100000, loss: 4.0457, tea_CELoss: 1.7452, stu_CELoss: 1.9129, DMLLoss: 0.3877, 
2022-07-31 09:08:40 - train: epoch 0017, iter [00800, 05004], lr: 0.100000, loss: 3.9952, tea_CELoss: 1.6923, stu_CELoss: 1.9088, DMLLoss: 0.3940, 
2022-07-31 09:09:38 - train: epoch 0017, iter [00900, 05004], lr: 0.100000, loss: 3.9778, tea_CELoss: 1.7089, stu_CELoss: 1.9050, DMLLoss: 0.3639, 
2022-07-31 09:10:35 - train: epoch 0017, iter [01000, 05004], lr: 0.100000, loss: 4.2585, tea_CELoss: 1.8325, stu_CELoss: 2.0403, DMLLoss: 0.3857, 
2022-07-31 09:11:33 - train: epoch 0017, iter [01100, 05004], lr: 0.100000, loss: 4.5286, tea_CELoss: 2.0331, stu_CELoss: 2.1335, DMLLoss: 0.3621, 
2022-07-31 09:12:30 - train: epoch 0017, iter [01200, 05004], lr: 0.100000, loss: 3.8404, tea_CELoss: 1.5784, stu_CELoss: 1.8621, DMLLoss: 0.3998, 
2022-07-31 09:13:28 - train: epoch 0017, iter [01300, 05004], lr: 0.100000, loss: 4.2811, tea_CELoss: 1.8414, stu_CELoss: 2.0682, DMLLoss: 0.3715, 
2022-07-31 09:14:25 - train: epoch 0017, iter [01400, 05004], lr: 0.100000, loss: 4.2199, tea_CELoss: 1.7979, stu_CELoss: 2.0163, DMLLoss: 0.4057, 
2022-07-31 09:15:23 - train: epoch 0017, iter [01500, 05004], lr: 0.100000, loss: 3.8250, tea_CELoss: 1.6594, stu_CELoss: 1.7769, DMLLoss: 0.3887, 
2022-07-31 09:16:21 - train: epoch 0017, iter [01600, 05004], lr: 0.100000, loss: 4.1899, tea_CELoss: 1.7896, stu_CELoss: 2.0161, DMLLoss: 0.3841, 
2022-07-31 09:17:19 - train: epoch 0017, iter [01700, 05004], lr: 0.100000, loss: 3.8174, tea_CELoss: 1.6198, stu_CELoss: 1.8319, DMLLoss: 0.3657, 
2022-07-31 09:18:16 - train: epoch 0017, iter [01800, 05004], lr: 0.100000, loss: 4.2488, tea_CELoss: 1.8261, stu_CELoss: 2.0234, DMLLoss: 0.3994, 
2022-07-31 09:19:14 - train: epoch 0017, iter [01900, 05004], lr: 0.100000, loss: 3.9643, tea_CELoss: 1.6423, stu_CELoss: 1.9160, DMLLoss: 0.4060, 
2022-07-31 09:20:12 - train: epoch 0017, iter [02000, 05004], lr: 0.100000, loss: 4.2614, tea_CELoss: 1.8807, stu_CELoss: 2.0223, DMLLoss: 0.3584, 
2022-07-31 09:21:10 - train: epoch 0017, iter [02100, 05004], lr: 0.100000, loss: 4.0213, tea_CELoss: 1.7143, stu_CELoss: 1.9092, DMLLoss: 0.3978, 
2022-07-31 09:22:07 - train: epoch 0017, iter [02200, 05004], lr: 0.100000, loss: 3.6754, tea_CELoss: 1.5547, stu_CELoss: 1.7475, DMLLoss: 0.3732, 
2022-07-31 09:23:05 - train: epoch 0017, iter [02300, 05004], lr: 0.100000, loss: 4.1978, tea_CELoss: 1.8119, stu_CELoss: 2.0080, DMLLoss: 0.3779, 
2022-07-31 09:24:02 - train: epoch 0017, iter [02400, 05004], lr: 0.100000, loss: 4.2506, tea_CELoss: 1.8628, stu_CELoss: 2.0024, DMLLoss: 0.3853, 
2022-07-31 09:25:00 - train: epoch 0017, iter [02500, 05004], lr: 0.100000, loss: 4.3448, tea_CELoss: 1.8689, stu_CELoss: 2.0766, DMLLoss: 0.3993, 
2022-07-31 09:25:58 - train: epoch 0017, iter [02600, 05004], lr: 0.100000, loss: 4.0710, tea_CELoss: 1.6939, stu_CELoss: 1.9829, DMLLoss: 0.3942, 
2022-07-31 09:26:55 - train: epoch 0017, iter [02700, 05004], lr: 0.100000, loss: 4.1214, tea_CELoss: 1.7245, stu_CELoss: 1.9995, DMLLoss: 0.3975, 
2022-07-31 09:27:52 - train: epoch 0017, iter [02800, 05004], lr: 0.100000, loss: 3.9898, tea_CELoss: 1.7372, stu_CELoss: 1.8963, DMLLoss: 0.3563, 
2022-07-31 09:28:50 - train: epoch 0017, iter [02900, 05004], lr: 0.100000, loss: 4.6895, tea_CELoss: 2.0886, stu_CELoss: 2.1867, DMLLoss: 0.4142, 
2022-07-31 09:29:47 - train: epoch 0017, iter [03000, 05004], lr: 0.100000, loss: 4.0677, tea_CELoss: 1.7274, stu_CELoss: 1.9502, DMLLoss: 0.3902, 
2022-07-31 09:30:45 - train: epoch 0017, iter [03100, 05004], lr: 0.100000, loss: 4.3876, tea_CELoss: 1.8729, stu_CELoss: 2.0604, DMLLoss: 0.4544, 
2022-07-31 09:31:42 - train: epoch 0017, iter [03200, 05004], lr: 0.100000, loss: 3.7799, tea_CELoss: 1.6041, stu_CELoss: 1.7964, DMLLoss: 0.3795, 
2022-07-31 09:32:40 - train: epoch 0017, iter [03300, 05004], lr: 0.100000, loss: 4.3616, tea_CELoss: 1.9259, stu_CELoss: 2.0940, DMLLoss: 0.3417, 
2022-07-31 09:33:38 - train: epoch 0017, iter [03400, 05004], lr: 0.100000, loss: 3.8670, tea_CELoss: 1.7093, stu_CELoss: 1.8116, DMLLoss: 0.3461, 
2022-07-31 09:34:35 - train: epoch 0017, iter [03500, 05004], lr: 0.100000, loss: 4.1900, tea_CELoss: 1.7992, stu_CELoss: 1.9902, DMLLoss: 0.4005, 
2022-07-31 09:35:33 - train: epoch 0017, iter [03600, 05004], lr: 0.100000, loss: 4.2989, tea_CELoss: 1.8250, stu_CELoss: 2.0715, DMLLoss: 0.4023, 
2022-07-31 09:36:31 - train: epoch 0017, iter [03700, 05004], lr: 0.100000, loss: 3.8533, tea_CELoss: 1.6277, stu_CELoss: 1.8372, DMLLoss: 0.3885, 
2022-07-31 09:37:28 - train: epoch 0017, iter [03800, 05004], lr: 0.100000, loss: 4.6948, tea_CELoss: 2.0042, stu_CELoss: 2.2346, DMLLoss: 0.4560, 
2022-07-31 09:38:26 - train: epoch 0017, iter [03900, 05004], lr: 0.100000, loss: 3.8507, tea_CELoss: 1.6109, stu_CELoss: 1.8555, DMLLoss: 0.3843, 
2022-07-31 09:39:25 - train: epoch 0017, iter [04000, 05004], lr: 0.100000, loss: 4.1988, tea_CELoss: 1.8735, stu_CELoss: 1.9878, DMLLoss: 0.3375, 
2022-07-31 09:40:23 - train: epoch 0017, iter [04100, 05004], lr: 0.100000, loss: 4.2931, tea_CELoss: 1.9031, stu_CELoss: 2.0071, DMLLoss: 0.3829, 
2022-07-31 09:41:21 - train: epoch 0017, iter [04200, 05004], lr: 0.100000, loss: 4.0806, tea_CELoss: 1.7619, stu_CELoss: 1.9275, DMLLoss: 0.3911, 
2022-07-31 09:42:19 - train: epoch 0017, iter [04300, 05004], lr: 0.100000, loss: 3.7721, tea_CELoss: 1.5808, stu_CELoss: 1.8054, DMLLoss: 0.3858, 
2022-07-31 09:43:17 - train: epoch 0017, iter [04400, 05004], lr: 0.100000, loss: 4.3329, tea_CELoss: 1.8954, stu_CELoss: 2.0256, DMLLoss: 0.4119, 
2022-07-31 09:44:15 - train: epoch 0017, iter [04500, 05004], lr: 0.100000, loss: 4.2922, tea_CELoss: 1.8640, stu_CELoss: 2.0699, DMLLoss: 0.3583, 
2022-07-31 09:45:13 - train: epoch 0017, iter [04600, 05004], lr: 0.100000, loss: 3.8831, tea_CELoss: 1.6354, stu_CELoss: 1.8819, DMLLoss: 0.3658, 
2022-07-31 09:46:11 - train: epoch 0017, iter [04700, 05004], lr: 0.100000, loss: 4.5046, tea_CELoss: 1.9471, stu_CELoss: 2.1601, DMLLoss: 0.3974, 
2022-07-31 09:47:09 - train: epoch 0017, iter [04800, 05004], lr: 0.100000, loss: 4.2510, tea_CELoss: 1.8578, stu_CELoss: 1.9964, DMLLoss: 0.3967, 
2022-07-31 09:48:07 - train: epoch 0017, iter [04900, 05004], lr: 0.100000, loss: 4.2498, tea_CELoss: 1.8171, stu_CELoss: 2.0457, DMLLoss: 0.3870, 
2022-07-31 09:49:05 - train: epoch 0017, iter [05000, 05004], lr: 0.100000, loss: 4.1109, tea_CELoss: 1.7504, stu_CELoss: 1.9774, DMLLoss: 0.3831, 
2022-07-31 09:49:08 - train: epoch 017, train_loss: 4.1197
2022-07-31 09:51:38 - eval: epoch: 017, tea_acc1: 62.562%, tea_acc5: 85.074%, tea_test_loss: 1.5659, stu_acc1: 59.012%, stu_acc5: 82.672%, stu_test_loss: 1.7228
2022-07-31 09:51:39 - until epoch: 017, tea_best_acc1: 62.884%, stu_best_acc1: 59.012%
2022-07-31 09:51:39 - epoch 018 lr: 0.100000
2022-07-31 09:52:43 - train: epoch 0018, iter [00100, 05004], lr: 0.100000, loss: 3.9606, tea_CELoss: 1.6747, stu_CELoss: 1.8333, DMLLoss: 0.4526, 
2022-07-31 09:53:41 - train: epoch 0018, iter [00200, 05004], lr: 0.100000, loss: 4.5267, tea_CELoss: 1.9525, stu_CELoss: 2.1744, DMLLoss: 0.3998, 
2022-07-31 09:54:39 - train: epoch 0018, iter [00300, 05004], lr: 0.100000, loss: 4.2834, tea_CELoss: 1.7512, stu_CELoss: 2.0655, DMLLoss: 0.4667, 
2022-07-31 09:55:37 - train: epoch 0018, iter [00400, 05004], lr: 0.100000, loss: 4.3363, tea_CELoss: 1.8166, stu_CELoss: 2.0689, DMLLoss: 0.4508, 
2022-07-31 09:56:35 - train: epoch 0018, iter [00500, 05004], lr: 0.100000, loss: 4.0577, tea_CELoss: 1.7371, stu_CELoss: 1.9631, DMLLoss: 0.3575, 
2022-07-31 09:57:33 - train: epoch 0018, iter [00600, 05004], lr: 0.100000, loss: 4.1079, tea_CELoss: 1.8031, stu_CELoss: 1.9484, DMLLoss: 0.3564, 
2022-07-31 09:58:30 - train: epoch 0018, iter [00700, 05004], lr: 0.100000, loss: 3.6509, tea_CELoss: 1.5918, stu_CELoss: 1.6693, DMLLoss: 0.3898, 
2022-07-31 09:59:28 - train: epoch 0018, iter [00800, 05004], lr: 0.100000, loss: 4.1592, tea_CELoss: 1.7745, stu_CELoss: 1.9957, DMLLoss: 0.3890, 
2022-07-31 10:00:26 - train: epoch 0018, iter [00900, 05004], lr: 0.100000, loss: 4.6216, tea_CELoss: 2.0276, stu_CELoss: 2.2060, DMLLoss: 0.3880, 
2022-07-31 10:01:24 - train: epoch 0018, iter [01000, 05004], lr: 0.100000, loss: 3.7835, tea_CELoss: 1.6405, stu_CELoss: 1.7715, DMLLoss: 0.3715, 
2022-07-31 10:02:22 - train: epoch 0018, iter [01100, 05004], lr: 0.100000, loss: 4.3234, tea_CELoss: 1.9027, stu_CELoss: 2.0100, DMLLoss: 0.4106, 
2022-07-31 10:03:20 - train: epoch 0018, iter [01200, 05004], lr: 0.100000, loss: 3.8373, tea_CELoss: 1.5874, stu_CELoss: 1.8551, DMLLoss: 0.3947, 
2022-07-31 10:04:18 - train: epoch 0018, iter [01300, 05004], lr: 0.100000, loss: 4.3579, tea_CELoss: 1.8859, stu_CELoss: 2.0820, DMLLoss: 0.3900, 
2022-07-31 10:05:16 - train: epoch 0018, iter [01400, 05004], lr: 0.100000, loss: 4.2930, tea_CELoss: 1.8288, stu_CELoss: 2.0536, DMLLoss: 0.4107, 
2022-07-31 10:06:14 - train: epoch 0018, iter [01500, 05004], lr: 0.100000, loss: 4.4726, tea_CELoss: 1.8933, stu_CELoss: 2.1571, DMLLoss: 0.4221, 
2022-07-31 10:07:12 - train: epoch 0018, iter [01600, 05004], lr: 0.100000, loss: 3.9830, tea_CELoss: 1.7549, stu_CELoss: 1.8331, DMLLoss: 0.3950, 
2022-07-31 10:08:10 - train: epoch 0018, iter [01700, 05004], lr: 0.100000, loss: 4.2713, tea_CELoss: 1.8551, stu_CELoss: 2.0338, DMLLoss: 0.3824, 
2022-07-31 10:09:08 - train: epoch 0018, iter [01800, 05004], lr: 0.100000, loss: 3.8303, tea_CELoss: 1.5872, stu_CELoss: 1.8352, DMLLoss: 0.4079, 
2022-07-31 10:10:06 - train: epoch 0018, iter [01900, 05004], lr: 0.100000, loss: 4.1246, tea_CELoss: 1.7679, stu_CELoss: 1.9679, DMLLoss: 0.3887, 
2022-07-31 10:11:04 - train: epoch 0018, iter [02000, 05004], lr: 0.100000, loss: 4.7562, tea_CELoss: 2.0551, stu_CELoss: 2.2662, DMLLoss: 0.4350, 
2022-07-31 10:12:02 - train: epoch 0018, iter [02100, 05004], lr: 0.100000, loss: 4.5975, tea_CELoss: 1.9971, stu_CELoss: 2.1830, DMLLoss: 0.4175, 
2022-07-31 10:13:00 - train: epoch 0018, iter [02200, 05004], lr: 0.100000, loss: 4.1587, tea_CELoss: 1.7901, stu_CELoss: 1.9473, DMLLoss: 0.4213, 
2022-07-31 10:13:58 - train: epoch 0018, iter [02300, 05004], lr: 0.100000, loss: 4.0868, tea_CELoss: 1.7473, stu_CELoss: 1.9352, DMLLoss: 0.4043, 
2022-07-31 10:14:56 - train: epoch 0018, iter [02400, 05004], lr: 0.100000, loss: 4.0123, tea_CELoss: 1.7774, stu_CELoss: 1.8983, DMLLoss: 0.3366, 
2022-07-31 10:15:54 - train: epoch 0018, iter [02500, 05004], lr: 0.100000, loss: 3.4991, tea_CELoss: 1.4598, stu_CELoss: 1.6724, DMLLoss: 0.3670, 
2022-07-31 10:16:52 - train: epoch 0018, iter [02600, 05004], lr: 0.100000, loss: 3.8819, tea_CELoss: 1.6760, stu_CELoss: 1.8422, DMLLoss: 0.3637, 
2022-07-31 10:17:50 - train: epoch 0018, iter [02700, 05004], lr: 0.100000, loss: 4.3424, tea_CELoss: 1.9038, stu_CELoss: 2.0451, DMLLoss: 0.3935, 
2022-07-31 10:18:48 - train: epoch 0018, iter [02800, 05004], lr: 0.100000, loss: 3.8058, tea_CELoss: 1.6642, stu_CELoss: 1.7739, DMLLoss: 0.3678, 
2022-07-31 10:19:46 - train: epoch 0018, iter [02900, 05004], lr: 0.100000, loss: 4.1397, tea_CELoss: 1.7918, stu_CELoss: 1.9637, DMLLoss: 0.3841, 
2022-07-31 10:20:44 - train: epoch 0018, iter [03000, 05004], lr: 0.100000, loss: 4.0398, tea_CELoss: 1.6867, stu_CELoss: 1.9640, DMLLoss: 0.3891, 
2022-07-31 10:21:42 - train: epoch 0018, iter [03100, 05004], lr: 0.100000, loss: 4.8592, tea_CELoss: 2.1590, stu_CELoss: 2.3495, DMLLoss: 0.3507, 
2022-07-31 10:22:40 - train: epoch 0018, iter [03200, 05004], lr: 0.100000, loss: 4.1230, tea_CELoss: 1.7515, stu_CELoss: 1.9903, DMLLoss: 0.3813, 
2022-07-31 10:23:38 - train: epoch 0018, iter [03300, 05004], lr: 0.100000, loss: 3.9774, tea_CELoss: 1.6987, stu_CELoss: 1.8903, DMLLoss: 0.3884, 
2022-07-31 10:24:36 - train: epoch 0018, iter [03400, 05004], lr: 0.100000, loss: 4.4183, tea_CELoss: 1.9176, stu_CELoss: 2.1240, DMLLoss: 0.3766, 
2022-07-31 10:25:34 - train: epoch 0018, iter [03500, 05004], lr: 0.100000, loss: 4.3514, tea_CELoss: 1.8768, stu_CELoss: 2.0498, DMLLoss: 0.4249, 
2022-07-31 10:26:32 - train: epoch 0018, iter [03600, 05004], lr: 0.100000, loss: 4.1034, tea_CELoss: 1.7430, stu_CELoss: 1.9738, DMLLoss: 0.3866, 
2022-07-31 10:27:29 - train: epoch 0018, iter [03700, 05004], lr: 0.100000, loss: 4.4569, tea_CELoss: 1.8988, stu_CELoss: 2.1079, DMLLoss: 0.4502, 
2022-07-31 10:28:27 - train: epoch 0018, iter [03800, 05004], lr: 0.100000, loss: 4.4328, tea_CELoss: 1.9384, stu_CELoss: 2.1159, DMLLoss: 0.3785, 
2022-07-31 10:29:25 - train: epoch 0018, iter [03900, 05004], lr: 0.100000, loss: 4.4962, tea_CELoss: 1.9378, stu_CELoss: 2.1450, DMLLoss: 0.4133, 
2022-07-31 10:30:23 - train: epoch 0018, iter [04000, 05004], lr: 0.100000, loss: 4.3381, tea_CELoss: 1.8835, stu_CELoss: 2.0738, DMLLoss: 0.3808, 
2022-07-31 10:31:21 - train: epoch 0018, iter [04100, 05004], lr: 0.100000, loss: 4.5259, tea_CELoss: 1.9938, stu_CELoss: 2.1485, DMLLoss: 0.3835, 
2022-07-31 10:32:20 - train: epoch 0018, iter [04200, 05004], lr: 0.100000, loss: 4.0782, tea_CELoss: 1.7279, stu_CELoss: 1.9967, DMLLoss: 0.3536, 
2022-07-31 10:33:18 - train: epoch 0018, iter [04300, 05004], lr: 0.100000, loss: 4.4410, tea_CELoss: 1.9330, stu_CELoss: 2.1301, DMLLoss: 0.3779, 
2022-07-31 10:34:15 - train: epoch 0018, iter [04400, 05004], lr: 0.100000, loss: 4.0324, tea_CELoss: 1.7318, stu_CELoss: 1.9326, DMLLoss: 0.3680, 
2022-07-31 10:35:13 - train: epoch 0018, iter [04500, 05004], lr: 0.100000, loss: 4.2795, tea_CELoss: 1.8580, stu_CELoss: 2.0273, DMLLoss: 0.3941, 
2022-07-31 10:36:11 - train: epoch 0018, iter [04600, 05004], lr: 0.100000, loss: 4.0466, tea_CELoss: 1.7731, stu_CELoss: 1.9126, DMLLoss: 0.3609, 
2022-07-31 10:37:08 - train: epoch 0018, iter [04700, 05004], lr: 0.100000, loss: 4.3353, tea_CELoss: 1.9275, stu_CELoss: 2.0050, DMLLoss: 0.4028, 
2022-07-31 10:38:06 - train: epoch 0018, iter [04800, 05004], lr: 0.100000, loss: 4.1011, tea_CELoss: 1.7545, stu_CELoss: 1.9371, DMLLoss: 0.4095, 
2022-07-31 10:39:04 - train: epoch 0018, iter [04900, 05004], lr: 0.100000, loss: 3.9747, tea_CELoss: 1.6321, stu_CELoss: 1.9295, DMLLoss: 0.4130, 
2022-07-31 10:40:01 - train: epoch 0018, iter [05000, 05004], lr: 0.100000, loss: 4.3508, tea_CELoss: 1.9019, stu_CELoss: 2.0692, DMLLoss: 0.3797, 
2022-07-31 10:40:04 - train: epoch 018, train_loss: 4.0996
2022-07-31 10:42:36 - eval: epoch: 018, tea_acc1: 63.004%, tea_acc5: 85.796%, tea_test_loss: 1.5169, stu_acc1: 58.560%, stu_acc5: 82.238%, stu_test_loss: 1.7506
2022-07-31 10:42:37 - until epoch: 018, tea_best_acc1: 63.004%, stu_best_acc1: 59.012%
2022-07-31 10:42:37 - epoch 019 lr: 0.100000
2022-07-31 10:43:42 - train: epoch 0019, iter [00100, 05004], lr: 0.100000, loss: 3.4990, tea_CELoss: 1.4594, stu_CELoss: 1.6759, DMLLoss: 0.3637, 
2022-07-31 10:44:40 - train: epoch 0019, iter [00200, 05004], lr: 0.100000, loss: 3.8675, tea_CELoss: 1.6043, stu_CELoss: 1.8239, DMLLoss: 0.4394, 
2022-07-31 10:45:38 - train: epoch 0019, iter [00300, 05004], lr: 0.100000, loss: 4.3501, tea_CELoss: 1.8780, stu_CELoss: 2.0805, DMLLoss: 0.3916, 
2022-07-31 10:46:36 - train: epoch 0019, iter [00400, 05004], lr: 0.100000, loss: 4.2310, tea_CELoss: 1.8289, stu_CELoss: 2.0126, DMLLoss: 0.3895, 
2022-07-31 10:47:35 - train: epoch 0019, iter [00500, 05004], lr: 0.100000, loss: 3.6803, tea_CELoss: 1.5861, stu_CELoss: 1.7465, DMLLoss: 0.3477, 
2022-07-31 10:48:33 - train: epoch 0019, iter [00600, 05004], lr: 0.100000, loss: 4.3099, tea_CELoss: 1.8490, stu_CELoss: 2.0547, DMLLoss: 0.4062, 
2022-07-31 10:49:31 - train: epoch 0019, iter [00700, 05004], lr: 0.100000, loss: 4.0422, tea_CELoss: 1.7514, stu_CELoss: 1.8762, DMLLoss: 0.4146, 
2022-07-31 10:50:29 - train: epoch 0019, iter [00800, 05004], lr: 0.100000, loss: 4.2221, tea_CELoss: 1.8370, stu_CELoss: 1.9725, DMLLoss: 0.4126, 
2022-07-31 10:51:28 - train: epoch 0019, iter [00900, 05004], lr: 0.100000, loss: 3.9392, tea_CELoss: 1.6912, stu_CELoss: 1.8908, DMLLoss: 0.3573, 
2022-07-31 10:52:26 - train: epoch 0019, iter [01000, 05004], lr: 0.100000, loss: 4.3960, tea_CELoss: 1.9376, stu_CELoss: 2.0849, DMLLoss: 0.3735, 
2022-07-31 10:53:24 - train: epoch 0019, iter [01100, 05004], lr: 0.100000, loss: 4.0266, tea_CELoss: 1.7400, stu_CELoss: 1.8887, DMLLoss: 0.3979, 
2022-07-31 10:54:22 - train: epoch 0019, iter [01200, 05004], lr: 0.100000, loss: 4.2289, tea_CELoss: 1.8344, stu_CELoss: 2.0073, DMLLoss: 0.3872, 
2022-07-31 10:55:21 - train: epoch 0019, iter [01300, 05004], lr: 0.100000, loss: 4.4424, tea_CELoss: 1.9667, stu_CELoss: 2.0724, DMLLoss: 0.4033, 
2022-07-31 10:56:19 - train: epoch 0019, iter [01400, 05004], lr: 0.100000, loss: 3.8207, tea_CELoss: 1.6527, stu_CELoss: 1.8229, DMLLoss: 0.3451, 
2022-07-31 10:57:17 - train: epoch 0019, iter [01500, 05004], lr: 0.100000, loss: 4.3303, tea_CELoss: 1.8935, stu_CELoss: 2.0621, DMLLoss: 0.3747, 
2022-07-31 10:58:15 - train: epoch 0019, iter [01600, 05004], lr: 0.100000, loss: 3.7866, tea_CELoss: 1.5404, stu_CELoss: 1.8059, DMLLoss: 0.4403, 
2022-07-31 10:59:14 - train: epoch 0019, iter [01700, 05004], lr: 0.100000, loss: 4.4250, tea_CELoss: 1.9123, stu_CELoss: 2.1129, DMLLoss: 0.3998, 
2022-07-31 11:00:12 - train: epoch 0019, iter [01800, 05004], lr: 0.100000, loss: 3.9207, tea_CELoss: 1.6670, stu_CELoss: 1.8456, DMLLoss: 0.4081, 
2022-07-31 11:01:10 - train: epoch 0019, iter [01900, 05004], lr: 0.100000, loss: 4.2782, tea_CELoss: 1.8658, stu_CELoss: 2.0355, DMLLoss: 0.3769, 
2022-07-31 11:02:08 - train: epoch 0019, iter [02000, 05004], lr: 0.100000, loss: 3.8383, tea_CELoss: 1.6607, stu_CELoss: 1.7954, DMLLoss: 0.3822, 
2022-07-31 11:03:06 - train: epoch 0019, iter [02100, 05004], lr: 0.100000, loss: 4.1757, tea_CELoss: 1.8200, stu_CELoss: 1.9585, DMLLoss: 0.3972, 
2022-07-31 11:04:05 - train: epoch 0019, iter [02200, 05004], lr: 0.100000, loss: 4.2798, tea_CELoss: 1.8233, stu_CELoss: 2.0851, DMLLoss: 0.3714, 
2022-07-31 11:05:03 - train: epoch 0019, iter [02300, 05004], lr: 0.100000, loss: 4.1857, tea_CELoss: 1.8278, stu_CELoss: 1.9180, DMLLoss: 0.4400, 
2022-07-31 11:06:02 - train: epoch 0019, iter [02400, 05004], lr: 0.100000, loss: 4.4518, tea_CELoss: 1.9019, stu_CELoss: 2.1277, DMLLoss: 0.4222, 
2022-07-31 11:07:00 - train: epoch 0019, iter [02500, 05004], lr: 0.100000, loss: 4.3322, tea_CELoss: 1.8961, stu_CELoss: 2.0286, DMLLoss: 0.4075, 
2022-07-31 11:07:59 - train: epoch 0019, iter [02600, 05004], lr: 0.100000, loss: 3.8641, tea_CELoss: 1.6842, stu_CELoss: 1.8161, DMLLoss: 0.3638, 
2022-07-31 11:08:58 - train: epoch 0019, iter [02700, 05004], lr: 0.100000, loss: 4.2573, tea_CELoss: 1.7887, stu_CELoss: 2.0507, DMLLoss: 0.4179, 
2022-07-31 11:09:56 - train: epoch 0019, iter [02800, 05004], lr: 0.100000, loss: 3.8454, tea_CELoss: 1.6395, stu_CELoss: 1.8171, DMLLoss: 0.3888, 
2022-07-31 11:10:55 - train: epoch 0019, iter [02900, 05004], lr: 0.100000, loss: 4.2060, tea_CELoss: 1.8191, stu_CELoss: 1.9792, DMLLoss: 0.4077, 
2022-07-31 11:11:53 - train: epoch 0019, iter [03000, 05004], lr: 0.100000, loss: 4.6878, tea_CELoss: 2.0171, stu_CELoss: 2.2287, DMLLoss: 0.4420, 
2022-07-31 11:12:51 - train: epoch 0019, iter [03100, 05004], lr: 0.100000, loss: 4.0690, tea_CELoss: 1.7914, stu_CELoss: 1.8958, DMLLoss: 0.3818, 
2022-07-31 11:13:48 - train: epoch 0019, iter [03200, 05004], lr: 0.100000, loss: 3.8493, tea_CELoss: 1.6740, stu_CELoss: 1.7971, DMLLoss: 0.3781, 
2022-07-31 11:14:46 - train: epoch 0019, iter [03300, 05004], lr: 0.100000, loss: 4.1489, tea_CELoss: 1.7481, stu_CELoss: 2.0033, DMLLoss: 0.3975, 
2022-07-31 11:15:45 - train: epoch 0019, iter [03400, 05004], lr: 0.100000, loss: 3.9534, tea_CELoss: 1.6749, stu_CELoss: 1.8685, DMLLoss: 0.4101, 
2022-07-31 11:16:43 - train: epoch 0019, iter [03500, 05004], lr: 0.100000, loss: 4.5033, tea_CELoss: 1.9550, stu_CELoss: 2.1466, DMLLoss: 0.4018, 
2022-07-31 11:17:41 - train: epoch 0019, iter [03600, 05004], lr: 0.100000, loss: 3.5915, tea_CELoss: 1.5122, stu_CELoss: 1.6998, DMLLoss: 0.3795, 
2022-07-31 11:18:39 - train: epoch 0019, iter [03700, 05004], lr: 0.100000, loss: 4.1323, tea_CELoss: 1.8388, stu_CELoss: 1.9384, DMLLoss: 0.3550, 
2022-07-31 11:19:37 - train: epoch 0019, iter [03800, 05004], lr: 0.100000, loss: 4.3469, tea_CELoss: 1.8405, stu_CELoss: 2.1051, DMLLoss: 0.4013, 
2022-07-31 11:20:35 - train: epoch 0019, iter [03900, 05004], lr: 0.100000, loss: 4.0045, tea_CELoss: 1.8019, stu_CELoss: 1.8524, DMLLoss: 0.3502, 
2022-07-31 11:21:34 - train: epoch 0019, iter [04000, 05004], lr: 0.100000, loss: 4.1421, tea_CELoss: 1.8581, stu_CELoss: 1.9452, DMLLoss: 0.3389, 
2022-07-31 11:22:32 - train: epoch 0019, iter [04100, 05004], lr: 0.100000, loss: 4.4981, tea_CELoss: 1.9838, stu_CELoss: 2.1484, DMLLoss: 0.3659, 
2022-07-31 11:23:31 - train: epoch 0019, iter [04200, 05004], lr: 0.100000, loss: 3.9794, tea_CELoss: 1.6694, stu_CELoss: 1.9187, DMLLoss: 0.3913, 
2022-07-31 11:24:29 - train: epoch 0019, iter [04300, 05004], lr: 0.100000, loss: 4.0263, tea_CELoss: 1.7384, stu_CELoss: 1.9423, DMLLoss: 0.3455, 
2022-07-31 11:25:27 - train: epoch 0019, iter [04400, 05004], lr: 0.100000, loss: 4.4212, tea_CELoss: 1.8848, stu_CELoss: 2.1210, DMLLoss: 0.4153, 
2022-07-31 11:26:26 - train: epoch 0019, iter [04500, 05004], lr: 0.100000, loss: 4.7474, tea_CELoss: 2.1193, stu_CELoss: 2.2337, DMLLoss: 0.3944, 
2022-07-31 11:27:23 - train: epoch 0019, iter [04600, 05004], lr: 0.100000, loss: 3.9518, tea_CELoss: 1.6677, stu_CELoss: 1.8903, DMLLoss: 0.3938, 
2022-07-31 11:28:21 - train: epoch 0019, iter [04700, 05004], lr: 0.100000, loss: 4.0370, tea_CELoss: 1.7556, stu_CELoss: 1.8871, DMLLoss: 0.3943, 
2022-07-31 11:29:19 - train: epoch 0019, iter [04800, 05004], lr: 0.100000, loss: 4.2283, tea_CELoss: 1.8695, stu_CELoss: 1.9941, DMLLoss: 0.3646, 
2022-07-31 11:30:18 - train: epoch 0019, iter [04900, 05004], lr: 0.100000, loss: 3.9547, tea_CELoss: 1.7244, stu_CELoss: 1.8650, DMLLoss: 0.3654, 
2022-07-31 11:31:15 - train: epoch 0019, iter [05000, 05004], lr: 0.100000, loss: 3.8605, tea_CELoss: 1.6837, stu_CELoss: 1.8297, DMLLoss: 0.3472, 
2022-07-31 11:31:18 - train: epoch 019, train_loss: 4.0871
2022-07-31 11:33:47 - eval: epoch: 019, tea_acc1: 61.572%, tea_acc5: 84.914%, tea_test_loss: 1.5771, stu_acc1: 59.576%, stu_acc5: 82.950%, stu_test_loss: 1.7238
2022-07-31 11:33:48 - until epoch: 019, tea_best_acc1: 63.004%, stu_best_acc1: 59.576%
2022-07-31 11:33:48 - epoch 020 lr: 0.100000
2022-07-31 11:34:51 - train: epoch 0020, iter [00100, 05004], lr: 0.100000, loss: 4.0750, tea_CELoss: 1.7442, stu_CELoss: 1.9230, DMLLoss: 0.4078, 
2022-07-31 11:35:49 - train: epoch 0020, iter [00200, 05004], lr: 0.100000, loss: 3.6571, tea_CELoss: 1.6472, stu_CELoss: 1.6628, DMLLoss: 0.3471, 
2022-07-31 11:36:46 - train: epoch 0020, iter [00300, 05004], lr: 0.100000, loss: 3.7785, tea_CELoss: 1.6824, stu_CELoss: 1.7608, DMLLoss: 0.3354, 
2022-07-31 11:37:44 - train: epoch 0020, iter [00400, 05004], lr: 0.100000, loss: 3.7204, tea_CELoss: 1.6048, stu_CELoss: 1.7545, DMLLoss: 0.3611, 
2022-07-31 11:38:41 - train: epoch 0020, iter [00500, 05004], lr: 0.100000, loss: 3.9459, tea_CELoss: 1.6923, stu_CELoss: 1.8643, DMLLoss: 0.3893, 
2022-07-31 11:39:39 - train: epoch 0020, iter [00600, 05004], lr: 0.100000, loss: 3.9351, tea_CELoss: 1.7111, stu_CELoss: 1.8421, DMLLoss: 0.3818, 
2022-07-31 11:40:37 - train: epoch 0020, iter [00700, 05004], lr: 0.100000, loss: 3.7528, tea_CELoss: 1.5638, stu_CELoss: 1.7723, DMLLoss: 0.4168, 
2022-07-31 11:41:34 - train: epoch 0020, iter [00800, 05004], lr: 0.100000, loss: 4.2430, tea_CELoss: 1.8623, stu_CELoss: 1.9876, DMLLoss: 0.3931, 
2022-07-31 11:42:32 - train: epoch 0020, iter [00900, 05004], lr: 0.100000, loss: 4.3929, tea_CELoss: 1.9158, stu_CELoss: 2.0688, DMLLoss: 0.4083, 
2022-07-31 11:43:30 - train: epoch 0020, iter [01000, 05004], lr: 0.100000, loss: 4.2238, tea_CELoss: 1.8817, stu_CELoss: 1.9712, DMLLoss: 0.3709, 
2022-07-31 11:44:27 - train: epoch 0020, iter [01100, 05004], lr: 0.100000, loss: 3.9211, tea_CELoss: 1.6427, stu_CELoss: 1.8982, DMLLoss: 0.3802, 
2022-07-31 11:45:25 - train: epoch 0020, iter [01200, 05004], lr: 0.100000, loss: 3.7452, tea_CELoss: 1.5608, stu_CELoss: 1.7594, DMLLoss: 0.4250, 
2022-07-31 11:46:23 - train: epoch 0020, iter [01300, 05004], lr: 0.100000, loss: 4.0434, tea_CELoss: 1.7646, stu_CELoss: 1.8986, DMLLoss: 0.3802, 
2022-07-31 11:47:20 - train: epoch 0020, iter [01400, 05004], lr: 0.100000, loss: 3.9796, tea_CELoss: 1.6755, stu_CELoss: 1.9036, DMLLoss: 0.4005, 
2022-07-31 11:48:18 - train: epoch 0020, iter [01500, 05004], lr: 0.100000, loss: 3.8967, tea_CELoss: 1.6597, stu_CELoss: 1.8834, DMLLoss: 0.3535, 
2022-07-31 11:49:16 - train: epoch 0020, iter [01600, 05004], lr: 0.100000, loss: 4.4012, tea_CELoss: 1.8967, stu_CELoss: 2.1190, DMLLoss: 0.3855, 
2022-07-31 11:50:13 - train: epoch 0020, iter [01700, 05004], lr: 0.100000, loss: 3.9092, tea_CELoss: 1.7123, stu_CELoss: 1.8272, DMLLoss: 0.3697, 
2022-07-31 11:51:11 - train: epoch 0020, iter [01800, 05004], lr: 0.100000, loss: 4.2057, tea_CELoss: 1.7511, stu_CELoss: 2.0249, DMLLoss: 0.4297, 
2022-07-31 11:52:08 - train: epoch 0020, iter [01900, 05004], lr: 0.100000, loss: 4.1745, tea_CELoss: 1.7580, stu_CELoss: 1.9572, DMLLoss: 0.4593, 
2022-07-31 11:53:06 - train: epoch 0020, iter [02000, 05004], lr: 0.100000, loss: 3.8987, tea_CELoss: 1.6523, stu_CELoss: 1.8775, DMLLoss: 0.3689, 
2022-07-31 11:54:03 - train: epoch 0020, iter [02100, 05004], lr: 0.100000, loss: 4.5993, tea_CELoss: 1.9705, stu_CELoss: 2.1864, DMLLoss: 0.4425, 
2022-07-31 11:55:01 - train: epoch 0020, iter [02200, 05004], lr: 0.100000, loss: 3.7113, tea_CELoss: 1.6042, stu_CELoss: 1.7276, DMLLoss: 0.3795, 
2022-07-31 11:55:58 - train: epoch 0020, iter [02300, 05004], lr: 0.100000, loss: 4.0336, tea_CELoss: 1.7200, stu_CELoss: 1.9176, DMLLoss: 0.3960, 
2022-07-31 11:56:56 - train: epoch 0020, iter [02400, 05004], lr: 0.100000, loss: 4.3394, tea_CELoss: 1.8721, stu_CELoss: 2.0565, DMLLoss: 0.4108, 
2022-07-31 11:57:53 - train: epoch 0020, iter [02500, 05004], lr: 0.100000, loss: 3.9942, tea_CELoss: 1.7356, stu_CELoss: 1.8698, DMLLoss: 0.3889, 
2022-07-31 11:58:51 - train: epoch 0020, iter [02600, 05004], lr: 0.100000, loss: 4.0255, tea_CELoss: 1.7572, stu_CELoss: 1.8715, DMLLoss: 0.3968, 
2022-07-31 11:59:48 - train: epoch 0020, iter [02700, 05004], lr: 0.100000, loss: 3.8970, tea_CELoss: 1.6902, stu_CELoss: 1.8387, DMLLoss: 0.3682, 
2022-07-31 12:00:46 - train: epoch 0020, iter [02800, 05004], lr: 0.100000, loss: 4.2178, tea_CELoss: 1.8282, stu_CELoss: 2.0013, DMLLoss: 0.3883, 
2022-07-31 12:01:44 - train: epoch 0020, iter [02900, 05004], lr: 0.100000, loss: 4.2881, tea_CELoss: 1.8539, stu_CELoss: 1.9999, DMLLoss: 0.4343, 
2022-07-31 12:02:41 - train: epoch 0020, iter [03000, 05004], lr: 0.100000, loss: 4.3415, tea_CELoss: 1.8897, stu_CELoss: 2.0986, DMLLoss: 0.3532, 
2022-07-31 12:03:39 - train: epoch 0020, iter [03100, 05004], lr: 0.100000, loss: 4.1395, tea_CELoss: 1.7518, stu_CELoss: 1.9851, DMLLoss: 0.4026, 
2022-07-31 12:04:36 - train: epoch 0020, iter [03200, 05004], lr: 0.100000, loss: 4.1247, tea_CELoss: 1.7978, stu_CELoss: 1.9685, DMLLoss: 0.3584, 
2022-07-31 12:05:34 - train: epoch 0020, iter [03300, 05004], lr: 0.100000, loss: 3.6576, tea_CELoss: 1.5638, stu_CELoss: 1.7325, DMLLoss: 0.3612, 
2022-07-31 12:06:31 - train: epoch 0020, iter [03400, 05004], lr: 0.100000, loss: 4.0556, tea_CELoss: 1.7386, stu_CELoss: 1.9062, DMLLoss: 0.4108, 
2022-07-31 12:07:29 - train: epoch 0020, iter [03500, 05004], lr: 0.100000, loss: 3.6768, tea_CELoss: 1.6246, stu_CELoss: 1.6943, DMLLoss: 0.3579, 
2022-07-31 12:08:26 - train: epoch 0020, iter [03600, 05004], lr: 0.100000, loss: 4.1126, tea_CELoss: 1.7956, stu_CELoss: 1.9282, DMLLoss: 0.3887, 
2022-07-31 12:09:24 - train: epoch 0020, iter [03700, 05004], lr: 0.100000, loss: 4.0736, tea_CELoss: 1.8156, stu_CELoss: 1.9162, DMLLoss: 0.3418, 
2022-07-31 12:10:21 - train: epoch 0020, iter [03800, 05004], lr: 0.100000, loss: 3.9607, tea_CELoss: 1.7754, stu_CELoss: 1.7974, DMLLoss: 0.3879, 
2022-07-31 12:11:18 - train: epoch 0020, iter [03900, 05004], lr: 0.100000, loss: 4.5395, tea_CELoss: 1.9729, stu_CELoss: 2.1511, DMLLoss: 0.4155, 
2022-07-31 12:12:16 - train: epoch 0020, iter [04000, 05004], lr: 0.100000, loss: 3.9604, tea_CELoss: 1.6871, stu_CELoss: 1.8990, DMLLoss: 0.3743, 
2022-07-31 12:13:13 - train: epoch 0020, iter [04100, 05004], lr: 0.100000, loss: 4.2123, tea_CELoss: 1.8413, stu_CELoss: 1.9802, DMLLoss: 0.3907, 
2022-07-31 12:14:11 - train: epoch 0020, iter [04200, 05004], lr: 0.100000, loss: 4.0915, tea_CELoss: 1.7775, stu_CELoss: 1.9494, DMLLoss: 0.3646, 
2022-07-31 12:15:08 - train: epoch 0020, iter [04300, 05004], lr: 0.100000, loss: 4.3896, tea_CELoss: 1.9060, stu_CELoss: 2.0739, DMLLoss: 0.4097, 
2022-07-31 12:16:06 - train: epoch 0020, iter [04400, 05004], lr: 0.100000, loss: 4.0886, tea_CELoss: 1.7772, stu_CELoss: 1.9543, DMLLoss: 0.3571, 
2022-07-31 12:17:03 - train: epoch 0020, iter [04500, 05004], lr: 0.100000, loss: 4.0895, tea_CELoss: 1.7972, stu_CELoss: 1.9424, DMLLoss: 0.3500, 
2022-07-31 12:18:01 - train: epoch 0020, iter [04600, 05004], lr: 0.100000, loss: 4.2262, tea_CELoss: 1.8522, stu_CELoss: 1.9743, DMLLoss: 0.3997, 
2022-07-31 12:18:58 - train: epoch 0020, iter [04700, 05004], lr: 0.100000, loss: 3.7580, tea_CELoss: 1.6134, stu_CELoss: 1.7638, DMLLoss: 0.3808, 
2022-07-31 12:19:56 - train: epoch 0020, iter [04800, 05004], lr: 0.100000, loss: 3.9485, tea_CELoss: 1.7478, stu_CELoss: 1.8430, DMLLoss: 0.3577, 
2022-07-31 12:20:53 - train: epoch 0020, iter [04900, 05004], lr: 0.100000, loss: 4.1710, tea_CELoss: 1.7801, stu_CELoss: 1.9798, DMLLoss: 0.4110, 
2022-07-31 12:21:51 - train: epoch 0020, iter [05000, 05004], lr: 0.100000, loss: 3.8786, tea_CELoss: 1.7214, stu_CELoss: 1.7834, DMLLoss: 0.3737, 
2022-07-31 12:21:54 - train: epoch 020, train_loss: 4.0708
2022-07-31 12:24:21 - eval: epoch: 020, tea_acc1: 62.070%, tea_acc5: 85.100%, tea_test_loss: 1.5737, stu_acc1: 59.834%, stu_acc5: 83.158%, stu_test_loss: 1.6817
2022-07-31 12:24:22 - until epoch: 020, tea_best_acc1: 63.004%, stu_best_acc1: 59.834%
2022-07-31 12:24:22 - epoch 021 lr: 0.100000
2022-07-31 12:25:26 - train: epoch 0021, iter [00100, 05004], lr: 0.100000, loss: 4.0425, tea_CELoss: 1.7341, stu_CELoss: 1.9102, DMLLoss: 0.3983, 
2022-07-31 12:26:24 - train: epoch 0021, iter [00200, 05004], lr: 0.100000, loss: 4.1251, tea_CELoss: 1.7294, stu_CELoss: 1.9491, DMLLoss: 0.4466, 
2022-07-31 12:27:22 - train: epoch 0021, iter [00300, 05004], lr: 0.100000, loss: 3.5703, tea_CELoss: 1.5251, stu_CELoss: 1.6904, DMLLoss: 0.3548, 
2022-07-31 12:28:19 - train: epoch 0021, iter [00400, 05004], lr: 0.100000, loss: 4.1432, tea_CELoss: 1.8018, stu_CELoss: 1.9458, DMLLoss: 0.3956, 
2022-07-31 12:29:17 - train: epoch 0021, iter [00500, 05004], lr: 0.100000, loss: 3.4750, tea_CELoss: 1.5083, stu_CELoss: 1.6317, DMLLoss: 0.3350, 
2022-07-31 12:30:15 - train: epoch 0021, iter [00600, 05004], lr: 0.100000, loss: 3.8528, tea_CELoss: 1.6861, stu_CELoss: 1.7764, DMLLoss: 0.3902, 
2022-07-31 12:31:13 - train: epoch 0021, iter [00700, 05004], lr: 0.100000, loss: 3.6069, tea_CELoss: 1.4599, stu_CELoss: 1.7629, DMLLoss: 0.3841, 
2022-07-31 12:32:10 - train: epoch 0021, iter [00800, 05004], lr: 0.100000, loss: 4.0372, tea_CELoss: 1.7239, stu_CELoss: 1.9252, DMLLoss: 0.3881, 
2022-07-31 12:33:08 - train: epoch 0021, iter [00900, 05004], lr: 0.100000, loss: 3.9708, tea_CELoss: 1.6985, stu_CELoss: 1.8646, DMLLoss: 0.4078, 
2022-07-31 12:34:06 - train: epoch 0021, iter [01000, 05004], lr: 0.100000, loss: 3.7350, tea_CELoss: 1.5939, stu_CELoss: 1.7800, DMLLoss: 0.3611, 
2022-07-31 12:35:04 - train: epoch 0021, iter [01100, 05004], lr: 0.100000, loss: 4.0307, tea_CELoss: 1.7934, stu_CELoss: 1.8876, DMLLoss: 0.3498, 
2022-07-31 12:36:01 - train: epoch 0021, iter [01200, 05004], lr: 0.100000, loss: 3.9549, tea_CELoss: 1.7486, stu_CELoss: 1.8544, DMLLoss: 0.3519, 
2022-07-31 12:36:59 - train: epoch 0021, iter [01300, 05004], lr: 0.100000, loss: 3.5996, tea_CELoss: 1.5132, stu_CELoss: 1.7138, DMLLoss: 0.3725, 
2022-07-31 12:37:57 - train: epoch 0021, iter [01400, 05004], lr: 0.100000, loss: 3.3418, tea_CELoss: 1.4384, stu_CELoss: 1.5771, DMLLoss: 0.3263, 
2022-07-31 12:38:55 - train: epoch 0021, iter [01500, 05004], lr: 0.100000, loss: 4.0756, tea_CELoss: 1.7303, stu_CELoss: 1.9538, DMLLoss: 0.3915, 
2022-07-31 12:39:52 - train: epoch 0021, iter [01600, 05004], lr: 0.100000, loss: 4.0072, tea_CELoss: 1.6790, stu_CELoss: 1.9072, DMLLoss: 0.4210, 
2022-07-31 12:40:50 - train: epoch 0021, iter [01700, 05004], lr: 0.100000, loss: 4.2615, tea_CELoss: 1.9009, stu_CELoss: 2.0142, DMLLoss: 0.3465, 
2022-07-31 12:41:48 - train: epoch 0021, iter [01800, 05004], lr: 0.100000, loss: 3.9699, tea_CELoss: 1.7222, stu_CELoss: 1.9063, DMLLoss: 0.3414, 
2022-07-31 12:42:45 - train: epoch 0021, iter [01900, 05004], lr: 0.100000, loss: 4.4567, tea_CELoss: 1.9498, stu_CELoss: 2.0702, DMLLoss: 0.4367, 
2022-07-31 12:43:43 - train: epoch 0021, iter [02000, 05004], lr: 0.100000, loss: 4.1677, tea_CELoss: 1.8882, stu_CELoss: 1.9107, DMLLoss: 0.3688, 
2022-07-31 12:44:41 - train: epoch 0021, iter [02100, 05004], lr: 0.100000, loss: 3.5506, tea_CELoss: 1.5159, stu_CELoss: 1.6557, DMLLoss: 0.3790, 
2022-07-31 12:45:39 - train: epoch 0021, iter [02200, 05004], lr: 0.100000, loss: 4.0885, tea_CELoss: 1.7730, stu_CELoss: 1.9157, DMLLoss: 0.3998, 
2022-07-31 12:46:37 - train: epoch 0021, iter [02300, 05004], lr: 0.100000, loss: 4.4279, tea_CELoss: 1.9524, stu_CELoss: 2.0590, DMLLoss: 0.4164, 
2022-07-31 12:47:36 - train: epoch 0021, iter [02400, 05004], lr: 0.100000, loss: 3.6880, tea_CELoss: 1.5898, stu_CELoss: 1.7828, DMLLoss: 0.3154, 
2022-07-31 12:48:34 - train: epoch 0021, iter [02500, 05004], lr: 0.100000, loss: 4.1364, tea_CELoss: 1.7788, stu_CELoss: 1.9306, DMLLoss: 0.4270, 
2022-07-31 12:49:32 - train: epoch 0021, iter [02600, 05004], lr: 0.100000, loss: 4.2498, tea_CELoss: 1.8339, stu_CELoss: 2.0032, DMLLoss: 0.4127, 
2022-07-31 12:50:31 - train: epoch 0021, iter [02700, 05004], lr: 0.100000, loss: 3.7432, tea_CELoss: 1.5636, stu_CELoss: 1.7669, DMLLoss: 0.4127, 
2022-07-31 12:51:29 - train: epoch 0021, iter [02800, 05004], lr: 0.100000, loss: 3.8744, tea_CELoss: 1.6566, stu_CELoss: 1.8324, DMLLoss: 0.3853, 
2022-07-31 12:52:27 - train: epoch 0021, iter [02900, 05004], lr: 0.100000, loss: 4.0264, tea_CELoss: 1.7514, stu_CELoss: 1.8843, DMLLoss: 0.3907, 
2022-07-31 12:53:25 - train: epoch 0021, iter [03000, 05004], lr: 0.100000, loss: 4.3841, tea_CELoss: 1.8873, stu_CELoss: 2.0952, DMLLoss: 0.4016, 
2022-07-31 12:54:23 - train: epoch 0021, iter [03100, 05004], lr: 0.100000, loss: 4.2089, tea_CELoss: 1.8181, stu_CELoss: 1.9918, DMLLoss: 0.3990, 
2022-07-31 12:55:21 - train: epoch 0021, iter [03200, 05004], lr: 0.100000, loss: 3.8389, tea_CELoss: 1.6146, stu_CELoss: 1.8252, DMLLoss: 0.3992, 
2022-07-31 12:56:18 - train: epoch 0021, iter [03300, 05004], lr: 0.100000, loss: 4.6066, tea_CELoss: 1.9672, stu_CELoss: 2.2336, DMLLoss: 0.4058, 
2022-07-31 12:57:16 - train: epoch 0021, iter [03400, 05004], lr: 0.100000, loss: 4.4822, tea_CELoss: 1.9907, stu_CELoss: 2.1175, DMLLoss: 0.3740, 
2022-07-31 12:58:14 - train: epoch 0021, iter [03500, 05004], lr: 0.100000, loss: 4.1533, tea_CELoss: 1.8058, stu_CELoss: 1.9542, DMLLoss: 0.3934, 
2022-07-31 12:59:12 - train: epoch 0021, iter [03600, 05004], lr: 0.100000, loss: 4.2060, tea_CELoss: 1.8263, stu_CELoss: 1.9884, DMLLoss: 0.3913, 
2022-07-31 13:00:10 - train: epoch 0021, iter [03700, 05004], lr: 0.100000, loss: 3.8159, tea_CELoss: 1.6243, stu_CELoss: 1.8113, DMLLoss: 0.3803, 
2022-07-31 13:01:07 - train: epoch 0021, iter [03800, 05004], lr: 0.100000, loss: 4.0059, tea_CELoss: 1.7423, stu_CELoss: 1.8630, DMLLoss: 0.4006, 
2022-07-31 13:02:05 - train: epoch 0021, iter [03900, 05004], lr: 0.100000, loss: 3.8709, tea_CELoss: 1.6714, stu_CELoss: 1.8025, DMLLoss: 0.3970, 
2022-07-31 13:03:03 - train: epoch 0021, iter [04000, 05004], lr: 0.100000, loss: 4.4088, tea_CELoss: 1.9340, stu_CELoss: 2.0967, DMLLoss: 0.3781, 
2022-07-31 13:04:01 - train: epoch 0021, iter [04100, 05004], lr: 0.100000, loss: 3.7846, tea_CELoss: 1.6096, stu_CELoss: 1.7971, DMLLoss: 0.3780, 
2022-07-31 13:04:59 - train: epoch 0021, iter [04200, 05004], lr: 0.100000, loss: 3.9538, tea_CELoss: 1.7516, stu_CELoss: 1.8542, DMLLoss: 0.3480, 
2022-07-31 13:05:56 - train: epoch 0021, iter [04300, 05004], lr: 0.100000, loss: 4.4111, tea_CELoss: 1.9469, stu_CELoss: 2.0858, DMLLoss: 0.3783, 
2022-07-31 13:06:54 - train: epoch 0021, iter [04400, 05004], lr: 0.100000, loss: 4.1302, tea_CELoss: 1.8133, stu_CELoss: 1.9435, DMLLoss: 0.3734, 
2022-07-31 13:07:52 - train: epoch 0021, iter [04500, 05004], lr: 0.100000, loss: 4.3402, tea_CELoss: 1.8435, stu_CELoss: 2.0799, DMLLoss: 0.4168, 
2022-07-31 13:08:50 - train: epoch 0021, iter [04600, 05004], lr: 0.100000, loss: 4.1441, tea_CELoss: 1.7939, stu_CELoss: 1.9739, DMLLoss: 0.3763, 
2022-07-31 13:09:47 - train: epoch 0021, iter [04700, 05004], lr: 0.100000, loss: 4.2754, tea_CELoss: 1.8783, stu_CELoss: 2.0378, DMLLoss: 0.3593, 
2022-07-31 13:10:45 - train: epoch 0021, iter [04800, 05004], lr: 0.100000, loss: 4.1415, tea_CELoss: 1.7942, stu_CELoss: 1.9619, DMLLoss: 0.3854, 
2022-07-31 13:11:43 - train: epoch 0021, iter [04900, 05004], lr: 0.100000, loss: 3.6647, tea_CELoss: 1.5831, stu_CELoss: 1.6944, DMLLoss: 0.3872, 
2022-07-31 13:12:40 - train: epoch 0021, iter [05000, 05004], lr: 0.100000, loss: 3.8698, tea_CELoss: 1.6939, stu_CELoss: 1.8163, DMLLoss: 0.3596, 
2022-07-31 13:12:43 - train: epoch 021, train_loss: 4.0585
2022-07-31 13:15:12 - eval: epoch: 021, tea_acc1: 61.982%, tea_acc5: 85.268%, tea_test_loss: 1.5583, stu_acc1: 59.250%, stu_acc5: 82.980%, stu_test_loss: 1.7106
2022-07-31 13:15:12 - until epoch: 021, tea_best_acc1: 63.004%, stu_best_acc1: 59.834%
2022-07-31 13:15:12 - epoch 022 lr: 0.100000
2022-07-31 13:16:16 - train: epoch 0022, iter [00100, 05004], lr: 0.100000, loss: 3.4030, tea_CELoss: 1.4189, stu_CELoss: 1.5849, DMLLoss: 0.3992, 
2022-07-31 13:17:14 - train: epoch 0022, iter [00200, 05004], lr: 0.100000, loss: 3.9646, tea_CELoss: 1.6736, stu_CELoss: 1.9104, DMLLoss: 0.3806, 
2022-07-31 13:18:12 - train: epoch 0022, iter [00300, 05004], lr: 0.100000, loss: 3.7483, tea_CELoss: 1.5922, stu_CELoss: 1.7994, DMLLoss: 0.3567, 
2022-07-31 13:19:09 - train: epoch 0022, iter [00400, 05004], lr: 0.100000, loss: 3.7462, tea_CELoss: 1.6309, stu_CELoss: 1.7359, DMLLoss: 0.3794, 
2022-07-31 13:20:07 - train: epoch 0022, iter [00500, 05004], lr: 0.100000, loss: 3.9794, tea_CELoss: 1.7077, stu_CELoss: 1.8787, DMLLoss: 0.3931, 
2022-07-31 13:21:05 - train: epoch 0022, iter [00600, 05004], lr: 0.100000, loss: 4.2056, tea_CELoss: 1.7646, stu_CELoss: 2.0447, DMLLoss: 0.3963, 
2022-07-31 13:22:02 - train: epoch 0022, iter [00700, 05004], lr: 0.100000, loss: 4.3770, tea_CELoss: 1.8743, stu_CELoss: 2.0713, DMLLoss: 0.4314, 
2022-07-31 13:23:00 - train: epoch 0022, iter [00800, 05004], lr: 0.100000, loss: 4.3470, tea_CELoss: 1.8536, stu_CELoss: 2.1102, DMLLoss: 0.3832, 
2022-07-31 13:23:57 - train: epoch 0022, iter [00900, 05004], lr: 0.100000, loss: 4.2529, tea_CELoss: 1.7953, stu_CELoss: 2.0490, DMLLoss: 0.4086, 
2022-07-31 13:24:55 - train: epoch 0022, iter [01000, 05004], lr: 0.100000, loss: 4.3553, tea_CELoss: 1.9324, stu_CELoss: 2.0023, DMLLoss: 0.4206, 
2022-07-31 13:25:53 - train: epoch 0022, iter [01100, 05004], lr: 0.100000, loss: 3.7648, tea_CELoss: 1.5996, stu_CELoss: 1.8188, DMLLoss: 0.3464, 
2022-07-31 13:26:50 - train: epoch 0022, iter [01200, 05004], lr: 0.100000, loss: 3.2890, tea_CELoss: 1.3468, stu_CELoss: 1.5619, DMLLoss: 0.3803, 
2022-07-31 13:27:47 - train: epoch 0022, iter [01300, 05004], lr: 0.100000, loss: 4.3071, tea_CELoss: 1.8079, stu_CELoss: 2.0582, DMLLoss: 0.4410, 
2022-07-31 13:28:45 - train: epoch 0022, iter [01400, 05004], lr: 0.100000, loss: 3.8473, tea_CELoss: 1.5731, stu_CELoss: 1.8196, DMLLoss: 0.4547, 
2022-07-31 13:29:42 - train: epoch 0022, iter [01500, 05004], lr: 0.100000, loss: 4.3047, tea_CELoss: 1.8854, stu_CELoss: 2.0335, DMLLoss: 0.3858, 
2022-07-31 13:30:40 - train: epoch 0022, iter [01600, 05004], lr: 0.100000, loss: 3.8658, tea_CELoss: 1.6575, stu_CELoss: 1.8202, DMLLoss: 0.3881, 
2022-07-31 13:31:37 - train: epoch 0022, iter [01700, 05004], lr: 0.100000, loss: 4.2947, tea_CELoss: 1.8648, stu_CELoss: 2.0682, DMLLoss: 0.3618, 
2022-07-31 13:32:35 - train: epoch 0022, iter [01800, 05004], lr: 0.100000, loss: 4.1739, tea_CELoss: 1.7895, stu_CELoss: 1.9909, DMLLoss: 0.3935, 
2022-07-31 13:33:33 - train: epoch 0022, iter [01900, 05004], lr: 0.100000, loss: 4.0023, tea_CELoss: 1.7402, stu_CELoss: 1.8890, DMLLoss: 0.3732, 
2022-07-31 13:34:30 - train: epoch 0022, iter [02000, 05004], lr: 0.100000, loss: 3.7321, tea_CELoss: 1.6747, stu_CELoss: 1.7137, DMLLoss: 0.3437, 
2022-07-31 13:35:28 - train: epoch 0022, iter [02100, 05004], lr: 0.100000, loss: 3.8091, tea_CELoss: 1.6087, stu_CELoss: 1.8322, DMLLoss: 0.3682, 
2022-07-31 13:36:25 - train: epoch 0022, iter [02200, 05004], lr: 0.100000, loss: 3.6007, tea_CELoss: 1.5721, stu_CELoss: 1.6533, DMLLoss: 0.3754, 
2022-07-31 13:37:23 - train: epoch 0022, iter [02300, 05004], lr: 0.100000, loss: 4.1491, tea_CELoss: 1.7596, stu_CELoss: 1.9831, DMLLoss: 0.4064, 
2022-07-31 13:38:20 - train: epoch 0022, iter [02400, 05004], lr: 0.100000, loss: 4.3397, tea_CELoss: 1.9531, stu_CELoss: 2.0566, DMLLoss: 0.3300, 
2022-07-31 13:39:18 - train: epoch 0022, iter [02500, 05004], lr: 0.100000, loss: 4.1316, tea_CELoss: 1.7994, stu_CELoss: 1.9724, DMLLoss: 0.3598, 
2022-07-31 13:40:16 - train: epoch 0022, iter [02600, 05004], lr: 0.100000, loss: 3.8263, tea_CELoss: 1.6814, stu_CELoss: 1.7657, DMLLoss: 0.3792, 
2022-07-31 13:41:13 - train: epoch 0022, iter [02700, 05004], lr: 0.100000, loss: 3.9019, tea_CELoss: 1.7453, stu_CELoss: 1.8087, DMLLoss: 0.3480, 
2022-07-31 13:42:11 - train: epoch 0022, iter [02800, 05004], lr: 0.100000, loss: 4.4089, tea_CELoss: 1.9533, stu_CELoss: 2.0562, DMLLoss: 0.3994, 
2022-07-31 13:43:09 - train: epoch 0022, iter [02900, 05004], lr: 0.100000, loss: 3.7633, tea_CELoss: 1.5608, stu_CELoss: 1.7916, DMLLoss: 0.4109, 
2022-07-31 13:44:06 - train: epoch 0022, iter [03000, 05004], lr: 0.100000, loss: 3.9828, tea_CELoss: 1.7402, stu_CELoss: 1.8841, DMLLoss: 0.3585, 
2022-07-31 13:45:04 - train: epoch 0022, iter [03100, 05004], lr: 0.100000, loss: 4.2249, tea_CELoss: 1.9087, stu_CELoss: 1.9278, DMLLoss: 0.3884, 
2022-07-31 13:46:02 - train: epoch 0022, iter [03200, 05004], lr: 0.100000, loss: 4.1060, tea_CELoss: 1.7701, stu_CELoss: 1.9614, DMLLoss: 0.3746, 
2022-07-31 13:47:00 - train: epoch 0022, iter [03300, 05004], lr: 0.100000, loss: 3.9970, tea_CELoss: 1.7439, stu_CELoss: 1.8926, DMLLoss: 0.3605, 
2022-07-31 13:47:58 - train: epoch 0022, iter [03400, 05004], lr: 0.100000, loss: 3.8406, tea_CELoss: 1.6483, stu_CELoss: 1.7967, DMLLoss: 0.3956, 
2022-07-31 13:48:56 - train: epoch 0022, iter [03500, 05004], lr: 0.100000, loss: 4.3273, tea_CELoss: 1.8763, stu_CELoss: 2.0660, DMLLoss: 0.3849, 
2022-07-31 13:49:54 - train: epoch 0022, iter [03600, 05004], lr: 0.100000, loss: 4.1179, tea_CELoss: 1.8071, stu_CELoss: 1.9464, DMLLoss: 0.3644, 
2022-07-31 13:50:52 - train: epoch 0022, iter [03700, 05004], lr: 0.100000, loss: 4.1455, tea_CELoss: 1.7874, stu_CELoss: 1.9340, DMLLoss: 0.4241, 
2022-07-31 13:51:50 - train: epoch 0022, iter [03800, 05004], lr: 0.100000, loss: 4.2169, tea_CELoss: 1.8403, stu_CELoss: 1.9883, DMLLoss: 0.3884, 
2022-07-31 13:52:48 - train: epoch 0022, iter [03900, 05004], lr: 0.100000, loss: 4.0327, tea_CELoss: 1.7156, stu_CELoss: 1.9099, DMLLoss: 0.4071, 
2022-07-31 13:53:46 - train: epoch 0022, iter [04000, 05004], lr: 0.100000, loss: 4.2845, tea_CELoss: 1.9029, stu_CELoss: 2.0055, DMLLoss: 0.3762, 
2022-07-31 13:54:44 - train: epoch 0022, iter [04100, 05004], lr: 0.100000, loss: 4.2127, tea_CELoss: 1.8529, stu_CELoss: 1.9837, DMLLoss: 0.3761, 
2022-07-31 13:55:42 - train: epoch 0022, iter [04200, 05004], lr: 0.100000, loss: 4.1621, tea_CELoss: 1.7974, stu_CELoss: 1.9710, DMLLoss: 0.3937, 
2022-07-31 13:56:40 - train: epoch 0022, iter [04300, 05004], lr: 0.100000, loss: 3.9197, tea_CELoss: 1.7302, stu_CELoss: 1.8095, DMLLoss: 0.3799, 
2022-07-31 13:57:38 - train: epoch 0022, iter [04400, 05004], lr: 0.100000, loss: 3.8119, tea_CELoss: 1.6142, stu_CELoss: 1.8395, DMLLoss: 0.3582, 
2022-07-31 13:58:36 - train: epoch 0022, iter [04500, 05004], lr: 0.100000, loss: 3.9981, tea_CELoss: 1.7695, stu_CELoss: 1.8655, DMLLoss: 0.3631, 
2022-07-31 13:59:34 - train: epoch 0022, iter [04600, 05004], lr: 0.100000, loss: 4.4554, tea_CELoss: 1.9608, stu_CELoss: 2.1157, DMLLoss: 0.3790, 
2022-07-31 14:00:32 - train: epoch 0022, iter [04700, 05004], lr: 0.100000, loss: 4.2943, tea_CELoss: 1.9104, stu_CELoss: 2.0236, DMLLoss: 0.3603, 
2022-07-31 14:01:30 - train: epoch 0022, iter [04800, 05004], lr: 0.100000, loss: 3.4513, tea_CELoss: 1.4580, stu_CELoss: 1.6354, DMLLoss: 0.3579, 
2022-07-31 14:02:28 - train: epoch 0022, iter [04900, 05004], lr: 0.100000, loss: 4.1176, tea_CELoss: 1.7899, stu_CELoss: 1.9433, DMLLoss: 0.3844, 
2022-07-31 14:03:26 - train: epoch 0022, iter [05000, 05004], lr: 0.100000, loss: 3.8974, tea_CELoss: 1.6646, stu_CELoss: 1.8435, DMLLoss: 0.3893, 
2022-07-31 14:03:29 - train: epoch 022, train_loss: 4.0456
2022-07-31 14:05:58 - eval: epoch: 022, tea_acc1: 63.140%, tea_acc5: 85.744%, tea_test_loss: 1.5198, stu_acc1: 56.692%, stu_acc5: 80.330%, stu_test_loss: 2.0103
2022-07-31 14:05:59 - until epoch: 022, tea_best_acc1: 63.140%, stu_best_acc1: 59.834%
2022-07-31 14:05:59 - epoch 023 lr: 0.100000
2022-07-31 14:07:02 - train: epoch 0023, iter [00100, 05004], lr: 0.100000, loss: 4.0790, tea_CELoss: 1.7360, stu_CELoss: 1.9123, DMLLoss: 0.4308, 
2022-07-31 14:07:59 - train: epoch 0023, iter [00200, 05004], lr: 0.100000, loss: 3.6867, tea_CELoss: 1.6223, stu_CELoss: 1.7254, DMLLoss: 0.3390, 
2022-07-31 14:08:57 - train: epoch 0023, iter [00300, 05004], lr: 0.100000, loss: 3.9386, tea_CELoss: 1.6864, stu_CELoss: 1.8678, DMLLoss: 0.3843, 
2022-07-31 14:09:54 - train: epoch 0023, iter [00400, 05004], lr: 0.100000, loss: 3.9008, tea_CELoss: 1.6675, stu_CELoss: 1.8341, DMLLoss: 0.3992, 
2022-07-31 14:10:52 - train: epoch 0023, iter [00500, 05004], lr: 0.100000, loss: 4.0524, tea_CELoss: 1.7699, stu_CELoss: 1.9074, DMLLoss: 0.3751, 
2022-07-31 14:11:49 - train: epoch 0023, iter [00600, 05004], lr: 0.100000, loss: 4.1978, tea_CELoss: 1.8139, stu_CELoss: 1.9832, DMLLoss: 0.4007, 
2022-07-31 14:12:47 - train: epoch 0023, iter [00700, 05004], lr: 0.100000, loss: 4.0394, tea_CELoss: 1.6924, stu_CELoss: 1.9471, DMLLoss: 0.3999, 
2022-07-31 14:13:44 - train: epoch 0023, iter [00800, 05004], lr: 0.100000, loss: 3.8564, tea_CELoss: 1.6456, stu_CELoss: 1.8374, DMLLoss: 0.3733, 
2022-07-31 14:14:42 - train: epoch 0023, iter [00900, 05004], lr: 0.100000, loss: 4.1058, tea_CELoss: 1.7979, stu_CELoss: 1.9147, DMLLoss: 0.3932, 
2022-07-31 14:15:40 - train: epoch 0023, iter [01000, 05004], lr: 0.100000, loss: 3.6739, tea_CELoss: 1.5843, stu_CELoss: 1.6816, DMLLoss: 0.4080, 
2022-07-31 14:16:37 - train: epoch 0023, iter [01100, 05004], lr: 0.100000, loss: 4.0770, tea_CELoss: 1.7900, stu_CELoss: 1.9004, DMLLoss: 0.3866, 
2022-07-31 14:17:35 - train: epoch 0023, iter [01200, 05004], lr: 0.100000, loss: 3.8455, tea_CELoss: 1.6973, stu_CELoss: 1.8033, DMLLoss: 0.3450, 
2022-07-31 14:18:32 - train: epoch 0023, iter [01300, 05004], lr: 0.100000, loss: 3.8112, tea_CELoss: 1.6187, stu_CELoss: 1.7698, DMLLoss: 0.4227, 
2022-07-31 14:19:30 - train: epoch 0023, iter [01400, 05004], lr: 0.100000, loss: 4.0259, tea_CELoss: 1.7268, stu_CELoss: 1.9184, DMLLoss: 0.3807, 
2022-07-31 14:20:27 - train: epoch 0023, iter [01500, 05004], lr: 0.100000, loss: 3.7145, tea_CELoss: 1.6013, stu_CELoss: 1.7388, DMLLoss: 0.3745, 
2022-07-31 14:21:25 - train: epoch 0023, iter [01600, 05004], lr: 0.100000, loss: 4.1494, tea_CELoss: 1.8047, stu_CELoss: 1.9567, DMLLoss: 0.3880, 
2022-07-31 14:22:22 - train: epoch 0023, iter [01700, 05004], lr: 0.100000, loss: 3.7336, tea_CELoss: 1.5976, stu_CELoss: 1.7466, DMLLoss: 0.3893, 
2022-07-31 14:23:20 - train: epoch 0023, iter [01800, 05004], lr: 0.100000, loss: 4.2918, tea_CELoss: 1.8853, stu_CELoss: 2.0292, DMLLoss: 0.3773, 
2022-07-31 14:24:18 - train: epoch 0023, iter [01900, 05004], lr: 0.100000, loss: 4.4219, tea_CELoss: 1.8993, stu_CELoss: 2.0827, DMLLoss: 0.4399, 
2022-07-31 14:25:15 - train: epoch 0023, iter [02000, 05004], lr: 0.100000, loss: 3.5683, tea_CELoss: 1.4583, stu_CELoss: 1.7023, DMLLoss: 0.4077, 
2022-07-31 14:26:12 - train: epoch 0023, iter [02100, 05004], lr: 0.100000, loss: 3.8709, tea_CELoss: 1.7105, stu_CELoss: 1.8110, DMLLoss: 0.3494, 
2022-07-31 14:27:10 - train: epoch 0023, iter [02200, 05004], lr: 0.100000, loss: 3.6191, tea_CELoss: 1.5725, stu_CELoss: 1.7057, DMLLoss: 0.3409, 
2022-07-31 14:28:07 - train: epoch 0023, iter [02300, 05004], lr: 0.100000, loss: 3.8551, tea_CELoss: 1.6740, stu_CELoss: 1.7964, DMLLoss: 0.3847, 
2022-07-31 14:29:04 - train: epoch 0023, iter [02400, 05004], lr: 0.100000, loss: 3.9766, tea_CELoss: 1.7634, stu_CELoss: 1.8327, DMLLoss: 0.3806, 
2022-07-31 14:30:02 - train: epoch 0023, iter [02500, 05004], lr: 0.100000, loss: 3.9731, tea_CELoss: 1.7342, stu_CELoss: 1.8571, DMLLoss: 0.3818, 
2022-07-31 14:30:59 - train: epoch 0023, iter [02600, 05004], lr: 0.100000, loss: 4.1888, tea_CELoss: 1.8514, stu_CELoss: 1.9404, DMLLoss: 0.3970, 
2022-07-31 14:31:57 - train: epoch 0023, iter [02700, 05004], lr: 0.100000, loss: 4.3663, tea_CELoss: 1.9199, stu_CELoss: 2.0474, DMLLoss: 0.3991, 
2022-07-31 14:32:54 - train: epoch 0023, iter [02800, 05004], lr: 0.100000, loss: 4.4240, tea_CELoss: 1.9655, stu_CELoss: 2.0898, DMLLoss: 0.3687, 
2022-07-31 14:33:52 - train: epoch 0023, iter [02900, 05004], lr: 0.100000, loss: 3.9777, tea_CELoss: 1.7141, stu_CELoss: 1.8528, DMLLoss: 0.4109, 
2022-07-31 14:34:49 - train: epoch 0023, iter [03000, 05004], lr: 0.100000, loss: 4.1806, tea_CELoss: 1.8515, stu_CELoss: 1.9276, DMLLoss: 0.4015, 
2022-07-31 14:35:47 - train: epoch 0023, iter [03100, 05004], lr: 0.100000, loss: 4.4801, tea_CELoss: 1.9902, stu_CELoss: 2.1081, DMLLoss: 0.3818, 
2022-07-31 14:36:44 - train: epoch 0023, iter [03200, 05004], lr: 0.100000, loss: 4.3105, tea_CELoss: 1.9104, stu_CELoss: 2.0060, DMLLoss: 0.3941, 
2022-07-31 14:37:42 - train: epoch 0023, iter [03300, 05004], lr: 0.100000, loss: 3.9077, tea_CELoss: 1.7306, stu_CELoss: 1.8049, DMLLoss: 0.3722, 
2022-07-31 14:38:39 - train: epoch 0023, iter [03400, 05004], lr: 0.100000, loss: 4.1145, tea_CELoss: 1.7726, stu_CELoss: 1.9733, DMLLoss: 0.3685, 
2022-07-31 14:39:37 - train: epoch 0023, iter [03500, 05004], lr: 0.100000, loss: 3.9093, tea_CELoss: 1.6903, stu_CELoss: 1.8400, DMLLoss: 0.3790, 
2022-07-31 14:40:34 - train: epoch 0023, iter [03600, 05004], lr: 0.100000, loss: 3.9248, tea_CELoss: 1.7558, stu_CELoss: 1.8257, DMLLoss: 0.3432, 
2022-07-31 14:41:32 - train: epoch 0023, iter [03700, 05004], lr: 0.100000, loss: 4.1781, tea_CELoss: 1.7422, stu_CELoss: 1.9964, DMLLoss: 0.4395, 
2022-07-31 14:42:30 - train: epoch 0023, iter [03800, 05004], lr: 0.100000, loss: 4.3775, tea_CELoss: 1.9218, stu_CELoss: 2.0590, DMLLoss: 0.3967, 
2022-07-31 14:43:27 - train: epoch 0023, iter [03900, 05004], lr: 0.100000, loss: 4.2791, tea_CELoss: 1.8541, stu_CELoss: 2.0472, DMLLoss: 0.3779, 
2022-07-31 14:44:25 - train: epoch 0023, iter [04000, 05004], lr: 0.100000, loss: 3.9512, tea_CELoss: 1.7193, stu_CELoss: 1.8337, DMLLoss: 0.3982, 
2022-07-31 14:45:23 - train: epoch 0023, iter [04100, 05004], lr: 0.100000, loss: 3.8298, tea_CELoss: 1.6512, stu_CELoss: 1.7743, DMLLoss: 0.4044, 
2022-07-31 14:46:21 - train: epoch 0023, iter [04200, 05004], lr: 0.100000, loss: 3.5602, tea_CELoss: 1.5414, stu_CELoss: 1.6573, DMLLoss: 0.3615, 
2022-07-31 14:47:19 - train: epoch 0023, iter [04300, 05004], lr: 0.100000, loss: 3.8748, tea_CELoss: 1.6531, stu_CELoss: 1.8687, DMLLoss: 0.3530, 
2022-07-31 14:48:17 - train: epoch 0023, iter [04400, 05004], lr: 0.100000, loss: 3.6176, tea_CELoss: 1.5917, stu_CELoss: 1.6696, DMLLoss: 0.3563, 
2022-07-31 14:49:15 - train: epoch 0023, iter [04500, 05004], lr: 0.100000, loss: 3.8464, tea_CELoss: 1.7008, stu_CELoss: 1.7802, DMLLoss: 0.3654, 
2022-07-31 14:50:13 - train: epoch 0023, iter [04600, 05004], lr: 0.100000, loss: 4.2572, tea_CELoss: 1.8108, stu_CELoss: 2.0279, DMLLoss: 0.4184, 
2022-07-31 14:51:11 - train: epoch 0023, iter [04700, 05004], lr: 0.100000, loss: 3.6740, tea_CELoss: 1.5942, stu_CELoss: 1.7355, DMLLoss: 0.3443, 
2022-07-31 14:52:08 - train: epoch 0023, iter [04800, 05004], lr: 0.100000, loss: 4.0242, tea_CELoss: 1.7185, stu_CELoss: 1.9519, DMLLoss: 0.3538, 
2022-07-31 14:53:06 - train: epoch 0023, iter [04900, 05004], lr: 0.100000, loss: 3.6482, tea_CELoss: 1.5409, stu_CELoss: 1.7352, DMLLoss: 0.3721, 
2022-07-31 14:54:04 - train: epoch 0023, iter [05000, 05004], lr: 0.100000, loss: 4.1891, tea_CELoss: 1.8214, stu_CELoss: 2.0059, DMLLoss: 0.3617, 
2022-07-31 14:54:07 - train: epoch 023, train_loss: 4.0333
2022-07-31 14:56:35 - eval: epoch: 023, tea_acc1: 62.930%, tea_acc5: 85.870%, tea_test_loss: 1.5200, stu_acc1: 59.458%, stu_acc5: 83.076%, stu_test_loss: 1.6975
2022-07-31 14:56:36 - until epoch: 023, tea_best_acc1: 63.140%, stu_best_acc1: 59.834%
2022-07-31 14:56:36 - epoch 024 lr: 0.100000
2022-07-31 14:57:40 - train: epoch 0024, iter [00100, 05004], lr: 0.100000, loss: 4.3786, tea_CELoss: 1.8897, stu_CELoss: 2.0801, DMLLoss: 0.4088, 
2022-07-31 14:58:37 - train: epoch 0024, iter [00200, 05004], lr: 0.100000, loss: 3.7798, tea_CELoss: 1.6108, stu_CELoss: 1.7978, DMLLoss: 0.3711, 
2022-07-31 14:59:35 - train: epoch 0024, iter [00300, 05004], lr: 0.100000, loss: 4.1581, tea_CELoss: 1.7358, stu_CELoss: 2.0344, DMLLoss: 0.3879, 
2022-07-31 15:00:32 - train: epoch 0024, iter [00400, 05004], lr: 0.100000, loss: 4.1840, tea_CELoss: 1.7938, stu_CELoss: 1.9841, DMLLoss: 0.4061, 
2022-07-31 15:01:30 - train: epoch 0024, iter [00500, 05004], lr: 0.100000, loss: 4.1519, tea_CELoss: 1.8155, stu_CELoss: 1.9477, DMLLoss: 0.3887, 
2022-07-31 15:02:28 - train: epoch 0024, iter [00600, 05004], lr: 0.100000, loss: 4.1853, tea_CELoss: 1.8359, stu_CELoss: 1.9661, DMLLoss: 0.3833, 
2022-07-31 15:03:25 - train: epoch 0024, iter [00700, 05004], lr: 0.100000, loss: 3.6231, tea_CELoss: 1.5753, stu_CELoss: 1.6774, DMLLoss: 0.3704, 
2022-07-31 15:04:23 - train: epoch 0024, iter [00800, 05004], lr: 0.100000, loss: 3.6169, tea_CELoss: 1.5804, stu_CELoss: 1.6586, DMLLoss: 0.3779, 
2022-07-31 15:05:21 - train: epoch 0024, iter [00900, 05004], lr: 0.100000, loss: 3.7543, tea_CELoss: 1.6321, stu_CELoss: 1.7586, DMLLoss: 0.3636, 
2022-07-31 15:06:18 - train: epoch 0024, iter [01000, 05004], lr: 0.100000, loss: 4.0212, tea_CELoss: 1.7066, stu_CELoss: 1.9159, DMLLoss: 0.3988, 
2022-07-31 15:07:16 - train: epoch 0024, iter [01100, 05004], lr: 0.100000, loss: 3.6895, tea_CELoss: 1.6001, stu_CELoss: 1.6812, DMLLoss: 0.4081, 
2022-07-31 15:08:14 - train: epoch 0024, iter [01200, 05004], lr: 0.100000, loss: 3.9148, tea_CELoss: 1.6765, stu_CELoss: 1.8182, DMLLoss: 0.4201, 
2022-07-31 15:09:11 - train: epoch 0024, iter [01300, 05004], lr: 0.100000, loss: 4.4760, tea_CELoss: 1.9994, stu_CELoss: 2.0793, DMLLoss: 0.3973, 
2022-07-31 15:10:09 - train: epoch 0024, iter [01400, 05004], lr: 0.100000, loss: 3.5248, tea_CELoss: 1.5400, stu_CELoss: 1.6482, DMLLoss: 0.3367, 
2022-07-31 15:11:07 - train: epoch 0024, iter [01500, 05004], lr: 0.100000, loss: 4.1886, tea_CELoss: 1.8409, stu_CELoss: 1.9878, DMLLoss: 0.3599, 
2022-07-31 15:12:04 - train: epoch 0024, iter [01600, 05004], lr: 0.100000, loss: 3.9695, tea_CELoss: 1.7257, stu_CELoss: 1.8935, DMLLoss: 0.3504, 
2022-07-31 15:13:02 - train: epoch 0024, iter [01700, 05004], lr: 0.100000, loss: 4.0361, tea_CELoss: 1.7673, stu_CELoss: 1.8785, DMLLoss: 0.3903, 
2022-07-31 15:14:00 - train: epoch 0024, iter [01800, 05004], lr: 0.100000, loss: 4.0872, tea_CELoss: 1.7323, stu_CELoss: 1.9494, DMLLoss: 0.4055, 
2022-07-31 15:14:57 - train: epoch 0024, iter [01900, 05004], lr: 0.100000, loss: 3.9067, tea_CELoss: 1.6517, stu_CELoss: 1.8599, DMLLoss: 0.3951, 
2022-07-31 15:15:55 - train: epoch 0024, iter [02000, 05004], lr: 0.100000, loss: 4.0709, tea_CELoss: 1.7948, stu_CELoss: 1.8746, DMLLoss: 0.4014, 
2022-07-31 15:16:53 - train: epoch 0024, iter [02100, 05004], lr: 0.100000, loss: 3.9027, tea_CELoss: 1.7002, stu_CELoss: 1.8283, DMLLoss: 0.3743, 
2022-07-31 15:17:51 - train: epoch 0024, iter [02200, 05004], lr: 0.100000, loss: 3.8478, tea_CELoss: 1.6550, stu_CELoss: 1.8581, DMLLoss: 0.3347, 
2022-07-31 15:18:49 - train: epoch 0024, iter [02300, 05004], lr: 0.100000, loss: 3.9277, tea_CELoss: 1.6398, stu_CELoss: 1.8893, DMLLoss: 0.3987, 
2022-07-31 15:19:47 - train: epoch 0024, iter [02400, 05004], lr: 0.100000, loss: 4.5794, tea_CELoss: 1.9885, stu_CELoss: 2.1477, DMLLoss: 0.4432, 
2022-07-31 15:20:44 - train: epoch 0024, iter [02500, 05004], lr: 0.100000, loss: 4.0794, tea_CELoss: 1.7717, stu_CELoss: 1.9256, DMLLoss: 0.3821, 
2022-07-31 15:21:42 - train: epoch 0024, iter [02600, 05004], lr: 0.100000, loss: 4.5741, tea_CELoss: 2.0413, stu_CELoss: 2.1121, DMLLoss: 0.4207, 
2022-07-31 15:22:40 - train: epoch 0024, iter [02700, 05004], lr: 0.100000, loss: 4.2966, tea_CELoss: 1.9012, stu_CELoss: 2.0427, DMLLoss: 0.3528, 
2022-07-31 15:23:38 - train: epoch 0024, iter [02800, 05004], lr: 0.100000, loss: 4.4391, tea_CELoss: 1.9457, stu_CELoss: 2.0951, DMLLoss: 0.3983, 
2022-07-31 15:24:36 - train: epoch 0024, iter [02900, 05004], lr: 0.100000, loss: 3.7615, tea_CELoss: 1.6195, stu_CELoss: 1.7861, DMLLoss: 0.3559, 
2022-07-31 15:25:34 - train: epoch 0024, iter [03000, 05004], lr: 0.100000, loss: 3.9091, tea_CELoss: 1.6794, stu_CELoss: 1.8357, DMLLoss: 0.3940, 
2022-07-31 15:26:32 - train: epoch 0024, iter [03100, 05004], lr: 0.100000, loss: 3.5575, tea_CELoss: 1.5068, stu_CELoss: 1.6884, DMLLoss: 0.3623, 
2022-07-31 15:27:29 - train: epoch 0024, iter [03200, 05004], lr: 0.100000, loss: 4.4119, tea_CELoss: 1.9082, stu_CELoss: 2.0827, DMLLoss: 0.4209, 
2022-07-31 15:28:27 - train: epoch 0024, iter [03300, 05004], lr: 0.100000, loss: 3.6723, tea_CELoss: 1.6146, stu_CELoss: 1.7130, DMLLoss: 0.3446, 
2022-07-31 15:29:25 - train: epoch 0024, iter [03400, 05004], lr: 0.100000, loss: 3.8424, tea_CELoss: 1.6285, stu_CELoss: 1.7638, DMLLoss: 0.4501, 
2022-07-31 15:30:23 - train: epoch 0024, iter [03500, 05004], lr: 0.100000, loss: 4.2035, tea_CELoss: 1.7962, stu_CELoss: 2.0116, DMLLoss: 0.3957, 
2022-07-31 15:31:20 - train: epoch 0024, iter [03600, 05004], lr: 0.100000, loss: 3.9934, tea_CELoss: 1.7545, stu_CELoss: 1.8546, DMLLoss: 0.3843, 
2022-07-31 15:32:18 - train: epoch 0024, iter [03700, 05004], lr: 0.100000, loss: 3.8511, tea_CELoss: 1.6501, stu_CELoss: 1.8432, DMLLoss: 0.3578, 
2022-07-31 15:33:16 - train: epoch 0024, iter [03800, 05004], lr: 0.100000, loss: 4.2472, tea_CELoss: 1.8090, stu_CELoss: 2.0643, DMLLoss: 0.3739, 
2022-07-31 15:34:13 - train: epoch 0024, iter [03900, 05004], lr: 0.100000, loss: 3.6514, tea_CELoss: 1.5889, stu_CELoss: 1.7169, DMLLoss: 0.3456, 
2022-07-31 15:35:11 - train: epoch 0024, iter [04000, 05004], lr: 0.100000, loss: 4.2069, tea_CELoss: 1.8841, stu_CELoss: 1.9508, DMLLoss: 0.3721, 
2022-07-31 15:36:08 - train: epoch 0024, iter [04100, 05004], lr: 0.100000, loss: 3.7644, tea_CELoss: 1.6751, stu_CELoss: 1.7347, DMLLoss: 0.3546, 
2022-07-31 15:37:06 - train: epoch 0024, iter [04200, 05004], lr: 0.100000, loss: 3.9004, tea_CELoss: 1.7107, stu_CELoss: 1.8195, DMLLoss: 0.3702, 
2022-07-31 15:38:04 - train: epoch 0024, iter [04300, 05004], lr: 0.100000, loss: 3.8040, tea_CELoss: 1.7017, stu_CELoss: 1.7546, DMLLoss: 0.3477, 
2022-07-31 15:39:01 - train: epoch 0024, iter [04400, 05004], lr: 0.100000, loss: 4.0312, tea_CELoss: 1.7576, stu_CELoss: 1.8990, DMLLoss: 0.3747, 
2022-07-31 15:39:59 - train: epoch 0024, iter [04500, 05004], lr: 0.100000, loss: 3.5675, tea_CELoss: 1.5276, stu_CELoss: 1.6572, DMLLoss: 0.3827, 
2022-07-31 15:40:57 - train: epoch 0024, iter [04600, 05004], lr: 0.100000, loss: 4.4897, tea_CELoss: 1.9478, stu_CELoss: 2.1665, DMLLoss: 0.3754, 
2022-07-31 15:41:54 - train: epoch 0024, iter [04700, 05004], lr: 0.100000, loss: 3.9470, tea_CELoss: 1.6675, stu_CELoss: 1.9019, DMLLoss: 0.3776, 
2022-07-31 15:42:52 - train: epoch 0024, iter [04800, 05004], lr: 0.100000, loss: 3.3543, tea_CELoss: 1.4238, stu_CELoss: 1.5794, DMLLoss: 0.3511, 
2022-07-31 15:43:50 - train: epoch 0024, iter [04900, 05004], lr: 0.100000, loss: 4.2239, tea_CELoss: 1.8357, stu_CELoss: 2.0103, DMLLoss: 0.3778, 
2022-07-31 15:44:48 - train: epoch 0024, iter [05000, 05004], lr: 0.100000, loss: 4.2808, tea_CELoss: 1.8213, stu_CELoss: 2.0496, DMLLoss: 0.4100, 
2022-07-31 15:44:50 - train: epoch 024, train_loss: 4.0204
2022-07-31 15:47:19 - eval: epoch: 024, tea_acc1: 63.050%, tea_acc5: 85.874%, tea_test_loss: 1.5190, stu_acc1: 54.454%, stu_acc5: 77.760%, stu_test_loss: 2.8358
2022-07-31 15:47:20 - until epoch: 024, tea_best_acc1: 63.140%, stu_best_acc1: 59.834%
2022-07-31 15:47:20 - epoch 025 lr: 0.100000
2022-07-31 15:48:23 - train: epoch 0025, iter [00100, 05004], lr: 0.100000, loss: 3.9170, tea_CELoss: 1.7469, stu_CELoss: 1.8305, DMLLoss: 0.3396, 
2022-07-31 15:49:21 - train: epoch 0025, iter [00200, 05004], lr: 0.100000, loss: 3.5279, tea_CELoss: 1.4605, stu_CELoss: 1.6414, DMLLoss: 0.4260, 
2022-07-31 15:50:18 - train: epoch 0025, iter [00300, 05004], lr: 0.100000, loss: 3.8706, tea_CELoss: 1.6322, stu_CELoss: 1.8336, DMLLoss: 0.4048, 
2022-07-31 15:51:16 - train: epoch 0025, iter [00400, 05004], lr: 0.100000, loss: 4.3735, tea_CELoss: 1.9051, stu_CELoss: 2.0506, DMLLoss: 0.4178, 
2022-07-31 15:52:13 - train: epoch 0025, iter [00500, 05004], lr: 0.100000, loss: 3.7920, tea_CELoss: 1.6291, stu_CELoss: 1.7600, DMLLoss: 0.4029, 
2022-07-31 15:53:11 - train: epoch 0025, iter [00600, 05004], lr: 0.100000, loss: 4.0998, tea_CELoss: 1.7875, stu_CELoss: 1.9461, DMLLoss: 0.3662, 
2022-07-31 15:54:08 - train: epoch 0025, iter [00700, 05004], lr: 0.100000, loss: 3.9247, tea_CELoss: 1.6665, stu_CELoss: 1.8455, DMLLoss: 0.4128, 
2022-07-31 15:55:06 - train: epoch 0025, iter [00800, 05004], lr: 0.100000, loss: 3.8233, tea_CELoss: 1.6026, stu_CELoss: 1.8436, DMLLoss: 0.3771, 
2022-07-31 15:56:04 - train: epoch 0025, iter [00900, 05004], lr: 0.100000, loss: 3.9290, tea_CELoss: 1.6772, stu_CELoss: 1.8583, DMLLoss: 0.3935, 
2022-07-31 15:57:01 - train: epoch 0025, iter [01000, 05004], lr: 0.100000, loss: 4.0993, tea_CELoss: 1.8139, stu_CELoss: 1.9355, DMLLoss: 0.3500, 
2022-07-31 15:57:59 - train: epoch 0025, iter [01100, 05004], lr: 0.100000, loss: 3.8616, tea_CELoss: 1.6768, stu_CELoss: 1.7865, DMLLoss: 0.3984, 
2022-07-31 15:58:56 - train: epoch 0025, iter [01200, 05004], lr: 0.100000, loss: 4.1379, tea_CELoss: 1.8061, stu_CELoss: 1.9477, DMLLoss: 0.3841, 
2022-07-31 15:59:54 - train: epoch 0025, iter [01300, 05004], lr: 0.100000, loss: 3.8210, tea_CELoss: 1.6822, stu_CELoss: 1.7955, DMLLoss: 0.3433, 
2022-07-31 16:00:52 - train: epoch 0025, iter [01400, 05004], lr: 0.100000, loss: 3.5328, tea_CELoss: 1.5029, stu_CELoss: 1.6894, DMLLoss: 0.3406, 
2022-07-31 16:01:49 - train: epoch 0025, iter [01500, 05004], lr: 0.100000, loss: 4.3904, tea_CELoss: 1.9539, stu_CELoss: 2.0547, DMLLoss: 0.3819, 
2022-07-31 16:02:47 - train: epoch 0025, iter [01600, 05004], lr: 0.100000, loss: 3.5667, tea_CELoss: 1.5409, stu_CELoss: 1.6420, DMLLoss: 0.3838, 
2022-07-31 16:03:44 - train: epoch 0025, iter [01700, 05004], lr: 0.100000, loss: 4.0377, tea_CELoss: 1.7293, stu_CELoss: 1.8917, DMLLoss: 0.4166, 
2022-07-31 16:04:42 - train: epoch 0025, iter [01800, 05004], lr: 0.100000, loss: 3.6713, tea_CELoss: 1.5302, stu_CELoss: 1.7111, DMLLoss: 0.4301, 
2022-07-31 16:05:39 - train: epoch 0025, iter [01900, 05004], lr: 0.100000, loss: 3.8131, tea_CELoss: 1.6447, stu_CELoss: 1.8160, DMLLoss: 0.3524, 
2022-07-31 16:06:37 - train: epoch 0025, iter [02000, 05004], lr: 0.100000, loss: 4.0041, tea_CELoss: 1.7140, stu_CELoss: 1.9005, DMLLoss: 0.3897, 
2022-07-31 16:07:34 - train: epoch 0025, iter [02100, 05004], lr: 0.100000, loss: 3.4081, tea_CELoss: 1.4570, stu_CELoss: 1.5865, DMLLoss: 0.3646, 
2022-07-31 16:08:32 - train: epoch 0025, iter [02200, 05004], lr: 0.100000, loss: 4.1062, tea_CELoss: 1.8301, stu_CELoss: 1.9279, DMLLoss: 0.3482, 
2022-07-31 16:09:29 - train: epoch 0025, iter [02300, 05004], lr: 0.100000, loss: 3.8902, tea_CELoss: 1.6532, stu_CELoss: 1.8456, DMLLoss: 0.3914, 
2022-07-31 16:10:27 - train: epoch 0025, iter [02400, 05004], lr: 0.100000, loss: 3.6433, tea_CELoss: 1.5863, stu_CELoss: 1.6981, DMLLoss: 0.3588, 
2022-07-31 16:11:25 - train: epoch 0025, iter [02500, 05004], lr: 0.100000, loss: 4.1489, tea_CELoss: 1.7597, stu_CELoss: 1.9899, DMLLoss: 0.3993, 
2022-07-31 16:12:22 - train: epoch 0025, iter [02600, 05004], lr: 0.100000, loss: 3.9734, tea_CELoss: 1.7264, stu_CELoss: 1.8483, DMLLoss: 0.3986, 
2022-07-31 16:13:20 - train: epoch 0025, iter [02700, 05004], lr: 0.100000, loss: 4.2552, tea_CELoss: 1.8516, stu_CELoss: 2.0133, DMLLoss: 0.3903, 
2022-07-31 16:14:17 - train: epoch 0025, iter [02800, 05004], lr: 0.100000, loss: 4.1994, tea_CELoss: 1.8026, stu_CELoss: 1.9615, DMLLoss: 0.4353, 
2022-07-31 16:15:15 - train: epoch 0025, iter [02900, 05004], lr: 0.100000, loss: 4.4328, tea_CELoss: 1.9678, stu_CELoss: 2.0683, DMLLoss: 0.3967, 
2022-07-31 16:16:12 - train: epoch 0025, iter [03000, 05004], lr: 0.100000, loss: 4.0121, tea_CELoss: 1.7041, stu_CELoss: 1.9126, DMLLoss: 0.3954, 
2022-07-31 16:17:09 - train: epoch 0025, iter [03100, 05004], lr: 0.100000, loss: 4.1464, tea_CELoss: 1.7878, stu_CELoss: 1.9697, DMLLoss: 0.3889, 
2022-07-31 16:18:07 - train: epoch 0025, iter [03200, 05004], lr: 0.100000, loss: 4.2109, tea_CELoss: 1.8258, stu_CELoss: 2.0226, DMLLoss: 0.3625, 
2022-07-31 16:19:04 - train: epoch 0025, iter [03300, 05004], lr: 0.100000, loss: 3.6264, tea_CELoss: 1.5623, stu_CELoss: 1.6849, DMLLoss: 0.3793, 
2022-07-31 16:20:01 - train: epoch 0025, iter [03400, 05004], lr: 0.100000, loss: 4.0694, tea_CELoss: 1.7350, stu_CELoss: 1.9785, DMLLoss: 0.3558, 
2022-07-31 16:20:58 - train: epoch 0025, iter [03500, 05004], lr: 0.100000, loss: 3.9462, tea_CELoss: 1.6924, stu_CELoss: 1.9018, DMLLoss: 0.3520, 
2022-07-31 16:21:56 - train: epoch 0025, iter [03600, 05004], lr: 0.100000, loss: 4.2289, tea_CELoss: 1.8566, stu_CELoss: 2.0058, DMLLoss: 0.3665, 
2022-07-31 16:22:53 - train: epoch 0025, iter [03700, 05004], lr: 0.100000, loss: 3.9582, tea_CELoss: 1.6978, stu_CELoss: 1.8984, DMLLoss: 0.3620, 
2022-07-31 16:23:50 - train: epoch 0025, iter [03800, 05004], lr: 0.100000, loss: 4.1945, tea_CELoss: 1.8484, stu_CELoss: 1.9983, DMLLoss: 0.3478, 
2022-07-31 16:24:48 - train: epoch 0025, iter [03900, 05004], lr: 0.100000, loss: 4.5777, tea_CELoss: 2.0615, stu_CELoss: 2.1122, DMLLoss: 0.4040, 
2022-07-31 16:25:45 - train: epoch 0025, iter [04000, 05004], lr: 0.100000, loss: 3.9863, tea_CELoss: 1.6926, stu_CELoss: 1.9386, DMLLoss: 0.3551, 
2022-07-31 16:26:42 - train: epoch 0025, iter [04100, 05004], lr: 0.100000, loss: 4.3998, tea_CELoss: 1.9432, stu_CELoss: 2.0725, DMLLoss: 0.3841, 
2022-07-31 16:27:40 - train: epoch 0025, iter [04200, 05004], lr: 0.100000, loss: 3.9880, tea_CELoss: 1.7568, stu_CELoss: 1.8572, DMLLoss: 0.3740, 
2022-07-31 16:28:37 - train: epoch 0025, iter [04300, 05004], lr: 0.100000, loss: 3.7556, tea_CELoss: 1.5897, stu_CELoss: 1.8211, DMLLoss: 0.3447, 
2022-07-31 16:29:35 - train: epoch 0025, iter [04400, 05004], lr: 0.100000, loss: 3.9268, tea_CELoss: 1.7226, stu_CELoss: 1.8669, DMLLoss: 0.3374, 
2022-07-31 16:30:32 - train: epoch 0025, iter [04500, 05004], lr: 0.100000, loss: 4.0078, tea_CELoss: 1.7300, stu_CELoss: 1.8977, DMLLoss: 0.3801, 
2022-07-31 16:31:29 - train: epoch 0025, iter [04600, 05004], lr: 0.100000, loss: 3.9184, tea_CELoss: 1.6675, stu_CELoss: 1.8583, DMLLoss: 0.3926, 
2022-07-31 16:32:27 - train: epoch 0025, iter [04700, 05004], lr: 0.100000, loss: 3.8813, tea_CELoss: 1.6577, stu_CELoss: 1.8142, DMLLoss: 0.4094, 
2022-07-31 16:33:24 - train: epoch 0025, iter [04800, 05004], lr: 0.100000, loss: 3.7648, tea_CELoss: 1.6247, stu_CELoss: 1.7984, DMLLoss: 0.3417, 
2022-07-31 16:34:21 - train: epoch 0025, iter [04900, 05004], lr: 0.100000, loss: 4.0669, tea_CELoss: 1.7700, stu_CELoss: 1.9047, DMLLoss: 0.3922, 
2022-07-31 16:35:18 - train: epoch 0025, iter [05000, 05004], lr: 0.100000, loss: 4.5031, tea_CELoss: 1.9741, stu_CELoss: 2.1430, DMLLoss: 0.3861, 
2022-07-31 16:35:21 - train: epoch 025, train_loss: 4.0146
2022-07-31 16:37:51 - eval: epoch: 025, tea_acc1: 61.240%, tea_acc5: 84.436%, tea_test_loss: 1.6052, stu_acc1: 56.798%, stu_acc5: 80.058%, stu_test_loss: 2.0242
2022-07-31 16:37:52 - until epoch: 025, tea_best_acc1: 63.140%, stu_best_acc1: 59.834%
2022-07-31 16:37:52 - epoch 026 lr: 0.100000
2022-07-31 16:38:55 - train: epoch 0026, iter [00100, 05004], lr: 0.100000, loss: 3.7418, tea_CELoss: 1.6017, stu_CELoss: 1.7970, DMLLoss: 0.3431, 
2022-07-31 16:39:53 - train: epoch 0026, iter [00200, 05004], lr: 0.100000, loss: 3.7474, tea_CELoss: 1.6194, stu_CELoss: 1.7404, DMLLoss: 0.3876, 
2022-07-31 16:40:51 - train: epoch 0026, iter [00300, 05004], lr: 0.100000, loss: 4.2595, tea_CELoss: 1.8384, stu_CELoss: 2.0480, DMLLoss: 0.3731, 
2022-07-31 16:41:48 - train: epoch 0026, iter [00400, 05004], lr: 0.100000, loss: 3.5883, tea_CELoss: 1.5174, stu_CELoss: 1.6769, DMLLoss: 0.3940, 
2022-07-31 16:42:46 - train: epoch 0026, iter [00500, 05004], lr: 0.100000, loss: 4.0723, tea_CELoss: 1.7409, stu_CELoss: 1.9787, DMLLoss: 0.3527, 
2022-07-31 16:43:44 - train: epoch 0026, iter [00600, 05004], lr: 0.100000, loss: 4.6075, tea_CELoss: 2.0050, stu_CELoss: 2.2416, DMLLoss: 0.3609, 
2022-07-31 16:44:41 - train: epoch 0026, iter [00700, 05004], lr: 0.100000, loss: 4.0129, tea_CELoss: 1.7991, stu_CELoss: 1.8572, DMLLoss: 0.3566, 
2022-07-31 16:45:39 - train: epoch 0026, iter [00800, 05004], lr: 0.100000, loss: 3.6371, tea_CELoss: 1.5777, stu_CELoss: 1.7074, DMLLoss: 0.3521, 
2022-07-31 16:46:37 - train: epoch 0026, iter [00900, 05004], lr: 0.100000, loss: 4.7848, tea_CELoss: 2.1337, stu_CELoss: 2.2106, DMLLoss: 0.4405, 
2022-07-31 16:47:34 - train: epoch 0026, iter [01000, 05004], lr: 0.100000, loss: 3.9669, tea_CELoss: 1.6364, stu_CELoss: 1.9150, DMLLoss: 0.4155, 
2022-07-31 16:48:32 - train: epoch 0026, iter [01100, 05004], lr: 0.100000, loss: 4.0527, tea_CELoss: 1.7187, stu_CELoss: 1.8978, DMLLoss: 0.4362, 
2022-07-31 16:49:30 - train: epoch 0026, iter [01200, 05004], lr: 0.100000, loss: 4.2395, tea_CELoss: 1.8438, stu_CELoss: 1.9895, DMLLoss: 0.4061, 
2022-07-31 16:50:27 - train: epoch 0026, iter [01300, 05004], lr: 0.100000, loss: 3.8064, tea_CELoss: 1.6853, stu_CELoss: 1.7487, DMLLoss: 0.3724, 
2022-07-31 16:51:25 - train: epoch 0026, iter [01400, 05004], lr: 0.100000, loss: 4.1264, tea_CELoss: 1.7569, stu_CELoss: 1.9479, DMLLoss: 0.4216, 
2022-07-31 16:52:23 - train: epoch 0026, iter [01500, 05004], lr: 0.100000, loss: 3.7358, tea_CELoss: 1.5920, stu_CELoss: 1.7168, DMLLoss: 0.4270, 
2022-07-31 16:53:21 - train: epoch 0026, iter [01600, 05004], lr: 0.100000, loss: 4.0562, tea_CELoss: 1.7586, stu_CELoss: 1.9380, DMLLoss: 0.3595, 
2022-07-31 16:54:18 - train: epoch 0026, iter [01700, 05004], lr: 0.100000, loss: 3.8777, tea_CELoss: 1.6755, stu_CELoss: 1.8232, DMLLoss: 0.3791, 
2022-07-31 16:55:16 - train: epoch 0026, iter [01800, 05004], lr: 0.100000, loss: 4.4542, tea_CELoss: 2.0049, stu_CELoss: 2.1071, DMLLoss: 0.3422, 
2022-07-31 16:56:14 - train: epoch 0026, iter [01900, 05004], lr: 0.100000, loss: 4.2345, tea_CELoss: 1.8619, stu_CELoss: 1.9922, DMLLoss: 0.3803, 
2022-07-31 16:57:11 - train: epoch 0026, iter [02000, 05004], lr: 0.100000, loss: 4.1783, tea_CELoss: 1.8641, stu_CELoss: 1.9479, DMLLoss: 0.3663, 
2022-07-31 16:58:09 - train: epoch 0026, iter [02100, 05004], lr: 0.100000, loss: 3.8254, tea_CELoss: 1.6978, stu_CELoss: 1.7311, DMLLoss: 0.3965, 
2022-07-31 16:59:07 - train: epoch 0026, iter [02200, 05004], lr: 0.100000, loss: 4.0325, tea_CELoss: 1.7362, stu_CELoss: 1.8692, DMLLoss: 0.4271, 
2022-07-31 17:00:05 - train: epoch 0026, iter [02300, 05004], lr: 0.100000, loss: 3.9551, tea_CELoss: 1.7185, stu_CELoss: 1.8594, DMLLoss: 0.3772, 
2022-07-31 17:01:02 - train: epoch 0026, iter [02400, 05004], lr: 0.100000, loss: 4.1503, tea_CELoss: 1.8145, stu_CELoss: 1.9374, DMLLoss: 0.3984, 
2022-07-31 17:02:00 - train: epoch 0026, iter [02500, 05004], lr: 0.100000, loss: 4.2553, tea_CELoss: 1.8423, stu_CELoss: 2.0245, DMLLoss: 0.3884, 
2022-07-31 17:02:58 - train: epoch 0026, iter [02600, 05004], lr: 0.100000, loss: 4.3662, tea_CELoss: 1.9207, stu_CELoss: 2.0546, DMLLoss: 0.3910, 
2022-07-31 17:03:56 - train: epoch 0026, iter [02700, 05004], lr: 0.100000, loss: 4.4742, tea_CELoss: 1.9737, stu_CELoss: 2.0681, DMLLoss: 0.4324, 
2022-07-31 17:04:54 - train: epoch 0026, iter [02800, 05004], lr: 0.100000, loss: 4.0440, tea_CELoss: 1.8018, stu_CELoss: 1.8494, DMLLoss: 0.3928, 
2022-07-31 17:05:51 - train: epoch 0026, iter [02900, 05004], lr: 0.100000, loss: 4.3892, tea_CELoss: 1.8976, stu_CELoss: 2.0588, DMLLoss: 0.4328, 
2022-07-31 17:06:49 - train: epoch 0026, iter [03000, 05004], lr: 0.100000, loss: 3.9266, tea_CELoss: 1.6699, stu_CELoss: 1.8899, DMLLoss: 0.3668, 
2022-07-31 17:07:47 - train: epoch 0026, iter [03100, 05004], lr: 0.100000, loss: 4.2227, tea_CELoss: 1.8409, stu_CELoss: 1.9879, DMLLoss: 0.3939, 
2022-07-31 17:08:45 - train: epoch 0026, iter [03200, 05004], lr: 0.100000, loss: 4.0859, tea_CELoss: 1.7893, stu_CELoss: 1.9103, DMLLoss: 0.3863, 
2022-07-31 17:09:43 - train: epoch 0026, iter [03300, 05004], lr: 0.100000, loss: 3.9605, tea_CELoss: 1.7126, stu_CELoss: 1.8541, DMLLoss: 0.3938, 
2022-07-31 17:10:41 - train: epoch 0026, iter [03400, 05004], lr: 0.100000, loss: 4.1129, tea_CELoss: 1.8041, stu_CELoss: 1.9459, DMLLoss: 0.3629, 
2022-07-31 17:11:38 - train: epoch 0026, iter [03500, 05004], lr: 0.100000, loss: 4.2427, tea_CELoss: 1.8905, stu_CELoss: 2.0077, DMLLoss: 0.3445, 
2022-07-31 17:12:36 - train: epoch 0026, iter [03600, 05004], lr: 0.100000, loss: 3.6466, tea_CELoss: 1.6155, stu_CELoss: 1.6848, DMLLoss: 0.3462, 
2022-07-31 17:13:34 - train: epoch 0026, iter [03700, 05004], lr: 0.100000, loss: 3.9211, tea_CELoss: 1.7741, stu_CELoss: 1.8006, DMLLoss: 0.3464, 
2022-07-31 17:14:32 - train: epoch 0026, iter [03800, 05004], lr: 0.100000, loss: 4.3077, tea_CELoss: 1.8752, stu_CELoss: 2.0335, DMLLoss: 0.3990, 
2022-07-31 17:15:30 - train: epoch 0026, iter [03900, 05004], lr: 0.100000, loss: 4.2050, tea_CELoss: 1.8282, stu_CELoss: 2.0052, DMLLoss: 0.3717, 
2022-07-31 17:16:27 - train: epoch 0026, iter [04000, 05004], lr: 0.100000, loss: 4.0952, tea_CELoss: 1.7701, stu_CELoss: 1.9297, DMLLoss: 0.3954, 
2022-07-31 17:17:25 - train: epoch 0026, iter [04100, 05004], lr: 0.100000, loss: 3.9616, tea_CELoss: 1.7660, stu_CELoss: 1.8470, DMLLoss: 0.3486, 
2022-07-31 17:18:23 - train: epoch 0026, iter [04200, 05004], lr: 0.100000, loss: 4.2499, tea_CELoss: 1.9039, stu_CELoss: 2.0050, DMLLoss: 0.3411, 
2022-07-31 17:19:21 - train: epoch 0026, iter [04300, 05004], lr: 0.100000, loss: 4.3167, tea_CELoss: 1.8915, stu_CELoss: 2.0419, DMLLoss: 0.3834, 
2022-07-31 17:20:18 - train: epoch 0026, iter [04400, 05004], lr: 0.100000, loss: 4.2389, tea_CELoss: 1.8779, stu_CELoss: 2.0030, DMLLoss: 0.3581, 
2022-07-31 17:21:16 - train: epoch 0026, iter [04500, 05004], lr: 0.100000, loss: 4.8077, tea_CELoss: 2.0458, stu_CELoss: 2.3410, DMLLoss: 0.4210, 
2022-07-31 17:22:14 - train: epoch 0026, iter [04600, 05004], lr: 0.100000, loss: 4.0587, tea_CELoss: 1.7787, stu_CELoss: 1.8829, DMLLoss: 0.3971, 
2022-07-31 17:23:12 - train: epoch 0026, iter [04700, 05004], lr: 0.100000, loss: 3.7670, tea_CELoss: 1.6100, stu_CELoss: 1.7617, DMLLoss: 0.3953, 
2022-07-31 17:24:09 - train: epoch 0026, iter [04800, 05004], lr: 0.100000, loss: 3.7635, tea_CELoss: 1.6256, stu_CELoss: 1.7705, DMLLoss: 0.3675, 
2022-07-31 17:25:07 - train: epoch 0026, iter [04900, 05004], lr: 0.100000, loss: 4.1713, tea_CELoss: 1.8283, stu_CELoss: 1.9162, DMLLoss: 0.4267, 
2022-07-31 17:26:05 - train: epoch 0026, iter [05000, 05004], lr: 0.100000, loss: 4.1673, tea_CELoss: 1.8611, stu_CELoss: 1.9647, DMLLoss: 0.3415, 
2022-07-31 17:26:08 - train: epoch 026, train_loss: 4.0071
2022-07-31 17:28:36 - eval: epoch: 026, tea_acc1: 62.508%, tea_acc5: 85.790%, tea_test_loss: 1.5311, stu_acc1: 58.516%, stu_acc5: 82.796%, stu_test_loss: 1.7243
2022-07-31 17:28:37 - until epoch: 026, tea_best_acc1: 63.140%, stu_best_acc1: 59.834%
2022-07-31 17:28:37 - epoch 027 lr: 0.100000
2022-07-31 17:29:41 - train: epoch 0027, iter [00100, 05004], lr: 0.100000, loss: 3.8709, tea_CELoss: 1.6461, stu_CELoss: 1.8436, DMLLoss: 0.3812, 
2022-07-31 17:30:39 - train: epoch 0027, iter [00200, 05004], lr: 0.100000, loss: 3.9646, tea_CELoss: 1.7241, stu_CELoss: 1.8364, DMLLoss: 0.4042, 
2022-07-31 17:31:37 - train: epoch 0027, iter [00300, 05004], lr: 0.100000, loss: 4.3212, tea_CELoss: 1.8987, stu_CELoss: 2.0274, DMLLoss: 0.3951, 
2022-07-31 17:32:35 - train: epoch 0027, iter [00400, 05004], lr: 0.100000, loss: 4.3315, tea_CELoss: 1.9390, stu_CELoss: 1.9984, DMLLoss: 0.3941, 
2022-07-31 17:33:32 - train: epoch 0027, iter [00500, 05004], lr: 0.100000, loss: 3.8369, tea_CELoss: 1.6487, stu_CELoss: 1.7874, DMLLoss: 0.4008, 
2022-07-31 17:34:30 - train: epoch 0027, iter [00600, 05004], lr: 0.100000, loss: 4.1693, tea_CELoss: 1.8347, stu_CELoss: 1.9383, DMLLoss: 0.3962, 
2022-07-31 17:35:28 - train: epoch 0027, iter [00700, 05004], lr: 0.100000, loss: 3.8903, tea_CELoss: 1.7185, stu_CELoss: 1.8461, DMLLoss: 0.3257, 
2022-07-31 17:36:25 - train: epoch 0027, iter [00800, 05004], lr: 0.100000, loss: 3.9226, tea_CELoss: 1.7204, stu_CELoss: 1.8171, DMLLoss: 0.3851, 
2022-07-31 17:37:23 - train: epoch 0027, iter [00900, 05004], lr: 0.100000, loss: 4.0567, tea_CELoss: 1.7208, stu_CELoss: 1.8985, DMLLoss: 0.4374, 
2022-07-31 17:38:20 - train: epoch 0027, iter [01000, 05004], lr: 0.100000, loss: 3.8711, tea_CELoss: 1.6197, stu_CELoss: 1.8523, DMLLoss: 0.3991, 
2022-07-31 17:39:18 - train: epoch 0027, iter [01100, 05004], lr: 0.100000, loss: 3.8025, tea_CELoss: 1.6808, stu_CELoss: 1.7559, DMLLoss: 0.3658, 
2022-07-31 17:40:16 - train: epoch 0027, iter [01200, 05004], lr: 0.100000, loss: 4.2393, tea_CELoss: 1.8494, stu_CELoss: 2.0158, DMLLoss: 0.3741, 
2022-07-31 17:41:13 - train: epoch 0027, iter [01300, 05004], lr: 0.100000, loss: 3.8094, tea_CELoss: 1.6187, stu_CELoss: 1.7807, DMLLoss: 0.4100, 
2022-07-31 17:42:11 - train: epoch 0027, iter [01400, 05004], lr: 0.100000, loss: 4.1566, tea_CELoss: 1.7873, stu_CELoss: 2.0045, DMLLoss: 0.3648, 
2022-07-31 17:43:09 - train: epoch 0027, iter [01500, 05004], lr: 0.100000, loss: 4.2795, tea_CELoss: 1.8610, stu_CELoss: 2.0157, DMLLoss: 0.4029, 
2022-07-31 17:44:07 - train: epoch 0027, iter [01600, 05004], lr: 0.100000, loss: 4.1888, tea_CELoss: 1.7920, stu_CELoss: 1.9785, DMLLoss: 0.4183, 
2022-07-31 17:45:04 - train: epoch 0027, iter [01700, 05004], lr: 0.100000, loss: 3.7314, tea_CELoss: 1.6768, stu_CELoss: 1.7296, DMLLoss: 0.3250, 
2022-07-31 17:46:02 - train: epoch 0027, iter [01800, 05004], lr: 0.100000, loss: 3.6101, tea_CELoss: 1.5325, stu_CELoss: 1.6741, DMLLoss: 0.4036, 
2022-07-31 17:46:59 - train: epoch 0027, iter [01900, 05004], lr: 0.100000, loss: 4.2253, tea_CELoss: 1.8233, stu_CELoss: 2.0059, DMLLoss: 0.3961, 
2022-07-31 17:47:57 - train: epoch 0027, iter [02000, 05004], lr: 0.100000, loss: 3.8878, tea_CELoss: 1.6883, stu_CELoss: 1.8116, DMLLoss: 0.3879, 
2022-07-31 17:48:55 - train: epoch 0027, iter [02100, 05004], lr: 0.100000, loss: 4.3455, tea_CELoss: 1.9296, stu_CELoss: 2.0373, DMLLoss: 0.3787, 
2022-07-31 17:49:53 - train: epoch 0027, iter [02200, 05004], lr: 0.100000, loss: 4.4669, tea_CELoss: 1.9518, stu_CELoss: 2.0704, DMLLoss: 0.4447, 
2022-07-31 17:50:51 - train: epoch 0027, iter [02300, 05004], lr: 0.100000, loss: 4.3679, tea_CELoss: 1.9079, stu_CELoss: 2.0799, DMLLoss: 0.3801, 
2022-07-31 17:51:49 - train: epoch 0027, iter [02400, 05004], lr: 0.100000, loss: 3.9805, tea_CELoss: 1.7879, stu_CELoss: 1.8367, DMLLoss: 0.3559, 
2022-07-31 17:52:47 - train: epoch 0027, iter [02500, 05004], lr: 0.100000, loss: 3.8907, tea_CELoss: 1.6907, stu_CELoss: 1.8152, DMLLoss: 0.3848, 
2022-07-31 17:53:45 - train: epoch 0027, iter [02600, 05004], lr: 0.100000, loss: 4.2485, tea_CELoss: 1.8790, stu_CELoss: 1.9824, DMLLoss: 0.3871, 
2022-07-31 17:54:43 - train: epoch 0027, iter [02700, 05004], lr: 0.100000, loss: 3.9260, tea_CELoss: 1.7435, stu_CELoss: 1.7989, DMLLoss: 0.3836, 
2022-07-31 17:55:41 - train: epoch 0027, iter [02800, 05004], lr: 0.100000, loss: 4.2172, tea_CELoss: 1.7953, stu_CELoss: 2.0113, DMLLoss: 0.4106, 
2022-07-31 17:56:39 - train: epoch 0027, iter [02900, 05004], lr: 0.100000, loss: 4.2734, tea_CELoss: 1.8926, stu_CELoss: 1.9561, DMLLoss: 0.4247, 
2022-07-31 17:57:37 - train: epoch 0027, iter [03000, 05004], lr: 0.100000, loss: 3.9868, tea_CELoss: 1.7209, stu_CELoss: 1.9020, DMLLoss: 0.3640, 
2022-07-31 17:58:35 - train: epoch 0027, iter [03100, 05004], lr: 0.100000, loss: 3.7135, tea_CELoss: 1.5960, stu_CELoss: 1.7357, DMLLoss: 0.3818, 
2022-07-31 17:59:33 - train: epoch 0027, iter [03200, 05004], lr: 0.100000, loss: 3.5581, tea_CELoss: 1.4842, stu_CELoss: 1.6732, DMLLoss: 0.4007, 
2022-07-31 18:00:31 - train: epoch 0027, iter [03300, 05004], lr: 0.100000, loss: 4.1224, tea_CELoss: 1.7637, stu_CELoss: 1.9457, DMLLoss: 0.4130, 
2022-07-31 18:01:29 - train: epoch 0027, iter [03400, 05004], lr: 0.100000, loss: 3.7452, tea_CELoss: 1.5763, stu_CELoss: 1.7824, DMLLoss: 0.3864, 
2022-07-31 18:02:27 - train: epoch 0027, iter [03500, 05004], lr: 0.100000, loss: 4.5201, tea_CELoss: 1.8673, stu_CELoss: 2.2237, DMLLoss: 0.4291, 
2022-07-31 18:03:25 - train: epoch 0027, iter [03600, 05004], lr: 0.100000, loss: 4.3118, tea_CELoss: 1.8447, stu_CELoss: 2.0414, DMLLoss: 0.4257, 
2022-07-31 18:04:23 - train: epoch 0027, iter [03700, 05004], lr: 0.100000, loss: 4.1090, tea_CELoss: 1.8289, stu_CELoss: 1.9302, DMLLoss: 0.3498, 
2022-07-31 18:05:21 - train: epoch 0027, iter [03800, 05004], lr: 0.100000, loss: 3.4843, tea_CELoss: 1.4682, stu_CELoss: 1.6415, DMLLoss: 0.3746, 
2022-07-31 18:06:19 - train: epoch 0027, iter [03900, 05004], lr: 0.100000, loss: 3.9605, tea_CELoss: 1.7590, stu_CELoss: 1.8145, DMLLoss: 0.3870, 
2022-07-31 18:07:17 - train: epoch 0027, iter [04000, 05004], lr: 0.100000, loss: 4.3223, tea_CELoss: 1.8970, stu_CELoss: 2.0026, DMLLoss: 0.4227, 
2022-07-31 18:08:15 - train: epoch 0027, iter [04100, 05004], lr: 0.100000, loss: 4.0127, tea_CELoss: 1.7166, stu_CELoss: 1.9472, DMLLoss: 0.3489, 
2022-07-31 18:09:13 - train: epoch 0027, iter [04200, 05004], lr: 0.100000, loss: 4.0358, tea_CELoss: 1.7370, stu_CELoss: 1.9164, DMLLoss: 0.3824, 
2022-07-31 18:10:11 - train: epoch 0027, iter [04300, 05004], lr: 0.100000, loss: 3.8423, tea_CELoss: 1.6443, stu_CELoss: 1.8269, DMLLoss: 0.3711, 
2022-07-31 18:11:09 - train: epoch 0027, iter [04400, 05004], lr: 0.100000, loss: 4.0819, tea_CELoss: 1.7998, stu_CELoss: 1.9165, DMLLoss: 0.3656, 
2022-07-31 18:12:07 - train: epoch 0027, iter [04500, 05004], lr: 0.100000, loss: 3.9088, tea_CELoss: 1.7033, stu_CELoss: 1.8252, DMLLoss: 0.3804, 
2022-07-31 18:13:05 - train: epoch 0027, iter [04600, 05004], lr: 0.100000, loss: 3.7780, tea_CELoss: 1.6479, stu_CELoss: 1.7759, DMLLoss: 0.3542, 
2022-07-31 18:14:03 - train: epoch 0027, iter [04700, 05004], lr: 0.100000, loss: 4.4946, tea_CELoss: 1.9683, stu_CELoss: 2.1496, DMLLoss: 0.3767, 
2022-07-31 18:15:01 - train: epoch 0027, iter [04800, 05004], lr: 0.100000, loss: 4.2865, tea_CELoss: 1.8864, stu_CELoss: 2.0278, DMLLoss: 0.3722, 
2022-07-31 18:15:59 - train: epoch 0027, iter [04900, 05004], lr: 0.100000, loss: 3.8302, tea_CELoss: 1.6737, stu_CELoss: 1.7878, DMLLoss: 0.3688, 
2022-07-31 18:16:57 - train: epoch 0027, iter [05000, 05004], lr: 0.100000, loss: 3.8117, tea_CELoss: 1.6380, stu_CELoss: 1.8078, DMLLoss: 0.3659, 
2022-07-31 18:17:00 - train: epoch 027, train_loss: 3.9976
2022-07-31 18:19:30 - eval: epoch: 027, tea_acc1: 63.550%, tea_acc5: 86.018%, tea_test_loss: 1.5101, stu_acc1: 60.812%, stu_acc5: 84.048%, stu_test_loss: 1.6333
2022-07-31 18:19:32 - until epoch: 027, tea_best_acc1: 63.550%, stu_best_acc1: 60.812%
2022-07-31 18:19:32 - epoch 028 lr: 0.100000
2022-07-31 18:20:35 - train: epoch 0028, iter [00100, 05004], lr: 0.100000, loss: 3.5313, tea_CELoss: 1.4993, stu_CELoss: 1.6593, DMLLoss: 0.3728, 
2022-07-31 18:21:33 - train: epoch 0028, iter [00200, 05004], lr: 0.100000, loss: 3.8824, tea_CELoss: 1.6580, stu_CELoss: 1.8320, DMLLoss: 0.3924, 
2022-07-31 18:22:30 - train: epoch 0028, iter [00300, 05004], lr: 0.100000, loss: 4.1425, tea_CELoss: 1.7922, stu_CELoss: 1.9410, DMLLoss: 0.4093, 
2022-07-31 18:23:28 - train: epoch 0028, iter [00400, 05004], lr: 0.100000, loss: 3.9977, tea_CELoss: 1.7819, stu_CELoss: 1.8388, DMLLoss: 0.3770, 
2022-07-31 18:24:26 - train: epoch 0028, iter [00500, 05004], lr: 0.100000, loss: 3.7113, tea_CELoss: 1.5961, stu_CELoss: 1.7287, DMLLoss: 0.3864, 
2022-07-31 18:25:23 - train: epoch 0028, iter [00600, 05004], lr: 0.100000, loss: 4.4229, tea_CELoss: 1.9000, stu_CELoss: 2.1093, DMLLoss: 0.4137, 
2022-07-31 18:26:21 - train: epoch 0028, iter [00700, 05004], lr: 0.100000, loss: 4.2663, tea_CELoss: 1.8364, stu_CELoss: 2.0247, DMLLoss: 0.4051, 
2022-07-31 18:27:19 - train: epoch 0028, iter [00800, 05004], lr: 0.100000, loss: 3.5797, tea_CELoss: 1.5493, stu_CELoss: 1.6667, DMLLoss: 0.3638, 
2022-07-31 18:28:16 - train: epoch 0028, iter [00900, 05004], lr: 0.100000, loss: 3.7082, tea_CELoss: 1.6073, stu_CELoss: 1.7577, DMLLoss: 0.3433, 
2022-07-31 18:29:14 - train: epoch 0028, iter [01000, 05004], lr: 0.100000, loss: 4.0507, tea_CELoss: 1.7480, stu_CELoss: 1.9235, DMLLoss: 0.3791, 
2022-07-31 18:30:11 - train: epoch 0028, iter [01100, 05004], lr: 0.100000, loss: 3.5688, tea_CELoss: 1.5120, stu_CELoss: 1.6688, DMLLoss: 0.3881, 
2022-07-31 18:31:09 - train: epoch 0028, iter [01200, 05004], lr: 0.100000, loss: 3.9475, tea_CELoss: 1.7106, stu_CELoss: 1.8846, DMLLoss: 0.3523, 
2022-07-31 18:32:06 - train: epoch 0028, iter [01300, 05004], lr: 0.100000, loss: 4.1105, tea_CELoss: 1.7524, stu_CELoss: 1.9337, DMLLoss: 0.4245, 
2022-07-31 18:33:04 - train: epoch 0028, iter [01400, 05004], lr: 0.100000, loss: 4.2967, tea_CELoss: 1.8819, stu_CELoss: 2.0279, DMLLoss: 0.3869, 
2022-07-31 18:34:02 - train: epoch 0028, iter [01500, 05004], lr: 0.100000, loss: 4.0513, tea_CELoss: 1.7328, stu_CELoss: 1.9348, DMLLoss: 0.3838, 
2022-07-31 18:34:59 - train: epoch 0028, iter [01600, 05004], lr: 0.100000, loss: 3.9111, tea_CELoss: 1.6714, stu_CELoss: 1.8389, DMLLoss: 0.4008, 
2022-07-31 18:35:57 - train: epoch 0028, iter [01700, 05004], lr: 0.100000, loss: 4.1520, tea_CELoss: 1.8310, stu_CELoss: 1.9379, DMLLoss: 0.3831, 
2022-07-31 18:36:55 - train: epoch 0028, iter [01800, 05004], lr: 0.100000, loss: 3.8362, tea_CELoss: 1.6787, stu_CELoss: 1.7922, DMLLoss: 0.3654, 
2022-07-31 18:37:52 - train: epoch 0028, iter [01900, 05004], lr: 0.100000, loss: 4.0545, tea_CELoss: 1.7449, stu_CELoss: 1.9063, DMLLoss: 0.4032, 
2022-07-31 18:38:50 - train: epoch 0028, iter [02000, 05004], lr: 0.100000, loss: 4.0070, tea_CELoss: 1.7241, stu_CELoss: 1.8972, DMLLoss: 0.3858, 
2022-07-31 18:39:47 - train: epoch 0028, iter [02100, 05004], lr: 0.100000, loss: 4.6269, tea_CELoss: 2.0002, stu_CELoss: 2.2024, DMLLoss: 0.4243, 
2022-07-31 18:40:45 - train: epoch 0028, iter [02200, 05004], lr: 0.100000, loss: 4.0424, tea_CELoss: 1.7632, stu_CELoss: 1.9420, DMLLoss: 0.3373, 
2022-07-31 18:41:43 - train: epoch 0028, iter [02300, 05004], lr: 0.100000, loss: 3.8748, tea_CELoss: 1.6786, stu_CELoss: 1.8005, DMLLoss: 0.3957, 
2022-07-31 18:42:40 - train: epoch 0028, iter [02400, 05004], lr: 0.100000, loss: 4.1230, tea_CELoss: 1.7701, stu_CELoss: 1.9349, DMLLoss: 0.4181, 
2022-07-31 18:43:38 - train: epoch 0028, iter [02500, 05004], lr: 0.100000, loss: 4.1584, tea_CELoss: 1.8458, stu_CELoss: 1.9124, DMLLoss: 0.4003, 
2022-07-31 18:44:35 - train: epoch 0028, iter [02600, 05004], lr: 0.100000, loss: 3.7778, tea_CELoss: 1.6316, stu_CELoss: 1.7963, DMLLoss: 0.3498, 
2022-07-31 18:45:33 - train: epoch 0028, iter [02700, 05004], lr: 0.100000, loss: 3.8474, tea_CELoss: 1.6603, stu_CELoss: 1.7964, DMLLoss: 0.3907, 
2022-07-31 18:46:31 - train: epoch 0028, iter [02800, 05004], lr: 0.100000, loss: 4.1503, tea_CELoss: 1.8459, stu_CELoss: 1.9648, DMLLoss: 0.3396, 
2022-07-31 18:47:28 - train: epoch 0028, iter [02900, 05004], lr: 0.100000, loss: 4.3484, tea_CELoss: 1.9334, stu_CELoss: 2.0353, DMLLoss: 0.3797, 
2022-07-31 18:48:26 - train: epoch 0028, iter [03000, 05004], lr: 0.100000, loss: 4.1021, tea_CELoss: 1.7726, stu_CELoss: 1.9460, DMLLoss: 0.3835, 
2022-07-31 18:49:24 - train: epoch 0028, iter [03100, 05004], lr: 0.100000, loss: 4.0629, tea_CELoss: 1.7766, stu_CELoss: 1.9057, DMLLoss: 0.3805, 
2022-07-31 18:50:22 - train: epoch 0028, iter [03200, 05004], lr: 0.100000, loss: 3.6209, tea_CELoss: 1.5629, stu_CELoss: 1.7237, DMLLoss: 0.3343, 
2022-07-31 18:51:20 - train: epoch 0028, iter [03300, 05004], lr: 0.100000, loss: 4.2179, tea_CELoss: 1.8576, stu_CELoss: 1.9528, DMLLoss: 0.4075, 
2022-07-31 18:52:18 - train: epoch 0028, iter [03400, 05004], lr: 0.100000, loss: 4.3569, tea_CELoss: 1.8953, stu_CELoss: 2.0427, DMLLoss: 0.4189, 
2022-07-31 18:53:16 - train: epoch 0028, iter [03500, 05004], lr: 0.100000, loss: 4.1014, tea_CELoss: 1.7679, stu_CELoss: 1.9291, DMLLoss: 0.4043, 
2022-07-31 18:54:14 - train: epoch 0028, iter [03600, 05004], lr: 0.100000, loss: 3.7883, tea_CELoss: 1.6444, stu_CELoss: 1.8145, DMLLoss: 0.3294, 
2022-07-31 18:55:12 - train: epoch 0028, iter [03700, 05004], lr: 0.100000, loss: 4.0332, tea_CELoss: 1.7239, stu_CELoss: 1.9262, DMLLoss: 0.3831, 
2022-07-31 18:56:10 - train: epoch 0028, iter [03800, 05004], lr: 0.100000, loss: 3.3965, tea_CELoss: 1.4265, stu_CELoss: 1.6006, DMLLoss: 0.3694, 
2022-07-31 18:57:08 - train: epoch 0028, iter [03900, 05004], lr: 0.100000, loss: 4.3432, tea_CELoss: 1.8794, stu_CELoss: 2.0271, DMLLoss: 0.4367, 
2022-07-31 18:58:07 - train: epoch 0028, iter [04000, 05004], lr: 0.100000, loss: 4.2955, tea_CELoss: 1.8719, stu_CELoss: 2.0243, DMLLoss: 0.3993, 
2022-07-31 18:59:05 - train: epoch 0028, iter [04100, 05004], lr: 0.100000, loss: 4.1360, tea_CELoss: 1.8027, stu_CELoss: 1.9483, DMLLoss: 0.3851, 
2022-07-31 19:00:03 - train: epoch 0028, iter [04200, 05004], lr: 0.100000, loss: 4.2903, tea_CELoss: 1.8965, stu_CELoss: 2.0462, DMLLoss: 0.3476, 
2022-07-31 19:01:01 - train: epoch 0028, iter [04300, 05004], lr: 0.100000, loss: 3.9260, tea_CELoss: 1.7400, stu_CELoss: 1.8176, DMLLoss: 0.3684, 
2022-07-31 19:01:59 - train: epoch 0028, iter [04400, 05004], lr: 0.100000, loss: 3.8180, tea_CELoss: 1.6899, stu_CELoss: 1.7896, DMLLoss: 0.3385, 
2022-07-31 19:02:57 - train: epoch 0028, iter [04500, 05004], lr: 0.100000, loss: 4.1388, tea_CELoss: 1.8011, stu_CELoss: 1.9522, DMLLoss: 0.3855, 
2022-07-31 19:03:55 - train: epoch 0028, iter [04600, 05004], lr: 0.100000, loss: 4.1100, tea_CELoss: 1.7926, stu_CELoss: 1.9555, DMLLoss: 0.3619, 
2022-07-31 19:04:53 - train: epoch 0028, iter [04700, 05004], lr: 0.100000, loss: 4.3818, tea_CELoss: 1.9001, stu_CELoss: 2.0842, DMLLoss: 0.3975, 
2022-07-31 19:05:51 - train: epoch 0028, iter [04800, 05004], lr: 0.100000, loss: 3.7665, tea_CELoss: 1.6157, stu_CELoss: 1.7927, DMLLoss: 0.3581, 
2022-07-31 19:06:49 - train: epoch 0028, iter [04900, 05004], lr: 0.100000, loss: 4.3053, tea_CELoss: 1.8276, stu_CELoss: 2.0457, DMLLoss: 0.4320, 
2022-07-31 19:07:47 - train: epoch 0028, iter [05000, 05004], lr: 0.100000, loss: 3.8300, tea_CELoss: 1.6638, stu_CELoss: 1.7817, DMLLoss: 0.3845, 
2022-07-31 19:07:50 - train: epoch 028, train_loss: 3.9866
2022-07-31 19:10:19 - eval: epoch: 028, tea_acc1: 64.104%, tea_acc5: 86.208%, tea_test_loss: 1.4862, stu_acc1: 59.940%, stu_acc5: 83.364%, stu_test_loss: 1.6726
2022-07-31 19:10:21 - until epoch: 028, tea_best_acc1: 64.104%, stu_best_acc1: 60.812%
2022-07-31 19:10:21 - epoch 029 lr: 0.100000
2022-07-31 19:11:24 - train: epoch 0029, iter [00100, 05004], lr: 0.100000, loss: 3.8888, tea_CELoss: 1.7128, stu_CELoss: 1.7917, DMLLoss: 0.3844, 
2022-07-31 19:12:22 - train: epoch 0029, iter [00200, 05004], lr: 0.100000, loss: 3.8220, tea_CELoss: 1.6117, stu_CELoss: 1.8268, DMLLoss: 0.3835, 
2022-07-31 19:13:19 - train: epoch 0029, iter [00300, 05004], lr: 0.100000, loss: 4.4207, tea_CELoss: 1.9594, stu_CELoss: 2.1038, DMLLoss: 0.3575, 
2022-07-31 19:14:17 - train: epoch 0029, iter [00400, 05004], lr: 0.100000, loss: 4.2442, tea_CELoss: 1.8133, stu_CELoss: 2.0453, DMLLoss: 0.3856, 
2022-07-31 19:15:14 - train: epoch 0029, iter [00500, 05004], lr: 0.100000, loss: 4.2131, tea_CELoss: 1.8088, stu_CELoss: 1.9903, DMLLoss: 0.4141, 
2022-07-31 19:16:12 - train: epoch 0029, iter [00600, 05004], lr: 0.100000, loss: 4.1212, tea_CELoss: 1.7717, stu_CELoss: 1.9314, DMLLoss: 0.4181, 
2022-07-31 19:17:10 - train: epoch 0029, iter [00700, 05004], lr: 0.100000, loss: 3.1035, tea_CELoss: 1.2857, stu_CELoss: 1.4572, DMLLoss: 0.3606, 
2022-07-31 19:18:07 - train: epoch 0029, iter [00800, 05004], lr: 0.100000, loss: 4.1539, tea_CELoss: 1.7878, stu_CELoss: 1.9447, DMLLoss: 0.4213, 
2022-07-31 19:19:05 - train: epoch 0029, iter [00900, 05004], lr: 0.100000, loss: 3.9891, tea_CELoss: 1.7722, stu_CELoss: 1.8600, DMLLoss: 0.3570, 
2022-07-31 19:20:03 - train: epoch 0029, iter [01000, 05004], lr: 0.100000, loss: 3.9703, tea_CELoss: 1.7269, stu_CELoss: 1.8939, DMLLoss: 0.3495, 
2022-07-31 19:21:00 - train: epoch 0029, iter [01100, 05004], lr: 0.100000, loss: 3.9936, tea_CELoss: 1.7455, stu_CELoss: 1.8474, DMLLoss: 0.4006, 
2022-07-31 19:21:58 - train: epoch 0029, iter [01200, 05004], lr: 0.100000, loss: 3.9854, tea_CELoss: 1.6830, stu_CELoss: 1.8956, DMLLoss: 0.4067, 
2022-07-31 19:22:56 - train: epoch 0029, iter [01300, 05004], lr: 0.100000, loss: 3.8889, tea_CELoss: 1.6740, stu_CELoss: 1.8418, DMLLoss: 0.3731, 
2022-07-31 19:23:54 - train: epoch 0029, iter [01400, 05004], lr: 0.100000, loss: 4.0775, tea_CELoss: 1.6930, stu_CELoss: 1.9478, DMLLoss: 0.4367, 
2022-07-31 19:24:52 - train: epoch 0029, iter [01500, 05004], lr: 0.100000, loss: 3.9578, tea_CELoss: 1.6974, stu_CELoss: 1.8734, DMLLoss: 0.3871, 
2022-07-31 19:25:50 - train: epoch 0029, iter [01600, 05004], lr: 0.100000, loss: 4.0716, tea_CELoss: 1.7329, stu_CELoss: 1.9727, DMLLoss: 0.3660, 
2022-07-31 19:26:48 - train: epoch 0029, iter [01700, 05004], lr: 0.100000, loss: 3.6646, tea_CELoss: 1.5997, stu_CELoss: 1.7021, DMLLoss: 0.3627, 
2022-07-31 19:27:46 - train: epoch 0029, iter [01800, 05004], lr: 0.100000, loss: 4.2753, tea_CELoss: 1.8847, stu_CELoss: 1.9945, DMLLoss: 0.3962, 
2022-07-31 19:28:43 - train: epoch 0029, iter [01900, 05004], lr: 0.100000, loss: 3.9021, tea_CELoss: 1.6924, stu_CELoss: 1.8272, DMLLoss: 0.3825, 
2022-07-31 19:29:41 - train: epoch 0029, iter [02000, 05004], lr: 0.100000, loss: 3.7677, tea_CELoss: 1.6565, stu_CELoss: 1.7769, DMLLoss: 0.3343, 
2022-07-31 19:30:38 - train: epoch 0029, iter [02100, 05004], lr: 0.100000, loss: 3.9461, tea_CELoss: 1.7255, stu_CELoss: 1.8585, DMLLoss: 0.3621, 
2022-07-31 19:31:36 - train: epoch 0029, iter [02200, 05004], lr: 0.100000, loss: 4.0598, tea_CELoss: 1.7938, stu_CELoss: 1.9108, DMLLoss: 0.3552, 
2022-07-31 19:32:33 - train: epoch 0029, iter [02300, 05004], lr: 0.100000, loss: 4.1093, tea_CELoss: 1.7810, stu_CELoss: 1.9353, DMLLoss: 0.3929, 
2022-07-31 19:33:31 - train: epoch 0029, iter [02400, 05004], lr: 0.100000, loss: 3.6263, tea_CELoss: 1.5746, stu_CELoss: 1.6833, DMLLoss: 0.3684, 
2022-07-31 19:34:29 - train: epoch 0029, iter [02500, 05004], lr: 0.100000, loss: 4.0414, tea_CELoss: 1.7928, stu_CELoss: 1.8908, DMLLoss: 0.3577, 
2022-07-31 19:35:27 - train: epoch 0029, iter [02600, 05004], lr: 0.100000, loss: 4.2076, tea_CELoss: 1.8861, stu_CELoss: 1.9519, DMLLoss: 0.3695, 
2022-07-31 19:36:24 - train: epoch 0029, iter [02700, 05004], lr: 0.100000, loss: 4.0497, tea_CELoss: 1.7272, stu_CELoss: 1.9118, DMLLoss: 0.4107, 
2022-07-31 19:37:22 - train: epoch 0029, iter [02800, 05004], lr: 0.100000, loss: 3.8486, tea_CELoss: 1.7182, stu_CELoss: 1.7863, DMLLoss: 0.3440, 
2022-07-31 19:38:20 - train: epoch 0029, iter [02900, 05004], lr: 0.100000, loss: 4.2126, tea_CELoss: 1.8687, stu_CELoss: 1.9452, DMLLoss: 0.3988, 
2022-07-31 19:39:17 - train: epoch 0029, iter [03000, 05004], lr: 0.100000, loss: 4.0178, tea_CELoss: 1.7339, stu_CELoss: 1.8898, DMLLoss: 0.3940, 
2022-07-31 19:40:15 - train: epoch 0029, iter [03100, 05004], lr: 0.100000, loss: 4.1196, tea_CELoss: 1.7806, stu_CELoss: 1.9658, DMLLoss: 0.3732, 
2022-07-31 19:41:13 - train: epoch 0029, iter [03200, 05004], lr: 0.100000, loss: 4.1017, tea_CELoss: 1.8459, stu_CELoss: 1.8540, DMLLoss: 0.4018, 
2022-07-31 19:42:11 - train: epoch 0029, iter [03300, 05004], lr: 0.100000, loss: 3.6575, tea_CELoss: 1.5731, stu_CELoss: 1.7486, DMLLoss: 0.3359, 
2022-07-31 19:43:08 - train: epoch 0029, iter [03400, 05004], lr: 0.100000, loss: 3.7417, tea_CELoss: 1.5700, stu_CELoss: 1.8082, DMLLoss: 0.3634, 
2022-07-31 19:44:06 - train: epoch 0029, iter [03500, 05004], lr: 0.100000, loss: 3.9564, tea_CELoss: 1.6882, stu_CELoss: 1.8945, DMLLoss: 0.3737, 
2022-07-31 19:45:04 - train: epoch 0029, iter [03600, 05004], lr: 0.100000, loss: 3.8246, tea_CELoss: 1.6478, stu_CELoss: 1.7773, DMLLoss: 0.3995, 
2022-07-31 19:46:02 - train: epoch 0029, iter [03700, 05004], lr: 0.100000, loss: 3.7895, tea_CELoss: 1.6459, stu_CELoss: 1.7683, DMLLoss: 0.3754, 
2022-07-31 19:46:59 - train: epoch 0029, iter [03800, 05004], lr: 0.100000, loss: 3.8146, tea_CELoss: 1.7368, stu_CELoss: 1.7460, DMLLoss: 0.3318, 
2022-07-31 19:47:57 - train: epoch 0029, iter [03900, 05004], lr: 0.100000, loss: 3.7075, tea_CELoss: 1.6277, stu_CELoss: 1.7242, DMLLoss: 0.3556, 
2022-07-31 19:48:55 - train: epoch 0029, iter [04000, 05004], lr: 0.100000, loss: 4.0086, tea_CELoss: 1.7617, stu_CELoss: 1.8371, DMLLoss: 0.4098, 
2022-07-31 19:49:53 - train: epoch 0029, iter [04100, 05004], lr: 0.100000, loss: 4.2948, tea_CELoss: 1.8568, stu_CELoss: 2.0172, DMLLoss: 0.4209, 
2022-07-31 19:50:50 - train: epoch 0029, iter [04200, 05004], lr: 0.100000, loss: 3.8984, tea_CELoss: 1.7018, stu_CELoss: 1.8411, DMLLoss: 0.3556, 
2022-07-31 19:51:48 - train: epoch 0029, iter [04300, 05004], lr: 0.100000, loss: 4.4051, tea_CELoss: 1.8891, stu_CELoss: 2.0952, DMLLoss: 0.4208, 
2022-07-31 19:52:45 - train: epoch 0029, iter [04400, 05004], lr: 0.100000, loss: 4.1924, tea_CELoss: 1.8892, stu_CELoss: 1.9540, DMLLoss: 0.3492, 
2022-07-31 19:53:43 - train: epoch 0029, iter [04500, 05004], lr: 0.100000, loss: 4.4733, tea_CELoss: 1.9742, stu_CELoss: 2.0990, DMLLoss: 0.4001, 
2022-07-31 19:54:40 - train: epoch 0029, iter [04600, 05004], lr: 0.100000, loss: 4.0492, tea_CELoss: 1.7884, stu_CELoss: 1.8981, DMLLoss: 0.3627, 
2022-07-31 19:55:38 - train: epoch 0029, iter [04700, 05004], lr: 0.100000, loss: 3.4848, tea_CELoss: 1.4908, stu_CELoss: 1.6513, DMLLoss: 0.3427, 
2022-07-31 19:56:35 - train: epoch 0029, iter [04800, 05004], lr: 0.100000, loss: 3.8482, tea_CELoss: 1.6820, stu_CELoss: 1.7535, DMLLoss: 0.4127, 
2022-07-31 19:57:33 - train: epoch 0029, iter [04900, 05004], lr: 0.100000, loss: 4.3535, tea_CELoss: 1.9259, stu_CELoss: 2.0359, DMLLoss: 0.3917, 
2022-07-31 19:58:30 - train: epoch 0029, iter [05000, 05004], lr: 0.100000, loss: 3.5113, tea_CELoss: 1.5492, stu_CELoss: 1.6363, DMLLoss: 0.3259, 
2022-07-31 19:58:33 - train: epoch 029, train_loss: 3.9841
2022-07-31 20:01:01 - eval: epoch: 029, tea_acc1: 63.898%, tea_acc5: 86.064%, tea_test_loss: 1.4915, stu_acc1: 60.822%, stu_acc5: 83.974%, stu_test_loss: 1.6377
2022-07-31 20:01:02 - until epoch: 029, tea_best_acc1: 64.104%, stu_best_acc1: 60.822%
2022-07-31 20:01:02 - epoch 030 lr: 0.100000
2022-07-31 20:02:06 - train: epoch 0030, iter [00100, 05004], lr: 0.100000, loss: 4.0215, tea_CELoss: 1.7405, stu_CELoss: 1.9135, DMLLoss: 0.3676, 
2022-07-31 20:03:03 - train: epoch 0030, iter [00200, 05004], lr: 0.100000, loss: 3.8216, tea_CELoss: 1.6202, stu_CELoss: 1.7613, DMLLoss: 0.4402, 
2022-07-31 20:04:01 - train: epoch 0030, iter [00300, 05004], lr: 0.100000, loss: 3.6371, tea_CELoss: 1.5372, stu_CELoss: 1.7074, DMLLoss: 0.3926, 
2022-07-31 20:04:58 - train: epoch 0030, iter [00400, 05004], lr: 0.100000, loss: 3.8916, tea_CELoss: 1.6717, stu_CELoss: 1.8086, DMLLoss: 0.4113, 
2022-07-31 20:05:56 - train: epoch 0030, iter [00500, 05004], lr: 0.100000, loss: 4.1019, tea_CELoss: 1.8099, stu_CELoss: 1.8954, DMLLoss: 0.3966, 
2022-07-31 20:06:53 - train: epoch 0030, iter [00600, 05004], lr: 0.100000, loss: 3.7778, tea_CELoss: 1.6528, stu_CELoss: 1.7283, DMLLoss: 0.3968, 
2022-07-31 20:07:51 - train: epoch 0030, iter [00700, 05004], lr: 0.100000, loss: 3.6906, tea_CELoss: 1.6140, stu_CELoss: 1.7146, DMLLoss: 0.3620, 
2022-07-31 20:08:48 - train: epoch 0030, iter [00800, 05004], lr: 0.100000, loss: 4.0339, tea_CELoss: 1.8150, stu_CELoss: 1.8465, DMLLoss: 0.3724, 
2022-07-31 20:09:46 - train: epoch 0030, iter [00900, 05004], lr: 0.100000, loss: 3.9669, tea_CELoss: 1.7202, stu_CELoss: 1.8790, DMLLoss: 0.3677, 
2022-07-31 20:10:43 - train: epoch 0030, iter [01000, 05004], lr: 0.100000, loss: 3.6924, tea_CELoss: 1.5910, stu_CELoss: 1.7001, DMLLoss: 0.4014, 
2022-07-31 20:11:41 - train: epoch 0030, iter [01100, 05004], lr: 0.100000, loss: 3.6468, tea_CELoss: 1.5965, stu_CELoss: 1.6909, DMLLoss: 0.3594, 
2022-07-31 20:12:38 - train: epoch 0030, iter [01200, 05004], lr: 0.100000, loss: 4.0476, tea_CELoss: 1.7404, stu_CELoss: 1.9346, DMLLoss: 0.3726, 
2022-07-31 20:13:36 - train: epoch 0030, iter [01300, 05004], lr: 0.100000, loss: 3.6661, tea_CELoss: 1.5998, stu_CELoss: 1.7188, DMLLoss: 0.3475, 
2022-07-31 20:14:33 - train: epoch 0030, iter [01400, 05004], lr: 0.100000, loss: 3.5701, tea_CELoss: 1.5331, stu_CELoss: 1.6761, DMLLoss: 0.3609, 
2022-07-31 20:15:31 - train: epoch 0030, iter [01500, 05004], lr: 0.100000, loss: 3.7858, tea_CELoss: 1.6362, stu_CELoss: 1.7574, DMLLoss: 0.3923, 
2022-07-31 20:16:28 - train: epoch 0030, iter [01600, 05004], lr: 0.100000, loss: 3.9894, tea_CELoss: 1.7247, stu_CELoss: 1.8577, DMLLoss: 0.4070, 
2022-07-31 20:17:26 - train: epoch 0030, iter [01700, 05004], lr: 0.100000, loss: 4.3593, tea_CELoss: 1.8924, stu_CELoss: 2.0910, DMLLoss: 0.3759, 
2022-07-31 20:18:24 - train: epoch 0030, iter [01800, 05004], lr: 0.100000, loss: 4.0428, tea_CELoss: 1.7287, stu_CELoss: 1.9112, DMLLoss: 0.4029, 
2022-07-31 20:19:21 - train: epoch 0030, iter [01900, 05004], lr: 0.100000, loss: 4.1439, tea_CELoss: 1.8149, stu_CELoss: 1.9282, DMLLoss: 0.4008, 
2022-07-31 20:20:19 - train: epoch 0030, iter [02000, 05004], lr: 0.100000, loss: 3.8226, tea_CELoss: 1.6504, stu_CELoss: 1.8006, DMLLoss: 0.3716, 
2022-07-31 20:21:17 - train: epoch 0030, iter [02100, 05004], lr: 0.100000, loss: 4.2503, tea_CELoss: 1.8460, stu_CELoss: 2.0061, DMLLoss: 0.3982, 
2022-07-31 20:22:15 - train: epoch 0030, iter [02200, 05004], lr: 0.100000, loss: 4.0468, tea_CELoss: 1.7917, stu_CELoss: 1.8787, DMLLoss: 0.3764, 
2022-07-31 20:23:13 - train: epoch 0030, iter [02300, 05004], lr: 0.100000, loss: 4.0031, tea_CELoss: 1.6706, stu_CELoss: 1.9358, DMLLoss: 0.3967, 
2022-07-31 20:24:10 - train: epoch 0030, iter [02400, 05004], lr: 0.100000, loss: 4.1720, tea_CELoss: 1.7974, stu_CELoss: 1.9842, DMLLoss: 0.3904, 
2022-07-31 20:25:08 - train: epoch 0030, iter [02500, 05004], lr: 0.100000, loss: 4.2902, tea_CELoss: 1.9086, stu_CELoss: 2.0045, DMLLoss: 0.3771, 
2022-07-31 20:26:06 - train: epoch 0030, iter [02600, 05004], lr: 0.100000, loss: 4.1022, tea_CELoss: 1.7274, stu_CELoss: 1.9806, DMLLoss: 0.3942, 
2022-07-31 20:27:03 - train: epoch 0030, iter [02700, 05004], lr: 0.100000, loss: 3.6910, tea_CELoss: 1.5927, stu_CELoss: 1.7500, DMLLoss: 0.3483, 
2022-07-31 20:28:01 - train: epoch 0030, iter [02800, 05004], lr: 0.100000, loss: 3.9237, tea_CELoss: 1.7252, stu_CELoss: 1.8458, DMLLoss: 0.3527, 
2022-07-31 20:28:58 - train: epoch 0030, iter [02900, 05004], lr: 0.100000, loss: 3.6398, tea_CELoss: 1.5741, stu_CELoss: 1.7029, DMLLoss: 0.3629, 
2022-07-31 20:29:56 - train: epoch 0030, iter [03000, 05004], lr: 0.100000, loss: 4.5412, tea_CELoss: 1.9940, stu_CELoss: 2.1269, DMLLoss: 0.4203, 
2022-07-31 20:30:54 - train: epoch 0030, iter [03100, 05004], lr: 0.100000, loss: 4.0298, tea_CELoss: 1.7565, stu_CELoss: 1.9171, DMLLoss: 0.3563, 
2022-07-31 20:31:51 - train: epoch 0030, iter [03200, 05004], lr: 0.100000, loss: 3.6859, tea_CELoss: 1.5915, stu_CELoss: 1.7117, DMLLoss: 0.3826, 
2022-07-31 20:32:49 - train: epoch 0030, iter [03300, 05004], lr: 0.100000, loss: 4.1967, tea_CELoss: 1.8506, stu_CELoss: 1.9913, DMLLoss: 0.3547, 
2022-07-31 20:33:47 - train: epoch 0030, iter [03400, 05004], lr: 0.100000, loss: 3.7058, tea_CELoss: 1.6115, stu_CELoss: 1.6793, DMLLoss: 0.4150, 
2022-07-31 20:34:44 - train: epoch 0030, iter [03500, 05004], lr: 0.100000, loss: 4.1987, tea_CELoss: 1.8025, stu_CELoss: 1.9911, DMLLoss: 0.4051, 
2022-07-31 20:35:42 - train: epoch 0030, iter [03600, 05004], lr: 0.100000, loss: 4.0909, tea_CELoss: 1.8163, stu_CELoss: 1.8750, DMLLoss: 0.3996, 
2022-07-31 20:36:40 - train: epoch 0030, iter [03700, 05004], lr: 0.100000, loss: 3.8119, tea_CELoss: 1.6857, stu_CELoss: 1.8021, DMLLoss: 0.3241, 
2022-07-31 20:37:37 - train: epoch 0030, iter [03800, 05004], lr: 0.100000, loss: 3.7062, tea_CELoss: 1.5878, stu_CELoss: 1.7790, DMLLoss: 0.3394, 
2022-07-31 20:38:35 - train: epoch 0030, iter [03900, 05004], lr: 0.100000, loss: 3.5844, tea_CELoss: 1.5413, stu_CELoss: 1.6704, DMLLoss: 0.3727, 
2022-07-31 20:39:33 - train: epoch 0030, iter [04000, 05004], lr: 0.100000, loss: 4.0013, tea_CELoss: 1.7404, stu_CELoss: 1.8993, DMLLoss: 0.3616, 
2022-07-31 20:40:31 - train: epoch 0030, iter [04100, 05004], lr: 0.100000, loss: 3.9583, tea_CELoss: 1.7313, stu_CELoss: 1.8755, DMLLoss: 0.3515, 
2022-07-31 20:41:29 - train: epoch 0030, iter [04200, 05004], lr: 0.100000, loss: 4.2027, tea_CELoss: 1.8124, stu_CELoss: 1.9969, DMLLoss: 0.3934, 
2022-07-31 20:42:26 - train: epoch 0030, iter [04300, 05004], lr: 0.100000, loss: 3.9770, tea_CELoss: 1.7517, stu_CELoss: 1.8456, DMLLoss: 0.3796, 
2022-07-31 20:43:24 - train: epoch 0030, iter [04400, 05004], lr: 0.100000, loss: 3.9539, tea_CELoss: 1.7625, stu_CELoss: 1.8496, DMLLoss: 0.3419, 
2022-07-31 20:44:22 - train: epoch 0030, iter [04500, 05004], lr: 0.100000, loss: 4.1706, tea_CELoss: 1.7998, stu_CELoss: 1.9617, DMLLoss: 0.4091, 
2022-07-31 20:45:19 - train: epoch 0030, iter [04600, 05004], lr: 0.100000, loss: 3.6832, tea_CELoss: 1.6126, stu_CELoss: 1.7120, DMLLoss: 0.3587, 
2022-07-31 20:46:17 - train: epoch 0030, iter [04700, 05004], lr: 0.100000, loss: 3.8677, tea_CELoss: 1.6555, stu_CELoss: 1.8528, DMLLoss: 0.3595, 
2022-07-31 20:47:14 - train: epoch 0030, iter [04800, 05004], lr: 0.100000, loss: 3.8678, tea_CELoss: 1.6509, stu_CELoss: 1.8480, DMLLoss: 0.3689, 
2022-07-31 20:48:12 - train: epoch 0030, iter [04900, 05004], lr: 0.100000, loss: 4.2213, tea_CELoss: 1.8825, stu_CELoss: 1.9654, DMLLoss: 0.3735, 
2022-07-31 20:49:10 - train: epoch 0030, iter [05000, 05004], lr: 0.100000, loss: 4.1227, tea_CELoss: 1.7896, stu_CELoss: 1.9475, DMLLoss: 0.3856, 
2022-07-31 20:49:12 - train: epoch 030, train_loss: 3.9731
2022-07-31 20:51:43 - eval: epoch: 030, tea_acc1: 63.578%, tea_acc5: 86.002%, tea_test_loss: 1.5012, stu_acc1: 60.658%, stu_acc5: 84.004%, stu_test_loss: 1.6527
2022-07-31 20:51:44 - until epoch: 030, tea_best_acc1: 64.104%, stu_best_acc1: 60.822%
2022-07-31 20:51:44 - epoch 031 lr: 0.010000
2022-07-31 20:52:47 - train: epoch 0031, iter [00100, 05004], lr: 0.010000, loss: 3.4977, tea_CELoss: 1.5398, stu_CELoss: 1.7198, DMLLoss: 0.2380, 
2022-07-31 20:53:44 - train: epoch 0031, iter [00200, 05004], lr: 0.010000, loss: 3.2803, tea_CELoss: 1.5193, stu_CELoss: 1.5558, DMLLoss: 0.2052, 
2022-07-31 20:54:42 - train: epoch 0031, iter [00300, 05004], lr: 0.010000, loss: 3.1284, tea_CELoss: 1.4118, stu_CELoss: 1.4785, DMLLoss: 0.2381, 
2022-07-31 20:55:39 - train: epoch 0031, iter [00400, 05004], lr: 0.010000, loss: 3.2232, tea_CELoss: 1.4265, stu_CELoss: 1.5641, DMLLoss: 0.2327, 
2022-07-31 20:56:36 - train: epoch 0031, iter [00500, 05004], lr: 0.010000, loss: 3.3854, tea_CELoss: 1.5071, stu_CELoss: 1.6482, DMLLoss: 0.2302, 
2022-07-31 20:57:33 - train: epoch 0031, iter [00600, 05004], lr: 0.010000, loss: 2.9872, tea_CELoss: 1.2982, stu_CELoss: 1.4792, DMLLoss: 0.2097, 
2022-07-31 20:58:30 - train: epoch 0031, iter [00700, 05004], lr: 0.010000, loss: 3.2785, tea_CELoss: 1.4726, stu_CELoss: 1.5744, DMLLoss: 0.2315, 
2022-07-31 20:59:28 - train: epoch 0031, iter [00800, 05004], lr: 0.010000, loss: 3.0845, tea_CELoss: 1.4053, stu_CELoss: 1.4961, DMLLoss: 0.1831, 
2022-07-31 21:00:26 - train: epoch 0031, iter [00900, 05004], lr: 0.010000, loss: 3.1840, tea_CELoss: 1.4004, stu_CELoss: 1.5527, DMLLoss: 0.2308, 
2022-07-31 21:01:23 - train: epoch 0031, iter [01000, 05004], lr: 0.010000, loss: 3.5273, tea_CELoss: 1.5847, stu_CELoss: 1.7183, DMLLoss: 0.2243, 
2022-07-31 21:02:21 - train: epoch 0031, iter [01100, 05004], lr: 0.010000, loss: 3.1950, tea_CELoss: 1.4301, stu_CELoss: 1.5454, DMLLoss: 0.2196, 
2022-07-31 21:03:18 - train: epoch 0031, iter [01200, 05004], lr: 0.010000, loss: 3.2565, tea_CELoss: 1.4430, stu_CELoss: 1.5831, DMLLoss: 0.2304, 
2022-07-31 21:04:16 - train: epoch 0031, iter [01300, 05004], lr: 0.010000, loss: 2.4645, tea_CELoss: 1.1032, stu_CELoss: 1.1817, DMLLoss: 0.1795, 
2022-07-31 21:05:13 - train: epoch 0031, iter [01400, 05004], lr: 0.010000, loss: 3.0786, tea_CELoss: 1.3822, stu_CELoss: 1.4985, DMLLoss: 0.1979, 
2022-07-31 21:06:11 - train: epoch 0031, iter [01500, 05004], lr: 0.010000, loss: 3.1995, tea_CELoss: 1.4119, stu_CELoss: 1.5808, DMLLoss: 0.2068, 
2022-07-31 21:07:08 - train: epoch 0031, iter [01600, 05004], lr: 0.010000, loss: 2.9802, tea_CELoss: 1.3081, stu_CELoss: 1.4924, DMLLoss: 0.1797, 
2022-07-31 21:08:05 - train: epoch 0031, iter [01700, 05004], lr: 0.010000, loss: 3.0931, tea_CELoss: 1.3976, stu_CELoss: 1.5095, DMLLoss: 0.1860, 
2022-07-31 21:09:03 - train: epoch 0031, iter [01800, 05004], lr: 0.010000, loss: 2.4574, tea_CELoss: 1.0898, stu_CELoss: 1.1908, DMLLoss: 0.1768, 
2022-07-31 21:10:00 - train: epoch 0031, iter [01900, 05004], lr: 0.010000, loss: 2.8304, tea_CELoss: 1.2427, stu_CELoss: 1.4063, DMLLoss: 0.1814, 
2022-07-31 21:10:58 - train: epoch 0031, iter [02000, 05004], lr: 0.010000, loss: 2.9759, tea_CELoss: 1.3052, stu_CELoss: 1.4704, DMLLoss: 0.2002, 
2022-07-31 21:11:55 - train: epoch 0031, iter [02100, 05004], lr: 0.010000, loss: 2.5956, tea_CELoss: 1.0995, stu_CELoss: 1.3165, DMLLoss: 0.1796, 
2022-07-31 21:12:53 - train: epoch 0031, iter [02200, 05004], lr: 0.010000, loss: 2.6459, tea_CELoss: 1.1456, stu_CELoss: 1.3009, DMLLoss: 0.1994, 
2022-07-31 21:13:50 - train: epoch 0031, iter [02300, 05004], lr: 0.010000, loss: 2.8420, tea_CELoss: 1.2725, stu_CELoss: 1.4063, DMLLoss: 0.1632, 
2022-07-31 21:14:47 - train: epoch 0031, iter [02400, 05004], lr: 0.010000, loss: 2.8333, tea_CELoss: 1.2502, stu_CELoss: 1.3958, DMLLoss: 0.1873, 
2022-07-31 21:15:45 - train: epoch 0031, iter [02500, 05004], lr: 0.010000, loss: 3.3490, tea_CELoss: 1.4931, stu_CELoss: 1.6461, DMLLoss: 0.2098, 
2022-07-31 21:16:42 - train: epoch 0031, iter [02600, 05004], lr: 0.010000, loss: 3.0754, tea_CELoss: 1.3300, stu_CELoss: 1.5469, DMLLoss: 0.1985, 
2022-07-31 21:17:40 - train: epoch 0031, iter [02700, 05004], lr: 0.010000, loss: 3.1133, tea_CELoss: 1.3789, stu_CELoss: 1.5166, DMLLoss: 0.2178, 
2022-07-31 21:18:37 - train: epoch 0031, iter [02800, 05004], lr: 0.010000, loss: 3.0259, tea_CELoss: 1.3301, stu_CELoss: 1.5222, DMLLoss: 0.1736, 
2022-07-31 21:19:35 - train: epoch 0031, iter [02900, 05004], lr: 0.010000, loss: 3.2919, tea_CELoss: 1.5138, stu_CELoss: 1.5992, DMLLoss: 0.1789, 
2022-07-31 21:20:33 - train: epoch 0031, iter [03000, 05004], lr: 0.010000, loss: 3.6580, tea_CELoss: 1.6351, stu_CELoss: 1.8153, DMLLoss: 0.2076, 
2022-07-31 21:21:30 - train: epoch 0031, iter [03100, 05004], lr: 0.010000, loss: 2.8827, tea_CELoss: 1.2650, stu_CELoss: 1.4342, DMLLoss: 0.1835, 
2022-07-31 21:22:27 - train: epoch 0031, iter [03200, 05004], lr: 0.010000, loss: 3.0774, tea_CELoss: 1.3821, stu_CELoss: 1.4920, DMLLoss: 0.2034, 
2022-07-31 21:23:25 - train: epoch 0031, iter [03300, 05004], lr: 0.010000, loss: 2.6780, tea_CELoss: 1.1989, stu_CELoss: 1.3093, DMLLoss: 0.1697, 
2022-07-31 21:24:23 - train: epoch 0031, iter [03400, 05004], lr: 0.010000, loss: 3.3332, tea_CELoss: 1.4714, stu_CELoss: 1.6572, DMLLoss: 0.2046, 
2022-07-31 21:25:20 - train: epoch 0031, iter [03500, 05004], lr: 0.010000, loss: 3.0519, tea_CELoss: 1.3789, stu_CELoss: 1.4811, DMLLoss: 0.1918, 
2022-07-31 21:26:18 - train: epoch 0031, iter [03600, 05004], lr: 0.010000, loss: 2.9821, tea_CELoss: 1.3428, stu_CELoss: 1.4585, DMLLoss: 0.1808, 
2022-07-31 21:27:15 - train: epoch 0031, iter [03700, 05004], lr: 0.010000, loss: 2.7223, tea_CELoss: 1.1954, stu_CELoss: 1.3493, DMLLoss: 0.1776, 
2022-07-31 21:28:13 - train: epoch 0031, iter [03800, 05004], lr: 0.010000, loss: 2.6922, tea_CELoss: 1.1947, stu_CELoss: 1.3004, DMLLoss: 0.1971, 
2022-07-31 21:29:10 - train: epoch 0031, iter [03900, 05004], lr: 0.010000, loss: 2.7316, tea_CELoss: 1.1874, stu_CELoss: 1.3661, DMLLoss: 0.1781, 
2022-07-31 21:30:08 - train: epoch 0031, iter [04000, 05004], lr: 0.010000, loss: 2.6431, tea_CELoss: 1.1648, stu_CELoss: 1.3012, DMLLoss: 0.1771, 
2022-07-31 21:31:05 - train: epoch 0031, iter [04100, 05004], lr: 0.010000, loss: 2.9610, tea_CELoss: 1.3481, stu_CELoss: 1.4421, DMLLoss: 0.1708, 
2022-07-31 21:32:03 - train: epoch 0031, iter [04200, 05004], lr: 0.010000, loss: 2.9002, tea_CELoss: 1.2827, stu_CELoss: 1.4237, DMLLoss: 0.1938, 
2022-07-31 21:33:01 - train: epoch 0031, iter [04300, 05004], lr: 0.010000, loss: 2.8709, tea_CELoss: 1.2923, stu_CELoss: 1.4186, DMLLoss: 0.1599, 
2022-07-31 21:33:59 - train: epoch 0031, iter [04400, 05004], lr: 0.010000, loss: 3.2115, tea_CELoss: 1.4528, stu_CELoss: 1.5850, DMLLoss: 0.1737, 
2022-07-31 21:34:56 - train: epoch 0031, iter [04500, 05004], lr: 0.010000, loss: 2.8145, tea_CELoss: 1.2511, stu_CELoss: 1.3930, DMLLoss: 0.1704, 
2022-07-31 21:35:54 - train: epoch 0031, iter [04600, 05004], lr: 0.010000, loss: 2.8339, tea_CELoss: 1.2479, stu_CELoss: 1.3992, DMLLoss: 0.1868, 
2022-07-31 21:36:52 - train: epoch 0031, iter [04700, 05004], lr: 0.010000, loss: 2.4272, tea_CELoss: 1.0771, stu_CELoss: 1.1923, DMLLoss: 0.1578, 
2022-07-31 21:37:49 - train: epoch 0031, iter [04800, 05004], lr: 0.010000, loss: 2.7677, tea_CELoss: 1.2651, stu_CELoss: 1.3449, DMLLoss: 0.1577, 
2022-07-31 21:38:47 - train: epoch 0031, iter [04900, 05004], lr: 0.010000, loss: 2.8608, tea_CELoss: 1.3154, stu_CELoss: 1.3614, DMLLoss: 0.1839, 
2022-07-31 21:39:45 - train: epoch 0031, iter [05000, 05004], lr: 0.010000, loss: 2.7522, tea_CELoss: 1.2454, stu_CELoss: 1.3514, DMLLoss: 0.1555, 
2022-07-31 21:39:48 - train: epoch 031, train_loss: 2.9596
2022-07-31 21:42:19 - eval: epoch: 031, tea_acc1: 73.714%, tea_acc5: 91.622%, tea_test_loss: 1.0433, stu_acc1: 71.418%, stu_acc5: 90.316%, stu_test_loss: 1.1512
2022-07-31 21:42:20 - until epoch: 031, tea_best_acc1: 73.714%, stu_best_acc1: 71.418%
2022-07-31 21:42:20 - epoch 032 lr: 0.010000
2022-07-31 21:43:23 - train: epoch 0032, iter [00100, 05004], lr: 0.010000, loss: 2.3719, tea_CELoss: 1.0573, stu_CELoss: 1.1443, DMLLoss: 0.1703, 
2022-07-31 21:44:21 - train: epoch 0032, iter [00200, 05004], lr: 0.010000, loss: 2.3855, tea_CELoss: 1.0331, stu_CELoss: 1.1969, DMLLoss: 0.1556, 
2022-07-31 21:45:18 - train: epoch 0032, iter [00300, 05004], lr: 0.010000, loss: 2.5319, tea_CELoss: 1.1312, stu_CELoss: 1.2416, DMLLoss: 0.1591, 
2022-07-31 21:46:16 - train: epoch 0032, iter [00400, 05004], lr: 0.010000, loss: 3.0321, tea_CELoss: 1.3465, stu_CELoss: 1.5111, DMLLoss: 0.1745, 
2022-07-31 21:47:13 - train: epoch 0032, iter [00500, 05004], lr: 0.010000, loss: 2.5864, tea_CELoss: 1.1276, stu_CELoss: 1.2867, DMLLoss: 0.1721, 
2022-07-31 21:48:11 - train: epoch 0032, iter [00600, 05004], lr: 0.010000, loss: 2.7740, tea_CELoss: 1.2442, stu_CELoss: 1.3631, DMLLoss: 0.1666, 
2022-07-31 21:49:08 - train: epoch 0032, iter [00700, 05004], lr: 0.010000, loss: 2.6408, tea_CELoss: 1.1616, stu_CELoss: 1.2984, DMLLoss: 0.1807, 
2022-07-31 21:50:06 - train: epoch 0032, iter [00800, 05004], lr: 0.010000, loss: 2.9855, tea_CELoss: 1.3160, stu_CELoss: 1.4890, DMLLoss: 0.1805, 
2022-07-31 21:51:03 - train: epoch 0032, iter [00900, 05004], lr: 0.010000, loss: 2.5499, tea_CELoss: 1.0995, stu_CELoss: 1.2558, DMLLoss: 0.1946, 
2022-07-31 21:52:01 - train: epoch 0032, iter [01000, 05004], lr: 0.010000, loss: 3.1060, tea_CELoss: 1.3524, stu_CELoss: 1.5683, DMLLoss: 0.1853, 
2022-07-31 21:52:58 - train: epoch 0032, iter [01100, 05004], lr: 0.010000, loss: 2.6864, tea_CELoss: 1.1722, stu_CELoss: 1.3221, DMLLoss: 0.1921, 
2022-07-31 21:53:56 - train: epoch 0032, iter [01200, 05004], lr: 0.010000, loss: 2.6869, tea_CELoss: 1.2033, stu_CELoss: 1.3243, DMLLoss: 0.1593, 
2022-07-31 21:54:53 - train: epoch 0032, iter [01300, 05004], lr: 0.010000, loss: 2.6983, tea_CELoss: 1.1950, stu_CELoss: 1.3296, DMLLoss: 0.1737, 
2022-07-31 21:55:50 - train: epoch 0032, iter [01400, 05004], lr: 0.010000, loss: 2.7364, tea_CELoss: 1.2222, stu_CELoss: 1.3531, DMLLoss: 0.1611, 
2022-07-31 21:56:47 - train: epoch 0032, iter [01500, 05004], lr: 0.010000, loss: 2.9717, tea_CELoss: 1.3368, stu_CELoss: 1.4454, DMLLoss: 0.1895, 
2022-07-31 21:57:44 - train: epoch 0032, iter [01600, 05004], lr: 0.010000, loss: 3.2046, tea_CELoss: 1.4278, stu_CELoss: 1.5822, DMLLoss: 0.1946, 
2022-07-31 21:58:41 - train: epoch 0032, iter [01700, 05004], lr: 0.010000, loss: 3.0428, tea_CELoss: 1.3427, stu_CELoss: 1.4964, DMLLoss: 0.2037, 
2022-07-31 21:59:38 - train: epoch 0032, iter [01800, 05004], lr: 0.010000, loss: 3.3859, tea_CELoss: 1.5084, stu_CELoss: 1.6802, DMLLoss: 0.1972, 
2022-07-31 22:00:36 - train: epoch 0032, iter [01900, 05004], lr: 0.010000, loss: 2.1726, tea_CELoss: 0.9505, stu_CELoss: 1.0624, DMLLoss: 0.1597, 
2022-07-31 22:01:33 - train: epoch 0032, iter [02000, 05004], lr: 0.010000, loss: 2.5198, tea_CELoss: 1.1429, stu_CELoss: 1.2132, DMLLoss: 0.1636, 
2022-07-31 22:02:31 - train: epoch 0032, iter [02100, 05004], lr: 0.010000, loss: 2.3990, tea_CELoss: 1.0460, stu_CELoss: 1.1804, DMLLoss: 0.1727, 
2022-07-31 22:03:28 - train: epoch 0032, iter [02200, 05004], lr: 0.010000, loss: 2.8657, tea_CELoss: 1.2762, stu_CELoss: 1.4257, DMLLoss: 0.1638, 
2022-07-31 22:04:26 - train: epoch 0032, iter [02300, 05004], lr: 0.010000, loss: 2.8935, tea_CELoss: 1.2986, stu_CELoss: 1.4159, DMLLoss: 0.1790, 
2022-07-31 22:05:24 - train: epoch 0032, iter [02400, 05004], lr: 0.010000, loss: 2.4616, tea_CELoss: 1.0894, stu_CELoss: 1.2181, DMLLoss: 0.1541, 
2022-07-31 22:06:22 - train: epoch 0032, iter [02500, 05004], lr: 0.010000, loss: 2.6295, tea_CELoss: 1.1764, stu_CELoss: 1.2924, DMLLoss: 0.1607, 
2022-07-31 22:07:20 - train: epoch 0032, iter [02600, 05004], lr: 0.010000, loss: 2.3349, tea_CELoss: 1.0365, stu_CELoss: 1.1532, DMLLoss: 0.1452, 
2022-07-31 22:08:18 - train: epoch 0032, iter [02700, 05004], lr: 0.010000, loss: 2.4317, tea_CELoss: 1.0424, stu_CELoss: 1.2097, DMLLoss: 0.1796, 
2022-07-31 22:09:16 - train: epoch 0032, iter [02800, 05004], lr: 0.010000, loss: 2.7659, tea_CELoss: 1.2351, stu_CELoss: 1.3563, DMLLoss: 0.1745, 
2022-07-31 22:10:14 - train: epoch 0032, iter [02900, 05004], lr: 0.010000, loss: 2.3779, tea_CELoss: 1.0690, stu_CELoss: 1.1613, DMLLoss: 0.1475, 
2022-07-31 22:11:12 - train: epoch 0032, iter [03000, 05004], lr: 0.010000, loss: 2.2538, tea_CELoss: 1.0097, stu_CELoss: 1.0746, DMLLoss: 0.1695, 
2022-07-31 22:12:10 - train: epoch 0032, iter [03100, 05004], lr: 0.010000, loss: 2.9362, tea_CELoss: 1.3051, stu_CELoss: 1.4424, DMLLoss: 0.1887, 
2022-07-31 22:13:08 - train: epoch 0032, iter [03200, 05004], lr: 0.010000, loss: 2.9087, tea_CELoss: 1.2856, stu_CELoss: 1.4424, DMLLoss: 0.1807, 
2022-07-31 22:14:05 - train: epoch 0032, iter [03300, 05004], lr: 0.010000, loss: 2.6920, tea_CELoss: 1.2621, stu_CELoss: 1.2743, DMLLoss: 0.1556, 
2022-07-31 22:15:03 - train: epoch 0032, iter [03400, 05004], lr: 0.010000, loss: 2.4147, tea_CELoss: 1.0367, stu_CELoss: 1.2163, DMLLoss: 0.1616, 
2022-07-31 22:16:01 - train: epoch 0032, iter [03500, 05004], lr: 0.010000, loss: 2.5298, tea_CELoss: 1.1149, stu_CELoss: 1.2502, DMLLoss: 0.1647, 
2022-07-31 22:16:58 - train: epoch 0032, iter [03600, 05004], lr: 0.010000, loss: 3.0722, tea_CELoss: 1.3740, stu_CELoss: 1.5426, DMLLoss: 0.1556, 
2022-07-31 22:17:56 - train: epoch 0032, iter [03700, 05004], lr: 0.010000, loss: 2.6771, tea_CELoss: 1.2242, stu_CELoss: 1.2857, DMLLoss: 0.1672, 
2022-07-31 22:18:53 - train: epoch 0032, iter [03800, 05004], lr: 0.010000, loss: 2.3435, tea_CELoss: 1.0473, stu_CELoss: 1.1701, DMLLoss: 0.1262, 
2022-07-31 22:19:51 - train: epoch 0032, iter [03900, 05004], lr: 0.010000, loss: 2.3062, tea_CELoss: 1.0164, stu_CELoss: 1.1383, DMLLoss: 0.1515, 
2022-07-31 22:20:48 - train: epoch 0032, iter [04000, 05004], lr: 0.010000, loss: 2.7579, tea_CELoss: 1.2272, stu_CELoss: 1.3794, DMLLoss: 0.1513, 
2022-07-31 22:21:46 - train: epoch 0032, iter [04100, 05004], lr: 0.010000, loss: 2.4704, tea_CELoss: 1.1097, stu_CELoss: 1.1952, DMLLoss: 0.1655, 
2022-07-31 22:22:43 - train: epoch 0032, iter [04200, 05004], lr: 0.010000, loss: 2.4094, tea_CELoss: 1.0692, stu_CELoss: 1.1884, DMLLoss: 0.1518, 
2022-07-31 22:23:41 - train: epoch 0032, iter [04300, 05004], lr: 0.010000, loss: 2.8752, tea_CELoss: 1.2795, stu_CELoss: 1.4048, DMLLoss: 0.1908, 
2022-07-31 22:24:38 - train: epoch 0032, iter [04400, 05004], lr: 0.010000, loss: 2.3667, tea_CELoss: 1.0359, stu_CELoss: 1.1617, DMLLoss: 0.1692, 
2022-07-31 22:25:36 - train: epoch 0032, iter [04500, 05004], lr: 0.010000, loss: 3.0094, tea_CELoss: 1.3253, stu_CELoss: 1.5168, DMLLoss: 0.1673, 
2022-07-31 22:26:33 - train: epoch 0032, iter [04600, 05004], lr: 0.010000, loss: 2.7068, tea_CELoss: 1.1885, stu_CELoss: 1.3550, DMLLoss: 0.1634, 
2022-07-31 22:27:31 - train: epoch 0032, iter [04700, 05004], lr: 0.010000, loss: 2.8303, tea_CELoss: 1.2929, stu_CELoss: 1.3643, DMLLoss: 0.1730, 
2022-07-31 22:28:28 - train: epoch 0032, iter [04800, 05004], lr: 0.010000, loss: 2.4535, tea_CELoss: 1.0425, stu_CELoss: 1.1973, DMLLoss: 0.2136, 
2022-07-31 22:29:25 - train: epoch 0032, iter [04900, 05004], lr: 0.010000, loss: 2.5337, tea_CELoss: 1.1264, stu_CELoss: 1.2453, DMLLoss: 0.1621, 
2022-07-31 22:30:23 - train: epoch 0032, iter [05000, 05004], lr: 0.010000, loss: 2.6458, tea_CELoss: 1.1858, stu_CELoss: 1.2915, DMLLoss: 0.1686, 
2022-07-31 22:30:25 - train: epoch 032, train_loss: 2.7076
2022-07-31 22:32:55 - eval: epoch: 032, tea_acc1: 74.400%, tea_acc5: 92.092%, tea_test_loss: 1.0068, stu_acc1: 72.238%, stu_acc5: 90.790%, stu_test_loss: 1.1115
2022-07-31 22:32:57 - until epoch: 032, tea_best_acc1: 74.400%, stu_best_acc1: 72.238%
2022-07-31 22:32:57 - epoch 033 lr: 0.010000
2022-07-31 22:34:00 - train: epoch 0033, iter [00100, 05004], lr: 0.010000, loss: 2.2157, tea_CELoss: 0.9349, stu_CELoss: 1.1120, DMLLoss: 0.1688, 
2022-07-31 22:34:58 - train: epoch 0033, iter [00200, 05004], lr: 0.010000, loss: 2.6152, tea_CELoss: 1.1586, stu_CELoss: 1.2836, DMLLoss: 0.1730, 
2022-07-31 22:35:55 - train: epoch 0033, iter [00300, 05004], lr: 0.010000, loss: 2.6184, tea_CELoss: 1.1471, stu_CELoss: 1.3085, DMLLoss: 0.1628, 
2022-07-31 22:36:53 - train: epoch 0033, iter [00400, 05004], lr: 0.010000, loss: 2.5631, tea_CELoss: 1.1436, stu_CELoss: 1.2823, DMLLoss: 0.1372, 
2022-07-31 22:37:50 - train: epoch 0033, iter [00500, 05004], lr: 0.010000, loss: 2.7600, tea_CELoss: 1.2473, stu_CELoss: 1.3415, DMLLoss: 0.1711, 
2022-07-31 22:38:48 - train: epoch 0033, iter [00600, 05004], lr: 0.010000, loss: 2.6726, tea_CELoss: 1.1419, stu_CELoss: 1.3428, DMLLoss: 0.1880, 
2022-07-31 22:39:45 - train: epoch 0033, iter [00700, 05004], lr: 0.010000, loss: 2.8142, tea_CELoss: 1.2625, stu_CELoss: 1.3879, DMLLoss: 0.1638, 
2022-07-31 22:40:43 - train: epoch 0033, iter [00800, 05004], lr: 0.010000, loss: 2.9361, tea_CELoss: 1.2868, stu_CELoss: 1.4663, DMLLoss: 0.1831, 
2022-07-31 22:41:40 - train: epoch 0033, iter [00900, 05004], lr: 0.010000, loss: 2.5172, tea_CELoss: 1.1201, stu_CELoss: 1.2360, DMLLoss: 0.1611, 
2022-07-31 22:42:38 - train: epoch 0033, iter [01000, 05004], lr: 0.010000, loss: 2.7409, tea_CELoss: 1.2527, stu_CELoss: 1.2963, DMLLoss: 0.1919, 
2022-07-31 22:43:35 - train: epoch 0033, iter [01100, 05004], lr: 0.010000, loss: 2.0723, tea_CELoss: 0.9356, stu_CELoss: 0.9927, DMLLoss: 0.1441, 
2022-07-31 22:44:33 - train: epoch 0033, iter [01200, 05004], lr: 0.010000, loss: 3.0654, tea_CELoss: 1.3573, stu_CELoss: 1.5300, DMLLoss: 0.1781, 
2022-07-31 22:45:30 - train: epoch 0033, iter [01300, 05004], lr: 0.010000, loss: 2.5362, tea_CELoss: 1.1593, stu_CELoss: 1.2103, DMLLoss: 0.1666, 
2022-07-31 22:46:28 - train: epoch 0033, iter [01400, 05004], lr: 0.010000, loss: 2.4819, tea_CELoss: 1.0856, stu_CELoss: 1.2328, DMLLoss: 0.1635, 
2022-07-31 22:47:25 - train: epoch 0033, iter [01500, 05004], lr: 0.010000, loss: 3.0795, tea_CELoss: 1.3749, stu_CELoss: 1.5239, DMLLoss: 0.1807, 
2022-07-31 22:48:23 - train: epoch 0033, iter [01600, 05004], lr: 0.010000, loss: 2.9017, tea_CELoss: 1.2641, stu_CELoss: 1.4357, DMLLoss: 0.2019, 
2022-07-31 22:49:20 - train: epoch 0033, iter [01700, 05004], lr: 0.010000, loss: 2.7614, tea_CELoss: 1.2136, stu_CELoss: 1.3834, DMLLoss: 0.1644, 
2022-07-31 22:50:17 - train: epoch 0033, iter [01800, 05004], lr: 0.010000, loss: 2.4023, tea_CELoss: 1.0457, stu_CELoss: 1.1931, DMLLoss: 0.1636, 
2022-07-31 22:51:15 - train: epoch 0033, iter [01900, 05004], lr: 0.010000, loss: 2.6608, tea_CELoss: 1.2047, stu_CELoss: 1.3122, DMLLoss: 0.1440, 
2022-07-31 22:52:13 - train: epoch 0033, iter [02000, 05004], lr: 0.010000, loss: 2.2125, tea_CELoss: 0.9669, stu_CELoss: 1.0958, DMLLoss: 0.1498, 
2022-07-31 22:53:10 - train: epoch 0033, iter [02100, 05004], lr: 0.010000, loss: 2.7858, tea_CELoss: 1.2205, stu_CELoss: 1.3704, DMLLoss: 0.1949, 
2022-07-31 22:54:08 - train: epoch 0033, iter [02200, 05004], lr: 0.010000, loss: 2.7046, tea_CELoss: 1.2154, stu_CELoss: 1.3329, DMLLoss: 0.1564, 
2022-07-31 22:55:05 - train: epoch 0033, iter [02300, 05004], lr: 0.010000, loss: 2.4304, tea_CELoss: 1.0719, stu_CELoss: 1.1987, DMLLoss: 0.1598, 
2022-07-31 22:56:03 - train: epoch 0033, iter [02400, 05004], lr: 0.010000, loss: 3.0940, tea_CELoss: 1.4041, stu_CELoss: 1.4956, DMLLoss: 0.1943, 
2022-07-31 22:57:01 - train: epoch 0033, iter [02500, 05004], lr: 0.010000, loss: 2.4930, tea_CELoss: 1.0509, stu_CELoss: 1.2652, DMLLoss: 0.1769, 
2022-07-31 22:57:58 - train: epoch 0033, iter [02600, 05004], lr: 0.010000, loss: 2.2735, tea_CELoss: 1.0031, stu_CELoss: 1.1033, DMLLoss: 0.1670, 
2022-07-31 22:58:55 - train: epoch 0033, iter [02700, 05004], lr: 0.010000, loss: 2.5673, tea_CELoss: 1.1586, stu_CELoss: 1.2567, DMLLoss: 0.1521, 
2022-07-31 22:59:52 - train: epoch 0033, iter [02800, 05004], lr: 0.010000, loss: 2.5985, tea_CELoss: 1.1326, stu_CELoss: 1.2876, DMLLoss: 0.1783, 
2022-07-31 23:00:50 - train: epoch 0033, iter [02900, 05004], lr: 0.010000, loss: 2.4089, tea_CELoss: 1.0634, stu_CELoss: 1.1949, DMLLoss: 0.1505, 
2022-07-31 23:01:47 - train: epoch 0033, iter [03000, 05004], lr: 0.010000, loss: 2.5161, tea_CELoss: 1.1101, stu_CELoss: 1.2419, DMLLoss: 0.1641, 
2022-07-31 23:02:44 - train: epoch 0033, iter [03100, 05004], lr: 0.010000, loss: 2.4017, tea_CELoss: 1.0460, stu_CELoss: 1.1746, DMLLoss: 0.1811, 
2022-07-31 23:03:41 - train: epoch 0033, iter [03200, 05004], lr: 0.010000, loss: 2.3963, tea_CELoss: 1.0570, stu_CELoss: 1.1762, DMLLoss: 0.1631, 
2022-07-31 23:04:38 - train: epoch 0033, iter [03300, 05004], lr: 0.010000, loss: 2.5494, tea_CELoss: 1.1053, stu_CELoss: 1.2684, DMLLoss: 0.1757, 
2022-07-31 23:05:35 - train: epoch 0033, iter [03400, 05004], lr: 0.010000, loss: 2.3558, tea_CELoss: 1.0441, stu_CELoss: 1.1689, DMLLoss: 0.1429, 
2022-07-31 23:06:32 - train: epoch 0033, iter [03500, 05004], lr: 0.010000, loss: 2.6704, tea_CELoss: 1.1647, stu_CELoss: 1.3403, DMLLoss: 0.1654, 
2022-07-31 23:07:29 - train: epoch 0033, iter [03600, 05004], lr: 0.010000, loss: 3.0189, tea_CELoss: 1.3045, stu_CELoss: 1.5171, DMLLoss: 0.1973, 
2022-07-31 23:08:26 - train: epoch 0033, iter [03700, 05004], lr: 0.010000, loss: 2.3591, tea_CELoss: 1.0273, stu_CELoss: 1.1595, DMLLoss: 0.1722, 
2022-07-31 23:09:23 - train: epoch 0033, iter [03800, 05004], lr: 0.010000, loss: 2.6413, tea_CELoss: 1.1501, stu_CELoss: 1.3304, DMLLoss: 0.1609, 
2022-07-31 23:10:21 - train: epoch 0033, iter [03900, 05004], lr: 0.010000, loss: 2.9381, tea_CELoss: 1.3262, stu_CELoss: 1.4358, DMLLoss: 0.1761, 
2022-07-31 23:11:18 - train: epoch 0033, iter [04000, 05004], lr: 0.010000, loss: 2.9897, tea_CELoss: 1.3603, stu_CELoss: 1.4658, DMLLoss: 0.1636, 
2022-07-31 23:12:15 - train: epoch 0033, iter [04100, 05004], lr: 0.010000, loss: 2.6445, tea_CELoss: 1.2021, stu_CELoss: 1.2916, DMLLoss: 0.1507, 
2022-07-31 23:13:12 - train: epoch 0033, iter [04200, 05004], lr: 0.010000, loss: 2.3907, tea_CELoss: 1.0508, stu_CELoss: 1.1737, DMLLoss: 0.1662, 
2022-07-31 23:14:09 - train: epoch 0033, iter [04300, 05004], lr: 0.010000, loss: 2.8079, tea_CELoss: 1.2476, stu_CELoss: 1.3949, DMLLoss: 0.1653, 
2022-07-31 23:15:06 - train: epoch 0033, iter [04400, 05004], lr: 0.010000, loss: 2.6590, tea_CELoss: 1.1776, stu_CELoss: 1.3269, DMLLoss: 0.1545, 
2022-07-31 23:16:04 - train: epoch 0033, iter [04500, 05004], lr: 0.010000, loss: 2.7388, tea_CELoss: 1.1661, stu_CELoss: 1.3942, DMLLoss: 0.1785, 
2022-07-31 23:17:01 - train: epoch 0033, iter [04600, 05004], lr: 0.010000, loss: 2.6991, tea_CELoss: 1.2019, stu_CELoss: 1.3231, DMLLoss: 0.1741, 
2022-07-31 23:17:58 - train: epoch 0033, iter [04700, 05004], lr: 0.010000, loss: 2.7938, tea_CELoss: 1.2445, stu_CELoss: 1.3623, DMLLoss: 0.1871, 
2022-07-31 23:18:55 - train: epoch 0033, iter [04800, 05004], lr: 0.010000, loss: 3.0945, tea_CELoss: 1.4217, stu_CELoss: 1.5144, DMLLoss: 0.1583, 
2022-07-31 23:19:53 - train: epoch 0033, iter [04900, 05004], lr: 0.010000, loss: 2.6733, tea_CELoss: 1.2337, stu_CELoss: 1.2785, DMLLoss: 0.1611, 
2022-07-31 23:20:50 - train: epoch 0033, iter [05000, 05004], lr: 0.010000, loss: 2.5739, tea_CELoss: 1.1091, stu_CELoss: 1.2822, DMLLoss: 0.1826, 
2022-07-31 23:20:53 - train: epoch 033, train_loss: 2.6067
2022-07-31 23:23:26 - eval: epoch: 033, tea_acc1: 74.808%, tea_acc5: 92.254%, tea_test_loss: 0.9911, stu_acc1: 72.688%, stu_acc5: 91.120%, stu_test_loss: 1.0893
2022-07-31 23:23:27 - until epoch: 033, tea_best_acc1: 74.808%, stu_best_acc1: 72.688%
2022-07-31 23:23:27 - epoch 034 lr: 0.010000
2022-07-31 23:24:30 - train: epoch 0034, iter [00100, 05004], lr: 0.010000, loss: 2.5275, tea_CELoss: 1.1324, stu_CELoss: 1.2375, DMLLoss: 0.1576, 
2022-07-31 23:25:27 - train: epoch 0034, iter [00200, 05004], lr: 0.010000, loss: 2.6354, tea_CELoss: 1.1946, stu_CELoss: 1.2739, DMLLoss: 0.1669, 
2022-07-31 23:26:24 - train: epoch 0034, iter [00300, 05004], lr: 0.010000, loss: 2.4505, tea_CELoss: 1.0796, stu_CELoss: 1.2188, DMLLoss: 0.1521, 
2022-07-31 23:27:21 - train: epoch 0034, iter [00400, 05004], lr: 0.010000, loss: 2.3008, tea_CELoss: 1.0238, stu_CELoss: 1.1288, DMLLoss: 0.1482, 
2022-07-31 23:28:18 - train: epoch 0034, iter [00500, 05004], lr: 0.010000, loss: 2.4364, tea_CELoss: 1.0882, stu_CELoss: 1.1985, DMLLoss: 0.1496, 
2022-07-31 23:29:15 - train: epoch 0034, iter [00600, 05004], lr: 0.010000, loss: 2.5375, tea_CELoss: 1.1372, stu_CELoss: 1.2421, DMLLoss: 0.1583, 
2022-07-31 23:30:12 - train: epoch 0034, iter [00700, 05004], lr: 0.010000, loss: 2.3940, tea_CELoss: 1.0638, stu_CELoss: 1.1783, DMLLoss: 0.1519, 
2022-07-31 23:31:09 - train: epoch 0034, iter [00800, 05004], lr: 0.010000, loss: 2.6335, tea_CELoss: 1.1604, stu_CELoss: 1.3229, DMLLoss: 0.1503, 
2022-07-31 23:32:07 - train: epoch 0034, iter [00900, 05004], lr: 0.010000, loss: 2.2728, tea_CELoss: 1.0128, stu_CELoss: 1.1114, DMLLoss: 0.1486, 
2022-07-31 23:33:04 - train: epoch 0034, iter [01000, 05004], lr: 0.010000, loss: 2.5525, tea_CELoss: 1.1411, stu_CELoss: 1.2714, DMLLoss: 0.1401, 
2022-07-31 23:34:01 - train: epoch 0034, iter [01100, 05004], lr: 0.010000, loss: 2.3767, tea_CELoss: 1.0133, stu_CELoss: 1.1939, DMLLoss: 0.1695, 
2022-07-31 23:34:58 - train: epoch 0034, iter [01200, 05004], lr: 0.010000, loss: 2.6773, tea_CELoss: 1.1642, stu_CELoss: 1.3121, DMLLoss: 0.2011, 
2022-07-31 23:35:55 - train: epoch 0034, iter [01300, 05004], lr: 0.010000, loss: 2.2136, tea_CELoss: 0.9448, stu_CELoss: 1.1000, DMLLoss: 0.1688, 
2022-07-31 23:36:52 - train: epoch 0034, iter [01400, 05004], lr: 0.010000, loss: 2.3626, tea_CELoss: 1.0080, stu_CELoss: 1.1912, DMLLoss: 0.1634, 
2022-07-31 23:37:49 - train: epoch 0034, iter [01500, 05004], lr: 0.010000, loss: 2.5669, tea_CELoss: 1.1714, stu_CELoss: 1.2343, DMLLoss: 0.1613, 
2022-07-31 23:38:47 - train: epoch 0034, iter [01600, 05004], lr: 0.010000, loss: 2.5200, tea_CELoss: 1.1148, stu_CELoss: 1.2490, DMLLoss: 0.1563, 
2022-07-31 23:39:44 - train: epoch 0034, iter [01700, 05004], lr: 0.010000, loss: 2.4399, tea_CELoss: 1.0230, stu_CELoss: 1.2420, DMLLoss: 0.1749, 
2022-07-31 23:40:41 - train: epoch 0034, iter [01800, 05004], lr: 0.010000, loss: 2.8471, tea_CELoss: 1.2455, stu_CELoss: 1.4124, DMLLoss: 0.1892, 
2022-07-31 23:41:38 - train: epoch 0034, iter [01900, 05004], lr: 0.010000, loss: 2.7244, tea_CELoss: 1.2197, stu_CELoss: 1.3444, DMLLoss: 0.1603, 
2022-07-31 23:42:36 - train: epoch 0034, iter [02000, 05004], lr: 0.010000, loss: 2.4555, tea_CELoss: 1.0765, stu_CELoss: 1.2258, DMLLoss: 0.1532, 
2022-07-31 23:43:33 - train: epoch 0034, iter [02100, 05004], lr: 0.010000, loss: 2.6281, tea_CELoss: 1.1178, stu_CELoss: 1.3215, DMLLoss: 0.1888, 
2022-07-31 23:44:30 - train: epoch 0034, iter [02200, 05004], lr: 0.010000, loss: 2.4125, tea_CELoss: 1.0895, stu_CELoss: 1.1607, DMLLoss: 0.1623, 
2022-07-31 23:45:28 - train: epoch 0034, iter [02300, 05004], lr: 0.010000, loss: 2.7916, tea_CELoss: 1.2503, stu_CELoss: 1.3539, DMLLoss: 0.1874, 
2022-07-31 23:46:26 - train: epoch 0034, iter [02400, 05004], lr: 0.010000, loss: 2.2716, tea_CELoss: 1.0334, stu_CELoss: 1.1002, DMLLoss: 0.1380, 
2022-07-31 23:47:23 - train: epoch 0034, iter [02500, 05004], lr: 0.010000, loss: 2.7990, tea_CELoss: 1.2434, stu_CELoss: 1.3776, DMLLoss: 0.1780, 
2022-07-31 23:48:21 - train: epoch 0034, iter [02600, 05004], lr: 0.010000, loss: 2.9490, tea_CELoss: 1.3119, stu_CELoss: 1.4530, DMLLoss: 0.1842, 
2022-07-31 23:49:18 - train: epoch 0034, iter [02700, 05004], lr: 0.010000, loss: 2.7744, tea_CELoss: 1.2481, stu_CELoss: 1.3680, DMLLoss: 0.1584, 
2022-07-31 23:50:16 - train: epoch 0034, iter [02800, 05004], lr: 0.010000, loss: 2.2586, tea_CELoss: 0.9944, stu_CELoss: 1.0959, DMLLoss: 0.1683, 
2022-07-31 23:51:13 - train: epoch 0034, iter [02900, 05004], lr: 0.010000, loss: 2.2810, tea_CELoss: 0.9914, stu_CELoss: 1.1410, DMLLoss: 0.1486, 
2022-07-31 23:52:11 - train: epoch 0034, iter [03000, 05004], lr: 0.010000, loss: 2.1947, tea_CELoss: 0.9652, stu_CELoss: 1.0731, DMLLoss: 0.1564, 
2022-07-31 23:53:09 - train: epoch 0034, iter [03100, 05004], lr: 0.010000, loss: 2.3573, tea_CELoss: 1.0603, stu_CELoss: 1.1267, DMLLoss: 0.1703, 
2022-07-31 23:54:07 - train: epoch 0034, iter [03200, 05004], lr: 0.010000, loss: 2.6852, tea_CELoss: 1.1577, stu_CELoss: 1.3444, DMLLoss: 0.1830, 
2022-07-31 23:55:04 - train: epoch 0034, iter [03300, 05004], lr: 0.010000, loss: 2.4271, tea_CELoss: 1.0816, stu_CELoss: 1.1733, DMLLoss: 0.1722, 
2022-07-31 23:56:02 - train: epoch 0034, iter [03400, 05004], lr: 0.010000, loss: 2.8174, tea_CELoss: 1.2393, stu_CELoss: 1.4155, DMLLoss: 0.1625, 
2022-07-31 23:56:59 - train: epoch 0034, iter [03500, 05004], lr: 0.010000, loss: 2.4672, tea_CELoss: 1.1099, stu_CELoss: 1.1839, DMLLoss: 0.1734, 
2022-07-31 23:57:57 - train: epoch 0034, iter [03600, 05004], lr: 0.010000, loss: 2.1504, tea_CELoss: 0.9579, stu_CELoss: 1.0547, DMLLoss: 0.1377, 
2022-07-31 23:58:55 - train: epoch 0034, iter [03700, 05004], lr: 0.010000, loss: 2.7025, tea_CELoss: 1.1723, stu_CELoss: 1.3279, DMLLoss: 0.2023, 
2022-07-31 23:59:52 - train: epoch 0034, iter [03800, 05004], lr: 0.010000, loss: 2.2437, tea_CELoss: 0.9869, stu_CELoss: 1.1138, DMLLoss: 0.1431, 
2022-08-01 00:00:50 - train: epoch 0034, iter [03900, 05004], lr: 0.010000, loss: 3.2439, tea_CELoss: 1.4319, stu_CELoss: 1.6283, DMLLoss: 0.1836, 
2022-08-01 00:01:47 - train: epoch 0034, iter [04000, 05004], lr: 0.010000, loss: 2.5170, tea_CELoss: 1.1075, stu_CELoss: 1.2297, DMLLoss: 0.1797, 
2022-08-01 00:02:45 - train: epoch 0034, iter [04100, 05004], lr: 0.010000, loss: 2.8344, tea_CELoss: 1.2406, stu_CELoss: 1.4134, DMLLoss: 0.1804, 
2022-08-01 00:03:43 - train: epoch 0034, iter [04200, 05004], lr: 0.010000, loss: 2.2996, tea_CELoss: 1.0045, stu_CELoss: 1.1368, DMLLoss: 0.1582, 
2022-08-01 00:04:40 - train: epoch 0034, iter [04300, 05004], lr: 0.010000, loss: 2.2404, tea_CELoss: 0.9878, stu_CELoss: 1.0898, DMLLoss: 0.1628, 
2022-08-01 00:05:38 - train: epoch 0034, iter [04400, 05004], lr: 0.010000, loss: 2.2651, tea_CELoss: 0.9897, stu_CELoss: 1.1118, DMLLoss: 0.1636, 
2022-08-01 00:06:36 - train: epoch 0034, iter [04500, 05004], lr: 0.010000, loss: 2.7954, tea_CELoss: 1.2459, stu_CELoss: 1.3956, DMLLoss: 0.1539, 
2022-08-01 00:07:34 - train: epoch 0034, iter [04600, 05004], lr: 0.010000, loss: 2.7808, tea_CELoss: 1.2500, stu_CELoss: 1.3605, DMLLoss: 0.1704, 
2022-08-01 00:08:31 - train: epoch 0034, iter [04700, 05004], lr: 0.010000, loss: 2.6182, tea_CELoss: 1.1258, stu_CELoss: 1.2815, DMLLoss: 0.2109, 
2022-08-01 00:09:29 - train: epoch 0034, iter [04800, 05004], lr: 0.010000, loss: 2.6356, tea_CELoss: 1.1838, stu_CELoss: 1.2865, DMLLoss: 0.1653, 
2022-08-01 00:10:27 - train: epoch 0034, iter [04900, 05004], lr: 0.010000, loss: 2.6974, tea_CELoss: 1.2156, stu_CELoss: 1.3179, DMLLoss: 0.1639, 
2022-08-01 00:11:25 - train: epoch 0034, iter [05000, 05004], lr: 0.010000, loss: 2.2196, tea_CELoss: 0.9508, stu_CELoss: 1.1074, DMLLoss: 0.1614, 
2022-08-01 00:11:27 - train: epoch 034, train_loss: 2.5422
2022-08-01 00:14:01 - eval: epoch: 034, tea_acc1: 75.228%, tea_acc5: 92.508%, tea_test_loss: 0.9727, stu_acc1: 72.616%, stu_acc5: 91.054%, stu_test_loss: 1.0915
2022-08-01 00:14:02 - until epoch: 034, tea_best_acc1: 75.228%, stu_best_acc1: 72.688%
2022-08-01 00:14:02 - epoch 035 lr: 0.010000
2022-08-01 00:15:05 - train: epoch 0035, iter [00100, 05004], lr: 0.010000, loss: 2.3600, tea_CELoss: 1.0277, stu_CELoss: 1.1629, DMLLoss: 0.1694, 
2022-08-01 00:16:02 - train: epoch 0035, iter [00200, 05004], lr: 0.010000, loss: 2.2192, tea_CELoss: 0.9622, stu_CELoss: 1.0950, DMLLoss: 0.1620, 
2022-08-01 00:17:00 - train: epoch 0035, iter [00300, 05004], lr: 0.010000, loss: 2.5924, tea_CELoss: 1.1434, stu_CELoss: 1.2754, DMLLoss: 0.1736, 
2022-08-01 00:17:57 - train: epoch 0035, iter [00400, 05004], lr: 0.010000, loss: 2.2307, tea_CELoss: 0.9722, stu_CELoss: 1.0829, DMLLoss: 0.1756, 
2022-08-01 00:18:54 - train: epoch 0035, iter [00500, 05004], lr: 0.010000, loss: 2.5390, tea_CELoss: 1.0984, stu_CELoss: 1.2677, DMLLoss: 0.1729, 
2022-08-01 00:19:51 - train: epoch 0035, iter [00600, 05004], lr: 0.010000, loss: 2.3610, tea_CELoss: 0.9870, stu_CELoss: 1.1994, DMLLoss: 0.1746, 
2022-08-01 00:20:48 - train: epoch 0035, iter [00700, 05004], lr: 0.010000, loss: 2.3113, tea_CELoss: 1.0267, stu_CELoss: 1.1120, DMLLoss: 0.1726, 
2022-08-01 00:21:45 - train: epoch 0035, iter [00800, 05004], lr: 0.010000, loss: 2.5161, tea_CELoss: 1.1267, stu_CELoss: 1.2209, DMLLoss: 0.1685, 
2022-08-01 00:22:42 - train: epoch 0035, iter [00900, 05004], lr: 0.010000, loss: 2.7133, tea_CELoss: 1.1986, stu_CELoss: 1.3483, DMLLoss: 0.1664, 
2022-08-01 00:23:39 - train: epoch 0035, iter [01000, 05004], lr: 0.010000, loss: 2.1167, tea_CELoss: 0.9288, stu_CELoss: 1.0394, DMLLoss: 0.1485, 
2022-08-01 00:24:36 - train: epoch 0035, iter [01100, 05004], lr: 0.010000, loss: 2.6570, tea_CELoss: 1.1568, stu_CELoss: 1.3171, DMLLoss: 0.1831, 
2022-08-01 00:25:33 - train: epoch 0035, iter [01200, 05004], lr: 0.010000, loss: 2.1361, tea_CELoss: 0.9352, stu_CELoss: 1.0393, DMLLoss: 0.1616, 
2022-08-01 00:26:30 - train: epoch 0035, iter [01300, 05004], lr: 0.010000, loss: 2.4025, tea_CELoss: 1.0689, stu_CELoss: 1.1821, DMLLoss: 0.1515, 
2022-08-01 00:27:28 - train: epoch 0035, iter [01400, 05004], lr: 0.010000, loss: 2.5864, tea_CELoss: 1.1422, stu_CELoss: 1.2808, DMLLoss: 0.1635, 
2022-08-01 00:28:25 - train: epoch 0035, iter [01500, 05004], lr: 0.010000, loss: 2.7047, tea_CELoss: 1.2056, stu_CELoss: 1.3441, DMLLoss: 0.1550, 
2022-08-01 00:29:22 - train: epoch 0035, iter [01600, 05004], lr: 0.010000, loss: 2.2076, tea_CELoss: 0.9974, stu_CELoss: 1.0715, DMLLoss: 0.1387, 
2022-08-01 00:30:19 - train: epoch 0035, iter [01700, 05004], lr: 0.010000, loss: 2.0512, tea_CELoss: 0.9030, stu_CELoss: 1.0108, DMLLoss: 0.1374, 
2022-08-01 00:31:16 - train: epoch 0035, iter [01800, 05004], lr: 0.010000, loss: 2.7310, tea_CELoss: 1.1820, stu_CELoss: 1.3511, DMLLoss: 0.1980, 
2022-08-01 00:32:14 - train: epoch 0035, iter [01900, 05004], lr: 0.010000, loss: 2.5375, tea_CELoss: 1.1458, stu_CELoss: 1.2246, DMLLoss: 0.1671, 
2022-08-01 00:33:11 - train: epoch 0035, iter [02000, 05004], lr: 0.010000, loss: 2.6660, tea_CELoss: 1.1980, stu_CELoss: 1.3171, DMLLoss: 0.1509, 
2022-08-01 00:34:08 - train: epoch 0035, iter [02100, 05004], lr: 0.010000, loss: 2.6001, tea_CELoss: 1.1627, stu_CELoss: 1.2760, DMLLoss: 0.1615, 
2022-08-01 00:35:05 - train: epoch 0035, iter [02200, 05004], lr: 0.010000, loss: 2.4288, tea_CELoss: 1.0962, stu_CELoss: 1.1746, DMLLoss: 0.1580, 
2022-08-01 00:36:03 - train: epoch 0035, iter [02300, 05004], lr: 0.010000, loss: 2.5209, tea_CELoss: 1.1314, stu_CELoss: 1.2394, DMLLoss: 0.1501, 
2022-08-01 00:37:00 - train: epoch 0035, iter [02400, 05004], lr: 0.010000, loss: 2.5552, tea_CELoss: 1.1310, stu_CELoss: 1.2459, DMLLoss: 0.1784, 
2022-08-01 00:37:57 - train: epoch 0035, iter [02500, 05004], lr: 0.010000, loss: 2.5759, tea_CELoss: 1.1378, stu_CELoss: 1.2661, DMLLoss: 0.1720, 
2022-08-01 00:38:54 - train: epoch 0035, iter [02600, 05004], lr: 0.010000, loss: 2.3974, tea_CELoss: 1.0753, stu_CELoss: 1.1502, DMLLoss: 0.1718, 
2022-08-01 00:39:51 - train: epoch 0035, iter [02700, 05004], lr: 0.010000, loss: 2.7740, tea_CELoss: 1.2241, stu_CELoss: 1.3804, DMLLoss: 0.1696, 
2022-08-01 00:40:49 - train: epoch 0035, iter [02800, 05004], lr: 0.010000, loss: 2.7188, tea_CELoss: 1.2082, stu_CELoss: 1.3197, DMLLoss: 0.1909, 
2022-08-01 00:41:46 - train: epoch 0035, iter [02900, 05004], lr: 0.010000, loss: 2.3178, tea_CELoss: 1.0232, stu_CELoss: 1.1407, DMLLoss: 0.1540, 
2022-08-01 00:42:43 - train: epoch 0035, iter [03000, 05004], lr: 0.010000, loss: 2.2883, tea_CELoss: 1.0365, stu_CELoss: 1.0906, DMLLoss: 0.1612, 
2022-08-01 00:43:40 - train: epoch 0035, iter [03100, 05004], lr: 0.010000, loss: 2.7479, tea_CELoss: 1.1963, stu_CELoss: 1.3918, DMLLoss: 0.1599, 
2022-08-01 00:44:38 - train: epoch 0035, iter [03200, 05004], lr: 0.010000, loss: 2.3739, tea_CELoss: 1.0733, stu_CELoss: 1.1448, DMLLoss: 0.1557, 
2022-08-01 00:45:35 - train: epoch 0035, iter [03300, 05004], lr: 0.010000, loss: 2.5482, tea_CELoss: 1.1644, stu_CELoss: 1.2184, DMLLoss: 0.1654, 
2022-08-01 00:46:32 - train: epoch 0035, iter [03400, 05004], lr: 0.010000, loss: 2.8005, tea_CELoss: 1.2180, stu_CELoss: 1.4088, DMLLoss: 0.1738, 
2022-08-01 00:47:30 - train: epoch 0035, iter [03500, 05004], lr: 0.010000, loss: 2.1930, tea_CELoss: 0.9329, stu_CELoss: 1.1156, DMLLoss: 0.1445, 
2022-08-01 00:48:27 - train: epoch 0035, iter [03600, 05004], lr: 0.010000, loss: 2.6214, tea_CELoss: 1.1027, stu_CELoss: 1.3202, DMLLoss: 0.1985, 
2022-08-01 00:49:24 - train: epoch 0035, iter [03700, 05004], lr: 0.010000, loss: 2.2907, tea_CELoss: 1.0037, stu_CELoss: 1.1193, DMLLoss: 0.1678, 
2022-08-01 00:50:21 - train: epoch 0035, iter [03800, 05004], lr: 0.010000, loss: 2.1159, tea_CELoss: 0.9169, stu_CELoss: 1.0494, DMLLoss: 0.1497, 
2022-08-01 00:51:19 - train: epoch 0035, iter [03900, 05004], lr: 0.010000, loss: 2.5521, tea_CELoss: 1.0909, stu_CELoss: 1.2827, DMLLoss: 0.1785, 
2022-08-01 00:52:16 - train: epoch 0035, iter [04000, 05004], lr: 0.010000, loss: 2.4004, tea_CELoss: 1.0438, stu_CELoss: 1.1883, DMLLoss: 0.1683, 
2022-08-01 00:53:13 - train: epoch 0035, iter [04100, 05004], lr: 0.010000, loss: 2.4033, tea_CELoss: 1.0362, stu_CELoss: 1.1753, DMLLoss: 0.1918, 
2022-08-01 00:54:11 - train: epoch 0035, iter [04200, 05004], lr: 0.010000, loss: 2.3497, tea_CELoss: 1.0470, stu_CELoss: 1.1539, DMLLoss: 0.1488, 
2022-08-01 00:55:08 - train: epoch 0035, iter [04300, 05004], lr: 0.010000, loss: 2.5630, tea_CELoss: 1.0974, stu_CELoss: 1.2938, DMLLoss: 0.1718, 
2022-08-01 00:56:06 - train: epoch 0035, iter [04400, 05004], lr: 0.010000, loss: 2.7533, tea_CELoss: 1.2284, stu_CELoss: 1.3436, DMLLoss: 0.1813, 
2022-08-01 00:57:03 - train: epoch 0035, iter [04500, 05004], lr: 0.010000, loss: 2.5139, tea_CELoss: 1.1089, stu_CELoss: 1.2110, DMLLoss: 0.1940, 
2022-08-01 00:58:01 - train: epoch 0035, iter [04600, 05004], lr: 0.010000, loss: 2.4978, tea_CELoss: 1.1027, stu_CELoss: 1.2174, DMLLoss: 0.1778, 
2022-08-01 00:58:58 - train: epoch 0035, iter [04700, 05004], lr: 0.010000, loss: 2.6354, tea_CELoss: 1.1327, stu_CELoss: 1.3034, DMLLoss: 0.1993, 
2022-08-01 00:59:55 - train: epoch 0035, iter [04800, 05004], lr: 0.010000, loss: 2.4872, tea_CELoss: 1.0818, stu_CELoss: 1.2409, DMLLoss: 0.1645, 
2022-08-01 01:00:53 - train: epoch 0035, iter [04900, 05004], lr: 0.010000, loss: 2.5489, tea_CELoss: 1.1352, stu_CELoss: 1.2510, DMLLoss: 0.1626, 
2022-08-01 01:01:50 - train: epoch 0035, iter [05000, 05004], lr: 0.010000, loss: 2.5868, tea_CELoss: 1.1830, stu_CELoss: 1.2433, DMLLoss: 0.1605, 
2022-08-01 01:01:53 - train: epoch 035, train_loss: 2.4993
2022-08-01 01:04:24 - eval: epoch: 035, tea_acc1: 75.306%, tea_acc5: 92.652%, tea_test_loss: 0.9662, stu_acc1: 73.016%, stu_acc5: 91.362%, stu_test_loss: 1.0720
2022-08-01 01:04:25 - until epoch: 035, tea_best_acc1: 75.306%, stu_best_acc1: 73.016%
2022-08-01 01:04:25 - epoch 036 lr: 0.010000
2022-08-01 01:05:29 - train: epoch 0036, iter [00100, 05004], lr: 0.010000, loss: 2.5976, tea_CELoss: 1.1764, stu_CELoss: 1.2711, DMLLoss: 0.1501, 
2022-08-01 01:06:26 - train: epoch 0036, iter [00200, 05004], lr: 0.010000, loss: 1.8821, tea_CELoss: 0.8084, stu_CELoss: 0.9252, DMLLoss: 0.1486, 
2022-08-01 01:07:24 - train: epoch 0036, iter [00300, 05004], lr: 0.010000, loss: 2.0474, tea_CELoss: 0.8940, stu_CELoss: 0.9958, DMLLoss: 0.1575, 
2022-08-01 01:08:21 - train: epoch 0036, iter [00400, 05004], lr: 0.010000, loss: 2.3855, tea_CELoss: 1.0684, stu_CELoss: 1.1706, DMLLoss: 0.1464, 
2022-08-01 01:09:18 - train: epoch 0036, iter [00500, 05004], lr: 0.010000, loss: 2.4726, tea_CELoss: 1.0741, stu_CELoss: 1.2111, DMLLoss: 0.1875, 
2022-08-01 01:10:15 - train: epoch 0036, iter [00600, 05004], lr: 0.010000, loss: 2.2368, tea_CELoss: 0.9899, stu_CELoss: 1.0766, DMLLoss: 0.1702, 
2022-08-01 01:11:12 - train: epoch 0036, iter [00700, 05004], lr: 0.010000, loss: 2.2358, tea_CELoss: 0.9878, stu_CELoss: 1.0819, DMLLoss: 0.1660, 
2022-08-01 01:12:09 - train: epoch 0036, iter [00800, 05004], lr: 0.010000, loss: 2.1917, tea_CELoss: 0.9460, stu_CELoss: 1.0768, DMLLoss: 0.1689, 
2022-08-01 01:13:06 - train: epoch 0036, iter [00900, 05004], lr: 0.010000, loss: 2.5576, tea_CELoss: 1.1172, stu_CELoss: 1.2712, DMLLoss: 0.1692, 
2022-08-01 01:14:04 - train: epoch 0036, iter [01000, 05004], lr: 0.010000, loss: 2.2999, tea_CELoss: 0.9347, stu_CELoss: 1.1693, DMLLoss: 0.1958, 
2022-08-01 01:15:01 - train: epoch 0036, iter [01100, 05004], lr: 0.010000, loss: 2.3794, tea_CELoss: 1.0552, stu_CELoss: 1.1556, DMLLoss: 0.1686, 
2022-08-01 01:15:58 - train: epoch 0036, iter [01200, 05004], lr: 0.010000, loss: 2.5082, tea_CELoss: 1.0973, stu_CELoss: 1.2335, DMLLoss: 0.1774, 
2022-08-01 01:16:56 - train: epoch 0036, iter [01300, 05004], lr: 0.010000, loss: 2.4763, tea_CELoss: 1.1015, stu_CELoss: 1.2164, DMLLoss: 0.1584, 
2022-08-01 01:17:53 - train: epoch 0036, iter [01400, 05004], lr: 0.010000, loss: 2.5228, tea_CELoss: 1.0787, stu_CELoss: 1.2586, DMLLoss: 0.1855, 
2022-08-01 01:18:51 - train: epoch 0036, iter [01500, 05004], lr: 0.010000, loss: 2.3614, tea_CELoss: 1.0515, stu_CELoss: 1.1420, DMLLoss: 0.1678, 
2022-08-01 01:19:48 - train: epoch 0036, iter [01600, 05004], lr: 0.010000, loss: 2.6351, tea_CELoss: 1.1763, stu_CELoss: 1.2892, DMLLoss: 0.1696, 
2022-08-01 01:20:45 - train: epoch 0036, iter [01700, 05004], lr: 0.010000, loss: 2.3766, tea_CELoss: 1.0595, stu_CELoss: 1.1467, DMLLoss: 0.1704, 
2022-08-01 01:21:42 - train: epoch 0036, iter [01800, 05004], lr: 0.010000, loss: 2.2011, tea_CELoss: 0.9456, stu_CELoss: 1.0834, DMLLoss: 0.1721, 
2022-08-01 01:22:39 - train: epoch 0036, iter [01900, 05004], lr: 0.010000, loss: 2.9300, tea_CELoss: 1.2859, stu_CELoss: 1.4585, DMLLoss: 0.1856, 
2022-08-01 01:23:37 - train: epoch 0036, iter [02000, 05004], lr: 0.010000, loss: 2.6068, tea_CELoss: 1.1176, stu_CELoss: 1.3233, DMLLoss: 0.1658, 
2022-08-01 01:24:34 - train: epoch 0036, iter [02100, 05004], lr: 0.010000, loss: 2.4478, tea_CELoss: 1.0549, stu_CELoss: 1.2281, DMLLoss: 0.1648, 
2022-08-01 01:25:31 - train: epoch 0036, iter [02200, 05004], lr: 0.010000, loss: 2.5335, tea_CELoss: 1.0933, stu_CELoss: 1.2678, DMLLoss: 0.1724, 
2022-08-01 01:26:28 - train: epoch 0036, iter [02300, 05004], lr: 0.010000, loss: 2.6835, tea_CELoss: 1.2102, stu_CELoss: 1.3110, DMLLoss: 0.1623, 
2022-08-01 01:27:26 - train: epoch 0036, iter [02400, 05004], lr: 0.010000, loss: 2.8165, tea_CELoss: 1.3025, stu_CELoss: 1.3439, DMLLoss: 0.1700, 
2022-08-01 01:28:23 - train: epoch 0036, iter [02500, 05004], lr: 0.010000, loss: 2.2788, tea_CELoss: 0.9849, stu_CELoss: 1.1146, DMLLoss: 0.1793, 
2022-08-01 01:29:20 - train: epoch 0036, iter [02600, 05004], lr: 0.010000, loss: 2.5747, tea_CELoss: 1.1327, stu_CELoss: 1.2789, DMLLoss: 0.1631, 
2022-08-01 01:30:18 - train: epoch 0036, iter [02700, 05004], lr: 0.010000, loss: 2.4039, tea_CELoss: 1.0719, stu_CELoss: 1.1634, DMLLoss: 0.1687, 
2022-08-01 01:31:15 - train: epoch 0036, iter [02800, 05004], lr: 0.010000, loss: 2.4654, tea_CELoss: 1.0951, stu_CELoss: 1.1830, DMLLoss: 0.1873, 
2022-08-01 01:32:13 - train: epoch 0036, iter [02900, 05004], lr: 0.010000, loss: 2.2321, tea_CELoss: 0.9431, stu_CELoss: 1.1116, DMLLoss: 0.1773, 
2022-08-01 01:33:10 - train: epoch 0036, iter [03000, 05004], lr: 0.010000, loss: 2.3699, tea_CELoss: 1.0397, stu_CELoss: 1.1668, DMLLoss: 0.1633, 
2022-08-01 01:34:08 - train: epoch 0036, iter [03100, 05004], lr: 0.010000, loss: 2.5042, tea_CELoss: 1.1357, stu_CELoss: 1.2105, DMLLoss: 0.1580, 
2022-08-01 01:35:05 - train: epoch 0036, iter [03200, 05004], lr: 0.010000, loss: 2.7646, tea_CELoss: 1.2186, stu_CELoss: 1.3667, DMLLoss: 0.1794, 
2022-08-01 01:36:03 - train: epoch 0036, iter [03300, 05004], lr: 0.010000, loss: 2.4620, tea_CELoss: 1.1148, stu_CELoss: 1.1792, DMLLoss: 0.1680, 
2022-08-01 01:37:00 - train: epoch 0036, iter [03400, 05004], lr: 0.010000, loss: 2.4775, tea_CELoss: 1.1100, stu_CELoss: 1.2103, DMLLoss: 0.1571, 
2022-08-01 01:37:57 - train: epoch 0036, iter [03500, 05004], lr: 0.010000, loss: 2.9059, tea_CELoss: 1.2785, stu_CELoss: 1.4196, DMLLoss: 0.2078, 
2022-08-01 01:38:54 - train: epoch 0036, iter [03600, 05004], lr: 0.010000, loss: 2.5598, tea_CELoss: 1.1034, stu_CELoss: 1.2671, DMLLoss: 0.1893, 
2022-08-01 01:39:52 - train: epoch 0036, iter [03700, 05004], lr: 0.010000, loss: 2.3583, tea_CELoss: 1.0482, stu_CELoss: 1.1467, DMLLoss: 0.1634, 
2022-08-01 01:40:49 - train: epoch 0036, iter [03800, 05004], lr: 0.010000, loss: 2.7252, tea_CELoss: 1.2152, stu_CELoss: 1.3325, DMLLoss: 0.1775, 
2022-08-01 01:41:46 - train: epoch 0036, iter [03900, 05004], lr: 0.010000, loss: 2.6181, tea_CELoss: 1.1287, stu_CELoss: 1.2786, DMLLoss: 0.2109, 
2022-08-01 01:42:44 - train: epoch 0036, iter [04000, 05004], lr: 0.010000, loss: 2.3946, tea_CELoss: 1.0770, stu_CELoss: 1.1465, DMLLoss: 0.1711, 
2022-08-01 01:43:41 - train: epoch 0036, iter [04100, 05004], lr: 0.010000, loss: 2.5426, tea_CELoss: 1.1029, stu_CELoss: 1.2474, DMLLoss: 0.1923, 
2022-08-01 01:44:39 - train: epoch 0036, iter [04200, 05004], lr: 0.010000, loss: 2.6007, tea_CELoss: 1.1249, stu_CELoss: 1.3078, DMLLoss: 0.1680, 
2022-08-01 01:45:36 - train: epoch 0036, iter [04300, 05004], lr: 0.010000, loss: 2.2889, tea_CELoss: 1.0074, stu_CELoss: 1.1178, DMLLoss: 0.1637, 
2022-08-01 01:46:33 - train: epoch 0036, iter [04400, 05004], lr: 0.010000, loss: 2.7713, tea_CELoss: 1.1750, stu_CELoss: 1.4153, DMLLoss: 0.1810, 
2022-08-01 01:47:30 - train: epoch 0036, iter [04500, 05004], lr: 0.010000, loss: 2.4133, tea_CELoss: 1.0621, stu_CELoss: 1.1855, DMLLoss: 0.1657, 
2022-08-01 01:48:28 - train: epoch 0036, iter [04600, 05004], lr: 0.010000, loss: 2.1023, tea_CELoss: 0.9039, stu_CELoss: 1.0603, DMLLoss: 0.1381, 
2022-08-01 01:49:25 - train: epoch 0036, iter [04700, 05004], lr: 0.010000, loss: 2.3481, tea_CELoss: 1.0127, stu_CELoss: 1.1414, DMLLoss: 0.1940, 
2022-08-01 01:50:23 - train: epoch 0036, iter [04800, 05004], lr: 0.010000, loss: 2.2692, tea_CELoss: 0.9772, stu_CELoss: 1.1136, DMLLoss: 0.1784, 
2022-08-01 01:51:20 - train: epoch 0036, iter [04900, 05004], lr: 0.010000, loss: 2.4144, tea_CELoss: 1.0247, stu_CELoss: 1.1983, DMLLoss: 0.1914, 
2022-08-01 01:52:17 - train: epoch 0036, iter [05000, 05004], lr: 0.010000, loss: 2.2600, tea_CELoss: 0.9755, stu_CELoss: 1.1149, DMLLoss: 0.1697, 
2022-08-01 01:52:20 - train: epoch 036, train_loss: 2.4667
2022-08-01 01:54:53 - eval: epoch: 036, tea_acc1: 75.440%, tea_acc5: 92.664%, tea_test_loss: 0.9608, stu_acc1: 73.330%, stu_acc5: 91.482%, stu_test_loss: 1.0594
2022-08-01 01:54:54 - until epoch: 036, tea_best_acc1: 75.440%, stu_best_acc1: 73.330%
2022-08-01 01:54:54 - epoch 037 lr: 0.010000
2022-08-01 01:55:57 - train: epoch 0037, iter [00100, 05004], lr: 0.010000, loss: 2.1549, tea_CELoss: 0.9203, stu_CELoss: 1.0847, DMLLoss: 0.1499, 
2022-08-01 01:56:54 - train: epoch 0037, iter [00200, 05004], lr: 0.010000, loss: 2.2871, tea_CELoss: 0.9883, stu_CELoss: 1.1379, DMLLoss: 0.1608, 
2022-08-01 01:57:51 - train: epoch 0037, iter [00300, 05004], lr: 0.010000, loss: 2.3001, tea_CELoss: 1.0196, stu_CELoss: 1.1113, DMLLoss: 0.1693, 
2022-08-01 01:58:48 - train: epoch 0037, iter [00400, 05004], lr: 0.010000, loss: 1.9667, tea_CELoss: 0.8473, stu_CELoss: 0.9479, DMLLoss: 0.1715, 
2022-08-01 01:59:45 - train: epoch 0037, iter [00500, 05004], lr: 0.010000, loss: 2.7606, tea_CELoss: 1.1761, stu_CELoss: 1.3770, DMLLoss: 0.2075, 
2022-08-01 02:00:43 - train: epoch 0037, iter [00600, 05004], lr: 0.010000, loss: 3.0412, tea_CELoss: 1.3643, stu_CELoss: 1.4884, DMLLoss: 0.1885, 
2022-08-01 02:01:41 - train: epoch 0037, iter [00700, 05004], lr: 0.010000, loss: 2.7727, tea_CELoss: 1.2072, stu_CELoss: 1.3608, DMLLoss: 0.2047, 
2022-08-01 02:02:38 - train: epoch 0037, iter [00800, 05004], lr: 0.010000, loss: 2.0761, tea_CELoss: 0.9487, stu_CELoss: 0.9570, DMLLoss: 0.1704, 
2022-08-01 02:03:35 - train: epoch 0037, iter [00900, 05004], lr: 0.010000, loss: 2.7150, tea_CELoss: 1.1695, stu_CELoss: 1.3456, DMLLoss: 0.1999, 
2022-08-01 02:04:32 - train: epoch 0037, iter [01000, 05004], lr: 0.010000, loss: 2.6447, tea_CELoss: 1.1367, stu_CELoss: 1.3479, DMLLoss: 0.1601, 
2022-08-01 02:05:29 - train: epoch 0037, iter [01100, 05004], lr: 0.010000, loss: 2.6876, tea_CELoss: 1.1824, stu_CELoss: 1.3360, DMLLoss: 0.1692, 
2022-08-01 02:06:27 - train: epoch 0037, iter [01200, 05004], lr: 0.010000, loss: 2.4796, tea_CELoss: 1.0777, stu_CELoss: 1.2515, DMLLoss: 0.1503, 
2022-08-01 02:07:24 - train: epoch 0037, iter [01300, 05004], lr: 0.010000, loss: 2.7698, tea_CELoss: 1.2069, stu_CELoss: 1.3885, DMLLoss: 0.1744, 
2022-08-01 02:08:21 - train: epoch 0037, iter [01400, 05004], lr: 0.010000, loss: 2.8015, tea_CELoss: 1.1819, stu_CELoss: 1.4106, DMLLoss: 0.2089, 
2022-08-01 02:09:18 - train: epoch 0037, iter [01500, 05004], lr: 0.010000, loss: 2.2001, tea_CELoss: 0.9393, stu_CELoss: 1.0981, DMLLoss: 0.1626, 
2022-08-01 02:10:16 - train: epoch 0037, iter [01600, 05004], lr: 0.010000, loss: 2.4973, tea_CELoss: 1.0894, stu_CELoss: 1.2463, DMLLoss: 0.1615, 
2022-08-01 02:11:13 - train: epoch 0037, iter [01700, 05004], lr: 0.010000, loss: 2.2300, tea_CELoss: 0.9517, stu_CELoss: 1.0894, DMLLoss: 0.1890, 
2022-08-01 02:12:10 - train: epoch 0037, iter [01800, 05004], lr: 0.010000, loss: 2.6239, tea_CELoss: 1.1654, stu_CELoss: 1.2771, DMLLoss: 0.1814, 
2022-08-01 02:13:07 - train: epoch 0037, iter [01900, 05004], lr: 0.010000, loss: 2.3884, tea_CELoss: 1.0187, stu_CELoss: 1.1766, DMLLoss: 0.1930, 
2022-08-01 02:14:04 - train: epoch 0037, iter [02000, 05004], lr: 0.010000, loss: 2.3246, tea_CELoss: 1.0365, stu_CELoss: 1.1323, DMLLoss: 0.1559, 
2022-08-01 02:15:02 - train: epoch 0037, iter [02100, 05004], lr: 0.010000, loss: 2.2203, tea_CELoss: 0.9761, stu_CELoss: 1.0642, DMLLoss: 0.1800, 
2022-08-01 02:15:59 - train: epoch 0037, iter [02200, 05004], lr: 0.010000, loss: 2.3786, tea_CELoss: 1.0405, stu_CELoss: 1.1382, DMLLoss: 0.1999, 
2022-08-01 02:16:56 - train: epoch 0037, iter [02300, 05004], lr: 0.010000, loss: 2.1275, tea_CELoss: 0.9094, stu_CELoss: 1.0562, DMLLoss: 0.1619, 
2022-08-01 02:17:53 - train: epoch 0037, iter [02400, 05004], lr: 0.010000, loss: 2.5661, tea_CELoss: 1.1035, stu_CELoss: 1.2426, DMLLoss: 0.2200, 
2022-08-01 02:18:50 - train: epoch 0037, iter [02500, 05004], lr: 0.010000, loss: 2.5811, tea_CELoss: 1.1360, stu_CELoss: 1.2723, DMLLoss: 0.1728, 
2022-08-01 02:19:48 - train: epoch 0037, iter [02600, 05004], lr: 0.010000, loss: 3.2151, tea_CELoss: 1.4335, stu_CELoss: 1.5785, DMLLoss: 0.2031, 
2022-08-01 02:20:45 - train: epoch 0037, iter [02700, 05004], lr: 0.010000, loss: 2.9899, tea_CELoss: 1.2991, stu_CELoss: 1.4833, DMLLoss: 0.2074, 
2022-08-01 02:21:42 - train: epoch 0037, iter [02800, 05004], lr: 0.010000, loss: 2.5387, tea_CELoss: 1.0566, stu_CELoss: 1.3096, DMLLoss: 0.1725, 
2022-08-01 02:22:39 - train: epoch 0037, iter [02900, 05004], lr: 0.010000, loss: 2.4163, tea_CELoss: 1.0671, stu_CELoss: 1.1828, DMLLoss: 0.1665, 
2022-08-01 02:23:37 - train: epoch 0037, iter [03000, 05004], lr: 0.010000, loss: 2.8534, tea_CELoss: 1.2547, stu_CELoss: 1.4207, DMLLoss: 0.1780, 
2022-08-01 02:24:34 - train: epoch 0037, iter [03100, 05004], lr: 0.010000, loss: 2.3221, tea_CELoss: 1.0318, stu_CELoss: 1.1474, DMLLoss: 0.1429, 
2022-08-01 02:25:31 - train: epoch 0037, iter [03200, 05004], lr: 0.010000, loss: 2.7850, tea_CELoss: 1.2282, stu_CELoss: 1.3332, DMLLoss: 0.2236, 
2022-08-01 02:26:28 - train: epoch 0037, iter [03300, 05004], lr: 0.010000, loss: 2.4441, tea_CELoss: 1.1019, stu_CELoss: 1.1904, DMLLoss: 0.1518, 
2022-08-01 02:27:26 - train: epoch 0037, iter [03400, 05004], lr: 0.010000, loss: 2.0932, tea_CELoss: 0.8902, stu_CELoss: 1.0392, DMLLoss: 0.1637, 
2022-08-01 02:28:23 - train: epoch 0037, iter [03500, 05004], lr: 0.010000, loss: 2.3842, tea_CELoss: 1.0541, stu_CELoss: 1.1468, DMLLoss: 0.1833, 
2022-08-01 02:29:20 - train: epoch 0037, iter [03600, 05004], lr: 0.010000, loss: 2.5837, tea_CELoss: 1.0985, stu_CELoss: 1.3063, DMLLoss: 0.1789, 
2022-08-01 02:30:17 - train: epoch 0037, iter [03700, 05004], lr: 0.010000, loss: 2.4751, tea_CELoss: 1.1170, stu_CELoss: 1.1806, DMLLoss: 0.1775, 
2022-08-01 02:31:15 - train: epoch 0037, iter [03800, 05004], lr: 0.010000, loss: 2.5603, tea_CELoss: 1.1018, stu_CELoss: 1.2493, DMLLoss: 0.2092, 
2022-08-01 02:32:12 - train: epoch 0037, iter [03900, 05004], lr: 0.010000, loss: 2.9476, tea_CELoss: 1.3270, stu_CELoss: 1.4298, DMLLoss: 0.1909, 
2022-08-01 02:33:09 - train: epoch 0037, iter [04000, 05004], lr: 0.010000, loss: 2.4760, tea_CELoss: 1.0688, stu_CELoss: 1.2140, DMLLoss: 0.1932, 
2022-08-01 02:34:07 - train: epoch 0037, iter [04100, 05004], lr: 0.010000, loss: 2.4862, tea_CELoss: 1.0794, stu_CELoss: 1.2086, DMLLoss: 0.1982, 
2022-08-01 02:35:04 - train: epoch 0037, iter [04200, 05004], lr: 0.010000, loss: 2.6555, tea_CELoss: 1.2083, stu_CELoss: 1.2826, DMLLoss: 0.1645, 
2022-08-01 02:36:02 - train: epoch 0037, iter [04300, 05004], lr: 0.010000, loss: 2.5349, tea_CELoss: 1.1037, stu_CELoss: 1.2342, DMLLoss: 0.1969, 
2022-08-01 02:36:59 - train: epoch 0037, iter [04400, 05004], lr: 0.010000, loss: 2.4199, tea_CELoss: 1.0794, stu_CELoss: 1.1769, DMLLoss: 0.1636, 
2022-08-01 02:37:56 - train: epoch 0037, iter [04500, 05004], lr: 0.010000, loss: 2.4528, tea_CELoss: 1.0701, stu_CELoss: 1.1975, DMLLoss: 0.1852, 
2022-08-01 02:38:53 - train: epoch 0037, iter [04600, 05004], lr: 0.010000, loss: 2.2883, tea_CELoss: 0.9741, stu_CELoss: 1.1379, DMLLoss: 0.1763, 
2022-08-01 02:39:51 - train: epoch 0037, iter [04700, 05004], lr: 0.010000, loss: 2.3237, tea_CELoss: 1.0061, stu_CELoss: 1.1599, DMLLoss: 0.1577, 
2022-08-01 02:40:48 - train: epoch 0037, iter [04800, 05004], lr: 0.010000, loss: 2.2860, tea_CELoss: 0.9700, stu_CELoss: 1.1449, DMLLoss: 0.1711, 
2022-08-01 02:41:46 - train: epoch 0037, iter [04900, 05004], lr: 0.010000, loss: 2.6124, tea_CELoss: 1.1332, stu_CELoss: 1.2967, DMLLoss: 0.1826, 
2022-08-01 02:42:43 - train: epoch 0037, iter [05000, 05004], lr: 0.010000, loss: 2.5518, tea_CELoss: 1.1065, stu_CELoss: 1.2486, DMLLoss: 0.1967, 
2022-08-01 02:42:46 - train: epoch 037, train_loss: 2.4491
2022-08-01 02:45:15 - eval: epoch: 037, tea_acc1: 75.770%, tea_acc5: 92.850%, tea_test_loss: 0.9514, stu_acc1: 73.634%, stu_acc5: 91.530%, stu_test_loss: 1.0518
2022-08-01 02:45:17 - until epoch: 037, tea_best_acc1: 75.770%, stu_best_acc1: 73.634%
2022-08-01 02:45:17 - epoch 038 lr: 0.010000
2022-08-01 02:46:20 - train: epoch 0038, iter [00100, 05004], lr: 0.010000, loss: 2.1381, tea_CELoss: 0.9354, stu_CELoss: 1.0391, DMLLoss: 0.1636, 
2022-08-01 02:47:17 - train: epoch 0038, iter [00200, 05004], lr: 0.010000, loss: 2.5130, tea_CELoss: 1.0640, stu_CELoss: 1.2618, DMLLoss: 0.1871, 
2022-08-01 02:48:14 - train: epoch 0038, iter [00300, 05004], lr: 0.010000, loss: 2.1912, tea_CELoss: 0.9735, stu_CELoss: 1.0542, DMLLoss: 0.1636, 
2022-08-01 02:49:12 - train: epoch 0038, iter [00400, 05004], lr: 0.010000, loss: 2.1768, tea_CELoss: 0.9442, stu_CELoss: 1.0588, DMLLoss: 0.1738, 
2022-08-01 02:50:09 - train: epoch 0038, iter [00500, 05004], lr: 0.010000, loss: 2.0256, tea_CELoss: 0.8629, stu_CELoss: 0.9859, DMLLoss: 0.1768, 
2022-08-01 02:51:06 - train: epoch 0038, iter [00600, 05004], lr: 0.010000, loss: 2.7838, tea_CELoss: 1.2300, stu_CELoss: 1.3645, DMLLoss: 0.1893, 
2022-08-01 02:52:04 - train: epoch 0038, iter [00700, 05004], lr: 0.010000, loss: 2.1582, tea_CELoss: 0.9306, stu_CELoss: 1.0527, DMLLoss: 0.1749, 
2022-08-01 02:53:01 - train: epoch 0038, iter [00800, 05004], lr: 0.010000, loss: 2.2996, tea_CELoss: 1.0119, stu_CELoss: 1.1051, DMLLoss: 0.1826, 
2022-08-01 02:53:59 - train: epoch 0038, iter [00900, 05004], lr: 0.010000, loss: 2.7220, tea_CELoss: 1.1861, stu_CELoss: 1.3457, DMLLoss: 0.1902, 
2022-08-01 02:54:56 - train: epoch 0038, iter [01000, 05004], lr: 0.010000, loss: 2.6840, tea_CELoss: 1.2085, stu_CELoss: 1.2965, DMLLoss: 0.1790, 
2022-08-01 02:55:53 - train: epoch 0038, iter [01100, 05004], lr: 0.010000, loss: 2.5262, tea_CELoss: 1.0693, stu_CELoss: 1.2528, DMLLoss: 0.2041, 
2022-08-01 02:56:50 - train: epoch 0038, iter [01200, 05004], lr: 0.010000, loss: 2.5470, tea_CELoss: 1.1076, stu_CELoss: 1.2525, DMLLoss: 0.1869, 
2022-08-01 02:57:47 - train: epoch 0038, iter [01300, 05004], lr: 0.010000, loss: 2.2727, tea_CELoss: 0.9964, stu_CELoss: 1.0955, DMLLoss: 0.1807, 
2022-08-01 02:58:44 - train: epoch 0038, iter [01400, 05004], lr: 0.010000, loss: 2.3950, tea_CELoss: 1.0152, stu_CELoss: 1.1936, DMLLoss: 0.1862, 
2022-08-01 02:59:42 - train: epoch 0038, iter [01500, 05004], lr: 0.010000, loss: 2.4493, tea_CELoss: 1.0991, stu_CELoss: 1.2017, DMLLoss: 0.1484, 
2022-08-01 03:00:39 - train: epoch 0038, iter [01600, 05004], lr: 0.010000, loss: 2.3423, tea_CELoss: 1.0232, stu_CELoss: 1.1373, DMLLoss: 0.1817, 
2022-08-01 03:01:36 - train: epoch 0038, iter [01700, 05004], lr: 0.010000, loss: 2.3404, tea_CELoss: 0.9900, stu_CELoss: 1.1648, DMLLoss: 0.1856, 
2022-08-01 03:02:33 - train: epoch 0038, iter [01800, 05004], lr: 0.010000, loss: 2.7287, tea_CELoss: 1.1417, stu_CELoss: 1.3993, DMLLoss: 0.1878, 
2022-08-01 03:03:30 - train: epoch 0038, iter [01900, 05004], lr: 0.010000, loss: 2.6322, tea_CELoss: 1.1256, stu_CELoss: 1.3087, DMLLoss: 0.1979, 
2022-08-01 03:04:27 - train: epoch 0038, iter [02000, 05004], lr: 0.010000, loss: 2.5941, tea_CELoss: 1.1549, stu_CELoss: 1.2650, DMLLoss: 0.1742, 
2022-08-01 03:05:24 - train: epoch 0038, iter [02100, 05004], lr: 0.010000, loss: 2.4613, tea_CELoss: 1.0507, stu_CELoss: 1.2215, DMLLoss: 0.1891, 
2022-08-01 03:06:21 - train: epoch 0038, iter [02200, 05004], lr: 0.010000, loss: 2.3549, tea_CELoss: 1.0356, stu_CELoss: 1.1498, DMLLoss: 0.1695, 
2022-08-01 03:07:17 - train: epoch 0038, iter [02300, 05004], lr: 0.010000, loss: 2.2780, tea_CELoss: 0.9438, stu_CELoss: 1.1354, DMLLoss: 0.1989, 
2022-08-01 03:08:14 - train: epoch 0038, iter [02400, 05004], lr: 0.010000, loss: 2.9706, tea_CELoss: 1.2722, stu_CELoss: 1.4719, DMLLoss: 0.2264, 
2022-08-01 03:09:11 - train: epoch 0038, iter [02500, 05004], lr: 0.010000, loss: 2.4042, tea_CELoss: 1.0196, stu_CELoss: 1.1849, DMLLoss: 0.1998, 
2022-08-01 03:10:08 - train: epoch 0038, iter [02600, 05004], lr: 0.010000, loss: 2.6096, tea_CELoss: 1.1397, stu_CELoss: 1.3085, DMLLoss: 0.1614, 
2022-08-01 03:11:05 - train: epoch 0038, iter [02700, 05004], lr: 0.010000, loss: 2.5961, tea_CELoss: 1.1909, stu_CELoss: 1.2294, DMLLoss: 0.1758, 
2022-08-01 03:12:02 - train: epoch 0038, iter [02800, 05004], lr: 0.010000, loss: 2.8462, tea_CELoss: 1.2609, stu_CELoss: 1.3868, DMLLoss: 0.1984, 
2022-08-01 03:12:58 - train: epoch 0038, iter [02900, 05004], lr: 0.010000, loss: 2.4138, tea_CELoss: 1.0340, stu_CELoss: 1.2031, DMLLoss: 0.1767, 
2022-08-01 03:13:55 - train: epoch 0038, iter [03000, 05004], lr: 0.010000, loss: 2.4263, tea_CELoss: 1.0737, stu_CELoss: 1.1653, DMLLoss: 0.1872, 
2022-08-01 03:14:52 - train: epoch 0038, iter [03100, 05004], lr: 0.010000, loss: 2.6601, tea_CELoss: 1.1945, stu_CELoss: 1.2947, DMLLoss: 0.1709, 
2022-08-01 03:15:49 - train: epoch 0038, iter [03200, 05004], lr: 0.010000, loss: 1.9793, tea_CELoss: 0.8721, stu_CELoss: 0.9633, DMLLoss: 0.1439, 
2022-08-01 03:16:46 - train: epoch 0038, iter [03300, 05004], lr: 0.010000, loss: 1.9931, tea_CELoss: 0.8787, stu_CELoss: 0.9570, DMLLoss: 0.1574, 
2022-08-01 03:17:43 - train: epoch 0038, iter [03400, 05004], lr: 0.010000, loss: 2.3145, tea_CELoss: 0.9998, stu_CELoss: 1.1448, DMLLoss: 0.1700, 
2022-08-01 03:18:40 - train: epoch 0038, iter [03500, 05004], lr: 0.010000, loss: 2.4074, tea_CELoss: 1.0668, stu_CELoss: 1.1773, DMLLoss: 0.1633, 
2022-08-01 03:19:37 - train: epoch 0038, iter [03600, 05004], lr: 0.010000, loss: 2.2512, tea_CELoss: 0.9654, stu_CELoss: 1.1043, DMLLoss: 0.1815, 
2022-08-01 03:20:34 - train: epoch 0038, iter [03700, 05004], lr: 0.010000, loss: 2.2868, tea_CELoss: 1.0145, stu_CELoss: 1.1143, DMLLoss: 0.1581, 
2022-08-01 03:21:31 - train: epoch 0038, iter [03800, 05004], lr: 0.010000, loss: 2.6759, tea_CELoss: 1.1665, stu_CELoss: 1.3163, DMLLoss: 0.1931, 
2022-08-01 03:22:28 - train: epoch 0038, iter [03900, 05004], lr: 0.010000, loss: 2.3063, tea_CELoss: 0.9945, stu_CELoss: 1.1238, DMLLoss: 0.1881, 
2022-08-01 03:23:25 - train: epoch 0038, iter [04000, 05004], lr: 0.010000, loss: 2.4467, tea_CELoss: 1.0706, stu_CELoss: 1.1897, DMLLoss: 0.1865, 
2022-08-01 03:24:23 - train: epoch 0038, iter [04100, 05004], lr: 0.010000, loss: 2.1724, tea_CELoss: 0.9201, stu_CELoss: 1.0706, DMLLoss: 0.1817, 
2022-08-01 03:25:20 - train: epoch 0038, iter [04200, 05004], lr: 0.010000, loss: 2.1339, tea_CELoss: 0.9081, stu_CELoss: 1.0652, DMLLoss: 0.1606, 
2022-08-01 03:26:17 - train: epoch 0038, iter [04300, 05004], lr: 0.010000, loss: 2.7115, tea_CELoss: 1.1896, stu_CELoss: 1.3245, DMLLoss: 0.1975, 
2022-08-01 03:27:14 - train: epoch 0038, iter [04400, 05004], lr: 0.010000, loss: 2.5489, tea_CELoss: 1.0982, stu_CELoss: 1.2548, DMLLoss: 0.1959, 
2022-08-01 03:28:11 - train: epoch 0038, iter [04500, 05004], lr: 0.010000, loss: 2.6278, tea_CELoss: 1.1453, stu_CELoss: 1.2717, DMLLoss: 0.2108, 
2022-08-01 03:29:08 - train: epoch 0038, iter [04600, 05004], lr: 0.010000, loss: 2.6574, tea_CELoss: 1.1795, stu_CELoss: 1.3104, DMLLoss: 0.1674, 
2022-08-01 03:30:05 - train: epoch 0038, iter [04700, 05004], lr: 0.010000, loss: 2.6429, tea_CELoss: 1.1780, stu_CELoss: 1.2804, DMLLoss: 0.1846, 
2022-08-01 03:31:02 - train: epoch 0038, iter [04800, 05004], lr: 0.010000, loss: 2.4560, tea_CELoss: 1.0835, stu_CELoss: 1.2125, DMLLoss: 0.1600, 
2022-08-01 03:31:59 - train: epoch 0038, iter [04900, 05004], lr: 0.010000, loss: 2.3688, tea_CELoss: 1.0335, stu_CELoss: 1.1590, DMLLoss: 0.1762, 
2022-08-01 03:32:56 - train: epoch 0038, iter [05000, 05004], lr: 0.010000, loss: 2.1708, tea_CELoss: 0.9103, stu_CELoss: 1.0960, DMLLoss: 0.1645, 
2022-08-01 03:32:59 - train: epoch 038, train_loss: 2.4317
2022-08-01 03:35:32 - eval: epoch: 038, tea_acc1: 75.702%, tea_acc5: 92.804%, tea_test_loss: 0.9499, stu_acc1: 73.394%, stu_acc5: 91.488%, stu_test_loss: 1.0591
2022-08-01 03:35:33 - until epoch: 038, tea_best_acc1: 75.770%, stu_best_acc1: 73.634%
2022-08-01 03:35:33 - epoch 039 lr: 0.010000
2022-08-01 03:36:36 - train: epoch 0039, iter [00100, 05004], lr: 0.010000, loss: 2.4181, tea_CELoss: 1.0456, stu_CELoss: 1.2104, DMLLoss: 0.1621, 
2022-08-01 03:37:33 - train: epoch 0039, iter [00200, 05004], lr: 0.010000, loss: 2.7649, tea_CELoss: 1.2259, stu_CELoss: 1.3508, DMLLoss: 0.1882, 
2022-08-01 03:38:31 - train: epoch 0039, iter [00300, 05004], lr: 0.010000, loss: 2.1803, tea_CELoss: 0.9534, stu_CELoss: 1.0681, DMLLoss: 0.1588, 
2022-08-01 03:39:29 - train: epoch 0039, iter [00400, 05004], lr: 0.010000, loss: 2.5220, tea_CELoss: 1.1092, stu_CELoss: 1.2488, DMLLoss: 0.1641, 
2022-08-01 03:40:27 - train: epoch 0039, iter [00500, 05004], lr: 0.010000, loss: 2.4736, tea_CELoss: 1.0688, stu_CELoss: 1.2189, DMLLoss: 0.1859, 
2022-08-01 03:41:24 - train: epoch 0039, iter [00600, 05004], lr: 0.010000, loss: 2.1473, tea_CELoss: 0.8991, stu_CELoss: 1.0782, DMLLoss: 0.1699, 
2022-08-01 03:42:22 - train: epoch 0039, iter [00700, 05004], lr: 0.010000, loss: 3.0034, tea_CELoss: 1.3170, stu_CELoss: 1.4759, DMLLoss: 0.2105, 
2022-08-01 03:43:20 - train: epoch 0039, iter [00800, 05004], lr: 0.010000, loss: 2.4206, tea_CELoss: 1.0296, stu_CELoss: 1.1905, DMLLoss: 0.2005, 
2022-08-01 03:44:17 - train: epoch 0039, iter [00900, 05004], lr: 0.010000, loss: 2.5281, tea_CELoss: 1.1051, stu_CELoss: 1.2518, DMLLoss: 0.1712, 
2022-08-01 03:45:15 - train: epoch 0039, iter [01000, 05004], lr: 0.010000, loss: 2.3608, tea_CELoss: 1.0197, stu_CELoss: 1.1708, DMLLoss: 0.1704, 
2022-08-01 03:46:12 - train: epoch 0039, iter [01100, 05004], lr: 0.010000, loss: 2.6657, tea_CELoss: 1.1965, stu_CELoss: 1.2733, DMLLoss: 0.1959, 
2022-08-01 03:47:09 - train: epoch 0039, iter [01200, 05004], lr: 0.010000, loss: 2.2768, tea_CELoss: 0.9754, stu_CELoss: 1.1440, DMLLoss: 0.1575, 
2022-08-01 03:48:06 - train: epoch 0039, iter [01300, 05004], lr: 0.010000, loss: 2.7529, tea_CELoss: 1.1744, stu_CELoss: 1.3889, DMLLoss: 0.1896, 
2022-08-01 03:49:03 - train: epoch 0039, iter [01400, 05004], lr: 0.010000, loss: 2.3783, tea_CELoss: 1.0562, stu_CELoss: 1.1448, DMLLoss: 0.1773, 
2022-08-01 03:50:00 - train: epoch 0039, iter [01500, 05004], lr: 0.010000, loss: 2.0451, tea_CELoss: 0.8598, stu_CELoss: 0.9985, DMLLoss: 0.1868, 
2022-08-01 03:50:57 - train: epoch 0039, iter [01600, 05004], lr: 0.010000, loss: 2.4047, tea_CELoss: 1.0281, stu_CELoss: 1.1750, DMLLoss: 0.2016, 
2022-08-01 03:51:54 - train: epoch 0039, iter [01700, 05004], lr: 0.010000, loss: 2.3437, tea_CELoss: 1.0052, stu_CELoss: 1.1700, DMLLoss: 0.1685, 
2022-08-01 03:52:51 - train: epoch 0039, iter [01800, 05004], lr: 0.010000, loss: 2.5091, tea_CELoss: 1.0910, stu_CELoss: 1.2337, DMLLoss: 0.1843, 
2022-08-01 03:53:49 - train: epoch 0039, iter [01900, 05004], lr: 0.010000, loss: 2.0085, tea_CELoss: 0.8993, stu_CELoss: 0.9317, DMLLoss: 0.1775, 
2022-08-01 03:54:46 - train: epoch 0039, iter [02000, 05004], lr: 0.010000, loss: 2.3519, tea_CELoss: 1.0171, stu_CELoss: 1.1407, DMLLoss: 0.1941, 
2022-08-01 03:55:42 - train: epoch 0039, iter [02100, 05004], lr: 0.010000, loss: 2.6423, tea_CELoss: 1.1446, stu_CELoss: 1.2922, DMLLoss: 0.2055, 
2022-08-01 03:56:40 - train: epoch 0039, iter [02200, 05004], lr: 0.010000, loss: 2.2361, tea_CELoss: 0.9743, stu_CELoss: 1.0754, DMLLoss: 0.1864, 
2022-08-01 03:57:37 - train: epoch 0039, iter [02300, 05004], lr: 0.010000, loss: 3.0077, tea_CELoss: 1.3359, stu_CELoss: 1.4619, DMLLoss: 0.2099, 
2022-08-01 03:58:33 - train: epoch 0039, iter [02400, 05004], lr: 0.010000, loss: 2.8243, tea_CELoss: 1.1984, stu_CELoss: 1.3994, DMLLoss: 0.2266, 
2022-08-01 03:59:31 - train: epoch 0039, iter [02500, 05004], lr: 0.010000, loss: 2.5401, tea_CELoss: 1.0829, stu_CELoss: 1.2540, DMLLoss: 0.2033, 
2022-08-01 04:00:28 - train: epoch 0039, iter [02600, 05004], lr: 0.010000, loss: 2.3607, tea_CELoss: 0.9832, stu_CELoss: 1.1968, DMLLoss: 0.1807, 
2022-08-01 04:01:24 - train: epoch 0039, iter [02700, 05004], lr: 0.010000, loss: 2.6229, tea_CELoss: 1.1435, stu_CELoss: 1.2800, DMLLoss: 0.1994, 
2022-08-01 04:02:22 - train: epoch 0039, iter [02800, 05004], lr: 0.010000, loss: 2.4096, tea_CELoss: 1.0222, stu_CELoss: 1.1964, DMLLoss: 0.1909, 
2022-08-01 04:03:18 - train: epoch 0039, iter [02900, 05004], lr: 0.010000, loss: 2.1103, tea_CELoss: 0.9357, stu_CELoss: 1.0197, DMLLoss: 0.1550, 
2022-08-01 04:04:16 - train: epoch 0039, iter [03000, 05004], lr: 0.010000, loss: 2.3891, tea_CELoss: 1.0513, stu_CELoss: 1.1630, DMLLoss: 0.1748, 
2022-08-01 04:05:13 - train: epoch 0039, iter [03100, 05004], lr: 0.010000, loss: 2.2546, tea_CELoss: 0.9561, stu_CELoss: 1.1109, DMLLoss: 0.1877, 
2022-08-01 04:06:10 - train: epoch 0039, iter [03200, 05004], lr: 0.010000, loss: 2.2758, tea_CELoss: 0.9336, stu_CELoss: 1.1358, DMLLoss: 0.2064, 
2022-08-01 04:07:07 - train: epoch 0039, iter [03300, 05004], lr: 0.010000, loss: 2.3523, tea_CELoss: 1.0084, stu_CELoss: 1.1509, DMLLoss: 0.1929, 
2022-08-01 04:08:04 - train: epoch 0039, iter [03400, 05004], lr: 0.010000, loss: 2.6604, tea_CELoss: 1.1605, stu_CELoss: 1.3083, DMLLoss: 0.1915, 
2022-08-01 04:09:01 - train: epoch 0039, iter [03500, 05004], lr: 0.010000, loss: 2.6848, tea_CELoss: 1.1967, stu_CELoss: 1.3046, DMLLoss: 0.1836, 
2022-08-01 04:09:58 - train: epoch 0039, iter [03600, 05004], lr: 0.010000, loss: 2.7713, tea_CELoss: 1.2275, stu_CELoss: 1.3510, DMLLoss: 0.1928, 
2022-08-01 04:10:55 - train: epoch 0039, iter [03700, 05004], lr: 0.010000, loss: 2.2518, tea_CELoss: 0.9967, stu_CELoss: 1.0743, DMLLoss: 0.1808, 
2022-08-01 04:11:52 - train: epoch 0039, iter [03800, 05004], lr: 0.010000, loss: 2.0452, tea_CELoss: 0.8843, stu_CELoss: 0.9974, DMLLoss: 0.1635, 
2022-08-01 04:12:49 - train: epoch 0039, iter [03900, 05004], lr: 0.010000, loss: 2.4274, tea_CELoss: 1.0534, stu_CELoss: 1.1712, DMLLoss: 0.2028, 
2022-08-01 04:13:46 - train: epoch 0039, iter [04000, 05004], lr: 0.010000, loss: 2.4442, tea_CELoss: 1.0748, stu_CELoss: 1.1728, DMLLoss: 0.1966, 
2022-08-01 04:14:43 - train: epoch 0039, iter [04100, 05004], lr: 0.010000, loss: 2.4391, tea_CELoss: 1.0629, stu_CELoss: 1.1773, DMLLoss: 0.1988, 
2022-08-01 04:15:40 - train: epoch 0039, iter [04200, 05004], lr: 0.010000, loss: 2.7048, tea_CELoss: 1.1788, stu_CELoss: 1.3385, DMLLoss: 0.1874, 
2022-08-01 04:16:37 - train: epoch 0039, iter [04300, 05004], lr: 0.010000, loss: 2.3817, tea_CELoss: 0.9985, stu_CELoss: 1.1979, DMLLoss: 0.1853, 
2022-08-01 04:17:34 - train: epoch 0039, iter [04400, 05004], lr: 0.010000, loss: 2.3353, tea_CELoss: 1.0095, stu_CELoss: 1.1453, DMLLoss: 0.1805, 
2022-08-01 04:18:31 - train: epoch 0039, iter [04500, 05004], lr: 0.010000, loss: 2.3119, tea_CELoss: 1.0160, stu_CELoss: 1.1363, DMLLoss: 0.1595, 
2022-08-01 04:19:28 - train: epoch 0039, iter [04600, 05004], lr: 0.010000, loss: 2.5905, tea_CELoss: 1.1065, stu_CELoss: 1.2684, DMLLoss: 0.2156, 
2022-08-01 04:20:25 - train: epoch 0039, iter [04700, 05004], lr: 0.010000, loss: 2.4246, tea_CELoss: 0.9937, stu_CELoss: 1.2063, DMLLoss: 0.2246, 
2022-08-01 04:21:22 - train: epoch 0039, iter [04800, 05004], lr: 0.010000, loss: 2.1603, tea_CELoss: 0.9500, stu_CELoss: 1.0363, DMLLoss: 0.1741, 
2022-08-01 04:22:19 - train: epoch 0039, iter [04900, 05004], lr: 0.010000, loss: 2.0853, tea_CELoss: 0.9404, stu_CELoss: 0.9603, DMLLoss: 0.1846, 
2022-08-01 04:23:16 - train: epoch 0039, iter [05000, 05004], lr: 0.010000, loss: 2.4330, tea_CELoss: 1.0582, stu_CELoss: 1.1669, DMLLoss: 0.2079, 
2022-08-01 04:23:19 - train: epoch 039, train_loss: 2.4207
2022-08-01 04:25:51 - eval: epoch: 039, tea_acc1: 75.684%, tea_acc5: 92.864%, tea_test_loss: 0.9502, stu_acc1: 73.240%, stu_acc5: 91.566%, stu_test_loss: 1.0578
2022-08-01 04:25:52 - until epoch: 039, tea_best_acc1: 75.770%, stu_best_acc1: 73.634%
2022-08-01 04:25:52 - epoch 040 lr: 0.010000
2022-08-01 04:26:55 - train: epoch 0040, iter [00100, 05004], lr: 0.010000, loss: 2.8885, tea_CELoss: 1.2878, stu_CELoss: 1.4183, DMLLoss: 0.1825, 
2022-08-01 04:27:52 - train: epoch 0040, iter [00200, 05004], lr: 0.010000, loss: 2.6460, tea_CELoss: 1.1756, stu_CELoss: 1.2738, DMLLoss: 0.1967, 
2022-08-01 04:28:49 - train: epoch 0040, iter [00300, 05004], lr: 0.010000, loss: 2.8400, tea_CELoss: 1.2834, stu_CELoss: 1.3652, DMLLoss: 0.1914, 
2022-08-01 04:29:47 - train: epoch 0040, iter [00400, 05004], lr: 0.010000, loss: 1.9910, tea_CELoss: 0.8351, stu_CELoss: 0.9531, DMLLoss: 0.2028, 
2022-08-01 04:30:44 - train: epoch 0040, iter [00500, 05004], lr: 0.010000, loss: 2.1724, tea_CELoss: 0.9525, stu_CELoss: 1.0539, DMLLoss: 0.1660, 
2022-08-01 04:31:41 - train: epoch 0040, iter [00600, 05004], lr: 0.010000, loss: 2.1484, tea_CELoss: 0.8976, stu_CELoss: 1.0604, DMLLoss: 0.1904, 
2022-08-01 04:32:39 - train: epoch 0040, iter [00700, 05004], lr: 0.010000, loss: 2.5607, tea_CELoss: 1.0998, stu_CELoss: 1.2685, DMLLoss: 0.1923, 
2022-08-01 04:33:36 - train: epoch 0040, iter [00800, 05004], lr: 0.010000, loss: 2.3556, tea_CELoss: 1.0165, stu_CELoss: 1.1442, DMLLoss: 0.1949, 
2022-08-01 04:34:33 - train: epoch 0040, iter [00900, 05004], lr: 0.010000, loss: 2.2310, tea_CELoss: 0.9666, stu_CELoss: 1.0833, DMLLoss: 0.1811, 
2022-08-01 04:35:31 - train: epoch 0040, iter [01000, 05004], lr: 0.010000, loss: 2.1967, tea_CELoss: 0.9507, stu_CELoss: 1.0543, DMLLoss: 0.1917, 
2022-08-01 04:36:28 - train: epoch 0040, iter [01100, 05004], lr: 0.010000, loss: 1.9688, tea_CELoss: 0.8315, stu_CELoss: 0.9685, DMLLoss: 0.1687, 
2022-08-01 04:37:25 - train: epoch 0040, iter [01200, 05004], lr: 0.010000, loss: 2.1589, tea_CELoss: 0.9295, stu_CELoss: 1.0413, DMLLoss: 0.1881, 
2022-08-01 04:38:23 - train: epoch 0040, iter [01300, 05004], lr: 0.010000, loss: 2.1522, tea_CELoss: 0.9287, stu_CELoss: 1.0405, DMLLoss: 0.1830, 
2022-08-01 04:39:20 - train: epoch 0040, iter [01400, 05004], lr: 0.010000, loss: 2.6459, tea_CELoss: 1.1387, stu_CELoss: 1.3136, DMLLoss: 0.1936, 
2022-08-01 04:40:17 - train: epoch 0040, iter [01500, 05004], lr: 0.010000, loss: 2.8043, tea_CELoss: 1.2701, stu_CELoss: 1.3639, DMLLoss: 0.1703, 
2022-08-01 04:41:14 - train: epoch 0040, iter [01600, 05004], lr: 0.010000, loss: 2.3554, tea_CELoss: 1.0181, stu_CELoss: 1.1527, DMLLoss: 0.1846, 
2022-08-01 04:42:12 - train: epoch 0040, iter [01700, 05004], lr: 0.010000, loss: 2.4194, tea_CELoss: 1.0084, stu_CELoss: 1.2095, DMLLoss: 0.2015, 
2022-08-01 04:43:09 - train: epoch 0040, iter [01800, 05004], lr: 0.010000, loss: 2.1811, tea_CELoss: 0.9587, stu_CELoss: 1.0573, DMLLoss: 0.1651, 
2022-08-01 04:44:07 - train: epoch 0040, iter [01900, 05004], lr: 0.010000, loss: 2.2411, tea_CELoss: 0.9695, stu_CELoss: 1.0855, DMLLoss: 0.1861, 
2022-08-01 04:45:04 - train: epoch 0040, iter [02000, 05004], lr: 0.010000, loss: 2.3178, tea_CELoss: 1.0362, stu_CELoss: 1.1170, DMLLoss: 0.1646, 
2022-08-01 04:46:01 - train: epoch 0040, iter [02100, 05004], lr: 0.010000, loss: 1.9665, tea_CELoss: 0.8468, stu_CELoss: 0.9466, DMLLoss: 0.1731, 
2022-08-01 04:46:59 - train: epoch 0040, iter [02200, 05004], lr: 0.010000, loss: 2.6020, tea_CELoss: 1.1391, stu_CELoss: 1.2716, DMLLoss: 0.1913, 
2022-08-01 04:47:56 - train: epoch 0040, iter [02300, 05004], lr: 0.010000, loss: 2.4180, tea_CELoss: 1.0592, stu_CELoss: 1.1892, DMLLoss: 0.1695, 
2022-08-01 04:48:54 - train: epoch 0040, iter [02400, 05004], lr: 0.010000, loss: 2.4677, tea_CELoss: 1.0615, stu_CELoss: 1.2086, DMLLoss: 0.1976, 
2022-08-01 04:49:51 - train: epoch 0040, iter [02500, 05004], lr: 0.010000, loss: 2.6081, tea_CELoss: 1.1532, stu_CELoss: 1.2565, DMLLoss: 0.1984, 
2022-08-01 04:50:49 - train: epoch 0040, iter [02600, 05004], lr: 0.010000, loss: 2.4903, tea_CELoss: 1.0869, stu_CELoss: 1.2200, DMLLoss: 0.1834, 
2022-08-01 04:51:46 - train: epoch 0040, iter [02700, 05004], lr: 0.010000, loss: 2.6368, tea_CELoss: 1.1576, stu_CELoss: 1.2820, DMLLoss: 0.1972, 
2022-08-01 04:52:43 - train: epoch 0040, iter [02800, 05004], lr: 0.010000, loss: 2.4261, tea_CELoss: 1.0557, stu_CELoss: 1.1731, DMLLoss: 0.1973, 
2022-08-01 04:53:41 - train: epoch 0040, iter [02900, 05004], lr: 0.010000, loss: 2.7055, tea_CELoss: 1.1884, stu_CELoss: 1.3237, DMLLoss: 0.1934, 
2022-08-01 04:54:38 - train: epoch 0040, iter [03000, 05004], lr: 0.010000, loss: 2.3907, tea_CELoss: 1.0142, stu_CELoss: 1.1739, DMLLoss: 0.2025, 
2022-08-01 04:55:35 - train: epoch 0040, iter [03100, 05004], lr: 0.010000, loss: 2.5642, tea_CELoss: 1.0741, stu_CELoss: 1.2528, DMLLoss: 0.2373, 
2022-08-01 04:56:33 - train: epoch 0040, iter [03200, 05004], lr: 0.010000, loss: 3.0417, tea_CELoss: 1.3378, stu_CELoss: 1.4661, DMLLoss: 0.2379, 
2022-08-01 04:57:30 - train: epoch 0040, iter [03300, 05004], lr: 0.010000, loss: 2.6883, tea_CELoss: 1.1614, stu_CELoss: 1.3237, DMLLoss: 0.2033, 
2022-08-01 04:58:27 - train: epoch 0040, iter [03400, 05004], lr: 0.010000, loss: 2.2453, tea_CELoss: 0.9468, stu_CELoss: 1.1083, DMLLoss: 0.1902, 
2022-08-01 04:59:25 - train: epoch 0040, iter [03500, 05004], lr: 0.010000, loss: 2.6736, tea_CELoss: 1.1757, stu_CELoss: 1.2789, DMLLoss: 0.2189, 
2022-08-01 05:00:22 - train: epoch 0040, iter [03600, 05004], lr: 0.010000, loss: 2.2405, tea_CELoss: 0.9554, stu_CELoss: 1.0944, DMLLoss: 0.1906, 
2022-08-01 05:01:19 - train: epoch 0040, iter [03700, 05004], lr: 0.010000, loss: 2.2714, tea_CELoss: 0.9553, stu_CELoss: 1.1190, DMLLoss: 0.1972, 
2022-08-01 05:02:17 - train: epoch 0040, iter [03800, 05004], lr: 0.010000, loss: 2.1882, tea_CELoss: 0.9435, stu_CELoss: 1.0643, DMLLoss: 0.1804, 
2022-08-01 05:03:14 - train: epoch 0040, iter [03900, 05004], lr: 0.010000, loss: 2.4138, tea_CELoss: 1.0268, stu_CELoss: 1.1832, DMLLoss: 0.2037, 
2022-08-01 05:04:12 - train: epoch 0040, iter [04000, 05004], lr: 0.010000, loss: 2.4307, tea_CELoss: 1.0696, stu_CELoss: 1.1717, DMLLoss: 0.1895, 
2022-08-01 05:05:09 - train: epoch 0040, iter [04100, 05004], lr: 0.010000, loss: 2.1682, tea_CELoss: 0.9266, stu_CELoss: 1.0401, DMLLoss: 0.2015, 
2022-08-01 05:06:07 - train: epoch 0040, iter [04200, 05004], lr: 0.010000, loss: 1.9515, tea_CELoss: 0.8199, stu_CELoss: 0.9411, DMLLoss: 0.1905, 
2022-08-01 05:07:04 - train: epoch 0040, iter [04300, 05004], lr: 0.010000, loss: 2.5168, tea_CELoss: 1.1033, stu_CELoss: 1.2125, DMLLoss: 0.2011, 
2022-08-01 05:08:01 - train: epoch 0040, iter [04400, 05004], lr: 0.010000, loss: 2.2153, tea_CELoss: 0.9376, stu_CELoss: 1.0931, DMLLoss: 0.1846, 
2022-08-01 05:08:59 - train: epoch 0040, iter [04500, 05004], lr: 0.010000, loss: 2.1637, tea_CELoss: 0.9100, stu_CELoss: 1.0570, DMLLoss: 0.1967, 
2022-08-01 05:09:57 - train: epoch 0040, iter [04600, 05004], lr: 0.010000, loss: 2.4601, tea_CELoss: 1.0284, stu_CELoss: 1.2219, DMLLoss: 0.2097, 
2022-08-01 05:10:54 - train: epoch 0040, iter [04700, 05004], lr: 0.010000, loss: 2.6154, tea_CELoss: 1.1542, stu_CELoss: 1.2387, DMLLoss: 0.2226, 
2022-08-01 05:11:52 - train: epoch 0040, iter [04800, 05004], lr: 0.010000, loss: 2.4185, tea_CELoss: 1.0323, stu_CELoss: 1.1839, DMLLoss: 0.2023, 
2022-08-01 05:12:49 - train: epoch 0040, iter [04900, 05004], lr: 0.010000, loss: 2.4630, tea_CELoss: 1.0865, stu_CELoss: 1.2003, DMLLoss: 0.1762, 
2022-08-01 05:13:47 - train: epoch 0040, iter [05000, 05004], lr: 0.010000, loss: 2.4224, tea_CELoss: 0.9885, stu_CELoss: 1.1974, DMLLoss: 0.2364, 
2022-08-01 05:13:50 - train: epoch 040, train_loss: 2.4081
2022-08-01 05:16:21 - eval: epoch: 040, tea_acc1: 75.622%, tea_acc5: 92.794%, tea_test_loss: 0.9459, stu_acc1: 72.976%, stu_acc5: 91.182%, stu_test_loss: 1.0850
2022-08-01 05:16:21 - until epoch: 040, tea_best_acc1: 75.770%, stu_best_acc1: 73.634%
2022-08-01 05:16:21 - epoch 041 lr: 0.010000
2022-08-01 05:17:25 - train: epoch 0041, iter [00100, 05004], lr: 0.010000, loss: 2.6306, tea_CELoss: 1.1426, stu_CELoss: 1.2859, DMLLoss: 0.2021, 
2022-08-01 05:18:22 - train: epoch 0041, iter [00200, 05004], lr: 0.010000, loss: 2.8914, tea_CELoss: 1.2413, stu_CELoss: 1.4584, DMLLoss: 0.1917, 
2022-08-01 05:19:20 - train: epoch 0041, iter [00300, 05004], lr: 0.010000, loss: 2.6277, tea_CELoss: 1.1345, stu_CELoss: 1.2882, DMLLoss: 0.2050, 
2022-08-01 05:20:17 - train: epoch 0041, iter [00400, 05004], lr: 0.010000, loss: 2.2325, tea_CELoss: 0.9892, stu_CELoss: 1.0451, DMLLoss: 0.1982, 
2022-08-01 05:21:15 - train: epoch 0041, iter [00500, 05004], lr: 0.010000, loss: 2.0824, tea_CELoss: 0.8806, stu_CELoss: 1.0016, DMLLoss: 0.2002, 
2022-08-01 05:22:12 - train: epoch 0041, iter [00600, 05004], lr: 0.010000, loss: 2.3860, tea_CELoss: 1.0022, stu_CELoss: 1.1782, DMLLoss: 0.2056, 
2022-08-01 05:23:10 - train: epoch 0041, iter [00700, 05004], lr: 0.010000, loss: 2.2515, tea_CELoss: 0.9348, stu_CELoss: 1.1090, DMLLoss: 0.2077, 
2022-08-01 05:24:07 - train: epoch 0041, iter [00800, 05004], lr: 0.010000, loss: 2.4040, tea_CELoss: 1.0044, stu_CELoss: 1.1963, DMLLoss: 0.2033, 
2022-08-01 05:25:05 - train: epoch 0041, iter [00900, 05004], lr: 0.010000, loss: 2.3689, tea_CELoss: 1.0397, stu_CELoss: 1.1594, DMLLoss: 0.1697, 
2022-08-01 05:26:02 - train: epoch 0041, iter [01000, 05004], lr: 0.010000, loss: 2.6488, tea_CELoss: 1.1477, stu_CELoss: 1.3095, DMLLoss: 0.1916, 
2022-08-01 05:27:00 - train: epoch 0041, iter [01100, 05004], lr: 0.010000, loss: 2.4027, tea_CELoss: 1.0227, stu_CELoss: 1.1954, DMLLoss: 0.1846, 
2022-08-01 05:27:57 - train: epoch 0041, iter [01200, 05004], lr: 0.010000, loss: 2.1417, tea_CELoss: 0.9314, stu_CELoss: 1.0448, DMLLoss: 0.1656, 
2022-08-01 05:28:55 - train: epoch 0041, iter [01300, 05004], lr: 0.010000, loss: 2.0317, tea_CELoss: 0.8740, stu_CELoss: 0.9809, DMLLoss: 0.1768, 
2022-08-01 05:29:52 - train: epoch 0041, iter [01400, 05004], lr: 0.010000, loss: 2.6154, tea_CELoss: 1.1299, stu_CELoss: 1.2483, DMLLoss: 0.2371, 
2022-08-01 05:30:50 - train: epoch 0041, iter [01500, 05004], lr: 0.010000, loss: 2.5433, tea_CELoss: 1.1031, stu_CELoss: 1.2384, DMLLoss: 0.2018, 
2022-08-01 05:31:47 - train: epoch 0041, iter [01600, 05004], lr: 0.010000, loss: 2.1121, tea_CELoss: 0.8731, stu_CELoss: 1.0337, DMLLoss: 0.2053, 
2022-08-01 05:32:45 - train: epoch 0041, iter [01700, 05004], lr: 0.010000, loss: 2.3386, tea_CELoss: 1.0232, stu_CELoss: 1.1291, DMLLoss: 0.1863, 
2022-08-01 05:33:42 - train: epoch 0041, iter [01800, 05004], lr: 0.010000, loss: 2.5076, tea_CELoss: 1.0772, stu_CELoss: 1.2338, DMLLoss: 0.1966, 
2022-08-01 05:34:40 - train: epoch 0041, iter [01900, 05004], lr: 0.010000, loss: 2.3580, tea_CELoss: 1.0046, stu_CELoss: 1.1683, DMLLoss: 0.1851, 
2022-08-01 05:35:37 - train: epoch 0041, iter [02000, 05004], lr: 0.010000, loss: 2.2887, tea_CELoss: 0.9592, stu_CELoss: 1.1266, DMLLoss: 0.2029, 
2022-08-01 05:36:35 - train: epoch 0041, iter [02100, 05004], lr: 0.010000, loss: 2.2111, tea_CELoss: 0.9610, stu_CELoss: 1.0577, DMLLoss: 0.1924, 
2022-08-01 05:37:32 - train: epoch 0041, iter [02200, 05004], lr: 0.010000, loss: 2.1392, tea_CELoss: 0.9045, stu_CELoss: 1.0483, DMLLoss: 0.1864, 
2022-08-01 05:38:30 - train: epoch 0041, iter [02300, 05004], lr: 0.010000, loss: 2.4225, tea_CELoss: 1.0162, stu_CELoss: 1.1829, DMLLoss: 0.2234, 
2022-08-01 05:39:27 - train: epoch 0041, iter [02400, 05004], lr: 0.010000, loss: 2.7435, tea_CELoss: 1.1662, stu_CELoss: 1.3471, DMLLoss: 0.2303, 
2022-08-01 05:40:25 - train: epoch 0041, iter [02500, 05004], lr: 0.010000, loss: 2.2603, tea_CELoss: 1.0029, stu_CELoss: 1.0815, DMLLoss: 0.1760, 
2022-08-01 05:41:22 - train: epoch 0041, iter [02600, 05004], lr: 0.010000, loss: 2.6724, tea_CELoss: 1.1664, stu_CELoss: 1.3058, DMLLoss: 0.2002, 
2022-08-01 05:42:20 - train: epoch 0041, iter [02700, 05004], lr: 0.010000, loss: 2.9006, tea_CELoss: 1.2690, stu_CELoss: 1.4136, DMLLoss: 0.2180, 
2022-08-01 05:43:17 - train: epoch 0041, iter [02800, 05004], lr: 0.010000, loss: 2.0450, tea_CELoss: 0.8834, stu_CELoss: 0.9852, DMLLoss: 0.1764, 
2022-08-01 05:44:15 - train: epoch 0041, iter [02900, 05004], lr: 0.010000, loss: 2.2399, tea_CELoss: 0.9561, stu_CELoss: 1.0972, DMLLoss: 0.1865, 
2022-08-01 05:45:12 - train: epoch 0041, iter [03000, 05004], lr: 0.010000, loss: 2.5737, tea_CELoss: 1.1316, stu_CELoss: 1.2447, DMLLoss: 0.1974, 
2022-08-01 05:46:09 - train: epoch 0041, iter [03100, 05004], lr: 0.010000, loss: 2.4321, tea_CELoss: 1.0511, stu_CELoss: 1.1766, DMLLoss: 0.2044, 
2022-08-01 05:47:07 - train: epoch 0041, iter [03200, 05004], lr: 0.010000, loss: 2.2361, tea_CELoss: 0.9563, stu_CELoss: 1.0791, DMLLoss: 0.2007, 
2022-08-01 05:48:04 - train: epoch 0041, iter [03300, 05004], lr: 0.010000, loss: 2.3446, tea_CELoss: 1.0452, stu_CELoss: 1.1195, DMLLoss: 0.1800, 
2022-08-01 05:49:01 - train: epoch 0041, iter [03400, 05004], lr: 0.010000, loss: 2.3464, tea_CELoss: 1.0192, stu_CELoss: 1.1266, DMLLoss: 0.2006, 
2022-08-01 05:49:59 - train: epoch 0041, iter [03500, 05004], lr: 0.010000, loss: 2.0184, tea_CELoss: 0.8607, stu_CELoss: 0.9907, DMLLoss: 0.1670, 
2022-08-01 05:50:56 - train: epoch 0041, iter [03600, 05004], lr: 0.010000, loss: 2.6483, tea_CELoss: 1.1929, stu_CELoss: 1.2798, DMLLoss: 0.1756, 
2022-08-01 05:51:53 - train: epoch 0041, iter [03700, 05004], lr: 0.010000, loss: 2.8507, tea_CELoss: 1.2386, stu_CELoss: 1.4257, DMLLoss: 0.1863, 
2022-08-01 05:52:51 - train: epoch 0041, iter [03800, 05004], lr: 0.010000, loss: 2.3783, tea_CELoss: 1.0153, stu_CELoss: 1.1600, DMLLoss: 0.2030, 
2022-08-01 05:53:48 - train: epoch 0041, iter [03900, 05004], lr: 0.010000, loss: 2.5372, tea_CELoss: 1.0858, stu_CELoss: 1.2417, DMLLoss: 0.2097, 
2022-08-01 05:54:46 - train: epoch 0041, iter [04000, 05004], lr: 0.010000, loss: 2.2824, tea_CELoss: 0.9753, stu_CELoss: 1.1089, DMLLoss: 0.1982, 
2022-08-01 05:55:44 - train: epoch 0041, iter [04100, 05004], lr: 0.010000, loss: 2.4625, tea_CELoss: 1.0202, stu_CELoss: 1.2296, DMLLoss: 0.2128, 
2022-08-01 05:56:42 - train: epoch 0041, iter [04200, 05004], lr: 0.010000, loss: 1.9789, tea_CELoss: 0.7843, stu_CELoss: 0.9851, DMLLoss: 0.2095, 
2022-08-01 05:57:39 - train: epoch 0041, iter [04300, 05004], lr: 0.010000, loss: 2.3046, tea_CELoss: 0.9745, stu_CELoss: 1.1379, DMLLoss: 0.1922, 
2022-08-01 05:58:37 - train: epoch 0041, iter [04400, 05004], lr: 0.010000, loss: 2.0428, tea_CELoss: 0.8894, stu_CELoss: 0.9931, DMLLoss: 0.1603, 
2022-08-01 05:59:35 - train: epoch 0041, iter [04500, 05004], lr: 0.010000, loss: 2.4591, tea_CELoss: 1.0702, stu_CELoss: 1.2070, DMLLoss: 0.1819, 
2022-08-01 06:00:32 - train: epoch 0041, iter [04600, 05004], lr: 0.010000, loss: 2.5388, tea_CELoss: 1.0833, stu_CELoss: 1.2505, DMLLoss: 0.2049, 
2022-08-01 06:01:30 - train: epoch 0041, iter [04700, 05004], lr: 0.010000, loss: 2.6404, tea_CELoss: 1.1521, stu_CELoss: 1.3035, DMLLoss: 0.1847, 
2022-08-01 06:02:28 - train: epoch 0041, iter [04800, 05004], lr: 0.010000, loss: 2.1177, tea_CELoss: 0.8909, stu_CELoss: 1.0314, DMLLoss: 0.1953, 
2022-08-01 06:03:26 - train: epoch 0041, iter [04900, 05004], lr: 0.010000, loss: 2.6422, tea_CELoss: 1.1073, stu_CELoss: 1.2887, DMLLoss: 0.2462, 
2022-08-01 06:04:23 - train: epoch 0041, iter [05000, 05004], lr: 0.010000, loss: 2.3724, tea_CELoss: 1.0006, stu_CELoss: 1.1575, DMLLoss: 0.2144, 
2022-08-01 06:04:26 - train: epoch 041, train_loss: 2.4061
2022-08-01 06:06:59 - eval: epoch: 041, tea_acc1: 75.462%, tea_acc5: 92.868%, tea_test_loss: 0.9557, stu_acc1: 73.542%, stu_acc5: 91.658%, stu_test_loss: 1.0486
2022-08-01 06:07:00 - until epoch: 041, tea_best_acc1: 75.770%, stu_best_acc1: 73.634%
2022-08-01 06:07:00 - epoch 042 lr: 0.010000
2022-08-01 06:08:03 - train: epoch 0042, iter [00100, 05004], lr: 0.010000, loss: 1.9054, tea_CELoss: 0.8147, stu_CELoss: 0.9215, DMLLoss: 0.1692, 
2022-08-01 06:09:01 - train: epoch 0042, iter [00200, 05004], lr: 0.010000, loss: 2.2623, tea_CELoss: 0.9706, stu_CELoss: 1.0872, DMLLoss: 0.2045, 
2022-08-01 06:09:58 - train: epoch 0042, iter [00300, 05004], lr: 0.010000, loss: 2.7984, tea_CELoss: 1.2250, stu_CELoss: 1.3494, DMLLoss: 0.2240, 
2022-08-01 06:10:55 - train: epoch 0042, iter [00400, 05004], lr: 0.010000, loss: 2.0806, tea_CELoss: 0.8719, stu_CELoss: 1.0173, DMLLoss: 0.1915, 
2022-08-01 06:11:52 - train: epoch 0042, iter [00500, 05004], lr: 0.010000, loss: 2.1617, tea_CELoss: 0.9072, stu_CELoss: 1.0467, DMLLoss: 0.2078, 
2022-08-01 06:12:50 - train: epoch 0042, iter [00600, 05004], lr: 0.010000, loss: 2.3965, tea_CELoss: 1.0336, stu_CELoss: 1.1749, DMLLoss: 0.1881, 
2022-08-01 06:13:47 - train: epoch 0042, iter [00700, 05004], lr: 0.010000, loss: 2.4441, tea_CELoss: 1.0599, stu_CELoss: 1.1841, DMLLoss: 0.2000, 
2022-08-01 06:14:45 - train: epoch 0042, iter [00800, 05004], lr: 0.010000, loss: 2.1969, tea_CELoss: 0.9389, stu_CELoss: 1.0699, DMLLoss: 0.1880, 
2022-08-01 06:15:42 - train: epoch 0042, iter [00900, 05004], lr: 0.010000, loss: 2.5467, tea_CELoss: 1.0969, stu_CELoss: 1.2682, DMLLoss: 0.1816, 
2022-08-01 06:16:39 - train: epoch 0042, iter [01000, 05004], lr: 0.010000, loss: 2.8796, tea_CELoss: 1.2324, stu_CELoss: 1.4081, DMLLoss: 0.2391, 
2022-08-01 06:17:36 - train: epoch 0042, iter [01100, 05004], lr: 0.010000, loss: 2.1457, tea_CELoss: 0.9306, stu_CELoss: 1.0297, DMLLoss: 0.1854, 
2022-08-01 06:18:34 - train: epoch 0042, iter [01200, 05004], lr: 0.010000, loss: 1.9042, tea_CELoss: 0.8063, stu_CELoss: 0.9176, DMLLoss: 0.1803, 
2022-08-01 06:19:31 - train: epoch 0042, iter [01300, 05004], lr: 0.010000, loss: 2.5134, tea_CELoss: 1.0825, stu_CELoss: 1.2362, DMLLoss: 0.1947, 
2022-08-01 06:20:29 - train: epoch 0042, iter [01400, 05004], lr: 0.010000, loss: 2.8298, tea_CELoss: 1.2081, stu_CELoss: 1.4134, DMLLoss: 0.2083, 
2022-08-01 06:21:26 - train: epoch 0042, iter [01500, 05004], lr: 0.010000, loss: 2.1386, tea_CELoss: 0.8591, stu_CELoss: 1.0369, DMLLoss: 0.2426, 
2022-08-01 06:22:23 - train: epoch 0042, iter [01600, 05004], lr: 0.010000, loss: 2.6413, tea_CELoss: 1.0982, stu_CELoss: 1.3203, DMLLoss: 0.2228, 
2022-08-01 06:23:20 - train: epoch 0042, iter [01700, 05004], lr: 0.010000, loss: 2.5510, tea_CELoss: 1.0966, stu_CELoss: 1.2742, DMLLoss: 0.1802, 
2022-08-01 06:24:17 - train: epoch 0042, iter [01800, 05004], lr: 0.010000, loss: 2.0194, tea_CELoss: 0.8624, stu_CELoss: 0.9724, DMLLoss: 0.1845, 
2022-08-01 06:25:15 - train: epoch 0042, iter [01900, 05004], lr: 0.010000, loss: 2.4215, tea_CELoss: 1.0169, stu_CELoss: 1.1804, DMLLoss: 0.2242, 
2022-08-01 06:26:12 - train: epoch 0042, iter [02000, 05004], lr: 0.010000, loss: 2.4069, tea_CELoss: 1.0431, stu_CELoss: 1.1745, DMLLoss: 0.1892, 
2022-08-01 06:27:09 - train: epoch 0042, iter [02100, 05004], lr: 0.010000, loss: 2.0042, tea_CELoss: 0.8317, stu_CELoss: 0.9851, DMLLoss: 0.1874, 
2022-08-01 06:28:07 - train: epoch 0042, iter [02200, 05004], lr: 0.010000, loss: 2.0406, tea_CELoss: 0.8790, stu_CELoss: 0.9845, DMLLoss: 0.1771, 
2022-08-01 06:29:04 - train: epoch 0042, iter [02300, 05004], lr: 0.010000, loss: 2.8229, tea_CELoss: 1.2131, stu_CELoss: 1.3926, DMLLoss: 0.2172, 
2022-08-01 06:30:02 - train: epoch 0042, iter [02400, 05004], lr: 0.010000, loss: 2.4259, tea_CELoss: 1.0295, stu_CELoss: 1.1820, DMLLoss: 0.2144, 
2022-08-01 06:30:59 - train: epoch 0042, iter [02500, 05004], lr: 0.010000, loss: 2.6416, tea_CELoss: 1.1676, stu_CELoss: 1.2679, DMLLoss: 0.2061, 
2022-08-01 06:31:56 - train: epoch 0042, iter [02600, 05004], lr: 0.010000, loss: 2.6586, tea_CELoss: 1.1789, stu_CELoss: 1.2830, DMLLoss: 0.1967, 
2022-08-01 06:32:53 - train: epoch 0042, iter [02700, 05004], lr: 0.010000, loss: 2.1098, tea_CELoss: 0.8875, stu_CELoss: 1.0469, DMLLoss: 0.1755, 
2022-08-01 06:33:51 - train: epoch 0042, iter [02800, 05004], lr: 0.010000, loss: 2.0537, tea_CELoss: 0.8820, stu_CELoss: 0.9797, DMLLoss: 0.1920, 
2022-08-01 06:34:48 - train: epoch 0042, iter [02900, 05004], lr: 0.010000, loss: 2.3830, tea_CELoss: 1.0266, stu_CELoss: 1.1829, DMLLoss: 0.1735, 
2022-08-01 06:35:45 - train: epoch 0042, iter [03000, 05004], lr: 0.010000, loss: 2.2669, tea_CELoss: 0.9696, stu_CELoss: 1.1001, DMLLoss: 0.1972, 
2022-08-01 06:36:43 - train: epoch 0042, iter [03100, 05004], lr: 0.010000, loss: 2.3694, tea_CELoss: 1.0303, stu_CELoss: 1.1324, DMLLoss: 0.2067, 
2022-08-01 06:37:40 - train: epoch 0042, iter [03200, 05004], lr: 0.010000, loss: 2.8677, tea_CELoss: 1.2365, stu_CELoss: 1.4169, DMLLoss: 0.2143, 
2022-08-01 06:38:37 - train: epoch 0042, iter [03300, 05004], lr: 0.010000, loss: 3.2328, tea_CELoss: 1.4079, stu_CELoss: 1.5853, DMLLoss: 0.2396, 
2022-08-01 06:39:34 - train: epoch 0042, iter [03400, 05004], lr: 0.010000, loss: 2.1259, tea_CELoss: 0.9001, stu_CELoss: 1.0247, DMLLoss: 0.2011, 
2022-08-01 06:40:32 - train: epoch 0042, iter [03500, 05004], lr: 0.010000, loss: 2.4568, tea_CELoss: 1.0564, stu_CELoss: 1.1993, DMLLoss: 0.2012, 
2022-08-01 06:41:29 - train: epoch 0042, iter [03600, 05004], lr: 0.010000, loss: 2.5325, tea_CELoss: 1.0964, stu_CELoss: 1.2334, DMLLoss: 0.2028, 
2022-08-01 06:42:27 - train: epoch 0042, iter [03700, 05004], lr: 0.010000, loss: 2.3544, tea_CELoss: 1.0167, stu_CELoss: 1.1337, DMLLoss: 0.2040, 
2022-08-01 06:43:24 - train: epoch 0042, iter [03800, 05004], lr: 0.010000, loss: 2.1533, tea_CELoss: 0.9320, stu_CELoss: 1.0251, DMLLoss: 0.1962, 
2022-08-01 06:44:22 - train: epoch 0042, iter [03900, 05004], lr: 0.010000, loss: 2.5281, tea_CELoss: 1.0810, stu_CELoss: 1.2279, DMLLoss: 0.2193, 
2022-08-01 06:45:19 - train: epoch 0042, iter [04000, 05004], lr: 0.010000, loss: 2.3393, tea_CELoss: 1.0417, stu_CELoss: 1.1055, DMLLoss: 0.1922, 
2022-08-01 06:46:17 - train: epoch 0042, iter [04100, 05004], lr: 0.010000, loss: 2.4111, tea_CELoss: 1.0246, stu_CELoss: 1.1850, DMLLoss: 0.2014, 
2022-08-01 06:47:14 - train: epoch 0042, iter [04200, 05004], lr: 0.010000, loss: 2.7845, tea_CELoss: 1.2246, stu_CELoss: 1.3452, DMLLoss: 0.2147, 
2022-08-01 06:48:12 - train: epoch 0042, iter [04300, 05004], lr: 0.010000, loss: 2.2919, tea_CELoss: 0.9564, stu_CELoss: 1.1490, DMLLoss: 0.1864, 
2022-08-01 06:49:09 - train: epoch 0042, iter [04400, 05004], lr: 0.010000, loss: 2.1066, tea_CELoss: 0.9306, stu_CELoss: 0.9877, DMLLoss: 0.1882, 
2022-08-01 06:50:07 - train: epoch 0042, iter [04500, 05004], lr: 0.010000, loss: 2.2386, tea_CELoss: 0.9683, stu_CELoss: 1.0778, DMLLoss: 0.1925, 
2022-08-01 06:51:04 - train: epoch 0042, iter [04600, 05004], lr: 0.010000, loss: 2.3294, tea_CELoss: 1.0059, stu_CELoss: 1.1043, DMLLoss: 0.2193, 
2022-08-01 06:52:02 - train: epoch 0042, iter [04700, 05004], lr: 0.010000, loss: 2.1482, tea_CELoss: 0.9231, stu_CELoss: 1.0526, DMLLoss: 0.1725, 
2022-08-01 06:52:59 - train: epoch 0042, iter [04800, 05004], lr: 0.010000, loss: 2.6477, tea_CELoss: 1.1524, stu_CELoss: 1.3055, DMLLoss: 0.1898, 
2022-08-01 06:53:57 - train: epoch 0042, iter [04900, 05004], lr: 0.010000, loss: 2.4949, tea_CELoss: 1.0867, stu_CELoss: 1.2013, DMLLoss: 0.2069, 
2022-08-01 06:54:54 - train: epoch 0042, iter [05000, 05004], lr: 0.010000, loss: 2.5936, tea_CELoss: 1.1099, stu_CELoss: 1.2715, DMLLoss: 0.2122, 
2022-08-01 06:54:57 - train: epoch 042, train_loss: 2.4042
2022-08-01 06:57:29 - eval: epoch: 042, tea_acc1: 75.636%, tea_acc5: 92.946%, tea_test_loss: 0.9507, stu_acc1: 73.076%, stu_acc5: 91.398%, stu_test_loss: 1.0690
2022-08-01 06:57:30 - until epoch: 042, tea_best_acc1: 75.770%, stu_best_acc1: 73.634%
2022-08-01 06:57:30 - epoch 043 lr: 0.010000
2022-08-01 06:58:34 - train: epoch 0043, iter [00100, 05004], lr: 0.010000, loss: 2.3444, tea_CELoss: 1.0288, stu_CELoss: 1.1353, DMLLoss: 0.1803, 
2022-08-01 06:59:31 - train: epoch 0043, iter [00200, 05004], lr: 0.010000, loss: 2.9640, tea_CELoss: 1.2961, stu_CELoss: 1.4735, DMLLoss: 0.1944, 
2022-08-01 07:00:29 - train: epoch 0043, iter [00300, 05004], lr: 0.010000, loss: 2.1548, tea_CELoss: 0.9459, stu_CELoss: 1.0422, DMLLoss: 0.1667, 
2022-08-01 07:01:27 - train: epoch 0043, iter [00400, 05004], lr: 0.010000, loss: 2.1204, tea_CELoss: 0.8889, stu_CELoss: 1.0711, DMLLoss: 0.1605, 
2022-08-01 07:02:24 - train: epoch 0043, iter [00500, 05004], lr: 0.010000, loss: 2.1415, tea_CELoss: 0.8758, stu_CELoss: 1.0559, DMLLoss: 0.2098, 
2022-08-01 07:03:22 - train: epoch 0043, iter [00600, 05004], lr: 0.010000, loss: 2.4369, tea_CELoss: 1.0507, stu_CELoss: 1.1703, DMLLoss: 0.2158, 
2022-08-01 07:04:19 - train: epoch 0043, iter [00700, 05004], lr: 0.010000, loss: 2.3235, tea_CELoss: 0.9621, stu_CELoss: 1.1576, DMLLoss: 0.2038, 
2022-08-01 07:05:17 - train: epoch 0043, iter [00800, 05004], lr: 0.010000, loss: 2.2268, tea_CELoss: 0.9577, stu_CELoss: 1.0856, DMLLoss: 0.1836, 
2022-08-01 07:06:14 - train: epoch 0043, iter [00900, 05004], lr: 0.010000, loss: 2.2634, tea_CELoss: 0.9285, stu_CELoss: 1.1242, DMLLoss: 0.2107, 
2022-08-01 07:07:12 - train: epoch 0043, iter [01000, 05004], lr: 0.010000, loss: 3.0073, tea_CELoss: 1.3176, stu_CELoss: 1.4720, DMLLoss: 0.2177, 
2022-08-01 07:08:09 - train: epoch 0043, iter [01100, 05004], lr: 0.010000, loss: 2.5931, tea_CELoss: 1.1202, stu_CELoss: 1.2795, DMLLoss: 0.1934, 
2022-08-01 07:09:07 - train: epoch 0043, iter [01200, 05004], lr: 0.010000, loss: 2.4134, tea_CELoss: 1.0328, stu_CELoss: 1.1893, DMLLoss: 0.1913, 
2022-08-01 07:10:04 - train: epoch 0043, iter [01300, 05004], lr: 0.010000, loss: 2.7030, tea_CELoss: 1.1503, stu_CELoss: 1.3458, DMLLoss: 0.2070, 
2022-08-01 07:11:02 - train: epoch 0043, iter [01400, 05004], lr: 0.010000, loss: 2.1551, tea_CELoss: 0.9188, stu_CELoss: 1.0186, DMLLoss: 0.2176, 
2022-08-01 07:11:59 - train: epoch 0043, iter [01500, 05004], lr: 0.010000, loss: 2.1203, tea_CELoss: 0.8865, stu_CELoss: 1.0326, DMLLoss: 0.2012, 
2022-08-01 07:12:57 - train: epoch 0043, iter [01600, 05004], lr: 0.010000, loss: 2.2628, tea_CELoss: 0.9733, stu_CELoss: 1.0656, DMLLoss: 0.2239, 
2022-08-01 07:13:54 - train: epoch 0043, iter [01700, 05004], lr: 0.010000, loss: 2.3597, tea_CELoss: 0.9945, stu_CELoss: 1.1590, DMLLoss: 0.2062, 
2022-08-01 07:14:52 - train: epoch 0043, iter [01800, 05004], lr: 0.010000, loss: 2.7462, tea_CELoss: 1.1756, stu_CELoss: 1.3549, DMLLoss: 0.2158, 
2022-08-01 07:15:49 - train: epoch 0043, iter [01900, 05004], lr: 0.010000, loss: 2.7481, tea_CELoss: 1.1855, stu_CELoss: 1.3217, DMLLoss: 0.2409, 
2022-08-01 07:16:47 - train: epoch 0043, iter [02000, 05004], lr: 0.010000, loss: 2.0771, tea_CELoss: 0.8662, stu_CELoss: 1.0144, DMLLoss: 0.1965, 
2022-08-01 07:17:44 - train: epoch 0043, iter [02100, 05004], lr: 0.010000, loss: 2.2435, tea_CELoss: 0.9461, stu_CELoss: 1.0520, DMLLoss: 0.2454, 
2022-08-01 07:18:42 - train: epoch 0043, iter [02200, 05004], lr: 0.010000, loss: 2.8080, tea_CELoss: 1.2140, stu_CELoss: 1.3666, DMLLoss: 0.2275, 
2022-08-01 07:19:39 - train: epoch 0043, iter [02300, 05004], lr: 0.010000, loss: 2.8444, tea_CELoss: 1.2197, stu_CELoss: 1.3979, DMLLoss: 0.2269, 
2022-08-01 07:20:37 - train: epoch 0043, iter [02400, 05004], lr: 0.010000, loss: 1.9143, tea_CELoss: 0.8035, stu_CELoss: 0.8962, DMLLoss: 0.2147, 
2022-08-01 07:21:35 - train: epoch 0043, iter [02500, 05004], lr: 0.010000, loss: 2.3235, tea_CELoss: 1.0044, stu_CELoss: 1.1074, DMLLoss: 0.2117, 
2022-08-01 07:22:33 - train: epoch 0043, iter [02600, 05004], lr: 0.010000, loss: 2.2134, tea_CELoss: 0.9070, stu_CELoss: 1.1077, DMLLoss: 0.1988, 
2022-08-01 07:23:30 - train: epoch 0043, iter [02700, 05004], lr: 0.010000, loss: 2.6116, tea_CELoss: 1.1202, stu_CELoss: 1.2927, DMLLoss: 0.1987, 
2022-08-01 07:24:28 - train: epoch 0043, iter [02800, 05004], lr: 0.010000, loss: 2.3265, tea_CELoss: 1.0227, stu_CELoss: 1.1033, DMLLoss: 0.2005, 
2022-08-01 07:25:26 - train: epoch 0043, iter [02900, 05004], lr: 0.010000, loss: 2.4475, tea_CELoss: 1.0342, stu_CELoss: 1.2011, DMLLoss: 0.2122, 
2022-08-01 07:26:24 - train: epoch 0043, iter [03000, 05004], lr: 0.010000, loss: 2.7319, tea_CELoss: 1.1796, stu_CELoss: 1.3205, DMLLoss: 0.2318, 
2022-08-01 07:27:21 - train: epoch 0043, iter [03100, 05004], lr: 0.010000, loss: 2.6426, tea_CELoss: 1.1233, stu_CELoss: 1.3024, DMLLoss: 0.2169, 
2022-08-01 07:28:19 - train: epoch 0043, iter [03200, 05004], lr: 0.010000, loss: 2.4001, tea_CELoss: 1.0508, stu_CELoss: 1.1366, DMLLoss: 0.2127, 
2022-08-01 07:29:17 - train: epoch 0043, iter [03300, 05004], lr: 0.010000, loss: 2.7408, tea_CELoss: 1.1713, stu_CELoss: 1.3589, DMLLoss: 0.2106, 
2022-08-01 07:30:15 - train: epoch 0043, iter [03400, 05004], lr: 0.010000, loss: 2.2350, tea_CELoss: 0.9797, stu_CELoss: 1.0480, DMLLoss: 0.2073, 
2022-08-01 07:31:13 - train: epoch 0043, iter [03500, 05004], lr: 0.010000, loss: 2.2546, tea_CELoss: 0.9657, stu_CELoss: 1.0974, DMLLoss: 0.1915, 
2022-08-01 07:32:11 - train: epoch 0043, iter [03600, 05004], lr: 0.010000, loss: 2.6019, tea_CELoss: 1.1308, stu_CELoss: 1.2363, DMLLoss: 0.2347, 
2022-08-01 07:33:09 - train: epoch 0043, iter [03700, 05004], lr: 0.010000, loss: 2.2547, tea_CELoss: 0.9659, stu_CELoss: 1.0896, DMLLoss: 0.1992, 
2022-08-01 07:34:06 - train: epoch 0043, iter [03800, 05004], lr: 0.010000, loss: 2.8956, tea_CELoss: 1.2227, stu_CELoss: 1.4315, DMLLoss: 0.2414, 
2022-08-01 07:35:04 - train: epoch 0043, iter [03900, 05004], lr: 0.010000, loss: 2.4318, tea_CELoss: 1.0236, stu_CELoss: 1.1832, DMLLoss: 0.2251, 
2022-08-01 07:36:02 - train: epoch 0043, iter [04000, 05004], lr: 0.010000, loss: 2.7342, tea_CELoss: 1.1814, stu_CELoss: 1.3198, DMLLoss: 0.2330, 
2022-08-01 07:37:00 - train: epoch 0043, iter [04100, 05004], lr: 0.010000, loss: 2.4774, tea_CELoss: 1.0610, stu_CELoss: 1.2176, DMLLoss: 0.1987, 
2022-08-01 07:37:58 - train: epoch 0043, iter [04200, 05004], lr: 0.010000, loss: 2.7447, tea_CELoss: 1.1165, stu_CELoss: 1.3911, DMLLoss: 0.2372, 
2022-08-01 07:38:56 - train: epoch 0043, iter [04300, 05004], lr: 0.010000, loss: 2.2568, tea_CELoss: 0.9599, stu_CELoss: 1.0958, DMLLoss: 0.2010, 
2022-08-01 07:39:53 - train: epoch 0043, iter [04400, 05004], lr: 0.010000, loss: 2.4123, tea_CELoss: 1.0472, stu_CELoss: 1.1572, DMLLoss: 0.2079, 
2022-08-01 07:40:51 - train: epoch 0043, iter [04500, 05004], lr: 0.010000, loss: 2.2494, tea_CELoss: 0.9829, stu_CELoss: 1.0747, DMLLoss: 0.1918, 
2022-08-01 07:41:49 - train: epoch 0043, iter [04600, 05004], lr: 0.010000, loss: 2.5118, tea_CELoss: 1.0556, stu_CELoss: 1.2360, DMLLoss: 0.2202, 
2022-08-01 07:42:46 - train: epoch 0043, iter [04700, 05004], lr: 0.010000, loss: 2.5558, tea_CELoss: 1.0850, stu_CELoss: 1.2633, DMLLoss: 0.2075, 
2022-08-01 07:43:44 - train: epoch 0043, iter [04800, 05004], lr: 0.010000, loss: 2.3536, tea_CELoss: 0.9880, stu_CELoss: 1.1589, DMLLoss: 0.2067, 
2022-08-01 07:44:42 - train: epoch 0043, iter [04900, 05004], lr: 0.010000, loss: 2.3163, tea_CELoss: 1.0025, stu_CELoss: 1.1257, DMLLoss: 0.1882, 
2022-08-01 07:45:39 - train: epoch 0043, iter [05000, 05004], lr: 0.010000, loss: 2.4405, tea_CELoss: 1.0600, stu_CELoss: 1.1706, DMLLoss: 0.2099, 
2022-08-01 07:45:42 - train: epoch 043, train_loss: 2.4069
2022-08-01 07:48:15 - eval: epoch: 043, tea_acc1: 74.824%, tea_acc5: 92.618%, tea_test_loss: 0.9779, stu_acc1: 72.574%, stu_acc5: 91.234%, stu_test_loss: 1.0837
2022-08-01 07:48:16 - until epoch: 043, tea_best_acc1: 75.770%, stu_best_acc1: 73.634%
2022-08-01 07:48:16 - epoch 044 lr: 0.010000
2022-08-01 07:49:20 - train: epoch 0044, iter [00100, 05004], lr: 0.010000, loss: 2.3905, tea_CELoss: 1.0683, stu_CELoss: 1.1079, DMLLoss: 0.2144, 
2022-08-01 07:50:18 - train: epoch 0044, iter [00200, 05004], lr: 0.010000, loss: 2.4201, tea_CELoss: 1.0329, stu_CELoss: 1.1785, DMLLoss: 0.2088, 
2022-08-01 07:51:16 - train: epoch 0044, iter [00300, 05004], lr: 0.010000, loss: 2.4431, tea_CELoss: 1.0662, stu_CELoss: 1.1594, DMLLoss: 0.2175, 
2022-08-01 07:52:14 - train: epoch 0044, iter [00400, 05004], lr: 0.010000, loss: 2.0688, tea_CELoss: 0.8615, stu_CELoss: 1.0163, DMLLoss: 0.1910, 
2022-08-01 07:53:12 - train: epoch 0044, iter [00500, 05004], lr: 0.010000, loss: 2.5509, tea_CELoss: 1.0657, stu_CELoss: 1.2614, DMLLoss: 0.2239, 
2022-08-01 07:54:09 - train: epoch 0044, iter [00600, 05004], lr: 0.010000, loss: 2.0938, tea_CELoss: 0.8716, stu_CELoss: 1.0321, DMLLoss: 0.1901, 
2022-08-01 07:55:07 - train: epoch 0044, iter [00700, 05004], lr: 0.010000, loss: 2.3296, tea_CELoss: 0.9920, stu_CELoss: 1.0980, DMLLoss: 0.2396, 
2022-08-01 07:56:05 - train: epoch 0044, iter [00800, 05004], lr: 0.010000, loss: 2.4185, tea_CELoss: 1.0407, stu_CELoss: 1.1646, DMLLoss: 0.2132, 
2022-08-01 07:57:03 - train: epoch 0044, iter [00900, 05004], lr: 0.010000, loss: 2.4426, tea_CELoss: 1.0576, stu_CELoss: 1.1500, DMLLoss: 0.2350, 
2022-08-01 07:58:00 - train: epoch 0044, iter [01000, 05004], lr: 0.010000, loss: 2.4204, tea_CELoss: 1.0590, stu_CELoss: 1.1670, DMLLoss: 0.1945, 
2022-08-01 07:58:58 - train: epoch 0044, iter [01100, 05004], lr: 0.010000, loss: 2.0804, tea_CELoss: 0.8981, stu_CELoss: 1.0040, DMLLoss: 0.1783, 
2022-08-01 07:59:56 - train: epoch 0044, iter [01200, 05004], lr: 0.010000, loss: 2.4828, tea_CELoss: 1.0942, stu_CELoss: 1.2034, DMLLoss: 0.1852, 
2022-08-01 08:00:54 - train: epoch 0044, iter [01300, 05004], lr: 0.010000, loss: 2.5143, tea_CELoss: 1.0832, stu_CELoss: 1.2453, DMLLoss: 0.1858, 
2022-08-01 08:01:52 - train: epoch 0044, iter [01400, 05004], lr: 0.010000, loss: 2.1689, tea_CELoss: 0.8943, stu_CELoss: 1.0797, DMLLoss: 0.1949, 
2022-08-01 08:02:50 - train: epoch 0044, iter [01500, 05004], lr: 0.010000, loss: 2.3081, tea_CELoss: 0.9836, stu_CELoss: 1.0998, DMLLoss: 0.2247, 
2022-08-01 08:03:47 - train: epoch 0044, iter [01600, 05004], lr: 0.010000, loss: 1.9859, tea_CELoss: 0.8062, stu_CELoss: 0.9871, DMLLoss: 0.1926, 
2022-08-01 08:04:45 - train: epoch 0044, iter [01700, 05004], lr: 0.010000, loss: 2.1461, tea_CELoss: 0.9203, stu_CELoss: 1.0274, DMLLoss: 0.1984, 
2022-08-01 08:05:43 - train: epoch 0044, iter [01800, 05004], lr: 0.010000, loss: 2.5099, tea_CELoss: 1.0255, stu_CELoss: 1.2571, DMLLoss: 0.2273, 
2022-08-01 08:06:41 - train: epoch 0044, iter [01900, 05004], lr: 0.010000, loss: 2.6948, tea_CELoss: 1.1559, stu_CELoss: 1.2931, DMLLoss: 0.2458, 
2022-08-01 08:07:38 - train: epoch 0044, iter [02000, 05004], lr: 0.010000, loss: 1.8914, tea_CELoss: 0.7993, stu_CELoss: 0.8961, DMLLoss: 0.1960, 
2022-08-01 08:08:36 - train: epoch 0044, iter [02100, 05004], lr: 0.010000, loss: 2.5022, tea_CELoss: 1.0782, stu_CELoss: 1.1866, DMLLoss: 0.2374, 
2022-08-01 08:09:34 - train: epoch 0044, iter [02200, 05004], lr: 0.010000, loss: 2.6500, tea_CELoss: 1.1256, stu_CELoss: 1.2926, DMLLoss: 0.2318, 
2022-08-01 08:10:31 - train: epoch 0044, iter [02300, 05004], lr: 0.010000, loss: 2.8084, tea_CELoss: 1.2234, stu_CELoss: 1.3754, DMLLoss: 0.2095, 
2022-08-01 08:11:29 - train: epoch 0044, iter [02400, 05004], lr: 0.010000, loss: 2.3468, tea_CELoss: 1.0219, stu_CELoss: 1.1002, DMLLoss: 0.2246, 
2022-08-01 08:12:27 - train: epoch 0044, iter [02500, 05004], lr: 0.010000, loss: 2.5951, tea_CELoss: 1.1113, stu_CELoss: 1.2531, DMLLoss: 0.2306, 
2022-08-01 08:13:24 - train: epoch 0044, iter [02600, 05004], lr: 0.010000, loss: 2.5239, tea_CELoss: 1.0692, stu_CELoss: 1.2454, DMLLoss: 0.2093, 
2022-08-01 08:14:22 - train: epoch 0044, iter [02700, 05004], lr: 0.010000, loss: 2.3997, tea_CELoss: 1.0374, stu_CELoss: 1.1457, DMLLoss: 0.2166, 
2022-08-01 08:15:19 - train: epoch 0044, iter [02800, 05004], lr: 0.010000, loss: 2.2034, tea_CELoss: 0.9619, stu_CELoss: 1.0331, DMLLoss: 0.2083, 
2022-08-01 08:16:17 - train: epoch 0044, iter [02900, 05004], lr: 0.010000, loss: 2.0115, tea_CELoss: 0.8436, stu_CELoss: 0.9893, DMLLoss: 0.1787, 
2022-08-01 08:17:15 - train: epoch 0044, iter [03000, 05004], lr: 0.010000, loss: 2.0913, tea_CELoss: 0.8829, stu_CELoss: 1.0243, DMLLoss: 0.1841, 
2022-08-01 08:18:12 - train: epoch 0044, iter [03100, 05004], lr: 0.010000, loss: 2.2137, tea_CELoss: 0.9569, stu_CELoss: 1.0621, DMLLoss: 0.1947, 
2022-08-01 08:19:10 - train: epoch 0044, iter [03200, 05004], lr: 0.010000, loss: 2.0550, tea_CELoss: 0.8774, stu_CELoss: 0.9690, DMLLoss: 0.2086, 
2022-08-01 08:20:07 - train: epoch 0044, iter [03300, 05004], lr: 0.010000, loss: 2.4284, tea_CELoss: 1.0266, stu_CELoss: 1.1796, DMLLoss: 0.2222, 
2022-08-01 08:21:05 - train: epoch 0044, iter [03400, 05004], lr: 0.010000, loss: 2.5117, tea_CELoss: 1.1016, stu_CELoss: 1.1943, DMLLoss: 0.2157, 
2022-08-01 08:22:03 - train: epoch 0044, iter [03500, 05004], lr: 0.010000, loss: 2.3830, tea_CELoss: 1.0028, stu_CELoss: 1.1488, DMLLoss: 0.2314, 
2022-08-01 08:23:00 - train: epoch 0044, iter [03600, 05004], lr: 0.010000, loss: 2.6639, tea_CELoss: 1.1693, stu_CELoss: 1.2743, DMLLoss: 0.2202, 
2022-08-01 08:23:58 - train: epoch 0044, iter [03700, 05004], lr: 0.010000, loss: 2.4247, tea_CELoss: 1.0222, stu_CELoss: 1.1799, DMLLoss: 0.2226, 
2022-08-01 08:24:55 - train: epoch 0044, iter [03800, 05004], lr: 0.010000, loss: 2.0961, tea_CELoss: 0.8990, stu_CELoss: 1.0127, DMLLoss: 0.1845, 
2022-08-01 08:25:53 - train: epoch 0044, iter [03900, 05004], lr: 0.010000, loss: 2.3897, tea_CELoss: 1.0391, stu_CELoss: 1.1546, DMLLoss: 0.1960, 
2022-08-01 08:26:51 - train: epoch 0044, iter [04000, 05004], lr: 0.010000, loss: 2.6280, tea_CELoss: 1.1386, stu_CELoss: 1.2653, DMLLoss: 0.2240, 
2022-08-01 08:27:49 - train: epoch 0044, iter [04100, 05004], lr: 0.010000, loss: 2.3493, tea_CELoss: 0.9551, stu_CELoss: 1.1623, DMLLoss: 0.2318, 
2022-08-01 08:28:47 - train: epoch 0044, iter [04200, 05004], lr: 0.010000, loss: 2.5479, tea_CELoss: 1.0586, stu_CELoss: 1.2478, DMLLoss: 0.2415, 
2022-08-01 08:29:44 - train: epoch 0044, iter [04300, 05004], lr: 0.010000, loss: 2.3423, tea_CELoss: 0.9370, stu_CELoss: 1.1749, DMLLoss: 0.2304, 
2022-08-01 08:30:42 - train: epoch 0044, iter [04400, 05004], lr: 0.010000, loss: 2.4741, tea_CELoss: 1.0588, stu_CELoss: 1.2099, DMLLoss: 0.2054, 
2022-08-01 08:31:40 - train: epoch 0044, iter [04500, 05004], lr: 0.010000, loss: 2.6294, tea_CELoss: 1.1318, stu_CELoss: 1.2821, DMLLoss: 0.2155, 
2022-08-01 08:32:37 - train: epoch 0044, iter [04600, 05004], lr: 0.010000, loss: 2.3752, tea_CELoss: 0.9953, stu_CELoss: 1.1694, DMLLoss: 0.2104, 
2022-08-01 08:33:35 - train: epoch 0044, iter [04700, 05004], lr: 0.010000, loss: 2.5912, tea_CELoss: 1.1374, stu_CELoss: 1.2550, DMLLoss: 0.1988, 
2022-08-01 08:34:33 - train: epoch 0044, iter [04800, 05004], lr: 0.010000, loss: 2.2278, tea_CELoss: 0.9310, stu_CELoss: 1.0729, DMLLoss: 0.2239, 
2022-08-01 08:35:31 - train: epoch 0044, iter [04900, 05004], lr: 0.010000, loss: 2.1560, tea_CELoss: 0.8931, stu_CELoss: 1.0444, DMLLoss: 0.2185, 
2022-08-01 08:36:29 - train: epoch 0044, iter [05000, 05004], lr: 0.010000, loss: 2.4702, tea_CELoss: 1.0777, stu_CELoss: 1.1987, DMLLoss: 0.1939, 
2022-08-01 08:36:32 - train: epoch 044, train_loss: 2.4040
2022-08-01 08:39:05 - eval: epoch: 044, tea_acc1: 75.028%, tea_acc5: 92.578%, tea_test_loss: 0.9748, stu_acc1: 73.014%, stu_acc5: 91.392%, stu_test_loss: 1.0747
2022-08-01 08:39:05 - until epoch: 044, tea_best_acc1: 75.770%, stu_best_acc1: 73.634%
2022-08-01 08:39:05 - epoch 045 lr: 0.010000
2022-08-01 08:40:08 - train: epoch 0045, iter [00100, 05004], lr: 0.010000, loss: 2.0724, tea_CELoss: 0.8756, stu_CELoss: 0.9914, DMLLoss: 0.2054, 
2022-08-01 08:41:06 - train: epoch 0045, iter [00200, 05004], lr: 0.010000, loss: 2.0531, tea_CELoss: 0.8486, stu_CELoss: 1.0044, DMLLoss: 0.2002, 
2022-08-01 08:42:03 - train: epoch 0045, iter [00300, 05004], lr: 0.010000, loss: 2.3596, tea_CELoss: 0.9790, stu_CELoss: 1.1580, DMLLoss: 0.2227, 
2022-08-01 08:43:00 - train: epoch 0045, iter [00400, 05004], lr: 0.010000, loss: 2.2364, tea_CELoss: 0.9474, stu_CELoss: 1.0794, DMLLoss: 0.2096, 
2022-08-01 08:43:57 - train: epoch 0045, iter [00500, 05004], lr: 0.010000, loss: 2.9035, tea_CELoss: 1.2095, stu_CELoss: 1.4382, DMLLoss: 0.2557, 
2022-08-01 08:44:55 - train: epoch 0045, iter [00600, 05004], lr: 0.010000, loss: 2.5727, tea_CELoss: 1.1062, stu_CELoss: 1.2520, DMLLoss: 0.2146, 
2022-08-01 08:45:52 - train: epoch 0045, iter [00700, 05004], lr: 0.010000, loss: 2.3331, tea_CELoss: 1.0098, stu_CELoss: 1.1048, DMLLoss: 0.2185, 
2022-08-01 08:46:49 - train: epoch 0045, iter [00800, 05004], lr: 0.010000, loss: 2.3349, tea_CELoss: 0.9525, stu_CELoss: 1.1697, DMLLoss: 0.2127, 
2022-08-01 08:47:46 - train: epoch 0045, iter [00900, 05004], lr: 0.010000, loss: 2.1953, tea_CELoss: 0.9257, stu_CELoss: 1.0762, DMLLoss: 0.1934, 
2022-08-01 08:48:44 - train: epoch 0045, iter [01000, 05004], lr: 0.010000, loss: 2.2477, tea_CELoss: 0.9104, stu_CELoss: 1.1066, DMLLoss: 0.2307, 
2022-08-01 08:49:41 - train: epoch 0045, iter [01100, 05004], lr: 0.010000, loss: 2.5375, tea_CELoss: 1.0556, stu_CELoss: 1.2429, DMLLoss: 0.2391, 
2022-08-01 08:50:38 - train: epoch 0045, iter [01200, 05004], lr: 0.010000, loss: 2.4101, tea_CELoss: 1.0072, stu_CELoss: 1.1919, DMLLoss: 0.2109, 
2022-08-01 08:51:36 - train: epoch 0045, iter [01300, 05004], lr: 0.010000, loss: 2.4390, tea_CELoss: 1.0520, stu_CELoss: 1.1838, DMLLoss: 0.2032, 
2022-08-01 08:52:33 - train: epoch 0045, iter [01400, 05004], lr: 0.010000, loss: 2.6069, tea_CELoss: 1.1467, stu_CELoss: 1.2361, DMLLoss: 0.2241, 
2022-08-01 08:53:30 - train: epoch 0045, iter [01500, 05004], lr: 0.010000, loss: 2.2971, tea_CELoss: 0.9662, stu_CELoss: 1.1130, DMLLoss: 0.2179, 
2022-08-01 08:54:28 - train: epoch 0045, iter [01600, 05004], lr: 0.010000, loss: 2.0305, tea_CELoss: 0.8880, stu_CELoss: 0.9442, DMLLoss: 0.1982, 
2022-08-01 08:55:25 - train: epoch 0045, iter [01700, 05004], lr: 0.010000, loss: 2.1061, tea_CELoss: 0.9059, stu_CELoss: 0.9944, DMLLoss: 0.2058, 
2022-08-01 08:56:23 - train: epoch 0045, iter [01800, 05004], lr: 0.010000, loss: 2.4412, tea_CELoss: 1.0058, stu_CELoss: 1.2154, DMLLoss: 0.2200, 
2022-08-01 08:57:20 - train: epoch 0045, iter [01900, 05004], lr: 0.010000, loss: 2.4817, tea_CELoss: 1.0548, stu_CELoss: 1.2112, DMLLoss: 0.2157, 
2022-08-01 08:58:18 - train: epoch 0045, iter [02000, 05004], lr: 0.010000, loss: 2.4726, tea_CELoss: 1.0629, stu_CELoss: 1.2098, DMLLoss: 0.1999, 
2022-08-01 08:59:15 - train: epoch 0045, iter [02100, 05004], lr: 0.010000, loss: 2.2281, tea_CELoss: 0.9007, stu_CELoss: 1.0965, DMLLoss: 0.2309, 
2022-08-01 09:00:12 - train: epoch 0045, iter [02200, 05004], lr: 0.010000, loss: 2.2868, tea_CELoss: 0.9363, stu_CELoss: 1.1350, DMLLoss: 0.2155, 
2022-08-01 09:01:10 - train: epoch 0045, iter [02300, 05004], lr: 0.010000, loss: 2.1727, tea_CELoss: 0.9004, stu_CELoss: 1.0551, DMLLoss: 0.2172, 
2022-08-01 09:02:07 - train: epoch 0045, iter [02400, 05004], lr: 0.010000, loss: 2.1574, tea_CELoss: 0.9390, stu_CELoss: 1.0288, DMLLoss: 0.1896, 
2022-08-01 09:03:04 - train: epoch 0045, iter [02500, 05004], lr: 0.010000, loss: 2.5722, tea_CELoss: 1.1503, stu_CELoss: 1.2231, DMLLoss: 0.1989, 
2022-08-01 09:04:02 - train: epoch 0045, iter [02600, 05004], lr: 0.010000, loss: 2.7192, tea_CELoss: 1.1927, stu_CELoss: 1.2921, DMLLoss: 0.2345, 
2022-08-01 09:04:59 - train: epoch 0045, iter [02700, 05004], lr: 0.010000, loss: 2.0742, tea_CELoss: 0.9016, stu_CELoss: 0.9769, DMLLoss: 0.1958, 
2022-08-01 09:05:56 - train: epoch 0045, iter [02800, 05004], lr: 0.010000, loss: 2.2720, tea_CELoss: 0.9735, stu_CELoss: 1.1026, DMLLoss: 0.1959, 
2022-08-01 09:06:54 - train: epoch 0045, iter [02900, 05004], lr: 0.010000, loss: 2.8346, tea_CELoss: 1.2138, stu_CELoss: 1.3943, DMLLoss: 0.2265, 
2022-08-01 09:07:51 - train: epoch 0045, iter [03000, 05004], lr: 0.010000, loss: 2.5139, tea_CELoss: 1.0650, stu_CELoss: 1.2018, DMLLoss: 0.2471, 
2022-08-01 09:08:49 - train: epoch 0045, iter [03100, 05004], lr: 0.010000, loss: 2.3608, tea_CELoss: 0.9910, stu_CELoss: 1.1234, DMLLoss: 0.2464, 
2022-08-01 09:09:46 - train: epoch 0045, iter [03200, 05004], lr: 0.010000, loss: 2.5275, tea_CELoss: 1.0765, stu_CELoss: 1.2370, DMLLoss: 0.2140, 
2022-08-01 09:10:44 - train: epoch 0045, iter [03300, 05004], lr: 0.010000, loss: 2.5565, tea_CELoss: 1.0456, stu_CELoss: 1.2781, DMLLoss: 0.2328, 
2022-08-01 09:11:41 - train: epoch 0045, iter [03400, 05004], lr: 0.010000, loss: 2.3521, tea_CELoss: 1.0007, stu_CELoss: 1.1309, DMLLoss: 0.2204, 
2022-08-01 09:12:39 - train: epoch 0045, iter [03500, 05004], lr: 0.010000, loss: 2.4089, tea_CELoss: 1.0409, stu_CELoss: 1.1583, DMLLoss: 0.2098, 
2022-08-01 09:13:36 - train: epoch 0045, iter [03600, 05004], lr: 0.010000, loss: 2.3961, tea_CELoss: 1.0387, stu_CELoss: 1.1609, DMLLoss: 0.1965, 
2022-08-01 09:14:34 - train: epoch 0045, iter [03700, 05004], lr: 0.010000, loss: 2.1765, tea_CELoss: 0.9371, stu_CELoss: 1.0380, DMLLoss: 0.2014, 
2022-08-01 09:15:31 - train: epoch 0045, iter [03800, 05004], lr: 0.010000, loss: 2.3619, tea_CELoss: 0.9857, stu_CELoss: 1.1535, DMLLoss: 0.2227, 
2022-08-01 09:16:29 - train: epoch 0045, iter [03900, 05004], lr: 0.010000, loss: 2.5988, tea_CELoss: 1.1212, stu_CELoss: 1.2815, DMLLoss: 0.1961, 
2022-08-01 09:17:27 - train: epoch 0045, iter [04000, 05004], lr: 0.010000, loss: 2.4595, tea_CELoss: 1.0589, stu_CELoss: 1.1740, DMLLoss: 0.2265, 
2022-08-01 09:18:24 - train: epoch 0045, iter [04100, 05004], lr: 0.010000, loss: 2.4416, tea_CELoss: 1.0309, stu_CELoss: 1.1791, DMLLoss: 0.2316, 
2022-08-01 09:19:21 - train: epoch 0045, iter [04200, 05004], lr: 0.010000, loss: 2.9341, tea_CELoss: 1.2393, stu_CELoss: 1.4270, DMLLoss: 0.2677, 
2022-08-01 09:20:19 - train: epoch 0045, iter [04300, 05004], lr: 0.010000, loss: 2.4755, tea_CELoss: 1.0628, stu_CELoss: 1.1996, DMLLoss: 0.2132, 
2022-08-01 09:21:17 - train: epoch 0045, iter [04400, 05004], lr: 0.010000, loss: 2.6122, tea_CELoss: 1.1065, stu_CELoss: 1.2926, DMLLoss: 0.2131, 
2022-08-01 09:22:14 - train: epoch 0045, iter [04500, 05004], lr: 0.010000, loss: 2.4608, tea_CELoss: 1.0665, stu_CELoss: 1.1827, DMLLoss: 0.2116, 
2022-08-01 09:23:11 - train: epoch 0045, iter [04600, 05004], lr: 0.010000, loss: 2.7414, tea_CELoss: 1.1674, stu_CELoss: 1.3476, DMLLoss: 0.2265, 
2022-08-01 09:24:09 - train: epoch 0045, iter [04700, 05004], lr: 0.010000, loss: 2.5528, tea_CELoss: 1.1189, stu_CELoss: 1.2286, DMLLoss: 0.2052, 
2022-08-01 09:25:06 - train: epoch 0045, iter [04800, 05004], lr: 0.010000, loss: 2.1639, tea_CELoss: 0.9186, stu_CELoss: 1.0558, DMLLoss: 0.1895, 
2022-08-01 09:26:04 - train: epoch 0045, iter [04900, 05004], lr: 0.010000, loss: 2.7468, tea_CELoss: 1.2000, stu_CELoss: 1.3213, DMLLoss: 0.2254, 
2022-08-01 09:27:01 - train: epoch 0045, iter [05000, 05004], lr: 0.010000, loss: 2.2382, tea_CELoss: 0.9543, stu_CELoss: 1.0731, DMLLoss: 0.2108, 
2022-08-01 09:27:04 - train: epoch 045, train_loss: 2.4047
2022-08-01 09:29:36 - eval: epoch: 045, tea_acc1: 74.530%, tea_acc5: 92.386%, tea_test_loss: 0.9949, stu_acc1: 72.966%, stu_acc5: 91.358%, stu_test_loss: 1.0682
2022-08-01 09:29:37 - until epoch: 045, tea_best_acc1: 75.770%, stu_best_acc1: 73.634%
2022-08-01 09:29:37 - epoch 046 lr: 0.010000
2022-08-01 09:30:41 - train: epoch 0046, iter [00100, 05004], lr: 0.010000, loss: 1.8291, tea_CELoss: 0.7675, stu_CELoss: 0.8797, DMLLoss: 0.1819, 
2022-08-01 09:31:38 - train: epoch 0046, iter [00200, 05004], lr: 0.010000, loss: 2.2015, tea_CELoss: 0.9188, stu_CELoss: 1.0801, DMLLoss: 0.2027, 
2022-08-01 09:32:35 - train: epoch 0046, iter [00300, 05004], lr: 0.010000, loss: 2.6176, tea_CELoss: 1.1133, stu_CELoss: 1.2905, DMLLoss: 0.2138, 
2022-08-01 09:33:33 - train: epoch 0046, iter [00400, 05004], lr: 0.010000, loss: 2.1684, tea_CELoss: 0.9270, stu_CELoss: 1.0279, DMLLoss: 0.2135, 
2022-08-01 09:34:30 - train: epoch 0046, iter [00500, 05004], lr: 0.010000, loss: 2.2657, tea_CELoss: 0.9272, stu_CELoss: 1.1425, DMLLoss: 0.1960, 
2022-08-01 09:35:27 - train: epoch 0046, iter [00600, 05004], lr: 0.010000, loss: 2.2994, tea_CELoss: 0.9345, stu_CELoss: 1.1259, DMLLoss: 0.2390, 
2022-08-01 09:36:25 - train: epoch 0046, iter [00700, 05004], lr: 0.010000, loss: 2.1402, tea_CELoss: 0.9150, stu_CELoss: 1.0321, DMLLoss: 0.1931, 
2022-08-01 09:37:22 - train: epoch 0046, iter [00800, 05004], lr: 0.010000, loss: 2.6383, tea_CELoss: 1.1216, stu_CELoss: 1.2874, DMLLoss: 0.2292, 
2022-08-01 09:38:19 - train: epoch 0046, iter [00900, 05004], lr: 0.010000, loss: 2.2511, tea_CELoss: 0.9446, stu_CELoss: 1.0907, DMLLoss: 0.2158, 
2022-08-01 09:39:16 - train: epoch 0046, iter [01000, 05004], lr: 0.010000, loss: 2.0737, tea_CELoss: 0.8547, stu_CELoss: 0.9947, DMLLoss: 0.2242, 
2022-08-01 09:40:14 - train: epoch 0046, iter [01100, 05004], lr: 0.010000, loss: 2.2570, tea_CELoss: 0.9892, stu_CELoss: 1.0576, DMLLoss: 0.2102, 
2022-08-01 09:41:11 - train: epoch 0046, iter [01200, 05004], lr: 0.010000, loss: 2.2714, tea_CELoss: 0.9607, stu_CELoss: 1.0938, DMLLoss: 0.2169, 
2022-08-01 09:42:08 - train: epoch 0046, iter [01300, 05004], lr: 0.010000, loss: 2.6628, tea_CELoss: 1.1708, stu_CELoss: 1.2505, DMLLoss: 0.2415, 
2022-08-01 09:43:05 - train: epoch 0046, iter [01400, 05004], lr: 0.010000, loss: 2.4932, tea_CELoss: 1.0651, stu_CELoss: 1.2233, DMLLoss: 0.2047, 
2022-08-01 09:44:02 - train: epoch 0046, iter [01500, 05004], lr: 0.010000, loss: 2.0912, tea_CELoss: 0.8542, stu_CELoss: 1.0265, DMLLoss: 0.2105, 
2022-08-01 09:45:00 - train: epoch 0046, iter [01600, 05004], lr: 0.010000, loss: 3.1003, tea_CELoss: 1.3562, stu_CELoss: 1.4994, DMLLoss: 0.2447, 
2022-08-01 09:45:57 - train: epoch 0046, iter [01700, 05004], lr: 0.010000, loss: 2.1980, tea_CELoss: 0.9777, stu_CELoss: 1.0198, DMLLoss: 0.2005, 
2022-08-01 09:46:54 - train: epoch 0046, iter [01800, 05004], lr: 0.010000, loss: 2.5197, tea_CELoss: 1.0975, stu_CELoss: 1.2218, DMLLoss: 0.2004, 
2022-08-01 09:47:51 - train: epoch 0046, iter [01900, 05004], lr: 0.010000, loss: 2.3490, tea_CELoss: 0.9888, stu_CELoss: 1.1235, DMLLoss: 0.2368, 
2022-08-01 09:48:48 - train: epoch 0046, iter [02000, 05004], lr: 0.010000, loss: 2.1295, tea_CELoss: 0.8574, stu_CELoss: 1.0338, DMLLoss: 0.2383, 
2022-08-01 09:49:46 - train: epoch 0046, iter [02100, 05004], lr: 0.010000, loss: 2.8187, tea_CELoss: 1.2019, stu_CELoss: 1.3657, DMLLoss: 0.2511, 
2022-08-01 09:50:43 - train: epoch 0046, iter [02200, 05004], lr: 0.010000, loss: 2.2171, tea_CELoss: 0.9253, stu_CELoss: 1.0811, DMLLoss: 0.2107, 
2022-08-01 09:51:40 - train: epoch 0046, iter [02300, 05004], lr: 0.010000, loss: 2.8667, tea_CELoss: 1.2028, stu_CELoss: 1.4181, DMLLoss: 0.2458, 
2022-08-01 09:52:37 - train: epoch 0046, iter [02400, 05004], lr: 0.010000, loss: 2.7427, tea_CELoss: 1.1851, stu_CELoss: 1.3326, DMLLoss: 0.2250, 
2022-08-01 09:53:34 - train: epoch 0046, iter [02500, 05004], lr: 0.010000, loss: 2.3746, tea_CELoss: 1.0383, stu_CELoss: 1.1158, DMLLoss: 0.2205, 
2022-08-01 09:54:32 - train: epoch 0046, iter [02600, 05004], lr: 0.010000, loss: 2.9170, tea_CELoss: 1.2640, stu_CELoss: 1.4247, DMLLoss: 0.2283, 
2022-08-01 09:55:29 - train: epoch 0046, iter [02700, 05004], lr: 0.010000, loss: 2.1349, tea_CELoss: 0.8886, stu_CELoss: 1.0438, DMLLoss: 0.2025, 
2022-08-01 09:56:26 - train: epoch 0046, iter [02800, 05004], lr: 0.010000, loss: 2.1730, tea_CELoss: 0.9226, stu_CELoss: 1.0282, DMLLoss: 0.2222, 
2022-08-01 09:57:23 - train: epoch 0046, iter [02900, 05004], lr: 0.010000, loss: 2.7281, tea_CELoss: 1.1854, stu_CELoss: 1.3361, DMLLoss: 0.2066, 
2022-08-01 09:58:21 - train: epoch 0046, iter [03000, 05004], lr: 0.010000, loss: 2.3060, tea_CELoss: 1.0288, stu_CELoss: 1.0752, DMLLoss: 0.2020, 
2022-08-01 09:59:18 - train: epoch 0046, iter [03100, 05004], lr: 0.010000, loss: 2.2271, tea_CELoss: 0.9683, stu_CELoss: 1.0855, DMLLoss: 0.1733, 
2022-08-01 10:00:15 - train: epoch 0046, iter [03200, 05004], lr: 0.010000, loss: 2.3666, tea_CELoss: 1.0178, stu_CELoss: 1.1427, DMLLoss: 0.2061, 
2022-08-01 10:01:12 - train: epoch 0046, iter [03300, 05004], lr: 0.010000, loss: 2.5207, tea_CELoss: 1.0557, stu_CELoss: 1.2452, DMLLoss: 0.2197, 
2022-08-01 10:02:09 - train: epoch 0046, iter [03400, 05004], lr: 0.010000, loss: 2.5311, tea_CELoss: 1.0792, stu_CELoss: 1.2147, DMLLoss: 0.2372, 
2022-08-01 10:03:07 - train: epoch 0046, iter [03500, 05004], lr: 0.010000, loss: 2.5274, tea_CELoss: 1.0951, stu_CELoss: 1.2050, DMLLoss: 0.2273, 
2022-08-01 10:04:04 - train: epoch 0046, iter [03600, 05004], lr: 0.010000, loss: 2.4464, tea_CELoss: 1.0178, stu_CELoss: 1.2102, DMLLoss: 0.2184, 
2022-08-01 10:05:01 - train: epoch 0046, iter [03700, 05004], lr: 0.010000, loss: 2.1739, tea_CELoss: 0.8797, stu_CELoss: 1.0863, DMLLoss: 0.2079, 
2022-08-01 10:05:58 - train: epoch 0046, iter [03800, 05004], lr: 0.010000, loss: 2.3481, tea_CELoss: 0.9766, stu_CELoss: 1.1344, DMLLoss: 0.2371, 
2022-08-01 10:06:55 - train: epoch 0046, iter [03900, 05004], lr: 0.010000, loss: 2.4053, tea_CELoss: 1.0407, stu_CELoss: 1.1567, DMLLoss: 0.2079, 
2022-08-01 10:07:53 - train: epoch 0046, iter [04000, 05004], lr: 0.010000, loss: 2.2610, tea_CELoss: 0.9825, stu_CELoss: 1.0864, DMLLoss: 0.1922, 
2022-08-01 10:08:50 - train: epoch 0046, iter [04100, 05004], lr: 0.010000, loss: 2.6029, tea_CELoss: 1.1244, stu_CELoss: 1.2719, DMLLoss: 0.2066, 
2022-08-01 10:09:47 - train: epoch 0046, iter [04200, 05004], lr: 0.010000, loss: 2.2857, tea_CELoss: 0.9636, stu_CELoss: 1.0865, DMLLoss: 0.2356, 
2022-08-01 10:10:44 - train: epoch 0046, iter [04300, 05004], lr: 0.010000, loss: 2.6568, tea_CELoss: 1.1415, stu_CELoss: 1.2767, DMLLoss: 0.2386, 
2022-08-01 10:11:42 - train: epoch 0046, iter [04400, 05004], lr: 0.010000, loss: 2.7892, tea_CELoss: 1.1778, stu_CELoss: 1.3703, DMLLoss: 0.2411, 
2022-08-01 10:12:39 - train: epoch 0046, iter [04500, 05004], lr: 0.010000, loss: 2.3887, tea_CELoss: 1.0774, stu_CELoss: 1.1009, DMLLoss: 0.2104, 
2022-08-01 10:13:36 - train: epoch 0046, iter [04600, 05004], lr: 0.010000, loss: 2.4016, tea_CELoss: 1.0298, stu_CELoss: 1.1468, DMLLoss: 0.2250, 
2022-08-01 10:14:34 - train: epoch 0046, iter [04700, 05004], lr: 0.010000, loss: 2.4371, tea_CELoss: 1.0316, stu_CELoss: 1.1868, DMLLoss: 0.2187, 
2022-08-01 10:15:31 - train: epoch 0046, iter [04800, 05004], lr: 0.010000, loss: 2.0170, tea_CELoss: 0.8429, stu_CELoss: 0.9804, DMLLoss: 0.1937, 
2022-08-01 10:16:29 - train: epoch 0046, iter [04900, 05004], lr: 0.010000, loss: 2.7072, tea_CELoss: 1.1654, stu_CELoss: 1.3294, DMLLoss: 0.2125, 
2022-08-01 10:17:26 - train: epoch 0046, iter [05000, 05004], lr: 0.010000, loss: 2.4250, tea_CELoss: 1.0050, stu_CELoss: 1.1646, DMLLoss: 0.2554, 
2022-08-01 10:17:29 - train: epoch 046, train_loss: 2.4062
2022-08-01 10:20:02 - eval: epoch: 046, tea_acc1: 74.828%, tea_acc5: 92.522%, tea_test_loss: 0.9786, stu_acc1: 72.996%, stu_acc5: 91.568%, stu_test_loss: 1.0636
2022-08-01 10:20:02 - until epoch: 046, tea_best_acc1: 75.770%, stu_best_acc1: 73.634%
2022-08-01 10:20:02 - epoch 047 lr: 0.010000
2022-08-01 10:21:06 - train: epoch 0047, iter [00100, 05004], lr: 0.010000, loss: 2.7486, tea_CELoss: 1.1571, stu_CELoss: 1.3316, DMLLoss: 0.2599, 
2022-08-01 10:22:03 - train: epoch 0047, iter [00200, 05004], lr: 0.010000, loss: 2.6179, tea_CELoss: 1.1031, stu_CELoss: 1.2838, DMLLoss: 0.2310, 
2022-08-01 10:23:01 - train: epoch 0047, iter [00300, 05004], lr: 0.010000, loss: 2.0372, tea_CELoss: 0.8326, stu_CELoss: 1.0087, DMLLoss: 0.1959, 
2022-08-01 10:23:58 - train: epoch 0047, iter [00400, 05004], lr: 0.010000, loss: 1.9681, tea_CELoss: 0.8246, stu_CELoss: 0.9621, DMLLoss: 0.1814, 
2022-08-01 10:24:55 - train: epoch 0047, iter [00500, 05004], lr: 0.010000, loss: 2.1389, tea_CELoss: 0.8951, stu_CELoss: 1.0154, DMLLoss: 0.2284, 
2022-08-01 10:25:52 - train: epoch 0047, iter [00600, 05004], lr: 0.010000, loss: 2.1624, tea_CELoss: 0.9133, stu_CELoss: 1.0416, DMLLoss: 0.2075, 
2022-08-01 10:26:50 - train: epoch 0047, iter [00700, 05004], lr: 0.010000, loss: 2.4823, tea_CELoss: 1.0610, stu_CELoss: 1.2022, DMLLoss: 0.2191, 
2022-08-01 10:27:48 - train: epoch 0047, iter [00800, 05004], lr: 0.010000, loss: 2.4485, tea_CELoss: 1.0501, stu_CELoss: 1.1735, DMLLoss: 0.2249, 
2022-08-01 10:28:45 - train: epoch 0047, iter [00900, 05004], lr: 0.010000, loss: 2.6136, tea_CELoss: 1.0791, stu_CELoss: 1.3098, DMLLoss: 0.2247, 
2022-08-01 10:29:43 - train: epoch 0047, iter [01000, 05004], lr: 0.010000, loss: 2.4677, tea_CELoss: 1.0516, stu_CELoss: 1.1943, DMLLoss: 0.2218, 
2022-08-01 10:30:40 - train: epoch 0047, iter [01100, 05004], lr: 0.010000, loss: 2.6979, tea_CELoss: 1.1348, stu_CELoss: 1.3213, DMLLoss: 0.2417, 
2022-08-01 10:31:38 - train: epoch 0047, iter [01200, 05004], lr: 0.010000, loss: 2.2823, tea_CELoss: 0.9651, stu_CELoss: 1.0952, DMLLoss: 0.2220, 
2022-08-01 10:32:36 - train: epoch 0047, iter [01300, 05004], lr: 0.010000, loss: 2.2502, tea_CELoss: 0.9292, stu_CELoss: 1.1148, DMLLoss: 0.2062, 
2022-08-01 10:33:33 - train: epoch 0047, iter [01400, 05004], lr: 0.010000, loss: 2.4264, tea_CELoss: 1.0509, stu_CELoss: 1.1820, DMLLoss: 0.1935, 
2022-08-01 10:34:31 - train: epoch 0047, iter [01500, 05004], lr: 0.010000, loss: 2.5453, tea_CELoss: 1.0962, stu_CELoss: 1.2341, DMLLoss: 0.2150, 
2022-08-01 10:35:28 - train: epoch 0047, iter [01600, 05004], lr: 0.010000, loss: 2.2153, tea_CELoss: 0.9538, stu_CELoss: 1.0712, DMLLoss: 0.1903, 
2022-08-01 10:36:26 - train: epoch 0047, iter [01700, 05004], lr: 0.010000, loss: 1.9235, tea_CELoss: 0.8112, stu_CELoss: 0.9177, DMLLoss: 0.1947, 
2022-08-01 10:37:24 - train: epoch 0047, iter [01800, 05004], lr: 0.010000, loss: 2.4343, tea_CELoss: 1.0296, stu_CELoss: 1.1730, DMLLoss: 0.2317, 
2022-08-01 10:38:22 - train: epoch 0047, iter [01900, 05004], lr: 0.010000, loss: 2.2897, tea_CELoss: 1.0178, stu_CELoss: 1.0791, DMLLoss: 0.1928, 
2022-08-01 10:39:19 - train: epoch 0047, iter [02000, 05004], lr: 0.010000, loss: 2.7988, tea_CELoss: 1.2230, stu_CELoss: 1.3439, DMLLoss: 0.2320, 
2022-08-01 10:40:17 - train: epoch 0047, iter [02100, 05004], lr: 0.010000, loss: 2.3756, tea_CELoss: 0.9832, stu_CELoss: 1.1802, DMLLoss: 0.2121, 
2022-08-01 10:41:14 - train: epoch 0047, iter [02200, 05004], lr: 0.010000, loss: 2.6336, tea_CELoss: 1.1408, stu_CELoss: 1.2614, DMLLoss: 0.2314, 
2022-08-01 10:42:11 - train: epoch 0047, iter [02300, 05004], lr: 0.010000, loss: 2.3971, tea_CELoss: 1.0730, stu_CELoss: 1.1105, DMLLoss: 0.2135, 
2022-08-01 10:43:09 - train: epoch 0047, iter [02400, 05004], lr: 0.010000, loss: 2.3936, tea_CELoss: 1.0167, stu_CELoss: 1.1681, DMLLoss: 0.2088, 
2022-08-01 10:44:06 - train: epoch 0047, iter [02500, 05004], lr: 0.010000, loss: 2.4442, tea_CELoss: 1.0243, stu_CELoss: 1.2021, DMLLoss: 0.2178, 
2022-08-01 10:45:03 - train: epoch 0047, iter [02600, 05004], lr: 0.010000, loss: 3.0459, tea_CELoss: 1.3518, stu_CELoss: 1.4728, DMLLoss: 0.2214, 
2022-08-01 10:46:00 - train: epoch 0047, iter [02700, 05004], lr: 0.010000, loss: 2.0528, tea_CELoss: 0.8562, stu_CELoss: 0.9741, DMLLoss: 0.2224, 
2022-08-01 10:46:58 - train: epoch 0047, iter [02800, 05004], lr: 0.010000, loss: 2.5941, tea_CELoss: 1.1316, stu_CELoss: 1.2248, DMLLoss: 0.2377, 
2022-08-01 10:47:54 - train: epoch 0047, iter [02900, 05004], lr: 0.010000, loss: 2.3507, tea_CELoss: 0.9860, stu_CELoss: 1.1370, DMLLoss: 0.2277, 
2022-08-01 10:48:52 - train: epoch 0047, iter [03000, 05004], lr: 0.010000, loss: 2.4139, tea_CELoss: 1.0278, stu_CELoss: 1.1817, DMLLoss: 0.2045, 
2022-08-01 10:49:49 - train: epoch 0047, iter [03100, 05004], lr: 0.010000, loss: 2.1668, tea_CELoss: 0.9243, stu_CELoss: 1.0538, DMLLoss: 0.1887, 
2022-08-01 10:50:46 - train: epoch 0047, iter [03200, 05004], lr: 0.010000, loss: 2.5478, tea_CELoss: 1.1235, stu_CELoss: 1.1991, DMLLoss: 0.2252, 
2022-08-01 10:51:43 - train: epoch 0047, iter [03300, 05004], lr: 0.010000, loss: 2.5783, tea_CELoss: 1.0959, stu_CELoss: 1.2590, DMLLoss: 0.2235, 
2022-08-01 10:52:41 - train: epoch 0047, iter [03400, 05004], lr: 0.010000, loss: 2.3301, tea_CELoss: 1.0105, stu_CELoss: 1.0964, DMLLoss: 0.2232, 
2022-08-01 10:53:38 - train: epoch 0047, iter [03500, 05004], lr: 0.010000, loss: 2.6947, tea_CELoss: 1.1810, stu_CELoss: 1.2952, DMLLoss: 0.2185, 
2022-08-01 10:54:35 - train: epoch 0047, iter [03600, 05004], lr: 0.010000, loss: 2.4221, tea_CELoss: 1.0351, stu_CELoss: 1.1490, DMLLoss: 0.2380, 
2022-08-01 10:55:32 - train: epoch 0047, iter [03700, 05004], lr: 0.010000, loss: 2.0066, tea_CELoss: 0.8332, stu_CELoss: 0.9614, DMLLoss: 0.2120, 
2022-08-01 10:56:29 - train: epoch 0047, iter [03800, 05004], lr: 0.010000, loss: 2.0826, tea_CELoss: 0.8781, stu_CELoss: 1.0065, DMLLoss: 0.1979, 
2022-08-01 10:57:26 - train: epoch 0047, iter [03900, 05004], lr: 0.010000, loss: 2.6275, tea_CELoss: 1.0756, stu_CELoss: 1.2947, DMLLoss: 0.2572, 
2022-08-01 10:58:24 - train: epoch 0047, iter [04000, 05004], lr: 0.010000, loss: 2.5815, tea_CELoss: 1.0660, stu_CELoss: 1.2823, DMLLoss: 0.2332, 
2022-08-01 10:59:21 - train: epoch 0047, iter [04100, 05004], lr: 0.010000, loss: 2.5570, tea_CELoss: 1.0554, stu_CELoss: 1.2559, DMLLoss: 0.2458, 
2022-08-01 11:00:18 - train: epoch 0047, iter [04200, 05004], lr: 0.010000, loss: 2.3996, tea_CELoss: 1.0135, stu_CELoss: 1.1688, DMLLoss: 0.2173, 
2022-08-01 11:01:15 - train: epoch 0047, iter [04300, 05004], lr: 0.010000, loss: 2.3373, tea_CELoss: 0.9758, stu_CELoss: 1.1221, DMLLoss: 0.2393, 
2022-08-01 11:02:12 - train: epoch 0047, iter [04400, 05004], lr: 0.010000, loss: 2.6453, tea_CELoss: 1.1126, stu_CELoss: 1.2751, DMLLoss: 0.2576, 
2022-08-01 11:03:09 - train: epoch 0047, iter [04500, 05004], lr: 0.010000, loss: 2.4037, tea_CELoss: 1.0456, stu_CELoss: 1.1575, DMLLoss: 0.2007, 
2022-08-01 11:04:06 - train: epoch 0047, iter [04600, 05004], lr: 0.010000, loss: 2.2268, tea_CELoss: 0.9076, stu_CELoss: 1.0896, DMLLoss: 0.2296, 
2022-08-01 11:05:04 - train: epoch 0047, iter [04700, 05004], lr: 0.010000, loss: 2.6007, tea_CELoss: 1.1447, stu_CELoss: 1.2373, DMLLoss: 0.2187, 
2022-08-01 11:06:01 - train: epoch 0047, iter [04800, 05004], lr: 0.010000, loss: 2.1573, tea_CELoss: 0.9505, stu_CELoss: 0.9911, DMLLoss: 0.2157, 
2022-08-01 11:06:58 - train: epoch 0047, iter [04900, 05004], lr: 0.010000, loss: 2.4391, tea_CELoss: 1.0330, stu_CELoss: 1.1720, DMLLoss: 0.2341, 
2022-08-01 11:07:55 - train: epoch 0047, iter [05000, 05004], lr: 0.010000, loss: 2.3738, tea_CELoss: 0.9926, stu_CELoss: 1.1727, DMLLoss: 0.2085, 
2022-08-01 11:07:58 - train: epoch 047, train_loss: 2.3979
2022-08-01 11:10:28 - eval: epoch: 047, tea_acc1: 75.442%, tea_acc5: 92.800%, tea_test_loss: 0.9541, stu_acc1: 72.974%, stu_acc5: 91.470%, stu_test_loss: 1.0704
2022-08-01 11:10:29 - until epoch: 047, tea_best_acc1: 75.770%, stu_best_acc1: 73.634%
2022-08-01 11:10:29 - epoch 048 lr: 0.010000
2022-08-01 11:11:32 - train: epoch 0048, iter [00100, 05004], lr: 0.010000, loss: 2.6252, tea_CELoss: 1.1320, stu_CELoss: 1.2749, DMLLoss: 0.2183, 
2022-08-01 11:12:30 - train: epoch 0048, iter [00200, 05004], lr: 0.010000, loss: 2.9204, tea_CELoss: 1.2575, stu_CELoss: 1.4305, DMLLoss: 0.2324, 
2022-08-01 11:13:27 - train: epoch 0048, iter [00300, 05004], lr: 0.010000, loss: 2.2289, tea_CELoss: 0.9060, stu_CELoss: 1.0978, DMLLoss: 0.2251, 
2022-08-01 11:14:24 - train: epoch 0048, iter [00400, 05004], lr: 0.010000, loss: 2.2321, tea_CELoss: 0.9338, stu_CELoss: 1.0854, DMLLoss: 0.2128, 
2022-08-01 11:15:21 - train: epoch 0048, iter [00500, 05004], lr: 0.010000, loss: 2.5335, tea_CELoss: 1.0735, stu_CELoss: 1.2340, DMLLoss: 0.2261, 
2022-08-01 11:16:19 - train: epoch 0048, iter [00600, 05004], lr: 0.010000, loss: 2.4395, tea_CELoss: 1.0164, stu_CELoss: 1.1831, DMLLoss: 0.2400, 
2022-08-01 11:17:16 - train: epoch 0048, iter [00700, 05004], lr: 0.010000, loss: 2.1633, tea_CELoss: 0.9185, stu_CELoss: 1.0471, DMLLoss: 0.1977, 
2022-08-01 11:18:13 - train: epoch 0048, iter [00800, 05004], lr: 0.010000, loss: 2.5751, tea_CELoss: 1.0886, stu_CELoss: 1.2659, DMLLoss: 0.2206, 
2022-08-01 11:19:10 - train: epoch 0048, iter [00900, 05004], lr: 0.010000, loss: 2.4148, tea_CELoss: 1.0306, stu_CELoss: 1.1812, DMLLoss: 0.2030, 
2022-08-01 11:20:07 - train: epoch 0048, iter [01000, 05004], lr: 0.010000, loss: 2.4253, tea_CELoss: 1.0104, stu_CELoss: 1.1700, DMLLoss: 0.2448, 
2022-08-01 11:21:04 - train: epoch 0048, iter [01100, 05004], lr: 0.010000, loss: 2.6492, tea_CELoss: 1.1669, stu_CELoss: 1.2480, DMLLoss: 0.2344, 
2022-08-01 11:22:01 - train: epoch 0048, iter [01200, 05004], lr: 0.010000, loss: 2.9337, tea_CELoss: 1.2872, stu_CELoss: 1.4331, DMLLoss: 0.2134, 
2022-08-01 11:22:58 - train: epoch 0048, iter [01300, 05004], lr: 0.010000, loss: 2.4441, tea_CELoss: 1.0382, stu_CELoss: 1.2020, DMLLoss: 0.2039, 
2022-08-01 11:23:55 - train: epoch 0048, iter [01400, 05004], lr: 0.010000, loss: 2.3205, tea_CELoss: 0.9600, stu_CELoss: 1.1022, DMLLoss: 0.2583, 
2022-08-01 11:24:52 - train: epoch 0048, iter [01500, 05004], lr: 0.010000, loss: 2.4236, tea_CELoss: 1.0047, stu_CELoss: 1.1888, DMLLoss: 0.2301, 
2022-08-01 11:25:49 - train: epoch 0048, iter [01600, 05004], lr: 0.010000, loss: 2.5265, tea_CELoss: 1.0739, stu_CELoss: 1.2052, DMLLoss: 0.2474, 
2022-08-01 11:26:46 - train: epoch 0048, iter [01700, 05004], lr: 0.010000, loss: 2.3749, tea_CELoss: 1.0218, stu_CELoss: 1.1347, DMLLoss: 0.2184, 
2022-08-01 11:27:43 - train: epoch 0048, iter [01800, 05004], lr: 0.010000, loss: 2.1925, tea_CELoss: 0.8920, stu_CELoss: 1.0767, DMLLoss: 0.2238, 
2022-08-01 11:28:40 - train: epoch 0048, iter [01900, 05004], lr: 0.010000, loss: 2.4111, tea_CELoss: 1.0670, stu_CELoss: 1.1590, DMLLoss: 0.1851, 
2022-08-01 11:29:38 - train: epoch 0048, iter [02000, 05004], lr: 0.010000, loss: 2.4561, tea_CELoss: 1.0767, stu_CELoss: 1.1552, DMLLoss: 0.2242, 
2022-08-01 11:30:35 - train: epoch 0048, iter [02100, 05004], lr: 0.010000, loss: 2.4598, tea_CELoss: 1.0495, stu_CELoss: 1.1921, DMLLoss: 0.2181, 
2022-08-01 11:31:32 - train: epoch 0048, iter [02200, 05004], lr: 0.010000, loss: 2.7896, tea_CELoss: 1.1926, stu_CELoss: 1.3788, DMLLoss: 0.2182, 
2022-08-01 11:32:29 - train: epoch 0048, iter [02300, 05004], lr: 0.010000, loss: 2.3724, tea_CELoss: 1.0183, stu_CELoss: 1.1223, DMLLoss: 0.2318, 
2022-08-01 11:33:26 - train: epoch 0048, iter [02400, 05004], lr: 0.010000, loss: 2.9565, tea_CELoss: 1.3221, stu_CELoss: 1.4072, DMLLoss: 0.2272, 
2022-08-01 11:34:23 - train: epoch 0048, iter [02500, 05004], lr: 0.010000, loss: 2.4489, tea_CELoss: 1.0344, stu_CELoss: 1.1773, DMLLoss: 0.2373, 
2022-08-01 11:35:20 - train: epoch 0048, iter [02600, 05004], lr: 0.010000, loss: 2.6414, tea_CELoss: 1.1178, stu_CELoss: 1.2855, DMLLoss: 0.2381, 
2022-08-01 11:36:17 - train: epoch 0048, iter [02700, 05004], lr: 0.010000, loss: 2.7265, tea_CELoss: 1.1708, stu_CELoss: 1.3204, DMLLoss: 0.2353, 
2022-08-01 11:37:14 - train: epoch 0048, iter [02800, 05004], lr: 0.010000, loss: 2.1478, tea_CELoss: 0.9024, stu_CELoss: 1.0226, DMLLoss: 0.2228, 
2022-08-01 11:38:11 - train: epoch 0048, iter [02900, 05004], lr: 0.010000, loss: 2.3115, tea_CELoss: 0.9578, stu_CELoss: 1.1165, DMLLoss: 0.2372, 
2022-08-01 11:39:08 - train: epoch 0048, iter [03000, 05004], lr: 0.010000, loss: 2.5162, tea_CELoss: 1.0602, stu_CELoss: 1.2347, DMLLoss: 0.2213, 
2022-08-01 11:40:05 - train: epoch 0048, iter [03100, 05004], lr: 0.010000, loss: 2.5496, tea_CELoss: 1.0912, stu_CELoss: 1.2176, DMLLoss: 0.2408, 
2022-08-01 11:41:02 - train: epoch 0048, iter [03200, 05004], lr: 0.010000, loss: 2.3181, tea_CELoss: 0.9616, stu_CELoss: 1.1098, DMLLoss: 0.2466, 
2022-08-01 11:41:59 - train: epoch 0048, iter [03300, 05004], lr: 0.010000, loss: 2.3011, tea_CELoss: 0.9803, stu_CELoss: 1.1264, DMLLoss: 0.1944, 
2022-08-01 11:42:55 - train: epoch 0048, iter [03400, 05004], lr: 0.010000, loss: 2.3664, tea_CELoss: 0.9458, stu_CELoss: 1.1822, DMLLoss: 0.2384, 
2022-08-01 11:43:53 - train: epoch 0048, iter [03500, 05004], lr: 0.010000, loss: 2.6912, tea_CELoss: 1.1794, stu_CELoss: 1.2845, DMLLoss: 0.2272, 
2022-08-01 11:44:49 - train: epoch 0048, iter [03600, 05004], lr: 0.010000, loss: 2.4186, tea_CELoss: 1.0539, stu_CELoss: 1.1370, DMLLoss: 0.2278, 
2022-08-01 11:45:46 - train: epoch 0048, iter [03700, 05004], lr: 0.010000, loss: 2.5593, tea_CELoss: 1.1075, stu_CELoss: 1.2126, DMLLoss: 0.2392, 
2022-08-01 11:46:43 - train: epoch 0048, iter [03800, 05004], lr: 0.010000, loss: 2.1106, tea_CELoss: 0.8915, stu_CELoss: 1.0192, DMLLoss: 0.1999, 
2022-08-01 11:47:40 - train: epoch 0048, iter [03900, 05004], lr: 0.010000, loss: 2.5832, tea_CELoss: 1.0772, stu_CELoss: 1.2644, DMLLoss: 0.2415, 
2022-08-01 11:48:38 - train: epoch 0048, iter [04000, 05004], lr: 0.010000, loss: 2.0664, tea_CELoss: 0.8725, stu_CELoss: 0.9781, DMLLoss: 0.2158, 
2022-08-01 11:49:35 - train: epoch 0048, iter [04100, 05004], lr: 0.010000, loss: 2.4886, tea_CELoss: 1.1120, stu_CELoss: 1.1804, DMLLoss: 0.1962, 
2022-08-01 11:50:32 - train: epoch 0048, iter [04200, 05004], lr: 0.010000, loss: 2.5455, tea_CELoss: 1.0762, stu_CELoss: 1.2472, DMLLoss: 0.2221, 
2022-08-01 11:51:29 - train: epoch 0048, iter [04300, 05004], lr: 0.010000, loss: 2.5544, tea_CELoss: 1.1020, stu_CELoss: 1.2336, DMLLoss: 0.2188, 
2022-08-01 11:52:26 - train: epoch 0048, iter [04400, 05004], lr: 0.010000, loss: 2.4671, tea_CELoss: 1.0181, stu_CELoss: 1.2102, DMLLoss: 0.2388, 
2022-08-01 11:53:23 - train: epoch 0048, iter [04500, 05004], lr: 0.010000, loss: 2.6126, tea_CELoss: 1.1323, stu_CELoss: 1.2569, DMLLoss: 0.2233, 
2022-08-01 11:54:20 - train: epoch 0048, iter [04600, 05004], lr: 0.010000, loss: 2.4311, tea_CELoss: 1.0190, stu_CELoss: 1.1726, DMLLoss: 0.2395, 
2022-08-01 11:55:17 - train: epoch 0048, iter [04700, 05004], lr: 0.010000, loss: 2.2167, tea_CELoss: 0.9141, stu_CELoss: 1.0526, DMLLoss: 0.2500, 
2022-08-01 11:56:14 - train: epoch 0048, iter [04800, 05004], lr: 0.010000, loss: 2.8357, tea_CELoss: 1.2381, stu_CELoss: 1.3131, DMLLoss: 0.2844, 
2022-08-01 11:57:12 - train: epoch 0048, iter [04900, 05004], lr: 0.010000, loss: 2.8749, tea_CELoss: 1.2730, stu_CELoss: 1.3999, DMLLoss: 0.2020, 
2022-08-01 11:58:09 - train: epoch 0048, iter [05000, 05004], lr: 0.010000, loss: 2.3650, tea_CELoss: 1.0106, stu_CELoss: 1.1480, DMLLoss: 0.2065, 
2022-08-01 11:58:12 - train: epoch 048, train_loss: 2.4017
2022-08-01 12:00:47 - eval: epoch: 048, tea_acc1: 74.796%, tea_acc5: 92.700%, tea_test_loss: 0.9778, stu_acc1: 72.772%, stu_acc5: 91.380%, stu_test_loss: 1.0819
2022-08-01 12:00:48 - until epoch: 048, tea_best_acc1: 75.770%, stu_best_acc1: 73.634%
2022-08-01 12:00:48 - epoch 049 lr: 0.010000
2022-08-01 12:01:52 - train: epoch 0049, iter [00100, 05004], lr: 0.010000, loss: 2.6000, tea_CELoss: 1.0894, stu_CELoss: 1.2383, DMLLoss: 0.2723, 
2022-08-01 12:02:49 - train: epoch 0049, iter [00200, 05004], lr: 0.010000, loss: 2.1001, tea_CELoss: 0.8737, stu_CELoss: 0.9928, DMLLoss: 0.2336, 
2022-08-01 12:03:46 - train: epoch 0049, iter [00300, 05004], lr: 0.010000, loss: 2.3795, tea_CELoss: 0.9948, stu_CELoss: 1.1767, DMLLoss: 0.2079, 
2022-08-01 12:04:43 - train: epoch 0049, iter [00400, 05004], lr: 0.010000, loss: 2.4389, tea_CELoss: 1.0012, stu_CELoss: 1.1834, DMLLoss: 0.2543, 
2022-08-01 12:05:41 - train: epoch 0049, iter [00500, 05004], lr: 0.010000, loss: 2.5044, tea_CELoss: 1.0391, stu_CELoss: 1.2314, DMLLoss: 0.2339, 
2022-08-01 12:06:38 - train: epoch 0049, iter [00600, 05004], lr: 0.010000, loss: 2.0869, tea_CELoss: 0.8877, stu_CELoss: 0.9854, DMLLoss: 0.2139, 
2022-08-01 12:07:35 - train: epoch 0049, iter [00700, 05004], lr: 0.010000, loss: 2.4084, tea_CELoss: 1.0319, stu_CELoss: 1.1550, DMLLoss: 0.2215, 
2022-08-01 12:08:32 - train: epoch 0049, iter [00800, 05004], lr: 0.010000, loss: 2.8122, tea_CELoss: 1.1848, stu_CELoss: 1.3880, DMLLoss: 0.2395, 
2022-08-01 12:09:30 - train: epoch 0049, iter [00900, 05004], lr: 0.010000, loss: 1.8915, tea_CELoss: 0.8085, stu_CELoss: 0.8987, DMLLoss: 0.1843, 
2022-08-01 12:10:27 - train: epoch 0049, iter [01000, 05004], lr: 0.010000, loss: 2.1102, tea_CELoss: 0.8978, stu_CELoss: 1.0130, DMLLoss: 0.1994, 
2022-08-01 12:11:24 - train: epoch 0049, iter [01100, 05004], lr: 0.010000, loss: 2.2123, tea_CELoss: 0.9415, stu_CELoss: 1.0770, DMLLoss: 0.1939, 
2022-08-01 12:12:21 - train: epoch 0049, iter [01200, 05004], lr: 0.010000, loss: 2.2879, tea_CELoss: 0.9929, stu_CELoss: 1.0614, DMLLoss: 0.2336, 
2022-08-01 12:13:19 - train: epoch 0049, iter [01300, 05004], lr: 0.010000, loss: 2.5616, tea_CELoss: 1.1224, stu_CELoss: 1.2397, DMLLoss: 0.1995, 
2022-08-01 12:14:16 - train: epoch 0049, iter [01400, 05004], lr: 0.010000, loss: 2.5808, tea_CELoss: 1.1088, stu_CELoss: 1.2314, DMLLoss: 0.2406, 
2022-08-01 12:15:13 - train: epoch 0049, iter [01500, 05004], lr: 0.010000, loss: 2.3195, tea_CELoss: 0.9248, stu_CELoss: 1.1626, DMLLoss: 0.2322, 
2022-08-01 12:16:11 - train: epoch 0049, iter [01600, 05004], lr: 0.010000, loss: 2.3325, tea_CELoss: 0.9765, stu_CELoss: 1.1142, DMLLoss: 0.2418, 
2022-08-01 12:17:08 - train: epoch 0049, iter [01700, 05004], lr: 0.010000, loss: 2.5254, tea_CELoss: 1.0864, stu_CELoss: 1.2081, DMLLoss: 0.2309, 
2022-08-01 12:18:05 - train: epoch 0049, iter [01800, 05004], lr: 0.010000, loss: 2.2687, tea_CELoss: 0.9695, stu_CELoss: 1.0891, DMLLoss: 0.2101, 
2022-08-01 12:19:02 - train: epoch 0049, iter [01900, 05004], lr: 0.010000, loss: 2.1008, tea_CELoss: 0.8680, stu_CELoss: 1.0174, DMLLoss: 0.2154, 
2022-08-01 12:20:00 - train: epoch 0049, iter [02000, 05004], lr: 0.010000, loss: 2.2013, tea_CELoss: 0.9298, stu_CELoss: 1.0706, DMLLoss: 0.2009, 
2022-08-01 12:20:57 - train: epoch 0049, iter [02100, 05004], lr: 0.010000, loss: 2.0237, tea_CELoss: 0.8476, stu_CELoss: 0.9771, DMLLoss: 0.1991, 
2022-08-01 12:21:54 - train: epoch 0049, iter [02200, 05004], lr: 0.010000, loss: 2.3456, tea_CELoss: 0.9765, stu_CELoss: 1.1194, DMLLoss: 0.2497, 
2022-08-01 12:22:51 - train: epoch 0049, iter [02300, 05004], lr: 0.010000, loss: 2.2827, tea_CELoss: 0.9825, stu_CELoss: 1.0659, DMLLoss: 0.2343, 
2022-08-01 12:23:49 - train: epoch 0049, iter [02400, 05004], lr: 0.010000, loss: 2.3414, tea_CELoss: 0.9662, stu_CELoss: 1.1427, DMLLoss: 0.2325, 
2022-08-01 12:24:46 - train: epoch 0049, iter [02500, 05004], lr: 0.010000, loss: 2.3389, tea_CELoss: 0.9646, stu_CELoss: 1.1474, DMLLoss: 0.2268, 
2022-08-01 12:25:43 - train: epoch 0049, iter [02600, 05004], lr: 0.010000, loss: 2.5584, tea_CELoss: 1.0477, stu_CELoss: 1.2725, DMLLoss: 0.2383, 
2022-08-01 12:26:40 - train: epoch 0049, iter [02700, 05004], lr: 0.010000, loss: 2.6834, tea_CELoss: 1.1530, stu_CELoss: 1.2798, DMLLoss: 0.2506, 
2022-08-01 12:27:38 - train: epoch 0049, iter [02800, 05004], lr: 0.010000, loss: 2.6259, tea_CELoss: 1.0924, stu_CELoss: 1.2763, DMLLoss: 0.2572, 
2022-08-01 12:28:35 - train: epoch 0049, iter [02900, 05004], lr: 0.010000, loss: 2.4660, tea_CELoss: 1.0606, stu_CELoss: 1.1619, DMLLoss: 0.2435, 
2022-08-01 12:29:32 - train: epoch 0049, iter [03000, 05004], lr: 0.010000, loss: 2.0960, tea_CELoss: 0.8257, stu_CELoss: 1.0318, DMLLoss: 0.2385, 
2022-08-01 12:30:29 - train: epoch 0049, iter [03100, 05004], lr: 0.010000, loss: 2.4354, tea_CELoss: 1.0107, stu_CELoss: 1.2018, DMLLoss: 0.2229, 
2022-08-01 12:31:26 - train: epoch 0049, iter [03200, 05004], lr: 0.010000, loss: 2.4225, tea_CELoss: 1.0216, stu_CELoss: 1.1958, DMLLoss: 0.2051, 
2022-08-01 12:32:23 - train: epoch 0049, iter [03300, 05004], lr: 0.010000, loss: 2.5637, tea_CELoss: 1.0955, stu_CELoss: 1.2306, DMLLoss: 0.2375, 
2022-08-01 12:33:20 - train: epoch 0049, iter [03400, 05004], lr: 0.010000, loss: 2.4455, tea_CELoss: 1.0280, stu_CELoss: 1.2040, DMLLoss: 0.2135, 
2022-08-01 12:34:17 - train: epoch 0049, iter [03500, 05004], lr: 0.010000, loss: 2.5779, tea_CELoss: 1.1241, stu_CELoss: 1.2323, DMLLoss: 0.2214, 
2022-08-01 12:35:14 - train: epoch 0049, iter [03600, 05004], lr: 0.010000, loss: 2.6555, tea_CELoss: 1.1494, stu_CELoss: 1.2441, DMLLoss: 0.2620, 
2022-08-01 12:36:11 - train: epoch 0049, iter [03700, 05004], lr: 0.010000, loss: 2.3800, tea_CELoss: 0.9904, stu_CELoss: 1.1656, DMLLoss: 0.2239, 
2022-08-01 12:37:09 - train: epoch 0049, iter [03800, 05004], lr: 0.010000, loss: 2.7081, tea_CELoss: 1.1728, stu_CELoss: 1.2864, DMLLoss: 0.2489, 
2022-08-01 12:38:06 - train: epoch 0049, iter [03900, 05004], lr: 0.010000, loss: 2.4452, tea_CELoss: 1.0120, stu_CELoss: 1.1951, DMLLoss: 0.2381, 
2022-08-01 12:39:03 - train: epoch 0049, iter [04000, 05004], lr: 0.010000, loss: 2.0291, tea_CELoss: 0.8380, stu_CELoss: 0.9822, DMLLoss: 0.2089, 
2022-08-01 12:40:00 - train: epoch 0049, iter [04100, 05004], lr: 0.010000, loss: 2.3038, tea_CELoss: 0.9881, stu_CELoss: 1.1161, DMLLoss: 0.1996, 
2022-08-01 12:40:57 - train: epoch 0049, iter [04200, 05004], lr: 0.010000, loss: 2.3515, tea_CELoss: 1.0024, stu_CELoss: 1.1278, DMLLoss: 0.2213, 
2022-08-01 12:41:54 - train: epoch 0049, iter [04300, 05004], lr: 0.010000, loss: 2.5706, tea_CELoss: 1.0928, stu_CELoss: 1.2043, DMLLoss: 0.2735, 
2022-08-01 12:42:52 - train: epoch 0049, iter [04400, 05004], lr: 0.010000, loss: 2.2381, tea_CELoss: 0.9302, stu_CELoss: 1.0943, DMLLoss: 0.2135, 
2022-08-01 12:43:48 - train: epoch 0049, iter [04500, 05004], lr: 0.010000, loss: 2.0880, tea_CELoss: 0.9022, stu_CELoss: 0.9891, DMLLoss: 0.1967, 
2022-08-01 12:44:46 - train: epoch 0049, iter [04600, 05004], lr: 0.010000, loss: 2.6874, tea_CELoss: 1.1466, stu_CELoss: 1.2741, DMLLoss: 0.2668, 
2022-08-01 12:45:43 - train: epoch 0049, iter [04700, 05004], lr: 0.010000, loss: 2.6341, tea_CELoss: 1.1376, stu_CELoss: 1.2949, DMLLoss: 0.2015, 
2022-08-01 12:46:40 - train: epoch 0049, iter [04800, 05004], lr: 0.010000, loss: 2.4782, tea_CELoss: 1.0559, stu_CELoss: 1.1754, DMLLoss: 0.2470, 
2022-08-01 12:47:37 - train: epoch 0049, iter [04900, 05004], lr: 0.010000, loss: 2.6416, tea_CELoss: 1.1231, stu_CELoss: 1.2930, DMLLoss: 0.2255, 
2022-08-01 12:48:34 - train: epoch 0049, iter [05000, 05004], lr: 0.010000, loss: 2.5175, tea_CELoss: 1.0956, stu_CELoss: 1.1553, DMLLoss: 0.2666, 
2022-08-01 12:48:36 - train: epoch 049, train_loss: 2.3989
2022-08-01 12:51:12 - eval: epoch: 049, tea_acc1: 75.546%, tea_acc5: 92.874%, tea_test_loss: 0.9582, stu_acc1: 72.434%, stu_acc5: 91.066%, stu_test_loss: 1.0965
2022-08-01 12:51:13 - until epoch: 049, tea_best_acc1: 75.770%, stu_best_acc1: 73.634%
2022-08-01 12:51:13 - epoch 050 lr: 0.010000
2022-08-01 12:52:16 - train: epoch 0050, iter [00100, 05004], lr: 0.010000, loss: 2.3240, tea_CELoss: 0.9889, stu_CELoss: 1.1043, DMLLoss: 0.2308, 
2022-08-01 12:53:13 - train: epoch 0050, iter [00200, 05004], lr: 0.010000, loss: 2.2779, tea_CELoss: 0.9438, stu_CELoss: 1.0951, DMLLoss: 0.2389, 
2022-08-01 12:54:10 - train: epoch 0050, iter [00300, 05004], lr: 0.010000, loss: 2.2699, tea_CELoss: 0.9561, stu_CELoss: 1.1099, DMLLoss: 0.2039, 
2022-08-01 12:55:07 - train: epoch 0050, iter [00400, 05004], lr: 0.010000, loss: 2.1435, tea_CELoss: 0.9152, stu_CELoss: 1.0265, DMLLoss: 0.2019, 
2022-08-01 12:56:04 - train: epoch 0050, iter [00500, 05004], lr: 0.010000, loss: 2.5096, tea_CELoss: 1.0856, stu_CELoss: 1.1946, DMLLoss: 0.2294, 
2022-08-01 12:57:01 - train: epoch 0050, iter [00600, 05004], lr: 0.010000, loss: 2.5482, tea_CELoss: 1.1162, stu_CELoss: 1.2351, DMLLoss: 0.1970, 
2022-08-01 12:57:58 - train: epoch 0050, iter [00700, 05004], lr: 0.010000, loss: 2.0117, tea_CELoss: 0.8654, stu_CELoss: 0.9599, DMLLoss: 0.1865, 
2022-08-01 12:58:55 - train: epoch 0050, iter [00800, 05004], lr: 0.010000, loss: 2.0755, tea_CELoss: 0.8855, stu_CELoss: 0.9972, DMLLoss: 0.1928, 
2022-08-01 12:59:52 - train: epoch 0050, iter [00900, 05004], lr: 0.010000, loss: 2.1187, tea_CELoss: 0.8989, stu_CELoss: 1.0017, DMLLoss: 0.2180, 
2022-08-01 13:00:49 - train: epoch 0050, iter [01000, 05004], lr: 0.010000, loss: 2.3549, tea_CELoss: 0.9563, stu_CELoss: 1.1235, DMLLoss: 0.2751, 
2022-08-01 13:01:46 - train: epoch 0050, iter [01100, 05004], lr: 0.010000, loss: 2.3406, tea_CELoss: 0.9801, stu_CELoss: 1.1316, DMLLoss: 0.2290, 
2022-08-01 13:02:43 - train: epoch 0050, iter [01200, 05004], lr: 0.010000, loss: 2.1351, tea_CELoss: 0.8603, stu_CELoss: 1.0685, DMLLoss: 0.2062, 
2022-08-01 13:03:40 - train: epoch 0050, iter [01300, 05004], lr: 0.010000, loss: 2.3001, tea_CELoss: 0.9706, stu_CELoss: 1.0823, DMLLoss: 0.2471, 
2022-08-01 13:04:37 - train: epoch 0050, iter [01400, 05004], lr: 0.010000, loss: 2.4386, tea_CELoss: 1.0274, stu_CELoss: 1.1850, DMLLoss: 0.2261, 
2022-08-01 13:05:34 - train: epoch 0050, iter [01500, 05004], lr: 0.010000, loss: 2.1862, tea_CELoss: 0.9481, stu_CELoss: 1.0162, DMLLoss: 0.2219, 
2022-08-01 13:06:31 - train: epoch 0050, iter [01600, 05004], lr: 0.010000, loss: 2.1110, tea_CELoss: 0.8813, stu_CELoss: 1.0263, DMLLoss: 0.2034, 
2022-08-01 13:07:28 - train: epoch 0050, iter [01700, 05004], lr: 0.010000, loss: 2.2238, tea_CELoss: 0.9151, stu_CELoss: 1.0452, DMLLoss: 0.2636, 
2022-08-01 13:08:25 - train: epoch 0050, iter [01800, 05004], lr: 0.010000, loss: 2.7129, tea_CELoss: 1.1633, stu_CELoss: 1.2691, DMLLoss: 0.2805, 
2022-08-01 13:09:22 - train: epoch 0050, iter [01900, 05004], lr: 0.010000, loss: 2.2890, tea_CELoss: 0.9987, stu_CELoss: 1.0710, DMLLoss: 0.2193, 
2022-08-01 13:10:19 - train: epoch 0050, iter [02000, 05004], lr: 0.010000, loss: 2.1093, tea_CELoss: 0.9007, stu_CELoss: 1.0047, DMLLoss: 0.2040, 
2022-08-01 13:11:16 - train: epoch 0050, iter [02100, 05004], lr: 0.010000, loss: 2.2200, tea_CELoss: 0.9798, stu_CELoss: 1.0507, DMLLoss: 0.1895, 
2022-08-01 13:12:13 - train: epoch 0050, iter [02200, 05004], lr: 0.010000, loss: 2.2154, tea_CELoss: 0.9511, stu_CELoss: 1.0517, DMLLoss: 0.2125, 
2022-08-01 13:13:10 - train: epoch 0050, iter [02300, 05004], lr: 0.010000, loss: 2.0914, tea_CELoss: 0.8795, stu_CELoss: 1.0020, DMLLoss: 0.2099, 
2022-08-01 13:14:06 - train: epoch 0050, iter [02400, 05004], lr: 0.010000, loss: 2.5476, tea_CELoss: 1.0945, stu_CELoss: 1.2197, DMLLoss: 0.2334, 
2022-08-01 13:15:03 - train: epoch 0050, iter [02500, 05004], lr: 0.010000, loss: 2.3143, tea_CELoss: 0.9817, stu_CELoss: 1.1434, DMLLoss: 0.1891, 
2022-08-01 13:16:00 - train: epoch 0050, iter [02600, 05004], lr: 0.010000, loss: 2.1867, tea_CELoss: 0.8994, stu_CELoss: 1.0659, DMLLoss: 0.2213, 
2022-08-01 13:16:58 - train: epoch 0050, iter [02700, 05004], lr: 0.010000, loss: 2.6709, tea_CELoss: 1.1298, stu_CELoss: 1.2852, DMLLoss: 0.2559, 
2022-08-01 13:17:55 - train: epoch 0050, iter [02800, 05004], lr: 0.010000, loss: 2.6476, tea_CELoss: 1.1308, stu_CELoss: 1.2954, DMLLoss: 0.2215, 
2022-08-01 13:18:52 - train: epoch 0050, iter [02900, 05004], lr: 0.010000, loss: 2.9777, tea_CELoss: 1.2674, stu_CELoss: 1.4764, DMLLoss: 0.2339, 
2022-08-01 13:19:49 - train: epoch 0050, iter [03000, 05004], lr: 0.010000, loss: 2.4051, tea_CELoss: 1.0233, stu_CELoss: 1.1630, DMLLoss: 0.2187, 
2022-08-01 13:20:46 - train: epoch 0050, iter [03100, 05004], lr: 0.010000, loss: 2.5027, tea_CELoss: 1.0693, stu_CELoss: 1.2052, DMLLoss: 0.2282, 
2022-08-01 13:21:44 - train: epoch 0050, iter [03200, 05004], lr: 0.010000, loss: 2.8535, tea_CELoss: 1.2017, stu_CELoss: 1.3960, DMLLoss: 0.2558, 
2022-08-01 13:22:41 - train: epoch 0050, iter [03300, 05004], lr: 0.010000, loss: 2.0537, tea_CELoss: 0.8445, stu_CELoss: 0.9824, DMLLoss: 0.2268, 
2022-08-01 13:23:38 - train: epoch 0050, iter [03400, 05004], lr: 0.010000, loss: 2.3200, tea_CELoss: 0.9761, stu_CELoss: 1.1258, DMLLoss: 0.2180, 
2022-08-01 13:24:36 - train: epoch 0050, iter [03500, 05004], lr: 0.010000, loss: 2.5860, tea_CELoss: 1.1331, stu_CELoss: 1.2442, DMLLoss: 0.2087, 
2022-08-01 13:25:33 - train: epoch 0050, iter [03600, 05004], lr: 0.010000, loss: 2.3128, tea_CELoss: 0.9715, stu_CELoss: 1.1269, DMLLoss: 0.2145, 
2022-08-01 13:26:31 - train: epoch 0050, iter [03700, 05004], lr: 0.010000, loss: 2.6862, tea_CELoss: 1.1061, stu_CELoss: 1.2929, DMLLoss: 0.2871, 
2022-08-01 13:27:28 - train: epoch 0050, iter [03800, 05004], lr: 0.010000, loss: 2.1574, tea_CELoss: 0.8991, stu_CELoss: 1.0281, DMLLoss: 0.2302, 
2022-08-01 13:28:25 - train: epoch 0050, iter [03900, 05004], lr: 0.010000, loss: 2.1424, tea_CELoss: 0.9084, stu_CELoss: 1.0258, DMLLoss: 0.2081, 
2022-08-01 13:29:22 - train: epoch 0050, iter [04000, 05004], lr: 0.010000, loss: 2.6920, tea_CELoss: 1.1688, stu_CELoss: 1.2992, DMLLoss: 0.2241, 
2022-08-01 13:30:19 - train: epoch 0050, iter [04100, 05004], lr: 0.010000, loss: 2.4411, tea_CELoss: 1.0231, stu_CELoss: 1.1890, DMLLoss: 0.2290, 
2022-08-01 13:31:17 - train: epoch 0050, iter [04200, 05004], lr: 0.010000, loss: 2.5572, tea_CELoss: 1.0928, stu_CELoss: 1.2383, DMLLoss: 0.2261, 
2022-08-01 13:32:14 - train: epoch 0050, iter [04300, 05004], lr: 0.010000, loss: 2.7486, tea_CELoss: 1.1868, stu_CELoss: 1.3162, DMLLoss: 0.2456, 
2022-08-01 13:33:11 - train: epoch 0050, iter [04400, 05004], lr: 0.010000, loss: 2.1286, tea_CELoss: 0.8774, stu_CELoss: 1.0223, DMLLoss: 0.2290, 
2022-08-01 13:34:08 - train: epoch 0050, iter [04500, 05004], lr: 0.010000, loss: 2.1660, tea_CELoss: 0.9225, stu_CELoss: 1.0238, DMLLoss: 0.2197, 
2022-08-01 13:35:05 - train: epoch 0050, iter [04600, 05004], lr: 0.010000, loss: 2.7914, tea_CELoss: 1.1885, stu_CELoss: 1.3472, DMLLoss: 0.2557, 
2022-08-01 13:36:03 - train: epoch 0050, iter [04700, 05004], lr: 0.010000, loss: 2.7348, tea_CELoss: 1.2030, stu_CELoss: 1.3106, DMLLoss: 0.2212, 
2022-08-01 13:37:00 - train: epoch 0050, iter [04800, 05004], lr: 0.010000, loss: 2.3658, tea_CELoss: 1.0097, stu_CELoss: 1.1487, DMLLoss: 0.2074, 
2022-08-01 13:37:57 - train: epoch 0050, iter [04900, 05004], lr: 0.010000, loss: 2.3154, tea_CELoss: 0.9243, stu_CELoss: 1.1422, DMLLoss: 0.2489, 
2022-08-01 13:38:55 - train: epoch 0050, iter [05000, 05004], lr: 0.010000, loss: 2.2555, tea_CELoss: 0.9357, stu_CELoss: 1.0932, DMLLoss: 0.2266, 
2022-08-01 13:38:57 - train: epoch 050, train_loss: 2.3984
2022-08-01 13:41:33 - eval: epoch: 050, tea_acc1: 75.084%, tea_acc5: 92.662%, tea_test_loss: 0.9694, stu_acc1: 73.250%, stu_acc5: 91.438%, stu_test_loss: 1.0692
2022-08-01 13:41:34 - until epoch: 050, tea_best_acc1: 75.770%, stu_best_acc1: 73.634%
2022-08-01 13:41:34 - epoch 051 lr: 0.010000
2022-08-01 13:42:37 - train: epoch 0051, iter [00100, 05004], lr: 0.010000, loss: 2.3639, tea_CELoss: 0.9771, stu_CELoss: 1.1678, DMLLoss: 0.2190, 
2022-08-01 13:43:34 - train: epoch 0051, iter [00200, 05004], lr: 0.010000, loss: 2.8190, tea_CELoss: 1.1761, stu_CELoss: 1.4171, DMLLoss: 0.2259, 
2022-08-01 13:44:32 - train: epoch 0051, iter [00300, 05004], lr: 0.010000, loss: 2.4238, tea_CELoss: 1.0346, stu_CELoss: 1.1433, DMLLoss: 0.2459, 
2022-08-01 13:45:29 - train: epoch 0051, iter [00400, 05004], lr: 0.010000, loss: 2.1464, tea_CELoss: 0.8816, stu_CELoss: 1.0275, DMLLoss: 0.2373, 
2022-08-01 13:46:26 - train: epoch 0051, iter [00500, 05004], lr: 0.010000, loss: 2.4945, tea_CELoss: 1.0564, stu_CELoss: 1.1816, DMLLoss: 0.2565, 
2022-08-01 13:47:23 - train: epoch 0051, iter [00600, 05004], lr: 0.010000, loss: 2.1761, tea_CELoss: 0.9293, stu_CELoss: 1.0134, DMLLoss: 0.2334, 
2022-08-01 13:48:21 - train: epoch 0051, iter [00700, 05004], lr: 0.010000, loss: 2.2225, tea_CELoss: 0.9106, stu_CELoss: 1.0879, DMLLoss: 0.2240, 
2022-08-01 13:49:18 - train: epoch 0051, iter [00800, 05004], lr: 0.010000, loss: 2.7377, tea_CELoss: 1.1348, stu_CELoss: 1.3420, DMLLoss: 0.2609, 
2022-08-01 13:50:15 - train: epoch 0051, iter [00900, 05004], lr: 0.010000, loss: 2.0684, tea_CELoss: 0.8738, stu_CELoss: 0.9978, DMLLoss: 0.1968, 
2022-08-01 13:51:12 - train: epoch 0051, iter [01000, 05004], lr: 0.010000, loss: 2.8145, tea_CELoss: 1.1577, stu_CELoss: 1.3838, DMLLoss: 0.2730, 
2022-08-01 13:52:09 - train: epoch 0051, iter [01100, 05004], lr: 0.010000, loss: 2.8487, tea_CELoss: 1.1999, stu_CELoss: 1.4059, DMLLoss: 0.2430, 
2022-08-01 13:53:06 - train: epoch 0051, iter [01200, 05004], lr: 0.010000, loss: 1.9306, tea_CELoss: 0.7843, stu_CELoss: 0.9233, DMLLoss: 0.2230, 
2022-08-01 13:54:03 - train: epoch 0051, iter [01300, 05004], lr: 0.010000, loss: 2.1723, tea_CELoss: 0.9187, stu_CELoss: 1.0150, DMLLoss: 0.2385, 
2022-08-01 13:55:00 - train: epoch 0051, iter [01400, 05004], lr: 0.010000, loss: 2.1728, tea_CELoss: 0.9180, stu_CELoss: 1.0436, DMLLoss: 0.2113, 
2022-08-01 13:55:58 - train: epoch 0051, iter [01500, 05004], lr: 0.010000, loss: 2.4224, tea_CELoss: 1.0191, stu_CELoss: 1.1895, DMLLoss: 0.2139, 
2022-08-01 13:56:55 - train: epoch 0051, iter [01600, 05004], lr: 0.010000, loss: 2.0099, tea_CELoss: 0.8296, stu_CELoss: 0.9532, DMLLoss: 0.2271, 
2022-08-01 13:57:52 - train: epoch 0051, iter [01700, 05004], lr: 0.010000, loss: 2.4228, tea_CELoss: 1.0188, stu_CELoss: 1.1632, DMLLoss: 0.2408, 
2022-08-01 13:58:49 - train: epoch 0051, iter [01800, 05004], lr: 0.010000, loss: 2.5596, tea_CELoss: 1.1227, stu_CELoss: 1.2446, DMLLoss: 0.1924, 
2022-08-01 13:59:47 - train: epoch 0051, iter [01900, 05004], lr: 0.010000, loss: 2.2782, tea_CELoss: 0.9476, stu_CELoss: 1.1117, DMLLoss: 0.2190, 
2022-08-01 14:00:43 - train: epoch 0051, iter [02000, 05004], lr: 0.010000, loss: 2.0203, tea_CELoss: 0.8679, stu_CELoss: 0.9453, DMLLoss: 0.2071, 
2022-08-01 14:01:41 - train: epoch 0051, iter [02100, 05004], lr: 0.010000, loss: 2.6399, tea_CELoss: 1.1779, stu_CELoss: 1.2418, DMLLoss: 0.2202, 
2022-08-01 14:02:38 - train: epoch 0051, iter [02200, 05004], lr: 0.010000, loss: 2.5381, tea_CELoss: 1.0508, stu_CELoss: 1.2124, DMLLoss: 0.2749, 
2022-08-01 14:03:35 - train: epoch 0051, iter [02300, 05004], lr: 0.010000, loss: 2.5222, tea_CELoss: 1.0766, stu_CELoss: 1.1996, DMLLoss: 0.2460, 
2022-08-01 14:04:32 - train: epoch 0051, iter [02400, 05004], lr: 0.010000, loss: 2.4039, tea_CELoss: 1.0365, stu_CELoss: 1.1677, DMLLoss: 0.1997, 
2022-08-01 14:05:30 - train: epoch 0051, iter [02500, 05004], lr: 0.010000, loss: 1.9999, tea_CELoss: 0.8380, stu_CELoss: 0.9522, DMLLoss: 0.2097, 
2022-08-01 14:06:27 - train: epoch 0051, iter [02600, 05004], lr: 0.010000, loss: 2.5106, tea_CELoss: 1.0708, stu_CELoss: 1.1933, DMLLoss: 0.2465, 
2022-08-01 14:07:24 - train: epoch 0051, iter [02700, 05004], lr: 0.010000, loss: 2.1952, tea_CELoss: 0.9247, stu_CELoss: 1.0652, DMLLoss: 0.2053, 
2022-08-01 14:08:22 - train: epoch 0051, iter [02800, 05004], lr: 0.010000, loss: 2.0847, tea_CELoss: 0.8811, stu_CELoss: 0.9924, DMLLoss: 0.2112, 
2022-08-01 14:09:19 - train: epoch 0051, iter [02900, 05004], lr: 0.010000, loss: 2.4840, tea_CELoss: 1.0686, stu_CELoss: 1.1871, DMLLoss: 0.2283, 
2022-08-01 14:10:16 - train: epoch 0051, iter [03000, 05004], lr: 0.010000, loss: 2.3335, tea_CELoss: 0.9634, stu_CELoss: 1.1188, DMLLoss: 0.2514, 
2022-08-01 14:11:14 - train: epoch 0051, iter [03100, 05004], lr: 0.010000, loss: 2.0780, tea_CELoss: 0.8727, stu_CELoss: 1.0276, DMLLoss: 0.1777, 
2022-08-01 14:12:11 - train: epoch 0051, iter [03200, 05004], lr: 0.010000, loss: 2.3099, tea_CELoss: 0.9722, stu_CELoss: 1.1155, DMLLoss: 0.2223, 
2022-08-01 14:13:08 - train: epoch 0051, iter [03300, 05004], lr: 0.010000, loss: 2.7589, tea_CELoss: 1.1975, stu_CELoss: 1.3012, DMLLoss: 0.2602, 
2022-08-01 14:14:05 - train: epoch 0051, iter [03400, 05004], lr: 0.010000, loss: 2.6170, tea_CELoss: 1.0781, stu_CELoss: 1.2871, DMLLoss: 0.2518, 
2022-08-01 14:15:02 - train: epoch 0051, iter [03500, 05004], lr: 0.010000, loss: 2.3324, tea_CELoss: 0.9885, stu_CELoss: 1.1260, DMLLoss: 0.2180, 
2022-08-01 14:15:59 - train: epoch 0051, iter [03600, 05004], lr: 0.010000, loss: 2.3457, tea_CELoss: 0.9787, stu_CELoss: 1.1300, DMLLoss: 0.2370, 
2022-08-01 14:16:56 - train: epoch 0051, iter [03700, 05004], lr: 0.010000, loss: 2.5550, tea_CELoss: 1.0960, stu_CELoss: 1.2243, DMLLoss: 0.2346, 
2022-08-01 14:17:53 - train: epoch 0051, iter [03800, 05004], lr: 0.010000, loss: 2.4920, tea_CELoss: 1.0322, stu_CELoss: 1.1840, DMLLoss: 0.2758, 
2022-08-01 14:18:50 - train: epoch 0051, iter [03900, 05004], lr: 0.010000, loss: 2.5191, tea_CELoss: 1.0549, stu_CELoss: 1.2201, DMLLoss: 0.2441, 
2022-08-01 14:19:48 - train: epoch 0051, iter [04000, 05004], lr: 0.010000, loss: 2.5801, tea_CELoss: 1.1186, stu_CELoss: 1.2153, DMLLoss: 0.2462, 
2022-08-01 14:20:45 - train: epoch 0051, iter [04100, 05004], lr: 0.010000, loss: 2.4151, tea_CELoss: 1.0429, stu_CELoss: 1.1566, DMLLoss: 0.2157, 
2022-08-01 14:21:42 - train: epoch 0051, iter [04200, 05004], lr: 0.010000, loss: 2.9308, tea_CELoss: 1.2442, stu_CELoss: 1.4280, DMLLoss: 0.2587, 
2022-08-01 14:22:40 - train: epoch 0051, iter [04300, 05004], lr: 0.010000, loss: 2.3319, tea_CELoss: 0.9988, stu_CELoss: 1.1225, DMLLoss: 0.2107, 
2022-08-01 14:23:37 - train: epoch 0051, iter [04400, 05004], lr: 0.010000, loss: 2.3949, tea_CELoss: 1.0186, stu_CELoss: 1.1402, DMLLoss: 0.2362, 
2022-08-01 14:24:34 - train: epoch 0051, iter [04500, 05004], lr: 0.010000, loss: 2.0742, tea_CELoss: 0.8662, stu_CELoss: 0.9777, DMLLoss: 0.2303, 
2022-08-01 14:25:32 - train: epoch 0051, iter [04600, 05004], lr: 0.010000, loss: 2.6333, tea_CELoss: 1.1467, stu_CELoss: 1.2627, DMLLoss: 0.2239, 
2022-08-01 14:26:29 - train: epoch 0051, iter [04700, 05004], lr: 0.010000, loss: 2.4864, tea_CELoss: 1.0315, stu_CELoss: 1.2276, DMLLoss: 0.2274, 
2022-08-01 14:27:26 - train: epoch 0051, iter [04800, 05004], lr: 0.010000, loss: 2.4865, tea_CELoss: 1.0914, stu_CELoss: 1.1727, DMLLoss: 0.2224, 
2022-08-01 14:28:23 - train: epoch 0051, iter [04900, 05004], lr: 0.010000, loss: 2.4977, tea_CELoss: 1.0593, stu_CELoss: 1.1918, DMLLoss: 0.2465, 
2022-08-01 14:29:20 - train: epoch 0051, iter [05000, 05004], lr: 0.010000, loss: 2.1520, tea_CELoss: 0.8801, stu_CELoss: 1.0525, DMLLoss: 0.2195, 
2022-08-01 14:29:23 - train: epoch 051, train_loss: 2.3956
2022-08-01 14:31:59 - eval: epoch: 051, tea_acc1: 75.222%, tea_acc5: 92.630%, tea_test_loss: 0.9655, stu_acc1: 72.952%, stu_acc5: 91.278%, stu_test_loss: 1.0763
2022-08-01 14:32:00 - until epoch: 051, tea_best_acc1: 75.770%, stu_best_acc1: 73.634%
2022-08-01 14:32:00 - epoch 052 lr: 0.010000
2022-08-01 14:33:04 - train: epoch 0052, iter [00100, 05004], lr: 0.010000, loss: 2.2829, tea_CELoss: 0.9601, stu_CELoss: 1.1094, DMLLoss: 0.2133, 
2022-08-01 14:34:01 - train: epoch 0052, iter [00200, 05004], lr: 0.010000, loss: 2.4810, tea_CELoss: 1.0217, stu_CELoss: 1.2352, DMLLoss: 0.2241, 
2022-08-01 14:34:59 - train: epoch 0052, iter [00300, 05004], lr: 0.010000, loss: 2.2219, tea_CELoss: 0.9239, stu_CELoss: 1.0749, DMLLoss: 0.2231, 
2022-08-01 14:35:56 - train: epoch 0052, iter [00400, 05004], lr: 0.010000, loss: 2.5145, tea_CELoss: 1.0590, stu_CELoss: 1.2312, DMLLoss: 0.2242, 
2022-08-01 14:36:53 - train: epoch 0052, iter [00500, 05004], lr: 0.010000, loss: 2.4845, tea_CELoss: 1.0817, stu_CELoss: 1.1649, DMLLoss: 0.2379, 
2022-08-01 14:37:50 - train: epoch 0052, iter [00600, 05004], lr: 0.010000, loss: 2.3642, tea_CELoss: 0.9916, stu_CELoss: 1.1449, DMLLoss: 0.2278, 
2022-08-01 14:38:48 - train: epoch 0052, iter [00700, 05004], lr: 0.010000, loss: 2.7201, tea_CELoss: 1.1546, stu_CELoss: 1.3188, DMLLoss: 0.2467, 
2022-08-01 14:39:45 - train: epoch 0052, iter [00800, 05004], lr: 0.010000, loss: 2.1466, tea_CELoss: 0.9027, stu_CELoss: 1.0225, DMLLoss: 0.2213, 
2022-08-01 14:40:43 - train: epoch 0052, iter [00900, 05004], lr: 0.010000, loss: 2.5964, tea_CELoss: 1.1109, stu_CELoss: 1.2387, DMLLoss: 0.2468, 
2022-08-01 14:41:40 - train: epoch 0052, iter [01000, 05004], lr: 0.010000, loss: 2.5011, tea_CELoss: 1.0592, stu_CELoss: 1.2002, DMLLoss: 0.2418, 
2022-08-01 14:42:37 - train: epoch 0052, iter [01100, 05004], lr: 0.010000, loss: 2.3444, tea_CELoss: 0.9620, stu_CELoss: 1.1280, DMLLoss: 0.2543, 
2022-08-01 14:43:35 - train: epoch 0052, iter [01200, 05004], lr: 0.010000, loss: 2.5306, tea_CELoss: 1.0513, stu_CELoss: 1.2526, DMLLoss: 0.2267, 
2022-08-01 14:44:32 - train: epoch 0052, iter [01300, 05004], lr: 0.010000, loss: 2.5326, tea_CELoss: 1.0491, stu_CELoss: 1.2258, DMLLoss: 0.2577, 
2022-08-01 14:45:30 - train: epoch 0052, iter [01400, 05004], lr: 0.010000, loss: 2.6685, tea_CELoss: 1.1200, stu_CELoss: 1.2916, DMLLoss: 0.2570, 
2022-08-01 14:46:27 - train: epoch 0052, iter [01500, 05004], lr: 0.010000, loss: 2.1385, tea_CELoss: 0.8788, stu_CELoss: 1.0401, DMLLoss: 0.2196, 
2022-08-01 14:47:25 - train: epoch 0052, iter [01600, 05004], lr: 0.010000, loss: 2.0164, tea_CELoss: 0.8507, stu_CELoss: 0.9530, DMLLoss: 0.2127, 
2022-08-01 14:48:22 - train: epoch 0052, iter [01700, 05004], lr: 0.010000, loss: 2.1922, tea_CELoss: 0.9292, stu_CELoss: 1.0547, DMLLoss: 0.2083, 
2022-08-01 14:49:19 - train: epoch 0052, iter [01800, 05004], lr: 0.010000, loss: 2.2877, tea_CELoss: 0.9853, stu_CELoss: 1.0769, DMLLoss: 0.2255, 
2022-08-01 14:50:16 - train: epoch 0052, iter [01900, 05004], lr: 0.010000, loss: 2.0284, tea_CELoss: 0.8893, stu_CELoss: 0.9449, DMLLoss: 0.1942, 
2022-08-01 14:51:14 - train: epoch 0052, iter [02000, 05004], lr: 0.010000, loss: 2.6958, tea_CELoss: 1.1475, stu_CELoss: 1.2675, DMLLoss: 0.2808, 
2022-08-01 14:52:11 - train: epoch 0052, iter [02100, 05004], lr: 0.010000, loss: 2.1995, tea_CELoss: 0.9567, stu_CELoss: 1.0116, DMLLoss: 0.2312, 
2022-08-01 14:53:09 - train: epoch 0052, iter [02200, 05004], lr: 0.010000, loss: 2.7427, tea_CELoss: 1.1971, stu_CELoss: 1.3147, DMLLoss: 0.2309, 
2022-08-01 14:54:06 - train: epoch 0052, iter [02300, 05004], lr: 0.010000, loss: 2.3544, tea_CELoss: 1.0103, stu_CELoss: 1.1377, DMLLoss: 0.2063, 
2022-08-01 14:55:04 - train: epoch 0052, iter [02400, 05004], lr: 0.010000, loss: 1.8315, tea_CELoss: 0.7730, stu_CELoss: 0.8638, DMLLoss: 0.1947, 
2022-08-01 14:56:01 - train: epoch 0052, iter [02500, 05004], lr: 0.010000, loss: 2.1917, tea_CELoss: 0.9322, stu_CELoss: 1.0671, DMLLoss: 0.1924, 
2022-08-01 14:56:58 - train: epoch 0052, iter [02600, 05004], lr: 0.010000, loss: 2.0543, tea_CELoss: 0.8743, stu_CELoss: 0.9792, DMLLoss: 0.2008, 
2022-08-01 14:57:56 - train: epoch 0052, iter [02700, 05004], lr: 0.010000, loss: 2.4077, tea_CELoss: 1.0189, stu_CELoss: 1.1613, DMLLoss: 0.2276, 
2022-08-01 14:58:53 - train: epoch 0052, iter [02800, 05004], lr: 0.010000, loss: 2.4365, tea_CELoss: 1.0081, stu_CELoss: 1.1691, DMLLoss: 0.2593, 
2022-08-01 14:59:50 - train: epoch 0052, iter [02900, 05004], lr: 0.010000, loss: 2.3699, tea_CELoss: 1.0087, stu_CELoss: 1.1407, DMLLoss: 0.2205, 
2022-08-01 15:00:48 - train: epoch 0052, iter [03000, 05004], lr: 0.010000, loss: 2.2973, tea_CELoss: 0.9866, stu_CELoss: 1.0966, DMLLoss: 0.2141, 
2022-08-01 15:01:45 - train: epoch 0052, iter [03100, 05004], lr: 0.010000, loss: 2.6187, tea_CELoss: 1.1328, stu_CELoss: 1.2662, DMLLoss: 0.2197, 
2022-08-01 15:02:42 - train: epoch 0052, iter [03200, 05004], lr: 0.010000, loss: 2.5529, tea_CELoss: 1.0968, stu_CELoss: 1.2266, DMLLoss: 0.2295, 
2022-08-01 15:03:39 - train: epoch 0052, iter [03300, 05004], lr: 0.010000, loss: 2.7517, tea_CELoss: 1.1610, stu_CELoss: 1.3172, DMLLoss: 0.2735, 
2022-08-01 15:04:37 - train: epoch 0052, iter [03400, 05004], lr: 0.010000, loss: 2.3470, tea_CELoss: 1.0038, stu_CELoss: 1.1290, DMLLoss: 0.2142, 
2022-08-01 15:05:34 - train: epoch 0052, iter [03500, 05004], lr: 0.010000, loss: 2.5445, tea_CELoss: 1.0636, stu_CELoss: 1.2308, DMLLoss: 0.2500, 
2022-08-01 15:06:31 - train: epoch 0052, iter [03600, 05004], lr: 0.010000, loss: 2.5014, tea_CELoss: 1.0743, stu_CELoss: 1.1872, DMLLoss: 0.2399, 
2022-08-01 15:07:29 - train: epoch 0052, iter [03700, 05004], lr: 0.010000, loss: 2.7241, tea_CELoss: 1.1400, stu_CELoss: 1.3303, DMLLoss: 0.2537, 
2022-08-01 15:08:26 - train: epoch 0052, iter [03800, 05004], lr: 0.010000, loss: 2.5103, tea_CELoss: 1.0670, stu_CELoss: 1.2039, DMLLoss: 0.2394, 
2022-08-01 15:09:24 - train: epoch 0052, iter [03900, 05004], lr: 0.010000, loss: 2.2763, tea_CELoss: 0.9528, stu_CELoss: 1.0699, DMLLoss: 0.2536, 
2022-08-01 15:10:21 - train: epoch 0052, iter [04000, 05004], lr: 0.010000, loss: 2.9532, tea_CELoss: 1.2819, stu_CELoss: 1.4087, DMLLoss: 0.2626, 
2022-08-01 15:11:18 - train: epoch 0052, iter [04100, 05004], lr: 0.010000, loss: 2.1457, tea_CELoss: 0.8935, stu_CELoss: 1.0174, DMLLoss: 0.2348, 
2022-08-01 15:12:16 - train: epoch 0052, iter [04200, 05004], lr: 0.010000, loss: 2.6829, tea_CELoss: 1.1359, stu_CELoss: 1.2702, DMLLoss: 0.2768, 
2022-08-01 15:13:13 - train: epoch 0052, iter [04300, 05004], lr: 0.010000, loss: 2.2910, tea_CELoss: 0.9813, stu_CELoss: 1.1063, DMLLoss: 0.2034, 
2022-08-01 15:14:11 - train: epoch 0052, iter [04400, 05004], lr: 0.010000, loss: 2.5562, tea_CELoss: 1.0871, stu_CELoss: 1.2056, DMLLoss: 0.2635, 
2022-08-01 15:15:08 - train: epoch 0052, iter [04500, 05004], lr: 0.010000, loss: 2.2493, tea_CELoss: 0.9134, stu_CELoss: 1.0893, DMLLoss: 0.2465, 
2022-08-01 15:16:06 - train: epoch 0052, iter [04600, 05004], lr: 0.010000, loss: 2.3665, tea_CELoss: 1.0257, stu_CELoss: 1.1162, DMLLoss: 0.2245, 
2022-08-01 15:17:04 - train: epoch 0052, iter [04700, 05004], lr: 0.010000, loss: 2.4686, tea_CELoss: 1.0425, stu_CELoss: 1.2005, DMLLoss: 0.2255, 
2022-08-01 15:18:01 - train: epoch 0052, iter [04800, 05004], lr: 0.010000, loss: 2.0071, tea_CELoss: 0.8567, stu_CELoss: 0.9461, DMLLoss: 0.2043, 
2022-08-01 15:18:59 - train: epoch 0052, iter [04900, 05004], lr: 0.010000, loss: 2.2336, tea_CELoss: 0.9728, stu_CELoss: 1.0298, DMLLoss: 0.2310, 
2022-08-01 15:19:56 - train: epoch 0052, iter [05000, 05004], lr: 0.010000, loss: 2.2886, tea_CELoss: 0.9043, stu_CELoss: 1.1475, DMLLoss: 0.2368, 
2022-08-01 15:19:59 - train: epoch 052, train_loss: 2.3894
2022-08-01 15:22:34 - eval: epoch: 052, tea_acc1: 75.154%, tea_acc5: 92.566%, tea_test_loss: 0.9767, stu_acc1: 72.818%, stu_acc5: 91.312%, stu_test_loss: 1.0866
2022-08-01 15:22:35 - until epoch: 052, tea_best_acc1: 75.770%, stu_best_acc1: 73.634%
2022-08-01 15:22:35 - epoch 053 lr: 0.010000
2022-08-01 15:23:39 - train: epoch 0053, iter [00100, 05004], lr: 0.010000, loss: 2.4843, tea_CELoss: 1.0082, stu_CELoss: 1.2398, DMLLoss: 0.2362, 
2022-08-01 15:24:36 - train: epoch 0053, iter [00200, 05004], lr: 0.010000, loss: 2.1423, tea_CELoss: 0.8395, stu_CELoss: 1.0537, DMLLoss: 0.2492, 
2022-08-01 15:25:33 - train: epoch 0053, iter [00300, 05004], lr: 0.010000, loss: 2.1134, tea_CELoss: 0.8617, stu_CELoss: 0.9957, DMLLoss: 0.2560, 
2022-08-01 15:26:30 - train: epoch 0053, iter [00400, 05004], lr: 0.010000, loss: 2.3572, tea_CELoss: 0.9755, stu_CELoss: 1.1321, DMLLoss: 0.2497, 
2022-08-01 15:27:27 - train: epoch 0053, iter [00500, 05004], lr: 0.010000, loss: 2.1834, tea_CELoss: 0.9518, stu_CELoss: 0.9860, DMLLoss: 0.2456, 
2022-08-01 15:28:25 - train: epoch 0053, iter [00600, 05004], lr: 0.010000, loss: 2.2651, tea_CELoss: 0.9523, stu_CELoss: 1.0587, DMLLoss: 0.2541, 
2022-08-01 15:29:22 - train: epoch 0053, iter [00700, 05004], lr: 0.010000, loss: 2.5280, tea_CELoss: 1.0579, stu_CELoss: 1.2240, DMLLoss: 0.2462, 
2022-08-01 15:30:19 - train: epoch 0053, iter [00800, 05004], lr: 0.010000, loss: 2.1223, tea_CELoss: 0.8902, stu_CELoss: 1.0381, DMLLoss: 0.1940, 
2022-08-01 15:31:16 - train: epoch 0053, iter [00900, 05004], lr: 0.010000, loss: 2.0987, tea_CELoss: 0.8237, stu_CELoss: 1.0412, DMLLoss: 0.2338, 
2022-08-01 15:32:14 - train: epoch 0053, iter [01000, 05004], lr: 0.010000, loss: 2.1808, tea_CELoss: 0.9072, stu_CELoss: 1.0505, DMLLoss: 0.2231, 
2022-08-01 15:33:11 - train: epoch 0053, iter [01100, 05004], lr: 0.010000, loss: 2.5423, tea_CELoss: 1.0566, stu_CELoss: 1.2266, DMLLoss: 0.2591, 
2022-08-01 15:34:09 - train: epoch 0053, iter [01200, 05004], lr: 0.010000, loss: 2.0890, tea_CELoss: 0.8485, stu_CELoss: 1.0053, DMLLoss: 0.2352, 
2022-08-01 15:35:06 - train: epoch 0053, iter [01300, 05004], lr: 0.010000, loss: 2.4897, tea_CELoss: 1.0838, stu_CELoss: 1.1594, DMLLoss: 0.2465, 
2022-08-01 15:36:03 - train: epoch 0053, iter [01400, 05004], lr: 0.010000, loss: 2.3359, tea_CELoss: 0.9667, stu_CELoss: 1.1094, DMLLoss: 0.2598, 
2022-08-01 15:37:00 - train: epoch 0053, iter [01500, 05004], lr: 0.010000, loss: 2.2189, tea_CELoss: 0.9244, stu_CELoss: 1.0836, DMLLoss: 0.2108, 
2022-08-01 15:37:57 - train: epoch 0053, iter [01600, 05004], lr: 0.010000, loss: 2.5752, tea_CELoss: 1.0646, stu_CELoss: 1.2531, DMLLoss: 0.2576, 
2022-08-01 15:38:55 - train: epoch 0053, iter [01700, 05004], lr: 0.010000, loss: 2.5137, tea_CELoss: 1.0900, stu_CELoss: 1.2052, DMLLoss: 0.2185, 
2022-08-01 15:39:52 - train: epoch 0053, iter [01800, 05004], lr: 0.010000, loss: 2.6292, tea_CELoss: 1.1256, stu_CELoss: 1.2583, DMLLoss: 0.2452, 
2022-08-01 15:40:49 - train: epoch 0053, iter [01900, 05004], lr: 0.010000, loss: 1.9740, tea_CELoss: 0.8500, stu_CELoss: 0.9130, DMLLoss: 0.2109, 
2022-08-01 15:41:46 - train: epoch 0053, iter [02000, 05004], lr: 0.010000, loss: 2.5702, tea_CELoss: 1.0846, stu_CELoss: 1.2263, DMLLoss: 0.2594, 
2022-08-01 15:42:44 - train: epoch 0053, iter [02100, 05004], lr: 0.010000, loss: 2.8857, tea_CELoss: 1.1834, stu_CELoss: 1.4536, DMLLoss: 0.2487, 
2022-08-01 15:43:41 - train: epoch 0053, iter [02200, 05004], lr: 0.010000, loss: 2.5700, tea_CELoss: 1.1149, stu_CELoss: 1.2215, DMLLoss: 0.2335, 
2022-08-01 15:44:38 - train: epoch 0053, iter [02300, 05004], lr: 0.010000, loss: 2.3235, tea_CELoss: 0.9895, stu_CELoss: 1.1062, DMLLoss: 0.2277, 
2022-08-01 15:45:36 - train: epoch 0053, iter [02400, 05004], lr: 0.010000, loss: 2.2690, tea_CELoss: 0.9702, stu_CELoss: 1.0755, DMLLoss: 0.2233, 
2022-08-01 15:46:33 - train: epoch 0053, iter [02500, 05004], lr: 0.010000, loss: 2.7157, tea_CELoss: 1.2016, stu_CELoss: 1.2983, DMLLoss: 0.2158, 
2022-08-01 15:47:31 - train: epoch 0053, iter [02600, 05004], lr: 0.010000, loss: 2.7129, tea_CELoss: 1.1260, stu_CELoss: 1.2960, DMLLoss: 0.2910, 
2022-08-01 15:48:28 - train: epoch 0053, iter [02700, 05004], lr: 0.010000, loss: 2.3247, tea_CELoss: 0.9486, stu_CELoss: 1.0954, DMLLoss: 0.2808, 
2022-08-01 15:49:26 - train: epoch 0053, iter [02800, 05004], lr: 0.010000, loss: 2.6251, tea_CELoss: 1.0896, stu_CELoss: 1.2797, DMLLoss: 0.2558, 
2022-08-01 15:50:23 - train: epoch 0053, iter [02900, 05004], lr: 0.010000, loss: 2.1284, tea_CELoss: 0.8872, stu_CELoss: 0.9970, DMLLoss: 0.2442, 
2022-08-01 15:51:20 - train: epoch 0053, iter [03000, 05004], lr: 0.010000, loss: 2.2221, tea_CELoss: 0.9240, stu_CELoss: 1.0520, DMLLoss: 0.2461, 
2022-08-01 15:52:18 - train: epoch 0053, iter [03100, 05004], lr: 0.010000, loss: 2.4272, tea_CELoss: 1.0274, stu_CELoss: 1.1716, DMLLoss: 0.2282, 
2022-08-01 15:53:15 - train: epoch 0053, iter [03200, 05004], lr: 0.010000, loss: 2.3435, tea_CELoss: 0.9486, stu_CELoss: 1.1577, DMLLoss: 0.2373, 
2022-08-01 15:54:13 - train: epoch 0053, iter [03300, 05004], lr: 0.010000, loss: 2.4194, tea_CELoss: 1.0205, stu_CELoss: 1.1577, DMLLoss: 0.2412, 
2022-08-01 15:55:10 - train: epoch 0053, iter [03400, 05004], lr: 0.010000, loss: 2.6198, tea_CELoss: 1.1419, stu_CELoss: 1.2552, DMLLoss: 0.2228, 
2022-08-01 15:56:08 - train: epoch 0053, iter [03500, 05004], lr: 0.010000, loss: 2.3470, tea_CELoss: 0.9800, stu_CELoss: 1.1499, DMLLoss: 0.2172, 
2022-08-01 15:57:06 - train: epoch 0053, iter [03600, 05004], lr: 0.010000, loss: 2.5767, tea_CELoss: 1.0967, stu_CELoss: 1.2308, DMLLoss: 0.2493, 
2022-08-01 15:58:03 - train: epoch 0053, iter [03700, 05004], lr: 0.010000, loss: 2.5934, tea_CELoss: 1.0669, stu_CELoss: 1.2856, DMLLoss: 0.2409, 
2022-08-01 15:59:01 - train: epoch 0053, iter [03800, 05004], lr: 0.010000, loss: 2.2869, tea_CELoss: 0.9568, stu_CELoss: 1.1009, DMLLoss: 0.2292, 
2022-08-01 15:59:59 - train: epoch 0053, iter [03900, 05004], lr: 0.010000, loss: 2.5201, tea_CELoss: 1.0255, stu_CELoss: 1.2402, DMLLoss: 0.2544, 
2022-08-01 16:00:56 - train: epoch 0053, iter [04000, 05004], lr: 0.010000, loss: 2.9587, tea_CELoss: 1.2880, stu_CELoss: 1.4462, DMLLoss: 0.2245, 
2022-08-01 16:01:54 - train: epoch 0053, iter [04100, 05004], lr: 0.010000, loss: 2.7168, tea_CELoss: 1.1793, stu_CELoss: 1.3047, DMLLoss: 0.2328, 
2022-08-01 16:02:51 - train: epoch 0053, iter [04200, 05004], lr: 0.010000, loss: 2.5130, tea_CELoss: 1.0278, stu_CELoss: 1.2549, DMLLoss: 0.2303, 
2022-08-01 16:03:49 - train: epoch 0053, iter [04300, 05004], lr: 0.010000, loss: 2.9285, tea_CELoss: 1.2721, stu_CELoss: 1.4049, DMLLoss: 0.2515, 
2022-08-01 16:04:46 - train: epoch 0053, iter [04400, 05004], lr: 0.010000, loss: 2.5516, tea_CELoss: 1.1044, stu_CELoss: 1.2288, DMLLoss: 0.2185, 
2022-08-01 16:05:44 - train: epoch 0053, iter [04500, 05004], lr: 0.010000, loss: 2.5869, tea_CELoss: 1.1046, stu_CELoss: 1.2538, DMLLoss: 0.2285, 
2022-08-01 16:06:41 - train: epoch 0053, iter [04600, 05004], lr: 0.010000, loss: 2.5896, tea_CELoss: 1.0863, stu_CELoss: 1.2892, DMLLoss: 0.2141, 
2022-08-01 16:07:39 - train: epoch 0053, iter [04700, 05004], lr: 0.010000, loss: 2.0898, tea_CELoss: 0.8846, stu_CELoss: 0.9992, DMLLoss: 0.2059, 
2022-08-01 16:08:36 - train: epoch 0053, iter [04800, 05004], lr: 0.010000, loss: 2.7643, tea_CELoss: 1.2010, stu_CELoss: 1.3167, DMLLoss: 0.2465, 
2022-08-01 16:09:34 - train: epoch 0053, iter [04900, 05004], lr: 0.010000, loss: 2.3117, tea_CELoss: 1.0072, stu_CELoss: 1.0840, DMLLoss: 0.2205, 
2022-08-01 16:10:32 - train: epoch 0053, iter [05000, 05004], lr: 0.010000, loss: 2.1769, tea_CELoss: 0.9375, stu_CELoss: 1.0172, DMLLoss: 0.2223, 
2022-08-01 16:10:34 - train: epoch 053, train_loss: 2.3819
2022-08-01 16:13:08 - eval: epoch: 053, tea_acc1: 75.096%, tea_acc5: 92.670%, tea_test_loss: 0.9752, stu_acc1: 73.156%, stu_acc5: 91.574%, stu_test_loss: 1.0612
2022-08-01 16:13:09 - until epoch: 053, tea_best_acc1: 75.770%, stu_best_acc1: 73.634%
2022-08-01 16:13:09 - epoch 054 lr: 0.010000
2022-08-01 16:14:13 - train: epoch 0054, iter [00100, 05004], lr: 0.010000, loss: 2.1462, tea_CELoss: 0.8871, stu_CELoss: 1.0480, DMLLoss: 0.2111, 
2022-08-01 16:15:11 - train: epoch 0054, iter [00200, 05004], lr: 0.010000, loss: 2.4830, tea_CELoss: 1.0655, stu_CELoss: 1.1788, DMLLoss: 0.2388, 
2022-08-01 16:16:08 - train: epoch 0054, iter [00300, 05004], lr: 0.010000, loss: 2.5108, tea_CELoss: 1.0611, stu_CELoss: 1.2159, DMLLoss: 0.2338, 
2022-08-01 16:17:06 - train: epoch 0054, iter [00400, 05004], lr: 0.010000, loss: 2.1254, tea_CELoss: 0.9110, stu_CELoss: 0.9965, DMLLoss: 0.2179, 
2022-08-01 16:18:03 - train: epoch 0054, iter [00500, 05004], lr: 0.010000, loss: 2.1922, tea_CELoss: 0.9143, stu_CELoss: 1.0546, DMLLoss: 0.2233, 
2022-08-01 16:19:01 - train: epoch 0054, iter [00600, 05004], lr: 0.010000, loss: 2.2492, tea_CELoss: 0.9446, stu_CELoss: 1.0643, DMLLoss: 0.2403, 
2022-08-01 16:19:58 - train: epoch 0054, iter [00700, 05004], lr: 0.010000, loss: 2.7214, tea_CELoss: 1.1699, stu_CELoss: 1.3115, DMLLoss: 0.2399, 
2022-08-01 16:20:56 - train: epoch 0054, iter [00800, 05004], lr: 0.010000, loss: 2.3454, tea_CELoss: 0.9627, stu_CELoss: 1.1301, DMLLoss: 0.2525, 
2022-08-01 16:21:53 - train: epoch 0054, iter [00900, 05004], lr: 0.010000, loss: 1.9454, tea_CELoss: 0.8575, stu_CELoss: 0.9042, DMLLoss: 0.1837, 
2022-08-01 16:22:51 - train: epoch 0054, iter [01000, 05004], lr: 0.010000, loss: 2.1958, tea_CELoss: 0.9146, stu_CELoss: 1.0327, DMLLoss: 0.2485, 
2022-08-01 16:23:48 - train: epoch 0054, iter [01100, 05004], lr: 0.010000, loss: 2.1360, tea_CELoss: 0.8827, stu_CELoss: 1.0129, DMLLoss: 0.2404, 
2022-08-01 16:24:46 - train: epoch 0054, iter [01200, 05004], lr: 0.010000, loss: 2.2752, tea_CELoss: 0.8972, stu_CELoss: 1.1014, DMLLoss: 0.2766, 
2022-08-01 16:25:43 - train: epoch 0054, iter [01300, 05004], lr: 0.010000, loss: 2.2309, tea_CELoss: 0.9308, stu_CELoss: 1.0631, DMLLoss: 0.2370, 
2022-08-01 16:26:41 - train: epoch 0054, iter [01400, 05004], lr: 0.010000, loss: 2.7267, tea_CELoss: 1.1749, stu_CELoss: 1.3076, DMLLoss: 0.2442, 
2022-08-01 16:27:38 - train: epoch 0054, iter [01500, 05004], lr: 0.010000, loss: 2.2235, tea_CELoss: 0.9252, stu_CELoss: 1.0447, DMLLoss: 0.2536, 
2022-08-01 16:28:36 - train: epoch 0054, iter [01600, 05004], lr: 0.010000, loss: 1.9019, tea_CELoss: 0.7502, stu_CELoss: 0.9446, DMLLoss: 0.2071, 
2022-08-01 16:29:33 - train: epoch 0054, iter [01700, 05004], lr: 0.010000, loss: 2.3945, tea_CELoss: 1.0101, stu_CELoss: 1.1591, DMLLoss: 0.2253, 
2022-08-01 16:30:31 - train: epoch 0054, iter [01800, 05004], lr: 0.010000, loss: 1.8763, tea_CELoss: 0.7882, stu_CELoss: 0.8857, DMLLoss: 0.2024, 
2022-08-01 16:31:28 - train: epoch 0054, iter [01900, 05004], lr: 0.010000, loss: 2.2918, tea_CELoss: 0.9749, stu_CELoss: 1.0776, DMLLoss: 0.2394, 
2022-08-01 16:32:26 - train: epoch 0054, iter [02000, 05004], lr: 0.010000, loss: 2.5662, tea_CELoss: 1.0592, stu_CELoss: 1.2429, DMLLoss: 0.2640, 
2022-08-01 16:33:23 - train: epoch 0054, iter [02100, 05004], lr: 0.010000, loss: 1.9058, tea_CELoss: 0.8208, stu_CELoss: 0.8948, DMLLoss: 0.1902, 
2022-08-01 16:34:20 - train: epoch 0054, iter [02200, 05004], lr: 0.010000, loss: 2.1696, tea_CELoss: 0.8983, stu_CELoss: 1.0383, DMLLoss: 0.2330, 
2022-08-01 16:35:17 - train: epoch 0054, iter [02300, 05004], lr: 0.010000, loss: 2.0800, tea_CELoss: 0.8449, stu_CELoss: 0.9909, DMLLoss: 0.2443, 
2022-08-01 16:36:15 - train: epoch 0054, iter [02400, 05004], lr: 0.010000, loss: 2.1865, tea_CELoss: 0.9081, stu_CELoss: 1.0459, DMLLoss: 0.2324, 
2022-08-01 16:37:12 - train: epoch 0054, iter [02500, 05004], lr: 0.010000, loss: 2.6144, tea_CELoss: 1.0837, stu_CELoss: 1.2557, DMLLoss: 0.2750, 
2022-08-01 16:38:10 - train: epoch 0054, iter [02600, 05004], lr: 0.010000, loss: 2.0532, tea_CELoss: 0.8605, stu_CELoss: 0.9895, DMLLoss: 0.2032, 
2022-08-01 16:39:07 - train: epoch 0054, iter [02700, 05004], lr: 0.010000, loss: 2.0459, tea_CELoss: 0.8419, stu_CELoss: 0.9903, DMLLoss: 0.2137, 
2022-08-01 16:40:04 - train: epoch 0054, iter [02800, 05004], lr: 0.010000, loss: 2.8407, tea_CELoss: 1.2529, stu_CELoss: 1.3373, DMLLoss: 0.2504, 
2022-08-01 16:41:02 - train: epoch 0054, iter [02900, 05004], lr: 0.010000, loss: 2.3273, tea_CELoss: 0.9339, stu_CELoss: 1.1379, DMLLoss: 0.2555, 
2022-08-01 16:41:59 - train: epoch 0054, iter [03000, 05004], lr: 0.010000, loss: 2.5562, tea_CELoss: 1.0791, stu_CELoss: 1.2554, DMLLoss: 0.2216, 
2022-08-01 16:42:57 - train: epoch 0054, iter [03100, 05004], lr: 0.010000, loss: 2.4764, tea_CELoss: 1.0507, stu_CELoss: 1.2070, DMLLoss: 0.2186, 
2022-08-01 16:43:54 - train: epoch 0054, iter [03200, 05004], lr: 0.010000, loss: 2.9036, tea_CELoss: 1.2546, stu_CELoss: 1.4194, DMLLoss: 0.2297, 
2022-08-01 16:44:52 - train: epoch 0054, iter [03300, 05004], lr: 0.010000, loss: 2.7975, tea_CELoss: 1.2268, stu_CELoss: 1.3386, DMLLoss: 0.2320, 
2022-08-01 16:45:49 - train: epoch 0054, iter [03400, 05004], lr: 0.010000, loss: 2.3394, tea_CELoss: 1.0074, stu_CELoss: 1.0970, DMLLoss: 0.2351, 
2022-08-01 16:46:46 - train: epoch 0054, iter [03500, 05004], lr: 0.010000, loss: 2.4774, tea_CELoss: 1.0014, stu_CELoss: 1.2040, DMLLoss: 0.2720, 
2022-08-01 16:47:44 - train: epoch 0054, iter [03600, 05004], lr: 0.010000, loss: 2.3036, tea_CELoss: 0.9420, stu_CELoss: 1.1282, DMLLoss: 0.2334, 
2022-08-01 16:48:41 - train: epoch 0054, iter [03700, 05004], lr: 0.010000, loss: 2.3961, tea_CELoss: 1.0298, stu_CELoss: 1.1414, DMLLoss: 0.2250, 
2022-08-01 16:49:39 - train: epoch 0054, iter [03800, 05004], lr: 0.010000, loss: 2.2062, tea_CELoss: 0.9448, stu_CELoss: 1.0252, DMLLoss: 0.2362, 
2022-08-01 16:50:36 - train: epoch 0054, iter [03900, 05004], lr: 0.010000, loss: 2.5915, tea_CELoss: 1.1041, stu_CELoss: 1.2449, DMLLoss: 0.2424, 
2022-08-01 16:51:33 - train: epoch 0054, iter [04000, 05004], lr: 0.010000, loss: 2.1219, tea_CELoss: 0.8983, stu_CELoss: 1.0139, DMLLoss: 0.2098, 
2022-08-01 16:52:31 - train: epoch 0054, iter [04100, 05004], lr: 0.010000, loss: 2.7170, tea_CELoss: 1.0965, stu_CELoss: 1.3338, DMLLoss: 0.2867, 
2022-08-01 16:53:28 - train: epoch 0054, iter [04200, 05004], lr: 0.010000, loss: 2.2400, tea_CELoss: 0.9272, stu_CELoss: 1.0644, DMLLoss: 0.2483, 
2022-08-01 16:54:26 - train: epoch 0054, iter [04300, 05004], lr: 0.010000, loss: 2.6150, tea_CELoss: 1.1171, stu_CELoss: 1.2736, DMLLoss: 0.2243, 
2022-08-01 16:55:23 - train: epoch 0054, iter [04400, 05004], lr: 0.010000, loss: 2.1840, tea_CELoss: 0.9159, stu_CELoss: 1.0651, DMLLoss: 0.2030, 
2022-08-01 16:56:20 - train: epoch 0054, iter [04500, 05004], lr: 0.010000, loss: 2.2154, tea_CELoss: 0.9050, stu_CELoss: 1.0554, DMLLoss: 0.2551, 
2022-08-01 16:57:18 - train: epoch 0054, iter [04600, 05004], lr: 0.010000, loss: 2.5199, tea_CELoss: 1.0302, stu_CELoss: 1.2115, DMLLoss: 0.2782, 
2022-08-01 16:58:15 - train: epoch 0054, iter [04700, 05004], lr: 0.010000, loss: 2.7977, tea_CELoss: 1.1619, stu_CELoss: 1.3926, DMLLoss: 0.2432, 
2022-08-01 16:59:13 - train: epoch 0054, iter [04800, 05004], lr: 0.010000, loss: 2.4585, tea_CELoss: 1.0686, stu_CELoss: 1.1821, DMLLoss: 0.2078, 
2022-08-01 17:00:10 - train: epoch 0054, iter [04900, 05004], lr: 0.010000, loss: 2.3271, tea_CELoss: 0.9498, stu_CELoss: 1.1337, DMLLoss: 0.2435, 
2022-08-01 17:01:07 - train: epoch 0054, iter [05000, 05004], lr: 0.010000, loss: 2.1722, tea_CELoss: 0.8965, stu_CELoss: 1.0499, DMLLoss: 0.2258, 
2022-08-01 17:01:10 - train: epoch 054, train_loss: 2.3788
2022-08-01 17:03:44 - eval: epoch: 054, tea_acc1: 74.838%, tea_acc5: 92.594%, tea_test_loss: 0.9801, stu_acc1: 72.636%, stu_acc5: 91.392%, stu_test_loss: 1.0828
2022-08-01 17:03:45 - until epoch: 054, tea_best_acc1: 75.770%, stu_best_acc1: 73.634%
2022-08-01 17:03:45 - epoch 055 lr: 0.010000
2022-08-01 17:04:49 - train: epoch 0055, iter [00100, 05004], lr: 0.010000, loss: 2.3963, tea_CELoss: 1.0125, stu_CELoss: 1.1831, DMLLoss: 0.2007, 
2022-08-01 17:05:47 - train: epoch 0055, iter [00200, 05004], lr: 0.010000, loss: 2.1742, tea_CELoss: 0.8510, stu_CELoss: 1.0649, DMLLoss: 0.2583, 
2022-08-01 17:06:45 - train: epoch 0055, iter [00300, 05004], lr: 0.010000, loss: 2.0273, tea_CELoss: 0.8096, stu_CELoss: 0.9315, DMLLoss: 0.2861, 
2022-08-01 17:07:42 - train: epoch 0055, iter [00400, 05004], lr: 0.010000, loss: 1.8744, tea_CELoss: 0.8079, stu_CELoss: 0.8600, DMLLoss: 0.2065, 
2022-08-01 17:08:40 - train: epoch 0055, iter [00500, 05004], lr: 0.010000, loss: 2.1048, tea_CELoss: 0.8579, stu_CELoss: 1.0042, DMLLoss: 0.2427, 
2022-08-01 17:09:38 - train: epoch 0055, iter [00600, 05004], lr: 0.010000, loss: 2.3837, tea_CELoss: 0.9895, stu_CELoss: 1.1443, DMLLoss: 0.2499, 
2022-08-01 17:10:35 - train: epoch 0055, iter [00700, 05004], lr: 0.010000, loss: 2.3154, tea_CELoss: 0.9702, stu_CELoss: 1.1107, DMLLoss: 0.2345, 
2022-08-01 17:11:33 - train: epoch 0055, iter [00800, 05004], lr: 0.010000, loss: 1.9670, tea_CELoss: 0.8276, stu_CELoss: 0.9159, DMLLoss: 0.2236, 
2022-08-01 17:12:31 - train: epoch 0055, iter [00900, 05004], lr: 0.010000, loss: 2.5663, tea_CELoss: 1.0754, stu_CELoss: 1.2406, DMLLoss: 0.2503, 
2022-08-01 17:13:29 - train: epoch 0055, iter [01000, 05004], lr: 0.010000, loss: 2.5685, tea_CELoss: 1.0907, stu_CELoss: 1.2449, DMLLoss: 0.2329, 
2022-08-01 17:14:26 - train: epoch 0055, iter [01100, 05004], lr: 0.010000, loss: 2.2984, tea_CELoss: 0.9770, stu_CELoss: 1.0870, DMLLoss: 0.2343, 
2022-08-01 17:15:24 - train: epoch 0055, iter [01200, 05004], lr: 0.010000, loss: 2.1092, tea_CELoss: 0.8634, stu_CELoss: 1.0154, DMLLoss: 0.2304, 
2022-08-01 17:16:22 - train: epoch 0055, iter [01300, 05004], lr: 0.010000, loss: 2.6059, tea_CELoss: 1.1285, stu_CELoss: 1.2627, DMLLoss: 0.2147, 
2022-08-01 17:17:20 - train: epoch 0055, iter [01400, 05004], lr: 0.010000, loss: 2.3177, tea_CELoss: 0.9455, stu_CELoss: 1.1282, DMLLoss: 0.2439, 
2022-08-01 17:18:17 - train: epoch 0055, iter [01500, 05004], lr: 0.010000, loss: 2.1974, tea_CELoss: 0.9693, stu_CELoss: 1.0258, DMLLoss: 0.2023, 
2022-08-01 17:19:15 - train: epoch 0055, iter [01600, 05004], lr: 0.010000, loss: 2.5454, tea_CELoss: 1.0799, stu_CELoss: 1.2484, DMLLoss: 0.2171, 
2022-08-01 17:20:13 - train: epoch 0055, iter [01700, 05004], lr: 0.010000, loss: 2.4322, tea_CELoss: 1.0298, stu_CELoss: 1.1666, DMLLoss: 0.2358, 
2022-08-01 17:21:11 - train: epoch 0055, iter [01800, 05004], lr: 0.010000, loss: 2.2151, tea_CELoss: 0.8749, stu_CELoss: 1.0963, DMLLoss: 0.2440, 
2022-08-01 17:22:08 - train: epoch 0055, iter [01900, 05004], lr: 0.010000, loss: 2.5570, tea_CELoss: 1.0291, stu_CELoss: 1.2484, DMLLoss: 0.2795, 
2022-08-01 17:23:06 - train: epoch 0055, iter [02000, 05004], lr: 0.010000, loss: 2.1640, tea_CELoss: 0.8681, stu_CELoss: 1.0702, DMLLoss: 0.2257, 
2022-08-01 17:24:04 - train: epoch 0055, iter [02100, 05004], lr: 0.010000, loss: 1.9691, tea_CELoss: 0.8065, stu_CELoss: 0.9668, DMLLoss: 0.1958, 
2022-08-01 17:25:01 - train: epoch 0055, iter [02200, 05004], lr: 0.010000, loss: 2.9052, tea_CELoss: 1.2725, stu_CELoss: 1.3921, DMLLoss: 0.2406, 
2022-08-01 17:25:59 - train: epoch 0055, iter [02300, 05004], lr: 0.010000, loss: 2.2916, tea_CELoss: 0.9583, stu_CELoss: 1.0767, DMLLoss: 0.2566, 
2022-08-01 17:26:56 - train: epoch 0055, iter [02400, 05004], lr: 0.010000, loss: 1.9851, tea_CELoss: 0.8390, stu_CELoss: 0.9514, DMLLoss: 0.1947, 
2022-08-01 17:27:54 - train: epoch 0055, iter [02500, 05004], lr: 0.010000, loss: 2.0765, tea_CELoss: 0.8665, stu_CELoss: 0.9832, DMLLoss: 0.2267, 
2022-08-01 17:28:51 - train: epoch 0055, iter [02600, 05004], lr: 0.010000, loss: 2.0636, tea_CELoss: 0.8572, stu_CELoss: 0.9861, DMLLoss: 0.2203, 
2022-08-01 17:29:49 - train: epoch 0055, iter [02700, 05004], lr: 0.010000, loss: 2.1661, tea_CELoss: 0.9141, stu_CELoss: 1.0000, DMLLoss: 0.2520, 
2022-08-01 17:30:47 - train: epoch 0055, iter [02800, 05004], lr: 0.010000, loss: 2.8432, tea_CELoss: 1.2164, stu_CELoss: 1.3755, DMLLoss: 0.2513, 
2022-08-01 17:31:44 - train: epoch 0055, iter [02900, 05004], lr: 0.010000, loss: 2.2893, tea_CELoss: 0.9903, stu_CELoss: 1.0751, DMLLoss: 0.2239, 
2022-08-01 17:32:42 - train: epoch 0055, iter [03000, 05004], lr: 0.010000, loss: 2.2487, tea_CELoss: 0.9559, stu_CELoss: 1.0538, DMLLoss: 0.2390, 
2022-08-01 17:33:39 - train: epoch 0055, iter [03100, 05004], lr: 0.010000, loss: 2.4088, tea_CELoss: 1.0258, stu_CELoss: 1.1497, DMLLoss: 0.2333, 
2022-08-01 17:34:37 - train: epoch 0055, iter [03200, 05004], lr: 0.010000, loss: 2.3308, tea_CELoss: 0.9888, stu_CELoss: 1.1144, DMLLoss: 0.2276, 
2022-08-01 17:35:34 - train: epoch 0055, iter [03300, 05004], lr: 0.010000, loss: 2.1102, tea_CELoss: 0.8625, stu_CELoss: 1.0219, DMLLoss: 0.2258, 
2022-08-01 17:36:32 - train: epoch 0055, iter [03400, 05004], lr: 0.010000, loss: 2.3314, tea_CELoss: 0.9900, stu_CELoss: 1.1000, DMLLoss: 0.2415, 
2022-08-01 17:37:29 - train: epoch 0055, iter [03500, 05004], lr: 0.010000, loss: 1.9981, tea_CELoss: 0.8164, stu_CELoss: 0.9846, DMLLoss: 0.1971, 
2022-08-01 17:38:27 - train: epoch 0055, iter [03600, 05004], lr: 0.010000, loss: 2.4924, tea_CELoss: 1.0696, stu_CELoss: 1.1876, DMLLoss: 0.2352, 
2022-08-01 17:39:24 - train: epoch 0055, iter [03700, 05004], lr: 0.010000, loss: 1.8618, tea_CELoss: 0.7991, stu_CELoss: 0.8479, DMLLoss: 0.2148, 
2022-08-01 17:40:22 - train: epoch 0055, iter [03800, 05004], lr: 0.010000, loss: 2.7045, tea_CELoss: 1.1917, stu_CELoss: 1.2580, DMLLoss: 0.2548, 
2022-08-01 17:41:19 - train: epoch 0055, iter [03900, 05004], lr: 0.010000, loss: 2.8565, tea_CELoss: 1.2028, stu_CELoss: 1.3888, DMLLoss: 0.2649, 
2022-08-01 17:42:17 - train: epoch 0055, iter [04000, 05004], lr: 0.010000, loss: 2.5442, tea_CELoss: 1.0850, stu_CELoss: 1.2283, DMLLoss: 0.2310, 
2022-08-01 17:43:14 - train: epoch 0055, iter [04100, 05004], lr: 0.010000, loss: 2.0829, tea_CELoss: 0.8994, stu_CELoss: 0.9828, DMLLoss: 0.2007, 
2022-08-01 17:44:12 - train: epoch 0055, iter [04200, 05004], lr: 0.010000, loss: 2.4153, tea_CELoss: 1.0015, stu_CELoss: 1.1546, DMLLoss: 0.2592, 
2022-08-01 17:45:10 - train: epoch 0055, iter [04300, 05004], lr: 0.010000, loss: 2.3805, tea_CELoss: 0.9882, stu_CELoss: 1.1546, DMLLoss: 0.2377, 
2022-08-01 17:46:08 - train: epoch 0055, iter [04400, 05004], lr: 0.010000, loss: 2.5056, tea_CELoss: 1.0780, stu_CELoss: 1.2158, DMLLoss: 0.2118, 
2022-08-01 17:47:06 - train: epoch 0055, iter [04500, 05004], lr: 0.010000, loss: 2.5460, tea_CELoss: 1.0769, stu_CELoss: 1.2048, DMLLoss: 0.2644, 
2022-08-01 17:48:04 - train: epoch 0055, iter [04600, 05004], lr: 0.010000, loss: 2.5447, tea_CELoss: 1.0619, stu_CELoss: 1.2548, DMLLoss: 0.2280, 
2022-08-01 17:49:02 - train: epoch 0055, iter [04700, 05004], lr: 0.010000, loss: 2.2784, tea_CELoss: 0.9715, stu_CELoss: 1.0801, DMLLoss: 0.2268, 
2022-08-01 17:50:00 - train: epoch 0055, iter [04800, 05004], lr: 0.010000, loss: 2.2887, tea_CELoss: 0.9744, stu_CELoss: 1.0739, DMLLoss: 0.2403, 
2022-08-01 17:50:58 - train: epoch 0055, iter [04900, 05004], lr: 0.010000, loss: 2.5055, tea_CELoss: 1.0287, stu_CELoss: 1.2229, DMLLoss: 0.2539, 
2022-08-01 17:51:55 - train: epoch 0055, iter [05000, 05004], lr: 0.010000, loss: 2.5973, tea_CELoss: 1.1021, stu_CELoss: 1.2234, DMLLoss: 0.2718, 
2022-08-01 17:51:58 - train: epoch 055, train_loss: 2.3778
2022-08-01 17:54:35 - eval: epoch: 055, tea_acc1: 75.360%, tea_acc5: 92.636%, tea_test_loss: 0.9626, stu_acc1: 73.266%, stu_acc5: 91.526%, stu_test_loss: 1.0651
2022-08-01 17:54:36 - until epoch: 055, tea_best_acc1: 75.770%, stu_best_acc1: 73.634%
2022-08-01 17:54:36 - epoch 056 lr: 0.010000
2022-08-01 17:55:40 - train: epoch 0056, iter [00100, 05004], lr: 0.010000, loss: 2.8762, tea_CELoss: 1.2472, stu_CELoss: 1.3626, DMLLoss: 0.2665, 
2022-08-01 17:56:37 - train: epoch 0056, iter [00200, 05004], lr: 0.010000, loss: 1.9369, tea_CELoss: 0.7936, stu_CELoss: 0.9287, DMLLoss: 0.2146, 
2022-08-01 17:57:34 - train: epoch 0056, iter [00300, 05004], lr: 0.010000, loss: 2.0312, tea_CELoss: 0.8244, stu_CELoss: 0.9831, DMLLoss: 0.2237, 
2022-08-01 17:58:31 - train: epoch 0056, iter [00400, 05004], lr: 0.010000, loss: 2.4767, tea_CELoss: 1.0054, stu_CELoss: 1.1865, DMLLoss: 0.2848, 
2022-08-01 17:59:29 - train: epoch 0056, iter [00500, 05004], lr: 0.010000, loss: 2.6078, tea_CELoss: 1.1464, stu_CELoss: 1.2130, DMLLoss: 0.2484, 
2022-08-01 18:00:25 - train: epoch 0056, iter [00600, 05004], lr: 0.010000, loss: 2.2933, tea_CELoss: 0.9909, stu_CELoss: 1.0980, DMLLoss: 0.2044, 
2022-08-01 18:01:22 - train: epoch 0056, iter [00700, 05004], lr: 0.010000, loss: 2.7516, tea_CELoss: 1.1688, stu_CELoss: 1.3218, DMLLoss: 0.2609, 
2022-08-01 18:02:19 - train: epoch 0056, iter [00800, 05004], lr: 0.010000, loss: 2.3933, tea_CELoss: 1.0040, stu_CELoss: 1.1422, DMLLoss: 0.2471, 
2022-08-01 18:03:17 - train: epoch 0056, iter [00900, 05004], lr: 0.010000, loss: 2.3113, tea_CELoss: 0.9558, stu_CELoss: 1.1188, DMLLoss: 0.2367, 
2022-08-01 18:04:14 - train: epoch 0056, iter [01000, 05004], lr: 0.010000, loss: 2.3580, tea_CELoss: 0.9958, stu_CELoss: 1.1303, DMLLoss: 0.2320, 
2022-08-01 18:05:11 - train: epoch 0056, iter [01100, 05004], lr: 0.010000, loss: 2.1820, tea_CELoss: 0.8784, stu_CELoss: 1.0697, DMLLoss: 0.2339, 
2022-08-01 18:06:08 - train: epoch 0056, iter [01200, 05004], lr: 0.010000, loss: 2.3585, tea_CELoss: 0.9768, stu_CELoss: 1.1103, DMLLoss: 0.2713, 
2022-08-01 18:07:05 - train: epoch 0056, iter [01300, 05004], lr: 0.010000, loss: 2.7388, tea_CELoss: 1.1603, stu_CELoss: 1.3160, DMLLoss: 0.2626, 
2022-08-01 18:08:02 - train: epoch 0056, iter [01400, 05004], lr: 0.010000, loss: 2.2891, tea_CELoss: 0.9805, stu_CELoss: 1.0825, DMLLoss: 0.2261, 
2022-08-01 18:08:59 - train: epoch 0056, iter [01500, 05004], lr: 0.010000, loss: 2.7029, tea_CELoss: 1.1385, stu_CELoss: 1.2977, DMLLoss: 0.2667, 
2022-08-01 18:09:56 - train: epoch 0056, iter [01600, 05004], lr: 0.010000, loss: 2.3624, tea_CELoss: 0.9866, stu_CELoss: 1.1560, DMLLoss: 0.2198, 
2022-08-01 18:10:54 - train: epoch 0056, iter [01700, 05004], lr: 0.010000, loss: 2.4239, tea_CELoss: 1.0459, stu_CELoss: 1.1642, DMLLoss: 0.2138, 
2022-08-01 18:11:51 - train: epoch 0056, iter [01800, 05004], lr: 0.010000, loss: 2.1792, tea_CELoss: 0.8668, stu_CELoss: 1.0466, DMLLoss: 0.2658, 
2022-08-01 18:12:48 - train: epoch 0056, iter [01900, 05004], lr: 0.010000, loss: 2.3614, tea_CELoss: 1.0247, stu_CELoss: 1.1121, DMLLoss: 0.2245, 
2022-08-01 18:13:45 - train: epoch 0056, iter [02000, 05004], lr: 0.010000, loss: 2.2293, tea_CELoss: 0.9540, stu_CELoss: 1.0386, DMLLoss: 0.2368, 
2022-08-01 18:14:42 - train: epoch 0056, iter [02100, 05004], lr: 0.010000, loss: 2.2932, tea_CELoss: 0.9387, stu_CELoss: 1.1058, DMLLoss: 0.2487, 
2022-08-01 18:15:39 - train: epoch 0056, iter [02200, 05004], lr: 0.010000, loss: 2.5313, tea_CELoss: 1.1034, stu_CELoss: 1.2063, DMLLoss: 0.2216, 
2022-08-01 18:16:36 - train: epoch 0056, iter [02300, 05004], lr: 0.010000, loss: 2.6800, tea_CELoss: 1.1828, stu_CELoss: 1.2570, DMLLoss: 0.2402, 
2022-08-01 18:17:33 - train: epoch 0056, iter [02400, 05004], lr: 0.010000, loss: 2.3014, tea_CELoss: 0.9617, stu_CELoss: 1.1197, DMLLoss: 0.2201, 
2022-08-01 18:18:30 - train: epoch 0056, iter [02500, 05004], lr: 0.010000, loss: 3.0865, tea_CELoss: 1.3459, stu_CELoss: 1.4702, DMLLoss: 0.2704, 
2022-08-01 18:19:27 - train: epoch 0056, iter [02600, 05004], lr: 0.010000, loss: 2.2057, tea_CELoss: 0.8800, stu_CELoss: 1.0944, DMLLoss: 0.2313, 
2022-08-01 18:20:24 - train: epoch 0056, iter [02700, 05004], lr: 0.010000, loss: 2.2010, tea_CELoss: 0.9132, stu_CELoss: 1.0613, DMLLoss: 0.2265, 
2022-08-01 18:21:22 - train: epoch 0056, iter [02800, 05004], lr: 0.010000, loss: 2.3120, tea_CELoss: 0.9680, stu_CELoss: 1.1309, DMLLoss: 0.2131, 
2022-08-01 18:22:19 - train: epoch 0056, iter [02900, 05004], lr: 0.010000, loss: 2.7283, tea_CELoss: 1.1635, stu_CELoss: 1.3281, DMLLoss: 0.2366, 
2022-08-01 18:23:16 - train: epoch 0056, iter [03000, 05004], lr: 0.010000, loss: 2.5027, tea_CELoss: 1.0107, stu_CELoss: 1.1912, DMLLoss: 0.3008, 
2022-08-01 18:24:13 - train: epoch 0056, iter [03100, 05004], lr: 0.010000, loss: 2.4228, tea_CELoss: 1.0029, stu_CELoss: 1.1606, DMLLoss: 0.2593, 
2022-08-01 18:25:10 - train: epoch 0056, iter [03200, 05004], lr: 0.010000, loss: 2.4103, tea_CELoss: 1.0090, stu_CELoss: 1.1811, DMLLoss: 0.2203, 
2022-08-01 18:26:07 - train: epoch 0056, iter [03300, 05004], lr: 0.010000, loss: 2.4080, tea_CELoss: 1.0297, stu_CELoss: 1.1137, DMLLoss: 0.2645, 
2022-08-01 18:27:04 - train: epoch 0056, iter [03400, 05004], lr: 0.010000, loss: 2.1256, tea_CELoss: 0.8848, stu_CELoss: 1.0043, DMLLoss: 0.2366, 
2022-08-01 18:28:01 - train: epoch 0056, iter [03500, 05004], lr: 0.010000, loss: 2.4466, tea_CELoss: 1.0265, stu_CELoss: 1.2014, DMLLoss: 0.2187, 
2022-08-01 18:28:58 - train: epoch 0056, iter [03600, 05004], lr: 0.010000, loss: 2.3589, tea_CELoss: 0.9904, stu_CELoss: 1.1223, DMLLoss: 0.2462, 
2022-08-01 18:29:55 - train: epoch 0056, iter [03700, 05004], lr: 0.010000, loss: 2.7258, tea_CELoss: 1.1592, stu_CELoss: 1.3360, DMLLoss: 0.2306, 
2022-08-01 18:30:51 - train: epoch 0056, iter [03800, 05004], lr: 0.010000, loss: 2.2545, tea_CELoss: 0.8999, stu_CELoss: 1.0954, DMLLoss: 0.2592, 
2022-08-01 18:31:49 - train: epoch 0056, iter [03900, 05004], lr: 0.010000, loss: 2.6265, tea_CELoss: 1.0997, stu_CELoss: 1.2705, DMLLoss: 0.2563, 
2022-08-01 18:32:46 - train: epoch 0056, iter [04000, 05004], lr: 0.010000, loss: 2.3427, tea_CELoss: 1.0310, stu_CELoss: 1.1117, DMLLoss: 0.2000, 
2022-08-01 18:33:43 - train: epoch 0056, iter [04100, 05004], lr: 0.010000, loss: 2.3594, tea_CELoss: 0.9804, stu_CELoss: 1.1235, DMLLoss: 0.2555, 
2022-08-01 18:34:40 - train: epoch 0056, iter [04200, 05004], lr: 0.010000, loss: 2.3759, tea_CELoss: 1.0247, stu_CELoss: 1.1440, DMLLoss: 0.2072, 
2022-08-01 18:35:36 - train: epoch 0056, iter [04300, 05004], lr: 0.010000, loss: 2.6524, tea_CELoss: 1.1679, stu_CELoss: 1.2523, DMLLoss: 0.2322, 
2022-08-01 18:36:33 - train: epoch 0056, iter [04400, 05004], lr: 0.010000, loss: 2.2406, tea_CELoss: 0.9405, stu_CELoss: 1.0569, DMLLoss: 0.2431, 
2022-08-01 18:37:31 - train: epoch 0056, iter [04500, 05004], lr: 0.010000, loss: 2.4230, tea_CELoss: 1.0701, stu_CELoss: 1.1351, DMLLoss: 0.2178, 
2022-08-01 18:38:28 - train: epoch 0056, iter [04600, 05004], lr: 0.010000, loss: 2.5912, tea_CELoss: 1.1151, stu_CELoss: 1.2476, DMLLoss: 0.2285, 
2022-08-01 18:39:24 - train: epoch 0056, iter [04700, 05004], lr: 0.010000, loss: 2.2168, tea_CELoss: 0.9075, stu_CELoss: 1.0809, DMLLoss: 0.2284, 
2022-08-01 18:40:22 - train: epoch 0056, iter [04800, 05004], lr: 0.010000, loss: 2.3137, tea_CELoss: 0.9729, stu_CELoss: 1.1119, DMLLoss: 0.2290, 
2022-08-01 18:41:18 - train: epoch 0056, iter [04900, 05004], lr: 0.010000, loss: 2.4389, tea_CELoss: 0.9879, stu_CELoss: 1.1771, DMLLoss: 0.2740, 
2022-08-01 18:42:15 - train: epoch 0056, iter [05000, 05004], lr: 0.010000, loss: 2.4611, tea_CELoss: 1.0695, stu_CELoss: 1.1824, DMLLoss: 0.2092, 
2022-08-01 18:42:18 - train: epoch 056, train_loss: 2.3698
2022-08-01 18:44:53 - eval: epoch: 056, tea_acc1: 75.256%, tea_acc5: 92.750%, tea_test_loss: 0.9680, stu_acc1: 73.224%, stu_acc5: 91.522%, stu_test_loss: 1.0640
2022-08-01 18:44:54 - until epoch: 056, tea_best_acc1: 75.770%, stu_best_acc1: 73.634%
2022-08-01 18:44:54 - epoch 057 lr: 0.010000
2022-08-01 18:45:59 - train: epoch 0057, iter [00100, 05004], lr: 0.010000, loss: 2.3361, tea_CELoss: 1.0027, stu_CELoss: 1.1238, DMLLoss: 0.2097, 
2022-08-01 18:46:56 - train: epoch 0057, iter [00200, 05004], lr: 0.010000, loss: 2.0863, tea_CELoss: 0.8548, stu_CELoss: 1.0147, DMLLoss: 0.2168, 
2022-08-01 18:47:54 - train: epoch 0057, iter [00300, 05004], lr: 0.010000, loss: 2.3117, tea_CELoss: 0.9778, stu_CELoss: 1.0994, DMLLoss: 0.2344, 
2022-08-01 18:48:52 - train: epoch 0057, iter [00400, 05004], lr: 0.010000, loss: 2.1524, tea_CELoss: 0.8810, stu_CELoss: 1.0520, DMLLoss: 0.2195, 
2022-08-01 18:49:49 - train: epoch 0057, iter [00500, 05004], lr: 0.010000, loss: 2.1646, tea_CELoss: 0.9033, stu_CELoss: 1.0180, DMLLoss: 0.2433, 
2022-08-01 18:50:47 - train: epoch 0057, iter [00600, 05004], lr: 0.010000, loss: 2.4983, tea_CELoss: 1.0266, stu_CELoss: 1.2403, DMLLoss: 0.2314, 
2022-08-01 18:51:45 - train: epoch 0057, iter [00700, 05004], lr: 0.010000, loss: 1.8042, tea_CELoss: 0.7677, stu_CELoss: 0.8211, DMLLoss: 0.2153, 
2022-08-01 18:52:42 - train: epoch 0057, iter [00800, 05004], lr: 0.010000, loss: 2.6363, tea_CELoss: 1.0968, stu_CELoss: 1.2925, DMLLoss: 0.2470, 
2022-08-01 18:53:40 - train: epoch 0057, iter [00900, 05004], lr: 0.010000, loss: 2.3565, tea_CELoss: 0.9517, stu_CELoss: 1.1444, DMLLoss: 0.2604, 
2022-08-01 18:54:37 - train: epoch 0057, iter [01000, 05004], lr: 0.010000, loss: 2.1094, tea_CELoss: 0.8711, stu_CELoss: 1.0146, DMLLoss: 0.2237, 
2022-08-01 18:55:35 - train: epoch 0057, iter [01100, 05004], lr: 0.010000, loss: 1.9968, tea_CELoss: 0.8044, stu_CELoss: 0.9679, DMLLoss: 0.2245, 
2022-08-01 18:56:32 - train: epoch 0057, iter [01200, 05004], lr: 0.010000, loss: 2.1175, tea_CELoss: 0.8659, stu_CELoss: 1.0039, DMLLoss: 0.2476, 
2022-08-01 18:57:29 - train: epoch 0057, iter [01300, 05004], lr: 0.010000, loss: 2.4773, tea_CELoss: 1.0760, stu_CELoss: 1.1810, DMLLoss: 0.2203, 
2022-08-01 18:58:26 - train: epoch 0057, iter [01400, 05004], lr: 0.010000, loss: 2.1171, tea_CELoss: 0.8276, stu_CELoss: 1.0160, DMLLoss: 0.2735, 
2022-08-01 18:59:24 - train: epoch 0057, iter [01500, 05004], lr: 0.010000, loss: 2.5454, tea_CELoss: 1.0644, stu_CELoss: 1.2018, DMLLoss: 0.2791, 
2022-08-01 19:00:21 - train: epoch 0057, iter [01600, 05004], lr: 0.010000, loss: 2.6617, tea_CELoss: 1.1234, stu_CELoss: 1.2830, DMLLoss: 0.2553, 
2022-08-01 19:01:18 - train: epoch 0057, iter [01700, 05004], lr: 0.010000, loss: 2.4683, tea_CELoss: 1.0246, stu_CELoss: 1.1934, DMLLoss: 0.2504, 
2022-08-01 19:02:16 - train: epoch 0057, iter [01800, 05004], lr: 0.010000, loss: 2.2418, tea_CELoss: 0.9231, stu_CELoss: 1.0775, DMLLoss: 0.2411, 
2022-08-01 19:03:13 - train: epoch 0057, iter [01900, 05004], lr: 0.010000, loss: 2.0892, tea_CELoss: 0.8812, stu_CELoss: 1.0041, DMLLoss: 0.2040, 
2022-08-01 19:04:10 - train: epoch 0057, iter [02000, 05004], lr: 0.010000, loss: 2.2358, tea_CELoss: 0.9346, stu_CELoss: 1.0976, DMLLoss: 0.2036, 
2022-08-01 19:05:08 - train: epoch 0057, iter [02100, 05004], lr: 0.010000, loss: 2.1871, tea_CELoss: 0.8890, stu_CELoss: 1.0528, DMLLoss: 0.2453, 
2022-08-01 19:06:05 - train: epoch 0057, iter [02200, 05004], lr: 0.010000, loss: 2.1805, tea_CELoss: 0.9234, stu_CELoss: 1.0102, DMLLoss: 0.2469, 
2022-08-01 19:07:02 - train: epoch 0057, iter [02300, 05004], lr: 0.010000, loss: 2.6348, tea_CELoss: 1.1334, stu_CELoss: 1.2498, DMLLoss: 0.2515, 
2022-08-01 19:08:00 - train: epoch 0057, iter [02400, 05004], lr: 0.010000, loss: 2.5095, tea_CELoss: 1.0623, stu_CELoss: 1.2096, DMLLoss: 0.2375, 
2022-08-01 19:08:57 - train: epoch 0057, iter [02500, 05004], lr: 0.010000, loss: 2.4869, tea_CELoss: 1.0632, stu_CELoss: 1.1645, DMLLoss: 0.2593, 
2022-08-01 19:09:54 - train: epoch 0057, iter [02600, 05004], lr: 0.010000, loss: 2.2709, tea_CELoss: 0.9794, stu_CELoss: 1.0708, DMLLoss: 0.2207, 
2022-08-01 19:10:51 - train: epoch 0057, iter [02700, 05004], lr: 0.010000, loss: 2.3219, tea_CELoss: 0.9594, stu_CELoss: 1.1158, DMLLoss: 0.2467, 
2022-08-01 19:11:48 - train: epoch 0057, iter [02800, 05004], lr: 0.010000, loss: 2.0026, tea_CELoss: 0.8310, stu_CELoss: 0.9489, DMLLoss: 0.2226, 
2022-08-01 19:12:46 - train: epoch 0057, iter [02900, 05004], lr: 0.010000, loss: 2.4263, tea_CELoss: 0.9939, stu_CELoss: 1.1792, DMLLoss: 0.2532, 
2022-08-01 19:13:43 - train: epoch 0057, iter [03000, 05004], lr: 0.010000, loss: 2.6114, tea_CELoss: 1.1023, stu_CELoss: 1.2628, DMLLoss: 0.2463, 
2022-08-01 19:14:40 - train: epoch 0057, iter [03100, 05004], lr: 0.010000, loss: 2.5610, tea_CELoss: 1.0623, stu_CELoss: 1.2337, DMLLoss: 0.2649, 
2022-08-01 19:15:37 - train: epoch 0057, iter [03200, 05004], lr: 0.010000, loss: 2.6662, tea_CELoss: 1.1113, stu_CELoss: 1.3239, DMLLoss: 0.2310, 
2022-08-01 19:16:35 - train: epoch 0057, iter [03300, 05004], lr: 0.010000, loss: 2.4251, tea_CELoss: 1.0002, stu_CELoss: 1.1821, DMLLoss: 0.2428, 
2022-08-01 19:17:32 - train: epoch 0057, iter [03400, 05004], lr: 0.010000, loss: 2.5976, tea_CELoss: 1.1113, stu_CELoss: 1.2413, DMLLoss: 0.2449, 
2022-08-01 19:18:30 - train: epoch 0057, iter [03500, 05004], lr: 0.010000, loss: 2.5849, tea_CELoss: 1.1043, stu_CELoss: 1.2420, DMLLoss: 0.2386, 
2022-08-01 19:19:27 - train: epoch 0057, iter [03600, 05004], lr: 0.010000, loss: 2.3282, tea_CELoss: 0.9524, stu_CELoss: 1.1314, DMLLoss: 0.2445, 
2022-08-01 19:20:24 - train: epoch 0057, iter [03700, 05004], lr: 0.010000, loss: 2.7798, tea_CELoss: 1.2140, stu_CELoss: 1.3419, DMLLoss: 0.2239, 
2022-08-01 19:21:22 - train: epoch 0057, iter [03800, 05004], lr: 0.010000, loss: 2.2540, tea_CELoss: 0.9498, stu_CELoss: 1.1062, DMLLoss: 0.1980, 
2022-08-01 19:22:19 - train: epoch 0057, iter [03900, 05004], lr: 0.010000, loss: 2.9428, tea_CELoss: 1.2435, stu_CELoss: 1.4406, DMLLoss: 0.2587, 
2022-08-01 19:23:17 - train: epoch 0057, iter [04000, 05004], lr: 0.010000, loss: 2.3954, tea_CELoss: 0.9939, stu_CELoss: 1.1572, DMLLoss: 0.2443, 
2022-08-01 19:24:14 - train: epoch 0057, iter [04100, 05004], lr: 0.010000, loss: 2.4849, tea_CELoss: 1.0444, stu_CELoss: 1.2015, DMLLoss: 0.2390, 
2022-08-01 19:25:12 - train: epoch 0057, iter [04200, 05004], lr: 0.010000, loss: 2.2203, tea_CELoss: 0.9019, stu_CELoss: 1.0741, DMLLoss: 0.2443, 
2022-08-01 19:26:10 - train: epoch 0057, iter [04300, 05004], lr: 0.010000, loss: 2.0799, tea_CELoss: 0.9122, stu_CELoss: 0.9801, DMLLoss: 0.1877, 
2022-08-01 19:27:08 - train: epoch 0057, iter [04400, 05004], lr: 0.010000, loss: 2.6523, tea_CELoss: 1.1050, stu_CELoss: 1.2766, DMLLoss: 0.2706, 
2022-08-01 19:28:05 - train: epoch 0057, iter [04500, 05004], lr: 0.010000, loss: 2.7015, tea_CELoss: 1.1293, stu_CELoss: 1.2731, DMLLoss: 0.2991, 
2022-08-01 19:29:03 - train: epoch 0057, iter [04600, 05004], lr: 0.010000, loss: 2.1706, tea_CELoss: 0.8773, stu_CELoss: 1.0509, DMLLoss: 0.2424, 
2022-08-01 19:30:02 - train: epoch 0057, iter [04700, 05004], lr: 0.010000, loss: 2.4143, tea_CELoss: 1.0130, stu_CELoss: 1.1541, DMLLoss: 0.2472, 
2022-08-01 19:31:00 - train: epoch 0057, iter [04800, 05004], lr: 0.010000, loss: 2.7137, tea_CELoss: 1.1360, stu_CELoss: 1.3112, DMLLoss: 0.2665, 
2022-08-01 19:31:58 - train: epoch 0057, iter [04900, 05004], lr: 0.010000, loss: 2.3652, tea_CELoss: 0.9873, stu_CELoss: 1.1437, DMLLoss: 0.2342, 
2022-08-01 19:32:56 - train: epoch 0057, iter [05000, 05004], lr: 0.010000, loss: 2.6317, tea_CELoss: 1.0941, stu_CELoss: 1.2578, DMLLoss: 0.2798, 
2022-08-01 19:32:59 - train: epoch 057, train_loss: 2.3683
2022-08-01 19:35:33 - eval: epoch: 057, tea_acc1: 75.472%, tea_acc5: 92.870%, tea_test_loss: 0.9576, stu_acc1: 73.086%, stu_acc5: 91.554%, stu_test_loss: 1.0734
2022-08-01 19:35:34 - until epoch: 057, tea_best_acc1: 75.770%, stu_best_acc1: 73.634%
2022-08-01 19:35:34 - epoch 058 lr: 0.010000
2022-08-01 19:36:38 - train: epoch 0058, iter [00100, 05004], lr: 0.010000, loss: 2.1268, tea_CELoss: 0.9169, stu_CELoss: 1.0131, DMLLoss: 0.1968, 
2022-08-01 19:37:36 - train: epoch 0058, iter [00200, 05004], lr: 0.010000, loss: 2.1388, tea_CELoss: 0.8790, stu_CELoss: 1.0538, DMLLoss: 0.2061, 
2022-08-01 19:38:34 - train: epoch 0058, iter [00300, 05004], lr: 0.010000, loss: 2.2880, tea_CELoss: 0.9613, stu_CELoss: 1.0955, DMLLoss: 0.2312, 
2022-08-01 19:39:31 - train: epoch 0058, iter [00400, 05004], lr: 0.010000, loss: 2.2315, tea_CELoss: 0.9336, stu_CELoss: 1.0919, DMLLoss: 0.2060, 
2022-08-01 19:40:29 - train: epoch 0058, iter [00500, 05004], lr: 0.010000, loss: 2.2185, tea_CELoss: 0.9398, stu_CELoss: 1.0542, DMLLoss: 0.2246, 
2022-08-01 19:41:27 - train: epoch 0058, iter [00600, 05004], lr: 0.010000, loss: 2.5760, tea_CELoss: 1.0212, stu_CELoss: 1.2701, DMLLoss: 0.2847, 
2022-08-01 19:42:25 - train: epoch 0058, iter [00700, 05004], lr: 0.010000, loss: 2.3340, tea_CELoss: 0.9840, stu_CELoss: 1.1093, DMLLoss: 0.2407, 
2022-08-01 19:43:23 - train: epoch 0058, iter [00800, 05004], lr: 0.010000, loss: 2.3446, tea_CELoss: 0.9548, stu_CELoss: 1.1509, DMLLoss: 0.2390, 
2022-08-01 19:44:21 - train: epoch 0058, iter [00900, 05004], lr: 0.010000, loss: 2.0737, tea_CELoss: 0.8888, stu_CELoss: 0.9850, DMLLoss: 0.1998, 
2022-08-01 19:45:18 - train: epoch 0058, iter [01000, 05004], lr: 0.010000, loss: 2.0293, tea_CELoss: 0.8644, stu_CELoss: 0.9409, DMLLoss: 0.2240, 
2022-08-01 19:46:16 - train: epoch 0058, iter [01100, 05004], lr: 0.010000, loss: 2.2985, tea_CELoss: 0.9781, stu_CELoss: 1.1003, DMLLoss: 0.2201, 
2022-08-01 19:47:14 - train: epoch 0058, iter [01200, 05004], lr: 0.010000, loss: 1.9189, tea_CELoss: 0.7663, stu_CELoss: 0.9307, DMLLoss: 0.2219, 
2022-08-01 19:48:12 - train: epoch 0058, iter [01300, 05004], lr: 0.010000, loss: 2.4040, tea_CELoss: 0.9901, stu_CELoss: 1.1559, DMLLoss: 0.2580, 
2022-08-01 19:49:10 - train: epoch 0058, iter [01400, 05004], lr: 0.010000, loss: 2.3707, tea_CELoss: 0.9807, stu_CELoss: 1.1354, DMLLoss: 0.2546, 
2022-08-01 19:50:08 - train: epoch 0058, iter [01500, 05004], lr: 0.010000, loss: 2.3254, tea_CELoss: 0.9823, stu_CELoss: 1.0779, DMLLoss: 0.2652, 
2022-08-01 19:51:06 - train: epoch 0058, iter [01600, 05004], lr: 0.010000, loss: 2.4756, tea_CELoss: 1.0573, stu_CELoss: 1.1888, DMLLoss: 0.2295, 
2022-08-01 19:52:04 - train: epoch 0058, iter [01700, 05004], lr: 0.010000, loss: 2.7032, tea_CELoss: 1.1578, stu_CELoss: 1.3094, DMLLoss: 0.2359, 
2022-08-01 19:53:02 - train: epoch 0058, iter [01800, 05004], lr: 0.010000, loss: 2.5466, tea_CELoss: 1.1008, stu_CELoss: 1.1999, DMLLoss: 0.2459, 
2022-08-01 19:54:00 - train: epoch 0058, iter [01900, 05004], lr: 0.010000, loss: 2.6573, tea_CELoss: 1.1012, stu_CELoss: 1.3133, DMLLoss: 0.2427, 
2022-08-01 19:54:58 - train: epoch 0058, iter [02000, 05004], lr: 0.010000, loss: 2.5594, tea_CELoss: 1.0854, stu_CELoss: 1.2131, DMLLoss: 0.2608, 
2022-08-01 19:55:56 - train: epoch 0058, iter [02100, 05004], lr: 0.010000, loss: 2.1990, tea_CELoss: 0.9067, stu_CELoss: 1.0384, DMLLoss: 0.2538, 
2022-08-01 19:56:54 - train: epoch 0058, iter [02200, 05004], lr: 0.010000, loss: 2.3051, tea_CELoss: 0.9641, stu_CELoss: 1.1080, DMLLoss: 0.2330, 
2022-08-01 19:57:52 - train: epoch 0058, iter [02300, 05004], lr: 0.010000, loss: 2.4404, tea_CELoss: 1.0046, stu_CELoss: 1.1855, DMLLoss: 0.2503, 
2022-08-01 19:58:50 - train: epoch 0058, iter [02400, 05004], lr: 0.010000, loss: 2.3879, tea_CELoss: 1.0109, stu_CELoss: 1.1468, DMLLoss: 0.2303, 
2022-08-01 19:59:48 - train: epoch 0058, iter [02500, 05004], lr: 0.010000, loss: 2.6673, tea_CELoss: 1.1440, stu_CELoss: 1.3011, DMLLoss: 0.2222, 
2022-08-01 20:00:46 - train: epoch 0058, iter [02600, 05004], lr: 0.010000, loss: 2.1802, tea_CELoss: 0.9376, stu_CELoss: 1.0137, DMLLoss: 0.2290, 
2022-08-01 20:01:44 - train: epoch 0058, iter [02700, 05004], lr: 0.010000, loss: 2.6304, tea_CELoss: 1.1780, stu_CELoss: 1.2365, DMLLoss: 0.2159, 
2022-08-01 20:02:42 - train: epoch 0058, iter [02800, 05004], lr: 0.010000, loss: 2.2595, tea_CELoss: 0.9788, stu_CELoss: 1.0400, DMLLoss: 0.2407, 
2022-08-01 20:03:40 - train: epoch 0058, iter [02900, 05004], lr: 0.010000, loss: 2.0485, tea_CELoss: 0.8236, stu_CELoss: 1.0051, DMLLoss: 0.2198, 
2022-08-01 20:04:38 - train: epoch 0058, iter [03000, 05004], lr: 0.010000, loss: 2.6008, tea_CELoss: 1.0989, stu_CELoss: 1.2418, DMLLoss: 0.2601, 
2022-08-01 20:05:36 - train: epoch 0058, iter [03100, 05004], lr: 0.010000, loss: 2.3851, tea_CELoss: 1.0117, stu_CELoss: 1.1289, DMLLoss: 0.2445, 
2022-08-01 20:06:34 - train: epoch 0058, iter [03200, 05004], lr: 0.010000, loss: 1.9396, tea_CELoss: 0.8341, stu_CELoss: 0.8881, DMLLoss: 0.2174, 
2022-08-01 20:07:32 - train: epoch 0058, iter [03300, 05004], lr: 0.010000, loss: 2.4277, tea_CELoss: 1.0274, stu_CELoss: 1.1629, DMLLoss: 0.2374, 
2022-08-01 20:08:30 - train: epoch 0058, iter [03400, 05004], lr: 0.010000, loss: 2.4936, tea_CELoss: 1.0652, stu_CELoss: 1.1953, DMLLoss: 0.2331, 
2022-08-01 20:09:28 - train: epoch 0058, iter [03500, 05004], lr: 0.010000, loss: 2.1051, tea_CELoss: 0.8487, stu_CELoss: 1.0099, DMLLoss: 0.2464, 
2022-08-01 20:10:26 - train: epoch 0058, iter [03600, 05004], lr: 0.010000, loss: 2.6733, tea_CELoss: 1.1262, stu_CELoss: 1.2991, DMLLoss: 0.2481, 
2022-08-01 20:11:24 - train: epoch 0058, iter [03700, 05004], lr: 0.010000, loss: 2.1540, tea_CELoss: 0.8978, stu_CELoss: 1.0298, DMLLoss: 0.2264, 
2022-08-01 20:12:22 - train: epoch 0058, iter [03800, 05004], lr: 0.010000, loss: 2.5782, tea_CELoss: 1.0180, stu_CELoss: 1.2584, DMLLoss: 0.3019, 
2022-08-01 20:13:21 - train: epoch 0058, iter [03900, 05004], lr: 0.010000, loss: 2.2100, tea_CELoss: 0.9317, stu_CELoss: 1.0433, DMLLoss: 0.2351, 
2022-08-01 20:14:19 - train: epoch 0058, iter [04000, 05004], lr: 0.010000, loss: 2.5252, tea_CELoss: 1.1158, stu_CELoss: 1.1836, DMLLoss: 0.2258, 
2022-08-01 20:15:17 - train: epoch 0058, iter [04100, 05004], lr: 0.010000, loss: 1.9960, tea_CELoss: 0.8149, stu_CELoss: 0.9305, DMLLoss: 0.2505, 
2022-08-01 20:16:15 - train: epoch 0058, iter [04200, 05004], lr: 0.010000, loss: 2.1632, tea_CELoss: 0.9443, stu_CELoss: 1.0001, DMLLoss: 0.2187, 
2022-08-01 20:17:13 - train: epoch 0058, iter [04300, 05004], lr: 0.010000, loss: 2.5371, tea_CELoss: 1.1025, stu_CELoss: 1.1932, DMLLoss: 0.2413, 
2022-08-01 20:18:11 - train: epoch 0058, iter [04400, 05004], lr: 0.010000, loss: 2.4029, tea_CELoss: 1.0123, stu_CELoss: 1.1624, DMLLoss: 0.2282, 
2022-08-01 20:19:10 - train: epoch 0058, iter [04500, 05004], lr: 0.010000, loss: 2.1509, tea_CELoss: 0.8606, stu_CELoss: 1.0279, DMLLoss: 0.2625, 
2022-08-01 20:20:08 - train: epoch 0058, iter [04600, 05004], lr: 0.010000, loss: 2.5362, tea_CELoss: 1.0395, stu_CELoss: 1.2410, DMLLoss: 0.2557, 
2022-08-01 20:21:06 - train: epoch 0058, iter [04700, 05004], lr: 0.010000, loss: 2.5239, tea_CELoss: 1.0573, stu_CELoss: 1.2246, DMLLoss: 0.2420, 
2022-08-01 20:22:05 - train: epoch 0058, iter [04800, 05004], lr: 0.010000, loss: 2.3841, tea_CELoss: 1.0035, stu_CELoss: 1.1393, DMLLoss: 0.2413, 
2022-08-01 20:23:03 - train: epoch 0058, iter [04900, 05004], lr: 0.010000, loss: 2.3363, tea_CELoss: 1.0093, stu_CELoss: 1.1046, DMLLoss: 0.2224, 
2022-08-01 20:24:01 - train: epoch 0058, iter [05000, 05004], lr: 0.010000, loss: 2.1092, tea_CELoss: 0.8826, stu_CELoss: 1.0187, DMLLoss: 0.2079, 
2022-08-01 20:24:04 - train: epoch 058, train_loss: 2.3630
2022-08-01 20:26:39 - eval: epoch: 058, tea_acc1: 75.102%, tea_acc5: 92.630%, tea_test_loss: 0.9734, stu_acc1: 73.464%, stu_acc5: 91.640%, stu_test_loss: 1.0562
2022-08-01 20:26:40 - until epoch: 058, tea_best_acc1: 75.770%, stu_best_acc1: 73.634%
2022-08-01 20:26:40 - epoch 059 lr: 0.010000
2022-08-01 20:27:45 - train: epoch 0059, iter [00100, 05004], lr: 0.010000, loss: 2.5732, tea_CELoss: 1.0886, stu_CELoss: 1.2370, DMLLoss: 0.2476, 
2022-08-01 20:28:43 - train: epoch 0059, iter [00200, 05004], lr: 0.010000, loss: 2.1317, tea_CELoss: 0.8940, stu_CELoss: 1.0207, DMLLoss: 0.2170, 
2022-08-01 20:29:42 - train: epoch 0059, iter [00300, 05004], lr: 0.010000, loss: 2.1239, tea_CELoss: 0.9073, stu_CELoss: 0.9906, DMLLoss: 0.2260, 
2022-08-01 20:30:40 - train: epoch 0059, iter [00400, 05004], lr: 0.010000, loss: 2.2193, tea_CELoss: 0.9802, stu_CELoss: 1.0205, DMLLoss: 0.2186, 
2022-08-01 20:31:38 - train: epoch 0059, iter [00500, 05004], lr: 0.010000, loss: 2.4989, tea_CELoss: 1.0430, stu_CELoss: 1.2027, DMLLoss: 0.2533, 
2022-08-01 20:32:36 - train: epoch 0059, iter [00600, 05004], lr: 0.010000, loss: 2.2127, tea_CELoss: 0.9115, stu_CELoss: 1.0637, DMLLoss: 0.2375, 
2022-08-01 20:33:34 - train: epoch 0059, iter [00700, 05004], lr: 0.010000, loss: 2.0601, tea_CELoss: 0.8721, stu_CELoss: 0.9601, DMLLoss: 0.2279, 
2022-08-01 20:34:32 - train: epoch 0059, iter [00800, 05004], lr: 0.010000, loss: 2.5477, tea_CELoss: 1.1090, stu_CELoss: 1.1818, DMLLoss: 0.2569, 
2022-08-01 20:35:30 - train: epoch 0059, iter [00900, 05004], lr: 0.010000, loss: 2.1767, tea_CELoss: 0.9157, stu_CELoss: 1.0466, DMLLoss: 0.2144, 
2022-08-01 20:36:29 - train: epoch 0059, iter [01000, 05004], lr: 0.010000, loss: 2.4597, tea_CELoss: 1.0294, stu_CELoss: 1.1614, DMLLoss: 0.2689, 
2022-08-01 20:37:27 - train: epoch 0059, iter [01100, 05004], lr: 0.010000, loss: 3.0151, tea_CELoss: 1.2825, stu_CELoss: 1.4519, DMLLoss: 0.2806, 
2022-08-01 20:38:25 - train: epoch 0059, iter [01200, 05004], lr: 0.010000, loss: 2.1323, tea_CELoss: 0.9113, stu_CELoss: 1.0161, DMLLoss: 0.2050, 
2022-08-01 20:39:23 - train: epoch 0059, iter [01300, 05004], lr: 0.010000, loss: 2.5725, tea_CELoss: 1.0687, stu_CELoss: 1.2438, DMLLoss: 0.2600, 
2022-08-01 20:40:21 - train: epoch 0059, iter [01400, 05004], lr: 0.010000, loss: 2.7095, tea_CELoss: 1.1727, stu_CELoss: 1.2886, DMLLoss: 0.2482, 
2022-08-01 20:41:20 - train: epoch 0059, iter [01500, 05004], lr: 0.010000, loss: 2.3615, tea_CELoss: 0.9731, stu_CELoss: 1.1671, DMLLoss: 0.2212, 
2022-08-01 20:42:18 - train: epoch 0059, iter [01600, 05004], lr: 0.010000, loss: 1.8707, tea_CELoss: 0.7703, stu_CELoss: 0.8759, DMLLoss: 0.2245, 
2022-08-01 20:43:16 - train: epoch 0059, iter [01700, 05004], lr: 0.010000, loss: 2.1817, tea_CELoss: 0.9018, stu_CELoss: 1.0582, DMLLoss: 0.2216, 
2022-08-01 20:44:14 - train: epoch 0059, iter [01800, 05004], lr: 0.010000, loss: 2.3303, tea_CELoss: 1.0099, stu_CELoss: 1.0987, DMLLoss: 0.2217, 
2022-08-01 20:45:12 - train: epoch 0059, iter [01900, 05004], lr: 0.010000, loss: 2.2941, tea_CELoss: 0.9896, stu_CELoss: 1.1023, DMLLoss: 0.2021, 
2022-08-01 20:46:10 - train: epoch 0059, iter [02000, 05004], lr: 0.010000, loss: 1.9446, tea_CELoss: 0.7858, stu_CELoss: 0.9179, DMLLoss: 0.2409, 
2022-08-01 20:47:08 - train: epoch 0059, iter [02100, 05004], lr: 0.010000, loss: 2.6507, tea_CELoss: 1.1327, stu_CELoss: 1.2775, DMLLoss: 0.2405, 
2022-08-01 20:48:06 - train: epoch 0059, iter [02200, 05004], lr: 0.010000, loss: 2.3584, tea_CELoss: 1.0145, stu_CELoss: 1.1277, DMLLoss: 0.2162, 
2022-08-01 20:49:05 - train: epoch 0059, iter [02300, 05004], lr: 0.010000, loss: 2.2656, tea_CELoss: 0.9252, stu_CELoss: 1.1029, DMLLoss: 0.2374, 
2022-08-01 20:50:03 - train: epoch 0059, iter [02400, 05004], lr: 0.010000, loss: 2.6124, tea_CELoss: 1.1024, stu_CELoss: 1.2499, DMLLoss: 0.2601, 
2022-08-01 20:51:01 - train: epoch 0059, iter [02500, 05004], lr: 0.010000, loss: 2.6594, tea_CELoss: 1.1204, stu_CELoss: 1.3029, DMLLoss: 0.2361, 
2022-08-01 20:51:59 - train: epoch 0059, iter [02600, 05004], lr: 0.010000, loss: 2.3409, tea_CELoss: 0.9939, stu_CELoss: 1.1310, DMLLoss: 0.2161, 
2022-08-01 20:52:57 - train: epoch 0059, iter [02700, 05004], lr: 0.010000, loss: 2.1250, tea_CELoss: 0.8847, stu_CELoss: 1.0045, DMLLoss: 0.2359, 
2022-08-01 20:53:55 - train: epoch 0059, iter [02800, 05004], lr: 0.010000, loss: 2.5153, tea_CELoss: 1.0983, stu_CELoss: 1.1932, DMLLoss: 0.2238, 
2022-08-01 20:54:54 - train: epoch 0059, iter [02900, 05004], lr: 0.010000, loss: 2.3584, tea_CELoss: 0.9474, stu_CELoss: 1.1678, DMLLoss: 0.2432, 
2022-08-01 20:55:52 - train: epoch 0059, iter [03000, 05004], lr: 0.010000, loss: 2.9997, tea_CELoss: 1.2979, stu_CELoss: 1.4320, DMLLoss: 0.2698, 
2022-08-01 20:56:50 - train: epoch 0059, iter [03100, 05004], lr: 0.010000, loss: 2.2008, tea_CELoss: 0.9031, stu_CELoss: 1.0555, DMLLoss: 0.2422, 
2022-08-01 20:57:48 - train: epoch 0059, iter [03200, 05004], lr: 0.010000, loss: 2.5518, tea_CELoss: 1.0860, stu_CELoss: 1.2150, DMLLoss: 0.2508, 
2022-08-01 20:58:46 - train: epoch 0059, iter [03300, 05004], lr: 0.010000, loss: 2.3635, tea_CELoss: 0.9871, stu_CELoss: 1.1339, DMLLoss: 0.2425, 
2022-08-01 20:59:44 - train: epoch 0059, iter [03400, 05004], lr: 0.010000, loss: 3.0819, tea_CELoss: 1.2989, stu_CELoss: 1.5064, DMLLoss: 0.2766, 
2022-08-01 21:00:42 - train: epoch 0059, iter [03500, 05004], lr: 0.010000, loss: 2.5834, tea_CELoss: 1.1125, stu_CELoss: 1.1985, DMLLoss: 0.2724, 
2022-08-01 21:01:40 - train: epoch 0059, iter [03600, 05004], lr: 0.010000, loss: 2.6900, tea_CELoss: 1.1449, stu_CELoss: 1.2828, DMLLoss: 0.2623, 
2022-08-01 21:02:38 - train: epoch 0059, iter [03700, 05004], lr: 0.010000, loss: 2.4710, tea_CELoss: 1.0334, stu_CELoss: 1.2113, DMLLoss: 0.2263, 
2022-08-01 21:03:36 - train: epoch 0059, iter [03800, 05004], lr: 0.010000, loss: 2.3663, tea_CELoss: 1.0293, stu_CELoss: 1.1199, DMLLoss: 0.2171, 
2022-08-01 21:04:34 - train: epoch 0059, iter [03900, 05004], lr: 0.010000, loss: 2.1227, tea_CELoss: 0.8869, stu_CELoss: 1.0028, DMLLoss: 0.2330, 
2022-08-01 21:05:33 - train: epoch 0059, iter [04000, 05004], lr: 0.010000, loss: 2.7990, tea_CELoss: 1.2415, stu_CELoss: 1.3234, DMLLoss: 0.2341, 
2022-08-01 21:06:30 - train: epoch 0059, iter [04100, 05004], lr: 0.010000, loss: 1.9713, tea_CELoss: 0.8127, stu_CELoss: 0.9602, DMLLoss: 0.1984, 
2022-08-01 21:07:29 - train: epoch 0059, iter [04200, 05004], lr: 0.010000, loss: 2.3595, tea_CELoss: 0.9232, stu_CELoss: 1.1527, DMLLoss: 0.2836, 
2022-08-01 21:08:27 - train: epoch 0059, iter [04300, 05004], lr: 0.010000, loss: 2.5908, tea_CELoss: 1.0560, stu_CELoss: 1.2892, DMLLoss: 0.2456, 
2022-08-01 21:09:25 - train: epoch 0059, iter [04400, 05004], lr: 0.010000, loss: 2.5014, tea_CELoss: 1.0675, stu_CELoss: 1.1774, DMLLoss: 0.2566, 
2022-08-01 21:10:23 - train: epoch 0059, iter [04500, 05004], lr: 0.010000, loss: 3.0206, tea_CELoss: 1.2902, stu_CELoss: 1.4486, DMLLoss: 0.2819, 
2022-08-01 21:11:21 - train: epoch 0059, iter [04600, 05004], lr: 0.010000, loss: 2.5482, tea_CELoss: 1.1023, stu_CELoss: 1.2204, DMLLoss: 0.2255, 
2022-08-01 21:12:19 - train: epoch 0059, iter [04700, 05004], lr: 0.010000, loss: 2.4668, tea_CELoss: 1.0317, stu_CELoss: 1.1717, DMLLoss: 0.2634, 
2022-08-01 21:13:17 - train: epoch 0059, iter [04800, 05004], lr: 0.010000, loss: 2.2948, tea_CELoss: 0.9440, stu_CELoss: 1.1040, DMLLoss: 0.2468, 
2022-08-01 21:14:15 - train: epoch 0059, iter [04900, 05004], lr: 0.010000, loss: 2.3689, tea_CELoss: 0.9476, stu_CELoss: 1.1780, DMLLoss: 0.2433, 
2022-08-01 21:15:13 - train: epoch 0059, iter [05000, 05004], lr: 0.010000, loss: 2.5009, tea_CELoss: 1.0179, stu_CELoss: 1.2328, DMLLoss: 0.2503, 
2022-08-01 21:15:16 - train: epoch 059, train_loss: 2.3576
2022-08-01 21:17:48 - eval: epoch: 059, tea_acc1: 73.982%, tea_acc5: 92.132%, tea_test_loss: 1.0158, stu_acc1: 72.766%, stu_acc5: 91.334%, stu_test_loss: 1.0796
2022-08-01 21:17:49 - until epoch: 059, tea_best_acc1: 75.770%, stu_best_acc1: 73.634%
2022-08-01 21:17:49 - epoch 060 lr: 0.010000
2022-08-01 21:18:52 - train: epoch 0060, iter [00100, 05004], lr: 0.010000, loss: 2.1097, tea_CELoss: 0.8550, stu_CELoss: 1.0200, DMLLoss: 0.2347, 
2022-08-01 21:19:50 - train: epoch 0060, iter [00200, 05004], lr: 0.010000, loss: 2.0376, tea_CELoss: 0.8176, stu_CELoss: 0.9662, DMLLoss: 0.2537, 
2022-08-01 21:20:47 - train: epoch 0060, iter [00300, 05004], lr: 0.010000, loss: 2.3167, tea_CELoss: 0.9020, stu_CELoss: 1.1114, DMLLoss: 0.3033, 
2022-08-01 21:21:44 - train: epoch 0060, iter [00400, 05004], lr: 0.010000, loss: 2.5253, tea_CELoss: 1.1027, stu_CELoss: 1.2144, DMLLoss: 0.2083, 
2022-08-01 21:22:42 - train: epoch 0060, iter [00500, 05004], lr: 0.010000, loss: 2.6601, tea_CELoss: 1.1680, stu_CELoss: 1.2583, DMLLoss: 0.2339, 
2022-08-01 21:23:39 - train: epoch 0060, iter [00600, 05004], lr: 0.010000, loss: 2.4323, tea_CELoss: 1.0365, stu_CELoss: 1.1465, DMLLoss: 0.2494, 
2022-08-01 21:24:36 - train: epoch 0060, iter [00700, 05004], lr: 0.010000, loss: 2.2966, tea_CELoss: 0.9416, stu_CELoss: 1.0891, DMLLoss: 0.2659, 
2022-08-01 21:25:34 - train: epoch 0060, iter [00800, 05004], lr: 0.010000, loss: 2.5336, tea_CELoss: 1.0374, stu_CELoss: 1.2539, DMLLoss: 0.2422, 
2022-08-01 21:26:31 - train: epoch 0060, iter [00900, 05004], lr: 0.010000, loss: 2.1144, tea_CELoss: 0.8965, stu_CELoss: 1.0084, DMLLoss: 0.2095, 
2022-08-01 21:27:29 - train: epoch 0060, iter [01000, 05004], lr: 0.010000, loss: 1.9668, tea_CELoss: 0.8777, stu_CELoss: 0.9108, DMLLoss: 0.1784, 
2022-08-01 21:28:27 - train: epoch 0060, iter [01100, 05004], lr: 0.010000, loss: 2.2721, tea_CELoss: 0.9371, stu_CELoss: 1.0904, DMLLoss: 0.2447, 
2022-08-01 21:29:24 - train: epoch 0060, iter [01200, 05004], lr: 0.010000, loss: 2.0937, tea_CELoss: 0.8905, stu_CELoss: 1.0001, DMLLoss: 0.2030, 
2022-08-01 21:30:21 - train: epoch 0060, iter [01300, 05004], lr: 0.010000, loss: 2.0491, tea_CELoss: 0.8678, stu_CELoss: 0.9444, DMLLoss: 0.2369, 
2022-08-01 21:31:18 - train: epoch 0060, iter [01400, 05004], lr: 0.010000, loss: 2.6178, tea_CELoss: 1.0949, stu_CELoss: 1.2899, DMLLoss: 0.2330, 
2022-08-01 21:32:15 - train: epoch 0060, iter [01500, 05004], lr: 0.010000, loss: 2.4749, tea_CELoss: 1.0336, stu_CELoss: 1.1525, DMLLoss: 0.2888, 
2022-08-01 21:33:12 - train: epoch 0060, iter [01600, 05004], lr: 0.010000, loss: 2.2352, tea_CELoss: 0.9443, stu_CELoss: 1.0559, DMLLoss: 0.2350, 
2022-08-01 21:34:09 - train: epoch 0060, iter [01700, 05004], lr: 0.010000, loss: 2.5104, tea_CELoss: 1.0672, stu_CELoss: 1.1892, DMLLoss: 0.2540, 
2022-08-01 21:35:06 - train: epoch 0060, iter [01800, 05004], lr: 0.010000, loss: 2.6569, tea_CELoss: 1.1084, stu_CELoss: 1.2805, DMLLoss: 0.2681, 
2022-08-01 21:36:03 - train: epoch 0060, iter [01900, 05004], lr: 0.010000, loss: 2.2885, tea_CELoss: 0.9451, stu_CELoss: 1.1065, DMLLoss: 0.2369, 
2022-08-01 21:37:01 - train: epoch 0060, iter [02000, 05004], lr: 0.010000, loss: 2.3281, tea_CELoss: 0.9807, stu_CELoss: 1.1201, DMLLoss: 0.2273, 
2022-08-01 21:37:58 - train: epoch 0060, iter [02100, 05004], lr: 0.010000, loss: 2.8463, tea_CELoss: 1.2032, stu_CELoss: 1.3730, DMLLoss: 0.2701, 
2022-08-01 21:38:55 - train: epoch 0060, iter [02200, 05004], lr: 0.010000, loss: 2.4927, tea_CELoss: 1.0490, stu_CELoss: 1.2002, DMLLoss: 0.2434, 
2022-08-01 21:39:52 - train: epoch 0060, iter [02300, 05004], lr: 0.010000, loss: 2.1017, tea_CELoss: 0.8666, stu_CELoss: 1.0117, DMLLoss: 0.2234, 
2022-08-01 21:40:49 - train: epoch 0060, iter [02400, 05004], lr: 0.010000, loss: 2.4516, tea_CELoss: 1.0331, stu_CELoss: 1.1610, DMLLoss: 0.2575, 
2022-08-01 21:41:46 - train: epoch 0060, iter [02500, 05004], lr: 0.010000, loss: 2.4154, tea_CELoss: 1.0378, stu_CELoss: 1.1490, DMLLoss: 0.2286, 
2022-08-01 21:42:43 - train: epoch 0060, iter [02600, 05004], lr: 0.010000, loss: 2.2954, tea_CELoss: 0.9549, stu_CELoss: 1.0809, DMLLoss: 0.2596, 
2022-08-01 21:43:40 - train: epoch 0060, iter [02700, 05004], lr: 0.010000, loss: 2.0086, tea_CELoss: 0.8383, stu_CELoss: 0.9479, DMLLoss: 0.2224, 
2022-08-01 21:44:37 - train: epoch 0060, iter [02800, 05004], lr: 0.010000, loss: 2.5955, tea_CELoss: 1.0896, stu_CELoss: 1.2239, DMLLoss: 0.2821, 
2022-08-01 21:45:34 - train: epoch 0060, iter [02900, 05004], lr: 0.010000, loss: 1.9626, tea_CELoss: 0.7593, stu_CELoss: 0.9514, DMLLoss: 0.2519, 
2022-08-01 21:46:31 - train: epoch 0060, iter [03000, 05004], lr: 0.010000, loss: 2.4446, tea_CELoss: 1.0041, stu_CELoss: 1.1885, DMLLoss: 0.2519, 
2022-08-01 21:47:28 - train: epoch 0060, iter [03100, 05004], lr: 0.010000, loss: 2.7138, tea_CELoss: 1.1292, stu_CELoss: 1.3121, DMLLoss: 0.2725, 
2022-08-01 21:48:25 - train: epoch 0060, iter [03200, 05004], lr: 0.010000, loss: 2.2208, tea_CELoss: 0.9118, stu_CELoss: 1.0465, DMLLoss: 0.2625, 
2022-08-01 21:49:22 - train: epoch 0060, iter [03300, 05004], lr: 0.010000, loss: 1.8533, tea_CELoss: 0.7543, stu_CELoss: 0.8680, DMLLoss: 0.2310, 
2022-08-01 21:50:19 - train: epoch 0060, iter [03400, 05004], lr: 0.010000, loss: 2.6923, tea_CELoss: 1.1418, stu_CELoss: 1.2638, DMLLoss: 0.2867, 
2022-08-01 21:51:17 - train: epoch 0060, iter [03500, 05004], lr: 0.010000, loss: 2.5643, tea_CELoss: 1.0920, stu_CELoss: 1.2375, DMLLoss: 0.2348, 
2022-08-01 21:52:14 - train: epoch 0060, iter [03600, 05004], lr: 0.010000, loss: 2.6174, tea_CELoss: 1.1166, stu_CELoss: 1.2315, DMLLoss: 0.2693, 
2022-08-01 21:53:11 - train: epoch 0060, iter [03700, 05004], lr: 0.010000, loss: 2.6680, tea_CELoss: 1.1669, stu_CELoss: 1.2694, DMLLoss: 0.2317, 
2022-08-01 21:54:08 - train: epoch 0060, iter [03800, 05004], lr: 0.010000, loss: 2.6020, tea_CELoss: 1.0781, stu_CELoss: 1.2759, DMLLoss: 0.2480, 
2022-08-01 21:55:05 - train: epoch 0060, iter [03900, 05004], lr: 0.010000, loss: 2.8166, tea_CELoss: 1.1995, stu_CELoss: 1.3616, DMLLoss: 0.2555, 
2022-08-01 21:56:02 - train: epoch 0060, iter [04000, 05004], lr: 0.010000, loss: 2.5124, tea_CELoss: 1.0574, stu_CELoss: 1.2247, DMLLoss: 0.2303, 
2022-08-01 21:57:00 - train: epoch 0060, iter [04100, 05004], lr: 0.010000, loss: 2.7355, tea_CELoss: 1.1319, stu_CELoss: 1.3125, DMLLoss: 0.2911, 
2022-08-01 21:57:57 - train: epoch 0060, iter [04200, 05004], lr: 0.010000, loss: 2.2813, tea_CELoss: 0.9253, stu_CELoss: 1.0763, DMLLoss: 0.2798, 
2022-08-01 21:58:54 - train: epoch 0060, iter [04300, 05004], lr: 0.010000, loss: 2.0970, tea_CELoss: 0.8749, stu_CELoss: 1.0018, DMLLoss: 0.2202, 
2022-08-01 21:59:51 - train: epoch 0060, iter [04400, 05004], lr: 0.010000, loss: 2.6495, tea_CELoss: 1.0786, stu_CELoss: 1.2930, DMLLoss: 0.2779, 
2022-08-01 22:00:48 - train: epoch 0060, iter [04500, 05004], lr: 0.010000, loss: 2.7084, tea_CELoss: 1.1725, stu_CELoss: 1.2968, DMLLoss: 0.2392, 
2022-08-01 22:01:45 - train: epoch 0060, iter [04600, 05004], lr: 0.010000, loss: 2.1234, tea_CELoss: 0.8751, stu_CELoss: 1.0169, DMLLoss: 0.2313, 
2022-08-01 22:02:43 - train: epoch 0060, iter [04700, 05004], lr: 0.010000, loss: 2.2320, tea_CELoss: 0.9103, stu_CELoss: 1.0587, DMLLoss: 0.2630, 
2022-08-01 22:03:40 - train: epoch 0060, iter [04800, 05004], lr: 0.010000, loss: 2.2859, tea_CELoss: 0.9292, stu_CELoss: 1.1240, DMLLoss: 0.2327, 
2022-08-01 22:04:37 - train: epoch 0060, iter [04900, 05004], lr: 0.010000, loss: 2.4214, tea_CELoss: 1.0298, stu_CELoss: 1.1706, DMLLoss: 0.2210, 
2022-08-01 22:05:34 - train: epoch 0060, iter [05000, 05004], lr: 0.010000, loss: 2.5291, tea_CELoss: 1.0554, stu_CELoss: 1.2212, DMLLoss: 0.2524, 
2022-08-01 22:05:37 - train: epoch 060, train_loss: 2.3530
2022-08-01 22:08:12 - eval: epoch: 060, tea_acc1: 75.366%, tea_acc5: 92.746%, tea_test_loss: 0.9650, stu_acc1: 72.706%, stu_acc5: 91.200%, stu_test_loss: 1.0987
2022-08-01 22:08:13 - until epoch: 060, tea_best_acc1: 75.770%, stu_best_acc1: 73.634%
2022-08-01 22:08:13 - epoch 061 lr: 0.001000
2022-08-01 22:09:16 - train: epoch 0061, iter [00100, 05004], lr: 0.001000, loss: 2.0118, tea_CELoss: 0.8582, stu_CELoss: 0.9594, DMLLoss: 0.1942, 
2022-08-01 22:10:13 - train: epoch 0061, iter [00200, 05004], lr: 0.001000, loss: 2.2279, tea_CELoss: 0.9556, stu_CELoss: 1.0953, DMLLoss: 0.1770, 
2022-08-01 22:11:10 - train: epoch 0061, iter [00300, 05004], lr: 0.001000, loss: 1.8038, tea_CELoss: 0.7299, stu_CELoss: 0.8929, DMLLoss: 0.1809, 
2022-08-01 22:12:07 - train: epoch 0061, iter [00400, 05004], lr: 0.001000, loss: 2.5168, tea_CELoss: 1.1036, stu_CELoss: 1.2172, DMLLoss: 0.1960, 
2022-08-01 22:13:04 - train: epoch 0061, iter [00500, 05004], lr: 0.001000, loss: 2.1884, tea_CELoss: 0.9540, stu_CELoss: 1.0668, DMLLoss: 0.1676, 
2022-08-01 22:14:01 - train: epoch 0061, iter [00600, 05004], lr: 0.001000, loss: 1.9939, tea_CELoss: 0.8772, stu_CELoss: 0.9599, DMLLoss: 0.1568, 
2022-08-01 22:14:58 - train: epoch 0061, iter [00700, 05004], lr: 0.001000, loss: 1.7572, tea_CELoss: 0.7298, stu_CELoss: 0.8786, DMLLoss: 0.1488, 
2022-08-01 22:15:55 - train: epoch 0061, iter [00800, 05004], lr: 0.001000, loss: 2.0871, tea_CELoss: 0.8726, stu_CELoss: 1.0324, DMLLoss: 0.1821, 
2022-08-01 22:16:52 - train: epoch 0061, iter [00900, 05004], lr: 0.001000, loss: 1.7074, tea_CELoss: 0.7229, stu_CELoss: 0.8365, DMLLoss: 0.1480, 
2022-08-01 22:17:49 - train: epoch 0061, iter [01000, 05004], lr: 0.001000, loss: 1.6876, tea_CELoss: 0.6878, stu_CELoss: 0.8091, DMLLoss: 0.1908, 
2022-08-01 22:18:46 - train: epoch 0061, iter [01100, 05004], lr: 0.001000, loss: 1.9282, tea_CELoss: 0.8247, stu_CELoss: 0.9312, DMLLoss: 0.1723, 
2022-08-01 22:19:43 - train: epoch 0061, iter [01200, 05004], lr: 0.001000, loss: 1.7724, tea_CELoss: 0.7742, stu_CELoss: 0.8568, DMLLoss: 0.1414, 
2022-08-01 22:20:40 - train: epoch 0061, iter [01300, 05004], lr: 0.001000, loss: 2.3089, tea_CELoss: 1.0375, stu_CELoss: 1.1016, DMLLoss: 0.1698, 
2022-08-01 22:21:37 - train: epoch 0061, iter [01400, 05004], lr: 0.001000, loss: 2.0414, tea_CELoss: 0.8638, stu_CELoss: 0.9982, DMLLoss: 0.1794, 
2022-08-01 22:22:34 - train: epoch 0061, iter [01500, 05004], lr: 0.001000, loss: 2.1952, tea_CELoss: 0.9539, stu_CELoss: 1.0801, DMLLoss: 0.1612, 
2022-08-01 22:23:31 - train: epoch 0061, iter [01600, 05004], lr: 0.001000, loss: 1.9740, tea_CELoss: 0.8546, stu_CELoss: 0.9624, DMLLoss: 0.1570, 
2022-08-01 22:24:28 - train: epoch 0061, iter [01700, 05004], lr: 0.001000, loss: 1.9383, tea_CELoss: 0.8119, stu_CELoss: 0.9328, DMLLoss: 0.1936, 
2022-08-01 22:25:25 - train: epoch 0061, iter [01800, 05004], lr: 0.001000, loss: 1.9483, tea_CELoss: 0.8445, stu_CELoss: 0.9437, DMLLoss: 0.1601, 
2022-08-01 22:26:22 - train: epoch 0061, iter [01900, 05004], lr: 0.001000, loss: 2.4685, tea_CELoss: 1.0872, stu_CELoss: 1.1867, DMLLoss: 0.1946, 
2022-08-01 22:27:19 - train: epoch 0061, iter [02000, 05004], lr: 0.001000, loss: 1.9355, tea_CELoss: 0.7881, stu_CELoss: 0.9681, DMLLoss: 0.1792, 
2022-08-01 22:28:16 - train: epoch 0061, iter [02100, 05004], lr: 0.001000, loss: 1.9764, tea_CELoss: 0.8276, stu_CELoss: 0.9822, DMLLoss: 0.1665, 
2022-08-01 22:29:13 - train: epoch 0061, iter [02200, 05004], lr: 0.001000, loss: 1.9633, tea_CELoss: 0.8417, stu_CELoss: 0.9817, DMLLoss: 0.1399, 
2022-08-01 22:30:10 - train: epoch 0061, iter [02300, 05004], lr: 0.001000, loss: 2.2262, tea_CELoss: 0.9518, stu_CELoss: 1.1224, DMLLoss: 0.1520, 
2022-08-01 22:31:07 - train: epoch 0061, iter [02400, 05004], lr: 0.001000, loss: 1.8921, tea_CELoss: 0.8177, stu_CELoss: 0.9187, DMLLoss: 0.1557, 
2022-08-01 22:32:04 - train: epoch 0061, iter [02500, 05004], lr: 0.001000, loss: 1.9078, tea_CELoss: 0.8409, stu_CELoss: 0.9253, DMLLoss: 0.1416, 
2022-08-01 22:33:02 - train: epoch 0061, iter [02600, 05004], lr: 0.001000, loss: 1.8272, tea_CELoss: 0.7626, stu_CELoss: 0.9069, DMLLoss: 0.1577, 
2022-08-01 22:33:59 - train: epoch 0061, iter [02700, 05004], lr: 0.001000, loss: 2.2465, tea_CELoss: 0.9825, stu_CELoss: 1.0962, DMLLoss: 0.1678, 
2022-08-01 22:34:56 - train: epoch 0061, iter [02800, 05004], lr: 0.001000, loss: 1.9373, tea_CELoss: 0.8278, stu_CELoss: 0.9543, DMLLoss: 0.1552, 
2022-08-01 22:35:53 - train: epoch 0061, iter [02900, 05004], lr: 0.001000, loss: 2.2765, tea_CELoss: 0.9640, stu_CELoss: 1.1375, DMLLoss: 0.1750, 
2022-08-01 22:36:50 - train: epoch 0061, iter [03000, 05004], lr: 0.001000, loss: 1.8071, tea_CELoss: 0.7221, stu_CELoss: 0.8938, DMLLoss: 0.1912, 
2022-08-01 22:37:48 - train: epoch 0061, iter [03100, 05004], lr: 0.001000, loss: 1.6931, tea_CELoss: 0.7109, stu_CELoss: 0.8311, DMLLoss: 0.1511, 
2022-08-01 22:38:45 - train: epoch 0061, iter [03200, 05004], lr: 0.001000, loss: 1.7229, tea_CELoss: 0.7294, stu_CELoss: 0.8469, DMLLoss: 0.1466, 
2022-08-01 22:39:43 - train: epoch 0061, iter [03300, 05004], lr: 0.001000, loss: 1.9587, tea_CELoss: 0.8129, stu_CELoss: 0.9771, DMLLoss: 0.1687, 
2022-08-01 22:40:40 - train: epoch 0061, iter [03400, 05004], lr: 0.001000, loss: 1.7934, tea_CELoss: 0.7385, stu_CELoss: 0.8954, DMLLoss: 0.1596, 
2022-08-01 22:41:37 - train: epoch 0061, iter [03500, 05004], lr: 0.001000, loss: 2.1815, tea_CELoss: 0.9387, stu_CELoss: 1.0857, DMLLoss: 0.1570, 
2022-08-01 22:42:34 - train: epoch 0061, iter [03600, 05004], lr: 0.001000, loss: 1.8864, tea_CELoss: 0.8105, stu_CELoss: 0.9338, DMLLoss: 0.1420, 
2022-08-01 22:43:32 - train: epoch 0061, iter [03700, 05004], lr: 0.001000, loss: 2.0351, tea_CELoss: 0.8415, stu_CELoss: 1.0286, DMLLoss: 0.1649, 
2022-08-01 22:44:29 - train: epoch 0061, iter [03800, 05004], lr: 0.001000, loss: 2.0340, tea_CELoss: 0.8556, stu_CELoss: 1.0176, DMLLoss: 0.1608, 
2022-08-01 22:45:27 - train: epoch 0061, iter [03900, 05004], lr: 0.001000, loss: 1.9389, tea_CELoss: 0.8239, stu_CELoss: 0.9633, DMLLoss: 0.1517, 
2022-08-01 22:46:24 - train: epoch 0061, iter [04000, 05004], lr: 0.001000, loss: 2.4512, tea_CELoss: 1.0576, stu_CELoss: 1.2157, DMLLoss: 0.1780, 
2022-08-01 22:47:22 - train: epoch 0061, iter [04100, 05004], lr: 0.001000, loss: 2.2039, tea_CELoss: 0.9535, stu_CELoss: 1.0922, DMLLoss: 0.1582, 
2022-08-01 22:48:19 - train: epoch 0061, iter [04200, 05004], lr: 0.001000, loss: 2.0052, tea_CELoss: 0.8864, stu_CELoss: 0.9582, DMLLoss: 0.1606, 
2022-08-01 22:49:17 - train: epoch 0061, iter [04300, 05004], lr: 0.001000, loss: 1.9487, tea_CELoss: 0.8682, stu_CELoss: 0.9403, DMLLoss: 0.1402, 
2022-08-01 22:50:14 - train: epoch 0061, iter [04400, 05004], lr: 0.001000, loss: 2.3951, tea_CELoss: 1.0204, stu_CELoss: 1.1759, DMLLoss: 0.1987, 
2022-08-01 22:51:11 - train: epoch 0061, iter [04500, 05004], lr: 0.001000, loss: 1.8206, tea_CELoss: 0.7372, stu_CELoss: 0.9065, DMLLoss: 0.1770, 
2022-08-01 22:52:08 - train: epoch 0061, iter [04600, 05004], lr: 0.001000, loss: 1.8862, tea_CELoss: 0.7868, stu_CELoss: 0.9493, DMLLoss: 0.1501, 
2022-08-01 22:53:06 - train: epoch 0061, iter [04700, 05004], lr: 0.001000, loss: 1.6550, tea_CELoss: 0.7244, stu_CELoss: 0.8094, DMLLoss: 0.1212, 
2022-08-01 22:54:03 - train: epoch 0061, iter [04800, 05004], lr: 0.001000, loss: 2.0416, tea_CELoss: 0.8954, stu_CELoss: 1.0159, DMLLoss: 0.1303, 
2022-08-01 22:55:01 - train: epoch 0061, iter [04900, 05004], lr: 0.001000, loss: 1.9216, tea_CELoss: 0.8187, stu_CELoss: 0.9512, DMLLoss: 0.1517, 
2022-08-01 22:55:58 - train: epoch 0061, iter [05000, 05004], lr: 0.001000, loss: 2.3451, tea_CELoss: 1.0155, stu_CELoss: 1.1456, DMLLoss: 0.1840, 
2022-08-01 22:56:01 - train: epoch 061, train_loss: 1.9966
2022-08-01 22:58:35 - eval: epoch: 061, tea_acc1: 77.904%, tea_acc5: 93.902%, tea_test_loss: 0.8578, stu_acc1: 76.044%, stu_acc5: 92.998%, stu_test_loss: 0.9388
2022-08-01 22:58:36 - until epoch: 061, tea_best_acc1: 77.904%, stu_best_acc1: 76.044%
2022-08-01 22:58:36 - epoch 062 lr: 0.001000
2022-08-01 22:59:40 - train: epoch 0062, iter [00100, 05004], lr: 0.001000, loss: 2.0105, tea_CELoss: 0.8559, stu_CELoss: 0.9859, DMLLoss: 0.1687, 
2022-08-01 23:00:37 - train: epoch 0062, iter [00200, 05004], lr: 0.001000, loss: 2.1672, tea_CELoss: 0.9441, stu_CELoss: 1.0614, DMLLoss: 0.1617, 
2022-08-01 23:01:35 - train: epoch 0062, iter [00300, 05004], lr: 0.001000, loss: 2.2336, tea_CELoss: 0.9358, stu_CELoss: 1.1045, DMLLoss: 0.1932, 
2022-08-01 23:02:32 - train: epoch 0062, iter [00400, 05004], lr: 0.001000, loss: 2.0341, tea_CELoss: 0.8920, stu_CELoss: 0.9858, DMLLoss: 0.1563, 
2022-08-01 23:03:30 - train: epoch 0062, iter [00500, 05004], lr: 0.001000, loss: 1.6847, tea_CELoss: 0.6814, stu_CELoss: 0.8307, DMLLoss: 0.1725, 
2022-08-01 23:04:27 - train: epoch 0062, iter [00600, 05004], lr: 0.001000, loss: 1.7820, tea_CELoss: 0.7451, stu_CELoss: 0.8923, DMLLoss: 0.1446, 
2022-08-01 23:05:25 - train: epoch 0062, iter [00700, 05004], lr: 0.001000, loss: 2.0637, tea_CELoss: 0.8929, stu_CELoss: 1.0214, DMLLoss: 0.1495, 
2022-08-01 23:06:22 - train: epoch 0062, iter [00800, 05004], lr: 0.001000, loss: 2.1760, tea_CELoss: 0.9188, stu_CELoss: 1.0799, DMLLoss: 0.1773, 
2022-08-01 23:07:20 - train: epoch 0062, iter [00900, 05004], lr: 0.001000, loss: 2.0633, tea_CELoss: 0.8660, stu_CELoss: 1.0191, DMLLoss: 0.1782, 
2022-08-01 23:08:18 - train: epoch 0062, iter [01000, 05004], lr: 0.001000, loss: 2.1997, tea_CELoss: 0.9114, stu_CELoss: 1.1049, DMLLoss: 0.1833, 
2022-08-01 23:09:15 - train: epoch 0062, iter [01100, 05004], lr: 0.001000, loss: 1.4597, tea_CELoss: 0.6004, stu_CELoss: 0.7123, DMLLoss: 0.1470, 
2022-08-01 23:10:12 - train: epoch 0062, iter [01200, 05004], lr: 0.001000, loss: 2.0783, tea_CELoss: 0.9049, stu_CELoss: 1.0241, DMLLoss: 0.1494, 
2022-08-01 23:11:10 - train: epoch 0062, iter [01300, 05004], lr: 0.001000, loss: 1.6190, tea_CELoss: 0.7110, stu_CELoss: 0.7789, DMLLoss: 0.1291, 
2022-08-01 23:12:08 - train: epoch 0062, iter [01400, 05004], lr: 0.001000, loss: 1.5790, tea_CELoss: 0.6812, stu_CELoss: 0.7594, DMLLoss: 0.1384, 
2022-08-01 23:13:05 - train: epoch 0062, iter [01500, 05004], lr: 0.001000, loss: 1.7611, tea_CELoss: 0.7161, stu_CELoss: 0.8881, DMLLoss: 0.1569, 
2022-08-01 23:14:03 - train: epoch 0062, iter [01600, 05004], lr: 0.001000, loss: 2.0090, tea_CELoss: 0.8226, stu_CELoss: 1.0322, DMLLoss: 0.1543, 
2022-08-01 23:15:01 - train: epoch 0062, iter [01700, 05004], lr: 0.001000, loss: 1.7669, tea_CELoss: 0.7530, stu_CELoss: 0.8746, DMLLoss: 0.1393, 
2022-08-01 23:15:58 - train: epoch 0062, iter [01800, 05004], lr: 0.001000, loss: 1.8066, tea_CELoss: 0.8155, stu_CELoss: 0.8464, DMLLoss: 0.1447, 
2022-08-01 23:16:56 - train: epoch 0062, iter [01900, 05004], lr: 0.001000, loss: 1.5876, tea_CELoss: 0.6422, stu_CELoss: 0.7968, DMLLoss: 0.1485, 
2022-08-01 23:17:54 - train: epoch 0062, iter [02000, 05004], lr: 0.001000, loss: 2.0142, tea_CELoss: 0.8506, stu_CELoss: 1.0152, DMLLoss: 0.1485, 
2022-08-01 23:18:51 - train: epoch 0062, iter [02100, 05004], lr: 0.001000, loss: 2.1327, tea_CELoss: 0.9022, stu_CELoss: 1.0649, DMLLoss: 0.1656, 
2022-08-01 23:19:49 - train: epoch 0062, iter [02200, 05004], lr: 0.001000, loss: 1.7318, tea_CELoss: 0.7462, stu_CELoss: 0.8463, DMLLoss: 0.1392, 
2022-08-01 23:20:47 - train: epoch 0062, iter [02300, 05004], lr: 0.001000, loss: 1.8814, tea_CELoss: 0.7872, stu_CELoss: 0.9324, DMLLoss: 0.1619, 
2022-08-01 23:21:44 - train: epoch 0062, iter [02400, 05004], lr: 0.001000, loss: 1.9678, tea_CELoss: 0.8269, stu_CELoss: 0.9635, DMLLoss: 0.1774, 
2022-08-01 23:22:42 - train: epoch 0062, iter [02500, 05004], lr: 0.001000, loss: 2.0579, tea_CELoss: 0.8823, stu_CELoss: 1.0059, DMLLoss: 0.1697, 
2022-08-01 23:23:40 - train: epoch 0062, iter [02600, 05004], lr: 0.001000, loss: 1.7641, tea_CELoss: 0.7388, stu_CELoss: 0.8735, DMLLoss: 0.1518, 
2022-08-01 23:24:38 - train: epoch 0062, iter [02700, 05004], lr: 0.001000, loss: 1.8839, tea_CELoss: 0.8495, stu_CELoss: 0.9111, DMLLoss: 0.1233, 
2022-08-01 23:25:36 - train: epoch 0062, iter [02800, 05004], lr: 0.001000, loss: 1.9906, tea_CELoss: 0.8425, stu_CELoss: 0.9925, DMLLoss: 0.1556, 
2022-08-01 23:26:33 - train: epoch 0062, iter [02900, 05004], lr: 0.001000, loss: 1.9281, tea_CELoss: 0.8086, stu_CELoss: 0.9432, DMLLoss: 0.1764, 
2022-08-01 23:27:31 - train: epoch 0062, iter [03000, 05004], lr: 0.001000, loss: 2.0628, tea_CELoss: 0.8646, stu_CELoss: 1.0385, DMLLoss: 0.1597, 
2022-08-01 23:28:29 - train: epoch 0062, iter [03100, 05004], lr: 0.001000, loss: 2.0106, tea_CELoss: 0.8572, stu_CELoss: 0.9759, DMLLoss: 0.1775, 
2022-08-01 23:29:27 - train: epoch 0062, iter [03200, 05004], lr: 0.001000, loss: 1.4279, tea_CELoss: 0.5884, stu_CELoss: 0.7171, DMLLoss: 0.1225, 
2022-08-01 23:30:24 - train: epoch 0062, iter [03300, 05004], lr: 0.001000, loss: 2.0536, tea_CELoss: 0.8840, stu_CELoss: 1.0118, DMLLoss: 0.1579, 
2022-08-01 23:31:22 - train: epoch 0062, iter [03400, 05004], lr: 0.001000, loss: 1.6303, tea_CELoss: 0.6729, stu_CELoss: 0.8119, DMLLoss: 0.1455, 
2022-08-01 23:32:20 - train: epoch 0062, iter [03500, 05004], lr: 0.001000, loss: 2.0269, tea_CELoss: 0.8050, stu_CELoss: 1.0462, DMLLoss: 0.1757, 
2022-08-01 23:33:18 - train: epoch 0062, iter [03600, 05004], lr: 0.001000, loss: 1.9255, tea_CELoss: 0.8246, stu_CELoss: 0.9453, DMLLoss: 0.1556, 
2022-08-01 23:34:16 - train: epoch 0062, iter [03700, 05004], lr: 0.001000, loss: 1.9160, tea_CELoss: 0.8200, stu_CELoss: 0.9423, DMLLoss: 0.1537, 
2022-08-01 23:35:13 - train: epoch 0062, iter [03800, 05004], lr: 0.001000, loss: 1.8448, tea_CELoss: 0.7829, stu_CELoss: 0.9117, DMLLoss: 0.1501, 
2022-08-01 23:36:11 - train: epoch 0062, iter [03900, 05004], lr: 0.001000, loss: 1.9316, tea_CELoss: 0.8267, stu_CELoss: 0.9773, DMLLoss: 0.1276, 
2022-08-01 23:37:09 - train: epoch 0062, iter [04000, 05004], lr: 0.001000, loss: 1.8032, tea_CELoss: 0.7675, stu_CELoss: 0.8905, DMLLoss: 0.1453, 
2022-08-01 23:38:06 - train: epoch 0062, iter [04100, 05004], lr: 0.001000, loss: 1.7130, tea_CELoss: 0.7138, stu_CELoss: 0.8562, DMLLoss: 0.1430, 
2022-08-01 23:39:04 - train: epoch 0062, iter [04200, 05004], lr: 0.001000, loss: 1.9143, tea_CELoss: 0.8234, stu_CELoss: 0.9478, DMLLoss: 0.1430, 
2022-08-01 23:40:02 - train: epoch 0062, iter [04300, 05004], lr: 0.001000, loss: 1.7245, tea_CELoss: 0.7409, stu_CELoss: 0.8270, DMLLoss: 0.1566, 
2022-08-01 23:40:59 - train: epoch 0062, iter [04400, 05004], lr: 0.001000, loss: 2.2106, tea_CELoss: 0.9505, stu_CELoss: 1.1078, DMLLoss: 0.1523, 
2022-08-01 23:41:57 - train: epoch 0062, iter [04500, 05004], lr: 0.001000, loss: 2.0885, tea_CELoss: 0.8974, stu_CELoss: 1.0257, DMLLoss: 0.1654, 
2022-08-01 23:42:55 - train: epoch 0062, iter [04600, 05004], lr: 0.001000, loss: 1.7152, tea_CELoss: 0.7172, stu_CELoss: 0.8477, DMLLoss: 0.1502, 
2022-08-01 23:43:53 - train: epoch 0062, iter [04700, 05004], lr: 0.001000, loss: 1.8046, tea_CELoss: 0.7422, stu_CELoss: 0.9228, DMLLoss: 0.1396, 
2022-08-01 23:44:51 - train: epoch 0062, iter [04800, 05004], lr: 0.001000, loss: 1.8272, tea_CELoss: 0.7554, stu_CELoss: 0.9108, DMLLoss: 0.1609, 
2022-08-01 23:45:49 - train: epoch 0062, iter [04900, 05004], lr: 0.001000, loss: 1.6050, tea_CELoss: 0.6723, stu_CELoss: 0.8052, DMLLoss: 0.1275, 
2022-08-01 23:46:46 - train: epoch 0062, iter [05000, 05004], lr: 0.001000, loss: 1.8934, tea_CELoss: 0.8178, stu_CELoss: 0.9081, DMLLoss: 0.1676, 
2022-08-01 23:46:49 - train: epoch 062, train_loss: 1.8927
2022-08-01 23:49:20 - eval: epoch: 062, tea_acc1: 78.080%, tea_acc5: 94.024%, tea_test_loss: 0.8468, stu_acc1: 76.402%, stu_acc5: 93.148%, stu_test_loss: 0.9269
2022-08-01 23:49:22 - until epoch: 062, tea_best_acc1: 78.080%, stu_best_acc1: 76.402%
2022-08-01 23:49:22 - epoch 063 lr: 0.001000
2022-08-01 23:50:25 - train: epoch 0063, iter [00100, 05004], lr: 0.001000, loss: 1.7182, tea_CELoss: 0.7166, stu_CELoss: 0.8579, DMLLoss: 0.1437, 
2022-08-01 23:51:23 - train: epoch 0063, iter [00200, 05004], lr: 0.001000, loss: 2.0162, tea_CELoss: 0.8628, stu_CELoss: 0.9841, DMLLoss: 0.1693, 
2022-08-01 23:52:21 - train: epoch 0063, iter [00300, 05004], lr: 0.001000, loss: 1.7964, tea_CELoss: 0.7091, stu_CELoss: 0.9222, DMLLoss: 0.1651, 
2022-08-01 23:53:18 - train: epoch 0063, iter [00400, 05004], lr: 0.001000, loss: 1.7400, tea_CELoss: 0.7682, stu_CELoss: 0.8513, DMLLoss: 0.1206, 
2022-08-01 23:54:15 - train: epoch 0063, iter [00500, 05004], lr: 0.001000, loss: 1.6723, tea_CELoss: 0.7232, stu_CELoss: 0.8120, DMLLoss: 0.1372, 
2022-08-01 23:55:13 - train: epoch 0063, iter [00600, 05004], lr: 0.001000, loss: 1.8557, tea_CELoss: 0.7736, stu_CELoss: 0.9311, DMLLoss: 0.1510, 
2022-08-01 23:56:10 - train: epoch 0063, iter [00700, 05004], lr: 0.001000, loss: 1.7540, tea_CELoss: 0.7302, stu_CELoss: 0.8509, DMLLoss: 0.1729, 
2022-08-01 23:57:08 - train: epoch 0063, iter [00800, 05004], lr: 0.001000, loss: 1.7780, tea_CELoss: 0.7456, stu_CELoss: 0.8985, DMLLoss: 0.1339, 
2022-08-01 23:58:05 - train: epoch 0063, iter [00900, 05004], lr: 0.001000, loss: 1.8559, tea_CELoss: 0.7880, stu_CELoss: 0.9148, DMLLoss: 0.1531, 
2022-08-01 23:59:02 - train: epoch 0063, iter [01000, 05004], lr: 0.001000, loss: 1.8834, tea_CELoss: 0.8084, stu_CELoss: 0.9289, DMLLoss: 0.1461, 
2022-08-01 23:59:59 - train: epoch 0063, iter [01100, 05004], lr: 0.001000, loss: 1.8780, tea_CELoss: 0.7711, stu_CELoss: 0.9476, DMLLoss: 0.1594, 
