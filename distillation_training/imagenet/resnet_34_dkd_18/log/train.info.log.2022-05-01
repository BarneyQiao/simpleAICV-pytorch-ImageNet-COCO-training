2022-05-01 17:02:36 - teacher: resnet34
2022-05-01 17:02:36 - student: resnet18
2022-05-01 17:02:36 - num_classes: 1000
2022-05-01 17:02:36 - input_image_size: 224
2022-05-01 17:02:36 - scale: 1.1428571428571428
2022-05-01 17:02:36 - teacher_pretrained_model_path: /root/code/simpleAICV-pytorch-ImageNet-COCO-training/pretrained_models/resnet/resnet34-acc73.930.pth
2022-05-01 17:02:36 - student_pretrained_model_path: 
2022-05-01 17:02:36 - freeze_teacher: True
2022-05-01 17:02:36 - loss_list: ['CELoss', 'DKDLoss']
2022-05-01 17:02:36 - alpha: 1.0
2022-05-01 17:02:36 - beta: 0.5
2022-05-01 17:02:36 - T: 1.0
2022-05-01 17:02:36 - train_criterion: {'CELoss': CELoss(
  (loss): CrossEntropyLoss()
), 'DKDLoss': DKDLoss()}
2022-05-01 17:02:36 - loss_name: DKDLoss
2022-05-01 17:02:36 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2022-05-01 17:02:36 - train_dataset: <simpleAICV.classification.datasets.ilsvrc2012dataset.ILSVRC2012Dataset object at 0x7f983c1c2880>
2022-05-01 17:02:36 - val_dataset: <simpleAICV.classification.datasets.ilsvrc2012dataset.ILSVRC2012Dataset object at 0x7f983c1c2b50>
2022-05-01 17:02:36 - collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f983c1c2b80>
2022-05-01 17:02:36 - seed: 0
2022-05-01 17:02:36 - batch_size: 256
2022-05-01 17:02:36 - num_workers: 16
2022-05-01 17:02:36 - optimizer: ('SGD', {'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0001})
2022-05-01 17:02:36 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.1, 'milestones': [30, 60, 90]})
2022-05-01 17:02:36 - epochs: 100
2022-05-01 17:02:36 - print_interval: 100
2022-05-01 17:02:36 - sync_bn: False
2022-05-01 17:02:36 - apex: True
2022-05-01 17:02:36 - gpus_type: NVIDIA RTX A5000
2022-05-01 17:02:36 - gpus_num: 2
2022-05-01 17:02:36 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f9819a454f0>
2022-05-01 17:02:36 - --------------------parameters--------------------
2022-05-01 17:02:36 - name: teacher.conv1.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.conv1.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.conv1.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.0.conv1.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.0.conv1.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.0.conv1.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.0.conv2.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.0.conv2.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.0.conv2.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.1.conv1.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.1.conv1.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.1.conv1.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.1.conv2.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.1.conv2.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.1.conv2.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.2.conv1.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.2.conv1.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.2.conv1.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.2.conv2.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.2.conv2.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.2.conv2.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.0.conv1.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.0.conv1.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.0.conv1.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.0.conv2.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.0.conv2.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.0.conv2.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.0.downsample_conv.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.0.downsample_conv.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.0.downsample_conv.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.1.conv1.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.1.conv1.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.1.conv1.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.1.conv2.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.1.conv2.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.1.conv2.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.2.conv1.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.2.conv1.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.2.conv1.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.2.conv2.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.2.conv2.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.2.conv2.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.3.conv1.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.3.conv1.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.3.conv1.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.3.conv2.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.3.conv2.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.3.conv2.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.0.conv1.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.0.conv1.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.0.conv1.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.0.conv2.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.0.conv2.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.0.conv2.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.0.downsample_conv.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.0.downsample_conv.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.0.downsample_conv.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.1.conv1.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.1.conv1.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.1.conv1.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.1.conv2.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.1.conv2.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.1.conv2.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.2.conv1.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.2.conv1.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.2.conv1.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.2.conv2.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.2.conv2.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.2.conv2.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.3.conv1.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.3.conv1.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.3.conv1.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.3.conv2.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.3.conv2.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.3.conv2.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.4.conv1.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.4.conv1.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.4.conv1.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.4.conv2.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.4.conv2.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.4.conv2.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.5.conv1.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.5.conv1.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.5.conv1.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.5.conv2.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.5.conv2.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.5.conv2.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.0.conv1.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.0.conv1.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.0.conv1.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.0.conv2.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.0.conv2.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.0.conv2.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.0.downsample_conv.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.0.downsample_conv.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.0.downsample_conv.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.1.conv1.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.1.conv1.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.1.conv1.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.1.conv2.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.1.conv2.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.1.conv2.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.2.conv1.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.2.conv1.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.2.conv1.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.2.conv2.layer.0.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.2.conv2.layer.1.weight, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.2.conv2.layer.1.bias, grad: False
2022-05-01 17:02:36 - name: teacher.fc.weight, grad: False
2022-05-01 17:02:36 - name: teacher.fc.bias, grad: False
2022-05-01 17:02:36 - name: student.conv1.layer.0.weight, grad: True
2022-05-01 17:02:36 - name: student.conv1.layer.1.weight, grad: True
2022-05-01 17:02:36 - name: student.conv1.layer.1.bias, grad: True
2022-05-01 17:02:36 - name: student.layer1.0.conv1.layer.0.weight, grad: True
2022-05-01 17:02:36 - name: student.layer1.0.conv1.layer.1.weight, grad: True
2022-05-01 17:02:36 - name: student.layer1.0.conv1.layer.1.bias, grad: True
2022-05-01 17:02:36 - name: student.layer1.0.conv2.layer.0.weight, grad: True
2022-05-01 17:02:36 - name: student.layer1.0.conv2.layer.1.weight, grad: True
2022-05-01 17:02:36 - name: student.layer1.0.conv2.layer.1.bias, grad: True
2022-05-01 17:02:36 - name: student.layer1.1.conv1.layer.0.weight, grad: True
2022-05-01 17:02:36 - name: student.layer1.1.conv1.layer.1.weight, grad: True
2022-05-01 17:02:36 - name: student.layer1.1.conv1.layer.1.bias, grad: True
2022-05-01 17:02:36 - name: student.layer1.1.conv2.layer.0.weight, grad: True
2022-05-01 17:02:36 - name: student.layer1.1.conv2.layer.1.weight, grad: True
2022-05-01 17:02:36 - name: student.layer1.1.conv2.layer.1.bias, grad: True
2022-05-01 17:02:36 - name: student.layer2.0.conv1.layer.0.weight, grad: True
2022-05-01 17:02:36 - name: student.layer2.0.conv1.layer.1.weight, grad: True
2022-05-01 17:02:36 - name: student.layer2.0.conv1.layer.1.bias, grad: True
2022-05-01 17:02:36 - name: student.layer2.0.conv2.layer.0.weight, grad: True
2022-05-01 17:02:36 - name: student.layer2.0.conv2.layer.1.weight, grad: True
2022-05-01 17:02:36 - name: student.layer2.0.conv2.layer.1.bias, grad: True
2022-05-01 17:02:36 - name: student.layer2.0.downsample_conv.layer.0.weight, grad: True
2022-05-01 17:02:36 - name: student.layer2.0.downsample_conv.layer.1.weight, grad: True
2022-05-01 17:02:36 - name: student.layer2.0.downsample_conv.layer.1.bias, grad: True
2022-05-01 17:02:36 - name: student.layer2.1.conv1.layer.0.weight, grad: True
2022-05-01 17:02:36 - name: student.layer2.1.conv1.layer.1.weight, grad: True
2022-05-01 17:02:36 - name: student.layer2.1.conv1.layer.1.bias, grad: True
2022-05-01 17:02:36 - name: student.layer2.1.conv2.layer.0.weight, grad: True
2022-05-01 17:02:36 - name: student.layer2.1.conv2.layer.1.weight, grad: True
2022-05-01 17:02:36 - name: student.layer2.1.conv2.layer.1.bias, grad: True
2022-05-01 17:02:36 - name: student.layer3.0.conv1.layer.0.weight, grad: True
2022-05-01 17:02:36 - name: student.layer3.0.conv1.layer.1.weight, grad: True
2022-05-01 17:02:36 - name: student.layer3.0.conv1.layer.1.bias, grad: True
2022-05-01 17:02:36 - name: student.layer3.0.conv2.layer.0.weight, grad: True
2022-05-01 17:02:36 - name: student.layer3.0.conv2.layer.1.weight, grad: True
2022-05-01 17:02:36 - name: student.layer3.0.conv2.layer.1.bias, grad: True
2022-05-01 17:02:36 - name: student.layer3.0.downsample_conv.layer.0.weight, grad: True
2022-05-01 17:02:36 - name: student.layer3.0.downsample_conv.layer.1.weight, grad: True
2022-05-01 17:02:36 - name: student.layer3.0.downsample_conv.layer.1.bias, grad: True
2022-05-01 17:02:36 - name: student.layer3.1.conv1.layer.0.weight, grad: True
2022-05-01 17:02:36 - name: student.layer3.1.conv1.layer.1.weight, grad: True
2022-05-01 17:02:36 - name: student.layer3.1.conv1.layer.1.bias, grad: True
2022-05-01 17:02:36 - name: student.layer3.1.conv2.layer.0.weight, grad: True
2022-05-01 17:02:36 - name: student.layer3.1.conv2.layer.1.weight, grad: True
2022-05-01 17:02:36 - name: student.layer3.1.conv2.layer.1.bias, grad: True
2022-05-01 17:02:36 - name: student.layer4.0.conv1.layer.0.weight, grad: True
2022-05-01 17:02:36 - name: student.layer4.0.conv1.layer.1.weight, grad: True
2022-05-01 17:02:36 - name: student.layer4.0.conv1.layer.1.bias, grad: True
2022-05-01 17:02:36 - name: student.layer4.0.conv2.layer.0.weight, grad: True
2022-05-01 17:02:36 - name: student.layer4.0.conv2.layer.1.weight, grad: True
2022-05-01 17:02:36 - name: student.layer4.0.conv2.layer.1.bias, grad: True
2022-05-01 17:02:36 - name: student.layer4.0.downsample_conv.layer.0.weight, grad: True
2022-05-01 17:02:36 - name: student.layer4.0.downsample_conv.layer.1.weight, grad: True
2022-05-01 17:02:36 - name: student.layer4.0.downsample_conv.layer.1.bias, grad: True
2022-05-01 17:02:36 - name: student.layer4.1.conv1.layer.0.weight, grad: True
2022-05-01 17:02:36 - name: student.layer4.1.conv1.layer.1.weight, grad: True
2022-05-01 17:02:36 - name: student.layer4.1.conv1.layer.1.bias, grad: True
2022-05-01 17:02:36 - name: student.layer4.1.conv2.layer.0.weight, grad: True
2022-05-01 17:02:36 - name: student.layer4.1.conv2.layer.1.weight, grad: True
2022-05-01 17:02:36 - name: student.layer4.1.conv2.layer.1.bias, grad: True
2022-05-01 17:02:36 - name: student.fc.weight, grad: True
2022-05-01 17:02:36 - name: student.fc.bias, grad: True
2022-05-01 17:02:36 - --------------------buffers--------------------
2022-05-01 17:02:36 - name: teacher.conv1.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.conv1.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.conv1.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.0.conv1.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.0.conv1.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.0.conv2.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.0.conv2.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.1.conv1.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.1.conv1.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.1.conv2.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.1.conv2.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.2.conv1.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.2.conv1.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.2.conv1.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.2.conv2.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.2.conv2.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer1.2.conv2.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.0.conv1.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.0.conv1.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.0.conv2.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.0.conv2.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.0.downsample_conv.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.0.downsample_conv.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.1.conv1.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.1.conv1.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.1.conv2.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.1.conv2.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.2.conv1.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.2.conv1.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.2.conv1.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.2.conv2.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.2.conv2.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.2.conv2.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.3.conv1.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.3.conv1.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.3.conv1.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.3.conv2.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.3.conv2.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer2.3.conv2.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.0.conv1.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.0.conv1.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.0.conv2.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.0.conv2.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.0.downsample_conv.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.0.downsample_conv.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.1.conv1.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.1.conv1.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.1.conv2.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.1.conv2.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.2.conv1.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.2.conv1.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.2.conv1.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.2.conv2.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.2.conv2.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.2.conv2.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.3.conv1.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.3.conv1.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.3.conv1.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.3.conv2.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.3.conv2.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.3.conv2.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.4.conv1.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.4.conv1.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.4.conv1.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.4.conv2.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.4.conv2.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.4.conv2.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.5.conv1.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.5.conv1.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.5.conv1.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.5.conv2.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.5.conv2.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer3.5.conv2.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.0.conv1.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.0.conv1.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.0.conv2.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.0.conv2.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.0.downsample_conv.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.0.downsample_conv.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.1.conv1.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.1.conv1.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.1.conv2.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.1.conv2.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.2.conv1.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.2.conv1.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.2.conv1.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.2.conv2.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.2.conv2.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: teacher.layer4.2.conv2.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: student.conv1.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: student.conv1.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: student.conv1.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: student.layer1.0.conv1.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: student.layer1.0.conv1.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: student.layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: student.layer1.0.conv2.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: student.layer1.0.conv2.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: student.layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: student.layer1.1.conv1.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: student.layer1.1.conv1.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: student.layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: student.layer1.1.conv2.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: student.layer1.1.conv2.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: student.layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: student.layer2.0.conv1.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: student.layer2.0.conv1.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: student.layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: student.layer2.0.conv2.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: student.layer2.0.conv2.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: student.layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: student.layer2.0.downsample_conv.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: student.layer2.0.downsample_conv.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: student.layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: student.layer2.1.conv1.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: student.layer2.1.conv1.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: student.layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: student.layer2.1.conv2.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: student.layer2.1.conv2.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: student.layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: student.layer3.0.conv1.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: student.layer3.0.conv1.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: student.layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: student.layer3.0.conv2.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: student.layer3.0.conv2.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: student.layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: student.layer3.0.downsample_conv.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: student.layer3.0.downsample_conv.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: student.layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: student.layer3.1.conv1.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: student.layer3.1.conv1.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: student.layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: student.layer3.1.conv2.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: student.layer3.1.conv2.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: student.layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: student.layer4.0.conv1.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: student.layer4.0.conv1.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: student.layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: student.layer4.0.conv2.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: student.layer4.0.conv2.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: student.layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: student.layer4.0.downsample_conv.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: student.layer4.0.downsample_conv.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: student.layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: student.layer4.1.conv1.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: student.layer4.1.conv1.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: student.layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - name: student.layer4.1.conv2.layer.1.running_mean, grad: False
2022-05-01 17:02:36 - name: student.layer4.1.conv2.layer.1.running_var, grad: False
2022-05-01 17:02:36 - name: student.layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2022-05-01 17:02:36 - epoch 001 lr: 0.1
2022-05-01 17:03:16 - train: epoch 0001, iter [00100, 05004], lr: 0.100000, loss: 13.5834, stu_CELoss: 6.7487 DKDLoss: 6.8347 
2022-05-01 17:03:49 - train: epoch 0001, iter [00200, 05004], lr: 0.100000, loss: 13.3663, stu_CELoss: 6.5577 DKDLoss: 6.8086 
2022-05-01 17:04:23 - train: epoch 0001, iter [00300, 05004], lr: 0.100000, loss: 12.3745, stu_CELoss: 6.3649 DKDLoss: 6.0096 
2022-05-01 17:04:55 - train: epoch 0001, iter [00400, 05004], lr: 0.100000, loss: 12.3733, stu_CELoss: 6.2066 DKDLoss: 6.1667 
2022-05-01 17:05:28 - train: epoch 0001, iter [00500, 05004], lr: 0.100000, loss: 11.9468, stu_CELoss: 6.0406 DKDLoss: 5.9062 
2022-05-01 17:06:03 - train: epoch 0001, iter [00600, 05004], lr: 0.100000, loss: 11.3366, stu_CELoss: 5.7074 DKDLoss: 5.6292 
2022-05-01 17:06:35 - train: epoch 0001, iter [00700, 05004], lr: 0.100000, loss: 11.1444, stu_CELoss: 5.6987 DKDLoss: 5.4457 
2022-05-01 17:07:09 - train: epoch 0001, iter [00800, 05004], lr: 0.100000, loss: 11.0571, stu_CELoss: 5.7290 DKDLoss: 5.3282 
2022-05-01 17:07:42 - train: epoch 0001, iter [00900, 05004], lr: 0.100000, loss: 10.6264, stu_CELoss: 5.5833 DKDLoss: 5.0432 
2022-05-01 17:08:16 - train: epoch 0001, iter [01000, 05004], lr: 0.100000, loss: 10.5867, stu_CELoss: 5.4275 DKDLoss: 5.1591 
2022-05-01 17:08:48 - train: epoch 0001, iter [01100, 05004], lr: 0.100000, loss: 10.4045, stu_CELoss: 5.4492 DKDLoss: 4.9553 
2022-05-01 17:09:22 - train: epoch 0001, iter [01200, 05004], lr: 0.100000, loss: 10.2906, stu_CELoss: 5.2621 DKDLoss: 5.0286 
2022-05-01 17:09:54 - train: epoch 0001, iter [01300, 05004], lr: 0.100000, loss: 10.0307, stu_CELoss: 5.1721 DKDLoss: 4.8586 
2022-05-01 17:10:28 - train: epoch 0001, iter [01400, 05004], lr: 0.100000, loss: 9.9595, stu_CELoss: 5.1834 DKDLoss: 4.7761 
2022-05-01 17:11:01 - train: epoch 0001, iter [01500, 05004], lr: 0.100000, loss: 9.8669, stu_CELoss: 4.9718 DKDLoss: 4.8950 
2022-05-01 17:11:34 - train: epoch 0001, iter [01600, 05004], lr: 0.100000, loss: 9.7088, stu_CELoss: 5.0753 DKDLoss: 4.6335 
2022-05-01 17:12:08 - train: epoch 0001, iter [01700, 05004], lr: 0.100000, loss: 9.2978, stu_CELoss: 4.7967 DKDLoss: 4.5011 
2022-05-01 17:12:41 - train: epoch 0001, iter [01800, 05004], lr: 0.100000, loss: 9.3444, stu_CELoss: 4.9080 DKDLoss: 4.4364 
2022-05-01 17:13:15 - train: epoch 0001, iter [01900, 05004], lr: 0.100000, loss: 9.4097, stu_CELoss: 4.7514 DKDLoss: 4.6583 
2022-05-01 17:13:47 - train: epoch 0001, iter [02000, 05004], lr: 0.100000, loss: 8.8472, stu_CELoss: 4.5432 DKDLoss: 4.3040 
2022-05-01 17:14:20 - train: epoch 0001, iter [02100, 05004], lr: 0.100000, loss: 8.7773, stu_CELoss: 4.5993 DKDLoss: 4.1781 
2022-05-01 17:14:53 - train: epoch 0001, iter [02200, 05004], lr: 0.100000, loss: 8.8051, stu_CELoss: 4.5958 DKDLoss: 4.2093 
2022-05-01 17:15:26 - train: epoch 0001, iter [02300, 05004], lr: 0.100000, loss: 8.3836, stu_CELoss: 4.3817 DKDLoss: 4.0019 
2022-05-01 17:16:00 - train: epoch 0001, iter [02400, 05004], lr: 0.100000, loss: 8.3628, stu_CELoss: 4.3990 DKDLoss: 3.9639 
2022-05-01 17:16:33 - train: epoch 0001, iter [02500, 05004], lr: 0.100000, loss: 8.2607, stu_CELoss: 4.3985 DKDLoss: 3.8621 
2022-05-01 17:17:06 - train: epoch 0001, iter [02600, 05004], lr: 0.100000, loss: 8.6094, stu_CELoss: 4.6038 DKDLoss: 4.0056 
2022-05-01 17:17:39 - train: epoch 0001, iter [02700, 05004], lr: 0.100000, loss: 8.4249, stu_CELoss: 4.5473 DKDLoss: 3.8776 
2022-05-01 17:18:13 - train: epoch 0001, iter [02800, 05004], lr: 0.100000, loss: 7.9906, stu_CELoss: 4.2154 DKDLoss: 3.7752 
2022-05-01 17:18:45 - train: epoch 0001, iter [02900, 05004], lr: 0.100000, loss: 7.9153, stu_CELoss: 4.1730 DKDLoss: 3.7423 
2022-05-01 17:19:19 - train: epoch 0001, iter [03000, 05004], lr: 0.100000, loss: 7.9998, stu_CELoss: 4.2333 DKDLoss: 3.7666 
2022-05-01 17:19:51 - train: epoch 0001, iter [03100, 05004], lr: 0.100000, loss: 8.4254, stu_CELoss: 4.3810 DKDLoss: 4.0444 
2022-05-01 17:20:25 - train: epoch 0001, iter [03200, 05004], lr: 0.100000, loss: 7.6356, stu_CELoss: 4.1298 DKDLoss: 3.5057 
2022-05-01 17:20:59 - train: epoch 0001, iter [03300, 05004], lr: 0.100000, loss: 7.3264, stu_CELoss: 3.9236 DKDLoss: 3.4029 
2022-05-01 17:21:31 - train: epoch 0001, iter [03400, 05004], lr: 0.100000, loss: 7.4418, stu_CELoss: 3.9771 DKDLoss: 3.4646 
2022-05-01 17:22:06 - train: epoch 0001, iter [03500, 05004], lr: 0.100000, loss: 7.7120, stu_CELoss: 4.0835 DKDLoss: 3.6285 
2022-05-01 17:22:37 - train: epoch 0001, iter [03600, 05004], lr: 0.100000, loss: 7.3564, stu_CELoss: 3.8776 DKDLoss: 3.4788 
2022-05-01 17:23:12 - train: epoch 0001, iter [03700, 05004], lr: 0.100000, loss: 7.4716, stu_CELoss: 4.1548 DKDLoss: 3.3168 
2022-05-01 17:23:45 - train: epoch 0001, iter [03800, 05004], lr: 0.100000, loss: 7.1887, stu_CELoss: 3.8588 DKDLoss: 3.3299 
2022-05-01 17:24:18 - train: epoch 0001, iter [03900, 05004], lr: 0.100000, loss: 7.4608, stu_CELoss: 4.0165 DKDLoss: 3.4443 
2022-05-01 17:24:51 - train: epoch 0001, iter [04000, 05004], lr: 0.100000, loss: 7.3135, stu_CELoss: 3.8819 DKDLoss: 3.4316 
2022-05-01 17:25:24 - train: epoch 0001, iter [04100, 05004], lr: 0.100000, loss: 7.1064, stu_CELoss: 3.8878 DKDLoss: 3.2187 
2022-05-01 17:25:57 - train: epoch 0001, iter [04200, 05004], lr: 0.100000, loss: 7.1938, stu_CELoss: 3.8050 DKDLoss: 3.3888 
2022-05-01 17:26:31 - train: epoch 0001, iter [04300, 05004], lr: 0.100000, loss: 7.1809, stu_CELoss: 3.7243 DKDLoss: 3.4566 
2022-05-01 17:27:03 - train: epoch 0001, iter [04400, 05004], lr: 0.100000, loss: 6.6294, stu_CELoss: 3.5332 DKDLoss: 3.0962 
2022-05-01 17:27:37 - train: epoch 0001, iter [04500, 05004], lr: 0.100000, loss: 7.0140, stu_CELoss: 3.7579 DKDLoss: 3.2561 
2022-05-01 17:28:11 - train: epoch 0001, iter [04600, 05004], lr: 0.100000, loss: 7.0844, stu_CELoss: 3.8957 DKDLoss: 3.1887 
2022-05-01 17:28:43 - train: epoch 0001, iter [04700, 05004], lr: 0.100000, loss: 6.8853, stu_CELoss: 3.7704 DKDLoss: 3.1149 
2022-05-01 17:29:17 - train: epoch 0001, iter [04800, 05004], lr: 0.100000, loss: 7.0216, stu_CELoss: 3.9389 DKDLoss: 3.0827 
2022-05-01 17:29:50 - train: epoch 0001, iter [04900, 05004], lr: 0.100000, loss: 6.6261, stu_CELoss: 3.5805 DKDLoss: 3.0456 
2022-05-01 17:30:22 - train: epoch 0001, iter [05000, 05004], lr: 0.100000, loss: 6.6203, stu_CELoss: 3.5121 DKDLoss: 3.1082 
2022-05-01 17:30:23 - train: epoch 001, train_loss: 8.8926
2022-05-01 17:32:55 - eval: epoch: 001, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 27.034%, stu_acc5: 52.846%, stu_test_loss: 3.4582
2022-05-01 17:32:55 - until epoch: 001, tea_best_acc1: 73.944%, stu_best_acc1: 27.034%
2022-05-01 17:32:55 - epoch 002 lr: 0.1
2022-05-01 17:33:34 - train: epoch 0002, iter [00100, 05004], lr: 0.100000, loss: 6.2868, stu_CELoss: 3.4117 DKDLoss: 2.8751 
2022-05-01 17:34:07 - train: epoch 0002, iter [00200, 05004], lr: 0.100000, loss: 6.3392, stu_CELoss: 3.3952 DKDLoss: 2.9440 
2022-05-01 17:34:41 - train: epoch 0002, iter [00300, 05004], lr: 0.100000, loss: 6.5295, stu_CELoss: 3.5423 DKDLoss: 2.9872 
2022-05-01 17:35:14 - train: epoch 0002, iter [00400, 05004], lr: 0.100000, loss: 6.5201, stu_CELoss: 3.6295 DKDLoss: 2.8906 
2022-05-01 17:35:48 - train: epoch 0002, iter [00500, 05004], lr: 0.100000, loss: 6.2506, stu_CELoss: 3.4223 DKDLoss: 2.8284 
2022-05-01 17:36:20 - train: epoch 0002, iter [00600, 05004], lr: 0.100000, loss: 6.2888, stu_CELoss: 3.3683 DKDLoss: 2.9205 
2022-05-01 17:36:54 - train: epoch 0002, iter [00700, 05004], lr: 0.100000, loss: 6.6240, stu_CELoss: 3.7287 DKDLoss: 2.8953 
2022-05-01 17:37:26 - train: epoch 0002, iter [00800, 05004], lr: 0.100000, loss: 6.4116, stu_CELoss: 3.4367 DKDLoss: 2.9749 
2022-05-01 17:38:00 - train: epoch 0002, iter [00900, 05004], lr: 0.100000, loss: 6.1478, stu_CELoss: 3.2547 DKDLoss: 2.8931 
2022-05-01 17:38:33 - train: epoch 0002, iter [01000, 05004], lr: 0.100000, loss: 6.0431, stu_CELoss: 3.2886 DKDLoss: 2.7545 
2022-05-01 17:39:07 - train: epoch 0002, iter [01100, 05004], lr: 0.100000, loss: 6.2635, stu_CELoss: 3.4877 DKDLoss: 2.7758 
2022-05-01 17:39:39 - train: epoch 0002, iter [01200, 05004], lr: 0.100000, loss: 6.0455, stu_CELoss: 3.2339 DKDLoss: 2.8116 
2022-05-01 17:40:13 - train: epoch 0002, iter [01300, 05004], lr: 0.100000, loss: 6.3546, stu_CELoss: 3.3800 DKDLoss: 2.9746 
2022-05-01 17:40:46 - train: epoch 0002, iter [01400, 05004], lr: 0.100000, loss: 6.4279, stu_CELoss: 3.4960 DKDLoss: 2.9319 
2022-05-01 17:41:19 - train: epoch 0002, iter [01500, 05004], lr: 0.100000, loss: 6.3386, stu_CELoss: 3.3719 DKDLoss: 2.9667 
2022-05-01 17:41:51 - train: epoch 0002, iter [01600, 05004], lr: 0.100000, loss: 6.1987, stu_CELoss: 3.3781 DKDLoss: 2.8205 
2022-05-01 17:42:26 - train: epoch 0002, iter [01700, 05004], lr: 0.100000, loss: 5.9660, stu_CELoss: 3.2911 DKDLoss: 2.6749 
2022-05-01 17:42:58 - train: epoch 0002, iter [01800, 05004], lr: 0.100000, loss: 5.9520, stu_CELoss: 3.3171 DKDLoss: 2.6349 
2022-05-01 17:43:32 - train: epoch 0002, iter [01900, 05004], lr: 0.100000, loss: 5.7494, stu_CELoss: 3.0713 DKDLoss: 2.6781 
2022-05-01 17:44:05 - train: epoch 0002, iter [02000, 05004], lr: 0.100000, loss: 5.6666, stu_CELoss: 2.9169 DKDLoss: 2.7497 
2022-05-01 17:44:39 - train: epoch 0002, iter [02100, 05004], lr: 0.100000, loss: 5.8913, stu_CELoss: 3.2964 DKDLoss: 2.5949 
2022-05-01 17:45:13 - train: epoch 0002, iter [02200, 05004], lr: 0.100000, loss: 5.9766, stu_CELoss: 3.2901 DKDLoss: 2.6865 
2022-05-01 17:45:47 - train: epoch 0002, iter [02300, 05004], lr: 0.100000, loss: 5.8401, stu_CELoss: 3.2052 DKDLoss: 2.6349 
2022-05-01 17:46:20 - train: epoch 0002, iter [02400, 05004], lr: 0.100000, loss: 5.7290, stu_CELoss: 3.0694 DKDLoss: 2.6596 
2022-05-01 17:46:53 - train: epoch 0002, iter [02500, 05004], lr: 0.100000, loss: 5.6998, stu_CELoss: 3.0710 DKDLoss: 2.6288 
2022-05-01 17:47:26 - train: epoch 0002, iter [02600, 05004], lr: 0.100000, loss: 5.6535, stu_CELoss: 2.9535 DKDLoss: 2.7001 
2022-05-01 17:48:00 - train: epoch 0002, iter [02700, 05004], lr: 0.100000, loss: 6.2300, stu_CELoss: 3.4234 DKDLoss: 2.8067 
2022-05-01 17:48:32 - train: epoch 0002, iter [02800, 05004], lr: 0.100000, loss: 5.7594, stu_CELoss: 3.2054 DKDLoss: 2.5540 
2022-05-01 17:49:07 - train: epoch 0002, iter [02900, 05004], lr: 0.100000, loss: 5.8227, stu_CELoss: 3.1534 DKDLoss: 2.6693 
2022-05-01 17:49:38 - train: epoch 0002, iter [03000, 05004], lr: 0.100000, loss: 5.1391, stu_CELoss: 2.8393 DKDLoss: 2.2998 
2022-05-01 17:50:12 - train: epoch 0002, iter [03100, 05004], lr: 0.100000, loss: 5.9730, stu_CELoss: 3.1406 DKDLoss: 2.8324 
2022-05-01 17:50:45 - train: epoch 0002, iter [03200, 05004], lr: 0.100000, loss: 5.9974, stu_CELoss: 3.2699 DKDLoss: 2.7275 
2022-05-01 17:51:18 - train: epoch 0002, iter [03300, 05004], lr: 0.100000, loss: 5.6821, stu_CELoss: 3.2648 DKDLoss: 2.4173 
2022-05-01 17:51:51 - train: epoch 0002, iter [03400, 05004], lr: 0.100000, loss: 5.7077, stu_CELoss: 3.1004 DKDLoss: 2.6074 
2022-05-01 17:52:25 - train: epoch 0002, iter [03500, 05004], lr: 0.100000, loss: 5.7754, stu_CELoss: 3.1170 DKDLoss: 2.6584 
2022-05-01 17:52:58 - train: epoch 0002, iter [03600, 05004], lr: 0.100000, loss: 5.6251, stu_CELoss: 3.1368 DKDLoss: 2.4883 
2022-05-01 17:53:31 - train: epoch 0002, iter [03700, 05004], lr: 0.100000, loss: 5.8652, stu_CELoss: 3.3717 DKDLoss: 2.4935 
2022-05-01 17:54:04 - train: epoch 0002, iter [03800, 05004], lr: 0.100000, loss: 5.2601, stu_CELoss: 2.9786 DKDLoss: 2.2815 
2022-05-01 17:54:38 - train: epoch 0002, iter [03900, 05004], lr: 0.100000, loss: 5.7022, stu_CELoss: 3.1540 DKDLoss: 2.5482 
2022-05-01 17:55:11 - train: epoch 0002, iter [04000, 05004], lr: 0.100000, loss: 5.0736, stu_CELoss: 2.7961 DKDLoss: 2.2775 
2022-05-01 17:55:43 - train: epoch 0002, iter [04100, 05004], lr: 0.100000, loss: 5.7605, stu_CELoss: 3.1429 DKDLoss: 2.6176 
2022-05-01 17:56:17 - train: epoch 0002, iter [04200, 05004], lr: 0.100000, loss: 5.5468, stu_CELoss: 3.0754 DKDLoss: 2.4714 
2022-05-01 17:56:50 - train: epoch 0002, iter [04300, 05004], lr: 0.100000, loss: 5.4153, stu_CELoss: 3.0371 DKDLoss: 2.3782 
2022-05-01 17:57:24 - train: epoch 0002, iter [04400, 05004], lr: 0.100000, loss: 5.3610, stu_CELoss: 2.9511 DKDLoss: 2.4099 
2022-05-01 17:57:57 - train: epoch 0002, iter [04500, 05004], lr: 0.100000, loss: 5.1675, stu_CELoss: 2.8112 DKDLoss: 2.3563 
2022-05-01 17:58:30 - train: epoch 0002, iter [04600, 05004], lr: 0.100000, loss: 5.5264, stu_CELoss: 2.9285 DKDLoss: 2.5978 
2022-05-01 17:59:02 - train: epoch 0002, iter [04700, 05004], lr: 0.100000, loss: 5.1545, stu_CELoss: 2.7415 DKDLoss: 2.4129 
2022-05-01 17:59:36 - train: epoch 0002, iter [04800, 05004], lr: 0.100000, loss: 5.3118, stu_CELoss: 3.1061 DKDLoss: 2.2057 
2022-05-01 18:00:09 - train: epoch 0002, iter [04900, 05004], lr: 0.100000, loss: 5.2456, stu_CELoss: 2.8733 DKDLoss: 2.3723 
2022-05-01 18:00:41 - train: epoch 0002, iter [05000, 05004], lr: 0.100000, loss: 5.4472, stu_CELoss: 3.0729 DKDLoss: 2.3742 
2022-05-01 18:00:42 - train: epoch 002, train_loss: 5.8570
2022-05-01 18:03:10 - eval: epoch: 002, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 38.762%, stu_acc5: 65.794%, stu_test_loss: 2.7622
2022-05-01 18:03:11 - until epoch: 002, tea_best_acc1: 73.944%, stu_best_acc1: 38.762%
2022-05-01 18:03:11 - epoch 003 lr: 0.1
2022-05-01 18:03:49 - train: epoch 0003, iter [00100, 05004], lr: 0.100000, loss: 5.1978, stu_CELoss: 2.9704 DKDLoss: 2.2274 
2022-05-01 18:04:23 - train: epoch 0003, iter [00200, 05004], lr: 0.100000, loss: 5.3253, stu_CELoss: 2.9715 DKDLoss: 2.3538 
2022-05-01 18:04:56 - train: epoch 0003, iter [00300, 05004], lr: 0.100000, loss: 5.3243, stu_CELoss: 2.9228 DKDLoss: 2.4015 
2022-05-01 18:05:29 - train: epoch 0003, iter [00400, 05004], lr: 0.100000, loss: 5.2230, stu_CELoss: 2.9669 DKDLoss: 2.2560 
2022-05-01 18:06:01 - train: epoch 0003, iter [00500, 05004], lr: 0.100000, loss: 5.2773, stu_CELoss: 3.0147 DKDLoss: 2.2625 
2022-05-01 18:06:36 - train: epoch 0003, iter [00600, 05004], lr: 0.100000, loss: 4.8199, stu_CELoss: 2.6884 DKDLoss: 2.1315 
2022-05-01 18:07:08 - train: epoch 0003, iter [00700, 05004], lr: 0.100000, loss: 5.2310, stu_CELoss: 3.0249 DKDLoss: 2.2060 
2022-05-01 18:07:41 - train: epoch 0003, iter [00800, 05004], lr: 0.100000, loss: 5.6079, stu_CELoss: 3.1974 DKDLoss: 2.4105 
2022-05-01 18:08:14 - train: epoch 0003, iter [00900, 05004], lr: 0.100000, loss: 5.1086, stu_CELoss: 2.8528 DKDLoss: 2.2558 
2022-05-01 18:08:47 - train: epoch 0003, iter [01000, 05004], lr: 0.100000, loss: 4.9830, stu_CELoss: 2.8943 DKDLoss: 2.0887 
2022-05-01 18:09:20 - train: epoch 0003, iter [01100, 05004], lr: 0.100000, loss: 5.1000, stu_CELoss: 2.8371 DKDLoss: 2.2628 
2022-05-01 18:09:53 - train: epoch 0003, iter [01200, 05004], lr: 0.100000, loss: 5.0539, stu_CELoss: 2.8703 DKDLoss: 2.1835 
2022-05-01 18:10:26 - train: epoch 0003, iter [01300, 05004], lr: 0.100000, loss: 4.7986, stu_CELoss: 2.7589 DKDLoss: 2.0397 
2022-05-01 18:10:58 - train: epoch 0003, iter [01400, 05004], lr: 0.100000, loss: 5.1205, stu_CELoss: 2.8031 DKDLoss: 2.3173 
2022-05-01 18:11:32 - train: epoch 0003, iter [01500, 05004], lr: 0.100000, loss: 5.3524, stu_CELoss: 3.0439 DKDLoss: 2.3085 
2022-05-01 18:12:06 - train: epoch 0003, iter [01600, 05004], lr: 0.100000, loss: 5.0009, stu_CELoss: 2.7052 DKDLoss: 2.2956 
2022-05-01 18:12:38 - train: epoch 0003, iter [01700, 05004], lr: 0.100000, loss: 4.8803, stu_CELoss: 2.7189 DKDLoss: 2.1614 
2022-05-01 18:13:12 - train: epoch 0003, iter [01800, 05004], lr: 0.100000, loss: 4.8079, stu_CELoss: 2.7752 DKDLoss: 2.0327 
2022-05-01 18:13:46 - train: epoch 0003, iter [01900, 05004], lr: 0.100000, loss: 5.1956, stu_CELoss: 2.8596 DKDLoss: 2.3360 
2022-05-01 18:14:19 - train: epoch 0003, iter [02000, 05004], lr: 0.100000, loss: 5.1661, stu_CELoss: 3.0695 DKDLoss: 2.0966 
2022-05-01 18:14:52 - train: epoch 0003, iter [02100, 05004], lr: 0.100000, loss: 4.9817, stu_CELoss: 2.9076 DKDLoss: 2.0741 
2022-05-01 18:15:25 - train: epoch 0003, iter [02200, 05004], lr: 0.100000, loss: 5.4190, stu_CELoss: 3.2597 DKDLoss: 2.1594 
2022-05-01 18:15:59 - train: epoch 0003, iter [02300, 05004], lr: 0.100000, loss: 4.7454, stu_CELoss: 2.7349 DKDLoss: 2.0105 
2022-05-01 18:16:32 - train: epoch 0003, iter [02400, 05004], lr: 0.100000, loss: 4.6332, stu_CELoss: 2.6274 DKDLoss: 2.0058 
2022-05-01 18:17:06 - train: epoch 0003, iter [02500, 05004], lr: 0.100000, loss: 5.1374, stu_CELoss: 2.8971 DKDLoss: 2.2403 
2022-05-01 18:17:39 - train: epoch 0003, iter [02600, 05004], lr: 0.100000, loss: 4.8442, stu_CELoss: 2.8384 DKDLoss: 2.0059 
2022-05-01 18:18:13 - train: epoch 0003, iter [02700, 05004], lr: 0.100000, loss: 5.0494, stu_CELoss: 2.9819 DKDLoss: 2.0675 
2022-05-01 18:18:46 - train: epoch 0003, iter [02800, 05004], lr: 0.100000, loss: 4.8519, stu_CELoss: 2.7648 DKDLoss: 2.0872 
2022-05-01 18:19:20 - train: epoch 0003, iter [02900, 05004], lr: 0.100000, loss: 5.1325, stu_CELoss: 2.9682 DKDLoss: 2.1644 
2022-05-01 18:19:52 - train: epoch 0003, iter [03000, 05004], lr: 0.100000, loss: 5.0495, stu_CELoss: 2.8329 DKDLoss: 2.2166 
2022-05-01 18:20:27 - train: epoch 0003, iter [03100, 05004], lr: 0.100000, loss: 5.2718, stu_CELoss: 3.1038 DKDLoss: 2.1680 
2022-05-01 18:21:00 - train: epoch 0003, iter [03200, 05004], lr: 0.100000, loss: 5.0164, stu_CELoss: 2.9197 DKDLoss: 2.0967 
2022-05-01 18:21:33 - train: epoch 0003, iter [03300, 05004], lr: 0.100000, loss: 4.9139, stu_CELoss: 2.7467 DKDLoss: 2.1672 
2022-05-01 18:22:07 - train: epoch 0003, iter [03400, 05004], lr: 0.100000, loss: 5.1710, stu_CELoss: 3.0050 DKDLoss: 2.1659 
2022-05-01 18:22:40 - train: epoch 0003, iter [03500, 05004], lr: 0.100000, loss: 5.3746, stu_CELoss: 2.9419 DKDLoss: 2.4327 
2022-05-01 18:23:15 - train: epoch 0003, iter [03600, 05004], lr: 0.100000, loss: 4.9504, stu_CELoss: 2.6538 DKDLoss: 2.2966 
2022-05-01 18:23:49 - train: epoch 0003, iter [03700, 05004], lr: 0.100000, loss: 4.9414, stu_CELoss: 2.8328 DKDLoss: 2.1086 
2022-05-01 18:24:22 - train: epoch 0003, iter [03800, 05004], lr: 0.100000, loss: 5.2509, stu_CELoss: 3.0890 DKDLoss: 2.1619 
2022-05-01 18:24:56 - train: epoch 0003, iter [03900, 05004], lr: 0.100000, loss: 5.2397, stu_CELoss: 3.0758 DKDLoss: 2.1639 
2022-05-01 18:25:30 - train: epoch 0003, iter [04000, 05004], lr: 0.100000, loss: 4.5682, stu_CELoss: 2.4852 DKDLoss: 2.0830 
2022-05-01 18:26:04 - train: epoch 0003, iter [04100, 05004], lr: 0.100000, loss: 4.5441, stu_CELoss: 2.7409 DKDLoss: 1.8032 
2022-05-01 18:26:36 - train: epoch 0003, iter [04200, 05004], lr: 0.100000, loss: 4.7928, stu_CELoss: 2.7906 DKDLoss: 2.0021 
2022-05-01 18:27:11 - train: epoch 0003, iter [04300, 05004], lr: 0.100000, loss: 4.5945, stu_CELoss: 2.4916 DKDLoss: 2.1029 
2022-05-01 18:27:44 - train: epoch 0003, iter [04400, 05004], lr: 0.100000, loss: 4.5594, stu_CELoss: 2.6672 DKDLoss: 1.8921 
2022-05-01 18:28:18 - train: epoch 0003, iter [04500, 05004], lr: 0.100000, loss: 4.7942, stu_CELoss: 2.7171 DKDLoss: 2.0771 
2022-05-01 18:28:51 - train: epoch 0003, iter [04600, 05004], lr: 0.100000, loss: 4.5282, stu_CELoss: 2.5494 DKDLoss: 1.9788 
2022-05-01 18:29:24 - train: epoch 0003, iter [04700, 05004], lr: 0.100000, loss: 4.7440, stu_CELoss: 2.7494 DKDLoss: 1.9946 
2022-05-01 18:29:58 - train: epoch 0003, iter [04800, 05004], lr: 0.100000, loss: 5.3528, stu_CELoss: 3.1236 DKDLoss: 2.2292 
2022-05-01 18:30:31 - train: epoch 0003, iter [04900, 05004], lr: 0.100000, loss: 5.0552, stu_CELoss: 2.8679 DKDLoss: 2.1873 
2022-05-01 18:31:03 - train: epoch 0003, iter [05000, 05004], lr: 0.100000, loss: 5.0259, stu_CELoss: 2.8367 DKDLoss: 2.1891 
2022-05-01 18:31:04 - train: epoch 003, train_loss: 5.0377
2022-05-01 18:33:35 - eval: epoch: 003, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 40.262%, stu_acc5: 67.332%, stu_test_loss: 2.6681
2022-05-01 18:33:36 - until epoch: 003, tea_best_acc1: 73.944%, stu_best_acc1: 40.262%
2022-05-01 18:33:36 - epoch 004 lr: 0.1
2022-05-01 18:34:15 - train: epoch 0004, iter [00100, 05004], lr: 0.100000, loss: 5.2444, stu_CELoss: 3.0963 DKDLoss: 2.1480 
2022-05-01 18:34:49 - train: epoch 0004, iter [00200, 05004], lr: 0.100000, loss: 4.6613, stu_CELoss: 2.5809 DKDLoss: 2.0804 
2022-05-01 18:35:23 - train: epoch 0004, iter [00300, 05004], lr: 0.100000, loss: 4.8676, stu_CELoss: 2.7138 DKDLoss: 2.1537 
2022-05-01 18:35:55 - train: epoch 0004, iter [00400, 05004], lr: 0.100000, loss: 4.4657, stu_CELoss: 2.6243 DKDLoss: 1.8415 
2022-05-01 18:36:29 - train: epoch 0004, iter [00500, 05004], lr: 0.100000, loss: 4.8529, stu_CELoss: 2.6667 DKDLoss: 2.1863 
2022-05-01 18:37:02 - train: epoch 0004, iter [00600, 05004], lr: 0.100000, loss: 5.1913, stu_CELoss: 3.0643 DKDLoss: 2.1269 
2022-05-01 18:37:36 - train: epoch 0004, iter [00700, 05004], lr: 0.100000, loss: 4.8747, stu_CELoss: 2.8971 DKDLoss: 1.9776 
2022-05-01 18:38:08 - train: epoch 0004, iter [00800, 05004], lr: 0.100000, loss: 5.0265, stu_CELoss: 2.8312 DKDLoss: 2.1954 
2022-05-01 18:38:41 - train: epoch 0004, iter [00900, 05004], lr: 0.100000, loss: 4.4596, stu_CELoss: 2.4392 DKDLoss: 2.0204 
2022-05-01 18:39:15 - train: epoch 0004, iter [01000, 05004], lr: 0.100000, loss: 4.9923, stu_CELoss: 2.8133 DKDLoss: 2.1791 
2022-05-01 18:39:48 - train: epoch 0004, iter [01100, 05004], lr: 0.100000, loss: 5.0122, stu_CELoss: 2.9410 DKDLoss: 2.0711 
2022-05-01 18:40:21 - train: epoch 0004, iter [01200, 05004], lr: 0.100000, loss: 4.6343, stu_CELoss: 2.5535 DKDLoss: 2.0807 
2022-05-01 18:40:55 - train: epoch 0004, iter [01300, 05004], lr: 0.100000, loss: 4.6242, stu_CELoss: 2.6547 DKDLoss: 1.9694 
2022-05-01 18:41:28 - train: epoch 0004, iter [01400, 05004], lr: 0.100000, loss: 4.6360, stu_CELoss: 2.7409 DKDLoss: 1.8951 
2022-05-01 18:42:01 - train: epoch 0004, iter [01500, 05004], lr: 0.100000, loss: 4.6447, stu_CELoss: 2.5886 DKDLoss: 2.0561 
2022-05-01 18:42:35 - train: epoch 0004, iter [01600, 05004], lr: 0.100000, loss: 4.7554, stu_CELoss: 2.7362 DKDLoss: 2.0191 
2022-05-01 18:43:08 - train: epoch 0004, iter [01700, 05004], lr: 0.100000, loss: 4.6651, stu_CELoss: 2.6356 DKDLoss: 2.0295 
2022-05-01 18:43:41 - train: epoch 0004, iter [01800, 05004], lr: 0.100000, loss: 5.0743, stu_CELoss: 2.9548 DKDLoss: 2.1195 
2022-05-01 18:44:14 - train: epoch 0004, iter [01900, 05004], lr: 0.100000, loss: 5.0066, stu_CELoss: 2.8187 DKDLoss: 2.1879 
2022-05-01 18:44:47 - train: epoch 0004, iter [02000, 05004], lr: 0.100000, loss: 4.9363, stu_CELoss: 2.8467 DKDLoss: 2.0896 
2022-05-01 18:45:21 - train: epoch 0004, iter [02100, 05004], lr: 0.100000, loss: 4.6666, stu_CELoss: 2.6771 DKDLoss: 1.9895 
2022-05-01 18:45:53 - train: epoch 0004, iter [02200, 05004], lr: 0.100000, loss: 4.7192, stu_CELoss: 2.7205 DKDLoss: 1.9987 
2022-05-01 18:46:26 - train: epoch 0004, iter [02300, 05004], lr: 0.100000, loss: 4.3487, stu_CELoss: 2.4619 DKDLoss: 1.8868 
2022-05-01 18:46:59 - train: epoch 0004, iter [02400, 05004], lr: 0.100000, loss: 4.3803, stu_CELoss: 2.5093 DKDLoss: 1.8710 
2022-05-01 18:47:33 - train: epoch 0004, iter [02500, 05004], lr: 0.100000, loss: 4.3645, stu_CELoss: 2.4496 DKDLoss: 1.9149 
2022-05-01 18:48:04 - train: epoch 0004, iter [02600, 05004], lr: 0.100000, loss: 4.7469, stu_CELoss: 2.7295 DKDLoss: 2.0174 
2022-05-01 18:48:38 - train: epoch 0004, iter [02700, 05004], lr: 0.100000, loss: 4.6434, stu_CELoss: 2.6230 DKDLoss: 2.0204 
2022-05-01 18:49:12 - train: epoch 0004, iter [02800, 05004], lr: 0.100000, loss: 4.4886, stu_CELoss: 2.5604 DKDLoss: 1.9281 
2022-05-01 18:49:43 - train: epoch 0004, iter [02900, 05004], lr: 0.100000, loss: 4.8740, stu_CELoss: 2.7238 DKDLoss: 2.1502 
2022-05-01 18:50:17 - train: epoch 0004, iter [03000, 05004], lr: 0.100000, loss: 4.8842, stu_CELoss: 2.8774 DKDLoss: 2.0068 
2022-05-01 18:50:50 - train: epoch 0004, iter [03100, 05004], lr: 0.100000, loss: 4.5695, stu_CELoss: 2.6858 DKDLoss: 1.8837 
2022-05-01 18:51:23 - train: epoch 0004, iter [03200, 05004], lr: 0.100000, loss: 5.0252, stu_CELoss: 2.8603 DKDLoss: 2.1649 
2022-05-01 18:51:55 - train: epoch 0004, iter [03300, 05004], lr: 0.100000, loss: 4.7143, stu_CELoss: 2.7243 DKDLoss: 1.9900 
2022-05-01 18:52:28 - train: epoch 0004, iter [03400, 05004], lr: 0.100000, loss: 4.8043, stu_CELoss: 2.7153 DKDLoss: 2.0890 
2022-05-01 18:53:01 - train: epoch 0004, iter [03500, 05004], lr: 0.100000, loss: 4.5981, stu_CELoss: 2.7025 DKDLoss: 1.8956 
2022-05-01 18:53:35 - train: epoch 0004, iter [03600, 05004], lr: 0.100000, loss: 4.7398, stu_CELoss: 2.7041 DKDLoss: 2.0357 
2022-05-01 18:54:08 - train: epoch 0004, iter [03700, 05004], lr: 0.100000, loss: 4.5596, stu_CELoss: 2.7054 DKDLoss: 1.8542 
2022-05-01 18:54:42 - train: epoch 0004, iter [03800, 05004], lr: 0.100000, loss: 4.4977, stu_CELoss: 2.5263 DKDLoss: 1.9714 
2022-05-01 18:55:14 - train: epoch 0004, iter [03900, 05004], lr: 0.100000, loss: 4.6136, stu_CELoss: 2.6375 DKDLoss: 1.9761 
2022-05-01 18:55:47 - train: epoch 0004, iter [04000, 05004], lr: 0.100000, loss: 4.3047, stu_CELoss: 2.4509 DKDLoss: 1.8538 
2022-05-01 18:56:19 - train: epoch 0004, iter [04100, 05004], lr: 0.100000, loss: 4.4220, stu_CELoss: 2.5203 DKDLoss: 1.9017 
2022-05-01 18:56:53 - train: epoch 0004, iter [04200, 05004], lr: 0.100000, loss: 4.4952, stu_CELoss: 2.5523 DKDLoss: 1.9429 
2022-05-01 18:57:25 - train: epoch 0004, iter [04300, 05004], lr: 0.100000, loss: 4.4963, stu_CELoss: 2.5423 DKDLoss: 1.9540 
2022-05-01 18:57:59 - train: epoch 0004, iter [04400, 05004], lr: 0.100000, loss: 4.6303, stu_CELoss: 2.6046 DKDLoss: 2.0257 
2022-05-01 18:58:32 - train: epoch 0004, iter [04500, 05004], lr: 0.100000, loss: 3.9722, stu_CELoss: 2.1797 DKDLoss: 1.7926 
2022-05-01 18:59:05 - train: epoch 0004, iter [04600, 05004], lr: 0.100000, loss: 4.3898, stu_CELoss: 2.4256 DKDLoss: 1.9642 
2022-05-01 18:59:38 - train: epoch 0004, iter [04700, 05004], lr: 0.100000, loss: 4.5923, stu_CELoss: 2.6112 DKDLoss: 1.9810 
2022-05-01 19:00:11 - train: epoch 0004, iter [04800, 05004], lr: 0.100000, loss: 4.2851, stu_CELoss: 2.3444 DKDLoss: 1.9407 
2022-05-01 19:00:43 - train: epoch 0004, iter [04900, 05004], lr: 0.100000, loss: 4.7576, stu_CELoss: 2.7518 DKDLoss: 2.0058 
2022-05-01 19:01:15 - train: epoch 0004, iter [05000, 05004], lr: 0.100000, loss: 4.6388, stu_CELoss: 2.5484 DKDLoss: 2.0904 
2022-05-01 19:01:16 - train: epoch 004, train_loss: 4.6650
2022-05-01 19:03:44 - eval: epoch: 004, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 46.604%, stu_acc5: 72.612%, stu_test_loss: 2.3481
2022-05-01 19:03:45 - until epoch: 004, tea_best_acc1: 73.944%, stu_best_acc1: 46.604%
2022-05-01 19:03:45 - epoch 005 lr: 0.1
2022-05-01 19:04:24 - train: epoch 0005, iter [00100, 05004], lr: 0.100000, loss: 4.7895, stu_CELoss: 2.7942 DKDLoss: 1.9953 
2022-05-01 19:04:57 - train: epoch 0005, iter [00200, 05004], lr: 0.100000, loss: 4.6016, stu_CELoss: 2.6360 DKDLoss: 1.9655 
2022-05-01 19:05:30 - train: epoch 0005, iter [00300, 05004], lr: 0.100000, loss: 4.9822, stu_CELoss: 2.9436 DKDLoss: 2.0385 
2022-05-01 19:06:02 - train: epoch 0005, iter [00400, 05004], lr: 0.100000, loss: 4.2035, stu_CELoss: 2.4172 DKDLoss: 1.7862 
2022-05-01 19:06:36 - train: epoch 0005, iter [00500, 05004], lr: 0.100000, loss: 4.4046, stu_CELoss: 2.5502 DKDLoss: 1.8544 
2022-05-01 19:07:08 - train: epoch 0005, iter [00600, 05004], lr: 0.100000, loss: 4.4894, stu_CELoss: 2.6849 DKDLoss: 1.8044 
2022-05-01 19:07:42 - train: epoch 0005, iter [00700, 05004], lr: 0.100000, loss: 4.5027, stu_CELoss: 2.6461 DKDLoss: 1.8566 
2022-05-01 19:08:14 - train: epoch 0005, iter [00800, 05004], lr: 0.100000, loss: 4.6929, stu_CELoss: 2.8401 DKDLoss: 1.8528 
2022-05-01 19:08:47 - train: epoch 0005, iter [00900, 05004], lr: 0.100000, loss: 4.4457, stu_CELoss: 2.5521 DKDLoss: 1.8936 
2022-05-01 19:09:20 - train: epoch 0005, iter [01000, 05004], lr: 0.100000, loss: 4.7459, stu_CELoss: 2.7363 DKDLoss: 2.0096 
2022-05-01 19:09:53 - train: epoch 0005, iter [01100, 05004], lr: 0.100000, loss: 4.4694, stu_CELoss: 2.5574 DKDLoss: 1.9119 
2022-05-01 19:10:25 - train: epoch 0005, iter [01200, 05004], lr: 0.100000, loss: 4.6076, stu_CELoss: 2.6147 DKDLoss: 1.9928 
2022-05-01 19:10:59 - train: epoch 0005, iter [01300, 05004], lr: 0.100000, loss: 4.3773, stu_CELoss: 2.4962 DKDLoss: 1.8810 
2022-05-01 19:11:31 - train: epoch 0005, iter [01400, 05004], lr: 0.100000, loss: 4.5747, stu_CELoss: 2.6678 DKDLoss: 1.9069 
2022-05-01 19:12:05 - train: epoch 0005, iter [01500, 05004], lr: 0.100000, loss: 4.4914, stu_CELoss: 2.5006 DKDLoss: 1.9908 
2022-05-01 19:12:37 - train: epoch 0005, iter [01600, 05004], lr: 0.100000, loss: 3.9936, stu_CELoss: 2.2463 DKDLoss: 1.7473 
2022-05-01 19:13:11 - train: epoch 0005, iter [01700, 05004], lr: 0.100000, loss: 4.4875, stu_CELoss: 2.6286 DKDLoss: 1.8588 
2022-05-01 19:13:44 - train: epoch 0005, iter [01800, 05004], lr: 0.100000, loss: 4.4361, stu_CELoss: 2.4465 DKDLoss: 1.9896 
2022-05-01 19:14:17 - train: epoch 0005, iter [01900, 05004], lr: 0.100000, loss: 4.3575, stu_CELoss: 2.4937 DKDLoss: 1.8639 
2022-05-01 19:14:50 - train: epoch 0005, iter [02000, 05004], lr: 0.100000, loss: 4.4675, stu_CELoss: 2.5650 DKDLoss: 1.9024 
2022-05-01 19:15:23 - train: epoch 0005, iter [02100, 05004], lr: 0.100000, loss: 4.3248, stu_CELoss: 2.5338 DKDLoss: 1.7911 
2022-05-01 19:15:56 - train: epoch 0005, iter [02200, 05004], lr: 0.100000, loss: 4.3914, stu_CELoss: 2.4218 DKDLoss: 1.9696 
2022-05-01 19:16:29 - train: epoch 0005, iter [02300, 05004], lr: 0.100000, loss: 4.1017, stu_CELoss: 2.2381 DKDLoss: 1.8636 
2022-05-01 19:17:02 - train: epoch 0005, iter [02400, 05004], lr: 0.100000, loss: 4.4452, stu_CELoss: 2.5456 DKDLoss: 1.8996 
2022-05-01 19:17:35 - train: epoch 0005, iter [02500, 05004], lr: 0.100000, loss: 4.5945, stu_CELoss: 2.6766 DKDLoss: 1.9180 
2022-05-01 19:18:08 - train: epoch 0005, iter [02600, 05004], lr: 0.100000, loss: 4.4100, stu_CELoss: 2.4836 DKDLoss: 1.9264 
2022-05-01 19:18:41 - train: epoch 0005, iter [02700, 05004], lr: 0.100000, loss: 4.7255, stu_CELoss: 2.7487 DKDLoss: 1.9767 
2022-05-01 19:19:13 - train: epoch 0005, iter [02800, 05004], lr: 0.100000, loss: 4.4943, stu_CELoss: 2.5024 DKDLoss: 1.9918 
2022-05-01 19:19:46 - train: epoch 0005, iter [02900, 05004], lr: 0.100000, loss: 4.3828, stu_CELoss: 2.6316 DKDLoss: 1.7512 
2022-05-01 19:20:19 - train: epoch 0005, iter [03000, 05004], lr: 0.100000, loss: 4.2848, stu_CELoss: 2.5328 DKDLoss: 1.7520 
2022-05-01 19:20:53 - train: epoch 0005, iter [03100, 05004], lr: 0.100000, loss: 4.6520, stu_CELoss: 2.6495 DKDLoss: 2.0025 
2022-05-01 19:21:26 - train: epoch 0005, iter [03200, 05004], lr: 0.100000, loss: 4.3528, stu_CELoss: 2.5320 DKDLoss: 1.8208 
2022-05-01 19:21:59 - train: epoch 0005, iter [03300, 05004], lr: 0.100000, loss: 4.1846, stu_CELoss: 2.3525 DKDLoss: 1.8321 
2022-05-01 19:22:32 - train: epoch 0005, iter [03400, 05004], lr: 0.100000, loss: 4.3261, stu_CELoss: 2.5091 DKDLoss: 1.8170 
2022-05-01 19:23:04 - train: epoch 0005, iter [03500, 05004], lr: 0.100000, loss: 4.4800, stu_CELoss: 2.6976 DKDLoss: 1.7824 
2022-05-01 19:23:38 - train: epoch 0005, iter [03600, 05004], lr: 0.100000, loss: 4.3791, stu_CELoss: 2.5406 DKDLoss: 1.8386 
2022-05-01 19:24:10 - train: epoch 0005, iter [03700, 05004], lr: 0.100000, loss: 4.3707, stu_CELoss: 2.4623 DKDLoss: 1.9083 
2022-05-01 19:24:44 - train: epoch 0005, iter [03800, 05004], lr: 0.100000, loss: 4.5486, stu_CELoss: 2.6644 DKDLoss: 1.8842 
2022-05-01 19:25:16 - train: epoch 0005, iter [03900, 05004], lr: 0.100000, loss: 4.6557, stu_CELoss: 2.7173 DKDLoss: 1.9383 
2022-05-01 19:25:49 - train: epoch 0005, iter [04000, 05004], lr: 0.100000, loss: 4.3698, stu_CELoss: 2.5887 DKDLoss: 1.7811 
2022-05-01 19:26:22 - train: epoch 0005, iter [04100, 05004], lr: 0.100000, loss: 4.4700, stu_CELoss: 2.6352 DKDLoss: 1.8348 
2022-05-01 19:26:55 - train: epoch 0005, iter [04200, 05004], lr: 0.100000, loss: 4.5191, stu_CELoss: 2.7463 DKDLoss: 1.7727 
2022-05-01 19:27:28 - train: epoch 0005, iter [04300, 05004], lr: 0.100000, loss: 4.3797, stu_CELoss: 2.5844 DKDLoss: 1.7953 
2022-05-01 19:28:00 - train: epoch 0005, iter [04400, 05004], lr: 0.100000, loss: 4.9431, stu_CELoss: 2.8777 DKDLoss: 2.0654 
2022-05-01 19:28:34 - train: epoch 0005, iter [04500, 05004], lr: 0.100000, loss: 4.4041, stu_CELoss: 2.6235 DKDLoss: 1.7806 
2022-05-01 19:29:06 - train: epoch 0005, iter [04600, 05004], lr: 0.100000, loss: 4.4193, stu_CELoss: 2.4671 DKDLoss: 1.9522 
2022-05-01 19:29:40 - train: epoch 0005, iter [04700, 05004], lr: 0.100000, loss: 4.1921, stu_CELoss: 2.3696 DKDLoss: 1.8225 
2022-05-01 19:30:13 - train: epoch 0005, iter [04800, 05004], lr: 0.100000, loss: 4.0554, stu_CELoss: 2.3970 DKDLoss: 1.6584 
2022-05-01 19:30:46 - train: epoch 0005, iter [04900, 05004], lr: 0.100000, loss: 4.7745, stu_CELoss: 2.8564 DKDLoss: 1.9181 
2022-05-01 19:31:17 - train: epoch 0005, iter [05000, 05004], lr: 0.100000, loss: 4.2804, stu_CELoss: 2.5568 DKDLoss: 1.7236 
2022-05-01 19:31:18 - train: epoch 005, train_loss: 4.4481
2022-05-01 19:33:47 - eval: epoch: 005, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 46.962%, stu_acc5: 73.328%, stu_test_loss: 2.3199
2022-05-01 19:33:47 - until epoch: 005, tea_best_acc1: 73.944%, stu_best_acc1: 46.962%
2022-05-01 19:33:47 - epoch 006 lr: 0.1
2022-05-01 19:34:25 - train: epoch 0006, iter [00100, 05004], lr: 0.100000, loss: 3.7752, stu_CELoss: 2.2665 DKDLoss: 1.5087 
2022-05-01 19:34:58 - train: epoch 0006, iter [00200, 05004], lr: 0.100000, loss: 4.0286, stu_CELoss: 2.3993 DKDLoss: 1.6294 
2022-05-01 19:35:31 - train: epoch 0006, iter [00300, 05004], lr: 0.100000, loss: 4.2861, stu_CELoss: 2.3749 DKDLoss: 1.9112 
2022-05-01 19:36:03 - train: epoch 0006, iter [00400, 05004], lr: 0.100000, loss: 4.3579, stu_CELoss: 2.5265 DKDLoss: 1.8314 
2022-05-01 19:36:36 - train: epoch 0006, iter [00500, 05004], lr: 0.100000, loss: 4.2583, stu_CELoss: 2.4290 DKDLoss: 1.8292 
2022-05-01 19:37:09 - train: epoch 0006, iter [00600, 05004], lr: 0.100000, loss: 3.9411, stu_CELoss: 2.2387 DKDLoss: 1.7024 
2022-05-01 19:37:42 - train: epoch 0006, iter [00700, 05004], lr: 0.100000, loss: 4.8100, stu_CELoss: 2.8346 DKDLoss: 1.9755 
2022-05-01 19:38:13 - train: epoch 0006, iter [00800, 05004], lr: 0.100000, loss: 4.2338, stu_CELoss: 2.4195 DKDLoss: 1.8143 
2022-05-01 19:38:46 - train: epoch 0006, iter [00900, 05004], lr: 0.100000, loss: 3.9550, stu_CELoss: 2.2639 DKDLoss: 1.6911 
2022-05-01 19:39:18 - train: epoch 0006, iter [01000, 05004], lr: 0.100000, loss: 4.3784, stu_CELoss: 2.5181 DKDLoss: 1.8603 
2022-05-01 19:39:50 - train: epoch 0006, iter [01100, 05004], lr: 0.100000, loss: 4.3266, stu_CELoss: 2.5019 DKDLoss: 1.8248 
2022-05-01 19:40:24 - train: epoch 0006, iter [01200, 05004], lr: 0.100000, loss: 4.5208, stu_CELoss: 2.6995 DKDLoss: 1.8213 
2022-05-01 19:40:55 - train: epoch 0006, iter [01300, 05004], lr: 0.100000, loss: 4.2479, stu_CELoss: 2.4830 DKDLoss: 1.7649 
2022-05-01 19:41:29 - train: epoch 0006, iter [01400, 05004], lr: 0.100000, loss: 4.4842, stu_CELoss: 2.6875 DKDLoss: 1.7967 
2022-05-01 19:42:00 - train: epoch 0006, iter [01500, 05004], lr: 0.100000, loss: 4.7198, stu_CELoss: 2.7386 DKDLoss: 1.9812 
2022-05-01 19:42:33 - train: epoch 0006, iter [01600, 05004], lr: 0.100000, loss: 4.0822, stu_CELoss: 2.3398 DKDLoss: 1.7424 
2022-05-01 19:43:07 - train: epoch 0006, iter [01700, 05004], lr: 0.100000, loss: 4.3893, stu_CELoss: 2.6529 DKDLoss: 1.7363 
2022-05-01 19:43:39 - train: epoch 0006, iter [01800, 05004], lr: 0.100000, loss: 4.2767, stu_CELoss: 2.4902 DKDLoss: 1.7865 
2022-05-01 19:44:12 - train: epoch 0006, iter [01900, 05004], lr: 0.100000, loss: 4.1548, stu_CELoss: 2.3987 DKDLoss: 1.7560 
2022-05-01 19:44:44 - train: epoch 0006, iter [02000, 05004], lr: 0.100000, loss: 4.5505, stu_CELoss: 2.6808 DKDLoss: 1.8698 
2022-05-01 19:45:18 - train: epoch 0006, iter [02100, 05004], lr: 0.100000, loss: 4.2388, stu_CELoss: 2.4379 DKDLoss: 1.8009 
2022-05-01 19:45:50 - train: epoch 0006, iter [02200, 05004], lr: 0.100000, loss: 4.1712, stu_CELoss: 2.3168 DKDLoss: 1.8543 
2022-05-01 19:46:23 - train: epoch 0006, iter [02300, 05004], lr: 0.100000, loss: 4.2299, stu_CELoss: 2.4810 DKDLoss: 1.7490 
2022-05-01 19:46:55 - train: epoch 0006, iter [02400, 05004], lr: 0.100000, loss: 4.3850, stu_CELoss: 2.4760 DKDLoss: 1.9090 
2022-05-01 19:47:28 - train: epoch 0006, iter [02500, 05004], lr: 0.100000, loss: 4.2756, stu_CELoss: 2.4471 DKDLoss: 1.8284 
2022-05-01 19:48:01 - train: epoch 0006, iter [02600, 05004], lr: 0.100000, loss: 4.3049, stu_CELoss: 2.5407 DKDLoss: 1.7642 
2022-05-01 19:48:33 - train: epoch 0006, iter [02700, 05004], lr: 0.100000, loss: 4.3530, stu_CELoss: 2.5089 DKDLoss: 1.8441 
2022-05-01 19:49:07 - train: epoch 0006, iter [02800, 05004], lr: 0.100000, loss: 4.0460, stu_CELoss: 2.2608 DKDLoss: 1.7852 
2022-05-01 19:49:39 - train: epoch 0006, iter [02900, 05004], lr: 0.100000, loss: 4.2620, stu_CELoss: 2.5294 DKDLoss: 1.7326 
2022-05-01 19:50:13 - train: epoch 0006, iter [03000, 05004], lr: 0.100000, loss: 4.3531, stu_CELoss: 2.4955 DKDLoss: 1.8576 
2022-05-01 19:50:45 - train: epoch 0006, iter [03100, 05004], lr: 0.100000, loss: 4.2292, stu_CELoss: 2.4643 DKDLoss: 1.7649 
2022-05-01 19:51:18 - train: epoch 0006, iter [03200, 05004], lr: 0.100000, loss: 4.1604, stu_CELoss: 2.4041 DKDLoss: 1.7563 
2022-05-01 19:51:50 - train: epoch 0006, iter [03300, 05004], lr: 0.100000, loss: 4.4671, stu_CELoss: 2.4773 DKDLoss: 1.9898 
2022-05-01 19:52:23 - train: epoch 0006, iter [03400, 05004], lr: 0.100000, loss: 4.3049, stu_CELoss: 2.5048 DKDLoss: 1.8001 
2022-05-01 19:52:56 - train: epoch 0006, iter [03500, 05004], lr: 0.100000, loss: 4.1429, stu_CELoss: 2.4188 DKDLoss: 1.7241 
2022-05-01 19:53:29 - train: epoch 0006, iter [03600, 05004], lr: 0.100000, loss: 4.3389, stu_CELoss: 2.5134 DKDLoss: 1.8255 
2022-05-01 19:54:01 - train: epoch 0006, iter [03700, 05004], lr: 0.100000, loss: 4.1313, stu_CELoss: 2.3895 DKDLoss: 1.7418 
2022-05-01 19:54:35 - train: epoch 0006, iter [03800, 05004], lr: 0.100000, loss: 3.9595, stu_CELoss: 2.2847 DKDLoss: 1.6748 
2022-05-01 19:55:07 - train: epoch 0006, iter [03900, 05004], lr: 0.100000, loss: 4.2706, stu_CELoss: 2.5256 DKDLoss: 1.7450 
2022-05-01 19:55:40 - train: epoch 0006, iter [04000, 05004], lr: 0.100000, loss: 4.4079, stu_CELoss: 2.5039 DKDLoss: 1.9039 
2022-05-01 19:56:12 - train: epoch 0006, iter [04100, 05004], lr: 0.100000, loss: 4.4914, stu_CELoss: 2.5827 DKDLoss: 1.9087 
2022-05-01 19:56:46 - train: epoch 0006, iter [04200, 05004], lr: 0.100000, loss: 4.0856, stu_CELoss: 2.2805 DKDLoss: 1.8052 
2022-05-01 19:57:18 - train: epoch 0006, iter [04300, 05004], lr: 0.100000, loss: 4.5293, stu_CELoss: 2.5604 DKDLoss: 1.9689 
2022-05-01 19:57:51 - train: epoch 0006, iter [04400, 05004], lr: 0.100000, loss: 4.2719, stu_CELoss: 2.4112 DKDLoss: 1.8606 
2022-05-01 19:58:24 - train: epoch 0006, iter [04500, 05004], lr: 0.100000, loss: 4.4282, stu_CELoss: 2.6821 DKDLoss: 1.7460 
2022-05-01 19:58:56 - train: epoch 0006, iter [04600, 05004], lr: 0.100000, loss: 4.2093, stu_CELoss: 2.3628 DKDLoss: 1.8465 
2022-05-01 19:59:30 - train: epoch 0006, iter [04700, 05004], lr: 0.100000, loss: 3.9298, stu_CELoss: 2.3371 DKDLoss: 1.5927 
2022-05-01 20:00:02 - train: epoch 0006, iter [04800, 05004], lr: 0.100000, loss: 4.0521, stu_CELoss: 2.3850 DKDLoss: 1.6672 
2022-05-01 20:00:35 - train: epoch 0006, iter [04900, 05004], lr: 0.100000, loss: 4.1457, stu_CELoss: 2.4881 DKDLoss: 1.6576 
2022-05-01 20:01:06 - train: epoch 0006, iter [05000, 05004], lr: 0.100000, loss: 4.1576, stu_CELoss: 2.3924 DKDLoss: 1.7653 
2022-05-01 20:01:07 - train: epoch 006, train_loss: 4.3128
2022-05-01 20:03:34 - eval: epoch: 006, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 47.476%, stu_acc5: 73.644%, stu_test_loss: 2.2982
2022-05-01 20:03:34 - until epoch: 006, tea_best_acc1: 73.944%, stu_best_acc1: 47.476%
2022-05-01 20:03:34 - epoch 007 lr: 0.1
2022-05-01 20:04:12 - train: epoch 0007, iter [00100, 05004], lr: 0.100000, loss: 4.1708, stu_CELoss: 2.3249 DKDLoss: 1.8459 
2022-05-01 20:04:45 - train: epoch 0007, iter [00200, 05004], lr: 0.100000, loss: 4.0438, stu_CELoss: 2.3708 DKDLoss: 1.6729 
2022-05-01 20:05:19 - train: epoch 0007, iter [00300, 05004], lr: 0.100000, loss: 4.5353, stu_CELoss: 2.6762 DKDLoss: 1.8591 
2022-05-01 20:05:51 - train: epoch 0007, iter [00400, 05004], lr: 0.100000, loss: 4.0349, stu_CELoss: 2.4042 DKDLoss: 1.6307 
2022-05-01 20:06:24 - train: epoch 0007, iter [00500, 05004], lr: 0.100000, loss: 4.0350, stu_CELoss: 2.2815 DKDLoss: 1.7535 
2022-05-01 20:06:57 - train: epoch 0007, iter [00600, 05004], lr: 0.100000, loss: 4.2432, stu_CELoss: 2.5488 DKDLoss: 1.6944 
2022-05-01 20:07:30 - train: epoch 0007, iter [00700, 05004], lr: 0.100000, loss: 4.2016, stu_CELoss: 2.4561 DKDLoss: 1.7455 
2022-05-01 20:08:02 - train: epoch 0007, iter [00800, 05004], lr: 0.100000, loss: 4.1405, stu_CELoss: 2.4389 DKDLoss: 1.7017 
2022-05-01 20:08:35 - train: epoch 0007, iter [00900, 05004], lr: 0.100000, loss: 4.3107, stu_CELoss: 2.5494 DKDLoss: 1.7613 
2022-05-01 20:09:07 - train: epoch 0007, iter [01000, 05004], lr: 0.100000, loss: 3.9671, stu_CELoss: 2.4072 DKDLoss: 1.5600 
2022-05-01 20:09:40 - train: epoch 0007, iter [01100, 05004], lr: 0.100000, loss: 4.4353, stu_CELoss: 2.6448 DKDLoss: 1.7905 
2022-05-01 20:10:13 - train: epoch 0007, iter [01200, 05004], lr: 0.100000, loss: 4.3727, stu_CELoss: 2.5730 DKDLoss: 1.7997 
2022-05-01 20:10:46 - train: epoch 0007, iter [01300, 05004], lr: 0.100000, loss: 4.0342, stu_CELoss: 2.2564 DKDLoss: 1.7779 
2022-05-01 20:11:18 - train: epoch 0007, iter [01400, 05004], lr: 0.100000, loss: 4.4837, stu_CELoss: 2.5909 DKDLoss: 1.8928 
2022-05-01 20:11:52 - train: epoch 0007, iter [01500, 05004], lr: 0.100000, loss: 4.3908, stu_CELoss: 2.5607 DKDLoss: 1.8301 
2022-05-01 20:12:24 - train: epoch 0007, iter [01600, 05004], lr: 0.100000, loss: 4.0604, stu_CELoss: 2.4019 DKDLoss: 1.6585 
2022-05-01 20:12:57 - train: epoch 0007, iter [01700, 05004], lr: 0.100000, loss: 4.0487, stu_CELoss: 2.3250 DKDLoss: 1.7238 
2022-05-01 20:13:29 - train: epoch 0007, iter [01800, 05004], lr: 0.100000, loss: 4.3101, stu_CELoss: 2.5849 DKDLoss: 1.7251 
2022-05-01 20:14:02 - train: epoch 0007, iter [01900, 05004], lr: 0.100000, loss: 4.2605, stu_CELoss: 2.5030 DKDLoss: 1.7576 
2022-05-01 20:14:36 - train: epoch 0007, iter [02000, 05004], lr: 0.100000, loss: 4.1124, stu_CELoss: 2.2546 DKDLoss: 1.8578 
2022-05-01 20:15:07 - train: epoch 0007, iter [02100, 05004], lr: 0.100000, loss: 4.4327, stu_CELoss: 2.6590 DKDLoss: 1.7737 
2022-05-01 20:15:41 - train: epoch 0007, iter [02200, 05004], lr: 0.100000, loss: 4.0652, stu_CELoss: 2.3571 DKDLoss: 1.7081 
2022-05-01 20:16:15 - train: epoch 0007, iter [02300, 05004], lr: 0.100000, loss: 4.2223, stu_CELoss: 2.4996 DKDLoss: 1.7227 
2022-05-01 20:16:46 - train: epoch 0007, iter [02400, 05004], lr: 0.100000, loss: 4.7548, stu_CELoss: 2.7796 DKDLoss: 1.9752 
2022-05-01 20:17:19 - train: epoch 0007, iter [02500, 05004], lr: 0.100000, loss: 4.1930, stu_CELoss: 2.4648 DKDLoss: 1.7283 
2022-05-01 20:17:52 - train: epoch 0007, iter [02600, 05004], lr: 0.100000, loss: 4.1570, stu_CELoss: 2.3925 DKDLoss: 1.7646 
2022-05-01 20:18:24 - train: epoch 0007, iter [02700, 05004], lr: 0.100000, loss: 3.8935, stu_CELoss: 2.2897 DKDLoss: 1.6038 
2022-05-01 20:18:59 - train: epoch 0007, iter [02800, 05004], lr: 0.100000, loss: 4.2216, stu_CELoss: 2.4905 DKDLoss: 1.7311 
2022-05-01 20:19:30 - train: epoch 0007, iter [02900, 05004], lr: 0.100000, loss: 4.4118, stu_CELoss: 2.4478 DKDLoss: 1.9640 
2022-05-01 20:20:03 - train: epoch 0007, iter [03000, 05004], lr: 0.100000, loss: 4.7347, stu_CELoss: 2.7615 DKDLoss: 1.9732 
2022-05-01 20:20:36 - train: epoch 0007, iter [03100, 05004], lr: 0.100000, loss: 3.8893, stu_CELoss: 2.2925 DKDLoss: 1.5968 
2022-05-01 20:21:09 - train: epoch 0007, iter [03200, 05004], lr: 0.100000, loss: 4.1468, stu_CELoss: 2.3321 DKDLoss: 1.8147 
2022-05-01 20:21:42 - train: epoch 0007, iter [03300, 05004], lr: 0.100000, loss: 4.6913, stu_CELoss: 2.7668 DKDLoss: 1.9245 
2022-05-01 20:22:15 - train: epoch 0007, iter [03400, 05004], lr: 0.100000, loss: 4.3337, stu_CELoss: 2.5827 DKDLoss: 1.7510 
2022-05-01 20:22:47 - train: epoch 0007, iter [03500, 05004], lr: 0.100000, loss: 4.5375, stu_CELoss: 2.6415 DKDLoss: 1.8960 
2022-05-01 20:23:20 - train: epoch 0007, iter [03600, 05004], lr: 0.100000, loss: 4.2463, stu_CELoss: 2.4418 DKDLoss: 1.8045 
2022-05-01 20:23:52 - train: epoch 0007, iter [03700, 05004], lr: 0.100000, loss: 4.0909, stu_CELoss: 2.3218 DKDLoss: 1.7691 
2022-05-01 20:24:25 - train: epoch 0007, iter [03800, 05004], lr: 0.100000, loss: 4.5097, stu_CELoss: 2.7482 DKDLoss: 1.7615 
2022-05-01 20:24:57 - train: epoch 0007, iter [03900, 05004], lr: 0.100000, loss: 4.2840, stu_CELoss: 2.5314 DKDLoss: 1.7526 
2022-05-01 20:25:30 - train: epoch 0007, iter [04000, 05004], lr: 0.100000, loss: 4.3109, stu_CELoss: 2.6033 DKDLoss: 1.7076 
2022-05-01 20:26:03 - train: epoch 0007, iter [04100, 05004], lr: 0.100000, loss: 4.2463, stu_CELoss: 2.4354 DKDLoss: 1.8109 
2022-05-01 20:26:36 - train: epoch 0007, iter [04200, 05004], lr: 0.100000, loss: 4.1382, stu_CELoss: 2.3530 DKDLoss: 1.7852 
2022-05-01 20:27:09 - train: epoch 0007, iter [04300, 05004], lr: 0.100000, loss: 4.2935, stu_CELoss: 2.5821 DKDLoss: 1.7114 
2022-05-01 20:27:42 - train: epoch 0007, iter [04400, 05004], lr: 0.100000, loss: 4.0423, stu_CELoss: 2.3159 DKDLoss: 1.7264 
2022-05-01 20:28:14 - train: epoch 0007, iter [04500, 05004], lr: 0.100000, loss: 4.1189, stu_CELoss: 2.4290 DKDLoss: 1.6899 
2022-05-01 20:28:47 - train: epoch 0007, iter [04600, 05004], lr: 0.100000, loss: 4.3738, stu_CELoss: 2.4776 DKDLoss: 1.8962 
2022-05-01 20:29:19 - train: epoch 0007, iter [04700, 05004], lr: 0.100000, loss: 3.9506, stu_CELoss: 2.2567 DKDLoss: 1.6940 
2022-05-01 20:29:53 - train: epoch 0007, iter [04800, 05004], lr: 0.100000, loss: 4.5720, stu_CELoss: 2.7088 DKDLoss: 1.8631 
2022-05-01 20:30:26 - train: epoch 0007, iter [04900, 05004], lr: 0.100000, loss: 4.1615, stu_CELoss: 2.4556 DKDLoss: 1.7059 
2022-05-01 20:30:58 - train: epoch 0007, iter [05000, 05004], lr: 0.100000, loss: 4.0127, stu_CELoss: 2.3340 DKDLoss: 1.6787 
2022-05-01 20:30:58 - train: epoch 007, train_loss: 4.2225
2022-05-01 20:33:26 - eval: epoch: 007, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 46.462%, stu_acc5: 72.318%, stu_test_loss: 2.3657
2022-05-01 20:33:26 - until epoch: 007, tea_best_acc1: 73.944%, stu_best_acc1: 47.476%
2022-05-01 20:33:26 - epoch 008 lr: 0.1
2022-05-01 20:34:04 - train: epoch 0008, iter [00100, 05004], lr: 0.100000, loss: 4.1737, stu_CELoss: 2.4392 DKDLoss: 1.7346 
2022-05-01 20:34:36 - train: epoch 0008, iter [00200, 05004], lr: 0.100000, loss: 4.3549, stu_CELoss: 2.5578 DKDLoss: 1.7971 
2022-05-01 20:35:09 - train: epoch 0008, iter [00300, 05004], lr: 0.100000, loss: 4.4168, stu_CELoss: 2.4995 DKDLoss: 1.9173 
2022-05-01 20:35:41 - train: epoch 0008, iter [00400, 05004], lr: 0.100000, loss: 3.9405, stu_CELoss: 2.3098 DKDLoss: 1.6307 
2022-05-01 20:36:14 - train: epoch 0008, iter [00500, 05004], lr: 0.100000, loss: 3.9048, stu_CELoss: 2.2200 DKDLoss: 1.6848 
2022-05-01 20:36:45 - train: epoch 0008, iter [00600, 05004], lr: 0.100000, loss: 3.9215, stu_CELoss: 2.3025 DKDLoss: 1.6191 
2022-05-01 20:37:19 - train: epoch 0008, iter [00700, 05004], lr: 0.100000, loss: 4.3486, stu_CELoss: 2.5192 DKDLoss: 1.8294 
2022-05-01 20:37:51 - train: epoch 0008, iter [00800, 05004], lr: 0.100000, loss: 3.8121, stu_CELoss: 2.1489 DKDLoss: 1.6632 
2022-05-01 20:38:25 - train: epoch 0008, iter [00900, 05004], lr: 0.100000, loss: 3.9581, stu_CELoss: 2.4350 DKDLoss: 1.5231 
2022-05-01 20:38:57 - train: epoch 0008, iter [01000, 05004], lr: 0.100000, loss: 4.3925, stu_CELoss: 2.5325 DKDLoss: 1.8599 
2022-05-01 20:39:29 - train: epoch 0008, iter [01100, 05004], lr: 0.100000, loss: 3.8145, stu_CELoss: 2.2522 DKDLoss: 1.5623 
2022-05-01 20:40:02 - train: epoch 0008, iter [01200, 05004], lr: 0.100000, loss: 3.6239, stu_CELoss: 2.0548 DKDLoss: 1.5691 
2022-05-01 20:40:34 - train: epoch 0008, iter [01300, 05004], lr: 0.100000, loss: 4.2743, stu_CELoss: 2.4452 DKDLoss: 1.8292 
2022-05-01 20:41:07 - train: epoch 0008, iter [01400, 05004], lr: 0.100000, loss: 4.1468, stu_CELoss: 2.4069 DKDLoss: 1.7399 
2022-05-01 20:41:39 - train: epoch 0008, iter [01500, 05004], lr: 0.100000, loss: 4.4777, stu_CELoss: 2.5735 DKDLoss: 1.9042 
2022-05-01 20:42:12 - train: epoch 0008, iter [01600, 05004], lr: 0.100000, loss: 4.4415, stu_CELoss: 2.5880 DKDLoss: 1.8535 
2022-05-01 20:42:45 - train: epoch 0008, iter [01700, 05004], lr: 0.100000, loss: 3.9923, stu_CELoss: 2.3945 DKDLoss: 1.5977 
2022-05-01 20:43:17 - train: epoch 0008, iter [01800, 05004], lr: 0.100000, loss: 4.4289, stu_CELoss: 2.5452 DKDLoss: 1.8837 
2022-05-01 20:43:49 - train: epoch 0008, iter [01900, 05004], lr: 0.100000, loss: 3.9790, stu_CELoss: 2.2547 DKDLoss: 1.7242 
2022-05-01 20:44:22 - train: epoch 0008, iter [02000, 05004], lr: 0.100000, loss: 4.4507, stu_CELoss: 2.7972 DKDLoss: 1.6535 
2022-05-01 20:44:54 - train: epoch 0008, iter [02100, 05004], lr: 0.100000, loss: 4.0362, stu_CELoss: 2.3472 DKDLoss: 1.6891 
2022-05-01 20:45:28 - train: epoch 0008, iter [02200, 05004], lr: 0.100000, loss: 4.0332, stu_CELoss: 2.4405 DKDLoss: 1.5927 
2022-05-01 20:46:01 - train: epoch 0008, iter [02300, 05004], lr: 0.100000, loss: 3.8732, stu_CELoss: 2.2801 DKDLoss: 1.5931 
2022-05-01 20:46:34 - train: epoch 0008, iter [02400, 05004], lr: 0.100000, loss: 4.0122, stu_CELoss: 2.2872 DKDLoss: 1.7250 
2022-05-01 20:47:06 - train: epoch 0008, iter [02500, 05004], lr: 0.100000, loss: 4.0246, stu_CELoss: 2.3272 DKDLoss: 1.6974 
2022-05-01 20:47:39 - train: epoch 0008, iter [02600, 05004], lr: 0.100000, loss: 4.0392, stu_CELoss: 2.2853 DKDLoss: 1.7538 
2022-05-01 20:48:12 - train: epoch 0008, iter [02700, 05004], lr: 0.100000, loss: 4.2724, stu_CELoss: 2.5264 DKDLoss: 1.7460 
2022-05-01 20:48:44 - train: epoch 0008, iter [02800, 05004], lr: 0.100000, loss: 4.1764, stu_CELoss: 2.4304 DKDLoss: 1.7460 
2022-05-01 20:49:17 - train: epoch 0008, iter [02900, 05004], lr: 0.100000, loss: 4.4112, stu_CELoss: 2.6705 DKDLoss: 1.7406 
2022-05-01 20:49:49 - train: epoch 0008, iter [03000, 05004], lr: 0.100000, loss: 4.6490, stu_CELoss: 2.7581 DKDLoss: 1.8909 
2022-05-01 20:50:22 - train: epoch 0008, iter [03100, 05004], lr: 0.100000, loss: 4.1631, stu_CELoss: 2.3899 DKDLoss: 1.7732 
2022-05-01 20:50:55 - train: epoch 0008, iter [03200, 05004], lr: 0.100000, loss: 4.2655, stu_CELoss: 2.5317 DKDLoss: 1.7338 
2022-05-01 20:51:29 - train: epoch 0008, iter [03300, 05004], lr: 0.100000, loss: 4.2779, stu_CELoss: 2.5218 DKDLoss: 1.7560 
2022-05-01 20:52:00 - train: epoch 0008, iter [03400, 05004], lr: 0.100000, loss: 4.3468, stu_CELoss: 2.6383 DKDLoss: 1.7085 
2022-05-01 20:52:34 - train: epoch 0008, iter [03500, 05004], lr: 0.100000, loss: 4.0019, stu_CELoss: 2.3784 DKDLoss: 1.6235 
2022-05-01 20:53:06 - train: epoch 0008, iter [03600, 05004], lr: 0.100000, loss: 4.2800, stu_CELoss: 2.5518 DKDLoss: 1.7282 
2022-05-01 20:53:39 - train: epoch 0008, iter [03700, 05004], lr: 0.100000, loss: 4.0679, stu_CELoss: 2.4137 DKDLoss: 1.6542 
2022-05-01 20:54:12 - train: epoch 0008, iter [03800, 05004], lr: 0.100000, loss: 4.3928, stu_CELoss: 2.4403 DKDLoss: 1.9525 
2022-05-01 20:54:44 - train: epoch 0008, iter [03900, 05004], lr: 0.100000, loss: 4.1265, stu_CELoss: 2.4278 DKDLoss: 1.6987 
2022-05-01 20:55:17 - train: epoch 0008, iter [04000, 05004], lr: 0.100000, loss: 4.3869, stu_CELoss: 2.5471 DKDLoss: 1.8399 
2022-05-01 20:55:50 - train: epoch 0008, iter [04100, 05004], lr: 0.100000, loss: 4.2763, stu_CELoss: 2.4641 DKDLoss: 1.8122 
2022-05-01 20:56:23 - train: epoch 0008, iter [04200, 05004], lr: 0.100000, loss: 4.1441, stu_CELoss: 2.3987 DKDLoss: 1.7453 
2022-05-01 20:56:56 - train: epoch 0008, iter [04300, 05004], lr: 0.100000, loss: 3.8229, stu_CELoss: 2.1661 DKDLoss: 1.6568 
2022-05-01 20:57:28 - train: epoch 0008, iter [04400, 05004], lr: 0.100000, loss: 4.1823, stu_CELoss: 2.4272 DKDLoss: 1.7551 
2022-05-01 20:58:01 - train: epoch 0008, iter [04500, 05004], lr: 0.100000, loss: 4.1762, stu_CELoss: 2.3752 DKDLoss: 1.8009 
2022-05-01 20:58:33 - train: epoch 0008, iter [04600, 05004], lr: 0.100000, loss: 4.2917, stu_CELoss: 2.4739 DKDLoss: 1.8179 
2022-05-01 20:59:06 - train: epoch 0008, iter [04700, 05004], lr: 0.100000, loss: 4.0022, stu_CELoss: 2.2986 DKDLoss: 1.7036 
2022-05-01 20:59:38 - train: epoch 0008, iter [04800, 05004], lr: 0.100000, loss: 4.2656, stu_CELoss: 2.4423 DKDLoss: 1.8233 
2022-05-01 21:00:12 - train: epoch 0008, iter [04900, 05004], lr: 0.100000, loss: 3.7871, stu_CELoss: 2.2845 DKDLoss: 1.5027 
2022-05-01 21:00:42 - train: epoch 0008, iter [05000, 05004], lr: 0.100000, loss: 3.9871, stu_CELoss: 2.4521 DKDLoss: 1.5350 
2022-05-01 21:00:43 - train: epoch 008, train_loss: 4.1474
2022-05-01 21:03:11 - eval: epoch: 008, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 48.948%, stu_acc5: 74.802%, stu_test_loss: 2.2227
2022-05-01 21:03:11 - until epoch: 008, tea_best_acc1: 73.944%, stu_best_acc1: 48.948%
2022-05-01 21:03:11 - epoch 009 lr: 0.1
2022-05-01 21:03:49 - train: epoch 0009, iter [00100, 05004], lr: 0.100000, loss: 3.5123, stu_CELoss: 2.0442 DKDLoss: 1.4680 
2022-05-01 21:04:22 - train: epoch 0009, iter [00200, 05004], lr: 0.100000, loss: 4.0341, stu_CELoss: 2.3796 DKDLoss: 1.6545 
2022-05-01 21:04:54 - train: epoch 0009, iter [00300, 05004], lr: 0.100000, loss: 4.1442, stu_CELoss: 2.4328 DKDLoss: 1.7115 
2022-05-01 21:05:27 - train: epoch 0009, iter [00400, 05004], lr: 0.100000, loss: 4.2084, stu_CELoss: 2.5154 DKDLoss: 1.6930 
2022-05-01 21:05:59 - train: epoch 0009, iter [00500, 05004], lr: 0.100000, loss: 4.1279, stu_CELoss: 2.3063 DKDLoss: 1.8216 
2022-05-01 21:06:32 - train: epoch 0009, iter [00600, 05004], lr: 0.100000, loss: 3.7885, stu_CELoss: 2.2302 DKDLoss: 1.5583 
2022-05-01 21:07:05 - train: epoch 0009, iter [00700, 05004], lr: 0.100000, loss: 3.7133, stu_CELoss: 2.1412 DKDLoss: 1.5721 
2022-05-01 21:07:37 - train: epoch 0009, iter [00800, 05004], lr: 0.100000, loss: 3.9026, stu_CELoss: 2.2780 DKDLoss: 1.6246 
2022-05-01 21:08:10 - train: epoch 0009, iter [00900, 05004], lr: 0.100000, loss: 4.0655, stu_CELoss: 2.3105 DKDLoss: 1.7550 
2022-05-01 21:08:42 - train: epoch 0009, iter [01000, 05004], lr: 0.100000, loss: 3.8258, stu_CELoss: 2.2770 DKDLoss: 1.5487 
2022-05-01 21:09:15 - train: epoch 0009, iter [01100, 05004], lr: 0.100000, loss: 4.2252, stu_CELoss: 2.5532 DKDLoss: 1.6720 
2022-05-01 21:09:48 - train: epoch 0009, iter [01200, 05004], lr: 0.100000, loss: 4.2459, stu_CELoss: 2.4619 DKDLoss: 1.7840 
2022-05-01 21:10:20 - train: epoch 0009, iter [01300, 05004], lr: 0.100000, loss: 4.2663, stu_CELoss: 2.5348 DKDLoss: 1.7316 
2022-05-01 21:10:52 - train: epoch 0009, iter [01400, 05004], lr: 0.100000, loss: 3.7830, stu_CELoss: 2.1381 DKDLoss: 1.6449 
2022-05-01 21:11:25 - train: epoch 0009, iter [01500, 05004], lr: 0.100000, loss: 3.8956, stu_CELoss: 2.2764 DKDLoss: 1.6193 
2022-05-01 21:11:59 - train: epoch 0009, iter [01600, 05004], lr: 0.100000, loss: 4.0964, stu_CELoss: 2.3521 DKDLoss: 1.7443 
2022-05-01 21:12:31 - train: epoch 0009, iter [01700, 05004], lr: 0.100000, loss: 4.3619, stu_CELoss: 2.6280 DKDLoss: 1.7339 
2022-05-01 21:13:03 - train: epoch 0009, iter [01800, 05004], lr: 0.100000, loss: 4.1084, stu_CELoss: 2.4345 DKDLoss: 1.6739 
2022-05-01 21:13:36 - train: epoch 0009, iter [01900, 05004], lr: 0.100000, loss: 3.6860, stu_CELoss: 2.0803 DKDLoss: 1.6057 
2022-05-01 21:14:09 - train: epoch 0009, iter [02000, 05004], lr: 0.100000, loss: 4.0051, stu_CELoss: 2.3056 DKDLoss: 1.6996 
2022-05-01 21:14:41 - train: epoch 0009, iter [02100, 05004], lr: 0.100000, loss: 4.0640, stu_CELoss: 2.4392 DKDLoss: 1.6248 
2022-05-01 21:15:14 - train: epoch 0009, iter [02200, 05004], lr: 0.100000, loss: 4.2184, stu_CELoss: 2.4955 DKDLoss: 1.7229 
2022-05-01 21:15:46 - train: epoch 0009, iter [02300, 05004], lr: 0.100000, loss: 3.8676, stu_CELoss: 2.1873 DKDLoss: 1.6803 
2022-05-01 21:16:19 - train: epoch 0009, iter [02400, 05004], lr: 0.100000, loss: 4.0133, stu_CELoss: 2.3315 DKDLoss: 1.6817 
2022-05-01 21:16:51 - train: epoch 0009, iter [02500, 05004], lr: 0.100000, loss: 4.1434, stu_CELoss: 2.3577 DKDLoss: 1.7858 
2022-05-01 21:17:24 - train: epoch 0009, iter [02600, 05004], lr: 0.100000, loss: 4.0411, stu_CELoss: 2.3443 DKDLoss: 1.6968 
2022-05-01 21:17:57 - train: epoch 0009, iter [02700, 05004], lr: 0.100000, loss: 4.1477, stu_CELoss: 2.4913 DKDLoss: 1.6564 
2022-05-01 21:18:29 - train: epoch 0009, iter [02800, 05004], lr: 0.100000, loss: 4.1967, stu_CELoss: 2.5218 DKDLoss: 1.6749 
2022-05-01 21:19:02 - train: epoch 0009, iter [02900, 05004], lr: 0.100000, loss: 3.6966, stu_CELoss: 2.1317 DKDLoss: 1.5649 
2022-05-01 21:19:34 - train: epoch 0009, iter [03000, 05004], lr: 0.100000, loss: 3.7705, stu_CELoss: 2.1116 DKDLoss: 1.6589 
2022-05-01 21:20:06 - train: epoch 0009, iter [03100, 05004], lr: 0.100000, loss: 4.0361, stu_CELoss: 2.3891 DKDLoss: 1.6470 
2022-05-01 21:20:39 - train: epoch 0009, iter [03200, 05004], lr: 0.100000, loss: 4.1099, stu_CELoss: 2.4539 DKDLoss: 1.6560 
2022-05-01 21:21:11 - train: epoch 0009, iter [03300, 05004], lr: 0.100000, loss: 4.1713, stu_CELoss: 2.5191 DKDLoss: 1.6522 
2022-05-01 21:21:44 - train: epoch 0009, iter [03400, 05004], lr: 0.100000, loss: 3.8751, stu_CELoss: 2.2443 DKDLoss: 1.6308 
2022-05-01 21:22:16 - train: epoch 0009, iter [03500, 05004], lr: 0.100000, loss: 4.3726, stu_CELoss: 2.5159 DKDLoss: 1.8567 
2022-05-01 21:22:50 - train: epoch 0009, iter [03600, 05004], lr: 0.100000, loss: 3.9036, stu_CELoss: 2.2685 DKDLoss: 1.6351 
2022-05-01 21:23:21 - train: epoch 0009, iter [03700, 05004], lr: 0.100000, loss: 4.2561, stu_CELoss: 2.4501 DKDLoss: 1.8059 
2022-05-01 21:23:54 - train: epoch 0009, iter [03800, 05004], lr: 0.100000, loss: 4.1010, stu_CELoss: 2.4589 DKDLoss: 1.6420 
2022-05-01 21:24:25 - train: epoch 0009, iter [03900, 05004], lr: 0.100000, loss: 4.1545, stu_CELoss: 2.3706 DKDLoss: 1.7839 
2022-05-01 21:24:58 - train: epoch 0009, iter [04000, 05004], lr: 0.100000, loss: 4.3170, stu_CELoss: 2.6697 DKDLoss: 1.6473 
2022-05-01 21:25:29 - train: epoch 0009, iter [04100, 05004], lr: 0.100000, loss: 4.2147, stu_CELoss: 2.4986 DKDLoss: 1.7162 
2022-05-01 21:26:03 - train: epoch 0009, iter [04200, 05004], lr: 0.100000, loss: 3.8404, stu_CELoss: 2.3219 DKDLoss: 1.5185 
2022-05-01 21:26:35 - train: epoch 0009, iter [04300, 05004], lr: 0.100000, loss: 3.6674, stu_CELoss: 2.0856 DKDLoss: 1.5818 
2022-05-01 21:27:09 - train: epoch 0009, iter [04400, 05004], lr: 0.100000, loss: 4.1046, stu_CELoss: 2.4105 DKDLoss: 1.6941 
2022-05-01 21:27:41 - train: epoch 0009, iter [04500, 05004], lr: 0.100000, loss: 4.0283, stu_CELoss: 2.4131 DKDLoss: 1.6151 
2022-05-01 21:28:13 - train: epoch 0009, iter [04600, 05004], lr: 0.100000, loss: 4.5035, stu_CELoss: 2.6694 DKDLoss: 1.8341 
2022-05-01 21:28:46 - train: epoch 0009, iter [04700, 05004], lr: 0.100000, loss: 4.3346, stu_CELoss: 2.6476 DKDLoss: 1.6870 
2022-05-01 21:29:19 - train: epoch 0009, iter [04800, 05004], lr: 0.100000, loss: 4.0323, stu_CELoss: 2.4368 DKDLoss: 1.5955 
2022-05-01 21:29:51 - train: epoch 0009, iter [04900, 05004], lr: 0.100000, loss: 4.2729, stu_CELoss: 2.5439 DKDLoss: 1.7290 
2022-05-01 21:30:22 - train: epoch 0009, iter [05000, 05004], lr: 0.100000, loss: 3.8945, stu_CELoss: 2.2221 DKDLoss: 1.6723 
2022-05-01 21:30:23 - train: epoch 009, train_loss: 4.0900
2022-05-01 21:32:51 - eval: epoch: 009, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 50.458%, stu_acc5: 75.886%, stu_test_loss: 2.1541
2022-05-01 21:32:52 - until epoch: 009, tea_best_acc1: 73.944%, stu_best_acc1: 50.458%
2022-05-01 21:32:52 - epoch 010 lr: 0.1
2022-05-01 21:33:29 - train: epoch 0010, iter [00100, 05004], lr: 0.100000, loss: 3.8001, stu_CELoss: 2.2114 DKDLoss: 1.5887 
2022-05-01 21:34:02 - train: epoch 0010, iter [00200, 05004], lr: 0.100000, loss: 4.1293, stu_CELoss: 2.4434 DKDLoss: 1.6860 
2022-05-01 21:34:35 - train: epoch 0010, iter [00300, 05004], lr: 0.100000, loss: 4.0299, stu_CELoss: 2.3838 DKDLoss: 1.6460 
2022-05-01 21:35:08 - train: epoch 0010, iter [00400, 05004], lr: 0.100000, loss: 4.2879, stu_CELoss: 2.5539 DKDLoss: 1.7340 
2022-05-01 21:35:39 - train: epoch 0010, iter [00500, 05004], lr: 0.100000, loss: 3.7935, stu_CELoss: 2.2738 DKDLoss: 1.5196 
2022-05-01 21:36:13 - train: epoch 0010, iter [00600, 05004], lr: 0.100000, loss: 4.1255, stu_CELoss: 2.5300 DKDLoss: 1.5955 
2022-05-01 21:36:45 - train: epoch 0010, iter [00700, 05004], lr: 0.100000, loss: 4.2374, stu_CELoss: 2.5993 DKDLoss: 1.6381 
2022-05-01 21:37:19 - train: epoch 0010, iter [00800, 05004], lr: 0.100000, loss: 4.1850, stu_CELoss: 2.5050 DKDLoss: 1.6800 
2022-05-01 21:37:50 - train: epoch 0010, iter [00900, 05004], lr: 0.100000, loss: 3.8250, stu_CELoss: 2.1644 DKDLoss: 1.6606 
2022-05-01 21:38:25 - train: epoch 0010, iter [01000, 05004], lr: 0.100000, loss: 3.5957, stu_CELoss: 2.0790 DKDLoss: 1.5167 
2022-05-01 21:38:57 - train: epoch 0010, iter [01100, 05004], lr: 0.100000, loss: 3.9626, stu_CELoss: 2.2457 DKDLoss: 1.7169 
2022-05-01 21:39:31 - train: epoch 0010, iter [01200, 05004], lr: 0.100000, loss: 4.1206, stu_CELoss: 2.4602 DKDLoss: 1.6604 
2022-05-01 21:40:03 - train: epoch 0010, iter [01300, 05004], lr: 0.100000, loss: 3.7231, stu_CELoss: 2.1907 DKDLoss: 1.5325 
2022-05-01 21:40:36 - train: epoch 0010, iter [01400, 05004], lr: 0.100000, loss: 4.2319, stu_CELoss: 2.5355 DKDLoss: 1.6964 
2022-05-01 21:41:09 - train: epoch 0010, iter [01500, 05004], lr: 0.100000, loss: 3.8078, stu_CELoss: 2.1059 DKDLoss: 1.7019 
2022-05-01 21:41:41 - train: epoch 0010, iter [01600, 05004], lr: 0.100000, loss: 4.1780, stu_CELoss: 2.4678 DKDLoss: 1.7103 
2022-05-01 21:42:14 - train: epoch 0010, iter [01700, 05004], lr: 0.100000, loss: 4.1782, stu_CELoss: 2.5251 DKDLoss: 1.6531 
2022-05-01 21:42:47 - train: epoch 0010, iter [01800, 05004], lr: 0.100000, loss: 3.8950, stu_CELoss: 2.2989 DKDLoss: 1.5961 
2022-05-01 21:43:20 - train: epoch 0010, iter [01900, 05004], lr: 0.100000, loss: 4.0690, stu_CELoss: 2.4285 DKDLoss: 1.6405 
2022-05-01 21:43:53 - train: epoch 0010, iter [02000, 05004], lr: 0.100000, loss: 4.1260, stu_CELoss: 2.4172 DKDLoss: 1.7088 
2022-05-01 21:44:26 - train: epoch 0010, iter [02100, 05004], lr: 0.100000, loss: 3.8084, stu_CELoss: 2.2368 DKDLoss: 1.5716 
2022-05-01 21:44:58 - train: epoch 0010, iter [02200, 05004], lr: 0.100000, loss: 4.2552, stu_CELoss: 2.5262 DKDLoss: 1.7290 
2022-05-01 21:45:30 - train: epoch 0010, iter [02300, 05004], lr: 0.100000, loss: 4.1217, stu_CELoss: 2.6230 DKDLoss: 1.4987 
2022-05-01 21:46:03 - train: epoch 0010, iter [02400, 05004], lr: 0.100000, loss: 4.4477, stu_CELoss: 2.7000 DKDLoss: 1.7477 
2022-05-01 21:46:36 - train: epoch 0010, iter [02500, 05004], lr: 0.100000, loss: 4.0277, stu_CELoss: 2.4385 DKDLoss: 1.5892 
2022-05-01 21:47:08 - train: epoch 0010, iter [02600, 05004], lr: 0.100000, loss: 4.2794, stu_CELoss: 2.4773 DKDLoss: 1.8021 
2022-05-01 21:47:41 - train: epoch 0010, iter [02700, 05004], lr: 0.100000, loss: 4.0442, stu_CELoss: 2.3172 DKDLoss: 1.7270 
2022-05-01 21:48:14 - train: epoch 0010, iter [02800, 05004], lr: 0.100000, loss: 4.3872, stu_CELoss: 2.5021 DKDLoss: 1.8850 
2022-05-01 21:48:47 - train: epoch 0010, iter [02900, 05004], lr: 0.100000, loss: 4.2138, stu_CELoss: 2.5078 DKDLoss: 1.7059 
2022-05-01 21:49:19 - train: epoch 0010, iter [03000, 05004], lr: 0.100000, loss: 3.8064, stu_CELoss: 2.2433 DKDLoss: 1.5631 
2022-05-01 21:49:52 - train: epoch 0010, iter [03100, 05004], lr: 0.100000, loss: 4.4645, stu_CELoss: 2.6937 DKDLoss: 1.7708 
2022-05-01 21:50:25 - train: epoch 0010, iter [03200, 05004], lr: 0.100000, loss: 3.9743, stu_CELoss: 2.3378 DKDLoss: 1.6365 
2022-05-01 21:50:58 - train: epoch 0010, iter [03300, 05004], lr: 0.100000, loss: 4.2945, stu_CELoss: 2.5603 DKDLoss: 1.7342 
2022-05-01 21:51:31 - train: epoch 0010, iter [03400, 05004], lr: 0.100000, loss: 4.3889, stu_CELoss: 2.5723 DKDLoss: 1.8165 
2022-05-01 21:52:04 - train: epoch 0010, iter [03500, 05004], lr: 0.100000, loss: 4.2373, stu_CELoss: 2.5325 DKDLoss: 1.7048 
2022-05-01 21:52:38 - train: epoch 0010, iter [03600, 05004], lr: 0.100000, loss: 4.3862, stu_CELoss: 2.5415 DKDLoss: 1.8447 
2022-05-01 21:53:11 - train: epoch 0010, iter [03700, 05004], lr: 0.100000, loss: 4.4103, stu_CELoss: 2.6094 DKDLoss: 1.8009 
2022-05-01 21:53:44 - train: epoch 0010, iter [03800, 05004], lr: 0.100000, loss: 4.3270, stu_CELoss: 2.5357 DKDLoss: 1.7913 
2022-05-01 21:54:18 - train: epoch 0010, iter [03900, 05004], lr: 0.100000, loss: 3.7866, stu_CELoss: 2.2042 DKDLoss: 1.5824 
2022-05-01 21:54:50 - train: epoch 0010, iter [04000, 05004], lr: 0.100000, loss: 4.0926, stu_CELoss: 2.3539 DKDLoss: 1.7387 
2022-05-01 21:55:24 - train: epoch 0010, iter [04100, 05004], lr: 0.100000, loss: 3.6749, stu_CELoss: 2.1447 DKDLoss: 1.5302 
2022-05-01 21:55:56 - train: epoch 0010, iter [04200, 05004], lr: 0.100000, loss: 4.0451, stu_CELoss: 2.3394 DKDLoss: 1.7057 
2022-05-01 21:56:28 - train: epoch 0010, iter [04300, 05004], lr: 0.100000, loss: 4.1201, stu_CELoss: 2.3628 DKDLoss: 1.7573 
2022-05-01 21:57:01 - train: epoch 0010, iter [04400, 05004], lr: 0.100000, loss: 3.8768, stu_CELoss: 2.2975 DKDLoss: 1.5792 
2022-05-01 21:57:35 - train: epoch 0010, iter [04500, 05004], lr: 0.100000, loss: 4.1784, stu_CELoss: 2.5142 DKDLoss: 1.6642 
2022-05-01 21:58:07 - train: epoch 0010, iter [04600, 05004], lr: 0.100000, loss: 4.1964, stu_CELoss: 2.3735 DKDLoss: 1.8229 
2022-05-01 21:58:39 - train: epoch 0010, iter [04700, 05004], lr: 0.100000, loss: 3.9340, stu_CELoss: 2.2790 DKDLoss: 1.6550 
2022-05-01 21:59:12 - train: epoch 0010, iter [04800, 05004], lr: 0.100000, loss: 4.2014, stu_CELoss: 2.3769 DKDLoss: 1.8245 
2022-05-01 21:59:45 - train: epoch 0010, iter [04900, 05004], lr: 0.100000, loss: 4.3273, stu_CELoss: 2.5299 DKDLoss: 1.7973 
2022-05-01 22:00:16 - train: epoch 0010, iter [05000, 05004], lr: 0.100000, loss: 3.9247, stu_CELoss: 2.2994 DKDLoss: 1.6253 
2022-05-01 22:00:17 - train: epoch 010, train_loss: 4.0476
2022-05-01 22:02:43 - eval: epoch: 010, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 49.654%, stu_acc5: 75.452%, stu_test_loss: 2.1842
2022-05-01 22:02:43 - until epoch: 010, tea_best_acc1: 73.944%, stu_best_acc1: 50.458%
2022-05-01 22:02:43 - epoch 011 lr: 0.1
2022-05-01 22:03:21 - train: epoch 0011, iter [00100, 05004], lr: 0.100000, loss: 3.8875, stu_CELoss: 2.2984 DKDLoss: 1.5891 
2022-05-01 22:03:53 - train: epoch 0011, iter [00200, 05004], lr: 0.100000, loss: 4.2533, stu_CELoss: 2.6408 DKDLoss: 1.6125 
2022-05-01 22:04:26 - train: epoch 0011, iter [00300, 05004], lr: 0.100000, loss: 4.2129, stu_CELoss: 2.5387 DKDLoss: 1.6742 
2022-05-01 22:04:58 - train: epoch 0011, iter [00400, 05004], lr: 0.100000, loss: 4.3000, stu_CELoss: 2.6178 DKDLoss: 1.6822 
2022-05-01 22:05:31 - train: epoch 0011, iter [00500, 05004], lr: 0.100000, loss: 3.9371, stu_CELoss: 2.2620 DKDLoss: 1.6751 
2022-05-01 22:06:04 - train: epoch 0011, iter [00600, 05004], lr: 0.100000, loss: 4.3866, stu_CELoss: 2.6528 DKDLoss: 1.7337 
2022-05-01 22:06:36 - train: epoch 0011, iter [00700, 05004], lr: 0.100000, loss: 4.3811, stu_CELoss: 2.4895 DKDLoss: 1.8916 
2022-05-01 22:07:08 - train: epoch 0011, iter [00800, 05004], lr: 0.100000, loss: 4.0176, stu_CELoss: 2.4269 DKDLoss: 1.5907 
2022-05-01 22:07:40 - train: epoch 0011, iter [00900, 05004], lr: 0.100000, loss: 4.0748, stu_CELoss: 2.5775 DKDLoss: 1.4973 
2022-05-01 22:08:13 - train: epoch 0011, iter [01000, 05004], lr: 0.100000, loss: 3.9461, stu_CELoss: 2.3093 DKDLoss: 1.6368 
2022-05-01 22:08:45 - train: epoch 0011, iter [01100, 05004], lr: 0.100000, loss: 3.7897, stu_CELoss: 2.2423 DKDLoss: 1.5474 
2022-05-01 22:09:18 - train: epoch 0011, iter [01200, 05004], lr: 0.100000, loss: 4.3278, stu_CELoss: 2.5359 DKDLoss: 1.7919 
2022-05-01 22:09:51 - train: epoch 0011, iter [01300, 05004], lr: 0.100000, loss: 4.0525, stu_CELoss: 2.3623 DKDLoss: 1.6902 
2022-05-01 22:10:23 - train: epoch 0011, iter [01400, 05004], lr: 0.100000, loss: 4.1998, stu_CELoss: 2.6119 DKDLoss: 1.5880 
2022-05-01 22:10:57 - train: epoch 0011, iter [01500, 05004], lr: 0.100000, loss: 4.2260, stu_CELoss: 2.4541 DKDLoss: 1.7719 
2022-05-01 22:11:28 - train: epoch 0011, iter [01600, 05004], lr: 0.100000, loss: 4.0142, stu_CELoss: 2.4611 DKDLoss: 1.5531 
2022-05-01 22:12:01 - train: epoch 0011, iter [01700, 05004], lr: 0.100000, loss: 4.2374, stu_CELoss: 2.5285 DKDLoss: 1.7089 
2022-05-01 22:12:34 - train: epoch 0011, iter [01800, 05004], lr: 0.100000, loss: 4.0793, stu_CELoss: 2.4504 DKDLoss: 1.6288 
2022-05-01 22:13:07 - train: epoch 0011, iter [01900, 05004], lr: 0.100000, loss: 4.0567, stu_CELoss: 2.3002 DKDLoss: 1.7564 
2022-05-01 22:13:41 - train: epoch 0011, iter [02000, 05004], lr: 0.100000, loss: 3.9640, stu_CELoss: 2.2137 DKDLoss: 1.7503 
2022-05-01 22:14:15 - train: epoch 0011, iter [02100, 05004], lr: 0.100000, loss: 3.9271, stu_CELoss: 2.2784 DKDLoss: 1.6487 
2022-05-01 22:14:50 - train: epoch 0011, iter [02200, 05004], lr: 0.100000, loss: 3.8373, stu_CELoss: 2.1782 DKDLoss: 1.6591 
2022-05-01 22:15:24 - train: epoch 0011, iter [02300, 05004], lr: 0.100000, loss: 3.9694, stu_CELoss: 2.3619 DKDLoss: 1.6076 
2022-05-01 22:15:59 - train: epoch 0011, iter [02400, 05004], lr: 0.100000, loss: 3.6978, stu_CELoss: 2.1679 DKDLoss: 1.5299 
2022-05-01 22:16:32 - train: epoch 0011, iter [02500, 05004], lr: 0.100000, loss: 3.9046, stu_CELoss: 2.3827 DKDLoss: 1.5219 
2022-05-01 22:17:06 - train: epoch 0011, iter [02600, 05004], lr: 0.100000, loss: 3.9887, stu_CELoss: 2.2676 DKDLoss: 1.7210 
2022-05-01 22:17:40 - train: epoch 0011, iter [02700, 05004], lr: 0.100000, loss: 3.8555, stu_CELoss: 2.2919 DKDLoss: 1.5635 
2022-05-01 22:18:14 - train: epoch 0011, iter [02800, 05004], lr: 0.100000, loss: 3.5884, stu_CELoss: 2.0776 DKDLoss: 1.5108 
2022-05-01 22:18:48 - train: epoch 0011, iter [02900, 05004], lr: 0.100000, loss: 3.9830, stu_CELoss: 2.3805 DKDLoss: 1.6025 
2022-05-01 22:19:22 - train: epoch 0011, iter [03000, 05004], lr: 0.100000, loss: 4.3809, stu_CELoss: 2.6725 DKDLoss: 1.7084 
2022-05-01 22:19:56 - train: epoch 0011, iter [03100, 05004], lr: 0.100000, loss: 4.0507, stu_CELoss: 2.3703 DKDLoss: 1.6804 
2022-05-01 22:20:31 - train: epoch 0011, iter [03200, 05004], lr: 0.100000, loss: 4.1018, stu_CELoss: 2.3734 DKDLoss: 1.7284 
2022-05-01 22:21:05 - train: epoch 0011, iter [03300, 05004], lr: 0.100000, loss: 3.9645, stu_CELoss: 2.3471 DKDLoss: 1.6174 
2022-05-01 22:21:38 - train: epoch 0011, iter [03400, 05004], lr: 0.100000, loss: 3.7030, stu_CELoss: 2.2733 DKDLoss: 1.4297 
2022-05-01 22:22:12 - train: epoch 0011, iter [03500, 05004], lr: 0.100000, loss: 3.9379, stu_CELoss: 2.3008 DKDLoss: 1.6371 
2022-05-01 22:22:47 - train: epoch 0011, iter [03600, 05004], lr: 0.100000, loss: 3.8191, stu_CELoss: 2.2208 DKDLoss: 1.5983 
2022-05-01 22:23:21 - train: epoch 0011, iter [03700, 05004], lr: 0.100000, loss: 4.3066, stu_CELoss: 2.6545 DKDLoss: 1.6521 
2022-05-01 22:23:55 - train: epoch 0011, iter [03800, 05004], lr: 0.100000, loss: 4.0199, stu_CELoss: 2.3377 DKDLoss: 1.6822 
2022-05-01 22:24:29 - train: epoch 0011, iter [03900, 05004], lr: 0.100000, loss: 3.9196, stu_CELoss: 2.3013 DKDLoss: 1.6184 
2022-05-01 22:25:03 - train: epoch 0011, iter [04000, 05004], lr: 0.100000, loss: 3.7457, stu_CELoss: 2.0632 DKDLoss: 1.6826 
2022-05-01 22:25:37 - train: epoch 0011, iter [04100, 05004], lr: 0.100000, loss: 3.8719, stu_CELoss: 2.2385 DKDLoss: 1.6334 
2022-05-01 22:26:11 - train: epoch 0011, iter [04200, 05004], lr: 0.100000, loss: 3.8611, stu_CELoss: 2.2635 DKDLoss: 1.5977 
2022-05-01 22:26:44 - train: epoch 0011, iter [04300, 05004], lr: 0.100000, loss: 3.9817, stu_CELoss: 2.3101 DKDLoss: 1.6716 
2022-05-01 22:27:19 - train: epoch 0011, iter [04400, 05004], lr: 0.100000, loss: 4.1555, stu_CELoss: 2.5507 DKDLoss: 1.6047 
2022-05-01 22:27:54 - train: epoch 0011, iter [04500, 05004], lr: 0.100000, loss: 3.7596, stu_CELoss: 2.2055 DKDLoss: 1.5541 
2022-05-01 22:28:27 - train: epoch 0011, iter [04600, 05004], lr: 0.100000, loss: 3.9060, stu_CELoss: 2.3506 DKDLoss: 1.5554 
2022-05-01 22:29:00 - train: epoch 0011, iter [04700, 05004], lr: 0.100000, loss: 3.8956, stu_CELoss: 2.2726 DKDLoss: 1.6230 
2022-05-01 22:29:35 - train: epoch 0011, iter [04800, 05004], lr: 0.100000, loss: 3.6928, stu_CELoss: 2.0695 DKDLoss: 1.6234 
2022-05-01 22:30:09 - train: epoch 0011, iter [04900, 05004], lr: 0.100000, loss: 3.6663, stu_CELoss: 2.1250 DKDLoss: 1.5412 
2022-05-01 22:30:42 - train: epoch 0011, iter [05000, 05004], lr: 0.100000, loss: 3.8021, stu_CELoss: 2.2932 DKDLoss: 1.5089 
2022-05-01 22:30:43 - train: epoch 011, train_loss: 4.0130
2022-05-01 22:33:14 - eval: epoch: 011, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 51.276%, stu_acc5: 77.128%, stu_test_loss: 2.0866
2022-05-01 22:33:14 - until epoch: 011, tea_best_acc1: 73.944%, stu_best_acc1: 51.276%
2022-05-01 22:33:14 - epoch 012 lr: 0.1
2022-05-01 22:33:53 - train: epoch 0012, iter [00100, 05004], lr: 0.100000, loss: 3.5393, stu_CELoss: 2.1076 DKDLoss: 1.4317 
2022-05-01 22:34:27 - train: epoch 0012, iter [00200, 05004], lr: 0.100000, loss: 3.5273, stu_CELoss: 2.0240 DKDLoss: 1.5034 
2022-05-01 22:35:00 - train: epoch 0012, iter [00300, 05004], lr: 0.100000, loss: 3.9335, stu_CELoss: 2.2937 DKDLoss: 1.6398 
2022-05-01 22:35:34 - train: epoch 0012, iter [00400, 05004], lr: 0.100000, loss: 3.8120, stu_CELoss: 2.2971 DKDLoss: 1.5149 
2022-05-01 22:36:07 - train: epoch 0012, iter [00500, 05004], lr: 0.100000, loss: 4.3999, stu_CELoss: 2.5824 DKDLoss: 1.8175 
2022-05-01 22:36:41 - train: epoch 0012, iter [00600, 05004], lr: 0.100000, loss: 3.6806, stu_CELoss: 2.0487 DKDLoss: 1.6319 
2022-05-01 22:37:15 - train: epoch 0012, iter [00700, 05004], lr: 0.100000, loss: 3.6609, stu_CELoss: 2.1169 DKDLoss: 1.5440 
2022-05-01 22:37:49 - train: epoch 0012, iter [00800, 05004], lr: 0.100000, loss: 4.0346, stu_CELoss: 2.5746 DKDLoss: 1.4600 
2022-05-01 22:38:23 - train: epoch 0012, iter [00900, 05004], lr: 0.100000, loss: 4.0167, stu_CELoss: 2.3766 DKDLoss: 1.6400 
2022-05-01 22:38:58 - train: epoch 0012, iter [01000, 05004], lr: 0.100000, loss: 3.7219, stu_CELoss: 2.2101 DKDLoss: 1.5118 
2022-05-01 22:39:31 - train: epoch 0012, iter [01100, 05004], lr: 0.100000, loss: 4.1558, stu_CELoss: 2.5727 DKDLoss: 1.5830 
2022-05-01 22:40:05 - train: epoch 0012, iter [01200, 05004], lr: 0.100000, loss: 3.6113, stu_CELoss: 2.0862 DKDLoss: 1.5251 
2022-05-01 22:40:39 - train: epoch 0012, iter [01300, 05004], lr: 0.100000, loss: 3.7660, stu_CELoss: 2.2265 DKDLoss: 1.5395 
2022-05-01 22:41:13 - train: epoch 0012, iter [01400, 05004], lr: 0.100000, loss: 4.2514, stu_CELoss: 2.5543 DKDLoss: 1.6971 
2022-05-01 22:41:47 - train: epoch 0012, iter [01500, 05004], lr: 0.100000, loss: 3.7081, stu_CELoss: 2.1606 DKDLoss: 1.5475 
2022-05-01 22:42:21 - train: epoch 0012, iter [01600, 05004], lr: 0.100000, loss: 3.9290, stu_CELoss: 2.3088 DKDLoss: 1.6202 
2022-05-01 22:42:55 - train: epoch 0012, iter [01700, 05004], lr: 0.100000, loss: 3.7042, stu_CELoss: 2.1587 DKDLoss: 1.5455 
2022-05-01 22:43:29 - train: epoch 0012, iter [01800, 05004], lr: 0.100000, loss: 3.9648, stu_CELoss: 2.3999 DKDLoss: 1.5649 
2022-05-01 22:44:03 - train: epoch 0012, iter [01900, 05004], lr: 0.100000, loss: 4.1600, stu_CELoss: 2.5174 DKDLoss: 1.6426 
2022-05-01 22:44:36 - train: epoch 0012, iter [02000, 05004], lr: 0.100000, loss: 4.1195, stu_CELoss: 2.4578 DKDLoss: 1.6618 
2022-05-01 22:45:11 - train: epoch 0012, iter [02100, 05004], lr: 0.100000, loss: 4.0341, stu_CELoss: 2.4822 DKDLoss: 1.5519 
2022-05-01 22:45:44 - train: epoch 0012, iter [02200, 05004], lr: 0.100000, loss: 4.0528, stu_CELoss: 2.4889 DKDLoss: 1.5639 
2022-05-01 22:46:18 - train: epoch 0012, iter [02300, 05004], lr: 0.100000, loss: 4.0154, stu_CELoss: 2.3689 DKDLoss: 1.6464 
2022-05-01 22:46:52 - train: epoch 0012, iter [02400, 05004], lr: 0.100000, loss: 4.2546, stu_CELoss: 2.4133 DKDLoss: 1.8414 
2022-05-01 22:47:26 - train: epoch 0012, iter [02500, 05004], lr: 0.100000, loss: 3.8717, stu_CELoss: 2.2180 DKDLoss: 1.6538 
2022-05-01 22:48:00 - train: epoch 0012, iter [02600, 05004], lr: 0.100000, loss: 3.6971, stu_CELoss: 2.2003 DKDLoss: 1.4968 
2022-05-01 22:48:34 - train: epoch 0012, iter [02700, 05004], lr: 0.100000, loss: 3.8668, stu_CELoss: 2.3002 DKDLoss: 1.5666 
2022-05-01 22:49:09 - train: epoch 0012, iter [02800, 05004], lr: 0.100000, loss: 3.8172, stu_CELoss: 2.3770 DKDLoss: 1.4402 
2022-05-01 22:49:42 - train: epoch 0012, iter [02900, 05004], lr: 0.100000, loss: 3.7482, stu_CELoss: 2.3307 DKDLoss: 1.4175 
2022-05-01 22:50:16 - train: epoch 0012, iter [03000, 05004], lr: 0.100000, loss: 3.7442, stu_CELoss: 2.1832 DKDLoss: 1.5610 
2022-05-01 22:50:49 - train: epoch 0012, iter [03100, 05004], lr: 0.100000, loss: 4.1083, stu_CELoss: 2.4645 DKDLoss: 1.6439 
2022-05-01 22:51:24 - train: epoch 0012, iter [03200, 05004], lr: 0.100000, loss: 4.0102, stu_CELoss: 2.2918 DKDLoss: 1.7184 
2022-05-01 22:51:58 - train: epoch 0012, iter [03300, 05004], lr: 0.100000, loss: 3.7738, stu_CELoss: 2.2655 DKDLoss: 1.5083 
2022-05-01 22:52:32 - train: epoch 0012, iter [03400, 05004], lr: 0.100000, loss: 3.8781, stu_CELoss: 2.3876 DKDLoss: 1.4904 
2022-05-01 22:53:05 - train: epoch 0012, iter [03500, 05004], lr: 0.100000, loss: 3.9009, stu_CELoss: 2.3097 DKDLoss: 1.5912 
2022-05-01 22:53:40 - train: epoch 0012, iter [03600, 05004], lr: 0.100000, loss: 4.1184, stu_CELoss: 2.2983 DKDLoss: 1.8200 
2022-05-01 22:54:13 - train: epoch 0012, iter [03700, 05004], lr: 0.100000, loss: 4.0701, stu_CELoss: 2.5486 DKDLoss: 1.5215 
2022-05-01 22:54:47 - train: epoch 0012, iter [03800, 05004], lr: 0.100000, loss: 4.2374, stu_CELoss: 2.4858 DKDLoss: 1.7516 
2022-05-01 22:55:21 - train: epoch 0012, iter [03900, 05004], lr: 0.100000, loss: 3.6636, stu_CELoss: 2.1219 DKDLoss: 1.5417 
2022-05-01 22:55:54 - train: epoch 0012, iter [04000, 05004], lr: 0.100000, loss: 3.9745, stu_CELoss: 2.3740 DKDLoss: 1.6005 
2022-05-01 22:56:29 - train: epoch 0012, iter [04100, 05004], lr: 0.100000, loss: 4.1656, stu_CELoss: 2.4311 DKDLoss: 1.7346 
2022-05-01 22:57:04 - train: epoch 0012, iter [04200, 05004], lr: 0.100000, loss: 3.8614, stu_CELoss: 2.2595 DKDLoss: 1.6019 
2022-05-01 22:57:38 - train: epoch 0012, iter [04300, 05004], lr: 0.100000, loss: 4.0230, stu_CELoss: 2.4912 DKDLoss: 1.5318 
2022-05-01 22:58:11 - train: epoch 0012, iter [04400, 05004], lr: 0.100000, loss: 3.9245, stu_CELoss: 2.3259 DKDLoss: 1.5985 
2022-05-01 22:58:46 - train: epoch 0012, iter [04500, 05004], lr: 0.100000, loss: 3.9464, stu_CELoss: 2.3069 DKDLoss: 1.6395 
2022-05-01 22:59:20 - train: epoch 0012, iter [04600, 05004], lr: 0.100000, loss: 4.1744, stu_CELoss: 2.4086 DKDLoss: 1.7658 
2022-05-01 22:59:54 - train: epoch 0012, iter [04700, 05004], lr: 0.100000, loss: 3.8047, stu_CELoss: 2.2474 DKDLoss: 1.5573 
2022-05-01 23:00:28 - train: epoch 0012, iter [04800, 05004], lr: 0.100000, loss: 4.0233, stu_CELoss: 2.3563 DKDLoss: 1.6670 
2022-05-01 23:01:04 - train: epoch 0012, iter [04900, 05004], lr: 0.100000, loss: 3.8442, stu_CELoss: 2.2286 DKDLoss: 1.6156 
2022-05-01 23:01:37 - train: epoch 0012, iter [05000, 05004], lr: 0.100000, loss: 3.8198, stu_CELoss: 2.2950 DKDLoss: 1.5248 
2022-05-01 23:01:37 - train: epoch 012, train_loss: 3.9742
2022-05-01 23:04:09 - eval: epoch: 012, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 49.862%, stu_acc5: 75.720%, stu_test_loss: 2.1673
2022-05-01 23:04:09 - until epoch: 012, tea_best_acc1: 73.944%, stu_best_acc1: 51.276%
2022-05-01 23:04:09 - epoch 013 lr: 0.1
2022-05-01 23:04:48 - train: epoch 0013, iter [00100, 05004], lr: 0.100000, loss: 3.5604, stu_CELoss: 2.0776 DKDLoss: 1.4829 
2022-05-01 23:05:23 - train: epoch 0013, iter [00200, 05004], lr: 0.100000, loss: 3.9545, stu_CELoss: 2.3629 DKDLoss: 1.5916 
2022-05-01 23:05:58 - train: epoch 0013, iter [00300, 05004], lr: 0.100000, loss: 3.7216, stu_CELoss: 2.3062 DKDLoss: 1.4154 
2022-05-01 23:06:33 - train: epoch 0013, iter [00400, 05004], lr: 0.100000, loss: 3.7789, stu_CELoss: 2.1797 DKDLoss: 1.5993 
2022-05-01 23:07:08 - train: epoch 0013, iter [00500, 05004], lr: 0.100000, loss: 3.9635, stu_CELoss: 2.3717 DKDLoss: 1.5918 
2022-05-01 23:07:43 - train: epoch 0013, iter [00600, 05004], lr: 0.100000, loss: 3.8620, stu_CELoss: 2.3933 DKDLoss: 1.4687 
2022-05-01 23:08:17 - train: epoch 0013, iter [00700, 05004], lr: 0.100000, loss: 3.8698, stu_CELoss: 2.2309 DKDLoss: 1.6389 
2022-05-01 23:08:52 - train: epoch 0013, iter [00800, 05004], lr: 0.100000, loss: 4.4023, stu_CELoss: 2.5758 DKDLoss: 1.8265 
2022-05-01 23:09:27 - train: epoch 0013, iter [00900, 05004], lr: 0.100000, loss: 4.0017, stu_CELoss: 2.4605 DKDLoss: 1.5412 
2022-05-01 23:10:02 - train: epoch 0013, iter [01000, 05004], lr: 0.100000, loss: 3.9072, stu_CELoss: 2.2933 DKDLoss: 1.6140 
2022-05-01 23:10:36 - train: epoch 0013, iter [01100, 05004], lr: 0.100000, loss: 3.9118, stu_CELoss: 2.3102 DKDLoss: 1.6016 
2022-05-01 23:11:11 - train: epoch 0013, iter [01200, 05004], lr: 0.100000, loss: 4.1930, stu_CELoss: 2.5446 DKDLoss: 1.6484 
2022-05-01 23:11:46 - train: epoch 0013, iter [01300, 05004], lr: 0.100000, loss: 3.9381, stu_CELoss: 2.2571 DKDLoss: 1.6810 
2022-05-01 23:12:21 - train: epoch 0013, iter [01400, 05004], lr: 0.100000, loss: 3.8484, stu_CELoss: 2.2112 DKDLoss: 1.6372 
2022-05-01 23:12:56 - train: epoch 0013, iter [01500, 05004], lr: 0.100000, loss: 4.1154, stu_CELoss: 2.4297 DKDLoss: 1.6857 
2022-05-01 23:13:31 - train: epoch 0013, iter [01600, 05004], lr: 0.100000, loss: 3.9961, stu_CELoss: 2.3557 DKDLoss: 1.6404 
2022-05-01 23:14:06 - train: epoch 0013, iter [01700, 05004], lr: 0.100000, loss: 4.0253, stu_CELoss: 2.3270 DKDLoss: 1.6983 
2022-05-01 23:14:41 - train: epoch 0013, iter [01800, 05004], lr: 0.100000, loss: 4.0279, stu_CELoss: 2.3405 DKDLoss: 1.6874 
2022-05-01 23:15:16 - train: epoch 0013, iter [01900, 05004], lr: 0.100000, loss: 3.9509, stu_CELoss: 2.3750 DKDLoss: 1.5759 
2022-05-01 23:15:51 - train: epoch 0013, iter [02000, 05004], lr: 0.100000, loss: 3.9522, stu_CELoss: 2.3359 DKDLoss: 1.6163 
2022-05-01 23:16:26 - train: epoch 0013, iter [02100, 05004], lr: 0.100000, loss: 4.0913, stu_CELoss: 2.4442 DKDLoss: 1.6470 
2022-05-01 23:17:01 - train: epoch 0013, iter [02200, 05004], lr: 0.100000, loss: 3.8905, stu_CELoss: 2.2629 DKDLoss: 1.6276 
2022-05-01 23:17:35 - train: epoch 0013, iter [02300, 05004], lr: 0.100000, loss: 3.9338, stu_CELoss: 2.3216 DKDLoss: 1.6122 
2022-05-01 23:18:10 - train: epoch 0013, iter [02400, 05004], lr: 0.100000, loss: 4.1786, stu_CELoss: 2.5116 DKDLoss: 1.6670 
2022-05-01 23:18:44 - train: epoch 0013, iter [02500, 05004], lr: 0.100000, loss: 3.9384, stu_CELoss: 2.3065 DKDLoss: 1.6320 
2022-05-01 23:19:19 - train: epoch 0013, iter [02600, 05004], lr: 0.100000, loss: 3.7506, stu_CELoss: 2.2526 DKDLoss: 1.4980 
2022-05-01 23:19:55 - train: epoch 0013, iter [02700, 05004], lr: 0.100000, loss: 3.9890, stu_CELoss: 2.3804 DKDLoss: 1.6086 
2022-05-01 23:20:30 - train: epoch 0013, iter [02800, 05004], lr: 0.100000, loss: 3.9808, stu_CELoss: 2.3069 DKDLoss: 1.6739 
2022-05-01 23:21:04 - train: epoch 0013, iter [02900, 05004], lr: 0.100000, loss: 3.8279, stu_CELoss: 2.3738 DKDLoss: 1.4542 
2022-05-01 23:21:39 - train: epoch 0013, iter [03000, 05004], lr: 0.100000, loss: 3.9065, stu_CELoss: 2.1597 DKDLoss: 1.7468 
2022-05-01 23:22:13 - train: epoch 0013, iter [03100, 05004], lr: 0.100000, loss: 4.0342, stu_CELoss: 2.3058 DKDLoss: 1.7285 
2022-05-01 23:22:48 - train: epoch 0013, iter [03200, 05004], lr: 0.100000, loss: 4.0549, stu_CELoss: 2.4297 DKDLoss: 1.6252 
2022-05-01 23:23:23 - train: epoch 0013, iter [03300, 05004], lr: 0.100000, loss: 3.7818, stu_CELoss: 2.1900 DKDLoss: 1.5918 
2022-05-01 23:23:59 - train: epoch 0013, iter [03400, 05004], lr: 0.100000, loss: 3.9385, stu_CELoss: 2.2593 DKDLoss: 1.6791 
2022-05-01 23:24:32 - train: epoch 0013, iter [03500, 05004], lr: 0.100000, loss: 3.9521, stu_CELoss: 2.3118 DKDLoss: 1.6403 
2022-05-01 23:25:08 - train: epoch 0013, iter [03600, 05004], lr: 0.100000, loss: 4.0996, stu_CELoss: 2.4593 DKDLoss: 1.6403 
2022-05-01 23:25:43 - train: epoch 0013, iter [03700, 05004], lr: 0.100000, loss: 3.8681, stu_CELoss: 2.1266 DKDLoss: 1.7415 
2022-05-01 23:26:18 - train: epoch 0013, iter [03800, 05004], lr: 0.100000, loss: 4.0336, stu_CELoss: 2.5214 DKDLoss: 1.5122 
2022-05-01 23:26:53 - train: epoch 0013, iter [03900, 05004], lr: 0.100000, loss: 4.2168, stu_CELoss: 2.5626 DKDLoss: 1.6542 
2022-05-01 23:27:28 - train: epoch 0013, iter [04000, 05004], lr: 0.100000, loss: 3.9191, stu_CELoss: 2.3332 DKDLoss: 1.5859 
2022-05-01 23:28:02 - train: epoch 0013, iter [04100, 05004], lr: 0.100000, loss: 3.9211, stu_CELoss: 2.2510 DKDLoss: 1.6702 
2022-05-01 23:28:39 - train: epoch 0013, iter [04200, 05004], lr: 0.100000, loss: 4.1322, stu_CELoss: 2.3931 DKDLoss: 1.7391 
2022-05-01 23:29:11 - train: epoch 0013, iter [04300, 05004], lr: 0.100000, loss: 4.1988, stu_CELoss: 2.3726 DKDLoss: 1.8262 
2022-05-01 23:29:46 - train: epoch 0013, iter [04400, 05004], lr: 0.100000, loss: 3.7728, stu_CELoss: 2.1994 DKDLoss: 1.5734 
2022-05-01 23:30:21 - train: epoch 0013, iter [04500, 05004], lr: 0.100000, loss: 3.7385, stu_CELoss: 2.2361 DKDLoss: 1.5024 
2022-05-01 23:30:57 - train: epoch 0013, iter [04600, 05004], lr: 0.100000, loss: 3.9422, stu_CELoss: 2.1824 DKDLoss: 1.7599 
2022-05-01 23:31:32 - train: epoch 0013, iter [04700, 05004], lr: 0.100000, loss: 4.0302, stu_CELoss: 2.4561 DKDLoss: 1.5742 
2022-05-01 23:32:08 - train: epoch 0013, iter [04800, 05004], lr: 0.100000, loss: 4.1206, stu_CELoss: 2.4449 DKDLoss: 1.6757 
2022-05-01 23:32:43 - train: epoch 0013, iter [04900, 05004], lr: 0.100000, loss: 4.1694, stu_CELoss: 2.5068 DKDLoss: 1.6625 
2022-05-01 23:33:16 - train: epoch 0013, iter [05000, 05004], lr: 0.100000, loss: 3.9734, stu_CELoss: 2.2905 DKDLoss: 1.6829 
2022-05-01 23:33:17 - train: epoch 013, train_loss: 3.9522
2022-05-01 23:35:51 - eval: epoch: 013, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 51.800%, stu_acc5: 77.056%, stu_test_loss: 2.0778
2022-05-01 23:35:52 - until epoch: 013, tea_best_acc1: 73.944%, stu_best_acc1: 51.800%
2022-05-01 23:35:52 - epoch 014 lr: 0.1
2022-05-01 23:36:32 - train: epoch 0014, iter [00100, 05004], lr: 0.100000, loss: 3.5730, stu_CELoss: 2.1981 DKDLoss: 1.3749 
2022-05-01 23:37:07 - train: epoch 0014, iter [00200, 05004], lr: 0.100000, loss: 4.0511, stu_CELoss: 2.4198 DKDLoss: 1.6313 
2022-05-01 23:37:41 - train: epoch 0014, iter [00300, 05004], lr: 0.100000, loss: 3.3787, stu_CELoss: 2.1270 DKDLoss: 1.2517 
2022-05-01 23:38:16 - train: epoch 0014, iter [00400, 05004], lr: 0.100000, loss: 3.7522, stu_CELoss: 2.2155 DKDLoss: 1.5367 
2022-05-01 23:38:51 - train: epoch 0014, iter [00500, 05004], lr: 0.100000, loss: 3.7012, stu_CELoss: 2.2388 DKDLoss: 1.4624 
2022-05-01 23:39:25 - train: epoch 0014, iter [00600, 05004], lr: 0.100000, loss: 3.9913, stu_CELoss: 2.4651 DKDLoss: 1.5262 
2022-05-01 23:40:00 - train: epoch 0014, iter [00700, 05004], lr: 0.100000, loss: 3.6667, stu_CELoss: 2.1868 DKDLoss: 1.4800 
2022-05-01 23:40:35 - train: epoch 0014, iter [00800, 05004], lr: 0.100000, loss: 3.8052, stu_CELoss: 2.2355 DKDLoss: 1.5697 
2022-05-01 23:41:09 - train: epoch 0014, iter [00900, 05004], lr: 0.100000, loss: 3.6234, stu_CELoss: 2.1485 DKDLoss: 1.4749 
2022-05-01 23:41:44 - train: epoch 0014, iter [01000, 05004], lr: 0.100000, loss: 4.1840, stu_CELoss: 2.4365 DKDLoss: 1.7475 
2022-05-01 23:42:19 - train: epoch 0014, iter [01100, 05004], lr: 0.100000, loss: 3.8752, stu_CELoss: 2.2826 DKDLoss: 1.5926 
2022-05-01 23:42:54 - train: epoch 0014, iter [01200, 05004], lr: 0.100000, loss: 4.3861, stu_CELoss: 2.5938 DKDLoss: 1.7923 
2022-05-01 23:43:29 - train: epoch 0014, iter [01300, 05004], lr: 0.100000, loss: 4.1854, stu_CELoss: 2.4654 DKDLoss: 1.7200 
2022-05-01 23:44:03 - train: epoch 0014, iter [01400, 05004], lr: 0.100000, loss: 4.0156, stu_CELoss: 2.4196 DKDLoss: 1.5960 
2022-05-01 23:44:38 - train: epoch 0014, iter [01500, 05004], lr: 0.100000, loss: 4.2657, stu_CELoss: 2.5127 DKDLoss: 1.7530 
2022-05-01 23:45:14 - train: epoch 0014, iter [01600, 05004], lr: 0.100000, loss: 3.7881, stu_CELoss: 2.2598 DKDLoss: 1.5283 
2022-05-01 23:45:49 - train: epoch 0014, iter [01700, 05004], lr: 0.100000, loss: 4.0010, stu_CELoss: 2.4243 DKDLoss: 1.5766 
2022-05-01 23:46:23 - train: epoch 0014, iter [01800, 05004], lr: 0.100000, loss: 4.2495, stu_CELoss: 2.5180 DKDLoss: 1.7315 
2022-05-01 23:46:59 - train: epoch 0014, iter [01900, 05004], lr: 0.100000, loss: 3.7510, stu_CELoss: 2.2561 DKDLoss: 1.4949 
2022-05-01 23:47:34 - train: epoch 0014, iter [02000, 05004], lr: 0.100000, loss: 3.8300, stu_CELoss: 2.1757 DKDLoss: 1.6543 
2022-05-01 23:48:08 - train: epoch 0014, iter [02100, 05004], lr: 0.100000, loss: 3.9484, stu_CELoss: 2.3484 DKDLoss: 1.6000 
2022-05-01 23:48:43 - train: epoch 0014, iter [02200, 05004], lr: 0.100000, loss: 3.8129, stu_CELoss: 2.1987 DKDLoss: 1.6142 
2022-05-01 23:49:16 - train: epoch 0014, iter [02300, 05004], lr: 0.100000, loss: 3.9969, stu_CELoss: 2.3291 DKDLoss: 1.6677 
2022-05-01 23:49:51 - train: epoch 0014, iter [02400, 05004], lr: 0.100000, loss: 3.9400, stu_CELoss: 2.3473 DKDLoss: 1.5927 
2022-05-01 23:50:26 - train: epoch 0014, iter [02500, 05004], lr: 0.100000, loss: 3.9004, stu_CELoss: 2.3055 DKDLoss: 1.5949 
2022-05-01 23:51:00 - train: epoch 0014, iter [02600, 05004], lr: 0.100000, loss: 3.7714, stu_CELoss: 2.2017 DKDLoss: 1.5697 
2022-05-01 23:51:36 - train: epoch 0014, iter [02700, 05004], lr: 0.100000, loss: 4.0764, stu_CELoss: 2.3457 DKDLoss: 1.7307 
2022-05-01 23:52:10 - train: epoch 0014, iter [02800, 05004], lr: 0.100000, loss: 4.0824, stu_CELoss: 2.5150 DKDLoss: 1.5673 
2022-05-01 23:52:46 - train: epoch 0014, iter [02900, 05004], lr: 0.100000, loss: 4.1485, stu_CELoss: 2.4619 DKDLoss: 1.6866 
2022-05-01 23:53:21 - train: epoch 0014, iter [03000, 05004], lr: 0.100000, loss: 4.1284, stu_CELoss: 2.4492 DKDLoss: 1.6793 
2022-05-01 23:53:56 - train: epoch 0014, iter [03100, 05004], lr: 0.100000, loss: 4.0036, stu_CELoss: 2.2578 DKDLoss: 1.7458 
2022-05-01 23:54:30 - train: epoch 0014, iter [03200, 05004], lr: 0.100000, loss: 3.7907, stu_CELoss: 2.2536 DKDLoss: 1.5372 
2022-05-01 23:55:06 - train: epoch 0014, iter [03300, 05004], lr: 0.100000, loss: 3.6979, stu_CELoss: 2.1677 DKDLoss: 1.5301 
2022-05-01 23:55:41 - train: epoch 0014, iter [03400, 05004], lr: 0.100000, loss: 3.8752, stu_CELoss: 2.2699 DKDLoss: 1.6053 
2022-05-01 23:56:15 - train: epoch 0014, iter [03500, 05004], lr: 0.100000, loss: 4.0280, stu_CELoss: 2.3435 DKDLoss: 1.6845 
2022-05-01 23:56:51 - train: epoch 0014, iter [03600, 05004], lr: 0.100000, loss: 3.6511, stu_CELoss: 2.0904 DKDLoss: 1.5607 
2022-05-01 23:57:25 - train: epoch 0014, iter [03700, 05004], lr: 0.100000, loss: 4.1385, stu_CELoss: 2.4640 DKDLoss: 1.6745 
2022-05-01 23:58:01 - train: epoch 0014, iter [03800, 05004], lr: 0.100000, loss: 3.8961, stu_CELoss: 2.4083 DKDLoss: 1.4878 
2022-05-01 23:58:35 - train: epoch 0014, iter [03900, 05004], lr: 0.100000, loss: 3.9672, stu_CELoss: 2.4268 DKDLoss: 1.5404 
2022-05-01 23:59:11 - train: epoch 0014, iter [04000, 05004], lr: 0.100000, loss: 3.9471, stu_CELoss: 2.3357 DKDLoss: 1.6113 
2022-05-01 23:59:45 - train: epoch 0014, iter [04100, 05004], lr: 0.100000, loss: 4.1554, stu_CELoss: 2.3526 DKDLoss: 1.8028 
2022-05-02 00:00:20 - train: epoch 0014, iter [04200, 05004], lr: 0.100000, loss: 3.7943, stu_CELoss: 2.2153 DKDLoss: 1.5790 
2022-05-02 00:00:55 - train: epoch 0014, iter [04300, 05004], lr: 0.100000, loss: 3.9723, stu_CELoss: 2.4125 DKDLoss: 1.5597 
2022-05-02 00:01:30 - train: epoch 0014, iter [04400, 05004], lr: 0.100000, loss: 3.8947, stu_CELoss: 2.2850 DKDLoss: 1.6098 
2022-05-02 00:02:06 - train: epoch 0014, iter [04500, 05004], lr: 0.100000, loss: 4.0154, stu_CELoss: 2.3787 DKDLoss: 1.6366 
2022-05-02 00:02:40 - train: epoch 0014, iter [04600, 05004], lr: 0.100000, loss: 3.9748, stu_CELoss: 2.2933 DKDLoss: 1.6815 
2022-05-02 00:03:16 - train: epoch 0014, iter [04700, 05004], lr: 0.100000, loss: 3.7139, stu_CELoss: 2.1288 DKDLoss: 1.5851 
2022-05-02 00:03:50 - train: epoch 0014, iter [04800, 05004], lr: 0.100000, loss: 4.2641, stu_CELoss: 2.5227 DKDLoss: 1.7414 
2022-05-02 00:04:25 - train: epoch 0014, iter [04900, 05004], lr: 0.100000, loss: 4.0409, stu_CELoss: 2.4591 DKDLoss: 1.5818 
2022-05-02 00:04:58 - train: epoch 0014, iter [05000, 05004], lr: 0.100000, loss: 3.7570, stu_CELoss: 2.3325 DKDLoss: 1.4245 
2022-05-02 00:04:59 - train: epoch 014, train_loss: 3.9302
2022-05-02 00:07:34 - eval: epoch: 014, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 50.690%, stu_acc5: 76.124%, stu_test_loss: 2.1424
2022-05-02 00:07:34 - until epoch: 014, tea_best_acc1: 73.944%, stu_best_acc1: 51.800%
2022-05-02 00:07:34 - epoch 015 lr: 0.1
2022-05-02 00:08:15 - train: epoch 0015, iter [00100, 05004], lr: 0.100000, loss: 3.6972, stu_CELoss: 2.1064 DKDLoss: 1.5908 
2022-05-02 00:08:50 - train: epoch 0015, iter [00200, 05004], lr: 0.100000, loss: 3.9173, stu_CELoss: 2.4442 DKDLoss: 1.4732 
2022-05-02 00:09:24 - train: epoch 0015, iter [00300, 05004], lr: 0.100000, loss: 4.1267, stu_CELoss: 2.5368 DKDLoss: 1.5899 
2022-05-02 00:09:59 - train: epoch 0015, iter [00400, 05004], lr: 0.100000, loss: 3.8015, stu_CELoss: 2.2372 DKDLoss: 1.5643 
2022-05-02 00:10:33 - train: epoch 0015, iter [00500, 05004], lr: 0.100000, loss: 3.9542, stu_CELoss: 2.2680 DKDLoss: 1.6862 
2022-05-02 00:11:09 - train: epoch 0015, iter [00600, 05004], lr: 0.100000, loss: 3.9381, stu_CELoss: 2.4027 DKDLoss: 1.5354 
2022-05-02 00:11:45 - train: epoch 0015, iter [00700, 05004], lr: 0.100000, loss: 4.1097, stu_CELoss: 2.4403 DKDLoss: 1.6694 
2022-05-02 00:12:19 - train: epoch 0015, iter [00800, 05004], lr: 0.100000, loss: 3.6987, stu_CELoss: 2.2096 DKDLoss: 1.4891 
2022-05-02 00:12:55 - train: epoch 0015, iter [00900, 05004], lr: 0.100000, loss: 3.5311, stu_CELoss: 2.1133 DKDLoss: 1.4179 
2022-05-02 00:13:28 - train: epoch 0015, iter [01000, 05004], lr: 0.100000, loss: 3.8673, stu_CELoss: 2.2693 DKDLoss: 1.5980 
2022-05-02 00:14:04 - train: epoch 0015, iter [01100, 05004], lr: 0.100000, loss: 3.8284, stu_CELoss: 2.2675 DKDLoss: 1.5609 
2022-05-02 00:14:39 - train: epoch 0015, iter [01200, 05004], lr: 0.100000, loss: 3.7930, stu_CELoss: 2.3376 DKDLoss: 1.4554 
2022-05-02 00:15:14 - train: epoch 0015, iter [01300, 05004], lr: 0.100000, loss: 4.1514, stu_CELoss: 2.5464 DKDLoss: 1.6050 
2022-05-02 00:15:48 - train: epoch 0015, iter [01400, 05004], lr: 0.100000, loss: 3.7051, stu_CELoss: 2.2123 DKDLoss: 1.4928 
2022-05-02 00:16:23 - train: epoch 0015, iter [01500, 05004], lr: 0.100000, loss: 4.0226, stu_CELoss: 2.3791 DKDLoss: 1.6435 
2022-05-02 00:16:59 - train: epoch 0015, iter [01600, 05004], lr: 0.100000, loss: 4.3430, stu_CELoss: 2.5123 DKDLoss: 1.8307 
2022-05-02 00:17:33 - train: epoch 0015, iter [01700, 05004], lr: 0.100000, loss: 4.1968, stu_CELoss: 2.3944 DKDLoss: 1.8024 
2022-05-02 00:18:07 - train: epoch 0015, iter [01800, 05004], lr: 0.100000, loss: 3.9627, stu_CELoss: 2.3708 DKDLoss: 1.5919 
2022-05-02 00:18:42 - train: epoch 0015, iter [01900, 05004], lr: 0.100000, loss: 3.8197, stu_CELoss: 2.1851 DKDLoss: 1.6346 
2022-05-02 00:19:18 - train: epoch 0015, iter [02000, 05004], lr: 0.100000, loss: 3.5400, stu_CELoss: 2.0554 DKDLoss: 1.4846 
2022-05-02 00:19:53 - train: epoch 0015, iter [02100, 05004], lr: 0.100000, loss: 3.7397, stu_CELoss: 2.2266 DKDLoss: 1.5131 
2022-05-02 00:20:27 - train: epoch 0015, iter [02200, 05004], lr: 0.100000, loss: 3.7586, stu_CELoss: 2.2811 DKDLoss: 1.4775 
2022-05-02 00:21:03 - train: epoch 0015, iter [02300, 05004], lr: 0.100000, loss: 4.0156, stu_CELoss: 2.3658 DKDLoss: 1.6497 
2022-05-02 00:21:38 - train: epoch 0015, iter [02400, 05004], lr: 0.100000, loss: 3.8007, stu_CELoss: 2.3245 DKDLoss: 1.4763 
2022-05-02 00:22:13 - train: epoch 0015, iter [02500, 05004], lr: 0.100000, loss: 3.9054, stu_CELoss: 2.4180 DKDLoss: 1.4874 
2022-05-02 00:22:49 - train: epoch 0015, iter [02600, 05004], lr: 0.100000, loss: 3.7221, stu_CELoss: 2.1411 DKDLoss: 1.5810 
2022-05-02 00:23:23 - train: epoch 0015, iter [02700, 05004], lr: 0.100000, loss: 3.8482, stu_CELoss: 2.4355 DKDLoss: 1.4127 
2022-05-02 00:23:58 - train: epoch 0015, iter [02800, 05004], lr: 0.100000, loss: 4.0048, stu_CELoss: 2.3838 DKDLoss: 1.6210 
2022-05-02 00:24:34 - train: epoch 0015, iter [02900, 05004], lr: 0.100000, loss: 3.8790, stu_CELoss: 2.3115 DKDLoss: 1.5674 
2022-05-02 00:25:09 - train: epoch 0015, iter [03000, 05004], lr: 0.100000, loss: 3.7124, stu_CELoss: 2.1330 DKDLoss: 1.5794 
2022-05-02 00:25:44 - train: epoch 0015, iter [03100, 05004], lr: 0.100000, loss: 3.7833, stu_CELoss: 2.2951 DKDLoss: 1.4882 
2022-05-02 00:26:19 - train: epoch 0015, iter [03200, 05004], lr: 0.100000, loss: 3.9196, stu_CELoss: 2.2441 DKDLoss: 1.6755 
2022-05-02 00:26:55 - train: epoch 0015, iter [03300, 05004], lr: 0.100000, loss: 3.6918, stu_CELoss: 2.1516 DKDLoss: 1.5402 
2022-05-02 00:27:30 - train: epoch 0015, iter [03400, 05004], lr: 0.100000, loss: 3.8567, stu_CELoss: 2.2356 DKDLoss: 1.6211 
2022-05-02 00:28:04 - train: epoch 0015, iter [03500, 05004], lr: 0.100000, loss: 4.1512, stu_CELoss: 2.5196 DKDLoss: 1.6316 
2022-05-02 00:28:39 - train: epoch 0015, iter [03600, 05004], lr: 0.100000, loss: 4.1077, stu_CELoss: 2.4707 DKDLoss: 1.6371 
2022-05-02 00:29:15 - train: epoch 0015, iter [03700, 05004], lr: 0.100000, loss: 3.5151, stu_CELoss: 1.9686 DKDLoss: 1.5465 
2022-05-02 00:29:51 - train: epoch 0015, iter [03800, 05004], lr: 0.100000, loss: 3.7928, stu_CELoss: 2.2985 DKDLoss: 1.4944 
2022-05-02 00:30:25 - train: epoch 0015, iter [03900, 05004], lr: 0.100000, loss: 4.2633, stu_CELoss: 2.4786 DKDLoss: 1.7847 
2022-05-02 00:31:00 - train: epoch 0015, iter [04000, 05004], lr: 0.100000, loss: 4.0706, stu_CELoss: 2.3762 DKDLoss: 1.6944 
2022-05-02 00:31:35 - train: epoch 0015, iter [04100, 05004], lr: 0.100000, loss: 4.0199, stu_CELoss: 2.3105 DKDLoss: 1.7095 
2022-05-02 00:32:11 - train: epoch 0015, iter [04200, 05004], lr: 0.100000, loss: 3.8309, stu_CELoss: 2.2187 DKDLoss: 1.6122 
2022-05-02 00:32:46 - train: epoch 0015, iter [04300, 05004], lr: 0.100000, loss: 4.1323, stu_CELoss: 2.3559 DKDLoss: 1.7764 
2022-05-02 00:33:21 - train: epoch 0015, iter [04400, 05004], lr: 0.100000, loss: 3.7408, stu_CELoss: 2.2579 DKDLoss: 1.4830 
2022-05-02 00:33:56 - train: epoch 0015, iter [04500, 05004], lr: 0.100000, loss: 3.9336, stu_CELoss: 2.3506 DKDLoss: 1.5830 
2022-05-02 00:34:30 - train: epoch 0015, iter [04600, 05004], lr: 0.100000, loss: 4.0345, stu_CELoss: 2.3798 DKDLoss: 1.6546 
2022-05-02 00:35:06 - train: epoch 0015, iter [04700, 05004], lr: 0.100000, loss: 4.1292, stu_CELoss: 2.4364 DKDLoss: 1.6929 
2022-05-02 00:35:40 - train: epoch 0015, iter [04800, 05004], lr: 0.100000, loss: 4.0669, stu_CELoss: 2.4529 DKDLoss: 1.6140 
2022-05-02 00:36:13 - train: epoch 0015, iter [04900, 05004], lr: 0.100000, loss: 3.7595, stu_CELoss: 2.2284 DKDLoss: 1.5312 
2022-05-02 00:36:46 - train: epoch 0015, iter [05000, 05004], lr: 0.100000, loss: 3.9468, stu_CELoss: 2.4634 DKDLoss: 1.4834 
2022-05-02 00:36:47 - train: epoch 015, train_loss: 3.9130
2022-05-02 00:39:17 - eval: epoch: 015, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 50.664%, stu_acc5: 76.752%, stu_test_loss: 2.1236
2022-05-02 00:39:17 - until epoch: 015, tea_best_acc1: 73.944%, stu_best_acc1: 51.800%
2022-05-02 00:39:17 - epoch 016 lr: 0.1
2022-05-02 00:39:56 - train: epoch 0016, iter [00100, 05004], lr: 0.100000, loss: 3.6903, stu_CELoss: 2.2224 DKDLoss: 1.4678 
2022-05-02 00:40:30 - train: epoch 0016, iter [00200, 05004], lr: 0.100000, loss: 3.6469, stu_CELoss: 2.1013 DKDLoss: 1.5456 
2022-05-02 00:41:04 - train: epoch 0016, iter [00300, 05004], lr: 0.100000, loss: 3.9294, stu_CELoss: 2.3343 DKDLoss: 1.5951 
2022-05-02 00:41:38 - train: epoch 0016, iter [00400, 05004], lr: 0.100000, loss: 3.8014, stu_CELoss: 2.2853 DKDLoss: 1.5161 
2022-05-02 00:42:12 - train: epoch 0016, iter [00500, 05004], lr: 0.100000, loss: 3.6780, stu_CELoss: 2.2306 DKDLoss: 1.4474 
2022-05-02 00:42:45 - train: epoch 0016, iter [00600, 05004], lr: 0.100000, loss: 3.7246, stu_CELoss: 2.1580 DKDLoss: 1.5665 
2022-05-02 00:43:19 - train: epoch 0016, iter [00700, 05004], lr: 0.100000, loss: 3.6263, stu_CELoss: 2.1449 DKDLoss: 1.4814 
2022-05-02 00:43:53 - train: epoch 0016, iter [00800, 05004], lr: 0.100000, loss: 3.6562, stu_CELoss: 2.2182 DKDLoss: 1.4380 
2022-05-02 00:44:27 - train: epoch 0016, iter [00900, 05004], lr: 0.100000, loss: 4.0195, stu_CELoss: 2.3483 DKDLoss: 1.6711 
2022-05-02 00:45:00 - train: epoch 0016, iter [01000, 05004], lr: 0.100000, loss: 4.0309, stu_CELoss: 2.3701 DKDLoss: 1.6608 
2022-05-02 00:45:34 - train: epoch 0016, iter [01100, 05004], lr: 0.100000, loss: 4.0066, stu_CELoss: 2.3293 DKDLoss: 1.6773 
2022-05-02 00:46:08 - train: epoch 0016, iter [01200, 05004], lr: 0.100000, loss: 3.7722, stu_CELoss: 2.2141 DKDLoss: 1.5580 
2022-05-02 00:46:41 - train: epoch 0016, iter [01300, 05004], lr: 0.100000, loss: 4.0398, stu_CELoss: 2.3928 DKDLoss: 1.6470 
2022-05-02 00:47:16 - train: epoch 0016, iter [01400, 05004], lr: 0.100000, loss: 3.6770, stu_CELoss: 2.2014 DKDLoss: 1.4756 
2022-05-02 00:47:49 - train: epoch 0016, iter [01500, 05004], lr: 0.100000, loss: 4.2503, stu_CELoss: 2.6145 DKDLoss: 1.6358 
2022-05-02 00:48:23 - train: epoch 0016, iter [01600, 05004], lr: 0.100000, loss: 4.0969, stu_CELoss: 2.5618 DKDLoss: 1.5350 
2022-05-02 00:48:56 - train: epoch 0016, iter [01700, 05004], lr: 0.100000, loss: 3.7723, stu_CELoss: 2.2294 DKDLoss: 1.5429 
2022-05-02 00:49:30 - train: epoch 0016, iter [01800, 05004], lr: 0.100000, loss: 3.8771, stu_CELoss: 2.4571 DKDLoss: 1.4200 
2022-05-02 00:50:04 - train: epoch 0016, iter [01900, 05004], lr: 0.100000, loss: 3.8455, stu_CELoss: 2.3019 DKDLoss: 1.5436 
2022-05-02 00:50:39 - train: epoch 0016, iter [02000, 05004], lr: 0.100000, loss: 3.4663, stu_CELoss: 1.9106 DKDLoss: 1.5556 
2022-05-02 00:51:13 - train: epoch 0016, iter [02100, 05004], lr: 0.100000, loss: 3.9518, stu_CELoss: 2.3698 DKDLoss: 1.5820 
2022-05-02 00:51:48 - train: epoch 0016, iter [02200, 05004], lr: 0.100000, loss: 3.8025, stu_CELoss: 2.2967 DKDLoss: 1.5058 
2022-05-02 00:52:22 - train: epoch 0016, iter [02300, 05004], lr: 0.100000, loss: 4.1665, stu_CELoss: 2.4755 DKDLoss: 1.6910 
2022-05-02 00:52:57 - train: epoch 0016, iter [02400, 05004], lr: 0.100000, loss: 3.9308, stu_CELoss: 2.2732 DKDLoss: 1.6576 
2022-05-02 00:53:31 - train: epoch 0016, iter [02500, 05004], lr: 0.100000, loss: 4.0286, stu_CELoss: 2.3423 DKDLoss: 1.6863 
2022-05-02 00:54:05 - train: epoch 0016, iter [02600, 05004], lr: 0.100000, loss: 4.1397, stu_CELoss: 2.3872 DKDLoss: 1.7525 
2022-05-02 00:54:40 - train: epoch 0016, iter [02700, 05004], lr: 0.100000, loss: 3.6531, stu_CELoss: 2.2187 DKDLoss: 1.4344 
2022-05-02 00:55:15 - train: epoch 0016, iter [02800, 05004], lr: 0.100000, loss: 3.6959, stu_CELoss: 2.1365 DKDLoss: 1.5595 
2022-05-02 00:55:50 - train: epoch 0016, iter [02900, 05004], lr: 0.100000, loss: 3.9157, stu_CELoss: 2.2728 DKDLoss: 1.6429 
2022-05-02 00:56:25 - train: epoch 0016, iter [03000, 05004], lr: 0.100000, loss: 4.0256, stu_CELoss: 2.4177 DKDLoss: 1.6079 
2022-05-02 00:56:59 - train: epoch 0016, iter [03100, 05004], lr: 0.100000, loss: 4.0097, stu_CELoss: 2.4411 DKDLoss: 1.5686 
2022-05-02 00:57:34 - train: epoch 0016, iter [03200, 05004], lr: 0.100000, loss: 3.8488, stu_CELoss: 2.3140 DKDLoss: 1.5349 
2022-05-02 00:58:09 - train: epoch 0016, iter [03300, 05004], lr: 0.100000, loss: 3.8360, stu_CELoss: 2.3505 DKDLoss: 1.4856 
2022-05-02 00:58:43 - train: epoch 0016, iter [03400, 05004], lr: 0.100000, loss: 4.0139, stu_CELoss: 2.3727 DKDLoss: 1.6412 
2022-05-02 00:59:18 - train: epoch 0016, iter [03500, 05004], lr: 0.100000, loss: 3.6208, stu_CELoss: 2.1650 DKDLoss: 1.4558 
2022-05-02 00:59:53 - train: epoch 0016, iter [03600, 05004], lr: 0.100000, loss: 3.6278, stu_CELoss: 2.1397 DKDLoss: 1.4881 
2022-05-02 01:00:27 - train: epoch 0016, iter [03700, 05004], lr: 0.100000, loss: 3.7623, stu_CELoss: 2.2095 DKDLoss: 1.5528 
2022-05-02 01:01:03 - train: epoch 0016, iter [03800, 05004], lr: 0.100000, loss: 3.9605, stu_CELoss: 2.5018 DKDLoss: 1.4587 
2022-05-02 01:01:36 - train: epoch 0016, iter [03900, 05004], lr: 0.100000, loss: 4.0493, stu_CELoss: 2.4150 DKDLoss: 1.6343 
2022-05-02 01:02:12 - train: epoch 0016, iter [04000, 05004], lr: 0.100000, loss: 3.9152, stu_CELoss: 2.3145 DKDLoss: 1.6007 
2022-05-02 01:02:47 - train: epoch 0016, iter [04100, 05004], lr: 0.100000, loss: 3.7825, stu_CELoss: 2.1707 DKDLoss: 1.6118 
2022-05-02 01:03:22 - train: epoch 0016, iter [04200, 05004], lr: 0.100000, loss: 3.7600, stu_CELoss: 2.1903 DKDLoss: 1.5697 
2022-05-02 01:03:57 - train: epoch 0016, iter [04300, 05004], lr: 0.100000, loss: 3.6607, stu_CELoss: 2.1641 DKDLoss: 1.4966 
2022-05-02 01:04:32 - train: epoch 0016, iter [04400, 05004], lr: 0.100000, loss: 3.5865, stu_CELoss: 2.1707 DKDLoss: 1.4158 
2022-05-02 01:05:06 - train: epoch 0016, iter [04500, 05004], lr: 0.100000, loss: 3.8738, stu_CELoss: 2.3596 DKDLoss: 1.5142 
2022-05-02 01:05:40 - train: epoch 0016, iter [04600, 05004], lr: 0.100000, loss: 3.6397, stu_CELoss: 2.1446 DKDLoss: 1.4951 
2022-05-02 01:06:17 - train: epoch 0016, iter [04700, 05004], lr: 0.100000, loss: 3.8832, stu_CELoss: 2.4134 DKDLoss: 1.4698 
2022-05-02 01:06:51 - train: epoch 0016, iter [04800, 05004], lr: 0.100000, loss: 3.7266, stu_CELoss: 2.2522 DKDLoss: 1.4745 
2022-05-02 01:07:27 - train: epoch 0016, iter [04900, 05004], lr: 0.100000, loss: 3.9209, stu_CELoss: 2.2851 DKDLoss: 1.6359 
2022-05-02 01:07:59 - train: epoch 0016, iter [05000, 05004], lr: 0.100000, loss: 4.0918, stu_CELoss: 2.4606 DKDLoss: 1.6312 
2022-05-02 01:08:00 - train: epoch 016, train_loss: 3.8918
2022-05-02 01:10:34 - eval: epoch: 016, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 49.532%, stu_acc5: 75.478%, stu_test_loss: 2.1802
2022-05-02 01:10:35 - until epoch: 016, tea_best_acc1: 73.944%, stu_best_acc1: 51.800%
2022-05-02 01:10:35 - epoch 017 lr: 0.1
2022-05-02 01:11:14 - train: epoch 0017, iter [00100, 05004], lr: 0.100000, loss: 3.8858, stu_CELoss: 2.3130 DKDLoss: 1.5728 
2022-05-02 01:11:50 - train: epoch 0017, iter [00200, 05004], lr: 0.100000, loss: 4.1844, stu_CELoss: 2.4819 DKDLoss: 1.7025 
2022-05-02 01:12:25 - train: epoch 0017, iter [00300, 05004], lr: 0.100000, loss: 3.9204, stu_CELoss: 2.4819 DKDLoss: 1.4385 
2022-05-02 01:13:00 - train: epoch 0017, iter [00400, 05004], lr: 0.100000, loss: 3.7044, stu_CELoss: 2.0915 DKDLoss: 1.6128 
2022-05-02 01:13:35 - train: epoch 0017, iter [00500, 05004], lr: 0.100000, loss: 3.6614, stu_CELoss: 2.2674 DKDLoss: 1.3941 
2022-05-02 01:14:09 - train: epoch 0017, iter [00600, 05004], lr: 0.100000, loss: 4.3360, stu_CELoss: 2.5788 DKDLoss: 1.7572 
2022-05-02 01:14:44 - train: epoch 0017, iter [00700, 05004], lr: 0.100000, loss: 3.8117, stu_CELoss: 2.2551 DKDLoss: 1.5566 
2022-05-02 01:15:20 - train: epoch 0017, iter [00800, 05004], lr: 0.100000, loss: 3.5891, stu_CELoss: 2.1379 DKDLoss: 1.4512 
2022-05-02 01:15:54 - train: epoch 0017, iter [00900, 05004], lr: 0.100000, loss: 3.7057, stu_CELoss: 2.2169 DKDLoss: 1.4888 
2022-05-02 01:16:29 - train: epoch 0017, iter [01000, 05004], lr: 0.100000, loss: 4.0027, stu_CELoss: 2.3678 DKDLoss: 1.6348 
2022-05-02 01:17:04 - train: epoch 0017, iter [01100, 05004], lr: 0.100000, loss: 4.1061, stu_CELoss: 2.6013 DKDLoss: 1.5048 
2022-05-02 01:17:38 - train: epoch 0017, iter [01200, 05004], lr: 0.100000, loss: 3.6591, stu_CELoss: 2.1232 DKDLoss: 1.5359 
2022-05-02 01:18:13 - train: epoch 0017, iter [01300, 05004], lr: 0.100000, loss: 3.8240, stu_CELoss: 2.3227 DKDLoss: 1.5013 
2022-05-02 01:18:48 - train: epoch 0017, iter [01400, 05004], lr: 0.100000, loss: 3.7549, stu_CELoss: 2.2698 DKDLoss: 1.4851 
2022-05-02 01:19:22 - train: epoch 0017, iter [01500, 05004], lr: 0.100000, loss: 3.9414, stu_CELoss: 2.2958 DKDLoss: 1.6456 
2022-05-02 01:19:57 - train: epoch 0017, iter [01600, 05004], lr: 0.100000, loss: 3.8300, stu_CELoss: 2.2598 DKDLoss: 1.5702 
2022-05-02 01:20:33 - train: epoch 0017, iter [01700, 05004], lr: 0.100000, loss: 3.5845, stu_CELoss: 2.1035 DKDLoss: 1.4810 
2022-05-02 01:21:07 - train: epoch 0017, iter [01800, 05004], lr: 0.100000, loss: 3.9720, stu_CELoss: 2.3927 DKDLoss: 1.5792 
2022-05-02 01:21:42 - train: epoch 0017, iter [01900, 05004], lr: 0.100000, loss: 3.8438, stu_CELoss: 2.2553 DKDLoss: 1.5885 
2022-05-02 01:22:18 - train: epoch 0017, iter [02000, 05004], lr: 0.100000, loss: 3.6328, stu_CELoss: 2.1769 DKDLoss: 1.4560 
2022-05-02 01:22:53 - train: epoch 0017, iter [02100, 05004], lr: 0.100000, loss: 3.9472, stu_CELoss: 2.3236 DKDLoss: 1.6236 
2022-05-02 01:23:26 - train: epoch 0017, iter [02200, 05004], lr: 0.100000, loss: 3.6900, stu_CELoss: 2.0706 DKDLoss: 1.6194 
2022-05-02 01:24:02 - train: epoch 0017, iter [02300, 05004], lr: 0.100000, loss: 3.9862, stu_CELoss: 2.3484 DKDLoss: 1.6378 
2022-05-02 01:24:36 - train: epoch 0017, iter [02400, 05004], lr: 0.100000, loss: 3.8528, stu_CELoss: 2.3215 DKDLoss: 1.5313 
2022-05-02 01:25:12 - train: epoch 0017, iter [02500, 05004], lr: 0.100000, loss: 4.2805, stu_CELoss: 2.5787 DKDLoss: 1.7018 
2022-05-02 01:25:46 - train: epoch 0017, iter [02600, 05004], lr: 0.100000, loss: 3.7987, stu_CELoss: 2.2582 DKDLoss: 1.5405 
2022-05-02 01:26:22 - train: epoch 0017, iter [02700, 05004], lr: 0.100000, loss: 3.7894, stu_CELoss: 2.1977 DKDLoss: 1.5918 
2022-05-02 01:26:55 - train: epoch 0017, iter [02800, 05004], lr: 0.100000, loss: 3.8699, stu_CELoss: 2.2269 DKDLoss: 1.6430 
2022-05-02 01:27:31 - train: epoch 0017, iter [02900, 05004], lr: 0.100000, loss: 4.0459, stu_CELoss: 2.5647 DKDLoss: 1.4812 
2022-05-02 01:28:05 - train: epoch 0017, iter [03000, 05004], lr: 0.100000, loss: 3.9566, stu_CELoss: 2.3854 DKDLoss: 1.5712 
2022-05-02 01:28:40 - train: epoch 0017, iter [03100, 05004], lr: 0.100000, loss: 3.8400, stu_CELoss: 2.3202 DKDLoss: 1.5198 
2022-05-02 01:29:15 - train: epoch 0017, iter [03200, 05004], lr: 0.100000, loss: 3.8636, stu_CELoss: 2.2247 DKDLoss: 1.6389 
2022-05-02 01:29:50 - train: epoch 0017, iter [03300, 05004], lr: 0.100000, loss: 3.8215, stu_CELoss: 2.4441 DKDLoss: 1.3774 
2022-05-02 01:30:24 - train: epoch 0017, iter [03400, 05004], lr: 0.100000, loss: 3.7494, stu_CELoss: 2.1998 DKDLoss: 1.5496 
2022-05-02 01:30:59 - train: epoch 0017, iter [03500, 05004], lr: 0.100000, loss: 3.9575, stu_CELoss: 2.3254 DKDLoss: 1.6321 
2022-05-02 01:31:34 - train: epoch 0017, iter [03600, 05004], lr: 0.100000, loss: 3.9587, stu_CELoss: 2.3472 DKDLoss: 1.6114 
2022-05-02 01:32:09 - train: epoch 0017, iter [03700, 05004], lr: 0.100000, loss: 3.6359, stu_CELoss: 2.1011 DKDLoss: 1.5349 
2022-05-02 01:32:44 - train: epoch 0017, iter [03800, 05004], lr: 0.100000, loss: 4.3420, stu_CELoss: 2.6350 DKDLoss: 1.7070 
2022-05-02 01:33:19 - train: epoch 0017, iter [03900, 05004], lr: 0.100000, loss: 3.5582, stu_CELoss: 2.0477 DKDLoss: 1.5105 
2022-05-02 01:33:54 - train: epoch 0017, iter [04000, 05004], lr: 0.100000, loss: 3.6791, stu_CELoss: 2.3042 DKDLoss: 1.3749 
2022-05-02 01:34:28 - train: epoch 0017, iter [04100, 05004], lr: 0.100000, loss: 4.1780, stu_CELoss: 2.4801 DKDLoss: 1.6979 
2022-05-02 01:35:04 - train: epoch 0017, iter [04200, 05004], lr: 0.100000, loss: 3.9160, stu_CELoss: 2.2703 DKDLoss: 1.6457 
2022-05-02 01:35:37 - train: epoch 0017, iter [04300, 05004], lr: 0.100000, loss: 3.7650, stu_CELoss: 2.1260 DKDLoss: 1.6390 
2022-05-02 01:36:13 - train: epoch 0017, iter [04400, 05004], lr: 0.100000, loss: 3.8573, stu_CELoss: 2.3167 DKDLoss: 1.5406 
2022-05-02 01:36:47 - train: epoch 0017, iter [04500, 05004], lr: 0.100000, loss: 3.9017, stu_CELoss: 2.3446 DKDLoss: 1.5571 
2022-05-02 01:37:24 - train: epoch 0017, iter [04600, 05004], lr: 0.100000, loss: 3.6544, stu_CELoss: 2.1630 DKDLoss: 1.4914 
2022-05-02 01:37:58 - train: epoch 0017, iter [04700, 05004], lr: 0.100000, loss: 4.0408, stu_CELoss: 2.4671 DKDLoss: 1.5737 
2022-05-02 01:38:33 - train: epoch 0017, iter [04800, 05004], lr: 0.100000, loss: 4.0284, stu_CELoss: 2.4124 DKDLoss: 1.6160 
2022-05-02 01:39:07 - train: epoch 0017, iter [04900, 05004], lr: 0.100000, loss: 3.7825, stu_CELoss: 2.2841 DKDLoss: 1.4984 
2022-05-02 01:39:40 - train: epoch 0017, iter [05000, 05004], lr: 0.100000, loss: 3.8920, stu_CELoss: 2.2158 DKDLoss: 1.6762 
2022-05-02 01:39:41 - train: epoch 017, train_loss: 3.8773
2022-05-02 01:42:15 - eval: epoch: 017, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 51.490%, stu_acc5: 76.920%, stu_test_loss: 2.0909
2022-05-02 01:42:15 - until epoch: 017, tea_best_acc1: 73.944%, stu_best_acc1: 51.800%
2022-05-02 01:42:15 - epoch 018 lr: 0.1
2022-05-02 01:42:55 - train: epoch 0018, iter [00100, 05004], lr: 0.100000, loss: 3.7409, stu_CELoss: 2.1423 DKDLoss: 1.5986 
2022-05-02 01:43:29 - train: epoch 0018, iter [00200, 05004], lr: 0.100000, loss: 4.2402, stu_CELoss: 2.6456 DKDLoss: 1.5947 
2022-05-02 01:44:03 - train: epoch 0018, iter [00300, 05004], lr: 0.100000, loss: 4.1738, stu_CELoss: 2.4488 DKDLoss: 1.7250 
2022-05-02 01:44:39 - train: epoch 0018, iter [00400, 05004], lr: 0.100000, loss: 4.0643, stu_CELoss: 2.4403 DKDLoss: 1.6240 
2022-05-02 01:45:13 - train: epoch 0018, iter [00500, 05004], lr: 0.100000, loss: 4.1197, stu_CELoss: 2.3790 DKDLoss: 1.7407 
2022-05-02 01:45:48 - train: epoch 0018, iter [00600, 05004], lr: 0.100000, loss: 3.8695, stu_CELoss: 2.3344 DKDLoss: 1.5352 
2022-05-02 01:46:22 - train: epoch 0018, iter [00700, 05004], lr: 0.100000, loss: 3.8170, stu_CELoss: 2.1553 DKDLoss: 1.6617 
2022-05-02 01:46:57 - train: epoch 0018, iter [00800, 05004], lr: 0.100000, loss: 3.9568, stu_CELoss: 2.3769 DKDLoss: 1.5800 
2022-05-02 01:47:31 - train: epoch 0018, iter [00900, 05004], lr: 0.100000, loss: 4.0003, stu_CELoss: 2.5180 DKDLoss: 1.4824 
2022-05-02 01:48:07 - train: epoch 0018, iter [01000, 05004], lr: 0.100000, loss: 3.6515, stu_CELoss: 2.1552 DKDLoss: 1.4962 
2022-05-02 01:48:41 - train: epoch 0018, iter [01100, 05004], lr: 0.100000, loss: 3.9932, stu_CELoss: 2.3844 DKDLoss: 1.6089 
2022-05-02 01:49:16 - train: epoch 0018, iter [01200, 05004], lr: 0.100000, loss: 3.6795, stu_CELoss: 2.1603 DKDLoss: 1.5193 
2022-05-02 01:49:50 - train: epoch 0018, iter [01300, 05004], lr: 0.100000, loss: 3.9936, stu_CELoss: 2.3907 DKDLoss: 1.6029 
2022-05-02 01:50:25 - train: epoch 0018, iter [01400, 05004], lr: 0.100000, loss: 3.8468, stu_CELoss: 2.3354 DKDLoss: 1.5114 
2022-05-02 01:51:01 - train: epoch 0018, iter [01500, 05004], lr: 0.100000, loss: 4.2788, stu_CELoss: 2.5998 DKDLoss: 1.6790 
2022-05-02 01:51:35 - train: epoch 0018, iter [01600, 05004], lr: 0.100000, loss: 4.0060, stu_CELoss: 2.3221 DKDLoss: 1.6839 
2022-05-02 01:52:10 - train: epoch 0018, iter [01700, 05004], lr: 0.100000, loss: 4.1564, stu_CELoss: 2.5086 DKDLoss: 1.6478 
2022-05-02 01:52:45 - train: epoch 0018, iter [01800, 05004], lr: 0.100000, loss: 3.7068, stu_CELoss: 2.1637 DKDLoss: 1.5431 
2022-05-02 01:53:20 - train: epoch 0018, iter [01900, 05004], lr: 0.100000, loss: 3.8891, stu_CELoss: 2.3116 DKDLoss: 1.5774 
2022-05-02 01:53:56 - train: epoch 0018, iter [02000, 05004], lr: 0.100000, loss: 4.3316, stu_CELoss: 2.6862 DKDLoss: 1.6455 
2022-05-02 01:54:30 - train: epoch 0018, iter [02100, 05004], lr: 0.100000, loss: 4.2088, stu_CELoss: 2.4977 DKDLoss: 1.7112 
2022-05-02 01:55:04 - train: epoch 0018, iter [02200, 05004], lr: 0.100000, loss: 4.0104, stu_CELoss: 2.3173 DKDLoss: 1.6931 
2022-05-02 01:55:39 - train: epoch 0018, iter [02300, 05004], lr: 0.100000, loss: 3.9676, stu_CELoss: 2.2927 DKDLoss: 1.6749 
2022-05-02 01:56:14 - train: epoch 0018, iter [02400, 05004], lr: 0.100000, loss: 3.7278, stu_CELoss: 2.3054 DKDLoss: 1.4223 
2022-05-02 01:56:50 - train: epoch 0018, iter [02500, 05004], lr: 0.100000, loss: 3.4757, stu_CELoss: 1.9512 DKDLoss: 1.5245 
2022-05-02 01:57:24 - train: epoch 0018, iter [02600, 05004], lr: 0.100000, loss: 3.6926, stu_CELoss: 2.1670 DKDLoss: 1.5256 
2022-05-02 01:57:59 - train: epoch 0018, iter [02700, 05004], lr: 0.100000, loss: 3.8352, stu_CELoss: 2.3899 DKDLoss: 1.4453 
2022-05-02 01:58:34 - train: epoch 0018, iter [02800, 05004], lr: 0.100000, loss: 3.8055, stu_CELoss: 2.1564 DKDLoss: 1.6491 
2022-05-02 01:59:07 - train: epoch 0018, iter [02900, 05004], lr: 0.100000, loss: 3.7079, stu_CELoss: 2.1970 DKDLoss: 1.5109 
2022-05-02 01:59:43 - train: epoch 0018, iter [03000, 05004], lr: 0.100000, loss: 3.6704, stu_CELoss: 2.1917 DKDLoss: 1.4787 
2022-05-02 02:00:18 - train: epoch 0018, iter [03100, 05004], lr: 0.100000, loss: 4.4736, stu_CELoss: 2.8308 DKDLoss: 1.6428 
2022-05-02 02:00:53 - train: epoch 0018, iter [03200, 05004], lr: 0.100000, loss: 4.0831, stu_CELoss: 2.3760 DKDLoss: 1.7071 
2022-05-02 02:01:28 - train: epoch 0018, iter [03300, 05004], lr: 0.100000, loss: 3.9913, stu_CELoss: 2.3041 DKDLoss: 1.6872 
2022-05-02 02:02:02 - train: epoch 0018, iter [03400, 05004], lr: 0.100000, loss: 3.9293, stu_CELoss: 2.4116 DKDLoss: 1.5178 
2022-05-02 02:02:38 - train: epoch 0018, iter [03500, 05004], lr: 0.100000, loss: 3.7454, stu_CELoss: 2.2896 DKDLoss: 1.4557 
2022-05-02 02:03:13 - train: epoch 0018, iter [03600, 05004], lr: 0.100000, loss: 3.9399, stu_CELoss: 2.3577 DKDLoss: 1.5822 
2022-05-02 02:03:48 - train: epoch 0018, iter [03700, 05004], lr: 0.100000, loss: 4.1868, stu_CELoss: 2.4839 DKDLoss: 1.7030 
2022-05-02 02:04:22 - train: epoch 0018, iter [03800, 05004], lr: 0.100000, loss: 4.0477, stu_CELoss: 2.4493 DKDLoss: 1.5984 
2022-05-02 02:04:58 - train: epoch 0018, iter [03900, 05004], lr: 0.100000, loss: 3.8933, stu_CELoss: 2.4751 DKDLoss: 1.4183 
2022-05-02 02:05:33 - train: epoch 0018, iter [04000, 05004], lr: 0.100000, loss: 4.0069, stu_CELoss: 2.4509 DKDLoss: 1.5561 
2022-05-02 02:06:08 - train: epoch 0018, iter [04100, 05004], lr: 0.100000, loss: 4.0883, stu_CELoss: 2.5599 DKDLoss: 1.5284 
2022-05-02 02:06:42 - train: epoch 0018, iter [04200, 05004], lr: 0.100000, loss: 3.9844, stu_CELoss: 2.3411 DKDLoss: 1.6432 
2022-05-02 02:07:18 - train: epoch 0018, iter [04300, 05004], lr: 0.100000, loss: 3.8483, stu_CELoss: 2.3822 DKDLoss: 1.4661 
2022-05-02 02:07:54 - train: epoch 0018, iter [04400, 05004], lr: 0.100000, loss: 3.7929, stu_CELoss: 2.1795 DKDLoss: 1.6135 
2022-05-02 02:08:27 - train: epoch 0018, iter [04500, 05004], lr: 0.100000, loss: 4.1074, stu_CELoss: 2.4368 DKDLoss: 1.6705 
2022-05-02 02:09:03 - train: epoch 0018, iter [04600, 05004], lr: 0.100000, loss: 3.9829, stu_CELoss: 2.3028 DKDLoss: 1.6801 
2022-05-02 02:09:37 - train: epoch 0018, iter [04700, 05004], lr: 0.100000, loss: 3.8909, stu_CELoss: 2.3345 DKDLoss: 1.5564 
2022-05-02 02:10:13 - train: epoch 0018, iter [04800, 05004], lr: 0.100000, loss: 3.9684, stu_CELoss: 2.3544 DKDLoss: 1.6140 
2022-05-02 02:10:47 - train: epoch 0018, iter [04900, 05004], lr: 0.100000, loss: 3.9599, stu_CELoss: 2.2610 DKDLoss: 1.6989 
2022-05-02 02:11:20 - train: epoch 0018, iter [05000, 05004], lr: 0.100000, loss: 3.9212, stu_CELoss: 2.4427 DKDLoss: 1.4785 
2022-05-02 02:11:21 - train: epoch 018, train_loss: 3.8593
2022-05-02 02:13:56 - eval: epoch: 018, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 52.454%, stu_acc5: 77.686%, stu_test_loss: 2.0451
2022-05-02 02:13:56 - until epoch: 018, tea_best_acc1: 73.944%, stu_best_acc1: 52.454%
2022-05-02 02:13:56 - epoch 019 lr: 0.1
2022-05-02 02:14:37 - train: epoch 0019, iter [00100, 05004], lr: 0.100000, loss: 3.5896, stu_CELoss: 2.0609 DKDLoss: 1.5287 
2022-05-02 02:15:10 - train: epoch 0019, iter [00200, 05004], lr: 0.100000, loss: 3.8509, stu_CELoss: 2.2615 DKDLoss: 1.5893 
2022-05-02 02:15:46 - train: epoch 0019, iter [00300, 05004], lr: 0.100000, loss: 3.9787, stu_CELoss: 2.4568 DKDLoss: 1.5219 
2022-05-02 02:16:20 - train: epoch 0019, iter [00400, 05004], lr: 0.100000, loss: 3.9176, stu_CELoss: 2.3514 DKDLoss: 1.5663 
2022-05-02 02:16:54 - train: epoch 0019, iter [00500, 05004], lr: 0.100000, loss: 3.6673, stu_CELoss: 2.1582 DKDLoss: 1.5090 
2022-05-02 02:17:27 - train: epoch 0019, iter [00600, 05004], lr: 0.100000, loss: 3.8771, stu_CELoss: 2.3776 DKDLoss: 1.4995 
2022-05-02 02:18:02 - train: epoch 0019, iter [00700, 05004], lr: 0.100000, loss: 3.7956, stu_CELoss: 2.3035 DKDLoss: 1.4921 
2022-05-02 02:18:37 - train: epoch 0019, iter [00800, 05004], lr: 0.100000, loss: 3.8009, stu_CELoss: 2.3228 DKDLoss: 1.4781 
2022-05-02 02:19:13 - train: epoch 0019, iter [00900, 05004], lr: 0.100000, loss: 3.8074, stu_CELoss: 2.2435 DKDLoss: 1.5639 
2022-05-02 02:19:47 - train: epoch 0019, iter [01000, 05004], lr: 0.100000, loss: 4.0899, stu_CELoss: 2.5173 DKDLoss: 1.5725 
2022-05-02 02:20:21 - train: epoch 0019, iter [01100, 05004], lr: 0.100000, loss: 3.8064, stu_CELoss: 2.2805 DKDLoss: 1.5259 
2022-05-02 02:20:58 - train: epoch 0019, iter [01200, 05004], lr: 0.100000, loss: 3.7476, stu_CELoss: 2.2906 DKDLoss: 1.4570 
2022-05-02 02:21:32 - train: epoch 0019, iter [01300, 05004], lr: 0.100000, loss: 3.7968, stu_CELoss: 2.4066 DKDLoss: 1.3902 
2022-05-02 02:22:07 - train: epoch 0019, iter [01400, 05004], lr: 0.100000, loss: 3.8071, stu_CELoss: 2.2239 DKDLoss: 1.5833 
2022-05-02 02:22:42 - train: epoch 0019, iter [01500, 05004], lr: 0.100000, loss: 4.2597, stu_CELoss: 2.5588 DKDLoss: 1.7009 
2022-05-02 02:23:16 - train: epoch 0019, iter [01600, 05004], lr: 0.100000, loss: 3.7593, stu_CELoss: 2.1489 DKDLoss: 1.6104 
2022-05-02 02:23:51 - train: epoch 0019, iter [01700, 05004], lr: 0.100000, loss: 4.1372, stu_CELoss: 2.4796 DKDLoss: 1.6576 
2022-05-02 02:24:26 - train: epoch 0019, iter [01800, 05004], lr: 0.100000, loss: 3.6588, stu_CELoss: 2.2263 DKDLoss: 1.4326 
2022-05-02 02:25:00 - train: epoch 0019, iter [01900, 05004], lr: 0.100000, loss: 4.1067, stu_CELoss: 2.4382 DKDLoss: 1.6686 
2022-05-02 02:25:36 - train: epoch 0019, iter [02000, 05004], lr: 0.100000, loss: 3.8489, stu_CELoss: 2.2787 DKDLoss: 1.5702 
2022-05-02 02:26:10 - train: epoch 0019, iter [02100, 05004], lr: 0.100000, loss: 4.0929, stu_CELoss: 2.3503 DKDLoss: 1.7426 
2022-05-02 02:26:45 - train: epoch 0019, iter [02200, 05004], lr: 0.100000, loss: 3.7600, stu_CELoss: 2.2990 DKDLoss: 1.4610 
2022-05-02 02:27:20 - train: epoch 0019, iter [02300, 05004], lr: 0.100000, loss: 3.8203, stu_CELoss: 2.2219 DKDLoss: 1.5984 
2022-05-02 02:27:55 - train: epoch 0019, iter [02400, 05004], lr: 0.100000, loss: 4.1145, stu_CELoss: 2.4867 DKDLoss: 1.6279 
2022-05-02 02:28:30 - train: epoch 0019, iter [02500, 05004], lr: 0.100000, loss: 3.9696, stu_CELoss: 2.3558 DKDLoss: 1.6139 
2022-05-02 02:29:05 - train: epoch 0019, iter [02600, 05004], lr: 0.100000, loss: 3.6559, stu_CELoss: 2.1551 DKDLoss: 1.5007 
2022-05-02 02:29:40 - train: epoch 0019, iter [02700, 05004], lr: 0.100000, loss: 4.0228, stu_CELoss: 2.3308 DKDLoss: 1.6920 
2022-05-02 02:30:15 - train: epoch 0019, iter [02800, 05004], lr: 0.100000, loss: 3.7200, stu_CELoss: 2.1916 DKDLoss: 1.5283 
2022-05-02 02:30:51 - train: epoch 0019, iter [02900, 05004], lr: 0.100000, loss: 3.9743, stu_CELoss: 2.4004 DKDLoss: 1.5738 
2022-05-02 02:31:25 - train: epoch 0019, iter [03000, 05004], lr: 0.100000, loss: 4.2724, stu_CELoss: 2.5363 DKDLoss: 1.7361 
2022-05-02 02:32:01 - train: epoch 0019, iter [03100, 05004], lr: 0.100000, loss: 3.8117, stu_CELoss: 2.2458 DKDLoss: 1.5659 
2022-05-02 02:32:35 - train: epoch 0019, iter [03200, 05004], lr: 0.100000, loss: 3.5905, stu_CELoss: 2.1075 DKDLoss: 1.4830 
2022-05-02 02:33:10 - train: epoch 0019, iter [03300, 05004], lr: 0.100000, loss: 3.9668, stu_CELoss: 2.3435 DKDLoss: 1.6232 
2022-05-02 02:33:44 - train: epoch 0019, iter [03400, 05004], lr: 0.100000, loss: 3.9865, stu_CELoss: 2.3551 DKDLoss: 1.6315 
2022-05-02 02:34:20 - train: epoch 0019, iter [03500, 05004], lr: 0.100000, loss: 4.2170, stu_CELoss: 2.5730 DKDLoss: 1.6441 
2022-05-02 02:34:55 - train: epoch 0019, iter [03600, 05004], lr: 0.100000, loss: 3.8551, stu_CELoss: 2.1775 DKDLoss: 1.6776 
2022-05-02 02:35:29 - train: epoch 0019, iter [03700, 05004], lr: 0.100000, loss: 3.7904, stu_CELoss: 2.3275 DKDLoss: 1.4630 
2022-05-02 02:36:04 - train: epoch 0019, iter [03800, 05004], lr: 0.100000, loss: 4.0372, stu_CELoss: 2.3775 DKDLoss: 1.6596 
2022-05-02 02:36:39 - train: epoch 0019, iter [03900, 05004], lr: 0.100000, loss: 3.8949, stu_CELoss: 2.3077 DKDLoss: 1.5872 
2022-05-02 02:37:14 - train: epoch 0019, iter [04000, 05004], lr: 0.100000, loss: 3.5809, stu_CELoss: 2.2014 DKDLoss: 1.3796 
2022-05-02 02:37:49 - train: epoch 0019, iter [04100, 05004], lr: 0.100000, loss: 3.8245, stu_CELoss: 2.3681 DKDLoss: 1.4564 
2022-05-02 02:38:24 - train: epoch 0019, iter [04200, 05004], lr: 0.100000, loss: 3.8452, stu_CELoss: 2.2831 DKDLoss: 1.5621 
2022-05-02 02:39:00 - train: epoch 0019, iter [04300, 05004], lr: 0.100000, loss: 3.9152, stu_CELoss: 2.3124 DKDLoss: 1.6028 
2022-05-02 02:39:34 - train: epoch 0019, iter [04400, 05004], lr: 0.100000, loss: 4.0540, stu_CELoss: 2.4394 DKDLoss: 1.6146 
2022-05-02 02:40:08 - train: epoch 0019, iter [04500, 05004], lr: 0.100000, loss: 4.0405, stu_CELoss: 2.5554 DKDLoss: 1.4851 
2022-05-02 02:40:44 - train: epoch 0019, iter [04600, 05004], lr: 0.100000, loss: 3.8990, stu_CELoss: 2.2677 DKDLoss: 1.6314 
2022-05-02 02:41:17 - train: epoch 0019, iter [04700, 05004], lr: 0.100000, loss: 3.7510, stu_CELoss: 2.1858 DKDLoss: 1.5652 
2022-05-02 02:41:53 - train: epoch 0019, iter [04800, 05004], lr: 0.100000, loss: 3.6280, stu_CELoss: 2.2430 DKDLoss: 1.3851 
2022-05-02 02:42:27 - train: epoch 0019, iter [04900, 05004], lr: 0.100000, loss: 3.5907, stu_CELoss: 2.1980 DKDLoss: 1.3927 
2022-05-02 02:43:01 - train: epoch 0019, iter [05000, 05004], lr: 0.100000, loss: 3.8725, stu_CELoss: 2.2572 DKDLoss: 1.6153 
2022-05-02 02:43:02 - train: epoch 019, train_loss: 3.8495
2022-05-02 02:45:35 - eval: epoch: 019, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 51.984%, stu_acc5: 77.458%, stu_test_loss: 2.0592
2022-05-02 02:45:36 - until epoch: 019, tea_best_acc1: 73.944%, stu_best_acc1: 52.454%
2022-05-02 02:45:36 - epoch 020 lr: 0.1
2022-05-02 02:46:16 - train: epoch 0020, iter [00100, 05004], lr: 0.100000, loss: 3.9715, stu_CELoss: 2.4328 DKDLoss: 1.5387 
2022-05-02 02:46:50 - train: epoch 0020, iter [00200, 05004], lr: 0.100000, loss: 3.4857, stu_CELoss: 2.0340 DKDLoss: 1.4517 
2022-05-02 02:47:24 - train: epoch 0020, iter [00300, 05004], lr: 0.100000, loss: 3.7226, stu_CELoss: 2.2128 DKDLoss: 1.5098 
2022-05-02 02:47:59 - train: epoch 0020, iter [00400, 05004], lr: 0.100000, loss: 3.7484, stu_CELoss: 2.1642 DKDLoss: 1.5842 
2022-05-02 02:48:34 - train: epoch 0020, iter [00500, 05004], lr: 0.100000, loss: 3.7763, stu_CELoss: 2.2788 DKDLoss: 1.4975 
2022-05-02 02:49:08 - train: epoch 0020, iter [00600, 05004], lr: 0.100000, loss: 3.9218, stu_CELoss: 2.3303 DKDLoss: 1.5915 
2022-05-02 02:49:44 - train: epoch 0020, iter [00700, 05004], lr: 0.100000, loss: 3.8673, stu_CELoss: 2.1719 DKDLoss: 1.6954 
2022-05-02 02:50:18 - train: epoch 0020, iter [00800, 05004], lr: 0.100000, loss: 4.0447, stu_CELoss: 2.3873 DKDLoss: 1.6574 
2022-05-02 02:50:52 - train: epoch 0020, iter [00900, 05004], lr: 0.100000, loss: 4.0241, stu_CELoss: 2.4425 DKDLoss: 1.5816 
2022-05-02 02:51:28 - train: epoch 0020, iter [01000, 05004], lr: 0.100000, loss: 3.9325, stu_CELoss: 2.4087 DKDLoss: 1.5239 
2022-05-02 02:52:02 - train: epoch 0020, iter [01100, 05004], lr: 0.100000, loss: 3.6241, stu_CELoss: 2.1305 DKDLoss: 1.4936 
2022-05-02 02:52:37 - train: epoch 0020, iter [01200, 05004], lr: 0.100000, loss: 3.5924, stu_CELoss: 2.0654 DKDLoss: 1.5269 
2022-05-02 02:53:12 - train: epoch 0020, iter [01300, 05004], lr: 0.100000, loss: 3.7437, stu_CELoss: 2.2985 DKDLoss: 1.4452 
2022-05-02 02:53:47 - train: epoch 0020, iter [01400, 05004], lr: 0.100000, loss: 3.6936, stu_CELoss: 2.1800 DKDLoss: 1.5136 
2022-05-02 02:54:21 - train: epoch 0020, iter [01500, 05004], lr: 0.100000, loss: 3.8275, stu_CELoss: 2.1813 DKDLoss: 1.6462 
2022-05-02 02:54:57 - train: epoch 0020, iter [01600, 05004], lr: 0.100000, loss: 4.2074, stu_CELoss: 2.5243 DKDLoss: 1.6831 
2022-05-02 02:55:31 - train: epoch 0020, iter [01700, 05004], lr: 0.100000, loss: 3.8534, stu_CELoss: 2.2220 DKDLoss: 1.6314 
2022-05-02 02:56:06 - train: epoch 0020, iter [01800, 05004], lr: 0.100000, loss: 3.9597, stu_CELoss: 2.3772 DKDLoss: 1.5825 
2022-05-02 02:56:42 - train: epoch 0020, iter [01900, 05004], lr: 0.100000, loss: 3.9190, stu_CELoss: 2.2814 DKDLoss: 1.6375 
2022-05-02 02:57:17 - train: epoch 0020, iter [02000, 05004], lr: 0.100000, loss: 3.7421, stu_CELoss: 2.1920 DKDLoss: 1.5501 
2022-05-02 02:57:51 - train: epoch 0020, iter [02100, 05004], lr: 0.100000, loss: 4.2220, stu_CELoss: 2.5757 DKDLoss: 1.6462 
2022-05-02 02:58:26 - train: epoch 0020, iter [02200, 05004], lr: 0.100000, loss: 3.6936, stu_CELoss: 2.1537 DKDLoss: 1.5400 
2022-05-02 02:59:00 - train: epoch 0020, iter [02300, 05004], lr: 0.100000, loss: 3.6777, stu_CELoss: 2.2474 DKDLoss: 1.4304 
2022-05-02 02:59:35 - train: epoch 0020, iter [02400, 05004], lr: 0.100000, loss: 3.8184, stu_CELoss: 2.3550 DKDLoss: 1.4634 
2022-05-02 03:00:10 - train: epoch 0020, iter [02500, 05004], lr: 0.100000, loss: 3.9483, stu_CELoss: 2.3235 DKDLoss: 1.6248 
2022-05-02 03:00:45 - train: epoch 0020, iter [02600, 05004], lr: 0.100000, loss: 3.7639, stu_CELoss: 2.2320 DKDLoss: 1.5319 
2022-05-02 03:01:20 - train: epoch 0020, iter [02700, 05004], lr: 0.100000, loss: 3.8306, stu_CELoss: 2.2227 DKDLoss: 1.6079 
2022-05-02 03:01:55 - train: epoch 0020, iter [02800, 05004], lr: 0.100000, loss: 3.9270, stu_CELoss: 2.3346 DKDLoss: 1.5924 
2022-05-02 03:02:29 - train: epoch 0020, iter [02900, 05004], lr: 0.100000, loss: 3.7578, stu_CELoss: 2.2835 DKDLoss: 1.4743 
2022-05-02 03:03:05 - train: epoch 0020, iter [03000, 05004], lr: 0.100000, loss: 4.1529, stu_CELoss: 2.4711 DKDLoss: 1.6818 
2022-05-02 03:03:40 - train: epoch 0020, iter [03100, 05004], lr: 0.100000, loss: 3.9873, stu_CELoss: 2.3233 DKDLoss: 1.6640 
2022-05-02 03:04:14 - train: epoch 0020, iter [03200, 05004], lr: 0.100000, loss: 3.7626, stu_CELoss: 2.1877 DKDLoss: 1.5750 
2022-05-02 03:04:48 - train: epoch 0020, iter [03300, 05004], lr: 0.100000, loss: 3.7018, stu_CELoss: 2.1259 DKDLoss: 1.5758 
2022-05-02 03:05:25 - train: epoch 0020, iter [03400, 05004], lr: 0.100000, loss: 3.9831, stu_CELoss: 2.3158 DKDLoss: 1.6674 
2022-05-02 03:06:00 - train: epoch 0020, iter [03500, 05004], lr: 0.100000, loss: 3.6186, stu_CELoss: 2.0915 DKDLoss: 1.5272 
2022-05-02 03:06:34 - train: epoch 0020, iter [03600, 05004], lr: 0.100000, loss: 3.8392, stu_CELoss: 2.3045 DKDLoss: 1.5347 
2022-05-02 03:07:08 - train: epoch 0020, iter [03700, 05004], lr: 0.100000, loss: 4.0042, stu_CELoss: 2.3560 DKDLoss: 1.6481 
2022-05-02 03:07:45 - train: epoch 0020, iter [03800, 05004], lr: 0.100000, loss: 3.8296, stu_CELoss: 2.2182 DKDLoss: 1.6114 
2022-05-02 03:08:18 - train: epoch 0020, iter [03900, 05004], lr: 0.100000, loss: 4.0071, stu_CELoss: 2.4646 DKDLoss: 1.5425 
2022-05-02 03:08:54 - train: epoch 0020, iter [04000, 05004], lr: 0.100000, loss: 3.9782, stu_CELoss: 2.2914 DKDLoss: 1.6868 
2022-05-02 03:09:28 - train: epoch 0020, iter [04100, 05004], lr: 0.100000, loss: 3.7748, stu_CELoss: 2.2733 DKDLoss: 1.5015 
2022-05-02 03:10:03 - train: epoch 0020, iter [04200, 05004], lr: 0.100000, loss: 3.6324, stu_CELoss: 2.2238 DKDLoss: 1.4086 
2022-05-02 03:10:38 - train: epoch 0020, iter [04300, 05004], lr: 0.100000, loss: 3.9405, stu_CELoss: 2.4166 DKDLoss: 1.5239 
2022-05-02 03:11:14 - train: epoch 0020, iter [04400, 05004], lr: 0.100000, loss: 3.8545, stu_CELoss: 2.2849 DKDLoss: 1.5697 
2022-05-02 03:11:48 - train: epoch 0020, iter [04500, 05004], lr: 0.100000, loss: 3.7632, stu_CELoss: 2.2269 DKDLoss: 1.5363 
2022-05-02 03:12:23 - train: epoch 0020, iter [04600, 05004], lr: 0.100000, loss: 3.8336, stu_CELoss: 2.3450 DKDLoss: 1.4885 
2022-05-02 03:12:57 - train: epoch 0020, iter [04700, 05004], lr: 0.100000, loss: 3.6729, stu_CELoss: 2.1149 DKDLoss: 1.5580 
2022-05-02 03:13:32 - train: epoch 0020, iter [04800, 05004], lr: 0.100000, loss: 3.6268, stu_CELoss: 2.2201 DKDLoss: 1.4067 
2022-05-02 03:14:08 - train: epoch 0020, iter [04900, 05004], lr: 0.100000, loss: 4.0209, stu_CELoss: 2.3407 DKDLoss: 1.6802 
2022-05-02 03:14:41 - train: epoch 0020, iter [05000, 05004], lr: 0.100000, loss: 3.6082, stu_CELoss: 2.1798 DKDLoss: 1.4284 
2022-05-02 03:14:42 - train: epoch 020, train_loss: 3.8357
2022-05-02 03:17:17 - eval: epoch: 020, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 52.204%, stu_acc5: 77.362%, stu_test_loss: 2.0615
2022-05-02 03:17:17 - until epoch: 020, tea_best_acc1: 73.944%, stu_best_acc1: 52.454%
2022-05-02 03:17:17 - epoch 021 lr: 0.1
2022-05-02 03:17:57 - train: epoch 0021, iter [00100, 05004], lr: 0.100000, loss: 3.7500, stu_CELoss: 2.2499 DKDLoss: 1.5001 
2022-05-02 03:18:33 - train: epoch 0021, iter [00200, 05004], lr: 0.100000, loss: 3.9409, stu_CELoss: 2.3213 DKDLoss: 1.6196 
2022-05-02 03:19:06 - train: epoch 0021, iter [00300, 05004], lr: 0.100000, loss: 3.4456, stu_CELoss: 1.9780 DKDLoss: 1.4676 
2022-05-02 03:19:41 - train: epoch 0021, iter [00400, 05004], lr: 0.100000, loss: 3.6361, stu_CELoss: 2.2174 DKDLoss: 1.4187 
2022-05-02 03:20:16 - train: epoch 0021, iter [00500, 05004], lr: 0.100000, loss: 3.4507, stu_CELoss: 2.0431 DKDLoss: 1.4076 
2022-05-02 03:20:50 - train: epoch 0021, iter [00600, 05004], lr: 0.100000, loss: 3.6395, stu_CELoss: 2.1465 DKDLoss: 1.4929 
2022-05-02 03:21:24 - train: epoch 0021, iter [00700, 05004], lr: 0.100000, loss: 3.7175, stu_CELoss: 2.1360 DKDLoss: 1.5815 
2022-05-02 03:21:59 - train: epoch 0021, iter [00800, 05004], lr: 0.100000, loss: 3.9380, stu_CELoss: 2.3301 DKDLoss: 1.6079 
2022-05-02 03:22:34 - train: epoch 0021, iter [00900, 05004], lr: 0.100000, loss: 3.8851, stu_CELoss: 2.2709 DKDLoss: 1.6142 
2022-05-02 03:23:08 - train: epoch 0021, iter [01000, 05004], lr: 0.100000, loss: 3.5919, stu_CELoss: 2.1456 DKDLoss: 1.4462 
2022-05-02 03:23:44 - train: epoch 0021, iter [01100, 05004], lr: 0.100000, loss: 3.8943, stu_CELoss: 2.3565 DKDLoss: 1.5378 
2022-05-02 03:24:18 - train: epoch 0021, iter [01200, 05004], lr: 0.100000, loss: 3.7209, stu_CELoss: 2.2740 DKDLoss: 1.4469 
2022-05-02 03:24:53 - train: epoch 0021, iter [01300, 05004], lr: 0.100000, loss: 3.6052, stu_CELoss: 2.1411 DKDLoss: 1.4641 
2022-05-02 03:25:28 - train: epoch 0021, iter [01400, 05004], lr: 0.100000, loss: 3.5160, stu_CELoss: 1.9475 DKDLoss: 1.5685 
2022-05-02 03:26:03 - train: epoch 0021, iter [01500, 05004], lr: 0.100000, loss: 3.8408, stu_CELoss: 2.3089 DKDLoss: 1.5318 
2022-05-02 03:26:37 - train: epoch 0021, iter [01600, 05004], lr: 0.100000, loss: 3.8909, stu_CELoss: 2.3351 DKDLoss: 1.5558 
2022-05-02 03:27:13 - train: epoch 0021, iter [01700, 05004], lr: 0.100000, loss: 3.7319, stu_CELoss: 2.3016 DKDLoss: 1.4303 
2022-05-02 03:27:47 - train: epoch 0021, iter [01800, 05004], lr: 0.100000, loss: 3.8037, stu_CELoss: 2.3114 DKDLoss: 1.4923 
2022-05-02 03:28:23 - train: epoch 0021, iter [01900, 05004], lr: 0.100000, loss: 4.1543, stu_CELoss: 2.5014 DKDLoss: 1.6529 
2022-05-02 03:28:57 - train: epoch 0021, iter [02000, 05004], lr: 0.100000, loss: 3.8310, stu_CELoss: 2.3117 DKDLoss: 1.5193 
2022-05-02 03:29:33 - train: epoch 0021, iter [02100, 05004], lr: 0.100000, loss: 3.3419, stu_CELoss: 1.9748 DKDLoss: 1.3672 
2022-05-02 03:30:08 - train: epoch 0021, iter [02200, 05004], lr: 0.100000, loss: 3.8827, stu_CELoss: 2.3241 DKDLoss: 1.5586 
2022-05-02 03:30:43 - train: epoch 0021, iter [02300, 05004], lr: 0.100000, loss: 4.0451, stu_CELoss: 2.4919 DKDLoss: 1.5532 
2022-05-02 03:31:17 - train: epoch 0021, iter [02400, 05004], lr: 0.100000, loss: 3.5149, stu_CELoss: 2.1135 DKDLoss: 1.4014 
2022-05-02 03:31:52 - train: epoch 0021, iter [02500, 05004], lr: 0.100000, loss: 3.5823, stu_CELoss: 2.1374 DKDLoss: 1.4449 
2022-05-02 03:32:28 - train: epoch 0021, iter [02600, 05004], lr: 0.100000, loss: 3.8267, stu_CELoss: 2.3417 DKDLoss: 1.4850 
2022-05-02 03:33:03 - train: epoch 0021, iter [02700, 05004], lr: 0.100000, loss: 3.9171, stu_CELoss: 2.1419 DKDLoss: 1.7752 
2022-05-02 03:33:37 - train: epoch 0021, iter [02800, 05004], lr: 0.100000, loss: 3.7222, stu_CELoss: 2.2446 DKDLoss: 1.4776 
2022-05-02 03:34:12 - train: epoch 0021, iter [02900, 05004], lr: 0.100000, loss: 3.9385, stu_CELoss: 2.3544 DKDLoss: 1.5841 
2022-05-02 03:34:47 - train: epoch 0021, iter [03000, 05004], lr: 0.100000, loss: 4.0578, stu_CELoss: 2.4518 DKDLoss: 1.6060 
2022-05-02 03:35:22 - train: epoch 0021, iter [03100, 05004], lr: 0.100000, loss: 3.8713, stu_CELoss: 2.3198 DKDLoss: 1.5515 
2022-05-02 03:35:57 - train: epoch 0021, iter [03200, 05004], lr: 0.100000, loss: 3.5484, stu_CELoss: 2.0655 DKDLoss: 1.4830 
2022-05-02 03:36:31 - train: epoch 0021, iter [03300, 05004], lr: 0.100000, loss: 4.0799, stu_CELoss: 2.5493 DKDLoss: 1.5307 
2022-05-02 03:37:06 - train: epoch 0021, iter [03400, 05004], lr: 0.100000, loss: 4.1361, stu_CELoss: 2.5199 DKDLoss: 1.6161 
2022-05-02 03:37:41 - train: epoch 0021, iter [03500, 05004], lr: 0.100000, loss: 3.8985, stu_CELoss: 2.3264 DKDLoss: 1.5721 
2022-05-02 03:38:16 - train: epoch 0021, iter [03600, 05004], lr: 0.100000, loss: 4.0943, stu_CELoss: 2.4107 DKDLoss: 1.6836 
2022-05-02 03:38:51 - train: epoch 0021, iter [03700, 05004], lr: 0.100000, loss: 3.9026, stu_CELoss: 2.2737 DKDLoss: 1.6289 
2022-05-02 03:39:26 - train: epoch 0021, iter [03800, 05004], lr: 0.100000, loss: 3.8256, stu_CELoss: 2.3265 DKDLoss: 1.4991 
2022-05-02 03:40:01 - train: epoch 0021, iter [03900, 05004], lr: 0.100000, loss: 3.7221, stu_CELoss: 2.1881 DKDLoss: 1.5341 
2022-05-02 03:40:35 - train: epoch 0021, iter [04000, 05004], lr: 0.100000, loss: 4.0135, stu_CELoss: 2.4770 DKDLoss: 1.5365 
2022-05-02 03:41:10 - train: epoch 0021, iter [04100, 05004], lr: 0.100000, loss: 3.8544, stu_CELoss: 2.1968 DKDLoss: 1.6576 
2022-05-02 03:41:45 - train: epoch 0021, iter [04200, 05004], lr: 0.100000, loss: 3.8856, stu_CELoss: 2.3131 DKDLoss: 1.5725 
2022-05-02 03:42:21 - train: epoch 0021, iter [04300, 05004], lr: 0.100000, loss: 3.9378, stu_CELoss: 2.4338 DKDLoss: 1.5040 
2022-05-02 03:42:56 - train: epoch 0021, iter [04400, 05004], lr: 0.100000, loss: 3.8683, stu_CELoss: 2.3674 DKDLoss: 1.5009 
2022-05-02 03:43:31 - train: epoch 0021, iter [04500, 05004], lr: 0.100000, loss: 3.8957, stu_CELoss: 2.3376 DKDLoss: 1.5581 
2022-05-02 03:44:05 - train: epoch 0021, iter [04600, 05004], lr: 0.100000, loss: 3.7914, stu_CELoss: 2.2729 DKDLoss: 1.5185 
2022-05-02 03:44:41 - train: epoch 0021, iter [04700, 05004], lr: 0.100000, loss: 4.0343, stu_CELoss: 2.4439 DKDLoss: 1.5904 
2022-05-02 03:45:15 - train: epoch 0021, iter [04800, 05004], lr: 0.100000, loss: 3.9282, stu_CELoss: 2.3581 DKDLoss: 1.5701 
2022-05-02 03:45:51 - train: epoch 0021, iter [04900, 05004], lr: 0.100000, loss: 3.6924, stu_CELoss: 2.0837 DKDLoss: 1.6087 
2022-05-02 03:46:24 - train: epoch 0021, iter [05000, 05004], lr: 0.100000, loss: 3.8661, stu_CELoss: 2.2278 DKDLoss: 1.6383 
2022-05-02 03:46:25 - train: epoch 021, train_loss: 3.8299
2022-05-02 03:48:59 - eval: epoch: 021, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 51.926%, stu_acc5: 77.198%, stu_test_loss: 2.0805
2022-05-02 03:48:59 - until epoch: 021, tea_best_acc1: 73.944%, stu_best_acc1: 52.454%
2022-05-02 03:48:59 - epoch 022 lr: 0.1
2022-05-02 03:49:39 - train: epoch 0022, iter [00100, 05004], lr: 0.100000, loss: 3.4753, stu_CELoss: 1.9788 DKDLoss: 1.4964 
2022-05-02 03:50:13 - train: epoch 0022, iter [00200, 05004], lr: 0.100000, loss: 3.6378, stu_CELoss: 2.2193 DKDLoss: 1.4185 
2022-05-02 03:50:48 - train: epoch 0022, iter [00300, 05004], lr: 0.100000, loss: 3.7876, stu_CELoss: 2.2044 DKDLoss: 1.5832 
2022-05-02 03:51:22 - train: epoch 0022, iter [00400, 05004], lr: 0.100000, loss: 3.7240, stu_CELoss: 2.2368 DKDLoss: 1.4873 
2022-05-02 03:51:56 - train: epoch 0022, iter [00500, 05004], lr: 0.100000, loss: 3.6810, stu_CELoss: 2.2354 DKDLoss: 1.4457 
2022-05-02 03:52:31 - train: epoch 0022, iter [00600, 05004], lr: 0.100000, loss: 3.8785, stu_CELoss: 2.3633 DKDLoss: 1.5152 
2022-05-02 03:53:06 - train: epoch 0022, iter [00700, 05004], lr: 0.100000, loss: 4.1246, stu_CELoss: 2.5094 DKDLoss: 1.6152 
2022-05-02 03:53:40 - train: epoch 0022, iter [00800, 05004], lr: 0.100000, loss: 3.9403, stu_CELoss: 2.4173 DKDLoss: 1.5230 
2022-05-02 03:54:14 - train: epoch 0022, iter [00900, 05004], lr: 0.100000, loss: 3.6963, stu_CELoss: 2.2328 DKDLoss: 1.4634 
2022-05-02 03:54:48 - train: epoch 0022, iter [01000, 05004], lr: 0.100000, loss: 3.9607, stu_CELoss: 2.4683 DKDLoss: 1.4924 
2022-05-02 03:55:24 - train: epoch 0022, iter [01100, 05004], lr: 0.100000, loss: 3.6177, stu_CELoss: 2.1549 DKDLoss: 1.4627 
2022-05-02 03:55:59 - train: epoch 0022, iter [01200, 05004], lr: 0.100000, loss: 3.3007, stu_CELoss: 1.8646 DKDLoss: 1.4361 
2022-05-02 03:56:33 - train: epoch 0022, iter [01300, 05004], lr: 0.100000, loss: 4.1296, stu_CELoss: 2.4372 DKDLoss: 1.6923 
2022-05-02 03:57:09 - train: epoch 0022, iter [01400, 05004], lr: 0.100000, loss: 3.8256, stu_CELoss: 2.0922 DKDLoss: 1.7334 
2022-05-02 03:57:43 - train: epoch 0022, iter [01500, 05004], lr: 0.100000, loss: 3.8814, stu_CELoss: 2.3739 DKDLoss: 1.5075 
2022-05-02 03:58:18 - train: epoch 0022, iter [01600, 05004], lr: 0.100000, loss: 3.6558, stu_CELoss: 2.1370 DKDLoss: 1.5187 
2022-05-02 03:58:53 - train: epoch 0022, iter [01700, 05004], lr: 0.100000, loss: 4.0287, stu_CELoss: 2.4498 DKDLoss: 1.5790 
2022-05-02 03:59:28 - train: epoch 0022, iter [01800, 05004], lr: 0.100000, loss: 4.1079, stu_CELoss: 2.4107 DKDLoss: 1.6972 
2022-05-02 04:00:03 - train: epoch 0022, iter [01900, 05004], lr: 0.100000, loss: 3.9543, stu_CELoss: 2.3147 DKDLoss: 1.6395 
2022-05-02 04:00:38 - train: epoch 0022, iter [02000, 05004], lr: 0.100000, loss: 3.8277, stu_CELoss: 2.1849 DKDLoss: 1.6428 
2022-05-02 04:01:12 - train: epoch 0022, iter [02100, 05004], lr: 0.100000, loss: 3.3152, stu_CELoss: 2.0308 DKDLoss: 1.2844 
2022-05-02 04:01:48 - train: epoch 0022, iter [02200, 05004], lr: 0.100000, loss: 3.4901, stu_CELoss: 2.0234 DKDLoss: 1.4667 
2022-05-02 04:02:22 - train: epoch 0022, iter [02300, 05004], lr: 0.100000, loss: 4.0233, stu_CELoss: 2.3919 DKDLoss: 1.6313 
2022-05-02 04:02:58 - train: epoch 0022, iter [02400, 05004], lr: 0.100000, loss: 4.1381, stu_CELoss: 2.5348 DKDLoss: 1.6033 
2022-05-02 04:03:32 - train: epoch 0022, iter [02500, 05004], lr: 0.100000, loss: 3.8501, stu_CELoss: 2.3148 DKDLoss: 1.5353 
2022-05-02 04:04:07 - train: epoch 0022, iter [02600, 05004], lr: 0.100000, loss: 3.7867, stu_CELoss: 2.2437 DKDLoss: 1.5431 
2022-05-02 04:04:42 - train: epoch 0022, iter [02700, 05004], lr: 0.100000, loss: 3.9187, stu_CELoss: 2.2817 DKDLoss: 1.6370 
2022-05-02 04:05:17 - train: epoch 0022, iter [02800, 05004], lr: 0.100000, loss: 4.1542, stu_CELoss: 2.4936 DKDLoss: 1.6606 
2022-05-02 04:05:51 - train: epoch 0022, iter [02900, 05004], lr: 0.100000, loss: 3.9770, stu_CELoss: 2.2166 DKDLoss: 1.7604 
2022-05-02 04:06:26 - train: epoch 0022, iter [03000, 05004], lr: 0.100000, loss: 3.7397, stu_CELoss: 2.2645 DKDLoss: 1.4752 
2022-05-02 04:07:01 - train: epoch 0022, iter [03100, 05004], lr: 0.100000, loss: 3.9801, stu_CELoss: 2.4295 DKDLoss: 1.5506 
2022-05-02 04:07:35 - train: epoch 0022, iter [03200, 05004], lr: 0.100000, loss: 3.7276, stu_CELoss: 2.2673 DKDLoss: 1.4603 
2022-05-02 04:08:11 - train: epoch 0022, iter [03300, 05004], lr: 0.100000, loss: 3.9740, stu_CELoss: 2.3162 DKDLoss: 1.6577 
2022-05-02 04:08:46 - train: epoch 0022, iter [03400, 05004], lr: 0.100000, loss: 3.8665, stu_CELoss: 2.2916 DKDLoss: 1.5750 
2022-05-02 04:09:20 - train: epoch 0022, iter [03500, 05004], lr: 0.100000, loss: 3.7830, stu_CELoss: 2.2929 DKDLoss: 1.4901 
2022-05-02 04:09:56 - train: epoch 0022, iter [03600, 05004], lr: 0.100000, loss: 3.8434, stu_CELoss: 2.2578 DKDLoss: 1.5856 
2022-05-02 04:10:30 - train: epoch 0022, iter [03700, 05004], lr: 0.100000, loss: 4.0391, stu_CELoss: 2.3505 DKDLoss: 1.6886 
2022-05-02 04:11:05 - train: epoch 0022, iter [03800, 05004], lr: 0.100000, loss: 3.9702, stu_CELoss: 2.4355 DKDLoss: 1.5347 
2022-05-02 04:11:40 - train: epoch 0022, iter [03900, 05004], lr: 0.100000, loss: 3.9268, stu_CELoss: 2.3252 DKDLoss: 1.6016 
2022-05-02 04:12:16 - train: epoch 0022, iter [04000, 05004], lr: 0.100000, loss: 3.6836, stu_CELoss: 2.2398 DKDLoss: 1.4437 
2022-05-02 04:12:51 - train: epoch 0022, iter [04100, 05004], lr: 0.100000, loss: 3.8610, stu_CELoss: 2.3046 DKDLoss: 1.5564 
2022-05-02 04:13:25 - train: epoch 0022, iter [04200, 05004], lr: 0.100000, loss: 3.8027, stu_CELoss: 2.2840 DKDLoss: 1.5187 
2022-05-02 04:14:00 - train: epoch 0022, iter [04300, 05004], lr: 0.100000, loss: 3.8315, stu_CELoss: 2.2577 DKDLoss: 1.5738 
2022-05-02 04:14:35 - train: epoch 0022, iter [04400, 05004], lr: 0.100000, loss: 3.7548, stu_CELoss: 2.1833 DKDLoss: 1.5716 
2022-05-02 04:15:11 - train: epoch 0022, iter [04500, 05004], lr: 0.100000, loss: 3.5830, stu_CELoss: 2.1671 DKDLoss: 1.4159 
2022-05-02 04:15:44 - train: epoch 0022, iter [04600, 05004], lr: 0.100000, loss: 3.9388, stu_CELoss: 2.4994 DKDLoss: 1.4394 
2022-05-02 04:16:20 - train: epoch 0022, iter [04700, 05004], lr: 0.100000, loss: 3.8640, stu_CELoss: 2.3653 DKDLoss: 1.4988 
2022-05-02 04:16:54 - train: epoch 0022, iter [04800, 05004], lr: 0.100000, loss: 3.3136, stu_CELoss: 1.8807 DKDLoss: 1.4329 
2022-05-02 04:17:30 - train: epoch 0022, iter [04900, 05004], lr: 0.100000, loss: 3.8310, stu_CELoss: 2.3668 DKDLoss: 1.4641 
2022-05-02 04:18:03 - train: epoch 0022, iter [05000, 05004], lr: 0.100000, loss: 3.7449, stu_CELoss: 2.1273 DKDLoss: 1.6176 
2022-05-02 04:18:03 - train: epoch 022, train_loss: 3.8152
2022-05-02 04:20:39 - eval: epoch: 022, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 51.350%, stu_acc5: 76.902%, stu_test_loss: 2.0939
2022-05-02 04:20:39 - until epoch: 022, tea_best_acc1: 73.944%, stu_best_acc1: 52.454%
2022-05-02 04:20:39 - epoch 023 lr: 0.1
2022-05-02 04:21:19 - train: epoch 0023, iter [00100, 05004], lr: 0.100000, loss: 3.9696, stu_CELoss: 2.3568 DKDLoss: 1.6127 
2022-05-02 04:21:54 - train: epoch 0023, iter [00200, 05004], lr: 0.100000, loss: 3.3672, stu_CELoss: 2.0247 DKDLoss: 1.3425 
2022-05-02 04:22:29 - train: epoch 0023, iter [00300, 05004], lr: 0.100000, loss: 3.5874, stu_CELoss: 2.2299 DKDLoss: 1.3575 
2022-05-02 04:23:03 - train: epoch 0023, iter [00400, 05004], lr: 0.100000, loss: 3.6831, stu_CELoss: 2.2001 DKDLoss: 1.4830 
2022-05-02 04:23:37 - train: epoch 0023, iter [00500, 05004], lr: 0.100000, loss: 3.7839, stu_CELoss: 2.2784 DKDLoss: 1.5055 
2022-05-02 04:24:12 - train: epoch 0023, iter [00600, 05004], lr: 0.100000, loss: 3.7636, stu_CELoss: 2.2633 DKDLoss: 1.5004 
2022-05-02 04:24:46 - train: epoch 0023, iter [00700, 05004], lr: 0.100000, loss: 3.9261, stu_CELoss: 2.3457 DKDLoss: 1.5804 
2022-05-02 04:25:21 - train: epoch 0023, iter [00800, 05004], lr: 0.100000, loss: 3.8742, stu_CELoss: 2.3279 DKDLoss: 1.5463 
2022-05-02 04:25:56 - train: epoch 0023, iter [00900, 05004], lr: 0.100000, loss: 3.7648, stu_CELoss: 2.3459 DKDLoss: 1.4189 
2022-05-02 04:26:32 - train: epoch 0023, iter [01000, 05004], lr: 0.100000, loss: 3.7290, stu_CELoss: 2.1538 DKDLoss: 1.5752 
2022-05-02 04:27:06 - train: epoch 0023, iter [01100, 05004], lr: 0.100000, loss: 3.8113, stu_CELoss: 2.2756 DKDLoss: 1.5357 
2022-05-02 04:27:41 - train: epoch 0023, iter [01200, 05004], lr: 0.100000, loss: 3.5086, stu_CELoss: 2.1134 DKDLoss: 1.3952 
2022-05-02 04:28:16 - train: epoch 0023, iter [01300, 05004], lr: 0.100000, loss: 3.8533, stu_CELoss: 2.1997 DKDLoss: 1.6537 
2022-05-02 04:28:51 - train: epoch 0023, iter [01400, 05004], lr: 0.100000, loss: 3.9111, stu_CELoss: 2.3182 DKDLoss: 1.5929 
2022-05-02 04:29:26 - train: epoch 0023, iter [01500, 05004], lr: 0.100000, loss: 3.6799, stu_CELoss: 2.1663 DKDLoss: 1.5136 
2022-05-02 04:30:01 - train: epoch 0023, iter [01600, 05004], lr: 0.100000, loss: 3.6845, stu_CELoss: 2.2286 DKDLoss: 1.4559 
2022-05-02 04:30:35 - train: epoch 0023, iter [01700, 05004], lr: 0.100000, loss: 3.9810, stu_CELoss: 2.2416 DKDLoss: 1.7394 
2022-05-02 04:31:10 - train: epoch 0023, iter [01800, 05004], lr: 0.100000, loss: 4.0149, stu_CELoss: 2.4429 DKDLoss: 1.5719 
2022-05-02 04:31:45 - train: epoch 0023, iter [01900, 05004], lr: 0.100000, loss: 4.0937, stu_CELoss: 2.5252 DKDLoss: 1.5686 
2022-05-02 04:32:19 - train: epoch 0023, iter [02000, 05004], lr: 0.100000, loss: 3.5471, stu_CELoss: 2.0613 DKDLoss: 1.4858 
2022-05-02 04:32:54 - train: epoch 0023, iter [02100, 05004], lr: 0.100000, loss: 3.7449, stu_CELoss: 2.2375 DKDLoss: 1.5073 
2022-05-02 04:33:29 - train: epoch 0023, iter [02200, 05004], lr: 0.100000, loss: 3.3139, stu_CELoss: 1.9449 DKDLoss: 1.3690 
2022-05-02 04:34:04 - train: epoch 0023, iter [02300, 05004], lr: 0.100000, loss: 3.8212, stu_CELoss: 2.2034 DKDLoss: 1.6177 
2022-05-02 04:34:39 - train: epoch 0023, iter [02400, 05004], lr: 0.100000, loss: 3.7433, stu_CELoss: 2.2044 DKDLoss: 1.5389 
2022-05-02 04:35:14 - train: epoch 0023, iter [02500, 05004], lr: 0.100000, loss: 4.0571, stu_CELoss: 2.4101 DKDLoss: 1.6470 
2022-05-02 04:35:48 - train: epoch 0023, iter [02600, 05004], lr: 0.100000, loss: 3.6820, stu_CELoss: 2.2741 DKDLoss: 1.4079 
2022-05-02 04:36:22 - train: epoch 0023, iter [02700, 05004], lr: 0.100000, loss: 3.9772, stu_CELoss: 2.4420 DKDLoss: 1.5351 
2022-05-02 04:36:57 - train: epoch 0023, iter [02800, 05004], lr: 0.100000, loss: 4.1745, stu_CELoss: 2.4789 DKDLoss: 1.6956 
2022-05-02 04:37:31 - train: epoch 0023, iter [02900, 05004], lr: 0.100000, loss: 3.8467, stu_CELoss: 2.2556 DKDLoss: 1.5911 
2022-05-02 04:38:07 - train: epoch 0023, iter [03000, 05004], lr: 0.100000, loss: 3.8829, stu_CELoss: 2.3632 DKDLoss: 1.5197 
2022-05-02 04:38:41 - train: epoch 0023, iter [03100, 05004], lr: 0.100000, loss: 3.9426, stu_CELoss: 2.4712 DKDLoss: 1.4714 
2022-05-02 04:39:16 - train: epoch 0023, iter [03200, 05004], lr: 0.100000, loss: 3.7454, stu_CELoss: 2.2556 DKDLoss: 1.4898 
2022-05-02 04:39:51 - train: epoch 0023, iter [03300, 05004], lr: 0.100000, loss: 3.8248, stu_CELoss: 2.2487 DKDLoss: 1.5761 
2022-05-02 04:40:26 - train: epoch 0023, iter [03400, 05004], lr: 0.100000, loss: 4.0407, stu_CELoss: 2.4163 DKDLoss: 1.6244 
2022-05-02 04:41:00 - train: epoch 0023, iter [03500, 05004], lr: 0.100000, loss: 3.6329, stu_CELoss: 2.1931 DKDLoss: 1.4398 
2022-05-02 04:41:35 - train: epoch 0023, iter [03600, 05004], lr: 0.100000, loss: 3.8045, stu_CELoss: 2.2790 DKDLoss: 1.5255 
2022-05-02 04:42:10 - train: epoch 0023, iter [03700, 05004], lr: 0.100000, loss: 3.7901, stu_CELoss: 2.2588 DKDLoss: 1.5313 
2022-05-02 04:42:45 - train: epoch 0023, iter [03800, 05004], lr: 0.100000, loss: 3.9056, stu_CELoss: 2.4012 DKDLoss: 1.5043 
2022-05-02 04:43:20 - train: epoch 0023, iter [03900, 05004], lr: 0.100000, loss: 3.8374, stu_CELoss: 2.3723 DKDLoss: 1.4651 
2022-05-02 04:43:55 - train: epoch 0023, iter [04000, 05004], lr: 0.100000, loss: 3.8509, stu_CELoss: 2.3054 DKDLoss: 1.5455 
2022-05-02 04:44:30 - train: epoch 0023, iter [04100, 05004], lr: 0.100000, loss: 3.6975, stu_CELoss: 2.1407 DKDLoss: 1.5568 
2022-05-02 04:45:05 - train: epoch 0023, iter [04200, 05004], lr: 0.100000, loss: 3.6223, stu_CELoss: 2.0097 DKDLoss: 1.6126 
2022-05-02 04:45:39 - train: epoch 0023, iter [04300, 05004], lr: 0.100000, loss: 3.6486, stu_CELoss: 2.1684 DKDLoss: 1.4802 
2022-05-02 04:46:14 - train: epoch 0023, iter [04400, 05004], lr: 0.100000, loss: 3.7743, stu_CELoss: 2.1229 DKDLoss: 1.6514 
2022-05-02 04:46:49 - train: epoch 0023, iter [04500, 05004], lr: 0.100000, loss: 3.8018, stu_CELoss: 2.2208 DKDLoss: 1.5809 
2022-05-02 04:47:24 - train: epoch 0023, iter [04600, 05004], lr: 0.100000, loss: 3.9670, stu_CELoss: 2.3893 DKDLoss: 1.5777 
2022-05-02 04:48:00 - train: epoch 0023, iter [04700, 05004], lr: 0.100000, loss: 3.7879, stu_CELoss: 2.1968 DKDLoss: 1.5910 
2022-05-02 04:48:32 - train: epoch 0023, iter [04800, 05004], lr: 0.100000, loss: 3.7420, stu_CELoss: 2.2457 DKDLoss: 1.4963 
2022-05-02 04:49:08 - train: epoch 0023, iter [04900, 05004], lr: 0.100000, loss: 3.5569, stu_CELoss: 2.0872 DKDLoss: 1.4697 
2022-05-02 04:49:42 - train: epoch 0023, iter [05000, 05004], lr: 0.100000, loss: 3.8686, stu_CELoss: 2.3621 DKDLoss: 1.5065 
2022-05-02 04:49:43 - train: epoch 023, train_loss: 3.8054
2022-05-02 04:52:17 - eval: epoch: 023, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 50.884%, stu_acc5: 76.320%, stu_test_loss: 2.1248
2022-05-02 04:52:18 - until epoch: 023, tea_best_acc1: 73.944%, stu_best_acc1: 52.454%
2022-05-02 04:52:18 - epoch 024 lr: 0.1
2022-05-02 04:52:57 - train: epoch 0024, iter [00100, 05004], lr: 0.100000, loss: 3.9779, stu_CELoss: 2.5212 DKDLoss: 1.4566 
2022-05-02 04:53:32 - train: epoch 0024, iter [00200, 05004], lr: 0.100000, loss: 3.5966, stu_CELoss: 2.1602 DKDLoss: 1.4364 
2022-05-02 04:54:07 - train: epoch 0024, iter [00300, 05004], lr: 0.100000, loss: 3.8598, stu_CELoss: 2.2761 DKDLoss: 1.5837 
2022-05-02 04:54:43 - train: epoch 0024, iter [00400, 05004], lr: 0.100000, loss: 3.9973, stu_CELoss: 2.3911 DKDLoss: 1.6063 
2022-05-02 04:55:17 - train: epoch 0024, iter [00500, 05004], lr: 0.100000, loss: 3.8510, stu_CELoss: 2.3196 DKDLoss: 1.5313 
2022-05-02 04:55:51 - train: epoch 0024, iter [00600, 05004], lr: 0.100000, loss: 3.8364, stu_CELoss: 2.2718 DKDLoss: 1.5646 
2022-05-02 04:56:26 - train: epoch 0024, iter [00700, 05004], lr: 0.100000, loss: 3.5320, stu_CELoss: 2.0588 DKDLoss: 1.4732 
2022-05-02 04:57:00 - train: epoch 0024, iter [00800, 05004], lr: 0.100000, loss: 3.7559, stu_CELoss: 2.1274 DKDLoss: 1.6285 
2022-05-02 04:57:35 - train: epoch 0024, iter [00900, 05004], lr: 0.100000, loss: 3.7242, stu_CELoss: 2.1791 DKDLoss: 1.5452 
2022-05-02 04:58:10 - train: epoch 0024, iter [01000, 05004], lr: 0.100000, loss: 3.9445, stu_CELoss: 2.3417 DKDLoss: 1.6028 
2022-05-02 04:58:43 - train: epoch 0024, iter [01100, 05004], lr: 0.100000, loss: 3.5571, stu_CELoss: 2.0425 DKDLoss: 1.5146 
2022-05-02 04:59:19 - train: epoch 0024, iter [01200, 05004], lr: 0.100000, loss: 3.6586, stu_CELoss: 2.1946 DKDLoss: 1.4640 
2022-05-02 04:59:52 - train: epoch 0024, iter [01300, 05004], lr: 0.100000, loss: 4.0676, stu_CELoss: 2.4491 DKDLoss: 1.6185 
2022-05-02 05:00:28 - train: epoch 0024, iter [01400, 05004], lr: 0.100000, loss: 3.5763, stu_CELoss: 2.0295 DKDLoss: 1.5468 
2022-05-02 05:01:03 - train: epoch 0024, iter [01500, 05004], lr: 0.100000, loss: 3.8389, stu_CELoss: 2.3429 DKDLoss: 1.4960 
2022-05-02 05:01:37 - train: epoch 0024, iter [01600, 05004], lr: 0.100000, loss: 3.8365, stu_CELoss: 2.3104 DKDLoss: 1.5261 
2022-05-02 05:02:11 - train: epoch 0024, iter [01700, 05004], lr: 0.100000, loss: 3.8511, stu_CELoss: 2.2628 DKDLoss: 1.5883 
2022-05-02 05:02:46 - train: epoch 0024, iter [01800, 05004], lr: 0.100000, loss: 3.8653, stu_CELoss: 2.3798 DKDLoss: 1.4855 
2022-05-02 05:03:21 - train: epoch 0024, iter [01900, 05004], lr: 0.100000, loss: 3.6483, stu_CELoss: 2.2013 DKDLoss: 1.4471 
2022-05-02 05:03:55 - train: epoch 0024, iter [02000, 05004], lr: 0.100000, loss: 3.7959, stu_CELoss: 2.2721 DKDLoss: 1.5237 
2022-05-02 05:04:30 - train: epoch 0024, iter [02100, 05004], lr: 0.100000, loss: 3.5694, stu_CELoss: 2.1275 DKDLoss: 1.4419 
2022-05-02 05:05:07 - train: epoch 0024, iter [02200, 05004], lr: 0.100000, loss: 3.4455, stu_CELoss: 2.1411 DKDLoss: 1.3044 
2022-05-02 05:05:41 - train: epoch 0024, iter [02300, 05004], lr: 0.100000, loss: 3.8678, stu_CELoss: 2.3209 DKDLoss: 1.5469 
2022-05-02 05:06:16 - train: epoch 0024, iter [02400, 05004], lr: 0.100000, loss: 4.0343, stu_CELoss: 2.4685 DKDLoss: 1.5658 
2022-05-02 05:06:49 - train: epoch 0024, iter [02500, 05004], lr: 0.100000, loss: 3.5930, stu_CELoss: 2.1849 DKDLoss: 1.4081 
2022-05-02 05:07:24 - train: epoch 0024, iter [02600, 05004], lr: 0.100000, loss: 4.1090, stu_CELoss: 2.5533 DKDLoss: 1.5556 
2022-05-02 05:08:00 - train: epoch 0024, iter [02700, 05004], lr: 0.100000, loss: 3.9065, stu_CELoss: 2.4193 DKDLoss: 1.4872 
2022-05-02 05:08:34 - train: epoch 0024, iter [02800, 05004], lr: 0.100000, loss: 3.7586, stu_CELoss: 2.3981 DKDLoss: 1.3605 
2022-05-02 05:09:10 - train: epoch 0024, iter [02900, 05004], lr: 0.100000, loss: 3.8061, stu_CELoss: 2.2191 DKDLoss: 1.5870 
2022-05-02 05:09:44 - train: epoch 0024, iter [03000, 05004], lr: 0.100000, loss: 3.3434, stu_CELoss: 1.9490 DKDLoss: 1.3943 
2022-05-02 05:10:19 - train: epoch 0024, iter [03100, 05004], lr: 0.100000, loss: 3.4141, stu_CELoss: 1.9966 DKDLoss: 1.4175 
2022-05-02 05:10:53 - train: epoch 0024, iter [03200, 05004], lr: 0.100000, loss: 3.9596, stu_CELoss: 2.3619 DKDLoss: 1.5977 
2022-05-02 05:11:29 - train: epoch 0024, iter [03300, 05004], lr: 0.100000, loss: 3.6844, stu_CELoss: 2.1586 DKDLoss: 1.5257 
2022-05-02 05:12:03 - train: epoch 0024, iter [03400, 05004], lr: 0.100000, loss: 3.4850, stu_CELoss: 2.0723 DKDLoss: 1.4126 
2022-05-02 05:12:38 - train: epoch 0024, iter [03500, 05004], lr: 0.100000, loss: 3.8957, stu_CELoss: 2.3336 DKDLoss: 1.5622 
2022-05-02 05:13:13 - train: epoch 0024, iter [03600, 05004], lr: 0.100000, loss: 3.7491, stu_CELoss: 2.2545 DKDLoss: 1.4945 
2022-05-02 05:13:49 - train: epoch 0024, iter [03700, 05004], lr: 0.100000, loss: 3.4788, stu_CELoss: 2.1169 DKDLoss: 1.3619 
2022-05-02 05:14:24 - train: epoch 0024, iter [03800, 05004], lr: 0.100000, loss: 3.8753, stu_CELoss: 2.4113 DKDLoss: 1.4639 
2022-05-02 05:14:59 - train: epoch 0024, iter [03900, 05004], lr: 0.100000, loss: 3.4772, stu_CELoss: 2.0413 DKDLoss: 1.4359 
2022-05-02 05:15:33 - train: epoch 0024, iter [04000, 05004], lr: 0.100000, loss: 3.8232, stu_CELoss: 2.3340 DKDLoss: 1.4892 
2022-05-02 05:16:08 - train: epoch 0024, iter [04100, 05004], lr: 0.100000, loss: 3.9237, stu_CELoss: 2.2793 DKDLoss: 1.6443 
2022-05-02 05:16:43 - train: epoch 0024, iter [04200, 05004], lr: 0.100000, loss: 3.6918, stu_CELoss: 2.2325 DKDLoss: 1.4592 
2022-05-02 05:17:18 - train: epoch 0024, iter [04300, 05004], lr: 0.100000, loss: 3.5927, stu_CELoss: 2.1590 DKDLoss: 1.4338 
2022-05-02 05:17:53 - train: epoch 0024, iter [04400, 05004], lr: 0.100000, loss: 3.9489, stu_CELoss: 2.4076 DKDLoss: 1.5413 
2022-05-02 05:18:28 - train: epoch 0024, iter [04500, 05004], lr: 0.100000, loss: 3.5159, stu_CELoss: 2.0228 DKDLoss: 1.4931 
2022-05-02 05:19:03 - train: epoch 0024, iter [04600, 05004], lr: 0.100000, loss: 4.0431, stu_CELoss: 2.4839 DKDLoss: 1.5592 
2022-05-02 05:19:38 - train: epoch 0024, iter [04700, 05004], lr: 0.100000, loss: 3.7882, stu_CELoss: 2.2260 DKDLoss: 1.5622 
2022-05-02 05:20:13 - train: epoch 0024, iter [04800, 05004], lr: 0.100000, loss: 3.5593, stu_CELoss: 1.9987 DKDLoss: 1.5605 
2022-05-02 05:20:49 - train: epoch 0024, iter [04900, 05004], lr: 0.100000, loss: 3.9528, stu_CELoss: 2.4037 DKDLoss: 1.5491 
2022-05-02 05:21:21 - train: epoch 0024, iter [05000, 05004], lr: 0.100000, loss: 3.7867, stu_CELoss: 2.3010 DKDLoss: 1.4857 
2022-05-02 05:21:22 - train: epoch 024, train_loss: 3.8008
2022-05-02 05:23:55 - eval: epoch: 024, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 51.682%, stu_acc5: 77.212%, stu_test_loss: 2.0693
2022-05-02 05:23:55 - until epoch: 024, tea_best_acc1: 73.944%, stu_best_acc1: 52.454%
2022-05-02 05:23:55 - epoch 025 lr: 0.1
2022-05-02 05:24:35 - train: epoch 0025, iter [00100, 05004], lr: 0.100000, loss: 3.9019, stu_CELoss: 2.2748 DKDLoss: 1.6271 
2022-05-02 05:25:10 - train: epoch 0025, iter [00200, 05004], lr: 0.100000, loss: 3.3976, stu_CELoss: 1.9568 DKDLoss: 1.4408 
2022-05-02 05:25:44 - train: epoch 0025, iter [00300, 05004], lr: 0.100000, loss: 3.4779, stu_CELoss: 2.0811 DKDLoss: 1.3968 
2022-05-02 05:26:19 - train: epoch 0025, iter [00400, 05004], lr: 0.100000, loss: 4.0791, stu_CELoss: 2.4705 DKDLoss: 1.6086 
2022-05-02 05:26:53 - train: epoch 0025, iter [00500, 05004], lr: 0.100000, loss: 3.4557, stu_CELoss: 2.0920 DKDLoss: 1.3637 
2022-05-02 05:27:28 - train: epoch 0025, iter [00600, 05004], lr: 0.100000, loss: 3.8068, stu_CELoss: 2.2913 DKDLoss: 1.5154 
2022-05-02 05:28:03 - train: epoch 0025, iter [00700, 05004], lr: 0.100000, loss: 3.7999, stu_CELoss: 2.1841 DKDLoss: 1.6159 
2022-05-02 05:28:37 - train: epoch 0025, iter [00800, 05004], lr: 0.100000, loss: 3.7785, stu_CELoss: 2.1865 DKDLoss: 1.5919 
2022-05-02 05:29:12 - train: epoch 0025, iter [00900, 05004], lr: 0.100000, loss: 3.7030, stu_CELoss: 2.2081 DKDLoss: 1.4949 
2022-05-02 05:29:46 - train: epoch 0025, iter [01000, 05004], lr: 0.100000, loss: 3.5789, stu_CELoss: 2.2029 DKDLoss: 1.3759 
2022-05-02 05:30:21 - train: epoch 0025, iter [01100, 05004], lr: 0.100000, loss: 3.5989, stu_CELoss: 2.1684 DKDLoss: 1.4305 
2022-05-02 05:30:55 - train: epoch 0025, iter [01200, 05004], lr: 0.100000, loss: 3.8496, stu_CELoss: 2.3611 DKDLoss: 1.4885 
2022-05-02 05:31:30 - train: epoch 0025, iter [01300, 05004], lr: 0.100000, loss: 3.8004, stu_CELoss: 2.2384 DKDLoss: 1.5620 
2022-05-02 05:32:05 - train: epoch 0025, iter [01400, 05004], lr: 0.100000, loss: 3.7886, stu_CELoss: 2.1730 DKDLoss: 1.6156 
2022-05-02 05:32:41 - train: epoch 0025, iter [01500, 05004], lr: 0.100000, loss: 3.8356, stu_CELoss: 2.3904 DKDLoss: 1.4452 
2022-05-02 05:33:14 - train: epoch 0025, iter [01600, 05004], lr: 0.100000, loss: 3.6320, stu_CELoss: 2.1126 DKDLoss: 1.5194 
2022-05-02 05:33:49 - train: epoch 0025, iter [01700, 05004], lr: 0.100000, loss: 3.8715, stu_CELoss: 2.3261 DKDLoss: 1.5454 
2022-05-02 05:34:24 - train: epoch 0025, iter [01800, 05004], lr: 0.100000, loss: 3.8306, stu_CELoss: 2.1505 DKDLoss: 1.6801 
2022-05-02 05:34:59 - train: epoch 0025, iter [01900, 05004], lr: 0.100000, loss: 3.4619, stu_CELoss: 2.1059 DKDLoss: 1.3559 
2022-05-02 05:35:33 - train: epoch 0025, iter [02000, 05004], lr: 0.100000, loss: 3.7898, stu_CELoss: 2.2720 DKDLoss: 1.5178 
2022-05-02 05:36:10 - train: epoch 0025, iter [02100, 05004], lr: 0.100000, loss: 3.4153, stu_CELoss: 1.9163 DKDLoss: 1.4990 
2022-05-02 05:36:44 - train: epoch 0025, iter [02200, 05004], lr: 0.100000, loss: 3.7283, stu_CELoss: 2.2826 DKDLoss: 1.4457 
2022-05-02 05:37:18 - train: epoch 0025, iter [02300, 05004], lr: 0.100000, loss: 3.8217, stu_CELoss: 2.2050 DKDLoss: 1.6167 
2022-05-02 05:37:53 - train: epoch 0025, iter [02400, 05004], lr: 0.100000, loss: 3.6145, stu_CELoss: 2.1601 DKDLoss: 1.4544 
2022-05-02 05:38:28 - train: epoch 0025, iter [02500, 05004], lr: 0.100000, loss: 3.8762, stu_CELoss: 2.3536 DKDLoss: 1.5225 
2022-05-02 05:39:04 - train: epoch 0025, iter [02600, 05004], lr: 0.100000, loss: 3.8371, stu_CELoss: 2.2616 DKDLoss: 1.5755 
2022-05-02 05:39:39 - train: epoch 0025, iter [02700, 05004], lr: 0.100000, loss: 3.8697, stu_CELoss: 2.3537 DKDLoss: 1.5160 
2022-05-02 05:40:13 - train: epoch 0025, iter [02800, 05004], lr: 0.100000, loss: 3.8233, stu_CELoss: 2.3680 DKDLoss: 1.4553 
2022-05-02 05:40:49 - train: epoch 0025, iter [02900, 05004], lr: 0.100000, loss: 3.7877, stu_CELoss: 2.3285 DKDLoss: 1.4592 
2022-05-02 05:41:24 - train: epoch 0025, iter [03000, 05004], lr: 0.100000, loss: 4.1719, stu_CELoss: 2.3987 DKDLoss: 1.7732 
2022-05-02 05:41:58 - train: epoch 0025, iter [03100, 05004], lr: 0.100000, loss: 3.9425, stu_CELoss: 2.3633 DKDLoss: 1.5792 
2022-05-02 05:42:34 - train: epoch 0025, iter [03200, 05004], lr: 0.100000, loss: 3.8803, stu_CELoss: 2.3784 DKDLoss: 1.5020 
2022-05-02 05:43:08 - train: epoch 0025, iter [03300, 05004], lr: 0.100000, loss: 3.7520, stu_CELoss: 2.1599 DKDLoss: 1.5921 
2022-05-02 05:43:43 - train: epoch 0025, iter [03400, 05004], lr: 0.100000, loss: 3.8440, stu_CELoss: 2.3410 DKDLoss: 1.5030 
2022-05-02 05:44:18 - train: epoch 0025, iter [03500, 05004], lr: 0.100000, loss: 3.8308, stu_CELoss: 2.2911 DKDLoss: 1.5396 
2022-05-02 05:44:53 - train: epoch 0025, iter [03600, 05004], lr: 0.100000, loss: 4.0444, stu_CELoss: 2.4325 DKDLoss: 1.6119 
2022-05-02 05:45:27 - train: epoch 0025, iter [03700, 05004], lr: 0.100000, loss: 3.6061, stu_CELoss: 2.2000 DKDLoss: 1.4062 
2022-05-02 05:46:02 - train: epoch 0025, iter [03800, 05004], lr: 0.100000, loss: 4.0066, stu_CELoss: 2.4441 DKDLoss: 1.5625 
2022-05-02 05:46:37 - train: epoch 0025, iter [03900, 05004], lr: 0.100000, loss: 4.0899, stu_CELoss: 2.5394 DKDLoss: 1.5505 
2022-05-02 05:47:12 - train: epoch 0025, iter [04000, 05004], lr: 0.100000, loss: 3.8624, stu_CELoss: 2.3178 DKDLoss: 1.5446 
2022-05-02 05:47:46 - train: epoch 0025, iter [04100, 05004], lr: 0.100000, loss: 3.9116, stu_CELoss: 2.4380 DKDLoss: 1.4736 
2022-05-02 05:48:22 - train: epoch 0025, iter [04200, 05004], lr: 0.100000, loss: 3.7005, stu_CELoss: 2.2688 DKDLoss: 1.4317 
2022-05-02 05:48:56 - train: epoch 0025, iter [04300, 05004], lr: 0.100000, loss: 3.7388, stu_CELoss: 2.1505 DKDLoss: 1.5883 
2022-05-02 05:49:32 - train: epoch 0025, iter [04400, 05004], lr: 0.100000, loss: 3.8743, stu_CELoss: 2.3193 DKDLoss: 1.5550 
2022-05-02 05:50:06 - train: epoch 0025, iter [04500, 05004], lr: 0.100000, loss: 3.7639, stu_CELoss: 2.3107 DKDLoss: 1.4532 
2022-05-02 05:50:41 - train: epoch 0025, iter [04600, 05004], lr: 0.100000, loss: 3.6483, stu_CELoss: 2.2419 DKDLoss: 1.4063 
2022-05-02 05:51:16 - train: epoch 0025, iter [04700, 05004], lr: 0.100000, loss: 3.8637, stu_CELoss: 2.2883 DKDLoss: 1.5754 
2022-05-02 05:51:51 - train: epoch 0025, iter [04800, 05004], lr: 0.100000, loss: 3.4645, stu_CELoss: 2.0270 DKDLoss: 1.4375 
2022-05-02 05:52:26 - train: epoch 0025, iter [04900, 05004], lr: 0.100000, loss: 3.4951, stu_CELoss: 2.1452 DKDLoss: 1.3499 
2022-05-02 05:52:59 - train: epoch 0025, iter [05000, 05004], lr: 0.100000, loss: 4.0252, stu_CELoss: 2.5004 DKDLoss: 1.5248 
2022-05-02 05:53:00 - train: epoch 025, train_loss: 3.7933
2022-05-02 05:55:33 - eval: epoch: 025, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 51.624%, stu_acc5: 77.188%, stu_test_loss: 2.0852
2022-05-02 05:55:34 - until epoch: 025, tea_best_acc1: 73.944%, stu_best_acc1: 52.454%
2022-05-02 05:55:34 - epoch 026 lr: 0.1
2022-05-02 05:56:14 - train: epoch 0026, iter [00100, 05004], lr: 0.100000, loss: 3.6245, stu_CELoss: 2.1022 DKDLoss: 1.5223 
2022-05-02 05:56:49 - train: epoch 0026, iter [00200, 05004], lr: 0.100000, loss: 3.5937, stu_CELoss: 2.1368 DKDLoss: 1.4568 
2022-05-02 05:57:23 - train: epoch 0026, iter [00300, 05004], lr: 0.100000, loss: 3.8499, stu_CELoss: 2.3398 DKDLoss: 1.5101 
2022-05-02 05:57:58 - train: epoch 0026, iter [00400, 05004], lr: 0.100000, loss: 3.4116, stu_CELoss: 1.9572 DKDLoss: 1.4544 
2022-05-02 05:58:32 - train: epoch 0026, iter [00500, 05004], lr: 0.100000, loss: 3.7282, stu_CELoss: 2.2825 DKDLoss: 1.4457 
2022-05-02 05:59:06 - train: epoch 0026, iter [00600, 05004], lr: 0.100000, loss: 4.1413, stu_CELoss: 2.6205 DKDLoss: 1.5209 
2022-05-02 05:59:41 - train: epoch 0026, iter [00700, 05004], lr: 0.100000, loss: 3.6393, stu_CELoss: 2.2215 DKDLoss: 1.4178 
2022-05-02 06:00:15 - train: epoch 0026, iter [00800, 05004], lr: 0.100000, loss: 3.4533, stu_CELoss: 2.0032 DKDLoss: 1.4501 
2022-05-02 06:00:51 - train: epoch 0026, iter [00900, 05004], lr: 0.100000, loss: 4.2569, stu_CELoss: 2.7268 DKDLoss: 1.5301 
2022-05-02 06:01:25 - train: epoch 0026, iter [01000, 05004], lr: 0.100000, loss: 3.9442, stu_CELoss: 2.2813 DKDLoss: 1.6628 
2022-05-02 06:02:00 - train: epoch 0026, iter [01100, 05004], lr: 0.100000, loss: 3.7065, stu_CELoss: 2.1862 DKDLoss: 1.5203 
2022-05-02 06:02:35 - train: epoch 0026, iter [01200, 05004], lr: 0.100000, loss: 4.1109, stu_CELoss: 2.4936 DKDLoss: 1.6173 
2022-05-02 06:03:09 - train: epoch 0026, iter [01300, 05004], lr: 0.100000, loss: 3.6396, stu_CELoss: 2.1689 DKDLoss: 1.4707 
2022-05-02 06:03:44 - train: epoch 0026, iter [01400, 05004], lr: 0.100000, loss: 3.7863, stu_CELoss: 2.2717 DKDLoss: 1.5146 
2022-05-02 06:04:19 - train: epoch 0026, iter [01500, 05004], lr: 0.100000, loss: 3.4065, stu_CELoss: 2.0116 DKDLoss: 1.3950 
2022-05-02 06:04:54 - train: epoch 0026, iter [01600, 05004], lr: 0.100000, loss: 3.6108, stu_CELoss: 2.1809 DKDLoss: 1.4299 
2022-05-02 06:05:28 - train: epoch 0026, iter [01700, 05004], lr: 0.100000, loss: 3.7495, stu_CELoss: 2.2132 DKDLoss: 1.5363 
2022-05-02 06:06:04 - train: epoch 0026, iter [01800, 05004], lr: 0.100000, loss: 4.1383, stu_CELoss: 2.5851 DKDLoss: 1.5532 
2022-05-02 06:06:37 - train: epoch 0026, iter [01900, 05004], lr: 0.100000, loss: 4.0192, stu_CELoss: 2.4828 DKDLoss: 1.5365 
2022-05-02 06:07:12 - train: epoch 0026, iter [02000, 05004], lr: 0.100000, loss: 4.1484, stu_CELoss: 2.4727 DKDLoss: 1.6757 
2022-05-02 06:07:47 - train: epoch 0026, iter [02100, 05004], lr: 0.100000, loss: 3.6922, stu_CELoss: 2.1878 DKDLoss: 1.5044 
2022-05-02 06:08:23 - train: epoch 0026, iter [02200, 05004], lr: 0.100000, loss: 3.8080, stu_CELoss: 2.2742 DKDLoss: 1.5338 
2022-05-02 06:08:56 - train: epoch 0026, iter [02300, 05004], lr: 0.100000, loss: 3.8996, stu_CELoss: 2.3059 DKDLoss: 1.5937 
2022-05-02 06:09:33 - train: epoch 0026, iter [02400, 05004], lr: 0.100000, loss: 3.8810, stu_CELoss: 2.3528 DKDLoss: 1.5282 
2022-05-02 06:10:07 - train: epoch 0026, iter [02500, 05004], lr: 0.100000, loss: 3.9543, stu_CELoss: 2.4606 DKDLoss: 1.4937 
2022-05-02 06:10:41 - train: epoch 0026, iter [02600, 05004], lr: 0.100000, loss: 3.9138, stu_CELoss: 2.3897 DKDLoss: 1.5241 
2022-05-02 06:11:17 - train: epoch 0026, iter [02700, 05004], lr: 0.100000, loss: 4.0485, stu_CELoss: 2.5451 DKDLoss: 1.5034 
2022-05-02 06:11:51 - train: epoch 0026, iter [02800, 05004], lr: 0.100000, loss: 3.7490, stu_CELoss: 2.2351 DKDLoss: 1.5138 
2022-05-02 06:12:27 - train: epoch 0026, iter [02900, 05004], lr: 0.100000, loss: 3.9517, stu_CELoss: 2.3858 DKDLoss: 1.5658 
2022-05-02 06:13:01 - train: epoch 0026, iter [03000, 05004], lr: 0.100000, loss: 3.8751, stu_CELoss: 2.2915 DKDLoss: 1.5836 
2022-05-02 06:13:36 - train: epoch 0026, iter [03100, 05004], lr: 0.100000, loss: 4.0125, stu_CELoss: 2.4593 DKDLoss: 1.5533 
2022-05-02 06:14:11 - train: epoch 0026, iter [03200, 05004], lr: 0.100000, loss: 4.0448, stu_CELoss: 2.4454 DKDLoss: 1.5994 
2022-05-02 06:14:45 - train: epoch 0026, iter [03300, 05004], lr: 0.100000, loss: 3.6848, stu_CELoss: 2.1766 DKDLoss: 1.5082 
2022-05-02 06:15:19 - train: epoch 0026, iter [03400, 05004], lr: 0.100000, loss: 3.7666, stu_CELoss: 2.2294 DKDLoss: 1.5373 
2022-05-02 06:15:56 - train: epoch 0026, iter [03500, 05004], lr: 0.100000, loss: 3.6592, stu_CELoss: 2.3235 DKDLoss: 1.3357 
2022-05-02 06:16:30 - train: epoch 0026, iter [03600, 05004], lr: 0.100000, loss: 3.4318, stu_CELoss: 1.9892 DKDLoss: 1.4426 
2022-05-02 06:17:06 - train: epoch 0026, iter [03700, 05004], lr: 0.100000, loss: 3.6911, stu_CELoss: 2.2102 DKDLoss: 1.4809 
2022-05-02 06:17:41 - train: epoch 0026, iter [03800, 05004], lr: 0.100000, loss: 4.0539, stu_CELoss: 2.4389 DKDLoss: 1.6150 
2022-05-02 06:18:15 - train: epoch 0026, iter [03900, 05004], lr: 0.100000, loss: 3.8305, stu_CELoss: 2.3410 DKDLoss: 1.4895 
2022-05-02 06:18:50 - train: epoch 0026, iter [04000, 05004], lr: 0.100000, loss: 3.5203, stu_CELoss: 2.1627 DKDLoss: 1.3576 
2022-05-02 06:19:25 - train: epoch 0026, iter [04100, 05004], lr: 0.100000, loss: 3.8513, stu_CELoss: 2.2207 DKDLoss: 1.6306 
2022-05-02 06:20:01 - train: epoch 0026, iter [04200, 05004], lr: 0.100000, loss: 3.8231, stu_CELoss: 2.3073 DKDLoss: 1.5158 
2022-05-02 06:20:35 - train: epoch 0026, iter [04300, 05004], lr: 0.100000, loss: 3.9549, stu_CELoss: 2.4720 DKDLoss: 1.4829 
2022-05-02 06:21:11 - train: epoch 0026, iter [04400, 05004], lr: 0.100000, loss: 3.9382, stu_CELoss: 2.4101 DKDLoss: 1.5281 
2022-05-02 06:21:45 - train: epoch 0026, iter [04500, 05004], lr: 0.100000, loss: 4.0364, stu_CELoss: 2.6202 DKDLoss: 1.4162 
2022-05-02 06:22:22 - train: epoch 0026, iter [04600, 05004], lr: 0.100000, loss: 3.7809, stu_CELoss: 2.2605 DKDLoss: 1.5204 
2022-05-02 06:22:57 - train: epoch 0026, iter [04700, 05004], lr: 0.100000, loss: 3.6108, stu_CELoss: 2.0853 DKDLoss: 1.5255 
2022-05-02 06:23:32 - train: epoch 0026, iter [04800, 05004], lr: 0.100000, loss: 3.6536, stu_CELoss: 2.1869 DKDLoss: 1.4666 
2022-05-02 06:24:06 - train: epoch 0026, iter [04900, 05004], lr: 0.100000, loss: 3.8212, stu_CELoss: 2.2861 DKDLoss: 1.5350 
2022-05-02 06:24:39 - train: epoch 0026, iter [05000, 05004], lr: 0.100000, loss: 3.9411, stu_CELoss: 2.4249 DKDLoss: 1.5163 
2022-05-02 06:24:40 - train: epoch 026, train_loss: 3.7857
2022-05-02 06:27:14 - eval: epoch: 026, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 50.862%, stu_acc5: 76.634%, stu_test_loss: 2.1087
2022-05-02 06:27:14 - until epoch: 026, tea_best_acc1: 73.944%, stu_best_acc1: 52.454%
2022-05-02 06:27:14 - epoch 027 lr: 0.1
2022-05-02 06:27:54 - train: epoch 0027, iter [00100, 05004], lr: 0.100000, loss: 3.7944, stu_CELoss: 2.2693 DKDLoss: 1.5251 
2022-05-02 06:28:29 - train: epoch 0027, iter [00200, 05004], lr: 0.100000, loss: 3.5340, stu_CELoss: 2.1360 DKDLoss: 1.3981 
2022-05-02 06:29:03 - train: epoch 0027, iter [00300, 05004], lr: 0.100000, loss: 3.9544, stu_CELoss: 2.4517 DKDLoss: 1.5027 
2022-05-02 06:29:37 - train: epoch 0027, iter [00400, 05004], lr: 0.100000, loss: 3.8235, stu_CELoss: 2.3905 DKDLoss: 1.4330 
2022-05-02 06:30:11 - train: epoch 0027, iter [00500, 05004], lr: 0.100000, loss: 3.8905, stu_CELoss: 2.2766 DKDLoss: 1.6140 
2022-05-02 06:30:46 - train: epoch 0027, iter [00600, 05004], lr: 0.100000, loss: 3.7835, stu_CELoss: 2.3219 DKDLoss: 1.4616 
2022-05-02 06:31:19 - train: epoch 0027, iter [00700, 05004], lr: 0.100000, loss: 3.5599, stu_CELoss: 2.1920 DKDLoss: 1.3679 
2022-05-02 06:31:55 - train: epoch 0027, iter [00800, 05004], lr: 0.100000, loss: 3.8773, stu_CELoss: 2.3433 DKDLoss: 1.5340 
2022-05-02 06:32:28 - train: epoch 0027, iter [00900, 05004], lr: 0.100000, loss: 3.9299, stu_CELoss: 2.2814 DKDLoss: 1.6485 
2022-05-02 06:33:04 - train: epoch 0027, iter [01000, 05004], lr: 0.100000, loss: 3.7146, stu_CELoss: 2.1625 DKDLoss: 1.5522 
2022-05-02 06:33:40 - train: epoch 0027, iter [01100, 05004], lr: 0.100000, loss: 3.5180, stu_CELoss: 2.1243 DKDLoss: 1.3937 
2022-05-02 06:34:13 - train: epoch 0027, iter [01200, 05004], lr: 0.100000, loss: 3.9485, stu_CELoss: 2.3788 DKDLoss: 1.5697 
2022-05-02 06:34:49 - train: epoch 0027, iter [01300, 05004], lr: 0.100000, loss: 3.7630, stu_CELoss: 2.2168 DKDLoss: 1.5461 
2022-05-02 06:35:23 - train: epoch 0027, iter [01400, 05004], lr: 0.100000, loss: 4.0728, stu_CELoss: 2.4432 DKDLoss: 1.6296 
2022-05-02 06:35:58 - train: epoch 0027, iter [01500, 05004], lr: 0.100000, loss: 3.9288, stu_CELoss: 2.3989 DKDLoss: 1.5299 
2022-05-02 06:36:32 - train: epoch 0027, iter [01600, 05004], lr: 0.100000, loss: 3.7548, stu_CELoss: 2.2953 DKDLoss: 1.4595 
2022-05-02 06:37:06 - train: epoch 0027, iter [01700, 05004], lr: 0.100000, loss: 3.8066, stu_CELoss: 2.2625 DKDLoss: 1.5442 
2022-05-02 06:37:41 - train: epoch 0027, iter [01800, 05004], lr: 0.100000, loss: 3.7434, stu_CELoss: 2.0837 DKDLoss: 1.6597 
2022-05-02 06:38:16 - train: epoch 0027, iter [01900, 05004], lr: 0.100000, loss: 3.9585, stu_CELoss: 2.4016 DKDLoss: 1.5569 
2022-05-02 06:38:50 - train: epoch 0027, iter [02000, 05004], lr: 0.100000, loss: 3.4806, stu_CELoss: 2.1697 DKDLoss: 1.3109 
2022-05-02 06:39:26 - train: epoch 0027, iter [02100, 05004], lr: 0.100000, loss: 3.9745, stu_CELoss: 2.4605 DKDLoss: 1.5140 
2022-05-02 06:40:00 - train: epoch 0027, iter [02200, 05004], lr: 0.100000, loss: 4.1004, stu_CELoss: 2.4580 DKDLoss: 1.6424 
2022-05-02 06:40:35 - train: epoch 0027, iter [02300, 05004], lr: 0.100000, loss: 4.0914, stu_CELoss: 2.4976 DKDLoss: 1.5938 
2022-05-02 06:41:10 - train: epoch 0027, iter [02400, 05004], lr: 0.100000, loss: 3.5235, stu_CELoss: 2.1269 DKDLoss: 1.3966 
2022-05-02 06:41:44 - train: epoch 0027, iter [02500, 05004], lr: 0.100000, loss: 3.8200, stu_CELoss: 2.2311 DKDLoss: 1.5889 
2022-05-02 06:42:20 - train: epoch 0027, iter [02600, 05004], lr: 0.100000, loss: 3.6355, stu_CELoss: 2.2763 DKDLoss: 1.3592 
2022-05-02 06:42:55 - train: epoch 0027, iter [02700, 05004], lr: 0.100000, loss: 3.8606, stu_CELoss: 2.3154 DKDLoss: 1.5452 
2022-05-02 06:43:29 - train: epoch 0027, iter [02800, 05004], lr: 0.100000, loss: 3.7934, stu_CELoss: 2.3410 DKDLoss: 1.4524 
2022-05-02 06:44:04 - train: epoch 0027, iter [02900, 05004], lr: 0.100000, loss: 4.0513, stu_CELoss: 2.4282 DKDLoss: 1.6231 
2022-05-02 06:44:40 - train: epoch 0027, iter [03000, 05004], lr: 0.100000, loss: 3.6950, stu_CELoss: 2.2369 DKDLoss: 1.4580 
2022-05-02 06:45:14 - train: epoch 0027, iter [03100, 05004], lr: 0.100000, loss: 3.3941, stu_CELoss: 1.9962 DKDLoss: 1.3978 
2022-05-02 06:45:50 - train: epoch 0027, iter [03200, 05004], lr: 0.100000, loss: 3.6878, stu_CELoss: 2.0974 DKDLoss: 1.5904 
2022-05-02 06:46:24 - train: epoch 0027, iter [03300, 05004], lr: 0.100000, loss: 3.6196, stu_CELoss: 2.1920 DKDLoss: 1.4276 
2022-05-02 06:46:59 - train: epoch 0027, iter [03400, 05004], lr: 0.100000, loss: 3.7817, stu_CELoss: 2.1632 DKDLoss: 1.6186 
2022-05-02 06:47:34 - train: epoch 0027, iter [03500, 05004], lr: 0.100000, loss: 3.8946, stu_CELoss: 2.4076 DKDLoss: 1.4870 
2022-05-02 06:48:10 - train: epoch 0027, iter [03600, 05004], lr: 0.100000, loss: 3.7046, stu_CELoss: 2.2753 DKDLoss: 1.4292 
2022-05-02 06:48:44 - train: epoch 0027, iter [03700, 05004], lr: 0.100000, loss: 4.0394, stu_CELoss: 2.3978 DKDLoss: 1.6415 
2022-05-02 06:49:19 - train: epoch 0027, iter [03800, 05004], lr: 0.100000, loss: 3.3976, stu_CELoss: 1.9261 DKDLoss: 1.4715 
2022-05-02 06:49:54 - train: epoch 0027, iter [03900, 05004], lr: 0.100000, loss: 3.6628, stu_CELoss: 2.2266 DKDLoss: 1.4362 
2022-05-02 06:50:30 - train: epoch 0027, iter [04000, 05004], lr: 0.100000, loss: 4.0643, stu_CELoss: 2.4494 DKDLoss: 1.6150 
2022-05-02 06:51:04 - train: epoch 0027, iter [04100, 05004], lr: 0.100000, loss: 3.8114, stu_CELoss: 2.3514 DKDLoss: 1.4600 
2022-05-02 06:51:40 - train: epoch 0027, iter [04200, 05004], lr: 0.100000, loss: 3.7656, stu_CELoss: 2.2726 DKDLoss: 1.4930 
2022-05-02 06:52:15 - train: epoch 0027, iter [04300, 05004], lr: 0.100000, loss: 3.5881, stu_CELoss: 2.1283 DKDLoss: 1.4598 
2022-05-02 06:52:50 - train: epoch 0027, iter [04400, 05004], lr: 0.100000, loss: 3.9260, stu_CELoss: 2.3630 DKDLoss: 1.5629 
2022-05-02 06:53:24 - train: epoch 0027, iter [04500, 05004], lr: 0.100000, loss: 3.7617, stu_CELoss: 2.2553 DKDLoss: 1.5065 
2022-05-02 06:54:00 - train: epoch 0027, iter [04600, 05004], lr: 0.100000, loss: 3.6201, stu_CELoss: 2.1651 DKDLoss: 1.4550 
2022-05-02 06:54:34 - train: epoch 0027, iter [04700, 05004], lr: 0.100000, loss: 4.0032, stu_CELoss: 2.4735 DKDLoss: 1.5298 
2022-05-02 06:55:10 - train: epoch 0027, iter [04800, 05004], lr: 0.100000, loss: 4.1065, stu_CELoss: 2.4986 DKDLoss: 1.6079 
2022-05-02 06:55:44 - train: epoch 0027, iter [04900, 05004], lr: 0.100000, loss: 3.4338, stu_CELoss: 2.1502 DKDLoss: 1.2837 
2022-05-02 06:56:18 - train: epoch 0027, iter [05000, 05004], lr: 0.100000, loss: 3.6231, stu_CELoss: 2.1667 DKDLoss: 1.4564 
2022-05-02 06:56:18 - train: epoch 027, train_loss: 3.7741
2022-05-02 06:58:52 - eval: epoch: 027, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 53.152%, stu_acc5: 78.224%, stu_test_loss: 2.0185
2022-05-02 06:58:53 - until epoch: 027, tea_best_acc1: 73.944%, stu_best_acc1: 53.152%
2022-05-02 06:58:53 - epoch 028 lr: 0.1
2022-05-02 06:59:33 - train: epoch 0028, iter [00100, 05004], lr: 0.100000, loss: 3.3732, stu_CELoss: 1.9908 DKDLoss: 1.3824 
2022-05-02 07:00:07 - train: epoch 0028, iter [00200, 05004], lr: 0.100000, loss: 3.7892, stu_CELoss: 2.2746 DKDLoss: 1.5146 
2022-05-02 07:00:42 - train: epoch 0028, iter [00300, 05004], lr: 0.100000, loss: 3.9173, stu_CELoss: 2.3830 DKDLoss: 1.5343 
2022-05-02 07:01:16 - train: epoch 0028, iter [00400, 05004], lr: 0.100000, loss: 3.8772, stu_CELoss: 2.3028 DKDLoss: 1.5743 
2022-05-02 07:01:51 - train: epoch 0028, iter [00500, 05004], lr: 0.100000, loss: 3.8009, stu_CELoss: 2.2172 DKDLoss: 1.5837 
2022-05-02 07:02:26 - train: epoch 0028, iter [00600, 05004], lr: 0.100000, loss: 3.8505, stu_CELoss: 2.3827 DKDLoss: 1.4678 
2022-05-02 07:03:00 - train: epoch 0028, iter [00700, 05004], lr: 0.100000, loss: 3.9625, stu_CELoss: 2.3923 DKDLoss: 1.5702 
2022-05-02 07:03:34 - train: epoch 0028, iter [00800, 05004], lr: 0.100000, loss: 3.5738, stu_CELoss: 2.0635 DKDLoss: 1.5103 
2022-05-02 07:04:09 - train: epoch 0028, iter [00900, 05004], lr: 0.100000, loss: 3.5812, stu_CELoss: 2.1593 DKDLoss: 1.4218 
2022-05-02 07:04:43 - train: epoch 0028, iter [01000, 05004], lr: 0.100000, loss: 3.9481, stu_CELoss: 2.3804 DKDLoss: 1.5677 
2022-05-02 07:05:18 - train: epoch 0028, iter [01100, 05004], lr: 0.100000, loss: 3.5647, stu_CELoss: 2.1204 DKDLoss: 1.4444 
2022-05-02 07:05:53 - train: epoch 0028, iter [01200, 05004], lr: 0.100000, loss: 3.8360, stu_CELoss: 2.2478 DKDLoss: 1.5882 
2022-05-02 07:06:28 - train: epoch 0028, iter [01300, 05004], lr: 0.100000, loss: 3.9822, stu_CELoss: 2.3998 DKDLoss: 1.5824 
2022-05-02 07:07:03 - train: epoch 0028, iter [01400, 05004], lr: 0.100000, loss: 4.0233, stu_CELoss: 2.4234 DKDLoss: 1.6000 
2022-05-02 07:07:38 - train: epoch 0028, iter [01500, 05004], lr: 0.100000, loss: 3.7574, stu_CELoss: 2.2913 DKDLoss: 1.4660 
2022-05-02 07:08:12 - train: epoch 0028, iter [01600, 05004], lr: 0.100000, loss: 3.9202, stu_CELoss: 2.2620 DKDLoss: 1.6582 
2022-05-02 07:08:47 - train: epoch 0028, iter [01700, 05004], lr: 0.100000, loss: 3.8801, stu_CELoss: 2.3719 DKDLoss: 1.5082 
2022-05-02 07:09:22 - train: epoch 0028, iter [01800, 05004], lr: 0.100000, loss: 3.6166, stu_CELoss: 2.1510 DKDLoss: 1.4656 
2022-05-02 07:09:55 - train: epoch 0028, iter [01900, 05004], lr: 0.100000, loss: 3.9553, stu_CELoss: 2.2989 DKDLoss: 1.6564 
2022-05-02 07:10:31 - train: epoch 0028, iter [02000, 05004], lr: 0.100000, loss: 3.8140, stu_CELoss: 2.3270 DKDLoss: 1.4870 
2022-05-02 07:11:06 - train: epoch 0028, iter [02100, 05004], lr: 0.100000, loss: 4.0100, stu_CELoss: 2.5050 DKDLoss: 1.5051 
2022-05-02 07:11:40 - train: epoch 0028, iter [02200, 05004], lr: 0.100000, loss: 3.8404, stu_CELoss: 2.3536 DKDLoss: 1.4868 
2022-05-02 07:12:15 - train: epoch 0028, iter [02300, 05004], lr: 0.100000, loss: 3.8595, stu_CELoss: 2.2632 DKDLoss: 1.5963 
2022-05-02 07:12:50 - train: epoch 0028, iter [02400, 05004], lr: 0.100000, loss: 3.8848, stu_CELoss: 2.2895 DKDLoss: 1.5952 
2022-05-02 07:13:25 - train: epoch 0028, iter [02500, 05004], lr: 0.100000, loss: 4.0479, stu_CELoss: 2.3907 DKDLoss: 1.6572 
2022-05-02 07:13:59 - train: epoch 0028, iter [02600, 05004], lr: 0.100000, loss: 3.7977, stu_CELoss: 2.2705 DKDLoss: 1.5271 
2022-05-02 07:14:34 - train: epoch 0028, iter [02700, 05004], lr: 0.100000, loss: 3.7566, stu_CELoss: 2.1989 DKDLoss: 1.5577 
2022-05-02 07:15:09 - train: epoch 0028, iter [02800, 05004], lr: 0.100000, loss: 3.8298, stu_CELoss: 2.4118 DKDLoss: 1.4181 
2022-05-02 07:15:45 - train: epoch 0028, iter [02900, 05004], lr: 0.100000, loss: 3.7235, stu_CELoss: 2.3433 DKDLoss: 1.3803 
2022-05-02 07:16:18 - train: epoch 0028, iter [03000, 05004], lr: 0.100000, loss: 3.4887, stu_CELoss: 2.1744 DKDLoss: 1.3144 
2022-05-02 07:16:54 - train: epoch 0028, iter [03100, 05004], lr: 0.100000, loss: 3.7551, stu_CELoss: 2.2583 DKDLoss: 1.4968 
2022-05-02 07:17:28 - train: epoch 0028, iter [03200, 05004], lr: 0.100000, loss: 3.5116, stu_CELoss: 2.0563 DKDLoss: 1.4553 
2022-05-02 07:18:04 - train: epoch 0028, iter [03300, 05004], lr: 0.100000, loss: 3.8102, stu_CELoss: 2.2929 DKDLoss: 1.5173 
2022-05-02 07:18:39 - train: epoch 0028, iter [03400, 05004], lr: 0.100000, loss: 4.0071, stu_CELoss: 2.4487 DKDLoss: 1.5584 
2022-05-02 07:19:14 - train: epoch 0028, iter [03500, 05004], lr: 0.100000, loss: 3.8166, stu_CELoss: 2.2256 DKDLoss: 1.5910 
2022-05-02 07:19:48 - train: epoch 0028, iter [03600, 05004], lr: 0.100000, loss: 3.7878, stu_CELoss: 2.2510 DKDLoss: 1.5368 
2022-05-02 07:20:22 - train: epoch 0028, iter [03700, 05004], lr: 0.100000, loss: 3.8575, stu_CELoss: 2.2792 DKDLoss: 1.5784 
2022-05-02 07:20:58 - train: epoch 0028, iter [03800, 05004], lr: 0.100000, loss: 3.4624, stu_CELoss: 1.9236 DKDLoss: 1.5388 
2022-05-02 07:21:33 - train: epoch 0028, iter [03900, 05004], lr: 0.100000, loss: 4.1422, stu_CELoss: 2.5779 DKDLoss: 1.5643 
2022-05-02 07:22:07 - train: epoch 0028, iter [04000, 05004], lr: 0.100000, loss: 3.7923, stu_CELoss: 2.3343 DKDLoss: 1.4580 
2022-05-02 07:22:42 - train: epoch 0028, iter [04100, 05004], lr: 0.100000, loss: 3.8065, stu_CELoss: 2.3194 DKDLoss: 1.4871 
2022-05-02 07:23:17 - train: epoch 0028, iter [04200, 05004], lr: 0.100000, loss: 3.8378, stu_CELoss: 2.2953 DKDLoss: 1.5425 
2022-05-02 07:23:51 - train: epoch 0028, iter [04300, 05004], lr: 0.100000, loss: 3.8011, stu_CELoss: 2.3037 DKDLoss: 1.4974 
2022-05-02 07:24:27 - train: epoch 0028, iter [04400, 05004], lr: 0.100000, loss: 3.6123, stu_CELoss: 2.1586 DKDLoss: 1.4538 
2022-05-02 07:25:03 - train: epoch 0028, iter [04500, 05004], lr: 0.100000, loss: 4.0326, stu_CELoss: 2.4260 DKDLoss: 1.6066 
2022-05-02 07:25:36 - train: epoch 0028, iter [04600, 05004], lr: 0.100000, loss: 3.6161, stu_CELoss: 2.2283 DKDLoss: 1.3878 
2022-05-02 07:26:13 - train: epoch 0028, iter [04700, 05004], lr: 0.100000, loss: 3.8963, stu_CELoss: 2.4526 DKDLoss: 1.4437 
2022-05-02 07:26:47 - train: epoch 0028, iter [04800, 05004], lr: 0.100000, loss: 3.6015, stu_CELoss: 2.1431 DKDLoss: 1.4583 
2022-05-02 07:27:22 - train: epoch 0028, iter [04900, 05004], lr: 0.100000, loss: 3.8615, stu_CELoss: 2.3062 DKDLoss: 1.5553 
2022-05-02 07:27:55 - train: epoch 0028, iter [05000, 05004], lr: 0.100000, loss: 3.6185, stu_CELoss: 2.1836 DKDLoss: 1.4349 
2022-05-02 07:27:56 - train: epoch 028, train_loss: 3.7722
2022-05-02 07:30:29 - eval: epoch: 028, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 52.468%, stu_acc5: 77.750%, stu_test_loss: 2.0444
2022-05-02 07:30:29 - until epoch: 028, tea_best_acc1: 73.944%, stu_best_acc1: 53.152%
2022-05-02 07:30:29 - epoch 029 lr: 0.1
2022-05-02 07:31:09 - train: epoch 0029, iter [00100, 05004], lr: 0.100000, loss: 3.7669, stu_CELoss: 2.2491 DKDLoss: 1.5178 
2022-05-02 07:31:44 - train: epoch 0029, iter [00200, 05004], lr: 0.100000, loss: 3.7020, stu_CELoss: 2.1659 DKDLoss: 1.5361 
2022-05-02 07:32:19 - train: epoch 0029, iter [00300, 05004], lr: 0.100000, loss: 3.9458, stu_CELoss: 2.4932 DKDLoss: 1.4526 
2022-05-02 07:32:53 - train: epoch 0029, iter [00400, 05004], lr: 0.100000, loss: 4.2363, stu_CELoss: 2.4710 DKDLoss: 1.7653 
2022-05-02 07:33:28 - train: epoch 0029, iter [00500, 05004], lr: 0.100000, loss: 3.8986, stu_CELoss: 2.4281 DKDLoss: 1.4705 
2022-05-02 07:34:02 - train: epoch 0029, iter [00600, 05004], lr: 0.100000, loss: 3.9179, stu_CELoss: 2.3845 DKDLoss: 1.5334 
2022-05-02 07:34:37 - train: epoch 0029, iter [00700, 05004], lr: 0.100000, loss: 3.3602, stu_CELoss: 1.8848 DKDLoss: 1.4753 
2022-05-02 07:35:11 - train: epoch 0029, iter [00800, 05004], lr: 0.100000, loss: 3.9719, stu_CELoss: 2.3692 DKDLoss: 1.6027 
2022-05-02 07:35:46 - train: epoch 0029, iter [00900, 05004], lr: 0.100000, loss: 3.8302, stu_CELoss: 2.3099 DKDLoss: 1.5202 
2022-05-02 07:36:22 - train: epoch 0029, iter [01000, 05004], lr: 0.100000, loss: 3.6405, stu_CELoss: 2.2248 DKDLoss: 1.4157 
2022-05-02 07:36:55 - train: epoch 0029, iter [01100, 05004], lr: 0.100000, loss: 3.6325, stu_CELoss: 2.2112 DKDLoss: 1.4213 
2022-05-02 07:37:30 - train: epoch 0029, iter [01200, 05004], lr: 0.100000, loss: 4.0451, stu_CELoss: 2.4454 DKDLoss: 1.5997 
2022-05-02 07:38:04 - train: epoch 0029, iter [01300, 05004], lr: 0.100000, loss: 3.5328, stu_CELoss: 2.1953 DKDLoss: 1.3376 
2022-05-02 07:38:39 - train: epoch 0029, iter [01400, 05004], lr: 0.100000, loss: 3.9678, stu_CELoss: 2.3206 DKDLoss: 1.6472 
2022-05-02 07:39:14 - train: epoch 0029, iter [01500, 05004], lr: 0.100000, loss: 3.6366, stu_CELoss: 2.2324 DKDLoss: 1.4041 
2022-05-02 07:39:48 - train: epoch 0029, iter [01600, 05004], lr: 0.100000, loss: 3.7735, stu_CELoss: 2.2161 DKDLoss: 1.5574 
2022-05-02 07:40:24 - train: epoch 0029, iter [01700, 05004], lr: 0.100000, loss: 3.7088, stu_CELoss: 2.1392 DKDLoss: 1.5696 
2022-05-02 07:40:58 - train: epoch 0029, iter [01800, 05004], lr: 0.100000, loss: 3.9273, stu_CELoss: 2.3886 DKDLoss: 1.5387 
2022-05-02 07:41:33 - train: epoch 0029, iter [01900, 05004], lr: 0.100000, loss: 3.6980, stu_CELoss: 2.2013 DKDLoss: 1.4967 
2022-05-02 07:42:07 - train: epoch 0029, iter [02000, 05004], lr: 0.100000, loss: 3.6850, stu_CELoss: 2.1691 DKDLoss: 1.5159 
2022-05-02 07:42:44 - train: epoch 0029, iter [02100, 05004], lr: 0.100000, loss: 3.6897, stu_CELoss: 2.2393 DKDLoss: 1.4504 
2022-05-02 07:43:18 - train: epoch 0029, iter [02200, 05004], lr: 0.100000, loss: 3.8094, stu_CELoss: 2.3110 DKDLoss: 1.4984 
2022-05-02 07:43:53 - train: epoch 0029, iter [02300, 05004], lr: 0.100000, loss: 3.5551, stu_CELoss: 2.1744 DKDLoss: 1.3807 
2022-05-02 07:44:28 - train: epoch 0029, iter [02400, 05004], lr: 0.100000, loss: 3.7303, stu_CELoss: 2.1841 DKDLoss: 1.5462 
2022-05-02 07:45:04 - train: epoch 0029, iter [02500, 05004], lr: 0.100000, loss: 3.5715, stu_CELoss: 2.2229 DKDLoss: 1.3486 
2022-05-02 07:45:39 - train: epoch 0029, iter [02600, 05004], lr: 0.100000, loss: 3.9518, stu_CELoss: 2.3292 DKDLoss: 1.6226 
2022-05-02 07:46:13 - train: epoch 0029, iter [02700, 05004], lr: 0.100000, loss: 3.8097, stu_CELoss: 2.3151 DKDLoss: 1.4947 
2022-05-02 07:46:48 - train: epoch 0029, iter [02800, 05004], lr: 0.100000, loss: 3.7489, stu_CELoss: 2.1976 DKDLoss: 1.5513 
2022-05-02 07:47:23 - train: epoch 0029, iter [02900, 05004], lr: 0.100000, loss: 3.6565, stu_CELoss: 2.2549 DKDLoss: 1.4016 
2022-05-02 07:47:59 - train: epoch 0029, iter [03000, 05004], lr: 0.100000, loss: 3.8370, stu_CELoss: 2.3525 DKDLoss: 1.4845 
2022-05-02 07:48:35 - train: epoch 0029, iter [03100, 05004], lr: 0.100000, loss: 3.8099, stu_CELoss: 2.2664 DKDLoss: 1.5435 
2022-05-02 07:49:09 - train: epoch 0029, iter [03200, 05004], lr: 0.100000, loss: 3.7752, stu_CELoss: 2.2850 DKDLoss: 1.4902 
2022-05-02 07:49:44 - train: epoch 0029, iter [03300, 05004], lr: 0.100000, loss: 3.4430, stu_CELoss: 2.0840 DKDLoss: 1.3590 
2022-05-02 07:50:19 - train: epoch 0029, iter [03400, 05004], lr: 0.100000, loss: 3.7426, stu_CELoss: 2.1974 DKDLoss: 1.5452 
2022-05-02 07:50:55 - train: epoch 0029, iter [03500, 05004], lr: 0.100000, loss: 3.8231, stu_CELoss: 2.2937 DKDLoss: 1.5294 
2022-05-02 07:51:30 - train: epoch 0029, iter [03600, 05004], lr: 0.100000, loss: 3.7551, stu_CELoss: 2.1944 DKDLoss: 1.5607 
2022-05-02 07:52:04 - train: epoch 0029, iter [03700, 05004], lr: 0.100000, loss: 3.5971, stu_CELoss: 2.1104 DKDLoss: 1.4867 
2022-05-02 07:52:39 - train: epoch 0029, iter [03800, 05004], lr: 0.100000, loss: 3.6425, stu_CELoss: 2.1649 DKDLoss: 1.4776 
2022-05-02 07:53:14 - train: epoch 0029, iter [03900, 05004], lr: 0.100000, loss: 3.7038, stu_CELoss: 2.2242 DKDLoss: 1.4795 
2022-05-02 07:53:49 - train: epoch 0029, iter [04000, 05004], lr: 0.100000, loss: 3.6942, stu_CELoss: 2.2142 DKDLoss: 1.4800 
2022-05-02 07:54:24 - train: epoch 0029, iter [04100, 05004], lr: 0.100000, loss: 3.9521, stu_CELoss: 2.3529 DKDLoss: 1.5992 
2022-05-02 07:54:59 - train: epoch 0029, iter [04200, 05004], lr: 0.100000, loss: 3.8060, stu_CELoss: 2.2326 DKDLoss: 1.5735 
2022-05-02 07:55:34 - train: epoch 0029, iter [04300, 05004], lr: 0.100000, loss: 3.9371, stu_CELoss: 2.4496 DKDLoss: 1.4875 
2022-05-02 07:56:10 - train: epoch 0029, iter [04400, 05004], lr: 0.100000, loss: 3.7815, stu_CELoss: 2.2829 DKDLoss: 1.4986 
2022-05-02 07:56:45 - train: epoch 0029, iter [04500, 05004], lr: 0.100000, loss: 4.0711, stu_CELoss: 2.5348 DKDLoss: 1.5363 
2022-05-02 07:57:20 - train: epoch 0029, iter [04600, 05004], lr: 0.100000, loss: 3.9936, stu_CELoss: 2.3584 DKDLoss: 1.6352 
2022-05-02 07:57:55 - train: epoch 0029, iter [04700, 05004], lr: 0.100000, loss: 3.5461, stu_CELoss: 2.0351 DKDLoss: 1.5110 
2022-05-02 07:58:29 - train: epoch 0029, iter [04800, 05004], lr: 0.100000, loss: 3.7001, stu_CELoss: 2.1627 DKDLoss: 1.5374 
2022-05-02 07:59:05 - train: epoch 0029, iter [04900, 05004], lr: 0.100000, loss: 3.8815, stu_CELoss: 2.3693 DKDLoss: 1.5122 
2022-05-02 07:59:38 - train: epoch 0029, iter [05000, 05004], lr: 0.100000, loss: 3.4198, stu_CELoss: 2.0037 DKDLoss: 1.4160 
2022-05-02 07:59:39 - train: epoch 029, train_loss: 3.7681
2022-05-02 08:02:13 - eval: epoch: 029, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 52.738%, stu_acc5: 78.284%, stu_test_loss: 2.0100
2022-05-02 08:02:13 - until epoch: 029, tea_best_acc1: 73.944%, stu_best_acc1: 53.152%
2022-05-02 08:02:13 - epoch 030 lr: 0.1
2022-05-02 08:02:53 - train: epoch 0030, iter [00100, 05004], lr: 0.100000, loss: 3.7386, stu_CELoss: 2.2956 DKDLoss: 1.4430 
2022-05-02 08:03:28 - train: epoch 0030, iter [00200, 05004], lr: 0.100000, loss: 3.8922, stu_CELoss: 2.2396 DKDLoss: 1.6525 
2022-05-02 08:04:02 - train: epoch 0030, iter [00300, 05004], lr: 0.100000, loss: 3.4472, stu_CELoss: 1.9857 DKDLoss: 1.4615 
2022-05-02 08:04:37 - train: epoch 0030, iter [00400, 05004], lr: 0.100000, loss: 3.7482, stu_CELoss: 2.2655 DKDLoss: 1.4827 
2022-05-02 08:05:11 - train: epoch 0030, iter [00500, 05004], lr: 0.100000, loss: 3.8203, stu_CELoss: 2.2914 DKDLoss: 1.5288 
2022-05-02 08:05:45 - train: epoch 0030, iter [00600, 05004], lr: 0.100000, loss: 3.6747, stu_CELoss: 2.1702 DKDLoss: 1.5045 
2022-05-02 08:06:21 - train: epoch 0030, iter [00700, 05004], lr: 0.100000, loss: 3.6340, stu_CELoss: 2.1538 DKDLoss: 1.4802 
2022-05-02 08:06:55 - train: epoch 0030, iter [00800, 05004], lr: 0.100000, loss: 3.7752, stu_CELoss: 2.2755 DKDLoss: 1.4997 
2022-05-02 08:07:29 - train: epoch 0030, iter [00900, 05004], lr: 0.100000, loss: 3.8117, stu_CELoss: 2.3060 DKDLoss: 1.5057 
2022-05-02 08:08:04 - train: epoch 0030, iter [01000, 05004], lr: 0.100000, loss: 3.4931, stu_CELoss: 2.0438 DKDLoss: 1.4493 
2022-05-02 08:08:38 - train: epoch 0030, iter [01100, 05004], lr: 0.100000, loss: 3.5953, stu_CELoss: 2.1343 DKDLoss: 1.4610 
2022-05-02 08:09:12 - train: epoch 0030, iter [01200, 05004], lr: 0.100000, loss: 3.7994, stu_CELoss: 2.3332 DKDLoss: 1.4662 
2022-05-02 08:09:46 - train: epoch 0030, iter [01300, 05004], lr: 0.100000, loss: 3.6067, stu_CELoss: 2.1661 DKDLoss: 1.4407 
2022-05-02 08:10:20 - train: epoch 0030, iter [01400, 05004], lr: 0.100000, loss: 3.4913, stu_CELoss: 2.0415 DKDLoss: 1.4498 
2022-05-02 08:10:55 - train: epoch 0030, iter [01500, 05004], lr: 0.100000, loss: 3.6800, stu_CELoss: 2.1755 DKDLoss: 1.5045 
2022-05-02 08:11:30 - train: epoch 0030, iter [01600, 05004], lr: 0.100000, loss: 3.8322, stu_CELoss: 2.2545 DKDLoss: 1.5777 
2022-05-02 08:12:04 - train: epoch 0030, iter [01700, 05004], lr: 0.100000, loss: 3.8218, stu_CELoss: 2.3867 DKDLoss: 1.4351 
2022-05-02 08:12:39 - train: epoch 0030, iter [01800, 05004], lr: 0.100000, loss: 3.8534, stu_CELoss: 2.3126 DKDLoss: 1.5408 
2022-05-02 08:13:14 - train: epoch 0030, iter [01900, 05004], lr: 0.100000, loss: 3.5883, stu_CELoss: 2.1953 DKDLoss: 1.3929 
2022-05-02 08:13:49 - train: epoch 0030, iter [02000, 05004], lr: 0.100000, loss: 3.7399, stu_CELoss: 2.2702 DKDLoss: 1.4697 
2022-05-02 08:14:23 - train: epoch 0030, iter [02100, 05004], lr: 0.100000, loss: 3.8501, stu_CELoss: 2.3826 DKDLoss: 1.4675 
2022-05-02 08:14:58 - train: epoch 0030, iter [02200, 05004], lr: 0.100000, loss: 3.9276, stu_CELoss: 2.3573 DKDLoss: 1.5703 
2022-05-02 08:15:33 - train: epoch 0030, iter [02300, 05004], lr: 0.100000, loss: 3.9426, stu_CELoss: 2.2497 DKDLoss: 1.6929 
2022-05-02 08:16:08 - train: epoch 0030, iter [02400, 05004], lr: 0.100000, loss: 3.9035, stu_CELoss: 2.3705 DKDLoss: 1.5330 
2022-05-02 08:16:42 - train: epoch 0030, iter [02500, 05004], lr: 0.100000, loss: 4.0126, stu_CELoss: 2.4429 DKDLoss: 1.5697 
2022-05-02 08:17:18 - train: epoch 0030, iter [02600, 05004], lr: 0.100000, loss: 3.6583, stu_CELoss: 2.2072 DKDLoss: 1.4511 
2022-05-02 08:17:52 - train: epoch 0030, iter [02700, 05004], lr: 0.100000, loss: 3.5418, stu_CELoss: 2.0753 DKDLoss: 1.4665 
2022-05-02 08:18:28 - train: epoch 0030, iter [02800, 05004], lr: 0.100000, loss: 3.5655, stu_CELoss: 2.1995 DKDLoss: 1.3660 
2022-05-02 08:19:02 - train: epoch 0030, iter [02900, 05004], lr: 0.100000, loss: 3.5957, stu_CELoss: 2.0766 DKDLoss: 1.5191 
2022-05-02 08:19:37 - train: epoch 0030, iter [03000, 05004], lr: 0.100000, loss: 4.0516, stu_CELoss: 2.4295 DKDLoss: 1.6222 
2022-05-02 08:20:13 - train: epoch 0030, iter [03100, 05004], lr: 0.100000, loss: 3.8827, stu_CELoss: 2.2977 DKDLoss: 1.5849 
2022-05-02 08:20:48 - train: epoch 0030, iter [03200, 05004], lr: 0.100000, loss: 3.6785, stu_CELoss: 2.0774 DKDLoss: 1.6011 
2022-05-02 08:21:22 - train: epoch 0030, iter [03300, 05004], lr: 0.100000, loss: 3.9074, stu_CELoss: 2.3639 DKDLoss: 1.5435 
2022-05-02 08:21:56 - train: epoch 0030, iter [03400, 05004], lr: 0.100000, loss: 3.5404, stu_CELoss: 2.0264 DKDLoss: 1.5140 
2022-05-02 08:22:32 - train: epoch 0030, iter [03500, 05004], lr: 0.100000, loss: 3.6863, stu_CELoss: 2.3321 DKDLoss: 1.3541 
2022-05-02 08:23:06 - train: epoch 0030, iter [03600, 05004], lr: 0.100000, loss: 3.6045, stu_CELoss: 2.1899 DKDLoss: 1.4146 
2022-05-02 08:23:39 - train: epoch 0030, iter [03700, 05004], lr: 0.100000, loss: 3.7848, stu_CELoss: 2.2484 DKDLoss: 1.5364 
2022-05-02 08:24:14 - train: epoch 0030, iter [03800, 05004], lr: 0.100000, loss: 3.8289, stu_CELoss: 2.2763 DKDLoss: 1.5526 
2022-05-02 08:24:49 - train: epoch 0030, iter [03900, 05004], lr: 0.100000, loss: 3.6552, stu_CELoss: 2.1518 DKDLoss: 1.5033 
2022-05-02 08:25:23 - train: epoch 0030, iter [04000, 05004], lr: 0.100000, loss: 3.6886, stu_CELoss: 2.2684 DKDLoss: 1.4202 
2022-05-02 08:25:58 - train: epoch 0030, iter [04100, 05004], lr: 0.100000, loss: 3.6513, stu_CELoss: 2.1862 DKDLoss: 1.4650 
2022-05-02 08:26:32 - train: epoch 0030, iter [04200, 05004], lr: 0.100000, loss: 4.0125, stu_CELoss: 2.4196 DKDLoss: 1.5929 
2022-05-02 08:27:06 - train: epoch 0030, iter [04300, 05004], lr: 0.100000, loss: 3.7704, stu_CELoss: 2.2374 DKDLoss: 1.5330 
2022-05-02 08:27:41 - train: epoch 0030, iter [04400, 05004], lr: 0.100000, loss: 3.6987, stu_CELoss: 2.2232 DKDLoss: 1.4754 
2022-05-02 08:28:16 - train: epoch 0030, iter [04500, 05004], lr: 0.100000, loss: 3.8827, stu_CELoss: 2.3391 DKDLoss: 1.5436 
2022-05-02 08:28:49 - train: epoch 0030, iter [04600, 05004], lr: 0.100000, loss: 3.8929, stu_CELoss: 2.2235 DKDLoss: 1.6694 
2022-05-02 08:29:24 - train: epoch 0030, iter [04700, 05004], lr: 0.100000, loss: 3.8956, stu_CELoss: 2.2545 DKDLoss: 1.6411 
2022-05-02 08:29:59 - train: epoch 0030, iter [04800, 05004], lr: 0.100000, loss: 3.8672, stu_CELoss: 2.1850 DKDLoss: 1.6823 
2022-05-02 08:30:33 - train: epoch 0030, iter [04900, 05004], lr: 0.100000, loss: 3.7100, stu_CELoss: 2.3450 DKDLoss: 1.3650 
2022-05-02 08:31:06 - train: epoch 0030, iter [05000, 05004], lr: 0.100000, loss: 3.8361, stu_CELoss: 2.3442 DKDLoss: 1.4919 
2022-05-02 08:31:08 - train: epoch 030, train_loss: 3.7611
2022-05-02 08:33:39 - eval: epoch: 030, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 52.172%, stu_acc5: 77.656%, stu_test_loss: 2.0580
2022-05-02 08:33:39 - until epoch: 030, tea_best_acc1: 73.944%, stu_best_acc1: 53.152%
2022-05-02 08:33:39 - epoch 031 lr: 0.010000000000000002
2022-05-02 08:34:19 - train: epoch 0031, iter [00100, 05004], lr: 0.010000, loss: 3.2469, stu_CELoss: 1.9862 DKDLoss: 1.2607 
2022-05-02 08:34:54 - train: epoch 0031, iter [00200, 05004], lr: 0.010000, loss: 3.0881, stu_CELoss: 1.9383 DKDLoss: 1.1498 
2022-05-02 08:35:28 - train: epoch 0031, iter [00300, 05004], lr: 0.010000, loss: 2.9964, stu_CELoss: 1.8689 DKDLoss: 1.1275 
2022-05-02 08:36:01 - train: epoch 0031, iter [00400, 05004], lr: 0.010000, loss: 3.0644, stu_CELoss: 1.9256 DKDLoss: 1.1388 
2022-05-02 08:36:35 - train: epoch 0031, iter [00500, 05004], lr: 0.010000, loss: 3.0209, stu_CELoss: 1.9439 DKDLoss: 1.0770 
2022-05-02 08:37:09 - train: epoch 0031, iter [00600, 05004], lr: 0.010000, loss: 2.8391, stu_CELoss: 1.7892 DKDLoss: 1.0499 
2022-05-02 08:37:44 - train: epoch 0031, iter [00700, 05004], lr: 0.010000, loss: 3.1113, stu_CELoss: 2.0000 DKDLoss: 1.1113 
2022-05-02 08:38:17 - train: epoch 0031, iter [00800, 05004], lr: 0.010000, loss: 2.7681, stu_CELoss: 1.7904 DKDLoss: 0.9778 
2022-05-02 08:38:52 - train: epoch 0031, iter [00900, 05004], lr: 0.010000, loss: 2.8140, stu_CELoss: 1.8226 DKDLoss: 0.9914 
2022-05-02 08:39:27 - train: epoch 0031, iter [01000, 05004], lr: 0.010000, loss: 3.1917, stu_CELoss: 2.1038 DKDLoss: 1.0879 
2022-05-02 08:39:59 - train: epoch 0031, iter [01100, 05004], lr: 0.010000, loss: 2.9684, stu_CELoss: 1.9093 DKDLoss: 1.0592 
2022-05-02 08:40:34 - train: epoch 0031, iter [01200, 05004], lr: 0.010000, loss: 2.9361, stu_CELoss: 1.9103 DKDLoss: 1.0258 
2022-05-02 08:41:08 - train: epoch 0031, iter [01300, 05004], lr: 0.010000, loss: 2.5246, stu_CELoss: 1.5459 DKDLoss: 0.9787 
2022-05-02 08:41:43 - train: epoch 0031, iter [01400, 05004], lr: 0.010000, loss: 2.7790, stu_CELoss: 1.8186 DKDLoss: 0.9604 
2022-05-02 08:42:17 - train: epoch 0031, iter [01500, 05004], lr: 0.010000, loss: 3.0484, stu_CELoss: 1.9772 DKDLoss: 1.0712 
2022-05-02 08:42:51 - train: epoch 0031, iter [01600, 05004], lr: 0.010000, loss: 2.8405, stu_CELoss: 1.8281 DKDLoss: 1.0124 
2022-05-02 08:43:25 - train: epoch 0031, iter [01700, 05004], lr: 0.010000, loss: 2.8856, stu_CELoss: 1.8486 DKDLoss: 1.0370 
2022-05-02 08:43:59 - train: epoch 0031, iter [01800, 05004], lr: 0.010000, loss: 2.5311, stu_CELoss: 1.5144 DKDLoss: 1.0166 
2022-05-02 08:44:35 - train: epoch 0031, iter [01900, 05004], lr: 0.010000, loss: 2.8066, stu_CELoss: 1.7615 DKDLoss: 1.0452 
2022-05-02 08:45:07 - train: epoch 0031, iter [02000, 05004], lr: 0.010000, loss: 2.9422, stu_CELoss: 1.8619 DKDLoss: 1.0803 
2022-05-02 08:45:42 - train: epoch 0031, iter [02100, 05004], lr: 0.010000, loss: 2.6487, stu_CELoss: 1.7129 DKDLoss: 0.9357 
2022-05-02 08:46:16 - train: epoch 0031, iter [02200, 05004], lr: 0.010000, loss: 2.7910, stu_CELoss: 1.7267 DKDLoss: 1.0643 
2022-05-02 08:46:50 - train: epoch 0031, iter [02300, 05004], lr: 0.010000, loss: 2.6094, stu_CELoss: 1.7314 DKDLoss: 0.8780 
2022-05-02 08:47:25 - train: epoch 0031, iter [02400, 05004], lr: 0.010000, loss: 2.7080, stu_CELoss: 1.7917 DKDLoss: 0.9163 
2022-05-02 08:47:59 - train: epoch 0031, iter [02500, 05004], lr: 0.010000, loss: 3.1194, stu_CELoss: 2.0662 DKDLoss: 1.0533 
2022-05-02 08:48:34 - train: epoch 0031, iter [02600, 05004], lr: 0.010000, loss: 2.8758, stu_CELoss: 1.8896 DKDLoss: 0.9862 
2022-05-02 08:49:08 - train: epoch 0031, iter [02700, 05004], lr: 0.010000, loss: 2.8124, stu_CELoss: 1.8532 DKDLoss: 0.9592 
2022-05-02 08:49:42 - train: epoch 0031, iter [02800, 05004], lr: 0.010000, loss: 2.9908, stu_CELoss: 1.9642 DKDLoss: 1.0267 
2022-05-02 08:50:17 - train: epoch 0031, iter [02900, 05004], lr: 0.010000, loss: 2.9493, stu_CELoss: 1.9957 DKDLoss: 0.9536 
2022-05-02 08:50:50 - train: epoch 0031, iter [03000, 05004], lr: 0.010000, loss: 3.1502, stu_CELoss: 2.1709 DKDLoss: 0.9793 
2022-05-02 08:51:25 - train: epoch 0031, iter [03100, 05004], lr: 0.010000, loss: 2.7968, stu_CELoss: 1.8791 DKDLoss: 0.9177 
2022-05-02 08:51:58 - train: epoch 0031, iter [03200, 05004], lr: 0.010000, loss: 2.9096, stu_CELoss: 1.8794 DKDLoss: 1.0302 
2022-05-02 08:52:33 - train: epoch 0031, iter [03300, 05004], lr: 0.010000, loss: 2.5247, stu_CELoss: 1.6685 DKDLoss: 0.8562 
2022-05-02 08:53:08 - train: epoch 0031, iter [03400, 05004], lr: 0.010000, loss: 2.8807, stu_CELoss: 1.9685 DKDLoss: 0.9123 
2022-05-02 08:53:42 - train: epoch 0031, iter [03500, 05004], lr: 0.010000, loss: 2.7723, stu_CELoss: 1.8514 DKDLoss: 0.9210 
2022-05-02 08:54:16 - train: epoch 0031, iter [03600, 05004], lr: 0.010000, loss: 2.8236, stu_CELoss: 1.8858 DKDLoss: 0.9378 
2022-05-02 08:54:51 - train: epoch 0031, iter [03700, 05004], lr: 0.010000, loss: 2.5176, stu_CELoss: 1.6605 DKDLoss: 0.8571 
2022-05-02 08:55:25 - train: epoch 0031, iter [03800, 05004], lr: 0.010000, loss: 2.5585, stu_CELoss: 1.6229 DKDLoss: 0.9356 
2022-05-02 08:55:59 - train: epoch 0031, iter [03900, 05004], lr: 0.010000, loss: 2.6943, stu_CELoss: 1.7102 DKDLoss: 0.9841 
2022-05-02 08:56:35 - train: epoch 0031, iter [04000, 05004], lr: 0.010000, loss: 2.4820, stu_CELoss: 1.5931 DKDLoss: 0.8889 
2022-05-02 08:57:09 - train: epoch 0031, iter [04100, 05004], lr: 0.010000, loss: 2.5793, stu_CELoss: 1.7746 DKDLoss: 0.8047 
2022-05-02 08:57:43 - train: epoch 0031, iter [04200, 05004], lr: 0.010000, loss: 2.6392, stu_CELoss: 1.7447 DKDLoss: 0.8945 
2022-05-02 08:58:18 - train: epoch 0031, iter [04300, 05004], lr: 0.010000, loss: 2.4327, stu_CELoss: 1.6228 DKDLoss: 0.8100 
2022-05-02 08:58:52 - train: epoch 0031, iter [04400, 05004], lr: 0.010000, loss: 2.8298, stu_CELoss: 1.9755 DKDLoss: 0.8543 
2022-05-02 08:59:27 - train: epoch 0031, iter [04500, 05004], lr: 0.010000, loss: 2.7159, stu_CELoss: 1.7716 DKDLoss: 0.9442 
2022-05-02 09:00:00 - train: epoch 0031, iter [04600, 05004], lr: 0.010000, loss: 2.7114, stu_CELoss: 1.7476 DKDLoss: 0.9638 
2022-05-02 09:00:35 - train: epoch 0031, iter [04700, 05004], lr: 0.010000, loss: 2.4907, stu_CELoss: 1.5841 DKDLoss: 0.9066 
2022-05-02 09:01:10 - train: epoch 0031, iter [04800, 05004], lr: 0.010000, loss: 2.4281, stu_CELoss: 1.6241 DKDLoss: 0.8040 
2022-05-02 09:01:45 - train: epoch 0031, iter [04900, 05004], lr: 0.010000, loss: 2.6587, stu_CELoss: 1.7763 DKDLoss: 0.8824 
2022-05-02 09:02:17 - train: epoch 0031, iter [05000, 05004], lr: 0.010000, loss: 2.5245, stu_CELoss: 1.6573 DKDLoss: 0.8672 
2022-05-02 09:02:18 - train: epoch 031, train_loss: 2.7716
2022-05-02 09:04:52 - eval: epoch: 031, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 65.062%, stu_acc5: 86.484%, stu_test_loss: 1.4311
2022-05-02 09:04:52 - until epoch: 031, tea_best_acc1: 73.944%, stu_best_acc1: 65.062%
2022-05-02 09:04:52 - epoch 032 lr: 0.010000000000000002
2022-05-02 09:05:31 - train: epoch 0032, iter [00100, 05004], lr: 0.010000, loss: 2.2842, stu_CELoss: 1.4660 DKDLoss: 0.8182 
2022-05-02 09:06:05 - train: epoch 0032, iter [00200, 05004], lr: 0.010000, loss: 2.4186, stu_CELoss: 1.5516 DKDLoss: 0.8670 
2022-05-02 09:06:40 - train: epoch 0032, iter [00300, 05004], lr: 0.010000, loss: 2.3558, stu_CELoss: 1.5284 DKDLoss: 0.8274 
2022-05-02 09:07:14 - train: epoch 0032, iter [00400, 05004], lr: 0.010000, loss: 2.5761, stu_CELoss: 1.7882 DKDLoss: 0.7879 
2022-05-02 09:07:50 - train: epoch 0032, iter [00500, 05004], lr: 0.010000, loss: 2.6392, stu_CELoss: 1.6801 DKDLoss: 0.9591 
2022-05-02 09:08:23 - train: epoch 0032, iter [00600, 05004], lr: 0.010000, loss: 2.5821, stu_CELoss: 1.7298 DKDLoss: 0.8523 
2022-05-02 09:08:58 - train: epoch 0032, iter [00700, 05004], lr: 0.010000, loss: 2.6825, stu_CELoss: 1.6914 DKDLoss: 0.9911 
2022-05-02 09:09:31 - train: epoch 0032, iter [00800, 05004], lr: 0.010000, loss: 2.6126, stu_CELoss: 1.7802 DKDLoss: 0.8323 
2022-05-02 09:10:06 - train: epoch 0032, iter [00900, 05004], lr: 0.010000, loss: 2.5694, stu_CELoss: 1.5933 DKDLoss: 0.9761 
2022-05-02 09:10:40 - train: epoch 0032, iter [01000, 05004], lr: 0.010000, loss: 2.9169, stu_CELoss: 1.9920 DKDLoss: 0.9249 
2022-05-02 09:11:14 - train: epoch 0032, iter [01100, 05004], lr: 0.010000, loss: 2.5064, stu_CELoss: 1.6223 DKDLoss: 0.8841 
2022-05-02 09:11:50 - train: epoch 0032, iter [01200, 05004], lr: 0.010000, loss: 2.7919, stu_CELoss: 1.7956 DKDLoss: 0.9963 
2022-05-02 09:12:24 - train: epoch 0032, iter [01300, 05004], lr: 0.010000, loss: 2.6014, stu_CELoss: 1.6984 DKDLoss: 0.9030 
2022-05-02 09:13:00 - train: epoch 0032, iter [01400, 05004], lr: 0.010000, loss: 2.7988, stu_CELoss: 1.8129 DKDLoss: 0.9858 
2022-05-02 09:13:34 - train: epoch 0032, iter [01500, 05004], lr: 0.010000, loss: 2.8142, stu_CELoss: 1.8568 DKDLoss: 0.9574 
2022-05-02 09:14:10 - train: epoch 0032, iter [01600, 05004], lr: 0.010000, loss: 2.7720, stu_CELoss: 1.8934 DKDLoss: 0.8786 
2022-05-02 09:14:45 - train: epoch 0032, iter [01700, 05004], lr: 0.010000, loss: 2.7885, stu_CELoss: 1.8896 DKDLoss: 0.8988 
2022-05-02 09:15:20 - train: epoch 0032, iter [01800, 05004], lr: 0.010000, loss: 2.9611, stu_CELoss: 2.0735 DKDLoss: 0.8877 
2022-05-02 09:15:56 - train: epoch 0032, iter [01900, 05004], lr: 0.010000, loss: 2.1621, stu_CELoss: 1.3202 DKDLoss: 0.8419 
2022-05-02 09:16:31 - train: epoch 0032, iter [02000, 05004], lr: 0.010000, loss: 2.4559, stu_CELoss: 1.5924 DKDLoss: 0.8634 
2022-05-02 09:17:06 - train: epoch 0032, iter [02100, 05004], lr: 0.010000, loss: 2.4359, stu_CELoss: 1.5569 DKDLoss: 0.8791 
2022-05-02 09:17:39 - train: epoch 0032, iter [02200, 05004], lr: 0.010000, loss: 2.4647, stu_CELoss: 1.6739 DKDLoss: 0.7908 
2022-05-02 09:18:15 - train: epoch 0032, iter [02300, 05004], lr: 0.010000, loss: 2.5855, stu_CELoss: 1.7403 DKDLoss: 0.8452 
2022-05-02 09:18:49 - train: epoch 0032, iter [02400, 05004], lr: 0.010000, loss: 2.4020, stu_CELoss: 1.5362 DKDLoss: 0.8658 
2022-05-02 09:19:24 - train: epoch 0032, iter [02500, 05004], lr: 0.010000, loss: 2.3953, stu_CELoss: 1.6073 DKDLoss: 0.7880 
2022-05-02 09:20:00 - train: epoch 0032, iter [02600, 05004], lr: 0.010000, loss: 2.4192, stu_CELoss: 1.5837 DKDLoss: 0.8355 
2022-05-02 09:20:35 - train: epoch 0032, iter [02700, 05004], lr: 0.010000, loss: 2.3809, stu_CELoss: 1.5458 DKDLoss: 0.8351 
2022-05-02 09:21:09 - train: epoch 0032, iter [02800, 05004], lr: 0.010000, loss: 2.6182, stu_CELoss: 1.8130 DKDLoss: 0.8053 
2022-05-02 09:21:44 - train: epoch 0032, iter [02900, 05004], lr: 0.010000, loss: 2.3446, stu_CELoss: 1.5151 DKDLoss: 0.8295 
2022-05-02 09:22:18 - train: epoch 0032, iter [03000, 05004], lr: 0.010000, loss: 2.4089, stu_CELoss: 1.5304 DKDLoss: 0.8784 
2022-05-02 09:22:53 - train: epoch 0032, iter [03100, 05004], lr: 0.010000, loss: 2.7454, stu_CELoss: 1.8505 DKDLoss: 0.8949 
2022-05-02 09:23:27 - train: epoch 0032, iter [03200, 05004], lr: 0.010000, loss: 2.7260, stu_CELoss: 1.8120 DKDLoss: 0.9140 
2022-05-02 09:24:01 - train: epoch 0032, iter [03300, 05004], lr: 0.010000, loss: 2.4363, stu_CELoss: 1.6425 DKDLoss: 0.7938 
2022-05-02 09:24:37 - train: epoch 0032, iter [03400, 05004], lr: 0.010000, loss: 2.4617, stu_CELoss: 1.5864 DKDLoss: 0.8753 
2022-05-02 09:25:10 - train: epoch 0032, iter [03500, 05004], lr: 0.010000, loss: 2.4982, stu_CELoss: 1.6300 DKDLoss: 0.8682 
2022-05-02 09:25:45 - train: epoch 0032, iter [03600, 05004], lr: 0.010000, loss: 2.6836, stu_CELoss: 1.8674 DKDLoss: 0.8162 
2022-05-02 09:26:20 - train: epoch 0032, iter [03700, 05004], lr: 0.010000, loss: 2.5393, stu_CELoss: 1.7103 DKDLoss: 0.8290 
2022-05-02 09:26:55 - train: epoch 0032, iter [03800, 05004], lr: 0.010000, loss: 2.2660, stu_CELoss: 1.4831 DKDLoss: 0.7828 
2022-05-02 09:27:29 - train: epoch 0032, iter [03900, 05004], lr: 0.010000, loss: 2.1946, stu_CELoss: 1.3994 DKDLoss: 0.7952 
2022-05-02 09:28:03 - train: epoch 0032, iter [04000, 05004], lr: 0.010000, loss: 2.6217, stu_CELoss: 1.7892 DKDLoss: 0.8326 
2022-05-02 09:28:39 - train: epoch 0032, iter [04100, 05004], lr: 0.010000, loss: 2.4192, stu_CELoss: 1.5427 DKDLoss: 0.8766 
2022-05-02 09:29:12 - train: epoch 0032, iter [04200, 05004], lr: 0.010000, loss: 2.3998, stu_CELoss: 1.6035 DKDLoss: 0.7964 
2022-05-02 09:29:47 - train: epoch 0032, iter [04300, 05004], lr: 0.010000, loss: 2.6397, stu_CELoss: 1.7703 DKDLoss: 0.8694 
2022-05-02 09:30:22 - train: epoch 0032, iter [04400, 05004], lr: 0.010000, loss: 2.2813, stu_CELoss: 1.4985 DKDLoss: 0.7828 
2022-05-02 09:30:58 - train: epoch 0032, iter [04500, 05004], lr: 0.010000, loss: 2.6222, stu_CELoss: 1.7894 DKDLoss: 0.8328 
2022-05-02 09:31:36 - train: epoch 0032, iter [04600, 05004], lr: 0.010000, loss: 2.4760, stu_CELoss: 1.6427 DKDLoss: 0.8333 
2022-05-02 09:32:14 - train: epoch 0032, iter [04700, 05004], lr: 0.010000, loss: 2.6489, stu_CELoss: 1.7918 DKDLoss: 0.8571 
2022-05-02 09:32:52 - train: epoch 0032, iter [04800, 05004], lr: 0.010000, loss: 2.5724, stu_CELoss: 1.6450 DKDLoss: 0.9274 
2022-05-02 09:33:29 - train: epoch 0032, iter [04900, 05004], lr: 0.010000, loss: 2.4415, stu_CELoss: 1.6527 DKDLoss: 0.7887 
2022-05-02 09:34:05 - train: epoch 0032, iter [05000, 05004], lr: 0.010000, loss: 2.5067, stu_CELoss: 1.6812 DKDLoss: 0.8255 
2022-05-02 09:34:06 - train: epoch 032, train_loss: 2.5530
2022-05-02 09:36:40 - eval: epoch: 032, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 65.952%, stu_acc5: 87.146%, stu_test_loss: 1.3848
2022-05-02 09:36:40 - until epoch: 032, tea_best_acc1: 73.944%, stu_best_acc1: 65.952%
2022-05-02 09:36:40 - epoch 033 lr: 0.010000000000000002
2022-05-02 09:37:18 - train: epoch 0033, iter [00100, 05004], lr: 0.010000, loss: 2.3257, stu_CELoss: 1.4598 DKDLoss: 0.8659 
2022-05-02 09:37:52 - train: epoch 0033, iter [00200, 05004], lr: 0.010000, loss: 2.4325, stu_CELoss: 1.6364 DKDLoss: 0.7961 
2022-05-02 09:38:25 - train: epoch 0033, iter [00300, 05004], lr: 0.010000, loss: 2.5180, stu_CELoss: 1.6684 DKDLoss: 0.8496 
2022-05-02 09:38:59 - train: epoch 0033, iter [00400, 05004], lr: 0.010000, loss: 2.3739, stu_CELoss: 1.6058 DKDLoss: 0.7681 
2022-05-02 09:39:32 - train: epoch 0033, iter [00500, 05004], lr: 0.010000, loss: 2.5005, stu_CELoss: 1.7147 DKDLoss: 0.7858 
2022-05-02 09:40:07 - train: epoch 0033, iter [00600, 05004], lr: 0.010000, loss: 2.5999, stu_CELoss: 1.7050 DKDLoss: 0.8949 
2022-05-02 09:40:40 - train: epoch 0033, iter [00700, 05004], lr: 0.010000, loss: 2.7558, stu_CELoss: 1.8312 DKDLoss: 0.9246 
2022-05-02 09:41:13 - train: epoch 0033, iter [00800, 05004], lr: 0.010000, loss: 2.7629, stu_CELoss: 1.8281 DKDLoss: 0.9347 
2022-05-02 09:41:47 - train: epoch 0033, iter [00900, 05004], lr: 0.010000, loss: 2.3873, stu_CELoss: 1.5641 DKDLoss: 0.8232 
2022-05-02 09:42:20 - train: epoch 0033, iter [01000, 05004], lr: 0.010000, loss: 2.4264, stu_CELoss: 1.6871 DKDLoss: 0.7393 
2022-05-02 09:42:53 - train: epoch 0033, iter [01100, 05004], lr: 0.010000, loss: 2.0871, stu_CELoss: 1.3335 DKDLoss: 0.7536 
2022-05-02 09:43:27 - train: epoch 0033, iter [01200, 05004], lr: 0.010000, loss: 2.7065, stu_CELoss: 1.8929 DKDLoss: 0.8137 
2022-05-02 09:44:01 - train: epoch 0033, iter [01300, 05004], lr: 0.010000, loss: 2.2737, stu_CELoss: 1.5492 DKDLoss: 0.7245 
2022-05-02 09:44:34 - train: epoch 0033, iter [01400, 05004], lr: 0.010000, loss: 2.4065, stu_CELoss: 1.5585 DKDLoss: 0.8480 
2022-05-02 09:45:07 - train: epoch 0033, iter [01500, 05004], lr: 0.010000, loss: 2.7355, stu_CELoss: 1.8900 DKDLoss: 0.8454 
2022-05-02 09:45:41 - train: epoch 0033, iter [01600, 05004], lr: 0.010000, loss: 2.7019, stu_CELoss: 1.8223 DKDLoss: 0.8796 
2022-05-02 09:46:13 - train: epoch 0033, iter [01700, 05004], lr: 0.010000, loss: 2.6118, stu_CELoss: 1.7368 DKDLoss: 0.8750 
2022-05-02 09:46:48 - train: epoch 0033, iter [01800, 05004], lr: 0.010000, loss: 2.5003, stu_CELoss: 1.5863 DKDLoss: 0.9140 
2022-05-02 09:47:21 - train: epoch 0033, iter [01900, 05004], lr: 0.010000, loss: 2.4517, stu_CELoss: 1.6361 DKDLoss: 0.8156 
2022-05-02 09:47:54 - train: epoch 0033, iter [02000, 05004], lr: 0.010000, loss: 2.2883, stu_CELoss: 1.4634 DKDLoss: 0.8249 
2022-05-02 09:48:27 - train: epoch 0033, iter [02100, 05004], lr: 0.010000, loss: 2.6473, stu_CELoss: 1.7638 DKDLoss: 0.8835 
2022-05-02 09:49:00 - train: epoch 0033, iter [02200, 05004], lr: 0.010000, loss: 2.4931, stu_CELoss: 1.6878 DKDLoss: 0.8053 
2022-05-02 09:49:34 - train: epoch 0033, iter [02300, 05004], lr: 0.010000, loss: 2.4424, stu_CELoss: 1.5972 DKDLoss: 0.8452 
2022-05-02 09:50:08 - train: epoch 0033, iter [02400, 05004], lr: 0.010000, loss: 2.7355, stu_CELoss: 1.9096 DKDLoss: 0.8259 
2022-05-02 09:50:42 - train: epoch 0033, iter [02500, 05004], lr: 0.010000, loss: 2.4348, stu_CELoss: 1.6018 DKDLoss: 0.8329 
2022-05-02 09:51:16 - train: epoch 0033, iter [02600, 05004], lr: 0.010000, loss: 2.4426, stu_CELoss: 1.5750 DKDLoss: 0.8675 
2022-05-02 09:51:49 - train: epoch 0033, iter [02700, 05004], lr: 0.010000, loss: 2.3924, stu_CELoss: 1.5860 DKDLoss: 0.8064 
2022-05-02 09:52:22 - train: epoch 0033, iter [02800, 05004], lr: 0.010000, loss: 2.3544, stu_CELoss: 1.5674 DKDLoss: 0.7870 
2022-05-02 09:52:56 - train: epoch 0033, iter [02900, 05004], lr: 0.010000, loss: 2.2135, stu_CELoss: 1.4691 DKDLoss: 0.7444 
2022-05-02 09:53:29 - train: epoch 0033, iter [03000, 05004], lr: 0.010000, loss: 2.5020, stu_CELoss: 1.6860 DKDLoss: 0.8160 
2022-05-02 09:54:03 - train: epoch 0033, iter [03100, 05004], lr: 0.010000, loss: 2.4362, stu_CELoss: 1.5697 DKDLoss: 0.8665 
2022-05-02 09:54:35 - train: epoch 0033, iter [03200, 05004], lr: 0.010000, loss: 2.4966, stu_CELoss: 1.6072 DKDLoss: 0.8894 
2022-05-02 09:55:09 - train: epoch 0033, iter [03300, 05004], lr: 0.010000, loss: 2.3249, stu_CELoss: 1.5909 DKDLoss: 0.7340 
2022-05-02 09:55:43 - train: epoch 0033, iter [03400, 05004], lr: 0.010000, loss: 2.3594, stu_CELoss: 1.5220 DKDLoss: 0.8375 
2022-05-02 09:56:18 - train: epoch 0033, iter [03500, 05004], lr: 0.010000, loss: 2.5331, stu_CELoss: 1.6553 DKDLoss: 0.8778 
2022-05-02 09:56:52 - train: epoch 0033, iter [03600, 05004], lr: 0.010000, loss: 2.8818, stu_CELoss: 1.9446 DKDLoss: 0.9372 
2022-05-02 09:57:26 - train: epoch 0033, iter [03700, 05004], lr: 0.010000, loss: 2.4353, stu_CELoss: 1.5481 DKDLoss: 0.8872 
2022-05-02 09:58:01 - train: epoch 0033, iter [03800, 05004], lr: 0.010000, loss: 2.4752, stu_CELoss: 1.6445 DKDLoss: 0.8307 
2022-05-02 09:58:34 - train: epoch 0033, iter [03900, 05004], lr: 0.010000, loss: 2.7208, stu_CELoss: 1.8970 DKDLoss: 0.8237 
2022-05-02 09:59:10 - train: epoch 0033, iter [04000, 05004], lr: 0.010000, loss: 2.5666, stu_CELoss: 1.7680 DKDLoss: 0.7986 
2022-05-02 09:59:43 - train: epoch 0033, iter [04100, 05004], lr: 0.010000, loss: 2.5348, stu_CELoss: 1.6691 DKDLoss: 0.8657 
2022-05-02 10:00:17 - train: epoch 0033, iter [04200, 05004], lr: 0.010000, loss: 2.3589, stu_CELoss: 1.5731 DKDLoss: 0.7858 
2022-05-02 10:00:51 - train: epoch 0033, iter [04300, 05004], lr: 0.010000, loss: 2.4988, stu_CELoss: 1.7113 DKDLoss: 0.7875 
2022-05-02 10:01:25 - train: epoch 0033, iter [04400, 05004], lr: 0.010000, loss: 2.3687, stu_CELoss: 1.5898 DKDLoss: 0.7789 
2022-05-02 10:01:59 - train: epoch 0033, iter [04500, 05004], lr: 0.010000, loss: 2.6637, stu_CELoss: 1.8049 DKDLoss: 0.8588 
2022-05-02 10:02:33 - train: epoch 0033, iter [04600, 05004], lr: 0.010000, loss: 2.5634, stu_CELoss: 1.7040 DKDLoss: 0.8594 
2022-05-02 10:03:06 - train: epoch 0033, iter [04700, 05004], lr: 0.010000, loss: 2.5444, stu_CELoss: 1.7029 DKDLoss: 0.8416 
2022-05-02 10:03:39 - train: epoch 0033, iter [04800, 05004], lr: 0.010000, loss: 2.7839, stu_CELoss: 1.9343 DKDLoss: 0.8495 
2022-05-02 10:04:14 - train: epoch 0033, iter [04900, 05004], lr: 0.010000, loss: 2.4985, stu_CELoss: 1.6695 DKDLoss: 0.8289 
2022-05-02 10:04:45 - train: epoch 0033, iter [05000, 05004], lr: 0.010000, loss: 2.4699, stu_CELoss: 1.6151 DKDLoss: 0.8548 
2022-05-02 10:04:47 - train: epoch 033, train_loss: 2.4699
2022-05-02 10:07:16 - eval: epoch: 033, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 66.584%, stu_acc5: 87.324%, stu_test_loss: 1.3695
2022-05-02 10:07:17 - until epoch: 033, tea_best_acc1: 73.944%, stu_best_acc1: 66.584%
2022-05-02 10:07:17 - epoch 034 lr: 0.010000000000000002
2022-05-02 10:07:55 - train: epoch 0034, iter [00100, 05004], lr: 0.010000, loss: 2.3574, stu_CELoss: 1.5731 DKDLoss: 0.7843 
2022-05-02 10:08:28 - train: epoch 0034, iter [00200, 05004], lr: 0.010000, loss: 2.5095, stu_CELoss: 1.6650 DKDLoss: 0.8445 
2022-05-02 10:09:01 - train: epoch 0034, iter [00300, 05004], lr: 0.010000, loss: 2.2729, stu_CELoss: 1.5272 DKDLoss: 0.7457 
2022-05-02 10:09:36 - train: epoch 0034, iter [00400, 05004], lr: 0.010000, loss: 2.3914, stu_CELoss: 1.5405 DKDLoss: 0.8509 
2022-05-02 10:10:09 - train: epoch 0034, iter [00500, 05004], lr: 0.010000, loss: 2.3773, stu_CELoss: 1.6058 DKDLoss: 0.7715 
2022-05-02 10:10:43 - train: epoch 0034, iter [00600, 05004], lr: 0.010000, loss: 2.4390, stu_CELoss: 1.6509 DKDLoss: 0.7882 
2022-05-02 10:11:16 - train: epoch 0034, iter [00700, 05004], lr: 0.010000, loss: 2.3645, stu_CELoss: 1.5613 DKDLoss: 0.8032 
2022-05-02 10:11:49 - train: epoch 0034, iter [00800, 05004], lr: 0.010000, loss: 2.4075, stu_CELoss: 1.6565 DKDLoss: 0.7510 
2022-05-02 10:12:22 - train: epoch 0034, iter [00900, 05004], lr: 0.010000, loss: 2.2942, stu_CELoss: 1.4851 DKDLoss: 0.8091 
2022-05-02 10:12:56 - train: epoch 0034, iter [01000, 05004], lr: 0.010000, loss: 2.3274, stu_CELoss: 1.5856 DKDLoss: 0.7419 
2022-05-02 10:13:29 - train: epoch 0034, iter [01100, 05004], lr: 0.010000, loss: 2.4111, stu_CELoss: 1.5439 DKDLoss: 0.8672 
2022-05-02 10:14:03 - train: epoch 0034, iter [01200, 05004], lr: 0.010000, loss: 2.4479, stu_CELoss: 1.6338 DKDLoss: 0.8141 
2022-05-02 10:14:36 - train: epoch 0034, iter [01300, 05004], lr: 0.010000, loss: 2.3347, stu_CELoss: 1.5162 DKDLoss: 0.8185 
2022-05-02 10:15:09 - train: epoch 0034, iter [01400, 05004], lr: 0.010000, loss: 2.3417, stu_CELoss: 1.5249 DKDLoss: 0.8168 
2022-05-02 10:15:42 - train: epoch 0034, iter [01500, 05004], lr: 0.010000, loss: 2.3498, stu_CELoss: 1.5793 DKDLoss: 0.7705 
2022-05-02 10:16:16 - train: epoch 0034, iter [01600, 05004], lr: 0.010000, loss: 2.3831, stu_CELoss: 1.5887 DKDLoss: 0.7944 
2022-05-02 10:16:49 - train: epoch 0034, iter [01700, 05004], lr: 0.010000, loss: 2.5613, stu_CELoss: 1.6608 DKDLoss: 0.9004 
2022-05-02 10:17:23 - train: epoch 0034, iter [01800, 05004], lr: 0.010000, loss: 2.5496, stu_CELoss: 1.7592 DKDLoss: 0.7904 
2022-05-02 10:17:56 - train: epoch 0034, iter [01900, 05004], lr: 0.010000, loss: 2.5664, stu_CELoss: 1.6955 DKDLoss: 0.8709 
2022-05-02 10:18:30 - train: epoch 0034, iter [02000, 05004], lr: 0.010000, loss: 2.2583, stu_CELoss: 1.5025 DKDLoss: 0.7557 
2022-05-02 10:19:03 - train: epoch 0034, iter [02100, 05004], lr: 0.010000, loss: 2.4878, stu_CELoss: 1.6820 DKDLoss: 0.8058 
2022-05-02 10:19:36 - train: epoch 0034, iter [02200, 05004], lr: 0.010000, loss: 2.2153, stu_CELoss: 1.4705 DKDLoss: 0.7448 
2022-05-02 10:20:10 - train: epoch 0034, iter [02300, 05004], lr: 0.010000, loss: 2.6057, stu_CELoss: 1.7870 DKDLoss: 0.8187 
2022-05-02 10:20:43 - train: epoch 0034, iter [02400, 05004], lr: 0.010000, loss: 2.2240, stu_CELoss: 1.4436 DKDLoss: 0.7804 
2022-05-02 10:21:18 - train: epoch 0034, iter [02500, 05004], lr: 0.010000, loss: 2.5795, stu_CELoss: 1.8007 DKDLoss: 0.7788 
2022-05-02 10:21:52 - train: epoch 0034, iter [02600, 05004], lr: 0.010000, loss: 2.4996, stu_CELoss: 1.7394 DKDLoss: 0.7601 
2022-05-02 10:22:24 - train: epoch 0034, iter [02700, 05004], lr: 0.010000, loss: 2.5386, stu_CELoss: 1.7313 DKDLoss: 0.8073 
2022-05-02 10:22:57 - train: epoch 0034, iter [02800, 05004], lr: 0.010000, loss: 2.2215, stu_CELoss: 1.4812 DKDLoss: 0.7402 
2022-05-02 10:23:32 - train: epoch 0034, iter [02900, 05004], lr: 0.010000, loss: 2.1985, stu_CELoss: 1.4362 DKDLoss: 0.7623 
2022-05-02 10:24:05 - train: epoch 0034, iter [03000, 05004], lr: 0.010000, loss: 2.2236, stu_CELoss: 1.4369 DKDLoss: 0.7867 
2022-05-02 10:24:38 - train: epoch 0034, iter [03100, 05004], lr: 0.010000, loss: 2.2202, stu_CELoss: 1.4667 DKDLoss: 0.7535 
2022-05-02 10:25:12 - train: epoch 0034, iter [03200, 05004], lr: 0.010000, loss: 2.3712, stu_CELoss: 1.6040 DKDLoss: 0.7672 
2022-05-02 10:25:46 - train: epoch 0034, iter [03300, 05004], lr: 0.010000, loss: 2.2551, stu_CELoss: 1.5056 DKDLoss: 0.7494 
2022-05-02 10:26:20 - train: epoch 0034, iter [03400, 05004], lr: 0.010000, loss: 2.5841, stu_CELoss: 1.8113 DKDLoss: 0.7727 
2022-05-02 10:26:53 - train: epoch 0034, iter [03500, 05004], lr: 0.010000, loss: 2.2991, stu_CELoss: 1.5046 DKDLoss: 0.7945 
2022-05-02 10:27:27 - train: epoch 0034, iter [03600, 05004], lr: 0.010000, loss: 2.2394, stu_CELoss: 1.4297 DKDLoss: 0.8096 
2022-05-02 10:28:01 - train: epoch 0034, iter [03700, 05004], lr: 0.010000, loss: 2.5132, stu_CELoss: 1.6911 DKDLoss: 0.8221 
2022-05-02 10:28:33 - train: epoch 0034, iter [03800, 05004], lr: 0.010000, loss: 2.3007, stu_CELoss: 1.4919 DKDLoss: 0.8087 
2022-05-02 10:29:08 - train: epoch 0034, iter [03900, 05004], lr: 0.010000, loss: 2.7997, stu_CELoss: 2.0117 DKDLoss: 0.7880 
2022-05-02 10:29:41 - train: epoch 0034, iter [04000, 05004], lr: 0.010000, loss: 2.4319, stu_CELoss: 1.5663 DKDLoss: 0.8656 
2022-05-02 10:30:15 - train: epoch 0034, iter [04100, 05004], lr: 0.010000, loss: 2.5677, stu_CELoss: 1.8107 DKDLoss: 0.7570 
2022-05-02 10:30:48 - train: epoch 0034, iter [04200, 05004], lr: 0.010000, loss: 2.3771, stu_CELoss: 1.5153 DKDLoss: 0.8618 
2022-05-02 10:31:22 - train: epoch 0034, iter [04300, 05004], lr: 0.010000, loss: 2.2395, stu_CELoss: 1.4482 DKDLoss: 0.7913 
2022-05-02 10:31:56 - train: epoch 0034, iter [04400, 05004], lr: 0.010000, loss: 2.3077, stu_CELoss: 1.4763 DKDLoss: 0.8315 
2022-05-02 10:32:29 - train: epoch 0034, iter [04500, 05004], lr: 0.010000, loss: 2.4347, stu_CELoss: 1.6984 DKDLoss: 0.7362 
2022-05-02 10:33:03 - train: epoch 0034, iter [04600, 05004], lr: 0.010000, loss: 2.6242, stu_CELoss: 1.7749 DKDLoss: 0.8493 
2022-05-02 10:33:36 - train: epoch 0034, iter [04700, 05004], lr: 0.010000, loss: 2.4992, stu_CELoss: 1.6807 DKDLoss: 0.8186 
2022-05-02 10:34:09 - train: epoch 0034, iter [04800, 05004], lr: 0.010000, loss: 2.5332, stu_CELoss: 1.6761 DKDLoss: 0.8571 
2022-05-02 10:34:43 - train: epoch 0034, iter [04900, 05004], lr: 0.010000, loss: 2.3695, stu_CELoss: 1.6825 DKDLoss: 0.6870 
2022-05-02 10:35:15 - train: epoch 0034, iter [05000, 05004], lr: 0.010000, loss: 2.3518, stu_CELoss: 1.5138 DKDLoss: 0.8380 
2022-05-02 10:35:16 - train: epoch 034, train_loss: 2.4187
2022-05-02 10:37:45 - eval: epoch: 034, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 66.772%, stu_acc5: 87.472%, stu_test_loss: 1.3546
2022-05-02 10:37:46 - until epoch: 034, tea_best_acc1: 73.944%, stu_best_acc1: 66.772%
2022-05-02 10:37:46 - epoch 035 lr: 0.010000000000000002
2022-05-02 10:38:24 - train: epoch 0035, iter [00100, 05004], lr: 0.010000, loss: 2.2932, stu_CELoss: 1.5113 DKDLoss: 0.7819 
2022-05-02 10:38:57 - train: epoch 0035, iter [00200, 05004], lr: 0.010000, loss: 2.2788, stu_CELoss: 1.4870 DKDLoss: 0.7918 
2022-05-02 10:39:31 - train: epoch 0035, iter [00300, 05004], lr: 0.010000, loss: 2.4753, stu_CELoss: 1.6566 DKDLoss: 0.8187 
2022-05-02 10:40:05 - train: epoch 0035, iter [00400, 05004], lr: 0.010000, loss: 2.1462, stu_CELoss: 1.4392 DKDLoss: 0.7070 
2022-05-02 10:40:40 - train: epoch 0035, iter [00500, 05004], lr: 0.010000, loss: 2.2498, stu_CELoss: 1.5486 DKDLoss: 0.7011 
2022-05-02 10:41:14 - train: epoch 0035, iter [00600, 05004], lr: 0.010000, loss: 2.2881, stu_CELoss: 1.4977 DKDLoss: 0.7904 
2022-05-02 10:41:49 - train: epoch 0035, iter [00700, 05004], lr: 0.010000, loss: 2.3134, stu_CELoss: 1.4959 DKDLoss: 0.8175 
2022-05-02 10:42:22 - train: epoch 0035, iter [00800, 05004], lr: 0.010000, loss: 2.3271, stu_CELoss: 1.5680 DKDLoss: 0.7591 
2022-05-02 10:42:57 - train: epoch 0035, iter [00900, 05004], lr: 0.010000, loss: 2.6058, stu_CELoss: 1.7813 DKDLoss: 0.8245 
2022-05-02 10:43:31 - train: epoch 0035, iter [01000, 05004], lr: 0.010000, loss: 2.0828, stu_CELoss: 1.3621 DKDLoss: 0.7206 
2022-05-02 10:44:06 - train: epoch 0035, iter [01100, 05004], lr: 0.010000, loss: 2.4887, stu_CELoss: 1.6843 DKDLoss: 0.8044 
2022-05-02 10:44:40 - train: epoch 0035, iter [01200, 05004], lr: 0.010000, loss: 2.3524, stu_CELoss: 1.4626 DKDLoss: 0.8899 
2022-05-02 10:45:14 - train: epoch 0035, iter [01300, 05004], lr: 0.010000, loss: 2.4617, stu_CELoss: 1.6771 DKDLoss: 0.7847 
2022-05-02 10:45:48 - train: epoch 0035, iter [01400, 05004], lr: 0.010000, loss: 2.4667, stu_CELoss: 1.6582 DKDLoss: 0.8086 
2022-05-02 10:46:22 - train: epoch 0035, iter [01500, 05004], lr: 0.010000, loss: 2.4834, stu_CELoss: 1.6623 DKDLoss: 0.8211 
2022-05-02 10:46:58 - train: epoch 0035, iter [01600, 05004], lr: 0.010000, loss: 2.2220, stu_CELoss: 1.4785 DKDLoss: 0.7435 
2022-05-02 10:47:30 - train: epoch 0035, iter [01700, 05004], lr: 0.010000, loss: 2.1913, stu_CELoss: 1.3638 DKDLoss: 0.8275 
2022-05-02 10:48:05 - train: epoch 0035, iter [01800, 05004], lr: 0.010000, loss: 2.6759, stu_CELoss: 1.8201 DKDLoss: 0.8558 
2022-05-02 10:48:40 - train: epoch 0035, iter [01900, 05004], lr: 0.010000, loss: 2.4437, stu_CELoss: 1.6632 DKDLoss: 0.7806 
2022-05-02 10:49:14 - train: epoch 0035, iter [02000, 05004], lr: 0.010000, loss: 2.4768, stu_CELoss: 1.6427 DKDLoss: 0.8341 
2022-05-02 10:49:51 - train: epoch 0035, iter [02100, 05004], lr: 0.010000, loss: 2.4937, stu_CELoss: 1.6735 DKDLoss: 0.8202 
2022-05-02 10:50:28 - train: epoch 0035, iter [02200, 05004], lr: 0.010000, loss: 2.3379, stu_CELoss: 1.5440 DKDLoss: 0.7939 
2022-05-02 10:51:06 - train: epoch 0035, iter [02300, 05004], lr: 0.010000, loss: 2.2542, stu_CELoss: 1.5618 DKDLoss: 0.6924 
2022-05-02 10:51:42 - train: epoch 0035, iter [02400, 05004], lr: 0.010000, loss: 2.4179, stu_CELoss: 1.6227 DKDLoss: 0.7952 
2022-05-02 10:52:21 - train: epoch 0035, iter [02500, 05004], lr: 0.010000, loss: 2.4227, stu_CELoss: 1.6409 DKDLoss: 0.7819 
2022-05-02 10:52:58 - train: epoch 0035, iter [02600, 05004], lr: 0.010000, loss: 2.3384, stu_CELoss: 1.5074 DKDLoss: 0.8309 
2022-05-02 10:53:35 - train: epoch 0035, iter [02700, 05004], lr: 0.010000, loss: 2.4763, stu_CELoss: 1.7129 DKDLoss: 0.7634 
2022-05-02 10:54:09 - train: epoch 0035, iter [02800, 05004], lr: 0.010000, loss: 2.5880, stu_CELoss: 1.7241 DKDLoss: 0.8639 
2022-05-02 10:54:43 - train: epoch 0035, iter [02900, 05004], lr: 0.010000, loss: 2.2979, stu_CELoss: 1.5137 DKDLoss: 0.7843 
2022-05-02 10:55:17 - train: epoch 0035, iter [03000, 05004], lr: 0.010000, loss: 2.2239, stu_CELoss: 1.4660 DKDLoss: 0.7578 
2022-05-02 10:55:50 - train: epoch 0035, iter [03100, 05004], lr: 0.010000, loss: 2.5079, stu_CELoss: 1.7506 DKDLoss: 0.7573 
2022-05-02 10:56:25 - train: epoch 0035, iter [03200, 05004], lr: 0.010000, loss: 2.3831, stu_CELoss: 1.5913 DKDLoss: 0.7918 
2022-05-02 10:56:58 - train: epoch 0035, iter [03300, 05004], lr: 0.010000, loss: 2.4209, stu_CELoss: 1.6488 DKDLoss: 0.7721 
2022-05-02 10:57:32 - train: epoch 0035, iter [03400, 05004], lr: 0.010000, loss: 2.5633, stu_CELoss: 1.7380 DKDLoss: 0.8253 
2022-05-02 10:58:06 - train: epoch 0035, iter [03500, 05004], lr: 0.010000, loss: 2.0025, stu_CELoss: 1.3486 DKDLoss: 0.6539 
2022-05-02 10:58:41 - train: epoch 0035, iter [03600, 05004], lr: 0.010000, loss: 2.5352, stu_CELoss: 1.6529 DKDLoss: 0.8822 
2022-05-02 10:59:15 - train: epoch 0035, iter [03700, 05004], lr: 0.010000, loss: 2.3404, stu_CELoss: 1.5120 DKDLoss: 0.8284 
2022-05-02 10:59:49 - train: epoch 0035, iter [03800, 05004], lr: 0.010000, loss: 2.0820, stu_CELoss: 1.3396 DKDLoss: 0.7424 
2022-05-02 11:00:23 - train: epoch 0035, iter [03900, 05004], lr: 0.010000, loss: 2.4633, stu_CELoss: 1.6482 DKDLoss: 0.8151 
2022-05-02 11:00:58 - train: epoch 0035, iter [04000, 05004], lr: 0.010000, loss: 2.2542, stu_CELoss: 1.4915 DKDLoss: 0.7627 
2022-05-02 11:01:32 - train: epoch 0035, iter [04100, 05004], lr: 0.010000, loss: 2.4136, stu_CELoss: 1.6063 DKDLoss: 0.8073 
2022-05-02 11:02:06 - train: epoch 0035, iter [04200, 05004], lr: 0.010000, loss: 2.2564, stu_CELoss: 1.4827 DKDLoss: 0.7737 
2022-05-02 11:02:40 - train: epoch 0035, iter [04300, 05004], lr: 0.010000, loss: 2.5677, stu_CELoss: 1.6887 DKDLoss: 0.8790 
2022-05-02 11:03:15 - train: epoch 0035, iter [04400, 05004], lr: 0.010000, loss: 2.5906, stu_CELoss: 1.7872 DKDLoss: 0.8034 
2022-05-02 11:03:48 - train: epoch 0035, iter [04500, 05004], lr: 0.010000, loss: 2.4203, stu_CELoss: 1.6264 DKDLoss: 0.7940 
2022-05-02 11:04:22 - train: epoch 0035, iter [04600, 05004], lr: 0.010000, loss: 2.3863, stu_CELoss: 1.6046 DKDLoss: 0.7817 
2022-05-02 11:04:57 - train: epoch 0035, iter [04700, 05004], lr: 0.010000, loss: 2.5959, stu_CELoss: 1.7345 DKDLoss: 0.8614 
2022-05-02 11:05:30 - train: epoch 0035, iter [04800, 05004], lr: 0.010000, loss: 2.4334, stu_CELoss: 1.6499 DKDLoss: 0.7835 
2022-05-02 11:06:05 - train: epoch 0035, iter [04900, 05004], lr: 0.010000, loss: 2.2749, stu_CELoss: 1.5049 DKDLoss: 0.7700 
2022-05-02 11:06:38 - train: epoch 0035, iter [05000, 05004], lr: 0.010000, loss: 2.3158, stu_CELoss: 1.5559 DKDLoss: 0.7599 
2022-05-02 11:06:39 - train: epoch 035, train_loss: 2.3858
2022-05-02 11:09:10 - eval: epoch: 035, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 67.080%, stu_acc5: 87.682%, stu_test_loss: 1.3426
2022-05-02 11:09:11 - until epoch: 035, tea_best_acc1: 73.944%, stu_best_acc1: 67.080%
2022-05-02 11:09:11 - epoch 036 lr: 0.010000000000000002
2022-05-02 11:09:50 - train: epoch 0036, iter [00100, 05004], lr: 0.010000, loss: 2.4562, stu_CELoss: 1.6532 DKDLoss: 0.8031 
2022-05-02 11:10:24 - train: epoch 0036, iter [00200, 05004], lr: 0.010000, loss: 2.1438, stu_CELoss: 1.3061 DKDLoss: 0.8377 
2022-05-02 11:10:58 - train: epoch 0036, iter [00300, 05004], lr: 0.010000, loss: 2.0332, stu_CELoss: 1.3220 DKDLoss: 0.7112 
2022-05-02 11:11:32 - train: epoch 0036, iter [00400, 05004], lr: 0.010000, loss: 2.2690, stu_CELoss: 1.5145 DKDLoss: 0.7545 
2022-05-02 11:12:05 - train: epoch 0036, iter [00500, 05004], lr: 0.010000, loss: 2.2017, stu_CELoss: 1.4645 DKDLoss: 0.7371 
2022-05-02 11:12:42 - train: epoch 0036, iter [00600, 05004], lr: 0.010000, loss: 2.2532, stu_CELoss: 1.4974 DKDLoss: 0.7559 
2022-05-02 11:13:14 - train: epoch 0036, iter [00700, 05004], lr: 0.010000, loss: 2.2904, stu_CELoss: 1.4941 DKDLoss: 0.7962 
2022-05-02 11:13:49 - train: epoch 0036, iter [00800, 05004], lr: 0.010000, loss: 2.3173, stu_CELoss: 1.5011 DKDLoss: 0.8163 
2022-05-02 11:14:22 - train: epoch 0036, iter [00900, 05004], lr: 0.010000, loss: 2.3685, stu_CELoss: 1.5537 DKDLoss: 0.8147 
2022-05-02 11:14:56 - train: epoch 0036, iter [01000, 05004], lr: 0.010000, loss: 2.3105, stu_CELoss: 1.5096 DKDLoss: 0.8009 
2022-05-02 11:15:30 - train: epoch 0036, iter [01100, 05004], lr: 0.010000, loss: 2.2852, stu_CELoss: 1.5239 DKDLoss: 0.7613 
2022-05-02 11:16:04 - train: epoch 0036, iter [01200, 05004], lr: 0.010000, loss: 2.3851, stu_CELoss: 1.6301 DKDLoss: 0.7549 
2022-05-02 11:16:37 - train: epoch 0036, iter [01300, 05004], lr: 0.010000, loss: 2.4593, stu_CELoss: 1.6093 DKDLoss: 0.8500 
2022-05-02 11:17:11 - train: epoch 0036, iter [01400, 05004], lr: 0.010000, loss: 2.3955, stu_CELoss: 1.6209 DKDLoss: 0.7745 
2022-05-02 11:17:45 - train: epoch 0036, iter [01500, 05004], lr: 0.010000, loss: 2.3306, stu_CELoss: 1.5352 DKDLoss: 0.7954 
2022-05-02 11:18:18 - train: epoch 0036, iter [01600, 05004], lr: 0.010000, loss: 2.5224, stu_CELoss: 1.7208 DKDLoss: 0.8016 
2022-05-02 11:18:53 - train: epoch 0036, iter [01700, 05004], lr: 0.010000, loss: 2.2126, stu_CELoss: 1.5152 DKDLoss: 0.6974 
2022-05-02 11:19:27 - train: epoch 0036, iter [01800, 05004], lr: 0.010000, loss: 2.1631, stu_CELoss: 1.4577 DKDLoss: 0.7055 
2022-05-02 11:20:01 - train: epoch 0036, iter [01900, 05004], lr: 0.010000, loss: 2.6602, stu_CELoss: 1.8424 DKDLoss: 0.8178 
2022-05-02 11:20:34 - train: epoch 0036, iter [02000, 05004], lr: 0.010000, loss: 2.2689, stu_CELoss: 1.5515 DKDLoss: 0.7175 
2022-05-02 11:21:09 - train: epoch 0036, iter [02100, 05004], lr: 0.010000, loss: 2.3503, stu_CELoss: 1.5855 DKDLoss: 0.7648 
2022-05-02 11:21:43 - train: epoch 0036, iter [02200, 05004], lr: 0.010000, loss: 2.2863, stu_CELoss: 1.5476 DKDLoss: 0.7387 
2022-05-02 11:22:17 - train: epoch 0036, iter [02300, 05004], lr: 0.010000, loss: 2.4337, stu_CELoss: 1.7233 DKDLoss: 0.7104 
2022-05-02 11:22:51 - train: epoch 0036, iter [02400, 05004], lr: 0.010000, loss: 2.6018, stu_CELoss: 1.8212 DKDLoss: 0.7805 
2022-05-02 11:23:25 - train: epoch 0036, iter [02500, 05004], lr: 0.010000, loss: 2.1984, stu_CELoss: 1.4524 DKDLoss: 0.7460 
2022-05-02 11:23:59 - train: epoch 0036, iter [02600, 05004], lr: 0.010000, loss: 2.5313, stu_CELoss: 1.7144 DKDLoss: 0.8169 
2022-05-02 11:24:32 - train: epoch 0036, iter [02700, 05004], lr: 0.010000, loss: 2.2657, stu_CELoss: 1.5601 DKDLoss: 0.7056 
2022-05-02 11:25:06 - train: epoch 0036, iter [02800, 05004], lr: 0.010000, loss: 2.4092, stu_CELoss: 1.5907 DKDLoss: 0.8186 
2022-05-02 11:25:40 - train: epoch 0036, iter [02900, 05004], lr: 0.010000, loss: 2.1996, stu_CELoss: 1.4623 DKDLoss: 0.7372 
2022-05-02 11:26:13 - train: epoch 0036, iter [03000, 05004], lr: 0.010000, loss: 2.3076, stu_CELoss: 1.4860 DKDLoss: 0.8216 
2022-05-02 11:26:46 - train: epoch 0036, iter [03100, 05004], lr: 0.010000, loss: 2.5122, stu_CELoss: 1.6903 DKDLoss: 0.8220 
2022-05-02 11:27:20 - train: epoch 0036, iter [03200, 05004], lr: 0.010000, loss: 2.3933, stu_CELoss: 1.6721 DKDLoss: 0.7212 
2022-05-02 11:27:52 - train: epoch 0036, iter [03300, 05004], lr: 0.010000, loss: 2.3251, stu_CELoss: 1.5348 DKDLoss: 0.7904 
2022-05-02 11:28:25 - train: epoch 0036, iter [03400, 05004], lr: 0.010000, loss: 2.3003, stu_CELoss: 1.5117 DKDLoss: 0.7886 
2022-05-02 11:28:58 - train: epoch 0036, iter [03500, 05004], lr: 0.010000, loss: 2.5675, stu_CELoss: 1.7611 DKDLoss: 0.8064 
2022-05-02 11:29:31 - train: epoch 0036, iter [03600, 05004], lr: 0.010000, loss: 2.3086, stu_CELoss: 1.5495 DKDLoss: 0.7592 
2022-05-02 11:30:05 - train: epoch 0036, iter [03700, 05004], lr: 0.010000, loss: 2.3029, stu_CELoss: 1.5343 DKDLoss: 0.7687 
2022-05-02 11:30:38 - train: epoch 0036, iter [03800, 05004], lr: 0.010000, loss: 2.5915, stu_CELoss: 1.7974 DKDLoss: 0.7941 
2022-05-02 11:31:11 - train: epoch 0036, iter [03900, 05004], lr: 0.010000, loss: 2.3116, stu_CELoss: 1.5601 DKDLoss: 0.7515 
2022-05-02 11:31:46 - train: epoch 0036, iter [04000, 05004], lr: 0.010000, loss: 2.2374, stu_CELoss: 1.5031 DKDLoss: 0.7342 
2022-05-02 11:32:21 - train: epoch 0036, iter [04100, 05004], lr: 0.010000, loss: 2.2478, stu_CELoss: 1.5117 DKDLoss: 0.7361 
2022-05-02 11:32:55 - train: epoch 0036, iter [04200, 05004], lr: 0.010000, loss: 2.3907, stu_CELoss: 1.6539 DKDLoss: 0.7369 
2022-05-02 11:33:28 - train: epoch 0036, iter [04300, 05004], lr: 0.010000, loss: 2.1599, stu_CELoss: 1.4611 DKDLoss: 0.6988 
2022-05-02 11:34:02 - train: epoch 0036, iter [04400, 05004], lr: 0.010000, loss: 2.4320, stu_CELoss: 1.6706 DKDLoss: 0.7614 
2022-05-02 11:34:36 - train: epoch 0036, iter [04500, 05004], lr: 0.010000, loss: 2.2396, stu_CELoss: 1.4985 DKDLoss: 0.7411 
2022-05-02 11:35:09 - train: epoch 0036, iter [04600, 05004], lr: 0.010000, loss: 2.1922, stu_CELoss: 1.4531 DKDLoss: 0.7391 
2022-05-02 11:35:44 - train: epoch 0036, iter [04700, 05004], lr: 0.010000, loss: 2.3406, stu_CELoss: 1.5383 DKDLoss: 0.8023 
2022-05-02 11:36:18 - train: epoch 0036, iter [04800, 05004], lr: 0.010000, loss: 2.4624, stu_CELoss: 1.6170 DKDLoss: 0.8454 
2022-05-02 11:36:52 - train: epoch 0036, iter [04900, 05004], lr: 0.010000, loss: 2.5661, stu_CELoss: 1.6813 DKDLoss: 0.8848 
2022-05-02 11:37:25 - train: epoch 0036, iter [05000, 05004], lr: 0.010000, loss: 2.4732, stu_CELoss: 1.5886 DKDLoss: 0.8846 
2022-05-02 11:37:25 - train: epoch 036, train_loss: 2.3609
2022-05-02 11:39:56 - eval: epoch: 036, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 67.250%, stu_acc5: 87.816%, stu_test_loss: 1.3371
2022-05-02 11:39:56 - until epoch: 036, tea_best_acc1: 73.944%, stu_best_acc1: 67.250%
2022-05-02 11:39:56 - epoch 037 lr: 0.010000000000000002
2022-05-02 11:40:35 - train: epoch 0037, iter [00100, 05004], lr: 0.010000, loss: 1.9955, stu_CELoss: 1.3378 DKDLoss: 0.6577 
2022-05-02 11:41:10 - train: epoch 0037, iter [00200, 05004], lr: 0.010000, loss: 2.2127, stu_CELoss: 1.4913 DKDLoss: 0.7214 
2022-05-02 11:41:44 - train: epoch 0037, iter [00300, 05004], lr: 0.010000, loss: 2.2296, stu_CELoss: 1.4899 DKDLoss: 0.7397 
2022-05-02 11:42:18 - train: epoch 0037, iter [00400, 05004], lr: 0.010000, loss: 2.2230, stu_CELoss: 1.4147 DKDLoss: 0.8083 
2022-05-02 11:42:51 - train: epoch 0037, iter [00500, 05004], lr: 0.010000, loss: 2.7056, stu_CELoss: 1.8800 DKDLoss: 0.8257 
2022-05-02 11:43:25 - train: epoch 0037, iter [00600, 05004], lr: 0.010000, loss: 2.5602, stu_CELoss: 1.8586 DKDLoss: 0.7016 
2022-05-02 11:43:58 - train: epoch 0037, iter [00700, 05004], lr: 0.010000, loss: 2.7142, stu_CELoss: 1.8678 DKDLoss: 0.8464 
2022-05-02 11:44:32 - train: epoch 0037, iter [00800, 05004], lr: 0.010000, loss: 2.1246, stu_CELoss: 1.3518 DKDLoss: 0.7728 
2022-05-02 11:45:05 - train: epoch 0037, iter [00900, 05004], lr: 0.010000, loss: 2.4030, stu_CELoss: 1.6632 DKDLoss: 0.7398 
2022-05-02 11:45:40 - train: epoch 0037, iter [01000, 05004], lr: 0.010000, loss: 2.2315, stu_CELoss: 1.5418 DKDLoss: 0.6897 
2022-05-02 11:46:13 - train: epoch 0037, iter [01100, 05004], lr: 0.010000, loss: 2.3715, stu_CELoss: 1.6023 DKDLoss: 0.7693 
2022-05-02 11:46:47 - train: epoch 0037, iter [01200, 05004], lr: 0.010000, loss: 2.3335, stu_CELoss: 1.5891 DKDLoss: 0.7444 
2022-05-02 11:47:19 - train: epoch 0037, iter [01300, 05004], lr: 0.010000, loss: 2.5353, stu_CELoss: 1.7536 DKDLoss: 0.7817 
2022-05-02 11:47:54 - train: epoch 0037, iter [01400, 05004], lr: 0.010000, loss: 2.7184, stu_CELoss: 1.8803 DKDLoss: 0.8381 
2022-05-02 11:48:27 - train: epoch 0037, iter [01500, 05004], lr: 0.010000, loss: 2.2482, stu_CELoss: 1.4840 DKDLoss: 0.7642 
2022-05-02 11:49:01 - train: epoch 0037, iter [01600, 05004], lr: 0.010000, loss: 2.4220, stu_CELoss: 1.6160 DKDLoss: 0.8061 
2022-05-02 11:49:35 - train: epoch 0037, iter [01700, 05004], lr: 0.010000, loss: 2.3630, stu_CELoss: 1.5177 DKDLoss: 0.8454 
2022-05-02 11:50:09 - train: epoch 0037, iter [01800, 05004], lr: 0.010000, loss: 2.3832, stu_CELoss: 1.6670 DKDLoss: 0.7161 
2022-05-02 11:50:43 - train: epoch 0037, iter [01900, 05004], lr: 0.010000, loss: 2.2717, stu_CELoss: 1.5032 DKDLoss: 0.7685 
2022-05-02 11:51:18 - train: epoch 0037, iter [02000, 05004], lr: 0.010000, loss: 2.3474, stu_CELoss: 1.5672 DKDLoss: 0.7803 
2022-05-02 11:51:52 - train: epoch 0037, iter [02100, 05004], lr: 0.010000, loss: 2.3110, stu_CELoss: 1.4860 DKDLoss: 0.8250 
2022-05-02 11:52:27 - train: epoch 0037, iter [02200, 05004], lr: 0.010000, loss: 2.3171, stu_CELoss: 1.5279 DKDLoss: 0.7892 
2022-05-02 11:53:01 - train: epoch 0037, iter [02300, 05004], lr: 0.010000, loss: 2.1180, stu_CELoss: 1.4002 DKDLoss: 0.7178 
2022-05-02 11:53:37 - train: epoch 0037, iter [02400, 05004], lr: 0.010000, loss: 2.5385, stu_CELoss: 1.6627 DKDLoss: 0.8758 
2022-05-02 11:54:14 - train: epoch 0037, iter [02500, 05004], lr: 0.010000, loss: 2.5334, stu_CELoss: 1.7466 DKDLoss: 0.7868 
2022-05-02 11:54:52 - train: epoch 0037, iter [02600, 05004], lr: 0.010000, loss: 2.8599, stu_CELoss: 1.9915 DKDLoss: 0.8684 
2022-05-02 11:55:30 - train: epoch 0037, iter [02700, 05004], lr: 0.010000, loss: 2.7047, stu_CELoss: 1.9074 DKDLoss: 0.7973 
2022-05-02 11:56:06 - train: epoch 0037, iter [02800, 05004], lr: 0.010000, loss: 2.3777, stu_CELoss: 1.5999 DKDLoss: 0.7779 
2022-05-02 11:56:44 - train: epoch 0037, iter [02900, 05004], lr: 0.010000, loss: 2.1501, stu_CELoss: 1.4636 DKDLoss: 0.6866 
2022-05-02 11:57:19 - train: epoch 0037, iter [03000, 05004], lr: 0.010000, loss: 2.5438, stu_CELoss: 1.7957 DKDLoss: 0.7481 
2022-05-02 11:57:53 - train: epoch 0037, iter [03100, 05004], lr: 0.010000, loss: 2.2853, stu_CELoss: 1.5101 DKDLoss: 0.7752 
2022-05-02 11:58:26 - train: epoch 0037, iter [03200, 05004], lr: 0.010000, loss: 2.6525, stu_CELoss: 1.8290 DKDLoss: 0.8234 
2022-05-02 11:59:00 - train: epoch 0037, iter [03300, 05004], lr: 0.010000, loss: 2.3136, stu_CELoss: 1.5566 DKDLoss: 0.7570 
2022-05-02 11:59:33 - train: epoch 0037, iter [03400, 05004], lr: 0.010000, loss: 2.0982, stu_CELoss: 1.3525 DKDLoss: 0.7457 
2022-05-02 12:00:09 - train: epoch 0037, iter [03500, 05004], lr: 0.010000, loss: 2.3994, stu_CELoss: 1.5734 DKDLoss: 0.8260 
2022-05-02 12:00:41 - train: epoch 0037, iter [03600, 05004], lr: 0.010000, loss: 2.3055, stu_CELoss: 1.5669 DKDLoss: 0.7386 
2022-05-02 12:01:16 - train: epoch 0037, iter [03700, 05004], lr: 0.010000, loss: 2.3020, stu_CELoss: 1.5546 DKDLoss: 0.7474 
2022-05-02 12:01:49 - train: epoch 0037, iter [03800, 05004], lr: 0.010000, loss: 2.4104, stu_CELoss: 1.6310 DKDLoss: 0.7794 
2022-05-02 12:02:22 - train: epoch 0037, iter [03900, 05004], lr: 0.010000, loss: 2.5522, stu_CELoss: 1.8525 DKDLoss: 0.6997 
2022-05-02 12:02:57 - train: epoch 0037, iter [04000, 05004], lr: 0.010000, loss: 2.5467, stu_CELoss: 1.6985 DKDLoss: 0.8481 
2022-05-02 12:03:30 - train: epoch 0037, iter [04100, 05004], lr: 0.010000, loss: 2.4775, stu_CELoss: 1.5996 DKDLoss: 0.8780 
2022-05-02 12:04:03 - train: epoch 0037, iter [04200, 05004], lr: 0.010000, loss: 2.3260, stu_CELoss: 1.6022 DKDLoss: 0.7238 
2022-05-02 12:04:36 - train: epoch 0037, iter [04300, 05004], lr: 0.010000, loss: 2.3153, stu_CELoss: 1.5672 DKDLoss: 0.7481 
2022-05-02 12:05:10 - train: epoch 0037, iter [04400, 05004], lr: 0.010000, loss: 2.2480, stu_CELoss: 1.5302 DKDLoss: 0.7178 
2022-05-02 12:05:44 - train: epoch 0037, iter [04500, 05004], lr: 0.010000, loss: 2.4969, stu_CELoss: 1.6168 DKDLoss: 0.8801 
2022-05-02 12:06:18 - train: epoch 0037, iter [04600, 05004], lr: 0.010000, loss: 2.2354, stu_CELoss: 1.4762 DKDLoss: 0.7591 
2022-05-02 12:06:51 - train: epoch 0037, iter [04700, 05004], lr: 0.010000, loss: 2.4659, stu_CELoss: 1.6250 DKDLoss: 0.8410 
2022-05-02 12:07:25 - train: epoch 0037, iter [04800, 05004], lr: 0.010000, loss: 2.2920, stu_CELoss: 1.5055 DKDLoss: 0.7865 
2022-05-02 12:07:59 - train: epoch 0037, iter [04900, 05004], lr: 0.010000, loss: 2.3713, stu_CELoss: 1.6223 DKDLoss: 0.7489 
2022-05-02 12:08:31 - train: epoch 0037, iter [05000, 05004], lr: 0.010000, loss: 2.5168, stu_CELoss: 1.6790 DKDLoss: 0.8378 
2022-05-02 12:08:32 - train: epoch 037, train_loss: 2.3503
2022-05-02 12:11:03 - eval: epoch: 037, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 67.128%, stu_acc5: 87.686%, stu_test_loss: 1.3457
2022-05-02 12:11:04 - until epoch: 037, tea_best_acc1: 73.944%, stu_best_acc1: 67.250%
2022-05-02 12:11:04 - epoch 038 lr: 0.010000000000000002
2022-05-02 12:11:42 - train: epoch 0038, iter [00100, 05004], lr: 0.010000, loss: 2.2442, stu_CELoss: 1.4756 DKDLoss: 0.7686 
2022-05-02 12:12:17 - train: epoch 0038, iter [00200, 05004], lr: 0.010000, loss: 2.3200, stu_CELoss: 1.6288 DKDLoss: 0.6912 
2022-05-02 12:12:50 - train: epoch 0038, iter [00300, 05004], lr: 0.010000, loss: 2.0813, stu_CELoss: 1.3348 DKDLoss: 0.7465 
2022-05-02 12:13:25 - train: epoch 0038, iter [00400, 05004], lr: 0.010000, loss: 2.1771, stu_CELoss: 1.4361 DKDLoss: 0.7410 
2022-05-02 12:13:58 - train: epoch 0038, iter [00500, 05004], lr: 0.010000, loss: 2.1616, stu_CELoss: 1.4056 DKDLoss: 0.7561 
2022-05-02 12:14:33 - train: epoch 0038, iter [00600, 05004], lr: 0.010000, loss: 2.5960, stu_CELoss: 1.7359 DKDLoss: 0.8601 
2022-05-02 12:15:07 - train: epoch 0038, iter [00700, 05004], lr: 0.010000, loss: 2.1233, stu_CELoss: 1.3828 DKDLoss: 0.7405 
2022-05-02 12:15:41 - train: epoch 0038, iter [00800, 05004], lr: 0.010000, loss: 2.2574, stu_CELoss: 1.4683 DKDLoss: 0.7891 
2022-05-02 12:16:16 - train: epoch 0038, iter [00900, 05004], lr: 0.010000, loss: 2.3150, stu_CELoss: 1.6171 DKDLoss: 0.6979 
2022-05-02 12:16:49 - train: epoch 0038, iter [01000, 05004], lr: 0.010000, loss: 2.4657, stu_CELoss: 1.7277 DKDLoss: 0.7380 
2022-05-02 12:17:24 - train: epoch 0038, iter [01100, 05004], lr: 0.010000, loss: 2.6345, stu_CELoss: 1.7688 DKDLoss: 0.8657 
2022-05-02 12:17:57 - train: epoch 0038, iter [01200, 05004], lr: 0.010000, loss: 2.5966, stu_CELoss: 1.7571 DKDLoss: 0.8396 
2022-05-02 12:18:32 - train: epoch 0038, iter [01300, 05004], lr: 0.010000, loss: 2.2495, stu_CELoss: 1.5147 DKDLoss: 0.7347 
2022-05-02 12:19:05 - train: epoch 0038, iter [01400, 05004], lr: 0.010000, loss: 2.0980, stu_CELoss: 1.4420 DKDLoss: 0.6560 
2022-05-02 12:19:39 - train: epoch 0038, iter [01500, 05004], lr: 0.010000, loss: 2.3379, stu_CELoss: 1.5994 DKDLoss: 0.7385 
2022-05-02 12:20:14 - train: epoch 0038, iter [01600, 05004], lr: 0.010000, loss: 2.2721, stu_CELoss: 1.5319 DKDLoss: 0.7402 
2022-05-02 12:20:47 - train: epoch 0038, iter [01700, 05004], lr: 0.010000, loss: 2.4854, stu_CELoss: 1.6513 DKDLoss: 0.8342 
2022-05-02 12:21:21 - train: epoch 0038, iter [01800, 05004], lr: 0.010000, loss: 2.4536, stu_CELoss: 1.7130 DKDLoss: 0.7406 
2022-05-02 12:21:55 - train: epoch 0038, iter [01900, 05004], lr: 0.010000, loss: 2.4290, stu_CELoss: 1.7084 DKDLoss: 0.7205 
2022-05-02 12:22:28 - train: epoch 0038, iter [02000, 05004], lr: 0.010000, loss: 2.3409, stu_CELoss: 1.6600 DKDLoss: 0.6809 
2022-05-02 12:23:03 - train: epoch 0038, iter [02100, 05004], lr: 0.010000, loss: 2.3320, stu_CELoss: 1.5542 DKDLoss: 0.7779 
2022-05-02 12:23:36 - train: epoch 0038, iter [02200, 05004], lr: 0.010000, loss: 2.2053, stu_CELoss: 1.4793 DKDLoss: 0.7260 
2022-05-02 12:24:10 - train: epoch 0038, iter [02300, 05004], lr: 0.010000, loss: 2.3631, stu_CELoss: 1.5265 DKDLoss: 0.8365 
2022-05-02 12:24:43 - train: epoch 0038, iter [02400, 05004], lr: 0.010000, loss: 2.6852, stu_CELoss: 1.8775 DKDLoss: 0.8077 
2022-05-02 12:25:17 - train: epoch 0038, iter [02500, 05004], lr: 0.010000, loss: 2.2876, stu_CELoss: 1.5123 DKDLoss: 0.7753 
2022-05-02 12:25:50 - train: epoch 0038, iter [02600, 05004], lr: 0.010000, loss: 2.4968, stu_CELoss: 1.6644 DKDLoss: 0.8324 
2022-05-02 12:26:26 - train: epoch 0038, iter [02700, 05004], lr: 0.010000, loss: 2.4951, stu_CELoss: 1.6898 DKDLoss: 0.8052 
2022-05-02 12:26:59 - train: epoch 0038, iter [02800, 05004], lr: 0.010000, loss: 2.6654, stu_CELoss: 1.8627 DKDLoss: 0.8027 
2022-05-02 12:27:34 - train: epoch 0038, iter [02900, 05004], lr: 0.010000, loss: 2.2762, stu_CELoss: 1.5743 DKDLoss: 0.7019 
2022-05-02 12:28:08 - train: epoch 0038, iter [03000, 05004], lr: 0.010000, loss: 2.2167, stu_CELoss: 1.5193 DKDLoss: 0.6974 
2022-05-02 12:28:43 - train: epoch 0038, iter [03100, 05004], lr: 0.010000, loss: 2.3862, stu_CELoss: 1.6679 DKDLoss: 0.7183 
2022-05-02 12:29:18 - train: epoch 0038, iter [03200, 05004], lr: 0.010000, loss: 2.0818, stu_CELoss: 1.3200 DKDLoss: 0.7617 
2022-05-02 12:29:52 - train: epoch 0038, iter [03300, 05004], lr: 0.010000, loss: 2.0773, stu_CELoss: 1.3294 DKDLoss: 0.7478 
2022-05-02 12:30:26 - train: epoch 0038, iter [03400, 05004], lr: 0.010000, loss: 2.3039, stu_CELoss: 1.4758 DKDLoss: 0.8280 
2022-05-02 12:31:02 - train: epoch 0038, iter [03500, 05004], lr: 0.010000, loss: 2.3271, stu_CELoss: 1.5726 DKDLoss: 0.7545 
2022-05-02 12:31:36 - train: epoch 0038, iter [03600, 05004], lr: 0.010000, loss: 2.3144, stu_CELoss: 1.5008 DKDLoss: 0.8136 
2022-05-02 12:32:10 - train: epoch 0038, iter [03700, 05004], lr: 0.010000, loss: 2.3732, stu_CELoss: 1.5320 DKDLoss: 0.8412 
2022-05-02 12:32:45 - train: epoch 0038, iter [03800, 05004], lr: 0.010000, loss: 2.7276, stu_CELoss: 1.8424 DKDLoss: 0.8852 
2022-05-02 12:33:20 - train: epoch 0038, iter [03900, 05004], lr: 0.010000, loss: 2.1643, stu_CELoss: 1.4232 DKDLoss: 0.7411 
2022-05-02 12:33:54 - train: epoch 0038, iter [04000, 05004], lr: 0.010000, loss: 2.2526, stu_CELoss: 1.5346 DKDLoss: 0.7180 
2022-05-02 12:34:29 - train: epoch 0038, iter [04100, 05004], lr: 0.010000, loss: 2.1184, stu_CELoss: 1.4142 DKDLoss: 0.7043 
2022-05-02 12:35:02 - train: epoch 0038, iter [04200, 05004], lr: 0.010000, loss: 2.1895, stu_CELoss: 1.4639 DKDLoss: 0.7256 
2022-05-02 12:35:37 - train: epoch 0038, iter [04300, 05004], lr: 0.010000, loss: 2.3984, stu_CELoss: 1.6668 DKDLoss: 0.7315 
2022-05-02 12:36:11 - train: epoch 0038, iter [04400, 05004], lr: 0.010000, loss: 2.4315, stu_CELoss: 1.6448 DKDLoss: 0.7867 
2022-05-02 12:36:46 - train: epoch 0038, iter [04500, 05004], lr: 0.010000, loss: 2.4586, stu_CELoss: 1.6977 DKDLoss: 0.7610 
2022-05-02 12:37:21 - train: epoch 0038, iter [04600, 05004], lr: 0.010000, loss: 2.4190, stu_CELoss: 1.7007 DKDLoss: 0.7183 
2022-05-02 12:37:56 - train: epoch 0038, iter [04700, 05004], lr: 0.010000, loss: 2.1454, stu_CELoss: 1.4857 DKDLoss: 0.6597 
2022-05-02 12:38:30 - train: epoch 0038, iter [04800, 05004], lr: 0.010000, loss: 2.2793, stu_CELoss: 1.5486 DKDLoss: 0.7308 
2022-05-02 12:39:05 - train: epoch 0038, iter [04900, 05004], lr: 0.010000, loss: 2.2624, stu_CELoss: 1.4942 DKDLoss: 0.7682 
2022-05-02 12:39:38 - train: epoch 0038, iter [05000, 05004], lr: 0.010000, loss: 2.2377, stu_CELoss: 1.4421 DKDLoss: 0.7956 
2022-05-02 12:39:39 - train: epoch 038, train_loss: 2.3403
2022-05-02 12:42:12 - eval: epoch: 038, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 67.344%, stu_acc5: 87.726%, stu_test_loss: 1.3369
2022-05-02 12:42:13 - until epoch: 038, tea_best_acc1: 73.944%, stu_best_acc1: 67.344%
2022-05-02 12:42:13 - epoch 039 lr: 0.010000000000000002
2022-05-02 12:42:51 - train: epoch 0039, iter [00100, 05004], lr: 0.010000, loss: 2.2120, stu_CELoss: 1.5001 DKDLoss: 0.7119 
2022-05-02 12:43:26 - train: epoch 0039, iter [00200, 05004], lr: 0.010000, loss: 2.4195, stu_CELoss: 1.7064 DKDLoss: 0.7131 
2022-05-02 12:44:00 - train: epoch 0039, iter [00300, 05004], lr: 0.010000, loss: 2.2997, stu_CELoss: 1.4821 DKDLoss: 0.8176 
2022-05-02 12:44:34 - train: epoch 0039, iter [00400, 05004], lr: 0.010000, loss: 2.2639, stu_CELoss: 1.5372 DKDLoss: 0.7267 
2022-05-02 12:45:09 - train: epoch 0039, iter [00500, 05004], lr: 0.010000, loss: 2.2647, stu_CELoss: 1.5616 DKDLoss: 0.7031 
2022-05-02 12:45:43 - train: epoch 0039, iter [00600, 05004], lr: 0.010000, loss: 2.1470, stu_CELoss: 1.4026 DKDLoss: 0.7444 
2022-05-02 12:46:19 - train: epoch 0039, iter [00700, 05004], lr: 0.010000, loss: 2.5456, stu_CELoss: 1.8284 DKDLoss: 0.7172 
2022-05-02 12:46:57 - train: epoch 0039, iter [00800, 05004], lr: 0.010000, loss: 2.3231, stu_CELoss: 1.5578 DKDLoss: 0.7653 
2022-05-02 12:47:33 - train: epoch 0039, iter [00900, 05004], lr: 0.010000, loss: 2.3635, stu_CELoss: 1.5929 DKDLoss: 0.7706 
2022-05-02 12:48:12 - train: epoch 0039, iter [01000, 05004], lr: 0.010000, loss: 2.2822, stu_CELoss: 1.5585 DKDLoss: 0.7236 
2022-05-02 12:48:48 - train: epoch 0039, iter [01100, 05004], lr: 0.010000, loss: 2.5795, stu_CELoss: 1.7732 DKDLoss: 0.8063 
2022-05-02 12:49:26 - train: epoch 0039, iter [01200, 05004], lr: 0.010000, loss: 2.3006, stu_CELoss: 1.4865 DKDLoss: 0.8140 
2022-05-02 12:50:04 - train: epoch 0039, iter [01300, 05004], lr: 0.010000, loss: 2.4594, stu_CELoss: 1.7002 DKDLoss: 0.7592 
2022-05-02 12:50:37 - train: epoch 0039, iter [01400, 05004], lr: 0.010000, loss: 2.3530, stu_CELoss: 1.5465 DKDLoss: 0.8065 
2022-05-02 12:51:11 - train: epoch 0039, iter [01500, 05004], lr: 0.010000, loss: 1.9393, stu_CELoss: 1.2932 DKDLoss: 0.6461 
2022-05-02 12:51:45 - train: epoch 0039, iter [01600, 05004], lr: 0.010000, loss: 2.3106, stu_CELoss: 1.5309 DKDLoss: 0.7797 
2022-05-02 12:52:19 - train: epoch 0039, iter [01700, 05004], lr: 0.010000, loss: 2.2018, stu_CELoss: 1.4681 DKDLoss: 0.7338 
2022-05-02 12:52:52 - train: epoch 0039, iter [01800, 05004], lr: 0.010000, loss: 2.5262, stu_CELoss: 1.7246 DKDLoss: 0.8016 
2022-05-02 12:53:26 - train: epoch 0039, iter [01900, 05004], lr: 0.010000, loss: 2.0322, stu_CELoss: 1.3187 DKDLoss: 0.7135 
2022-05-02 12:53:58 - train: epoch 0039, iter [02000, 05004], lr: 0.010000, loss: 2.5041, stu_CELoss: 1.5826 DKDLoss: 0.9214 
2022-05-02 12:54:32 - train: epoch 0039, iter [02100, 05004], lr: 0.010000, loss: 2.5228, stu_CELoss: 1.7569 DKDLoss: 0.7659 
2022-05-02 12:55:05 - train: epoch 0039, iter [02200, 05004], lr: 0.010000, loss: 2.2480, stu_CELoss: 1.4671 DKDLoss: 0.7809 
2022-05-02 12:55:39 - train: epoch 0039, iter [02300, 05004], lr: 0.010000, loss: 2.7372, stu_CELoss: 1.9889 DKDLoss: 0.7483 
2022-05-02 12:56:12 - train: epoch 0039, iter [02400, 05004], lr: 0.010000, loss: 2.5511, stu_CELoss: 1.7621 DKDLoss: 0.7890 
2022-05-02 12:56:45 - train: epoch 0039, iter [02500, 05004], lr: 0.010000, loss: 2.3922, stu_CELoss: 1.6987 DKDLoss: 0.6935 
2022-05-02 12:57:19 - train: epoch 0039, iter [02600, 05004], lr: 0.010000, loss: 2.1947, stu_CELoss: 1.4763 DKDLoss: 0.7184 
2022-05-02 12:57:52 - train: epoch 0039, iter [02700, 05004], lr: 0.010000, loss: 2.5527, stu_CELoss: 1.7506 DKDLoss: 0.8021 
2022-05-02 12:58:26 - train: epoch 0039, iter [02800, 05004], lr: 0.010000, loss: 2.4012, stu_CELoss: 1.5492 DKDLoss: 0.8519 
2022-05-02 12:58:59 - train: epoch 0039, iter [02900, 05004], lr: 0.010000, loss: 2.1235, stu_CELoss: 1.3968 DKDLoss: 0.7267 
2022-05-02 12:59:34 - train: epoch 0039, iter [03000, 05004], lr: 0.010000, loss: 2.3504, stu_CELoss: 1.6127 DKDLoss: 0.7377 
2022-05-02 13:00:07 - train: epoch 0039, iter [03100, 05004], lr: 0.010000, loss: 2.3082, stu_CELoss: 1.4983 DKDLoss: 0.8099 
2022-05-02 13:00:41 - train: epoch 0039, iter [03200, 05004], lr: 0.010000, loss: 2.3556, stu_CELoss: 1.5064 DKDLoss: 0.8492 
2022-05-02 13:01:14 - train: epoch 0039, iter [03300, 05004], lr: 0.010000, loss: 2.2487, stu_CELoss: 1.4989 DKDLoss: 0.7499 
2022-05-02 13:01:47 - train: epoch 0039, iter [03400, 05004], lr: 0.010000, loss: 2.4550, stu_CELoss: 1.6787 DKDLoss: 0.7763 
2022-05-02 13:02:20 - train: epoch 0039, iter [03500, 05004], lr: 0.010000, loss: 2.6184, stu_CELoss: 1.7327 DKDLoss: 0.8857 
2022-05-02 13:02:55 - train: epoch 0039, iter [03600, 05004], lr: 0.010000, loss: 2.4785, stu_CELoss: 1.7363 DKDLoss: 0.7422 
2022-05-02 13:03:27 - train: epoch 0039, iter [03700, 05004], lr: 0.010000, loss: 2.1254, stu_CELoss: 1.3993 DKDLoss: 0.7261 
2022-05-02 13:04:02 - train: epoch 0039, iter [03800, 05004], lr: 0.010000, loss: 1.9309, stu_CELoss: 1.2465 DKDLoss: 0.6844 
2022-05-02 13:04:35 - train: epoch 0039, iter [03900, 05004], lr: 0.010000, loss: 2.4413, stu_CELoss: 1.6183 DKDLoss: 0.8230 
2022-05-02 13:05:09 - train: epoch 0039, iter [04000, 05004], lr: 0.010000, loss: 2.3959, stu_CELoss: 1.6164 DKDLoss: 0.7795 
2022-05-02 13:05:42 - train: epoch 0039, iter [04100, 05004], lr: 0.010000, loss: 2.3725, stu_CELoss: 1.6227 DKDLoss: 0.7498 
2022-05-02 13:06:16 - train: epoch 0039, iter [04200, 05004], lr: 0.010000, loss: 2.5681, stu_CELoss: 1.7379 DKDLoss: 0.8302 
2022-05-02 13:06:49 - train: epoch 0039, iter [04300, 05004], lr: 0.010000, loss: 2.3319, stu_CELoss: 1.5268 DKDLoss: 0.8051 
2022-05-02 13:07:23 - train: epoch 0039, iter [04400, 05004], lr: 0.010000, loss: 2.3908, stu_CELoss: 1.5705 DKDLoss: 0.8203 
2022-05-02 13:07:57 - train: epoch 0039, iter [04500, 05004], lr: 0.010000, loss: 2.1791, stu_CELoss: 1.4553 DKDLoss: 0.7238 
2022-05-02 13:08:31 - train: epoch 0039, iter [04600, 05004], lr: 0.010000, loss: 2.4513, stu_CELoss: 1.6225 DKDLoss: 0.8288 
2022-05-02 13:09:04 - train: epoch 0039, iter [04700, 05004], lr: 0.010000, loss: 2.3092, stu_CELoss: 1.5805 DKDLoss: 0.7287 
2022-05-02 13:09:38 - train: epoch 0039, iter [04800, 05004], lr: 0.010000, loss: 2.1667, stu_CELoss: 1.4291 DKDLoss: 0.7376 
2022-05-02 13:10:10 - train: epoch 0039, iter [04900, 05004], lr: 0.010000, loss: 2.1767, stu_CELoss: 1.3574 DKDLoss: 0.8193 
2022-05-02 13:10:43 - train: epoch 0039, iter [05000, 05004], lr: 0.010000, loss: 2.4481, stu_CELoss: 1.6413 DKDLoss: 0.8069 
2022-05-02 13:10:44 - train: epoch 039, train_loss: 2.3365
2022-05-02 13:13:14 - eval: epoch: 039, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 66.836%, stu_acc5: 87.700%, stu_test_loss: 1.3416
2022-05-02 13:13:14 - until epoch: 039, tea_best_acc1: 73.944%, stu_best_acc1: 67.344%
2022-05-02 13:13:14 - epoch 040 lr: 0.010000000000000002
2022-05-02 13:13:53 - train: epoch 0040, iter [00100, 05004], lr: 0.010000, loss: 2.5405, stu_CELoss: 1.7930 DKDLoss: 0.7474 
2022-05-02 13:14:26 - train: epoch 0040, iter [00200, 05004], lr: 0.010000, loss: 2.4776, stu_CELoss: 1.6734 DKDLoss: 0.8042 
2022-05-02 13:15:00 - train: epoch 0040, iter [00300, 05004], lr: 0.010000, loss: 2.5521, stu_CELoss: 1.8234 DKDLoss: 0.7287 
2022-05-02 13:15:33 - train: epoch 0040, iter [00400, 05004], lr: 0.010000, loss: 2.0506, stu_CELoss: 1.3277 DKDLoss: 0.7229 
2022-05-02 13:16:07 - train: epoch 0040, iter [00500, 05004], lr: 0.010000, loss: 2.2132, stu_CELoss: 1.4337 DKDLoss: 0.7796 
2022-05-02 13:16:39 - train: epoch 0040, iter [00600, 05004], lr: 0.010000, loss: 2.2511, stu_CELoss: 1.4446 DKDLoss: 0.8065 
2022-05-02 13:17:14 - train: epoch 0040, iter [00700, 05004], lr: 0.010000, loss: 2.3622, stu_CELoss: 1.5861 DKDLoss: 0.7761 
2022-05-02 13:17:47 - train: epoch 0040, iter [00800, 05004], lr: 0.010000, loss: 2.2715, stu_CELoss: 1.4772 DKDLoss: 0.7943 
2022-05-02 13:18:22 - train: epoch 0040, iter [00900, 05004], lr: 0.010000, loss: 2.3206, stu_CELoss: 1.5160 DKDLoss: 0.8046 
2022-05-02 13:18:54 - train: epoch 0040, iter [01000, 05004], lr: 0.010000, loss: 2.3076, stu_CELoss: 1.4751 DKDLoss: 0.8325 
2022-05-02 13:19:28 - train: epoch 0040, iter [01100, 05004], lr: 0.010000, loss: 2.1428, stu_CELoss: 1.3786 DKDLoss: 0.7641 
2022-05-02 13:20:01 - train: epoch 0040, iter [01200, 05004], lr: 0.010000, loss: 2.1243, stu_CELoss: 1.3890 DKDLoss: 0.7353 
2022-05-02 13:20:35 - train: epoch 0040, iter [01300, 05004], lr: 0.010000, loss: 2.2046, stu_CELoss: 1.4490 DKDLoss: 0.7556 
2022-05-02 13:21:08 - train: epoch 0040, iter [01400, 05004], lr: 0.010000, loss: 2.4108, stu_CELoss: 1.6771 DKDLoss: 0.7337 
2022-05-02 13:21:41 - train: epoch 0040, iter [01500, 05004], lr: 0.010000, loss: 2.4247, stu_CELoss: 1.7529 DKDLoss: 0.6718 
2022-05-02 13:22:15 - train: epoch 0040, iter [01600, 05004], lr: 0.010000, loss: 2.3026, stu_CELoss: 1.5419 DKDLoss: 0.7606 
2022-05-02 13:22:47 - train: epoch 0040, iter [01700, 05004], lr: 0.010000, loss: 2.4838, stu_CELoss: 1.6916 DKDLoss: 0.7921 
2022-05-02 13:23:21 - train: epoch 0040, iter [01800, 05004], lr: 0.010000, loss: 2.0814, stu_CELoss: 1.4098 DKDLoss: 0.6716 
2022-05-02 13:23:56 - train: epoch 0040, iter [01900, 05004], lr: 0.010000, loss: 2.1936, stu_CELoss: 1.4516 DKDLoss: 0.7420 
2022-05-02 13:24:28 - train: epoch 0040, iter [02000, 05004], lr: 0.010000, loss: 2.3847, stu_CELoss: 1.6406 DKDLoss: 0.7441 
2022-05-02 13:25:01 - train: epoch 0040, iter [02100, 05004], lr: 0.010000, loss: 2.0965, stu_CELoss: 1.3292 DKDLoss: 0.7673 
2022-05-02 13:25:35 - train: epoch 0040, iter [02200, 05004], lr: 0.010000, loss: 2.2106, stu_CELoss: 1.5312 DKDLoss: 0.6795 
2022-05-02 13:26:09 - train: epoch 0040, iter [02300, 05004], lr: 0.010000, loss: 2.2811, stu_CELoss: 1.5751 DKDLoss: 0.7060 
2022-05-02 13:26:45 - train: epoch 0040, iter [02400, 05004], lr: 0.010000, loss: 2.4694, stu_CELoss: 1.6224 DKDLoss: 0.8470 
2022-05-02 13:27:19 - train: epoch 0040, iter [02500, 05004], lr: 0.010000, loss: 2.4880, stu_CELoss: 1.6852 DKDLoss: 0.8029 
2022-05-02 13:27:53 - train: epoch 0040, iter [02600, 05004], lr: 0.010000, loss: 2.2760, stu_CELoss: 1.5430 DKDLoss: 0.7330 
2022-05-02 13:28:27 - train: epoch 0040, iter [02700, 05004], lr: 0.010000, loss: 2.4426, stu_CELoss: 1.7119 DKDLoss: 0.7307 
2022-05-02 13:29:01 - train: epoch 0040, iter [02800, 05004], lr: 0.010000, loss: 2.3232, stu_CELoss: 1.5205 DKDLoss: 0.8027 
2022-05-02 13:29:36 - train: epoch 0040, iter [02900, 05004], lr: 0.010000, loss: 2.4360, stu_CELoss: 1.6939 DKDLoss: 0.7421 
2022-05-02 13:30:11 - train: epoch 0040, iter [03000, 05004], lr: 0.010000, loss: 2.4170, stu_CELoss: 1.6430 DKDLoss: 0.7740 
2022-05-02 13:30:44 - train: epoch 0040, iter [03100, 05004], lr: 0.010000, loss: 2.6049, stu_CELoss: 1.7626 DKDLoss: 0.8423 
2022-05-02 13:31:19 - train: epoch 0040, iter [03200, 05004], lr: 0.010000, loss: 2.6926, stu_CELoss: 1.8839 DKDLoss: 0.8087 
2022-05-02 13:31:53 - train: epoch 0040, iter [03300, 05004], lr: 0.010000, loss: 2.5582, stu_CELoss: 1.7439 DKDLoss: 0.8144 
2022-05-02 13:32:28 - train: epoch 0040, iter [03400, 05004], lr: 0.010000, loss: 2.2649, stu_CELoss: 1.4542 DKDLoss: 0.8108 
2022-05-02 13:33:03 - train: epoch 0040, iter [03500, 05004], lr: 0.010000, loss: 2.2235, stu_CELoss: 1.5455 DKDLoss: 0.6780 
2022-05-02 13:33:37 - train: epoch 0040, iter [03600, 05004], lr: 0.010000, loss: 2.2146, stu_CELoss: 1.4415 DKDLoss: 0.7730 
2022-05-02 13:34:11 - train: epoch 0040, iter [03700, 05004], lr: 0.010000, loss: 2.3640, stu_CELoss: 1.4976 DKDLoss: 0.8664 
2022-05-02 13:34:47 - train: epoch 0040, iter [03800, 05004], lr: 0.010000, loss: 2.0960, stu_CELoss: 1.3923 DKDLoss: 0.7038 
2022-05-02 13:35:25 - train: epoch 0040, iter [03900, 05004], lr: 0.010000, loss: 2.2983, stu_CELoss: 1.5896 DKDLoss: 0.7087 
2022-05-02 13:36:02 - train: epoch 0040, iter [04000, 05004], lr: 0.010000, loss: 2.3775, stu_CELoss: 1.5620 DKDLoss: 0.8155 
2022-05-02 13:36:40 - train: epoch 0040, iter [04100, 05004], lr: 0.010000, loss: 2.3195, stu_CELoss: 1.4771 DKDLoss: 0.8425 
2022-05-02 13:37:20 - train: epoch 0040, iter [04200, 05004], lr: 0.010000, loss: 2.1665, stu_CELoss: 1.3358 DKDLoss: 0.8308 
2022-05-02 13:37:57 - train: epoch 0040, iter [04300, 05004], lr: 0.010000, loss: 2.3055, stu_CELoss: 1.5618 DKDLoss: 0.7437 
2022-05-02 13:38:34 - train: epoch 0040, iter [04400, 05004], lr: 0.010000, loss: 2.4224, stu_CELoss: 1.5425 DKDLoss: 0.8798 
2022-05-02 13:39:08 - train: epoch 0040, iter [04500, 05004], lr: 0.010000, loss: 2.2370, stu_CELoss: 1.4784 DKDLoss: 0.7586 
2022-05-02 13:39:44 - train: epoch 0040, iter [04600, 05004], lr: 0.010000, loss: 2.4708, stu_CELoss: 1.6139 DKDLoss: 0.8569 
2022-05-02 13:40:19 - train: epoch 0040, iter [04700, 05004], lr: 0.010000, loss: 2.4239, stu_CELoss: 1.6162 DKDLoss: 0.8077 
2022-05-02 13:40:52 - train: epoch 0040, iter [04800, 05004], lr: 0.010000, loss: 2.3625, stu_CELoss: 1.5561 DKDLoss: 0.8064 
2022-05-02 13:41:27 - train: epoch 0040, iter [04900, 05004], lr: 0.010000, loss: 2.2972, stu_CELoss: 1.5564 DKDLoss: 0.7408 
2022-05-02 13:42:00 - train: epoch 0040, iter [05000, 05004], lr: 0.010000, loss: 2.2880, stu_CELoss: 1.5447 DKDLoss: 0.7433 
2022-05-02 13:42:01 - train: epoch 040, train_loss: 2.3293
2022-05-02 13:44:35 - eval: epoch: 040, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 66.846%, stu_acc5: 87.724%, stu_test_loss: 1.3499
2022-05-02 13:44:35 - until epoch: 040, tea_best_acc1: 73.944%, stu_best_acc1: 67.344%
2022-05-02 13:44:35 - epoch 041 lr: 0.010000000000000002
2022-05-02 13:45:15 - train: epoch 0041, iter [00100, 05004], lr: 0.010000, loss: 2.4993, stu_CELoss: 1.7320 DKDLoss: 0.7673 
2022-05-02 13:45:50 - train: epoch 0041, iter [00200, 05004], lr: 0.010000, loss: 2.6898, stu_CELoss: 1.9035 DKDLoss: 0.7863 
2022-05-02 13:46:24 - train: epoch 0041, iter [00300, 05004], lr: 0.010000, loss: 2.3956, stu_CELoss: 1.6381 DKDLoss: 0.7575 
2022-05-02 13:46:59 - train: epoch 0041, iter [00400, 05004], lr: 0.010000, loss: 2.3160, stu_CELoss: 1.5229 DKDLoss: 0.7931 
2022-05-02 13:47:33 - train: epoch 0041, iter [00500, 05004], lr: 0.010000, loss: 2.0186, stu_CELoss: 1.3106 DKDLoss: 0.7080 
2022-05-02 13:48:09 - train: epoch 0041, iter [00600, 05004], lr: 0.010000, loss: 2.5446, stu_CELoss: 1.7250 DKDLoss: 0.8196 
2022-05-02 13:48:43 - train: epoch 0041, iter [00700, 05004], lr: 0.010000, loss: 2.1214, stu_CELoss: 1.4336 DKDLoss: 0.6879 
2022-05-02 13:49:18 - train: epoch 0041, iter [00800, 05004], lr: 0.010000, loss: 2.0887, stu_CELoss: 1.4172 DKDLoss: 0.6714 
2022-05-02 13:49:52 - train: epoch 0041, iter [00900, 05004], lr: 0.010000, loss: 2.1734, stu_CELoss: 1.5005 DKDLoss: 0.6729 
2022-05-02 13:50:27 - train: epoch 0041, iter [01000, 05004], lr: 0.010000, loss: 2.3919, stu_CELoss: 1.6315 DKDLoss: 0.7604 
2022-05-02 13:51:02 - train: epoch 0041, iter [01100, 05004], lr: 0.010000, loss: 2.2406, stu_CELoss: 1.5807 DKDLoss: 0.6599 
2022-05-02 13:51:36 - train: epoch 0041, iter [01200, 05004], lr: 0.010000, loss: 2.0686, stu_CELoss: 1.3652 DKDLoss: 0.7034 
2022-05-02 13:52:11 - train: epoch 0041, iter [01300, 05004], lr: 0.010000, loss: 2.1509, stu_CELoss: 1.4080 DKDLoss: 0.7429 
2022-05-02 13:52:46 - train: epoch 0041, iter [01400, 05004], lr: 0.010000, loss: 2.4008, stu_CELoss: 1.5860 DKDLoss: 0.8148 
2022-05-02 13:53:21 - train: epoch 0041, iter [01500, 05004], lr: 0.010000, loss: 2.5280, stu_CELoss: 1.6807 DKDLoss: 0.8473 
2022-05-02 13:53:56 - train: epoch 0041, iter [01600, 05004], lr: 0.010000, loss: 1.9872, stu_CELoss: 1.2894 DKDLoss: 0.6978 
2022-05-02 13:54:31 - train: epoch 0041, iter [01700, 05004], lr: 0.010000, loss: 2.3346, stu_CELoss: 1.5400 DKDLoss: 0.7946 
2022-05-02 13:55:06 - train: epoch 0041, iter [01800, 05004], lr: 0.010000, loss: 2.3437, stu_CELoss: 1.6162 DKDLoss: 0.7275 
2022-05-02 13:55:42 - train: epoch 0041, iter [01900, 05004], lr: 0.010000, loss: 2.3730, stu_CELoss: 1.5803 DKDLoss: 0.7927 
2022-05-02 13:56:16 - train: epoch 0041, iter [02000, 05004], lr: 0.010000, loss: 2.3401, stu_CELoss: 1.4989 DKDLoss: 0.8412 
2022-05-02 13:56:52 - train: epoch 0041, iter [02100, 05004], lr: 0.010000, loss: 2.2179, stu_CELoss: 1.4396 DKDLoss: 0.7783 
2022-05-02 13:57:26 - train: epoch 0041, iter [02200, 05004], lr: 0.010000, loss: 2.0851, stu_CELoss: 1.3529 DKDLoss: 0.7322 
2022-05-02 13:58:01 - train: epoch 0041, iter [02300, 05004], lr: 0.010000, loss: 2.4026, stu_CELoss: 1.5966 DKDLoss: 0.8060 
2022-05-02 13:58:35 - train: epoch 0041, iter [02400, 05004], lr: 0.010000, loss: 2.5879, stu_CELoss: 1.7713 DKDLoss: 0.8166 
2022-05-02 13:59:09 - train: epoch 0041, iter [02500, 05004], lr: 0.010000, loss: 2.2106, stu_CELoss: 1.4865 DKDLoss: 0.7241 
2022-05-02 13:59:44 - train: epoch 0041, iter [02600, 05004], lr: 0.010000, loss: 2.6291, stu_CELoss: 1.7955 DKDLoss: 0.8336 
2022-05-02 14:00:19 - train: epoch 0041, iter [02700, 05004], lr: 0.010000, loss: 2.5140, stu_CELoss: 1.7991 DKDLoss: 0.7150 
2022-05-02 14:00:54 - train: epoch 0041, iter [02800, 05004], lr: 0.010000, loss: 2.1703, stu_CELoss: 1.4146 DKDLoss: 0.7557 
2022-05-02 14:01:30 - train: epoch 0041, iter [02900, 05004], lr: 0.010000, loss: 2.1520, stu_CELoss: 1.4502 DKDLoss: 0.7018 
2022-05-02 14:02:05 - train: epoch 0041, iter [03000, 05004], lr: 0.010000, loss: 2.4456, stu_CELoss: 1.6610 DKDLoss: 0.7846 
2022-05-02 14:02:40 - train: epoch 0041, iter [03100, 05004], lr: 0.010000, loss: 2.3540, stu_CELoss: 1.5807 DKDLoss: 0.7733 
2022-05-02 14:03:14 - train: epoch 0041, iter [03200, 05004], lr: 0.010000, loss: 2.2804, stu_CELoss: 1.5312 DKDLoss: 0.7492 
2022-05-02 14:03:49 - train: epoch 0041, iter [03300, 05004], lr: 0.010000, loss: 2.2539, stu_CELoss: 1.5052 DKDLoss: 0.7487 
2022-05-02 14:04:24 - train: epoch 0041, iter [03400, 05004], lr: 0.010000, loss: 2.2783, stu_CELoss: 1.5222 DKDLoss: 0.7561 
2022-05-02 14:05:00 - train: epoch 0041, iter [03500, 05004], lr: 0.010000, loss: 2.2805, stu_CELoss: 1.4418 DKDLoss: 0.8387 
2022-05-02 14:05:34 - train: epoch 0041, iter [03600, 05004], lr: 0.010000, loss: 2.3082, stu_CELoss: 1.6245 DKDLoss: 0.6837 
2022-05-02 14:06:09 - train: epoch 0041, iter [03700, 05004], lr: 0.010000, loss: 2.4645, stu_CELoss: 1.7118 DKDLoss: 0.7527 
2022-05-02 14:06:44 - train: epoch 0041, iter [03800, 05004], lr: 0.010000, loss: 2.1909, stu_CELoss: 1.4711 DKDLoss: 0.7199 
2022-05-02 14:07:19 - train: epoch 0041, iter [03900, 05004], lr: 0.010000, loss: 2.3643, stu_CELoss: 1.6329 DKDLoss: 0.7313 
2022-05-02 14:07:54 - train: epoch 0041, iter [04000, 05004], lr: 0.010000, loss: 2.3052, stu_CELoss: 1.4936 DKDLoss: 0.8117 
2022-05-02 14:08:29 - train: epoch 0041, iter [04100, 05004], lr: 0.010000, loss: 2.3674, stu_CELoss: 1.5655 DKDLoss: 0.8019 
2022-05-02 14:09:04 - train: epoch 0041, iter [04200, 05004], lr: 0.010000, loss: 2.1411, stu_CELoss: 1.3544 DKDLoss: 0.7868 
2022-05-02 14:09:39 - train: epoch 0041, iter [04300, 05004], lr: 0.010000, loss: 2.4303, stu_CELoss: 1.5633 DKDLoss: 0.8670 
2022-05-02 14:10:14 - train: epoch 0041, iter [04400, 05004], lr: 0.010000, loss: 2.0004, stu_CELoss: 1.3222 DKDLoss: 0.6782 
2022-05-02 14:10:50 - train: epoch 0041, iter [04500, 05004], lr: 0.010000, loss: 2.3725, stu_CELoss: 1.6461 DKDLoss: 0.7264 
2022-05-02 14:11:25 - train: epoch 0041, iter [04600, 05004], lr: 0.010000, loss: 2.4085, stu_CELoss: 1.5995 DKDLoss: 0.8091 
2022-05-02 14:11:59 - train: epoch 0041, iter [04700, 05004], lr: 0.010000, loss: 2.5968, stu_CELoss: 1.7680 DKDLoss: 0.8288 
2022-05-02 14:12:35 - train: epoch 0041, iter [04800, 05004], lr: 0.010000, loss: 2.1841, stu_CELoss: 1.4190 DKDLoss: 0.7650 
2022-05-02 14:13:10 - train: epoch 0041, iter [04900, 05004], lr: 0.010000, loss: 2.3626, stu_CELoss: 1.6187 DKDLoss: 0.7439 
2022-05-02 14:13:43 - train: epoch 0041, iter [05000, 05004], lr: 0.010000, loss: 2.3988, stu_CELoss: 1.5316 DKDLoss: 0.8672 
2022-05-02 14:13:43 - train: epoch 041, train_loss: 2.3315
2022-05-02 14:16:17 - eval: epoch: 041, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 67.142%, stu_acc5: 87.830%, stu_test_loss: 1.3449
2022-05-02 14:16:17 - until epoch: 041, tea_best_acc1: 73.944%, stu_best_acc1: 67.344%
2022-05-02 14:16:17 - epoch 042 lr: 0.010000000000000002
2022-05-02 14:16:57 - train: epoch 0042, iter [00100, 05004], lr: 0.010000, loss: 2.0771, stu_CELoss: 1.3279 DKDLoss: 0.7493 
2022-05-02 14:17:32 - train: epoch 0042, iter [00200, 05004], lr: 0.010000, loss: 2.2728, stu_CELoss: 1.5131 DKDLoss: 0.7597 
2022-05-02 14:18:06 - train: epoch 0042, iter [00300, 05004], lr: 0.010000, loss: 2.5389, stu_CELoss: 1.7611 DKDLoss: 0.7777 
2022-05-02 14:18:40 - train: epoch 0042, iter [00400, 05004], lr: 0.010000, loss: 2.0733, stu_CELoss: 1.3504 DKDLoss: 0.7229 
2022-05-02 14:19:14 - train: epoch 0042, iter [00500, 05004], lr: 0.010000, loss: 2.1033, stu_CELoss: 1.3769 DKDLoss: 0.7264 
2022-05-02 14:19:50 - train: epoch 0042, iter [00600, 05004], lr: 0.010000, loss: 2.2846, stu_CELoss: 1.5355 DKDLoss: 0.7491 
2022-05-02 14:20:24 - train: epoch 0042, iter [00700, 05004], lr: 0.010000, loss: 2.6166, stu_CELoss: 1.7259 DKDLoss: 0.8908 
2022-05-02 14:20:58 - train: epoch 0042, iter [00800, 05004], lr: 0.010000, loss: 2.3082, stu_CELoss: 1.4908 DKDLoss: 0.8175 
2022-05-02 14:21:34 - train: epoch 0042, iter [00900, 05004], lr: 0.010000, loss: 2.2500, stu_CELoss: 1.5211 DKDLoss: 0.7288 
2022-05-02 14:22:08 - train: epoch 0042, iter [01000, 05004], lr: 0.010000, loss: 2.6866, stu_CELoss: 1.8768 DKDLoss: 0.8097 
2022-05-02 14:22:44 - train: epoch 0042, iter [01100, 05004], lr: 0.010000, loss: 2.1341, stu_CELoss: 1.4143 DKDLoss: 0.7197 
2022-05-02 14:23:18 - train: epoch 0042, iter [01200, 05004], lr: 0.010000, loss: 2.0925, stu_CELoss: 1.3482 DKDLoss: 0.7443 
2022-05-02 14:23:54 - train: epoch 0042, iter [01300, 05004], lr: 0.010000, loss: 2.1803, stu_CELoss: 1.5100 DKDLoss: 0.6704 
2022-05-02 14:24:28 - train: epoch 0042, iter [01400, 05004], lr: 0.010000, loss: 2.5052, stu_CELoss: 1.7926 DKDLoss: 0.7126 
2022-05-02 14:25:04 - train: epoch 0042, iter [01500, 05004], lr: 0.010000, loss: 2.0859, stu_CELoss: 1.3508 DKDLoss: 0.7352 
2022-05-02 14:25:38 - train: epoch 0042, iter [01600, 05004], lr: 0.010000, loss: 2.4190, stu_CELoss: 1.6419 DKDLoss: 0.7771 
2022-05-02 14:26:14 - train: epoch 0042, iter [01700, 05004], lr: 0.010000, loss: 2.3488, stu_CELoss: 1.6470 DKDLoss: 0.7018 
2022-05-02 14:26:49 - train: epoch 0042, iter [01800, 05004], lr: 0.010000, loss: 2.1882, stu_CELoss: 1.4142 DKDLoss: 0.7741 
2022-05-02 14:27:24 - train: epoch 0042, iter [01900, 05004], lr: 0.010000, loss: 2.4687, stu_CELoss: 1.6405 DKDLoss: 0.8282 
2022-05-02 14:27:58 - train: epoch 0042, iter [02000, 05004], lr: 0.010000, loss: 2.3738, stu_CELoss: 1.5788 DKDLoss: 0.7950 
2022-05-02 14:28:35 - train: epoch 0042, iter [02100, 05004], lr: 0.010000, loss: 2.2150, stu_CELoss: 1.3980 DKDLoss: 0.8170 
2022-05-02 14:29:09 - train: epoch 0042, iter [02200, 05004], lr: 0.010000, loss: 2.1175, stu_CELoss: 1.3528 DKDLoss: 0.7647 
2022-05-02 14:29:45 - train: epoch 0042, iter [02300, 05004], lr: 0.010000, loss: 2.6343, stu_CELoss: 1.8352 DKDLoss: 0.7991 
2022-05-02 14:30:20 - train: epoch 0042, iter [02400, 05004], lr: 0.010000, loss: 2.3450, stu_CELoss: 1.6043 DKDLoss: 0.7407 
2022-05-02 14:30:55 - train: epoch 0042, iter [02500, 05004], lr: 0.010000, loss: 2.4936, stu_CELoss: 1.7034 DKDLoss: 0.7902 
2022-05-02 14:31:31 - train: epoch 0042, iter [02600, 05004], lr: 0.010000, loss: 2.5625, stu_CELoss: 1.7939 DKDLoss: 0.7686 
2022-05-02 14:32:06 - train: epoch 0042, iter [02700, 05004], lr: 0.010000, loss: 2.1286, stu_CELoss: 1.4061 DKDLoss: 0.7225 
2022-05-02 14:32:41 - train: epoch 0042, iter [02800, 05004], lr: 0.010000, loss: 2.1640, stu_CELoss: 1.4082 DKDLoss: 0.7559 
2022-05-02 14:33:17 - train: epoch 0042, iter [02900, 05004], lr: 0.010000, loss: 2.3089, stu_CELoss: 1.5568 DKDLoss: 0.7521 
2022-05-02 14:33:53 - train: epoch 0042, iter [03000, 05004], lr: 0.010000, loss: 2.3632, stu_CELoss: 1.5391 DKDLoss: 0.8241 
2022-05-02 14:34:27 - train: epoch 0042, iter [03100, 05004], lr: 0.010000, loss: 2.2888, stu_CELoss: 1.5253 DKDLoss: 0.7635 
2022-05-02 14:35:02 - train: epoch 0042, iter [03200, 05004], lr: 0.010000, loss: 2.4156, stu_CELoss: 1.7061 DKDLoss: 0.7095 
2022-05-02 14:35:37 - train: epoch 0042, iter [03300, 05004], lr: 0.010000, loss: 2.6276, stu_CELoss: 1.9060 DKDLoss: 0.7215 
2022-05-02 14:36:12 - train: epoch 0042, iter [03400, 05004], lr: 0.010000, loss: 2.2815, stu_CELoss: 1.4434 DKDLoss: 0.8381 
2022-05-02 14:36:47 - train: epoch 0042, iter [03500, 05004], lr: 0.010000, loss: 2.4092, stu_CELoss: 1.6204 DKDLoss: 0.7888 
2022-05-02 14:37:22 - train: epoch 0042, iter [03600, 05004], lr: 0.010000, loss: 2.4180, stu_CELoss: 1.6019 DKDLoss: 0.8162 
2022-05-02 14:37:57 - train: epoch 0042, iter [03700, 05004], lr: 0.010000, loss: 2.5186, stu_CELoss: 1.6106 DKDLoss: 0.9080 
2022-05-02 14:38:32 - train: epoch 0042, iter [03800, 05004], lr: 0.010000, loss: 2.0784, stu_CELoss: 1.3188 DKDLoss: 0.7596 
2022-05-02 14:39:07 - train: epoch 0042, iter [03900, 05004], lr: 0.010000, loss: 2.3819, stu_CELoss: 1.6018 DKDLoss: 0.7801 
2022-05-02 14:39:43 - train: epoch 0042, iter [04000, 05004], lr: 0.010000, loss: 2.2072, stu_CELoss: 1.4932 DKDLoss: 0.7140 
2022-05-02 14:40:18 - train: epoch 0042, iter [04100, 05004], lr: 0.010000, loss: 2.2990, stu_CELoss: 1.5448 DKDLoss: 0.7542 
2022-05-02 14:40:52 - train: epoch 0042, iter [04200, 05004], lr: 0.010000, loss: 2.6084, stu_CELoss: 1.8087 DKDLoss: 0.7997 
2022-05-02 14:41:28 - train: epoch 0042, iter [04300, 05004], lr: 0.010000, loss: 2.1609, stu_CELoss: 1.4442 DKDLoss: 0.7168 
2022-05-02 14:42:04 - train: epoch 0042, iter [04400, 05004], lr: 0.010000, loss: 2.1636, stu_CELoss: 1.4171 DKDLoss: 0.7464 
2022-05-02 14:42:39 - train: epoch 0042, iter [04500, 05004], lr: 0.010000, loss: 2.2364, stu_CELoss: 1.4761 DKDLoss: 0.7603 
2022-05-02 14:43:14 - train: epoch 0042, iter [04600, 05004], lr: 0.010000, loss: 2.4102, stu_CELoss: 1.6089 DKDLoss: 0.8013 
2022-05-02 14:43:50 - train: epoch 0042, iter [04700, 05004], lr: 0.010000, loss: 2.1646, stu_CELoss: 1.4082 DKDLoss: 0.7564 
2022-05-02 14:44:25 - train: epoch 0042, iter [04800, 05004], lr: 0.010000, loss: 2.5379, stu_CELoss: 1.7671 DKDLoss: 0.7708 
2022-05-02 14:45:01 - train: epoch 0042, iter [04900, 05004], lr: 0.010000, loss: 2.4039, stu_CELoss: 1.6319 DKDLoss: 0.7720 
2022-05-02 14:45:34 - train: epoch 0042, iter [05000, 05004], lr: 0.010000, loss: 2.4670, stu_CELoss: 1.6445 DKDLoss: 0.8226 
2022-05-02 14:45:35 - train: epoch 042, train_loss: 2.3367
2022-05-02 14:48:11 - eval: epoch: 042, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 67.140%, stu_acc5: 87.838%, stu_test_loss: 1.3451
2022-05-02 14:48:12 - until epoch: 042, tea_best_acc1: 73.944%, stu_best_acc1: 67.344%
2022-05-02 14:48:12 - epoch 043 lr: 0.010000000000000002
2022-05-02 14:48:52 - train: epoch 0043, iter [00100, 05004], lr: 0.010000, loss: 2.2067, stu_CELoss: 1.4983 DKDLoss: 0.7084 
2022-05-02 14:49:26 - train: epoch 0043, iter [00200, 05004], lr: 0.010000, loss: 2.6377, stu_CELoss: 1.8922 DKDLoss: 0.7454 
2022-05-02 14:50:01 - train: epoch 0043, iter [00300, 05004], lr: 0.010000, loss: 2.1420, stu_CELoss: 1.4387 DKDLoss: 0.7033 
2022-05-02 14:50:36 - train: epoch 0043, iter [00400, 05004], lr: 0.010000, loss: 2.1709, stu_CELoss: 1.3836 DKDLoss: 0.7874 
2022-05-02 14:51:12 - train: epoch 0043, iter [00500, 05004], lr: 0.010000, loss: 2.2819, stu_CELoss: 1.4757 DKDLoss: 0.8063 
2022-05-02 14:51:46 - train: epoch 0043, iter [00600, 05004], lr: 0.010000, loss: 2.3345, stu_CELoss: 1.5640 DKDLoss: 0.7706 
2022-05-02 14:52:22 - train: epoch 0043, iter [00700, 05004], lr: 0.010000, loss: 2.2329, stu_CELoss: 1.5111 DKDLoss: 0.7217 
2022-05-02 14:52:56 - train: epoch 0043, iter [00800, 05004], lr: 0.010000, loss: 2.1115, stu_CELoss: 1.4094 DKDLoss: 0.7021 
2022-05-02 14:53:32 - train: epoch 0043, iter [00900, 05004], lr: 0.010000, loss: 2.1537, stu_CELoss: 1.4648 DKDLoss: 0.6890 
2022-05-02 14:54:11 - train: epoch 0043, iter [01000, 05004], lr: 0.010000, loss: 2.6605, stu_CELoss: 1.8736 DKDLoss: 0.7869 
2022-05-02 14:54:50 - train: epoch 0043, iter [01100, 05004], lr: 0.010000, loss: 2.2161, stu_CELoss: 1.5446 DKDLoss: 0.6715 
2022-05-02 14:55:27 - train: epoch 0043, iter [01200, 05004], lr: 0.010000, loss: 2.2353, stu_CELoss: 1.5191 DKDLoss: 0.7163 
2022-05-02 14:56:05 - train: epoch 0043, iter [01300, 05004], lr: 0.010000, loss: 2.4353, stu_CELoss: 1.7443 DKDLoss: 0.6909 
2022-05-02 14:56:42 - train: epoch 0043, iter [01400, 05004], lr: 0.010000, loss: 2.2035, stu_CELoss: 1.4306 DKDLoss: 0.7729 
2022-05-02 14:57:19 - train: epoch 0043, iter [01500, 05004], lr: 0.010000, loss: 2.1364, stu_CELoss: 1.3792 DKDLoss: 0.7573 
2022-05-02 14:57:55 - train: epoch 0043, iter [01600, 05004], lr: 0.010000, loss: 2.2467, stu_CELoss: 1.4598 DKDLoss: 0.7868 
2022-05-02 14:58:29 - train: epoch 0043, iter [01700, 05004], lr: 0.010000, loss: 2.3143, stu_CELoss: 1.5389 DKDLoss: 0.7754 
2022-05-02 14:59:04 - train: epoch 0043, iter [01800, 05004], lr: 0.010000, loss: 2.4643, stu_CELoss: 1.7254 DKDLoss: 0.7389 
2022-05-02 14:59:40 - train: epoch 0043, iter [01900, 05004], lr: 0.010000, loss: 2.5385, stu_CELoss: 1.7617 DKDLoss: 0.7768 
2022-05-02 15:00:15 - train: epoch 0043, iter [02000, 05004], lr: 0.010000, loss: 2.0322, stu_CELoss: 1.3413 DKDLoss: 0.6909 
2022-05-02 15:00:50 - train: epoch 0043, iter [02100, 05004], lr: 0.010000, loss: 2.2088, stu_CELoss: 1.4904 DKDLoss: 0.7183 
2022-05-02 15:01:24 - train: epoch 0043, iter [02200, 05004], lr: 0.010000, loss: 2.5442, stu_CELoss: 1.7349 DKDLoss: 0.8093 
2022-05-02 15:01:59 - train: epoch 0043, iter [02300, 05004], lr: 0.010000, loss: 2.6591, stu_CELoss: 1.8138 DKDLoss: 0.8453 
2022-05-02 15:02:33 - train: epoch 0043, iter [02400, 05004], lr: 0.010000, loss: 2.1623, stu_CELoss: 1.3485 DKDLoss: 0.8137 
2022-05-02 15:03:09 - train: epoch 0043, iter [02500, 05004], lr: 0.010000, loss: 2.4777, stu_CELoss: 1.6474 DKDLoss: 0.8303 
2022-05-02 15:03:43 - train: epoch 0043, iter [02600, 05004], lr: 0.010000, loss: 2.1457, stu_CELoss: 1.4164 DKDLoss: 0.7293 
2022-05-02 15:04:16 - train: epoch 0043, iter [02700, 05004], lr: 0.010000, loss: 2.4264, stu_CELoss: 1.6718 DKDLoss: 0.7546 
2022-05-02 15:04:51 - train: epoch 0043, iter [02800, 05004], lr: 0.010000, loss: 2.4217, stu_CELoss: 1.6040 DKDLoss: 0.8177 
2022-05-02 15:05:26 - train: epoch 0043, iter [02900, 05004], lr: 0.010000, loss: 2.2928, stu_CELoss: 1.5013 DKDLoss: 0.7915 
2022-05-02 15:06:00 - train: epoch 0043, iter [03000, 05004], lr: 0.010000, loss: 2.5699, stu_CELoss: 1.7340 DKDLoss: 0.8359 
2022-05-02 15:06:35 - train: epoch 0043, iter [03100, 05004], lr: 0.010000, loss: 2.5514, stu_CELoss: 1.7241 DKDLoss: 0.8272 
2022-05-02 15:07:09 - train: epoch 0043, iter [03200, 05004], lr: 0.010000, loss: 2.2765, stu_CELoss: 1.4976 DKDLoss: 0.7789 
2022-05-02 15:07:43 - train: epoch 0043, iter [03300, 05004], lr: 0.010000, loss: 2.3816, stu_CELoss: 1.6475 DKDLoss: 0.7341 
2022-05-02 15:08:17 - train: epoch 0043, iter [03400, 05004], lr: 0.010000, loss: 2.2640, stu_CELoss: 1.4233 DKDLoss: 0.8407 
2022-05-02 15:08:52 - train: epoch 0043, iter [03500, 05004], lr: 0.010000, loss: 2.1915, stu_CELoss: 1.4667 DKDLoss: 0.7248 
2022-05-02 15:09:26 - train: epoch 0043, iter [03600, 05004], lr: 0.010000, loss: 2.4829, stu_CELoss: 1.6664 DKDLoss: 0.8165 
2022-05-02 15:10:01 - train: epoch 0043, iter [03700, 05004], lr: 0.010000, loss: 2.2523, stu_CELoss: 1.4784 DKDLoss: 0.7740 
2022-05-02 15:10:36 - train: epoch 0043, iter [03800, 05004], lr: 0.010000, loss: 2.7077, stu_CELoss: 1.8817 DKDLoss: 0.8260 
2022-05-02 15:11:11 - train: epoch 0043, iter [03900, 05004], lr: 0.010000, loss: 2.4492, stu_CELoss: 1.6536 DKDLoss: 0.7956 
2022-05-02 15:11:45 - train: epoch 0043, iter [04000, 05004], lr: 0.010000, loss: 2.5332, stu_CELoss: 1.7304 DKDLoss: 0.8028 
2022-05-02 15:12:19 - train: epoch 0043, iter [04100, 05004], lr: 0.010000, loss: 2.4762, stu_CELoss: 1.6043 DKDLoss: 0.8719 
2022-05-02 15:12:54 - train: epoch 0043, iter [04200, 05004], lr: 0.010000, loss: 2.4352, stu_CELoss: 1.6751 DKDLoss: 0.7600 
2022-05-02 15:13:29 - train: epoch 0043, iter [04300, 05004], lr: 0.010000, loss: 2.2259, stu_CELoss: 1.4759 DKDLoss: 0.7500 
2022-05-02 15:14:05 - train: epoch 0043, iter [04400, 05004], lr: 0.010000, loss: 2.4229, stu_CELoss: 1.6449 DKDLoss: 0.7781 
2022-05-02 15:14:39 - train: epoch 0043, iter [04500, 05004], lr: 0.010000, loss: 2.1807, stu_CELoss: 1.4336 DKDLoss: 0.7471 
2022-05-02 15:15:13 - train: epoch 0043, iter [04600, 05004], lr: 0.010000, loss: 2.3757, stu_CELoss: 1.6027 DKDLoss: 0.7731 
2022-05-02 15:15:47 - train: epoch 0043, iter [04700, 05004], lr: 0.010000, loss: 2.4167, stu_CELoss: 1.6034 DKDLoss: 0.8133 
2022-05-02 15:16:22 - train: epoch 0043, iter [04800, 05004], lr: 0.010000, loss: 2.4029, stu_CELoss: 1.5933 DKDLoss: 0.8096 
2022-05-02 15:16:56 - train: epoch 0043, iter [04900, 05004], lr: 0.010000, loss: 2.1957, stu_CELoss: 1.4721 DKDLoss: 0.7235 
2022-05-02 15:17:28 - train: epoch 0043, iter [05000, 05004], lr: 0.010000, loss: 2.4622, stu_CELoss: 1.6422 DKDLoss: 0.8200 
2022-05-02 15:17:29 - train: epoch 043, train_loss: 2.3407
2022-05-02 15:20:04 - eval: epoch: 043, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 66.972%, stu_acc5: 87.682%, stu_test_loss: 1.3488
2022-05-02 15:20:04 - until epoch: 043, tea_best_acc1: 73.944%, stu_best_acc1: 67.344%
2022-05-02 15:20:04 - epoch 044 lr: 0.010000000000000002
2022-05-02 15:20:45 - train: epoch 0044, iter [00100, 05004], lr: 0.010000, loss: 2.3213, stu_CELoss: 1.5622 DKDLoss: 0.7590 
2022-05-02 15:21:19 - train: epoch 0044, iter [00200, 05004], lr: 0.010000, loss: 2.3767, stu_CELoss: 1.5721 DKDLoss: 0.8046 
2022-05-02 15:21:54 - train: epoch 0044, iter [00300, 05004], lr: 0.010000, loss: 2.3231, stu_CELoss: 1.5711 DKDLoss: 0.7520 
2022-05-02 15:22:28 - train: epoch 0044, iter [00400, 05004], lr: 0.010000, loss: 2.0183, stu_CELoss: 1.3278 DKDLoss: 0.6905 
2022-05-02 15:23:03 - train: epoch 0044, iter [00500, 05004], lr: 0.010000, loss: 2.4102, stu_CELoss: 1.6168 DKDLoss: 0.7935 
2022-05-02 15:23:36 - train: epoch 0044, iter [00600, 05004], lr: 0.010000, loss: 2.0707, stu_CELoss: 1.3498 DKDLoss: 0.7210 
2022-05-02 15:24:11 - train: epoch 0044, iter [00700, 05004], lr: 0.010000, loss: 2.2667, stu_CELoss: 1.4625 DKDLoss: 0.8043 
2022-05-02 15:24:46 - train: epoch 0044, iter [00800, 05004], lr: 0.010000, loss: 2.2397, stu_CELoss: 1.4989 DKDLoss: 0.7409 
2022-05-02 15:25:20 - train: epoch 0044, iter [00900, 05004], lr: 0.010000, loss: 2.2097, stu_CELoss: 1.4915 DKDLoss: 0.7182 
2022-05-02 15:25:56 - train: epoch 0044, iter [01000, 05004], lr: 0.010000, loss: 2.1973, stu_CELoss: 1.5166 DKDLoss: 0.6807 
2022-05-02 15:26:30 - train: epoch 0044, iter [01100, 05004], lr: 0.010000, loss: 2.0303, stu_CELoss: 1.2794 DKDLoss: 0.7509 
2022-05-02 15:27:05 - train: epoch 0044, iter [01200, 05004], lr: 0.010000, loss: 2.2608, stu_CELoss: 1.5679 DKDLoss: 0.6928 
2022-05-02 15:27:40 - train: epoch 0044, iter [01300, 05004], lr: 0.010000, loss: 2.3656, stu_CELoss: 1.6371 DKDLoss: 0.7285 
2022-05-02 15:28:16 - train: epoch 0044, iter [01400, 05004], lr: 0.010000, loss: 2.2616, stu_CELoss: 1.4666 DKDLoss: 0.7950 
2022-05-02 15:28:50 - train: epoch 0044, iter [01500, 05004], lr: 0.010000, loss: 2.4278, stu_CELoss: 1.6106 DKDLoss: 0.8171 
2022-05-02 15:29:26 - train: epoch 0044, iter [01600, 05004], lr: 0.010000, loss: 2.1411, stu_CELoss: 1.3611 DKDLoss: 0.7800 
2022-05-02 15:30:01 - train: epoch 0044, iter [01700, 05004], lr: 0.010000, loss: 2.2148, stu_CELoss: 1.4075 DKDLoss: 0.8073 
2022-05-02 15:30:36 - train: epoch 0044, iter [01800, 05004], lr: 0.010000, loss: 2.2993, stu_CELoss: 1.5608 DKDLoss: 0.7385 
2022-05-02 15:31:10 - train: epoch 0044, iter [01900, 05004], lr: 0.010000, loss: 2.5191, stu_CELoss: 1.7001 DKDLoss: 0.8190 
2022-05-02 15:31:45 - train: epoch 0044, iter [02000, 05004], lr: 0.010000, loss: 2.0784, stu_CELoss: 1.3451 DKDLoss: 0.7333 
2022-05-02 15:32:20 - train: epoch 0044, iter [02100, 05004], lr: 0.010000, loss: 2.3034, stu_CELoss: 1.5817 DKDLoss: 0.7217 
2022-05-02 15:32:56 - train: epoch 0044, iter [02200, 05004], lr: 0.010000, loss: 2.3739, stu_CELoss: 1.6442 DKDLoss: 0.7297 
2022-05-02 15:33:31 - train: epoch 0044, iter [02300, 05004], lr: 0.010000, loss: 2.4338, stu_CELoss: 1.6948 DKDLoss: 0.7389 
2022-05-02 15:34:06 - train: epoch 0044, iter [02400, 05004], lr: 0.010000, loss: 2.3541, stu_CELoss: 1.5698 DKDLoss: 0.7843 
2022-05-02 15:34:40 - train: epoch 0044, iter [02500, 05004], lr: 0.010000, loss: 2.4518, stu_CELoss: 1.6846 DKDLoss: 0.7672 
2022-05-02 15:35:15 - train: epoch 0044, iter [02600, 05004], lr: 0.010000, loss: 2.3165, stu_CELoss: 1.6051 DKDLoss: 0.7114 
2022-05-02 15:35:50 - train: epoch 0044, iter [02700, 05004], lr: 0.010000, loss: 2.4976, stu_CELoss: 1.6726 DKDLoss: 0.8250 
2022-05-02 15:36:25 - train: epoch 0044, iter [02800, 05004], lr: 0.010000, loss: 2.1789, stu_CELoss: 1.4168 DKDLoss: 0.7621 
2022-05-02 15:36:58 - train: epoch 0044, iter [02900, 05004], lr: 0.010000, loss: 1.9470, stu_CELoss: 1.2798 DKDLoss: 0.6671 
2022-05-02 15:37:34 - train: epoch 0044, iter [03000, 05004], lr: 0.010000, loss: 2.2227, stu_CELoss: 1.4644 DKDLoss: 0.7582 
2022-05-02 15:38:08 - train: epoch 0044, iter [03100, 05004], lr: 0.010000, loss: 2.0180, stu_CELoss: 1.3552 DKDLoss: 0.6628 
2022-05-02 15:38:43 - train: epoch 0044, iter [03200, 05004], lr: 0.010000, loss: 2.2157, stu_CELoss: 1.4201 DKDLoss: 0.7956 
2022-05-02 15:39:17 - train: epoch 0044, iter [03300, 05004], lr: 0.010000, loss: 2.2645, stu_CELoss: 1.5432 DKDLoss: 0.7213 
2022-05-02 15:39:53 - train: epoch 0044, iter [03400, 05004], lr: 0.010000, loss: 2.3069, stu_CELoss: 1.6002 DKDLoss: 0.7067 
2022-05-02 15:40:27 - train: epoch 0044, iter [03500, 05004], lr: 0.010000, loss: 2.5000, stu_CELoss: 1.6457 DKDLoss: 0.8543 
2022-05-02 15:41:03 - train: epoch 0044, iter [03600, 05004], lr: 0.010000, loss: 2.5093, stu_CELoss: 1.7050 DKDLoss: 0.8043 
2022-05-02 15:41:37 - train: epoch 0044, iter [03700, 05004], lr: 0.010000, loss: 2.3297, stu_CELoss: 1.5826 DKDLoss: 0.7472 
2022-05-02 15:42:13 - train: epoch 0044, iter [03800, 05004], lr: 0.010000, loss: 2.0274, stu_CELoss: 1.3283 DKDLoss: 0.6991 
2022-05-02 15:42:48 - train: epoch 0044, iter [03900, 05004], lr: 0.010000, loss: 2.2716, stu_CELoss: 1.4663 DKDLoss: 0.8053 
2022-05-02 15:43:23 - train: epoch 0044, iter [04000, 05004], lr: 0.010000, loss: 2.3114, stu_CELoss: 1.5935 DKDLoss: 0.7179 
2022-05-02 15:43:57 - train: epoch 0044, iter [04100, 05004], lr: 0.010000, loss: 2.2208, stu_CELoss: 1.4461 DKDLoss: 0.7747 
2022-05-02 15:44:33 - train: epoch 0044, iter [04200, 05004], lr: 0.010000, loss: 2.5584, stu_CELoss: 1.7222 DKDLoss: 0.8362 
2022-05-02 15:45:07 - train: epoch 0044, iter [04300, 05004], lr: 0.010000, loss: 2.2467, stu_CELoss: 1.4826 DKDLoss: 0.7641 
2022-05-02 15:45:42 - train: epoch 0044, iter [04400, 05004], lr: 0.010000, loss: 2.3617, stu_CELoss: 1.6026 DKDLoss: 0.7591 
2022-05-02 15:46:17 - train: epoch 0044, iter [04500, 05004], lr: 0.010000, loss: 2.5043, stu_CELoss: 1.6632 DKDLoss: 0.8411 
2022-05-02 15:46:52 - train: epoch 0044, iter [04600, 05004], lr: 0.010000, loss: 2.3122, stu_CELoss: 1.5103 DKDLoss: 0.8019 
2022-05-02 15:47:27 - train: epoch 0044, iter [04700, 05004], lr: 0.010000, loss: 2.3600, stu_CELoss: 1.6088 DKDLoss: 0.7512 
2022-05-02 15:48:02 - train: epoch 0044, iter [04800, 05004], lr: 0.010000, loss: 2.3261, stu_CELoss: 1.5276 DKDLoss: 0.7985 
2022-05-02 15:48:37 - train: epoch 0044, iter [04900, 05004], lr: 0.010000, loss: 2.2505, stu_CELoss: 1.4340 DKDLoss: 0.8165 
2022-05-02 15:49:11 - train: epoch 0044, iter [05000, 05004], lr: 0.010000, loss: 2.3714, stu_CELoss: 1.6180 DKDLoss: 0.7534 
2022-05-02 15:49:12 - train: epoch 044, train_loss: 2.3440
2022-05-02 15:51:47 - eval: epoch: 044, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 66.648%, stu_acc5: 87.588%, stu_test_loss: 1.3599
2022-05-02 15:51:47 - until epoch: 044, tea_best_acc1: 73.944%, stu_best_acc1: 67.344%
2022-05-02 15:51:47 - epoch 045 lr: 0.010000000000000002
2022-05-02 15:52:26 - train: epoch 0045, iter [00100, 05004], lr: 0.010000, loss: 2.2063, stu_CELoss: 1.4146 DKDLoss: 0.7918 
2022-05-02 15:53:01 - train: epoch 0045, iter [00200, 05004], lr: 0.010000, loss: 2.2935, stu_CELoss: 1.4112 DKDLoss: 0.8823 
2022-05-02 15:53:37 - train: epoch 0045, iter [00300, 05004], lr: 0.010000, loss: 2.2108, stu_CELoss: 1.4979 DKDLoss: 0.7129 
2022-05-02 15:54:11 - train: epoch 0045, iter [00400, 05004], lr: 0.010000, loss: 2.2479, stu_CELoss: 1.4831 DKDLoss: 0.7648 
2022-05-02 15:54:46 - train: epoch 0045, iter [00500, 05004], lr: 0.010000, loss: 2.4547, stu_CELoss: 1.6899 DKDLoss: 0.7647 
2022-05-02 15:55:20 - train: epoch 0045, iter [00600, 05004], lr: 0.010000, loss: 2.5205, stu_CELoss: 1.7231 DKDLoss: 0.7974 
2022-05-02 15:55:56 - train: epoch 0045, iter [00700, 05004], lr: 0.010000, loss: 2.3126, stu_CELoss: 1.5096 DKDLoss: 0.8030 
2022-05-02 15:56:30 - train: epoch 0045, iter [00800, 05004], lr: 0.010000, loss: 2.2941, stu_CELoss: 1.5186 DKDLoss: 0.7755 
2022-05-02 15:57:05 - train: epoch 0045, iter [00900, 05004], lr: 0.010000, loss: 2.2758, stu_CELoss: 1.4929 DKDLoss: 0.7829 
2022-05-02 15:57:40 - train: epoch 0045, iter [01000, 05004], lr: 0.010000, loss: 2.3775, stu_CELoss: 1.5005 DKDLoss: 0.8769 
2022-05-02 15:58:16 - train: epoch 0045, iter [01100, 05004], lr: 0.010000, loss: 2.3589, stu_CELoss: 1.5816 DKDLoss: 0.7774 
2022-05-02 15:58:49 - train: epoch 0045, iter [01200, 05004], lr: 0.010000, loss: 2.2715, stu_CELoss: 1.5509 DKDLoss: 0.7206 
2022-05-02 15:59:25 - train: epoch 0045, iter [01300, 05004], lr: 0.010000, loss: 2.4227, stu_CELoss: 1.6742 DKDLoss: 0.7485 
2022-05-02 16:00:00 - train: epoch 0045, iter [01400, 05004], lr: 0.010000, loss: 2.4472, stu_CELoss: 1.7396 DKDLoss: 0.7077 
2022-05-02 16:00:35 - train: epoch 0045, iter [01500, 05004], lr: 0.010000, loss: 2.3085, stu_CELoss: 1.5384 DKDLoss: 0.7701 
2022-05-02 16:01:09 - train: epoch 0045, iter [01600, 05004], lr: 0.010000, loss: 2.0857, stu_CELoss: 1.2962 DKDLoss: 0.7895 
2022-05-02 16:01:45 - train: epoch 0045, iter [01700, 05004], lr: 0.010000, loss: 2.0941, stu_CELoss: 1.3697 DKDLoss: 0.7244 
2022-05-02 16:02:20 - train: epoch 0045, iter [01800, 05004], lr: 0.010000, loss: 2.3901, stu_CELoss: 1.6102 DKDLoss: 0.7799 
2022-05-02 16:02:55 - train: epoch 0045, iter [01900, 05004], lr: 0.010000, loss: 2.4435, stu_CELoss: 1.6604 DKDLoss: 0.7831 
2022-05-02 16:03:31 - train: epoch 0045, iter [02000, 05004], lr: 0.010000, loss: 2.4232, stu_CELoss: 1.6415 DKDLoss: 0.7817 
2022-05-02 16:04:04 - train: epoch 0045, iter [02100, 05004], lr: 0.010000, loss: 2.4347, stu_CELoss: 1.5350 DKDLoss: 0.8997 
2022-05-02 16:04:40 - train: epoch 0045, iter [02200, 05004], lr: 0.010000, loss: 2.2909, stu_CELoss: 1.5279 DKDLoss: 0.7630 
2022-05-02 16:05:15 - train: epoch 0045, iter [02300, 05004], lr: 0.010000, loss: 2.2303, stu_CELoss: 1.4564 DKDLoss: 0.7739 
2022-05-02 16:05:51 - train: epoch 0045, iter [02400, 05004], lr: 0.010000, loss: 2.0784, stu_CELoss: 1.3396 DKDLoss: 0.7388 
2022-05-02 16:06:25 - train: epoch 0045, iter [02500, 05004], lr: 0.010000, loss: 2.3436, stu_CELoss: 1.5933 DKDLoss: 0.7503 
2022-05-02 16:07:01 - train: epoch 0045, iter [02600, 05004], lr: 0.010000, loss: 2.3217, stu_CELoss: 1.6048 DKDLoss: 0.7168 
2022-05-02 16:07:35 - train: epoch 0045, iter [02700, 05004], lr: 0.010000, loss: 2.1662, stu_CELoss: 1.3993 DKDLoss: 0.7670 
2022-05-02 16:08:11 - train: epoch 0045, iter [02800, 05004], lr: 0.010000, loss: 2.2821, stu_CELoss: 1.5230 DKDLoss: 0.7590 
2022-05-02 16:08:44 - train: epoch 0045, iter [02900, 05004], lr: 0.010000, loss: 2.5699, stu_CELoss: 1.7661 DKDLoss: 0.8038 
2022-05-02 16:09:20 - train: epoch 0045, iter [03000, 05004], lr: 0.010000, loss: 2.5239, stu_CELoss: 1.6917 DKDLoss: 0.8322 
2022-05-02 16:09:55 - train: epoch 0045, iter [03100, 05004], lr: 0.010000, loss: 2.2581, stu_CELoss: 1.5057 DKDLoss: 0.7524 
2022-05-02 16:10:29 - train: epoch 0045, iter [03200, 05004], lr: 0.010000, loss: 2.4240, stu_CELoss: 1.6114 DKDLoss: 0.8125 
2022-05-02 16:11:04 - train: epoch 0045, iter [03300, 05004], lr: 0.010000, loss: 2.4157, stu_CELoss: 1.6384 DKDLoss: 0.7773 
2022-05-02 16:11:38 - train: epoch 0045, iter [03400, 05004], lr: 0.010000, loss: 2.2868, stu_CELoss: 1.5179 DKDLoss: 0.7689 
2022-05-02 16:12:13 - train: epoch 0045, iter [03500, 05004], lr: 0.010000, loss: 2.3543, stu_CELoss: 1.5069 DKDLoss: 0.8474 
2022-05-02 16:12:46 - train: epoch 0045, iter [03600, 05004], lr: 0.010000, loss: 2.4452, stu_CELoss: 1.6324 DKDLoss: 0.8127 
2022-05-02 16:13:21 - train: epoch 0045, iter [03700, 05004], lr: 0.010000, loss: 2.1378, stu_CELoss: 1.4218 DKDLoss: 0.7160 
2022-05-02 16:13:55 - train: epoch 0045, iter [03800, 05004], lr: 0.010000, loss: 2.3027, stu_CELoss: 1.4912 DKDLoss: 0.8115 
2022-05-02 16:14:30 - train: epoch 0045, iter [03900, 05004], lr: 0.010000, loss: 2.3061, stu_CELoss: 1.5749 DKDLoss: 0.7311 
2022-05-02 16:15:04 - train: epoch 0045, iter [04000, 05004], lr: 0.010000, loss: 2.4113, stu_CELoss: 1.6332 DKDLoss: 0.7780 
2022-05-02 16:15:38 - train: epoch 0045, iter [04100, 05004], lr: 0.010000, loss: 2.3252, stu_CELoss: 1.5492 DKDLoss: 0.7760 
2022-05-02 16:16:12 - train: epoch 0045, iter [04200, 05004], lr: 0.010000, loss: 2.6757, stu_CELoss: 1.8232 DKDLoss: 0.8525 
2022-05-02 16:16:47 - train: epoch 0045, iter [04300, 05004], lr: 0.010000, loss: 2.5219, stu_CELoss: 1.6630 DKDLoss: 0.8589 
2022-05-02 16:17:21 - train: epoch 0045, iter [04400, 05004], lr: 0.010000, loss: 2.5743, stu_CELoss: 1.7179 DKDLoss: 0.8564 
2022-05-02 16:17:56 - train: epoch 0045, iter [04500, 05004], lr: 0.010000, loss: 2.2884, stu_CELoss: 1.5128 DKDLoss: 0.7756 
2022-05-02 16:18:29 - train: epoch 0045, iter [04600, 05004], lr: 0.010000, loss: 2.6796, stu_CELoss: 1.8318 DKDLoss: 0.8478 
2022-05-02 16:19:04 - train: epoch 0045, iter [04700, 05004], lr: 0.010000, loss: 2.1990, stu_CELoss: 1.5265 DKDLoss: 0.6725 
2022-05-02 16:19:38 - train: epoch 0045, iter [04800, 05004], lr: 0.010000, loss: 2.2303, stu_CELoss: 1.4467 DKDLoss: 0.7836 
2022-05-02 16:20:13 - train: epoch 0045, iter [04900, 05004], lr: 0.010000, loss: 2.5004, stu_CELoss: 1.7123 DKDLoss: 0.7881 
2022-05-02 16:20:45 - train: epoch 0045, iter [05000, 05004], lr: 0.010000, loss: 2.2763, stu_CELoss: 1.4945 DKDLoss: 0.7818 
2022-05-02 16:20:46 - train: epoch 045, train_loss: 2.3468
2022-05-02 16:23:25 - eval: epoch: 045, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 66.700%, stu_acc5: 87.620%, stu_test_loss: 1.3624
2022-05-02 16:23:25 - until epoch: 045, tea_best_acc1: 73.944%, stu_best_acc1: 67.344%
2022-05-02 16:23:25 - epoch 046 lr: 0.010000000000000002
2022-05-02 16:24:08 - train: epoch 0046, iter [00100, 05004], lr: 0.010000, loss: 2.1397, stu_CELoss: 1.3191 DKDLoss: 0.8206 
2022-05-02 16:24:45 - train: epoch 0046, iter [00200, 05004], lr: 0.010000, loss: 2.1133, stu_CELoss: 1.4139 DKDLoss: 0.6994 
2022-05-02 16:25:22 - train: epoch 0046, iter [00300, 05004], lr: 0.010000, loss: 2.4329, stu_CELoss: 1.6780 DKDLoss: 0.7549 
2022-05-02 16:25:58 - train: epoch 0046, iter [00400, 05004], lr: 0.010000, loss: 2.0338, stu_CELoss: 1.3077 DKDLoss: 0.7262 
2022-05-02 16:26:31 - train: epoch 0046, iter [00500, 05004], lr: 0.010000, loss: 2.2869, stu_CELoss: 1.5127 DKDLoss: 0.7742 
2022-05-02 16:27:05 - train: epoch 0046, iter [00600, 05004], lr: 0.010000, loss: 2.2649, stu_CELoss: 1.5112 DKDLoss: 0.7537 
2022-05-02 16:27:39 - train: epoch 0046, iter [00700, 05004], lr: 0.010000, loss: 2.1165, stu_CELoss: 1.3825 DKDLoss: 0.7340 
2022-05-02 16:28:13 - train: epoch 0046, iter [00800, 05004], lr: 0.010000, loss: 2.3900, stu_CELoss: 1.6232 DKDLoss: 0.7668 
2022-05-02 16:28:46 - train: epoch 0046, iter [00900, 05004], lr: 0.010000, loss: 2.3281, stu_CELoss: 1.5337 DKDLoss: 0.7945 
2022-05-02 16:29:20 - train: epoch 0046, iter [01000, 05004], lr: 0.010000, loss: 2.0666, stu_CELoss: 1.3273 DKDLoss: 0.7393 
2022-05-02 16:29:53 - train: epoch 0046, iter [01100, 05004], lr: 0.010000, loss: 2.1632, stu_CELoss: 1.4579 DKDLoss: 0.7053 
2022-05-02 16:30:27 - train: epoch 0046, iter [01200, 05004], lr: 0.010000, loss: 2.1675, stu_CELoss: 1.4491 DKDLoss: 0.7184 
2022-05-02 16:31:01 - train: epoch 0046, iter [01300, 05004], lr: 0.010000, loss: 2.5549, stu_CELoss: 1.7226 DKDLoss: 0.8324 
2022-05-02 16:31:35 - train: epoch 0046, iter [01400, 05004], lr: 0.010000, loss: 2.4854, stu_CELoss: 1.6904 DKDLoss: 0.7950 
2022-05-02 16:32:09 - train: epoch 0046, iter [01500, 05004], lr: 0.010000, loss: 2.1619, stu_CELoss: 1.3956 DKDLoss: 0.7663 
2022-05-02 16:32:42 - train: epoch 0046, iter [01600, 05004], lr: 0.010000, loss: 2.5936, stu_CELoss: 1.8733 DKDLoss: 0.7203 
2022-05-02 16:33:16 - train: epoch 0046, iter [01700, 05004], lr: 0.010000, loss: 2.4241, stu_CELoss: 1.6116 DKDLoss: 0.8125 
2022-05-02 16:33:50 - train: epoch 0046, iter [01800, 05004], lr: 0.010000, loss: 2.4051, stu_CELoss: 1.6177 DKDLoss: 0.7875 
2022-05-02 16:34:24 - train: epoch 0046, iter [01900, 05004], lr: 0.010000, loss: 2.3347, stu_CELoss: 1.5882 DKDLoss: 0.7466 
2022-05-02 16:34:58 - train: epoch 0046, iter [02000, 05004], lr: 0.010000, loss: 2.1782, stu_CELoss: 1.4461 DKDLoss: 0.7321 
2022-05-02 16:35:31 - train: epoch 0046, iter [02100, 05004], lr: 0.010000, loss: 2.7168, stu_CELoss: 1.8663 DKDLoss: 0.8505 
2022-05-02 16:36:05 - train: epoch 0046, iter [02200, 05004], lr: 0.010000, loss: 2.1683, stu_CELoss: 1.3796 DKDLoss: 0.7887 
2022-05-02 16:36:39 - train: epoch 0046, iter [02300, 05004], lr: 0.010000, loss: 2.6263, stu_CELoss: 1.8576 DKDLoss: 0.7688 
2022-05-02 16:37:13 - train: epoch 0046, iter [02400, 05004], lr: 0.010000, loss: 2.5610, stu_CELoss: 1.7568 DKDLoss: 0.8042 
2022-05-02 16:37:47 - train: epoch 0046, iter [02500, 05004], lr: 0.010000, loss: 2.3115, stu_CELoss: 1.5128 DKDLoss: 0.7987 
2022-05-02 16:38:21 - train: epoch 0046, iter [02600, 05004], lr: 0.010000, loss: 2.5932, stu_CELoss: 1.8472 DKDLoss: 0.7460 
2022-05-02 16:38:55 - train: epoch 0046, iter [02700, 05004], lr: 0.010000, loss: 2.2923, stu_CELoss: 1.4816 DKDLoss: 0.8107 
2022-05-02 16:39:28 - train: epoch 0046, iter [02800, 05004], lr: 0.010000, loss: 2.1891, stu_CELoss: 1.4173 DKDLoss: 0.7718 
2022-05-02 16:40:03 - train: epoch 0046, iter [02900, 05004], lr: 0.010000, loss: 2.3454, stu_CELoss: 1.6393 DKDLoss: 0.7062 
2022-05-02 16:40:36 - train: epoch 0046, iter [03000, 05004], lr: 0.010000, loss: 2.3199, stu_CELoss: 1.5217 DKDLoss: 0.7982 
2022-05-02 16:41:10 - train: epoch 0046, iter [03100, 05004], lr: 0.010000, loss: 2.2075, stu_CELoss: 1.4841 DKDLoss: 0.7234 
2022-05-02 16:41:43 - train: epoch 0046, iter [03200, 05004], lr: 0.010000, loss: 2.2759, stu_CELoss: 1.4990 DKDLoss: 0.7769 
2022-05-02 16:42:18 - train: epoch 0046, iter [03300, 05004], lr: 0.010000, loss: 2.5070, stu_CELoss: 1.6640 DKDLoss: 0.8430 
2022-05-02 16:42:51 - train: epoch 0046, iter [03400, 05004], lr: 0.010000, loss: 2.1750, stu_CELoss: 1.4842 DKDLoss: 0.6908 
2022-05-02 16:43:26 - train: epoch 0046, iter [03500, 05004], lr: 0.010000, loss: 2.5204, stu_CELoss: 1.6614 DKDLoss: 0.8590 
2022-05-02 16:44:00 - train: epoch 0046, iter [03600, 05004], lr: 0.010000, loss: 2.3405, stu_CELoss: 1.5564 DKDLoss: 0.7841 
2022-05-02 16:44:35 - train: epoch 0046, iter [03700, 05004], lr: 0.010000, loss: 2.1390, stu_CELoss: 1.3460 DKDLoss: 0.7930 
2022-05-02 16:45:07 - train: epoch 0046, iter [03800, 05004], lr: 0.010000, loss: 2.2964, stu_CELoss: 1.5200 DKDLoss: 0.7764 
2022-05-02 16:45:43 - train: epoch 0046, iter [03900, 05004], lr: 0.010000, loss: 2.3682, stu_CELoss: 1.5941 DKDLoss: 0.7741 
2022-05-02 16:46:16 - train: epoch 0046, iter [04000, 05004], lr: 0.010000, loss: 2.2513, stu_CELoss: 1.5206 DKDLoss: 0.7307 
2022-05-02 16:46:51 - train: epoch 0046, iter [04100, 05004], lr: 0.010000, loss: 2.5578, stu_CELoss: 1.7604 DKDLoss: 0.7973 
2022-05-02 16:47:25 - train: epoch 0046, iter [04200, 05004], lr: 0.010000, loss: 2.1681, stu_CELoss: 1.4287 DKDLoss: 0.7394 
2022-05-02 16:47:59 - train: epoch 0046, iter [04300, 05004], lr: 0.010000, loss: 2.4566, stu_CELoss: 1.6606 DKDLoss: 0.7961 
2022-05-02 16:48:32 - train: epoch 0046, iter [04400, 05004], lr: 0.010000, loss: 2.5022, stu_CELoss: 1.7202 DKDLoss: 0.7821 
2022-05-02 16:49:07 - train: epoch 0046, iter [04500, 05004], lr: 0.010000, loss: 2.4266, stu_CELoss: 1.5798 DKDLoss: 0.8468 
2022-05-02 16:49:40 - train: epoch 0046, iter [04600, 05004], lr: 0.010000, loss: 2.3072, stu_CELoss: 1.5281 DKDLoss: 0.7791 
2022-05-02 16:50:15 - train: epoch 0046, iter [04700, 05004], lr: 0.010000, loss: 2.3299, stu_CELoss: 1.5395 DKDLoss: 0.7904 
2022-05-02 16:50:49 - train: epoch 0046, iter [04800, 05004], lr: 0.010000, loss: 1.9512, stu_CELoss: 1.2505 DKDLoss: 0.7007 
2022-05-02 16:51:23 - train: epoch 0046, iter [04900, 05004], lr: 0.010000, loss: 2.3227, stu_CELoss: 1.6889 DKDLoss: 0.6338 
2022-05-02 16:51:55 - train: epoch 0046, iter [05000, 05004], lr: 0.010000, loss: 2.3381, stu_CELoss: 1.5633 DKDLoss: 0.7748 
2022-05-02 16:51:56 - train: epoch 046, train_loss: 2.3525
2022-05-02 16:54:29 - eval: epoch: 046, tea_acc1: 73.944%, tea_acc5: 91.756%, tea_test_loss: 1.0381, stu_acc1: 66.678%, stu_acc5: 87.418%, stu_test_loss: 1.3720
2022-05-02 16:54:29 - until epoch: 046, tea_best_acc1: 73.944%, stu_best_acc1: 67.344%
2022-05-02 16:54:29 - epoch 047 lr: 0.010000000000000002
2022-05-02 16:55:09 - train: epoch 0047, iter [00100, 05004], lr: 0.010000, loss: 2.3826, stu_CELoss: 1.6983 DKDLoss: 0.6843 
2022-05-02 16:55:44 - train: epoch 0047, iter [00200, 05004], lr: 0.010000, loss: 2.5462, stu_CELoss: 1.7697 DKDLoss: 0.7765 
2022-05-02 16:56:18 - train: epoch 0047, iter [00300, 05004], lr: 0.010000, loss: 1.9842, stu_CELoss: 1.2789 DKDLoss: 0.7053 
2022-05-02 16:56:52 - train: epoch 0047, iter [00400, 05004], lr: 0.010000, loss: 2.0333, stu_CELoss: 1.3101 DKDLoss: 0.7232 
2022-05-02 16:57:27 - train: epoch 0047, iter [00500, 05004], lr: 0.010000, loss: 2.1837, stu_CELoss: 1.4355 DKDLoss: 0.7482 
2022-05-02 16:58:01 - train: epoch 0047, iter [00600, 05004], lr: 0.010000, loss: 2.3467, stu_CELoss: 1.5029 DKDLoss: 0.8438 
2022-05-02 16:58:35 - train: epoch 0047, iter [00700, 05004], lr: 0.010000, loss: 2.4465, stu_CELoss: 1.6071 DKDLoss: 0.8394 
2022-05-02 16:59:09 - train: epoch 0047, iter [00800, 05004], lr: 0.010000, loss: 2.3276, stu_CELoss: 1.5217 DKDLoss: 0.8059 
2022-05-02 16:59:43 - train: epoch 0047, iter [00900, 05004], lr: 0.010000, loss: 2.4228, stu_CELoss: 1.6963 DKDLoss: 0.7265 
2022-05-02 17:00:17 - train: epoch 0047, iter [01000, 05004], lr: 0.010000, loss: 2.3559, stu_CELoss: 1.5535 DKDLoss: 0.8024 
2022-05-02 17:00:51 - train: epoch 0047, iter [01100, 05004], lr: 0.010000, loss: 2.5635, stu_CELoss: 1.7574 DKDLoss: 0.8060 
2022-05-02 17:01:25 - train: epoch 0047, iter [01200, 05004], lr: 0.010000, loss: 2.3269, stu_CELoss: 1.5162 DKDLoss: 0.8107 
2022-05-02 17:02:01 - train: epoch 0047, iter [01300, 05004], lr: 0.010000, loss: 2.2317, stu_CELoss: 1.4861 DKDLoss: 0.7456 
2022-05-02 17:02:35 - train: epoch 0047, iter [01400, 05004], lr: 0.010000, loss: 2.3841, stu_CELoss: 1.6293 DKDLoss: 0.7548 
