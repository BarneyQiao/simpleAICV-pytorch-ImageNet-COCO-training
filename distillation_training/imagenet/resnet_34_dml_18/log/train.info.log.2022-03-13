2022-03-13 17:49:06 - teacher: resnet34
2022-03-13 17:49:06 - student: resnet18
2022-03-13 17:49:06 - num_classes: 1000
2022-03-13 17:49:06 - input_image_size: 224
2022-03-13 17:49:06 - scale: 1.1428571428571428
2022-03-13 17:49:06 - teacher_pretrained_model_path: /root/code/simpleAICV-pytorch-ImageNet-COCO-training/pretrained_models/resnet/resnet34-acc73.930.pth
2022-03-13 17:49:06 - student_pretrained_model_path: 
2022-03-13 17:49:06 - freeze_teacher: False
2022-03-13 17:49:06 - loss_list: ['CELoss', 'DMLLoss']
2022-03-13 17:49:06 - T: 1
2022-03-13 17:49:06 - train_criterion: {'CELoss': CELoss(
  (loss): CrossEntropyLoss()
), 'DMLLoss': DMLLoss()}
2022-03-13 17:49:06 - loss_name: DMLLoss
2022-03-13 17:49:06 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2022-03-13 17:49:06 - train_dataset: <simpleAICV.classification.datasets.ilsvrc2012dataset.ILSVRC2012Dataset object at 0x7ff0aab9b730>
2022-03-13 17:49:06 - val_dataset: <simpleAICV.classification.datasets.ilsvrc2012dataset.ILSVRC2012Dataset object at 0x7ff0aab9ba00>
2022-03-13 17:49:06 - collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7ff0aab9ba30>
2022-03-13 17:49:06 - seed: 0
2022-03-13 17:49:06 - batch_size: 256
2022-03-13 17:49:06 - num_workers: 16
2022-03-13 17:49:06 - optimizer: ('SGD', {'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0001})
2022-03-13 17:49:06 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.1, 'milestones': [30, 60, 90]})
2022-03-13 17:49:06 - epochs: 100
2022-03-13 17:49:06 - print_interval: 100
2022-03-13 17:49:06 - distributed: True
2022-03-13 17:49:06 - sync_bn: False
2022-03-13 17:49:06 - apex: True
2022-03-13 17:49:06 - gpus_type: NVIDIA GeForce RTX 3090
2022-03-13 17:49:06 - gpus_num: 2
2022-03-13 17:49:06 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7ff0a2f671b0>
2022-03-13 17:49:11 - --------------------parameters--------------------
2022-03-13 17:49:11 - name: teacher.conv1.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.conv1.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.conv1.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer1.0.conv1.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer1.0.conv1.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer1.0.conv1.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer1.0.conv2.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer1.0.conv2.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer1.0.conv2.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer1.1.conv1.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer1.1.conv1.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer1.1.conv1.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer1.1.conv2.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer1.1.conv2.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer1.1.conv2.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer1.2.conv1.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer1.2.conv1.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer1.2.conv1.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer1.2.conv2.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer1.2.conv2.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer1.2.conv2.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer2.0.conv1.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer2.0.conv1.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer2.0.conv1.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer2.0.conv2.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer2.0.conv2.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer2.0.conv2.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer2.0.downsample_conv.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer2.0.downsample_conv.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer2.0.downsample_conv.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer2.1.conv1.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer2.1.conv1.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer2.1.conv1.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer2.1.conv2.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer2.1.conv2.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer2.1.conv2.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer2.2.conv1.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer2.2.conv1.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer2.2.conv1.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer2.2.conv2.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer2.2.conv2.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer2.2.conv2.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer2.3.conv1.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer2.3.conv1.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer2.3.conv1.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer2.3.conv2.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer2.3.conv2.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer2.3.conv2.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.0.conv1.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.0.conv1.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.0.conv1.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.0.conv2.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.0.conv2.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.0.conv2.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.0.downsample_conv.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.0.downsample_conv.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.0.downsample_conv.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.1.conv1.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.1.conv1.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.1.conv1.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.1.conv2.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.1.conv2.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.1.conv2.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.2.conv1.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.2.conv1.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.2.conv1.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.2.conv2.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.2.conv2.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.2.conv2.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.3.conv1.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.3.conv1.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.3.conv1.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.3.conv2.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.3.conv2.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.3.conv2.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.4.conv1.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.4.conv1.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.4.conv1.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.4.conv2.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.4.conv2.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.4.conv2.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.5.conv1.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.5.conv1.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.5.conv1.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.5.conv2.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.5.conv2.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer3.5.conv2.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer4.0.conv1.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer4.0.conv1.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer4.0.conv1.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer4.0.conv2.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer4.0.conv2.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer4.0.conv2.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer4.0.downsample_conv.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer4.0.downsample_conv.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer4.0.downsample_conv.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer4.1.conv1.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer4.1.conv1.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer4.1.conv1.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer4.1.conv2.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer4.1.conv2.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer4.1.conv2.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer4.2.conv1.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer4.2.conv1.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer4.2.conv1.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.layer4.2.conv2.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer4.2.conv2.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: teacher.layer4.2.conv2.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: teacher.fc.weight, grad: True
2022-03-13 17:49:11 - name: teacher.fc.bias, grad: True
2022-03-13 17:49:11 - name: student.conv1.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: student.conv1.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: student.conv1.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: student.layer1.0.conv1.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: student.layer1.0.conv1.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: student.layer1.0.conv1.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: student.layer1.0.conv2.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: student.layer1.0.conv2.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: student.layer1.0.conv2.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: student.layer1.1.conv1.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: student.layer1.1.conv1.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: student.layer1.1.conv1.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: student.layer1.1.conv2.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: student.layer1.1.conv2.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: student.layer1.1.conv2.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: student.layer2.0.conv1.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: student.layer2.0.conv1.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: student.layer2.0.conv1.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: student.layer2.0.conv2.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: student.layer2.0.conv2.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: student.layer2.0.conv2.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: student.layer2.0.downsample_conv.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: student.layer2.0.downsample_conv.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: student.layer2.0.downsample_conv.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: student.layer2.1.conv1.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: student.layer2.1.conv1.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: student.layer2.1.conv1.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: student.layer2.1.conv2.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: student.layer2.1.conv2.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: student.layer2.1.conv2.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: student.layer3.0.conv1.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: student.layer3.0.conv1.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: student.layer3.0.conv1.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: student.layer3.0.conv2.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: student.layer3.0.conv2.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: student.layer3.0.conv2.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: student.layer3.0.downsample_conv.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: student.layer3.0.downsample_conv.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: student.layer3.0.downsample_conv.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: student.layer3.1.conv1.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: student.layer3.1.conv1.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: student.layer3.1.conv1.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: student.layer3.1.conv2.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: student.layer3.1.conv2.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: student.layer3.1.conv2.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: student.layer4.0.conv1.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: student.layer4.0.conv1.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: student.layer4.0.conv1.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: student.layer4.0.conv2.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: student.layer4.0.conv2.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: student.layer4.0.conv2.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: student.layer4.0.downsample_conv.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: student.layer4.0.downsample_conv.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: student.layer4.0.downsample_conv.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: student.layer4.1.conv1.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: student.layer4.1.conv1.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: student.layer4.1.conv1.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: student.layer4.1.conv2.layer.0.weight, grad: True
2022-03-13 17:49:11 - name: student.layer4.1.conv2.layer.1.weight, grad: True
2022-03-13 17:49:11 - name: student.layer4.1.conv2.layer.1.bias, grad: True
2022-03-13 17:49:11 - name: student.fc.weight, grad: True
2022-03-13 17:49:11 - name: student.fc.bias, grad: True
2022-03-13 17:49:11 - --------------------buffers--------------------
2022-03-13 17:49:11 - name: teacher.conv1.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.conv1.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.conv1.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer1.0.conv1.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer1.0.conv1.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer1.0.conv2.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer1.0.conv2.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer1.1.conv1.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer1.1.conv1.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer1.1.conv2.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer1.1.conv2.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer1.2.conv1.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer1.2.conv1.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer1.2.conv1.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer1.2.conv2.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer1.2.conv2.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer1.2.conv2.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer2.0.conv1.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer2.0.conv1.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer2.0.conv2.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer2.0.conv2.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer2.0.downsample_conv.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer2.0.downsample_conv.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer2.1.conv1.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer2.1.conv1.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer2.1.conv2.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer2.1.conv2.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer2.2.conv1.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer2.2.conv1.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer2.2.conv1.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer2.2.conv2.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer2.2.conv2.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer2.2.conv2.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer2.3.conv1.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer2.3.conv1.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer2.3.conv1.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer2.3.conv2.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer2.3.conv2.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer2.3.conv2.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.0.conv1.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.0.conv1.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.0.conv2.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.0.conv2.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.0.downsample_conv.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.0.downsample_conv.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.1.conv1.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.1.conv1.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.1.conv2.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.1.conv2.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.2.conv1.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.2.conv1.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.2.conv1.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.2.conv2.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.2.conv2.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.2.conv2.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.3.conv1.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.3.conv1.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.3.conv1.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.3.conv2.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.3.conv2.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.3.conv2.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.4.conv1.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.4.conv1.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.4.conv1.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.4.conv2.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.4.conv2.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.4.conv2.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.5.conv1.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.5.conv1.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.5.conv1.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.5.conv2.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.5.conv2.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer3.5.conv2.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer4.0.conv1.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer4.0.conv1.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer4.0.conv2.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer4.0.conv2.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer4.0.downsample_conv.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer4.0.downsample_conv.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer4.1.conv1.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer4.1.conv1.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer4.1.conv2.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer4.1.conv2.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer4.2.conv1.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer4.2.conv1.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer4.2.conv1.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: teacher.layer4.2.conv2.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: teacher.layer4.2.conv2.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: teacher.layer4.2.conv2.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: student.conv1.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: student.conv1.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: student.conv1.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: student.layer1.0.conv1.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: student.layer1.0.conv1.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: student.layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: student.layer1.0.conv2.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: student.layer1.0.conv2.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: student.layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: student.layer1.1.conv1.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: student.layer1.1.conv1.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: student.layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: student.layer1.1.conv2.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: student.layer1.1.conv2.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: student.layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: student.layer2.0.conv1.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: student.layer2.0.conv1.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: student.layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: student.layer2.0.conv2.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: student.layer2.0.conv2.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: student.layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: student.layer2.0.downsample_conv.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: student.layer2.0.downsample_conv.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: student.layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: student.layer2.1.conv1.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: student.layer2.1.conv1.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: student.layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: student.layer2.1.conv2.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: student.layer2.1.conv2.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: student.layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: student.layer3.0.conv1.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: student.layer3.0.conv1.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: student.layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: student.layer3.0.conv2.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: student.layer3.0.conv2.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: student.layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: student.layer3.0.downsample_conv.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: student.layer3.0.downsample_conv.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: student.layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: student.layer3.1.conv1.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: student.layer3.1.conv1.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: student.layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: student.layer3.1.conv2.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: student.layer3.1.conv2.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: student.layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: student.layer4.0.conv1.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: student.layer4.0.conv1.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: student.layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: student.layer4.0.conv2.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: student.layer4.0.conv2.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: student.layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: student.layer4.0.downsample_conv.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: student.layer4.0.downsample_conv.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: student.layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: student.layer4.1.conv1.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: student.layer4.1.conv1.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: student.layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - name: student.layer4.1.conv2.layer.1.running_mean, grad: False
2022-03-13 17:49:11 - name: student.layer4.1.conv2.layer.1.running_var, grad: False
2022-03-13 17:49:11 - name: student.layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2022-03-13 17:49:11 - epoch 001 lr: 0.1
2022-03-13 17:49:50 - train: epoch 0001, iter [00100, 05004], lr: 0.100000, loss: 12.0588, tea_CELoss: 4.7142 stu_CELoss: 6.7247 DMLLoss: 0.6199 
2022-03-13 17:50:22 - train: epoch 0001, iter [00200, 05004], lr: 0.100000, loss: 11.0951, tea_CELoss: 3.7630 stu_CELoss: 6.4714 DMLLoss: 0.8606 
2022-03-13 17:50:56 - train: epoch 0001, iter [00300, 05004], lr: 0.100000, loss: 10.9426, tea_CELoss: 3.8860 stu_CELoss: 6.2818 DMLLoss: 0.7748 
2022-03-13 17:51:29 - train: epoch 0001, iter [00400, 05004], lr: 0.100000, loss: 10.4181, tea_CELoss: 3.5103 stu_CELoss: 6.1191 DMLLoss: 0.7887 
2022-03-13 17:52:02 - train: epoch 0001, iter [00500, 05004], lr: 0.100000, loss: 10.3129, tea_CELoss: 3.6225 stu_CELoss: 5.9344 DMLLoss: 0.7560 
2022-03-13 17:52:36 - train: epoch 0001, iter [00600, 05004], lr: 0.100000, loss: 9.8506, tea_CELoss: 3.3221 stu_CELoss: 5.6605 DMLLoss: 0.8680 
2022-03-13 17:53:08 - train: epoch 0001, iter [00700, 05004], lr: 0.100000, loss: 9.8375, tea_CELoss: 3.3090 stu_CELoss: 5.6725 DMLLoss: 0.8560 
2022-03-13 17:53:41 - train: epoch 0001, iter [00800, 05004], lr: 0.100000, loss: 9.7821, tea_CELoss: 3.3239 stu_CELoss: 5.6009 DMLLoss: 0.8573 
2022-03-13 17:54:15 - train: epoch 0001, iter [00900, 05004], lr: 0.100000, loss: 9.7156, tea_CELoss: 3.3816 stu_CELoss: 5.5140 DMLLoss: 0.8200 
2022-03-13 17:54:48 - train: epoch 0001, iter [01000, 05004], lr: 0.100000, loss: 9.4472, tea_CELoss: 3.2490 stu_CELoss: 5.3679 DMLLoss: 0.8303 
2022-03-13 17:55:21 - train: epoch 0001, iter [01100, 05004], lr: 0.100000, loss: 9.6107, tea_CELoss: 3.4409 stu_CELoss: 5.4222 DMLLoss: 0.7477 
2022-03-13 17:55:54 - train: epoch 0001, iter [01200, 05004], lr: 0.100000, loss: 9.1473, tea_CELoss: 3.1742 stu_CELoss: 5.2169 DMLLoss: 0.7562 
2022-03-13 17:56:26 - train: epoch 0001, iter [01300, 05004], lr: 0.100000, loss: 9.0161, tea_CELoss: 3.1002 stu_CELoss: 5.0965 DMLLoss: 0.8194 
2022-03-13 17:57:00 - train: epoch 0001, iter [01400, 05004], lr: 0.100000, loss: 8.9433, tea_CELoss: 3.1449 stu_CELoss: 5.0230 DMLLoss: 0.7754 
2022-03-13 17:57:33 - train: epoch 0001, iter [01500, 05004], lr: 0.100000, loss: 8.7313, tea_CELoss: 2.9567 stu_CELoss: 4.9458 DMLLoss: 0.8288 
2022-03-13 17:58:06 - train: epoch 0001, iter [01600, 05004], lr: 0.100000, loss: 8.9485, tea_CELoss: 3.2300 stu_CELoss: 4.9669 DMLLoss: 0.7516 
2022-03-13 17:58:39 - train: epoch 0001, iter [01700, 05004], lr: 0.100000, loss: 8.5906, tea_CELoss: 2.9131 stu_CELoss: 4.8229 DMLLoss: 0.8545 
2022-03-13 17:59:12 - train: epoch 0001, iter [01800, 05004], lr: 0.100000, loss: 8.6011, tea_CELoss: 3.0354 stu_CELoss: 4.7964 DMLLoss: 0.7693 
2022-03-13 17:59:45 - train: epoch 0001, iter [01900, 05004], lr: 0.100000, loss: 8.3409, tea_CELoss: 2.9433 stu_CELoss: 4.6452 DMLLoss: 0.7524 
2022-03-13 18:00:18 - train: epoch 0001, iter [02000, 05004], lr: 0.100000, loss: 8.3872, tea_CELoss: 3.0256 stu_CELoss: 4.6199 DMLLoss: 0.7416 
2022-03-13 18:00:51 - train: epoch 0001, iter [02100, 05004], lr: 0.100000, loss: 8.2686, tea_CELoss: 3.0288 stu_CELoss: 4.5022 DMLLoss: 0.7376 
2022-03-13 18:01:24 - train: epoch 0001, iter [02200, 05004], lr: 0.100000, loss: 8.2375, tea_CELoss: 2.9637 stu_CELoss: 4.5384 DMLLoss: 0.7354 
2022-03-13 18:01:57 - train: epoch 0001, iter [02300, 05004], lr: 0.100000, loss: 7.9584, tea_CELoss: 2.9036 stu_CELoss: 4.3280 DMLLoss: 0.7268 
2022-03-13 18:02:30 - train: epoch 0001, iter [02400, 05004], lr: 0.100000, loss: 7.9673, tea_CELoss: 2.9106 stu_CELoss: 4.3363 DMLLoss: 0.7204 
2022-03-13 18:03:03 - train: epoch 0001, iter [02500, 05004], lr: 0.100000, loss: 8.1514, tea_CELoss: 3.0417 stu_CELoss: 4.4189 DMLLoss: 0.6908 
2022-03-13 18:03:36 - train: epoch 0001, iter [02600, 05004], lr: 0.100000, loss: 8.2248, tea_CELoss: 2.9941 stu_CELoss: 4.5061 DMLLoss: 0.7246 
2022-03-13 18:04:09 - train: epoch 0001, iter [02700, 05004], lr: 0.100000, loss: 8.1428, tea_CELoss: 2.9885 stu_CELoss: 4.4308 DMLLoss: 0.7235 
2022-03-13 18:04:42 - train: epoch 0001, iter [02800, 05004], lr: 0.100000, loss: 7.5765, tea_CELoss: 2.7534 stu_CELoss: 4.1260 DMLLoss: 0.6971 
2022-03-13 18:05:15 - train: epoch 0001, iter [02900, 05004], lr: 0.100000, loss: 7.6100, tea_CELoss: 2.8193 stu_CELoss: 4.1053 DMLLoss: 0.6854 
2022-03-13 18:05:49 - train: epoch 0001, iter [03000, 05004], lr: 0.100000, loss: 7.8831, tea_CELoss: 3.0056 stu_CELoss: 4.1808 DMLLoss: 0.6966 
2022-03-13 18:06:22 - train: epoch 0001, iter [03100, 05004], lr: 0.100000, loss: 7.8726, tea_CELoss: 2.9689 stu_CELoss: 4.2210 DMLLoss: 0.6827 
2022-03-13 18:06:55 - train: epoch 0001, iter [03200, 05004], lr: 0.100000, loss: 7.7218, tea_CELoss: 2.8867 stu_CELoss: 4.1674 DMLLoss: 0.6677 
2022-03-13 18:07:28 - train: epoch 0001, iter [03300, 05004], lr: 0.100000, loss: 7.2620, tea_CELoss: 2.7328 stu_CELoss: 3.8825 DMLLoss: 0.6467 
2022-03-13 18:08:01 - train: epoch 0001, iter [03400, 05004], lr: 0.100000, loss: 7.4217, tea_CELoss: 2.8603 stu_CELoss: 3.9080 DMLLoss: 0.6534 
2022-03-13 18:08:34 - train: epoch 0001, iter [03500, 05004], lr: 0.100000, loss: 7.3878, tea_CELoss: 2.7484 stu_CELoss: 3.9504 DMLLoss: 0.6890 
2022-03-13 18:09:08 - train: epoch 0001, iter [03600, 05004], lr: 0.100000, loss: 7.3777, tea_CELoss: 2.8401 stu_CELoss: 3.8999 DMLLoss: 0.6376 
2022-03-13 18:09:42 - train: epoch 0001, iter [03700, 05004], lr: 0.100000, loss: 7.7677, tea_CELoss: 2.9623 stu_CELoss: 4.1220 DMLLoss: 0.6834 
2022-03-13 18:10:15 - train: epoch 0001, iter [03800, 05004], lr: 0.100000, loss: 7.2366, tea_CELoss: 2.7430 stu_CELoss: 3.8534 DMLLoss: 0.6402 
2022-03-13 18:10:49 - train: epoch 0001, iter [03900, 05004], lr: 0.100000, loss: 7.4721, tea_CELoss: 2.8367 stu_CELoss: 3.9418 DMLLoss: 0.6936 
2022-03-13 18:11:23 - train: epoch 0001, iter [04000, 05004], lr: 0.100000, loss: 7.0960, tea_CELoss: 2.6527 stu_CELoss: 3.7826 DMLLoss: 0.6607 
2022-03-13 18:11:56 - train: epoch 0001, iter [04100, 05004], lr: 0.100000, loss: 7.2932, tea_CELoss: 2.8330 stu_CELoss: 3.8326 DMLLoss: 0.6275 
2022-03-13 18:12:29 - train: epoch 0001, iter [04200, 05004], lr: 0.100000, loss: 6.9725, tea_CELoss: 2.6050 stu_CELoss: 3.7118 DMLLoss: 0.6557 
2022-03-13 18:13:04 - train: epoch 0001, iter [04300, 05004], lr: 0.100000, loss: 6.9548, tea_CELoss: 2.6489 stu_CELoss: 3.6942 DMLLoss: 0.6117 
2022-03-13 18:13:37 - train: epoch 0001, iter [04400, 05004], lr: 0.100000, loss: 6.7092, tea_CELoss: 2.5717 stu_CELoss: 3.5308 DMLLoss: 0.6067 
2022-03-13 18:14:10 - train: epoch 0001, iter [04500, 05004], lr: 0.100000, loss: 7.1042, tea_CELoss: 2.7395 stu_CELoss: 3.7319 DMLLoss: 0.6327 
2022-03-13 18:14:44 - train: epoch 0001, iter [04600, 05004], lr: 0.100000, loss: 7.3391, tea_CELoss: 2.8344 stu_CELoss: 3.8319 DMLLoss: 0.6728 
2022-03-13 18:15:18 - train: epoch 0001, iter [04700, 05004], lr: 0.100000, loss: 7.0926, tea_CELoss: 2.8430 stu_CELoss: 3.6859 DMLLoss: 0.5637 
2022-03-13 18:15:52 - train: epoch 0001, iter [04800, 05004], lr: 0.100000, loss: 7.4241, tea_CELoss: 2.9288 stu_CELoss: 3.8692 DMLLoss: 0.6261 
2022-03-13 18:16:25 - train: epoch 0001, iter [04900, 05004], lr: 0.100000, loss: 6.6980, tea_CELoss: 2.6494 stu_CELoss: 3.4573 DMLLoss: 0.5913 
2022-03-13 18:16:58 - train: epoch 0001, iter [05000, 05004], lr: 0.100000, loss: 6.6325, tea_CELoss: 2.5320 stu_CELoss: 3.4802 DMLLoss: 0.6203 
2022-03-13 18:16:59 - train: epoch 001, train_loss: 8.3382
2022-03-13 18:19:27 - eval: epoch: 001, tea_acc1: 47.048%, tea_acc5: 73.340%, tea_test_loss: 2.3979, stu_acc1: 27.236%, stu_acc5: 52.328%, stu_test_loss: 3.4705
2022-03-13 18:19:28 - until epoch: 001, tea_best_acc1: 47.048%, stu_best_acc1: 27.236%
2022-03-13 18:19:28 - epoch 002 lr: 0.1
2022-03-13 18:20:07 - train: epoch 0002, iter [00100, 05004], lr: 0.100000, loss: 6.4288, tea_CELoss: 2.4645 stu_CELoss: 3.3385 DMLLoss: 0.6258 
2022-03-13 18:20:41 - train: epoch 0002, iter [00200, 05004], lr: 0.100000, loss: 6.5649, tea_CELoss: 2.5862 stu_CELoss: 3.4116 DMLLoss: 0.5671 
2022-03-13 18:21:15 - train: epoch 0002, iter [00300, 05004], lr: 0.100000, loss: 6.7818, tea_CELoss: 2.6830 stu_CELoss: 3.5144 DMLLoss: 0.5844 
2022-03-13 18:21:48 - train: epoch 0002, iter [00400, 05004], lr: 0.100000, loss: 6.9513, tea_CELoss: 2.7518 stu_CELoss: 3.6145 DMLLoss: 0.5850 
2022-03-13 18:22:22 - train: epoch 0002, iter [00500, 05004], lr: 0.100000, loss: 6.4833, tea_CELoss: 2.6095 stu_CELoss: 3.3298 DMLLoss: 0.5440 
2022-03-13 18:22:55 - train: epoch 0002, iter [00600, 05004], lr: 0.100000, loss: 6.2945, tea_CELoss: 2.4194 stu_CELoss: 3.2726 DMLLoss: 0.6024 
2022-03-13 18:23:28 - train: epoch 0002, iter [00700, 05004], lr: 0.100000, loss: 6.7972, tea_CELoss: 2.6816 stu_CELoss: 3.5153 DMLLoss: 0.6004 
2022-03-13 18:24:02 - train: epoch 0002, iter [00800, 05004], lr: 0.100000, loss: 6.6938, tea_CELoss: 2.6248 stu_CELoss: 3.4702 DMLLoss: 0.5988 
2022-03-13 18:24:36 - train: epoch 0002, iter [00900, 05004], lr: 0.100000, loss: 6.3711, tea_CELoss: 2.5306 stu_CELoss: 3.2751 DMLLoss: 0.5655 
2022-03-13 18:25:09 - train: epoch 0002, iter [01000, 05004], lr: 0.100000, loss: 6.4254, tea_CELoss: 2.5923 stu_CELoss: 3.3080 DMLLoss: 0.5251 
2022-03-13 18:25:42 - train: epoch 0002, iter [01100, 05004], lr: 0.100000, loss: 7.0135, tea_CELoss: 2.8733 stu_CELoss: 3.6067 DMLLoss: 0.5336 
2022-03-13 18:26:16 - train: epoch 0002, iter [01200, 05004], lr: 0.100000, loss: 6.1157, tea_CELoss: 2.4593 stu_CELoss: 3.1442 DMLLoss: 0.5122 
2022-03-13 18:26:49 - train: epoch 0002, iter [01300, 05004], lr: 0.100000, loss: 6.3005, tea_CELoss: 2.4827 stu_CELoss: 3.2857 DMLLoss: 0.5321 
2022-03-13 18:27:23 - train: epoch 0002, iter [01400, 05004], lr: 0.100000, loss: 6.6464, tea_CELoss: 2.6388 stu_CELoss: 3.4475 DMLLoss: 0.5600 
2022-03-13 18:27:56 - train: epoch 0002, iter [01500, 05004], lr: 0.100000, loss: 6.6097, tea_CELoss: 2.5962 stu_CELoss: 3.4368 DMLLoss: 0.5767 
2022-03-13 18:28:30 - train: epoch 0002, iter [01600, 05004], lr: 0.100000, loss: 6.4420, tea_CELoss: 2.5387 stu_CELoss: 3.3456 DMLLoss: 0.5577 
2022-03-13 18:29:02 - train: epoch 0002, iter [01700, 05004], lr: 0.100000, loss: 6.1657, tea_CELoss: 2.4707 stu_CELoss: 3.1881 DMLLoss: 0.5069 
2022-03-13 18:29:36 - train: epoch 0002, iter [01800, 05004], lr: 0.100000, loss: 6.3132, tea_CELoss: 2.5527 stu_CELoss: 3.2136 DMLLoss: 0.5469 
2022-03-13 18:30:09 - train: epoch 0002, iter [01900, 05004], lr: 0.100000, loss: 5.7463, tea_CELoss: 2.3046 stu_CELoss: 2.9143 DMLLoss: 0.5273 
2022-03-13 18:30:43 - train: epoch 0002, iter [02000, 05004], lr: 0.100000, loss: 5.6588, tea_CELoss: 2.2285 stu_CELoss: 2.9074 DMLLoss: 0.5229 
2022-03-13 18:31:16 - train: epoch 0002, iter [02100, 05004], lr: 0.100000, loss: 6.0955, tea_CELoss: 2.4929 stu_CELoss: 3.1186 DMLLoss: 0.4840 
2022-03-13 18:31:50 - train: epoch 0002, iter [02200, 05004], lr: 0.100000, loss: 6.1800, tea_CELoss: 2.5617 stu_CELoss: 3.1272 DMLLoss: 0.4910 
2022-03-13 18:32:23 - train: epoch 0002, iter [02300, 05004], lr: 0.100000, loss: 6.2653, tea_CELoss: 2.4905 stu_CELoss: 3.2280 DMLLoss: 0.5468 
2022-03-13 18:32:56 - train: epoch 0002, iter [02400, 05004], lr: 0.100000, loss: 5.9485, tea_CELoss: 2.4121 stu_CELoss: 3.0303 DMLLoss: 0.5061 
2022-03-13 18:33:29 - train: epoch 0002, iter [02500, 05004], lr: 0.100000, loss: 5.8528, tea_CELoss: 2.3389 stu_CELoss: 2.9826 DMLLoss: 0.5313 
2022-03-13 18:34:03 - train: epoch 0002, iter [02600, 05004], lr: 0.100000, loss: 5.7066, tea_CELoss: 2.3154 stu_CELoss: 2.8998 DMLLoss: 0.4914 
2022-03-13 18:34:36 - train: epoch 0002, iter [02700, 05004], lr: 0.100000, loss: 6.3007, tea_CELoss: 2.5880 stu_CELoss: 3.2183 DMLLoss: 0.4944 
2022-03-13 18:35:09 - train: epoch 0002, iter [02800, 05004], lr: 0.100000, loss: 6.2561, tea_CELoss: 2.5384 stu_CELoss: 3.2132 DMLLoss: 0.5045 
2022-03-13 18:35:42 - train: epoch 0002, iter [02900, 05004], lr: 0.100000, loss: 6.0444, tea_CELoss: 2.4699 stu_CELoss: 3.0769 DMLLoss: 0.4976 
2022-03-13 18:36:15 - train: epoch 0002, iter [03000, 05004], lr: 0.100000, loss: 5.7757, tea_CELoss: 2.3645 stu_CELoss: 2.9064 DMLLoss: 0.5049 
2022-03-13 18:36:48 - train: epoch 0002, iter [03100, 05004], lr: 0.100000, loss: 6.0845, tea_CELoss: 2.4647 stu_CELoss: 3.0985 DMLLoss: 0.5213 
2022-03-13 18:37:21 - train: epoch 0002, iter [03200, 05004], lr: 0.100000, loss: 6.2577, tea_CELoss: 2.5970 stu_CELoss: 3.1741 DMLLoss: 0.4867 
2022-03-13 18:37:54 - train: epoch 0002, iter [03300, 05004], lr: 0.100000, loss: 6.2002, tea_CELoss: 2.6319 stu_CELoss: 3.1320 DMLLoss: 0.4363 
2022-03-13 18:38:28 - train: epoch 0002, iter [03400, 05004], lr: 0.100000, loss: 6.1184, tea_CELoss: 2.4052 stu_CELoss: 3.1667 DMLLoss: 0.5465 
2022-03-13 18:39:01 - train: epoch 0002, iter [03500, 05004], lr: 0.100000, loss: 5.8578, tea_CELoss: 2.3990 stu_CELoss: 2.9739 DMLLoss: 0.4849 
2022-03-13 18:39:34 - train: epoch 0002, iter [03600, 05004], lr: 0.100000, loss: 6.2943, tea_CELoss: 2.6345 stu_CELoss: 3.1868 DMLLoss: 0.4731 
2022-03-13 18:40:07 - train: epoch 0002, iter [03700, 05004], lr: 0.100000, loss: 6.5077, tea_CELoss: 2.6836 stu_CELoss: 3.3097 DMLLoss: 0.5144 
2022-03-13 18:40:40 - train: epoch 0002, iter [03800, 05004], lr: 0.100000, loss: 5.9498, tea_CELoss: 2.5240 stu_CELoss: 2.9475 DMLLoss: 0.4783 
2022-03-13 18:41:14 - train: epoch 0002, iter [03900, 05004], lr: 0.100000, loss: 6.0064, tea_CELoss: 2.4627 stu_CELoss: 3.0406 DMLLoss: 0.5032 
2022-03-13 18:41:47 - train: epoch 0002, iter [04000, 05004], lr: 0.100000, loss: 5.7104, tea_CELoss: 2.3158 stu_CELoss: 2.9217 DMLLoss: 0.4729 
2022-03-13 18:42:20 - train: epoch 0002, iter [04100, 05004], lr: 0.100000, loss: 5.9703, tea_CELoss: 2.4449 stu_CELoss: 3.0476 DMLLoss: 0.4778 
2022-03-13 18:42:53 - train: epoch 0002, iter [04200, 05004], lr: 0.100000, loss: 5.9937, tea_CELoss: 2.5079 stu_CELoss: 3.0266 DMLLoss: 0.4592 
2022-03-13 18:43:26 - train: epoch 0002, iter [04300, 05004], lr: 0.100000, loss: 5.8232, tea_CELoss: 2.4392 stu_CELoss: 2.9261 DMLLoss: 0.4578 
2022-03-13 18:44:00 - train: epoch 0002, iter [04400, 05004], lr: 0.100000, loss: 5.6940, tea_CELoss: 2.2970 stu_CELoss: 2.8891 DMLLoss: 0.5079 
2022-03-13 18:44:32 - train: epoch 0002, iter [04500, 05004], lr: 0.100000, loss: 5.4489, tea_CELoss: 2.2268 stu_CELoss: 2.7430 DMLLoss: 0.4792 
2022-03-13 18:45:06 - train: epoch 0002, iter [04600, 05004], lr: 0.100000, loss: 5.8869, tea_CELoss: 2.3827 stu_CELoss: 2.9984 DMLLoss: 0.5058 
2022-03-13 18:45:38 - train: epoch 0002, iter [04700, 05004], lr: 0.100000, loss: 5.5064, tea_CELoss: 2.3013 stu_CELoss: 2.7741 DMLLoss: 0.4310 
2022-03-13 18:46:11 - train: epoch 0002, iter [04800, 05004], lr: 0.100000, loss: 6.1090, tea_CELoss: 2.5126 stu_CELoss: 3.0966 DMLLoss: 0.4998 
2022-03-13 18:46:44 - train: epoch 0002, iter [04900, 05004], lr: 0.100000, loss: 5.7530, tea_CELoss: 2.3720 stu_CELoss: 2.8936 DMLLoss: 0.4874 
2022-03-13 18:47:16 - train: epoch 0002, iter [05000, 05004], lr: 0.100000, loss: 5.9042, tea_CELoss: 2.4367 stu_CELoss: 2.9934 DMLLoss: 0.4741 
2022-03-13 18:47:17 - train: epoch 002, train_loss: 6.2215
2022-03-13 18:49:45 - eval: epoch: 002, tea_acc1: 50.326%, tea_acc5: 76.384%, tea_test_loss: 2.1573, stu_acc1: 39.642%, stu_acc5: 66.782%, stu_test_loss: 2.7002
2022-03-13 18:49:46 - until epoch: 002, tea_best_acc1: 50.326%, stu_best_acc1: 39.642%
2022-03-13 18:49:46 - epoch 003 lr: 0.1
2022-03-13 18:50:24 - train: epoch 0003, iter [00100, 05004], lr: 0.100000, loss: 5.9487, tea_CELoss: 2.4970 stu_CELoss: 2.9784 DMLLoss: 0.4733 
2022-03-13 18:50:57 - train: epoch 0003, iter [00200, 05004], lr: 0.100000, loss: 5.7444, tea_CELoss: 2.3634 stu_CELoss: 2.8855 DMLLoss: 0.4956 
2022-03-13 18:51:31 - train: epoch 0003, iter [00300, 05004], lr: 0.100000, loss: 5.8243, tea_CELoss: 2.4324 stu_CELoss: 2.8880 DMLLoss: 0.5039 
2022-03-13 18:52:04 - train: epoch 0003, iter [00400, 05004], lr: 0.100000, loss: 5.8241, tea_CELoss: 2.4445 stu_CELoss: 2.9342 DMLLoss: 0.4455 
2022-03-13 18:52:37 - train: epoch 0003, iter [00500, 05004], lr: 0.100000, loss: 5.9849, tea_CELoss: 2.5224 stu_CELoss: 3.0091 DMLLoss: 0.4535 
2022-03-13 18:53:10 - train: epoch 0003, iter [00600, 05004], lr: 0.100000, loss: 5.3893, tea_CELoss: 2.2478 stu_CELoss: 2.7095 DMLLoss: 0.4320 
2022-03-13 18:53:43 - train: epoch 0003, iter [00700, 05004], lr: 0.100000, loss: 5.9858, tea_CELoss: 2.4988 stu_CELoss: 3.0220 DMLLoss: 0.4650 
2022-03-13 18:54:16 - train: epoch 0003, iter [00800, 05004], lr: 0.100000, loss: 6.1214, tea_CELoss: 2.5214 stu_CELoss: 3.0957 DMLLoss: 0.5042 
2022-03-13 18:54:49 - train: epoch 0003, iter [00900, 05004], lr: 0.100000, loss: 5.7885, tea_CELoss: 2.4457 stu_CELoss: 2.8985 DMLLoss: 0.4443 
2022-03-13 18:55:22 - train: epoch 0003, iter [01000, 05004], lr: 0.100000, loss: 5.8961, tea_CELoss: 2.4837 stu_CELoss: 2.9278 DMLLoss: 0.4846 
2022-03-13 18:55:56 - train: epoch 0003, iter [01100, 05004], lr: 0.100000, loss: 5.7273, tea_CELoss: 2.4085 stu_CELoss: 2.8299 DMLLoss: 0.4890 
2022-03-13 18:56:28 - train: epoch 0003, iter [01200, 05004], lr: 0.100000, loss: 5.8397, tea_CELoss: 2.4235 stu_CELoss: 2.9264 DMLLoss: 0.4898 
2022-03-13 18:57:02 - train: epoch 0003, iter [01300, 05004], lr: 0.100000, loss: 5.4474, tea_CELoss: 2.3067 stu_CELoss: 2.7247 DMLLoss: 0.4160 
2022-03-13 18:57:35 - train: epoch 0003, iter [01400, 05004], lr: 0.100000, loss: 5.3270, tea_CELoss: 2.3014 stu_CELoss: 2.5990 DMLLoss: 0.4267 
2022-03-13 18:58:08 - train: epoch 0003, iter [01500, 05004], lr: 0.100000, loss: 6.1053, tea_CELoss: 2.5814 stu_CELoss: 3.0648 DMLLoss: 0.4591 
2022-03-13 18:58:42 - train: epoch 0003, iter [01600, 05004], lr: 0.100000, loss: 5.4165, tea_CELoss: 2.2861 stu_CELoss: 2.6823 DMLLoss: 0.4481 
2022-03-13 18:59:15 - train: epoch 0003, iter [01700, 05004], lr: 0.100000, loss: 5.5045, tea_CELoss: 2.3187 stu_CELoss: 2.7530 DMLLoss: 0.4327 
2022-03-13 18:59:48 - train: epoch 0003, iter [01800, 05004], lr: 0.100000, loss: 5.5111, tea_CELoss: 2.4280 stu_CELoss: 2.6586 DMLLoss: 0.4245 
2022-03-13 19:00:22 - train: epoch 0003, iter [01900, 05004], lr: 0.100000, loss: 5.8357, tea_CELoss: 2.4440 stu_CELoss: 2.9061 DMLLoss: 0.4857 
2022-03-13 19:00:54 - train: epoch 0003, iter [02000, 05004], lr: 0.100000, loss: 6.0880, tea_CELoss: 2.6390 stu_CELoss: 3.0016 DMLLoss: 0.4473 
2022-03-13 19:01:28 - train: epoch 0003, iter [02100, 05004], lr: 0.100000, loss: 5.6831, tea_CELoss: 2.3824 stu_CELoss: 2.8624 DMLLoss: 0.4383 
2022-03-13 19:02:00 - train: epoch 0003, iter [02200, 05004], lr: 0.100000, loss: 6.5673, tea_CELoss: 2.8025 stu_CELoss: 3.2740 DMLLoss: 0.4909 
2022-03-13 19:02:34 - train: epoch 0003, iter [02300, 05004], lr: 0.100000, loss: 5.5602, tea_CELoss: 2.4022 stu_CELoss: 2.7644 DMLLoss: 0.3936 
2022-03-13 19:03:07 - train: epoch 0003, iter [02400, 05004], lr: 0.100000, loss: 5.4665, tea_CELoss: 2.2696 stu_CELoss: 2.7551 DMLLoss: 0.4418 
2022-03-13 19:03:40 - train: epoch 0003, iter [02500, 05004], lr: 0.100000, loss: 5.8000, tea_CELoss: 2.4418 stu_CELoss: 2.9116 DMLLoss: 0.4467 
2022-03-13 19:04:13 - train: epoch 0003, iter [02600, 05004], lr: 0.100000, loss: 5.8792, tea_CELoss: 2.4795 stu_CELoss: 2.9133 DMLLoss: 0.4864 
2022-03-13 19:04:46 - train: epoch 0003, iter [02700, 05004], lr: 0.100000, loss: 6.0726, tea_CELoss: 2.6503 stu_CELoss: 2.9810 DMLLoss: 0.4412 
2022-03-13 19:05:19 - train: epoch 0003, iter [02800, 05004], lr: 0.100000, loss: 5.3796, tea_CELoss: 2.2944 stu_CELoss: 2.6619 DMLLoss: 0.4233 
2022-03-13 19:05:53 - train: epoch 0003, iter [02900, 05004], lr: 0.100000, loss: 5.7326, tea_CELoss: 2.4415 stu_CELoss: 2.8460 DMLLoss: 0.4451 
2022-03-13 19:06:26 - train: epoch 0003, iter [03000, 05004], lr: 0.100000, loss: 5.4476, tea_CELoss: 2.2603 stu_CELoss: 2.7781 DMLLoss: 0.4092 
2022-03-13 19:07:00 - train: epoch 0003, iter [03100, 05004], lr: 0.100000, loss: 6.1251, tea_CELoss: 2.6275 stu_CELoss: 3.0338 DMLLoss: 0.4638 
2022-03-13 19:07:32 - train: epoch 0003, iter [03200, 05004], lr: 0.100000, loss: 5.8597, tea_CELoss: 2.4837 stu_CELoss: 2.9162 DMLLoss: 0.4597 
2022-03-13 19:08:05 - train: epoch 0003, iter [03300, 05004], lr: 0.100000, loss: 5.4115, tea_CELoss: 2.3176 stu_CELoss: 2.6670 DMLLoss: 0.4269 
2022-03-13 19:08:39 - train: epoch 0003, iter [03400, 05004], lr: 0.100000, loss: 6.1451, tea_CELoss: 2.6459 stu_CELoss: 3.0392 DMLLoss: 0.4600 
2022-03-13 19:09:12 - train: epoch 0003, iter [03500, 05004], lr: 0.100000, loss: 5.6488, tea_CELoss: 2.3077 stu_CELoss: 2.8936 DMLLoss: 0.4475 
2022-03-13 19:09:45 - train: epoch 0003, iter [03600, 05004], lr: 0.100000, loss: 5.3680, tea_CELoss: 2.2841 stu_CELoss: 2.6611 DMLLoss: 0.4228 
2022-03-13 19:10:18 - train: epoch 0003, iter [03700, 05004], lr: 0.100000, loss: 5.7354, tea_CELoss: 2.4442 stu_CELoss: 2.8492 DMLLoss: 0.4420 
2022-03-13 19:10:51 - train: epoch 0003, iter [03800, 05004], lr: 0.100000, loss: 5.9968, tea_CELoss: 2.5525 stu_CELoss: 3.0055 DMLLoss: 0.4388 
2022-03-13 19:11:24 - train: epoch 0003, iter [03900, 05004], lr: 0.100000, loss: 6.2463, tea_CELoss: 2.6900 stu_CELoss: 3.0763 DMLLoss: 0.4800 
2022-03-13 19:11:57 - train: epoch 0003, iter [04000, 05004], lr: 0.100000, loss: 5.1280, tea_CELoss: 2.1423 stu_CELoss: 2.5340 DMLLoss: 0.4517 
2022-03-13 19:12:31 - train: epoch 0003, iter [04100, 05004], lr: 0.100000, loss: 5.6109, tea_CELoss: 2.4310 stu_CELoss: 2.7868 DMLLoss: 0.3930 
2022-03-13 19:13:03 - train: epoch 0003, iter [04200, 05004], lr: 0.100000, loss: 5.6992, tea_CELoss: 2.4492 stu_CELoss: 2.8139 DMLLoss: 0.4360 
2022-03-13 19:13:37 - train: epoch 0003, iter [04300, 05004], lr: 0.100000, loss: 5.0492, tea_CELoss: 2.1287 stu_CELoss: 2.4911 DMLLoss: 0.4294 
2022-03-13 19:14:10 - train: epoch 0003, iter [04400, 05004], lr: 0.100000, loss: 5.4176, tea_CELoss: 2.3289 stu_CELoss: 2.6762 DMLLoss: 0.4125 
2022-03-13 19:14:43 - train: epoch 0003, iter [04500, 05004], lr: 0.100000, loss: 5.5566, tea_CELoss: 2.3530 stu_CELoss: 2.7633 DMLLoss: 0.4403 
2022-03-13 19:15:16 - train: epoch 0003, iter [04600, 05004], lr: 0.100000, loss: 5.3194, tea_CELoss: 2.2341 stu_CELoss: 2.6251 DMLLoss: 0.4602 
2022-03-13 19:15:49 - train: epoch 0003, iter [04700, 05004], lr: 0.100000, loss: 5.3996, tea_CELoss: 2.3492 stu_CELoss: 2.6696 DMLLoss: 0.3808 
2022-03-13 19:16:22 - train: epoch 0003, iter [04800, 05004], lr: 0.100000, loss: 6.1600, tea_CELoss: 2.6163 stu_CELoss: 3.0716 DMLLoss: 0.4722 
2022-03-13 19:16:55 - train: epoch 0003, iter [04900, 05004], lr: 0.100000, loss: 5.7589, tea_CELoss: 2.4398 stu_CELoss: 2.8710 DMLLoss: 0.4481 
2022-03-13 19:17:27 - train: epoch 0003, iter [05000, 05004], lr: 0.100000, loss: 5.7184, tea_CELoss: 2.3910 stu_CELoss: 2.8758 DMLLoss: 0.4517 
2022-03-13 19:17:28 - train: epoch 003, train_loss: 5.6846
2022-03-13 19:19:57 - eval: epoch: 003, tea_acc1: 50.830%, tea_acc5: 76.900%, tea_test_loss: 2.1325, stu_acc1: 43.052%, stu_acc5: 69.662%, stu_test_loss: 2.5382
2022-03-13 19:19:58 - until epoch: 003, tea_best_acc1: 50.830%, stu_best_acc1: 43.052%
2022-03-13 19:19:58 - epoch 004 lr: 0.1
2022-03-13 19:20:35 - train: epoch 0004, iter [00100, 05004], lr: 0.100000, loss: 6.1546, tea_CELoss: 2.7076 stu_CELoss: 2.9666 DMLLoss: 0.4804 
2022-03-13 19:21:09 - train: epoch 0004, iter [00200, 05004], lr: 0.100000, loss: 5.1330, tea_CELoss: 2.2215 stu_CELoss: 2.5108 DMLLoss: 0.4007 
2022-03-13 19:21:43 - train: epoch 0004, iter [00300, 05004], lr: 0.100000, loss: 5.3783, tea_CELoss: 2.3203 stu_CELoss: 2.6483 DMLLoss: 0.4097 
2022-03-13 19:22:16 - train: epoch 0004, iter [00400, 05004], lr: 0.100000, loss: 5.4382, tea_CELoss: 2.3307 stu_CELoss: 2.6675 DMLLoss: 0.4399 
2022-03-13 19:22:49 - train: epoch 0004, iter [00500, 05004], lr: 0.100000, loss: 5.4015, tea_CELoss: 2.3090 stu_CELoss: 2.6327 DMLLoss: 0.4599 
2022-03-13 19:23:23 - train: epoch 0004, iter [00600, 05004], lr: 0.100000, loss: 5.8899, tea_CELoss: 2.5454 stu_CELoss: 2.9179 DMLLoss: 0.4266 
2022-03-13 19:23:57 - train: epoch 0004, iter [00700, 05004], lr: 0.100000, loss: 5.7825, tea_CELoss: 2.4923 stu_CELoss: 2.8688 DMLLoss: 0.4215 
2022-03-13 19:24:30 - train: epoch 0004, iter [00800, 05004], lr: 0.100000, loss: 5.3345, tea_CELoss: 2.2515 stu_CELoss: 2.6436 DMLLoss: 0.4393 
2022-03-13 19:25:04 - train: epoch 0004, iter [00900, 05004], lr: 0.100000, loss: 4.8356, tea_CELoss: 2.0248 stu_CELoss: 2.3820 DMLLoss: 0.4289 
2022-03-13 19:25:37 - train: epoch 0004, iter [01000, 05004], lr: 0.100000, loss: 5.6040, tea_CELoss: 2.3256 stu_CELoss: 2.8138 DMLLoss: 0.4645 
2022-03-13 19:26:11 - train: epoch 0004, iter [01100, 05004], lr: 0.100000, loss: 5.7882, tea_CELoss: 2.4814 stu_CELoss: 2.8645 DMLLoss: 0.4422 
2022-03-13 19:26:45 - train: epoch 0004, iter [01200, 05004], lr: 0.100000, loss: 5.0879, tea_CELoss: 2.1263 stu_CELoss: 2.5296 DMLLoss: 0.4321 
2022-03-13 19:27:18 - train: epoch 0004, iter [01300, 05004], lr: 0.100000, loss: 5.4654, tea_CELoss: 2.3672 stu_CELoss: 2.6324 DMLLoss: 0.4658 
2022-03-13 19:27:52 - train: epoch 0004, iter [01400, 05004], lr: 0.100000, loss: 5.6604, tea_CELoss: 2.4571 stu_CELoss: 2.7716 DMLLoss: 0.4318 
2022-03-13 19:28:25 - train: epoch 0004, iter [01500, 05004], lr: 0.100000, loss: 5.3834, tea_CELoss: 2.2659 stu_CELoss: 2.6792 DMLLoss: 0.4383 
2022-03-13 19:29:00 - train: epoch 0004, iter [01600, 05004], lr: 0.100000, loss: 5.6901, tea_CELoss: 2.4503 stu_CELoss: 2.7870 DMLLoss: 0.4527 
2022-03-13 19:29:33 - train: epoch 0004, iter [01700, 05004], lr: 0.100000, loss: 5.4167, tea_CELoss: 2.3182 stu_CELoss: 2.6358 DMLLoss: 0.4627 
2022-03-13 19:30:07 - train: epoch 0004, iter [01800, 05004], lr: 0.100000, loss: 5.9714, tea_CELoss: 2.5722 stu_CELoss: 2.9672 DMLLoss: 0.4320 
2022-03-13 19:30:40 - train: epoch 0004, iter [01900, 05004], lr: 0.100000, loss: 5.4768, tea_CELoss: 2.3452 stu_CELoss: 2.6982 DMLLoss: 0.4333 
2022-03-13 19:31:15 - train: epoch 0004, iter [02000, 05004], lr: 0.100000, loss: 5.7665, tea_CELoss: 2.4670 stu_CELoss: 2.8600 DMLLoss: 0.4395 
2022-03-13 19:31:48 - train: epoch 0004, iter [02100, 05004], lr: 0.100000, loss: 5.3224, tea_CELoss: 2.2996 stu_CELoss: 2.6225 DMLLoss: 0.4004 
2022-03-13 19:32:21 - train: epoch 0004, iter [02200, 05004], lr: 0.100000, loss: 5.5329, tea_CELoss: 2.3603 stu_CELoss: 2.7371 DMLLoss: 0.4355 
2022-03-13 19:32:54 - train: epoch 0004, iter [02300, 05004], lr: 0.100000, loss: 4.9927, tea_CELoss: 2.0749 stu_CELoss: 2.4962 DMLLoss: 0.4216 
2022-03-13 19:33:28 - train: epoch 0004, iter [02400, 05004], lr: 0.100000, loss: 5.0325, tea_CELoss: 2.1581 stu_CELoss: 2.4362 DMLLoss: 0.4383 
2022-03-13 19:34:01 - train: epoch 0004, iter [02500, 05004], lr: 0.100000, loss: 5.1926, tea_CELoss: 2.1719 stu_CELoss: 2.5801 DMLLoss: 0.4406 
2022-03-13 19:34:34 - train: epoch 0004, iter [02600, 05004], lr: 0.100000, loss: 5.5009, tea_CELoss: 2.4090 stu_CELoss: 2.6633 DMLLoss: 0.4286 
2022-03-13 19:35:08 - train: epoch 0004, iter [02700, 05004], lr: 0.100000, loss: 5.2067, tea_CELoss: 2.2448 stu_CELoss: 2.5443 DMLLoss: 0.4176 
2022-03-13 19:35:42 - train: epoch 0004, iter [02800, 05004], lr: 0.100000, loss: 5.3142, tea_CELoss: 2.2628 stu_CELoss: 2.6098 DMLLoss: 0.4416 
2022-03-13 19:36:15 - train: epoch 0004, iter [02900, 05004], lr: 0.100000, loss: 5.4858, tea_CELoss: 2.3453 stu_CELoss: 2.7002 DMLLoss: 0.4403 
2022-03-13 19:36:48 - train: epoch 0004, iter [03000, 05004], lr: 0.100000, loss: 5.6435, tea_CELoss: 2.4326 stu_CELoss: 2.7706 DMLLoss: 0.4403 
2022-03-13 19:37:22 - train: epoch 0004, iter [03100, 05004], lr: 0.100000, loss: 5.4797, tea_CELoss: 2.3420 stu_CELoss: 2.6687 DMLLoss: 0.4689 
2022-03-13 19:37:55 - train: epoch 0004, iter [03200, 05004], lr: 0.100000, loss: 5.5819, tea_CELoss: 2.3724 stu_CELoss: 2.7556 DMLLoss: 0.4539 
2022-03-13 19:38:29 - train: epoch 0004, iter [03300, 05004], lr: 0.100000, loss: 5.3397, tea_CELoss: 2.3303 stu_CELoss: 2.6340 DMLLoss: 0.3755 
2022-03-13 19:39:02 - train: epoch 0004, iter [03400, 05004], lr: 0.100000, loss: 5.3579, tea_CELoss: 2.3017 stu_CELoss: 2.6229 DMLLoss: 0.4333 
2022-03-13 19:39:36 - train: epoch 0004, iter [03500, 05004], lr: 0.100000, loss: 5.5390, tea_CELoss: 2.4211 stu_CELoss: 2.7222 DMLLoss: 0.3957 
2022-03-13 19:40:09 - train: epoch 0004, iter [03600, 05004], lr: 0.100000, loss: 5.4163, tea_CELoss: 2.3035 stu_CELoss: 2.6700 DMLLoss: 0.4429 
2022-03-13 19:40:42 - train: epoch 0004, iter [03700, 05004], lr: 0.100000, loss: 5.6228, tea_CELoss: 2.4474 stu_CELoss: 2.7431 DMLLoss: 0.4322 
2022-03-13 19:41:16 - train: epoch 0004, iter [03800, 05004], lr: 0.100000, loss: 5.0661, tea_CELoss: 2.1453 stu_CELoss: 2.4989 DMLLoss: 0.4219 
2022-03-13 19:41:49 - train: epoch 0004, iter [03900, 05004], lr: 0.100000, loss: 5.2182, tea_CELoss: 2.2159 stu_CELoss: 2.5600 DMLLoss: 0.4423 
2022-03-13 19:42:22 - train: epoch 0004, iter [04000, 05004], lr: 0.100000, loss: 5.0263, tea_CELoss: 2.1691 stu_CELoss: 2.4331 DMLLoss: 0.4241 
2022-03-13 19:42:56 - train: epoch 0004, iter [04100, 05004], lr: 0.100000, loss: 5.2177, tea_CELoss: 2.2800 stu_CELoss: 2.5282 DMLLoss: 0.4095 
2022-03-13 19:43:29 - train: epoch 0004, iter [04200, 05004], lr: 0.100000, loss: 5.2599, tea_CELoss: 2.2434 stu_CELoss: 2.6001 DMLLoss: 0.4165 
2022-03-13 19:44:03 - train: epoch 0004, iter [04300, 05004], lr: 0.100000, loss: 5.2577, tea_CELoss: 2.2255 stu_CELoss: 2.5730 DMLLoss: 0.4591 
2022-03-13 19:44:36 - train: epoch 0004, iter [04400, 05004], lr: 0.100000, loss: 5.1958, tea_CELoss: 2.2009 stu_CELoss: 2.5645 DMLLoss: 0.4304 
2022-03-13 19:45:09 - train: epoch 0004, iter [04500, 05004], lr: 0.100000, loss: 4.6749, tea_CELoss: 2.0188 stu_CELoss: 2.2818 DMLLoss: 0.3743 
2022-03-13 19:45:43 - train: epoch 0004, iter [04600, 05004], lr: 0.100000, loss: 5.1292, tea_CELoss: 2.2109 stu_CELoss: 2.5355 DMLLoss: 0.3828 
2022-03-13 19:46:15 - train: epoch 0004, iter [04700, 05004], lr: 0.100000, loss: 5.1543, tea_CELoss: 2.2246 stu_CELoss: 2.4890 DMLLoss: 0.4408 
2022-03-13 19:46:49 - train: epoch 0004, iter [04800, 05004], lr: 0.100000, loss: 4.8989, tea_CELoss: 2.0877 stu_CELoss: 2.3666 DMLLoss: 0.4446 
2022-03-13 19:47:21 - train: epoch 0004, iter [04900, 05004], lr: 0.100000, loss: 5.4602, tea_CELoss: 2.3475 stu_CELoss: 2.6889 DMLLoss: 0.4238 
2022-03-13 19:47:54 - train: epoch 0004, iter [05000, 05004], lr: 0.100000, loss: 5.2687, tea_CELoss: 2.2956 stu_CELoss: 2.5362 DMLLoss: 0.4369 
2022-03-13 19:47:55 - train: epoch 004, train_loss: 5.4555
2022-03-13 19:50:25 - eval: epoch: 004, tea_acc1: 51.576%, tea_acc5: 77.446%, tea_test_loss: 2.0745, stu_acc1: 45.324%, stu_acc5: 71.990%, stu_test_loss: 2.3920
2022-03-13 19:50:26 - until epoch: 004, tea_best_acc1: 51.576%, stu_best_acc1: 45.324%
2022-03-13 19:50:26 - epoch 005 lr: 0.1
2022-03-13 19:51:05 - train: epoch 0005, iter [00100, 05004], lr: 0.100000, loss: 5.5962, tea_CELoss: 2.4407 stu_CELoss: 2.7430 DMLLoss: 0.4125 
2022-03-13 19:51:38 - train: epoch 0005, iter [00200, 05004], lr: 0.100000, loss: 5.4224, tea_CELoss: 2.3627 stu_CELoss: 2.6434 DMLLoss: 0.4163 
2022-03-13 19:52:11 - train: epoch 0005, iter [00300, 05004], lr: 0.100000, loss: 5.8600, tea_CELoss: 2.5272 stu_CELoss: 2.8666 DMLLoss: 0.4662 
2022-03-13 19:52:44 - train: epoch 0005, iter [00400, 05004], lr: 0.100000, loss: 5.1908, tea_CELoss: 2.2690 stu_CELoss: 2.4884 DMLLoss: 0.4334 
2022-03-13 19:53:18 - train: epoch 0005, iter [00500, 05004], lr: 0.100000, loss: 5.1642, tea_CELoss: 2.1994 stu_CELoss: 2.5298 DMLLoss: 0.4351 
2022-03-13 19:53:50 - train: epoch 0005, iter [00600, 05004], lr: 0.100000, loss: 5.5970, tea_CELoss: 2.4168 stu_CELoss: 2.7113 DMLLoss: 0.4689 
2022-03-13 19:54:24 - train: epoch 0005, iter [00700, 05004], lr: 0.100000, loss: 5.4437, tea_CELoss: 2.3617 stu_CELoss: 2.6280 DMLLoss: 0.4540 
2022-03-13 19:54:56 - train: epoch 0005, iter [00800, 05004], lr: 0.100000, loss: 5.8994, tea_CELoss: 2.5737 stu_CELoss: 2.8672 DMLLoss: 0.4585 
2022-03-13 19:55:29 - train: epoch 0005, iter [00900, 05004], lr: 0.100000, loss: 5.3459, tea_CELoss: 2.3300 stu_CELoss: 2.5770 DMLLoss: 0.4388 
2022-03-13 19:56:02 - train: epoch 0005, iter [01000, 05004], lr: 0.100000, loss: 5.6105, tea_CELoss: 2.4660 stu_CELoss: 2.7508 DMLLoss: 0.3937 
2022-03-13 19:56:35 - train: epoch 0005, iter [01100, 05004], lr: 0.100000, loss: 5.4016, tea_CELoss: 2.3439 stu_CELoss: 2.6131 DMLLoss: 0.4446 
2022-03-13 19:57:09 - train: epoch 0005, iter [01200, 05004], lr: 0.100000, loss: 5.4305, tea_CELoss: 2.3642 stu_CELoss: 2.6516 DMLLoss: 0.4146 
2022-03-13 19:57:41 - train: epoch 0005, iter [01300, 05004], lr: 0.100000, loss: 5.0614, tea_CELoss: 2.1568 stu_CELoss: 2.4869 DMLLoss: 0.4177 
2022-03-13 19:58:15 - train: epoch 0005, iter [01400, 05004], lr: 0.100000, loss: 5.3146, tea_CELoss: 2.3537 stu_CELoss: 2.5822 DMLLoss: 0.3787 
2022-03-13 19:58:48 - train: epoch 0005, iter [01500, 05004], lr: 0.100000, loss: 5.2309, tea_CELoss: 2.2462 stu_CELoss: 2.5777 DMLLoss: 0.4071 
2022-03-13 19:59:21 - train: epoch 0005, iter [01600, 05004], lr: 0.100000, loss: 4.8629, tea_CELoss: 2.0830 stu_CELoss: 2.3879 DMLLoss: 0.3920 
2022-03-13 19:59:55 - train: epoch 0005, iter [01700, 05004], lr: 0.100000, loss: 5.4927, tea_CELoss: 2.3502 stu_CELoss: 2.7057 DMLLoss: 0.4368 
2022-03-13 20:00:28 - train: epoch 0005, iter [01800, 05004], lr: 0.100000, loss: 5.1074, tea_CELoss: 2.2152 stu_CELoss: 2.4495 DMLLoss: 0.4428 
2022-03-13 20:01:01 - train: epoch 0005, iter [01900, 05004], lr: 0.100000, loss: 5.1254, tea_CELoss: 2.2629 stu_CELoss: 2.4632 DMLLoss: 0.3994 
2022-03-13 20:01:35 - train: epoch 0005, iter [02000, 05004], lr: 0.100000, loss: 5.2879, tea_CELoss: 2.2878 stu_CELoss: 2.5627 DMLLoss: 0.4375 
2022-03-13 20:02:08 - train: epoch 0005, iter [02100, 05004], lr: 0.100000, loss: 5.2066, tea_CELoss: 2.1780 stu_CELoss: 2.5910 DMLLoss: 0.4377 
2022-03-13 20:02:41 - train: epoch 0005, iter [02200, 05004], lr: 0.100000, loss: 5.3435, tea_CELoss: 2.3228 stu_CELoss: 2.6106 DMLLoss: 0.4101 
2022-03-13 20:03:15 - train: epoch 0005, iter [02300, 05004], lr: 0.100000, loss: 4.7158, tea_CELoss: 2.0186 stu_CELoss: 2.2677 DMLLoss: 0.4295 
2022-03-13 20:03:48 - train: epoch 0005, iter [02400, 05004], lr: 0.100000, loss: 5.2545, tea_CELoss: 2.2987 stu_CELoss: 2.5315 DMLLoss: 0.4243 
2022-03-13 20:04:22 - train: epoch 0005, iter [02500, 05004], lr: 0.100000, loss: 5.5141, tea_CELoss: 2.3707 stu_CELoss: 2.6927 DMLLoss: 0.4507 
2022-03-13 20:04:55 - train: epoch 0005, iter [02600, 05004], lr: 0.100000, loss: 5.2046, tea_CELoss: 2.2154 stu_CELoss: 2.5255 DMLLoss: 0.4637 
2022-03-13 20:05:28 - train: epoch 0005, iter [02700, 05004], lr: 0.100000, loss: 5.5214, tea_CELoss: 2.3351 stu_CELoss: 2.7531 DMLLoss: 0.4331 
2022-03-13 20:06:01 - train: epoch 0005, iter [02800, 05004], lr: 0.100000, loss: 5.2397, tea_CELoss: 2.2601 stu_CELoss: 2.5760 DMLLoss: 0.4037 
2022-03-13 20:06:35 - train: epoch 0005, iter [02900, 05004], lr: 0.100000, loss: 5.2785, tea_CELoss: 2.3088 stu_CELoss: 2.5884 DMLLoss: 0.3813 
2022-03-13 20:07:08 - train: epoch 0005, iter [03000, 05004], lr: 0.100000, loss: 5.2657, tea_CELoss: 2.2863 stu_CELoss: 2.5579 DMLLoss: 0.4215 
2022-03-13 20:07:42 - train: epoch 0005, iter [03100, 05004], lr: 0.100000, loss: 5.4794, tea_CELoss: 2.3119 stu_CELoss: 2.6922 DMLLoss: 0.4752 
2022-03-13 20:08:15 - train: epoch 0005, iter [03200, 05004], lr: 0.100000, loss: 5.4903, tea_CELoss: 2.4088 stu_CELoss: 2.6741 DMLLoss: 0.4073 
2022-03-13 20:08:48 - train: epoch 0005, iter [03300, 05004], lr: 0.100000, loss: 4.9813, tea_CELoss: 2.2183 stu_CELoss: 2.3291 DMLLoss: 0.4338 
2022-03-13 20:09:21 - train: epoch 0005, iter [03400, 05004], lr: 0.100000, loss: 5.3077, tea_CELoss: 2.2945 stu_CELoss: 2.5293 DMLLoss: 0.4839 
2022-03-13 20:09:54 - train: epoch 0005, iter [03500, 05004], lr: 0.100000, loss: 5.6245, tea_CELoss: 2.5061 stu_CELoss: 2.7024 DMLLoss: 0.4159 
2022-03-13 20:10:28 - train: epoch 0005, iter [03600, 05004], lr: 0.100000, loss: 5.3192, tea_CELoss: 2.3321 stu_CELoss: 2.6026 DMLLoss: 0.3845 
2022-03-13 20:11:01 - train: epoch 0005, iter [03700, 05004], lr: 0.100000, loss: 5.1927, tea_CELoss: 2.2613 stu_CELoss: 2.5353 DMLLoss: 0.3961 
2022-03-13 20:11:35 - train: epoch 0005, iter [03800, 05004], lr: 0.100000, loss: 5.4945, tea_CELoss: 2.3106 stu_CELoss: 2.7574 DMLLoss: 0.4265 
2022-03-13 20:12:08 - train: epoch 0005, iter [03900, 05004], lr: 0.100000, loss: 5.5691, tea_CELoss: 2.4294 stu_CELoss: 2.7013 DMLLoss: 0.4384 
2022-03-13 20:12:42 - train: epoch 0005, iter [04000, 05004], lr: 0.100000, loss: 5.4301, tea_CELoss: 2.3793 stu_CELoss: 2.6034 DMLLoss: 0.4475 
2022-03-13 20:13:15 - train: epoch 0005, iter [04100, 05004], lr: 0.100000, loss: 5.4865, tea_CELoss: 2.3824 stu_CELoss: 2.6674 DMLLoss: 0.4367 
2022-03-13 20:13:48 - train: epoch 0005, iter [04200, 05004], lr: 0.100000, loss: 5.6558, tea_CELoss: 2.5094 stu_CELoss: 2.7167 DMLLoss: 0.4297 
2022-03-13 20:14:22 - train: epoch 0005, iter [04300, 05004], lr: 0.100000, loss: 5.4673, tea_CELoss: 2.4210 stu_CELoss: 2.6476 DMLLoss: 0.3988 
2022-03-13 20:14:55 - train: epoch 0005, iter [04400, 05004], lr: 0.100000, loss: 5.6290, tea_CELoss: 2.5202 stu_CELoss: 2.6817 DMLLoss: 0.4270 
2022-03-13 20:15:29 - train: epoch 0005, iter [04500, 05004], lr: 0.100000, loss: 5.3500, tea_CELoss: 2.3372 stu_CELoss: 2.6250 DMLLoss: 0.3878 
2022-03-13 20:16:02 - train: epoch 0005, iter [04600, 05004], lr: 0.100000, loss: 5.1466, tea_CELoss: 2.2976 stu_CELoss: 2.4746 DMLLoss: 0.3745 
2022-03-13 20:16:35 - train: epoch 0005, iter [04700, 05004], lr: 0.100000, loss: 5.0206, tea_CELoss: 2.1517 stu_CELoss: 2.4452 DMLLoss: 0.4238 
2022-03-13 20:17:08 - train: epoch 0005, iter [04800, 05004], lr: 0.100000, loss: 5.1406, tea_CELoss: 2.3036 stu_CELoss: 2.4442 DMLLoss: 0.3928 
2022-03-13 20:17:42 - train: epoch 0005, iter [04900, 05004], lr: 0.100000, loss: 5.8426, tea_CELoss: 2.5116 stu_CELoss: 2.8641 DMLLoss: 0.4670 
2022-03-13 20:18:13 - train: epoch 0005, iter [05000, 05004], lr: 0.100000, loss: 5.1444, tea_CELoss: 2.2708 stu_CELoss: 2.4821 DMLLoss: 0.3915 
2022-03-13 20:18:14 - train: epoch 005, train_loss: 5.3299
2022-03-13 20:20:44 - eval: epoch: 005, tea_acc1: 52.464%, tea_acc5: 78.044%, tea_test_loss: 2.0285, stu_acc1: 47.326%, stu_acc5: 73.578%, stu_test_loss: 2.3004
2022-03-13 20:20:45 - until epoch: 005, tea_best_acc1: 52.464%, stu_best_acc1: 47.326%
2022-03-13 20:20:45 - epoch 006 lr: 0.1
2022-03-13 20:21:24 - train: epoch 0006, iter [00100, 05004], lr: 0.100000, loss: 4.8995, tea_CELoss: 2.1713 stu_CELoss: 2.3347 DMLLoss: 0.3934 
2022-03-13 20:21:57 - train: epoch 0006, iter [00200, 05004], lr: 0.100000, loss: 5.2237, tea_CELoss: 2.3028 stu_CELoss: 2.5347 DMLLoss: 0.3863 
2022-03-13 20:22:31 - train: epoch 0006, iter [00300, 05004], lr: 0.100000, loss: 4.9598, tea_CELoss: 2.1852 stu_CELoss: 2.3766 DMLLoss: 0.3980 
2022-03-13 20:23:04 - train: epoch 0006, iter [00400, 05004], lr: 0.100000, loss: 5.2246, tea_CELoss: 2.3146 stu_CELoss: 2.4855 DMLLoss: 0.4245 
2022-03-13 20:23:38 - train: epoch 0006, iter [00500, 05004], lr: 0.100000, loss: 4.9551, tea_CELoss: 2.1125 stu_CELoss: 2.4203 DMLLoss: 0.4223 
2022-03-13 20:24:11 - train: epoch 0006, iter [00600, 05004], lr: 0.100000, loss: 4.9101, tea_CELoss: 2.1786 stu_CELoss: 2.3276 DMLLoss: 0.4039 
2022-03-13 20:24:45 - train: epoch 0006, iter [00700, 05004], lr: 0.100000, loss: 5.6825, tea_CELoss: 2.4771 stu_CELoss: 2.7800 DMLLoss: 0.4254 
2022-03-13 20:25:18 - train: epoch 0006, iter [00800, 05004], lr: 0.100000, loss: 4.9989, tea_CELoss: 2.1301 stu_CELoss: 2.4570 DMLLoss: 0.4117 
2022-03-13 20:25:51 - train: epoch 0006, iter [00900, 05004], lr: 0.100000, loss: 4.9670, tea_CELoss: 2.2355 stu_CELoss: 2.3415 DMLLoss: 0.3900 
2022-03-13 20:26:24 - train: epoch 0006, iter [01000, 05004], lr: 0.100000, loss: 5.1896, tea_CELoss: 2.2815 stu_CELoss: 2.4812 DMLLoss: 0.4269 
2022-03-13 20:26:57 - train: epoch 0006, iter [01100, 05004], lr: 0.100000, loss: 5.3857, tea_CELoss: 2.3199 stu_CELoss: 2.6271 DMLLoss: 0.4387 
2022-03-13 20:27:31 - train: epoch 0006, iter [01200, 05004], lr: 0.100000, loss: 5.4455, tea_CELoss: 2.3584 stu_CELoss: 2.6378 DMLLoss: 0.4494 
2022-03-13 20:28:04 - train: epoch 0006, iter [01300, 05004], lr: 0.100000, loss: 5.2757, tea_CELoss: 2.2806 stu_CELoss: 2.5733 DMLLoss: 0.4218 
2022-03-13 20:28:38 - train: epoch 0006, iter [01400, 05004], lr: 0.100000, loss: 5.4668, tea_CELoss: 2.3836 stu_CELoss: 2.6462 DMLLoss: 0.4370 
2022-03-13 20:29:10 - train: epoch 0006, iter [01500, 05004], lr: 0.100000, loss: 5.6478, tea_CELoss: 2.4874 stu_CELoss: 2.7464 DMLLoss: 0.4141 
2022-03-13 20:29:43 - train: epoch 0006, iter [01600, 05004], lr: 0.100000, loss: 5.0889, tea_CELoss: 2.2526 stu_CELoss: 2.4015 DMLLoss: 0.4347 
2022-03-13 20:30:17 - train: epoch 0006, iter [01700, 05004], lr: 0.100000, loss: 5.4835, tea_CELoss: 2.4331 stu_CELoss: 2.6521 DMLLoss: 0.3983 
2022-03-13 20:30:50 - train: epoch 0006, iter [01800, 05004], lr: 0.100000, loss: 5.3937, tea_CELoss: 2.3750 stu_CELoss: 2.5855 DMLLoss: 0.4332 
2022-03-13 20:31:23 - train: epoch 0006, iter [01900, 05004], lr: 0.100000, loss: 5.1493, tea_CELoss: 2.2463 stu_CELoss: 2.5099 DMLLoss: 0.3930 
2022-03-13 20:31:57 - train: epoch 0006, iter [02000, 05004], lr: 0.100000, loss: 5.5396, tea_CELoss: 2.4027 stu_CELoss: 2.7171 DMLLoss: 0.4198 
2022-03-13 20:32:30 - train: epoch 0006, iter [02100, 05004], lr: 0.100000, loss: 5.2202, tea_CELoss: 2.2924 stu_CELoss: 2.5176 DMLLoss: 0.4103 
2022-03-13 20:33:03 - train: epoch 0006, iter [02200, 05004], lr: 0.100000, loss: 4.8373, tea_CELoss: 2.1323 stu_CELoss: 2.3151 DMLLoss: 0.3898 
2022-03-13 20:33:37 - train: epoch 0006, iter [02300, 05004], lr: 0.100000, loss: 5.1048, tea_CELoss: 2.2750 stu_CELoss: 2.4260 DMLLoss: 0.4038 
2022-03-13 20:34:10 - train: epoch 0006, iter [02400, 05004], lr: 0.100000, loss: 5.2185, tea_CELoss: 2.2663 stu_CELoss: 2.5275 DMLLoss: 0.4246 
2022-03-13 20:34:43 - train: epoch 0006, iter [02500, 05004], lr: 0.100000, loss: 5.2500, tea_CELoss: 2.2958 stu_CELoss: 2.5829 DMLLoss: 0.3714 
2022-03-13 20:35:16 - train: epoch 0006, iter [02600, 05004], lr: 0.100000, loss: 5.2831, tea_CELoss: 2.2848 stu_CELoss: 2.5749 DMLLoss: 0.4235 
2022-03-13 20:35:49 - train: epoch 0006, iter [02700, 05004], lr: 0.100000, loss: 5.2415, tea_CELoss: 2.3617 stu_CELoss: 2.4768 DMLLoss: 0.4030 
2022-03-13 20:36:23 - train: epoch 0006, iter [02800, 05004], lr: 0.100000, loss: 4.7607, tea_CELoss: 2.0701 stu_CELoss: 2.2997 DMLLoss: 0.3908 
2022-03-13 20:36:56 - train: epoch 0006, iter [02900, 05004], lr: 0.100000, loss: 5.2659, tea_CELoss: 2.2555 stu_CELoss: 2.5716 DMLLoss: 0.4388 
2022-03-13 20:37:29 - train: epoch 0006, iter [03000, 05004], lr: 0.100000, loss: 5.1440, tea_CELoss: 2.2315 stu_CELoss: 2.4990 DMLLoss: 0.4135 
2022-03-13 20:38:02 - train: epoch 0006, iter [03100, 05004], lr: 0.100000, loss: 5.1648, tea_CELoss: 2.1977 stu_CELoss: 2.5538 DMLLoss: 0.4133 
2022-03-13 20:38:35 - train: epoch 0006, iter [03200, 05004], lr: 0.100000, loss: 5.0314, tea_CELoss: 2.1998 stu_CELoss: 2.4477 DMLLoss: 0.3839 
2022-03-13 20:39:08 - train: epoch 0006, iter [03300, 05004], lr: 0.100000, loss: 5.1607, tea_CELoss: 2.1830 stu_CELoss: 2.5403 DMLLoss: 0.4373 
2022-03-13 20:39:42 - train: epoch 0006, iter [03400, 05004], lr: 0.100000, loss: 5.2384, tea_CELoss: 2.2651 stu_CELoss: 2.5770 DMLLoss: 0.3962 
2022-03-13 20:40:15 - train: epoch 0006, iter [03500, 05004], lr: 0.100000, loss: 5.3063, tea_CELoss: 2.3380 stu_CELoss: 2.5408 DMLLoss: 0.4275 
2022-03-13 20:40:48 - train: epoch 0006, iter [03600, 05004], lr: 0.100000, loss: 5.2056, tea_CELoss: 2.3066 stu_CELoss: 2.5015 DMLLoss: 0.3974 
2022-03-13 20:41:21 - train: epoch 0006, iter [03700, 05004], lr: 0.100000, loss: 4.9606, tea_CELoss: 2.1974 stu_CELoss: 2.3606 DMLLoss: 0.4026 
2022-03-13 20:41:53 - train: epoch 0006, iter [03800, 05004], lr: 0.100000, loss: 5.0199, tea_CELoss: 2.1639 stu_CELoss: 2.4325 DMLLoss: 0.4234 
2022-03-13 20:42:26 - train: epoch 0006, iter [03900, 05004], lr: 0.100000, loss: 5.3292, tea_CELoss: 2.2879 stu_CELoss: 2.6069 DMLLoss: 0.4343 
2022-03-13 20:43:00 - train: epoch 0006, iter [04000, 05004], lr: 0.100000, loss: 5.1960, tea_CELoss: 2.2802 stu_CELoss: 2.4922 DMLLoss: 0.4235 
2022-03-13 20:43:33 - train: epoch 0006, iter [04100, 05004], lr: 0.100000, loss: 5.1292, tea_CELoss: 2.2638 stu_CELoss: 2.4790 DMLLoss: 0.3864 
2022-03-13 20:44:05 - train: epoch 0006, iter [04200, 05004], lr: 0.100000, loss: 4.8571, tea_CELoss: 2.1093 stu_CELoss: 2.3405 DMLLoss: 0.4073 
2022-03-13 20:44:38 - train: epoch 0006, iter [04300, 05004], lr: 0.100000, loss: 5.3433, tea_CELoss: 2.3075 stu_CELoss: 2.6026 DMLLoss: 0.4332 
2022-03-13 20:45:12 - train: epoch 0006, iter [04400, 05004], lr: 0.100000, loss: 5.1316, tea_CELoss: 2.2183 stu_CELoss: 2.4899 DMLLoss: 0.4233 
2022-03-13 20:45:46 - train: epoch 0006, iter [04500, 05004], lr: 0.100000, loss: 5.4403, tea_CELoss: 2.4030 stu_CELoss: 2.6244 DMLLoss: 0.4128 
2022-03-13 20:46:19 - train: epoch 0006, iter [04600, 05004], lr: 0.100000, loss: 5.0509, tea_CELoss: 2.2609 stu_CELoss: 2.4069 DMLLoss: 0.3831 
2022-03-13 20:46:52 - train: epoch 0006, iter [04700, 05004], lr: 0.100000, loss: 5.0401, tea_CELoss: 2.2165 stu_CELoss: 2.4433 DMLLoss: 0.3803 
2022-03-13 20:47:25 - train: epoch 0006, iter [04800, 05004], lr: 0.100000, loss: 4.9981, tea_CELoss: 2.2137 stu_CELoss: 2.3970 DMLLoss: 0.3874 
2022-03-13 20:47:58 - train: epoch 0006, iter [04900, 05004], lr: 0.100000, loss: 5.1695, tea_CELoss: 2.3211 stu_CELoss: 2.4868 DMLLoss: 0.3616 
2022-03-13 20:48:30 - train: epoch 0006, iter [05000, 05004], lr: 0.100000, loss: 4.8643, tea_CELoss: 2.1078 stu_CELoss: 2.3653 DMLLoss: 0.3912 
2022-03-13 20:48:31 - train: epoch 006, train_loss: 5.2529
2022-03-13 20:51:00 - eval: epoch: 006, tea_acc1: 53.998%, tea_acc5: 79.194%, tea_test_loss: 1.9546, stu_acc1: 47.784%, stu_acc5: 73.888%, stu_test_loss: 2.2703
2022-03-13 20:51:01 - until epoch: 006, tea_best_acc1: 53.998%, stu_best_acc1: 47.784%
2022-03-13 20:51:01 - epoch 007 lr: 0.1
2022-03-13 20:51:39 - train: epoch 0007, iter [00100, 05004], lr: 0.100000, loss: 4.8017, tea_CELoss: 2.1398 stu_CELoss: 2.2560 DMLLoss: 0.4059 
2022-03-13 20:52:13 - train: epoch 0007, iter [00200, 05004], lr: 0.100000, loss: 5.1232, tea_CELoss: 2.2815 stu_CELoss: 2.4466 DMLLoss: 0.3950 
2022-03-13 20:52:47 - train: epoch 0007, iter [00300, 05004], lr: 0.100000, loss: 5.6468, tea_CELoss: 2.5102 stu_CELoss: 2.7034 DMLLoss: 0.4332 
2022-03-13 20:53:21 - train: epoch 0007, iter [00400, 05004], lr: 0.100000, loss: 5.0790, tea_CELoss: 2.2572 stu_CELoss: 2.4446 DMLLoss: 0.3772 
2022-03-13 20:53:55 - train: epoch 0007, iter [00500, 05004], lr: 0.100000, loss: 4.7942, tea_CELoss: 2.0540 stu_CELoss: 2.3449 DMLLoss: 0.3952 
2022-03-13 20:54:28 - train: epoch 0007, iter [00600, 05004], lr: 0.100000, loss: 5.6388, tea_CELoss: 2.5252 stu_CELoss: 2.7239 DMLLoss: 0.3898 
2022-03-13 20:55:02 - train: epoch 0007, iter [00700, 05004], lr: 0.100000, loss: 5.0612, tea_CELoss: 2.2548 stu_CELoss: 2.4230 DMLLoss: 0.3834 
2022-03-13 20:55:35 - train: epoch 0007, iter [00800, 05004], lr: 0.100000, loss: 5.1989, tea_CELoss: 2.2542 stu_CELoss: 2.5395 DMLLoss: 0.4051 
2022-03-13 20:56:09 - train: epoch 0007, iter [00900, 05004], lr: 0.100000, loss: 5.2925, tea_CELoss: 2.3806 stu_CELoss: 2.5134 DMLLoss: 0.3985 
2022-03-13 20:56:43 - train: epoch 0007, iter [01000, 05004], lr: 0.100000, loss: 5.0860, tea_CELoss: 2.2422 stu_CELoss: 2.4464 DMLLoss: 0.3974 
2022-03-13 20:57:17 - train: epoch 0007, iter [01100, 05004], lr: 0.100000, loss: 5.2984, tea_CELoss: 2.3455 stu_CELoss: 2.5220 DMLLoss: 0.4309 
2022-03-13 20:57:50 - train: epoch 0007, iter [01200, 05004], lr: 0.100000, loss: 5.1945, tea_CELoss: 2.2708 stu_CELoss: 2.4812 DMLLoss: 0.4426 
2022-03-13 20:58:24 - train: epoch 0007, iter [01300, 05004], lr: 0.100000, loss: 4.7509, tea_CELoss: 2.0793 stu_CELoss: 2.2517 DMLLoss: 0.4199 
2022-03-13 20:58:57 - train: epoch 0007, iter [01400, 05004], lr: 0.100000, loss: 5.3079, tea_CELoss: 2.3421 stu_CELoss: 2.5655 DMLLoss: 0.4004 
2022-03-13 20:59:31 - train: epoch 0007, iter [01500, 05004], lr: 0.100000, loss: 5.4105, tea_CELoss: 2.4243 stu_CELoss: 2.5743 DMLLoss: 0.4119 
2022-03-13 21:00:05 - train: epoch 0007, iter [01600, 05004], lr: 0.100000, loss: 5.1909, tea_CELoss: 2.2594 stu_CELoss: 2.5013 DMLLoss: 0.4302 
2022-03-13 21:00:38 - train: epoch 0007, iter [01700, 05004], lr: 0.100000, loss: 5.0931, tea_CELoss: 2.1736 stu_CELoss: 2.4693 DMLLoss: 0.4502 
2022-03-13 21:01:11 - train: epoch 0007, iter [01800, 05004], lr: 0.100000, loss: 5.3104, tea_CELoss: 2.3597 stu_CELoss: 2.5246 DMLLoss: 0.4261 
2022-03-13 21:01:45 - train: epoch 0007, iter [01900, 05004], lr: 0.100000, loss: 5.1675, tea_CELoss: 2.2237 stu_CELoss: 2.5244 DMLLoss: 0.4194 
2022-03-13 21:02:19 - train: epoch 0007, iter [02000, 05004], lr: 0.100000, loss: 4.5593, tea_CELoss: 2.0033 stu_CELoss: 2.1826 DMLLoss: 0.3734 
2022-03-13 21:02:53 - train: epoch 0007, iter [02100, 05004], lr: 0.100000, loss: 5.4776, tea_CELoss: 2.3629 stu_CELoss: 2.7070 DMLLoss: 0.4077 
2022-03-13 21:03:26 - train: epoch 0007, iter [02200, 05004], lr: 0.100000, loss: 4.8556, tea_CELoss: 2.1184 stu_CELoss: 2.3467 DMLLoss: 0.3905 
2022-03-13 21:04:00 - train: epoch 0007, iter [02300, 05004], lr: 0.100000, loss: 5.4484, tea_CELoss: 2.3247 stu_CELoss: 2.6670 DMLLoss: 0.4567 
2022-03-13 21:04:33 - train: epoch 0007, iter [02400, 05004], lr: 0.100000, loss: 5.6745, tea_CELoss: 2.5014 stu_CELoss: 2.7740 DMLLoss: 0.3991 
2022-03-13 21:05:07 - train: epoch 0007, iter [02500, 05004], lr: 0.100000, loss: 5.3602, tea_CELoss: 2.3470 stu_CELoss: 2.6008 DMLLoss: 0.4124 
2022-03-13 21:05:40 - train: epoch 0007, iter [02600, 05004], lr: 0.100000, loss: 4.9534, tea_CELoss: 2.1738 stu_CELoss: 2.4029 DMLLoss: 0.3767 
2022-03-13 21:06:13 - train: epoch 0007, iter [02700, 05004], lr: 0.100000, loss: 4.9107, tea_CELoss: 2.1863 stu_CELoss: 2.3399 DMLLoss: 0.3845 
2022-03-13 21:06:46 - train: epoch 0007, iter [02800, 05004], lr: 0.100000, loss: 5.0542, tea_CELoss: 2.1785 stu_CELoss: 2.4763 DMLLoss: 0.3994 
2022-03-13 21:07:21 - train: epoch 0007, iter [02900, 05004], lr: 0.100000, loss: 5.1539, tea_CELoss: 2.1915 stu_CELoss: 2.4843 DMLLoss: 0.4781 
2022-03-13 21:07:54 - train: epoch 0007, iter [03000, 05004], lr: 0.100000, loss: 5.4796, tea_CELoss: 2.4488 stu_CELoss: 2.6006 DMLLoss: 0.4302 
2022-03-13 21:08:27 - train: epoch 0007, iter [03100, 05004], lr: 0.100000, loss: 4.8253, tea_CELoss: 2.1194 stu_CELoss: 2.3180 DMLLoss: 0.3880 
2022-03-13 21:09:01 - train: epoch 0007, iter [03200, 05004], lr: 0.100000, loss: 4.6486, tea_CELoss: 2.0057 stu_CELoss: 2.2617 DMLLoss: 0.3812 
2022-03-13 21:09:34 - train: epoch 0007, iter [03300, 05004], lr: 0.100000, loss: 5.5174, tea_CELoss: 2.4566 stu_CELoss: 2.6610 DMLLoss: 0.3999 
2022-03-13 21:10:07 - train: epoch 0007, iter [03400, 05004], lr: 0.100000, loss: 5.5080, tea_CELoss: 2.4016 stu_CELoss: 2.6633 DMLLoss: 0.4431 
2022-03-13 21:10:40 - train: epoch 0007, iter [03500, 05004], lr: 0.100000, loss: 5.4609, tea_CELoss: 2.4242 stu_CELoss: 2.6441 DMLLoss: 0.3926 
2022-03-13 21:11:14 - train: epoch 0007, iter [03600, 05004], lr: 0.100000, loss: 5.0641, tea_CELoss: 2.2157 stu_CELoss: 2.4402 DMLLoss: 0.4082 
2022-03-13 21:11:47 - train: epoch 0007, iter [03700, 05004], lr: 0.100000, loss: 5.0399, tea_CELoss: 2.2172 stu_CELoss: 2.4167 DMLLoss: 0.4059 
2022-03-13 21:12:20 - train: epoch 0007, iter [03800, 05004], lr: 0.100000, loss: 5.7380, tea_CELoss: 2.5269 stu_CELoss: 2.7710 DMLLoss: 0.4402 
2022-03-13 21:12:54 - train: epoch 0007, iter [03900, 05004], lr: 0.100000, loss: 5.3932, tea_CELoss: 2.3605 stu_CELoss: 2.5681 DMLLoss: 0.4646 
2022-03-13 21:13:27 - train: epoch 0007, iter [04000, 05004], lr: 0.100000, loss: 5.5712, tea_CELoss: 2.4346 stu_CELoss: 2.6855 DMLLoss: 0.4511 
2022-03-13 21:14:00 - train: epoch 0007, iter [04100, 05004], lr: 0.100000, loss: 5.1125, tea_CELoss: 2.2323 stu_CELoss: 2.4438 DMLLoss: 0.4364 
2022-03-13 21:14:34 - train: epoch 0007, iter [04200, 05004], lr: 0.100000, loss: 4.8431, tea_CELoss: 2.1354 stu_CELoss: 2.3252 DMLLoss: 0.3825 
2022-03-13 21:15:07 - train: epoch 0007, iter [04300, 05004], lr: 0.100000, loss: 5.3284, tea_CELoss: 2.3870 stu_CELoss: 2.5592 DMLLoss: 0.3822 
2022-03-13 21:15:41 - train: epoch 0007, iter [04400, 05004], lr: 0.100000, loss: 4.8651, tea_CELoss: 2.1549 stu_CELoss: 2.3086 DMLLoss: 0.4017 
2022-03-13 21:16:14 - train: epoch 0007, iter [04500, 05004], lr: 0.100000, loss: 5.2459, tea_CELoss: 2.3080 stu_CELoss: 2.5309 DMLLoss: 0.4070 
2022-03-13 21:16:48 - train: epoch 0007, iter [04600, 05004], lr: 0.100000, loss: 5.2948, tea_CELoss: 2.3587 stu_CELoss: 2.5107 DMLLoss: 0.4254 
2022-03-13 21:17:20 - train: epoch 0007, iter [04700, 05004], lr: 0.100000, loss: 4.6786, tea_CELoss: 2.0030 stu_CELoss: 2.2830 DMLLoss: 0.3927 
2022-03-13 21:17:55 - train: epoch 0007, iter [04800, 05004], lr: 0.100000, loss: 5.4262, tea_CELoss: 2.3716 stu_CELoss: 2.6733 DMLLoss: 0.3813 
2022-03-13 21:18:28 - train: epoch 0007, iter [04900, 05004], lr: 0.100000, loss: 4.9938, tea_CELoss: 2.1780 stu_CELoss: 2.4215 DMLLoss: 0.3942 
2022-03-13 21:19:00 - train: epoch 0007, iter [05000, 05004], lr: 0.100000, loss: 5.1887, tea_CELoss: 2.3038 stu_CELoss: 2.4823 DMLLoss: 0.4027 
2022-03-13 21:19:01 - train: epoch 007, train_loss: 5.2008
2022-03-13 21:21:29 - eval: epoch: 007, tea_acc1: 53.848%, tea_acc5: 79.018%, tea_test_loss: 1.9619, stu_acc1: 48.488%, stu_acc5: 74.446%, stu_test_loss: 2.2386
2022-03-13 21:21:30 - until epoch: 007, tea_best_acc1: 53.998%, stu_best_acc1: 48.488%
2022-03-13 21:21:30 - epoch 008 lr: 0.1
2022-03-13 21:22:08 - train: epoch 0008, iter [00100, 05004], lr: 0.100000, loss: 5.0424, tea_CELoss: 2.2307 stu_CELoss: 2.4197 DMLLoss: 0.3920 
2022-03-13 21:22:43 - train: epoch 0008, iter [00200, 05004], lr: 0.100000, loss: 5.4911, tea_CELoss: 2.4132 stu_CELoss: 2.6819 DMLLoss: 0.3960 
2022-03-13 21:23:14 - train: epoch 0008, iter [00300, 05004], lr: 0.100000, loss: 5.1624, tea_CELoss: 2.2873 stu_CELoss: 2.4675 DMLLoss: 0.4076 
2022-03-13 21:23:49 - train: epoch 0008, iter [00400, 05004], lr: 0.100000, loss: 4.8582, tea_CELoss: 2.1344 stu_CELoss: 2.3170 DMLLoss: 0.4068 
2022-03-13 21:24:23 - train: epoch 0008, iter [00500, 05004], lr: 0.100000, loss: 4.7988, tea_CELoss: 2.1095 stu_CELoss: 2.2895 DMLLoss: 0.3997 
2022-03-13 21:24:57 - train: epoch 0008, iter [00600, 05004], lr: 0.100000, loss: 4.7908, tea_CELoss: 2.1625 stu_CELoss: 2.2451 DMLLoss: 0.3832 
2022-03-13 21:25:30 - train: epoch 0008, iter [00700, 05004], lr: 0.100000, loss: 5.3659, tea_CELoss: 2.2990 stu_CELoss: 2.6225 DMLLoss: 0.4444 
2022-03-13 21:26:04 - train: epoch 0008, iter [00800, 05004], lr: 0.100000, loss: 4.5594, tea_CELoss: 1.9640 stu_CELoss: 2.2118 DMLLoss: 0.3836 
2022-03-13 21:26:37 - train: epoch 0008, iter [00900, 05004], lr: 0.100000, loss: 5.1280, tea_CELoss: 2.2476 stu_CELoss: 2.4659 DMLLoss: 0.4145 
2022-03-13 21:27:11 - train: epoch 0008, iter [01000, 05004], lr: 0.100000, loss: 5.2292, tea_CELoss: 2.3180 stu_CELoss: 2.5064 DMLLoss: 0.4048 
2022-03-13 21:27:44 - train: epoch 0008, iter [01100, 05004], lr: 0.100000, loss: 4.8857, tea_CELoss: 2.1555 stu_CELoss: 2.3144 DMLLoss: 0.4158 
2022-03-13 21:28:17 - train: epoch 0008, iter [01200, 05004], lr: 0.100000, loss: 4.4361, tea_CELoss: 1.8909 stu_CELoss: 2.1436 DMLLoss: 0.4015 
2022-03-13 21:28:50 - train: epoch 0008, iter [01300, 05004], lr: 0.100000, loss: 5.1502, tea_CELoss: 2.2440 stu_CELoss: 2.4690 DMLLoss: 0.4372 
2022-03-13 21:29:24 - train: epoch 0008, iter [01400, 05004], lr: 0.100000, loss: 5.0713, tea_CELoss: 2.2526 stu_CELoss: 2.4497 DMLLoss: 0.3690 
2022-03-13 21:29:58 - train: epoch 0008, iter [01500, 05004], lr: 0.100000, loss: 5.3875, tea_CELoss: 2.2897 stu_CELoss: 2.6181 DMLLoss: 0.4797 
2022-03-13 21:30:33 - train: epoch 0008, iter [01600, 05004], lr: 0.100000, loss: 5.1900, tea_CELoss: 2.2746 stu_CELoss: 2.5359 DMLLoss: 0.3796 
2022-03-13 21:31:06 - train: epoch 0008, iter [01700, 05004], lr: 0.100000, loss: 5.1458, tea_CELoss: 2.3094 stu_CELoss: 2.4183 DMLLoss: 0.4181 
2022-03-13 21:31:39 - train: epoch 0008, iter [01800, 05004], lr: 0.100000, loss: 5.4411, tea_CELoss: 2.3535 stu_CELoss: 2.6289 DMLLoss: 0.4587 
2022-03-13 21:32:13 - train: epoch 0008, iter [01900, 05004], lr: 0.100000, loss: 4.7676, tea_CELoss: 2.1250 stu_CELoss: 2.2805 DMLLoss: 0.3622 
2022-03-13 21:32:46 - train: epoch 0008, iter [02000, 05004], lr: 0.100000, loss: 5.7841, tea_CELoss: 2.5899 stu_CELoss: 2.7867 DMLLoss: 0.4076 
2022-03-13 21:33:20 - train: epoch 0008, iter [02100, 05004], lr: 0.100000, loss: 5.1504, tea_CELoss: 2.2182 stu_CELoss: 2.5127 DMLLoss: 0.4194 
2022-03-13 21:33:54 - train: epoch 0008, iter [02200, 05004], lr: 0.100000, loss: 5.3638, tea_CELoss: 2.4063 stu_CELoss: 2.5613 DMLLoss: 0.3963 
2022-03-13 21:34:27 - train: epoch 0008, iter [02300, 05004], lr: 0.100000, loss: 4.8951, tea_CELoss: 2.1810 stu_CELoss: 2.3130 DMLLoss: 0.4011 
2022-03-13 21:35:00 - train: epoch 0008, iter [02400, 05004], lr: 0.100000, loss: 4.8511, tea_CELoss: 2.0989 stu_CELoss: 2.3164 DMLLoss: 0.4358 
2022-03-13 21:35:34 - train: epoch 0008, iter [02500, 05004], lr: 0.100000, loss: 5.1415, tea_CELoss: 2.2876 stu_CELoss: 2.4273 DMLLoss: 0.4266 
2022-03-13 21:36:08 - train: epoch 0008, iter [02600, 05004], lr: 0.100000, loss: 5.0045, tea_CELoss: 2.2234 stu_CELoss: 2.3577 DMLLoss: 0.4233 
2022-03-13 21:36:41 - train: epoch 0008, iter [02700, 05004], lr: 0.100000, loss: 5.5551, tea_CELoss: 2.4717 stu_CELoss: 2.6578 DMLLoss: 0.4257 
2022-03-13 21:37:14 - train: epoch 0008, iter [02800, 05004], lr: 0.100000, loss: 5.1067, tea_CELoss: 2.3090 stu_CELoss: 2.4193 DMLLoss: 0.3784 
2022-03-13 21:37:48 - train: epoch 0008, iter [02900, 05004], lr: 0.100000, loss: 5.4023, tea_CELoss: 2.3652 stu_CELoss: 2.6310 DMLLoss: 0.4061 
2022-03-13 21:38:22 - train: epoch 0008, iter [03000, 05004], lr: 0.100000, loss: 5.6019, tea_CELoss: 2.4669 stu_CELoss: 2.7432 DMLLoss: 0.3918 
2022-03-13 21:38:55 - train: epoch 0008, iter [03100, 05004], lr: 0.100000, loss: 5.1573, tea_CELoss: 2.2616 stu_CELoss: 2.4861 DMLLoss: 0.4096 
2022-03-13 21:39:29 - train: epoch 0008, iter [03200, 05004], lr: 0.100000, loss: 5.3972, tea_CELoss: 2.3840 stu_CELoss: 2.5757 DMLLoss: 0.4375 
2022-03-13 21:40:02 - train: epoch 0008, iter [03300, 05004], lr: 0.100000, loss: 5.2800, tea_CELoss: 2.3139 stu_CELoss: 2.5499 DMLLoss: 0.4162 
2022-03-13 21:40:35 - train: epoch 0008, iter [03400, 05004], lr: 0.100000, loss: 5.4253, tea_CELoss: 2.4033 stu_CELoss: 2.6307 DMLLoss: 0.3913 
2022-03-13 21:41:08 - train: epoch 0008, iter [03500, 05004], lr: 0.100000, loss: 5.0993, tea_CELoss: 2.2699 stu_CELoss: 2.4311 DMLLoss: 0.3983 
2022-03-13 21:41:41 - train: epoch 0008, iter [03600, 05004], lr: 0.100000, loss: 5.3525, tea_CELoss: 2.3813 stu_CELoss: 2.5718 DMLLoss: 0.3994 
2022-03-13 21:42:14 - train: epoch 0008, iter [03700, 05004], lr: 0.100000, loss: 4.9871, tea_CELoss: 2.2021 stu_CELoss: 2.3703 DMLLoss: 0.4146 
2022-03-13 21:42:48 - train: epoch 0008, iter [03800, 05004], lr: 0.100000, loss: 4.9903, tea_CELoss: 2.1992 stu_CELoss: 2.3876 DMLLoss: 0.4036 
2022-03-13 21:43:20 - train: epoch 0008, iter [03900, 05004], lr: 0.100000, loss: 5.3134, tea_CELoss: 2.3520 stu_CELoss: 2.5601 DMLLoss: 0.4013 
2022-03-13 21:43:54 - train: epoch 0008, iter [04000, 05004], lr: 0.100000, loss: 5.5487, tea_CELoss: 2.4811 stu_CELoss: 2.6376 DMLLoss: 0.4299 
2022-03-13 21:44:27 - train: epoch 0008, iter [04100, 05004], lr: 0.100000, loss: 5.0149, tea_CELoss: 2.1783 stu_CELoss: 2.4262 DMLLoss: 0.4104 
2022-03-13 21:45:01 - train: epoch 0008, iter [04200, 05004], lr: 0.100000, loss: 5.0895, tea_CELoss: 2.2767 stu_CELoss: 2.3926 DMLLoss: 0.4202 
2022-03-13 21:45:34 - train: epoch 0008, iter [04300, 05004], lr: 0.100000, loss: 4.7412, tea_CELoss: 2.1006 stu_CELoss: 2.2619 DMLLoss: 0.3786 
2022-03-13 21:46:08 - train: epoch 0008, iter [04400, 05004], lr: 0.100000, loss: 5.1849, tea_CELoss: 2.3211 stu_CELoss: 2.4777 DMLLoss: 0.3862 
2022-03-13 21:46:40 - train: epoch 0008, iter [04500, 05004], lr: 0.100000, loss: 5.1095, tea_CELoss: 2.2835 stu_CELoss: 2.4212 DMLLoss: 0.4048 
2022-03-13 21:47:14 - train: epoch 0008, iter [04600, 05004], lr: 0.100000, loss: 5.2580, tea_CELoss: 2.3548 stu_CELoss: 2.4887 DMLLoss: 0.4144 
2022-03-13 21:47:48 - train: epoch 0008, iter [04700, 05004], lr: 0.100000, loss: 5.0527, tea_CELoss: 2.2196 stu_CELoss: 2.4323 DMLLoss: 0.4007 
2022-03-13 21:48:20 - train: epoch 0008, iter [04800, 05004], lr: 0.100000, loss: 5.1485, tea_CELoss: 2.2581 stu_CELoss: 2.4977 DMLLoss: 0.3928 
2022-03-13 21:48:53 - train: epoch 0008, iter [04900, 05004], lr: 0.100000, loss: 5.0081, tea_CELoss: 2.2113 stu_CELoss: 2.4364 DMLLoss: 0.3604 
2022-03-13 21:49:26 - train: epoch 0008, iter [05000, 05004], lr: 0.100000, loss: 5.1394, tea_CELoss: 2.2984 stu_CELoss: 2.4531 DMLLoss: 0.3878 
2022-03-13 21:49:27 - train: epoch 008, train_loss: 5.1585
2022-03-13 21:51:56 - eval: epoch: 008, tea_acc1: 52.700%, tea_acc5: 78.396%, tea_test_loss: 2.0182, stu_acc1: 49.316%, stu_acc5: 75.396%, stu_test_loss: 2.1945
2022-03-13 21:51:56 - until epoch: 008, tea_best_acc1: 53.998%, stu_best_acc1: 49.316%
2022-03-13 21:51:56 - epoch 009 lr: 0.1
2022-03-13 21:52:35 - train: epoch 0009, iter [00100, 05004], lr: 0.100000, loss: 4.4069, tea_CELoss: 1.9400 stu_CELoss: 2.1128 DMLLoss: 0.3541 
2022-03-13 21:53:09 - train: epoch 0009, iter [00200, 05004], lr: 0.100000, loss: 5.0898, tea_CELoss: 2.1867 stu_CELoss: 2.4963 DMLLoss: 0.4067 
2022-03-13 21:53:42 - train: epoch 0009, iter [00300, 05004], lr: 0.100000, loss: 5.0397, tea_CELoss: 2.1911 stu_CELoss: 2.4466 DMLLoss: 0.4021 
2022-03-13 21:54:16 - train: epoch 0009, iter [00400, 05004], lr: 0.100000, loss: 5.5480, tea_CELoss: 2.4427 stu_CELoss: 2.6557 DMLLoss: 0.4496 
2022-03-13 21:54:50 - train: epoch 0009, iter [00500, 05004], lr: 0.100000, loss: 4.7725, tea_CELoss: 2.1099 stu_CELoss: 2.2517 DMLLoss: 0.4108 
2022-03-13 21:55:22 - train: epoch 0009, iter [00600, 05004], lr: 0.100000, loss: 4.8118, tea_CELoss: 2.0812 stu_CELoss: 2.3614 DMLLoss: 0.3692 
2022-03-13 21:55:56 - train: epoch 0009, iter [00700, 05004], lr: 0.100000, loss: 4.6718, tea_CELoss: 1.9954 stu_CELoss: 2.2534 DMLLoss: 0.4229 
2022-03-13 21:56:30 - train: epoch 0009, iter [00800, 05004], lr: 0.100000, loss: 4.8860, tea_CELoss: 2.0628 stu_CELoss: 2.4060 DMLLoss: 0.4172 
2022-03-13 21:57:05 - train: epoch 0009, iter [00900, 05004], lr: 0.100000, loss: 4.8386, tea_CELoss: 2.1356 stu_CELoss: 2.3032 DMLLoss: 0.3998 
2022-03-13 21:57:38 - train: epoch 0009, iter [01000, 05004], lr: 0.100000, loss: 4.9858, tea_CELoss: 2.1985 stu_CELoss: 2.3988 DMLLoss: 0.3885 
2022-03-13 21:58:12 - train: epoch 0009, iter [01100, 05004], lr: 0.100000, loss: 5.4562, tea_CELoss: 2.3929 stu_CELoss: 2.6219 DMLLoss: 0.4414 
2022-03-13 21:58:46 - train: epoch 0009, iter [01200, 05004], lr: 0.100000, loss: 5.2345, tea_CELoss: 2.3237 stu_CELoss: 2.4891 DMLLoss: 0.4217 
2022-03-13 21:59:19 - train: epoch 0009, iter [01300, 05004], lr: 0.100000, loss: 5.5334, tea_CELoss: 2.4691 stu_CELoss: 2.6420 DMLLoss: 0.4224 
2022-03-13 21:59:52 - train: epoch 0009, iter [01400, 05004], lr: 0.100000, loss: 4.6490, tea_CELoss: 2.0502 stu_CELoss: 2.1854 DMLLoss: 0.4135 
2022-03-13 22:00:26 - train: epoch 0009, iter [01500, 05004], lr: 0.100000, loss: 4.8619, tea_CELoss: 2.1012 stu_CELoss: 2.3606 DMLLoss: 0.4001 
2022-03-13 22:00:59 - train: epoch 0009, iter [01600, 05004], lr: 0.100000, loss: 5.1244, tea_CELoss: 2.2595 stu_CELoss: 2.4380 DMLLoss: 0.4270 
2022-03-13 22:01:32 - train: epoch 0009, iter [01700, 05004], lr: 0.100000, loss: 5.4300, tea_CELoss: 2.4450 stu_CELoss: 2.5861 DMLLoss: 0.3990 
2022-03-13 22:02:05 - train: epoch 0009, iter [01800, 05004], lr: 0.100000, loss: 5.1108, tea_CELoss: 2.2915 stu_CELoss: 2.4459 DMLLoss: 0.3735 
2022-03-13 22:02:38 - train: epoch 0009, iter [01900, 05004], lr: 0.100000, loss: 4.5718, tea_CELoss: 2.0035 stu_CELoss: 2.1700 DMLLoss: 0.3983 
2022-03-13 22:03:11 - train: epoch 0009, iter [02000, 05004], lr: 0.100000, loss: 4.9771, tea_CELoss: 2.1206 stu_CELoss: 2.4333 DMLLoss: 0.4232 
2022-03-13 22:03:44 - train: epoch 0009, iter [02100, 05004], lr: 0.100000, loss: 5.4026, tea_CELoss: 2.4259 stu_CELoss: 2.5864 DMLLoss: 0.3903 
2022-03-13 22:04:17 - train: epoch 0009, iter [02200, 05004], lr: 0.100000, loss: 5.3132, tea_CELoss: 2.3148 stu_CELoss: 2.5809 DMLLoss: 0.4175 
2022-03-13 22:04:50 - train: epoch 0009, iter [02300, 05004], lr: 0.100000, loss: 4.7571, tea_CELoss: 2.0180 stu_CELoss: 2.3380 DMLLoss: 0.4010 
2022-03-13 22:05:23 - train: epoch 0009, iter [02400, 05004], lr: 0.100000, loss: 5.1485, tea_CELoss: 2.2878 stu_CELoss: 2.4315 DMLLoss: 0.4292 
2022-03-13 22:05:55 - train: epoch 0009, iter [02500, 05004], lr: 0.100000, loss: 4.9597, tea_CELoss: 2.1569 stu_CELoss: 2.3840 DMLLoss: 0.4188 
2022-03-13 22:06:28 - train: epoch 0009, iter [02600, 05004], lr: 0.100000, loss: 4.9831, tea_CELoss: 2.1840 stu_CELoss: 2.3770 DMLLoss: 0.4221 
2022-03-13 22:07:00 - train: epoch 0009, iter [02700, 05004], lr: 0.100000, loss: 5.1009, tea_CELoss: 2.2279 stu_CELoss: 2.4841 DMLLoss: 0.3889 
2022-03-13 22:07:33 - train: epoch 0009, iter [02800, 05004], lr: 0.100000, loss: 5.1498, tea_CELoss: 2.2826 stu_CELoss: 2.4828 DMLLoss: 0.3844 
2022-03-13 22:08:05 - train: epoch 0009, iter [02900, 05004], lr: 0.100000, loss: 4.6144, tea_CELoss: 2.0585 stu_CELoss: 2.1755 DMLLoss: 0.3804 
2022-03-13 22:08:38 - train: epoch 0009, iter [03000, 05004], lr: 0.100000, loss: 4.6532, tea_CELoss: 2.0155 stu_CELoss: 2.2478 DMLLoss: 0.3900 
2022-03-13 22:09:11 - train: epoch 0009, iter [03100, 05004], lr: 0.100000, loss: 5.0680, tea_CELoss: 2.2662 stu_CELoss: 2.4207 DMLLoss: 0.3811 
2022-03-13 22:09:43 - train: epoch 0009, iter [03200, 05004], lr: 0.100000, loss: 5.0441, tea_CELoss: 2.2444 stu_CELoss: 2.4345 DMLLoss: 0.3652 
2022-03-13 22:10:16 - train: epoch 0009, iter [03300, 05004], lr: 0.100000, loss: 5.5592, tea_CELoss: 2.4295 stu_CELoss: 2.6983 DMLLoss: 0.4315 
2022-03-13 22:10:50 - train: epoch 0009, iter [03400, 05004], lr: 0.100000, loss: 4.9908, tea_CELoss: 2.2200 stu_CELoss: 2.3645 DMLLoss: 0.4063 
2022-03-13 22:11:22 - train: epoch 0009, iter [03500, 05004], lr: 0.100000, loss: 5.2845, tea_CELoss: 2.3357 stu_CELoss: 2.5684 DMLLoss: 0.3804 
2022-03-13 22:11:54 - train: epoch 0009, iter [03600, 05004], lr: 0.100000, loss: 4.8652, tea_CELoss: 2.0782 stu_CELoss: 2.3948 DMLLoss: 0.3922 
2022-03-13 22:12:27 - train: epoch 0009, iter [03700, 05004], lr: 0.100000, loss: 5.2519, tea_CELoss: 2.3245 stu_CELoss: 2.5385 DMLLoss: 0.3889 
2022-03-13 22:13:00 - train: epoch 0009, iter [03800, 05004], lr: 0.100000, loss: 5.4069, tea_CELoss: 2.4218 stu_CELoss: 2.5722 DMLLoss: 0.4129 
2022-03-13 22:13:32 - train: epoch 0009, iter [03900, 05004], lr: 0.100000, loss: 4.8933, tea_CELoss: 2.1202 stu_CELoss: 2.3907 DMLLoss: 0.3824 
2022-03-13 22:14:05 - train: epoch 0009, iter [04000, 05004], lr: 0.100000, loss: 5.7182, tea_CELoss: 2.4990 stu_CELoss: 2.7947 DMLLoss: 0.4245 
2022-03-13 22:14:38 - train: epoch 0009, iter [04100, 05004], lr: 0.100000, loss: 5.1910, tea_CELoss: 2.2933 stu_CELoss: 2.5058 DMLLoss: 0.3919 
2022-03-13 22:15:11 - train: epoch 0009, iter [04200, 05004], lr: 0.100000, loss: 4.9345, tea_CELoss: 2.1815 stu_CELoss: 2.3719 DMLLoss: 0.3811 
2022-03-13 22:15:44 - train: epoch 0009, iter [04300, 05004], lr: 0.100000, loss: 4.5772, tea_CELoss: 1.9660 stu_CELoss: 2.2128 DMLLoss: 0.3985 
2022-03-13 22:16:17 - train: epoch 0009, iter [04400, 05004], lr: 0.100000, loss: 5.1298, tea_CELoss: 2.3649 stu_CELoss: 2.3844 DMLLoss: 0.3806 
2022-03-13 22:16:50 - train: epoch 0009, iter [04500, 05004], lr: 0.100000, loss: 5.3568, tea_CELoss: 2.3156 stu_CELoss: 2.6236 DMLLoss: 0.4176 
2022-03-13 22:17:22 - train: epoch 0009, iter [04600, 05004], lr: 0.100000, loss: 5.5479, tea_CELoss: 2.4667 stu_CELoss: 2.6598 DMLLoss: 0.4214 
2022-03-13 22:17:55 - train: epoch 0009, iter [04700, 05004], lr: 0.100000, loss: 5.6296, tea_CELoss: 2.5156 stu_CELoss: 2.7086 DMLLoss: 0.4054 
2022-03-13 22:18:29 - train: epoch 0009, iter [04800, 05004], lr: 0.100000, loss: 5.1479, tea_CELoss: 2.2673 stu_CELoss: 2.4671 DMLLoss: 0.4136 
2022-03-13 22:19:02 - train: epoch 0009, iter [04900, 05004], lr: 0.100000, loss: 5.3240, tea_CELoss: 2.3505 stu_CELoss: 2.5791 DMLLoss: 0.3944 
2022-03-13 22:19:33 - train: epoch 0009, iter [05000, 05004], lr: 0.100000, loss: 4.8990, tea_CELoss: 2.1622 stu_CELoss: 2.3180 DMLLoss: 0.4188 
2022-03-13 22:19:34 - train: epoch 009, train_loss: 5.1248
2022-03-13 22:22:02 - eval: epoch: 009, tea_acc1: 52.844%, tea_acc5: 78.148%, tea_test_loss: 2.0125, stu_acc1: 49.436%, stu_acc5: 75.460%, stu_test_loss: 2.1831
2022-03-13 22:22:03 - until epoch: 009, tea_best_acc1: 53.998%, stu_best_acc1: 49.436%
2022-03-13 22:22:03 - epoch 010 lr: 0.1
2022-03-13 22:22:41 - train: epoch 0010, iter [00100, 05004], lr: 0.100000, loss: 4.7105, tea_CELoss: 2.0291 stu_CELoss: 2.2897 DMLLoss: 0.3917 
2022-03-13 22:23:15 - train: epoch 0010, iter [00200, 05004], lr: 0.100000, loss: 5.0599, tea_CELoss: 2.2707 stu_CELoss: 2.4012 DMLLoss: 0.3881 
2022-03-13 22:23:49 - train: epoch 0010, iter [00300, 05004], lr: 0.100000, loss: 5.1581, tea_CELoss: 2.2641 stu_CELoss: 2.4878 DMLLoss: 0.4062 
2022-03-13 22:24:22 - train: epoch 0010, iter [00400, 05004], lr: 0.100000, loss: 5.4283, tea_CELoss: 2.3368 stu_CELoss: 2.6621 DMLLoss: 0.4294 
2022-03-13 22:24:55 - train: epoch 0010, iter [00500, 05004], lr: 0.100000, loss: 4.9548, tea_CELoss: 2.2208 stu_CELoss: 2.3540 DMLLoss: 0.3800 
2022-03-13 22:25:29 - train: epoch 0010, iter [00600, 05004], lr: 0.100000, loss: 5.3782, tea_CELoss: 2.4192 stu_CELoss: 2.5538 DMLLoss: 0.4052 
2022-03-13 22:26:02 - train: epoch 0010, iter [00700, 05004], lr: 0.100000, loss: 5.3699, tea_CELoss: 2.3910 stu_CELoss: 2.5600 DMLLoss: 0.4189 
2022-03-13 22:26:36 - train: epoch 0010, iter [00800, 05004], lr: 0.100000, loss: 5.2514, tea_CELoss: 2.3340 stu_CELoss: 2.5065 DMLLoss: 0.4110 
2022-03-13 22:27:10 - train: epoch 0010, iter [00900, 05004], lr: 0.100000, loss: 4.7349, tea_CELoss: 2.0943 stu_CELoss: 2.2425 DMLLoss: 0.3981 
2022-03-13 22:27:43 - train: epoch 0010, iter [01000, 05004], lr: 0.100000, loss: 4.4921, tea_CELoss: 1.9746 stu_CELoss: 2.1477 DMLLoss: 0.3697 
2022-03-13 22:28:17 - train: epoch 0010, iter [01100, 05004], lr: 0.100000, loss: 4.8862, tea_CELoss: 2.1093 stu_CELoss: 2.3431 DMLLoss: 0.4338 
2022-03-13 22:28:51 - train: epoch 0010, iter [01200, 05004], lr: 0.100000, loss: 5.2709, tea_CELoss: 2.3158 stu_CELoss: 2.5409 DMLLoss: 0.4142 
2022-03-13 22:29:25 - train: epoch 0010, iter [01300, 05004], lr: 0.100000, loss: 4.7455, tea_CELoss: 2.1207 stu_CELoss: 2.2555 DMLLoss: 0.3694 
2022-03-13 22:29:58 - train: epoch 0010, iter [01400, 05004], lr: 0.100000, loss: 5.4859, tea_CELoss: 2.4523 stu_CELoss: 2.6493 DMLLoss: 0.3843 
2022-03-13 22:30:32 - train: epoch 0010, iter [01500, 05004], lr: 0.100000, loss: 4.6262, tea_CELoss: 2.0429 stu_CELoss: 2.1663 DMLLoss: 0.4170 
2022-03-13 22:31:05 - train: epoch 0010, iter [01600, 05004], lr: 0.100000, loss: 5.1736, tea_CELoss: 2.2610 stu_CELoss: 2.5078 DMLLoss: 0.4048 
2022-03-13 22:31:39 - train: epoch 0010, iter [01700, 05004], lr: 0.100000, loss: 5.4604, tea_CELoss: 2.4298 stu_CELoss: 2.6060 DMLLoss: 0.4246 
2022-03-13 22:32:13 - train: epoch 0010, iter [01800, 05004], lr: 0.100000, loss: 4.8634, tea_CELoss: 2.1468 stu_CELoss: 2.3103 DMLLoss: 0.4063 
2022-03-13 22:32:47 - train: epoch 0010, iter [01900, 05004], lr: 0.100000, loss: 5.0113, tea_CELoss: 2.1928 stu_CELoss: 2.4153 DMLLoss: 0.4032 
2022-03-13 22:33:21 - train: epoch 0010, iter [02000, 05004], lr: 0.100000, loss: 5.1305, tea_CELoss: 2.2533 stu_CELoss: 2.4482 DMLLoss: 0.4290 
2022-03-13 22:33:54 - train: epoch 0010, iter [02100, 05004], lr: 0.100000, loss: 4.7982, tea_CELoss: 2.1523 stu_CELoss: 2.2463 DMLLoss: 0.3996 
2022-03-13 22:34:28 - train: epoch 0010, iter [02200, 05004], lr: 0.100000, loss: 5.1941, tea_CELoss: 2.3513 stu_CELoss: 2.4773 DMLLoss: 0.3655 
2022-03-13 22:35:01 - train: epoch 0010, iter [02300, 05004], lr: 0.100000, loss: 5.3568, tea_CELoss: 2.3872 stu_CELoss: 2.5790 DMLLoss: 0.3906 
2022-03-13 22:35:35 - train: epoch 0010, iter [02400, 05004], lr: 0.100000, loss: 5.6829, tea_CELoss: 2.5965 stu_CELoss: 2.6730 DMLLoss: 0.4134 
2022-03-13 22:36:09 - train: epoch 0010, iter [02500, 05004], lr: 0.100000, loss: 5.2857, tea_CELoss: 2.3471 stu_CELoss: 2.5249 DMLLoss: 0.4138 
2022-03-13 22:36:42 - train: epoch 0010, iter [02600, 05004], lr: 0.100000, loss: 5.1668, tea_CELoss: 2.2555 stu_CELoss: 2.4677 DMLLoss: 0.4436 
2022-03-13 22:37:16 - train: epoch 0010, iter [02700, 05004], lr: 0.100000, loss: 4.7719, tea_CELoss: 2.1231 stu_CELoss: 2.2551 DMLLoss: 0.3938 
2022-03-13 22:37:50 - train: epoch 0010, iter [02800, 05004], lr: 0.100000, loss: 5.2474, tea_CELoss: 2.3502 stu_CELoss: 2.4748 DMLLoss: 0.4224 
2022-03-13 22:38:24 - train: epoch 0010, iter [02900, 05004], lr: 0.100000, loss: 5.4101, tea_CELoss: 2.4298 stu_CELoss: 2.5598 DMLLoss: 0.4204 
2022-03-13 22:38:57 - train: epoch 0010, iter [03000, 05004], lr: 0.100000, loss: 4.8404, tea_CELoss: 2.1208 stu_CELoss: 2.3250 DMLLoss: 0.3947 
2022-03-13 22:39:30 - train: epoch 0010, iter [03100, 05004], lr: 0.100000, loss: 5.5194, tea_CELoss: 2.4447 stu_CELoss: 2.6525 DMLLoss: 0.4222 
2022-03-13 22:40:04 - train: epoch 0010, iter [03200, 05004], lr: 0.100000, loss: 5.0531, tea_CELoss: 2.2608 stu_CELoss: 2.4208 DMLLoss: 0.3716 
2022-03-13 22:40:38 - train: epoch 0010, iter [03300, 05004], lr: 0.100000, loss: 5.5280, tea_CELoss: 2.4985 stu_CELoss: 2.6182 DMLLoss: 0.4112 
2022-03-13 22:41:12 - train: epoch 0010, iter [03400, 05004], lr: 0.100000, loss: 5.4895, tea_CELoss: 2.5094 stu_CELoss: 2.5546 DMLLoss: 0.4255 
2022-03-13 22:41:45 - train: epoch 0010, iter [03500, 05004], lr: 0.100000, loss: 5.3805, tea_CELoss: 2.4431 stu_CELoss: 2.5555 DMLLoss: 0.3818 
2022-03-13 22:42:19 - train: epoch 0010, iter [03600, 05004], lr: 0.100000, loss: 5.4911, tea_CELoss: 2.4468 stu_CELoss: 2.6232 DMLLoss: 0.4212 
2022-03-13 22:42:53 - train: epoch 0010, iter [03700, 05004], lr: 0.100000, loss: 5.5577, tea_CELoss: 2.4404 stu_CELoss: 2.7098 DMLLoss: 0.4074 
2022-03-13 22:43:26 - train: epoch 0010, iter [03800, 05004], lr: 0.100000, loss: 5.3501, tea_CELoss: 2.4148 stu_CELoss: 2.5176 DMLLoss: 0.4178 
2022-03-13 22:43:59 - train: epoch 0010, iter [03900, 05004], lr: 0.100000, loss: 4.7667, tea_CELoss: 2.1031 stu_CELoss: 2.2843 DMLLoss: 0.3793 
2022-03-13 22:44:33 - train: epoch 0010, iter [04000, 05004], lr: 0.100000, loss: 4.9092, tea_CELoss: 2.1478 stu_CELoss: 2.3916 DMLLoss: 0.3699 
2022-03-13 22:45:06 - train: epoch 0010, iter [04100, 05004], lr: 0.100000, loss: 4.6772, tea_CELoss: 2.0194 stu_CELoss: 2.2687 DMLLoss: 0.3890 
2022-03-13 22:45:40 - train: epoch 0010, iter [04200, 05004], lr: 0.100000, loss: 5.0729, tea_CELoss: 2.2444 stu_CELoss: 2.4280 DMLLoss: 0.4005 
2022-03-13 22:46:13 - train: epoch 0010, iter [04300, 05004], lr: 0.100000, loss: 4.8915, tea_CELoss: 2.1423 stu_CELoss: 2.3573 DMLLoss: 0.3920 
2022-03-13 22:46:47 - train: epoch 0010, iter [04400, 05004], lr: 0.100000, loss: 4.9123, tea_CELoss: 2.1679 stu_CELoss: 2.3675 DMLLoss: 0.3769 
2022-03-13 22:47:21 - train: epoch 0010, iter [04500, 05004], lr: 0.100000, loss: 5.2828, tea_CELoss: 2.3077 stu_CELoss: 2.5427 DMLLoss: 0.4323 
2022-03-13 22:47:54 - train: epoch 0010, iter [04600, 05004], lr: 0.100000, loss: 4.9148, tea_CELoss: 2.2083 stu_CELoss: 2.3092 DMLLoss: 0.3974 
2022-03-13 22:48:28 - train: epoch 0010, iter [04700, 05004], lr: 0.100000, loss: 4.9930, tea_CELoss: 2.2211 stu_CELoss: 2.3841 DMLLoss: 0.3878 
2022-03-13 22:49:01 - train: epoch 0010, iter [04800, 05004], lr: 0.100000, loss: 5.0308, tea_CELoss: 2.2280 stu_CELoss: 2.3956 DMLLoss: 0.4072 
2022-03-13 22:49:34 - train: epoch 0010, iter [04900, 05004], lr: 0.100000, loss: 5.1468, tea_CELoss: 2.2943 stu_CELoss: 2.4454 DMLLoss: 0.4071 
2022-03-13 22:50:07 - train: epoch 0010, iter [05000, 05004], lr: 0.100000, loss: 4.7703, tea_CELoss: 2.0968 stu_CELoss: 2.2717 DMLLoss: 0.4019 
2022-03-13 22:50:08 - train: epoch 010, train_loss: 5.1020
2022-03-13 22:52:37 - eval: epoch: 010, tea_acc1: 51.848%, tea_acc5: 77.544%, tea_test_loss: 2.0566, stu_acc1: 49.330%, stu_acc5: 75.308%, stu_test_loss: 2.1918
2022-03-13 22:52:38 - until epoch: 010, tea_best_acc1: 53.998%, stu_best_acc1: 49.436%
2022-03-13 22:52:38 - epoch 011 lr: 0.1
2022-03-13 22:53:16 - train: epoch 0011, iter [00100, 05004], lr: 0.100000, loss: 4.9914, tea_CELoss: 2.2008 stu_CELoss: 2.3721 DMLLoss: 0.4185 
2022-03-13 22:53:50 - train: epoch 0011, iter [00200, 05004], lr: 0.100000, loss: 5.4365, tea_CELoss: 2.4684 stu_CELoss: 2.5593 DMLLoss: 0.4087 
2022-03-13 22:54:24 - train: epoch 0011, iter [00300, 05004], lr: 0.100000, loss: 5.3810, tea_CELoss: 2.4611 stu_CELoss: 2.5351 DMLLoss: 0.3848 
2022-03-13 22:54:58 - train: epoch 0011, iter [00400, 05004], lr: 0.100000, loss: 5.5770, tea_CELoss: 2.4661 stu_CELoss: 2.6666 DMLLoss: 0.4443 
2022-03-13 22:55:31 - train: epoch 0011, iter [00500, 05004], lr: 0.100000, loss: 4.7721, tea_CELoss: 2.0886 stu_CELoss: 2.2750 DMLLoss: 0.4085 
2022-03-13 22:56:04 - train: epoch 0011, iter [00600, 05004], lr: 0.100000, loss: 5.6463, tea_CELoss: 2.5295 stu_CELoss: 2.6594 DMLLoss: 0.4573 
2022-03-13 22:56:38 - train: epoch 0011, iter [00700, 05004], lr: 0.100000, loss: 5.2298, tea_CELoss: 2.3971 stu_CELoss: 2.4069 DMLLoss: 0.4257 
2022-03-13 22:57:10 - train: epoch 0011, iter [00800, 05004], lr: 0.100000, loss: 5.4095, tea_CELoss: 2.3786 stu_CELoss: 2.5757 DMLLoss: 0.4552 
2022-03-13 22:57:45 - train: epoch 0011, iter [00900, 05004], lr: 0.100000, loss: 5.2492, tea_CELoss: 2.4130 stu_CELoss: 2.4646 DMLLoss: 0.3716 
2022-03-13 22:58:18 - train: epoch 0011, iter [01000, 05004], lr: 0.100000, loss: 4.8815, tea_CELoss: 2.1504 stu_CELoss: 2.3062 DMLLoss: 0.4250 
2022-03-13 22:58:52 - train: epoch 0011, iter [01100, 05004], lr: 0.100000, loss: 4.9732, tea_CELoss: 2.1846 stu_CELoss: 2.3950 DMLLoss: 0.3935 
2022-03-13 22:59:26 - train: epoch 0011, iter [01200, 05004], lr: 0.100000, loss: 5.3956, tea_CELoss: 2.3932 stu_CELoss: 2.6082 DMLLoss: 0.3941 
2022-03-13 22:59:59 - train: epoch 0011, iter [01300, 05004], lr: 0.100000, loss: 5.0534, tea_CELoss: 2.2724 stu_CELoss: 2.3935 DMLLoss: 0.3874 
2022-03-13 23:00:33 - train: epoch 0011, iter [01400, 05004], lr: 0.100000, loss: 5.2811, tea_CELoss: 2.3951 stu_CELoss: 2.5293 DMLLoss: 0.3567 
2022-03-13 23:01:07 - train: epoch 0011, iter [01500, 05004], lr: 0.100000, loss: 5.1213, tea_CELoss: 2.2484 stu_CELoss: 2.4787 DMLLoss: 0.3942 
2022-03-13 23:01:41 - train: epoch 0011, iter [01600, 05004], lr: 0.100000, loss: 5.3521, tea_CELoss: 2.4258 stu_CELoss: 2.5375 DMLLoss: 0.3888 
2022-03-13 23:02:14 - train: epoch 0011, iter [01700, 05004], lr: 0.100000, loss: 5.4464, tea_CELoss: 2.4082 stu_CELoss: 2.5617 DMLLoss: 0.4764 
2022-03-13 23:02:48 - train: epoch 0011, iter [01800, 05004], lr: 0.100000, loss: 5.1264, tea_CELoss: 2.3446 stu_CELoss: 2.4397 DMLLoss: 0.3421 
2022-03-13 23:03:22 - train: epoch 0011, iter [01900, 05004], lr: 0.100000, loss: 4.9298, tea_CELoss: 2.1974 stu_CELoss: 2.3359 DMLLoss: 0.3964 
2022-03-13 23:03:56 - train: epoch 0011, iter [02000, 05004], lr: 0.100000, loss: 4.8609, tea_CELoss: 2.1140 stu_CELoss: 2.3704 DMLLoss: 0.3765 
2022-03-13 23:04:29 - train: epoch 0011, iter [02100, 05004], lr: 0.100000, loss: 4.8161, tea_CELoss: 2.1111 stu_CELoss: 2.3072 DMLLoss: 0.3978 
2022-03-13 23:05:03 - train: epoch 0011, iter [02200, 05004], lr: 0.100000, loss: 4.8406, tea_CELoss: 2.0997 stu_CELoss: 2.3313 DMLLoss: 0.4095 
2022-03-13 23:05:37 - train: epoch 0011, iter [02300, 05004], lr: 0.100000, loss: 5.2598, tea_CELoss: 2.3033 stu_CELoss: 2.5453 DMLLoss: 0.4112 
2022-03-13 23:06:10 - train: epoch 0011, iter [02400, 05004], lr: 0.100000, loss: 4.6646, tea_CELoss: 2.0959 stu_CELoss: 2.2210 DMLLoss: 0.3478 
2022-03-13 23:06:44 - train: epoch 0011, iter [02500, 05004], lr: 0.100000, loss: 5.1686, tea_CELoss: 2.3031 stu_CELoss: 2.4494 DMLLoss: 0.4161 
2022-03-13 23:07:18 - train: epoch 0011, iter [02600, 05004], lr: 0.100000, loss: 4.9468, tea_CELoss: 2.1791 stu_CELoss: 2.3687 DMLLoss: 0.3989 
2022-03-13 23:07:52 - train: epoch 0011, iter [02700, 05004], lr: 0.100000, loss: 4.7556, tea_CELoss: 2.0849 stu_CELoss: 2.2858 DMLLoss: 0.3850 
2022-03-13 23:08:26 - train: epoch 0011, iter [02800, 05004], lr: 0.100000, loss: 4.4725, tea_CELoss: 1.9951 stu_CELoss: 2.1292 DMLLoss: 0.3483 
2022-03-13 23:09:00 - train: epoch 0011, iter [02900, 05004], lr: 0.100000, loss: 5.0791, tea_CELoss: 2.2672 stu_CELoss: 2.4503 DMLLoss: 0.3616 
2022-03-13 23:09:33 - train: epoch 0011, iter [03000, 05004], lr: 0.100000, loss: 5.6734, tea_CELoss: 2.5167 stu_CELoss: 2.7608 DMLLoss: 0.3959 
2022-03-13 23:10:07 - train: epoch 0011, iter [03100, 05004], lr: 0.100000, loss: 4.9061, tea_CELoss: 2.2046 stu_CELoss: 2.3168 DMLLoss: 0.3847 
2022-03-13 23:10:41 - train: epoch 0011, iter [03200, 05004], lr: 0.100000, loss: 5.1867, tea_CELoss: 2.2692 stu_CELoss: 2.5188 DMLLoss: 0.3987 
2022-03-13 23:11:15 - train: epoch 0011, iter [03300, 05004], lr: 0.100000, loss: 5.1315, tea_CELoss: 2.2936 stu_CELoss: 2.4364 DMLLoss: 0.4016 
2022-03-13 23:11:48 - train: epoch 0011, iter [03400, 05004], lr: 0.100000, loss: 4.8758, tea_CELoss: 2.1801 stu_CELoss: 2.3445 DMLLoss: 0.3512 
2022-03-13 23:12:22 - train: epoch 0011, iter [03500, 05004], lr: 0.100000, loss: 4.9444, tea_CELoss: 2.1760 stu_CELoss: 2.3691 DMLLoss: 0.3993 
2022-03-13 23:12:56 - train: epoch 0011, iter [03600, 05004], lr: 0.100000, loss: 4.7316, tea_CELoss: 2.0899 stu_CELoss: 2.2534 DMLLoss: 0.3884 
2022-03-13 23:13:29 - train: epoch 0011, iter [03700, 05004], lr: 0.100000, loss: 5.5081, tea_CELoss: 2.4356 stu_CELoss: 2.6413 DMLLoss: 0.4312 
2022-03-13 23:14:03 - train: epoch 0011, iter [03800, 05004], lr: 0.100000, loss: 4.9555, tea_CELoss: 2.2161 stu_CELoss: 2.3729 DMLLoss: 0.3665 
2022-03-13 23:14:37 - train: epoch 0011, iter [03900, 05004], lr: 0.100000, loss: 5.0611, tea_CELoss: 2.2679 stu_CELoss: 2.3636 DMLLoss: 0.4296 
2022-03-13 23:15:11 - train: epoch 0011, iter [04000, 05004], lr: 0.100000, loss: 4.6617, tea_CELoss: 1.9946 stu_CELoss: 2.2468 DMLLoss: 0.4204 
2022-03-13 23:15:45 - train: epoch 0011, iter [04100, 05004], lr: 0.100000, loss: 4.9222, tea_CELoss: 2.1216 stu_CELoss: 2.3328 DMLLoss: 0.4678 
2022-03-13 23:16:18 - train: epoch 0011, iter [04200, 05004], lr: 0.100000, loss: 4.8286, tea_CELoss: 2.1312 stu_CELoss: 2.3278 DMLLoss: 0.3696 
2022-03-13 23:16:52 - train: epoch 0011, iter [04300, 05004], lr: 0.100000, loss: 4.9918, tea_CELoss: 2.2162 stu_CELoss: 2.3548 DMLLoss: 0.4208 
2022-03-13 23:17:26 - train: epoch 0011, iter [04400, 05004], lr: 0.100000, loss: 5.6099, tea_CELoss: 2.5222 stu_CELoss: 2.6966 DMLLoss: 0.3910 
2022-03-13 23:18:00 - train: epoch 0011, iter [04500, 05004], lr: 0.100000, loss: 4.7764, tea_CELoss: 2.1411 stu_CELoss: 2.2640 DMLLoss: 0.3713 
2022-03-13 23:18:33 - train: epoch 0011, iter [04600, 05004], lr: 0.100000, loss: 5.0977, tea_CELoss: 2.2951 stu_CELoss: 2.4071 DMLLoss: 0.3955 
2022-03-13 23:19:07 - train: epoch 0011, iter [04700, 05004], lr: 0.100000, loss: 4.8786, tea_CELoss: 2.1834 stu_CELoss: 2.3272 DMLLoss: 0.3681 
2022-03-13 23:19:41 - train: epoch 0011, iter [04800, 05004], lr: 0.100000, loss: 4.5359, tea_CELoss: 1.9752 stu_CELoss: 2.1873 DMLLoss: 0.3735 
2022-03-13 23:20:15 - train: epoch 0011, iter [04900, 05004], lr: 0.100000, loss: 4.6497, tea_CELoss: 2.0219 stu_CELoss: 2.2437 DMLLoss: 0.3840 
2022-03-13 23:20:47 - train: epoch 0011, iter [05000, 05004], lr: 0.100000, loss: 4.9562, tea_CELoss: 2.2758 stu_CELoss: 2.3221 DMLLoss: 0.3583 
2022-03-13 23:20:48 - train: epoch 011, train_loss: 5.0797
2022-03-13 23:23:17 - eval: epoch: 011, tea_acc1: 51.820%, tea_acc5: 77.470%, tea_test_loss: 2.0612, stu_acc1: 48.856%, stu_acc5: 75.254%, stu_test_loss: 2.2121
2022-03-13 23:23:18 - until epoch: 011, tea_best_acc1: 53.998%, stu_best_acc1: 49.436%
2022-03-13 23:23:18 - epoch 012 lr: 0.1
2022-03-13 23:23:55 - train: epoch 0012, iter [00100, 05004], lr: 0.100000, loss: 4.7219, tea_CELoss: 2.1171 stu_CELoss: 2.2618 DMLLoss: 0.3430 
2022-03-13 23:24:30 - train: epoch 0012, iter [00200, 05004], lr: 0.100000, loss: 4.4786, tea_CELoss: 1.9518 stu_CELoss: 2.1426 DMLLoss: 0.3841 
2022-03-13 23:25:04 - train: epoch 0012, iter [00300, 05004], lr: 0.100000, loss: 4.7175, tea_CELoss: 2.0855 stu_CELoss: 2.2588 DMLLoss: 0.3732 
2022-03-13 23:25:37 - train: epoch 0012, iter [00400, 05004], lr: 0.100000, loss: 5.0559, tea_CELoss: 2.2477 stu_CELoss: 2.3988 DMLLoss: 0.4094 
2022-03-13 23:26:11 - train: epoch 0012, iter [00500, 05004], lr: 0.100000, loss: 5.6127, tea_CELoss: 2.4674 stu_CELoss: 2.6654 DMLLoss: 0.4799 
2022-03-13 23:26:45 - train: epoch 0012, iter [00600, 05004], lr: 0.100000, loss: 4.5884, tea_CELoss: 2.0494 stu_CELoss: 2.1354 DMLLoss: 0.4036 
2022-03-13 23:27:19 - train: epoch 0012, iter [00700, 05004], lr: 0.100000, loss: 4.5845, tea_CELoss: 2.0102 stu_CELoss: 2.1878 DMLLoss: 0.3865 
2022-03-13 23:27:51 - train: epoch 0012, iter [00800, 05004], lr: 0.100000, loss: 5.6321, tea_CELoss: 2.5333 stu_CELoss: 2.6550 DMLLoss: 0.4438 
2022-03-13 23:28:25 - train: epoch 0012, iter [00900, 05004], lr: 0.100000, loss: 5.1202, tea_CELoss: 2.2908 stu_CELoss: 2.4077 DMLLoss: 0.4217 
2022-03-13 23:28:59 - train: epoch 0012, iter [01000, 05004], lr: 0.100000, loss: 4.8329, tea_CELoss: 2.1273 stu_CELoss: 2.2922 DMLLoss: 0.4134 
2022-03-13 23:29:32 - train: epoch 0012, iter [01100, 05004], lr: 0.100000, loss: 5.3969, tea_CELoss: 2.3800 stu_CELoss: 2.6328 DMLLoss: 0.3841 
2022-03-13 23:30:06 - train: epoch 0012, iter [01200, 05004], lr: 0.100000, loss: 4.4814, tea_CELoss: 1.9490 stu_CELoss: 2.1429 DMLLoss: 0.3894 
2022-03-13 23:30:39 - train: epoch 0012, iter [01300, 05004], lr: 0.100000, loss: 4.6075, tea_CELoss: 2.0295 stu_CELoss: 2.1887 DMLLoss: 0.3893 
2022-03-13 23:31:13 - train: epoch 0012, iter [01400, 05004], lr: 0.100000, loss: 5.5846, tea_CELoss: 2.5384 stu_CELoss: 2.6181 DMLLoss: 0.4281 
2022-03-13 23:31:47 - train: epoch 0012, iter [01500, 05004], lr: 0.100000, loss: 4.6846, tea_CELoss: 2.1520 stu_CELoss: 2.1783 DMLLoss: 0.3543 
2022-03-13 23:32:20 - train: epoch 0012, iter [01600, 05004], lr: 0.100000, loss: 4.9333, tea_CELoss: 2.1708 stu_CELoss: 2.3791 DMLLoss: 0.3835 
2022-03-13 23:32:54 - train: epoch 0012, iter [01700, 05004], lr: 0.100000, loss: 4.8190, tea_CELoss: 2.1205 stu_CELoss: 2.3159 DMLLoss: 0.3826 
2022-03-13 23:33:28 - train: epoch 0012, iter [01800, 05004], lr: 0.100000, loss: 5.2947, tea_CELoss: 2.3694 stu_CELoss: 2.5393 DMLLoss: 0.3860 
2022-03-13 23:34:01 - train: epoch 0012, iter [01900, 05004], lr: 0.100000, loss: 5.4598, tea_CELoss: 2.4025 stu_CELoss: 2.6347 DMLLoss: 0.4225 
2022-03-13 23:34:35 - train: epoch 0012, iter [02000, 05004], lr: 0.100000, loss: 5.0751, tea_CELoss: 2.3134 stu_CELoss: 2.3840 DMLLoss: 0.3776 
2022-03-13 23:35:09 - train: epoch 0012, iter [02100, 05004], lr: 0.100000, loss: 5.5062, tea_CELoss: 2.4492 stu_CELoss: 2.6324 DMLLoss: 0.4246 
2022-03-13 23:35:42 - train: epoch 0012, iter [02200, 05004], lr: 0.100000, loss: 5.5078, tea_CELoss: 2.4292 stu_CELoss: 2.6523 DMLLoss: 0.4264 
2022-03-13 23:36:16 - train: epoch 0012, iter [02300, 05004], lr: 0.100000, loss: 4.9682, tea_CELoss: 2.2377 stu_CELoss: 2.2948 DMLLoss: 0.4356 
2022-03-13 23:36:50 - train: epoch 0012, iter [02400, 05004], lr: 0.100000, loss: 5.2185, tea_CELoss: 2.2791 stu_CELoss: 2.5080 DMLLoss: 0.4314 
2022-03-13 23:37:23 - train: epoch 0012, iter [02500, 05004], lr: 0.100000, loss: 4.8993, tea_CELoss: 2.1127 stu_CELoss: 2.3320 DMLLoss: 0.4546 
2022-03-13 23:37:57 - train: epoch 0012, iter [02600, 05004], lr: 0.100000, loss: 4.7164, tea_CELoss: 2.0932 stu_CELoss: 2.2516 DMLLoss: 0.3715 
2022-03-13 23:38:30 - train: epoch 0012, iter [02700, 05004], lr: 0.100000, loss: 4.8530, tea_CELoss: 2.1533 stu_CELoss: 2.3042 DMLLoss: 0.3955 
2022-03-13 23:39:04 - train: epoch 0012, iter [02800, 05004], lr: 0.100000, loss: 5.4025, tea_CELoss: 2.3726 stu_CELoss: 2.5998 DMLLoss: 0.4301 
2022-03-13 23:39:38 - train: epoch 0012, iter [02900, 05004], lr: 0.100000, loss: 5.0862, tea_CELoss: 2.2571 stu_CELoss: 2.4706 DMLLoss: 0.3585 
2022-03-13 23:40:11 - train: epoch 0012, iter [03000, 05004], lr: 0.100000, loss: 4.6632, tea_CELoss: 2.0808 stu_CELoss: 2.1996 DMLLoss: 0.3828 
2022-03-13 23:40:45 - train: epoch 0012, iter [03100, 05004], lr: 0.100000, loss: 5.1647, tea_CELoss: 2.2907 stu_CELoss: 2.4907 DMLLoss: 0.3833 
2022-03-13 23:41:18 - train: epoch 0012, iter [03200, 05004], lr: 0.100000, loss: 4.8499, tea_CELoss: 2.1635 stu_CELoss: 2.2960 DMLLoss: 0.3904 
2022-03-13 23:41:52 - train: epoch 0012, iter [03300, 05004], lr: 0.100000, loss: 5.0057, tea_CELoss: 2.2494 stu_CELoss: 2.3707 DMLLoss: 0.3855 
2022-03-13 23:42:26 - train: epoch 0012, iter [03400, 05004], lr: 0.100000, loss: 4.9812, tea_CELoss: 2.2187 stu_CELoss: 2.3751 DMLLoss: 0.3874 
2022-03-13 23:42:59 - train: epoch 0012, iter [03500, 05004], lr: 0.100000, loss: 5.1844, tea_CELoss: 2.2769 stu_CELoss: 2.4842 DMLLoss: 0.4234 
2022-03-13 23:43:34 - train: epoch 0012, iter [03600, 05004], lr: 0.100000, loss: 4.9209, tea_CELoss: 2.1786 stu_CELoss: 2.3447 DMLLoss: 0.3976 
2022-03-13 23:44:07 - train: epoch 0012, iter [03700, 05004], lr: 0.100000, loss: 5.4244, tea_CELoss: 2.4062 stu_CELoss: 2.5849 DMLLoss: 0.4332 
2022-03-13 23:44:41 - train: epoch 0012, iter [03800, 05004], lr: 0.100000, loss: 5.2057, tea_CELoss: 2.3187 stu_CELoss: 2.5376 DMLLoss: 0.3495 
2022-03-13 23:45:15 - train: epoch 0012, iter [03900, 05004], lr: 0.100000, loss: 4.5696, tea_CELoss: 1.9531 stu_CELoss: 2.2303 DMLLoss: 0.3862 
2022-03-13 23:45:48 - train: epoch 0012, iter [04000, 05004], lr: 0.100000, loss: 5.0729, tea_CELoss: 2.2787 stu_CELoss: 2.4418 DMLLoss: 0.3524 
2022-03-13 23:46:22 - train: epoch 0012, iter [04100, 05004], lr: 0.100000, loss: 5.1557, tea_CELoss: 2.2970 stu_CELoss: 2.4622 DMLLoss: 0.3965 
2022-03-13 23:46:56 - train: epoch 0012, iter [04200, 05004], lr: 0.100000, loss: 4.9161, tea_CELoss: 2.1684 stu_CELoss: 2.3726 DMLLoss: 0.3750 
2022-03-13 23:47:29 - train: epoch 0012, iter [04300, 05004], lr: 0.100000, loss: 5.4630, tea_CELoss: 2.4649 stu_CELoss: 2.5928 DMLLoss: 0.4053 
2022-03-13 23:48:03 - train: epoch 0012, iter [04400, 05004], lr: 0.100000, loss: 4.8964, tea_CELoss: 2.1419 stu_CELoss: 2.3779 DMLLoss: 0.3766 
2022-03-13 23:48:37 - train: epoch 0012, iter [04500, 05004], lr: 0.100000, loss: 5.0135, tea_CELoss: 2.2080 stu_CELoss: 2.4128 DMLLoss: 0.3927 
2022-03-13 23:49:10 - train: epoch 0012, iter [04600, 05004], lr: 0.100000, loss: 5.2516, tea_CELoss: 2.3323 stu_CELoss: 2.4936 DMLLoss: 0.4258 
2022-03-13 23:49:44 - train: epoch 0012, iter [04700, 05004], lr: 0.100000, loss: 4.5771, tea_CELoss: 2.0557 stu_CELoss: 2.1543 DMLLoss: 0.3671 
2022-03-13 23:50:18 - train: epoch 0012, iter [04800, 05004], lr: 0.100000, loss: 5.2959, tea_CELoss: 2.4120 stu_CELoss: 2.4557 DMLLoss: 0.4282 
2022-03-13 23:50:52 - train: epoch 0012, iter [04900, 05004], lr: 0.100000, loss: 4.6419, tea_CELoss: 2.0629 stu_CELoss: 2.2304 DMLLoss: 0.3486 
2022-03-13 23:51:25 - train: epoch 0012, iter [05000, 05004], lr: 0.100000, loss: 4.8327, tea_CELoss: 2.1656 stu_CELoss: 2.3057 DMLLoss: 0.3614 
2022-03-13 23:51:26 - train: epoch 012, train_loss: 5.0557
2022-03-13 23:53:56 - eval: epoch: 012, tea_acc1: 54.362%, tea_acc5: 79.312%, tea_test_loss: 1.9537, stu_acc1: 51.080%, stu_acc5: 76.594%, stu_test_loss: 2.1130
2022-03-13 23:53:57 - until epoch: 012, tea_best_acc1: 54.362%, stu_best_acc1: 51.080%
2022-03-13 23:53:57 - epoch 013 lr: 0.1
2022-03-13 23:54:34 - train: epoch 0013, iter [00100, 05004], lr: 0.100000, loss: 4.5957, tea_CELoss: 2.0554 stu_CELoss: 2.1261 DMLLoss: 0.4143 
2022-03-13 23:55:07 - train: epoch 0013, iter [00200, 05004], lr: 0.100000, loss: 4.8835, tea_CELoss: 2.1624 stu_CELoss: 2.3197 DMLLoss: 0.4014 
2022-03-13 23:55:40 - train: epoch 0013, iter [00300, 05004], lr: 0.100000, loss: 5.1613, tea_CELoss: 2.2778 stu_CELoss: 2.4460 DMLLoss: 0.4375 
2022-03-13 23:56:13 - train: epoch 0013, iter [00400, 05004], lr: 0.100000, loss: 4.8092, tea_CELoss: 2.2053 stu_CELoss: 2.2521 DMLLoss: 0.3518 
2022-03-13 23:56:46 - train: epoch 0013, iter [00500, 05004], lr: 0.100000, loss: 4.9336, tea_CELoss: 2.1603 stu_CELoss: 2.3822 DMLLoss: 0.3910 
2022-03-13 23:57:19 - train: epoch 0013, iter [00600, 05004], lr: 0.100000, loss: 5.0646, tea_CELoss: 2.2623 stu_CELoss: 2.4019 DMLLoss: 0.4003 
2022-03-13 23:57:52 - train: epoch 0013, iter [00700, 05004], lr: 0.100000, loss: 4.8154, tea_CELoss: 2.1305 stu_CELoss: 2.3033 DMLLoss: 0.3816 
2022-03-13 23:58:24 - train: epoch 0013, iter [00800, 05004], lr: 0.100000, loss: 5.5535, tea_CELoss: 2.4571 stu_CELoss: 2.6809 DMLLoss: 0.4154 
2022-03-13 23:58:58 - train: epoch 0013, iter [00900, 05004], lr: 0.100000, loss: 5.2404, tea_CELoss: 2.3634 stu_CELoss: 2.4537 DMLLoss: 0.4233 
2022-03-13 23:59:31 - train: epoch 0013, iter [01000, 05004], lr: 0.100000, loss: 4.7228, tea_CELoss: 2.1315 stu_CELoss: 2.2453 DMLLoss: 0.3460 
2022-03-14 00:00:04 - train: epoch 0013, iter [01100, 05004], lr: 0.100000, loss: 5.0358, tea_CELoss: 2.2834 stu_CELoss: 2.3547 DMLLoss: 0.3977 
2022-03-14 00:00:37 - train: epoch 0013, iter [01200, 05004], lr: 0.100000, loss: 5.4165, tea_CELoss: 2.4155 stu_CELoss: 2.5885 DMLLoss: 0.4125 
2022-03-14 00:01:10 - train: epoch 0013, iter [01300, 05004], lr: 0.100000, loss: 4.9399, tea_CELoss: 2.1478 stu_CELoss: 2.3716 DMLLoss: 0.4204 
2022-03-14 00:01:43 - train: epoch 0013, iter [01400, 05004], lr: 0.100000, loss: 4.9692, tea_CELoss: 2.2055 stu_CELoss: 2.3539 DMLLoss: 0.4098 
2022-03-14 00:02:17 - train: epoch 0013, iter [01500, 05004], lr: 0.100000, loss: 5.1805, tea_CELoss: 2.2667 stu_CELoss: 2.5034 DMLLoss: 0.4105 
2022-03-14 00:02:50 - train: epoch 0013, iter [01600, 05004], lr: 0.100000, loss: 4.9767, tea_CELoss: 2.2095 stu_CELoss: 2.3827 DMLLoss: 0.3845 
2022-03-14 00:03:23 - train: epoch 0013, iter [01700, 05004], lr: 0.100000, loss: 4.9717, tea_CELoss: 2.1965 stu_CELoss: 2.3890 DMLLoss: 0.3862 
2022-03-14 00:03:56 - train: epoch 0013, iter [01800, 05004], lr: 0.100000, loss: 4.9292, tea_CELoss: 2.2097 stu_CELoss: 2.3611 DMLLoss: 0.3584 
2022-03-14 00:04:29 - train: epoch 0013, iter [01900, 05004], lr: 0.100000, loss: 4.9975, tea_CELoss: 2.2678 stu_CELoss: 2.3477 DMLLoss: 0.3820 
2022-03-14 00:05:02 - train: epoch 0013, iter [02000, 05004], lr: 0.100000, loss: 4.9377, tea_CELoss: 2.1813 stu_CELoss: 2.3612 DMLLoss: 0.3952 
2022-03-14 00:05:35 - train: epoch 0013, iter [02100, 05004], lr: 0.100000, loss: 5.2469, tea_CELoss: 2.3379 stu_CELoss: 2.5010 DMLLoss: 0.4079 
2022-03-14 00:06:09 - train: epoch 0013, iter [02200, 05004], lr: 0.100000, loss: 4.7675, tea_CELoss: 2.0909 stu_CELoss: 2.3305 DMLLoss: 0.3460 
2022-03-14 00:06:42 - train: epoch 0013, iter [02300, 05004], lr: 0.100000, loss: 5.1489, tea_CELoss: 2.2946 stu_CELoss: 2.4202 DMLLoss: 0.4340 
2022-03-14 00:07:15 - train: epoch 0013, iter [02400, 05004], lr: 0.100000, loss: 5.1719, tea_CELoss: 2.2845 stu_CELoss: 2.5034 DMLLoss: 0.3840 
2022-03-14 00:07:48 - train: epoch 0013, iter [02500, 05004], lr: 0.100000, loss: 4.9386, tea_CELoss: 2.1742 stu_CELoss: 2.3646 DMLLoss: 0.3999 
2022-03-14 00:08:21 - train: epoch 0013, iter [02600, 05004], lr: 0.100000, loss: 4.8173, tea_CELoss: 2.1403 stu_CELoss: 2.2810 DMLLoss: 0.3961 
2022-03-14 00:08:54 - train: epoch 0013, iter [02700, 05004], lr: 0.100000, loss: 5.1315, tea_CELoss: 2.2197 stu_CELoss: 2.4716 DMLLoss: 0.4402 
2022-03-14 00:09:28 - train: epoch 0013, iter [02800, 05004], lr: 0.100000, loss: 5.1546, tea_CELoss: 2.3156 stu_CELoss: 2.4293 DMLLoss: 0.4097 
2022-03-14 00:10:01 - train: epoch 0013, iter [02900, 05004], lr: 0.100000, loss: 5.1806, tea_CELoss: 2.3415 stu_CELoss: 2.4557 DMLLoss: 0.3835 
2022-03-14 00:10:33 - train: epoch 0013, iter [03000, 05004], lr: 0.100000, loss: 4.7447, tea_CELoss: 2.0804 stu_CELoss: 2.2773 DMLLoss: 0.3870 
2022-03-14 00:11:06 - train: epoch 0013, iter [03100, 05004], lr: 0.100000, loss: 4.8419, tea_CELoss: 2.1791 stu_CELoss: 2.2675 DMLLoss: 0.3954 
2022-03-14 00:11:39 - train: epoch 0013, iter [03200, 05004], lr: 0.100000, loss: 5.2465, tea_CELoss: 2.2945 stu_CELoss: 2.5380 DMLLoss: 0.4139 
2022-03-14 00:12:13 - train: epoch 0013, iter [03300, 05004], lr: 0.100000, loss: 4.7147, tea_CELoss: 2.0786 stu_CELoss: 2.2630 DMLLoss: 0.3731 
2022-03-14 00:12:46 - train: epoch 0013, iter [03400, 05004], lr: 0.100000, loss: 4.7734, tea_CELoss: 2.1219 stu_CELoss: 2.2694 DMLLoss: 0.3821 
2022-03-14 00:13:18 - train: epoch 0013, iter [03500, 05004], lr: 0.100000, loss: 4.8278, tea_CELoss: 2.1163 stu_CELoss: 2.2947 DMLLoss: 0.4167 
2022-03-14 00:13:51 - train: epoch 0013, iter [03600, 05004], lr: 0.100000, loss: 5.2476, tea_CELoss: 2.2986 stu_CELoss: 2.5292 DMLLoss: 0.4198 
2022-03-14 00:14:24 - train: epoch 0013, iter [03700, 05004], lr: 0.100000, loss: 4.6207, tea_CELoss: 2.0180 stu_CELoss: 2.2252 DMLLoss: 0.3775 
2022-03-14 00:14:57 - train: epoch 0013, iter [03800, 05004], lr: 0.100000, loss: 5.5184, tea_CELoss: 2.4899 stu_CELoss: 2.6109 DMLLoss: 0.4176 
2022-03-14 00:15:30 - train: epoch 0013, iter [03900, 05004], lr: 0.100000, loss: 5.3895, tea_CELoss: 2.4221 stu_CELoss: 2.5526 DMLLoss: 0.4148 
2022-03-14 00:16:03 - train: epoch 0013, iter [04000, 05004], lr: 0.100000, loss: 4.9918, tea_CELoss: 2.2549 stu_CELoss: 2.3551 DMLLoss: 0.3818 
2022-03-14 00:16:37 - train: epoch 0013, iter [04100, 05004], lr: 0.100000, loss: 4.6476, tea_CELoss: 2.0197 stu_CELoss: 2.2464 DMLLoss: 0.3815 
2022-03-14 00:17:10 - train: epoch 0013, iter [04200, 05004], lr: 0.100000, loss: 5.1099, tea_CELoss: 2.2666 stu_CELoss: 2.4625 DMLLoss: 0.3808 
2022-03-14 00:17:42 - train: epoch 0013, iter [04300, 05004], lr: 0.100000, loss: 5.0018, tea_CELoss: 2.2333 stu_CELoss: 2.3907 DMLLoss: 0.3778 
2022-03-14 00:18:16 - train: epoch 0013, iter [04400, 05004], lr: 0.100000, loss: 4.8137, tea_CELoss: 2.0664 stu_CELoss: 2.3117 DMLLoss: 0.4356 
2022-03-14 00:18:49 - train: epoch 0013, iter [04500, 05004], lr: 0.100000, loss: 4.8188, tea_CELoss: 2.1076 stu_CELoss: 2.3121 DMLLoss: 0.3991 
2022-03-14 00:19:23 - train: epoch 0013, iter [04600, 05004], lr: 0.100000, loss: 4.8634, tea_CELoss: 2.1511 stu_CELoss: 2.3516 DMLLoss: 0.3607 
2022-03-14 00:19:55 - train: epoch 0013, iter [04700, 05004], lr: 0.100000, loss: 5.1695, tea_CELoss: 2.3063 stu_CELoss: 2.4840 DMLLoss: 0.3791 
2022-03-14 00:20:28 - train: epoch 0013, iter [04800, 05004], lr: 0.100000, loss: 5.1453, tea_CELoss: 2.3402 stu_CELoss: 2.4387 DMLLoss: 0.3665 
2022-03-14 00:21:01 - train: epoch 0013, iter [04900, 05004], lr: 0.100000, loss: 5.4143, tea_CELoss: 2.4355 stu_CELoss: 2.5827 DMLLoss: 0.3961 
2022-03-14 00:21:33 - train: epoch 0013, iter [05000, 05004], lr: 0.100000, loss: 4.9760, tea_CELoss: 2.1820 stu_CELoss: 2.3926 DMLLoss: 0.4014 
2022-03-14 00:21:34 - train: epoch 013, train_loss: 5.0431
2022-03-14 00:24:03 - eval: epoch: 013, tea_acc1: 54.616%, tea_acc5: 79.770%, tea_test_loss: 1.9289, stu_acc1: 51.234%, stu_acc5: 76.910%, stu_test_loss: 2.1048
2022-03-14 00:24:04 - until epoch: 013, tea_best_acc1: 54.616%, stu_best_acc1: 51.234%
2022-03-14 00:24:04 - epoch 014 lr: 0.1
2022-03-14 00:24:41 - train: epoch 0014, iter [00100, 05004], lr: 0.100000, loss: 5.0101, tea_CELoss: 2.2639 stu_CELoss: 2.3763 DMLLoss: 0.3699 
2022-03-14 00:25:15 - train: epoch 0014, iter [00200, 05004], lr: 0.100000, loss: 5.5921, tea_CELoss: 2.4939 stu_CELoss: 2.6439 DMLLoss: 0.4543 
2022-03-14 00:25:48 - train: epoch 0014, iter [00300, 05004], lr: 0.100000, loss: 4.5974, tea_CELoss: 2.0339 stu_CELoss: 2.2283 DMLLoss: 0.3353 
2022-03-14 00:26:22 - train: epoch 0014, iter [00400, 05004], lr: 0.100000, loss: 4.7305, tea_CELoss: 2.1073 stu_CELoss: 2.2260 DMLLoss: 0.3972 
2022-03-14 00:26:54 - train: epoch 0014, iter [00500, 05004], lr: 0.100000, loss: 4.9257, tea_CELoss: 2.1500 stu_CELoss: 2.3806 DMLLoss: 0.3951 
2022-03-14 00:27:27 - train: epoch 0014, iter [00600, 05004], lr: 0.100000, loss: 5.2746, tea_CELoss: 2.3704 stu_CELoss: 2.4829 DMLLoss: 0.4213 
2022-03-14 00:28:01 - train: epoch 0014, iter [00700, 05004], lr: 0.100000, loss: 4.7436, tea_CELoss: 2.1673 stu_CELoss: 2.1722 DMLLoss: 0.4042 
2022-03-14 00:28:35 - train: epoch 0014, iter [00800, 05004], lr: 0.100000, loss: 4.8505, tea_CELoss: 2.1484 stu_CELoss: 2.2903 DMLLoss: 0.4119 
2022-03-14 00:29:07 - train: epoch 0014, iter [00900, 05004], lr: 0.100000, loss: 4.9357, tea_CELoss: 2.2125 stu_CELoss: 2.3696 DMLLoss: 0.3536 
2022-03-14 00:29:40 - train: epoch 0014, iter [01000, 05004], lr: 0.100000, loss: 5.2239, tea_CELoss: 2.3360 stu_CELoss: 2.4890 DMLLoss: 0.3989 
2022-03-14 00:30:14 - train: epoch 0014, iter [01100, 05004], lr: 0.100000, loss: 4.9112, tea_CELoss: 2.1531 stu_CELoss: 2.3583 DMLLoss: 0.3999 
2022-03-14 00:30:47 - train: epoch 0014, iter [01200, 05004], lr: 0.100000, loss: 5.3275, tea_CELoss: 2.3592 stu_CELoss: 2.5757 DMLLoss: 0.3926 
2022-03-14 00:31:21 - train: epoch 0014, iter [01300, 05004], lr: 0.100000, loss: 5.2302, tea_CELoss: 2.2919 stu_CELoss: 2.5339 DMLLoss: 0.4044 
2022-03-14 00:31:54 - train: epoch 0014, iter [01400, 05004], lr: 0.100000, loss: 5.3373, tea_CELoss: 2.3271 stu_CELoss: 2.6038 DMLLoss: 0.4063 
2022-03-14 00:32:27 - train: epoch 0014, iter [01500, 05004], lr: 0.100000, loss: 5.3163, tea_CELoss: 2.3560 stu_CELoss: 2.5770 DMLLoss: 0.3832 
2022-03-14 00:33:00 - train: epoch 0014, iter [01600, 05004], lr: 0.100000, loss: 5.0913, tea_CELoss: 2.2190 stu_CELoss: 2.4603 DMLLoss: 0.4120 
2022-03-14 00:33:34 - train: epoch 0014, iter [01700, 05004], lr: 0.100000, loss: 5.2602, tea_CELoss: 2.3725 stu_CELoss: 2.4880 DMLLoss: 0.3997 
2022-03-14 00:34:07 - train: epoch 0014, iter [01800, 05004], lr: 0.100000, loss: 5.2836, tea_CELoss: 2.2948 stu_CELoss: 2.5687 DMLLoss: 0.4200 
2022-03-14 00:34:41 - train: epoch 0014, iter [01900, 05004], lr: 0.100000, loss: 4.8943, tea_CELoss: 2.1934 stu_CELoss: 2.3115 DMLLoss: 0.3894 
2022-03-14 00:35:13 - train: epoch 0014, iter [02000, 05004], lr: 0.100000, loss: 4.7941, tea_CELoss: 2.0935 stu_CELoss: 2.3008 DMLLoss: 0.3999 
2022-03-14 00:35:46 - train: epoch 0014, iter [02100, 05004], lr: 0.100000, loss: 5.3830, tea_CELoss: 2.3842 stu_CELoss: 2.5742 DMLLoss: 0.4245 
2022-03-14 00:36:19 - train: epoch 0014, iter [02200, 05004], lr: 0.100000, loss: 4.9063, tea_CELoss: 2.1828 stu_CELoss: 2.3370 DMLLoss: 0.3865 
2022-03-14 00:36:52 - train: epoch 0014, iter [02300, 05004], lr: 0.100000, loss: 4.6018, tea_CELoss: 2.0210 stu_CELoss: 2.2102 DMLLoss: 0.3706 
2022-03-14 00:37:25 - train: epoch 0014, iter [02400, 05004], lr: 0.100000, loss: 5.1803, tea_CELoss: 2.3045 stu_CELoss: 2.4870 DMLLoss: 0.3888 
2022-03-14 00:37:59 - train: epoch 0014, iter [02500, 05004], lr: 0.100000, loss: 4.8965, tea_CELoss: 2.1546 stu_CELoss: 2.3530 DMLLoss: 0.3889 
2022-03-14 00:38:32 - train: epoch 0014, iter [02600, 05004], lr: 0.100000, loss: 4.7445, tea_CELoss: 2.1004 stu_CELoss: 2.2398 DMLLoss: 0.4043 
2022-03-14 00:39:05 - train: epoch 0014, iter [02700, 05004], lr: 0.100000, loss: 5.1648, tea_CELoss: 2.3166 stu_CELoss: 2.4133 DMLLoss: 0.4349 
2022-03-14 00:39:38 - train: epoch 0014, iter [02800, 05004], lr: 0.100000, loss: 5.4461, tea_CELoss: 2.5173 stu_CELoss: 2.5254 DMLLoss: 0.4033 
2022-03-14 00:40:11 - train: epoch 0014, iter [02900, 05004], lr: 0.100000, loss: 5.1358, tea_CELoss: 2.2478 stu_CELoss: 2.4499 DMLLoss: 0.4381 
2022-03-14 00:40:45 - train: epoch 0014, iter [03000, 05004], lr: 0.100000, loss: 5.2759, tea_CELoss: 2.3043 stu_CELoss: 2.5440 DMLLoss: 0.4276 
2022-03-14 00:41:18 - train: epoch 0014, iter [03100, 05004], lr: 0.100000, loss: 4.8432, tea_CELoss: 2.1354 stu_CELoss: 2.2810 DMLLoss: 0.4268 
2022-03-14 00:41:51 - train: epoch 0014, iter [03200, 05004], lr: 0.100000, loss: 5.0286, tea_CELoss: 2.2660 stu_CELoss: 2.3907 DMLLoss: 0.3719 
2022-03-14 00:42:25 - train: epoch 0014, iter [03300, 05004], lr: 0.100000, loss: 4.7008, tea_CELoss: 2.1061 stu_CELoss: 2.2223 DMLLoss: 0.3724 
2022-03-14 00:42:58 - train: epoch 0014, iter [03400, 05004], lr: 0.100000, loss: 4.9099, tea_CELoss: 2.1343 stu_CELoss: 2.3684 DMLLoss: 0.4073 
2022-03-14 00:43:32 - train: epoch 0014, iter [03500, 05004], lr: 0.100000, loss: 4.9611, tea_CELoss: 2.1962 stu_CELoss: 2.3609 DMLLoss: 0.4040 
2022-03-14 00:44:05 - train: epoch 0014, iter [03600, 05004], lr: 0.100000, loss: 4.7494, tea_CELoss: 2.1412 stu_CELoss: 2.2288 DMLLoss: 0.3794 
2022-03-14 00:44:38 - train: epoch 0014, iter [03700, 05004], lr: 0.100000, loss: 5.0212, tea_CELoss: 2.2575 stu_CELoss: 2.3953 DMLLoss: 0.3683 
2022-03-14 00:45:11 - train: epoch 0014, iter [03800, 05004], lr: 0.100000, loss: 5.3876, tea_CELoss: 2.3987 stu_CELoss: 2.5699 DMLLoss: 0.4190 
2022-03-14 00:45:44 - train: epoch 0014, iter [03900, 05004], lr: 0.100000, loss: 5.1803, tea_CELoss: 2.3202 stu_CELoss: 2.4748 DMLLoss: 0.3854 
2022-03-14 00:46:18 - train: epoch 0014, iter [04000, 05004], lr: 0.100000, loss: 5.1271, tea_CELoss: 2.2863 stu_CELoss: 2.4452 DMLLoss: 0.3956 
2022-03-14 00:46:51 - train: epoch 0014, iter [04100, 05004], lr: 0.100000, loss: 5.0815, tea_CELoss: 2.2835 stu_CELoss: 2.3936 DMLLoss: 0.4044 
2022-03-14 00:47:24 - train: epoch 0014, iter [04200, 05004], lr: 0.100000, loss: 4.9255, tea_CELoss: 2.2312 stu_CELoss: 2.3069 DMLLoss: 0.3873 
2022-03-14 00:47:57 - train: epoch 0014, iter [04300, 05004], lr: 0.100000, loss: 5.0516, tea_CELoss: 2.2976 stu_CELoss: 2.3843 DMLLoss: 0.3697 
2022-03-14 00:48:31 - train: epoch 0014, iter [04400, 05004], lr: 0.100000, loss: 4.9331, tea_CELoss: 2.1895 stu_CELoss: 2.3363 DMLLoss: 0.4073 
2022-03-14 00:49:04 - train: epoch 0014, iter [04500, 05004], lr: 0.100000, loss: 5.0008, tea_CELoss: 2.2348 stu_CELoss: 2.3737 DMLLoss: 0.3924 
2022-03-14 00:49:37 - train: epoch 0014, iter [04600, 05004], lr: 0.100000, loss: 4.7280, tea_CELoss: 2.0717 stu_CELoss: 2.2726 DMLLoss: 0.3837 
2022-03-14 00:50:10 - train: epoch 0014, iter [04700, 05004], lr: 0.100000, loss: 4.8079, tea_CELoss: 2.1530 stu_CELoss: 2.2834 DMLLoss: 0.3715 
2022-03-14 00:50:43 - train: epoch 0014, iter [04800, 05004], lr: 0.100000, loss: 5.3920, tea_CELoss: 2.3881 stu_CELoss: 2.5732 DMLLoss: 0.4306 
2022-03-14 00:51:17 - train: epoch 0014, iter [04900, 05004], lr: 0.100000, loss: 5.2400, tea_CELoss: 2.3634 stu_CELoss: 2.4632 DMLLoss: 0.4134 
2022-03-14 00:51:48 - train: epoch 0014, iter [05000, 05004], lr: 0.100000, loss: 4.9509, tea_CELoss: 2.1685 stu_CELoss: 2.3842 DMLLoss: 0.3982 
2022-03-14 00:51:49 - train: epoch 014, train_loss: 5.0323
2022-03-14 00:54:17 - eval: epoch: 014, tea_acc1: 52.840%, tea_acc5: 78.228%, tea_test_loss: 2.0076, stu_acc1: 48.760%, stu_acc5: 75.156%, stu_test_loss: 2.2240
2022-03-14 00:54:18 - until epoch: 014, tea_best_acc1: 54.616%, stu_best_acc1: 51.234%
2022-03-14 00:54:18 - epoch 015 lr: 0.1
2022-03-14 00:54:55 - train: epoch 0015, iter [00100, 05004], lr: 0.100000, loss: 4.7932, tea_CELoss: 2.1288 stu_CELoss: 2.2686 DMLLoss: 0.3958 
2022-03-14 00:55:29 - train: epoch 0015, iter [00200, 05004], lr: 0.100000, loss: 5.4118, tea_CELoss: 2.4381 stu_CELoss: 2.5786 DMLLoss: 0.3951 
2022-03-14 00:56:02 - train: epoch 0015, iter [00300, 05004], lr: 0.100000, loss: 5.4163, tea_CELoss: 2.4403 stu_CELoss: 2.5788 DMLLoss: 0.3971 
2022-03-14 00:56:34 - train: epoch 0015, iter [00400, 05004], lr: 0.100000, loss: 4.9940, tea_CELoss: 2.1579 stu_CELoss: 2.4168 DMLLoss: 0.4193 
2022-03-14 00:57:08 - train: epoch 0015, iter [00500, 05004], lr: 0.100000, loss: 4.6445, tea_CELoss: 2.0783 stu_CELoss: 2.2048 DMLLoss: 0.3613 
2022-03-14 00:57:40 - train: epoch 0015, iter [00600, 05004], lr: 0.100000, loss: 5.2277, tea_CELoss: 2.3746 stu_CELoss: 2.4678 DMLLoss: 0.3853 
2022-03-14 00:58:14 - train: epoch 0015, iter [00700, 05004], lr: 0.100000, loss: 5.1117, tea_CELoss: 2.3017 stu_CELoss: 2.4099 DMLLoss: 0.4001 
2022-03-14 00:58:47 - train: epoch 0015, iter [00800, 05004], lr: 0.100000, loss: 4.8100, tea_CELoss: 2.1273 stu_CELoss: 2.2676 DMLLoss: 0.4151 
2022-03-14 00:59:20 - train: epoch 0015, iter [00900, 05004], lr: 0.100000, loss: 4.6295, tea_CELoss: 2.0207 stu_CELoss: 2.2216 DMLLoss: 0.3871 
2022-03-14 00:59:53 - train: epoch 0015, iter [01000, 05004], lr: 0.100000, loss: 5.1159, tea_CELoss: 2.2156 stu_CELoss: 2.4779 DMLLoss: 0.4224 
2022-03-14 01:00:26 - train: epoch 0015, iter [01100, 05004], lr: 0.100000, loss: 4.9159, tea_CELoss: 2.1417 stu_CELoss: 2.3827 DMLLoss: 0.3916 
2022-03-14 01:01:00 - train: epoch 0015, iter [01200, 05004], lr: 0.100000, loss: 5.1156, tea_CELoss: 2.2976 stu_CELoss: 2.4227 DMLLoss: 0.3953 
2022-03-14 01:01:33 - train: epoch 0015, iter [01300, 05004], lr: 0.100000, loss: 5.3459, tea_CELoss: 2.3897 stu_CELoss: 2.5726 DMLLoss: 0.3837 
2022-03-14 01:02:06 - train: epoch 0015, iter [01400, 05004], lr: 0.100000, loss: 4.7043, tea_CELoss: 2.0970 stu_CELoss: 2.2442 DMLLoss: 0.3631 
2022-03-14 01:02:40 - train: epoch 0015, iter [01500, 05004], lr: 0.100000, loss: 4.8995, tea_CELoss: 2.2026 stu_CELoss: 2.3315 DMLLoss: 0.3653 
2022-03-14 01:03:13 - train: epoch 0015, iter [01600, 05004], lr: 0.100000, loss: 5.1914, tea_CELoss: 2.2890 stu_CELoss: 2.5018 DMLLoss: 0.4006 
2022-03-14 01:03:45 - train: epoch 0015, iter [01700, 05004], lr: 0.100000, loss: 5.1622, tea_CELoss: 2.3409 stu_CELoss: 2.4116 DMLLoss: 0.4096 
2022-03-14 01:04:18 - train: epoch 0015, iter [01800, 05004], lr: 0.100000, loss: 5.0033, tea_CELoss: 2.2348 stu_CELoss: 2.4015 DMLLoss: 0.3670 
2022-03-14 01:04:51 - train: epoch 0015, iter [01900, 05004], lr: 0.100000, loss: 4.6667, tea_CELoss: 2.0554 stu_CELoss: 2.1969 DMLLoss: 0.4144 
2022-03-14 01:05:25 - train: epoch 0015, iter [02000, 05004], lr: 0.100000, loss: 4.6904, tea_CELoss: 2.0763 stu_CELoss: 2.2376 DMLLoss: 0.3765 
2022-03-14 01:05:59 - train: epoch 0015, iter [02100, 05004], lr: 0.100000, loss: 4.9883, tea_CELoss: 2.1754 stu_CELoss: 2.3643 DMLLoss: 0.4485 
2022-03-14 01:06:32 - train: epoch 0015, iter [02200, 05004], lr: 0.100000, loss: 5.2152, tea_CELoss: 2.3076 stu_CELoss: 2.4826 DMLLoss: 0.4250 
2022-03-14 01:07:04 - train: epoch 0015, iter [02300, 05004], lr: 0.100000, loss: 4.9921, tea_CELoss: 2.2332 stu_CELoss: 2.3579 DMLLoss: 0.4010 
2022-03-14 01:07:39 - train: epoch 0015, iter [02400, 05004], lr: 0.100000, loss: 4.9156, tea_CELoss: 2.1854 stu_CELoss: 2.3015 DMLLoss: 0.4287 
2022-03-14 01:08:11 - train: epoch 0015, iter [02500, 05004], lr: 0.100000, loss: 5.1745, tea_CELoss: 2.2941 stu_CELoss: 2.4622 DMLLoss: 0.4182 
2022-03-14 01:08:45 - train: epoch 0015, iter [02600, 05004], lr: 0.100000, loss: 4.7715, tea_CELoss: 2.1220 stu_CELoss: 2.2382 DMLLoss: 0.4113 
2022-03-14 01:09:17 - train: epoch 0015, iter [02700, 05004], lr: 0.100000, loss: 5.2814, tea_CELoss: 2.3342 stu_CELoss: 2.5761 DMLLoss: 0.3711 
2022-03-14 01:09:50 - train: epoch 0015, iter [02800, 05004], lr: 0.100000, loss: 5.0417, tea_CELoss: 2.2000 stu_CELoss: 2.4344 DMLLoss: 0.4072 
2022-03-14 01:10:24 - train: epoch 0015, iter [02900, 05004], lr: 0.100000, loss: 4.9270, tea_CELoss: 2.2054 stu_CELoss: 2.3177 DMLLoss: 0.4039 
2022-03-14 01:10:57 - train: epoch 0015, iter [03000, 05004], lr: 0.100000, loss: 4.6354, tea_CELoss: 2.0017 stu_CELoss: 2.2552 DMLLoss: 0.3786 
2022-03-14 01:11:30 - train: epoch 0015, iter [03100, 05004], lr: 0.100000, loss: 4.9571, tea_CELoss: 2.2150 stu_CELoss: 2.3497 DMLLoss: 0.3924 
2022-03-14 01:12:03 - train: epoch 0015, iter [03200, 05004], lr: 0.100000, loss: 5.0194, tea_CELoss: 2.2052 stu_CELoss: 2.3672 DMLLoss: 0.4471 
2022-03-14 01:12:36 - train: epoch 0015, iter [03300, 05004], lr: 0.100000, loss: 4.8558, tea_CELoss: 2.1657 stu_CELoss: 2.2994 DMLLoss: 0.3907 
2022-03-14 01:13:10 - train: epoch 0015, iter [03400, 05004], lr: 0.100000, loss: 4.7555, tea_CELoss: 2.1407 stu_CELoss: 2.2154 DMLLoss: 0.3994 
2022-03-14 01:13:43 - train: epoch 0015, iter [03500, 05004], lr: 0.100000, loss: 5.3517, tea_CELoss: 2.3736 stu_CELoss: 2.5358 DMLLoss: 0.4422 
2022-03-14 01:14:15 - train: epoch 0015, iter [03600, 05004], lr: 0.100000, loss: 5.1714, tea_CELoss: 2.3508 stu_CELoss: 2.4307 DMLLoss: 0.3899 
2022-03-14 01:14:49 - train: epoch 0015, iter [03700, 05004], lr: 0.100000, loss: 4.2508, tea_CELoss: 1.8425 stu_CELoss: 2.0305 DMLLoss: 0.3778 
2022-03-14 01:15:22 - train: epoch 0015, iter [03800, 05004], lr: 0.100000, loss: 5.1899, tea_CELoss: 2.3879 stu_CELoss: 2.4112 DMLLoss: 0.3907 
2022-03-14 01:15:55 - train: epoch 0015, iter [03900, 05004], lr: 0.100000, loss: 5.1764, tea_CELoss: 2.2816 stu_CELoss: 2.4733 DMLLoss: 0.4216 
2022-03-14 01:16:28 - train: epoch 0015, iter [04000, 05004], lr: 0.100000, loss: 5.0525, tea_CELoss: 2.2204 stu_CELoss: 2.4084 DMLLoss: 0.4237 
2022-03-14 01:17:02 - train: epoch 0015, iter [04100, 05004], lr: 0.100000, loss: 4.9381, tea_CELoss: 2.1923 stu_CELoss: 2.3598 DMLLoss: 0.3860 
2022-03-14 01:17:34 - train: epoch 0015, iter [04200, 05004], lr: 0.100000, loss: 4.6039, tea_CELoss: 2.0704 stu_CELoss: 2.1791 DMLLoss: 0.3544 
2022-03-14 01:18:08 - train: epoch 0015, iter [04300, 05004], lr: 0.100000, loss: 4.9457, tea_CELoss: 2.2002 stu_CELoss: 2.3505 DMLLoss: 0.3950 
2022-03-14 01:18:41 - train: epoch 0015, iter [04400, 05004], lr: 0.100000, loss: 4.9460, tea_CELoss: 2.2118 stu_CELoss: 2.3817 DMLLoss: 0.3526 
2022-03-14 01:19:15 - train: epoch 0015, iter [04500, 05004], lr: 0.100000, loss: 4.9029, tea_CELoss: 2.1151 stu_CELoss: 2.3734 DMLLoss: 0.4144 
2022-03-14 01:19:48 - train: epoch 0015, iter [04600, 05004], lr: 0.100000, loss: 5.0953, tea_CELoss: 2.3052 stu_CELoss: 2.4262 DMLLoss: 0.3640 
2022-03-14 01:20:20 - train: epoch 0015, iter [04700, 05004], lr: 0.100000, loss: 5.0959, tea_CELoss: 2.2550 stu_CELoss: 2.4239 DMLLoss: 0.4171 
2022-03-14 01:20:54 - train: epoch 0015, iter [04800, 05004], lr: 0.100000, loss: 5.2407, tea_CELoss: 2.2722 stu_CELoss: 2.5308 DMLLoss: 0.4377 
2022-03-14 01:21:27 - train: epoch 0015, iter [04900, 05004], lr: 0.100000, loss: 4.9856, tea_CELoss: 2.1848 stu_CELoss: 2.3601 DMLLoss: 0.4407 
2022-03-14 01:21:59 - train: epoch 0015, iter [05000, 05004], lr: 0.100000, loss: 5.2713, tea_CELoss: 2.3168 stu_CELoss: 2.5523 DMLLoss: 0.4022 
2022-03-14 01:22:00 - train: epoch 015, train_loss: 5.0212
2022-03-14 01:24:29 - eval: epoch: 015, tea_acc1: 53.652%, tea_acc5: 79.186%, tea_test_loss: 1.9687, stu_acc1: 51.138%, stu_acc5: 77.036%, stu_test_loss: 2.0877
2022-03-14 01:24:30 - until epoch: 015, tea_best_acc1: 54.616%, stu_best_acc1: 51.234%
2022-03-14 01:24:30 - epoch 016 lr: 0.1
2022-03-14 01:25:07 - train: epoch 0016, iter [00100, 05004], lr: 0.100000, loss: 4.8036, tea_CELoss: 2.2074 stu_CELoss: 2.2418 DMLLoss: 0.3544 
2022-03-14 01:25:41 - train: epoch 0016, iter [00200, 05004], lr: 0.100000, loss: 4.5510, tea_CELoss: 2.0087 stu_CELoss: 2.1319 DMLLoss: 0.4105 
2022-03-14 01:26:14 - train: epoch 0016, iter [00300, 05004], lr: 0.100000, loss: 5.1821, tea_CELoss: 2.2635 stu_CELoss: 2.4611 DMLLoss: 0.4574 
2022-03-14 01:26:47 - train: epoch 0016, iter [00400, 05004], lr: 0.100000, loss: 4.9981, tea_CELoss: 2.2150 stu_CELoss: 2.3984 DMLLoss: 0.3847 
2022-03-14 01:27:20 - train: epoch 0016, iter [00500, 05004], lr: 0.100000, loss: 4.9008, tea_CELoss: 2.1856 stu_CELoss: 2.3397 DMLLoss: 0.3755 
2022-03-14 01:27:53 - train: epoch 0016, iter [00600, 05004], lr: 0.100000, loss: 4.7986, tea_CELoss: 2.0974 stu_CELoss: 2.2663 DMLLoss: 0.4348 
2022-03-14 01:28:26 - train: epoch 0016, iter [00700, 05004], lr: 0.100000, loss: 4.7363, tea_CELoss: 2.1357 stu_CELoss: 2.2572 DMLLoss: 0.3434 
2022-03-14 01:29:00 - train: epoch 0016, iter [00800, 05004], lr: 0.100000, loss: 4.8724, tea_CELoss: 2.2037 stu_CELoss: 2.2625 DMLLoss: 0.4062 
2022-03-14 01:29:32 - train: epoch 0016, iter [00900, 05004], lr: 0.100000, loss: 5.0198, tea_CELoss: 2.1796 stu_CELoss: 2.4392 DMLLoss: 0.4010 
2022-03-14 01:30:05 - train: epoch 0016, iter [01000, 05004], lr: 0.100000, loss: 4.7754, tea_CELoss: 2.0963 stu_CELoss: 2.2354 DMLLoss: 0.4437 
2022-03-14 01:30:39 - train: epoch 0016, iter [01100, 05004], lr: 0.100000, loss: 5.0998, tea_CELoss: 2.2616 stu_CELoss: 2.4171 DMLLoss: 0.4210 
2022-03-14 01:31:11 - train: epoch 0016, iter [01200, 05004], lr: 0.100000, loss: 4.7870, tea_CELoss: 2.1135 stu_CELoss: 2.2595 DMLLoss: 0.4141 
2022-03-14 01:31:45 - train: epoch 0016, iter [01300, 05004], lr: 0.100000, loss: 5.0588, tea_CELoss: 2.2989 stu_CELoss: 2.3976 DMLLoss: 0.3624 
2022-03-14 01:32:18 - train: epoch 0016, iter [01400, 05004], lr: 0.100000, loss: 4.8464, tea_CELoss: 2.1414 stu_CELoss: 2.3185 DMLLoss: 0.3865 
2022-03-14 01:32:51 - train: epoch 0016, iter [01500, 05004], lr: 0.100000, loss: 5.5420, tea_CELoss: 2.4952 stu_CELoss: 2.6540 DMLLoss: 0.3929 
2022-03-14 01:33:24 - train: epoch 0016, iter [01600, 05004], lr: 0.100000, loss: 5.4459, tea_CELoss: 2.4629 stu_CELoss: 2.6110 DMLLoss: 0.3719 
2022-03-14 01:33:57 - train: epoch 0016, iter [01700, 05004], lr: 0.100000, loss: 5.0632, tea_CELoss: 2.2497 stu_CELoss: 2.3900 DMLLoss: 0.4236 
2022-03-14 01:34:30 - train: epoch 0016, iter [01800, 05004], lr: 0.100000, loss: 5.3057, tea_CELoss: 2.3566 stu_CELoss: 2.5237 DMLLoss: 0.4253 
2022-03-14 01:35:03 - train: epoch 0016, iter [01900, 05004], lr: 0.100000, loss: 5.0107, tea_CELoss: 2.2068 stu_CELoss: 2.4244 DMLLoss: 0.3794 
2022-03-14 01:35:36 - train: epoch 0016, iter [02000, 05004], lr: 0.100000, loss: 4.2713, tea_CELoss: 1.8601 stu_CELoss: 2.0402 DMLLoss: 0.3710 
2022-03-14 01:36:10 - train: epoch 0016, iter [02100, 05004], lr: 0.100000, loss: 5.0416, tea_CELoss: 2.2179 stu_CELoss: 2.4278 DMLLoss: 0.3959 
2022-03-14 01:36:43 - train: epoch 0016, iter [02200, 05004], lr: 0.100000, loss: 5.1752, tea_CELoss: 2.2956 stu_CELoss: 2.4665 DMLLoss: 0.4131 
2022-03-14 01:37:16 - train: epoch 0016, iter [02300, 05004], lr: 0.100000, loss: 5.1548, tea_CELoss: 2.2728 stu_CELoss: 2.5011 DMLLoss: 0.3809 
2022-03-14 01:37:49 - train: epoch 0016, iter [02400, 05004], lr: 0.100000, loss: 4.8997, tea_CELoss: 2.2058 stu_CELoss: 2.3062 DMLLoss: 0.3877 
2022-03-14 01:38:22 - train: epoch 0016, iter [02500, 05004], lr: 0.100000, loss: 5.0011, tea_CELoss: 2.1606 stu_CELoss: 2.4014 DMLLoss: 0.4391 
2022-03-14 01:38:55 - train: epoch 0016, iter [02600, 05004], lr: 0.100000, loss: 5.0081, tea_CELoss: 2.2515 stu_CELoss: 2.3594 DMLLoss: 0.3972 
2022-03-14 01:39:28 - train: epoch 0016, iter [02700, 05004], lr: 0.100000, loss: 4.9113, tea_CELoss: 2.1704 stu_CELoss: 2.2898 DMLLoss: 0.4511 
2022-03-14 01:40:01 - train: epoch 0016, iter [02800, 05004], lr: 0.100000, loss: 4.6615, tea_CELoss: 2.1008 stu_CELoss: 2.2083 DMLLoss: 0.3524 
2022-03-14 01:40:35 - train: epoch 0016, iter [02900, 05004], lr: 0.100000, loss: 4.8268, tea_CELoss: 2.1123 stu_CELoss: 2.3439 DMLLoss: 0.3706 
2022-03-14 01:41:07 - train: epoch 0016, iter [03000, 05004], lr: 0.100000, loss: 5.3602, tea_CELoss: 2.4233 stu_CELoss: 2.5207 DMLLoss: 0.4162 
2022-03-14 01:41:41 - train: epoch 0016, iter [03100, 05004], lr: 0.100000, loss: 4.9938, tea_CELoss: 2.2454 stu_CELoss: 2.3753 DMLLoss: 0.3731 
2022-03-14 01:42:13 - train: epoch 0016, iter [03200, 05004], lr: 0.100000, loss: 5.0724, tea_CELoss: 2.2245 stu_CELoss: 2.4321 DMLLoss: 0.4159 
2022-03-14 01:42:47 - train: epoch 0016, iter [03300, 05004], lr: 0.100000, loss: 5.0764, tea_CELoss: 2.3250 stu_CELoss: 2.3932 DMLLoss: 0.3582 
2022-03-14 01:43:20 - train: epoch 0016, iter [03400, 05004], lr: 0.100000, loss: 4.9446, tea_CELoss: 2.2385 stu_CELoss: 2.3145 DMLLoss: 0.3916 
2022-03-14 01:43:53 - train: epoch 0016, iter [03500, 05004], lr: 0.100000, loss: 4.7305, tea_CELoss: 2.0861 stu_CELoss: 2.2505 DMLLoss: 0.3939 
2022-03-14 01:44:26 - train: epoch 0016, iter [03600, 05004], lr: 0.100000, loss: 4.7275, tea_CELoss: 2.0748 stu_CELoss: 2.2573 DMLLoss: 0.3955 
2022-03-14 01:44:59 - train: epoch 0016, iter [03700, 05004], lr: 0.100000, loss: 5.0865, tea_CELoss: 2.2168 stu_CELoss: 2.4463 DMLLoss: 0.4234 
2022-03-14 01:45:32 - train: epoch 0016, iter [03800, 05004], lr: 0.100000, loss: 5.4583, tea_CELoss: 2.4973 stu_CELoss: 2.5749 DMLLoss: 0.3860 
2022-03-14 01:46:06 - train: epoch 0016, iter [03900, 05004], lr: 0.100000, loss: 5.1980, tea_CELoss: 2.3408 stu_CELoss: 2.4690 DMLLoss: 0.3882 
2022-03-14 01:46:39 - train: epoch 0016, iter [04000, 05004], lr: 0.100000, loss: 5.1658, tea_CELoss: 2.3572 stu_CELoss: 2.4173 DMLLoss: 0.3913 
2022-03-14 01:47:12 - train: epoch 0016, iter [04100, 05004], lr: 0.100000, loss: 4.9300, tea_CELoss: 2.1600 stu_CELoss: 2.3587 DMLLoss: 0.4113 
2022-03-14 01:47:45 - train: epoch 0016, iter [04200, 05004], lr: 0.100000, loss: 4.8712, tea_CELoss: 2.1830 stu_CELoss: 2.2996 DMLLoss: 0.3886 
2022-03-14 01:48:18 - train: epoch 0016, iter [04300, 05004], lr: 0.100000, loss: 4.5823, tea_CELoss: 2.0380 stu_CELoss: 2.1688 DMLLoss: 0.3755 
2022-03-14 01:48:51 - train: epoch 0016, iter [04400, 05004], lr: 0.100000, loss: 4.8196, tea_CELoss: 2.1662 stu_CELoss: 2.2689 DMLLoss: 0.3845 
2022-03-14 01:49:24 - train: epoch 0016, iter [04500, 05004], lr: 0.100000, loss: 5.2651, tea_CELoss: 2.3880 stu_CELoss: 2.4881 DMLLoss: 0.3890 
2022-03-14 01:49:57 - train: epoch 0016, iter [04600, 05004], lr: 0.100000, loss: 4.7683, tea_CELoss: 2.1396 stu_CELoss: 2.2596 DMLLoss: 0.3692 
2022-03-14 01:50:30 - train: epoch 0016, iter [04700, 05004], lr: 0.100000, loss: 5.4048, tea_CELoss: 2.4468 stu_CELoss: 2.5551 DMLLoss: 0.4029 
2022-03-14 01:51:04 - train: epoch 0016, iter [04800, 05004], lr: 0.100000, loss: 4.9065, tea_CELoss: 2.1920 stu_CELoss: 2.3477 DMLLoss: 0.3669 
2022-03-14 01:51:37 - train: epoch 0016, iter [04900, 05004], lr: 0.100000, loss: 5.0920, tea_CELoss: 2.2544 stu_CELoss: 2.4348 DMLLoss: 0.4028 
2022-03-14 01:52:08 - train: epoch 0016, iter [05000, 05004], lr: 0.100000, loss: 5.2805, tea_CELoss: 2.3697 stu_CELoss: 2.5177 DMLLoss: 0.3931 
2022-03-14 01:52:09 - train: epoch 016, train_loss: 5.0099
2022-03-14 01:54:38 - eval: epoch: 016, tea_acc1: 53.844%, tea_acc5: 79.152%, tea_test_loss: 1.9503, stu_acc1: 50.758%, stu_acc5: 76.986%, stu_test_loss: 2.0937
2022-03-14 01:54:39 - until epoch: 016, tea_best_acc1: 54.616%, stu_best_acc1: 51.234%
2022-03-14 01:54:39 - epoch 017 lr: 0.1
2022-03-14 01:55:17 - train: epoch 0017, iter [00100, 05004], lr: 0.100000, loss: 5.0263, tea_CELoss: 2.2467 stu_CELoss: 2.3830 DMLLoss: 0.3966 
2022-03-14 01:55:50 - train: epoch 0017, iter [00200, 05004], lr: 0.100000, loss: 5.5186, tea_CELoss: 2.4610 stu_CELoss: 2.5996 DMLLoss: 0.4580 
2022-03-14 01:56:23 - train: epoch 0017, iter [00300, 05004], lr: 0.100000, loss: 5.3137, tea_CELoss: 2.3814 stu_CELoss: 2.5517 DMLLoss: 0.3807 
2022-03-14 01:56:57 - train: epoch 0017, iter [00400, 05004], lr: 0.100000, loss: 4.3132, tea_CELoss: 1.9279 stu_CELoss: 2.0029 DMLLoss: 0.3824 
2022-03-14 01:57:30 - train: epoch 0017, iter [00500, 05004], lr: 0.100000, loss: 4.7631, tea_CELoss: 2.1806 stu_CELoss: 2.2363 DMLLoss: 0.3462 
2022-03-14 01:58:03 - train: epoch 0017, iter [00600, 05004], lr: 0.100000, loss: 5.6400, tea_CELoss: 2.5373 stu_CELoss: 2.6897 DMLLoss: 0.4130 
2022-03-14 01:58:36 - train: epoch 0017, iter [00700, 05004], lr: 0.100000, loss: 4.8105, tea_CELoss: 2.1558 stu_CELoss: 2.2893 DMLLoss: 0.3655 
2022-03-14 01:59:09 - train: epoch 0017, iter [00800, 05004], lr: 0.100000, loss: 4.8713, tea_CELoss: 2.1750 stu_CELoss: 2.3002 DMLLoss: 0.3961 
2022-03-14 01:59:42 - train: epoch 0017, iter [00900, 05004], lr: 0.100000, loss: 4.9739, tea_CELoss: 2.1712 stu_CELoss: 2.3949 DMLLoss: 0.4078 
2022-03-14 02:00:15 - train: epoch 0017, iter [01000, 05004], lr: 0.100000, loss: 5.1045, tea_CELoss: 2.2739 stu_CELoss: 2.3915 DMLLoss: 0.4391 
2022-03-14 02:00:49 - train: epoch 0017, iter [01100, 05004], lr: 0.100000, loss: 5.4861, tea_CELoss: 2.4575 stu_CELoss: 2.6399 DMLLoss: 0.3887 
2022-03-14 02:01:22 - train: epoch 0017, iter [01200, 05004], lr: 0.100000, loss: 4.6722, tea_CELoss: 2.0905 stu_CELoss: 2.2203 DMLLoss: 0.3614 
2022-03-14 02:01:55 - train: epoch 0017, iter [01300, 05004], lr: 0.100000, loss: 5.2891, tea_CELoss: 2.3633 stu_CELoss: 2.5101 DMLLoss: 0.4157 
2022-03-14 02:02:28 - train: epoch 0017, iter [01400, 05004], lr: 0.100000, loss: 5.1421, tea_CELoss: 2.2719 stu_CELoss: 2.3921 DMLLoss: 0.4782 
2022-03-14 02:03:01 - train: epoch 0017, iter [01500, 05004], lr: 0.100000, loss: 4.8214, tea_CELoss: 2.1292 stu_CELoss: 2.2999 DMLLoss: 0.3922 
2022-03-14 02:03:34 - train: epoch 0017, iter [01600, 05004], lr: 0.100000, loss: 4.9360, tea_CELoss: 2.1721 stu_CELoss: 2.3699 DMLLoss: 0.3940 
2022-03-14 02:04:07 - train: epoch 0017, iter [01700, 05004], lr: 0.100000, loss: 4.6530, tea_CELoss: 2.0409 stu_CELoss: 2.2169 DMLLoss: 0.3952 
2022-03-14 02:04:41 - train: epoch 0017, iter [01800, 05004], lr: 0.100000, loss: 5.1487, tea_CELoss: 2.3044 stu_CELoss: 2.4031 DMLLoss: 0.4412 
2022-03-14 02:05:14 - train: epoch 0017, iter [01900, 05004], lr: 0.100000, loss: 4.9356, tea_CELoss: 2.2555 stu_CELoss: 2.2611 DMLLoss: 0.4190 
2022-03-14 02:05:47 - train: epoch 0017, iter [02000, 05004], lr: 0.100000, loss: 4.9428, tea_CELoss: 2.2273 stu_CELoss: 2.3705 DMLLoss: 0.3450 
2022-03-14 02:06:20 - train: epoch 0017, iter [02100, 05004], lr: 0.100000, loss: 4.9109, tea_CELoss: 2.1815 stu_CELoss: 2.3247 DMLLoss: 0.4048 
2022-03-14 02:06:53 - train: epoch 0017, iter [02200, 05004], lr: 0.100000, loss: 4.6665, tea_CELoss: 2.0406 stu_CELoss: 2.1851 DMLLoss: 0.4408 
2022-03-14 02:07:26 - train: epoch 0017, iter [02300, 05004], lr: 0.100000, loss: 5.1974, tea_CELoss: 2.3288 stu_CELoss: 2.4600 DMLLoss: 0.4086 
2022-03-14 02:07:59 - train: epoch 0017, iter [02400, 05004], lr: 0.100000, loss: 5.1994, tea_CELoss: 2.3282 stu_CELoss: 2.4701 DMLLoss: 0.4011 
2022-03-14 02:08:32 - train: epoch 0017, iter [02500, 05004], lr: 0.100000, loss: 5.3076, tea_CELoss: 2.4037 stu_CELoss: 2.4952 DMLLoss: 0.4088 
2022-03-14 02:09:05 - train: epoch 0017, iter [02600, 05004], lr: 0.100000, loss: 4.8315, tea_CELoss: 2.1300 stu_CELoss: 2.2945 DMLLoss: 0.4069 
2022-03-14 02:09:38 - train: epoch 0017, iter [02700, 05004], lr: 0.100000, loss: 4.9718, tea_CELoss: 2.1725 stu_CELoss: 2.3946 DMLLoss: 0.4047 
2022-03-14 02:10:11 - train: epoch 0017, iter [02800, 05004], lr: 0.100000, loss: 4.7458, tea_CELoss: 2.1666 stu_CELoss: 2.2217 DMLLoss: 0.3575 
2022-03-14 02:10:45 - train: epoch 0017, iter [02900, 05004], lr: 0.100000, loss: 5.6302, tea_CELoss: 2.5013 stu_CELoss: 2.7130 DMLLoss: 0.4159 
2022-03-14 02:11:17 - train: epoch 0017, iter [03000, 05004], lr: 0.100000, loss: 4.7898, tea_CELoss: 2.1282 stu_CELoss: 2.2726 DMLLoss: 0.3890 
2022-03-14 02:11:51 - train: epoch 0017, iter [03100, 05004], lr: 0.100000, loss: 5.2078, tea_CELoss: 2.3214 stu_CELoss: 2.4387 DMLLoss: 0.4478 
2022-03-14 02:12:24 - train: epoch 0017, iter [03200, 05004], lr: 0.100000, loss: 4.8851, tea_CELoss: 2.1958 stu_CELoss: 2.2513 DMLLoss: 0.4381 
2022-03-14 02:12:56 - train: epoch 0017, iter [03300, 05004], lr: 0.100000, loss: 5.1955, tea_CELoss: 2.3656 stu_CELoss: 2.4633 DMLLoss: 0.3665 
2022-03-14 02:13:29 - train: epoch 0017, iter [03400, 05004], lr: 0.100000, loss: 4.7729, tea_CELoss: 2.1389 stu_CELoss: 2.2702 DMLLoss: 0.3639 
2022-03-14 02:14:02 - train: epoch 0017, iter [03500, 05004], lr: 0.100000, loss: 4.9191, tea_CELoss: 2.1636 stu_CELoss: 2.3630 DMLLoss: 0.3925 
2022-03-14 02:14:34 - train: epoch 0017, iter [03600, 05004], lr: 0.100000, loss: 5.1952, tea_CELoss: 2.3349 stu_CELoss: 2.4873 DMLLoss: 0.3731 
2022-03-14 02:15:08 - train: epoch 0017, iter [03700, 05004], lr: 0.100000, loss: 4.7760, tea_CELoss: 2.1435 stu_CELoss: 2.2446 DMLLoss: 0.3878 
2022-03-14 02:15:41 - train: epoch 0017, iter [03800, 05004], lr: 0.100000, loss: 5.6235, tea_CELoss: 2.5337 stu_CELoss: 2.6907 DMLLoss: 0.3992 
2022-03-14 02:16:14 - train: epoch 0017, iter [03900, 05004], lr: 0.100000, loss: 4.6727, tea_CELoss: 2.0861 stu_CELoss: 2.1974 DMLLoss: 0.3892 
2022-03-14 02:16:47 - train: epoch 0017, iter [04000, 05004], lr: 0.100000, loss: 4.9324, tea_CELoss: 2.2148 stu_CELoss: 2.3509 DMLLoss: 0.3667 
2022-03-14 02:17:20 - train: epoch 0017, iter [04100, 05004], lr: 0.100000, loss: 5.3439, tea_CELoss: 2.3467 stu_CELoss: 2.5667 DMLLoss: 0.4305 
2022-03-14 02:17:54 - train: epoch 0017, iter [04200, 05004], lr: 0.100000, loss: 5.0286, tea_CELoss: 2.2673 stu_CELoss: 2.4005 DMLLoss: 0.3609 
2022-03-14 02:18:26 - train: epoch 0017, iter [04300, 05004], lr: 0.100000, loss: 4.6270, tea_CELoss: 2.0217 stu_CELoss: 2.1986 DMLLoss: 0.4067 
2022-03-14 02:18:59 - train: epoch 0017, iter [04400, 05004], lr: 0.100000, loss: 5.3166, tea_CELoss: 2.3785 stu_CELoss: 2.4977 DMLLoss: 0.4404 
2022-03-14 02:19:32 - train: epoch 0017, iter [04500, 05004], lr: 0.100000, loss: 5.2535, tea_CELoss: 2.3976 stu_CELoss: 2.4681 DMLLoss: 0.3879 
2022-03-14 02:20:05 - train: epoch 0017, iter [04600, 05004], lr: 0.100000, loss: 4.7712, tea_CELoss: 2.0971 stu_CELoss: 2.2766 DMLLoss: 0.3976 
2022-03-14 02:20:38 - train: epoch 0017, iter [04700, 05004], lr: 0.100000, loss: 5.3904, tea_CELoss: 2.4612 stu_CELoss: 2.5099 DMLLoss: 0.4193 
2022-03-14 02:21:10 - train: epoch 0017, iter [04800, 05004], lr: 0.100000, loss: 5.1789, tea_CELoss: 2.3115 stu_CELoss: 2.4456 DMLLoss: 0.4218 
2022-03-14 02:21:44 - train: epoch 0017, iter [04900, 05004], lr: 0.100000, loss: 5.1112, tea_CELoss: 2.3173 stu_CELoss: 2.3972 DMLLoss: 0.3968 
2022-03-14 02:22:15 - train: epoch 0017, iter [05000, 05004], lr: 0.100000, loss: 4.8788, tea_CELoss: 2.1055 stu_CELoss: 2.3405 DMLLoss: 0.4327 
2022-03-14 02:22:16 - train: epoch 017, train_loss: 5.0029
2022-03-14 02:24:44 - eval: epoch: 017, tea_acc1: 54.006%, tea_acc5: 79.252%, tea_test_loss: 1.9536, stu_acc1: 51.192%, stu_acc5: 77.068%, stu_test_loss: 2.1033
2022-03-14 02:24:44 - until epoch: 017, tea_best_acc1: 54.616%, stu_best_acc1: 51.234%
2022-03-14 02:24:44 - epoch 018 lr: 0.1
2022-03-14 02:25:22 - train: epoch 0018, iter [00100, 05004], lr: 0.100000, loss: 4.7354, tea_CELoss: 2.1349 stu_CELoss: 2.2526 DMLLoss: 0.3478 
2022-03-14 02:25:55 - train: epoch 0018, iter [00200, 05004], lr: 0.100000, loss: 5.6533, tea_CELoss: 2.5296 stu_CELoss: 2.6944 DMLLoss: 0.4292 
2022-03-14 02:26:29 - train: epoch 0018, iter [00300, 05004], lr: 0.100000, loss: 5.3427, tea_CELoss: 2.3654 stu_CELoss: 2.5442 DMLLoss: 0.4330 
2022-03-14 02:27:02 - train: epoch 0018, iter [00400, 05004], lr: 0.100000, loss: 5.2366, tea_CELoss: 2.3928 stu_CELoss: 2.4621 DMLLoss: 0.3817 
2022-03-14 02:27:35 - train: epoch 0018, iter [00500, 05004], lr: 0.100000, loss: 5.0865, tea_CELoss: 2.2641 stu_CELoss: 2.4186 DMLLoss: 0.4037 
2022-03-14 02:28:08 - train: epoch 0018, iter [00600, 05004], lr: 0.100000, loss: 5.0059, tea_CELoss: 2.2490 stu_CELoss: 2.3773 DMLLoss: 0.3796 
2022-03-14 02:28:41 - train: epoch 0018, iter [00700, 05004], lr: 0.100000, loss: 4.5691, tea_CELoss: 2.0102 stu_CELoss: 2.1462 DMLLoss: 0.4127 
2022-03-14 02:29:14 - train: epoch 0018, iter [00800, 05004], lr: 0.100000, loss: 5.1156, tea_CELoss: 2.3250 stu_CELoss: 2.4190 DMLLoss: 0.3715 
2022-03-14 02:29:47 - train: epoch 0018, iter [00900, 05004], lr: 0.100000, loss: 5.4264, tea_CELoss: 2.4034 stu_CELoss: 2.6269 DMLLoss: 0.3961 
2022-03-14 02:30:19 - train: epoch 0018, iter [01000, 05004], lr: 0.100000, loss: 4.6811, tea_CELoss: 2.0839 stu_CELoss: 2.2063 DMLLoss: 0.3908 
2022-03-14 02:30:52 - train: epoch 0018, iter [01100, 05004], lr: 0.100000, loss: 5.3822, tea_CELoss: 2.3951 stu_CELoss: 2.5829 DMLLoss: 0.4042 
2022-03-14 02:31:26 - train: epoch 0018, iter [01200, 05004], lr: 0.100000, loss: 4.6571, tea_CELoss: 2.0469 stu_CELoss: 2.2126 DMLLoss: 0.3977 
2022-03-14 02:31:59 - train: epoch 0018, iter [01300, 05004], lr: 0.100000, loss: 5.2379, tea_CELoss: 2.2822 stu_CELoss: 2.5661 DMLLoss: 0.3896 
2022-03-14 02:32:32 - train: epoch 0018, iter [01400, 05004], lr: 0.100000, loss: 5.2637, tea_CELoss: 2.2999 stu_CELoss: 2.5202 DMLLoss: 0.4435 
2022-03-14 02:33:05 - train: epoch 0018, iter [01500, 05004], lr: 0.100000, loss: 5.4926, tea_CELoss: 2.5008 stu_CELoss: 2.5679 DMLLoss: 0.4239 
2022-03-14 02:33:38 - train: epoch 0018, iter [01600, 05004], lr: 0.100000, loss: 5.0586, tea_CELoss: 2.3127 stu_CELoss: 2.3616 DMLLoss: 0.3843 
2022-03-14 02:34:11 - train: epoch 0018, iter [01700, 05004], lr: 0.100000, loss: 5.0723, tea_CELoss: 2.2442 stu_CELoss: 2.4373 DMLLoss: 0.3909 
2022-03-14 02:34:44 - train: epoch 0018, iter [01800, 05004], lr: 0.100000, loss: 4.6964, tea_CELoss: 2.0940 stu_CELoss: 2.2122 DMLLoss: 0.3902 
2022-03-14 02:35:17 - train: epoch 0018, iter [01900, 05004], lr: 0.100000, loss: 5.0821, tea_CELoss: 2.2921 stu_CELoss: 2.4144 DMLLoss: 0.3756 
2022-03-14 02:35:50 - train: epoch 0018, iter [02000, 05004], lr: 0.100000, loss: 5.6079, tea_CELoss: 2.5084 stu_CELoss: 2.6968 DMLLoss: 0.4027 
2022-03-14 02:36:23 - train: epoch 0018, iter [02100, 05004], lr: 0.100000, loss: 5.5525, tea_CELoss: 2.4687 stu_CELoss: 2.6413 DMLLoss: 0.4425 
2022-03-14 02:36:57 - train: epoch 0018, iter [02200, 05004], lr: 0.100000, loss: 4.9815, tea_CELoss: 2.2724 stu_CELoss: 2.3250 DMLLoss: 0.3842 
2022-03-14 02:37:29 - train: epoch 0018, iter [02300, 05004], lr: 0.100000, loss: 5.0038, tea_CELoss: 2.2102 stu_CELoss: 2.4000 DMLLoss: 0.3937 
2022-03-14 02:38:03 - train: epoch 0018, iter [02400, 05004], lr: 0.100000, loss: 4.9270, tea_CELoss: 2.2287 stu_CELoss: 2.3291 DMLLoss: 0.3693 
2022-03-14 02:38:36 - train: epoch 0018, iter [02500, 05004], lr: 0.100000, loss: 4.4915, tea_CELoss: 1.9792 stu_CELoss: 2.0965 DMLLoss: 0.4157 
2022-03-14 02:39:08 - train: epoch 0018, iter [02600, 05004], lr: 0.100000, loss: 4.6370, tea_CELoss: 1.9998 stu_CELoss: 2.2351 DMLLoss: 0.4021 
2022-03-14 02:39:41 - train: epoch 0018, iter [02700, 05004], lr: 0.100000, loss: 5.1221, tea_CELoss: 2.2972 stu_CELoss: 2.4208 DMLLoss: 0.4041 
2022-03-14 02:40:14 - train: epoch 0018, iter [02800, 05004], lr: 0.100000, loss: 4.5924, tea_CELoss: 2.0677 stu_CELoss: 2.1593 DMLLoss: 0.3653 
2022-03-14 02:40:47 - train: epoch 0018, iter [02900, 05004], lr: 0.100000, loss: 4.9912, tea_CELoss: 2.2179 stu_CELoss: 2.3687 DMLLoss: 0.4045 
2022-03-14 02:41:21 - train: epoch 0018, iter [03000, 05004], lr: 0.100000, loss: 4.8882, tea_CELoss: 2.1965 stu_CELoss: 2.3234 DMLLoss: 0.3683 
2022-03-14 02:41:53 - train: epoch 0018, iter [03100, 05004], lr: 0.100000, loss: 5.8377, tea_CELoss: 2.6344 stu_CELoss: 2.7907 DMLLoss: 0.4126 
2022-03-14 02:42:26 - train: epoch 0018, iter [03200, 05004], lr: 0.100000, loss: 5.1366, tea_CELoss: 2.2932 stu_CELoss: 2.4247 DMLLoss: 0.4186 
2022-03-14 02:42:59 - train: epoch 0018, iter [03300, 05004], lr: 0.100000, loss: 4.9325, tea_CELoss: 2.1831 stu_CELoss: 2.3711 DMLLoss: 0.3783 
2022-03-14 02:43:32 - train: epoch 0018, iter [03400, 05004], lr: 0.100000, loss: 5.2236, tea_CELoss: 2.3680 stu_CELoss: 2.4827 DMLLoss: 0.3728 
2022-03-14 02:44:06 - train: epoch 0018, iter [03500, 05004], lr: 0.100000, loss: 5.0574, tea_CELoss: 2.2506 stu_CELoss: 2.4007 DMLLoss: 0.4061 
2022-03-14 02:44:39 - train: epoch 0018, iter [03600, 05004], lr: 0.100000, loss: 4.9365, tea_CELoss: 2.2544 stu_CELoss: 2.3041 DMLLoss: 0.3780 
2022-03-14 02:45:12 - train: epoch 0018, iter [03700, 05004], lr: 0.100000, loss: 5.3526, tea_CELoss: 2.4290 stu_CELoss: 2.5022 DMLLoss: 0.4214 
2022-03-14 02:45:45 - train: epoch 0018, iter [03800, 05004], lr: 0.100000, loss: 5.3110, tea_CELoss: 2.3402 stu_CELoss: 2.6003 DMLLoss: 0.3706 
2022-03-14 02:46:18 - train: epoch 0018, iter [03900, 05004], lr: 0.100000, loss: 5.2173, tea_CELoss: 2.3657 stu_CELoss: 2.4732 DMLLoss: 0.3785 
2022-03-14 02:46:52 - train: epoch 0018, iter [04000, 05004], lr: 0.100000, loss: 5.4234, tea_CELoss: 2.4503 stu_CELoss: 2.5869 DMLLoss: 0.3862 
2022-03-14 02:47:24 - train: epoch 0018, iter [04100, 05004], lr: 0.100000, loss: 5.4213, tea_CELoss: 2.4132 stu_CELoss: 2.6328 DMLLoss: 0.3752 
2022-03-14 02:47:58 - train: epoch 0018, iter [04200, 05004], lr: 0.100000, loss: 4.9709, tea_CELoss: 2.2454 stu_CELoss: 2.3611 DMLLoss: 0.3644 
2022-03-14 02:48:30 - train: epoch 0018, iter [04300, 05004], lr: 0.100000, loss: 5.1194, tea_CELoss: 2.3505 stu_CELoss: 2.4189 DMLLoss: 0.3499 
2022-03-14 02:49:03 - train: epoch 0018, iter [04400, 05004], lr: 0.100000, loss: 4.8733, tea_CELoss: 2.1734 stu_CELoss: 2.2854 DMLLoss: 0.4145 
2022-03-14 02:49:36 - train: epoch 0018, iter [04500, 05004], lr: 0.100000, loss: 5.4391, tea_CELoss: 2.4592 stu_CELoss: 2.5266 DMLLoss: 0.4533 
2022-03-14 02:50:10 - train: epoch 0018, iter [04600, 05004], lr: 0.100000, loss: 5.0737, tea_CELoss: 2.2787 stu_CELoss: 2.3660 DMLLoss: 0.4291 
2022-03-14 02:50:43 - train: epoch 0018, iter [04700, 05004], lr: 0.100000, loss: 5.1839, tea_CELoss: 2.3090 stu_CELoss: 2.4908 DMLLoss: 0.3841 
2022-03-14 02:51:16 - train: epoch 0018, iter [04800, 05004], lr: 0.100000, loss: 5.0012, tea_CELoss: 2.2792 stu_CELoss: 2.3212 DMLLoss: 0.4009 
2022-03-14 02:51:49 - train: epoch 0018, iter [04900, 05004], lr: 0.100000, loss: 4.9145, tea_CELoss: 2.1774 stu_CELoss: 2.3349 DMLLoss: 0.4023 
2022-03-14 02:52:21 - train: epoch 0018, iter [05000, 05004], lr: 0.100000, loss: 5.1279, tea_CELoss: 2.3080 stu_CELoss: 2.4382 DMLLoss: 0.3816 
2022-03-14 02:52:22 - train: epoch 018, train_loss: 4.9937
2022-03-14 02:54:50 - eval: epoch: 018, tea_acc1: 53.490%, tea_acc5: 79.162%, tea_test_loss: 1.9664, stu_acc1: 50.594%, stu_acc5: 76.442%, stu_test_loss: 2.1327
2022-03-14 02:54:51 - until epoch: 018, tea_best_acc1: 54.616%, stu_best_acc1: 51.234%
2022-03-14 02:54:51 - epoch 019 lr: 0.1
2022-03-14 02:55:30 - train: epoch 0019, iter [00100, 05004], lr: 0.100000, loss: 4.4973, tea_CELoss: 1.9866 stu_CELoss: 2.1480 DMLLoss: 0.3627 
2022-03-14 02:56:03 - train: epoch 0019, iter [00200, 05004], lr: 0.100000, loss: 4.8766, tea_CELoss: 2.1585 stu_CELoss: 2.3242 DMLLoss: 0.3939 
2022-03-14 02:56:36 - train: epoch 0019, iter [00300, 05004], lr: 0.100000, loss: 5.2705, tea_CELoss: 2.4053 stu_CELoss: 2.4829 DMLLoss: 0.3824 
2022-03-14 02:57:08 - train: epoch 0019, iter [00400, 05004], lr: 0.100000, loss: 5.2069, tea_CELoss: 2.3563 stu_CELoss: 2.4393 DMLLoss: 0.4114 
2022-03-14 02:57:42 - train: epoch 0019, iter [00500, 05004], lr: 0.100000, loss: 4.5594, tea_CELoss: 2.0295 stu_CELoss: 2.1565 DMLLoss: 0.3734 
2022-03-14 02:58:15 - train: epoch 0019, iter [00600, 05004], lr: 0.100000, loss: 5.0616, tea_CELoss: 2.2232 stu_CELoss: 2.4348 DMLLoss: 0.4036 
2022-03-14 02:58:47 - train: epoch 0019, iter [00700, 05004], lr: 0.100000, loss: 4.8545, tea_CELoss: 2.1068 stu_CELoss: 2.3512 DMLLoss: 0.3965 
2022-03-14 02:59:21 - train: epoch 0019, iter [00800, 05004], lr: 0.100000, loss: 5.0863, tea_CELoss: 2.2429 stu_CELoss: 2.4363 DMLLoss: 0.4071 
2022-03-14 02:59:54 - train: epoch 0019, iter [00900, 05004], lr: 0.100000, loss: 4.8389, tea_CELoss: 2.1552 stu_CELoss: 2.2773 DMLLoss: 0.4064 
2022-03-14 03:00:27 - train: epoch 0019, iter [01000, 05004], lr: 0.100000, loss: 5.4304, tea_CELoss: 2.4204 stu_CELoss: 2.6065 DMLLoss: 0.4036 
2022-03-14 03:01:00 - train: epoch 0019, iter [01100, 05004], lr: 0.100000, loss: 4.8995, tea_CELoss: 2.2013 stu_CELoss: 2.2944 DMLLoss: 0.4038 
2022-03-14 03:01:34 - train: epoch 0019, iter [01200, 05004], lr: 0.100000, loss: 4.9567, tea_CELoss: 2.2236 stu_CELoss: 2.3457 DMLLoss: 0.3874 
2022-03-14 03:02:07 - train: epoch 0019, iter [01300, 05004], lr: 0.100000, loss: 5.1076, tea_CELoss: 2.3107 stu_CELoss: 2.3804 DMLLoss: 0.4165 
2022-03-14 03:02:41 - train: epoch 0019, iter [01400, 05004], lr: 0.100000, loss: 4.5142, tea_CELoss: 1.9839 stu_CELoss: 2.1423 DMLLoss: 0.3880 
2022-03-14 03:03:13 - train: epoch 0019, iter [01500, 05004], lr: 0.100000, loss: 5.5010, tea_CELoss: 2.3930 stu_CELoss: 2.6573 DMLLoss: 0.4507 
2022-03-14 03:03:46 - train: epoch 0019, iter [01600, 05004], lr: 0.100000, loss: 4.4842, tea_CELoss: 2.0261 stu_CELoss: 2.0727 DMLLoss: 0.3854 
2022-03-14 03:04:20 - train: epoch 0019, iter [01700, 05004], lr: 0.100000, loss: 5.2363, tea_CELoss: 2.3635 stu_CELoss: 2.4924 DMLLoss: 0.3804 
2022-03-14 03:04:53 - train: epoch 0019, iter [01800, 05004], lr: 0.100000, loss: 4.8074, tea_CELoss: 2.1191 stu_CELoss: 2.2737 DMLLoss: 0.4146 
2022-03-14 03:05:26 - train: epoch 0019, iter [01900, 05004], lr: 0.100000, loss: 5.1684, tea_CELoss: 2.3317 stu_CELoss: 2.4868 DMLLoss: 0.3500 
2022-03-14 03:05:59 - train: epoch 0019, iter [02000, 05004], lr: 0.100000, loss: 5.0244, tea_CELoss: 2.2089 stu_CELoss: 2.4376 DMLLoss: 0.3780 
2022-03-14 03:06:32 - train: epoch 0019, iter [02100, 05004], lr: 0.100000, loss: 5.0311, tea_CELoss: 2.2465 stu_CELoss: 2.3943 DMLLoss: 0.3902 
2022-03-14 03:07:05 - train: epoch 0019, iter [02200, 05004], lr: 0.100000, loss: 5.2354, tea_CELoss: 2.3087 stu_CELoss: 2.5050 DMLLoss: 0.4218 
2022-03-14 03:07:38 - train: epoch 0019, iter [02300, 05004], lr: 0.100000, loss: 5.1298, tea_CELoss: 2.3270 stu_CELoss: 2.4015 DMLLoss: 0.4013 
2022-03-14 03:08:12 - train: epoch 0019, iter [02400, 05004], lr: 0.100000, loss: 5.3844, tea_CELoss: 2.4114 stu_CELoss: 2.5652 DMLLoss: 0.4077 
2022-03-14 03:08:45 - train: epoch 0019, iter [02500, 05004], lr: 0.100000, loss: 5.1197, tea_CELoss: 2.3254 stu_CELoss: 2.4370 DMLLoss: 0.3573 
2022-03-14 03:09:19 - train: epoch 0019, iter [02600, 05004], lr: 0.100000, loss: 4.7184, tea_CELoss: 2.0906 stu_CELoss: 2.2610 DMLLoss: 0.3668 
2022-03-14 03:09:52 - train: epoch 0019, iter [02700, 05004], lr: 0.100000, loss: 5.0614, tea_CELoss: 2.2475 stu_CELoss: 2.4044 DMLLoss: 0.4095 
2022-03-14 03:10:25 - train: epoch 0019, iter [02800, 05004], lr: 0.100000, loss: 4.8311, tea_CELoss: 2.1596 stu_CELoss: 2.2724 DMLLoss: 0.3991 
2022-03-14 03:10:58 - train: epoch 0019, iter [02900, 05004], lr: 0.100000, loss: 5.3805, tea_CELoss: 2.3860 stu_CELoss: 2.5636 DMLLoss: 0.4310 
2022-03-14 03:11:31 - train: epoch 0019, iter [03000, 05004], lr: 0.100000, loss: 5.4446, tea_CELoss: 2.4424 stu_CELoss: 2.5992 DMLLoss: 0.4029 
2022-03-14 03:12:04 - train: epoch 0019, iter [03100, 05004], lr: 0.100000, loss: 4.9264, tea_CELoss: 2.1783 stu_CELoss: 2.3438 DMLLoss: 0.4042 
2022-03-14 03:12:37 - train: epoch 0019, iter [03200, 05004], lr: 0.100000, loss: 4.6759, tea_CELoss: 2.0880 stu_CELoss: 2.2141 DMLLoss: 0.3738 
2022-03-14 03:13:11 - train: epoch 0019, iter [03300, 05004], lr: 0.100000, loss: 4.8674, tea_CELoss: 2.2116 stu_CELoss: 2.2860 DMLLoss: 0.3698 
2022-03-14 03:13:43 - train: epoch 0019, iter [03400, 05004], lr: 0.100000, loss: 5.0766, tea_CELoss: 2.1937 stu_CELoss: 2.4630 DMLLoss: 0.4199 
2022-03-14 03:14:17 - train: epoch 0019, iter [03500, 05004], lr: 0.100000, loss: 5.5548, tea_CELoss: 2.5118 stu_CELoss: 2.5994 DMLLoss: 0.4436 
2022-03-14 03:14:50 - train: epoch 0019, iter [03600, 05004], lr: 0.100000, loss: 4.5944, tea_CELoss: 1.9931 stu_CELoss: 2.2029 DMLLoss: 0.3983 
2022-03-14 03:15:23 - train: epoch 0019, iter [03700, 05004], lr: 0.100000, loss: 5.0501, tea_CELoss: 2.2682 stu_CELoss: 2.3933 DMLLoss: 0.3886 
2022-03-14 03:15:56 - train: epoch 0019, iter [03800, 05004], lr: 0.100000, loss: 5.1606, tea_CELoss: 2.3218 stu_CELoss: 2.4675 DMLLoss: 0.3713 
2022-03-14 03:16:29 - train: epoch 0019, iter [03900, 05004], lr: 0.100000, loss: 4.8940, tea_CELoss: 2.2135 stu_CELoss: 2.3112 DMLLoss: 0.3693 
2022-03-14 03:17:03 - train: epoch 0019, iter [04000, 05004], lr: 0.100000, loss: 4.8083, tea_CELoss: 2.1653 stu_CELoss: 2.2860 DMLLoss: 0.3570 
2022-03-14 03:17:36 - train: epoch 0019, iter [04100, 05004], lr: 0.100000, loss: 5.3153, tea_CELoss: 2.3508 stu_CELoss: 2.5751 DMLLoss: 0.3894 
2022-03-14 03:18:09 - train: epoch 0019, iter [04200, 05004], lr: 0.100000, loss: 4.8797, tea_CELoss: 2.2140 stu_CELoss: 2.3049 DMLLoss: 0.3607 
2022-03-14 03:18:42 - train: epoch 0019, iter [04300, 05004], lr: 0.100000, loss: 5.0462, tea_CELoss: 2.2210 stu_CELoss: 2.4171 DMLLoss: 0.4081 
2022-03-14 03:19:15 - train: epoch 0019, iter [04400, 05004], lr: 0.100000, loss: 5.4132, tea_CELoss: 2.4280 stu_CELoss: 2.5644 DMLLoss: 0.4209 
2022-03-14 03:19:48 - train: epoch 0019, iter [04500, 05004], lr: 0.100000, loss: 5.5239, tea_CELoss: 2.5078 stu_CELoss: 2.5955 DMLLoss: 0.4206 
2022-03-14 03:20:21 - train: epoch 0019, iter [04600, 05004], lr: 0.100000, loss: 4.6780, tea_CELoss: 2.1317 stu_CELoss: 2.1869 DMLLoss: 0.3594 
2022-03-14 03:20:55 - train: epoch 0019, iter [04700, 05004], lr: 0.100000, loss: 4.9039, tea_CELoss: 2.1634 stu_CELoss: 2.3455 DMLLoss: 0.3950 
2022-03-14 03:21:28 - train: epoch 0019, iter [04800, 05004], lr: 0.100000, loss: 5.0001, tea_CELoss: 2.2659 stu_CELoss: 2.3842 DMLLoss: 0.3500 
2022-03-14 03:22:01 - train: epoch 0019, iter [04900, 05004], lr: 0.100000, loss: 4.8745, tea_CELoss: 2.1542 stu_CELoss: 2.3283 DMLLoss: 0.3920 
2022-03-14 03:22:33 - train: epoch 0019, iter [05000, 05004], lr: 0.100000, loss: 4.8342, tea_CELoss: 2.1749 stu_CELoss: 2.2737 DMLLoss: 0.3856 
2022-03-14 03:22:34 - train: epoch 019, train_loss: 4.9886
2022-03-14 03:25:01 - eval: epoch: 019, tea_acc1: 52.932%, tea_acc5: 78.332%, tea_test_loss: 2.0140, stu_acc1: 51.818%, stu_acc5: 77.296%, stu_test_loss: 2.0703
2022-03-14 03:25:02 - until epoch: 019, tea_best_acc1: 54.616%, stu_best_acc1: 51.818%
2022-03-14 03:25:02 - epoch 020 lr: 0.1
2022-03-14 03:25:40 - train: epoch 0020, iter [00100, 05004], lr: 0.100000, loss: 5.0109, tea_CELoss: 2.2578 stu_CELoss: 2.3726 DMLLoss: 0.3805 
2022-03-14 03:26:14 - train: epoch 0020, iter [00200, 05004], lr: 0.100000, loss: 4.4760, tea_CELoss: 1.9439 stu_CELoss: 2.1615 DMLLoss: 0.3705 
2022-03-14 03:26:47 - train: epoch 0020, iter [00300, 05004], lr: 0.100000, loss: 4.7603, tea_CELoss: 2.1441 stu_CELoss: 2.2219 DMLLoss: 0.3943 
2022-03-14 03:27:21 - train: epoch 0020, iter [00400, 05004], lr: 0.100000, loss: 4.6380, tea_CELoss: 2.0770 stu_CELoss: 2.1899 DMLLoss: 0.3710 
2022-03-14 03:27:53 - train: epoch 0020, iter [00500, 05004], lr: 0.100000, loss: 4.8712, tea_CELoss: 2.1711 stu_CELoss: 2.3223 DMLLoss: 0.3778 
2022-03-14 03:28:27 - train: epoch 0020, iter [00600, 05004], lr: 0.100000, loss: 5.0303, tea_CELoss: 2.2461 stu_CELoss: 2.3758 DMLLoss: 0.4084 
2022-03-14 03:29:00 - train: epoch 0020, iter [00700, 05004], lr: 0.100000, loss: 4.5136, tea_CELoss: 1.9664 stu_CELoss: 2.1480 DMLLoss: 0.3992 
2022-03-14 03:29:34 - train: epoch 0020, iter [00800, 05004], lr: 0.100000, loss: 5.2778, tea_CELoss: 2.3632 stu_CELoss: 2.5305 DMLLoss: 0.3842 
2022-03-14 03:30:06 - train: epoch 0020, iter [00900, 05004], lr: 0.100000, loss: 5.2592, tea_CELoss: 2.3728 stu_CELoss: 2.5184 DMLLoss: 0.3680 
2022-03-14 03:30:40 - train: epoch 0020, iter [01000, 05004], lr: 0.100000, loss: 5.0405, tea_CELoss: 2.3034 stu_CELoss: 2.3465 DMLLoss: 0.3905 
2022-03-14 03:31:13 - train: epoch 0020, iter [01100, 05004], lr: 0.100000, loss: 4.8344, tea_CELoss: 2.1888 stu_CELoss: 2.2181 DMLLoss: 0.4276 
2022-03-14 03:31:46 - train: epoch 0020, iter [01200, 05004], lr: 0.100000, loss: 4.6836, tea_CELoss: 2.0481 stu_CELoss: 2.2051 DMLLoss: 0.4304 
2022-03-14 03:32:19 - train: epoch 0020, iter [01300, 05004], lr: 0.100000, loss: 4.9918, tea_CELoss: 2.2721 stu_CELoss: 2.3351 DMLLoss: 0.3846 
2022-03-14 03:32:53 - train: epoch 0020, iter [01400, 05004], lr: 0.100000, loss: 4.9905, tea_CELoss: 2.2050 stu_CELoss: 2.3903 DMLLoss: 0.3951 
2022-03-14 03:33:26 - train: epoch 0020, iter [01500, 05004], lr: 0.100000, loss: 4.7889, tea_CELoss: 2.1009 stu_CELoss: 2.3166 DMLLoss: 0.3714 
2022-03-14 03:33:59 - train: epoch 0020, iter [01600, 05004], lr: 0.100000, loss: 5.1032, tea_CELoss: 2.3081 stu_CELoss: 2.4205 DMLLoss: 0.3746 
2022-03-14 03:34:32 - train: epoch 0020, iter [01700, 05004], lr: 0.100000, loss: 4.8311, tea_CELoss: 2.1811 stu_CELoss: 2.2404 DMLLoss: 0.4096 
2022-03-14 03:35:06 - train: epoch 0020, iter [01800, 05004], lr: 0.100000, loss: 5.0762, tea_CELoss: 2.2565 stu_CELoss: 2.4378 DMLLoss: 0.3819 
2022-03-14 03:35:39 - train: epoch 0020, iter [01900, 05004], lr: 0.100000, loss: 4.8807, tea_CELoss: 2.1341 stu_CELoss: 2.3399 DMLLoss: 0.4067 
2022-03-14 03:36:12 - train: epoch 0020, iter [02000, 05004], lr: 0.100000, loss: 4.8011, tea_CELoss: 2.0912 stu_CELoss: 2.3153 DMLLoss: 0.3946 
2022-03-14 03:36:46 - train: epoch 0020, iter [02100, 05004], lr: 0.100000, loss: 5.4261, tea_CELoss: 2.4320 stu_CELoss: 2.5893 DMLLoss: 0.4048 
2022-03-14 03:37:19 - train: epoch 0020, iter [02200, 05004], lr: 0.100000, loss: 4.5301, tea_CELoss: 2.0152 stu_CELoss: 2.1560 DMLLoss: 0.3589 
2022-03-14 03:37:52 - train: epoch 0020, iter [02300, 05004], lr: 0.100000, loss: 4.8465, tea_CELoss: 2.1309 stu_CELoss: 2.3009 DMLLoss: 0.4147 
2022-03-14 03:38:25 - train: epoch 0020, iter [02400, 05004], lr: 0.100000, loss: 5.3403, tea_CELoss: 2.4104 stu_CELoss: 2.5286 DMLLoss: 0.4013 
2022-03-14 03:38:58 - train: epoch 0020, iter [02500, 05004], lr: 0.100000, loss: 4.9483, tea_CELoss: 2.1872 stu_CELoss: 2.3571 DMLLoss: 0.4040 
2022-03-14 03:39:32 - train: epoch 0020, iter [02600, 05004], lr: 0.100000, loss: 4.9066, tea_CELoss: 2.1619 stu_CELoss: 2.3460 DMLLoss: 0.3987 
2022-03-14 03:40:05 - train: epoch 0020, iter [02700, 05004], lr: 0.100000, loss: 4.8333, tea_CELoss: 2.1097 stu_CELoss: 2.3462 DMLLoss: 0.3775 
2022-03-14 03:40:38 - train: epoch 0020, iter [02800, 05004], lr: 0.100000, loss: 5.2474, tea_CELoss: 2.3196 stu_CELoss: 2.5074 DMLLoss: 0.4204 
2022-03-14 03:41:11 - train: epoch 0020, iter [02900, 05004], lr: 0.100000, loss: 5.1783, tea_CELoss: 2.3164 stu_CELoss: 2.4515 DMLLoss: 0.4104 
2022-03-14 03:41:44 - train: epoch 0020, iter [03000, 05004], lr: 0.100000, loss: 5.2416, tea_CELoss: 2.3409 stu_CELoss: 2.4949 DMLLoss: 0.4058 
2022-03-14 03:42:17 - train: epoch 0020, iter [03100, 05004], lr: 0.100000, loss: 5.2046, tea_CELoss: 2.2773 stu_CELoss: 2.5031 DMLLoss: 0.4242 
2022-03-14 03:42:51 - train: epoch 0020, iter [03200, 05004], lr: 0.100000, loss: 4.9168, tea_CELoss: 2.1987 stu_CELoss: 2.3343 DMLLoss: 0.3837 
2022-03-14 03:43:24 - train: epoch 0020, iter [03300, 05004], lr: 0.100000, loss: 4.6898, tea_CELoss: 2.0466 stu_CELoss: 2.2411 DMLLoss: 0.4021 
2022-03-14 03:43:57 - train: epoch 0020, iter [03400, 05004], lr: 0.100000, loss: 4.9820, tea_CELoss: 2.2328 stu_CELoss: 2.3569 DMLLoss: 0.3923 
2022-03-14 03:44:30 - train: epoch 0020, iter [03500, 05004], lr: 0.100000, loss: 4.5191, tea_CELoss: 2.0110 stu_CELoss: 2.1382 DMLLoss: 0.3699 
2022-03-14 03:45:03 - train: epoch 0020, iter [03600, 05004], lr: 0.100000, loss: 4.9974, tea_CELoss: 2.2253 stu_CELoss: 2.3884 DMLLoss: 0.3837 
2022-03-14 03:45:37 - train: epoch 0020, iter [03700, 05004], lr: 0.100000, loss: 4.8852, tea_CELoss: 2.1725 stu_CELoss: 2.3300 DMLLoss: 0.3827 
2022-03-14 03:46:10 - train: epoch 0020, iter [03800, 05004], lr: 0.100000, loss: 4.9558, tea_CELoss: 2.1904 stu_CELoss: 2.3420 DMLLoss: 0.4233 
2022-03-14 03:46:43 - train: epoch 0020, iter [03900, 05004], lr: 0.100000, loss: 5.1149, tea_CELoss: 2.2786 stu_CELoss: 2.4202 DMLLoss: 0.4160 
2022-03-14 03:47:16 - train: epoch 0020, iter [04000, 05004], lr: 0.100000, loss: 5.0804, tea_CELoss: 2.2914 stu_CELoss: 2.3693 DMLLoss: 0.4198 
2022-03-14 03:47:49 - train: epoch 0020, iter [04100, 05004], lr: 0.100000, loss: 5.0933, tea_CELoss: 2.2645 stu_CELoss: 2.3967 DMLLoss: 0.4321 
2022-03-14 03:48:22 - train: epoch 0020, iter [04200, 05004], lr: 0.100000, loss: 4.9664, tea_CELoss: 2.2182 stu_CELoss: 2.3715 DMLLoss: 0.3767 
2022-03-14 03:48:55 - train: epoch 0020, iter [04300, 05004], lr: 0.100000, loss: 5.3596, tea_CELoss: 2.4133 stu_CELoss: 2.5358 DMLLoss: 0.4105 
2022-03-14 03:49:29 - train: epoch 0020, iter [04400, 05004], lr: 0.100000, loss: 5.0517, tea_CELoss: 2.1867 stu_CELoss: 2.4617 DMLLoss: 0.4034 
2022-03-14 03:50:02 - train: epoch 0020, iter [04500, 05004], lr: 0.100000, loss: 5.0846, tea_CELoss: 2.3349 stu_CELoss: 2.3615 DMLLoss: 0.3881 
2022-03-14 03:50:35 - train: epoch 0020, iter [04600, 05004], lr: 0.100000, loss: 5.0836, tea_CELoss: 2.2907 stu_CELoss: 2.3810 DMLLoss: 0.4119 
2022-03-14 03:51:08 - train: epoch 0020, iter [04700, 05004], lr: 0.100000, loss: 4.8665, tea_CELoss: 2.1505 stu_CELoss: 2.3251 DMLLoss: 0.3909 
2022-03-14 03:51:41 - train: epoch 0020, iter [04800, 05004], lr: 0.100000, loss: 4.7386, tea_CELoss: 2.1234 stu_CELoss: 2.2606 DMLLoss: 0.3546 
2022-03-14 03:52:14 - train: epoch 0020, iter [04900, 05004], lr: 0.100000, loss: 5.0061, tea_CELoss: 2.2813 stu_CELoss: 2.3419 DMLLoss: 0.3829 
2022-03-14 03:52:46 - train: epoch 0020, iter [05000, 05004], lr: 0.100000, loss: 4.8043, tea_CELoss: 2.1590 stu_CELoss: 2.2720 DMLLoss: 0.3734 
2022-03-14 03:52:47 - train: epoch 020, train_loss: 4.9784
2022-03-14 03:55:15 - eval: epoch: 020, tea_acc1: 54.708%, tea_acc5: 79.676%, tea_test_loss: 1.9170, stu_acc1: 51.892%, stu_acc5: 77.390%, stu_test_loss: 2.0600
2022-03-14 03:55:16 - until epoch: 020, tea_best_acc1: 54.708%, stu_best_acc1: 51.892%
2022-03-14 03:55:16 - epoch 021 lr: 0.1
2022-03-14 03:55:54 - train: epoch 0021, iter [00100, 05004], lr: 0.100000, loss: 4.9278, tea_CELoss: 2.1416 stu_CELoss: 2.3799 DMLLoss: 0.4064 
2022-03-14 03:56:28 - train: epoch 0021, iter [00200, 05004], lr: 0.100000, loss: 5.0443, tea_CELoss: 2.2012 stu_CELoss: 2.4132 DMLLoss: 0.4300 
2022-03-14 03:57:00 - train: epoch 0021, iter [00300, 05004], lr: 0.100000, loss: 4.4187, tea_CELoss: 1.9595 stu_CELoss: 2.0758 DMLLoss: 0.3834 
2022-03-14 03:57:33 - train: epoch 0021, iter [00400, 05004], lr: 0.100000, loss: 4.7807, tea_CELoss: 2.2090 stu_CELoss: 2.2058 DMLLoss: 0.3659 
2022-03-14 03:58:06 - train: epoch 0021, iter [00500, 05004], lr: 0.100000, loss: 4.2876, tea_CELoss: 1.9307 stu_CELoss: 1.9915 DMLLoss: 0.3654 
2022-03-14 03:58:40 - train: epoch 0021, iter [00600, 05004], lr: 0.100000, loss: 4.6868, tea_CELoss: 2.1018 stu_CELoss: 2.2011 DMLLoss: 0.3839 
2022-03-14 03:59:13 - train: epoch 0021, iter [00700, 05004], lr: 0.100000, loss: 4.4851, tea_CELoss: 1.9876 stu_CELoss: 2.1314 DMLLoss: 0.3661 
2022-03-14 03:59:46 - train: epoch 0021, iter [00800, 05004], lr: 0.100000, loss: 4.9907, tea_CELoss: 2.2469 stu_CELoss: 2.3487 DMLLoss: 0.3951 
2022-03-14 04:00:19 - train: epoch 0021, iter [00900, 05004], lr: 0.100000, loss: 4.8025, tea_CELoss: 2.1741 stu_CELoss: 2.2568 DMLLoss: 0.3717 
2022-03-14 04:00:52 - train: epoch 0021, iter [01000, 05004], lr: 0.100000, loss: 4.6951, tea_CELoss: 2.1317 stu_CELoss: 2.1784 DMLLoss: 0.3851 
2022-03-14 04:01:25 - train: epoch 0021, iter [01100, 05004], lr: 0.100000, loss: 4.9829, tea_CELoss: 2.2352 stu_CELoss: 2.3877 DMLLoss: 0.3600 
2022-03-14 04:01:59 - train: epoch 0021, iter [01200, 05004], lr: 0.100000, loss: 4.8740, tea_CELoss: 2.1756 stu_CELoss: 2.2979 DMLLoss: 0.4006 
2022-03-14 04:02:32 - train: epoch 0021, iter [01300, 05004], lr: 0.100000, loss: 4.5418, tea_CELoss: 2.0326 stu_CELoss: 2.1530 DMLLoss: 0.3562 
2022-03-14 04:03:05 - train: epoch 0021, iter [01400, 05004], lr: 0.100000, loss: 4.3653, tea_CELoss: 1.9398 stu_CELoss: 2.0464 DMLLoss: 0.3791 
2022-03-14 04:03:38 - train: epoch 0021, iter [01500, 05004], lr: 0.100000, loss: 4.9673, tea_CELoss: 2.1996 stu_CELoss: 2.3591 DMLLoss: 0.4086 
2022-03-14 04:04:11 - train: epoch 0021, iter [01600, 05004], lr: 0.100000, loss: 4.9310, tea_CELoss: 2.1858 stu_CELoss: 2.3094 DMLLoss: 0.4358 
2022-03-14 04:04:45 - train: epoch 0021, iter [01700, 05004], lr: 0.100000, loss: 5.1335, tea_CELoss: 2.3732 stu_CELoss: 2.4033 DMLLoss: 0.3570 
2022-03-14 04:05:18 - train: epoch 0021, iter [01800, 05004], lr: 0.100000, loss: 5.0457, tea_CELoss: 2.1981 stu_CELoss: 2.4395 DMLLoss: 0.4081 
2022-03-14 04:05:51 - train: epoch 0021, iter [01900, 05004], lr: 0.100000, loss: 5.2203, tea_CELoss: 2.3522 stu_CELoss: 2.4432 DMLLoss: 0.4250 
2022-03-14 04:06:24 - train: epoch 0021, iter [02000, 05004], lr: 0.100000, loss: 5.1535, tea_CELoss: 2.3045 stu_CELoss: 2.4575 DMLLoss: 0.3915 
2022-03-14 04:06:57 - train: epoch 0021, iter [02100, 05004], lr: 0.100000, loss: 4.3800, tea_CELoss: 1.9822 stu_CELoss: 2.0300 DMLLoss: 0.3679 
2022-03-14 04:07:30 - train: epoch 0021, iter [02200, 05004], lr: 0.100000, loss: 5.1364, tea_CELoss: 2.2945 stu_CELoss: 2.4488 DMLLoss: 0.3930 
2022-03-14 04:08:04 - train: epoch 0021, iter [02300, 05004], lr: 0.100000, loss: 5.4421, tea_CELoss: 2.3682 stu_CELoss: 2.6384 DMLLoss: 0.4355 
2022-03-14 04:08:36 - train: epoch 0021, iter [02400, 05004], lr: 0.100000, loss: 4.6151, tea_CELoss: 2.0239 stu_CELoss: 2.2232 DMLLoss: 0.3680 
2022-03-14 04:09:10 - train: epoch 0021, iter [02500, 05004], lr: 0.100000, loss: 4.8632, tea_CELoss: 2.2178 stu_CELoss: 2.2545 DMLLoss: 0.3909 
2022-03-14 04:09:43 - train: epoch 0021, iter [02600, 05004], lr: 0.100000, loss: 5.0871, tea_CELoss: 2.3050 stu_CELoss: 2.4139 DMLLoss: 0.3682 
2022-03-14 04:10:17 - train: epoch 0021, iter [02700, 05004], lr: 0.100000, loss: 4.6523, tea_CELoss: 2.0184 stu_CELoss: 2.2292 DMLLoss: 0.4047 
2022-03-14 04:10:49 - train: epoch 0021, iter [02800, 05004], lr: 0.100000, loss: 4.9468, tea_CELoss: 2.2116 stu_CELoss: 2.3428 DMLLoss: 0.3925 
2022-03-14 04:11:22 - train: epoch 0021, iter [02900, 05004], lr: 0.100000, loss: 4.8273, tea_CELoss: 2.1423 stu_CELoss: 2.3000 DMLLoss: 0.3851 
2022-03-14 04:11:55 - train: epoch 0021, iter [03000, 05004], lr: 0.100000, loss: 5.4074, tea_CELoss: 2.3527 stu_CELoss: 2.6216 DMLLoss: 0.4331 
2022-03-14 04:12:29 - train: epoch 0021, iter [03100, 05004], lr: 0.100000, loss: 5.2567, tea_CELoss: 2.3835 stu_CELoss: 2.4520 DMLLoss: 0.4211 
2022-03-14 04:13:02 - train: epoch 0021, iter [03200, 05004], lr: 0.100000, loss: 4.6517, tea_CELoss: 2.0141 stu_CELoss: 2.2463 DMLLoss: 0.3913 
2022-03-14 04:13:35 - train: epoch 0021, iter [03300, 05004], lr: 0.100000, loss: 5.5176, tea_CELoss: 2.4563 stu_CELoss: 2.6728 DMLLoss: 0.3885 
2022-03-14 04:14:07 - train: epoch 0021, iter [03400, 05004], lr: 0.100000, loss: 5.3417, tea_CELoss: 2.4291 stu_CELoss: 2.5343 DMLLoss: 0.3783 
2022-03-14 04:14:41 - train: epoch 0021, iter [03500, 05004], lr: 0.100000, loss: 5.1432, tea_CELoss: 2.3608 stu_CELoss: 2.3784 DMLLoss: 0.4040 
2022-03-14 04:15:14 - train: epoch 0021, iter [03600, 05004], lr: 0.100000, loss: 5.3155, tea_CELoss: 2.3731 stu_CELoss: 2.5354 DMLLoss: 0.4071 
2022-03-14 04:15:47 - train: epoch 0021, iter [03700, 05004], lr: 0.100000, loss: 4.9782, tea_CELoss: 2.2455 stu_CELoss: 2.3426 DMLLoss: 0.3900 
2022-03-14 04:16:21 - train: epoch 0021, iter [03800, 05004], lr: 0.100000, loss: 4.9054, tea_CELoss: 2.2154 stu_CELoss: 2.2977 DMLLoss: 0.3923 
2022-03-14 04:16:54 - train: epoch 0021, iter [03900, 05004], lr: 0.100000, loss: 4.7705, tea_CELoss: 2.1600 stu_CELoss: 2.2241 DMLLoss: 0.3865 
2022-03-14 04:17:27 - train: epoch 0021, iter [04000, 05004], lr: 0.100000, loss: 5.3697, tea_CELoss: 2.3784 stu_CELoss: 2.5587 DMLLoss: 0.4326 
2022-03-14 04:18:01 - train: epoch 0021, iter [04100, 05004], lr: 0.100000, loss: 4.6433, tea_CELoss: 2.0632 stu_CELoss: 2.2086 DMLLoss: 0.3715 
2022-03-14 04:18:34 - train: epoch 0021, iter [04200, 05004], lr: 0.100000, loss: 5.1399, tea_CELoss: 2.3005 stu_CELoss: 2.4141 DMLLoss: 0.4253 
2022-03-14 04:19:06 - train: epoch 0021, iter [04300, 05004], lr: 0.100000, loss: 5.3418, tea_CELoss: 2.4542 stu_CELoss: 2.4951 DMLLoss: 0.3924 
2022-03-14 04:19:39 - train: epoch 0021, iter [04400, 05004], lr: 0.100000, loss: 5.1714, tea_CELoss: 2.2945 stu_CELoss: 2.4751 DMLLoss: 0.4018 
2022-03-14 04:20:12 - train: epoch 0021, iter [04500, 05004], lr: 0.100000, loss: 5.1027, tea_CELoss: 2.2856 stu_CELoss: 2.4058 DMLLoss: 0.4113 
2022-03-14 04:20:46 - train: epoch 0021, iter [04600, 05004], lr: 0.100000, loss: 4.9835, tea_CELoss: 2.2484 stu_CELoss: 2.3711 DMLLoss: 0.3640 
2022-03-14 04:21:19 - train: epoch 0021, iter [04700, 05004], lr: 0.100000, loss: 5.1673, tea_CELoss: 2.3400 stu_CELoss: 2.4587 DMLLoss: 0.3686 
2022-03-14 04:21:52 - train: epoch 0021, iter [04800, 05004], lr: 0.100000, loss: 5.1087, tea_CELoss: 2.2962 stu_CELoss: 2.4236 DMLLoss: 0.3888 
2022-03-14 04:22:25 - train: epoch 0021, iter [04900, 05004], lr: 0.100000, loss: 4.3618, tea_CELoss: 1.9456 stu_CELoss: 2.0560 DMLLoss: 0.3601 
2022-03-14 04:22:56 - train: epoch 0021, iter [05000, 05004], lr: 0.100000, loss: 4.9049, tea_CELoss: 2.2247 stu_CELoss: 2.3057 DMLLoss: 0.3745 
2022-03-14 04:22:57 - train: epoch 021, train_loss: 4.9768
2022-03-14 04:25:26 - eval: epoch: 021, tea_acc1: 54.220%, tea_acc5: 79.484%, tea_test_loss: 1.9311, stu_acc1: 50.606%, stu_acc5: 76.368%, stu_test_loss: 2.1295
2022-03-14 04:25:27 - until epoch: 021, tea_best_acc1: 54.708%, stu_best_acc1: 51.892%
2022-03-14 04:25:27 - epoch 022 lr: 0.1
2022-03-14 04:26:05 - train: epoch 0022, iter [00100, 05004], lr: 0.100000, loss: 4.3953, tea_CELoss: 1.9417 stu_CELoss: 2.0848 DMLLoss: 0.3689 
2022-03-14 04:26:38 - train: epoch 0022, iter [00200, 05004], lr: 0.100000, loss: 4.8563, tea_CELoss: 2.1358 stu_CELoss: 2.3347 DMLLoss: 0.3858 
2022-03-14 04:27:11 - train: epoch 0022, iter [00300, 05004], lr: 0.100000, loss: 4.8260, tea_CELoss: 2.1525 stu_CELoss: 2.2554 DMLLoss: 0.4181 
2022-03-14 04:27:44 - train: epoch 0022, iter [00400, 05004], lr: 0.100000, loss: 4.7259, tea_CELoss: 2.0983 stu_CELoss: 2.1956 DMLLoss: 0.4319 
2022-03-14 04:28:17 - train: epoch 0022, iter [00500, 05004], lr: 0.100000, loss: 4.7747, tea_CELoss: 2.1608 stu_CELoss: 2.2393 DMLLoss: 0.3746 
2022-03-14 04:28:50 - train: epoch 0022, iter [00600, 05004], lr: 0.100000, loss: 5.0291, tea_CELoss: 2.2576 stu_CELoss: 2.3788 DMLLoss: 0.3927 
2022-03-14 04:29:23 - train: epoch 0022, iter [00700, 05004], lr: 0.100000, loss: 5.3402, tea_CELoss: 2.3646 stu_CELoss: 2.5396 DMLLoss: 0.4361 
2022-03-14 04:29:56 - train: epoch 0022, iter [00800, 05004], lr: 0.100000, loss: 5.0315, tea_CELoss: 2.2614 stu_CELoss: 2.4127 DMLLoss: 0.3573 
2022-03-14 04:30:30 - train: epoch 0022, iter [00900, 05004], lr: 0.100000, loss: 5.1409, tea_CELoss: 2.3055 stu_CELoss: 2.4325 DMLLoss: 0.4029 
2022-03-14 04:31:03 - train: epoch 0022, iter [01000, 05004], lr: 0.100000, loss: 5.1475, tea_CELoss: 2.3557 stu_CELoss: 2.4128 DMLLoss: 0.3790 
2022-03-14 04:31:35 - train: epoch 0022, iter [01100, 05004], lr: 0.100000, loss: 4.5724, tea_CELoss: 2.0095 stu_CELoss: 2.2018 DMLLoss: 0.3610 
2022-03-14 04:32:09 - train: epoch 0022, iter [01200, 05004], lr: 0.100000, loss: 4.2782, tea_CELoss: 1.8982 stu_CELoss: 2.0092 DMLLoss: 0.3709 
2022-03-14 04:32:42 - train: epoch 0022, iter [01300, 05004], lr: 0.100000, loss: 5.2124, tea_CELoss: 2.3269 stu_CELoss: 2.4441 DMLLoss: 0.4415 
2022-03-14 04:33:16 - train: epoch 0022, iter [01400, 05004], lr: 0.100000, loss: 4.7580, tea_CELoss: 2.0844 stu_CELoss: 2.2551 DMLLoss: 0.4186 
2022-03-14 04:33:48 - train: epoch 0022, iter [01500, 05004], lr: 0.100000, loss: 5.1922, tea_CELoss: 2.3224 stu_CELoss: 2.4864 DMLLoss: 0.3834 
2022-03-14 04:34:22 - train: epoch 0022, iter [01600, 05004], lr: 0.100000, loss: 4.8544, tea_CELoss: 2.1851 stu_CELoss: 2.2907 DMLLoss: 0.3786 
2022-03-14 04:34:56 - train: epoch 0022, iter [01700, 05004], lr: 0.100000, loss: 5.1384, tea_CELoss: 2.3252 stu_CELoss: 2.4137 DMLLoss: 0.3994 
2022-03-14 04:35:29 - train: epoch 0022, iter [01800, 05004], lr: 0.100000, loss: 5.2285, tea_CELoss: 2.3417 stu_CELoss: 2.4908 DMLLoss: 0.3960 
2022-03-14 04:36:01 - train: epoch 0022, iter [01900, 05004], lr: 0.100000, loss: 5.0221, tea_CELoss: 2.1951 stu_CELoss: 2.4202 DMLLoss: 0.4068 
2022-03-14 04:36:35 - train: epoch 0022, iter [02000, 05004], lr: 0.100000, loss: 4.6065, tea_CELoss: 2.1026 stu_CELoss: 2.1408 DMLLoss: 0.3631 
2022-03-14 04:37:07 - train: epoch 0022, iter [02100, 05004], lr: 0.100000, loss: 4.7947, tea_CELoss: 2.1585 stu_CELoss: 2.2569 DMLLoss: 0.3794 
2022-03-14 04:37:40 - train: epoch 0022, iter [02200, 05004], lr: 0.100000, loss: 4.5021, tea_CELoss: 2.0033 stu_CELoss: 2.1347 DMLLoss: 0.3642 
2022-03-14 04:38:14 - train: epoch 0022, iter [02300, 05004], lr: 0.100000, loss: 5.1963, tea_CELoss: 2.3175 stu_CELoss: 2.4754 DMLLoss: 0.4034 
2022-03-14 04:38:47 - train: epoch 0022, iter [02400, 05004], lr: 0.100000, loss: 5.4144, tea_CELoss: 2.4647 stu_CELoss: 2.5948 DMLLoss: 0.3550 
2022-03-14 04:39:21 - train: epoch 0022, iter [02500, 05004], lr: 0.100000, loss: 4.9762, tea_CELoss: 2.2529 stu_CELoss: 2.3289 DMLLoss: 0.3944 
2022-03-14 04:39:54 - train: epoch 0022, iter [02600, 05004], lr: 0.100000, loss: 4.7044, tea_CELoss: 2.1192 stu_CELoss: 2.2128 DMLLoss: 0.3725 
2022-03-14 04:40:27 - train: epoch 0022, iter [02700, 05004], lr: 0.100000, loss: 4.7773, tea_CELoss: 2.1357 stu_CELoss: 2.2692 DMLLoss: 0.3724 
2022-03-14 04:41:00 - train: epoch 0022, iter [02800, 05004], lr: 0.100000, loss: 5.2729, tea_CELoss: 2.3636 stu_CELoss: 2.5161 DMLLoss: 0.3932 
2022-03-14 04:41:33 - train: epoch 0022, iter [02900, 05004], lr: 0.100000, loss: 4.8317, tea_CELoss: 2.1072 stu_CELoss: 2.3088 DMLLoss: 0.4156 
2022-03-14 04:42:06 - train: epoch 0022, iter [03000, 05004], lr: 0.100000, loss: 4.9601, tea_CELoss: 2.2159 stu_CELoss: 2.3563 DMLLoss: 0.3879 
2022-03-14 04:42:40 - train: epoch 0022, iter [03100, 05004], lr: 0.100000, loss: 5.2064, tea_CELoss: 2.3566 stu_CELoss: 2.4663 DMLLoss: 0.3834 
2022-03-14 04:43:13 - train: epoch 0022, iter [03200, 05004], lr: 0.100000, loss: 4.7711, tea_CELoss: 2.1319 stu_CELoss: 2.2893 DMLLoss: 0.3499 
2022-03-14 04:43:46 - train: epoch 0022, iter [03300, 05004], lr: 0.100000, loss: 4.9879, tea_CELoss: 2.2207 stu_CELoss: 2.3685 DMLLoss: 0.3987 
2022-03-14 04:44:20 - train: epoch 0022, iter [03400, 05004], lr: 0.100000, loss: 4.9249, tea_CELoss: 2.2001 stu_CELoss: 2.3238 DMLLoss: 0.4010 
2022-03-14 04:44:52 - train: epoch 0022, iter [03500, 05004], lr: 0.100000, loss: 4.9676, tea_CELoss: 2.2416 stu_CELoss: 2.3652 DMLLoss: 0.3608 
2022-03-14 04:45:26 - train: epoch 0022, iter [03600, 05004], lr: 0.100000, loss: 4.8668, tea_CELoss: 2.1704 stu_CELoss: 2.3142 DMLLoss: 0.3821 
2022-03-14 04:45:59 - train: epoch 0022, iter [03700, 05004], lr: 0.100000, loss: 5.1104, tea_CELoss: 2.2439 stu_CELoss: 2.4418 DMLLoss: 0.4247 
2022-03-14 04:46:32 - train: epoch 0022, iter [03800, 05004], lr: 0.100000, loss: 5.2612, tea_CELoss: 2.3360 stu_CELoss: 2.5113 DMLLoss: 0.4139 
2022-03-14 04:47:05 - train: epoch 0022, iter [03900, 05004], lr: 0.100000, loss: 5.2664, tea_CELoss: 2.3144 stu_CELoss: 2.5213 DMLLoss: 0.4307 
2022-03-14 04:47:38 - train: epoch 0022, iter [04000, 05004], lr: 0.100000, loss: 5.0420, tea_CELoss: 2.2583 stu_CELoss: 2.3821 DMLLoss: 0.4016 
2022-03-14 04:48:11 - train: epoch 0022, iter [04100, 05004], lr: 0.100000, loss: 4.9929, tea_CELoss: 2.3016 stu_CELoss: 2.3233 DMLLoss: 0.3680 
2022-03-14 04:48:45 - train: epoch 0022, iter [04200, 05004], lr: 0.100000, loss: 5.0555, tea_CELoss: 2.2443 stu_CELoss: 2.3985 DMLLoss: 0.4127 
2022-03-14 04:49:18 - train: epoch 0022, iter [04300, 05004], lr: 0.100000, loss: 4.9004, tea_CELoss: 2.1639 stu_CELoss: 2.3285 DMLLoss: 0.4080 
2022-03-14 04:49:51 - train: epoch 0022, iter [04400, 05004], lr: 0.100000, loss: 4.6881, tea_CELoss: 2.0660 stu_CELoss: 2.2356 DMLLoss: 0.3864 
2022-03-14 04:50:24 - train: epoch 0022, iter [04500, 05004], lr: 0.100000, loss: 4.8499, tea_CELoss: 2.2394 stu_CELoss: 2.2580 DMLLoss: 0.3525 
2022-03-14 04:50:57 - train: epoch 0022, iter [04600, 05004], lr: 0.100000, loss: 5.2563, tea_CELoss: 2.3866 stu_CELoss: 2.4904 DMLLoss: 0.3793 
2022-03-14 04:51:29 - train: epoch 0022, iter [04700, 05004], lr: 0.100000, loss: 5.1529, tea_CELoss: 2.2826 stu_CELoss: 2.4486 DMLLoss: 0.4217 
2022-03-14 04:52:03 - train: epoch 0022, iter [04800, 05004], lr: 0.100000, loss: 4.3189, tea_CELoss: 1.9543 stu_CELoss: 2.0080 DMLLoss: 0.3566 
2022-03-14 04:52:36 - train: epoch 0022, iter [04900, 05004], lr: 0.100000, loss: 5.0426, tea_CELoss: 2.2480 stu_CELoss: 2.4225 DMLLoss: 0.3722 
2022-03-14 04:53:07 - train: epoch 0022, iter [05000, 05004], lr: 0.100000, loss: 4.6830, tea_CELoss: 2.0548 stu_CELoss: 2.2362 DMLLoss: 0.3920 
2022-03-14 04:53:09 - train: epoch 022, train_loss: 4.9672
2022-03-14 04:55:37 - eval: epoch: 022, tea_acc1: 54.152%, tea_acc5: 79.100%, tea_test_loss: 1.9473, stu_acc1: 51.776%, stu_acc5: 77.326%, stu_test_loss: 2.0616
2022-03-14 04:55:38 - until epoch: 022, tea_best_acc1: 54.708%, stu_best_acc1: 51.892%
2022-03-14 04:55:38 - epoch 023 lr: 0.1
2022-03-14 04:56:16 - train: epoch 0023, iter [00100, 05004], lr: 0.100000, loss: 5.0980, tea_CELoss: 2.2756 stu_CELoss: 2.4309 DMLLoss: 0.3916 
2022-03-14 04:56:49 - train: epoch 0023, iter [00200, 05004], lr: 0.100000, loss: 4.4805, tea_CELoss: 1.9843 stu_CELoss: 2.1185 DMLLoss: 0.3777 
2022-03-14 04:57:22 - train: epoch 0023, iter [00300, 05004], lr: 0.100000, loss: 4.7511, tea_CELoss: 2.1276 stu_CELoss: 2.2269 DMLLoss: 0.3966 
2022-03-14 04:57:55 - train: epoch 0023, iter [00400, 05004], lr: 0.100000, loss: 5.0486, tea_CELoss: 2.2388 stu_CELoss: 2.3938 DMLLoss: 0.4161 
2022-03-14 04:58:28 - train: epoch 0023, iter [00500, 05004], lr: 0.100000, loss: 4.8622, tea_CELoss: 2.2049 stu_CELoss: 2.3072 DMLLoss: 0.3501 
2022-03-14 04:59:02 - train: epoch 0023, iter [00600, 05004], lr: 0.100000, loss: 5.2017, tea_CELoss: 2.3045 stu_CELoss: 2.4493 DMLLoss: 0.4479 
2022-03-14 04:59:35 - train: epoch 0023, iter [00700, 05004], lr: 0.100000, loss: 4.8832, tea_CELoss: 2.1722 stu_CELoss: 2.3286 DMLLoss: 0.3824 
2022-03-14 05:00:09 - train: epoch 0023, iter [00800, 05004], lr: 0.100000, loss: 4.9588, tea_CELoss: 2.2013 stu_CELoss: 2.3621 DMLLoss: 0.3954 
2022-03-14 05:00:41 - train: epoch 0023, iter [00900, 05004], lr: 0.100000, loss: 5.0738, tea_CELoss: 2.2165 stu_CELoss: 2.4484 DMLLoss: 0.4089 
2022-03-14 05:01:15 - train: epoch 0023, iter [01000, 05004], lr: 0.100000, loss: 4.6879, tea_CELoss: 2.0020 stu_CELoss: 2.2348 DMLLoss: 0.4511 
2022-03-14 05:01:49 - train: epoch 0023, iter [01100, 05004], lr: 0.100000, loss: 4.9749, tea_CELoss: 2.2182 stu_CELoss: 2.3797 DMLLoss: 0.3770 
2022-03-14 05:02:22 - train: epoch 0023, iter [01200, 05004], lr: 0.100000, loss: 4.6825, tea_CELoss: 2.0881 stu_CELoss: 2.2474 DMLLoss: 0.3471 
2022-03-14 05:02:55 - train: epoch 0023, iter [01300, 05004], lr: 0.100000, loss: 4.6550, tea_CELoss: 2.0847 stu_CELoss: 2.1868 DMLLoss: 0.3835 
2022-03-14 05:03:29 - train: epoch 0023, iter [01400, 05004], lr: 0.100000, loss: 5.0586, tea_CELoss: 2.2185 stu_CELoss: 2.3981 DMLLoss: 0.4420 
2022-03-14 05:04:02 - train: epoch 0023, iter [01500, 05004], lr: 0.100000, loss: 4.6912, tea_CELoss: 2.0858 stu_CELoss: 2.2059 DMLLoss: 0.3995 
2022-03-14 05:04:35 - train: epoch 0023, iter [01600, 05004], lr: 0.100000, loss: 4.8930, tea_CELoss: 2.2305 stu_CELoss: 2.2376 DMLLoss: 0.4249 
2022-03-14 05:05:08 - train: epoch 0023, iter [01700, 05004], lr: 0.100000, loss: 4.7106, tea_CELoss: 2.0909 stu_CELoss: 2.2227 DMLLoss: 0.3970 
2022-03-14 05:05:41 - train: epoch 0023, iter [01800, 05004], lr: 0.100000, loss: 5.3230, tea_CELoss: 2.3188 stu_CELoss: 2.5827 DMLLoss: 0.4216 
2022-03-14 05:06:14 - train: epoch 0023, iter [01900, 05004], lr: 0.100000, loss: 5.2949, tea_CELoss: 2.4112 stu_CELoss: 2.4543 DMLLoss: 0.4294 
2022-03-14 05:06:48 - train: epoch 0023, iter [02000, 05004], lr: 0.100000, loss: 4.5818, tea_CELoss: 1.9754 stu_CELoss: 2.1976 DMLLoss: 0.4088 
2022-03-14 05:07:21 - train: epoch 0023, iter [02100, 05004], lr: 0.100000, loss: 4.8832, tea_CELoss: 2.2010 stu_CELoss: 2.3137 DMLLoss: 0.3684 
2022-03-14 05:07:55 - train: epoch 0023, iter [02200, 05004], lr: 0.100000, loss: 4.3940, tea_CELoss: 1.9851 stu_CELoss: 2.0372 DMLLoss: 0.3717 
2022-03-14 05:08:27 - train: epoch 0023, iter [02300, 05004], lr: 0.100000, loss: 4.6737, tea_CELoss: 2.1477 stu_CELoss: 2.1350 DMLLoss: 0.3910 
2022-03-14 05:09:00 - train: epoch 0023, iter [02400, 05004], lr: 0.100000, loss: 4.8819, tea_CELoss: 2.2078 stu_CELoss: 2.3028 DMLLoss: 0.3713 
2022-03-14 05:09:34 - train: epoch 0023, iter [02500, 05004], lr: 0.100000, loss: 4.9943, tea_CELoss: 2.2236 stu_CELoss: 2.3899 DMLLoss: 0.3809 
2022-03-14 05:10:07 - train: epoch 0023, iter [02600, 05004], lr: 0.100000, loss: 4.9817, tea_CELoss: 2.2703 stu_CELoss: 2.3153 DMLLoss: 0.3961 
2022-03-14 05:10:41 - train: epoch 0023, iter [02700, 05004], lr: 0.100000, loss: 5.3380, tea_CELoss: 2.3927 stu_CELoss: 2.5310 DMLLoss: 0.4143 
2022-03-14 05:11:14 - train: epoch 0023, iter [02800, 05004], lr: 0.100000, loss: 5.3684, tea_CELoss: 2.3960 stu_CELoss: 2.5696 DMLLoss: 0.4027 
2022-03-14 05:11:47 - train: epoch 0023, iter [02900, 05004], lr: 0.100000, loss: 4.8863, tea_CELoss: 2.1974 stu_CELoss: 2.3051 DMLLoss: 0.3838 
2022-03-14 05:12:21 - train: epoch 0023, iter [03000, 05004], lr: 0.100000, loss: 5.1878, tea_CELoss: 2.3044 stu_CELoss: 2.4991 DMLLoss: 0.3842 
2022-03-14 05:12:54 - train: epoch 0023, iter [03100, 05004], lr: 0.100000, loss: 5.5277, tea_CELoss: 2.4432 stu_CELoss: 2.6822 DMLLoss: 0.4023 
2022-03-14 05:13:27 - train: epoch 0023, iter [03200, 05004], lr: 0.100000, loss: 5.0546, tea_CELoss: 2.2402 stu_CELoss: 2.4272 DMLLoss: 0.3873 
2022-03-14 05:14:00 - train: epoch 0023, iter [03300, 05004], lr: 0.100000, loss: 4.8859, tea_CELoss: 2.1909 stu_CELoss: 2.3031 DMLLoss: 0.3918 
2022-03-14 05:14:34 - train: epoch 0023, iter [03400, 05004], lr: 0.100000, loss: 5.1661, tea_CELoss: 2.3022 stu_CELoss: 2.4922 DMLLoss: 0.3717 
2022-03-14 05:15:07 - train: epoch 0023, iter [03500, 05004], lr: 0.100000, loss: 4.7439, tea_CELoss: 2.1261 stu_CELoss: 2.2574 DMLLoss: 0.3604 
2022-03-14 05:15:40 - train: epoch 0023, iter [03600, 05004], lr: 0.100000, loss: 4.7524, tea_CELoss: 2.1530 stu_CELoss: 2.2324 DMLLoss: 0.3670 
2022-03-14 05:16:13 - train: epoch 0023, iter [03700, 05004], lr: 0.100000, loss: 5.0818, tea_CELoss: 2.2923 stu_CELoss: 2.3947 DMLLoss: 0.3947 
2022-03-14 05:16:47 - train: epoch 0023, iter [03800, 05004], lr: 0.100000, loss: 5.3056, tea_CELoss: 2.4087 stu_CELoss: 2.4969 DMLLoss: 0.4000 
2022-03-14 05:17:19 - train: epoch 0023, iter [03900, 05004], lr: 0.100000, loss: 5.1549, tea_CELoss: 2.3480 stu_CELoss: 2.4012 DMLLoss: 0.4057 
2022-03-14 05:17:53 - train: epoch 0023, iter [04000, 05004], lr: 0.100000, loss: 4.8451, tea_CELoss: 2.1406 stu_CELoss: 2.3139 DMLLoss: 0.3906 
2022-03-14 05:18:26 - train: epoch 0023, iter [04100, 05004], lr: 0.100000, loss: 4.5985, tea_CELoss: 2.0143 stu_CELoss: 2.2029 DMLLoss: 0.3813 
2022-03-14 05:18:59 - train: epoch 0023, iter [04200, 05004], lr: 0.100000, loss: 4.4048, tea_CELoss: 1.9576 stu_CELoss: 2.0646 DMLLoss: 0.3826 
2022-03-14 05:19:32 - train: epoch 0023, iter [04300, 05004], lr: 0.100000, loss: 4.4987, tea_CELoss: 2.0288 stu_CELoss: 2.1224 DMLLoss: 0.3475 
2022-03-14 05:20:06 - train: epoch 0023, iter [04400, 05004], lr: 0.100000, loss: 4.6857, tea_CELoss: 2.0710 stu_CELoss: 2.2420 DMLLoss: 0.3727 
2022-03-14 05:20:39 - train: epoch 0023, iter [04500, 05004], lr: 0.100000, loss: 4.8069, tea_CELoss: 2.0989 stu_CELoss: 2.3132 DMLLoss: 0.3948 
2022-03-14 05:21:12 - train: epoch 0023, iter [04600, 05004], lr: 0.100000, loss: 5.1075, tea_CELoss: 2.2693 stu_CELoss: 2.4320 DMLLoss: 0.4062 
2022-03-14 05:21:45 - train: epoch 0023, iter [04700, 05004], lr: 0.100000, loss: 4.6170, tea_CELoss: 2.0904 stu_CELoss: 2.1630 DMLLoss: 0.3636 
2022-03-14 05:22:17 - train: epoch 0023, iter [04800, 05004], lr: 0.100000, loss: 5.0413, tea_CELoss: 2.2633 stu_CELoss: 2.3868 DMLLoss: 0.3912 
2022-03-14 05:22:51 - train: epoch 0023, iter [04900, 05004], lr: 0.100000, loss: 4.6511, tea_CELoss: 2.0558 stu_CELoss: 2.2478 DMLLoss: 0.3475 
2022-03-14 05:23:22 - train: epoch 0023, iter [05000, 05004], lr: 0.100000, loss: 5.2044, tea_CELoss: 2.2714 stu_CELoss: 2.5210 DMLLoss: 0.4120 
2022-03-14 05:23:23 - train: epoch 023, train_loss: 4.9596
2022-03-14 05:25:53 - eval: epoch: 023, tea_acc1: 54.306%, tea_acc5: 79.180%, tea_test_loss: 1.9483, stu_acc1: 51.512%, stu_acc5: 77.080%, stu_test_loss: 2.0888
2022-03-14 05:25:54 - until epoch: 023, tea_best_acc1: 54.708%, stu_best_acc1: 51.892%
2022-03-14 05:25:54 - epoch 024 lr: 0.1
2022-03-14 05:26:32 - train: epoch 0024, iter [00100, 05004], lr: 0.100000, loss: 5.2913, tea_CELoss: 2.3764 stu_CELoss: 2.5143 DMLLoss: 0.4006 
2022-03-14 05:27:06 - train: epoch 0024, iter [00200, 05004], lr: 0.100000, loss: 4.6531, tea_CELoss: 2.0940 stu_CELoss: 2.1970 DMLLoss: 0.3622 
2022-03-14 05:27:39 - train: epoch 0024, iter [00300, 05004], lr: 0.100000, loss: 4.9744, tea_CELoss: 2.2235 stu_CELoss: 2.3512 DMLLoss: 0.3997 
2022-03-14 05:28:12 - train: epoch 0024, iter [00400, 05004], lr: 0.100000, loss: 5.1487, tea_CELoss: 2.3443 stu_CELoss: 2.4432 DMLLoss: 0.3613 
2022-03-14 05:28:45 - train: epoch 0024, iter [00500, 05004], lr: 0.100000, loss: 5.0617, tea_CELoss: 2.2688 stu_CELoss: 2.3959 DMLLoss: 0.3970 
2022-03-14 05:29:18 - train: epoch 0024, iter [00600, 05004], lr: 0.100000, loss: 5.0118, tea_CELoss: 2.2109 stu_CELoss: 2.4107 DMLLoss: 0.3902 
2022-03-14 05:29:52 - train: epoch 0024, iter [00700, 05004], lr: 0.100000, loss: 4.6350, tea_CELoss: 2.0901 stu_CELoss: 2.1831 DMLLoss: 0.3618 
2022-03-14 05:30:25 - train: epoch 0024, iter [00800, 05004], lr: 0.100000, loss: 4.6103, tea_CELoss: 2.0233 stu_CELoss: 2.2014 DMLLoss: 0.3855 
2022-03-14 05:30:58 - train: epoch 0024, iter [00900, 05004], lr: 0.100000, loss: 4.5597, tea_CELoss: 2.0162 stu_CELoss: 2.1802 DMLLoss: 0.3633 
2022-03-14 05:31:31 - train: epoch 0024, iter [01000, 05004], lr: 0.100000, loss: 4.8456, tea_CELoss: 2.2022 stu_CELoss: 2.2750 DMLLoss: 0.3684 
2022-03-14 05:32:04 - train: epoch 0024, iter [01100, 05004], lr: 0.100000, loss: 4.4824, tea_CELoss: 2.0012 stu_CELoss: 2.1350 DMLLoss: 0.3461 
2022-03-14 05:32:37 - train: epoch 0024, iter [01200, 05004], lr: 0.100000, loss: 4.8732, tea_CELoss: 2.1573 stu_CELoss: 2.3123 DMLLoss: 0.4035 
2022-03-14 05:33:11 - train: epoch 0024, iter [01300, 05004], lr: 0.100000, loss: 5.3641, tea_CELoss: 2.3485 stu_CELoss: 2.5950 DMLLoss: 0.4206 
2022-03-14 05:33:44 - train: epoch 0024, iter [01400, 05004], lr: 0.100000, loss: 4.3556, tea_CELoss: 1.9441 stu_CELoss: 2.0568 DMLLoss: 0.3548 
2022-03-14 05:34:17 - train: epoch 0024, iter [01500, 05004], lr: 0.100000, loss: 5.1940, tea_CELoss: 2.3724 stu_CELoss: 2.4332 DMLLoss: 0.3883 
2022-03-14 05:34:50 - train: epoch 0024, iter [01600, 05004], lr: 0.100000, loss: 5.0334, tea_CELoss: 2.2587 stu_CELoss: 2.4034 DMLLoss: 0.3713 
2022-03-14 05:35:23 - train: epoch 0024, iter [01700, 05004], lr: 0.100000, loss: 4.8673, tea_CELoss: 2.1656 stu_CELoss: 2.3122 DMLLoss: 0.3895 
2022-03-14 05:35:56 - train: epoch 0024, iter [01800, 05004], lr: 0.100000, loss: 5.0780, tea_CELoss: 2.2868 stu_CELoss: 2.3762 DMLLoss: 0.4150 
2022-03-14 05:36:30 - train: epoch 0024, iter [01900, 05004], lr: 0.100000, loss: 4.8318, tea_CELoss: 2.1492 stu_CELoss: 2.3058 DMLLoss: 0.3768 
2022-03-14 05:37:03 - train: epoch 0024, iter [02000, 05004], lr: 0.100000, loss: 5.1147, tea_CELoss: 2.2183 stu_CELoss: 2.4912 DMLLoss: 0.4052 
2022-03-14 05:37:37 - train: epoch 0024, iter [02100, 05004], lr: 0.100000, loss: 4.6337, tea_CELoss: 2.0529 stu_CELoss: 2.2209 DMLLoss: 0.3599 
2022-03-14 05:38:10 - train: epoch 0024, iter [02200, 05004], lr: 0.100000, loss: 4.6153, tea_CELoss: 2.1002 stu_CELoss: 2.1411 DMLLoss: 0.3741 
2022-03-14 05:38:43 - train: epoch 0024, iter [02300, 05004], lr: 0.100000, loss: 4.9611, tea_CELoss: 2.2052 stu_CELoss: 2.3602 DMLLoss: 0.3957 
2022-03-14 05:39:17 - train: epoch 0024, iter [02400, 05004], lr: 0.100000, loss: 5.2991, tea_CELoss: 2.4140 stu_CELoss: 2.4824 DMLLoss: 0.4027 
2022-03-14 05:39:49 - train: epoch 0024, iter [02500, 05004], lr: 0.100000, loss: 4.9759, tea_CELoss: 2.1647 stu_CELoss: 2.3626 DMLLoss: 0.4486 
2022-03-14 05:40:23 - train: epoch 0024, iter [02600, 05004], lr: 0.100000, loss: 5.5529, tea_CELoss: 2.4821 stu_CELoss: 2.6575 DMLLoss: 0.4133 
2022-03-14 05:40:56 - train: epoch 0024, iter [02700, 05004], lr: 0.100000, loss: 5.2904, tea_CELoss: 2.3798 stu_CELoss: 2.4948 DMLLoss: 0.4158 
2022-03-14 05:41:29 - train: epoch 0024, iter [02800, 05004], lr: 0.100000, loss: 5.0932, tea_CELoss: 2.2735 stu_CELoss: 2.4329 DMLLoss: 0.3868 
2022-03-14 05:42:02 - train: epoch 0024, iter [02900, 05004], lr: 0.100000, loss: 4.8024, tea_CELoss: 2.1002 stu_CELoss: 2.2903 DMLLoss: 0.4118 
2022-03-14 05:42:35 - train: epoch 0024, iter [03000, 05004], lr: 0.100000, loss: 4.6079, tea_CELoss: 2.0980 stu_CELoss: 2.1555 DMLLoss: 0.3545 
2022-03-14 05:43:09 - train: epoch 0024, iter [03100, 05004], lr: 0.100000, loss: 4.5459, tea_CELoss: 2.0503 stu_CELoss: 2.1113 DMLLoss: 0.3843 
2022-03-14 05:43:42 - train: epoch 0024, iter [03200, 05004], lr: 0.100000, loss: 5.2682, tea_CELoss: 2.3486 stu_CELoss: 2.5359 DMLLoss: 0.3836 
2022-03-14 05:44:15 - train: epoch 0024, iter [03300, 05004], lr: 0.100000, loss: 4.7929, tea_CELoss: 2.1242 stu_CELoss: 2.2973 DMLLoss: 0.3715 
2022-03-14 05:44:48 - train: epoch 0024, iter [03400, 05004], lr: 0.100000, loss: 4.6094, tea_CELoss: 2.0704 stu_CELoss: 2.1295 DMLLoss: 0.4095 
2022-03-14 05:45:21 - train: epoch 0024, iter [03500, 05004], lr: 0.100000, loss: 5.1329, tea_CELoss: 2.2706 stu_CELoss: 2.4809 DMLLoss: 0.3814 
2022-03-14 05:45:55 - train: epoch 0024, iter [03600, 05004], lr: 0.100000, loss: 4.8011, tea_CELoss: 2.1215 stu_CELoss: 2.3126 DMLLoss: 0.3670 
2022-03-14 05:46:28 - train: epoch 0024, iter [03700, 05004], lr: 0.100000, loss: 4.6870, tea_CELoss: 2.0924 stu_CELoss: 2.2160 DMLLoss: 0.3785 
2022-03-14 05:47:01 - train: epoch 0024, iter [03800, 05004], lr: 0.100000, loss: 5.2033, tea_CELoss: 2.3557 stu_CELoss: 2.4362 DMLLoss: 0.4115 
2022-03-14 05:47:34 - train: epoch 0024, iter [03900, 05004], lr: 0.100000, loss: 4.5521, tea_CELoss: 2.0574 stu_CELoss: 2.1384 DMLLoss: 0.3563 
2022-03-14 05:48:07 - train: epoch 0024, iter [04000, 05004], lr: 0.100000, loss: 5.0937, tea_CELoss: 2.2478 stu_CELoss: 2.4562 DMLLoss: 0.3896 
2022-03-14 05:48:40 - train: epoch 0024, iter [04100, 05004], lr: 0.100000, loss: 4.8526, tea_CELoss: 2.1789 stu_CELoss: 2.2998 DMLLoss: 0.3739 
2022-03-14 05:49:14 - train: epoch 0024, iter [04200, 05004], lr: 0.100000, loss: 4.8542, tea_CELoss: 2.2106 stu_CELoss: 2.2743 DMLLoss: 0.3693 
2022-03-14 05:49:47 - train: epoch 0024, iter [04300, 05004], lr: 0.100000, loss: 4.7592, tea_CELoss: 2.1136 stu_CELoss: 2.2423 DMLLoss: 0.4034 
2022-03-14 05:50:20 - train: epoch 0024, iter [04400, 05004], lr: 0.100000, loss: 5.0539, tea_CELoss: 2.2937 stu_CELoss: 2.3851 DMLLoss: 0.3751 
2022-03-14 05:50:53 - train: epoch 0024, iter [04500, 05004], lr: 0.100000, loss: 4.4914, tea_CELoss: 2.0016 stu_CELoss: 2.1331 DMLLoss: 0.3567 
2022-03-14 05:51:26 - train: epoch 0024, iter [04600, 05004], lr: 0.100000, loss: 5.3188, tea_CELoss: 2.4070 stu_CELoss: 2.5112 DMLLoss: 0.4006 
2022-03-14 05:51:59 - train: epoch 0024, iter [04700, 05004], lr: 0.100000, loss: 4.8574, tea_CELoss: 2.1907 stu_CELoss: 2.2585 DMLLoss: 0.4082 
2022-03-14 05:52:32 - train: epoch 0024, iter [04800, 05004], lr: 0.100000, loss: 4.4913, tea_CELoss: 1.9946 stu_CELoss: 2.1208 DMLLoss: 0.3759 
2022-03-14 05:53:05 - train: epoch 0024, iter [04900, 05004], lr: 0.100000, loss: 5.0999, tea_CELoss: 2.2715 stu_CELoss: 2.4440 DMLLoss: 0.3844 
2022-03-14 05:53:37 - train: epoch 0024, iter [05000, 05004], lr: 0.100000, loss: 5.2746, tea_CELoss: 2.3641 stu_CELoss: 2.4919 DMLLoss: 0.4186 
2022-03-14 05:53:38 - train: epoch 024, train_loss: 4.9553
2022-03-14 05:56:07 - eval: epoch: 024, tea_acc1: 53.740%, tea_acc5: 79.154%, tea_test_loss: 1.9612, stu_acc1: 51.578%, stu_acc5: 76.840%, stu_test_loss: 2.0970
2022-03-14 05:56:07 - until epoch: 024, tea_best_acc1: 54.708%, stu_best_acc1: 51.892%
2022-03-14 05:56:07 - epoch 025 lr: 0.1
2022-03-14 05:56:45 - train: epoch 0025, iter [00100, 05004], lr: 0.100000, loss: 4.9860, tea_CELoss: 2.2211 stu_CELoss: 2.3501 DMLLoss: 0.4149 
2022-03-14 05:57:18 - train: epoch 0025, iter [00200, 05004], lr: 0.100000, loss: 4.2298, tea_CELoss: 1.8758 stu_CELoss: 1.9620 DMLLoss: 0.3920 
2022-03-14 05:57:51 - train: epoch 0025, iter [00300, 05004], lr: 0.100000, loss: 4.8067, tea_CELoss: 2.1285 stu_CELoss: 2.2619 DMLLoss: 0.4163 
2022-03-14 05:58:24 - train: epoch 0025, iter [00400, 05004], lr: 0.100000, loss: 5.5066, tea_CELoss: 2.4889 stu_CELoss: 2.6085 DMLLoss: 0.4092 
2022-03-14 05:58:57 - train: epoch 0025, iter [00500, 05004], lr: 0.100000, loss: 4.7350, tea_CELoss: 2.1010 stu_CELoss: 2.2475 DMLLoss: 0.3865 
2022-03-14 05:59:30 - train: epoch 0025, iter [00600, 05004], lr: 0.100000, loss: 4.9771, tea_CELoss: 2.2377 stu_CELoss: 2.3272 DMLLoss: 0.4122 
2022-03-14 06:00:03 - train: epoch 0025, iter [00700, 05004], lr: 0.100000, loss: 4.7884, tea_CELoss: 2.1463 stu_CELoss: 2.2634 DMLLoss: 0.3788 
2022-03-14 06:00:36 - train: epoch 0025, iter [00800, 05004], lr: 0.100000, loss: 4.7619, tea_CELoss: 2.1481 stu_CELoss: 2.2288 DMLLoss: 0.3849 
2022-03-14 06:01:09 - train: epoch 0025, iter [00900, 05004], lr: 0.100000, loss: 4.9445, tea_CELoss: 2.2101 stu_CELoss: 2.3515 DMLLoss: 0.3829 
2022-03-14 06:01:42 - train: epoch 0025, iter [01000, 05004], lr: 0.100000, loss: 4.8578, tea_CELoss: 2.2013 stu_CELoss: 2.2523 DMLLoss: 0.4042 
2022-03-14 06:02:15 - train: epoch 0025, iter [01100, 05004], lr: 0.100000, loss: 4.9372, tea_CELoss: 2.2043 stu_CELoss: 2.3302 DMLLoss: 0.4027 
2022-03-14 06:02:48 - train: epoch 0025, iter [01200, 05004], lr: 0.100000, loss: 5.0769, tea_CELoss: 2.2999 stu_CELoss: 2.3813 DMLLoss: 0.3958 
2022-03-14 06:03:21 - train: epoch 0025, iter [01300, 05004], lr: 0.100000, loss: 4.6785, tea_CELoss: 2.0896 stu_CELoss: 2.2153 DMLLoss: 0.3736 
2022-03-14 06:03:53 - train: epoch 0025, iter [01400, 05004], lr: 0.100000, loss: 4.5135, tea_CELoss: 2.0286 stu_CELoss: 2.1371 DMLLoss: 0.3478 
2022-03-14 06:04:27 - train: epoch 0025, iter [01500, 05004], lr: 0.100000, loss: 5.0382, tea_CELoss: 2.3199 stu_CELoss: 2.3560 DMLLoss: 0.3623 
2022-03-14 06:05:00 - train: epoch 0025, iter [01600, 05004], lr: 0.100000, loss: 4.8973, tea_CELoss: 2.2026 stu_CELoss: 2.2813 DMLLoss: 0.4134 
2022-03-14 06:05:33 - train: epoch 0025, iter [01700, 05004], lr: 0.100000, loss: 5.1430, tea_CELoss: 2.2877 stu_CELoss: 2.4122 DMLLoss: 0.4431 
2022-03-14 06:06:05 - train: epoch 0025, iter [01800, 05004], lr: 0.100000, loss: 4.7673, tea_CELoss: 2.0883 stu_CELoss: 2.2855 DMLLoss: 0.3935 
2022-03-14 06:06:38 - train: epoch 0025, iter [01900, 05004], lr: 0.100000, loss: 4.6721, tea_CELoss: 2.1405 stu_CELoss: 2.1617 DMLLoss: 0.3699 
2022-03-14 06:07:11 - train: epoch 0025, iter [02000, 05004], lr: 0.100000, loss: 4.8332, tea_CELoss: 2.1624 stu_CELoss: 2.2924 DMLLoss: 0.3784 
2022-03-14 06:07:44 - train: epoch 0025, iter [02100, 05004], lr: 0.100000, loss: 4.1966, tea_CELoss: 1.8867 stu_CELoss: 1.9617 DMLLoss: 0.3481 
2022-03-14 06:08:17 - train: epoch 0025, iter [02200, 05004], lr: 0.100000, loss: 4.7763, tea_CELoss: 2.1288 stu_CELoss: 2.2925 DMLLoss: 0.3550 
2022-03-14 06:08:49 - train: epoch 0025, iter [02300, 05004], lr: 0.100000, loss: 4.9511, tea_CELoss: 2.1510 stu_CELoss: 2.3144 DMLLoss: 0.4857 
2022-03-14 06:09:23 - train: epoch 0025, iter [02400, 05004], lr: 0.100000, loss: 4.8948, tea_CELoss: 2.1825 stu_CELoss: 2.3255 DMLLoss: 0.3868 
2022-03-14 06:09:56 - train: epoch 0025, iter [02500, 05004], lr: 0.100000, loss: 5.0713, tea_CELoss: 2.2946 stu_CELoss: 2.3723 DMLLoss: 0.4044 
2022-03-14 06:10:29 - train: epoch 0025, iter [02600, 05004], lr: 0.100000, loss: 4.8033, tea_CELoss: 2.1561 stu_CELoss: 2.2531 DMLLoss: 0.3941 
2022-03-14 06:11:03 - train: epoch 0025, iter [02700, 05004], lr: 0.100000, loss: 5.2645, tea_CELoss: 2.3503 stu_CELoss: 2.4954 DMLLoss: 0.4188 
2022-03-14 06:11:35 - train: epoch 0025, iter [02800, 05004], lr: 0.100000, loss: 5.1457, tea_CELoss: 2.2985 stu_CELoss: 2.4360 DMLLoss: 0.4112 
2022-03-14 06:12:09 - train: epoch 0025, iter [02900, 05004], lr: 0.100000, loss: 5.2483, tea_CELoss: 2.3825 stu_CELoss: 2.4626 DMLLoss: 0.4032 
2022-03-14 06:12:42 - train: epoch 0025, iter [03000, 05004], lr: 0.100000, loss: 4.9379, tea_CELoss: 2.2458 stu_CELoss: 2.3082 DMLLoss: 0.3839 
2022-03-14 06:13:15 - train: epoch 0025, iter [03100, 05004], lr: 0.100000, loss: 5.1060, tea_CELoss: 2.3105 stu_CELoss: 2.4266 DMLLoss: 0.3689 
2022-03-14 06:13:47 - train: epoch 0025, iter [03200, 05004], lr: 0.100000, loss: 4.8779, tea_CELoss: 2.1740 stu_CELoss: 2.3219 DMLLoss: 0.3819 
2022-03-14 06:14:20 - train: epoch 0025, iter [03300, 05004], lr: 0.100000, loss: 4.8552, tea_CELoss: 2.1671 stu_CELoss: 2.2901 DMLLoss: 0.3980 
2022-03-14 06:14:53 - train: epoch 0025, iter [03400, 05004], lr: 0.100000, loss: 4.9397, tea_CELoss: 2.2298 stu_CELoss: 2.2976 DMLLoss: 0.4123 
2022-03-14 06:15:26 - train: epoch 0025, iter [03500, 05004], lr: 0.100000, loss: 4.9780, tea_CELoss: 2.1797 stu_CELoss: 2.3996 DMLLoss: 0.3987 
2022-03-14 06:15:58 - train: epoch 0025, iter [03600, 05004], lr: 0.100000, loss: 4.9640, tea_CELoss: 2.2602 stu_CELoss: 2.3161 DMLLoss: 0.3877 
2022-03-14 06:16:32 - train: epoch 0025, iter [03700, 05004], lr: 0.100000, loss: 4.9502, tea_CELoss: 2.2803 stu_CELoss: 2.2961 DMLLoss: 0.3738 
2022-03-14 06:17:05 - train: epoch 0025, iter [03800, 05004], lr: 0.100000, loss: 5.0243, tea_CELoss: 2.3000 stu_CELoss: 2.3298 DMLLoss: 0.3945 
2022-03-14 06:17:38 - train: epoch 0025, iter [03900, 05004], lr: 0.100000, loss: 5.4838, tea_CELoss: 2.4405 stu_CELoss: 2.6389 DMLLoss: 0.4044 
2022-03-14 06:18:10 - train: epoch 0025, iter [04000, 05004], lr: 0.100000, loss: 5.1018, tea_CELoss: 2.3107 stu_CELoss: 2.4273 DMLLoss: 0.3638 
2022-03-14 06:18:43 - train: epoch 0025, iter [04100, 05004], lr: 0.100000, loss: 5.3085, tea_CELoss: 2.3991 stu_CELoss: 2.5056 DMLLoss: 0.4038 
2022-03-14 06:19:17 - train: epoch 0025, iter [04200, 05004], lr: 0.100000, loss: 4.9600, tea_CELoss: 2.2541 stu_CELoss: 2.3464 DMLLoss: 0.3595 
2022-03-14 06:19:49 - train: epoch 0025, iter [04300, 05004], lr: 0.100000, loss: 4.7772, tea_CELoss: 2.1738 stu_CELoss: 2.2199 DMLLoss: 0.3835 
2022-03-14 06:20:23 - train: epoch 0025, iter [04400, 05004], lr: 0.100000, loss: 4.7904, tea_CELoss: 2.1262 stu_CELoss: 2.2716 DMLLoss: 0.3925 
2022-03-14 06:20:55 - train: epoch 0025, iter [04500, 05004], lr: 0.100000, loss: 5.0399, tea_CELoss: 2.2760 stu_CELoss: 2.3298 DMLLoss: 0.4342 
2022-03-14 06:21:28 - train: epoch 0025, iter [04600, 05004], lr: 0.100000, loss: 4.5185, tea_CELoss: 1.9497 stu_CELoss: 2.2001 DMLLoss: 0.3687 
2022-03-14 06:22:01 - train: epoch 0025, iter [04700, 05004], lr: 0.100000, loss: 4.9758, tea_CELoss: 2.2326 stu_CELoss: 2.3354 DMLLoss: 0.4078 
2022-03-14 06:22:34 - train: epoch 0025, iter [04800, 05004], lr: 0.100000, loss: 4.6625, tea_CELoss: 2.1155 stu_CELoss: 2.1565 DMLLoss: 0.3905 
2022-03-14 06:23:07 - train: epoch 0025, iter [04900, 05004], lr: 0.100000, loss: 4.8719, tea_CELoss: 2.1770 stu_CELoss: 2.3087 DMLLoss: 0.3862 
2022-03-14 06:23:39 - train: epoch 0025, iter [05000, 05004], lr: 0.100000, loss: 5.6273, tea_CELoss: 2.5872 stu_CELoss: 2.6492 DMLLoss: 0.3909 
2022-03-14 06:23:40 - train: epoch 025, train_loss: 4.9532
2022-03-14 06:26:08 - eval: epoch: 025, tea_acc1: 53.834%, tea_acc5: 79.334%, tea_test_loss: 1.9501, stu_acc1: 51.648%, stu_acc5: 77.164%, stu_test_loss: 2.0695
2022-03-14 06:26:09 - until epoch: 025, tea_best_acc1: 54.708%, stu_best_acc1: 51.892%
2022-03-14 06:26:09 - epoch 026 lr: 0.1
2022-03-14 06:26:47 - train: epoch 0026, iter [00100, 05004], lr: 0.100000, loss: 4.7575, tea_CELoss: 2.1413 stu_CELoss: 2.2417 DMLLoss: 0.3745 
2022-03-14 06:27:20 - train: epoch 0026, iter [00200, 05004], lr: 0.100000, loss: 4.7116, tea_CELoss: 2.1199 stu_CELoss: 2.2139 DMLLoss: 0.3778 
2022-03-14 06:27:53 - train: epoch 0026, iter [00300, 05004], lr: 0.100000, loss: 5.0810, tea_CELoss: 2.3048 stu_CELoss: 2.3757 DMLLoss: 0.4006 
2022-03-14 06:28:26 - train: epoch 0026, iter [00400, 05004], lr: 0.100000, loss: 4.4575, tea_CELoss: 1.9819 stu_CELoss: 2.0969 DMLLoss: 0.3787 
2022-03-14 06:28:59 - train: epoch 0026, iter [00500, 05004], lr: 0.100000, loss: 5.2060, tea_CELoss: 2.3452 stu_CELoss: 2.4693 DMLLoss: 0.3915 
2022-03-14 06:29:32 - train: epoch 0026, iter [00600, 05004], lr: 0.100000, loss: 5.6437, tea_CELoss: 2.5542 stu_CELoss: 2.6723 DMLLoss: 0.4172 
2022-03-14 06:30:05 - train: epoch 0026, iter [00700, 05004], lr: 0.100000, loss: 4.8807, tea_CELoss: 2.1825 stu_CELoss: 2.3186 DMLLoss: 0.3796 
2022-03-14 06:30:39 - train: epoch 0026, iter [00800, 05004], lr: 0.100000, loss: 4.5335, tea_CELoss: 1.9838 stu_CELoss: 2.1468 DMLLoss: 0.4028 
2022-03-14 06:31:12 - train: epoch 0026, iter [00900, 05004], lr: 0.100000, loss: 5.7215, tea_CELoss: 2.6215 stu_CELoss: 2.6817 DMLLoss: 0.4183 
2022-03-14 06:31:45 - train: epoch 0026, iter [01000, 05004], lr: 0.100000, loss: 5.0808, tea_CELoss: 2.1971 stu_CELoss: 2.4193 DMLLoss: 0.4645 
2022-03-14 06:32:19 - train: epoch 0026, iter [01100, 05004], lr: 0.100000, loss: 4.8948, tea_CELoss: 2.1875 stu_CELoss: 2.3174 DMLLoss: 0.3899 
2022-03-14 06:32:52 - train: epoch 0026, iter [01200, 05004], lr: 0.100000, loss: 5.2469, tea_CELoss: 2.3758 stu_CELoss: 2.4988 DMLLoss: 0.3723 
2022-03-14 06:33:25 - train: epoch 0026, iter [01300, 05004], lr: 0.100000, loss: 4.8403, tea_CELoss: 2.1751 stu_CELoss: 2.2679 DMLLoss: 0.3974 
2022-03-14 06:33:58 - train: epoch 0026, iter [01400, 05004], lr: 0.100000, loss: 4.9288, tea_CELoss: 2.2087 stu_CELoss: 2.3263 DMLLoss: 0.3938 
2022-03-14 06:34:31 - train: epoch 0026, iter [01500, 05004], lr: 0.100000, loss: 4.6567, tea_CELoss: 2.1061 stu_CELoss: 2.1355 DMLLoss: 0.4151 
2022-03-14 06:35:05 - train: epoch 0026, iter [01600, 05004], lr: 0.100000, loss: 4.9418, tea_CELoss: 2.2014 stu_CELoss: 2.3482 DMLLoss: 0.3922 
2022-03-14 06:35:38 - train: epoch 0026, iter [01700, 05004], lr: 0.100000, loss: 4.9064, tea_CELoss: 2.1692 stu_CELoss: 2.3434 DMLLoss: 0.3938 
2022-03-14 06:36:12 - train: epoch 0026, iter [01800, 05004], lr: 0.100000, loss: 5.4421, tea_CELoss: 2.4488 stu_CELoss: 2.5874 DMLLoss: 0.4059 
2022-03-14 06:36:45 - train: epoch 0026, iter [01900, 05004], lr: 0.100000, loss: 5.2011, tea_CELoss: 2.3313 stu_CELoss: 2.4729 DMLLoss: 0.3969 
2022-03-14 06:37:18 - train: epoch 0026, iter [02000, 05004], lr: 0.100000, loss: 5.3663, tea_CELoss: 2.3923 stu_CELoss: 2.5607 DMLLoss: 0.4133 
2022-03-14 06:37:51 - train: epoch 0026, iter [02100, 05004], lr: 0.100000, loss: 4.7893, tea_CELoss: 2.1027 stu_CELoss: 2.3113 DMLLoss: 0.3753 
2022-03-14 06:38:24 - train: epoch 0026, iter [02200, 05004], lr: 0.100000, loss: 4.8883, tea_CELoss: 2.2108 stu_CELoss: 2.2851 DMLLoss: 0.3925 
2022-03-14 06:38:58 - train: epoch 0026, iter [02300, 05004], lr: 0.100000, loss: 4.8526, tea_CELoss: 2.1979 stu_CELoss: 2.2855 DMLLoss: 0.3692 
2022-03-14 06:39:31 - train: epoch 0026, iter [02400, 05004], lr: 0.100000, loss: 5.0137, tea_CELoss: 2.2551 stu_CELoss: 2.3948 DMLLoss: 0.3639 
2022-03-14 06:40:04 - train: epoch 0026, iter [02500, 05004], lr: 0.100000, loss: 5.2658, tea_CELoss: 2.4490 stu_CELoss: 2.4239 DMLLoss: 0.3928 
2022-03-14 06:40:37 - train: epoch 0026, iter [02600, 05004], lr: 0.100000, loss: 5.0165, tea_CELoss: 2.2787 stu_CELoss: 2.3615 DMLLoss: 0.3763 
2022-03-14 06:41:10 - train: epoch 0026, iter [02700, 05004], lr: 0.100000, loss: 5.4205, tea_CELoss: 2.4243 stu_CELoss: 2.5827 DMLLoss: 0.4136 
2022-03-14 06:41:43 - train: epoch 0026, iter [02800, 05004], lr: 0.100000, loss: 5.0612, tea_CELoss: 2.2452 stu_CELoss: 2.3848 DMLLoss: 0.4313 
2022-03-14 06:42:16 - train: epoch 0026, iter [02900, 05004], lr: 0.100000, loss: 5.5429, tea_CELoss: 2.5117 stu_CELoss: 2.6228 DMLLoss: 0.4084 
2022-03-14 06:42:49 - train: epoch 0026, iter [03000, 05004], lr: 0.100000, loss: 5.0114, tea_CELoss: 2.2524 stu_CELoss: 2.3512 DMLLoss: 0.4077 
2022-03-14 06:43:22 - train: epoch 0026, iter [03100, 05004], lr: 0.100000, loss: 5.0917, tea_CELoss: 2.2430 stu_CELoss: 2.4592 DMLLoss: 0.3895 
2022-03-14 06:43:56 - train: epoch 0026, iter [03200, 05004], lr: 0.100000, loss: 5.2592, tea_CELoss: 2.3415 stu_CELoss: 2.5032 DMLLoss: 0.4145 
2022-03-14 06:44:29 - train: epoch 0026, iter [03300, 05004], lr: 0.100000, loss: 4.8616, tea_CELoss: 2.1891 stu_CELoss: 2.2603 DMLLoss: 0.4122 
2022-03-14 06:45:02 - train: epoch 0026, iter [03400, 05004], lr: 0.100000, loss: 5.0531, tea_CELoss: 2.2302 stu_CELoss: 2.4422 DMLLoss: 0.3807 
2022-03-14 06:45:36 - train: epoch 0026, iter [03500, 05004], lr: 0.100000, loss: 5.1924, tea_CELoss: 2.3807 stu_CELoss: 2.4405 DMLLoss: 0.3712 
2022-03-14 06:46:09 - train: epoch 0026, iter [03600, 05004], lr: 0.100000, loss: 4.5621, tea_CELoss: 2.0505 stu_CELoss: 2.1302 DMLLoss: 0.3814 
2022-03-14 06:46:42 - train: epoch 0026, iter [03700, 05004], lr: 0.100000, loss: 4.9447, tea_CELoss: 2.2100 stu_CELoss: 2.3591 DMLLoss: 0.3756 
2022-03-14 06:47:15 - train: epoch 0026, iter [03800, 05004], lr: 0.100000, loss: 5.2127, tea_CELoss: 2.3581 stu_CELoss: 2.4585 DMLLoss: 0.3961 
2022-03-14 06:47:48 - train: epoch 0026, iter [03900, 05004], lr: 0.100000, loss: 5.2028, tea_CELoss: 2.3290 stu_CELoss: 2.4804 DMLLoss: 0.3935 
2022-03-14 06:48:22 - train: epoch 0026, iter [04000, 05004], lr: 0.100000, loss: 5.0551, tea_CELoss: 2.2286 stu_CELoss: 2.3876 DMLLoss: 0.4388 
2022-03-14 06:48:55 - train: epoch 0026, iter [04100, 05004], lr: 0.100000, loss: 4.9388, tea_CELoss: 2.2177 stu_CELoss: 2.3548 DMLLoss: 0.3663 
2022-03-14 06:49:28 - train: epoch 0026, iter [04200, 05004], lr: 0.100000, loss: 5.1263, tea_CELoss: 2.3674 stu_CELoss: 2.4043 DMLLoss: 0.3546 
2022-03-14 06:50:01 - train: epoch 0026, iter [04300, 05004], lr: 0.100000, loss: 5.1370, tea_CELoss: 2.3114 stu_CELoss: 2.4464 DMLLoss: 0.3792 
2022-03-14 06:50:34 - train: epoch 0026, iter [04400, 05004], lr: 0.100000, loss: 5.1930, tea_CELoss: 2.3134 stu_CELoss: 2.4910 DMLLoss: 0.3887 
2022-03-14 06:51:08 - train: epoch 0026, iter [04500, 05004], lr: 0.100000, loss: 5.7359, tea_CELoss: 2.5847 stu_CELoss: 2.7674 DMLLoss: 0.3838 
2022-03-14 06:51:41 - train: epoch 0026, iter [04600, 05004], lr: 0.100000, loss: 4.8588, tea_CELoss: 2.1886 stu_CELoss: 2.2864 DMLLoss: 0.3838 
2022-03-14 06:52:14 - train: epoch 0026, iter [04700, 05004], lr: 0.100000, loss: 4.6180, tea_CELoss: 2.0346 stu_CELoss: 2.1815 DMLLoss: 0.4018 
2022-03-14 06:52:47 - train: epoch 0026, iter [04800, 05004], lr: 0.100000, loss: 4.7770, tea_CELoss: 2.1611 stu_CELoss: 2.2135 DMLLoss: 0.4024 
2022-03-14 06:53:20 - train: epoch 0026, iter [04900, 05004], lr: 0.100000, loss: 5.0403, tea_CELoss: 2.2587 stu_CELoss: 2.3871 DMLLoss: 0.3945 
2022-03-14 06:53:52 - train: epoch 0026, iter [05000, 05004], lr: 0.100000, loss: 5.1659, tea_CELoss: 2.3292 stu_CELoss: 2.4721 DMLLoss: 0.3647 
2022-03-14 06:53:53 - train: epoch 026, train_loss: 4.9475
2022-03-14 06:56:22 - eval: epoch: 026, tea_acc1: 54.358%, tea_acc5: 79.690%, tea_test_loss: 1.9214, stu_acc1: 50.794%, stu_acc5: 76.598%, stu_test_loss: 2.1217
2022-03-14 06:56:23 - until epoch: 026, tea_best_acc1: 54.708%, stu_best_acc1: 51.892%
2022-03-14 06:56:23 - epoch 027 lr: 0.1
2022-03-14 06:57:00 - train: epoch 0027, iter [00100, 05004], lr: 0.100000, loss: 4.9572, tea_CELoss: 2.2066 stu_CELoss: 2.3471 DMLLoss: 0.4034 
2022-03-14 06:57:34 - train: epoch 0027, iter [00200, 05004], lr: 0.100000, loss: 4.8692, tea_CELoss: 2.1053 stu_CELoss: 2.3337 DMLLoss: 0.4301 
2022-03-14 06:58:06 - train: epoch 0027, iter [00300, 05004], lr: 0.100000, loss: 5.2548, tea_CELoss: 2.3115 stu_CELoss: 2.5276 DMLLoss: 0.4157 
2022-03-14 06:58:40 - train: epoch 0027, iter [00400, 05004], lr: 0.100000, loss: 5.2809, tea_CELoss: 2.3362 stu_CELoss: 2.5199 DMLLoss: 0.4248 
2022-03-14 06:59:13 - train: epoch 0027, iter [00500, 05004], lr: 0.100000, loss: 4.8560, tea_CELoss: 2.1235 stu_CELoss: 2.3043 DMLLoss: 0.4282 
2022-03-14 06:59:46 - train: epoch 0027, iter [00600, 05004], lr: 0.100000, loss: 5.0608, tea_CELoss: 2.2717 stu_CELoss: 2.3949 DMLLoss: 0.3942 
2022-03-14 07:00:19 - train: epoch 0027, iter [00700, 05004], lr: 0.100000, loss: 4.8412, tea_CELoss: 2.1630 stu_CELoss: 2.3295 DMLLoss: 0.3487 
2022-03-14 07:00:52 - train: epoch 0027, iter [00800, 05004], lr: 0.100000, loss: 5.0401, tea_CELoss: 2.2653 stu_CELoss: 2.3865 DMLLoss: 0.3883 
2022-03-14 07:01:25 - train: epoch 0027, iter [00900, 05004], lr: 0.100000, loss: 5.0114, tea_CELoss: 2.2643 stu_CELoss: 2.3319 DMLLoss: 0.4151 
2022-03-14 07:01:58 - train: epoch 0027, iter [01000, 05004], lr: 0.100000, loss: 4.7573, tea_CELoss: 2.1291 stu_CELoss: 2.2634 DMLLoss: 0.3648 
2022-03-14 07:02:31 - train: epoch 0027, iter [01100, 05004], lr: 0.100000, loss: 4.6882, tea_CELoss: 2.1539 stu_CELoss: 2.1558 DMLLoss: 0.3785 
2022-03-14 07:03:04 - train: epoch 0027, iter [01200, 05004], lr: 0.100000, loss: 5.2066, tea_CELoss: 2.2863 stu_CELoss: 2.4797 DMLLoss: 0.4406 
2022-03-14 07:03:38 - train: epoch 0027, iter [01300, 05004], lr: 0.100000, loss: 4.8338, tea_CELoss: 2.1760 stu_CELoss: 2.2727 DMLLoss: 0.3850 
2022-03-14 07:04:11 - train: epoch 0027, iter [01400, 05004], lr: 0.100000, loss: 5.1953, tea_CELoss: 2.3138 stu_CELoss: 2.4875 DMLLoss: 0.3940 
2022-03-14 07:04:44 - train: epoch 0027, iter [01500, 05004], lr: 0.100000, loss: 5.2122, tea_CELoss: 2.3467 stu_CELoss: 2.4940 DMLLoss: 0.3715 
2022-03-14 07:05:18 - train: epoch 0027, iter [01600, 05004], lr: 0.100000, loss: 5.1386, tea_CELoss: 2.2826 stu_CELoss: 2.4731 DMLLoss: 0.3829 
2022-03-14 07:05:51 - train: epoch 0027, iter [01700, 05004], lr: 0.100000, loss: 4.8716, tea_CELoss: 2.1359 stu_CELoss: 2.3397 DMLLoss: 0.3960 
2022-03-14 07:06:24 - train: epoch 0027, iter [01800, 05004], lr: 0.100000, loss: 4.7025, tea_CELoss: 2.0383 stu_CELoss: 2.2310 DMLLoss: 0.4333 
2022-03-14 07:06:57 - train: epoch 0027, iter [01900, 05004], lr: 0.100000, loss: 4.9993, tea_CELoss: 2.2554 stu_CELoss: 2.3523 DMLLoss: 0.3915 
2022-03-14 07:07:30 - train: epoch 0027, iter [02000, 05004], lr: 0.100000, loss: 4.7543, tea_CELoss: 2.1457 stu_CELoss: 2.2370 DMLLoss: 0.3716 
2022-03-14 07:08:03 - train: epoch 0027, iter [02100, 05004], lr: 0.100000, loss: 5.0695, tea_CELoss: 2.3004 stu_CELoss: 2.3881 DMLLoss: 0.3810 
2022-03-14 07:08:37 - train: epoch 0027, iter [02200, 05004], lr: 0.100000, loss: 5.3690, tea_CELoss: 2.3496 stu_CELoss: 2.5591 DMLLoss: 0.4603 
2022-03-14 07:09:10 - train: epoch 0027, iter [02300, 05004], lr: 0.100000, loss: 5.3530, tea_CELoss: 2.4280 stu_CELoss: 2.5287 DMLLoss: 0.3963 
2022-03-14 07:09:44 - train: epoch 0027, iter [02400, 05004], lr: 0.100000, loss: 4.7624, tea_CELoss: 2.1181 stu_CELoss: 2.2579 DMLLoss: 0.3863 
2022-03-14 07:10:17 - train: epoch 0027, iter [02500, 05004], lr: 0.100000, loss: 4.8042, tea_CELoss: 2.0628 stu_CELoss: 2.3456 DMLLoss: 0.3959 
2022-03-14 07:10:50 - train: epoch 0027, iter [02600, 05004], lr: 0.100000, loss: 5.0789, tea_CELoss: 2.2362 stu_CELoss: 2.4150 DMLLoss: 0.4278 
2022-03-14 07:11:23 - train: epoch 0027, iter [02700, 05004], lr: 0.100000, loss: 5.0301, tea_CELoss: 2.2191 stu_CELoss: 2.3669 DMLLoss: 0.4441 
2022-03-14 07:11:57 - train: epoch 0027, iter [02800, 05004], lr: 0.100000, loss: 4.9900, tea_CELoss: 2.2412 stu_CELoss: 2.3321 DMLLoss: 0.4168 
2022-03-14 07:12:30 - train: epoch 0027, iter [02900, 05004], lr: 0.100000, loss: 5.1598, tea_CELoss: 2.3215 stu_CELoss: 2.4396 DMLLoss: 0.3987 
2022-03-14 07:13:03 - train: epoch 0027, iter [03000, 05004], lr: 0.100000, loss: 4.8403, tea_CELoss: 2.1746 stu_CELoss: 2.3128 DMLLoss: 0.3529 
2022-03-14 07:13:36 - train: epoch 0027, iter [03100, 05004], lr: 0.100000, loss: 4.4707, tea_CELoss: 1.9483 stu_CELoss: 2.1601 DMLLoss: 0.3623 
2022-03-14 07:14:09 - train: epoch 0027, iter [03200, 05004], lr: 0.100000, loss: 4.8654, tea_CELoss: 2.1650 stu_CELoss: 2.2752 DMLLoss: 0.4252 
2022-03-14 07:14:42 - train: epoch 0027, iter [03300, 05004], lr: 0.100000, loss: 4.8739, tea_CELoss: 2.2094 stu_CELoss: 2.3282 DMLLoss: 0.3363 
2022-03-14 07:15:15 - train: epoch 0027, iter [03400, 05004], lr: 0.100000, loss: 4.7921, tea_CELoss: 2.1722 stu_CELoss: 2.2167 DMLLoss: 0.4032 
2022-03-14 07:15:48 - train: epoch 0027, iter [03500, 05004], lr: 0.100000, loss: 5.3342, tea_CELoss: 2.3895 stu_CELoss: 2.5273 DMLLoss: 0.4174 
2022-03-14 07:16:21 - train: epoch 0027, iter [03600, 05004], lr: 0.100000, loss: 5.1028, tea_CELoss: 2.2673 stu_CELoss: 2.4657 DMLLoss: 0.3698 
2022-03-14 07:16:54 - train: epoch 0027, iter [03700, 05004], lr: 0.100000, loss: 5.0711, tea_CELoss: 2.2705 stu_CELoss: 2.3545 DMLLoss: 0.4460 
2022-03-14 07:17:27 - train: epoch 0027, iter [03800, 05004], lr: 0.100000, loss: 4.4333, tea_CELoss: 1.9306 stu_CELoss: 2.1430 DMLLoss: 0.3597 
2022-03-14 07:18:00 - train: epoch 0027, iter [03900, 05004], lr: 0.100000, loss: 4.8166, tea_CELoss: 2.1602 stu_CELoss: 2.2666 DMLLoss: 0.3898 
2022-03-14 07:18:33 - train: epoch 0027, iter [04000, 05004], lr: 0.100000, loss: 5.2440, tea_CELoss: 2.3900 stu_CELoss: 2.4592 DMLLoss: 0.3948 
2022-03-14 07:19:07 - train: epoch 0027, iter [04100, 05004], lr: 0.100000, loss: 4.9678, tea_CELoss: 2.2029 stu_CELoss: 2.3778 DMLLoss: 0.3871 
2022-03-14 07:19:39 - train: epoch 0027, iter [04200, 05004], lr: 0.100000, loss: 4.9006, tea_CELoss: 2.1919 stu_CELoss: 2.2831 DMLLoss: 0.4257 
2022-03-14 07:20:13 - train: epoch 0027, iter [04300, 05004], lr: 0.100000, loss: 4.8199, tea_CELoss: 2.1436 stu_CELoss: 2.2940 DMLLoss: 0.3824 
2022-03-14 07:20:46 - train: epoch 0027, iter [04400, 05004], lr: 0.100000, loss: 5.2136, tea_CELoss: 2.2957 stu_CELoss: 2.5163 DMLLoss: 0.4016 
2022-03-14 07:21:19 - train: epoch 0027, iter [04500, 05004], lr: 0.100000, loss: 4.9610, tea_CELoss: 2.1845 stu_CELoss: 2.2948 DMLLoss: 0.4817 
2022-03-14 07:21:51 - train: epoch 0027, iter [04600, 05004], lr: 0.100000, loss: 4.7128, tea_CELoss: 2.0826 stu_CELoss: 2.2520 DMLLoss: 0.3782 
2022-03-14 07:22:24 - train: epoch 0027, iter [04700, 05004], lr: 0.100000, loss: 5.4297, tea_CELoss: 2.4477 stu_CELoss: 2.5556 DMLLoss: 0.4264 
2022-03-14 07:22:57 - train: epoch 0027, iter [04800, 05004], lr: 0.100000, loss: 5.2539, tea_CELoss: 2.3654 stu_CELoss: 2.5036 DMLLoss: 0.3848 
2022-03-14 07:23:31 - train: epoch 0027, iter [04900, 05004], lr: 0.100000, loss: 4.6767, tea_CELoss: 2.0984 stu_CELoss: 2.1972 DMLLoss: 0.3811 
2022-03-14 07:24:02 - train: epoch 0027, iter [05000, 05004], lr: 0.100000, loss: 4.8656, tea_CELoss: 2.1729 stu_CELoss: 2.2735 DMLLoss: 0.4193 
2022-03-14 07:24:03 - train: epoch 027, train_loss: 4.9394
2022-03-14 07:26:32 - eval: epoch: 027, tea_acc1: 54.934%, tea_acc5: 79.824%, tea_test_loss: 1.9080, stu_acc1: 52.980%, stu_acc5: 78.276%, stu_test_loss: 2.0089
2022-03-14 07:26:33 - until epoch: 027, tea_best_acc1: 54.934%, stu_best_acc1: 52.980%
2022-03-14 07:26:33 - epoch 028 lr: 0.1
2022-03-14 07:27:10 - train: epoch 0028, iter [00100, 05004], lr: 0.100000, loss: 4.5107, tea_CELoss: 2.0290 stu_CELoss: 2.1135 DMLLoss: 0.3682 
2022-03-14 07:27:43 - train: epoch 0028, iter [00200, 05004], lr: 0.100000, loss: 5.0461, tea_CELoss: 2.2687 stu_CELoss: 2.3519 DMLLoss: 0.4255 
2022-03-14 07:28:17 - train: epoch 0028, iter [00300, 05004], lr: 0.100000, loss: 5.0525, tea_CELoss: 2.2548 stu_CELoss: 2.4316 DMLLoss: 0.3661 
2022-03-14 07:28:50 - train: epoch 0028, iter [00400, 05004], lr: 0.100000, loss: 4.9940, tea_CELoss: 2.2216 stu_CELoss: 2.3815 DMLLoss: 0.3909 
2022-03-14 07:29:22 - train: epoch 0028, iter [00500, 05004], lr: 0.100000, loss: 4.6861, tea_CELoss: 2.0589 stu_CELoss: 2.2069 DMLLoss: 0.4203 
2022-03-14 07:29:56 - train: epoch 0028, iter [00600, 05004], lr: 0.100000, loss: 5.1888, tea_CELoss: 2.3392 stu_CELoss: 2.4707 DMLLoss: 0.3789 
2022-03-14 07:30:29 - train: epoch 0028, iter [00700, 05004], lr: 0.100000, loss: 5.3058, tea_CELoss: 2.3641 stu_CELoss: 2.5432 DMLLoss: 0.3985 
2022-03-14 07:31:02 - train: epoch 0028, iter [00800, 05004], lr: 0.100000, loss: 4.4871, tea_CELoss: 2.0058 stu_CELoss: 2.1373 DMLLoss: 0.3440 
2022-03-14 07:31:35 - train: epoch 0028, iter [00900, 05004], lr: 0.100000, loss: 4.5047, tea_CELoss: 2.0157 stu_CELoss: 2.1357 DMLLoss: 0.3533 
2022-03-14 07:32:09 - train: epoch 0028, iter [01000, 05004], lr: 0.100000, loss: 4.9257, tea_CELoss: 2.1917 stu_CELoss: 2.3415 DMLLoss: 0.3925 
2022-03-14 07:32:42 - train: epoch 0028, iter [01100, 05004], lr: 0.100000, loss: 4.5628, tea_CELoss: 2.0488 stu_CELoss: 2.1441 DMLLoss: 0.3699 
2022-03-14 07:33:15 - train: epoch 0028, iter [01200, 05004], lr: 0.100000, loss: 4.8235, tea_CELoss: 2.1598 stu_CELoss: 2.2759 DMLLoss: 0.3878 
2022-03-14 07:33:48 - train: epoch 0028, iter [01300, 05004], lr: 0.100000, loss: 4.9050, tea_CELoss: 2.2051 stu_CELoss: 2.3119 DMLLoss: 0.3881 
2022-03-14 07:34:21 - train: epoch 0028, iter [01400, 05004], lr: 0.100000, loss: 5.2041, tea_CELoss: 2.3032 stu_CELoss: 2.4676 DMLLoss: 0.4333 
2022-03-14 07:34:54 - train: epoch 0028, iter [01500, 05004], lr: 0.100000, loss: 4.9109, tea_CELoss: 2.2198 stu_CELoss: 2.3245 DMLLoss: 0.3666 
2022-03-14 07:35:27 - train: epoch 0028, iter [01600, 05004], lr: 0.100000, loss: 4.7983, tea_CELoss: 2.1771 stu_CELoss: 2.2416 DMLLoss: 0.3796 
2022-03-14 07:36:00 - train: epoch 0028, iter [01700, 05004], lr: 0.100000, loss: 5.2270, tea_CELoss: 2.4068 stu_CELoss: 2.4407 DMLLoss: 0.3794 
2022-03-14 07:36:34 - train: epoch 0028, iter [01800, 05004], lr: 0.100000, loss: 4.8237, tea_CELoss: 2.1437 stu_CELoss: 2.2944 DMLLoss: 0.3856 
2022-03-14 07:37:07 - train: epoch 0028, iter [01900, 05004], lr: 0.100000, loss: 4.8340, tea_CELoss: 2.1972 stu_CELoss: 2.2613 DMLLoss: 0.3755 
2022-03-14 07:37:40 - train: epoch 0028, iter [02000, 05004], lr: 0.100000, loss: 5.0389, tea_CELoss: 2.2499 stu_CELoss: 2.3751 DMLLoss: 0.4139 
2022-03-14 07:38:12 - train: epoch 0028, iter [02100, 05004], lr: 0.100000, loss: 5.5286, tea_CELoss: 2.4808 stu_CELoss: 2.6336 DMLLoss: 0.4143 
2022-03-14 07:38:46 - train: epoch 0028, iter [02200, 05004], lr: 0.100000, loss: 5.0252, tea_CELoss: 2.2759 stu_CELoss: 2.3631 DMLLoss: 0.3862 
2022-03-14 07:39:19 - train: epoch 0028, iter [02300, 05004], lr: 0.100000, loss: 4.8765, tea_CELoss: 2.1553 stu_CELoss: 2.3227 DMLLoss: 0.3985 
2022-03-14 07:39:52 - train: epoch 0028, iter [02400, 05004], lr: 0.100000, loss: 5.4363, tea_CELoss: 2.4589 stu_CELoss: 2.5577 DMLLoss: 0.4197 
2022-03-14 07:40:26 - train: epoch 0028, iter [02500, 05004], lr: 0.100000, loss: 5.2276, tea_CELoss: 2.3252 stu_CELoss: 2.4986 DMLLoss: 0.4038 
2022-03-14 07:40:58 - train: epoch 0028, iter [02600, 05004], lr: 0.100000, loss: 4.7283, tea_CELoss: 2.1238 stu_CELoss: 2.2455 DMLLoss: 0.3589 
2022-03-14 07:41:32 - train: epoch 0028, iter [02700, 05004], lr: 0.100000, loss: 4.8377, tea_CELoss: 2.1300 stu_CELoss: 2.3096 DMLLoss: 0.3981 
2022-03-14 07:42:05 - train: epoch 0028, iter [02800, 05004], lr: 0.100000, loss: 5.1958, tea_CELoss: 2.3271 stu_CELoss: 2.4764 DMLLoss: 0.3923 
2022-03-14 07:42:39 - train: epoch 0028, iter [02900, 05004], lr: 0.100000, loss: 5.0278, tea_CELoss: 2.3209 stu_CELoss: 2.3282 DMLLoss: 0.3787 
2022-03-14 07:43:12 - train: epoch 0028, iter [03000, 05004], lr: 0.100000, loss: 4.9421, tea_CELoss: 2.2103 stu_CELoss: 2.3316 DMLLoss: 0.4002 
2022-03-14 07:43:45 - train: epoch 0028, iter [03100, 05004], lr: 0.100000, loss: 4.9678, tea_CELoss: 2.2112 stu_CELoss: 2.3811 DMLLoss: 0.3755 
2022-03-14 07:44:18 - train: epoch 0028, iter [03200, 05004], lr: 0.100000, loss: 4.4708, tea_CELoss: 1.9431 stu_CELoss: 2.1549 DMLLoss: 0.3728 
2022-03-14 07:44:51 - train: epoch 0028, iter [03300, 05004], lr: 0.100000, loss: 5.1579, tea_CELoss: 2.3437 stu_CELoss: 2.4134 DMLLoss: 0.4008 
2022-03-14 07:45:24 - train: epoch 0028, iter [03400, 05004], lr: 0.100000, loss: 5.2218, tea_CELoss: 2.3609 stu_CELoss: 2.4816 DMLLoss: 0.3793 
2022-03-14 07:45:57 - train: epoch 0028, iter [03500, 05004], lr: 0.100000, loss: 4.8857, tea_CELoss: 2.2551 stu_CELoss: 2.2771 DMLLoss: 0.3535 
2022-03-14 07:46:30 - train: epoch 0028, iter [03600, 05004], lr: 0.100000, loss: 4.7967, tea_CELoss: 2.1763 stu_CELoss: 2.2676 DMLLoss: 0.3527 
2022-03-14 07:47:03 - train: epoch 0028, iter [03700, 05004], lr: 0.100000, loss: 5.0208, tea_CELoss: 2.2770 stu_CELoss: 2.4029 DMLLoss: 0.3409 
2022-03-14 07:47:37 - train: epoch 0028, iter [03800, 05004], lr: 0.100000, loss: 4.3572, tea_CELoss: 1.9669 stu_CELoss: 1.9884 DMLLoss: 0.4019 
2022-03-14 07:48:10 - train: epoch 0028, iter [03900, 05004], lr: 0.100000, loss: 5.2272, tea_CELoss: 2.3698 stu_CELoss: 2.4732 DMLLoss: 0.3842 
2022-03-14 07:48:42 - train: epoch 0028, iter [04000, 05004], lr: 0.100000, loss: 5.0465, tea_CELoss: 2.2692 stu_CELoss: 2.3491 DMLLoss: 0.4282 
2022-03-14 07:49:16 - train: epoch 0028, iter [04100, 05004], lr: 0.100000, loss: 5.1243, tea_CELoss: 2.3241 stu_CELoss: 2.4074 DMLLoss: 0.3928 
2022-03-14 07:49:49 - train: epoch 0028, iter [04200, 05004], lr: 0.100000, loss: 5.0409, tea_CELoss: 2.2786 stu_CELoss: 2.3925 DMLLoss: 0.3699 
2022-03-14 07:50:21 - train: epoch 0028, iter [04300, 05004], lr: 0.100000, loss: 4.8875, tea_CELoss: 2.1957 stu_CELoss: 2.2716 DMLLoss: 0.4203 
2022-03-14 07:50:55 - train: epoch 0028, iter [04400, 05004], lr: 0.100000, loss: 4.6351, tea_CELoss: 2.0588 stu_CELoss: 2.2138 DMLLoss: 0.3625 
2022-03-14 07:51:28 - train: epoch 0028, iter [04500, 05004], lr: 0.100000, loss: 5.1216, tea_CELoss: 2.3085 stu_CELoss: 2.4020 DMLLoss: 0.4110 
2022-03-14 07:52:01 - train: epoch 0028, iter [04600, 05004], lr: 0.100000, loss: 4.9164, tea_CELoss: 2.2412 stu_CELoss: 2.3079 DMLLoss: 0.3673 
2022-03-14 07:52:34 - train: epoch 0028, iter [04700, 05004], lr: 0.100000, loss: 5.0971, tea_CELoss: 2.3197 stu_CELoss: 2.4050 DMLLoss: 0.3724 
2022-03-14 07:53:07 - train: epoch 0028, iter [04800, 05004], lr: 0.100000, loss: 4.7776, tea_CELoss: 2.1339 stu_CELoss: 2.2410 DMLLoss: 0.4028 
2022-03-14 07:53:41 - train: epoch 0028, iter [04900, 05004], lr: 0.100000, loss: 5.1235, tea_CELoss: 2.2417 stu_CELoss: 2.4883 DMLLoss: 0.3935 
2022-03-14 07:54:12 - train: epoch 0028, iter [05000, 05004], lr: 0.100000, loss: 4.7785, tea_CELoss: 2.1592 stu_CELoss: 2.2379 DMLLoss: 0.3814 
2022-03-14 07:54:13 - train: epoch 028, train_loss: 4.9366
2022-03-14 07:56:41 - eval: epoch: 028, tea_acc1: 52.900%, tea_acc5: 78.348%, tea_test_loss: 2.0023, stu_acc1: 51.840%, stu_acc5: 77.266%, stu_test_loss: 2.0734
2022-03-14 07:56:42 - until epoch: 028, tea_best_acc1: 54.934%, stu_best_acc1: 52.980%
2022-03-14 07:56:42 - epoch 029 lr: 0.1
2022-03-14 07:57:20 - train: epoch 0029, iter [00100, 05004], lr: 0.100000, loss: 4.9546, tea_CELoss: 2.1752 stu_CELoss: 2.3880 DMLLoss: 0.3914 
2022-03-14 07:57:53 - train: epoch 0029, iter [00200, 05004], lr: 0.100000, loss: 4.9014, tea_CELoss: 2.1592 stu_CELoss: 2.3037 DMLLoss: 0.4384 
2022-03-14 07:58:27 - train: epoch 0029, iter [00300, 05004], lr: 0.100000, loss: 5.4693, tea_CELoss: 2.4720 stu_CELoss: 2.6000 DMLLoss: 0.3974 
2022-03-14 07:59:00 - train: epoch 0029, iter [00400, 05004], lr: 0.100000, loss: 5.2253, tea_CELoss: 2.4011 stu_CELoss: 2.4514 DMLLoss: 0.3728 
2022-03-14 07:59:33 - train: epoch 0029, iter [00500, 05004], lr: 0.100000, loss: 5.1591, tea_CELoss: 2.2608 stu_CELoss: 2.4394 DMLLoss: 0.4589 
2022-03-14 08:00:06 - train: epoch 0029, iter [00600, 05004], lr: 0.100000, loss: 5.2658, tea_CELoss: 2.3331 stu_CELoss: 2.5027 DMLLoss: 0.4300 
2022-03-14 08:00:39 - train: epoch 0029, iter [00700, 05004], lr: 0.100000, loss: 4.3497, tea_CELoss: 1.8668 stu_CELoss: 2.0682 DMLLoss: 0.4147 
2022-03-14 08:01:12 - train: epoch 0029, iter [00800, 05004], lr: 0.100000, loss: 4.9063, tea_CELoss: 2.1774 stu_CELoss: 2.3328 DMLLoss: 0.3961 
2022-03-14 08:01:46 - train: epoch 0029, iter [00900, 05004], lr: 0.100000, loss: 4.9737, tea_CELoss: 2.2025 stu_CELoss: 2.3529 DMLLoss: 0.4183 
2022-03-14 08:02:19 - train: epoch 0029, iter [01000, 05004], lr: 0.100000, loss: 4.8762, tea_CELoss: 2.1782 stu_CELoss: 2.3279 DMLLoss: 0.3701 
2022-03-14 08:02:52 - train: epoch 0029, iter [01100, 05004], lr: 0.100000, loss: 4.8766, tea_CELoss: 2.1801 stu_CELoss: 2.2816 DMLLoss: 0.4149 
2022-03-14 08:03:25 - train: epoch 0029, iter [01200, 05004], lr: 0.100000, loss: 5.0865, tea_CELoss: 2.2780 stu_CELoss: 2.3813 DMLLoss: 0.4272 
2022-03-14 08:03:58 - train: epoch 0029, iter [01300, 05004], lr: 0.100000, loss: 4.8549, tea_CELoss: 2.1543 stu_CELoss: 2.3088 DMLLoss: 0.3917 
2022-03-14 08:04:31 - train: epoch 0029, iter [01400, 05004], lr: 0.100000, loss: 4.9450, tea_CELoss: 2.2258 stu_CELoss: 2.3340 DMLLoss: 0.3852 
2022-03-14 08:05:04 - train: epoch 0029, iter [01500, 05004], lr: 0.100000, loss: 4.8403, tea_CELoss: 2.1658 stu_CELoss: 2.2809 DMLLoss: 0.3936 
2022-03-14 08:05:38 - train: epoch 0029, iter [01600, 05004], lr: 0.100000, loss: 5.0189, tea_CELoss: 2.2604 stu_CELoss: 2.3477 DMLLoss: 0.4108 
2022-03-14 08:06:11 - train: epoch 0029, iter [01700, 05004], lr: 0.100000, loss: 4.6445, tea_CELoss: 2.0483 stu_CELoss: 2.2199 DMLLoss: 0.3763 
2022-03-14 08:06:44 - train: epoch 0029, iter [01800, 05004], lr: 0.100000, loss: 5.1682, tea_CELoss: 2.3326 stu_CELoss: 2.4228 DMLLoss: 0.4129 
2022-03-14 08:07:17 - train: epoch 0029, iter [01900, 05004], lr: 0.100000, loss: 4.8474, tea_CELoss: 2.1513 stu_CELoss: 2.2852 DMLLoss: 0.4109 
2022-03-14 08:07:50 - train: epoch 0029, iter [02000, 05004], lr: 0.100000, loss: 4.7175, tea_CELoss: 2.1328 stu_CELoss: 2.2109 DMLLoss: 0.3739 
2022-03-14 08:08:23 - train: epoch 0029, iter [02100, 05004], lr: 0.100000, loss: 4.9743, tea_CELoss: 2.2759 stu_CELoss: 2.2798 DMLLoss: 0.4187 
2022-03-14 08:08:56 - train: epoch 0029, iter [02200, 05004], lr: 0.100000, loss: 4.9946, tea_CELoss: 2.2083 stu_CELoss: 2.4025 DMLLoss: 0.3838 
2022-03-14 08:09:30 - train: epoch 0029, iter [02300, 05004], lr: 0.100000, loss: 4.9337, tea_CELoss: 2.2054 stu_CELoss: 2.3381 DMLLoss: 0.3901 
2022-03-14 08:10:03 - train: epoch 0029, iter [02400, 05004], lr: 0.100000, loss: 4.5279, tea_CELoss: 2.0221 stu_CELoss: 2.1418 DMLLoss: 0.3640 
2022-03-14 08:10:36 - train: epoch 0029, iter [02500, 05004], lr: 0.100000, loss: 5.1810, tea_CELoss: 2.3285 stu_CELoss: 2.4550 DMLLoss: 0.3975 
2022-03-14 08:11:10 - train: epoch 0029, iter [02600, 05004], lr: 0.100000, loss: 5.0882, tea_CELoss: 2.2737 stu_CELoss: 2.4148 DMLLoss: 0.3997 
2022-03-14 08:11:43 - train: epoch 0029, iter [02700, 05004], lr: 0.100000, loss: 4.8581, tea_CELoss: 2.1736 stu_CELoss: 2.2744 DMLLoss: 0.4100 
2022-03-14 08:12:16 - train: epoch 0029, iter [02800, 05004], lr: 0.100000, loss: 4.7562, tea_CELoss: 2.1303 stu_CELoss: 2.2520 DMLLoss: 0.3739 
2022-03-14 08:12:49 - train: epoch 0029, iter [02900, 05004], lr: 0.100000, loss: 4.8955, tea_CELoss: 2.1832 stu_CELoss: 2.3358 DMLLoss: 0.3765 
2022-03-14 08:13:22 - train: epoch 0029, iter [03000, 05004], lr: 0.100000, loss: 5.1190, tea_CELoss: 2.3067 stu_CELoss: 2.3958 DMLLoss: 0.4166 
2022-03-14 08:13:55 - train: epoch 0029, iter [03100, 05004], lr: 0.100000, loss: 5.0669, tea_CELoss: 2.2727 stu_CELoss: 2.3868 DMLLoss: 0.4074 
2022-03-14 08:14:29 - train: epoch 0029, iter [03200, 05004], lr: 0.100000, loss: 5.0203, tea_CELoss: 2.1906 stu_CELoss: 2.4323 DMLLoss: 0.3974 
2022-03-14 08:15:02 - train: epoch 0029, iter [03300, 05004], lr: 0.100000, loss: 4.5710, tea_CELoss: 2.0800 stu_CELoss: 2.1397 DMLLoss: 0.3512 
2022-03-14 08:15:36 - train: epoch 0029, iter [03400, 05004], lr: 0.100000, loss: 4.8117, tea_CELoss: 2.1438 stu_CELoss: 2.2741 DMLLoss: 0.3937 
2022-03-14 08:16:09 - train: epoch 0029, iter [03500, 05004], lr: 0.100000, loss: 5.0826, tea_CELoss: 2.2842 stu_CELoss: 2.3862 DMLLoss: 0.4122 
2022-03-14 08:16:42 - train: epoch 0029, iter [03600, 05004], lr: 0.100000, loss: 4.8784, tea_CELoss: 2.1947 stu_CELoss: 2.2831 DMLLoss: 0.4007 
2022-03-14 08:17:15 - train: epoch 0029, iter [03700, 05004], lr: 0.100000, loss: 4.6964, tea_CELoss: 2.1363 stu_CELoss: 2.1815 DMLLoss: 0.3786 
2022-03-14 08:17:48 - train: epoch 0029, iter [03800, 05004], lr: 0.100000, loss: 4.7386, tea_CELoss: 2.1632 stu_CELoss: 2.1515 DMLLoss: 0.4239 
2022-03-14 08:18:21 - train: epoch 0029, iter [03900, 05004], lr: 0.100000, loss: 4.7138, tea_CELoss: 2.1528 stu_CELoss: 2.1786 DMLLoss: 0.3824 
2022-03-14 08:18:55 - train: epoch 0029, iter [04000, 05004], lr: 0.100000, loss: 5.0518, tea_CELoss: 2.2420 stu_CELoss: 2.3935 DMLLoss: 0.4164 
2022-03-14 08:19:28 - train: epoch 0029, iter [04100, 05004], lr: 0.100000, loss: 4.8984, tea_CELoss: 2.2044 stu_CELoss: 2.2921 DMLLoss: 0.4020 
2022-03-14 08:20:01 - train: epoch 0029, iter [04200, 05004], lr: 0.100000, loss: 4.9555, tea_CELoss: 2.2230 stu_CELoss: 2.3268 DMLLoss: 0.4057 
2022-03-14 08:20:35 - train: epoch 0029, iter [04300, 05004], lr: 0.100000, loss: 4.9324, tea_CELoss: 2.1946 stu_CELoss: 2.3556 DMLLoss: 0.3821 
2022-03-14 08:21:07 - train: epoch 0029, iter [04400, 05004], lr: 0.100000, loss: 5.1218, tea_CELoss: 2.3252 stu_CELoss: 2.4105 DMLLoss: 0.3862 
2022-03-14 08:21:41 - train: epoch 0029, iter [04500, 05004], lr: 0.100000, loss: 5.4264, tea_CELoss: 2.4612 stu_CELoss: 2.5297 DMLLoss: 0.4355 
2022-03-14 08:22:13 - train: epoch 0029, iter [04600, 05004], lr: 0.100000, loss: 5.1444, tea_CELoss: 2.2950 stu_CELoss: 2.4514 DMLLoss: 0.3980 
2022-03-14 08:22:47 - train: epoch 0029, iter [04700, 05004], lr: 0.100000, loss: 4.3198, tea_CELoss: 1.9580 stu_CELoss: 2.0273 DMLLoss: 0.3345 
2022-03-14 08:23:20 - train: epoch 0029, iter [04800, 05004], lr: 0.100000, loss: 4.8563, tea_CELoss: 2.1419 stu_CELoss: 2.3182 DMLLoss: 0.3962 
2022-03-14 08:23:53 - train: epoch 0029, iter [04900, 05004], lr: 0.100000, loss: 5.2256, tea_CELoss: 2.3947 stu_CELoss: 2.3990 DMLLoss: 0.4319 
2022-03-14 08:24:25 - train: epoch 0029, iter [05000, 05004], lr: 0.100000, loss: 4.4492, tea_CELoss: 2.0365 stu_CELoss: 2.0785 DMLLoss: 0.3342 
2022-03-14 08:24:26 - train: epoch 029, train_loss: 4.9370
2022-03-14 08:26:53 - eval: epoch: 029, tea_acc1: 54.348%, tea_acc5: 79.488%, tea_test_loss: 1.9362, stu_acc1: 52.320%, stu_acc5: 77.768%, stu_test_loss: 2.0368
2022-03-14 08:26:54 - until epoch: 029, tea_best_acc1: 54.934%, stu_best_acc1: 52.980%
2022-03-14 08:26:54 - epoch 030 lr: 0.1
2022-03-14 08:27:32 - train: epoch 0030, iter [00100, 05004], lr: 0.100000, loss: 4.9377, tea_CELoss: 2.1917 stu_CELoss: 2.3763 DMLLoss: 0.3697 
2022-03-14 08:28:05 - train: epoch 0030, iter [00200, 05004], lr: 0.100000, loss: 4.8933, tea_CELoss: 2.1659 stu_CELoss: 2.3027 DMLLoss: 0.4246 
2022-03-14 08:28:38 - train: epoch 0030, iter [00300, 05004], lr: 0.100000, loss: 4.6518, tea_CELoss: 2.0867 stu_CELoss: 2.1643 DMLLoss: 0.4009 
2022-03-14 08:29:11 - train: epoch 0030, iter [00400, 05004], lr: 0.100000, loss: 5.0258, tea_CELoss: 2.2606 stu_CELoss: 2.3695 DMLLoss: 0.3957 
2022-03-14 08:29:44 - train: epoch 0030, iter [00500, 05004], lr: 0.100000, loss: 5.1472, tea_CELoss: 2.3076 stu_CELoss: 2.4286 DMLLoss: 0.4110 
2022-03-14 08:30:17 - train: epoch 0030, iter [00600, 05004], lr: 0.100000, loss: 4.9408, tea_CELoss: 2.2099 stu_CELoss: 2.3275 DMLLoss: 0.4034 
2022-03-14 08:30:50 - train: epoch 0030, iter [00700, 05004], lr: 0.100000, loss: 4.7985, tea_CELoss: 2.1175 stu_CELoss: 2.2764 DMLLoss: 0.4047 
2022-03-14 08:31:24 - train: epoch 0030, iter [00800, 05004], lr: 0.100000, loss: 4.8742, tea_CELoss: 2.2090 stu_CELoss: 2.2933 DMLLoss: 0.3718 
2022-03-14 08:31:56 - train: epoch 0030, iter [00900, 05004], lr: 0.100000, loss: 4.9953, tea_CELoss: 2.2399 stu_CELoss: 2.3762 DMLLoss: 0.3792 
2022-03-14 08:32:29 - train: epoch 0030, iter [01000, 05004], lr: 0.100000, loss: 4.6086, tea_CELoss: 2.0404 stu_CELoss: 2.1536 DMLLoss: 0.4146 
2022-03-14 08:33:02 - train: epoch 0030, iter [01100, 05004], lr: 0.100000, loss: 4.7001, tea_CELoss: 2.0730 stu_CELoss: 2.2308 DMLLoss: 0.3963 
2022-03-14 08:33:35 - train: epoch 0030, iter [01200, 05004], lr: 0.100000, loss: 5.0889, tea_CELoss: 2.2403 stu_CELoss: 2.4299 DMLLoss: 0.4188 
2022-03-14 08:34:08 - train: epoch 0030, iter [01300, 05004], lr: 0.100000, loss: 4.6367, tea_CELoss: 2.0911 stu_CELoss: 2.1749 DMLLoss: 0.3707 
2022-03-14 08:34:41 - train: epoch 0030, iter [01400, 05004], lr: 0.100000, loss: 4.5825, tea_CELoss: 2.0746 stu_CELoss: 2.1425 DMLLoss: 0.3654 
2022-03-14 08:35:15 - train: epoch 0030, iter [01500, 05004], lr: 0.100000, loss: 4.7290, tea_CELoss: 2.1206 stu_CELoss: 2.2028 DMLLoss: 0.4056 
2022-03-14 08:35:48 - train: epoch 0030, iter [01600, 05004], lr: 0.100000, loss: 5.0841, tea_CELoss: 2.2654 stu_CELoss: 2.4008 DMLLoss: 0.4179 
2022-03-14 08:36:21 - train: epoch 0030, iter [01700, 05004], lr: 0.100000, loss: 5.2763, tea_CELoss: 2.3666 stu_CELoss: 2.5386 DMLLoss: 0.3712 
2022-03-14 08:36:54 - train: epoch 0030, iter [01800, 05004], lr: 0.100000, loss: 5.0189, tea_CELoss: 2.2614 stu_CELoss: 2.3584 DMLLoss: 0.3991 
2022-03-14 08:37:28 - train: epoch 0030, iter [01900, 05004], lr: 0.100000, loss: 5.0699, tea_CELoss: 2.3017 stu_CELoss: 2.3852 DMLLoss: 0.3831 
2022-03-14 08:38:01 - train: epoch 0030, iter [02000, 05004], lr: 0.100000, loss: 4.8257, tea_CELoss: 2.1565 stu_CELoss: 2.2806 DMLLoss: 0.3886 
2022-03-14 08:38:34 - train: epoch 0030, iter [02100, 05004], lr: 0.100000, loss: 5.1979, tea_CELoss: 2.2739 stu_CELoss: 2.4953 DMLLoss: 0.4287 
2022-03-14 08:39:08 - train: epoch 0030, iter [02200, 05004], lr: 0.100000, loss: 5.0940, tea_CELoss: 2.2495 stu_CELoss: 2.4550 DMLLoss: 0.3894 
2022-03-14 08:39:41 - train: epoch 0030, iter [02300, 05004], lr: 0.100000, loss: 5.0936, tea_CELoss: 2.2474 stu_CELoss: 2.4254 DMLLoss: 0.4209 
2022-03-14 08:40:14 - train: epoch 0030, iter [02400, 05004], lr: 0.100000, loss: 5.1445, tea_CELoss: 2.3140 stu_CELoss: 2.4190 DMLLoss: 0.4114 
2022-03-14 08:40:48 - train: epoch 0030, iter [02500, 05004], lr: 0.100000, loss: 5.0994, tea_CELoss: 2.2888 stu_CELoss: 2.4158 DMLLoss: 0.3948 
2022-03-14 08:41:21 - train: epoch 0030, iter [02600, 05004], lr: 0.100000, loss: 5.0565, tea_CELoss: 2.2175 stu_CELoss: 2.4221 DMLLoss: 0.4168 
2022-03-14 08:41:54 - train: epoch 0030, iter [02700, 05004], lr: 0.100000, loss: 4.6778, tea_CELoss: 2.1173 stu_CELoss: 2.1962 DMLLoss: 0.3643 
2022-03-14 08:42:27 - train: epoch 0030, iter [02800, 05004], lr: 0.100000, loss: 4.8692, tea_CELoss: 2.2143 stu_CELoss: 2.3005 DMLLoss: 0.3544 
2022-03-14 08:43:00 - train: epoch 0030, iter [02900, 05004], lr: 0.100000, loss: 4.7470, tea_CELoss: 2.1730 stu_CELoss: 2.1865 DMLLoss: 0.3876 
2022-03-14 08:43:34 - train: epoch 0030, iter [03000, 05004], lr: 0.100000, loss: 5.3198, tea_CELoss: 2.4006 stu_CELoss: 2.5023 DMLLoss: 0.4169 
2022-03-14 08:44:07 - train: epoch 0030, iter [03100, 05004], lr: 0.100000, loss: 5.2556, tea_CELoss: 2.3425 stu_CELoss: 2.4879 DMLLoss: 0.4251 
2022-03-14 08:44:40 - train: epoch 0030, iter [03200, 05004], lr: 0.100000, loss: 4.5495, tea_CELoss: 2.0339 stu_CELoss: 2.1381 DMLLoss: 0.3775 
2022-03-14 08:45:13 - train: epoch 0030, iter [03300, 05004], lr: 0.100000, loss: 5.0868, tea_CELoss: 2.3100 stu_CELoss: 2.4179 DMLLoss: 0.3589 
2022-03-14 08:45:46 - train: epoch 0030, iter [03400, 05004], lr: 0.100000, loss: 4.6816, tea_CELoss: 2.0841 stu_CELoss: 2.2091 DMLLoss: 0.3884 
2022-03-14 08:46:19 - train: epoch 0030, iter [03500, 05004], lr: 0.100000, loss: 5.0675, tea_CELoss: 2.2612 stu_CELoss: 2.4075 DMLLoss: 0.3988 
2022-03-14 08:46:54 - train: epoch 0030, iter [03600, 05004], lr: 0.100000, loss: 4.9590, tea_CELoss: 2.1816 stu_CELoss: 2.3821 DMLLoss: 0.3953 
2022-03-14 08:47:27 - train: epoch 0030, iter [03700, 05004], lr: 0.100000, loss: 4.6725, tea_CELoss: 2.1217 stu_CELoss: 2.1627 DMLLoss: 0.3881 
2022-03-14 08:48:00 - train: epoch 0030, iter [03800, 05004], lr: 0.100000, loss: 4.7568, tea_CELoss: 2.1696 stu_CELoss: 2.2424 DMLLoss: 0.3449 
2022-03-14 08:48:33 - train: epoch 0030, iter [03900, 05004], lr: 0.100000, loss: 4.6116, tea_CELoss: 2.0977 stu_CELoss: 2.1559 DMLLoss: 0.3580 
2022-03-14 08:49:05 - train: epoch 0030, iter [04000, 05004], lr: 0.100000, loss: 4.8007, tea_CELoss: 2.1676 stu_CELoss: 2.2305 DMLLoss: 0.4026 
2022-03-14 08:49:39 - train: epoch 0030, iter [04100, 05004], lr: 0.100000, loss: 4.9268, tea_CELoss: 2.2111 stu_CELoss: 2.2904 DMLLoss: 0.4253 
2022-03-14 08:50:12 - train: epoch 0030, iter [04200, 05004], lr: 0.100000, loss: 5.0872, tea_CELoss: 2.3464 stu_CELoss: 2.3566 DMLLoss: 0.3842 
2022-03-14 08:50:46 - train: epoch 0030, iter [04300, 05004], lr: 0.100000, loss: 4.9001, tea_CELoss: 2.1890 stu_CELoss: 2.3538 DMLLoss: 0.3574 
2022-03-14 08:51:19 - train: epoch 0030, iter [04400, 05004], lr: 0.100000, loss: 4.8982, tea_CELoss: 2.1942 stu_CELoss: 2.3272 DMLLoss: 0.3769 
2022-03-14 08:51:52 - train: epoch 0030, iter [04500, 05004], lr: 0.100000, loss: 5.1432, tea_CELoss: 2.2759 stu_CELoss: 2.4897 DMLLoss: 0.3776 
2022-03-14 08:52:25 - train: epoch 0030, iter [04600, 05004], lr: 0.100000, loss: 4.7006, tea_CELoss: 2.1240 stu_CELoss: 2.1816 DMLLoss: 0.3950 
2022-03-14 08:52:58 - train: epoch 0030, iter [04700, 05004], lr: 0.100000, loss: 4.8824, tea_CELoss: 2.1742 stu_CELoss: 2.3328 DMLLoss: 0.3753 
2022-03-14 08:53:32 - train: epoch 0030, iter [04800, 05004], lr: 0.100000, loss: 4.8206, tea_CELoss: 2.1312 stu_CELoss: 2.2946 DMLLoss: 0.3948 
2022-03-14 08:54:05 - train: epoch 0030, iter [04900, 05004], lr: 0.100000, loss: 5.2687, tea_CELoss: 2.3834 stu_CELoss: 2.4954 DMLLoss: 0.3899 
2022-03-14 08:54:36 - train: epoch 0030, iter [05000, 05004], lr: 0.100000, loss: 5.2275, tea_CELoss: 2.3725 stu_CELoss: 2.4440 DMLLoss: 0.4111 
2022-03-14 08:54:37 - train: epoch 030, train_loss: 4.9297
2022-03-14 08:57:06 - eval: epoch: 030, tea_acc1: 53.746%, tea_acc5: 79.086%, tea_test_loss: 1.9690, stu_acc1: 51.736%, stu_acc5: 77.460%, stu_test_loss: 2.0682
2022-03-14 08:57:07 - until epoch: 030, tea_best_acc1: 54.934%, stu_best_acc1: 52.980%
2022-03-14 08:57:07 - epoch 031 lr: 0.010000000000000002
2022-03-14 08:57:44 - train: epoch 0031, iter [00100, 05004], lr: 0.010000, loss: 4.3715, tea_CELoss: 1.9927 stu_CELoss: 2.1365 DMLLoss: 0.2422 
2022-03-14 08:58:18 - train: epoch 0031, iter [00200, 05004], lr: 0.010000, loss: 4.1237, tea_CELoss: 1.8804 stu_CELoss: 2.0088 DMLLoss: 0.2346 
2022-03-14 08:58:51 - train: epoch 0031, iter [00300, 05004], lr: 0.010000, loss: 3.9569, tea_CELoss: 1.8420 stu_CELoss: 1.8914 DMLLoss: 0.2235 
2022-03-14 08:59:25 - train: epoch 0031, iter [00400, 05004], lr: 0.010000, loss: 4.0076, tea_CELoss: 1.8273 stu_CELoss: 1.9515 DMLLoss: 0.2287 
2022-03-14 08:59:58 - train: epoch 0031, iter [00500, 05004], lr: 0.010000, loss: 4.2399, tea_CELoss: 1.9590 stu_CELoss: 2.0671 DMLLoss: 0.2138 
2022-03-14 09:00:31 - train: epoch 0031, iter [00600, 05004], lr: 0.010000, loss: 3.9392, tea_CELoss: 1.8047 stu_CELoss: 1.9126 DMLLoss: 0.2219 
2022-03-14 09:01:04 - train: epoch 0031, iter [00700, 05004], lr: 0.010000, loss: 3.9986, tea_CELoss: 1.8452 stu_CELoss: 1.9213 DMLLoss: 0.2321 
2022-03-14 09:01:37 - train: epoch 0031, iter [00800, 05004], lr: 0.010000, loss: 4.0322, tea_CELoss: 1.8385 stu_CELoss: 1.9676 DMLLoss: 0.2261 
2022-03-14 09:02:10 - train: epoch 0031, iter [00900, 05004], lr: 0.010000, loss: 3.9714, tea_CELoss: 1.7953 stu_CELoss: 1.9624 DMLLoss: 0.2138 
2022-03-14 09:02:43 - train: epoch 0031, iter [01000, 05004], lr: 0.010000, loss: 4.2993, tea_CELoss: 1.9513 stu_CELoss: 2.1344 DMLLoss: 0.2136 
2022-03-14 09:03:17 - train: epoch 0031, iter [01100, 05004], lr: 0.010000, loss: 4.1129, tea_CELoss: 1.8520 stu_CELoss: 2.0298 DMLLoss: 0.2311 
2022-03-14 09:03:50 - train: epoch 0031, iter [01200, 05004], lr: 0.010000, loss: 3.9430, tea_CELoss: 1.8117 stu_CELoss: 1.9129 DMLLoss: 0.2183 
2022-03-14 09:04:23 - train: epoch 0031, iter [01300, 05004], lr: 0.010000, loss: 3.2435, tea_CELoss: 1.4589 stu_CELoss: 1.5861 DMLLoss: 0.1985 
2022-03-14 09:04:56 - train: epoch 0031, iter [01400, 05004], lr: 0.010000, loss: 3.9321, tea_CELoss: 1.8302 stu_CELoss: 1.8880 DMLLoss: 0.2139 
2022-03-14 09:05:29 - train: epoch 0031, iter [01500, 05004], lr: 0.010000, loss: 4.1598, tea_CELoss: 1.9056 stu_CELoss: 2.0290 DMLLoss: 0.2252 
2022-03-14 09:06:02 - train: epoch 0031, iter [01600, 05004], lr: 0.010000, loss: 3.7834, tea_CELoss: 1.7229 stu_CELoss: 1.8560 DMLLoss: 0.2045 
2022-03-14 09:06:35 - train: epoch 0031, iter [01700, 05004], lr: 0.010000, loss: 3.8316, tea_CELoss: 1.7311 stu_CELoss: 1.8849 DMLLoss: 0.2155 
2022-03-14 09:07:09 - train: epoch 0031, iter [01800, 05004], lr: 0.010000, loss: 3.3184, tea_CELoss: 1.5027 stu_CELoss: 1.6085 DMLLoss: 0.2071 
2022-03-14 09:07:42 - train: epoch 0031, iter [01900, 05004], lr: 0.010000, loss: 3.8805, tea_CELoss: 1.7388 stu_CELoss: 1.9098 DMLLoss: 0.2320 
2022-03-14 09:08:15 - train: epoch 0031, iter [02000, 05004], lr: 0.010000, loss: 3.7713, tea_CELoss: 1.7207 stu_CELoss: 1.8452 DMLLoss: 0.2054 
2022-03-14 09:08:48 - train: epoch 0031, iter [02100, 05004], lr: 0.010000, loss: 3.5509, tea_CELoss: 1.6349 stu_CELoss: 1.7256 DMLLoss: 0.1904 
2022-03-14 09:09:21 - train: epoch 0031, iter [02200, 05004], lr: 0.010000, loss: 3.5604, tea_CELoss: 1.6078 stu_CELoss: 1.7604 DMLLoss: 0.1922 
2022-03-14 09:09:55 - train: epoch 0031, iter [02300, 05004], lr: 0.010000, loss: 3.7113, tea_CELoss: 1.7126 stu_CELoss: 1.7945 DMLLoss: 0.2042 
2022-03-14 09:10:28 - train: epoch 0031, iter [02400, 05004], lr: 0.010000, loss: 3.7374, tea_CELoss: 1.7140 stu_CELoss: 1.8221 DMLLoss: 0.2013 
2022-03-14 09:11:01 - train: epoch 0031, iter [02500, 05004], lr: 0.010000, loss: 4.2766, tea_CELoss: 1.9792 stu_CELoss: 2.0830 DMLLoss: 0.2144 
2022-03-14 09:11:34 - train: epoch 0031, iter [02600, 05004], lr: 0.010000, loss: 3.8252, tea_CELoss: 1.7666 stu_CELoss: 1.8691 DMLLoss: 0.1894 
2022-03-14 09:12:07 - train: epoch 0031, iter [02700, 05004], lr: 0.010000, loss: 3.9520, tea_CELoss: 1.7986 stu_CELoss: 1.9093 DMLLoss: 0.2441 
2022-03-14 09:12:40 - train: epoch 0031, iter [02800, 05004], lr: 0.010000, loss: 4.0884, tea_CELoss: 1.8655 stu_CELoss: 2.0051 DMLLoss: 0.2178 
2022-03-14 09:13:13 - train: epoch 0031, iter [02900, 05004], lr: 0.010000, loss: 4.2214, tea_CELoss: 1.9083 stu_CELoss: 2.0767 DMLLoss: 0.2364 
2022-03-14 09:13:46 - train: epoch 0031, iter [03000, 05004], lr: 0.010000, loss: 4.5664, tea_CELoss: 2.0786 stu_CELoss: 2.2516 DMLLoss: 0.2362 
2022-03-14 09:14:19 - train: epoch 0031, iter [03100, 05004], lr: 0.010000, loss: 3.8057, tea_CELoss: 1.7423 stu_CELoss: 1.8593 DMLLoss: 0.2042 
2022-03-14 09:14:52 - train: epoch 0031, iter [03200, 05004], lr: 0.010000, loss: 3.9512, tea_CELoss: 1.7433 stu_CELoss: 1.9877 DMLLoss: 0.2201 
2022-03-14 09:15:25 - train: epoch 0031, iter [03300, 05004], lr: 0.010000, loss: 3.5902, tea_CELoss: 1.6343 stu_CELoss: 1.7539 DMLLoss: 0.2020 
2022-03-14 09:15:58 - train: epoch 0031, iter [03400, 05004], lr: 0.010000, loss: 4.2164, tea_CELoss: 1.8911 stu_CELoss: 2.1018 DMLLoss: 0.2235 
2022-03-14 09:16:31 - train: epoch 0031, iter [03500, 05004], lr: 0.010000, loss: 3.8774, tea_CELoss: 1.7516 stu_CELoss: 1.9012 DMLLoss: 0.2245 
2022-03-14 09:17:05 - train: epoch 0031, iter [03600, 05004], lr: 0.010000, loss: 3.8578, tea_CELoss: 1.7588 stu_CELoss: 1.8877 DMLLoss: 0.2113 
2022-03-14 09:17:38 - train: epoch 0031, iter [03700, 05004], lr: 0.010000, loss: 3.6490, tea_CELoss: 1.6287 stu_CELoss: 1.8011 DMLLoss: 0.2192 
2022-03-14 09:18:11 - train: epoch 0031, iter [03800, 05004], lr: 0.010000, loss: 3.5425, tea_CELoss: 1.5960 stu_CELoss: 1.7293 DMLLoss: 0.2173 
2022-03-14 09:18:44 - train: epoch 0031, iter [03900, 05004], lr: 0.010000, loss: 3.6680, tea_CELoss: 1.6572 stu_CELoss: 1.7879 DMLLoss: 0.2229 
2022-03-14 09:19:18 - train: epoch 0031, iter [04000, 05004], lr: 0.010000, loss: 3.4150, tea_CELoss: 1.5582 stu_CELoss: 1.6727 DMLLoss: 0.1841 
2022-03-14 09:19:50 - train: epoch 0031, iter [04100, 05004], lr: 0.010000, loss: 3.7718, tea_CELoss: 1.7515 stu_CELoss: 1.8285 DMLLoss: 0.1918 
2022-03-14 09:20:23 - train: epoch 0031, iter [04200, 05004], lr: 0.010000, loss: 3.7919, tea_CELoss: 1.7393 stu_CELoss: 1.8364 DMLLoss: 0.2161 
2022-03-14 09:20:57 - train: epoch 0031, iter [04300, 05004], lr: 0.010000, loss: 3.5342, tea_CELoss: 1.6063 stu_CELoss: 1.7467 DMLLoss: 0.1811 
2022-03-14 09:21:29 - train: epoch 0031, iter [04400, 05004], lr: 0.010000, loss: 4.1509, tea_CELoss: 1.8981 stu_CELoss: 2.0434 DMLLoss: 0.2095 
2022-03-14 09:22:02 - train: epoch 0031, iter [04500, 05004], lr: 0.010000, loss: 3.8290, tea_CELoss: 1.7486 stu_CELoss: 1.8736 DMLLoss: 0.2068 
2022-03-14 09:22:36 - train: epoch 0031, iter [04600, 05004], lr: 0.010000, loss: 3.8421, tea_CELoss: 1.7361 stu_CELoss: 1.8746 DMLLoss: 0.2314 
2022-03-14 09:23:09 - train: epoch 0031, iter [04700, 05004], lr: 0.010000, loss: 3.3645, tea_CELoss: 1.5286 stu_CELoss: 1.6480 DMLLoss: 0.1879 
2022-03-14 09:23:42 - train: epoch 0031, iter [04800, 05004], lr: 0.010000, loss: 3.6187, tea_CELoss: 1.6546 stu_CELoss: 1.7605 DMLLoss: 0.2036 
2022-03-14 09:24:15 - train: epoch 0031, iter [04900, 05004], lr: 0.010000, loss: 3.7996, tea_CELoss: 1.6927 stu_CELoss: 1.8874 DMLLoss: 0.2195 
2022-03-14 09:24:46 - train: epoch 0031, iter [05000, 05004], lr: 0.010000, loss: 3.5364, tea_CELoss: 1.6312 stu_CELoss: 1.7063 DMLLoss: 0.1988 
2022-03-14 09:24:47 - train: epoch 031, train_loss: 3.8323
2022-03-14 09:27:15 - eval: epoch: 031, tea_acc1: 66.508%, tea_acc5: 87.546%, tea_test_loss: 1.3640, stu_acc1: 64.102%, stu_acc5: 85.736%, stu_test_loss: 1.4899
2022-03-14 09:27:16 - until epoch: 031, tea_best_acc1: 66.508%, stu_best_acc1: 64.102%
2022-03-14 09:27:16 - epoch 032 lr: 0.010000000000000002
2022-03-14 09:27:54 - train: epoch 0032, iter [00100, 05004], lr: 0.010000, loss: 3.1754, tea_CELoss: 1.4075 stu_CELoss: 1.5585 DMLLoss: 0.2095 
2022-03-14 09:28:27 - train: epoch 0032, iter [00200, 05004], lr: 0.010000, loss: 3.2826, tea_CELoss: 1.4707 stu_CELoss: 1.6148 DMLLoss: 0.1971 
2022-03-14 09:29:00 - train: epoch 0032, iter [00300, 05004], lr: 0.010000, loss: 3.3024, tea_CELoss: 1.5097 stu_CELoss: 1.6033 DMLLoss: 0.1894 
2022-03-14 09:29:33 - train: epoch 0032, iter [00400, 05004], lr: 0.010000, loss: 3.8535, tea_CELoss: 1.7757 stu_CELoss: 1.8660 DMLLoss: 0.2117 
2022-03-14 09:30:06 - train: epoch 0032, iter [00500, 05004], lr: 0.010000, loss: 3.5988, tea_CELoss: 1.6088 stu_CELoss: 1.7846 DMLLoss: 0.2054 
2022-03-14 09:30:39 - train: epoch 0032, iter [00600, 05004], lr: 0.010000, loss: 3.7558, tea_CELoss: 1.6700 stu_CELoss: 1.8860 DMLLoss: 0.1998 
2022-03-14 09:31:12 - train: epoch 0032, iter [00700, 05004], lr: 0.010000, loss: 3.6815, tea_CELoss: 1.6185 stu_CELoss: 1.8331 DMLLoss: 0.2299 
2022-03-14 09:31:45 - train: epoch 0032, iter [00800, 05004], lr: 0.010000, loss: 3.8337, tea_CELoss: 1.7285 stu_CELoss: 1.8731 DMLLoss: 0.2321 
2022-03-14 09:32:18 - train: epoch 0032, iter [00900, 05004], lr: 0.010000, loss: 3.5719, tea_CELoss: 1.5809 stu_CELoss: 1.7749 DMLLoss: 0.2162 
2022-03-14 09:32:52 - train: epoch 0032, iter [01000, 05004], lr: 0.010000, loss: 4.1176, tea_CELoss: 1.8597 stu_CELoss: 2.0353 DMLLoss: 0.2225 
2022-03-14 09:33:25 - train: epoch 0032, iter [01100, 05004], lr: 0.010000, loss: 3.4191, tea_CELoss: 1.5821 stu_CELoss: 1.6620 DMLLoss: 0.1749 
2022-03-14 09:33:58 - train: epoch 0032, iter [01200, 05004], lr: 0.010000, loss: 3.7324, tea_CELoss: 1.7019 stu_CELoss: 1.8384 DMLLoss: 0.1921 
2022-03-14 09:34:30 - train: epoch 0032, iter [01300, 05004], lr: 0.010000, loss: 3.5690, tea_CELoss: 1.6152 stu_CELoss: 1.7616 DMLLoss: 0.1922 
2022-03-14 09:35:04 - train: epoch 0032, iter [01400, 05004], lr: 0.010000, loss: 3.6446, tea_CELoss: 1.6349 stu_CELoss: 1.7912 DMLLoss: 0.2186 
2022-03-14 09:35:37 - train: epoch 0032, iter [01500, 05004], lr: 0.010000, loss: 3.9062, tea_CELoss: 1.7535 stu_CELoss: 1.9224 DMLLoss: 0.2302 
2022-03-14 09:36:10 - train: epoch 0032, iter [01600, 05004], lr: 0.010000, loss: 4.0364, tea_CELoss: 1.8572 stu_CELoss: 1.9786 DMLLoss: 0.2006 
2022-03-14 09:36:44 - train: epoch 0032, iter [01700, 05004], lr: 0.010000, loss: 3.9401, tea_CELoss: 1.8005 stu_CELoss: 1.9152 DMLLoss: 0.2244 
2022-03-14 09:37:17 - train: epoch 0032, iter [01800, 05004], lr: 0.010000, loss: 4.4286, tea_CELoss: 2.0182 stu_CELoss: 2.2016 DMLLoss: 0.2088 
2022-03-14 09:37:50 - train: epoch 0032, iter [01900, 05004], lr: 0.010000, loss: 2.9725, tea_CELoss: 1.3534 stu_CELoss: 1.4255 DMLLoss: 0.1935 
2022-03-14 09:38:23 - train: epoch 0032, iter [02000, 05004], lr: 0.010000, loss: 3.4654, tea_CELoss: 1.5572 stu_CELoss: 1.7215 DMLLoss: 0.1867 
2022-03-14 09:38:56 - train: epoch 0032, iter [02100, 05004], lr: 0.010000, loss: 3.1774, tea_CELoss: 1.4197 stu_CELoss: 1.5624 DMLLoss: 0.1953 
2022-03-14 09:39:29 - train: epoch 0032, iter [02200, 05004], lr: 0.010000, loss: 3.6940, tea_CELoss: 1.6731 stu_CELoss: 1.8168 DMLLoss: 0.2041 
2022-03-14 09:40:02 - train: epoch 0032, iter [02300, 05004], lr: 0.010000, loss: 3.7916, tea_CELoss: 1.7153 stu_CELoss: 1.8855 DMLLoss: 0.1907 
2022-03-14 09:40:35 - train: epoch 0032, iter [02400, 05004], lr: 0.010000, loss: 3.3536, tea_CELoss: 1.5052 stu_CELoss: 1.6414 DMLLoss: 0.2069 
2022-03-14 09:41:08 - train: epoch 0032, iter [02500, 05004], lr: 0.010000, loss: 3.5279, tea_CELoss: 1.5875 stu_CELoss: 1.7567 DMLLoss: 0.1836 
2022-03-14 09:41:42 - train: epoch 0032, iter [02600, 05004], lr: 0.010000, loss: 3.3500, tea_CELoss: 1.4794 stu_CELoss: 1.6799 DMLLoss: 0.1907 
2022-03-14 09:42:13 - train: epoch 0032, iter [02700, 05004], lr: 0.010000, loss: 3.3160, tea_CELoss: 1.5018 stu_CELoss: 1.6100 DMLLoss: 0.2041 
2022-03-14 09:42:47 - train: epoch 0032, iter [02800, 05004], lr: 0.010000, loss: 3.7375, tea_CELoss: 1.6730 stu_CELoss: 1.8531 DMLLoss: 0.2114 
2022-03-14 09:43:20 - train: epoch 0032, iter [02900, 05004], lr: 0.010000, loss: 3.3033, tea_CELoss: 1.4676 stu_CELoss: 1.6395 DMLLoss: 0.1962 
2022-03-14 09:43:53 - train: epoch 0032, iter [03000, 05004], lr: 0.010000, loss: 3.2321, tea_CELoss: 1.4518 stu_CELoss: 1.5578 DMLLoss: 0.2225 
2022-03-14 09:44:26 - train: epoch 0032, iter [03100, 05004], lr: 0.010000, loss: 3.8321, tea_CELoss: 1.7300 stu_CELoss: 1.8944 DMLLoss: 0.2077 
2022-03-14 09:45:00 - train: epoch 0032, iter [03200, 05004], lr: 0.010000, loss: 3.8105, tea_CELoss: 1.7429 stu_CELoss: 1.8504 DMLLoss: 0.2172 
2022-03-14 09:45:32 - train: epoch 0032, iter [03300, 05004], lr: 0.010000, loss: 3.4856, tea_CELoss: 1.5816 stu_CELoss: 1.7263 DMLLoss: 0.1777 
2022-03-14 09:46:06 - train: epoch 0032, iter [03400, 05004], lr: 0.010000, loss: 3.3868, tea_CELoss: 1.5095 stu_CELoss: 1.6675 DMLLoss: 0.2098 
2022-03-14 09:46:39 - train: epoch 0032, iter [03500, 05004], lr: 0.010000, loss: 3.4527, tea_CELoss: 1.5692 stu_CELoss: 1.6964 DMLLoss: 0.1871 
2022-03-14 09:47:13 - train: epoch 0032, iter [03600, 05004], lr: 0.010000, loss: 3.9450, tea_CELoss: 1.8314 stu_CELoss: 1.9111 DMLLoss: 0.2025 
2022-03-14 09:47:45 - train: epoch 0032, iter [03700, 05004], lr: 0.010000, loss: 3.6700, tea_CELoss: 1.6396 stu_CELoss: 1.8233 DMLLoss: 0.2072 
2022-03-14 09:48:18 - train: epoch 0032, iter [03800, 05004], lr: 0.010000, loss: 3.0739, tea_CELoss: 1.3490 stu_CELoss: 1.5383 DMLLoss: 0.1866 
2022-03-14 09:48:51 - train: epoch 0032, iter [03900, 05004], lr: 0.010000, loss: 3.0951, tea_CELoss: 1.3932 stu_CELoss: 1.5084 DMLLoss: 0.1935 
2022-03-14 09:49:25 - train: epoch 0032, iter [04000, 05004], lr: 0.010000, loss: 3.6309, tea_CELoss: 1.6484 stu_CELoss: 1.8001 DMLLoss: 0.1825 
2022-03-14 09:49:58 - train: epoch 0032, iter [04100, 05004], lr: 0.010000, loss: 3.3135, tea_CELoss: 1.5162 stu_CELoss: 1.5973 DMLLoss: 0.2000 
2022-03-14 09:50:30 - train: epoch 0032, iter [04200, 05004], lr: 0.010000, loss: 3.3404, tea_CELoss: 1.5294 stu_CELoss: 1.6321 DMLLoss: 0.1789 
2022-03-14 09:51:03 - train: epoch 0032, iter [04300, 05004], lr: 0.010000, loss: 3.8931, tea_CELoss: 1.7621 stu_CELoss: 1.9077 DMLLoss: 0.2232 
2022-03-14 09:51:37 - train: epoch 0032, iter [04400, 05004], lr: 0.010000, loss: 3.2801, tea_CELoss: 1.4928 stu_CELoss: 1.5916 DMLLoss: 0.1957 
2022-03-14 09:52:09 - train: epoch 0032, iter [04500, 05004], lr: 0.010000, loss: 3.8695, tea_CELoss: 1.7326 stu_CELoss: 1.9345 DMLLoss: 0.2023 
2022-03-14 09:52:43 - train: epoch 0032, iter [04600, 05004], lr: 0.010000, loss: 3.3592, tea_CELoss: 1.5522 stu_CELoss: 1.6173 DMLLoss: 0.1897 
2022-03-14 09:53:15 - train: epoch 0032, iter [04700, 05004], lr: 0.010000, loss: 3.7685, tea_CELoss: 1.6968 stu_CELoss: 1.8575 DMLLoss: 0.2143 
2022-03-14 09:53:49 - train: epoch 0032, iter [04800, 05004], lr: 0.010000, loss: 3.3086, tea_CELoss: 1.4873 stu_CELoss: 1.6308 DMLLoss: 0.1906 
2022-03-14 09:54:22 - train: epoch 0032, iter [04900, 05004], lr: 0.010000, loss: 3.4951, tea_CELoss: 1.5908 stu_CELoss: 1.7179 DMLLoss: 0.1863 
2022-03-14 09:54:54 - train: epoch 0032, iter [05000, 05004], lr: 0.010000, loss: 3.6838, tea_CELoss: 1.6627 stu_CELoss: 1.8068 DMLLoss: 0.2144 
2022-03-14 09:54:55 - train: epoch 032, train_loss: 3.5953
2022-03-14 09:57:23 - eval: epoch: 032, tea_acc1: 67.470%, tea_acc5: 88.192%, tea_test_loss: 1.3150, stu_acc1: 64.750%, stu_acc5: 86.372%, stu_test_loss: 1.4438
2022-03-14 09:57:24 - until epoch: 032, tea_best_acc1: 67.470%, stu_best_acc1: 64.750%
2022-03-14 09:57:24 - epoch 033 lr: 0.010000000000000002
2022-03-14 09:58:02 - train: epoch 0033, iter [00100, 05004], lr: 0.010000, loss: 3.1785, tea_CELoss: 1.3720 stu_CELoss: 1.5877 DMLLoss: 0.2188 
2022-03-14 09:58:35 - train: epoch 0033, iter [00200, 05004], lr: 0.010000, loss: 3.5588, tea_CELoss: 1.6316 stu_CELoss: 1.7292 DMLLoss: 0.1981 
2022-03-14 09:59:09 - train: epoch 0033, iter [00300, 05004], lr: 0.010000, loss: 3.5361, tea_CELoss: 1.5843 stu_CELoss: 1.7437 DMLLoss: 0.2081 
2022-03-14 09:59:42 - train: epoch 0033, iter [00400, 05004], lr: 0.010000, loss: 3.3286, tea_CELoss: 1.5015 stu_CELoss: 1.6304 DMLLoss: 0.1967 
2022-03-14 10:00:15 - train: epoch 0033, iter [00500, 05004], lr: 0.010000, loss: 3.7660, tea_CELoss: 1.7007 stu_CELoss: 1.8539 DMLLoss: 0.2114 
2022-03-14 10:00:48 - train: epoch 0033, iter [00600, 05004], lr: 0.010000, loss: 3.6713, tea_CELoss: 1.6433 stu_CELoss: 1.8116 DMLLoss: 0.2163 
2022-03-14 10:01:22 - train: epoch 0033, iter [00700, 05004], lr: 0.010000, loss: 3.9133, tea_CELoss: 1.7341 stu_CELoss: 1.9550 DMLLoss: 0.2242 
2022-03-14 10:01:54 - train: epoch 0033, iter [00800, 05004], lr: 0.010000, loss: 3.8821, tea_CELoss: 1.7555 stu_CELoss: 1.9046 DMLLoss: 0.2220 
2022-03-14 10:02:28 - train: epoch 0033, iter [00900, 05004], lr: 0.010000, loss: 3.2866, tea_CELoss: 1.5272 stu_CELoss: 1.5812 DMLLoss: 0.1781 
2022-03-14 10:03:01 - train: epoch 0033, iter [01000, 05004], lr: 0.010000, loss: 3.7810, tea_CELoss: 1.7071 stu_CELoss: 1.8477 DMLLoss: 0.2263 
2022-03-14 10:03:34 - train: epoch 0033, iter [01100, 05004], lr: 0.010000, loss: 2.8532, tea_CELoss: 1.2418 stu_CELoss: 1.4096 DMLLoss: 0.2018 
2022-03-14 10:04:08 - train: epoch 0033, iter [01200, 05004], lr: 0.010000, loss: 3.9422, tea_CELoss: 1.7794 stu_CELoss: 1.9385 DMLLoss: 0.2242 
2022-03-14 10:04:40 - train: epoch 0033, iter [01300, 05004], lr: 0.010000, loss: 3.3044, tea_CELoss: 1.4705 stu_CELoss: 1.6144 DMLLoss: 0.2195 
2022-03-14 10:05:14 - train: epoch 0033, iter [01400, 05004], lr: 0.010000, loss: 3.3024, tea_CELoss: 1.4644 stu_CELoss: 1.6182 DMLLoss: 0.2198 
2022-03-14 10:05:47 - train: epoch 0033, iter [01500, 05004], lr: 0.010000, loss: 3.9893, tea_CELoss: 1.8022 stu_CELoss: 1.9552 DMLLoss: 0.2320 
2022-03-14 10:06:20 - train: epoch 0033, iter [01600, 05004], lr: 0.010000, loss: 3.9314, tea_CELoss: 1.7777 stu_CELoss: 1.9339 DMLLoss: 0.2198 
2022-03-14 10:06:53 - train: epoch 0033, iter [01700, 05004], lr: 0.010000, loss: 3.6178, tea_CELoss: 1.6648 stu_CELoss: 1.7503 DMLLoss: 0.2027 
2022-03-14 10:07:27 - train: epoch 0033, iter [01800, 05004], lr: 0.010000, loss: 3.3662, tea_CELoss: 1.4879 stu_CELoss: 1.6485 DMLLoss: 0.2298 
2022-03-14 10:07:59 - train: epoch 0033, iter [01900, 05004], lr: 0.010000, loss: 3.5441, tea_CELoss: 1.5651 stu_CELoss: 1.7723 DMLLoss: 0.2067 
2022-03-14 10:08:32 - train: epoch 0033, iter [02000, 05004], lr: 0.010000, loss: 3.3061, tea_CELoss: 1.5009 stu_CELoss: 1.6016 DMLLoss: 0.2037 
2022-03-14 10:09:05 - train: epoch 0033, iter [02100, 05004], lr: 0.010000, loss: 3.7588, tea_CELoss: 1.7274 stu_CELoss: 1.8177 DMLLoss: 0.2137 
2022-03-14 10:09:39 - train: epoch 0033, iter [02200, 05004], lr: 0.010000, loss: 3.6815, tea_CELoss: 1.6667 stu_CELoss: 1.7928 DMLLoss: 0.2221 
2022-03-14 10:10:12 - train: epoch 0033, iter [02300, 05004], lr: 0.010000, loss: 3.2760, tea_CELoss: 1.4674 stu_CELoss: 1.6017 DMLLoss: 0.2069 
2022-03-14 10:10:45 - train: epoch 0033, iter [02400, 05004], lr: 0.010000, loss: 4.0989, tea_CELoss: 1.8369 stu_CELoss: 2.0342 DMLLoss: 0.2278 
2022-03-14 10:11:19 - train: epoch 0033, iter [02500, 05004], lr: 0.010000, loss: 3.3694, tea_CELoss: 1.5397 stu_CELoss: 1.6325 DMLLoss: 0.1972 
2022-03-14 10:11:52 - train: epoch 0033, iter [02600, 05004], lr: 0.010000, loss: 3.2691, tea_CELoss: 1.4302 stu_CELoss: 1.6179 DMLLoss: 0.2210 
2022-03-14 10:12:25 - train: epoch 0033, iter [02700, 05004], lr: 0.010000, loss: 3.4099, tea_CELoss: 1.5607 stu_CELoss: 1.6599 DMLLoss: 0.1892 
2022-03-14 10:12:58 - train: epoch 0033, iter [02800, 05004], lr: 0.010000, loss: 3.4142, tea_CELoss: 1.5443 stu_CELoss: 1.6533 DMLLoss: 0.2167 
2022-03-14 10:13:31 - train: epoch 0033, iter [02900, 05004], lr: 0.010000, loss: 3.2330, tea_CELoss: 1.4421 stu_CELoss: 1.5876 DMLLoss: 0.2033 
2022-03-14 10:14:05 - train: epoch 0033, iter [03000, 05004], lr: 0.010000, loss: 3.5016, tea_CELoss: 1.5634 stu_CELoss: 1.7449 DMLLoss: 0.1933 
2022-03-14 10:14:38 - train: epoch 0033, iter [03100, 05004], lr: 0.010000, loss: 3.5114, tea_CELoss: 1.5472 stu_CELoss: 1.7293 DMLLoss: 0.2349 
2022-03-14 10:15:10 - train: epoch 0033, iter [03200, 05004], lr: 0.010000, loss: 3.7295, tea_CELoss: 1.6400 stu_CELoss: 1.8568 DMLLoss: 0.2327 
2022-03-14 10:15:44 - train: epoch 0033, iter [03300, 05004], lr: 0.010000, loss: 3.4397, tea_CELoss: 1.5535 stu_CELoss: 1.6876 DMLLoss: 0.1986 
2022-03-14 10:16:17 - train: epoch 0033, iter [03400, 05004], lr: 0.010000, loss: 3.0544, tea_CELoss: 1.3696 stu_CELoss: 1.4932 DMLLoss: 0.1916 
2022-03-14 10:16:50 - train: epoch 0033, iter [03500, 05004], lr: 0.010000, loss: 3.7230, tea_CELoss: 1.6430 stu_CELoss: 1.8487 DMLLoss: 0.2313 
2022-03-14 10:17:23 - train: epoch 0033, iter [03600, 05004], lr: 0.010000, loss: 3.7053, tea_CELoss: 1.6751 stu_CELoss: 1.8142 DMLLoss: 0.2159 
2022-03-14 10:17:56 - train: epoch 0033, iter [03700, 05004], lr: 0.010000, loss: 3.3495, tea_CELoss: 1.4705 stu_CELoss: 1.6525 DMLLoss: 0.2265 
2022-03-14 10:18:30 - train: epoch 0033, iter [03800, 05004], lr: 0.010000, loss: 3.5663, tea_CELoss: 1.6034 stu_CELoss: 1.7490 DMLLoss: 0.2139 
2022-03-14 10:19:03 - train: epoch 0033, iter [03900, 05004], lr: 0.010000, loss: 3.9382, tea_CELoss: 1.7927 stu_CELoss: 1.9238 DMLLoss: 0.2217 
2022-03-14 10:19:36 - train: epoch 0033, iter [04000, 05004], lr: 0.010000, loss: 3.7321, tea_CELoss: 1.6683 stu_CELoss: 1.8650 DMLLoss: 0.1988 
2022-03-14 10:20:10 - train: epoch 0033, iter [04100, 05004], lr: 0.010000, loss: 3.6095, tea_CELoss: 1.6186 stu_CELoss: 1.7561 DMLLoss: 0.2348 
2022-03-14 10:20:43 - train: epoch 0033, iter [04200, 05004], lr: 0.010000, loss: 2.9326, tea_CELoss: 1.2540 stu_CELoss: 1.4788 DMLLoss: 0.1998 
2022-03-14 10:21:16 - train: epoch 0033, iter [04300, 05004], lr: 0.010000, loss: 3.7000, tea_CELoss: 1.6641 stu_CELoss: 1.8316 DMLLoss: 0.2043 
2022-03-14 10:21:49 - train: epoch 0033, iter [04400, 05004], lr: 0.010000, loss: 3.5781, tea_CELoss: 1.6021 stu_CELoss: 1.7668 DMLLoss: 0.2093 
2022-03-14 10:22:22 - train: epoch 0033, iter [04500, 05004], lr: 0.010000, loss: 3.8027, tea_CELoss: 1.6985 stu_CELoss: 1.8865 DMLLoss: 0.2177 
2022-03-14 10:22:54 - train: epoch 0033, iter [04600, 05004], lr: 0.010000, loss: 3.4799, tea_CELoss: 1.5639 stu_CELoss: 1.7043 DMLLoss: 0.2117 
2022-03-14 10:23:28 - train: epoch 0033, iter [04700, 05004], lr: 0.010000, loss: 3.7674, tea_CELoss: 1.7060 stu_CELoss: 1.8286 DMLLoss: 0.2328 
2022-03-14 10:24:01 - train: epoch 0033, iter [04800, 05004], lr: 0.010000, loss: 4.0372, tea_CELoss: 1.8288 stu_CELoss: 1.9950 DMLLoss: 0.2134 
2022-03-14 10:24:34 - train: epoch 0033, iter [04900, 05004], lr: 0.010000, loss: 3.5046, tea_CELoss: 1.5536 stu_CELoss: 1.7403 DMLLoss: 0.2107 
2022-03-14 10:25:06 - train: epoch 0033, iter [05000, 05004], lr: 0.010000, loss: 3.7925, tea_CELoss: 1.7376 stu_CELoss: 1.8066 DMLLoss: 0.2484 
2022-03-14 10:25:07 - train: epoch 033, train_loss: 3.5069
2022-03-14 10:27:36 - eval: epoch: 033, tea_acc1: 67.866%, tea_acc5: 88.506%, tea_test_loss: 1.2954, stu_acc1: 65.300%, stu_acc5: 86.584%, stu_test_loss: 1.4283
2022-03-14 10:27:37 - until epoch: 033, tea_best_acc1: 67.866%, stu_best_acc1: 65.300%
2022-03-14 10:27:37 - epoch 034 lr: 0.010000000000000002
2022-03-14 10:28:15 - train: epoch 0034, iter [00100, 05004], lr: 0.010000, loss: 3.3725, tea_CELoss: 1.5137 stu_CELoss: 1.6260 DMLLoss: 0.2328 
2022-03-14 10:28:49 - train: epoch 0034, iter [00200, 05004], lr: 0.010000, loss: 3.4633, tea_CELoss: 1.5441 stu_CELoss: 1.6995 DMLLoss: 0.2197 
2022-03-14 10:29:22 - train: epoch 0034, iter [00300, 05004], lr: 0.010000, loss: 3.3003, tea_CELoss: 1.4532 stu_CELoss: 1.6422 DMLLoss: 0.2050 
2022-03-14 10:29:55 - train: epoch 0034, iter [00400, 05004], lr: 0.010000, loss: 3.2409, tea_CELoss: 1.4546 stu_CELoss: 1.5734 DMLLoss: 0.2129 
2022-03-14 10:30:28 - train: epoch 0034, iter [00500, 05004], lr: 0.010000, loss: 3.3204, tea_CELoss: 1.4795 stu_CELoss: 1.6372 DMLLoss: 0.2037 
2022-03-14 10:31:01 - train: epoch 0034, iter [00600, 05004], lr: 0.010000, loss: 3.6132, tea_CELoss: 1.6354 stu_CELoss: 1.7777 DMLLoss: 0.2001 
2022-03-14 10:31:34 - train: epoch 0034, iter [00700, 05004], lr: 0.010000, loss: 3.2480, tea_CELoss: 1.4474 stu_CELoss: 1.5860 DMLLoss: 0.2146 
2022-03-14 10:32:08 - train: epoch 0034, iter [00800, 05004], lr: 0.010000, loss: 3.6146, tea_CELoss: 1.6714 stu_CELoss: 1.7296 DMLLoss: 0.2136 
2022-03-14 10:32:41 - train: epoch 0034, iter [00900, 05004], lr: 0.010000, loss: 3.1954, tea_CELoss: 1.4315 stu_CELoss: 1.5744 DMLLoss: 0.1895 
2022-03-14 10:33:14 - train: epoch 0034, iter [01000, 05004], lr: 0.010000, loss: 3.2560, tea_CELoss: 1.4521 stu_CELoss: 1.6075 DMLLoss: 0.1963 
2022-03-14 10:33:47 - train: epoch 0034, iter [01100, 05004], lr: 0.010000, loss: 3.3714, tea_CELoss: 1.4710 stu_CELoss: 1.6824 DMLLoss: 0.2180 
2022-03-14 10:34:21 - train: epoch 0034, iter [01200, 05004], lr: 0.010000, loss: 3.5319, tea_CELoss: 1.5908 stu_CELoss: 1.6983 DMLLoss: 0.2428 
2022-03-14 10:34:53 - train: epoch 0034, iter [01300, 05004], lr: 0.010000, loss: 3.2639, tea_CELoss: 1.4579 stu_CELoss: 1.6076 DMLLoss: 0.1985 
2022-03-14 10:35:26 - train: epoch 0034, iter [01400, 05004], lr: 0.010000, loss: 3.3033, tea_CELoss: 1.4785 stu_CELoss: 1.5952 DMLLoss: 0.2296 
2022-03-14 10:35:59 - train: epoch 0034, iter [01500, 05004], lr: 0.010000, loss: 3.3290, tea_CELoss: 1.4863 stu_CELoss: 1.6302 DMLLoss: 0.2125 
2022-03-14 10:36:33 - train: epoch 0034, iter [01600, 05004], lr: 0.010000, loss: 3.3896, tea_CELoss: 1.5093 stu_CELoss: 1.6484 DMLLoss: 0.2320 
2022-03-14 10:37:07 - train: epoch 0034, iter [01700, 05004], lr: 0.010000, loss: 3.5161, tea_CELoss: 1.5876 stu_CELoss: 1.7335 DMLLoss: 0.1951 
2022-03-14 10:37:40 - train: epoch 0034, iter [01800, 05004], lr: 0.010000, loss: 3.8260, tea_CELoss: 1.7097 stu_CELoss: 1.8840 DMLLoss: 0.2323 
2022-03-14 10:38:13 - train: epoch 0034, iter [01900, 05004], lr: 0.010000, loss: 3.6091, tea_CELoss: 1.6232 stu_CELoss: 1.7741 DMLLoss: 0.2119 
2022-03-14 10:38:47 - train: epoch 0034, iter [02000, 05004], lr: 0.010000, loss: 3.2296, tea_CELoss: 1.4386 stu_CELoss: 1.5842 DMLLoss: 0.2068 
2022-03-14 10:39:20 - train: epoch 0034, iter [02100, 05004], lr: 0.010000, loss: 3.5696, tea_CELoss: 1.5910 stu_CELoss: 1.7655 DMLLoss: 0.2131 
2022-03-14 10:39:54 - train: epoch 0034, iter [02200, 05004], lr: 0.010000, loss: 3.2720, tea_CELoss: 1.4859 stu_CELoss: 1.5856 DMLLoss: 0.2005 
2022-03-14 10:40:27 - train: epoch 0034, iter [02300, 05004], lr: 0.010000, loss: 3.7474, tea_CELoss: 1.6702 stu_CELoss: 1.8616 DMLLoss: 0.2156 
2022-03-14 10:41:00 - train: epoch 0034, iter [02400, 05004], lr: 0.010000, loss: 3.1037, tea_CELoss: 1.4217 stu_CELoss: 1.4830 DMLLoss: 0.1990 
2022-03-14 10:41:33 - train: epoch 0034, iter [02500, 05004], lr: 0.010000, loss: 3.8319, tea_CELoss: 1.7378 stu_CELoss: 1.8655 DMLLoss: 0.2285 
2022-03-14 10:42:06 - train: epoch 0034, iter [02600, 05004], lr: 0.010000, loss: 3.7133, tea_CELoss: 1.6927 stu_CELoss: 1.8095 DMLLoss: 0.2112 
2022-03-14 10:42:39 - train: epoch 0034, iter [02700, 05004], lr: 0.010000, loss: 3.7916, tea_CELoss: 1.7036 stu_CELoss: 1.8556 DMLLoss: 0.2324 
2022-03-14 10:43:13 - train: epoch 0034, iter [02800, 05004], lr: 0.010000, loss: 3.0536, tea_CELoss: 1.3590 stu_CELoss: 1.4948 DMLLoss: 0.1998 
2022-03-14 10:43:46 - train: epoch 0034, iter [02900, 05004], lr: 0.010000, loss: 3.0020, tea_CELoss: 1.3534 stu_CELoss: 1.4449 DMLLoss: 0.2038 
2022-03-14 10:44:20 - train: epoch 0034, iter [03000, 05004], lr: 0.010000, loss: 3.2877, tea_CELoss: 1.4100 stu_CELoss: 1.6602 DMLLoss: 0.2175 
2022-03-14 10:44:52 - train: epoch 0034, iter [03100, 05004], lr: 0.010000, loss: 3.2501, tea_CELoss: 1.4583 stu_CELoss: 1.5764 DMLLoss: 0.2154 
2022-03-14 10:45:26 - train: epoch 0034, iter [03200, 05004], lr: 0.010000, loss: 3.4606, tea_CELoss: 1.5757 stu_CELoss: 1.6647 DMLLoss: 0.2201 
2022-03-14 10:45:59 - train: epoch 0034, iter [03300, 05004], lr: 0.010000, loss: 3.3006, tea_CELoss: 1.4709 stu_CELoss: 1.6157 DMLLoss: 0.2141 
2022-03-14 10:46:32 - train: epoch 0034, iter [03400, 05004], lr: 0.010000, loss: 3.7757, tea_CELoss: 1.7232 stu_CELoss: 1.8220 DMLLoss: 0.2304 
2022-03-14 10:47:06 - train: epoch 0034, iter [03500, 05004], lr: 0.010000, loss: 3.1173, tea_CELoss: 1.3918 stu_CELoss: 1.5108 DMLLoss: 0.2147 
2022-03-14 10:47:39 - train: epoch 0034, iter [03600, 05004], lr: 0.010000, loss: 2.9374, tea_CELoss: 1.2913 stu_CELoss: 1.4526 DMLLoss: 0.1935 
2022-03-14 10:48:12 - train: epoch 0034, iter [03700, 05004], lr: 0.010000, loss: 3.5166, tea_CELoss: 1.5951 stu_CELoss: 1.7039 DMLLoss: 0.2175 
2022-03-14 10:48:45 - train: epoch 0034, iter [03800, 05004], lr: 0.010000, loss: 3.2952, tea_CELoss: 1.4809 stu_CELoss: 1.6055 DMLLoss: 0.2088 
2022-03-14 10:49:18 - train: epoch 0034, iter [03900, 05004], lr: 0.010000, loss: 4.1889, tea_CELoss: 1.8644 stu_CELoss: 2.0752 DMLLoss: 0.2493 
2022-03-14 10:49:51 - train: epoch 0034, iter [04000, 05004], lr: 0.010000, loss: 3.4231, tea_CELoss: 1.4991 stu_CELoss: 1.6816 DMLLoss: 0.2424 
2022-03-14 10:50:25 - train: epoch 0034, iter [04100, 05004], lr: 0.010000, loss: 3.7931, tea_CELoss: 1.7215 stu_CELoss: 1.8474 DMLLoss: 0.2242 
2022-03-14 10:50:58 - train: epoch 0034, iter [04200, 05004], lr: 0.010000, loss: 3.3767, tea_CELoss: 1.4823 stu_CELoss: 1.6781 DMLLoss: 0.2164 
2022-03-14 10:51:31 - train: epoch 0034, iter [04300, 05004], lr: 0.010000, loss: 3.1872, tea_CELoss: 1.4204 stu_CELoss: 1.5554 DMLLoss: 0.2114 
2022-03-14 10:52:04 - train: epoch 0034, iter [04400, 05004], lr: 0.010000, loss: 3.0617, tea_CELoss: 1.3513 stu_CELoss: 1.4771 DMLLoss: 0.2332 
2022-03-14 10:52:37 - train: epoch 0034, iter [04500, 05004], lr: 0.010000, loss: 3.7008, tea_CELoss: 1.6916 stu_CELoss: 1.7794 DMLLoss: 0.2297 
2022-03-14 10:53:11 - train: epoch 0034, iter [04600, 05004], lr: 0.010000, loss: 3.8081, tea_CELoss: 1.6782 stu_CELoss: 1.8758 DMLLoss: 0.2541 
2022-03-14 10:53:44 - train: epoch 0034, iter [04700, 05004], lr: 0.010000, loss: 3.6267, tea_CELoss: 1.6055 stu_CELoss: 1.7885 DMLLoss: 0.2327 
2022-03-14 10:54:17 - train: epoch 0034, iter [04800, 05004], lr: 0.010000, loss: 3.6765, tea_CELoss: 1.6026 stu_CELoss: 1.8279 DMLLoss: 0.2460 
2022-03-14 10:54:50 - train: epoch 0034, iter [04900, 05004], lr: 0.010000, loss: 3.6361, tea_CELoss: 1.6607 stu_CELoss: 1.7768 DMLLoss: 0.1986 
2022-03-14 10:55:22 - train: epoch 0034, iter [05000, 05004], lr: 0.010000, loss: 3.0832, tea_CELoss: 1.4120 stu_CELoss: 1.4792 DMLLoss: 0.1919 
2022-03-14 10:55:23 - train: epoch 034, train_loss: 3.4544
2022-03-14 10:57:52 - eval: epoch: 034, tea_acc1: 67.928%, tea_acc5: 88.502%, tea_test_loss: 1.2871, stu_acc1: 65.476%, stu_acc5: 86.822%, stu_test_loss: 1.4087
2022-03-14 10:57:53 - until epoch: 034, tea_best_acc1: 67.928%, stu_best_acc1: 65.476%
2022-03-14 10:57:53 - epoch 035 lr: 0.010000000000000002
2022-03-14 10:58:31 - train: epoch 0035, iter [00100, 05004], lr: 0.010000, loss: 3.2106, tea_CELoss: 1.4260 stu_CELoss: 1.5887 DMLLoss: 0.1959 
2022-03-14 10:59:05 - train: epoch 0035, iter [00200, 05004], lr: 0.010000, loss: 3.2019, tea_CELoss: 1.4109 stu_CELoss: 1.5617 DMLLoss: 0.2294 
2022-03-14 10:59:37 - train: epoch 0035, iter [00300, 05004], lr: 0.010000, loss: 3.4880, tea_CELoss: 1.5725 stu_CELoss: 1.7067 DMLLoss: 0.2088 
2022-03-14 11:00:11 - train: epoch 0035, iter [00400, 05004], lr: 0.010000, loss: 3.1383, tea_CELoss: 1.3786 stu_CELoss: 1.5302 DMLLoss: 0.2295 
2022-03-14 11:00:44 - train: epoch 0035, iter [00500, 05004], lr: 0.010000, loss: 3.3860, tea_CELoss: 1.4916 stu_CELoss: 1.6774 DMLLoss: 0.2170 
2022-03-14 11:01:17 - train: epoch 0035, iter [00600, 05004], lr: 0.010000, loss: 3.3099, tea_CELoss: 1.4730 stu_CELoss: 1.6107 DMLLoss: 0.2262 
2022-03-14 11:01:50 - train: epoch 0035, iter [00700, 05004], lr: 0.010000, loss: 3.0603, tea_CELoss: 1.3455 stu_CELoss: 1.4928 DMLLoss: 0.2221 
2022-03-14 11:02:24 - train: epoch 0035, iter [00800, 05004], lr: 0.010000, loss: 3.4929, tea_CELoss: 1.5907 stu_CELoss: 1.6997 DMLLoss: 0.2025 
2022-03-14 11:02:57 - train: epoch 0035, iter [00900, 05004], lr: 0.010000, loss: 3.8180, tea_CELoss: 1.6917 stu_CELoss: 1.8869 DMLLoss: 0.2393 
2022-03-14 11:03:30 - train: epoch 0035, iter [01000, 05004], lr: 0.010000, loss: 3.0135, tea_CELoss: 1.3443 stu_CELoss: 1.4707 DMLLoss: 0.1985 
2022-03-14 11:04:03 - train: epoch 0035, iter [01100, 05004], lr: 0.010000, loss: 3.7203, tea_CELoss: 1.6852 stu_CELoss: 1.7983 DMLLoss: 0.2367 
2022-03-14 11:04:36 - train: epoch 0035, iter [01200, 05004], lr: 0.010000, loss: 3.0463, tea_CELoss: 1.3497 stu_CELoss: 1.4769 DMLLoss: 0.2197 
2022-03-14 11:05:09 - train: epoch 0035, iter [01300, 05004], lr: 0.010000, loss: 3.6054, tea_CELoss: 1.6139 stu_CELoss: 1.7720 DMLLoss: 0.2195 
2022-03-14 11:05:43 - train: epoch 0035, iter [01400, 05004], lr: 0.010000, loss: 3.5288, tea_CELoss: 1.6067 stu_CELoss: 1.7043 DMLLoss: 0.2178 
2022-03-14 11:06:15 - train: epoch 0035, iter [01500, 05004], lr: 0.010000, loss: 3.6026, tea_CELoss: 1.6251 stu_CELoss: 1.7526 DMLLoss: 0.2249 
2022-03-14 11:06:49 - train: epoch 0035, iter [01600, 05004], lr: 0.010000, loss: 3.2751, tea_CELoss: 1.4569 stu_CELoss: 1.6032 DMLLoss: 0.2151 
2022-03-14 11:07:22 - train: epoch 0035, iter [01700, 05004], lr: 0.010000, loss: 2.9400, tea_CELoss: 1.2917 stu_CELoss: 1.4422 DMLLoss: 0.2061 
2022-03-14 11:07:55 - train: epoch 0035, iter [01800, 05004], lr: 0.010000, loss: 3.7298, tea_CELoss: 1.6154 stu_CELoss: 1.8634 DMLLoss: 0.2510 
2022-03-14 11:08:28 - train: epoch 0035, iter [01900, 05004], lr: 0.010000, loss: 3.5239, tea_CELoss: 1.5570 stu_CELoss: 1.7316 DMLLoss: 0.2353 
2022-03-14 11:09:01 - train: epoch 0035, iter [02000, 05004], lr: 0.010000, loss: 3.5353, tea_CELoss: 1.5992 stu_CELoss: 1.7166 DMLLoss: 0.2195 
2022-03-14 11:09:35 - train: epoch 0035, iter [02100, 05004], lr: 0.010000, loss: 3.4385, tea_CELoss: 1.5484 stu_CELoss: 1.6641 DMLLoss: 0.2260 
2022-03-14 11:10:08 - train: epoch 0035, iter [02200, 05004], lr: 0.010000, loss: 3.2529, tea_CELoss: 1.4396 stu_CELoss: 1.6072 DMLLoss: 0.2061 
2022-03-14 11:10:42 - train: epoch 0035, iter [02300, 05004], lr: 0.010000, loss: 3.3960, tea_CELoss: 1.5047 stu_CELoss: 1.6638 DMLLoss: 0.2275 
2022-03-14 11:11:14 - train: epoch 0035, iter [02400, 05004], lr: 0.010000, loss: 3.4958, tea_CELoss: 1.5211 stu_CELoss: 1.7455 DMLLoss: 0.2292 
2022-03-14 11:11:47 - train: epoch 0035, iter [02500, 05004], lr: 0.010000, loss: 3.4638, tea_CELoss: 1.5600 stu_CELoss: 1.6958 DMLLoss: 0.2080 
2022-03-14 11:12:20 - train: epoch 0035, iter [02600, 05004], lr: 0.010000, loss: 3.2678, tea_CELoss: 1.4319 stu_CELoss: 1.6298 DMLLoss: 0.2061 
2022-03-14 11:12:53 - train: epoch 0035, iter [02700, 05004], lr: 0.010000, loss: 3.6044, tea_CELoss: 1.6274 stu_CELoss: 1.7589 DMLLoss: 0.2181 
2022-03-14 11:13:26 - train: epoch 0035, iter [02800, 05004], lr: 0.010000, loss: 3.6768, tea_CELoss: 1.6276 stu_CELoss: 1.8148 DMLLoss: 0.2344 
2022-03-14 11:14:00 - train: epoch 0035, iter [02900, 05004], lr: 0.010000, loss: 3.1155, tea_CELoss: 1.3804 stu_CELoss: 1.5372 DMLLoss: 0.1979 
2022-03-14 11:14:33 - train: epoch 0035, iter [03000, 05004], lr: 0.010000, loss: 3.1987, tea_CELoss: 1.3950 stu_CELoss: 1.5860 DMLLoss: 0.2176 
2022-03-14 11:15:06 - train: epoch 0035, iter [03100, 05004], lr: 0.010000, loss: 3.7206, tea_CELoss: 1.6683 stu_CELoss: 1.8362 DMLLoss: 0.2161 
2022-03-14 11:15:39 - train: epoch 0035, iter [03200, 05004], lr: 0.010000, loss: 3.1810, tea_CELoss: 1.4382 stu_CELoss: 1.5331 DMLLoss: 0.2096 
2022-03-14 11:16:12 - train: epoch 0035, iter [03300, 05004], lr: 0.010000, loss: 3.4591, tea_CELoss: 1.5301 stu_CELoss: 1.7020 DMLLoss: 0.2270 
2022-03-14 11:16:44 - train: epoch 0035, iter [03400, 05004], lr: 0.010000, loss: 3.8471, tea_CELoss: 1.7385 stu_CELoss: 1.8804 DMLLoss: 0.2282 
2022-03-14 11:17:17 - train: epoch 0035, iter [03500, 05004], lr: 0.010000, loss: 2.9121, tea_CELoss: 1.2864 stu_CELoss: 1.4223 DMLLoss: 0.2033 
2022-03-14 11:17:50 - train: epoch 0035, iter [03600, 05004], lr: 0.010000, loss: 3.6209, tea_CELoss: 1.6451 stu_CELoss: 1.7373 DMLLoss: 0.2385 
2022-03-14 11:18:24 - train: epoch 0035, iter [03700, 05004], lr: 0.010000, loss: 3.2826, tea_CELoss: 1.4516 stu_CELoss: 1.6229 DMLLoss: 0.2080 
2022-03-14 11:18:56 - train: epoch 0035, iter [03800, 05004], lr: 0.010000, loss: 2.9636, tea_CELoss: 1.3108 stu_CELoss: 1.4582 DMLLoss: 0.1946 
2022-03-14 11:19:30 - train: epoch 0035, iter [03900, 05004], lr: 0.010000, loss: 3.4489, tea_CELoss: 1.5513 stu_CELoss: 1.6808 DMLLoss: 0.2168 
2022-03-14 11:20:02 - train: epoch 0035, iter [04000, 05004], lr: 0.010000, loss: 3.1809, tea_CELoss: 1.4361 stu_CELoss: 1.5494 DMLLoss: 0.1954 
2022-03-14 11:20:36 - train: epoch 0035, iter [04100, 05004], lr: 0.010000, loss: 3.5180, tea_CELoss: 1.5930 stu_CELoss: 1.6891 DMLLoss: 0.2359 
2022-03-14 11:21:08 - train: epoch 0035, iter [04200, 05004], lr: 0.010000, loss: 3.1685, tea_CELoss: 1.3995 stu_CELoss: 1.5584 DMLLoss: 0.2106 
2022-03-14 11:21:41 - train: epoch 0035, iter [04300, 05004], lr: 0.010000, loss: 3.5411, tea_CELoss: 1.5704 stu_CELoss: 1.7434 DMLLoss: 0.2273 
2022-03-14 11:22:14 - train: epoch 0035, iter [04400, 05004], lr: 0.010000, loss: 3.7443, tea_CELoss: 1.6442 stu_CELoss: 1.8667 DMLLoss: 0.2334 
2022-03-14 11:22:48 - train: epoch 0035, iter [04500, 05004], lr: 0.010000, loss: 3.5385, tea_CELoss: 1.5823 stu_CELoss: 1.7218 DMLLoss: 0.2344 
2022-03-14 11:23:20 - train: epoch 0035, iter [04600, 05004], lr: 0.010000, loss: 3.5089, tea_CELoss: 1.5788 stu_CELoss: 1.7002 DMLLoss: 0.2299 
2022-03-14 11:23:53 - train: epoch 0035, iter [04700, 05004], lr: 0.010000, loss: 3.6628, tea_CELoss: 1.6431 stu_CELoss: 1.7860 DMLLoss: 0.2337 
2022-03-14 11:24:26 - train: epoch 0035, iter [04800, 05004], lr: 0.010000, loss: 3.4975, tea_CELoss: 1.5839 stu_CELoss: 1.7201 DMLLoss: 0.1935 
2022-03-14 11:25:00 - train: epoch 0035, iter [04900, 05004], lr: 0.010000, loss: 3.3484, tea_CELoss: 1.4878 stu_CELoss: 1.6281 DMLLoss: 0.2326 
2022-03-14 11:25:31 - train: epoch 0035, iter [05000, 05004], lr: 0.010000, loss: 3.3738, tea_CELoss: 1.5159 stu_CELoss: 1.6434 DMLLoss: 0.2145 
2022-03-14 11:25:32 - train: epoch 035, train_loss: 3.4238
2022-03-14 11:28:01 - eval: epoch: 035, tea_acc1: 68.402%, tea_acc5: 88.736%, tea_test_loss: 1.2720, stu_acc1: 65.788%, stu_acc5: 86.952%, stu_test_loss: 1.3984
2022-03-14 11:28:02 - until epoch: 035, tea_best_acc1: 68.402%, stu_best_acc1: 65.788%
2022-03-14 11:28:02 - epoch 036 lr: 0.010000000000000002
2022-03-14 11:28:40 - train: epoch 0036, iter [00100, 05004], lr: 0.010000, loss: 3.5015, tea_CELoss: 1.6012 stu_CELoss: 1.7058 DMLLoss: 0.1944 
2022-03-14 11:29:13 - train: epoch 0036, iter [00200, 05004], lr: 0.010000, loss: 2.8231, tea_CELoss: 1.2046 stu_CELoss: 1.3858 DMLLoss: 0.2327 
2022-03-14 11:29:46 - train: epoch 0036, iter [00300, 05004], lr: 0.010000, loss: 2.8851, tea_CELoss: 1.2729 stu_CELoss: 1.3986 DMLLoss: 0.2137 
2022-03-14 11:30:19 - train: epoch 0036, iter [00400, 05004], lr: 0.010000, loss: 3.2321, tea_CELoss: 1.4463 stu_CELoss: 1.5662 DMLLoss: 0.2195 
2022-03-14 11:30:52 - train: epoch 0036, iter [00500, 05004], lr: 0.010000, loss: 3.1794, tea_CELoss: 1.4268 stu_CELoss: 1.5434 DMLLoss: 0.2092 
2022-03-14 11:31:26 - train: epoch 0036, iter [00600, 05004], lr: 0.010000, loss: 3.1829, tea_CELoss: 1.4091 stu_CELoss: 1.5406 DMLLoss: 0.2332 
2022-03-14 11:31:59 - train: epoch 0036, iter [00700, 05004], lr: 0.010000, loss: 3.2141, tea_CELoss: 1.4777 stu_CELoss: 1.5016 DMLLoss: 0.2348 
2022-03-14 11:32:32 - train: epoch 0036, iter [00800, 05004], lr: 0.010000, loss: 3.1286, tea_CELoss: 1.3942 stu_CELoss: 1.5206 DMLLoss: 0.2138 
2022-03-14 11:33:05 - train: epoch 0036, iter [00900, 05004], lr: 0.010000, loss: 3.3754, tea_CELoss: 1.5098 stu_CELoss: 1.6547 DMLLoss: 0.2109 
2022-03-14 11:33:38 - train: epoch 0036, iter [01000, 05004], lr: 0.010000, loss: 3.1357, tea_CELoss: 1.3698 stu_CELoss: 1.5405 DMLLoss: 0.2254 
2022-03-14 11:34:11 - train: epoch 0036, iter [01100, 05004], lr: 0.010000, loss: 3.2900, tea_CELoss: 1.4415 stu_CELoss: 1.6227 DMLLoss: 0.2258 
2022-03-14 11:34:45 - train: epoch 0036, iter [01200, 05004], lr: 0.010000, loss: 3.4536, tea_CELoss: 1.5241 stu_CELoss: 1.7027 DMLLoss: 0.2268 
2022-03-14 11:35:18 - train: epoch 0036, iter [01300, 05004], lr: 0.010000, loss: 3.4488, tea_CELoss: 1.5483 stu_CELoss: 1.6736 DMLLoss: 0.2269 
2022-03-14 11:35:51 - train: epoch 0036, iter [01400, 05004], lr: 0.010000, loss: 3.4988, tea_CELoss: 1.5762 stu_CELoss: 1.6785 DMLLoss: 0.2441 
2022-03-14 11:36:24 - train: epoch 0036, iter [01500, 05004], lr: 0.010000, loss: 3.4700, tea_CELoss: 1.5413 stu_CELoss: 1.6966 DMLLoss: 0.2320 
2022-03-14 11:36:57 - train: epoch 0036, iter [01600, 05004], lr: 0.010000, loss: 3.6257, tea_CELoss: 1.5980 stu_CELoss: 1.7917 DMLLoss: 0.2360 
2022-03-14 11:37:31 - train: epoch 0036, iter [01700, 05004], lr: 0.010000, loss: 3.3370, tea_CELoss: 1.4858 stu_CELoss: 1.6269 DMLLoss: 0.2244 
2022-03-14 11:38:04 - train: epoch 0036, iter [01800, 05004], lr: 0.010000, loss: 3.1857, tea_CELoss: 1.4301 stu_CELoss: 1.5666 DMLLoss: 0.1890 
2022-03-14 11:38:37 - train: epoch 0036, iter [01900, 05004], lr: 0.010000, loss: 3.7963, tea_CELoss: 1.6620 stu_CELoss: 1.8770 DMLLoss: 0.2573 
2022-03-14 11:39:10 - train: epoch 0036, iter [02000, 05004], lr: 0.010000, loss: 3.4632, tea_CELoss: 1.5989 stu_CELoss: 1.6581 DMLLoss: 0.2061 
2022-03-14 11:39:43 - train: epoch 0036, iter [02100, 05004], lr: 0.010000, loss: 3.2156, tea_CELoss: 1.4472 stu_CELoss: 1.5715 DMLLoss: 0.1969 
2022-03-14 11:40:16 - train: epoch 0036, iter [02200, 05004], lr: 0.010000, loss: 3.2963, tea_CELoss: 1.4747 stu_CELoss: 1.6110 DMLLoss: 0.2107 
2022-03-14 11:40:49 - train: epoch 0036, iter [02300, 05004], lr: 0.010000, loss: 3.6504, tea_CELoss: 1.6294 stu_CELoss: 1.8016 DMLLoss: 0.2193 
2022-03-14 11:41:22 - train: epoch 0036, iter [02400, 05004], lr: 0.010000, loss: 3.7994, tea_CELoss: 1.7459 stu_CELoss: 1.8226 DMLLoss: 0.2310 
2022-03-14 11:41:55 - train: epoch 0036, iter [02500, 05004], lr: 0.010000, loss: 3.0773, tea_CELoss: 1.3780 stu_CELoss: 1.4911 DMLLoss: 0.2082 
2022-03-14 11:42:29 - train: epoch 0036, iter [02600, 05004], lr: 0.010000, loss: 3.5038, tea_CELoss: 1.5574 stu_CELoss: 1.7447 DMLLoss: 0.2017 
2022-03-14 11:43:02 - train: epoch 0036, iter [02700, 05004], lr: 0.010000, loss: 3.2202, tea_CELoss: 1.4368 stu_CELoss: 1.5696 DMLLoss: 0.2138 
2022-03-14 11:43:35 - train: epoch 0036, iter [02800, 05004], lr: 0.010000, loss: 3.4577, tea_CELoss: 1.5349 stu_CELoss: 1.6870 DMLLoss: 0.2358 
2022-03-14 11:44:08 - train: epoch 0036, iter [02900, 05004], lr: 0.010000, loss: 3.3716, tea_CELoss: 1.4790 stu_CELoss: 1.6489 DMLLoss: 0.2437 
2022-03-14 11:44:41 - train: epoch 0036, iter [03000, 05004], lr: 0.010000, loss: 3.1853, tea_CELoss: 1.4078 stu_CELoss: 1.5528 DMLLoss: 0.2247 
2022-03-14 11:45:15 - train: epoch 0036, iter [03100, 05004], lr: 0.010000, loss: 3.4355, tea_CELoss: 1.4982 stu_CELoss: 1.6981 DMLLoss: 0.2392 
2022-03-14 11:45:48 - train: epoch 0036, iter [03200, 05004], lr: 0.010000, loss: 3.6912, tea_CELoss: 1.6460 stu_CELoss: 1.8191 DMLLoss: 0.2261 
2022-03-14 11:46:20 - train: epoch 0036, iter [03300, 05004], lr: 0.010000, loss: 3.2908, tea_CELoss: 1.4891 stu_CELoss: 1.6087 DMLLoss: 0.1930 
2022-03-14 11:46:53 - train: epoch 0036, iter [03400, 05004], lr: 0.010000, loss: 3.1863, tea_CELoss: 1.4060 stu_CELoss: 1.5427 DMLLoss: 0.2375 
2022-03-14 11:47:27 - train: epoch 0036, iter [03500, 05004], lr: 0.010000, loss: 3.7681, tea_CELoss: 1.6669 stu_CELoss: 1.8653 DMLLoss: 0.2359 
2022-03-14 11:48:00 - train: epoch 0036, iter [03600, 05004], lr: 0.010000, loss: 3.5127, tea_CELoss: 1.5738 stu_CELoss: 1.7031 DMLLoss: 0.2357 
2022-03-14 11:48:34 - train: epoch 0036, iter [03700, 05004], lr: 0.010000, loss: 3.3371, tea_CELoss: 1.4644 stu_CELoss: 1.6404 DMLLoss: 0.2323 
2022-03-14 11:49:07 - train: epoch 0036, iter [03800, 05004], lr: 0.010000, loss: 3.7972, tea_CELoss: 1.6848 stu_CELoss: 1.8718 DMLLoss: 0.2406 
2022-03-14 11:49:40 - train: epoch 0036, iter [03900, 05004], lr: 0.010000, loss: 3.4577, tea_CELoss: 1.5609 stu_CELoss: 1.6670 DMLLoss: 0.2298 
2022-03-14 11:50:13 - train: epoch 0036, iter [04000, 05004], lr: 0.010000, loss: 3.3705, tea_CELoss: 1.5187 stu_CELoss: 1.6307 DMLLoss: 0.2211 
2022-03-14 11:50:46 - train: epoch 0036, iter [04100, 05004], lr: 0.010000, loss: 3.2845, tea_CELoss: 1.4871 stu_CELoss: 1.5668 DMLLoss: 0.2306 
2022-03-14 11:51:20 - train: epoch 0036, iter [04200, 05004], lr: 0.010000, loss: 3.5843, tea_CELoss: 1.5920 stu_CELoss: 1.7624 DMLLoss: 0.2299 
2022-03-14 11:51:53 - train: epoch 0036, iter [04300, 05004], lr: 0.010000, loss: 3.2272, tea_CELoss: 1.4364 stu_CELoss: 1.5692 DMLLoss: 0.2216 
2022-03-14 11:52:26 - train: epoch 0036, iter [04400, 05004], lr: 0.010000, loss: 3.6637, tea_CELoss: 1.6162 stu_CELoss: 1.8113 DMLLoss: 0.2362 
2022-03-14 11:52:59 - train: epoch 0036, iter [04500, 05004], lr: 0.010000, loss: 3.4034, tea_CELoss: 1.4922 stu_CELoss: 1.6632 DMLLoss: 0.2479 
2022-03-14 11:53:32 - train: epoch 0036, iter [04600, 05004], lr: 0.010000, loss: 3.0472, tea_CELoss: 1.3857 stu_CELoss: 1.4729 DMLLoss: 0.1887 
2022-03-14 11:54:06 - train: epoch 0036, iter [04700, 05004], lr: 0.010000, loss: 3.3081, tea_CELoss: 1.4493 stu_CELoss: 1.6104 DMLLoss: 0.2485 
2022-03-14 11:54:39 - train: epoch 0036, iter [04800, 05004], lr: 0.010000, loss: 3.4431, tea_CELoss: 1.5134 stu_CELoss: 1.6738 DMLLoss: 0.2559 
2022-03-14 11:55:12 - train: epoch 0036, iter [04900, 05004], lr: 0.010000, loss: 3.3755, tea_CELoss: 1.5200 stu_CELoss: 1.6206 DMLLoss: 0.2350 
2022-03-14 11:55:44 - train: epoch 0036, iter [05000, 05004], lr: 0.010000, loss: 3.3571, tea_CELoss: 1.4946 stu_CELoss: 1.6403 DMLLoss: 0.2222 
2022-03-14 11:55:45 - train: epoch 036, train_loss: 3.4020
2022-03-14 11:58:13 - eval: epoch: 036, tea_acc1: 68.590%, tea_acc5: 88.766%, tea_test_loss: 1.2676, stu_acc1: 66.106%, stu_acc5: 87.070%, stu_test_loss: 1.3879
2022-03-14 11:58:14 - until epoch: 036, tea_best_acc1: 68.590%, stu_best_acc1: 66.106%
2022-03-14 11:58:14 - epoch 037 lr: 0.010000000000000002
2022-03-14 11:58:52 - train: epoch 0037, iter [00100, 05004], lr: 0.010000, loss: 2.8993, tea_CELoss: 1.2811 stu_CELoss: 1.4202 DMLLoss: 0.1981 
2022-03-14 11:59:25 - train: epoch 0037, iter [00200, 05004], lr: 0.010000, loss: 3.1656, tea_CELoss: 1.3933 stu_CELoss: 1.5634 DMLLoss: 0.2089 
2022-03-14 11:59:58 - train: epoch 0037, iter [00300, 05004], lr: 0.010000, loss: 3.1829, tea_CELoss: 1.4197 stu_CELoss: 1.5238 DMLLoss: 0.2394 
2022-03-14 12:00:31 - train: epoch 0037, iter [00400, 05004], lr: 0.010000, loss: 2.9905, tea_CELoss: 1.3064 stu_CELoss: 1.4652 DMLLoss: 0.2189 
2022-03-14 12:01:04 - train: epoch 0037, iter [00500, 05004], lr: 0.010000, loss: 3.7433, tea_CELoss: 1.6849 stu_CELoss: 1.8237 DMLLoss: 0.2347 
2022-03-14 12:01:37 - train: epoch 0037, iter [00600, 05004], lr: 0.010000, loss: 3.9981, tea_CELoss: 1.7822 stu_CELoss: 1.9618 DMLLoss: 0.2541 
2022-03-14 12:02:11 - train: epoch 0037, iter [00700, 05004], lr: 0.010000, loss: 3.8803, tea_CELoss: 1.7588 stu_CELoss: 1.8663 DMLLoss: 0.2552 
2022-03-14 12:02:44 - train: epoch 0037, iter [00800, 05004], lr: 0.010000, loss: 3.0061, tea_CELoss: 1.3360 stu_CELoss: 1.4435 DMLLoss: 0.2266 
2022-03-14 12:03:17 - train: epoch 0037, iter [00900, 05004], lr: 0.010000, loss: 3.5644, tea_CELoss: 1.6201 stu_CELoss: 1.7093 DMLLoss: 0.2349 
2022-03-14 12:03:50 - train: epoch 0037, iter [01000, 05004], lr: 0.010000, loss: 3.2444, tea_CELoss: 1.4636 stu_CELoss: 1.5943 DMLLoss: 0.1865 
2022-03-14 12:04:23 - train: epoch 0037, iter [01100, 05004], lr: 0.010000, loss: 3.5353, tea_CELoss: 1.5576 stu_CELoss: 1.7390 DMLLoss: 0.2386 
2022-03-14 12:04:56 - train: epoch 0037, iter [01200, 05004], lr: 0.010000, loss: 3.3616, tea_CELoss: 1.4684 stu_CELoss: 1.6847 DMLLoss: 0.2085 
2022-03-14 12:05:30 - train: epoch 0037, iter [01300, 05004], lr: 0.010000, loss: 3.7663, tea_CELoss: 1.7149 stu_CELoss: 1.8227 DMLLoss: 0.2287 
2022-03-14 12:06:03 - train: epoch 0037, iter [01400, 05004], lr: 0.010000, loss: 3.9413, tea_CELoss: 1.7544 stu_CELoss: 1.9491 DMLLoss: 0.2378 
2022-03-14 12:06:36 - train: epoch 0037, iter [01500, 05004], lr: 0.010000, loss: 3.1721, tea_CELoss: 1.3911 stu_CELoss: 1.5513 DMLLoss: 0.2297 
2022-03-14 12:07:09 - train: epoch 0037, iter [01600, 05004], lr: 0.010000, loss: 3.3855, tea_CELoss: 1.5022 stu_CELoss: 1.6611 DMLLoss: 0.2222 
2022-03-14 12:07:42 - train: epoch 0037, iter [01700, 05004], lr: 0.010000, loss: 3.2886, tea_CELoss: 1.4700 stu_CELoss: 1.5739 DMLLoss: 0.2448 
2022-03-14 12:08:16 - train: epoch 0037, iter [01800, 05004], lr: 0.010000, loss: 3.5082, tea_CELoss: 1.5817 stu_CELoss: 1.6957 DMLLoss: 0.2309 
2022-03-14 12:08:49 - train: epoch 0037, iter [01900, 05004], lr: 0.010000, loss: 3.2533, tea_CELoss: 1.4704 stu_CELoss: 1.5323 DMLLoss: 0.2506 
2022-03-14 12:09:22 - train: epoch 0037, iter [02000, 05004], lr: 0.010000, loss: 3.2909, tea_CELoss: 1.4626 stu_CELoss: 1.5991 DMLLoss: 0.2292 
2022-03-14 12:09:55 - train: epoch 0037, iter [02100, 05004], lr: 0.010000, loss: 3.1825, tea_CELoss: 1.4039 stu_CELoss: 1.5439 DMLLoss: 0.2347 
2022-03-14 12:10:29 - train: epoch 0037, iter [02200, 05004], lr: 0.010000, loss: 3.4306, tea_CELoss: 1.5234 stu_CELoss: 1.6550 DMLLoss: 0.2522 
2022-03-14 12:11:02 - train: epoch 0037, iter [02300, 05004], lr: 0.010000, loss: 3.0441, tea_CELoss: 1.3405 stu_CELoss: 1.4789 DMLLoss: 0.2247 
2022-03-14 12:11:35 - train: epoch 0037, iter [02400, 05004], lr: 0.010000, loss: 3.5066, tea_CELoss: 1.5284 stu_CELoss: 1.7115 DMLLoss: 0.2667 
2022-03-14 12:12:08 - train: epoch 0037, iter [02500, 05004], lr: 0.010000, loss: 3.6331, tea_CELoss: 1.6314 stu_CELoss: 1.7674 DMLLoss: 0.2343 
2022-03-14 12:12:42 - train: epoch 0037, iter [02600, 05004], lr: 0.010000, loss: 4.1927, tea_CELoss: 1.9184 stu_CELoss: 2.0227 DMLLoss: 0.2516 
2022-03-14 12:13:15 - train: epoch 0037, iter [02700, 05004], lr: 0.010000, loss: 4.0555, tea_CELoss: 1.7814 stu_CELoss: 2.0171 DMLLoss: 0.2571 
2022-03-14 12:13:48 - train: epoch 0037, iter [02800, 05004], lr: 0.010000, loss: 3.2766, tea_CELoss: 1.4617 stu_CELoss: 1.5973 DMLLoss: 0.2177 
2022-03-14 12:14:21 - train: epoch 0037, iter [02900, 05004], lr: 0.010000, loss: 3.2299, tea_CELoss: 1.4428 stu_CELoss: 1.5700 DMLLoss: 0.2171 
2022-03-14 12:14:54 - train: epoch 0037, iter [03000, 05004], lr: 0.010000, loss: 3.8143, tea_CELoss: 1.7208 stu_CELoss: 1.8774 DMLLoss: 0.2161 
2022-03-14 12:15:28 - train: epoch 0037, iter [03100, 05004], lr: 0.010000, loss: 3.1626, tea_CELoss: 1.4110 stu_CELoss: 1.5279 DMLLoss: 0.2238 
2022-03-14 12:16:02 - train: epoch 0037, iter [03200, 05004], lr: 0.010000, loss: 3.7918, tea_CELoss: 1.6897 stu_CELoss: 1.8619 DMLLoss: 0.2402 
2022-03-14 12:16:35 - train: epoch 0037, iter [03300, 05004], lr: 0.010000, loss: 3.3074, tea_CELoss: 1.4731 stu_CELoss: 1.6059 DMLLoss: 0.2285 
2022-03-14 12:17:08 - train: epoch 0037, iter [03400, 05004], lr: 0.010000, loss: 3.0224, tea_CELoss: 1.3882 stu_CELoss: 1.4198 DMLLoss: 0.2144 
2022-03-14 12:17:41 - train: epoch 0037, iter [03500, 05004], lr: 0.010000, loss: 3.4295, tea_CELoss: 1.5389 stu_CELoss: 1.6516 DMLLoss: 0.2391 
2022-03-14 12:18:15 - train: epoch 0037, iter [03600, 05004], lr: 0.010000, loss: 3.4607, tea_CELoss: 1.5160 stu_CELoss: 1.7111 DMLLoss: 0.2336 
2022-03-14 12:18:48 - train: epoch 0037, iter [03700, 05004], lr: 0.010000, loss: 3.3004, tea_CELoss: 1.4766 stu_CELoss: 1.5868 DMLLoss: 0.2370 
2022-03-14 12:19:21 - train: epoch 0037, iter [03800, 05004], lr: 0.010000, loss: 3.5258, tea_CELoss: 1.5762 stu_CELoss: 1.6940 DMLLoss: 0.2555 
2022-03-14 12:19:54 - train: epoch 0037, iter [03900, 05004], lr: 0.010000, loss: 3.9273, tea_CELoss: 1.7172 stu_CELoss: 1.9668 DMLLoss: 0.2433 
2022-03-14 12:20:28 - train: epoch 0037, iter [04000, 05004], lr: 0.010000, loss: 3.6215, tea_CELoss: 1.6070 stu_CELoss: 1.7646 DMLLoss: 0.2500 
2022-03-14 12:21:01 - train: epoch 0037, iter [04100, 05004], lr: 0.010000, loss: 3.2951, tea_CELoss: 1.4757 stu_CELoss: 1.5734 DMLLoss: 0.2459 
2022-03-14 12:21:34 - train: epoch 0037, iter [04200, 05004], lr: 0.010000, loss: 3.5853, tea_CELoss: 1.6163 stu_CELoss: 1.7395 DMLLoss: 0.2295 
2022-03-14 12:22:07 - train: epoch 0037, iter [04300, 05004], lr: 0.010000, loss: 3.3697, tea_CELoss: 1.4901 stu_CELoss: 1.6461 DMLLoss: 0.2335 
2022-03-14 12:22:40 - train: epoch 0037, iter [04400, 05004], lr: 0.010000, loss: 3.2503, tea_CELoss: 1.4861 stu_CELoss: 1.5584 DMLLoss: 0.2057 
2022-03-14 12:23:13 - train: epoch 0037, iter [04500, 05004], lr: 0.010000, loss: 3.4856, tea_CELoss: 1.5443 stu_CELoss: 1.6883 DMLLoss: 0.2530 
2022-03-14 12:23:46 - train: epoch 0037, iter [04600, 05004], lr: 0.010000, loss: 3.3110, tea_CELoss: 1.4450 stu_CELoss: 1.6040 DMLLoss: 0.2619 
2022-03-14 12:24:19 - train: epoch 0037, iter [04700, 05004], lr: 0.010000, loss: 3.3528, tea_CELoss: 1.4748 stu_CELoss: 1.6512 DMLLoss: 0.2269 
2022-03-14 12:24:53 - train: epoch 0037, iter [04800, 05004], lr: 0.010000, loss: 3.2464, tea_CELoss: 1.4462 stu_CELoss: 1.5599 DMLLoss: 0.2403 
2022-03-14 12:25:26 - train: epoch 0037, iter [04900, 05004], lr: 0.010000, loss: 3.5894, tea_CELoss: 1.6139 stu_CELoss: 1.7244 DMLLoss: 0.2512 
2022-03-14 12:25:57 - train: epoch 0037, iter [05000, 05004], lr: 0.010000, loss: 3.3275, tea_CELoss: 1.4989 stu_CELoss: 1.6081 DMLLoss: 0.2206 
2022-03-14 12:25:58 - train: epoch 037, train_loss: 3.3963
2022-03-14 12:28:27 - eval: epoch: 037, tea_acc1: 68.758%, tea_acc5: 89.044%, tea_test_loss: 1.2530, stu_acc1: 66.210%, stu_acc5: 87.260%, stu_test_loss: 1.3887
2022-03-14 12:28:28 - until epoch: 037, tea_best_acc1: 68.758%, stu_best_acc1: 66.210%
2022-03-14 12:28:28 - epoch 038 lr: 0.010000000000000002
2022-03-14 12:29:06 - train: epoch 0038, iter [00100, 05004], lr: 0.010000, loss: 3.0979, tea_CELoss: 1.3664 stu_CELoss: 1.4898 DMLLoss: 0.2417 
2022-03-14 12:29:39 - train: epoch 0038, iter [00200, 05004], lr: 0.010000, loss: 3.5785, tea_CELoss: 1.5651 stu_CELoss: 1.7723 DMLLoss: 0.2410 
2022-03-14 12:30:12 - train: epoch 0038, iter [00300, 05004], lr: 0.010000, loss: 3.0699, tea_CELoss: 1.3576 stu_CELoss: 1.4970 DMLLoss: 0.2153 
2022-03-14 12:30:46 - train: epoch 0038, iter [00400, 05004], lr: 0.010000, loss: 3.0157, tea_CELoss: 1.3203 stu_CELoss: 1.4761 DMLLoss: 0.2193 
2022-03-14 12:31:19 - train: epoch 0038, iter [00500, 05004], lr: 0.010000, loss: 3.0803, tea_CELoss: 1.3173 stu_CELoss: 1.5120 DMLLoss: 0.2510 
2022-03-14 12:31:52 - train: epoch 0038, iter [00600, 05004], lr: 0.010000, loss: 3.6953, tea_CELoss: 1.6498 stu_CELoss: 1.8038 DMLLoss: 0.2417 
2022-03-14 12:32:25 - train: epoch 0038, iter [00700, 05004], lr: 0.010000, loss: 3.0824, tea_CELoss: 1.3352 stu_CELoss: 1.5002 DMLLoss: 0.2470 
2022-03-14 12:32:59 - train: epoch 0038, iter [00800, 05004], lr: 0.010000, loss: 3.1362, tea_CELoss: 1.3791 stu_CELoss: 1.5272 DMLLoss: 0.2299 
2022-03-14 12:33:31 - train: epoch 0038, iter [00900, 05004], lr: 0.010000, loss: 3.5265, tea_CELoss: 1.5740 stu_CELoss: 1.7194 DMLLoss: 0.2331 
2022-03-14 12:34:05 - train: epoch 0038, iter [01000, 05004], lr: 0.010000, loss: 3.4775, tea_CELoss: 1.5982 stu_CELoss: 1.6648 DMLLoss: 0.2146 
2022-03-14 12:34:38 - train: epoch 0038, iter [01100, 05004], lr: 0.010000, loss: 3.5637, tea_CELoss: 1.5892 stu_CELoss: 1.7296 DMLLoss: 0.2449 
2022-03-14 12:35:11 - train: epoch 0038, iter [01200, 05004], lr: 0.010000, loss: 3.5666, tea_CELoss: 1.6042 stu_CELoss: 1.7357 DMLLoss: 0.2267 
2022-03-14 12:35:45 - train: epoch 0038, iter [01300, 05004], lr: 0.010000, loss: 3.3389, tea_CELoss: 1.4924 stu_CELoss: 1.6175 DMLLoss: 0.2291 
2022-03-14 12:36:18 - train: epoch 0038, iter [01400, 05004], lr: 0.010000, loss: 3.2451, tea_CELoss: 1.4756 stu_CELoss: 1.5464 DMLLoss: 0.2230 
2022-03-14 12:36:51 - train: epoch 0038, iter [01500, 05004], lr: 0.010000, loss: 3.2872, tea_CELoss: 1.4584 stu_CELoss: 1.6107 DMLLoss: 0.2181 
2022-03-14 12:37:25 - train: epoch 0038, iter [01600, 05004], lr: 0.010000, loss: 3.2187, tea_CELoss: 1.4266 stu_CELoss: 1.5647 DMLLoss: 0.2273 
2022-03-14 12:37:58 - train: epoch 0038, iter [01700, 05004], lr: 0.010000, loss: 3.2850, tea_CELoss: 1.4770 stu_CELoss: 1.5781 DMLLoss: 0.2299 
2022-03-14 12:38:31 - train: epoch 0038, iter [01800, 05004], lr: 0.010000, loss: 3.6206, tea_CELoss: 1.5788 stu_CELoss: 1.7928 DMLLoss: 0.2490 
2022-03-14 12:39:04 - train: epoch 0038, iter [01900, 05004], lr: 0.010000, loss: 3.7482, tea_CELoss: 1.6643 stu_CELoss: 1.8255 DMLLoss: 0.2584 
2022-03-14 12:39:37 - train: epoch 0038, iter [02000, 05004], lr: 0.010000, loss: 3.4522, tea_CELoss: 1.5256 stu_CELoss: 1.7003 DMLLoss: 0.2264 
2022-03-14 12:40:11 - train: epoch 0038, iter [02100, 05004], lr: 0.010000, loss: 3.2710, tea_CELoss: 1.4365 stu_CELoss: 1.5918 DMLLoss: 0.2428 
2022-03-14 12:40:44 - train: epoch 0038, iter [02200, 05004], lr: 0.010000, loss: 3.2549, tea_CELoss: 1.4620 stu_CELoss: 1.5706 DMLLoss: 0.2223 
2022-03-14 12:41:17 - train: epoch 0038, iter [02300, 05004], lr: 0.010000, loss: 3.2605, tea_CELoss: 1.4365 stu_CELoss: 1.5806 DMLLoss: 0.2435 
2022-03-14 12:41:51 - train: epoch 0038, iter [02400, 05004], lr: 0.010000, loss: 3.9389, tea_CELoss: 1.7385 stu_CELoss: 1.9286 DMLLoss: 0.2718 
2022-03-14 12:42:24 - train: epoch 0038, iter [02500, 05004], lr: 0.010000, loss: 3.2051, tea_CELoss: 1.3959 stu_CELoss: 1.5738 DMLLoss: 0.2354 
2022-03-14 12:42:57 - train: epoch 0038, iter [02600, 05004], lr: 0.010000, loss: 3.5751, tea_CELoss: 1.5881 stu_CELoss: 1.7408 DMLLoss: 0.2461 
2022-03-14 12:43:31 - train: epoch 0038, iter [02700, 05004], lr: 0.010000, loss: 3.6409, tea_CELoss: 1.5552 stu_CELoss: 1.8284 DMLLoss: 0.2573 
2022-03-14 12:44:04 - train: epoch 0038, iter [02800, 05004], lr: 0.010000, loss: 3.9627, tea_CELoss: 1.7830 stu_CELoss: 1.9347 DMLLoss: 0.2451 
2022-03-14 12:44:38 - train: epoch 0038, iter [02900, 05004], lr: 0.010000, loss: 3.3277, tea_CELoss: 1.4967 stu_CELoss: 1.6162 DMLLoss: 0.2148 
2022-03-14 12:45:10 - train: epoch 0038, iter [03000, 05004], lr: 0.010000, loss: 3.2577, tea_CELoss: 1.4369 stu_CELoss: 1.5955 DMLLoss: 0.2253 
2022-03-14 12:45:44 - train: epoch 0038, iter [03100, 05004], lr: 0.010000, loss: 3.6259, tea_CELoss: 1.6156 stu_CELoss: 1.7623 DMLLoss: 0.2480 
2022-03-14 12:46:17 - train: epoch 0038, iter [03200, 05004], lr: 0.010000, loss: 2.8686, tea_CELoss: 1.2752 stu_CELoss: 1.3864 DMLLoss: 0.2070 
2022-03-14 12:46:51 - train: epoch 0038, iter [03300, 05004], lr: 0.010000, loss: 2.8723, tea_CELoss: 1.2358 stu_CELoss: 1.4087 DMLLoss: 0.2278 
2022-03-14 12:47:24 - train: epoch 0038, iter [03400, 05004], lr: 0.010000, loss: 3.1741, tea_CELoss: 1.4112 stu_CELoss: 1.5504 DMLLoss: 0.2125 
2022-03-14 12:47:57 - train: epoch 0038, iter [03500, 05004], lr: 0.010000, loss: 3.3652, tea_CELoss: 1.4963 stu_CELoss: 1.6500 DMLLoss: 0.2189 
2022-03-14 12:48:30 - train: epoch 0038, iter [03600, 05004], lr: 0.010000, loss: 3.3118, tea_CELoss: 1.4517 stu_CELoss: 1.6057 DMLLoss: 0.2545 
2022-03-14 12:49:04 - train: epoch 0038, iter [03700, 05004], lr: 0.010000, loss: 3.2294, tea_CELoss: 1.4014 stu_CELoss: 1.5720 DMLLoss: 0.2561 
2022-03-14 12:49:36 - train: epoch 0038, iter [03800, 05004], lr: 0.010000, loss: 3.8482, tea_CELoss: 1.7029 stu_CELoss: 1.8882 DMLLoss: 0.2571 
2022-03-14 12:50:10 - train: epoch 0038, iter [03900, 05004], lr: 0.010000, loss: 3.1485, tea_CELoss: 1.4006 stu_CELoss: 1.5014 DMLLoss: 0.2465 
2022-03-14 12:50:44 - train: epoch 0038, iter [04000, 05004], lr: 0.010000, loss: 3.3224, tea_CELoss: 1.4620 stu_CELoss: 1.6215 DMLLoss: 0.2389 
2022-03-14 12:51:17 - train: epoch 0038, iter [04100, 05004], lr: 0.010000, loss: 2.9676, tea_CELoss: 1.3469 stu_CELoss: 1.4323 DMLLoss: 0.1883 
2022-03-14 12:51:50 - train: epoch 0038, iter [04200, 05004], lr: 0.010000, loss: 3.0713, tea_CELoss: 1.3512 stu_CELoss: 1.4919 DMLLoss: 0.2281 
2022-03-14 12:52:23 - train: epoch 0038, iter [04300, 05004], lr: 0.010000, loss: 3.5215, tea_CELoss: 1.5762 stu_CELoss: 1.6953 DMLLoss: 0.2500 
2022-03-14 12:52:56 - train: epoch 0038, iter [04400, 05004], lr: 0.010000, loss: 3.5207, tea_CELoss: 1.5481 stu_CELoss: 1.7033 DMLLoss: 0.2693 
2022-03-14 12:53:30 - train: epoch 0038, iter [04500, 05004], lr: 0.010000, loss: 3.7648, tea_CELoss: 1.6604 stu_CELoss: 1.8562 DMLLoss: 0.2482 
2022-03-14 12:54:03 - train: epoch 0038, iter [04600, 05004], lr: 0.010000, loss: 3.5921, tea_CELoss: 1.6603 stu_CELoss: 1.7050 DMLLoss: 0.2268 
2022-03-14 12:54:36 - train: epoch 0038, iter [04700, 05004], lr: 0.010000, loss: 3.2899, tea_CELoss: 1.4609 stu_CELoss: 1.6008 DMLLoss: 0.2282 
2022-03-14 12:55:10 - train: epoch 0038, iter [04800, 05004], lr: 0.010000, loss: 3.2494, tea_CELoss: 1.4483 stu_CELoss: 1.5677 DMLLoss: 0.2334 
2022-03-14 12:55:43 - train: epoch 0038, iter [04900, 05004], lr: 0.010000, loss: 3.2194, tea_CELoss: 1.4201 stu_CELoss: 1.5578 DMLLoss: 0.2416 
2022-03-14 12:56:14 - train: epoch 0038, iter [05000, 05004], lr: 0.010000, loss: 3.1639, tea_CELoss: 1.3140 stu_CELoss: 1.5780 DMLLoss: 0.2719 
2022-03-14 12:56:15 - train: epoch 038, train_loss: 3.3879
2022-03-14 12:58:44 - eval: epoch: 038, tea_acc1: 68.042%, tea_acc5: 88.530%, tea_test_loss: 1.2864, stu_acc1: 66.100%, stu_acc5: 87.188%, stu_test_loss: 1.3900
2022-03-14 12:58:45 - until epoch: 038, tea_best_acc1: 68.758%, stu_best_acc1: 66.210%
2022-03-14 12:58:45 - epoch 039 lr: 0.010000000000000002
2022-03-14 12:59:23 - train: epoch 0039, iter [00100, 05004], lr: 0.010000, loss: 3.2887, tea_CELoss: 1.4441 stu_CELoss: 1.6003 DMLLoss: 0.2442 
2022-03-14 12:59:57 - train: epoch 0039, iter [00200, 05004], lr: 0.010000, loss: 3.6053, tea_CELoss: 1.5866 stu_CELoss: 1.7944 DMLLoss: 0.2242 
2022-03-14 13:00:30 - train: epoch 0039, iter [00300, 05004], lr: 0.010000, loss: 3.1404, tea_CELoss: 1.3460 stu_CELoss: 1.5373 DMLLoss: 0.2571 
2022-03-14 13:01:04 - train: epoch 0039, iter [00400, 05004], lr: 0.010000, loss: 3.3187, tea_CELoss: 1.5016 stu_CELoss: 1.5975 DMLLoss: 0.2197 
2022-03-14 13:01:37 - train: epoch 0039, iter [00500, 05004], lr: 0.010000, loss: 3.3980, tea_CELoss: 1.5260 stu_CELoss: 1.6339 DMLLoss: 0.2382 
2022-03-14 13:02:10 - train: epoch 0039, iter [00600, 05004], lr: 0.010000, loss: 3.1032, tea_CELoss: 1.3800 stu_CELoss: 1.5043 DMLLoss: 0.2189 
2022-03-14 13:02:43 - train: epoch 0039, iter [00700, 05004], lr: 0.010000, loss: 3.9702, tea_CELoss: 1.7755 stu_CELoss: 1.9409 DMLLoss: 0.2539 
2022-03-14 13:03:16 - train: epoch 0039, iter [00800, 05004], lr: 0.010000, loss: 3.3267, tea_CELoss: 1.4528 stu_CELoss: 1.6396 DMLLoss: 0.2343 
2022-03-14 13:03:49 - train: epoch 0039, iter [00900, 05004], lr: 0.010000, loss: 3.5003, tea_CELoss: 1.5269 stu_CELoss: 1.7379 DMLLoss: 0.2355 
2022-03-14 13:04:23 - train: epoch 0039, iter [01000, 05004], lr: 0.010000, loss: 3.2838, tea_CELoss: 1.4601 stu_CELoss: 1.6066 DMLLoss: 0.2171 
2022-03-14 13:04:56 - train: epoch 0039, iter [01100, 05004], lr: 0.010000, loss: 3.8167, tea_CELoss: 1.6858 stu_CELoss: 1.8517 DMLLoss: 0.2791 
2022-03-14 13:05:29 - train: epoch 0039, iter [01200, 05004], lr: 0.010000, loss: 3.2590, tea_CELoss: 1.4220 stu_CELoss: 1.5915 DMLLoss: 0.2455 
2022-03-14 13:06:03 - train: epoch 0039, iter [01300, 05004], lr: 0.010000, loss: 3.6719, tea_CELoss: 1.6419 stu_CELoss: 1.7865 DMLLoss: 0.2436 
2022-03-14 13:06:36 - train: epoch 0039, iter [01400, 05004], lr: 0.010000, loss: 3.2209, tea_CELoss: 1.4122 stu_CELoss: 1.5658 DMLLoss: 0.2429 
2022-03-14 13:07:09 - train: epoch 0039, iter [01500, 05004], lr: 0.010000, loss: 2.9360, tea_CELoss: 1.2909 stu_CELoss: 1.4176 DMLLoss: 0.2275 
2022-03-14 13:07:43 - train: epoch 0039, iter [01600, 05004], lr: 0.010000, loss: 3.4924, tea_CELoss: 1.5459 stu_CELoss: 1.6854 DMLLoss: 0.2611 
2022-03-14 13:08:16 - train: epoch 0039, iter [01700, 05004], lr: 0.010000, loss: 3.2449, tea_CELoss: 1.4350 stu_CELoss: 1.5666 DMLLoss: 0.2433 
2022-03-14 13:08:49 - train: epoch 0039, iter [01800, 05004], lr: 0.010000, loss: 3.5177, tea_CELoss: 1.5557 stu_CELoss: 1.6982 DMLLoss: 0.2638 
2022-03-14 13:09:22 - train: epoch 0039, iter [01900, 05004], lr: 0.010000, loss: 2.8324, tea_CELoss: 1.2278 stu_CELoss: 1.3792 DMLLoss: 0.2255 
2022-03-14 13:09:56 - train: epoch 0039, iter [02000, 05004], lr: 0.010000, loss: 3.4480, tea_CELoss: 1.5385 stu_CELoss: 1.6594 DMLLoss: 0.2501 
2022-03-14 13:10:29 - train: epoch 0039, iter [02100, 05004], lr: 0.010000, loss: 3.7038, tea_CELoss: 1.6612 stu_CELoss: 1.7860 DMLLoss: 0.2567 
2022-03-14 13:11:01 - train: epoch 0039, iter [02200, 05004], lr: 0.010000, loss: 3.1825, tea_CELoss: 1.3917 stu_CELoss: 1.5558 DMLLoss: 0.2349 
2022-03-14 13:11:35 - train: epoch 0039, iter [02300, 05004], lr: 0.010000, loss: 4.0660, tea_CELoss: 1.8386 stu_CELoss: 1.9642 DMLLoss: 0.2632 
2022-03-14 13:12:09 - train: epoch 0039, iter [02400, 05004], lr: 0.010000, loss: 3.9361, tea_CELoss: 1.7394 stu_CELoss: 1.9242 DMLLoss: 0.2725 
2022-03-14 13:12:41 - train: epoch 0039, iter [02500, 05004], lr: 0.010000, loss: 3.6206, tea_CELoss: 1.6145 stu_CELoss: 1.7651 DMLLoss: 0.2409 
2022-03-14 13:13:15 - train: epoch 0039, iter [02600, 05004], lr: 0.010000, loss: 3.3053, tea_CELoss: 1.4731 stu_CELoss: 1.6098 DMLLoss: 0.2224 
2022-03-14 13:13:48 - train: epoch 0039, iter [02700, 05004], lr: 0.010000, loss: 3.7787, tea_CELoss: 1.7086 stu_CELoss: 1.8070 DMLLoss: 0.2630 
2022-03-14 13:14:21 - train: epoch 0039, iter [02800, 05004], lr: 0.010000, loss: 3.4261, tea_CELoss: 1.4990 stu_CELoss: 1.6745 DMLLoss: 0.2527 
2022-03-14 13:14:55 - train: epoch 0039, iter [02900, 05004], lr: 0.010000, loss: 2.9646, tea_CELoss: 1.3265 stu_CELoss: 1.4292 DMLLoss: 0.2089 
2022-03-14 13:15:28 - train: epoch 0039, iter [03000, 05004], lr: 0.010000, loss: 3.5317, tea_CELoss: 1.5776 stu_CELoss: 1.7103 DMLLoss: 0.2437 
2022-03-14 13:16:01 - train: epoch 0039, iter [03100, 05004], lr: 0.010000, loss: 3.1875, tea_CELoss: 1.4056 stu_CELoss: 1.5402 DMLLoss: 0.2418 
2022-03-14 13:16:34 - train: epoch 0039, iter [03200, 05004], lr: 0.010000, loss: 3.3486, tea_CELoss: 1.4785 stu_CELoss: 1.6200 DMLLoss: 0.2501 
2022-03-14 13:17:07 - train: epoch 0039, iter [03300, 05004], lr: 0.010000, loss: 3.3187, tea_CELoss: 1.4589 stu_CELoss: 1.5705 DMLLoss: 0.2893 
2022-03-14 13:17:41 - train: epoch 0039, iter [03400, 05004], lr: 0.010000, loss: 3.5692, tea_CELoss: 1.5501 stu_CELoss: 1.7477 DMLLoss: 0.2714 
2022-03-14 13:18:14 - train: epoch 0039, iter [03500, 05004], lr: 0.010000, loss: 3.7388, tea_CELoss: 1.6753 stu_CELoss: 1.8084 DMLLoss: 0.2551 
2022-03-14 13:18:47 - train: epoch 0039, iter [03600, 05004], lr: 0.010000, loss: 3.6115, tea_CELoss: 1.6461 stu_CELoss: 1.7288 DMLLoss: 0.2366 
2022-03-14 13:19:20 - train: epoch 0039, iter [03700, 05004], lr: 0.010000, loss: 3.0832, tea_CELoss: 1.4153 stu_CELoss: 1.4511 DMLLoss: 0.2168 
2022-03-14 13:19:53 - train: epoch 0039, iter [03800, 05004], lr: 0.010000, loss: 2.8808, tea_CELoss: 1.2770 stu_CELoss: 1.3830 DMLLoss: 0.2208 
2022-03-14 13:20:25 - train: epoch 0039, iter [03900, 05004], lr: 0.010000, loss: 3.5099, tea_CELoss: 1.5557 stu_CELoss: 1.7016 DMLLoss: 0.2527 
2022-03-14 13:20:59 - train: epoch 0039, iter [04000, 05004], lr: 0.010000, loss: 3.4570, tea_CELoss: 1.5415 stu_CELoss: 1.6849 DMLLoss: 0.2306 
2022-03-14 13:21:33 - train: epoch 0039, iter [04100, 05004], lr: 0.010000, loss: 3.5585, tea_CELoss: 1.5781 stu_CELoss: 1.7125 DMLLoss: 0.2679 
2022-03-14 13:22:06 - train: epoch 0039, iter [04200, 05004], lr: 0.010000, loss: 3.6420, tea_CELoss: 1.5803 stu_CELoss: 1.8001 DMLLoss: 0.2616 
2022-03-14 13:22:39 - train: epoch 0039, iter [04300, 05004], lr: 0.010000, loss: 3.1612, tea_CELoss: 1.3894 stu_CELoss: 1.5446 DMLLoss: 0.2271 
2022-03-14 13:23:12 - train: epoch 0039, iter [04400, 05004], lr: 0.010000, loss: 3.3738, tea_CELoss: 1.4694 stu_CELoss: 1.6494 DMLLoss: 0.2550 
2022-03-14 13:23:46 - train: epoch 0039, iter [04500, 05004], lr: 0.010000, loss: 3.2415, tea_CELoss: 1.4495 stu_CELoss: 1.5790 DMLLoss: 0.2131 
2022-03-14 13:24:19 - train: epoch 0039, iter [04600, 05004], lr: 0.010000, loss: 3.5560, tea_CELoss: 1.5686 stu_CELoss: 1.7362 DMLLoss: 0.2511 
2022-03-14 13:24:51 - train: epoch 0039, iter [04700, 05004], lr: 0.010000, loss: 3.5035, tea_CELoss: 1.5160 stu_CELoss: 1.7172 DMLLoss: 0.2702 
2022-03-14 13:25:25 - train: epoch 0039, iter [04800, 05004], lr: 0.010000, loss: 3.0904, tea_CELoss: 1.3562 stu_CELoss: 1.4932 DMLLoss: 0.2411 
2022-03-14 13:25:58 - train: epoch 0039, iter [04900, 05004], lr: 0.010000, loss: 3.0997, tea_CELoss: 1.3486 stu_CELoss: 1.4971 DMLLoss: 0.2539 
2022-03-14 13:26:30 - train: epoch 0039, iter [05000, 05004], lr: 0.010000, loss: 3.4973, tea_CELoss: 1.5695 stu_CELoss: 1.7054 DMLLoss: 0.2224 
2022-03-14 13:26:31 - train: epoch 039, train_loss: 3.3886
2022-03-14 13:29:00 - eval: epoch: 039, tea_acc1: 68.534%, tea_acc5: 88.944%, tea_test_loss: 1.2556, stu_acc1: 66.004%, stu_acc5: 87.180%, stu_test_loss: 1.3796
2022-03-14 13:29:00 - until epoch: 039, tea_best_acc1: 68.758%, stu_best_acc1: 66.210%
2022-03-14 13:29:00 - epoch 040 lr: 0.010000000000000002
2022-03-14 13:29:38 - train: epoch 0040, iter [00100, 05004], lr: 0.010000, loss: 3.9473, tea_CELoss: 1.7414 stu_CELoss: 1.9325 DMLLoss: 0.2734 
2022-03-14 13:30:12 - train: epoch 0040, iter [00200, 05004], lr: 0.010000, loss: 3.5585, tea_CELoss: 1.5347 stu_CELoss: 1.7566 DMLLoss: 0.2672 
2022-03-14 13:30:45 - train: epoch 0040, iter [00300, 05004], lr: 0.010000, loss: 3.6832, tea_CELoss: 1.6337 stu_CELoss: 1.7709 DMLLoss: 0.2785 
2022-03-14 13:31:17 - train: epoch 0040, iter [00400, 05004], lr: 0.010000, loss: 3.0137, tea_CELoss: 1.2929 stu_CELoss: 1.4673 DMLLoss: 0.2536 
2022-03-14 13:31:51 - train: epoch 0040, iter [00500, 05004], lr: 0.010000, loss: 3.0594, tea_CELoss: 1.3774 stu_CELoss: 1.4518 DMLLoss: 0.2302 
2022-03-14 13:32:24 - train: epoch 0040, iter [00600, 05004], lr: 0.010000, loss: 3.1168, tea_CELoss: 1.3763 stu_CELoss: 1.5033 DMLLoss: 0.2372 
2022-03-14 13:32:57 - train: epoch 0040, iter [00700, 05004], lr: 0.010000, loss: 3.5714, tea_CELoss: 1.5753 stu_CELoss: 1.7344 DMLLoss: 0.2617 
2022-03-14 13:33:30 - train: epoch 0040, iter [00800, 05004], lr: 0.010000, loss: 3.4003, tea_CELoss: 1.5065 stu_CELoss: 1.6121 DMLLoss: 0.2817 
2022-03-14 13:34:03 - train: epoch 0040, iter [00900, 05004], lr: 0.010000, loss: 3.1860, tea_CELoss: 1.4001 stu_CELoss: 1.5389 DMLLoss: 0.2470 
2022-03-14 13:34:37 - train: epoch 0040, iter [01000, 05004], lr: 0.010000, loss: 3.2470, tea_CELoss: 1.4122 stu_CELoss: 1.5537 DMLLoss: 0.2811 
2022-03-14 13:35:09 - train: epoch 0040, iter [01100, 05004], lr: 0.010000, loss: 2.8712, tea_CELoss: 1.2669 stu_CELoss: 1.3825 DMLLoss: 0.2218 
2022-03-14 13:35:43 - train: epoch 0040, iter [01200, 05004], lr: 0.010000, loss: 3.2112, tea_CELoss: 1.4007 stu_CELoss: 1.5356 DMLLoss: 0.2749 
2022-03-14 13:36:16 - train: epoch 0040, iter [01300, 05004], lr: 0.010000, loss: 3.1458, tea_CELoss: 1.3750 stu_CELoss: 1.5188 DMLLoss: 0.2520 
2022-03-14 13:36:49 - train: epoch 0040, iter [01400, 05004], lr: 0.010000, loss: 3.7342, tea_CELoss: 1.6491 stu_CELoss: 1.8406 DMLLoss: 0.2444 
2022-03-14 13:37:21 - train: epoch 0040, iter [01500, 05004], lr: 0.010000, loss: 3.7126, tea_CELoss: 1.6766 stu_CELoss: 1.7678 DMLLoss: 0.2683 
2022-03-14 13:37:55 - train: epoch 0040, iter [01600, 05004], lr: 0.010000, loss: 3.4168, tea_CELoss: 1.5335 stu_CELoss: 1.6302 DMLLoss: 0.2531 
2022-03-14 13:38:27 - train: epoch 0040, iter [01700, 05004], lr: 0.010000, loss: 3.5562, tea_CELoss: 1.5790 stu_CELoss: 1.7284 DMLLoss: 0.2488 
2022-03-14 13:39:01 - train: epoch 0040, iter [01800, 05004], lr: 0.010000, loss: 3.0431, tea_CELoss: 1.3377 stu_CELoss: 1.4922 DMLLoss: 0.2133 
2022-03-14 13:39:34 - train: epoch 0040, iter [01900, 05004], lr: 0.010000, loss: 3.1804, tea_CELoss: 1.4261 stu_CELoss: 1.5020 DMLLoss: 0.2523 
2022-03-14 13:40:08 - train: epoch 0040, iter [02000, 05004], lr: 0.010000, loss: 3.2886, tea_CELoss: 1.4495 stu_CELoss: 1.6070 DMLLoss: 0.2321 
2022-03-14 13:40:41 - train: epoch 0040, iter [02100, 05004], lr: 0.010000, loss: 2.8673, tea_CELoss: 1.2672 stu_CELoss: 1.3699 DMLLoss: 0.2302 
2022-03-14 13:41:14 - train: epoch 0040, iter [02200, 05004], lr: 0.010000, loss: 3.4646, tea_CELoss: 1.5598 stu_CELoss: 1.6476 DMLLoss: 0.2573 
2022-03-14 13:41:47 - train: epoch 0040, iter [02300, 05004], lr: 0.010000, loss: 3.5113, tea_CELoss: 1.5451 stu_CELoss: 1.6957 DMLLoss: 0.2705 
2022-03-14 13:42:21 - train: epoch 0040, iter [02400, 05004], lr: 0.010000, loss: 3.4555, tea_CELoss: 1.5192 stu_CELoss: 1.6922 DMLLoss: 0.2440 
2022-03-14 13:42:53 - train: epoch 0040, iter [02500, 05004], lr: 0.010000, loss: 3.6082, tea_CELoss: 1.6185 stu_CELoss: 1.7512 DMLLoss: 0.2386 
2022-03-14 13:43:27 - train: epoch 0040, iter [02600, 05004], lr: 0.010000, loss: 3.4248, tea_CELoss: 1.5595 stu_CELoss: 1.6285 DMLLoss: 0.2368 
2022-03-14 13:44:00 - train: epoch 0040, iter [02700, 05004], lr: 0.010000, loss: 3.6652, tea_CELoss: 1.6305 stu_CELoss: 1.7912 DMLLoss: 0.2435 
2022-03-14 13:44:33 - train: epoch 0040, iter [02800, 05004], lr: 0.010000, loss: 3.4891, tea_CELoss: 1.5329 stu_CELoss: 1.6904 DMLLoss: 0.2658 
2022-03-14 13:45:06 - train: epoch 0040, iter [02900, 05004], lr: 0.010000, loss: 3.7734, tea_CELoss: 1.6491 stu_CELoss: 1.8540 DMLLoss: 0.2703 
2022-03-14 13:45:39 - train: epoch 0040, iter [03000, 05004], lr: 0.010000, loss: 3.6555, tea_CELoss: 1.6211 stu_CELoss: 1.7776 DMLLoss: 0.2567 
2022-03-14 13:46:12 - train: epoch 0040, iter [03100, 05004], lr: 0.010000, loss: 3.5503, tea_CELoss: 1.5564 stu_CELoss: 1.7258 DMLLoss: 0.2682 
2022-03-14 13:46:46 - train: epoch 0040, iter [03200, 05004], lr: 0.010000, loss: 3.7632, tea_CELoss: 1.6648 stu_CELoss: 1.8228 DMLLoss: 0.2756 
2022-03-14 13:47:19 - train: epoch 0040, iter [03300, 05004], lr: 0.010000, loss: 3.6126, tea_CELoss: 1.6223 stu_CELoss: 1.7475 DMLLoss: 0.2428 
2022-03-14 13:47:52 - train: epoch 0040, iter [03400, 05004], lr: 0.010000, loss: 3.3220, tea_CELoss: 1.4933 stu_CELoss: 1.5912 DMLLoss: 0.2374 
2022-03-14 13:48:25 - train: epoch 0040, iter [03500, 05004], lr: 0.010000, loss: 3.4774, tea_CELoss: 1.5407 stu_CELoss: 1.6822 DMLLoss: 0.2545 
2022-03-14 13:48:57 - train: epoch 0040, iter [03600, 05004], lr: 0.010000, loss: 3.5649, tea_CELoss: 1.5636 stu_CELoss: 1.7318 DMLLoss: 0.2694 
2022-03-14 13:49:30 - train: epoch 0040, iter [03700, 05004], lr: 0.010000, loss: 3.3341, tea_CELoss: 1.4449 stu_CELoss: 1.6399 DMLLoss: 0.2494 
2022-03-14 13:50:03 - train: epoch 0040, iter [03800, 05004], lr: 0.010000, loss: 3.3330, tea_CELoss: 1.4834 stu_CELoss: 1.5910 DMLLoss: 0.2585 
2022-03-14 13:50:36 - train: epoch 0040, iter [03900, 05004], lr: 0.010000, loss: 3.4311, tea_CELoss: 1.5460 stu_CELoss: 1.6473 DMLLoss: 0.2378 
2022-03-14 13:51:09 - train: epoch 0040, iter [04000, 05004], lr: 0.010000, loss: 3.0381, tea_CELoss: 1.3242 stu_CELoss: 1.4837 DMLLoss: 0.2302 
2022-03-14 13:51:42 - train: epoch 0040, iter [04100, 05004], lr: 0.010000, loss: 3.3111, tea_CELoss: 1.4453 stu_CELoss: 1.5952 DMLLoss: 0.2706 
2022-03-14 13:52:15 - train: epoch 0040, iter [04200, 05004], lr: 0.010000, loss: 3.3679, tea_CELoss: 1.4820 stu_CELoss: 1.6154 DMLLoss: 0.2705 
2022-03-14 13:52:47 - train: epoch 0040, iter [04300, 05004], lr: 0.010000, loss: 3.3777, tea_CELoss: 1.4945 stu_CELoss: 1.6446 DMLLoss: 0.2386 
2022-03-14 13:53:21 - train: epoch 0040, iter [04400, 05004], lr: 0.010000, loss: 3.1033, tea_CELoss: 1.2964 stu_CELoss: 1.5388 DMLLoss: 0.2681 
2022-03-14 13:53:54 - train: epoch 0040, iter [04500, 05004], lr: 0.010000, loss: 2.9744, tea_CELoss: 1.3154 stu_CELoss: 1.4175 DMLLoss: 0.2415 
2022-03-14 13:54:26 - train: epoch 0040, iter [04600, 05004], lr: 0.010000, loss: 3.4713, tea_CELoss: 1.5355 stu_CELoss: 1.6807 DMLLoss: 0.2552 
2022-03-14 13:54:59 - train: epoch 0040, iter [04700, 05004], lr: 0.010000, loss: 3.6659, tea_CELoss: 1.6072 stu_CELoss: 1.7927 DMLLoss: 0.2660 
2022-03-14 13:55:33 - train: epoch 0040, iter [04800, 05004], lr: 0.010000, loss: 3.3555, tea_CELoss: 1.4858 stu_CELoss: 1.6149 DMLLoss: 0.2549 
2022-03-14 13:56:05 - train: epoch 0040, iter [04900, 05004], lr: 0.010000, loss: 3.2756, tea_CELoss: 1.4365 stu_CELoss: 1.5862 DMLLoss: 0.2528 
2022-03-14 13:56:37 - train: epoch 0040, iter [05000, 05004], lr: 0.010000, loss: 3.4441, tea_CELoss: 1.4820 stu_CELoss: 1.6929 DMLLoss: 0.2692 
2022-03-14 13:56:38 - train: epoch 040, train_loss: 3.3828
2022-03-14 13:59:06 - eval: epoch: 040, tea_acc1: 68.864%, tea_acc5: 88.910%, tea_test_loss: 1.2574, stu_acc1: 65.742%, stu_acc5: 87.156%, stu_test_loss: 1.3928
2022-03-14 13:59:07 - until epoch: 040, tea_best_acc1: 68.864%, stu_best_acc1: 66.210%
2022-03-14 13:59:07 - epoch 041 lr: 0.010000000000000002
2022-03-14 13:59:45 - train: epoch 0041, iter [00100, 05004], lr: 0.010000, loss: 3.7270, tea_CELoss: 1.6990 stu_CELoss: 1.7653 DMLLoss: 0.2626 
2022-03-14 14:00:18 - train: epoch 0041, iter [00200, 05004], lr: 0.010000, loss: 4.0485, tea_CELoss: 1.8110 stu_CELoss: 1.9629 DMLLoss: 0.2745 
2022-03-14 14:00:52 - train: epoch 0041, iter [00300, 05004], lr: 0.010000, loss: 3.5373, tea_CELoss: 1.5336 stu_CELoss: 1.7314 DMLLoss: 0.2723 
2022-03-14 14:01:24 - train: epoch 0041, iter [00400, 05004], lr: 0.010000, loss: 3.2493, tea_CELoss: 1.4142 stu_CELoss: 1.5742 DMLLoss: 0.2610 
2022-03-14 14:01:57 - train: epoch 0041, iter [00500, 05004], lr: 0.010000, loss: 3.0327, tea_CELoss: 1.3337 stu_CELoss: 1.4251 DMLLoss: 0.2740 
2022-03-14 14:02:31 - train: epoch 0041, iter [00600, 05004], lr: 0.010000, loss: 3.6845, tea_CELoss: 1.6011 stu_CELoss: 1.8087 DMLLoss: 0.2747 
2022-03-14 14:03:04 - train: epoch 0041, iter [00700, 05004], lr: 0.010000, loss: 3.1163, tea_CELoss: 1.3646 stu_CELoss: 1.4962 DMLLoss: 0.2555 
2022-03-14 14:03:37 - train: epoch 0041, iter [00800, 05004], lr: 0.010000, loss: 3.2650, tea_CELoss: 1.4501 stu_CELoss: 1.5545 DMLLoss: 0.2604 
2022-03-14 14:04:12 - train: epoch 0041, iter [00900, 05004], lr: 0.010000, loss: 3.0030, tea_CELoss: 1.3644 stu_CELoss: 1.4132 DMLLoss: 0.2254 
2022-03-14 14:04:44 - train: epoch 0041, iter [01000, 05004], lr: 0.010000, loss: 3.5245, tea_CELoss: 1.5901 stu_CELoss: 1.7051 DMLLoss: 0.2293 
2022-03-14 14:05:17 - train: epoch 0041, iter [01100, 05004], lr: 0.010000, loss: 3.2736, tea_CELoss: 1.4771 stu_CELoss: 1.5471 DMLLoss: 0.2494 
2022-03-14 14:05:50 - train: epoch 0041, iter [01200, 05004], lr: 0.010000, loss: 3.0251, tea_CELoss: 1.3448 stu_CELoss: 1.4539 DMLLoss: 0.2264 
2022-03-14 14:06:24 - train: epoch 0041, iter [01300, 05004], lr: 0.010000, loss: 3.0035, tea_CELoss: 1.3123 stu_CELoss: 1.4505 DMLLoss: 0.2406 
2022-03-14 14:06:57 - train: epoch 0041, iter [01400, 05004], lr: 0.010000, loss: 3.5792, tea_CELoss: 1.5509 stu_CELoss: 1.7295 DMLLoss: 0.2988 
2022-03-14 14:07:30 - train: epoch 0041, iter [01500, 05004], lr: 0.010000, loss: 3.9468, tea_CELoss: 1.7354 stu_CELoss: 1.9448 DMLLoss: 0.2666 
2022-03-14 14:08:03 - train: epoch 0041, iter [01600, 05004], lr: 0.010000, loss: 3.1346, tea_CELoss: 1.3695 stu_CELoss: 1.5046 DMLLoss: 0.2605 
2022-03-14 14:08:36 - train: epoch 0041, iter [01700, 05004], lr: 0.010000, loss: 3.3739, tea_CELoss: 1.4634 stu_CELoss: 1.6755 DMLLoss: 0.2351 
2022-03-14 14:09:10 - train: epoch 0041, iter [01800, 05004], lr: 0.010000, loss: 3.4429, tea_CELoss: 1.5508 stu_CELoss: 1.6542 DMLLoss: 0.2379 
2022-03-14 14:09:43 - train: epoch 0041, iter [01900, 05004], lr: 0.010000, loss: 3.6092, tea_CELoss: 1.6341 stu_CELoss: 1.7219 DMLLoss: 0.2532 
2022-03-14 14:10:17 - train: epoch 0041, iter [02000, 05004], lr: 0.010000, loss: 3.4061, tea_CELoss: 1.4905 stu_CELoss: 1.6467 DMLLoss: 0.2690 
2022-03-14 14:10:50 - train: epoch 0041, iter [02100, 05004], lr: 0.010000, loss: 3.0111, tea_CELoss: 1.3314 stu_CELoss: 1.4271 DMLLoss: 0.2526 
2022-03-14 14:11:22 - train: epoch 0041, iter [02200, 05004], lr: 0.010000, loss: 3.0213, tea_CELoss: 1.3257 stu_CELoss: 1.4716 DMLLoss: 0.2241 
2022-03-14 14:11:56 - train: epoch 0041, iter [02300, 05004], lr: 0.010000, loss: 3.1925, tea_CELoss: 1.3895 stu_CELoss: 1.5204 DMLLoss: 0.2826 
2022-03-14 14:12:29 - train: epoch 0041, iter [02400, 05004], lr: 0.010000, loss: 3.5762, tea_CELoss: 1.5869 stu_CELoss: 1.7253 DMLLoss: 0.2639 
2022-03-14 14:13:02 - train: epoch 0041, iter [02500, 05004], lr: 0.010000, loss: 3.0457, tea_CELoss: 1.3379 stu_CELoss: 1.4759 DMLLoss: 0.2319 
2022-03-14 14:13:35 - train: epoch 0041, iter [02600, 05004], lr: 0.010000, loss: 3.8328, tea_CELoss: 1.7121 stu_CELoss: 1.8542 DMLLoss: 0.2665 
2022-03-14 14:14:08 - train: epoch 0041, iter [02700, 05004], lr: 0.010000, loss: 3.7063, tea_CELoss: 1.5938 stu_CELoss: 1.8104 DMLLoss: 0.3021 
2022-03-14 14:14:41 - train: epoch 0041, iter [02800, 05004], lr: 0.010000, loss: 3.1801, tea_CELoss: 1.3945 stu_CELoss: 1.5218 DMLLoss: 0.2638 
2022-03-14 14:15:15 - train: epoch 0041, iter [02900, 05004], lr: 0.010000, loss: 3.2505, tea_CELoss: 1.4096 stu_CELoss: 1.5983 DMLLoss: 0.2426 
2022-03-14 14:15:48 - train: epoch 0041, iter [03000, 05004], lr: 0.010000, loss: 3.6510, tea_CELoss: 1.6001 stu_CELoss: 1.7783 DMLLoss: 0.2727 
2022-03-14 14:16:22 - train: epoch 0041, iter [03100, 05004], lr: 0.010000, loss: 3.4018, tea_CELoss: 1.5158 stu_CELoss: 1.6072 DMLLoss: 0.2789 
2022-03-14 14:16:55 - train: epoch 0041, iter [03200, 05004], lr: 0.010000, loss: 3.2667, tea_CELoss: 1.4382 stu_CELoss: 1.5582 DMLLoss: 0.2703 
2022-03-14 14:17:28 - train: epoch 0041, iter [03300, 05004], lr: 0.010000, loss: 3.2244, tea_CELoss: 1.4414 stu_CELoss: 1.5430 DMLLoss: 0.2400 
2022-03-14 14:18:01 - train: epoch 0041, iter [03400, 05004], lr: 0.010000, loss: 3.2982, tea_CELoss: 1.5043 stu_CELoss: 1.5704 DMLLoss: 0.2236 
2022-03-14 14:18:34 - train: epoch 0041, iter [03500, 05004], lr: 0.010000, loss: 3.1290, tea_CELoss: 1.3680 stu_CELoss: 1.4920 DMLLoss: 0.2689 
2022-03-14 14:19:07 - train: epoch 0041, iter [03600, 05004], lr: 0.010000, loss: 3.6134, tea_CELoss: 1.5950 stu_CELoss: 1.7426 DMLLoss: 0.2758 
2022-03-14 14:19:40 - train: epoch 0041, iter [03700, 05004], lr: 0.010000, loss: 3.6454, tea_CELoss: 1.5953 stu_CELoss: 1.7794 DMLLoss: 0.2706 
2022-03-14 14:20:13 - train: epoch 0041, iter [03800, 05004], lr: 0.010000, loss: 3.2559, tea_CELoss: 1.4094 stu_CELoss: 1.6082 DMLLoss: 0.2383 
2022-03-14 14:20:46 - train: epoch 0041, iter [03900, 05004], lr: 0.010000, loss: 3.2028, tea_CELoss: 1.4111 stu_CELoss: 1.5543 DMLLoss: 0.2374 
2022-03-14 14:21:19 - train: epoch 0041, iter [04000, 05004], lr: 0.010000, loss: 3.2182, tea_CELoss: 1.4105 stu_CELoss: 1.5500 DMLLoss: 0.2576 
2022-03-14 14:21:52 - train: epoch 0041, iter [04100, 05004], lr: 0.010000, loss: 3.3883, tea_CELoss: 1.4669 stu_CELoss: 1.6697 DMLLoss: 0.2518 
2022-03-14 14:22:24 - train: epoch 0041, iter [04200, 05004], lr: 0.010000, loss: 2.8750, tea_CELoss: 1.2402 stu_CELoss: 1.3819 DMLLoss: 0.2529 
2022-03-14 14:22:58 - train: epoch 0041, iter [04300, 05004], lr: 0.010000, loss: 3.1196, tea_CELoss: 1.4262 stu_CELoss: 1.4668 DMLLoss: 0.2266 
2022-03-14 14:23:31 - train: epoch 0041, iter [04400, 05004], lr: 0.010000, loss: 2.9822, tea_CELoss: 1.2676 stu_CELoss: 1.4611 DMLLoss: 0.2535 
2022-03-14 14:24:05 - train: epoch 0041, iter [04500, 05004], lr: 0.010000, loss: 3.5148, tea_CELoss: 1.5391 stu_CELoss: 1.7140 DMLLoss: 0.2617 
2022-03-14 14:24:37 - train: epoch 0041, iter [04600, 05004], lr: 0.010000, loss: 3.6552, tea_CELoss: 1.6112 stu_CELoss: 1.7551 DMLLoss: 0.2889 
2022-03-14 14:25:11 - train: epoch 0041, iter [04700, 05004], lr: 0.010000, loss: 3.5038, tea_CELoss: 1.5814 stu_CELoss: 1.6623 DMLLoss: 0.2601 
2022-03-14 14:25:44 - train: epoch 0041, iter [04800, 05004], lr: 0.010000, loss: 3.1874, tea_CELoss: 1.3791 stu_CELoss: 1.5388 DMLLoss: 0.2696 
2022-03-14 14:26:16 - train: epoch 0041, iter [04900, 05004], lr: 0.010000, loss: 3.4598, tea_CELoss: 1.5424 stu_CELoss: 1.6626 DMLLoss: 0.2548 
2022-03-14 14:26:48 - train: epoch 0041, iter [05000, 05004], lr: 0.010000, loss: 3.3835, tea_CELoss: 1.4922 stu_CELoss: 1.6422 DMLLoss: 0.2492 
2022-03-14 14:26:49 - train: epoch 041, train_loss: 3.3882
2022-03-14 14:29:16 - eval: epoch: 041, tea_acc1: 68.604%, tea_acc5: 88.856%, tea_test_loss: 1.2645, stu_acc1: 66.146%, stu_acc5: 87.262%, stu_test_loss: 1.3891
2022-03-14 14:29:17 - until epoch: 041, tea_best_acc1: 68.864%, stu_best_acc1: 66.210%
2022-03-14 14:29:17 - epoch 042 lr: 0.010000000000000002
2022-03-14 14:29:55 - train: epoch 0042, iter [00100, 05004], lr: 0.010000, loss: 2.9107, tea_CELoss: 1.2535 stu_CELoss: 1.4076 DMLLoss: 0.2496 
2022-03-14 14:30:28 - train: epoch 0042, iter [00200, 05004], lr: 0.010000, loss: 3.1749, tea_CELoss: 1.4127 stu_CELoss: 1.5024 DMLLoss: 0.2598 
2022-03-14 14:31:01 - train: epoch 0042, iter [00300, 05004], lr: 0.010000, loss: 3.8904, tea_CELoss: 1.7046 stu_CELoss: 1.8999 DMLLoss: 0.2859 
2022-03-14 14:31:34 - train: epoch 0042, iter [00400, 05004], lr: 0.010000, loss: 2.9950, tea_CELoss: 1.3216 stu_CELoss: 1.4385 DMLLoss: 0.2349 
2022-03-14 14:32:07 - train: epoch 0042, iter [00500, 05004], lr: 0.010000, loss: 3.0722, tea_CELoss: 1.3035 stu_CELoss: 1.5198 DMLLoss: 0.2489 
2022-03-14 14:32:40 - train: epoch 0042, iter [00600, 05004], lr: 0.010000, loss: 3.2448, tea_CELoss: 1.4001 stu_CELoss: 1.6000 DMLLoss: 0.2447 
2022-03-14 14:33:13 - train: epoch 0042, iter [00700, 05004], lr: 0.010000, loss: 3.4909, tea_CELoss: 1.5627 stu_CELoss: 1.6766 DMLLoss: 0.2516 
2022-03-14 14:33:46 - train: epoch 0042, iter [00800, 05004], lr: 0.010000, loss: 3.2447, tea_CELoss: 1.4014 stu_CELoss: 1.6099 DMLLoss: 0.2334 
2022-03-14 14:34:19 - train: epoch 0042, iter [00900, 05004], lr: 0.010000, loss: 3.4841, tea_CELoss: 1.5791 stu_CELoss: 1.6538 DMLLoss: 0.2511 
2022-03-14 14:34:52 - train: epoch 0042, iter [01000, 05004], lr: 0.010000, loss: 3.9732, tea_CELoss: 1.7490 stu_CELoss: 1.9416 DMLLoss: 0.2826 
2022-03-14 14:35:25 - train: epoch 0042, iter [01100, 05004], lr: 0.010000, loss: 3.1065, tea_CELoss: 1.3370 stu_CELoss: 1.5188 DMLLoss: 0.2507 
2022-03-14 14:35:58 - train: epoch 0042, iter [01200, 05004], lr: 0.010000, loss: 2.9887, tea_CELoss: 1.2845 stu_CELoss: 1.4651 DMLLoss: 0.2391 
2022-03-14 14:36:32 - train: epoch 0042, iter [01300, 05004], lr: 0.010000, loss: 3.3526, tea_CELoss: 1.5161 stu_CELoss: 1.5678 DMLLoss: 0.2686 
2022-03-14 14:37:05 - train: epoch 0042, iter [01400, 05004], lr: 0.010000, loss: 3.8051, tea_CELoss: 1.7038 stu_CELoss: 1.8479 DMLLoss: 0.2534 
2022-03-14 14:37:39 - train: epoch 0042, iter [01500, 05004], lr: 0.010000, loss: 2.9954, tea_CELoss: 1.3176 stu_CELoss: 1.4267 DMLLoss: 0.2512 
2022-03-14 14:38:11 - train: epoch 0042, iter [01600, 05004], lr: 0.010000, loss: 3.5594, tea_CELoss: 1.5915 stu_CELoss: 1.7390 DMLLoss: 0.2289 
2022-03-14 14:38:45 - train: epoch 0042, iter [01700, 05004], lr: 0.010000, loss: 3.5793, tea_CELoss: 1.5562 stu_CELoss: 1.7534 DMLLoss: 0.2697 
2022-03-14 14:39:17 - train: epoch 0042, iter [01800, 05004], lr: 0.010000, loss: 2.9948, tea_CELoss: 1.2655 stu_CELoss: 1.4511 DMLLoss: 0.2782 
2022-03-14 14:39:51 - train: epoch 0042, iter [01900, 05004], lr: 0.010000, loss: 3.5792, tea_CELoss: 1.5439 stu_CELoss: 1.7298 DMLLoss: 0.3056 
2022-03-14 14:40:24 - train: epoch 0042, iter [02000, 05004], lr: 0.010000, loss: 3.5045, tea_CELoss: 1.5171 stu_CELoss: 1.7134 DMLLoss: 0.2740 
2022-03-14 14:40:57 - train: epoch 0042, iter [02100, 05004], lr: 0.010000, loss: 2.9970, tea_CELoss: 1.3076 stu_CELoss: 1.4380 DMLLoss: 0.2514 
2022-03-14 14:41:30 - train: epoch 0042, iter [02200, 05004], lr: 0.010000, loss: 3.0589, tea_CELoss: 1.2830 stu_CELoss: 1.5010 DMLLoss: 0.2749 
2022-03-14 14:42:03 - train: epoch 0042, iter [02300, 05004], lr: 0.010000, loss: 3.5546, tea_CELoss: 1.5154 stu_CELoss: 1.7534 DMLLoss: 0.2859 
2022-03-14 14:42:37 - train: epoch 0042, iter [02400, 05004], lr: 0.010000, loss: 3.3734, tea_CELoss: 1.5023 stu_CELoss: 1.6395 DMLLoss: 0.2315 
2022-03-14 14:43:10 - train: epoch 0042, iter [02500, 05004], lr: 0.010000, loss: 3.7055, tea_CELoss: 1.6437 stu_CELoss: 1.7837 DMLLoss: 0.2781 
2022-03-14 14:43:43 - train: epoch 0042, iter [02600, 05004], lr: 0.010000, loss: 3.6757, tea_CELoss: 1.6784 stu_CELoss: 1.7522 DMLLoss: 0.2451 
2022-03-14 14:44:16 - train: epoch 0042, iter [02700, 05004], lr: 0.010000, loss: 3.0406, tea_CELoss: 1.3624 stu_CELoss: 1.4489 DMLLoss: 0.2293 
2022-03-14 14:44:49 - train: epoch 0042, iter [02800, 05004], lr: 0.010000, loss: 3.1403, tea_CELoss: 1.3463 stu_CELoss: 1.5222 DMLLoss: 0.2718 
2022-03-14 14:45:23 - train: epoch 0042, iter [02900, 05004], lr: 0.010000, loss: 3.2176, tea_CELoss: 1.4555 stu_CELoss: 1.5430 DMLLoss: 0.2191 
2022-03-14 14:45:55 - train: epoch 0042, iter [03000, 05004], lr: 0.010000, loss: 3.3580, tea_CELoss: 1.4582 stu_CELoss: 1.6208 DMLLoss: 0.2791 
2022-03-14 14:46:29 - train: epoch 0042, iter [03100, 05004], lr: 0.010000, loss: 3.3304, tea_CELoss: 1.4588 stu_CELoss: 1.5875 DMLLoss: 0.2841 
2022-03-14 14:47:02 - train: epoch 0042, iter [03200, 05004], lr: 0.010000, loss: 3.9387, tea_CELoss: 1.7032 stu_CELoss: 1.9437 DMLLoss: 0.2919 
2022-03-14 14:47:34 - train: epoch 0042, iter [03300, 05004], lr: 0.010000, loss: 4.1486, tea_CELoss: 1.8842 stu_CELoss: 2.0120 DMLLoss: 0.2524 
2022-03-14 14:48:08 - train: epoch 0042, iter [03400, 05004], lr: 0.010000, loss: 3.0174, tea_CELoss: 1.2877 stu_CELoss: 1.4691 DMLLoss: 0.2606 
2022-03-14 14:48:41 - train: epoch 0042, iter [03500, 05004], lr: 0.010000, loss: 3.4668, tea_CELoss: 1.5213 stu_CELoss: 1.6894 DMLLoss: 0.2561 
2022-03-14 14:49:14 - train: epoch 0042, iter [03600, 05004], lr: 0.010000, loss: 3.4589, tea_CELoss: 1.5066 stu_CELoss: 1.6712 DMLLoss: 0.2811 
2022-03-14 14:49:47 - train: epoch 0042, iter [03700, 05004], lr: 0.010000, loss: 3.4756, tea_CELoss: 1.4961 stu_CELoss: 1.7072 DMLLoss: 0.2723 
2022-03-14 14:50:20 - train: epoch 0042, iter [03800, 05004], lr: 0.010000, loss: 3.0156, tea_CELoss: 1.3201 stu_CELoss: 1.4427 DMLLoss: 0.2528 
2022-03-14 14:50:53 - train: epoch 0042, iter [03900, 05004], lr: 0.010000, loss: 3.5126, tea_CELoss: 1.5602 stu_CELoss: 1.6902 DMLLoss: 0.2622 
2022-03-14 14:51:26 - train: epoch 0042, iter [04000, 05004], lr: 0.010000, loss: 3.1284, tea_CELoss: 1.4117 stu_CELoss: 1.4777 DMLLoss: 0.2390 
2022-03-14 14:51:59 - train: epoch 0042, iter [04100, 05004], lr: 0.010000, loss: 3.4072, tea_CELoss: 1.4549 stu_CELoss: 1.6860 DMLLoss: 0.2664 
2022-03-14 14:52:32 - train: epoch 0042, iter [04200, 05004], lr: 0.010000, loss: 3.7712, tea_CELoss: 1.6951 stu_CELoss: 1.7925 DMLLoss: 0.2835 
2022-03-14 14:53:05 - train: epoch 0042, iter [04300, 05004], lr: 0.010000, loss: 3.2340, tea_CELoss: 1.4224 stu_CELoss: 1.5752 DMLLoss: 0.2364 
2022-03-14 14:53:38 - train: epoch 0042, iter [04400, 05004], lr: 0.010000, loss: 3.0532, tea_CELoss: 1.3148 stu_CELoss: 1.4874 DMLLoss: 0.2511 
2022-03-14 14:54:11 - train: epoch 0042, iter [04500, 05004], lr: 0.010000, loss: 3.3407, tea_CELoss: 1.4585 stu_CELoss: 1.6204 DMLLoss: 0.2618 
2022-03-14 14:54:44 - train: epoch 0042, iter [04600, 05004], lr: 0.010000, loss: 3.5945, tea_CELoss: 1.5810 stu_CELoss: 1.7452 DMLLoss: 0.2684 
2022-03-14 14:55:17 - train: epoch 0042, iter [04700, 05004], lr: 0.010000, loss: 3.1573, tea_CELoss: 1.3671 stu_CELoss: 1.5424 DMLLoss: 0.2477 
2022-03-14 14:55:50 - train: epoch 0042, iter [04800, 05004], lr: 0.010000, loss: 3.6972, tea_CELoss: 1.6261 stu_CELoss: 1.7963 DMLLoss: 0.2748 
2022-03-14 14:56:24 - train: epoch 0042, iter [04900, 05004], lr: 0.010000, loss: 3.5245, tea_CELoss: 1.5209 stu_CELoss: 1.7394 DMLLoss: 0.2642 
2022-03-14 14:56:55 - train: epoch 0042, iter [05000, 05004], lr: 0.010000, loss: 3.5011, tea_CELoss: 1.5522 stu_CELoss: 1.6618 DMLLoss: 0.2871 
2022-03-14 14:56:56 - train: epoch 042, train_loss: 3.3921
2022-03-14 14:59:25 - eval: epoch: 042, tea_acc1: 68.540%, tea_acc5: 89.056%, tea_test_loss: 1.2618, stu_acc1: 65.870%, stu_acc5: 87.098%, stu_test_loss: 1.3965
2022-03-14 14:59:26 - until epoch: 042, tea_best_acc1: 68.864%, stu_best_acc1: 66.210%
2022-03-14 14:59:26 - epoch 043 lr: 0.010000000000000002
2022-03-14 15:00:04 - train: epoch 0043, iter [00100, 05004], lr: 0.010000, loss: 3.3467, tea_CELoss: 1.4293 stu_CELoss: 1.6637 DMLLoss: 0.2536 
2022-03-14 15:00:37 - train: epoch 0043, iter [00200, 05004], lr: 0.010000, loss: 4.0819, tea_CELoss: 1.8682 stu_CELoss: 1.9304 DMLLoss: 0.2833 
2022-03-14 15:01:10 - train: epoch 0043, iter [00300, 05004], lr: 0.010000, loss: 3.0516, tea_CELoss: 1.3782 stu_CELoss: 1.4320 DMLLoss: 0.2414 
2022-03-14 15:01:43 - train: epoch 0043, iter [00400, 05004], lr: 0.010000, loss: 3.0971, tea_CELoss: 1.3454 stu_CELoss: 1.5020 DMLLoss: 0.2496 
2022-03-14 15:02:16 - train: epoch 0043, iter [00500, 05004], lr: 0.010000, loss: 3.1641, tea_CELoss: 1.3854 stu_CELoss: 1.5122 DMLLoss: 0.2665 
2022-03-14 15:02:49 - train: epoch 0043, iter [00600, 05004], lr: 0.010000, loss: 3.4100, tea_CELoss: 1.4799 stu_CELoss: 1.6414 DMLLoss: 0.2886 
2022-03-14 15:03:22 - train: epoch 0043, iter [00700, 05004], lr: 0.010000, loss: 3.4141, tea_CELoss: 1.5211 stu_CELoss: 1.6331 DMLLoss: 0.2599 
2022-03-14 15:03:55 - train: epoch 0043, iter [00800, 05004], lr: 0.010000, loss: 3.0790, tea_CELoss: 1.3671 stu_CELoss: 1.4789 DMLLoss: 0.2330 
2022-03-14 15:04:28 - train: epoch 0043, iter [00900, 05004], lr: 0.010000, loss: 3.2093, tea_CELoss: 1.3778 stu_CELoss: 1.5659 DMLLoss: 0.2656 
2022-03-14 15:05:01 - train: epoch 0043, iter [01000, 05004], lr: 0.010000, loss: 3.8990, tea_CELoss: 1.7400 stu_CELoss: 1.8770 DMLLoss: 0.2820 
2022-03-14 15:05:34 - train: epoch 0043, iter [01100, 05004], lr: 0.010000, loss: 3.4441, tea_CELoss: 1.5264 stu_CELoss: 1.6596 DMLLoss: 0.2581 
2022-03-14 15:06:07 - train: epoch 0043, iter [01200, 05004], lr: 0.010000, loss: 3.3228, tea_CELoss: 1.4584 stu_CELoss: 1.6241 DMLLoss: 0.2403 
2022-03-14 15:06:40 - train: epoch 0043, iter [01300, 05004], lr: 0.010000, loss: 3.7420, tea_CELoss: 1.7023 stu_CELoss: 1.7759 DMLLoss: 0.2639 
2022-03-14 15:07:13 - train: epoch 0043, iter [01400, 05004], lr: 0.010000, loss: 3.2301, tea_CELoss: 1.4136 stu_CELoss: 1.5586 DMLLoss: 0.2579 
2022-03-14 15:07:46 - train: epoch 0043, iter [01500, 05004], lr: 0.010000, loss: 2.9940, tea_CELoss: 1.2759 stu_CELoss: 1.4474 DMLLoss: 0.2706 
2022-03-14 15:08:20 - train: epoch 0043, iter [01600, 05004], lr: 0.010000, loss: 3.1904, tea_CELoss: 1.4002 stu_CELoss: 1.5234 DMLLoss: 0.2669 
2022-03-14 15:08:52 - train: epoch 0043, iter [01700, 05004], lr: 0.010000, loss: 3.4703, tea_CELoss: 1.5023 stu_CELoss: 1.7050 DMLLoss: 0.2630 
2022-03-14 15:09:25 - train: epoch 0043, iter [01800, 05004], lr: 0.010000, loss: 3.8509, tea_CELoss: 1.7510 stu_CELoss: 1.8328 DMLLoss: 0.2671 
2022-03-14 15:09:59 - train: epoch 0043, iter [01900, 05004], lr: 0.010000, loss: 3.6286, tea_CELoss: 1.6194 stu_CELoss: 1.7450 DMLLoss: 0.2642 
2022-03-14 15:10:32 - train: epoch 0043, iter [02000, 05004], lr: 0.010000, loss: 2.9391, tea_CELoss: 1.3203 stu_CELoss: 1.3781 DMLLoss: 0.2408 
2022-03-14 15:11:05 - train: epoch 0043, iter [02100, 05004], lr: 0.010000, loss: 3.3160, tea_CELoss: 1.4834 stu_CELoss: 1.5787 DMLLoss: 0.2539 
2022-03-14 15:11:38 - train: epoch 0043, iter [02200, 05004], lr: 0.010000, loss: 3.8494, tea_CELoss: 1.7076 stu_CELoss: 1.8777 DMLLoss: 0.2640 
2022-03-14 15:12:11 - train: epoch 0043, iter [02300, 05004], lr: 0.010000, loss: 3.9110, tea_CELoss: 1.7314 stu_CELoss: 1.8734 DMLLoss: 0.3062 
2022-03-14 15:12:44 - train: epoch 0043, iter [02400, 05004], lr: 0.010000, loss: 3.0272, tea_CELoss: 1.3081 stu_CELoss: 1.4559 DMLLoss: 0.2631 
2022-03-14 15:13:17 - train: epoch 0043, iter [02500, 05004], lr: 0.010000, loss: 3.5216, tea_CELoss: 1.5731 stu_CELoss: 1.6391 DMLLoss: 0.3095 
2022-03-14 15:13:51 - train: epoch 0043, iter [02600, 05004], lr: 0.010000, loss: 3.1788, tea_CELoss: 1.4038 stu_CELoss: 1.4979 DMLLoss: 0.2771 
2022-03-14 15:14:23 - train: epoch 0043, iter [02700, 05004], lr: 0.010000, loss: 3.5888, tea_CELoss: 1.5771 stu_CELoss: 1.7534 DMLLoss: 0.2582 
2022-03-14 15:14:57 - train: epoch 0043, iter [02800, 05004], lr: 0.010000, loss: 3.2874, tea_CELoss: 1.4561 stu_CELoss: 1.5725 DMLLoss: 0.2588 
2022-03-14 15:15:30 - train: epoch 0043, iter [02900, 05004], lr: 0.010000, loss: 3.2189, tea_CELoss: 1.4232 stu_CELoss: 1.5539 DMLLoss: 0.2418 
2022-03-14 15:16:03 - train: epoch 0043, iter [03000, 05004], lr: 0.010000, loss: 3.6496, tea_CELoss: 1.6582 stu_CELoss: 1.7433 DMLLoss: 0.2480 
2022-03-14 15:16:36 - train: epoch 0043, iter [03100, 05004], lr: 0.010000, loss: 3.7879, tea_CELoss: 1.6582 stu_CELoss: 1.8442 DMLLoss: 0.2856 
2022-03-14 15:17:09 - train: epoch 0043, iter [03200, 05004], lr: 0.010000, loss: 3.3986, tea_CELoss: 1.4414 stu_CELoss: 1.6712 DMLLoss: 0.2860 
2022-03-14 15:17:42 - train: epoch 0043, iter [03300, 05004], lr: 0.010000, loss: 3.6947, tea_CELoss: 1.6545 stu_CELoss: 1.7848 DMLLoss: 0.2554 
2022-03-14 15:18:15 - train: epoch 0043, iter [03400, 05004], lr: 0.010000, loss: 3.2168, tea_CELoss: 1.3808 stu_CELoss: 1.5598 DMLLoss: 0.2762 
2022-03-14 15:18:48 - train: epoch 0043, iter [03500, 05004], lr: 0.010000, loss: 3.1676, tea_CELoss: 1.3808 stu_CELoss: 1.5294 DMLLoss: 0.2574 
2022-03-14 15:19:21 - train: epoch 0043, iter [03600, 05004], lr: 0.010000, loss: 3.5791, tea_CELoss: 1.5640 stu_CELoss: 1.7391 DMLLoss: 0.2761 
2022-03-14 15:19:54 - train: epoch 0043, iter [03700, 05004], lr: 0.010000, loss: 3.2031, tea_CELoss: 1.4321 stu_CELoss: 1.5322 DMLLoss: 0.2388 
2022-03-14 15:20:27 - train: epoch 0043, iter [03800, 05004], lr: 0.010000, loss: 3.8741, tea_CELoss: 1.7146 stu_CELoss: 1.9002 DMLLoss: 0.2593 
2022-03-14 15:21:00 - train: epoch 0043, iter [03900, 05004], lr: 0.010000, loss: 3.2741, tea_CELoss: 1.4102 stu_CELoss: 1.5985 DMLLoss: 0.2654 
2022-03-14 15:21:34 - train: epoch 0043, iter [04000, 05004], lr: 0.010000, loss: 3.5682, tea_CELoss: 1.5579 stu_CELoss: 1.7168 DMLLoss: 0.2936 
2022-03-14 15:22:07 - train: epoch 0043, iter [04100, 05004], lr: 0.010000, loss: 3.4299, tea_CELoss: 1.4993 stu_CELoss: 1.6491 DMLLoss: 0.2815 
2022-03-14 15:22:40 - train: epoch 0043, iter [04200, 05004], lr: 0.010000, loss: 3.5811, tea_CELoss: 1.5416 stu_CELoss: 1.7681 DMLLoss: 0.2714 
2022-03-14 15:23:14 - train: epoch 0043, iter [04300, 05004], lr: 0.010000, loss: 3.5220, tea_CELoss: 1.6050 stu_CELoss: 1.6688 DMLLoss: 0.2481 
2022-03-14 15:23:46 - train: epoch 0043, iter [04400, 05004], lr: 0.010000, loss: 3.6545, tea_CELoss: 1.5951 stu_CELoss: 1.7870 DMLLoss: 0.2725 
2022-03-14 15:24:18 - train: epoch 0043, iter [04500, 05004], lr: 0.010000, loss: 3.3039, tea_CELoss: 1.4831 stu_CELoss: 1.5664 DMLLoss: 0.2545 
2022-03-14 15:24:52 - train: epoch 0043, iter [04600, 05004], lr: 0.010000, loss: 3.4014, tea_CELoss: 1.4917 stu_CELoss: 1.6491 DMLLoss: 0.2605 
2022-03-14 15:25:25 - train: epoch 0043, iter [04700, 05004], lr: 0.010000, loss: 3.2980, tea_CELoss: 1.4052 stu_CELoss: 1.5951 DMLLoss: 0.2977 
2022-03-14 15:25:58 - train: epoch 0043, iter [04800, 05004], lr: 0.010000, loss: 3.4148, tea_CELoss: 1.4794 stu_CELoss: 1.6638 DMLLoss: 0.2715 
2022-03-14 15:26:31 - train: epoch 0043, iter [04900, 05004], lr: 0.010000, loss: 3.1827, tea_CELoss: 1.4450 stu_CELoss: 1.5071 DMLLoss: 0.2305 
2022-03-14 15:27:03 - train: epoch 0043, iter [05000, 05004], lr: 0.010000, loss: 3.4107, tea_CELoss: 1.4897 stu_CELoss: 1.6434 DMLLoss: 0.2776 
2022-03-14 15:27:04 - train: epoch 043, train_loss: 3.3977
2022-03-14 15:29:33 - eval: epoch: 043, tea_acc1: 68.156%, tea_acc5: 88.632%, tea_test_loss: 1.2750, stu_acc1: 66.120%, stu_acc5: 87.102%, stu_test_loss: 1.3909
2022-03-14 15:29:34 - until epoch: 043, tea_best_acc1: 68.864%, stu_best_acc1: 66.210%
2022-03-14 15:29:34 - epoch 044 lr: 0.010000000000000002
2022-03-14 15:30:12 - train: epoch 0044, iter [00100, 05004], lr: 0.010000, loss: 3.3895, tea_CELoss: 1.4779 stu_CELoss: 1.6418 DMLLoss: 0.2698 
2022-03-14 15:30:45 - train: epoch 0044, iter [00200, 05004], lr: 0.010000, loss: 3.6288, tea_CELoss: 1.5893 stu_CELoss: 1.7504 DMLLoss: 0.2891 
2022-03-14 15:31:18 - train: epoch 0044, iter [00300, 05004], lr: 0.010000, loss: 3.4365, tea_CELoss: 1.4504 stu_CELoss: 1.7235 DMLLoss: 0.2626 
2022-03-14 15:31:51 - train: epoch 0044, iter [00400, 05004], lr: 0.010000, loss: 2.7999, tea_CELoss: 1.2310 stu_CELoss: 1.3338 DMLLoss: 0.2351 
2022-03-14 15:32:24 - train: epoch 0044, iter [00500, 05004], lr: 0.010000, loss: 3.7496, tea_CELoss: 1.6181 stu_CELoss: 1.8428 DMLLoss: 0.2887 
2022-03-14 15:32:58 - train: epoch 0044, iter [00600, 05004], lr: 0.010000, loss: 2.8627, tea_CELoss: 1.2314 stu_CELoss: 1.3883 DMLLoss: 0.2429 
2022-03-14 15:33:30 - train: epoch 0044, iter [00700, 05004], lr: 0.010000, loss: 3.1417, tea_CELoss: 1.3648 stu_CELoss: 1.4826 DMLLoss: 0.2943 
2022-03-14 15:34:04 - train: epoch 0044, iter [00800, 05004], lr: 0.010000, loss: 3.4359, tea_CELoss: 1.5320 stu_CELoss: 1.6343 DMLLoss: 0.2696 
2022-03-14 15:34:36 - train: epoch 0044, iter [00900, 05004], lr: 0.010000, loss: 3.3813, tea_CELoss: 1.4823 stu_CELoss: 1.6182 DMLLoss: 0.2808 
2022-03-14 15:35:09 - train: epoch 0044, iter [01000, 05004], lr: 0.010000, loss: 3.4318, tea_CELoss: 1.5179 stu_CELoss: 1.6591 DMLLoss: 0.2548 
2022-03-14 15:35:43 - train: epoch 0044, iter [01100, 05004], lr: 0.010000, loss: 2.9399, tea_CELoss: 1.2799 stu_CELoss: 1.3948 DMLLoss: 0.2651 
2022-03-14 15:36:16 - train: epoch 0044, iter [01200, 05004], lr: 0.010000, loss: 3.3352, tea_CELoss: 1.5026 stu_CELoss: 1.5983 DMLLoss: 0.2343 
2022-03-14 15:36:50 - train: epoch 0044, iter [01300, 05004], lr: 0.010000, loss: 3.3266, tea_CELoss: 1.4800 stu_CELoss: 1.6219 DMLLoss: 0.2248 
2022-03-14 15:37:23 - train: epoch 0044, iter [01400, 05004], lr: 0.010000, loss: 3.2419, tea_CELoss: 1.4083 stu_CELoss: 1.5562 DMLLoss: 0.2774 
2022-03-14 15:37:55 - train: epoch 0044, iter [01500, 05004], lr: 0.010000, loss: 3.4952, tea_CELoss: 1.5167 stu_CELoss: 1.6937 DMLLoss: 0.2847 
2022-03-14 15:38:29 - train: epoch 0044, iter [01600, 05004], lr: 0.010000, loss: 3.0005, tea_CELoss: 1.3140 stu_CELoss: 1.4473 DMLLoss: 0.2391 
2022-03-14 15:39:03 - train: epoch 0044, iter [01700, 05004], lr: 0.010000, loss: 3.2500, tea_CELoss: 1.4113 stu_CELoss: 1.5551 DMLLoss: 0.2837 
2022-03-14 15:39:36 - train: epoch 0044, iter [01800, 05004], lr: 0.010000, loss: 3.3885, tea_CELoss: 1.4505 stu_CELoss: 1.6715 DMLLoss: 0.2666 
2022-03-14 15:40:09 - train: epoch 0044, iter [01900, 05004], lr: 0.010000, loss: 3.6902, tea_CELoss: 1.6277 stu_CELoss: 1.7996 DMLLoss: 0.2629 
2022-03-14 15:40:42 - train: epoch 0044, iter [02000, 05004], lr: 0.010000, loss: 2.8394, tea_CELoss: 1.2202 stu_CELoss: 1.3716 DMLLoss: 0.2476 
2022-03-14 15:41:16 - train: epoch 0044, iter [02100, 05004], lr: 0.010000, loss: 3.3009, tea_CELoss: 1.4696 stu_CELoss: 1.5816 DMLLoss: 0.2496 
2022-03-14 15:41:49 - train: epoch 0044, iter [02200, 05004], lr: 0.010000, loss: 3.7159, tea_CELoss: 1.6284 stu_CELoss: 1.7849 DMLLoss: 0.3026 
2022-03-14 15:42:22 - train: epoch 0044, iter [02300, 05004], lr: 0.010000, loss: 3.8232, tea_CELoss: 1.6903 stu_CELoss: 1.8467 DMLLoss: 0.2861 
2022-03-14 15:42:55 - train: epoch 0044, iter [02400, 05004], lr: 0.010000, loss: 3.3980, tea_CELoss: 1.4557 stu_CELoss: 1.6690 DMLLoss: 0.2733 
2022-03-14 15:43:29 - train: epoch 0044, iter [02500, 05004], lr: 0.010000, loss: 3.5736, tea_CELoss: 1.6005 stu_CELoss: 1.7125 DMLLoss: 0.2606 
2022-03-14 15:44:02 - train: epoch 0044, iter [02600, 05004], lr: 0.010000, loss: 3.5895, tea_CELoss: 1.5858 stu_CELoss: 1.7303 DMLLoss: 0.2733 
2022-03-14 15:44:35 - train: epoch 0044, iter [02700, 05004], lr: 0.010000, loss: 3.5594, tea_CELoss: 1.5659 stu_CELoss: 1.7145 DMLLoss: 0.2790 
2022-03-14 15:45:09 - train: epoch 0044, iter [02800, 05004], lr: 0.010000, loss: 2.9975, tea_CELoss: 1.2977 stu_CELoss: 1.4319 DMLLoss: 0.2679 
2022-03-14 15:45:42 - train: epoch 0044, iter [02900, 05004], lr: 0.010000, loss: 2.9294, tea_CELoss: 1.3188 stu_CELoss: 1.3579 DMLLoss: 0.2528 
2022-03-14 15:46:15 - train: epoch 0044, iter [03000, 05004], lr: 0.010000, loss: 2.9891, tea_CELoss: 1.2686 stu_CELoss: 1.4641 DMLLoss: 0.2564 
2022-03-14 15:46:48 - train: epoch 0044, iter [03100, 05004], lr: 0.010000, loss: 3.1386, tea_CELoss: 1.3337 stu_CELoss: 1.5496 DMLLoss: 0.2553 
2022-03-14 15:47:21 - train: epoch 0044, iter [03200, 05004], lr: 0.010000, loss: 3.0699, tea_CELoss: 1.3840 stu_CELoss: 1.4375 DMLLoss: 0.2484 
2022-03-14 15:47:54 - train: epoch 0044, iter [03300, 05004], lr: 0.010000, loss: 3.2828, tea_CELoss: 1.4696 stu_CELoss: 1.5572 DMLLoss: 0.2560 
2022-03-14 15:48:27 - train: epoch 0044, iter [03400, 05004], lr: 0.010000, loss: 3.5255, tea_CELoss: 1.5645 stu_CELoss: 1.7027 DMLLoss: 0.2583 
2022-03-14 15:49:00 - train: epoch 0044, iter [03500, 05004], lr: 0.010000, loss: 3.3585, tea_CELoss: 1.4953 stu_CELoss: 1.5853 DMLLoss: 0.2779 
2022-03-14 15:49:34 - train: epoch 0044, iter [03600, 05004], lr: 0.010000, loss: 3.6166, tea_CELoss: 1.5474 stu_CELoss: 1.7672 DMLLoss: 0.3020 
2022-03-14 15:50:07 - train: epoch 0044, iter [03700, 05004], lr: 0.010000, loss: 3.2826, tea_CELoss: 1.4111 stu_CELoss: 1.6068 DMLLoss: 0.2647 
2022-03-14 15:50:40 - train: epoch 0044, iter [03800, 05004], lr: 0.010000, loss: 3.0510, tea_CELoss: 1.3892 stu_CELoss: 1.4375 DMLLoss: 0.2242 
2022-03-14 15:51:13 - train: epoch 0044, iter [03900, 05004], lr: 0.010000, loss: 3.2791, tea_CELoss: 1.4645 stu_CELoss: 1.5412 DMLLoss: 0.2734 
2022-03-14 15:51:47 - train: epoch 0044, iter [04000, 05004], lr: 0.010000, loss: 3.4999, tea_CELoss: 1.5424 stu_CELoss: 1.6937 DMLLoss: 0.2638 
2022-03-14 15:52:20 - train: epoch 0044, iter [04100, 05004], lr: 0.010000, loss: 3.4027, tea_CELoss: 1.5561 stu_CELoss: 1.5799 DMLLoss: 0.2668 
2022-03-14 15:52:53 - train: epoch 0044, iter [04200, 05004], lr: 0.010000, loss: 3.5969, tea_CELoss: 1.5948 stu_CELoss: 1.7279 DMLLoss: 0.2742 
2022-03-14 15:53:26 - train: epoch 0044, iter [04300, 05004], lr: 0.010000, loss: 3.3041, tea_CELoss: 1.4662 stu_CELoss: 1.5656 DMLLoss: 0.2723 
2022-03-14 15:54:00 - train: epoch 0044, iter [04400, 05004], lr: 0.010000, loss: 3.4705, tea_CELoss: 1.5183 stu_CELoss: 1.6860 DMLLoss: 0.2661 
2022-03-14 15:54:33 - train: epoch 0044, iter [04500, 05004], lr: 0.010000, loss: 3.6407, tea_CELoss: 1.6235 stu_CELoss: 1.7462 DMLLoss: 0.2710 
2022-03-14 15:55:07 - train: epoch 0044, iter [04600, 05004], lr: 0.010000, loss: 3.3652, tea_CELoss: 1.4712 stu_CELoss: 1.6049 DMLLoss: 0.2892 
2022-03-14 15:55:40 - train: epoch 0044, iter [04700, 05004], lr: 0.010000, loss: 3.5557, tea_CELoss: 1.5927 stu_CELoss: 1.6755 DMLLoss: 0.2876 
2022-03-14 15:56:12 - train: epoch 0044, iter [04800, 05004], lr: 0.010000, loss: 3.3501, tea_CELoss: 1.4152 stu_CELoss: 1.6322 DMLLoss: 0.3026 
2022-03-14 15:56:46 - train: epoch 0044, iter [04900, 05004], lr: 0.010000, loss: 3.2878, tea_CELoss: 1.4208 stu_CELoss: 1.5695 DMLLoss: 0.2974 
2022-03-14 15:57:17 - train: epoch 0044, iter [05000, 05004], lr: 0.010000, loss: 3.5601, tea_CELoss: 1.5569 stu_CELoss: 1.7323 DMLLoss: 0.2708 
2022-03-14 15:57:18 - train: epoch 044, train_loss: 3.4004
2022-03-14 15:59:46 - eval: epoch: 044, tea_acc1: 68.426%, tea_acc5: 88.766%, tea_test_loss: 1.2710, stu_acc1: 65.654%, stu_acc5: 87.016%, stu_test_loss: 1.4056
2022-03-14 15:59:46 - until epoch: 044, tea_best_acc1: 68.864%, stu_best_acc1: 66.210%
2022-03-14 15:59:46 - epoch 045 lr: 0.010000000000000002
2022-03-14 16:00:25 - train: epoch 0045, iter [00100, 05004], lr: 0.010000, loss: 2.9848, tea_CELoss: 1.3051 stu_CELoss: 1.4408 DMLLoss: 0.2389 
2022-03-14 16:00:58 - train: epoch 0045, iter [00200, 05004], lr: 0.010000, loss: 3.0789, tea_CELoss: 1.3343 stu_CELoss: 1.5005 DMLLoss: 0.2441 
2022-03-14 16:01:31 - train: epoch 0045, iter [00300, 05004], lr: 0.010000, loss: 3.2794, tea_CELoss: 1.4558 stu_CELoss: 1.5562 DMLLoss: 0.2674 
2022-03-14 16:02:04 - train: epoch 0045, iter [00400, 05004], lr: 0.010000, loss: 3.1839, tea_CELoss: 1.4126 stu_CELoss: 1.5213 DMLLoss: 0.2500 
2022-03-14 16:02:37 - train: epoch 0045, iter [00500, 05004], lr: 0.010000, loss: 3.8070, tea_CELoss: 1.6765 stu_CELoss: 1.8509 DMLLoss: 0.2796 
2022-03-14 16:03:10 - train: epoch 0045, iter [00600, 05004], lr: 0.010000, loss: 3.8313, tea_CELoss: 1.7040 stu_CELoss: 1.8342 DMLLoss: 0.2931 
2022-03-14 16:03:43 - train: epoch 0045, iter [00700, 05004], lr: 0.010000, loss: 3.1867, tea_CELoss: 1.4226 stu_CELoss: 1.4959 DMLLoss: 0.2682 
2022-03-14 16:04:17 - train: epoch 0045, iter [00800, 05004], lr: 0.010000, loss: 3.3046, tea_CELoss: 1.4678 stu_CELoss: 1.5798 DMLLoss: 0.2570 
2022-03-14 16:04:49 - train: epoch 0045, iter [00900, 05004], lr: 0.010000, loss: 3.1067, tea_CELoss: 1.3718 stu_CELoss: 1.4912 DMLLoss: 0.2437 
2022-03-14 16:05:23 - train: epoch 0045, iter [01000, 05004], lr: 0.010000, loss: 3.2098, tea_CELoss: 1.4027 stu_CELoss: 1.5514 DMLLoss: 0.2557 
2022-03-14 16:05:56 - train: epoch 0045, iter [01100, 05004], lr: 0.010000, loss: 3.4089, tea_CELoss: 1.5054 stu_CELoss: 1.6520 DMLLoss: 0.2514 
2022-03-14 16:06:28 - train: epoch 0045, iter [01200, 05004], lr: 0.010000, loss: 3.4416, tea_CELoss: 1.5005 stu_CELoss: 1.6889 DMLLoss: 0.2523 
2022-03-14 16:07:01 - train: epoch 0045, iter [01300, 05004], lr: 0.010000, loss: 3.5396, tea_CELoss: 1.5809 stu_CELoss: 1.6852 DMLLoss: 0.2735 
2022-03-14 16:07:35 - train: epoch 0045, iter [01400, 05004], lr: 0.010000, loss: 3.8761, tea_CELoss: 1.7374 stu_CELoss: 1.8338 DMLLoss: 0.3049 
2022-03-14 16:08:08 - train: epoch 0045, iter [01500, 05004], lr: 0.010000, loss: 3.4157, tea_CELoss: 1.4854 stu_CELoss: 1.6557 DMLLoss: 0.2745 
2022-03-14 16:08:41 - train: epoch 0045, iter [01600, 05004], lr: 0.010000, loss: 2.7889, tea_CELoss: 1.2131 stu_CELoss: 1.3412 DMLLoss: 0.2346 
2022-03-14 16:09:15 - train: epoch 0045, iter [01700, 05004], lr: 0.010000, loss: 3.0549, tea_CELoss: 1.3140 stu_CELoss: 1.4917 DMLLoss: 0.2492 
2022-03-14 16:09:47 - train: epoch 0045, iter [01800, 05004], lr: 0.010000, loss: 3.4584, tea_CELoss: 1.5163 stu_CELoss: 1.6533 DMLLoss: 0.2888 
2022-03-14 16:10:20 - train: epoch 0045, iter [01900, 05004], lr: 0.010000, loss: 3.4801, tea_CELoss: 1.5032 stu_CELoss: 1.7028 DMLLoss: 0.2742 
2022-03-14 16:10:53 - train: epoch 0045, iter [02000, 05004], lr: 0.010000, loss: 3.5040, tea_CELoss: 1.5503 stu_CELoss: 1.6994 DMLLoss: 0.2543 
2022-03-14 16:11:26 - train: epoch 0045, iter [02100, 05004], lr: 0.010000, loss: 3.3341, tea_CELoss: 1.4460 stu_CELoss: 1.5950 DMLLoss: 0.2931 
2022-03-14 16:12:00 - train: epoch 0045, iter [02200, 05004], lr: 0.010000, loss: 3.3449, tea_CELoss: 1.4665 stu_CELoss: 1.5781 DMLLoss: 0.3004 
2022-03-14 16:12:33 - train: epoch 0045, iter [02300, 05004], lr: 0.010000, loss: 3.0043, tea_CELoss: 1.3142 stu_CELoss: 1.4274 DMLLoss: 0.2627 
2022-03-14 16:13:07 - train: epoch 0045, iter [02400, 05004], lr: 0.010000, loss: 3.0261, tea_CELoss: 1.3094 stu_CELoss: 1.4384 DMLLoss: 0.2782 
2022-03-14 16:13:39 - train: epoch 0045, iter [02500, 05004], lr: 0.010000, loss: 3.4278, tea_CELoss: 1.5478 stu_CELoss: 1.6286 DMLLoss: 0.2513 
2022-03-14 16:14:12 - train: epoch 0045, iter [02600, 05004], lr: 0.010000, loss: 3.4741, tea_CELoss: 1.5845 stu_CELoss: 1.6423 DMLLoss: 0.2474 
2022-03-14 16:14:45 - train: epoch 0045, iter [02700, 05004], lr: 0.010000, loss: 3.0378, tea_CELoss: 1.3402 stu_CELoss: 1.4529 DMLLoss: 0.2447 
2022-03-14 16:15:18 - train: epoch 0045, iter [02800, 05004], lr: 0.010000, loss: 3.3598, tea_CELoss: 1.4931 stu_CELoss: 1.5960 DMLLoss: 0.2707 
2022-03-14 16:15:51 - train: epoch 0045, iter [02900, 05004], lr: 0.010000, loss: 3.7574, tea_CELoss: 1.6555 stu_CELoss: 1.8192 DMLLoss: 0.2827 
2022-03-14 16:16:24 - train: epoch 0045, iter [03000, 05004], lr: 0.010000, loss: 3.6228, tea_CELoss: 1.5535 stu_CELoss: 1.7590 DMLLoss: 0.3103 
2022-03-14 16:16:58 - train: epoch 0045, iter [03100, 05004], lr: 0.010000, loss: 3.2339, tea_CELoss: 1.4261 stu_CELoss: 1.5726 DMLLoss: 0.2352 
2022-03-14 16:17:31 - train: epoch 0045, iter [03200, 05004], lr: 0.010000, loss: 3.4840, tea_CELoss: 1.4964 stu_CELoss: 1.7178 DMLLoss: 0.2698 
2022-03-14 16:18:04 - train: epoch 0045, iter [03300, 05004], lr: 0.010000, loss: 3.5839, tea_CELoss: 1.5592 stu_CELoss: 1.7289 DMLLoss: 0.2957 
2022-03-14 16:18:37 - train: epoch 0045, iter [03400, 05004], lr: 0.010000, loss: 3.3350, tea_CELoss: 1.4253 stu_CELoss: 1.6389 DMLLoss: 0.2708 
2022-03-14 16:19:10 - train: epoch 0045, iter [03500, 05004], lr: 0.010000, loss: 3.4776, tea_CELoss: 1.4997 stu_CELoss: 1.7029 DMLLoss: 0.2750 
2022-03-14 16:19:43 - train: epoch 0045, iter [03600, 05004], lr: 0.010000, loss: 3.5117, tea_CELoss: 1.5261 stu_CELoss: 1.7322 DMLLoss: 0.2534 
2022-03-14 16:20:16 - train: epoch 0045, iter [03700, 05004], lr: 0.010000, loss: 3.1380, tea_CELoss: 1.3251 stu_CELoss: 1.5441 DMLLoss: 0.2689 
2022-03-14 16:20:49 - train: epoch 0045, iter [03800, 05004], lr: 0.010000, loss: 3.1769, tea_CELoss: 1.4018 stu_CELoss: 1.5077 DMLLoss: 0.2674 
2022-03-14 16:21:22 - train: epoch 0045, iter [03900, 05004], lr: 0.010000, loss: 3.4503, tea_CELoss: 1.5410 stu_CELoss: 1.6159 DMLLoss: 0.2933 
2022-03-14 16:21:54 - train: epoch 0045, iter [04000, 05004], lr: 0.010000, loss: 3.4176, tea_CELoss: 1.4849 stu_CELoss: 1.6518 DMLLoss: 0.2810 
2022-03-14 16:22:28 - train: epoch 0045, iter [04100, 05004], lr: 0.010000, loss: 3.2833, tea_CELoss: 1.4435 stu_CELoss: 1.5856 DMLLoss: 0.2542 
2022-03-14 16:23:01 - train: epoch 0045, iter [04200, 05004], lr: 0.010000, loss: 3.8694, tea_CELoss: 1.6950 stu_CELoss: 1.8655 DMLLoss: 0.3090 
2022-03-14 16:23:34 - train: epoch 0045, iter [04300, 05004], lr: 0.010000, loss: 3.5098, tea_CELoss: 1.5367 stu_CELoss: 1.6790 DMLLoss: 0.2941 
2022-03-14 16:24:07 - train: epoch 0045, iter [04400, 05004], lr: 0.010000, loss: 3.5988, tea_CELoss: 1.5975 stu_CELoss: 1.7032 DMLLoss: 0.2980 
2022-03-14 16:24:39 - train: epoch 0045, iter [04500, 05004], lr: 0.010000, loss: 3.3886, tea_CELoss: 1.4892 stu_CELoss: 1.6349 DMLLoss: 0.2646 
2022-03-14 16:25:13 - train: epoch 0045, iter [04600, 05004], lr: 0.010000, loss: 3.7602, tea_CELoss: 1.6729 stu_CELoss: 1.8007 DMLLoss: 0.2865 
2022-03-14 16:25:45 - train: epoch 0045, iter [04700, 05004], lr: 0.010000, loss: 3.3330, tea_CELoss: 1.4676 stu_CELoss: 1.5912 DMLLoss: 0.2742 
2022-03-14 16:26:19 - train: epoch 0045, iter [04800, 05004], lr: 0.010000, loss: 3.0329, tea_CELoss: 1.2965 stu_CELoss: 1.4727 DMLLoss: 0.2637 
2022-03-14 16:26:52 - train: epoch 0045, iter [04900, 05004], lr: 0.010000, loss: 3.7613, tea_CELoss: 1.6249 stu_CELoss: 1.8552 DMLLoss: 0.2812 
2022-03-14 16:27:23 - train: epoch 0045, iter [05000, 05004], lr: 0.010000, loss: 3.2976, tea_CELoss: 1.4486 stu_CELoss: 1.5730 DMLLoss: 0.2761 
2022-03-14 16:27:24 - train: epoch 045, train_loss: 3.4008
2022-03-14 16:29:54 - eval: epoch: 045, tea_acc1: 68.000%, tea_acc5: 88.602%, tea_test_loss: 1.2939, stu_acc1: 65.760%, stu_acc5: 87.134%, stu_test_loss: 1.3937
2022-03-14 16:29:54 - until epoch: 045, tea_best_acc1: 68.864%, stu_best_acc1: 66.210%
2022-03-14 16:29:54 - epoch 046 lr: 0.010000000000000002
2022-03-14 16:30:32 - train: epoch 0046, iter [00100, 05004], lr: 0.010000, loss: 2.9002, tea_CELoss: 1.2103 stu_CELoss: 1.4113 DMLLoss: 0.2786 
2022-03-14 16:31:05 - train: epoch 0046, iter [00200, 05004], lr: 0.010000, loss: 3.0989, tea_CELoss: 1.3721 stu_CELoss: 1.4687 DMLLoss: 0.2581 
2022-03-14 16:31:38 - train: epoch 0046, iter [00300, 05004], lr: 0.010000, loss: 3.5207, tea_CELoss: 1.5523 stu_CELoss: 1.6846 DMLLoss: 0.2839 
2022-03-14 16:32:12 - train: epoch 0046, iter [00400, 05004], lr: 0.010000, loss: 2.9397, tea_CELoss: 1.3001 stu_CELoss: 1.3735 DMLLoss: 0.2661 
2022-03-14 16:32:45 - train: epoch 0046, iter [00500, 05004], lr: 0.010000, loss: 3.3212, tea_CELoss: 1.4538 stu_CELoss: 1.5921 DMLLoss: 0.2753 
2022-03-14 16:33:19 - train: epoch 0046, iter [00600, 05004], lr: 0.010000, loss: 3.2398, tea_CELoss: 1.4062 stu_CELoss: 1.5855 DMLLoss: 0.2482 
2022-03-14 16:33:52 - train: epoch 0046, iter [00700, 05004], lr: 0.010000, loss: 3.0473, tea_CELoss: 1.3493 stu_CELoss: 1.4693 DMLLoss: 0.2287 
2022-03-14 16:34:25 - train: epoch 0046, iter [00800, 05004], lr: 0.010000, loss: 3.7946, tea_CELoss: 1.6354 stu_CELoss: 1.8640 DMLLoss: 0.2952 
2022-03-14 16:34:59 - train: epoch 0046, iter [00900, 05004], lr: 0.010000, loss: 3.2900, tea_CELoss: 1.4290 stu_CELoss: 1.5972 DMLLoss: 0.2638 
2022-03-14 16:35:32 - train: epoch 0046, iter [01000, 05004], lr: 0.010000, loss: 2.8797, tea_CELoss: 1.2548 stu_CELoss: 1.3728 DMLLoss: 0.2520 
2022-03-14 16:36:05 - train: epoch 0046, iter [01100, 05004], lr: 0.010000, loss: 3.1360, tea_CELoss: 1.3599 stu_CELoss: 1.4986 DMLLoss: 0.2776 
2022-03-14 16:36:39 - train: epoch 0046, iter [01200, 05004], lr: 0.010000, loss: 3.2922, tea_CELoss: 1.4214 stu_CELoss: 1.5979 DMLLoss: 0.2728 
2022-03-14 16:37:13 - train: epoch 0046, iter [01300, 05004], lr: 0.010000, loss: 3.7730, tea_CELoss: 1.6745 stu_CELoss: 1.8016 DMLLoss: 0.2968 
2022-03-14 16:37:47 - train: epoch 0046, iter [01400, 05004], lr: 0.010000, loss: 3.5881, tea_CELoss: 1.5586 stu_CELoss: 1.7351 DMLLoss: 0.2944 
2022-03-14 16:38:20 - train: epoch 0046, iter [01500, 05004], lr: 0.010000, loss: 3.0775, tea_CELoss: 1.3102 stu_CELoss: 1.4853 DMLLoss: 0.2820 
2022-03-14 16:38:54 - train: epoch 0046, iter [01600, 05004], lr: 0.010000, loss: 4.0597, tea_CELoss: 1.7870 stu_CELoss: 1.9856 DMLLoss: 0.2871 
2022-03-14 16:39:27 - train: epoch 0046, iter [01700, 05004], lr: 0.010000, loss: 3.3939, tea_CELoss: 1.4887 stu_CELoss: 1.6368 DMLLoss: 0.2685 
2022-03-14 16:40:01 - train: epoch 0046, iter [01800, 05004], lr: 0.010000, loss: 3.5354, tea_CELoss: 1.5792 stu_CELoss: 1.6735 DMLLoss: 0.2827 
2022-03-14 16:40:36 - train: epoch 0046, iter [01900, 05004], lr: 0.010000, loss: 3.2929, tea_CELoss: 1.4135 stu_CELoss: 1.6271 DMLLoss: 0.2523 
2022-03-14 16:41:09 - train: epoch 0046, iter [02000, 05004], lr: 0.010000, loss: 3.1820, tea_CELoss: 1.4069 stu_CELoss: 1.5209 DMLLoss: 0.2542 
2022-03-14 16:41:43 - train: epoch 0046, iter [02100, 05004], lr: 0.010000, loss: 4.1432, tea_CELoss: 1.8289 stu_CELoss: 1.9843 DMLLoss: 0.3300 
2022-03-14 16:42:17 - train: epoch 0046, iter [02200, 05004], lr: 0.010000, loss: 3.0554, tea_CELoss: 1.3523 stu_CELoss: 1.4548 DMLLoss: 0.2484 
2022-03-14 16:42:51 - train: epoch 0046, iter [02300, 05004], lr: 0.010000, loss: 3.9142, tea_CELoss: 1.7216 stu_CELoss: 1.8961 DMLLoss: 0.2966 
2022-03-14 16:43:24 - train: epoch 0046, iter [02400, 05004], lr: 0.010000, loss: 3.6981, tea_CELoss: 1.6210 stu_CELoss: 1.7939 DMLLoss: 0.2832 
2022-03-14 16:43:58 - train: epoch 0046, iter [02500, 05004], lr: 0.010000, loss: 3.3500, tea_CELoss: 1.4956 stu_CELoss: 1.5690 DMLLoss: 0.2854 
2022-03-14 16:44:32 - train: epoch 0046, iter [02600, 05004], lr: 0.010000, loss: 4.0678, tea_CELoss: 1.7695 stu_CELoss: 1.9495 DMLLoss: 0.3487 
2022-03-14 16:45:06 - train: epoch 0046, iter [02700, 05004], lr: 0.010000, loss: 3.1029, tea_CELoss: 1.3549 stu_CELoss: 1.5037 DMLLoss: 0.2443 
2022-03-14 16:45:39 - train: epoch 0046, iter [02800, 05004], lr: 0.010000, loss: 3.1303, tea_CELoss: 1.3684 stu_CELoss: 1.4838 DMLLoss: 0.2782 
2022-03-14 16:46:14 - train: epoch 0046, iter [02900, 05004], lr: 0.010000, loss: 3.7131, tea_CELoss: 1.6819 stu_CELoss: 1.7750 DMLLoss: 0.2561 
2022-03-14 16:46:48 - train: epoch 0046, iter [03000, 05004], lr: 0.010000, loss: 3.0947, tea_CELoss: 1.3973 stu_CELoss: 1.4564 DMLLoss: 0.2411 
2022-03-14 16:47:21 - train: epoch 0046, iter [03100, 05004], lr: 0.010000, loss: 3.0992, tea_CELoss: 1.3669 stu_CELoss: 1.4858 DMLLoss: 0.2465 
2022-03-14 16:47:56 - train: epoch 0046, iter [03200, 05004], lr: 0.010000, loss: 3.3306, tea_CELoss: 1.4350 stu_CELoss: 1.6032 DMLLoss: 0.2924 
2022-03-14 16:48:29 - train: epoch 0046, iter [03300, 05004], lr: 0.010000, loss: 3.6532, tea_CELoss: 1.6250 stu_CELoss: 1.7731 DMLLoss: 0.2551 
2022-03-14 16:49:03 - train: epoch 0046, iter [03400, 05004], lr: 0.010000, loss: 3.3118, tea_CELoss: 1.4085 stu_CELoss: 1.6151 DMLLoss: 0.2882 
2022-03-14 16:49:37 - train: epoch 0046, iter [03500, 05004], lr: 0.010000, loss: 3.7289, tea_CELoss: 1.6374 stu_CELoss: 1.8035 DMLLoss: 0.2881 
2022-03-14 16:50:11 - train: epoch 0046, iter [03600, 05004], lr: 0.010000, loss: 3.3453, tea_CELoss: 1.4938 stu_CELoss: 1.5890 DMLLoss: 0.2625 
2022-03-14 16:50:44 - train: epoch 0046, iter [03700, 05004], lr: 0.010000, loss: 3.0849, tea_CELoss: 1.3737 stu_CELoss: 1.4727 DMLLoss: 0.2384 
2022-03-14 16:51:18 - train: epoch 0046, iter [03800, 05004], lr: 0.010000, loss: 3.3805, tea_CELoss: 1.4539 stu_CELoss: 1.6519 DMLLoss: 0.2746 
2022-03-14 16:51:51 - train: epoch 0046, iter [03900, 05004], lr: 0.010000, loss: 3.2579, tea_CELoss: 1.4578 stu_CELoss: 1.5570 DMLLoss: 0.2431 
2022-03-14 16:52:25 - train: epoch 0046, iter [04000, 05004], lr: 0.010000, loss: 3.2034, tea_CELoss: 1.4442 stu_CELoss: 1.5031 DMLLoss: 0.2561 
2022-03-14 16:52:59 - train: epoch 0046, iter [04100, 05004], lr: 0.010000, loss: 3.8062, tea_CELoss: 1.6258 stu_CELoss: 1.8860 DMLLoss: 0.2944 
2022-03-14 16:53:34 - train: epoch 0046, iter [04200, 05004], lr: 0.010000, loss: 3.1203, tea_CELoss: 1.4179 stu_CELoss: 1.4523 DMLLoss: 0.2500 
2022-03-14 16:54:07 - train: epoch 0046, iter [04300, 05004], lr: 0.010000, loss: 3.6489, tea_CELoss: 1.5984 stu_CELoss: 1.7788 DMLLoss: 0.2717 
2022-03-14 16:54:41 - train: epoch 0046, iter [04400, 05004], lr: 0.010000, loss: 3.8711, tea_CELoss: 1.6906 stu_CELoss: 1.8904 DMLLoss: 0.2900 
2022-03-14 16:55:14 - train: epoch 0046, iter [04500, 05004], lr: 0.010000, loss: 3.4896, tea_CELoss: 1.5039 stu_CELoss: 1.6760 DMLLoss: 0.3097 
2022-03-14 16:55:48 - train: epoch 0046, iter [04600, 05004], lr: 0.010000, loss: 3.3563, tea_CELoss: 1.4751 stu_CELoss: 1.6034 DMLLoss: 0.2778 
2022-03-14 16:56:21 - train: epoch 0046, iter [04700, 05004], lr: 0.010000, loss: 3.3939, tea_CELoss: 1.4902 stu_CELoss: 1.6220 DMLLoss: 0.2817 
2022-03-14 16:56:56 - train: epoch 0046, iter [04800, 05004], lr: 0.010000, loss: 2.8262, tea_CELoss: 1.2421 stu_CELoss: 1.3727 DMLLoss: 0.2114 
2022-03-14 16:57:29 - train: epoch 0046, iter [04900, 05004], lr: 0.010000, loss: 3.5763, tea_CELoss: 1.6605 stu_CELoss: 1.6613 DMLLoss: 0.2545 
2022-03-14 16:58:00 - train: epoch 0046, iter [05000, 05004], lr: 0.010000, loss: 3.4605, tea_CELoss: 1.4913 stu_CELoss: 1.6814 DMLLoss: 0.2877 
2022-03-14 16:58:01 - train: epoch 046, train_loss: 3.4063
2022-03-14 17:00:30 - eval: epoch: 046, tea_acc1: 68.170%, tea_acc5: 88.812%, tea_test_loss: 1.2786, stu_acc1: 65.792%, stu_acc5: 87.012%, stu_test_loss: 1.3984
2022-03-14 17:00:31 - until epoch: 046, tea_best_acc1: 68.864%, stu_best_acc1: 66.210%
2022-03-14 17:00:31 - epoch 047 lr: 0.010000000000000002
2022-03-14 17:01:09 - train: epoch 0047, iter [00100, 05004], lr: 0.010000, loss: 3.8502, tea_CELoss: 1.6662 stu_CELoss: 1.8730 DMLLoss: 0.3110 
2022-03-14 17:01:42 - train: epoch 0047, iter [00200, 05004], lr: 0.010000, loss: 3.8472, tea_CELoss: 1.6527 stu_CELoss: 1.9076 DMLLoss: 0.2869 
2022-03-14 17:02:16 - train: epoch 0047, iter [00300, 05004], lr: 0.010000, loss: 2.9136, tea_CELoss: 1.2411 stu_CELoss: 1.4044 DMLLoss: 0.2682 
2022-03-14 17:02:49 - train: epoch 0047, iter [00400, 05004], lr: 0.010000, loss: 2.9635, tea_CELoss: 1.2863 stu_CELoss: 1.4334 DMLLoss: 0.2438 
2022-03-14 17:03:23 - train: epoch 0047, iter [00500, 05004], lr: 0.010000, loss: 3.0266, tea_CELoss: 1.3213 stu_CELoss: 1.4431 DMLLoss: 0.2622 
2022-03-14 17:03:57 - train: epoch 0047, iter [00600, 05004], lr: 0.010000, loss: 3.3645, tea_CELoss: 1.4220 stu_CELoss: 1.6220 DMLLoss: 0.3205 
2022-03-14 17:04:31 - train: epoch 0047, iter [00700, 05004], lr: 0.010000, loss: 3.4120, tea_CELoss: 1.4889 stu_CELoss: 1.6614 DMLLoss: 0.2617 
2022-03-14 17:05:04 - train: epoch 0047, iter [00800, 05004], lr: 0.010000, loss: 3.4535, tea_CELoss: 1.4914 stu_CELoss: 1.6669 DMLLoss: 0.2952 
2022-03-14 17:05:38 - train: epoch 0047, iter [00900, 05004], lr: 0.010000, loss: 3.6572, tea_CELoss: 1.6384 stu_CELoss: 1.7513 DMLLoss: 0.2676 
2022-03-14 17:06:12 - train: epoch 0047, iter [01000, 05004], lr: 0.010000, loss: 3.3873, tea_CELoss: 1.4878 stu_CELoss: 1.6345 DMLLoss: 0.2649 
2022-03-14 17:06:45 - train: epoch 0047, iter [01100, 05004], lr: 0.010000, loss: 3.8277, tea_CELoss: 1.7112 stu_CELoss: 1.8277 DMLLoss: 0.2887 
2022-03-14 17:07:19 - train: epoch 0047, iter [01200, 05004], lr: 0.010000, loss: 3.4360, tea_CELoss: 1.5035 stu_CELoss: 1.6271 DMLLoss: 0.3053 
2022-03-14 17:07:52 - train: epoch 0047, iter [01300, 05004], lr: 0.010000, loss: 3.2954, tea_CELoss: 1.4148 stu_CELoss: 1.5956 DMLLoss: 0.2849 
2022-03-14 17:08:27 - train: epoch 0047, iter [01400, 05004], lr: 0.010000, loss: 3.5379, tea_CELoss: 1.5638 stu_CELoss: 1.6987 DMLLoss: 0.2754 
2022-03-14 17:09:00 - train: epoch 0047, iter [01500, 05004], lr: 0.010000, loss: 3.4707, tea_CELoss: 1.5461 stu_CELoss: 1.6396 DMLLoss: 0.2849 
2022-03-14 17:09:33 - train: epoch 0047, iter [01600, 05004], lr: 0.010000, loss: 3.3007, tea_CELoss: 1.4694 stu_CELoss: 1.5791 DMLLoss: 0.2522 
2022-03-14 17:10:07 - train: epoch 0047, iter [01700, 05004], lr: 0.010000, loss: 3.0482, tea_CELoss: 1.3428 stu_CELoss: 1.4552 DMLLoss: 0.2502 
2022-03-14 17:10:41 - train: epoch 0047, iter [01800, 05004], lr: 0.010000, loss: 3.4935, tea_CELoss: 1.5153 stu_CELoss: 1.6901 DMLLoss: 0.2881 
2022-03-14 17:11:15 - train: epoch 0047, iter [01900, 05004], lr: 0.010000, loss: 3.1113, tea_CELoss: 1.3477 stu_CELoss: 1.5147 DMLLoss: 0.2488 
2022-03-14 17:11:49 - train: epoch 0047, iter [02000, 05004], lr: 0.010000, loss: 3.7714, tea_CELoss: 1.6611 stu_CELoss: 1.8103 DMLLoss: 0.3000 
2022-03-14 17:12:22 - train: epoch 0047, iter [02100, 05004], lr: 0.010000, loss: 3.4627, tea_CELoss: 1.5144 stu_CELoss: 1.6754 DMLLoss: 0.2729 
2022-03-14 17:12:56 - train: epoch 0047, iter [02200, 05004], lr: 0.010000, loss: 3.7701, tea_CELoss: 1.6459 stu_CELoss: 1.8311 DMLLoss: 0.2930 
2022-03-14 17:13:30 - train: epoch 0047, iter [02300, 05004], lr: 0.010000, loss: 3.4584, tea_CELoss: 1.5309 stu_CELoss: 1.6213 DMLLoss: 0.3062 
2022-03-14 17:14:03 - train: epoch 0047, iter [02400, 05004], lr: 0.010000, loss: 3.5662, tea_CELoss: 1.5892 stu_CELoss: 1.7083 DMLLoss: 0.2687 
2022-03-14 17:14:38 - train: epoch 0047, iter [02500, 05004], lr: 0.010000, loss: 3.3053, tea_CELoss: 1.4429 stu_CELoss: 1.5897 DMLLoss: 0.2727 
2022-03-14 17:15:11 - train: epoch 0047, iter [02600, 05004], lr: 0.010000, loss: 4.3405, tea_CELoss: 1.9129 stu_CELoss: 2.1101 DMLLoss: 0.3175 
2022-03-14 17:15:45 - train: epoch 0047, iter [02700, 05004], lr: 0.010000, loss: 2.9063, tea_CELoss: 1.2628 stu_CELoss: 1.3623 DMLLoss: 0.2813 
2022-03-14 17:16:18 - train: epoch 0047, iter [02800, 05004], lr: 0.010000, loss: 3.5804, tea_CELoss: 1.6039 stu_CELoss: 1.7128 DMLLoss: 0.2637 
2022-03-14 17:16:53 - train: epoch 0047, iter [02900, 05004], lr: 0.010000, loss: 3.3301, tea_CELoss: 1.4860 stu_CELoss: 1.5769 DMLLoss: 0.2671 
2022-03-14 17:17:26 - train: epoch 0047, iter [03000, 05004], lr: 0.010000, loss: 3.5284, tea_CELoss: 1.5823 stu_CELoss: 1.6676 DMLLoss: 0.2785 
2022-03-14 17:17:59 - train: epoch 0047, iter [03100, 05004], lr: 0.010000, loss: 3.1779, tea_CELoss: 1.3392 stu_CELoss: 1.5623 DMLLoss: 0.2764 
2022-03-14 17:18:34 - train: epoch 0047, iter [03200, 05004], lr: 0.010000, loss: 3.6182, tea_CELoss: 1.5728 stu_CELoss: 1.7675 DMLLoss: 0.2780 
2022-03-14 17:19:07 - train: epoch 0047, iter [03300, 05004], lr: 0.010000, loss: 3.5680, tea_CELoss: 1.5124 stu_CELoss: 1.7495 DMLLoss: 0.3062 
2022-03-14 17:19:41 - train: epoch 0047, iter [03400, 05004], lr: 0.010000, loss: 3.3134, tea_CELoss: 1.4314 stu_CELoss: 1.6072 DMLLoss: 0.2748 
2022-03-14 17:20:14 - train: epoch 0047, iter [03500, 05004], lr: 0.010000, loss: 3.6858, tea_CELoss: 1.5841 stu_CELoss: 1.8104 DMLLoss: 0.2914 
2022-03-14 17:20:48 - train: epoch 0047, iter [03600, 05004], lr: 0.010000, loss: 3.3982, tea_CELoss: 1.4998 stu_CELoss: 1.6468 DMLLoss: 0.2516 
2022-03-14 17:21:21 - train: epoch 0047, iter [03700, 05004], lr: 0.010000, loss: 3.2111, tea_CELoss: 1.3638 stu_CELoss: 1.5767 DMLLoss: 0.2706 
2022-03-14 17:21:54 - train: epoch 0047, iter [03800, 05004], lr: 0.010000, loss: 3.0510, tea_CELoss: 1.3285 stu_CELoss: 1.4329 DMLLoss: 0.2895 
2022-03-14 17:22:28 - train: epoch 0047, iter [03900, 05004], lr: 0.010000, loss: 3.6792, tea_CELoss: 1.5887 stu_CELoss: 1.7925 DMLLoss: 0.2980 
2022-03-14 17:23:02 - train: epoch 0047, iter [04000, 05004], lr: 0.010000, loss: 3.4736, tea_CELoss: 1.5308 stu_CELoss: 1.6988 DMLLoss: 0.2440 
2022-03-14 17:23:36 - train: epoch 0047, iter [04100, 05004], lr: 0.010000, loss: 3.5709, tea_CELoss: 1.5792 stu_CELoss: 1.7121 DMLLoss: 0.2797 
2022-03-14 17:24:09 - train: epoch 0047, iter [04200, 05004], lr: 0.010000, loss: 3.4816, tea_CELoss: 1.5370 stu_CELoss: 1.6363 DMLLoss: 0.3083 
2022-03-14 17:24:43 - train: epoch 0047, iter [04300, 05004], lr: 0.010000, loss: 3.1904, tea_CELoss: 1.3980 stu_CELoss: 1.5330 DMLLoss: 0.2594 
2022-03-14 17:25:17 - train: epoch 0047, iter [04400, 05004], lr: 0.010000, loss: 3.3893, tea_CELoss: 1.4727 stu_CELoss: 1.6282 DMLLoss: 0.2884 
2022-03-14 17:25:51 - train: epoch 0047, iter [04500, 05004], lr: 0.010000, loss: 3.3798, tea_CELoss: 1.5305 stu_CELoss: 1.5892 DMLLoss: 0.2601 
2022-03-14 17:26:24 - train: epoch 0047, iter [04600, 05004], lr: 0.010000, loss: 3.2997, tea_CELoss: 1.4441 stu_CELoss: 1.5912 DMLLoss: 0.2645 
2022-03-14 17:26:58 - train: epoch 0047, iter [04700, 05004], lr: 0.010000, loss: 3.6463, tea_CELoss: 1.5893 stu_CELoss: 1.7613 DMLLoss: 0.2957 
2022-03-14 17:27:31 - train: epoch 0047, iter [04800, 05004], lr: 0.010000, loss: 2.9728, tea_CELoss: 1.2487 stu_CELoss: 1.4137 DMLLoss: 0.3105 
2022-03-14 17:28:05 - train: epoch 0047, iter [04900, 05004], lr: 0.010000, loss: 3.5904, tea_CELoss: 1.5467 stu_CELoss: 1.7465 DMLLoss: 0.2973 
2022-03-14 17:28:37 - train: epoch 0047, iter [05000, 05004], lr: 0.010000, loss: 3.4274, tea_CELoss: 1.5154 stu_CELoss: 1.6550 DMLLoss: 0.2570 
2022-03-14 17:28:38 - train: epoch 047, train_loss: 3.4010
2022-03-14 17:31:07 - eval: epoch: 047, tea_acc1: 68.476%, tea_acc5: 88.908%, tea_test_loss: 1.2668, stu_acc1: 65.966%, stu_acc5: 87.030%, stu_test_loss: 1.3948
2022-03-14 17:31:08 - until epoch: 047, tea_best_acc1: 68.864%, stu_best_acc1: 66.210%
2022-03-14 17:31:08 - epoch 048 lr: 0.010000000000000002
2022-03-14 17:31:46 - train: epoch 0048, iter [00100, 05004], lr: 0.010000, loss: 3.6095, tea_CELoss: 1.5848 stu_CELoss: 1.7505 DMLLoss: 0.2743 
2022-03-14 17:32:20 - train: epoch 0048, iter [00200, 05004], lr: 0.010000, loss: 4.0132, tea_CELoss: 1.7829 stu_CELoss: 1.9374 DMLLoss: 0.2929 
2022-03-14 17:32:54 - train: epoch 0048, iter [00300, 05004], lr: 0.010000, loss: 3.3049, tea_CELoss: 1.4586 stu_CELoss: 1.5741 DMLLoss: 0.2722 
2022-03-14 17:33:28 - train: epoch 0048, iter [00400, 05004], lr: 0.010000, loss: 3.2539, tea_CELoss: 1.4289 stu_CELoss: 1.5630 DMLLoss: 0.2619 
2022-03-14 17:34:00 - train: epoch 0048, iter [00500, 05004], lr: 0.010000, loss: 3.6118, tea_CELoss: 1.5466 stu_CELoss: 1.7742 DMLLoss: 0.2910 
2022-03-14 17:34:34 - train: epoch 0048, iter [00600, 05004], lr: 0.010000, loss: 3.4266, tea_CELoss: 1.5226 stu_CELoss: 1.6417 DMLLoss: 0.2624 
2022-03-14 17:35:08 - train: epoch 0048, iter [00700, 05004], lr: 0.010000, loss: 3.0712, tea_CELoss: 1.3310 stu_CELoss: 1.4832 DMLLoss: 0.2569 
2022-03-14 17:35:41 - train: epoch 0048, iter [00800, 05004], lr: 0.010000, loss: 3.6003, tea_CELoss: 1.5859 stu_CELoss: 1.7499 DMLLoss: 0.2644 
2022-03-14 17:36:16 - train: epoch 0048, iter [00900, 05004], lr: 0.010000, loss: 3.5822, tea_CELoss: 1.5794 stu_CELoss: 1.6999 DMLLoss: 0.3029 
2022-03-14 17:36:49 - train: epoch 0048, iter [01000, 05004], lr: 0.010000, loss: 3.4966, tea_CELoss: 1.5064 stu_CELoss: 1.7141 DMLLoss: 0.2761 
2022-03-14 17:37:23 - train: epoch 0048, iter [01100, 05004], lr: 0.010000, loss: 3.7446, tea_CELoss: 1.6753 stu_CELoss: 1.8031 DMLLoss: 0.2662 
2022-03-14 17:37:56 - train: epoch 0048, iter [01200, 05004], lr: 0.010000, loss: 3.8214, tea_CELoss: 1.7223 stu_CELoss: 1.8393 DMLLoss: 0.2599 
2022-03-14 17:38:30 - train: epoch 0048, iter [01300, 05004], lr: 0.010000, loss: 3.4449, tea_CELoss: 1.5397 stu_CELoss: 1.6472 DMLLoss: 0.2580 
2022-03-14 17:39:04 - train: epoch 0048, iter [01400, 05004], lr: 0.010000, loss: 3.4932, tea_CELoss: 1.4559 stu_CELoss: 1.7045 DMLLoss: 0.3327 
2022-03-14 17:39:37 - train: epoch 0048, iter [01500, 05004], lr: 0.010000, loss: 3.6202, tea_CELoss: 1.5480 stu_CELoss: 1.7625 DMLLoss: 0.3097 
2022-03-14 17:40:10 - train: epoch 0048, iter [01600, 05004], lr: 0.010000, loss: 3.5174, tea_CELoss: 1.5491 stu_CELoss: 1.6525 DMLLoss: 0.3157 
2022-03-14 17:40:43 - train: epoch 0048, iter [01700, 05004], lr: 0.010000, loss: 3.5193, tea_CELoss: 1.4995 stu_CELoss: 1.7323 DMLLoss: 0.2875 
2022-03-14 17:41:17 - train: epoch 0048, iter [01800, 05004], lr: 0.010000, loss: 3.2466, tea_CELoss: 1.3803 stu_CELoss: 1.5808 DMLLoss: 0.2856 
2022-03-14 17:41:52 - train: epoch 0048, iter [01900, 05004], lr: 0.010000, loss: 3.5668, tea_CELoss: 1.5507 stu_CELoss: 1.7392 DMLLoss: 0.2768 
2022-03-14 17:42:25 - train: epoch 0048, iter [02000, 05004], lr: 0.010000, loss: 3.6593, tea_CELoss: 1.5524 stu_CELoss: 1.8005 DMLLoss: 0.3065 
2022-03-14 17:42:59 - train: epoch 0048, iter [02100, 05004], lr: 0.010000, loss: 3.5028, tea_CELoss: 1.5308 stu_CELoss: 1.6770 DMLLoss: 0.2950 
2022-03-14 17:43:32 - train: epoch 0048, iter [02200, 05004], lr: 0.010000, loss: 3.7805, tea_CELoss: 1.6475 stu_CELoss: 1.8337 DMLLoss: 0.2993 
2022-03-14 17:44:05 - train: epoch 0048, iter [02300, 05004], lr: 0.010000, loss: 3.3518, tea_CELoss: 1.4430 stu_CELoss: 1.5990 DMLLoss: 0.3098 
2022-03-14 17:44:39 - train: epoch 0048, iter [02400, 05004], lr: 0.010000, loss: 4.0004, tea_CELoss: 1.8164 stu_CELoss: 1.9161 DMLLoss: 0.2680 
2022-03-14 17:45:13 - train: epoch 0048, iter [02500, 05004], lr: 0.010000, loss: 3.5483, tea_CELoss: 1.5816 stu_CELoss: 1.6440 DMLLoss: 0.3227 
2022-03-14 17:45:46 - train: epoch 0048, iter [02600, 05004], lr: 0.010000, loss: 3.6657, tea_CELoss: 1.6403 stu_CELoss: 1.7367 DMLLoss: 0.2886 
2022-03-14 17:46:19 - train: epoch 0048, iter [02700, 05004], lr: 0.010000, loss: 3.7885, tea_CELoss: 1.6640 stu_CELoss: 1.8345 DMLLoss: 0.2900 
2022-03-14 17:46:54 - train: epoch 0048, iter [02800, 05004], lr: 0.010000, loss: 3.1702, tea_CELoss: 1.4072 stu_CELoss: 1.4998 DMLLoss: 0.2632 
2022-03-14 17:47:27 - train: epoch 0048, iter [02900, 05004], lr: 0.010000, loss: 3.2534, tea_CELoss: 1.3960 stu_CELoss: 1.5413 DMLLoss: 0.3161 
2022-03-14 17:48:01 - train: epoch 0048, iter [03000, 05004], lr: 0.010000, loss: 3.5846, tea_CELoss: 1.5938 stu_CELoss: 1.6834 DMLLoss: 0.3073 
2022-03-14 17:48:34 - train: epoch 0048, iter [03100, 05004], lr: 0.010000, loss: 3.6554, tea_CELoss: 1.6334 stu_CELoss: 1.7420 DMLLoss: 0.2800 
