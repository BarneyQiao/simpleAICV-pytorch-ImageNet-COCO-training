2022-03-10 08:16:07 - teacher: resnet34
2022-03-10 08:16:07 - student: resnet18
2022-03-10 08:16:07 - num_classes: 1000
2022-03-10 08:16:07 - input_image_size: 224
2022-03-10 08:16:07 - scale: 1.1428571428571428
2022-03-10 08:16:07 - teacher_pretrained_model_path: /root/code/simpleAICV-pytorch-ImageNet-COCO-training/pretrained_models/resnet/resnet34-acc73.930.pth
2022-03-10 08:16:07 - student_pretrained_model_path: 
2022-03-10 08:16:07 - freeze_teacher: True
2022-03-10 08:16:07 - loss_list: ['CELoss', 'KDLoss']
2022-03-10 08:16:07 - T: 1
2022-03-10 08:16:07 - train_criterion: {'CELoss': CELoss(
  (loss): CrossEntropyLoss()
), 'KDLoss': KDLoss()}
2022-03-10 08:16:07 - loss_name: KDLoss
2022-03-10 08:16:07 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2022-03-10 08:16:07 - train_dataset: <simpleAICV.classification.datasets.ilsvrc2012dataset.ILSVRC2012Dataset object at 0x7f14000ae730>
2022-03-10 08:16:07 - val_dataset: <simpleAICV.classification.datasets.ilsvrc2012dataset.ILSVRC2012Dataset object at 0x7f14000aea00>
2022-03-10 08:16:07 - collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f14000aea30>
2022-03-10 08:16:07 - seed: 0
2022-03-10 08:16:07 - batch_size: 256
2022-03-10 08:16:07 - num_workers: 16
2022-03-10 08:16:07 - optimizer: ('SGD', {'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0001})
2022-03-10 08:16:07 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.1, 'milestones': [30, 60, 90]})
2022-03-10 08:16:07 - epochs: 100
2022-03-10 08:16:07 - print_interval: 100
2022-03-10 08:16:07 - distributed: True
2022-03-10 08:16:07 - sync_bn: False
2022-03-10 08:16:07 - apex: True
2022-03-10 08:16:07 - gpus_type: NVIDIA GeForce RTX 3090
2022-03-10 08:16:07 - gpus_num: 2
2022-03-10 08:16:07 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f13e200f2f0>
2022-03-10 08:16:12 - --------------------parameters--------------------
2022-03-10 08:16:12 - name: teacher.conv1.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.conv1.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.conv1.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.0.conv1.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.0.conv1.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.0.conv1.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.0.conv2.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.0.conv2.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.0.conv2.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.1.conv1.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.1.conv1.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.1.conv1.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.1.conv2.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.1.conv2.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.1.conv2.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.2.conv1.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.2.conv1.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.2.conv1.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.2.conv2.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.2.conv2.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.2.conv2.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.0.conv1.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.0.conv1.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.0.conv1.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.0.conv2.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.0.conv2.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.0.conv2.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.0.downsample_conv.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.0.downsample_conv.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.0.downsample_conv.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.1.conv1.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.1.conv1.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.1.conv1.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.1.conv2.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.1.conv2.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.1.conv2.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.2.conv1.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.2.conv1.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.2.conv1.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.2.conv2.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.2.conv2.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.2.conv2.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.3.conv1.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.3.conv1.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.3.conv1.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.3.conv2.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.3.conv2.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.3.conv2.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.0.conv1.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.0.conv1.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.0.conv1.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.0.conv2.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.0.conv2.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.0.conv2.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.0.downsample_conv.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.0.downsample_conv.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.0.downsample_conv.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.1.conv1.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.1.conv1.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.1.conv1.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.1.conv2.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.1.conv2.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.1.conv2.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.2.conv1.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.2.conv1.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.2.conv1.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.2.conv2.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.2.conv2.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.2.conv2.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.3.conv1.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.3.conv1.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.3.conv1.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.3.conv2.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.3.conv2.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.3.conv2.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.4.conv1.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.4.conv1.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.4.conv1.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.4.conv2.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.4.conv2.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.4.conv2.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.5.conv1.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.5.conv1.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.5.conv1.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.5.conv2.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.5.conv2.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.5.conv2.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.0.conv1.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.0.conv1.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.0.conv1.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.0.conv2.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.0.conv2.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.0.conv2.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.0.downsample_conv.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.0.downsample_conv.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.0.downsample_conv.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.1.conv1.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.1.conv1.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.1.conv1.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.1.conv2.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.1.conv2.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.1.conv2.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.2.conv1.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.2.conv1.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.2.conv1.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.2.conv2.layer.0.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.2.conv2.layer.1.weight, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.2.conv2.layer.1.bias, grad: False
2022-03-10 08:16:12 - name: teacher.fc.weight, grad: False
2022-03-10 08:16:12 - name: teacher.fc.bias, grad: False
2022-03-10 08:16:12 - name: student.conv1.layer.0.weight, grad: True
2022-03-10 08:16:12 - name: student.conv1.layer.1.weight, grad: True
2022-03-10 08:16:12 - name: student.conv1.layer.1.bias, grad: True
2022-03-10 08:16:12 - name: student.layer1.0.conv1.layer.0.weight, grad: True
2022-03-10 08:16:12 - name: student.layer1.0.conv1.layer.1.weight, grad: True
2022-03-10 08:16:12 - name: student.layer1.0.conv1.layer.1.bias, grad: True
2022-03-10 08:16:12 - name: student.layer1.0.conv2.layer.0.weight, grad: True
2022-03-10 08:16:12 - name: student.layer1.0.conv2.layer.1.weight, grad: True
2022-03-10 08:16:12 - name: student.layer1.0.conv2.layer.1.bias, grad: True
2022-03-10 08:16:12 - name: student.layer1.1.conv1.layer.0.weight, grad: True
2022-03-10 08:16:12 - name: student.layer1.1.conv1.layer.1.weight, grad: True
2022-03-10 08:16:12 - name: student.layer1.1.conv1.layer.1.bias, grad: True
2022-03-10 08:16:12 - name: student.layer1.1.conv2.layer.0.weight, grad: True
2022-03-10 08:16:12 - name: student.layer1.1.conv2.layer.1.weight, grad: True
2022-03-10 08:16:12 - name: student.layer1.1.conv2.layer.1.bias, grad: True
2022-03-10 08:16:12 - name: student.layer2.0.conv1.layer.0.weight, grad: True
2022-03-10 08:16:12 - name: student.layer2.0.conv1.layer.1.weight, grad: True
2022-03-10 08:16:12 - name: student.layer2.0.conv1.layer.1.bias, grad: True
2022-03-10 08:16:12 - name: student.layer2.0.conv2.layer.0.weight, grad: True
2022-03-10 08:16:12 - name: student.layer2.0.conv2.layer.1.weight, grad: True
2022-03-10 08:16:12 - name: student.layer2.0.conv2.layer.1.bias, grad: True
2022-03-10 08:16:12 - name: student.layer2.0.downsample_conv.layer.0.weight, grad: True
2022-03-10 08:16:12 - name: student.layer2.0.downsample_conv.layer.1.weight, grad: True
2022-03-10 08:16:12 - name: student.layer2.0.downsample_conv.layer.1.bias, grad: True
2022-03-10 08:16:12 - name: student.layer2.1.conv1.layer.0.weight, grad: True
2022-03-10 08:16:12 - name: student.layer2.1.conv1.layer.1.weight, grad: True
2022-03-10 08:16:12 - name: student.layer2.1.conv1.layer.1.bias, grad: True
2022-03-10 08:16:12 - name: student.layer2.1.conv2.layer.0.weight, grad: True
2022-03-10 08:16:12 - name: student.layer2.1.conv2.layer.1.weight, grad: True
2022-03-10 08:16:12 - name: student.layer2.1.conv2.layer.1.bias, grad: True
2022-03-10 08:16:12 - name: student.layer3.0.conv1.layer.0.weight, grad: True
2022-03-10 08:16:12 - name: student.layer3.0.conv1.layer.1.weight, grad: True
2022-03-10 08:16:12 - name: student.layer3.0.conv1.layer.1.bias, grad: True
2022-03-10 08:16:12 - name: student.layer3.0.conv2.layer.0.weight, grad: True
2022-03-10 08:16:12 - name: student.layer3.0.conv2.layer.1.weight, grad: True
2022-03-10 08:16:12 - name: student.layer3.0.conv2.layer.1.bias, grad: True
2022-03-10 08:16:12 - name: student.layer3.0.downsample_conv.layer.0.weight, grad: True
2022-03-10 08:16:12 - name: student.layer3.0.downsample_conv.layer.1.weight, grad: True
2022-03-10 08:16:12 - name: student.layer3.0.downsample_conv.layer.1.bias, grad: True
2022-03-10 08:16:12 - name: student.layer3.1.conv1.layer.0.weight, grad: True
2022-03-10 08:16:12 - name: student.layer3.1.conv1.layer.1.weight, grad: True
2022-03-10 08:16:12 - name: student.layer3.1.conv1.layer.1.bias, grad: True
2022-03-10 08:16:12 - name: student.layer3.1.conv2.layer.0.weight, grad: True
2022-03-10 08:16:12 - name: student.layer3.1.conv2.layer.1.weight, grad: True
2022-03-10 08:16:12 - name: student.layer3.1.conv2.layer.1.bias, grad: True
2022-03-10 08:16:12 - name: student.layer4.0.conv1.layer.0.weight, grad: True
2022-03-10 08:16:12 - name: student.layer4.0.conv1.layer.1.weight, grad: True
2022-03-10 08:16:12 - name: student.layer4.0.conv1.layer.1.bias, grad: True
2022-03-10 08:16:12 - name: student.layer4.0.conv2.layer.0.weight, grad: True
2022-03-10 08:16:12 - name: student.layer4.0.conv2.layer.1.weight, grad: True
2022-03-10 08:16:12 - name: student.layer4.0.conv2.layer.1.bias, grad: True
2022-03-10 08:16:12 - name: student.layer4.0.downsample_conv.layer.0.weight, grad: True
2022-03-10 08:16:12 - name: student.layer4.0.downsample_conv.layer.1.weight, grad: True
2022-03-10 08:16:12 - name: student.layer4.0.downsample_conv.layer.1.bias, grad: True
2022-03-10 08:16:12 - name: student.layer4.1.conv1.layer.0.weight, grad: True
2022-03-10 08:16:12 - name: student.layer4.1.conv1.layer.1.weight, grad: True
2022-03-10 08:16:12 - name: student.layer4.1.conv1.layer.1.bias, grad: True
2022-03-10 08:16:12 - name: student.layer4.1.conv2.layer.0.weight, grad: True
2022-03-10 08:16:12 - name: student.layer4.1.conv2.layer.1.weight, grad: True
2022-03-10 08:16:12 - name: student.layer4.1.conv2.layer.1.bias, grad: True
2022-03-10 08:16:12 - name: student.fc.weight, grad: True
2022-03-10 08:16:12 - name: student.fc.bias, grad: True
2022-03-10 08:16:12 - --------------------buffers--------------------
2022-03-10 08:16:12 - name: teacher.conv1.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.conv1.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.conv1.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.0.conv1.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.0.conv1.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.0.conv2.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.0.conv2.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.1.conv1.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.1.conv1.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.1.conv2.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.1.conv2.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.2.conv1.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.2.conv1.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.2.conv1.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.2.conv2.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.2.conv2.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer1.2.conv2.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.0.conv1.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.0.conv1.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.0.conv2.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.0.conv2.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.0.downsample_conv.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.0.downsample_conv.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.1.conv1.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.1.conv1.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.1.conv2.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.1.conv2.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.2.conv1.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.2.conv1.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.2.conv1.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.2.conv2.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.2.conv2.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.2.conv2.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.3.conv1.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.3.conv1.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.3.conv1.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.3.conv2.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.3.conv2.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer2.3.conv2.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.0.conv1.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.0.conv1.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.0.conv2.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.0.conv2.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.0.downsample_conv.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.0.downsample_conv.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.1.conv1.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.1.conv1.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.1.conv2.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.1.conv2.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.2.conv1.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.2.conv1.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.2.conv1.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.2.conv2.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.2.conv2.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.2.conv2.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.3.conv1.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.3.conv1.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.3.conv1.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.3.conv2.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.3.conv2.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.3.conv2.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.4.conv1.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.4.conv1.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.4.conv1.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.4.conv2.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.4.conv2.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.4.conv2.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.5.conv1.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.5.conv1.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.5.conv1.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.5.conv2.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.5.conv2.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer3.5.conv2.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.0.conv1.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.0.conv1.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.0.conv2.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.0.conv2.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.0.downsample_conv.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.0.downsample_conv.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.1.conv1.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.1.conv1.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.1.conv2.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.1.conv2.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.2.conv1.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.2.conv1.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.2.conv1.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.2.conv2.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.2.conv2.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: teacher.layer4.2.conv2.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: student.conv1.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: student.conv1.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: student.conv1.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: student.layer1.0.conv1.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: student.layer1.0.conv1.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: student.layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: student.layer1.0.conv2.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: student.layer1.0.conv2.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: student.layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: student.layer1.1.conv1.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: student.layer1.1.conv1.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: student.layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: student.layer1.1.conv2.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: student.layer1.1.conv2.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: student.layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: student.layer2.0.conv1.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: student.layer2.0.conv1.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: student.layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: student.layer2.0.conv2.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: student.layer2.0.conv2.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: student.layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: student.layer2.0.downsample_conv.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: student.layer2.0.downsample_conv.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: student.layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: student.layer2.1.conv1.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: student.layer2.1.conv1.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: student.layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: student.layer2.1.conv2.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: student.layer2.1.conv2.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: student.layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: student.layer3.0.conv1.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: student.layer3.0.conv1.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: student.layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: student.layer3.0.conv2.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: student.layer3.0.conv2.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: student.layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: student.layer3.0.downsample_conv.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: student.layer3.0.downsample_conv.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: student.layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: student.layer3.1.conv1.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: student.layer3.1.conv1.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: student.layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: student.layer3.1.conv2.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: student.layer3.1.conv2.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: student.layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: student.layer4.0.conv1.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: student.layer4.0.conv1.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: student.layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: student.layer4.0.conv2.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: student.layer4.0.conv2.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: student.layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: student.layer4.0.downsample_conv.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: student.layer4.0.downsample_conv.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: student.layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: student.layer4.1.conv1.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: student.layer4.1.conv1.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: student.layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - name: student.layer4.1.conv2.layer.1.running_mean, grad: False
2022-03-10 08:16:12 - name: student.layer4.1.conv2.layer.1.running_var, grad: False
2022-03-10 08:16:12 - name: student.layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2022-03-10 08:16:12 - epoch 001 lr: 0.1
2022-03-10 08:16:50 - train: epoch 0001, iter [00100, 05004], lr: 0.100000, loss: 12.5307, CELoss: 6.7824 KDLoss: 5.7482 
2022-03-10 08:17:24 - train: epoch 0001, iter [00200, 05004], lr: 0.100000, loss: 12.1110, CELoss: 6.5281 KDLoss: 5.5829 
2022-03-10 08:17:58 - train: epoch 0001, iter [00300, 05004], lr: 0.100000, loss: 11.6064, CELoss: 6.3877 KDLoss: 5.2187 
2022-03-10 08:18:31 - train: epoch 0001, iter [00400, 05004], lr: 0.100000, loss: 11.3859, CELoss: 6.2016 KDLoss: 5.1843 
2022-03-10 08:19:04 - train: epoch 0001, iter [00500, 05004], lr: 0.100000, loss: 11.0619, CELoss: 6.0574 KDLoss: 5.0044 
2022-03-10 08:19:37 - train: epoch 0001, iter [00600, 05004], lr: 0.100000, loss: 10.5505, CELoss: 5.7642 KDLoss: 4.7863 
2022-03-10 08:20:12 - train: epoch 0001, iter [00700, 05004], lr: 0.100000, loss: 10.4202, CELoss: 5.7522 KDLoss: 4.6680 
2022-03-10 08:20:44 - train: epoch 0001, iter [00800, 05004], lr: 0.100000, loss: 10.2852, CELoss: 5.7087 KDLoss: 4.5765 
2022-03-10 08:21:18 - train: epoch 0001, iter [00900, 05004], lr: 0.100000, loss: 9.9743, CELoss: 5.6195 KDLoss: 4.3548 
2022-03-10 08:21:53 - train: epoch 0001, iter [01000, 05004], lr: 0.100000, loss: 9.9188, CELoss: 5.5121 KDLoss: 4.4067 
2022-03-10 08:22:25 - train: epoch 0001, iter [01100, 05004], lr: 0.100000, loss: 9.7383, CELoss: 5.4865 KDLoss: 4.2518 
2022-03-10 08:22:58 - train: epoch 0001, iter [01200, 05004], lr: 0.100000, loss: 9.5784, CELoss: 5.3156 KDLoss: 4.2628 
2022-03-10 08:23:31 - train: epoch 0001, iter [01300, 05004], lr: 0.100000, loss: 9.4929, CELoss: 5.2681 KDLoss: 4.2248 
2022-03-10 08:24:04 - train: epoch 0001, iter [01400, 05004], lr: 0.100000, loss: 9.2564, CELoss: 5.2158 KDLoss: 4.0406 
2022-03-10 08:24:38 - train: epoch 0001, iter [01500, 05004], lr: 0.100000, loss: 9.0359, CELoss: 4.9834 KDLoss: 4.0525 
2022-03-10 08:25:12 - train: epoch 0001, iter [01600, 05004], lr: 0.100000, loss: 9.0307, CELoss: 5.1079 KDLoss: 3.9227 
2022-03-10 08:25:46 - train: epoch 0001, iter [01700, 05004], lr: 0.100000, loss: 8.6231, CELoss: 4.8281 KDLoss: 3.7950 
2022-03-10 08:26:19 - train: epoch 0001, iter [01800, 05004], lr: 0.100000, loss: 8.7329, CELoss: 4.9733 KDLoss: 3.7596 
2022-03-10 08:26:52 - train: epoch 0001, iter [01900, 05004], lr: 0.100000, loss: 8.4793, CELoss: 4.7184 KDLoss: 3.7609 
2022-03-10 08:27:26 - train: epoch 0001, iter [02000, 05004], lr: 0.100000, loss: 8.2515, CELoss: 4.6400 KDLoss: 3.6115 
2022-03-10 08:27:59 - train: epoch 0001, iter [02100, 05004], lr: 0.100000, loss: 8.1858, CELoss: 4.6461 KDLoss: 3.5396 
2022-03-10 08:28:33 - train: epoch 0001, iter [02200, 05004], lr: 0.100000, loss: 8.1155, CELoss: 4.5851 KDLoss: 3.5304 
2022-03-10 08:29:06 - train: epoch 0001, iter [02300, 05004], lr: 0.100000, loss: 7.7565, CELoss: 4.4070 KDLoss: 3.3496 
2022-03-10 08:29:39 - train: epoch 0001, iter [02400, 05004], lr: 0.100000, loss: 7.7002, CELoss: 4.4422 KDLoss: 3.2579 
2022-03-10 08:30:12 - train: epoch 0001, iter [02500, 05004], lr: 0.100000, loss: 7.9260, CELoss: 4.5471 KDLoss: 3.3789 
2022-03-10 08:30:46 - train: epoch 0001, iter [02600, 05004], lr: 0.100000, loss: 7.9806, CELoss: 4.6161 KDLoss: 3.3645 
2022-03-10 08:31:20 - train: epoch 0001, iter [02700, 05004], lr: 0.100000, loss: 8.1201, CELoss: 4.6838 KDLoss: 3.4363 
2022-03-10 08:31:53 - train: epoch 0001, iter [02800, 05004], lr: 0.100000, loss: 7.4196, CELoss: 4.2343 KDLoss: 3.1854 
2022-03-10 08:32:27 - train: epoch 0001, iter [02900, 05004], lr: 0.100000, loss: 7.2424, CELoss: 4.1634 KDLoss: 3.0791 
2022-03-10 08:33:00 - train: epoch 0001, iter [03000, 05004], lr: 0.100000, loss: 7.3704, CELoss: 4.2572 KDLoss: 3.1132 
2022-03-10 08:33:33 - train: epoch 0001, iter [03100, 05004], lr: 0.100000, loss: 7.6658, CELoss: 4.3891 KDLoss: 3.2767 
2022-03-10 08:34:07 - train: epoch 0001, iter [03200, 05004], lr: 0.100000, loss: 7.2800, CELoss: 4.2292 KDLoss: 3.0508 
2022-03-10 08:34:41 - train: epoch 0001, iter [03300, 05004], lr: 0.100000, loss: 6.6729, CELoss: 3.9229 KDLoss: 2.7501 
2022-03-10 08:35:15 - train: epoch 0001, iter [03400, 05004], lr: 0.100000, loss: 6.8267, CELoss: 3.9528 KDLoss: 2.8739 
2022-03-10 08:35:47 - train: epoch 0001, iter [03500, 05004], lr: 0.100000, loss: 7.1819, CELoss: 4.1267 KDLoss: 3.0551 
2022-03-10 08:36:21 - train: epoch 0001, iter [03600, 05004], lr: 0.100000, loss: 6.9564, CELoss: 3.9983 KDLoss: 2.9582 
2022-03-10 08:36:54 - train: epoch 0001, iter [03700, 05004], lr: 0.100000, loss: 7.1295, CELoss: 4.2220 KDLoss: 2.9075 
2022-03-10 08:37:28 - train: epoch 0001, iter [03800, 05004], lr: 0.100000, loss: 6.5603, CELoss: 3.8549 KDLoss: 2.7055 
2022-03-10 08:38:02 - train: epoch 0001, iter [03900, 05004], lr: 0.100000, loss: 6.8810, CELoss: 4.0008 KDLoss: 2.8802 
2022-03-10 08:38:35 - train: epoch 0001, iter [04000, 05004], lr: 0.100000, loss: 6.6999, CELoss: 3.8856 KDLoss: 2.8143 
2022-03-10 08:39:08 - train: epoch 0001, iter [04100, 05004], lr: 0.100000, loss: 6.7089, CELoss: 3.9541 KDLoss: 2.7548 
2022-03-10 08:39:42 - train: epoch 0001, iter [04200, 05004], lr: 0.100000, loss: 6.5516, CELoss: 3.8180 KDLoss: 2.7336 
2022-03-10 08:40:16 - train: epoch 0001, iter [04300, 05004], lr: 0.100000, loss: 6.5477, CELoss: 3.7800 KDLoss: 2.7677 
2022-03-10 08:40:49 - train: epoch 0001, iter [04400, 05004], lr: 0.100000, loss: 6.0037, CELoss: 3.5293 KDLoss: 2.4744 
2022-03-10 08:41:23 - train: epoch 0001, iter [04500, 05004], lr: 0.100000, loss: 6.5045, CELoss: 3.8078 KDLoss: 2.6967 
2022-03-10 08:41:56 - train: epoch 0001, iter [04600, 05004], lr: 0.100000, loss: 6.6628, CELoss: 3.9597 KDLoss: 2.7030 
2022-03-10 08:42:30 - train: epoch 0001, iter [04700, 05004], lr: 0.100000, loss: 6.3467, CELoss: 3.7540 KDLoss: 2.5927 
2022-03-10 08:43:02 - train: epoch 0001, iter [04800, 05004], lr: 0.100000, loss: 6.6075, CELoss: 3.9784 KDLoss: 2.6291 
2022-03-10 08:43:36 - train: epoch 0001, iter [04900, 05004], lr: 0.100000, loss: 6.1057, CELoss: 3.6118 KDLoss: 2.4939 
2022-03-10 08:44:08 - train: epoch 0001, iter [05000, 05004], lr: 0.100000, loss: 6.0229, CELoss: 3.5208 KDLoss: 2.5020 
2022-03-10 08:44:08 - train: epoch 001, train_loss: 8.2459
2022-03-10 08:46:38 - eval: epoch: 001, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 25.826%, stu_acc5: 50.300%, stu_test_loss: 3.6219
2022-03-10 08:46:38 - until epoch: 001, tea_best_acc1: 73.950%, stu_best_acc1: 25.826%
2022-03-10 08:46:38 - epoch 002 lr: 0.1
2022-03-10 08:47:18 - train: epoch 0002, iter [00100, 05004], lr: 0.100000, loss: 5.7953, CELoss: 3.4213 KDLoss: 2.3740 
2022-03-10 08:47:51 - train: epoch 0002, iter [00200, 05004], lr: 0.100000, loss: 5.9230, CELoss: 3.5095 KDLoss: 2.4135 
2022-03-10 08:48:25 - train: epoch 0002, iter [00300, 05004], lr: 0.100000, loss: 6.2104, CELoss: 3.6573 KDLoss: 2.5531 
2022-03-10 08:48:57 - train: epoch 0002, iter [00400, 05004], lr: 0.100000, loss: 6.0571, CELoss: 3.6544 KDLoss: 2.4027 
2022-03-10 08:49:32 - train: epoch 0002, iter [00500, 05004], lr: 0.100000, loss: 5.6758, CELoss: 3.4325 KDLoss: 2.2433 
2022-03-10 08:50:05 - train: epoch 0002, iter [00600, 05004], lr: 0.100000, loss: 5.6442, CELoss: 3.3344 KDLoss: 2.3098 
2022-03-10 08:50:39 - train: epoch 0002, iter [00700, 05004], lr: 0.100000, loss: 6.1038, CELoss: 3.6315 KDLoss: 2.4723 
2022-03-10 08:51:12 - train: epoch 0002, iter [00800, 05004], lr: 0.100000, loss: 5.8485, CELoss: 3.4660 KDLoss: 2.3826 
2022-03-10 08:51:46 - train: epoch 0002, iter [00900, 05004], lr: 0.100000, loss: 5.5686, CELoss: 3.2921 KDLoss: 2.2765 
2022-03-10 08:52:20 - train: epoch 0002, iter [01000, 05004], lr: 0.100000, loss: 5.5321, CELoss: 3.3493 KDLoss: 2.1829 
2022-03-10 08:52:53 - train: epoch 0002, iter [01100, 05004], lr: 0.100000, loss: 6.0757, CELoss: 3.6841 KDLoss: 2.3917 
2022-03-10 08:53:27 - train: epoch 0002, iter [01200, 05004], lr: 0.100000, loss: 5.3990, CELoss: 3.2000 KDLoss: 2.1990 
2022-03-10 08:54:00 - train: epoch 0002, iter [01300, 05004], lr: 0.100000, loss: 5.6981, CELoss: 3.3588 KDLoss: 2.3393 
2022-03-10 08:54:34 - train: epoch 0002, iter [01400, 05004], lr: 0.100000, loss: 5.9811, CELoss: 3.5668 KDLoss: 2.4142 
2022-03-10 08:55:08 - train: epoch 0002, iter [01500, 05004], lr: 0.100000, loss: 5.6378, CELoss: 3.3642 KDLoss: 2.2736 
2022-03-10 08:55:42 - train: epoch 0002, iter [01600, 05004], lr: 0.100000, loss: 5.7139, CELoss: 3.4296 KDLoss: 2.2843 
2022-03-10 08:56:15 - train: epoch 0002, iter [01700, 05004], lr: 0.100000, loss: 5.3755, CELoss: 3.2777 KDLoss: 2.0978 
2022-03-10 08:56:48 - train: epoch 0002, iter [01800, 05004], lr: 0.100000, loss: 5.3735, CELoss: 3.2515 KDLoss: 2.1220 
2022-03-10 08:57:23 - train: epoch 0002, iter [01900, 05004], lr: 0.100000, loss: 5.0659, CELoss: 3.0443 KDLoss: 2.0217 
2022-03-10 08:57:57 - train: epoch 0002, iter [02000, 05004], lr: 0.100000, loss: 5.1301, CELoss: 2.9606 KDLoss: 2.1695 
2022-03-10 08:58:29 - train: epoch 0002, iter [02100, 05004], lr: 0.100000, loss: 5.2356, CELoss: 3.1578 KDLoss: 2.0777 
2022-03-10 08:59:03 - train: epoch 0002, iter [02200, 05004], lr: 0.100000, loss: 5.4904, CELoss: 3.2878 KDLoss: 2.2026 
2022-03-10 08:59:38 - train: epoch 0002, iter [02300, 05004], lr: 0.100000, loss: 5.3787, CELoss: 3.2198 KDLoss: 2.1589 
2022-03-10 09:00:10 - train: epoch 0002, iter [02400, 05004], lr: 0.100000, loss: 5.3236, CELoss: 3.1480 KDLoss: 2.1757 
2022-03-10 09:00:45 - train: epoch 0002, iter [02500, 05004], lr: 0.100000, loss: 5.0765, CELoss: 2.9988 KDLoss: 2.0777 
2022-03-10 09:01:17 - train: epoch 0002, iter [02600, 05004], lr: 0.100000, loss: 5.0310, CELoss: 2.9717 KDLoss: 2.0593 
2022-03-10 09:01:52 - train: epoch 0002, iter [02700, 05004], lr: 0.100000, loss: 5.5418, CELoss: 3.3596 KDLoss: 2.1822 
2022-03-10 09:02:25 - train: epoch 0002, iter [02800, 05004], lr: 0.100000, loss: 5.3841, CELoss: 3.2669 KDLoss: 2.1172 
2022-03-10 09:02:59 - train: epoch 0002, iter [02900, 05004], lr: 0.100000, loss: 5.2630, CELoss: 3.0983 KDLoss: 2.1647 
2022-03-10 09:03:32 - train: epoch 0002, iter [03000, 05004], lr: 0.100000, loss: 4.8310, CELoss: 2.9369 KDLoss: 1.8941 
2022-03-10 09:04:06 - train: epoch 0002, iter [03100, 05004], lr: 0.100000, loss: 5.2334, CELoss: 3.0944 KDLoss: 2.1389 
2022-03-10 09:04:40 - train: epoch 0002, iter [03200, 05004], lr: 0.100000, loss: 5.2721, CELoss: 3.1938 KDLoss: 2.0782 
2022-03-10 09:05:13 - train: epoch 0002, iter [03300, 05004], lr: 0.100000, loss: 5.2108, CELoss: 3.2746 KDLoss: 1.9362 
2022-03-10 09:05:47 - train: epoch 0002, iter [03400, 05004], lr: 0.100000, loss: 5.4555, CELoss: 3.2429 KDLoss: 2.2125 
2022-03-10 09:06:19 - train: epoch 0002, iter [03500, 05004], lr: 0.100000, loss: 5.2742, CELoss: 3.1367 KDLoss: 2.1375 
2022-03-10 09:06:54 - train: epoch 0002, iter [03600, 05004], lr: 0.100000, loss: 5.0868, CELoss: 3.1488 KDLoss: 1.9380 
2022-03-10 09:07:27 - train: epoch 0002, iter [03700, 05004], lr: 0.100000, loss: 5.4657, CELoss: 3.3616 KDLoss: 2.1042 
2022-03-10 09:08:01 - train: epoch 0002, iter [03800, 05004], lr: 0.100000, loss: 4.9946, CELoss: 3.0590 KDLoss: 1.9356 
2022-03-10 09:08:35 - train: epoch 0002, iter [03900, 05004], lr: 0.100000, loss: 5.1405, CELoss: 3.0975 KDLoss: 2.0430 
2022-03-10 09:09:08 - train: epoch 0002, iter [04000, 05004], lr: 0.100000, loss: 4.8316, CELoss: 2.9581 KDLoss: 1.8735 
2022-03-10 09:09:41 - train: epoch 0002, iter [04100, 05004], lr: 0.100000, loss: 5.1000, CELoss: 3.0857 KDLoss: 2.0143 
2022-03-10 09:10:16 - train: epoch 0002, iter [04200, 05004], lr: 0.100000, loss: 5.1112, CELoss: 3.0977 KDLoss: 2.0136 
2022-03-10 09:10:49 - train: epoch 0002, iter [04300, 05004], lr: 0.100000, loss: 5.1638, CELoss: 3.1467 KDLoss: 2.0171 
2022-03-10 09:11:23 - train: epoch 0002, iter [04400, 05004], lr: 0.100000, loss: 4.8296, CELoss: 2.9553 KDLoss: 1.8743 
2022-03-10 09:11:56 - train: epoch 0002, iter [04500, 05004], lr: 0.100000, loss: 4.6264, CELoss: 2.7967 KDLoss: 1.8297 
2022-03-10 09:12:30 - train: epoch 0002, iter [04600, 05004], lr: 0.100000, loss: 5.0004, CELoss: 2.9763 KDLoss: 2.0240 
2022-03-10 09:13:02 - train: epoch 0002, iter [04700, 05004], lr: 0.100000, loss: 4.7468, CELoss: 2.8333 KDLoss: 1.9136 
2022-03-10 09:13:36 - train: epoch 0002, iter [04800, 05004], lr: 0.100000, loss: 5.1844, CELoss: 3.2317 KDLoss: 1.9527 
2022-03-10 09:14:10 - train: epoch 0002, iter [04900, 05004], lr: 0.100000, loss: 4.7167, CELoss: 2.8675 KDLoss: 1.8492 
2022-03-10 09:14:42 - train: epoch 0002, iter [05000, 05004], lr: 0.100000, loss: 5.1438, CELoss: 3.1252 KDLoss: 2.0185 
2022-03-10 09:14:42 - train: epoch 002, train_loss: 5.4011
2022-03-10 09:17:10 - eval: epoch: 002, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 38.388%, stu_acc5: 65.300%, stu_test_loss: 2.8084
2022-03-10 09:17:11 - until epoch: 002, tea_best_acc1: 73.950%, stu_best_acc1: 38.388%
2022-03-10 09:17:11 - epoch 003 lr: 0.1
2022-03-10 09:17:49 - train: epoch 0003, iter [00100, 05004], lr: 0.100000, loss: 4.8515, CELoss: 3.0301 KDLoss: 1.8214 
2022-03-10 09:18:23 - train: epoch 0003, iter [00200, 05004], lr: 0.100000, loss: 4.8271, CELoss: 2.8912 KDLoss: 1.9359 
2022-03-10 09:18:56 - train: epoch 0003, iter [00300, 05004], lr: 0.100000, loss: 4.6613, CELoss: 2.8457 KDLoss: 1.8156 
2022-03-10 09:19:30 - train: epoch 0003, iter [00400, 05004], lr: 0.100000, loss: 4.9946, CELoss: 3.0779 KDLoss: 1.9167 
2022-03-10 09:20:03 - train: epoch 0003, iter [00500, 05004], lr: 0.100000, loss: 4.9336, CELoss: 3.0576 KDLoss: 1.8760 
2022-03-10 09:20:37 - train: epoch 0003, iter [00600, 05004], lr: 0.100000, loss: 4.4626, CELoss: 2.7286 KDLoss: 1.7340 
2022-03-10 09:21:10 - train: epoch 0003, iter [00700, 05004], lr: 0.100000, loss: 5.0307, CELoss: 3.1382 KDLoss: 1.8925 
2022-03-10 09:21:43 - train: epoch 0003, iter [00800, 05004], lr: 0.100000, loss: 5.0876, CELoss: 3.1460 KDLoss: 1.9415 
2022-03-10 09:22:17 - train: epoch 0003, iter [00900, 05004], lr: 0.100000, loss: 4.7639, CELoss: 2.9163 KDLoss: 1.8476 
2022-03-10 09:22:50 - train: epoch 0003, iter [01000, 05004], lr: 0.100000, loss: 4.6526, CELoss: 2.9543 KDLoss: 1.6983 
2022-03-10 09:23:24 - train: epoch 0003, iter [01100, 05004], lr: 0.100000, loss: 4.7653, CELoss: 2.9102 KDLoss: 1.8551 
2022-03-10 09:23:57 - train: epoch 0003, iter [01200, 05004], lr: 0.100000, loss: 4.7425, CELoss: 2.9266 KDLoss: 1.8160 
2022-03-10 09:24:31 - train: epoch 0003, iter [01300, 05004], lr: 0.100000, loss: 4.3642, CELoss: 2.7125 KDLoss: 1.6517 
2022-03-10 09:25:03 - train: epoch 0003, iter [01400, 05004], lr: 0.100000, loss: 4.5290, CELoss: 2.7540 KDLoss: 1.7750 
2022-03-10 09:25:36 - train: epoch 0003, iter [01500, 05004], lr: 0.100000, loss: 5.1193, CELoss: 3.1562 KDLoss: 1.9631 
2022-03-10 09:26:10 - train: epoch 0003, iter [01600, 05004], lr: 0.100000, loss: 4.6505, CELoss: 2.7788 KDLoss: 1.8717 
2022-03-10 09:26:44 - train: epoch 0003, iter [01700, 05004], lr: 0.100000, loss: 4.5008, CELoss: 2.7582 KDLoss: 1.7425 
2022-03-10 09:27:17 - train: epoch 0003, iter [01800, 05004], lr: 0.100000, loss: 4.2197, CELoss: 2.6703 KDLoss: 1.5494 
2022-03-10 09:27:52 - train: epoch 0003, iter [01900, 05004], lr: 0.100000, loss: 4.9067, CELoss: 2.9843 KDLoss: 1.9225 
2022-03-10 09:28:25 - train: epoch 0003, iter [02000, 05004], lr: 0.100000, loss: 4.7386, CELoss: 3.0385 KDLoss: 1.7001 
2022-03-10 09:28:59 - train: epoch 0003, iter [02100, 05004], lr: 0.100000, loss: 4.9859, CELoss: 3.1329 KDLoss: 1.8530 
2022-03-10 09:29:32 - train: epoch 0003, iter [02200, 05004], lr: 0.100000, loss: 5.2108, CELoss: 3.3005 KDLoss: 1.9103 
2022-03-10 09:30:06 - train: epoch 0003, iter [02300, 05004], lr: 0.100000, loss: 4.4960, CELoss: 2.8694 KDLoss: 1.6266 
2022-03-10 09:30:39 - train: epoch 0003, iter [02400, 05004], lr: 0.100000, loss: 4.4389, CELoss: 2.7144 KDLoss: 1.7244 
2022-03-10 09:31:13 - train: epoch 0003, iter [02500, 05004], lr: 0.100000, loss: 4.6301, CELoss: 2.8825 KDLoss: 1.7476 
2022-03-10 09:31:46 - train: epoch 0003, iter [02600, 05004], lr: 0.100000, loss: 4.7465, CELoss: 3.0164 KDLoss: 1.7301 
2022-03-10 09:32:21 - train: epoch 0003, iter [02700, 05004], lr: 0.100000, loss: 4.8305, CELoss: 3.0894 KDLoss: 1.7411 
2022-03-10 09:32:54 - train: epoch 0003, iter [02800, 05004], lr: 0.100000, loss: 4.3253, CELoss: 2.7034 KDLoss: 1.6218 
2022-03-10 09:33:27 - train: epoch 0003, iter [02900, 05004], lr: 0.100000, loss: 4.6079, CELoss: 2.8829 KDLoss: 1.7250 
2022-03-10 09:34:01 - train: epoch 0003, iter [03000, 05004], lr: 0.100000, loss: 4.4730, CELoss: 2.7868 KDLoss: 1.6862 
2022-03-10 09:34:36 - train: epoch 0003, iter [03100, 05004], lr: 0.100000, loss: 4.9070, CELoss: 3.0923 KDLoss: 1.8147 
2022-03-10 09:35:08 - train: epoch 0003, iter [03200, 05004], lr: 0.100000, loss: 4.7626, CELoss: 3.0157 KDLoss: 1.7470 
2022-03-10 09:35:42 - train: epoch 0003, iter [03300, 05004], lr: 0.100000, loss: 4.4620, CELoss: 2.7525 KDLoss: 1.7095 
2022-03-10 09:36:15 - train: epoch 0003, iter [03400, 05004], lr: 0.100000, loss: 4.9543, CELoss: 3.1173 KDLoss: 1.8369 
2022-03-10 09:36:50 - train: epoch 0003, iter [03500, 05004], lr: 0.100000, loss: 4.6778, CELoss: 2.8374 KDLoss: 1.8404 
2022-03-10 09:37:23 - train: epoch 0003, iter [03600, 05004], lr: 0.100000, loss: 4.5387, CELoss: 2.7576 KDLoss: 1.7811 
2022-03-10 09:37:57 - train: epoch 0003, iter [03700, 05004], lr: 0.100000, loss: 4.6360, CELoss: 2.8534 KDLoss: 1.7826 
2022-03-10 09:38:29 - train: epoch 0003, iter [03800, 05004], lr: 0.100000, loss: 4.6320, CELoss: 2.9567 KDLoss: 1.6753 
2022-03-10 09:39:03 - train: epoch 0003, iter [03900, 05004], lr: 0.100000, loss: 5.0607, CELoss: 3.1811 KDLoss: 1.8797 
2022-03-10 09:39:36 - train: epoch 0003, iter [04000, 05004], lr: 0.100000, loss: 4.1341, CELoss: 2.5423 KDLoss: 1.5918 
2022-03-10 09:40:10 - train: epoch 0003, iter [04100, 05004], lr: 0.100000, loss: 4.2773, CELoss: 2.8263 KDLoss: 1.4510 
2022-03-10 09:40:43 - train: epoch 0003, iter [04200, 05004], lr: 0.100000, loss: 4.4202, CELoss: 2.7996 KDLoss: 1.6207 
2022-03-10 09:41:17 - train: epoch 0003, iter [04300, 05004], lr: 0.100000, loss: 4.2078, CELoss: 2.5523 KDLoss: 1.6556 
2022-03-10 09:41:50 - train: epoch 0003, iter [04400, 05004], lr: 0.100000, loss: 4.3207, CELoss: 2.7374 KDLoss: 1.5833 
2022-03-10 09:42:24 - train: epoch 0003, iter [04500, 05004], lr: 0.100000, loss: 4.4001, CELoss: 2.7403 KDLoss: 1.6598 
2022-03-10 09:42:57 - train: epoch 0003, iter [04600, 05004], lr: 0.100000, loss: 4.2915, CELoss: 2.6722 KDLoss: 1.6193 
2022-03-10 09:43:31 - train: epoch 0003, iter [04700, 05004], lr: 0.100000, loss: 4.4056, CELoss: 2.7804 KDLoss: 1.6252 
2022-03-10 09:44:05 - train: epoch 0003, iter [04800, 05004], lr: 0.100000, loss: 5.0206, CELoss: 3.1735 KDLoss: 1.8470 
2022-03-10 09:44:38 - train: epoch 0003, iter [04900, 05004], lr: 0.100000, loss: 4.6123, CELoss: 2.8647 KDLoss: 1.7477 
2022-03-10 09:45:09 - train: epoch 0003, iter [05000, 05004], lr: 0.100000, loss: 4.7050, CELoss: 2.9145 KDLoss: 1.7905 
2022-03-10 09:45:10 - train: epoch 003, train_loss: 4.6386
2022-03-10 09:47:39 - eval: epoch: 003, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 41.378%, stu_acc5: 67.718%, stu_test_loss: 2.6351
2022-03-10 09:47:39 - until epoch: 003, tea_best_acc1: 73.950%, stu_best_acc1: 41.378%
2022-03-10 09:47:39 - epoch 004 lr: 0.1
2022-03-10 09:48:17 - train: epoch 0004, iter [00100, 05004], lr: 0.100000, loss: 4.7996, CELoss: 3.0800 KDLoss: 1.7196 
2022-03-10 09:48:53 - train: epoch 0004, iter [00200, 05004], lr: 0.100000, loss: 4.1154, CELoss: 2.5337 KDLoss: 1.5817 
2022-03-10 09:49:24 - train: epoch 0004, iter [00300, 05004], lr: 0.100000, loss: 4.4245, CELoss: 2.7378 KDLoss: 1.6867 
2022-03-10 09:49:59 - train: epoch 0004, iter [00400, 05004], lr: 0.100000, loss: 4.1923, CELoss: 2.6745 KDLoss: 1.5178 
2022-03-10 09:50:32 - train: epoch 0004, iter [00500, 05004], lr: 0.100000, loss: 4.2915, CELoss: 2.6280 KDLoss: 1.6634 
2022-03-10 09:51:04 - train: epoch 0004, iter [00600, 05004], lr: 0.100000, loss: 4.7451, CELoss: 2.9731 KDLoss: 1.7720 
2022-03-10 09:51:38 - train: epoch 0004, iter [00700, 05004], lr: 0.100000, loss: 4.5011, CELoss: 2.9156 KDLoss: 1.5855 
2022-03-10 09:52:12 - train: epoch 0004, iter [00800, 05004], lr: 0.100000, loss: 4.3254, CELoss: 2.7069 KDLoss: 1.6185 
2022-03-10 09:52:45 - train: epoch 0004, iter [00900, 05004], lr: 0.100000, loss: 4.0203, CELoss: 2.4662 KDLoss: 1.5541 
2022-03-10 09:53:19 - train: epoch 0004, iter [01000, 05004], lr: 0.100000, loss: 4.4670, CELoss: 2.7729 KDLoss: 1.6941 
2022-03-10 09:53:52 - train: epoch 0004, iter [01100, 05004], lr: 0.100000, loss: 4.3504, CELoss: 2.8022 KDLoss: 1.5482 
2022-03-10 09:54:26 - train: epoch 0004, iter [01200, 05004], lr: 0.100000, loss: 4.0992, CELoss: 2.5258 KDLoss: 1.5734 
2022-03-10 09:54:59 - train: epoch 0004, iter [01300, 05004], lr: 0.100000, loss: 4.3117, CELoss: 2.6653 KDLoss: 1.6465 
2022-03-10 09:55:32 - train: epoch 0004, iter [01400, 05004], lr: 0.100000, loss: 4.3732, CELoss: 2.8041 KDLoss: 1.5691 
2022-03-10 09:56:06 - train: epoch 0004, iter [01500, 05004], lr: 0.100000, loss: 4.1859, CELoss: 2.6037 KDLoss: 1.5822 
2022-03-10 09:56:39 - train: epoch 0004, iter [01600, 05004], lr: 0.100000, loss: 4.4651, CELoss: 2.7955 KDLoss: 1.6696 
2022-03-10 09:57:13 - train: epoch 0004, iter [01700, 05004], lr: 0.100000, loss: 4.2651, CELoss: 2.6669 KDLoss: 1.5982 
2022-03-10 09:57:46 - train: epoch 0004, iter [01800, 05004], lr: 0.100000, loss: 4.7620, CELoss: 3.0065 KDLoss: 1.7555 
2022-03-10 09:58:20 - train: epoch 0004, iter [01900, 05004], lr: 0.100000, loss: 4.4315, CELoss: 2.7598 KDLoss: 1.6717 
2022-03-10 09:58:54 - train: epoch 0004, iter [02000, 05004], lr: 0.100000, loss: 4.4919, CELoss: 2.8447 KDLoss: 1.6472 
2022-03-10 09:59:26 - train: epoch 0004, iter [02100, 05004], lr: 0.100000, loss: 4.1390, CELoss: 2.6161 KDLoss: 1.5229 
2022-03-10 10:00:00 - train: epoch 0004, iter [02200, 05004], lr: 0.100000, loss: 4.4229, CELoss: 2.8162 KDLoss: 1.6066 
2022-03-10 10:00:33 - train: epoch 0004, iter [02300, 05004], lr: 0.100000, loss: 3.9575, CELoss: 2.4586 KDLoss: 1.4989 
2022-03-10 10:01:07 - train: epoch 0004, iter [02400, 05004], lr: 0.100000, loss: 4.0737, CELoss: 2.5473 KDLoss: 1.5264 
2022-03-10 10:01:41 - train: epoch 0004, iter [02500, 05004], lr: 0.100000, loss: 4.0933, CELoss: 2.5610 KDLoss: 1.5323 
2022-03-10 10:02:15 - train: epoch 0004, iter [02600, 05004], lr: 0.100000, loss: 4.2945, CELoss: 2.7253 KDLoss: 1.5692 
2022-03-10 10:02:47 - train: epoch 0004, iter [02700, 05004], lr: 0.100000, loss: 4.0810, CELoss: 2.5454 KDLoss: 1.5356 
2022-03-10 10:03:20 - train: epoch 0004, iter [02800, 05004], lr: 0.100000, loss: 4.1999, CELoss: 2.6409 KDLoss: 1.5590 
2022-03-10 10:03:55 - train: epoch 0004, iter [02900, 05004], lr: 0.100000, loss: 4.2253, CELoss: 2.6153 KDLoss: 1.6101 
2022-03-10 10:04:28 - train: epoch 0004, iter [03000, 05004], lr: 0.100000, loss: 4.4672, CELoss: 2.7941 KDLoss: 1.6732 
2022-03-10 10:05:01 - train: epoch 0004, iter [03100, 05004], lr: 0.100000, loss: 4.3311, CELoss: 2.7532 KDLoss: 1.5779 
2022-03-10 10:05:35 - train: epoch 0004, iter [03200, 05004], lr: 0.100000, loss: 4.3158, CELoss: 2.7290 KDLoss: 1.5868 
2022-03-10 10:06:09 - train: epoch 0004, iter [03300, 05004], lr: 0.100000, loss: 4.0876, CELoss: 2.5904 KDLoss: 1.4972 
2022-03-10 10:06:42 - train: epoch 0004, iter [03400, 05004], lr: 0.100000, loss: 4.1108, CELoss: 2.5725 KDLoss: 1.5383 
2022-03-10 10:07:16 - train: epoch 0004, iter [03500, 05004], lr: 0.100000, loss: 4.1481, CELoss: 2.6953 KDLoss: 1.4528 
2022-03-10 10:07:50 - train: epoch 0004, iter [03600, 05004], lr: 0.100000, loss: 4.2741, CELoss: 2.7117 KDLoss: 1.5624 
2022-03-10 10:08:22 - train: epoch 0004, iter [03700, 05004], lr: 0.100000, loss: 4.4671, CELoss: 2.7806 KDLoss: 1.6865 
2022-03-10 10:08:56 - train: epoch 0004, iter [03800, 05004], lr: 0.100000, loss: 3.9554, CELoss: 2.4742 KDLoss: 1.4812 
2022-03-10 10:09:30 - train: epoch 0004, iter [03900, 05004], lr: 0.100000, loss: 4.1202, CELoss: 2.5331 KDLoss: 1.5871 
2022-03-10 10:10:03 - train: epoch 0004, iter [04000, 05004], lr: 0.100000, loss: 3.9863, CELoss: 2.5007 KDLoss: 1.4856 
2022-03-10 10:10:36 - train: epoch 0004, iter [04100, 05004], lr: 0.100000, loss: 4.1103, CELoss: 2.5883 KDLoss: 1.5220 
2022-03-10 10:11:10 - train: epoch 0004, iter [04200, 05004], lr: 0.100000, loss: 4.1523, CELoss: 2.6223 KDLoss: 1.5300 
2022-03-10 10:11:43 - train: epoch 0004, iter [04300, 05004], lr: 0.100000, loss: 4.2193, CELoss: 2.6381 KDLoss: 1.5812 
2022-03-10 10:12:15 - train: epoch 0004, iter [04400, 05004], lr: 0.100000, loss: 4.1344, CELoss: 2.5281 KDLoss: 1.6063 
2022-03-10 10:12:50 - train: epoch 0004, iter [04500, 05004], lr: 0.100000, loss: 3.7336, CELoss: 2.2876 KDLoss: 1.4461 
2022-03-10 10:13:23 - train: epoch 0004, iter [04600, 05004], lr: 0.100000, loss: 4.0802, CELoss: 2.5253 KDLoss: 1.5548 
2022-03-10 10:13:57 - train: epoch 0004, iter [04700, 05004], lr: 0.100000, loss: 4.0579, CELoss: 2.5186 KDLoss: 1.5393 
2022-03-10 10:14:29 - train: epoch 0004, iter [04800, 05004], lr: 0.100000, loss: 3.6895, CELoss: 2.2925 KDLoss: 1.3969 
2022-03-10 10:15:03 - train: epoch 0004, iter [04900, 05004], lr: 0.100000, loss: 4.3465, CELoss: 2.7458 KDLoss: 1.6007 
2022-03-10 10:15:35 - train: epoch 0004, iter [05000, 05004], lr: 0.100000, loss: 4.1998, CELoss: 2.6018 KDLoss: 1.5980 
2022-03-10 10:15:36 - train: epoch 004, train_loss: 4.3045
2022-03-10 10:18:04 - eval: epoch: 004, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 46.586%, stu_acc5: 72.590%, stu_test_loss: 2.3618
2022-03-10 10:18:04 - until epoch: 004, tea_best_acc1: 73.950%, stu_best_acc1: 46.586%
2022-03-10 10:18:04 - epoch 005 lr: 0.1
2022-03-10 10:18:42 - train: epoch 0005, iter [00100, 05004], lr: 0.100000, loss: 4.5108, CELoss: 2.8291 KDLoss: 1.6817 
2022-03-10 10:19:16 - train: epoch 0005, iter [00200, 05004], lr: 0.100000, loss: 4.2553, CELoss: 2.6350 KDLoss: 1.6203 
2022-03-10 10:19:50 - train: epoch 0005, iter [00300, 05004], lr: 0.100000, loss: 4.4769, CELoss: 2.8419 KDLoss: 1.6350 
2022-03-10 10:20:23 - train: epoch 0005, iter [00400, 05004], lr: 0.100000, loss: 3.8847, CELoss: 2.4591 KDLoss: 1.4256 
2022-03-10 10:20:56 - train: epoch 0005, iter [00500, 05004], lr: 0.100000, loss: 3.9749, CELoss: 2.5107 KDLoss: 1.4642 
2022-03-10 10:21:29 - train: epoch 0005, iter [00600, 05004], lr: 0.100000, loss: 4.2200, CELoss: 2.7120 KDLoss: 1.5080 
2022-03-10 10:22:04 - train: epoch 0005, iter [00700, 05004], lr: 0.100000, loss: 4.2458, CELoss: 2.7265 KDLoss: 1.5193 
2022-03-10 10:22:37 - train: epoch 0005, iter [00800, 05004], lr: 0.100000, loss: 4.5790, CELoss: 2.9496 KDLoss: 1.6294 
2022-03-10 10:23:10 - train: epoch 0005, iter [00900, 05004], lr: 0.100000, loss: 4.0979, CELoss: 2.5705 KDLoss: 1.5273 
2022-03-10 10:23:45 - train: epoch 0005, iter [01000, 05004], lr: 0.100000, loss: 4.3549, CELoss: 2.7499 KDLoss: 1.6050 
2022-03-10 10:24:18 - train: epoch 0005, iter [01100, 05004], lr: 0.100000, loss: 4.2542, CELoss: 2.6495 KDLoss: 1.6048 
2022-03-10 10:24:52 - train: epoch 0005, iter [01200, 05004], lr: 0.100000, loss: 4.4241, CELoss: 2.7456 KDLoss: 1.6785 
2022-03-10 10:25:25 - train: epoch 0005, iter [01300, 05004], lr: 0.100000, loss: 3.7842, CELoss: 2.4198 KDLoss: 1.3644 
2022-03-10 10:25:59 - train: epoch 0005, iter [01400, 05004], lr: 0.100000, loss: 4.1442, CELoss: 2.6276 KDLoss: 1.5166 
2022-03-10 10:26:32 - train: epoch 0005, iter [01500, 05004], lr: 0.100000, loss: 3.9710, CELoss: 2.4491 KDLoss: 1.5219 
2022-03-10 10:27:05 - train: epoch 0005, iter [01600, 05004], lr: 0.100000, loss: 3.7028, CELoss: 2.3338 KDLoss: 1.3690 
2022-03-10 10:27:39 - train: epoch 0005, iter [01700, 05004], lr: 0.100000, loss: 4.4281, CELoss: 2.7903 KDLoss: 1.6378 
2022-03-10 10:28:14 - train: epoch 0005, iter [01800, 05004], lr: 0.100000, loss: 3.9558, CELoss: 2.4438 KDLoss: 1.5120 
2022-03-10 10:28:47 - train: epoch 0005, iter [01900, 05004], lr: 0.100000, loss: 4.0025, CELoss: 2.4858 KDLoss: 1.5167 
2022-03-10 10:29:20 - train: epoch 0005, iter [02000, 05004], lr: 0.100000, loss: 4.0745, CELoss: 2.5744 KDLoss: 1.5001 
2022-03-10 10:29:54 - train: epoch 0005, iter [02100, 05004], lr: 0.100000, loss: 4.1833, CELoss: 2.6461 KDLoss: 1.5371 
2022-03-10 10:30:28 - train: epoch 0005, iter [02200, 05004], lr: 0.100000, loss: 4.0466, CELoss: 2.4755 KDLoss: 1.5711 
2022-03-10 10:31:01 - train: epoch 0005, iter [02300, 05004], lr: 0.100000, loss: 3.7043, CELoss: 2.2603 KDLoss: 1.4440 
2022-03-10 10:31:34 - train: epoch 0005, iter [02400, 05004], lr: 0.100000, loss: 4.1902, CELoss: 2.6239 KDLoss: 1.5663 
2022-03-10 10:32:07 - train: epoch 0005, iter [02500, 05004], lr: 0.100000, loss: 4.1779, CELoss: 2.6517 KDLoss: 1.5262 
2022-03-10 10:32:42 - train: epoch 0005, iter [02600, 05004], lr: 0.100000, loss: 4.0228, CELoss: 2.4674 KDLoss: 1.5554 
2022-03-10 10:33:16 - train: epoch 0005, iter [02700, 05004], lr: 0.100000, loss: 4.3374, CELoss: 2.7598 KDLoss: 1.5776 
2022-03-10 10:33:50 - train: epoch 0005, iter [02800, 05004], lr: 0.100000, loss: 4.1062, CELoss: 2.5665 KDLoss: 1.5397 
2022-03-10 10:34:22 - train: epoch 0005, iter [02900, 05004], lr: 0.100000, loss: 3.9830, CELoss: 2.6072 KDLoss: 1.3758 
2022-03-10 10:34:56 - train: epoch 0005, iter [03000, 05004], lr: 0.100000, loss: 4.1254, CELoss: 2.6302 KDLoss: 1.4952 
2022-03-10 10:35:29 - train: epoch 0005, iter [03100, 05004], lr: 0.100000, loss: 4.2482, CELoss: 2.6584 KDLoss: 1.5898 
2022-03-10 10:36:02 - train: epoch 0005, iter [03200, 05004], lr: 0.100000, loss: 4.2039, CELoss: 2.6642 KDLoss: 1.5397 
2022-03-10 10:36:36 - train: epoch 0005, iter [03300, 05004], lr: 0.100000, loss: 3.9435, CELoss: 2.4879 KDLoss: 1.4556 
2022-03-10 10:37:10 - train: epoch 0005, iter [03400, 05004], lr: 0.100000, loss: 4.1239, CELoss: 2.6389 KDLoss: 1.4850 
2022-03-10 10:37:43 - train: epoch 0005, iter [03500, 05004], lr: 0.100000, loss: 4.2099, CELoss: 2.7398 KDLoss: 1.4701 
2022-03-10 10:38:17 - train: epoch 0005, iter [03600, 05004], lr: 0.100000, loss: 4.2371, CELoss: 2.6920 KDLoss: 1.5451 
2022-03-10 10:38:50 - train: epoch 0005, iter [03700, 05004], lr: 0.100000, loss: 3.9860, CELoss: 2.4960 KDLoss: 1.4900 
2022-03-10 10:39:23 - train: epoch 0005, iter [03800, 05004], lr: 0.100000, loss: 4.1100, CELoss: 2.6216 KDLoss: 1.4884 
2022-03-10 10:39:57 - train: epoch 0005, iter [03900, 05004], lr: 0.100000, loss: 4.1876, CELoss: 2.6524 KDLoss: 1.5352 
2022-03-10 10:40:29 - train: epoch 0005, iter [04000, 05004], lr: 0.100000, loss: 4.0468, CELoss: 2.5930 KDLoss: 1.4537 
2022-03-10 10:41:04 - train: epoch 0005, iter [04100, 05004], lr: 0.100000, loss: 4.1343, CELoss: 2.6220 KDLoss: 1.5123 
2022-03-10 10:41:36 - train: epoch 0005, iter [04200, 05004], lr: 0.100000, loss: 3.9504, CELoss: 2.5946 KDLoss: 1.3559 
2022-03-10 10:42:10 - train: epoch 0005, iter [04300, 05004], lr: 0.100000, loss: 4.2075, CELoss: 2.6905 KDLoss: 1.5169 
2022-03-10 10:42:43 - train: epoch 0005, iter [04400, 05004], lr: 0.100000, loss: 4.3089, CELoss: 2.7266 KDLoss: 1.5823 
2022-03-10 10:43:17 - train: epoch 0005, iter [04500, 05004], lr: 0.100000, loss: 4.1314, CELoss: 2.6440 KDLoss: 1.4874 
2022-03-10 10:43:50 - train: epoch 0005, iter [04600, 05004], lr: 0.100000, loss: 4.0749, CELoss: 2.5234 KDLoss: 1.5515 
2022-03-10 10:44:23 - train: epoch 0005, iter [04700, 05004], lr: 0.100000, loss: 3.8247, CELoss: 2.4036 KDLoss: 1.4210 
2022-03-10 10:44:57 - train: epoch 0005, iter [04800, 05004], lr: 0.100000, loss: 3.7505, CELoss: 2.4591 KDLoss: 1.2914 
2022-03-10 10:45:31 - train: epoch 0005, iter [04900, 05004], lr: 0.100000, loss: 4.4320, CELoss: 2.8055 KDLoss: 1.6265 
2022-03-10 10:46:02 - train: epoch 0005, iter [05000, 05004], lr: 0.100000, loss: 3.8037, CELoss: 2.5115 KDLoss: 1.2922 
2022-03-10 10:46:03 - train: epoch 005, train_loss: 4.1110
2022-03-10 10:48:31 - eval: epoch: 005, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 46.890%, stu_acc5: 73.080%, stu_test_loss: 2.3305
2022-03-10 10:48:32 - until epoch: 005, tea_best_acc1: 73.950%, stu_best_acc1: 46.890%
2022-03-10 10:48:32 - epoch 006 lr: 0.1
2022-03-10 10:49:10 - train: epoch 0006, iter [00100, 05004], lr: 0.100000, loss: 3.5645, CELoss: 2.3440 KDLoss: 1.2205 
2022-03-10 10:49:44 - train: epoch 0006, iter [00200, 05004], lr: 0.100000, loss: 3.8860, CELoss: 2.5294 KDLoss: 1.3565 
2022-03-10 10:50:18 - train: epoch 0006, iter [00300, 05004], lr: 0.100000, loss: 3.9176, CELoss: 2.4234 KDLoss: 1.4943 
2022-03-10 10:50:50 - train: epoch 0006, iter [00400, 05004], lr: 0.100000, loss: 4.1412, CELoss: 2.6196 KDLoss: 1.5216 
2022-03-10 10:51:24 - train: epoch 0006, iter [00500, 05004], lr: 0.100000, loss: 3.6712, CELoss: 2.2978 KDLoss: 1.3734 
2022-03-10 10:51:57 - train: epoch 0006, iter [00600, 05004], lr: 0.100000, loss: 3.8829, CELoss: 2.4178 KDLoss: 1.4650 
2022-03-10 10:52:30 - train: epoch 0006, iter [00700, 05004], lr: 0.100000, loss: 4.2544, CELoss: 2.7504 KDLoss: 1.5041 
2022-03-10 10:53:04 - train: epoch 0006, iter [00800, 05004], lr: 0.100000, loss: 4.0085, CELoss: 2.4993 KDLoss: 1.5092 
2022-03-10 10:53:37 - train: epoch 0006, iter [00900, 05004], lr: 0.100000, loss: 3.8015, CELoss: 2.4055 KDLoss: 1.3959 
2022-03-10 10:54:11 - train: epoch 0006, iter [01000, 05004], lr: 0.100000, loss: 3.8065, CELoss: 2.4286 KDLoss: 1.3779 
2022-03-10 10:54:43 - train: epoch 0006, iter [01100, 05004], lr: 0.100000, loss: 4.2658, CELoss: 2.6765 KDLoss: 1.5893 
2022-03-10 10:55:17 - train: epoch 0006, iter [01200, 05004], lr: 0.100000, loss: 4.0652, CELoss: 2.6032 KDLoss: 1.4620 
2022-03-10 10:55:50 - train: epoch 0006, iter [01300, 05004], lr: 0.100000, loss: 4.1004, CELoss: 2.6058 KDLoss: 1.4947 
2022-03-10 10:56:24 - train: epoch 0006, iter [01400, 05004], lr: 0.100000, loss: 4.0129, CELoss: 2.6038 KDLoss: 1.4090 
2022-03-10 10:56:57 - train: epoch 0006, iter [01500, 05004], lr: 0.100000, loss: 4.3070, CELoss: 2.7371 KDLoss: 1.5699 
2022-03-10 10:57:30 - train: epoch 0006, iter [01600, 05004], lr: 0.100000, loss: 3.9254, CELoss: 2.4446 KDLoss: 1.4808 
2022-03-10 10:58:04 - train: epoch 0006, iter [01700, 05004], lr: 0.100000, loss: 4.0945, CELoss: 2.6878 KDLoss: 1.4067 
2022-03-10 10:58:37 - train: epoch 0006, iter [01800, 05004], lr: 0.100000, loss: 4.0230, CELoss: 2.5511 KDLoss: 1.4719 
2022-03-10 10:59:11 - train: epoch 0006, iter [01900, 05004], lr: 0.100000, loss: 3.9100, CELoss: 2.4908 KDLoss: 1.4192 
2022-03-10 10:59:44 - train: epoch 0006, iter [02000, 05004], lr: 0.100000, loss: 4.1364, CELoss: 2.6727 KDLoss: 1.4636 
2022-03-10 11:00:18 - train: epoch 0006, iter [02100, 05004], lr: 0.100000, loss: 3.9797, CELoss: 2.5411 KDLoss: 1.4386 
2022-03-10 11:00:50 - train: epoch 0006, iter [02200, 05004], lr: 0.100000, loss: 3.6231, CELoss: 2.2635 KDLoss: 1.3595 
2022-03-10 11:01:24 - train: epoch 0006, iter [02300, 05004], lr: 0.100000, loss: 3.9068, CELoss: 2.5020 KDLoss: 1.4048 
2022-03-10 11:01:57 - train: epoch 0006, iter [02400, 05004], lr: 0.100000, loss: 3.9687, CELoss: 2.4898 KDLoss: 1.4789 
2022-03-10 11:02:30 - train: epoch 0006, iter [02500, 05004], lr: 0.100000, loss: 3.9875, CELoss: 2.5053 KDLoss: 1.4823 
2022-03-10 11:03:04 - train: epoch 0006, iter [02600, 05004], lr: 0.100000, loss: 4.0593, CELoss: 2.6586 KDLoss: 1.4007 
2022-03-10 11:03:37 - train: epoch 0006, iter [02700, 05004], lr: 0.100000, loss: 3.9648, CELoss: 2.4980 KDLoss: 1.4668 
2022-03-10 11:04:11 - train: epoch 0006, iter [02800, 05004], lr: 0.100000, loss: 3.7353, CELoss: 2.3122 KDLoss: 1.4231 
2022-03-10 11:04:44 - train: epoch 0006, iter [02900, 05004], lr: 0.100000, loss: 4.1118, CELoss: 2.6301 KDLoss: 1.4817 
2022-03-10 11:05:17 - train: epoch 0006, iter [03000, 05004], lr: 0.100000, loss: 4.0468, CELoss: 2.5570 KDLoss: 1.4898 
2022-03-10 11:05:51 - train: epoch 0006, iter [03100, 05004], lr: 0.100000, loss: 3.8437, CELoss: 2.4097 KDLoss: 1.4340 
2022-03-10 11:06:24 - train: epoch 0006, iter [03200, 05004], lr: 0.100000, loss: 3.8094, CELoss: 2.4236 KDLoss: 1.3858 
2022-03-10 11:06:57 - train: epoch 0006, iter [03300, 05004], lr: 0.100000, loss: 4.0673, CELoss: 2.5075 KDLoss: 1.5598 
2022-03-10 11:07:31 - train: epoch 0006, iter [03400, 05004], lr: 0.100000, loss: 3.9766, CELoss: 2.4951 KDLoss: 1.4815 
2022-03-10 11:08:03 - train: epoch 0006, iter [03500, 05004], lr: 0.100000, loss: 4.0744, CELoss: 2.5774 KDLoss: 1.4970 
2022-03-10 11:08:37 - train: epoch 0006, iter [03600, 05004], lr: 0.100000, loss: 3.9608, CELoss: 2.5003 KDLoss: 1.4606 
2022-03-10 11:09:10 - train: epoch 0006, iter [03700, 05004], lr: 0.100000, loss: 3.6549, CELoss: 2.3290 KDLoss: 1.3259 
2022-03-10 11:09:44 - train: epoch 0006, iter [03800, 05004], lr: 0.100000, loss: 3.5335, CELoss: 2.2972 KDLoss: 1.2362 
2022-03-10 11:10:18 - train: epoch 0006, iter [03900, 05004], lr: 0.100000, loss: 4.0877, CELoss: 2.6122 KDLoss: 1.4754 
2022-03-10 11:10:51 - train: epoch 0006, iter [04000, 05004], lr: 0.100000, loss: 3.8557, CELoss: 2.4258 KDLoss: 1.4299 
2022-03-10 11:11:25 - train: epoch 0006, iter [04100, 05004], lr: 0.100000, loss: 3.8233, CELoss: 2.4651 KDLoss: 1.3582 
2022-03-10 11:11:57 - train: epoch 0006, iter [04200, 05004], lr: 0.100000, loss: 3.5577, CELoss: 2.2539 KDLoss: 1.3038 
2022-03-10 11:12:31 - train: epoch 0006, iter [04300, 05004], lr: 0.100000, loss: 4.2254, CELoss: 2.6553 KDLoss: 1.5701 
2022-03-10 11:13:05 - train: epoch 0006, iter [04400, 05004], lr: 0.100000, loss: 4.0817, CELoss: 2.5400 KDLoss: 1.5417 
2022-03-10 11:13:38 - train: epoch 0006, iter [04500, 05004], lr: 0.100000, loss: 3.8822, CELoss: 2.5574 KDLoss: 1.3248 
2022-03-10 11:14:11 - train: epoch 0006, iter [04600, 05004], lr: 0.100000, loss: 3.7929, CELoss: 2.4075 KDLoss: 1.3854 
2022-03-10 11:14:45 - train: epoch 0006, iter [04700, 05004], lr: 0.100000, loss: 3.7953, CELoss: 2.4494 KDLoss: 1.3459 
2022-03-10 11:15:18 - train: epoch 0006, iter [04800, 05004], lr: 0.100000, loss: 3.5684, CELoss: 2.3181 KDLoss: 1.2504 
2022-03-10 11:15:52 - train: epoch 0006, iter [04900, 05004], lr: 0.100000, loss: 3.7861, CELoss: 2.4768 KDLoss: 1.3092 
2022-03-10 11:16:24 - train: epoch 0006, iter [05000, 05004], lr: 0.100000, loss: 3.6461, CELoss: 2.3117 KDLoss: 1.3344 
2022-03-10 11:16:25 - train: epoch 006, train_loss: 3.9871
2022-03-10 11:18:54 - eval: epoch: 006, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 47.318%, stu_acc5: 73.590%, stu_test_loss: 2.3040
2022-03-10 11:18:55 - until epoch: 006, tea_best_acc1: 73.950%, stu_best_acc1: 47.318%
2022-03-10 11:18:55 - epoch 007 lr: 0.1
2022-03-10 11:19:33 - train: epoch 0007, iter [00100, 05004], lr: 0.100000, loss: 3.6965, CELoss: 2.3091 KDLoss: 1.3873 
2022-03-10 11:20:07 - train: epoch 0007, iter [00200, 05004], lr: 0.100000, loss: 3.8667, CELoss: 2.4763 KDLoss: 1.3904 
2022-03-10 11:20:41 - train: epoch 0007, iter [00300, 05004], lr: 0.100000, loss: 4.2602, CELoss: 2.7237 KDLoss: 1.5366 
2022-03-10 11:21:15 - train: epoch 0007, iter [00400, 05004], lr: 0.100000, loss: 3.8060, CELoss: 2.4680 KDLoss: 1.3380 
2022-03-10 11:21:48 - train: epoch 0007, iter [00500, 05004], lr: 0.100000, loss: 3.6517, CELoss: 2.3109 KDLoss: 1.3408 
2022-03-10 11:22:22 - train: epoch 0007, iter [00600, 05004], lr: 0.100000, loss: 4.2444, CELoss: 2.7430 KDLoss: 1.5014 
2022-03-10 11:22:55 - train: epoch 0007, iter [00700, 05004], lr: 0.100000, loss: 3.8108, CELoss: 2.4461 KDLoss: 1.3648 
2022-03-10 11:23:28 - train: epoch 0007, iter [00800, 05004], lr: 0.100000, loss: 3.9141, CELoss: 2.5223 KDLoss: 1.3917 
2022-03-10 11:24:01 - train: epoch 0007, iter [00900, 05004], lr: 0.100000, loss: 3.9588, CELoss: 2.5411 KDLoss: 1.4178 
2022-03-10 11:24:34 - train: epoch 0007, iter [01000, 05004], lr: 0.100000, loss: 3.7121, CELoss: 2.4469 KDLoss: 1.2652 
2022-03-10 11:25:08 - train: epoch 0007, iter [01100, 05004], lr: 0.100000, loss: 4.0320, CELoss: 2.6043 KDLoss: 1.4277 
2022-03-10 11:25:42 - train: epoch 0007, iter [01200, 05004], lr: 0.100000, loss: 3.9220, CELoss: 2.5008 KDLoss: 1.4213 
2022-03-10 11:26:15 - train: epoch 0007, iter [01300, 05004], lr: 0.100000, loss: 3.4937, CELoss: 2.1801 KDLoss: 1.3136 
2022-03-10 11:26:49 - train: epoch 0007, iter [01400, 05004], lr: 0.100000, loss: 3.9940, CELoss: 2.5473 KDLoss: 1.4466 
2022-03-10 11:27:22 - train: epoch 0007, iter [01500, 05004], lr: 0.100000, loss: 3.8573, CELoss: 2.5346 KDLoss: 1.3227 
2022-03-10 11:27:56 - train: epoch 0007, iter [01600, 05004], lr: 0.100000, loss: 3.8224, CELoss: 2.4282 KDLoss: 1.3942 
2022-03-10 11:28:30 - train: epoch 0007, iter [01700, 05004], lr: 0.100000, loss: 3.7778, CELoss: 2.4064 KDLoss: 1.3715 
2022-03-10 11:29:03 - train: epoch 0007, iter [01800, 05004], lr: 0.100000, loss: 3.9053, CELoss: 2.5653 KDLoss: 1.3400 
2022-03-10 11:29:36 - train: epoch 0007, iter [01900, 05004], lr: 0.100000, loss: 3.7743, CELoss: 2.4466 KDLoss: 1.3277 
2022-03-10 11:30:11 - train: epoch 0007, iter [02000, 05004], lr: 0.100000, loss: 3.4469, CELoss: 2.1312 KDLoss: 1.3158 
2022-03-10 11:30:44 - train: epoch 0007, iter [02100, 05004], lr: 0.100000, loss: 4.1274, CELoss: 2.6594 KDLoss: 1.4680 
2022-03-10 11:31:17 - train: epoch 0007, iter [02200, 05004], lr: 0.100000, loss: 3.6816, CELoss: 2.3583 KDLoss: 1.3233 
2022-03-10 11:31:51 - train: epoch 0007, iter [02300, 05004], lr: 0.100000, loss: 4.2660, CELoss: 2.7416 KDLoss: 1.5245 
2022-03-10 11:32:24 - train: epoch 0007, iter [02400, 05004], lr: 0.100000, loss: 4.2276, CELoss: 2.6948 KDLoss: 1.5328 
2022-03-10 11:32:58 - train: epoch 0007, iter [02500, 05004], lr: 0.100000, loss: 3.9697, CELoss: 2.5243 KDLoss: 1.4453 
2022-03-10 11:33:31 - train: epoch 0007, iter [02600, 05004], lr: 0.100000, loss: 3.8135, CELoss: 2.4214 KDLoss: 1.3921 
2022-03-10 11:34:04 - train: epoch 0007, iter [02700, 05004], lr: 0.100000, loss: 3.6325, CELoss: 2.3237 KDLoss: 1.3088 
2022-03-10 11:34:37 - train: epoch 0007, iter [02800, 05004], lr: 0.100000, loss: 3.7651, CELoss: 2.4166 KDLoss: 1.3485 
2022-03-10 11:35:12 - train: epoch 0007, iter [02900, 05004], lr: 0.100000, loss: 3.8120, CELoss: 2.3701 KDLoss: 1.4419 
2022-03-10 11:35:45 - train: epoch 0007, iter [03000, 05004], lr: 0.100000, loss: 4.1397, CELoss: 2.6452 KDLoss: 1.4945 
2022-03-10 11:36:19 - train: epoch 0007, iter [03100, 05004], lr: 0.100000, loss: 3.5930, CELoss: 2.3100 KDLoss: 1.2830 
2022-03-10 11:36:50 - train: epoch 0007, iter [03200, 05004], lr: 0.100000, loss: 3.7133, CELoss: 2.3391 KDLoss: 1.3742 
2022-03-10 11:37:25 - train: epoch 0007, iter [03300, 05004], lr: 0.100000, loss: 4.2593, CELoss: 2.6679 KDLoss: 1.5914 
2022-03-10 11:37:58 - train: epoch 0007, iter [03400, 05004], lr: 0.100000, loss: 4.2361, CELoss: 2.6979 KDLoss: 1.5383 
2022-03-10 11:38:32 - train: epoch 0007, iter [03500, 05004], lr: 0.100000, loss: 4.1111, CELoss: 2.5896 KDLoss: 1.5215 
2022-03-10 11:39:05 - train: epoch 0007, iter [03600, 05004], lr: 0.100000, loss: 3.9103, CELoss: 2.4340 KDLoss: 1.4763 
2022-03-10 11:39:37 - train: epoch 0007, iter [03700, 05004], lr: 0.100000, loss: 3.9202, CELoss: 2.4400 KDLoss: 1.4802 
2022-03-10 11:40:11 - train: epoch 0007, iter [03800, 05004], lr: 0.100000, loss: 4.2865, CELoss: 2.7519 KDLoss: 1.5347 
2022-03-10 11:40:45 - train: epoch 0007, iter [03900, 05004], lr: 0.100000, loss: 4.0850, CELoss: 2.5908 KDLoss: 1.4941 
2022-03-10 11:41:18 - train: epoch 0007, iter [04000, 05004], lr: 0.100000, loss: 4.1576, CELoss: 2.6790 KDLoss: 1.4786 
2022-03-10 11:41:51 - train: epoch 0007, iter [04100, 05004], lr: 0.100000, loss: 4.0000, CELoss: 2.4908 KDLoss: 1.5092 
2022-03-10 11:42:25 - train: epoch 0007, iter [04200, 05004], lr: 0.100000, loss: 3.7622, CELoss: 2.3773 KDLoss: 1.3849 
2022-03-10 11:42:58 - train: epoch 0007, iter [04300, 05004], lr: 0.100000, loss: 3.9221, CELoss: 2.5387 KDLoss: 1.3834 
2022-03-10 11:43:31 - train: epoch 0007, iter [04400, 05004], lr: 0.100000, loss: 3.7367, CELoss: 2.3512 KDLoss: 1.3855 
2022-03-10 11:44:04 - train: epoch 0007, iter [04500, 05004], lr: 0.100000, loss: 3.8415, CELoss: 2.4531 KDLoss: 1.3884 
2022-03-10 11:44:38 - train: epoch 0007, iter [04600, 05004], lr: 0.100000, loss: 3.9409, CELoss: 2.4651 KDLoss: 1.4759 
2022-03-10 11:45:12 - train: epoch 0007, iter [04700, 05004], lr: 0.100000, loss: 3.6170, CELoss: 2.2372 KDLoss: 1.3798 
2022-03-10 11:45:45 - train: epoch 0007, iter [04800, 05004], lr: 0.100000, loss: 4.1657, CELoss: 2.6598 KDLoss: 1.5059 
2022-03-10 11:46:19 - train: epoch 0007, iter [04900, 05004], lr: 0.100000, loss: 3.8007, CELoss: 2.4377 KDLoss: 1.3629 
2022-03-10 11:46:50 - train: epoch 0007, iter [05000, 05004], lr: 0.100000, loss: 3.7080, CELoss: 2.4008 KDLoss: 1.3072 
2022-03-10 11:46:51 - train: epoch 007, train_loss: 3.9063
2022-03-10 11:49:21 - eval: epoch: 007, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 47.762%, stu_acc5: 73.780%, stu_test_loss: 2.2845
2022-03-10 11:49:21 - until epoch: 007, tea_best_acc1: 73.950%, stu_best_acc1: 47.762%
2022-03-10 11:49:21 - epoch 008 lr: 0.1
2022-03-10 11:50:00 - train: epoch 0008, iter [00100, 05004], lr: 0.100000, loss: 3.7916, CELoss: 2.4362 KDLoss: 1.3555 
2022-03-10 11:50:33 - train: epoch 0008, iter [00200, 05004], lr: 0.100000, loss: 3.9877, CELoss: 2.5996 KDLoss: 1.3880 
2022-03-10 11:51:05 - train: epoch 0008, iter [00300, 05004], lr: 0.100000, loss: 3.8782, CELoss: 2.4518 KDLoss: 1.4264 
2022-03-10 11:51:39 - train: epoch 0008, iter [00400, 05004], lr: 0.100000, loss: 3.6264, CELoss: 2.3226 KDLoss: 1.3039 
2022-03-10 11:52:13 - train: epoch 0008, iter [00500, 05004], lr: 0.100000, loss: 3.5862, CELoss: 2.2902 KDLoss: 1.2961 
2022-03-10 11:52:47 - train: epoch 0008, iter [00600, 05004], lr: 0.100000, loss: 3.4922, CELoss: 2.2480 KDLoss: 1.2442 
2022-03-10 11:53:20 - train: epoch 0008, iter [00700, 05004], lr: 0.100000, loss: 4.1670, CELoss: 2.6161 KDLoss: 1.5509 
2022-03-10 11:53:54 - train: epoch 0008, iter [00800, 05004], lr: 0.100000, loss: 3.7445, CELoss: 2.3310 KDLoss: 1.4135 
2022-03-10 11:54:27 - train: epoch 0008, iter [00900, 05004], lr: 0.100000, loss: 3.8131, CELoss: 2.5030 KDLoss: 1.3101 
2022-03-10 11:55:01 - train: epoch 0008, iter [01000, 05004], lr: 0.100000, loss: 3.8675, CELoss: 2.4515 KDLoss: 1.4159 
2022-03-10 11:55:34 - train: epoch 0008, iter [01100, 05004], lr: 0.100000, loss: 3.7606, CELoss: 2.4010 KDLoss: 1.3596 
2022-03-10 11:56:08 - train: epoch 0008, iter [01200, 05004], lr: 0.100000, loss: 3.4175, CELoss: 2.1498 KDLoss: 1.2677 
2022-03-10 11:56:42 - train: epoch 0008, iter [01300, 05004], lr: 0.100000, loss: 3.9497, CELoss: 2.4766 KDLoss: 1.4731 
2022-03-10 11:57:15 - train: epoch 0008, iter [01400, 05004], lr: 0.100000, loss: 3.9692, CELoss: 2.5431 KDLoss: 1.4261 
2022-03-10 11:57:49 - train: epoch 0008, iter [01500, 05004], lr: 0.100000, loss: 4.0480, CELoss: 2.5783 KDLoss: 1.4698 
2022-03-10 11:58:23 - train: epoch 0008, iter [01600, 05004], lr: 0.100000, loss: 4.0632, CELoss: 2.5777 KDLoss: 1.4854 
2022-03-10 11:58:56 - train: epoch 0008, iter [01700, 05004], lr: 0.100000, loss: 3.7616, CELoss: 2.4398 KDLoss: 1.3218 
2022-03-10 11:59:30 - train: epoch 0008, iter [01800, 05004], lr: 0.100000, loss: 3.9386, CELoss: 2.5270 KDLoss: 1.4116 
2022-03-10 12:00:04 - train: epoch 0008, iter [01900, 05004], lr: 0.100000, loss: 3.7188, CELoss: 2.3406 KDLoss: 1.3782 
2022-03-10 12:00:38 - train: epoch 0008, iter [02000, 05004], lr: 0.100000, loss: 4.2190, CELoss: 2.7908 KDLoss: 1.4283 
2022-03-10 12:01:11 - train: epoch 0008, iter [02100, 05004], lr: 0.100000, loss: 3.8587, CELoss: 2.4515 KDLoss: 1.4072 
2022-03-10 12:01:45 - train: epoch 0008, iter [02200, 05004], lr: 0.100000, loss: 4.1015, CELoss: 2.6384 KDLoss: 1.4631 
2022-03-10 12:02:18 - train: epoch 0008, iter [02300, 05004], lr: 0.100000, loss: 3.6914, CELoss: 2.3543 KDLoss: 1.3371 
2022-03-10 12:02:51 - train: epoch 0008, iter [02400, 05004], lr: 0.100000, loss: 3.4737, CELoss: 2.2504 KDLoss: 1.2233 
2022-03-10 12:03:25 - train: epoch 0008, iter [02500, 05004], lr: 0.100000, loss: 3.8467, CELoss: 2.4440 KDLoss: 1.4027 
2022-03-10 12:03:58 - train: epoch 0008, iter [02600, 05004], lr: 0.100000, loss: 3.8312, CELoss: 2.3856 KDLoss: 1.4457 
2022-03-10 12:04:32 - train: epoch 0008, iter [02700, 05004], lr: 0.100000, loss: 4.1283, CELoss: 2.6378 KDLoss: 1.4905 
2022-03-10 12:05:06 - train: epoch 0008, iter [02800, 05004], lr: 0.100000, loss: 3.8901, CELoss: 2.5000 KDLoss: 1.3902 
2022-03-10 12:05:39 - train: epoch 0008, iter [02900, 05004], lr: 0.100000, loss: 4.0075, CELoss: 2.6192 KDLoss: 1.3883 
2022-03-10 12:06:13 - train: epoch 0008, iter [03000, 05004], lr: 0.100000, loss: 4.2274, CELoss: 2.7426 KDLoss: 1.4847 
2022-03-10 12:06:46 - train: epoch 0008, iter [03100, 05004], lr: 0.100000, loss: 3.9862, CELoss: 2.5415 KDLoss: 1.4448 
2022-03-10 12:07:21 - train: epoch 0008, iter [03200, 05004], lr: 0.100000, loss: 3.8976, CELoss: 2.5143 KDLoss: 1.3833 
2022-03-10 12:07:54 - train: epoch 0008, iter [03300, 05004], lr: 0.100000, loss: 4.0304, CELoss: 2.5827 KDLoss: 1.4476 
2022-03-10 12:08:27 - train: epoch 0008, iter [03400, 05004], lr: 0.100000, loss: 3.7809, CELoss: 2.4994 KDLoss: 1.2816 
2022-03-10 12:09:00 - train: epoch 0008, iter [03500, 05004], lr: 0.100000, loss: 3.7674, CELoss: 2.4323 KDLoss: 1.3351 
2022-03-10 12:09:35 - train: epoch 0008, iter [03600, 05004], lr: 0.100000, loss: 4.0678, CELoss: 2.6021 KDLoss: 1.4657 
2022-03-10 12:10:08 - train: epoch 0008, iter [03700, 05004], lr: 0.100000, loss: 3.6529, CELoss: 2.3661 KDLoss: 1.2868 
2022-03-10 12:10:42 - train: epoch 0008, iter [03800, 05004], lr: 0.100000, loss: 4.1536, CELoss: 2.5071 KDLoss: 1.6466 
2022-03-10 12:11:15 - train: epoch 0008, iter [03900, 05004], lr: 0.100000, loss: 3.8630, CELoss: 2.5055 KDLoss: 1.3576 
2022-03-10 12:11:49 - train: epoch 0008, iter [04000, 05004], lr: 0.100000, loss: 4.2000, CELoss: 2.6556 KDLoss: 1.5444 
2022-03-10 12:12:22 - train: epoch 0008, iter [04100, 05004], lr: 0.100000, loss: 3.7087, CELoss: 2.3609 KDLoss: 1.3478 
2022-03-10 12:12:57 - train: epoch 0008, iter [04200, 05004], lr: 0.100000, loss: 3.6208, CELoss: 2.2897 KDLoss: 1.3311 
2022-03-10 12:13:31 - train: epoch 0008, iter [04300, 05004], lr: 0.100000, loss: 3.4291, CELoss: 2.1713 KDLoss: 1.2577 
2022-03-10 12:14:04 - train: epoch 0008, iter [04400, 05004], lr: 0.100000, loss: 3.8825, CELoss: 2.4941 KDLoss: 1.3884 
2022-03-10 12:14:38 - train: epoch 0008, iter [04500, 05004], lr: 0.100000, loss: 3.7591, CELoss: 2.3806 KDLoss: 1.3785 
2022-03-10 12:15:11 - train: epoch 0008, iter [04600, 05004], lr: 0.100000, loss: 3.9920, CELoss: 2.4983 KDLoss: 1.4937 
2022-03-10 12:15:44 - train: epoch 0008, iter [04700, 05004], lr: 0.100000, loss: 3.7948, CELoss: 2.4098 KDLoss: 1.3850 
2022-03-10 12:16:18 - train: epoch 0008, iter [04800, 05004], lr: 0.100000, loss: 3.9092, CELoss: 2.4560 KDLoss: 1.4532 
2022-03-10 12:16:51 - train: epoch 0008, iter [04900, 05004], lr: 0.100000, loss: 3.6250, CELoss: 2.3300 KDLoss: 1.2950 
2022-03-10 12:17:24 - train: epoch 0008, iter [05000, 05004], lr: 0.100000, loss: 3.7842, CELoss: 2.5318 KDLoss: 1.2524 
2022-03-10 12:17:25 - train: epoch 008, train_loss: 3.8426
2022-03-10 12:19:54 - eval: epoch: 008, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 47.468%, stu_acc5: 73.168%, stu_test_loss: 2.3275
2022-03-10 12:19:55 - until epoch: 008, tea_best_acc1: 73.950%, stu_best_acc1: 47.762%
2022-03-10 12:19:55 - epoch 009 lr: 0.1
2022-03-10 12:20:33 - train: epoch 0009, iter [00100, 05004], lr: 0.100000, loss: 3.2197, CELoss: 2.0590 KDLoss: 1.1607 
2022-03-10 12:21:07 - train: epoch 0009, iter [00200, 05004], lr: 0.100000, loss: 3.9062, CELoss: 2.4819 KDLoss: 1.4242 
2022-03-10 12:21:39 - train: epoch 0009, iter [00300, 05004], lr: 0.100000, loss: 3.6836, CELoss: 2.3364 KDLoss: 1.3472 
2022-03-10 12:22:13 - train: epoch 0009, iter [00400, 05004], lr: 0.100000, loss: 3.9818, CELoss: 2.5856 KDLoss: 1.3962 
2022-03-10 12:22:46 - train: epoch 0009, iter [00500, 05004], lr: 0.100000, loss: 3.5536, CELoss: 2.2429 KDLoss: 1.3107 
2022-03-10 12:23:19 - train: epoch 0009, iter [00600, 05004], lr: 0.100000, loss: 3.7032, CELoss: 2.3618 KDLoss: 1.3414 
2022-03-10 12:23:52 - train: epoch 0009, iter [00700, 05004], lr: 0.100000, loss: 3.4766, CELoss: 2.2180 KDLoss: 1.2586 
2022-03-10 12:24:26 - train: epoch 0009, iter [00800, 05004], lr: 0.100000, loss: 3.7391, CELoss: 2.3851 KDLoss: 1.3541 
2022-03-10 12:25:00 - train: epoch 0009, iter [00900, 05004], lr: 0.100000, loss: 3.5966, CELoss: 2.2634 KDLoss: 1.3332 
2022-03-10 12:25:34 - train: epoch 0009, iter [01000, 05004], lr: 0.100000, loss: 3.4943, CELoss: 2.2801 KDLoss: 1.2141 
2022-03-10 12:26:08 - train: epoch 0009, iter [01100, 05004], lr: 0.100000, loss: 4.0387, CELoss: 2.6108 KDLoss: 1.4280 
2022-03-10 12:26:39 - train: epoch 0009, iter [01200, 05004], lr: 0.100000, loss: 3.8026, CELoss: 2.4284 KDLoss: 1.3743 
2022-03-10 12:27:13 - train: epoch 0009, iter [01300, 05004], lr: 0.100000, loss: 4.0663, CELoss: 2.6257 KDLoss: 1.4407 
2022-03-10 12:27:47 - train: epoch 0009, iter [01400, 05004], lr: 0.100000, loss: 3.3985, CELoss: 2.1444 KDLoss: 1.2541 
2022-03-10 12:28:21 - train: epoch 0009, iter [01500, 05004], lr: 0.100000, loss: 3.5588, CELoss: 2.3257 KDLoss: 1.2331 
2022-03-10 12:28:55 - train: epoch 0009, iter [01600, 05004], lr: 0.100000, loss: 3.7639, CELoss: 2.4006 KDLoss: 1.3633 
2022-03-10 12:29:27 - train: epoch 0009, iter [01700, 05004], lr: 0.100000, loss: 4.1615, CELoss: 2.6964 KDLoss: 1.4651 
2022-03-10 12:30:01 - train: epoch 0009, iter [01800, 05004], lr: 0.100000, loss: 3.7378, CELoss: 2.4324 KDLoss: 1.3055 
2022-03-10 12:30:34 - train: epoch 0009, iter [01900, 05004], lr: 0.100000, loss: 3.4417, CELoss: 2.1897 KDLoss: 1.2520 
2022-03-10 12:31:08 - train: epoch 0009, iter [02000, 05004], lr: 0.100000, loss: 3.7510, CELoss: 2.3837 KDLoss: 1.3673 
2022-03-10 12:31:42 - train: epoch 0009, iter [02100, 05004], lr: 0.100000, loss: 4.0119, CELoss: 2.6013 KDLoss: 1.4106 
2022-03-10 12:32:15 - train: epoch 0009, iter [02200, 05004], lr: 0.100000, loss: 3.7663, CELoss: 2.4484 KDLoss: 1.3179 
2022-03-10 12:32:48 - train: epoch 0009, iter [02300, 05004], lr: 0.100000, loss: 3.3808, CELoss: 2.1556 KDLoss: 1.2253 
2022-03-10 12:33:22 - train: epoch 0009, iter [02400, 05004], lr: 0.100000, loss: 3.9670, CELoss: 2.5422 KDLoss: 1.4248 
2022-03-10 12:33:56 - train: epoch 0009, iter [02500, 05004], lr: 0.100000, loss: 3.8363, CELoss: 2.4572 KDLoss: 1.3791 
2022-03-10 12:34:30 - train: epoch 0009, iter [02600, 05004], lr: 0.100000, loss: 3.6217, CELoss: 2.3074 KDLoss: 1.3143 
2022-03-10 12:35:03 - train: epoch 0009, iter [02700, 05004], lr: 0.100000, loss: 3.8181, CELoss: 2.4723 KDLoss: 1.3457 
2022-03-10 12:35:37 - train: epoch 0009, iter [02800, 05004], lr: 0.100000, loss: 3.9105, CELoss: 2.5049 KDLoss: 1.4055 
2022-03-10 12:36:10 - train: epoch 0009, iter [02900, 05004], lr: 0.100000, loss: 3.3709, CELoss: 2.1665 KDLoss: 1.2044 
2022-03-10 12:36:43 - train: epoch 0009, iter [03000, 05004], lr: 0.100000, loss: 3.4343, CELoss: 2.1573 KDLoss: 1.2770 
2022-03-10 12:37:17 - train: epoch 0009, iter [03100, 05004], lr: 0.100000, loss: 3.7031, CELoss: 2.3793 KDLoss: 1.3238 
2022-03-10 12:37:51 - train: epoch 0009, iter [03200, 05004], lr: 0.100000, loss: 3.7544, CELoss: 2.4470 KDLoss: 1.3074 
2022-03-10 12:38:24 - train: epoch 0009, iter [03300, 05004], lr: 0.100000, loss: 4.1122, CELoss: 2.6784 KDLoss: 1.4339 
2022-03-10 12:38:57 - train: epoch 0009, iter [03400, 05004], lr: 0.100000, loss: 3.9255, CELoss: 2.5041 KDLoss: 1.4214 
2022-03-10 12:39:30 - train: epoch 0009, iter [03500, 05004], lr: 0.100000, loss: 4.1257, CELoss: 2.5978 KDLoss: 1.5279 
2022-03-10 12:40:04 - train: epoch 0009, iter [03600, 05004], lr: 0.100000, loss: 3.4865, CELoss: 2.2417 KDLoss: 1.2448 
2022-03-10 12:40:36 - train: epoch 0009, iter [03700, 05004], lr: 0.100000, loss: 3.9748, CELoss: 2.5356 KDLoss: 1.4392 
2022-03-10 12:41:09 - train: epoch 0009, iter [03800, 05004], lr: 0.100000, loss: 3.9168, CELoss: 2.5457 KDLoss: 1.3711 
2022-03-10 12:41:42 - train: epoch 0009, iter [03900, 05004], lr: 0.100000, loss: 3.7698, CELoss: 2.4033 KDLoss: 1.3665 
2022-03-10 12:42:16 - train: epoch 0009, iter [04000, 05004], lr: 0.100000, loss: 4.0574, CELoss: 2.6964 KDLoss: 1.3610 
2022-03-10 12:42:48 - train: epoch 0009, iter [04100, 05004], lr: 0.100000, loss: 3.8752, CELoss: 2.4933 KDLoss: 1.3818 
2022-03-10 12:43:23 - train: epoch 0009, iter [04200, 05004], lr: 0.100000, loss: 3.5932, CELoss: 2.3612 KDLoss: 1.2321 
2022-03-10 12:43:55 - train: epoch 0009, iter [04300, 05004], lr: 0.100000, loss: 3.3290, CELoss: 2.1151 KDLoss: 1.2138 
2022-03-10 12:44:30 - train: epoch 0009, iter [04400, 05004], lr: 0.100000, loss: 3.8080, CELoss: 2.4480 KDLoss: 1.3600 
2022-03-10 12:45:02 - train: epoch 0009, iter [04500, 05004], lr: 0.100000, loss: 3.7861, CELoss: 2.4677 KDLoss: 1.3184 
2022-03-10 12:45:37 - train: epoch 0009, iter [04600, 05004], lr: 0.100000, loss: 4.1243, CELoss: 2.6394 KDLoss: 1.4849 
2022-03-10 12:46:09 - train: epoch 0009, iter [04700, 05004], lr: 0.100000, loss: 4.2393, CELoss: 2.7708 KDLoss: 1.4684 
2022-03-10 12:46:43 - train: epoch 0009, iter [04800, 05004], lr: 0.100000, loss: 3.8002, CELoss: 2.4427 KDLoss: 1.3575 
2022-03-10 12:47:16 - train: epoch 0009, iter [04900, 05004], lr: 0.100000, loss: 3.9056, CELoss: 2.4977 KDLoss: 1.4080 
2022-03-10 12:47:47 - train: epoch 0009, iter [05000, 05004], lr: 0.100000, loss: 3.6646, CELoss: 2.2930 KDLoss: 1.3716 
2022-03-10 12:47:48 - train: epoch 009, train_loss: 3.7879
2022-03-10 12:50:17 - eval: epoch: 009, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 49.420%, stu_acc5: 75.140%, stu_test_loss: 2.2024
2022-03-10 12:50:18 - until epoch: 009, tea_best_acc1: 73.950%, stu_best_acc1: 49.420%
2022-03-10 12:50:18 - epoch 010 lr: 0.1
2022-03-10 12:50:56 - train: epoch 0010, iter [00100, 05004], lr: 0.100000, loss: 3.5871, CELoss: 2.3068 KDLoss: 1.2803 
2022-03-10 12:51:29 - train: epoch 0010, iter [00200, 05004], lr: 0.100000, loss: 3.6777, CELoss: 2.3809 KDLoss: 1.2969 
2022-03-10 12:52:02 - train: epoch 0010, iter [00300, 05004], lr: 0.100000, loss: 3.8636, CELoss: 2.4918 KDLoss: 1.3718 
2022-03-10 12:52:36 - train: epoch 0010, iter [00400, 05004], lr: 0.100000, loss: 4.1670, CELoss: 2.6258 KDLoss: 1.5411 
2022-03-10 12:53:10 - train: epoch 0010, iter [00500, 05004], lr: 0.100000, loss: 3.6771, CELoss: 2.4004 KDLoss: 1.2767 
2022-03-10 12:53:43 - train: epoch 0010, iter [00600, 05004], lr: 0.100000, loss: 3.8867, CELoss: 2.5952 KDLoss: 1.2915 
2022-03-10 12:54:17 - train: epoch 0010, iter [00700, 05004], lr: 0.100000, loss: 4.1027, CELoss: 2.6876 KDLoss: 1.4151 
2022-03-10 12:54:51 - train: epoch 0010, iter [00800, 05004], lr: 0.100000, loss: 3.7413, CELoss: 2.4240 KDLoss: 1.3173 
2022-03-10 12:55:24 - train: epoch 0010, iter [00900, 05004], lr: 0.100000, loss: 3.4174, CELoss: 2.1839 KDLoss: 1.2335 
2022-03-10 12:55:58 - train: epoch 0010, iter [01000, 05004], lr: 0.100000, loss: 3.4064, CELoss: 2.1437 KDLoss: 1.2627 
2022-03-10 12:56:31 - train: epoch 0010, iter [01100, 05004], lr: 0.100000, loss: 3.7300, CELoss: 2.3585 KDLoss: 1.3715 
2022-03-10 12:57:05 - train: epoch 0010, iter [01200, 05004], lr: 0.100000, loss: 3.9555, CELoss: 2.5746 KDLoss: 1.3808 
2022-03-10 12:57:38 - train: epoch 0010, iter [01300, 05004], lr: 0.100000, loss: 3.5431, CELoss: 2.2692 KDLoss: 1.2739 
2022-03-10 12:58:12 - train: epoch 0010, iter [01400, 05004], lr: 0.100000, loss: 3.8543, CELoss: 2.5249 KDLoss: 1.3294 
2022-03-10 12:58:45 - train: epoch 0010, iter [01500, 05004], lr: 0.100000, loss: 3.4402, CELoss: 2.1488 KDLoss: 1.2914 
2022-03-10 12:59:19 - train: epoch 0010, iter [01600, 05004], lr: 0.100000, loss: 3.8614, CELoss: 2.4872 KDLoss: 1.3742 
2022-03-10 12:59:52 - train: epoch 0010, iter [01700, 05004], lr: 0.100000, loss: 4.1051, CELoss: 2.6423 KDLoss: 1.4628 
2022-03-10 13:00:25 - train: epoch 0010, iter [01800, 05004], lr: 0.100000, loss: 3.5461, CELoss: 2.2845 KDLoss: 1.2615 
2022-03-10 13:00:58 - train: epoch 0010, iter [01900, 05004], lr: 0.100000, loss: 3.7007, CELoss: 2.4175 KDLoss: 1.2832 
2022-03-10 13:01:32 - train: epoch 0010, iter [02000, 05004], lr: 0.100000, loss: 3.8417, CELoss: 2.4748 KDLoss: 1.3669 
2022-03-10 13:02:06 - train: epoch 0010, iter [02100, 05004], lr: 0.100000, loss: 3.5510, CELoss: 2.2618 KDLoss: 1.2892 
2022-03-10 13:02:40 - train: epoch 0010, iter [02200, 05004], lr: 0.100000, loss: 3.8107, CELoss: 2.4596 KDLoss: 1.3511 
2022-03-10 13:03:13 - train: epoch 0010, iter [02300, 05004], lr: 0.100000, loss: 3.8880, CELoss: 2.5707 KDLoss: 1.3173 
2022-03-10 13:03:47 - train: epoch 0010, iter [02400, 05004], lr: 0.100000, loss: 4.2449, CELoss: 2.7654 KDLoss: 1.4795 
2022-03-10 13:04:20 - train: epoch 0010, iter [02500, 05004], lr: 0.100000, loss: 3.8222, CELoss: 2.4720 KDLoss: 1.3503 
2022-03-10 13:04:54 - train: epoch 0010, iter [02600, 05004], lr: 0.100000, loss: 3.7712, CELoss: 2.4053 KDLoss: 1.3659 
2022-03-10 13:05:27 - train: epoch 0010, iter [02700, 05004], lr: 0.100000, loss: 3.6479, CELoss: 2.3178 KDLoss: 1.3301 
2022-03-10 13:06:01 - train: epoch 0010, iter [02800, 05004], lr: 0.100000, loss: 3.9965, CELoss: 2.5076 KDLoss: 1.4890 
2022-03-10 13:06:34 - train: epoch 0010, iter [02900, 05004], lr: 0.100000, loss: 3.9270, CELoss: 2.5045 KDLoss: 1.4225 
2022-03-10 13:07:08 - train: epoch 0010, iter [03000, 05004], lr: 0.100000, loss: 3.5396, CELoss: 2.2924 KDLoss: 1.2472 
2022-03-10 13:07:40 - train: epoch 0010, iter [03100, 05004], lr: 0.100000, loss: 4.1667, CELoss: 2.7404 KDLoss: 1.4263 
2022-03-10 13:08:14 - train: epoch 0010, iter [03200, 05004], lr: 0.100000, loss: 3.7442, CELoss: 2.4182 KDLoss: 1.3260 
2022-03-10 13:08:47 - train: epoch 0010, iter [03300, 05004], lr: 0.100000, loss: 3.8781, CELoss: 2.5547 KDLoss: 1.3234 
2022-03-10 13:09:21 - train: epoch 0010, iter [03400, 05004], lr: 0.100000, loss: 3.9633, CELoss: 2.5961 KDLoss: 1.3672 
2022-03-10 13:09:55 - train: epoch 0010, iter [03500, 05004], lr: 0.100000, loss: 4.0104, CELoss: 2.6162 KDLoss: 1.3942 
2022-03-10 13:10:28 - train: epoch 0010, iter [03600, 05004], lr: 0.100000, loss: 4.1638, CELoss: 2.6265 KDLoss: 1.5374 
2022-03-10 13:11:02 - train: epoch 0010, iter [03700, 05004], lr: 0.100000, loss: 4.1119, CELoss: 2.6452 KDLoss: 1.4668 
2022-03-10 13:11:35 - train: epoch 0010, iter [03800, 05004], lr: 0.100000, loss: 3.8740, CELoss: 2.4918 KDLoss: 1.3822 
2022-03-10 13:12:08 - train: epoch 0010, iter [03900, 05004], lr: 0.100000, loss: 3.4567, CELoss: 2.2308 KDLoss: 1.2259 
2022-03-10 13:12:42 - train: epoch 0010, iter [04000, 05004], lr: 0.100000, loss: 3.5002, CELoss: 2.2352 KDLoss: 1.2650 
2022-03-10 13:13:15 - train: epoch 0010, iter [04100, 05004], lr: 0.100000, loss: 3.4082, CELoss: 2.1937 KDLoss: 1.2145 
2022-03-10 13:13:47 - train: epoch 0010, iter [04200, 05004], lr: 0.100000, loss: 3.8761, CELoss: 2.4472 KDLoss: 1.4289 
2022-03-10 13:14:21 - train: epoch 0010, iter [04300, 05004], lr: 0.100000, loss: 3.8116, CELoss: 2.4192 KDLoss: 1.3924 
2022-03-10 13:14:55 - train: epoch 0010, iter [04400, 05004], lr: 0.100000, loss: 3.7176, CELoss: 2.3593 KDLoss: 1.3583 
2022-03-10 13:15:28 - train: epoch 0010, iter [04500, 05004], lr: 0.100000, loss: 3.7700, CELoss: 2.4872 KDLoss: 1.2829 
2022-03-10 13:16:02 - train: epoch 0010, iter [04600, 05004], lr: 0.100000, loss: 3.7227, CELoss: 2.3452 KDLoss: 1.3775 
2022-03-10 13:16:35 - train: epoch 0010, iter [04700, 05004], lr: 0.100000, loss: 3.6199, CELoss: 2.3490 KDLoss: 1.2709 
2022-03-10 13:17:08 - train: epoch 0010, iter [04800, 05004], lr: 0.100000, loss: 3.7389, CELoss: 2.3554 KDLoss: 1.3835 
2022-03-10 13:17:42 - train: epoch 0010, iter [04900, 05004], lr: 0.100000, loss: 3.8909, CELoss: 2.4983 KDLoss: 1.3927 
2022-03-10 13:18:14 - train: epoch 0010, iter [05000, 05004], lr: 0.100000, loss: 3.5545, CELoss: 2.2709 KDLoss: 1.2837 
2022-03-10 13:18:15 - train: epoch 010, train_loss: 3.7507
2022-03-10 13:20:43 - eval: epoch: 010, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 46.560%, stu_acc5: 72.958%, stu_test_loss: 2.3536
2022-03-10 13:20:43 - until epoch: 010, tea_best_acc1: 73.950%, stu_best_acc1: 49.420%
2022-03-10 13:20:43 - epoch 011 lr: 0.1
2022-03-10 13:21:21 - train: epoch 0011, iter [00100, 05004], lr: 0.100000, loss: 3.6232, CELoss: 2.3559 KDLoss: 1.2674 
2022-03-10 13:21:55 - train: epoch 0011, iter [00200, 05004], lr: 0.100000, loss: 3.9199, CELoss: 2.6007 KDLoss: 1.3192 
2022-03-10 13:22:28 - train: epoch 0011, iter [00300, 05004], lr: 0.100000, loss: 3.7493, CELoss: 2.4702 KDLoss: 1.2791 
2022-03-10 13:23:02 - train: epoch 0011, iter [00400, 05004], lr: 0.100000, loss: 4.0669, CELoss: 2.6587 KDLoss: 1.4082 
2022-03-10 13:23:35 - train: epoch 0011, iter [00500, 05004], lr: 0.100000, loss: 3.4610, CELoss: 2.2013 KDLoss: 1.2597 
2022-03-10 13:24:09 - train: epoch 0011, iter [00600, 05004], lr: 0.100000, loss: 4.0810, CELoss: 2.6628 KDLoss: 1.4183 
2022-03-10 13:24:43 - train: epoch 0011, iter [00700, 05004], lr: 0.100000, loss: 3.9469, CELoss: 2.5067 KDLoss: 1.4402 
2022-03-10 13:25:17 - train: epoch 0011, iter [00800, 05004], lr: 0.100000, loss: 3.9009, CELoss: 2.5429 KDLoss: 1.3580 
2022-03-10 13:25:49 - train: epoch 0011, iter [00900, 05004], lr: 0.100000, loss: 3.8408, CELoss: 2.6343 KDLoss: 1.2065 
2022-03-10 13:26:23 - train: epoch 0011, iter [01000, 05004], lr: 0.100000, loss: 3.5774, CELoss: 2.3126 KDLoss: 1.2648 
2022-03-10 13:26:58 - train: epoch 0011, iter [01100, 05004], lr: 0.100000, loss: 3.5240, CELoss: 2.2779 KDLoss: 1.2460 
2022-03-10 13:27:31 - train: epoch 0011, iter [01200, 05004], lr: 0.100000, loss: 4.0882, CELoss: 2.6476 KDLoss: 1.4407 
2022-03-10 13:28:05 - train: epoch 0011, iter [01300, 05004], lr: 0.100000, loss: 3.6007, CELoss: 2.3208 KDLoss: 1.2800 
2022-03-10 13:28:38 - train: epoch 0011, iter [01400, 05004], lr: 0.100000, loss: 4.1018, CELoss: 2.6787 KDLoss: 1.4231 
2022-03-10 13:29:12 - train: epoch 0011, iter [01500, 05004], lr: 0.100000, loss: 3.8078, CELoss: 2.4744 KDLoss: 1.3334 
2022-03-10 13:29:44 - train: epoch 0011, iter [01600, 05004], lr: 0.100000, loss: 3.8745, CELoss: 2.5367 KDLoss: 1.3377 
2022-03-10 13:30:19 - train: epoch 0011, iter [01700, 05004], lr: 0.100000, loss: 4.0319, CELoss: 2.5673 KDLoss: 1.4646 
2022-03-10 13:30:53 - train: epoch 0011, iter [01800, 05004], lr: 0.100000, loss: 3.7908, CELoss: 2.4764 KDLoss: 1.3144 
2022-03-10 13:31:27 - train: epoch 0011, iter [01900, 05004], lr: 0.100000, loss: 3.6325, CELoss: 2.2892 KDLoss: 1.3433 
2022-03-10 13:32:00 - train: epoch 0011, iter [02000, 05004], lr: 0.100000, loss: 3.7273, CELoss: 2.3283 KDLoss: 1.3990 
2022-03-10 13:32:33 - train: epoch 0011, iter [02100, 05004], lr: 0.100000, loss: 3.4812, CELoss: 2.2424 KDLoss: 1.2388 
2022-03-10 13:33:07 - train: epoch 0011, iter [02200, 05004], lr: 0.100000, loss: 3.6445, CELoss: 2.3031 KDLoss: 1.3414 
2022-03-10 13:33:40 - train: epoch 0011, iter [02300, 05004], lr: 0.100000, loss: 3.8531, CELoss: 2.4660 KDLoss: 1.3871 
2022-03-10 13:34:14 - train: epoch 0011, iter [02400, 05004], lr: 0.100000, loss: 3.3717, CELoss: 2.1739 KDLoss: 1.1979 
2022-03-10 13:34:48 - train: epoch 0011, iter [02500, 05004], lr: 0.100000, loss: 3.7498, CELoss: 2.4507 KDLoss: 1.2991 
2022-03-10 13:35:20 - train: epoch 0011, iter [02600, 05004], lr: 0.100000, loss: 3.7563, CELoss: 2.3524 KDLoss: 1.4039 
2022-03-10 13:35:54 - train: epoch 0011, iter [02700, 05004], lr: 0.100000, loss: 3.4168, CELoss: 2.2102 KDLoss: 1.2066 
2022-03-10 13:36:28 - train: epoch 0011, iter [02800, 05004], lr: 0.100000, loss: 3.3430, CELoss: 2.1435 KDLoss: 1.1995 
2022-03-10 13:37:02 - train: epoch 0011, iter [02900, 05004], lr: 0.100000, loss: 3.7653, CELoss: 2.4324 KDLoss: 1.3329 
2022-03-10 13:37:35 - train: epoch 0011, iter [03000, 05004], lr: 0.100000, loss: 4.0761, CELoss: 2.7004 KDLoss: 1.3757 
2022-03-10 13:38:10 - train: epoch 0011, iter [03100, 05004], lr: 0.100000, loss: 3.5399, CELoss: 2.3049 KDLoss: 1.2351 
2022-03-10 13:38:43 - train: epoch 0011, iter [03200, 05004], lr: 0.100000, loss: 3.5670, CELoss: 2.2971 KDLoss: 1.2699 
2022-03-10 13:39:17 - train: epoch 0011, iter [03300, 05004], lr: 0.100000, loss: 3.7035, CELoss: 2.3829 KDLoss: 1.3206 
2022-03-10 13:39:50 - train: epoch 0011, iter [03400, 05004], lr: 0.100000, loss: 3.5330, CELoss: 2.3535 KDLoss: 1.1795 
2022-03-10 13:40:23 - train: epoch 0011, iter [03500, 05004], lr: 0.100000, loss: 3.7844, CELoss: 2.4021 KDLoss: 1.3823 
2022-03-10 13:40:57 - train: epoch 0011, iter [03600, 05004], lr: 0.100000, loss: 3.5838, CELoss: 2.3084 KDLoss: 1.2754 
2022-03-10 13:41:31 - train: epoch 0011, iter [03700, 05004], lr: 0.100000, loss: 3.8123, CELoss: 2.5397 KDLoss: 1.2726 
2022-03-10 13:42:04 - train: epoch 0011, iter [03800, 05004], lr: 0.100000, loss: 3.6401, CELoss: 2.3552 KDLoss: 1.2849 
2022-03-10 13:42:38 - train: epoch 0011, iter [03900, 05004], lr: 0.100000, loss: 3.7418, CELoss: 2.4071 KDLoss: 1.3347 
2022-03-10 13:43:11 - train: epoch 0011, iter [04000, 05004], lr: 0.100000, loss: 3.4457, CELoss: 2.1484 KDLoss: 1.2973 
2022-03-10 13:43:44 - train: epoch 0011, iter [04100, 05004], lr: 0.100000, loss: 3.6889, CELoss: 2.3355 KDLoss: 1.3534 
2022-03-10 13:44:17 - train: epoch 0011, iter [04200, 05004], lr: 0.100000, loss: 3.6805, CELoss: 2.3764 KDLoss: 1.3040 
2022-03-10 13:44:50 - train: epoch 0011, iter [04300, 05004], lr: 0.100000, loss: 3.6867, CELoss: 2.3570 KDLoss: 1.3297 
2022-03-10 13:45:24 - train: epoch 0011, iter [04400, 05004], lr: 0.100000, loss: 3.9960, CELoss: 2.6243 KDLoss: 1.3717 
2022-03-10 13:45:58 - train: epoch 0011, iter [04500, 05004], lr: 0.100000, loss: 3.4977, CELoss: 2.2661 KDLoss: 1.2316 
2022-03-10 13:46:31 - train: epoch 0011, iter [04600, 05004], lr: 0.100000, loss: 3.8899, CELoss: 2.4894 KDLoss: 1.4005 
2022-03-10 13:47:05 - train: epoch 0011, iter [04700, 05004], lr: 0.100000, loss: 3.6885, CELoss: 2.3779 KDLoss: 1.3106 
2022-03-10 13:47:39 - train: epoch 0011, iter [04800, 05004], lr: 0.100000, loss: 3.4003, CELoss: 2.1518 KDLoss: 1.2485 
2022-03-10 13:48:12 - train: epoch 0011, iter [04900, 05004], lr: 0.100000, loss: 3.4818, CELoss: 2.2240 KDLoss: 1.2578 
2022-03-10 13:48:43 - train: epoch 0011, iter [05000, 05004], lr: 0.100000, loss: 3.6858, CELoss: 2.4300 KDLoss: 1.2558 
2022-03-10 13:48:44 - train: epoch 011, train_loss: 3.7192
2022-03-10 13:51:13 - eval: epoch: 011, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 48.332%, stu_acc5: 74.392%, stu_test_loss: 2.2593
2022-03-10 13:51:13 - until epoch: 011, tea_best_acc1: 73.950%, stu_best_acc1: 49.420%
2022-03-10 13:51:13 - epoch 012 lr: 0.1
2022-03-10 13:51:52 - train: epoch 0012, iter [00100, 05004], lr: 0.100000, loss: 3.3052, CELoss: 2.1549 KDLoss: 1.1503 
2022-03-10 13:52:25 - train: epoch 0012, iter [00200, 05004], lr: 0.100000, loss: 3.1765, CELoss: 2.0210 KDLoss: 1.1555 
2022-03-10 13:52:58 - train: epoch 0012, iter [00300, 05004], lr: 0.100000, loss: 3.4697, CELoss: 2.2407 KDLoss: 1.2290 
2022-03-10 13:53:32 - train: epoch 0012, iter [00400, 05004], lr: 0.100000, loss: 3.6998, CELoss: 2.4009 KDLoss: 1.2989 
2022-03-10 13:54:06 - train: epoch 0012, iter [00500, 05004], lr: 0.100000, loss: 4.0201, CELoss: 2.5759 KDLoss: 1.4442 
2022-03-10 13:54:39 - train: epoch 0012, iter [00600, 05004], lr: 0.100000, loss: 3.4659, CELoss: 2.1621 KDLoss: 1.3038 
2022-03-10 13:55:12 - train: epoch 0012, iter [00700, 05004], lr: 0.100000, loss: 3.3486, CELoss: 2.1565 KDLoss: 1.1921 
2022-03-10 13:55:46 - train: epoch 0012, iter [00800, 05004], lr: 0.100000, loss: 3.9200, CELoss: 2.6556 KDLoss: 1.2644 
2022-03-10 13:56:19 - train: epoch 0012, iter [00900, 05004], lr: 0.100000, loss: 3.5903, CELoss: 2.3263 KDLoss: 1.2640 
2022-03-10 13:56:53 - train: epoch 0012, iter [01000, 05004], lr: 0.100000, loss: 3.3989, CELoss: 2.2152 KDLoss: 1.1837 
2022-03-10 13:57:26 - train: epoch 0012, iter [01100, 05004], lr: 0.100000, loss: 4.0068, CELoss: 2.6462 KDLoss: 1.3606 
2022-03-10 13:58:00 - train: epoch 0012, iter [01200, 05004], lr: 0.100000, loss: 3.4247, CELoss: 2.1533 KDLoss: 1.2714 
2022-03-10 13:58:33 - train: epoch 0012, iter [01300, 05004], lr: 0.100000, loss: 3.4609, CELoss: 2.2276 KDLoss: 1.2333 
2022-03-10 13:59:07 - train: epoch 0012, iter [01400, 05004], lr: 0.100000, loss: 4.0705, CELoss: 2.6396 KDLoss: 1.4309 
2022-03-10 13:59:40 - train: epoch 0012, iter [01500, 05004], lr: 0.100000, loss: 3.3884, CELoss: 2.1828 KDLoss: 1.2056 
2022-03-10 14:00:13 - train: epoch 0012, iter [01600, 05004], lr: 0.100000, loss: 3.6443, CELoss: 2.3339 KDLoss: 1.3104 
2022-03-10 14:00:47 - train: epoch 0012, iter [01700, 05004], lr: 0.100000, loss: 3.6675, CELoss: 2.3564 KDLoss: 1.3110 
2022-03-10 14:01:20 - train: epoch 0012, iter [01800, 05004], lr: 0.100000, loss: 3.7515, CELoss: 2.4802 KDLoss: 1.2713 
2022-03-10 14:01:54 - train: epoch 0012, iter [01900, 05004], lr: 0.100000, loss: 3.8416, CELoss: 2.5535 KDLoss: 1.2881 
2022-03-10 14:02:28 - train: epoch 0012, iter [02000, 05004], lr: 0.100000, loss: 3.8735, CELoss: 2.4975 KDLoss: 1.3760 
2022-03-10 14:03:02 - train: epoch 0012, iter [02100, 05004], lr: 0.100000, loss: 3.7219, CELoss: 2.4871 KDLoss: 1.2348 
2022-03-10 14:03:34 - train: epoch 0012, iter [02200, 05004], lr: 0.100000, loss: 4.0771, CELoss: 2.6938 KDLoss: 1.3833 
2022-03-10 14:04:08 - train: epoch 0012, iter [02300, 05004], lr: 0.100000, loss: 3.7609, CELoss: 2.3905 KDLoss: 1.3704 
2022-03-10 14:04:42 - train: epoch 0012, iter [02400, 05004], lr: 0.100000, loss: 3.6714, CELoss: 2.3147 KDLoss: 1.3567 
2022-03-10 14:05:16 - train: epoch 0012, iter [02500, 05004], lr: 0.100000, loss: 3.3989, CELoss: 2.2001 KDLoss: 1.1987 
2022-03-10 14:05:48 - train: epoch 0012, iter [02600, 05004], lr: 0.100000, loss: 3.4206, CELoss: 2.2250 KDLoss: 1.1957 
2022-03-10 14:06:22 - train: epoch 0012, iter [02700, 05004], lr: 0.100000, loss: 3.6336, CELoss: 2.3589 KDLoss: 1.2747 
2022-03-10 14:06:55 - train: epoch 0012, iter [02800, 05004], lr: 0.100000, loss: 3.7858, CELoss: 2.5075 KDLoss: 1.2783 
2022-03-10 14:07:29 - train: epoch 0012, iter [02900, 05004], lr: 0.100000, loss: 3.6649, CELoss: 2.4270 KDLoss: 1.2379 
2022-03-10 14:08:02 - train: epoch 0012, iter [03000, 05004], lr: 0.100000, loss: 3.3533, CELoss: 2.1512 KDLoss: 1.2021 
2022-03-10 14:08:36 - train: epoch 0012, iter [03100, 05004], lr: 0.100000, loss: 3.7036, CELoss: 2.4118 KDLoss: 1.2918 
2022-03-10 14:09:09 - train: epoch 0012, iter [03200, 05004], lr: 0.100000, loss: 3.6053, CELoss: 2.3076 KDLoss: 1.2978 
2022-03-10 14:09:42 - train: epoch 0012, iter [03300, 05004], lr: 0.100000, loss: 3.7049, CELoss: 2.3916 KDLoss: 1.3133 
2022-03-10 14:10:16 - train: epoch 0012, iter [03400, 05004], lr: 0.100000, loss: 3.6170, CELoss: 2.3963 KDLoss: 1.2207 
2022-03-10 14:10:49 - train: epoch 0012, iter [03500, 05004], lr: 0.100000, loss: 3.7230, CELoss: 2.3965 KDLoss: 1.3265 
2022-03-10 14:11:23 - train: epoch 0012, iter [03600, 05004], lr: 0.100000, loss: 3.7863, CELoss: 2.3424 KDLoss: 1.4439 
2022-03-10 14:11:56 - train: epoch 0012, iter [03700, 05004], lr: 0.100000, loss: 3.8065, CELoss: 2.5443 KDLoss: 1.2622 
2022-03-10 14:12:29 - train: epoch 0012, iter [03800, 05004], lr: 0.100000, loss: 3.7730, CELoss: 2.4471 KDLoss: 1.3259 
2022-03-10 14:13:02 - train: epoch 0012, iter [03900, 05004], lr: 0.100000, loss: 3.2487, CELoss: 2.1019 KDLoss: 1.1468 
2022-03-10 14:13:36 - train: epoch 0012, iter [04000, 05004], lr: 0.100000, loss: 3.6825, CELoss: 2.3758 KDLoss: 1.3067 
2022-03-10 14:14:09 - train: epoch 0012, iter [04100, 05004], lr: 0.100000, loss: 3.8466, CELoss: 2.4720 KDLoss: 1.3746 
2022-03-10 14:14:41 - train: epoch 0012, iter [04200, 05004], lr: 0.100000, loss: 3.6263, CELoss: 2.3350 KDLoss: 1.2913 
2022-03-10 14:15:15 - train: epoch 0012, iter [04300, 05004], lr: 0.100000, loss: 3.8624, CELoss: 2.5739 KDLoss: 1.2884 
2022-03-10 14:15:50 - train: epoch 0012, iter [04400, 05004], lr: 0.100000, loss: 3.6785, CELoss: 2.4022 KDLoss: 1.2763 
2022-03-10 14:16:23 - train: epoch 0012, iter [04500, 05004], lr: 0.100000, loss: 3.7034, CELoss: 2.3502 KDLoss: 1.3532 
2022-03-10 14:16:56 - train: epoch 0012, iter [04600, 05004], lr: 0.100000, loss: 3.9828, CELoss: 2.5400 KDLoss: 1.4429 
2022-03-10 14:17:29 - train: epoch 0012, iter [04700, 05004], lr: 0.100000, loss: 3.4488, CELoss: 2.2422 KDLoss: 1.2066 
2022-03-10 14:18:03 - train: epoch 0012, iter [04800, 05004], lr: 0.100000, loss: 3.8847, CELoss: 2.4720 KDLoss: 1.4127 
2022-03-10 14:18:36 - train: epoch 0012, iter [04900, 05004], lr: 0.100000, loss: 3.3507, CELoss: 2.1395 KDLoss: 1.2112 
2022-03-10 14:19:08 - train: epoch 0012, iter [05000, 05004], lr: 0.100000, loss: 3.4620, CELoss: 2.2711 KDLoss: 1.1909 
2022-03-10 14:19:09 - train: epoch 012, train_loss: 3.6834
2022-03-10 14:21:37 - eval: epoch: 012, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 51.172%, stu_acc5: 76.686%, stu_test_loss: 2.1088
2022-03-10 14:21:38 - until epoch: 012, tea_best_acc1: 73.950%, stu_best_acc1: 51.172%
2022-03-10 14:21:38 - epoch 013 lr: 0.1
2022-03-10 14:22:16 - train: epoch 0013, iter [00100, 05004], lr: 0.100000, loss: 3.3496, CELoss: 2.1573 KDLoss: 1.1923 
2022-03-10 14:22:49 - train: epoch 0013, iter [00200, 05004], lr: 0.100000, loss: 3.6283, CELoss: 2.3488 KDLoss: 1.2795 
2022-03-10 14:23:23 - train: epoch 0013, iter [00300, 05004], lr: 0.100000, loss: 3.6929, CELoss: 2.4434 KDLoss: 1.2494 
2022-03-10 14:23:56 - train: epoch 0013, iter [00400, 05004], lr: 0.100000, loss: 3.5200, CELoss: 2.2303 KDLoss: 1.2896 
2022-03-10 14:24:30 - train: epoch 0013, iter [00500, 05004], lr: 0.100000, loss: 3.4895, CELoss: 2.2801 KDLoss: 1.2095 
2022-03-10 14:25:03 - train: epoch 0013, iter [00600, 05004], lr: 0.100000, loss: 3.6866, CELoss: 2.4285 KDLoss: 1.2582 
2022-03-10 14:25:37 - train: epoch 0013, iter [00700, 05004], lr: 0.100000, loss: 3.5858, CELoss: 2.2730 KDLoss: 1.3128 
2022-03-10 14:26:10 - train: epoch 0013, iter [00800, 05004], lr: 0.100000, loss: 3.8729, CELoss: 2.4885 KDLoss: 1.3843 
2022-03-10 14:26:44 - train: epoch 0013, iter [00900, 05004], lr: 0.100000, loss: 3.7489, CELoss: 2.4901 KDLoss: 1.2588 
2022-03-10 14:27:17 - train: epoch 0013, iter [01000, 05004], lr: 0.100000, loss: 3.5334, CELoss: 2.2936 KDLoss: 1.2398 
2022-03-10 14:27:51 - train: epoch 0013, iter [01100, 05004], lr: 0.100000, loss: 3.5353, CELoss: 2.2590 KDLoss: 1.2764 
2022-03-10 14:28:25 - train: epoch 0013, iter [01200, 05004], lr: 0.100000, loss: 3.9925, CELoss: 2.5990 KDLoss: 1.3934 
2022-03-10 14:28:58 - train: epoch 0013, iter [01300, 05004], lr: 0.100000, loss: 3.5546, CELoss: 2.2787 KDLoss: 1.2760 
2022-03-10 14:29:31 - train: epoch 0013, iter [01400, 05004], lr: 0.100000, loss: 3.7082, CELoss: 2.3650 KDLoss: 1.3432 
2022-03-10 14:30:05 - train: epoch 0013, iter [01500, 05004], lr: 0.100000, loss: 3.9288, CELoss: 2.5522 KDLoss: 1.3766 
2022-03-10 14:30:39 - train: epoch 0013, iter [01600, 05004], lr: 0.100000, loss: 3.5276, CELoss: 2.2765 KDLoss: 1.2511 
2022-03-10 14:31:12 - train: epoch 0013, iter [01700, 05004], lr: 0.100000, loss: 3.7669, CELoss: 2.4291 KDLoss: 1.3379 
2022-03-10 14:31:46 - train: epoch 0013, iter [01800, 05004], lr: 0.100000, loss: 3.6740, CELoss: 2.3576 KDLoss: 1.3165 
2022-03-10 14:32:19 - train: epoch 0013, iter [01900, 05004], lr: 0.100000, loss: 3.7571, CELoss: 2.4435 KDLoss: 1.3136 
2022-03-10 14:32:52 - train: epoch 0013, iter [02000, 05004], lr: 0.100000, loss: 3.6906, CELoss: 2.4187 KDLoss: 1.2719 
2022-03-10 14:33:26 - train: epoch 0013, iter [02100, 05004], lr: 0.100000, loss: 4.0375, CELoss: 2.5990 KDLoss: 1.4386 
2022-03-10 14:34:00 - train: epoch 0013, iter [02200, 05004], lr: 0.100000, loss: 3.3711, CELoss: 2.1690 KDLoss: 1.2021 
2022-03-10 14:34:34 - train: epoch 0013, iter [02300, 05004], lr: 0.100000, loss: 3.5222, CELoss: 2.2668 KDLoss: 1.2554 
2022-03-10 14:35:06 - train: epoch 0013, iter [02400, 05004], lr: 0.100000, loss: 4.0421, CELoss: 2.5785 KDLoss: 1.4635 
2022-03-10 14:35:40 - train: epoch 0013, iter [02500, 05004], lr: 0.100000, loss: 3.5006, CELoss: 2.2617 KDLoss: 1.2389 
2022-03-10 14:36:14 - train: epoch 0013, iter [02600, 05004], lr: 0.100000, loss: 3.5390, CELoss: 2.3287 KDLoss: 1.2103 
2022-03-10 14:36:47 - train: epoch 0013, iter [02700, 05004], lr: 0.100000, loss: 3.4738, CELoss: 2.2826 KDLoss: 1.1912 
2022-03-10 14:37:21 - train: epoch 0013, iter [02800, 05004], lr: 0.100000, loss: 3.8690, CELoss: 2.4852 KDLoss: 1.3838 
2022-03-10 14:37:54 - train: epoch 0013, iter [02900, 05004], lr: 0.100000, loss: 3.5665, CELoss: 2.3673 KDLoss: 1.1992 
2022-03-10 14:38:28 - train: epoch 0013, iter [03000, 05004], lr: 0.100000, loss: 3.4970, CELoss: 2.1889 KDLoss: 1.3081 
2022-03-10 14:39:00 - train: epoch 0013, iter [03100, 05004], lr: 0.100000, loss: 3.4767, CELoss: 2.2389 KDLoss: 1.2378 
2022-03-10 14:39:34 - train: epoch 0013, iter [03200, 05004], lr: 0.100000, loss: 3.9230, CELoss: 2.5322 KDLoss: 1.3908 
2022-03-10 14:40:07 - train: epoch 0013, iter [03300, 05004], lr: 0.100000, loss: 3.4762, CELoss: 2.2708 KDLoss: 1.2054 
2022-03-10 14:40:40 - train: epoch 0013, iter [03400, 05004], lr: 0.100000, loss: 3.6531, CELoss: 2.3120 KDLoss: 1.3410 
2022-03-10 14:41:13 - train: epoch 0013, iter [03500, 05004], lr: 0.100000, loss: 3.5407, CELoss: 2.2916 KDLoss: 1.2491 
2022-03-10 14:41:46 - train: epoch 0013, iter [03600, 05004], lr: 0.100000, loss: 3.7323, CELoss: 2.4359 KDLoss: 1.2964 
2022-03-10 14:42:20 - train: epoch 0013, iter [03700, 05004], lr: 0.100000, loss: 3.3968, CELoss: 2.1367 KDLoss: 1.2601 
2022-03-10 14:42:53 - train: epoch 0013, iter [03800, 05004], lr: 0.100000, loss: 3.9690, CELoss: 2.6123 KDLoss: 1.3567 
2022-03-10 14:43:26 - train: epoch 0013, iter [03900, 05004], lr: 0.100000, loss: 3.8740, CELoss: 2.5621 KDLoss: 1.3120 
2022-03-10 14:43:59 - train: epoch 0013, iter [04000, 05004], lr: 0.100000, loss: 3.5506, CELoss: 2.3158 KDLoss: 1.2348 
2022-03-10 14:44:33 - train: epoch 0013, iter [04100, 05004], lr: 0.100000, loss: 3.5916, CELoss: 2.2634 KDLoss: 1.3282 
2022-03-10 14:45:07 - train: epoch 0013, iter [04200, 05004], lr: 0.100000, loss: 3.7989, CELoss: 2.4223 KDLoss: 1.3766 
2022-03-10 14:45:39 - train: epoch 0013, iter [04300, 05004], lr: 0.100000, loss: 3.7122, CELoss: 2.3222 KDLoss: 1.3901 
2022-03-10 14:46:12 - train: epoch 0013, iter [04400, 05004], lr: 0.100000, loss: 3.5231, CELoss: 2.2345 KDLoss: 1.2885 
2022-03-10 14:46:46 - train: epoch 0013, iter [04500, 05004], lr: 0.100000, loss: 3.4250, CELoss: 2.2321 KDLoss: 1.1929 
2022-03-10 14:47:20 - train: epoch 0013, iter [04600, 05004], lr: 0.100000, loss: 3.5566, CELoss: 2.2193 KDLoss: 1.3373 
2022-03-10 14:47:53 - train: epoch 0013, iter [04700, 05004], lr: 0.100000, loss: 3.7785, CELoss: 2.5106 KDLoss: 1.2680 
2022-03-10 14:48:27 - train: epoch 0013, iter [04800, 05004], lr: 0.100000, loss: 3.6574, CELoss: 2.4015 KDLoss: 1.2559 
2022-03-10 14:49:01 - train: epoch 0013, iter [04900, 05004], lr: 0.100000, loss: 3.9339, CELoss: 2.5253 KDLoss: 1.4086 
2022-03-10 14:49:32 - train: epoch 0013, iter [05000, 05004], lr: 0.100000, loss: 3.7004, CELoss: 2.3317 KDLoss: 1.3686 
2022-03-10 14:49:33 - train: epoch 013, train_loss: 3.6621
2022-03-10 14:52:04 - eval: epoch: 013, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 50.848%, stu_acc5: 76.382%, stu_test_loss: 2.1264
2022-03-10 14:52:04 - until epoch: 013, tea_best_acc1: 73.950%, stu_best_acc1: 51.172%
2022-03-10 14:52:04 - epoch 014 lr: 0.1
2022-03-10 14:52:43 - train: epoch 0014, iter [00100, 05004], lr: 0.100000, loss: 3.4751, CELoss: 2.3060 KDLoss: 1.1691 
2022-03-10 14:53:16 - train: epoch 0014, iter [00200, 05004], lr: 0.100000, loss: 3.8123, CELoss: 2.4855 KDLoss: 1.3268 
2022-03-10 14:53:50 - train: epoch 0014, iter [00300, 05004], lr: 0.100000, loss: 3.1729, CELoss: 2.1436 KDLoss: 1.0293 
2022-03-10 14:54:23 - train: epoch 0014, iter [00400, 05004], lr: 0.100000, loss: 3.4053, CELoss: 2.2624 KDLoss: 1.1428 
2022-03-10 14:54:57 - train: epoch 0014, iter [00500, 05004], lr: 0.100000, loss: 3.6625, CELoss: 2.3634 KDLoss: 1.2991 
2022-03-10 14:55:30 - train: epoch 0014, iter [00600, 05004], lr: 0.100000, loss: 3.7413, CELoss: 2.4771 KDLoss: 1.2642 
2022-03-10 14:56:04 - train: epoch 0014, iter [00700, 05004], lr: 0.100000, loss: 3.5578, CELoss: 2.3175 KDLoss: 1.2403 
2022-03-10 14:56:37 - train: epoch 0014, iter [00800, 05004], lr: 0.100000, loss: 3.4254, CELoss: 2.2425 KDLoss: 1.1829 
2022-03-10 14:57:11 - train: epoch 0014, iter [00900, 05004], lr: 0.100000, loss: 3.4210, CELoss: 2.2466 KDLoss: 1.1744 
2022-03-10 14:57:43 - train: epoch 0014, iter [01000, 05004], lr: 0.100000, loss: 3.8212, CELoss: 2.4367 KDLoss: 1.3845 
2022-03-10 14:58:18 - train: epoch 0014, iter [01100, 05004], lr: 0.100000, loss: 3.6416, CELoss: 2.3420 KDLoss: 1.2996 
2022-03-10 14:58:52 - train: epoch 0014, iter [01200, 05004], lr: 0.100000, loss: 3.9580, CELoss: 2.5277 KDLoss: 1.4302 
2022-03-10 14:59:26 - train: epoch 0014, iter [01300, 05004], lr: 0.100000, loss: 3.8257, CELoss: 2.4828 KDLoss: 1.3430 
2022-03-10 14:59:59 - train: epoch 0014, iter [01400, 05004], lr: 0.100000, loss: 3.7292, CELoss: 2.4412 KDLoss: 1.2880 
2022-03-10 15:00:32 - train: epoch 0014, iter [01500, 05004], lr: 0.100000, loss: 3.8801, CELoss: 2.5024 KDLoss: 1.3777 
2022-03-10 15:01:05 - train: epoch 0014, iter [01600, 05004], lr: 0.100000, loss: 3.7461, CELoss: 2.4353 KDLoss: 1.3108 
2022-03-10 15:01:39 - train: epoch 0014, iter [01700, 05004], lr: 0.100000, loss: 3.6634, CELoss: 2.4062 KDLoss: 1.2572 
2022-03-10 15:02:13 - train: epoch 0014, iter [01800, 05004], lr: 0.100000, loss: 3.9185, CELoss: 2.4985 KDLoss: 1.4201 
2022-03-10 15:02:46 - train: epoch 0014, iter [01900, 05004], lr: 0.100000, loss: 3.5405, CELoss: 2.3001 KDLoss: 1.2404 
2022-03-10 15:03:20 - train: epoch 0014, iter [02000, 05004], lr: 0.100000, loss: 3.4190, CELoss: 2.1887 KDLoss: 1.2303 
2022-03-10 15:03:53 - train: epoch 0014, iter [02100, 05004], lr: 0.100000, loss: 3.6805, CELoss: 2.3636 KDLoss: 1.3169 
2022-03-10 15:04:27 - train: epoch 0014, iter [02200, 05004], lr: 0.100000, loss: 3.7537, CELoss: 2.3820 KDLoss: 1.3717 
2022-03-10 15:05:00 - train: epoch 0014, iter [02300, 05004], lr: 0.100000, loss: 3.3941, CELoss: 2.1551 KDLoss: 1.2390 
2022-03-10 15:05:34 - train: epoch 0014, iter [02400, 05004], lr: 0.100000, loss: 3.7150, CELoss: 2.4455 KDLoss: 1.2695 
2022-03-10 15:06:08 - train: epoch 0014, iter [02500, 05004], lr: 0.100000, loss: 3.5375, CELoss: 2.2822 KDLoss: 1.2554 
2022-03-10 15:06:41 - train: epoch 0014, iter [02600, 05004], lr: 0.100000, loss: 3.3213, CELoss: 2.1134 KDLoss: 1.2079 
2022-03-10 15:07:16 - train: epoch 0014, iter [02700, 05004], lr: 0.100000, loss: 3.8952, CELoss: 2.5186 KDLoss: 1.3766 
2022-03-10 15:07:48 - train: epoch 0014, iter [02800, 05004], lr: 0.100000, loss: 3.9841, CELoss: 2.5929 KDLoss: 1.3913 
2022-03-10 15:08:22 - train: epoch 0014, iter [02900, 05004], lr: 0.100000, loss: 3.6023, CELoss: 2.3740 KDLoss: 1.2283 
2022-03-10 15:08:56 - train: epoch 0014, iter [03000, 05004], lr: 0.100000, loss: 3.9928, CELoss: 2.5405 KDLoss: 1.4523 
2022-03-10 15:09:29 - train: epoch 0014, iter [03100, 05004], lr: 0.100000, loss: 3.8066, CELoss: 2.4031 KDLoss: 1.4034 
2022-03-10 15:10:03 - train: epoch 0014, iter [03200, 05004], lr: 0.100000, loss: 3.6901, CELoss: 2.3969 KDLoss: 1.2932 
2022-03-10 15:10:36 - train: epoch 0014, iter [03300, 05004], lr: 0.100000, loss: 3.3171, CELoss: 2.1563 KDLoss: 1.1608 
2022-03-10 15:11:10 - train: epoch 0014, iter [03400, 05004], lr: 0.100000, loss: 3.4915, CELoss: 2.2940 KDLoss: 1.1975 
2022-03-10 15:11:43 - train: epoch 0014, iter [03500, 05004], lr: 0.100000, loss: 3.5202, CELoss: 2.3008 KDLoss: 1.2194 
2022-03-10 15:12:17 - train: epoch 0014, iter [03600, 05004], lr: 0.100000, loss: 3.4017, CELoss: 2.1607 KDLoss: 1.2410 
2022-03-10 15:12:50 - train: epoch 0014, iter [03700, 05004], lr: 0.100000, loss: 3.5337, CELoss: 2.3221 KDLoss: 1.2116 
2022-03-10 15:13:24 - train: epoch 0014, iter [03800, 05004], lr: 0.100000, loss: 3.8500, CELoss: 2.5342 KDLoss: 1.3158 
2022-03-10 15:13:57 - train: epoch 0014, iter [03900, 05004], lr: 0.100000, loss: 3.6960, CELoss: 2.4308 KDLoss: 1.2652 
2022-03-10 15:14:30 - train: epoch 0014, iter [04000, 05004], lr: 0.100000, loss: 3.7657, CELoss: 2.4032 KDLoss: 1.3625 
2022-03-10 15:15:03 - train: epoch 0014, iter [04100, 05004], lr: 0.100000, loss: 3.6871, CELoss: 2.3191 KDLoss: 1.3680 
2022-03-10 15:15:37 - train: epoch 0014, iter [04200, 05004], lr: 0.100000, loss: 3.5609, CELoss: 2.2724 KDLoss: 1.2885 
2022-03-10 15:16:09 - train: epoch 0014, iter [04300, 05004], lr: 0.100000, loss: 3.7104, CELoss: 2.4190 KDLoss: 1.2914 
2022-03-10 15:16:43 - train: epoch 0014, iter [04400, 05004], lr: 0.100000, loss: 3.5343, CELoss: 2.2709 KDLoss: 1.2634 
2022-03-10 15:17:16 - train: epoch 0014, iter [04500, 05004], lr: 0.100000, loss: 3.7378, CELoss: 2.4168 KDLoss: 1.3209 
2022-03-10 15:17:50 - train: epoch 0014, iter [04600, 05004], lr: 0.100000, loss: 3.4321, CELoss: 2.1605 KDLoss: 1.2717 
2022-03-10 15:18:24 - train: epoch 0014, iter [04700, 05004], lr: 0.100000, loss: 3.4741, CELoss: 2.2310 KDLoss: 1.2431 
2022-03-10 15:18:56 - train: epoch 0014, iter [04800, 05004], lr: 0.100000, loss: 3.9569, CELoss: 2.5959 KDLoss: 1.3610 
2022-03-10 15:19:30 - train: epoch 0014, iter [04900, 05004], lr: 0.100000, loss: 3.6649, CELoss: 2.4504 KDLoss: 1.2145 
2022-03-10 15:20:01 - train: epoch 0014, iter [05000, 05004], lr: 0.100000, loss: 3.5746, CELoss: 2.3642 KDLoss: 1.2105 
2022-03-10 15:20:02 - train: epoch 014, train_loss: 3.6426
2022-03-10 15:22:31 - eval: epoch: 014, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 47.614%, stu_acc5: 73.754%, stu_test_loss: 2.3019
2022-03-10 15:22:31 - until epoch: 014, tea_best_acc1: 73.950%, stu_best_acc1: 51.172%
2022-03-10 15:22:31 - epoch 015 lr: 0.1
2022-03-10 15:23:10 - train: epoch 0015, iter [00100, 05004], lr: 0.100000, loss: 3.3618, CELoss: 2.1454 KDLoss: 1.2164 
2022-03-10 15:23:45 - train: epoch 0015, iter [00200, 05004], lr: 0.100000, loss: 3.8211, CELoss: 2.5203 KDLoss: 1.3008 
2022-03-10 15:24:17 - train: epoch 0015, iter [00300, 05004], lr: 0.100000, loss: 3.8529, CELoss: 2.5408 KDLoss: 1.3121 
2022-03-10 15:24:50 - train: epoch 0015, iter [00400, 05004], lr: 0.100000, loss: 3.5120, CELoss: 2.2692 KDLoss: 1.2428 
2022-03-10 15:25:23 - train: epoch 0015, iter [00500, 05004], lr: 0.100000, loss: 3.5198, CELoss: 2.2553 KDLoss: 1.2645 
2022-03-10 15:25:58 - train: epoch 0015, iter [00600, 05004], lr: 0.100000, loss: 3.7385, CELoss: 2.4640 KDLoss: 1.2745 
2022-03-10 15:26:30 - train: epoch 0015, iter [00700, 05004], lr: 0.100000, loss: 3.9005, CELoss: 2.4982 KDLoss: 1.4023 
2022-03-10 15:27:03 - train: epoch 0015, iter [00800, 05004], lr: 0.100000, loss: 3.3288, CELoss: 2.2099 KDLoss: 1.1189 
2022-03-10 15:27:38 - train: epoch 0015, iter [00900, 05004], lr: 0.100000, loss: 3.3406, CELoss: 2.1657 KDLoss: 1.1750 
2022-03-10 15:28:11 - train: epoch 0015, iter [01000, 05004], lr: 0.100000, loss: 3.6950, CELoss: 2.4136 KDLoss: 1.2814 
2022-03-10 15:28:45 - train: epoch 0015, iter [01100, 05004], lr: 0.100000, loss: 3.6449, CELoss: 2.3821 KDLoss: 1.2628 
2022-03-10 15:29:18 - train: epoch 0015, iter [01200, 05004], lr: 0.100000, loss: 3.6373, CELoss: 2.4332 KDLoss: 1.2041 
2022-03-10 15:29:52 - train: epoch 0015, iter [01300, 05004], lr: 0.100000, loss: 3.8177, CELoss: 2.5382 KDLoss: 1.2795 
2022-03-10 15:30:26 - train: epoch 0015, iter [01400, 05004], lr: 0.100000, loss: 3.4178, CELoss: 2.2316 KDLoss: 1.1862 
2022-03-10 15:30:59 - train: epoch 0015, iter [01500, 05004], lr: 0.100000, loss: 3.5481, CELoss: 2.3029 KDLoss: 1.2452 
2022-03-10 15:31:32 - train: epoch 0015, iter [01600, 05004], lr: 0.100000, loss: 3.8653, CELoss: 2.4651 KDLoss: 1.4002 
2022-03-10 15:32:06 - train: epoch 0015, iter [01700, 05004], lr: 0.100000, loss: 3.7560, CELoss: 2.3561 KDLoss: 1.3999 
2022-03-10 15:32:40 - train: epoch 0015, iter [01800, 05004], lr: 0.100000, loss: 3.6516, CELoss: 2.3593 KDLoss: 1.2923 
2022-03-10 15:33:13 - train: epoch 0015, iter [01900, 05004], lr: 0.100000, loss: 3.5612, CELoss: 2.2371 KDLoss: 1.3242 
2022-03-10 15:33:46 - train: epoch 0015, iter [02000, 05004], lr: 0.100000, loss: 3.2586, CELoss: 2.1145 KDLoss: 1.1441 
2022-03-10 15:34:20 - train: epoch 0015, iter [02100, 05004], lr: 0.100000, loss: 3.4635, CELoss: 2.2485 KDLoss: 1.2150 
2022-03-10 15:34:53 - train: epoch 0015, iter [02200, 05004], lr: 0.100000, loss: 3.6871, CELoss: 2.3911 KDLoss: 1.2960 
2022-03-10 15:35:27 - train: epoch 0015, iter [02300, 05004], lr: 0.100000, loss: 3.6168, CELoss: 2.3310 KDLoss: 1.2858 
2022-03-10 15:36:00 - train: epoch 0015, iter [02400, 05004], lr: 0.100000, loss: 3.6808, CELoss: 2.3776 KDLoss: 1.3032 
2022-03-10 15:36:33 - train: epoch 0015, iter [02500, 05004], lr: 0.100000, loss: 3.5869, CELoss: 2.3794 KDLoss: 1.2075 
2022-03-10 15:37:07 - train: epoch 0015, iter [02600, 05004], lr: 0.100000, loss: 3.6044, CELoss: 2.2958 KDLoss: 1.3085 
2022-03-10 15:37:40 - train: epoch 0015, iter [02700, 05004], lr: 0.100000, loss: 3.8376, CELoss: 2.5425 KDLoss: 1.2951 
2022-03-10 15:38:13 - train: epoch 0015, iter [02800, 05004], lr: 0.100000, loss: 3.6256, CELoss: 2.3554 KDLoss: 1.2702 
2022-03-10 15:38:47 - train: epoch 0015, iter [02900, 05004], lr: 0.100000, loss: 3.6927, CELoss: 2.4164 KDLoss: 1.2763 
2022-03-10 15:39:20 - train: epoch 0015, iter [03000, 05004], lr: 0.100000, loss: 3.5097, CELoss: 2.2245 KDLoss: 1.2852 
2022-03-10 15:39:54 - train: epoch 0015, iter [03100, 05004], lr: 0.100000, loss: 3.4330, CELoss: 2.2757 KDLoss: 1.1573 
2022-03-10 15:40:26 - train: epoch 0015, iter [03200, 05004], lr: 0.100000, loss: 3.5681, CELoss: 2.2465 KDLoss: 1.3216 
2022-03-10 15:41:00 - train: epoch 0015, iter [03300, 05004], lr: 0.100000, loss: 3.4330, CELoss: 2.2498 KDLoss: 1.1832 
2022-03-10 15:41:34 - train: epoch 0015, iter [03400, 05004], lr: 0.100000, loss: 3.4851, CELoss: 2.2188 KDLoss: 1.2664 
2022-03-10 15:42:07 - train: epoch 0015, iter [03500, 05004], lr: 0.100000, loss: 3.9184, CELoss: 2.5764 KDLoss: 1.3420 
2022-03-10 15:42:40 - train: epoch 0015, iter [03600, 05004], lr: 0.100000, loss: 3.7577, CELoss: 2.4794 KDLoss: 1.2783 
2022-03-10 15:43:13 - train: epoch 0015, iter [03700, 05004], lr: 0.100000, loss: 3.1859, CELoss: 2.0210 KDLoss: 1.1649 
2022-03-10 15:43:47 - train: epoch 0015, iter [03800, 05004], lr: 0.100000, loss: 3.5689, CELoss: 2.3325 KDLoss: 1.2364 
2022-03-10 15:44:20 - train: epoch 0015, iter [03900, 05004], lr: 0.100000, loss: 4.0162, CELoss: 2.5145 KDLoss: 1.5017 
2022-03-10 15:44:53 - train: epoch 0015, iter [04000, 05004], lr: 0.100000, loss: 3.6326, CELoss: 2.3475 KDLoss: 1.2851 
2022-03-10 15:45:26 - train: epoch 0015, iter [04100, 05004], lr: 0.100000, loss: 3.6171, CELoss: 2.3040 KDLoss: 1.3131 
2022-03-10 15:46:00 - train: epoch 0015, iter [04200, 05004], lr: 0.100000, loss: 3.3739, CELoss: 2.1568 KDLoss: 1.2171 
2022-03-10 15:46:34 - train: epoch 0015, iter [04300, 05004], lr: 0.100000, loss: 3.4159, CELoss: 2.1949 KDLoss: 1.2210 
2022-03-10 15:47:08 - train: epoch 0015, iter [04400, 05004], lr: 0.100000, loss: 3.5931, CELoss: 2.3287 KDLoss: 1.2643 
2022-03-10 15:47:41 - train: epoch 0015, iter [04500, 05004], lr: 0.100000, loss: 3.6039, CELoss: 2.3429 KDLoss: 1.2611 
2022-03-10 15:48:14 - train: epoch 0015, iter [04600, 05004], lr: 0.100000, loss: 3.8139, CELoss: 2.4558 KDLoss: 1.3581 
2022-03-10 15:48:47 - train: epoch 0015, iter [04700, 05004], lr: 0.100000, loss: 3.9346, CELoss: 2.4880 KDLoss: 1.4466 
2022-03-10 15:49:21 - train: epoch 0015, iter [04800, 05004], lr: 0.100000, loss: 3.8987, CELoss: 2.5444 KDLoss: 1.3542 
2022-03-10 15:49:54 - train: epoch 0015, iter [04900, 05004], lr: 0.100000, loss: 3.6853, CELoss: 2.3621 KDLoss: 1.3232 
2022-03-10 15:50:26 - train: epoch 0015, iter [05000, 05004], lr: 0.100000, loss: 3.6170, CELoss: 2.3937 KDLoss: 1.2233 
2022-03-10 15:50:27 - train: epoch 015, train_loss: 3.6260
2022-03-10 15:52:56 - eval: epoch: 015, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 51.552%, stu_acc5: 76.998%, stu_test_loss: 2.0942
2022-03-10 15:52:57 - until epoch: 015, tea_best_acc1: 73.950%, stu_best_acc1: 51.552%
2022-03-10 15:52:57 - epoch 016 lr: 0.1
2022-03-10 15:53:34 - train: epoch 0016, iter [00100, 05004], lr: 0.100000, loss: 3.3822, CELoss: 2.2426 KDLoss: 1.1397 
2022-03-10 15:54:08 - train: epoch 0016, iter [00200, 05004], lr: 0.100000, loss: 3.3553, CELoss: 2.1095 KDLoss: 1.2458 
2022-03-10 15:54:42 - train: epoch 0016, iter [00300, 05004], lr: 0.100000, loss: 3.5525, CELoss: 2.3084 KDLoss: 1.2441 
2022-03-10 15:55:15 - train: epoch 0016, iter [00400, 05004], lr: 0.100000, loss: 3.6403, CELoss: 2.3951 KDLoss: 1.2451 
2022-03-10 15:55:48 - train: epoch 0016, iter [00500, 05004], lr: 0.100000, loss: 3.4444, CELoss: 2.2648 KDLoss: 1.1796 
2022-03-10 15:56:22 - train: epoch 0016, iter [00600, 05004], lr: 0.100000, loss: 3.4572, CELoss: 2.1949 KDLoss: 1.2622 
2022-03-10 15:56:55 - train: epoch 0016, iter [00700, 05004], lr: 0.100000, loss: 3.3470, CELoss: 2.1833 KDLoss: 1.1637 
2022-03-10 15:57:30 - train: epoch 0016, iter [00800, 05004], lr: 0.100000, loss: 3.5798, CELoss: 2.2841 KDLoss: 1.2957 
2022-03-10 15:58:02 - train: epoch 0016, iter [00900, 05004], lr: 0.100000, loss: 3.6705, CELoss: 2.3739 KDLoss: 1.2966 
2022-03-10 15:58:36 - train: epoch 0016, iter [01000, 05004], lr: 0.100000, loss: 3.3471, CELoss: 2.1647 KDLoss: 1.1824 
2022-03-10 15:59:09 - train: epoch 0016, iter [01100, 05004], lr: 0.100000, loss: 3.6910, CELoss: 2.3842 KDLoss: 1.3068 
2022-03-10 15:59:43 - train: epoch 0016, iter [01200, 05004], lr: 0.100000, loss: 3.4164, CELoss: 2.1863 KDLoss: 1.2301 
2022-03-10 16:00:17 - train: epoch 0016, iter [01300, 05004], lr: 0.100000, loss: 3.6725, CELoss: 2.3826 KDLoss: 1.2899 
2022-03-10 16:00:51 - train: epoch 0016, iter [01400, 05004], lr: 0.100000, loss: 3.3859, CELoss: 2.2531 KDLoss: 1.1327 
2022-03-10 16:01:24 - train: epoch 0016, iter [01500, 05004], lr: 0.100000, loss: 3.7825, CELoss: 2.5208 KDLoss: 1.2617 
2022-03-10 16:01:57 - train: epoch 0016, iter [01600, 05004], lr: 0.100000, loss: 3.9131, CELoss: 2.5961 KDLoss: 1.3170 
2022-03-10 16:02:31 - train: epoch 0016, iter [01700, 05004], lr: 0.100000, loss: 3.5640, CELoss: 2.3155 KDLoss: 1.2485 
2022-03-10 16:03:06 - train: epoch 0016, iter [01800, 05004], lr: 0.100000, loss: 3.6239, CELoss: 2.4118 KDLoss: 1.2121 
2022-03-10 16:03:38 - train: epoch 0016, iter [01900, 05004], lr: 0.100000, loss: 3.5376, CELoss: 2.3792 KDLoss: 1.1584 
2022-03-10 16:04:12 - train: epoch 0016, iter [02000, 05004], lr: 0.100000, loss: 3.2241, CELoss: 1.9990 KDLoss: 1.2251 
2022-03-10 16:04:45 - train: epoch 0016, iter [02100, 05004], lr: 0.100000, loss: 3.6770, CELoss: 2.4022 KDLoss: 1.2748 
2022-03-10 16:05:19 - train: epoch 0016, iter [02200, 05004], lr: 0.100000, loss: 3.7005, CELoss: 2.3996 KDLoss: 1.3008 
2022-03-10 16:05:53 - train: epoch 0016, iter [02300, 05004], lr: 0.100000, loss: 3.8517, CELoss: 2.4622 KDLoss: 1.3895 
2022-03-10 16:06:27 - train: epoch 0016, iter [02400, 05004], lr: 0.100000, loss: 3.4366, CELoss: 2.2170 KDLoss: 1.2196 
2022-03-10 16:07:00 - train: epoch 0016, iter [02500, 05004], lr: 0.100000, loss: 3.7034, CELoss: 2.3670 KDLoss: 1.3364 
2022-03-10 16:07:33 - train: epoch 0016, iter [02600, 05004], lr: 0.100000, loss: 3.5196, CELoss: 2.2782 KDLoss: 1.2414 
2022-03-10 16:08:08 - train: epoch 0016, iter [02700, 05004], lr: 0.100000, loss: 3.4041, CELoss: 2.2490 KDLoss: 1.1551 
2022-03-10 16:08:41 - train: epoch 0016, iter [02800, 05004], lr: 0.100000, loss: 3.3942, CELoss: 2.2119 KDLoss: 1.1823 
2022-03-10 16:09:14 - train: epoch 0016, iter [02900, 05004], lr: 0.100000, loss: 3.6772, CELoss: 2.3803 KDLoss: 1.2970 
2022-03-10 16:09:47 - train: epoch 0016, iter [03000, 05004], lr: 0.100000, loss: 3.8579, CELoss: 2.4683 KDLoss: 1.3896 
2022-03-10 16:10:21 - train: epoch 0016, iter [03100, 05004], lr: 0.100000, loss: 3.6083, CELoss: 2.3896 KDLoss: 1.2188 
2022-03-10 16:10:54 - train: epoch 0016, iter [03200, 05004], lr: 0.100000, loss: 3.6592, CELoss: 2.4024 KDLoss: 1.2568 
2022-03-10 16:11:29 - train: epoch 0016, iter [03300, 05004], lr: 0.100000, loss: 3.6899, CELoss: 2.4503 KDLoss: 1.2397 
2022-03-10 16:12:02 - train: epoch 0016, iter [03400, 05004], lr: 0.100000, loss: 3.6027, CELoss: 2.3565 KDLoss: 1.2462 
2022-03-10 16:12:35 - train: epoch 0016, iter [03500, 05004], lr: 0.100000, loss: 3.2950, CELoss: 2.1498 KDLoss: 1.1452 
2022-03-10 16:13:08 - train: epoch 0016, iter [03600, 05004], lr: 0.100000, loss: 3.4679, CELoss: 2.1965 KDLoss: 1.2713 
2022-03-10 16:13:42 - train: epoch 0016, iter [03700, 05004], lr: 0.100000, loss: 3.4967, CELoss: 2.2997 KDLoss: 1.1970 
2022-03-10 16:14:16 - train: epoch 0016, iter [03800, 05004], lr: 0.100000, loss: 3.8908, CELoss: 2.5762 KDLoss: 1.3146 
2022-03-10 16:14:50 - train: epoch 0016, iter [03900, 05004], lr: 0.100000, loss: 3.7806, CELoss: 2.4207 KDLoss: 1.3599 
2022-03-10 16:15:22 - train: epoch 0016, iter [04000, 05004], lr: 0.100000, loss: 3.7043, CELoss: 2.4162 KDLoss: 1.2881 
2022-03-10 16:15:57 - train: epoch 0016, iter [04100, 05004], lr: 0.100000, loss: 3.4994, CELoss: 2.2412 KDLoss: 1.2582 
2022-03-10 16:16:29 - train: epoch 0016, iter [04200, 05004], lr: 0.100000, loss: 3.4546, CELoss: 2.2209 KDLoss: 1.2337 
2022-03-10 16:17:03 - train: epoch 0016, iter [04300, 05004], lr: 0.100000, loss: 3.2894, CELoss: 2.1503 KDLoss: 1.1391 
2022-03-10 16:17:37 - train: epoch 0016, iter [04400, 05004], lr: 0.100000, loss: 3.5311, CELoss: 2.3302 KDLoss: 1.2009 
2022-03-10 16:18:11 - train: epoch 0016, iter [04500, 05004], lr: 0.100000, loss: 3.7296, CELoss: 2.4740 KDLoss: 1.2555 
2022-03-10 16:18:44 - train: epoch 0016, iter [04600, 05004], lr: 0.100000, loss: 3.4874, CELoss: 2.2037 KDLoss: 1.2837 
2022-03-10 16:19:17 - train: epoch 0016, iter [04700, 05004], lr: 0.100000, loss: 3.7679, CELoss: 2.5288 KDLoss: 1.2391 
2022-03-10 16:19:50 - train: epoch 0016, iter [04800, 05004], lr: 0.100000, loss: 3.4048, CELoss: 2.2557 KDLoss: 1.1491 
2022-03-10 16:20:24 - train: epoch 0016, iter [04900, 05004], lr: 0.100000, loss: 3.6157, CELoss: 2.3327 KDLoss: 1.2830 
2022-03-10 16:20:55 - train: epoch 0016, iter [05000, 05004], lr: 0.100000, loss: 3.7437, CELoss: 2.4023 KDLoss: 1.3414 
2022-03-10 16:20:56 - train: epoch 016, train_loss: 3.6073
2022-03-10 16:23:25 - eval: epoch: 016, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 51.684%, stu_acc5: 77.038%, stu_test_loss: 2.0851
2022-03-10 16:23:25 - until epoch: 016, tea_best_acc1: 73.950%, stu_best_acc1: 51.684%
2022-03-10 16:23:25 - epoch 017 lr: 0.1
2022-03-10 16:24:03 - train: epoch 0017, iter [00100, 05004], lr: 0.100000, loss: 3.5471, CELoss: 2.3146 KDLoss: 1.2325 
2022-03-10 16:24:37 - train: epoch 0017, iter [00200, 05004], lr: 0.100000, loss: 4.0707, CELoss: 2.6147 KDLoss: 1.4560 
2022-03-10 16:25:11 - train: epoch 0017, iter [00300, 05004], lr: 0.100000, loss: 3.8389, CELoss: 2.5778 KDLoss: 1.2611 
2022-03-10 16:25:44 - train: epoch 0017, iter [00400, 05004], lr: 0.100000, loss: 3.3770, CELoss: 2.1032 KDLoss: 1.2737 
2022-03-10 16:26:18 - train: epoch 0017, iter [00500, 05004], lr: 0.100000, loss: 3.4614, CELoss: 2.3226 KDLoss: 1.1388 
2022-03-10 16:26:51 - train: epoch 0017, iter [00600, 05004], lr: 0.100000, loss: 3.9372, CELoss: 2.5764 KDLoss: 1.3608 
2022-03-10 16:27:25 - train: epoch 0017, iter [00700, 05004], lr: 0.100000, loss: 3.5383, CELoss: 2.2944 KDLoss: 1.2439 
2022-03-10 16:27:59 - train: epoch 0017, iter [00800, 05004], lr: 0.100000, loss: 3.5062, CELoss: 2.2560 KDLoss: 1.2502 
2022-03-10 16:28:31 - train: epoch 0017, iter [00900, 05004], lr: 0.100000, loss: 3.5360, CELoss: 2.3056 KDLoss: 1.2304 
2022-03-10 16:29:05 - train: epoch 0017, iter [01000, 05004], lr: 0.100000, loss: 3.6721, CELoss: 2.3899 KDLoss: 1.2822 
2022-03-10 16:29:38 - train: epoch 0017, iter [01100, 05004], lr: 0.100000, loss: 3.7995, CELoss: 2.5360 KDLoss: 1.2636 
2022-03-10 16:30:12 - train: epoch 0017, iter [01200, 05004], lr: 0.100000, loss: 3.4214, CELoss: 2.1972 KDLoss: 1.2242 
2022-03-10 16:30:45 - train: epoch 0017, iter [01300, 05004], lr: 0.100000, loss: 3.7115, CELoss: 2.4446 KDLoss: 1.2668 
2022-03-10 16:31:19 - train: epoch 0017, iter [01400, 05004], lr: 0.100000, loss: 3.7078, CELoss: 2.4132 KDLoss: 1.2946 
2022-03-10 16:31:52 - train: epoch 0017, iter [01500, 05004], lr: 0.100000, loss: 3.3811, CELoss: 2.1673 KDLoss: 1.2138 
2022-03-10 16:32:25 - train: epoch 0017, iter [01600, 05004], lr: 0.100000, loss: 3.5419, CELoss: 2.3100 KDLoss: 1.2319 
2022-03-10 16:33:00 - train: epoch 0017, iter [01700, 05004], lr: 0.100000, loss: 3.5196, CELoss: 2.2434 KDLoss: 1.2762 
2022-03-10 16:33:32 - train: epoch 0017, iter [01800, 05004], lr: 0.100000, loss: 3.7745, CELoss: 2.4373 KDLoss: 1.3372 
2022-03-10 16:34:06 - train: epoch 0017, iter [01900, 05004], lr: 0.100000, loss: 3.4457, CELoss: 2.2529 KDLoss: 1.1928 
2022-03-10 16:34:38 - train: epoch 0017, iter [02000, 05004], lr: 0.100000, loss: 3.5513, CELoss: 2.3185 KDLoss: 1.2327 
2022-03-10 16:35:12 - train: epoch 0017, iter [02100, 05004], lr: 0.100000, loss: 3.5897, CELoss: 2.2708 KDLoss: 1.3190 
2022-03-10 16:35:46 - train: epoch 0017, iter [02200, 05004], lr: 0.100000, loss: 3.3414, CELoss: 2.1138 KDLoss: 1.2276 
2022-03-10 16:36:19 - train: epoch 0017, iter [02300, 05004], lr: 0.100000, loss: 3.6873, CELoss: 2.4260 KDLoss: 1.2613 
2022-03-10 16:36:52 - train: epoch 0017, iter [02400, 05004], lr: 0.100000, loss: 3.6865, CELoss: 2.3774 KDLoss: 1.3091 
2022-03-10 16:37:26 - train: epoch 0017, iter [02500, 05004], lr: 0.100000, loss: 3.8281, CELoss: 2.4961 KDLoss: 1.3320 
2022-03-10 16:37:59 - train: epoch 0017, iter [02600, 05004], lr: 0.100000, loss: 3.7010, CELoss: 2.4191 KDLoss: 1.2819 
2022-03-10 16:38:32 - train: epoch 0017, iter [02700, 05004], lr: 0.100000, loss: 3.5571, CELoss: 2.2721 KDLoss: 1.2850 
2022-03-10 16:39:05 - train: epoch 0017, iter [02800, 05004], lr: 0.100000, loss: 3.4974, CELoss: 2.2565 KDLoss: 1.2409 
2022-03-10 16:39:39 - train: epoch 0017, iter [02900, 05004], lr: 0.100000, loss: 3.8670, CELoss: 2.6321 KDLoss: 1.2348 
2022-03-10 16:40:11 - train: epoch 0017, iter [03000, 05004], lr: 0.100000, loss: 3.4974, CELoss: 2.3008 KDLoss: 1.1966 
2022-03-10 16:40:45 - train: epoch 0017, iter [03100, 05004], lr: 0.100000, loss: 3.3759, CELoss: 2.2487 KDLoss: 1.1271 
2022-03-10 16:41:18 - train: epoch 0017, iter [03200, 05004], lr: 0.100000, loss: 3.4765, CELoss: 2.1851 KDLoss: 1.2914 
2022-03-10 16:41:52 - train: epoch 0017, iter [03300, 05004], lr: 0.100000, loss: 3.4931, CELoss: 2.3915 KDLoss: 1.1016 
2022-03-10 16:42:25 - train: epoch 0017, iter [03400, 05004], lr: 0.100000, loss: 3.4583, CELoss: 2.2554 KDLoss: 1.2029 
2022-03-10 16:42:58 - train: epoch 0017, iter [03500, 05004], lr: 0.100000, loss: 3.7266, CELoss: 2.4088 KDLoss: 1.3178 
2022-03-10 16:43:31 - train: epoch 0017, iter [03600, 05004], lr: 0.100000, loss: 3.8818, CELoss: 2.5017 KDLoss: 1.3800 
2022-03-10 16:44:05 - train: epoch 0017, iter [03700, 05004], lr: 0.100000, loss: 3.5228, CELoss: 2.2688 KDLoss: 1.2540 
2022-03-10 16:44:39 - train: epoch 0017, iter [03800, 05004], lr: 0.100000, loss: 4.2509, CELoss: 2.7965 KDLoss: 1.4545 
2022-03-10 16:45:12 - train: epoch 0017, iter [03900, 05004], lr: 0.100000, loss: 3.3994, CELoss: 2.1632 KDLoss: 1.2362 
2022-03-10 16:45:45 - train: epoch 0017, iter [04000, 05004], lr: 0.100000, loss: 3.4539, CELoss: 2.3271 KDLoss: 1.1268 
2022-03-10 16:46:18 - train: epoch 0017, iter [04100, 05004], lr: 0.100000, loss: 3.8056, CELoss: 2.4485 KDLoss: 1.3571 
2022-03-10 16:46:52 - train: epoch 0017, iter [04200, 05004], lr: 0.100000, loss: 3.5620, CELoss: 2.3219 KDLoss: 1.2401 
2022-03-10 16:47:25 - train: epoch 0017, iter [04300, 05004], lr: 0.100000, loss: 3.4650, CELoss: 2.2055 KDLoss: 1.2595 
2022-03-10 16:47:59 - train: epoch 0017, iter [04400, 05004], lr: 0.100000, loss: 3.7173, CELoss: 2.4598 KDLoss: 1.2575 
2022-03-10 16:48:32 - train: epoch 0017, iter [04500, 05004], lr: 0.100000, loss: 3.8267, CELoss: 2.4605 KDLoss: 1.3662 
2022-03-10 16:49:05 - train: epoch 0017, iter [04600, 05004], lr: 0.100000, loss: 3.3094, CELoss: 2.1650 KDLoss: 1.1444 
2022-03-10 16:49:38 - train: epoch 0017, iter [04700, 05004], lr: 0.100000, loss: 3.6747, CELoss: 2.4414 KDLoss: 1.2333 
2022-03-10 16:50:10 - train: epoch 0017, iter [04800, 05004], lr: 0.100000, loss: 3.7571, CELoss: 2.4492 KDLoss: 1.3079 
2022-03-10 16:50:45 - train: epoch 0017, iter [04900, 05004], lr: 0.100000, loss: 3.6464, CELoss: 2.3878 KDLoss: 1.2586 
2022-03-10 16:51:16 - train: epoch 0017, iter [05000, 05004], lr: 0.100000, loss: 3.5135, CELoss: 2.2452 KDLoss: 1.2683 
2022-03-10 16:51:17 - train: epoch 017, train_loss: 3.5959
2022-03-10 16:53:45 - eval: epoch: 017, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 51.018%, stu_acc5: 76.248%, stu_test_loss: 2.1311
2022-03-10 16:53:46 - until epoch: 017, tea_best_acc1: 73.950%, stu_best_acc1: 51.684%
2022-03-10 16:53:46 - epoch 018 lr: 0.1
2022-03-10 16:54:24 - train: epoch 0018, iter [00100, 05004], lr: 0.100000, loss: 3.4316, CELoss: 2.1601 KDLoss: 1.2715 
2022-03-10 16:54:57 - train: epoch 0018, iter [00200, 05004], lr: 0.100000, loss: 4.0702, CELoss: 2.7067 KDLoss: 1.3635 
2022-03-10 16:55:31 - train: epoch 0018, iter [00300, 05004], lr: 0.100000, loss: 3.9881, CELoss: 2.5107 KDLoss: 1.4774 
2022-03-10 16:56:05 - train: epoch 0018, iter [00400, 05004], lr: 0.100000, loss: 3.8120, CELoss: 2.5075 KDLoss: 1.3044 
2022-03-10 16:56:38 - train: epoch 0018, iter [00500, 05004], lr: 0.100000, loss: 3.7877, CELoss: 2.3844 KDLoss: 1.4033 
2022-03-10 16:57:12 - train: epoch 0018, iter [00600, 05004], lr: 0.100000, loss: 3.4339, CELoss: 2.2818 KDLoss: 1.1521 
2022-03-10 16:57:44 - train: epoch 0018, iter [00700, 05004], lr: 0.100000, loss: 3.2992, CELoss: 2.1032 KDLoss: 1.1960 
2022-03-10 16:58:17 - train: epoch 0018, iter [00800, 05004], lr: 0.100000, loss: 3.6039, CELoss: 2.3295 KDLoss: 1.2744 
2022-03-10 16:58:51 - train: epoch 0018, iter [00900, 05004], lr: 0.100000, loss: 3.7908, CELoss: 2.5386 KDLoss: 1.2522 
2022-03-10 16:59:25 - train: epoch 0018, iter [01000, 05004], lr: 0.100000, loss: 3.4878, CELoss: 2.2313 KDLoss: 1.2564 
2022-03-10 16:59:58 - train: epoch 0018, iter [01100, 05004], lr: 0.100000, loss: 3.8020, CELoss: 2.4625 KDLoss: 1.3395 
2022-03-10 17:00:32 - train: epoch 0018, iter [01200, 05004], lr: 0.100000, loss: 3.3316, CELoss: 2.1390 KDLoss: 1.1926 
2022-03-10 17:01:05 - train: epoch 0018, iter [01300, 05004], lr: 0.100000, loss: 3.7138, CELoss: 2.4438 KDLoss: 1.2700 
2022-03-10 17:01:39 - train: epoch 0018, iter [01400, 05004], lr: 0.100000, loss: 3.6316, CELoss: 2.3866 KDLoss: 1.2450 
2022-03-10 17:02:12 - train: epoch 0018, iter [01500, 05004], lr: 0.100000, loss: 3.9374, CELoss: 2.5689 KDLoss: 1.3686 
2022-03-10 17:02:45 - train: epoch 0018, iter [01600, 05004], lr: 0.100000, loss: 3.7326, CELoss: 2.3729 KDLoss: 1.3597 
2022-03-10 17:03:19 - train: epoch 0018, iter [01700, 05004], lr: 0.100000, loss: 3.6803, CELoss: 2.4433 KDLoss: 1.2370 
2022-03-10 17:03:52 - train: epoch 0018, iter [01800, 05004], lr: 0.100000, loss: 3.3409, CELoss: 2.1881 KDLoss: 1.1529 
2022-03-10 17:04:27 - train: epoch 0018, iter [01900, 05004], lr: 0.100000, loss: 3.7659, CELoss: 2.4461 KDLoss: 1.3198 
2022-03-10 17:05:00 - train: epoch 0018, iter [02000, 05004], lr: 0.100000, loss: 3.9010, CELoss: 2.5768 KDLoss: 1.3242 
2022-03-10 17:05:34 - train: epoch 0018, iter [02100, 05004], lr: 0.100000, loss: 3.8371, CELoss: 2.4876 KDLoss: 1.3495 
2022-03-10 17:06:07 - train: epoch 0018, iter [02200, 05004], lr: 0.100000, loss: 3.6126, CELoss: 2.3047 KDLoss: 1.3079 
2022-03-10 17:06:41 - train: epoch 0018, iter [02300, 05004], lr: 0.100000, loss: 3.7682, CELoss: 2.4326 KDLoss: 1.3356 
2022-03-10 17:07:14 - train: epoch 0018, iter [02400, 05004], lr: 0.100000, loss: 3.3884, CELoss: 2.2760 KDLoss: 1.1124 
2022-03-10 17:07:48 - train: epoch 0018, iter [02500, 05004], lr: 0.100000, loss: 3.1040, CELoss: 1.9475 KDLoss: 1.1565 
2022-03-10 17:08:21 - train: epoch 0018, iter [02600, 05004], lr: 0.100000, loss: 3.3362, CELoss: 2.1156 KDLoss: 1.2206 
2022-03-10 17:08:54 - train: epoch 0018, iter [02700, 05004], lr: 0.100000, loss: 3.6006, CELoss: 2.4125 KDLoss: 1.1881 
2022-03-10 17:09:28 - train: epoch 0018, iter [02800, 05004], lr: 0.100000, loss: 3.3208, CELoss: 2.1121 KDLoss: 1.2087 
2022-03-10 17:10:02 - train: epoch 0018, iter [02900, 05004], lr: 0.100000, loss: 3.5376, CELoss: 2.3275 KDLoss: 1.2101 
2022-03-10 17:10:36 - train: epoch 0018, iter [03000, 05004], lr: 0.100000, loss: 3.7223, CELoss: 2.3984 KDLoss: 1.3239 
2022-03-10 17:11:09 - train: epoch 0018, iter [03100, 05004], lr: 0.100000, loss: 4.1927, CELoss: 2.8360 KDLoss: 1.3567 
2022-03-10 17:11:42 - train: epoch 0018, iter [03200, 05004], lr: 0.100000, loss: 3.7496, CELoss: 2.3965 KDLoss: 1.3531 
2022-03-10 17:12:15 - train: epoch 0018, iter [03300, 05004], lr: 0.100000, loss: 3.7284, CELoss: 2.3839 KDLoss: 1.3445 
2022-03-10 17:12:50 - train: epoch 0018, iter [03400, 05004], lr: 0.100000, loss: 3.7190, CELoss: 2.4710 KDLoss: 1.2480 
2022-03-10 17:13:23 - train: epoch 0018, iter [03500, 05004], lr: 0.100000, loss: 3.5363, CELoss: 2.3495 KDLoss: 1.1867 
2022-03-10 17:13:57 - train: epoch 0018, iter [03600, 05004], lr: 0.100000, loss: 3.4317, CELoss: 2.2501 KDLoss: 1.1816 
2022-03-10 17:14:30 - train: epoch 0018, iter [03700, 05004], lr: 0.100000, loss: 3.9287, CELoss: 2.5425 KDLoss: 1.3863 
2022-03-10 17:15:05 - train: epoch 0018, iter [03800, 05004], lr: 0.100000, loss: 3.7704, CELoss: 2.4619 KDLoss: 1.3086 
2022-03-10 17:15:38 - train: epoch 0018, iter [03900, 05004], lr: 0.100000, loss: 3.6682, CELoss: 2.4724 KDLoss: 1.1959 
2022-03-10 17:16:11 - train: epoch 0018, iter [04000, 05004], lr: 0.100000, loss: 3.6986, CELoss: 2.4622 KDLoss: 1.2364 
2022-03-10 17:16:45 - train: epoch 0018, iter [04100, 05004], lr: 0.100000, loss: 3.7958, CELoss: 2.6027 KDLoss: 1.1931 
2022-03-10 17:17:18 - train: epoch 0018, iter [04200, 05004], lr: 0.100000, loss: 3.5771, CELoss: 2.3181 KDLoss: 1.2590 
2022-03-10 17:17:51 - train: epoch 0018, iter [04300, 05004], lr: 0.100000, loss: 3.7004, CELoss: 2.4450 KDLoss: 1.2554 
2022-03-10 17:18:25 - train: epoch 0018, iter [04400, 05004], lr: 0.100000, loss: 3.4409, CELoss: 2.2212 KDLoss: 1.2197 
2022-03-10 17:18:58 - train: epoch 0018, iter [04500, 05004], lr: 0.100000, loss: 3.7415, CELoss: 2.4512 KDLoss: 1.2903 
2022-03-10 17:19:33 - train: epoch 0018, iter [04600, 05004], lr: 0.100000, loss: 3.6321, CELoss: 2.3676 KDLoss: 1.2644 
2022-03-10 17:20:06 - train: epoch 0018, iter [04700, 05004], lr: 0.100000, loss: 3.7443, CELoss: 2.4182 KDLoss: 1.3261 
2022-03-10 17:20:40 - train: epoch 0018, iter [04800, 05004], lr: 0.100000, loss: 3.4816, CELoss: 2.2634 KDLoss: 1.2182 
2022-03-10 17:21:13 - train: epoch 0018, iter [04900, 05004], lr: 0.100000, loss: 3.5281, CELoss: 2.2571 KDLoss: 1.2710 
2022-03-10 17:21:45 - train: epoch 0018, iter [05000, 05004], lr: 0.100000, loss: 3.6525, CELoss: 2.4190 KDLoss: 1.2335 
2022-03-10 17:21:46 - train: epoch 018, train_loss: 3.5793
2022-03-10 17:24:14 - eval: epoch: 018, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 46.968%, stu_acc5: 73.252%, stu_test_loss: 2.3596
2022-03-10 17:24:15 - until epoch: 018, tea_best_acc1: 73.950%, stu_best_acc1: 51.684%
2022-03-10 17:24:15 - epoch 019 lr: 0.1
2022-03-10 17:24:55 - train: epoch 0019, iter [00100, 05004], lr: 0.100000, loss: 3.1237, CELoss: 1.9972 KDLoss: 1.1265 
2022-03-10 17:25:26 - train: epoch 0019, iter [00200, 05004], lr: 0.100000, loss: 3.5031, CELoss: 2.2913 KDLoss: 1.2118 
2022-03-10 17:26:00 - train: epoch 0019, iter [00300, 05004], lr: 0.100000, loss: 3.5989, CELoss: 2.3976 KDLoss: 1.2013 
2022-03-10 17:26:33 - train: epoch 0019, iter [00400, 05004], lr: 0.100000, loss: 3.6239, CELoss: 2.3976 KDLoss: 1.2263 
2022-03-10 17:27:06 - train: epoch 0019, iter [00500, 05004], lr: 0.100000, loss: 3.3346, CELoss: 2.1698 KDLoss: 1.1648 
2022-03-10 17:27:41 - train: epoch 0019, iter [00600, 05004], lr: 0.100000, loss: 3.5598, CELoss: 2.3455 KDLoss: 1.2143 
2022-03-10 17:28:14 - train: epoch 0019, iter [00700, 05004], lr: 0.100000, loss: 3.5509, CELoss: 2.3339 KDLoss: 1.2170 
2022-03-10 17:28:47 - train: epoch 0019, iter [00800, 05004], lr: 0.100000, loss: 3.6934, CELoss: 2.4008 KDLoss: 1.2926 
2022-03-10 17:29:21 - train: epoch 0019, iter [00900, 05004], lr: 0.100000, loss: 3.5324, CELoss: 2.2760 KDLoss: 1.2564 
2022-03-10 17:29:54 - train: epoch 0019, iter [01000, 05004], lr: 0.100000, loss: 3.7600, CELoss: 2.5147 KDLoss: 1.2453 
2022-03-10 17:30:28 - train: epoch 0019, iter [01100, 05004], lr: 0.100000, loss: 3.5843, CELoss: 2.3463 KDLoss: 1.2381 
2022-03-10 17:31:01 - train: epoch 0019, iter [01200, 05004], lr: 0.100000, loss: 3.4425, CELoss: 2.2570 KDLoss: 1.1855 
2022-03-10 17:31:35 - train: epoch 0019, iter [01300, 05004], lr: 0.100000, loss: 3.5273, CELoss: 2.3604 KDLoss: 1.1668 
2022-03-10 17:32:08 - train: epoch 0019, iter [01400, 05004], lr: 0.100000, loss: 3.2245, CELoss: 2.0616 KDLoss: 1.1629 
2022-03-10 17:32:42 - train: epoch 0019, iter [01500, 05004], lr: 0.100000, loss: 4.0744, CELoss: 2.6517 KDLoss: 1.4227 
2022-03-10 17:33:15 - train: epoch 0019, iter [01600, 05004], lr: 0.100000, loss: 3.1894, CELoss: 2.0405 KDLoss: 1.1489 
2022-03-10 17:33:48 - train: epoch 0019, iter [01700, 05004], lr: 0.100000, loss: 3.8170, CELoss: 2.4753 KDLoss: 1.3417 
2022-03-10 17:34:22 - train: epoch 0019, iter [01800, 05004], lr: 0.100000, loss: 3.5238, CELoss: 2.3218 KDLoss: 1.2020 
2022-03-10 17:34:55 - train: epoch 0019, iter [01900, 05004], lr: 0.100000, loss: 3.7639, CELoss: 2.4419 KDLoss: 1.3220 
2022-03-10 17:35:28 - train: epoch 0019, iter [02000, 05004], lr: 0.100000, loss: 3.5698, CELoss: 2.2889 KDLoss: 1.2809 
2022-03-10 17:36:01 - train: epoch 0019, iter [02100, 05004], lr: 0.100000, loss: 3.6825, CELoss: 2.3523 KDLoss: 1.3302 
2022-03-10 17:36:35 - train: epoch 0019, iter [02200, 05004], lr: 0.100000, loss: 3.7638, CELoss: 2.4738 KDLoss: 1.2900 
2022-03-10 17:37:09 - train: epoch 0019, iter [02300, 05004], lr: 0.100000, loss: 3.5697, CELoss: 2.2916 KDLoss: 1.2781 
2022-03-10 17:37:43 - train: epoch 0019, iter [02400, 05004], lr: 0.100000, loss: 3.9306, CELoss: 2.5621 KDLoss: 1.3685 
2022-03-10 17:38:16 - train: epoch 0019, iter [02500, 05004], lr: 0.100000, loss: 3.5744, CELoss: 2.3711 KDLoss: 1.2033 
2022-03-10 17:38:50 - train: epoch 0019, iter [02600, 05004], lr: 0.100000, loss: 3.3776, CELoss: 2.1877 KDLoss: 1.1899 
2022-03-10 17:39:22 - train: epoch 0019, iter [02700, 05004], lr: 0.100000, loss: 3.6474, CELoss: 2.3130 KDLoss: 1.3344 
2022-03-10 17:39:56 - train: epoch 0019, iter [02800, 05004], lr: 0.100000, loss: 3.3273, CELoss: 2.1659 KDLoss: 1.1615 
2022-03-10 17:40:30 - train: epoch 0019, iter [02900, 05004], lr: 0.100000, loss: 3.6165, CELoss: 2.3835 KDLoss: 1.2329 
2022-03-10 17:41:03 - train: epoch 0019, iter [03000, 05004], lr: 0.100000, loss: 4.0237, CELoss: 2.5790 KDLoss: 1.4446 
2022-03-10 17:41:37 - train: epoch 0019, iter [03100, 05004], lr: 0.100000, loss: 3.4080, CELoss: 2.2345 KDLoss: 1.1734 
2022-03-10 17:42:09 - train: epoch 0019, iter [03200, 05004], lr: 0.100000, loss: 3.1938, CELoss: 2.1182 KDLoss: 1.0755 
2022-03-10 17:42:43 - train: epoch 0019, iter [03300, 05004], lr: 0.100000, loss: 3.4569, CELoss: 2.2616 KDLoss: 1.1953 
2022-03-10 17:43:18 - train: epoch 0019, iter [03400, 05004], lr: 0.100000, loss: 3.7380, CELoss: 2.4033 KDLoss: 1.3348 
2022-03-10 17:43:50 - train: epoch 0019, iter [03500, 05004], lr: 0.100000, loss: 3.9367, CELoss: 2.5855 KDLoss: 1.3512 
2022-03-10 17:44:24 - train: epoch 0019, iter [03600, 05004], lr: 0.100000, loss: 3.2315, CELoss: 2.0723 KDLoss: 1.1592 
2022-03-10 17:44:57 - train: epoch 0019, iter [03700, 05004], lr: 0.100000, loss: 3.5912, CELoss: 2.4009 KDLoss: 1.1903 
2022-03-10 17:45:31 - train: epoch 0019, iter [03800, 05004], lr: 0.100000, loss: 3.8458, CELoss: 2.4765 KDLoss: 1.3693 
2022-03-10 17:46:04 - train: epoch 0019, iter [03900, 05004], lr: 0.100000, loss: 3.5369, CELoss: 2.2928 KDLoss: 1.2441 
2022-03-10 17:46:38 - train: epoch 0019, iter [04000, 05004], lr: 0.100000, loss: 3.3230, CELoss: 2.2051 KDLoss: 1.1179 
2022-03-10 17:47:10 - train: epoch 0019, iter [04100, 05004], lr: 0.100000, loss: 3.7168, CELoss: 2.4760 KDLoss: 1.2408 
2022-03-10 17:47:44 - train: epoch 0019, iter [04200, 05004], lr: 0.100000, loss: 3.6364, CELoss: 2.3612 KDLoss: 1.2752 
2022-03-10 17:48:17 - train: epoch 0019, iter [04300, 05004], lr: 0.100000, loss: 3.4504, CELoss: 2.2485 KDLoss: 1.2019 
2022-03-10 17:48:51 - train: epoch 0019, iter [04400, 05004], lr: 0.100000, loss: 3.7979, CELoss: 2.4905 KDLoss: 1.3074 
2022-03-10 17:49:23 - train: epoch 0019, iter [04500, 05004], lr: 0.100000, loss: 3.8175, CELoss: 2.5896 KDLoss: 1.2278 
2022-03-10 17:49:57 - train: epoch 0019, iter [04600, 05004], lr: 0.100000, loss: 3.4531, CELoss: 2.2532 KDLoss: 1.1999 
2022-03-10 17:50:30 - train: epoch 0019, iter [04700, 05004], lr: 0.100000, loss: 3.4641, CELoss: 2.2331 KDLoss: 1.2310 
2022-03-10 17:51:04 - train: epoch 0019, iter [04800, 05004], lr: 0.100000, loss: 3.5272, CELoss: 2.3638 KDLoss: 1.1633 
2022-03-10 17:51:36 - train: epoch 0019, iter [04900, 05004], lr: 0.100000, loss: 3.3560, CELoss: 2.2310 KDLoss: 1.1250 
2022-03-10 17:52:08 - train: epoch 0019, iter [05000, 05004], lr: 0.100000, loss: 3.4845, CELoss: 2.2457 KDLoss: 1.2388 
2022-03-10 17:52:09 - train: epoch 019, train_loss: 3.5685
2022-03-10 17:54:37 - eval: epoch: 019, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 50.884%, stu_acc5: 76.616%, stu_test_loss: 2.1229
2022-03-10 17:54:37 - until epoch: 019, tea_best_acc1: 73.950%, stu_best_acc1: 51.684%
2022-03-10 17:54:37 - epoch 020 lr: 0.1
2022-03-10 17:55:16 - train: epoch 0020, iter [00100, 05004], lr: 0.100000, loss: 3.6266, CELoss: 2.4054 KDLoss: 1.2212 
2022-03-10 17:55:50 - train: epoch 0020, iter [00200, 05004], lr: 0.100000, loss: 3.0941, CELoss: 2.0608 KDLoss: 1.0333 
2022-03-10 17:56:23 - train: epoch 0020, iter [00300, 05004], lr: 0.100000, loss: 3.4064, CELoss: 2.2039 KDLoss: 1.2025 
2022-03-10 17:56:56 - train: epoch 0020, iter [00400, 05004], lr: 0.100000, loss: 3.4120, CELoss: 2.1724 KDLoss: 1.2396 
2022-03-10 17:57:31 - train: epoch 0020, iter [00500, 05004], lr: 0.100000, loss: 3.4158, CELoss: 2.2156 KDLoss: 1.2002 
2022-03-10 17:58:02 - train: epoch 0020, iter [00600, 05004], lr: 0.100000, loss: 3.4669, CELoss: 2.2790 KDLoss: 1.1878 
2022-03-10 17:58:36 - train: epoch 0020, iter [00700, 05004], lr: 0.100000, loss: 3.2844, CELoss: 2.1057 KDLoss: 1.1786 
2022-03-10 17:59:10 - train: epoch 0020, iter [00800, 05004], lr: 0.100000, loss: 3.7416, CELoss: 2.4148 KDLoss: 1.3268 
2022-03-10 17:59:43 - train: epoch 0020, iter [00900, 05004], lr: 0.100000, loss: 3.6848, CELoss: 2.3845 KDLoss: 1.3002 
2022-03-10 18:00:17 - train: epoch 0020, iter [01000, 05004], lr: 0.100000, loss: 3.7170, CELoss: 2.4876 KDLoss: 1.2294 
2022-03-10 18:00:51 - train: epoch 0020, iter [01100, 05004], lr: 0.100000, loss: 3.4051, CELoss: 2.1827 KDLoss: 1.2223 
2022-03-10 18:01:24 - train: epoch 0020, iter [01200, 05004], lr: 0.100000, loss: 3.3710, CELoss: 2.1447 KDLoss: 1.2263 
2022-03-10 18:01:58 - train: epoch 0020, iter [01300, 05004], lr: 0.100000, loss: 3.6136, CELoss: 2.3873 KDLoss: 1.2263 
2022-03-10 18:02:31 - train: epoch 0020, iter [01400, 05004], lr: 0.100000, loss: 3.5437, CELoss: 2.2869 KDLoss: 1.2568 
2022-03-10 18:03:05 - train: epoch 0020, iter [01500, 05004], lr: 0.100000, loss: 3.5618, CELoss: 2.2745 KDLoss: 1.2873 
2022-03-10 18:03:39 - train: epoch 0020, iter [01600, 05004], lr: 0.100000, loss: 3.6237, CELoss: 2.3809 KDLoss: 1.2428 
2022-03-10 18:04:12 - train: epoch 0020, iter [01700, 05004], lr: 0.100000, loss: 3.4393, CELoss: 2.2520 KDLoss: 1.1872 
2022-03-10 18:04:46 - train: epoch 0020, iter [01800, 05004], lr: 0.100000, loss: 3.7155, CELoss: 2.4091 KDLoss: 1.3064 
2022-03-10 18:05:19 - train: epoch 0020, iter [01900, 05004], lr: 0.100000, loss: 3.4076, CELoss: 2.2051 KDLoss: 1.2025 
2022-03-10 18:05:53 - train: epoch 0020, iter [02000, 05004], lr: 0.100000, loss: 3.3338, CELoss: 2.1707 KDLoss: 1.1631 
2022-03-10 18:06:26 - train: epoch 0020, iter [02100, 05004], lr: 0.100000, loss: 4.0541, CELoss: 2.6536 KDLoss: 1.4005 
2022-03-10 18:06:59 - train: epoch 0020, iter [02200, 05004], lr: 0.100000, loss: 3.4803, CELoss: 2.2234 KDLoss: 1.2570 
2022-03-10 18:07:33 - train: epoch 0020, iter [02300, 05004], lr: 0.100000, loss: 3.3178, CELoss: 2.2114 KDLoss: 1.1064 
2022-03-10 18:08:07 - train: epoch 0020, iter [02400, 05004], lr: 0.100000, loss: 3.7490, CELoss: 2.5077 KDLoss: 1.2413 
2022-03-10 18:08:40 - train: epoch 0020, iter [02500, 05004], lr: 0.100000, loss: 3.4771, CELoss: 2.2700 KDLoss: 1.2071 
2022-03-10 18:09:13 - train: epoch 0020, iter [02600, 05004], lr: 0.100000, loss: 3.6843, CELoss: 2.3824 KDLoss: 1.3019 
2022-03-10 18:09:46 - train: epoch 0020, iter [02700, 05004], lr: 0.100000, loss: 3.4516, CELoss: 2.2298 KDLoss: 1.2217 
2022-03-10 18:10:20 - train: epoch 0020, iter [02800, 05004], lr: 0.100000, loss: 3.7242, CELoss: 2.4359 KDLoss: 1.2883 
2022-03-10 18:10:52 - train: epoch 0020, iter [02900, 05004], lr: 0.100000, loss: 3.6843, CELoss: 2.3991 KDLoss: 1.2852 
2022-03-10 18:11:27 - train: epoch 0020, iter [03000, 05004], lr: 0.100000, loss: 3.9335, CELoss: 2.5506 KDLoss: 1.3829 
2022-03-10 18:11:59 - train: epoch 0020, iter [03100, 05004], lr: 0.100000, loss: 3.5828, CELoss: 2.3138 KDLoss: 1.2690 
2022-03-10 18:12:33 - train: epoch 0020, iter [03200, 05004], lr: 0.100000, loss: 3.4775, CELoss: 2.2456 KDLoss: 1.2319 
2022-03-10 18:13:06 - train: epoch 0020, iter [03300, 05004], lr: 0.100000, loss: 3.4059, CELoss: 2.1683 KDLoss: 1.2375 
2022-03-10 18:13:39 - train: epoch 0020, iter [03400, 05004], lr: 0.100000, loss: 3.6058, CELoss: 2.3041 KDLoss: 1.3017 
2022-03-10 18:14:13 - train: epoch 0020, iter [03500, 05004], lr: 0.100000, loss: 3.0885, CELoss: 1.9813 KDLoss: 1.1071 
2022-03-10 18:14:46 - train: epoch 0020, iter [03600, 05004], lr: 0.100000, loss: 3.3636, CELoss: 2.2190 KDLoss: 1.1446 
2022-03-10 18:15:19 - train: epoch 0020, iter [03700, 05004], lr: 0.100000, loss: 3.6687, CELoss: 2.3513 KDLoss: 1.3174 
2022-03-10 18:15:53 - train: epoch 0020, iter [03800, 05004], lr: 0.100000, loss: 3.5788, CELoss: 2.2800 KDLoss: 1.2988 
2022-03-10 18:16:26 - train: epoch 0020, iter [03900, 05004], lr: 0.100000, loss: 3.6320, CELoss: 2.3644 KDLoss: 1.2675 
2022-03-10 18:17:00 - train: epoch 0020, iter [04000, 05004], lr: 0.100000, loss: 3.4938, CELoss: 2.2457 KDLoss: 1.2481 
2022-03-10 18:17:33 - train: epoch 0020, iter [04100, 05004], lr: 0.100000, loss: 3.7082, CELoss: 2.4171 KDLoss: 1.2911 
2022-03-10 18:18:07 - train: epoch 0020, iter [04200, 05004], lr: 0.100000, loss: 3.3653, CELoss: 2.2433 KDLoss: 1.1220 
2022-03-10 18:18:39 - train: epoch 0020, iter [04300, 05004], lr: 0.100000, loss: 3.8771, CELoss: 2.5545 KDLoss: 1.3226 
2022-03-10 18:19:13 - train: epoch 0020, iter [04400, 05004], lr: 0.100000, loss: 3.5925, CELoss: 2.3142 KDLoss: 1.2783 
2022-03-10 18:19:46 - train: epoch 0020, iter [04500, 05004], lr: 0.100000, loss: 3.5949, CELoss: 2.3459 KDLoss: 1.2490 
2022-03-10 18:20:21 - train: epoch 0020, iter [04600, 05004], lr: 0.100000, loss: 3.4329, CELoss: 2.2627 KDLoss: 1.1702 
2022-03-10 18:20:53 - train: epoch 0020, iter [04700, 05004], lr: 0.100000, loss: 3.4768, CELoss: 2.2078 KDLoss: 1.2690 
2022-03-10 18:21:26 - train: epoch 0020, iter [04800, 05004], lr: 0.100000, loss: 3.2927, CELoss: 2.1802 KDLoss: 1.1125 
2022-03-10 18:22:00 - train: epoch 0020, iter [04900, 05004], lr: 0.100000, loss: 3.7380, CELoss: 2.4205 KDLoss: 1.3174 
2022-03-10 18:22:32 - train: epoch 0020, iter [05000, 05004], lr: 0.100000, loss: 3.3241, CELoss: 2.1652 KDLoss: 1.1589 
2022-03-10 18:22:32 - train: epoch 020, train_loss: 3.5559
2022-03-10 18:25:00 - eval: epoch: 020, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 51.104%, stu_acc5: 76.358%, stu_test_loss: 2.1274
2022-03-10 18:25:01 - until epoch: 020, tea_best_acc1: 73.950%, stu_best_acc1: 51.684%
2022-03-10 18:25:01 - epoch 021 lr: 0.1
2022-03-10 18:25:39 - train: epoch 0021, iter [00100, 05004], lr: 0.100000, loss: 3.4819, CELoss: 2.2669 KDLoss: 1.2150 
2022-03-10 18:26:12 - train: epoch 0021, iter [00200, 05004], lr: 0.100000, loss: 3.6065, CELoss: 2.3282 KDLoss: 1.2783 
2022-03-10 18:26:46 - train: epoch 0021, iter [00300, 05004], lr: 0.100000, loss: 3.2215, CELoss: 2.0636 KDLoss: 1.1578 
2022-03-10 18:27:20 - train: epoch 0021, iter [00400, 05004], lr: 0.100000, loss: 3.5408, CELoss: 2.3367 KDLoss: 1.2041 
2022-03-10 18:27:53 - train: epoch 0021, iter [00500, 05004], lr: 0.100000, loss: 3.1651, CELoss: 2.0325 KDLoss: 1.1326 
2022-03-10 18:28:27 - train: epoch 0021, iter [00600, 05004], lr: 0.100000, loss: 3.2012, CELoss: 2.0789 KDLoss: 1.1224 
2022-03-10 18:29:00 - train: epoch 0021, iter [00700, 05004], lr: 0.100000, loss: 3.2093, CELoss: 2.0718 KDLoss: 1.1375 
2022-03-10 18:29:34 - train: epoch 0021, iter [00800, 05004], lr: 0.100000, loss: 3.4675, CELoss: 2.2708 KDLoss: 1.1967 
2022-03-10 18:30:07 - train: epoch 0021, iter [00900, 05004], lr: 0.100000, loss: 3.4760, CELoss: 2.2409 KDLoss: 1.2351 
2022-03-10 18:30:41 - train: epoch 0021, iter [01000, 05004], lr: 0.100000, loss: 3.4206, CELoss: 2.2133 KDLoss: 1.2073 
2022-03-10 18:31:14 - train: epoch 0021, iter [01100, 05004], lr: 0.100000, loss: 3.4770, CELoss: 2.2931 KDLoss: 1.1839 
2022-03-10 18:31:48 - train: epoch 0021, iter [01200, 05004], lr: 0.100000, loss: 3.3445, CELoss: 2.2112 KDLoss: 1.1333 
2022-03-10 18:32:22 - train: epoch 0021, iter [01300, 05004], lr: 0.100000, loss: 3.2453, CELoss: 2.1500 KDLoss: 1.0953 
2022-03-10 18:32:56 - train: epoch 0021, iter [01400, 05004], lr: 0.100000, loss: 3.1314, CELoss: 1.9648 KDLoss: 1.1666 
2022-03-10 18:33:28 - train: epoch 0021, iter [01500, 05004], lr: 0.100000, loss: 3.5026, CELoss: 2.3216 KDLoss: 1.1810 
2022-03-10 18:34:02 - train: epoch 0021, iter [01600, 05004], lr: 0.100000, loss: 3.5231, CELoss: 2.3265 KDLoss: 1.1965 
2022-03-10 18:34:37 - train: epoch 0021, iter [01700, 05004], lr: 0.100000, loss: 3.6482, CELoss: 2.4545 KDLoss: 1.1937 
2022-03-10 18:35:10 - train: epoch 0021, iter [01800, 05004], lr: 0.100000, loss: 3.5417, CELoss: 2.3434 KDLoss: 1.1982 
2022-03-10 18:35:44 - train: epoch 0021, iter [01900, 05004], lr: 0.100000, loss: 3.8633, CELoss: 2.5730 KDLoss: 1.2903 
2022-03-10 18:36:16 - train: epoch 0021, iter [02000, 05004], lr: 0.100000, loss: 3.7174, CELoss: 2.3872 KDLoss: 1.3302 
2022-03-10 18:36:50 - train: epoch 0021, iter [02100, 05004], lr: 0.100000, loss: 3.1623, CELoss: 2.0638 KDLoss: 1.0986 
2022-03-10 18:37:24 - train: epoch 0021, iter [02200, 05004], lr: 0.100000, loss: 3.9307, CELoss: 2.5110 KDLoss: 1.4198 
2022-03-10 18:37:57 - train: epoch 0021, iter [02300, 05004], lr: 0.100000, loss: 3.8247, CELoss: 2.5203 KDLoss: 1.3045 
2022-03-10 18:38:30 - train: epoch 0021, iter [02400, 05004], lr: 0.100000, loss: 3.1588, CELoss: 2.0899 KDLoss: 1.0689 
2022-03-10 18:39:04 - train: epoch 0021, iter [02500, 05004], lr: 0.100000, loss: 3.4308, CELoss: 2.2358 KDLoss: 1.1950 
2022-03-10 18:39:37 - train: epoch 0021, iter [02600, 05004], lr: 0.100000, loss: 3.6393, CELoss: 2.4146 KDLoss: 1.2247 
2022-03-10 18:40:11 - train: epoch 0021, iter [02700, 05004], lr: 0.100000, loss: 3.2392, CELoss: 1.9875 KDLoss: 1.2516 
2022-03-10 18:40:44 - train: epoch 0021, iter [02800, 05004], lr: 0.100000, loss: 3.5799, CELoss: 2.3080 KDLoss: 1.2720 
2022-03-10 18:41:17 - train: epoch 0021, iter [02900, 05004], lr: 0.100000, loss: 3.5826, CELoss: 2.3229 KDLoss: 1.2597 
2022-03-10 18:41:50 - train: epoch 0021, iter [03000, 05004], lr: 0.100000, loss: 4.0653, CELoss: 2.6119 KDLoss: 1.4534 
2022-03-10 18:42:24 - train: epoch 0021, iter [03100, 05004], lr: 0.100000, loss: 3.6802, CELoss: 2.3996 KDLoss: 1.2806 
2022-03-10 18:42:58 - train: epoch 0021, iter [03200, 05004], lr: 0.100000, loss: 3.2122, CELoss: 2.0901 KDLoss: 1.1221 
2022-03-10 18:43:30 - train: epoch 0021, iter [03300, 05004], lr: 0.100000, loss: 3.9866, CELoss: 2.6408 KDLoss: 1.3458 
2022-03-10 18:44:03 - train: epoch 0021, iter [03400, 05004], lr: 0.100000, loss: 3.7086, CELoss: 2.4907 KDLoss: 1.2179 
2022-03-10 18:44:38 - train: epoch 0021, iter [03500, 05004], lr: 0.100000, loss: 3.8295, CELoss: 2.4688 KDLoss: 1.3607 
2022-03-10 18:45:11 - train: epoch 0021, iter [03600, 05004], lr: 0.100000, loss: 3.8147, CELoss: 2.4588 KDLoss: 1.3560 
2022-03-10 18:45:44 - train: epoch 0021, iter [03700, 05004], lr: 0.100000, loss: 3.4741, CELoss: 2.2244 KDLoss: 1.2496 
2022-03-10 18:46:17 - train: epoch 0021, iter [03800, 05004], lr: 0.100000, loss: 3.5461, CELoss: 2.3094 KDLoss: 1.2367 
2022-03-10 18:46:52 - train: epoch 0021, iter [03900, 05004], lr: 0.100000, loss: 3.4374, CELoss: 2.2194 KDLoss: 1.2180 
2022-03-10 18:47:24 - train: epoch 0021, iter [04000, 05004], lr: 0.100000, loss: 3.6869, CELoss: 2.4608 KDLoss: 1.2261 
2022-03-10 18:47:59 - train: epoch 0021, iter [04100, 05004], lr: 0.100000, loss: 3.2733, CELoss: 2.1043 KDLoss: 1.1690 
2022-03-10 18:48:31 - train: epoch 0021, iter [04200, 05004], lr: 0.100000, loss: 3.8387, CELoss: 2.4460 KDLoss: 1.3927 
2022-03-10 18:49:05 - train: epoch 0021, iter [04300, 05004], lr: 0.100000, loss: 3.9086, CELoss: 2.5435 KDLoss: 1.3651 
2022-03-10 18:49:39 - train: epoch 0021, iter [04400, 05004], lr: 0.100000, loss: 3.7818, CELoss: 2.4440 KDLoss: 1.3378 
2022-03-10 18:50:13 - train: epoch 0021, iter [04500, 05004], lr: 0.100000, loss: 3.4748, CELoss: 2.3079 KDLoss: 1.1669 
2022-03-10 18:50:46 - train: epoch 0021, iter [04600, 05004], lr: 0.100000, loss: 3.6546, CELoss: 2.3944 KDLoss: 1.2602 
2022-03-10 18:51:19 - train: epoch 0021, iter [04700, 05004], lr: 0.100000, loss: 3.4856, CELoss: 2.3271 KDLoss: 1.1585 
2022-03-10 18:51:53 - train: epoch 0021, iter [04800, 05004], lr: 0.100000, loss: 3.7028, CELoss: 2.4362 KDLoss: 1.2665 
2022-03-10 18:52:26 - train: epoch 0021, iter [04900, 05004], lr: 0.100000, loss: 3.3255, CELoss: 2.1005 KDLoss: 1.2250 
2022-03-10 18:52:58 - train: epoch 0021, iter [05000, 05004], lr: 0.100000, loss: 3.4624, CELoss: 2.2296 KDLoss: 1.2328 
2022-03-10 18:52:59 - train: epoch 021, train_loss: 3.5495
2022-03-10 18:55:27 - eval: epoch: 021, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 50.780%, stu_acc5: 76.424%, stu_test_loss: 2.1222
2022-03-10 18:55:28 - until epoch: 021, tea_best_acc1: 73.950%, stu_best_acc1: 51.684%
2022-03-10 18:55:28 - epoch 022 lr: 0.1
2022-03-10 18:56:07 - train: epoch 0022, iter [00100, 05004], lr: 0.100000, loss: 3.1893, CELoss: 2.0430 KDLoss: 1.1463 
2022-03-10 18:56:40 - train: epoch 0022, iter [00200, 05004], lr: 0.100000, loss: 3.2946, CELoss: 2.2156 KDLoss: 1.0790 
2022-03-10 18:57:13 - train: epoch 0022, iter [00300, 05004], lr: 0.100000, loss: 3.3756, CELoss: 2.1891 KDLoss: 1.1865 
2022-03-10 18:57:47 - train: epoch 0022, iter [00400, 05004], lr: 0.100000, loss: 3.3278, CELoss: 2.1702 KDLoss: 1.1576 
2022-03-10 18:58:20 - train: epoch 0022, iter [00500, 05004], lr: 0.100000, loss: 3.3674, CELoss: 2.2229 KDLoss: 1.1445 
2022-03-10 18:58:54 - train: epoch 0022, iter [00600, 05004], lr: 0.100000, loss: 3.7313, CELoss: 2.4637 KDLoss: 1.2677 
2022-03-10 18:59:28 - train: epoch 0022, iter [00700, 05004], lr: 0.100000, loss: 3.6995, CELoss: 2.4405 KDLoss: 1.2590 
2022-03-10 19:00:01 - train: epoch 0022, iter [00800, 05004], lr: 0.100000, loss: 3.8234, CELoss: 2.5089 KDLoss: 1.3145 
2022-03-10 19:00:35 - train: epoch 0022, iter [00900, 05004], lr: 0.100000, loss: 3.6299, CELoss: 2.3603 KDLoss: 1.2696 
2022-03-10 19:01:08 - train: epoch 0022, iter [01000, 05004], lr: 0.100000, loss: 3.7475, CELoss: 2.4675 KDLoss: 1.2800 
2022-03-10 19:01:42 - train: epoch 0022, iter [01100, 05004], lr: 0.100000, loss: 3.3390, CELoss: 2.1595 KDLoss: 1.1795 
2022-03-10 19:02:16 - train: epoch 0022, iter [01200, 05004], lr: 0.100000, loss: 2.9844, CELoss: 1.9206 KDLoss: 1.0638 
2022-03-10 19:02:50 - train: epoch 0022, iter [01300, 05004], lr: 0.100000, loss: 3.8058, CELoss: 2.4470 KDLoss: 1.3587 
2022-03-10 19:03:23 - train: epoch 0022, iter [01400, 05004], lr: 0.100000, loss: 3.3974, CELoss: 2.1320 KDLoss: 1.2654 
2022-03-10 19:03:56 - train: epoch 0022, iter [01500, 05004], lr: 0.100000, loss: 3.6781, CELoss: 2.4716 KDLoss: 1.2065 
2022-03-10 19:04:30 - train: epoch 0022, iter [01600, 05004], lr: 0.100000, loss: 3.5255, CELoss: 2.2802 KDLoss: 1.2453 
2022-03-10 19:05:03 - train: epoch 0022, iter [01700, 05004], lr: 0.100000, loss: 3.6545, CELoss: 2.4425 KDLoss: 1.2120 
2022-03-10 19:05:37 - train: epoch 0022, iter [01800, 05004], lr: 0.100000, loss: 3.6125, CELoss: 2.3408 KDLoss: 1.2717 
2022-03-10 19:06:11 - train: epoch 0022, iter [01900, 05004], lr: 0.100000, loss: 3.7467, CELoss: 2.3979 KDLoss: 1.3489 
2022-03-10 19:06:45 - train: epoch 0022, iter [02000, 05004], lr: 0.100000, loss: 3.2516, CELoss: 2.1005 KDLoss: 1.1511 
2022-03-10 19:07:18 - train: epoch 0022, iter [02100, 05004], lr: 0.100000, loss: 3.2171, CELoss: 2.1541 KDLoss: 1.0630 
2022-03-10 19:07:52 - train: epoch 0022, iter [02200, 05004], lr: 0.100000, loss: 3.0944, CELoss: 1.9806 KDLoss: 1.1137 
2022-03-10 19:08:25 - train: epoch 0022, iter [02300, 05004], lr: 0.100000, loss: 3.7754, CELoss: 2.4274 KDLoss: 1.3479 
2022-03-10 19:08:59 - train: epoch 0022, iter [02400, 05004], lr: 0.100000, loss: 3.7302, CELoss: 2.4921 KDLoss: 1.2380 
2022-03-10 19:09:33 - train: epoch 0022, iter [02500, 05004], lr: 0.100000, loss: 3.4622, CELoss: 2.2771 KDLoss: 1.1851 
2022-03-10 19:10:05 - train: epoch 0022, iter [02600, 05004], lr: 0.100000, loss: 3.4883, CELoss: 2.2586 KDLoss: 1.2297 
2022-03-10 19:10:38 - train: epoch 0022, iter [02700, 05004], lr: 0.100000, loss: 3.4989, CELoss: 2.2616 KDLoss: 1.2373 
2022-03-10 19:11:11 - train: epoch 0022, iter [02800, 05004], lr: 0.100000, loss: 3.7359, CELoss: 2.4328 KDLoss: 1.3032 
2022-03-10 19:11:44 - train: epoch 0022, iter [02900, 05004], lr: 0.100000, loss: 3.6479, CELoss: 2.2861 KDLoss: 1.3618 
2022-03-10 19:12:17 - train: epoch 0022, iter [03000, 05004], lr: 0.100000, loss: 3.5606, CELoss: 2.3317 KDLoss: 1.2289 
2022-03-10 19:12:49 - train: epoch 0022, iter [03100, 05004], lr: 0.100000, loss: 3.8064, CELoss: 2.4724 KDLoss: 1.3340 
2022-03-10 19:13:23 - train: epoch 0022, iter [03200, 05004], lr: 0.100000, loss: 3.4193, CELoss: 2.2740 KDLoss: 1.1453 
2022-03-10 19:13:55 - train: epoch 0022, iter [03300, 05004], lr: 0.100000, loss: 3.5576, CELoss: 2.3313 KDLoss: 1.2263 
2022-03-10 19:14:28 - train: epoch 0022, iter [03400, 05004], lr: 0.100000, loss: 3.6314, CELoss: 2.3627 KDLoss: 1.2688 
2022-03-10 19:14:59 - train: epoch 0022, iter [03500, 05004], lr: 0.100000, loss: 3.6122, CELoss: 2.3769 KDLoss: 1.2352 
2022-03-10 19:15:32 - train: epoch 0022, iter [03600, 05004], lr: 0.100000, loss: 3.5039, CELoss: 2.2658 KDLoss: 1.2381 
2022-03-10 19:16:03 - train: epoch 0022, iter [03700, 05004], lr: 0.100000, loss: 3.7666, CELoss: 2.3818 KDLoss: 1.3847 
2022-03-10 19:16:35 - train: epoch 0022, iter [03800, 05004], lr: 0.100000, loss: 3.7911, CELoss: 2.4917 KDLoss: 1.2995 
2022-03-10 19:17:07 - train: epoch 0022, iter [03900, 05004], lr: 0.100000, loss: 3.6239, CELoss: 2.3442 KDLoss: 1.2797 
2022-03-10 19:17:39 - train: epoch 0022, iter [04000, 05004], lr: 0.100000, loss: 3.4151, CELoss: 2.2991 KDLoss: 1.1160 
2022-03-10 19:18:10 - train: epoch 0022, iter [04100, 05004], lr: 0.100000, loss: 3.6644, CELoss: 2.4017 KDLoss: 1.2627 
2022-03-10 19:18:41 - train: epoch 0022, iter [04200, 05004], lr: 0.100000, loss: 3.6143, CELoss: 2.3777 KDLoss: 1.2365 
2022-03-10 19:19:14 - train: epoch 0022, iter [04300, 05004], lr: 0.100000, loss: 3.4557, CELoss: 2.2459 KDLoss: 1.2098 
2022-03-10 19:19:47 - train: epoch 0022, iter [04400, 05004], lr: 0.100000, loss: 3.5165, CELoss: 2.2555 KDLoss: 1.2610 
2022-03-10 19:20:20 - train: epoch 0022, iter [04500, 05004], lr: 0.100000, loss: 3.3436, CELoss: 2.1897 KDLoss: 1.1540 
2022-03-10 19:20:54 - train: epoch 0022, iter [04600, 05004], lr: 0.100000, loss: 3.7808, CELoss: 2.5321 KDLoss: 1.2487 
2022-03-10 19:21:27 - train: epoch 0022, iter [04700, 05004], lr: 0.100000, loss: 3.5430, CELoss: 2.3922 KDLoss: 1.1508 
2022-03-10 19:22:00 - train: epoch 0022, iter [04800, 05004], lr: 0.100000, loss: 3.0470, CELoss: 1.9437 KDLoss: 1.1033 
2022-03-10 19:22:33 - train: epoch 0022, iter [04900, 05004], lr: 0.100000, loss: 3.4711, CELoss: 2.3033 KDLoss: 1.1678 
2022-03-10 19:23:05 - train: epoch 0022, iter [05000, 05004], lr: 0.100000, loss: 3.3239, CELoss: 2.1074 KDLoss: 1.2165 
2022-03-10 19:23:06 - train: epoch 022, train_loss: 3.5379
2022-03-10 19:25:34 - eval: epoch: 022, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 49.794%, stu_acc5: 75.402%, stu_test_loss: 2.1972
2022-03-10 19:25:35 - until epoch: 022, tea_best_acc1: 73.950%, stu_best_acc1: 51.684%
2022-03-10 19:25:35 - epoch 023 lr: 0.1
2022-03-10 19:26:13 - train: epoch 0023, iter [00100, 05004], lr: 0.100000, loss: 3.5564, CELoss: 2.3137 KDLoss: 1.2427 
2022-03-10 19:26:47 - train: epoch 0023, iter [00200, 05004], lr: 0.100000, loss: 2.9776, CELoss: 2.0132 KDLoss: 0.9644 
2022-03-10 19:27:19 - train: epoch 0023, iter [00300, 05004], lr: 0.100000, loss: 3.4181, CELoss: 2.2589 KDLoss: 1.1592 
2022-03-10 19:27:52 - train: epoch 0023, iter [00400, 05004], lr: 0.100000, loss: 3.4075, CELoss: 2.2215 KDLoss: 1.1860 
2022-03-10 19:28:27 - train: epoch 0023, iter [00500, 05004], lr: 0.100000, loss: 3.5243, CELoss: 2.3033 KDLoss: 1.2210 
2022-03-10 19:29:00 - train: epoch 0023, iter [00600, 05004], lr: 0.100000, loss: 3.5678, CELoss: 2.3193 KDLoss: 1.2485 
2022-03-10 19:29:34 - train: epoch 0023, iter [00700, 05004], lr: 0.100000, loss: 3.6635, CELoss: 2.3796 KDLoss: 1.2839 
2022-03-10 19:30:06 - train: epoch 0023, iter [00800, 05004], lr: 0.100000, loss: 3.5314, CELoss: 2.3307 KDLoss: 1.2007 
2022-03-10 19:30:41 - train: epoch 0023, iter [00900, 05004], lr: 0.100000, loss: 3.6008, CELoss: 2.4310 KDLoss: 1.1698 
2022-03-10 19:31:14 - train: epoch 0023, iter [01000, 05004], lr: 0.100000, loss: 3.3294, CELoss: 2.1369 KDLoss: 1.1925 
2022-03-10 19:31:49 - train: epoch 0023, iter [01100, 05004], lr: 0.100000, loss: 3.6708, CELoss: 2.3957 KDLoss: 1.2750 
2022-03-10 19:32:22 - train: epoch 0023, iter [01200, 05004], lr: 0.100000, loss: 3.2387, CELoss: 2.1702 KDLoss: 1.0685 
2022-03-10 19:32:55 - train: epoch 0023, iter [01300, 05004], lr: 0.100000, loss: 3.2293, CELoss: 2.0871 KDLoss: 1.1422 
2022-03-10 19:33:30 - train: epoch 0023, iter [01400, 05004], lr: 0.100000, loss: 3.4889, CELoss: 2.2870 KDLoss: 1.2019 
2022-03-10 19:34:03 - train: epoch 0023, iter [01500, 05004], lr: 0.100000, loss: 3.4129, CELoss: 2.2054 KDLoss: 1.2076 
2022-03-10 19:34:36 - train: epoch 0023, iter [01600, 05004], lr: 0.100000, loss: 3.4315, CELoss: 2.2884 KDLoss: 1.1431 
2022-03-10 19:35:10 - train: epoch 0023, iter [01700, 05004], lr: 0.100000, loss: 3.4616, CELoss: 2.1883 KDLoss: 1.2733 
2022-03-10 19:35:43 - train: epoch 0023, iter [01800, 05004], lr: 0.100000, loss: 3.8738, CELoss: 2.5341 KDLoss: 1.3396 
2022-03-10 19:36:17 - train: epoch 0023, iter [01900, 05004], lr: 0.100000, loss: 3.8421, CELoss: 2.5676 KDLoss: 1.2746 
2022-03-10 19:36:51 - train: epoch 0023, iter [02000, 05004], lr: 0.100000, loss: 3.2967, CELoss: 2.1264 KDLoss: 1.1703 
2022-03-10 19:37:24 - train: epoch 0023, iter [02100, 05004], lr: 0.100000, loss: 3.5162, CELoss: 2.2937 KDLoss: 1.2225 
2022-03-10 19:37:58 - train: epoch 0023, iter [02200, 05004], lr: 0.100000, loss: 3.1457, CELoss: 2.0495 KDLoss: 1.0963 
2022-03-10 19:38:31 - train: epoch 0023, iter [02300, 05004], lr: 0.100000, loss: 3.3246, CELoss: 2.1309 KDLoss: 1.1937 
2022-03-10 19:39:05 - train: epoch 0023, iter [02400, 05004], lr: 0.100000, loss: 3.6064, CELoss: 2.3588 KDLoss: 1.2477 
2022-03-10 19:39:38 - train: epoch 0023, iter [02500, 05004], lr: 0.100000, loss: 3.7035, CELoss: 2.3881 KDLoss: 1.3155 
2022-03-10 19:40:11 - train: epoch 0023, iter [02600, 05004], lr: 0.100000, loss: 3.4575, CELoss: 2.2755 KDLoss: 1.1820 
2022-03-10 19:40:45 - train: epoch 0023, iter [02700, 05004], lr: 0.100000, loss: 3.6880, CELoss: 2.4362 KDLoss: 1.2518 
2022-03-10 19:41:19 - train: epoch 0023, iter [02800, 05004], lr: 0.100000, loss: 3.7553, CELoss: 2.4559 KDLoss: 1.2993 
2022-03-10 19:41:52 - train: epoch 0023, iter [02900, 05004], lr: 0.100000, loss: 3.4561, CELoss: 2.2353 KDLoss: 1.2208 
2022-03-10 19:42:25 - train: epoch 0023, iter [03000, 05004], lr: 0.100000, loss: 3.6423, CELoss: 2.3904 KDLoss: 1.2520 
2022-03-10 19:42:59 - train: epoch 0023, iter [03100, 05004], lr: 0.100000, loss: 3.8087, CELoss: 2.5005 KDLoss: 1.3081 
2022-03-10 19:43:33 - train: epoch 0023, iter [03200, 05004], lr: 0.100000, loss: 3.7492, CELoss: 2.4299 KDLoss: 1.3193 
2022-03-10 19:44:05 - train: epoch 0023, iter [03300, 05004], lr: 0.100000, loss: 3.5752, CELoss: 2.3011 KDLoss: 1.2741 
2022-03-10 19:44:40 - train: epoch 0023, iter [03400, 05004], lr: 0.100000, loss: 3.7688, CELoss: 2.4471 KDLoss: 1.3216 
2022-03-10 19:45:11 - train: epoch 0023, iter [03500, 05004], lr: 0.100000, loss: 3.3000, CELoss: 2.1507 KDLoss: 1.1493 
2022-03-10 19:45:46 - train: epoch 0023, iter [03600, 05004], lr: 0.100000, loss: 3.4539, CELoss: 2.2531 KDLoss: 1.2008 
2022-03-10 19:46:19 - train: epoch 0023, iter [03700, 05004], lr: 0.100000, loss: 3.6475, CELoss: 2.3610 KDLoss: 1.2865 
2022-03-10 19:46:53 - train: epoch 0023, iter [03800, 05004], lr: 0.100000, loss: 3.6778, CELoss: 2.4401 KDLoss: 1.2377 
2022-03-10 19:47:26 - train: epoch 0023, iter [03900, 05004], lr: 0.100000, loss: 3.5448, CELoss: 2.3643 KDLoss: 1.1805 
2022-03-10 19:47:59 - train: epoch 0023, iter [04000, 05004], lr: 0.100000, loss: 3.6023, CELoss: 2.3715 KDLoss: 1.2308 
2022-03-10 19:48:33 - train: epoch 0023, iter [04100, 05004], lr: 0.100000, loss: 3.3043, CELoss: 2.1585 KDLoss: 1.1458 
2022-03-10 19:49:07 - train: epoch 0023, iter [04200, 05004], lr: 0.100000, loss: 3.2667, CELoss: 2.0623 KDLoss: 1.2044 
2022-03-10 19:49:40 - train: epoch 0023, iter [04300, 05004], lr: 0.100000, loss: 3.2520, CELoss: 2.1339 KDLoss: 1.1182 
2022-03-10 19:50:13 - train: epoch 0023, iter [04400, 05004], lr: 0.100000, loss: 3.3368, CELoss: 2.1289 KDLoss: 1.2079 
2022-03-10 19:50:46 - train: epoch 0023, iter [04500, 05004], lr: 0.100000, loss: 3.4834, CELoss: 2.2543 KDLoss: 1.2291 
2022-03-10 19:51:20 - train: epoch 0023, iter [04600, 05004], lr: 0.100000, loss: 3.6199, CELoss: 2.4001 KDLoss: 1.2198 
2022-03-10 19:51:52 - train: epoch 0023, iter [04700, 05004], lr: 0.100000, loss: 3.3682, CELoss: 2.1671 KDLoss: 1.2010 
2022-03-10 19:52:26 - train: epoch 0023, iter [04800, 05004], lr: 0.100000, loss: 3.6715, CELoss: 2.3720 KDLoss: 1.2995 
2022-03-10 19:53:00 - train: epoch 0023, iter [04900, 05004], lr: 0.100000, loss: 3.2992, CELoss: 2.1441 KDLoss: 1.1551 
2022-03-10 19:53:32 - train: epoch 0023, iter [05000, 05004], lr: 0.100000, loss: 3.6195, CELoss: 2.3584 KDLoss: 1.2610 
2022-03-10 19:53:33 - train: epoch 023, train_loss: 3.5271
2022-03-10 19:56:02 - eval: epoch: 023, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 51.494%, stu_acc5: 76.944%, stu_test_loss: 2.0962
2022-03-10 19:56:03 - until epoch: 023, tea_best_acc1: 73.950%, stu_best_acc1: 51.684%
2022-03-10 19:56:03 - epoch 024 lr: 0.1
2022-03-10 19:56:41 - train: epoch 0024, iter [00100, 05004], lr: 0.100000, loss: 3.6670, CELoss: 2.4933 KDLoss: 1.1737 
2022-03-10 19:57:16 - train: epoch 0024, iter [00200, 05004], lr: 0.100000, loss: 3.2745, CELoss: 2.1439 KDLoss: 1.1305 
2022-03-10 19:57:48 - train: epoch 0024, iter [00300, 05004], lr: 0.100000, loss: 3.4991, CELoss: 2.2684 KDLoss: 1.2307 
2022-03-10 19:58:22 - train: epoch 0024, iter [00400, 05004], lr: 0.100000, loss: 3.5923, CELoss: 2.3556 KDLoss: 1.2367 
2022-03-10 19:58:55 - train: epoch 0024, iter [00500, 05004], lr: 0.100000, loss: 3.7163, CELoss: 2.4478 KDLoss: 1.2685 
2022-03-10 19:59:28 - train: epoch 0024, iter [00600, 05004], lr: 0.100000, loss: 3.5724, CELoss: 2.3260 KDLoss: 1.2464 
2022-03-10 20:00:01 - train: epoch 0024, iter [00700, 05004], lr: 0.100000, loss: 3.2525, CELoss: 2.1197 KDLoss: 1.1329 
2022-03-10 20:00:36 - train: epoch 0024, iter [00800, 05004], lr: 0.100000, loss: 3.5163, CELoss: 2.2173 KDLoss: 1.2990 
2022-03-10 20:01:09 - train: epoch 0024, iter [00900, 05004], lr: 0.100000, loss: 3.3138, CELoss: 2.1482 KDLoss: 1.1656 
2022-03-10 20:01:42 - train: epoch 0024, iter [01000, 05004], lr: 0.100000, loss: 3.4122, CELoss: 2.2208 KDLoss: 1.1914 
2022-03-10 20:02:15 - train: epoch 0024, iter [01100, 05004], lr: 0.100000, loss: 3.2508, CELoss: 2.1033 KDLoss: 1.1474 
2022-03-10 20:02:49 - train: epoch 0024, iter [01200, 05004], lr: 0.100000, loss: 3.3750, CELoss: 2.1838 KDLoss: 1.1912 
2022-03-10 20:03:21 - train: epoch 0024, iter [01300, 05004], lr: 0.100000, loss: 3.9206, CELoss: 2.5460 KDLoss: 1.3746 
2022-03-10 20:03:55 - train: epoch 0024, iter [01400, 05004], lr: 0.100000, loss: 3.2625, CELoss: 2.0818 KDLoss: 1.1807 
2022-03-10 20:04:29 - train: epoch 0024, iter [01500, 05004], lr: 0.100000, loss: 3.6515, CELoss: 2.4277 KDLoss: 1.2239 
2022-03-10 20:05:03 - train: epoch 0024, iter [01600, 05004], lr: 0.100000, loss: 3.5171, CELoss: 2.2940 KDLoss: 1.2231 
2022-03-10 20:05:36 - train: epoch 0024, iter [01700, 05004], lr: 0.100000, loss: 3.5342, CELoss: 2.3057 KDLoss: 1.2285 
2022-03-10 20:06:09 - train: epoch 0024, iter [01800, 05004], lr: 0.100000, loss: 3.6038, CELoss: 2.3790 KDLoss: 1.2248 
2022-03-10 20:06:43 - train: epoch 0024, iter [01900, 05004], lr: 0.100000, loss: 3.3495, CELoss: 2.2104 KDLoss: 1.1392 
2022-03-10 20:07:17 - train: epoch 0024, iter [02000, 05004], lr: 0.100000, loss: 3.7998, CELoss: 2.4342 KDLoss: 1.3655 
2022-03-10 20:07:50 - train: epoch 0024, iter [02100, 05004], lr: 0.100000, loss: 3.2808, CELoss: 2.1808 KDLoss: 1.1000 
2022-03-10 20:08:23 - train: epoch 0024, iter [02200, 05004], lr: 0.100000, loss: 3.1891, CELoss: 2.1570 KDLoss: 1.0321 
2022-03-10 20:08:56 - train: epoch 0024, iter [02300, 05004], lr: 0.100000, loss: 3.5351, CELoss: 2.2942 KDLoss: 1.2409 
2022-03-10 20:09:30 - train: epoch 0024, iter [02400, 05004], lr: 0.100000, loss: 3.7142, CELoss: 2.4515 KDLoss: 1.2626 
2022-03-10 20:10:03 - train: epoch 0024, iter [02500, 05004], lr: 0.100000, loss: 3.3038, CELoss: 2.1684 KDLoss: 1.1353 
2022-03-10 20:10:36 - train: epoch 0024, iter [02600, 05004], lr: 0.100000, loss: 3.8365, CELoss: 2.5596 KDLoss: 1.2769 
2022-03-10 20:11:10 - train: epoch 0024, iter [02700, 05004], lr: 0.100000, loss: 3.7609, CELoss: 2.4843 KDLoss: 1.2766 
2022-03-10 20:11:43 - train: epoch 0024, iter [02800, 05004], lr: 0.100000, loss: 3.5736, CELoss: 2.4117 KDLoss: 1.1619 
2022-03-10 20:12:16 - train: epoch 0024, iter [02900, 05004], lr: 0.100000, loss: 3.3159, CELoss: 2.1278 KDLoss: 1.1881 
2022-03-10 20:12:49 - train: epoch 0024, iter [03000, 05004], lr: 0.100000, loss: 3.1249, CELoss: 2.0441 KDLoss: 1.0808 
2022-03-10 20:13:23 - train: epoch 0024, iter [03100, 05004], lr: 0.100000, loss: 3.0311, CELoss: 1.9925 KDLoss: 1.0386 
2022-03-10 20:13:56 - train: epoch 0024, iter [03200, 05004], lr: 0.100000, loss: 3.6830, CELoss: 2.4069 KDLoss: 1.2761 
2022-03-10 20:14:30 - train: epoch 0024, iter [03300, 05004], lr: 0.100000, loss: 3.4634, CELoss: 2.2003 KDLoss: 1.2631 
2022-03-10 20:15:03 - train: epoch 0024, iter [03400, 05004], lr: 0.100000, loss: 3.1235, CELoss: 2.0265 KDLoss: 1.0970 
2022-03-10 20:15:37 - train: epoch 0024, iter [03500, 05004], lr: 0.100000, loss: 3.7270, CELoss: 2.4252 KDLoss: 1.3019 
2022-03-10 20:16:10 - train: epoch 0024, iter [03600, 05004], lr: 0.100000, loss: 3.5359, CELoss: 2.3098 KDLoss: 1.2261 
2022-03-10 20:16:44 - train: epoch 0024, iter [03700, 05004], lr: 0.100000, loss: 3.3246, CELoss: 2.2074 KDLoss: 1.1172 
2022-03-10 20:17:19 - train: epoch 0024, iter [03800, 05004], lr: 0.100000, loss: 3.5593, CELoss: 2.3857 KDLoss: 1.1735 
2022-03-10 20:17:52 - train: epoch 0024, iter [03900, 05004], lr: 0.100000, loss: 3.2599, CELoss: 2.0891 KDLoss: 1.1708 
2022-03-10 20:18:26 - train: epoch 0024, iter [04000, 05004], lr: 0.100000, loss: 3.4939, CELoss: 2.3089 KDLoss: 1.1850 
2022-03-10 20:18:59 - train: epoch 0024, iter [04100, 05004], lr: 0.100000, loss: 3.4369, CELoss: 2.1971 KDLoss: 1.2398 
2022-03-10 20:19:33 - train: epoch 0024, iter [04200, 05004], lr: 0.100000, loss: 3.3263, CELoss: 2.1994 KDLoss: 1.1269 
2022-03-10 20:20:07 - train: epoch 0024, iter [04300, 05004], lr: 0.100000, loss: 3.2731, CELoss: 2.1300 KDLoss: 1.1431 
2022-03-10 20:20:40 - train: epoch 0024, iter [04400, 05004], lr: 0.100000, loss: 3.6580, CELoss: 2.4142 KDLoss: 1.2438 
2022-03-10 20:21:14 - train: epoch 0024, iter [04500, 05004], lr: 0.100000, loss: 3.2914, CELoss: 2.1303 KDLoss: 1.1611 
2022-03-10 20:21:47 - train: epoch 0024, iter [04600, 05004], lr: 0.100000, loss: 3.7449, CELoss: 2.4962 KDLoss: 1.2487 
2022-03-10 20:22:21 - train: epoch 0024, iter [04700, 05004], lr: 0.100000, loss: 3.4133, CELoss: 2.2158 KDLoss: 1.1975 
2022-03-10 20:22:54 - train: epoch 0024, iter [04800, 05004], lr: 0.100000, loss: 3.3255, CELoss: 2.1244 KDLoss: 1.2011 
2022-03-10 20:23:28 - train: epoch 0024, iter [04900, 05004], lr: 0.100000, loss: 3.7029, CELoss: 2.4462 KDLoss: 1.2567 
2022-03-10 20:23:59 - train: epoch 0024, iter [05000, 05004], lr: 0.100000, loss: 3.8801, CELoss: 2.5004 KDLoss: 1.3798 
2022-03-10 20:24:00 - train: epoch 024, train_loss: 3.5226
2022-03-10 20:26:29 - eval: epoch: 024, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 50.206%, stu_acc5: 75.600%, stu_test_loss: 2.1680
2022-03-10 20:26:29 - until epoch: 024, tea_best_acc1: 73.950%, stu_best_acc1: 51.684%
2022-03-10 20:26:29 - epoch 025 lr: 0.1
2022-03-10 20:27:08 - train: epoch 0025, iter [00100, 05004], lr: 0.100000, loss: 3.5186, CELoss: 2.2582 KDLoss: 1.2604 
2022-03-10 20:27:41 - train: epoch 0025, iter [00200, 05004], lr: 0.100000, loss: 3.2556, CELoss: 2.0481 KDLoss: 1.2075 
2022-03-10 20:28:15 - train: epoch 0025, iter [00300, 05004], lr: 0.100000, loss: 3.2693, CELoss: 2.1208 KDLoss: 1.1485 
2022-03-10 20:28:48 - train: epoch 0025, iter [00400, 05004], lr: 0.100000, loss: 3.8810, CELoss: 2.5467 KDLoss: 1.3343 
2022-03-10 20:29:21 - train: epoch 0025, iter [00500, 05004], lr: 0.100000, loss: 3.2944, CELoss: 2.1851 KDLoss: 1.1093 
2022-03-10 20:29:56 - train: epoch 0025, iter [00600, 05004], lr: 0.100000, loss: 3.4756, CELoss: 2.3052 KDLoss: 1.1704 
2022-03-10 20:30:28 - train: epoch 0025, iter [00700, 05004], lr: 0.100000, loss: 3.4985, CELoss: 2.2447 KDLoss: 1.2537 
2022-03-10 20:31:03 - train: epoch 0025, iter [00800, 05004], lr: 0.100000, loss: 3.3081, CELoss: 2.1246 KDLoss: 1.1835 
2022-03-10 20:31:36 - train: epoch 0025, iter [00900, 05004], lr: 0.100000, loss: 3.3623, CELoss: 2.1990 KDLoss: 1.1634 
2022-03-10 20:32:10 - train: epoch 0025, iter [01000, 05004], lr: 0.100000, loss: 3.4746, CELoss: 2.2783 KDLoss: 1.1963 
2022-03-10 20:32:43 - train: epoch 0025, iter [01100, 05004], lr: 0.100000, loss: 3.2469, CELoss: 2.1156 KDLoss: 1.1313 
2022-03-10 20:33:16 - train: epoch 0025, iter [01200, 05004], lr: 0.100000, loss: 3.7442, CELoss: 2.4874 KDLoss: 1.2569 
2022-03-10 20:33:50 - train: epoch 0025, iter [01300, 05004], lr: 0.100000, loss: 3.3241, CELoss: 2.1886 KDLoss: 1.1355 
2022-03-10 20:34:23 - train: epoch 0025, iter [01400, 05004], lr: 0.100000, loss: 3.1854, CELoss: 2.0146 KDLoss: 1.1708 
2022-03-10 20:34:57 - train: epoch 0025, iter [01500, 05004], lr: 0.100000, loss: 3.3802, CELoss: 2.2979 KDLoss: 1.0823 
2022-03-10 20:35:29 - train: epoch 0025, iter [01600, 05004], lr: 0.100000, loss: 3.5583, CELoss: 2.3067 KDLoss: 1.2516 
2022-03-10 20:36:04 - train: epoch 0025, iter [01700, 05004], lr: 0.100000, loss: 3.5717, CELoss: 2.3539 KDLoss: 1.2178 
2022-03-10 20:36:37 - train: epoch 0025, iter [01800, 05004], lr: 0.100000, loss: 3.3820, CELoss: 2.1647 KDLoss: 1.2172 
2022-03-10 20:37:11 - train: epoch 0025, iter [01900, 05004], lr: 0.100000, loss: 3.2845, CELoss: 2.1861 KDLoss: 1.0984 
2022-03-10 20:37:44 - train: epoch 0025, iter [02000, 05004], lr: 0.100000, loss: 3.4563, CELoss: 2.2363 KDLoss: 1.2200 
2022-03-10 20:38:18 - train: epoch 0025, iter [02100, 05004], lr: 0.100000, loss: 3.1589, CELoss: 1.9834 KDLoss: 1.1755 
2022-03-10 20:38:51 - train: epoch 0025, iter [02200, 05004], lr: 0.100000, loss: 3.4143, CELoss: 2.2315 KDLoss: 1.1828 
2022-03-10 20:39:25 - train: epoch 0025, iter [02300, 05004], lr: 0.100000, loss: 3.6970, CELoss: 2.3557 KDLoss: 1.3413 
2022-03-10 20:39:58 - train: epoch 0025, iter [02400, 05004], lr: 0.100000, loss: 3.5652, CELoss: 2.3437 KDLoss: 1.2215 
2022-03-10 20:40:32 - train: epoch 0025, iter [02500, 05004], lr: 0.100000, loss: 3.6900, CELoss: 2.4047 KDLoss: 1.2852 
2022-03-10 20:41:05 - train: epoch 0025, iter [02600, 05004], lr: 0.100000, loss: 3.5014, CELoss: 2.2815 KDLoss: 1.2199 
2022-03-10 20:41:40 - train: epoch 0025, iter [02700, 05004], lr: 0.100000, loss: 3.6793, CELoss: 2.4265 KDLoss: 1.2528 
2022-03-10 20:42:13 - train: epoch 0025, iter [02800, 05004], lr: 0.100000, loss: 3.5032, CELoss: 2.3356 KDLoss: 1.1676 
2022-03-10 20:42:47 - train: epoch 0025, iter [02900, 05004], lr: 0.100000, loss: 3.7038, CELoss: 2.4551 KDLoss: 1.2488 
2022-03-10 20:43:20 - train: epoch 0025, iter [03000, 05004], lr: 0.100000, loss: 3.7281, CELoss: 2.3774 KDLoss: 1.3506 
2022-03-10 20:43:54 - train: epoch 0025, iter [03100, 05004], lr: 0.100000, loss: 3.5911, CELoss: 2.3536 KDLoss: 1.2374 
2022-03-10 20:44:26 - train: epoch 0025, iter [03200, 05004], lr: 0.100000, loss: 3.5735, CELoss: 2.3102 KDLoss: 1.2633 
2022-03-10 20:45:01 - train: epoch 0025, iter [03300, 05004], lr: 0.100000, loss: 3.5809, CELoss: 2.2619 KDLoss: 1.3190 
2022-03-10 20:45:34 - train: epoch 0025, iter [03400, 05004], lr: 0.100000, loss: 3.4365, CELoss: 2.2316 KDLoss: 1.2048 
2022-03-10 20:46:07 - train: epoch 0025, iter [03500, 05004], lr: 0.100000, loss: 3.5352, CELoss: 2.3059 KDLoss: 1.2294 
2022-03-10 20:46:40 - train: epoch 0025, iter [03600, 05004], lr: 0.100000, loss: 3.6008, CELoss: 2.2892 KDLoss: 1.3116 
2022-03-10 20:47:14 - train: epoch 0025, iter [03700, 05004], lr: 0.100000, loss: 3.4967, CELoss: 2.2924 KDLoss: 1.2043 
2022-03-10 20:47:47 - train: epoch 0025, iter [03800, 05004], lr: 0.100000, loss: 3.4858, CELoss: 2.3050 KDLoss: 1.1808 
2022-03-10 20:48:20 - train: epoch 0025, iter [03900, 05004], lr: 0.100000, loss: 3.7601, CELoss: 2.5156 KDLoss: 1.2446 
2022-03-10 20:48:54 - train: epoch 0025, iter [04000, 05004], lr: 0.100000, loss: 3.5445, CELoss: 2.3021 KDLoss: 1.2423 
2022-03-10 20:49:28 - train: epoch 0025, iter [04100, 05004], lr: 0.100000, loss: 3.8081, CELoss: 2.5371 KDLoss: 1.2710 
2022-03-10 20:50:00 - train: epoch 0025, iter [04200, 05004], lr: 0.100000, loss: 3.4503, CELoss: 2.3090 KDLoss: 1.1413 
2022-03-10 20:50:35 - train: epoch 0025, iter [04300, 05004], lr: 0.100000, loss: 3.3003, CELoss: 2.1433 KDLoss: 1.1570 
2022-03-10 20:51:07 - train: epoch 0025, iter [04400, 05004], lr: 0.100000, loss: 3.2108, CELoss: 2.1151 KDLoss: 1.0957 
2022-03-10 20:51:40 - train: epoch 0025, iter [04500, 05004], lr: 0.100000, loss: 3.5412, CELoss: 2.3454 KDLoss: 1.1958 
2022-03-10 20:52:14 - train: epoch 0025, iter [04600, 05004], lr: 0.100000, loss: 3.2981, CELoss: 2.1540 KDLoss: 1.1441 
2022-03-10 20:52:48 - train: epoch 0025, iter [04700, 05004], lr: 0.100000, loss: 3.5527, CELoss: 2.2683 KDLoss: 1.2844 
2022-03-10 20:53:21 - train: epoch 0025, iter [04800, 05004], lr: 0.100000, loss: 3.2044, CELoss: 2.0874 KDLoss: 1.1170 
2022-03-10 20:53:54 - train: epoch 0025, iter [04900, 05004], lr: 0.100000, loss: 3.3877, CELoss: 2.2618 KDLoss: 1.1259 
2022-03-10 20:54:25 - train: epoch 0025, iter [05000, 05004], lr: 0.100000, loss: 3.9063, CELoss: 2.5984 KDLoss: 1.3079 
2022-03-10 20:54:26 - train: epoch 025, train_loss: 3.5147
2022-03-10 20:56:54 - eval: epoch: 025, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 51.696%, stu_acc5: 77.136%, stu_test_loss: 2.0882
2022-03-10 20:56:55 - until epoch: 025, tea_best_acc1: 73.950%, stu_best_acc1: 51.696%
2022-03-10 20:56:55 - epoch 026 lr: 0.1
2022-03-10 20:57:34 - train: epoch 0026, iter [00100, 05004], lr: 0.100000, loss: 3.3917, CELoss: 2.1754 KDLoss: 1.2163 
2022-03-10 20:58:07 - train: epoch 0026, iter [00200, 05004], lr: 0.100000, loss: 3.4785, CELoss: 2.2633 KDLoss: 1.2153 
2022-03-10 20:58:40 - train: epoch 0026, iter [00300, 05004], lr: 0.100000, loss: 3.5686, CELoss: 2.4048 KDLoss: 1.1637 
2022-03-10 20:59:14 - train: epoch 0026, iter [00400, 05004], lr: 0.100000, loss: 3.2124, CELoss: 2.0441 KDLoss: 1.1683 
2022-03-10 20:59:46 - train: epoch 0026, iter [00500, 05004], lr: 0.100000, loss: 3.6798, CELoss: 2.4163 KDLoss: 1.2635 
2022-03-10 21:00:20 - train: epoch 0026, iter [00600, 05004], lr: 0.100000, loss: 3.9811, CELoss: 2.7072 KDLoss: 1.2738 
2022-03-10 21:00:54 - train: epoch 0026, iter [00700, 05004], lr: 0.100000, loss: 3.3174, CELoss: 2.2120 KDLoss: 1.1054 
2022-03-10 21:01:28 - train: epoch 0026, iter [00800, 05004], lr: 0.100000, loss: 3.2285, CELoss: 2.1385 KDLoss: 1.0900 
2022-03-10 21:02:01 - train: epoch 0026, iter [00900, 05004], lr: 0.100000, loss: 3.8306, CELoss: 2.6149 KDLoss: 1.2156 
2022-03-10 21:02:35 - train: epoch 0026, iter [01000, 05004], lr: 0.100000, loss: 3.5999, CELoss: 2.3069 KDLoss: 1.2931 
2022-03-10 21:03:09 - train: epoch 0026, iter [01100, 05004], lr: 0.100000, loss: 3.7068, CELoss: 2.3695 KDLoss: 1.3374 
2022-03-10 21:03:43 - train: epoch 0026, iter [01200, 05004], lr: 0.100000, loss: 3.6759, CELoss: 2.3838 KDLoss: 1.2922 
2022-03-10 21:04:16 - train: epoch 0026, iter [01300, 05004], lr: 0.100000, loss: 3.3171, CELoss: 2.1939 KDLoss: 1.1232 
2022-03-10 21:04:50 - train: epoch 0026, iter [01400, 05004], lr: 0.100000, loss: 3.5863, CELoss: 2.3299 KDLoss: 1.2564 
2022-03-10 21:05:24 - train: epoch 0026, iter [01500, 05004], lr: 0.100000, loss: 3.2444, CELoss: 2.0786 KDLoss: 1.1657 
2022-03-10 21:05:58 - train: epoch 0026, iter [01600, 05004], lr: 0.100000, loss: 3.3395, CELoss: 2.2519 KDLoss: 1.0876 
2022-03-10 21:06:31 - train: epoch 0026, iter [01700, 05004], lr: 0.100000, loss: 3.4725, CELoss: 2.2665 KDLoss: 1.2061 
2022-03-10 21:07:05 - train: epoch 0026, iter [01800, 05004], lr: 0.100000, loss: 3.6214, CELoss: 2.4585 KDLoss: 1.1630 
2022-03-10 21:07:40 - train: epoch 0026, iter [01900, 05004], lr: 0.100000, loss: 3.5562, CELoss: 2.3759 KDLoss: 1.1803 
2022-03-10 21:08:13 - train: epoch 0026, iter [02000, 05004], lr: 0.100000, loss: 3.6942, CELoss: 2.4173 KDLoss: 1.2769 
2022-03-10 21:08:46 - train: epoch 0026, iter [02100, 05004], lr: 0.100000, loss: 3.4728, CELoss: 2.2644 KDLoss: 1.2084 
2022-03-10 21:09:21 - train: epoch 0026, iter [02200, 05004], lr: 0.100000, loss: 3.3777, CELoss: 2.2264 KDLoss: 1.1512 
2022-03-10 21:09:53 - train: epoch 0026, iter [02300, 05004], lr: 0.100000, loss: 3.5224, CELoss: 2.3001 KDLoss: 1.2224 
2022-03-10 21:10:27 - train: epoch 0026, iter [02400, 05004], lr: 0.100000, loss: 3.6160, CELoss: 2.3224 KDLoss: 1.2936 
2022-03-10 21:11:01 - train: epoch 0026, iter [02500, 05004], lr: 0.100000, loss: 3.6118, CELoss: 2.4236 KDLoss: 1.1882 
2022-03-10 21:11:35 - train: epoch 0026, iter [02600, 05004], lr: 0.100000, loss: 3.6210, CELoss: 2.4022 KDLoss: 1.2189 
2022-03-10 21:12:08 - train: epoch 0026, iter [02700, 05004], lr: 0.100000, loss: 3.6600, CELoss: 2.4395 KDLoss: 1.2205 
2022-03-10 21:12:41 - train: epoch 0026, iter [02800, 05004], lr: 0.100000, loss: 3.5477, CELoss: 2.3497 KDLoss: 1.1980 
2022-03-10 21:13:15 - train: epoch 0026, iter [02900, 05004], lr: 0.100000, loss: 3.7982, CELoss: 2.4870 KDLoss: 1.3112 
2022-03-10 21:13:47 - train: epoch 0026, iter [03000, 05004], lr: 0.100000, loss: 3.6030, CELoss: 2.3360 KDLoss: 1.2671 
2022-03-10 21:14:22 - train: epoch 0026, iter [03100, 05004], lr: 0.100000, loss: 3.6297, CELoss: 2.4162 KDLoss: 1.2134 
2022-03-10 21:14:56 - train: epoch 0026, iter [03200, 05004], lr: 0.100000, loss: 3.7851, CELoss: 2.4829 KDLoss: 1.3022 
2022-03-10 21:15:29 - train: epoch 0026, iter [03300, 05004], lr: 0.100000, loss: 3.3597, CELoss: 2.1742 KDLoss: 1.1855 
2022-03-10 21:16:02 - train: epoch 0026, iter [03400, 05004], lr: 0.100000, loss: 3.5029, CELoss: 2.2645 KDLoss: 1.2384 
2022-03-10 21:16:35 - train: epoch 0026, iter [03500, 05004], lr: 0.100000, loss: 3.5715, CELoss: 2.4482 KDLoss: 1.1233 
2022-03-10 21:17:09 - train: epoch 0026, iter [03600, 05004], lr: 0.100000, loss: 3.1178, CELoss: 2.0633 KDLoss: 1.0545 
2022-03-10 21:17:43 - train: epoch 0026, iter [03700, 05004], lr: 0.100000, loss: 3.5775, CELoss: 2.3392 KDLoss: 1.2383 
2022-03-10 21:18:17 - train: epoch 0026, iter [03800, 05004], lr: 0.100000, loss: 3.7367, CELoss: 2.4535 KDLoss: 1.2832 
2022-03-10 21:18:50 - train: epoch 0026, iter [03900, 05004], lr: 0.100000, loss: 3.5963, CELoss: 2.3895 KDLoss: 1.2068 
2022-03-10 21:19:23 - train: epoch 0026, iter [04000, 05004], lr: 0.100000, loss: 3.5545, CELoss: 2.3761 KDLoss: 1.1784 
2022-03-10 21:19:56 - train: epoch 0026, iter [04100, 05004], lr: 0.100000, loss: 3.3693, CELoss: 2.1600 KDLoss: 1.2093 
2022-03-10 21:20:30 - train: epoch 0026, iter [04200, 05004], lr: 0.100000, loss: 3.7685, CELoss: 2.4517 KDLoss: 1.3167 
2022-03-10 21:21:03 - train: epoch 0026, iter [04300, 05004], lr: 0.100000, loss: 3.6862, CELoss: 2.4383 KDLoss: 1.2479 
2022-03-10 21:21:36 - train: epoch 0026, iter [04400, 05004], lr: 0.100000, loss: 3.5924, CELoss: 2.4218 KDLoss: 1.1706 
2022-03-10 21:22:08 - train: epoch 0026, iter [04500, 05004], lr: 0.100000, loss: 3.8998, CELoss: 2.6564 KDLoss: 1.2433 
2022-03-10 21:22:43 - train: epoch 0026, iter [04600, 05004], lr: 0.100000, loss: 3.4040, CELoss: 2.2875 KDLoss: 1.1165 
2022-03-10 21:23:16 - train: epoch 0026, iter [04700, 05004], lr: 0.100000, loss: 3.4729, CELoss: 2.2026 KDLoss: 1.2703 
2022-03-10 21:23:50 - train: epoch 0026, iter [04800, 05004], lr: 0.100000, loss: 3.3810, CELoss: 2.2111 KDLoss: 1.1699 
2022-03-10 21:24:23 - train: epoch 0026, iter [04900, 05004], lr: 0.100000, loss: 3.7113, CELoss: 2.3863 KDLoss: 1.3250 
2022-03-10 21:24:55 - train: epoch 0026, iter [05000, 05004], lr: 0.100000, loss: 3.7870, CELoss: 2.4813 KDLoss: 1.3057 
2022-03-10 21:24:56 - train: epoch 026, train_loss: 3.5104
2022-03-10 21:27:25 - eval: epoch: 026, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 50.638%, stu_acc5: 76.090%, stu_test_loss: 2.1409
2022-03-10 21:27:26 - until epoch: 026, tea_best_acc1: 73.950%, stu_best_acc1: 51.696%
2022-03-10 21:27:26 - epoch 027 lr: 0.1
2022-03-10 21:28:04 - train: epoch 0027, iter [00100, 05004], lr: 0.100000, loss: 3.5528, CELoss: 2.3023 KDLoss: 1.2505 
2022-03-10 21:28:37 - train: epoch 0027, iter [00200, 05004], lr: 0.100000, loss: 3.3778, CELoss: 2.2632 KDLoss: 1.1146 
2022-03-10 21:29:11 - train: epoch 0027, iter [00300, 05004], lr: 0.100000, loss: 3.7586, CELoss: 2.4598 KDLoss: 1.2988 
2022-03-10 21:29:45 - train: epoch 0027, iter [00400, 05004], lr: 0.100000, loss: 3.6562, CELoss: 2.4513 KDLoss: 1.2049 
2022-03-10 21:30:18 - train: epoch 0027, iter [00500, 05004], lr: 0.100000, loss: 3.3492, CELoss: 2.1708 KDLoss: 1.1783 
2022-03-10 21:30:52 - train: epoch 0027, iter [00600, 05004], lr: 0.100000, loss: 3.5971, CELoss: 2.3712 KDLoss: 1.2259 
2022-03-10 21:31:26 - train: epoch 0027, iter [00700, 05004], lr: 0.100000, loss: 3.3289, CELoss: 2.2050 KDLoss: 1.1240 
2022-03-10 21:31:59 - train: epoch 0027, iter [00800, 05004], lr: 0.100000, loss: 3.4406, CELoss: 2.2864 KDLoss: 1.1542 
2022-03-10 21:32:33 - train: epoch 0027, iter [00900, 05004], lr: 0.100000, loss: 3.5862, CELoss: 2.3078 KDLoss: 1.2784 
2022-03-10 21:33:07 - train: epoch 0027, iter [01000, 05004], lr: 0.100000, loss: 3.4760, CELoss: 2.1984 KDLoss: 1.2775 
2022-03-10 21:33:40 - train: epoch 0027, iter [01100, 05004], lr: 0.100000, loss: 3.3280, CELoss: 2.1603 KDLoss: 1.1676 
2022-03-10 21:34:13 - train: epoch 0027, iter [01200, 05004], lr: 0.100000, loss: 3.6671, CELoss: 2.4372 KDLoss: 1.2299 
2022-03-10 21:34:47 - train: epoch 0027, iter [01300, 05004], lr: 0.100000, loss: 3.5977, CELoss: 2.2994 KDLoss: 1.2983 
2022-03-10 21:35:21 - train: epoch 0027, iter [01400, 05004], lr: 0.100000, loss: 3.7000, CELoss: 2.4370 KDLoss: 1.2631 
2022-03-10 21:35:54 - train: epoch 0027, iter [01500, 05004], lr: 0.100000, loss: 3.6867, CELoss: 2.4632 KDLoss: 1.2235 
2022-03-10 21:36:28 - train: epoch 0027, iter [01600, 05004], lr: 0.100000, loss: 3.5052, CELoss: 2.3458 KDLoss: 1.1594 
2022-03-10 21:37:01 - train: epoch 0027, iter [01700, 05004], lr: 0.100000, loss: 3.3561, CELoss: 2.1995 KDLoss: 1.1566 
2022-03-10 21:37:34 - train: epoch 0027, iter [01800, 05004], lr: 0.100000, loss: 3.4338, CELoss: 2.1151 KDLoss: 1.3186 
2022-03-10 21:38:08 - train: epoch 0027, iter [01900, 05004], lr: 0.100000, loss: 3.6525, CELoss: 2.3844 KDLoss: 1.2680 
2022-03-10 21:38:42 - train: epoch 0027, iter [02000, 05004], lr: 0.100000, loss: 3.4473, CELoss: 2.2946 KDLoss: 1.1527 
2022-03-10 21:39:15 - train: epoch 0027, iter [02100, 05004], lr: 0.100000, loss: 3.5405, CELoss: 2.3352 KDLoss: 1.2053 
2022-03-10 21:39:49 - train: epoch 0027, iter [02200, 05004], lr: 0.100000, loss: 3.7948, CELoss: 2.4528 KDLoss: 1.3420 
2022-03-10 21:40:22 - train: epoch 0027, iter [02300, 05004], lr: 0.100000, loss: 3.8131, CELoss: 2.5130 KDLoss: 1.3001 
2022-03-10 21:40:57 - train: epoch 0027, iter [02400, 05004], lr: 0.100000, loss: 3.1508, CELoss: 2.1588 KDLoss: 0.9920 
2022-03-10 21:41:30 - train: epoch 0027, iter [02500, 05004], lr: 0.100000, loss: 3.4731, CELoss: 2.2513 KDLoss: 1.2218 
2022-03-10 21:42:04 - train: epoch 0027, iter [02600, 05004], lr: 0.100000, loss: 3.3627, CELoss: 2.2432 KDLoss: 1.1195 
2022-03-10 21:42:37 - train: epoch 0027, iter [02700, 05004], lr: 0.100000, loss: 3.4607, CELoss: 2.2722 KDLoss: 1.1884 
2022-03-10 21:43:11 - train: epoch 0027, iter [02800, 05004], lr: 0.100000, loss: 3.5612, CELoss: 2.3494 KDLoss: 1.2118 
2022-03-10 21:43:44 - train: epoch 0027, iter [02900, 05004], lr: 0.100000, loss: 3.7474, CELoss: 2.4052 KDLoss: 1.3422 
2022-03-10 21:44:18 - train: epoch 0027, iter [03000, 05004], lr: 0.100000, loss: 3.3641, CELoss: 2.2512 KDLoss: 1.1129 
2022-03-10 21:44:51 - train: epoch 0027, iter [03100, 05004], lr: 0.100000, loss: 3.1469, CELoss: 2.0178 KDLoss: 1.1291 
2022-03-10 21:45:25 - train: epoch 0027, iter [03200, 05004], lr: 0.100000, loss: 3.3685, CELoss: 2.1445 KDLoss: 1.2240 
2022-03-10 21:45:58 - train: epoch 0027, iter [03300, 05004], lr: 0.100000, loss: 3.4728, CELoss: 2.2967 KDLoss: 1.1761 
2022-03-10 21:46:32 - train: epoch 0027, iter [03400, 05004], lr: 0.100000, loss: 3.4708, CELoss: 2.1753 KDLoss: 1.2954 
2022-03-10 21:47:05 - train: epoch 0027, iter [03500, 05004], lr: 0.100000, loss: 3.6714, CELoss: 2.4924 KDLoss: 1.1790 
2022-03-10 21:47:39 - train: epoch 0027, iter [03600, 05004], lr: 0.100000, loss: 3.4317, CELoss: 2.2897 KDLoss: 1.1419 
2022-03-10 21:48:12 - train: epoch 0027, iter [03700, 05004], lr: 0.100000, loss: 3.6270, CELoss: 2.3342 KDLoss: 1.2928 
2022-03-10 21:48:46 - train: epoch 0027, iter [03800, 05004], lr: 0.100000, loss: 3.2711, CELoss: 2.0536 KDLoss: 1.2175 
2022-03-10 21:49:20 - train: epoch 0027, iter [03900, 05004], lr: 0.100000, loss: 3.3486, CELoss: 2.2174 KDLoss: 1.1312 
2022-03-10 21:49:54 - train: epoch 0027, iter [04000, 05004], lr: 0.100000, loss: 3.7697, CELoss: 2.4369 KDLoss: 1.3328 
2022-03-10 21:50:28 - train: epoch 0027, iter [04100, 05004], lr: 0.100000, loss: 3.4985, CELoss: 2.3132 KDLoss: 1.1853 
2022-03-10 21:51:01 - train: epoch 0027, iter [04200, 05004], lr: 0.100000, loss: 3.5673, CELoss: 2.3217 KDLoss: 1.2456 
2022-03-10 21:51:34 - train: epoch 0027, iter [04300, 05004], lr: 0.100000, loss: 3.5152, CELoss: 2.2703 KDLoss: 1.2449 
2022-03-10 21:52:08 - train: epoch 0027, iter [04400, 05004], lr: 0.100000, loss: 3.6463, CELoss: 2.3896 KDLoss: 1.2567 
2022-03-10 21:52:41 - train: epoch 0027, iter [04500, 05004], lr: 0.100000, loss: 3.3690, CELoss: 2.2108 KDLoss: 1.1582 
2022-03-10 21:53:15 - train: epoch 0027, iter [04600, 05004], lr: 0.100000, loss: 3.4412, CELoss: 2.2386 KDLoss: 1.2026 
2022-03-10 21:53:49 - train: epoch 0027, iter [04700, 05004], lr: 0.100000, loss: 3.7530, CELoss: 2.4611 KDLoss: 1.2919 
2022-03-10 21:54:22 - train: epoch 0027, iter [04800, 05004], lr: 0.100000, loss: 3.7095, CELoss: 2.4220 KDLoss: 1.2875 
2022-03-10 21:54:56 - train: epoch 0027, iter [04900, 05004], lr: 0.100000, loss: 3.1608, CELoss: 2.1288 KDLoss: 1.0320 
2022-03-10 21:55:28 - train: epoch 0027, iter [05000, 05004], lr: 0.100000, loss: 3.4523, CELoss: 2.2283 KDLoss: 1.2240 
2022-03-10 21:55:28 - train: epoch 027, train_loss: 3.4980
2022-03-10 21:57:57 - eval: epoch: 027, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 51.828%, stu_acc5: 77.186%, stu_test_loss: 2.0693
2022-03-10 21:57:57 - until epoch: 027, tea_best_acc1: 73.950%, stu_best_acc1: 51.828%
2022-03-10 21:57:57 - epoch 028 lr: 0.1
2022-03-10 21:58:35 - train: epoch 0028, iter [00100, 05004], lr: 0.100000, loss: 3.1740, CELoss: 2.0624 KDLoss: 1.1116 
2022-03-10 21:59:10 - train: epoch 0028, iter [00200, 05004], lr: 0.100000, loss: 3.5082, CELoss: 2.2981 KDLoss: 1.2101 
2022-03-10 21:59:42 - train: epoch 0028, iter [00300, 05004], lr: 0.100000, loss: 3.6597, CELoss: 2.4266 KDLoss: 1.2331 
2022-03-10 22:00:15 - train: epoch 0028, iter [00400, 05004], lr: 0.100000, loss: 3.4320, CELoss: 2.2364 KDLoss: 1.1956 
2022-03-10 22:00:50 - train: epoch 0028, iter [00500, 05004], lr: 0.100000, loss: 3.4109, CELoss: 2.1611 KDLoss: 1.2498 
2022-03-10 22:01:23 - train: epoch 0028, iter [00600, 05004], lr: 0.100000, loss: 3.5682, CELoss: 2.3670 KDLoss: 1.2012 
2022-03-10 22:01:56 - train: epoch 0028, iter [00700, 05004], lr: 0.100000, loss: 3.6403, CELoss: 2.4331 KDLoss: 1.2072 
2022-03-10 22:02:30 - train: epoch 0028, iter [00800, 05004], lr: 0.100000, loss: 3.3236, CELoss: 2.1291 KDLoss: 1.1945 
2022-03-10 22:03:03 - train: epoch 0028, iter [00900, 05004], lr: 0.100000, loss: 3.2004, CELoss: 2.1274 KDLoss: 1.0730 
2022-03-10 22:03:36 - train: epoch 0028, iter [01000, 05004], lr: 0.100000, loss: 3.3112, CELoss: 2.1493 KDLoss: 1.1620 
2022-03-10 22:04:10 - train: epoch 0028, iter [01100, 05004], lr: 0.100000, loss: 3.1750, CELoss: 2.0518 KDLoss: 1.1232 
2022-03-10 22:04:44 - train: epoch 0028, iter [01200, 05004], lr: 0.100000, loss: 3.4868, CELoss: 2.2612 KDLoss: 1.2255 
2022-03-10 22:05:17 - train: epoch 0028, iter [01300, 05004], lr: 0.100000, loss: 3.4610, CELoss: 2.2618 KDLoss: 1.1992 
2022-03-10 22:05:51 - train: epoch 0028, iter [01400, 05004], lr: 0.100000, loss: 3.7017, CELoss: 2.4145 KDLoss: 1.2872 
2022-03-10 22:06:25 - train: epoch 0028, iter [01500, 05004], lr: 0.100000, loss: 3.3946, CELoss: 2.2454 KDLoss: 1.1492 
2022-03-10 22:06:58 - train: epoch 0028, iter [01600, 05004], lr: 0.100000, loss: 3.5402, CELoss: 2.2290 KDLoss: 1.3113 
2022-03-10 22:07:31 - train: epoch 0028, iter [01700, 05004], lr: 0.100000, loss: 3.5911, CELoss: 2.3439 KDLoss: 1.2473 
2022-03-10 22:08:05 - train: epoch 0028, iter [01800, 05004], lr: 0.100000, loss: 3.4092, CELoss: 2.2203 KDLoss: 1.1889 
2022-03-10 22:08:38 - train: epoch 0028, iter [01900, 05004], lr: 0.100000, loss: 3.5108, CELoss: 2.2848 KDLoss: 1.2260 
2022-03-10 22:09:13 - train: epoch 0028, iter [02000, 05004], lr: 0.100000, loss: 3.6416, CELoss: 2.3844 KDLoss: 1.2573 
2022-03-10 22:09:44 - train: epoch 0028, iter [02100, 05004], lr: 0.100000, loss: 3.9128, CELoss: 2.5818 KDLoss: 1.3310 
2022-03-10 22:10:19 - train: epoch 0028, iter [02200, 05004], lr: 0.100000, loss: 3.4233, CELoss: 2.2768 KDLoss: 1.1466 
2022-03-10 22:10:51 - train: epoch 0028, iter [02300, 05004], lr: 0.100000, loss: 3.4339, CELoss: 2.2332 KDLoss: 1.2008 
2022-03-10 22:11:25 - train: epoch 0028, iter [02400, 05004], lr: 0.100000, loss: 3.8898, CELoss: 2.4750 KDLoss: 1.4148 
2022-03-10 22:12:00 - train: epoch 0028, iter [02500, 05004], lr: 0.100000, loss: 3.8167, CELoss: 2.4954 KDLoss: 1.3214 
2022-03-10 22:12:32 - train: epoch 0028, iter [02600, 05004], lr: 0.100000, loss: 3.3679, CELoss: 2.2217 KDLoss: 1.1462 
2022-03-10 22:13:06 - train: epoch 0028, iter [02700, 05004], lr: 0.100000, loss: 3.4602, CELoss: 2.2543 KDLoss: 1.2059 
2022-03-10 22:13:39 - train: epoch 0028, iter [02800, 05004], lr: 0.100000, loss: 3.6479, CELoss: 2.4520 KDLoss: 1.1959 
2022-03-10 22:14:13 - train: epoch 0028, iter [02900, 05004], lr: 0.100000, loss: 3.4393, CELoss: 2.3262 KDLoss: 1.1131 
2022-03-10 22:14:46 - train: epoch 0028, iter [03000, 05004], lr: 0.100000, loss: 3.2401, CELoss: 2.1997 KDLoss: 1.0403 
2022-03-10 22:15:20 - train: epoch 0028, iter [03100, 05004], lr: 0.100000, loss: 3.5804, CELoss: 2.3585 KDLoss: 1.2219 
2022-03-10 22:15:54 - train: epoch 0028, iter [03200, 05004], lr: 0.100000, loss: 3.1520, CELoss: 2.0559 KDLoss: 1.0961 
2022-03-10 22:16:27 - train: epoch 0028, iter [03300, 05004], lr: 0.100000, loss: 3.6533, CELoss: 2.3789 KDLoss: 1.2744 
2022-03-10 22:17:01 - train: epoch 0028, iter [03400, 05004], lr: 0.100000, loss: 3.7534, CELoss: 2.4891 KDLoss: 1.2643 
2022-03-10 22:17:34 - train: epoch 0028, iter [03500, 05004], lr: 0.100000, loss: 3.6325, CELoss: 2.3003 KDLoss: 1.3322 
2022-03-10 22:18:08 - train: epoch 0028, iter [03600, 05004], lr: 0.100000, loss: 3.3553, CELoss: 2.2647 KDLoss: 1.0905 
2022-03-10 22:18:41 - train: epoch 0028, iter [03700, 05004], lr: 0.100000, loss: 3.6922, CELoss: 2.4033 KDLoss: 1.2888 
2022-03-10 22:19:14 - train: epoch 0028, iter [03800, 05004], lr: 0.100000, loss: 3.1532, CELoss: 2.0018 KDLoss: 1.1514 
2022-03-10 22:19:48 - train: epoch 0028, iter [03900, 05004], lr: 0.100000, loss: 3.7793, CELoss: 2.5236 KDLoss: 1.2557 
2022-03-10 22:20:22 - train: epoch 0028, iter [04000, 05004], lr: 0.100000, loss: 3.6578, CELoss: 2.4173 KDLoss: 1.2405 
2022-03-10 22:20:54 - train: epoch 0028, iter [04100, 05004], lr: 0.100000, loss: 3.7576, CELoss: 2.4659 KDLoss: 1.2917 
2022-03-10 22:21:28 - train: epoch 0028, iter [04200, 05004], lr: 0.100000, loss: 3.6649, CELoss: 2.3841 KDLoss: 1.2809 
2022-03-10 22:22:02 - train: epoch 0028, iter [04300, 05004], lr: 0.100000, loss: 3.5230, CELoss: 2.2834 KDLoss: 1.2396 
2022-03-10 22:22:35 - train: epoch 0028, iter [04400, 05004], lr: 0.100000, loss: 3.2006, CELoss: 2.1099 KDLoss: 1.0907 
2022-03-10 22:23:09 - train: epoch 0028, iter [04500, 05004], lr: 0.100000, loss: 3.6422, CELoss: 2.3467 KDLoss: 1.2955 
2022-03-10 22:23:43 - train: epoch 0028, iter [04600, 05004], lr: 0.100000, loss: 3.2607, CELoss: 2.1667 KDLoss: 1.0940 
2022-03-10 22:24:16 - train: epoch 0028, iter [04700, 05004], lr: 0.100000, loss: 3.6286, CELoss: 2.4374 KDLoss: 1.1912 
2022-03-10 22:24:50 - train: epoch 0028, iter [04800, 05004], lr: 0.100000, loss: 3.3263, CELoss: 2.1918 KDLoss: 1.1345 
2022-03-10 22:25:24 - train: epoch 0028, iter [04900, 05004], lr: 0.100000, loss: 3.8364, CELoss: 2.4990 KDLoss: 1.3374 
2022-03-10 22:25:55 - train: epoch 0028, iter [05000, 05004], lr: 0.100000, loss: 3.4065, CELoss: 2.2147 KDLoss: 1.1918 
2022-03-10 22:25:56 - train: epoch 028, train_loss: 3.4950
2022-03-10 22:28:25 - eval: epoch: 028, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 50.882%, stu_acc5: 76.444%, stu_test_loss: 2.1309
2022-03-10 22:28:25 - until epoch: 028, tea_best_acc1: 73.950%, stu_best_acc1: 51.828%
2022-03-10 22:28:25 - epoch 029 lr: 0.1
2022-03-10 22:29:03 - train: epoch 0029, iter [00100, 05004], lr: 0.100000, loss: 3.5382, CELoss: 2.3075 KDLoss: 1.2308 
2022-03-10 22:29:37 - train: epoch 0029, iter [00200, 05004], lr: 0.100000, loss: 3.2769, CELoss: 2.0923 KDLoss: 1.1846 
2022-03-10 22:30:11 - train: epoch 0029, iter [00300, 05004], lr: 0.100000, loss: 3.8226, CELoss: 2.5611 KDLoss: 1.2615 
2022-03-10 22:30:44 - train: epoch 0029, iter [00400, 05004], lr: 0.100000, loss: 3.8483, CELoss: 2.4738 KDLoss: 1.3745 
2022-03-10 22:31:19 - train: epoch 0029, iter [00500, 05004], lr: 0.100000, loss: 3.5570, CELoss: 2.3754 KDLoss: 1.1816 
2022-03-10 22:31:52 - train: epoch 0029, iter [00600, 05004], lr: 0.100000, loss: 3.6218, CELoss: 2.3758 KDLoss: 1.2460 
2022-03-10 22:32:26 - train: epoch 0029, iter [00700, 05004], lr: 0.100000, loss: 2.9600, CELoss: 1.8754 KDLoss: 1.0847 
2022-03-10 22:33:01 - train: epoch 0029, iter [00800, 05004], lr: 0.100000, loss: 3.6204, CELoss: 2.3513 KDLoss: 1.2691 
2022-03-10 22:33:33 - train: epoch 0029, iter [00900, 05004], lr: 0.100000, loss: 3.4478, CELoss: 2.2730 KDLoss: 1.1748 
2022-03-10 22:34:07 - train: epoch 0029, iter [01000, 05004], lr: 0.100000, loss: 3.4525, CELoss: 2.2376 KDLoss: 1.2149 
2022-03-10 22:34:41 - train: epoch 0029, iter [01100, 05004], lr: 0.100000, loss: 3.3425, CELoss: 2.1981 KDLoss: 1.1443 
2022-03-10 22:35:14 - train: epoch 0029, iter [01200, 05004], lr: 0.100000, loss: 3.6167, CELoss: 2.3480 KDLoss: 1.2687 
2022-03-10 22:35:48 - train: epoch 0029, iter [01300, 05004], lr: 0.100000, loss: 3.2955, CELoss: 2.2268 KDLoss: 1.0687 
2022-03-10 22:36:20 - train: epoch 0029, iter [01400, 05004], lr: 0.100000, loss: 3.6084, CELoss: 2.3322 KDLoss: 1.2761 
2022-03-10 22:36:54 - train: epoch 0029, iter [01500, 05004], lr: 0.100000, loss: 3.4307, CELoss: 2.2516 KDLoss: 1.1791 
2022-03-10 22:37:28 - train: epoch 0029, iter [01600, 05004], lr: 0.100000, loss: 3.6810, CELoss: 2.3524 KDLoss: 1.3286 
2022-03-10 22:38:02 - train: epoch 0029, iter [01700, 05004], lr: 0.100000, loss: 3.1543, CELoss: 2.0532 KDLoss: 1.1010 
2022-03-10 22:38:34 - train: epoch 0029, iter [01800, 05004], lr: 0.100000, loss: 3.8588, CELoss: 2.5053 KDLoss: 1.3535 
2022-03-10 22:39:08 - train: epoch 0029, iter [01900, 05004], lr: 0.100000, loss: 3.5185, CELoss: 2.2933 KDLoss: 1.2252 
2022-03-10 22:39:41 - train: epoch 0029, iter [02000, 05004], lr: 0.100000, loss: 3.3659, CELoss: 2.1698 KDLoss: 1.1961 
2022-03-10 22:40:14 - train: epoch 0029, iter [02100, 05004], lr: 0.100000, loss: 3.5041, CELoss: 2.2733 KDLoss: 1.2308 
2022-03-10 22:40:48 - train: epoch 0029, iter [02200, 05004], lr: 0.100000, loss: 3.4043, CELoss: 2.2473 KDLoss: 1.1570 
2022-03-10 22:41:21 - train: epoch 0029, iter [02300, 05004], lr: 0.100000, loss: 3.5012, CELoss: 2.3427 KDLoss: 1.1585 
2022-03-10 22:41:54 - train: epoch 0029, iter [02400, 05004], lr: 0.100000, loss: 3.1641, CELoss: 2.0700 KDLoss: 1.0941 
2022-03-10 22:42:28 - train: epoch 0029, iter [02500, 05004], lr: 0.100000, loss: 3.6242, CELoss: 2.4074 KDLoss: 1.2168 
2022-03-10 22:43:02 - train: epoch 0029, iter [02600, 05004], lr: 0.100000, loss: 3.6990, CELoss: 2.4113 KDLoss: 1.2878 
2022-03-10 22:43:35 - train: epoch 0029, iter [02700, 05004], lr: 0.100000, loss: 3.5363, CELoss: 2.3429 KDLoss: 1.1934 
2022-03-10 22:44:08 - train: epoch 0029, iter [02800, 05004], lr: 0.100000, loss: 3.3541, CELoss: 2.1937 KDLoss: 1.1604 
2022-03-10 22:44:42 - train: epoch 0029, iter [02900, 05004], lr: 0.100000, loss: 3.5224, CELoss: 2.3540 KDLoss: 1.1685 
2022-03-10 22:45:15 - train: epoch 0029, iter [03000, 05004], lr: 0.100000, loss: 3.6802, CELoss: 2.3993 KDLoss: 1.2809 
2022-03-10 22:45:49 - train: epoch 0029, iter [03100, 05004], lr: 0.100000, loss: 3.3953, CELoss: 2.2344 KDLoss: 1.1609 
2022-03-10 22:46:22 - train: epoch 0029, iter [03200, 05004], lr: 0.100000, loss: 3.4893, CELoss: 2.2993 KDLoss: 1.1900 
2022-03-10 22:46:55 - train: epoch 0029, iter [03300, 05004], lr: 0.100000, loss: 3.4244, CELoss: 2.2514 KDLoss: 1.1730 
2022-03-10 22:47:29 - train: epoch 0029, iter [03400, 05004], lr: 0.100000, loss: 3.4428, CELoss: 2.2218 KDLoss: 1.2210 
2022-03-10 22:48:02 - train: epoch 0029, iter [03500, 05004], lr: 0.100000, loss: 3.4885, CELoss: 2.2919 KDLoss: 1.1966 
2022-03-10 22:48:36 - train: epoch 0029, iter [03600, 05004], lr: 0.100000, loss: 3.4082, CELoss: 2.2048 KDLoss: 1.2034 
2022-03-10 22:49:09 - train: epoch 0029, iter [03700, 05004], lr: 0.100000, loss: 3.2451, CELoss: 2.1303 KDLoss: 1.1148 
2022-03-10 22:49:42 - train: epoch 0029, iter [03800, 05004], lr: 0.100000, loss: 3.4879, CELoss: 2.2651 KDLoss: 1.2228 
2022-03-10 22:50:17 - train: epoch 0029, iter [03900, 05004], lr: 0.100000, loss: 3.3374, CELoss: 2.1755 KDLoss: 1.1619 
2022-03-10 22:50:49 - train: epoch 0029, iter [04000, 05004], lr: 0.100000, loss: 3.7468, CELoss: 2.4152 KDLoss: 1.3316 
2022-03-10 22:51:22 - train: epoch 0029, iter [04100, 05004], lr: 0.100000, loss: 3.4139, CELoss: 2.2686 KDLoss: 1.1452 
2022-03-10 22:51:56 - train: epoch 0029, iter [04200, 05004], lr: 0.100000, loss: 3.7322, CELoss: 2.3805 KDLoss: 1.3517 
2022-03-10 22:52:29 - train: epoch 0029, iter [04300, 05004], lr: 0.100000, loss: 3.5415, CELoss: 2.3424 KDLoss: 1.1990 
2022-03-10 22:53:03 - train: epoch 0029, iter [04400, 05004], lr: 0.100000, loss: 3.4978, CELoss: 2.2945 KDLoss: 1.2033 
2022-03-10 22:53:36 - train: epoch 0029, iter [04500, 05004], lr: 0.100000, loss: 3.9138, CELoss: 2.5908 KDLoss: 1.3230 
2022-03-10 22:54:09 - train: epoch 0029, iter [04600, 05004], lr: 0.100000, loss: 3.7945, CELoss: 2.4501 KDLoss: 1.3444 
2022-03-10 22:54:42 - train: epoch 0029, iter [04700, 05004], lr: 0.100000, loss: 3.1936, CELoss: 2.0255 KDLoss: 1.1681 
2022-03-10 22:55:16 - train: epoch 0029, iter [04800, 05004], lr: 0.100000, loss: 3.3090, CELoss: 2.1589 KDLoss: 1.1501 
2022-03-10 22:55:50 - train: epoch 0029, iter [04900, 05004], lr: 0.100000, loss: 3.5640, CELoss: 2.3927 KDLoss: 1.1713 
2022-03-10 22:56:21 - train: epoch 0029, iter [05000, 05004], lr: 0.100000, loss: 3.1501, CELoss: 2.0347 KDLoss: 1.1154 
2022-03-10 22:56:22 - train: epoch 029, train_loss: 3.4894
2022-03-10 22:58:50 - eval: epoch: 029, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 52.288%, stu_acc5: 78.018%, stu_test_loss: 2.0327
2022-03-10 22:58:51 - until epoch: 029, tea_best_acc1: 73.950%, stu_best_acc1: 52.288%
2022-03-10 22:58:51 - epoch 030 lr: 0.1
2022-03-10 22:59:29 - train: epoch 0030, iter [00100, 05004], lr: 0.100000, loss: 3.4782, CELoss: 2.3277 KDLoss: 1.1505 
2022-03-10 23:00:03 - train: epoch 0030, iter [00200, 05004], lr: 0.100000, loss: 3.4715, CELoss: 2.1870 KDLoss: 1.2845 
2022-03-10 23:00:36 - train: epoch 0030, iter [00300, 05004], lr: 0.100000, loss: 3.2624, CELoss: 2.0985 KDLoss: 1.1639 
2022-03-10 23:01:10 - train: epoch 0030, iter [00400, 05004], lr: 0.100000, loss: 3.4571, CELoss: 2.2989 KDLoss: 1.1583 
2022-03-10 23:01:43 - train: epoch 0030, iter [00500, 05004], lr: 0.100000, loss: 3.5547, CELoss: 2.3430 KDLoss: 1.2118 
2022-03-10 23:02:17 - train: epoch 0030, iter [00600, 05004], lr: 0.100000, loss: 3.4009, CELoss: 2.1666 KDLoss: 1.2342 
2022-03-10 23:02:50 - train: epoch 0030, iter [00700, 05004], lr: 0.100000, loss: 3.3618, CELoss: 2.1831 KDLoss: 1.1787 
2022-03-10 23:03:24 - train: epoch 0030, iter [00800, 05004], lr: 0.100000, loss: 3.6758, CELoss: 2.3899 KDLoss: 1.2859 
2022-03-10 23:03:57 - train: epoch 0030, iter [00900, 05004], lr: 0.100000, loss: 3.6144, CELoss: 2.4003 KDLoss: 1.2141 
2022-03-10 23:04:31 - train: epoch 0030, iter [01000, 05004], lr: 0.100000, loss: 3.1825, CELoss: 2.0298 KDLoss: 1.1527 
2022-03-10 23:05:04 - train: epoch 0030, iter [01100, 05004], lr: 0.100000, loss: 3.1471, CELoss: 2.0983 KDLoss: 1.0489 
2022-03-10 23:05:37 - train: epoch 0030, iter [01200, 05004], lr: 0.100000, loss: 3.4535, CELoss: 2.3388 KDLoss: 1.1146 
2022-03-10 23:06:10 - train: epoch 0030, iter [01300, 05004], lr: 0.100000, loss: 3.2850, CELoss: 2.1662 KDLoss: 1.1188 
2022-03-10 23:06:44 - train: epoch 0030, iter [01400, 05004], lr: 0.100000, loss: 3.2775, CELoss: 2.0785 KDLoss: 1.1990 
2022-03-10 23:07:18 - train: epoch 0030, iter [01500, 05004], lr: 0.100000, loss: 3.2777, CELoss: 2.1266 KDLoss: 1.1510 
2022-03-10 23:07:51 - train: epoch 0030, iter [01600, 05004], lr: 0.100000, loss: 3.5525, CELoss: 2.2693 KDLoss: 1.2832 
2022-03-10 23:08:25 - train: epoch 0030, iter [01700, 05004], lr: 0.100000, loss: 3.5345, CELoss: 2.4108 KDLoss: 1.1237 
2022-03-10 23:08:59 - train: epoch 0030, iter [01800, 05004], lr: 0.100000, loss: 3.5642, CELoss: 2.3016 KDLoss: 1.2625 
2022-03-10 23:09:32 - train: epoch 0030, iter [01900, 05004], lr: 0.100000, loss: 3.4531, CELoss: 2.3020 KDLoss: 1.1511 
2022-03-10 23:10:05 - train: epoch 0030, iter [02000, 05004], lr: 0.100000, loss: 3.2029, CELoss: 2.1146 KDLoss: 1.0883 
2022-03-10 23:10:39 - train: epoch 0030, iter [02100, 05004], lr: 0.100000, loss: 3.5384, CELoss: 2.3571 KDLoss: 1.1813 
2022-03-10 23:11:12 - train: epoch 0030, iter [02200, 05004], lr: 0.100000, loss: 3.5665, CELoss: 2.2841 KDLoss: 1.2824 
2022-03-10 23:11:46 - train: epoch 0030, iter [02300, 05004], lr: 0.100000, loss: 3.7817, CELoss: 2.3657 KDLoss: 1.4160 
2022-03-10 23:12:20 - train: epoch 0030, iter [02400, 05004], lr: 0.100000, loss: 3.6654, CELoss: 2.3882 KDLoss: 1.2772 
2022-03-10 23:12:53 - train: epoch 0030, iter [02500, 05004], lr: 0.100000, loss: 3.5378, CELoss: 2.3300 KDLoss: 1.2078 
2022-03-10 23:13:27 - train: epoch 0030, iter [02600, 05004], lr: 0.100000, loss: 3.4669, CELoss: 2.2912 KDLoss: 1.1757 
2022-03-10 23:13:59 - train: epoch 0030, iter [02700, 05004], lr: 0.100000, loss: 3.2754, CELoss: 2.1435 KDLoss: 1.1319 
2022-03-10 23:14:34 - train: epoch 0030, iter [02800, 05004], lr: 0.100000, loss: 3.2894, CELoss: 2.2297 KDLoss: 1.0598 
2022-03-10 23:15:06 - train: epoch 0030, iter [02900, 05004], lr: 0.100000, loss: 3.3263, CELoss: 2.1704 KDLoss: 1.1559 
2022-03-10 23:15:40 - train: epoch 0030, iter [03000, 05004], lr: 0.100000, loss: 3.6018, CELoss: 2.3652 KDLoss: 1.2366 
2022-03-10 23:16:13 - train: epoch 0030, iter [03100, 05004], lr: 0.100000, loss: 3.7879, CELoss: 2.4736 KDLoss: 1.3143 
2022-03-10 23:16:47 - train: epoch 0030, iter [03200, 05004], lr: 0.100000, loss: 3.3968, CELoss: 2.1655 KDLoss: 1.2313 
2022-03-10 23:17:20 - train: epoch 0030, iter [03300, 05004], lr: 0.100000, loss: 3.7554, CELoss: 2.4458 KDLoss: 1.3096 
2022-03-10 23:17:54 - train: epoch 0030, iter [03400, 05004], lr: 0.100000, loss: 3.3156, CELoss: 2.1574 KDLoss: 1.1582 
2022-03-10 23:18:28 - train: epoch 0030, iter [03500, 05004], lr: 0.100000, loss: 3.4399, CELoss: 2.3098 KDLoss: 1.1301 
2022-03-10 23:19:01 - train: epoch 0030, iter [03600, 05004], lr: 0.100000, loss: 3.6165, CELoss: 2.3522 KDLoss: 1.2642 
2022-03-10 23:19:35 - train: epoch 0030, iter [03700, 05004], lr: 0.100000, loss: 3.4840, CELoss: 2.2580 KDLoss: 1.2259 
2022-03-10 23:20:09 - train: epoch 0030, iter [03800, 05004], lr: 0.100000, loss: 3.3242, CELoss: 2.1708 KDLoss: 1.1534 
2022-03-10 23:20:41 - train: epoch 0030, iter [03900, 05004], lr: 0.100000, loss: 3.3968, CELoss: 2.2118 KDLoss: 1.1850 
2022-03-10 23:21:15 - train: epoch 0030, iter [04000, 05004], lr: 0.100000, loss: 3.2819, CELoss: 2.2055 KDLoss: 1.0764 
2022-03-10 23:21:48 - train: epoch 0030, iter [04100, 05004], lr: 0.100000, loss: 3.4817, CELoss: 2.2875 KDLoss: 1.1941 
2022-03-10 23:22:22 - train: epoch 0030, iter [04200, 05004], lr: 0.100000, loss: 3.8001, CELoss: 2.4807 KDLoss: 1.3194 
2022-03-10 23:22:56 - train: epoch 0030, iter [04300, 05004], lr: 0.100000, loss: 3.4687, CELoss: 2.2762 KDLoss: 1.1925 
2022-03-10 23:23:29 - train: epoch 0030, iter [04400, 05004], lr: 0.100000, loss: 3.5787, CELoss: 2.3224 KDLoss: 1.2563 
2022-03-10 23:24:03 - train: epoch 0030, iter [04500, 05004], lr: 0.100000, loss: 3.7655, CELoss: 2.4368 KDLoss: 1.3286 
2022-03-10 23:24:36 - train: epoch 0030, iter [04600, 05004], lr: 0.100000, loss: 3.4323, CELoss: 2.1567 KDLoss: 1.2757 
2022-03-10 23:25:10 - train: epoch 0030, iter [04700, 05004], lr: 0.100000, loss: 3.4014, CELoss: 2.2079 KDLoss: 1.1936 
2022-03-10 23:25:42 - train: epoch 0030, iter [04800, 05004], lr: 0.100000, loss: 3.4796, CELoss: 2.2355 KDLoss: 1.2441 
2022-03-10 23:26:16 - train: epoch 0030, iter [04900, 05004], lr: 0.100000, loss: 3.5782, CELoss: 2.3996 KDLoss: 1.1786 
2022-03-10 23:26:48 - train: epoch 0030, iter [05000, 05004], lr: 0.100000, loss: 3.7265, CELoss: 2.4520 KDLoss: 1.2745 
2022-03-10 23:26:48 - train: epoch 030, train_loss: 3.4864
2022-03-10 23:29:17 - eval: epoch: 030, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 52.234%, stu_acc5: 77.896%, stu_test_loss: 2.0571
2022-03-10 23:29:17 - until epoch: 030, tea_best_acc1: 73.950%, stu_best_acc1: 52.288%
2022-03-10 23:29:17 - epoch 031 lr: 0.010000000000000002
2022-03-10 23:29:56 - train: epoch 0031, iter [00100, 05004], lr: 0.010000, loss: 2.9224, CELoss: 1.9999 KDLoss: 0.9225 
2022-03-10 23:30:29 - train: epoch 0031, iter [00200, 05004], lr: 0.010000, loss: 2.8066, CELoss: 1.9281 KDLoss: 0.8785 
2022-03-10 23:31:03 - train: epoch 0031, iter [00300, 05004], lr: 0.010000, loss: 2.7558, CELoss: 1.8796 KDLoss: 0.8762 
2022-03-10 23:31:37 - train: epoch 0031, iter [00400, 05004], lr: 0.010000, loss: 2.7976, CELoss: 1.9256 KDLoss: 0.8720 
2022-03-10 23:32:11 - train: epoch 0031, iter [00500, 05004], lr: 0.010000, loss: 2.7862, CELoss: 1.9396 KDLoss: 0.8466 
2022-03-10 23:32:43 - train: epoch 0031, iter [00600, 05004], lr: 0.010000, loss: 2.7900, CELoss: 1.9080 KDLoss: 0.8821 
2022-03-10 23:33:17 - train: epoch 0031, iter [00700, 05004], lr: 0.010000, loss: 2.6951, CELoss: 1.8769 KDLoss: 0.8182 
2022-03-10 23:33:51 - train: epoch 0031, iter [00800, 05004], lr: 0.010000, loss: 2.5732, CELoss: 1.8399 KDLoss: 0.7333 
2022-03-10 23:34:25 - train: epoch 0031, iter [00900, 05004], lr: 0.010000, loss: 2.6370, CELoss: 1.8810 KDLoss: 0.7560 
2022-03-10 23:34:58 - train: epoch 0031, iter [01000, 05004], lr: 0.010000, loss: 3.0660, CELoss: 2.1706 KDLoss: 0.8954 
2022-03-10 23:35:32 - train: epoch 0031, iter [01100, 05004], lr: 0.010000, loss: 2.8126, CELoss: 1.9580 KDLoss: 0.8547 
2022-03-10 23:36:07 - train: epoch 0031, iter [01200, 05004], lr: 0.010000, loss: 2.7288, CELoss: 1.8684 KDLoss: 0.8604 
2022-03-10 23:36:41 - train: epoch 0031, iter [01300, 05004], lr: 0.010000, loss: 2.0854, CELoss: 1.4442 KDLoss: 0.6411 
2022-03-10 23:37:14 - train: epoch 0031, iter [01400, 05004], lr: 0.010000, loss: 2.6314, CELoss: 1.9009 KDLoss: 0.7305 
2022-03-10 23:37:48 - train: epoch 0031, iter [01500, 05004], lr: 0.010000, loss: 2.8157, CELoss: 1.9818 KDLoss: 0.8339 
2022-03-10 23:38:21 - train: epoch 0031, iter [01600, 05004], lr: 0.010000, loss: 2.5230, CELoss: 1.7820 KDLoss: 0.7409 
2022-03-10 23:38:55 - train: epoch 0031, iter [01700, 05004], lr: 0.010000, loss: 2.6159, CELoss: 1.8377 KDLoss: 0.7782 
2022-03-10 23:39:28 - train: epoch 0031, iter [01800, 05004], lr: 0.010000, loss: 2.2789, CELoss: 1.5399 KDLoss: 0.7390 
2022-03-10 23:40:02 - train: epoch 0031, iter [01900, 05004], lr: 0.010000, loss: 2.6218, CELoss: 1.7986 KDLoss: 0.8232 
2022-03-10 23:40:35 - train: epoch 0031, iter [02000, 05004], lr: 0.010000, loss: 2.5223, CELoss: 1.7501 KDLoss: 0.7722 
2022-03-10 23:41:09 - train: epoch 0031, iter [02100, 05004], lr: 0.010000, loss: 2.3508, CELoss: 1.6603 KDLoss: 0.6905 
2022-03-10 23:41:42 - train: epoch 0031, iter [02200, 05004], lr: 0.010000, loss: 2.5014, CELoss: 1.7338 KDLoss: 0.7676 
2022-03-10 23:42:16 - train: epoch 0031, iter [02300, 05004], lr: 0.010000, loss: 2.4393, CELoss: 1.7336 KDLoss: 0.7057 
2022-03-10 23:42:50 - train: epoch 0031, iter [02400, 05004], lr: 0.010000, loss: 2.4560, CELoss: 1.7541 KDLoss: 0.7019 
2022-03-10 23:43:23 - train: epoch 0031, iter [02500, 05004], lr: 0.010000, loss: 2.9020, CELoss: 2.0533 KDLoss: 0.8486 
2022-03-10 23:43:56 - train: epoch 0031, iter [02600, 05004], lr: 0.010000, loss: 2.6271, CELoss: 1.8552 KDLoss: 0.7720 
2022-03-10 23:44:30 - train: epoch 0031, iter [02700, 05004], lr: 0.010000, loss: 2.5547, CELoss: 1.8151 KDLoss: 0.7396 
2022-03-10 23:45:03 - train: epoch 0031, iter [02800, 05004], lr: 0.010000, loss: 2.7199, CELoss: 1.9639 KDLoss: 0.7560 
2022-03-10 23:45:37 - train: epoch 0031, iter [02900, 05004], lr: 0.010000, loss: 2.7738, CELoss: 2.0161 KDLoss: 0.7578 
2022-03-10 23:46:10 - train: epoch 0031, iter [03000, 05004], lr: 0.010000, loss: 3.1255, CELoss: 2.2478 KDLoss: 0.8776 
2022-03-10 23:46:44 - train: epoch 0031, iter [03100, 05004], lr: 0.010000, loss: 2.5441, CELoss: 1.8274 KDLoss: 0.7166 
2022-03-10 23:47:17 - train: epoch 0031, iter [03200, 05004], lr: 0.010000, loss: 2.6707, CELoss: 1.8651 KDLoss: 0.8057 
2022-03-10 23:47:51 - train: epoch 0031, iter [03300, 05004], lr: 0.010000, loss: 2.3950, CELoss: 1.7454 KDLoss: 0.6496 
2022-03-10 23:48:24 - train: epoch 0031, iter [03400, 05004], lr: 0.010000, loss: 2.8142, CELoss: 2.0720 KDLoss: 0.7423 
2022-03-10 23:48:58 - train: epoch 0031, iter [03500, 05004], lr: 0.010000, loss: 2.5114, CELoss: 1.8488 KDLoss: 0.6626 
2022-03-10 23:49:31 - train: epoch 0031, iter [03600, 05004], lr: 0.010000, loss: 2.6325, CELoss: 1.9214 KDLoss: 0.7111 
2022-03-10 23:50:05 - train: epoch 0031, iter [03700, 05004], lr: 0.010000, loss: 2.4194, CELoss: 1.7462 KDLoss: 0.6732 
2022-03-10 23:50:37 - train: epoch 0031, iter [03800, 05004], lr: 0.010000, loss: 2.3718, CELoss: 1.6667 KDLoss: 0.7051 
2022-03-10 23:51:12 - train: epoch 0031, iter [03900, 05004], lr: 0.010000, loss: 2.5437, CELoss: 1.7888 KDLoss: 0.7549 
2022-03-10 23:51:46 - train: epoch 0031, iter [04000, 05004], lr: 0.010000, loss: 2.4138, CELoss: 1.7043 KDLoss: 0.7095 
2022-03-10 23:52:19 - train: epoch 0031, iter [04100, 05004], lr: 0.010000, loss: 2.3919, CELoss: 1.7784 KDLoss: 0.6134 
2022-03-10 23:52:52 - train: epoch 0031, iter [04200, 05004], lr: 0.010000, loss: 2.5578, CELoss: 1.8316 KDLoss: 0.7262 
2022-03-10 23:53:26 - train: epoch 0031, iter [04300, 05004], lr: 0.010000, loss: 2.3135, CELoss: 1.6771 KDLoss: 0.6364 
2022-03-10 23:54:00 - train: epoch 0031, iter [04400, 05004], lr: 0.010000, loss: 2.7464, CELoss: 2.0314 KDLoss: 0.7151 
2022-03-10 23:54:34 - train: epoch 0031, iter [04500, 05004], lr: 0.010000, loss: 2.4659, CELoss: 1.7824 KDLoss: 0.6835 
2022-03-10 23:55:07 - train: epoch 0031, iter [04600, 05004], lr: 0.010000, loss: 2.5440, CELoss: 1.7852 KDLoss: 0.7588 
2022-03-10 23:55:41 - train: epoch 0031, iter [04700, 05004], lr: 0.010000, loss: 2.2909, CELoss: 1.6096 KDLoss: 0.6814 
2022-03-10 23:56:15 - train: epoch 0031, iter [04800, 05004], lr: 0.010000, loss: 2.4894, CELoss: 1.7882 KDLoss: 0.7012 
2022-03-10 23:56:48 - train: epoch 0031, iter [04900, 05004], lr: 0.010000, loss: 2.5457, CELoss: 1.8213 KDLoss: 0.7244 
2022-03-10 23:57:20 - train: epoch 0031, iter [05000, 05004], lr: 0.010000, loss: 2.3407, CELoss: 1.6993 KDLoss: 0.6414 
2022-03-10 23:57:21 - train: epoch 031, train_loss: 2.5719
2022-03-10 23:59:51 - eval: epoch: 031, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 64.998%, stu_acc5: 86.318%, stu_test_loss: 1.4455
2022-03-10 23:59:51 - until epoch: 031, tea_best_acc1: 73.950%, stu_best_acc1: 64.998%
2022-03-10 23:59:51 - epoch 032 lr: 0.010000000000000002
2022-03-11 00:00:30 - train: epoch 0032, iter [00100, 05004], lr: 0.010000, loss: 2.0871, CELoss: 1.4921 KDLoss: 0.5950 
2022-03-11 00:01:03 - train: epoch 0032, iter [00200, 05004], lr: 0.010000, loss: 2.2600, CELoss: 1.5929 KDLoss: 0.6671 
2022-03-11 00:01:36 - train: epoch 0032, iter [00300, 05004], lr: 0.010000, loss: 2.2668, CELoss: 1.6031 KDLoss: 0.6637 
2022-03-11 00:02:10 - train: epoch 0032, iter [00400, 05004], lr: 0.010000, loss: 2.5878, CELoss: 1.8872 KDLoss: 0.7006 
2022-03-11 00:02:43 - train: epoch 0032, iter [00500, 05004], lr: 0.010000, loss: 2.4727, CELoss: 1.7180 KDLoss: 0.7546 
2022-03-11 00:03:17 - train: epoch 0032, iter [00600, 05004], lr: 0.010000, loss: 2.4222, CELoss: 1.7160 KDLoss: 0.7062 
2022-03-11 00:03:51 - train: epoch 0032, iter [00700, 05004], lr: 0.010000, loss: 2.4061, CELoss: 1.6838 KDLoss: 0.7223 
2022-03-11 00:04:24 - train: epoch 0032, iter [00800, 05004], lr: 0.010000, loss: 2.4885, CELoss: 1.8151 KDLoss: 0.6734 
2022-03-11 00:04:57 - train: epoch 0032, iter [00900, 05004], lr: 0.010000, loss: 2.4252, CELoss: 1.6812 KDLoss: 0.7440 
2022-03-11 00:05:32 - train: epoch 0032, iter [01000, 05004], lr: 0.010000, loss: 2.7787, CELoss: 2.0130 KDLoss: 0.7657 
2022-03-11 00:06:05 - train: epoch 0032, iter [01100, 05004], lr: 0.010000, loss: 2.2822, CELoss: 1.6277 KDLoss: 0.6545 
2022-03-11 00:06:39 - train: epoch 0032, iter [01200, 05004], lr: 0.010000, loss: 2.4425, CELoss: 1.7196 KDLoss: 0.7229 
2022-03-11 00:07:13 - train: epoch 0032, iter [01300, 05004], lr: 0.010000, loss: 2.3281, CELoss: 1.6856 KDLoss: 0.6426 
2022-03-11 00:07:46 - train: epoch 0032, iter [01400, 05004], lr: 0.010000, loss: 2.3705, CELoss: 1.7241 KDLoss: 0.6464 
2022-03-11 00:08:19 - train: epoch 0032, iter [01500, 05004], lr: 0.010000, loss: 2.5882, CELoss: 1.8271 KDLoss: 0.7611 
2022-03-11 00:08:53 - train: epoch 0032, iter [01600, 05004], lr: 0.010000, loss: 2.5686, CELoss: 1.8892 KDLoss: 0.6794 
2022-03-11 00:09:26 - train: epoch 0032, iter [01700, 05004], lr: 0.010000, loss: 2.5703, CELoss: 1.8707 KDLoss: 0.6995 
2022-03-11 00:10:01 - train: epoch 0032, iter [01800, 05004], lr: 0.010000, loss: 2.8302, CELoss: 2.1305 KDLoss: 0.6997 
2022-03-11 00:10:33 - train: epoch 0032, iter [01900, 05004], lr: 0.010000, loss: 2.0191, CELoss: 1.3987 KDLoss: 0.6204 
2022-03-11 00:11:08 - train: epoch 0032, iter [02000, 05004], lr: 0.010000, loss: 2.2513, CELoss: 1.6008 KDLoss: 0.6504 
2022-03-11 00:11:41 - train: epoch 0032, iter [02100, 05004], lr: 0.010000, loss: 2.1875, CELoss: 1.5311 KDLoss: 0.6565 
2022-03-11 00:12:15 - train: epoch 0032, iter [02200, 05004], lr: 0.010000, loss: 2.3198, CELoss: 1.7027 KDLoss: 0.6171 
2022-03-11 00:12:48 - train: epoch 0032, iter [02300, 05004], lr: 0.010000, loss: 2.4040, CELoss: 1.7713 KDLoss: 0.6327 
2022-03-11 00:13:22 - train: epoch 0032, iter [02400, 05004], lr: 0.010000, loss: 2.1619, CELoss: 1.5447 KDLoss: 0.6173 
2022-03-11 00:13:55 - train: epoch 0032, iter [02500, 05004], lr: 0.010000, loss: 2.2316, CELoss: 1.6067 KDLoss: 0.6250 
2022-03-11 00:14:29 - train: epoch 0032, iter [02600, 05004], lr: 0.010000, loss: 2.1025, CELoss: 1.5369 KDLoss: 0.5656 
2022-03-11 00:15:02 - train: epoch 0032, iter [02700, 05004], lr: 0.010000, loss: 2.2274, CELoss: 1.5537 KDLoss: 0.6738 
2022-03-11 00:15:36 - train: epoch 0032, iter [02800, 05004], lr: 0.010000, loss: 2.4546, CELoss: 1.7975 KDLoss: 0.6571 
2022-03-11 00:16:10 - train: epoch 0032, iter [02900, 05004], lr: 0.010000, loss: 2.1866, CELoss: 1.5472 KDLoss: 0.6394 
2022-03-11 00:16:43 - train: epoch 0032, iter [03000, 05004], lr: 0.010000, loss: 2.1032, CELoss: 1.4820 KDLoss: 0.6212 
2022-03-11 00:17:17 - train: epoch 0032, iter [03100, 05004], lr: 0.010000, loss: 2.5565, CELoss: 1.8378 KDLoss: 0.7186 
2022-03-11 00:17:50 - train: epoch 0032, iter [03200, 05004], lr: 0.010000, loss: 2.4154, CELoss: 1.7560 KDLoss: 0.6594 
2022-03-11 00:18:24 - train: epoch 0032, iter [03300, 05004], lr: 0.010000, loss: 2.2870, CELoss: 1.6560 KDLoss: 0.6310 
2022-03-11 00:18:58 - train: epoch 0032, iter [03400, 05004], lr: 0.010000, loss: 2.2833, CELoss: 1.6059 KDLoss: 0.6774 
2022-03-11 00:19:31 - train: epoch 0032, iter [03500, 05004], lr: 0.010000, loss: 2.2601, CELoss: 1.6140 KDLoss: 0.6461 
2022-03-11 00:20:05 - train: epoch 0032, iter [03600, 05004], lr: 0.010000, loss: 2.5690, CELoss: 1.8994 KDLoss: 0.6696 
2022-03-11 00:20:38 - train: epoch 0032, iter [03700, 05004], lr: 0.010000, loss: 2.4048, CELoss: 1.7298 KDLoss: 0.6750 
2022-03-11 00:21:12 - train: epoch 0032, iter [03800, 05004], lr: 0.010000, loss: 2.0074, CELoss: 1.4422 KDLoss: 0.5652 
2022-03-11 00:21:45 - train: epoch 0032, iter [03900, 05004], lr: 0.010000, loss: 1.9937, CELoss: 1.4162 KDLoss: 0.5775 
2022-03-11 00:22:20 - train: epoch 0032, iter [04000, 05004], lr: 0.010000, loss: 2.4001, CELoss: 1.7699 KDLoss: 0.6301 
2022-03-11 00:22:53 - train: epoch 0032, iter [04100, 05004], lr: 0.010000, loss: 2.3072, CELoss: 1.6276 KDLoss: 0.6797 
2022-03-11 00:23:27 - train: epoch 0032, iter [04200, 05004], lr: 0.010000, loss: 2.1760, CELoss: 1.5705 KDLoss: 0.6055 
2022-03-11 00:24:00 - train: epoch 0032, iter [04300, 05004], lr: 0.010000, loss: 2.5019, CELoss: 1.7972 KDLoss: 0.7047 
2022-03-11 00:24:34 - train: epoch 0032, iter [04400, 05004], lr: 0.010000, loss: 2.0948, CELoss: 1.5016 KDLoss: 0.5932 
2022-03-11 00:25:07 - train: epoch 0032, iter [04500, 05004], lr: 0.010000, loss: 2.5065, CELoss: 1.8379 KDLoss: 0.6686 
2022-03-11 00:25:41 - train: epoch 0032, iter [04600, 05004], lr: 0.010000, loss: 2.3186, CELoss: 1.6688 KDLoss: 0.6498 
2022-03-11 00:26:15 - train: epoch 0032, iter [04700, 05004], lr: 0.010000, loss: 2.3962, CELoss: 1.7677 KDLoss: 0.6285 
2022-03-11 00:26:48 - train: epoch 0032, iter [04800, 05004], lr: 0.010000, loss: 2.1606, CELoss: 1.5385 KDLoss: 0.6221 
2022-03-11 00:27:21 - train: epoch 0032, iter [04900, 05004], lr: 0.010000, loss: 2.2884, CELoss: 1.6230 KDLoss: 0.6653 
2022-03-11 00:27:53 - train: epoch 0032, iter [05000, 05004], lr: 0.010000, loss: 2.2786, CELoss: 1.6560 KDLoss: 0.6226 
2022-03-11 00:27:54 - train: epoch 032, train_loss: 2.3683
2022-03-11 00:30:23 - eval: epoch: 032, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 65.726%, stu_acc5: 86.782%, stu_test_loss: 1.4102
2022-03-11 00:30:24 - until epoch: 032, tea_best_acc1: 73.950%, stu_best_acc1: 65.726%
2022-03-11 00:30:24 - epoch 033 lr: 0.010000000000000002
2022-03-11 00:31:02 - train: epoch 0033, iter [00100, 05004], lr: 0.010000, loss: 2.0957, CELoss: 1.4620 KDLoss: 0.6337 
2022-03-11 00:31:36 - train: epoch 0033, iter [00200, 05004], lr: 0.010000, loss: 2.2036, CELoss: 1.6549 KDLoss: 0.5488 
2022-03-11 00:32:09 - train: epoch 0033, iter [00300, 05004], lr: 0.010000, loss: 2.2917, CELoss: 1.6829 KDLoss: 0.6088 
2022-03-11 00:32:43 - train: epoch 0033, iter [00400, 05004], lr: 0.010000, loss: 2.1772, CELoss: 1.6050 KDLoss: 0.5722 
2022-03-11 00:33:16 - train: epoch 0033, iter [00500, 05004], lr: 0.010000, loss: 2.4573, CELoss: 1.7736 KDLoss: 0.6837 
2022-03-11 00:33:49 - train: epoch 0033, iter [00600, 05004], lr: 0.010000, loss: 2.3287, CELoss: 1.6601 KDLoss: 0.6685 
2022-03-11 00:34:24 - train: epoch 0033, iter [00700, 05004], lr: 0.010000, loss: 2.4844, CELoss: 1.8149 KDLoss: 0.6695 
2022-03-11 00:34:56 - train: epoch 0033, iter [00800, 05004], lr: 0.010000, loss: 2.5640, CELoss: 1.8317 KDLoss: 0.7323 
2022-03-11 00:35:31 - train: epoch 0033, iter [00900, 05004], lr: 0.010000, loss: 2.1651, CELoss: 1.5701 KDLoss: 0.5950 
2022-03-11 00:36:03 - train: epoch 0033, iter [01000, 05004], lr: 0.010000, loss: 2.4237, CELoss: 1.7796 KDLoss: 0.6441 
2022-03-11 00:36:37 - train: epoch 0033, iter [01100, 05004], lr: 0.010000, loss: 1.9066, CELoss: 1.3483 KDLoss: 0.5583 
2022-03-11 00:37:11 - train: epoch 0033, iter [01200, 05004], lr: 0.010000, loss: 2.6077, CELoss: 1.9151 KDLoss: 0.6926 
2022-03-11 00:37:44 - train: epoch 0033, iter [01300, 05004], lr: 0.010000, loss: 2.1436, CELoss: 1.5611 KDLoss: 0.5825 
2022-03-11 00:38:17 - train: epoch 0033, iter [01400, 05004], lr: 0.010000, loss: 2.2152, CELoss: 1.5796 KDLoss: 0.6357 
2022-03-11 00:38:52 - train: epoch 0033, iter [01500, 05004], lr: 0.010000, loss: 2.5057, CELoss: 1.8486 KDLoss: 0.6571 
2022-03-11 00:39:24 - train: epoch 0033, iter [01600, 05004], lr: 0.010000, loss: 2.6239, CELoss: 1.8829 KDLoss: 0.7410 
2022-03-11 00:39:58 - train: epoch 0033, iter [01700, 05004], lr: 0.010000, loss: 2.3577, CELoss: 1.7164 KDLoss: 0.6412 
2022-03-11 00:40:31 - train: epoch 0033, iter [01800, 05004], lr: 0.010000, loss: 2.2312, CELoss: 1.5777 KDLoss: 0.6535 
2022-03-11 00:41:05 - train: epoch 0033, iter [01900, 05004], lr: 0.010000, loss: 2.3303, CELoss: 1.6904 KDLoss: 0.6399 
2022-03-11 00:41:39 - train: epoch 0033, iter [02000, 05004], lr: 0.010000, loss: 2.1775, CELoss: 1.5062 KDLoss: 0.6713 
2022-03-11 00:42:11 - train: epoch 0033, iter [02100, 05004], lr: 0.010000, loss: 2.4964, CELoss: 1.7812 KDLoss: 0.7151 
2022-03-11 00:42:45 - train: epoch 0033, iter [02200, 05004], lr: 0.010000, loss: 2.3126, CELoss: 1.6959 KDLoss: 0.6167 
2022-03-11 00:43:19 - train: epoch 0033, iter [02300, 05004], lr: 0.010000, loss: 2.1374, CELoss: 1.5223 KDLoss: 0.6150 
2022-03-11 00:43:52 - train: epoch 0033, iter [02400, 05004], lr: 0.010000, loss: 2.5082, CELoss: 1.8750 KDLoss: 0.6332 
2022-03-11 00:44:25 - train: epoch 0033, iter [02500, 05004], lr: 0.010000, loss: 2.2901, CELoss: 1.6527 KDLoss: 0.6374 
2022-03-11 00:44:59 - train: epoch 0033, iter [02600, 05004], lr: 0.010000, loss: 2.1829, CELoss: 1.5494 KDLoss: 0.6335 
2022-03-11 00:45:32 - train: epoch 0033, iter [02700, 05004], lr: 0.010000, loss: 2.2270, CELoss: 1.6214 KDLoss: 0.6056 
2022-03-11 00:46:06 - train: epoch 0033, iter [02800, 05004], lr: 0.010000, loss: 2.2534, CELoss: 1.6386 KDLoss: 0.6147 
2022-03-11 00:46:38 - train: epoch 0033, iter [02900, 05004], lr: 0.010000, loss: 2.1744, CELoss: 1.5754 KDLoss: 0.5990 
2022-03-11 00:47:13 - train: epoch 0033, iter [03000, 05004], lr: 0.010000, loss: 2.3213, CELoss: 1.7050 KDLoss: 0.6163 
2022-03-11 00:47:46 - train: epoch 0033, iter [03100, 05004], lr: 0.010000, loss: 2.2284, CELoss: 1.5953 KDLoss: 0.6331 
2022-03-11 00:48:19 - train: epoch 0033, iter [03200, 05004], lr: 0.010000, loss: 2.4386, CELoss: 1.7478 KDLoss: 0.6908 
2022-03-11 00:48:52 - train: epoch 0033, iter [03300, 05004], lr: 0.010000, loss: 2.1895, CELoss: 1.6158 KDLoss: 0.5736 
2022-03-11 00:49:26 - train: epoch 0033, iter [03400, 05004], lr: 0.010000, loss: 2.0816, CELoss: 1.4740 KDLoss: 0.6076 
2022-03-11 00:49:58 - train: epoch 0033, iter [03500, 05004], lr: 0.010000, loss: 2.4121, CELoss: 1.7053 KDLoss: 0.7068 
2022-03-11 00:50:32 - train: epoch 0033, iter [03600, 05004], lr: 0.010000, loss: 2.5249, CELoss: 1.8140 KDLoss: 0.7109 
2022-03-11 00:51:05 - train: epoch 0033, iter [03700, 05004], lr: 0.010000, loss: 2.2111, CELoss: 1.5340 KDLoss: 0.6771 
2022-03-11 00:51:38 - train: epoch 0033, iter [03800, 05004], lr: 0.010000, loss: 2.3134, CELoss: 1.6639 KDLoss: 0.6495 
2022-03-11 00:52:11 - train: epoch 0033, iter [03900, 05004], lr: 0.010000, loss: 2.4817, CELoss: 1.8760 KDLoss: 0.6058 
2022-03-11 00:52:44 - train: epoch 0033, iter [04000, 05004], lr: 0.010000, loss: 2.4400, CELoss: 1.7912 KDLoss: 0.6488 
2022-03-11 00:53:18 - train: epoch 0033, iter [04100, 05004], lr: 0.010000, loss: 2.2901, CELoss: 1.6815 KDLoss: 0.6086 
2022-03-11 00:53:52 - train: epoch 0033, iter [04200, 05004], lr: 0.010000, loss: 1.9769, CELoss: 1.3893 KDLoss: 0.5876 
2022-03-11 00:54:24 - train: epoch 0033, iter [04300, 05004], lr: 0.010000, loss: 2.3167, CELoss: 1.7076 KDLoss: 0.6091 
2022-03-11 00:54:58 - train: epoch 0033, iter [04400, 05004], lr: 0.010000, loss: 2.3217, CELoss: 1.7381 KDLoss: 0.5836 
2022-03-11 00:55:31 - train: epoch 0033, iter [04500, 05004], lr: 0.010000, loss: 2.4666, CELoss: 1.8088 KDLoss: 0.6579 
2022-03-11 00:56:04 - train: epoch 0033, iter [04600, 05004], lr: 0.010000, loss: 2.2540, CELoss: 1.6022 KDLoss: 0.6518 
2022-03-11 00:56:38 - train: epoch 0033, iter [04700, 05004], lr: 0.010000, loss: 2.4856, CELoss: 1.7891 KDLoss: 0.6966 
2022-03-11 00:57:10 - train: epoch 0033, iter [04800, 05004], lr: 0.010000, loss: 2.5578, CELoss: 1.8938 KDLoss: 0.6640 
2022-03-11 00:57:44 - train: epoch 0033, iter [04900, 05004], lr: 0.010000, loss: 2.2937, CELoss: 1.6630 KDLoss: 0.6307 
2022-03-11 00:58:15 - train: epoch 0033, iter [05000, 05004], lr: 0.010000, loss: 2.5293, CELoss: 1.8800 KDLoss: 0.6492 
2022-03-11 00:58:16 - train: epoch 033, train_loss: 2.2894
2022-03-11 01:00:44 - eval: epoch: 033, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 66.214%, stu_acc5: 87.166%, stu_test_loss: 1.3839
2022-03-11 01:00:45 - until epoch: 033, tea_best_acc1: 73.950%, stu_best_acc1: 66.214%
2022-03-11 01:00:45 - epoch 034 lr: 0.010000000000000002
2022-03-11 01:01:24 - train: epoch 0034, iter [00100, 05004], lr: 0.010000, loss: 2.1451, CELoss: 1.5581 KDLoss: 0.5870 
2022-03-11 01:01:57 - train: epoch 0034, iter [00200, 05004], lr: 0.010000, loss: 2.1762, CELoss: 1.5714 KDLoss: 0.6048 
2022-03-11 01:02:30 - train: epoch 0034, iter [00300, 05004], lr: 0.010000, loss: 2.1576, CELoss: 1.5599 KDLoss: 0.5977 
2022-03-11 01:03:04 - train: epoch 0034, iter [00400, 05004], lr: 0.010000, loss: 2.0274, CELoss: 1.4696 KDLoss: 0.5578 
2022-03-11 01:03:38 - train: epoch 0034, iter [00500, 05004], lr: 0.010000, loss: 2.1155, CELoss: 1.5413 KDLoss: 0.5741 
2022-03-11 01:04:12 - train: epoch 0034, iter [00600, 05004], lr: 0.010000, loss: 2.3188, CELoss: 1.6807 KDLoss: 0.6381 
2022-03-11 01:04:45 - train: epoch 0034, iter [00700, 05004], lr: 0.010000, loss: 2.1553, CELoss: 1.5599 KDLoss: 0.5953 
2022-03-11 01:05:19 - train: epoch 0034, iter [00800, 05004], lr: 0.010000, loss: 2.2132, CELoss: 1.6384 KDLoss: 0.5748 
2022-03-11 01:05:52 - train: epoch 0034, iter [00900, 05004], lr: 0.010000, loss: 2.1427, CELoss: 1.5371 KDLoss: 0.6057 
2022-03-11 01:06:26 - train: epoch 0034, iter [01000, 05004], lr: 0.010000, loss: 2.0404, CELoss: 1.5322 KDLoss: 0.5082 
2022-03-11 01:06:59 - train: epoch 0034, iter [01100, 05004], lr: 0.010000, loss: 2.2666, CELoss: 1.5905 KDLoss: 0.6762 
2022-03-11 01:07:33 - train: epoch 0034, iter [01200, 05004], lr: 0.010000, loss: 2.3781, CELoss: 1.7096 KDLoss: 0.6685 
2022-03-11 01:08:05 - train: epoch 0034, iter [01300, 05004], lr: 0.010000, loss: 2.0836, CELoss: 1.4864 KDLoss: 0.5972 
2022-03-11 01:08:39 - train: epoch 0034, iter [01400, 05004], lr: 0.010000, loss: 2.1265, CELoss: 1.5248 KDLoss: 0.6018 
2022-03-11 01:09:13 - train: epoch 0034, iter [01500, 05004], lr: 0.010000, loss: 2.1422, CELoss: 1.5685 KDLoss: 0.5738 
2022-03-11 01:09:46 - train: epoch 0034, iter [01600, 05004], lr: 0.010000, loss: 2.1419, CELoss: 1.5419 KDLoss: 0.5999 
2022-03-11 01:10:20 - train: epoch 0034, iter [01700, 05004], lr: 0.010000, loss: 2.2602, CELoss: 1.6335 KDLoss: 0.6267 
2022-03-11 01:10:53 - train: epoch 0034, iter [01800, 05004], lr: 0.010000, loss: 2.4229, CELoss: 1.8070 KDLoss: 0.6159 
2022-03-11 01:11:27 - train: epoch 0034, iter [01900, 05004], lr: 0.010000, loss: 2.3718, CELoss: 1.7272 KDLoss: 0.6446 
2022-03-11 01:12:01 - train: epoch 0034, iter [02000, 05004], lr: 0.010000, loss: 2.2091, CELoss: 1.5845 KDLoss: 0.6246 
2022-03-11 01:12:34 - train: epoch 0034, iter [02100, 05004], lr: 0.010000, loss: 2.3272, CELoss: 1.6591 KDLoss: 0.6681 
2022-03-11 01:13:07 - train: epoch 0034, iter [02200, 05004], lr: 0.010000, loss: 1.9990, CELoss: 1.4712 KDLoss: 0.5279 
2022-03-11 01:13:41 - train: epoch 0034, iter [02300, 05004], lr: 0.010000, loss: 2.4083, CELoss: 1.7753 KDLoss: 0.6329 
2022-03-11 01:14:15 - train: epoch 0034, iter [02400, 05004], lr: 0.010000, loss: 2.0578, CELoss: 1.4711 KDLoss: 0.5867 
2022-03-11 01:14:47 - train: epoch 0034, iter [02500, 05004], lr: 0.010000, loss: 2.3713, CELoss: 1.7491 KDLoss: 0.6222 
2022-03-11 01:15:21 - train: epoch 0034, iter [02600, 05004], lr: 0.010000, loss: 2.3125, CELoss: 1.7400 KDLoss: 0.5725 
2022-03-11 01:15:54 - train: epoch 0034, iter [02700, 05004], lr: 0.010000, loss: 2.3488, CELoss: 1.7530 KDLoss: 0.5959 
2022-03-11 01:16:28 - train: epoch 0034, iter [02800, 05004], lr: 0.010000, loss: 2.0470, CELoss: 1.5000 KDLoss: 0.5470 
2022-03-11 01:17:02 - train: epoch 0034, iter [02900, 05004], lr: 0.010000, loss: 1.9063, CELoss: 1.3670 KDLoss: 0.5392 
2022-03-11 01:17:35 - train: epoch 0034, iter [03000, 05004], lr: 0.010000, loss: 2.0055, CELoss: 1.4561 KDLoss: 0.5494 
2022-03-11 01:18:09 - train: epoch 0034, iter [03100, 05004], lr: 0.010000, loss: 2.1143, CELoss: 1.5422 KDLoss: 0.5721 
2022-03-11 01:18:42 - train: epoch 0034, iter [03200, 05004], lr: 0.010000, loss: 2.2385, CELoss: 1.6340 KDLoss: 0.6045 
2022-03-11 01:19:16 - train: epoch 0034, iter [03300, 05004], lr: 0.010000, loss: 2.1515, CELoss: 1.5426 KDLoss: 0.6089 
2022-03-11 01:19:49 - train: epoch 0034, iter [03400, 05004], lr: 0.010000, loss: 2.4632, CELoss: 1.8107 KDLoss: 0.6525 
2022-03-11 01:20:22 - train: epoch 0034, iter [03500, 05004], lr: 0.010000, loss: 2.0946, CELoss: 1.5129 KDLoss: 0.5817 
2022-03-11 01:20:57 - train: epoch 0034, iter [03600, 05004], lr: 0.010000, loss: 1.9522, CELoss: 1.3936 KDLoss: 0.5586 
2022-03-11 01:21:30 - train: epoch 0034, iter [03700, 05004], lr: 0.010000, loss: 2.2955, CELoss: 1.6776 KDLoss: 0.6179 
2022-03-11 01:22:04 - train: epoch 0034, iter [03800, 05004], lr: 0.010000, loss: 2.0689, CELoss: 1.5109 KDLoss: 0.5580 
2022-03-11 01:22:37 - train: epoch 0034, iter [03900, 05004], lr: 0.010000, loss: 2.5991, CELoss: 1.9536 KDLoss: 0.6455 
2022-03-11 01:23:11 - train: epoch 0034, iter [04000, 05004], lr: 0.010000, loss: 2.1991, CELoss: 1.5583 KDLoss: 0.6408 
2022-03-11 01:23:46 - train: epoch 0034, iter [04100, 05004], lr: 0.010000, loss: 2.4119, CELoss: 1.7995 KDLoss: 0.6124 
2022-03-11 01:24:19 - train: epoch 0034, iter [04200, 05004], lr: 0.010000, loss: 2.2893, CELoss: 1.6148 KDLoss: 0.6745 
2022-03-11 01:24:53 - train: epoch 0034, iter [04300, 05004], lr: 0.010000, loss: 2.1080, CELoss: 1.4699 KDLoss: 0.6382 
2022-03-11 01:25:26 - train: epoch 0034, iter [04400, 05004], lr: 0.010000, loss: 2.0241, CELoss: 1.4195 KDLoss: 0.6046 
2022-03-11 01:26:00 - train: epoch 0034, iter [04500, 05004], lr: 0.010000, loss: 2.3485, CELoss: 1.7375 KDLoss: 0.6110 
2022-03-11 01:26:33 - train: epoch 0034, iter [04600, 05004], lr: 0.010000, loss: 2.5223, CELoss: 1.8545 KDLoss: 0.6678 
2022-03-11 01:27:06 - train: epoch 0034, iter [04700, 05004], lr: 0.010000, loss: 2.3713, CELoss: 1.6904 KDLoss: 0.6809 
2022-03-11 01:27:40 - train: epoch 0034, iter [04800, 05004], lr: 0.010000, loss: 2.2696, CELoss: 1.6534 KDLoss: 0.6162 
2022-03-11 01:28:14 - train: epoch 0034, iter [04900, 05004], lr: 0.010000, loss: 2.2192, CELoss: 1.6681 KDLoss: 0.5511 
2022-03-11 01:28:46 - train: epoch 0034, iter [05000, 05004], lr: 0.010000, loss: 2.1121, CELoss: 1.5350 KDLoss: 0.5772 
2022-03-11 01:28:46 - train: epoch 034, train_loss: 2.2411
2022-03-11 01:31:15 - eval: epoch: 034, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 66.540%, stu_acc5: 87.374%, stu_test_loss: 1.3691
2022-03-11 01:31:16 - until epoch: 034, tea_best_acc1: 73.950%, stu_best_acc1: 66.540%
2022-03-11 01:31:16 - epoch 035 lr: 0.010000000000000002
2022-03-11 01:31:54 - train: epoch 0035, iter [00100, 05004], lr: 0.010000, loss: 2.1450, CELoss: 1.5700 KDLoss: 0.5750 
2022-03-11 01:32:28 - train: epoch 0035, iter [00200, 05004], lr: 0.010000, loss: 2.1225, CELoss: 1.5150 KDLoss: 0.6075 
2022-03-11 01:33:00 - train: epoch 0035, iter [00300, 05004], lr: 0.010000, loss: 2.3040, CELoss: 1.6536 KDLoss: 0.6504 
2022-03-11 01:33:33 - train: epoch 0035, iter [00400, 05004], lr: 0.010000, loss: 2.0091, CELoss: 1.4578 KDLoss: 0.5513 
2022-03-11 01:34:06 - train: epoch 0035, iter [00500, 05004], lr: 0.010000, loss: 2.0537, CELoss: 1.5281 KDLoss: 0.5256 
2022-03-11 01:34:40 - train: epoch 0035, iter [00600, 05004], lr: 0.010000, loss: 2.0993, CELoss: 1.5144 KDLoss: 0.5849 
2022-03-11 01:35:13 - train: epoch 0035, iter [00700, 05004], lr: 0.010000, loss: 2.0261, CELoss: 1.4460 KDLoss: 0.5801 
2022-03-11 01:35:47 - train: epoch 0035, iter [00800, 05004], lr: 0.010000, loss: 2.2652, CELoss: 1.6413 KDLoss: 0.6239 
2022-03-11 01:36:21 - train: epoch 0035, iter [00900, 05004], lr: 0.010000, loss: 2.4265, CELoss: 1.7882 KDLoss: 0.6383 
2022-03-11 01:36:54 - train: epoch 0035, iter [01000, 05004], lr: 0.010000, loss: 1.9061, CELoss: 1.3864 KDLoss: 0.5197 
2022-03-11 01:37:28 - train: epoch 0035, iter [01100, 05004], lr: 0.010000, loss: 2.2491, CELoss: 1.6442 KDLoss: 0.6049 
2022-03-11 01:38:01 - train: epoch 0035, iter [01200, 05004], lr: 0.010000, loss: 2.0915, CELoss: 1.4789 KDLoss: 0.6126 
2022-03-11 01:38:35 - train: epoch 0035, iter [01300, 05004], lr: 0.010000, loss: 2.3534, CELoss: 1.7245 KDLoss: 0.6289 
2022-03-11 01:39:09 - train: epoch 0035, iter [01400, 05004], lr: 0.010000, loss: 2.2508, CELoss: 1.6665 KDLoss: 0.5843 
2022-03-11 01:39:42 - train: epoch 0035, iter [01500, 05004], lr: 0.010000, loss: 2.2651, CELoss: 1.6597 KDLoss: 0.6053 
2022-03-11 01:40:16 - train: epoch 0035, iter [01600, 05004], lr: 0.010000, loss: 2.0868, CELoss: 1.5148 KDLoss: 0.5720 
2022-03-11 01:40:49 - train: epoch 0035, iter [01700, 05004], lr: 0.010000, loss: 2.0464, CELoss: 1.4339 KDLoss: 0.6125 
2022-03-11 01:41:23 - train: epoch 0035, iter [01800, 05004], lr: 0.010000, loss: 2.2611, CELoss: 1.6752 KDLoss: 0.5860 
2022-03-11 01:41:57 - train: epoch 0035, iter [01900, 05004], lr: 0.010000, loss: 2.2470, CELoss: 1.6461 KDLoss: 0.6008 
2022-03-11 01:42:31 - train: epoch 0035, iter [02000, 05004], lr: 0.010000, loss: 2.1713, CELoss: 1.5796 KDLoss: 0.5918 
2022-03-11 01:43:04 - train: epoch 0035, iter [02100, 05004], lr: 0.010000, loss: 2.2136, CELoss: 1.5903 KDLoss: 0.6234 
2022-03-11 01:43:38 - train: epoch 0035, iter [02200, 05004], lr: 0.010000, loss: 2.0253, CELoss: 1.4785 KDLoss: 0.5468 
2022-03-11 01:44:11 - train: epoch 0035, iter [02300, 05004], lr: 0.010000, loss: 2.0319, CELoss: 1.5223 KDLoss: 0.5096 
2022-03-11 01:44:45 - train: epoch 0035, iter [02400, 05004], lr: 0.010000, loss: 2.2883, CELoss: 1.6611 KDLoss: 0.6272 
2022-03-11 01:45:18 - train: epoch 0035, iter [02500, 05004], lr: 0.010000, loss: 2.2914, CELoss: 1.6577 KDLoss: 0.6337 
2022-03-11 01:45:51 - train: epoch 0035, iter [02600, 05004], lr: 0.010000, loss: 2.0952, CELoss: 1.4913 KDLoss: 0.6039 
2022-03-11 01:46:26 - train: epoch 0035, iter [02700, 05004], lr: 0.010000, loss: 2.3996, CELoss: 1.7345 KDLoss: 0.6651 
2022-03-11 01:46:59 - train: epoch 0035, iter [02800, 05004], lr: 0.010000, loss: 2.4401, CELoss: 1.7718 KDLoss: 0.6683 
2022-03-11 01:47:32 - train: epoch 0035, iter [02900, 05004], lr: 0.010000, loss: 2.0988, CELoss: 1.5586 KDLoss: 0.5402 
2022-03-11 01:48:05 - train: epoch 0035, iter [03000, 05004], lr: 0.010000, loss: 2.0721, CELoss: 1.5015 KDLoss: 0.5705 
2022-03-11 01:48:38 - train: epoch 0035, iter [03100, 05004], lr: 0.010000, loss: 2.2901, CELoss: 1.7211 KDLoss: 0.5690 
2022-03-11 01:49:12 - train: epoch 0035, iter [03200, 05004], lr: 0.010000, loss: 2.0809, CELoss: 1.5245 KDLoss: 0.5564 
2022-03-11 01:49:45 - train: epoch 0035, iter [03300, 05004], lr: 0.010000, loss: 2.0397, CELoss: 1.5205 KDLoss: 0.5192 
2022-03-11 01:50:18 - train: epoch 0035, iter [03400, 05004], lr: 0.010000, loss: 2.4073, CELoss: 1.8138 KDLoss: 0.5935 
2022-03-11 01:50:52 - train: epoch 0035, iter [03500, 05004], lr: 0.010000, loss: 1.9251, CELoss: 1.4357 KDLoss: 0.4893 
2022-03-11 01:51:25 - train: epoch 0035, iter [03600, 05004], lr: 0.010000, loss: 2.5115, CELoss: 1.7809 KDLoss: 0.7306 
2022-03-11 01:51:59 - train: epoch 0035, iter [03700, 05004], lr: 0.010000, loss: 2.1406, CELoss: 1.5213 KDLoss: 0.6194 
2022-03-11 01:52:32 - train: epoch 0035, iter [03800, 05004], lr: 0.010000, loss: 1.9589, CELoss: 1.4025 KDLoss: 0.5564 
2022-03-11 01:53:06 - train: epoch 0035, iter [03900, 05004], lr: 0.010000, loss: 2.0674, CELoss: 1.5420 KDLoss: 0.5254 
2022-03-11 01:53:38 - train: epoch 0035, iter [04000, 05004], lr: 0.010000, loss: 2.1652, CELoss: 1.5725 KDLoss: 0.5927 
2022-03-11 01:54:12 - train: epoch 0035, iter [04100, 05004], lr: 0.010000, loss: 2.2711, CELoss: 1.6359 KDLoss: 0.6353 
2022-03-11 01:54:44 - train: epoch 0035, iter [04200, 05004], lr: 0.010000, loss: 2.0926, CELoss: 1.4934 KDLoss: 0.5992 
2022-03-11 01:55:18 - train: epoch 0035, iter [04300, 05004], lr: 0.010000, loss: 2.4203, CELoss: 1.7407 KDLoss: 0.6795 
2022-03-11 01:55:50 - train: epoch 0035, iter [04400, 05004], lr: 0.010000, loss: 2.3066, CELoss: 1.7118 KDLoss: 0.5948 
2022-03-11 01:56:24 - train: epoch 0035, iter [04500, 05004], lr: 0.010000, loss: 2.3372, CELoss: 1.6713 KDLoss: 0.6659 
2022-03-11 01:56:56 - train: epoch 0035, iter [04600, 05004], lr: 0.010000, loss: 2.2140, CELoss: 1.6425 KDLoss: 0.5715 
2022-03-11 01:57:30 - train: epoch 0035, iter [04700, 05004], lr: 0.010000, loss: 2.4365, CELoss: 1.7657 KDLoss: 0.6707 
2022-03-11 01:58:03 - train: epoch 0035, iter [04800, 05004], lr: 0.010000, loss: 2.2512, CELoss: 1.6671 KDLoss: 0.5840 
2022-03-11 01:58:36 - train: epoch 0035, iter [04900, 05004], lr: 0.010000, loss: 2.2454, CELoss: 1.6423 KDLoss: 0.6031 
2022-03-11 01:59:08 - train: epoch 0035, iter [05000, 05004], lr: 0.010000, loss: 2.2299, CELoss: 1.6437 KDLoss: 0.5862 
2022-03-11 01:59:08 - train: epoch 035, train_loss: 2.2111
2022-03-11 02:01:36 - eval: epoch: 035, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 66.646%, stu_acc5: 87.450%, stu_test_loss: 1.3565
2022-03-11 02:01:37 - until epoch: 035, tea_best_acc1: 73.950%, stu_best_acc1: 66.646%
2022-03-11 02:01:37 - epoch 036 lr: 0.010000000000000002
2022-03-11 02:02:16 - train: epoch 0036, iter [00100, 05004], lr: 0.010000, loss: 2.2888, CELoss: 1.6762 KDLoss: 0.6126 
2022-03-11 02:02:48 - train: epoch 0036, iter [00200, 05004], lr: 0.010000, loss: 1.9298, CELoss: 1.3147 KDLoss: 0.6151 
2022-03-11 02:03:22 - train: epoch 0036, iter [00300, 05004], lr: 0.010000, loss: 1.9529, CELoss: 1.4017 KDLoss: 0.5512 
2022-03-11 02:03:55 - train: epoch 0036, iter [00400, 05004], lr: 0.010000, loss: 2.1964, CELoss: 1.5952 KDLoss: 0.6012 
2022-03-11 02:04:29 - train: epoch 0036, iter [00500, 05004], lr: 0.010000, loss: 2.0443, CELoss: 1.4942 KDLoss: 0.5501 
2022-03-11 02:05:02 - train: epoch 0036, iter [00600, 05004], lr: 0.010000, loss: 1.9864, CELoss: 1.4466 KDLoss: 0.5398 
2022-03-11 02:05:35 - train: epoch 0036, iter [00700, 05004], lr: 0.010000, loss: 2.1478, CELoss: 1.5391 KDLoss: 0.6087 
2022-03-11 02:06:10 - train: epoch 0036, iter [00800, 05004], lr: 0.010000, loss: 2.1468, CELoss: 1.5065 KDLoss: 0.6403 
2022-03-11 02:06:43 - train: epoch 0036, iter [00900, 05004], lr: 0.010000, loss: 2.1160, CELoss: 1.5309 KDLoss: 0.5851 
2022-03-11 02:07:16 - train: epoch 0036, iter [01000, 05004], lr: 0.010000, loss: 2.1348, CELoss: 1.5328 KDLoss: 0.6020 
2022-03-11 02:07:50 - train: epoch 0036, iter [01100, 05004], lr: 0.010000, loss: 2.1457, CELoss: 1.5787 KDLoss: 0.5670 
2022-03-11 02:08:25 - train: epoch 0036, iter [01200, 05004], lr: 0.010000, loss: 2.2269, CELoss: 1.6576 KDLoss: 0.5693 
2022-03-11 02:08:57 - train: epoch 0036, iter [01300, 05004], lr: 0.010000, loss: 2.3234, CELoss: 1.6790 KDLoss: 0.6444 
2022-03-11 02:09:32 - train: epoch 0036, iter [01400, 05004], lr: 0.010000, loss: 2.2219, CELoss: 1.6224 KDLoss: 0.5994 
2022-03-11 02:10:05 - train: epoch 0036, iter [01500, 05004], lr: 0.010000, loss: 2.1754, CELoss: 1.5866 KDLoss: 0.5887 
2022-03-11 02:10:39 - train: epoch 0036, iter [01600, 05004], lr: 0.010000, loss: 2.3139, CELoss: 1.7270 KDLoss: 0.5869 
2022-03-11 02:11:12 - train: epoch 0036, iter [01700, 05004], lr: 0.010000, loss: 2.1055, CELoss: 1.5348 KDLoss: 0.5707 
2022-03-11 02:11:45 - train: epoch 0036, iter [01800, 05004], lr: 0.010000, loss: 1.9651, CELoss: 1.4473 KDLoss: 0.5179 
2022-03-11 02:12:19 - train: epoch 0036, iter [01900, 05004], lr: 0.010000, loss: 2.4862, CELoss: 1.8446 KDLoss: 0.6417 
2022-03-11 02:12:52 - train: epoch 0036, iter [02000, 05004], lr: 0.010000, loss: 2.2612, CELoss: 1.6595 KDLoss: 0.6017 
2022-03-11 02:13:26 - train: epoch 0036, iter [02100, 05004], lr: 0.010000, loss: 2.0904, CELoss: 1.5277 KDLoss: 0.5627 
2022-03-11 02:13:59 - train: epoch 0036, iter [02200, 05004], lr: 0.010000, loss: 2.1288, CELoss: 1.5536 KDLoss: 0.5753 
2022-03-11 02:14:32 - train: epoch 0036, iter [02300, 05004], lr: 0.010000, loss: 2.4174, CELoss: 1.8065 KDLoss: 0.6109 
2022-03-11 02:15:06 - train: epoch 0036, iter [02400, 05004], lr: 0.010000, loss: 2.3408, CELoss: 1.7621 KDLoss: 0.5788 
2022-03-11 02:15:39 - train: epoch 0036, iter [02500, 05004], lr: 0.010000, loss: 2.0700, CELoss: 1.4708 KDLoss: 0.5992 
2022-03-11 02:16:12 - train: epoch 0036, iter [02600, 05004], lr: 0.010000, loss: 2.2130, CELoss: 1.6265 KDLoss: 0.5865 
2022-03-11 02:16:45 - train: epoch 0036, iter [02700, 05004], lr: 0.010000, loss: 2.0397, CELoss: 1.5063 KDLoss: 0.5335 
2022-03-11 02:17:19 - train: epoch 0036, iter [02800, 05004], lr: 0.010000, loss: 2.2662, CELoss: 1.6167 KDLoss: 0.6495 
2022-03-11 02:17:53 - train: epoch 0036, iter [02900, 05004], lr: 0.010000, loss: 2.1919, CELoss: 1.5620 KDLoss: 0.6299 
2022-03-11 02:18:26 - train: epoch 0036, iter [03000, 05004], lr: 0.010000, loss: 2.0187, CELoss: 1.4457 KDLoss: 0.5730 
2022-03-11 02:19:00 - train: epoch 0036, iter [03100, 05004], lr: 0.010000, loss: 2.2364, CELoss: 1.6335 KDLoss: 0.6029 
2022-03-11 02:19:33 - train: epoch 0036, iter [03200, 05004], lr: 0.010000, loss: 2.2899, CELoss: 1.7123 KDLoss: 0.5776 
2022-03-11 02:20:07 - train: epoch 0036, iter [03300, 05004], lr: 0.010000, loss: 2.1709, CELoss: 1.5973 KDLoss: 0.5736 
2022-03-11 02:20:40 - train: epoch 0036, iter [03400, 05004], lr: 0.010000, loss: 1.9733, CELoss: 1.4508 KDLoss: 0.5225 
2022-03-11 02:21:13 - train: epoch 0036, iter [03500, 05004], lr: 0.010000, loss: 2.4448, CELoss: 1.7794 KDLoss: 0.6654 
2022-03-11 02:21:45 - train: epoch 0036, iter [03600, 05004], lr: 0.010000, loss: 2.2367, CELoss: 1.6436 KDLoss: 0.5931 
2022-03-11 02:22:19 - train: epoch 0036, iter [03700, 05004], lr: 0.010000, loss: 2.0217, CELoss: 1.4735 KDLoss: 0.5482 
2022-03-11 02:22:53 - train: epoch 0036, iter [03800, 05004], lr: 0.010000, loss: 2.4261, CELoss: 1.7919 KDLoss: 0.6342 
2022-03-11 02:23:27 - train: epoch 0036, iter [03900, 05004], lr: 0.010000, loss: 2.2283, CELoss: 1.6235 KDLoss: 0.6048 
2022-03-11 02:24:01 - train: epoch 0036, iter [04000, 05004], lr: 0.010000, loss: 2.0931, CELoss: 1.5356 KDLoss: 0.5575 
2022-03-11 02:24:34 - train: epoch 0036, iter [04100, 05004], lr: 0.010000, loss: 2.1259, CELoss: 1.5428 KDLoss: 0.5831 
2022-03-11 02:25:07 - train: epoch 0036, iter [04200, 05004], lr: 0.010000, loss: 2.2695, CELoss: 1.6643 KDLoss: 0.6052 
2022-03-11 02:25:40 - train: epoch 0036, iter [04300, 05004], lr: 0.010000, loss: 2.0475, CELoss: 1.5099 KDLoss: 0.5376 
2022-03-11 02:26:14 - train: epoch 0036, iter [04400, 05004], lr: 0.010000, loss: 2.3372, CELoss: 1.7013 KDLoss: 0.6359 
2022-03-11 02:26:47 - train: epoch 0036, iter [04500, 05004], lr: 0.010000, loss: 2.1694, CELoss: 1.5950 KDLoss: 0.5744 
2022-03-11 02:27:20 - train: epoch 0036, iter [04600, 05004], lr: 0.010000, loss: 2.0131, CELoss: 1.4506 KDLoss: 0.5625 
2022-03-11 02:27:54 - train: epoch 0036, iter [04700, 05004], lr: 0.010000, loss: 2.2681, CELoss: 1.6170 KDLoss: 0.6511 
2022-03-11 02:28:28 - train: epoch 0036, iter [04800, 05004], lr: 0.010000, loss: 2.2860, CELoss: 1.6245 KDLoss: 0.6615 
2022-03-11 02:29:01 - train: epoch 0036, iter [04900, 05004], lr: 0.010000, loss: 2.2346, CELoss: 1.5917 KDLoss: 0.6429 
2022-03-11 02:29:32 - train: epoch 0036, iter [05000, 05004], lr: 0.010000, loss: 2.0880, CELoss: 1.5097 KDLoss: 0.5783 
2022-03-11 02:29:33 - train: epoch 036, train_loss: 2.1895
2022-03-11 02:32:02 - eval: epoch: 036, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 67.182%, stu_acc5: 87.716%, stu_test_loss: 1.3476
2022-03-11 02:32:03 - until epoch: 036, tea_best_acc1: 73.950%, stu_best_acc1: 67.182%
2022-03-11 02:32:03 - epoch 037 lr: 0.010000000000000002
2022-03-11 02:32:41 - train: epoch 0037, iter [00100, 05004], lr: 0.010000, loss: 1.8623, CELoss: 1.3644 KDLoss: 0.4979 
2022-03-11 02:33:15 - train: epoch 0037, iter [00200, 05004], lr: 0.010000, loss: 2.0974, CELoss: 1.5491 KDLoss: 0.5482 
2022-03-11 02:33:49 - train: epoch 0037, iter [00300, 05004], lr: 0.010000, loss: 2.0005, CELoss: 1.4792 KDLoss: 0.5213 
2022-03-11 02:34:22 - train: epoch 0037, iter [00400, 05004], lr: 0.010000, loss: 1.8928, CELoss: 1.3553 KDLoss: 0.5375 
2022-03-11 02:34:55 - train: epoch 0037, iter [00500, 05004], lr: 0.010000, loss: 2.3488, CELoss: 1.7618 KDLoss: 0.5870 
2022-03-11 02:35:29 - train: epoch 0037, iter [00600, 05004], lr: 0.010000, loss: 2.5631, CELoss: 1.9271 KDLoss: 0.6359 
2022-03-11 02:36:03 - train: epoch 0037, iter [00700, 05004], lr: 0.010000, loss: 2.4986, CELoss: 1.8159 KDLoss: 0.6828 
2022-03-11 02:36:36 - train: epoch 0037, iter [00800, 05004], lr: 0.010000, loss: 1.9481, CELoss: 1.3927 KDLoss: 0.5553 
2022-03-11 02:37:10 - train: epoch 0037, iter [00900, 05004], lr: 0.010000, loss: 2.2844, CELoss: 1.7088 KDLoss: 0.5756 
2022-03-11 02:37:43 - train: epoch 0037, iter [01000, 05004], lr: 0.010000, loss: 2.0880, CELoss: 1.5429 KDLoss: 0.5451 
2022-03-11 02:38:17 - train: epoch 0037, iter [01100, 05004], lr: 0.010000, loss: 2.2333, CELoss: 1.6334 KDLoss: 0.5999 
2022-03-11 02:38:50 - train: epoch 0037, iter [01200, 05004], lr: 0.010000, loss: 2.1569, CELoss: 1.6161 KDLoss: 0.5408 
2022-03-11 02:39:23 - train: epoch 0037, iter [01300, 05004], lr: 0.010000, loss: 2.3113, CELoss: 1.7409 KDLoss: 0.5704 
2022-03-11 02:39:58 - train: epoch 0037, iter [01400, 05004], lr: 0.010000, loss: 2.5493, CELoss: 1.8725 KDLoss: 0.6769 
2022-03-11 02:40:30 - train: epoch 0037, iter [01500, 05004], lr: 0.010000, loss: 1.8807, CELoss: 1.3706 KDLoss: 0.5101 
2022-03-11 02:41:04 - train: epoch 0037, iter [01600, 05004], lr: 0.010000, loss: 2.0850, CELoss: 1.5553 KDLoss: 0.5297 
2022-03-11 02:41:38 - train: epoch 0037, iter [01700, 05004], lr: 0.010000, loss: 2.1444, CELoss: 1.5136 KDLoss: 0.6308 
2022-03-11 02:42:11 - train: epoch 0037, iter [01800, 05004], lr: 0.010000, loss: 2.2133, CELoss: 1.6527 KDLoss: 0.5606 
2022-03-11 02:42:44 - train: epoch 0037, iter [01900, 05004], lr: 0.010000, loss: 2.1846, CELoss: 1.5684 KDLoss: 0.6162 
2022-03-11 02:43:19 - train: epoch 0037, iter [02000, 05004], lr: 0.010000, loss: 2.0882, CELoss: 1.5165 KDLoss: 0.5717 
2022-03-11 02:43:51 - train: epoch 0037, iter [02100, 05004], lr: 0.010000, loss: 2.2192, CELoss: 1.5373 KDLoss: 0.6818 
2022-03-11 02:44:26 - train: epoch 0037, iter [02200, 05004], lr: 0.010000, loss: 2.1552, CELoss: 1.5605 KDLoss: 0.5946 
2022-03-11 02:44:59 - train: epoch 0037, iter [02300, 05004], lr: 0.010000, loss: 1.9134, CELoss: 1.4135 KDLoss: 0.4999 
2022-03-11 02:45:32 - train: epoch 0037, iter [02400, 05004], lr: 0.010000, loss: 2.1413, CELoss: 1.5228 KDLoss: 0.6185 
2022-03-11 02:46:06 - train: epoch 0037, iter [02500, 05004], lr: 0.010000, loss: 2.3226, CELoss: 1.7377 KDLoss: 0.5849 
2022-03-11 02:46:40 - train: epoch 0037, iter [02600, 05004], lr: 0.010000, loss: 2.6454, CELoss: 1.9704 KDLoss: 0.6750 
2022-03-11 02:47:14 - train: epoch 0037, iter [02700, 05004], lr: 0.010000, loss: 2.6163, CELoss: 1.9284 KDLoss: 0.6878 
2022-03-11 02:47:47 - train: epoch 0037, iter [02800, 05004], lr: 0.010000, loss: 2.2172, CELoss: 1.6096 KDLoss: 0.6077 
2022-03-11 02:48:21 - train: epoch 0037, iter [02900, 05004], lr: 0.010000, loss: 2.0337, CELoss: 1.4853 KDLoss: 0.5484 
2022-03-11 02:48:54 - train: epoch 0037, iter [03000, 05004], lr: 0.010000, loss: 2.3907, CELoss: 1.7869 KDLoss: 0.6038 
2022-03-11 02:49:27 - train: epoch 0037, iter [03100, 05004], lr: 0.010000, loss: 2.0716, CELoss: 1.5061 KDLoss: 0.5656 
2022-03-11 02:50:01 - train: epoch 0037, iter [03200, 05004], lr: 0.010000, loss: 2.4405, CELoss: 1.7882 KDLoss: 0.6524 
2022-03-11 02:50:35 - train: epoch 0037, iter [03300, 05004], lr: 0.010000, loss: 2.2058, CELoss: 1.6318 KDLoss: 0.5740 
2022-03-11 02:51:08 - train: epoch 0037, iter [03400, 05004], lr: 0.010000, loss: 1.9117, CELoss: 1.3790 KDLoss: 0.5327 
2022-03-11 02:51:42 - train: epoch 0037, iter [03500, 05004], lr: 0.010000, loss: 2.3214, CELoss: 1.6580 KDLoss: 0.6634 
2022-03-11 02:52:16 - train: epoch 0037, iter [03600, 05004], lr: 0.010000, loss: 2.1808, CELoss: 1.6310 KDLoss: 0.5498 
2022-03-11 02:52:49 - train: epoch 0037, iter [03700, 05004], lr: 0.010000, loss: 2.1142, CELoss: 1.5419 KDLoss: 0.5724 
2022-03-11 02:53:23 - train: epoch 0037, iter [03800, 05004], lr: 0.010000, loss: 2.2455, CELoss: 1.6328 KDLoss: 0.6127 
2022-03-11 02:53:56 - train: epoch 0037, iter [03900, 05004], lr: 0.010000, loss: 2.5832, CELoss: 1.9367 KDLoss: 0.6466 
2022-03-11 02:54:30 - train: epoch 0037, iter [04000, 05004], lr: 0.010000, loss: 2.3837, CELoss: 1.7310 KDLoss: 0.6527 
2022-03-11 02:55:03 - train: epoch 0037, iter [04100, 05004], lr: 0.010000, loss: 2.2359, CELoss: 1.6081 KDLoss: 0.6278 
2022-03-11 02:55:37 - train: epoch 0037, iter [04200, 05004], lr: 0.010000, loss: 2.3589, CELoss: 1.7353 KDLoss: 0.6236 
2022-03-11 02:56:09 - train: epoch 0037, iter [04300, 05004], lr: 0.010000, loss: 2.2068, CELoss: 1.5962 KDLoss: 0.6106 
2022-03-11 02:56:43 - train: epoch 0037, iter [04400, 05004], lr: 0.010000, loss: 2.0195, CELoss: 1.5087 KDLoss: 0.5108 
2022-03-11 02:57:16 - train: epoch 0037, iter [04500, 05004], lr: 0.010000, loss: 2.2558, CELoss: 1.6025 KDLoss: 0.6534 
2022-03-11 02:57:49 - train: epoch 0037, iter [04600, 05004], lr: 0.010000, loss: 2.1016, CELoss: 1.4954 KDLoss: 0.6062 
2022-03-11 02:58:23 - train: epoch 0037, iter [04700, 05004], lr: 0.010000, loss: 2.1338, CELoss: 1.5418 KDLoss: 0.5920 
2022-03-11 02:58:56 - train: epoch 0037, iter [04800, 05004], lr: 0.010000, loss: 2.0350, CELoss: 1.4821 KDLoss: 0.5530 
2022-03-11 02:59:29 - train: epoch 0037, iter [04900, 05004], lr: 0.010000, loss: 2.2605, CELoss: 1.6328 KDLoss: 0.6277 
2022-03-11 03:00:02 - train: epoch 0037, iter [05000, 05004], lr: 0.010000, loss: 2.2992, CELoss: 1.6600 KDLoss: 0.6392 
2022-03-11 03:00:02 - train: epoch 037, train_loss: 2.1789
2022-03-11 03:02:31 - eval: epoch: 037, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 66.666%, stu_acc5: 87.424%, stu_test_loss: 1.3656
2022-03-11 03:02:31 - until epoch: 037, tea_best_acc1: 73.950%, stu_best_acc1: 67.182%
2022-03-11 03:02:31 - epoch 038 lr: 0.010000000000000002
2022-03-11 03:03:09 - train: epoch 0038, iter [00100, 05004], lr: 0.010000, loss: 2.0358, CELoss: 1.4320 KDLoss: 0.6039 
2022-03-11 03:03:43 - train: epoch 0038, iter [00200, 05004], lr: 0.010000, loss: 2.3397, CELoss: 1.7270 KDLoss: 0.6127 
2022-03-11 03:04:16 - train: epoch 0038, iter [00300, 05004], lr: 0.010000, loss: 2.0797, CELoss: 1.4581 KDLoss: 0.6216 
2022-03-11 03:04:51 - train: epoch 0038, iter [00400, 05004], lr: 0.010000, loss: 2.0509, CELoss: 1.4560 KDLoss: 0.5949 
2022-03-11 03:05:23 - train: epoch 0038, iter [00500, 05004], lr: 0.010000, loss: 2.0385, CELoss: 1.4620 KDLoss: 0.5765 
2022-03-11 03:05:56 - train: epoch 0038, iter [00600, 05004], lr: 0.010000, loss: 2.2910, CELoss: 1.6783 KDLoss: 0.6127 
2022-03-11 03:06:30 - train: epoch 0038, iter [00700, 05004], lr: 0.010000, loss: 2.0136, CELoss: 1.4482 KDLoss: 0.5654 
2022-03-11 03:07:04 - train: epoch 0038, iter [00800, 05004], lr: 0.010000, loss: 1.9931, CELoss: 1.4398 KDLoss: 0.5533 
2022-03-11 03:07:38 - train: epoch 0038, iter [00900, 05004], lr: 0.010000, loss: 2.2828, CELoss: 1.6773 KDLoss: 0.6055 
2022-03-11 03:08:10 - train: epoch 0038, iter [01000, 05004], lr: 0.010000, loss: 2.2098, CELoss: 1.6315 KDLoss: 0.5782 
2022-03-11 03:08:44 - train: epoch 0038, iter [01100, 05004], lr: 0.010000, loss: 2.3094, CELoss: 1.6800 KDLoss: 0.6293 
2022-03-11 03:09:17 - train: epoch 0038, iter [01200, 05004], lr: 0.010000, loss: 2.3328, CELoss: 1.7205 KDLoss: 0.6123 
2022-03-11 03:09:51 - train: epoch 0038, iter [01300, 05004], lr: 0.010000, loss: 2.1129, CELoss: 1.5161 KDLoss: 0.5968 
2022-03-11 03:10:24 - train: epoch 0038, iter [01400, 05004], lr: 0.010000, loss: 2.0342, CELoss: 1.4983 KDLoss: 0.5359 
2022-03-11 03:10:58 - train: epoch 0038, iter [01500, 05004], lr: 0.010000, loss: 2.1734, CELoss: 1.5995 KDLoss: 0.5739 
2022-03-11 03:11:31 - train: epoch 0038, iter [01600, 05004], lr: 0.010000, loss: 2.1655, CELoss: 1.5944 KDLoss: 0.5711 
2022-03-11 03:12:06 - train: epoch 0038, iter [01700, 05004], lr: 0.010000, loss: 2.1770, CELoss: 1.5730 KDLoss: 0.6040 
2022-03-11 03:12:39 - train: epoch 0038, iter [01800, 05004], lr: 0.010000, loss: 2.2415, CELoss: 1.6344 KDLoss: 0.6071 
2022-03-11 03:13:12 - train: epoch 0038, iter [01900, 05004], lr: 0.010000, loss: 2.3569, CELoss: 1.7392 KDLoss: 0.6177 
2022-03-11 03:13:46 - train: epoch 0038, iter [02000, 05004], lr: 0.010000, loss: 2.2396, CELoss: 1.6725 KDLoss: 0.5671 
2022-03-11 03:14:19 - train: epoch 0038, iter [02100, 05004], lr: 0.010000, loss: 2.2399, CELoss: 1.5662 KDLoss: 0.6737 
2022-03-11 03:14:54 - train: epoch 0038, iter [02200, 05004], lr: 0.010000, loss: 1.9697, CELoss: 1.4671 KDLoss: 0.5025 
2022-03-11 03:15:27 - train: epoch 0038, iter [02300, 05004], lr: 0.010000, loss: 2.1762, CELoss: 1.5444 KDLoss: 0.6319 
2022-03-11 03:16:00 - train: epoch 0038, iter [02400, 05004], lr: 0.010000, loss: 2.3993, CELoss: 1.7940 KDLoss: 0.6053 
2022-03-11 03:16:34 - train: epoch 0038, iter [02500, 05004], lr: 0.010000, loss: 2.0756, CELoss: 1.5260 KDLoss: 0.5496 
2022-03-11 03:17:08 - train: epoch 0038, iter [02600, 05004], lr: 0.010000, loss: 2.2403, CELoss: 1.6438 KDLoss: 0.5964 
2022-03-11 03:17:41 - train: epoch 0038, iter [02700, 05004], lr: 0.010000, loss: 2.3616, CELoss: 1.7301 KDLoss: 0.6315 
2022-03-11 03:18:15 - train: epoch 0038, iter [02800, 05004], lr: 0.010000, loss: 2.3901, CELoss: 1.7856 KDLoss: 0.6045 
2022-03-11 03:18:48 - train: epoch 0038, iter [02900, 05004], lr: 0.010000, loss: 2.2020, CELoss: 1.6255 KDLoss: 0.5765 
2022-03-11 03:19:22 - train: epoch 0038, iter [03000, 05004], lr: 0.010000, loss: 2.0446, CELoss: 1.4918 KDLoss: 0.5528 
2022-03-11 03:19:55 - train: epoch 0038, iter [03100, 05004], lr: 0.010000, loss: 2.2986, CELoss: 1.7235 KDLoss: 0.5751 
2022-03-11 03:20:28 - train: epoch 0038, iter [03200, 05004], lr: 0.010000, loss: 1.8709, CELoss: 1.3161 KDLoss: 0.5547 
2022-03-11 03:21:01 - train: epoch 0038, iter [03300, 05004], lr: 0.010000, loss: 1.9031, CELoss: 1.3529 KDLoss: 0.5502 
2022-03-11 03:21:36 - train: epoch 0038, iter [03400, 05004], lr: 0.010000, loss: 2.0269, CELoss: 1.4696 KDLoss: 0.5573 
2022-03-11 03:22:08 - train: epoch 0038, iter [03500, 05004], lr: 0.010000, loss: 2.2060, CELoss: 1.6022 KDLoss: 0.6037 
2022-03-11 03:22:43 - train: epoch 0038, iter [03600, 05004], lr: 0.010000, loss: 2.0579, CELoss: 1.4752 KDLoss: 0.5827 
2022-03-11 03:23:15 - train: epoch 0038, iter [03700, 05004], lr: 0.010000, loss: 2.0385, CELoss: 1.4808 KDLoss: 0.5577 
2022-03-11 03:23:49 - train: epoch 0038, iter [03800, 05004], lr: 0.010000, loss: 2.4402, CELoss: 1.7900 KDLoss: 0.6502 
2022-03-11 03:24:23 - train: epoch 0038, iter [03900, 05004], lr: 0.010000, loss: 1.9751, CELoss: 1.4322 KDLoss: 0.5429 
2022-03-11 03:24:56 - train: epoch 0038, iter [04000, 05004], lr: 0.010000, loss: 2.1979, CELoss: 1.6190 KDLoss: 0.5789 
2022-03-11 03:25:30 - train: epoch 0038, iter [04100, 05004], lr: 0.010000, loss: 1.9543, CELoss: 1.4197 KDLoss: 0.5346 
2022-03-11 03:26:02 - train: epoch 0038, iter [04200, 05004], lr: 0.010000, loss: 1.9570, CELoss: 1.4434 KDLoss: 0.5135 
2022-03-11 03:26:36 - train: epoch 0038, iter [04300, 05004], lr: 0.010000, loss: 2.2360, CELoss: 1.6793 KDLoss: 0.5566 
2022-03-11 03:27:09 - train: epoch 0038, iter [04400, 05004], lr: 0.010000, loss: 2.4070, CELoss: 1.7410 KDLoss: 0.6659 
2022-03-11 03:27:43 - train: epoch 0038, iter [04500, 05004], lr: 0.010000, loss: 2.3849, CELoss: 1.7589 KDLoss: 0.6260 
2022-03-11 03:28:18 - train: epoch 0038, iter [04600, 05004], lr: 0.010000, loss: 2.2453, CELoss: 1.6629 KDLoss: 0.5824 
2022-03-11 03:28:51 - train: epoch 0038, iter [04700, 05004], lr: 0.010000, loss: 1.9393, CELoss: 1.4713 KDLoss: 0.4680 
2022-03-11 03:29:24 - train: epoch 0038, iter [04800, 05004], lr: 0.010000, loss: 2.1996, CELoss: 1.6215 KDLoss: 0.5781 
2022-03-11 03:29:57 - train: epoch 0038, iter [04900, 05004], lr: 0.010000, loss: 2.1051, CELoss: 1.5099 KDLoss: 0.5952 
2022-03-11 03:30:28 - train: epoch 0038, iter [05000, 05004], lr: 0.010000, loss: 2.0143, CELoss: 1.4462 KDLoss: 0.5681 
2022-03-11 03:30:29 - train: epoch 038, train_loss: 2.1697
2022-03-11 03:32:58 - eval: epoch: 038, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 66.802%, stu_acc5: 87.594%, stu_test_loss: 1.3565
2022-03-11 03:32:59 - until epoch: 038, tea_best_acc1: 73.950%, stu_best_acc1: 67.182%
2022-03-11 03:32:59 - epoch 039 lr: 0.010000000000000002
2022-03-11 03:33:37 - train: epoch 0039, iter [00100, 05004], lr: 0.010000, loss: 1.9916, CELoss: 1.4750 KDLoss: 0.5166 
2022-03-11 03:34:11 - train: epoch 0039, iter [00200, 05004], lr: 0.010000, loss: 2.3027, CELoss: 1.7192 KDLoss: 0.5835 
2022-03-11 03:34:44 - train: epoch 0039, iter [00300, 05004], lr: 0.010000, loss: 2.1137, CELoss: 1.4886 KDLoss: 0.6251 
2022-03-11 03:35:17 - train: epoch 0039, iter [00400, 05004], lr: 0.010000, loss: 2.1568, CELoss: 1.5856 KDLoss: 0.5712 
2022-03-11 03:35:52 - train: epoch 0039, iter [00500, 05004], lr: 0.010000, loss: 2.1561, CELoss: 1.5748 KDLoss: 0.5813 
2022-03-11 03:36:24 - train: epoch 0039, iter [00600, 05004], lr: 0.010000, loss: 2.0271, CELoss: 1.4578 KDLoss: 0.5693 
2022-03-11 03:36:59 - train: epoch 0039, iter [00700, 05004], lr: 0.010000, loss: 2.4441, CELoss: 1.8631 KDLoss: 0.5810 
2022-03-11 03:37:32 - train: epoch 0039, iter [00800, 05004], lr: 0.010000, loss: 2.2305, CELoss: 1.6124 KDLoss: 0.6180 
2022-03-11 03:38:06 - train: epoch 0039, iter [00900, 05004], lr: 0.010000, loss: 2.2032, CELoss: 1.5890 KDLoss: 0.6142 
2022-03-11 03:38:39 - train: epoch 0039, iter [01000, 05004], lr: 0.010000, loss: 2.0916, CELoss: 1.5043 KDLoss: 0.5873 
2022-03-11 03:39:13 - train: epoch 0039, iter [01100, 05004], lr: 0.010000, loss: 2.3728, CELoss: 1.7433 KDLoss: 0.6295 
2022-03-11 03:39:47 - train: epoch 0039, iter [01200, 05004], lr: 0.010000, loss: 2.1020, CELoss: 1.5276 KDLoss: 0.5743 
2022-03-11 03:40:20 - train: epoch 0039, iter [01300, 05004], lr: 0.010000, loss: 2.4415, CELoss: 1.8442 KDLoss: 0.5972 
2022-03-11 03:40:53 - train: epoch 0039, iter [01400, 05004], lr: 0.010000, loss: 2.1126, CELoss: 1.5208 KDLoss: 0.5919 
2022-03-11 03:41:26 - train: epoch 0039, iter [01500, 05004], lr: 0.010000, loss: 1.7678, CELoss: 1.3057 KDLoss: 0.4621 
2022-03-11 03:42:00 - train: epoch 0039, iter [01600, 05004], lr: 0.010000, loss: 2.3394, CELoss: 1.6667 KDLoss: 0.6727 
2022-03-11 03:42:34 - train: epoch 0039, iter [01700, 05004], lr: 0.010000, loss: 2.0941, CELoss: 1.5319 KDLoss: 0.5621 
2022-03-11 03:43:07 - train: epoch 0039, iter [01800, 05004], lr: 0.010000, loss: 2.2059, CELoss: 1.6476 KDLoss: 0.5583 
2022-03-11 03:43:41 - train: epoch 0039, iter [01900, 05004], lr: 0.010000, loss: 1.9921, CELoss: 1.3781 KDLoss: 0.6140 
2022-03-11 03:44:13 - train: epoch 0039, iter [02000, 05004], lr: 0.010000, loss: 2.2092, CELoss: 1.5750 KDLoss: 0.6342 
2022-03-11 03:44:47 - train: epoch 0039, iter [02100, 05004], lr: 0.010000, loss: 2.2462, CELoss: 1.6611 KDLoss: 0.5851 
2022-03-11 03:45:20 - train: epoch 0039, iter [02200, 05004], lr: 0.010000, loss: 2.0203, CELoss: 1.4456 KDLoss: 0.5747 
2022-03-11 03:45:54 - train: epoch 0039, iter [02300, 05004], lr: 0.010000, loss: 2.4269, CELoss: 1.8115 KDLoss: 0.6154 
2022-03-11 03:46:26 - train: epoch 0039, iter [02400, 05004], lr: 0.010000, loss: 2.4436, CELoss: 1.8257 KDLoss: 0.6179 
2022-03-11 03:47:00 - train: epoch 0039, iter [02500, 05004], lr: 0.010000, loss: 2.2470, CELoss: 1.6204 KDLoss: 0.6266 
2022-03-11 03:47:34 - train: epoch 0039, iter [02600, 05004], lr: 0.010000, loss: 2.0896, CELoss: 1.5389 KDLoss: 0.5507 
2022-03-11 03:48:07 - train: epoch 0039, iter [02700, 05004], lr: 0.010000, loss: 2.3377, CELoss: 1.7382 KDLoss: 0.5996 
2022-03-11 03:48:41 - train: epoch 0039, iter [02800, 05004], lr: 0.010000, loss: 2.3226, CELoss: 1.6309 KDLoss: 0.6917 
2022-03-11 03:49:14 - train: epoch 0039, iter [02900, 05004], lr: 0.010000, loss: 1.8967, CELoss: 1.3881 KDLoss: 0.5086 
2022-03-11 03:49:48 - train: epoch 0039, iter [03000, 05004], lr: 0.010000, loss: 2.2212, CELoss: 1.6329 KDLoss: 0.5883 
2022-03-11 03:50:21 - train: epoch 0039, iter [03100, 05004], lr: 0.010000, loss: 2.0563, CELoss: 1.4526 KDLoss: 0.6037 
2022-03-11 03:50:54 - train: epoch 0039, iter [03200, 05004], lr: 0.010000, loss: 2.2164, CELoss: 1.5737 KDLoss: 0.6427 
2022-03-11 03:51:28 - train: epoch 0039, iter [03300, 05004], lr: 0.010000, loss: 2.1306, CELoss: 1.5242 KDLoss: 0.6065 
2022-03-11 03:52:02 - train: epoch 0039, iter [03400, 05004], lr: 0.010000, loss: 2.1989, CELoss: 1.6171 KDLoss: 0.5819 
2022-03-11 03:52:36 - train: epoch 0039, iter [03500, 05004], lr: 0.010000, loss: 2.3491, CELoss: 1.6936 KDLoss: 0.6554 
2022-03-11 03:53:09 - train: epoch 0039, iter [03600, 05004], lr: 0.010000, loss: 2.3818, CELoss: 1.7648 KDLoss: 0.6169 
2022-03-11 03:53:43 - train: epoch 0039, iter [03700, 05004], lr: 0.010000, loss: 2.1168, CELoss: 1.5293 KDLoss: 0.5875 
2022-03-11 03:54:17 - train: epoch 0039, iter [03800, 05004], lr: 0.010000, loss: 1.9264, CELoss: 1.3765 KDLoss: 0.5499 
2022-03-11 03:54:50 - train: epoch 0039, iter [03900, 05004], lr: 0.010000, loss: 2.3247, CELoss: 1.6489 KDLoss: 0.6758 
2022-03-11 03:55:23 - train: epoch 0039, iter [04000, 05004], lr: 0.010000, loss: 2.3092, CELoss: 1.6755 KDLoss: 0.6336 
2022-03-11 03:55:58 - train: epoch 0039, iter [04100, 05004], lr: 0.010000, loss: 2.2750, CELoss: 1.6512 KDLoss: 0.6238 
2022-03-11 03:56:31 - train: epoch 0039, iter [04200, 05004], lr: 0.010000, loss: 2.3842, CELoss: 1.7166 KDLoss: 0.6676 
2022-03-11 03:57:04 - train: epoch 0039, iter [04300, 05004], lr: 0.010000, loss: 2.0355, CELoss: 1.4736 KDLoss: 0.5619 
2022-03-11 03:57:37 - train: epoch 0039, iter [04400, 05004], lr: 0.010000, loss: 2.1994, CELoss: 1.5836 KDLoss: 0.6157 
2022-03-11 03:58:11 - train: epoch 0039, iter [04500, 05004], lr: 0.010000, loss: 2.0419, CELoss: 1.5179 KDLoss: 0.5240 
2022-03-11 03:58:44 - train: epoch 0039, iter [04600, 05004], lr: 0.010000, loss: 2.3324, CELoss: 1.6902 KDLoss: 0.6422 
2022-03-11 03:59:18 - train: epoch 0039, iter [04700, 05004], lr: 0.010000, loss: 2.1372, CELoss: 1.5938 KDLoss: 0.5433 
2022-03-11 03:59:51 - train: epoch 0039, iter [04800, 05004], lr: 0.010000, loss: 2.0948, CELoss: 1.4940 KDLoss: 0.6007 
2022-03-11 04:00:25 - train: epoch 0039, iter [04900, 05004], lr: 0.010000, loss: 1.8889, CELoss: 1.3317 KDLoss: 0.5572 
2022-03-11 04:00:57 - train: epoch 0039, iter [05000, 05004], lr: 0.010000, loss: 2.3000, CELoss: 1.6634 KDLoss: 0.6366 
2022-03-11 04:00:57 - train: epoch 039, train_loss: 2.1673
2022-03-11 04:03:26 - eval: epoch: 039, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 66.386%, stu_acc5: 87.492%, stu_test_loss: 1.3665
2022-03-11 04:03:26 - until epoch: 039, tea_best_acc1: 73.950%, stu_best_acc1: 67.182%
2022-03-11 04:03:26 - epoch 040 lr: 0.010000000000000002
2022-03-11 04:04:05 - train: epoch 0040, iter [00100, 05004], lr: 0.010000, loss: 2.4402, CELoss: 1.8636 KDLoss: 0.5766 
2022-03-11 04:04:38 - train: epoch 0040, iter [00200, 05004], lr: 0.010000, loss: 2.2654, CELoss: 1.6509 KDLoss: 0.6145 
2022-03-11 04:05:12 - train: epoch 0040, iter [00300, 05004], lr: 0.010000, loss: 2.2830, CELoss: 1.6782 KDLoss: 0.6048 
2022-03-11 04:05:45 - train: epoch 0040, iter [00400, 05004], lr: 0.010000, loss: 1.9655, CELoss: 1.3835 KDLoss: 0.5821 
2022-03-11 04:06:18 - train: epoch 0040, iter [00500, 05004], lr: 0.010000, loss: 1.8903, CELoss: 1.3825 KDLoss: 0.5078 
2022-03-11 04:06:53 - train: epoch 0040, iter [00600, 05004], lr: 0.010000, loss: 2.0409, CELoss: 1.4523 KDLoss: 0.5886 
2022-03-11 04:07:26 - train: epoch 0040, iter [00700, 05004], lr: 0.010000, loss: 2.1996, CELoss: 1.6104 KDLoss: 0.5892 
2022-03-11 04:07:59 - train: epoch 0040, iter [00800, 05004], lr: 0.010000, loss: 2.0940, CELoss: 1.5148 KDLoss: 0.5792 
2022-03-11 04:08:33 - train: epoch 0040, iter [00900, 05004], lr: 0.010000, loss: 2.1039, CELoss: 1.5074 KDLoss: 0.5965 
2022-03-11 04:09:08 - train: epoch 0040, iter [01000, 05004], lr: 0.010000, loss: 2.1409, CELoss: 1.4880 KDLoss: 0.6529 
2022-03-11 04:09:41 - train: epoch 0040, iter [01100, 05004], lr: 0.010000, loss: 1.8535, CELoss: 1.3347 KDLoss: 0.5187 
2022-03-11 04:10:14 - train: epoch 0040, iter [01200, 05004], lr: 0.010000, loss: 1.9607, CELoss: 1.4216 KDLoss: 0.5391 
2022-03-11 04:10:48 - train: epoch 0040, iter [01300, 05004], lr: 0.010000, loss: 2.0983, CELoss: 1.5003 KDLoss: 0.5980 
2022-03-11 04:11:22 - train: epoch 0040, iter [01400, 05004], lr: 0.010000, loss: 2.2503, CELoss: 1.6896 KDLoss: 0.5607 
2022-03-11 04:11:55 - train: epoch 0040, iter [01500, 05004], lr: 0.010000, loss: 2.2668, CELoss: 1.7193 KDLoss: 0.5474 
2022-03-11 04:12:28 - train: epoch 0040, iter [01600, 05004], lr: 0.010000, loss: 2.2062, CELoss: 1.5794 KDLoss: 0.6268 
2022-03-11 04:13:03 - train: epoch 0040, iter [01700, 05004], lr: 0.010000, loss: 2.2168, CELoss: 1.6156 KDLoss: 0.6012 
2022-03-11 04:13:36 - train: epoch 0040, iter [01800, 05004], lr: 0.010000, loss: 1.9310, CELoss: 1.4213 KDLoss: 0.5097 
2022-03-11 04:14:10 - train: epoch 0040, iter [01900, 05004], lr: 0.010000, loss: 2.0859, CELoss: 1.4809 KDLoss: 0.6051 
2022-03-11 04:14:43 - train: epoch 0040, iter [02000, 05004], lr: 0.010000, loss: 1.9978, CELoss: 1.4860 KDLoss: 0.5117 
2022-03-11 04:15:16 - train: epoch 0040, iter [02100, 05004], lr: 0.010000, loss: 1.8751, CELoss: 1.3146 KDLoss: 0.5605 
2022-03-11 04:15:51 - train: epoch 0040, iter [02200, 05004], lr: 0.010000, loss: 2.2453, CELoss: 1.6515 KDLoss: 0.5938 
2022-03-11 04:16:23 - train: epoch 0040, iter [02300, 05004], lr: 0.010000, loss: 2.2078, CELoss: 1.6377 KDLoss: 0.5700 
2022-03-11 04:16:57 - train: epoch 0040, iter [02400, 05004], lr: 0.010000, loss: 2.2515, CELoss: 1.5923 KDLoss: 0.6592 
2022-03-11 04:17:30 - train: epoch 0040, iter [02500, 05004], lr: 0.010000, loss: 2.2555, CELoss: 1.6624 KDLoss: 0.5931 
2022-03-11 04:18:04 - train: epoch 0040, iter [02600, 05004], lr: 0.010000, loss: 2.0866, CELoss: 1.5538 KDLoss: 0.5328 
2022-03-11 04:18:38 - train: epoch 0040, iter [02700, 05004], lr: 0.010000, loss: 2.2681, CELoss: 1.6701 KDLoss: 0.5980 
2022-03-11 04:19:10 - train: epoch 0040, iter [02800, 05004], lr: 0.010000, loss: 2.3005, CELoss: 1.6649 KDLoss: 0.6356 
2022-03-11 04:19:44 - train: epoch 0040, iter [02900, 05004], lr: 0.010000, loss: 2.3471, CELoss: 1.7166 KDLoss: 0.6305 
2022-03-11 04:20:17 - train: epoch 0040, iter [03000, 05004], lr: 0.010000, loss: 2.2206, CELoss: 1.6428 KDLoss: 0.5777 
2022-03-11 04:20:52 - train: epoch 0040, iter [03100, 05004], lr: 0.010000, loss: 2.2846, CELoss: 1.6522 KDLoss: 0.6323 
2022-03-11 04:21:24 - train: epoch 0040, iter [03200, 05004], lr: 0.010000, loss: 2.4314, CELoss: 1.7670 KDLoss: 0.6644 
2022-03-11 04:21:58 - train: epoch 0040, iter [03300, 05004], lr: 0.010000, loss: 2.1554, CELoss: 1.6209 KDLoss: 0.5345 
2022-03-11 04:22:31 - train: epoch 0040, iter [03400, 05004], lr: 0.010000, loss: 2.1611, CELoss: 1.5538 KDLoss: 0.6073 
2022-03-11 04:23:05 - train: epoch 0040, iter [03500, 05004], lr: 0.010000, loss: 2.2017, CELoss: 1.6322 KDLoss: 0.5695 
2022-03-11 04:23:38 - train: epoch 0040, iter [03600, 05004], lr: 0.010000, loss: 2.2447, CELoss: 1.6443 KDLoss: 0.6005 
2022-03-11 04:24:11 - train: epoch 0040, iter [03700, 05004], lr: 0.010000, loss: 2.1715, CELoss: 1.5109 KDLoss: 0.6606 
2022-03-11 04:24:45 - train: epoch 0040, iter [03800, 05004], lr: 0.010000, loss: 2.1658, CELoss: 1.5948 KDLoss: 0.5710 
2022-03-11 04:25:18 - train: epoch 0040, iter [03900, 05004], lr: 0.010000, loss: 2.1703, CELoss: 1.5943 KDLoss: 0.5759 
2022-03-11 04:25:53 - train: epoch 0040, iter [04000, 05004], lr: 0.010000, loss: 1.9256, CELoss: 1.3936 KDLoss: 0.5320 
2022-03-11 04:26:25 - train: epoch 0040, iter [04100, 05004], lr: 0.010000, loss: 2.1463, CELoss: 1.5222 KDLoss: 0.6242 
2022-03-11 04:27:00 - train: epoch 0040, iter [04200, 05004], lr: 0.010000, loss: 2.1723, CELoss: 1.5648 KDLoss: 0.6075 
2022-03-11 04:27:33 - train: epoch 0040, iter [04300, 05004], lr: 0.010000, loss: 2.1496, CELoss: 1.5748 KDLoss: 0.5748 
2022-03-11 04:28:05 - train: epoch 0040, iter [04400, 05004], lr: 0.010000, loss: 1.9270, CELoss: 1.3618 KDLoss: 0.5652 
2022-03-11 04:28:39 - train: epoch 0040, iter [04500, 05004], lr: 0.010000, loss: 1.9051, CELoss: 1.3624 KDLoss: 0.5428 
2022-03-11 04:29:12 - train: epoch 0040, iter [04600, 05004], lr: 0.010000, loss: 2.2005, CELoss: 1.6120 KDLoss: 0.5885 
2022-03-11 04:29:45 - train: epoch 0040, iter [04700, 05004], lr: 0.010000, loss: 2.4577, CELoss: 1.7647 KDLoss: 0.6930 
2022-03-11 04:30:19 - train: epoch 0040, iter [04800, 05004], lr: 0.010000, loss: 2.0505, CELoss: 1.4930 KDLoss: 0.5574 
2022-03-11 04:30:53 - train: epoch 0040, iter [04900, 05004], lr: 0.010000, loss: 2.0830, CELoss: 1.5179 KDLoss: 0.5652 
2022-03-11 04:31:24 - train: epoch 0040, iter [05000, 05004], lr: 0.010000, loss: 2.1789, CELoss: 1.5686 KDLoss: 0.6102 
2022-03-11 04:31:25 - train: epoch 040, train_loss: 2.1613
2022-03-11 04:33:53 - eval: epoch: 040, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 66.998%, stu_acc5: 87.768%, stu_test_loss: 1.3413
2022-03-11 04:33:53 - until epoch: 040, tea_best_acc1: 73.950%, stu_best_acc1: 67.182%
2022-03-11 04:33:53 - epoch 041 lr: 0.010000000000000002
2022-03-11 04:34:32 - train: epoch 0041, iter [00100, 05004], lr: 0.010000, loss: 2.3309, CELoss: 1.7306 KDLoss: 0.6003 
2022-03-11 04:35:05 - train: epoch 0041, iter [00200, 05004], lr: 0.010000, loss: 2.5162, CELoss: 1.9078 KDLoss: 0.6084 
2022-03-11 04:35:39 - train: epoch 0041, iter [00300, 05004], lr: 0.010000, loss: 2.1873, CELoss: 1.6283 KDLoss: 0.5590 
2022-03-11 04:36:13 - train: epoch 0041, iter [00400, 05004], lr: 0.010000, loss: 2.1073, CELoss: 1.4975 KDLoss: 0.6098 
2022-03-11 04:36:46 - train: epoch 0041, iter [00500, 05004], lr: 0.010000, loss: 1.9719, CELoss: 1.4088 KDLoss: 0.5631 
2022-03-11 04:37:19 - train: epoch 0041, iter [00600, 05004], lr: 0.010000, loss: 2.3111, CELoss: 1.6872 KDLoss: 0.6239 
2022-03-11 04:37:54 - train: epoch 0041, iter [00700, 05004], lr: 0.010000, loss: 1.8633, CELoss: 1.3539 KDLoss: 0.5094 
2022-03-11 04:38:27 - train: epoch 0041, iter [00800, 05004], lr: 0.010000, loss: 1.9925, CELoss: 1.4636 KDLoss: 0.5290 
2022-03-11 04:39:01 - train: epoch 0041, iter [00900, 05004], lr: 0.010000, loss: 2.0264, CELoss: 1.4680 KDLoss: 0.5584 
2022-03-11 04:39:35 - train: epoch 0041, iter [01000, 05004], lr: 0.010000, loss: 2.2921, CELoss: 1.6990 KDLoss: 0.5931 
2022-03-11 04:40:08 - train: epoch 0041, iter [01100, 05004], lr: 0.010000, loss: 2.0012, CELoss: 1.4834 KDLoss: 0.5178 
2022-03-11 04:40:41 - train: epoch 0041, iter [01200, 05004], lr: 0.010000, loss: 1.9234, CELoss: 1.4040 KDLoss: 0.5194 
2022-03-11 04:41:15 - train: epoch 0041, iter [01300, 05004], lr: 0.010000, loss: 1.8745, CELoss: 1.3526 KDLoss: 0.5219 
2022-03-11 04:41:49 - train: epoch 0041, iter [01400, 05004], lr: 0.010000, loss: 2.2218, CELoss: 1.6030 KDLoss: 0.6188 
2022-03-11 04:42:22 - train: epoch 0041, iter [01500, 05004], lr: 0.010000, loss: 2.5144, CELoss: 1.8636 KDLoss: 0.6508 
2022-03-11 04:42:56 - train: epoch 0041, iter [01600, 05004], lr: 0.010000, loss: 2.0743, CELoss: 1.4619 KDLoss: 0.6125 
2022-03-11 04:43:29 - train: epoch 0041, iter [01700, 05004], lr: 0.010000, loss: 2.2009, CELoss: 1.6051 KDLoss: 0.5958 
2022-03-11 04:44:03 - train: epoch 0041, iter [01800, 05004], lr: 0.010000, loss: 2.2106, CELoss: 1.6301 KDLoss: 0.5805 
2022-03-11 04:44:37 - train: epoch 0041, iter [01900, 05004], lr: 0.010000, loss: 2.1722, CELoss: 1.6232 KDLoss: 0.5490 
2022-03-11 04:45:11 - train: epoch 0041, iter [02000, 05004], lr: 0.010000, loss: 2.2464, CELoss: 1.6098 KDLoss: 0.6366 
2022-03-11 04:45:45 - train: epoch 0041, iter [02100, 05004], lr: 0.010000, loss: 1.9499, CELoss: 1.4068 KDLoss: 0.5430 
2022-03-11 04:46:18 - train: epoch 0041, iter [02200, 05004], lr: 0.010000, loss: 1.8878, CELoss: 1.3777 KDLoss: 0.5101 
2022-03-11 04:46:50 - train: epoch 0041, iter [02300, 05004], lr: 0.010000, loss: 2.0680, CELoss: 1.5153 KDLoss: 0.5527 
2022-03-11 04:47:25 - train: epoch 0041, iter [02400, 05004], lr: 0.010000, loss: 2.4102, CELoss: 1.7378 KDLoss: 0.6723 
2022-03-11 04:47:58 - train: epoch 0041, iter [02500, 05004], lr: 0.010000, loss: 1.9382, CELoss: 1.3867 KDLoss: 0.5515 
2022-03-11 04:48:31 - train: epoch 0041, iter [02600, 05004], lr: 0.010000, loss: 2.4320, CELoss: 1.7780 KDLoss: 0.6540 
2022-03-11 04:49:05 - train: epoch 0041, iter [02700, 05004], lr: 0.010000, loss: 2.3608, CELoss: 1.7714 KDLoss: 0.5894 
2022-03-11 04:49:39 - train: epoch 0041, iter [02800, 05004], lr: 0.010000, loss: 2.0664, CELoss: 1.4778 KDLoss: 0.5886 
2022-03-11 04:50:12 - train: epoch 0041, iter [02900, 05004], lr: 0.010000, loss: 2.0485, CELoss: 1.4966 KDLoss: 0.5518 
2022-03-11 04:50:46 - train: epoch 0041, iter [03000, 05004], lr: 0.010000, loss: 2.3940, CELoss: 1.7133 KDLoss: 0.6807 
2022-03-11 04:51:19 - train: epoch 0041, iter [03100, 05004], lr: 0.010000, loss: 2.1713, CELoss: 1.5700 KDLoss: 0.6012 
2022-03-11 04:51:53 - train: epoch 0041, iter [03200, 05004], lr: 0.010000, loss: 2.1469, CELoss: 1.5645 KDLoss: 0.5824 
2022-03-11 04:52:26 - train: epoch 0041, iter [03300, 05004], lr: 0.010000, loss: 2.0320, CELoss: 1.4569 KDLoss: 0.5751 
2022-03-11 04:52:59 - train: epoch 0041, iter [03400, 05004], lr: 0.010000, loss: 2.0698, CELoss: 1.5383 KDLoss: 0.5315 
2022-03-11 04:53:33 - train: epoch 0041, iter [03500, 05004], lr: 0.010000, loss: 2.0615, CELoss: 1.4790 KDLoss: 0.5825 
2022-03-11 04:54:06 - train: epoch 0041, iter [03600, 05004], lr: 0.010000, loss: 2.2887, CELoss: 1.6981 KDLoss: 0.5906 
2022-03-11 04:54:40 - train: epoch 0041, iter [03700, 05004], lr: 0.010000, loss: 2.2539, CELoss: 1.6745 KDLoss: 0.5794 
2022-03-11 04:55:13 - train: epoch 0041, iter [03800, 05004], lr: 0.010000, loss: 2.0838, CELoss: 1.5062 KDLoss: 0.5776 
2022-03-11 04:55:48 - train: epoch 0041, iter [03900, 05004], lr: 0.010000, loss: 2.0100, CELoss: 1.4757 KDLoss: 0.5343 
2022-03-11 04:56:21 - train: epoch 0041, iter [04000, 05004], lr: 0.010000, loss: 1.9775, CELoss: 1.3981 KDLoss: 0.5794 
2022-03-11 04:56:54 - train: epoch 0041, iter [04100, 05004], lr: 0.010000, loss: 2.1594, CELoss: 1.5468 KDLoss: 0.6126 
2022-03-11 04:57:28 - train: epoch 0041, iter [04200, 05004], lr: 0.010000, loss: 1.7493, CELoss: 1.2683 KDLoss: 0.4810 
2022-03-11 04:58:01 - train: epoch 0041, iter [04300, 05004], lr: 0.010000, loss: 1.9906, CELoss: 1.4301 KDLoss: 0.5605 
2022-03-11 04:58:34 - train: epoch 0041, iter [04400, 05004], lr: 0.010000, loss: 1.9240, CELoss: 1.3978 KDLoss: 0.5261 
2022-03-11 04:59:08 - train: epoch 0041, iter [04500, 05004], lr: 0.010000, loss: 2.1994, CELoss: 1.6399 KDLoss: 0.5595 
2022-03-11 04:59:41 - train: epoch 0041, iter [04600, 05004], lr: 0.010000, loss: 2.2251, CELoss: 1.6447 KDLoss: 0.5804 
2022-03-11 05:00:15 - train: epoch 0041, iter [04700, 05004], lr: 0.010000, loss: 2.1653, CELoss: 1.5931 KDLoss: 0.5721 
2022-03-11 05:00:48 - train: epoch 0041, iter [04800, 05004], lr: 0.010000, loss: 2.0604, CELoss: 1.4647 KDLoss: 0.5957 
2022-03-11 05:01:21 - train: epoch 0041, iter [04900, 05004], lr: 0.010000, loss: 2.2210, CELoss: 1.5471 KDLoss: 0.6739 
2022-03-11 05:01:53 - train: epoch 0041, iter [05000, 05004], lr: 0.010000, loss: 2.1754, CELoss: 1.5696 KDLoss: 0.6058 
2022-03-11 05:01:54 - train: epoch 041, train_loss: 2.1638
2022-03-11 05:04:23 - eval: epoch: 041, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 66.586%, stu_acc5: 87.548%, stu_test_loss: 1.3657
2022-03-11 05:04:24 - until epoch: 041, tea_best_acc1: 73.950%, stu_best_acc1: 67.182%
2022-03-11 05:04:24 - epoch 042 lr: 0.010000000000000002
2022-03-11 05:05:02 - train: epoch 0042, iter [00100, 05004], lr: 0.010000, loss: 1.8717, CELoss: 1.3625 KDLoss: 0.5091 
2022-03-11 05:05:36 - train: epoch 0042, iter [00200, 05004], lr: 0.010000, loss: 1.9897, CELoss: 1.4438 KDLoss: 0.5459 
2022-03-11 05:06:09 - train: epoch 0042, iter [00300, 05004], lr: 0.010000, loss: 2.4098, CELoss: 1.7900 KDLoss: 0.6198 
2022-03-11 05:06:41 - train: epoch 0042, iter [00400, 05004], lr: 0.010000, loss: 1.9412, CELoss: 1.3979 KDLoss: 0.5433 
2022-03-11 05:07:15 - train: epoch 0042, iter [00500, 05004], lr: 0.010000, loss: 1.9179, CELoss: 1.4058 KDLoss: 0.5120 
2022-03-11 05:07:49 - train: epoch 0042, iter [00600, 05004], lr: 0.010000, loss: 2.0330, CELoss: 1.5291 KDLoss: 0.5040 
2022-03-11 05:08:21 - train: epoch 0042, iter [00700, 05004], lr: 0.010000, loss: 2.2742, CELoss: 1.6416 KDLoss: 0.6326 
2022-03-11 05:08:55 - train: epoch 0042, iter [00800, 05004], lr: 0.010000, loss: 2.1562, CELoss: 1.5459 KDLoss: 0.6103 
2022-03-11 05:09:29 - train: epoch 0042, iter [00900, 05004], lr: 0.010000, loss: 2.2840, CELoss: 1.6697 KDLoss: 0.6142 
2022-03-11 05:10:02 - train: epoch 0042, iter [01000, 05004], lr: 0.010000, loss: 2.4680, CELoss: 1.8517 KDLoss: 0.6163 
2022-03-11 05:10:37 - train: epoch 0042, iter [01100, 05004], lr: 0.010000, loss: 2.0344, CELoss: 1.4747 KDLoss: 0.5597 
2022-03-11 05:11:10 - train: epoch 0042, iter [01200, 05004], lr: 0.010000, loss: 1.8962, CELoss: 1.3211 KDLoss: 0.5751 
2022-03-11 05:11:43 - train: epoch 0042, iter [01300, 05004], lr: 0.010000, loss: 2.2858, CELoss: 1.7070 KDLoss: 0.5787 
2022-03-11 05:12:18 - train: epoch 0042, iter [01400, 05004], lr: 0.010000, loss: 2.4498, CELoss: 1.8298 KDLoss: 0.6200 
2022-03-11 05:12:52 - train: epoch 0042, iter [01500, 05004], lr: 0.010000, loss: 1.9804, CELoss: 1.4241 KDLoss: 0.5563 
2022-03-11 05:13:24 - train: epoch 0042, iter [01600, 05004], lr: 0.010000, loss: 2.1210, CELoss: 1.5907 KDLoss: 0.5303 
2022-03-11 05:13:59 - train: epoch 0042, iter [01700, 05004], lr: 0.010000, loss: 2.3196, CELoss: 1.7266 KDLoss: 0.5929 
2022-03-11 05:14:32 - train: epoch 0042, iter [01800, 05004], lr: 0.010000, loss: 1.8654, CELoss: 1.3543 KDLoss: 0.5111 
2022-03-11 05:15:06 - train: epoch 0042, iter [01900, 05004], lr: 0.010000, loss: 2.3011, CELoss: 1.6523 KDLoss: 0.6489 
2022-03-11 05:15:39 - train: epoch 0042, iter [02000, 05004], lr: 0.010000, loss: 2.1954, CELoss: 1.5698 KDLoss: 0.6257 
2022-03-11 05:16:14 - train: epoch 0042, iter [02100, 05004], lr: 0.010000, loss: 1.8976, CELoss: 1.3406 KDLoss: 0.5570 
2022-03-11 05:16:47 - train: epoch 0042, iter [02200, 05004], lr: 0.010000, loss: 1.9719, CELoss: 1.4168 KDLoss: 0.5551 
2022-03-11 05:17:21 - train: epoch 0042, iter [02300, 05004], lr: 0.010000, loss: 2.2821, CELoss: 1.6418 KDLoss: 0.6404 
2022-03-11 05:17:54 - train: epoch 0042, iter [02400, 05004], lr: 0.010000, loss: 2.2021, CELoss: 1.6195 KDLoss: 0.5826 
2022-03-11 05:18:28 - train: epoch 0042, iter [02500, 05004], lr: 0.010000, loss: 2.3085, CELoss: 1.7284 KDLoss: 0.5800 
2022-03-11 05:19:02 - train: epoch 0042, iter [02600, 05004], lr: 0.010000, loss: 2.3428, CELoss: 1.7192 KDLoss: 0.6236 
2022-03-11 05:19:35 - train: epoch 0042, iter [02700, 05004], lr: 0.010000, loss: 2.0007, CELoss: 1.4678 KDLoss: 0.5329 
2022-03-11 05:20:08 - train: epoch 0042, iter [02800, 05004], lr: 0.010000, loss: 2.0739, CELoss: 1.4710 KDLoss: 0.6029 
2022-03-11 05:20:42 - train: epoch 0042, iter [02900, 05004], lr: 0.010000, loss: 2.0965, CELoss: 1.5762 KDLoss: 0.5203 
2022-03-11 05:21:16 - train: epoch 0042, iter [03000, 05004], lr: 0.010000, loss: 2.1273, CELoss: 1.5176 KDLoss: 0.6097 
2022-03-11 05:21:50 - train: epoch 0042, iter [03100, 05004], lr: 0.010000, loss: 2.3008, CELoss: 1.6481 KDLoss: 0.6527 
2022-03-11 05:22:23 - train: epoch 0042, iter [03200, 05004], lr: 0.010000, loss: 2.3364, CELoss: 1.7648 KDLoss: 0.5716 
2022-03-11 05:22:57 - train: epoch 0042, iter [03300, 05004], lr: 0.010000, loss: 2.5912, CELoss: 1.9249 KDLoss: 0.6664 
2022-03-11 05:23:30 - train: epoch 0042, iter [03400, 05004], lr: 0.010000, loss: 1.8883, CELoss: 1.3503 KDLoss: 0.5380 
2022-03-11 05:24:02 - train: epoch 0042, iter [03500, 05004], lr: 0.010000, loss: 2.1347, CELoss: 1.5876 KDLoss: 0.5471 
2022-03-11 05:24:36 - train: epoch 0042, iter [03600, 05004], lr: 0.010000, loss: 2.2124, CELoss: 1.6390 KDLoss: 0.5734 
2022-03-11 05:25:09 - train: epoch 0042, iter [03700, 05004], lr: 0.010000, loss: 2.2456, CELoss: 1.5917 KDLoss: 0.6539 
2022-03-11 05:25:44 - train: epoch 0042, iter [03800, 05004], lr: 0.010000, loss: 1.8970, CELoss: 1.3389 KDLoss: 0.5581 
2022-03-11 05:26:16 - train: epoch 0042, iter [03900, 05004], lr: 0.010000, loss: 2.0997, CELoss: 1.5380 KDLoss: 0.5617 
2022-03-11 05:26:50 - train: epoch 0042, iter [04000, 05004], lr: 0.010000, loss: 2.0011, CELoss: 1.4514 KDLoss: 0.5498 
2022-03-11 05:27:23 - train: epoch 0042, iter [04100, 05004], lr: 0.010000, loss: 2.2043, CELoss: 1.5803 KDLoss: 0.6241 
2022-03-11 05:27:57 - train: epoch 0042, iter [04200, 05004], lr: 0.010000, loss: 2.3323, CELoss: 1.7482 KDLoss: 0.5841 
2022-03-11 05:28:30 - train: epoch 0042, iter [04300, 05004], lr: 0.010000, loss: 2.0368, CELoss: 1.4913 KDLoss: 0.5455 
2022-03-11 05:29:03 - train: epoch 0042, iter [04400, 05004], lr: 0.010000, loss: 2.0123, CELoss: 1.4499 KDLoss: 0.5623 
2022-03-11 05:29:36 - train: epoch 0042, iter [04500, 05004], lr: 0.010000, loss: 2.1356, CELoss: 1.5315 KDLoss: 0.6041 
2022-03-11 05:30:10 - train: epoch 0042, iter [04600, 05004], lr: 0.010000, loss: 2.3139, CELoss: 1.6670 KDLoss: 0.6468 
2022-03-11 05:30:43 - train: epoch 0042, iter [04700, 05004], lr: 0.010000, loss: 1.9798, CELoss: 1.4219 KDLoss: 0.5579 
2022-03-11 05:31:16 - train: epoch 0042, iter [04800, 05004], lr: 0.010000, loss: 2.4420, CELoss: 1.8151 KDLoss: 0.6270 
2022-03-11 05:31:49 - train: epoch 0042, iter [04900, 05004], lr: 0.010000, loss: 2.2025, CELoss: 1.6015 KDLoss: 0.6009 
2022-03-11 05:32:21 - train: epoch 0042, iter [05000, 05004], lr: 0.010000, loss: 2.3203, CELoss: 1.6807 KDLoss: 0.6396 
2022-03-11 05:32:22 - train: epoch 042, train_loss: 2.1667
2022-03-11 05:34:50 - eval: epoch: 042, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 66.462%, stu_acc5: 87.352%, stu_test_loss: 1.3734
2022-03-11 05:34:51 - until epoch: 042, tea_best_acc1: 73.950%, stu_best_acc1: 67.182%
2022-03-11 05:34:51 - epoch 043 lr: 0.010000000000000002
2022-03-11 05:35:29 - train: epoch 0043, iter [00100, 05004], lr: 0.010000, loss: 2.2153, CELoss: 1.6243 KDLoss: 0.5910 
2022-03-11 05:36:02 - train: epoch 0043, iter [00200, 05004], lr: 0.010000, loss: 2.4104, CELoss: 1.8482 KDLoss: 0.5622 
2022-03-11 05:36:36 - train: epoch 0043, iter [00300, 05004], lr: 0.010000, loss: 1.9203, CELoss: 1.4245 KDLoss: 0.4957 
2022-03-11 05:37:09 - train: epoch 0043, iter [00400, 05004], lr: 0.010000, loss: 1.9332, CELoss: 1.4061 KDLoss: 0.5271 
2022-03-11 05:37:43 - train: epoch 0043, iter [00500, 05004], lr: 0.010000, loss: 2.0254, CELoss: 1.4402 KDLoss: 0.5853 
2022-03-11 05:38:16 - train: epoch 0043, iter [00600, 05004], lr: 0.010000, loss: 2.2380, CELoss: 1.6147 KDLoss: 0.6233 
2022-03-11 05:38:49 - train: epoch 0043, iter [00700, 05004], lr: 0.010000, loss: 2.1760, CELoss: 1.5555 KDLoss: 0.6205 
2022-03-11 05:39:22 - train: epoch 0043, iter [00800, 05004], lr: 0.010000, loss: 1.9986, CELoss: 1.4711 KDLoss: 0.5275 
2022-03-11 05:39:56 - train: epoch 0043, iter [00900, 05004], lr: 0.010000, loss: 1.9639, CELoss: 1.4357 KDLoss: 0.5282 
2022-03-11 05:40:29 - train: epoch 0043, iter [01000, 05004], lr: 0.010000, loss: 2.5774, CELoss: 1.9238 KDLoss: 0.6536 
2022-03-11 05:41:03 - train: epoch 0043, iter [01100, 05004], lr: 0.010000, loss: 2.1611, CELoss: 1.6056 KDLoss: 0.5555 
2022-03-11 05:41:36 - train: epoch 0043, iter [01200, 05004], lr: 0.010000, loss: 2.0800, CELoss: 1.5216 KDLoss: 0.5585 
2022-03-11 05:42:09 - train: epoch 0043, iter [01300, 05004], lr: 0.010000, loss: 2.2796, CELoss: 1.7327 KDLoss: 0.5469 
2022-03-11 05:42:43 - train: epoch 0043, iter [01400, 05004], lr: 0.010000, loss: 2.1172, CELoss: 1.5202 KDLoss: 0.5971 
2022-03-11 05:43:17 - train: epoch 0043, iter [01500, 05004], lr: 0.010000, loss: 1.9502, CELoss: 1.3710 KDLoss: 0.5792 
2022-03-11 05:43:50 - train: epoch 0043, iter [01600, 05004], lr: 0.010000, loss: 2.1531, CELoss: 1.5353 KDLoss: 0.6178 
2022-03-11 05:44:24 - train: epoch 0043, iter [01700, 05004], lr: 0.010000, loss: 2.1664, CELoss: 1.5540 KDLoss: 0.6124 
2022-03-11 05:44:58 - train: epoch 0043, iter [01800, 05004], lr: 0.010000, loss: 2.3792, CELoss: 1.7786 KDLoss: 0.6006 
2022-03-11 05:45:32 - train: epoch 0043, iter [01900, 05004], lr: 0.010000, loss: 2.3214, CELoss: 1.7124 KDLoss: 0.6090 
2022-03-11 05:46:04 - train: epoch 0043, iter [02000, 05004], lr: 0.010000, loss: 1.9356, CELoss: 1.3838 KDLoss: 0.5519 
2022-03-11 05:46:38 - train: epoch 0043, iter [02100, 05004], lr: 0.010000, loss: 2.0382, CELoss: 1.4602 KDLoss: 0.5780 
2022-03-11 05:47:12 - train: epoch 0043, iter [02200, 05004], lr: 0.010000, loss: 2.4993, CELoss: 1.8652 KDLoss: 0.6341 
2022-03-11 05:47:45 - train: epoch 0043, iter [02300, 05004], lr: 0.010000, loss: 2.3933, CELoss: 1.7617 KDLoss: 0.6316 
2022-03-11 05:48:17 - train: epoch 0043, iter [02400, 05004], lr: 0.010000, loss: 1.9435, CELoss: 1.3554 KDLoss: 0.5881 
2022-03-11 05:48:51 - train: epoch 0043, iter [02500, 05004], lr: 0.010000, loss: 2.2521, CELoss: 1.5903 KDLoss: 0.6618 
2022-03-11 05:49:26 - train: epoch 0043, iter [02600, 05004], lr: 0.010000, loss: 1.9701, CELoss: 1.4589 KDLoss: 0.5113 
2022-03-11 05:49:58 - train: epoch 0043, iter [02700, 05004], lr: 0.010000, loss: 2.3161, CELoss: 1.6985 KDLoss: 0.6176 
2022-03-11 05:50:32 - train: epoch 0043, iter [02800, 05004], lr: 0.010000, loss: 2.2060, CELoss: 1.5824 KDLoss: 0.6236 
2022-03-11 05:51:05 - train: epoch 0043, iter [02900, 05004], lr: 0.010000, loss: 2.0948, CELoss: 1.5529 KDLoss: 0.5419 
2022-03-11 05:51:39 - train: epoch 0043, iter [03000, 05004], lr: 0.010000, loss: 2.4353, CELoss: 1.7585 KDLoss: 0.6768 
2022-03-11 05:52:11 - train: epoch 0043, iter [03100, 05004], lr: 0.010000, loss: 2.3398, CELoss: 1.7271 KDLoss: 0.6127 
2022-03-11 05:52:46 - train: epoch 0043, iter [03200, 05004], lr: 0.010000, loss: 2.1856, CELoss: 1.5513 KDLoss: 0.6343 
2022-03-11 05:53:19 - train: epoch 0043, iter [03300, 05004], lr: 0.010000, loss: 2.3975, CELoss: 1.7494 KDLoss: 0.6481 
2022-03-11 05:53:52 - train: epoch 0043, iter [03400, 05004], lr: 0.010000, loss: 2.1355, CELoss: 1.5346 KDLoss: 0.6010 
2022-03-11 05:54:26 - train: epoch 0043, iter [03500, 05004], lr: 0.010000, loss: 2.0639, CELoss: 1.4964 KDLoss: 0.5675 
2022-03-11 05:54:59 - train: epoch 0043, iter [03600, 05004], lr: 0.010000, loss: 2.3823, CELoss: 1.7023 KDLoss: 0.6800 
2022-03-11 05:55:33 - train: epoch 0043, iter [03700, 05004], lr: 0.010000, loss: 2.1207, CELoss: 1.5215 KDLoss: 0.5991 
2022-03-11 05:56:06 - train: epoch 0043, iter [03800, 05004], lr: 0.010000, loss: 2.4853, CELoss: 1.8625 KDLoss: 0.6228 
2022-03-11 05:56:39 - train: epoch 0043, iter [03900, 05004], lr: 0.010000, loss: 2.0703, CELoss: 1.5526 KDLoss: 0.5177 
2022-03-11 05:57:13 - train: epoch 0043, iter [04000, 05004], lr: 0.010000, loss: 2.2718, CELoss: 1.6531 KDLoss: 0.6187 
2022-03-11 05:57:47 - train: epoch 0043, iter [04100, 05004], lr: 0.010000, loss: 2.1600, CELoss: 1.5908 KDLoss: 0.5692 
2022-03-11 05:58:21 - train: epoch 0043, iter [04200, 05004], lr: 0.010000, loss: 2.3159, CELoss: 1.6689 KDLoss: 0.6470 
2022-03-11 05:58:54 - train: epoch 0043, iter [04300, 05004], lr: 0.010000, loss: 2.2869, CELoss: 1.6808 KDLoss: 0.6061 
2022-03-11 05:59:28 - train: epoch 0043, iter [04400, 05004], lr: 0.010000, loss: 2.2455, CELoss: 1.6422 KDLoss: 0.6033 
2022-03-11 06:00:01 - train: epoch 0043, iter [04500, 05004], lr: 0.010000, loss: 2.1633, CELoss: 1.5753 KDLoss: 0.5880 
2022-03-11 06:00:34 - train: epoch 0043, iter [04600, 05004], lr: 0.010000, loss: 2.2772, CELoss: 1.6487 KDLoss: 0.6285 
2022-03-11 06:01:08 - train: epoch 0043, iter [04700, 05004], lr: 0.010000, loss: 2.0622, CELoss: 1.4869 KDLoss: 0.5753 
2022-03-11 06:01:41 - train: epoch 0043, iter [04800, 05004], lr: 0.010000, loss: 2.1711, CELoss: 1.5724 KDLoss: 0.5987 
2022-03-11 06:02:15 - train: epoch 0043, iter [04900, 05004], lr: 0.010000, loss: 2.0366, CELoss: 1.5220 KDLoss: 0.5146 
2022-03-11 06:02:46 - train: epoch 0043, iter [05000, 05004], lr: 0.010000, loss: 2.1188, CELoss: 1.5142 KDLoss: 0.6045 
2022-03-11 06:02:47 - train: epoch 043, train_loss: 2.1735
2022-03-11 06:05:16 - eval: epoch: 043, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 66.508%, stu_acc5: 87.480%, stu_test_loss: 1.3601
2022-03-11 06:05:16 - until epoch: 043, tea_best_acc1: 73.950%, stu_best_acc1: 67.182%
2022-03-11 06:05:16 - epoch 044 lr: 0.010000000000000002
2022-03-11 06:05:55 - train: epoch 0044, iter [00100, 05004], lr: 0.010000, loss: 2.2337, CELoss: 1.6497 KDLoss: 0.5841 
2022-03-11 06:06:28 - train: epoch 0044, iter [00200, 05004], lr: 0.010000, loss: 2.2731, CELoss: 1.6578 KDLoss: 0.6153 
2022-03-11 06:07:02 - train: epoch 0044, iter [00300, 05004], lr: 0.010000, loss: 2.0434, CELoss: 1.5010 KDLoss: 0.5424 
2022-03-11 06:07:36 - train: epoch 0044, iter [00400, 05004], lr: 0.010000, loss: 1.8612, CELoss: 1.3341 KDLoss: 0.5271 
2022-03-11 06:08:09 - train: epoch 0044, iter [00500, 05004], lr: 0.010000, loss: 2.3404, CELoss: 1.6944 KDLoss: 0.6461 
2022-03-11 06:08:43 - train: epoch 0044, iter [00600, 05004], lr: 0.010000, loss: 1.7689, CELoss: 1.2736 KDLoss: 0.4953 
2022-03-11 06:09:16 - train: epoch 0044, iter [00700, 05004], lr: 0.010000, loss: 1.8480, CELoss: 1.3269 KDLoss: 0.5211 
2022-03-11 06:09:49 - train: epoch 0044, iter [00800, 05004], lr: 0.010000, loss: 2.1710, CELoss: 1.5960 KDLoss: 0.5750 
2022-03-11 06:10:22 - train: epoch 0044, iter [00900, 05004], lr: 0.010000, loss: 2.0849, CELoss: 1.5332 KDLoss: 0.5517 
2022-03-11 06:10:55 - train: epoch 0044, iter [01000, 05004], lr: 0.010000, loss: 2.0841, CELoss: 1.5523 KDLoss: 0.5318 
2022-03-11 06:11:29 - train: epoch 0044, iter [01100, 05004], lr: 0.010000, loss: 1.9736, CELoss: 1.3792 KDLoss: 0.5944 
2022-03-11 06:12:03 - train: epoch 0044, iter [01200, 05004], lr: 0.010000, loss: 2.0335, CELoss: 1.5377 KDLoss: 0.4958 
2022-03-11 06:12:36 - train: epoch 0044, iter [01300, 05004], lr: 0.010000, loss: 2.1459, CELoss: 1.5907 KDLoss: 0.5552 
2022-03-11 06:13:10 - train: epoch 0044, iter [01400, 05004], lr: 0.010000, loss: 2.1108, CELoss: 1.4956 KDLoss: 0.6152 
2022-03-11 06:13:43 - train: epoch 0044, iter [01500, 05004], lr: 0.010000, loss: 2.1938, CELoss: 1.5844 KDLoss: 0.6094 
2022-03-11 06:14:17 - train: epoch 0044, iter [01600, 05004], lr: 0.010000, loss: 2.0166, CELoss: 1.4287 KDLoss: 0.5879 
2022-03-11 06:14:50 - train: epoch 0044, iter [01700, 05004], lr: 0.010000, loss: 2.0923, CELoss: 1.4744 KDLoss: 0.6178 
2022-03-11 06:15:24 - train: epoch 0044, iter [01800, 05004], lr: 0.010000, loss: 2.2112, CELoss: 1.6321 KDLoss: 0.5792 
2022-03-11 06:15:56 - train: epoch 0044, iter [01900, 05004], lr: 0.010000, loss: 2.3272, CELoss: 1.7190 KDLoss: 0.6082 
2022-03-11 06:16:30 - train: epoch 0044, iter [02000, 05004], lr: 0.010000, loss: 1.8621, CELoss: 1.3099 KDLoss: 0.5523 
2022-03-11 06:17:04 - train: epoch 0044, iter [02100, 05004], lr: 0.010000, loss: 2.1415, CELoss: 1.5688 KDLoss: 0.5727 
2022-03-11 06:17:38 - train: epoch 0044, iter [02200, 05004], lr: 0.010000, loss: 2.2681, CELoss: 1.6950 KDLoss: 0.5731 
2022-03-11 06:18:10 - train: epoch 0044, iter [02300, 05004], lr: 0.010000, loss: 2.3836, CELoss: 1.7600 KDLoss: 0.6236 
2022-03-11 06:18:44 - train: epoch 0044, iter [02400, 05004], lr: 0.010000, loss: 2.1400, CELoss: 1.5351 KDLoss: 0.6049 
2022-03-11 06:19:18 - train: epoch 0044, iter [02500, 05004], lr: 0.010000, loss: 2.2588, CELoss: 1.6780 KDLoss: 0.5808 
2022-03-11 06:19:51 - train: epoch 0044, iter [02600, 05004], lr: 0.010000, loss: 2.2986, CELoss: 1.6767 KDLoss: 0.6219 
2022-03-11 06:20:25 - train: epoch 0044, iter [02700, 05004], lr: 0.010000, loss: 2.3148, CELoss: 1.6730 KDLoss: 0.6418 
2022-03-11 06:20:58 - train: epoch 0044, iter [02800, 05004], lr: 0.010000, loss: 2.0204, CELoss: 1.4581 KDLoss: 0.5623 
2022-03-11 06:21:31 - train: epoch 0044, iter [02900, 05004], lr: 0.010000, loss: 1.8784, CELoss: 1.3457 KDLoss: 0.5327 
2022-03-11 06:22:06 - train: epoch 0044, iter [03000, 05004], lr: 0.010000, loss: 1.9258, CELoss: 1.3643 KDLoss: 0.5616 
2022-03-11 06:22:38 - train: epoch 0044, iter [03100, 05004], lr: 0.010000, loss: 1.9408, CELoss: 1.4186 KDLoss: 0.5222 
2022-03-11 06:23:12 - train: epoch 0044, iter [03200, 05004], lr: 0.010000, loss: 1.9316, CELoss: 1.3991 KDLoss: 0.5325 
2022-03-11 06:23:45 - train: epoch 0044, iter [03300, 05004], lr: 0.010000, loss: 2.1281, CELoss: 1.5654 KDLoss: 0.5627 
2022-03-11 06:24:19 - train: epoch 0044, iter [03400, 05004], lr: 0.010000, loss: 2.2540, CELoss: 1.6472 KDLoss: 0.6068 
2022-03-11 06:24:53 - train: epoch 0044, iter [03500, 05004], lr: 0.010000, loss: 2.2011, CELoss: 1.5787 KDLoss: 0.6224 
2022-03-11 06:25:26 - train: epoch 0044, iter [03600, 05004], lr: 0.010000, loss: 2.2952, CELoss: 1.6688 KDLoss: 0.6264 
2022-03-11 06:25:59 - train: epoch 0044, iter [03700, 05004], lr: 0.010000, loss: 2.2111, CELoss: 1.6191 KDLoss: 0.5920 
2022-03-11 06:26:33 - train: epoch 0044, iter [03800, 05004], lr: 0.010000, loss: 1.9250, CELoss: 1.3838 KDLoss: 0.5412 
2022-03-11 06:27:07 - train: epoch 0044, iter [03900, 05004], lr: 0.010000, loss: 2.1480, CELoss: 1.5529 KDLoss: 0.5951 
2022-03-11 06:27:40 - train: epoch 0044, iter [04000, 05004], lr: 0.010000, loss: 2.1494, CELoss: 1.6084 KDLoss: 0.5410 
2022-03-11 06:28:13 - train: epoch 0044, iter [04100, 05004], lr: 0.010000, loss: 2.0658, CELoss: 1.4643 KDLoss: 0.6015 
2022-03-11 06:28:47 - train: epoch 0044, iter [04200, 05004], lr: 0.010000, loss: 2.3625, CELoss: 1.7213 KDLoss: 0.6412 
2022-03-11 06:29:20 - train: epoch 0044, iter [04300, 05004], lr: 0.010000, loss: 2.1788, CELoss: 1.5678 KDLoss: 0.6110 
2022-03-11 06:29:54 - train: epoch 0044, iter [04400, 05004], lr: 0.010000, loss: 2.2018, CELoss: 1.6298 KDLoss: 0.5720 
2022-03-11 06:30:27 - train: epoch 0044, iter [04500, 05004], lr: 0.010000, loss: 2.3485, CELoss: 1.7006 KDLoss: 0.6478 
2022-03-11 06:31:00 - train: epoch 0044, iter [04600, 05004], lr: 0.010000, loss: 2.1726, CELoss: 1.5393 KDLoss: 0.6333 
2022-03-11 06:31:33 - train: epoch 0044, iter [04700, 05004], lr: 0.010000, loss: 2.1882, CELoss: 1.6215 KDLoss: 0.5667 
2022-03-11 06:32:07 - train: epoch 0044, iter [04800, 05004], lr: 0.010000, loss: 2.2155, CELoss: 1.5676 KDLoss: 0.6479 
2022-03-11 06:32:39 - train: epoch 0044, iter [04900, 05004], lr: 0.010000, loss: 2.1814, CELoss: 1.5179 KDLoss: 0.6635 
2022-03-11 06:33:11 - train: epoch 0044, iter [05000, 05004], lr: 0.010000, loss: 2.3002, CELoss: 1.6837 KDLoss: 0.6165 
2022-03-11 06:33:12 - train: epoch 044, train_loss: 2.1750
2022-03-11 06:35:41 - eval: epoch: 044, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 66.556%, stu_acc5: 87.492%, stu_test_loss: 1.3700
2022-03-11 06:35:42 - until epoch: 044, tea_best_acc1: 73.950%, stu_best_acc1: 67.182%
2022-03-11 06:35:42 - epoch 045 lr: 0.010000000000000002
2022-03-11 06:36:21 - train: epoch 0045, iter [00100, 05004], lr: 0.010000, loss: 2.0137, CELoss: 1.4374 KDLoss: 0.5764 
2022-03-11 06:36:53 - train: epoch 0045, iter [00200, 05004], lr: 0.010000, loss: 2.0381, CELoss: 1.4304 KDLoss: 0.6076 
2022-03-11 06:37:27 - train: epoch 0045, iter [00300, 05004], lr: 0.010000, loss: 2.0729, CELoss: 1.5269 KDLoss: 0.5460 
2022-03-11 06:38:00 - train: epoch 0045, iter [00400, 05004], lr: 0.010000, loss: 2.1724, CELoss: 1.5883 KDLoss: 0.5841 
2022-03-11 06:38:34 - train: epoch 0045, iter [00500, 05004], lr: 0.010000, loss: 2.3357, CELoss: 1.7406 KDLoss: 0.5951 
2022-03-11 06:39:07 - train: epoch 0045, iter [00600, 05004], lr: 0.010000, loss: 2.3452, CELoss: 1.7191 KDLoss: 0.6261 
2022-03-11 06:39:41 - train: epoch 0045, iter [00700, 05004], lr: 0.010000, loss: 2.0371, CELoss: 1.4855 KDLoss: 0.5516 
2022-03-11 06:40:14 - train: epoch 0045, iter [00800, 05004], lr: 0.010000, loss: 2.1729, CELoss: 1.5362 KDLoss: 0.6367 
2022-03-11 06:40:48 - train: epoch 0045, iter [00900, 05004], lr: 0.010000, loss: 1.9409, CELoss: 1.4291 KDLoss: 0.5118 
2022-03-11 06:41:21 - train: epoch 0045, iter [01000, 05004], lr: 0.010000, loss: 2.0720, CELoss: 1.4787 KDLoss: 0.5933 
2022-03-11 06:41:55 - train: epoch 0045, iter [01100, 05004], lr: 0.010000, loss: 2.1958, CELoss: 1.5933 KDLoss: 0.6026 
2022-03-11 06:42:27 - train: epoch 0045, iter [01200, 05004], lr: 0.010000, loss: 2.2649, CELoss: 1.6427 KDLoss: 0.6222 
2022-03-11 06:43:01 - train: epoch 0045, iter [01300, 05004], lr: 0.010000, loss: 2.1747, CELoss: 1.6089 KDLoss: 0.5658 
2022-03-11 06:43:35 - train: epoch 0045, iter [01400, 05004], lr: 0.010000, loss: 2.4100, CELoss: 1.8045 KDLoss: 0.6055 
2022-03-11 06:44:09 - train: epoch 0045, iter [01500, 05004], lr: 0.010000, loss: 2.0877, CELoss: 1.5196 KDLoss: 0.5680 
2022-03-11 06:44:42 - train: epoch 0045, iter [01600, 05004], lr: 0.010000, loss: 1.8366, CELoss: 1.3031 KDLoss: 0.5335 
2022-03-11 06:45:16 - train: epoch 0045, iter [01700, 05004], lr: 0.010000, loss: 1.9258, CELoss: 1.3960 KDLoss: 0.5298 
2022-03-11 06:45:49 - train: epoch 0045, iter [01800, 05004], lr: 0.010000, loss: 2.1665, CELoss: 1.5525 KDLoss: 0.6140 
2022-03-11 06:46:22 - train: epoch 0045, iter [01900, 05004], lr: 0.010000, loss: 2.1913, CELoss: 1.6355 KDLoss: 0.5558 
2022-03-11 06:46:56 - train: epoch 0045, iter [02000, 05004], lr: 0.010000, loss: 2.2482, CELoss: 1.6145 KDLoss: 0.6338 
2022-03-11 06:47:29 - train: epoch 0045, iter [02100, 05004], lr: 0.010000, loss: 2.3490, CELoss: 1.6196 KDLoss: 0.7294 
2022-03-11 06:48:03 - train: epoch 0045, iter [02200, 05004], lr: 0.010000, loss: 2.1489, CELoss: 1.5147 KDLoss: 0.6341 
2022-03-11 06:48:36 - train: epoch 0045, iter [02300, 05004], lr: 0.010000, loss: 2.0044, CELoss: 1.4518 KDLoss: 0.5526 
2022-03-11 06:49:09 - train: epoch 0045, iter [02400, 05004], lr: 0.010000, loss: 1.9992, CELoss: 1.4309 KDLoss: 0.5683 
2022-03-11 06:49:44 - train: epoch 0045, iter [02500, 05004], lr: 0.010000, loss: 2.1636, CELoss: 1.6198 KDLoss: 0.5438 
2022-03-11 06:50:17 - train: epoch 0045, iter [02600, 05004], lr: 0.010000, loss: 2.3004, CELoss: 1.6795 KDLoss: 0.6209 
2022-03-11 06:50:52 - train: epoch 0045, iter [02700, 05004], lr: 0.010000, loss: 2.0312, CELoss: 1.4428 KDLoss: 0.5884 
2022-03-11 06:51:24 - train: epoch 0045, iter [02800, 05004], lr: 0.010000, loss: 2.2237, CELoss: 1.5996 KDLoss: 0.6241 
2022-03-11 06:51:58 - train: epoch 0045, iter [02900, 05004], lr: 0.010000, loss: 2.3577, CELoss: 1.7652 KDLoss: 0.5926 
2022-03-11 06:52:31 - train: epoch 0045, iter [03000, 05004], lr: 0.010000, loss: 2.2706, CELoss: 1.6267 KDLoss: 0.6439 
2022-03-11 06:53:05 - train: epoch 0045, iter [03100, 05004], lr: 0.010000, loss: 2.1349, CELoss: 1.5626 KDLoss: 0.5723 
2022-03-11 06:53:38 - train: epoch 0045, iter [03200, 05004], lr: 0.010000, loss: 2.3741, CELoss: 1.7103 KDLoss: 0.6638 
2022-03-11 06:54:11 - train: epoch 0045, iter [03300, 05004], lr: 0.010000, loss: 2.3823, CELoss: 1.7190 KDLoss: 0.6633 
2022-03-11 06:54:44 - train: epoch 0045, iter [03400, 05004], lr: 0.010000, loss: 2.2552, CELoss: 1.6159 KDLoss: 0.6392 
2022-03-11 06:55:18 - train: epoch 0045, iter [03500, 05004], lr: 0.010000, loss: 2.0720, CELoss: 1.5145 KDLoss: 0.5575 
2022-03-11 06:55:51 - train: epoch 0045, iter [03600, 05004], lr: 0.010000, loss: 2.3560, CELoss: 1.7220 KDLoss: 0.6340 
2022-03-11 06:56:25 - train: epoch 0045, iter [03700, 05004], lr: 0.010000, loss: 2.0623, CELoss: 1.4918 KDLoss: 0.5705 
2022-03-11 06:56:58 - train: epoch 0045, iter [03800, 05004], lr: 0.010000, loss: 2.1115, CELoss: 1.4928 KDLoss: 0.6187 
2022-03-11 06:57:32 - train: epoch 0045, iter [03900, 05004], lr: 0.010000, loss: 2.2959, CELoss: 1.6763 KDLoss: 0.6196 
2022-03-11 06:58:04 - train: epoch 0045, iter [04000, 05004], lr: 0.010000, loss: 2.2511, CELoss: 1.6114 KDLoss: 0.6397 
2022-03-11 06:58:37 - train: epoch 0045, iter [04100, 05004], lr: 0.010000, loss: 2.0123, CELoss: 1.4532 KDLoss: 0.5591 
2022-03-11 06:59:11 - train: epoch 0045, iter [04200, 05004], lr: 0.010000, loss: 2.5070, CELoss: 1.8233 KDLoss: 0.6837 
2022-03-11 06:59:44 - train: epoch 0045, iter [04300, 05004], lr: 0.010000, loss: 2.3337, CELoss: 1.6780 KDLoss: 0.6557 
2022-03-11 07:00:17 - train: epoch 0045, iter [04400, 05004], lr: 0.010000, loss: 2.4135, CELoss: 1.7543 KDLoss: 0.6592 
2022-03-11 07:00:51 - train: epoch 0045, iter [04500, 05004], lr: 0.010000, loss: 2.1016, CELoss: 1.5254 KDLoss: 0.5762 
2022-03-11 07:01:24 - train: epoch 0045, iter [04600, 05004], lr: 0.010000, loss: 2.4110, CELoss: 1.7923 KDLoss: 0.6187 
2022-03-11 07:01:58 - train: epoch 0045, iter [04700, 05004], lr: 0.010000, loss: 2.2160, CELoss: 1.6161 KDLoss: 0.5999 
2022-03-11 07:02:30 - train: epoch 0045, iter [04800, 05004], lr: 0.010000, loss: 2.0169, CELoss: 1.4431 KDLoss: 0.5738 
2022-03-11 07:03:04 - train: epoch 0045, iter [04900, 05004], lr: 0.010000, loss: 2.3754, CELoss: 1.7358 KDLoss: 0.6396 
2022-03-11 07:03:36 - train: epoch 0045, iter [05000, 05004], lr: 0.010000, loss: 2.0630, CELoss: 1.4859 KDLoss: 0.5772 
2022-03-11 07:03:37 - train: epoch 045, train_loss: 2.1779
2022-03-11 07:06:06 - eval: epoch: 045, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 66.404%, stu_acc5: 87.476%, stu_test_loss: 1.3726
2022-03-11 07:06:07 - until epoch: 045, tea_best_acc1: 73.950%, stu_best_acc1: 67.182%
2022-03-11 07:06:07 - epoch 046 lr: 0.010000000000000002
2022-03-11 07:06:46 - train: epoch 0046, iter [00100, 05004], lr: 0.010000, loss: 1.8301, CELoss: 1.2833 KDLoss: 0.5468 
2022-03-11 07:07:19 - train: epoch 0046, iter [00200, 05004], lr: 0.010000, loss: 1.9638, CELoss: 1.4330 KDLoss: 0.5308 
2022-03-11 07:07:52 - train: epoch 0046, iter [00300, 05004], lr: 0.010000, loss: 2.2311, CELoss: 1.6445 KDLoss: 0.5866 
2022-03-11 07:08:26 - train: epoch 0046, iter [00400, 05004], lr: 0.010000, loss: 2.0475, CELoss: 1.4111 KDLoss: 0.6364 
2022-03-11 07:08:58 - train: epoch 0046, iter [00500, 05004], lr: 0.010000, loss: 2.1364, CELoss: 1.5355 KDLoss: 0.6009 
2022-03-11 07:09:31 - train: epoch 0046, iter [00600, 05004], lr: 0.010000, loss: 2.0584, CELoss: 1.4909 KDLoss: 0.5675 
2022-03-11 07:10:05 - train: epoch 0046, iter [00700, 05004], lr: 0.010000, loss: 2.0542, CELoss: 1.4562 KDLoss: 0.5980 
2022-03-11 07:10:38 - train: epoch 0046, iter [00800, 05004], lr: 0.010000, loss: 2.3571, CELoss: 1.7193 KDLoss: 0.6378 
2022-03-11 07:11:12 - train: epoch 0046, iter [00900, 05004], lr: 0.010000, loss: 2.0849, CELoss: 1.5128 KDLoss: 0.5722 
2022-03-11 07:11:46 - train: epoch 0046, iter [01000, 05004], lr: 0.010000, loss: 1.7567, CELoss: 1.2737 KDLoss: 0.4830 
2022-03-11 07:12:18 - train: epoch 0046, iter [01100, 05004], lr: 0.010000, loss: 1.9844, CELoss: 1.4216 KDLoss: 0.5627 
2022-03-11 07:12:52 - train: epoch 0046, iter [01200, 05004], lr: 0.010000, loss: 2.0846, CELoss: 1.4977 KDLoss: 0.5870 
2022-03-11 07:13:25 - train: epoch 0046, iter [01300, 05004], lr: 0.010000, loss: 2.3664, CELoss: 1.7115 KDLoss: 0.6549 
2022-03-11 07:13:59 - train: epoch 0046, iter [01400, 05004], lr: 0.010000, loss: 2.3278, CELoss: 1.6652 KDLoss: 0.6626 
2022-03-11 07:14:33 - train: epoch 0046, iter [01500, 05004], lr: 0.010000, loss: 2.0274, CELoss: 1.4243 KDLoss: 0.6031 
2022-03-11 07:15:06 - train: epoch 0046, iter [01600, 05004], lr: 0.010000, loss: 2.4950, CELoss: 1.9004 KDLoss: 0.5946 
2022-03-11 07:15:39 - train: epoch 0046, iter [01700, 05004], lr: 0.010000, loss: 2.2214, CELoss: 1.6016 KDLoss: 0.6198 
2022-03-11 07:16:12 - train: epoch 0046, iter [01800, 05004], lr: 0.010000, loss: 2.2969, CELoss: 1.6709 KDLoss: 0.6260 
2022-03-11 07:16:47 - train: epoch 0046, iter [01900, 05004], lr: 0.010000, loss: 2.1310, CELoss: 1.5863 KDLoss: 0.5447 
2022-03-11 07:17:20 - train: epoch 0046, iter [02000, 05004], lr: 0.010000, loss: 2.0339, CELoss: 1.4616 KDLoss: 0.5723 
2022-03-11 07:17:52 - train: epoch 0046, iter [02100, 05004], lr: 0.010000, loss: 2.6314, CELoss: 1.9215 KDLoss: 0.7099 
2022-03-11 07:18:27 - train: epoch 0046, iter [02200, 05004], lr: 0.010000, loss: 1.9633, CELoss: 1.4061 KDLoss: 0.5571 
2022-03-11 07:19:00 - train: epoch 0046, iter [02300, 05004], lr: 0.010000, loss: 2.4701, CELoss: 1.8210 KDLoss: 0.6491 
2022-03-11 07:19:34 - train: epoch 0046, iter [02400, 05004], lr: 0.010000, loss: 2.3583, CELoss: 1.7393 KDLoss: 0.6190 
2022-03-11 07:20:06 - train: epoch 0046, iter [02500, 05004], lr: 0.010000, loss: 2.1128, CELoss: 1.5086 KDLoss: 0.6043 
2022-03-11 07:20:40 - train: epoch 0046, iter [02600, 05004], lr: 0.010000, loss: 2.4991, CELoss: 1.8728 KDLoss: 0.6263 
2022-03-11 07:21:13 - train: epoch 0046, iter [02700, 05004], lr: 0.010000, loss: 2.0282, CELoss: 1.4428 KDLoss: 0.5854 
2022-03-11 07:21:48 - train: epoch 0046, iter [02800, 05004], lr: 0.010000, loss: 1.9890, CELoss: 1.4404 KDLoss: 0.5486 
2022-03-11 07:22:20 - train: epoch 0046, iter [02900, 05004], lr: 0.010000, loss: 2.3581, CELoss: 1.7636 KDLoss: 0.5945 
2022-03-11 07:22:54 - train: epoch 0046, iter [03000, 05004], lr: 0.010000, loss: 1.9176, CELoss: 1.3977 KDLoss: 0.5200 
2022-03-11 07:23:27 - train: epoch 0046, iter [03100, 05004], lr: 0.010000, loss: 2.1181, CELoss: 1.5677 KDLoss: 0.5504 
2022-03-11 07:24:00 - train: epoch 0046, iter [03200, 05004], lr: 0.010000, loss: 2.1070, CELoss: 1.5468 KDLoss: 0.5603 
2022-03-11 07:24:33 - train: epoch 0046, iter [03300, 05004], lr: 0.010000, loss: 2.3156, CELoss: 1.6750 KDLoss: 0.6406 
2022-03-11 07:25:07 - train: epoch 0046, iter [03400, 05004], lr: 0.010000, loss: 2.1371, CELoss: 1.5864 KDLoss: 0.5507 
2022-03-11 07:25:42 - train: epoch 0046, iter [03500, 05004], lr: 0.010000, loss: 2.5443, CELoss: 1.8169 KDLoss: 0.7274 
2022-03-11 07:26:14 - train: epoch 0046, iter [03600, 05004], lr: 0.010000, loss: 2.0400, CELoss: 1.4913 KDLoss: 0.5487 
2022-03-11 07:26:48 - train: epoch 0046, iter [03700, 05004], lr: 0.010000, loss: 2.0078, CELoss: 1.4274 KDLoss: 0.5804 
2022-03-11 07:27:21 - train: epoch 0046, iter [03800, 05004], lr: 0.010000, loss: 2.1922, CELoss: 1.5664 KDLoss: 0.6258 
2022-03-11 07:27:54 - train: epoch 0046, iter [03900, 05004], lr: 0.010000, loss: 2.1632, CELoss: 1.6095 KDLoss: 0.5537 
2022-03-11 07:28:28 - train: epoch 0046, iter [04000, 05004], lr: 0.010000, loss: 2.0096, CELoss: 1.4861 KDLoss: 0.5236 
2022-03-11 07:29:02 - train: epoch 0046, iter [04100, 05004], lr: 0.010000, loss: 2.3840, CELoss: 1.7587 KDLoss: 0.6253 
2022-03-11 07:29:34 - train: epoch 0046, iter [04200, 05004], lr: 0.010000, loss: 2.0053, CELoss: 1.4377 KDLoss: 0.5676 
2022-03-11 07:30:07 - train: epoch 0046, iter [04300, 05004], lr: 0.010000, loss: 2.2432, CELoss: 1.6212 KDLoss: 0.6220 
2022-03-11 07:30:40 - train: epoch 0046, iter [04400, 05004], lr: 0.010000, loss: 2.4629, CELoss: 1.8248 KDLoss: 0.6381 
2022-03-11 07:31:14 - train: epoch 0046, iter [04500, 05004], lr: 0.010000, loss: 2.1554, CELoss: 1.5670 KDLoss: 0.5884 
2022-03-11 07:31:47 - train: epoch 0046, iter [04600, 05004], lr: 0.010000, loss: 2.0512, CELoss: 1.4753 KDLoss: 0.5760 
2022-03-11 07:32:20 - train: epoch 0046, iter [04700, 05004], lr: 0.010000, loss: 2.1459, CELoss: 1.5271 KDLoss: 0.6188 
2022-03-11 07:32:52 - train: epoch 0046, iter [04800, 05004], lr: 0.010000, loss: 1.8827, CELoss: 1.3297 KDLoss: 0.5530 
2022-03-11 07:33:26 - train: epoch 0046, iter [04900, 05004], lr: 0.010000, loss: 2.2240, CELoss: 1.6872 KDLoss: 0.5369 
2022-03-11 07:33:58 - train: epoch 0046, iter [05000, 05004], lr: 0.010000, loss: 2.1329, CELoss: 1.5340 KDLoss: 0.5988 
2022-03-11 07:33:59 - train: epoch 046, train_loss: 2.1841
2022-03-11 07:36:28 - eval: epoch: 046, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 66.560%, stu_acc5: 87.660%, stu_test_loss: 1.3619
2022-03-11 07:36:29 - until epoch: 046, tea_best_acc1: 73.950%, stu_best_acc1: 67.182%
2022-03-11 07:36:29 - epoch 047 lr: 0.010000000000000002
2022-03-11 07:37:07 - train: epoch 0047, iter [00100, 05004], lr: 0.010000, loss: 2.5178, CELoss: 1.8749 KDLoss: 0.6429 
2022-03-11 07:37:41 - train: epoch 0047, iter [00200, 05004], lr: 0.010000, loss: 2.3512, CELoss: 1.7614 KDLoss: 0.5898 
2022-03-11 07:38:14 - train: epoch 0047, iter [00300, 05004], lr: 0.010000, loss: 2.0299, CELoss: 1.4406 KDLoss: 0.5893 
2022-03-11 07:38:48 - train: epoch 0047, iter [00400, 05004], lr: 0.010000, loss: 1.9159, CELoss: 1.3645 KDLoss: 0.5514 
2022-03-11 07:39:21 - train: epoch 0047, iter [00500, 05004], lr: 0.010000, loss: 1.9356, CELoss: 1.4139 KDLoss: 0.5217 
2022-03-11 07:39:54 - train: epoch 0047, iter [00600, 05004], lr: 0.010000, loss: 2.1102, CELoss: 1.5145 KDLoss: 0.5957 
2022-03-11 07:40:28 - train: epoch 0047, iter [00700, 05004], lr: 0.010000, loss: 2.2756, CELoss: 1.6498 KDLoss: 0.6258 
2022-03-11 07:41:01 - train: epoch 0047, iter [00800, 05004], lr: 0.010000, loss: 2.2092, CELoss: 1.5483 KDLoss: 0.6609 
2022-03-11 07:41:33 - train: epoch 0047, iter [00900, 05004], lr: 0.010000, loss: 2.3524, CELoss: 1.7646 KDLoss: 0.5878 
2022-03-11 07:42:08 - train: epoch 0047, iter [01000, 05004], lr: 0.010000, loss: 2.1601, CELoss: 1.5567 KDLoss: 0.6034 
2022-03-11 07:42:41 - train: epoch 0047, iter [01100, 05004], lr: 0.010000, loss: 2.3535, CELoss: 1.6998 KDLoss: 0.6538 
2022-03-11 07:43:14 - train: epoch 0047, iter [01200, 05004], lr: 0.010000, loss: 2.2127, CELoss: 1.5769 KDLoss: 0.6358 
2022-03-11 07:43:48 - train: epoch 0047, iter [01300, 05004], lr: 0.010000, loss: 2.0900, CELoss: 1.4976 KDLoss: 0.5924 
2022-03-11 07:44:22 - train: epoch 0047, iter [01400, 05004], lr: 0.010000, loss: 2.1528, CELoss: 1.5698 KDLoss: 0.5831 
2022-03-11 07:44:55 - train: epoch 0047, iter [01500, 05004], lr: 0.010000, loss: 2.1917, CELoss: 1.6253 KDLoss: 0.5663 
2022-03-11 07:45:30 - train: epoch 0047, iter [01600, 05004], lr: 0.010000, loss: 2.1045, CELoss: 1.5340 KDLoss: 0.5705 
2022-03-11 07:46:02 - train: epoch 0047, iter [01700, 05004], lr: 0.010000, loss: 2.0447, CELoss: 1.4347 KDLoss: 0.6099 
2022-03-11 07:46:35 - train: epoch 0047, iter [01800, 05004], lr: 0.010000, loss: 2.3824, CELoss: 1.7104 KDLoss: 0.6720 
2022-03-11 07:47:10 - train: epoch 0047, iter [01900, 05004], lr: 0.010000, loss: 2.1505, CELoss: 1.5399 KDLoss: 0.6106 
2022-03-11 07:47:43 - train: epoch 0047, iter [02000, 05004], lr: 0.010000, loss: 2.3720, CELoss: 1.7648 KDLoss: 0.6072 
2022-03-11 07:48:16 - train: epoch 0047, iter [02100, 05004], lr: 0.010000, loss: 2.1971, CELoss: 1.6069 KDLoss: 0.5902 
2022-03-11 07:48:49 - train: epoch 0047, iter [02200, 05004], lr: 0.010000, loss: 2.3058, CELoss: 1.7285 KDLoss: 0.5772 
2022-03-11 07:49:23 - train: epoch 0047, iter [02300, 05004], lr: 0.010000, loss: 2.1830, CELoss: 1.5963 KDLoss: 0.5867 
2022-03-11 07:49:57 - train: epoch 0047, iter [02400, 05004], lr: 0.010000, loss: 2.2915, CELoss: 1.6539 KDLoss: 0.6376 
2022-03-11 07:50:30 - train: epoch 0047, iter [02500, 05004], lr: 0.010000, loss: 2.1291, CELoss: 1.5562 KDLoss: 0.5730 
2022-03-11 07:51:04 - train: epoch 0047, iter [02600, 05004], lr: 0.010000, loss: 2.6426, CELoss: 1.9925 KDLoss: 0.6501 
2022-03-11 07:51:37 - train: epoch 0047, iter [02700, 05004], lr: 0.010000, loss: 2.0296, CELoss: 1.4082 KDLoss: 0.6214 
2022-03-11 07:52:11 - train: epoch 0047, iter [02800, 05004], lr: 0.010000, loss: 2.0928, CELoss: 1.5771 KDLoss: 0.5157 
2022-03-11 07:52:44 - train: epoch 0047, iter [02900, 05004], lr: 0.010000, loss: 2.0731, CELoss: 1.5098 KDLoss: 0.5633 
2022-03-11 07:53:18 - train: epoch 0047, iter [03000, 05004], lr: 0.010000, loss: 2.2855, CELoss: 1.6645 KDLoss: 0.6209 
2022-03-11 07:53:51 - train: epoch 0047, iter [03100, 05004], lr: 0.010000, loss: 2.0240, CELoss: 1.4575 KDLoss: 0.5665 
2022-03-11 07:54:26 - train: epoch 0047, iter [03200, 05004], lr: 0.010000, loss: 2.3302, CELoss: 1.7162 KDLoss: 0.6141 
2022-03-11 07:54:59 - train: epoch 0047, iter [03300, 05004], lr: 0.010000, loss: 2.2510, CELoss: 1.6188 KDLoss: 0.6322 
2022-03-11 07:55:32 - train: epoch 0047, iter [03400, 05004], lr: 0.010000, loss: 2.1128, CELoss: 1.5314 KDLoss: 0.5815 
2022-03-11 07:56:06 - train: epoch 0047, iter [03500, 05004], lr: 0.010000, loss: 2.3209, CELoss: 1.7115 KDLoss: 0.6094 
2022-03-11 07:56:39 - train: epoch 0047, iter [03600, 05004], lr: 0.010000, loss: 2.1898, CELoss: 1.5850 KDLoss: 0.6049 
2022-03-11 07:57:13 - train: epoch 0047, iter [03700, 05004], lr: 0.010000, loss: 2.0985, CELoss: 1.4764 KDLoss: 0.6221 
2022-03-11 07:57:46 - train: epoch 0047, iter [03800, 05004], lr: 0.010000, loss: 1.8755, CELoss: 1.3419 KDLoss: 0.5337 
2022-03-11 07:58:19 - train: epoch 0047, iter [03900, 05004], lr: 0.010000, loss: 2.3440, CELoss: 1.6818 KDLoss: 0.6622 
2022-03-11 07:58:53 - train: epoch 0047, iter [04000, 05004], lr: 0.010000, loss: 2.2981, CELoss: 1.6625 KDLoss: 0.6355 
2022-03-11 07:59:27 - train: epoch 0047, iter [04100, 05004], lr: 0.010000, loss: 2.2102, CELoss: 1.6465 KDLoss: 0.5637 
2022-03-11 08:00:00 - train: epoch 0047, iter [04200, 05004], lr: 0.010000, loss: 2.2690, CELoss: 1.6042 KDLoss: 0.6648 
2022-03-11 08:00:35 - train: epoch 0047, iter [04300, 05004], lr: 0.010000, loss: 2.0248, CELoss: 1.4211 KDLoss: 0.6037 
2022-03-11 08:01:09 - train: epoch 0047, iter [04400, 05004], lr: 0.010000, loss: 2.2456, CELoss: 1.6393 KDLoss: 0.6062 
2022-03-11 08:01:42 - train: epoch 0047, iter [04500, 05004], lr: 0.010000, loss: 2.2741, CELoss: 1.6067 KDLoss: 0.6674 
2022-03-11 08:02:15 - train: epoch 0047, iter [04600, 05004], lr: 0.010000, loss: 2.2185, CELoss: 1.5574 KDLoss: 0.6611 
2022-03-11 08:02:48 - train: epoch 0047, iter [04700, 05004], lr: 0.010000, loss: 2.3754, CELoss: 1.7155 KDLoss: 0.6599 
2022-03-11 08:03:21 - train: epoch 0047, iter [04800, 05004], lr: 0.010000, loss: 1.9122, CELoss: 1.3361 KDLoss: 0.5760 
2022-03-11 08:03:55 - train: epoch 0047, iter [04900, 05004], lr: 0.010000, loss: 2.2598, CELoss: 1.6129 KDLoss: 0.6469 
2022-03-11 08:04:27 - train: epoch 0047, iter [05000, 05004], lr: 0.010000, loss: 2.1627, CELoss: 1.5913 KDLoss: 0.5714 
2022-03-11 08:04:28 - train: epoch 047, train_loss: 2.1803
2022-03-11 08:06:57 - eval: epoch: 047, tea_acc1: 73.950%, tea_acc5: 91.758%, tea_test_loss: 1.0379, stu_acc1: 66.852%, stu_acc5: 87.556%, stu_test_loss: 1.3639
2022-03-11 08:06:57 - until epoch: 047, tea_best_acc1: 73.950%, stu_best_acc1: 67.182%
2022-03-11 08:06:57 - epoch 048 lr: 0.010000000000000002
2022-03-11 08:07:36 - train: epoch 0048, iter [00100, 05004], lr: 0.010000, loss: 2.2158, CELoss: 1.6806 KDLoss: 0.5352 
2022-03-11 08:08:10 - train: epoch 0048, iter [00200, 05004], lr: 0.010000, loss: 2.6807, CELoss: 1.9766 KDLoss: 0.7041 
2022-03-11 08:08:44 - train: epoch 0048, iter [00300, 05004], lr: 0.010000, loss: 2.2135, CELoss: 1.5992 KDLoss: 0.6143 
2022-03-11 08:09:17 - train: epoch 0048, iter [00400, 05004], lr: 0.010000, loss: 2.1401, CELoss: 1.5072 KDLoss: 0.6329 
2022-03-11 08:09:50 - train: epoch 0048, iter [00500, 05004], lr: 0.010000, loss: 2.1992, CELoss: 1.6002 KDLoss: 0.5990 
2022-03-11 08:10:23 - train: epoch 0048, iter [00600, 05004], lr: 0.010000, loss: 2.1807, CELoss: 1.5807 KDLoss: 0.6000 
2022-03-11 08:10:57 - train: epoch 0048, iter [00700, 05004], lr: 0.010000, loss: 2.0081, CELoss: 1.4541 KDLoss: 0.5540 
2022-03-11 08:11:31 - train: epoch 0048, iter [00800, 05004], lr: 0.010000, loss: 2.2386, CELoss: 1.6847 KDLoss: 0.5539 
2022-03-11 08:12:04 - train: epoch 0048, iter [00900, 05004], lr: 0.010000, loss: 2.2704, CELoss: 1.6478 KDLoss: 0.6226 
2022-03-11 08:12:38 - train: epoch 0048, iter [01000, 05004], lr: 0.010000, loss: 2.2090, CELoss: 1.6152 KDLoss: 0.5938 
2022-03-11 08:13:12 - train: epoch 0048, iter [01100, 05004], lr: 0.010000, loss: 2.4974, CELoss: 1.8298 KDLoss: 0.6676 
2022-03-11 08:13:44 - train: epoch 0048, iter [01200, 05004], lr: 0.010000, loss: 2.4375, CELoss: 1.8282 KDLoss: 0.6093 
2022-03-11 08:14:18 - train: epoch 0048, iter [01300, 05004], lr: 0.010000, loss: 2.3148, CELoss: 1.6920 KDLoss: 0.6229 
2022-03-11 08:14:51 - train: epoch 0048, iter [01400, 05004], lr: 0.010000, loss: 2.1141, CELoss: 1.5062 KDLoss: 0.6079 
2022-03-11 08:15:24 - train: epoch 0048, iter [01500, 05004], lr: 0.010000, loss: 2.3539, CELoss: 1.7233 KDLoss: 0.6306 
2022-03-11 08:15:58 - train: epoch 0048, iter [01600, 05004], lr: 0.010000, loss: 2.2817, CELoss: 1.6428 KDLoss: 0.6389 
