2022-10-01 23:01:00 - network: resnet50_dino_pretrain_model
2022-10-01 23:01:00 - head_planes: 65536
2022-10-01 23:01:00 - global_crop_nums: 2
2022-10-01 23:01:00 - local_crop_nums: 8
2022-10-01 23:01:00 - teacher_model: ResNetDINOPretrainModel(
  (conv1): ConvBnActBlock(
    (layer): Sequential(
      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv2): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv3): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
      (relu): ReLU(inplace=True)
      (downsample_conv): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
    )
    (1): Bottleneck(
      (conv1): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv2): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv3): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv2): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv3): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv2): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv3): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
      (relu): ReLU(inplace=True)
      (downsample_conv): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
    )
    (1): Bottleneck(
      (conv1): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv2): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv3): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv2): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv3): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv2): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv3): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv2): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv3): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
      (relu): ReLU(inplace=True)
      (downsample_conv): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
    )
    (1): Bottleneck(
      (conv1): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv2): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv3): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv2): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv3): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv2): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv3): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv2): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv3): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv2): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv3): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv2): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv3): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
      (relu): ReLU(inplace=True)
      (downsample_conv): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
    )
    (1): Bottleneck(
      (conv1): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv2): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv3): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv2): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv3): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (head): DINOPretrainModelHead(
    (layers): Sequential(
      (0): Linear(in_features=2048, out_features=2048, bias=True)
      (1): GELU()
      (2): Linear(in_features=2048, out_features=2048, bias=True)
      (3): GELU()
      (4): Linear(in_features=2048, out_features=256, bias=True)
    )
    (last_layer): Linear(in_features=256, out_features=65536, bias=False)
  )
)
2022-10-01 23:01:00 - student_model: ResNetDINOPretrainModel(
  (conv1): ConvBnActBlock(
    (layer): Sequential(
      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv2): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv3): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
      (relu): ReLU(inplace=True)
      (downsample_conv): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
    )
    (1): Bottleneck(
      (conv1): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv2): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv3): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv2): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv3): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv2): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv3): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
      (relu): ReLU(inplace=True)
      (downsample_conv): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
    )
    (1): Bottleneck(
      (conv1): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv2): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv3): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv2): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv3): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv2): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv3): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv2): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv3): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
      (relu): ReLU(inplace=True)
      (downsample_conv): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
    )
    (1): Bottleneck(
      (conv1): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv2): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv3): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv2): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv3): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv2): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv3): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv2): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv3): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv2): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv3): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv2): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv3): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
      (relu): ReLU(inplace=True)
      (downsample_conv): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
    )
    (1): Bottleneck(
      (conv1): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv2): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv3): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv2): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (conv3): ConvBnActBlock(
        (layer): Sequential(
          (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
      )
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (head): DINOPretrainModelHead(
    (layers): Sequential(
      (0): Linear(in_features=2048, out_features=2048, bias=True)
      (1): GELU()
      (2): Linear(in_features=2048, out_features=2048, bias=True)
      (3): GELU()
      (4): Linear(in_features=2048, out_features=256, bias=True)
    )
    (last_layer): Linear(in_features=256, out_features=65536, bias=False)
  )
)
2022-10-01 23:01:00 - trained_teacher_model_path: 
2022-10-01 23:01:00 - trained_student_model_path: 
2022-10-01 23:01:00 - train_criterion: DINOLoss()
2022-10-01 23:01:00 - train_dataset: <simpleAICV.classification.datasets.ilsvrc2012dataset.ILSVRC2012Dataset object at 0x7f2d5c097670>
2022-10-01 23:01:00 - train_collater: <simpleAICV.contrastive_learning.common.DINOPretrainCollater object at 0x7f2d5c0976a0>
2022-10-01 23:01:00 - seed: 0
2022-10-01 23:01:00 - batch_size: 128
2022-10-01 23:01:00 - num_workers: 20
2022-10-01 23:01:00 - optimizer: ('SGD', {'lr': 0.015, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0001, 'no_weight_decay_layer_name_list': []})
2022-10-01 23:01:00 - lr_scheduler: ('Cosine', {'warm_up_epochs': 10, 'final_value': 1e-06})
2022-10-01 23:01:00 - weight_decay_scheduler: ('Cosine', {'warm_up_epochs': 0, 'final_value': 0.0001})
2022-10-01 23:01:00 - momentum_teacher_scheduler: ('Cosine', {'warm_up_epochs': 0, 'momentum': 0.996, 'final_value': 1})
2022-10-01 23:01:00 - epochs: 100
2022-10-01 23:01:00 - print_interval: 100
2022-10-01 23:01:00 - sync_bn: False
2022-10-01 23:01:00 - apex: True
2022-10-01 23:01:00 - gpus_type: NVIDIA RTX A5000
2022-10-01 23:01:00 - gpus_num: 2
2022-10-01 23:01:00 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f2d38978330>
2022-10-01 23:01:00 - --------student no weight decay layers--------
2022-10-01 23:01:00 - student model. name: conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer1.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer1.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer1.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer1.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer1.0.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer1.0.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer1.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer1.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer1.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer1.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer1.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer1.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer1.1.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer1.1.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer1.2.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer1.2.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer1.2.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer1.2.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer1.2.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer1.2.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.0.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.0.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.1.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.1.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.2.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.2.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.2.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.2.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.2.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.2.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.3.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.3.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.3.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.3.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.3.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.3.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.0.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.0.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.1.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.1.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.2.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.2.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.2.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.2.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.2.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.2.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.3.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.3.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.3.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.3.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.3.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.3.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.4.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.4.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.4.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.4.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.4.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.4.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.5.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.5.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.5.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.5.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.5.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.5.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer4.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer4.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer4.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer4.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer4.0.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer4.0.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer4.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer4.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer4.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer4.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer4.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer4.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer4.1.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer4.1.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer4.2.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer4.2.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer4.2.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer4.2.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer4.2.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer4.2.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: head.layers.0.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: head.layers.2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: head.layers.4.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-01 23:01:00 - --------student weight decay layers--------
2022-10-01 23:01:00 - student model. name: conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer1.0.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer1.0.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer1.0.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer1.0.downsample_conv.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer1.1.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer1.1.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer1.1.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer1.2.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer1.2.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer1.2.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.0.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.0.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.0.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.0.downsample_conv.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.1.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.1.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.1.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.2.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.2.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.2.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.3.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.3.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer2.3.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.0.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.0.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.0.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.0.downsample_conv.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.1.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.1.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.1.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.2.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.2.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.2.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.3.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.3.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.3.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.4.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.4.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.4.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.5.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.5.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer3.5.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer4.0.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer4.0.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer4.0.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer4.0.downsample_conv.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer4.1.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer4.1.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer4.1.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer4.2.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer4.2.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: layer4.2.conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: head.layers.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: head.layers.2.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: head.layers.4.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:00 - student model. name: head.last_layer.weight_v, weight_decay: 0.0001, lr_scale: not setting!
2022-10-01 23:01:01 - ------------teacher-parameters------------
2022-10-01 23:01:01 - teacher model. name: module.conv1.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.conv1.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.conv1.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.0.conv1.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.0.conv1.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.0.conv1.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.0.conv2.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.0.conv2.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.0.conv2.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.0.conv3.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.0.conv3.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.0.conv3.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.0.downsample_conv.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.0.downsample_conv.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.0.downsample_conv.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.1.conv1.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.1.conv1.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.1.conv1.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.1.conv2.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.1.conv2.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.1.conv2.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.1.conv3.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.1.conv3.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.1.conv3.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.2.conv1.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.2.conv1.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.2.conv1.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.2.conv2.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.2.conv2.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.2.conv2.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.2.conv3.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.2.conv3.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.2.conv3.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.0.conv1.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.0.conv1.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.0.conv1.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.0.conv2.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.0.conv2.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.0.conv2.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.0.conv3.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.0.conv3.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.0.conv3.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.0.downsample_conv.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.0.downsample_conv.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.0.downsample_conv.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.1.conv1.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.1.conv1.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.1.conv1.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.1.conv2.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.1.conv2.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.1.conv2.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.1.conv3.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.1.conv3.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.1.conv3.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.2.conv1.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.2.conv1.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.2.conv1.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.2.conv2.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.2.conv2.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.2.conv2.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.2.conv3.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.2.conv3.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.2.conv3.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.3.conv1.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.3.conv1.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.3.conv1.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.3.conv2.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.3.conv2.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.3.conv2.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.3.conv3.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.3.conv3.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.3.conv3.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.0.conv1.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.0.conv1.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.0.conv1.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.0.conv2.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.0.conv2.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.0.conv2.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.0.conv3.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.0.conv3.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.0.conv3.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.0.downsample_conv.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.0.downsample_conv.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.0.downsample_conv.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.1.conv1.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.1.conv1.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.1.conv1.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.1.conv2.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.1.conv2.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.1.conv2.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.1.conv3.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.1.conv3.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.1.conv3.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.2.conv1.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.2.conv1.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.2.conv1.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.2.conv2.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.2.conv2.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.2.conv2.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.2.conv3.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.2.conv3.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.2.conv3.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.3.conv1.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.3.conv1.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.3.conv1.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.3.conv2.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.3.conv2.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.3.conv2.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.3.conv3.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.3.conv3.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.3.conv3.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.4.conv1.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.4.conv1.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.4.conv1.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.4.conv2.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.4.conv2.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.4.conv2.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.4.conv3.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.4.conv3.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.4.conv3.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.5.conv1.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.5.conv1.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.5.conv1.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.5.conv2.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.5.conv2.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.5.conv2.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.5.conv3.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.5.conv3.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.5.conv3.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.0.conv1.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.0.conv1.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.0.conv1.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.0.conv2.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.0.conv2.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.0.conv2.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.0.conv3.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.0.conv3.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.0.conv3.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.0.downsample_conv.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.0.downsample_conv.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.0.downsample_conv.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.1.conv1.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.1.conv1.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.1.conv1.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.1.conv2.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.1.conv2.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.1.conv2.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.1.conv3.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.1.conv3.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.1.conv3.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.2.conv1.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.2.conv1.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.2.conv1.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.2.conv2.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.2.conv2.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.2.conv2.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.2.conv3.layer.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.2.conv3.layer.1.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.2.conv3.layer.1.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.head.layers.0.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.head.layers.0.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.head.layers.2.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.head.layers.2.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.head.layers.4.weight, grad: False
2022-10-01 23:01:01 - teacher model. name: module.head.layers.4.bias, grad: False
2022-10-01 23:01:01 - teacher model. name: module.head.last_layer.weight_g, grad: False
2022-10-01 23:01:01 - teacher model. name: module.head.last_layer.weight_v, grad: False
2022-10-01 23:01:01 - ------------teacher-buffers------------
2022-10-01 23:01:01 - teacher model. name: module.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.0.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.0.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.0.conv2.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.0.conv2.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.0.conv3.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.0.conv3.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.0.conv3.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.0.downsample_conv.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.0.downsample_conv.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.1.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.1.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.1.conv2.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.1.conv2.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.1.conv3.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.1.conv3.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.1.conv3.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.2.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.2.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.2.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.2.conv2.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.2.conv2.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.2.conv2.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.2.conv3.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.2.conv3.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer1.2.conv3.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.0.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.0.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.0.conv2.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.0.conv2.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.0.conv3.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.0.conv3.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.0.conv3.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.0.downsample_conv.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.0.downsample_conv.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.1.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.1.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.1.conv2.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.1.conv2.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.1.conv3.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.1.conv3.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.1.conv3.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.2.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.2.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.2.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.2.conv2.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.2.conv2.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.2.conv2.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.2.conv3.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.2.conv3.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.2.conv3.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.3.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.3.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.3.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.3.conv2.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.3.conv2.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.3.conv2.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.3.conv3.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.3.conv3.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer2.3.conv3.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.0.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.0.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.0.conv2.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.0.conv2.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.0.conv3.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.0.conv3.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.0.conv3.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.0.downsample_conv.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.0.downsample_conv.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.1.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.1.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.1.conv2.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.1.conv2.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.1.conv3.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.1.conv3.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.1.conv3.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.2.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.2.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.2.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.2.conv2.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.2.conv2.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.2.conv2.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.2.conv3.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.2.conv3.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.2.conv3.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.3.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.3.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.3.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.3.conv2.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.3.conv2.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.3.conv2.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.3.conv3.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.3.conv3.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.3.conv3.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.4.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.4.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.4.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.4.conv2.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.4.conv2.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.4.conv2.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.4.conv3.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.4.conv3.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.4.conv3.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.5.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.5.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.5.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.5.conv2.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.5.conv2.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.5.conv2.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.5.conv3.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.5.conv3.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer3.5.conv3.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.0.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.0.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.0.conv2.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.0.conv2.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.0.conv3.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.0.conv3.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.0.conv3.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.0.downsample_conv.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.0.downsample_conv.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.1.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.1.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.1.conv2.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.1.conv2.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.1.conv3.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.1.conv3.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.1.conv3.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.2.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.2.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.2.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.2.conv2.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.2.conv2.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.2.conv2.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.2.conv3.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.2.conv3.layer.1.running_var, grad: False
2022-10-01 23:01:01 - teacher model. name: module.layer4.2.conv3.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - ------------student-parameters------------
2022-10-01 23:01:01 - student model. name: module.conv1.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.conv1.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.conv1.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer1.0.conv1.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer1.0.conv1.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer1.0.conv1.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer1.0.conv2.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer1.0.conv2.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer1.0.conv2.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer1.0.conv3.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer1.0.conv3.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer1.0.conv3.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer1.0.downsample_conv.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer1.0.downsample_conv.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer1.0.downsample_conv.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer1.1.conv1.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer1.1.conv1.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer1.1.conv1.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer1.1.conv2.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer1.1.conv2.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer1.1.conv2.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer1.1.conv3.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer1.1.conv3.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer1.1.conv3.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer1.2.conv1.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer1.2.conv1.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer1.2.conv1.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer1.2.conv2.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer1.2.conv2.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer1.2.conv2.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer1.2.conv3.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer1.2.conv3.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer1.2.conv3.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.0.conv1.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.0.conv1.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.0.conv1.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.0.conv2.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.0.conv2.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.0.conv2.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.0.conv3.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.0.conv3.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.0.conv3.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.0.downsample_conv.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.0.downsample_conv.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.0.downsample_conv.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.1.conv1.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.1.conv1.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.1.conv1.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.1.conv2.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.1.conv2.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.1.conv2.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.1.conv3.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.1.conv3.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.1.conv3.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.2.conv1.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.2.conv1.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.2.conv1.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.2.conv2.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.2.conv2.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.2.conv2.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.2.conv3.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.2.conv3.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.2.conv3.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.3.conv1.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.3.conv1.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.3.conv1.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.3.conv2.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.3.conv2.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.3.conv2.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.3.conv3.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.3.conv3.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer2.3.conv3.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.0.conv1.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.0.conv1.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.0.conv1.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.0.conv2.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.0.conv2.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.0.conv2.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.0.conv3.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.0.conv3.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.0.conv3.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.0.downsample_conv.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.0.downsample_conv.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.0.downsample_conv.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.1.conv1.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.1.conv1.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.1.conv1.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.1.conv2.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.1.conv2.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.1.conv2.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.1.conv3.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.1.conv3.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.1.conv3.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.2.conv1.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.2.conv1.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.2.conv1.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.2.conv2.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.2.conv2.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.2.conv2.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.2.conv3.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.2.conv3.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.2.conv3.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.3.conv1.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.3.conv1.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.3.conv1.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.3.conv2.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.3.conv2.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.3.conv2.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.3.conv3.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.3.conv3.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.3.conv3.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.4.conv1.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.4.conv1.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.4.conv1.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.4.conv2.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.4.conv2.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.4.conv2.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.4.conv3.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.4.conv3.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.4.conv3.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.5.conv1.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.5.conv1.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.5.conv1.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.5.conv2.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.5.conv2.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.5.conv2.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.5.conv3.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.5.conv3.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer3.5.conv3.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer4.0.conv1.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer4.0.conv1.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer4.0.conv1.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer4.0.conv2.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer4.0.conv2.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer4.0.conv2.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer4.0.conv3.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer4.0.conv3.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer4.0.conv3.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer4.0.downsample_conv.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer4.0.downsample_conv.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer4.0.downsample_conv.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer4.1.conv1.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer4.1.conv1.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer4.1.conv1.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer4.1.conv2.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer4.1.conv2.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer4.1.conv2.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer4.1.conv3.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer4.1.conv3.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer4.1.conv3.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer4.2.conv1.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer4.2.conv1.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer4.2.conv1.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer4.2.conv2.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer4.2.conv2.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer4.2.conv2.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.layer4.2.conv3.layer.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer4.2.conv3.layer.1.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.layer4.2.conv3.layer.1.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.head.layers.0.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.head.layers.0.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.head.layers.2.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.head.layers.2.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.head.layers.4.weight, grad: True
2022-10-01 23:01:01 - student model. name: module.head.layers.4.bias, grad: True
2022-10-01 23:01:01 - student model. name: module.head.last_layer.weight_g, grad: False
2022-10-01 23:01:01 - student model. name: module.head.last_layer.weight_v, grad: True
2022-10-01 23:01:01 - ------------student-buffers------------
2022-10-01 23:01:01 - student model. name: module.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer1.0.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer1.0.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer1.0.conv2.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer1.0.conv2.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer1.0.conv3.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer1.0.conv3.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer1.0.conv3.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer1.0.downsample_conv.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer1.0.downsample_conv.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer1.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer1.1.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer1.1.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer1.1.conv2.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer1.1.conv2.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer1.1.conv3.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer1.1.conv3.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer1.1.conv3.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer1.2.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer1.2.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer1.2.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer1.2.conv2.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer1.2.conv2.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer1.2.conv2.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer1.2.conv3.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer1.2.conv3.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer1.2.conv3.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.0.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.0.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.0.conv2.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.0.conv2.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.0.conv3.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.0.conv3.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.0.conv3.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.0.downsample_conv.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.0.downsample_conv.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.1.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.1.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.1.conv2.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.1.conv2.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.1.conv3.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.1.conv3.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.1.conv3.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.2.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.2.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.2.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.2.conv2.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.2.conv2.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.2.conv2.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.2.conv3.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.2.conv3.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.2.conv3.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.3.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.3.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.3.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.3.conv2.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.3.conv2.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.3.conv2.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.3.conv3.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.3.conv3.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer2.3.conv3.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.0.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.0.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.0.conv2.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.0.conv2.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.0.conv3.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.0.conv3.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.0.conv3.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.0.downsample_conv.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.0.downsample_conv.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.1.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.1.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.1.conv2.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.1.conv2.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.1.conv3.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.1.conv3.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.1.conv3.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.2.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.2.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.2.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.2.conv2.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.2.conv2.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.2.conv2.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.2.conv3.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.2.conv3.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.2.conv3.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.3.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.3.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.3.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.3.conv2.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.3.conv2.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.3.conv2.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.3.conv3.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.3.conv3.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.3.conv3.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.4.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.4.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.4.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.4.conv2.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.4.conv2.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.4.conv2.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.4.conv3.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.4.conv3.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.4.conv3.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.5.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.5.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.5.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.5.conv2.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.5.conv2.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.5.conv2.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.5.conv3.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.5.conv3.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer3.5.conv3.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer4.0.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer4.0.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer4.0.conv2.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer4.0.conv2.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer4.0.conv3.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer4.0.conv3.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer4.0.conv3.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer4.0.downsample_conv.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer4.0.downsample_conv.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer4.1.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer4.1.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer4.1.conv2.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer4.1.conv2.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer4.1.conv3.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer4.1.conv3.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer4.1.conv3.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer4.2.conv1.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer4.2.conv1.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer4.2.conv1.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer4.2.conv2.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer4.2.conv2.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer4.2.conv2.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - student model. name: module.layer4.2.conv3.layer.1.running_mean, grad: False
2022-10-01 23:01:01 - student model. name: module.layer4.2.conv3.layer.1.running_var, grad: False
2022-10-01 23:01:01 - student model. name: module.layer4.2.conv3.layer.1.num_batches_tracked, grad: False
2022-10-01 23:01:01 - epoch 001 lr: 0.015000
2022-10-01 23:01:55 - train: epoch 0001, iter [00100, 10009], lr: 0.001515, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 11.2455
2022-10-01 23:02:43 - train: epoch 0001, iter [00200, 10009], lr: 0.001530, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 11.2397
2022-10-01 23:03:30 - train: epoch 0001, iter [00300, 10009], lr: 0.001545, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 11.2405
2022-10-01 23:04:17 - train: epoch 0001, iter [00400, 10009], lr: 0.001560, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 11.2386
2022-10-01 23:05:05 - train: epoch 0001, iter [00500, 10009], lr: 0.001575, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 11.2210
2022-10-01 23:05:52 - train: epoch 0001, iter [00600, 10009], lr: 0.001590, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 11.2205
2022-10-01 23:06:39 - train: epoch 0001, iter [00700, 10009], lr: 0.001605, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 11.1763
2022-10-01 23:07:27 - train: epoch 0001, iter [00800, 10009], lr: 0.001620, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 11.1411
2022-10-01 23:08:14 - train: epoch 0001, iter [00900, 10009], lr: 0.001635, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 11.0894
2022-10-01 23:09:01 - train: epoch 0001, iter [01000, 10009], lr: 0.001650, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 11.0647
2022-10-01 23:09:49 - train: epoch 0001, iter [01100, 10009], lr: 0.001665, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 11.0318
2022-10-01 23:10:36 - train: epoch 0001, iter [01200, 10009], lr: 0.001680, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 11.0359
2022-10-01 23:11:23 - train: epoch 0001, iter [01300, 10009], lr: 0.001695, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 11.0743
2022-10-01 23:12:11 - train: epoch 0001, iter [01400, 10009], lr: 0.001710, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 11.0286
2022-10-01 23:12:58 - train: epoch 0001, iter [01500, 10009], lr: 0.001725, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.9748
2022-10-01 23:13:46 - train: epoch 0001, iter [01600, 10009], lr: 0.001740, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.9681
2022-10-01 23:14:33 - train: epoch 0001, iter [01700, 10009], lr: 0.001755, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.8771
2022-10-01 23:15:20 - train: epoch 0001, iter [01800, 10009], lr: 0.001770, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.9325
2022-10-01 23:16:08 - train: epoch 0001, iter [01900, 10009], lr: 0.001785, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.8651
2022-10-01 23:16:55 - train: epoch 0001, iter [02000, 10009], lr: 0.001800, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.8378
2022-10-01 23:17:42 - train: epoch 0001, iter [02100, 10009], lr: 0.001815, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.8675
2022-10-01 23:18:30 - train: epoch 0001, iter [02200, 10009], lr: 0.001830, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.8724
2022-10-01 23:19:17 - train: epoch 0001, iter [02300, 10009], lr: 0.001845, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.8495
2022-10-01 23:20:05 - train: epoch 0001, iter [02400, 10009], lr: 0.001860, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.8540
2022-10-01 23:20:52 - train: epoch 0001, iter [02500, 10009], lr: 0.001875, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.8325
2022-10-01 23:21:39 - train: epoch 0001, iter [02600, 10009], lr: 0.001890, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.7976
2022-10-01 23:22:27 - train: epoch 0001, iter [02700, 10009], lr: 0.001905, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.7880
2022-10-01 23:23:14 - train: epoch 0001, iter [02800, 10009], lr: 0.001920, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.7909
2022-10-01 23:24:01 - train: epoch 0001, iter [02900, 10009], lr: 0.001935, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.7178
2022-10-01 23:24:49 - train: epoch 0001, iter [03000, 10009], lr: 0.001950, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.7365
2022-10-01 23:25:36 - train: epoch 0001, iter [03100, 10009], lr: 0.001965, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.7772
2022-10-01 23:26:23 - train: epoch 0001, iter [03200, 10009], lr: 0.001980, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.7843
2022-10-01 23:27:11 - train: epoch 0001, iter [03300, 10009], lr: 0.001995, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.7676
2022-10-01 23:27:58 - train: epoch 0001, iter [03400, 10009], lr: 0.002010, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.7494
2022-10-01 23:28:46 - train: epoch 0001, iter [03500, 10009], lr: 0.002025, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.7302
2022-10-01 23:29:33 - train: epoch 0001, iter [03600, 10009], lr: 0.002040, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.7679
2022-10-01 23:30:21 - train: epoch 0001, iter [03700, 10009], lr: 0.002055, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.7822
2022-10-01 23:31:08 - train: epoch 0001, iter [03800, 10009], lr: 0.002069, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.7351
2022-10-01 23:31:55 - train: epoch 0001, iter [03900, 10009], lr: 0.002084, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.7841
2022-10-01 23:32:43 - train: epoch 0001, iter [04000, 10009], lr: 0.002099, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.8154
2022-10-01 23:33:30 - train: epoch 0001, iter [04100, 10009], lr: 0.002114, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.7748
2022-10-01 23:34:18 - train: epoch 0001, iter [04200, 10009], lr: 0.002129, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.7517
2022-10-01 23:35:05 - train: epoch 0001, iter [04300, 10009], lr: 0.002144, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.7399
2022-10-01 23:35:53 - train: epoch 0001, iter [04400, 10009], lr: 0.002159, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.7039
2022-10-01 23:36:40 - train: epoch 0001, iter [04500, 10009], lr: 0.002174, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.7426
2022-10-01 23:37:27 - train: epoch 0001, iter [04600, 10009], lr: 0.002189, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.7896
2022-10-01 23:38:15 - train: epoch 0001, iter [04700, 10009], lr: 0.002204, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.7817
2022-10-01 23:39:02 - train: epoch 0001, iter [04800, 10009], lr: 0.002219, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.7802
2022-10-01 23:39:50 - train: epoch 0001, iter [04900, 10009], lr: 0.002234, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.7273
2022-10-01 23:40:37 - train: epoch 0001, iter [05000, 10009], lr: 0.002249, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.7314
2022-10-01 23:41:24 - train: epoch 0001, iter [05100, 10009], lr: 0.002264, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.7563
2022-10-01 23:42:12 - train: epoch 0001, iter [05200, 10009], lr: 0.002279, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.7696
2022-10-01 23:42:59 - train: epoch 0001, iter [05300, 10009], lr: 0.002294, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.7425
2022-10-01 23:43:47 - train: epoch 0001, iter [05400, 10009], lr: 0.002309, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.6116
2022-10-01 23:44:34 - train: epoch 0001, iter [05500, 10009], lr: 0.002324, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.6515
2022-10-01 23:45:21 - train: epoch 0001, iter [05600, 10009], lr: 0.002339, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.6649
2022-10-01 23:46:09 - train: epoch 0001, iter [05700, 10009], lr: 0.002354, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.6489
2022-10-01 23:46:56 - train: epoch 0001, iter [05800, 10009], lr: 0.002369, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.6837
2022-10-01 23:47:43 - train: epoch 0001, iter [05900, 10009], lr: 0.002384, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.6461
2022-10-01 23:48:31 - train: epoch 0001, iter [06000, 10009], lr: 0.002399, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.6531
2022-10-01 23:49:18 - train: epoch 0001, iter [06100, 10009], lr: 0.002414, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.5865
2022-10-01 23:50:06 - train: epoch 0001, iter [06200, 10009], lr: 0.002429, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.3524
2022-10-01 23:50:53 - train: epoch 0001, iter [06300, 10009], lr: 0.002444, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.3497
2022-10-01 23:51:40 - train: epoch 0001, iter [06400, 10009], lr: 0.002459, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.4668
2022-10-01 23:52:28 - train: epoch 0001, iter [06500, 10009], lr: 0.002474, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.4584
2022-10-01 23:53:15 - train: epoch 0001, iter [06600, 10009], lr: 0.002489, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.5146
2022-10-01 23:54:02 - train: epoch 0001, iter [06700, 10009], lr: 0.002504, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.5382
2022-10-01 23:54:50 - train: epoch 0001, iter [06800, 10009], lr: 0.002519, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.6223
2022-10-01 23:55:37 - train: epoch 0001, iter [06900, 10009], lr: 0.002534, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.5985
2022-10-01 23:56:24 - train: epoch 0001, iter [07000, 10009], lr: 0.002549, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.6277
2022-10-01 23:57:12 - train: epoch 0001, iter [07100, 10009], lr: 0.002564, weight_decay: 0.000100, momentum_teacher: 0.996000, loss: 10.5478
2022-10-01 23:57:59 - train: epoch 0001, iter [07200, 10009], lr: 0.002579, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.4815
2022-10-01 23:58:46 - train: epoch 0001, iter [07300, 10009], lr: 0.002594, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.5188
2022-10-01 23:59:33 - train: epoch 0001, iter [07400, 10009], lr: 0.002609, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.5058
2022-10-02 00:00:21 - train: epoch 0001, iter [07500, 10009], lr: 0.002624, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.4405
2022-10-02 00:01:08 - train: epoch 0001, iter [07600, 10009], lr: 0.002639, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.4388
2022-10-02 00:01:56 - train: epoch 0001, iter [07700, 10009], lr: 0.002654, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.4296
2022-10-02 00:02:43 - train: epoch 0001, iter [07800, 10009], lr: 0.002669, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.4245
2022-10-02 00:03:30 - train: epoch 0001, iter [07900, 10009], lr: 0.002684, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.2931
2022-10-02 00:04:18 - train: epoch 0001, iter [08000, 10009], lr: 0.002699, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.3391
2022-10-02 00:05:05 - train: epoch 0001, iter [08100, 10009], lr: 0.002714, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.3671
2022-10-02 00:05:52 - train: epoch 0001, iter [08200, 10009], lr: 0.002729, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.4184
2022-10-02 00:06:40 - train: epoch 0001, iter [08300, 10009], lr: 0.002744, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.4116
2022-10-02 00:07:27 - train: epoch 0001, iter [08400, 10009], lr: 0.002759, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.3696
2022-10-02 00:08:14 - train: epoch 0001, iter [08500, 10009], lr: 0.002774, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.4122
2022-10-02 00:09:02 - train: epoch 0001, iter [08600, 10009], lr: 0.002789, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.2643
2022-10-02 00:09:49 - train: epoch 0001, iter [08700, 10009], lr: 0.002804, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.3413
2022-10-02 00:10:37 - train: epoch 0001, iter [08800, 10009], lr: 0.002819, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.3238
2022-10-02 00:11:24 - train: epoch 0001, iter [08900, 10009], lr: 0.002834, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.3504
2022-10-02 00:12:12 - train: epoch 0001, iter [09000, 10009], lr: 0.002849, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.3032
2022-10-02 00:12:59 - train: epoch 0001, iter [09100, 10009], lr: 0.002864, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.3895
2022-10-02 00:13:47 - train: epoch 0001, iter [09200, 10009], lr: 0.002879, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.3708
2022-10-02 00:14:34 - train: epoch 0001, iter [09300, 10009], lr: 0.002894, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.4474
2022-10-02 00:15:22 - train: epoch 0001, iter [09400, 10009], lr: 0.002909, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.3623
2022-10-02 00:16:09 - train: epoch 0001, iter [09500, 10009], lr: 0.002924, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.3241
2022-10-02 00:16:57 - train: epoch 0001, iter [09600, 10009], lr: 0.002939, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.3364
2022-10-02 00:17:44 - train: epoch 0001, iter [09700, 10009], lr: 0.002954, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.3947
2022-10-02 00:18:32 - train: epoch 0001, iter [09800, 10009], lr: 0.002969, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.2904
2022-10-02 00:19:19 - train: epoch 0001, iter [09900, 10009], lr: 0.002984, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.3200
2022-10-02 00:20:07 - train: epoch 0001, iter [10000, 10009], lr: 0.002999, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.1894
2022-10-02 00:20:12 - train: epoch 001, train_loss: 10.6880
2022-10-02 00:20:13 - until epoch: 001, best_loss: 10.6880
2022-10-02 00:20:13 - epoch 002 lr: 0.003000
2022-10-02 00:21:05 - train: epoch 0002, iter [00100, 10009], lr: 0.003015, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.2115
2022-10-02 00:21:53 - train: epoch 0002, iter [00200, 10009], lr: 0.003030, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.2616
2022-10-02 00:22:40 - train: epoch 0002, iter [00300, 10009], lr: 0.003045, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.3271
2022-10-02 00:23:27 - train: epoch 0002, iter [00400, 10009], lr: 0.003060, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.2105
2022-10-02 00:24:15 - train: epoch 0002, iter [00500, 10009], lr: 0.003075, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.3123
2022-10-02 00:25:02 - train: epoch 0002, iter [00600, 10009], lr: 0.003090, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.1885
2022-10-02 00:25:49 - train: epoch 0002, iter [00700, 10009], lr: 0.003105, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 9.8893
2022-10-02 00:26:36 - train: epoch 0002, iter [00800, 10009], lr: 0.003120, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 9.9071
2022-10-02 00:27:24 - train: epoch 0002, iter [00900, 10009], lr: 0.003135, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 9.8351
2022-10-02 00:28:11 - train: epoch 0002, iter [01000, 10009], lr: 0.003150, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 9.9190
2022-10-02 00:28:58 - train: epoch 0002, iter [01100, 10009], lr: 0.003165, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 9.8919
2022-10-02 00:29:46 - train: epoch 0002, iter [01200, 10009], lr: 0.003180, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.0224
2022-10-02 00:30:33 - train: epoch 0002, iter [01300, 10009], lr: 0.003195, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 9.7894
2022-10-02 00:31:21 - train: epoch 0002, iter [01400, 10009], lr: 0.003210, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 9.6534
2022-10-02 00:32:08 - train: epoch 0002, iter [01500, 10009], lr: 0.003225, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 9.8365
2022-10-02 00:32:56 - train: epoch 0002, iter [01600, 10009], lr: 0.003240, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 9.8500
2022-10-02 00:33:43 - train: epoch 0002, iter [01700, 10009], lr: 0.003255, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 9.8347
2022-10-02 00:34:30 - train: epoch 0002, iter [01800, 10009], lr: 0.003270, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 10.0089
2022-10-02 00:35:18 - train: epoch 0002, iter [01900, 10009], lr: 0.003285, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 9.9563
2022-10-02 00:36:05 - train: epoch 0002, iter [02000, 10009], lr: 0.003300, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 9.7919
2022-10-02 00:36:52 - train: epoch 0002, iter [02100, 10009], lr: 0.003315, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 9.7190
2022-10-02 00:37:40 - train: epoch 0002, iter [02200, 10009], lr: 0.003330, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 9.5713
2022-10-02 00:38:27 - train: epoch 0002, iter [02300, 10009], lr: 0.003345, weight_decay: 0.000100, momentum_teacher: 0.996001, loss: 9.6039
2022-10-02 00:39:15 - train: epoch 0002, iter [02400, 10009], lr: 0.003360, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.7676
2022-10-02 00:40:02 - train: epoch 0002, iter [02500, 10009], lr: 0.003375, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.7444
2022-10-02 00:40:50 - train: epoch 0002, iter [02600, 10009], lr: 0.003390, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.6661
2022-10-02 00:41:37 - train: epoch 0002, iter [02700, 10009], lr: 0.003405, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.4564
2022-10-02 00:42:24 - train: epoch 0002, iter [02800, 10009], lr: 0.003420, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.4896
2022-10-02 00:43:12 - train: epoch 0002, iter [02900, 10009], lr: 0.003435, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.4276
2022-10-02 00:43:59 - train: epoch 0002, iter [03000, 10009], lr: 0.003450, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.6006
2022-10-02 00:44:46 - train: epoch 0002, iter [03100, 10009], lr: 0.003465, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.5850
2022-10-02 00:45:34 - train: epoch 0002, iter [03200, 10009], lr: 0.003480, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.7593
2022-10-02 00:46:21 - train: epoch 0002, iter [03300, 10009], lr: 0.003495, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.6687
2022-10-02 00:47:08 - train: epoch 0002, iter [03400, 10009], lr: 0.003510, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.6072
2022-10-02 00:47:56 - train: epoch 0002, iter [03500, 10009], lr: 0.003525, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.5616
2022-10-02 00:48:43 - train: epoch 0002, iter [03600, 10009], lr: 0.003540, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.3727
2022-10-02 00:49:31 - train: epoch 0002, iter [03700, 10009], lr: 0.003555, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.1360
2022-10-02 00:50:18 - train: epoch 0002, iter [03800, 10009], lr: 0.003569, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.1624
2022-10-02 00:51:05 - train: epoch 0002, iter [03900, 10009], lr: 0.003584, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.5836
2022-10-02 00:51:53 - train: epoch 0002, iter [04000, 10009], lr: 0.003599, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.4008
2022-10-02 00:52:40 - train: epoch 0002, iter [04100, 10009], lr: 0.003614, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.3536
2022-10-02 00:53:27 - train: epoch 0002, iter [04200, 10009], lr: 0.003629, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.4295
2022-10-02 00:54:15 - train: epoch 0002, iter [04300, 10009], lr: 0.003644, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.2046
2022-10-02 00:55:02 - train: epoch 0002, iter [04400, 10009], lr: 0.003659, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.1367
2022-10-02 00:55:50 - train: epoch 0002, iter [04500, 10009], lr: 0.003674, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.1069
2022-10-02 00:56:37 - train: epoch 0002, iter [04600, 10009], lr: 0.003689, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.0044
2022-10-02 00:57:24 - train: epoch 0002, iter [04700, 10009], lr: 0.003704, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 8.9263
2022-10-02 00:58:12 - train: epoch 0002, iter [04800, 10009], lr: 0.003719, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.0571
2022-10-02 00:58:59 - train: epoch 0002, iter [04900, 10009], lr: 0.003734, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.0903
2022-10-02 00:59:46 - train: epoch 0002, iter [05000, 10009], lr: 0.003749, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.3119
2022-10-02 01:00:34 - train: epoch 0002, iter [05100, 10009], lr: 0.003764, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.4152
2022-10-02 01:01:21 - train: epoch 0002, iter [05200, 10009], lr: 0.003779, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.2365
2022-10-02 01:02:08 - train: epoch 0002, iter [05300, 10009], lr: 0.003794, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.1233
2022-10-02 01:02:56 - train: epoch 0002, iter [05400, 10009], lr: 0.003809, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.2050
2022-10-02 01:03:43 - train: epoch 0002, iter [05500, 10009], lr: 0.003824, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.1809
2022-10-02 01:04:30 - train: epoch 0002, iter [05600, 10009], lr: 0.003839, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.3639
2022-10-02 01:05:18 - train: epoch 0002, iter [05700, 10009], lr: 0.003854, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.4138
2022-10-02 01:06:05 - train: epoch 0002, iter [05800, 10009], lr: 0.003869, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.1400
2022-10-02 01:06:52 - train: epoch 0002, iter [05900, 10009], lr: 0.003884, weight_decay: 0.000100, momentum_teacher: 0.996002, loss: 9.0077
2022-10-02 01:07:40 - train: epoch 0002, iter [06000, 10009], lr: 0.003899, weight_decay: 0.000100, momentum_teacher: 0.996003, loss: 9.2166
2022-10-02 01:08:27 - train: epoch 0002, iter [06100, 10009], lr: 0.003914, weight_decay: 0.000100, momentum_teacher: 0.996003, loss: 9.2167
2022-10-02 01:09:15 - train: epoch 0002, iter [06200, 10009], lr: 0.003929, weight_decay: 0.000100, momentum_teacher: 0.996003, loss: 8.8512
2022-10-02 01:10:02 - train: epoch 0002, iter [06300, 10009], lr: 0.003944, weight_decay: 0.000100, momentum_teacher: 0.996003, loss: 8.8888
2022-10-02 01:10:50 - train: epoch 0002, iter [06400, 10009], lr: 0.003959, weight_decay: 0.000100, momentum_teacher: 0.996003, loss: 9.0546
2022-10-02 01:11:37 - train: epoch 0002, iter [06500, 10009], lr: 0.003974, weight_decay: 0.000100, momentum_teacher: 0.996003, loss: 9.1825
2022-10-02 01:12:24 - train: epoch 0002, iter [06600, 10009], lr: 0.003989, weight_decay: 0.000100, momentum_teacher: 0.996003, loss: 8.8055
2022-10-02 01:13:12 - train: epoch 0002, iter [06700, 10009], lr: 0.004004, weight_decay: 0.000100, momentum_teacher: 0.996003, loss: 9.0364
2022-10-02 01:13:59 - train: epoch 0002, iter [06800, 10009], lr: 0.004019, weight_decay: 0.000100, momentum_teacher: 0.996003, loss: 8.9349
2022-10-02 01:14:47 - train: epoch 0002, iter [06900, 10009], lr: 0.004034, weight_decay: 0.000100, momentum_teacher: 0.996003, loss: 9.1097
2022-10-02 01:15:34 - train: epoch 0002, iter [07000, 10009], lr: 0.004049, weight_decay: 0.000100, momentum_teacher: 0.996003, loss: 9.0755
2022-10-02 01:16:22 - train: epoch 0002, iter [07100, 10009], lr: 0.004064, weight_decay: 0.000100, momentum_teacher: 0.996003, loss: 9.2904
2022-10-02 01:17:09 - train: epoch 0002, iter [07200, 10009], lr: 0.004079, weight_decay: 0.000100, momentum_teacher: 0.996003, loss: 9.1021
2022-10-02 01:17:56 - train: epoch 0002, iter [07300, 10009], lr: 0.004094, weight_decay: 0.000100, momentum_teacher: 0.996003, loss: 8.8133
2022-10-02 01:18:44 - train: epoch 0002, iter [07400, 10009], lr: 0.004109, weight_decay: 0.000100, momentum_teacher: 0.996003, loss: 8.9738
2022-10-02 01:19:31 - train: epoch 0002, iter [07500, 10009], lr: 0.004124, weight_decay: 0.000100, momentum_teacher: 0.996003, loss: 9.0319
2022-10-02 01:20:19 - train: epoch 0002, iter [07600, 10009], lr: 0.004139, weight_decay: 0.000100, momentum_teacher: 0.996003, loss: 8.8055
2022-10-02 01:21:06 - train: epoch 0002, iter [07700, 10009], lr: 0.004154, weight_decay: 0.000100, momentum_teacher: 0.996003, loss: 8.8118
2022-10-02 01:21:54 - train: epoch 0002, iter [07800, 10009], lr: 0.004169, weight_decay: 0.000100, momentum_teacher: 0.996003, loss: 9.0605
2022-10-02 01:22:41 - train: epoch 0002, iter [07900, 10009], lr: 0.004184, weight_decay: 0.000100, momentum_teacher: 0.996003, loss: 9.1606
2022-10-02 01:23:29 - train: epoch 0002, iter [08000, 10009], lr: 0.004199, weight_decay: 0.000100, momentum_teacher: 0.996003, loss: 9.0486
2022-10-02 01:24:16 - train: epoch 0002, iter [08100, 10009], lr: 0.004214, weight_decay: 0.000100, momentum_teacher: 0.996003, loss: 8.9321
2022-10-02 01:25:04 - train: epoch 0002, iter [08200, 10009], lr: 0.004229, weight_decay: 0.000100, momentum_teacher: 0.996003, loss: 8.9494
2022-10-02 01:25:51 - train: epoch 0002, iter [08300, 10009], lr: 0.004244, weight_decay: 0.000100, momentum_teacher: 0.996003, loss: 9.0150
2022-10-02 01:26:39 - train: epoch 0002, iter [08400, 10009], lr: 0.004259, weight_decay: 0.000100, momentum_teacher: 0.996003, loss: 8.9570
2022-10-02 01:27:26 - train: epoch 0002, iter [08500, 10009], lr: 0.004274, weight_decay: 0.000100, momentum_teacher: 0.996003, loss: 8.8864
2022-10-02 01:28:13 - train: epoch 0002, iter [08600, 10009], lr: 0.004289, weight_decay: 0.000100, momentum_teacher: 0.996003, loss: 9.0440
2022-10-02 01:29:01 - train: epoch 0002, iter [08700, 10009], lr: 0.004304, weight_decay: 0.000100, momentum_teacher: 0.996003, loss: 8.7919
2022-10-02 01:29:48 - train: epoch 0002, iter [08800, 10009], lr: 0.004319, weight_decay: 0.000100, momentum_teacher: 0.996003, loss: 8.7544
2022-10-02 01:30:36 - train: epoch 0002, iter [08900, 10009], lr: 0.004334, weight_decay: 0.000100, momentum_teacher: 0.996004, loss: 8.9597
2022-10-02 01:31:23 - train: epoch 0002, iter [09000, 10009], lr: 0.004349, weight_decay: 0.000100, momentum_teacher: 0.996004, loss: 8.9230
2022-10-02 01:32:11 - train: epoch 0002, iter [09100, 10009], lr: 0.004364, weight_decay: 0.000100, momentum_teacher: 0.996004, loss: 8.7858
2022-10-02 01:32:58 - train: epoch 0002, iter [09200, 10009], lr: 0.004379, weight_decay: 0.000100, momentum_teacher: 0.996004, loss: 9.0402
2022-10-02 01:33:46 - train: epoch 0002, iter [09300, 10009], lr: 0.004394, weight_decay: 0.000100, momentum_teacher: 0.996004, loss: 8.9179
2022-10-02 01:34:33 - train: epoch 0002, iter [09400, 10009], lr: 0.004409, weight_decay: 0.000100, momentum_teacher: 0.996004, loss: 8.9258
2022-10-02 01:35:21 - train: epoch 0002, iter [09500, 10009], lr: 0.004424, weight_decay: 0.000100, momentum_teacher: 0.996004, loss: 8.9606
2022-10-02 01:36:08 - train: epoch 0002, iter [09600, 10009], lr: 0.004439, weight_decay: 0.000100, momentum_teacher: 0.996004, loss: 8.9147
2022-10-02 01:36:56 - train: epoch 0002, iter [09700, 10009], lr: 0.004454, weight_decay: 0.000100, momentum_teacher: 0.996004, loss: 9.0125
2022-10-02 01:37:43 - train: epoch 0002, iter [09800, 10009], lr: 0.004469, weight_decay: 0.000100, momentum_teacher: 0.996004, loss: 8.9883
2022-10-02 01:38:30 - train: epoch 0002, iter [09900, 10009], lr: 0.004484, weight_decay: 0.000100, momentum_teacher: 0.996004, loss: 9.0257
2022-10-02 01:39:18 - train: epoch 0002, iter [10000, 10009], lr: 0.004499, weight_decay: 0.000100, momentum_teacher: 0.996004, loss: 8.7367
2022-10-02 01:39:23 - train: epoch 002, train_loss: 9.3416
2022-10-02 01:39:25 - until epoch: 002, best_loss: 9.3416
2022-10-02 01:39:25 - epoch 003 lr: 0.004500
2022-10-02 01:40:17 - train: epoch 0003, iter [00100, 10009], lr: 0.004515, weight_decay: 0.000100, momentum_teacher: 0.996004, loss: 8.9661
2022-10-02 01:41:04 - train: epoch 0003, iter [00200, 10009], lr: 0.004530, weight_decay: 0.000100, momentum_teacher: 0.996004, loss: 8.6816
2022-10-02 01:41:51 - train: epoch 0003, iter [00300, 10009], lr: 0.004545, weight_decay: 0.000100, momentum_teacher: 0.996004, loss: 8.5700
2022-10-02 01:42:39 - train: epoch 0003, iter [00400, 10009], lr: 0.004560, weight_decay: 0.000100, momentum_teacher: 0.996004, loss: 8.7926
2022-10-02 01:43:26 - train: epoch 0003, iter [00500, 10009], lr: 0.004575, weight_decay: 0.000100, momentum_teacher: 0.996004, loss: 9.0450
2022-10-02 01:44:13 - train: epoch 0003, iter [00600, 10009], lr: 0.004590, weight_decay: 0.000100, momentum_teacher: 0.996004, loss: 9.0532
2022-10-02 01:45:01 - train: epoch 0003, iter [00700, 10009], lr: 0.004605, weight_decay: 0.000100, momentum_teacher: 0.996004, loss: 9.0800
2022-10-02 01:45:48 - train: epoch 0003, iter [00800, 10009], lr: 0.004620, weight_decay: 0.000100, momentum_teacher: 0.996004, loss: 8.9955
2022-10-02 01:46:36 - train: epoch 0003, iter [00900, 10009], lr: 0.004635, weight_decay: 0.000100, momentum_teacher: 0.996004, loss: 8.9632
2022-10-02 01:47:23 - train: epoch 0003, iter [01000, 10009], lr: 0.004650, weight_decay: 0.000100, momentum_teacher: 0.996004, loss: 8.9181
2022-10-02 01:48:11 - train: epoch 0003, iter [01100, 10009], lr: 0.004665, weight_decay: 0.000100, momentum_teacher: 0.996004, loss: 8.7538
2022-10-02 01:48:58 - train: epoch 0003, iter [01200, 10009], lr: 0.004680, weight_decay: 0.000100, momentum_teacher: 0.996004, loss: 8.9036
2022-10-02 01:49:45 - train: epoch 0003, iter [01300, 10009], lr: 0.004695, weight_decay: 0.000100, momentum_teacher: 0.996004, loss: 8.9437
2022-10-02 01:50:33 - train: epoch 0003, iter [01400, 10009], lr: 0.004710, weight_decay: 0.000100, momentum_teacher: 0.996005, loss: 8.9875
2022-10-02 01:51:20 - train: epoch 0003, iter [01500, 10009], lr: 0.004725, weight_decay: 0.000100, momentum_teacher: 0.996005, loss: 8.9131
2022-10-02 01:52:07 - train: epoch 0003, iter [01600, 10009], lr: 0.004740, weight_decay: 0.000100, momentum_teacher: 0.996005, loss: 9.1416
2022-10-02 01:52:55 - train: epoch 0003, iter [01700, 10009], lr: 0.004755, weight_decay: 0.000100, momentum_teacher: 0.996005, loss: 8.9640
2022-10-02 01:53:42 - train: epoch 0003, iter [01800, 10009], lr: 0.004770, weight_decay: 0.000100, momentum_teacher: 0.996005, loss: 8.9330
2022-10-02 01:54:29 - train: epoch 0003, iter [01900, 10009], lr: 0.004785, weight_decay: 0.000100, momentum_teacher: 0.996005, loss: 8.8750
2022-10-02 01:55:17 - train: epoch 0003, iter [02000, 10009], lr: 0.004800, weight_decay: 0.000100, momentum_teacher: 0.996005, loss: 8.9185
2022-10-02 01:56:04 - train: epoch 0003, iter [02100, 10009], lr: 0.004815, weight_decay: 0.000100, momentum_teacher: 0.996005, loss: 8.7694
2022-10-02 01:56:51 - train: epoch 0003, iter [02200, 10009], lr: 0.004830, weight_decay: 0.000100, momentum_teacher: 0.996005, loss: 8.7241
2022-10-02 01:57:39 - train: epoch 0003, iter [02300, 10009], lr: 0.004845, weight_decay: 0.000100, momentum_teacher: 0.996005, loss: 8.9454
2022-10-02 01:58:26 - train: epoch 0003, iter [02400, 10009], lr: 0.004860, weight_decay: 0.000100, momentum_teacher: 0.996005, loss: 8.8321
2022-10-02 01:59:13 - train: epoch 0003, iter [02500, 10009], lr: 0.004875, weight_decay: 0.000100, momentum_teacher: 0.996005, loss: 8.9315
2022-10-02 02:00:01 - train: epoch 0003, iter [02600, 10009], lr: 0.004890, weight_decay: 0.000100, momentum_teacher: 0.996005, loss: 8.9801
2022-10-02 02:00:48 - train: epoch 0003, iter [02700, 10009], lr: 0.004905, weight_decay: 0.000100, momentum_teacher: 0.996005, loss: 8.9204
2022-10-02 02:01:36 - train: epoch 0003, iter [02800, 10009], lr: 0.004920, weight_decay: 0.000100, momentum_teacher: 0.996005, loss: 9.0723
2022-10-02 02:02:23 - train: epoch 0003, iter [02900, 10009], lr: 0.004935, weight_decay: 0.000100, momentum_teacher: 0.996005, loss: 8.9571
2022-10-02 02:03:11 - train: epoch 0003, iter [03000, 10009], lr: 0.004950, weight_decay: 0.000100, momentum_teacher: 0.996005, loss: 9.0139
2022-10-02 02:03:58 - train: epoch 0003, iter [03100, 10009], lr: 0.004965, weight_decay: 0.000100, momentum_teacher: 0.996005, loss: 8.6269
2022-10-02 02:04:45 - train: epoch 0003, iter [03200, 10009], lr: 0.004980, weight_decay: 0.000100, momentum_teacher: 0.996005, loss: 8.7280
2022-10-02 02:05:33 - train: epoch 0003, iter [03300, 10009], lr: 0.004995, weight_decay: 0.000100, momentum_teacher: 0.996005, loss: 9.0475
2022-10-02 02:06:20 - train: epoch 0003, iter [03400, 10009], lr: 0.005010, weight_decay: 0.000100, momentum_teacher: 0.996005, loss: 8.8545
2022-10-02 02:07:07 - train: epoch 0003, iter [03500, 10009], lr: 0.005025, weight_decay: 0.000100, momentum_teacher: 0.996005, loss: 9.0558
2022-10-02 02:07:55 - train: epoch 0003, iter [03600, 10009], lr: 0.005040, weight_decay: 0.000100, momentum_teacher: 0.996005, loss: 8.8719
2022-10-02 02:08:42 - train: epoch 0003, iter [03700, 10009], lr: 0.005055, weight_decay: 0.000100, momentum_teacher: 0.996006, loss: 8.8032
2022-10-02 02:09:30 - train: epoch 0003, iter [03800, 10009], lr: 0.005069, weight_decay: 0.000100, momentum_teacher: 0.996006, loss: 8.7931
2022-10-02 02:10:17 - train: epoch 0003, iter [03900, 10009], lr: 0.005084, weight_decay: 0.000100, momentum_teacher: 0.996006, loss: 8.7172
2022-10-02 02:11:05 - train: epoch 0003, iter [04000, 10009], lr: 0.005099, weight_decay: 0.000100, momentum_teacher: 0.996006, loss: 8.8388
2022-10-02 02:11:52 - train: epoch 0003, iter [04100, 10009], lr: 0.005114, weight_decay: 0.000100, momentum_teacher: 0.996006, loss: 8.6987
2022-10-02 02:12:40 - train: epoch 0003, iter [04200, 10009], lr: 0.005129, weight_decay: 0.000100, momentum_teacher: 0.996006, loss: 8.6359
2022-10-02 02:13:27 - train: epoch 0003, iter [04300, 10009], lr: 0.005144, weight_decay: 0.000100, momentum_teacher: 0.996006, loss: 8.8016
2022-10-02 02:14:14 - train: epoch 0003, iter [04400, 10009], lr: 0.005159, weight_decay: 0.000100, momentum_teacher: 0.996006, loss: 9.0523
2022-10-02 02:15:02 - train: epoch 0003, iter [04500, 10009], lr: 0.005174, weight_decay: 0.000100, momentum_teacher: 0.996006, loss: 9.0587
2022-10-02 02:15:49 - train: epoch 0003, iter [04600, 10009], lr: 0.005189, weight_decay: 0.000100, momentum_teacher: 0.996006, loss: 8.6788
2022-10-02 02:16:37 - train: epoch 0003, iter [04700, 10009], lr: 0.005204, weight_decay: 0.000100, momentum_teacher: 0.996006, loss: 8.8635
2022-10-02 02:17:24 - train: epoch 0003, iter [04800, 10009], lr: 0.005219, weight_decay: 0.000100, momentum_teacher: 0.996006, loss: 8.7403
2022-10-02 02:18:11 - train: epoch 0003, iter [04900, 10009], lr: 0.005234, weight_decay: 0.000100, momentum_teacher: 0.996006, loss: 8.6885
2022-10-02 02:18:59 - train: epoch 0003, iter [05000, 10009], lr: 0.005249, weight_decay: 0.000100, momentum_teacher: 0.996006, loss: 8.6594
2022-10-02 02:19:46 - train: epoch 0003, iter [05100, 10009], lr: 0.005264, weight_decay: 0.000100, momentum_teacher: 0.996006, loss: 8.5693
2022-10-02 02:20:34 - train: epoch 0003, iter [05200, 10009], lr: 0.005279, weight_decay: 0.000100, momentum_teacher: 0.996006, loss: 8.8605
2022-10-02 02:21:21 - train: epoch 0003, iter [05300, 10009], lr: 0.005294, weight_decay: 0.000100, momentum_teacher: 0.996006, loss: 8.7724
2022-10-02 02:22:09 - train: epoch 0003, iter [05400, 10009], lr: 0.005309, weight_decay: 0.000100, momentum_teacher: 0.996006, loss: 8.7552
2022-10-02 02:22:56 - train: epoch 0003, iter [05500, 10009], lr: 0.005324, weight_decay: 0.000100, momentum_teacher: 0.996006, loss: 8.7651
2022-10-02 02:23:43 - train: epoch 0003, iter [05600, 10009], lr: 0.005339, weight_decay: 0.000100, momentum_teacher: 0.996006, loss: 8.7008
2022-10-02 02:24:31 - train: epoch 0003, iter [05700, 10009], lr: 0.005354, weight_decay: 0.000100, momentum_teacher: 0.996007, loss: 8.7624
2022-10-02 02:25:18 - train: epoch 0003, iter [05800, 10009], lr: 0.005369, weight_decay: 0.000100, momentum_teacher: 0.996007, loss: 8.6205
2022-10-02 02:26:06 - train: epoch 0003, iter [05900, 10009], lr: 0.005384, weight_decay: 0.000100, momentum_teacher: 0.996007, loss: 8.6774
2022-10-02 02:26:53 - train: epoch 0003, iter [06000, 10009], lr: 0.005399, weight_decay: 0.000100, momentum_teacher: 0.996007, loss: 8.7087
2022-10-02 02:27:40 - train: epoch 0003, iter [06100, 10009], lr: 0.005414, weight_decay: 0.000100, momentum_teacher: 0.996007, loss: 8.7134
2022-10-02 02:28:28 - train: epoch 0003, iter [06200, 10009], lr: 0.005429, weight_decay: 0.000100, momentum_teacher: 0.996007, loss: 8.6468
2022-10-02 02:29:15 - train: epoch 0003, iter [06300, 10009], lr: 0.005444, weight_decay: 0.000100, momentum_teacher: 0.996007, loss: 8.5833
2022-10-02 02:30:02 - train: epoch 0003, iter [06400, 10009], lr: 0.005459, weight_decay: 0.000100, momentum_teacher: 0.996007, loss: 8.6465
2022-10-02 02:30:50 - train: epoch 0003, iter [06500, 10009], lr: 0.005474, weight_decay: 0.000100, momentum_teacher: 0.996007, loss: 8.8225
2022-10-02 02:31:37 - train: epoch 0003, iter [06600, 10009], lr: 0.005489, weight_decay: 0.000100, momentum_teacher: 0.996007, loss: 8.7059
2022-10-02 02:32:25 - train: epoch 0003, iter [06700, 10009], lr: 0.005504, weight_decay: 0.000100, momentum_teacher: 0.996007, loss: 8.7366
2022-10-02 02:33:12 - train: epoch 0003, iter [06800, 10009], lr: 0.005519, weight_decay: 0.000100, momentum_teacher: 0.996007, loss: 8.6999
2022-10-02 02:33:59 - train: epoch 0003, iter [06900, 10009], lr: 0.005534, weight_decay: 0.000100, momentum_teacher: 0.996007, loss: 8.7342
2022-10-02 02:34:47 - train: epoch 0003, iter [07000, 10009], lr: 0.005549, weight_decay: 0.000100, momentum_teacher: 0.996007, loss: 8.7827
2022-10-02 02:35:34 - train: epoch 0003, iter [07100, 10009], lr: 0.005564, weight_decay: 0.000100, momentum_teacher: 0.996007, loss: 8.5065
2022-10-02 02:36:21 - train: epoch 0003, iter [07200, 10009], lr: 0.005579, weight_decay: 0.000100, momentum_teacher: 0.996007, loss: 8.5230
2022-10-02 02:37:09 - train: epoch 0003, iter [07300, 10009], lr: 0.005594, weight_decay: 0.000100, momentum_teacher: 0.996007, loss: 8.5247
2022-10-02 02:37:56 - train: epoch 0003, iter [07400, 10009], lr: 0.005609, weight_decay: 0.000100, momentum_teacher: 0.996007, loss: 8.7591
2022-10-02 02:38:43 - train: epoch 0003, iter [07500, 10009], lr: 0.005624, weight_decay: 0.000100, momentum_teacher: 0.996007, loss: 8.6834
2022-10-02 02:39:31 - train: epoch 0003, iter [07600, 10009], lr: 0.005639, weight_decay: 0.000100, momentum_teacher: 0.996008, loss: 8.5334
2022-10-02 02:40:18 - train: epoch 0003, iter [07700, 10009], lr: 0.005654, weight_decay: 0.000100, momentum_teacher: 0.996008, loss: 8.4792
2022-10-02 02:41:06 - train: epoch 0003, iter [07800, 10009], lr: 0.005669, weight_decay: 0.000100, momentum_teacher: 0.996008, loss: 8.2360
2022-10-02 02:41:53 - train: epoch 0003, iter [07900, 10009], lr: 0.005684, weight_decay: 0.000100, momentum_teacher: 0.996008, loss: 8.6296
2022-10-02 02:42:40 - train: epoch 0003, iter [08000, 10009], lr: 0.005699, weight_decay: 0.000100, momentum_teacher: 0.996008, loss: 8.7654
2022-10-02 02:43:28 - train: epoch 0003, iter [08100, 10009], lr: 0.005714, weight_decay: 0.000100, momentum_teacher: 0.996008, loss: 8.4835
2022-10-02 02:44:15 - train: epoch 0003, iter [08200, 10009], lr: 0.005729, weight_decay: 0.000100, momentum_teacher: 0.996008, loss: 8.5865
2022-10-02 02:45:02 - train: epoch 0003, iter [08300, 10009], lr: 0.005744, weight_decay: 0.000100, momentum_teacher: 0.996008, loss: 8.5020
2022-10-02 02:45:50 - train: epoch 0003, iter [08400, 10009], lr: 0.005759, weight_decay: 0.000100, momentum_teacher: 0.996008, loss: 8.4915
2022-10-02 02:46:37 - train: epoch 0003, iter [08500, 10009], lr: 0.005774, weight_decay: 0.000100, momentum_teacher: 0.996008, loss: 8.4120
2022-10-02 02:47:25 - train: epoch 0003, iter [08600, 10009], lr: 0.005789, weight_decay: 0.000100, momentum_teacher: 0.996008, loss: 8.4555
2022-10-02 02:48:12 - train: epoch 0003, iter [08700, 10009], lr: 0.005804, weight_decay: 0.000100, momentum_teacher: 0.996008, loss: 8.7091
2022-10-02 02:49:00 - train: epoch 0003, iter [08800, 10009], lr: 0.005819, weight_decay: 0.000100, momentum_teacher: 0.996008, loss: 8.3017
2022-10-02 02:49:48 - train: epoch 0003, iter [08900, 10009], lr: 0.005834, weight_decay: 0.000100, momentum_teacher: 0.996008, loss: 8.3690
2022-10-02 02:50:35 - train: epoch 0003, iter [09000, 10009], lr: 0.005849, weight_decay: 0.000100, momentum_teacher: 0.996008, loss: 8.5335
2022-10-02 02:51:23 - train: epoch 0003, iter [09100, 10009], lr: 0.005864, weight_decay: 0.000100, momentum_teacher: 0.996008, loss: 8.6129
2022-10-02 02:52:10 - train: epoch 0003, iter [09200, 10009], lr: 0.005879, weight_decay: 0.000100, momentum_teacher: 0.996008, loss: 8.4204
2022-10-02 02:52:58 - train: epoch 0003, iter [09300, 10009], lr: 0.005894, weight_decay: 0.000100, momentum_teacher: 0.996008, loss: 8.5160
2022-10-02 02:53:45 - train: epoch 0003, iter [09400, 10009], lr: 0.005909, weight_decay: 0.000100, momentum_teacher: 0.996009, loss: 8.2694
2022-10-02 02:54:33 - train: epoch 0003, iter [09500, 10009], lr: 0.005924, weight_decay: 0.000100, momentum_teacher: 0.996009, loss: 8.4704
2022-10-02 02:55:20 - train: epoch 0003, iter [09600, 10009], lr: 0.005939, weight_decay: 0.000100, momentum_teacher: 0.996009, loss: 8.3968
2022-10-02 02:56:07 - train: epoch 0003, iter [09700, 10009], lr: 0.005954, weight_decay: 0.000100, momentum_teacher: 0.996009, loss: 8.5158
2022-10-02 02:56:55 - train: epoch 0003, iter [09800, 10009], lr: 0.005969, weight_decay: 0.000100, momentum_teacher: 0.996009, loss: 8.4392
2022-10-02 02:57:42 - train: epoch 0003, iter [09900, 10009], lr: 0.005984, weight_decay: 0.000100, momentum_teacher: 0.996009, loss: 8.3560
2022-10-02 02:58:30 - train: epoch 0003, iter [10000, 10009], lr: 0.005999, weight_decay: 0.000100, momentum_teacher: 0.996009, loss: 8.3754
2022-10-02 02:58:35 - train: epoch 003, train_loss: 8.7306
2022-10-02 02:58:36 - until epoch: 003, best_loss: 8.7306
2022-10-02 02:58:36 - epoch 004 lr: 0.006000
2022-10-02 02:59:28 - train: epoch 0004, iter [00100, 10009], lr: 0.006015, weight_decay: 0.000100, momentum_teacher: 0.996009, loss: 8.3499
2022-10-02 03:00:16 - train: epoch 0004, iter [00200, 10009], lr: 0.006030, weight_decay: 0.000100, momentum_teacher: 0.996009, loss: 8.6956
2022-10-02 03:01:03 - train: epoch 0004, iter [00300, 10009], lr: 0.006045, weight_decay: 0.000100, momentum_teacher: 0.996009, loss: 8.3178
2022-10-02 03:01:50 - train: epoch 0004, iter [00400, 10009], lr: 0.006060, weight_decay: 0.000100, momentum_teacher: 0.996009, loss: 8.4253
2022-10-02 03:02:38 - train: epoch 0004, iter [00500, 10009], lr: 0.006075, weight_decay: 0.000100, momentum_teacher: 0.996009, loss: 8.3958
2022-10-02 03:03:25 - train: epoch 0004, iter [00600, 10009], lr: 0.006090, weight_decay: 0.000100, momentum_teacher: 0.996009, loss: 8.2459
2022-10-02 03:04:13 - train: epoch 0004, iter [00700, 10009], lr: 0.006105, weight_decay: 0.000100, momentum_teacher: 0.996009, loss: 8.2793
2022-10-02 03:05:00 - train: epoch 0004, iter [00800, 10009], lr: 0.006120, weight_decay: 0.000100, momentum_teacher: 0.996009, loss: 8.3468
2022-10-02 03:05:48 - train: epoch 0004, iter [00900, 10009], lr: 0.006135, weight_decay: 0.000100, momentum_teacher: 0.996009, loss: 8.3850
2022-10-02 03:06:36 - train: epoch 0004, iter [01000, 10009], lr: 0.006150, weight_decay: 0.000100, momentum_teacher: 0.996009, loss: 8.1567
2022-10-02 03:07:23 - train: epoch 0004, iter [01100, 10009], lr: 0.006165, weight_decay: 0.000100, momentum_teacher: 0.996010, loss: 8.3162
2022-10-02 03:08:11 - train: epoch 0004, iter [01200, 10009], lr: 0.006180, weight_decay: 0.000100, momentum_teacher: 0.996010, loss: 8.2587
2022-10-02 03:08:58 - train: epoch 0004, iter [01300, 10009], lr: 0.006195, weight_decay: 0.000100, momentum_teacher: 0.996010, loss: 8.1918
2022-10-02 03:09:46 - train: epoch 0004, iter [01400, 10009], lr: 0.006210, weight_decay: 0.000100, momentum_teacher: 0.996010, loss: 8.1615
2022-10-02 03:10:33 - train: epoch 0004, iter [01500, 10009], lr: 0.006225, weight_decay: 0.000100, momentum_teacher: 0.996010, loss: 8.5450
2022-10-02 03:11:21 - train: epoch 0004, iter [01600, 10009], lr: 0.006240, weight_decay: 0.000100, momentum_teacher: 0.996010, loss: 8.1262
2022-10-02 03:12:08 - train: epoch 0004, iter [01700, 10009], lr: 0.006255, weight_decay: 0.000100, momentum_teacher: 0.996010, loss: 8.3788
2022-10-02 03:12:55 - train: epoch 0004, iter [01800, 10009], lr: 0.006270, weight_decay: 0.000100, momentum_teacher: 0.996010, loss: 8.2394
2022-10-02 03:13:43 - train: epoch 0004, iter [01900, 10009], lr: 0.006285, weight_decay: 0.000100, momentum_teacher: 0.996010, loss: 8.0689
2022-10-02 03:14:30 - train: epoch 0004, iter [02000, 10009], lr: 0.006300, weight_decay: 0.000100, momentum_teacher: 0.996010, loss: 8.3943
2022-10-02 03:15:18 - train: epoch 0004, iter [02100, 10009], lr: 0.006315, weight_decay: 0.000100, momentum_teacher: 0.996010, loss: 8.2902
2022-10-02 03:16:05 - train: epoch 0004, iter [02200, 10009], lr: 0.006330, weight_decay: 0.000100, momentum_teacher: 0.996010, loss: 8.2518
2022-10-02 03:16:53 - train: epoch 0004, iter [02300, 10009], lr: 0.006345, weight_decay: 0.000100, momentum_teacher: 0.996010, loss: 8.3449
2022-10-02 03:17:40 - train: epoch 0004, iter [02400, 10009], lr: 0.006360, weight_decay: 0.000100, momentum_teacher: 0.996010, loss: 8.0682
2022-10-02 03:18:28 - train: epoch 0004, iter [02500, 10009], lr: 0.006375, weight_decay: 0.000100, momentum_teacher: 0.996010, loss: 8.1415
2022-10-02 03:19:15 - train: epoch 0004, iter [02600, 10009], lr: 0.006390, weight_decay: 0.000100, momentum_teacher: 0.996010, loss: 8.1984
2022-10-02 03:20:03 - train: epoch 0004, iter [02700, 10009], lr: 0.006405, weight_decay: 0.000100, momentum_teacher: 0.996011, loss: 8.2679
2022-10-02 03:20:50 - train: epoch 0004, iter [02800, 10009], lr: 0.006420, weight_decay: 0.000100, momentum_teacher: 0.996011, loss: 8.3454
2022-10-02 03:21:37 - train: epoch 0004, iter [02900, 10009], lr: 0.006435, weight_decay: 0.000100, momentum_teacher: 0.996011, loss: 8.2940
2022-10-02 03:22:29 - train: epoch 0004, iter [03000, 10009], lr: 0.006450, weight_decay: 0.000100, momentum_teacher: 0.996011, loss: 8.2123
2022-10-02 03:23:18 - train: epoch 0004, iter [03100, 10009], lr: 0.006465, weight_decay: 0.000100, momentum_teacher: 0.996011, loss: 8.3215
2022-10-02 03:24:07 - train: epoch 0004, iter [03200, 10009], lr: 0.006480, weight_decay: 0.000100, momentum_teacher: 0.996011, loss: 8.3655
2022-10-02 03:24:55 - train: epoch 0004, iter [03300, 10009], lr: 0.006495, weight_decay: 0.000100, momentum_teacher: 0.996011, loss: 8.1546
2022-10-02 03:25:42 - train: epoch 0004, iter [03400, 10009], lr: 0.006510, weight_decay: 0.000100, momentum_teacher: 0.996011, loss: 8.2245
2022-10-02 03:26:30 - train: epoch 0004, iter [03500, 10009], lr: 0.006525, weight_decay: 0.000100, momentum_teacher: 0.996011, loss: 8.1384
2022-10-02 03:27:17 - train: epoch 0004, iter [03600, 10009], lr: 0.006540, weight_decay: 0.000100, momentum_teacher: 0.996011, loss: 7.9589
2022-10-02 03:28:05 - train: epoch 0004, iter [03700, 10009], lr: 0.006555, weight_decay: 0.000100, momentum_teacher: 0.996011, loss: 8.0601
2022-10-02 03:28:52 - train: epoch 0004, iter [03800, 10009], lr: 0.006569, weight_decay: 0.000100, momentum_teacher: 0.996011, loss: 8.0847
2022-10-02 03:29:41 - train: epoch 0004, iter [03900, 10009], lr: 0.006584, weight_decay: 0.000100, momentum_teacher: 0.996011, loss: 8.0246
2022-10-02 03:30:29 - train: epoch 0004, iter [04000, 10009], lr: 0.006599, weight_decay: 0.000100, momentum_teacher: 0.996011, loss: 8.0335
2022-10-02 03:31:16 - train: epoch 0004, iter [04100, 10009], lr: 0.006614, weight_decay: 0.000100, momentum_teacher: 0.996011, loss: 8.0099
2022-10-02 03:32:11 - train: epoch 0004, iter [04200, 10009], lr: 0.006629, weight_decay: 0.000100, momentum_teacher: 0.996012, loss: 8.0113
2022-10-02 03:32:58 - train: epoch 0004, iter [04300, 10009], lr: 0.006644, weight_decay: 0.000100, momentum_teacher: 0.996012, loss: 8.0427
2022-10-02 03:33:45 - train: epoch 0004, iter [04400, 10009], lr: 0.006659, weight_decay: 0.000100, momentum_teacher: 0.996012, loss: 8.2060
2022-10-02 03:34:33 - train: epoch 0004, iter [04500, 10009], lr: 0.006674, weight_decay: 0.000100, momentum_teacher: 0.996012, loss: 8.1389
2022-10-02 03:35:20 - train: epoch 0004, iter [04600, 10009], lr: 0.006689, weight_decay: 0.000100, momentum_teacher: 0.996012, loss: 7.9440
2022-10-02 03:36:07 - train: epoch 0004, iter [04700, 10009], lr: 0.006704, weight_decay: 0.000100, momentum_teacher: 0.996012, loss: 8.0302
2022-10-02 03:36:55 - train: epoch 0004, iter [04800, 10009], lr: 0.006719, weight_decay: 0.000100, momentum_teacher: 0.996012, loss: 7.9524
2022-10-02 03:37:42 - train: epoch 0004, iter [04900, 10009], lr: 0.006734, weight_decay: 0.000100, momentum_teacher: 0.996012, loss: 7.9589
2022-10-02 03:38:30 - train: epoch 0004, iter [05000, 10009], lr: 0.006749, weight_decay: 0.000100, momentum_teacher: 0.996012, loss: 8.0593
2022-10-02 03:39:18 - train: epoch 0004, iter [05100, 10009], lr: 0.006764, weight_decay: 0.000100, momentum_teacher: 0.996012, loss: 7.8538
2022-10-02 03:40:05 - train: epoch 0004, iter [05200, 10009], lr: 0.006779, weight_decay: 0.000100, momentum_teacher: 0.996012, loss: 8.1454
2022-10-02 03:40:52 - train: epoch 0004, iter [05300, 10009], lr: 0.006794, weight_decay: 0.000100, momentum_teacher: 0.996012, loss: 8.0288
2022-10-02 03:41:40 - train: epoch 0004, iter [05400, 10009], lr: 0.006809, weight_decay: 0.000100, momentum_teacher: 0.996012, loss: 7.7485
2022-10-02 03:42:28 - train: epoch 0004, iter [05500, 10009], lr: 0.006824, weight_decay: 0.000100, momentum_teacher: 0.996012, loss: 8.0784
2022-10-02 03:43:22 - train: epoch 0004, iter [05600, 10009], lr: 0.006839, weight_decay: 0.000100, momentum_teacher: 0.996012, loss: 7.9484
2022-10-02 03:44:10 - train: epoch 0004, iter [05700, 10009], lr: 0.006854, weight_decay: 0.000100, momentum_teacher: 0.996013, loss: 8.0211
2022-10-02 03:44:57 - train: epoch 0004, iter [05800, 10009], lr: 0.006869, weight_decay: 0.000100, momentum_teacher: 0.996013, loss: 8.1078
2022-10-02 03:45:44 - train: epoch 0004, iter [05900, 10009], lr: 0.006884, weight_decay: 0.000100, momentum_teacher: 0.996013, loss: 7.8493
2022-10-02 03:46:32 - train: epoch 0004, iter [06000, 10009], lr: 0.006899, weight_decay: 0.000100, momentum_teacher: 0.996013, loss: 8.0691
2022-10-02 03:47:19 - train: epoch 0004, iter [06100, 10009], lr: 0.006914, weight_decay: 0.000100, momentum_teacher: 0.996013, loss: 7.8668
2022-10-02 03:48:07 - train: epoch 0004, iter [06200, 10009], lr: 0.006929, weight_decay: 0.000100, momentum_teacher: 0.996013, loss: 7.9473
2022-10-02 03:48:54 - train: epoch 0004, iter [06300, 10009], lr: 0.006944, weight_decay: 0.000100, momentum_teacher: 0.996013, loss: 7.9094
2022-10-02 03:49:42 - train: epoch 0004, iter [06400, 10009], lr: 0.006959, weight_decay: 0.000100, momentum_teacher: 0.996013, loss: 7.9235
2022-10-02 03:50:30 - train: epoch 0004, iter [06500, 10009], lr: 0.006974, weight_decay: 0.000100, momentum_teacher: 0.996013, loss: 7.8779
2022-10-02 03:51:17 - train: epoch 0004, iter [06600, 10009], lr: 0.006989, weight_decay: 0.000100, momentum_teacher: 0.996013, loss: 7.6828
2022-10-02 03:52:05 - train: epoch 0004, iter [06700, 10009], lr: 0.007004, weight_decay: 0.000100, momentum_teacher: 0.996013, loss: 7.6691
2022-10-02 03:52:52 - train: epoch 0004, iter [06800, 10009], lr: 0.007019, weight_decay: 0.000100, momentum_teacher: 0.996013, loss: 7.6970
2022-10-02 03:53:40 - train: epoch 0004, iter [06900, 10009], lr: 0.007034, weight_decay: 0.000100, momentum_teacher: 0.996013, loss: 7.7621
2022-10-02 03:54:34 - train: epoch 0004, iter [07000, 10009], lr: 0.007049, weight_decay: 0.000100, momentum_teacher: 0.996013, loss: 7.9038
2022-10-02 03:55:22 - train: epoch 0004, iter [07100, 10009], lr: 0.007064, weight_decay: 0.000100, momentum_teacher: 0.996014, loss: 7.9619
2022-10-02 03:56:09 - train: epoch 0004, iter [07200, 10009], lr: 0.007079, weight_decay: 0.000100, momentum_teacher: 0.996014, loss: 8.0111
2022-10-02 03:56:57 - train: epoch 0004, iter [07300, 10009], lr: 0.007094, weight_decay: 0.000100, momentum_teacher: 0.996014, loss: 7.9302
2022-10-02 03:57:44 - train: epoch 0004, iter [07400, 10009], lr: 0.007109, weight_decay: 0.000100, momentum_teacher: 0.996014, loss: 7.8417
2022-10-02 03:58:32 - train: epoch 0004, iter [07500, 10009], lr: 0.007124, weight_decay: 0.000100, momentum_teacher: 0.996014, loss: 7.9109
2022-10-02 03:59:19 - train: epoch 0004, iter [07600, 10009], lr: 0.007139, weight_decay: 0.000100, momentum_teacher: 0.996014, loss: 7.9686
2022-10-02 04:00:07 - train: epoch 0004, iter [07700, 10009], lr: 0.007154, weight_decay: 0.000100, momentum_teacher: 0.996014, loss: 7.8909
2022-10-02 04:00:54 - train: epoch 0004, iter [07800, 10009], lr: 0.007169, weight_decay: 0.000100, momentum_teacher: 0.996014, loss: 7.6590
2022-10-02 04:01:42 - train: epoch 0004, iter [07900, 10009], lr: 0.007184, weight_decay: 0.000100, momentum_teacher: 0.996014, loss: 7.9611
2022-10-02 04:02:29 - train: epoch 0004, iter [08000, 10009], lr: 0.007199, weight_decay: 0.000100, momentum_teacher: 0.996014, loss: 7.8089
2022-10-02 04:03:29 - train: epoch 0004, iter [08100, 10009], lr: 0.007214, weight_decay: 0.000100, momentum_teacher: 0.996014, loss: 7.9595
2022-10-02 04:04:17 - train: epoch 0004, iter [08200, 10009], lr: 0.007229, weight_decay: 0.000100, momentum_teacher: 0.996014, loss: 7.8066
2022-10-02 04:05:04 - train: epoch 0004, iter [08300, 10009], lr: 0.007244, weight_decay: 0.000100, momentum_teacher: 0.996014, loss: 7.9480
2022-10-02 04:05:52 - train: epoch 0004, iter [08400, 10009], lr: 0.007259, weight_decay: 0.000100, momentum_teacher: 0.996015, loss: 7.7309
2022-10-02 04:06:40 - train: epoch 0004, iter [08500, 10009], lr: 0.007274, weight_decay: 0.000100, momentum_teacher: 0.996015, loss: 7.7245
2022-10-02 04:07:27 - train: epoch 0004, iter [08600, 10009], lr: 0.007289, weight_decay: 0.000100, momentum_teacher: 0.996015, loss: 7.7547
2022-10-02 04:08:15 - train: epoch 0004, iter [08700, 10009], lr: 0.007304, weight_decay: 0.000100, momentum_teacher: 0.996015, loss: 7.6359
2022-10-02 04:09:02 - train: epoch 0004, iter [08800, 10009], lr: 0.007319, weight_decay: 0.000100, momentum_teacher: 0.996015, loss: 7.8177
2022-10-02 04:09:50 - train: epoch 0004, iter [08900, 10009], lr: 0.007334, weight_decay: 0.000100, momentum_teacher: 0.996015, loss: 7.6957
2022-10-02 04:10:37 - train: epoch 0004, iter [09000, 10009], lr: 0.007349, weight_decay: 0.000100, momentum_teacher: 0.996015, loss: 7.8395
2022-10-02 04:11:25 - train: epoch 0004, iter [09100, 10009], lr: 0.007364, weight_decay: 0.000100, momentum_teacher: 0.996015, loss: 7.7832
2022-10-02 04:12:12 - train: epoch 0004, iter [09200, 10009], lr: 0.007379, weight_decay: 0.000100, momentum_teacher: 0.996015, loss: 7.7504
2022-10-02 04:12:59 - train: epoch 0004, iter [09300, 10009], lr: 0.007394, weight_decay: 0.000100, momentum_teacher: 0.996015, loss: 7.7720
2022-10-02 04:13:47 - train: epoch 0004, iter [09400, 10009], lr: 0.007409, weight_decay: 0.000100, momentum_teacher: 0.996015, loss: 7.7563
2022-10-02 04:14:34 - train: epoch 0004, iter [09500, 10009], lr: 0.007424, weight_decay: 0.000100, momentum_teacher: 0.996015, loss: 7.7149
2022-10-02 04:15:22 - train: epoch 0004, iter [09600, 10009], lr: 0.007439, weight_decay: 0.000100, momentum_teacher: 0.996015, loss: 7.7015
2022-10-02 04:16:09 - train: epoch 0004, iter [09700, 10009], lr: 0.007454, weight_decay: 0.000100, momentum_teacher: 0.996016, loss: 7.6925
2022-10-02 04:16:57 - train: epoch 0004, iter [09800, 10009], lr: 0.007469, weight_decay: 0.000100, momentum_teacher: 0.996016, loss: 7.8242
2022-10-02 04:17:44 - train: epoch 0004, iter [09900, 10009], lr: 0.007484, weight_decay: 0.000100, momentum_teacher: 0.996016, loss: 7.6172
2022-10-02 04:18:31 - train: epoch 0004, iter [10000, 10009], lr: 0.007499, weight_decay: 0.000100, momentum_teacher: 0.996016, loss: 7.7220
2022-10-02 04:18:37 - train: epoch 004, train_loss: 8.0293
2022-10-02 04:18:38 - until epoch: 004, best_loss: 8.0293
2022-10-02 04:18:38 - epoch 005 lr: 0.007500
2022-10-02 04:19:30 - train: epoch 0005, iter [00100, 10009], lr: 0.007515, weight_decay: 0.000100, momentum_teacher: 0.996016, loss: 7.6731
2022-10-02 04:20:18 - train: epoch 0005, iter [00200, 10009], lr: 0.007530, weight_decay: 0.000100, momentum_teacher: 0.996016, loss: 7.7127
2022-10-02 04:21:05 - train: epoch 0005, iter [00300, 10009], lr: 0.007545, weight_decay: 0.000100, momentum_teacher: 0.996016, loss: 7.6907
2022-10-02 04:21:52 - train: epoch 0005, iter [00400, 10009], lr: 0.007560, weight_decay: 0.000100, momentum_teacher: 0.996016, loss: 7.7358
2022-10-02 04:22:39 - train: epoch 0005, iter [00500, 10009], lr: 0.007575, weight_decay: 0.000100, momentum_teacher: 0.996016, loss: 7.6828
2022-10-02 04:23:27 - train: epoch 0005, iter [00600, 10009], lr: 0.007590, weight_decay: 0.000100, momentum_teacher: 0.996016, loss: 7.6022
2022-10-02 04:24:14 - train: epoch 0005, iter [00700, 10009], lr: 0.007605, weight_decay: 0.000100, momentum_teacher: 0.996016, loss: 7.6664
2022-10-02 04:25:02 - train: epoch 0005, iter [00800, 10009], lr: 0.007620, weight_decay: 0.000100, momentum_teacher: 0.996016, loss: 7.6833
2022-10-02 04:25:49 - train: epoch 0005, iter [00900, 10009], lr: 0.007635, weight_decay: 0.000100, momentum_teacher: 0.996016, loss: 7.9816
2022-10-02 04:26:36 - train: epoch 0005, iter [01000, 10009], lr: 0.007650, weight_decay: 0.000100, momentum_teacher: 0.996017, loss: 7.7243
2022-10-02 04:27:24 - train: epoch 0005, iter [01100, 10009], lr: 0.007665, weight_decay: 0.000100, momentum_teacher: 0.996017, loss: 7.6563
2022-10-02 04:28:11 - train: epoch 0005, iter [01200, 10009], lr: 0.007680, weight_decay: 0.000100, momentum_teacher: 0.996017, loss: 7.7430
2022-10-02 04:28:58 - train: epoch 0005, iter [01300, 10009], lr: 0.007695, weight_decay: 0.000100, momentum_teacher: 0.996017, loss: 7.5300
2022-10-02 04:29:46 - train: epoch 0005, iter [01400, 10009], lr: 0.007710, weight_decay: 0.000100, momentum_teacher: 0.996017, loss: 7.7388
2022-10-02 04:30:33 - train: epoch 0005, iter [01500, 10009], lr: 0.007725, weight_decay: 0.000100, momentum_teacher: 0.996017, loss: 7.9412
2022-10-02 04:31:21 - train: epoch 0005, iter [01600, 10009], lr: 0.007740, weight_decay: 0.000100, momentum_teacher: 0.996017, loss: 7.9738
2022-10-02 04:32:08 - train: epoch 0005, iter [01700, 10009], lr: 0.007755, weight_decay: 0.000100, momentum_teacher: 0.996017, loss: 7.8154
2022-10-02 04:32:55 - train: epoch 0005, iter [01800, 10009], lr: 0.007770, weight_decay: 0.000100, momentum_teacher: 0.996017, loss: 7.6963
2022-10-02 04:33:43 - train: epoch 0005, iter [01900, 10009], lr: 0.007785, weight_decay: 0.000100, momentum_teacher: 0.996017, loss: 7.6863
2022-10-02 04:34:30 - train: epoch 0005, iter [02000, 10009], lr: 0.007800, weight_decay: 0.000100, momentum_teacher: 0.996017, loss: 7.7300
2022-10-02 04:35:17 - train: epoch 0005, iter [02100, 10009], lr: 0.007815, weight_decay: 0.000100, momentum_teacher: 0.996017, loss: 7.7366
2022-10-02 04:36:05 - train: epoch 0005, iter [02200, 10009], lr: 0.007830, weight_decay: 0.000100, momentum_teacher: 0.996018, loss: 7.8955
2022-10-02 04:36:52 - train: epoch 0005, iter [02300, 10009], lr: 0.007845, weight_decay: 0.000100, momentum_teacher: 0.996018, loss: 7.9435
2022-10-02 04:37:40 - train: epoch 0005, iter [02400, 10009], lr: 0.007860, weight_decay: 0.000100, momentum_teacher: 0.996018, loss: 7.8154
2022-10-02 04:38:27 - train: epoch 0005, iter [02500, 10009], lr: 0.007875, weight_decay: 0.000100, momentum_teacher: 0.996018, loss: 7.7170
2022-10-02 04:39:14 - train: epoch 0005, iter [02600, 10009], lr: 0.007890, weight_decay: 0.000100, momentum_teacher: 0.996018, loss: 7.7722
2022-10-02 04:40:02 - train: epoch 0005, iter [02700, 10009], lr: 0.007905, weight_decay: 0.000100, momentum_teacher: 0.996018, loss: 7.7409
2022-10-02 04:40:49 - train: epoch 0005, iter [02800, 10009], lr: 0.007920, weight_decay: 0.000100, momentum_teacher: 0.996018, loss: 7.8069
2022-10-02 04:41:37 - train: epoch 0005, iter [02900, 10009], lr: 0.007935, weight_decay: 0.000100, momentum_teacher: 0.996018, loss: 7.7295
2022-10-02 04:42:24 - train: epoch 0005, iter [03000, 10009], lr: 0.007950, weight_decay: 0.000100, momentum_teacher: 0.996018, loss: 7.6437
2022-10-02 04:43:12 - train: epoch 0005, iter [03100, 10009], lr: 0.007965, weight_decay: 0.000100, momentum_teacher: 0.996018, loss: 7.7368
2022-10-02 04:43:59 - train: epoch 0005, iter [03200, 10009], lr: 0.007980, weight_decay: 0.000100, momentum_teacher: 0.996018, loss: 7.9788
2022-10-02 04:44:47 - train: epoch 0005, iter [03300, 10009], lr: 0.007995, weight_decay: 0.000100, momentum_teacher: 0.996018, loss: 7.6898
2022-10-02 04:45:34 - train: epoch 0005, iter [03400, 10009], lr: 0.008010, weight_decay: 0.000100, momentum_teacher: 0.996019, loss: 7.7382
2022-10-02 04:46:22 - train: epoch 0005, iter [03500, 10009], lr: 0.008025, weight_decay: 0.000100, momentum_teacher: 0.996019, loss: 7.9477
2022-10-02 04:47:09 - train: epoch 0005, iter [03600, 10009], lr: 0.008040, weight_decay: 0.000100, momentum_teacher: 0.996019, loss: 7.8125
2022-10-02 04:47:56 - train: epoch 0005, iter [03700, 10009], lr: 0.008055, weight_decay: 0.000100, momentum_teacher: 0.996019, loss: 7.6694
2022-10-02 04:48:44 - train: epoch 0005, iter [03800, 10009], lr: 0.008069, weight_decay: 0.000100, momentum_teacher: 0.996019, loss: 7.7484
2022-10-02 04:49:31 - train: epoch 0005, iter [03900, 10009], lr: 0.008084, weight_decay: 0.000100, momentum_teacher: 0.996019, loss: 7.9315
2022-10-02 04:50:19 - train: epoch 0005, iter [04000, 10009], lr: 0.008099, weight_decay: 0.000100, momentum_teacher: 0.996019, loss: 7.4810
2022-10-02 04:52:07 - train: epoch 0005, iter [04100, 10009], lr: 0.008114, weight_decay: 0.000100, momentum_teacher: 0.996019, loss: 7.7312
2022-10-02 04:56:52 - train: epoch 0005, iter [04200, 10009], lr: 0.008129, weight_decay: 0.000100, momentum_teacher: 0.996019, loss: 7.7092
2022-10-02 05:00:54 - train: epoch 0005, iter [04300, 10009], lr: 0.008144, weight_decay: 0.000100, momentum_teacher: 0.996019, loss: 7.8065
2022-10-02 05:06:51 - train: epoch 0005, iter [04400, 10009], lr: 0.008159, weight_decay: 0.000100, momentum_teacher: 0.996019, loss: 7.6964
2022-10-02 05:15:51 - train: epoch 0005, iter [04500, 10009], lr: 0.008174, weight_decay: 0.000100, momentum_teacher: 0.996020, loss: 7.8950
2022-10-02 05:26:51 - train: epoch 0005, iter [04600, 10009], lr: 0.008189, weight_decay: 0.000100, momentum_teacher: 0.996020, loss: 7.9005
2022-10-02 05:38:19 - train: epoch 0005, iter [04700, 10009], lr: 0.008204, weight_decay: 0.000100, momentum_teacher: 0.996020, loss: 7.7949
2022-10-02 05:47:10 - train: epoch 0005, iter [04800, 10009], lr: 0.008219, weight_decay: 0.000100, momentum_teacher: 0.996020, loss: 7.7137
2022-10-02 05:55:25 - train: epoch 0005, iter [04900, 10009], lr: 0.008234, weight_decay: 0.000100, momentum_teacher: 0.996020, loss: 7.6979
2022-10-02 05:58:46 - train: epoch 0005, iter [05000, 10009], lr: 0.008249, weight_decay: 0.000100, momentum_teacher: 0.996020, loss: 7.7944
2022-10-02 05:59:42 - train: epoch 0005, iter [05100, 10009], lr: 0.008264, weight_decay: 0.000100, momentum_teacher: 0.996020, loss: 7.8329
2022-10-02 06:00:29 - train: epoch 0005, iter [05200, 10009], lr: 0.008279, weight_decay: 0.000100, momentum_teacher: 0.996020, loss: 7.7547
2022-10-02 06:01:17 - train: epoch 0005, iter [05300, 10009], lr: 0.008294, weight_decay: 0.000100, momentum_teacher: 0.996020, loss: 7.7223
2022-10-02 06:02:04 - train: epoch 0005, iter [05400, 10009], lr: 0.008309, weight_decay: 0.000100, momentum_teacher: 0.996020, loss: 7.7704
2022-10-02 06:02:52 - train: epoch 0005, iter [05500, 10009], lr: 0.008324, weight_decay: 0.000100, momentum_teacher: 0.996020, loss: 7.7533
2022-10-02 06:03:39 - train: epoch 0005, iter [05600, 10009], lr: 0.008339, weight_decay: 0.000100, momentum_teacher: 0.996020, loss: 7.6860
2022-10-02 06:04:27 - train: epoch 0005, iter [05700, 10009], lr: 0.008354, weight_decay: 0.000100, momentum_teacher: 0.996021, loss: 7.5208
2022-10-02 06:05:14 - train: epoch 0005, iter [05800, 10009], lr: 0.008369, weight_decay: 0.000100, momentum_teacher: 0.996021, loss: 7.6064
2022-10-02 06:06:02 - train: epoch 0005, iter [05900, 10009], lr: 0.008384, weight_decay: 0.000100, momentum_teacher: 0.996021, loss: 7.7610
2022-10-02 06:06:49 - train: epoch 0005, iter [06000, 10009], lr: 0.008399, weight_decay: 0.000100, momentum_teacher: 0.996021, loss: 7.7236
2022-10-02 06:07:37 - train: epoch 0005, iter [06100, 10009], lr: 0.008414, weight_decay: 0.000100, momentum_teacher: 0.996021, loss: 7.6560
2022-10-02 06:08:24 - train: epoch 0005, iter [06200, 10009], lr: 0.008429, weight_decay: 0.000100, momentum_teacher: 0.996021, loss: 7.8341
2022-10-02 06:09:12 - train: epoch 0005, iter [06300, 10009], lr: 0.008444, weight_decay: 0.000100, momentum_teacher: 0.996021, loss: 7.4525
2022-10-02 06:09:59 - train: epoch 0005, iter [06400, 10009], lr: 0.008459, weight_decay: 0.000100, momentum_teacher: 0.996021, loss: 7.8137
2022-10-02 06:10:47 - train: epoch 0005, iter [06500, 10009], lr: 0.008474, weight_decay: 0.000100, momentum_teacher: 0.996021, loss: 7.8348
2022-10-02 06:11:34 - train: epoch 0005, iter [06600, 10009], lr: 0.008489, weight_decay: 0.000100, momentum_teacher: 0.996021, loss: 7.6151
2022-10-02 06:12:22 - train: epoch 0005, iter [06700, 10009], lr: 0.008504, weight_decay: 0.000100, momentum_teacher: 0.996021, loss: 7.7477
2022-10-02 06:13:09 - train: epoch 0005, iter [06800, 10009], lr: 0.008519, weight_decay: 0.000100, momentum_teacher: 0.996022, loss: 7.6816
2022-10-02 06:13:57 - train: epoch 0005, iter [06900, 10009], lr: 0.008534, weight_decay: 0.000100, momentum_teacher: 0.996022, loss: 7.8045
2022-10-02 06:14:44 - train: epoch 0005, iter [07000, 10009], lr: 0.008549, weight_decay: 0.000100, momentum_teacher: 0.996022, loss: 7.6653
2022-10-02 06:15:32 - train: epoch 0005, iter [07100, 10009], lr: 0.008564, weight_decay: 0.000100, momentum_teacher: 0.996022, loss: 7.8196
2022-10-02 06:16:20 - train: epoch 0005, iter [07200, 10009], lr: 0.008579, weight_decay: 0.000100, momentum_teacher: 0.996022, loss: 7.8575
2022-10-02 06:17:08 - train: epoch 0005, iter [07300, 10009], lr: 0.008594, weight_decay: 0.000100, momentum_teacher: 0.996022, loss: 7.7090
2022-10-02 06:17:56 - train: epoch 0005, iter [07400, 10009], lr: 0.008609, weight_decay: 0.000100, momentum_teacher: 0.996022, loss: 7.7142
2022-10-02 06:18:43 - train: epoch 0005, iter [07500, 10009], lr: 0.008624, weight_decay: 0.000100, momentum_teacher: 0.996022, loss: 7.8298
2022-10-02 06:19:30 - train: epoch 0005, iter [07600, 10009], lr: 0.008639, weight_decay: 0.000100, momentum_teacher: 0.996022, loss: 7.7961
2022-10-02 06:20:18 - train: epoch 0005, iter [07700, 10009], lr: 0.008654, weight_decay: 0.000100, momentum_teacher: 0.996022, loss: 7.5111
2022-10-02 06:21:05 - train: epoch 0005, iter [07800, 10009], lr: 0.008669, weight_decay: 0.000100, momentum_teacher: 0.996023, loss: 7.7728
2022-10-02 06:21:53 - train: epoch 0005, iter [07900, 10009], lr: 0.008684, weight_decay: 0.000100, momentum_teacher: 0.996023, loss: 7.6829
2022-10-02 06:22:41 - train: epoch 0005, iter [08000, 10009], lr: 0.008699, weight_decay: 0.000100, momentum_teacher: 0.996023, loss: 7.6177
2022-10-02 06:23:28 - train: epoch 0005, iter [08100, 10009], lr: 0.008714, weight_decay: 0.000100, momentum_teacher: 0.996023, loss: 7.7574
2022-10-02 06:24:19 - train: epoch 0005, iter [08200, 10009], lr: 0.008729, weight_decay: 0.000100, momentum_teacher: 0.996023, loss: 7.9343
2022-10-02 06:25:12 - train: epoch 0005, iter [08300, 10009], lr: 0.008744, weight_decay: 0.000100, momentum_teacher: 0.996023, loss: 7.7828
2022-10-02 06:26:01 - train: epoch 0005, iter [08400, 10009], lr: 0.008759, weight_decay: 0.000100, momentum_teacher: 0.996023, loss: 7.8587
2022-10-02 06:26:49 - train: epoch 0005, iter [08500, 10009], lr: 0.008774, weight_decay: 0.000100, momentum_teacher: 0.996023, loss: 7.6442
2022-10-02 06:27:37 - train: epoch 0005, iter [08600, 10009], lr: 0.008789, weight_decay: 0.000100, momentum_teacher: 0.996023, loss: 7.7487
2022-10-02 06:28:24 - train: epoch 0005, iter [08700, 10009], lr: 0.008804, weight_decay: 0.000100, momentum_teacher: 0.996023, loss: 7.5840
2022-10-02 06:29:12 - train: epoch 0005, iter [08800, 10009], lr: 0.008819, weight_decay: 0.000100, momentum_teacher: 0.996023, loss: 7.6975
2022-10-02 06:30:00 - train: epoch 0005, iter [08900, 10009], lr: 0.008834, weight_decay: 0.000100, momentum_teacher: 0.996024, loss: 7.9039
2022-10-02 06:30:47 - train: epoch 0005, iter [09000, 10009], lr: 0.008849, weight_decay: 0.000100, momentum_teacher: 0.996024, loss: 7.6942
2022-10-02 06:31:34 - train: epoch 0005, iter [09100, 10009], lr: 0.008864, weight_decay: 0.000100, momentum_teacher: 0.996024, loss: 7.8069
2022-10-02 06:32:22 - train: epoch 0005, iter [09200, 10009], lr: 0.008879, weight_decay: 0.000100, momentum_teacher: 0.996024, loss: 7.8040
2022-10-02 06:33:17 - train: epoch 0005, iter [09300, 10009], lr: 0.008894, weight_decay: 0.000100, momentum_teacher: 0.996024, loss: 7.9015
2022-10-02 06:34:14 - train: epoch 0005, iter [09400, 10009], lr: 0.008909, weight_decay: 0.000100, momentum_teacher: 0.996024, loss: 7.6906
2022-10-02 06:35:22 - train: epoch 0005, iter [09500, 10009], lr: 0.008924, weight_decay: 0.000100, momentum_teacher: 0.996024, loss: 7.8988
2022-10-02 06:36:24 - train: epoch 0005, iter [09600, 10009], lr: 0.008939, weight_decay: 0.000100, momentum_teacher: 0.996024, loss: 7.8002
2022-10-02 06:37:11 - train: epoch 0005, iter [09700, 10009], lr: 0.008954, weight_decay: 0.000100, momentum_teacher: 0.996024, loss: 7.7935
2022-10-02 06:37:59 - train: epoch 0005, iter [09800, 10009], lr: 0.008969, weight_decay: 0.000100, momentum_teacher: 0.996024, loss: 7.8207
2022-10-02 06:38:47 - train: epoch 0005, iter [09900, 10009], lr: 0.008984, weight_decay: 0.000100, momentum_teacher: 0.996025, loss: 7.7565
2022-10-02 06:39:34 - train: epoch 0005, iter [10000, 10009], lr: 0.008999, weight_decay: 0.000100, momentum_teacher: 0.996025, loss: 7.8747
2022-10-02 06:39:39 - train: epoch 005, train_loss: 7.7332
2022-10-02 06:39:41 - until epoch: 005, best_loss: 7.7332
2022-10-02 06:39:41 - epoch 006 lr: 0.009000
2022-10-02 06:40:33 - train: epoch 0006, iter [00100, 10009], lr: 0.009015, weight_decay: 0.000100, momentum_teacher: 0.996025, loss: 7.8751
2022-10-02 06:41:20 - train: epoch 0006, iter [00200, 10009], lr: 0.009030, weight_decay: 0.000100, momentum_teacher: 0.996025, loss: 7.7131
2022-10-02 06:42:08 - train: epoch 0006, iter [00300, 10009], lr: 0.009045, weight_decay: 0.000100, momentum_teacher: 0.996025, loss: 7.8370
2022-10-02 06:42:58 - train: epoch 0006, iter [00400, 10009], lr: 0.009060, weight_decay: 0.000100, momentum_teacher: 0.996025, loss: 7.8332
2022-10-02 06:43:46 - train: epoch 0006, iter [00500, 10009], lr: 0.009075, weight_decay: 0.000100, momentum_teacher: 0.996025, loss: 7.8751
2022-10-02 06:44:34 - train: epoch 0006, iter [00600, 10009], lr: 0.009090, weight_decay: 0.000100, momentum_teacher: 0.996025, loss: 7.8816
2022-10-02 06:45:22 - train: epoch 0006, iter [00700, 10009], lr: 0.009105, weight_decay: 0.000100, momentum_teacher: 0.996025, loss: 7.5743
2022-10-02 06:46:09 - train: epoch 0006, iter [00800, 10009], lr: 0.009120, weight_decay: 0.000100, momentum_teacher: 0.996025, loss: 7.9239
2022-10-02 06:46:57 - train: epoch 0006, iter [00900, 10009], lr: 0.009135, weight_decay: 0.000100, momentum_teacher: 0.996026, loss: 7.8358
2022-10-02 06:47:45 - train: epoch 0006, iter [01000, 10009], lr: 0.009150, weight_decay: 0.000100, momentum_teacher: 0.996026, loss: 7.7285
2022-10-02 06:48:33 - train: epoch 0006, iter [01100, 10009], lr: 0.009165, weight_decay: 0.000100, momentum_teacher: 0.996026, loss: 7.8898
2022-10-02 06:49:20 - train: epoch 0006, iter [01200, 10009], lr: 0.009180, weight_decay: 0.000100, momentum_teacher: 0.996026, loss: 7.8370
2022-10-02 06:50:08 - train: epoch 0006, iter [01300, 10009], lr: 0.009195, weight_decay: 0.000100, momentum_teacher: 0.996026, loss: 7.8231
2022-10-02 06:50:55 - train: epoch 0006, iter [01400, 10009], lr: 0.009210, weight_decay: 0.000100, momentum_teacher: 0.996026, loss: 7.8443
2022-10-02 06:51:43 - train: epoch 0006, iter [01500, 10009], lr: 0.009225, weight_decay: 0.000100, momentum_teacher: 0.996026, loss: 7.9911
2022-10-02 06:52:31 - train: epoch 0006, iter [01600, 10009], lr: 0.009240, weight_decay: 0.000100, momentum_teacher: 0.996026, loss: 7.9447
2022-10-02 06:53:18 - train: epoch 0006, iter [01700, 10009], lr: 0.009255, weight_decay: 0.000100, momentum_teacher: 0.996026, loss: 7.6140
2022-10-02 06:54:05 - train: epoch 0006, iter [01800, 10009], lr: 0.009270, weight_decay: 0.000100, momentum_teacher: 0.996026, loss: 7.7747
2022-10-02 06:54:53 - train: epoch 0006, iter [01900, 10009], lr: 0.009285, weight_decay: 0.000100, momentum_teacher: 0.996027, loss: 7.9648
2022-10-02 06:55:40 - train: epoch 0006, iter [02000, 10009], lr: 0.009300, weight_decay: 0.000100, momentum_teacher: 0.996027, loss: 7.8281
2022-10-02 06:56:27 - train: epoch 0006, iter [02100, 10009], lr: 0.009315, weight_decay: 0.000100, momentum_teacher: 0.996027, loss: 7.9162
2022-10-02 06:57:15 - train: epoch 0006, iter [02200, 10009], lr: 0.009330, weight_decay: 0.000100, momentum_teacher: 0.996027, loss: 7.8121
2022-10-02 06:58:03 - train: epoch 0006, iter [02300, 10009], lr: 0.009345, weight_decay: 0.000100, momentum_teacher: 0.996027, loss: 7.5984
2022-10-02 06:58:50 - train: epoch 0006, iter [02400, 10009], lr: 0.009360, weight_decay: 0.000100, momentum_teacher: 0.996027, loss: 7.8367
2022-10-02 06:59:37 - train: epoch 0006, iter [02500, 10009], lr: 0.009375, weight_decay: 0.000100, momentum_teacher: 0.996027, loss: 7.7489
2022-10-02 07:00:25 - train: epoch 0006, iter [02600, 10009], lr: 0.009390, weight_decay: 0.000100, momentum_teacher: 0.996027, loss: 7.8069
2022-10-02 07:01:12 - train: epoch 0006, iter [02700, 10009], lr: 0.009405, weight_decay: 0.000100, momentum_teacher: 0.996027, loss: 7.6960
2022-10-02 07:02:00 - train: epoch 0006, iter [02800, 10009], lr: 0.009420, weight_decay: 0.000100, momentum_teacher: 0.996027, loss: 7.7109
2022-10-02 07:02:47 - train: epoch 0006, iter [02900, 10009], lr: 0.009435, weight_decay: 0.000100, momentum_teacher: 0.996028, loss: 7.6729
2022-10-02 07:03:35 - train: epoch 0006, iter [03000, 10009], lr: 0.009450, weight_decay: 0.000100, momentum_teacher: 0.996028, loss: 7.6753
2022-10-02 07:04:22 - train: epoch 0006, iter [03100, 10009], lr: 0.009465, weight_decay: 0.000100, momentum_teacher: 0.996028, loss: 7.7896
2022-10-02 07:05:10 - train: epoch 0006, iter [03200, 10009], lr: 0.009480, weight_decay: 0.000100, momentum_teacher: 0.996028, loss: 7.5989
2022-10-02 07:05:57 - train: epoch 0006, iter [03300, 10009], lr: 0.009495, weight_decay: 0.000100, momentum_teacher: 0.996028, loss: 7.8057
2022-10-02 07:06:45 - train: epoch 0006, iter [03400, 10009], lr: 0.009510, weight_decay: 0.000100, momentum_teacher: 0.996028, loss: 7.6075
2022-10-02 07:07:32 - train: epoch 0006, iter [03500, 10009], lr: 0.009525, weight_decay: 0.000100, momentum_teacher: 0.996028, loss: 7.6513
2022-10-02 07:08:20 - train: epoch 0006, iter [03600, 10009], lr: 0.009540, weight_decay: 0.000100, momentum_teacher: 0.996028, loss: 7.8764
2022-10-02 07:09:08 - train: epoch 0006, iter [03700, 10009], lr: 0.009555, weight_decay: 0.000100, momentum_teacher: 0.996028, loss: 7.7121
2022-10-02 07:09:55 - train: epoch 0006, iter [03800, 10009], lr: 0.009569, weight_decay: 0.000100, momentum_teacher: 0.996028, loss: 7.5523
2022-10-02 07:10:43 - train: epoch 0006, iter [03900, 10009], lr: 0.009584, weight_decay: 0.000100, momentum_teacher: 0.996029, loss: 7.6796
2022-10-02 07:11:30 - train: epoch 0006, iter [04000, 10009], lr: 0.009599, weight_decay: 0.000100, momentum_teacher: 0.996029, loss: 7.6276
2022-10-02 07:12:18 - train: epoch 0006, iter [04100, 10009], lr: 0.009614, weight_decay: 0.000100, momentum_teacher: 0.996029, loss: 7.8002
2022-10-02 07:13:05 - train: epoch 0006, iter [04200, 10009], lr: 0.009629, weight_decay: 0.000100, momentum_teacher: 0.996029, loss: 7.6615
2022-10-02 07:13:53 - train: epoch 0006, iter [04300, 10009], lr: 0.009644, weight_decay: 0.000100, momentum_teacher: 0.996029, loss: 7.7250
2022-10-02 07:14:40 - train: epoch 0006, iter [04400, 10009], lr: 0.009659, weight_decay: 0.000100, momentum_teacher: 0.996029, loss: 7.4661
2022-10-02 07:15:27 - train: epoch 0006, iter [04500, 10009], lr: 0.009674, weight_decay: 0.000100, momentum_teacher: 0.996029, loss: 7.7628
2022-10-02 07:16:15 - train: epoch 0006, iter [04600, 10009], lr: 0.009689, weight_decay: 0.000100, momentum_teacher: 0.996029, loss: 7.4199
2022-10-02 07:17:03 - train: epoch 0006, iter [04700, 10009], lr: 0.009704, weight_decay: 0.000100, momentum_teacher: 0.996029, loss: 7.6071
2022-10-02 07:17:50 - train: epoch 0006, iter [04800, 10009], lr: 0.009719, weight_decay: 0.000100, momentum_teacher: 0.996030, loss: 7.4459
2022-10-02 07:18:38 - train: epoch 0006, iter [04900, 10009], lr: 0.009734, weight_decay: 0.000100, momentum_teacher: 0.996030, loss: 7.7069
2022-10-02 07:19:25 - train: epoch 0006, iter [05000, 10009], lr: 0.009749, weight_decay: 0.000100, momentum_teacher: 0.996030, loss: 7.6149
2022-10-02 07:20:13 - train: epoch 0006, iter [05100, 10009], lr: 0.009764, weight_decay: 0.000100, momentum_teacher: 0.996030, loss: 7.6848
2022-10-02 07:21:00 - train: epoch 0006, iter [05200, 10009], lr: 0.009779, weight_decay: 0.000100, momentum_teacher: 0.996030, loss: 7.5810
2022-10-02 07:21:48 - train: epoch 0006, iter [05300, 10009], lr: 0.009794, weight_decay: 0.000100, momentum_teacher: 0.996030, loss: 7.5902
2022-10-02 07:22:35 - train: epoch 0006, iter [05400, 10009], lr: 0.009809, weight_decay: 0.000100, momentum_teacher: 0.996030, loss: 7.5710
2022-10-02 07:23:23 - train: epoch 0006, iter [05500, 10009], lr: 0.009824, weight_decay: 0.000100, momentum_teacher: 0.996030, loss: 7.4696
2022-10-02 07:24:10 - train: epoch 0006, iter [05600, 10009], lr: 0.009839, weight_decay: 0.000100, momentum_teacher: 0.996030, loss: 7.7346
2022-10-02 07:24:57 - train: epoch 0006, iter [05700, 10009], lr: 0.009854, weight_decay: 0.000100, momentum_teacher: 0.996031, loss: 7.5609
2022-10-02 07:25:45 - train: epoch 0006, iter [05800, 10009], lr: 0.009869, weight_decay: 0.000100, momentum_teacher: 0.996031, loss: 7.6964
2022-10-02 07:26:32 - train: epoch 0006, iter [05900, 10009], lr: 0.009884, weight_decay: 0.000100, momentum_teacher: 0.996031, loss: 7.6322
2022-10-02 07:27:20 - train: epoch 0006, iter [06000, 10009], lr: 0.009899, weight_decay: 0.000100, momentum_teacher: 0.996031, loss: 7.8747
2022-10-02 07:28:07 - train: epoch 0006, iter [06100, 10009], lr: 0.009914, weight_decay: 0.000100, momentum_teacher: 0.996031, loss: 7.3725
2022-10-02 07:28:55 - train: epoch 0006, iter [06200, 10009], lr: 0.009929, weight_decay: 0.000100, momentum_teacher: 0.996031, loss: 7.4680
2022-10-02 07:29:42 - train: epoch 0006, iter [06300, 10009], lr: 0.009944, weight_decay: 0.000100, momentum_teacher: 0.996031, loss: 7.4687
2022-10-02 07:30:30 - train: epoch 0006, iter [06400, 10009], lr: 0.009959, weight_decay: 0.000100, momentum_teacher: 0.996031, loss: 7.6574
2022-10-02 07:31:17 - train: epoch 0006, iter [06500, 10009], lr: 0.009974, weight_decay: 0.000100, momentum_teacher: 0.996031, loss: 7.5376
2022-10-02 07:32:04 - train: epoch 0006, iter [06600, 10009], lr: 0.009989, weight_decay: 0.000100, momentum_teacher: 0.996032, loss: 7.5064
2022-10-02 07:32:52 - train: epoch 0006, iter [06700, 10009], lr: 0.010004, weight_decay: 0.000100, momentum_teacher: 0.996032, loss: 7.6236
2022-10-02 07:33:40 - train: epoch 0006, iter [06800, 10009], lr: 0.010019, weight_decay: 0.000100, momentum_teacher: 0.996032, loss: 7.4982
2022-10-02 07:34:27 - train: epoch 0006, iter [06900, 10009], lr: 0.010034, weight_decay: 0.000100, momentum_teacher: 0.996032, loss: 7.5813
2022-10-02 07:35:14 - train: epoch 0006, iter [07000, 10009], lr: 0.010049, weight_decay: 0.000100, momentum_teacher: 0.996032, loss: 7.5717
2022-10-02 07:36:02 - train: epoch 0006, iter [07100, 10009], lr: 0.010064, weight_decay: 0.000100, momentum_teacher: 0.996032, loss: 7.5817
2022-10-02 07:36:49 - train: epoch 0006, iter [07200, 10009], lr: 0.010079, weight_decay: 0.000100, momentum_teacher: 0.996032, loss: 7.7032
2022-10-02 07:37:37 - train: epoch 0006, iter [07300, 10009], lr: 0.010094, weight_decay: 0.000100, momentum_teacher: 0.996032, loss: 7.4093
2022-10-02 07:38:24 - train: epoch 0006, iter [07400, 10009], lr: 0.010109, weight_decay: 0.000100, momentum_teacher: 0.996032, loss: 7.4434
2022-10-02 07:39:12 - train: epoch 0006, iter [07500, 10009], lr: 0.010124, weight_decay: 0.000100, momentum_teacher: 0.996033, loss: 7.4286
2022-10-02 07:39:59 - train: epoch 0006, iter [07600, 10009], lr: 0.010139, weight_decay: 0.000100, momentum_teacher: 0.996033, loss: 7.4946
2022-10-02 07:40:47 - train: epoch 0006, iter [07700, 10009], lr: 0.010154, weight_decay: 0.000100, momentum_teacher: 0.996033, loss: 7.4833
2022-10-02 07:41:34 - train: epoch 0006, iter [07800, 10009], lr: 0.010169, weight_decay: 0.000100, momentum_teacher: 0.996033, loss: 7.6174
2022-10-02 07:42:22 - train: epoch 0006, iter [07900, 10009], lr: 0.010184, weight_decay: 0.000100, momentum_teacher: 0.996033, loss: 7.4153
2022-10-02 07:43:10 - train: epoch 0006, iter [08000, 10009], lr: 0.010199, weight_decay: 0.000100, momentum_teacher: 0.996033, loss: 7.3063
2022-10-02 07:43:57 - train: epoch 0006, iter [08100, 10009], lr: 0.010214, weight_decay: 0.000100, momentum_teacher: 0.996033, loss: 7.4750
2022-10-02 07:44:45 - train: epoch 0006, iter [08200, 10009], lr: 0.010229, weight_decay: 0.000100, momentum_teacher: 0.996033, loss: 7.5851
2022-10-02 07:45:32 - train: epoch 0006, iter [08300, 10009], lr: 0.010244, weight_decay: 0.000100, momentum_teacher: 0.996033, loss: 7.4669
2022-10-02 07:46:20 - train: epoch 0006, iter [08400, 10009], lr: 0.010259, weight_decay: 0.000100, momentum_teacher: 0.996034, loss: 7.2662
2022-10-02 07:47:08 - train: epoch 0006, iter [08500, 10009], lr: 0.010274, weight_decay: 0.000100, momentum_teacher: 0.996034, loss: 7.1760
2022-10-02 07:47:55 - train: epoch 0006, iter [08600, 10009], lr: 0.010289, weight_decay: 0.000100, momentum_teacher: 0.996034, loss: 7.3637
2022-10-02 07:48:43 - train: epoch 0006, iter [08700, 10009], lr: 0.010304, weight_decay: 0.000100, momentum_teacher: 0.996034, loss: 7.2251
2022-10-02 07:49:30 - train: epoch 0006, iter [08800, 10009], lr: 0.010319, weight_decay: 0.000100, momentum_teacher: 0.996034, loss: 7.5427
2022-10-02 07:50:18 - train: epoch 0006, iter [08900, 10009], lr: 0.010334, weight_decay: 0.000100, momentum_teacher: 0.996034, loss: 7.3563
2022-10-02 07:51:06 - train: epoch 0006, iter [09000, 10009], lr: 0.010349, weight_decay: 0.000100, momentum_teacher: 0.996034, loss: 7.3720
2022-10-02 07:51:53 - train: epoch 0006, iter [09100, 10009], lr: 0.010364, weight_decay: 0.000100, momentum_teacher: 0.996034, loss: 7.5129
2022-10-02 07:52:41 - train: epoch 0006, iter [09200, 10009], lr: 0.010379, weight_decay: 0.000100, momentum_teacher: 0.996034, loss: 7.2543
2022-10-02 07:53:28 - train: epoch 0006, iter [09300, 10009], lr: 0.010394, weight_decay: 0.000100, momentum_teacher: 0.996035, loss: 7.2560
2022-10-02 07:54:16 - train: epoch 0006, iter [09400, 10009], lr: 0.010409, weight_decay: 0.000100, momentum_teacher: 0.996035, loss: 7.2875
2022-10-02 07:55:03 - train: epoch 0006, iter [09500, 10009], lr: 0.010424, weight_decay: 0.000100, momentum_teacher: 0.996035, loss: 7.3360
2022-10-02 07:55:51 - train: epoch 0006, iter [09600, 10009], lr: 0.010439, weight_decay: 0.000100, momentum_teacher: 0.996035, loss: 7.1621
2022-10-02 07:56:38 - train: epoch 0006, iter [09700, 10009], lr: 0.010454, weight_decay: 0.000100, momentum_teacher: 0.996035, loss: 7.2684
2022-10-02 07:57:26 - train: epoch 0006, iter [09800, 10009], lr: 0.010469, weight_decay: 0.000100, momentum_teacher: 0.996035, loss: 7.2534
2022-10-02 07:58:13 - train: epoch 0006, iter [09900, 10009], lr: 0.010484, weight_decay: 0.000100, momentum_teacher: 0.996035, loss: 7.3012
2022-10-02 07:59:01 - train: epoch 0006, iter [10000, 10009], lr: 0.010499, weight_decay: 0.000100, momentum_teacher: 0.996035, loss: 7.4540
2022-10-02 07:59:06 - train: epoch 006, train_loss: 7.6095
2022-10-02 07:59:08 - until epoch: 006, best_loss: 7.6095
2022-10-02 07:59:08 - epoch 007 lr: 0.010500
2022-10-02 08:00:00 - train: epoch 0007, iter [00100, 10009], lr: 0.010515, weight_decay: 0.000100, momentum_teacher: 0.996036, loss: 6.9937
2022-10-02 08:00:47 - train: epoch 0007, iter [00200, 10009], lr: 0.010530, weight_decay: 0.000100, momentum_teacher: 0.996036, loss: 7.3925
2022-10-02 08:01:35 - train: epoch 0007, iter [00300, 10009], lr: 0.010545, weight_decay: 0.000100, momentum_teacher: 0.996036, loss: 7.2111
2022-10-02 08:02:24 - train: epoch 0007, iter [00400, 10009], lr: 0.010560, weight_decay: 0.000100, momentum_teacher: 0.996036, loss: 7.3734
2022-10-02 08:03:14 - train: epoch 0007, iter [00500, 10009], lr: 0.010575, weight_decay: 0.000100, momentum_teacher: 0.996036, loss: 7.3563
2022-10-02 08:04:05 - train: epoch 0007, iter [00600, 10009], lr: 0.010590, weight_decay: 0.000100, momentum_teacher: 0.996036, loss: 7.3473
2022-10-02 08:04:54 - train: epoch 0007, iter [00700, 10009], lr: 0.010605, weight_decay: 0.000100, momentum_teacher: 0.996036, loss: 7.2163
2022-10-02 08:05:41 - train: epoch 0007, iter [00800, 10009], lr: 0.010620, weight_decay: 0.000100, momentum_teacher: 0.996036, loss: 7.1781
2022-10-02 08:06:29 - train: epoch 0007, iter [00900, 10009], lr: 0.010635, weight_decay: 0.000100, momentum_teacher: 0.996036, loss: 7.3047
2022-10-02 08:07:16 - train: epoch 0007, iter [01000, 10009], lr: 0.010650, weight_decay: 0.000100, momentum_teacher: 0.996037, loss: 7.4322
2022-10-02 08:08:04 - train: epoch 0007, iter [01100, 10009], lr: 0.010665, weight_decay: 0.000100, momentum_teacher: 0.996037, loss: 7.2680
2022-10-02 08:08:52 - train: epoch 0007, iter [01200, 10009], lr: 0.010680, weight_decay: 0.000100, momentum_teacher: 0.996037, loss: 7.2409
2022-10-02 08:09:41 - train: epoch 0007, iter [01300, 10009], lr: 0.010695, weight_decay: 0.000100, momentum_teacher: 0.996037, loss: 7.1052
2022-10-02 08:10:32 - train: epoch 0007, iter [01400, 10009], lr: 0.010710, weight_decay: 0.000100, momentum_teacher: 0.996037, loss: 7.3581
2022-10-02 08:11:21 - train: epoch 0007, iter [01500, 10009], lr: 0.010725, weight_decay: 0.000100, momentum_teacher: 0.996037, loss: 7.2878
2022-10-02 08:12:08 - train: epoch 0007, iter [01600, 10009], lr: 0.010740, weight_decay: 0.000100, momentum_teacher: 0.996037, loss: 6.9518
2022-10-02 08:12:56 - train: epoch 0007, iter [01700, 10009], lr: 0.010755, weight_decay: 0.000100, momentum_teacher: 0.996037, loss: 7.1820
2022-10-02 08:13:44 - train: epoch 0007, iter [01800, 10009], lr: 0.010770, weight_decay: 0.000100, momentum_teacher: 0.996038, loss: 7.1646
2022-10-02 08:14:33 - train: epoch 0007, iter [01900, 10009], lr: 0.010785, weight_decay: 0.000100, momentum_teacher: 0.996038, loss: 7.0907
2022-10-02 08:15:20 - train: epoch 0007, iter [02000, 10009], lr: 0.010800, weight_decay: 0.000100, momentum_teacher: 0.996038, loss: 6.9876
2022-10-02 08:16:08 - train: epoch 0007, iter [02100, 10009], lr: 0.010815, weight_decay: 0.000100, momentum_teacher: 0.996038, loss: 7.2378
2022-10-02 08:16:55 - train: epoch 0007, iter [02200, 10009], lr: 0.010830, weight_decay: 0.000100, momentum_teacher: 0.996038, loss: 7.0924
2022-10-02 08:17:43 - train: epoch 0007, iter [02300, 10009], lr: 0.010845, weight_decay: 0.000100, momentum_teacher: 0.996038, loss: 7.1247
2022-10-02 08:18:30 - train: epoch 0007, iter [02400, 10009], lr: 0.010860, weight_decay: 0.000100, momentum_teacher: 0.996038, loss: 6.9287
2022-10-02 08:19:18 - train: epoch 0007, iter [02500, 10009], lr: 0.010875, weight_decay: 0.000100, momentum_teacher: 0.996038, loss: 7.0540
2022-10-02 08:20:05 - train: epoch 0007, iter [02600, 10009], lr: 0.010890, weight_decay: 0.000100, momentum_teacher: 0.996039, loss: 7.0553
2022-10-02 08:20:53 - train: epoch 0007, iter [02700, 10009], lr: 0.010905, weight_decay: 0.000100, momentum_teacher: 0.996039, loss: 6.9428
2022-10-02 08:21:40 - train: epoch 0007, iter [02800, 10009], lr: 0.010920, weight_decay: 0.000100, momentum_teacher: 0.996039, loss: 7.0770
2022-10-02 08:22:28 - train: epoch 0007, iter [02900, 10009], lr: 0.010935, weight_decay: 0.000100, momentum_teacher: 0.996039, loss: 7.0419
2022-10-02 08:23:15 - train: epoch 0007, iter [03000, 10009], lr: 0.010950, weight_decay: 0.000100, momentum_teacher: 0.996039, loss: 7.0392
2022-10-02 08:24:03 - train: epoch 0007, iter [03100, 10009], lr: 0.010965, weight_decay: 0.000100, momentum_teacher: 0.996039, loss: 6.9361
2022-10-02 08:24:50 - train: epoch 0007, iter [03200, 10009], lr: 0.010980, weight_decay: 0.000100, momentum_teacher: 0.996039, loss: 6.9373
2022-10-02 08:25:38 - train: epoch 0007, iter [03300, 10009], lr: 0.010995, weight_decay: 0.000100, momentum_teacher: 0.996039, loss: 6.8322
2022-10-02 08:26:25 - train: epoch 0007, iter [03400, 10009], lr: 0.011010, weight_decay: 0.000100, momentum_teacher: 0.996040, loss: 7.0978
2022-10-02 08:27:13 - train: epoch 0007, iter [03500, 10009], lr: 0.011025, weight_decay: 0.000100, momentum_teacher: 0.996040, loss: 6.9696
2022-10-02 08:28:00 - train: epoch 0007, iter [03600, 10009], lr: 0.011040, weight_decay: 0.000100, momentum_teacher: 0.996040, loss: 6.9808
2022-10-02 08:28:48 - train: epoch 0007, iter [03700, 10009], lr: 0.011055, weight_decay: 0.000100, momentum_teacher: 0.996040, loss: 6.9919
2022-10-02 08:29:35 - train: epoch 0007, iter [03800, 10009], lr: 0.011069, weight_decay: 0.000100, momentum_teacher: 0.996040, loss: 6.9817
2022-10-02 08:30:23 - train: epoch 0007, iter [03900, 10009], lr: 0.011084, weight_decay: 0.000100, momentum_teacher: 0.996040, loss: 7.0688
2022-10-02 08:31:16 - train: epoch 0007, iter [04000, 10009], lr: 0.011099, weight_decay: 0.000100, momentum_teacher: 0.996040, loss: 6.8929
2022-10-02 08:32:04 - train: epoch 0007, iter [04100, 10009], lr: 0.011114, weight_decay: 0.000100, momentum_teacher: 0.996040, loss: 6.9098
2022-10-02 08:32:51 - train: epoch 0007, iter [04200, 10009], lr: 0.011129, weight_decay: 0.000100, momentum_teacher: 0.996041, loss: 6.8861
2022-10-02 08:33:39 - train: epoch 0007, iter [04300, 10009], lr: 0.011144, weight_decay: 0.000100, momentum_teacher: 0.996041, loss: 7.0504
2022-10-02 08:34:26 - train: epoch 0007, iter [04400, 10009], lr: 0.011159, weight_decay: 0.000100, momentum_teacher: 0.996041, loss: 6.8623
2022-10-02 08:35:14 - train: epoch 0007, iter [04500, 10009], lr: 0.011174, weight_decay: 0.000100, momentum_teacher: 0.996041, loss: 6.8202
2022-10-02 08:36:01 - train: epoch 0007, iter [04600, 10009], lr: 0.011189, weight_decay: 0.000100, momentum_teacher: 0.996041, loss: 6.8456
2022-10-02 08:36:48 - train: epoch 0007, iter [04700, 10009], lr: 0.011204, weight_decay: 0.000100, momentum_teacher: 0.996041, loss: 6.7924
2022-10-02 08:37:36 - train: epoch 0007, iter [04800, 10009], lr: 0.011219, weight_decay: 0.000100, momentum_teacher: 0.996041, loss: 6.8111
2022-10-02 08:38:23 - train: epoch 0007, iter [04900, 10009], lr: 0.011234, weight_decay: 0.000100, momentum_teacher: 0.996041, loss: 6.7469
2022-10-02 08:39:11 - train: epoch 0007, iter [05000, 10009], lr: 0.011249, weight_decay: 0.000100, momentum_teacher: 0.996042, loss: 6.7921
2022-10-02 08:39:58 - train: epoch 0007, iter [05100, 10009], lr: 0.011264, weight_decay: 0.000100, momentum_teacher: 0.996042, loss: 6.7588
2022-10-02 08:40:46 - train: epoch 0007, iter [05200, 10009], lr: 0.011279, weight_decay: 0.000100, momentum_teacher: 0.996042, loss: 6.6027
2022-10-02 08:41:33 - train: epoch 0007, iter [05300, 10009], lr: 0.011294, weight_decay: 0.000100, momentum_teacher: 0.996042, loss: 6.7639
2022-10-02 08:42:20 - train: epoch 0007, iter [05400, 10009], lr: 0.011309, weight_decay: 0.000100, momentum_teacher: 0.996042, loss: 6.4948
2022-10-02 08:43:08 - train: epoch 0007, iter [05500, 10009], lr: 0.011324, weight_decay: 0.000100, momentum_teacher: 0.996042, loss: 6.7557
2022-10-02 08:43:55 - train: epoch 0007, iter [05600, 10009], lr: 0.011339, weight_decay: 0.000100, momentum_teacher: 0.996042, loss: 6.7087
2022-10-02 08:44:43 - train: epoch 0007, iter [05700, 10009], lr: 0.011354, weight_decay: 0.000100, momentum_teacher: 0.996042, loss: 6.8137
2022-10-02 08:45:30 - train: epoch 0007, iter [05800, 10009], lr: 0.011369, weight_decay: 0.000100, momentum_teacher: 0.996043, loss: 6.8444
2022-10-02 08:46:17 - train: epoch 0007, iter [05900, 10009], lr: 0.011384, weight_decay: 0.000100, momentum_teacher: 0.996043, loss: 6.6188
2022-10-02 08:47:05 - train: epoch 0007, iter [06000, 10009], lr: 0.011399, weight_decay: 0.000100, momentum_teacher: 0.996043, loss: 6.3772
2022-10-02 08:47:52 - train: epoch 0007, iter [06100, 10009], lr: 0.011414, weight_decay: 0.000100, momentum_teacher: 0.996043, loss: 6.7076
2022-10-02 08:48:40 - train: epoch 0007, iter [06200, 10009], lr: 0.011429, weight_decay: 0.000100, momentum_teacher: 0.996043, loss: 6.8408
2022-10-02 08:49:28 - train: epoch 0007, iter [06300, 10009], lr: 0.011444, weight_decay: 0.000100, momentum_teacher: 0.996043, loss: 6.4504
2022-10-02 08:50:16 - train: epoch 0007, iter [06400, 10009], lr: 0.011459, weight_decay: 0.000100, momentum_teacher: 0.996043, loss: 6.6440
2022-10-02 08:51:03 - train: epoch 0007, iter [06500, 10009], lr: 0.011474, weight_decay: 0.000100, momentum_teacher: 0.996043, loss: 6.4871
2022-10-02 08:51:51 - train: epoch 0007, iter [06600, 10009], lr: 0.011489, weight_decay: 0.000100, momentum_teacher: 0.996044, loss: 6.7518
2022-10-02 08:52:38 - train: epoch 0007, iter [06700, 10009], lr: 0.011504, weight_decay: 0.000100, momentum_teacher: 0.996044, loss: 6.5422
2022-10-02 08:53:26 - train: epoch 0007, iter [06800, 10009], lr: 0.011519, weight_decay: 0.000100, momentum_teacher: 0.996044, loss: 6.3760
2022-10-02 08:54:13 - train: epoch 0007, iter [06900, 10009], lr: 0.011534, weight_decay: 0.000100, momentum_teacher: 0.996044, loss: 6.5939
2022-10-02 08:55:01 - train: epoch 0007, iter [07000, 10009], lr: 0.011549, weight_decay: 0.000100, momentum_teacher: 0.996044, loss: 6.4073
2022-10-02 08:55:48 - train: epoch 0007, iter [07100, 10009], lr: 0.011564, weight_decay: 0.000100, momentum_teacher: 0.996044, loss: 6.4944
2022-10-02 08:56:36 - train: epoch 0007, iter [07200, 10009], lr: 0.011579, weight_decay: 0.000100, momentum_teacher: 0.996044, loss: 6.4485
2022-10-02 08:57:23 - train: epoch 0007, iter [07300, 10009], lr: 0.011594, weight_decay: 0.000100, momentum_teacher: 0.996045, loss: 6.4915
2022-10-02 08:58:11 - train: epoch 0007, iter [07400, 10009], lr: 0.011609, weight_decay: 0.000100, momentum_teacher: 0.996045, loss: 6.5264
2022-10-02 08:58:58 - train: epoch 0007, iter [07500, 10009], lr: 0.011624, weight_decay: 0.000100, momentum_teacher: 0.996045, loss: 6.4353
2022-10-02 08:59:46 - train: epoch 0007, iter [07600, 10009], lr: 0.011639, weight_decay: 0.000100, momentum_teacher: 0.996045, loss: 6.5128
2022-10-02 09:00:34 - train: epoch 0007, iter [07700, 10009], lr: 0.011654, weight_decay: 0.000100, momentum_teacher: 0.996045, loss: 6.4773
2022-10-02 09:01:21 - train: epoch 0007, iter [07800, 10009], lr: 0.011669, weight_decay: 0.000100, momentum_teacher: 0.996045, loss: 6.4026
2022-10-02 09:02:09 - train: epoch 0007, iter [07900, 10009], lr: 0.011684, weight_decay: 0.000100, momentum_teacher: 0.996045, loss: 6.3363
2022-10-02 09:02:56 - train: epoch 0007, iter [08000, 10009], lr: 0.011699, weight_decay: 0.000100, momentum_teacher: 0.996045, loss: 6.3521
2022-10-02 09:03:44 - train: epoch 0007, iter [08100, 10009], lr: 0.011714, weight_decay: 0.000100, momentum_teacher: 0.996046, loss: 6.3032
2022-10-02 09:04:31 - train: epoch 0007, iter [08200, 10009], lr: 0.011729, weight_decay: 0.000100, momentum_teacher: 0.996046, loss: 6.4654
2022-10-02 09:05:19 - train: epoch 0007, iter [08300, 10009], lr: 0.011744, weight_decay: 0.000100, momentum_teacher: 0.996046, loss: 6.5062
2022-10-02 09:06:07 - train: epoch 0007, iter [08400, 10009], lr: 0.011759, weight_decay: 0.000100, momentum_teacher: 0.996046, loss: 6.2760
2022-10-02 09:06:54 - train: epoch 0007, iter [08500, 10009], lr: 0.011774, weight_decay: 0.000100, momentum_teacher: 0.996046, loss: 6.4005
2022-10-02 09:07:42 - train: epoch 0007, iter [08600, 10009], lr: 0.011789, weight_decay: 0.000100, momentum_teacher: 0.996046, loss: 6.5377
2022-10-02 09:08:29 - train: epoch 0007, iter [08700, 10009], lr: 0.011804, weight_decay: 0.000100, momentum_teacher: 0.996046, loss: 6.2465
2022-10-02 09:09:17 - train: epoch 0007, iter [08800, 10009], lr: 0.011819, weight_decay: 0.000100, momentum_teacher: 0.996047, loss: 6.4205
2022-10-02 09:10:04 - train: epoch 0007, iter [08900, 10009], lr: 0.011834, weight_decay: 0.000100, momentum_teacher: 0.996047, loss: 6.3241
2022-10-02 09:10:52 - train: epoch 0007, iter [09000, 10009], lr: 0.011849, weight_decay: 0.000100, momentum_teacher: 0.996047, loss: 6.2904
2022-10-02 09:11:39 - train: epoch 0007, iter [09100, 10009], lr: 0.011864, weight_decay: 0.000100, momentum_teacher: 0.996047, loss: 6.4001
2022-10-02 09:12:27 - train: epoch 0007, iter [09200, 10009], lr: 0.011879, weight_decay: 0.000100, momentum_teacher: 0.996047, loss: 6.3011
2022-10-02 09:13:14 - train: epoch 0007, iter [09300, 10009], lr: 0.011894, weight_decay: 0.000100, momentum_teacher: 0.996047, loss: 6.1426
2022-10-02 09:14:02 - train: epoch 0007, iter [09400, 10009], lr: 0.011909, weight_decay: 0.000100, momentum_teacher: 0.996047, loss: 6.2187
2022-10-02 09:14:49 - train: epoch 0007, iter [09500, 10009], lr: 0.011924, weight_decay: 0.000100, momentum_teacher: 0.996047, loss: 6.4233
2022-10-02 09:15:37 - train: epoch 0007, iter [09600, 10009], lr: 0.011939, weight_decay: 0.000100, momentum_teacher: 0.996048, loss: 6.3350
2022-10-02 09:16:25 - train: epoch 0007, iter [09700, 10009], lr: 0.011954, weight_decay: 0.000100, momentum_teacher: 0.996048, loss: 6.1310
2022-10-02 09:17:12 - train: epoch 0007, iter [09800, 10009], lr: 0.011969, weight_decay: 0.000100, momentum_teacher: 0.996048, loss: 6.2359
2022-10-02 09:18:00 - train: epoch 0007, iter [09900, 10009], lr: 0.011984, weight_decay: 0.000100, momentum_teacher: 0.996048, loss: 6.2648
2022-10-02 09:18:47 - train: epoch 0007, iter [10000, 10009], lr: 0.011999, weight_decay: 0.000100, momentum_teacher: 0.996048, loss: 6.4005
2022-10-02 09:18:53 - train: epoch 007, train_loss: 6.7635
2022-10-02 09:18:54 - until epoch: 007, best_loss: 6.7635
2022-10-02 09:18:54 - epoch 008 lr: 0.012000
2022-10-02 09:19:46 - train: epoch 0008, iter [00100, 10009], lr: 0.012015, weight_decay: 0.000100, momentum_teacher: 0.996048, loss: 6.2343
2022-10-02 09:20:34 - train: epoch 0008, iter [00200, 10009], lr: 0.012030, weight_decay: 0.000100, momentum_teacher: 0.996048, loss: 6.2414
2022-10-02 09:21:21 - train: epoch 0008, iter [00300, 10009], lr: 0.012045, weight_decay: 0.000100, momentum_teacher: 0.996049, loss: 6.3851
2022-10-02 09:22:09 - train: epoch 0008, iter [00400, 10009], lr: 0.012060, weight_decay: 0.000100, momentum_teacher: 0.996049, loss: 6.2753
2022-10-02 09:22:56 - train: epoch 0008, iter [00500, 10009], lr: 0.012075, weight_decay: 0.000100, momentum_teacher: 0.996049, loss: 6.2157
2022-10-02 09:23:43 - train: epoch 0008, iter [00600, 10009], lr: 0.012090, weight_decay: 0.000100, momentum_teacher: 0.996049, loss: 6.3184
2022-10-02 09:24:31 - train: epoch 0008, iter [00700, 10009], lr: 0.012105, weight_decay: 0.000100, momentum_teacher: 0.996049, loss: 6.2303
2022-10-02 09:25:18 - train: epoch 0008, iter [00800, 10009], lr: 0.012120, weight_decay: 0.000100, momentum_teacher: 0.996049, loss: 6.2536
2022-10-02 09:26:06 - train: epoch 0008, iter [00900, 10009], lr: 0.012135, weight_decay: 0.000100, momentum_teacher: 0.996049, loss: 6.0847
2022-10-02 09:26:53 - train: epoch 0008, iter [01000, 10009], lr: 0.012150, weight_decay: 0.000100, momentum_teacher: 0.996050, loss: 6.3581
2022-10-02 09:27:40 - train: epoch 0008, iter [01100, 10009], lr: 0.012165, weight_decay: 0.000100, momentum_teacher: 0.996050, loss: 6.2039
2022-10-02 09:28:28 - train: epoch 0008, iter [01200, 10009], lr: 0.012180, weight_decay: 0.000100, momentum_teacher: 0.996050, loss: 6.2399
2022-10-02 09:29:15 - train: epoch 0008, iter [01300, 10009], lr: 0.012195, weight_decay: 0.000100, momentum_teacher: 0.996050, loss: 6.1001
2022-10-02 09:30:03 - train: epoch 0008, iter [01400, 10009], lr: 0.012210, weight_decay: 0.000100, momentum_teacher: 0.996050, loss: 6.1483
2022-10-02 09:30:50 - train: epoch 0008, iter [01500, 10009], lr: 0.012225, weight_decay: 0.000100, momentum_teacher: 0.996050, loss: 6.2263
2022-10-02 09:31:38 - train: epoch 0008, iter [01600, 10009], lr: 0.012240, weight_decay: 0.000100, momentum_teacher: 0.996050, loss: 6.2353
2022-10-02 09:32:25 - train: epoch 0008, iter [01700, 10009], lr: 0.012255, weight_decay: 0.000100, momentum_teacher: 0.996051, loss: 6.2397
2022-10-02 09:33:13 - train: epoch 0008, iter [01800, 10009], lr: 0.012270, weight_decay: 0.000100, momentum_teacher: 0.996051, loss: 6.2624
2022-10-02 09:34:00 - train: epoch 0008, iter [01900, 10009], lr: 0.012285, weight_decay: 0.000100, momentum_teacher: 0.996051, loss: 6.1098
2022-10-02 09:34:47 - train: epoch 0008, iter [02000, 10009], lr: 0.012300, weight_decay: 0.000100, momentum_teacher: 0.996051, loss: 6.2604
2022-10-02 09:35:35 - train: epoch 0008, iter [02100, 10009], lr: 0.012315, weight_decay: 0.000100, momentum_teacher: 0.996051, loss: 6.1741
2022-10-02 09:36:22 - train: epoch 0008, iter [02200, 10009], lr: 0.012330, weight_decay: 0.000100, momentum_teacher: 0.996051, loss: 6.2312
2022-10-02 09:37:09 - train: epoch 0008, iter [02300, 10009], lr: 0.012345, weight_decay: 0.000100, momentum_teacher: 0.996051, loss: 6.0343
2022-10-02 09:37:57 - train: epoch 0008, iter [02400, 10009], lr: 0.012360, weight_decay: 0.000100, momentum_teacher: 0.996052, loss: 6.1744
2022-10-02 09:38:44 - train: epoch 0008, iter [02500, 10009], lr: 0.012375, weight_decay: 0.000100, momentum_teacher: 0.996052, loss: 6.0158
2022-10-02 09:39:32 - train: epoch 0008, iter [02600, 10009], lr: 0.012390, weight_decay: 0.000100, momentum_teacher: 0.996052, loss: 6.3408
2022-10-02 09:40:19 - train: epoch 0008, iter [02700, 10009], lr: 0.012405, weight_decay: 0.000100, momentum_teacher: 0.996052, loss: 6.0890
2022-10-02 09:41:07 - train: epoch 0008, iter [02800, 10009], lr: 0.012420, weight_decay: 0.000100, momentum_teacher: 0.996052, loss: 6.1247
2022-10-02 09:41:54 - train: epoch 0008, iter [02900, 10009], lr: 0.012435, weight_decay: 0.000100, momentum_teacher: 0.996052, loss: 6.1668
2022-10-02 09:42:42 - train: epoch 0008, iter [03000, 10009], lr: 0.012450, weight_decay: 0.000100, momentum_teacher: 0.996052, loss: 6.0663
2022-10-02 09:43:29 - train: epoch 0008, iter [03100, 10009], lr: 0.012465, weight_decay: 0.000100, momentum_teacher: 0.996053, loss: 6.2130
2022-10-02 09:44:16 - train: epoch 0008, iter [03200, 10009], lr: 0.012480, weight_decay: 0.000100, momentum_teacher: 0.996053, loss: 6.1033
2022-10-02 09:45:04 - train: epoch 0008, iter [03300, 10009], lr: 0.012495, weight_decay: 0.000100, momentum_teacher: 0.996053, loss: 6.1461
2022-10-02 09:45:51 - train: epoch 0008, iter [03400, 10009], lr: 0.012510, weight_decay: 0.000100, momentum_teacher: 0.996053, loss: 6.0349
2022-10-02 09:46:39 - train: epoch 0008, iter [03500, 10009], lr: 0.012525, weight_decay: 0.000100, momentum_teacher: 0.996053, loss: 6.2108
2022-10-02 09:47:26 - train: epoch 0008, iter [03600, 10009], lr: 0.012540, weight_decay: 0.000100, momentum_teacher: 0.996053, loss: 6.2179
2022-10-02 09:48:14 - train: epoch 0008, iter [03700, 10009], lr: 0.012555, weight_decay: 0.000100, momentum_teacher: 0.996053, loss: 6.1853
2022-10-02 09:49:01 - train: epoch 0008, iter [03800, 10009], lr: 0.012569, weight_decay: 0.000100, momentum_teacher: 0.996054, loss: 6.0837
2022-10-02 09:49:48 - train: epoch 0008, iter [03900, 10009], lr: 0.012584, weight_decay: 0.000100, momentum_teacher: 0.996054, loss: 6.0857
2022-10-02 09:50:36 - train: epoch 0008, iter [04000, 10009], lr: 0.012599, weight_decay: 0.000100, momentum_teacher: 0.996054, loss: 6.0204
2022-10-02 09:51:23 - train: epoch 0008, iter [04100, 10009], lr: 0.012614, weight_decay: 0.000100, momentum_teacher: 0.996054, loss: 6.0918
2022-10-02 09:52:11 - train: epoch 0008, iter [04200, 10009], lr: 0.012629, weight_decay: 0.000100, momentum_teacher: 0.996054, loss: 6.1322
2022-10-02 09:53:00 - train: epoch 0008, iter [04300, 10009], lr: 0.012644, weight_decay: 0.000100, momentum_teacher: 0.996054, loss: 6.2147
2022-10-02 09:53:48 - train: epoch 0008, iter [04400, 10009], lr: 0.012659, weight_decay: 0.000100, momentum_teacher: 0.996054, loss: 6.1500
2022-10-02 09:54:35 - train: epoch 0008, iter [04500, 10009], lr: 0.012674, weight_decay: 0.000100, momentum_teacher: 0.996055, loss: 6.1018
2022-10-02 09:55:23 - train: epoch 0008, iter [04600, 10009], lr: 0.012689, weight_decay: 0.000100, momentum_teacher: 0.996055, loss: 6.1788
2022-10-02 09:56:10 - train: epoch 0008, iter [04700, 10009], lr: 0.012704, weight_decay: 0.000100, momentum_teacher: 0.996055, loss: 5.9579
2022-10-02 09:56:58 - train: epoch 0008, iter [04800, 10009], lr: 0.012719, weight_decay: 0.000100, momentum_teacher: 0.996055, loss: 6.1135
2022-10-02 09:57:45 - train: epoch 0008, iter [04900, 10009], lr: 0.012734, weight_decay: 0.000100, momentum_teacher: 0.996055, loss: 5.9714
2022-10-02 09:58:33 - train: epoch 0008, iter [05000, 10009], lr: 0.012749, weight_decay: 0.000100, momentum_teacher: 0.996055, loss: 6.0141
2022-10-02 09:59:20 - train: epoch 0008, iter [05100, 10009], lr: 0.012764, weight_decay: 0.000100, momentum_teacher: 0.996055, loss: 6.1356
2022-10-02 10:00:08 - train: epoch 0008, iter [05200, 10009], lr: 0.012779, weight_decay: 0.000100, momentum_teacher: 0.996056, loss: 6.0549
2022-10-02 10:00:55 - train: epoch 0008, iter [05300, 10009], lr: 0.012794, weight_decay: 0.000100, momentum_teacher: 0.996056, loss: 6.1987
2022-10-02 10:01:42 - train: epoch 0008, iter [05400, 10009], lr: 0.012809, weight_decay: 0.000100, momentum_teacher: 0.996056, loss: 6.1272
2022-10-02 10:02:30 - train: epoch 0008, iter [05500, 10009], lr: 0.012824, weight_decay: 0.000100, momentum_teacher: 0.996056, loss: 6.0313
2022-10-02 10:03:17 - train: epoch 0008, iter [05600, 10009], lr: 0.012839, weight_decay: 0.000100, momentum_teacher: 0.996056, loss: 6.1265
2022-10-02 10:04:04 - train: epoch 0008, iter [05700, 10009], lr: 0.012854, weight_decay: 0.000100, momentum_teacher: 0.996056, loss: 6.0307
2022-10-02 10:04:52 - train: epoch 0008, iter [05800, 10009], lr: 0.012869, weight_decay: 0.000100, momentum_teacher: 0.996056, loss: 5.9441
2022-10-02 10:05:39 - train: epoch 0008, iter [05900, 10009], lr: 0.012884, weight_decay: 0.000100, momentum_teacher: 0.996057, loss: 6.0084
2022-10-02 10:06:27 - train: epoch 0008, iter [06000, 10009], lr: 0.012899, weight_decay: 0.000100, momentum_teacher: 0.996057, loss: 6.0263
2022-10-02 10:07:14 - train: epoch 0008, iter [06100, 10009], lr: 0.012914, weight_decay: 0.000100, momentum_teacher: 0.996057, loss: 6.0323
2022-10-02 10:08:02 - train: epoch 0008, iter [06200, 10009], lr: 0.012929, weight_decay: 0.000100, momentum_teacher: 0.996057, loss: 5.9952
2022-10-02 10:08:49 - train: epoch 0008, iter [06300, 10009], lr: 0.012944, weight_decay: 0.000100, momentum_teacher: 0.996057, loss: 6.0858
2022-10-02 10:09:37 - train: epoch 0008, iter [06400, 10009], lr: 0.012959, weight_decay: 0.000100, momentum_teacher: 0.996057, loss: 5.8765
2022-10-02 10:10:24 - train: epoch 0008, iter [06500, 10009], lr: 0.012974, weight_decay: 0.000100, momentum_teacher: 0.996057, loss: 6.0525
2022-10-02 10:11:13 - train: epoch 0008, iter [06600, 10009], lr: 0.012989, weight_decay: 0.000100, momentum_teacher: 0.996058, loss: 5.8879
2022-10-02 10:12:01 - train: epoch 0008, iter [06700, 10009], lr: 0.013004, weight_decay: 0.000100, momentum_teacher: 0.996058, loss: 6.0754
2022-10-02 10:12:48 - train: epoch 0008, iter [06800, 10009], lr: 0.013019, weight_decay: 0.000100, momentum_teacher: 0.996058, loss: 5.9665
2022-10-02 10:13:38 - train: epoch 0008, iter [06900, 10009], lr: 0.013034, weight_decay: 0.000100, momentum_teacher: 0.996058, loss: 6.0512
2022-10-02 10:14:25 - train: epoch 0008, iter [07000, 10009], lr: 0.013049, weight_decay: 0.000100, momentum_teacher: 0.996058, loss: 5.8767
2022-10-02 10:15:13 - train: epoch 0008, iter [07100, 10009], lr: 0.013064, weight_decay: 0.000100, momentum_teacher: 0.996058, loss: 6.0184
2022-10-02 10:16:00 - train: epoch 0008, iter [07200, 10009], lr: 0.013079, weight_decay: 0.000100, momentum_teacher: 0.996059, loss: 6.0637
2022-10-02 10:16:48 - train: epoch 0008, iter [07300, 10009], lr: 0.013094, weight_decay: 0.000100, momentum_teacher: 0.996059, loss: 6.0823
2022-10-02 10:17:35 - train: epoch 0008, iter [07400, 10009], lr: 0.013109, weight_decay: 0.000100, momentum_teacher: 0.996059, loss: 5.7065
2022-10-02 10:18:22 - train: epoch 0008, iter [07500, 10009], lr: 0.013124, weight_decay: 0.000100, momentum_teacher: 0.996059, loss: 5.9489
2022-10-02 10:19:10 - train: epoch 0008, iter [07600, 10009], lr: 0.013139, weight_decay: 0.000100, momentum_teacher: 0.996059, loss: 5.9458
2022-10-02 10:19:57 - train: epoch 0008, iter [07700, 10009], lr: 0.013154, weight_decay: 0.000100, momentum_teacher: 0.996059, loss: 5.9591
2022-10-02 10:20:45 - train: epoch 0008, iter [07800, 10009], lr: 0.013169, weight_decay: 0.000100, momentum_teacher: 0.996059, loss: 5.8787
2022-10-02 10:21:32 - train: epoch 0008, iter [07900, 10009], lr: 0.013184, weight_decay: 0.000100, momentum_teacher: 0.996060, loss: 6.0762
2022-10-02 10:22:19 - train: epoch 0008, iter [08000, 10009], lr: 0.013199, weight_decay: 0.000100, momentum_teacher: 0.996060, loss: 5.9644
2022-10-02 10:23:07 - train: epoch 0008, iter [08100, 10009], lr: 0.013214, weight_decay: 0.000100, momentum_teacher: 0.996060, loss: 5.9660
2022-10-02 10:23:54 - train: epoch 0008, iter [08200, 10009], lr: 0.013229, weight_decay: 0.000100, momentum_teacher: 0.996060, loss: 6.0868
2022-10-02 10:24:42 - train: epoch 0008, iter [08300, 10009], lr: 0.013244, weight_decay: 0.000100, momentum_teacher: 0.996060, loss: 5.8411
2022-10-02 10:25:32 - train: epoch 0008, iter [08400, 10009], lr: 0.013259, weight_decay: 0.000100, momentum_teacher: 0.996060, loss: 5.9278
2022-10-02 10:26:19 - train: epoch 0008, iter [08500, 10009], lr: 0.013274, weight_decay: 0.000100, momentum_teacher: 0.996060, loss: 5.9152
2022-10-02 10:27:08 - train: epoch 0008, iter [08600, 10009], lr: 0.013289, weight_decay: 0.000100, momentum_teacher: 0.996061, loss: 6.0698
2022-10-02 10:27:59 - train: epoch 0008, iter [08700, 10009], lr: 0.013304, weight_decay: 0.000100, momentum_teacher: 0.996061, loss: 5.8133
2022-10-02 10:28:52 - train: epoch 0008, iter [08800, 10009], lr: 0.013319, weight_decay: 0.000100, momentum_teacher: 0.996061, loss: 5.8793
2022-10-02 10:29:43 - train: epoch 0008, iter [08900, 10009], lr: 0.013334, weight_decay: 0.000100, momentum_teacher: 0.996061, loss: 5.8262
2022-10-02 10:30:36 - train: epoch 0008, iter [09000, 10009], lr: 0.013349, weight_decay: 0.000100, momentum_teacher: 0.996061, loss: 6.0602
2022-10-02 10:31:33 - train: epoch 0008, iter [09100, 10009], lr: 0.013364, weight_decay: 0.000100, momentum_teacher: 0.996061, loss: 5.9430
2022-10-02 10:32:32 - train: epoch 0008, iter [09200, 10009], lr: 0.013379, weight_decay: 0.000100, momentum_teacher: 0.996062, loss: 5.8862
2022-10-02 10:33:27 - train: epoch 0008, iter [09300, 10009], lr: 0.013394, weight_decay: 0.000100, momentum_teacher: 0.996062, loss: 5.8777
2022-10-02 10:34:18 - train: epoch 0008, iter [09400, 10009], lr: 0.013409, weight_decay: 0.000100, momentum_teacher: 0.996062, loss: 5.9197
2022-10-02 10:35:09 - train: epoch 0008, iter [09500, 10009], lr: 0.013424, weight_decay: 0.000100, momentum_teacher: 0.996062, loss: 5.9326
2022-10-02 10:36:00 - train: epoch 0008, iter [09600, 10009], lr: 0.013439, weight_decay: 0.000100, momentum_teacher: 0.996062, loss: 5.9115
2022-10-02 10:37:00 - train: epoch 0008, iter [09700, 10009], lr: 0.013454, weight_decay: 0.000100, momentum_teacher: 0.996062, loss: 5.7871
2022-10-02 10:37:53 - train: epoch 0008, iter [09800, 10009], lr: 0.013469, weight_decay: 0.000100, momentum_teacher: 0.996063, loss: 5.8217
2022-10-02 10:38:52 - train: epoch 0008, iter [09900, 10009], lr: 0.013484, weight_decay: 0.000100, momentum_teacher: 0.996063, loss: 6.0361
2022-10-02 10:39:48 - train: epoch 0008, iter [10000, 10009], lr: 0.013499, weight_decay: 0.000100, momentum_teacher: 0.996063, loss: 5.9693
2022-10-02 10:39:53 - train: epoch 008, train_loss: 6.0622
2022-10-02 10:39:55 - until epoch: 008, best_loss: 6.0622
2022-10-02 10:39:55 - epoch 009 lr: 0.013500
2022-10-02 10:40:49 - train: epoch 0009, iter [00100, 10009], lr: 0.013515, weight_decay: 0.000100, momentum_teacher: 0.996063, loss: 6.0142
2022-10-02 10:41:37 - train: epoch 0009, iter [00200, 10009], lr: 0.013530, weight_decay: 0.000100, momentum_teacher: 0.996063, loss: 5.8266
2022-10-02 10:42:26 - train: epoch 0009, iter [00300, 10009], lr: 0.013545, weight_decay: 0.000100, momentum_teacher: 0.996063, loss: 5.8409
2022-10-02 10:43:24 - train: epoch 0009, iter [00400, 10009], lr: 0.013560, weight_decay: 0.000100, momentum_teacher: 0.996063, loss: 5.7103
2022-10-02 10:44:19 - train: epoch 0009, iter [00500, 10009], lr: 0.013575, weight_decay: 0.000100, momentum_teacher: 0.996064, loss: 5.8905
2022-10-02 10:45:18 - train: epoch 0009, iter [00600, 10009], lr: 0.013590, weight_decay: 0.000100, momentum_teacher: 0.996064, loss: 5.7619
2022-10-02 10:46:14 - train: epoch 0009, iter [00700, 10009], lr: 0.013605, weight_decay: 0.000100, momentum_teacher: 0.996064, loss: 5.9385
2022-10-02 10:47:04 - train: epoch 0009, iter [00800, 10009], lr: 0.013620, weight_decay: 0.000100, momentum_teacher: 0.996064, loss: 5.9342
2022-10-02 10:48:06 - train: epoch 0009, iter [00900, 10009], lr: 0.013635, weight_decay: 0.000100, momentum_teacher: 0.996064, loss: 5.7753
2022-10-02 10:49:04 - train: epoch 0009, iter [01000, 10009], lr: 0.013650, weight_decay: 0.000100, momentum_teacher: 0.996064, loss: 5.8330
2022-10-02 10:49:54 - train: epoch 0009, iter [01100, 10009], lr: 0.013665, weight_decay: 0.000100, momentum_teacher: 0.996065, loss: 5.6911
2022-10-02 10:50:43 - train: epoch 0009, iter [01200, 10009], lr: 0.013680, weight_decay: 0.000100, momentum_teacher: 0.996065, loss: 5.6649
2022-10-02 10:51:31 - train: epoch 0009, iter [01300, 10009], lr: 0.013695, weight_decay: 0.000100, momentum_teacher: 0.996065, loss: 6.0490
2022-10-02 10:52:22 - train: epoch 0009, iter [01400, 10009], lr: 0.013710, weight_decay: 0.000100, momentum_teacher: 0.996065, loss: 5.8225
2022-10-02 10:53:12 - train: epoch 0009, iter [01500, 10009], lr: 0.013725, weight_decay: 0.000100, momentum_teacher: 0.996065, loss: 5.8203
2022-10-02 10:54:00 - train: epoch 0009, iter [01600, 10009], lr: 0.013740, weight_decay: 0.000100, momentum_teacher: 0.996065, loss: 5.7432
2022-10-02 10:54:57 - train: epoch 0009, iter [01700, 10009], lr: 0.013755, weight_decay: 0.000100, momentum_teacher: 0.996066, loss: 5.8562
2022-10-02 10:55:59 - train: epoch 0009, iter [01800, 10009], lr: 0.013770, weight_decay: 0.000100, momentum_teacher: 0.996066, loss: 5.7530
2022-10-02 10:56:57 - train: epoch 0009, iter [01900, 10009], lr: 0.013785, weight_decay: 0.000100, momentum_teacher: 0.996066, loss: 5.5367
2022-10-02 10:57:58 - train: epoch 0009, iter [02000, 10009], lr: 0.013800, weight_decay: 0.000100, momentum_teacher: 0.996066, loss: 5.7942
2022-10-02 10:58:50 - train: epoch 0009, iter [02100, 10009], lr: 0.013815, weight_decay: 0.000100, momentum_teacher: 0.996066, loss: 5.8495
2022-10-02 10:59:51 - train: epoch 0009, iter [02200, 10009], lr: 0.013830, weight_decay: 0.000100, momentum_teacher: 0.996066, loss: 5.8301
2022-10-02 11:00:53 - train: epoch 0009, iter [02300, 10009], lr: 0.013845, weight_decay: 0.000100, momentum_teacher: 0.996066, loss: 5.7881
2022-10-02 11:01:51 - train: epoch 0009, iter [02400, 10009], lr: 0.013860, weight_decay: 0.000100, momentum_teacher: 0.996067, loss: 5.8840
2022-10-02 11:02:50 - train: epoch 0009, iter [02500, 10009], lr: 0.013875, weight_decay: 0.000100, momentum_teacher: 0.996067, loss: 5.6505
2022-10-02 11:03:52 - train: epoch 0009, iter [02600, 10009], lr: 0.013890, weight_decay: 0.000100, momentum_teacher: 0.996067, loss: 5.7006
2022-10-02 11:04:45 - train: epoch 0009, iter [02700, 10009], lr: 0.013905, weight_decay: 0.000100, momentum_teacher: 0.996067, loss: 5.8122
2022-10-02 11:05:44 - train: epoch 0009, iter [02800, 10009], lr: 0.013920, weight_decay: 0.000100, momentum_teacher: 0.996067, loss: 5.8268
2022-10-02 11:06:38 - train: epoch 0009, iter [02900, 10009], lr: 0.013935, weight_decay: 0.000100, momentum_teacher: 0.996067, loss: 5.6798
2022-10-02 11:07:32 - train: epoch 0009, iter [03000, 10009], lr: 0.013950, weight_decay: 0.000100, momentum_teacher: 0.996068, loss: 5.7742
2022-10-02 11:08:21 - train: epoch 0009, iter [03100, 10009], lr: 0.013965, weight_decay: 0.000100, momentum_teacher: 0.996068, loss: 5.6321
2022-10-02 11:09:13 - train: epoch 0009, iter [03200, 10009], lr: 0.013980, weight_decay: 0.000100, momentum_teacher: 0.996068, loss: 5.7856
2022-10-02 11:10:03 - train: epoch 0009, iter [03300, 10009], lr: 0.013995, weight_decay: 0.000100, momentum_teacher: 0.996068, loss: 5.7730
2022-10-02 11:11:02 - train: epoch 0009, iter [03400, 10009], lr: 0.014010, weight_decay: 0.000100, momentum_teacher: 0.996068, loss: 5.7497
2022-10-02 11:11:52 - train: epoch 0009, iter [03500, 10009], lr: 0.014025, weight_decay: 0.000100, momentum_teacher: 0.996068, loss: 5.8480
2022-10-02 11:12:42 - train: epoch 0009, iter [03600, 10009], lr: 0.014040, weight_decay: 0.000100, momentum_teacher: 0.996069, loss: 5.5958
2022-10-02 11:13:41 - train: epoch 0009, iter [03700, 10009], lr: 0.014055, weight_decay: 0.000100, momentum_teacher: 0.996069, loss: 5.6303
2022-10-02 11:14:42 - train: epoch 0009, iter [03800, 10009], lr: 0.014069, weight_decay: 0.000100, momentum_teacher: 0.996069, loss: 5.6275
2022-10-02 11:15:42 - train: epoch 0009, iter [03900, 10009], lr: 0.014084, weight_decay: 0.000100, momentum_teacher: 0.996069, loss: 5.6498
2022-10-02 11:16:49 - train: epoch 0009, iter [04000, 10009], lr: 0.014099, weight_decay: 0.000100, momentum_teacher: 0.996069, loss: 5.6870
2022-10-02 11:17:53 - train: epoch 0009, iter [04100, 10009], lr: 0.014114, weight_decay: 0.000100, momentum_teacher: 0.996069, loss: 5.7891
2022-10-02 11:19:04 - train: epoch 0009, iter [04200, 10009], lr: 0.014129, weight_decay: 0.000100, momentum_teacher: 0.996070, loss: 5.6921
2022-10-02 11:20:18 - train: epoch 0009, iter [04300, 10009], lr: 0.014144, weight_decay: 0.000100, momentum_teacher: 0.996070, loss: 5.5202
2022-10-02 11:21:20 - train: epoch 0009, iter [04400, 10009], lr: 0.014159, weight_decay: 0.000100, momentum_teacher: 0.996070, loss: 5.7182
2022-10-02 11:22:35 - train: epoch 0009, iter [04500, 10009], lr: 0.014174, weight_decay: 0.000100, momentum_teacher: 0.996070, loss: 5.7349
2022-10-02 11:23:36 - train: epoch 0009, iter [04600, 10009], lr: 0.014189, weight_decay: 0.000100, momentum_teacher: 0.996070, loss: 5.5282
2022-10-02 11:24:53 - train: epoch 0009, iter [04700, 10009], lr: 0.014204, weight_decay: 0.000100, momentum_teacher: 0.996070, loss: 5.5536
2022-10-02 11:26:25 - train: epoch 0009, iter [04800, 10009], lr: 0.014219, weight_decay: 0.000100, momentum_teacher: 0.996071, loss: 5.6905
2022-10-02 11:27:38 - train: epoch 0009, iter [04900, 10009], lr: 0.014234, weight_decay: 0.000100, momentum_teacher: 0.996071, loss: 5.8099
2022-10-02 11:29:16 - train: epoch 0009, iter [05000, 10009], lr: 0.014249, weight_decay: 0.000100, momentum_teacher: 0.996071, loss: 5.5108
2022-10-02 11:30:12 - train: epoch 0009, iter [05100, 10009], lr: 0.014264, weight_decay: 0.000100, momentum_teacher: 0.996071, loss: 5.6765
2022-10-02 11:31:09 - train: epoch 0009, iter [05200, 10009], lr: 0.014279, weight_decay: 0.000100, momentum_teacher: 0.996071, loss: 5.6091
2022-10-02 11:32:26 - train: epoch 0009, iter [05300, 10009], lr: 0.014294, weight_decay: 0.000100, momentum_teacher: 0.996071, loss: 5.6882
2022-10-02 11:33:40 - train: epoch 0009, iter [05400, 10009], lr: 0.014309, weight_decay: 0.000100, momentum_teacher: 0.996072, loss: 5.4873
2022-10-02 11:34:56 - train: epoch 0009, iter [05500, 10009], lr: 0.014324, weight_decay: 0.000100, momentum_teacher: 0.996072, loss: 5.6921
2022-10-02 11:36:08 - train: epoch 0009, iter [05600, 10009], lr: 0.014339, weight_decay: 0.000100, momentum_teacher: 0.996072, loss: 5.6381
2022-10-02 11:37:36 - train: epoch 0009, iter [05700, 10009], lr: 0.014354, weight_decay: 0.000100, momentum_teacher: 0.996072, loss: 5.6128
2022-10-02 11:38:46 - train: epoch 0009, iter [05800, 10009], lr: 0.014369, weight_decay: 0.000100, momentum_teacher: 0.996072, loss: 5.5767
2022-10-02 11:40:08 - train: epoch 0009, iter [05900, 10009], lr: 0.014384, weight_decay: 0.000100, momentum_teacher: 0.996072, loss: 5.5146
2022-10-02 11:41:20 - train: epoch 0009, iter [06000, 10009], lr: 0.014399, weight_decay: 0.000100, momentum_teacher: 0.996073, loss: 5.6378
2022-10-02 11:42:37 - train: epoch 0009, iter [06100, 10009], lr: 0.014414, weight_decay: 0.000100, momentum_teacher: 0.996073, loss: 5.7718
2022-10-02 11:43:49 - train: epoch 0009, iter [06200, 10009], lr: 0.014429, weight_decay: 0.000100, momentum_teacher: 0.996073, loss: 5.5836
2022-10-02 11:45:28 - train: epoch 0009, iter [06300, 10009], lr: 0.014444, weight_decay: 0.000100, momentum_teacher: 0.996073, loss: 5.6488
2022-10-02 11:46:41 - train: epoch 0009, iter [06400, 10009], lr: 0.014459, weight_decay: 0.000100, momentum_teacher: 0.996073, loss: 5.6040
2022-10-02 11:48:03 - train: epoch 0009, iter [06500, 10009], lr: 0.014474, weight_decay: 0.000100, momentum_teacher: 0.996073, loss: 5.4984
2022-10-02 11:49:17 - train: epoch 0009, iter [06600, 10009], lr: 0.014489, weight_decay: 0.000100, momentum_teacher: 0.996074, loss: 5.4472
2022-10-02 11:50:17 - train: epoch 0009, iter [06700, 10009], lr: 0.014504, weight_decay: 0.000100, momentum_teacher: 0.996074, loss: 5.5819
2022-10-02 11:51:06 - train: epoch 0009, iter [06800, 10009], lr: 0.014519, weight_decay: 0.000100, momentum_teacher: 0.996074, loss: 5.4603
2022-10-02 11:51:56 - train: epoch 0009, iter [06900, 10009], lr: 0.014534, weight_decay: 0.000100, momentum_teacher: 0.996074, loss: 5.6882
2022-10-02 11:52:43 - train: epoch 0009, iter [07000, 10009], lr: 0.014549, weight_decay: 0.000100, momentum_teacher: 0.996074, loss: 5.6422
2022-10-02 11:53:31 - train: epoch 0009, iter [07100, 10009], lr: 0.014564, weight_decay: 0.000100, momentum_teacher: 0.996074, loss: 5.6288
2022-10-02 11:54:18 - train: epoch 0009, iter [07200, 10009], lr: 0.014579, weight_decay: 0.000100, momentum_teacher: 0.996075, loss: 5.5334
2022-10-02 11:55:05 - train: epoch 0009, iter [07300, 10009], lr: 0.014594, weight_decay: 0.000100, momentum_teacher: 0.996075, loss: 5.4779
2022-10-02 11:55:53 - train: epoch 0009, iter [07400, 10009], lr: 0.014609, weight_decay: 0.000100, momentum_teacher: 0.996075, loss: 5.6451
2022-10-02 11:56:41 - train: epoch 0009, iter [07500, 10009], lr: 0.014624, weight_decay: 0.000100, momentum_teacher: 0.996075, loss: 5.3561
2022-10-02 11:57:28 - train: epoch 0009, iter [07600, 10009], lr: 0.014639, weight_decay: 0.000100, momentum_teacher: 0.996075, loss: 5.5638
2022-10-02 11:58:16 - train: epoch 0009, iter [07700, 10009], lr: 0.014654, weight_decay: 0.000100, momentum_teacher: 0.996075, loss: 5.5783
2022-10-02 11:59:03 - train: epoch 0009, iter [07800, 10009], lr: 0.014669, weight_decay: 0.000100, momentum_teacher: 0.996076, loss: 5.4933
2022-10-02 11:59:50 - train: epoch 0009, iter [07900, 10009], lr: 0.014684, weight_decay: 0.000100, momentum_teacher: 0.996076, loss: 5.6756
2022-10-02 12:00:38 - train: epoch 0009, iter [08000, 10009], lr: 0.014699, weight_decay: 0.000100, momentum_teacher: 0.996076, loss: 5.5644
2022-10-02 12:01:25 - train: epoch 0009, iter [08100, 10009], lr: 0.014714, weight_decay: 0.000100, momentum_teacher: 0.996076, loss: 5.4900
2022-10-02 12:02:13 - train: epoch 0009, iter [08200, 10009], lr: 0.014729, weight_decay: 0.000100, momentum_teacher: 0.996076, loss: 5.7360
2022-10-02 12:03:00 - train: epoch 0009, iter [08300, 10009], lr: 0.014744, weight_decay: 0.000100, momentum_teacher: 0.996076, loss: 5.6517
2022-10-02 12:03:48 - train: epoch 0009, iter [08400, 10009], lr: 0.014759, weight_decay: 0.000100, momentum_teacher: 0.996077, loss: 5.4587
2022-10-02 12:04:35 - train: epoch 0009, iter [08500, 10009], lr: 0.014774, weight_decay: 0.000100, momentum_teacher: 0.996077, loss: 5.6183
2022-10-02 12:05:23 - train: epoch 0009, iter [08600, 10009], lr: 0.014789, weight_decay: 0.000100, momentum_teacher: 0.996077, loss: 5.4839
2022-10-02 12:06:10 - train: epoch 0009, iter [08700, 10009], lr: 0.014804, weight_decay: 0.000100, momentum_teacher: 0.996077, loss: 5.5383
2022-10-02 12:06:57 - train: epoch 0009, iter [08800, 10009], lr: 0.014819, weight_decay: 0.000100, momentum_teacher: 0.996077, loss: 5.5408
2022-10-02 12:07:45 - train: epoch 0009, iter [08900, 10009], lr: 0.014834, weight_decay: 0.000100, momentum_teacher: 0.996077, loss: 5.5810
2022-10-02 12:08:32 - train: epoch 0009, iter [09000, 10009], lr: 0.014849, weight_decay: 0.000100, momentum_teacher: 0.996078, loss: 5.5556
2022-10-02 12:09:20 - train: epoch 0009, iter [09100, 10009], lr: 0.014864, weight_decay: 0.000100, momentum_teacher: 0.996078, loss: 5.5393
2022-10-02 12:10:07 - train: epoch 0009, iter [09200, 10009], lr: 0.014879, weight_decay: 0.000100, momentum_teacher: 0.996078, loss: 5.5307
2022-10-02 12:10:55 - train: epoch 0009, iter [09300, 10009], lr: 0.014894, weight_decay: 0.000100, momentum_teacher: 0.996078, loss: 5.7673
2022-10-02 12:11:46 - train: epoch 0009, iter [09400, 10009], lr: 0.014909, weight_decay: 0.000100, momentum_teacher: 0.996078, loss: 5.6190
2022-10-02 12:12:33 - train: epoch 0009, iter [09500, 10009], lr: 0.014924, weight_decay: 0.000100, momentum_teacher: 0.996079, loss: 5.5596
2022-10-02 12:13:21 - train: epoch 0009, iter [09600, 10009], lr: 0.014939, weight_decay: 0.000100, momentum_teacher: 0.996079, loss: 5.6443
2022-10-02 12:14:08 - train: epoch 0009, iter [09700, 10009], lr: 0.014954, weight_decay: 0.000100, momentum_teacher: 0.996079, loss: 5.4395
2022-10-02 12:14:56 - train: epoch 0009, iter [09800, 10009], lr: 0.014969, weight_decay: 0.000100, momentum_teacher: 0.996079, loss: 5.5917
2022-10-02 12:15:43 - train: epoch 0009, iter [09900, 10009], lr: 0.014984, weight_decay: 0.000100, momentum_teacher: 0.996079, loss: 5.4889
2022-10-02 12:16:31 - train: epoch 0009, iter [10000, 10009], lr: 0.014999, weight_decay: 0.000100, momentum_teacher: 0.996079, loss: 5.4842
2022-10-02 12:16:36 - train: epoch 009, train_loss: 5.6706
2022-10-02 12:16:38 - until epoch: 009, best_loss: 5.6706
2022-10-02 12:16:38 - epoch 010 lr: 0.015000
2022-10-02 12:17:29 - train: epoch 0010, iter [00100, 10009], lr: 0.015015, weight_decay: 0.000100, momentum_teacher: 0.996080, loss: 5.6291
2022-10-02 12:18:17 - train: epoch 0010, iter [00200, 10009], lr: 0.015030, weight_decay: 0.000100, momentum_teacher: 0.996080, loss: 5.5206
2022-10-02 12:19:04 - train: epoch 0010, iter [00300, 10009], lr: 0.015045, weight_decay: 0.000100, momentum_teacher: 0.996080, loss: 5.6554
2022-10-02 12:19:51 - train: epoch 0010, iter [00400, 10009], lr: 0.015060, weight_decay: 0.000100, momentum_teacher: 0.996080, loss: 5.6333
2022-10-02 12:20:39 - train: epoch 0010, iter [00500, 10009], lr: 0.015075, weight_decay: 0.000100, momentum_teacher: 0.996080, loss: 5.5742
2022-10-02 12:21:26 - train: epoch 0010, iter [00600, 10009], lr: 0.015090, weight_decay: 0.000100, momentum_teacher: 0.996080, loss: 5.4639
2022-10-02 12:22:13 - train: epoch 0010, iter [00700, 10009], lr: 0.015105, weight_decay: 0.000100, momentum_teacher: 0.996081, loss: 5.5928
2022-10-02 12:23:01 - train: epoch 0010, iter [00800, 10009], lr: 0.015120, weight_decay: 0.000100, momentum_teacher: 0.996081, loss: 5.4444
2022-10-02 12:23:48 - train: epoch 0010, iter [00900, 10009], lr: 0.015135, weight_decay: 0.000100, momentum_teacher: 0.996081, loss: 5.3832
2022-10-02 12:24:36 - train: epoch 0010, iter [01000, 10009], lr: 0.015150, weight_decay: 0.000100, momentum_teacher: 0.996081, loss: 5.4769
2022-10-02 12:25:23 - train: epoch 0010, iter [01100, 10009], lr: 0.015165, weight_decay: 0.000100, momentum_teacher: 0.996081, loss: 5.5151
2022-10-02 12:26:11 - train: epoch 0010, iter [01200, 10009], lr: 0.015180, weight_decay: 0.000100, momentum_teacher: 0.996082, loss: 5.4389
2022-10-02 12:26:58 - train: epoch 0010, iter [01300, 10009], lr: 0.015195, weight_decay: 0.000100, momentum_teacher: 0.996082, loss: 5.4129
2022-10-02 12:27:46 - train: epoch 0010, iter [01400, 10009], lr: 0.015210, weight_decay: 0.000100, momentum_teacher: 0.996082, loss: 5.5199
2022-10-02 12:28:34 - train: epoch 0010, iter [01500, 10009], lr: 0.015225, weight_decay: 0.000100, momentum_teacher: 0.996082, loss: 5.5492
2022-10-02 12:29:21 - train: epoch 0010, iter [01600, 10009], lr: 0.015240, weight_decay: 0.000100, momentum_teacher: 0.996082, loss: 5.4609
2022-10-02 12:30:08 - train: epoch 0010, iter [01700, 10009], lr: 0.015255, weight_decay: 0.000100, momentum_teacher: 0.996082, loss: 5.3538
2022-10-02 12:30:56 - train: epoch 0010, iter [01800, 10009], lr: 0.015270, weight_decay: 0.000100, momentum_teacher: 0.996083, loss: 5.3000
2022-10-02 12:31:43 - train: epoch 0010, iter [01900, 10009], lr: 0.015285, weight_decay: 0.000100, momentum_teacher: 0.996083, loss: 5.4032
2022-10-02 12:32:31 - train: epoch 0010, iter [02000, 10009], lr: 0.015300, weight_decay: 0.000100, momentum_teacher: 0.996083, loss: 5.4011
2022-10-02 12:33:18 - train: epoch 0010, iter [02100, 10009], lr: 0.015315, weight_decay: 0.000100, momentum_teacher: 0.996083, loss: 5.5238
2022-10-02 12:34:05 - train: epoch 0010, iter [02200, 10009], lr: 0.015330, weight_decay: 0.000100, momentum_teacher: 0.996083, loss: 5.4191
2022-10-02 12:34:52 - train: epoch 0010, iter [02300, 10009], lr: 0.015345, weight_decay: 0.000100, momentum_teacher: 0.996083, loss: 5.4369
2022-10-02 12:35:40 - train: epoch 0010, iter [02400, 10009], lr: 0.015360, weight_decay: 0.000100, momentum_teacher: 0.996084, loss: 5.4596
2022-10-02 12:36:27 - train: epoch 0010, iter [02500, 10009], lr: 0.015375, weight_decay: 0.000100, momentum_teacher: 0.996084, loss: 5.3720
2022-10-02 12:37:15 - train: epoch 0010, iter [02600, 10009], lr: 0.015390, weight_decay: 0.000100, momentum_teacher: 0.996084, loss: 5.3605
2022-10-02 12:38:02 - train: epoch 0010, iter [02700, 10009], lr: 0.015405, weight_decay: 0.000100, momentum_teacher: 0.996084, loss: 5.4620
2022-10-02 12:38:50 - train: epoch 0010, iter [02800, 10009], lr: 0.015420, weight_decay: 0.000100, momentum_teacher: 0.996084, loss: 5.4573
2022-10-02 12:39:37 - train: epoch 0010, iter [02900, 10009], lr: 0.015435, weight_decay: 0.000100, momentum_teacher: 0.996085, loss: 5.6424
2022-10-02 12:40:25 - train: epoch 0010, iter [03000, 10009], lr: 0.015450, weight_decay: 0.000100, momentum_teacher: 0.996085, loss: 5.3369
2022-10-02 12:41:12 - train: epoch 0010, iter [03100, 10009], lr: 0.015465, weight_decay: 0.000100, momentum_teacher: 0.996085, loss: 5.3245
2022-10-02 12:42:00 - train: epoch 0010, iter [03200, 10009], lr: 0.015480, weight_decay: 0.000100, momentum_teacher: 0.996085, loss: 5.6050
2022-10-02 12:42:47 - train: epoch 0010, iter [03300, 10009], lr: 0.015495, weight_decay: 0.000100, momentum_teacher: 0.996085, loss: 5.3938
2022-10-02 12:43:34 - train: epoch 0010, iter [03400, 10009], lr: 0.015510, weight_decay: 0.000100, momentum_teacher: 0.996085, loss: 5.2510
2022-10-02 12:44:22 - train: epoch 0010, iter [03500, 10009], lr: 0.015525, weight_decay: 0.000100, momentum_teacher: 0.996086, loss: 5.4502
2022-10-02 12:45:09 - train: epoch 0010, iter [03600, 10009], lr: 0.015540, weight_decay: 0.000100, momentum_teacher: 0.996086, loss: 5.4166
2022-10-02 12:45:57 - train: epoch 0010, iter [03700, 10009], lr: 0.015555, weight_decay: 0.000100, momentum_teacher: 0.996086, loss: 5.5293
2022-10-02 12:46:44 - train: epoch 0010, iter [03800, 10009], lr: 0.015569, weight_decay: 0.000100, momentum_teacher: 0.996086, loss: 5.2565
2022-10-02 12:47:32 - train: epoch 0010, iter [03900, 10009], lr: 0.015584, weight_decay: 0.000100, momentum_teacher: 0.996086, loss: 5.3931
2022-10-02 12:48:21 - train: epoch 0010, iter [04000, 10009], lr: 0.015599, weight_decay: 0.000100, momentum_teacher: 0.996087, loss: 5.4321
2022-10-02 12:49:09 - train: epoch 0010, iter [04100, 10009], lr: 0.015614, weight_decay: 0.000100, momentum_teacher: 0.996087, loss: 5.4416
2022-10-02 12:49:56 - train: epoch 0010, iter [04200, 10009], lr: 0.015629, weight_decay: 0.000100, momentum_teacher: 0.996087, loss: 5.2516
2022-10-02 12:50:44 - train: epoch 0010, iter [04300, 10009], lr: 0.015644, weight_decay: 0.000100, momentum_teacher: 0.996087, loss: 5.3323
2022-10-02 12:51:32 - train: epoch 0010, iter [04400, 10009], lr: 0.015659, weight_decay: 0.000100, momentum_teacher: 0.996087, loss: 5.3964
2022-10-02 12:52:19 - train: epoch 0010, iter [04500, 10009], lr: 0.015674, weight_decay: 0.000100, momentum_teacher: 0.996087, loss: 5.3177
2022-10-02 12:53:07 - train: epoch 0010, iter [04600, 10009], lr: 0.015689, weight_decay: 0.000100, momentum_teacher: 0.996088, loss: 5.4703
2022-10-02 12:53:55 - train: epoch 0010, iter [04700, 10009], lr: 0.015704, weight_decay: 0.000100, momentum_teacher: 0.996088, loss: 5.5454
2022-10-02 12:54:42 - train: epoch 0010, iter [04800, 10009], lr: 0.015719, weight_decay: 0.000100, momentum_teacher: 0.996088, loss: 5.4059
2022-10-02 12:55:30 - train: epoch 0010, iter [04900, 10009], lr: 0.015734, weight_decay: 0.000100, momentum_teacher: 0.996088, loss: 5.5730
2022-10-02 12:56:17 - train: epoch 0010, iter [05000, 10009], lr: 0.015749, weight_decay: 0.000100, momentum_teacher: 0.996088, loss: 5.3232
2022-10-02 12:57:05 - train: epoch 0010, iter [05100, 10009], lr: 0.015764, weight_decay: 0.000100, momentum_teacher: 0.996089, loss: 5.5702
2022-10-02 12:57:53 - train: epoch 0010, iter [05200, 10009], lr: 0.015779, weight_decay: 0.000100, momentum_teacher: 0.996089, loss: 5.3564
2022-10-02 12:58:41 - train: epoch 0010, iter [05300, 10009], lr: 0.015794, weight_decay: 0.000100, momentum_teacher: 0.996089, loss: 5.3155
2022-10-02 12:59:29 - train: epoch 0010, iter [05400, 10009], lr: 0.015809, weight_decay: 0.000100, momentum_teacher: 0.996089, loss: 5.4402
2022-10-02 13:00:17 - train: epoch 0010, iter [05500, 10009], lr: 0.015824, weight_decay: 0.000100, momentum_teacher: 0.996089, loss: 5.4417
2022-10-02 13:01:06 - train: epoch 0010, iter [05600, 10009], lr: 0.015839, weight_decay: 0.000100, momentum_teacher: 0.996090, loss: 5.5024
2022-10-02 13:01:54 - train: epoch 0010, iter [05700, 10009], lr: 0.015854, weight_decay: 0.000100, momentum_teacher: 0.996090, loss: 5.2482
2022-10-02 13:02:41 - train: epoch 0010, iter [05800, 10009], lr: 0.015869, weight_decay: 0.000100, momentum_teacher: 0.996090, loss: 5.2660
2022-10-02 13:03:29 - train: epoch 0010, iter [05900, 10009], lr: 0.015884, weight_decay: 0.000100, momentum_teacher: 0.996090, loss: 5.2922
2022-10-02 13:04:16 - train: epoch 0010, iter [06000, 10009], lr: 0.015899, weight_decay: 0.000100, momentum_teacher: 0.996090, loss: 5.2674
2022-10-02 13:05:04 - train: epoch 0010, iter [06100, 10009], lr: 0.015914, weight_decay: 0.000100, momentum_teacher: 0.996090, loss: 5.4599
2022-10-02 13:05:51 - train: epoch 0010, iter [06200, 10009], lr: 0.015929, weight_decay: 0.000100, momentum_teacher: 0.996091, loss: 5.3630
2022-10-02 13:06:39 - train: epoch 0010, iter [06300, 10009], lr: 0.015944, weight_decay: 0.000100, momentum_teacher: 0.996091, loss: 5.4701
2022-10-02 13:07:27 - train: epoch 0010, iter [06400, 10009], lr: 0.015959, weight_decay: 0.000100, momentum_teacher: 0.996091, loss: 5.2694
2022-10-02 13:08:20 - train: epoch 0010, iter [06500, 10009], lr: 0.015974, weight_decay: 0.000100, momentum_teacher: 0.996091, loss: 5.3848
2022-10-02 13:09:13 - train: epoch 0010, iter [06600, 10009], lr: 0.015989, weight_decay: 0.000100, momentum_teacher: 0.996091, loss: 5.3632
2022-10-02 13:10:08 - train: epoch 0010, iter [06700, 10009], lr: 0.016004, weight_decay: 0.000100, momentum_teacher: 0.996092, loss: 5.3906
2022-10-02 13:10:57 - train: epoch 0010, iter [06800, 10009], lr: 0.016019, weight_decay: 0.000100, momentum_teacher: 0.996092, loss: 5.3525
2022-10-02 13:11:54 - train: epoch 0010, iter [06900, 10009], lr: 0.016034, weight_decay: 0.000100, momentum_teacher: 0.996092, loss: 5.4285
2022-10-02 13:12:58 - train: epoch 0010, iter [07000, 10009], lr: 0.016049, weight_decay: 0.000100, momentum_teacher: 0.996092, loss: 5.1971
2022-10-02 13:13:45 - train: epoch 0010, iter [07100, 10009], lr: 0.016064, weight_decay: 0.000100, momentum_teacher: 0.996092, loss: 5.4117
2022-10-02 13:14:33 - train: epoch 0010, iter [07200, 10009], lr: 0.016079, weight_decay: 0.000100, momentum_teacher: 0.996093, loss: 5.3001
2022-10-02 13:15:20 - train: epoch 0010, iter [07300, 10009], lr: 0.016094, weight_decay: 0.000100, momentum_teacher: 0.996093, loss: 5.2719
2022-10-02 13:16:08 - train: epoch 0010, iter [07400, 10009], lr: 0.016109, weight_decay: 0.000100, momentum_teacher: 0.996093, loss: 5.3702
2022-10-02 13:16:55 - train: epoch 0010, iter [07500, 10009], lr: 0.016124, weight_decay: 0.000100, momentum_teacher: 0.996093, loss: 5.1968
2022-10-02 13:17:43 - train: epoch 0010, iter [07600, 10009], lr: 0.016139, weight_decay: 0.000100, momentum_teacher: 0.996093, loss: 5.5039
2022-10-02 13:18:41 - train: epoch 0010, iter [07700, 10009], lr: 0.016154, weight_decay: 0.000100, momentum_teacher: 0.996093, loss: 5.1412
2022-10-02 13:19:33 - train: epoch 0010, iter [07800, 10009], lr: 0.016169, weight_decay: 0.000100, momentum_teacher: 0.996094, loss: 5.3348
2022-10-02 13:20:24 - train: epoch 0010, iter [07900, 10009], lr: 0.016184, weight_decay: 0.000100, momentum_teacher: 0.996094, loss: 5.2984
2022-10-02 13:21:11 - train: epoch 0010, iter [08000, 10009], lr: 0.016199, weight_decay: 0.000100, momentum_teacher: 0.996094, loss: 5.3932
2022-10-02 13:21:59 - train: epoch 0010, iter [08100, 10009], lr: 0.016214, weight_decay: 0.000100, momentum_teacher: 0.996094, loss: 5.2798
2022-10-02 13:22:53 - train: epoch 0010, iter [08200, 10009], lr: 0.016229, weight_decay: 0.000100, momentum_teacher: 0.996094, loss: 5.2180
2022-10-02 13:23:55 - train: epoch 0010, iter [08300, 10009], lr: 0.016244, weight_decay: 0.000100, momentum_teacher: 0.996095, loss: 5.1926
2022-10-02 13:24:44 - train: epoch 0010, iter [08400, 10009], lr: 0.016259, weight_decay: 0.000100, momentum_teacher: 0.996095, loss: 5.2577
2022-10-02 13:26:04 - train: epoch 0010, iter [08500, 10009], lr: 0.016274, weight_decay: 0.000100, momentum_teacher: 0.996095, loss: 5.3728
2022-10-02 13:27:24 - train: epoch 0010, iter [08600, 10009], lr: 0.016289, weight_decay: 0.000100, momentum_teacher: 0.996095, loss: 5.2235
2022-10-02 13:28:13 - train: epoch 0010, iter [08700, 10009], lr: 0.016304, weight_decay: 0.000100, momentum_teacher: 0.996095, loss: 5.1696
2022-10-02 13:29:01 - train: epoch 0010, iter [08800, 10009], lr: 0.016319, weight_decay: 0.000100, momentum_teacher: 0.996096, loss: 5.2658
2022-10-02 13:30:20 - train: epoch 0010, iter [08900, 10009], lr: 0.016334, weight_decay: 0.000100, momentum_teacher: 0.996096, loss: 5.2623
2022-10-02 13:31:08 - train: epoch 0010, iter [09000, 10009], lr: 0.016349, weight_decay: 0.000100, momentum_teacher: 0.996096, loss: 5.2651
2022-10-02 13:31:55 - train: epoch 0010, iter [09100, 10009], lr: 0.016364, weight_decay: 0.000100, momentum_teacher: 0.996096, loss: 5.1725
2022-10-02 13:32:43 - train: epoch 0010, iter [09200, 10009], lr: 0.016379, weight_decay: 0.000100, momentum_teacher: 0.996096, loss: 5.2606
2022-10-02 13:33:30 - train: epoch 0010, iter [09300, 10009], lr: 0.016394, weight_decay: 0.000100, momentum_teacher: 0.996097, loss: 5.1378
2022-10-02 13:34:18 - train: epoch 0010, iter [09400, 10009], lr: 0.016409, weight_decay: 0.000100, momentum_teacher: 0.996097, loss: 5.3354
2022-10-02 13:35:06 - train: epoch 0010, iter [09500, 10009], lr: 0.016424, weight_decay: 0.000100, momentum_teacher: 0.996097, loss: 5.2113
2022-10-02 13:35:53 - train: epoch 0010, iter [09600, 10009], lr: 0.016439, weight_decay: 0.000100, momentum_teacher: 0.996097, loss: 5.3099
2022-10-02 13:36:40 - train: epoch 0010, iter [09700, 10009], lr: 0.016454, weight_decay: 0.000100, momentum_teacher: 0.996097, loss: 5.3247
2022-10-02 13:37:28 - train: epoch 0010, iter [09800, 10009], lr: 0.016469, weight_decay: 0.000100, momentum_teacher: 0.996097, loss: 5.1325
2022-10-02 13:38:15 - train: epoch 0010, iter [09900, 10009], lr: 0.016484, weight_decay: 0.000100, momentum_teacher: 0.996098, loss: 5.0221
2022-10-02 13:39:20 - train: epoch 0010, iter [10000, 10009], lr: 0.016499, weight_decay: 0.000100, momentum_teacher: 0.996098, loss: 5.1080
2022-10-02 13:39:25 - train: epoch 010, train_loss: 5.3785
2022-10-02 13:39:27 - until epoch: 010, best_loss: 5.3785
2022-10-02 13:39:27 - epoch 011 lr: 0.015000
2022-10-02 13:40:19 - train: epoch 0011, iter [00100, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996098, loss: 5.2329
2022-10-02 13:41:06 - train: epoch 0011, iter [00200, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996098, loss: 5.0409
2022-10-02 13:41:53 - train: epoch 0011, iter [00300, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996098, loss: 5.1637
2022-10-02 13:42:40 - train: epoch 0011, iter [00400, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996099, loss: 5.4058
2022-10-02 13:43:28 - train: epoch 0011, iter [00500, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996099, loss: 5.1673
2022-10-02 13:44:15 - train: epoch 0011, iter [00600, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996099, loss: 5.2407
2022-10-02 13:45:03 - train: epoch 0011, iter [00700, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996099, loss: 5.0588
2022-10-02 13:45:50 - train: epoch 0011, iter [00800, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996099, loss: 5.4604
2022-10-02 13:46:37 - train: epoch 0011, iter [00900, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996100, loss: 5.2222
2022-10-02 13:47:25 - train: epoch 0011, iter [01000, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996100, loss: 5.3149
2022-10-02 13:48:12 - train: epoch 0011, iter [01100, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996100, loss: 5.2203
2022-10-02 13:49:00 - train: epoch 0011, iter [01200, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996100, loss: 5.1943
2022-10-02 13:49:47 - train: epoch 0011, iter [01300, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996100, loss: 5.2797
2022-10-02 13:50:35 - train: epoch 0011, iter [01400, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996101, loss: 5.1417
2022-10-02 13:51:22 - train: epoch 0011, iter [01500, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996101, loss: 5.1421
2022-10-02 13:52:09 - train: epoch 0011, iter [01600, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996101, loss: 5.2616
2022-10-02 13:52:57 - train: epoch 0011, iter [01700, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996101, loss: 5.1999
2022-10-02 13:53:44 - train: epoch 0011, iter [01800, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996101, loss: 4.9943
2022-10-02 13:54:32 - train: epoch 0011, iter [01900, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996102, loss: 5.2701
2022-10-02 13:55:19 - train: epoch 0011, iter [02000, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996102, loss: 5.2437
2022-10-02 13:56:06 - train: epoch 0011, iter [02100, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996102, loss: 5.2363
2022-10-02 13:56:54 - train: epoch 0011, iter [02200, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996102, loss: 5.1283
2022-10-02 13:57:41 - train: epoch 0011, iter [02300, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996102, loss: 5.3964
2022-10-02 13:58:29 - train: epoch 0011, iter [02400, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996103, loss: 5.1325
2022-10-02 13:59:16 - train: epoch 0011, iter [02500, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996103, loss: 5.1702
2022-10-02 14:00:04 - train: epoch 0011, iter [02600, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996103, loss: 5.2224
2022-10-02 14:00:51 - train: epoch 0011, iter [02700, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996103, loss: 5.0941
2022-10-02 14:01:39 - train: epoch 0011, iter [02800, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996103, loss: 5.1582
2022-10-02 14:02:26 - train: epoch 0011, iter [02900, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996104, loss: 5.0492
2022-10-02 14:03:13 - train: epoch 0011, iter [03000, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996104, loss: 5.0534
2022-10-02 14:04:01 - train: epoch 0011, iter [03100, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996104, loss: 5.2058
2022-10-02 14:04:48 - train: epoch 0011, iter [03200, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996104, loss: 5.2664
2022-10-02 14:05:36 - train: epoch 0011, iter [03300, 10009], lr: 0.015000, weight_decay: 0.000100, momentum_teacher: 0.996104, loss: 5.1660
2022-10-02 14:06:23 - train: epoch 0011, iter [03400, 10009], lr: 0.014999, weight_decay: 0.000100, momentum_teacher: 0.996105, loss: 4.9817
2022-10-02 14:07:10 - train: epoch 0011, iter [03500, 10009], lr: 0.014999, weight_decay: 0.000100, momentum_teacher: 0.996105, loss: 5.2445
2022-10-02 14:07:58 - train: epoch 0011, iter [03600, 10009], lr: 0.014999, weight_decay: 0.000100, momentum_teacher: 0.996105, loss: 5.0461
2022-10-02 14:08:46 - train: epoch 0011, iter [03700, 10009], lr: 0.014999, weight_decay: 0.000100, momentum_teacher: 0.996105, loss: 5.3599
2022-10-02 14:09:33 - train: epoch 0011, iter [03800, 10009], lr: 0.014999, weight_decay: 0.000100, momentum_teacher: 0.996105, loss: 5.3847
2022-10-02 14:10:20 - train: epoch 0011, iter [03900, 10009], lr: 0.014999, weight_decay: 0.000100, momentum_teacher: 0.996106, loss: 5.2668
2022-10-02 14:11:08 - train: epoch 0011, iter [04000, 10009], lr: 0.014999, weight_decay: 0.000100, momentum_teacher: 0.996106, loss: 5.1584
2022-10-02 14:11:55 - train: epoch 0011, iter [04100, 10009], lr: 0.014999, weight_decay: 0.000100, momentum_teacher: 0.996106, loss: 5.0252
2022-10-02 14:12:43 - train: epoch 0011, iter [04200, 10009], lr: 0.014999, weight_decay: 0.000100, momentum_teacher: 0.996106, loss: 5.0643
2022-10-02 14:13:30 - train: epoch 0011, iter [04300, 10009], lr: 0.014999, weight_decay: 0.000100, momentum_teacher: 0.996106, loss: 5.2665
2022-10-02 14:14:17 - train: epoch 0011, iter [04400, 10009], lr: 0.014999, weight_decay: 0.000100, momentum_teacher: 0.996107, loss: 5.0494
2022-10-02 14:15:05 - train: epoch 0011, iter [04500, 10009], lr: 0.014999, weight_decay: 0.000100, momentum_teacher: 0.996107, loss: 5.0018
2022-10-02 14:15:52 - train: epoch 0011, iter [04600, 10009], lr: 0.014999, weight_decay: 0.000100, momentum_teacher: 0.996107, loss: 5.1700
2022-10-02 14:16:40 - train: epoch 0011, iter [04700, 10009], lr: 0.014999, weight_decay: 0.000100, momentum_teacher: 0.996107, loss: 5.1194
2022-10-02 14:17:27 - train: epoch 0011, iter [04800, 10009], lr: 0.014999, weight_decay: 0.000100, momentum_teacher: 0.996107, loss: 5.3229
2022-10-02 14:18:14 - train: epoch 0011, iter [04900, 10009], lr: 0.014999, weight_decay: 0.000100, momentum_teacher: 0.996108, loss: 5.1399
2022-10-02 14:19:02 - train: epoch 0011, iter [05000, 10009], lr: 0.014999, weight_decay: 0.000100, momentum_teacher: 0.996108, loss: 5.2211
2022-10-02 14:19:49 - train: epoch 0011, iter [05100, 10009], lr: 0.014999, weight_decay: 0.000100, momentum_teacher: 0.996108, loss: 5.0274
2022-10-02 14:20:37 - train: epoch 0011, iter [05200, 10009], lr: 0.014999, weight_decay: 0.000100, momentum_teacher: 0.996108, loss: 5.0885
2022-10-02 14:21:24 - train: epoch 0011, iter [05300, 10009], lr: 0.014999, weight_decay: 0.000100, momentum_teacher: 0.996108, loss: 5.1274
2022-10-02 14:22:11 - train: epoch 0011, iter [05400, 10009], lr: 0.014999, weight_decay: 0.000100, momentum_teacher: 0.996109, loss: 5.2116
2022-10-02 14:22:59 - train: epoch 0011, iter [05500, 10009], lr: 0.014999, weight_decay: 0.000100, momentum_teacher: 0.996109, loss: 5.1064
2022-10-02 14:23:46 - train: epoch 0011, iter [05600, 10009], lr: 0.014999, weight_decay: 0.000100, momentum_teacher: 0.996109, loss: 4.9366
2022-10-02 14:24:34 - train: epoch 0011, iter [05700, 10009], lr: 0.014999, weight_decay: 0.000100, momentum_teacher: 0.996109, loss: 5.0030
2022-10-02 14:25:21 - train: epoch 0011, iter [05800, 10009], lr: 0.014998, weight_decay: 0.000100, momentum_teacher: 0.996109, loss: 5.1934
2022-10-02 14:26:09 - train: epoch 0011, iter [05900, 10009], lr: 0.014998, weight_decay: 0.000100, momentum_teacher: 0.996110, loss: 5.0500
2022-10-02 14:26:56 - train: epoch 0011, iter [06000, 10009], lr: 0.014998, weight_decay: 0.000100, momentum_teacher: 0.996110, loss: 5.2011
2022-10-02 14:27:44 - train: epoch 0011, iter [06100, 10009], lr: 0.014998, weight_decay: 0.000100, momentum_teacher: 0.996110, loss: 5.2410
2022-10-02 14:28:31 - train: epoch 0011, iter [06200, 10009], lr: 0.014998, weight_decay: 0.000100, momentum_teacher: 0.996110, loss: 5.1245
2022-10-02 14:29:18 - train: epoch 0011, iter [06300, 10009], lr: 0.014998, weight_decay: 0.000100, momentum_teacher: 0.996110, loss: 4.9238
2022-10-02 14:30:06 - train: epoch 0011, iter [06400, 10009], lr: 0.014998, weight_decay: 0.000100, momentum_teacher: 0.996111, loss: 5.1886
2022-10-02 14:30:53 - train: epoch 0011, iter [06500, 10009], lr: 0.014998, weight_decay: 0.000100, momentum_teacher: 0.996111, loss: 5.0230
2022-10-02 14:31:41 - train: epoch 0011, iter [06600, 10009], lr: 0.014998, weight_decay: 0.000100, momentum_teacher: 0.996111, loss: 4.9630
2022-10-02 14:32:28 - train: epoch 0011, iter [06700, 10009], lr: 0.014998, weight_decay: 0.000100, momentum_teacher: 0.996111, loss: 5.2897
2022-10-02 14:33:16 - train: epoch 0011, iter [06800, 10009], lr: 0.014998, weight_decay: 0.000100, momentum_teacher: 0.996112, loss: 5.2047
2022-10-02 14:34:03 - train: epoch 0011, iter [06900, 10009], lr: 0.014998, weight_decay: 0.000100, momentum_teacher: 0.996112, loss: 5.0869
2022-10-02 14:34:51 - train: epoch 0011, iter [07000, 10009], lr: 0.014998, weight_decay: 0.000100, momentum_teacher: 0.996112, loss: 5.2831
2022-10-02 14:35:38 - train: epoch 0011, iter [07100, 10009], lr: 0.014998, weight_decay: 0.000100, momentum_teacher: 0.996112, loss: 5.1717
2022-10-02 14:36:26 - train: epoch 0011, iter [07200, 10009], lr: 0.014998, weight_decay: 0.000100, momentum_teacher: 0.996112, loss: 5.0159
2022-10-02 14:37:13 - train: epoch 0011, iter [07300, 10009], lr: 0.014998, weight_decay: 0.000100, momentum_teacher: 0.996113, loss: 5.1110
2022-10-02 14:38:00 - train: epoch 0011, iter [07400, 10009], lr: 0.014998, weight_decay: 0.000100, momentum_teacher: 0.996113, loss: 5.2171
2022-10-02 14:38:48 - train: epoch 0011, iter [07500, 10009], lr: 0.014997, weight_decay: 0.000100, momentum_teacher: 0.996113, loss: 5.1663
2022-10-02 14:39:35 - train: epoch 0011, iter [07600, 10009], lr: 0.014997, weight_decay: 0.000100, momentum_teacher: 0.996113, loss: 4.9968
2022-10-02 14:40:28 - train: epoch 0011, iter [07700, 10009], lr: 0.014997, weight_decay: 0.000100, momentum_teacher: 0.996113, loss: 5.1091
2022-10-02 14:41:15 - train: epoch 0011, iter [07800, 10009], lr: 0.014997, weight_decay: 0.000100, momentum_teacher: 0.996114, loss: 5.0232
2022-10-02 14:42:03 - train: epoch 0011, iter [07900, 10009], lr: 0.014997, weight_decay: 0.000100, momentum_teacher: 0.996114, loss: 4.9306
2022-10-02 14:42:50 - train: epoch 0011, iter [08000, 10009], lr: 0.014997, weight_decay: 0.000100, momentum_teacher: 0.996114, loss: 4.9652
2022-10-02 14:43:38 - train: epoch 0011, iter [08100, 10009], lr: 0.014997, weight_decay: 0.000100, momentum_teacher: 0.996114, loss: 5.1228
2022-10-02 14:44:25 - train: epoch 0011, iter [08200, 10009], lr: 0.014997, weight_decay: 0.000100, momentum_teacher: 0.996114, loss: 4.9884
2022-10-02 14:45:13 - train: epoch 0011, iter [08300, 10009], lr: 0.014997, weight_decay: 0.000100, momentum_teacher: 0.996115, loss: 5.0410
2022-10-02 14:46:00 - train: epoch 0011, iter [08400, 10009], lr: 0.014997, weight_decay: 0.000100, momentum_teacher: 0.996115, loss: 5.1938
2022-10-02 14:46:48 - train: epoch 0011, iter [08500, 10009], lr: 0.014997, weight_decay: 0.000100, momentum_teacher: 0.996115, loss: 5.1889
2022-10-02 14:47:35 - train: epoch 0011, iter [08600, 10009], lr: 0.014997, weight_decay: 0.000100, momentum_teacher: 0.996115, loss: 5.0571
2022-10-02 14:48:23 - train: epoch 0011, iter [08700, 10009], lr: 0.014997, weight_decay: 0.000100, momentum_teacher: 0.996115, loss: 5.1519
2022-10-02 14:49:10 - train: epoch 0011, iter [08800, 10009], lr: 0.014996, weight_decay: 0.000100, momentum_teacher: 0.996116, loss: 5.1157
2022-10-02 14:49:58 - train: epoch 0011, iter [08900, 10009], lr: 0.014996, weight_decay: 0.000100, momentum_teacher: 0.996116, loss: 5.1896
2022-10-02 14:50:45 - train: epoch 0011, iter [09000, 10009], lr: 0.014996, weight_decay: 0.000100, momentum_teacher: 0.996116, loss: 4.9829
2022-10-02 14:51:33 - train: epoch 0011, iter [09100, 10009], lr: 0.014996, weight_decay: 0.000100, momentum_teacher: 0.996116, loss: 4.8639
2022-10-02 14:52:21 - train: epoch 0011, iter [09200, 10009], lr: 0.014996, weight_decay: 0.000100, momentum_teacher: 0.996117, loss: 4.9123
2022-10-02 14:53:08 - train: epoch 0011, iter [09300, 10009], lr: 0.014996, weight_decay: 0.000100, momentum_teacher: 0.996117, loss: 5.0274
2022-10-02 14:53:55 - train: epoch 0011, iter [09400, 10009], lr: 0.014996, weight_decay: 0.000100, momentum_teacher: 0.996117, loss: 4.9446
2022-10-02 14:54:43 - train: epoch 0011, iter [09500, 10009], lr: 0.014996, weight_decay: 0.000100, momentum_teacher: 0.996117, loss: 5.2769
2022-10-02 14:56:18 - train: epoch 0011, iter [09600, 10009], lr: 0.014996, weight_decay: 0.000100, momentum_teacher: 0.996117, loss: 4.9883
2022-10-02 14:57:05 - train: epoch 0011, iter [09700, 10009], lr: 0.014996, weight_decay: 0.000100, momentum_teacher: 0.996118, loss: 5.0295
2022-10-02 14:58:16 - train: epoch 0011, iter [09800, 10009], lr: 0.014996, weight_decay: 0.000100, momentum_teacher: 0.996118, loss: 5.0886
2022-10-02 14:59:14 - train: epoch 0011, iter [09900, 10009], lr: 0.014996, weight_decay: 0.000100, momentum_teacher: 0.996118, loss: 4.9186
2022-10-02 15:00:02 - train: epoch 0011, iter [10000, 10009], lr: 0.014995, weight_decay: 0.000100, momentum_teacher: 0.996118, loss: 4.8145
2022-10-02 15:00:07 - train: epoch 011, train_loss: 5.1335
2022-10-02 15:00:09 - until epoch: 011, best_loss: 5.1335
2022-10-02 15:00:09 - epoch 012 lr: 0.014995
2022-10-02 15:01:02 - train: epoch 0012, iter [00100, 10009], lr: 0.014995, weight_decay: 0.000100, momentum_teacher: 0.996118, loss: 5.2807
2022-10-02 15:01:56 - train: epoch 0012, iter [00200, 10009], lr: 0.014995, weight_decay: 0.000100, momentum_teacher: 0.996119, loss: 4.8527
2022-10-02 15:03:21 - train: epoch 0012, iter [00300, 10009], lr: 0.014995, weight_decay: 0.000100, momentum_teacher: 0.996119, loss: 5.0192
2022-10-02 15:04:11 - train: epoch 0012, iter [00400, 10009], lr: 0.014995, weight_decay: 0.000100, momentum_teacher: 0.996119, loss: 4.9839
2022-10-02 15:04:59 - train: epoch 0012, iter [00500, 10009], lr: 0.014995, weight_decay: 0.000100, momentum_teacher: 0.996119, loss: 5.1511
2022-10-02 15:05:46 - train: epoch 0012, iter [00600, 10009], lr: 0.014995, weight_decay: 0.000100, momentum_teacher: 0.996120, loss: 5.1208
2022-10-02 15:06:34 - train: epoch 0012, iter [00700, 10009], lr: 0.014995, weight_decay: 0.000100, momentum_teacher: 0.996120, loss: 5.0583
2022-10-02 15:07:21 - train: epoch 0012, iter [00800, 10009], lr: 0.014995, weight_decay: 0.000100, momentum_teacher: 0.996120, loss: 5.1331
2022-10-02 15:08:09 - train: epoch 0012, iter [00900, 10009], lr: 0.014995, weight_decay: 0.000100, momentum_teacher: 0.996120, loss: 5.2080
2022-10-02 15:08:57 - train: epoch 0012, iter [01000, 10009], lr: 0.014994, weight_decay: 0.000100, momentum_teacher: 0.996120, loss: 4.9370
2022-10-02 15:09:44 - train: epoch 0012, iter [01100, 10009], lr: 0.014994, weight_decay: 0.000100, momentum_teacher: 0.996121, loss: 4.8163
2022-10-02 15:10:32 - train: epoch 0012, iter [01200, 10009], lr: 0.014994, weight_decay: 0.000100, momentum_teacher: 0.996121, loss: 4.9918
2022-10-02 15:11:19 - train: epoch 0012, iter [01300, 10009], lr: 0.014994, weight_decay: 0.000100, momentum_teacher: 0.996121, loss: 4.8570
2022-10-02 15:12:07 - train: epoch 0012, iter [01400, 10009], lr: 0.014994, weight_decay: 0.000100, momentum_teacher: 0.996121, loss: 4.9361
2022-10-02 15:12:55 - train: epoch 0012, iter [01500, 10009], lr: 0.014994, weight_decay: 0.000100, momentum_teacher: 0.996121, loss: 5.0733
2022-10-02 15:13:42 - train: epoch 0012, iter [01600, 10009], lr: 0.014994, weight_decay: 0.000100, momentum_teacher: 0.996122, loss: 5.1746
2022-10-02 15:14:30 - train: epoch 0012, iter [01700, 10009], lr: 0.014994, weight_decay: 0.000100, momentum_teacher: 0.996122, loss: 5.1778
2022-10-02 15:15:18 - train: epoch 0012, iter [01800, 10009], lr: 0.014994, weight_decay: 0.000100, momentum_teacher: 0.996122, loss: 5.0524
2022-10-02 15:16:05 - train: epoch 0012, iter [01900, 10009], lr: 0.014994, weight_decay: 0.000100, momentum_teacher: 0.996122, loss: 5.1171
2022-10-02 15:16:53 - train: epoch 0012, iter [02000, 10009], lr: 0.014993, weight_decay: 0.000100, momentum_teacher: 0.996123, loss: 4.8166
2022-10-02 15:17:40 - train: epoch 0012, iter [02100, 10009], lr: 0.014993, weight_decay: 0.000100, momentum_teacher: 0.996123, loss: 5.0623
2022-10-02 15:18:28 - train: epoch 0012, iter [02200, 10009], lr: 0.014993, weight_decay: 0.000100, momentum_teacher: 0.996123, loss: 5.0821
2022-10-02 15:19:15 - train: epoch 0012, iter [02300, 10009], lr: 0.014993, weight_decay: 0.000100, momentum_teacher: 0.996123, loss: 4.7549
2022-10-02 15:20:03 - train: epoch 0012, iter [02400, 10009], lr: 0.014993, weight_decay: 0.000100, momentum_teacher: 0.996123, loss: 4.9988
2022-10-02 15:20:50 - train: epoch 0012, iter [02500, 10009], lr: 0.014993, weight_decay: 0.000100, momentum_teacher: 0.996124, loss: 4.8046
2022-10-02 15:21:38 - train: epoch 0012, iter [02600, 10009], lr: 0.014993, weight_decay: 0.000100, momentum_teacher: 0.996124, loss: 4.8260
2022-10-02 15:22:25 - train: epoch 0012, iter [02700, 10009], lr: 0.014993, weight_decay: 0.000100, momentum_teacher: 0.996124, loss: 5.0130
2022-10-02 15:23:13 - train: epoch 0012, iter [02800, 10009], lr: 0.014993, weight_decay: 0.000100, momentum_teacher: 0.996124, loss: 4.9591
2022-10-02 15:24:00 - train: epoch 0012, iter [02900, 10009], lr: 0.014992, weight_decay: 0.000100, momentum_teacher: 0.996124, loss: 4.9912
2022-10-02 15:25:01 - train: epoch 0012, iter [03000, 10009], lr: 0.014992, weight_decay: 0.000100, momentum_teacher: 0.996125, loss: 4.9867
2022-10-02 15:26:04 - train: epoch 0012, iter [03100, 10009], lr: 0.014992, weight_decay: 0.000100, momentum_teacher: 0.996125, loss: 4.9470
2022-10-02 15:26:52 - train: epoch 0012, iter [03200, 10009], lr: 0.014992, weight_decay: 0.000100, momentum_teacher: 0.996125, loss: 5.0337
2022-10-02 15:27:39 - train: epoch 0012, iter [03300, 10009], lr: 0.014992, weight_decay: 0.000100, momentum_teacher: 0.996125, loss: 4.9715
2022-10-02 15:28:27 - train: epoch 0012, iter [03400, 10009], lr: 0.014992, weight_decay: 0.000100, momentum_teacher: 0.996126, loss: 4.8649
2022-10-02 15:29:14 - train: epoch 0012, iter [03500, 10009], lr: 0.014992, weight_decay: 0.000100, momentum_teacher: 0.996126, loss: 5.0284
2022-10-02 15:30:02 - train: epoch 0012, iter [03600, 10009], lr: 0.014992, weight_decay: 0.000100, momentum_teacher: 0.996126, loss: 4.8903
2022-10-02 15:30:49 - train: epoch 0012, iter [03700, 10009], lr: 0.014991, weight_decay: 0.000100, momentum_teacher: 0.996126, loss: 5.0528
2022-10-02 15:31:37 - train: epoch 0012, iter [03800, 10009], lr: 0.014991, weight_decay: 0.000100, momentum_teacher: 0.996126, loss: 4.9532
2022-10-02 15:32:24 - train: epoch 0012, iter [03900, 10009], lr: 0.014991, weight_decay: 0.000100, momentum_teacher: 0.996127, loss: 5.0002
2022-10-02 15:33:12 - train: epoch 0012, iter [04000, 10009], lr: 0.014991, weight_decay: 0.000100, momentum_teacher: 0.996127, loss: 4.8909
2022-10-02 15:34:00 - train: epoch 0012, iter [04100, 10009], lr: 0.014991, weight_decay: 0.000100, momentum_teacher: 0.996127, loss: 5.0091
2022-10-02 15:34:47 - train: epoch 0012, iter [04200, 10009], lr: 0.014991, weight_decay: 0.000100, momentum_teacher: 0.996127, loss: 4.9286
2022-10-02 15:35:35 - train: epoch 0012, iter [04300, 10009], lr: 0.014991, weight_decay: 0.000100, momentum_teacher: 0.996128, loss: 4.6382
2022-10-02 15:36:22 - train: epoch 0012, iter [04400, 10009], lr: 0.014991, weight_decay: 0.000100, momentum_teacher: 0.996128, loss: 4.9221
2022-10-02 15:37:10 - train: epoch 0012, iter [04500, 10009], lr: 0.014990, weight_decay: 0.000100, momentum_teacher: 0.996128, loss: 5.0084
2022-10-02 15:37:57 - train: epoch 0012, iter [04600, 10009], lr: 0.014990, weight_decay: 0.000100, momentum_teacher: 0.996128, loss: 5.0718
2022-10-02 15:38:45 - train: epoch 0012, iter [04700, 10009], lr: 0.014990, weight_decay: 0.000100, momentum_teacher: 0.996128, loss: 5.0115
2022-10-02 15:39:33 - train: epoch 0012, iter [04800, 10009], lr: 0.014990, weight_decay: 0.000100, momentum_teacher: 0.996129, loss: 4.7887
2022-10-02 15:40:20 - train: epoch 0012, iter [04900, 10009], lr: 0.014990, weight_decay: 0.000100, momentum_teacher: 0.996129, loss: 4.8742
2022-10-02 15:41:08 - train: epoch 0012, iter [05000, 10009], lr: 0.014990, weight_decay: 0.000100, momentum_teacher: 0.996129, loss: 4.7755
2022-10-02 15:42:50 - train: epoch 0012, iter [05100, 10009], lr: 0.014990, weight_decay: 0.000100, momentum_teacher: 0.996129, loss: 4.9923
2022-10-02 15:44:38 - train: epoch 0012, iter [05200, 10009], lr: 0.014989, weight_decay: 0.000100, momentum_teacher: 0.996130, loss: 4.7661
2022-10-02 15:46:48 - train: epoch 0012, iter [05300, 10009], lr: 0.014989, weight_decay: 0.000100, momentum_teacher: 0.996130, loss: 4.9241
2022-10-02 15:50:09 - train: epoch 0012, iter [05400, 10009], lr: 0.014989, weight_decay: 0.000100, momentum_teacher: 0.996130, loss: 4.9251
2022-10-02 15:52:30 - train: epoch 0012, iter [05500, 10009], lr: 0.014989, weight_decay: 0.000100, momentum_teacher: 0.996130, loss: 4.9876
2022-10-02 15:55:26 - train: epoch 0012, iter [05600, 10009], lr: 0.014989, weight_decay: 0.000100, momentum_teacher: 0.996130, loss: 4.8605
2022-10-02 16:00:11 - train: epoch 0012, iter [05700, 10009], lr: 0.014989, weight_decay: 0.000100, momentum_teacher: 0.996131, loss: 4.8495
2022-10-02 16:06:27 - train: epoch 0012, iter [05800, 10009], lr: 0.014989, weight_decay: 0.000100, momentum_teacher: 0.996131, loss: 5.0986
2022-10-02 16:09:28 - train: epoch 0012, iter [05900, 10009], lr: 0.014988, weight_decay: 0.000100, momentum_teacher: 0.996131, loss: 5.1658
2022-10-02 16:10:18 - train: epoch 0012, iter [06000, 10009], lr: 0.014988, weight_decay: 0.000100, momentum_teacher: 0.996131, loss: 4.7433
2022-10-02 16:11:05 - train: epoch 0012, iter [06100, 10009], lr: 0.014988, weight_decay: 0.000100, momentum_teacher: 0.996132, loss: 4.7497
2022-10-02 16:11:57 - train: epoch 0012, iter [06200, 10009], lr: 0.014988, weight_decay: 0.000100, momentum_teacher: 0.996132, loss: 4.8284
2022-10-02 16:13:04 - train: epoch 0012, iter [06300, 10009], lr: 0.014988, weight_decay: 0.000100, momentum_teacher: 0.996132, loss: 4.8151
2022-10-02 16:13:52 - train: epoch 0012, iter [06400, 10009], lr: 0.014988, weight_decay: 0.000100, momentum_teacher: 0.996132, loss: 4.7851
2022-10-02 16:15:03 - train: epoch 0012, iter [06500, 10009], lr: 0.014988, weight_decay: 0.000100, momentum_teacher: 0.996132, loss: 4.8176
2022-10-02 16:15:50 - train: epoch 0012, iter [06600, 10009], lr: 0.014987, weight_decay: 0.000100, momentum_teacher: 0.996133, loss: 5.0384
2022-10-02 16:16:38 - train: epoch 0012, iter [06700, 10009], lr: 0.014987, weight_decay: 0.000100, momentum_teacher: 0.996133, loss: 5.0911
2022-10-02 16:17:26 - train: epoch 0012, iter [06800, 10009], lr: 0.014987, weight_decay: 0.000100, momentum_teacher: 0.996133, loss: 4.8712
2022-10-02 16:18:13 - train: epoch 0012, iter [06900, 10009], lr: 0.014987, weight_decay: 0.000100, momentum_teacher: 0.996133, loss: 4.7056
2022-10-02 16:19:00 - train: epoch 0012, iter [07000, 10009], lr: 0.014987, weight_decay: 0.000100, momentum_teacher: 0.996134, loss: 4.8870
2022-10-02 16:19:48 - train: epoch 0012, iter [07100, 10009], lr: 0.014987, weight_decay: 0.000100, momentum_teacher: 0.996134, loss: 4.8773
2022-10-02 16:20:36 - train: epoch 0012, iter [07200, 10009], lr: 0.014986, weight_decay: 0.000100, momentum_teacher: 0.996134, loss: 4.9149
2022-10-02 16:21:23 - train: epoch 0012, iter [07300, 10009], lr: 0.014986, weight_decay: 0.000100, momentum_teacher: 0.996134, loss: 4.8301
2022-10-02 16:22:11 - train: epoch 0012, iter [07400, 10009], lr: 0.014986, weight_decay: 0.000100, momentum_teacher: 0.996134, loss: 4.8502
2022-10-02 16:22:58 - train: epoch 0012, iter [07500, 10009], lr: 0.014986, weight_decay: 0.000100, momentum_teacher: 0.996135, loss: 4.8878
2022-10-02 16:23:46 - train: epoch 0012, iter [07600, 10009], lr: 0.014986, weight_decay: 0.000100, momentum_teacher: 0.996135, loss: 4.7992
2022-10-02 16:24:33 - train: epoch 0012, iter [07700, 10009], lr: 0.014986, weight_decay: 0.000100, momentum_teacher: 0.996135, loss: 5.0363
2022-10-02 16:25:21 - train: epoch 0012, iter [07800, 10009], lr: 0.014986, weight_decay: 0.000100, momentum_teacher: 0.996135, loss: 4.8188
2022-10-02 16:26:09 - train: epoch 0012, iter [07900, 10009], lr: 0.014985, weight_decay: 0.000100, momentum_teacher: 0.996136, loss: 4.8669
2022-10-02 16:26:57 - train: epoch 0012, iter [08000, 10009], lr: 0.014985, weight_decay: 0.000100, momentum_teacher: 0.996136, loss: 5.0038
2022-10-02 16:27:45 - train: epoch 0012, iter [08100, 10009], lr: 0.014985, weight_decay: 0.000100, momentum_teacher: 0.996136, loss: 4.8676
2022-10-02 16:28:32 - train: epoch 0012, iter [08200, 10009], lr: 0.014985, weight_decay: 0.000100, momentum_teacher: 0.996136, loss: 4.8107
2022-10-02 16:29:20 - train: epoch 0012, iter [08300, 10009], lr: 0.014985, weight_decay: 0.000100, momentum_teacher: 0.996137, loss: 4.7839
2022-10-02 16:30:08 - train: epoch 0012, iter [08400, 10009], lr: 0.014985, weight_decay: 0.000100, momentum_teacher: 0.996137, loss: 4.8088
2022-10-02 16:30:55 - train: epoch 0012, iter [08500, 10009], lr: 0.014984, weight_decay: 0.000100, momentum_teacher: 0.996137, loss: 4.7585
2022-10-02 16:31:43 - train: epoch 0012, iter [08600, 10009], lr: 0.014984, weight_decay: 0.000100, momentum_teacher: 0.996137, loss: 5.0606
2022-10-02 16:32:30 - train: epoch 0012, iter [08700, 10009], lr: 0.014984, weight_decay: 0.000100, momentum_teacher: 0.996137, loss: 4.6952
2022-10-02 16:33:18 - train: epoch 0012, iter [08800, 10009], lr: 0.014984, weight_decay: 0.000100, momentum_teacher: 0.996138, loss: 4.8153
2022-10-02 16:34:06 - train: epoch 0012, iter [08900, 10009], lr: 0.014984, weight_decay: 0.000100, momentum_teacher: 0.996138, loss: 4.9472
2022-10-02 16:34:53 - train: epoch 0012, iter [09000, 10009], lr: 0.014984, weight_decay: 0.000100, momentum_teacher: 0.996138, loss: 4.9282
2022-10-02 16:35:41 - train: epoch 0012, iter [09100, 10009], lr: 0.014983, weight_decay: 0.000100, momentum_teacher: 0.996138, loss: 4.7070
2022-10-02 16:36:39 - train: epoch 0012, iter [09200, 10009], lr: 0.014983, weight_decay: 0.000100, momentum_teacher: 0.996139, loss: 4.8814
2022-10-02 16:37:27 - train: epoch 0012, iter [09300, 10009], lr: 0.014983, weight_decay: 0.000100, momentum_teacher: 0.996139, loss: 4.7554
2022-10-02 16:38:15 - train: epoch 0012, iter [09400, 10009], lr: 0.014983, weight_decay: 0.000100, momentum_teacher: 0.996139, loss: 4.7693
2022-10-02 16:39:03 - train: epoch 0012, iter [09500, 10009], lr: 0.014983, weight_decay: 0.000100, momentum_teacher: 0.996139, loss: 4.7429
2022-10-02 16:39:51 - train: epoch 0012, iter [09600, 10009], lr: 0.014982, weight_decay: 0.000100, momentum_teacher: 0.996140, loss: 4.7879
2022-10-02 16:40:38 - train: epoch 0012, iter [09700, 10009], lr: 0.014982, weight_decay: 0.000100, momentum_teacher: 0.996140, loss: 4.9498
2022-10-02 16:41:27 - train: epoch 0012, iter [09800, 10009], lr: 0.014982, weight_decay: 0.000100, momentum_teacher: 0.996140, loss: 4.9746
2022-10-02 16:42:14 - train: epoch 0012, iter [09900, 10009], lr: 0.014982, weight_decay: 0.000100, momentum_teacher: 0.996140, loss: 5.0292
2022-10-02 16:43:02 - train: epoch 0012, iter [10000, 10009], lr: 0.014982, weight_decay: 0.000100, momentum_teacher: 0.996140, loss: 4.8995
2022-10-02 16:43:07 - train: epoch 012, train_loss: 4.9182
2022-10-02 16:43:09 - until epoch: 012, best_loss: 4.9182
2022-10-02 16:43:09 - epoch 013 lr: 0.014982
2022-10-02 16:44:01 - train: epoch 0013, iter [00100, 10009], lr: 0.014982, weight_decay: 0.000100, momentum_teacher: 0.996141, loss: 4.6900
2022-10-02 16:44:48 - train: epoch 0013, iter [00200, 10009], lr: 0.014981, weight_decay: 0.000100, momentum_teacher: 0.996141, loss: 4.7954
2022-10-02 16:45:36 - train: epoch 0013, iter [00300, 10009], lr: 0.014981, weight_decay: 0.000100, momentum_teacher: 0.996141, loss: 4.8395
2022-10-02 16:46:23 - train: epoch 0013, iter [00400, 10009], lr: 0.014981, weight_decay: 0.000100, momentum_teacher: 0.996141, loss: 4.9898
2022-10-02 16:47:11 - train: epoch 0013, iter [00500, 10009], lr: 0.014981, weight_decay: 0.000100, momentum_teacher: 0.996142, loss: 4.7223
2022-10-02 16:47:58 - train: epoch 0013, iter [00600, 10009], lr: 0.014981, weight_decay: 0.000100, momentum_teacher: 0.996142, loss: 4.8796
2022-10-02 16:48:46 - train: epoch 0013, iter [00700, 10009], lr: 0.014980, weight_decay: 0.000100, momentum_teacher: 0.996142, loss: 4.7132
2022-10-02 16:49:33 - train: epoch 0013, iter [00800, 10009], lr: 0.014980, weight_decay: 0.000100, momentum_teacher: 0.996142, loss: 4.6440
2022-10-02 16:50:21 - train: epoch 0013, iter [00900, 10009], lr: 0.014980, weight_decay: 0.000100, momentum_teacher: 0.996143, loss: 4.6973
2022-10-02 16:51:08 - train: epoch 0013, iter [01000, 10009], lr: 0.014980, weight_decay: 0.000100, momentum_teacher: 0.996143, loss: 4.6846
2022-10-02 16:51:56 - train: epoch 0013, iter [01100, 10009], lr: 0.014980, weight_decay: 0.000100, momentum_teacher: 0.996143, loss: 4.8985
2022-10-02 16:52:44 - train: epoch 0013, iter [01200, 10009], lr: 0.014979, weight_decay: 0.000100, momentum_teacher: 0.996143, loss: 4.6995
2022-10-02 16:53:31 - train: epoch 0013, iter [01300, 10009], lr: 0.014979, weight_decay: 0.000100, momentum_teacher: 0.996143, loss: 4.8075
2022-10-02 16:54:19 - train: epoch 0013, iter [01400, 10009], lr: 0.014979, weight_decay: 0.000100, momentum_teacher: 0.996144, loss: 4.8520
2022-10-02 16:55:32 - train: epoch 0013, iter [01500, 10009], lr: 0.014979, weight_decay: 0.000100, momentum_teacher: 0.996144, loss: 4.5289
2022-10-02 16:56:26 - train: epoch 0013, iter [01600, 10009], lr: 0.014979, weight_decay: 0.000100, momentum_teacher: 0.996144, loss: 4.6957
2022-10-02 16:57:14 - train: epoch 0013, iter [01700, 10009], lr: 0.014978, weight_decay: 0.000100, momentum_teacher: 0.996144, loss: 4.8014
2022-10-02 16:58:02 - train: epoch 0013, iter [01800, 10009], lr: 0.014978, weight_decay: 0.000100, momentum_teacher: 0.996145, loss: 4.8381
2022-10-02 16:58:49 - train: epoch 0013, iter [01900, 10009], lr: 0.014978, weight_decay: 0.000100, momentum_teacher: 0.996145, loss: 4.8421
2022-10-02 16:59:37 - train: epoch 0013, iter [02000, 10009], lr: 0.014978, weight_decay: 0.000100, momentum_teacher: 0.996145, loss: 4.6892
2022-10-02 17:00:25 - train: epoch 0013, iter [02100, 10009], lr: 0.014978, weight_decay: 0.000100, momentum_teacher: 0.996145, loss: 4.8082
2022-10-02 17:01:13 - train: epoch 0013, iter [02200, 10009], lr: 0.014977, weight_decay: 0.000100, momentum_teacher: 0.996146, loss: 4.6844
2022-10-02 17:02:01 - train: epoch 0013, iter [02300, 10009], lr: 0.014977, weight_decay: 0.000100, momentum_teacher: 0.996146, loss: 4.7228
2022-10-02 17:02:48 - train: epoch 0013, iter [02400, 10009], lr: 0.014977, weight_decay: 0.000100, momentum_teacher: 0.996146, loss: 4.7261
2022-10-02 17:03:36 - train: epoch 0013, iter [02500, 10009], lr: 0.014977, weight_decay: 0.000100, momentum_teacher: 0.996146, loss: 4.7441
2022-10-02 17:04:23 - train: epoch 0013, iter [02600, 10009], lr: 0.014977, weight_decay: 0.000100, momentum_teacher: 0.996147, loss: 4.7706
2022-10-02 17:05:11 - train: epoch 0013, iter [02700, 10009], lr: 0.014976, weight_decay: 0.000100, momentum_teacher: 0.996147, loss: 4.9091
2022-10-02 17:06:00 - train: epoch 0013, iter [02800, 10009], lr: 0.014976, weight_decay: 0.000100, momentum_teacher: 0.996147, loss: 4.6140
2022-10-02 17:06:48 - train: epoch 0013, iter [02900, 10009], lr: 0.014976, weight_decay: 0.000100, momentum_teacher: 0.996147, loss: 4.7243
2022-10-02 17:07:36 - train: epoch 0013, iter [03000, 10009], lr: 0.014976, weight_decay: 0.000100, momentum_teacher: 0.996147, loss: 4.7365
2022-10-02 17:08:23 - train: epoch 0013, iter [03100, 10009], lr: 0.014976, weight_decay: 0.000100, momentum_teacher: 0.996148, loss: 4.6039
2022-10-02 17:09:15 - train: epoch 0013, iter [03200, 10009], lr: 0.014975, weight_decay: 0.000100, momentum_teacher: 0.996148, loss: 4.7352
2022-10-02 17:10:11 - train: epoch 0013, iter [03300, 10009], lr: 0.014975, weight_decay: 0.000100, momentum_teacher: 0.996148, loss: 4.8773
2022-10-02 17:10:59 - train: epoch 0013, iter [03400, 10009], lr: 0.014975, weight_decay: 0.000100, momentum_teacher: 0.996148, loss: 4.8240
2022-10-02 17:11:47 - train: epoch 0013, iter [03500, 10009], lr: 0.014975, weight_decay: 0.000100, momentum_teacher: 0.996149, loss: 4.6936
2022-10-02 17:12:34 - train: epoch 0013, iter [03600, 10009], lr: 0.014975, weight_decay: 0.000100, momentum_teacher: 0.996149, loss: 4.6301
2022-10-02 17:13:22 - train: epoch 0013, iter [03700, 10009], lr: 0.014974, weight_decay: 0.000100, momentum_teacher: 0.996149, loss: 4.6058
2022-10-02 17:14:10 - train: epoch 0013, iter [03800, 10009], lr: 0.014974, weight_decay: 0.000100, momentum_teacher: 0.996149, loss: 4.6889
2022-10-02 17:14:57 - train: epoch 0013, iter [03900, 10009], lr: 0.014974, weight_decay: 0.000100, momentum_teacher: 0.996150, loss: 4.6214
2022-10-02 17:15:44 - train: epoch 0013, iter [04000, 10009], lr: 0.014974, weight_decay: 0.000100, momentum_teacher: 0.996150, loss: 4.8175
2022-10-02 17:16:32 - train: epoch 0013, iter [04100, 10009], lr: 0.014973, weight_decay: 0.000100, momentum_teacher: 0.996150, loss: 4.7556
2022-10-02 17:17:19 - train: epoch 0013, iter [04200, 10009], lr: 0.014973, weight_decay: 0.000100, momentum_teacher: 0.996150, loss: 4.6327
2022-10-02 17:18:06 - train: epoch 0013, iter [04300, 10009], lr: 0.014973, weight_decay: 0.000100, momentum_teacher: 0.996151, loss: 4.8560
2022-10-02 17:18:54 - train: epoch 0013, iter [04400, 10009], lr: 0.014973, weight_decay: 0.000100, momentum_teacher: 0.996151, loss: 4.7413
2022-10-02 17:19:41 - train: epoch 0013, iter [04500, 10009], lr: 0.014973, weight_decay: 0.000100, momentum_teacher: 0.996151, loss: 4.6015
2022-10-02 17:20:29 - train: epoch 0013, iter [04600, 10009], lr: 0.014972, weight_decay: 0.000100, momentum_teacher: 0.996151, loss: 4.6909
2022-10-02 17:21:17 - train: epoch 0013, iter [04700, 10009], lr: 0.014972, weight_decay: 0.000100, momentum_teacher: 0.996152, loss: 4.9869
2022-10-02 17:22:04 - train: epoch 0013, iter [04800, 10009], lr: 0.014972, weight_decay: 0.000100, momentum_teacher: 0.996152, loss: 4.8775
2022-10-02 17:22:51 - train: epoch 0013, iter [04900, 10009], lr: 0.014972, weight_decay: 0.000100, momentum_teacher: 0.996152, loss: 4.7090
2022-10-02 17:23:39 - train: epoch 0013, iter [05000, 10009], lr: 0.014971, weight_decay: 0.000100, momentum_teacher: 0.996152, loss: 4.7319
2022-10-02 17:24:26 - train: epoch 0013, iter [05100, 10009], lr: 0.014971, weight_decay: 0.000100, momentum_teacher: 0.996152, loss: 4.9575
2022-10-02 17:25:18 - train: epoch 0013, iter [05200, 10009], lr: 0.014971, weight_decay: 0.000100, momentum_teacher: 0.996153, loss: 4.6846
2022-10-02 17:26:06 - train: epoch 0013, iter [05300, 10009], lr: 0.014971, weight_decay: 0.000100, momentum_teacher: 0.996153, loss: 4.5672
2022-10-02 17:26:53 - train: epoch 0013, iter [05400, 10009], lr: 0.014971, weight_decay: 0.000100, momentum_teacher: 0.996153, loss: 4.6453
2022-10-02 17:27:41 - train: epoch 0013, iter [05500, 10009], lr: 0.014970, weight_decay: 0.000100, momentum_teacher: 0.996153, loss: 4.6578
2022-10-02 17:28:28 - train: epoch 0013, iter [05600, 10009], lr: 0.014970, weight_decay: 0.000100, momentum_teacher: 0.996154, loss: 4.5157
2022-10-02 17:29:22 - train: epoch 0013, iter [05700, 10009], lr: 0.014970, weight_decay: 0.000100, momentum_teacher: 0.996154, loss: 4.7548
2022-10-02 17:30:27 - train: epoch 0013, iter [05800, 10009], lr: 0.014970, weight_decay: 0.000100, momentum_teacher: 0.996154, loss: 4.5369
2022-10-02 17:31:17 - train: epoch 0013, iter [05900, 10009], lr: 0.014969, weight_decay: 0.000100, momentum_teacher: 0.996154, loss: 4.5744
2022-10-02 17:32:06 - train: epoch 0013, iter [06000, 10009], lr: 0.014969, weight_decay: 0.000100, momentum_teacher: 0.996155, loss: 4.7342
2022-10-02 17:32:53 - train: epoch 0013, iter [06100, 10009], lr: 0.014969, weight_decay: 0.000100, momentum_teacher: 0.996155, loss: 4.6065
2022-10-02 17:33:40 - train: epoch 0013, iter [06200, 10009], lr: 0.014969, weight_decay: 0.000100, momentum_teacher: 0.996155, loss: 4.6466
2022-10-02 17:34:29 - train: epoch 0013, iter [06300, 10009], lr: 0.014968, weight_decay: 0.000100, momentum_teacher: 0.996155, loss: 4.8228
2022-10-02 17:35:16 - train: epoch 0013, iter [06400, 10009], lr: 0.014968, weight_decay: 0.000100, momentum_teacher: 0.996156, loss: 4.5472
2022-10-02 17:36:04 - train: epoch 0013, iter [06500, 10009], lr: 0.014968, weight_decay: 0.000100, momentum_teacher: 0.996156, loss: 4.6372
2022-10-02 17:36:51 - train: epoch 0013, iter [06600, 10009], lr: 0.014968, weight_decay: 0.000100, momentum_teacher: 0.996156, loss: 4.5572
2022-10-02 17:37:39 - train: epoch 0013, iter [06700, 10009], lr: 0.014967, weight_decay: 0.000100, momentum_teacher: 0.996156, loss: 4.5512
2022-10-02 17:38:26 - train: epoch 0013, iter [06800, 10009], lr: 0.014967, weight_decay: 0.000100, momentum_teacher: 0.996157, loss: 4.5880
2022-10-02 17:39:56 - train: epoch 0013, iter [06900, 10009], lr: 0.014967, weight_decay: 0.000100, momentum_teacher: 0.996157, loss: 4.5914
2022-10-02 17:41:03 - train: epoch 0013, iter [07000, 10009], lr: 0.014967, weight_decay: 0.000100, momentum_teacher: 0.996157, loss: 4.6686
2022-10-02 17:41:52 - train: epoch 0013, iter [07100, 10009], lr: 0.014966, weight_decay: 0.000100, momentum_teacher: 0.996157, loss: 4.4935
2022-10-02 17:42:43 - train: epoch 0013, iter [07200, 10009], lr: 0.014966, weight_decay: 0.000100, momentum_teacher: 0.996158, loss: 4.4934
2022-10-02 17:43:32 - train: epoch 0013, iter [07300, 10009], lr: 0.014966, weight_decay: 0.000100, momentum_teacher: 0.996158, loss: 4.4819
2022-10-02 17:44:26 - train: epoch 0013, iter [07400, 10009], lr: 0.014966, weight_decay: 0.000100, momentum_teacher: 0.996158, loss: 4.7380
2022-10-02 17:45:26 - train: epoch 0013, iter [07500, 10009], lr: 0.014965, weight_decay: 0.000100, momentum_teacher: 0.996158, loss: 4.6671
2022-10-02 17:46:22 - train: epoch 0013, iter [07600, 10009], lr: 0.014965, weight_decay: 0.000100, momentum_teacher: 0.996159, loss: 4.7363
2022-10-02 17:47:16 - train: epoch 0013, iter [07700, 10009], lr: 0.014965, weight_decay: 0.000100, momentum_teacher: 0.996159, loss: 4.5274
2022-10-02 17:48:10 - train: epoch 0013, iter [07800, 10009], lr: 0.014965, weight_decay: 0.000100, momentum_teacher: 0.996159, loss: 4.6395
2022-10-02 17:49:00 - train: epoch 0013, iter [07900, 10009], lr: 0.014964, weight_decay: 0.000100, momentum_teacher: 0.996159, loss: 4.7725
2022-10-02 17:49:53 - train: epoch 0013, iter [08000, 10009], lr: 0.014964, weight_decay: 0.000100, momentum_teacher: 0.996160, loss: 4.8065
2022-10-02 17:50:48 - train: epoch 0013, iter [08100, 10009], lr: 0.014964, weight_decay: 0.000100, momentum_teacher: 0.996160, loss: 4.6302
2022-10-02 17:52:03 - train: epoch 0013, iter [08200, 10009], lr: 0.014964, weight_decay: 0.000100, momentum_teacher: 0.996160, loss: 4.7390
2022-10-02 17:53:17 - train: epoch 0013, iter [08300, 10009], lr: 0.014963, weight_decay: 0.000100, momentum_teacher: 0.996160, loss: 4.6962
2022-10-02 17:54:17 - train: epoch 0013, iter [08400, 10009], lr: 0.014963, weight_decay: 0.000100, momentum_teacher: 0.996161, loss: 4.6065
2022-10-02 17:55:20 - train: epoch 0013, iter [08500, 10009], lr: 0.014963, weight_decay: 0.000100, momentum_teacher: 0.996161, loss: 4.5061
2022-10-02 17:56:35 - train: epoch 0013, iter [08600, 10009], lr: 0.014963, weight_decay: 0.000100, momentum_teacher: 0.996161, loss: 4.6478
2022-10-02 17:57:41 - train: epoch 0013, iter [08700, 10009], lr: 0.014962, weight_decay: 0.000100, momentum_teacher: 0.996161, loss: 4.8827
2022-10-02 17:58:45 - train: epoch 0013, iter [08800, 10009], lr: 0.014962, weight_decay: 0.000100, momentum_teacher: 0.996161, loss: 4.6138
2022-10-02 17:59:45 - train: epoch 0013, iter [08900, 10009], lr: 0.014962, weight_decay: 0.000100, momentum_teacher: 0.996162, loss: 4.8176
2022-10-02 18:00:46 - train: epoch 0013, iter [09000, 10009], lr: 0.014962, weight_decay: 0.000100, momentum_teacher: 0.996162, loss: 4.5388
2022-10-02 18:01:50 - train: epoch 0013, iter [09100, 10009], lr: 0.014961, weight_decay: 0.000100, momentum_teacher: 0.996162, loss: 4.7866
2022-10-02 18:02:48 - train: epoch 0013, iter [09200, 10009], lr: 0.014961, weight_decay: 0.000100, momentum_teacher: 0.996162, loss: 4.6059
2022-10-02 18:03:48 - train: epoch 0013, iter [09300, 10009], lr: 0.014961, weight_decay: 0.000100, momentum_teacher: 0.996163, loss: 4.5680
2022-10-02 18:04:50 - train: epoch 0013, iter [09400, 10009], lr: 0.014961, weight_decay: 0.000100, momentum_teacher: 0.996163, loss: 4.4404
2022-10-02 18:05:57 - train: epoch 0013, iter [09500, 10009], lr: 0.014960, weight_decay: 0.000100, momentum_teacher: 0.996163, loss: 4.4088
2022-10-02 18:07:05 - train: epoch 0013, iter [09600, 10009], lr: 0.014960, weight_decay: 0.000100, momentum_teacher: 0.996163, loss: 4.6244
2022-10-02 18:08:04 - train: epoch 0013, iter [09700, 10009], lr: 0.014960, weight_decay: 0.000100, momentum_teacher: 0.996164, loss: 4.7524
2022-10-02 18:09:08 - train: epoch 0013, iter [09800, 10009], lr: 0.014959, weight_decay: 0.000100, momentum_teacher: 0.996164, loss: 4.5689
2022-10-02 18:10:08 - train: epoch 0013, iter [09900, 10009], lr: 0.014959, weight_decay: 0.000100, momentum_teacher: 0.996164, loss: 4.7495
2022-10-02 18:11:05 - train: epoch 0013, iter [10000, 10009], lr: 0.014959, weight_decay: 0.000100, momentum_teacher: 0.996164, loss: 4.6120
2022-10-02 18:11:10 - train: epoch 013, train_loss: 4.7189
2022-10-02 18:11:11 - until epoch: 013, best_loss: 4.7189
2022-10-02 21:14:47 - epoch 014 lr: 0.014959
2022-10-02 21:15:42 - train: epoch 0014, iter [00100, 10009], lr: 0.014959, weight_decay: 0.000100, momentum_teacher: 0.996165, loss: 4.6446
2022-10-02 21:16:29 - train: epoch 0014, iter [00200, 10009], lr: 0.014958, weight_decay: 0.000100, momentum_teacher: 0.996165, loss: 4.5594
2022-10-02 21:17:17 - train: epoch 0014, iter [00300, 10009], lr: 0.014958, weight_decay: 0.000100, momentum_teacher: 0.996165, loss: 4.7187
2022-10-02 21:18:05 - train: epoch 0014, iter [00400, 10009], lr: 0.014958, weight_decay: 0.000100, momentum_teacher: 0.996165, loss: 4.7160
2022-10-02 21:18:52 - train: epoch 0014, iter [00500, 10009], lr: 0.014958, weight_decay: 0.000100, momentum_teacher: 0.996166, loss: 4.5886
2022-10-02 21:19:40 - train: epoch 0014, iter [00600, 10009], lr: 0.014957, weight_decay: 0.000100, momentum_teacher: 0.996166, loss: 4.5262
2022-10-02 21:20:27 - train: epoch 0014, iter [00700, 10009], lr: 0.014957, weight_decay: 0.000100, momentum_teacher: 0.996166, loss: 4.4503
2022-10-02 21:21:15 - train: epoch 0014, iter [00800, 10009], lr: 0.014957, weight_decay: 0.000100, momentum_teacher: 0.996166, loss: 4.6301
2022-10-02 21:22:03 - train: epoch 0014, iter [00900, 10009], lr: 0.014956, weight_decay: 0.000100, momentum_teacher: 0.996167, loss: 4.4666
2022-10-02 21:22:50 - train: epoch 0014, iter [01000, 10009], lr: 0.014956, weight_decay: 0.000100, momentum_teacher: 0.996167, loss: 4.5889
2022-10-02 21:23:38 - train: epoch 0014, iter [01100, 10009], lr: 0.014956, weight_decay: 0.000100, momentum_teacher: 0.996167, loss: 4.3655
2022-10-02 21:24:26 - train: epoch 0014, iter [01200, 10009], lr: 0.014956, weight_decay: 0.000100, momentum_teacher: 0.996167, loss: 4.5257
2022-10-02 21:25:13 - train: epoch 0014, iter [01300, 10009], lr: 0.014955, weight_decay: 0.000100, momentum_teacher: 0.996168, loss: 4.6995
2022-10-02 21:26:01 - train: epoch 0014, iter [01400, 10009], lr: 0.014955, weight_decay: 0.000100, momentum_teacher: 0.996168, loss: 4.5422
2022-10-02 21:26:48 - train: epoch 0014, iter [01500, 10009], lr: 0.014955, weight_decay: 0.000100, momentum_teacher: 0.996168, loss: 4.6839
2022-10-02 21:27:36 - train: epoch 0014, iter [01600, 10009], lr: 0.014954, weight_decay: 0.000100, momentum_teacher: 0.996169, loss: 4.3855
2022-10-02 21:28:25 - train: epoch 0014, iter [01700, 10009], lr: 0.014954, weight_decay: 0.000100, momentum_teacher: 0.996169, loss: 4.5049
2022-10-02 21:29:12 - train: epoch 0014, iter [01800, 10009], lr: 0.014954, weight_decay: 0.000100, momentum_teacher: 0.996169, loss: 4.5486
2022-10-02 21:30:00 - train: epoch 0014, iter [01900, 10009], lr: 0.014954, weight_decay: 0.000100, momentum_teacher: 0.996169, loss: 4.4243
2022-10-02 21:30:48 - train: epoch 0014, iter [02000, 10009], lr: 0.014953, weight_decay: 0.000100, momentum_teacher: 0.996170, loss: 4.7101
2022-10-02 21:31:36 - train: epoch 0014, iter [02100, 10009], lr: 0.014953, weight_decay: 0.000100, momentum_teacher: 0.996170, loss: 4.6183
2022-10-02 21:32:23 - train: epoch 0014, iter [02200, 10009], lr: 0.014953, weight_decay: 0.000100, momentum_teacher: 0.996170, loss: 4.5451
2022-10-02 21:33:11 - train: epoch 0014, iter [02300, 10009], lr: 0.014952, weight_decay: 0.000100, momentum_teacher: 0.996170, loss: 4.4891
2022-10-02 21:33:59 - train: epoch 0014, iter [02400, 10009], lr: 0.014952, weight_decay: 0.000100, momentum_teacher: 0.996171, loss: 4.4040
2022-10-02 21:34:47 - train: epoch 0014, iter [02500, 10009], lr: 0.014952, weight_decay: 0.000100, momentum_teacher: 0.996171, loss: 4.5727
2022-10-02 21:35:35 - train: epoch 0014, iter [02600, 10009], lr: 0.014952, weight_decay: 0.000100, momentum_teacher: 0.996171, loss: 4.5408
2022-10-02 21:36:23 - train: epoch 0014, iter [02700, 10009], lr: 0.014951, weight_decay: 0.000100, momentum_teacher: 0.996171, loss: 4.6516
2022-10-02 21:37:11 - train: epoch 0014, iter [02800, 10009], lr: 0.014951, weight_decay: 0.000100, momentum_teacher: 0.996172, loss: 4.7760
2022-10-02 21:37:59 - train: epoch 0014, iter [02900, 10009], lr: 0.014951, weight_decay: 0.000100, momentum_teacher: 0.996172, loss: 4.7398
2022-10-02 21:38:46 - train: epoch 0014, iter [03000, 10009], lr: 0.014950, weight_decay: 0.000100, momentum_teacher: 0.996172, loss: 4.5847
2022-10-02 21:39:34 - train: epoch 0014, iter [03100, 10009], lr: 0.014950, weight_decay: 0.000100, momentum_teacher: 0.996172, loss: 4.3756
2022-10-02 21:40:22 - train: epoch 0014, iter [03200, 10009], lr: 0.014950, weight_decay: 0.000100, momentum_teacher: 0.996173, loss: 4.4689
2022-10-02 21:41:10 - train: epoch 0014, iter [03300, 10009], lr: 0.014949, weight_decay: 0.000100, momentum_teacher: 0.996173, loss: 4.5387
2022-10-02 21:42:00 - train: epoch 0014, iter [03400, 10009], lr: 0.014949, weight_decay: 0.000100, momentum_teacher: 0.996173, loss: 4.5155
2022-10-02 21:42:51 - train: epoch 0014, iter [03500, 10009], lr: 0.014949, weight_decay: 0.000100, momentum_teacher: 0.996173, loss: 4.3479
2022-10-02 21:43:40 - train: epoch 0014, iter [03600, 10009], lr: 0.014948, weight_decay: 0.000100, momentum_teacher: 0.996174, loss: 4.5718
2022-10-02 21:44:28 - train: epoch 0014, iter [03700, 10009], lr: 0.014948, weight_decay: 0.000100, momentum_teacher: 0.996174, loss: 4.6367
2022-10-02 21:45:16 - train: epoch 0014, iter [03800, 10009], lr: 0.014948, weight_decay: 0.000100, momentum_teacher: 0.996174, loss: 4.4790
2022-10-02 21:46:04 - train: epoch 0014, iter [03900, 10009], lr: 0.014948, weight_decay: 0.000100, momentum_teacher: 0.996174, loss: 4.6211
2022-10-02 21:46:51 - train: epoch 0014, iter [04000, 10009], lr: 0.014947, weight_decay: 0.000100, momentum_teacher: 0.996175, loss: 4.5070
2022-10-02 21:47:39 - train: epoch 0014, iter [04100, 10009], lr: 0.014947, weight_decay: 0.000100, momentum_teacher: 0.996175, loss: 4.4345
2022-10-02 21:48:27 - train: epoch 0014, iter [04200, 10009], lr: 0.014947, weight_decay: 0.000100, momentum_teacher: 0.996175, loss: 4.6096
2022-10-02 21:49:15 - train: epoch 0014, iter [04300, 10009], lr: 0.014946, weight_decay: 0.000100, momentum_teacher: 0.996175, loss: 4.7184
2022-10-02 21:50:03 - train: epoch 0014, iter [04400, 10009], lr: 0.014946, weight_decay: 0.000100, momentum_teacher: 0.996176, loss: 4.6009
2022-10-02 21:50:51 - train: epoch 0014, iter [04500, 10009], lr: 0.014946, weight_decay: 0.000100, momentum_teacher: 0.996176, loss: 4.4623
2022-10-02 21:51:38 - train: epoch 0014, iter [04600, 10009], lr: 0.014945, weight_decay: 0.000100, momentum_teacher: 0.996176, loss: 4.5301
2022-10-02 21:52:26 - train: epoch 0014, iter [04700, 10009], lr: 0.014945, weight_decay: 0.000100, momentum_teacher: 0.996176, loss: 4.4912
2022-10-02 21:53:18 - train: epoch 0014, iter [04800, 10009], lr: 0.014945, weight_decay: 0.000100, momentum_teacher: 0.996177, loss: 4.4436
2022-10-02 21:54:08 - train: epoch 0014, iter [04900, 10009], lr: 0.014944, weight_decay: 0.000100, momentum_teacher: 0.996177, loss: 4.5330
2022-10-02 21:54:58 - train: epoch 0014, iter [05000, 10009], lr: 0.014944, weight_decay: 0.000100, momentum_teacher: 0.996177, loss: 4.4848
2022-10-02 21:55:46 - train: epoch 0014, iter [05100, 10009], lr: 0.014944, weight_decay: 0.000100, momentum_teacher: 0.996177, loss: 4.6346
2022-10-02 21:56:35 - train: epoch 0014, iter [05200, 10009], lr: 0.014943, weight_decay: 0.000100, momentum_teacher: 0.996178, loss: 4.5988
2022-10-02 21:57:23 - train: epoch 0014, iter [05300, 10009], lr: 0.014943, weight_decay: 0.000100, momentum_teacher: 0.996178, loss: 4.7363
2022-10-02 21:58:12 - train: epoch 0014, iter [05400, 10009], lr: 0.014943, weight_decay: 0.000100, momentum_teacher: 0.996178, loss: 4.6211
2022-10-02 21:59:02 - train: epoch 0014, iter [05500, 10009], lr: 0.014943, weight_decay: 0.000100, momentum_teacher: 0.996178, loss: 4.3047
2022-10-02 21:59:57 - train: epoch 0014, iter [05600, 10009], lr: 0.014942, weight_decay: 0.000100, momentum_teacher: 0.996179, loss: 4.5072
2022-10-02 22:00:56 - train: epoch 0014, iter [05700, 10009], lr: 0.014942, weight_decay: 0.000100, momentum_teacher: 0.996179, loss: 4.3974
2022-10-02 22:01:54 - train: epoch 0014, iter [05800, 10009], lr: 0.014942, weight_decay: 0.000100, momentum_teacher: 0.996179, loss: 4.5400
2022-10-02 22:02:51 - train: epoch 0014, iter [05900, 10009], lr: 0.014941, weight_decay: 0.000100, momentum_teacher: 0.996180, loss: 4.3561
2022-10-02 22:03:39 - train: epoch 0014, iter [06000, 10009], lr: 0.014941, weight_decay: 0.000100, momentum_teacher: 0.996180, loss: 4.7066
2022-10-02 22:04:27 - train: epoch 0014, iter [06100, 10009], lr: 0.014941, weight_decay: 0.000100, momentum_teacher: 0.996180, loss: 4.3819
2022-10-02 22:05:14 - train: epoch 0014, iter [06200, 10009], lr: 0.014940, weight_decay: 0.000100, momentum_teacher: 0.996180, loss: 4.7375
2022-10-02 22:06:02 - train: epoch 0014, iter [06300, 10009], lr: 0.014940, weight_decay: 0.000100, momentum_teacher: 0.996181, loss: 4.4572
2022-10-02 22:06:49 - train: epoch 0014, iter [06400, 10009], lr: 0.014940, weight_decay: 0.000100, momentum_teacher: 0.996181, loss: 4.5019
2022-10-02 22:07:37 - train: epoch 0014, iter [06500, 10009], lr: 0.014939, weight_decay: 0.000100, momentum_teacher: 0.996181, loss: 4.6226
2022-10-02 22:08:24 - train: epoch 0014, iter [06600, 10009], lr: 0.014939, weight_decay: 0.000100, momentum_teacher: 0.996181, loss: 4.3332
2022-10-02 22:09:12 - train: epoch 0014, iter [06700, 10009], lr: 0.014939, weight_decay: 0.000100, momentum_teacher: 0.996182, loss: 4.4377
2022-10-02 22:09:59 - train: epoch 0014, iter [06800, 10009], lr: 0.014938, weight_decay: 0.000100, momentum_teacher: 0.996182, loss: 4.6191
2022-10-02 22:10:47 - train: epoch 0014, iter [06900, 10009], lr: 0.014938, weight_decay: 0.000100, momentum_teacher: 0.996182, loss: 4.4405
2022-10-02 22:11:34 - train: epoch 0014, iter [07000, 10009], lr: 0.014938, weight_decay: 0.000100, momentum_teacher: 0.996182, loss: 4.4880
2022-10-02 22:12:22 - train: epoch 0014, iter [07100, 10009], lr: 0.014937, weight_decay: 0.000100, momentum_teacher: 0.996183, loss: 4.6751
2022-10-02 22:13:09 - train: epoch 0014, iter [07200, 10009], lr: 0.014937, weight_decay: 0.000100, momentum_teacher: 0.996183, loss: 4.4272
2022-10-02 22:13:57 - train: epoch 0014, iter [07300, 10009], lr: 0.014937, weight_decay: 0.000100, momentum_teacher: 0.996183, loss: 4.3537
2022-10-02 22:14:44 - train: epoch 0014, iter [07400, 10009], lr: 0.014936, weight_decay: 0.000100, momentum_teacher: 0.996183, loss: 4.4399
2022-10-02 22:15:31 - train: epoch 0014, iter [07500, 10009], lr: 0.014936, weight_decay: 0.000100, momentum_teacher: 0.996184, loss: 4.2879
2022-10-02 22:16:19 - train: epoch 0014, iter [07600, 10009], lr: 0.014936, weight_decay: 0.000100, momentum_teacher: 0.996184, loss: 4.3919
2022-10-02 22:17:06 - train: epoch 0014, iter [07700, 10009], lr: 0.014935, weight_decay: 0.000100, momentum_teacher: 0.996184, loss: 4.4553
2022-10-02 22:17:54 - train: epoch 0014, iter [07800, 10009], lr: 0.014935, weight_decay: 0.000100, momentum_teacher: 0.996184, loss: 4.5033
2022-10-02 22:18:41 - train: epoch 0014, iter [07900, 10009], lr: 0.014934, weight_decay: 0.000100, momentum_teacher: 0.996185, loss: 4.4695
2022-10-02 22:19:29 - train: epoch 0014, iter [08000, 10009], lr: 0.014934, weight_decay: 0.000100, momentum_teacher: 0.996185, loss: 4.7410
2022-10-02 22:20:16 - train: epoch 0014, iter [08100, 10009], lr: 0.014934, weight_decay: 0.000100, momentum_teacher: 0.996185, loss: 4.5439
2022-10-02 22:21:04 - train: epoch 0014, iter [08200, 10009], lr: 0.014933, weight_decay: 0.000100, momentum_teacher: 0.996186, loss: 4.5653
2022-10-02 22:21:52 - train: epoch 0014, iter [08300, 10009], lr: 0.014933, weight_decay: 0.000100, momentum_teacher: 0.996186, loss: 4.7103
2022-10-02 22:22:39 - train: epoch 0014, iter [08400, 10009], lr: 0.014933, weight_decay: 0.000100, momentum_teacher: 0.996186, loss: 4.7008
2022-10-02 22:23:27 - train: epoch 0014, iter [08500, 10009], lr: 0.014932, weight_decay: 0.000100, momentum_teacher: 0.996186, loss: 4.4727
2022-10-02 22:24:14 - train: epoch 0014, iter [08600, 10009], lr: 0.014932, weight_decay: 0.000100, momentum_teacher: 0.996187, loss: 4.4652
2022-10-02 22:25:02 - train: epoch 0014, iter [08700, 10009], lr: 0.014932, weight_decay: 0.000100, momentum_teacher: 0.996187, loss: 4.5953
2022-10-02 22:25:49 - train: epoch 0014, iter [08800, 10009], lr: 0.014931, weight_decay: 0.000100, momentum_teacher: 0.996187, loss: 4.3701
2022-10-02 22:26:37 - train: epoch 0014, iter [08900, 10009], lr: 0.014931, weight_decay: 0.000100, momentum_teacher: 0.996187, loss: 4.4080
2022-10-02 22:27:24 - train: epoch 0014, iter [09000, 10009], lr: 0.014931, weight_decay: 0.000100, momentum_teacher: 0.996188, loss: 4.6541
2022-10-02 22:28:11 - train: epoch 0014, iter [09100, 10009], lr: 0.014930, weight_decay: 0.000100, momentum_teacher: 0.996188, loss: 4.3086
2022-10-02 22:28:59 - train: epoch 0014, iter [09200, 10009], lr: 0.014930, weight_decay: 0.000100, momentum_teacher: 0.996188, loss: 4.5575
2022-10-02 22:29:46 - train: epoch 0014, iter [09300, 10009], lr: 0.014930, weight_decay: 0.000100, momentum_teacher: 0.996188, loss: 4.5947
2022-10-02 22:30:34 - train: epoch 0014, iter [09400, 10009], lr: 0.014929, weight_decay: 0.000100, momentum_teacher: 0.996189, loss: 4.5020
2022-10-02 22:31:21 - train: epoch 0014, iter [09500, 10009], lr: 0.014929, weight_decay: 0.000100, momentum_teacher: 0.996189, loss: 4.7055
2022-10-02 22:32:08 - train: epoch 0014, iter [09600, 10009], lr: 0.014928, weight_decay: 0.000100, momentum_teacher: 0.996189, loss: 4.5148
2022-10-02 22:32:56 - train: epoch 0014, iter [09700, 10009], lr: 0.014928, weight_decay: 0.000100, momentum_teacher: 0.996190, loss: 4.6408
2022-10-02 22:33:43 - train: epoch 0014, iter [09800, 10009], lr: 0.014928, weight_decay: 0.000100, momentum_teacher: 0.996190, loss: 4.6469
2022-10-02 22:34:30 - train: epoch 0014, iter [09900, 10009], lr: 0.014927, weight_decay: 0.000100, momentum_teacher: 0.996190, loss: 4.5329
2022-10-02 22:35:18 - train: epoch 0014, iter [10000, 10009], lr: 0.014927, weight_decay: 0.000100, momentum_teacher: 0.996190, loss: 4.4039
2022-10-02 22:35:23 - train: epoch 014, train_loss: 4.5489
2022-10-02 22:35:24 - until epoch: 014, best_loss: 4.5489
2022-10-02 22:35:24 - epoch 015 lr: 0.014927
2022-10-02 22:36:17 - train: epoch 0015, iter [00100, 10009], lr: 0.014927, weight_decay: 0.000100, momentum_teacher: 0.996191, loss: 4.3329
2022-10-02 22:37:05 - train: epoch 0015, iter [00200, 10009], lr: 0.014926, weight_decay: 0.000100, momentum_teacher: 0.996191, loss: 4.3795
2022-10-02 22:37:53 - train: epoch 0015, iter [00300, 10009], lr: 0.014926, weight_decay: 0.000100, momentum_teacher: 0.996191, loss: 4.3642
2022-10-02 22:38:41 - train: epoch 0015, iter [00400, 10009], lr: 0.014926, weight_decay: 0.000100, momentum_teacher: 0.996191, loss: 4.3876
2022-10-02 22:39:29 - train: epoch 0015, iter [00500, 10009], lr: 0.014925, weight_decay: 0.000100, momentum_teacher: 0.996192, loss: 4.4176
2022-10-02 22:40:16 - train: epoch 0015, iter [00600, 10009], lr: 0.014925, weight_decay: 0.000100, momentum_teacher: 0.996192, loss: 4.5645
2022-10-02 22:41:04 - train: epoch 0015, iter [00700, 10009], lr: 0.014924, weight_decay: 0.000100, momentum_teacher: 0.996192, loss: 4.5024
2022-10-02 22:41:52 - train: epoch 0015, iter [00800, 10009], lr: 0.014924, weight_decay: 0.000100, momentum_teacher: 0.996192, loss: 4.4250
2022-10-02 22:42:40 - train: epoch 0015, iter [00900, 10009], lr: 0.014924, weight_decay: 0.000100, momentum_teacher: 0.996193, loss: 4.5579
2022-10-02 22:43:27 - train: epoch 0015, iter [01000, 10009], lr: 0.014923, weight_decay: 0.000100, momentum_teacher: 0.996193, loss: 4.4469
2022-10-02 22:44:15 - train: epoch 0015, iter [01100, 10009], lr: 0.014923, weight_decay: 0.000100, momentum_teacher: 0.996193, loss: 4.3690
2022-10-02 22:45:03 - train: epoch 0015, iter [01200, 10009], lr: 0.014923, weight_decay: 0.000100, momentum_teacher: 0.996194, loss: 4.2808
2022-10-02 22:45:53 - train: epoch 0015, iter [01300, 10009], lr: 0.014922, weight_decay: 0.000100, momentum_teacher: 0.996194, loss: 4.2747
2022-10-02 22:46:41 - train: epoch 0015, iter [01400, 10009], lr: 0.014922, weight_decay: 0.000100, momentum_teacher: 0.996194, loss: 4.2392
2022-10-02 22:47:30 - train: epoch 0015, iter [01500, 10009], lr: 0.014921, weight_decay: 0.000100, momentum_teacher: 0.996194, loss: 4.4159
2022-10-02 22:48:22 - train: epoch 0015, iter [01600, 10009], lr: 0.014921, weight_decay: 0.000100, momentum_teacher: 0.996195, loss: 4.4138
2022-10-02 22:49:23 - train: epoch 0015, iter [01700, 10009], lr: 0.014921, weight_decay: 0.000100, momentum_teacher: 0.996195, loss: 4.2913
2022-10-02 22:50:17 - train: epoch 0015, iter [01800, 10009], lr: 0.014920, weight_decay: 0.000100, momentum_teacher: 0.996195, loss: 4.3433
2022-10-02 22:51:15 - train: epoch 0015, iter [01900, 10009], lr: 0.014920, weight_decay: 0.000100, momentum_teacher: 0.996195, loss: 4.4549
2022-10-02 22:52:10 - train: epoch 0015, iter [02000, 10009], lr: 0.014920, weight_decay: 0.000100, momentum_teacher: 0.996196, loss: 4.5172
2022-10-02 22:53:12 - train: epoch 0015, iter [02100, 10009], lr: 0.014919, weight_decay: 0.000100, momentum_teacher: 0.996196, loss: 4.5915
2022-10-02 22:54:08 - train: epoch 0015, iter [02200, 10009], lr: 0.014919, weight_decay: 0.000100, momentum_teacher: 0.996196, loss: 4.5046
2022-10-02 22:55:12 - train: epoch 0015, iter [02300, 10009], lr: 0.014918, weight_decay: 0.000100, momentum_teacher: 0.996197, loss: 4.3419
2022-10-02 22:56:16 - train: epoch 0015, iter [02400, 10009], lr: 0.014918, weight_decay: 0.000100, momentum_teacher: 0.996197, loss: 4.2620
2022-10-02 22:57:12 - train: epoch 0015, iter [02500, 10009], lr: 0.014918, weight_decay: 0.000100, momentum_teacher: 0.996197, loss: 4.6667
2022-10-02 22:58:19 - train: epoch 0015, iter [02600, 10009], lr: 0.014917, weight_decay: 0.000100, momentum_teacher: 0.996197, loss: 4.3212
2022-10-02 22:59:22 - train: epoch 0015, iter [02700, 10009], lr: 0.014917, weight_decay: 0.000100, momentum_teacher: 0.996198, loss: 4.3569
2022-10-02 23:00:27 - train: epoch 0015, iter [02800, 10009], lr: 0.014916, weight_decay: 0.000100, momentum_teacher: 0.996198, loss: 4.4855
2022-10-02 23:01:41 - train: epoch 0015, iter [02900, 10009], lr: 0.014916, weight_decay: 0.000100, momentum_teacher: 0.996198, loss: 4.6724
2022-10-02 23:02:44 - train: epoch 0015, iter [03000, 10009], lr: 0.014916, weight_decay: 0.000100, momentum_teacher: 0.996198, loss: 4.4748
2022-10-02 23:03:33 - train: epoch 0015, iter [03100, 10009], lr: 0.014915, weight_decay: 0.000100, momentum_teacher: 0.996199, loss: 4.5630
2022-10-02 23:04:25 - train: epoch 0015, iter [03200, 10009], lr: 0.014915, weight_decay: 0.000100, momentum_teacher: 0.996199, loss: 4.4290
2022-10-02 23:05:22 - train: epoch 0015, iter [03300, 10009], lr: 0.014915, weight_decay: 0.000100, momentum_teacher: 0.996199, loss: 4.3300
2022-10-02 23:06:19 - train: epoch 0015, iter [03400, 10009], lr: 0.014914, weight_decay: 0.000100, momentum_teacher: 0.996200, loss: 4.6207
2022-10-02 23:07:11 - train: epoch 0015, iter [03500, 10009], lr: 0.014914, weight_decay: 0.000100, momentum_teacher: 0.996200, loss: 4.3598
2022-10-02 23:07:59 - train: epoch 0015, iter [03600, 10009], lr: 0.014913, weight_decay: 0.000100, momentum_teacher: 0.996200, loss: 4.6133
2022-10-02 23:08:47 - train: epoch 0015, iter [03700, 10009], lr: 0.014913, weight_decay: 0.000100, momentum_teacher: 0.996200, loss: 4.5887
2022-10-02 23:09:35 - train: epoch 0015, iter [03800, 10009], lr: 0.014913, weight_decay: 0.000100, momentum_teacher: 0.996201, loss: 4.5217
2022-10-02 23:10:22 - train: epoch 0015, iter [03900, 10009], lr: 0.014912, weight_decay: 0.000100, momentum_teacher: 0.996201, loss: 4.2952
2022-10-02 23:11:10 - train: epoch 0015, iter [04000, 10009], lr: 0.014912, weight_decay: 0.000100, momentum_teacher: 0.996201, loss: 4.3895
2022-10-02 23:11:58 - train: epoch 0015, iter [04100, 10009], lr: 0.014911, weight_decay: 0.000100, momentum_teacher: 0.996201, loss: 4.5736
2022-10-02 23:12:46 - train: epoch 0015, iter [04200, 10009], lr: 0.014911, weight_decay: 0.000100, momentum_teacher: 0.996202, loss: 4.4682
2022-10-02 23:13:36 - train: epoch 0015, iter [04300, 10009], lr: 0.014911, weight_decay: 0.000100, momentum_teacher: 0.996202, loss: 4.4809
2022-10-02 23:14:24 - train: epoch 0015, iter [04400, 10009], lr: 0.014910, weight_decay: 0.000100, momentum_teacher: 0.996202, loss: 4.3129
2022-10-02 23:15:12 - train: epoch 0015, iter [04500, 10009], lr: 0.014910, weight_decay: 0.000100, momentum_teacher: 0.996203, loss: 4.4394
2022-10-02 23:16:00 - train: epoch 0015, iter [04600, 10009], lr: 0.014909, weight_decay: 0.000100, momentum_teacher: 0.996203, loss: 4.3670
2022-10-02 23:16:48 - train: epoch 0015, iter [04700, 10009], lr: 0.014909, weight_decay: 0.000100, momentum_teacher: 0.996203, loss: 4.3334
2022-10-02 23:17:36 - train: epoch 0015, iter [04800, 10009], lr: 0.014909, weight_decay: 0.000100, momentum_teacher: 0.996203, loss: 4.6035
2022-10-02 23:18:26 - train: epoch 0015, iter [04900, 10009], lr: 0.014908, weight_decay: 0.000100, momentum_teacher: 0.996204, loss: 4.3936
2022-10-02 23:19:15 - train: epoch 0015, iter [05000, 10009], lr: 0.014908, weight_decay: 0.000100, momentum_teacher: 0.996204, loss: 4.5575
2022-10-02 23:20:07 - train: epoch 0015, iter [05100, 10009], lr: 0.014907, weight_decay: 0.000100, momentum_teacher: 0.996204, loss: 4.4788
2022-10-02 23:21:00 - train: epoch 0015, iter [05200, 10009], lr: 0.014907, weight_decay: 0.000100, momentum_teacher: 0.996204, loss: 4.3046
2022-10-02 23:22:15 - train: epoch 0015, iter [05300, 10009], lr: 0.014906, weight_decay: 0.000100, momentum_teacher: 0.996205, loss: 4.4022
2022-10-02 23:23:03 - train: epoch 0015, iter [05400, 10009], lr: 0.014906, weight_decay: 0.000100, momentum_teacher: 0.996205, loss: 4.4496
2022-10-02 23:24:02 - train: epoch 0015, iter [05500, 10009], lr: 0.014906, weight_decay: 0.000100, momentum_teacher: 0.996205, loss: 4.4670
2022-10-02 23:26:07 - train: epoch 0015, iter [05600, 10009], lr: 0.014905, weight_decay: 0.000100, momentum_teacher: 0.996206, loss: 4.5765
2022-10-02 23:26:55 - train: epoch 0015, iter [05700, 10009], lr: 0.014905, weight_decay: 0.000100, momentum_teacher: 0.996206, loss: 4.2639
2022-10-02 23:27:42 - train: epoch 0015, iter [05800, 10009], lr: 0.014904, weight_decay: 0.000100, momentum_teacher: 0.996206, loss: 4.4802
2022-10-02 23:28:30 - train: epoch 0015, iter [05900, 10009], lr: 0.014904, weight_decay: 0.000100, momentum_teacher: 0.996206, loss: 4.3052
2022-10-02 23:29:18 - train: epoch 0015, iter [06000, 10009], lr: 0.014904, weight_decay: 0.000100, momentum_teacher: 0.996207, loss: 4.3017
2022-10-02 23:30:05 - train: epoch 0015, iter [06100, 10009], lr: 0.014903, weight_decay: 0.000100, momentum_teacher: 0.996207, loss: 4.4360
2022-10-02 23:30:53 - train: epoch 0015, iter [06200, 10009], lr: 0.014903, weight_decay: 0.000100, momentum_teacher: 0.996207, loss: 4.2973
2022-10-02 23:31:41 - train: epoch 0015, iter [06300, 10009], lr: 0.014902, weight_decay: 0.000100, momentum_teacher: 0.996208, loss: 4.4916
2022-10-02 23:32:29 - train: epoch 0015, iter [06400, 10009], lr: 0.014902, weight_decay: 0.000100, momentum_teacher: 0.996208, loss: 4.4646
2022-10-02 23:33:16 - train: epoch 0015, iter [06500, 10009], lr: 0.014901, weight_decay: 0.000100, momentum_teacher: 0.996208, loss: 4.4570
2022-10-02 23:34:04 - train: epoch 0015, iter [06600, 10009], lr: 0.014901, weight_decay: 0.000100, momentum_teacher: 0.996208, loss: 4.5285
2022-10-02 23:34:52 - train: epoch 0015, iter [06700, 10009], lr: 0.014901, weight_decay: 0.000100, momentum_teacher: 0.996209, loss: 4.3093
2022-10-02 23:35:43 - train: epoch 0015, iter [06800, 10009], lr: 0.014900, weight_decay: 0.000100, momentum_teacher: 0.996209, loss: 4.3538
2022-10-02 23:36:37 - train: epoch 0015, iter [06900, 10009], lr: 0.014900, weight_decay: 0.000100, momentum_teacher: 0.996209, loss: 4.3527
2022-10-02 23:37:29 - train: epoch 0015, iter [07000, 10009], lr: 0.014899, weight_decay: 0.000100, momentum_teacher: 0.996209, loss: 4.3616
2022-10-02 23:38:19 - train: epoch 0015, iter [07100, 10009], lr: 0.014899, weight_decay: 0.000100, momentum_teacher: 0.996210, loss: 4.3942
2022-10-02 23:39:07 - train: epoch 0015, iter [07200, 10009], lr: 0.014898, weight_decay: 0.000100, momentum_teacher: 0.996210, loss: 4.4435
2022-10-02 23:40:10 - train: epoch 0015, iter [07300, 10009], lr: 0.014898, weight_decay: 0.000100, momentum_teacher: 0.996210, loss: 4.5634
2022-10-02 23:42:27 - train: epoch 0015, iter [07400, 10009], lr: 0.014898, weight_decay: 0.000100, momentum_teacher: 0.996211, loss: 4.5677
2022-10-02 23:43:57 - train: epoch 0015, iter [07500, 10009], lr: 0.014897, weight_decay: 0.000100, momentum_teacher: 0.996211, loss: 4.2728
2022-10-02 23:44:46 - train: epoch 0015, iter [07600, 10009], lr: 0.014897, weight_decay: 0.000100, momentum_teacher: 0.996211, loss: 4.4495
2022-10-02 23:45:34 - train: epoch 0015, iter [07700, 10009], lr: 0.014896, weight_decay: 0.000100, momentum_teacher: 0.996211, loss: 4.3443
2022-10-02 23:46:23 - train: epoch 0015, iter [07800, 10009], lr: 0.014896, weight_decay: 0.000100, momentum_teacher: 0.996212, loss: 4.5064
2022-10-02 23:47:12 - train: epoch 0015, iter [07900, 10009], lr: 0.014895, weight_decay: 0.000100, momentum_teacher: 0.996212, loss: 4.4937
2022-10-02 23:48:01 - train: epoch 0015, iter [08000, 10009], lr: 0.014895, weight_decay: 0.000100, momentum_teacher: 0.996212, loss: 4.3721
2022-10-02 23:48:50 - train: epoch 0015, iter [08100, 10009], lr: 0.014895, weight_decay: 0.000100, momentum_teacher: 0.996213, loss: 4.3192
2022-10-02 23:49:39 - train: epoch 0015, iter [08200, 10009], lr: 0.014894, weight_decay: 0.000100, momentum_teacher: 0.996213, loss: 4.4206
2022-10-02 23:50:27 - train: epoch 0015, iter [08300, 10009], lr: 0.014894, weight_decay: 0.000100, momentum_teacher: 0.996213, loss: 4.1652
2022-10-02 23:51:19 - train: epoch 0015, iter [08400, 10009], lr: 0.014893, weight_decay: 0.000100, momentum_teacher: 0.996213, loss: 4.3138
2022-10-02 23:53:38 - train: epoch 0015, iter [08500, 10009], lr: 0.014893, weight_decay: 0.000100, momentum_teacher: 0.996214, loss: 4.1636
2022-10-02 23:54:25 - train: epoch 0015, iter [08600, 10009], lr: 0.014892, weight_decay: 0.000100, momentum_teacher: 0.996214, loss: 4.4956
2022-10-02 23:55:13 - train: epoch 0015, iter [08700, 10009], lr: 0.014892, weight_decay: 0.000100, momentum_teacher: 0.996214, loss: 4.4787
2022-10-02 23:56:01 - train: epoch 0015, iter [08800, 10009], lr: 0.014891, weight_decay: 0.000100, momentum_teacher: 0.996215, loss: 4.2279
2022-10-02 23:56:48 - train: epoch 0015, iter [08900, 10009], lr: 0.014891, weight_decay: 0.000100, momentum_teacher: 0.996215, loss: 4.2495
2022-10-02 23:57:36 - train: epoch 0015, iter [09000, 10009], lr: 0.014891, weight_decay: 0.000100, momentum_teacher: 0.996215, loss: 4.4419
2022-10-02 23:58:24 - train: epoch 0015, iter [09100, 10009], lr: 0.014890, weight_decay: 0.000100, momentum_teacher: 0.996215, loss: 4.2130
2022-10-02 23:59:12 - train: epoch 0015, iter [09200, 10009], lr: 0.014890, weight_decay: 0.000100, momentum_teacher: 0.996216, loss: 4.5512
2022-10-03 00:00:00 - train: epoch 0015, iter [09300, 10009], lr: 0.014889, weight_decay: 0.000100, momentum_teacher: 0.996216, loss: 4.2672
2022-10-03 00:00:48 - train: epoch 0015, iter [09400, 10009], lr: 0.014889, weight_decay: 0.000100, momentum_teacher: 0.996216, loss: 4.3309
2022-10-03 00:01:36 - train: epoch 0015, iter [09500, 10009], lr: 0.014888, weight_decay: 0.000100, momentum_teacher: 0.996217, loss: 4.3627
2022-10-03 00:02:30 - train: epoch 0015, iter [09600, 10009], lr: 0.014888, weight_decay: 0.000100, momentum_teacher: 0.996217, loss: 4.2526
2022-10-03 00:03:18 - train: epoch 0015, iter [09700, 10009], lr: 0.014887, weight_decay: 0.000100, momentum_teacher: 0.996217, loss: 4.2832
2022-10-03 00:04:06 - train: epoch 0015, iter [09800, 10009], lr: 0.014887, weight_decay: 0.000100, momentum_teacher: 0.996217, loss: 4.4661
2022-10-03 00:04:54 - train: epoch 0015, iter [09900, 10009], lr: 0.014887, weight_decay: 0.000100, momentum_teacher: 0.996218, loss: 4.4652
2022-10-03 00:05:42 - train: epoch 0015, iter [10000, 10009], lr: 0.014886, weight_decay: 0.000100, momentum_teacher: 0.996218, loss: 4.4133
2022-10-03 00:05:47 - train: epoch 015, train_loss: 4.4047
2022-10-03 00:05:49 - until epoch: 015, best_loss: 4.4047
2022-10-03 00:05:49 - epoch 016 lr: 0.014886
2022-10-03 00:06:43 - train: epoch 0016, iter [00100, 10009], lr: 0.014886, weight_decay: 0.000100, momentum_teacher: 0.996218, loss: 4.0956
2022-10-03 00:07:31 - train: epoch 0016, iter [00200, 10009], lr: 0.014885, weight_decay: 0.000100, momentum_teacher: 0.996219, loss: 4.1960
2022-10-03 00:08:18 - train: epoch 0016, iter [00300, 10009], lr: 0.014885, weight_decay: 0.000100, momentum_teacher: 0.996219, loss: 4.5357
2022-10-03 00:09:06 - train: epoch 0016, iter [00400, 10009], lr: 0.014884, weight_decay: 0.000100, momentum_teacher: 0.996219, loss: 4.2118
2022-10-03 00:09:55 - train: epoch 0016, iter [00500, 10009], lr: 0.014884, weight_decay: 0.000100, momentum_teacher: 0.996219, loss: 4.3915
2022-10-03 00:10:43 - train: epoch 0016, iter [00600, 10009], lr: 0.014883, weight_decay: 0.000100, momentum_teacher: 0.996220, loss: 4.4083
2022-10-03 00:11:31 - train: epoch 0016, iter [00700, 10009], lr: 0.014883, weight_decay: 0.000100, momentum_teacher: 0.996220, loss: 4.1942
2022-10-03 00:12:19 - train: epoch 0016, iter [00800, 10009], lr: 0.014882, weight_decay: 0.000100, momentum_teacher: 0.996220, loss: 4.2643
2022-10-03 00:13:07 - train: epoch 0016, iter [00900, 10009], lr: 0.014882, weight_decay: 0.000100, momentum_teacher: 0.996221, loss: 4.3139
2022-10-03 00:13:55 - train: epoch 0016, iter [01000, 10009], lr: 0.014881, weight_decay: 0.000100, momentum_teacher: 0.996221, loss: 4.2443
2022-10-03 00:14:43 - train: epoch 0016, iter [01100, 10009], lr: 0.014881, weight_decay: 0.000100, momentum_teacher: 0.996221, loss: 4.3249
2022-10-03 00:15:32 - train: epoch 0016, iter [01200, 10009], lr: 0.014881, weight_decay: 0.000100, momentum_teacher: 0.996221, loss: 4.2728
2022-10-03 00:16:20 - train: epoch 0016, iter [01300, 10009], lr: 0.014880, weight_decay: 0.000100, momentum_teacher: 0.996222, loss: 4.5135
2022-10-03 00:17:08 - train: epoch 0016, iter [01400, 10009], lr: 0.014880, weight_decay: 0.000100, momentum_teacher: 0.996222, loss: 4.4322
2022-10-03 00:17:56 - train: epoch 0016, iter [01500, 10009], lr: 0.014879, weight_decay: 0.000100, momentum_teacher: 0.996222, loss: 4.3548
2022-10-03 00:18:45 - train: epoch 0016, iter [01600, 10009], lr: 0.014879, weight_decay: 0.000100, momentum_teacher: 0.996223, loss: 4.4387
2022-10-03 00:19:38 - train: epoch 0016, iter [01700, 10009], lr: 0.014878, weight_decay: 0.000100, momentum_teacher: 0.996223, loss: 4.4607
2022-10-03 00:20:30 - train: epoch 0016, iter [01800, 10009], lr: 0.014878, weight_decay: 0.000100, momentum_teacher: 0.996223, loss: 4.3464
2022-10-03 00:21:18 - train: epoch 0016, iter [01900, 10009], lr: 0.014877, weight_decay: 0.000100, momentum_teacher: 0.996223, loss: 4.2411
2022-10-03 00:22:06 - train: epoch 0016, iter [02000, 10009], lr: 0.014877, weight_decay: 0.000100, momentum_teacher: 0.996224, loss: 4.4491
2022-10-03 00:22:54 - train: epoch 0016, iter [02100, 10009], lr: 0.014876, weight_decay: 0.000100, momentum_teacher: 0.996224, loss: 4.2400
2022-10-03 00:23:44 - train: epoch 0016, iter [02200, 10009], lr: 0.014876, weight_decay: 0.000100, momentum_teacher: 0.996224, loss: 4.2070
2022-10-03 00:24:32 - train: epoch 0016, iter [02300, 10009], lr: 0.014875, weight_decay: 0.000100, momentum_teacher: 0.996225, loss: 4.0846
2022-10-03 00:25:20 - train: epoch 0016, iter [02400, 10009], lr: 0.014875, weight_decay: 0.000100, momentum_teacher: 0.996225, loss: 4.3083
2022-10-03 00:26:08 - train: epoch 0016, iter [02500, 10009], lr: 0.014874, weight_decay: 0.000100, momentum_teacher: 0.996225, loss: 4.0585
2022-10-03 00:26:56 - train: epoch 0016, iter [02600, 10009], lr: 0.014874, weight_decay: 0.000100, momentum_teacher: 0.996225, loss: 4.2101
2022-10-03 00:27:43 - train: epoch 0016, iter [02700, 10009], lr: 0.014873, weight_decay: 0.000100, momentum_teacher: 0.996226, loss: 4.2428
2022-10-03 00:28:47 - train: epoch 0016, iter [02800, 10009], lr: 0.014873, weight_decay: 0.000100, momentum_teacher: 0.996226, loss: 4.2493
2022-10-03 00:29:35 - train: epoch 0016, iter [02900, 10009], lr: 0.014873, weight_decay: 0.000100, momentum_teacher: 0.996226, loss: 4.3303
2022-10-03 00:30:22 - train: epoch 0016, iter [03000, 10009], lr: 0.014872, weight_decay: 0.000100, momentum_teacher: 0.996227, loss: 4.3274
2022-10-03 00:31:10 - train: epoch 0016, iter [03100, 10009], lr: 0.014872, weight_decay: 0.000100, momentum_teacher: 0.996227, loss: 4.2382
2022-10-03 00:31:58 - train: epoch 0016, iter [03200, 10009], lr: 0.014871, weight_decay: 0.000100, momentum_teacher: 0.996227, loss: 4.1820
2022-10-03 00:32:46 - train: epoch 0016, iter [03300, 10009], lr: 0.014871, weight_decay: 0.000100, momentum_teacher: 0.996227, loss: 4.3033
2022-10-03 00:33:35 - train: epoch 0016, iter [03400, 10009], lr: 0.014870, weight_decay: 0.000100, momentum_teacher: 0.996228, loss: 4.2751
2022-10-03 00:34:23 - train: epoch 0016, iter [03500, 10009], lr: 0.014870, weight_decay: 0.000100, momentum_teacher: 0.996228, loss: 4.2636
2022-10-03 00:35:14 - train: epoch 0016, iter [03600, 10009], lr: 0.014869, weight_decay: 0.000100, momentum_teacher: 0.996228, loss: 4.1816
2022-10-03 00:36:06 - train: epoch 0016, iter [03700, 10009], lr: 0.014869, weight_decay: 0.000100, momentum_teacher: 0.996229, loss: 4.4950
2022-10-03 00:37:01 - train: epoch 0016, iter [03800, 10009], lr: 0.014868, weight_decay: 0.000100, momentum_teacher: 0.996229, loss: 4.3608
2022-10-03 00:37:59 - train: epoch 0016, iter [03900, 10009], lr: 0.014868, weight_decay: 0.000100, momentum_teacher: 0.996229, loss: 4.2444
2022-10-03 00:38:52 - train: epoch 0016, iter [04000, 10009], lr: 0.014867, weight_decay: 0.000100, momentum_teacher: 0.996230, loss: 4.5106
2022-10-03 00:39:44 - train: epoch 0016, iter [04100, 10009], lr: 0.014867, weight_decay: 0.000100, momentum_teacher: 0.996230, loss: 4.3422
2022-10-03 00:40:37 - train: epoch 0016, iter [04200, 10009], lr: 0.014866, weight_decay: 0.000100, momentum_teacher: 0.996230, loss: 4.3212
2022-10-03 00:41:27 - train: epoch 0016, iter [04300, 10009], lr: 0.014866, weight_decay: 0.000100, momentum_teacher: 0.996230, loss: 4.4380
2022-10-03 00:42:16 - train: epoch 0016, iter [04400, 10009], lr: 0.014865, weight_decay: 0.000100, momentum_teacher: 0.996231, loss: 4.1933
2022-10-03 00:43:06 - train: epoch 0016, iter [04500, 10009], lr: 0.014865, weight_decay: 0.000100, momentum_teacher: 0.996231, loss: 4.3597
2022-10-03 00:43:54 - train: epoch 0016, iter [04600, 10009], lr: 0.014864, weight_decay: 0.000100, momentum_teacher: 0.996231, loss: 4.0406
2022-10-03 00:44:43 - train: epoch 0016, iter [04700, 10009], lr: 0.014864, weight_decay: 0.000100, momentum_teacher: 0.996232, loss: 4.0983
2022-10-03 00:45:36 - train: epoch 0016, iter [04800, 10009], lr: 0.014863, weight_decay: 0.000100, momentum_teacher: 0.996232, loss: 4.1538
2022-10-03 00:46:24 - train: epoch 0016, iter [04900, 10009], lr: 0.014863, weight_decay: 0.000100, momentum_teacher: 0.996232, loss: 4.3069
2022-10-03 00:47:15 - train: epoch 0016, iter [05000, 10009], lr: 0.014862, weight_decay: 0.000100, momentum_teacher: 0.996232, loss: 4.2723
2022-10-03 00:48:03 - train: epoch 0016, iter [05100, 10009], lr: 0.014862, weight_decay: 0.000100, momentum_teacher: 0.996233, loss: 4.2545
2022-10-03 00:49:02 - train: epoch 0016, iter [05200, 10009], lr: 0.014861, weight_decay: 0.000100, momentum_teacher: 0.996233, loss: 4.2716
2022-10-03 00:50:06 - train: epoch 0016, iter [05300, 10009], lr: 0.014861, weight_decay: 0.000100, momentum_teacher: 0.996233, loss: 4.2611
2022-10-03 00:51:04 - train: epoch 0016, iter [05400, 10009], lr: 0.014860, weight_decay: 0.000100, momentum_teacher: 0.996234, loss: 4.3392
2022-10-03 00:52:02 - train: epoch 0016, iter [05500, 10009], lr: 0.014860, weight_decay: 0.000100, momentum_teacher: 0.996234, loss: 4.1941
2022-10-03 00:52:50 - train: epoch 0016, iter [05600, 10009], lr: 0.014859, weight_decay: 0.000100, momentum_teacher: 0.996234, loss: 4.2314
2022-10-03 00:53:40 - train: epoch 0016, iter [05700, 10009], lr: 0.014859, weight_decay: 0.000100, momentum_teacher: 0.996235, loss: 4.2543
2022-10-03 00:54:29 - train: epoch 0016, iter [05800, 10009], lr: 0.014858, weight_decay: 0.000100, momentum_teacher: 0.996235, loss: 4.4033
2022-10-03 00:55:17 - train: epoch 0016, iter [05900, 10009], lr: 0.014858, weight_decay: 0.000100, momentum_teacher: 0.996235, loss: 4.4196
2022-10-03 00:56:15 - train: epoch 0016, iter [06000, 10009], lr: 0.014857, weight_decay: 0.000100, momentum_teacher: 0.996235, loss: 4.3167
2022-10-03 00:57:03 - train: epoch 0016, iter [06100, 10009], lr: 0.014857, weight_decay: 0.000100, momentum_teacher: 0.996236, loss: 4.2828
2022-10-03 00:57:52 - train: epoch 0016, iter [06200, 10009], lr: 0.014856, weight_decay: 0.000100, momentum_teacher: 0.996236, loss: 4.1150
2022-10-03 00:58:44 - train: epoch 0016, iter [06300, 10009], lr: 0.014856, weight_decay: 0.000100, momentum_teacher: 0.996236, loss: 4.2027
2022-10-03 00:59:31 - train: epoch 0016, iter [06400, 10009], lr: 0.014855, weight_decay: 0.000100, momentum_teacher: 0.996237, loss: 4.2017
2022-10-03 01:00:20 - train: epoch 0016, iter [06500, 10009], lr: 0.014855, weight_decay: 0.000100, momentum_teacher: 0.996237, loss: 4.3198
2022-10-03 01:01:09 - train: epoch 0016, iter [06600, 10009], lr: 0.014854, weight_decay: 0.000100, momentum_teacher: 0.996237, loss: 4.0203
2022-10-03 01:02:04 - train: epoch 0016, iter [06700, 10009], lr: 0.014854, weight_decay: 0.000100, momentum_teacher: 0.996237, loss: 4.2798
2022-10-03 01:02:57 - train: epoch 0016, iter [06800, 10009], lr: 0.014853, weight_decay: 0.000100, momentum_teacher: 0.996238, loss: 4.3518
2022-10-03 01:03:52 - train: epoch 0016, iter [06900, 10009], lr: 0.014853, weight_decay: 0.000100, momentum_teacher: 0.996238, loss: 4.2971
2022-10-03 01:04:49 - train: epoch 0016, iter [07000, 10009], lr: 0.014852, weight_decay: 0.000100, momentum_teacher: 0.996238, loss: 4.1502
2022-10-03 01:05:40 - train: epoch 0016, iter [07100, 10009], lr: 0.014852, weight_decay: 0.000100, momentum_teacher: 0.996239, loss: 4.3064
2022-10-03 01:06:28 - train: epoch 0016, iter [07200, 10009], lr: 0.014851, weight_decay: 0.000100, momentum_teacher: 0.996239, loss: 4.2590
2022-10-03 01:07:20 - train: epoch 0016, iter [07300, 10009], lr: 0.014851, weight_decay: 0.000100, momentum_teacher: 0.996239, loss: 4.3809
2022-10-03 01:08:31 - train: epoch 0016, iter [07400, 10009], lr: 0.014850, weight_decay: 0.000100, momentum_teacher: 0.996240, loss: 4.4107
2022-10-03 01:09:39 - train: epoch 0016, iter [07500, 10009], lr: 0.014849, weight_decay: 0.000100, momentum_teacher: 0.996240, loss: 4.3435
2022-10-03 01:10:35 - train: epoch 0016, iter [07600, 10009], lr: 0.014849, weight_decay: 0.000100, momentum_teacher: 0.996240, loss: 4.4861
2022-10-03 01:11:31 - train: epoch 0016, iter [07700, 10009], lr: 0.014848, weight_decay: 0.000100, momentum_teacher: 0.996240, loss: 4.1145
2022-10-03 01:12:29 - train: epoch 0016, iter [07800, 10009], lr: 0.014848, weight_decay: 0.000100, momentum_teacher: 0.996241, loss: 4.2413
2022-10-03 01:13:25 - train: epoch 0016, iter [07900, 10009], lr: 0.014847, weight_decay: 0.000100, momentum_teacher: 0.996241, loss: 4.3801
2022-10-03 01:15:00 - train: epoch 0016, iter [08000, 10009], lr: 0.014847, weight_decay: 0.000100, momentum_teacher: 0.996241, loss: 4.2174
2022-10-03 01:15:48 - train: epoch 0016, iter [08100, 10009], lr: 0.014846, weight_decay: 0.000100, momentum_teacher: 0.996242, loss: 4.4082
2022-10-03 01:16:37 - train: epoch 0016, iter [08200, 10009], lr: 0.014846, weight_decay: 0.000100, momentum_teacher: 0.996242, loss: 4.2090
2022-10-03 01:17:26 - train: epoch 0016, iter [08300, 10009], lr: 0.014845, weight_decay: 0.000100, momentum_teacher: 0.996242, loss: 4.3750
2022-10-03 01:18:17 - train: epoch 0016, iter [08400, 10009], lr: 0.014845, weight_decay: 0.000100, momentum_teacher: 0.996243, loss: 4.2476
2022-10-03 01:19:05 - train: epoch 0016, iter [08500, 10009], lr: 0.014844, weight_decay: 0.000100, momentum_teacher: 0.996243, loss: 4.2333
2022-10-03 01:19:53 - train: epoch 0016, iter [08600, 10009], lr: 0.014844, weight_decay: 0.000100, momentum_teacher: 0.996243, loss: 4.2484
2022-10-03 01:20:41 - train: epoch 0016, iter [08700, 10009], lr: 0.014843, weight_decay: 0.000100, momentum_teacher: 0.996243, loss: 4.1827
2022-10-03 01:21:30 - train: epoch 0016, iter [08800, 10009], lr: 0.014843, weight_decay: 0.000100, momentum_teacher: 0.996244, loss: 4.3324
2022-10-03 01:22:21 - train: epoch 0016, iter [08900, 10009], lr: 0.014842, weight_decay: 0.000100, momentum_teacher: 0.996244, loss: 4.2972
2022-10-03 01:23:09 - train: epoch 0016, iter [09000, 10009], lr: 0.014842, weight_decay: 0.000100, momentum_teacher: 0.996244, loss: 4.3031
2022-10-03 01:23:57 - train: epoch 0016, iter [09100, 10009], lr: 0.014841, weight_decay: 0.000100, momentum_teacher: 0.996245, loss: 4.3316
2022-10-03 01:24:45 - train: epoch 0016, iter [09200, 10009], lr: 0.014840, weight_decay: 0.000100, momentum_teacher: 0.996245, loss: 4.2218
2022-10-03 01:25:33 - train: epoch 0016, iter [09300, 10009], lr: 0.014840, weight_decay: 0.000100, momentum_teacher: 0.996245, loss: 4.4184
2022-10-03 01:26:21 - train: epoch 0016, iter [09400, 10009], lr: 0.014839, weight_decay: 0.000100, momentum_teacher: 0.996246, loss: 4.3768
2022-10-03 01:27:08 - train: epoch 0016, iter [09500, 10009], lr: 0.014839, weight_decay: 0.000100, momentum_teacher: 0.996246, loss: 4.0904
2022-10-03 01:27:56 - train: epoch 0016, iter [09600, 10009], lr: 0.014838, weight_decay: 0.000100, momentum_teacher: 0.996246, loss: 4.0785
2022-10-03 01:28:44 - train: epoch 0016, iter [09700, 10009], lr: 0.014838, weight_decay: 0.000100, momentum_teacher: 0.996246, loss: 3.9280
2022-10-03 01:29:32 - train: epoch 0016, iter [09800, 10009], lr: 0.014837, weight_decay: 0.000100, momentum_teacher: 0.996247, loss: 4.2336
2022-10-03 01:30:19 - train: epoch 0016, iter [09900, 10009], lr: 0.014837, weight_decay: 0.000100, momentum_teacher: 0.996247, loss: 4.1301
2022-10-03 01:31:07 - train: epoch 0016, iter [10000, 10009], lr: 0.014836, weight_decay: 0.000100, momentum_teacher: 0.996247, loss: 4.2137
2022-10-03 01:31:12 - train: epoch 016, train_loss: 4.2789
2022-10-03 01:31:14 - until epoch: 016, best_loss: 4.2789
2022-10-03 01:31:14 - epoch 017 lr: 0.014836
2022-10-03 01:32:07 - train: epoch 0017, iter [00100, 10009], lr: 0.014836, weight_decay: 0.000100, momentum_teacher: 0.996248, loss: 4.1837
2022-10-03 01:32:55 - train: epoch 0017, iter [00200, 10009], lr: 0.014835, weight_decay: 0.000100, momentum_teacher: 0.996248, loss: 4.1287
2022-10-03 01:33:43 - train: epoch 0017, iter [00300, 10009], lr: 0.014834, weight_decay: 0.000100, momentum_teacher: 0.996248, loss: 4.2517
2022-10-03 01:34:32 - train: epoch 0017, iter [00400, 10009], lr: 0.014834, weight_decay: 0.000100, momentum_teacher: 0.996249, loss: 4.3253
2022-10-03 01:35:22 - train: epoch 0017, iter [00500, 10009], lr: 0.014833, weight_decay: 0.000100, momentum_teacher: 0.996249, loss: 4.2274
2022-10-03 01:36:13 - train: epoch 0017, iter [00600, 10009], lr: 0.014833, weight_decay: 0.000100, momentum_teacher: 0.996249, loss: 4.3256
2022-10-03 01:37:00 - train: epoch 0017, iter [00700, 10009], lr: 0.014832, weight_decay: 0.000100, momentum_teacher: 0.996250, loss: 4.1097
2022-10-03 01:37:48 - train: epoch 0017, iter [00800, 10009], lr: 0.014832, weight_decay: 0.000100, momentum_teacher: 0.996250, loss: 3.9786
2022-10-03 01:38:36 - train: epoch 0017, iter [00900, 10009], lr: 0.014831, weight_decay: 0.000100, momentum_teacher: 0.996250, loss: 4.3574
2022-10-03 01:39:24 - train: epoch 0017, iter [01000, 10009], lr: 0.014831, weight_decay: 0.000100, momentum_teacher: 0.996250, loss: 4.2817
2022-10-03 01:40:12 - train: epoch 0017, iter [01100, 10009], lr: 0.014830, weight_decay: 0.000100, momentum_teacher: 0.996251, loss: 4.1416
2022-10-03 01:41:00 - train: epoch 0017, iter [01200, 10009], lr: 0.014830, weight_decay: 0.000100, momentum_teacher: 0.996251, loss: 4.1010
2022-10-03 01:41:47 - train: epoch 0017, iter [01300, 10009], lr: 0.014829, weight_decay: 0.000100, momentum_teacher: 0.996251, loss: 4.1490
2022-10-03 01:42:35 - train: epoch 0017, iter [01400, 10009], lr: 0.014828, weight_decay: 0.000100, momentum_teacher: 0.996252, loss: 4.4362
2022-10-03 01:43:23 - train: epoch 0017, iter [01500, 10009], lr: 0.014828, weight_decay: 0.000100, momentum_teacher: 0.996252, loss: 4.3652
2022-10-03 01:44:13 - train: epoch 0017, iter [01600, 10009], lr: 0.014827, weight_decay: 0.000100, momentum_teacher: 0.996252, loss: 4.0538
2022-10-03 01:45:01 - train: epoch 0017, iter [01700, 10009], lr: 0.014827, weight_decay: 0.000100, momentum_teacher: 0.996253, loss: 4.1189
2022-10-03 01:45:48 - train: epoch 0017, iter [01800, 10009], lr: 0.014826, weight_decay: 0.000100, momentum_teacher: 0.996253, loss: 4.2909
2022-10-03 01:46:36 - train: epoch 0017, iter [01900, 10009], lr: 0.014826, weight_decay: 0.000100, momentum_teacher: 0.996253, loss: 4.3093
2022-10-03 01:47:36 - train: epoch 0017, iter [02000, 10009], lr: 0.014825, weight_decay: 0.000100, momentum_teacher: 0.996253, loss: 4.0166
2022-10-03 01:48:23 - train: epoch 0017, iter [02100, 10009], lr: 0.014825, weight_decay: 0.000100, momentum_teacher: 0.996254, loss: 4.2868
2022-10-03 01:49:11 - train: epoch 0017, iter [02200, 10009], lr: 0.014824, weight_decay: 0.000100, momentum_teacher: 0.996254, loss: 4.2167
2022-10-03 01:49:59 - train: epoch 0017, iter [02300, 10009], lr: 0.014823, weight_decay: 0.000100, momentum_teacher: 0.996254, loss: 4.2500
2022-10-03 01:50:53 - train: epoch 0017, iter [02400, 10009], lr: 0.014823, weight_decay: 0.000100, momentum_teacher: 0.996255, loss: 3.8283
2022-10-03 01:51:57 - train: epoch 0017, iter [02500, 10009], lr: 0.014822, weight_decay: 0.000100, momentum_teacher: 0.996255, loss: 4.2308
2022-10-03 01:53:18 - train: epoch 0017, iter [02600, 10009], lr: 0.014822, weight_decay: 0.000100, momentum_teacher: 0.996255, loss: 4.3074
2022-10-03 01:54:24 - train: epoch 0017, iter [02700, 10009], lr: 0.014821, weight_decay: 0.000100, momentum_teacher: 0.996256, loss: 4.2248
2022-10-03 01:55:12 - train: epoch 0017, iter [02800, 10009], lr: 0.014821, weight_decay: 0.000100, momentum_teacher: 0.996256, loss: 4.3939
2022-10-03 01:56:01 - train: epoch 0017, iter [02900, 10009], lr: 0.014820, weight_decay: 0.000100, momentum_teacher: 0.996256, loss: 4.3221
2022-10-03 01:56:49 - train: epoch 0017, iter [03000, 10009], lr: 0.014819, weight_decay: 0.000100, momentum_teacher: 0.996257, loss: 4.1759
2022-10-03 01:57:52 - train: epoch 0017, iter [03100, 10009], lr: 0.014819, weight_decay: 0.000100, momentum_teacher: 0.996257, loss: 4.1544
2022-10-03 01:58:46 - train: epoch 0017, iter [03200, 10009], lr: 0.014818, weight_decay: 0.000100, momentum_teacher: 0.996257, loss: 4.1233
2022-10-03 01:59:35 - train: epoch 0017, iter [03300, 10009], lr: 0.014818, weight_decay: 0.000100, momentum_teacher: 0.996257, loss: 4.2895
2022-10-03 02:00:23 - train: epoch 0017, iter [03400, 10009], lr: 0.014817, weight_decay: 0.000100, momentum_teacher: 0.996258, loss: 4.0901
2022-10-03 02:01:13 - train: epoch 0017, iter [03500, 10009], lr: 0.014817, weight_decay: 0.000100, momentum_teacher: 0.996258, loss: 3.9361
2022-10-03 02:02:09 - train: epoch 0017, iter [03600, 10009], lr: 0.014816, weight_decay: 0.000100, momentum_teacher: 0.996258, loss: 4.1512
2022-10-03 02:03:00 - train: epoch 0017, iter [03700, 10009], lr: 0.014815, weight_decay: 0.000100, momentum_teacher: 0.996259, loss: 4.1535
2022-10-03 02:03:58 - train: epoch 0017, iter [03800, 10009], lr: 0.014815, weight_decay: 0.000100, momentum_teacher: 0.996259, loss: 4.0410
2022-10-03 02:05:50 - train: epoch 0017, iter [03900, 10009], lr: 0.014814, weight_decay: 0.000100, momentum_teacher: 0.996259, loss: 4.3875
2022-10-03 02:09:06 - train: epoch 0017, iter [04000, 10009], lr: 0.014814, weight_decay: 0.000100, momentum_teacher: 0.996260, loss: 3.9837
2022-10-03 02:10:09 - train: epoch 0017, iter [04100, 10009], lr: 0.014813, weight_decay: 0.000100, momentum_teacher: 0.996260, loss: 4.1084
2022-10-03 02:12:06 - train: epoch 0017, iter [04200, 10009], lr: 0.014812, weight_decay: 0.000100, momentum_teacher: 0.996260, loss: 4.1937
2022-10-03 02:12:54 - train: epoch 0017, iter [04300, 10009], lr: 0.014812, weight_decay: 0.000100, momentum_teacher: 0.996261, loss: 4.3415
2022-10-03 02:13:43 - train: epoch 0017, iter [04400, 10009], lr: 0.014811, weight_decay: 0.000100, momentum_teacher: 0.996261, loss: 4.2042
2022-10-03 02:14:43 - train: epoch 0017, iter [04500, 10009], lr: 0.014811, weight_decay: 0.000100, momentum_teacher: 0.996261, loss: 4.2236
2022-10-03 02:15:59 - train: epoch 0017, iter [04600, 10009], lr: 0.014810, weight_decay: 0.000100, momentum_teacher: 0.996261, loss: 4.1554
2022-10-03 02:18:11 - train: epoch 0017, iter [04700, 10009], lr: 0.014810, weight_decay: 0.000100, momentum_teacher: 0.996262, loss: 4.2789
2022-10-03 02:19:38 - train: epoch 0017, iter [04800, 10009], lr: 0.014809, weight_decay: 0.000100, momentum_teacher: 0.996262, loss: 4.2093
2022-10-03 02:20:32 - train: epoch 0017, iter [04900, 10009], lr: 0.014808, weight_decay: 0.000100, momentum_teacher: 0.996262, loss: 3.9893
2022-10-03 02:21:23 - train: epoch 0017, iter [05000, 10009], lr: 0.014808, weight_decay: 0.000100, momentum_teacher: 0.996263, loss: 4.1772
2022-10-03 02:22:30 - train: epoch 0017, iter [05100, 10009], lr: 0.014807, weight_decay: 0.000100, momentum_teacher: 0.996263, loss: 4.0965
2022-10-03 02:23:18 - train: epoch 0017, iter [05200, 10009], lr: 0.014807, weight_decay: 0.000100, momentum_teacher: 0.996263, loss: 4.1343
2022-10-03 02:24:06 - train: epoch 0017, iter [05300, 10009], lr: 0.014806, weight_decay: 0.000100, momentum_teacher: 0.996264, loss: 3.9861
2022-10-03 02:24:55 - train: epoch 0017, iter [05400, 10009], lr: 0.014805, weight_decay: 0.000100, momentum_teacher: 0.996264, loss: 4.2644
2022-10-03 02:25:44 - train: epoch 0017, iter [05500, 10009], lr: 0.014805, weight_decay: 0.000100, momentum_teacher: 0.996264, loss: 4.1178
2022-10-03 02:26:33 - train: epoch 0017, iter [05600, 10009], lr: 0.014804, weight_decay: 0.000100, momentum_teacher: 0.996265, loss: 4.0668
2022-10-03 02:27:22 - train: epoch 0017, iter [05700, 10009], lr: 0.014804, weight_decay: 0.000100, momentum_teacher: 0.996265, loss: 4.2013
2022-10-03 02:29:49 - train: epoch 0017, iter [05800, 10009], lr: 0.014803, weight_decay: 0.000100, momentum_teacher: 0.996265, loss: 3.9455
2022-10-03 02:31:11 - train: epoch 0017, iter [05900, 10009], lr: 0.014802, weight_decay: 0.000100, momentum_teacher: 0.996266, loss: 4.3147
2022-10-03 02:32:28 - train: epoch 0017, iter [06000, 10009], lr: 0.014802, weight_decay: 0.000100, momentum_teacher: 0.996266, loss: 3.9539
2022-10-03 02:33:57 - train: epoch 0017, iter [06100, 10009], lr: 0.014801, weight_decay: 0.000100, momentum_teacher: 0.996266, loss: 4.1007
2022-10-03 02:35:04 - train: epoch 0017, iter [06200, 10009], lr: 0.014801, weight_decay: 0.000100, momentum_teacher: 0.996266, loss: 4.2195
2022-10-03 02:35:57 - train: epoch 0017, iter [06300, 10009], lr: 0.014800, weight_decay: 0.000100, momentum_teacher: 0.996267, loss: 4.3693
2022-10-03 02:36:45 - train: epoch 0017, iter [06400, 10009], lr: 0.014799, weight_decay: 0.000100, momentum_teacher: 0.996267, loss: 4.2742
2022-10-03 02:37:33 - train: epoch 0017, iter [06500, 10009], lr: 0.014799, weight_decay: 0.000100, momentum_teacher: 0.996267, loss: 4.2175
2022-10-03 02:38:21 - train: epoch 0017, iter [06600, 10009], lr: 0.014798, weight_decay: 0.000100, momentum_teacher: 0.996268, loss: 4.1727
2022-10-03 02:39:10 - train: epoch 0017, iter [06700, 10009], lr: 0.014798, weight_decay: 0.000100, momentum_teacher: 0.996268, loss: 3.9735
2022-10-03 02:39:58 - train: epoch 0017, iter [06800, 10009], lr: 0.014797, weight_decay: 0.000100, momentum_teacher: 0.996268, loss: 4.2511
2022-10-03 02:40:46 - train: epoch 0017, iter [06900, 10009], lr: 0.014796, weight_decay: 0.000100, momentum_teacher: 0.996269, loss: 4.0481
2022-10-03 02:41:34 - train: epoch 0017, iter [07000, 10009], lr: 0.014796, weight_decay: 0.000100, momentum_teacher: 0.996269, loss: 4.1184
2022-10-03 02:42:24 - train: epoch 0017, iter [07100, 10009], lr: 0.014795, weight_decay: 0.000100, momentum_teacher: 0.996269, loss: 4.0414
2022-10-03 02:43:13 - train: epoch 0017, iter [07200, 10009], lr: 0.014795, weight_decay: 0.000100, momentum_teacher: 0.996270, loss: 4.1311
2022-10-03 02:44:01 - train: epoch 0017, iter [07300, 10009], lr: 0.014794, weight_decay: 0.000100, momentum_teacher: 0.996270, loss: 4.1331
2022-10-03 02:44:55 - train: epoch 0017, iter [07400, 10009], lr: 0.014793, weight_decay: 0.000100, momentum_teacher: 0.996270, loss: 4.1970
2022-10-03 02:45:50 - train: epoch 0017, iter [07500, 10009], lr: 0.014793, weight_decay: 0.000100, momentum_teacher: 0.996271, loss: 4.1151
2022-10-03 02:47:15 - train: epoch 0017, iter [07600, 10009], lr: 0.014792, weight_decay: 0.000100, momentum_teacher: 0.996271, loss: 4.3270
2022-10-03 02:48:46 - train: epoch 0017, iter [07700, 10009], lr: 0.014792, weight_decay: 0.000100, momentum_teacher: 0.996271, loss: 4.1043
2022-10-03 02:50:08 - train: epoch 0017, iter [07800, 10009], lr: 0.014791, weight_decay: 0.000100, momentum_teacher: 0.996271, loss: 4.2264
2022-10-03 02:51:20 - train: epoch 0017, iter [07900, 10009], lr: 0.014790, weight_decay: 0.000100, momentum_teacher: 0.996272, loss: 4.1668
2022-10-03 02:52:27 - train: epoch 0017, iter [08000, 10009], lr: 0.014790, weight_decay: 0.000100, momentum_teacher: 0.996272, loss: 4.1778
2022-10-03 02:53:35 - train: epoch 0017, iter [08100, 10009], lr: 0.014789, weight_decay: 0.000100, momentum_teacher: 0.996272, loss: 4.0404
2022-10-03 02:55:05 - train: epoch 0017, iter [08200, 10009], lr: 0.014789, weight_decay: 0.000100, momentum_teacher: 0.996273, loss: 4.3929
2022-10-03 02:56:26 - train: epoch 0017, iter [08300, 10009], lr: 0.014788, weight_decay: 0.000100, momentum_teacher: 0.996273, loss: 4.0792
2022-10-03 02:57:41 - train: epoch 0017, iter [08400, 10009], lr: 0.014787, weight_decay: 0.000100, momentum_teacher: 0.996273, loss: 4.0610
2022-10-03 02:58:56 - train: epoch 0017, iter [08500, 10009], lr: 0.014787, weight_decay: 0.000100, momentum_teacher: 0.996274, loss: 4.1061
2022-10-03 03:00:12 - train: epoch 0017, iter [08600, 10009], lr: 0.014786, weight_decay: 0.000100, momentum_teacher: 0.996274, loss: 4.1688
2022-10-03 03:01:24 - train: epoch 0017, iter [08700, 10009], lr: 0.014785, weight_decay: 0.000100, momentum_teacher: 0.996274, loss: 4.0478
2022-10-03 03:02:27 - train: epoch 0017, iter [08800, 10009], lr: 0.014785, weight_decay: 0.000100, momentum_teacher: 0.996275, loss: 4.2190
2022-10-03 03:03:21 - train: epoch 0017, iter [08900, 10009], lr: 0.014784, weight_decay: 0.000100, momentum_teacher: 0.996275, loss: 4.1703
2022-10-03 03:04:10 - train: epoch 0017, iter [09000, 10009], lr: 0.014784, weight_decay: 0.000100, momentum_teacher: 0.996275, loss: 4.2108
2022-10-03 03:05:04 - train: epoch 0017, iter [09100, 10009], lr: 0.014783, weight_decay: 0.000100, momentum_teacher: 0.996276, loss: 4.0961
2022-10-03 03:06:44 - train: epoch 0017, iter [09200, 10009], lr: 0.014782, weight_decay: 0.000100, momentum_teacher: 0.996276, loss: 4.1571
2022-10-03 03:08:44 - train: epoch 0017, iter [09300, 10009], lr: 0.014782, weight_decay: 0.000100, momentum_teacher: 0.996276, loss: 4.1979
2022-10-03 03:10:54 - train: epoch 0017, iter [09400, 10009], lr: 0.014781, weight_decay: 0.000100, momentum_teacher: 0.996277, loss: 4.0820
2022-10-03 03:13:04 - train: epoch 0017, iter [09500, 10009], lr: 0.014780, weight_decay: 0.000100, momentum_teacher: 0.996277, loss: 4.1734
2022-10-03 03:15:46 - train: epoch 0017, iter [09600, 10009], lr: 0.014780, weight_decay: 0.000100, momentum_teacher: 0.996277, loss: 4.2079
2022-10-03 03:17:06 - train: epoch 0017, iter [09700, 10009], lr: 0.014779, weight_decay: 0.000100, momentum_teacher: 0.996278, loss: 4.2160
2022-10-03 03:18:50 - train: epoch 0017, iter [09800, 10009], lr: 0.014779, weight_decay: 0.000100, momentum_teacher: 0.996278, loss: 4.0554
2022-10-03 03:21:34 - train: epoch 0017, iter [09900, 10009], lr: 0.014778, weight_decay: 0.000100, momentum_teacher: 0.996278, loss: 4.2757
2022-10-03 03:23:42 - train: epoch 0017, iter [10000, 10009], lr: 0.014777, weight_decay: 0.000100, momentum_teacher: 0.996278, loss: 4.0916
2022-10-03 03:23:48 - train: epoch 017, train_loss: 4.1682
2022-10-03 03:23:50 - until epoch: 017, best_loss: 4.1682
2022-10-03 03:23:50 - epoch 018 lr: 0.014777
2022-10-03 03:24:43 - train: epoch 0018, iter [00100, 10009], lr: 0.014777, weight_decay: 0.000100, momentum_teacher: 0.996279, loss: 4.1515
2022-10-03 03:25:31 - train: epoch 0018, iter [00200, 10009], lr: 0.014776, weight_decay: 0.000100, momentum_teacher: 0.996279, loss: 4.3767
2022-10-03 03:26:19 - train: epoch 0018, iter [00300, 10009], lr: 0.014775, weight_decay: 0.000100, momentum_teacher: 0.996279, loss: 3.9667
2022-10-03 03:27:07 - train: epoch 0018, iter [00400, 10009], lr: 0.014775, weight_decay: 0.000100, momentum_teacher: 0.996280, loss: 4.1195
2022-10-03 03:27:55 - train: epoch 0018, iter [00500, 10009], lr: 0.014774, weight_decay: 0.000100, momentum_teacher: 0.996280, loss: 4.0087
2022-10-03 03:28:43 - train: epoch 0018, iter [00600, 10009], lr: 0.014773, weight_decay: 0.000100, momentum_teacher: 0.996280, loss: 4.2063
2022-10-03 03:29:31 - train: epoch 0018, iter [00700, 10009], lr: 0.014773, weight_decay: 0.000100, momentum_teacher: 0.996281, loss: 3.9989
2022-10-03 03:30:18 - train: epoch 0018, iter [00800, 10009], lr: 0.014772, weight_decay: 0.000100, momentum_teacher: 0.996281, loss: 4.0088
2022-10-03 03:31:06 - train: epoch 0018, iter [00900, 10009], lr: 0.014772, weight_decay: 0.000100, momentum_teacher: 0.996281, loss: 4.1841
2022-10-03 03:31:54 - train: epoch 0018, iter [01000, 10009], lr: 0.014771, weight_decay: 0.000100, momentum_teacher: 0.996282, loss: 3.9777
2022-10-03 03:32:42 - train: epoch 0018, iter [01100, 10009], lr: 0.014770, weight_decay: 0.000100, momentum_teacher: 0.996282, loss: 4.2548
2022-10-03 03:33:30 - train: epoch 0018, iter [01200, 10009], lr: 0.014770, weight_decay: 0.000100, momentum_teacher: 0.996282, loss: 4.2895
2022-10-03 03:34:18 - train: epoch 0018, iter [01300, 10009], lr: 0.014769, weight_decay: 0.000100, momentum_teacher: 0.996283, loss: 3.9789
2022-10-03 03:35:05 - train: epoch 0018, iter [01400, 10009], lr: 0.014768, weight_decay: 0.000100, momentum_teacher: 0.996283, loss: 4.2537
2022-10-03 03:35:53 - train: epoch 0018, iter [01500, 10009], lr: 0.014768, weight_decay: 0.000100, momentum_teacher: 0.996283, loss: 3.9701
2022-10-03 03:36:41 - train: epoch 0018, iter [01600, 10009], lr: 0.014767, weight_decay: 0.000100, momentum_teacher: 0.996284, loss: 3.8626
2022-10-03 03:37:28 - train: epoch 0018, iter [01700, 10009], lr: 0.014766, weight_decay: 0.000100, momentum_teacher: 0.996284, loss: 4.1290
2022-10-03 03:38:16 - train: epoch 0018, iter [01800, 10009], lr: 0.014766, weight_decay: 0.000100, momentum_teacher: 0.996284, loss: 4.1597
2022-10-03 03:39:04 - train: epoch 0018, iter [01900, 10009], lr: 0.014765, weight_decay: 0.000100, momentum_teacher: 0.996285, loss: 4.2038
2022-10-03 03:39:51 - train: epoch 0018, iter [02000, 10009], lr: 0.014764, weight_decay: 0.000100, momentum_teacher: 0.996285, loss: 4.3183
2022-10-03 03:40:39 - train: epoch 0018, iter [02100, 10009], lr: 0.014764, weight_decay: 0.000100, momentum_teacher: 0.996285, loss: 3.9761
2022-10-03 03:41:27 - train: epoch 0018, iter [02200, 10009], lr: 0.014763, weight_decay: 0.000100, momentum_teacher: 0.996286, loss: 4.1432
2022-10-03 03:42:14 - train: epoch 0018, iter [02300, 10009], lr: 0.014762, weight_decay: 0.000100, momentum_teacher: 0.996286, loss: 4.3152
2022-10-03 03:43:02 - train: epoch 0018, iter [02400, 10009], lr: 0.014762, weight_decay: 0.000100, momentum_teacher: 0.996286, loss: 3.9146
2022-10-03 03:43:50 - train: epoch 0018, iter [02500, 10009], lr: 0.014761, weight_decay: 0.000100, momentum_teacher: 0.996287, loss: 4.1708
2022-10-03 03:44:38 - train: epoch 0018, iter [02600, 10009], lr: 0.014760, weight_decay: 0.000100, momentum_teacher: 0.996287, loss: 4.1730
2022-10-03 03:45:26 - train: epoch 0018, iter [02700, 10009], lr: 0.014760, weight_decay: 0.000100, momentum_teacher: 0.996287, loss: 4.1717
2022-10-03 03:46:14 - train: epoch 0018, iter [02800, 10009], lr: 0.014759, weight_decay: 0.000100, momentum_teacher: 0.996288, loss: 4.0171
2022-10-03 03:47:01 - train: epoch 0018, iter [02900, 10009], lr: 0.014759, weight_decay: 0.000100, momentum_teacher: 0.996288, loss: 4.1776
2022-10-03 03:47:49 - train: epoch 0018, iter [03000, 10009], lr: 0.014758, weight_decay: 0.000100, momentum_teacher: 0.996288, loss: 4.3862
2022-10-03 03:48:37 - train: epoch 0018, iter [03100, 10009], lr: 0.014757, weight_decay: 0.000100, momentum_teacher: 0.996289, loss: 3.9412
2022-10-03 03:49:25 - train: epoch 0018, iter [03200, 10009], lr: 0.014757, weight_decay: 0.000100, momentum_teacher: 0.996289, loss: 3.9110
2022-10-03 03:50:13 - train: epoch 0018, iter [03300, 10009], lr: 0.014756, weight_decay: 0.000100, momentum_teacher: 0.996289, loss: 4.2313
2022-10-03 03:51:00 - train: epoch 0018, iter [03400, 10009], lr: 0.014755, weight_decay: 0.000100, momentum_teacher: 0.996289, loss: 4.2840
2022-10-03 03:51:48 - train: epoch 0018, iter [03500, 10009], lr: 0.014755, weight_decay: 0.000100, momentum_teacher: 0.996290, loss: 4.0613
2022-10-03 03:52:36 - train: epoch 0018, iter [03600, 10009], lr: 0.014754, weight_decay: 0.000100, momentum_teacher: 0.996290, loss: 4.3106
2022-10-03 03:53:24 - train: epoch 0018, iter [03700, 10009], lr: 0.014753, weight_decay: 0.000100, momentum_teacher: 0.996290, loss: 4.1763
2022-10-03 03:54:44 - train: epoch 0018, iter [03800, 10009], lr: 0.014753, weight_decay: 0.000100, momentum_teacher: 0.996291, loss: 4.1397
2022-10-03 03:56:47 - train: epoch 0018, iter [03900, 10009], lr: 0.014752, weight_decay: 0.000100, momentum_teacher: 0.996291, loss: 4.1034
2022-10-03 04:04:28 - train: epoch 0018, iter [04000, 10009], lr: 0.014751, weight_decay: 0.000100, momentum_teacher: 0.996291, loss: 4.1260
2022-10-03 04:05:45 - train: epoch 0018, iter [04100, 10009], lr: 0.014751, weight_decay: 0.000100, momentum_teacher: 0.996292, loss: 4.0212
2022-10-03 04:06:33 - train: epoch 0018, iter [04200, 10009], lr: 0.014750, weight_decay: 0.000100, momentum_teacher: 0.996292, loss: 4.0158
2022-10-03 04:07:20 - train: epoch 0018, iter [04300, 10009], lr: 0.014749, weight_decay: 0.000100, momentum_teacher: 0.996292, loss: 4.0237
2022-10-03 04:08:08 - train: epoch 0018, iter [04400, 10009], lr: 0.014749, weight_decay: 0.000100, momentum_teacher: 0.996293, loss: 3.8618
2022-10-03 04:08:56 - train: epoch 0018, iter [04500, 10009], lr: 0.014748, weight_decay: 0.000100, momentum_teacher: 0.996293, loss: 4.0299
2022-10-03 04:09:43 - train: epoch 0018, iter [04600, 10009], lr: 0.014747, weight_decay: 0.000100, momentum_teacher: 0.996293, loss: 4.2880
2022-10-03 04:10:31 - train: epoch 0018, iter [04700, 10009], lr: 0.014747, weight_decay: 0.000100, momentum_teacher: 0.996294, loss: 4.1751
2022-10-03 04:11:19 - train: epoch 0018, iter [04800, 10009], lr: 0.014746, weight_decay: 0.000100, momentum_teacher: 0.996294, loss: 4.0495
2022-10-03 04:12:06 - train: epoch 0018, iter [04900, 10009], lr: 0.014745, weight_decay: 0.000100, momentum_teacher: 0.996294, loss: 4.1835
2022-10-03 04:12:54 - train: epoch 0018, iter [05000, 10009], lr: 0.014744, weight_decay: 0.000100, momentum_teacher: 0.996295, loss: 3.9403
2022-10-03 04:13:42 - train: epoch 0018, iter [05100, 10009], lr: 0.014744, weight_decay: 0.000100, momentum_teacher: 0.996295, loss: 4.1548
2022-10-03 04:14:29 - train: epoch 0018, iter [05200, 10009], lr: 0.014743, weight_decay: 0.000100, momentum_teacher: 0.996295, loss: 4.2710
2022-10-03 04:15:17 - train: epoch 0018, iter [05300, 10009], lr: 0.014742, weight_decay: 0.000100, momentum_teacher: 0.996296, loss: 4.2399
2022-10-03 04:16:05 - train: epoch 0018, iter [05400, 10009], lr: 0.014742, weight_decay: 0.000100, momentum_teacher: 0.996296, loss: 4.0741
2022-10-03 04:16:53 - train: epoch 0018, iter [05500, 10009], lr: 0.014741, weight_decay: 0.000100, momentum_teacher: 0.996296, loss: 4.2691
2022-10-03 04:17:40 - train: epoch 0018, iter [05600, 10009], lr: 0.014740, weight_decay: 0.000100, momentum_teacher: 0.996297, loss: 4.1270
2022-10-03 04:18:28 - train: epoch 0018, iter [05700, 10009], lr: 0.014740, weight_decay: 0.000100, momentum_teacher: 0.996297, loss: 4.1017
2022-10-03 04:19:15 - train: epoch 0018, iter [05800, 10009], lr: 0.014739, weight_decay: 0.000100, momentum_teacher: 0.996297, loss: 4.0714
2022-10-03 04:20:03 - train: epoch 0018, iter [05900, 10009], lr: 0.014738, weight_decay: 0.000100, momentum_teacher: 0.996298, loss: 4.0281
2022-10-03 04:20:51 - train: epoch 0018, iter [06000, 10009], lr: 0.014738, weight_decay: 0.000100, momentum_teacher: 0.996298, loss: 4.2155
2022-10-03 04:21:39 - train: epoch 0018, iter [06100, 10009], lr: 0.014737, weight_decay: 0.000100, momentum_teacher: 0.996298, loss: 3.8860
2022-10-03 04:22:26 - train: epoch 0018, iter [06200, 10009], lr: 0.014736, weight_decay: 0.000100, momentum_teacher: 0.996299, loss: 4.2336
2022-10-03 04:23:14 - train: epoch 0018, iter [06300, 10009], lr: 0.014736, weight_decay: 0.000100, momentum_teacher: 0.996299, loss: 4.0883
2022-10-03 04:24:02 - train: epoch 0018, iter [06400, 10009], lr: 0.014735, weight_decay: 0.000100, momentum_teacher: 0.996299, loss: 4.1171
2022-10-03 04:24:49 - train: epoch 0018, iter [06500, 10009], lr: 0.014734, weight_decay: 0.000100, momentum_teacher: 0.996300, loss: 4.0910
2022-10-03 04:25:37 - train: epoch 0018, iter [06600, 10009], lr: 0.014734, weight_decay: 0.000100, momentum_teacher: 0.996300, loss: 4.2651
2022-10-03 04:26:24 - train: epoch 0018, iter [06700, 10009], lr: 0.014733, weight_decay: 0.000100, momentum_teacher: 0.996300, loss: 4.0440
2022-10-03 04:27:12 - train: epoch 0018, iter [06800, 10009], lr: 0.014732, weight_decay: 0.000100, momentum_teacher: 0.996301, loss: 3.8945
2022-10-03 04:28:00 - train: epoch 0018, iter [06900, 10009], lr: 0.014731, weight_decay: 0.000100, momentum_teacher: 0.996301, loss: 3.9969
2022-10-03 04:28:47 - train: epoch 0018, iter [07000, 10009], lr: 0.014731, weight_decay: 0.000100, momentum_teacher: 0.996301, loss: 3.9893
2022-10-03 04:29:35 - train: epoch 0018, iter [07100, 10009], lr: 0.014730, weight_decay: 0.000100, momentum_teacher: 0.996302, loss: 4.2084
2022-10-03 04:30:23 - train: epoch 0018, iter [07200, 10009], lr: 0.014729, weight_decay: 0.000100, momentum_teacher: 0.996302, loss: 4.1334
2022-10-03 04:31:10 - train: epoch 0018, iter [07300, 10009], lr: 0.014729, weight_decay: 0.000100, momentum_teacher: 0.996302, loss: 4.0297
2022-10-03 04:31:58 - train: epoch 0018, iter [07400, 10009], lr: 0.014728, weight_decay: 0.000100, momentum_teacher: 0.996303, loss: 4.1288
2022-10-03 04:32:45 - train: epoch 0018, iter [07500, 10009], lr: 0.014727, weight_decay: 0.000100, momentum_teacher: 0.996303, loss: 4.0552
2022-10-03 04:33:33 - train: epoch 0018, iter [07600, 10009], lr: 0.014727, weight_decay: 0.000100, momentum_teacher: 0.996303, loss: 3.9334
2022-10-03 04:34:20 - train: epoch 0018, iter [07700, 10009], lr: 0.014726, weight_decay: 0.000100, momentum_teacher: 0.996304, loss: 4.0749
2022-10-03 04:35:08 - train: epoch 0018, iter [07800, 10009], lr: 0.014725, weight_decay: 0.000100, momentum_teacher: 0.996304, loss: 3.9851
2022-10-03 04:35:56 - train: epoch 0018, iter [07900, 10009], lr: 0.014724, weight_decay: 0.000100, momentum_teacher: 0.996304, loss: 4.1029
2022-10-03 04:36:43 - train: epoch 0018, iter [08000, 10009], lr: 0.014724, weight_decay: 0.000100, momentum_teacher: 0.996305, loss: 3.9427
2022-10-03 04:37:31 - train: epoch 0018, iter [08100, 10009], lr: 0.014723, weight_decay: 0.000100, momentum_teacher: 0.996305, loss: 4.1160
2022-10-03 04:38:19 - train: epoch 0018, iter [08200, 10009], lr: 0.014722, weight_decay: 0.000100, momentum_teacher: 0.996305, loss: 4.0842
2022-10-03 04:39:06 - train: epoch 0018, iter [08300, 10009], lr: 0.014722, weight_decay: 0.000100, momentum_teacher: 0.996306, loss: 4.0912
2022-10-03 04:39:54 - train: epoch 0018, iter [08400, 10009], lr: 0.014721, weight_decay: 0.000100, momentum_teacher: 0.996306, loss: 4.0351
2022-10-03 04:40:42 - train: epoch 0018, iter [08500, 10009], lr: 0.014720, weight_decay: 0.000100, momentum_teacher: 0.996306, loss: 3.9113
2022-10-03 04:41:29 - train: epoch 0018, iter [08600, 10009], lr: 0.014720, weight_decay: 0.000100, momentum_teacher: 0.996307, loss: 4.0096
2022-10-03 04:42:17 - train: epoch 0018, iter [08700, 10009], lr: 0.014719, weight_decay: 0.000100, momentum_teacher: 0.996307, loss: 4.2980
2022-10-03 04:43:05 - train: epoch 0018, iter [08800, 10009], lr: 0.014718, weight_decay: 0.000100, momentum_teacher: 0.996307, loss: 3.9443
2022-10-03 04:43:52 - train: epoch 0018, iter [08900, 10009], lr: 0.014717, weight_decay: 0.000100, momentum_teacher: 0.996308, loss: 3.9702
2022-10-03 04:44:40 - train: epoch 0018, iter [09000, 10009], lr: 0.014717, weight_decay: 0.000100, momentum_teacher: 0.996308, loss: 4.1716
2022-10-03 04:45:28 - train: epoch 0018, iter [09100, 10009], lr: 0.014716, weight_decay: 0.000100, momentum_teacher: 0.996308, loss: 3.9886
2022-10-03 04:46:15 - train: epoch 0018, iter [09200, 10009], lr: 0.014715, weight_decay: 0.000100, momentum_teacher: 0.996309, loss: 4.1507
2022-10-03 04:47:03 - train: epoch 0018, iter [09300, 10009], lr: 0.014715, weight_decay: 0.000100, momentum_teacher: 0.996309, loss: 4.1607
2022-10-03 04:47:51 - train: epoch 0018, iter [09400, 10009], lr: 0.014714, weight_decay: 0.000100, momentum_teacher: 0.996309, loss: 3.8525
2022-10-03 04:48:38 - train: epoch 0018, iter [09500, 10009], lr: 0.014713, weight_decay: 0.000100, momentum_teacher: 0.996310, loss: 4.0244
2022-10-03 04:49:26 - train: epoch 0018, iter [09600, 10009], lr: 0.014712, weight_decay: 0.000100, momentum_teacher: 0.996310, loss: 3.9523
2022-10-03 04:50:14 - train: epoch 0018, iter [09700, 10009], lr: 0.014712, weight_decay: 0.000100, momentum_teacher: 0.996310, loss: 4.3690
2022-10-03 04:51:02 - train: epoch 0018, iter [09800, 10009], lr: 0.014711, weight_decay: 0.000100, momentum_teacher: 0.996311, loss: 4.2380
2022-10-03 04:51:49 - train: epoch 0018, iter [09900, 10009], lr: 0.014710, weight_decay: 0.000100, momentum_teacher: 0.996311, loss: 4.0457
2022-10-03 04:52:37 - train: epoch 0018, iter [10000, 10009], lr: 0.014710, weight_decay: 0.000100, momentum_teacher: 0.996311, loss: 3.9558
2022-10-03 04:52:42 - train: epoch 018, train_loss: 4.0847
2022-10-03 04:52:44 - until epoch: 018, best_loss: 4.0847
2022-10-03 04:52:44 - epoch 019 lr: 0.014709
2022-10-03 04:53:37 - train: epoch 0019, iter [00100, 10009], lr: 0.014709, weight_decay: 0.000100, momentum_teacher: 0.996312, loss: 3.9704
2022-10-03 04:54:25 - train: epoch 0019, iter [00200, 10009], lr: 0.014708, weight_decay: 0.000100, momentum_teacher: 0.996312, loss: 3.9517
2022-10-03 04:55:12 - train: epoch 0019, iter [00300, 10009], lr: 0.014707, weight_decay: 0.000100, momentum_teacher: 0.996312, loss: 4.1589
2022-10-03 04:56:00 - train: epoch 0019, iter [00400, 10009], lr: 0.014707, weight_decay: 0.000100, momentum_teacher: 0.996313, loss: 4.0670
2022-10-03 04:56:47 - train: epoch 0019, iter [00500, 10009], lr: 0.014706, weight_decay: 0.000100, momentum_teacher: 0.996313, loss: 3.9561
2022-10-03 04:57:35 - train: epoch 0019, iter [00600, 10009], lr: 0.014705, weight_decay: 0.000100, momentum_teacher: 0.996313, loss: 3.8400
2022-10-03 04:58:23 - train: epoch 0019, iter [00700, 10009], lr: 0.014704, weight_decay: 0.000100, momentum_teacher: 0.996314, loss: 3.9242
2022-10-03 04:59:10 - train: epoch 0019, iter [00800, 10009], lr: 0.014704, weight_decay: 0.000100, momentum_teacher: 0.996314, loss: 3.8614
2022-10-03 04:59:58 - train: epoch 0019, iter [00900, 10009], lr: 0.014703, weight_decay: 0.000100, momentum_teacher: 0.996314, loss: 4.0308
2022-10-03 05:00:46 - train: epoch 0019, iter [01000, 10009], lr: 0.014702, weight_decay: 0.000100, momentum_teacher: 0.996315, loss: 4.0231
2022-10-03 05:01:33 - train: epoch 0019, iter [01100, 10009], lr: 0.014701, weight_decay: 0.000100, momentum_teacher: 0.996315, loss: 3.9701
2022-10-03 05:02:21 - train: epoch 0019, iter [01200, 10009], lr: 0.014701, weight_decay: 0.000100, momentum_teacher: 0.996315, loss: 4.1148
2022-10-03 05:03:08 - train: epoch 0019, iter [01300, 10009], lr: 0.014700, weight_decay: 0.000100, momentum_teacher: 0.996316, loss: 4.0281
2022-10-03 05:03:56 - train: epoch 0019, iter [01400, 10009], lr: 0.014699, weight_decay: 0.000100, momentum_teacher: 0.996316, loss: 4.1196
2022-10-03 05:04:43 - train: epoch 0019, iter [01500, 10009], lr: 0.014699, weight_decay: 0.000100, momentum_teacher: 0.996316, loss: 3.9186
2022-10-03 05:05:31 - train: epoch 0019, iter [01600, 10009], lr: 0.014698, weight_decay: 0.000100, momentum_teacher: 0.996317, loss: 4.1490
2022-10-03 05:06:18 - train: epoch 0019, iter [01700, 10009], lr: 0.014697, weight_decay: 0.000100, momentum_teacher: 0.996317, loss: 4.1918
2022-10-03 05:07:05 - train: epoch 0019, iter [01800, 10009], lr: 0.014696, weight_decay: 0.000100, momentum_teacher: 0.996317, loss: 4.1763
2022-10-03 05:07:53 - train: epoch 0019, iter [01900, 10009], lr: 0.014696, weight_decay: 0.000100, momentum_teacher: 0.996318, loss: 3.8201
2022-10-03 05:08:41 - train: epoch 0019, iter [02000, 10009], lr: 0.014695, weight_decay: 0.000100, momentum_teacher: 0.996318, loss: 4.0513
2022-10-03 05:09:29 - train: epoch 0019, iter [02100, 10009], lr: 0.014694, weight_decay: 0.000100, momentum_teacher: 0.996318, loss: 3.9159
2022-10-03 05:10:16 - train: epoch 0019, iter [02200, 10009], lr: 0.014693, weight_decay: 0.000100, momentum_teacher: 0.996319, loss: 4.3433
2022-10-03 05:11:04 - train: epoch 0019, iter [02300, 10009], lr: 0.014693, weight_decay: 0.000100, momentum_teacher: 0.996319, loss: 4.1373
2022-10-03 05:11:51 - train: epoch 0019, iter [02400, 10009], lr: 0.014692, weight_decay: 0.000100, momentum_teacher: 0.996319, loss: 3.9736
2022-10-03 05:12:39 - train: epoch 0019, iter [02500, 10009], lr: 0.014691, weight_decay: 0.000100, momentum_teacher: 0.996320, loss: 3.9350
2022-10-03 05:13:27 - train: epoch 0019, iter [02600, 10009], lr: 0.014690, weight_decay: 0.000100, momentum_teacher: 0.996320, loss: 4.0260
2022-10-03 05:14:14 - train: epoch 0019, iter [02700, 10009], lr: 0.014690, weight_decay: 0.000100, momentum_teacher: 0.996320, loss: 3.8311
2022-10-03 05:15:02 - train: epoch 0019, iter [02800, 10009], lr: 0.014689, weight_decay: 0.000100, momentum_teacher: 0.996321, loss: 3.7037
2022-10-03 05:15:49 - train: epoch 0019, iter [02900, 10009], lr: 0.014688, weight_decay: 0.000100, momentum_teacher: 0.996321, loss: 3.9745
2022-10-03 05:16:37 - train: epoch 0019, iter [03000, 10009], lr: 0.014687, weight_decay: 0.000100, momentum_teacher: 0.996322, loss: 3.9989
2022-10-03 05:17:24 - train: epoch 0019, iter [03100, 10009], lr: 0.014687, weight_decay: 0.000100, momentum_teacher: 0.996322, loss: 4.1664
2022-10-03 05:18:12 - train: epoch 0019, iter [03200, 10009], lr: 0.014686, weight_decay: 0.000100, momentum_teacher: 0.996322, loss: 4.0991
2022-10-03 05:18:59 - train: epoch 0019, iter [03300, 10009], lr: 0.014685, weight_decay: 0.000100, momentum_teacher: 0.996323, loss: 3.8587
2022-10-03 05:19:47 - train: epoch 0019, iter [03400, 10009], lr: 0.014684, weight_decay: 0.000100, momentum_teacher: 0.996323, loss: 4.1300
2022-10-03 05:20:34 - train: epoch 0019, iter [03500, 10009], lr: 0.014684, weight_decay: 0.000100, momentum_teacher: 0.996323, loss: 3.9764
2022-10-03 05:21:22 - train: epoch 0019, iter [03600, 10009], lr: 0.014683, weight_decay: 0.000100, momentum_teacher: 0.996324, loss: 3.9295
2022-10-03 05:22:10 - train: epoch 0019, iter [03700, 10009], lr: 0.014682, weight_decay: 0.000100, momentum_teacher: 0.996324, loss: 4.0199
2022-10-03 05:22:57 - train: epoch 0019, iter [03800, 10009], lr: 0.014681, weight_decay: 0.000100, momentum_teacher: 0.996324, loss: 4.0261
2022-10-03 05:23:45 - train: epoch 0019, iter [03900, 10009], lr: 0.014681, weight_decay: 0.000100, momentum_teacher: 0.996325, loss: 4.0918
2022-10-03 05:24:33 - train: epoch 0019, iter [04000, 10009], lr: 0.014680, weight_decay: 0.000100, momentum_teacher: 0.996325, loss: 4.0060
2022-10-03 05:25:20 - train: epoch 0019, iter [04100, 10009], lr: 0.014679, weight_decay: 0.000100, momentum_teacher: 0.996325, loss: 3.9843
2022-10-03 05:26:08 - train: epoch 0019, iter [04200, 10009], lr: 0.014678, weight_decay: 0.000100, momentum_teacher: 0.996326, loss: 3.9624
2022-10-03 05:26:55 - train: epoch 0019, iter [04300, 10009], lr: 0.014678, weight_decay: 0.000100, momentum_teacher: 0.996326, loss: 4.0866
2022-10-03 05:27:42 - train: epoch 0019, iter [04400, 10009], lr: 0.014677, weight_decay: 0.000100, momentum_teacher: 0.996326, loss: 4.1821
2022-10-03 05:28:30 - train: epoch 0019, iter [04500, 10009], lr: 0.014676, weight_decay: 0.000100, momentum_teacher: 0.996327, loss: 4.1386
2022-10-03 05:29:17 - train: epoch 0019, iter [04600, 10009], lr: 0.014675, weight_decay: 0.000100, momentum_teacher: 0.996327, loss: 3.8371
2022-10-03 05:30:05 - train: epoch 0019, iter [04700, 10009], lr: 0.014675, weight_decay: 0.000100, momentum_teacher: 0.996327, loss: 4.1276
2022-10-03 05:30:53 - train: epoch 0019, iter [04800, 10009], lr: 0.014674, weight_decay: 0.000100, momentum_teacher: 0.996328, loss: 4.1607
2022-10-03 05:31:40 - train: epoch 0019, iter [04900, 10009], lr: 0.014673, weight_decay: 0.000100, momentum_teacher: 0.996328, loss: 3.9823
2022-10-03 05:32:28 - train: epoch 0019, iter [05000, 10009], lr: 0.014672, weight_decay: 0.000100, momentum_teacher: 0.996328, loss: 3.8049
2022-10-03 05:33:15 - train: epoch 0019, iter [05100, 10009], lr: 0.014672, weight_decay: 0.000100, momentum_teacher: 0.996329, loss: 4.1548
2022-10-03 05:34:03 - train: epoch 0019, iter [05200, 10009], lr: 0.014671, weight_decay: 0.000100, momentum_teacher: 0.996329, loss: 3.9593
2022-10-03 05:34:50 - train: epoch 0019, iter [05300, 10009], lr: 0.014670, weight_decay: 0.000100, momentum_teacher: 0.996329, loss: 4.1261
2022-10-03 05:35:38 - train: epoch 0019, iter [05400, 10009], lr: 0.014669, weight_decay: 0.000100, momentum_teacher: 0.996330, loss: 4.0466
2022-10-03 05:36:25 - train: epoch 0019, iter [05500, 10009], lr: 0.014669, weight_decay: 0.000100, momentum_teacher: 0.996330, loss: 3.8553
2022-10-03 05:37:13 - train: epoch 0019, iter [05600, 10009], lr: 0.014668, weight_decay: 0.000100, momentum_teacher: 0.996330, loss: 3.9266
2022-10-03 05:38:00 - train: epoch 0019, iter [05700, 10009], lr: 0.014667, weight_decay: 0.000100, momentum_teacher: 0.996331, loss: 4.1539
2022-10-03 05:38:48 - train: epoch 0019, iter [05800, 10009], lr: 0.014666, weight_decay: 0.000100, momentum_teacher: 0.996331, loss: 3.9855
2022-10-03 05:39:36 - train: epoch 0019, iter [05900, 10009], lr: 0.014665, weight_decay: 0.000100, momentum_teacher: 0.996331, loss: 4.1718
2022-10-03 05:40:23 - train: epoch 0019, iter [06000, 10009], lr: 0.014665, weight_decay: 0.000100, momentum_teacher: 0.996332, loss: 3.9958
2022-10-03 05:41:11 - train: epoch 0019, iter [06100, 10009], lr: 0.014664, weight_decay: 0.000100, momentum_teacher: 0.996332, loss: 4.1597
2022-10-03 05:41:59 - train: epoch 0019, iter [06200, 10009], lr: 0.014663, weight_decay: 0.000100, momentum_teacher: 0.996333, loss: 4.1420
2022-10-03 05:42:46 - train: epoch 0019, iter [06300, 10009], lr: 0.014662, weight_decay: 0.000100, momentum_teacher: 0.996333, loss: 4.0391
2022-10-03 05:43:34 - train: epoch 0019, iter [06400, 10009], lr: 0.014662, weight_decay: 0.000100, momentum_teacher: 0.996333, loss: 3.9387
2022-10-03 05:44:21 - train: epoch 0019, iter [06500, 10009], lr: 0.014661, weight_decay: 0.000100, momentum_teacher: 0.996334, loss: 4.2886
2022-10-03 05:45:09 - train: epoch 0019, iter [06600, 10009], lr: 0.014660, weight_decay: 0.000100, momentum_teacher: 0.996334, loss: 3.9265
2022-10-03 05:45:57 - train: epoch 0019, iter [06700, 10009], lr: 0.014659, weight_decay: 0.000100, momentum_teacher: 0.996334, loss: 3.8877
2022-10-03 05:46:44 - train: epoch 0019, iter [06800, 10009], lr: 0.014658, weight_decay: 0.000100, momentum_teacher: 0.996335, loss: 3.8520
2022-10-03 05:47:32 - train: epoch 0019, iter [06900, 10009], lr: 0.014658, weight_decay: 0.000100, momentum_teacher: 0.996335, loss: 4.0334
2022-10-03 05:48:19 - train: epoch 0019, iter [07000, 10009], lr: 0.014657, weight_decay: 0.000100, momentum_teacher: 0.996335, loss: 4.0512
2022-10-03 05:49:07 - train: epoch 0019, iter [07100, 10009], lr: 0.014656, weight_decay: 0.000100, momentum_teacher: 0.996336, loss: 3.8736
2022-10-03 05:49:55 - train: epoch 0019, iter [07200, 10009], lr: 0.014655, weight_decay: 0.000100, momentum_teacher: 0.996336, loss: 4.0666
2022-10-03 05:50:43 - train: epoch 0019, iter [07300, 10009], lr: 0.014655, weight_decay: 0.000100, momentum_teacher: 0.996336, loss: 4.0019
2022-10-03 05:51:30 - train: epoch 0019, iter [07400, 10009], lr: 0.014654, weight_decay: 0.000100, momentum_teacher: 0.996337, loss: 4.0701
2022-10-03 05:52:18 - train: epoch 0019, iter [07500, 10009], lr: 0.014653, weight_decay: 0.000100, momentum_teacher: 0.996337, loss: 3.8102
2022-10-03 05:53:05 - train: epoch 0019, iter [07600, 10009], lr: 0.014652, weight_decay: 0.000100, momentum_teacher: 0.996337, loss: 3.9106
2022-10-03 05:53:53 - train: epoch 0019, iter [07700, 10009], lr: 0.014651, weight_decay: 0.000100, momentum_teacher: 0.996338, loss: 4.0947
2022-10-03 05:54:41 - train: epoch 0019, iter [07800, 10009], lr: 0.014651, weight_decay: 0.000100, momentum_teacher: 0.996338, loss: 3.9470
2022-10-03 05:55:28 - train: epoch 0019, iter [07900, 10009], lr: 0.014650, weight_decay: 0.000100, momentum_teacher: 0.996338, loss: 4.1250
2022-10-03 05:56:16 - train: epoch 0019, iter [08000, 10009], lr: 0.014649, weight_decay: 0.000100, momentum_teacher: 0.996339, loss: 4.0809
2022-10-03 05:57:03 - train: epoch 0019, iter [08100, 10009], lr: 0.014648, weight_decay: 0.000100, momentum_teacher: 0.996339, loss: 3.9362
2022-10-03 05:57:51 - train: epoch 0019, iter [08200, 10009], lr: 0.014647, weight_decay: 0.000100, momentum_teacher: 0.996339, loss: 4.0928
2022-10-03 05:58:39 - train: epoch 0019, iter [08300, 10009], lr: 0.014647, weight_decay: 0.000100, momentum_teacher: 0.996340, loss: 4.2750
2022-10-03 05:59:26 - train: epoch 0019, iter [08400, 10009], lr: 0.014646, weight_decay: 0.000100, momentum_teacher: 0.996340, loss: 3.9354
2022-10-03 06:00:14 - train: epoch 0019, iter [08500, 10009], lr: 0.014645, weight_decay: 0.000100, momentum_teacher: 0.996341, loss: 4.0660
2022-10-03 06:01:01 - train: epoch 0019, iter [08600, 10009], lr: 0.014644, weight_decay: 0.000100, momentum_teacher: 0.996341, loss: 3.9409
2022-10-03 06:01:49 - train: epoch 0019, iter [08700, 10009], lr: 0.014643, weight_decay: 0.000100, momentum_teacher: 0.996341, loss: 4.1578
2022-10-03 06:02:37 - train: epoch 0019, iter [08800, 10009], lr: 0.014643, weight_decay: 0.000100, momentum_teacher: 0.996342, loss: 3.9368
2022-10-03 06:03:24 - train: epoch 0019, iter [08900, 10009], lr: 0.014642, weight_decay: 0.000100, momentum_teacher: 0.996342, loss: 4.0209
2022-10-03 06:04:12 - train: epoch 0019, iter [09000, 10009], lr: 0.014641, weight_decay: 0.000100, momentum_teacher: 0.996342, loss: 4.1677
2022-10-03 06:05:00 - train: epoch 0019, iter [09100, 10009], lr: 0.014640, weight_decay: 0.000100, momentum_teacher: 0.996343, loss: 4.1296
2022-10-03 06:05:47 - train: epoch 0019, iter [09200, 10009], lr: 0.014639, weight_decay: 0.000100, momentum_teacher: 0.996343, loss: 4.1263
2022-10-03 06:06:35 - train: epoch 0019, iter [09300, 10009], lr: 0.014639, weight_decay: 0.000100, momentum_teacher: 0.996343, loss: 3.8601
2022-10-03 06:07:22 - train: epoch 0019, iter [09400, 10009], lr: 0.014638, weight_decay: 0.000100, momentum_teacher: 0.996344, loss: 4.1495
2022-10-03 06:08:10 - train: epoch 0019, iter [09500, 10009], lr: 0.014637, weight_decay: 0.000100, momentum_teacher: 0.996344, loss: 3.9643
2022-10-03 06:08:58 - train: epoch 0019, iter [09600, 10009], lr: 0.014636, weight_decay: 0.000100, momentum_teacher: 0.996344, loss: 4.1072
2022-10-03 06:09:45 - train: epoch 0019, iter [09700, 10009], lr: 0.014635, weight_decay: 0.000100, momentum_teacher: 0.996345, loss: 4.1442
2022-10-03 06:10:33 - train: epoch 0019, iter [09800, 10009], lr: 0.014635, weight_decay: 0.000100, momentum_teacher: 0.996345, loss: 4.0625
2022-10-03 06:11:20 - train: epoch 0019, iter [09900, 10009], lr: 0.014634, weight_decay: 0.000100, momentum_teacher: 0.996345, loss: 3.9668
2022-10-03 06:12:08 - train: epoch 0019, iter [10000, 10009], lr: 0.014633, weight_decay: 0.000100, momentum_teacher: 0.996346, loss: 4.0980
2022-10-03 06:12:13 - train: epoch 019, train_loss: 4.0088
2022-10-03 06:12:15 - until epoch: 019, best_loss: 4.0088
2022-10-03 06:12:15 - epoch 020 lr: 0.014633
2022-10-03 06:13:09 - train: epoch 0020, iter [00100, 10009], lr: 0.014632, weight_decay: 0.000100, momentum_teacher: 0.996346, loss: 4.0663
2022-10-03 06:13:56 - train: epoch 0020, iter [00200, 10009], lr: 0.014631, weight_decay: 0.000100, momentum_teacher: 0.996347, loss: 3.8782
2022-10-03 06:14:44 - train: epoch 0020, iter [00300, 10009], lr: 0.014631, weight_decay: 0.000100, momentum_teacher: 0.996347, loss: 4.0210
2022-10-03 06:15:31 - train: epoch 0020, iter [00400, 10009], lr: 0.014630, weight_decay: 0.000100, momentum_teacher: 0.996347, loss: 3.9054
2022-10-03 06:16:19 - train: epoch 0020, iter [00500, 10009], lr: 0.014629, weight_decay: 0.000100, momentum_teacher: 0.996348, loss: 3.9236
2022-10-03 06:17:06 - train: epoch 0020, iter [00600, 10009], lr: 0.014628, weight_decay: 0.000100, momentum_teacher: 0.996348, loss: 4.0859
2022-10-03 06:17:54 - train: epoch 0020, iter [00700, 10009], lr: 0.014627, weight_decay: 0.000100, momentum_teacher: 0.996348, loss: 3.8438
2022-10-03 06:18:41 - train: epoch 0020, iter [00800, 10009], lr: 0.014626, weight_decay: 0.000100, momentum_teacher: 0.996349, loss: 4.1201
2022-10-03 06:19:29 - train: epoch 0020, iter [00900, 10009], lr: 0.014626, weight_decay: 0.000100, momentum_teacher: 0.996349, loss: 3.8158
2022-10-03 06:20:17 - train: epoch 0020, iter [01000, 10009], lr: 0.014625, weight_decay: 0.000100, momentum_teacher: 0.996349, loss: 3.8903
2022-10-03 06:21:04 - train: epoch 0020, iter [01100, 10009], lr: 0.014624, weight_decay: 0.000100, momentum_teacher: 0.996350, loss: 4.1431
2022-10-03 06:21:52 - train: epoch 0020, iter [01200, 10009], lr: 0.014623, weight_decay: 0.000100, momentum_teacher: 0.996350, loss: 4.1899
2022-10-03 06:22:39 - train: epoch 0020, iter [01300, 10009], lr: 0.014622, weight_decay: 0.000100, momentum_teacher: 0.996350, loss: 3.8872
2022-10-03 06:23:27 - train: epoch 0020, iter [01400, 10009], lr: 0.014622, weight_decay: 0.000100, momentum_teacher: 0.996351, loss: 3.8922
2022-10-03 06:24:15 - train: epoch 0020, iter [01500, 10009], lr: 0.014621, weight_decay: 0.000100, momentum_teacher: 0.996351, loss: 3.9502
2022-10-03 06:25:02 - train: epoch 0020, iter [01600, 10009], lr: 0.014620, weight_decay: 0.000100, momentum_teacher: 0.996352, loss: 3.8901
2022-10-03 06:25:50 - train: epoch 0020, iter [01700, 10009], lr: 0.014619, weight_decay: 0.000100, momentum_teacher: 0.996352, loss: 3.9773
2022-10-03 06:26:37 - train: epoch 0020, iter [01800, 10009], lr: 0.014618, weight_decay: 0.000100, momentum_teacher: 0.996352, loss: 3.9208
2022-10-03 06:27:24 - train: epoch 0020, iter [01900, 10009], lr: 0.014617, weight_decay: 0.000100, momentum_teacher: 0.996353, loss: 3.7837
2022-10-03 06:28:12 - train: epoch 0020, iter [02000, 10009], lr: 0.014617, weight_decay: 0.000100, momentum_teacher: 0.996353, loss: 3.9396
2022-10-03 06:28:59 - train: epoch 0020, iter [02100, 10009], lr: 0.014616, weight_decay: 0.000100, momentum_teacher: 0.996353, loss: 4.1110
2022-10-03 06:29:47 - train: epoch 0020, iter [02200, 10009], lr: 0.014615, weight_decay: 0.000100, momentum_teacher: 0.996354, loss: 4.1214
2022-10-03 06:30:34 - train: epoch 0020, iter [02300, 10009], lr: 0.014614, weight_decay: 0.000100, momentum_teacher: 0.996354, loss: 3.9165
2022-10-03 06:31:22 - train: epoch 0020, iter [02400, 10009], lr: 0.014613, weight_decay: 0.000100, momentum_teacher: 0.996354, loss: 3.8314
2022-10-03 06:32:09 - train: epoch 0020, iter [02500, 10009], lr: 0.014612, weight_decay: 0.000100, momentum_teacher: 0.996355, loss: 4.1464
2022-10-03 06:32:57 - train: epoch 0020, iter [02600, 10009], lr: 0.014612, weight_decay: 0.000100, momentum_teacher: 0.996355, loss: 4.0362
2022-10-03 06:33:44 - train: epoch 0020, iter [02700, 10009], lr: 0.014611, weight_decay: 0.000100, momentum_teacher: 0.996355, loss: 3.9965
2022-10-03 06:34:32 - train: epoch 0020, iter [02800, 10009], lr: 0.014610, weight_decay: 0.000100, momentum_teacher: 0.996356, loss: 4.1116
2022-10-03 06:35:19 - train: epoch 0020, iter [02900, 10009], lr: 0.014609, weight_decay: 0.000100, momentum_teacher: 0.996356, loss: 4.2652
2022-10-03 06:36:07 - train: epoch 0020, iter [03000, 10009], lr: 0.014608, weight_decay: 0.000100, momentum_teacher: 0.996356, loss: 3.9042
2022-10-03 06:36:54 - train: epoch 0020, iter [03100, 10009], lr: 0.014607, weight_decay: 0.000100, momentum_teacher: 0.996357, loss: 4.1318
2022-10-03 06:37:42 - train: epoch 0020, iter [03200, 10009], lr: 0.014607, weight_decay: 0.000100, momentum_teacher: 0.996357, loss: 4.1039
2022-10-03 06:38:29 - train: epoch 0020, iter [03300, 10009], lr: 0.014606, weight_decay: 0.000100, momentum_teacher: 0.996358, loss: 4.0311
2022-10-03 06:39:17 - train: epoch 0020, iter [03400, 10009], lr: 0.014605, weight_decay: 0.000100, momentum_teacher: 0.996358, loss: 3.9972
2022-10-03 06:40:04 - train: epoch 0020, iter [03500, 10009], lr: 0.014604, weight_decay: 0.000100, momentum_teacher: 0.996358, loss: 4.0335
2022-10-03 06:40:52 - train: epoch 0020, iter [03600, 10009], lr: 0.014603, weight_decay: 0.000100, momentum_teacher: 0.996359, loss: 3.8162
2022-10-03 06:41:39 - train: epoch 0020, iter [03700, 10009], lr: 0.014602, weight_decay: 0.000100, momentum_teacher: 0.996359, loss: 3.8812
2022-10-03 06:42:27 - train: epoch 0020, iter [03800, 10009], lr: 0.014602, weight_decay: 0.000100, momentum_teacher: 0.996359, loss: 3.9396
2022-10-03 06:43:14 - train: epoch 0020, iter [03900, 10009], lr: 0.014601, weight_decay: 0.000100, momentum_teacher: 0.996360, loss: 4.0755
2022-10-03 06:44:02 - train: epoch 0020, iter [04000, 10009], lr: 0.014600, weight_decay: 0.000100, momentum_teacher: 0.996360, loss: 3.8252
2022-10-03 06:44:49 - train: epoch 0020, iter [04100, 10009], lr: 0.014599, weight_decay: 0.000100, momentum_teacher: 0.996360, loss: 3.9452
2022-10-03 06:45:37 - train: epoch 0020, iter [04200, 10009], lr: 0.014598, weight_decay: 0.000100, momentum_teacher: 0.996361, loss: 3.9868
2022-10-03 06:46:25 - train: epoch 0020, iter [04300, 10009], lr: 0.014597, weight_decay: 0.000100, momentum_teacher: 0.996361, loss: 3.9538
2022-10-03 06:47:12 - train: epoch 0020, iter [04400, 10009], lr: 0.014597, weight_decay: 0.000100, momentum_teacher: 0.996362, loss: 3.8636
2022-10-03 06:48:00 - train: epoch 0020, iter [04500, 10009], lr: 0.014596, weight_decay: 0.000100, momentum_teacher: 0.996362, loss: 3.8711
2022-10-03 06:48:48 - train: epoch 0020, iter [04600, 10009], lr: 0.014595, weight_decay: 0.000100, momentum_teacher: 0.996362, loss: 4.0350
2022-10-03 06:49:35 - train: epoch 0020, iter [04700, 10009], lr: 0.014594, weight_decay: 0.000100, momentum_teacher: 0.996363, loss: 3.8452
2022-10-03 06:50:23 - train: epoch 0020, iter [04800, 10009], lr: 0.014593, weight_decay: 0.000100, momentum_teacher: 0.996363, loss: 3.8493
2022-10-03 06:51:10 - train: epoch 0020, iter [04900, 10009], lr: 0.014592, weight_decay: 0.000100, momentum_teacher: 0.996363, loss: 3.9236
2022-10-03 06:51:58 - train: epoch 0020, iter [05000, 10009], lr: 0.014591, weight_decay: 0.000100, momentum_teacher: 0.996364, loss: 3.9915
2022-10-03 06:52:46 - train: epoch 0020, iter [05100, 10009], lr: 0.014591, weight_decay: 0.000100, momentum_teacher: 0.996364, loss: 3.8153
2022-10-03 06:53:33 - train: epoch 0020, iter [05200, 10009], lr: 0.014590, weight_decay: 0.000100, momentum_teacher: 0.996364, loss: 3.7969
2022-10-03 06:54:21 - train: epoch 0020, iter [05300, 10009], lr: 0.014589, weight_decay: 0.000100, momentum_teacher: 0.996365, loss: 4.0613
2022-10-03 06:55:09 - train: epoch 0020, iter [05400, 10009], lr: 0.014588, weight_decay: 0.000100, momentum_teacher: 0.996365, loss: 4.0013
2022-10-03 06:55:56 - train: epoch 0020, iter [05500, 10009], lr: 0.014587, weight_decay: 0.000100, momentum_teacher: 0.996365, loss: 3.9390
2022-10-03 06:56:44 - train: epoch 0020, iter [05600, 10009], lr: 0.014586, weight_decay: 0.000100, momentum_teacher: 0.996366, loss: 3.8844
2022-10-03 06:57:32 - train: epoch 0020, iter [05700, 10009], lr: 0.014585, weight_decay: 0.000100, momentum_teacher: 0.996366, loss: 3.7759
2022-10-03 06:58:19 - train: epoch 0020, iter [05800, 10009], lr: 0.014585, weight_decay: 0.000100, momentum_teacher: 0.996367, loss: 4.0222
2022-10-03 06:59:07 - train: epoch 0020, iter [05900, 10009], lr: 0.014584, weight_decay: 0.000100, momentum_teacher: 0.996367, loss: 3.9175
2022-10-03 06:59:54 - train: epoch 0020, iter [06000, 10009], lr: 0.014583, weight_decay: 0.000100, momentum_teacher: 0.996367, loss: 4.2365
2022-10-03 07:00:42 - train: epoch 0020, iter [06100, 10009], lr: 0.014582, weight_decay: 0.000100, momentum_teacher: 0.996368, loss: 3.6562
2022-10-03 07:01:30 - train: epoch 0020, iter [06200, 10009], lr: 0.014581, weight_decay: 0.000100, momentum_teacher: 0.996368, loss: 4.0220
2022-10-03 07:02:17 - train: epoch 0020, iter [06300, 10009], lr: 0.014580, weight_decay: 0.000100, momentum_teacher: 0.996368, loss: 3.8341
2022-10-03 07:03:05 - train: epoch 0020, iter [06400, 10009], lr: 0.014579, weight_decay: 0.000100, momentum_teacher: 0.996369, loss: 3.9466
2022-10-03 07:03:53 - train: epoch 0020, iter [06500, 10009], lr: 0.014579, weight_decay: 0.000100, momentum_teacher: 0.996369, loss: 4.0827
2022-10-03 07:04:40 - train: epoch 0020, iter [06600, 10009], lr: 0.014578, weight_decay: 0.000100, momentum_teacher: 0.996369, loss: 3.9264
2022-10-03 07:05:28 - train: epoch 0020, iter [06700, 10009], lr: 0.014577, weight_decay: 0.000100, momentum_teacher: 0.996370, loss: 4.0574
2022-10-03 07:06:15 - train: epoch 0020, iter [06800, 10009], lr: 0.014576, weight_decay: 0.000100, momentum_teacher: 0.996370, loss: 4.0111
2022-10-03 07:07:02 - train: epoch 0020, iter [06900, 10009], lr: 0.014575, weight_decay: 0.000100, momentum_teacher: 0.996371, loss: 3.9807
2022-10-03 07:07:50 - train: epoch 0020, iter [07000, 10009], lr: 0.014574, weight_decay: 0.000100, momentum_teacher: 0.996371, loss: 3.8273
2022-10-03 07:08:37 - train: epoch 0020, iter [07100, 10009], lr: 0.014573, weight_decay: 0.000100, momentum_teacher: 0.996371, loss: 4.0116
2022-10-03 07:09:25 - train: epoch 0020, iter [07200, 10009], lr: 0.014573, weight_decay: 0.000100, momentum_teacher: 0.996372, loss: 3.7931
2022-10-03 07:10:13 - train: epoch 0020, iter [07300, 10009], lr: 0.014572, weight_decay: 0.000100, momentum_teacher: 0.996372, loss: 4.0990
2022-10-03 07:11:00 - train: epoch 0020, iter [07400, 10009], lr: 0.014571, weight_decay: 0.000100, momentum_teacher: 0.996372, loss: 3.9376
2022-10-03 07:11:48 - train: epoch 0020, iter [07500, 10009], lr: 0.014570, weight_decay: 0.000100, momentum_teacher: 0.996373, loss: 3.7827
2022-10-03 07:12:36 - train: epoch 0020, iter [07600, 10009], lr: 0.014569, weight_decay: 0.000100, momentum_teacher: 0.996373, loss: 3.7930
2022-10-03 07:13:23 - train: epoch 0020, iter [07700, 10009], lr: 0.014568, weight_decay: 0.000100, momentum_teacher: 0.996373, loss: 3.9969
2022-10-03 07:14:11 - train: epoch 0020, iter [07800, 10009], lr: 0.014567, weight_decay: 0.000100, momentum_teacher: 0.996374, loss: 4.0008
2022-10-03 07:14:58 - train: epoch 0020, iter [07900, 10009], lr: 0.014566, weight_decay: 0.000100, momentum_teacher: 0.996374, loss: 3.8327
2022-10-03 07:15:46 - train: epoch 0020, iter [08000, 10009], lr: 0.014566, weight_decay: 0.000100, momentum_teacher: 0.996375, loss: 4.0184
2022-10-03 07:16:34 - train: epoch 0020, iter [08100, 10009], lr: 0.014565, weight_decay: 0.000100, momentum_teacher: 0.996375, loss: 4.0563
2022-10-03 07:17:21 - train: epoch 0020, iter [08200, 10009], lr: 0.014564, weight_decay: 0.000100, momentum_teacher: 0.996375, loss: 3.9331
2022-10-03 07:18:09 - train: epoch 0020, iter [08300, 10009], lr: 0.014563, weight_decay: 0.000100, momentum_teacher: 0.996376, loss: 3.7902
2022-10-03 07:18:57 - train: epoch 0020, iter [08400, 10009], lr: 0.014562, weight_decay: 0.000100, momentum_teacher: 0.996376, loss: 3.8193
2022-10-03 07:19:44 - train: epoch 0020, iter [08500, 10009], lr: 0.014561, weight_decay: 0.000100, momentum_teacher: 0.996376, loss: 4.1321
2022-10-03 07:20:32 - train: epoch 0020, iter [08600, 10009], lr: 0.014560, weight_decay: 0.000100, momentum_teacher: 0.996377, loss: 3.9261
2022-10-03 07:21:19 - train: epoch 0020, iter [08700, 10009], lr: 0.014559, weight_decay: 0.000100, momentum_teacher: 0.996377, loss: 3.9362
2022-10-03 07:22:07 - train: epoch 0020, iter [08800, 10009], lr: 0.014558, weight_decay: 0.000100, momentum_teacher: 0.996378, loss: 3.9896
2022-10-03 07:22:54 - train: epoch 0020, iter [08900, 10009], lr: 0.014558, weight_decay: 0.000100, momentum_teacher: 0.996378, loss: 3.9964
2022-10-03 07:23:42 - train: epoch 0020, iter [09000, 10009], lr: 0.014557, weight_decay: 0.000100, momentum_teacher: 0.996378, loss: 4.0224
2022-10-03 07:24:30 - train: epoch 0020, iter [09100, 10009], lr: 0.014556, weight_decay: 0.000100, momentum_teacher: 0.996379, loss: 3.8964
2022-10-03 07:25:17 - train: epoch 0020, iter [09200, 10009], lr: 0.014555, weight_decay: 0.000100, momentum_teacher: 0.996379, loss: 3.7309
2022-10-03 07:26:05 - train: epoch 0020, iter [09300, 10009], lr: 0.014554, weight_decay: 0.000100, momentum_teacher: 0.996379, loss: 3.8742
2022-10-03 07:26:52 - train: epoch 0020, iter [09400, 10009], lr: 0.014553, weight_decay: 0.000100, momentum_teacher: 0.996380, loss: 3.9252
2022-10-03 07:27:40 - train: epoch 0020, iter [09500, 10009], lr: 0.014552, weight_decay: 0.000100, momentum_teacher: 0.996380, loss: 3.8324
2022-10-03 07:28:28 - train: epoch 0020, iter [09600, 10009], lr: 0.014551, weight_decay: 0.000100, momentum_teacher: 0.996380, loss: 4.0907
2022-10-03 07:29:15 - train: epoch 0020, iter [09700, 10009], lr: 0.014550, weight_decay: 0.000100, momentum_teacher: 0.996381, loss: 3.8525
2022-10-03 07:30:03 - train: epoch 0020, iter [09800, 10009], lr: 0.014550, weight_decay: 0.000100, momentum_teacher: 0.996381, loss: 3.7886
2022-10-03 07:30:51 - train: epoch 0020, iter [09900, 10009], lr: 0.014549, weight_decay: 0.000100, momentum_teacher: 0.996382, loss: 3.6630
2022-10-03 07:31:38 - train: epoch 0020, iter [10000, 10009], lr: 0.014548, weight_decay: 0.000100, momentum_teacher: 0.996382, loss: 3.9495
2022-10-03 07:31:44 - train: epoch 020, train_loss: 3.9424
2022-10-03 07:31:45 - until epoch: 020, best_loss: 3.9424
2022-10-03 07:31:45 - epoch 021 lr: 0.014548
2022-10-03 07:32:39 - train: epoch 0021, iter [00100, 10009], lr: 0.014547, weight_decay: 0.000100, momentum_teacher: 0.996382, loss: 3.9582
2022-10-03 07:33:27 - train: epoch 0021, iter [00200, 10009], lr: 0.014546, weight_decay: 0.000100, momentum_teacher: 0.996383, loss: 3.8950
2022-10-03 07:34:14 - train: epoch 0021, iter [00300, 10009], lr: 0.014545, weight_decay: 0.000100, momentum_teacher: 0.996383, loss: 3.8162
2022-10-03 07:35:02 - train: epoch 0021, iter [00400, 10009], lr: 0.014544, weight_decay: 0.000100, momentum_teacher: 0.996383, loss: 3.7735
2022-10-03 07:35:49 - train: epoch 0021, iter [00500, 10009], lr: 0.014543, weight_decay: 0.000100, momentum_teacher: 0.996384, loss: 3.9706
2022-10-03 07:36:37 - train: epoch 0021, iter [00600, 10009], lr: 0.014542, weight_decay: 0.000100, momentum_teacher: 0.996384, loss: 3.5454
2022-10-03 07:37:24 - train: epoch 0021, iter [00700, 10009], lr: 0.014541, weight_decay: 0.000100, momentum_teacher: 0.996385, loss: 3.7614
2022-10-03 07:38:12 - train: epoch 0021, iter [00800, 10009], lr: 0.014541, weight_decay: 0.000100, momentum_teacher: 0.996385, loss: 3.8000
2022-10-03 07:39:00 - train: epoch 0021, iter [00900, 10009], lr: 0.014540, weight_decay: 0.000100, momentum_teacher: 0.996385, loss: 3.9330
2022-10-03 07:39:47 - train: epoch 0021, iter [01000, 10009], lr: 0.014539, weight_decay: 0.000100, momentum_teacher: 0.996386, loss: 3.7724
2022-10-03 07:40:34 - train: epoch 0021, iter [01100, 10009], lr: 0.014538, weight_decay: 0.000100, momentum_teacher: 0.996386, loss: 3.9493
2022-10-03 07:41:22 - train: epoch 0021, iter [01200, 10009], lr: 0.014537, weight_decay: 0.000100, momentum_teacher: 0.996386, loss: 3.7886
2022-10-03 07:42:10 - train: epoch 0021, iter [01300, 10009], lr: 0.014536, weight_decay: 0.000100, momentum_teacher: 0.996387, loss: 3.9477
2022-10-03 07:42:57 - train: epoch 0021, iter [01400, 10009], lr: 0.014535, weight_decay: 0.000100, momentum_teacher: 0.996387, loss: 3.9200
2022-10-03 07:43:45 - train: epoch 0021, iter [01500, 10009], lr: 0.014534, weight_decay: 0.000100, momentum_teacher: 0.996388, loss: 3.9382
2022-10-03 07:44:32 - train: epoch 0021, iter [01600, 10009], lr: 0.014533, weight_decay: 0.000100, momentum_teacher: 0.996388, loss: 4.0318
2022-10-03 07:45:19 - train: epoch 0021, iter [01700, 10009], lr: 0.014532, weight_decay: 0.000100, momentum_teacher: 0.996388, loss: 3.8865
2022-10-03 07:46:07 - train: epoch 0021, iter [01800, 10009], lr: 0.014531, weight_decay: 0.000100, momentum_teacher: 0.996389, loss: 3.9431
2022-10-03 07:46:54 - train: epoch 0021, iter [01900, 10009], lr: 0.014531, weight_decay: 0.000100, momentum_teacher: 0.996389, loss: 3.8470
2022-10-03 07:47:42 - train: epoch 0021, iter [02000, 10009], lr: 0.014530, weight_decay: 0.000100, momentum_teacher: 0.996389, loss: 3.7353
2022-10-03 07:48:29 - train: epoch 0021, iter [02100, 10009], lr: 0.014529, weight_decay: 0.000100, momentum_teacher: 0.996390, loss: 3.8709
2022-10-03 07:49:17 - train: epoch 0021, iter [02200, 10009], lr: 0.014528, weight_decay: 0.000100, momentum_teacher: 0.996390, loss: 3.6067
2022-10-03 07:50:04 - train: epoch 0021, iter [02300, 10009], lr: 0.014527, weight_decay: 0.000100, momentum_teacher: 0.996390, loss: 3.8921
2022-10-03 07:50:52 - train: epoch 0021, iter [02400, 10009], lr: 0.014526, weight_decay: 0.000100, momentum_teacher: 0.996391, loss: 3.9634
2022-10-03 07:51:40 - train: epoch 0021, iter [02500, 10009], lr: 0.014525, weight_decay: 0.000100, momentum_teacher: 0.996391, loss: 3.8940
2022-10-03 07:52:27 - train: epoch 0021, iter [02600, 10009], lr: 0.014524, weight_decay: 0.000100, momentum_teacher: 0.996392, loss: 3.9464
2022-10-03 07:53:15 - train: epoch 0021, iter [02700, 10009], lr: 0.014523, weight_decay: 0.000100, momentum_teacher: 0.996392, loss: 3.7655
2022-10-03 07:54:02 - train: epoch 0021, iter [02800, 10009], lr: 0.014522, weight_decay: 0.000100, momentum_teacher: 0.996392, loss: 3.8700
2022-10-03 07:54:50 - train: epoch 0021, iter [02900, 10009], lr: 0.014521, weight_decay: 0.000100, momentum_teacher: 0.996393, loss: 3.9766
2022-10-03 07:55:37 - train: epoch 0021, iter [03000, 10009], lr: 0.014521, weight_decay: 0.000100, momentum_teacher: 0.996393, loss: 3.7062
2022-10-03 07:56:25 - train: epoch 0021, iter [03100, 10009], lr: 0.014520, weight_decay: 0.000100, momentum_teacher: 0.996393, loss: 3.8711
2022-10-03 07:57:12 - train: epoch 0021, iter [03200, 10009], lr: 0.014519, weight_decay: 0.000100, momentum_teacher: 0.996394, loss: 3.8597
2022-10-03 07:58:00 - train: epoch 0021, iter [03300, 10009], lr: 0.014518, weight_decay: 0.000100, momentum_teacher: 0.996394, loss: 3.8447
2022-10-03 07:58:47 - train: epoch 0021, iter [03400, 10009], lr: 0.014517, weight_decay: 0.000100, momentum_teacher: 0.996395, loss: 4.0190
2022-10-03 07:59:35 - train: epoch 0021, iter [03500, 10009], lr: 0.014516, weight_decay: 0.000100, momentum_teacher: 0.996395, loss: 3.8736
2022-10-03 08:00:22 - train: epoch 0021, iter [03600, 10009], lr: 0.014515, weight_decay: 0.000100, momentum_teacher: 0.996395, loss: 3.7724
2022-10-03 08:01:10 - train: epoch 0021, iter [03700, 10009], lr: 0.014514, weight_decay: 0.000100, momentum_teacher: 0.996396, loss: 3.8161
2022-10-03 08:01:57 - train: epoch 0021, iter [03800, 10009], lr: 0.014513, weight_decay: 0.000100, momentum_teacher: 0.996396, loss: 3.8027
2022-10-03 08:02:45 - train: epoch 0021, iter [03900, 10009], lr: 0.014512, weight_decay: 0.000100, momentum_teacher: 0.996396, loss: 3.9129
2022-10-03 08:03:33 - train: epoch 0021, iter [04000, 10009], lr: 0.014511, weight_decay: 0.000100, momentum_teacher: 0.996397, loss: 4.0501
2022-10-03 08:04:20 - train: epoch 0021, iter [04100, 10009], lr: 0.014510, weight_decay: 0.000100, momentum_teacher: 0.996397, loss: 3.9528
2022-10-03 08:05:08 - train: epoch 0021, iter [04200, 10009], lr: 0.014509, weight_decay: 0.000100, momentum_teacher: 0.996398, loss: 3.6753
2022-10-03 08:05:55 - train: epoch 0021, iter [04300, 10009], lr: 0.014508, weight_decay: 0.000100, momentum_teacher: 0.996398, loss: 3.9227
2022-10-03 08:06:43 - train: epoch 0021, iter [04400, 10009], lr: 0.014508, weight_decay: 0.000100, momentum_teacher: 0.996398, loss: 4.0416
2022-10-03 08:07:30 - train: epoch 0021, iter [04500, 10009], lr: 0.014507, weight_decay: 0.000100, momentum_teacher: 0.996399, loss: 3.8116
2022-10-03 08:08:18 - train: epoch 0021, iter [04600, 10009], lr: 0.014506, weight_decay: 0.000100, momentum_teacher: 0.996399, loss: 3.9899
2022-10-03 08:09:05 - train: epoch 0021, iter [04700, 10009], lr: 0.014505, weight_decay: 0.000100, momentum_teacher: 0.996399, loss: 3.8855
2022-10-03 08:09:53 - train: epoch 0021, iter [04800, 10009], lr: 0.014504, weight_decay: 0.000100, momentum_teacher: 0.996400, loss: 3.7963
2022-10-03 08:10:40 - train: epoch 0021, iter [04900, 10009], lr: 0.014503, weight_decay: 0.000100, momentum_teacher: 0.996400, loss: 3.7739
2022-10-03 08:11:28 - train: epoch 0021, iter [05000, 10009], lr: 0.014502, weight_decay: 0.000100, momentum_teacher: 0.996401, loss: 3.8594
2022-10-03 08:12:16 - train: epoch 0021, iter [05100, 10009], lr: 0.014501, weight_decay: 0.000100, momentum_teacher: 0.996401, loss: 3.9790
2022-10-03 08:13:03 - train: epoch 0021, iter [05200, 10009], lr: 0.014500, weight_decay: 0.000100, momentum_teacher: 0.996401, loss: 3.6609
2022-10-03 08:13:51 - train: epoch 0021, iter [05300, 10009], lr: 0.014499, weight_decay: 0.000100, momentum_teacher: 0.996402, loss: 3.7629
2022-10-03 08:14:38 - train: epoch 0021, iter [05400, 10009], lr: 0.014498, weight_decay: 0.000100, momentum_teacher: 0.996402, loss: 3.9875
2022-10-03 08:15:26 - train: epoch 0021, iter [05500, 10009], lr: 0.014497, weight_decay: 0.000100, momentum_teacher: 0.996403, loss: 3.6428
2022-10-03 08:16:13 - train: epoch 0021, iter [05600, 10009], lr: 0.014496, weight_decay: 0.000100, momentum_teacher: 0.996403, loss: 3.9208
2022-10-03 08:17:01 - train: epoch 0021, iter [05700, 10009], lr: 0.014495, weight_decay: 0.000100, momentum_teacher: 0.996403, loss: 3.6151
2022-10-03 08:17:49 - train: epoch 0021, iter [05800, 10009], lr: 0.014494, weight_decay: 0.000100, momentum_teacher: 0.996404, loss: 3.7063
2022-10-03 08:18:36 - train: epoch 0021, iter [05900, 10009], lr: 0.014493, weight_decay: 0.000100, momentum_teacher: 0.996404, loss: 3.8198
2022-10-03 08:19:24 - train: epoch 0021, iter [06000, 10009], lr: 0.014493, weight_decay: 0.000100, momentum_teacher: 0.996404, loss: 3.9034
2022-10-03 08:20:11 - train: epoch 0021, iter [06100, 10009], lr: 0.014492, weight_decay: 0.000100, momentum_teacher: 0.996405, loss: 3.8175
2022-10-03 08:20:59 - train: epoch 0021, iter [06200, 10009], lr: 0.014491, weight_decay: 0.000100, momentum_teacher: 0.996405, loss: 3.8097
2022-10-03 08:21:47 - train: epoch 0021, iter [06300, 10009], lr: 0.014490, weight_decay: 0.000100, momentum_teacher: 0.996406, loss: 3.8365
2022-10-03 08:22:34 - train: epoch 0021, iter [06400, 10009], lr: 0.014489, weight_decay: 0.000100, momentum_teacher: 0.996406, loss: 3.7758
2022-10-03 08:23:22 - train: epoch 0021, iter [06500, 10009], lr: 0.014488, weight_decay: 0.000100, momentum_teacher: 0.996406, loss: 3.9589
2022-10-03 08:24:09 - train: epoch 0021, iter [06600, 10009], lr: 0.014487, weight_decay: 0.000100, momentum_teacher: 0.996407, loss: 3.9317
2022-10-03 08:24:56 - train: epoch 0021, iter [06700, 10009], lr: 0.014486, weight_decay: 0.000100, momentum_teacher: 0.996407, loss: 3.8536
2022-10-03 08:25:44 - train: epoch 0021, iter [06800, 10009], lr: 0.014485, weight_decay: 0.000100, momentum_teacher: 0.996407, loss: 3.9995
2022-10-03 08:26:31 - train: epoch 0021, iter [06900, 10009], lr: 0.014484, weight_decay: 0.000100, momentum_teacher: 0.996408, loss: 3.6832
2022-10-03 08:27:19 - train: epoch 0021, iter [07000, 10009], lr: 0.014483, weight_decay: 0.000100, momentum_teacher: 0.996408, loss: 4.0272
2022-10-03 08:28:06 - train: epoch 0021, iter [07100, 10009], lr: 0.014482, weight_decay: 0.000100, momentum_teacher: 0.996409, loss: 3.9272
2022-10-03 08:28:54 - train: epoch 0021, iter [07200, 10009], lr: 0.014481, weight_decay: 0.000100, momentum_teacher: 0.996409, loss: 3.9337
2022-10-03 08:29:41 - train: epoch 0021, iter [07300, 10009], lr: 0.014480, weight_decay: 0.000100, momentum_teacher: 0.996409, loss: 3.7853
2022-10-03 08:30:29 - train: epoch 0021, iter [07400, 10009], lr: 0.014479, weight_decay: 0.000100, momentum_teacher: 0.996410, loss: 3.7940
2022-10-03 08:31:17 - train: epoch 0021, iter [07500, 10009], lr: 0.014478, weight_decay: 0.000100, momentum_teacher: 0.996410, loss: 3.8851
2022-10-03 08:32:04 - train: epoch 0021, iter [07600, 10009], lr: 0.014477, weight_decay: 0.000100, momentum_teacher: 0.996410, loss: 3.8909
2022-10-03 08:32:52 - train: epoch 0021, iter [07700, 10009], lr: 0.014476, weight_decay: 0.000100, momentum_teacher: 0.996411, loss: 3.6871
2022-10-03 08:33:40 - train: epoch 0021, iter [07800, 10009], lr: 0.014475, weight_decay: 0.000100, momentum_teacher: 0.996411, loss: 3.6369
2022-10-03 08:34:27 - train: epoch 0021, iter [07900, 10009], lr: 0.014474, weight_decay: 0.000100, momentum_teacher: 0.996412, loss: 3.8715
2022-10-03 08:35:15 - train: epoch 0021, iter [08000, 10009], lr: 0.014473, weight_decay: 0.000100, momentum_teacher: 0.996412, loss: 3.8948
2022-10-03 08:36:02 - train: epoch 0021, iter [08100, 10009], lr: 0.014472, weight_decay: 0.000100, momentum_teacher: 0.996412, loss: 3.7898
2022-10-03 08:36:50 - train: epoch 0021, iter [08200, 10009], lr: 0.014472, weight_decay: 0.000100, momentum_teacher: 0.996413, loss: 3.8291
2022-10-03 08:37:37 - train: epoch 0021, iter [08300, 10009], lr: 0.014471, weight_decay: 0.000100, momentum_teacher: 0.996413, loss: 3.8285
2022-10-03 08:38:25 - train: epoch 0021, iter [08400, 10009], lr: 0.014470, weight_decay: 0.000100, momentum_teacher: 0.996414, loss: 4.1505
2022-10-03 08:39:12 - train: epoch 0021, iter [08500, 10009], lr: 0.014469, weight_decay: 0.000100, momentum_teacher: 0.996414, loss: 3.8366
2022-10-03 08:40:00 - train: epoch 0021, iter [08600, 10009], lr: 0.014468, weight_decay: 0.000100, momentum_teacher: 0.996414, loss: 3.9030
2022-10-03 08:40:47 - train: epoch 0021, iter [08700, 10009], lr: 0.014467, weight_decay: 0.000100, momentum_teacher: 0.996415, loss: 4.0550
2022-10-03 08:41:35 - train: epoch 0021, iter [08800, 10009], lr: 0.014466, weight_decay: 0.000100, momentum_teacher: 0.996415, loss: 3.7727
2022-10-03 08:42:22 - train: epoch 0021, iter [08900, 10009], lr: 0.014465, weight_decay: 0.000100, momentum_teacher: 0.996415, loss: 4.0223
2022-10-03 08:43:10 - train: epoch 0021, iter [09000, 10009], lr: 0.014464, weight_decay: 0.000100, momentum_teacher: 0.996416, loss: 3.7519
2022-10-03 08:43:57 - train: epoch 0021, iter [09100, 10009], lr: 0.014463, weight_decay: 0.000100, momentum_teacher: 0.996416, loss: 3.8550
2022-10-03 08:44:45 - train: epoch 0021, iter [09200, 10009], lr: 0.014462, weight_decay: 0.000100, momentum_teacher: 0.996417, loss: 3.9655
2022-10-03 08:45:32 - train: epoch 0021, iter [09300, 10009], lr: 0.014461, weight_decay: 0.000100, momentum_teacher: 0.996417, loss: 3.9249
2022-10-03 08:46:20 - train: epoch 0021, iter [09400, 10009], lr: 0.014460, weight_decay: 0.000100, momentum_teacher: 0.996417, loss: 3.9933
2022-10-03 08:47:07 - train: epoch 0021, iter [09500, 10009], lr: 0.014459, weight_decay: 0.000100, momentum_teacher: 0.996418, loss: 3.8760
2022-10-03 08:47:55 - train: epoch 0021, iter [09600, 10009], lr: 0.014458, weight_decay: 0.000100, momentum_teacher: 0.996418, loss: 3.6950
2022-10-03 08:48:42 - train: epoch 0021, iter [09700, 10009], lr: 0.014457, weight_decay: 0.000100, momentum_teacher: 0.996419, loss: 3.8082
2022-10-03 08:49:30 - train: epoch 0021, iter [09800, 10009], lr: 0.014456, weight_decay: 0.000100, momentum_teacher: 0.996419, loss: 3.9808
2022-10-03 08:50:17 - train: epoch 0021, iter [09900, 10009], lr: 0.014455, weight_decay: 0.000100, momentum_teacher: 0.996419, loss: 3.9713
2022-10-03 08:51:05 - train: epoch 0021, iter [10000, 10009], lr: 0.014454, weight_decay: 0.000100, momentum_teacher: 0.996420, loss: 3.7891
2022-10-03 08:51:11 - train: epoch 021, train_loss: 3.8852
2022-10-03 08:51:12 - until epoch: 021, best_loss: 3.8852
2022-10-03 08:51:12 - epoch 022 lr: 0.014454
2022-10-03 08:52:05 - train: epoch 0022, iter [00100, 10009], lr: 0.014453, weight_decay: 0.000100, momentum_teacher: 0.996420, loss: 3.8394
2022-10-03 08:52:53 - train: epoch 0022, iter [00200, 10009], lr: 0.014452, weight_decay: 0.000100, momentum_teacher: 0.996420, loss: 4.0751
2022-10-03 08:53:40 - train: epoch 0022, iter [00300, 10009], lr: 0.014451, weight_decay: 0.000100, momentum_teacher: 0.996421, loss: 3.9737
2022-10-03 08:54:28 - train: epoch 0022, iter [00400, 10009], lr: 0.014450, weight_decay: 0.000100, momentum_teacher: 0.996421, loss: 3.8516
2022-10-03 08:55:15 - train: epoch 0022, iter [00500, 10009], lr: 0.014449, weight_decay: 0.000100, momentum_teacher: 0.996422, loss: 3.9329
2022-10-03 08:56:03 - train: epoch 0022, iter [00600, 10009], lr: 0.014448, weight_decay: 0.000100, momentum_teacher: 0.996422, loss: 3.6604
2022-10-03 08:56:50 - train: epoch 0022, iter [00700, 10009], lr: 0.014447, weight_decay: 0.000100, momentum_teacher: 0.996422, loss: 3.9488
2022-10-03 08:57:38 - train: epoch 0022, iter [00800, 10009], lr: 0.014446, weight_decay: 0.000100, momentum_teacher: 0.996423, loss: 3.5960
2022-10-03 08:58:25 - train: epoch 0022, iter [00900, 10009], lr: 0.014445, weight_decay: 0.000100, momentum_teacher: 0.996423, loss: 3.8056
2022-10-03 08:59:13 - train: epoch 0022, iter [01000, 10009], lr: 0.014444, weight_decay: 0.000100, momentum_teacher: 0.996424, loss: 3.8857
2022-10-03 09:00:00 - train: epoch 0022, iter [01100, 10009], lr: 0.014443, weight_decay: 0.000100, momentum_teacher: 0.996424, loss: 3.8546
2022-10-03 09:00:47 - train: epoch 0022, iter [01200, 10009], lr: 0.014442, weight_decay: 0.000100, momentum_teacher: 0.996424, loss: 3.8793
2022-10-03 09:01:35 - train: epoch 0022, iter [01300, 10009], lr: 0.014441, weight_decay: 0.000100, momentum_teacher: 0.996425, loss: 3.6725
2022-10-03 09:02:22 - train: epoch 0022, iter [01400, 10009], lr: 0.014440, weight_decay: 0.000100, momentum_teacher: 0.996425, loss: 3.7208
2022-10-03 09:03:10 - train: epoch 0022, iter [01500, 10009], lr: 0.014439, weight_decay: 0.000100, momentum_teacher: 0.996425, loss: 3.8913
2022-10-03 09:03:57 - train: epoch 0022, iter [01600, 10009], lr: 0.014438, weight_decay: 0.000100, momentum_teacher: 0.996426, loss: 3.8612
2022-10-03 09:04:45 - train: epoch 0022, iter [01700, 10009], lr: 0.014437, weight_decay: 0.000100, momentum_teacher: 0.996426, loss: 4.0401
2022-10-03 09:05:32 - train: epoch 0022, iter [01800, 10009], lr: 0.014436, weight_decay: 0.000100, momentum_teacher: 0.996427, loss: 3.8782
2022-10-03 09:06:20 - train: epoch 0022, iter [01900, 10009], lr: 0.014435, weight_decay: 0.000100, momentum_teacher: 0.996427, loss: 3.8037
2022-10-03 09:07:07 - train: epoch 0022, iter [02000, 10009], lr: 0.014434, weight_decay: 0.000100, momentum_teacher: 0.996427, loss: 3.6560
2022-10-03 09:07:55 - train: epoch 0022, iter [02100, 10009], lr: 0.014433, weight_decay: 0.000100, momentum_teacher: 0.996428, loss: 3.7413
2022-10-03 09:08:43 - train: epoch 0022, iter [02200, 10009], lr: 0.014432, weight_decay: 0.000100, momentum_teacher: 0.996428, loss: 3.9019
2022-10-03 09:09:30 - train: epoch 0022, iter [02300, 10009], lr: 0.014431, weight_decay: 0.000100, momentum_teacher: 0.996429, loss: 3.9790
2022-10-03 09:10:18 - train: epoch 0022, iter [02400, 10009], lr: 0.014430, weight_decay: 0.000100, momentum_teacher: 0.996429, loss: 3.8354
2022-10-03 09:11:05 - train: epoch 0022, iter [02500, 10009], lr: 0.014429, weight_decay: 0.000100, momentum_teacher: 0.996429, loss: 3.6182
2022-10-03 09:11:52 - train: epoch 0022, iter [02600, 10009], lr: 0.014428, weight_decay: 0.000100, momentum_teacher: 0.996430, loss: 3.9052
2022-10-03 09:12:40 - train: epoch 0022, iter [02700, 10009], lr: 0.014427, weight_decay: 0.000100, momentum_teacher: 0.996430, loss: 3.8878
2022-10-03 09:13:27 - train: epoch 0022, iter [02800, 10009], lr: 0.014426, weight_decay: 0.000100, momentum_teacher: 0.996431, loss: 4.0387
2022-10-03 09:14:15 - train: epoch 0022, iter [02900, 10009], lr: 0.014425, weight_decay: 0.000100, momentum_teacher: 0.996431, loss: 3.7445
2022-10-03 09:15:02 - train: epoch 0022, iter [03000, 10009], lr: 0.014424, weight_decay: 0.000100, momentum_teacher: 0.996431, loss: 3.9372
2022-10-03 09:15:50 - train: epoch 0022, iter [03100, 10009], lr: 0.014423, weight_decay: 0.000100, momentum_teacher: 0.996432, loss: 3.8369
2022-10-03 09:16:37 - train: epoch 0022, iter [03200, 10009], lr: 0.014422, weight_decay: 0.000100, momentum_teacher: 0.996432, loss: 3.7789
2022-10-03 09:17:24 - train: epoch 0022, iter [03300, 10009], lr: 0.014421, weight_decay: 0.000100, momentum_teacher: 0.996432, loss: 3.8016
2022-10-03 09:18:12 - train: epoch 0022, iter [03400, 10009], lr: 0.014420, weight_decay: 0.000100, momentum_teacher: 0.996433, loss: 3.9503
2022-10-03 09:19:00 - train: epoch 0022, iter [03500, 10009], lr: 0.014419, weight_decay: 0.000100, momentum_teacher: 0.996433, loss: 3.8291
2022-10-03 09:19:47 - train: epoch 0022, iter [03600, 10009], lr: 0.014418, weight_decay: 0.000100, momentum_teacher: 0.996434, loss: 3.9554
2022-10-03 09:20:34 - train: epoch 0022, iter [03700, 10009], lr: 0.014417, weight_decay: 0.000100, momentum_teacher: 0.996434, loss: 3.7325
2022-10-03 09:21:22 - train: epoch 0022, iter [03800, 10009], lr: 0.014416, weight_decay: 0.000100, momentum_teacher: 0.996434, loss: 4.0067
2022-10-03 09:22:09 - train: epoch 0022, iter [03900, 10009], lr: 0.014415, weight_decay: 0.000100, momentum_teacher: 0.996435, loss: 3.4588
2022-10-03 09:22:57 - train: epoch 0022, iter [04000, 10009], lr: 0.014414, weight_decay: 0.000100, momentum_teacher: 0.996435, loss: 3.7582
2022-10-03 09:23:44 - train: epoch 0022, iter [04100, 10009], lr: 0.014413, weight_decay: 0.000100, momentum_teacher: 0.996436, loss: 3.9411
2022-10-03 09:24:32 - train: epoch 0022, iter [04200, 10009], lr: 0.014412, weight_decay: 0.000100, momentum_teacher: 0.996436, loss: 3.6549
2022-10-03 09:25:19 - train: epoch 0022, iter [04300, 10009], lr: 0.014411, weight_decay: 0.000100, momentum_teacher: 0.996436, loss: 3.9062
2022-10-03 09:26:07 - train: epoch 0022, iter [04400, 10009], lr: 0.014410, weight_decay: 0.000100, momentum_teacher: 0.996437, loss: 3.7619
2022-10-03 09:26:55 - train: epoch 0022, iter [04500, 10009], lr: 0.014409, weight_decay: 0.000100, momentum_teacher: 0.996437, loss: 3.6501
2022-10-03 09:27:42 - train: epoch 0022, iter [04600, 10009], lr: 0.014408, weight_decay: 0.000100, momentum_teacher: 0.996438, loss: 3.9435
2022-10-03 09:28:29 - train: epoch 0022, iter [04700, 10009], lr: 0.014407, weight_decay: 0.000100, momentum_teacher: 0.996438, loss: 3.6560
2022-10-03 09:29:17 - train: epoch 0022, iter [04800, 10009], lr: 0.014406, weight_decay: 0.000100, momentum_teacher: 0.996438, loss: 3.8128
2022-10-03 09:30:04 - train: epoch 0022, iter [04900, 10009], lr: 0.014405, weight_decay: 0.000100, momentum_teacher: 0.996439, loss: 3.8468
2022-10-03 09:30:52 - train: epoch 0022, iter [05000, 10009], lr: 0.014404, weight_decay: 0.000100, momentum_teacher: 0.996439, loss: 3.8302
2022-10-03 09:31:39 - train: epoch 0022, iter [05100, 10009], lr: 0.014403, weight_decay: 0.000100, momentum_teacher: 0.996440, loss: 3.8983
2022-10-03 09:32:27 - train: epoch 0022, iter [05200, 10009], lr: 0.014402, weight_decay: 0.000100, momentum_teacher: 0.996440, loss: 3.6457
2022-10-03 09:33:14 - train: epoch 0022, iter [05300, 10009], lr: 0.014401, weight_decay: 0.000100, momentum_teacher: 0.996440, loss: 3.8391
2022-10-03 09:34:02 - train: epoch 0022, iter [05400, 10009], lr: 0.014400, weight_decay: 0.000100, momentum_teacher: 0.996441, loss: 3.9230
2022-10-03 09:34:49 - train: epoch 0022, iter [05500, 10009], lr: 0.014399, weight_decay: 0.000100, momentum_teacher: 0.996441, loss: 3.8243
2022-10-03 09:35:36 - train: epoch 0022, iter [05600, 10009], lr: 0.014398, weight_decay: 0.000100, momentum_teacher: 0.996441, loss: 3.8826
2022-10-03 09:36:24 - train: epoch 0022, iter [05700, 10009], lr: 0.014397, weight_decay: 0.000100, momentum_teacher: 0.996442, loss: 3.8957
2022-10-03 09:37:11 - train: epoch 0022, iter [05800, 10009], lr: 0.014396, weight_decay: 0.000100, momentum_teacher: 0.996442, loss: 3.7617
2022-10-03 09:37:59 - train: epoch 0022, iter [05900, 10009], lr: 0.014395, weight_decay: 0.000100, momentum_teacher: 0.996443, loss: 3.7948
2022-10-03 09:38:46 - train: epoch 0022, iter [06000, 10009], lr: 0.014394, weight_decay: 0.000100, momentum_teacher: 0.996443, loss: 4.0355
2022-10-03 09:39:33 - train: epoch 0022, iter [06100, 10009], lr: 0.014393, weight_decay: 0.000100, momentum_teacher: 0.996443, loss: 3.6313
2022-10-03 09:40:21 - train: epoch 0022, iter [06200, 10009], lr: 0.014392, weight_decay: 0.000100, momentum_teacher: 0.996444, loss: 3.7595
2022-10-03 09:41:08 - train: epoch 0022, iter [06300, 10009], lr: 0.014391, weight_decay: 0.000100, momentum_teacher: 0.996444, loss: 3.6974
2022-10-03 09:41:56 - train: epoch 0022, iter [06400, 10009], lr: 0.014389, weight_decay: 0.000100, momentum_teacher: 0.996445, loss: 3.7148
2022-10-03 09:42:43 - train: epoch 0022, iter [06500, 10009], lr: 0.014388, weight_decay: 0.000100, momentum_teacher: 0.996445, loss: 4.0101
2022-10-03 09:43:31 - train: epoch 0022, iter [06600, 10009], lr: 0.014387, weight_decay: 0.000100, momentum_teacher: 0.996445, loss: 3.7697
2022-10-03 09:44:18 - train: epoch 0022, iter [06700, 10009], lr: 0.014386, weight_decay: 0.000100, momentum_teacher: 0.996446, loss: 3.9414
2022-10-03 09:45:06 - train: epoch 0022, iter [06800, 10009], lr: 0.014385, weight_decay: 0.000100, momentum_teacher: 0.996446, loss: 3.9700
2022-10-03 09:45:53 - train: epoch 0022, iter [06900, 10009], lr: 0.014384, weight_decay: 0.000100, momentum_teacher: 0.996447, loss: 4.0171
2022-10-03 09:46:40 - train: epoch 0022, iter [07000, 10009], lr: 0.014383, weight_decay: 0.000100, momentum_teacher: 0.996447, loss: 3.8443
2022-10-03 09:47:28 - train: epoch 0022, iter [07100, 10009], lr: 0.014382, weight_decay: 0.000100, momentum_teacher: 0.996447, loss: 3.6808
2022-10-03 09:48:15 - train: epoch 0022, iter [07200, 10009], lr: 0.014381, weight_decay: 0.000100, momentum_teacher: 0.996448, loss: 3.7669
2022-10-03 09:49:03 - train: epoch 0022, iter [07300, 10009], lr: 0.014380, weight_decay: 0.000100, momentum_teacher: 0.996448, loss: 3.9023
2022-10-03 09:49:50 - train: epoch 0022, iter [07400, 10009], lr: 0.014379, weight_decay: 0.000100, momentum_teacher: 0.996449, loss: 3.8708
2022-10-03 09:50:38 - train: epoch 0022, iter [07500, 10009], lr: 0.014378, weight_decay: 0.000100, momentum_teacher: 0.996449, loss: 3.6414
2022-10-03 09:51:25 - train: epoch 0022, iter [07600, 10009], lr: 0.014377, weight_decay: 0.000100, momentum_teacher: 0.996449, loss: 3.8662
2022-10-03 09:52:13 - train: epoch 0022, iter [07700, 10009], lr: 0.014376, weight_decay: 0.000100, momentum_teacher: 0.996450, loss: 3.8680
2022-10-03 09:53:00 - train: epoch 0022, iter [07800, 10009], lr: 0.014375, weight_decay: 0.000100, momentum_teacher: 0.996450, loss: 3.9087
2022-10-03 09:53:48 - train: epoch 0022, iter [07900, 10009], lr: 0.014374, weight_decay: 0.000100, momentum_teacher: 0.996451, loss: 3.8556
2022-10-03 09:54:35 - train: epoch 0022, iter [08000, 10009], lr: 0.014373, weight_decay: 0.000100, momentum_teacher: 0.996451, loss: 3.9185
2022-10-03 09:55:23 - train: epoch 0022, iter [08100, 10009], lr: 0.014372, weight_decay: 0.000100, momentum_teacher: 0.996451, loss: 3.7864
2022-10-03 09:56:10 - train: epoch 0022, iter [08200, 10009], lr: 0.014371, weight_decay: 0.000100, momentum_teacher: 0.996452, loss: 4.0036
2022-10-03 09:56:58 - train: epoch 0022, iter [08300, 10009], lr: 0.014370, weight_decay: 0.000100, momentum_teacher: 0.996452, loss: 3.6535
2022-10-03 09:57:46 - train: epoch 0022, iter [08400, 10009], lr: 0.014369, weight_decay: 0.000100, momentum_teacher: 0.996453, loss: 3.9176
2022-10-03 09:58:33 - train: epoch 0022, iter [08500, 10009], lr: 0.014368, weight_decay: 0.000100, momentum_teacher: 0.996453, loss: 3.7689
2022-10-03 09:59:21 - train: epoch 0022, iter [08600, 10009], lr: 0.014367, weight_decay: 0.000100, momentum_teacher: 0.996453, loss: 3.5815
2022-10-03 10:00:08 - train: epoch 0022, iter [08700, 10009], lr: 0.014365, weight_decay: 0.000100, momentum_teacher: 0.996454, loss: 3.8924
2022-10-03 10:00:56 - train: epoch 0022, iter [08800, 10009], lr: 0.014364, weight_decay: 0.000100, momentum_teacher: 0.996454, loss: 4.1012
2022-10-03 10:01:43 - train: epoch 0022, iter [08900, 10009], lr: 0.014363, weight_decay: 0.000100, momentum_teacher: 0.996455, loss: 3.9862
2022-10-03 10:02:31 - train: epoch 0022, iter [09000, 10009], lr: 0.014362, weight_decay: 0.000100, momentum_teacher: 0.996455, loss: 3.9861
2022-10-03 10:03:18 - train: epoch 0022, iter [09100, 10009], lr: 0.014361, weight_decay: 0.000100, momentum_teacher: 0.996455, loss: 3.8650
2022-10-03 10:04:06 - train: epoch 0022, iter [09200, 10009], lr: 0.014360, weight_decay: 0.000100, momentum_teacher: 0.996456, loss: 4.0557
2022-10-03 10:04:53 - train: epoch 0022, iter [09300, 10009], lr: 0.014359, weight_decay: 0.000100, momentum_teacher: 0.996456, loss: 3.7591
2022-10-03 10:05:40 - train: epoch 0022, iter [09400, 10009], lr: 0.014358, weight_decay: 0.000100, momentum_teacher: 0.996457, loss: 3.7941
2022-10-03 10:06:28 - train: epoch 0022, iter [09500, 10009], lr: 0.014357, weight_decay: 0.000100, momentum_teacher: 0.996457, loss: 3.7845
2022-10-03 10:07:16 - train: epoch 0022, iter [09600, 10009], lr: 0.014356, weight_decay: 0.000100, momentum_teacher: 0.996457, loss: 3.5982
2022-10-03 10:08:03 - train: epoch 0022, iter [09700, 10009], lr: 0.014355, weight_decay: 0.000100, momentum_teacher: 0.996458, loss: 3.8439
2022-10-03 10:08:51 - train: epoch 0022, iter [09800, 10009], lr: 0.014354, weight_decay: 0.000100, momentum_teacher: 0.996458, loss: 3.6410
2022-10-03 10:09:38 - train: epoch 0022, iter [09900, 10009], lr: 0.014353, weight_decay: 0.000100, momentum_teacher: 0.996459, loss: 3.7183
2022-10-03 10:10:26 - train: epoch 0022, iter [10000, 10009], lr: 0.014352, weight_decay: 0.000100, momentum_teacher: 0.996459, loss: 3.6993
2022-10-03 10:10:31 - train: epoch 022, train_loss: 3.8317
2022-10-03 10:10:33 - until epoch: 022, best_loss: 3.8317
2022-10-03 10:10:33 - epoch 023 lr: 0.014352
2022-10-03 10:11:26 - train: epoch 0023, iter [00100, 10009], lr: 0.014351, weight_decay: 0.000100, momentum_teacher: 0.996459, loss: 3.6323
2022-10-03 10:12:14 - train: epoch 0023, iter [00200, 10009], lr: 0.014350, weight_decay: 0.000100, momentum_teacher: 0.996460, loss: 3.7679
2022-10-03 10:13:02 - train: epoch 0023, iter [00300, 10009], lr: 0.014348, weight_decay: 0.000100, momentum_teacher: 0.996460, loss: 3.5448
2022-10-03 10:13:49 - train: epoch 0023, iter [00400, 10009], lr: 0.014347, weight_decay: 0.000100, momentum_teacher: 0.996461, loss: 3.5336
2022-10-03 10:14:37 - train: epoch 0023, iter [00500, 10009], lr: 0.014346, weight_decay: 0.000100, momentum_teacher: 0.996461, loss: 3.8896
2022-10-03 10:15:25 - train: epoch 0023, iter [00600, 10009], lr: 0.014345, weight_decay: 0.000100, momentum_teacher: 0.996461, loss: 3.5897
2022-10-03 10:16:12 - train: epoch 0023, iter [00700, 10009], lr: 0.014344, weight_decay: 0.000100, momentum_teacher: 0.996462, loss: 3.6047
2022-10-03 10:17:00 - train: epoch 0023, iter [00800, 10009], lr: 0.014343, weight_decay: 0.000100, momentum_teacher: 0.996462, loss: 3.8002
2022-10-03 10:17:48 - train: epoch 0023, iter [00900, 10009], lr: 0.014342, weight_decay: 0.000100, momentum_teacher: 0.996463, loss: 4.0186
2022-10-03 10:18:35 - train: epoch 0023, iter [01000, 10009], lr: 0.014341, weight_decay: 0.000100, momentum_teacher: 0.996463, loss: 3.7301
2022-10-03 10:19:23 - train: epoch 0023, iter [01100, 10009], lr: 0.014340, weight_decay: 0.000100, momentum_teacher: 0.996463, loss: 3.9512
2022-10-03 10:20:10 - train: epoch 0023, iter [01200, 10009], lr: 0.014339, weight_decay: 0.000100, momentum_teacher: 0.996464, loss: 3.4672
2022-10-03 10:20:58 - train: epoch 0023, iter [01300, 10009], lr: 0.014338, weight_decay: 0.000100, momentum_teacher: 0.996464, loss: 3.7309
2022-10-03 10:21:45 - train: epoch 0023, iter [01400, 10009], lr: 0.014337, weight_decay: 0.000100, momentum_teacher: 0.996465, loss: 3.9703
2022-10-03 10:22:33 - train: epoch 0023, iter [01500, 10009], lr: 0.014336, weight_decay: 0.000100, momentum_teacher: 0.996465, loss: 3.8519
2022-10-03 10:23:20 - train: epoch 0023, iter [01600, 10009], lr: 0.014335, weight_decay: 0.000100, momentum_teacher: 0.996465, loss: 3.7814
2022-10-03 10:24:08 - train: epoch 0023, iter [01700, 10009], lr: 0.014333, weight_decay: 0.000100, momentum_teacher: 0.996466, loss: 3.6784
2022-10-03 10:24:56 - train: epoch 0023, iter [01800, 10009], lr: 0.014332, weight_decay: 0.000100, momentum_teacher: 0.996466, loss: 3.6422
2022-10-03 10:25:44 - train: epoch 0023, iter [01900, 10009], lr: 0.014331, weight_decay: 0.000100, momentum_teacher: 0.996467, loss: 3.8310
2022-10-03 10:26:31 - train: epoch 0023, iter [02000, 10009], lr: 0.014330, weight_decay: 0.000100, momentum_teacher: 0.996467, loss: 3.6807
2022-10-03 10:27:19 - train: epoch 0023, iter [02100, 10009], lr: 0.014329, weight_decay: 0.000100, momentum_teacher: 0.996467, loss: 3.7438
2022-10-03 10:28:06 - train: epoch 0023, iter [02200, 10009], lr: 0.014328, weight_decay: 0.000100, momentum_teacher: 0.996468, loss: 3.8653
2022-10-03 10:28:54 - train: epoch 0023, iter [02300, 10009], lr: 0.014327, weight_decay: 0.000100, momentum_teacher: 0.996468, loss: 3.6865
2022-10-03 10:29:42 - train: epoch 0023, iter [02400, 10009], lr: 0.014326, weight_decay: 0.000100, momentum_teacher: 0.996469, loss: 3.8918
2022-10-03 10:30:29 - train: epoch 0023, iter [02500, 10009], lr: 0.014325, weight_decay: 0.000100, momentum_teacher: 0.996469, loss: 3.7700
2022-10-03 10:31:17 - train: epoch 0023, iter [02600, 10009], lr: 0.014324, weight_decay: 0.000100, momentum_teacher: 0.996469, loss: 3.8005
2022-10-03 10:32:05 - train: epoch 0023, iter [02700, 10009], lr: 0.014323, weight_decay: 0.000100, momentum_teacher: 0.996470, loss: 3.8162
2022-10-03 10:32:52 - train: epoch 0023, iter [02800, 10009], lr: 0.014322, weight_decay: 0.000100, momentum_teacher: 0.996470, loss: 3.8759
2022-10-03 10:33:40 - train: epoch 0023, iter [02900, 10009], lr: 0.014320, weight_decay: 0.000100, momentum_teacher: 0.996471, loss: 4.0030
2022-10-03 10:34:28 - train: epoch 0023, iter [03000, 10009], lr: 0.014319, weight_decay: 0.000100, momentum_teacher: 0.996471, loss: 3.7807
2022-10-03 10:35:15 - train: epoch 0023, iter [03100, 10009], lr: 0.014318, weight_decay: 0.000100, momentum_teacher: 0.996471, loss: 3.6789
2022-10-03 10:36:03 - train: epoch 0023, iter [03200, 10009], lr: 0.014317, weight_decay: 0.000100, momentum_teacher: 0.996472, loss: 3.7268
2022-10-03 10:36:51 - train: epoch 0023, iter [03300, 10009], lr: 0.014316, weight_decay: 0.000100, momentum_teacher: 0.996472, loss: 3.8049
2022-10-03 10:37:38 - train: epoch 0023, iter [03400, 10009], lr: 0.014315, weight_decay: 0.000100, momentum_teacher: 0.996473, loss: 3.7808
2022-10-03 10:38:26 - train: epoch 0023, iter [03500, 10009], lr: 0.014314, weight_decay: 0.000100, momentum_teacher: 0.996473, loss: 3.7091
2022-10-03 10:39:13 - train: epoch 0023, iter [03600, 10009], lr: 0.014313, weight_decay: 0.000100, momentum_teacher: 0.996473, loss: 3.7355
2022-10-03 10:40:01 - train: epoch 0023, iter [03700, 10009], lr: 0.014312, weight_decay: 0.000100, momentum_teacher: 0.996474, loss: 3.7008
2022-10-03 10:40:48 - train: epoch 0023, iter [03800, 10009], lr: 0.014311, weight_decay: 0.000100, momentum_teacher: 0.996474, loss: 3.5997
2022-10-03 10:41:36 - train: epoch 0023, iter [03900, 10009], lr: 0.014310, weight_decay: 0.000100, momentum_teacher: 0.996475, loss: 3.6943
2022-10-03 10:42:23 - train: epoch 0023, iter [04000, 10009], lr: 0.014308, weight_decay: 0.000100, momentum_teacher: 0.996475, loss: 3.6901
2022-10-03 10:43:11 - train: epoch 0023, iter [04100, 10009], lr: 0.014307, weight_decay: 0.000100, momentum_teacher: 0.996476, loss: 3.8790
2022-10-03 10:43:58 - train: epoch 0023, iter [04200, 10009], lr: 0.014306, weight_decay: 0.000100, momentum_teacher: 0.996476, loss: 3.9104
2022-10-03 10:44:46 - train: epoch 0023, iter [04300, 10009], lr: 0.014305, weight_decay: 0.000100, momentum_teacher: 0.996476, loss: 3.9176
2022-10-03 10:45:33 - train: epoch 0023, iter [04400, 10009], lr: 0.014304, weight_decay: 0.000100, momentum_teacher: 0.996477, loss: 3.6791
2022-10-03 10:46:21 - train: epoch 0023, iter [04500, 10009], lr: 0.014303, weight_decay: 0.000100, momentum_teacher: 0.996477, loss: 3.8577
2022-10-03 10:47:08 - train: epoch 0023, iter [04600, 10009], lr: 0.014302, weight_decay: 0.000100, momentum_teacher: 0.996478, loss: 3.7965
2022-10-03 10:47:56 - train: epoch 0023, iter [04700, 10009], lr: 0.014301, weight_decay: 0.000100, momentum_teacher: 0.996478, loss: 3.7585
2022-10-03 10:48:43 - train: epoch 0023, iter [04800, 10009], lr: 0.014300, weight_decay: 0.000100, momentum_teacher: 0.996478, loss: 3.7449
2022-10-03 10:49:31 - train: epoch 0023, iter [04900, 10009], lr: 0.014299, weight_decay: 0.000100, momentum_teacher: 0.996479, loss: 3.5896
2022-10-03 10:50:18 - train: epoch 0023, iter [05000, 10009], lr: 0.014297, weight_decay: 0.000100, momentum_teacher: 0.996479, loss: 3.7573
2022-10-03 10:51:05 - train: epoch 0023, iter [05100, 10009], lr: 0.014296, weight_decay: 0.000100, momentum_teacher: 0.996480, loss: 3.8741
2022-10-03 10:51:53 - train: epoch 0023, iter [05200, 10009], lr: 0.014295, weight_decay: 0.000100, momentum_teacher: 0.996480, loss: 3.6157
2022-10-03 10:52:40 - train: epoch 0023, iter [05300, 10009], lr: 0.014294, weight_decay: 0.000100, momentum_teacher: 0.996480, loss: 3.7591
2022-10-03 10:53:28 - train: epoch 0023, iter [05400, 10009], lr: 0.014293, weight_decay: 0.000100, momentum_teacher: 0.996481, loss: 3.8710
2022-10-03 10:54:15 - train: epoch 0023, iter [05500, 10009], lr: 0.014292, weight_decay: 0.000100, momentum_teacher: 0.996481, loss: 3.5512
2022-10-03 10:55:02 - train: epoch 0023, iter [05600, 10009], lr: 0.014291, weight_decay: 0.000100, momentum_teacher: 0.996482, loss: 3.8428
2022-10-03 10:55:50 - train: epoch 0023, iter [05700, 10009], lr: 0.014290, weight_decay: 0.000100, momentum_teacher: 0.996482, loss: 3.7912
2022-10-03 10:56:37 - train: epoch 0023, iter [05800, 10009], lr: 0.014289, weight_decay: 0.000100, momentum_teacher: 0.996482, loss: 3.9893
2022-10-03 10:57:25 - train: epoch 0023, iter [05900, 10009], lr: 0.014287, weight_decay: 0.000100, momentum_teacher: 0.996483, loss: 3.6582
2022-10-03 10:58:12 - train: epoch 0023, iter [06000, 10009], lr: 0.014286, weight_decay: 0.000100, momentum_teacher: 0.996483, loss: 3.9254
2022-10-03 10:59:00 - train: epoch 0023, iter [06100, 10009], lr: 0.014285, weight_decay: 0.000100, momentum_teacher: 0.996484, loss: 3.7457
2022-10-03 10:59:47 - train: epoch 0023, iter [06200, 10009], lr: 0.014284, weight_decay: 0.000100, momentum_teacher: 0.996484, loss: 3.9297
2022-10-03 11:00:35 - train: epoch 0023, iter [06300, 10009], lr: 0.014283, weight_decay: 0.000100, momentum_teacher: 0.996484, loss: 3.6917
2022-10-03 11:01:22 - train: epoch 0023, iter [06400, 10009], lr: 0.014282, weight_decay: 0.000100, momentum_teacher: 0.996485, loss: 3.8668
2022-10-03 11:02:09 - train: epoch 0023, iter [06500, 10009], lr: 0.014281, weight_decay: 0.000100, momentum_teacher: 0.996485, loss: 3.7878
2022-10-03 11:02:57 - train: epoch 0023, iter [06600, 10009], lr: 0.014280, weight_decay: 0.000100, momentum_teacher: 0.996486, loss: 3.8813
2022-10-03 11:03:44 - train: epoch 0023, iter [06700, 10009], lr: 0.014278, weight_decay: 0.000100, momentum_teacher: 0.996486, loss: 3.7938
2022-10-03 11:04:32 - train: epoch 0023, iter [06800, 10009], lr: 0.014277, weight_decay: 0.000100, momentum_teacher: 0.996487, loss: 4.0136
2022-10-03 11:05:19 - train: epoch 0023, iter [06900, 10009], lr: 0.014276, weight_decay: 0.000100, momentum_teacher: 0.996487, loss: 4.1254
2022-10-03 11:06:06 - train: epoch 0023, iter [07000, 10009], lr: 0.014275, weight_decay: 0.000100, momentum_teacher: 0.996487, loss: 3.8395
2022-10-03 11:06:54 - train: epoch 0023, iter [07100, 10009], lr: 0.014274, weight_decay: 0.000100, momentum_teacher: 0.996488, loss: 3.6912
2022-10-03 11:07:41 - train: epoch 0023, iter [07200, 10009], lr: 0.014273, weight_decay: 0.000100, momentum_teacher: 0.996488, loss: 3.9449
2022-10-03 11:08:29 - train: epoch 0023, iter [07300, 10009], lr: 0.014272, weight_decay: 0.000100, momentum_teacher: 0.996489, loss: 3.6671
2022-10-03 11:09:16 - train: epoch 0023, iter [07400, 10009], lr: 0.014271, weight_decay: 0.000100, momentum_teacher: 0.996489, loss: 3.7676
2022-10-03 11:10:04 - train: epoch 0023, iter [07500, 10009], lr: 0.014270, weight_decay: 0.000100, momentum_teacher: 0.996489, loss: 3.6905
2022-10-03 11:10:51 - train: epoch 0023, iter [07600, 10009], lr: 0.014268, weight_decay: 0.000100, momentum_teacher: 0.996490, loss: 3.7242
2022-10-03 11:11:39 - train: epoch 0023, iter [07700, 10009], lr: 0.014267, weight_decay: 0.000100, momentum_teacher: 0.996490, loss: 3.9039
2022-10-03 11:12:26 - train: epoch 0023, iter [07800, 10009], lr: 0.014266, weight_decay: 0.000100, momentum_teacher: 0.996491, loss: 3.8159
2022-10-03 11:13:14 - train: epoch 0023, iter [07900, 10009], lr: 0.014265, weight_decay: 0.000100, momentum_teacher: 0.996491, loss: 3.6636
2022-10-03 11:14:01 - train: epoch 0023, iter [08000, 10009], lr: 0.014264, weight_decay: 0.000100, momentum_teacher: 0.996491, loss: 3.7024
2022-10-03 11:14:49 - train: epoch 0023, iter [08100, 10009], lr: 0.014263, weight_decay: 0.000100, momentum_teacher: 0.996492, loss: 3.6958
2022-10-03 11:15:36 - train: epoch 0023, iter [08200, 10009], lr: 0.014262, weight_decay: 0.000100, momentum_teacher: 0.996492, loss: 3.9362
2022-10-03 11:16:24 - train: epoch 0023, iter [08300, 10009], lr: 0.014260, weight_decay: 0.000100, momentum_teacher: 0.996493, loss: 4.1250
2022-10-03 11:17:11 - train: epoch 0023, iter [08400, 10009], lr: 0.014259, weight_decay: 0.000100, momentum_teacher: 0.996493, loss: 3.6558
2022-10-03 11:17:59 - train: epoch 0023, iter [08500, 10009], lr: 0.014258, weight_decay: 0.000100, momentum_teacher: 0.996494, loss: 3.6545
2022-10-03 11:18:46 - train: epoch 0023, iter [08600, 10009], lr: 0.014257, weight_decay: 0.000100, momentum_teacher: 0.996494, loss: 3.6672
2022-10-03 11:19:34 - train: epoch 0023, iter [08700, 10009], lr: 0.014256, weight_decay: 0.000100, momentum_teacher: 0.996494, loss: 3.7070
2022-10-03 11:20:23 - train: epoch 0023, iter [08800, 10009], lr: 0.014255, weight_decay: 0.000100, momentum_teacher: 0.996495, loss: 3.7034
2022-10-03 11:21:10 - train: epoch 0023, iter [08900, 10009], lr: 0.014254, weight_decay: 0.000100, momentum_teacher: 0.996495, loss: 3.8543
2022-10-03 11:21:58 - train: epoch 0023, iter [09000, 10009], lr: 0.014253, weight_decay: 0.000100, momentum_teacher: 0.996496, loss: 3.6752
2022-10-03 11:22:46 - train: epoch 0023, iter [09100, 10009], lr: 0.014251, weight_decay: 0.000100, momentum_teacher: 0.996496, loss: 3.9074
2022-10-03 11:23:33 - train: epoch 0023, iter [09200, 10009], lr: 0.014250, weight_decay: 0.000100, momentum_teacher: 0.996496, loss: 3.7430
2022-10-03 11:24:21 - train: epoch 0023, iter [09300, 10009], lr: 0.014249, weight_decay: 0.000100, momentum_teacher: 0.996497, loss: 3.8648
2022-10-03 11:25:09 - train: epoch 0023, iter [09400, 10009], lr: 0.014248, weight_decay: 0.000100, momentum_teacher: 0.996497, loss: 3.9468
2022-10-03 11:25:59 - train: epoch 0023, iter [09500, 10009], lr: 0.014247, weight_decay: 0.000100, momentum_teacher: 0.996498, loss: 3.7909
2022-10-03 11:26:46 - train: epoch 0023, iter [09600, 10009], lr: 0.014246, weight_decay: 0.000100, momentum_teacher: 0.996498, loss: 3.5805
2022-10-03 11:27:34 - train: epoch 0023, iter [09700, 10009], lr: 0.014245, weight_decay: 0.000100, momentum_teacher: 0.996498, loss: 3.8670
2022-10-03 11:28:21 - train: epoch 0023, iter [09800, 10009], lr: 0.014243, weight_decay: 0.000100, momentum_teacher: 0.996499, loss: 3.6280
2022-10-03 11:29:09 - train: epoch 0023, iter [09900, 10009], lr: 0.014242, weight_decay: 0.000100, momentum_teacher: 0.996499, loss: 3.7457
2022-10-03 11:29:56 - train: epoch 0023, iter [10000, 10009], lr: 0.014241, weight_decay: 0.000100, momentum_teacher: 0.996500, loss: 3.8301
2022-10-03 11:30:02 - train: epoch 023, train_loss: 3.7844
2022-10-03 11:30:04 - until epoch: 023, best_loss: 3.7844
2022-10-03 11:30:04 - epoch 024 lr: 0.014241
2022-10-03 11:30:57 - train: epoch 0024, iter [00100, 10009], lr: 0.014240, weight_decay: 0.000100, momentum_teacher: 0.996500, loss: 3.8930
2022-10-03 11:31:44 - train: epoch 0024, iter [00200, 10009], lr: 0.014239, weight_decay: 0.000100, momentum_teacher: 0.996501, loss: 3.7143
2022-10-03 11:32:32 - train: epoch 0024, iter [00300, 10009], lr: 0.014238, weight_decay: 0.000100, momentum_teacher: 0.996501, loss: 3.7929
2022-10-03 11:33:19 - train: epoch 0024, iter [00400, 10009], lr: 0.014236, weight_decay: 0.000100, momentum_teacher: 0.996501, loss: 3.6041
2022-10-03 11:34:07 - train: epoch 0024, iter [00500, 10009], lr: 0.014235, weight_decay: 0.000100, momentum_teacher: 0.996502, loss: 3.9264
2022-10-03 11:34:54 - train: epoch 0024, iter [00600, 10009], lr: 0.014234, weight_decay: 0.000100, momentum_teacher: 0.996502, loss: 3.8630
2022-10-03 11:35:42 - train: epoch 0024, iter [00700, 10009], lr: 0.014233, weight_decay: 0.000100, momentum_teacher: 0.996503, loss: 3.6267
2022-10-03 11:36:30 - train: epoch 0024, iter [00800, 10009], lr: 0.014232, weight_decay: 0.000100, momentum_teacher: 0.996503, loss: 3.8855
2022-10-03 11:37:17 - train: epoch 0024, iter [00900, 10009], lr: 0.014231, weight_decay: 0.000100, momentum_teacher: 0.996504, loss: 3.6412
2022-10-03 11:38:05 - train: epoch 0024, iter [01000, 10009], lr: 0.014229, weight_decay: 0.000100, momentum_teacher: 0.996504, loss: 3.7933
2022-10-03 11:38:52 - train: epoch 0024, iter [01100, 10009], lr: 0.014228, weight_decay: 0.000100, momentum_teacher: 0.996504, loss: 3.6229
2022-10-03 11:39:40 - train: epoch 0024, iter [01200, 10009], lr: 0.014227, weight_decay: 0.000100, momentum_teacher: 0.996505, loss: 3.6528
2022-10-03 11:40:27 - train: epoch 0024, iter [01300, 10009], lr: 0.014226, weight_decay: 0.000100, momentum_teacher: 0.996505, loss: 3.8050
2022-10-03 11:41:15 - train: epoch 0024, iter [01400, 10009], lr: 0.014225, weight_decay: 0.000100, momentum_teacher: 0.996506, loss: 3.7415
2022-10-03 11:42:02 - train: epoch 0024, iter [01500, 10009], lr: 0.014224, weight_decay: 0.000100, momentum_teacher: 0.996506, loss: 3.4789
2022-10-03 11:42:50 - train: epoch 0024, iter [01600, 10009], lr: 0.014223, weight_decay: 0.000100, momentum_teacher: 0.996506, loss: 3.8361
2022-10-03 11:43:37 - train: epoch 0024, iter [01700, 10009], lr: 0.014221, weight_decay: 0.000100, momentum_teacher: 0.996507, loss: 3.8078
2022-10-03 11:44:25 - train: epoch 0024, iter [01800, 10009], lr: 0.014220, weight_decay: 0.000100, momentum_teacher: 0.996507, loss: 3.6203
2022-10-03 11:45:12 - train: epoch 0024, iter [01900, 10009], lr: 0.014219, weight_decay: 0.000100, momentum_teacher: 0.996508, loss: 3.6857
2022-10-03 11:46:00 - train: epoch 0024, iter [02000, 10009], lr: 0.014218, weight_decay: 0.000100, momentum_teacher: 0.996508, loss: 3.8317
2022-10-03 11:46:48 - train: epoch 0024, iter [02100, 10009], lr: 0.014217, weight_decay: 0.000100, momentum_teacher: 0.996509, loss: 3.7320
2022-10-03 11:47:35 - train: epoch 0024, iter [02200, 10009], lr: 0.014216, weight_decay: 0.000100, momentum_teacher: 0.996509, loss: 3.7129
2022-10-03 11:48:23 - train: epoch 0024, iter [02300, 10009], lr: 0.014214, weight_decay: 0.000100, momentum_teacher: 0.996509, loss: 3.5807
2022-10-03 11:49:10 - train: epoch 0024, iter [02400, 10009], lr: 0.014213, weight_decay: 0.000100, momentum_teacher: 0.996510, loss: 3.6681
2022-10-03 11:49:58 - train: epoch 0024, iter [02500, 10009], lr: 0.014212, weight_decay: 0.000100, momentum_teacher: 0.996510, loss: 3.8172
2022-10-03 11:50:46 - train: epoch 0024, iter [02600, 10009], lr: 0.014211, weight_decay: 0.000100, momentum_teacher: 0.996511, loss: 3.5771
2022-10-03 11:51:33 - train: epoch 0024, iter [02700, 10009], lr: 0.014210, weight_decay: 0.000100, momentum_teacher: 0.996511, loss: 3.6347
2022-10-03 11:52:21 - train: epoch 0024, iter [02800, 10009], lr: 0.014209, weight_decay: 0.000100, momentum_teacher: 0.996511, loss: 3.7337
2022-10-03 11:53:09 - train: epoch 0024, iter [02900, 10009], lr: 0.014207, weight_decay: 0.000100, momentum_teacher: 0.996512, loss: 4.0631
2022-10-03 11:53:56 - train: epoch 0024, iter [03000, 10009], lr: 0.014206, weight_decay: 0.000100, momentum_teacher: 0.996512, loss: 3.7950
2022-10-03 11:54:44 - train: epoch 0024, iter [03100, 10009], lr: 0.014205, weight_decay: 0.000100, momentum_teacher: 0.996513, loss: 3.6465
2022-10-03 11:55:31 - train: epoch 0024, iter [03200, 10009], lr: 0.014204, weight_decay: 0.000100, momentum_teacher: 0.996513, loss: 3.6524
2022-10-03 11:56:19 - train: epoch 0024, iter [03300, 10009], lr: 0.014203, weight_decay: 0.000100, momentum_teacher: 0.996514, loss: 3.6789
2022-10-03 11:57:07 - train: epoch 0024, iter [03400, 10009], lr: 0.014202, weight_decay: 0.000100, momentum_teacher: 0.996514, loss: 3.8284
2022-10-03 11:57:55 - train: epoch 0024, iter [03500, 10009], lr: 0.014200, weight_decay: 0.000100, momentum_teacher: 0.996514, loss: 3.6231
2022-10-03 11:58:42 - train: epoch 0024, iter [03600, 10009], lr: 0.014199, weight_decay: 0.000100, momentum_teacher: 0.996515, loss: 3.6457
2022-10-03 11:59:30 - train: epoch 0024, iter [03700, 10009], lr: 0.014198, weight_decay: 0.000100, momentum_teacher: 0.996515, loss: 3.8726
2022-10-03 12:00:18 - train: epoch 0024, iter [03800, 10009], lr: 0.014197, weight_decay: 0.000100, momentum_teacher: 0.996516, loss: 3.5720
2022-10-03 12:01:10 - train: epoch 0024, iter [03900, 10009], lr: 0.014196, weight_decay: 0.000100, momentum_teacher: 0.996516, loss: 3.6291
2022-10-03 12:02:26 - train: epoch 0024, iter [04000, 10009], lr: 0.014194, weight_decay: 0.000100, momentum_teacher: 0.996517, loss: 3.8732
2022-10-03 12:03:27 - train: epoch 0024, iter [04100, 10009], lr: 0.014193, weight_decay: 0.000100, momentum_teacher: 0.996517, loss: 3.7131
2022-10-03 12:04:45 - train: epoch 0024, iter [04200, 10009], lr: 0.014192, weight_decay: 0.000100, momentum_teacher: 0.996517, loss: 3.7928
2022-10-03 12:05:53 - train: epoch 0024, iter [04300, 10009], lr: 0.014191, weight_decay: 0.000100, momentum_teacher: 0.996518, loss: 3.9513
2022-10-03 12:06:41 - train: epoch 0024, iter [04400, 10009], lr: 0.014190, weight_decay: 0.000100, momentum_teacher: 0.996518, loss: 3.9209
2022-10-03 12:07:29 - train: epoch 0024, iter [04500, 10009], lr: 0.014189, weight_decay: 0.000100, momentum_teacher: 0.996519, loss: 3.6530
2022-10-03 12:08:16 - train: epoch 0024, iter [04600, 10009], lr: 0.014187, weight_decay: 0.000100, momentum_teacher: 0.996519, loss: 3.4484
2022-10-03 12:09:04 - train: epoch 0024, iter [04700, 10009], lr: 0.014186, weight_decay: 0.000100, momentum_teacher: 0.996519, loss: 3.8016
2022-10-03 12:09:52 - train: epoch 0024, iter [04800, 10009], lr: 0.014185, weight_decay: 0.000100, momentum_teacher: 0.996520, loss: 3.6185
2022-10-03 12:10:40 - train: epoch 0024, iter [04900, 10009], lr: 0.014184, weight_decay: 0.000100, momentum_teacher: 0.996520, loss: 3.7964
2022-10-03 12:11:28 - train: epoch 0024, iter [05000, 10009], lr: 0.014183, weight_decay: 0.000100, momentum_teacher: 0.996521, loss: 3.6742
2022-10-03 12:12:15 - train: epoch 0024, iter [05100, 10009], lr: 0.014181, weight_decay: 0.000100, momentum_teacher: 0.996521, loss: 3.9225
2022-10-03 12:13:04 - train: epoch 0024, iter [05200, 10009], lr: 0.014180, weight_decay: 0.000100, momentum_teacher: 0.996522, loss: 3.7327
2022-10-03 12:14:24 - train: epoch 0024, iter [05300, 10009], lr: 0.014179, weight_decay: 0.000100, momentum_teacher: 0.996522, loss: 3.7232
2022-10-03 12:15:29 - train: epoch 0024, iter [05400, 10009], lr: 0.014178, weight_decay: 0.000100, momentum_teacher: 0.996522, loss: 3.8805
2022-10-03 12:16:19 - train: epoch 0024, iter [05500, 10009], lr: 0.014177, weight_decay: 0.000100, momentum_teacher: 0.996523, loss: 3.6618
2022-10-03 12:17:08 - train: epoch 0024, iter [05600, 10009], lr: 0.014176, weight_decay: 0.000100, momentum_teacher: 0.996523, loss: 3.8015
2022-10-03 12:18:16 - train: epoch 0024, iter [05700, 10009], lr: 0.014174, weight_decay: 0.000100, momentum_teacher: 0.996524, loss: 3.8228
2022-10-03 12:19:05 - train: epoch 0024, iter [05800, 10009], lr: 0.014173, weight_decay: 0.000100, momentum_teacher: 0.996524, loss: 3.9348
2022-10-03 12:20:07 - train: epoch 0024, iter [05900, 10009], lr: 0.014172, weight_decay: 0.000100, momentum_teacher: 0.996525, loss: 3.6559
2022-10-03 12:20:57 - train: epoch 0024, iter [06000, 10009], lr: 0.014171, weight_decay: 0.000100, momentum_teacher: 0.996525, loss: 3.9964
2022-10-03 12:21:44 - train: epoch 0024, iter [06100, 10009], lr: 0.014170, weight_decay: 0.000100, momentum_teacher: 0.996525, loss: 3.7582
2022-10-03 12:22:32 - train: epoch 0024, iter [06200, 10009], lr: 0.014168, weight_decay: 0.000100, momentum_teacher: 0.996526, loss: 3.7480
2022-10-03 12:23:20 - train: epoch 0024, iter [06300, 10009], lr: 0.014167, weight_decay: 0.000100, momentum_teacher: 0.996526, loss: 3.5731
2022-10-03 12:24:09 - train: epoch 0024, iter [06400, 10009], lr: 0.014166, weight_decay: 0.000100, momentum_teacher: 0.996527, loss: 3.8505
2022-10-03 12:24:56 - train: epoch 0024, iter [06500, 10009], lr: 0.014165, weight_decay: 0.000100, momentum_teacher: 0.996527, loss: 3.9358
2022-10-03 12:25:45 - train: epoch 0024, iter [06600, 10009], lr: 0.014164, weight_decay: 0.000100, momentum_teacher: 0.996527, loss: 3.5767
2022-10-03 12:26:45 - train: epoch 0024, iter [06700, 10009], lr: 0.014162, weight_decay: 0.000100, momentum_teacher: 0.996528, loss: 3.7131
2022-10-03 12:27:52 - train: epoch 0024, iter [06800, 10009], lr: 0.014161, weight_decay: 0.000100, momentum_teacher: 0.996528, loss: 3.7835
2022-10-03 12:28:56 - train: epoch 0024, iter [06900, 10009], lr: 0.014160, weight_decay: 0.000100, momentum_teacher: 0.996529, loss: 3.8151
2022-10-03 12:29:44 - train: epoch 0024, iter [07000, 10009], lr: 0.014159, weight_decay: 0.000100, momentum_teacher: 0.996529, loss: 3.4241
2022-10-03 12:30:38 - train: epoch 0024, iter [07100, 10009], lr: 0.014158, weight_decay: 0.000100, momentum_teacher: 0.996530, loss: 3.5276
2022-10-03 12:31:26 - train: epoch 0024, iter [07200, 10009], lr: 0.014156, weight_decay: 0.000100, momentum_teacher: 0.996530, loss: 3.8884
2022-10-03 12:32:18 - train: epoch 0024, iter [07300, 10009], lr: 0.014155, weight_decay: 0.000100, momentum_teacher: 0.996530, loss: 3.7736
2022-10-03 12:33:06 - train: epoch 0024, iter [07400, 10009], lr: 0.014154, weight_decay: 0.000100, momentum_teacher: 0.996531, loss: 3.8456
2022-10-03 12:33:54 - train: epoch 0024, iter [07500, 10009], lr: 0.014153, weight_decay: 0.000100, momentum_teacher: 0.996531, loss: 3.8248
2022-10-03 12:34:44 - train: epoch 0024, iter [07600, 10009], lr: 0.014152, weight_decay: 0.000100, momentum_teacher: 0.996532, loss: 3.6528
2022-10-03 12:35:31 - train: epoch 0024, iter [07700, 10009], lr: 0.014150, weight_decay: 0.000100, momentum_teacher: 0.996532, loss: 3.2468
2022-10-03 12:36:19 - train: epoch 0024, iter [07800, 10009], lr: 0.014149, weight_decay: 0.000100, momentum_teacher: 0.996533, loss: 3.7300
2022-10-03 12:37:07 - train: epoch 0024, iter [07900, 10009], lr: 0.014148, weight_decay: 0.000100, momentum_teacher: 0.996533, loss: 3.8270
2022-10-03 12:37:55 - train: epoch 0024, iter [08000, 10009], lr: 0.014147, weight_decay: 0.000100, momentum_teacher: 0.996533, loss: 3.8396
2022-10-03 12:38:42 - train: epoch 0024, iter [08100, 10009], lr: 0.014145, weight_decay: 0.000100, momentum_teacher: 0.996534, loss: 3.7842
2022-10-03 12:39:30 - train: epoch 0024, iter [08200, 10009], lr: 0.014144, weight_decay: 0.000100, momentum_teacher: 0.996534, loss: 3.5475
2022-10-03 12:40:18 - train: epoch 0024, iter [08300, 10009], lr: 0.014143, weight_decay: 0.000100, momentum_teacher: 0.996535, loss: 3.7481
2022-10-03 12:41:15 - train: epoch 0024, iter [08400, 10009], lr: 0.014142, weight_decay: 0.000100, momentum_teacher: 0.996535, loss: 3.5400
2022-10-03 12:42:11 - train: epoch 0024, iter [08500, 10009], lr: 0.014141, weight_decay: 0.000100, momentum_teacher: 0.996536, loss: 3.7931
2022-10-03 12:43:04 - train: epoch 0024, iter [08600, 10009], lr: 0.014139, weight_decay: 0.000100, momentum_teacher: 0.996536, loss: 3.7875
2022-10-03 12:43:59 - train: epoch 0024, iter [08700, 10009], lr: 0.014138, weight_decay: 0.000100, momentum_teacher: 0.996536, loss: 3.5950
2022-10-03 12:44:49 - train: epoch 0024, iter [08800, 10009], lr: 0.014137, weight_decay: 0.000100, momentum_teacher: 0.996537, loss: 3.5917
2022-10-03 12:45:37 - train: epoch 0024, iter [08900, 10009], lr: 0.014136, weight_decay: 0.000100, momentum_teacher: 0.996537, loss: 3.6117
2022-10-03 12:46:32 - train: epoch 0024, iter [09000, 10009], lr: 0.014135, weight_decay: 0.000100, momentum_teacher: 0.996538, loss: 3.4881
2022-10-03 12:47:24 - train: epoch 0024, iter [09100, 10009], lr: 0.014133, weight_decay: 0.000100, momentum_teacher: 0.996538, loss: 3.8460
2022-10-03 12:48:18 - train: epoch 0024, iter [09200, 10009], lr: 0.014132, weight_decay: 0.000100, momentum_teacher: 0.996539, loss: 3.8126
2022-10-03 12:49:07 - train: epoch 0024, iter [09300, 10009], lr: 0.014131, weight_decay: 0.000100, momentum_teacher: 0.996539, loss: 3.4185
2022-10-03 12:49:56 - train: epoch 0024, iter [09400, 10009], lr: 0.014130, weight_decay: 0.000100, momentum_teacher: 0.996539, loss: 3.6775
2022-10-03 12:50:44 - train: epoch 0024, iter [09500, 10009], lr: 0.014128, weight_decay: 0.000100, momentum_teacher: 0.996540, loss: 3.5494
2022-10-03 12:51:32 - train: epoch 0024, iter [09600, 10009], lr: 0.014127, weight_decay: 0.000100, momentum_teacher: 0.996540, loss: 3.7481
2022-10-03 12:52:29 - train: epoch 0024, iter [09700, 10009], lr: 0.014126, weight_decay: 0.000100, momentum_teacher: 0.996541, loss: 3.7880
2022-10-03 12:53:29 - train: epoch 0024, iter [09800, 10009], lr: 0.014125, weight_decay: 0.000100, momentum_teacher: 0.996541, loss: 3.5869
2022-10-03 12:54:48 - train: epoch 0024, iter [09900, 10009], lr: 0.014124, weight_decay: 0.000100, momentum_teacher: 0.996542, loss: 3.9489
2022-10-03 12:57:13 - train: epoch 0024, iter [10000, 10009], lr: 0.014122, weight_decay: 0.000100, momentum_teacher: 0.996542, loss: 3.8932
2022-10-03 12:57:18 - train: epoch 024, train_loss: 3.7401
2022-10-03 12:57:20 - until epoch: 024, best_loss: 3.7401
2022-10-03 12:57:20 - epoch 025 lr: 0.014122
2022-10-03 12:58:14 - train: epoch 0025, iter [00100, 10009], lr: 0.014121, weight_decay: 0.000100, momentum_teacher: 0.996542, loss: 3.5523
2022-10-03 12:59:01 - train: epoch 0025, iter [00200, 10009], lr: 0.014120, weight_decay: 0.000100, momentum_teacher: 0.996543, loss: 3.6944
2022-10-03 12:59:49 - train: epoch 0025, iter [00300, 10009], lr: 0.014118, weight_decay: 0.000100, momentum_teacher: 0.996543, loss: 3.8252
2022-10-03 13:00:37 - train: epoch 0025, iter [00400, 10009], lr: 0.014117, weight_decay: 0.000100, momentum_teacher: 0.996544, loss: 3.6806
2022-10-03 13:01:25 - train: epoch 0025, iter [00500, 10009], lr: 0.014116, weight_decay: 0.000100, momentum_teacher: 0.996544, loss: 3.9618
2022-10-03 13:02:12 - train: epoch 0025, iter [00600, 10009], lr: 0.014115, weight_decay: 0.000100, momentum_teacher: 0.996545, loss: 3.7089
2022-10-03 13:03:00 - train: epoch 0025, iter [00700, 10009], lr: 0.014114, weight_decay: 0.000100, momentum_teacher: 0.996545, loss: 3.9818
2022-10-03 13:03:48 - train: epoch 0025, iter [00800, 10009], lr: 0.014112, weight_decay: 0.000100, momentum_teacher: 0.996546, loss: 3.7176
2022-10-03 13:04:44 - train: epoch 0025, iter [00900, 10009], lr: 0.014111, weight_decay: 0.000100, momentum_teacher: 0.996546, loss: 3.6255
2022-10-03 13:05:32 - train: epoch 0025, iter [01000, 10009], lr: 0.014110, weight_decay: 0.000100, momentum_teacher: 0.996546, loss: 3.5134
2022-10-03 13:06:20 - train: epoch 0025, iter [01100, 10009], lr: 0.014109, weight_decay: 0.000100, momentum_teacher: 0.996547, loss: 3.4269
2022-10-03 13:07:09 - train: epoch 0025, iter [01200, 10009], lr: 0.014107, weight_decay: 0.000100, momentum_teacher: 0.996547, loss: 3.6928
2022-10-03 13:07:57 - train: epoch 0025, iter [01300, 10009], lr: 0.014106, weight_decay: 0.000100, momentum_teacher: 0.996548, loss: 3.8042
2022-10-03 13:08:51 - train: epoch 0025, iter [01400, 10009], lr: 0.014105, weight_decay: 0.000100, momentum_teacher: 0.996548, loss: 4.0416
2022-10-03 13:09:39 - train: epoch 0025, iter [01500, 10009], lr: 0.014104, weight_decay: 0.000100, momentum_teacher: 0.996549, loss: 3.6794
2022-10-03 13:10:31 - train: epoch 0025, iter [01600, 10009], lr: 0.014102, weight_decay: 0.000100, momentum_teacher: 0.996549, loss: 3.6509
2022-10-03 13:11:29 - train: epoch 0025, iter [01700, 10009], lr: 0.014101, weight_decay: 0.000100, momentum_teacher: 0.996549, loss: 3.6406
2022-10-03 13:12:29 - train: epoch 0025, iter [01800, 10009], lr: 0.014100, weight_decay: 0.000100, momentum_teacher: 0.996550, loss: 3.6188
2022-10-03 13:13:25 - train: epoch 0025, iter [01900, 10009], lr: 0.014099, weight_decay: 0.000100, momentum_teacher: 0.996550, loss: 3.7057
2022-10-03 13:14:16 - train: epoch 0025, iter [02000, 10009], lr: 0.014097, weight_decay: 0.000100, momentum_teacher: 0.996551, loss: 3.4701
2022-10-03 13:15:07 - train: epoch 0025, iter [02100, 10009], lr: 0.014096, weight_decay: 0.000100, momentum_teacher: 0.996551, loss: 3.7868
2022-10-03 13:15:58 - train: epoch 0025, iter [02200, 10009], lr: 0.014095, weight_decay: 0.000100, momentum_teacher: 0.996552, loss: 3.7126
2022-10-03 13:16:47 - train: epoch 0025, iter [02300, 10009], lr: 0.014094, weight_decay: 0.000100, momentum_teacher: 0.996552, loss: 3.4922
2022-10-03 13:17:35 - train: epoch 0025, iter [02400, 10009], lr: 0.014092, weight_decay: 0.000100, momentum_teacher: 0.996552, loss: 3.6892
2022-10-03 13:18:23 - train: epoch 0025, iter [02500, 10009], lr: 0.014091, weight_decay: 0.000100, momentum_teacher: 0.996553, loss: 3.5824
2022-10-03 13:19:11 - train: epoch 0025, iter [02600, 10009], lr: 0.014090, weight_decay: 0.000100, momentum_teacher: 0.996553, loss: 3.8189
2022-10-03 13:19:59 - train: epoch 0025, iter [02700, 10009], lr: 0.014089, weight_decay: 0.000100, momentum_teacher: 0.996554, loss: 3.7912
2022-10-03 13:20:48 - train: epoch 0025, iter [02800, 10009], lr: 0.014087, weight_decay: 0.000100, momentum_teacher: 0.996554, loss: 3.7172
2022-10-03 13:21:41 - train: epoch 0025, iter [02900, 10009], lr: 0.014086, weight_decay: 0.000100, momentum_teacher: 0.996555, loss: 3.8448
2022-10-03 13:22:37 - train: epoch 0025, iter [03000, 10009], lr: 0.014085, weight_decay: 0.000100, momentum_teacher: 0.996555, loss: 3.6492
2022-10-03 13:23:40 - train: epoch 0025, iter [03100, 10009], lr: 0.014084, weight_decay: 0.000100, momentum_teacher: 0.996555, loss: 3.6190
2022-10-03 13:24:31 - train: epoch 0025, iter [03200, 10009], lr: 0.014082, weight_decay: 0.000100, momentum_teacher: 0.996556, loss: 3.7614
2022-10-03 13:25:20 - train: epoch 0025, iter [03300, 10009], lr: 0.014081, weight_decay: 0.000100, momentum_teacher: 0.996556, loss: 3.7884
2022-10-03 13:26:09 - train: epoch 0025, iter [03400, 10009], lr: 0.014080, weight_decay: 0.000100, momentum_teacher: 0.996557, loss: 3.6135
2022-10-03 13:26:57 - train: epoch 0025, iter [03500, 10009], lr: 0.014079, weight_decay: 0.000100, momentum_teacher: 0.996557, loss: 3.7849
2022-10-03 13:27:50 - train: epoch 0025, iter [03600, 10009], lr: 0.014077, weight_decay: 0.000100, momentum_teacher: 0.996558, loss: 3.6020
2022-10-03 13:28:46 - train: epoch 0025, iter [03700, 10009], lr: 0.014076, weight_decay: 0.000100, momentum_teacher: 0.996558, loss: 3.5633
2022-10-03 13:29:34 - train: epoch 0025, iter [03800, 10009], lr: 0.014075, weight_decay: 0.000100, momentum_teacher: 0.996558, loss: 3.6388
2022-10-03 13:30:28 - train: epoch 0025, iter [03900, 10009], lr: 0.014074, weight_decay: 0.000100, momentum_teacher: 0.996559, loss: 3.7188
2022-10-03 13:31:25 - train: epoch 0025, iter [04000, 10009], lr: 0.014072, weight_decay: 0.000100, momentum_teacher: 0.996559, loss: 3.7891
2022-10-03 13:32:24 - train: epoch 0025, iter [04100, 10009], lr: 0.014071, weight_decay: 0.000100, momentum_teacher: 0.996560, loss: 3.4311
2022-10-03 13:33:29 - train: epoch 0025, iter [04200, 10009], lr: 0.014070, weight_decay: 0.000100, momentum_teacher: 0.996560, loss: 3.8543
2022-10-03 13:34:43 - train: epoch 0025, iter [04300, 10009], lr: 0.014069, weight_decay: 0.000100, momentum_teacher: 0.996561, loss: 3.6649
2022-10-03 13:35:54 - train: epoch 0025, iter [04400, 10009], lr: 0.014067, weight_decay: 0.000100, momentum_teacher: 0.996561, loss: 3.5954
2022-10-03 13:37:04 - train: epoch 0025, iter [04500, 10009], lr: 0.014066, weight_decay: 0.000100, momentum_teacher: 0.996562, loss: 3.6240
2022-10-03 13:38:45 - train: epoch 0025, iter [04600, 10009], lr: 0.014065, weight_decay: 0.000100, momentum_teacher: 0.996562, loss: 3.6445
2022-10-03 13:40:07 - train: epoch 0025, iter [04700, 10009], lr: 0.014064, weight_decay: 0.000100, momentum_teacher: 0.996562, loss: 3.8394
2022-10-03 13:42:07 - train: epoch 0025, iter [04800, 10009], lr: 0.014062, weight_decay: 0.000100, momentum_teacher: 0.996563, loss: 3.6588
2022-10-03 13:43:34 - train: epoch 0025, iter [04900, 10009], lr: 0.014061, weight_decay: 0.000100, momentum_teacher: 0.996563, loss: 3.7024
2022-10-03 13:45:08 - train: epoch 0025, iter [05000, 10009], lr: 0.014060, weight_decay: 0.000100, momentum_teacher: 0.996564, loss: 3.6597
2022-10-03 13:46:41 - train: epoch 0025, iter [05100, 10009], lr: 0.014058, weight_decay: 0.000100, momentum_teacher: 0.996564, loss: 3.6994
2022-10-03 13:48:37 - train: epoch 0025, iter [05200, 10009], lr: 0.014057, weight_decay: 0.000100, momentum_teacher: 0.996565, loss: 3.5902
2022-10-03 13:51:13 - train: epoch 0025, iter [05300, 10009], lr: 0.014056, weight_decay: 0.000100, momentum_teacher: 0.996565, loss: 3.7723
2022-10-03 13:52:38 - train: epoch 0025, iter [05400, 10009], lr: 0.014055, weight_decay: 0.000100, momentum_teacher: 0.996565, loss: 3.6746
2022-10-03 13:54:33 - train: epoch 0025, iter [05500, 10009], lr: 0.014053, weight_decay: 0.000100, momentum_teacher: 0.996566, loss: 3.6963
2022-10-03 13:55:48 - train: epoch 0025, iter [05600, 10009], lr: 0.014052, weight_decay: 0.000100, momentum_teacher: 0.996566, loss: 3.7488
2022-10-03 13:57:20 - train: epoch 0025, iter [05700, 10009], lr: 0.014051, weight_decay: 0.000100, momentum_teacher: 0.996567, loss: 3.5580
2022-10-03 13:59:09 - train: epoch 0025, iter [05800, 10009], lr: 0.014050, weight_decay: 0.000100, momentum_teacher: 0.996567, loss: 3.5643
2022-10-03 14:01:14 - train: epoch 0025, iter [05900, 10009], lr: 0.014048, weight_decay: 0.000100, momentum_teacher: 0.996568, loss: 3.7522
2022-10-03 14:03:14 - train: epoch 0025, iter [06000, 10009], lr: 0.014047, weight_decay: 0.000100, momentum_teacher: 0.996568, loss: 3.8340
2022-10-03 14:04:46 - train: epoch 0025, iter [06100, 10009], lr: 0.014046, weight_decay: 0.000100, momentum_teacher: 0.996569, loss: 3.5900
2022-10-03 14:07:15 - train: epoch 0025, iter [06200, 10009], lr: 0.014044, weight_decay: 0.000100, momentum_teacher: 0.996569, loss: 3.6632
2022-10-03 14:08:56 - train: epoch 0025, iter [06300, 10009], lr: 0.014043, weight_decay: 0.000100, momentum_teacher: 0.996569, loss: 3.5191
2022-10-03 14:10:40 - train: epoch 0025, iter [06400, 10009], lr: 0.014042, weight_decay: 0.000100, momentum_teacher: 0.996570, loss: 3.5226
2022-10-03 14:12:35 - train: epoch 0025, iter [06500, 10009], lr: 0.014041, weight_decay: 0.000100, momentum_teacher: 0.996570, loss: 3.8211
2022-10-03 14:14:32 - train: epoch 0025, iter [06600, 10009], lr: 0.014039, weight_decay: 0.000100, momentum_teacher: 0.996571, loss: 3.8595
2022-10-03 14:16:44 - train: epoch 0025, iter [06700, 10009], lr: 0.014038, weight_decay: 0.000100, momentum_teacher: 0.996571, loss: 3.6896
2022-10-03 14:18:41 - train: epoch 0025, iter [06800, 10009], lr: 0.014037, weight_decay: 0.000100, momentum_teacher: 0.996572, loss: 3.6113
2022-10-03 14:20:12 - train: epoch 0025, iter [06900, 10009], lr: 0.014036, weight_decay: 0.000100, momentum_teacher: 0.996572, loss: 3.9043
2022-10-03 14:22:25 - train: epoch 0025, iter [07000, 10009], lr: 0.014034, weight_decay: 0.000100, momentum_teacher: 0.996572, loss: 3.6683
2022-10-03 14:23:59 - train: epoch 0025, iter [07100, 10009], lr: 0.014033, weight_decay: 0.000100, momentum_teacher: 0.996573, loss: 3.6427
2022-10-03 14:25:32 - train: epoch 0025, iter [07200, 10009], lr: 0.014032, weight_decay: 0.000100, momentum_teacher: 0.996573, loss: 3.6213
2022-10-03 14:27:25 - train: epoch 0025, iter [07300, 10009], lr: 0.014030, weight_decay: 0.000100, momentum_teacher: 0.996574, loss: 3.7375
2022-10-03 14:29:19 - train: epoch 0025, iter [07400, 10009], lr: 0.014029, weight_decay: 0.000100, momentum_teacher: 0.996574, loss: 3.6820
2022-10-03 14:30:26 - train: epoch 0025, iter [07500, 10009], lr: 0.014028, weight_decay: 0.000100, momentum_teacher: 0.996575, loss: 3.7279
2022-10-03 14:31:50 - train: epoch 0025, iter [07600, 10009], lr: 0.014027, weight_decay: 0.000100, momentum_teacher: 0.996575, loss: 3.9696
2022-10-03 14:33:18 - train: epoch 0025, iter [07700, 10009], lr: 0.014025, weight_decay: 0.000100, momentum_teacher: 0.996576, loss: 3.4157
2022-10-03 14:34:40 - train: epoch 0025, iter [07800, 10009], lr: 0.014024, weight_decay: 0.000100, momentum_teacher: 0.996576, loss: 3.8322
2022-10-03 14:36:07 - train: epoch 0025, iter [07900, 10009], lr: 0.014023, weight_decay: 0.000100, momentum_teacher: 0.996576, loss: 3.7363
2022-10-03 14:37:44 - train: epoch 0025, iter [08000, 10009], lr: 0.014021, weight_decay: 0.000100, momentum_teacher: 0.996577, loss: 3.2694
2022-10-03 14:39:05 - train: epoch 0025, iter [08100, 10009], lr: 0.014020, weight_decay: 0.000100, momentum_teacher: 0.996577, loss: 3.5176
2022-10-03 14:40:30 - train: epoch 0025, iter [08200, 10009], lr: 0.014019, weight_decay: 0.000100, momentum_teacher: 0.996578, loss: 3.9315
2022-10-03 14:42:05 - train: epoch 0025, iter [08300, 10009], lr: 0.014017, weight_decay: 0.000100, momentum_teacher: 0.996578, loss: 3.7693
2022-10-03 14:43:36 - train: epoch 0025, iter [08400, 10009], lr: 0.014016, weight_decay: 0.000100, momentum_teacher: 0.996579, loss: 3.6799
2022-10-03 14:45:06 - train: epoch 0025, iter [08500, 10009], lr: 0.014015, weight_decay: 0.000100, momentum_teacher: 0.996579, loss: 3.6818
2022-10-03 14:46:26 - train: epoch 0025, iter [08600, 10009], lr: 0.014014, weight_decay: 0.000100, momentum_teacher: 0.996580, loss: 4.0372
2022-10-03 14:47:57 - train: epoch 0025, iter [08700, 10009], lr: 0.014012, weight_decay: 0.000100, momentum_teacher: 0.996580, loss: 3.6330
2022-10-03 14:50:00 - train: epoch 0025, iter [08800, 10009], lr: 0.014011, weight_decay: 0.000100, momentum_teacher: 0.996580, loss: 3.7793
2022-10-03 14:51:39 - train: epoch 0025, iter [08900, 10009], lr: 0.014010, weight_decay: 0.000100, momentum_teacher: 0.996581, loss: 3.8309
2022-10-03 14:53:18 - train: epoch 0025, iter [09000, 10009], lr: 0.014008, weight_decay: 0.000100, momentum_teacher: 0.996581, loss: 3.5578
2022-10-03 14:54:57 - train: epoch 0025, iter [09100, 10009], lr: 0.014007, weight_decay: 0.000100, momentum_teacher: 0.996582, loss: 3.6170
2022-10-03 14:56:25 - train: epoch 0025, iter [09200, 10009], lr: 0.014006, weight_decay: 0.000100, momentum_teacher: 0.996582, loss: 3.6345
2022-10-03 14:58:25 - train: epoch 0025, iter [09300, 10009], lr: 0.014005, weight_decay: 0.000100, momentum_teacher: 0.996583, loss: 3.6661
2022-10-03 15:00:16 - train: epoch 0025, iter [09400, 10009], lr: 0.014003, weight_decay: 0.000100, momentum_teacher: 0.996583, loss: 3.7962
2022-10-03 15:02:09 - train: epoch 0025, iter [09500, 10009], lr: 0.014002, weight_decay: 0.000100, momentum_teacher: 0.996584, loss: 3.7284
2022-10-03 15:03:53 - train: epoch 0025, iter [09600, 10009], lr: 0.014001, weight_decay: 0.000100, momentum_teacher: 0.996584, loss: 3.5076
2022-10-03 15:06:28 - train: epoch 0025, iter [09700, 10009], lr: 0.013999, weight_decay: 0.000100, momentum_teacher: 0.996584, loss: 3.5010
2022-10-03 15:07:55 - train: epoch 0025, iter [09800, 10009], lr: 0.013998, weight_decay: 0.000100, momentum_teacher: 0.996585, loss: 3.5899
2022-10-03 15:09:22 - train: epoch 0025, iter [09900, 10009], lr: 0.013997, weight_decay: 0.000100, momentum_teacher: 0.996585, loss: 3.6860
2022-10-03 15:10:40 - train: epoch 0025, iter [10000, 10009], lr: 0.013995, weight_decay: 0.000100, momentum_teacher: 0.996586, loss: 3.8384
2022-10-03 15:10:46 - train: epoch 025, train_loss: 3.6980
2022-10-03 15:10:47 - until epoch: 025, best_loss: 3.6980
2022-10-03 15:10:47 - epoch 026 lr: 0.013995
2022-10-03 15:11:41 - train: epoch 0026, iter [00100, 10009], lr: 0.013994, weight_decay: 0.000100, momentum_teacher: 0.996586, loss: 3.6774
2022-10-03 15:12:29 - train: epoch 0026, iter [00200, 10009], lr: 0.013993, weight_decay: 0.000100, momentum_teacher: 0.996587, loss: 3.5925
2022-10-03 15:13:16 - train: epoch 0026, iter [00300, 10009], lr: 0.013991, weight_decay: 0.000100, momentum_teacher: 0.996587, loss: 3.7373
2022-10-03 15:14:05 - train: epoch 0026, iter [00400, 10009], lr: 0.013990, weight_decay: 0.000100, momentum_teacher: 0.996588, loss: 3.7151
2022-10-03 15:14:58 - train: epoch 0026, iter [00500, 10009], lr: 0.013989, weight_decay: 0.000100, momentum_teacher: 0.996588, loss: 3.6430
2022-10-03 15:15:46 - train: epoch 0026, iter [00600, 10009], lr: 0.013987, weight_decay: 0.000100, momentum_teacher: 0.996588, loss: 3.7361
2022-10-03 15:16:34 - train: epoch 0026, iter [00700, 10009], lr: 0.013986, weight_decay: 0.000100, momentum_teacher: 0.996589, loss: 3.7607
2022-10-03 15:17:22 - train: epoch 0026, iter [00800, 10009], lr: 0.013985, weight_decay: 0.000100, momentum_teacher: 0.996589, loss: 3.7789
2022-10-03 15:18:10 - train: epoch 0026, iter [00900, 10009], lr: 0.013983, weight_decay: 0.000100, momentum_teacher: 0.996590, loss: 3.7475
2022-10-03 15:18:59 - train: epoch 0026, iter [01000, 10009], lr: 0.013982, weight_decay: 0.000100, momentum_teacher: 0.996590, loss: 3.5265
2022-10-03 15:19:46 - train: epoch 0026, iter [01100, 10009], lr: 0.013981, weight_decay: 0.000100, momentum_teacher: 0.996591, loss: 3.6951
2022-10-03 15:20:35 - train: epoch 0026, iter [01200, 10009], lr: 0.013980, weight_decay: 0.000100, momentum_teacher: 0.996591, loss: 3.8276
2022-10-03 15:21:22 - train: epoch 0026, iter [01300, 10009], lr: 0.013978, weight_decay: 0.000100, momentum_teacher: 0.996592, loss: 3.6950
2022-10-03 15:22:11 - train: epoch 0026, iter [01400, 10009], lr: 0.013977, weight_decay: 0.000100, momentum_teacher: 0.996592, loss: 3.7259
2022-10-03 15:23:00 - train: epoch 0026, iter [01500, 10009], lr: 0.013976, weight_decay: 0.000100, momentum_teacher: 0.996592, loss: 3.6107
2022-10-03 15:23:48 - train: epoch 0026, iter [01600, 10009], lr: 0.013974, weight_decay: 0.000100, momentum_teacher: 0.996593, loss: 3.5593
2022-10-03 15:24:35 - train: epoch 0026, iter [01700, 10009], lr: 0.013973, weight_decay: 0.000100, momentum_teacher: 0.996593, loss: 3.9458
2022-10-03 15:25:23 - train: epoch 0026, iter [01800, 10009], lr: 0.013972, weight_decay: 0.000100, momentum_teacher: 0.996594, loss: 3.8418
2022-10-03 15:26:11 - train: epoch 0026, iter [01900, 10009], lr: 0.013970, weight_decay: 0.000100, momentum_teacher: 0.996594, loss: 3.6664
2022-10-03 15:27:10 - train: epoch 0026, iter [02000, 10009], lr: 0.013969, weight_decay: 0.000100, momentum_teacher: 0.996595, loss: 3.6970
2022-10-03 15:28:04 - train: epoch 0026, iter [02100, 10009], lr: 0.013968, weight_decay: 0.000100, momentum_teacher: 0.996595, loss: 3.6857
2022-10-03 15:28:52 - train: epoch 0026, iter [02200, 10009], lr: 0.013966, weight_decay: 0.000100, momentum_teacher: 0.996596, loss: 3.7369
2022-10-03 15:29:49 - train: epoch 0026, iter [02300, 10009], lr: 0.013965, weight_decay: 0.000100, momentum_teacher: 0.996596, loss: 3.7683
2022-10-03 15:30:37 - train: epoch 0026, iter [02400, 10009], lr: 0.013964, weight_decay: 0.000100, momentum_teacher: 0.996596, loss: 3.7584
2022-10-03 15:31:36 - train: epoch 0026, iter [02500, 10009], lr: 0.013962, weight_decay: 0.000100, momentum_teacher: 0.996597, loss: 3.6026
2022-10-03 15:32:55 - train: epoch 0026, iter [02600, 10009], lr: 0.013961, weight_decay: 0.000100, momentum_teacher: 0.996597, loss: 3.9107
2022-10-03 15:34:11 - train: epoch 0026, iter [02700, 10009], lr: 0.013960, weight_decay: 0.000100, momentum_teacher: 0.996598, loss: 3.5761
2022-10-03 15:36:14 - train: epoch 0026, iter [02800, 10009], lr: 0.013958, weight_decay: 0.000100, momentum_teacher: 0.996598, loss: 3.7378
2022-10-03 15:37:29 - train: epoch 0026, iter [02900, 10009], lr: 0.013957, weight_decay: 0.000100, momentum_teacher: 0.996599, loss: 3.6327
2022-10-03 15:38:59 - train: epoch 0026, iter [03000, 10009], lr: 0.013956, weight_decay: 0.000100, momentum_teacher: 0.996599, loss: 3.5057
2022-10-03 15:40:45 - train: epoch 0026, iter [03100, 10009], lr: 0.013954, weight_decay: 0.000100, momentum_teacher: 0.996600, loss: 3.7028
2022-10-03 15:41:42 - train: epoch 0026, iter [03200, 10009], lr: 0.013953, weight_decay: 0.000100, momentum_teacher: 0.996600, loss: 3.6123
2022-10-03 15:43:21 - train: epoch 0026, iter [03300, 10009], lr: 0.013952, weight_decay: 0.000100, momentum_teacher: 0.996601, loss: 3.8133
2022-10-03 15:44:25 - train: epoch 0026, iter [03400, 10009], lr: 0.013950, weight_decay: 0.000100, momentum_teacher: 0.996601, loss: 3.6306
2022-10-03 15:46:24 - train: epoch 0026, iter [03500, 10009], lr: 0.013949, weight_decay: 0.000100, momentum_teacher: 0.996601, loss: 3.6310
2022-10-03 15:48:14 - train: epoch 0026, iter [03600, 10009], lr: 0.013948, weight_decay: 0.000100, momentum_teacher: 0.996602, loss: 3.6271
2022-10-03 15:49:45 - train: epoch 0026, iter [03700, 10009], lr: 0.013946, weight_decay: 0.000100, momentum_teacher: 0.996602, loss: 3.3685
2022-10-03 15:50:59 - train: epoch 0026, iter [03800, 10009], lr: 0.013945, weight_decay: 0.000100, momentum_teacher: 0.996603, loss: 3.5783
2022-10-03 15:52:21 - train: epoch 0026, iter [03900, 10009], lr: 0.013944, weight_decay: 0.000100, momentum_teacher: 0.996603, loss: 3.6171
2022-10-03 15:54:19 - train: epoch 0026, iter [04000, 10009], lr: 0.013942, weight_decay: 0.000100, momentum_teacher: 0.996604, loss: 3.6599
2022-10-03 15:56:59 - train: epoch 0026, iter [04100, 10009], lr: 0.013941, weight_decay: 0.000100, momentum_teacher: 0.996604, loss: 3.6005
2022-10-03 15:59:12 - train: epoch 0026, iter [04200, 10009], lr: 0.013940, weight_decay: 0.000100, momentum_teacher: 0.996605, loss: 3.6260
2022-10-03 16:01:55 - train: epoch 0026, iter [04300, 10009], lr: 0.013938, weight_decay: 0.000100, momentum_teacher: 0.996605, loss: 3.5828
2022-10-03 16:03:15 - train: epoch 0026, iter [04400, 10009], lr: 0.013937, weight_decay: 0.000100, momentum_teacher: 0.996605, loss: 3.8557
2022-10-03 16:04:56 - train: epoch 0026, iter [04500, 10009], lr: 0.013936, weight_decay: 0.000100, momentum_teacher: 0.996606, loss: 3.5732
2022-10-03 16:06:33 - train: epoch 0026, iter [04600, 10009], lr: 0.013934, weight_decay: 0.000100, momentum_teacher: 0.996606, loss: 3.7725
2022-10-03 16:08:04 - train: epoch 0026, iter [04700, 10009], lr: 0.013933, weight_decay: 0.000100, momentum_teacher: 0.996607, loss: 3.8515
2022-10-03 16:10:19 - train: epoch 0026, iter [04800, 10009], lr: 0.013932, weight_decay: 0.000100, momentum_teacher: 0.996607, loss: 3.8481
2022-10-03 16:13:20 - train: epoch 0026, iter [04900, 10009], lr: 0.013930, weight_decay: 0.000100, momentum_teacher: 0.996608, loss: 3.6758
2022-10-03 16:19:08 - train: epoch 0026, iter [05000, 10009], lr: 0.013929, weight_decay: 0.000100, momentum_teacher: 0.996608, loss: 3.5004
2022-10-03 16:22:19 - train: epoch 0026, iter [05100, 10009], lr: 0.013928, weight_decay: 0.000100, momentum_teacher: 0.996609, loss: 3.5929
2022-10-03 16:25:38 - train: epoch 0026, iter [05200, 10009], lr: 0.013926, weight_decay: 0.000100, momentum_teacher: 0.996609, loss: 3.8274
2022-10-03 16:27:19 - train: epoch 0026, iter [05300, 10009], lr: 0.013925, weight_decay: 0.000100, momentum_teacher: 0.996610, loss: 3.7351
2022-10-03 16:29:20 - train: epoch 0026, iter [05400, 10009], lr: 0.013923, weight_decay: 0.000100, momentum_teacher: 0.996610, loss: 3.8317
2022-10-03 16:31:51 - train: epoch 0026, iter [05500, 10009], lr: 0.013922, weight_decay: 0.000100, momentum_teacher: 0.996610, loss: 3.5927
2022-10-03 16:34:28 - train: epoch 0026, iter [05600, 10009], lr: 0.013921, weight_decay: 0.000100, momentum_teacher: 0.996611, loss: 3.4486
2022-10-03 16:36:23 - train: epoch 0026, iter [05700, 10009], lr: 0.013919, weight_decay: 0.000100, momentum_teacher: 0.996611, loss: 3.7584
2022-10-03 16:38:34 - train: epoch 0026, iter [05800, 10009], lr: 0.013918, weight_decay: 0.000100, momentum_teacher: 0.996612, loss: 3.6671
2022-10-03 16:42:15 - train: epoch 0026, iter [05900, 10009], lr: 0.013917, weight_decay: 0.000100, momentum_teacher: 0.996612, loss: 3.8487
2022-10-03 16:45:32 - train: epoch 0026, iter [06000, 10009], lr: 0.013915, weight_decay: 0.000100, momentum_teacher: 0.996613, loss: 3.7762
2022-10-03 16:48:51 - train: epoch 0026, iter [06100, 10009], lr: 0.013914, weight_decay: 0.000100, momentum_teacher: 0.996613, loss: 3.9248
2022-10-03 16:52:27 - train: epoch 0026, iter [06200, 10009], lr: 0.013913, weight_decay: 0.000100, momentum_teacher: 0.996614, loss: 3.5820
2022-10-03 16:56:38 - train: epoch 0026, iter [06300, 10009], lr: 0.013911, weight_decay: 0.000100, momentum_teacher: 0.996614, loss: 3.3802
2022-10-03 17:00:48 - train: epoch 0026, iter [06400, 10009], lr: 0.013910, weight_decay: 0.000100, momentum_teacher: 0.996614, loss: 3.7592
2022-10-03 17:05:56 - train: epoch 0026, iter [06500, 10009], lr: 0.013909, weight_decay: 0.000100, momentum_teacher: 0.996615, loss: 3.7426
2022-10-03 17:09:53 - train: epoch 0026, iter [06600, 10009], lr: 0.013907, weight_decay: 0.000100, momentum_teacher: 0.996615, loss: 3.6351
2022-10-03 17:13:22 - train: epoch 0026, iter [06700, 10009], lr: 0.013906, weight_decay: 0.000100, momentum_teacher: 0.996616, loss: 3.6392
2022-10-03 17:17:46 - train: epoch 0026, iter [06800, 10009], lr: 0.013905, weight_decay: 0.000100, momentum_teacher: 0.996616, loss: 3.6565
2022-10-03 17:21:29 - train: epoch 0026, iter [06900, 10009], lr: 0.013903, weight_decay: 0.000100, momentum_teacher: 0.996617, loss: 3.6976
2022-10-03 17:25:11 - train: epoch 0026, iter [07000, 10009], lr: 0.013902, weight_decay: 0.000100, momentum_teacher: 0.996617, loss: 3.4961
2022-10-03 17:29:24 - train: epoch 0026, iter [07100, 10009], lr: 0.013900, weight_decay: 0.000100, momentum_teacher: 0.996618, loss: 3.7331
2022-10-03 17:33:42 - train: epoch 0026, iter [07200, 10009], lr: 0.013899, weight_decay: 0.000100, momentum_teacher: 0.996618, loss: 3.7000
2022-10-03 17:37:07 - train: epoch 0026, iter [07300, 10009], lr: 0.013898, weight_decay: 0.000100, momentum_teacher: 0.996619, loss: 3.6264
2022-10-03 17:39:37 - train: epoch 0026, iter [07400, 10009], lr: 0.013896, weight_decay: 0.000100, momentum_teacher: 0.996619, loss: 3.5779
2022-10-03 17:41:14 - train: epoch 0026, iter [07500, 10009], lr: 0.013895, weight_decay: 0.000100, momentum_teacher: 0.996619, loss: 3.8305
2022-10-03 17:42:48 - train: epoch 0026, iter [07600, 10009], lr: 0.013894, weight_decay: 0.000100, momentum_teacher: 0.996620, loss: 3.7276
2022-10-03 17:44:14 - train: epoch 0026, iter [07700, 10009], lr: 0.013892, weight_decay: 0.000100, momentum_teacher: 0.996620, loss: 3.7865
2022-10-03 17:45:46 - train: epoch 0026, iter [07800, 10009], lr: 0.013891, weight_decay: 0.000100, momentum_teacher: 0.996621, loss: 3.8329
2022-10-03 17:47:08 - train: epoch 0026, iter [07900, 10009], lr: 0.013889, weight_decay: 0.000100, momentum_teacher: 0.996621, loss: 3.5640
2022-10-03 17:48:38 - train: epoch 0026, iter [08000, 10009], lr: 0.013888, weight_decay: 0.000100, momentum_teacher: 0.996622, loss: 3.7208
2022-10-03 17:49:48 - train: epoch 0026, iter [08100, 10009], lr: 0.013887, weight_decay: 0.000100, momentum_teacher: 0.996622, loss: 3.7821
2022-10-03 17:50:53 - train: epoch 0026, iter [08200, 10009], lr: 0.013885, weight_decay: 0.000100, momentum_teacher: 0.996623, loss: 3.7354
2022-10-03 17:51:52 - train: epoch 0026, iter [08300, 10009], lr: 0.013884, weight_decay: 0.000100, momentum_teacher: 0.996623, loss: 3.7571
2022-10-03 17:52:40 - train: epoch 0026, iter [08400, 10009], lr: 0.013883, weight_decay: 0.000100, momentum_teacher: 0.996624, loss: 3.5279
2022-10-03 17:53:33 - train: epoch 0026, iter [08500, 10009], lr: 0.013881, weight_decay: 0.000100, momentum_teacher: 0.996624, loss: 3.7773
2022-10-03 17:54:22 - train: epoch 0026, iter [08600, 10009], lr: 0.013880, weight_decay: 0.000100, momentum_teacher: 0.996624, loss: 3.4315
2022-10-03 17:55:26 - train: epoch 0026, iter [08700, 10009], lr: 0.013879, weight_decay: 0.000100, momentum_teacher: 0.996625, loss: 3.7671
2022-10-03 17:56:29 - train: epoch 0026, iter [08800, 10009], lr: 0.013877, weight_decay: 0.000100, momentum_teacher: 0.996625, loss: 3.5227
2022-10-03 17:57:31 - train: epoch 0026, iter [08900, 10009], lr: 0.013876, weight_decay: 0.000100, momentum_teacher: 0.996626, loss: 3.6780
2022-10-03 17:58:32 - train: epoch 0026, iter [09000, 10009], lr: 0.013874, weight_decay: 0.000100, momentum_teacher: 0.996626, loss: 3.4987
2022-10-03 17:59:36 - train: epoch 0026, iter [09100, 10009], lr: 0.013873, weight_decay: 0.000100, momentum_teacher: 0.996627, loss: 3.6839
2022-10-03 18:00:35 - train: epoch 0026, iter [09200, 10009], lr: 0.013872, weight_decay: 0.000100, momentum_teacher: 0.996627, loss: 3.6576
2022-10-03 18:01:49 - train: epoch 0026, iter [09300, 10009], lr: 0.013870, weight_decay: 0.000100, momentum_teacher: 0.996628, loss: 3.6043
2022-10-03 18:02:53 - train: epoch 0026, iter [09400, 10009], lr: 0.013869, weight_decay: 0.000100, momentum_teacher: 0.996628, loss: 3.7502
2022-10-03 18:03:44 - train: epoch 0026, iter [09500, 10009], lr: 0.013867, weight_decay: 0.000100, momentum_teacher: 0.996629, loss: 3.7617
2022-10-03 18:04:32 - train: epoch 0026, iter [09600, 10009], lr: 0.013866, weight_decay: 0.000100, momentum_teacher: 0.996629, loss: 3.5984
2022-10-03 18:05:21 - train: epoch 0026, iter [09700, 10009], lr: 0.013865, weight_decay: 0.000100, momentum_teacher: 0.996629, loss: 3.4910
2022-10-03 18:06:20 - train: epoch 0026, iter [09800, 10009], lr: 0.013863, weight_decay: 0.000100, momentum_teacher: 0.996630, loss: 4.0201
2022-10-03 18:07:24 - train: epoch 0026, iter [09900, 10009], lr: 0.013862, weight_decay: 0.000100, momentum_teacher: 0.996630, loss: 3.7307
2022-10-03 18:08:34 - train: epoch 0026, iter [10000, 10009], lr: 0.013861, weight_decay: 0.000100, momentum_teacher: 0.996631, loss: 3.7165
2022-10-03 18:08:39 - train: epoch 026, train_loss: 3.6611
2022-10-03 18:08:41 - until epoch: 026, best_loss: 3.6611
2022-10-03 18:08:41 - epoch 027 lr: 0.013860
2022-10-03 18:09:34 - train: epoch 0027, iter [00100, 10009], lr: 0.013859, weight_decay: 0.000100, momentum_teacher: 0.996631, loss: 3.5293
2022-10-03 18:10:22 - train: epoch 0027, iter [00200, 10009], lr: 0.013858, weight_decay: 0.000100, momentum_teacher: 0.996632, loss: 3.6672
2022-10-03 18:11:10 - train: epoch 0027, iter [00300, 10009], lr: 0.013856, weight_decay: 0.000100, momentum_teacher: 0.996632, loss: 3.7484
2022-10-03 18:11:58 - train: epoch 0027, iter [00400, 10009], lr: 0.013855, weight_decay: 0.000100, momentum_teacher: 0.996633, loss: 3.5112
2022-10-03 18:12:46 - train: epoch 0027, iter [00500, 10009], lr: 0.013853, weight_decay: 0.000100, momentum_teacher: 0.996633, loss: 3.3922
2022-10-03 18:13:37 - train: epoch 0027, iter [00600, 10009], lr: 0.013852, weight_decay: 0.000100, momentum_teacher: 0.996634, loss: 3.6980
2022-10-03 18:14:26 - train: epoch 0027, iter [00700, 10009], lr: 0.013851, weight_decay: 0.000100, momentum_teacher: 0.996634, loss: 3.8826
2022-10-03 18:15:18 - train: epoch 0027, iter [00800, 10009], lr: 0.013849, weight_decay: 0.000100, momentum_teacher: 0.996635, loss: 3.3943
2022-10-03 18:16:17 - train: epoch 0027, iter [00900, 10009], lr: 0.013848, weight_decay: 0.000100, momentum_teacher: 0.996635, loss: 3.5933
2022-10-03 18:17:14 - train: epoch 0027, iter [01000, 10009], lr: 0.013847, weight_decay: 0.000100, momentum_teacher: 0.996635, loss: 3.6497
2022-10-03 18:18:27 - train: epoch 0027, iter [01100, 10009], lr: 0.013845, weight_decay: 0.000100, momentum_teacher: 0.996636, loss: 3.6651
2022-10-03 18:19:39 - train: epoch 0027, iter [01200, 10009], lr: 0.013844, weight_decay: 0.000100, momentum_teacher: 0.996636, loss: 3.4087
2022-10-03 18:20:37 - train: epoch 0027, iter [01300, 10009], lr: 0.013842, weight_decay: 0.000100, momentum_teacher: 0.996637, loss: 3.4062
2022-10-03 18:21:36 - train: epoch 0027, iter [01400, 10009], lr: 0.013841, weight_decay: 0.000100, momentum_teacher: 0.996637, loss: 3.1298
2022-10-03 18:22:25 - train: epoch 0027, iter [01500, 10009], lr: 0.013840, weight_decay: 0.000100, momentum_teacher: 0.996638, loss: 3.5870
2022-10-03 18:23:19 - train: epoch 0027, iter [01600, 10009], lr: 0.013838, weight_decay: 0.000100, momentum_teacher: 0.996638, loss: 3.7379
2022-10-03 18:24:19 - train: epoch 0027, iter [01700, 10009], lr: 0.013837, weight_decay: 0.000100, momentum_teacher: 0.996639, loss: 3.4802
2022-10-03 18:25:07 - train: epoch 0027, iter [01800, 10009], lr: 0.013835, weight_decay: 0.000100, momentum_teacher: 0.996639, loss: 3.4934
2022-10-03 18:25:58 - train: epoch 0027, iter [01900, 10009], lr: 0.013834, weight_decay: 0.000100, momentum_teacher: 0.996640, loss: 3.7463
2022-10-03 18:27:01 - train: epoch 0027, iter [02000, 10009], lr: 0.013833, weight_decay: 0.000100, momentum_teacher: 0.996640, loss: 3.5512
2022-10-03 18:28:09 - train: epoch 0027, iter [02100, 10009], lr: 0.013831, weight_decay: 0.000100, momentum_teacher: 0.996641, loss: 3.6824
2022-10-03 18:29:18 - train: epoch 0027, iter [02200, 10009], lr: 0.013830, weight_decay: 0.000100, momentum_teacher: 0.996641, loss: 3.5436
2022-10-03 18:30:23 - train: epoch 0027, iter [02300, 10009], lr: 0.013828, weight_decay: 0.000100, momentum_teacher: 0.996641, loss: 3.7355
2022-10-03 18:31:34 - train: epoch 0027, iter [02400, 10009], lr: 0.013827, weight_decay: 0.000100, momentum_teacher: 0.996642, loss: 3.5102
2022-10-03 18:32:36 - train: epoch 0027, iter [02500, 10009], lr: 0.013826, weight_decay: 0.000100, momentum_teacher: 0.996642, loss: 3.5260
2022-10-03 18:33:49 - train: epoch 0027, iter [02600, 10009], lr: 0.013824, weight_decay: 0.000100, momentum_teacher: 0.996643, loss: 3.7232
2022-10-03 18:34:47 - train: epoch 0027, iter [02700, 10009], lr: 0.013823, weight_decay: 0.000100, momentum_teacher: 0.996643, loss: 3.6637
2022-10-03 18:35:47 - train: epoch 0027, iter [02800, 10009], lr: 0.013821, weight_decay: 0.000100, momentum_teacher: 0.996644, loss: 3.3909
2022-10-03 18:36:53 - train: epoch 0027, iter [02900, 10009], lr: 0.013820, weight_decay: 0.000100, momentum_teacher: 0.996644, loss: 3.7510
2022-10-03 18:38:07 - train: epoch 0027, iter [03000, 10009], lr: 0.013819, weight_decay: 0.000100, momentum_teacher: 0.996645, loss: 3.5829
2022-10-03 18:39:14 - train: epoch 0027, iter [03100, 10009], lr: 0.013817, weight_decay: 0.000100, momentum_teacher: 0.996645, loss: 3.5956
2022-10-03 18:40:34 - train: epoch 0027, iter [03200, 10009], lr: 0.013816, weight_decay: 0.000100, momentum_teacher: 0.996646, loss: 3.7036
2022-10-03 18:41:54 - train: epoch 0027, iter [03300, 10009], lr: 0.013814, weight_decay: 0.000100, momentum_teacher: 0.996646, loss: 3.6935
2022-10-03 18:43:28 - train: epoch 0027, iter [03400, 10009], lr: 0.013813, weight_decay: 0.000100, momentum_teacher: 0.996647, loss: 3.5587
2022-10-03 18:44:56 - train: epoch 0027, iter [03500, 10009], lr: 0.013811, weight_decay: 0.000100, momentum_teacher: 0.996647, loss: 3.4336
2022-10-03 18:46:23 - train: epoch 0027, iter [03600, 10009], lr: 0.013810, weight_decay: 0.000100, momentum_teacher: 0.996647, loss: 3.6259
2022-10-03 18:47:56 - train: epoch 0027, iter [03700, 10009], lr: 0.013809, weight_decay: 0.000100, momentum_teacher: 0.996648, loss: 3.7184
2022-10-03 18:49:35 - train: epoch 0027, iter [03800, 10009], lr: 0.013807, weight_decay: 0.000100, momentum_teacher: 0.996648, loss: 3.6994
2022-10-03 18:51:12 - train: epoch 0027, iter [03900, 10009], lr: 0.013806, weight_decay: 0.000100, momentum_teacher: 0.996649, loss: 3.6318
2022-10-03 18:52:49 - train: epoch 0027, iter [04000, 10009], lr: 0.013804, weight_decay: 0.000100, momentum_teacher: 0.996649, loss: 3.6212
2022-10-03 18:54:57 - train: epoch 0027, iter [04100, 10009], lr: 0.013803, weight_decay: 0.000100, momentum_teacher: 0.996650, loss: 3.6883
2022-10-03 18:56:14 - train: epoch 0027, iter [04200, 10009], lr: 0.013802, weight_decay: 0.000100, momentum_teacher: 0.996650, loss: 3.7726
2022-10-03 18:57:30 - train: epoch 0027, iter [04300, 10009], lr: 0.013800, weight_decay: 0.000100, momentum_teacher: 0.996651, loss: 3.6818
2022-10-03 18:59:06 - train: epoch 0027, iter [04400, 10009], lr: 0.013799, weight_decay: 0.000100, momentum_teacher: 0.996651, loss: 3.7269
2022-10-03 19:00:47 - train: epoch 0027, iter [04500, 10009], lr: 0.013797, weight_decay: 0.000100, momentum_teacher: 0.996652, loss: 3.6330
2022-10-03 19:02:17 - train: epoch 0027, iter [04600, 10009], lr: 0.013796, weight_decay: 0.000100, momentum_teacher: 0.996652, loss: 3.6948
2022-10-03 19:03:48 - train: epoch 0027, iter [04700, 10009], lr: 0.013794, weight_decay: 0.000100, momentum_teacher: 0.996653, loss: 3.5786
2022-10-03 19:05:10 - train: epoch 0027, iter [04800, 10009], lr: 0.013793, weight_decay: 0.000100, momentum_teacher: 0.996653, loss: 3.3726
2022-10-03 19:06:19 - train: epoch 0027, iter [04900, 10009], lr: 0.013792, weight_decay: 0.000100, momentum_teacher: 0.996653, loss: 3.4190
2022-10-03 19:07:31 - train: epoch 0027, iter [05000, 10009], lr: 0.013790, weight_decay: 0.000100, momentum_teacher: 0.996654, loss: 3.7566
2022-10-03 19:08:44 - train: epoch 0027, iter [05100, 10009], lr: 0.013789, weight_decay: 0.000100, momentum_teacher: 0.996654, loss: 3.2389
2022-10-03 19:09:50 - train: epoch 0027, iter [05200, 10009], lr: 0.013787, weight_decay: 0.000100, momentum_teacher: 0.996655, loss: 3.5827
2022-10-03 19:10:41 - train: epoch 0027, iter [05300, 10009], lr: 0.013786, weight_decay: 0.000100, momentum_teacher: 0.996655, loss: 3.5485
2022-10-03 19:11:29 - train: epoch 0027, iter [05400, 10009], lr: 0.013784, weight_decay: 0.000100, momentum_teacher: 0.996656, loss: 3.4806
2022-10-03 19:12:18 - train: epoch 0027, iter [05500, 10009], lr: 0.013783, weight_decay: 0.000100, momentum_teacher: 0.996656, loss: 3.4847
2022-10-03 19:13:07 - train: epoch 0027, iter [05600, 10009], lr: 0.013782, weight_decay: 0.000100, momentum_teacher: 0.996657, loss: 3.5340
2022-10-03 19:13:56 - train: epoch 0027, iter [05700, 10009], lr: 0.013780, weight_decay: 0.000100, momentum_teacher: 0.996657, loss: 3.5635
2022-10-03 19:14:45 - train: epoch 0027, iter [05800, 10009], lr: 0.013779, weight_decay: 0.000100, momentum_teacher: 0.996658, loss: 3.4971
2022-10-03 19:15:39 - train: epoch 0027, iter [05900, 10009], lr: 0.013777, weight_decay: 0.000100, momentum_teacher: 0.996658, loss: 3.6999
2022-10-03 19:16:34 - train: epoch 0027, iter [06000, 10009], lr: 0.013776, weight_decay: 0.000100, momentum_teacher: 0.996659, loss: 3.5185
2022-10-03 19:17:24 - train: epoch 0027, iter [06100, 10009], lr: 0.013774, weight_decay: 0.000100, momentum_teacher: 0.996659, loss: 3.5649
2022-10-03 19:18:32 - train: epoch 0027, iter [06200, 10009], lr: 0.013773, weight_decay: 0.000100, momentum_teacher: 0.996660, loss: 3.2675
2022-10-03 19:19:43 - train: epoch 0027, iter [06300, 10009], lr: 0.013772, weight_decay: 0.000100, momentum_teacher: 0.996660, loss: 3.4988
2022-10-03 19:20:58 - train: epoch 0027, iter [06400, 10009], lr: 0.013770, weight_decay: 0.000100, momentum_teacher: 0.996660, loss: 3.5990
2022-10-03 19:22:04 - train: epoch 0027, iter [06500, 10009], lr: 0.013769, weight_decay: 0.000100, momentum_teacher: 0.996661, loss: 3.7904
2022-10-03 19:23:04 - train: epoch 0027, iter [06600, 10009], lr: 0.013767, weight_decay: 0.000100, momentum_teacher: 0.996661, loss: 3.6602
2022-10-03 19:23:53 - train: epoch 0027, iter [06700, 10009], lr: 0.013766, weight_decay: 0.000100, momentum_teacher: 0.996662, loss: 3.5786
2022-10-03 19:24:49 - train: epoch 0027, iter [06800, 10009], lr: 0.013764, weight_decay: 0.000100, momentum_teacher: 0.996662, loss: 3.6075
2022-10-03 19:25:46 - train: epoch 0027, iter [06900, 10009], lr: 0.013763, weight_decay: 0.000100, momentum_teacher: 0.996663, loss: 3.7928
2022-10-03 19:26:37 - train: epoch 0027, iter [07000, 10009], lr: 0.013762, weight_decay: 0.000100, momentum_teacher: 0.996663, loss: 3.5899
2022-10-03 19:27:29 - train: epoch 0027, iter [07100, 10009], lr: 0.013760, weight_decay: 0.000100, momentum_teacher: 0.996664, loss: 3.8805
2022-10-03 19:28:37 - train: epoch 0027, iter [07200, 10009], lr: 0.013759, weight_decay: 0.000100, momentum_teacher: 0.996664, loss: 3.5765
2022-10-03 19:30:00 - train: epoch 0027, iter [07300, 10009], lr: 0.013757, weight_decay: 0.000100, momentum_teacher: 0.996665, loss: 3.5435
2022-10-03 19:31:16 - train: epoch 0027, iter [07400, 10009], lr: 0.013756, weight_decay: 0.000100, momentum_teacher: 0.996665, loss: 3.6059
2022-10-03 19:32:31 - train: epoch 0027, iter [07500, 10009], lr: 0.013754, weight_decay: 0.000100, momentum_teacher: 0.996666, loss: 3.6196
2022-10-03 19:33:42 - train: epoch 0027, iter [07600, 10009], lr: 0.013753, weight_decay: 0.000100, momentum_teacher: 0.996666, loss: 3.6247
2022-10-03 19:34:49 - train: epoch 0027, iter [07700, 10009], lr: 0.013751, weight_decay: 0.000100, momentum_teacher: 0.996667, loss: 3.3582
2022-10-03 19:36:11 - train: epoch 0027, iter [07800, 10009], lr: 0.013750, weight_decay: 0.000100, momentum_teacher: 0.996667, loss: 3.6787
2022-10-03 19:37:30 - train: epoch 0027, iter [07900, 10009], lr: 0.013749, weight_decay: 0.000100, momentum_teacher: 0.996667, loss: 3.6718
2022-10-03 19:38:51 - train: epoch 0027, iter [08000, 10009], lr: 0.013747, weight_decay: 0.000100, momentum_teacher: 0.996668, loss: 3.5031
2022-10-03 19:40:06 - train: epoch 0027, iter [08100, 10009], lr: 0.013746, weight_decay: 0.000100, momentum_teacher: 0.996668, loss: 3.6985
2022-10-03 19:41:20 - train: epoch 0027, iter [08200, 10009], lr: 0.013744, weight_decay: 0.000100, momentum_teacher: 0.996669, loss: 3.6033
2022-10-03 19:42:39 - train: epoch 0027, iter [08300, 10009], lr: 0.013743, weight_decay: 0.000100, momentum_teacher: 0.996669, loss: 3.6118
2022-10-03 19:44:04 - train: epoch 0027, iter [08400, 10009], lr: 0.013741, weight_decay: 0.000100, momentum_teacher: 0.996670, loss: 3.7676
2022-10-03 19:45:23 - train: epoch 0027, iter [08500, 10009], lr: 0.013740, weight_decay: 0.000100, momentum_teacher: 0.996670, loss: 3.6639
2022-10-03 19:46:40 - train: epoch 0027, iter [08600, 10009], lr: 0.013738, weight_decay: 0.000100, momentum_teacher: 0.996671, loss: 3.5846
2022-10-03 19:47:43 - train: epoch 0027, iter [08700, 10009], lr: 0.013737, weight_decay: 0.000100, momentum_teacher: 0.996671, loss: 3.5861
2022-10-03 19:48:43 - train: epoch 0027, iter [08800, 10009], lr: 0.013735, weight_decay: 0.000100, momentum_teacher: 0.996672, loss: 3.6142
2022-10-03 19:49:43 - train: epoch 0027, iter [08900, 10009], lr: 0.013734, weight_decay: 0.000100, momentum_teacher: 0.996672, loss: 3.6827
2022-10-03 19:50:52 - train: epoch 0027, iter [09000, 10009], lr: 0.013733, weight_decay: 0.000100, momentum_teacher: 0.996673, loss: 3.5252
2022-10-03 19:52:09 - train: epoch 0027, iter [09100, 10009], lr: 0.013731, weight_decay: 0.000100, momentum_teacher: 0.996673, loss: 3.7019
2022-10-03 19:53:13 - train: epoch 0027, iter [09200, 10009], lr: 0.013730, weight_decay: 0.000100, momentum_teacher: 0.996674, loss: 3.4423
2022-10-03 19:54:19 - train: epoch 0027, iter [09300, 10009], lr: 0.013728, weight_decay: 0.000100, momentum_teacher: 0.996674, loss: 3.7106
2022-10-03 19:55:14 - train: epoch 0027, iter [09400, 10009], lr: 0.013727, weight_decay: 0.000100, momentum_teacher: 0.996675, loss: 3.6758
2022-10-03 19:56:03 - train: epoch 0027, iter [09500, 10009], lr: 0.013725, weight_decay: 0.000100, momentum_teacher: 0.996675, loss: 3.6597
2022-10-03 19:56:53 - train: epoch 0027, iter [09600, 10009], lr: 0.013724, weight_decay: 0.000100, momentum_teacher: 0.996675, loss: 3.7770
2022-10-03 19:57:47 - train: epoch 0027, iter [09700, 10009], lr: 0.013722, weight_decay: 0.000100, momentum_teacher: 0.996676, loss: 3.4436
2022-10-03 19:58:53 - train: epoch 0027, iter [09800, 10009], lr: 0.013721, weight_decay: 0.000100, momentum_teacher: 0.996676, loss: 3.4585
2022-10-03 20:00:23 - train: epoch 0027, iter [09900, 10009], lr: 0.013719, weight_decay: 0.000100, momentum_teacher: 0.996677, loss: 3.7266
2022-10-03 20:01:46 - train: epoch 0027, iter [10000, 10009], lr: 0.013718, weight_decay: 0.000100, momentum_teacher: 0.996677, loss: 3.5366
2022-10-03 20:01:57 - train: epoch 027, train_loss: 3.6261
2022-10-03 20:01:59 - until epoch: 027, best_loss: 3.6261
2022-10-03 20:01:59 - epoch 028 lr: 0.013718
2022-10-03 20:02:52 - train: epoch 0028, iter [00100, 10009], lr: 0.013716, weight_decay: 0.000100, momentum_teacher: 0.996678, loss: 3.5969
2022-10-03 20:03:40 - train: epoch 0028, iter [00200, 10009], lr: 0.013715, weight_decay: 0.000100, momentum_teacher: 0.996678, loss: 3.7144
2022-10-03 20:04:28 - train: epoch 0028, iter [00300, 10009], lr: 0.013713, weight_decay: 0.000100, momentum_teacher: 0.996679, loss: 3.5795
2022-10-03 20:05:16 - train: epoch 0028, iter [00400, 10009], lr: 0.013712, weight_decay: 0.000100, momentum_teacher: 0.996679, loss: 3.5796
2022-10-03 20:06:04 - train: epoch 0028, iter [00500, 10009], lr: 0.013711, weight_decay: 0.000100, momentum_teacher: 0.996680, loss: 3.5201
2022-10-03 20:06:51 - train: epoch 0028, iter [00600, 10009], lr: 0.013709, weight_decay: 0.000100, momentum_teacher: 0.996680, loss: 3.5657
2022-10-03 20:07:39 - train: epoch 0028, iter [00700, 10009], lr: 0.013708, weight_decay: 0.000100, momentum_teacher: 0.996681, loss: 3.8364
2022-10-03 20:08:31 - train: epoch 0028, iter [00800, 10009], lr: 0.013706, weight_decay: 0.000100, momentum_teacher: 0.996681, loss: 3.2949
2022-10-03 20:09:20 - train: epoch 0028, iter [00900, 10009], lr: 0.013705, weight_decay: 0.000100, momentum_teacher: 0.996682, loss: 3.5305
2022-10-03 20:10:15 - train: epoch 0028, iter [01000, 10009], lr: 0.013703, weight_decay: 0.000100, momentum_teacher: 0.996682, loss: 3.7171
2022-10-03 20:11:11 - train: epoch 0028, iter [01100, 10009], lr: 0.013702, weight_decay: 0.000100, momentum_teacher: 0.996683, loss: 3.6277
2022-10-03 20:12:06 - train: epoch 0028, iter [01200, 10009], lr: 0.013700, weight_decay: 0.000100, momentum_teacher: 0.996683, loss: 3.5501
2022-10-03 20:13:02 - train: epoch 0028, iter [01300, 10009], lr: 0.013699, weight_decay: 0.000100, momentum_teacher: 0.996684, loss: 3.7504
2022-10-03 20:13:59 - train: epoch 0028, iter [01400, 10009], lr: 0.013697, weight_decay: 0.000100, momentum_teacher: 0.996684, loss: 3.3978
2022-10-03 20:14:47 - train: epoch 0028, iter [01500, 10009], lr: 0.013696, weight_decay: 0.000100, momentum_teacher: 0.996684, loss: 3.7281
2022-10-03 20:15:39 - train: epoch 0028, iter [01600, 10009], lr: 0.013694, weight_decay: 0.000100, momentum_teacher: 0.996685, loss: 3.4048
2022-10-03 20:16:33 - train: epoch 0028, iter [01700, 10009], lr: 0.013693, weight_decay: 0.000100, momentum_teacher: 0.996685, loss: 3.7409
2022-10-03 20:17:31 - train: epoch 0028, iter [01800, 10009], lr: 0.013691, weight_decay: 0.000100, momentum_teacher: 0.996686, loss: 3.5336
2022-10-03 20:18:47 - train: epoch 0028, iter [01900, 10009], lr: 0.013690, weight_decay: 0.000100, momentum_teacher: 0.996686, loss: 3.4290
2022-10-03 20:19:46 - train: epoch 0028, iter [02000, 10009], lr: 0.013688, weight_decay: 0.000100, momentum_teacher: 0.996687, loss: 3.7285
2022-10-03 20:20:57 - train: epoch 0028, iter [02100, 10009], lr: 0.013687, weight_decay: 0.000100, momentum_teacher: 0.996687, loss: 3.6397
2022-10-03 20:22:36 - train: epoch 0028, iter [02200, 10009], lr: 0.013686, weight_decay: 0.000100, momentum_teacher: 0.996688, loss: 3.5946
2022-10-03 20:23:34 - train: epoch 0028, iter [02300, 10009], lr: 0.013684, weight_decay: 0.000100, momentum_teacher: 0.996688, loss: 3.4421
2022-10-03 20:24:46 - train: epoch 0028, iter [02400, 10009], lr: 0.013683, weight_decay: 0.000100, momentum_teacher: 0.996689, loss: 3.5991
2022-10-03 20:26:40 - train: epoch 0028, iter [02500, 10009], lr: 0.013681, weight_decay: 0.000100, momentum_teacher: 0.996689, loss: 3.6170
2022-10-03 20:27:44 - train: epoch 0028, iter [02600, 10009], lr: 0.013680, weight_decay: 0.000100, momentum_teacher: 0.996690, loss: 3.7701
2022-10-03 20:28:41 - train: epoch 0028, iter [02700, 10009], lr: 0.013678, weight_decay: 0.000100, momentum_teacher: 0.996690, loss: 3.5184
2022-10-03 20:29:46 - train: epoch 0028, iter [02800, 10009], lr: 0.013677, weight_decay: 0.000100, momentum_teacher: 0.996691, loss: 3.8542
2022-10-03 20:31:42 - train: epoch 0028, iter [02900, 10009], lr: 0.013675, weight_decay: 0.000100, momentum_teacher: 0.996691, loss: 3.4728
2022-10-03 20:32:58 - train: epoch 0028, iter [03000, 10009], lr: 0.013674, weight_decay: 0.000100, momentum_teacher: 0.996692, loss: 3.3626
2022-10-03 20:34:59 - train: epoch 0028, iter [03100, 10009], lr: 0.013672, weight_decay: 0.000100, momentum_teacher: 0.996692, loss: 3.7449
2022-10-03 20:36:43 - train: epoch 0028, iter [03200, 10009], lr: 0.013671, weight_decay: 0.000100, momentum_teacher: 0.996693, loss: 3.5196
2022-10-03 20:38:01 - train: epoch 0028, iter [03300, 10009], lr: 0.013669, weight_decay: 0.000100, momentum_teacher: 0.996693, loss: 3.5349
2022-10-03 20:39:09 - train: epoch 0028, iter [03400, 10009], lr: 0.013668, weight_decay: 0.000100, momentum_teacher: 0.996693, loss: 3.3938
2022-10-03 20:40:17 - train: epoch 0028, iter [03500, 10009], lr: 0.013666, weight_decay: 0.000100, momentum_teacher: 0.996694, loss: 3.5179
2022-10-03 20:42:15 - train: epoch 0028, iter [03600, 10009], lr: 0.013665, weight_decay: 0.000100, momentum_teacher: 0.996694, loss: 3.4560
2022-10-03 20:44:12 - train: epoch 0028, iter [03700, 10009], lr: 0.013663, weight_decay: 0.000100, momentum_teacher: 0.996695, loss: 3.6353
2022-10-03 20:46:13 - train: epoch 0028, iter [03800, 10009], lr: 0.013662, weight_decay: 0.000100, momentum_teacher: 0.996695, loss: 3.4603
2022-10-03 20:47:45 - train: epoch 0028, iter [03900, 10009], lr: 0.013660, weight_decay: 0.000100, momentum_teacher: 0.996696, loss: 3.2875
2022-10-03 20:49:27 - train: epoch 0028, iter [04000, 10009], lr: 0.013659, weight_decay: 0.000100, momentum_teacher: 0.996696, loss: 3.3312
2022-10-03 20:52:23 - train: epoch 0028, iter [04100, 10009], lr: 0.013657, weight_decay: 0.000100, momentum_teacher: 0.996697, loss: 3.5061
2022-10-03 20:55:27 - train: epoch 0028, iter [04200, 10009], lr: 0.013656, weight_decay: 0.000100, momentum_teacher: 0.996697, loss: 3.4738
2022-10-03 20:58:31 - train: epoch 0028, iter [04300, 10009], lr: 0.013654, weight_decay: 0.000100, momentum_teacher: 0.996698, loss: 3.7763
2022-10-03 21:01:17 - train: epoch 0028, iter [04400, 10009], lr: 0.013653, weight_decay: 0.000100, momentum_teacher: 0.996698, loss: 3.6803
2022-10-03 21:04:17 - train: epoch 0028, iter [04500, 10009], lr: 0.013651, weight_decay: 0.000100, momentum_teacher: 0.996699, loss: 3.5779
2022-10-03 21:06:48 - train: epoch 0028, iter [04600, 10009], lr: 0.013650, weight_decay: 0.000100, momentum_teacher: 0.996699, loss: 3.4581
2022-10-03 21:09:25 - train: epoch 0028, iter [04700, 10009], lr: 0.013648, weight_decay: 0.000100, momentum_teacher: 0.996700, loss: 3.5897
2022-10-03 21:12:06 - train: epoch 0028, iter [04800, 10009], lr: 0.013647, weight_decay: 0.000100, momentum_teacher: 0.996700, loss: 3.8974
2022-10-03 21:14:36 - train: epoch 0028, iter [04900, 10009], lr: 0.013645, weight_decay: 0.000100, momentum_teacher: 0.996701, loss: 3.4714
2022-10-03 21:17:11 - train: epoch 0028, iter [05000, 10009], lr: 0.013644, weight_decay: 0.000100, momentum_teacher: 0.996701, loss: 3.5901
2022-10-03 21:19:29 - train: epoch 0028, iter [05100, 10009], lr: 0.013642, weight_decay: 0.000100, momentum_teacher: 0.996702, loss: 3.5826
2022-10-03 21:21:38 - train: epoch 0028, iter [05200, 10009], lr: 0.013641, weight_decay: 0.000100, momentum_teacher: 0.996702, loss: 3.5250
2022-10-03 21:23:57 - train: epoch 0028, iter [05300, 10009], lr: 0.013639, weight_decay: 0.000100, momentum_teacher: 0.996703, loss: 3.6257
2022-10-03 21:26:08 - train: epoch 0028, iter [05400, 10009], lr: 0.013638, weight_decay: 0.000100, momentum_teacher: 0.996703, loss: 3.2951
2022-10-03 21:28:06 - train: epoch 0028, iter [05500, 10009], lr: 0.013636, weight_decay: 0.000100, momentum_teacher: 0.996703, loss: 3.4807
2022-10-03 21:30:04 - train: epoch 0028, iter [05600, 10009], lr: 0.013635, weight_decay: 0.000100, momentum_teacher: 0.996704, loss: 3.5167
2022-10-03 21:31:55 - train: epoch 0028, iter [05700, 10009], lr: 0.013633, weight_decay: 0.000100, momentum_teacher: 0.996704, loss: 3.6689
2022-10-03 21:33:58 - train: epoch 0028, iter [05800, 10009], lr: 0.013632, weight_decay: 0.000100, momentum_teacher: 0.996705, loss: 3.5920
2022-10-03 21:36:08 - train: epoch 0028, iter [05900, 10009], lr: 0.013630, weight_decay: 0.000100, momentum_teacher: 0.996705, loss: 3.7307
2022-10-03 21:37:58 - train: epoch 0028, iter [06000, 10009], lr: 0.013629, weight_decay: 0.000100, momentum_teacher: 0.996706, loss: 3.4236
2022-10-03 21:39:57 - train: epoch 0028, iter [06100, 10009], lr: 0.013627, weight_decay: 0.000100, momentum_teacher: 0.996706, loss: 3.5726
2022-10-03 21:42:04 - train: epoch 0028, iter [06200, 10009], lr: 0.013626, weight_decay: 0.000100, momentum_teacher: 0.996707, loss: 3.7439
2022-10-03 21:44:02 - train: epoch 0028, iter [06300, 10009], lr: 0.013624, weight_decay: 0.000100, momentum_teacher: 0.996707, loss: 3.6371
2022-10-03 21:46:09 - train: epoch 0028, iter [06400, 10009], lr: 0.013623, weight_decay: 0.000100, momentum_teacher: 0.996708, loss: 3.4264
2022-10-03 21:47:49 - train: epoch 0028, iter [06500, 10009], lr: 0.013621, weight_decay: 0.000100, momentum_teacher: 0.996708, loss: 3.4534
2022-10-03 21:49:35 - train: epoch 0028, iter [06600, 10009], lr: 0.013620, weight_decay: 0.000100, momentum_teacher: 0.996709, loss: 3.7943
2022-10-03 21:51:09 - train: epoch 0028, iter [06700, 10009], lr: 0.013618, weight_decay: 0.000100, momentum_teacher: 0.996709, loss: 3.8990
2022-10-03 21:52:20 - train: epoch 0028, iter [06800, 10009], lr: 0.013617, weight_decay: 0.000100, momentum_teacher: 0.996710, loss: 3.5054
2022-10-03 21:53:25 - train: epoch 0028, iter [06900, 10009], lr: 0.013615, weight_decay: 0.000100, momentum_teacher: 0.996710, loss: 3.5628
2022-10-03 21:54:40 - train: epoch 0028, iter [07000, 10009], lr: 0.013614, weight_decay: 0.000100, momentum_teacher: 0.996711, loss: 3.4787
2022-10-03 21:56:06 - train: epoch 0028, iter [07100, 10009], lr: 0.013612, weight_decay: 0.000100, momentum_teacher: 0.996711, loss: 3.6784
2022-10-03 21:57:22 - train: epoch 0028, iter [07200, 10009], lr: 0.013611, weight_decay: 0.000100, momentum_teacher: 0.996712, loss: 3.6603
2022-10-03 21:58:29 - train: epoch 0028, iter [07300, 10009], lr: 0.013609, weight_decay: 0.000100, momentum_teacher: 0.996712, loss: 3.5275
2022-10-03 21:59:18 - train: epoch 0028, iter [07400, 10009], lr: 0.013608, weight_decay: 0.000100, momentum_teacher: 0.996713, loss: 3.5170
2022-10-03 22:00:06 - train: epoch 0028, iter [07500, 10009], lr: 0.013606, weight_decay: 0.000100, momentum_teacher: 0.996713, loss: 3.6036
2022-10-03 22:01:00 - train: epoch 0028, iter [07600, 10009], lr: 0.013605, weight_decay: 0.000100, momentum_teacher: 0.996714, loss: 3.4094
2022-10-03 22:02:23 - train: epoch 0028, iter [07700, 10009], lr: 0.013603, weight_decay: 0.000100, momentum_teacher: 0.996714, loss: 3.6774
2022-10-03 22:03:26 - train: epoch 0028, iter [07800, 10009], lr: 0.013602, weight_decay: 0.000100, momentum_teacher: 0.996714, loss: 3.4538
2022-10-03 22:04:55 - train: epoch 0028, iter [07900, 10009], lr: 0.013600, weight_decay: 0.000100, momentum_teacher: 0.996715, loss: 3.3500
2022-10-03 22:06:07 - train: epoch 0028, iter [08000, 10009], lr: 0.013598, weight_decay: 0.000100, momentum_teacher: 0.996715, loss: 3.4946
2022-10-03 22:07:25 - train: epoch 0028, iter [08100, 10009], lr: 0.013597, weight_decay: 0.000100, momentum_teacher: 0.996716, loss: 3.6433
2022-10-03 22:08:39 - train: epoch 0028, iter [08200, 10009], lr: 0.013595, weight_decay: 0.000100, momentum_teacher: 0.996716, loss: 3.4701
2022-10-03 22:09:51 - train: epoch 0028, iter [08300, 10009], lr: 0.013594, weight_decay: 0.000100, momentum_teacher: 0.996717, loss: 3.5367
2022-10-03 22:11:03 - train: epoch 0028, iter [08400, 10009], lr: 0.013592, weight_decay: 0.000100, momentum_teacher: 0.996717, loss: 3.3805
2022-10-03 22:12:24 - train: epoch 0028, iter [08500, 10009], lr: 0.013591, weight_decay: 0.000100, momentum_teacher: 0.996718, loss: 3.7420
2022-10-03 22:13:44 - train: epoch 0028, iter [08600, 10009], lr: 0.013589, weight_decay: 0.000100, momentum_teacher: 0.996718, loss: 3.5683
2022-10-03 22:15:04 - train: epoch 0028, iter [08700, 10009], lr: 0.013588, weight_decay: 0.000100, momentum_teacher: 0.996719, loss: 3.4156
2022-10-03 22:16:05 - train: epoch 0028, iter [08800, 10009], lr: 0.013586, weight_decay: 0.000100, momentum_teacher: 0.996719, loss: 3.4551
2022-10-03 22:17:21 - train: epoch 0028, iter [08900, 10009], lr: 0.013585, weight_decay: 0.000100, momentum_teacher: 0.996720, loss: 3.7314
2022-10-03 22:18:37 - train: epoch 0028, iter [09000, 10009], lr: 0.013583, weight_decay: 0.000100, momentum_teacher: 0.996720, loss: 3.9209
2022-10-03 22:20:00 - train: epoch 0028, iter [09100, 10009], lr: 0.013582, weight_decay: 0.000100, momentum_teacher: 0.996721, loss: 3.6465
2022-10-03 22:21:06 - train: epoch 0028, iter [09200, 10009], lr: 0.013580, weight_decay: 0.000100, momentum_teacher: 0.996721, loss: 3.7482
2022-10-03 22:21:57 - train: epoch 0028, iter [09300, 10009], lr: 0.013579, weight_decay: 0.000100, momentum_teacher: 0.996722, loss: 3.5321
2022-10-03 22:22:47 - train: epoch 0028, iter [09400, 10009], lr: 0.013577, weight_decay: 0.000100, momentum_teacher: 0.996722, loss: 3.4617
2022-10-03 22:23:59 - train: epoch 0028, iter [09500, 10009], lr: 0.013576, weight_decay: 0.000100, momentum_teacher: 0.996723, loss: 3.5690
2022-10-03 22:25:14 - train: epoch 0028, iter [09600, 10009], lr: 0.013574, weight_decay: 0.000100, momentum_teacher: 0.996723, loss: 3.3752
2022-10-03 22:26:45 - train: epoch 0028, iter [09700, 10009], lr: 0.013572, weight_decay: 0.000100, momentum_teacher: 0.996724, loss: 3.4054
2022-10-03 22:28:06 - train: epoch 0028, iter [09800, 10009], lr: 0.013571, weight_decay: 0.000100, momentum_teacher: 0.996724, loss: 3.5914
2022-10-03 22:29:08 - train: epoch 0028, iter [09900, 10009], lr: 0.013569, weight_decay: 0.000100, momentum_teacher: 0.996725, loss: 3.4049
2022-10-03 22:30:25 - train: epoch 0028, iter [10000, 10009], lr: 0.013568, weight_decay: 0.000100, momentum_teacher: 0.996725, loss: 3.4503
2022-10-03 22:30:31 - train: epoch 028, train_loss: 3.5897
2022-10-03 22:30:32 - until epoch: 028, best_loss: 3.5897
2022-10-03 22:30:32 - epoch 029 lr: 0.013568
2022-10-03 22:31:26 - train: epoch 0029, iter [00100, 10009], lr: 0.013566, weight_decay: 0.000100, momentum_teacher: 0.996726, loss: 3.3897
2022-10-03 22:32:14 - train: epoch 0029, iter [00200, 10009], lr: 0.013565, weight_decay: 0.000100, momentum_teacher: 0.996726, loss: 3.5058
2022-10-03 22:33:02 - train: epoch 0029, iter [00300, 10009], lr: 0.013563, weight_decay: 0.000100, momentum_teacher: 0.996727, loss: 3.6827
2022-10-03 22:33:50 - train: epoch 0029, iter [00400, 10009], lr: 0.013562, weight_decay: 0.000100, momentum_teacher: 0.996727, loss: 3.7594
2022-10-03 22:34:37 - train: epoch 0029, iter [00500, 10009], lr: 0.013560, weight_decay: 0.000100, momentum_teacher: 0.996728, loss: 3.4122
2022-10-03 22:35:25 - train: epoch 0029, iter [00600, 10009], lr: 0.013558, weight_decay: 0.000100, momentum_teacher: 0.996728, loss: 3.5939
2022-10-03 22:36:13 - train: epoch 0029, iter [00700, 10009], lr: 0.013557, weight_decay: 0.000100, momentum_teacher: 0.996729, loss: 3.7021
2022-10-03 22:37:00 - train: epoch 0029, iter [00800, 10009], lr: 0.013555, weight_decay: 0.000100, momentum_teacher: 0.996729, loss: 3.5332
2022-10-03 22:37:48 - train: epoch 0029, iter [00900, 10009], lr: 0.013554, weight_decay: 0.000100, momentum_teacher: 0.996730, loss: 3.6286
2022-10-03 22:38:36 - train: epoch 0029, iter [01000, 10009], lr: 0.013552, weight_decay: 0.000100, momentum_teacher: 0.996730, loss: 3.6862
2022-10-03 22:39:23 - train: epoch 0029, iter [01100, 10009], lr: 0.013551, weight_decay: 0.000100, momentum_teacher: 0.996730, loss: 3.5286
2022-10-03 22:40:11 - train: epoch 0029, iter [01200, 10009], lr: 0.013549, weight_decay: 0.000100, momentum_teacher: 0.996731, loss: 3.7427
2022-10-03 22:41:08 - train: epoch 0029, iter [01300, 10009], lr: 0.013548, weight_decay: 0.000100, momentum_teacher: 0.996731, loss: 3.6103
2022-10-03 22:42:11 - train: epoch 0029, iter [01400, 10009], lr: 0.013546, weight_decay: 0.000100, momentum_teacher: 0.996732, loss: 3.6531
2022-10-03 22:43:00 - train: epoch 0029, iter [01500, 10009], lr: 0.013545, weight_decay: 0.000100, momentum_teacher: 0.996732, loss: 3.5492
2022-10-03 22:43:56 - train: epoch 0029, iter [01600, 10009], lr: 0.013543, weight_decay: 0.000100, momentum_teacher: 0.996733, loss: 3.7065
2022-10-03 22:46:46 - train: epoch 0029, iter [01700, 10009], lr: 0.013541, weight_decay: 0.000100, momentum_teacher: 0.996733, loss: 3.6714
2022-10-03 22:48:51 - train: epoch 0029, iter [01800, 10009], lr: 0.013540, weight_decay: 0.000100, momentum_teacher: 0.996734, loss: 3.6330
2022-10-03 22:51:32 - train: epoch 0029, iter [01900, 10009], lr: 0.013538, weight_decay: 0.000100, momentum_teacher: 0.996734, loss: 3.4115
2022-10-03 22:54:06 - train: epoch 0029, iter [02000, 10009], lr: 0.013537, weight_decay: 0.000100, momentum_teacher: 0.996735, loss: 3.6684
2022-10-03 22:56:01 - train: epoch 0029, iter [02100, 10009], lr: 0.013535, weight_decay: 0.000100, momentum_teacher: 0.996735, loss: 3.6966
2022-10-03 22:58:27 - train: epoch 0029, iter [02200, 10009], lr: 0.013534, weight_decay: 0.000100, momentum_teacher: 0.996736, loss: 3.6743
2022-10-03 23:01:04 - train: epoch 0029, iter [02300, 10009], lr: 0.013532, weight_decay: 0.000100, momentum_teacher: 0.996736, loss: 3.6127
2022-10-03 23:03:22 - train: epoch 0029, iter [02400, 10009], lr: 0.013531, weight_decay: 0.000100, momentum_teacher: 0.996737, loss: 3.5221
2022-10-03 23:05:59 - train: epoch 0029, iter [02500, 10009], lr: 0.013529, weight_decay: 0.000100, momentum_teacher: 0.996737, loss: 3.5481
2022-10-03 23:07:40 - train: epoch 0029, iter [02600, 10009], lr: 0.013528, weight_decay: 0.000100, momentum_teacher: 0.996738, loss: 3.6086
2022-10-03 23:09:53 - train: epoch 0029, iter [02700, 10009], lr: 0.013526, weight_decay: 0.000100, momentum_teacher: 0.996738, loss: 3.7487
2022-10-03 23:12:09 - train: epoch 0029, iter [02800, 10009], lr: 0.013524, weight_decay: 0.000100, momentum_teacher: 0.996739, loss: 3.6098
2022-10-03 23:13:58 - train: epoch 0029, iter [02900, 10009], lr: 0.013523, weight_decay: 0.000100, momentum_teacher: 0.996739, loss: 3.7372
2022-10-03 23:15:34 - train: epoch 0029, iter [03000, 10009], lr: 0.013521, weight_decay: 0.000100, momentum_teacher: 0.996740, loss: 3.5232
2022-10-03 23:16:47 - train: epoch 0029, iter [03100, 10009], lr: 0.013520, weight_decay: 0.000100, momentum_teacher: 0.996740, loss: 3.4862
2022-10-03 23:17:37 - train: epoch 0029, iter [03200, 10009], lr: 0.013518, weight_decay: 0.000100, momentum_teacher: 0.996741, loss: 3.6086
2022-10-03 23:18:29 - train: epoch 0029, iter [03300, 10009], lr: 0.013517, weight_decay: 0.000100, momentum_teacher: 0.996741, loss: 3.6025
2022-10-03 23:19:27 - train: epoch 0029, iter [03400, 10009], lr: 0.013515, weight_decay: 0.000100, momentum_teacher: 0.996742, loss: 3.4789
2022-10-03 23:20:35 - train: epoch 0029, iter [03500, 10009], lr: 0.013513, weight_decay: 0.000100, momentum_teacher: 0.996742, loss: 3.4905
2022-10-03 23:21:45 - train: epoch 0029, iter [03600, 10009], lr: 0.013512, weight_decay: 0.000100, momentum_teacher: 0.996743, loss: 3.6505
2022-10-03 23:22:34 - train: epoch 0029, iter [03700, 10009], lr: 0.013510, weight_decay: 0.000100, momentum_teacher: 0.996743, loss: 3.5294
2022-10-03 23:23:45 - train: epoch 0029, iter [03800, 10009], lr: 0.013509, weight_decay: 0.000100, momentum_teacher: 0.996744, loss: 3.5222
2022-10-03 23:25:39 - train: epoch 0029, iter [03900, 10009], lr: 0.013507, weight_decay: 0.000100, momentum_teacher: 0.996744, loss: 3.4461
2022-10-03 23:27:12 - train: epoch 0029, iter [04000, 10009], lr: 0.013506, weight_decay: 0.000100, momentum_teacher: 0.996745, loss: 3.6062
2022-10-03 23:28:40 - train: epoch 0029, iter [04100, 10009], lr: 0.013504, weight_decay: 0.000100, momentum_teacher: 0.996745, loss: 3.4768
2022-10-03 23:29:58 - train: epoch 0029, iter [04200, 10009], lr: 0.013503, weight_decay: 0.000100, momentum_teacher: 0.996746, loss: 3.6605
2022-10-03 23:31:06 - train: epoch 0029, iter [04300, 10009], lr: 0.013501, weight_decay: 0.000100, momentum_teacher: 0.996746, loss: 3.4983
2022-10-03 23:31:55 - train: epoch 0029, iter [04400, 10009], lr: 0.013499, weight_decay: 0.000100, momentum_teacher: 0.996747, loss: 3.7006
2022-10-03 23:33:34 - train: epoch 0029, iter [04500, 10009], lr: 0.013498, weight_decay: 0.000100, momentum_teacher: 0.996747, loss: 3.5495
2022-10-03 23:35:04 - train: epoch 0029, iter [04600, 10009], lr: 0.013496, weight_decay: 0.000100, momentum_teacher: 0.996748, loss: 3.7715
2022-10-03 23:35:57 - train: epoch 0029, iter [04700, 10009], lr: 0.013495, weight_decay: 0.000100, momentum_teacher: 0.996748, loss: 3.3196
2022-10-03 23:37:17 - train: epoch 0029, iter [04800, 10009], lr: 0.013493, weight_decay: 0.000100, momentum_teacher: 0.996749, loss: 3.7143
2022-10-03 23:38:32 - train: epoch 0029, iter [04900, 10009], lr: 0.013492, weight_decay: 0.000100, momentum_teacher: 0.996749, loss: 3.6029
2022-10-03 23:39:33 - train: epoch 0029, iter [05000, 10009], lr: 0.013490, weight_decay: 0.000100, momentum_teacher: 0.996749, loss: 3.5498
2022-10-03 23:41:09 - train: epoch 0029, iter [05100, 10009], lr: 0.013488, weight_decay: 0.000100, momentum_teacher: 0.996750, loss: 3.4657
2022-10-03 23:42:40 - train: epoch 0029, iter [05200, 10009], lr: 0.013487, weight_decay: 0.000100, momentum_teacher: 0.996750, loss: 3.4288
2022-10-03 23:44:04 - train: epoch 0029, iter [05300, 10009], lr: 0.013485, weight_decay: 0.000100, momentum_teacher: 0.996751, loss: 3.5439
2022-10-03 23:45:31 - train: epoch 0029, iter [05400, 10009], lr: 0.013484, weight_decay: 0.000100, momentum_teacher: 0.996751, loss: 3.3922
2022-10-03 23:46:47 - train: epoch 0029, iter [05500, 10009], lr: 0.013482, weight_decay: 0.000100, momentum_teacher: 0.996752, loss: 3.6250
2022-10-03 23:48:11 - train: epoch 0029, iter [05600, 10009], lr: 0.013480, weight_decay: 0.000100, momentum_teacher: 0.996752, loss: 3.6417
2022-10-03 23:49:17 - train: epoch 0029, iter [05700, 10009], lr: 0.013479, weight_decay: 0.000100, momentum_teacher: 0.996753, loss: 3.5220
2022-10-03 23:50:34 - train: epoch 0029, iter [05800, 10009], lr: 0.013477, weight_decay: 0.000100, momentum_teacher: 0.996753, loss: 3.4988
2022-10-03 23:52:50 - train: epoch 0029, iter [05900, 10009], lr: 0.013476, weight_decay: 0.000100, momentum_teacher: 0.996754, loss: 3.4061
2022-10-03 23:54:54 - train: epoch 0029, iter [06000, 10009], lr: 0.013474, weight_decay: 0.000100, momentum_teacher: 0.996754, loss: 3.5758
2022-10-03 23:56:02 - train: epoch 0029, iter [06100, 10009], lr: 0.013473, weight_decay: 0.000100, momentum_teacher: 0.996755, loss: 3.6036
2022-10-03 23:58:12 - train: epoch 0029, iter [06200, 10009], lr: 0.013471, weight_decay: 0.000100, momentum_teacher: 0.996755, loss: 3.5604
2022-10-03 23:59:12 - train: epoch 0029, iter [06300, 10009], lr: 0.013469, weight_decay: 0.000100, momentum_teacher: 0.996756, loss: 3.4861
