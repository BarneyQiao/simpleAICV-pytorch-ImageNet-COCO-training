2022-10-04 00:00:04 - train: epoch 0061, iter [00120, 01251], lr: 0.000247, loss: 0.3932
2022-10-04 00:00:23 - train: epoch 0061, iter [00130, 01251], lr: 0.000247, loss: 0.4003
2022-10-04 00:00:41 - train: epoch 0061, iter [00140, 01251], lr: 0.000247, loss: 0.4128
2022-10-04 00:01:00 - train: epoch 0061, iter [00150, 01251], lr: 0.000247, loss: 0.4011
2022-10-04 00:01:19 - train: epoch 0061, iter [00160, 01251], lr: 0.000247, loss: 0.4019
2022-10-04 00:01:38 - train: epoch 0061, iter [00170, 01251], lr: 0.000247, loss: 0.4062
2022-10-04 00:01:57 - train: epoch 0061, iter [00180, 01251], lr: 0.000246, loss: 0.4130
2022-10-04 00:02:16 - train: epoch 0061, iter [00190, 01251], lr: 0.000246, loss: 0.3947
2022-10-04 00:02:35 - train: epoch 0061, iter [00200, 01251], lr: 0.000246, loss: 0.3884
2022-10-04 00:02:54 - train: epoch 0061, iter [00210, 01251], lr: 0.000246, loss: 0.4323
2022-10-04 00:03:13 - train: epoch 0061, iter [00220, 01251], lr: 0.000246, loss: 0.4048
2022-10-04 00:03:32 - train: epoch 0061, iter [00230, 01251], lr: 0.000246, loss: 0.4329
2022-10-04 00:03:51 - train: epoch 0061, iter [00240, 01251], lr: 0.000246, loss: 0.3892
2022-10-04 00:04:10 - train: epoch 0061, iter [00250, 01251], lr: 0.000246, loss: 0.4118
2022-10-04 00:04:29 - train: epoch 0061, iter [00260, 01251], lr: 0.000246, loss: 0.4085
2022-10-04 00:04:47 - train: epoch 0061, iter [00270, 01251], lr: 0.000246, loss: 0.4177
2022-10-04 00:05:06 - train: epoch 0061, iter [00280, 01251], lr: 0.000246, loss: 0.4081
2022-10-04 00:05:25 - train: epoch 0061, iter [00290, 01251], lr: 0.000246, loss: 0.4121
2022-10-04 00:05:44 - train: epoch 0061, iter [00300, 01251], lr: 0.000245, loss: 0.4078
2022-10-04 00:06:03 - train: epoch 0061, iter [00310, 01251], lr: 0.000245, loss: 0.3936
2022-10-04 00:06:22 - train: epoch 0061, iter [00320, 01251], lr: 0.000245, loss: 0.4325
2022-10-04 00:06:40 - train: epoch 0061, iter [00330, 01251], lr: 0.000245, loss: 0.3930
2022-10-04 00:06:59 - train: epoch 0061, iter [00340, 01251], lr: 0.000245, loss: 0.4064
2022-10-04 00:07:18 - train: epoch 0061, iter [00350, 01251], lr: 0.000245, loss: 0.4133
2022-10-04 00:07:38 - train: epoch 0061, iter [00360, 01251], lr: 0.000245, loss: 0.4092
2022-10-04 00:07:56 - train: epoch 0061, iter [00370, 01251], lr: 0.000245, loss: 0.3941
2022-10-04 00:08:15 - train: epoch 0061, iter [00380, 01251], lr: 0.000245, loss: 0.3883
2022-10-04 00:08:34 - train: epoch 0061, iter [00390, 01251], lr: 0.000245, loss: 0.4313
2022-10-04 00:08:53 - train: epoch 0061, iter [00400, 01251], lr: 0.000245, loss: 0.3897
2022-10-04 00:09:12 - train: epoch 0061, iter [00410, 01251], lr: 0.000245, loss: 0.4030
2022-10-04 00:09:32 - train: epoch 0061, iter [00420, 01251], lr: 0.000244, loss: 0.3962
2022-10-04 00:09:51 - train: epoch 0061, iter [00430, 01251], lr: 0.000244, loss: 0.3946
2022-10-04 00:10:09 - train: epoch 0061, iter [00440, 01251], lr: 0.000244, loss: 0.3889
2022-10-04 00:10:29 - train: epoch 0061, iter [00450, 01251], lr: 0.000244, loss: 0.4026
2022-10-04 00:10:47 - train: epoch 0061, iter [00460, 01251], lr: 0.000244, loss: 0.4052
2022-10-04 00:11:06 - train: epoch 0061, iter [00470, 01251], lr: 0.000244, loss: 0.3939
2022-10-04 00:11:24 - train: epoch 0061, iter [00480, 01251], lr: 0.000244, loss: 0.3946
2022-10-04 00:11:43 - train: epoch 0061, iter [00490, 01251], lr: 0.000244, loss: 0.3917
2022-10-04 00:12:02 - train: epoch 0061, iter [00500, 01251], lr: 0.000244, loss: 0.4069
2022-10-04 00:12:21 - train: epoch 0061, iter [00510, 01251], lr: 0.000244, loss: 0.4070
2022-10-04 00:12:40 - train: epoch 0061, iter [00520, 01251], lr: 0.000244, loss: 0.4144
2022-10-04 00:12:59 - train: epoch 0061, iter [00530, 01251], lr: 0.000244, loss: 0.4237
2022-10-04 00:13:18 - train: epoch 0061, iter [00540, 01251], lr: 0.000243, loss: 0.4097
2022-10-04 00:13:36 - train: epoch 0061, iter [00550, 01251], lr: 0.000243, loss: 0.4074
2022-10-04 00:13:55 - train: epoch 0061, iter [00560, 01251], lr: 0.000243, loss: 0.4165
2022-10-04 00:14:13 - train: epoch 0061, iter [00570, 01251], lr: 0.000243, loss: 0.4116
2022-10-04 00:14:32 - train: epoch 0061, iter [00580, 01251], lr: 0.000243, loss: 0.4065
2022-10-04 00:14:51 - train: epoch 0061, iter [00590, 01251], lr: 0.000243, loss: 0.3982
2022-10-04 00:15:09 - train: epoch 0061, iter [00600, 01251], lr: 0.000243, loss: 0.4262
2022-10-04 00:15:28 - train: epoch 0061, iter [00610, 01251], lr: 0.000243, loss: 0.4132
2022-10-04 00:15:48 - train: epoch 0061, iter [00620, 01251], lr: 0.000243, loss: 0.3887
2022-10-04 00:16:06 - train: epoch 0061, iter [00630, 01251], lr: 0.000243, loss: 0.3785
2022-10-04 00:16:25 - train: epoch 0061, iter [00640, 01251], lr: 0.000243, loss: 0.4131
2022-10-04 00:16:44 - train: epoch 0061, iter [00650, 01251], lr: 0.000243, loss: 0.4143
2022-10-04 00:17:03 - train: epoch 0061, iter [00660, 01251], lr: 0.000242, loss: 0.3988
2022-10-04 00:17:22 - train: epoch 0061, iter [00670, 01251], lr: 0.000242, loss: 0.4094
2022-10-04 00:17:41 - train: epoch 0061, iter [00680, 01251], lr: 0.000242, loss: 0.4071
2022-10-04 00:18:00 - train: epoch 0061, iter [00690, 01251], lr: 0.000242, loss: 0.3990
2022-10-04 00:18:20 - train: epoch 0061, iter [00700, 01251], lr: 0.000242, loss: 0.4001
2022-10-04 00:18:38 - train: epoch 0061, iter [00710, 01251], lr: 0.000242, loss: 0.4300
2022-10-04 00:18:57 - train: epoch 0061, iter [00720, 01251], lr: 0.000242, loss: 0.3940
2022-10-04 00:19:17 - train: epoch 0061, iter [00730, 01251], lr: 0.000242, loss: 0.4271
2022-10-04 00:19:35 - train: epoch 0061, iter [00740, 01251], lr: 0.000242, loss: 0.3908
2022-10-04 00:19:54 - train: epoch 0061, iter [00750, 01251], lr: 0.000242, loss: 0.4114
2022-10-04 00:20:13 - train: epoch 0061, iter [00760, 01251], lr: 0.000242, loss: 0.3997
2022-10-04 00:20:31 - train: epoch 0061, iter [00770, 01251], lr: 0.000242, loss: 0.3972
2022-10-04 00:20:50 - train: epoch 0061, iter [00780, 01251], lr: 0.000241, loss: 0.4337
2022-10-04 00:21:09 - train: epoch 0061, iter [00790, 01251], lr: 0.000241, loss: 0.3843
2022-10-04 00:21:28 - train: epoch 0061, iter [00800, 01251], lr: 0.000241, loss: 0.4046
2022-10-04 00:21:46 - train: epoch 0061, iter [00810, 01251], lr: 0.000241, loss: 0.4084
2022-10-04 00:22:05 - train: epoch 0061, iter [00820, 01251], lr: 0.000241, loss: 0.4073
2022-10-04 00:22:24 - train: epoch 0061, iter [00830, 01251], lr: 0.000241, loss: 0.3799
2022-10-04 00:22:43 - train: epoch 0061, iter [00840, 01251], lr: 0.000241, loss: 0.4027
2022-10-04 00:23:02 - train: epoch 0061, iter [00850, 01251], lr: 0.000241, loss: 0.4070
2022-10-04 00:23:20 - train: epoch 0061, iter [00860, 01251], lr: 0.000241, loss: 0.4035
2022-10-04 00:23:40 - train: epoch 0061, iter [00870, 01251], lr: 0.000241, loss: 0.3890
2022-10-04 00:23:59 - train: epoch 0061, iter [00880, 01251], lr: 0.000241, loss: 0.4092
2022-10-04 00:24:17 - train: epoch 0061, iter [00890, 01251], lr: 0.000241, loss: 0.4211
2022-10-04 00:24:36 - train: epoch 0061, iter [00900, 01251], lr: 0.000241, loss: 0.4134
2022-10-04 00:24:55 - train: epoch 0061, iter [00910, 01251], lr: 0.000240, loss: 0.4211
2022-10-04 00:25:14 - train: epoch 0061, iter [00920, 01251], lr: 0.000240, loss: 0.4186
2022-10-04 00:25:33 - train: epoch 0061, iter [00930, 01251], lr: 0.000240, loss: 0.4041
2022-10-04 00:25:52 - train: epoch 0061, iter [00940, 01251], lr: 0.000240, loss: 0.4015
2022-10-04 00:26:10 - train: epoch 0061, iter [00950, 01251], lr: 0.000240, loss: 0.4140
2022-10-04 00:26:29 - train: epoch 0061, iter [00960, 01251], lr: 0.000240, loss: 0.3991
2022-10-04 00:26:49 - train: epoch 0061, iter [00970, 01251], lr: 0.000240, loss: 0.3856
2022-10-04 00:27:08 - train: epoch 0061, iter [00980, 01251], lr: 0.000240, loss: 0.4049
2022-10-04 00:27:26 - train: epoch 0061, iter [00990, 01251], lr: 0.000240, loss: 0.4072
2022-10-04 00:27:45 - train: epoch 0061, iter [01000, 01251], lr: 0.000240, loss: 0.4075
2022-10-04 00:28:04 - train: epoch 0061, iter [01010, 01251], lr: 0.000240, loss: 0.4143
2022-10-04 00:28:23 - train: epoch 0061, iter [01020, 01251], lr: 0.000240, loss: 0.4115
2022-10-04 00:28:42 - train: epoch 0061, iter [01030, 01251], lr: 0.000239, loss: 0.4102
2022-10-04 00:29:01 - train: epoch 0061, iter [01040, 01251], lr: 0.000239, loss: 0.4107
2022-10-04 00:29:20 - train: epoch 0061, iter [01050, 01251], lr: 0.000239, loss: 0.4238
2022-10-04 00:29:39 - train: epoch 0061, iter [01060, 01251], lr: 0.000239, loss: 0.4075
2022-10-04 00:29:57 - train: epoch 0061, iter [01070, 01251], lr: 0.000239, loss: 0.4032
2022-10-04 00:30:16 - train: epoch 0061, iter [01080, 01251], lr: 0.000239, loss: 0.3984
2022-10-04 00:30:36 - train: epoch 0061, iter [01090, 01251], lr: 0.000239, loss: 0.4003
2022-10-04 00:30:55 - train: epoch 0061, iter [01100, 01251], lr: 0.000239, loss: 0.3977
2022-10-04 00:31:14 - train: epoch 0061, iter [01110, 01251], lr: 0.000239, loss: 0.3935
2022-10-04 00:31:32 - train: epoch 0061, iter [01120, 01251], lr: 0.000239, loss: 0.4055
2022-10-04 00:31:51 - train: epoch 0061, iter [01130, 01251], lr: 0.000239, loss: 0.4091
2022-10-04 00:32:10 - train: epoch 0061, iter [01140, 01251], lr: 0.000239, loss: 0.4222
2022-10-04 00:32:29 - train: epoch 0061, iter [01150, 01251], lr: 0.000238, loss: 0.4120
2022-10-04 00:32:48 - train: epoch 0061, iter [01160, 01251], lr: 0.000238, loss: 0.3959
2022-10-04 00:33:06 - train: epoch 0061, iter [01170, 01251], lr: 0.000238, loss: 0.3984
2022-10-04 00:33:25 - train: epoch 0061, iter [01180, 01251], lr: 0.000238, loss: 0.4007
2022-10-04 00:33:44 - train: epoch 0061, iter [01190, 01251], lr: 0.000238, loss: 0.3867
2022-10-04 00:34:03 - train: epoch 0061, iter [01200, 01251], lr: 0.000238, loss: 0.3949
2022-10-04 00:34:21 - train: epoch 0061, iter [01210, 01251], lr: 0.000238, loss: 0.3990
2022-10-04 00:34:40 - train: epoch 0061, iter [01220, 01251], lr: 0.000238, loss: 0.4345
2022-10-04 00:34:59 - train: epoch 0061, iter [01230, 01251], lr: 0.000238, loss: 0.4128
2022-10-04 00:35:18 - train: epoch 0061, iter [01240, 01251], lr: 0.000238, loss: 0.3969
2022-10-04 00:35:36 - train: epoch 0061, iter [01250, 01251], lr: 0.000238, loss: 0.4080
2022-10-04 00:35:41 - train: epoch 061, train_loss: 0.4070
2022-10-04 00:35:46 - until epoch: 061, best_loss: 0.4070
2022-10-04 00:35:46 - epoch 062 lr: 0.000238
2022-10-04 00:36:11 - train: epoch 0062, iter [00010, 01251], lr: 0.000238, loss: 0.3953
2022-10-04 00:36:29 - train: epoch 0062, iter [00020, 01251], lr: 0.000237, loss: 0.4178
2022-10-04 00:36:47 - train: epoch 0062, iter [00030, 01251], lr: 0.000237, loss: 0.3987
2022-10-04 00:37:06 - train: epoch 0062, iter [00040, 01251], lr: 0.000237, loss: 0.3972
2022-10-04 00:37:25 - train: epoch 0062, iter [00050, 01251], lr: 0.000237, loss: 0.4009
2022-10-04 00:37:43 - train: epoch 0062, iter [00060, 01251], lr: 0.000237, loss: 0.4155
2022-10-04 00:38:03 - train: epoch 0062, iter [00070, 01251], lr: 0.000237, loss: 0.4068
2022-10-04 00:38:22 - train: epoch 0062, iter [00080, 01251], lr: 0.000237, loss: 0.4137
2022-10-04 00:38:41 - train: epoch 0062, iter [00090, 01251], lr: 0.000237, loss: 0.3890
2022-10-04 00:39:00 - train: epoch 0062, iter [00100, 01251], lr: 0.000237, loss: 0.4187
2022-10-04 00:39:19 - train: epoch 0062, iter [00110, 01251], lr: 0.000237, loss: 0.4046
2022-10-04 00:39:38 - train: epoch 0062, iter [00120, 01251], lr: 0.000237, loss: 0.4056
2022-10-04 00:39:56 - train: epoch 0062, iter [00130, 01251], lr: 0.000237, loss: 0.3934
2022-10-04 00:40:16 - train: epoch 0062, iter [00140, 01251], lr: 0.000236, loss: 0.3914
2022-10-04 00:40:34 - train: epoch 0062, iter [00150, 01251], lr: 0.000236, loss: 0.3879
2022-10-04 00:40:53 - train: epoch 0062, iter [00160, 01251], lr: 0.000236, loss: 0.3960
2022-10-04 00:41:12 - train: epoch 0062, iter [00170, 01251], lr: 0.000236, loss: 0.4028
2022-10-04 00:41:31 - train: epoch 0062, iter [00180, 01251], lr: 0.000236, loss: 0.4051
2022-10-04 00:41:50 - train: epoch 0062, iter [00190, 01251], lr: 0.000236, loss: 0.4148
2022-10-04 00:42:08 - train: epoch 0062, iter [00200, 01251], lr: 0.000236, loss: 0.4175
2022-10-04 00:42:27 - train: epoch 0062, iter [00210, 01251], lr: 0.000236, loss: 0.4059
2022-10-04 00:42:46 - train: epoch 0062, iter [00220, 01251], lr: 0.000236, loss: 0.4358
2022-10-04 00:43:04 - train: epoch 0062, iter [00230, 01251], lr: 0.000236, loss: 0.4270
2022-10-04 00:43:23 - train: epoch 0062, iter [00240, 01251], lr: 0.000236, loss: 0.4018
2022-10-04 00:43:42 - train: epoch 0062, iter [00250, 01251], lr: 0.000236, loss: 0.4008
2022-10-04 00:44:01 - train: epoch 0062, iter [00260, 01251], lr: 0.000235, loss: 0.4239
2022-10-04 00:44:19 - train: epoch 0062, iter [00270, 01251], lr: 0.000235, loss: 0.4261
2022-10-04 00:44:38 - train: epoch 0062, iter [00280, 01251], lr: 0.000235, loss: 0.4116
2022-10-04 00:44:57 - train: epoch 0062, iter [00290, 01251], lr: 0.000235, loss: 0.3981
2022-10-04 00:45:16 - train: epoch 0062, iter [00300, 01251], lr: 0.000235, loss: 0.4088
2022-10-04 00:45:34 - train: epoch 0062, iter [00310, 01251], lr: 0.000235, loss: 0.4032
2022-10-04 00:45:53 - train: epoch 0062, iter [00320, 01251], lr: 0.000235, loss: 0.3828
2022-10-04 00:46:12 - train: epoch 0062, iter [00330, 01251], lr: 0.000235, loss: 0.4120
2022-10-04 00:46:31 - train: epoch 0062, iter [00340, 01251], lr: 0.000235, loss: 0.4155
2022-10-04 00:46:50 - train: epoch 0062, iter [00350, 01251], lr: 0.000235, loss: 0.4070
2022-10-04 00:47:09 - train: epoch 0062, iter [00360, 01251], lr: 0.000235, loss: 0.4178
2022-10-04 00:47:28 - train: epoch 0062, iter [00370, 01251], lr: 0.000235, loss: 0.4086
2022-10-04 00:47:46 - train: epoch 0062, iter [00380, 01251], lr: 0.000235, loss: 0.4175
2022-10-04 00:48:05 - train: epoch 0062, iter [00390, 01251], lr: 0.000234, loss: 0.4079
2022-10-04 00:48:24 - train: epoch 0062, iter [00400, 01251], lr: 0.000234, loss: 0.3975
2022-10-04 00:48:44 - train: epoch 0062, iter [00410, 01251], lr: 0.000234, loss: 0.4155
2022-10-04 00:49:03 - train: epoch 0062, iter [00420, 01251], lr: 0.000234, loss: 0.4028
2022-10-04 00:49:22 - train: epoch 0062, iter [00430, 01251], lr: 0.000234, loss: 0.4016
2022-10-04 00:49:40 - train: epoch 0062, iter [00440, 01251], lr: 0.000234, loss: 0.4099
2022-10-04 00:49:59 - train: epoch 0062, iter [00450, 01251], lr: 0.000234, loss: 0.4024
2022-10-04 00:50:18 - train: epoch 0062, iter [00460, 01251], lr: 0.000234, loss: 0.4092
2022-10-04 00:50:37 - train: epoch 0062, iter [00470, 01251], lr: 0.000234, loss: 0.4122
2022-10-04 00:50:56 - train: epoch 0062, iter [00480, 01251], lr: 0.000234, loss: 0.4198
2022-10-04 00:51:15 - train: epoch 0062, iter [00490, 01251], lr: 0.000234, loss: 0.4115
2022-10-04 00:51:34 - train: epoch 0062, iter [00500, 01251], lr: 0.000234, loss: 0.4028
2022-10-04 00:51:53 - train: epoch 0062, iter [00510, 01251], lr: 0.000233, loss: 0.4104
2022-10-04 00:52:12 - train: epoch 0062, iter [00520, 01251], lr: 0.000233, loss: 0.4068
2022-10-04 00:52:31 - train: epoch 0062, iter [00530, 01251], lr: 0.000233, loss: 0.4019
2022-10-04 00:52:50 - train: epoch 0062, iter [00540, 01251], lr: 0.000233, loss: 0.4047
2022-10-04 00:53:09 - train: epoch 0062, iter [00550, 01251], lr: 0.000233, loss: 0.3928
2022-10-04 00:53:28 - train: epoch 0062, iter [00560, 01251], lr: 0.000233, loss: 0.3932
2022-10-04 00:53:47 - train: epoch 0062, iter [00570, 01251], lr: 0.000233, loss: 0.4088
2022-10-04 00:54:06 - train: epoch 0062, iter [00580, 01251], lr: 0.000233, loss: 0.4080
2022-10-04 00:54:25 - train: epoch 0062, iter [00590, 01251], lr: 0.000233, loss: 0.4041
2022-10-04 00:54:44 - train: epoch 0062, iter [00600, 01251], lr: 0.000233, loss: 0.3954
2022-10-04 00:55:03 - train: epoch 0062, iter [00610, 01251], lr: 0.000233, loss: 0.3982
2022-10-04 00:55:22 - train: epoch 0062, iter [00620, 01251], lr: 0.000233, loss: 0.4151
2022-10-04 00:55:41 - train: epoch 0062, iter [00630, 01251], lr: 0.000232, loss: 0.4258
2022-10-04 00:55:59 - train: epoch 0062, iter [00640, 01251], lr: 0.000232, loss: 0.4242
2022-10-04 00:56:18 - train: epoch 0062, iter [00650, 01251], lr: 0.000232, loss: 0.4118
2022-10-04 00:56:37 - train: epoch 0062, iter [00660, 01251], lr: 0.000232, loss: 0.3862
2022-10-04 00:56:56 - train: epoch 0062, iter [00670, 01251], lr: 0.000232, loss: 0.4122
2022-10-04 00:57:14 - train: epoch 0062, iter [00680, 01251], lr: 0.000232, loss: 0.3869
2022-10-04 00:57:33 - train: epoch 0062, iter [00690, 01251], lr: 0.000232, loss: 0.3974
2022-10-04 00:57:51 - train: epoch 0062, iter [00700, 01251], lr: 0.000232, loss: 0.3989
2022-10-04 00:58:11 - train: epoch 0062, iter [00710, 01251], lr: 0.000232, loss: 0.4132
2022-10-04 00:58:30 - train: epoch 0062, iter [00720, 01251], lr: 0.000232, loss: 0.4161
2022-10-04 00:58:48 - train: epoch 0062, iter [00730, 01251], lr: 0.000232, loss: 0.4017
2022-10-04 00:59:07 - train: epoch 0062, iter [00740, 01251], lr: 0.000232, loss: 0.4026
2022-10-04 00:59:26 - train: epoch 0062, iter [00750, 01251], lr: 0.000231, loss: 0.3894
2022-10-04 00:59:45 - train: epoch 0062, iter [00760, 01251], lr: 0.000231, loss: 0.3984
2022-10-04 01:00:04 - train: epoch 0062, iter [00770, 01251], lr: 0.000231, loss: 0.4155
2022-10-04 01:00:22 - train: epoch 0062, iter [00780, 01251], lr: 0.000231, loss: 0.4093
2022-10-04 01:00:42 - train: epoch 0062, iter [00790, 01251], lr: 0.000231, loss: 0.4108
2022-10-04 01:01:00 - train: epoch 0062, iter [00800, 01251], lr: 0.000231, loss: 0.4056
2022-10-04 01:01:19 - train: epoch 0062, iter [00810, 01251], lr: 0.000231, loss: 0.4137
2022-10-04 01:01:38 - train: epoch 0062, iter [00820, 01251], lr: 0.000231, loss: 0.4188
2022-10-04 01:01:57 - train: epoch 0062, iter [00830, 01251], lr: 0.000231, loss: 0.4262
2022-10-04 01:02:15 - train: epoch 0062, iter [00840, 01251], lr: 0.000231, loss: 0.4020
2022-10-04 01:02:34 - train: epoch 0062, iter [00850, 01251], lr: 0.000231, loss: 0.4136
2022-10-04 01:02:53 - train: epoch 0062, iter [00860, 01251], lr: 0.000231, loss: 0.4260
2022-10-04 01:03:12 - train: epoch 0062, iter [00870, 01251], lr: 0.000231, loss: 0.3772
2022-10-04 01:03:31 - train: epoch 0062, iter [00880, 01251], lr: 0.000230, loss: 0.4110
2022-10-04 01:03:49 - train: epoch 0062, iter [00890, 01251], lr: 0.000230, loss: 0.4211
2022-10-04 01:04:08 - train: epoch 0062, iter [00900, 01251], lr: 0.000230, loss: 0.4301
2022-10-04 01:04:27 - train: epoch 0062, iter [00910, 01251], lr: 0.000230, loss: 0.3956
2022-10-04 01:04:47 - train: epoch 0062, iter [00920, 01251], lr: 0.000230, loss: 0.4024
2022-10-04 01:05:06 - train: epoch 0062, iter [00930, 01251], lr: 0.000230, loss: 0.4062
2022-10-04 01:05:25 - train: epoch 0062, iter [00940, 01251], lr: 0.000230, loss: 0.3922
2022-10-04 01:05:44 - train: epoch 0062, iter [00950, 01251], lr: 0.000230, loss: 0.4181
2022-10-04 01:06:03 - train: epoch 0062, iter [00960, 01251], lr: 0.000230, loss: 0.4087
2022-10-04 01:06:22 - train: epoch 0062, iter [00970, 01251], lr: 0.000230, loss: 0.3973
2022-10-04 01:06:41 - train: epoch 0062, iter [00980, 01251], lr: 0.000230, loss: 0.4006
2022-10-04 01:06:59 - train: epoch 0062, iter [00990, 01251], lr: 0.000230, loss: 0.3929
2022-10-04 01:07:18 - train: epoch 0062, iter [01000, 01251], lr: 0.000229, loss: 0.4048
2022-10-04 01:07:37 - train: epoch 0062, iter [01010, 01251], lr: 0.000229, loss: 0.3991
2022-10-04 01:07:56 - train: epoch 0062, iter [01020, 01251], lr: 0.000229, loss: 0.4191
2022-10-04 01:08:14 - train: epoch 0062, iter [01030, 01251], lr: 0.000229, loss: 0.3888
2022-10-04 01:08:33 - train: epoch 0062, iter [01040, 01251], lr: 0.000229, loss: 0.3903
2022-10-04 01:08:52 - train: epoch 0062, iter [01050, 01251], lr: 0.000229, loss: 0.3908
2022-10-04 01:09:12 - train: epoch 0062, iter [01060, 01251], lr: 0.000229, loss: 0.4189
2022-10-04 01:09:30 - train: epoch 0062, iter [01070, 01251], lr: 0.000229, loss: 0.4057
2022-10-04 01:09:50 - train: epoch 0062, iter [01080, 01251], lr: 0.000229, loss: 0.4089
2022-10-04 01:10:09 - train: epoch 0062, iter [01090, 01251], lr: 0.000229, loss: 0.4124
2022-10-04 01:10:27 - train: epoch 0062, iter [01100, 01251], lr: 0.000229, loss: 0.4052
2022-10-04 01:10:46 - train: epoch 0062, iter [01110, 01251], lr: 0.000229, loss: 0.4146
2022-10-04 01:11:05 - train: epoch 0062, iter [01120, 01251], lr: 0.000228, loss: 0.4160
2022-10-04 01:11:24 - train: epoch 0062, iter [01130, 01251], lr: 0.000228, loss: 0.3755
2022-10-04 01:11:42 - train: epoch 0062, iter [01140, 01251], lr: 0.000228, loss: 0.3976
2022-10-04 01:12:01 - train: epoch 0062, iter [01150, 01251], lr: 0.000228, loss: 0.4106
2022-10-04 01:12:20 - train: epoch 0062, iter [01160, 01251], lr: 0.000228, loss: 0.4020
2022-10-04 01:12:39 - train: epoch 0062, iter [01170, 01251], lr: 0.000228, loss: 0.4076
2022-10-04 01:12:58 - train: epoch 0062, iter [01180, 01251], lr: 0.000228, loss: 0.4011
2022-10-04 01:13:17 - train: epoch 0062, iter [01190, 01251], lr: 0.000228, loss: 0.3948
2022-10-04 01:13:36 - train: epoch 0062, iter [01200, 01251], lr: 0.000228, loss: 0.4075
2022-10-04 01:13:55 - train: epoch 0062, iter [01210, 01251], lr: 0.000228, loss: 0.4273
2022-10-04 01:14:14 - train: epoch 0062, iter [01220, 01251], lr: 0.000228, loss: 0.4006
2022-10-04 01:14:32 - train: epoch 0062, iter [01230, 01251], lr: 0.000228, loss: 0.3860
2022-10-04 01:14:51 - train: epoch 0062, iter [01240, 01251], lr: 0.000228, loss: 0.4406
2022-10-04 01:15:10 - train: epoch 0062, iter [01250, 01251], lr: 0.000227, loss: 0.3943
2022-10-04 01:15:15 - train: epoch 062, train_loss: 0.4069
2022-10-04 01:15:20 - until epoch: 062, best_loss: 0.4069
2022-10-04 01:15:20 - epoch 063 lr: 0.000227
2022-10-04 01:15:44 - train: epoch 0063, iter [00010, 01251], lr: 0.000227, loss: 0.3981
2022-10-04 01:16:03 - train: epoch 0063, iter [00020, 01251], lr: 0.000227, loss: 0.3903
2022-10-04 01:16:21 - train: epoch 0063, iter [00030, 01251], lr: 0.000227, loss: 0.3934
2022-10-04 01:16:40 - train: epoch 0063, iter [00040, 01251], lr: 0.000227, loss: 0.4059
2022-10-04 01:16:59 - train: epoch 0063, iter [00050, 01251], lr: 0.000227, loss: 0.4286
2022-10-04 01:17:18 - train: epoch 0063, iter [00060, 01251], lr: 0.000227, loss: 0.4001
2022-10-04 01:17:36 - train: epoch 0063, iter [00070, 01251], lr: 0.000227, loss: 0.3985
2022-10-04 01:17:54 - train: epoch 0063, iter [00080, 01251], lr: 0.000227, loss: 0.4008
2022-10-04 01:18:13 - train: epoch 0063, iter [00090, 01251], lr: 0.000227, loss: 0.3895
2022-10-04 01:18:32 - train: epoch 0063, iter [00100, 01251], lr: 0.000227, loss: 0.4180
2022-10-04 01:18:51 - train: epoch 0063, iter [00110, 01251], lr: 0.000227, loss: 0.4170
2022-10-04 01:19:09 - train: epoch 0063, iter [00120, 01251], lr: 0.000226, loss: 0.4034
2022-10-04 01:19:28 - train: epoch 0063, iter [00130, 01251], lr: 0.000226, loss: 0.4269
2022-10-04 01:19:47 - train: epoch 0063, iter [00140, 01251], lr: 0.000226, loss: 0.3953
2022-10-04 01:20:07 - train: epoch 0063, iter [00150, 01251], lr: 0.000226, loss: 0.3882
2022-10-04 01:20:26 - train: epoch 0063, iter [00160, 01251], lr: 0.000226, loss: 0.4124
2022-10-04 01:20:44 - train: epoch 0063, iter [00170, 01251], lr: 0.000226, loss: 0.3960
2022-10-04 01:21:03 - train: epoch 0063, iter [00180, 01251], lr: 0.000226, loss: 0.4088
2022-10-04 01:21:22 - train: epoch 0063, iter [00190, 01251], lr: 0.000226, loss: 0.4061
2022-10-04 01:21:41 - train: epoch 0063, iter [00200, 01251], lr: 0.000226, loss: 0.4233
2022-10-04 01:22:00 - train: epoch 0063, iter [00210, 01251], lr: 0.000226, loss: 0.4129
2022-10-04 01:22:19 - train: epoch 0063, iter [00220, 01251], lr: 0.000226, loss: 0.4116
2022-10-04 01:22:38 - train: epoch 0063, iter [00230, 01251], lr: 0.000226, loss: 0.4040
2022-10-04 01:22:57 - train: epoch 0063, iter [00240, 01251], lr: 0.000225, loss: 0.3917
2022-10-04 01:23:16 - train: epoch 0063, iter [00250, 01251], lr: 0.000225, loss: 0.4044
2022-10-04 01:23:35 - train: epoch 0063, iter [00260, 01251], lr: 0.000225, loss: 0.4029
2022-10-04 01:23:53 - train: epoch 0063, iter [00270, 01251], lr: 0.000225, loss: 0.4163
2022-10-04 01:24:13 - train: epoch 0063, iter [00280, 01251], lr: 0.000225, loss: 0.4053
2022-10-04 01:24:32 - train: epoch 0063, iter [00290, 01251], lr: 0.000225, loss: 0.4322
2022-10-04 01:24:50 - train: epoch 0063, iter [00300, 01251], lr: 0.000225, loss: 0.4254
2022-10-04 01:25:10 - train: epoch 0063, iter [00310, 01251], lr: 0.000225, loss: 0.3953
2022-10-04 01:25:28 - train: epoch 0063, iter [00320, 01251], lr: 0.000225, loss: 0.4168
2022-10-04 01:25:47 - train: epoch 0063, iter [00330, 01251], lr: 0.000225, loss: 0.4017
2022-10-04 01:26:06 - train: epoch 0063, iter [00340, 01251], lr: 0.000225, loss: 0.4006
2022-10-04 01:26:24 - train: epoch 0063, iter [00350, 01251], lr: 0.000225, loss: 0.4130
2022-10-04 01:26:43 - train: epoch 0063, iter [00360, 01251], lr: 0.000225, loss: 0.4239
2022-10-04 01:27:02 - train: epoch 0063, iter [00370, 01251], lr: 0.000224, loss: 0.4066
2022-10-04 01:27:21 - train: epoch 0063, iter [00380, 01251], lr: 0.000224, loss: 0.3911
2022-10-04 01:27:41 - train: epoch 0063, iter [00390, 01251], lr: 0.000224, loss: 0.4016
2022-10-04 01:28:00 - train: epoch 0063, iter [00400, 01251], lr: 0.000224, loss: 0.4205
2022-10-04 01:28:19 - train: epoch 0063, iter [00410, 01251], lr: 0.000224, loss: 0.4210
2022-10-04 01:28:38 - train: epoch 0063, iter [00420, 01251], lr: 0.000224, loss: 0.4067
2022-10-04 01:28:57 - train: epoch 0063, iter [00430, 01251], lr: 0.000224, loss: 0.4104
2022-10-04 01:29:16 - train: epoch 0063, iter [00440, 01251], lr: 0.000224, loss: 0.3910
2022-10-04 01:29:35 - train: epoch 0063, iter [00450, 01251], lr: 0.000224, loss: 0.3971
2022-10-04 01:29:54 - train: epoch 0063, iter [00460, 01251], lr: 0.000224, loss: 0.4131
2022-10-04 01:30:13 - train: epoch 0063, iter [00470, 01251], lr: 0.000224, loss: 0.4186
2022-10-04 01:30:32 - train: epoch 0063, iter [00480, 01251], lr: 0.000224, loss: 0.4054
2022-10-04 01:30:51 - train: epoch 0063, iter [00490, 01251], lr: 0.000223, loss: 0.4154
2022-10-04 01:31:10 - train: epoch 0063, iter [00500, 01251], lr: 0.000223, loss: 0.4185
2022-10-04 01:31:29 - train: epoch 0063, iter [00510, 01251], lr: 0.000223, loss: 0.3981
2022-10-04 01:31:47 - train: epoch 0063, iter [00520, 01251], lr: 0.000223, loss: 0.4158
2022-10-04 01:32:06 - train: epoch 0063, iter [00530, 01251], lr: 0.000223, loss: 0.4099
2022-10-04 01:32:25 - train: epoch 0063, iter [00540, 01251], lr: 0.000223, loss: 0.4028
2022-10-04 01:32:43 - train: epoch 0063, iter [00550, 01251], lr: 0.000223, loss: 0.4088
2022-10-04 01:33:02 - train: epoch 0063, iter [00560, 01251], lr: 0.000223, loss: 0.4047
2022-10-04 01:33:21 - train: epoch 0063, iter [00570, 01251], lr: 0.000223, loss: 0.4166
2022-10-04 01:33:40 - train: epoch 0063, iter [00580, 01251], lr: 0.000223, loss: 0.4191
2022-10-04 01:33:58 - train: epoch 0063, iter [00590, 01251], lr: 0.000223, loss: 0.4018
2022-10-04 01:34:17 - train: epoch 0063, iter [00600, 01251], lr: 0.000223, loss: 0.4045
2022-10-04 01:34:37 - train: epoch 0063, iter [00610, 01251], lr: 0.000222, loss: 0.4138
2022-10-04 01:34:56 - train: epoch 0063, iter [00620, 01251], lr: 0.000222, loss: 0.3939
2022-10-04 01:35:14 - train: epoch 0063, iter [00630, 01251], lr: 0.000222, loss: 0.3826
2022-10-04 01:35:33 - train: epoch 0063, iter [00640, 01251], lr: 0.000222, loss: 0.4102
2022-10-04 01:35:52 - train: epoch 0063, iter [00650, 01251], lr: 0.000222, loss: 0.4179
2022-10-04 01:36:11 - train: epoch 0063, iter [00660, 01251], lr: 0.000222, loss: 0.4230
2022-10-04 01:36:30 - train: epoch 0063, iter [00670, 01251], lr: 0.000222, loss: 0.4202
2022-10-04 01:36:49 - train: epoch 0063, iter [00680, 01251], lr: 0.000222, loss: 0.3950
2022-10-04 01:37:08 - train: epoch 0063, iter [00690, 01251], lr: 0.000222, loss: 0.4185
2022-10-04 01:37:26 - train: epoch 0063, iter [00700, 01251], lr: 0.000222, loss: 0.3848
2022-10-04 01:37:45 - train: epoch 0063, iter [00710, 01251], lr: 0.000222, loss: 0.4119
2022-10-04 01:38:04 - train: epoch 0063, iter [00720, 01251], lr: 0.000222, loss: 0.4394
2022-10-04 01:38:23 - train: epoch 0063, iter [00730, 01251], lr: 0.000222, loss: 0.4256
2022-10-04 01:38:42 - train: epoch 0063, iter [00740, 01251], lr: 0.000221, loss: 0.3883
2022-10-04 01:39:01 - train: epoch 0063, iter [00750, 01251], lr: 0.000221, loss: 0.4163
2022-10-04 01:39:20 - train: epoch 0063, iter [00760, 01251], lr: 0.000221, loss: 0.4089
2022-10-04 01:39:39 - train: epoch 0063, iter [00770, 01251], lr: 0.000221, loss: 0.3950
2022-10-04 01:39:58 - train: epoch 0063, iter [00780, 01251], lr: 0.000221, loss: 0.4046
2022-10-04 01:40:16 - train: epoch 0063, iter [00790, 01251], lr: 0.000221, loss: 0.4069
2022-10-04 01:40:35 - train: epoch 0063, iter [00800, 01251], lr: 0.000221, loss: 0.4181
2022-10-04 01:40:54 - train: epoch 0063, iter [00810, 01251], lr: 0.000221, loss: 0.4103
2022-10-04 01:41:14 - train: epoch 0063, iter [00820, 01251], lr: 0.000221, loss: 0.3996
2022-10-04 01:41:33 - train: epoch 0063, iter [00830, 01251], lr: 0.000221, loss: 0.4218
2022-10-04 01:41:52 - train: epoch 0063, iter [00840, 01251], lr: 0.000221, loss: 0.3924
2022-10-04 01:42:10 - train: epoch 0063, iter [00850, 01251], lr: 0.000221, loss: 0.3985
2022-10-04 01:42:29 - train: epoch 0063, iter [00860, 01251], lr: 0.000220, loss: 0.3895
2022-10-04 01:42:48 - train: epoch 0063, iter [00870, 01251], lr: 0.000220, loss: 0.4238
2022-10-04 01:43:07 - train: epoch 0063, iter [00880, 01251], lr: 0.000220, loss: 0.3967
2022-10-04 01:43:26 - train: epoch 0063, iter [00890, 01251], lr: 0.000220, loss: 0.4250
2022-10-04 01:43:45 - train: epoch 0063, iter [00900, 01251], lr: 0.000220, loss: 0.3973
2022-10-04 01:44:04 - train: epoch 0063, iter [00910, 01251], lr: 0.000220, loss: 0.4140
2022-10-04 01:44:23 - train: epoch 0063, iter [00920, 01251], lr: 0.000220, loss: 0.3938
2022-10-04 01:44:41 - train: epoch 0063, iter [00930, 01251], lr: 0.000220, loss: 0.4044
2022-10-04 01:45:00 - train: epoch 0063, iter [00940, 01251], lr: 0.000220, loss: 0.4120
2022-10-04 01:45:19 - train: epoch 0063, iter [00950, 01251], lr: 0.000220, loss: 0.4012
2022-10-04 01:45:38 - train: epoch 0063, iter [00960, 01251], lr: 0.000220, loss: 0.4139
2022-10-04 01:45:57 - train: epoch 0063, iter [00970, 01251], lr: 0.000220, loss: 0.4128
2022-10-04 01:46:15 - train: epoch 0063, iter [00980, 01251], lr: 0.000219, loss: 0.4061
2022-10-04 01:46:35 - train: epoch 0063, iter [00990, 01251], lr: 0.000219, loss: 0.4050
2022-10-04 01:46:54 - train: epoch 0063, iter [01000, 01251], lr: 0.000219, loss: 0.3996
2022-10-04 01:47:13 - train: epoch 0063, iter [01010, 01251], lr: 0.000219, loss: 0.4039
2022-10-04 01:47:32 - train: epoch 0063, iter [01020, 01251], lr: 0.000219, loss: 0.3947
2022-10-04 01:47:51 - train: epoch 0063, iter [01030, 01251], lr: 0.000219, loss: 0.4115
2022-10-04 01:48:10 - train: epoch 0063, iter [01040, 01251], lr: 0.000219, loss: 0.3814
2022-10-04 01:48:29 - train: epoch 0063, iter [01050, 01251], lr: 0.000219, loss: 0.4189
2022-10-04 01:48:48 - train: epoch 0063, iter [01060, 01251], lr: 0.000219, loss: 0.4139
2022-10-04 01:49:07 - train: epoch 0063, iter [01070, 01251], lr: 0.000219, loss: 0.4096
2022-10-04 01:49:26 - train: epoch 0063, iter [01080, 01251], lr: 0.000219, loss: 0.4063
2022-10-04 01:49:44 - train: epoch 0063, iter [01090, 01251], lr: 0.000219, loss: 0.4064
2022-10-04 01:50:03 - train: epoch 0063, iter [01100, 01251], lr: 0.000219, loss: 0.4145
2022-10-04 01:50:22 - train: epoch 0063, iter [01110, 01251], lr: 0.000218, loss: 0.4128
2022-10-04 01:50:41 - train: epoch 0063, iter [01120, 01251], lr: 0.000218, loss: 0.4103
2022-10-04 01:51:01 - train: epoch 0063, iter [01130, 01251], lr: 0.000218, loss: 0.4115
2022-10-04 01:51:19 - train: epoch 0063, iter [01140, 01251], lr: 0.000218, loss: 0.3791
2022-10-04 01:51:38 - train: epoch 0063, iter [01150, 01251], lr: 0.000218, loss: 0.4144
2022-10-04 01:51:57 - train: epoch 0063, iter [01160, 01251], lr: 0.000218, loss: 0.4013
2022-10-04 01:52:15 - train: epoch 0063, iter [01170, 01251], lr: 0.000218, loss: 0.3983
2022-10-04 01:52:34 - train: epoch 0063, iter [01180, 01251], lr: 0.000218, loss: 0.3888
2022-10-04 01:52:52 - train: epoch 0063, iter [01190, 01251], lr: 0.000218, loss: 0.3870
2022-10-04 01:53:11 - train: epoch 0063, iter [01200, 01251], lr: 0.000218, loss: 0.4216
2022-10-04 01:53:30 - train: epoch 0063, iter [01210, 01251], lr: 0.000218, loss: 0.3989
2022-10-04 01:53:49 - train: epoch 0063, iter [01220, 01251], lr: 0.000218, loss: 0.4004
2022-10-04 01:54:08 - train: epoch 0063, iter [01230, 01251], lr: 0.000217, loss: 0.4056
2022-10-04 01:54:26 - train: epoch 0063, iter [01240, 01251], lr: 0.000217, loss: 0.4045
2022-10-04 01:54:45 - train: epoch 0063, iter [01250, 01251], lr: 0.000217, loss: 0.4042
2022-10-04 01:54:49 - train: epoch 063, train_loss: 0.4065
2022-10-04 01:54:54 - until epoch: 063, best_loss: 0.4065
2022-10-04 01:54:54 - epoch 064 lr: 0.000217
2022-10-04 01:55:18 - train: epoch 0064, iter [00010, 01251], lr: 0.000217, loss: 0.3926
2022-10-04 01:55:37 - train: epoch 0064, iter [00020, 01251], lr: 0.000217, loss: 0.4030
2022-10-04 01:55:56 - train: epoch 0064, iter [00030, 01251], lr: 0.000217, loss: 0.4097
2022-10-04 01:56:14 - train: epoch 0064, iter [00040, 01251], lr: 0.000217, loss: 0.4093
2022-10-04 01:56:33 - train: epoch 0064, iter [00050, 01251], lr: 0.000217, loss: 0.3878
2022-10-04 01:56:51 - train: epoch 0064, iter [00060, 01251], lr: 0.000217, loss: 0.4072
2022-10-04 01:57:10 - train: epoch 0064, iter [00070, 01251], lr: 0.000217, loss: 0.3975
2022-10-04 01:57:29 - train: epoch 0064, iter [00080, 01251], lr: 0.000217, loss: 0.4153
2022-10-04 01:57:47 - train: epoch 0064, iter [00090, 01251], lr: 0.000217, loss: 0.4026
2022-10-04 01:58:06 - train: epoch 0064, iter [00100, 01251], lr: 0.000217, loss: 0.4241
2022-10-04 01:58:25 - train: epoch 0064, iter [00110, 01251], lr: 0.000216, loss: 0.4164
2022-10-04 01:58:44 - train: epoch 0064, iter [00120, 01251], lr: 0.000216, loss: 0.3978
2022-10-04 01:59:03 - train: epoch 0064, iter [00130, 01251], lr: 0.000216, loss: 0.3974
2022-10-04 01:59:22 - train: epoch 0064, iter [00140, 01251], lr: 0.000216, loss: 0.4123
2022-10-04 01:59:41 - train: epoch 0064, iter [00150, 01251], lr: 0.000216, loss: 0.4051
2022-10-04 02:00:00 - train: epoch 0064, iter [00160, 01251], lr: 0.000216, loss: 0.4137
2022-10-04 02:00:19 - train: epoch 0064, iter [00170, 01251], lr: 0.000216, loss: 0.4073
2022-10-04 02:00:38 - train: epoch 0064, iter [00180, 01251], lr: 0.000216, loss: 0.4069
2022-10-04 02:00:57 - train: epoch 0064, iter [00190, 01251], lr: 0.000216, loss: 0.4163
2022-10-04 02:01:16 - train: epoch 0064, iter [00200, 01251], lr: 0.000216, loss: 0.4207
2022-10-04 02:01:35 - train: epoch 0064, iter [00210, 01251], lr: 0.000216, loss: 0.4261
2022-10-04 02:01:54 - train: epoch 0064, iter [00220, 01251], lr: 0.000216, loss: 0.3997
2022-10-04 02:02:13 - train: epoch 0064, iter [00230, 01251], lr: 0.000215, loss: 0.3920
2022-10-04 02:02:31 - train: epoch 0064, iter [00240, 01251], lr: 0.000215, loss: 0.4297
2022-10-04 02:02:50 - train: epoch 0064, iter [00250, 01251], lr: 0.000215, loss: 0.4066
2022-10-04 02:03:09 - train: epoch 0064, iter [00260, 01251], lr: 0.000215, loss: 0.3873
2022-10-04 02:03:28 - train: epoch 0064, iter [00270, 01251], lr: 0.000215, loss: 0.3987
2022-10-04 02:03:47 - train: epoch 0064, iter [00280, 01251], lr: 0.000215, loss: 0.4061
2022-10-04 02:04:05 - train: epoch 0064, iter [00290, 01251], lr: 0.000215, loss: 0.3896
2022-10-04 02:04:24 - train: epoch 0064, iter [00300, 01251], lr: 0.000215, loss: 0.4035
2022-10-04 02:04:43 - train: epoch 0064, iter [00310, 01251], lr: 0.000215, loss: 0.4181
2022-10-04 02:05:02 - train: epoch 0064, iter [00320, 01251], lr: 0.000215, loss: 0.3874
2022-10-04 02:05:21 - train: epoch 0064, iter [00330, 01251], lr: 0.000215, loss: 0.4003
2022-10-04 02:05:40 - train: epoch 0064, iter [00340, 01251], lr: 0.000215, loss: 0.4100
2022-10-04 02:05:58 - train: epoch 0064, iter [00350, 01251], lr: 0.000214, loss: 0.3986
2022-10-04 02:06:17 - train: epoch 0064, iter [00360, 01251], lr: 0.000214, loss: 0.3954
2022-10-04 02:06:36 - train: epoch 0064, iter [00370, 01251], lr: 0.000214, loss: 0.3954
2022-10-04 02:06:55 - train: epoch 0064, iter [00380, 01251], lr: 0.000214, loss: 0.3993
2022-10-04 02:07:13 - train: epoch 0064, iter [00390, 01251], lr: 0.000214, loss: 0.4045
2022-10-04 02:07:32 - train: epoch 0064, iter [00400, 01251], lr: 0.000214, loss: 0.3985
2022-10-04 02:07:51 - train: epoch 0064, iter [00410, 01251], lr: 0.000214, loss: 0.4180
2022-10-04 02:08:10 - train: epoch 0064, iter [00420, 01251], lr: 0.000214, loss: 0.4144
2022-10-04 02:08:29 - train: epoch 0064, iter [00430, 01251], lr: 0.000214, loss: 0.3998
2022-10-04 02:08:48 - train: epoch 0064, iter [00440, 01251], lr: 0.000214, loss: 0.4013
2022-10-04 02:09:07 - train: epoch 0064, iter [00450, 01251], lr: 0.000214, loss: 0.4067
2022-10-04 02:09:26 - train: epoch 0064, iter [00460, 01251], lr: 0.000214, loss: 0.4226
2022-10-04 02:09:45 - train: epoch 0064, iter [00470, 01251], lr: 0.000214, loss: 0.4154
2022-10-04 02:10:04 - train: epoch 0064, iter [00480, 01251], lr: 0.000213, loss: 0.4132
2022-10-04 02:10:22 - train: epoch 0064, iter [00490, 01251], lr: 0.000213, loss: 0.4262
2022-10-04 02:10:40 - train: epoch 0064, iter [00500, 01251], lr: 0.000213, loss: 0.4163
2022-10-04 02:11:00 - train: epoch 0064, iter [00510, 01251], lr: 0.000213, loss: 0.4191
2022-10-04 02:11:19 - train: epoch 0064, iter [00520, 01251], lr: 0.000213, loss: 0.4136
2022-10-04 02:11:38 - train: epoch 0064, iter [00530, 01251], lr: 0.000213, loss: 0.3925
2022-10-04 02:11:56 - train: epoch 0064, iter [00540, 01251], lr: 0.000213, loss: 0.3952
2022-10-04 02:12:15 - train: epoch 0064, iter [00550, 01251], lr: 0.000213, loss: 0.4261
2022-10-04 02:12:34 - train: epoch 0064, iter [00560, 01251], lr: 0.000213, loss: 0.4084
2022-10-04 02:12:52 - train: epoch 0064, iter [00570, 01251], lr: 0.000213, loss: 0.4233
2022-10-04 02:13:11 - train: epoch 0064, iter [00580, 01251], lr: 0.000213, loss: 0.4098
2022-10-04 02:13:30 - train: epoch 0064, iter [00590, 01251], lr: 0.000213, loss: 0.4004
2022-10-04 02:13:48 - train: epoch 0064, iter [00600, 01251], lr: 0.000212, loss: 0.3984
2022-10-04 02:14:07 - train: epoch 0064, iter [00610, 01251], lr: 0.000212, loss: 0.3914
2022-10-04 02:14:26 - train: epoch 0064, iter [00620, 01251], lr: 0.000212, loss: 0.3928
2022-10-04 02:14:44 - train: epoch 0064, iter [00630, 01251], lr: 0.000212, loss: 0.3883
2022-10-04 02:15:03 - train: epoch 0064, iter [00640, 01251], lr: 0.000212, loss: 0.3982
2022-10-04 02:15:22 - train: epoch 0064, iter [00650, 01251], lr: 0.000212, loss: 0.4190
2022-10-04 02:15:41 - train: epoch 0064, iter [00660, 01251], lr: 0.000212, loss: 0.4189
2022-10-04 02:16:00 - train: epoch 0064, iter [00670, 01251], lr: 0.000212, loss: 0.4140
2022-10-04 02:16:19 - train: epoch 0064, iter [00680, 01251], lr: 0.000212, loss: 0.4059
2022-10-04 02:16:37 - train: epoch 0064, iter [00690, 01251], lr: 0.000212, loss: 0.4062
2022-10-04 02:16:56 - train: epoch 0064, iter [00700, 01251], lr: 0.000212, loss: 0.3870
2022-10-04 02:17:15 - train: epoch 0064, iter [00710, 01251], lr: 0.000212, loss: 0.4088
2022-10-04 02:17:33 - train: epoch 0064, iter [00720, 01251], lr: 0.000212, loss: 0.4173
2022-10-04 02:17:52 - train: epoch 0064, iter [00730, 01251], lr: 0.000211, loss: 0.4078
2022-10-04 02:18:11 - train: epoch 0064, iter [00740, 01251], lr: 0.000211, loss: 0.4082
2022-10-04 02:18:29 - train: epoch 0064, iter [00750, 01251], lr: 0.000211, loss: 0.3991
2022-10-04 02:18:48 - train: epoch 0064, iter [00760, 01251], lr: 0.000211, loss: 0.3885
2022-10-04 02:19:07 - train: epoch 0064, iter [00770, 01251], lr: 0.000211, loss: 0.4003
2022-10-04 02:19:25 - train: epoch 0064, iter [00780, 01251], lr: 0.000211, loss: 0.3958
2022-10-04 02:19:44 - train: epoch 0064, iter [00790, 01251], lr: 0.000211, loss: 0.4165
2022-10-04 02:20:03 - train: epoch 0064, iter [00800, 01251], lr: 0.000211, loss: 0.4143
2022-10-04 02:20:22 - train: epoch 0064, iter [00810, 01251], lr: 0.000211, loss: 0.4194
2022-10-04 02:20:41 - train: epoch 0064, iter [00820, 01251], lr: 0.000211, loss: 0.4085
2022-10-04 02:21:00 - train: epoch 0064, iter [00830, 01251], lr: 0.000211, loss: 0.4034
2022-10-04 02:21:19 - train: epoch 0064, iter [00840, 01251], lr: 0.000211, loss: 0.4197
2022-10-04 02:21:37 - train: epoch 0064, iter [00850, 01251], lr: 0.000210, loss: 0.4169
2022-10-04 02:21:56 - train: epoch 0064, iter [00860, 01251], lr: 0.000210, loss: 0.4175
2022-10-04 02:22:15 - train: epoch 0064, iter [00870, 01251], lr: 0.000210, loss: 0.4108
2022-10-04 02:22:34 - train: epoch 0064, iter [00880, 01251], lr: 0.000210, loss: 0.3775
2022-10-04 02:22:52 - train: epoch 0064, iter [00890, 01251], lr: 0.000210, loss: 0.4027
2022-10-04 02:23:11 - train: epoch 0064, iter [00900, 01251], lr: 0.000210, loss: 0.4023
2022-10-04 02:23:29 - train: epoch 0064, iter [00910, 01251], lr: 0.000210, loss: 0.4067
2022-10-04 02:23:48 - train: epoch 0064, iter [00920, 01251], lr: 0.000210, loss: 0.4262
2022-10-04 02:24:07 - train: epoch 0064, iter [00930, 01251], lr: 0.000210, loss: 0.3969
2022-10-04 02:24:26 - train: epoch 0064, iter [00940, 01251], lr: 0.000210, loss: 0.3948
2022-10-04 02:24:45 - train: epoch 0064, iter [00950, 01251], lr: 0.000210, loss: 0.3888
2022-10-04 02:25:03 - train: epoch 0064, iter [00960, 01251], lr: 0.000210, loss: 0.4012
2022-10-04 02:25:22 - train: epoch 0064, iter [00970, 01251], lr: 0.000210, loss: 0.3894
2022-10-04 02:25:41 - train: epoch 0064, iter [00980, 01251], lr: 0.000209, loss: 0.3813
2022-10-04 02:26:00 - train: epoch 0064, iter [00990, 01251], lr: 0.000209, loss: 0.4243
2022-10-04 02:26:19 - train: epoch 0064, iter [01000, 01251], lr: 0.000209, loss: 0.3915
2022-10-04 02:26:38 - train: epoch 0064, iter [01010, 01251], lr: 0.000209, loss: 0.3994
2022-10-04 02:26:57 - train: epoch 0064, iter [01020, 01251], lr: 0.000209, loss: 0.4164
2022-10-04 02:27:16 - train: epoch 0064, iter [01030, 01251], lr: 0.000209, loss: 0.4165
2022-10-04 02:27:35 - train: epoch 0064, iter [01040, 01251], lr: 0.000209, loss: 0.4219
2022-10-04 02:27:54 - train: epoch 0064, iter [01050, 01251], lr: 0.000209, loss: 0.4057
2022-10-04 02:28:12 - train: epoch 0064, iter [01060, 01251], lr: 0.000209, loss: 0.4123
2022-10-04 02:28:31 - train: epoch 0064, iter [01070, 01251], lr: 0.000209, loss: 0.4087
2022-10-04 02:28:50 - train: epoch 0064, iter [01080, 01251], lr: 0.000209, loss: 0.4161
2022-10-04 02:29:08 - train: epoch 0064, iter [01090, 01251], lr: 0.000209, loss: 0.3991
2022-10-04 02:29:28 - train: epoch 0064, iter [01100, 01251], lr: 0.000208, loss: 0.3932
2022-10-04 02:29:47 - train: epoch 0064, iter [01110, 01251], lr: 0.000208, loss: 0.3869
2022-10-04 02:30:06 - train: epoch 0064, iter [01120, 01251], lr: 0.000208, loss: 0.4152
2022-10-04 02:30:24 - train: epoch 0064, iter [01130, 01251], lr: 0.000208, loss: 0.4084
2022-10-04 02:30:43 - train: epoch 0064, iter [01140, 01251], lr: 0.000208, loss: 0.4199
2022-10-04 02:31:02 - train: epoch 0064, iter [01150, 01251], lr: 0.000208, loss: 0.3879
2022-10-04 02:31:21 - train: epoch 0064, iter [01160, 01251], lr: 0.000208, loss: 0.4083
2022-10-04 02:31:40 - train: epoch 0064, iter [01170, 01251], lr: 0.000208, loss: 0.4218
2022-10-04 02:31:59 - train: epoch 0064, iter [01180, 01251], lr: 0.000208, loss: 0.4148
2022-10-04 02:32:17 - train: epoch 0064, iter [01190, 01251], lr: 0.000208, loss: 0.3976
2022-10-04 02:32:36 - train: epoch 0064, iter [01200, 01251], lr: 0.000208, loss: 0.4075
2022-10-04 02:32:55 - train: epoch 0064, iter [01210, 01251], lr: 0.000208, loss: 0.4094
2022-10-04 02:33:15 - train: epoch 0064, iter [01220, 01251], lr: 0.000208, loss: 0.3844
2022-10-04 02:33:34 - train: epoch 0064, iter [01230, 01251], lr: 0.000207, loss: 0.4113
2022-10-04 02:33:53 - train: epoch 0064, iter [01240, 01251], lr: 0.000207, loss: 0.4165
2022-10-04 02:34:11 - train: epoch 0064, iter [01250, 01251], lr: 0.000207, loss: 0.3928
2022-10-04 02:34:16 - train: epoch 064, train_loss: 0.4062
2022-10-04 02:34:20 - until epoch: 064, best_loss: 0.4062
2022-10-04 02:34:20 - epoch 065 lr: 0.000207
2022-10-04 02:34:45 - train: epoch 0065, iter [00010, 01251], lr: 0.000207, loss: 0.3861
2022-10-04 02:35:03 - train: epoch 0065, iter [00020, 01251], lr: 0.000207, loss: 0.4237
2022-10-04 02:35:22 - train: epoch 0065, iter [00030, 01251], lr: 0.000207, loss: 0.3806
2022-10-04 02:35:40 - train: epoch 0065, iter [00040, 01251], lr: 0.000207, loss: 0.3941
2022-10-04 02:35:58 - train: epoch 0065, iter [00050, 01251], lr: 0.000207, loss: 0.3877
2022-10-04 02:36:17 - train: epoch 0065, iter [00060, 01251], lr: 0.000207, loss: 0.3882
2022-10-04 02:36:35 - train: epoch 0065, iter [00070, 01251], lr: 0.000207, loss: 0.4116
2022-10-04 02:36:55 - train: epoch 0065, iter [00080, 01251], lr: 0.000207, loss: 0.4141
2022-10-04 02:37:13 - train: epoch 0065, iter [00090, 01251], lr: 0.000207, loss: 0.4092
2022-10-04 02:37:32 - train: epoch 0065, iter [00100, 01251], lr: 0.000206, loss: 0.4108
2022-10-04 02:37:51 - train: epoch 0065, iter [00110, 01251], lr: 0.000206, loss: 0.4086
2022-10-04 02:38:09 - train: epoch 0065, iter [00120, 01251], lr: 0.000206, loss: 0.4172
2022-10-04 02:38:28 - train: epoch 0065, iter [00130, 01251], lr: 0.000206, loss: 0.4067
2022-10-04 02:38:47 - train: epoch 0065, iter [00140, 01251], lr: 0.000206, loss: 0.4113
2022-10-04 02:39:06 - train: epoch 0065, iter [00150, 01251], lr: 0.000206, loss: 0.4085
2022-10-04 02:39:25 - train: epoch 0065, iter [00160, 01251], lr: 0.000206, loss: 0.4165
2022-10-04 02:39:43 - train: epoch 0065, iter [00170, 01251], lr: 0.000206, loss: 0.4085
2022-10-04 02:40:02 - train: epoch 0065, iter [00180, 01251], lr: 0.000206, loss: 0.3807
2022-10-04 02:40:20 - train: epoch 0065, iter [00190, 01251], lr: 0.000206, loss: 0.3931
2022-10-04 02:40:39 - train: epoch 0065, iter [00200, 01251], lr: 0.000206, loss: 0.4131
2022-10-04 02:40:59 - train: epoch 0065, iter [00210, 01251], lr: 0.000206, loss: 0.3912
2022-10-04 02:41:17 - train: epoch 0065, iter [00220, 01251], lr: 0.000206, loss: 0.4102
2022-10-04 02:41:36 - train: epoch 0065, iter [00230, 01251], lr: 0.000205, loss: 0.3944
2022-10-04 02:41:54 - train: epoch 0065, iter [00240, 01251], lr: 0.000205, loss: 0.3980
2022-10-04 02:42:13 - train: epoch 0065, iter [00250, 01251], lr: 0.000205, loss: 0.3982
2022-10-04 02:42:31 - train: epoch 0065, iter [00260, 01251], lr: 0.000205, loss: 0.3975
2022-10-04 02:42:50 - train: epoch 0065, iter [00270, 01251], lr: 0.000205, loss: 0.4000
2022-10-04 02:43:09 - train: epoch 0065, iter [00280, 01251], lr: 0.000205, loss: 0.4123
2022-10-04 02:43:27 - train: epoch 0065, iter [00290, 01251], lr: 0.000205, loss: 0.3950
2022-10-04 02:43:46 - train: epoch 0065, iter [00300, 01251], lr: 0.000205, loss: 0.3903
2022-10-04 02:44:05 - train: epoch 0065, iter [00310, 01251], lr: 0.000205, loss: 0.4078
2022-10-04 02:44:24 - train: epoch 0065, iter [00320, 01251], lr: 0.000205, loss: 0.3909
2022-10-04 02:44:43 - train: epoch 0065, iter [00330, 01251], lr: 0.000205, loss: 0.4060
2022-10-04 02:45:01 - train: epoch 0065, iter [00340, 01251], lr: 0.000205, loss: 0.3934
2022-10-04 02:45:20 - train: epoch 0065, iter [00350, 01251], lr: 0.000205, loss: 0.4041
2022-10-04 02:45:39 - train: epoch 0065, iter [00360, 01251], lr: 0.000204, loss: 0.3998
2022-10-04 02:45:57 - train: epoch 0065, iter [00370, 01251], lr: 0.000204, loss: 0.4078
2022-10-04 02:46:16 - train: epoch 0065, iter [00380, 01251], lr: 0.000204, loss: 0.4092
2022-10-04 02:46:35 - train: epoch 0065, iter [00390, 01251], lr: 0.000204, loss: 0.4007
2022-10-04 02:46:54 - train: epoch 0065, iter [00400, 01251], lr: 0.000204, loss: 0.4055
2022-10-04 02:47:13 - train: epoch 0065, iter [00410, 01251], lr: 0.000204, loss: 0.4175
2022-10-04 02:47:31 - train: epoch 0065, iter [00420, 01251], lr: 0.000204, loss: 0.3902
2022-10-04 02:47:50 - train: epoch 0065, iter [00430, 01251], lr: 0.000204, loss: 0.4123
2022-10-04 02:48:09 - train: epoch 0065, iter [00440, 01251], lr: 0.000204, loss: 0.4051
2022-10-04 02:48:28 - train: epoch 0065, iter [00450, 01251], lr: 0.000204, loss: 0.4154
2022-10-04 02:48:47 - train: epoch 0065, iter [00460, 01251], lr: 0.000204, loss: 0.3990
2022-10-04 02:49:06 - train: epoch 0065, iter [00470, 01251], lr: 0.000204, loss: 0.4113
2022-10-04 02:49:25 - train: epoch 0065, iter [00480, 01251], lr: 0.000203, loss: 0.4350
2022-10-04 02:49:43 - train: epoch 0065, iter [00490, 01251], lr: 0.000203, loss: 0.3998
2022-10-04 02:50:02 - train: epoch 0065, iter [00500, 01251], lr: 0.000203, loss: 0.4194
2022-10-04 02:50:21 - train: epoch 0065, iter [00510, 01251], lr: 0.000203, loss: 0.3981
2022-10-04 02:50:39 - train: epoch 0065, iter [00520, 01251], lr: 0.000203, loss: 0.3977
2022-10-04 02:50:59 - train: epoch 0065, iter [00530, 01251], lr: 0.000203, loss: 0.4019
2022-10-04 02:51:18 - train: epoch 0065, iter [00540, 01251], lr: 0.000203, loss: 0.4126
2022-10-04 02:51:36 - train: epoch 0065, iter [00550, 01251], lr: 0.000203, loss: 0.4028
2022-10-04 02:51:56 - train: epoch 0065, iter [00560, 01251], lr: 0.000203, loss: 0.4104
2022-10-04 02:52:14 - train: epoch 0065, iter [00570, 01251], lr: 0.000203, loss: 0.4178
2022-10-04 02:52:33 - train: epoch 0065, iter [00580, 01251], lr: 0.000203, loss: 0.4009
2022-10-04 02:52:52 - train: epoch 0065, iter [00590, 01251], lr: 0.000203, loss: 0.4003
2022-10-04 02:53:11 - train: epoch 0065, iter [00600, 01251], lr: 0.000203, loss: 0.3874
2022-10-04 02:53:30 - train: epoch 0065, iter [00610, 01251], lr: 0.000202, loss: 0.4105
2022-10-04 02:53:48 - train: epoch 0065, iter [00620, 01251], lr: 0.000202, loss: 0.4196
2022-10-04 02:54:07 - train: epoch 0065, iter [00630, 01251], lr: 0.000202, loss: 0.4001
2022-10-04 02:54:26 - train: epoch 0065, iter [00640, 01251], lr: 0.000202, loss: 0.4188
2022-10-04 02:54:45 - train: epoch 0065, iter [00650, 01251], lr: 0.000202, loss: 0.3890
2022-10-04 02:55:04 - train: epoch 0065, iter [00660, 01251], lr: 0.000202, loss: 0.3984
2022-10-04 02:55:23 - train: epoch 0065, iter [00670, 01251], lr: 0.000202, loss: 0.4185
2022-10-04 02:55:41 - train: epoch 0065, iter [00680, 01251], lr: 0.000202, loss: 0.3875
2022-10-04 02:56:00 - train: epoch 0065, iter [00690, 01251], lr: 0.000202, loss: 0.3883
2022-10-04 02:56:19 - train: epoch 0065, iter [00700, 01251], lr: 0.000202, loss: 0.4119
2022-10-04 02:56:38 - train: epoch 0065, iter [00710, 01251], lr: 0.000202, loss: 0.4017
2022-10-04 02:56:56 - train: epoch 0065, iter [00720, 01251], lr: 0.000202, loss: 0.3980
2022-10-04 02:57:15 - train: epoch 0065, iter [00730, 01251], lr: 0.000202, loss: 0.3888
2022-10-04 02:57:34 - train: epoch 0065, iter [00740, 01251], lr: 0.000201, loss: 0.3989
2022-10-04 02:57:53 - train: epoch 0065, iter [00750, 01251], lr: 0.000201, loss: 0.3887
2022-10-04 02:58:11 - train: epoch 0065, iter [00760, 01251], lr: 0.000201, loss: 0.3965
2022-10-04 02:58:30 - train: epoch 0065, iter [00770, 01251], lr: 0.000201, loss: 0.3930
2022-10-04 02:58:49 - train: epoch 0065, iter [00780, 01251], lr: 0.000201, loss: 0.4189
2022-10-04 02:59:08 - train: epoch 0065, iter [00790, 01251], lr: 0.000201, loss: 0.4030
2022-10-04 02:59:26 - train: epoch 0065, iter [00800, 01251], lr: 0.000201, loss: 0.4035
2022-10-04 02:59:45 - train: epoch 0065, iter [00810, 01251], lr: 0.000201, loss: 0.4163
2022-10-04 03:00:04 - train: epoch 0065, iter [00820, 01251], lr: 0.000201, loss: 0.3969
2022-10-04 03:00:22 - train: epoch 0065, iter [00830, 01251], lr: 0.000201, loss: 0.3930
2022-10-04 03:00:41 - train: epoch 0065, iter [00840, 01251], lr: 0.000201, loss: 0.3930
2022-10-04 03:01:00 - train: epoch 0065, iter [00850, 01251], lr: 0.000201, loss: 0.3943
2022-10-04 03:01:19 - train: epoch 0065, iter [00860, 01251], lr: 0.000200, loss: 0.4166
2022-10-04 03:01:38 - train: epoch 0065, iter [00870, 01251], lr: 0.000200, loss: 0.4112
2022-10-04 03:01:57 - train: epoch 0065, iter [00880, 01251], lr: 0.000200, loss: 0.4099
2022-10-04 03:02:15 - train: epoch 0065, iter [00890, 01251], lr: 0.000200, loss: 0.4004
2022-10-04 03:02:34 - train: epoch 0065, iter [00900, 01251], lr: 0.000200, loss: 0.4074
2022-10-04 03:02:53 - train: epoch 0065, iter [00910, 01251], lr: 0.000200, loss: 0.4027
2022-10-04 03:03:11 - train: epoch 0065, iter [00920, 01251], lr: 0.000200, loss: 0.3883
2022-10-04 03:03:30 - train: epoch 0065, iter [00930, 01251], lr: 0.000200, loss: 0.4070
2022-10-04 03:03:49 - train: epoch 0065, iter [00940, 01251], lr: 0.000200, loss: 0.4092
2022-10-04 03:04:07 - train: epoch 0065, iter [00950, 01251], lr: 0.000200, loss: 0.4034
2022-10-04 03:04:26 - train: epoch 0065, iter [00960, 01251], lr: 0.000200, loss: 0.4133
2022-10-04 03:04:45 - train: epoch 0065, iter [00970, 01251], lr: 0.000200, loss: 0.4132
2022-10-04 03:05:04 - train: epoch 0065, iter [00980, 01251], lr: 0.000200, loss: 0.4205
2022-10-04 03:05:22 - train: epoch 0065, iter [00990, 01251], lr: 0.000199, loss: 0.4043
2022-10-04 03:05:41 - train: epoch 0065, iter [01000, 01251], lr: 0.000199, loss: 0.4241
2022-10-04 03:06:00 - train: epoch 0065, iter [01010, 01251], lr: 0.000199, loss: 0.4078
2022-10-04 03:06:19 - train: epoch 0065, iter [01020, 01251], lr: 0.000199, loss: 0.4002
2022-10-04 03:06:38 - train: epoch 0065, iter [01030, 01251], lr: 0.000199, loss: 0.4030
2022-10-04 03:06:57 - train: epoch 0065, iter [01040, 01251], lr: 0.000199, loss: 0.4018
2022-10-04 03:07:16 - train: epoch 0065, iter [01050, 01251], lr: 0.000199, loss: 0.4169
2022-10-04 03:07:34 - train: epoch 0065, iter [01060, 01251], lr: 0.000199, loss: 0.4024
2022-10-04 03:07:53 - train: epoch 0065, iter [01070, 01251], lr: 0.000199, loss: 0.3866
2022-10-04 03:08:12 - train: epoch 0065, iter [01080, 01251], lr: 0.000199, loss: 0.4014
2022-10-04 03:08:31 - train: epoch 0065, iter [01090, 01251], lr: 0.000199, loss: 0.3843
2022-10-04 03:08:50 - train: epoch 0065, iter [01100, 01251], lr: 0.000199, loss: 0.4055
2022-10-04 03:09:09 - train: epoch 0065, iter [01110, 01251], lr: 0.000199, loss: 0.3969
2022-10-04 03:09:28 - train: epoch 0065, iter [01120, 01251], lr: 0.000198, loss: 0.4145
2022-10-04 03:09:46 - train: epoch 0065, iter [01130, 01251], lr: 0.000198, loss: 0.3939
2022-10-04 03:10:05 - train: epoch 0065, iter [01140, 01251], lr: 0.000198, loss: 0.3967
2022-10-04 03:10:24 - train: epoch 0065, iter [01150, 01251], lr: 0.000198, loss: 0.3907
2022-10-04 03:10:43 - train: epoch 0065, iter [01160, 01251], lr: 0.000198, loss: 0.4036
2022-10-04 03:11:01 - train: epoch 0065, iter [01170, 01251], lr: 0.000198, loss: 0.3918
2022-10-04 03:11:20 - train: epoch 0065, iter [01180, 01251], lr: 0.000198, loss: 0.4007
2022-10-04 03:11:39 - train: epoch 0065, iter [01190, 01251], lr: 0.000198, loss: 0.4118
2022-10-04 03:11:58 - train: epoch 0065, iter [01200, 01251], lr: 0.000198, loss: 0.4224
2022-10-04 03:12:17 - train: epoch 0065, iter [01210, 01251], lr: 0.000198, loss: 0.4022
2022-10-04 03:12:35 - train: epoch 0065, iter [01220, 01251], lr: 0.000198, loss: 0.3945
2022-10-04 03:12:54 - train: epoch 0065, iter [01230, 01251], lr: 0.000198, loss: 0.4129
2022-10-04 03:13:13 - train: epoch 0065, iter [01240, 01251], lr: 0.000197, loss: 0.4290
2022-10-04 03:13:31 - train: epoch 0065, iter [01250, 01251], lr: 0.000197, loss: 0.4042
2022-10-04 03:13:36 - train: epoch 065, train_loss: 0.4059
2022-10-04 03:13:41 - until epoch: 065, best_loss: 0.4059
2022-10-04 03:13:41 - epoch 066 lr: 0.000197
2022-10-04 03:14:06 - train: epoch 0066, iter [00010, 01251], lr: 0.000197, loss: 0.4007
2022-10-04 03:14:24 - train: epoch 0066, iter [00020, 01251], lr: 0.000197, loss: 0.3957
2022-10-04 03:14:43 - train: epoch 0066, iter [00030, 01251], lr: 0.000197, loss: 0.4025
2022-10-04 03:15:01 - train: epoch 0066, iter [00040, 01251], lr: 0.000197, loss: 0.4085
2022-10-04 03:15:19 - train: epoch 0066, iter [00050, 01251], lr: 0.000197, loss: 0.4035
2022-10-04 03:15:38 - train: epoch 0066, iter [00060, 01251], lr: 0.000197, loss: 0.3944
2022-10-04 03:15:57 - train: epoch 0066, iter [00070, 01251], lr: 0.000197, loss: 0.3993
2022-10-04 03:16:16 - train: epoch 0066, iter [00080, 01251], lr: 0.000197, loss: 0.3988
2022-10-04 03:16:34 - train: epoch 0066, iter [00090, 01251], lr: 0.000197, loss: 0.4131
2022-10-04 03:16:53 - train: epoch 0066, iter [00100, 01251], lr: 0.000197, loss: 0.3930
2022-10-04 03:17:12 - train: epoch 0066, iter [00110, 01251], lr: 0.000197, loss: 0.4284
2022-10-04 03:17:31 - train: epoch 0066, iter [00120, 01251], lr: 0.000196, loss: 0.4118
2022-10-04 03:17:50 - train: epoch 0066, iter [00130, 01251], lr: 0.000196, loss: 0.4029
2022-10-04 03:18:08 - train: epoch 0066, iter [00140, 01251], lr: 0.000196, loss: 0.3818
2022-10-04 03:18:27 - train: epoch 0066, iter [00150, 01251], lr: 0.000196, loss: 0.4070
2022-10-04 03:18:46 - train: epoch 0066, iter [00160, 01251], lr: 0.000196, loss: 0.3969
2022-10-04 03:19:05 - train: epoch 0066, iter [00170, 01251], lr: 0.000196, loss: 0.4114
2022-10-04 03:19:23 - train: epoch 0066, iter [00180, 01251], lr: 0.000196, loss: 0.4094
2022-10-04 03:19:42 - train: epoch 0066, iter [00190, 01251], lr: 0.000196, loss: 0.4136
2022-10-04 03:20:00 - train: epoch 0066, iter [00200, 01251], lr: 0.000196, loss: 0.4051
2022-10-04 03:20:19 - train: epoch 0066, iter [00210, 01251], lr: 0.000196, loss: 0.4072
2022-10-04 03:20:37 - train: epoch 0066, iter [00220, 01251], lr: 0.000196, loss: 0.4115
2022-10-04 03:20:56 - train: epoch 0066, iter [00230, 01251], lr: 0.000196, loss: 0.3887
2022-10-04 03:21:15 - train: epoch 0066, iter [00240, 01251], lr: 0.000196, loss: 0.4089
2022-10-04 03:21:33 - train: epoch 0066, iter [00250, 01251], lr: 0.000195, loss: 0.4148
2022-10-04 03:21:52 - train: epoch 0066, iter [00260, 01251], lr: 0.000195, loss: 0.4016
2022-10-04 03:22:11 - train: epoch 0066, iter [00270, 01251], lr: 0.000195, loss: 0.3961
2022-10-04 03:22:30 - train: epoch 0066, iter [00280, 01251], lr: 0.000195, loss: 0.4013
2022-10-04 03:22:49 - train: epoch 0066, iter [00290, 01251], lr: 0.000195, loss: 0.3944
2022-10-04 03:23:09 - train: epoch 0066, iter [00300, 01251], lr: 0.000195, loss: 0.4178
2022-10-04 03:23:28 - train: epoch 0066, iter [00310, 01251], lr: 0.000195, loss: 0.4123
2022-10-04 03:23:46 - train: epoch 0066, iter [00320, 01251], lr: 0.000195, loss: 0.4194
2022-10-04 03:24:05 - train: epoch 0066, iter [00330, 01251], lr: 0.000195, loss: 0.3945
2022-10-04 03:24:24 - train: epoch 0066, iter [00340, 01251], lr: 0.000195, loss: 0.3984
2022-10-04 03:24:42 - train: epoch 0066, iter [00350, 01251], lr: 0.000195, loss: 0.4026
2022-10-04 03:25:01 - train: epoch 0066, iter [00360, 01251], lr: 0.000195, loss: 0.4061
2022-10-04 03:25:20 - train: epoch 0066, iter [00370, 01251], lr: 0.000194, loss: 0.3896
2022-10-04 03:25:39 - train: epoch 0066, iter [00380, 01251], lr: 0.000194, loss: 0.4126
2022-10-04 03:25:58 - train: epoch 0066, iter [00390, 01251], lr: 0.000194, loss: 0.4118
2022-10-04 03:26:17 - train: epoch 0066, iter [00400, 01251], lr: 0.000194, loss: 0.4021
2022-10-04 03:26:36 - train: epoch 0066, iter [00410, 01251], lr: 0.000194, loss: 0.4068
2022-10-04 03:26:55 - train: epoch 0066, iter [00420, 01251], lr: 0.000194, loss: 0.4017
2022-10-04 03:27:14 - train: epoch 0066, iter [00430, 01251], lr: 0.000194, loss: 0.3870
2022-10-04 03:27:33 - train: epoch 0066, iter [00440, 01251], lr: 0.000194, loss: 0.4138
2022-10-04 03:27:52 - train: epoch 0066, iter [00450, 01251], lr: 0.000194, loss: 0.4209
2022-10-04 03:28:11 - train: epoch 0066, iter [00460, 01251], lr: 0.000194, loss: 0.4223
2022-10-04 03:28:29 - train: epoch 0066, iter [00470, 01251], lr: 0.000194, loss: 0.4175
2022-10-04 03:28:48 - train: epoch 0066, iter [00480, 01251], lr: 0.000194, loss: 0.3965
2022-10-04 03:29:07 - train: epoch 0066, iter [00490, 01251], lr: 0.000194, loss: 0.3915
2022-10-04 03:29:26 - train: epoch 0066, iter [00500, 01251], lr: 0.000193, loss: 0.4050
2022-10-04 03:29:44 - train: epoch 0066, iter [00510, 01251], lr: 0.000193, loss: 0.3961
2022-10-04 03:30:03 - train: epoch 0066, iter [00520, 01251], lr: 0.000193, loss: 0.4220
2022-10-04 03:30:21 - train: epoch 0066, iter [00530, 01251], lr: 0.000193, loss: 0.4106
2022-10-04 03:30:40 - train: epoch 0066, iter [00540, 01251], lr: 0.000193, loss: 0.4201
2022-10-04 03:30:59 - train: epoch 0066, iter [00550, 01251], lr: 0.000193, loss: 0.4153
2022-10-04 03:31:18 - train: epoch 0066, iter [00560, 01251], lr: 0.000193, loss: 0.3871
2022-10-04 03:31:36 - train: epoch 0066, iter [00570, 01251], lr: 0.000193, loss: 0.4078
2022-10-04 03:31:55 - train: epoch 0066, iter [00580, 01251], lr: 0.000193, loss: 0.3871
2022-10-04 03:32:14 - train: epoch 0066, iter [00590, 01251], lr: 0.000193, loss: 0.4053
2022-10-04 03:32:33 - train: epoch 0066, iter [00600, 01251], lr: 0.000193, loss: 0.3908
2022-10-04 03:32:51 - train: epoch 0066, iter [00610, 01251], lr: 0.000193, loss: 0.4025
2022-10-04 03:33:10 - train: epoch 0066, iter [00620, 01251], lr: 0.000193, loss: 0.4128
2022-10-04 03:33:29 - train: epoch 0066, iter [00630, 01251], lr: 0.000192, loss: 0.4052
2022-10-04 03:33:47 - train: epoch 0066, iter [00640, 01251], lr: 0.000192, loss: 0.4071
2022-10-04 03:34:06 - train: epoch 0066, iter [00650, 01251], lr: 0.000192, loss: 0.3916
2022-10-04 03:34:25 - train: epoch 0066, iter [00660, 01251], lr: 0.000192, loss: 0.3975
2022-10-04 03:34:44 - train: epoch 0066, iter [00670, 01251], lr: 0.000192, loss: 0.4131
2022-10-04 03:35:02 - train: epoch 0066, iter [00680, 01251], lr: 0.000192, loss: 0.3971
2022-10-04 03:35:21 - train: epoch 0066, iter [00690, 01251], lr: 0.000192, loss: 0.4126
2022-10-04 03:35:40 - train: epoch 0066, iter [00700, 01251], lr: 0.000192, loss: 0.4223
2022-10-04 03:35:59 - train: epoch 0066, iter [00710, 01251], lr: 0.000192, loss: 0.3824
2022-10-04 03:36:18 - train: epoch 0066, iter [00720, 01251], lr: 0.000192, loss: 0.3962
2022-10-04 03:36:37 - train: epoch 0066, iter [00730, 01251], lr: 0.000192, loss: 0.4205
2022-10-04 03:36:55 - train: epoch 0066, iter [00740, 01251], lr: 0.000192, loss: 0.4109
2022-10-04 03:37:14 - train: epoch 0066, iter [00750, 01251], lr: 0.000192, loss: 0.4199
2022-10-04 03:37:33 - train: epoch 0066, iter [00760, 01251], lr: 0.000191, loss: 0.3872
2022-10-04 03:37:52 - train: epoch 0066, iter [00770, 01251], lr: 0.000191, loss: 0.4005
2022-10-04 03:38:10 - train: epoch 0066, iter [00780, 01251], lr: 0.000191, loss: 0.4152
2022-10-04 03:38:29 - train: epoch 0066, iter [00790, 01251], lr: 0.000191, loss: 0.4144
2022-10-04 03:38:48 - train: epoch 0066, iter [00800, 01251], lr: 0.000191, loss: 0.3962
2022-10-04 03:39:07 - train: epoch 0066, iter [00810, 01251], lr: 0.000191, loss: 0.4152
2022-10-04 03:39:25 - train: epoch 0066, iter [00820, 01251], lr: 0.000191, loss: 0.4176
2022-10-04 03:39:44 - train: epoch 0066, iter [00830, 01251], lr: 0.000191, loss: 0.4080
2022-10-04 03:40:02 - train: epoch 0066, iter [00840, 01251], lr: 0.000191, loss: 0.4094
2022-10-04 03:40:21 - train: epoch 0066, iter [00850, 01251], lr: 0.000191, loss: 0.4160
2022-10-04 03:40:40 - train: epoch 0066, iter [00860, 01251], lr: 0.000191, loss: 0.4008
2022-10-04 03:40:59 - train: epoch 0066, iter [00870, 01251], lr: 0.000191, loss: 0.4181
2022-10-04 03:41:17 - train: epoch 0066, iter [00880, 01251], lr: 0.000191, loss: 0.3965
2022-10-04 03:41:36 - train: epoch 0066, iter [00890, 01251], lr: 0.000190, loss: 0.3999
2022-10-04 03:41:55 - train: epoch 0066, iter [00900, 01251], lr: 0.000190, loss: 0.4062
2022-10-04 03:42:13 - train: epoch 0066, iter [00910, 01251], lr: 0.000190, loss: 0.3980
2022-10-04 03:42:32 - train: epoch 0066, iter [00920, 01251], lr: 0.000190, loss: 0.3884
2022-10-04 03:42:51 - train: epoch 0066, iter [00930, 01251], lr: 0.000190, loss: 0.4130
2022-10-04 03:43:10 - train: epoch 0066, iter [00940, 01251], lr: 0.000190, loss: 0.4129
2022-10-04 03:43:28 - train: epoch 0066, iter [00950, 01251], lr: 0.000190, loss: 0.4157
2022-10-04 03:43:47 - train: epoch 0066, iter [00960, 01251], lr: 0.000190, loss: 0.3936
2022-10-04 03:44:06 - train: epoch 0066, iter [00970, 01251], lr: 0.000190, loss: 0.3964
2022-10-04 03:44:24 - train: epoch 0066, iter [00980, 01251], lr: 0.000190, loss: 0.4013
2022-10-04 03:44:43 - train: epoch 0066, iter [00990, 01251], lr: 0.000190, loss: 0.4125
2022-10-04 03:45:02 - train: epoch 0066, iter [01000, 01251], lr: 0.000190, loss: 0.3907
2022-10-04 03:45:20 - train: epoch 0066, iter [01010, 01251], lr: 0.000189, loss: 0.4069
2022-10-04 03:45:39 - train: epoch 0066, iter [01020, 01251], lr: 0.000189, loss: 0.4131
2022-10-04 03:45:58 - train: epoch 0066, iter [01030, 01251], lr: 0.000189, loss: 0.3945
2022-10-04 03:46:16 - train: epoch 0066, iter [01040, 01251], lr: 0.000189, loss: 0.4121
2022-10-04 03:46:35 - train: epoch 0066, iter [01050, 01251], lr: 0.000189, loss: 0.4069
2022-10-04 03:46:54 - train: epoch 0066, iter [01060, 01251], lr: 0.000189, loss: 0.3920
2022-10-04 03:47:13 - train: epoch 0066, iter [01070, 01251], lr: 0.000189, loss: 0.4079
2022-10-04 03:47:32 - train: epoch 0066, iter [01080, 01251], lr: 0.000189, loss: 0.4079
2022-10-04 03:47:50 - train: epoch 0066, iter [01090, 01251], lr: 0.000189, loss: 0.4216
2022-10-04 03:48:09 - train: epoch 0066, iter [01100, 01251], lr: 0.000189, loss: 0.4078
2022-10-04 03:48:28 - train: epoch 0066, iter [01110, 01251], lr: 0.000189, loss: 0.4149
2022-10-04 03:48:47 - train: epoch 0066, iter [01120, 01251], lr: 0.000189, loss: 0.3965
2022-10-04 03:49:06 - train: epoch 0066, iter [01130, 01251], lr: 0.000189, loss: 0.4124
2022-10-04 03:49:25 - train: epoch 0066, iter [01140, 01251], lr: 0.000188, loss: 0.4148
2022-10-04 03:49:43 - train: epoch 0066, iter [01150, 01251], lr: 0.000188, loss: 0.4177
2022-10-04 03:50:03 - train: epoch 0066, iter [01160, 01251], lr: 0.000188, loss: 0.3861
2022-10-04 03:50:21 - train: epoch 0066, iter [01170, 01251], lr: 0.000188, loss: 0.4163
2022-10-04 03:50:40 - train: epoch 0066, iter [01180, 01251], lr: 0.000188, loss: 0.4164
2022-10-04 03:50:59 - train: epoch 0066, iter [01190, 01251], lr: 0.000188, loss: 0.4065
2022-10-04 03:51:18 - train: epoch 0066, iter [01200, 01251], lr: 0.000188, loss: 0.3964
2022-10-04 03:51:37 - train: epoch 0066, iter [01210, 01251], lr: 0.000188, loss: 0.4022
2022-10-04 03:51:55 - train: epoch 0066, iter [01220, 01251], lr: 0.000188, loss: 0.3865
2022-10-04 03:52:14 - train: epoch 0066, iter [01230, 01251], lr: 0.000188, loss: 0.4127
2022-10-04 03:52:33 - train: epoch 0066, iter [01240, 01251], lr: 0.000188, loss: 0.4169
2022-10-04 03:52:51 - train: epoch 0066, iter [01250, 01251], lr: 0.000188, loss: 0.4153
2022-10-04 03:52:56 - train: epoch 066, train_loss: 0.4055
2022-10-04 03:53:01 - until epoch: 066, best_loss: 0.4055
2022-10-04 03:53:01 - epoch 067 lr: 0.000188
2022-10-04 03:53:25 - train: epoch 0067, iter [00010, 01251], lr: 0.000188, loss: 0.3875
2022-10-04 03:53:43 - train: epoch 0067, iter [00020, 01251], lr: 0.000187, loss: 0.4053
2022-10-04 03:54:02 - train: epoch 0067, iter [00030, 01251], lr: 0.000187, loss: 0.4016
2022-10-04 03:54:20 - train: epoch 0067, iter [00040, 01251], lr: 0.000187, loss: 0.3904
2022-10-04 03:54:39 - train: epoch 0067, iter [00050, 01251], lr: 0.000187, loss: 0.4016
2022-10-04 03:54:57 - train: epoch 0067, iter [00060, 01251], lr: 0.000187, loss: 0.4117
2022-10-04 03:55:16 - train: epoch 0067, iter [00070, 01251], lr: 0.000187, loss: 0.4047
2022-10-04 03:55:35 - train: epoch 0067, iter [00080, 01251], lr: 0.000187, loss: 0.3943
2022-10-04 03:55:53 - train: epoch 0067, iter [00090, 01251], lr: 0.000187, loss: 0.3964
2022-10-04 03:56:12 - train: epoch 0067, iter [00100, 01251], lr: 0.000187, loss: 0.4001
2022-10-04 03:56:31 - train: epoch 0067, iter [00110, 01251], lr: 0.000187, loss: 0.4087
2022-10-04 03:56:49 - train: epoch 0067, iter [00120, 01251], lr: 0.000187, loss: 0.3902
2022-10-04 03:57:08 - train: epoch 0067, iter [00130, 01251], lr: 0.000187, loss: 0.4100
2022-10-04 03:57:27 - train: epoch 0067, iter [00140, 01251], lr: 0.000187, loss: 0.4182
2022-10-04 03:57:46 - train: epoch 0067, iter [00150, 01251], lr: 0.000186, loss: 0.3997
2022-10-04 03:58:05 - train: epoch 0067, iter [00160, 01251], lr: 0.000186, loss: 0.4090
2022-10-04 03:58:23 - train: epoch 0067, iter [00170, 01251], lr: 0.000186, loss: 0.3808
2022-10-04 03:58:42 - train: epoch 0067, iter [00180, 01251], lr: 0.000186, loss: 0.4027
2022-10-04 03:59:01 - train: epoch 0067, iter [00190, 01251], lr: 0.000186, loss: 0.4129
2022-10-04 03:59:20 - train: epoch 0067, iter [00200, 01251], lr: 0.000186, loss: 0.4002
2022-10-04 03:59:39 - train: epoch 0067, iter [00210, 01251], lr: 0.000186, loss: 0.4064
2022-10-04 03:59:58 - train: epoch 0067, iter [00220, 01251], lr: 0.000186, loss: 0.3902
2022-10-04 04:00:16 - train: epoch 0067, iter [00230, 01251], lr: 0.000186, loss: 0.4112
2022-10-04 04:00:35 - train: epoch 0067, iter [00240, 01251], lr: 0.000186, loss: 0.3930
2022-10-04 04:00:53 - train: epoch 0067, iter [00250, 01251], lr: 0.000186, loss: 0.3920
2022-10-04 04:01:12 - train: epoch 0067, iter [00260, 01251], lr: 0.000186, loss: 0.4044
2022-10-04 04:01:31 - train: epoch 0067, iter [00270, 01251], lr: 0.000186, loss: 0.3997
2022-10-04 04:01:50 - train: epoch 0067, iter [00280, 01251], lr: 0.000185, loss: 0.4177
2022-10-04 04:02:08 - train: epoch 0067, iter [00290, 01251], lr: 0.000185, loss: 0.4066
2022-10-04 04:02:27 - train: epoch 0067, iter [00300, 01251], lr: 0.000185, loss: 0.4225
2022-10-04 04:02:46 - train: epoch 0067, iter [00310, 01251], lr: 0.000185, loss: 0.3996
2022-10-04 04:03:04 - train: epoch 0067, iter [00320, 01251], lr: 0.000185, loss: 0.3995
2022-10-04 04:03:23 - train: epoch 0067, iter [00330, 01251], lr: 0.000185, loss: 0.4221
2022-10-04 04:03:42 - train: epoch 0067, iter [00340, 01251], lr: 0.000185, loss: 0.4100
2022-10-04 04:04:01 - train: epoch 0067, iter [00350, 01251], lr: 0.000185, loss: 0.3930
2022-10-04 04:04:20 - train: epoch 0067, iter [00360, 01251], lr: 0.000185, loss: 0.4033
2022-10-04 04:04:38 - train: epoch 0067, iter [00370, 01251], lr: 0.000185, loss: 0.4005
2022-10-04 04:04:57 - train: epoch 0067, iter [00380, 01251], lr: 0.000185, loss: 0.4040
2022-10-04 04:05:15 - train: epoch 0067, iter [00390, 01251], lr: 0.000185, loss: 0.4015
2022-10-04 04:05:35 - train: epoch 0067, iter [00400, 01251], lr: 0.000185, loss: 0.4170
2022-10-04 04:05:54 - train: epoch 0067, iter [00410, 01251], lr: 0.000184, loss: 0.4003
2022-10-04 04:06:12 - train: epoch 0067, iter [00420, 01251], lr: 0.000184, loss: 0.4147
2022-10-04 04:06:31 - train: epoch 0067, iter [00430, 01251], lr: 0.000184, loss: 0.4058
2022-10-04 04:06:50 - train: epoch 0067, iter [00440, 01251], lr: 0.000184, loss: 0.4166
2022-10-04 04:07:09 - train: epoch 0067, iter [00450, 01251], lr: 0.000184, loss: 0.4199
2022-10-04 04:07:28 - train: epoch 0067, iter [00460, 01251], lr: 0.000184, loss: 0.4024
2022-10-04 04:07:46 - train: epoch 0067, iter [00470, 01251], lr: 0.000184, loss: 0.3755
2022-10-04 04:08:05 - train: epoch 0067, iter [00480, 01251], lr: 0.000184, loss: 0.4021
2022-10-04 04:08:24 - train: epoch 0067, iter [00490, 01251], lr: 0.000184, loss: 0.4045
2022-10-04 04:08:42 - train: epoch 0067, iter [00500, 01251], lr: 0.000184, loss: 0.4064
2022-10-04 04:09:01 - train: epoch 0067, iter [00510, 01251], lr: 0.000184, loss: 0.4082
2022-10-04 04:09:20 - train: epoch 0067, iter [00520, 01251], lr: 0.000184, loss: 0.4178
2022-10-04 04:09:39 - train: epoch 0067, iter [00530, 01251], lr: 0.000184, loss: 0.3978
2022-10-04 04:09:57 - train: epoch 0067, iter [00540, 01251], lr: 0.000183, loss: 0.3915
2022-10-04 04:10:16 - train: epoch 0067, iter [00550, 01251], lr: 0.000183, loss: 0.4218
2022-10-04 04:10:35 - train: epoch 0067, iter [00560, 01251], lr: 0.000183, loss: 0.3930
2022-10-04 04:10:54 - train: epoch 0067, iter [00570, 01251], lr: 0.000183, loss: 0.3886
2022-10-04 04:11:12 - train: epoch 0067, iter [00580, 01251], lr: 0.000183, loss: 0.4102
2022-10-04 04:11:31 - train: epoch 0067, iter [00590, 01251], lr: 0.000183, loss: 0.4152
2022-10-04 04:11:49 - train: epoch 0067, iter [00600, 01251], lr: 0.000183, loss: 0.4123
2022-10-04 04:12:08 - train: epoch 0067, iter [00610, 01251], lr: 0.000183, loss: 0.4063
2022-10-04 04:12:27 - train: epoch 0067, iter [00620, 01251], lr: 0.000183, loss: 0.4137
2022-10-04 04:12:46 - train: epoch 0067, iter [00630, 01251], lr: 0.000183, loss: 0.4073
2022-10-04 04:13:04 - train: epoch 0067, iter [00640, 01251], lr: 0.000183, loss: 0.4008
2022-10-04 04:13:23 - train: epoch 0067, iter [00650, 01251], lr: 0.000183, loss: 0.3850
2022-10-04 04:13:42 - train: epoch 0067, iter [00660, 01251], lr: 0.000183, loss: 0.4165
2022-10-04 04:14:01 - train: epoch 0067, iter [00670, 01251], lr: 0.000182, loss: 0.4351
2022-10-04 04:14:20 - train: epoch 0067, iter [00680, 01251], lr: 0.000182, loss: 0.4134
2022-10-04 04:14:38 - train: epoch 0067, iter [00690, 01251], lr: 0.000182, loss: 0.4141
2022-10-04 04:14:57 - train: epoch 0067, iter [00700, 01251], lr: 0.000182, loss: 0.4032
2022-10-04 04:15:16 - train: epoch 0067, iter [00710, 01251], lr: 0.000182, loss: 0.3942
2022-10-04 04:15:35 - train: epoch 0067, iter [00720, 01251], lr: 0.000182, loss: 0.4090
2022-10-04 04:15:53 - train: epoch 0067, iter [00730, 01251], lr: 0.000182, loss: 0.4104
2022-10-04 04:16:13 - train: epoch 0067, iter [00740, 01251], lr: 0.000182, loss: 0.4129
2022-10-04 04:16:31 - train: epoch 0067, iter [00750, 01251], lr: 0.000182, loss: 0.4214
2022-10-04 04:16:50 - train: epoch 0067, iter [00760, 01251], lr: 0.000182, loss: 0.4107
2022-10-04 04:17:08 - train: epoch 0067, iter [00770, 01251], lr: 0.000182, loss: 0.3945
2022-10-04 04:17:27 - train: epoch 0067, iter [00780, 01251], lr: 0.000182, loss: 0.4110
2022-10-04 04:17:46 - train: epoch 0067, iter [00790, 01251], lr: 0.000182, loss: 0.3969
2022-10-04 04:18:04 - train: epoch 0067, iter [00800, 01251], lr: 0.000181, loss: 0.4215
2022-10-04 04:18:23 - train: epoch 0067, iter [00810, 01251], lr: 0.000181, loss: 0.3864
2022-10-04 04:18:42 - train: epoch 0067, iter [00820, 01251], lr: 0.000181, loss: 0.3890
2022-10-04 04:19:00 - train: epoch 0067, iter [00830, 01251], lr: 0.000181, loss: 0.4182
2022-10-04 04:19:19 - train: epoch 0067, iter [00840, 01251], lr: 0.000181, loss: 0.4060
2022-10-04 04:19:38 - train: epoch 0067, iter [00850, 01251], lr: 0.000181, loss: 0.4136
2022-10-04 04:19:57 - train: epoch 0067, iter [00860, 01251], lr: 0.000181, loss: 0.4147
2022-10-04 04:20:16 - train: epoch 0067, iter [00870, 01251], lr: 0.000181, loss: 0.3912
2022-10-04 04:20:35 - train: epoch 0067, iter [00880, 01251], lr: 0.000181, loss: 0.3973
2022-10-04 04:20:53 - train: epoch 0067, iter [00890, 01251], lr: 0.000181, loss: 0.4012
2022-10-04 04:21:12 - train: epoch 0067, iter [00900, 01251], lr: 0.000181, loss: 0.4090
2022-10-04 04:21:31 - train: epoch 0067, iter [00910, 01251], lr: 0.000181, loss: 0.4105
2022-10-04 04:21:50 - train: epoch 0067, iter [00920, 01251], lr: 0.000181, loss: 0.3903
2022-10-04 04:22:08 - train: epoch 0067, iter [00930, 01251], lr: 0.000180, loss: 0.4141
2022-10-04 04:22:27 - train: epoch 0067, iter [00940, 01251], lr: 0.000180, loss: 0.4160
2022-10-04 04:22:46 - train: epoch 0067, iter [00950, 01251], lr: 0.000180, loss: 0.4012
2022-10-04 04:23:05 - train: epoch 0067, iter [00960, 01251], lr: 0.000180, loss: 0.3822
2022-10-04 04:23:24 - train: epoch 0067, iter [00970, 01251], lr: 0.000180, loss: 0.4324
2022-10-04 04:23:43 - train: epoch 0067, iter [00980, 01251], lr: 0.000180, loss: 0.4163
2022-10-04 04:24:02 - train: epoch 0067, iter [00990, 01251], lr: 0.000180, loss: 0.3954
2022-10-04 04:24:21 - train: epoch 0067, iter [01000, 01251], lr: 0.000180, loss: 0.4086
2022-10-04 04:24:40 - train: epoch 0067, iter [01010, 01251], lr: 0.000180, loss: 0.4151
2022-10-04 04:24:58 - train: epoch 0067, iter [01020, 01251], lr: 0.000180, loss: 0.3913
2022-10-04 04:25:17 - train: epoch 0067, iter [01030, 01251], lr: 0.000180, loss: 0.4117
2022-10-04 04:25:36 - train: epoch 0067, iter [01040, 01251], lr: 0.000180, loss: 0.4017
2022-10-04 04:25:55 - train: epoch 0067, iter [01050, 01251], lr: 0.000180, loss: 0.4244
2022-10-04 04:26:13 - train: epoch 0067, iter [01060, 01251], lr: 0.000179, loss: 0.4299
2022-10-04 04:26:32 - train: epoch 0067, iter [01070, 01251], lr: 0.000179, loss: 0.3922
2022-10-04 04:26:51 - train: epoch 0067, iter [01080, 01251], lr: 0.000179, loss: 0.4338
2022-10-04 04:27:09 - train: epoch 0067, iter [01090, 01251], lr: 0.000179, loss: 0.4011
2022-10-04 04:27:28 - train: epoch 0067, iter [01100, 01251], lr: 0.000179, loss: 0.3953
2022-10-04 04:27:47 - train: epoch 0067, iter [01110, 01251], lr: 0.000179, loss: 0.3991
2022-10-04 04:28:06 - train: epoch 0067, iter [01120, 01251], lr: 0.000179, loss: 0.3965
2022-10-04 04:28:24 - train: epoch 0067, iter [01130, 01251], lr: 0.000179, loss: 0.3869
2022-10-04 04:28:43 - train: epoch 0067, iter [01140, 01251], lr: 0.000179, loss: 0.4071
2022-10-04 04:29:02 - train: epoch 0067, iter [01150, 01251], lr: 0.000179, loss: 0.4138
2022-10-04 04:29:20 - train: epoch 0067, iter [01160, 01251], lr: 0.000179, loss: 0.4167
2022-10-04 04:29:39 - train: epoch 0067, iter [01170, 01251], lr: 0.000179, loss: 0.3836
2022-10-04 04:29:58 - train: epoch 0067, iter [01180, 01251], lr: 0.000179, loss: 0.4020
2022-10-04 04:30:17 - train: epoch 0067, iter [01190, 01251], lr: 0.000178, loss: 0.4086
2022-10-04 04:30:36 - train: epoch 0067, iter [01200, 01251], lr: 0.000178, loss: 0.3905
2022-10-04 04:30:55 - train: epoch 0067, iter [01210, 01251], lr: 0.000178, loss: 0.4014
2022-10-04 04:31:14 - train: epoch 0067, iter [01220, 01251], lr: 0.000178, loss: 0.4119
2022-10-04 04:31:33 - train: epoch 0067, iter [01230, 01251], lr: 0.000178, loss: 0.4157
2022-10-04 04:31:52 - train: epoch 0067, iter [01240, 01251], lr: 0.000178, loss: 0.4132
2022-10-04 04:32:10 - train: epoch 0067, iter [01250, 01251], lr: 0.000178, loss: 0.4221
2022-10-04 04:32:15 - train: epoch 067, train_loss: 0.4052
2022-10-04 04:32:19 - until epoch: 067, best_loss: 0.4052
2022-10-04 04:32:19 - epoch 068 lr: 0.000178
2022-10-04 04:32:43 - train: epoch 0068, iter [00010, 01251], lr: 0.000178, loss: 0.4026
2022-10-04 04:33:02 - train: epoch 0068, iter [00020, 01251], lr: 0.000178, loss: 0.4118
2022-10-04 04:33:20 - train: epoch 0068, iter [00030, 01251], lr: 0.000178, loss: 0.4233
2022-10-04 04:33:39 - train: epoch 0068, iter [00040, 01251], lr: 0.000178, loss: 0.3892
2022-10-04 04:33:57 - train: epoch 0068, iter [00050, 01251], lr: 0.000178, loss: 0.4047
2022-10-04 04:34:15 - train: epoch 0068, iter [00060, 01251], lr: 0.000178, loss: 0.4046
2022-10-04 04:34:34 - train: epoch 0068, iter [00070, 01251], lr: 0.000177, loss: 0.3976
2022-10-04 04:34:52 - train: epoch 0068, iter [00080, 01251], lr: 0.000177, loss: 0.4144
2022-10-04 04:35:11 - train: epoch 0068, iter [00090, 01251], lr: 0.000177, loss: 0.3901
2022-10-04 04:35:30 - train: epoch 0068, iter [00100, 01251], lr: 0.000177, loss: 0.4161
2022-10-04 04:35:49 - train: epoch 0068, iter [00110, 01251], lr: 0.000177, loss: 0.3978
2022-10-04 04:36:07 - train: epoch 0068, iter [00120, 01251], lr: 0.000177, loss: 0.3964
2022-10-04 04:36:26 - train: epoch 0068, iter [00130, 01251], lr: 0.000177, loss: 0.3978
2022-10-04 04:36:45 - train: epoch 0068, iter [00140, 01251], lr: 0.000177, loss: 0.4322
2022-10-04 04:37:04 - train: epoch 0068, iter [00150, 01251], lr: 0.000177, loss: 0.3927
2022-10-04 04:37:22 - train: epoch 0068, iter [00160, 01251], lr: 0.000177, loss: 0.4358
2022-10-04 04:37:41 - train: epoch 0068, iter [00170, 01251], lr: 0.000177, loss: 0.4138
2022-10-04 04:37:59 - train: epoch 0068, iter [00180, 01251], lr: 0.000177, loss: 0.4161
2022-10-04 04:38:18 - train: epoch 0068, iter [00190, 01251], lr: 0.000177, loss: 0.4055
2022-10-04 04:38:36 - train: epoch 0068, iter [00200, 01251], lr: 0.000176, loss: 0.4134
2022-10-04 04:38:55 - train: epoch 0068, iter [00210, 01251], lr: 0.000176, loss: 0.4215
2022-10-04 04:39:14 - train: epoch 0068, iter [00220, 01251], lr: 0.000176, loss: 0.4214
2022-10-04 04:39:32 - train: epoch 0068, iter [00230, 01251], lr: 0.000176, loss: 0.4044
2022-10-04 04:39:51 - train: epoch 0068, iter [00240, 01251], lr: 0.000176, loss: 0.3999
2022-10-04 04:40:10 - train: epoch 0068, iter [00250, 01251], lr: 0.000176, loss: 0.4032
2022-10-04 04:40:29 - train: epoch 0068, iter [00260, 01251], lr: 0.000176, loss: 0.4003
2022-10-04 04:40:47 - train: epoch 0068, iter [00270, 01251], lr: 0.000176, loss: 0.4020
2022-10-04 04:41:06 - train: epoch 0068, iter [00280, 01251], lr: 0.000176, loss: 0.4211
2022-10-04 04:41:24 - train: epoch 0068, iter [00290, 01251], lr: 0.000176, loss: 0.3966
2022-10-04 04:41:43 - train: epoch 0068, iter [00300, 01251], lr: 0.000176, loss: 0.3990
2022-10-04 04:42:02 - train: epoch 0068, iter [00310, 01251], lr: 0.000176, loss: 0.4102
2022-10-04 04:42:21 - train: epoch 0068, iter [00320, 01251], lr: 0.000176, loss: 0.4138
2022-10-04 04:42:40 - train: epoch 0068, iter [00330, 01251], lr: 0.000175, loss: 0.3959
2022-10-04 04:42:59 - train: epoch 0068, iter [00340, 01251], lr: 0.000175, loss: 0.4072
2022-10-04 04:43:18 - train: epoch 0068, iter [00350, 01251], lr: 0.000175, loss: 0.3883
2022-10-04 04:43:38 - train: epoch 0068, iter [00360, 01251], lr: 0.000175, loss: 0.3909
2022-10-04 04:43:57 - train: epoch 0068, iter [00370, 01251], lr: 0.000175, loss: 0.4060
2022-10-04 04:44:16 - train: epoch 0068, iter [00380, 01251], lr: 0.000175, loss: 0.3974
2022-10-04 04:44:35 - train: epoch 0068, iter [00390, 01251], lr: 0.000175, loss: 0.4039
2022-10-04 04:44:54 - train: epoch 0068, iter [00400, 01251], lr: 0.000175, loss: 0.3969
2022-10-04 04:45:12 - train: epoch 0068, iter [00410, 01251], lr: 0.000175, loss: 0.4136
2022-10-04 04:45:31 - train: epoch 0068, iter [00420, 01251], lr: 0.000175, loss: 0.4091
2022-10-04 04:45:50 - train: epoch 0068, iter [00430, 01251], lr: 0.000175, loss: 0.3972
2022-10-04 04:46:08 - train: epoch 0068, iter [00440, 01251], lr: 0.000175, loss: 0.3979
2022-10-04 04:46:27 - train: epoch 0068, iter [00450, 01251], lr: 0.000175, loss: 0.4042
2022-10-04 04:46:46 - train: epoch 0068, iter [00460, 01251], lr: 0.000174, loss: 0.3925
2022-10-04 04:47:05 - train: epoch 0068, iter [00470, 01251], lr: 0.000174, loss: 0.4111
2022-10-04 04:47:24 - train: epoch 0068, iter [00480, 01251], lr: 0.000174, loss: 0.3971
2022-10-04 04:47:42 - train: epoch 0068, iter [00490, 01251], lr: 0.000174, loss: 0.4035
2022-10-04 04:48:01 - train: epoch 0068, iter [00500, 01251], lr: 0.000174, loss: 0.3830
2022-10-04 04:48:19 - train: epoch 0068, iter [00510, 01251], lr: 0.000174, loss: 0.4250
2022-10-04 04:48:38 - train: epoch 0068, iter [00520, 01251], lr: 0.000174, loss: 0.4135
2022-10-04 04:48:57 - train: epoch 0068, iter [00530, 01251], lr: 0.000174, loss: 0.4165
2022-10-04 04:49:15 - train: epoch 0068, iter [00540, 01251], lr: 0.000174, loss: 0.4049
2022-10-04 04:49:34 - train: epoch 0068, iter [00550, 01251], lr: 0.000174, loss: 0.4037
2022-10-04 04:49:53 - train: epoch 0068, iter [00560, 01251], lr: 0.000174, loss: 0.4214
2022-10-04 04:50:12 - train: epoch 0068, iter [00570, 01251], lr: 0.000174, loss: 0.3908
2022-10-04 04:50:31 - train: epoch 0068, iter [00580, 01251], lr: 0.000174, loss: 0.4148
2022-10-04 04:50:49 - train: epoch 0068, iter [00590, 01251], lr: 0.000173, loss: 0.4092
2022-10-04 04:51:08 - train: epoch 0068, iter [00600, 01251], lr: 0.000173, loss: 0.3892
2022-10-04 04:51:27 - train: epoch 0068, iter [00610, 01251], lr: 0.000173, loss: 0.3980
2022-10-04 04:51:45 - train: epoch 0068, iter [00620, 01251], lr: 0.000173, loss: 0.4135
2022-10-04 04:52:04 - train: epoch 0068, iter [00630, 01251], lr: 0.000173, loss: 0.4210
2022-10-04 04:52:23 - train: epoch 0068, iter [00640, 01251], lr: 0.000173, loss: 0.4264
2022-10-04 04:52:42 - train: epoch 0068, iter [00650, 01251], lr: 0.000173, loss: 0.4052
2022-10-04 04:53:01 - train: epoch 0068, iter [00660, 01251], lr: 0.000173, loss: 0.3992
2022-10-04 04:53:20 - train: epoch 0068, iter [00670, 01251], lr: 0.000173, loss: 0.3939
2022-10-04 04:53:39 - train: epoch 0068, iter [00680, 01251], lr: 0.000173, loss: 0.4086
2022-10-04 04:53:58 - train: epoch 0068, iter [00690, 01251], lr: 0.000173, loss: 0.4030
2022-10-04 04:54:17 - train: epoch 0068, iter [00700, 01251], lr: 0.000173, loss: 0.4105
2022-10-04 04:54:35 - train: epoch 0068, iter [00710, 01251], lr: 0.000173, loss: 0.3995
2022-10-04 04:54:54 - train: epoch 0068, iter [00720, 01251], lr: 0.000172, loss: 0.3899
2022-10-04 04:55:13 - train: epoch 0068, iter [00730, 01251], lr: 0.000172, loss: 0.4089
2022-10-04 04:55:32 - train: epoch 0068, iter [00740, 01251], lr: 0.000172, loss: 0.4136
2022-10-04 04:55:51 - train: epoch 0068, iter [00750, 01251], lr: 0.000172, loss: 0.3937
2022-10-04 04:56:09 - train: epoch 0068, iter [00760, 01251], lr: 0.000172, loss: 0.4149
2022-10-04 04:56:28 - train: epoch 0068, iter [00770, 01251], lr: 0.000172, loss: 0.4061
2022-10-04 04:56:47 - train: epoch 0068, iter [00780, 01251], lr: 0.000172, loss: 0.4140
2022-10-04 04:57:06 - train: epoch 0068, iter [00790, 01251], lr: 0.000172, loss: 0.3930
2022-10-04 04:57:24 - train: epoch 0068, iter [00800, 01251], lr: 0.000172, loss: 0.4052
2022-10-04 04:57:43 - train: epoch 0068, iter [00810, 01251], lr: 0.000172, loss: 0.3951
2022-10-04 04:58:02 - train: epoch 0068, iter [00820, 01251], lr: 0.000172, loss: 0.3993
2022-10-04 04:58:21 - train: epoch 0068, iter [00830, 01251], lr: 0.000172, loss: 0.4148
2022-10-04 04:58:40 - train: epoch 0068, iter [00840, 01251], lr: 0.000172, loss: 0.4157
2022-10-04 04:58:59 - train: epoch 0068, iter [00850, 01251], lr: 0.000172, loss: 0.4112
2022-10-04 04:59:17 - train: epoch 0068, iter [00860, 01251], lr: 0.000171, loss: 0.3913
2022-10-04 04:59:36 - train: epoch 0068, iter [00870, 01251], lr: 0.000171, loss: 0.3918
2022-10-04 04:59:55 - train: epoch 0068, iter [00880, 01251], lr: 0.000171, loss: 0.4110
2022-10-04 05:00:14 - train: epoch 0068, iter [00890, 01251], lr: 0.000171, loss: 0.4101
2022-10-04 05:00:32 - train: epoch 0068, iter [00900, 01251], lr: 0.000171, loss: 0.3943
2022-10-04 05:00:51 - train: epoch 0068, iter [00910, 01251], lr: 0.000171, loss: 0.4218
2022-10-04 05:01:10 - train: epoch 0068, iter [00920, 01251], lr: 0.000171, loss: 0.4019
2022-10-04 05:01:28 - train: epoch 0068, iter [00930, 01251], lr: 0.000171, loss: 0.4089
2022-10-04 05:01:47 - train: epoch 0068, iter [00940, 01251], lr: 0.000171, loss: 0.4159
2022-10-04 05:02:06 - train: epoch 0068, iter [00950, 01251], lr: 0.000171, loss: 0.4062
2022-10-04 05:02:25 - train: epoch 0068, iter [00960, 01251], lr: 0.000171, loss: 0.4071
2022-10-04 05:02:44 - train: epoch 0068, iter [00970, 01251], lr: 0.000171, loss: 0.4074
2022-10-04 05:03:03 - train: epoch 0068, iter [00980, 01251], lr: 0.000171, loss: 0.3961
2022-10-04 05:03:21 - train: epoch 0068, iter [00990, 01251], lr: 0.000170, loss: 0.4072
2022-10-04 05:03:40 - train: epoch 0068, iter [01000, 01251], lr: 0.000170, loss: 0.4208
2022-10-04 05:03:58 - train: epoch 0068, iter [01010, 01251], lr: 0.000170, loss: 0.4116
2022-10-04 05:04:17 - train: epoch 0068, iter [01020, 01251], lr: 0.000170, loss: 0.4004
2022-10-04 05:04:36 - train: epoch 0068, iter [01030, 01251], lr: 0.000170, loss: 0.4135
2022-10-04 05:04:54 - train: epoch 0068, iter [01040, 01251], lr: 0.000170, loss: 0.3897
2022-10-04 05:05:13 - train: epoch 0068, iter [01050, 01251], lr: 0.000170, loss: 0.4012
2022-10-04 05:05:31 - train: epoch 0068, iter [01060, 01251], lr: 0.000170, loss: 0.3863
2022-10-04 05:05:50 - train: epoch 0068, iter [01070, 01251], lr: 0.000170, loss: 0.4018
2022-10-04 05:06:09 - train: epoch 0068, iter [01080, 01251], lr: 0.000170, loss: 0.4018
2022-10-04 05:06:27 - train: epoch 0068, iter [01090, 01251], lr: 0.000170, loss: 0.3940
2022-10-04 05:06:46 - train: epoch 0068, iter [01100, 01251], lr: 0.000170, loss: 0.3956
2022-10-04 05:07:05 - train: epoch 0068, iter [01110, 01251], lr: 0.000170, loss: 0.4213
2022-10-04 05:07:24 - train: epoch 0068, iter [01120, 01251], lr: 0.000169, loss: 0.3990
2022-10-04 05:07:44 - train: epoch 0068, iter [01130, 01251], lr: 0.000169, loss: 0.4158
2022-10-04 05:08:03 - train: epoch 0068, iter [01140, 01251], lr: 0.000169, loss: 0.3979
2022-10-04 05:08:22 - train: epoch 0068, iter [01150, 01251], lr: 0.000169, loss: 0.4111
2022-10-04 05:08:40 - train: epoch 0068, iter [01160, 01251], lr: 0.000169, loss: 0.4090
2022-10-04 05:08:58 - train: epoch 0068, iter [01170, 01251], lr: 0.000169, loss: 0.4175
2022-10-04 05:09:17 - train: epoch 0068, iter [01180, 01251], lr: 0.000169, loss: 0.3946
2022-10-04 05:09:36 - train: epoch 0068, iter [01190, 01251], lr: 0.000169, loss: 0.4339
2022-10-04 05:09:55 - train: epoch 0068, iter [01200, 01251], lr: 0.000169, loss: 0.3905
2022-10-04 05:10:14 - train: epoch 0068, iter [01210, 01251], lr: 0.000169, loss: 0.3897
2022-10-04 05:10:33 - train: epoch 0068, iter [01220, 01251], lr: 0.000169, loss: 0.3867
2022-10-04 05:10:51 - train: epoch 0068, iter [01230, 01251], lr: 0.000169, loss: 0.4126
2022-10-04 05:11:10 - train: epoch 0068, iter [01240, 01251], lr: 0.000169, loss: 0.4224
2022-10-04 05:11:28 - train: epoch 0068, iter [01250, 01251], lr: 0.000168, loss: 0.4079
2022-10-04 05:11:33 - train: epoch 068, train_loss: 0.4049
2022-10-04 05:11:37 - until epoch: 068, best_loss: 0.4049
2022-10-04 05:11:37 - epoch 069 lr: 0.000168
2022-10-04 05:12:02 - train: epoch 0069, iter [00010, 01251], lr: 0.000168, loss: 0.3974
2022-10-04 05:12:20 - train: epoch 0069, iter [00020, 01251], lr: 0.000168, loss: 0.4007
2022-10-04 05:12:39 - train: epoch 0069, iter [00030, 01251], lr: 0.000168, loss: 0.4018
2022-10-04 05:12:57 - train: epoch 0069, iter [00040, 01251], lr: 0.000168, loss: 0.4078
2022-10-04 05:13:16 - train: epoch 0069, iter [00050, 01251], lr: 0.000168, loss: 0.3905
2022-10-04 05:13:34 - train: epoch 0069, iter [00060, 01251], lr: 0.000168, loss: 0.4103
2022-10-04 05:13:53 - train: epoch 0069, iter [00070, 01251], lr: 0.000168, loss: 0.3931
2022-10-04 05:14:12 - train: epoch 0069, iter [00080, 01251], lr: 0.000168, loss: 0.3998
2022-10-04 05:14:30 - train: epoch 0069, iter [00090, 01251], lr: 0.000168, loss: 0.3753
2022-10-04 05:14:49 - train: epoch 0069, iter [00100, 01251], lr: 0.000168, loss: 0.3894
2022-10-04 05:15:08 - train: epoch 0069, iter [00110, 01251], lr: 0.000168, loss: 0.4208
2022-10-04 05:15:26 - train: epoch 0069, iter [00120, 01251], lr: 0.000168, loss: 0.4186
2022-10-04 05:15:45 - train: epoch 0069, iter [00130, 01251], lr: 0.000168, loss: 0.3961
2022-10-04 05:16:03 - train: epoch 0069, iter [00140, 01251], lr: 0.000167, loss: 0.4036
2022-10-04 05:16:22 - train: epoch 0069, iter [00150, 01251], lr: 0.000167, loss: 0.4102
2022-10-04 05:16:41 - train: epoch 0069, iter [00160, 01251], lr: 0.000167, loss: 0.3992
2022-10-04 05:17:00 - train: epoch 0069, iter [00170, 01251], lr: 0.000167, loss: 0.4166
2022-10-04 05:17:19 - train: epoch 0069, iter [00180, 01251], lr: 0.000167, loss: 0.4128
2022-10-04 05:17:38 - train: epoch 0069, iter [00190, 01251], lr: 0.000167, loss: 0.4055
2022-10-04 05:17:57 - train: epoch 0069, iter [00200, 01251], lr: 0.000167, loss: 0.3940
2022-10-04 05:18:16 - train: epoch 0069, iter [00210, 01251], lr: 0.000167, loss: 0.4009
2022-10-04 05:18:34 - train: epoch 0069, iter [00220, 01251], lr: 0.000167, loss: 0.3970
2022-10-04 05:18:53 - train: epoch 0069, iter [00230, 01251], lr: 0.000167, loss: 0.3985
2022-10-04 05:19:12 - train: epoch 0069, iter [00240, 01251], lr: 0.000167, loss: 0.4106
2022-10-04 05:19:31 - train: epoch 0069, iter [00250, 01251], lr: 0.000167, loss: 0.4186
2022-10-04 05:19:50 - train: epoch 0069, iter [00260, 01251], lr: 0.000167, loss: 0.4205
2022-10-04 05:20:09 - train: epoch 0069, iter [00270, 01251], lr: 0.000166, loss: 0.3996
2022-10-04 05:20:28 - train: epoch 0069, iter [00280, 01251], lr: 0.000166, loss: 0.4185
2022-10-04 05:20:46 - train: epoch 0069, iter [00290, 01251], lr: 0.000166, loss: 0.4028
2022-10-04 05:21:05 - train: epoch 0069, iter [00300, 01251], lr: 0.000166, loss: 0.4088
2022-10-04 05:21:24 - train: epoch 0069, iter [00310, 01251], lr: 0.000166, loss: 0.4151
2022-10-04 05:21:42 - train: epoch 0069, iter [00320, 01251], lr: 0.000166, loss: 0.4327
2022-10-04 05:22:01 - train: epoch 0069, iter [00330, 01251], lr: 0.000166, loss: 0.4078
2022-10-04 05:22:19 - train: epoch 0069, iter [00340, 01251], lr: 0.000166, loss: 0.4151
2022-10-04 05:22:38 - train: epoch 0069, iter [00350, 01251], lr: 0.000166, loss: 0.4015
2022-10-04 05:22:57 - train: epoch 0069, iter [00360, 01251], lr: 0.000166, loss: 0.4079
2022-10-04 05:23:15 - train: epoch 0069, iter [00370, 01251], lr: 0.000166, loss: 0.3860
2022-10-04 05:23:34 - train: epoch 0069, iter [00380, 01251], lr: 0.000166, loss: 0.4064
2022-10-04 05:23:53 - train: epoch 0069, iter [00390, 01251], lr: 0.000166, loss: 0.3956
2022-10-04 05:24:12 - train: epoch 0069, iter [00400, 01251], lr: 0.000165, loss: 0.4016
2022-10-04 05:24:30 - train: epoch 0069, iter [00410, 01251], lr: 0.000165, loss: 0.4020
2022-10-04 05:24:49 - train: epoch 0069, iter [00420, 01251], lr: 0.000165, loss: 0.4056
2022-10-04 05:25:08 - train: epoch 0069, iter [00430, 01251], lr: 0.000165, loss: 0.3956
2022-10-04 05:25:27 - train: epoch 0069, iter [00440, 01251], lr: 0.000165, loss: 0.4031
2022-10-04 05:25:45 - train: epoch 0069, iter [00450, 01251], lr: 0.000165, loss: 0.3979
2022-10-04 05:26:04 - train: epoch 0069, iter [00460, 01251], lr: 0.000165, loss: 0.4133
2022-10-04 05:26:23 - train: epoch 0069, iter [00470, 01251], lr: 0.000165, loss: 0.3945
2022-10-04 05:26:41 - train: epoch 0069, iter [00480, 01251], lr: 0.000165, loss: 0.4235
2022-10-04 05:27:00 - train: epoch 0069, iter [00490, 01251], lr: 0.000165, loss: 0.4131
2022-10-04 05:27:19 - train: epoch 0069, iter [00500, 01251], lr: 0.000165, loss: 0.4092
2022-10-04 05:27:38 - train: epoch 0069, iter [00510, 01251], lr: 0.000165, loss: 0.4088
2022-10-04 05:27:57 - train: epoch 0069, iter [00520, 01251], lr: 0.000165, loss: 0.3984
2022-10-04 05:28:15 - train: epoch 0069, iter [00530, 01251], lr: 0.000165, loss: 0.4255
2022-10-04 05:28:34 - train: epoch 0069, iter [00540, 01251], lr: 0.000164, loss: 0.4120
2022-10-04 05:28:53 - train: epoch 0069, iter [00550, 01251], lr: 0.000164, loss: 0.4261
2022-10-04 05:29:11 - train: epoch 0069, iter [00560, 01251], lr: 0.000164, loss: 0.4012
2022-10-04 05:29:30 - train: epoch 0069, iter [00570, 01251], lr: 0.000164, loss: 0.4183
2022-10-04 05:29:49 - train: epoch 0069, iter [00580, 01251], lr: 0.000164, loss: 0.4126
2022-10-04 05:30:07 - train: epoch 0069, iter [00590, 01251], lr: 0.000164, loss: 0.4172
2022-10-04 05:30:26 - train: epoch 0069, iter [00600, 01251], lr: 0.000164, loss: 0.3869
2022-10-04 05:30:45 - train: epoch 0069, iter [00610, 01251], lr: 0.000164, loss: 0.4096
2022-10-04 05:31:03 - train: epoch 0069, iter [00620, 01251], lr: 0.000164, loss: 0.4264
2022-10-04 05:31:22 - train: epoch 0069, iter [00630, 01251], lr: 0.000164, loss: 0.4079
2022-10-04 05:31:41 - train: epoch 0069, iter [00640, 01251], lr: 0.000164, loss: 0.3850
2022-10-04 05:32:00 - train: epoch 0069, iter [00650, 01251], lr: 0.000164, loss: 0.4166
2022-10-04 05:32:19 - train: epoch 0069, iter [00660, 01251], lr: 0.000164, loss: 0.4037
2022-10-04 05:32:37 - train: epoch 0069, iter [00670, 01251], lr: 0.000163, loss: 0.4069
2022-10-04 05:32:56 - train: epoch 0069, iter [00680, 01251], lr: 0.000163, loss: 0.4120
2022-10-04 05:33:15 - train: epoch 0069, iter [00690, 01251], lr: 0.000163, loss: 0.4059
2022-10-04 05:33:34 - train: epoch 0069, iter [00700, 01251], lr: 0.000163, loss: 0.4150
2022-10-04 05:33:52 - train: epoch 0069, iter [00710, 01251], lr: 0.000163, loss: 0.4270
2022-10-04 05:34:11 - train: epoch 0069, iter [00720, 01251], lr: 0.000163, loss: 0.4178
2022-10-04 05:34:30 - train: epoch 0069, iter [00730, 01251], lr: 0.000163, loss: 0.4232
2022-10-04 05:34:49 - train: epoch 0069, iter [00740, 01251], lr: 0.000163, loss: 0.3972
2022-10-04 05:35:08 - train: epoch 0069, iter [00750, 01251], lr: 0.000163, loss: 0.4151
2022-10-04 05:35:27 - train: epoch 0069, iter [00760, 01251], lr: 0.000163, loss: 0.3780
2022-10-04 05:35:46 - train: epoch 0069, iter [00770, 01251], lr: 0.000163, loss: 0.4101
2022-10-04 05:36:05 - train: epoch 0069, iter [00780, 01251], lr: 0.000163, loss: 0.4008
2022-10-04 05:36:24 - train: epoch 0069, iter [00790, 01251], lr: 0.000163, loss: 0.4134
2022-10-04 05:36:43 - train: epoch 0069, iter [00800, 01251], lr: 0.000163, loss: 0.4335
2022-10-04 05:37:01 - train: epoch 0069, iter [00810, 01251], lr: 0.000162, loss: 0.4159
2022-10-04 05:37:20 - train: epoch 0069, iter [00820, 01251], lr: 0.000162, loss: 0.4008
2022-10-04 05:37:38 - train: epoch 0069, iter [00830, 01251], lr: 0.000162, loss: 0.4053
2022-10-04 05:37:57 - train: epoch 0069, iter [00840, 01251], lr: 0.000162, loss: 0.3994
2022-10-04 05:38:16 - train: epoch 0069, iter [00850, 01251], lr: 0.000162, loss: 0.4044
2022-10-04 05:38:35 - train: epoch 0069, iter [00860, 01251], lr: 0.000162, loss: 0.4031
2022-10-04 05:38:53 - train: epoch 0069, iter [00870, 01251], lr: 0.000162, loss: 0.3850
2022-10-04 05:39:12 - train: epoch 0069, iter [00880, 01251], lr: 0.000162, loss: 0.4055
2022-10-04 05:39:30 - train: epoch 0069, iter [00890, 01251], lr: 0.000162, loss: 0.4023
2022-10-04 05:39:49 - train: epoch 0069, iter [00900, 01251], lr: 0.000162, loss: 0.4139
2022-10-04 05:40:08 - train: epoch 0069, iter [00910, 01251], lr: 0.000162, loss: 0.4208
2022-10-04 05:40:27 - train: epoch 0069, iter [00920, 01251], lr: 0.000162, loss: 0.4100
2022-10-04 05:40:45 - train: epoch 0069, iter [00930, 01251], lr: 0.000162, loss: 0.4225
2022-10-04 05:41:04 - train: epoch 0069, iter [00940, 01251], lr: 0.000161, loss: 0.4131
2022-10-04 05:41:23 - train: epoch 0069, iter [00950, 01251], lr: 0.000161, loss: 0.4146
2022-10-04 05:41:42 - train: epoch 0069, iter [00960, 01251], lr: 0.000161, loss: 0.4008
2022-10-04 05:42:00 - train: epoch 0069, iter [00970, 01251], lr: 0.000161, loss: 0.4069
2022-10-04 05:42:19 - train: epoch 0069, iter [00980, 01251], lr: 0.000161, loss: 0.3899
2022-10-04 05:42:38 - train: epoch 0069, iter [00990, 01251], lr: 0.000161, loss: 0.4105
2022-10-04 05:42:57 - train: epoch 0069, iter [01000, 01251], lr: 0.000161, loss: 0.3896
2022-10-04 05:43:15 - train: epoch 0069, iter [01010, 01251], lr: 0.000161, loss: 0.4064
2022-10-04 05:43:34 - train: epoch 0069, iter [01020, 01251], lr: 0.000161, loss: 0.3995
2022-10-04 05:43:53 - train: epoch 0069, iter [01030, 01251], lr: 0.000161, loss: 0.4013
2022-10-04 05:44:11 - train: epoch 0069, iter [01040, 01251], lr: 0.000161, loss: 0.4086
2022-10-04 05:44:30 - train: epoch 0069, iter [01050, 01251], lr: 0.000161, loss: 0.4149
2022-10-04 05:44:48 - train: epoch 0069, iter [01060, 01251], lr: 0.000161, loss: 0.4205
2022-10-04 05:45:07 - train: epoch 0069, iter [01070, 01251], lr: 0.000160, loss: 0.4086
2022-10-04 05:45:26 - train: epoch 0069, iter [01080, 01251], lr: 0.000160, loss: 0.4168
2022-10-04 05:45:45 - train: epoch 0069, iter [01090, 01251], lr: 0.000160, loss: 0.4052
2022-10-04 05:46:04 - train: epoch 0069, iter [01100, 01251], lr: 0.000160, loss: 0.4254
2022-10-04 05:46:22 - train: epoch 0069, iter [01110, 01251], lr: 0.000160, loss: 0.4097
2022-10-04 05:46:41 - train: epoch 0069, iter [01120, 01251], lr: 0.000160, loss: 0.4056
2022-10-04 05:46:59 - train: epoch 0069, iter [01130, 01251], lr: 0.000160, loss: 0.4125
2022-10-04 05:47:18 - train: epoch 0069, iter [01140, 01251], lr: 0.000160, loss: 0.3826
2022-10-04 05:47:36 - train: epoch 0069, iter [01150, 01251], lr: 0.000160, loss: 0.3911
2022-10-04 05:47:55 - train: epoch 0069, iter [01160, 01251], lr: 0.000160, loss: 0.4154
2022-10-04 05:48:13 - train: epoch 0069, iter [01170, 01251], lr: 0.000160, loss: 0.4211
2022-10-04 05:48:32 - train: epoch 0069, iter [01180, 01251], lr: 0.000160, loss: 0.4009
2022-10-04 05:48:51 - train: epoch 0069, iter [01190, 01251], lr: 0.000160, loss: 0.4279
2022-10-04 05:49:09 - train: epoch 0069, iter [01200, 01251], lr: 0.000160, loss: 0.3902
2022-10-04 05:49:28 - train: epoch 0069, iter [01210, 01251], lr: 0.000159, loss: 0.4129
2022-10-04 05:49:47 - train: epoch 0069, iter [01220, 01251], lr: 0.000159, loss: 0.4080
2022-10-04 05:50:06 - train: epoch 0069, iter [01230, 01251], lr: 0.000159, loss: 0.3978
2022-10-04 05:50:24 - train: epoch 0069, iter [01240, 01251], lr: 0.000159, loss: 0.4028
2022-10-04 05:50:43 - train: epoch 0069, iter [01250, 01251], lr: 0.000159, loss: 0.4069
2022-10-04 05:50:48 - train: epoch 069, train_loss: 0.4046
2022-10-04 05:50:52 - until epoch: 069, best_loss: 0.4046
2022-10-04 05:50:52 - epoch 070 lr: 0.000159
2022-10-04 05:51:17 - train: epoch 0070, iter [00010, 01251], lr: 0.000159, loss: 0.3964
2022-10-04 05:51:35 - train: epoch 0070, iter [00020, 01251], lr: 0.000159, loss: 0.4157
2022-10-04 05:51:54 - train: epoch 0070, iter [00030, 01251], lr: 0.000159, loss: 0.3942
2022-10-04 05:52:14 - train: epoch 0070, iter [00040, 01251], lr: 0.000159, loss: 0.4167
2022-10-04 05:52:32 - train: epoch 0070, iter [00050, 01251], lr: 0.000159, loss: 0.3884
2022-10-04 05:52:50 - train: epoch 0070, iter [00060, 01251], lr: 0.000159, loss: 0.3925
2022-10-04 05:53:09 - train: epoch 0070, iter [00070, 01251], lr: 0.000159, loss: 0.4022
2022-10-04 05:53:28 - train: epoch 0070, iter [00080, 01251], lr: 0.000159, loss: 0.3931
2022-10-04 05:53:46 - train: epoch 0070, iter [00090, 01251], lr: 0.000158, loss: 0.4177
2022-10-04 05:54:05 - train: epoch 0070, iter [00100, 01251], lr: 0.000158, loss: 0.4105
2022-10-04 05:54:24 - train: epoch 0070, iter [00110, 01251], lr: 0.000158, loss: 0.4164
2022-10-04 05:54:42 - train: epoch 0070, iter [00120, 01251], lr: 0.000158, loss: 0.4103
2022-10-04 05:55:01 - train: epoch 0070, iter [00130, 01251], lr: 0.000158, loss: 0.3938
2022-10-04 05:55:20 - train: epoch 0070, iter [00140, 01251], lr: 0.000158, loss: 0.4014
2022-10-04 05:55:39 - train: epoch 0070, iter [00150, 01251], lr: 0.000158, loss: 0.3951
2022-10-04 05:55:57 - train: epoch 0070, iter [00160, 01251], lr: 0.000158, loss: 0.4113
2022-10-04 05:56:16 - train: epoch 0070, iter [00170, 01251], lr: 0.000158, loss: 0.4015
2022-10-04 05:56:34 - train: epoch 0070, iter [00180, 01251], lr: 0.000158, loss: 0.4179
2022-10-04 05:56:53 - train: epoch 0070, iter [00190, 01251], lr: 0.000158, loss: 0.3925
2022-10-04 05:57:12 - train: epoch 0070, iter [00200, 01251], lr: 0.000158, loss: 0.4028
2022-10-04 05:57:31 - train: epoch 0070, iter [00210, 01251], lr: 0.000158, loss: 0.4052
2022-10-04 05:57:50 - train: epoch 0070, iter [00220, 01251], lr: 0.000158, loss: 0.3914
2022-10-04 05:58:09 - train: epoch 0070, iter [00230, 01251], lr: 0.000157, loss: 0.4116
2022-10-04 05:58:28 - train: epoch 0070, iter [00240, 01251], lr: 0.000157, loss: 0.4017
2022-10-04 05:58:47 - train: epoch 0070, iter [00250, 01251], lr: 0.000157, loss: 0.4118
2022-10-04 05:59:05 - train: epoch 0070, iter [00260, 01251], lr: 0.000157, loss: 0.4082
2022-10-04 05:59:24 - train: epoch 0070, iter [00270, 01251], lr: 0.000157, loss: 0.3926
2022-10-04 05:59:43 - train: epoch 0070, iter [00280, 01251], lr: 0.000157, loss: 0.3914
2022-10-04 06:00:02 - train: epoch 0070, iter [00290, 01251], lr: 0.000157, loss: 0.3939
2022-10-04 06:00:21 - train: epoch 0070, iter [00300, 01251], lr: 0.000157, loss: 0.4168
2022-10-04 06:00:39 - train: epoch 0070, iter [00310, 01251], lr: 0.000157, loss: 0.3852
2022-10-04 06:00:58 - train: epoch 0070, iter [00320, 01251], lr: 0.000157, loss: 0.4104
2022-10-04 06:01:17 - train: epoch 0070, iter [00330, 01251], lr: 0.000157, loss: 0.3932
2022-10-04 06:01:36 - train: epoch 0070, iter [00340, 01251], lr: 0.000157, loss: 0.4066
2022-10-04 06:01:54 - train: epoch 0070, iter [00350, 01251], lr: 0.000157, loss: 0.4208
2022-10-04 06:02:13 - train: epoch 0070, iter [00360, 01251], lr: 0.000157, loss: 0.4240
2022-10-04 06:02:31 - train: epoch 0070, iter [00370, 01251], lr: 0.000156, loss: 0.4107
2022-10-04 06:02:50 - train: epoch 0070, iter [00380, 01251], lr: 0.000156, loss: 0.4076
2022-10-04 06:03:09 - train: epoch 0070, iter [00390, 01251], lr: 0.000156, loss: 0.4115
2022-10-04 06:03:28 - train: epoch 0070, iter [00400, 01251], lr: 0.000156, loss: 0.4001
2022-10-04 06:03:46 - train: epoch 0070, iter [00410, 01251], lr: 0.000156, loss: 0.4019
2022-10-04 06:04:05 - train: epoch 0070, iter [00420, 01251], lr: 0.000156, loss: 0.4063
2022-10-04 06:04:24 - train: epoch 0070, iter [00430, 01251], lr: 0.000156, loss: 0.4025
2022-10-04 06:04:43 - train: epoch 0070, iter [00440, 01251], lr: 0.000156, loss: 0.4049
2022-10-04 06:05:02 - train: epoch 0070, iter [00450, 01251], lr: 0.000156, loss: 0.3866
2022-10-04 06:05:21 - train: epoch 0070, iter [00460, 01251], lr: 0.000156, loss: 0.4030
2022-10-04 06:05:40 - train: epoch 0070, iter [00470, 01251], lr: 0.000156, loss: 0.3896
2022-10-04 06:05:59 - train: epoch 0070, iter [00480, 01251], lr: 0.000156, loss: 0.3955
2022-10-04 06:06:17 - train: epoch 0070, iter [00490, 01251], lr: 0.000156, loss: 0.4135
2022-10-04 06:06:36 - train: epoch 0070, iter [00500, 01251], lr: 0.000155, loss: 0.4025
2022-10-04 06:06:55 - train: epoch 0070, iter [00510, 01251], lr: 0.000155, loss: 0.3876
2022-10-04 06:07:14 - train: epoch 0070, iter [00520, 01251], lr: 0.000155, loss: 0.4088
2022-10-04 06:07:33 - train: epoch 0070, iter [00530, 01251], lr: 0.000155, loss: 0.4113
2022-10-04 06:07:52 - train: epoch 0070, iter [00540, 01251], lr: 0.000155, loss: 0.4175
2022-10-04 06:08:11 - train: epoch 0070, iter [00550, 01251], lr: 0.000155, loss: 0.4208
2022-10-04 06:08:29 - train: epoch 0070, iter [00560, 01251], lr: 0.000155, loss: 0.3837
2022-10-04 06:08:48 - train: epoch 0070, iter [00570, 01251], lr: 0.000155, loss: 0.3882
2022-10-04 06:09:07 - train: epoch 0070, iter [00580, 01251], lr: 0.000155, loss: 0.3983
2022-10-04 06:09:26 - train: epoch 0070, iter [00590, 01251], lr: 0.000155, loss: 0.4204
2022-10-04 06:09:45 - train: epoch 0070, iter [00600, 01251], lr: 0.000155, loss: 0.3971
2022-10-04 06:10:03 - train: epoch 0070, iter [00610, 01251], lr: 0.000155, loss: 0.4009
2022-10-04 06:10:22 - train: epoch 0070, iter [00620, 01251], lr: 0.000155, loss: 0.4008
2022-10-04 06:10:41 - train: epoch 0070, iter [00630, 01251], lr: 0.000155, loss: 0.3922
2022-10-04 06:11:00 - train: epoch 0070, iter [00640, 01251], lr: 0.000154, loss: 0.4027
2022-10-04 06:11:19 - train: epoch 0070, iter [00650, 01251], lr: 0.000154, loss: 0.4327
2022-10-04 06:11:38 - train: epoch 0070, iter [00660, 01251], lr: 0.000154, loss: 0.4003
2022-10-04 06:11:57 - train: epoch 0070, iter [00670, 01251], lr: 0.000154, loss: 0.4167
2022-10-04 06:12:16 - train: epoch 0070, iter [00680, 01251], lr: 0.000154, loss: 0.4076
2022-10-04 06:12:35 - train: epoch 0070, iter [00690, 01251], lr: 0.000154, loss: 0.4161
2022-10-04 06:12:53 - train: epoch 0070, iter [00700, 01251], lr: 0.000154, loss: 0.4091
2022-10-04 06:13:12 - train: epoch 0070, iter [00710, 01251], lr: 0.000154, loss: 0.3979
2022-10-04 06:13:30 - train: epoch 0070, iter [00720, 01251], lr: 0.000154, loss: 0.3937
2022-10-04 06:13:49 - train: epoch 0070, iter [00730, 01251], lr: 0.000154, loss: 0.4012
2022-10-04 06:14:08 - train: epoch 0070, iter [00740, 01251], lr: 0.000154, loss: 0.4052
2022-10-04 06:14:27 - train: epoch 0070, iter [00750, 01251], lr: 0.000154, loss: 0.4066
2022-10-04 06:14:45 - train: epoch 0070, iter [00760, 01251], lr: 0.000154, loss: 0.3954
2022-10-04 06:15:04 - train: epoch 0070, iter [00770, 01251], lr: 0.000154, loss: 0.4036
2022-10-04 06:15:23 - train: epoch 0070, iter [00780, 01251], lr: 0.000153, loss: 0.3960
2022-10-04 06:15:42 - train: epoch 0070, iter [00790, 01251], lr: 0.000153, loss: 0.4121
2022-10-04 06:16:00 - train: epoch 0070, iter [00800, 01251], lr: 0.000153, loss: 0.3970
2022-10-04 06:16:19 - train: epoch 0070, iter [00810, 01251], lr: 0.000153, loss: 0.4202
2022-10-04 06:16:37 - train: epoch 0070, iter [00820, 01251], lr: 0.000153, loss: 0.4011
2022-10-04 06:16:56 - train: epoch 0070, iter [00830, 01251], lr: 0.000153, loss: 0.3935
2022-10-04 06:17:15 - train: epoch 0070, iter [00840, 01251], lr: 0.000153, loss: 0.4107
2022-10-04 06:17:34 - train: epoch 0070, iter [00850, 01251], lr: 0.000153, loss: 0.4021
2022-10-04 06:17:52 - train: epoch 0070, iter [00860, 01251], lr: 0.000153, loss: 0.4303
2022-10-04 06:18:11 - train: epoch 0070, iter [00870, 01251], lr: 0.000153, loss: 0.3768
2022-10-04 06:18:30 - train: epoch 0070, iter [00880, 01251], lr: 0.000153, loss: 0.3919
2022-10-04 06:18:48 - train: epoch 0070, iter [00890, 01251], lr: 0.000153, loss: 0.4038
2022-10-04 06:19:08 - train: epoch 0070, iter [00900, 01251], lr: 0.000153, loss: 0.4164
2022-10-04 06:19:26 - train: epoch 0070, iter [00910, 01251], lr: 0.000152, loss: 0.4054
2022-10-04 06:19:45 - train: epoch 0070, iter [00920, 01251], lr: 0.000152, loss: 0.4111
2022-10-04 06:20:04 - train: epoch 0070, iter [00930, 01251], lr: 0.000152, loss: 0.3853
2022-10-04 06:20:23 - train: epoch 0070, iter [00940, 01251], lr: 0.000152, loss: 0.3984
2022-10-04 06:20:42 - train: epoch 0070, iter [00950, 01251], lr: 0.000152, loss: 0.4117
2022-10-04 06:21:00 - train: epoch 0070, iter [00960, 01251], lr: 0.000152, loss: 0.4095
2022-10-04 06:21:19 - train: epoch 0070, iter [00970, 01251], lr: 0.000152, loss: 0.4227
2022-10-04 06:21:38 - train: epoch 0070, iter [00980, 01251], lr: 0.000152, loss: 0.4170
2022-10-04 06:21:57 - train: epoch 0070, iter [00990, 01251], lr: 0.000152, loss: 0.4119
2022-10-04 06:22:16 - train: epoch 0070, iter [01000, 01251], lr: 0.000152, loss: 0.3972
2022-10-04 06:22:34 - train: epoch 0070, iter [01010, 01251], lr: 0.000152, loss: 0.3924
2022-10-04 06:22:52 - train: epoch 0070, iter [01020, 01251], lr: 0.000152, loss: 0.3949
2022-10-04 06:23:11 - train: epoch 0070, iter [01030, 01251], lr: 0.000152, loss: 0.3929
2022-10-04 06:23:30 - train: epoch 0070, iter [01040, 01251], lr: 0.000152, loss: 0.4067
2022-10-04 06:23:49 - train: epoch 0070, iter [01050, 01251], lr: 0.000151, loss: 0.4129
2022-10-04 06:24:08 - train: epoch 0070, iter [01060, 01251], lr: 0.000151, loss: 0.4236
2022-10-04 06:24:27 - train: epoch 0070, iter [01070, 01251], lr: 0.000151, loss: 0.4048
2022-10-04 06:24:45 - train: epoch 0070, iter [01080, 01251], lr: 0.000151, loss: 0.4017
2022-10-04 06:25:04 - train: epoch 0070, iter [01090, 01251], lr: 0.000151, loss: 0.4105
2022-10-04 06:25:23 - train: epoch 0070, iter [01100, 01251], lr: 0.000151, loss: 0.4012
2022-10-04 06:25:42 - train: epoch 0070, iter [01110, 01251], lr: 0.000151, loss: 0.4189
2022-10-04 06:26:01 - train: epoch 0070, iter [01120, 01251], lr: 0.000151, loss: 0.3941
2022-10-04 06:26:19 - train: epoch 0070, iter [01130, 01251], lr: 0.000151, loss: 0.4055
2022-10-04 06:26:38 - train: epoch 0070, iter [01140, 01251], lr: 0.000151, loss: 0.4080
2022-10-04 06:26:57 - train: epoch 0070, iter [01150, 01251], lr: 0.000151, loss: 0.3910
2022-10-04 06:27:16 - train: epoch 0070, iter [01160, 01251], lr: 0.000151, loss: 0.3938
2022-10-04 06:27:34 - train: epoch 0070, iter [01170, 01251], lr: 0.000151, loss: 0.4183
2022-10-04 06:27:53 - train: epoch 0070, iter [01180, 01251], lr: 0.000151, loss: 0.3900
2022-10-04 06:28:12 - train: epoch 0070, iter [01190, 01251], lr: 0.000150, loss: 0.3893
2022-10-04 06:28:31 - train: epoch 0070, iter [01200, 01251], lr: 0.000150, loss: 0.3935
2022-10-04 06:28:50 - train: epoch 0070, iter [01210, 01251], lr: 0.000150, loss: 0.4135
2022-10-04 06:29:08 - train: epoch 0070, iter [01220, 01251], lr: 0.000150, loss: 0.4320
2022-10-04 06:29:27 - train: epoch 0070, iter [01230, 01251], lr: 0.000150, loss: 0.4036
2022-10-04 06:29:46 - train: epoch 0070, iter [01240, 01251], lr: 0.000150, loss: 0.3977
2022-10-04 06:30:04 - train: epoch 0070, iter [01250, 01251], lr: 0.000150, loss: 0.4101
2022-10-04 06:30:09 - train: epoch 070, train_loss: 0.4043
2022-10-04 06:30:13 - until epoch: 070, best_loss: 0.4043
2022-10-04 06:30:13 - epoch 071 lr: 0.000150
2022-10-04 06:30:38 - train: epoch 0071, iter [00010, 01251], lr: 0.000150, loss: 0.3998
2022-10-04 06:30:57 - train: epoch 0071, iter [00020, 01251], lr: 0.000150, loss: 0.4119
2022-10-04 06:31:15 - train: epoch 0071, iter [00030, 01251], lr: 0.000150, loss: 0.4006
2022-10-04 06:31:34 - train: epoch 0071, iter [00040, 01251], lr: 0.000150, loss: 0.4064
2022-10-04 06:31:53 - train: epoch 0071, iter [00050, 01251], lr: 0.000150, loss: 0.3929
2022-10-04 06:32:12 - train: epoch 0071, iter [00060, 01251], lr: 0.000150, loss: 0.4190
2022-10-04 06:32:31 - train: epoch 0071, iter [00070, 01251], lr: 0.000149, loss: 0.4037
2022-10-04 06:32:50 - train: epoch 0071, iter [00080, 01251], lr: 0.000149, loss: 0.4038
2022-10-04 06:33:09 - train: epoch 0071, iter [00090, 01251], lr: 0.000149, loss: 0.4067
2022-10-04 06:33:28 - train: epoch 0071, iter [00100, 01251], lr: 0.000149, loss: 0.4057
2022-10-04 06:33:46 - train: epoch 0071, iter [00110, 01251], lr: 0.000149, loss: 0.3892
2022-10-04 06:34:05 - train: epoch 0071, iter [00120, 01251], lr: 0.000149, loss: 0.3962
2022-10-04 06:34:24 - train: epoch 0071, iter [00130, 01251], lr: 0.000149, loss: 0.4163
2022-10-04 06:34:43 - train: epoch 0071, iter [00140, 01251], lr: 0.000149, loss: 0.3969
2022-10-04 06:35:02 - train: epoch 0071, iter [00150, 01251], lr: 0.000149, loss: 0.4149
2022-10-04 06:35:20 - train: epoch 0071, iter [00160, 01251], lr: 0.000149, loss: 0.4308
2022-10-04 06:35:40 - train: epoch 0071, iter [00170, 01251], lr: 0.000149, loss: 0.4014
2022-10-04 06:35:59 - train: epoch 0071, iter [00180, 01251], lr: 0.000149, loss: 0.3981
2022-10-04 06:36:18 - train: epoch 0071, iter [00190, 01251], lr: 0.000149, loss: 0.3936
2022-10-04 06:36:36 - train: epoch 0071, iter [00200, 01251], lr: 0.000149, loss: 0.3963
2022-10-04 06:36:55 - train: epoch 0071, iter [00210, 01251], lr: 0.000148, loss: 0.3932
2022-10-04 06:37:14 - train: epoch 0071, iter [00220, 01251], lr: 0.000148, loss: 0.4170
2022-10-04 06:37:33 - train: epoch 0071, iter [00230, 01251], lr: 0.000148, loss: 0.4098
2022-10-04 06:37:52 - train: epoch 0071, iter [00240, 01251], lr: 0.000148, loss: 0.3867
2022-10-04 06:38:11 - train: epoch 0071, iter [00250, 01251], lr: 0.000148, loss: 0.4046
2022-10-04 06:38:30 - train: epoch 0071, iter [00260, 01251], lr: 0.000148, loss: 0.4062
2022-10-04 06:38:48 - train: epoch 0071, iter [00270, 01251], lr: 0.000148, loss: 0.4145
2022-10-04 06:39:07 - train: epoch 0071, iter [00280, 01251], lr: 0.000148, loss: 0.4218
2022-10-04 06:39:26 - train: epoch 0071, iter [00290, 01251], lr: 0.000148, loss: 0.4091
2022-10-04 06:39:45 - train: epoch 0071, iter [00300, 01251], lr: 0.000148, loss: 0.4073
2022-10-04 06:40:03 - train: epoch 0071, iter [00310, 01251], lr: 0.000148, loss: 0.4026
2022-10-04 06:40:22 - train: epoch 0071, iter [00320, 01251], lr: 0.000148, loss: 0.4071
2022-10-04 06:40:41 - train: epoch 0071, iter [00330, 01251], lr: 0.000148, loss: 0.4198
2022-10-04 06:41:00 - train: epoch 0071, iter [00340, 01251], lr: 0.000148, loss: 0.4054
2022-10-04 06:41:18 - train: epoch 0071, iter [00350, 01251], lr: 0.000147, loss: 0.4007
2022-10-04 06:41:37 - train: epoch 0071, iter [00360, 01251], lr: 0.000147, loss: 0.4196
2022-10-04 06:41:56 - train: epoch 0071, iter [00370, 01251], lr: 0.000147, loss: 0.4047
2022-10-04 06:42:14 - train: epoch 0071, iter [00380, 01251], lr: 0.000147, loss: 0.4165
2022-10-04 06:42:33 - train: epoch 0071, iter [00390, 01251], lr: 0.000147, loss: 0.4174
2022-10-04 06:42:52 - train: epoch 0071, iter [00400, 01251], lr: 0.000147, loss: 0.4000
2022-10-04 06:43:11 - train: epoch 0071, iter [00410, 01251], lr: 0.000147, loss: 0.3906
2022-10-04 06:43:30 - train: epoch 0071, iter [00420, 01251], lr: 0.000147, loss: 0.3833
2022-10-04 06:43:49 - train: epoch 0071, iter [00430, 01251], lr: 0.000147, loss: 0.4330
2022-10-04 06:44:08 - train: epoch 0071, iter [00440, 01251], lr: 0.000147, loss: 0.4032
2022-10-04 06:44:27 - train: epoch 0071, iter [00450, 01251], lr: 0.000147, loss: 0.3842
2022-10-04 06:44:46 - train: epoch 0071, iter [00460, 01251], lr: 0.000147, loss: 0.4242
2022-10-04 06:45:04 - train: epoch 0071, iter [00470, 01251], lr: 0.000147, loss: 0.3849
2022-10-04 06:45:23 - train: epoch 0071, iter [00480, 01251], lr: 0.000147, loss: 0.4231
2022-10-04 06:45:42 - train: epoch 0071, iter [00490, 01251], lr: 0.000146, loss: 0.3876
2022-10-04 06:46:00 - train: epoch 0071, iter [00500, 01251], lr: 0.000146, loss: 0.3978
2022-10-04 06:46:19 - train: epoch 0071, iter [00510, 01251], lr: 0.000146, loss: 0.3987
2022-10-04 06:46:39 - train: epoch 0071, iter [00520, 01251], lr: 0.000146, loss: 0.4023
2022-10-04 06:46:58 - train: epoch 0071, iter [00530, 01251], lr: 0.000146, loss: 0.4085
2022-10-04 06:47:17 - train: epoch 0071, iter [00540, 01251], lr: 0.000146, loss: 0.4029
2022-10-04 06:47:35 - train: epoch 0071, iter [00550, 01251], lr: 0.000146, loss: 0.3894
2022-10-04 06:47:54 - train: epoch 0071, iter [00560, 01251], lr: 0.000146, loss: 0.4058
2022-10-04 06:48:12 - train: epoch 0071, iter [00570, 01251], lr: 0.000146, loss: 0.4048
2022-10-04 06:48:31 - train: epoch 0071, iter [00580, 01251], lr: 0.000146, loss: 0.4111
2022-10-04 06:48:50 - train: epoch 0071, iter [00590, 01251], lr: 0.000146, loss: 0.4097
2022-10-04 06:49:09 - train: epoch 0071, iter [00600, 01251], lr: 0.000146, loss: 0.4162
2022-10-04 06:49:28 - train: epoch 0071, iter [00610, 01251], lr: 0.000146, loss: 0.4174
2022-10-04 06:49:47 - train: epoch 0071, iter [00620, 01251], lr: 0.000146, loss: 0.4168
2022-10-04 06:50:06 - train: epoch 0071, iter [00630, 01251], lr: 0.000145, loss: 0.4169
2022-10-04 06:50:25 - train: epoch 0071, iter [00640, 01251], lr: 0.000145, loss: 0.4139
2022-10-04 06:50:44 - train: epoch 0071, iter [00650, 01251], lr: 0.000145, loss: 0.4052
2022-10-04 06:51:02 - train: epoch 0071, iter [00660, 01251], lr: 0.000145, loss: 0.4051
2022-10-04 06:51:21 - train: epoch 0071, iter [00670, 01251], lr: 0.000145, loss: 0.3953
2022-10-04 06:51:40 - train: epoch 0071, iter [00680, 01251], lr: 0.000145, loss: 0.4062
2022-10-04 06:51:59 - train: epoch 0071, iter [00690, 01251], lr: 0.000145, loss: 0.3911
2022-10-04 06:52:18 - train: epoch 0071, iter [00700, 01251], lr: 0.000145, loss: 0.3924
2022-10-04 06:52:37 - train: epoch 0071, iter [00710, 01251], lr: 0.000145, loss: 0.3971
2022-10-04 06:52:56 - train: epoch 0071, iter [00720, 01251], lr: 0.000145, loss: 0.4050
2022-10-04 06:53:15 - train: epoch 0071, iter [00730, 01251], lr: 0.000145, loss: 0.4167
2022-10-04 06:53:34 - train: epoch 0071, iter [00740, 01251], lr: 0.000145, loss: 0.3841
2022-10-04 06:53:53 - train: epoch 0071, iter [00750, 01251], lr: 0.000145, loss: 0.3874
2022-10-04 06:54:12 - train: epoch 0071, iter [00760, 01251], lr: 0.000145, loss: 0.4053
2022-10-04 06:54:30 - train: epoch 0071, iter [00770, 01251], lr: 0.000144, loss: 0.4145
2022-10-04 06:54:49 - train: epoch 0071, iter [00780, 01251], lr: 0.000144, loss: 0.4003
2022-10-04 06:55:08 - train: epoch 0071, iter [00790, 01251], lr: 0.000144, loss: 0.4141
2022-10-04 06:55:27 - train: epoch 0071, iter [00800, 01251], lr: 0.000144, loss: 0.4078
2022-10-04 06:55:45 - train: epoch 0071, iter [00810, 01251], lr: 0.000144, loss: 0.3967
2022-10-04 06:56:04 - train: epoch 0071, iter [00820, 01251], lr: 0.000144, loss: 0.4130
2022-10-04 06:56:23 - train: epoch 0071, iter [00830, 01251], lr: 0.000144, loss: 0.4036
2022-10-04 06:56:42 - train: epoch 0071, iter [00840, 01251], lr: 0.000144, loss: 0.3991
2022-10-04 06:57:01 - train: epoch 0071, iter [00850, 01251], lr: 0.000144, loss: 0.4007
2022-10-04 06:57:20 - train: epoch 0071, iter [00860, 01251], lr: 0.000144, loss: 0.3976
2022-10-04 06:57:38 - train: epoch 0071, iter [00870, 01251], lr: 0.000144, loss: 0.4077
2022-10-04 06:57:57 - train: epoch 0071, iter [00880, 01251], lr: 0.000144, loss: 0.4189
2022-10-04 06:58:16 - train: epoch 0071, iter [00890, 01251], lr: 0.000144, loss: 0.4052
2022-10-04 06:58:34 - train: epoch 0071, iter [00900, 01251], lr: 0.000144, loss: 0.3916
2022-10-04 06:58:53 - train: epoch 0071, iter [00910, 01251], lr: 0.000143, loss: 0.4077
2022-10-04 06:59:12 - train: epoch 0071, iter [00920, 01251], lr: 0.000143, loss: 0.3962
2022-10-04 06:59:31 - train: epoch 0071, iter [00930, 01251], lr: 0.000143, loss: 0.4199
2022-10-04 06:59:50 - train: epoch 0071, iter [00940, 01251], lr: 0.000143, loss: 0.3986
2022-10-04 07:00:09 - train: epoch 0071, iter [00950, 01251], lr: 0.000143, loss: 0.4172
2022-10-04 07:00:27 - train: epoch 0071, iter [00960, 01251], lr: 0.000143, loss: 0.4026
2022-10-04 07:00:46 - train: epoch 0071, iter [00970, 01251], lr: 0.000143, loss: 0.3906
2022-10-04 07:01:05 - train: epoch 0071, iter [00980, 01251], lr: 0.000143, loss: 0.4020
2022-10-04 07:01:23 - train: epoch 0071, iter [00990, 01251], lr: 0.000143, loss: 0.4285
2022-10-04 07:01:42 - train: epoch 0071, iter [01000, 01251], lr: 0.000143, loss: 0.4072
2022-10-04 07:02:01 - train: epoch 0071, iter [01010, 01251], lr: 0.000143, loss: 0.3914
2022-10-04 07:02:19 - train: epoch 0071, iter [01020, 01251], lr: 0.000143, loss: 0.3983
2022-10-04 07:02:38 - train: epoch 0071, iter [01030, 01251], lr: 0.000143, loss: 0.4030
2022-10-04 07:02:56 - train: epoch 0071, iter [01040, 01251], lr: 0.000143, loss: 0.4018
2022-10-04 07:03:15 - train: epoch 0071, iter [01050, 01251], lr: 0.000142, loss: 0.4039
2022-10-04 07:03:34 - train: epoch 0071, iter [01060, 01251], lr: 0.000142, loss: 0.3983
2022-10-04 07:03:53 - train: epoch 0071, iter [01070, 01251], lr: 0.000142, loss: 0.3915
2022-10-04 07:04:11 - train: epoch 0071, iter [01080, 01251], lr: 0.000142, loss: 0.3862
2022-10-04 07:04:30 - train: epoch 0071, iter [01090, 01251], lr: 0.000142, loss: 0.4112
2022-10-04 07:04:49 - train: epoch 0071, iter [01100, 01251], lr: 0.000142, loss: 0.3924
2022-10-04 07:05:08 - train: epoch 0071, iter [01110, 01251], lr: 0.000142, loss: 0.4033
2022-10-04 07:05:26 - train: epoch 0071, iter [01120, 01251], lr: 0.000142, loss: 0.4113
2022-10-04 07:05:45 - train: epoch 0071, iter [01130, 01251], lr: 0.000142, loss: 0.3953
2022-10-04 07:06:03 - train: epoch 0071, iter [01140, 01251], lr: 0.000142, loss: 0.4214
2022-10-04 07:06:22 - train: epoch 0071, iter [01150, 01251], lr: 0.000142, loss: 0.4091
2022-10-04 07:06:41 - train: epoch 0071, iter [01160, 01251], lr: 0.000142, loss: 0.3915
2022-10-04 07:06:59 - train: epoch 0071, iter [01170, 01251], lr: 0.000142, loss: 0.4152
2022-10-04 07:07:18 - train: epoch 0071, iter [01180, 01251], lr: 0.000142, loss: 0.4048
2022-10-04 07:07:37 - train: epoch 0071, iter [01190, 01251], lr: 0.000141, loss: 0.4007
2022-10-04 07:07:56 - train: epoch 0071, iter [01200, 01251], lr: 0.000141, loss: 0.4014
2022-10-04 07:08:15 - train: epoch 0071, iter [01210, 01251], lr: 0.000141, loss: 0.3993
2022-10-04 07:08:33 - train: epoch 0071, iter [01220, 01251], lr: 0.000141, loss: 0.4034
2022-10-04 07:08:52 - train: epoch 0071, iter [01230, 01251], lr: 0.000141, loss: 0.4227
2022-10-04 07:09:10 - train: epoch 0071, iter [01240, 01251], lr: 0.000141, loss: 0.3901
2022-10-04 07:09:29 - train: epoch 0071, iter [01250, 01251], lr: 0.000141, loss: 0.4065
2022-10-04 07:09:33 - train: epoch 071, train_loss: 0.4039
2022-10-04 07:09:38 - until epoch: 071, best_loss: 0.4039
2022-10-04 07:09:38 - epoch 072 lr: 0.000141
2022-10-04 07:10:02 - train: epoch 0072, iter [00010, 01251], lr: 0.000141, loss: 0.3978
2022-10-04 07:10:20 - train: epoch 0072, iter [00020, 01251], lr: 0.000141, loss: 0.4162
2022-10-04 07:10:39 - train: epoch 0072, iter [00030, 01251], lr: 0.000141, loss: 0.4022
2022-10-04 07:10:57 - train: epoch 0072, iter [00040, 01251], lr: 0.000141, loss: 0.4142
2022-10-04 07:11:16 - train: epoch 0072, iter [00050, 01251], lr: 0.000141, loss: 0.4115
2022-10-04 07:11:35 - train: epoch 0072, iter [00060, 01251], lr: 0.000141, loss: 0.4118
2022-10-04 07:11:54 - train: epoch 0072, iter [00070, 01251], lr: 0.000141, loss: 0.4025
2022-10-04 07:12:13 - train: epoch 0072, iter [00080, 01251], lr: 0.000140, loss: 0.3920
2022-10-04 07:12:31 - train: epoch 0072, iter [00090, 01251], lr: 0.000140, loss: 0.4005
2022-10-04 07:12:50 - train: epoch 0072, iter [00100, 01251], lr: 0.000140, loss: 0.4026
2022-10-04 07:13:09 - train: epoch 0072, iter [00110, 01251], lr: 0.000140, loss: 0.4195
2022-10-04 07:13:28 - train: epoch 0072, iter [00120, 01251], lr: 0.000140, loss: 0.3935
2022-10-04 07:13:47 - train: epoch 0072, iter [00130, 01251], lr: 0.000140, loss: 0.3998
2022-10-04 07:14:05 - train: epoch 0072, iter [00140, 01251], lr: 0.000140, loss: 0.4045
2022-10-04 07:14:24 - train: epoch 0072, iter [00150, 01251], lr: 0.000140, loss: 0.3942
2022-10-04 07:14:43 - train: epoch 0072, iter [00160, 01251], lr: 0.000140, loss: 0.4053
2022-10-04 07:15:01 - train: epoch 0072, iter [00170, 01251], lr: 0.000140, loss: 0.4352
2022-10-04 07:15:20 - train: epoch 0072, iter [00180, 01251], lr: 0.000140, loss: 0.4217
2022-10-04 07:15:39 - train: epoch 0072, iter [00190, 01251], lr: 0.000140, loss: 0.4364
2022-10-04 07:15:57 - train: epoch 0072, iter [00200, 01251], lr: 0.000140, loss: 0.4094
2022-10-04 07:16:16 - train: epoch 0072, iter [00210, 01251], lr: 0.000140, loss: 0.3969
2022-10-04 07:16:35 - train: epoch 0072, iter [00220, 01251], lr: 0.000139, loss: 0.3784
2022-10-04 07:16:54 - train: epoch 0072, iter [00230, 01251], lr: 0.000139, loss: 0.4137
2022-10-04 07:17:13 - train: epoch 0072, iter [00240, 01251], lr: 0.000139, loss: 0.3965
2022-10-04 07:17:32 - train: epoch 0072, iter [00250, 01251], lr: 0.000139, loss: 0.3959
2022-10-04 07:17:51 - train: epoch 0072, iter [00260, 01251], lr: 0.000139, loss: 0.4089
2022-10-04 07:18:09 - train: epoch 0072, iter [00270, 01251], lr: 0.000139, loss: 0.4003
2022-10-04 07:18:28 - train: epoch 0072, iter [00280, 01251], lr: 0.000139, loss: 0.3961
2022-10-04 07:18:47 - train: epoch 0072, iter [00290, 01251], lr: 0.000139, loss: 0.4071
2022-10-04 07:19:06 - train: epoch 0072, iter [00300, 01251], lr: 0.000139, loss: 0.4115
2022-10-04 07:19:24 - train: epoch 0072, iter [00310, 01251], lr: 0.000139, loss: 0.4045
2022-10-04 07:19:43 - train: epoch 0072, iter [00320, 01251], lr: 0.000139, loss: 0.4007
2022-10-04 07:20:02 - train: epoch 0072, iter [00330, 01251], lr: 0.000139, loss: 0.3955
2022-10-04 07:20:21 - train: epoch 0072, iter [00340, 01251], lr: 0.000139, loss: 0.3959
2022-10-04 07:20:40 - train: epoch 0072, iter [00350, 01251], lr: 0.000139, loss: 0.3947
2022-10-04 07:20:58 - train: epoch 0072, iter [00360, 01251], lr: 0.000138, loss: 0.4003
2022-10-04 07:21:17 - train: epoch 0072, iter [00370, 01251], lr: 0.000138, loss: 0.4102
2022-10-04 07:21:36 - train: epoch 0072, iter [00380, 01251], lr: 0.000138, loss: 0.4121
2022-10-04 07:21:55 - train: epoch 0072, iter [00390, 01251], lr: 0.000138, loss: 0.4120
2022-10-04 07:22:14 - train: epoch 0072, iter [00400, 01251], lr: 0.000138, loss: 0.4072
2022-10-04 07:22:32 - train: epoch 0072, iter [00410, 01251], lr: 0.000138, loss: 0.4275
2022-10-04 07:22:51 - train: epoch 0072, iter [00420, 01251], lr: 0.000138, loss: 0.4054
2022-10-04 07:23:09 - train: epoch 0072, iter [00430, 01251], lr: 0.000138, loss: 0.4052
2022-10-04 07:23:28 - train: epoch 0072, iter [00440, 01251], lr: 0.000138, loss: 0.3920
2022-10-04 07:23:47 - train: epoch 0072, iter [00450, 01251], lr: 0.000138, loss: 0.4134
2022-10-04 07:24:06 - train: epoch 0072, iter [00460, 01251], lr: 0.000138, loss: 0.3897
2022-10-04 07:24:25 - train: epoch 0072, iter [00470, 01251], lr: 0.000138, loss: 0.3963
2022-10-04 07:24:44 - train: epoch 0072, iter [00480, 01251], lr: 0.000138, loss: 0.3987
2022-10-04 07:25:02 - train: epoch 0072, iter [00490, 01251], lr: 0.000138, loss: 0.3888
2022-10-04 07:25:20 - train: epoch 0072, iter [00500, 01251], lr: 0.000137, loss: 0.3769
2022-10-04 07:25:39 - train: epoch 0072, iter [00510, 01251], lr: 0.000137, loss: 0.3902
2022-10-04 07:25:58 - train: epoch 0072, iter [00520, 01251], lr: 0.000137, loss: 0.4314
2022-10-04 07:26:17 - train: epoch 0072, iter [00530, 01251], lr: 0.000137, loss: 0.4063
2022-10-04 07:26:36 - train: epoch 0072, iter [00540, 01251], lr: 0.000137, loss: 0.4109
2022-10-04 07:26:54 - train: epoch 0072, iter [00550, 01251], lr: 0.000137, loss: 0.4096
2022-10-04 07:27:12 - train: epoch 0072, iter [00560, 01251], lr: 0.000137, loss: 0.4004
2022-10-04 07:27:31 - train: epoch 0072, iter [00570, 01251], lr: 0.000137, loss: 0.4039
2022-10-04 07:27:50 - train: epoch 0072, iter [00580, 01251], lr: 0.000137, loss: 0.4056
2022-10-04 07:28:08 - train: epoch 0072, iter [00590, 01251], lr: 0.000137, loss: 0.4019
2022-10-04 07:28:27 - train: epoch 0072, iter [00600, 01251], lr: 0.000137, loss: 0.3793
2022-10-04 07:28:45 - train: epoch 0072, iter [00610, 01251], lr: 0.000137, loss: 0.4176
2022-10-04 07:29:04 - train: epoch 0072, iter [00620, 01251], lr: 0.000137, loss: 0.4168
2022-10-04 07:29:23 - train: epoch 0072, iter [00630, 01251], lr: 0.000137, loss: 0.4181
2022-10-04 07:29:42 - train: epoch 0072, iter [00640, 01251], lr: 0.000137, loss: 0.3822
2022-10-04 07:30:01 - train: epoch 0072, iter [00650, 01251], lr: 0.000136, loss: 0.3855
2022-10-04 07:30:19 - train: epoch 0072, iter [00660, 01251], lr: 0.000136, loss: 0.4177
2022-10-04 07:30:38 - train: epoch 0072, iter [00670, 01251], lr: 0.000136, loss: 0.4051
2022-10-04 07:30:57 - train: epoch 0072, iter [00680, 01251], lr: 0.000136, loss: 0.4081
2022-10-04 07:31:16 - train: epoch 0072, iter [00690, 01251], lr: 0.000136, loss: 0.3896
2022-10-04 07:31:35 - train: epoch 0072, iter [00700, 01251], lr: 0.000136, loss: 0.4030
2022-10-04 07:31:53 - train: epoch 0072, iter [00710, 01251], lr: 0.000136, loss: 0.4183
2022-10-04 07:32:12 - train: epoch 0072, iter [00720, 01251], lr: 0.000136, loss: 0.4056
2022-10-04 07:32:30 - train: epoch 0072, iter [00730, 01251], lr: 0.000136, loss: 0.4132
2022-10-04 07:32:49 - train: epoch 0072, iter [00740, 01251], lr: 0.000136, loss: 0.3968
2022-10-04 07:33:08 - train: epoch 0072, iter [00750, 01251], lr: 0.000136, loss: 0.4019
2022-10-04 07:33:27 - train: epoch 0072, iter [00760, 01251], lr: 0.000136, loss: 0.4168
2022-10-04 07:33:45 - train: epoch 0072, iter [00770, 01251], lr: 0.000136, loss: 0.4019
2022-10-04 07:34:04 - train: epoch 0072, iter [00780, 01251], lr: 0.000136, loss: 0.3954
2022-10-04 07:34:23 - train: epoch 0072, iter [00790, 01251], lr: 0.000135, loss: 0.4062
2022-10-04 07:34:41 - train: epoch 0072, iter [00800, 01251], lr: 0.000135, loss: 0.4085
2022-10-04 07:35:00 - train: epoch 0072, iter [00810, 01251], lr: 0.000135, loss: 0.3910
2022-10-04 07:35:19 - train: epoch 0072, iter [00820, 01251], lr: 0.000135, loss: 0.3675
2022-10-04 07:35:37 - train: epoch 0072, iter [00830, 01251], lr: 0.000135, loss: 0.3903
2022-10-04 07:35:56 - train: epoch 0072, iter [00840, 01251], lr: 0.000135, loss: 0.4177
2022-10-04 07:36:14 - train: epoch 0072, iter [00850, 01251], lr: 0.000135, loss: 0.4030
2022-10-04 07:36:33 - train: epoch 0072, iter [00860, 01251], lr: 0.000135, loss: 0.4016
2022-10-04 07:36:52 - train: epoch 0072, iter [00870, 01251], lr: 0.000135, loss: 0.3979
2022-10-04 07:37:11 - train: epoch 0072, iter [00880, 01251], lr: 0.000135, loss: 0.4119
2022-10-04 07:37:29 - train: epoch 0072, iter [00890, 01251], lr: 0.000135, loss: 0.4109
2022-10-04 07:37:48 - train: epoch 0072, iter [00900, 01251], lr: 0.000135, loss: 0.3978
2022-10-04 07:38:07 - train: epoch 0072, iter [00910, 01251], lr: 0.000135, loss: 0.4028
2022-10-04 07:38:25 - train: epoch 0072, iter [00920, 01251], lr: 0.000135, loss: 0.4150
2022-10-04 07:38:44 - train: epoch 0072, iter [00930, 01251], lr: 0.000134, loss: 0.4004
2022-10-04 07:39:03 - train: epoch 0072, iter [00940, 01251], lr: 0.000134, loss: 0.3914
2022-10-04 07:39:22 - train: epoch 0072, iter [00950, 01251], lr: 0.000134, loss: 0.4111
2022-10-04 07:39:40 - train: epoch 0072, iter [00960, 01251], lr: 0.000134, loss: 0.4009
2022-10-04 07:39:59 - train: epoch 0072, iter [00970, 01251], lr: 0.000134, loss: 0.4084
2022-10-04 07:40:17 - train: epoch 0072, iter [00980, 01251], lr: 0.000134, loss: 0.4188
2022-10-04 07:40:36 - train: epoch 0072, iter [00990, 01251], lr: 0.000134, loss: 0.4013
2022-10-04 07:40:55 - train: epoch 0072, iter [01000, 01251], lr: 0.000134, loss: 0.4116
2022-10-04 07:41:13 - train: epoch 0072, iter [01010, 01251], lr: 0.000134, loss: 0.3987
2022-10-04 07:41:32 - train: epoch 0072, iter [01020, 01251], lr: 0.000134, loss: 0.3891
2022-10-04 07:41:51 - train: epoch 0072, iter [01030, 01251], lr: 0.000134, loss: 0.3976
2022-10-04 07:42:10 - train: epoch 0072, iter [01040, 01251], lr: 0.000134, loss: 0.4127
2022-10-04 07:42:28 - train: epoch 0072, iter [01050, 01251], lr: 0.000134, loss: 0.3967
2022-10-04 07:42:47 - train: epoch 0072, iter [01060, 01251], lr: 0.000134, loss: 0.4128
2022-10-04 07:43:05 - train: epoch 0072, iter [01070, 01251], lr: 0.000134, loss: 0.3898
2022-10-04 07:43:24 - train: epoch 0072, iter [01080, 01251], lr: 0.000133, loss: 0.4096
2022-10-04 07:43:43 - train: epoch 0072, iter [01090, 01251], lr: 0.000133, loss: 0.4351
2022-10-04 07:44:01 - train: epoch 0072, iter [01100, 01251], lr: 0.000133, loss: 0.4145
2022-10-04 07:44:20 - train: epoch 0072, iter [01110, 01251], lr: 0.000133, loss: 0.4115
2022-10-04 07:44:39 - train: epoch 0072, iter [01120, 01251], lr: 0.000133, loss: 0.3984
2022-10-04 07:44:58 - train: epoch 0072, iter [01130, 01251], lr: 0.000133, loss: 0.3898
2022-10-04 07:45:16 - train: epoch 0072, iter [01140, 01251], lr: 0.000133, loss: 0.4088
2022-10-04 07:45:35 - train: epoch 0072, iter [01150, 01251], lr: 0.000133, loss: 0.4018
2022-10-04 07:45:53 - train: epoch 0072, iter [01160, 01251], lr: 0.000133, loss: 0.4256
2022-10-04 07:46:12 - train: epoch 0072, iter [01170, 01251], lr: 0.000133, loss: 0.3923
2022-10-04 07:46:31 - train: epoch 0072, iter [01180, 01251], lr: 0.000133, loss: 0.4171
2022-10-04 07:46:49 - train: epoch 0072, iter [01190, 01251], lr: 0.000133, loss: 0.3958
2022-10-04 07:47:08 - train: epoch 0072, iter [01200, 01251], lr: 0.000133, loss: 0.4027
2022-10-04 07:47:27 - train: epoch 0072, iter [01210, 01251], lr: 0.000133, loss: 0.4062
2022-10-04 07:47:45 - train: epoch 0072, iter [01220, 01251], lr: 0.000132, loss: 0.3906
2022-10-04 07:48:04 - train: epoch 0072, iter [01230, 01251], lr: 0.000132, loss: 0.3900
2022-10-04 07:48:22 - train: epoch 0072, iter [01240, 01251], lr: 0.000132, loss: 0.4099
2022-10-04 07:48:41 - train: epoch 0072, iter [01250, 01251], lr: 0.000132, loss: 0.4029
2022-10-04 07:48:46 - train: epoch 072, train_loss: 0.4036
2022-10-04 07:48:50 - until epoch: 072, best_loss: 0.4036
2022-10-04 07:48:50 - epoch 073 lr: 0.000132
2022-10-04 07:49:14 - train: epoch 0073, iter [00010, 01251], lr: 0.000132, loss: 0.3980
2022-10-04 07:49:33 - train: epoch 0073, iter [00020, 01251], lr: 0.000132, loss: 0.4062
2022-10-04 07:49:52 - train: epoch 0073, iter [00030, 01251], lr: 0.000132, loss: 0.4032
2022-10-04 07:50:11 - train: epoch 0073, iter [00040, 01251], lr: 0.000132, loss: 0.4153
2022-10-04 07:50:30 - train: epoch 0073, iter [00050, 01251], lr: 0.000132, loss: 0.3971
2022-10-04 07:50:48 - train: epoch 0073, iter [00060, 01251], lr: 0.000132, loss: 0.4179
2022-10-04 07:51:07 - train: epoch 0073, iter [00070, 01251], lr: 0.000132, loss: 0.3969
2022-10-04 07:51:25 - train: epoch 0073, iter [00080, 01251], lr: 0.000132, loss: 0.4025
2022-10-04 07:51:44 - train: epoch 0073, iter [00090, 01251], lr: 0.000132, loss: 0.3869
2022-10-04 07:52:03 - train: epoch 0073, iter [00100, 01251], lr: 0.000132, loss: 0.3967
2022-10-04 07:52:22 - train: epoch 0073, iter [00110, 01251], lr: 0.000131, loss: 0.4035
2022-10-04 07:52:41 - train: epoch 0073, iter [00120, 01251], lr: 0.000131, loss: 0.4130
2022-10-04 07:52:59 - train: epoch 0073, iter [00130, 01251], lr: 0.000131, loss: 0.4065
2022-10-04 07:53:18 - train: epoch 0073, iter [00140, 01251], lr: 0.000131, loss: 0.4090
2022-10-04 07:53:36 - train: epoch 0073, iter [00150, 01251], lr: 0.000131, loss: 0.4062
2022-10-04 07:53:55 - train: epoch 0073, iter [00160, 01251], lr: 0.000131, loss: 0.4058
2022-10-04 07:54:14 - train: epoch 0073, iter [00170, 01251], lr: 0.000131, loss: 0.3956
2022-10-04 07:54:33 - train: epoch 0073, iter [00180, 01251], lr: 0.000131, loss: 0.3949
2022-10-04 07:54:52 - train: epoch 0073, iter [00190, 01251], lr: 0.000131, loss: 0.4011
2022-10-04 07:55:11 - train: epoch 0073, iter [00200, 01251], lr: 0.000131, loss: 0.4167
2022-10-04 07:55:29 - train: epoch 0073, iter [00210, 01251], lr: 0.000131, loss: 0.3952
2022-10-04 07:55:48 - train: epoch 0073, iter [00220, 01251], lr: 0.000131, loss: 0.4136
2022-10-04 07:56:07 - train: epoch 0073, iter [00230, 01251], lr: 0.000131, loss: 0.3931
2022-10-04 07:56:25 - train: epoch 0073, iter [00240, 01251], lr: 0.000131, loss: 0.3894
2022-10-04 07:56:44 - train: epoch 0073, iter [00250, 01251], lr: 0.000131, loss: 0.3906
2022-10-04 07:57:02 - train: epoch 0073, iter [00260, 01251], lr: 0.000130, loss: 0.4001
2022-10-04 07:57:21 - train: epoch 0073, iter [00270, 01251], lr: 0.000130, loss: 0.4166
2022-10-04 07:57:40 - train: epoch 0073, iter [00280, 01251], lr: 0.000130, loss: 0.4014
2022-10-04 07:57:59 - train: epoch 0073, iter [00290, 01251], lr: 0.000130, loss: 0.4106
2022-10-04 07:58:18 - train: epoch 0073, iter [00300, 01251], lr: 0.000130, loss: 0.4042
2022-10-04 07:58:37 - train: epoch 0073, iter [00310, 01251], lr: 0.000130, loss: 0.4113
2022-10-04 07:58:56 - train: epoch 0073, iter [00320, 01251], lr: 0.000130, loss: 0.3983
2022-10-04 07:59:15 - train: epoch 0073, iter [00330, 01251], lr: 0.000130, loss: 0.4178
2022-10-04 07:59:33 - train: epoch 0073, iter [00340, 01251], lr: 0.000130, loss: 0.4116
2022-10-04 07:59:52 - train: epoch 0073, iter [00350, 01251], lr: 0.000130, loss: 0.3978
2022-10-04 08:00:11 - train: epoch 0073, iter [00360, 01251], lr: 0.000130, loss: 0.3885
2022-10-04 08:00:30 - train: epoch 0073, iter [00370, 01251], lr: 0.000130, loss: 0.4124
2022-10-04 08:00:49 - train: epoch 0073, iter [00380, 01251], lr: 0.000130, loss: 0.3925
2022-10-04 08:01:07 - train: epoch 0073, iter [00390, 01251], lr: 0.000130, loss: 0.4128
2022-10-04 08:01:26 - train: epoch 0073, iter [00400, 01251], lr: 0.000129, loss: 0.4013
2022-10-04 08:01:45 - train: epoch 0073, iter [00410, 01251], lr: 0.000129, loss: 0.4052
2022-10-04 08:02:03 - train: epoch 0073, iter [00420, 01251], lr: 0.000129, loss: 0.4169
2022-10-04 08:02:22 - train: epoch 0073, iter [00430, 01251], lr: 0.000129, loss: 0.3939
2022-10-04 08:02:41 - train: epoch 0073, iter [00440, 01251], lr: 0.000129, loss: 0.4026
2022-10-04 08:03:00 - train: epoch 0073, iter [00450, 01251], lr: 0.000129, loss: 0.4065
2022-10-04 08:03:18 - train: epoch 0073, iter [00460, 01251], lr: 0.000129, loss: 0.4010
2022-10-04 08:03:37 - train: epoch 0073, iter [00470, 01251], lr: 0.000129, loss: 0.4057
2022-10-04 08:03:56 - train: epoch 0073, iter [00480, 01251], lr: 0.000129, loss: 0.4104
2022-10-04 08:04:15 - train: epoch 0073, iter [00490, 01251], lr: 0.000129, loss: 0.4219
2022-10-04 08:04:33 - train: epoch 0073, iter [00500, 01251], lr: 0.000129, loss: 0.4080
2022-10-04 08:04:52 - train: epoch 0073, iter [00510, 01251], lr: 0.000129, loss: 0.3981
2022-10-04 08:05:10 - train: epoch 0073, iter [00520, 01251], lr: 0.000129, loss: 0.4128
2022-10-04 08:05:29 - train: epoch 0073, iter [00530, 01251], lr: 0.000129, loss: 0.3949
2022-10-04 08:05:48 - train: epoch 0073, iter [00540, 01251], lr: 0.000129, loss: 0.4054
2022-10-04 08:06:07 - train: epoch 0073, iter [00550, 01251], lr: 0.000128, loss: 0.3850
2022-10-04 08:06:26 - train: epoch 0073, iter [00560, 01251], lr: 0.000128, loss: 0.4226
2022-10-04 08:06:45 - train: epoch 0073, iter [00570, 01251], lr: 0.000128, loss: 0.4025
2022-10-04 08:07:03 - train: epoch 0073, iter [00580, 01251], lr: 0.000128, loss: 0.4178
2022-10-04 08:07:22 - train: epoch 0073, iter [00590, 01251], lr: 0.000128, loss: 0.4083
2022-10-04 08:07:41 - train: epoch 0073, iter [00600, 01251], lr: 0.000128, loss: 0.4155
2022-10-04 08:08:00 - train: epoch 0073, iter [00610, 01251], lr: 0.000128, loss: 0.4072
2022-10-04 08:08:19 - train: epoch 0073, iter [00620, 01251], lr: 0.000128, loss: 0.3991
2022-10-04 08:08:37 - train: epoch 0073, iter [00630, 01251], lr: 0.000128, loss: 0.3974
2022-10-04 08:08:56 - train: epoch 0073, iter [00640, 01251], lr: 0.000128, loss: 0.4113
2022-10-04 08:09:15 - train: epoch 0073, iter [00650, 01251], lr: 0.000128, loss: 0.3914
2022-10-04 08:09:34 - train: epoch 0073, iter [00660, 01251], lr: 0.000128, loss: 0.3999
2022-10-04 08:09:52 - train: epoch 0073, iter [00670, 01251], lr: 0.000128, loss: 0.3978
2022-10-04 08:10:11 - train: epoch 0073, iter [00680, 01251], lr: 0.000128, loss: 0.4054
2022-10-04 08:10:30 - train: epoch 0073, iter [00690, 01251], lr: 0.000127, loss: 0.4255
2022-10-04 08:10:48 - train: epoch 0073, iter [00700, 01251], lr: 0.000127, loss: 0.4019
2022-10-04 08:11:07 - train: epoch 0073, iter [00710, 01251], lr: 0.000127, loss: 0.4024
2022-10-04 08:11:26 - train: epoch 0073, iter [00720, 01251], lr: 0.000127, loss: 0.4207
2022-10-04 08:11:45 - train: epoch 0073, iter [00730, 01251], lr: 0.000127, loss: 0.3917
2022-10-04 08:12:04 - train: epoch 0073, iter [00740, 01251], lr: 0.000127, loss: 0.3963
2022-10-04 08:12:22 - train: epoch 0073, iter [00750, 01251], lr: 0.000127, loss: 0.4030
2022-10-04 08:12:41 - train: epoch 0073, iter [00760, 01251], lr: 0.000127, loss: 0.4045
2022-10-04 08:12:59 - train: epoch 0073, iter [00770, 01251], lr: 0.000127, loss: 0.3854
2022-10-04 08:13:18 - train: epoch 0073, iter [00780, 01251], lr: 0.000127, loss: 0.3943
2022-10-04 08:13:37 - train: epoch 0073, iter [00790, 01251], lr: 0.000127, loss: 0.4000
2022-10-04 08:13:55 - train: epoch 0073, iter [00800, 01251], lr: 0.000127, loss: 0.3862
2022-10-04 08:14:14 - train: epoch 0073, iter [00810, 01251], lr: 0.000127, loss: 0.3948
2022-10-04 08:14:33 - train: epoch 0073, iter [00820, 01251], lr: 0.000127, loss: 0.4186
2022-10-04 08:14:52 - train: epoch 0073, iter [00830, 01251], lr: 0.000127, loss: 0.4016
2022-10-04 08:15:10 - train: epoch 0073, iter [00840, 01251], lr: 0.000126, loss: 0.4184
2022-10-04 08:15:29 - train: epoch 0073, iter [00850, 01251], lr: 0.000126, loss: 0.3974
2022-10-04 08:15:48 - train: epoch 0073, iter [00860, 01251], lr: 0.000126, loss: 0.3722
2022-10-04 08:16:06 - train: epoch 0073, iter [00870, 01251], lr: 0.000126, loss: 0.3954
2022-10-04 08:16:25 - train: epoch 0073, iter [00880, 01251], lr: 0.000126, loss: 0.4061
2022-10-04 08:16:44 - train: epoch 0073, iter [00890, 01251], lr: 0.000126, loss: 0.4301
2022-10-04 08:17:02 - train: epoch 0073, iter [00900, 01251], lr: 0.000126, loss: 0.4037
2022-10-04 08:17:21 - train: epoch 0073, iter [00910, 01251], lr: 0.000126, loss: 0.3992
2022-10-04 08:17:40 - train: epoch 0073, iter [00920, 01251], lr: 0.000126, loss: 0.4088
2022-10-04 08:17:58 - train: epoch 0073, iter [00930, 01251], lr: 0.000126, loss: 0.3965
2022-10-04 08:18:17 - train: epoch 0073, iter [00940, 01251], lr: 0.000126, loss: 0.3989
2022-10-04 08:18:36 - train: epoch 0073, iter [00950, 01251], lr: 0.000126, loss: 0.3822
2022-10-04 08:18:55 - train: epoch 0073, iter [00960, 01251], lr: 0.000126, loss: 0.3929
2022-10-04 08:19:14 - train: epoch 0073, iter [00970, 01251], lr: 0.000126, loss: 0.4077
2022-10-04 08:19:33 - train: epoch 0073, iter [00980, 01251], lr: 0.000126, loss: 0.3797
2022-10-04 08:19:52 - train: epoch 0073, iter [00990, 01251], lr: 0.000125, loss: 0.4248
2022-10-04 08:20:11 - train: epoch 0073, iter [01000, 01251], lr: 0.000125, loss: 0.4093
2022-10-04 08:20:30 - train: epoch 0073, iter [01010, 01251], lr: 0.000125, loss: 0.3887
2022-10-04 08:20:50 - train: epoch 0073, iter [01020, 01251], lr: 0.000125, loss: 0.4040
2022-10-04 08:21:08 - train: epoch 0073, iter [01030, 01251], lr: 0.000125, loss: 0.4273
2022-10-04 08:21:27 - train: epoch 0073, iter [01040, 01251], lr: 0.000125, loss: 0.4192
2022-10-04 08:21:45 - train: epoch 0073, iter [01050, 01251], lr: 0.000125, loss: 0.4096
2022-10-04 08:22:04 - train: epoch 0073, iter [01060, 01251], lr: 0.000125, loss: 0.4010
2022-10-04 08:22:22 - train: epoch 0073, iter [01070, 01251], lr: 0.000125, loss: 0.4299
2022-10-04 08:22:41 - train: epoch 0073, iter [01080, 01251], lr: 0.000125, loss: 0.3992
2022-10-04 08:23:00 - train: epoch 0073, iter [01090, 01251], lr: 0.000125, loss: 0.3951
2022-10-04 08:23:19 - train: epoch 0073, iter [01100, 01251], lr: 0.000125, loss: 0.4134
2022-10-04 08:23:37 - train: epoch 0073, iter [01110, 01251], lr: 0.000125, loss: 0.3955
2022-10-04 08:23:56 - train: epoch 0073, iter [01120, 01251], lr: 0.000125, loss: 0.4040
2022-10-04 08:24:14 - train: epoch 0073, iter [01130, 01251], lr: 0.000124, loss: 0.4170
2022-10-04 08:24:32 - train: epoch 0073, iter [01140, 01251], lr: 0.000124, loss: 0.3979
2022-10-04 08:24:51 - train: epoch 0073, iter [01150, 01251], lr: 0.000124, loss: 0.3979
2022-10-04 08:25:11 - train: epoch 0073, iter [01160, 01251], lr: 0.000124, loss: 0.4116
2022-10-04 08:25:29 - train: epoch 0073, iter [01170, 01251], lr: 0.000124, loss: 0.4062
2022-10-04 08:25:48 - train: epoch 0073, iter [01180, 01251], lr: 0.000124, loss: 0.4006
2022-10-04 08:26:06 - train: epoch 0073, iter [01190, 01251], lr: 0.000124, loss: 0.4076
2022-10-04 08:26:25 - train: epoch 0073, iter [01200, 01251], lr: 0.000124, loss: 0.3921
2022-10-04 08:26:44 - train: epoch 0073, iter [01210, 01251], lr: 0.000124, loss: 0.4269
2022-10-04 08:27:02 - train: epoch 0073, iter [01220, 01251], lr: 0.000124, loss: 0.3982
2022-10-04 08:27:21 - train: epoch 0073, iter [01230, 01251], lr: 0.000124, loss: 0.4021
2022-10-04 08:27:40 - train: epoch 0073, iter [01240, 01251], lr: 0.000124, loss: 0.4164
2022-10-04 08:27:58 - train: epoch 0073, iter [01250, 01251], lr: 0.000124, loss: 0.4067
2022-10-04 08:28:03 - train: epoch 073, train_loss: 0.4034
2022-10-04 08:28:07 - until epoch: 073, best_loss: 0.4034
2022-10-04 08:28:07 - epoch 074 lr: 0.000124
2022-10-04 08:28:32 - train: epoch 0074, iter [00010, 01251], lr: 0.000124, loss: 0.4060
2022-10-04 08:28:51 - train: epoch 0074, iter [00020, 01251], lr: 0.000124, loss: 0.3940
2022-10-04 08:29:10 - train: epoch 0074, iter [00030, 01251], lr: 0.000123, loss: 0.3951
2022-10-04 08:29:28 - train: epoch 0074, iter [00040, 01251], lr: 0.000123, loss: 0.4087
2022-10-04 08:29:47 - train: epoch 0074, iter [00050, 01251], lr: 0.000123, loss: 0.4035
2022-10-04 08:30:06 - train: epoch 0074, iter [00060, 01251], lr: 0.000123, loss: 0.3828
2022-10-04 08:30:24 - train: epoch 0074, iter [00070, 01251], lr: 0.000123, loss: 0.4124
2022-10-04 08:30:43 - train: epoch 0074, iter [00080, 01251], lr: 0.000123, loss: 0.4053
2022-10-04 08:31:02 - train: epoch 0074, iter [00090, 01251], lr: 0.000123, loss: 0.4032
2022-10-04 08:31:21 - train: epoch 0074, iter [00100, 01251], lr: 0.000123, loss: 0.3946
2022-10-04 08:31:40 - train: epoch 0074, iter [00110, 01251], lr: 0.000123, loss: 0.3998
2022-10-04 08:31:58 - train: epoch 0074, iter [00120, 01251], lr: 0.000123, loss: 0.4032
2022-10-04 08:32:17 - train: epoch 0074, iter [00130, 01251], lr: 0.000123, loss: 0.4010
2022-10-04 08:32:35 - train: epoch 0074, iter [00140, 01251], lr: 0.000123, loss: 0.3971
2022-10-04 08:32:54 - train: epoch 0074, iter [00150, 01251], lr: 0.000123, loss: 0.4021
2022-10-04 08:33:13 - train: epoch 0074, iter [00160, 01251], lr: 0.000123, loss: 0.4091
2022-10-04 08:33:32 - train: epoch 0074, iter [00170, 01251], lr: 0.000123, loss: 0.4153
2022-10-04 08:33:51 - train: epoch 0074, iter [00180, 01251], lr: 0.000122, loss: 0.4028
2022-10-04 08:34:10 - train: epoch 0074, iter [00190, 01251], lr: 0.000122, loss: 0.3930
2022-10-04 08:34:28 - train: epoch 0074, iter [00200, 01251], lr: 0.000122, loss: 0.4112
2022-10-04 08:34:47 - train: epoch 0074, iter [00210, 01251], lr: 0.000122, loss: 0.4117
2022-10-04 08:35:06 - train: epoch 0074, iter [00220, 01251], lr: 0.000122, loss: 0.3794
2022-10-04 08:35:24 - train: epoch 0074, iter [00230, 01251], lr: 0.000122, loss: 0.4162
2022-10-04 08:35:43 - train: epoch 0074, iter [00240, 01251], lr: 0.000122, loss: 0.4027
2022-10-04 08:36:01 - train: epoch 0074, iter [00250, 01251], lr: 0.000122, loss: 0.4209
2022-10-04 08:36:20 - train: epoch 0074, iter [00260, 01251], lr: 0.000122, loss: 0.4043
2022-10-04 08:36:39 - train: epoch 0074, iter [00270, 01251], lr: 0.000122, loss: 0.4217
2022-10-04 08:36:58 - train: epoch 0074, iter [00280, 01251], lr: 0.000122, loss: 0.3927
2022-10-04 08:37:16 - train: epoch 0074, iter [00290, 01251], lr: 0.000122, loss: 0.3962
2022-10-04 08:37:35 - train: epoch 0074, iter [00300, 01251], lr: 0.000122, loss: 0.3974
2022-10-04 08:37:54 - train: epoch 0074, iter [00310, 01251], lr: 0.000122, loss: 0.4162
2022-10-04 08:38:13 - train: epoch 0074, iter [00320, 01251], lr: 0.000122, loss: 0.4034
2022-10-04 08:38:32 - train: epoch 0074, iter [00330, 01251], lr: 0.000121, loss: 0.4047
2022-10-04 08:38:50 - train: epoch 0074, iter [00340, 01251], lr: 0.000121, loss: 0.3909
2022-10-04 08:39:09 - train: epoch 0074, iter [00350, 01251], lr: 0.000121, loss: 0.4100
2022-10-04 08:39:29 - train: epoch 0074, iter [00360, 01251], lr: 0.000121, loss: 0.4007
2022-10-04 08:39:48 - train: epoch 0074, iter [00370, 01251], lr: 0.000121, loss: 0.4195
2022-10-04 08:40:06 - train: epoch 0074, iter [00380, 01251], lr: 0.000121, loss: 0.4157
2022-10-04 08:40:25 - train: epoch 0074, iter [00390, 01251], lr: 0.000121, loss: 0.3901
2022-10-04 08:40:44 - train: epoch 0074, iter [00400, 01251], lr: 0.000121, loss: 0.4028
2022-10-04 08:41:03 - train: epoch 0074, iter [00410, 01251], lr: 0.000121, loss: 0.4016
2022-10-04 08:41:21 - train: epoch 0074, iter [00420, 01251], lr: 0.000121, loss: 0.3869
2022-10-04 08:41:40 - train: epoch 0074, iter [00430, 01251], lr: 0.000121, loss: 0.3991
2022-10-04 08:41:59 - train: epoch 0074, iter [00440, 01251], lr: 0.000121, loss: 0.3935
2022-10-04 08:42:18 - train: epoch 0074, iter [00450, 01251], lr: 0.000121, loss: 0.4087
2022-10-04 08:42:36 - train: epoch 0074, iter [00460, 01251], lr: 0.000121, loss: 0.4092
2022-10-04 08:42:55 - train: epoch 0074, iter [00470, 01251], lr: 0.000120, loss: 0.4021
2022-10-04 08:43:14 - train: epoch 0074, iter [00480, 01251], lr: 0.000120, loss: 0.4035
2022-10-04 08:43:32 - train: epoch 0074, iter [00490, 01251], lr: 0.000120, loss: 0.3990
2022-10-04 08:43:51 - train: epoch 0074, iter [00500, 01251], lr: 0.000120, loss: 0.4191
2022-10-04 08:44:10 - train: epoch 0074, iter [00510, 01251], lr: 0.000120, loss: 0.4060
2022-10-04 08:44:29 - train: epoch 0074, iter [00520, 01251], lr: 0.000120, loss: 0.3954
2022-10-04 08:44:48 - train: epoch 0074, iter [00530, 01251], lr: 0.000120, loss: 0.4201
2022-10-04 08:45:06 - train: epoch 0074, iter [00540, 01251], lr: 0.000120, loss: 0.3981
2022-10-04 08:45:25 - train: epoch 0074, iter [00550, 01251], lr: 0.000120, loss: 0.4129
2022-10-04 08:45:44 - train: epoch 0074, iter [00560, 01251], lr: 0.000120, loss: 0.3956
2022-10-04 08:46:02 - train: epoch 0074, iter [00570, 01251], lr: 0.000120, loss: 0.4014
2022-10-04 08:46:21 - train: epoch 0074, iter [00580, 01251], lr: 0.000120, loss: 0.4181
2022-10-04 08:46:40 - train: epoch 0074, iter [00590, 01251], lr: 0.000120, loss: 0.4123
2022-10-04 08:46:58 - train: epoch 0074, iter [00600, 01251], lr: 0.000120, loss: 0.4252
2022-10-04 08:47:16 - train: epoch 0074, iter [00610, 01251], lr: 0.000120, loss: 0.4102
2022-10-04 08:47:35 - train: epoch 0074, iter [00620, 01251], lr: 0.000119, loss: 0.3992
2022-10-04 08:47:53 - train: epoch 0074, iter [00630, 01251], lr: 0.000119, loss: 0.4056
2022-10-04 08:48:12 - train: epoch 0074, iter [00640, 01251], lr: 0.000119, loss: 0.3976
2022-10-04 08:48:31 - train: epoch 0074, iter [00650, 01251], lr: 0.000119, loss: 0.4048
2022-10-04 08:48:50 - train: epoch 0074, iter [00660, 01251], lr: 0.000119, loss: 0.4039
2022-10-04 08:49:08 - train: epoch 0074, iter [00670, 01251], lr: 0.000119, loss: 0.3879
2022-10-04 08:49:27 - train: epoch 0074, iter [00680, 01251], lr: 0.000119, loss: 0.4076
2022-10-04 08:49:45 - train: epoch 0074, iter [00690, 01251], lr: 0.000119, loss: 0.4179
2022-10-04 08:50:04 - train: epoch 0074, iter [00700, 01251], lr: 0.000119, loss: 0.4135
2022-10-04 08:50:23 - train: epoch 0074, iter [00710, 01251], lr: 0.000119, loss: 0.3710
2022-10-04 08:50:42 - train: epoch 0074, iter [00720, 01251], lr: 0.000119, loss: 0.3926
2022-10-04 08:51:00 - train: epoch 0074, iter [00730, 01251], lr: 0.000119, loss: 0.4066
2022-10-04 08:51:19 - train: epoch 0074, iter [00740, 01251], lr: 0.000119, loss: 0.4128
2022-10-04 08:51:38 - train: epoch 0074, iter [00750, 01251], lr: 0.000119, loss: 0.4132
2022-10-04 08:51:56 - train: epoch 0074, iter [00760, 01251], lr: 0.000119, loss: 0.3927
2022-10-04 08:52:15 - train: epoch 0074, iter [00770, 01251], lr: 0.000118, loss: 0.4101
2022-10-04 08:52:34 - train: epoch 0074, iter [00780, 01251], lr: 0.000118, loss: 0.4196
2022-10-04 08:52:53 - train: epoch 0074, iter [00790, 01251], lr: 0.000118, loss: 0.3884
2022-10-04 08:53:12 - train: epoch 0074, iter [00800, 01251], lr: 0.000118, loss: 0.3977
2022-10-04 08:53:30 - train: epoch 0074, iter [00810, 01251], lr: 0.000118, loss: 0.4027
2022-10-04 08:53:49 - train: epoch 0074, iter [00820, 01251], lr: 0.000118, loss: 0.4122
2022-10-04 08:54:07 - train: epoch 0074, iter [00830, 01251], lr: 0.000118, loss: 0.4077
2022-10-04 08:54:26 - train: epoch 0074, iter [00840, 01251], lr: 0.000118, loss: 0.3894
2022-10-04 08:54:45 - train: epoch 0074, iter [00850, 01251], lr: 0.000118, loss: 0.3930
2022-10-04 08:55:04 - train: epoch 0074, iter [00860, 01251], lr: 0.000118, loss: 0.3874
2022-10-04 08:55:22 - train: epoch 0074, iter [00870, 01251], lr: 0.000118, loss: 0.3932
2022-10-04 08:55:41 - train: epoch 0074, iter [00880, 01251], lr: 0.000118, loss: 0.4104
2022-10-04 08:56:00 - train: epoch 0074, iter [00890, 01251], lr: 0.000118, loss: 0.4352
2022-10-04 08:56:18 - train: epoch 0074, iter [00900, 01251], lr: 0.000118, loss: 0.4120
2022-10-04 08:56:37 - train: epoch 0074, iter [00910, 01251], lr: 0.000118, loss: 0.4107
2022-10-04 08:56:56 - train: epoch 0074, iter [00920, 01251], lr: 0.000117, loss: 0.4099
2022-10-04 08:57:14 - train: epoch 0074, iter [00930, 01251], lr: 0.000117, loss: 0.4115
2022-10-04 08:57:33 - train: epoch 0074, iter [00940, 01251], lr: 0.000117, loss: 0.3919
2022-10-04 08:57:51 - train: epoch 0074, iter [00950, 01251], lr: 0.000117, loss: 0.3834
2022-10-04 08:58:11 - train: epoch 0074, iter [00960, 01251], lr: 0.000117, loss: 0.4119
2022-10-04 08:58:30 - train: epoch 0074, iter [00970, 01251], lr: 0.000117, loss: 0.4111
2022-10-04 08:58:48 - train: epoch 0074, iter [00980, 01251], lr: 0.000117, loss: 0.3929
2022-10-04 08:59:07 - train: epoch 0074, iter [00990, 01251], lr: 0.000117, loss: 0.3929
2022-10-04 08:59:26 - train: epoch 0074, iter [01000, 01251], lr: 0.000117, loss: 0.4085
2022-10-04 08:59:45 - train: epoch 0074, iter [01010, 01251], lr: 0.000117, loss: 0.4232
2022-10-04 09:00:03 - train: epoch 0074, iter [01020, 01251], lr: 0.000117, loss: 0.4090
2022-10-04 09:00:21 - train: epoch 0074, iter [01030, 01251], lr: 0.000117, loss: 0.3836
2022-10-04 09:00:40 - train: epoch 0074, iter [01040, 01251], lr: 0.000117, loss: 0.4118
2022-10-04 09:00:59 - train: epoch 0074, iter [01050, 01251], lr: 0.000117, loss: 0.4018
2022-10-04 09:01:18 - train: epoch 0074, iter [01060, 01251], lr: 0.000117, loss: 0.4203
2022-10-04 09:01:37 - train: epoch 0074, iter [01070, 01251], lr: 0.000116, loss: 0.4063
2022-10-04 09:01:55 - train: epoch 0074, iter [01080, 01251], lr: 0.000116, loss: 0.4043
2022-10-04 09:02:14 - train: epoch 0074, iter [01090, 01251], lr: 0.000116, loss: 0.3910
2022-10-04 09:02:34 - train: epoch 0074, iter [01100, 01251], lr: 0.000116, loss: 0.4074
2022-10-04 09:02:52 - train: epoch 0074, iter [01110, 01251], lr: 0.000116, loss: 0.4051
2022-10-04 09:03:11 - train: epoch 0074, iter [01120, 01251], lr: 0.000116, loss: 0.3832
2022-10-04 09:03:30 - train: epoch 0074, iter [01130, 01251], lr: 0.000116, loss: 0.3831
2022-10-04 09:03:49 - train: epoch 0074, iter [01140, 01251], lr: 0.000116, loss: 0.4084
2022-10-04 09:04:08 - train: epoch 0074, iter [01150, 01251], lr: 0.000116, loss: 0.3973
2022-10-04 09:04:27 - train: epoch 0074, iter [01160, 01251], lr: 0.000116, loss: 0.4219
2022-10-04 09:04:45 - train: epoch 0074, iter [01170, 01251], lr: 0.000116, loss: 0.3817
2022-10-04 09:05:04 - train: epoch 0074, iter [01180, 01251], lr: 0.000116, loss: 0.4078
2022-10-04 09:05:22 - train: epoch 0074, iter [01190, 01251], lr: 0.000116, loss: 0.4045
2022-10-04 09:05:41 - train: epoch 0074, iter [01200, 01251], lr: 0.000116, loss: 0.4021
2022-10-04 09:06:00 - train: epoch 0074, iter [01210, 01251], lr: 0.000116, loss: 0.4098
2022-10-04 09:06:19 - train: epoch 0074, iter [01220, 01251], lr: 0.000116, loss: 0.4015
2022-10-04 09:06:37 - train: epoch 0074, iter [01230, 01251], lr: 0.000115, loss: 0.4026
2022-10-04 09:06:56 - train: epoch 0074, iter [01240, 01251], lr: 0.000115, loss: 0.3900
2022-10-04 09:07:14 - train: epoch 0074, iter [01250, 01251], lr: 0.000115, loss: 0.3989
2022-10-04 09:07:19 - train: epoch 074, train_loss: 0.4031
2022-10-04 09:07:23 - until epoch: 074, best_loss: 0.4031
2022-10-04 09:07:23 - epoch 075 lr: 0.000115
2022-10-04 09:07:48 - train: epoch 0075, iter [00010, 01251], lr: 0.000115, loss: 0.4091
2022-10-04 09:08:06 - train: epoch 0075, iter [00020, 01251], lr: 0.000115, loss: 0.4000
2022-10-04 09:08:25 - train: epoch 0075, iter [00030, 01251], lr: 0.000115, loss: 0.3832
2022-10-04 09:08:44 - train: epoch 0075, iter [00040, 01251], lr: 0.000115, loss: 0.3922
2022-10-04 09:09:03 - train: epoch 0075, iter [00050, 01251], lr: 0.000115, loss: 0.3876
2022-10-04 09:09:21 - train: epoch 0075, iter [00060, 01251], lr: 0.000115, loss: 0.3917
2022-10-04 09:09:40 - train: epoch 0075, iter [00070, 01251], lr: 0.000115, loss: 0.4011
2022-10-04 09:09:59 - train: epoch 0075, iter [00080, 01251], lr: 0.000115, loss: 0.3884
2022-10-04 09:10:18 - train: epoch 0075, iter [00090, 01251], lr: 0.000115, loss: 0.4075
2022-10-04 09:10:37 - train: epoch 0075, iter [00100, 01251], lr: 0.000115, loss: 0.3947
2022-10-04 09:10:56 - train: epoch 0075, iter [00110, 01251], lr: 0.000115, loss: 0.4217
2022-10-04 09:11:15 - train: epoch 0075, iter [00120, 01251], lr: 0.000115, loss: 0.3983
2022-10-04 09:11:33 - train: epoch 0075, iter [00130, 01251], lr: 0.000114, loss: 0.3821
2022-10-04 09:11:52 - train: epoch 0075, iter [00140, 01251], lr: 0.000114, loss: 0.4053
2022-10-04 09:12:11 - train: epoch 0075, iter [00150, 01251], lr: 0.000114, loss: 0.4134
2022-10-04 09:12:30 - train: epoch 0075, iter [00160, 01251], lr: 0.000114, loss: 0.3923
2022-10-04 09:12:49 - train: epoch 0075, iter [00170, 01251], lr: 0.000114, loss: 0.4166
2022-10-04 09:13:08 - train: epoch 0075, iter [00180, 01251], lr: 0.000114, loss: 0.4024
2022-10-04 09:13:26 - train: epoch 0075, iter [00190, 01251], lr: 0.000114, loss: 0.4022
2022-10-04 09:13:45 - train: epoch 0075, iter [00200, 01251], lr: 0.000114, loss: 0.4013
2022-10-04 09:14:04 - train: epoch 0075, iter [00210, 01251], lr: 0.000114, loss: 0.3943
2022-10-04 09:14:23 - train: epoch 0075, iter [00220, 01251], lr: 0.000114, loss: 0.3817
2022-10-04 09:14:42 - train: epoch 0075, iter [00230, 01251], lr: 0.000114, loss: 0.3991
2022-10-04 09:15:01 - train: epoch 0075, iter [00240, 01251], lr: 0.000114, loss: 0.3975
2022-10-04 09:15:19 - train: epoch 0075, iter [00250, 01251], lr: 0.000114, loss: 0.4156
2022-10-04 09:15:38 - train: epoch 0075, iter [00260, 01251], lr: 0.000114, loss: 0.3959
2022-10-04 09:15:57 - train: epoch 0075, iter [00270, 01251], lr: 0.000114, loss: 0.4160
2022-10-04 09:16:16 - train: epoch 0075, iter [00280, 01251], lr: 0.000113, loss: 0.4099
2022-10-04 09:16:35 - train: epoch 0075, iter [00290, 01251], lr: 0.000113, loss: 0.3852
2022-10-04 09:16:53 - train: epoch 0075, iter [00300, 01251], lr: 0.000113, loss: 0.3967
2022-10-04 09:17:12 - train: epoch 0075, iter [00310, 01251], lr: 0.000113, loss: 0.4150
2022-10-04 09:17:31 - train: epoch 0075, iter [00320, 01251], lr: 0.000113, loss: 0.3987
2022-10-04 09:17:50 - train: epoch 0075, iter [00330, 01251], lr: 0.000113, loss: 0.4042
2022-10-04 09:18:09 - train: epoch 0075, iter [00340, 01251], lr: 0.000113, loss: 0.4137
2022-10-04 09:18:27 - train: epoch 0075, iter [00350, 01251], lr: 0.000113, loss: 0.4108
2022-10-04 09:18:46 - train: epoch 0075, iter [00360, 01251], lr: 0.000113, loss: 0.4134
2022-10-04 09:19:05 - train: epoch 0075, iter [00370, 01251], lr: 0.000113, loss: 0.3990
2022-10-04 09:19:23 - train: epoch 0075, iter [00380, 01251], lr: 0.000113, loss: 0.4044
2022-10-04 09:19:42 - train: epoch 0075, iter [00390, 01251], lr: 0.000113, loss: 0.4088
2022-10-04 09:20:00 - train: epoch 0075, iter [00400, 01251], lr: 0.000113, loss: 0.4063
2022-10-04 09:20:19 - train: epoch 0075, iter [00410, 01251], lr: 0.000113, loss: 0.4002
2022-10-04 09:20:37 - train: epoch 0075, iter [00420, 01251], lr: 0.000113, loss: 0.4077
2022-10-04 09:20:56 - train: epoch 0075, iter [00430, 01251], lr: 0.000112, loss: 0.4047
2022-10-04 09:21:14 - train: epoch 0075, iter [00440, 01251], lr: 0.000112, loss: 0.4091
2022-10-04 09:21:33 - train: epoch 0075, iter [00450, 01251], lr: 0.000112, loss: 0.3932
2022-10-04 09:21:51 - train: epoch 0075, iter [00460, 01251], lr: 0.000112, loss: 0.3993
2022-10-04 09:22:10 - train: epoch 0075, iter [00470, 01251], lr: 0.000112, loss: 0.4147
2022-10-04 09:22:28 - train: epoch 0075, iter [00480, 01251], lr: 0.000112, loss: 0.4370
2022-10-04 09:22:47 - train: epoch 0075, iter [00490, 01251], lr: 0.000112, loss: 0.4118
2022-10-04 09:23:06 - train: epoch 0075, iter [00500, 01251], lr: 0.000112, loss: 0.4238
2022-10-04 09:23:24 - train: epoch 0075, iter [00510, 01251], lr: 0.000112, loss: 0.4076
2022-10-04 09:23:44 - train: epoch 0075, iter [00520, 01251], lr: 0.000112, loss: 0.3892
2022-10-04 09:24:03 - train: epoch 0075, iter [00530, 01251], lr: 0.000112, loss: 0.3905
2022-10-04 09:24:21 - train: epoch 0075, iter [00540, 01251], lr: 0.000112, loss: 0.4005
2022-10-04 09:24:40 - train: epoch 0075, iter [00550, 01251], lr: 0.000112, loss: 0.4100
2022-10-04 09:24:59 - train: epoch 0075, iter [00560, 01251], lr: 0.000112, loss: 0.4076
2022-10-04 09:25:17 - train: epoch 0075, iter [00570, 01251], lr: 0.000112, loss: 0.3872
2022-10-04 09:25:36 - train: epoch 0075, iter [00580, 01251], lr: 0.000112, loss: 0.4084
2022-10-04 09:25:55 - train: epoch 0075, iter [00590, 01251], lr: 0.000111, loss: 0.3947
2022-10-04 09:26:13 - train: epoch 0075, iter [00600, 01251], lr: 0.000111, loss: 0.4148
2022-10-04 09:26:32 - train: epoch 0075, iter [00610, 01251], lr: 0.000111, loss: 0.4163
2022-10-04 09:26:51 - train: epoch 0075, iter [00620, 01251], lr: 0.000111, loss: 0.3823
2022-10-04 09:27:09 - train: epoch 0075, iter [00630, 01251], lr: 0.000111, loss: 0.3920
2022-10-04 09:27:28 - train: epoch 0075, iter [00640, 01251], lr: 0.000111, loss: 0.4063
2022-10-04 09:27:46 - train: epoch 0075, iter [00650, 01251], lr: 0.000111, loss: 0.4026
2022-10-04 09:28:05 - train: epoch 0075, iter [00660, 01251], lr: 0.000111, loss: 0.4211
2022-10-04 09:28:24 - train: epoch 0075, iter [00670, 01251], lr: 0.000111, loss: 0.4074
2022-10-04 09:28:42 - train: epoch 0075, iter [00680, 01251], lr: 0.000111, loss: 0.3940
2022-10-04 09:29:01 - train: epoch 0075, iter [00690, 01251], lr: 0.000111, loss: 0.4185
2022-10-04 09:29:20 - train: epoch 0075, iter [00700, 01251], lr: 0.000111, loss: 0.4002
2022-10-04 09:29:39 - train: epoch 0075, iter [00710, 01251], lr: 0.000111, loss: 0.3932
2022-10-04 09:29:57 - train: epoch 0075, iter [00720, 01251], lr: 0.000111, loss: 0.4132
2022-10-04 09:30:16 - train: epoch 0075, iter [00730, 01251], lr: 0.000111, loss: 0.3943
2022-10-04 09:30:35 - train: epoch 0075, iter [00740, 01251], lr: 0.000110, loss: 0.4001
2022-10-04 09:30:54 - train: epoch 0075, iter [00750, 01251], lr: 0.000110, loss: 0.3978
2022-10-04 09:31:13 - train: epoch 0075, iter [00760, 01251], lr: 0.000110, loss: 0.4178
2022-10-04 09:31:32 - train: epoch 0075, iter [00770, 01251], lr: 0.000110, loss: 0.4049
2022-10-04 09:31:51 - train: epoch 0075, iter [00780, 01251], lr: 0.000110, loss: 0.4128
2022-10-04 09:32:10 - train: epoch 0075, iter [00790, 01251], lr: 0.000110, loss: 0.4183
2022-10-04 09:32:29 - train: epoch 0075, iter [00800, 01251], lr: 0.000110, loss: 0.4030
2022-10-04 09:32:48 - train: epoch 0075, iter [00810, 01251], lr: 0.000110, loss: 0.4032
2022-10-04 09:33:07 - train: epoch 0075, iter [00820, 01251], lr: 0.000110, loss: 0.4122
2022-10-04 09:33:26 - train: epoch 0075, iter [00830, 01251], lr: 0.000110, loss: 0.4025
2022-10-04 09:33:45 - train: epoch 0075, iter [00840, 01251], lr: 0.000110, loss: 0.3954
2022-10-04 09:34:03 - train: epoch 0075, iter [00850, 01251], lr: 0.000110, loss: 0.4092
2022-10-04 09:34:22 - train: epoch 0075, iter [00860, 01251], lr: 0.000110, loss: 0.3988
2022-10-04 09:34:41 - train: epoch 0075, iter [00870, 01251], lr: 0.000110, loss: 0.3999
2022-10-04 09:35:00 - train: epoch 0075, iter [00880, 01251], lr: 0.000110, loss: 0.4044
2022-10-04 09:35:19 - train: epoch 0075, iter [00890, 01251], lr: 0.000109, loss: 0.4103
2022-10-04 09:35:38 - train: epoch 0075, iter [00900, 01251], lr: 0.000109, loss: 0.4030
2022-10-04 09:35:56 - train: epoch 0075, iter [00910, 01251], lr: 0.000109, loss: 0.3932
2022-10-04 09:36:15 - train: epoch 0075, iter [00920, 01251], lr: 0.000109, loss: 0.3813
2022-10-04 09:36:33 - train: epoch 0075, iter [00930, 01251], lr: 0.000109, loss: 0.3877
2022-10-04 09:36:52 - train: epoch 0075, iter [00940, 01251], lr: 0.000109, loss: 0.4068
2022-10-04 09:37:11 - train: epoch 0075, iter [00950, 01251], lr: 0.000109, loss: 0.3900
2022-10-04 09:37:30 - train: epoch 0075, iter [00960, 01251], lr: 0.000109, loss: 0.3991
2022-10-04 09:37:49 - train: epoch 0075, iter [00970, 01251], lr: 0.000109, loss: 0.3933
2022-10-04 09:38:07 - train: epoch 0075, iter [00980, 01251], lr: 0.000109, loss: 0.4132
2022-10-04 09:38:26 - train: epoch 0075, iter [00990, 01251], lr: 0.000109, loss: 0.4195
2022-10-04 09:38:45 - train: epoch 0075, iter [01000, 01251], lr: 0.000109, loss: 0.3967
2022-10-04 09:39:03 - train: epoch 0075, iter [01010, 01251], lr: 0.000109, loss: 0.3933
2022-10-04 09:39:22 - train: epoch 0075, iter [01020, 01251], lr: 0.000109, loss: 0.4065
2022-10-04 09:39:40 - train: epoch 0075, iter [01030, 01251], lr: 0.000109, loss: 0.3955
2022-10-04 09:39:59 - train: epoch 0075, iter [01040, 01251], lr: 0.000109, loss: 0.4184
2022-10-04 09:40:18 - train: epoch 0075, iter [01050, 01251], lr: 0.000108, loss: 0.3987
2022-10-04 09:40:36 - train: epoch 0075, iter [01060, 01251], lr: 0.000108, loss: 0.4007
2022-10-04 09:40:55 - train: epoch 0075, iter [01070, 01251], lr: 0.000108, loss: 0.3832
2022-10-04 09:41:14 - train: epoch 0075, iter [01080, 01251], lr: 0.000108, loss: 0.3950
2022-10-04 09:41:32 - train: epoch 0075, iter [01090, 01251], lr: 0.000108, loss: 0.4006
2022-10-04 09:41:51 - train: epoch 0075, iter [01100, 01251], lr: 0.000108, loss: 0.3820
2022-10-04 09:42:10 - train: epoch 0075, iter [01110, 01251], lr: 0.000108, loss: 0.3927
2022-10-04 09:42:29 - train: epoch 0075, iter [01120, 01251], lr: 0.000108, loss: 0.3957
2022-10-04 09:42:47 - train: epoch 0075, iter [01130, 01251], lr: 0.000108, loss: 0.3944
2022-10-04 09:43:06 - train: epoch 0075, iter [01140, 01251], lr: 0.000108, loss: 0.4048
2022-10-04 09:43:25 - train: epoch 0075, iter [01150, 01251], lr: 0.000108, loss: 0.3923
2022-10-04 09:43:44 - train: epoch 0075, iter [01160, 01251], lr: 0.000108, loss: 0.4109
2022-10-04 09:44:03 - train: epoch 0075, iter [01170, 01251], lr: 0.000108, loss: 0.4051
2022-10-04 09:44:21 - train: epoch 0075, iter [01180, 01251], lr: 0.000108, loss: 0.3962
2022-10-04 09:44:40 - train: epoch 0075, iter [01190, 01251], lr: 0.000108, loss: 0.4057
2022-10-04 09:44:59 - train: epoch 0075, iter [01200, 01251], lr: 0.000107, loss: 0.3833
2022-10-04 09:45:18 - train: epoch 0075, iter [01210, 01251], lr: 0.000107, loss: 0.4250
2022-10-04 09:45:36 - train: epoch 0075, iter [01220, 01251], lr: 0.000107, loss: 0.4036
2022-10-04 09:45:55 - train: epoch 0075, iter [01230, 01251], lr: 0.000107, loss: 0.3909
2022-10-04 09:46:13 - train: epoch 0075, iter [01240, 01251], lr: 0.000107, loss: 0.3886
2022-10-04 09:46:32 - train: epoch 0075, iter [01250, 01251], lr: 0.000107, loss: 0.3827
2022-10-04 09:46:36 - train: epoch 075, train_loss: 0.4028
2022-10-04 09:46:40 - until epoch: 075, best_loss: 0.4028
2022-10-04 09:46:40 - epoch 076 lr: 0.000107
2022-10-04 09:47:05 - train: epoch 0076, iter [00010, 01251], lr: 0.000107, loss: 0.4125
2022-10-04 09:47:24 - train: epoch 0076, iter [00020, 01251], lr: 0.000107, loss: 0.3951
2022-10-04 09:47:42 - train: epoch 0076, iter [00030, 01251], lr: 0.000107, loss: 0.3982
2022-10-04 09:48:01 - train: epoch 0076, iter [00040, 01251], lr: 0.000107, loss: 0.4063
2022-10-04 09:48:19 - train: epoch 0076, iter [00050, 01251], lr: 0.000107, loss: 0.4144
2022-10-04 09:48:38 - train: epoch 0076, iter [00060, 01251], lr: 0.000107, loss: 0.3897
2022-10-04 09:48:57 - train: epoch 0076, iter [00070, 01251], lr: 0.000107, loss: 0.3974
2022-10-04 09:49:16 - train: epoch 0076, iter [00080, 01251], lr: 0.000107, loss: 0.3927
2022-10-04 09:49:34 - train: epoch 0076, iter [00090, 01251], lr: 0.000107, loss: 0.4104
2022-10-04 09:49:53 - train: epoch 0076, iter [00100, 01251], lr: 0.000107, loss: 0.4027
2022-10-04 09:50:13 - train: epoch 0076, iter [00110, 01251], lr: 0.000106, loss: 0.4205
2022-10-04 09:50:32 - train: epoch 0076, iter [00120, 01251], lr: 0.000106, loss: 0.3919
2022-10-04 09:50:51 - train: epoch 0076, iter [00130, 01251], lr: 0.000106, loss: 0.3804
2022-10-04 09:51:09 - train: epoch 0076, iter [00140, 01251], lr: 0.000106, loss: 0.3883
2022-10-04 09:51:28 - train: epoch 0076, iter [00150, 01251], lr: 0.000106, loss: 0.4011
2022-10-04 09:51:47 - train: epoch 0076, iter [00160, 01251], lr: 0.000106, loss: 0.4106
2022-10-04 09:52:07 - train: epoch 0076, iter [00170, 01251], lr: 0.000106, loss: 0.3999
2022-10-04 09:52:25 - train: epoch 0076, iter [00180, 01251], lr: 0.000106, loss: 0.4025
2022-10-04 09:52:44 - train: epoch 0076, iter [00190, 01251], lr: 0.000106, loss: 0.4006
2022-10-04 09:53:03 - train: epoch 0076, iter [00200, 01251], lr: 0.000106, loss: 0.4009
2022-10-04 09:53:21 - train: epoch 0076, iter [00210, 01251], lr: 0.000106, loss: 0.4042
2022-10-04 09:53:40 - train: epoch 0076, iter [00220, 01251], lr: 0.000106, loss: 0.3987
2022-10-04 09:53:59 - train: epoch 0076, iter [00230, 01251], lr: 0.000106, loss: 0.4146
2022-10-04 09:54:18 - train: epoch 0076, iter [00240, 01251], lr: 0.000106, loss: 0.4209
2022-10-04 09:54:36 - train: epoch 0076, iter [00250, 01251], lr: 0.000106, loss: 0.4098
2022-10-04 09:54:55 - train: epoch 0076, iter [00260, 01251], lr: 0.000106, loss: 0.4001
2022-10-04 09:55:14 - train: epoch 0076, iter [00270, 01251], lr: 0.000105, loss: 0.4173
2022-10-04 09:55:33 - train: epoch 0076, iter [00280, 01251], lr: 0.000105, loss: 0.4097
2022-10-04 09:55:52 - train: epoch 0076, iter [00290, 01251], lr: 0.000105, loss: 0.3907
2022-10-04 09:56:11 - train: epoch 0076, iter [00300, 01251], lr: 0.000105, loss: 0.4171
2022-10-04 09:56:29 - train: epoch 0076, iter [00310, 01251], lr: 0.000105, loss: 0.4118
2022-10-04 09:56:48 - train: epoch 0076, iter [00320, 01251], lr: 0.000105, loss: 0.3913
2022-10-04 09:57:07 - train: epoch 0076, iter [00330, 01251], lr: 0.000105, loss: 0.3889
2022-10-04 09:57:26 - train: epoch 0076, iter [00340, 01251], lr: 0.000105, loss: 0.4116
2022-10-04 09:57:44 - train: epoch 0076, iter [00350, 01251], lr: 0.000105, loss: 0.4125
2022-10-04 09:58:03 - train: epoch 0076, iter [00360, 01251], lr: 0.000105, loss: 0.3999
2022-10-04 09:58:22 - train: epoch 0076, iter [00370, 01251], lr: 0.000105, loss: 0.4019
2022-10-04 09:58:41 - train: epoch 0076, iter [00380, 01251], lr: 0.000105, loss: 0.3973
2022-10-04 09:58:59 - train: epoch 0076, iter [00390, 01251], lr: 0.000105, loss: 0.4011
2022-10-04 09:59:18 - train: epoch 0076, iter [00400, 01251], lr: 0.000105, loss: 0.3979
2022-10-04 09:59:37 - train: epoch 0076, iter [00410, 01251], lr: 0.000105, loss: 0.4006
2022-10-04 09:59:56 - train: epoch 0076, iter [00420, 01251], lr: 0.000104, loss: 0.3987
2022-10-04 10:00:15 - train: epoch 0076, iter [00430, 01251], lr: 0.000104, loss: 0.3946
2022-10-04 10:00:33 - train: epoch 0076, iter [00440, 01251], lr: 0.000104, loss: 0.4070
2022-10-04 10:00:52 - train: epoch 0076, iter [00450, 01251], lr: 0.000104, loss: 0.3971
2022-10-04 10:01:12 - train: epoch 0076, iter [00460, 01251], lr: 0.000104, loss: 0.4018
2022-10-04 10:01:31 - train: epoch 0076, iter [00470, 01251], lr: 0.000104, loss: 0.4135
2022-10-04 10:01:50 - train: epoch 0076, iter [00480, 01251], lr: 0.000104, loss: 0.4189
2022-10-04 10:02:09 - train: epoch 0076, iter [00490, 01251], lr: 0.000104, loss: 0.4078
2022-10-04 10:02:28 - train: epoch 0076, iter [00500, 01251], lr: 0.000104, loss: 0.4028
2022-10-04 10:02:46 - train: epoch 0076, iter [00510, 01251], lr: 0.000104, loss: 0.4069
2022-10-04 10:03:05 - train: epoch 0076, iter [00520, 01251], lr: 0.000104, loss: 0.4084
2022-10-04 10:03:24 - train: epoch 0076, iter [00530, 01251], lr: 0.000104, loss: 0.4127
2022-10-04 10:03:42 - train: epoch 0076, iter [00540, 01251], lr: 0.000104, loss: 0.4072
2022-10-04 10:04:00 - train: epoch 0076, iter [00550, 01251], lr: 0.000104, loss: 0.4072
2022-10-04 10:04:19 - train: epoch 0076, iter [00560, 01251], lr: 0.000104, loss: 0.4161
2022-10-04 10:04:38 - train: epoch 0076, iter [00570, 01251], lr: 0.000104, loss: 0.3965
2022-10-04 10:04:57 - train: epoch 0076, iter [00580, 01251], lr: 0.000103, loss: 0.4116
2022-10-04 10:05:16 - train: epoch 0076, iter [00590, 01251], lr: 0.000103, loss: 0.4017
2022-10-04 10:05:35 - train: epoch 0076, iter [00600, 01251], lr: 0.000103, loss: 0.4052
2022-10-04 10:05:54 - train: epoch 0076, iter [00610, 01251], lr: 0.000103, loss: 0.4040
2022-10-04 10:06:12 - train: epoch 0076, iter [00620, 01251], lr: 0.000103, loss: 0.4255
2022-10-04 10:06:31 - train: epoch 0076, iter [00630, 01251], lr: 0.000103, loss: 0.3984
2022-10-04 10:06:50 - train: epoch 0076, iter [00640, 01251], lr: 0.000103, loss: 0.4181
2022-10-04 10:07:08 - train: epoch 0076, iter [00650, 01251], lr: 0.000103, loss: 0.3892
2022-10-04 10:07:27 - train: epoch 0076, iter [00660, 01251], lr: 0.000103, loss: 0.4133
2022-10-04 10:07:46 - train: epoch 0076, iter [00670, 01251], lr: 0.000103, loss: 0.4203
2022-10-04 10:08:04 - train: epoch 0076, iter [00680, 01251], lr: 0.000103, loss: 0.4095
2022-10-04 10:08:23 - train: epoch 0076, iter [00690, 01251], lr: 0.000103, loss: 0.3883
2022-10-04 10:08:42 - train: epoch 0076, iter [00700, 01251], lr: 0.000103, loss: 0.4019
2022-10-04 10:09:00 - train: epoch 0076, iter [00710, 01251], lr: 0.000103, loss: 0.3899
2022-10-04 10:09:19 - train: epoch 0076, iter [00720, 01251], lr: 0.000103, loss: 0.3961
2022-10-04 10:09:37 - train: epoch 0076, iter [00730, 01251], lr: 0.000103, loss: 0.3929
2022-10-04 10:09:56 - train: epoch 0076, iter [00740, 01251], lr: 0.000102, loss: 0.3902
2022-10-04 10:10:15 - train: epoch 0076, iter [00750, 01251], lr: 0.000102, loss: 0.3965
2022-10-04 10:10:34 - train: epoch 0076, iter [00760, 01251], lr: 0.000102, loss: 0.3946
2022-10-04 10:10:52 - train: epoch 0076, iter [00770, 01251], lr: 0.000102, loss: 0.4100
2022-10-04 10:11:11 - train: epoch 0076, iter [00780, 01251], lr: 0.000102, loss: 0.4199
2022-10-04 10:11:29 - train: epoch 0076, iter [00790, 01251], lr: 0.000102, loss: 0.4014
2022-10-04 10:11:48 - train: epoch 0076, iter [00800, 01251], lr: 0.000102, loss: 0.4083
2022-10-04 10:12:07 - train: epoch 0076, iter [00810, 01251], lr: 0.000102, loss: 0.4120
2022-10-04 10:12:26 - train: epoch 0076, iter [00820, 01251], lr: 0.000102, loss: 0.3887
2022-10-04 10:12:45 - train: epoch 0076, iter [00830, 01251], lr: 0.000102, loss: 0.3989
2022-10-04 10:13:04 - train: epoch 0076, iter [00840, 01251], lr: 0.000102, loss: 0.3951
2022-10-04 10:13:23 - train: epoch 0076, iter [00850, 01251], lr: 0.000102, loss: 0.3856
2022-10-04 10:13:42 - train: epoch 0076, iter [00860, 01251], lr: 0.000102, loss: 0.4134
2022-10-04 10:14:01 - train: epoch 0076, iter [00870, 01251], lr: 0.000102, loss: 0.3996
2022-10-04 10:14:19 - train: epoch 0076, iter [00880, 01251], lr: 0.000102, loss: 0.3967
2022-10-04 10:14:38 - train: epoch 0076, iter [00890, 01251], lr: 0.000102, loss: 0.4120
2022-10-04 10:14:57 - train: epoch 0076, iter [00900, 01251], lr: 0.000101, loss: 0.3966
2022-10-04 10:15:15 - train: epoch 0076, iter [00910, 01251], lr: 0.000101, loss: 0.4030
2022-10-04 10:15:34 - train: epoch 0076, iter [00920, 01251], lr: 0.000101, loss: 0.3891
2022-10-04 10:15:53 - train: epoch 0076, iter [00930, 01251], lr: 0.000101, loss: 0.3977
2022-10-04 10:16:12 - train: epoch 0076, iter [00940, 01251], lr: 0.000101, loss: 0.4007
2022-10-04 10:16:30 - train: epoch 0076, iter [00950, 01251], lr: 0.000101, loss: 0.4006
2022-10-04 10:16:49 - train: epoch 0076, iter [00960, 01251], lr: 0.000101, loss: 0.4088
2022-10-04 10:17:08 - train: epoch 0076, iter [00970, 01251], lr: 0.000101, loss: 0.4283
2022-10-04 10:17:26 - train: epoch 0076, iter [00980, 01251], lr: 0.000101, loss: 0.4050
2022-10-04 10:17:45 - train: epoch 0076, iter [00990, 01251], lr: 0.000101, loss: 0.3861
2022-10-04 10:18:04 - train: epoch 0076, iter [01000, 01251], lr: 0.000101, loss: 0.4152
2022-10-04 10:18:22 - train: epoch 0076, iter [01010, 01251], lr: 0.000101, loss: 0.3786
2022-10-04 10:18:41 - train: epoch 0076, iter [01020, 01251], lr: 0.000101, loss: 0.4160
2022-10-04 10:19:00 - train: epoch 0076, iter [01030, 01251], lr: 0.000101, loss: 0.4003
2022-10-04 10:19:19 - train: epoch 0076, iter [01040, 01251], lr: 0.000101, loss: 0.3824
2022-10-04 10:19:38 - train: epoch 0076, iter [01050, 01251], lr: 0.000101, loss: 0.4054
2022-10-04 10:19:57 - train: epoch 0076, iter [01060, 01251], lr: 0.000100, loss: 0.4035
2022-10-04 10:20:16 - train: epoch 0076, iter [01070, 01251], lr: 0.000100, loss: 0.4003
2022-10-04 10:20:35 - train: epoch 0076, iter [01080, 01251], lr: 0.000100, loss: 0.4140
2022-10-04 10:20:54 - train: epoch 0076, iter [01090, 01251], lr: 0.000100, loss: 0.3994
2022-10-04 10:21:12 - train: epoch 0076, iter [01100, 01251], lr: 0.000100, loss: 0.3991
2022-10-04 10:21:31 - train: epoch 0076, iter [01110, 01251], lr: 0.000100, loss: 0.4163
2022-10-04 10:21:50 - train: epoch 0076, iter [01120, 01251], lr: 0.000100, loss: 0.3928
2022-10-04 10:22:08 - train: epoch 0076, iter [01130, 01251], lr: 0.000100, loss: 0.3851
2022-10-04 10:22:27 - train: epoch 0076, iter [01140, 01251], lr: 0.000100, loss: 0.4046
2022-10-04 10:22:46 - train: epoch 0076, iter [01150, 01251], lr: 0.000100, loss: 0.4024
2022-10-04 10:23:04 - train: epoch 0076, iter [01160, 01251], lr: 0.000100, loss: 0.4100
2022-10-04 10:23:23 - train: epoch 0076, iter [01170, 01251], lr: 0.000100, loss: 0.4002
2022-10-04 10:23:42 - train: epoch 0076, iter [01180, 01251], lr: 0.000100, loss: 0.4070
2022-10-04 10:24:01 - train: epoch 0076, iter [01190, 01251], lr: 0.000100, loss: 0.4114
2022-10-04 10:24:20 - train: epoch 0076, iter [01200, 01251], lr: 0.000100, loss: 0.3916
2022-10-04 10:24:38 - train: epoch 0076, iter [01210, 01251], lr: 0.000100, loss: 0.4126
2022-10-04 10:24:57 - train: epoch 0076, iter [01220, 01251], lr: 0.000099, loss: 0.4095
2022-10-04 10:25:16 - train: epoch 0076, iter [01230, 01251], lr: 0.000099, loss: 0.4152
2022-10-04 10:25:35 - train: epoch 0076, iter [01240, 01251], lr: 0.000099, loss: 0.4154
2022-10-04 10:25:53 - train: epoch 0076, iter [01250, 01251], lr: 0.000099, loss: 0.3926
2022-10-04 10:25:57 - train: epoch 076, train_loss: 0.4025
2022-10-04 10:26:01 - until epoch: 076, best_loss: 0.4025
2022-10-04 10:26:01 - epoch 077 lr: 0.000099
2022-10-04 10:26:26 - train: epoch 0077, iter [00010, 01251], lr: 0.000099, loss: 0.4169
2022-10-04 10:26:45 - train: epoch 0077, iter [00020, 01251], lr: 0.000099, loss: 0.4140
2022-10-04 10:27:03 - train: epoch 0077, iter [00030, 01251], lr: 0.000099, loss: 0.4128
2022-10-04 10:27:22 - train: epoch 0077, iter [00040, 01251], lr: 0.000099, loss: 0.3994
2022-10-04 10:27:41 - train: epoch 0077, iter [00050, 01251], lr: 0.000099, loss: 0.3980
2022-10-04 10:28:00 - train: epoch 0077, iter [00060, 01251], lr: 0.000099, loss: 0.3982
2022-10-04 10:28:18 - train: epoch 0077, iter [00070, 01251], lr: 0.000099, loss: 0.3860
2022-10-04 10:28:38 - train: epoch 0077, iter [00080, 01251], lr: 0.000099, loss: 0.3939
2022-10-04 10:28:56 - train: epoch 0077, iter [00090, 01251], lr: 0.000099, loss: 0.3866
2022-10-04 10:29:15 - train: epoch 0077, iter [00100, 01251], lr: 0.000099, loss: 0.4075
2022-10-04 10:29:33 - train: epoch 0077, iter [00110, 01251], lr: 0.000099, loss: 0.4038
2022-10-04 10:29:53 - train: epoch 0077, iter [00120, 01251], lr: 0.000099, loss: 0.4020
2022-10-04 10:30:11 - train: epoch 0077, iter [00130, 01251], lr: 0.000098, loss: 0.3924
2022-10-04 10:30:31 - train: epoch 0077, iter [00140, 01251], lr: 0.000098, loss: 0.3848
2022-10-04 10:30:50 - train: epoch 0077, iter [00150, 01251], lr: 0.000098, loss: 0.4098
2022-10-04 10:31:09 - train: epoch 0077, iter [00160, 01251], lr: 0.000098, loss: 0.3874
2022-10-04 10:31:28 - train: epoch 0077, iter [00170, 01251], lr: 0.000098, loss: 0.3944
2022-10-04 10:31:47 - train: epoch 0077, iter [00180, 01251], lr: 0.000098, loss: 0.3893
2022-10-04 10:32:07 - train: epoch 0077, iter [00190, 01251], lr: 0.000098, loss: 0.3831
2022-10-04 10:32:26 - train: epoch 0077, iter [00200, 01251], lr: 0.000098, loss: 0.4112
2022-10-04 10:32:45 - train: epoch 0077, iter [00210, 01251], lr: 0.000098, loss: 0.3891
2022-10-04 10:33:05 - train: epoch 0077, iter [00220, 01251], lr: 0.000098, loss: 0.4029
2022-10-04 10:33:23 - train: epoch 0077, iter [00230, 01251], lr: 0.000098, loss: 0.3856
2022-10-04 10:33:42 - train: epoch 0077, iter [00240, 01251], lr: 0.000098, loss: 0.3843
2022-10-04 10:34:01 - train: epoch 0077, iter [00250, 01251], lr: 0.000098, loss: 0.4162
2022-10-04 10:34:20 - train: epoch 0077, iter [00260, 01251], lr: 0.000098, loss: 0.4000
2022-10-04 10:34:39 - train: epoch 0077, iter [00270, 01251], lr: 0.000098, loss: 0.3884
2022-10-04 10:34:58 - train: epoch 0077, iter [00280, 01251], lr: 0.000098, loss: 0.4205
2022-10-04 10:35:18 - train: epoch 0077, iter [00290, 01251], lr: 0.000097, loss: 0.4045
2022-10-04 10:35:37 - train: epoch 0077, iter [00300, 01251], lr: 0.000097, loss: 0.3827
2022-10-04 10:35:56 - train: epoch 0077, iter [00310, 01251], lr: 0.000097, loss: 0.4056
2022-10-04 10:36:15 - train: epoch 0077, iter [00320, 01251], lr: 0.000097, loss: 0.3999
2022-10-04 10:36:34 - train: epoch 0077, iter [00330, 01251], lr: 0.000097, loss: 0.4082
2022-10-04 10:36:53 - train: epoch 0077, iter [00340, 01251], lr: 0.000097, loss: 0.4044
2022-10-04 10:37:12 - train: epoch 0077, iter [00350, 01251], lr: 0.000097, loss: 0.4081
2022-10-04 10:37:30 - train: epoch 0077, iter [00360, 01251], lr: 0.000097, loss: 0.4340
2022-10-04 10:37:49 - train: epoch 0077, iter [00370, 01251], lr: 0.000097, loss: 0.4031
2022-10-04 10:38:09 - train: epoch 0077, iter [00380, 01251], lr: 0.000097, loss: 0.3963
2022-10-04 10:38:28 - train: epoch 0077, iter [00390, 01251], lr: 0.000097, loss: 0.4049
2022-10-04 10:38:47 - train: epoch 0077, iter [00400, 01251], lr: 0.000097, loss: 0.3926
2022-10-04 10:39:06 - train: epoch 0077, iter [00410, 01251], lr: 0.000097, loss: 0.4122
2022-10-04 10:39:24 - train: epoch 0077, iter [00420, 01251], lr: 0.000097, loss: 0.4008
2022-10-04 10:39:43 - train: epoch 0077, iter [00430, 01251], lr: 0.000097, loss: 0.4192
2022-10-04 10:40:02 - train: epoch 0077, iter [00440, 01251], lr: 0.000097, loss: 0.3847
2022-10-04 10:40:21 - train: epoch 0077, iter [00450, 01251], lr: 0.000096, loss: 0.3982
2022-10-04 10:40:40 - train: epoch 0077, iter [00460, 01251], lr: 0.000096, loss: 0.3910
2022-10-04 10:40:59 - train: epoch 0077, iter [00470, 01251], lr: 0.000096, loss: 0.4142
2022-10-04 10:41:18 - train: epoch 0077, iter [00480, 01251], lr: 0.000096, loss: 0.4189
2022-10-04 10:41:37 - train: epoch 0077, iter [00490, 01251], lr: 0.000096, loss: 0.4124
2022-10-04 10:41:57 - train: epoch 0077, iter [00500, 01251], lr: 0.000096, loss: 0.3990
2022-10-04 10:42:16 - train: epoch 0077, iter [00510, 01251], lr: 0.000096, loss: 0.4130
2022-10-04 10:42:35 - train: epoch 0077, iter [00520, 01251], lr: 0.000096, loss: 0.3998
2022-10-04 10:42:54 - train: epoch 0077, iter [00530, 01251], lr: 0.000096, loss: 0.3858
2022-10-04 10:43:13 - train: epoch 0077, iter [00540, 01251], lr: 0.000096, loss: 0.4082
2022-10-04 10:43:32 - train: epoch 0077, iter [00550, 01251], lr: 0.000096, loss: 0.4046
2022-10-04 10:43:51 - train: epoch 0077, iter [00560, 01251], lr: 0.000096, loss: 0.3954
2022-10-04 10:44:10 - train: epoch 0077, iter [00570, 01251], lr: 0.000096, loss: 0.3846
2022-10-04 10:44:30 - train: epoch 0077, iter [00580, 01251], lr: 0.000096, loss: 0.4249
2022-10-04 10:44:49 - train: epoch 0077, iter [00590, 01251], lr: 0.000096, loss: 0.4114
2022-10-04 10:45:08 - train: epoch 0077, iter [00600, 01251], lr: 0.000096, loss: 0.4133
2022-10-04 10:45:27 - train: epoch 0077, iter [00610, 01251], lr: 0.000095, loss: 0.3884
2022-10-04 10:45:47 - train: epoch 0077, iter [00620, 01251], lr: 0.000095, loss: 0.4010
2022-10-04 10:46:06 - train: epoch 0077, iter [00630, 01251], lr: 0.000095, loss: 0.3986
2022-10-04 10:46:24 - train: epoch 0077, iter [00640, 01251], lr: 0.000095, loss: 0.3925
2022-10-04 10:46:44 - train: epoch 0077, iter [00650, 01251], lr: 0.000095, loss: 0.4182
2022-10-04 10:47:03 - train: epoch 0077, iter [00660, 01251], lr: 0.000095, loss: 0.3964
2022-10-04 10:47:22 - train: epoch 0077, iter [00670, 01251], lr: 0.000095, loss: 0.4025
2022-10-04 10:47:41 - train: epoch 0077, iter [00680, 01251], lr: 0.000095, loss: 0.3930
2022-10-04 10:47:59 - train: epoch 0077, iter [00690, 01251], lr: 0.000095, loss: 0.3918
2022-10-04 10:48:19 - train: epoch 0077, iter [00700, 01251], lr: 0.000095, loss: 0.3770
2022-10-04 10:48:37 - train: epoch 0077, iter [00710, 01251], lr: 0.000095, loss: 0.4004
2022-10-04 10:48:56 - train: epoch 0077, iter [00720, 01251], lr: 0.000095, loss: 0.4034
2022-10-04 10:49:16 - train: epoch 0077, iter [00730, 01251], lr: 0.000095, loss: 0.4130
2022-10-04 10:49:35 - train: epoch 0077, iter [00740, 01251], lr: 0.000095, loss: 0.3916
2022-10-04 10:49:54 - train: epoch 0077, iter [00750, 01251], lr: 0.000095, loss: 0.4017
2022-10-04 10:50:13 - train: epoch 0077, iter [00760, 01251], lr: 0.000095, loss: 0.3955
2022-10-04 10:50:32 - train: epoch 0077, iter [00770, 01251], lr: 0.000095, loss: 0.3874
2022-10-04 10:50:51 - train: epoch 0077, iter [00780, 01251], lr: 0.000094, loss: 0.4051
2022-10-04 10:51:10 - train: epoch 0077, iter [00790, 01251], lr: 0.000094, loss: 0.4160
2022-10-04 10:51:29 - train: epoch 0077, iter [00800, 01251], lr: 0.000094, loss: 0.3858
2022-10-04 10:51:48 - train: epoch 0077, iter [00810, 01251], lr: 0.000094, loss: 0.4053
2022-10-04 10:52:07 - train: epoch 0077, iter [00820, 01251], lr: 0.000094, loss: 0.4170
2022-10-04 10:52:26 - train: epoch 0077, iter [00830, 01251], lr: 0.000094, loss: 0.3999
2022-10-04 10:52:45 - train: epoch 0077, iter [00840, 01251], lr: 0.000094, loss: 0.4004
2022-10-04 10:53:04 - train: epoch 0077, iter [00850, 01251], lr: 0.000094, loss: 0.3736
2022-10-04 10:53:23 - train: epoch 0077, iter [00860, 01251], lr: 0.000094, loss: 0.3930
2022-10-04 10:53:42 - train: epoch 0077, iter [00870, 01251], lr: 0.000094, loss: 0.4051
2022-10-04 10:54:01 - train: epoch 0077, iter [00880, 01251], lr: 0.000094, loss: 0.4080
2022-10-04 10:54:21 - train: epoch 0077, iter [00890, 01251], lr: 0.000094, loss: 0.4176
2022-10-04 10:54:40 - train: epoch 0077, iter [00900, 01251], lr: 0.000094, loss: 0.4134
2022-10-04 10:54:59 - train: epoch 0077, iter [00910, 01251], lr: 0.000094, loss: 0.4179
2022-10-04 10:55:18 - train: epoch 0077, iter [00920, 01251], lr: 0.000094, loss: 0.3969
2022-10-04 10:55:37 - train: epoch 0077, iter [00930, 01251], lr: 0.000094, loss: 0.3980
2022-10-04 10:55:56 - train: epoch 0077, iter [00940, 01251], lr: 0.000093, loss: 0.4104
2022-10-04 10:56:16 - train: epoch 0077, iter [00950, 01251], lr: 0.000093, loss: 0.3976
2022-10-04 10:56:35 - train: epoch 0077, iter [00960, 01251], lr: 0.000093, loss: 0.4137
2022-10-04 10:56:54 - train: epoch 0077, iter [00970, 01251], lr: 0.000093, loss: 0.4036
2022-10-04 10:57:14 - train: epoch 0077, iter [00980, 01251], lr: 0.000093, loss: 0.4115
2022-10-04 10:57:33 - train: epoch 0077, iter [00990, 01251], lr: 0.000093, loss: 0.3856
2022-10-04 10:57:53 - train: epoch 0077, iter [01000, 01251], lr: 0.000093, loss: 0.4023
2022-10-04 10:58:12 - train: epoch 0077, iter [01010, 01251], lr: 0.000093, loss: 0.3974
2022-10-04 10:58:31 - train: epoch 0077, iter [01020, 01251], lr: 0.000093, loss: 0.4097
2022-10-04 10:58:50 - train: epoch 0077, iter [01030, 01251], lr: 0.000093, loss: 0.3935
2022-10-04 10:59:09 - train: epoch 0077, iter [01040, 01251], lr: 0.000093, loss: 0.4066
2022-10-04 10:59:28 - train: epoch 0077, iter [01050, 01251], lr: 0.000093, loss: 0.3952
2022-10-04 10:59:47 - train: epoch 0077, iter [01060, 01251], lr: 0.000093, loss: 0.4016
2022-10-04 11:00:06 - train: epoch 0077, iter [01070, 01251], lr: 0.000093, loss: 0.4077
2022-10-04 11:00:25 - train: epoch 0077, iter [01080, 01251], lr: 0.000093, loss: 0.3903
2022-10-04 11:00:44 - train: epoch 0077, iter [01090, 01251], lr: 0.000093, loss: 0.3863
2022-10-04 11:01:03 - train: epoch 0077, iter [01100, 01251], lr: 0.000093, loss: 0.4149
2022-10-04 11:01:22 - train: epoch 0077, iter [01110, 01251], lr: 0.000092, loss: 0.3978
2022-10-04 11:01:42 - train: epoch 0077, iter [01120, 01251], lr: 0.000092, loss: 0.4318
2022-10-04 11:02:01 - train: epoch 0077, iter [01130, 01251], lr: 0.000092, loss: 0.4042
2022-10-04 11:02:20 - train: epoch 0077, iter [01140, 01251], lr: 0.000092, loss: 0.3845
2022-10-04 11:02:39 - train: epoch 0077, iter [01150, 01251], lr: 0.000092, loss: 0.3757
2022-10-04 11:02:58 - train: epoch 0077, iter [01160, 01251], lr: 0.000092, loss: 0.4021
2022-10-04 11:03:17 - train: epoch 0077, iter [01170, 01251], lr: 0.000092, loss: 0.4001
2022-10-04 11:03:36 - train: epoch 0077, iter [01180, 01251], lr: 0.000092, loss: 0.3794
2022-10-04 11:03:55 - train: epoch 0077, iter [01190, 01251], lr: 0.000092, loss: 0.4089
2022-10-04 11:04:14 - train: epoch 0077, iter [01200, 01251], lr: 0.000092, loss: 0.4089
2022-10-04 11:04:32 - train: epoch 0077, iter [01210, 01251], lr: 0.000092, loss: 0.3977
2022-10-04 11:04:51 - train: epoch 0077, iter [01220, 01251], lr: 0.000092, loss: 0.3989
2022-10-04 11:05:10 - train: epoch 0077, iter [01230, 01251], lr: 0.000092, loss: 0.4076
2022-10-04 11:05:29 - train: epoch 0077, iter [01240, 01251], lr: 0.000092, loss: 0.3858
2022-10-04 11:05:47 - train: epoch 0077, iter [01250, 01251], lr: 0.000092, loss: 0.3849
2022-10-04 11:05:52 - train: epoch 077, train_loss: 0.4021
2022-10-04 11:05:56 - until epoch: 077, best_loss: 0.4021
2022-10-04 11:05:56 - epoch 078 lr: 0.000092
2022-10-04 11:06:22 - train: epoch 0078, iter [00010, 01251], lr: 0.000092, loss: 0.4223
2022-10-04 11:06:41 - train: epoch 0078, iter [00020, 01251], lr: 0.000091, loss: 0.3905
2022-10-04 11:07:00 - train: epoch 0078, iter [00030, 01251], lr: 0.000091, loss: 0.4068
2022-10-04 11:07:19 - train: epoch 0078, iter [00040, 01251], lr: 0.000091, loss: 0.4041
2022-10-04 11:07:38 - train: epoch 0078, iter [00050, 01251], lr: 0.000091, loss: 0.3988
2022-10-04 11:07:57 - train: epoch 0078, iter [00060, 01251], lr: 0.000091, loss: 0.4139
2022-10-04 11:08:16 - train: epoch 0078, iter [00070, 01251], lr: 0.000091, loss: 0.4234
2022-10-04 11:08:36 - train: epoch 0078, iter [00080, 01251], lr: 0.000091, loss: 0.4303
2022-10-04 11:08:55 - train: epoch 0078, iter [00090, 01251], lr: 0.000091, loss: 0.4160
2022-10-04 11:09:14 - train: epoch 0078, iter [00100, 01251], lr: 0.000091, loss: 0.4129
2022-10-04 11:09:33 - train: epoch 0078, iter [00110, 01251], lr: 0.000091, loss: 0.4052
2022-10-04 11:09:53 - train: epoch 0078, iter [00120, 01251], lr: 0.000091, loss: 0.4189
2022-10-04 11:10:12 - train: epoch 0078, iter [00130, 01251], lr: 0.000091, loss: 0.4152
2022-10-04 11:10:31 - train: epoch 0078, iter [00140, 01251], lr: 0.000091, loss: 0.3923
2022-10-04 11:10:49 - train: epoch 0078, iter [00150, 01251], lr: 0.000091, loss: 0.3980
2022-10-04 11:11:08 - train: epoch 0078, iter [00160, 01251], lr: 0.000091, loss: 0.4030
2022-10-04 11:11:27 - train: epoch 0078, iter [00170, 01251], lr: 0.000091, loss: 0.3845
2022-10-04 11:11:46 - train: epoch 0078, iter [00180, 01251], lr: 0.000091, loss: 0.4007
2022-10-04 11:12:06 - train: epoch 0078, iter [00190, 01251], lr: 0.000090, loss: 0.3974
2022-10-04 11:12:25 - train: epoch 0078, iter [00200, 01251], lr: 0.000090, loss: 0.3973
2022-10-04 11:12:44 - train: epoch 0078, iter [00210, 01251], lr: 0.000090, loss: 0.3986
2022-10-04 11:13:02 - train: epoch 0078, iter [00220, 01251], lr: 0.000090, loss: 0.4020
2022-10-04 11:13:22 - train: epoch 0078, iter [00230, 01251], lr: 0.000090, loss: 0.4210
2022-10-04 11:13:40 - train: epoch 0078, iter [00240, 01251], lr: 0.000090, loss: 0.4042
2022-10-04 11:13:59 - train: epoch 0078, iter [00250, 01251], lr: 0.000090, loss: 0.4105
2022-10-04 11:14:18 - train: epoch 0078, iter [00260, 01251], lr: 0.000090, loss: 0.4156
2022-10-04 11:14:37 - train: epoch 0078, iter [00270, 01251], lr: 0.000090, loss: 0.4038
2022-10-04 11:14:56 - train: epoch 0078, iter [00280, 01251], lr: 0.000090, loss: 0.3935
2022-10-04 11:15:15 - train: epoch 0078, iter [00290, 01251], lr: 0.000090, loss: 0.4011
2022-10-04 11:15:35 - train: epoch 0078, iter [00300, 01251], lr: 0.000090, loss: 0.4137
2022-10-04 11:15:54 - train: epoch 0078, iter [00310, 01251], lr: 0.000090, loss: 0.4006
2022-10-04 11:16:12 - train: epoch 0078, iter [00320, 01251], lr: 0.000090, loss: 0.4040
2022-10-04 11:16:31 - train: epoch 0078, iter [00330, 01251], lr: 0.000090, loss: 0.3943
2022-10-04 11:16:50 - train: epoch 0078, iter [00340, 01251], lr: 0.000090, loss: 0.4028
2022-10-04 11:17:09 - train: epoch 0078, iter [00350, 01251], lr: 0.000090, loss: 0.3887
2022-10-04 11:17:28 - train: epoch 0078, iter [00360, 01251], lr: 0.000089, loss: 0.3925
2022-10-04 11:17:47 - train: epoch 0078, iter [00370, 01251], lr: 0.000089, loss: 0.4022
2022-10-04 11:18:06 - train: epoch 0078, iter [00380, 01251], lr: 0.000089, loss: 0.4032
2022-10-04 11:18:25 - train: epoch 0078, iter [00390, 01251], lr: 0.000089, loss: 0.3958
2022-10-04 11:18:43 - train: epoch 0078, iter [00400, 01251], lr: 0.000089, loss: 0.4226
2022-10-04 11:19:02 - train: epoch 0078, iter [00410, 01251], lr: 0.000089, loss: 0.3964
2022-10-04 11:19:21 - train: epoch 0078, iter [00420, 01251], lr: 0.000089, loss: 0.3980
2022-10-04 11:19:40 - train: epoch 0078, iter [00430, 01251], lr: 0.000089, loss: 0.3999
2022-10-04 11:19:59 - train: epoch 0078, iter [00440, 01251], lr: 0.000089, loss: 0.3975
2022-10-04 11:20:19 - train: epoch 0078, iter [00450, 01251], lr: 0.000089, loss: 0.4262
2022-10-04 11:20:38 - train: epoch 0078, iter [00460, 01251], lr: 0.000089, loss: 0.3897
2022-10-04 11:20:57 - train: epoch 0078, iter [00470, 01251], lr: 0.000089, loss: 0.3897
2022-10-04 11:21:17 - train: epoch 0078, iter [00480, 01251], lr: 0.000089, loss: 0.4043
2022-10-04 11:21:35 - train: epoch 0078, iter [00490, 01251], lr: 0.000089, loss: 0.4037
2022-10-04 11:21:55 - train: epoch 0078, iter [00500, 01251], lr: 0.000089, loss: 0.4029
2022-10-04 11:22:14 - train: epoch 0078, iter [00510, 01251], lr: 0.000089, loss: 0.4013
2022-10-04 11:22:33 - train: epoch 0078, iter [00520, 01251], lr: 0.000088, loss: 0.3972
2022-10-04 11:22:53 - train: epoch 0078, iter [00530, 01251], lr: 0.000088, loss: 0.4076
2022-10-04 11:23:12 - train: epoch 0078, iter [00540, 01251], lr: 0.000088, loss: 0.3991
2022-10-04 11:23:31 - train: epoch 0078, iter [00550, 01251], lr: 0.000088, loss: 0.3730
2022-10-04 11:23:50 - train: epoch 0078, iter [00560, 01251], lr: 0.000088, loss: 0.3896
2022-10-04 11:24:09 - train: epoch 0078, iter [00570, 01251], lr: 0.000088, loss: 0.4044
2022-10-04 11:24:27 - train: epoch 0078, iter [00580, 01251], lr: 0.000088, loss: 0.4138
2022-10-04 11:24:46 - train: epoch 0078, iter [00590, 01251], lr: 0.000088, loss: 0.4062
2022-10-04 11:25:05 - train: epoch 0078, iter [00600, 01251], lr: 0.000088, loss: 0.4097
2022-10-04 11:25:24 - train: epoch 0078, iter [00610, 01251], lr: 0.000088, loss: 0.4086
2022-10-04 11:25:43 - train: epoch 0078, iter [00620, 01251], lr: 0.000088, loss: 0.3917
2022-10-04 11:26:03 - train: epoch 0078, iter [00630, 01251], lr: 0.000088, loss: 0.4172
2022-10-04 11:26:22 - train: epoch 0078, iter [00640, 01251], lr: 0.000088, loss: 0.4011
2022-10-04 11:26:41 - train: epoch 0078, iter [00650, 01251], lr: 0.000088, loss: 0.4159
2022-10-04 11:27:00 - train: epoch 0078, iter [00660, 01251], lr: 0.000088, loss: 0.4058
2022-10-04 11:27:19 - train: epoch 0078, iter [00670, 01251], lr: 0.000088, loss: 0.3822
2022-10-04 11:27:37 - train: epoch 0078, iter [00680, 01251], lr: 0.000088, loss: 0.3924
2022-10-04 11:27:56 - train: epoch 0078, iter [00690, 01251], lr: 0.000087, loss: 0.3888
2022-10-04 11:28:15 - train: epoch 0078, iter [00700, 01251], lr: 0.000087, loss: 0.3909
2022-10-04 11:28:34 - train: epoch 0078, iter [00710, 01251], lr: 0.000087, loss: 0.3954
2022-10-04 11:28:53 - train: epoch 0078, iter [00720, 01251], lr: 0.000087, loss: 0.3911
2022-10-04 11:29:12 - train: epoch 0078, iter [00730, 01251], lr: 0.000087, loss: 0.4162
2022-10-04 11:29:32 - train: epoch 0078, iter [00740, 01251], lr: 0.000087, loss: 0.3908
2022-10-04 11:29:51 - train: epoch 0078, iter [00750, 01251], lr: 0.000087, loss: 0.4143
2022-10-04 11:30:10 - train: epoch 0078, iter [00760, 01251], lr: 0.000087, loss: 0.3979
2022-10-04 11:30:29 - train: epoch 0078, iter [00770, 01251], lr: 0.000087, loss: 0.4048
2022-10-04 11:30:48 - train: epoch 0078, iter [00780, 01251], lr: 0.000087, loss: 0.3935
2022-10-04 11:31:07 - train: epoch 0078, iter [00790, 01251], lr: 0.000087, loss: 0.3921
2022-10-04 11:31:26 - train: epoch 0078, iter [00800, 01251], lr: 0.000087, loss: 0.3964
2022-10-04 11:31:45 - train: epoch 0078, iter [00810, 01251], lr: 0.000087, loss: 0.4214
2022-10-04 11:32:04 - train: epoch 0078, iter [00820, 01251], lr: 0.000087, loss: 0.3820
2022-10-04 11:32:23 - train: epoch 0078, iter [00830, 01251], lr: 0.000087, loss: 0.3898
2022-10-04 11:32:42 - train: epoch 0078, iter [00840, 01251], lr: 0.000087, loss: 0.3869
2022-10-04 11:33:01 - train: epoch 0078, iter [00850, 01251], lr: 0.000087, loss: 0.4156
2022-10-04 11:33:20 - train: epoch 0078, iter [00860, 01251], lr: 0.000086, loss: 0.4193
2022-10-04 11:33:39 - train: epoch 0078, iter [00870, 01251], lr: 0.000086, loss: 0.4048
2022-10-04 11:33:58 - train: epoch 0078, iter [00880, 01251], lr: 0.000086, loss: 0.3845
2022-10-04 11:34:17 - train: epoch 0078, iter [00890, 01251], lr: 0.000086, loss: 0.4156
2022-10-04 11:34:36 - train: epoch 0078, iter [00900, 01251], lr: 0.000086, loss: 0.4210
2022-10-04 11:34:55 - train: epoch 0078, iter [00910, 01251], lr: 0.000086, loss: 0.3894
2022-10-04 11:35:14 - train: epoch 0078, iter [00920, 01251], lr: 0.000086, loss: 0.4086
2022-10-04 11:35:33 - train: epoch 0078, iter [00930, 01251], lr: 0.000086, loss: 0.4123
2022-10-04 11:35:52 - train: epoch 0078, iter [00940, 01251], lr: 0.000086, loss: 0.4087
2022-10-04 11:36:11 - train: epoch 0078, iter [00950, 01251], lr: 0.000086, loss: 0.4167
2022-10-04 11:36:30 - train: epoch 0078, iter [00960, 01251], lr: 0.000086, loss: 0.3962
2022-10-04 11:36:49 - train: epoch 0078, iter [00970, 01251], lr: 0.000086, loss: 0.3898
2022-10-04 11:37:08 - train: epoch 0078, iter [00980, 01251], lr: 0.000086, loss: 0.3964
2022-10-04 11:37:27 - train: epoch 0078, iter [00990, 01251], lr: 0.000086, loss: 0.4051
2022-10-04 11:37:46 - train: epoch 0078, iter [01000, 01251], lr: 0.000086, loss: 0.3961
2022-10-04 11:38:05 - train: epoch 0078, iter [01010, 01251], lr: 0.000086, loss: 0.3787
2022-10-04 11:38:23 - train: epoch 0078, iter [01020, 01251], lr: 0.000086, loss: 0.4067
2022-10-04 11:38:42 - train: epoch 0078, iter [01030, 01251], lr: 0.000085, loss: 0.4068
2022-10-04 11:39:01 - train: epoch 0078, iter [01040, 01251], lr: 0.000085, loss: 0.4144
2022-10-04 11:39:20 - train: epoch 0078, iter [01050, 01251], lr: 0.000085, loss: 0.4062
2022-10-04 11:39:38 - train: epoch 0078, iter [01060, 01251], lr: 0.000085, loss: 0.3923
2022-10-04 11:39:57 - train: epoch 0078, iter [01070, 01251], lr: 0.000085, loss: 0.3986
2022-10-04 11:40:16 - train: epoch 0078, iter [01080, 01251], lr: 0.000085, loss: 0.3933
2022-10-04 11:40:35 - train: epoch 0078, iter [01090, 01251], lr: 0.000085, loss: 0.4102
2022-10-04 11:40:54 - train: epoch 0078, iter [01100, 01251], lr: 0.000085, loss: 0.4128
2022-10-04 11:41:13 - train: epoch 0078, iter [01110, 01251], lr: 0.000085, loss: 0.4076
2022-10-04 11:41:32 - train: epoch 0078, iter [01120, 01251], lr: 0.000085, loss: 0.3859
2022-10-04 11:41:51 - train: epoch 0078, iter [01130, 01251], lr: 0.000085, loss: 0.4206
2022-10-04 11:42:10 - train: epoch 0078, iter [01140, 01251], lr: 0.000085, loss: 0.4064
2022-10-04 11:42:28 - train: epoch 0078, iter [01150, 01251], lr: 0.000085, loss: 0.3892
2022-10-04 11:42:47 - train: epoch 0078, iter [01160, 01251], lr: 0.000085, loss: 0.4060
2022-10-04 11:43:06 - train: epoch 0078, iter [01170, 01251], lr: 0.000085, loss: 0.3852
2022-10-04 11:43:26 - train: epoch 0078, iter [01180, 01251], lr: 0.000085, loss: 0.4098
2022-10-04 11:43:45 - train: epoch 0078, iter [01190, 01251], lr: 0.000085, loss: 0.3990
2022-10-04 11:44:04 - train: epoch 0078, iter [01200, 01251], lr: 0.000084, loss: 0.4100
2022-10-04 11:44:22 - train: epoch 0078, iter [01210, 01251], lr: 0.000084, loss: 0.3971
2022-10-04 11:44:41 - train: epoch 0078, iter [01220, 01251], lr: 0.000084, loss: 0.4132
2022-10-04 11:45:00 - train: epoch 0078, iter [01230, 01251], lr: 0.000084, loss: 0.4121
2022-10-04 11:45:19 - train: epoch 0078, iter [01240, 01251], lr: 0.000084, loss: 0.4042
2022-10-04 11:45:37 - train: epoch 0078, iter [01250, 01251], lr: 0.000084, loss: 0.3972
2022-10-04 11:45:42 - train: epoch 078, train_loss: 0.4019
2022-10-04 11:45:46 - until epoch: 078, best_loss: 0.4019
2022-10-04 11:45:46 - epoch 079 lr: 0.000084
2022-10-04 11:46:11 - train: epoch 0079, iter [00010, 01251], lr: 0.000084, loss: 0.4104
2022-10-04 11:46:29 - train: epoch 0079, iter [00020, 01251], lr: 0.000084, loss: 0.3840
2022-10-04 11:46:48 - train: epoch 0079, iter [00030, 01251], lr: 0.000084, loss: 0.4064
2022-10-04 11:47:07 - train: epoch 0079, iter [00040, 01251], lr: 0.000084, loss: 0.3787
2022-10-04 11:47:26 - train: epoch 0079, iter [00050, 01251], lr: 0.000084, loss: 0.4026
2022-10-04 11:47:45 - train: epoch 0079, iter [00060, 01251], lr: 0.000084, loss: 0.3965
2022-10-04 11:48:04 - train: epoch 0079, iter [00070, 01251], lr: 0.000084, loss: 0.4001
2022-10-04 11:48:23 - train: epoch 0079, iter [00080, 01251], lr: 0.000084, loss: 0.4050
2022-10-04 11:48:41 - train: epoch 0079, iter [00090, 01251], lr: 0.000084, loss: 0.3991
2022-10-04 11:49:00 - train: epoch 0079, iter [00100, 01251], lr: 0.000084, loss: 0.3954
2022-10-04 11:49:19 - train: epoch 0079, iter [00110, 01251], lr: 0.000084, loss: 0.4112
2022-10-04 11:49:38 - train: epoch 0079, iter [00120, 01251], lr: 0.000084, loss: 0.3793
2022-10-04 11:49:57 - train: epoch 0079, iter [00130, 01251], lr: 0.000083, loss: 0.4011
2022-10-04 11:50:16 - train: epoch 0079, iter [00140, 01251], lr: 0.000083, loss: 0.4118
2022-10-04 11:50:35 - train: epoch 0079, iter [00150, 01251], lr: 0.000083, loss: 0.4043
2022-10-04 11:50:54 - train: epoch 0079, iter [00160, 01251], lr: 0.000083, loss: 0.4032
2022-10-04 11:51:12 - train: epoch 0079, iter [00170, 01251], lr: 0.000083, loss: 0.4137
2022-10-04 11:51:31 - train: epoch 0079, iter [00180, 01251], lr: 0.000083, loss: 0.4052
2022-10-04 11:51:50 - train: epoch 0079, iter [00190, 01251], lr: 0.000083, loss: 0.4203
2022-10-04 11:52:10 - train: epoch 0079, iter [00200, 01251], lr: 0.000083, loss: 0.4117
2022-10-04 11:52:29 - train: epoch 0079, iter [00210, 01251], lr: 0.000083, loss: 0.3982
2022-10-04 11:52:47 - train: epoch 0079, iter [00220, 01251], lr: 0.000083, loss: 0.3927
2022-10-04 11:53:06 - train: epoch 0079, iter [00230, 01251], lr: 0.000083, loss: 0.4064
2022-10-04 11:53:25 - train: epoch 0079, iter [00240, 01251], lr: 0.000083, loss: 0.4144
2022-10-04 11:53:44 - train: epoch 0079, iter [00250, 01251], lr: 0.000083, loss: 0.4117
2022-10-04 11:54:03 - train: epoch 0079, iter [00260, 01251], lr: 0.000083, loss: 0.3880
2022-10-04 11:54:22 - train: epoch 0079, iter [00270, 01251], lr: 0.000083, loss: 0.3868
2022-10-04 11:54:41 - train: epoch 0079, iter [00280, 01251], lr: 0.000083, loss: 0.4098
2022-10-04 11:55:00 - train: epoch 0079, iter [00290, 01251], lr: 0.000083, loss: 0.3932
2022-10-04 11:55:18 - train: epoch 0079, iter [00300, 01251], lr: 0.000082, loss: 0.4068
2022-10-04 11:55:38 - train: epoch 0079, iter [00310, 01251], lr: 0.000082, loss: 0.4145
2022-10-04 11:55:57 - train: epoch 0079, iter [00320, 01251], lr: 0.000082, loss: 0.4268
2022-10-04 11:56:16 - train: epoch 0079, iter [00330, 01251], lr: 0.000082, loss: 0.4246
2022-10-04 11:56:35 - train: epoch 0079, iter [00340, 01251], lr: 0.000082, loss: 0.4044
2022-10-04 11:56:54 - train: epoch 0079, iter [00350, 01251], lr: 0.000082, loss: 0.4102
2022-10-04 11:57:12 - train: epoch 0079, iter [00360, 01251], lr: 0.000082, loss: 0.4108
2022-10-04 11:57:31 - train: epoch 0079, iter [00370, 01251], lr: 0.000082, loss: 0.4103
2022-10-04 11:57:50 - train: epoch 0079, iter [00380, 01251], lr: 0.000082, loss: 0.3935
2022-10-04 11:58:09 - train: epoch 0079, iter [00390, 01251], lr: 0.000082, loss: 0.3958
2022-10-04 11:58:28 - train: epoch 0079, iter [00400, 01251], lr: 0.000082, loss: 0.4053
2022-10-04 11:58:47 - train: epoch 0079, iter [00410, 01251], lr: 0.000082, loss: 0.3794
2022-10-04 11:59:06 - train: epoch 0079, iter [00420, 01251], lr: 0.000082, loss: 0.4050
2022-10-04 11:59:25 - train: epoch 0079, iter [00430, 01251], lr: 0.000082, loss: 0.4042
2022-10-04 11:59:44 - train: epoch 0079, iter [00440, 01251], lr: 0.000082, loss: 0.3991
2022-10-04 12:00:03 - train: epoch 0079, iter [00450, 01251], lr: 0.000082, loss: 0.3894
2022-10-04 12:00:22 - train: epoch 0079, iter [00460, 01251], lr: 0.000082, loss: 0.4026
2022-10-04 12:00:42 - train: epoch 0079, iter [00470, 01251], lr: 0.000081, loss: 0.3993
2022-10-04 12:01:00 - train: epoch 0079, iter [00480, 01251], lr: 0.000081, loss: 0.3826
2022-10-04 12:01:19 - train: epoch 0079, iter [00490, 01251], lr: 0.000081, loss: 0.3876
2022-10-04 12:01:38 - train: epoch 0079, iter [00500, 01251], lr: 0.000081, loss: 0.4305
2022-10-04 12:01:57 - train: epoch 0079, iter [00510, 01251], lr: 0.000081, loss: 0.4094
2022-10-04 12:02:16 - train: epoch 0079, iter [00520, 01251], lr: 0.000081, loss: 0.4028
2022-10-04 12:02:35 - train: epoch 0079, iter [00530, 01251], lr: 0.000081, loss: 0.4196
2022-10-04 12:02:53 - train: epoch 0079, iter [00540, 01251], lr: 0.000081, loss: 0.4191
2022-10-04 12:03:12 - train: epoch 0079, iter [00550, 01251], lr: 0.000081, loss: 0.4076
2022-10-04 12:03:31 - train: epoch 0079, iter [00560, 01251], lr: 0.000081, loss: 0.4190
2022-10-04 12:03:50 - train: epoch 0079, iter [00570, 01251], lr: 0.000081, loss: 0.3911
2022-10-04 12:04:08 - train: epoch 0079, iter [00580, 01251], lr: 0.000081, loss: 0.3916
2022-10-04 12:04:27 - train: epoch 0079, iter [00590, 01251], lr: 0.000081, loss: 0.4146
2022-10-04 12:04:46 - train: epoch 0079, iter [00600, 01251], lr: 0.000081, loss: 0.4053
2022-10-04 12:05:04 - train: epoch 0079, iter [00610, 01251], lr: 0.000081, loss: 0.4023
2022-10-04 12:05:23 - train: epoch 0079, iter [00620, 01251], lr: 0.000081, loss: 0.3965
2022-10-04 12:05:43 - train: epoch 0079, iter [00630, 01251], lr: 0.000081, loss: 0.4057
2022-10-04 12:06:01 - train: epoch 0079, iter [00640, 01251], lr: 0.000081, loss: 0.4168
2022-10-04 12:06:20 - train: epoch 0079, iter [00650, 01251], lr: 0.000080, loss: 0.3852
2022-10-04 12:06:39 - train: epoch 0079, iter [00660, 01251], lr: 0.000080, loss: 0.3956
2022-10-04 12:06:58 - train: epoch 0079, iter [00670, 01251], lr: 0.000080, loss: 0.4023
2022-10-04 12:07:17 - train: epoch 0079, iter [00680, 01251], lr: 0.000080, loss: 0.3834
2022-10-04 12:07:37 - train: epoch 0079, iter [00690, 01251], lr: 0.000080, loss: 0.3992
2022-10-04 12:07:55 - train: epoch 0079, iter [00700, 01251], lr: 0.000080, loss: 0.3842
2022-10-04 12:08:14 - train: epoch 0079, iter [00710, 01251], lr: 0.000080, loss: 0.3979
2022-10-04 12:08:33 - train: epoch 0079, iter [00720, 01251], lr: 0.000080, loss: 0.3888
2022-10-04 12:08:52 - train: epoch 0079, iter [00730, 01251], lr: 0.000080, loss: 0.4072
2022-10-04 12:09:10 - train: epoch 0079, iter [00740, 01251], lr: 0.000080, loss: 0.3974
2022-10-04 12:09:29 - train: epoch 0079, iter [00750, 01251], lr: 0.000080, loss: 0.3809
2022-10-04 12:09:48 - train: epoch 0079, iter [00760, 01251], lr: 0.000080, loss: 0.4170
2022-10-04 12:10:07 - train: epoch 0079, iter [00770, 01251], lr: 0.000080, loss: 0.4181
2022-10-04 12:10:25 - train: epoch 0079, iter [00780, 01251], lr: 0.000080, loss: 0.3942
2022-10-04 12:10:44 - train: epoch 0079, iter [00790, 01251], lr: 0.000080, loss: 0.3925
2022-10-04 12:11:03 - train: epoch 0079, iter [00800, 01251], lr: 0.000080, loss: 0.3824
2022-10-04 12:11:22 - train: epoch 0079, iter [00810, 01251], lr: 0.000080, loss: 0.4099
2022-10-04 12:11:41 - train: epoch 0079, iter [00820, 01251], lr: 0.000079, loss: 0.3924
2022-10-04 12:12:00 - train: epoch 0079, iter [00830, 01251], lr: 0.000079, loss: 0.4128
2022-10-04 12:12:19 - train: epoch 0079, iter [00840, 01251], lr: 0.000079, loss: 0.3805
2022-10-04 12:12:38 - train: epoch 0079, iter [00850, 01251], lr: 0.000079, loss: 0.3791
2022-10-04 12:12:57 - train: epoch 0079, iter [00860, 01251], lr: 0.000079, loss: 0.4234
2022-10-04 12:13:16 - train: epoch 0079, iter [00870, 01251], lr: 0.000079, loss: 0.3784
2022-10-04 12:13:35 - train: epoch 0079, iter [00880, 01251], lr: 0.000079, loss: 0.4163
2022-10-04 12:13:54 - train: epoch 0079, iter [00890, 01251], lr: 0.000079, loss: 0.3996
2022-10-04 12:14:13 - train: epoch 0079, iter [00900, 01251], lr: 0.000079, loss: 0.3950
2022-10-04 12:14:31 - train: epoch 0079, iter [00910, 01251], lr: 0.000079, loss: 0.4005
2022-10-04 12:14:51 - train: epoch 0079, iter [00920, 01251], lr: 0.000079, loss: 0.3930
2022-10-04 12:15:09 - train: epoch 0079, iter [00930, 01251], lr: 0.000079, loss: 0.3919
2022-10-04 12:15:28 - train: epoch 0079, iter [00940, 01251], lr: 0.000079, loss: 0.3953
2022-10-04 12:15:47 - train: epoch 0079, iter [00950, 01251], lr: 0.000079, loss: 0.3829
2022-10-04 12:16:06 - train: epoch 0079, iter [00960, 01251], lr: 0.000079, loss: 0.3873
2022-10-04 12:16:24 - train: epoch 0079, iter [00970, 01251], lr: 0.000079, loss: 0.4041
2022-10-04 12:16:43 - train: epoch 0079, iter [00980, 01251], lr: 0.000079, loss: 0.4025
2022-10-04 12:17:02 - train: epoch 0079, iter [00990, 01251], lr: 0.000079, loss: 0.4069
2022-10-04 12:17:21 - train: epoch 0079, iter [01000, 01251], lr: 0.000078, loss: 0.3993
2022-10-04 12:17:40 - train: epoch 0079, iter [01010, 01251], lr: 0.000078, loss: 0.4063
2022-10-04 12:17:58 - train: epoch 0079, iter [01020, 01251], lr: 0.000078, loss: 0.4135
2022-10-04 12:18:17 - train: epoch 0079, iter [01030, 01251], lr: 0.000078, loss: 0.4046
2022-10-04 12:18:37 - train: epoch 0079, iter [01040, 01251], lr: 0.000078, loss: 0.4162
2022-10-04 12:18:55 - train: epoch 0079, iter [01050, 01251], lr: 0.000078, loss: 0.4183
2022-10-04 12:19:14 - train: epoch 0079, iter [01060, 01251], lr: 0.000078, loss: 0.3829
2022-10-04 12:19:33 - train: epoch 0079, iter [01070, 01251], lr: 0.000078, loss: 0.4283
2022-10-04 12:19:52 - train: epoch 0079, iter [01080, 01251], lr: 0.000078, loss: 0.4106
2022-10-04 12:20:11 - train: epoch 0079, iter [01090, 01251], lr: 0.000078, loss: 0.3880
2022-10-04 12:20:29 - train: epoch 0079, iter [01100, 01251], lr: 0.000078, loss: 0.4048
2022-10-04 12:20:48 - train: epoch 0079, iter [01110, 01251], lr: 0.000078, loss: 0.3916
2022-10-04 12:21:07 - train: epoch 0079, iter [01120, 01251], lr: 0.000078, loss: 0.4008
2022-10-04 12:21:26 - train: epoch 0079, iter [01130, 01251], lr: 0.000078, loss: 0.4025
2022-10-04 12:21:45 - train: epoch 0079, iter [01140, 01251], lr: 0.000078, loss: 0.3956
2022-10-04 12:22:04 - train: epoch 0079, iter [01150, 01251], lr: 0.000078, loss: 0.3953
2022-10-04 12:22:22 - train: epoch 0079, iter [01160, 01251], lr: 0.000078, loss: 0.4020
2022-10-04 12:22:41 - train: epoch 0079, iter [01170, 01251], lr: 0.000078, loss: 0.3957
2022-10-04 12:23:00 - train: epoch 0079, iter [01180, 01251], lr: 0.000077, loss: 0.4106
2022-10-04 12:23:19 - train: epoch 0079, iter [01190, 01251], lr: 0.000077, loss: 0.4014
2022-10-04 12:23:38 - train: epoch 0079, iter [01200, 01251], lr: 0.000077, loss: 0.3879
2022-10-04 12:23:57 - train: epoch 0079, iter [01210, 01251], lr: 0.000077, loss: 0.4057
2022-10-04 12:24:16 - train: epoch 0079, iter [01220, 01251], lr: 0.000077, loss: 0.4227
2022-10-04 12:24:34 - train: epoch 0079, iter [01230, 01251], lr: 0.000077, loss: 0.4119
2022-10-04 12:24:54 - train: epoch 0079, iter [01240, 01251], lr: 0.000077, loss: 0.4078
2022-10-04 12:25:12 - train: epoch 0079, iter [01250, 01251], lr: 0.000077, loss: 0.4013
2022-10-04 12:25:17 - train: epoch 079, train_loss: 0.4017
2022-10-04 12:25:21 - until epoch: 079, best_loss: 0.4017
2022-10-04 12:25:21 - epoch 080 lr: 0.000077
2022-10-04 12:25:46 - train: epoch 0080, iter [00010, 01251], lr: 0.000077, loss: 0.4101
2022-10-04 12:26:05 - train: epoch 0080, iter [00020, 01251], lr: 0.000077, loss: 0.3871
2022-10-04 12:26:23 - train: epoch 0080, iter [00030, 01251], lr: 0.000077, loss: 0.4119
2022-10-04 12:26:42 - train: epoch 0080, iter [00040, 01251], lr: 0.000077, loss: 0.4082
2022-10-04 12:27:01 - train: epoch 0080, iter [00050, 01251], lr: 0.000077, loss: 0.3894
2022-10-04 12:27:19 - train: epoch 0080, iter [00060, 01251], lr: 0.000077, loss: 0.3889
2022-10-04 12:27:38 - train: epoch 0080, iter [00070, 01251], lr: 0.000077, loss: 0.3993
2022-10-04 12:27:56 - train: epoch 0080, iter [00080, 01251], lr: 0.000077, loss: 0.3920
2022-10-04 12:28:15 - train: epoch 0080, iter [00090, 01251], lr: 0.000077, loss: 0.3947
2022-10-04 12:28:34 - train: epoch 0080, iter [00100, 01251], lr: 0.000076, loss: 0.3993
2022-10-04 12:28:53 - train: epoch 0080, iter [00110, 01251], lr: 0.000076, loss: 0.3879
2022-10-04 12:29:13 - train: epoch 0080, iter [00120, 01251], lr: 0.000076, loss: 0.3928
2022-10-04 12:29:31 - train: epoch 0080, iter [00130, 01251], lr: 0.000076, loss: 0.3942
2022-10-04 12:29:50 - train: epoch 0080, iter [00140, 01251], lr: 0.000076, loss: 0.4032
2022-10-04 12:30:09 - train: epoch 0080, iter [00150, 01251], lr: 0.000076, loss: 0.4003
2022-10-04 12:30:28 - train: epoch 0080, iter [00160, 01251], lr: 0.000076, loss: 0.3933
2022-10-04 12:30:47 - train: epoch 0080, iter [00170, 01251], lr: 0.000076, loss: 0.3965
2022-10-04 12:31:06 - train: epoch 0080, iter [00180, 01251], lr: 0.000076, loss: 0.4041
2022-10-04 12:31:25 - train: epoch 0080, iter [00190, 01251], lr: 0.000076, loss: 0.4149
2022-10-04 12:31:44 - train: epoch 0080, iter [00200, 01251], lr: 0.000076, loss: 0.4054
2022-10-04 12:32:03 - train: epoch 0080, iter [00210, 01251], lr: 0.000076, loss: 0.4027
2022-10-04 12:32:21 - train: epoch 0080, iter [00220, 01251], lr: 0.000076, loss: 0.4055
2022-10-04 12:32:40 - train: epoch 0080, iter [00230, 01251], lr: 0.000076, loss: 0.3911
2022-10-04 12:32:59 - train: epoch 0080, iter [00240, 01251], lr: 0.000076, loss: 0.3832
2022-10-04 12:33:18 - train: epoch 0080, iter [00250, 01251], lr: 0.000076, loss: 0.4081
2022-10-04 12:33:37 - train: epoch 0080, iter [00260, 01251], lr: 0.000076, loss: 0.4072
2022-10-04 12:33:56 - train: epoch 0080, iter [00270, 01251], lr: 0.000076, loss: 0.3954
2022-10-04 12:34:15 - train: epoch 0080, iter [00280, 01251], lr: 0.000075, loss: 0.4019
2022-10-04 12:34:33 - train: epoch 0080, iter [00290, 01251], lr: 0.000075, loss: 0.4167
2022-10-04 12:34:52 - train: epoch 0080, iter [00300, 01251], lr: 0.000075, loss: 0.4248
2022-10-04 12:35:11 - train: epoch 0080, iter [00310, 01251], lr: 0.000075, loss: 0.3888
2022-10-04 12:35:30 - train: epoch 0080, iter [00320, 01251], lr: 0.000075, loss: 0.3930
2022-10-04 12:35:49 - train: epoch 0080, iter [00330, 01251], lr: 0.000075, loss: 0.3863
2022-10-04 12:36:08 - train: epoch 0080, iter [00340, 01251], lr: 0.000075, loss: 0.4057
2022-10-04 12:36:27 - train: epoch 0080, iter [00350, 01251], lr: 0.000075, loss: 0.3913
2022-10-04 12:36:46 - train: epoch 0080, iter [00360, 01251], lr: 0.000075, loss: 0.3924
2022-10-04 12:37:04 - train: epoch 0080, iter [00370, 01251], lr: 0.000075, loss: 0.3957
2022-10-04 12:37:23 - train: epoch 0080, iter [00380, 01251], lr: 0.000075, loss: 0.3894
2022-10-04 12:37:42 - train: epoch 0080, iter [00390, 01251], lr: 0.000075, loss: 0.4105
2022-10-04 12:38:01 - train: epoch 0080, iter [00400, 01251], lr: 0.000075, loss: 0.3886
2022-10-04 12:38:19 - train: epoch 0080, iter [00410, 01251], lr: 0.000075, loss: 0.3959
2022-10-04 12:38:38 - train: epoch 0080, iter [00420, 01251], lr: 0.000075, loss: 0.4124
2022-10-04 12:38:57 - train: epoch 0080, iter [00430, 01251], lr: 0.000075, loss: 0.3874
2022-10-04 12:39:16 - train: epoch 0080, iter [00440, 01251], lr: 0.000075, loss: 0.3870
2022-10-04 12:39:35 - train: epoch 0080, iter [00450, 01251], lr: 0.000075, loss: 0.3863
2022-10-04 12:39:54 - train: epoch 0080, iter [00460, 01251], lr: 0.000074, loss: 0.4126
2022-10-04 12:40:13 - train: epoch 0080, iter [00470, 01251], lr: 0.000074, loss: 0.3804
2022-10-04 12:40:32 - train: epoch 0080, iter [00480, 01251], lr: 0.000074, loss: 0.3907
2022-10-04 12:40:51 - train: epoch 0080, iter [00490, 01251], lr: 0.000074, loss: 0.4271
2022-10-04 12:41:10 - train: epoch 0080, iter [00500, 01251], lr: 0.000074, loss: 0.3877
2022-10-04 12:41:29 - train: epoch 0080, iter [00510, 01251], lr: 0.000074, loss: 0.4043
2022-10-04 12:41:48 - train: epoch 0080, iter [00520, 01251], lr: 0.000074, loss: 0.3868
2022-10-04 12:42:06 - train: epoch 0080, iter [00530, 01251], lr: 0.000074, loss: 0.3846
2022-10-04 12:42:25 - train: epoch 0080, iter [00540, 01251], lr: 0.000074, loss: 0.4008
2022-10-04 12:42:44 - train: epoch 0080, iter [00550, 01251], lr: 0.000074, loss: 0.4074
2022-10-04 12:43:03 - train: epoch 0080, iter [00560, 01251], lr: 0.000074, loss: 0.3962
2022-10-04 12:43:21 - train: epoch 0080, iter [00570, 01251], lr: 0.000074, loss: 0.3937
2022-10-04 12:43:40 - train: epoch 0080, iter [00580, 01251], lr: 0.000074, loss: 0.4075
2022-10-04 12:43:59 - train: epoch 0080, iter [00590, 01251], lr: 0.000074, loss: 0.4048
2022-10-04 12:44:17 - train: epoch 0080, iter [00600, 01251], lr: 0.000074, loss: 0.4258
2022-10-04 12:44:36 - train: epoch 0080, iter [00610, 01251], lr: 0.000074, loss: 0.4071
2022-10-04 12:44:55 - train: epoch 0080, iter [00620, 01251], lr: 0.000074, loss: 0.4028
2022-10-04 12:45:15 - train: epoch 0080, iter [00630, 01251], lr: 0.000074, loss: 0.3974
2022-10-04 12:45:34 - train: epoch 0080, iter [00640, 01251], lr: 0.000074, loss: 0.3886
2022-10-04 12:45:53 - train: epoch 0080, iter [00650, 01251], lr: 0.000073, loss: 0.4081
2022-10-04 12:46:12 - train: epoch 0080, iter [00660, 01251], lr: 0.000073, loss: 0.3920
2022-10-04 12:46:31 - train: epoch 0080, iter [00670, 01251], lr: 0.000073, loss: 0.3942
2022-10-04 12:46:50 - train: epoch 0080, iter [00680, 01251], lr: 0.000073, loss: 0.3847
2022-10-04 12:47:09 - train: epoch 0080, iter [00690, 01251], lr: 0.000073, loss: 0.3906
2022-10-04 12:47:28 - train: epoch 0080, iter [00700, 01251], lr: 0.000073, loss: 0.3898
2022-10-04 12:47:47 - train: epoch 0080, iter [00710, 01251], lr: 0.000073, loss: 0.4019
2022-10-04 12:48:05 - train: epoch 0080, iter [00720, 01251], lr: 0.000073, loss: 0.4105
2022-10-04 12:48:24 - train: epoch 0080, iter [00730, 01251], lr: 0.000073, loss: 0.4067
2022-10-04 12:48:43 - train: epoch 0080, iter [00740, 01251], lr: 0.000073, loss: 0.3966
2022-10-04 12:49:02 - train: epoch 0080, iter [00750, 01251], lr: 0.000073, loss: 0.3974
2022-10-04 12:49:21 - train: epoch 0080, iter [00760, 01251], lr: 0.000073, loss: 0.3886
2022-10-04 12:49:39 - train: epoch 0080, iter [00770, 01251], lr: 0.000073, loss: 0.3959
2022-10-04 12:49:58 - train: epoch 0080, iter [00780, 01251], lr: 0.000073, loss: 0.3927
2022-10-04 12:50:17 - train: epoch 0080, iter [00790, 01251], lr: 0.000073, loss: 0.4099
2022-10-04 12:50:36 - train: epoch 0080, iter [00800, 01251], lr: 0.000073, loss: 0.4015
2022-10-04 12:50:54 - train: epoch 0080, iter [00810, 01251], lr: 0.000073, loss: 0.4171
2022-10-04 12:51:13 - train: epoch 0080, iter [00820, 01251], lr: 0.000073, loss: 0.3975
2022-10-04 12:51:32 - train: epoch 0080, iter [00830, 01251], lr: 0.000072, loss: 0.4080
2022-10-04 12:51:51 - train: epoch 0080, iter [00840, 01251], lr: 0.000072, loss: 0.4010
2022-10-04 12:52:09 - train: epoch 0080, iter [00850, 01251], lr: 0.000072, loss: 0.4231
2022-10-04 12:52:29 - train: epoch 0080, iter [00860, 01251], lr: 0.000072, loss: 0.4053
2022-10-04 12:52:48 - train: epoch 0080, iter [00870, 01251], lr: 0.000072, loss: 0.4005
2022-10-04 12:53:07 - train: epoch 0080, iter [00880, 01251], lr: 0.000072, loss: 0.4002
2022-10-04 12:53:26 - train: epoch 0080, iter [00890, 01251], lr: 0.000072, loss: 0.3746
2022-10-04 12:53:45 - train: epoch 0080, iter [00900, 01251], lr: 0.000072, loss: 0.4158
2022-10-04 12:54:03 - train: epoch 0080, iter [00910, 01251], lr: 0.000072, loss: 0.3996
2022-10-04 12:54:22 - train: epoch 0080, iter [00920, 01251], lr: 0.000072, loss: 0.3885
2022-10-04 12:54:41 - train: epoch 0080, iter [00930, 01251], lr: 0.000072, loss: 0.4017
2022-10-04 12:55:00 - train: epoch 0080, iter [00940, 01251], lr: 0.000072, loss: 0.4124
2022-10-04 12:55:19 - train: epoch 0080, iter [00950, 01251], lr: 0.000072, loss: 0.4000
2022-10-04 12:55:39 - train: epoch 0080, iter [00960, 01251], lr: 0.000072, loss: 0.3933
2022-10-04 12:55:58 - train: epoch 0080, iter [00970, 01251], lr: 0.000072, loss: 0.3800
2022-10-04 12:56:17 - train: epoch 0080, iter [00980, 01251], lr: 0.000072, loss: 0.4032
2022-10-04 12:56:36 - train: epoch 0080, iter [00990, 01251], lr: 0.000072, loss: 0.3923
2022-10-04 12:56:55 - train: epoch 0080, iter [01000, 01251], lr: 0.000072, loss: 0.4130
2022-10-04 12:57:13 - train: epoch 0080, iter [01010, 01251], lr: 0.000071, loss: 0.4138
2022-10-04 12:57:32 - train: epoch 0080, iter [01020, 01251], lr: 0.000071, loss: 0.3996
2022-10-04 12:57:51 - train: epoch 0080, iter [01030, 01251], lr: 0.000071, loss: 0.4094
2022-10-04 12:58:10 - train: epoch 0080, iter [01040, 01251], lr: 0.000071, loss: 0.4058
2022-10-04 12:58:29 - train: epoch 0080, iter [01050, 01251], lr: 0.000071, loss: 0.3896
2022-10-04 12:58:47 - train: epoch 0080, iter [01060, 01251], lr: 0.000071, loss: 0.4093
2022-10-04 12:59:06 - train: epoch 0080, iter [01070, 01251], lr: 0.000071, loss: 0.4225
2022-10-04 12:59:25 - train: epoch 0080, iter [01080, 01251], lr: 0.000071, loss: 0.3821
2022-10-04 12:59:43 - train: epoch 0080, iter [01090, 01251], lr: 0.000071, loss: 0.3989
2022-10-04 13:00:02 - train: epoch 0080, iter [01100, 01251], lr: 0.000071, loss: 0.3894
2022-10-04 13:00:21 - train: epoch 0080, iter [01110, 01251], lr: 0.000071, loss: 0.3924
2022-10-04 13:00:41 - train: epoch 0080, iter [01120, 01251], lr: 0.000071, loss: 0.3870
2022-10-04 13:01:00 - train: epoch 0080, iter [01130, 01251], lr: 0.000071, loss: 0.4201
2022-10-04 13:01:19 - train: epoch 0080, iter [01140, 01251], lr: 0.000071, loss: 0.3978
2022-10-04 13:01:38 - train: epoch 0080, iter [01150, 01251], lr: 0.000071, loss: 0.4246
2022-10-04 13:01:56 - train: epoch 0080, iter [01160, 01251], lr: 0.000071, loss: 0.4084
2022-10-04 13:02:15 - train: epoch 0080, iter [01170, 01251], lr: 0.000071, loss: 0.3990
2022-10-04 13:02:34 - train: epoch 0080, iter [01180, 01251], lr: 0.000071, loss: 0.4245
2022-10-04 13:02:53 - train: epoch 0080, iter [01190, 01251], lr: 0.000071, loss: 0.3817
2022-10-04 13:03:12 - train: epoch 0080, iter [01200, 01251], lr: 0.000070, loss: 0.3858
2022-10-04 13:03:30 - train: epoch 0080, iter [01210, 01251], lr: 0.000070, loss: 0.4119
2022-10-04 13:03:49 - train: epoch 0080, iter [01220, 01251], lr: 0.000070, loss: 0.4107
2022-10-04 13:04:09 - train: epoch 0080, iter [01230, 01251], lr: 0.000070, loss: 0.4059
2022-10-04 13:04:28 - train: epoch 0080, iter [01240, 01251], lr: 0.000070, loss: 0.4219
2022-10-04 13:04:46 - train: epoch 0080, iter [01250, 01251], lr: 0.000070, loss: 0.3863
2022-10-04 13:04:51 - train: epoch 080, train_loss: 0.4013
2022-10-04 13:04:55 - until epoch: 080, best_loss: 0.4013
2022-10-04 13:04:55 - epoch 081 lr: 0.000070
2022-10-04 13:05:20 - train: epoch 0081, iter [00010, 01251], lr: 0.000070, loss: 0.3986
2022-10-04 13:05:39 - train: epoch 0081, iter [00020, 01251], lr: 0.000070, loss: 0.4003
2022-10-04 13:05:58 - train: epoch 0081, iter [00030, 01251], lr: 0.000070, loss: 0.4006
2022-10-04 13:06:16 - train: epoch 0081, iter [00040, 01251], lr: 0.000070, loss: 0.4242
2022-10-04 13:06:35 - train: epoch 0081, iter [00050, 01251], lr: 0.000070, loss: 0.3898
2022-10-04 13:06:54 - train: epoch 0081, iter [00060, 01251], lr: 0.000070, loss: 0.3913
2022-10-04 13:07:12 - train: epoch 0081, iter [00070, 01251], lr: 0.000070, loss: 0.4002
2022-10-04 13:07:31 - train: epoch 0081, iter [00080, 01251], lr: 0.000070, loss: 0.4184
2022-10-04 13:07:51 - train: epoch 0081, iter [00090, 01251], lr: 0.000070, loss: 0.4019
2022-10-04 13:08:10 - train: epoch 0081, iter [00100, 01251], lr: 0.000070, loss: 0.4001
2022-10-04 13:08:29 - train: epoch 0081, iter [00110, 01251], lr: 0.000070, loss: 0.3986
2022-10-04 13:08:47 - train: epoch 0081, iter [00120, 01251], lr: 0.000070, loss: 0.3841
2022-10-04 13:09:06 - train: epoch 0081, iter [00130, 01251], lr: 0.000069, loss: 0.4204
2022-10-04 13:09:26 - train: epoch 0081, iter [00140, 01251], lr: 0.000069, loss: 0.4184
2022-10-04 13:09:44 - train: epoch 0081, iter [00150, 01251], lr: 0.000069, loss: 0.4001
2022-10-04 13:10:04 - train: epoch 0081, iter [00160, 01251], lr: 0.000069, loss: 0.4146
2022-10-04 13:10:23 - train: epoch 0081, iter [00170, 01251], lr: 0.000069, loss: 0.4015
2022-10-04 13:10:42 - train: epoch 0081, iter [00180, 01251], lr: 0.000069, loss: 0.3981
2022-10-04 13:11:00 - train: epoch 0081, iter [00190, 01251], lr: 0.000069, loss: 0.3995
2022-10-04 13:11:19 - train: epoch 0081, iter [00200, 01251], lr: 0.000069, loss: 0.4159
2022-10-04 13:11:38 - train: epoch 0081, iter [00210, 01251], lr: 0.000069, loss: 0.4055
2022-10-04 13:11:56 - train: epoch 0081, iter [00220, 01251], lr: 0.000069, loss: 0.4001
2022-10-04 13:12:15 - train: epoch 0081, iter [00230, 01251], lr: 0.000069, loss: 0.3986
2022-10-04 13:12:34 - train: epoch 0081, iter [00240, 01251], lr: 0.000069, loss: 0.4040
2022-10-04 13:12:53 - train: epoch 0081, iter [00250, 01251], lr: 0.000069, loss: 0.4036
2022-10-04 13:13:12 - train: epoch 0081, iter [00260, 01251], lr: 0.000069, loss: 0.4033
2022-10-04 13:13:31 - train: epoch 0081, iter [00270, 01251], lr: 0.000069, loss: 0.3969
2022-10-04 13:13:50 - train: epoch 0081, iter [00280, 01251], lr: 0.000069, loss: 0.4060
2022-10-04 13:14:08 - train: epoch 0081, iter [00290, 01251], lr: 0.000069, loss: 0.4169
2022-10-04 13:14:27 - train: epoch 0081, iter [00300, 01251], lr: 0.000069, loss: 0.4091
2022-10-04 13:14:46 - train: epoch 0081, iter [00310, 01251], lr: 0.000069, loss: 0.4024
2022-10-04 13:15:05 - train: epoch 0081, iter [00320, 01251], lr: 0.000068, loss: 0.3906
2022-10-04 13:15:24 - train: epoch 0081, iter [00330, 01251], lr: 0.000068, loss: 0.3900
2022-10-04 13:15:42 - train: epoch 0081, iter [00340, 01251], lr: 0.000068, loss: 0.3982
2022-10-04 13:16:01 - train: epoch 0081, iter [00350, 01251], lr: 0.000068, loss: 0.4080
2022-10-04 13:16:20 - train: epoch 0081, iter [00360, 01251], lr: 0.000068, loss: 0.3981
2022-10-04 13:16:39 - train: epoch 0081, iter [00370, 01251], lr: 0.000068, loss: 0.3923
2022-10-04 13:16:58 - train: epoch 0081, iter [00380, 01251], lr: 0.000068, loss: 0.3981
2022-10-04 13:17:17 - train: epoch 0081, iter [00390, 01251], lr: 0.000068, loss: 0.4235
2022-10-04 13:17:36 - train: epoch 0081, iter [00400, 01251], lr: 0.000068, loss: 0.3931
2022-10-04 13:17:55 - train: epoch 0081, iter [00410, 01251], lr: 0.000068, loss: 0.4037
2022-10-04 13:18:14 - train: epoch 0081, iter [00420, 01251], lr: 0.000068, loss: 0.4214
2022-10-04 13:18:33 - train: epoch 0081, iter [00430, 01251], lr: 0.000068, loss: 0.3734
2022-10-04 13:18:52 - train: epoch 0081, iter [00440, 01251], lr: 0.000068, loss: 0.4088
2022-10-04 13:19:11 - train: epoch 0081, iter [00450, 01251], lr: 0.000068, loss: 0.4151
2022-10-04 13:19:30 - train: epoch 0081, iter [00460, 01251], lr: 0.000068, loss: 0.3962
2022-10-04 13:19:49 - train: epoch 0081, iter [00470, 01251], lr: 0.000068, loss: 0.4112
2022-10-04 13:20:08 - train: epoch 0081, iter [00480, 01251], lr: 0.000068, loss: 0.3910
2022-10-04 13:20:27 - train: epoch 0081, iter [00490, 01251], lr: 0.000068, loss: 0.3976
2022-10-04 13:20:45 - train: epoch 0081, iter [00500, 01251], lr: 0.000068, loss: 0.3983
2022-10-04 13:21:04 - train: epoch 0081, iter [00510, 01251], lr: 0.000067, loss: 0.3991
2022-10-04 13:21:23 - train: epoch 0081, iter [00520, 01251], lr: 0.000067, loss: 0.4182
2022-10-04 13:21:42 - train: epoch 0081, iter [00530, 01251], lr: 0.000067, loss: 0.3940
2022-10-04 13:22:01 - train: epoch 0081, iter [00540, 01251], lr: 0.000067, loss: 0.4002
2022-10-04 13:22:20 - train: epoch 0081, iter [00550, 01251], lr: 0.000067, loss: 0.4149
2022-10-04 13:22:39 - train: epoch 0081, iter [00560, 01251], lr: 0.000067, loss: 0.4015
2022-10-04 13:22:58 - train: epoch 0081, iter [00570, 01251], lr: 0.000067, loss: 0.3822
2022-10-04 13:23:17 - train: epoch 0081, iter [00580, 01251], lr: 0.000067, loss: 0.3953
2022-10-04 13:23:36 - train: epoch 0081, iter [00590, 01251], lr: 0.000067, loss: 0.4016
2022-10-04 13:23:55 - train: epoch 0081, iter [00600, 01251], lr: 0.000067, loss: 0.3987
2022-10-04 13:24:14 - train: epoch 0081, iter [00610, 01251], lr: 0.000067, loss: 0.3894
2022-10-04 13:24:33 - train: epoch 0081, iter [00620, 01251], lr: 0.000067, loss: 0.3997
2022-10-04 13:24:52 - train: epoch 0081, iter [00630, 01251], lr: 0.000067, loss: 0.4068
2022-10-04 13:25:11 - train: epoch 0081, iter [00640, 01251], lr: 0.000067, loss: 0.3957
2022-10-04 13:25:30 - train: epoch 0081, iter [00650, 01251], lr: 0.000067, loss: 0.3920
2022-10-04 13:25:49 - train: epoch 0081, iter [00660, 01251], lr: 0.000067, loss: 0.4010
2022-10-04 13:26:07 - train: epoch 0081, iter [00670, 01251], lr: 0.000067, loss: 0.3915
2022-10-04 13:26:26 - train: epoch 0081, iter [00680, 01251], lr: 0.000067, loss: 0.4041
2022-10-04 13:26:45 - train: epoch 0081, iter [00690, 01251], lr: 0.000067, loss: 0.3982
2022-10-04 13:27:04 - train: epoch 0081, iter [00700, 01251], lr: 0.000066, loss: 0.4228
2022-10-04 13:27:23 - train: epoch 0081, iter [00710, 01251], lr: 0.000066, loss: 0.3972
2022-10-04 13:27:42 - train: epoch 0081, iter [00720, 01251], lr: 0.000066, loss: 0.3934
2022-10-04 13:28:01 - train: epoch 0081, iter [00730, 01251], lr: 0.000066, loss: 0.4058
2022-10-04 13:28:19 - train: epoch 0081, iter [00740, 01251], lr: 0.000066, loss: 0.4009
2022-10-04 13:28:38 - train: epoch 0081, iter [00750, 01251], lr: 0.000066, loss: 0.3852
2022-10-04 13:28:57 - train: epoch 0081, iter [00760, 01251], lr: 0.000066, loss: 0.3830
2022-10-04 13:29:16 - train: epoch 0081, iter [00770, 01251], lr: 0.000066, loss: 0.3925
2022-10-04 13:29:34 - train: epoch 0081, iter [00780, 01251], lr: 0.000066, loss: 0.4052
2022-10-04 13:29:54 - train: epoch 0081, iter [00790, 01251], lr: 0.000066, loss: 0.4202
2022-10-04 13:30:13 - train: epoch 0081, iter [00800, 01251], lr: 0.000066, loss: 0.4049
2022-10-04 13:30:31 - train: epoch 0081, iter [00810, 01251], lr: 0.000066, loss: 0.4086
2022-10-04 13:30:50 - train: epoch 0081, iter [00820, 01251], lr: 0.000066, loss: 0.3927
2022-10-04 13:31:09 - train: epoch 0081, iter [00830, 01251], lr: 0.000066, loss: 0.3699
2022-10-04 13:31:28 - train: epoch 0081, iter [00840, 01251], lr: 0.000066, loss: 0.3910
2022-10-04 13:31:47 - train: epoch 0081, iter [00850, 01251], lr: 0.000066, loss: 0.3964
2022-10-04 13:32:05 - train: epoch 0081, iter [00860, 01251], lr: 0.000066, loss: 0.3753
2022-10-04 13:32:24 - train: epoch 0081, iter [00870, 01251], lr: 0.000066, loss: 0.4059
2022-10-04 13:32:43 - train: epoch 0081, iter [00880, 01251], lr: 0.000066, loss: 0.3955
2022-10-04 13:33:02 - train: epoch 0081, iter [00890, 01251], lr: 0.000065, loss: 0.4039
2022-10-04 13:33:21 - train: epoch 0081, iter [00900, 01251], lr: 0.000065, loss: 0.3966
2022-10-04 13:33:40 - train: epoch 0081, iter [00910, 01251], lr: 0.000065, loss: 0.3954
2022-10-04 13:33:59 - train: epoch 0081, iter [00920, 01251], lr: 0.000065, loss: 0.4062
2022-10-04 13:34:18 - train: epoch 0081, iter [00930, 01251], lr: 0.000065, loss: 0.4073
2022-10-04 13:34:38 - train: epoch 0081, iter [00940, 01251], lr: 0.000065, loss: 0.3871
2022-10-04 13:34:56 - train: epoch 0081, iter [00950, 01251], lr: 0.000065, loss: 0.3984
2022-10-04 13:35:15 - train: epoch 0081, iter [00960, 01251], lr: 0.000065, loss: 0.4118
2022-10-04 13:35:34 - train: epoch 0081, iter [00970, 01251], lr: 0.000065, loss: 0.3867
2022-10-04 13:35:53 - train: epoch 0081, iter [00980, 01251], lr: 0.000065, loss: 0.3992
2022-10-04 13:36:12 - train: epoch 0081, iter [00990, 01251], lr: 0.000065, loss: 0.4141
2022-10-04 13:36:30 - train: epoch 0081, iter [01000, 01251], lr: 0.000065, loss: 0.4259
2022-10-04 13:36:49 - train: epoch 0081, iter [01010, 01251], lr: 0.000065, loss: 0.3933
2022-10-04 13:37:08 - train: epoch 0081, iter [01020, 01251], lr: 0.000065, loss: 0.3974
2022-10-04 13:37:27 - train: epoch 0081, iter [01030, 01251], lr: 0.000065, loss: 0.4006
2022-10-04 13:37:46 - train: epoch 0081, iter [01040, 01251], lr: 0.000065, loss: 0.3997
2022-10-04 13:38:06 - train: epoch 0081, iter [01050, 01251], lr: 0.000065, loss: 0.4046
2022-10-04 13:38:25 - train: epoch 0081, iter [01060, 01251], lr: 0.000065, loss: 0.4063
2022-10-04 13:38:43 - train: epoch 0081, iter [01070, 01251], lr: 0.000065, loss: 0.4175
2022-10-04 13:39:02 - train: epoch 0081, iter [01080, 01251], lr: 0.000064, loss: 0.3971
2022-10-04 13:39:21 - train: epoch 0081, iter [01090, 01251], lr: 0.000064, loss: 0.4045
2022-10-04 13:39:40 - train: epoch 0081, iter [01100, 01251], lr: 0.000064, loss: 0.3967
2022-10-04 13:39:59 - train: epoch 0081, iter [01110, 01251], lr: 0.000064, loss: 0.4110
2022-10-04 13:40:18 - train: epoch 0081, iter [01120, 01251], lr: 0.000064, loss: 0.3953
2022-10-04 13:40:37 - train: epoch 0081, iter [01130, 01251], lr: 0.000064, loss: 0.4007
2022-10-04 13:40:55 - train: epoch 0081, iter [01140, 01251], lr: 0.000064, loss: 0.4088
2022-10-04 13:41:14 - train: epoch 0081, iter [01150, 01251], lr: 0.000064, loss: 0.4003
2022-10-04 13:41:33 - train: epoch 0081, iter [01160, 01251], lr: 0.000064, loss: 0.3947
2022-10-04 13:41:52 - train: epoch 0081, iter [01170, 01251], lr: 0.000064, loss: 0.4173
2022-10-04 13:42:10 - train: epoch 0081, iter [01180, 01251], lr: 0.000064, loss: 0.4031
2022-10-04 13:42:29 - train: epoch 0081, iter [01190, 01251], lr: 0.000064, loss: 0.3802
2022-10-04 13:42:48 - train: epoch 0081, iter [01200, 01251], lr: 0.000064, loss: 0.3975
2022-10-04 13:43:08 - train: epoch 0081, iter [01210, 01251], lr: 0.000064, loss: 0.3757
2022-10-04 13:43:26 - train: epoch 0081, iter [01220, 01251], lr: 0.000064, loss: 0.4042
2022-10-04 13:43:45 - train: epoch 0081, iter [01230, 01251], lr: 0.000064, loss: 0.3931
2022-10-04 13:44:04 - train: epoch 0081, iter [01240, 01251], lr: 0.000064, loss: 0.4000
2022-10-04 13:44:22 - train: epoch 0081, iter [01250, 01251], lr: 0.000064, loss: 0.4075
2022-10-04 13:44:27 - train: epoch 081, train_loss: 0.4011
2022-10-04 13:44:31 - until epoch: 081, best_loss: 0.4011
2022-10-04 13:44:31 - epoch 082 lr: 0.000064
2022-10-04 13:44:56 - train: epoch 0082, iter [00010, 01251], lr: 0.000064, loss: 0.4215
2022-10-04 13:45:15 - train: epoch 0082, iter [00020, 01251], lr: 0.000063, loss: 0.4106
2022-10-04 13:45:34 - train: epoch 0082, iter [00030, 01251], lr: 0.000063, loss: 0.3935
2022-10-04 13:45:52 - train: epoch 0082, iter [00040, 01251], lr: 0.000063, loss: 0.3939
2022-10-04 13:46:11 - train: epoch 0082, iter [00050, 01251], lr: 0.000063, loss: 0.4060
2022-10-04 13:46:30 - train: epoch 0082, iter [00060, 01251], lr: 0.000063, loss: 0.4100
2022-10-04 13:46:48 - train: epoch 0082, iter [00070, 01251], lr: 0.000063, loss: 0.4204
2022-10-04 13:47:07 - train: epoch 0082, iter [00080, 01251], lr: 0.000063, loss: 0.4168
2022-10-04 13:47:26 - train: epoch 0082, iter [00090, 01251], lr: 0.000063, loss: 0.4040
2022-10-04 13:47:46 - train: epoch 0082, iter [00100, 01251], lr: 0.000063, loss: 0.4213
2022-10-04 13:48:04 - train: epoch 0082, iter [00110, 01251], lr: 0.000063, loss: 0.4043
2022-10-04 13:48:24 - train: epoch 0082, iter [00120, 01251], lr: 0.000063, loss: 0.4061
2022-10-04 13:48:42 - train: epoch 0082, iter [00130, 01251], lr: 0.000063, loss: 0.3978
2022-10-04 13:49:01 - train: epoch 0082, iter [00140, 01251], lr: 0.000063, loss: 0.3811
2022-10-04 13:49:20 - train: epoch 0082, iter [00150, 01251], lr: 0.000063, loss: 0.4030
2022-10-04 13:49:39 - train: epoch 0082, iter [00160, 01251], lr: 0.000063, loss: 0.4025
2022-10-04 13:49:57 - train: epoch 0082, iter [00170, 01251], lr: 0.000063, loss: 0.4219
2022-10-04 13:50:16 - train: epoch 0082, iter [00180, 01251], lr: 0.000063, loss: 0.4112
2022-10-04 13:50:35 - train: epoch 0082, iter [00190, 01251], lr: 0.000063, loss: 0.4010
2022-10-04 13:50:54 - train: epoch 0082, iter [00200, 01251], lr: 0.000063, loss: 0.4023
2022-10-04 13:51:13 - train: epoch 0082, iter [00210, 01251], lr: 0.000063, loss: 0.4159
2022-10-04 13:51:31 - train: epoch 0082, iter [00220, 01251], lr: 0.000062, loss: 0.4085
2022-10-04 13:51:50 - train: epoch 0082, iter [00230, 01251], lr: 0.000062, loss: 0.3880
2022-10-04 13:52:09 - train: epoch 0082, iter [00240, 01251], lr: 0.000062, loss: 0.3902
2022-10-04 13:52:28 - train: epoch 0082, iter [00250, 01251], lr: 0.000062, loss: 0.4026
2022-10-04 13:52:47 - train: epoch 0082, iter [00260, 01251], lr: 0.000062, loss: 0.4114
2022-10-04 13:53:06 - train: epoch 0082, iter [00270, 01251], lr: 0.000062, loss: 0.3878
2022-10-04 13:53:25 - train: epoch 0082, iter [00280, 01251], lr: 0.000062, loss: 0.3999
2022-10-04 13:53:44 - train: epoch 0082, iter [00290, 01251], lr: 0.000062, loss: 0.3925
2022-10-04 13:54:02 - train: epoch 0082, iter [00300, 01251], lr: 0.000062, loss: 0.4116
2022-10-04 13:54:21 - train: epoch 0082, iter [00310, 01251], lr: 0.000062, loss: 0.4153
2022-10-04 13:54:40 - train: epoch 0082, iter [00320, 01251], lr: 0.000062, loss: 0.4025
2022-10-04 13:54:59 - train: epoch 0082, iter [00330, 01251], lr: 0.000062, loss: 0.4278
2022-10-04 13:55:18 - train: epoch 0082, iter [00340, 01251], lr: 0.000062, loss: 0.4089
2022-10-04 13:55:37 - train: epoch 0082, iter [00350, 01251], lr: 0.000062, loss: 0.3960
2022-10-04 13:55:56 - train: epoch 0082, iter [00360, 01251], lr: 0.000062, loss: 0.4138
2022-10-04 13:56:15 - train: epoch 0082, iter [00370, 01251], lr: 0.000062, loss: 0.4028
2022-10-04 13:56:33 - train: epoch 0082, iter [00380, 01251], lr: 0.000062, loss: 0.3924
2022-10-04 13:56:52 - train: epoch 0082, iter [00390, 01251], lr: 0.000062, loss: 0.4208
2022-10-04 13:57:11 - train: epoch 0082, iter [00400, 01251], lr: 0.000062, loss: 0.3895
2022-10-04 13:57:30 - train: epoch 0082, iter [00410, 01251], lr: 0.000061, loss: 0.4012
2022-10-04 13:57:49 - train: epoch 0082, iter [00420, 01251], lr: 0.000061, loss: 0.3951
2022-10-04 13:58:08 - train: epoch 0082, iter [00430, 01251], lr: 0.000061, loss: 0.3731
2022-10-04 13:58:27 - train: epoch 0082, iter [00440, 01251], lr: 0.000061, loss: 0.4018
2022-10-04 13:58:46 - train: epoch 0082, iter [00450, 01251], lr: 0.000061, loss: 0.3900
2022-10-04 13:59:05 - train: epoch 0082, iter [00460, 01251], lr: 0.000061, loss: 0.4021
2022-10-04 13:59:24 - train: epoch 0082, iter [00470, 01251], lr: 0.000061, loss: 0.3929
2022-10-04 13:59:43 - train: epoch 0082, iter [00480, 01251], lr: 0.000061, loss: 0.4085
2022-10-04 14:00:02 - train: epoch 0082, iter [00490, 01251], lr: 0.000061, loss: 0.4036
2022-10-04 14:00:21 - train: epoch 0082, iter [00500, 01251], lr: 0.000061, loss: 0.3981
2022-10-04 14:00:40 - train: epoch 0082, iter [00510, 01251], lr: 0.000061, loss: 0.3753
2022-10-04 14:00:59 - train: epoch 0082, iter [00520, 01251], lr: 0.000061, loss: 0.4176
2022-10-04 14:01:17 - train: epoch 0082, iter [00530, 01251], lr: 0.000061, loss: 0.4168
2022-10-04 14:01:36 - train: epoch 0082, iter [00540, 01251], lr: 0.000061, loss: 0.3891
2022-10-04 14:01:55 - train: epoch 0082, iter [00550, 01251], lr: 0.000061, loss: 0.3911
2022-10-04 14:02:14 - train: epoch 0082, iter [00560, 01251], lr: 0.000061, loss: 0.3886
2022-10-04 14:02:33 - train: epoch 0082, iter [00570, 01251], lr: 0.000061, loss: 0.3990
2022-10-04 14:02:51 - train: epoch 0082, iter [00580, 01251], lr: 0.000061, loss: 0.3982
2022-10-04 14:03:10 - train: epoch 0082, iter [00590, 01251], lr: 0.000061, loss: 0.4005
2022-10-04 14:03:30 - train: epoch 0082, iter [00600, 01251], lr: 0.000061, loss: 0.3984
2022-10-04 14:03:49 - train: epoch 0082, iter [00610, 01251], lr: 0.000060, loss: 0.3954
2022-10-04 14:04:07 - train: epoch 0082, iter [00620, 01251], lr: 0.000060, loss: 0.3905
2022-10-04 14:04:26 - train: epoch 0082, iter [00630, 01251], lr: 0.000060, loss: 0.3919
2022-10-04 14:04:45 - train: epoch 0082, iter [00640, 01251], lr: 0.000060, loss: 0.4054
2022-10-04 14:05:03 - train: epoch 0082, iter [00650, 01251], lr: 0.000060, loss: 0.4079
2022-10-04 14:05:22 - train: epoch 0082, iter [00660, 01251], lr: 0.000060, loss: 0.4086
2022-10-04 14:05:41 - train: epoch 0082, iter [00670, 01251], lr: 0.000060, loss: 0.3889
2022-10-04 14:06:00 - train: epoch 0082, iter [00680, 01251], lr: 0.000060, loss: 0.4103
2022-10-04 14:06:19 - train: epoch 0082, iter [00690, 01251], lr: 0.000060, loss: 0.3903
2022-10-04 14:06:38 - train: epoch 0082, iter [00700, 01251], lr: 0.000060, loss: 0.4098
2022-10-04 14:06:57 - train: epoch 0082, iter [00710, 01251], lr: 0.000060, loss: 0.4123
2022-10-04 14:07:15 - train: epoch 0082, iter [00720, 01251], lr: 0.000060, loss: 0.4143
2022-10-04 14:07:34 - train: epoch 0082, iter [00730, 01251], lr: 0.000060, loss: 0.4334
2022-10-04 14:07:53 - train: epoch 0082, iter [00740, 01251], lr: 0.000060, loss: 0.4344
2022-10-04 14:08:12 - train: epoch 0082, iter [00750, 01251], lr: 0.000060, loss: 0.3938
2022-10-04 14:08:31 - train: epoch 0082, iter [00760, 01251], lr: 0.000060, loss: 0.3979
2022-10-04 14:08:50 - train: epoch 0082, iter [00770, 01251], lr: 0.000060, loss: 0.4091
2022-10-04 14:09:09 - train: epoch 0082, iter [00780, 01251], lr: 0.000060, loss: 0.3848
2022-10-04 14:09:27 - train: epoch 0082, iter [00790, 01251], lr: 0.000060, loss: 0.3952
2022-10-04 14:09:46 - train: epoch 0082, iter [00800, 01251], lr: 0.000060, loss: 0.3830
2022-10-04 14:10:05 - train: epoch 0082, iter [00810, 01251], lr: 0.000059, loss: 0.3958
2022-10-04 14:10:24 - train: epoch 0082, iter [00820, 01251], lr: 0.000059, loss: 0.4025
2022-10-04 14:10:42 - train: epoch 0082, iter [00830, 01251], lr: 0.000059, loss: 0.3901
2022-10-04 14:11:01 - train: epoch 0082, iter [00840, 01251], lr: 0.000059, loss: 0.3949
2022-10-04 14:11:20 - train: epoch 0082, iter [00850, 01251], lr: 0.000059, loss: 0.3938
2022-10-04 14:11:39 - train: epoch 0082, iter [00860, 01251], lr: 0.000059, loss: 0.3987
2022-10-04 14:11:58 - train: epoch 0082, iter [00870, 01251], lr: 0.000059, loss: 0.3819
2022-10-04 14:12:16 - train: epoch 0082, iter [00880, 01251], lr: 0.000059, loss: 0.4105
2022-10-04 14:12:35 - train: epoch 0082, iter [00890, 01251], lr: 0.000059, loss: 0.3940
2022-10-04 14:12:53 - train: epoch 0082, iter [00900, 01251], lr: 0.000059, loss: 0.4079
2022-10-04 14:13:12 - train: epoch 0082, iter [00910, 01251], lr: 0.000059, loss: 0.4048
2022-10-04 14:13:30 - train: epoch 0082, iter [00920, 01251], lr: 0.000059, loss: 0.3949
2022-10-04 14:13:49 - train: epoch 0082, iter [00930, 01251], lr: 0.000059, loss: 0.3912
2022-10-04 14:14:07 - train: epoch 0082, iter [00940, 01251], lr: 0.000059, loss: 0.4022
2022-10-04 14:14:26 - train: epoch 0082, iter [00950, 01251], lr: 0.000059, loss: 0.4218
2022-10-04 14:14:45 - train: epoch 0082, iter [00960, 01251], lr: 0.000059, loss: 0.3950
2022-10-04 14:15:04 - train: epoch 0082, iter [00970, 01251], lr: 0.000059, loss: 0.4050
2022-10-04 14:15:23 - train: epoch 0082, iter [00980, 01251], lr: 0.000059, loss: 0.3959
2022-10-04 14:15:42 - train: epoch 0082, iter [00990, 01251], lr: 0.000059, loss: 0.3855
2022-10-04 14:16:01 - train: epoch 0082, iter [01000, 01251], lr: 0.000059, loss: 0.4068
2022-10-04 14:16:19 - train: epoch 0082, iter [01010, 01251], lr: 0.000058, loss: 0.4037
2022-10-04 14:16:38 - train: epoch 0082, iter [01020, 01251], lr: 0.000058, loss: 0.3853
2022-10-04 14:16:57 - train: epoch 0082, iter [01030, 01251], lr: 0.000058, loss: 0.3984
2022-10-04 14:17:15 - train: epoch 0082, iter [01040, 01251], lr: 0.000058, loss: 0.4125
2022-10-04 14:17:34 - train: epoch 0082, iter [01050, 01251], lr: 0.000058, loss: 0.3996
2022-10-04 14:17:53 - train: epoch 0082, iter [01060, 01251], lr: 0.000058, loss: 0.3863
2022-10-04 14:18:11 - train: epoch 0082, iter [01070, 01251], lr: 0.000058, loss: 0.3926
2022-10-04 14:18:30 - train: epoch 0082, iter [01080, 01251], lr: 0.000058, loss: 0.4015
2022-10-04 14:18:49 - train: epoch 0082, iter [01090, 01251], lr: 0.000058, loss: 0.3864
2022-10-04 14:19:08 - train: epoch 0082, iter [01100, 01251], lr: 0.000058, loss: 0.4041
2022-10-04 14:19:26 - train: epoch 0082, iter [01110, 01251], lr: 0.000058, loss: 0.4174
2022-10-04 14:19:45 - train: epoch 0082, iter [01120, 01251], lr: 0.000058, loss: 0.3991
2022-10-04 14:20:04 - train: epoch 0082, iter [01130, 01251], lr: 0.000058, loss: 0.4123
2022-10-04 14:20:23 - train: epoch 0082, iter [01140, 01251], lr: 0.000058, loss: 0.3973
2022-10-04 14:20:41 - train: epoch 0082, iter [01150, 01251], lr: 0.000058, loss: 0.3952
2022-10-04 14:21:00 - train: epoch 0082, iter [01160, 01251], lr: 0.000058, loss: 0.3996
2022-10-04 14:21:19 - train: epoch 0082, iter [01170, 01251], lr: 0.000058, loss: 0.3900
2022-10-04 14:21:38 - train: epoch 0082, iter [01180, 01251], lr: 0.000058, loss: 0.3925
2022-10-04 14:21:56 - train: epoch 0082, iter [01190, 01251], lr: 0.000058, loss: 0.4151
2022-10-04 14:22:15 - train: epoch 0082, iter [01200, 01251], lr: 0.000058, loss: 0.3957
2022-10-04 14:22:34 - train: epoch 0082, iter [01210, 01251], lr: 0.000057, loss: 0.3727
2022-10-04 14:22:53 - train: epoch 0082, iter [01220, 01251], lr: 0.000057, loss: 0.4010
2022-10-04 14:23:12 - train: epoch 0082, iter [01230, 01251], lr: 0.000057, loss: 0.3997
2022-10-04 14:23:30 - train: epoch 0082, iter [01240, 01251], lr: 0.000057, loss: 0.3762
2022-10-04 14:23:49 - train: epoch 0082, iter [01250, 01251], lr: 0.000057, loss: 0.4042
2022-10-04 14:23:54 - train: epoch 082, train_loss: 0.4008
2022-10-04 14:23:57 - until epoch: 082, best_loss: 0.4008
2022-10-04 14:23:57 - epoch 083 lr: 0.000057
2022-10-04 14:24:22 - train: epoch 0083, iter [00010, 01251], lr: 0.000057, loss: 0.4029
2022-10-04 14:24:41 - train: epoch 0083, iter [00020, 01251], lr: 0.000057, loss: 0.4176
2022-10-04 14:25:00 - train: epoch 0083, iter [00030, 01251], lr: 0.000057, loss: 0.4009
2022-10-04 14:25:19 - train: epoch 0083, iter [00040, 01251], lr: 0.000057, loss: 0.4031
2022-10-04 14:25:37 - train: epoch 0083, iter [00050, 01251], lr: 0.000057, loss: 0.4016
2022-10-04 14:25:56 - train: epoch 0083, iter [00060, 01251], lr: 0.000057, loss: 0.3868
2022-10-04 14:26:15 - train: epoch 0083, iter [00070, 01251], lr: 0.000057, loss: 0.4148
2022-10-04 14:26:34 - train: epoch 0083, iter [00080, 01251], lr: 0.000057, loss: 0.3899
2022-10-04 14:26:52 - train: epoch 0083, iter [00090, 01251], lr: 0.000057, loss: 0.4047
2022-10-04 14:27:11 - train: epoch 0083, iter [00100, 01251], lr: 0.000057, loss: 0.4066
2022-10-04 14:27:29 - train: epoch 0083, iter [00110, 01251], lr: 0.000057, loss: 0.3906
2022-10-04 14:27:48 - train: epoch 0083, iter [00120, 01251], lr: 0.000057, loss: 0.4062
2022-10-04 14:28:06 - train: epoch 0083, iter [00130, 01251], lr: 0.000057, loss: 0.4143
2022-10-04 14:28:25 - train: epoch 0083, iter [00140, 01251], lr: 0.000057, loss: 0.3896
2022-10-04 14:28:44 - train: epoch 0083, iter [00150, 01251], lr: 0.000057, loss: 0.3994
2022-10-04 14:29:03 - train: epoch 0083, iter [00160, 01251], lr: 0.000057, loss: 0.4143
2022-10-04 14:29:21 - train: epoch 0083, iter [00170, 01251], lr: 0.000056, loss: 0.4010
2022-10-04 14:29:41 - train: epoch 0083, iter [00180, 01251], lr: 0.000056, loss: 0.4178
2022-10-04 14:30:00 - train: epoch 0083, iter [00190, 01251], lr: 0.000056, loss: 0.3941
2022-10-04 14:30:18 - train: epoch 0083, iter [00200, 01251], lr: 0.000056, loss: 0.3655
2022-10-04 14:30:37 - train: epoch 0083, iter [00210, 01251], lr: 0.000056, loss: 0.4199
2022-10-04 14:30:56 - train: epoch 0083, iter [00220, 01251], lr: 0.000056, loss: 0.3928
2022-10-04 14:31:16 - train: epoch 0083, iter [00230, 01251], lr: 0.000056, loss: 0.4053
2022-10-04 14:31:35 - train: epoch 0083, iter [00240, 01251], lr: 0.000056, loss: 0.3900
2022-10-04 14:31:54 - train: epoch 0083, iter [00250, 01251], lr: 0.000056, loss: 0.4004
2022-10-04 14:32:13 - train: epoch 0083, iter [00260, 01251], lr: 0.000056, loss: 0.4157
2022-10-04 14:32:32 - train: epoch 0083, iter [00270, 01251], lr: 0.000056, loss: 0.4131
2022-10-04 14:32:52 - train: epoch 0083, iter [00280, 01251], lr: 0.000056, loss: 0.4098
2022-10-04 14:33:11 - train: epoch 0083, iter [00290, 01251], lr: 0.000056, loss: 0.4012
2022-10-04 14:33:30 - train: epoch 0083, iter [00300, 01251], lr: 0.000056, loss: 0.3899
2022-10-04 14:33:49 - train: epoch 0083, iter [00310, 01251], lr: 0.000056, loss: 0.3848
2022-10-04 14:34:08 - train: epoch 0083, iter [00320, 01251], lr: 0.000056, loss: 0.3933
2022-10-04 14:34:27 - train: epoch 0083, iter [00330, 01251], lr: 0.000056, loss: 0.3957
2022-10-04 14:34:46 - train: epoch 0083, iter [00340, 01251], lr: 0.000056, loss: 0.4047
2022-10-04 14:35:06 - train: epoch 0083, iter [00350, 01251], lr: 0.000056, loss: 0.3978
2022-10-04 14:35:25 - train: epoch 0083, iter [00360, 01251], lr: 0.000056, loss: 0.4055
2022-10-04 14:35:44 - train: epoch 0083, iter [00370, 01251], lr: 0.000055, loss: 0.4190
2022-10-04 14:36:03 - train: epoch 0083, iter [00380, 01251], lr: 0.000055, loss: 0.3932
2022-10-04 14:36:22 - train: epoch 0083, iter [00390, 01251], lr: 0.000055, loss: 0.4082
2022-10-04 14:36:41 - train: epoch 0083, iter [00400, 01251], lr: 0.000055, loss: 0.4152
2022-10-04 14:37:01 - train: epoch 0083, iter [00410, 01251], lr: 0.000055, loss: 0.3952
2022-10-04 14:37:19 - train: epoch 0083, iter [00420, 01251], lr: 0.000055, loss: 0.3804
2022-10-04 14:37:38 - train: epoch 0083, iter [00430, 01251], lr: 0.000055, loss: 0.4199
2022-10-04 14:37:57 - train: epoch 0083, iter [00440, 01251], lr: 0.000055, loss: 0.3869
2022-10-04 14:38:16 - train: epoch 0083, iter [00450, 01251], lr: 0.000055, loss: 0.3935
2022-10-04 14:38:35 - train: epoch 0083, iter [00460, 01251], lr: 0.000055, loss: 0.3827
2022-10-04 14:38:54 - train: epoch 0083, iter [00470, 01251], lr: 0.000055, loss: 0.4164
2022-10-04 14:39:14 - train: epoch 0083, iter [00480, 01251], lr: 0.000055, loss: 0.4081
2022-10-04 14:39:33 - train: epoch 0083, iter [00490, 01251], lr: 0.000055, loss: 0.4038
2022-10-04 14:39:51 - train: epoch 0083, iter [00500, 01251], lr: 0.000055, loss: 0.3981
2022-10-04 14:40:10 - train: epoch 0083, iter [00510, 01251], lr: 0.000055, loss: 0.3933
2022-10-04 14:40:29 - train: epoch 0083, iter [00520, 01251], lr: 0.000055, loss: 0.3952
2022-10-04 14:40:47 - train: epoch 0083, iter [00530, 01251], lr: 0.000055, loss: 0.4161
2022-10-04 14:41:06 - train: epoch 0083, iter [00540, 01251], lr: 0.000055, loss: 0.4171
2022-10-04 14:41:25 - train: epoch 0083, iter [00550, 01251], lr: 0.000055, loss: 0.3973
2022-10-04 14:41:44 - train: epoch 0083, iter [00560, 01251], lr: 0.000055, loss: 0.4014
2022-10-04 14:42:03 - train: epoch 0083, iter [00570, 01251], lr: 0.000055, loss: 0.3926
2022-10-04 14:42:22 - train: epoch 0083, iter [00580, 01251], lr: 0.000054, loss: 0.4132
2022-10-04 14:42:41 - train: epoch 0083, iter [00590, 01251], lr: 0.000054, loss: 0.4035
2022-10-04 14:43:00 - train: epoch 0083, iter [00600, 01251], lr: 0.000054, loss: 0.4118
2022-10-04 14:43:19 - train: epoch 0083, iter [00610, 01251], lr: 0.000054, loss: 0.3934
2022-10-04 14:43:38 - train: epoch 0083, iter [00620, 01251], lr: 0.000054, loss: 0.4167
2022-10-04 14:43:57 - train: epoch 0083, iter [00630, 01251], lr: 0.000054, loss: 0.3915
2022-10-04 14:44:16 - train: epoch 0083, iter [00640, 01251], lr: 0.000054, loss: 0.4312
2022-10-04 14:44:35 - train: epoch 0083, iter [00650, 01251], lr: 0.000054, loss: 0.3946
2022-10-04 14:44:54 - train: epoch 0083, iter [00660, 01251], lr: 0.000054, loss: 0.3959
2022-10-04 14:45:13 - train: epoch 0083, iter [00670, 01251], lr: 0.000054, loss: 0.4179
2022-10-04 14:45:32 - train: epoch 0083, iter [00680, 01251], lr: 0.000054, loss: 0.4084
2022-10-04 14:45:51 - train: epoch 0083, iter [00690, 01251], lr: 0.000054, loss: 0.4137
2022-10-04 14:46:11 - train: epoch 0083, iter [00700, 01251], lr: 0.000054, loss: 0.3926
2022-10-04 14:46:29 - train: epoch 0083, iter [00710, 01251], lr: 0.000054, loss: 0.4106
2022-10-04 14:46:48 - train: epoch 0083, iter [00720, 01251], lr: 0.000054, loss: 0.4197
2022-10-04 14:47:07 - train: epoch 0083, iter [00730, 01251], lr: 0.000054, loss: 0.3902
2022-10-04 14:47:26 - train: epoch 0083, iter [00740, 01251], lr: 0.000054, loss: 0.3986
2022-10-04 14:47:45 - train: epoch 0083, iter [00750, 01251], lr: 0.000054, loss: 0.3751
2022-10-04 14:48:03 - train: epoch 0083, iter [00760, 01251], lr: 0.000054, loss: 0.4092
2022-10-04 14:48:22 - train: epoch 0083, iter [00770, 01251], lr: 0.000054, loss: 0.3920
2022-10-04 14:48:41 - train: epoch 0083, iter [00780, 01251], lr: 0.000054, loss: 0.4161
2022-10-04 14:49:00 - train: epoch 0083, iter [00790, 01251], lr: 0.000053, loss: 0.4126
2022-10-04 14:49:19 - train: epoch 0083, iter [00800, 01251], lr: 0.000053, loss: 0.4043
2022-10-04 14:49:39 - train: epoch 0083, iter [00810, 01251], lr: 0.000053, loss: 0.3939
2022-10-04 14:49:58 - train: epoch 0083, iter [00820, 01251], lr: 0.000053, loss: 0.4031
2022-10-04 14:50:17 - train: epoch 0083, iter [00830, 01251], lr: 0.000053, loss: 0.4023
2022-10-04 14:50:36 - train: epoch 0083, iter [00840, 01251], lr: 0.000053, loss: 0.4209
2022-10-04 14:50:56 - train: epoch 0083, iter [00850, 01251], lr: 0.000053, loss: 0.4279
2022-10-04 14:51:15 - train: epoch 0083, iter [00860, 01251], lr: 0.000053, loss: 0.4055
2022-10-04 14:51:34 - train: epoch 0083, iter [00870, 01251], lr: 0.000053, loss: 0.3832
2022-10-04 14:51:53 - train: epoch 0083, iter [00880, 01251], lr: 0.000053, loss: 0.3941
2022-10-04 14:52:11 - train: epoch 0083, iter [00890, 01251], lr: 0.000053, loss: 0.4000
2022-10-04 14:52:31 - train: epoch 0083, iter [00900, 01251], lr: 0.000053, loss: 0.3854
2022-10-04 14:52:50 - train: epoch 0083, iter [00910, 01251], lr: 0.000053, loss: 0.3950
2022-10-04 14:53:09 - train: epoch 0083, iter [00920, 01251], lr: 0.000053, loss: 0.4089
2022-10-04 14:53:28 - train: epoch 0083, iter [00930, 01251], lr: 0.000053, loss: 0.4251
2022-10-04 14:53:47 - train: epoch 0083, iter [00940, 01251], lr: 0.000053, loss: 0.4057
2022-10-04 14:54:05 - train: epoch 0083, iter [00950, 01251], lr: 0.000053, loss: 0.4161
2022-10-04 14:54:25 - train: epoch 0083, iter [00960, 01251], lr: 0.000053, loss: 0.3974
2022-10-04 14:54:44 - train: epoch 0083, iter [00970, 01251], lr: 0.000053, loss: 0.3782
2022-10-04 14:55:02 - train: epoch 0083, iter [00980, 01251], lr: 0.000053, loss: 0.3926
2022-10-04 14:55:21 - train: epoch 0083, iter [00990, 01251], lr: 0.000053, loss: 0.3971
2022-10-04 14:55:41 - train: epoch 0083, iter [01000, 01251], lr: 0.000052, loss: 0.4021
2022-10-04 14:56:00 - train: epoch 0083, iter [01010, 01251], lr: 0.000052, loss: 0.4001
2022-10-04 14:56:19 - train: epoch 0083, iter [01020, 01251], lr: 0.000052, loss: 0.3906
2022-10-04 14:56:38 - train: epoch 0083, iter [01030, 01251], lr: 0.000052, loss: 0.4140
2022-10-04 14:56:57 - train: epoch 0083, iter [01040, 01251], lr: 0.000052, loss: 0.3916
2022-10-04 14:57:16 - train: epoch 0083, iter [01050, 01251], lr: 0.000052, loss: 0.4139
2022-10-04 14:57:34 - train: epoch 0083, iter [01060, 01251], lr: 0.000052, loss: 0.3952
2022-10-04 14:57:54 - train: epoch 0083, iter [01070, 01251], lr: 0.000052, loss: 0.3945
2022-10-04 14:58:12 - train: epoch 0083, iter [01080, 01251], lr: 0.000052, loss: 0.3695
2022-10-04 14:58:31 - train: epoch 0083, iter [01090, 01251], lr: 0.000052, loss: 0.3808
2022-10-04 14:58:50 - train: epoch 0083, iter [01100, 01251], lr: 0.000052, loss: 0.4018
2022-10-04 14:59:10 - train: epoch 0083, iter [01110, 01251], lr: 0.000052, loss: 0.4038
2022-10-04 14:59:29 - train: epoch 0083, iter [01120, 01251], lr: 0.000052, loss: 0.4077
2022-10-04 14:59:48 - train: epoch 0083, iter [01130, 01251], lr: 0.000052, loss: 0.3910
2022-10-04 15:00:07 - train: epoch 0083, iter [01140, 01251], lr: 0.000052, loss: 0.4106
2022-10-04 15:00:26 - train: epoch 0083, iter [01150, 01251], lr: 0.000052, loss: 0.3978
2022-10-04 15:00:45 - train: epoch 0083, iter [01160, 01251], lr: 0.000052, loss: 0.3979
2022-10-04 15:01:04 - train: epoch 0083, iter [01170, 01251], lr: 0.000052, loss: 0.3863
2022-10-04 15:01:23 - train: epoch 0083, iter [01180, 01251], lr: 0.000052, loss: 0.3940
2022-10-04 15:01:42 - train: epoch 0083, iter [01190, 01251], lr: 0.000052, loss: 0.3953
2022-10-04 15:02:01 - train: epoch 0083, iter [01200, 01251], lr: 0.000052, loss: 0.3960
2022-10-04 15:02:20 - train: epoch 0083, iter [01210, 01251], lr: 0.000051, loss: 0.4161
2022-10-04 15:02:39 - train: epoch 0083, iter [01220, 01251], lr: 0.000051, loss: 0.3984
2022-10-04 15:02:58 - train: epoch 0083, iter [01230, 01251], lr: 0.000051, loss: 0.3996
2022-10-04 15:03:17 - train: epoch 0083, iter [01240, 01251], lr: 0.000051, loss: 0.3965
2022-10-04 15:03:35 - train: epoch 0083, iter [01250, 01251], lr: 0.000051, loss: 0.4010
2022-10-04 15:03:40 - train: epoch 083, train_loss: 0.4006
2022-10-04 15:03:44 - until epoch: 083, best_loss: 0.4006
2022-10-04 15:03:44 - epoch 084 lr: 0.000051
2022-10-04 15:04:09 - train: epoch 0084, iter [00010, 01251], lr: 0.000051, loss: 0.3827
2022-10-04 15:04:28 - train: epoch 0084, iter [00020, 01251], lr: 0.000051, loss: 0.4155
2022-10-04 15:04:47 - train: epoch 0084, iter [00030, 01251], lr: 0.000051, loss: 0.4079
2022-10-04 15:05:07 - train: epoch 0084, iter [00040, 01251], lr: 0.000051, loss: 0.3949
2022-10-04 15:05:26 - train: epoch 0084, iter [00050, 01251], lr: 0.000051, loss: 0.4079
2022-10-04 15:05:45 - train: epoch 0084, iter [00060, 01251], lr: 0.000051, loss: 0.3881
2022-10-04 15:06:04 - train: epoch 0084, iter [00070, 01251], lr: 0.000051, loss: 0.4169
2022-10-04 15:06:23 - train: epoch 0084, iter [00080, 01251], lr: 0.000051, loss: 0.4114
2022-10-04 15:06:42 - train: epoch 0084, iter [00090, 01251], lr: 0.000051, loss: 0.3915
2022-10-04 15:07:01 - train: epoch 0084, iter [00100, 01251], lr: 0.000051, loss: 0.4094
2022-10-04 15:07:20 - train: epoch 0084, iter [00110, 01251], lr: 0.000051, loss: 0.4115
2022-10-04 15:07:39 - train: epoch 0084, iter [00120, 01251], lr: 0.000051, loss: 0.4061
2022-10-04 15:07:58 - train: epoch 0084, iter [00130, 01251], lr: 0.000051, loss: 0.3952
2022-10-04 15:08:17 - train: epoch 0084, iter [00140, 01251], lr: 0.000051, loss: 0.3966
2022-10-04 15:08:36 - train: epoch 0084, iter [00150, 01251], lr: 0.000051, loss: 0.3847
2022-10-04 15:08:55 - train: epoch 0084, iter [00160, 01251], lr: 0.000051, loss: 0.4130
2022-10-04 15:09:14 - train: epoch 0084, iter [00170, 01251], lr: 0.000050, loss: 0.3983
2022-10-04 15:09:34 - train: epoch 0084, iter [00180, 01251], lr: 0.000050, loss: 0.4058
2022-10-04 15:09:53 - train: epoch 0084, iter [00190, 01251], lr: 0.000050, loss: 0.4050
2022-10-04 15:10:12 - train: epoch 0084, iter [00200, 01251], lr: 0.000050, loss: 0.4009
2022-10-04 15:10:31 - train: epoch 0084, iter [00210, 01251], lr: 0.000050, loss: 0.4245
2022-10-04 15:10:50 - train: epoch 0084, iter [00220, 01251], lr: 0.000050, loss: 0.4030
2022-10-04 15:11:09 - train: epoch 0084, iter [00230, 01251], lr: 0.000050, loss: 0.3936
2022-10-04 15:11:28 - train: epoch 0084, iter [00240, 01251], lr: 0.000050, loss: 0.3891
2022-10-04 15:11:47 - train: epoch 0084, iter [00250, 01251], lr: 0.000050, loss: 0.4048
2022-10-04 15:12:06 - train: epoch 0084, iter [00260, 01251], lr: 0.000050, loss: 0.3869
2022-10-04 15:12:25 - train: epoch 0084, iter [00270, 01251], lr: 0.000050, loss: 0.3998
2022-10-04 15:12:44 - train: epoch 0084, iter [00280, 01251], lr: 0.000050, loss: 0.4062
2022-10-04 15:13:03 - train: epoch 0084, iter [00290, 01251], lr: 0.000050, loss: 0.4119
2022-10-04 15:13:22 - train: epoch 0084, iter [00300, 01251], lr: 0.000050, loss: 0.4065
2022-10-04 15:13:41 - train: epoch 0084, iter [00310, 01251], lr: 0.000050, loss: 0.4129
2022-10-04 15:14:00 - train: epoch 0084, iter [00320, 01251], lr: 0.000050, loss: 0.4052
2022-10-04 15:14:19 - train: epoch 0084, iter [00330, 01251], lr: 0.000050, loss: 0.4022
2022-10-04 15:14:39 - train: epoch 0084, iter [00340, 01251], lr: 0.000050, loss: 0.4100
2022-10-04 15:14:58 - train: epoch 0084, iter [00350, 01251], lr: 0.000050, loss: 0.4105
2022-10-04 15:15:17 - train: epoch 0084, iter [00360, 01251], lr: 0.000050, loss: 0.3818
2022-10-04 15:15:36 - train: epoch 0084, iter [00370, 01251], lr: 0.000050, loss: 0.3954
2022-10-04 15:15:55 - train: epoch 0084, iter [00380, 01251], lr: 0.000050, loss: 0.4146
2022-10-04 15:16:14 - train: epoch 0084, iter [00390, 01251], lr: 0.000049, loss: 0.4030
2022-10-04 15:16:33 - train: epoch 0084, iter [00400, 01251], lr: 0.000049, loss: 0.3940
2022-10-04 15:16:52 - train: epoch 0084, iter [00410, 01251], lr: 0.000049, loss: 0.4151
2022-10-04 15:17:11 - train: epoch 0084, iter [00420, 01251], lr: 0.000049, loss: 0.3954
2022-10-04 15:17:30 - train: epoch 0084, iter [00430, 01251], lr: 0.000049, loss: 0.3853
2022-10-04 15:17:49 - train: epoch 0084, iter [00440, 01251], lr: 0.000049, loss: 0.3903
2022-10-04 15:18:08 - train: epoch 0084, iter [00450, 01251], lr: 0.000049, loss: 0.3906
2022-10-04 15:18:26 - train: epoch 0084, iter [00460, 01251], lr: 0.000049, loss: 0.4094
2022-10-04 15:18:46 - train: epoch 0084, iter [00470, 01251], lr: 0.000049, loss: 0.4103
2022-10-04 15:19:05 - train: epoch 0084, iter [00480, 01251], lr: 0.000049, loss: 0.3910
2022-10-04 15:19:24 - train: epoch 0084, iter [00490, 01251], lr: 0.000049, loss: 0.3924
2022-10-04 15:19:43 - train: epoch 0084, iter [00500, 01251], lr: 0.000049, loss: 0.3954
2022-10-04 15:20:02 - train: epoch 0084, iter [00510, 01251], lr: 0.000049, loss: 0.3848
2022-10-04 15:20:21 - train: epoch 0084, iter [00520, 01251], lr: 0.000049, loss: 0.3941
2022-10-04 15:20:41 - train: epoch 0084, iter [00530, 01251], lr: 0.000049, loss: 0.4217
2022-10-04 15:21:00 - train: epoch 0084, iter [00540, 01251], lr: 0.000049, loss: 0.4000
2022-10-04 15:21:19 - train: epoch 0084, iter [00550, 01251], lr: 0.000049, loss: 0.3745
2022-10-04 15:21:38 - train: epoch 0084, iter [00560, 01251], lr: 0.000049, loss: 0.3936
2022-10-04 15:21:57 - train: epoch 0084, iter [00570, 01251], lr: 0.000049, loss: 0.4065
2022-10-04 15:22:16 - train: epoch 0084, iter [00580, 01251], lr: 0.000049, loss: 0.4093
2022-10-04 15:22:35 - train: epoch 0084, iter [00590, 01251], lr: 0.000049, loss: 0.4073
2022-10-04 15:22:53 - train: epoch 0084, iter [00600, 01251], lr: 0.000049, loss: 0.3799
2022-10-04 15:23:12 - train: epoch 0084, iter [00610, 01251], lr: 0.000048, loss: 0.4077
2022-10-04 15:23:31 - train: epoch 0084, iter [00620, 01251], lr: 0.000048, loss: 0.4162
2022-10-04 15:23:50 - train: epoch 0084, iter [00630, 01251], lr: 0.000048, loss: 0.4116
2022-10-04 15:24:09 - train: epoch 0084, iter [00640, 01251], lr: 0.000048, loss: 0.4032
2022-10-04 15:24:28 - train: epoch 0084, iter [00650, 01251], lr: 0.000048, loss: 0.3777
2022-10-04 15:24:48 - train: epoch 0084, iter [00660, 01251], lr: 0.000048, loss: 0.3950
2022-10-04 15:25:07 - train: epoch 0084, iter [00670, 01251], lr: 0.000048, loss: 0.4082
2022-10-04 15:25:26 - train: epoch 0084, iter [00680, 01251], lr: 0.000048, loss: 0.4223
2022-10-04 15:25:45 - train: epoch 0084, iter [00690, 01251], lr: 0.000048, loss: 0.3933
2022-10-04 15:26:04 - train: epoch 0084, iter [00700, 01251], lr: 0.000048, loss: 0.4026
2022-10-04 15:26:23 - train: epoch 0084, iter [00710, 01251], lr: 0.000048, loss: 0.4068
2022-10-04 15:26:41 - train: epoch 0084, iter [00720, 01251], lr: 0.000048, loss: 0.3906
2022-10-04 15:27:00 - train: epoch 0084, iter [00730, 01251], lr: 0.000048, loss: 0.4255
2022-10-04 15:27:20 - train: epoch 0084, iter [00740, 01251], lr: 0.000048, loss: 0.3843
2022-10-04 15:27:38 - train: epoch 0084, iter [00750, 01251], lr: 0.000048, loss: 0.3952
2022-10-04 15:27:57 - train: epoch 0084, iter [00760, 01251], lr: 0.000048, loss: 0.3987
2022-10-04 15:28:16 - train: epoch 0084, iter [00770, 01251], lr: 0.000048, loss: 0.4105
2022-10-04 15:28:35 - train: epoch 0084, iter [00780, 01251], lr: 0.000048, loss: 0.4134
2022-10-04 15:28:54 - train: epoch 0084, iter [00790, 01251], lr: 0.000048, loss: 0.3976
2022-10-04 15:29:13 - train: epoch 0084, iter [00800, 01251], lr: 0.000048, loss: 0.4006
2022-10-04 15:29:32 - train: epoch 0084, iter [00810, 01251], lr: 0.000048, loss: 0.3999
2022-10-04 15:29:51 - train: epoch 0084, iter [00820, 01251], lr: 0.000048, loss: 0.4173
2022-10-04 15:30:10 - train: epoch 0084, iter [00830, 01251], lr: 0.000047, loss: 0.3938
2022-10-04 15:30:29 - train: epoch 0084, iter [00840, 01251], lr: 0.000047, loss: 0.3761
2022-10-04 15:30:47 - train: epoch 0084, iter [00850, 01251], lr: 0.000047, loss: 0.3985
2022-10-04 15:31:07 - train: epoch 0084, iter [00860, 01251], lr: 0.000047, loss: 0.3875
2022-10-04 15:31:25 - train: epoch 0084, iter [00870, 01251], lr: 0.000047, loss: 0.3839
2022-10-04 15:31:44 - train: epoch 0084, iter [00880, 01251], lr: 0.000047, loss: 0.4070
2022-10-04 15:32:03 - train: epoch 0084, iter [00890, 01251], lr: 0.000047, loss: 0.3871
2022-10-04 15:32:22 - train: epoch 0084, iter [00900, 01251], lr: 0.000047, loss: 0.3833
2022-10-04 15:32:41 - train: epoch 0084, iter [00910, 01251], lr: 0.000047, loss: 0.4161
2022-10-04 15:33:00 - train: epoch 0084, iter [00920, 01251], lr: 0.000047, loss: 0.4052
2022-10-04 15:33:19 - train: epoch 0084, iter [00930, 01251], lr: 0.000047, loss: 0.4029
2022-10-04 15:33:38 - train: epoch 0084, iter [00940, 01251], lr: 0.000047, loss: 0.3930
2022-10-04 15:33:57 - train: epoch 0084, iter [00950, 01251], lr: 0.000047, loss: 0.4018
2022-10-04 15:34:17 - train: epoch 0084, iter [00960, 01251], lr: 0.000047, loss: 0.4180
2022-10-04 15:34:36 - train: epoch 0084, iter [00970, 01251], lr: 0.000047, loss: 0.4013
2022-10-04 15:34:55 - train: epoch 0084, iter [00980, 01251], lr: 0.000047, loss: 0.4060
2022-10-04 15:35:14 - train: epoch 0084, iter [00990, 01251], lr: 0.000047, loss: 0.3981
2022-10-04 15:35:33 - train: epoch 0084, iter [01000, 01251], lr: 0.000047, loss: 0.3886
2022-10-04 15:35:52 - train: epoch 0084, iter [01010, 01251], lr: 0.000047, loss: 0.4124
2022-10-04 15:36:11 - train: epoch 0084, iter [01020, 01251], lr: 0.000047, loss: 0.3892
2022-10-04 15:36:30 - train: epoch 0084, iter [01030, 01251], lr: 0.000047, loss: 0.3747
2022-10-04 15:36:49 - train: epoch 0084, iter [01040, 01251], lr: 0.000047, loss: 0.3900
2022-10-04 15:37:08 - train: epoch 0084, iter [01050, 01251], lr: 0.000046, loss: 0.3888
2022-10-04 15:37:26 - train: epoch 0084, iter [01060, 01251], lr: 0.000046, loss: 0.4060
2022-10-04 15:37:45 - train: epoch 0084, iter [01070, 01251], lr: 0.000046, loss: 0.3975
2022-10-04 15:38:04 - train: epoch 0084, iter [01080, 01251], lr: 0.000046, loss: 0.4070
2022-10-04 15:38:22 - train: epoch 0084, iter [01090, 01251], lr: 0.000046, loss: 0.3863
2022-10-04 15:38:42 - train: epoch 0084, iter [01100, 01251], lr: 0.000046, loss: 0.4022
2022-10-04 15:39:00 - train: epoch 0084, iter [01110, 01251], lr: 0.000046, loss: 0.3867
2022-10-04 15:39:19 - train: epoch 0084, iter [01120, 01251], lr: 0.000046, loss: 0.4114
2022-10-04 15:39:38 - train: epoch 0084, iter [01130, 01251], lr: 0.000046, loss: 0.3929
2022-10-04 15:39:57 - train: epoch 0084, iter [01140, 01251], lr: 0.000046, loss: 0.3983
2022-10-04 15:40:16 - train: epoch 0084, iter [01150, 01251], lr: 0.000046, loss: 0.4091
2022-10-04 15:40:35 - train: epoch 0084, iter [01160, 01251], lr: 0.000046, loss: 0.3926
2022-10-04 15:40:53 - train: epoch 0084, iter [01170, 01251], lr: 0.000046, loss: 0.3851
2022-10-04 15:41:12 - train: epoch 0084, iter [01180, 01251], lr: 0.000046, loss: 0.3926
2022-10-04 15:41:31 - train: epoch 0084, iter [01190, 01251], lr: 0.000046, loss: 0.4068
2022-10-04 15:41:49 - train: epoch 0084, iter [01200, 01251], lr: 0.000046, loss: 0.4118
2022-10-04 15:42:09 - train: epoch 0084, iter [01210, 01251], lr: 0.000046, loss: 0.3965
2022-10-04 15:42:28 - train: epoch 0084, iter [01220, 01251], lr: 0.000046, loss: 0.4127
2022-10-04 15:42:46 - train: epoch 0084, iter [01230, 01251], lr: 0.000046, loss: 0.3900
2022-10-04 15:43:05 - train: epoch 0084, iter [01240, 01251], lr: 0.000046, loss: 0.4051
2022-10-04 15:43:23 - train: epoch 0084, iter [01250, 01251], lr: 0.000046, loss: 0.3833
2022-10-04 15:43:28 - train: epoch 084, train_loss: 0.4004
2022-10-04 15:43:33 - until epoch: 084, best_loss: 0.4004
2022-10-04 15:43:33 - epoch 085 lr: 0.000046
2022-10-04 15:43:57 - train: epoch 0085, iter [00010, 01251], lr: 0.000046, loss: 0.3978
2022-10-04 15:44:15 - train: epoch 0085, iter [00020, 01251], lr: 0.000045, loss: 0.4122
2022-10-04 15:44:34 - train: epoch 0085, iter [00030, 01251], lr: 0.000045, loss: 0.3983
2022-10-04 15:44:53 - train: epoch 0085, iter [00040, 01251], lr: 0.000045, loss: 0.3944
2022-10-04 15:45:11 - train: epoch 0085, iter [00050, 01251], lr: 0.000045, loss: 0.4076
2022-10-04 15:45:30 - train: epoch 0085, iter [00060, 01251], lr: 0.000045, loss: 0.3912
2022-10-04 15:45:49 - train: epoch 0085, iter [00070, 01251], lr: 0.000045, loss: 0.3897
2022-10-04 15:46:08 - train: epoch 0085, iter [00080, 01251], lr: 0.000045, loss: 0.3945
2022-10-04 15:46:26 - train: epoch 0085, iter [00090, 01251], lr: 0.000045, loss: 0.3995
2022-10-04 15:46:45 - train: epoch 0085, iter [00100, 01251], lr: 0.000045, loss: 0.3983
2022-10-04 15:47:04 - train: epoch 0085, iter [00110, 01251], lr: 0.000045, loss: 0.4053
2022-10-04 15:47:23 - train: epoch 0085, iter [00120, 01251], lr: 0.000045, loss: 0.3974
2022-10-04 15:47:42 - train: epoch 0085, iter [00130, 01251], lr: 0.000045, loss: 0.3887
2022-10-04 15:48:01 - train: epoch 0085, iter [00140, 01251], lr: 0.000045, loss: 0.3982
2022-10-04 15:48:19 - train: epoch 0085, iter [00150, 01251], lr: 0.000045, loss: 0.3979
2022-10-04 15:48:38 - train: epoch 0085, iter [00160, 01251], lr: 0.000045, loss: 0.4212
2022-10-04 15:48:56 - train: epoch 0085, iter [00170, 01251], lr: 0.000045, loss: 0.4056
2022-10-04 15:49:15 - train: epoch 0085, iter [00180, 01251], lr: 0.000045, loss: 0.3945
2022-10-04 15:49:33 - train: epoch 0085, iter [00190, 01251], lr: 0.000045, loss: 0.3958
2022-10-04 15:49:52 - train: epoch 0085, iter [00200, 01251], lr: 0.000045, loss: 0.4197
2022-10-04 15:50:11 - train: epoch 0085, iter [00210, 01251], lr: 0.000045, loss: 0.4221
2022-10-04 15:50:30 - train: epoch 0085, iter [00220, 01251], lr: 0.000045, loss: 0.4033
2022-10-04 15:50:49 - train: epoch 0085, iter [00230, 01251], lr: 0.000045, loss: 0.4019
2022-10-04 15:51:07 - train: epoch 0085, iter [00240, 01251], lr: 0.000045, loss: 0.4004
2022-10-04 15:51:26 - train: epoch 0085, iter [00250, 01251], lr: 0.000044, loss: 0.4028
2022-10-04 15:51:44 - train: epoch 0085, iter [00260, 01251], lr: 0.000044, loss: 0.4108
2022-10-04 15:52:03 - train: epoch 0085, iter [00270, 01251], lr: 0.000044, loss: 0.4134
2022-10-04 15:52:22 - train: epoch 0085, iter [00280, 01251], lr: 0.000044, loss: 0.4008
2022-10-04 15:52:40 - train: epoch 0085, iter [00290, 01251], lr: 0.000044, loss: 0.3961
2022-10-04 15:52:59 - train: epoch 0085, iter [00300, 01251], lr: 0.000044, loss: 0.4122
2022-10-04 15:53:18 - train: epoch 0085, iter [00310, 01251], lr: 0.000044, loss: 0.3877
2022-10-04 15:53:36 - train: epoch 0085, iter [00320, 01251], lr: 0.000044, loss: 0.3969
2022-10-04 15:53:55 - train: epoch 0085, iter [00330, 01251], lr: 0.000044, loss: 0.3967
2022-10-04 15:54:14 - train: epoch 0085, iter [00340, 01251], lr: 0.000044, loss: 0.4059
2022-10-04 15:54:33 - train: epoch 0085, iter [00350, 01251], lr: 0.000044, loss: 0.4122
2022-10-04 15:54:51 - train: epoch 0085, iter [00360, 01251], lr: 0.000044, loss: 0.3842
2022-10-04 15:55:10 - train: epoch 0085, iter [00370, 01251], lr: 0.000044, loss: 0.3990
2022-10-04 15:55:30 - train: epoch 0085, iter [00380, 01251], lr: 0.000044, loss: 0.3914
2022-10-04 15:55:49 - train: epoch 0085, iter [00390, 01251], lr: 0.000044, loss: 0.4216
2022-10-04 15:56:08 - train: epoch 0085, iter [00400, 01251], lr: 0.000044, loss: 0.3977
2022-10-04 15:56:27 - train: epoch 0085, iter [00410, 01251], lr: 0.000044, loss: 0.4092
2022-10-04 15:56:46 - train: epoch 0085, iter [00420, 01251], lr: 0.000044, loss: 0.4047
2022-10-04 15:57:06 - train: epoch 0085, iter [00430, 01251], lr: 0.000044, loss: 0.3894
2022-10-04 15:57:25 - train: epoch 0085, iter [00440, 01251], lr: 0.000044, loss: 0.4042
2022-10-04 15:57:43 - train: epoch 0085, iter [00450, 01251], lr: 0.000044, loss: 0.3890
2022-10-04 15:58:03 - train: epoch 0085, iter [00460, 01251], lr: 0.000044, loss: 0.4173
2022-10-04 15:58:21 - train: epoch 0085, iter [00470, 01251], lr: 0.000044, loss: 0.4099
2022-10-04 15:58:40 - train: epoch 0085, iter [00480, 01251], lr: 0.000043, loss: 0.3924
2022-10-04 15:58:59 - train: epoch 0085, iter [00490, 01251], lr: 0.000043, loss: 0.3823
2022-10-04 15:59:18 - train: epoch 0085, iter [00500, 01251], lr: 0.000043, loss: 0.3795
2022-10-04 15:59:37 - train: epoch 0085, iter [00510, 01251], lr: 0.000043, loss: 0.4155
2022-10-04 15:59:56 - train: epoch 0085, iter [00520, 01251], lr: 0.000043, loss: 0.4054
2022-10-04 16:00:15 - train: epoch 0085, iter [00530, 01251], lr: 0.000043, loss: 0.4252
2022-10-04 16:00:34 - train: epoch 0085, iter [00540, 01251], lr: 0.000043, loss: 0.3941
2022-10-04 16:00:53 - train: epoch 0085, iter [00550, 01251], lr: 0.000043, loss: 0.4005
2022-10-04 16:01:12 - train: epoch 0085, iter [00560, 01251], lr: 0.000043, loss: 0.3987
2022-10-04 16:01:31 - train: epoch 0085, iter [00570, 01251], lr: 0.000043, loss: 0.4111
2022-10-04 16:01:49 - train: epoch 0085, iter [00580, 01251], lr: 0.000043, loss: 0.4095
2022-10-04 16:02:08 - train: epoch 0085, iter [00590, 01251], lr: 0.000043, loss: 0.4240
2022-10-04 16:02:27 - train: epoch 0085, iter [00600, 01251], lr: 0.000043, loss: 0.3789
2022-10-04 16:02:46 - train: epoch 0085, iter [00610, 01251], lr: 0.000043, loss: 0.4109
2022-10-04 16:03:06 - train: epoch 0085, iter [00620, 01251], lr: 0.000043, loss: 0.3886
2022-10-04 16:03:25 - train: epoch 0085, iter [00630, 01251], lr: 0.000043, loss: 0.3976
2022-10-04 16:03:43 - train: epoch 0085, iter [00640, 01251], lr: 0.000043, loss: 0.4196
2022-10-04 16:04:02 - train: epoch 0085, iter [00650, 01251], lr: 0.000043, loss: 0.4112
2022-10-04 16:04:21 - train: epoch 0085, iter [00660, 01251], lr: 0.000043, loss: 0.4239
2022-10-04 16:04:40 - train: epoch 0085, iter [00670, 01251], lr: 0.000043, loss: 0.4059
2022-10-04 16:04:59 - train: epoch 0085, iter [00680, 01251], lr: 0.000043, loss: 0.3995
2022-10-04 16:05:18 - train: epoch 0085, iter [00690, 01251], lr: 0.000043, loss: 0.3914
2022-10-04 16:05:37 - train: epoch 0085, iter [00700, 01251], lr: 0.000043, loss: 0.4052
2022-10-04 16:05:56 - train: epoch 0085, iter [00710, 01251], lr: 0.000042, loss: 0.4037
2022-10-04 16:06:15 - train: epoch 0085, iter [00720, 01251], lr: 0.000042, loss: 0.4104
2022-10-04 16:06:33 - train: epoch 0085, iter [00730, 01251], lr: 0.000042, loss: 0.3991
2022-10-04 16:06:53 - train: epoch 0085, iter [00740, 01251], lr: 0.000042, loss: 0.4107
2022-10-04 16:07:11 - train: epoch 0085, iter [00750, 01251], lr: 0.000042, loss: 0.4179
2022-10-04 16:07:30 - train: epoch 0085, iter [00760, 01251], lr: 0.000042, loss: 0.4141
2022-10-04 16:07:50 - train: epoch 0085, iter [00770, 01251], lr: 0.000042, loss: 0.4011
2022-10-04 16:08:08 - train: epoch 0085, iter [00780, 01251], lr: 0.000042, loss: 0.4059
2022-10-04 16:08:28 - train: epoch 0085, iter [00790, 01251], lr: 0.000042, loss: 0.3890
2022-10-04 16:08:46 - train: epoch 0085, iter [00800, 01251], lr: 0.000042, loss: 0.3969
2022-10-04 16:09:05 - train: epoch 0085, iter [00810, 01251], lr: 0.000042, loss: 0.3994
2022-10-04 16:09:24 - train: epoch 0085, iter [00820, 01251], lr: 0.000042, loss: 0.4028
2022-10-04 16:09:43 - train: epoch 0085, iter [00830, 01251], lr: 0.000042, loss: 0.4075
2022-10-04 16:10:02 - train: epoch 0085, iter [00840, 01251], lr: 0.000042, loss: 0.3727
2022-10-04 16:10:21 - train: epoch 0085, iter [00850, 01251], lr: 0.000042, loss: 0.3777
2022-10-04 16:10:40 - train: epoch 0085, iter [00860, 01251], lr: 0.000042, loss: 0.3865
2022-10-04 16:10:59 - train: epoch 0085, iter [00870, 01251], lr: 0.000042, loss: 0.4130
2022-10-04 16:11:18 - train: epoch 0085, iter [00880, 01251], lr: 0.000042, loss: 0.3867
2022-10-04 16:11:38 - train: epoch 0085, iter [00890, 01251], lr: 0.000042, loss: 0.4026
2022-10-04 16:11:57 - train: epoch 0085, iter [00900, 01251], lr: 0.000042, loss: 0.3909
2022-10-04 16:12:16 - train: epoch 0085, iter [00910, 01251], lr: 0.000042, loss: 0.3986
2022-10-04 16:12:35 - train: epoch 0085, iter [00920, 01251], lr: 0.000042, loss: 0.3863
2022-10-04 16:12:54 - train: epoch 0085, iter [00930, 01251], lr: 0.000042, loss: 0.4120
2022-10-04 16:13:13 - train: epoch 0085, iter [00940, 01251], lr: 0.000042, loss: 0.4006
2022-10-04 16:13:32 - train: epoch 0085, iter [00950, 01251], lr: 0.000041, loss: 0.4060
2022-10-04 16:13:51 - train: epoch 0085, iter [00960, 01251], lr: 0.000041, loss: 0.3960
2022-10-04 16:14:10 - train: epoch 0085, iter [00970, 01251], lr: 0.000041, loss: 0.3811
2022-10-04 16:14:29 - train: epoch 0085, iter [00980, 01251], lr: 0.000041, loss: 0.4016
2022-10-04 16:14:48 - train: epoch 0085, iter [00990, 01251], lr: 0.000041, loss: 0.3910
2022-10-04 16:15:07 - train: epoch 0085, iter [01000, 01251], lr: 0.000041, loss: 0.3973
2022-10-04 16:15:26 - train: epoch 0085, iter [01010, 01251], lr: 0.000041, loss: 0.4189
2022-10-04 16:15:45 - train: epoch 0085, iter [01020, 01251], lr: 0.000041, loss: 0.4132
2022-10-04 16:16:04 - train: epoch 0085, iter [01030, 01251], lr: 0.000041, loss: 0.3827
2022-10-04 16:16:23 - train: epoch 0085, iter [01040, 01251], lr: 0.000041, loss: 0.4164
2022-10-04 16:16:42 - train: epoch 0085, iter [01050, 01251], lr: 0.000041, loss: 0.4123
2022-10-04 16:17:00 - train: epoch 0085, iter [01060, 01251], lr: 0.000041, loss: 0.4122
2022-10-04 16:17:19 - train: epoch 0085, iter [01070, 01251], lr: 0.000041, loss: 0.4028
2022-10-04 16:17:38 - train: epoch 0085, iter [01080, 01251], lr: 0.000041, loss: 0.3758
2022-10-04 16:17:57 - train: epoch 0085, iter [01090, 01251], lr: 0.000041, loss: 0.4071
2022-10-04 16:18:16 - train: epoch 0085, iter [01100, 01251], lr: 0.000041, loss: 0.3958
2022-10-04 16:18:35 - train: epoch 0085, iter [01110, 01251], lr: 0.000041, loss: 0.3844
2022-10-04 16:18:54 - train: epoch 0085, iter [01120, 01251], lr: 0.000041, loss: 0.4047
2022-10-04 16:19:13 - train: epoch 0085, iter [01130, 01251], lr: 0.000041, loss: 0.4052
2022-10-04 16:19:32 - train: epoch 0085, iter [01140, 01251], lr: 0.000041, loss: 0.3919
2022-10-04 16:19:51 - train: epoch 0085, iter [01150, 01251], lr: 0.000041, loss: 0.4108
2022-10-04 16:20:10 - train: epoch 0085, iter [01160, 01251], lr: 0.000041, loss: 0.4033
2022-10-04 16:20:30 - train: epoch 0085, iter [01170, 01251], lr: 0.000041, loss: 0.3980
2022-10-04 16:20:49 - train: epoch 0085, iter [01180, 01251], lr: 0.000040, loss: 0.4014
2022-10-04 16:21:07 - train: epoch 0085, iter [01190, 01251], lr: 0.000040, loss: 0.4262
2022-10-04 16:21:26 - train: epoch 0085, iter [01200, 01251], lr: 0.000040, loss: 0.4017
2022-10-04 16:21:45 - train: epoch 0085, iter [01210, 01251], lr: 0.000040, loss: 0.4105
2022-10-04 16:22:04 - train: epoch 0085, iter [01220, 01251], lr: 0.000040, loss: 0.4149
2022-10-04 16:22:23 - train: epoch 0085, iter [01230, 01251], lr: 0.000040, loss: 0.4043
2022-10-04 16:22:43 - train: epoch 0085, iter [01240, 01251], lr: 0.000040, loss: 0.4210
2022-10-04 16:23:01 - train: epoch 0085, iter [01250, 01251], lr: 0.000040, loss: 0.3811
2022-10-04 16:23:06 - train: epoch 085, train_loss: 0.4001
2022-10-04 16:23:11 - until epoch: 085, best_loss: 0.4001
2022-10-04 16:23:11 - epoch 086 lr: 0.000040
2022-10-04 16:23:36 - train: epoch 0086, iter [00010, 01251], lr: 0.000040, loss: 0.3899
2022-10-04 16:23:55 - train: epoch 0086, iter [00020, 01251], lr: 0.000040, loss: 0.3922
2022-10-04 16:24:15 - train: epoch 0086, iter [00030, 01251], lr: 0.000040, loss: 0.3874
2022-10-04 16:24:34 - train: epoch 0086, iter [00040, 01251], lr: 0.000040, loss: 0.3920
2022-10-04 16:24:53 - train: epoch 0086, iter [00050, 01251], lr: 0.000040, loss: 0.3954
2022-10-04 16:25:12 - train: epoch 0086, iter [00060, 01251], lr: 0.000040, loss: 0.3956
2022-10-04 16:25:31 - train: epoch 0086, iter [00070, 01251], lr: 0.000040, loss: 0.4032
2022-10-04 16:25:49 - train: epoch 0086, iter [00080, 01251], lr: 0.000040, loss: 0.3965
2022-10-04 16:26:08 - train: epoch 0086, iter [00090, 01251], lr: 0.000040, loss: 0.3693
2022-10-04 16:26:26 - train: epoch 0086, iter [00100, 01251], lr: 0.000040, loss: 0.3995
2022-10-04 16:26:45 - train: epoch 0086, iter [00110, 01251], lr: 0.000040, loss: 0.3951
2022-10-04 16:27:05 - train: epoch 0086, iter [00120, 01251], lr: 0.000040, loss: 0.4088
2022-10-04 16:27:24 - train: epoch 0086, iter [00130, 01251], lr: 0.000040, loss: 0.3927
2022-10-04 16:27:43 - train: epoch 0086, iter [00140, 01251], lr: 0.000040, loss: 0.3963
2022-10-04 16:28:02 - train: epoch 0086, iter [00150, 01251], lr: 0.000040, loss: 0.3881
2022-10-04 16:28:21 - train: epoch 0086, iter [00160, 01251], lr: 0.000040, loss: 0.4099
2022-10-04 16:28:40 - train: epoch 0086, iter [00170, 01251], lr: 0.000039, loss: 0.3931
2022-10-04 16:28:59 - train: epoch 0086, iter [00180, 01251], lr: 0.000039, loss: 0.4143
2022-10-04 16:29:19 - train: epoch 0086, iter [00190, 01251], lr: 0.000039, loss: 0.3848
2022-10-04 16:29:38 - train: epoch 0086, iter [00200, 01251], lr: 0.000039, loss: 0.4083
2022-10-04 16:29:56 - train: epoch 0086, iter [00210, 01251], lr: 0.000039, loss: 0.3951
2022-10-04 16:30:16 - train: epoch 0086, iter [00220, 01251], lr: 0.000039, loss: 0.4035
2022-10-04 16:30:35 - train: epoch 0086, iter [00230, 01251], lr: 0.000039, loss: 0.4083
2022-10-04 16:30:54 - train: epoch 0086, iter [00240, 01251], lr: 0.000039, loss: 0.3886
2022-10-04 16:31:13 - train: epoch 0086, iter [00250, 01251], lr: 0.000039, loss: 0.4123
2022-10-04 16:31:32 - train: epoch 0086, iter [00260, 01251], lr: 0.000039, loss: 0.3899
2022-10-04 16:31:51 - train: epoch 0086, iter [00270, 01251], lr: 0.000039, loss: 0.3802
2022-10-04 16:32:10 - train: epoch 0086, iter [00280, 01251], lr: 0.000039, loss: 0.4008
2022-10-04 16:32:30 - train: epoch 0086, iter [00290, 01251], lr: 0.000039, loss: 0.4185
2022-10-04 16:32:49 - train: epoch 0086, iter [00300, 01251], lr: 0.000039, loss: 0.4131
2022-10-04 16:33:08 - train: epoch 0086, iter [00310, 01251], lr: 0.000039, loss: 0.4195
2022-10-04 16:33:27 - train: epoch 0086, iter [00320, 01251], lr: 0.000039, loss: 0.3882
2022-10-04 16:33:47 - train: epoch 0086, iter [00330, 01251], lr: 0.000039, loss: 0.4034
2022-10-04 16:34:06 - train: epoch 0086, iter [00340, 01251], lr: 0.000039, loss: 0.3979
2022-10-04 16:34:25 - train: epoch 0086, iter [00350, 01251], lr: 0.000039, loss: 0.3809
2022-10-04 16:34:44 - train: epoch 0086, iter [00360, 01251], lr: 0.000039, loss: 0.3977
2022-10-04 16:35:03 - train: epoch 0086, iter [00370, 01251], lr: 0.000039, loss: 0.4227
2022-10-04 16:35:22 - train: epoch 0086, iter [00380, 01251], lr: 0.000039, loss: 0.3995
2022-10-04 16:35:41 - train: epoch 0086, iter [00390, 01251], lr: 0.000039, loss: 0.4164
2022-10-04 16:36:01 - train: epoch 0086, iter [00400, 01251], lr: 0.000039, loss: 0.3905
2022-10-04 16:36:19 - train: epoch 0086, iter [00410, 01251], lr: 0.000038, loss: 0.3876
2022-10-04 16:36:38 - train: epoch 0086, iter [00420, 01251], lr: 0.000038, loss: 0.3987
2022-10-04 16:36:57 - train: epoch 0086, iter [00430, 01251], lr: 0.000038, loss: 0.4031
2022-10-04 16:37:16 - train: epoch 0086, iter [00440, 01251], lr: 0.000038, loss: 0.3977
2022-10-04 16:37:35 - train: epoch 0086, iter [00450, 01251], lr: 0.000038, loss: 0.4114
2022-10-04 16:37:54 - train: epoch 0086, iter [00460, 01251], lr: 0.000038, loss: 0.4035
2022-10-04 16:38:13 - train: epoch 0086, iter [00470, 01251], lr: 0.000038, loss: 0.3951
2022-10-04 16:38:32 - train: epoch 0086, iter [00480, 01251], lr: 0.000038, loss: 0.4055
2022-10-04 16:38:51 - train: epoch 0086, iter [00490, 01251], lr: 0.000038, loss: 0.3825
2022-10-04 16:39:10 - train: epoch 0086, iter [00500, 01251], lr: 0.000038, loss: 0.3796
2022-10-04 16:39:29 - train: epoch 0086, iter [00510, 01251], lr: 0.000038, loss: 0.4055
2022-10-04 16:39:49 - train: epoch 0086, iter [00520, 01251], lr: 0.000038, loss: 0.4025
2022-10-04 16:40:08 - train: epoch 0086, iter [00530, 01251], lr: 0.000038, loss: 0.4012
2022-10-04 16:40:28 - train: epoch 0086, iter [00540, 01251], lr: 0.000038, loss: 0.4196
2022-10-04 16:40:46 - train: epoch 0086, iter [00550, 01251], lr: 0.000038, loss: 0.3870
2022-10-04 16:41:05 - train: epoch 0086, iter [00560, 01251], lr: 0.000038, loss: 0.4189
2022-10-04 16:41:24 - train: epoch 0086, iter [00570, 01251], lr: 0.000038, loss: 0.3887
2022-10-04 16:41:43 - train: epoch 0086, iter [00580, 01251], lr: 0.000038, loss: 0.3967
2022-10-04 16:42:02 - train: epoch 0086, iter [00590, 01251], lr: 0.000038, loss: 0.3922
2022-10-04 16:42:21 - train: epoch 0086, iter [00600, 01251], lr: 0.000038, loss: 0.4030
2022-10-04 16:42:40 - train: epoch 0086, iter [00610, 01251], lr: 0.000038, loss: 0.3904
2022-10-04 16:43:00 - train: epoch 0086, iter [00620, 01251], lr: 0.000038, loss: 0.4093
2022-10-04 16:43:19 - train: epoch 0086, iter [00630, 01251], lr: 0.000038, loss: 0.4015
2022-10-04 16:43:38 - train: epoch 0086, iter [00640, 01251], lr: 0.000038, loss: 0.4206
2022-10-04 16:43:57 - train: epoch 0086, iter [00650, 01251], lr: 0.000038, loss: 0.4148
2022-10-04 16:44:15 - train: epoch 0086, iter [00660, 01251], lr: 0.000037, loss: 0.4170
2022-10-04 16:44:35 - train: epoch 0086, iter [00670, 01251], lr: 0.000037, loss: 0.4097
2022-10-04 16:44:54 - train: epoch 0086, iter [00680, 01251], lr: 0.000037, loss: 0.3960
2022-10-04 16:45:13 - train: epoch 0086, iter [00690, 01251], lr: 0.000037, loss: 0.4057
2022-10-04 16:45:32 - train: epoch 0086, iter [00700, 01251], lr: 0.000037, loss: 0.3965
2022-10-04 16:45:51 - train: epoch 0086, iter [00710, 01251], lr: 0.000037, loss: 0.4158
2022-10-04 16:46:10 - train: epoch 0086, iter [00720, 01251], lr: 0.000037, loss: 0.4016
2022-10-04 16:46:29 - train: epoch 0086, iter [00730, 01251], lr: 0.000037, loss: 0.3868
2022-10-04 16:46:48 - train: epoch 0086, iter [00740, 01251], lr: 0.000037, loss: 0.4067
2022-10-04 16:47:07 - train: epoch 0086, iter [00750, 01251], lr: 0.000037, loss: 0.3952
2022-10-04 16:47:26 - train: epoch 0086, iter [00760, 01251], lr: 0.000037, loss: 0.4004
2022-10-04 16:47:46 - train: epoch 0086, iter [00770, 01251], lr: 0.000037, loss: 0.3987
2022-10-04 16:48:05 - train: epoch 0086, iter [00780, 01251], lr: 0.000037, loss: 0.4000
2022-10-04 16:48:24 - train: epoch 0086, iter [00790, 01251], lr: 0.000037, loss: 0.3907
2022-10-04 16:48:43 - train: epoch 0086, iter [00800, 01251], lr: 0.000037, loss: 0.3888
2022-10-04 16:49:03 - train: epoch 0086, iter [00810, 01251], lr: 0.000037, loss: 0.4082
2022-10-04 16:49:22 - train: epoch 0086, iter [00820, 01251], lr: 0.000037, loss: 0.4123
2022-10-04 16:49:41 - train: epoch 0086, iter [00830, 01251], lr: 0.000037, loss: 0.3971
2022-10-04 16:50:00 - train: epoch 0086, iter [00840, 01251], lr: 0.000037, loss: 0.4094
2022-10-04 16:50:20 - train: epoch 0086, iter [00850, 01251], lr: 0.000037, loss: 0.4079
2022-10-04 16:50:39 - train: epoch 0086, iter [00860, 01251], lr: 0.000037, loss: 0.4063
2022-10-04 16:50:58 - train: epoch 0086, iter [00870, 01251], lr: 0.000037, loss: 0.4073
2022-10-04 16:51:17 - train: epoch 0086, iter [00880, 01251], lr: 0.000037, loss: 0.3964
2022-10-04 16:51:37 - train: epoch 0086, iter [00890, 01251], lr: 0.000037, loss: 0.4043
2022-10-04 16:51:56 - train: epoch 0086, iter [00900, 01251], lr: 0.000037, loss: 0.4097
2022-10-04 16:52:14 - train: epoch 0086, iter [00910, 01251], lr: 0.000036, loss: 0.3854
2022-10-04 16:52:34 - train: epoch 0086, iter [00920, 01251], lr: 0.000036, loss: 0.3927
2022-10-04 16:52:53 - train: epoch 0086, iter [00930, 01251], lr: 0.000036, loss: 0.4028
2022-10-04 16:53:12 - train: epoch 0086, iter [00940, 01251], lr: 0.000036, loss: 0.4191
2022-10-04 16:53:31 - train: epoch 0086, iter [00950, 01251], lr: 0.000036, loss: 0.3934
2022-10-04 16:53:51 - train: epoch 0086, iter [00960, 01251], lr: 0.000036, loss: 0.4103
2022-10-04 16:54:10 - train: epoch 0086, iter [00970, 01251], lr: 0.000036, loss: 0.3868
2022-10-04 16:54:30 - train: epoch 0086, iter [00980, 01251], lr: 0.000036, loss: 0.3957
2022-10-04 16:54:49 - train: epoch 0086, iter [00990, 01251], lr: 0.000036, loss: 0.3949
2022-10-04 16:55:09 - train: epoch 0086, iter [01000, 01251], lr: 0.000036, loss: 0.4248
2022-10-04 16:55:28 - train: epoch 0086, iter [01010, 01251], lr: 0.000036, loss: 0.4058
2022-10-04 16:55:47 - train: epoch 0086, iter [01020, 01251], lr: 0.000036, loss: 0.4065
2022-10-04 16:56:07 - train: epoch 0086, iter [01030, 01251], lr: 0.000036, loss: 0.4056
2022-10-04 16:56:26 - train: epoch 0086, iter [01040, 01251], lr: 0.000036, loss: 0.4063
2022-10-04 16:56:45 - train: epoch 0086, iter [01050, 01251], lr: 0.000036, loss: 0.4004
2022-10-04 16:57:04 - train: epoch 0086, iter [01060, 01251], lr: 0.000036, loss: 0.3954
2022-10-04 16:57:23 - train: epoch 0086, iter [01070, 01251], lr: 0.000036, loss: 0.4089
2022-10-04 16:57:42 - train: epoch 0086, iter [01080, 01251], lr: 0.000036, loss: 0.3899
2022-10-04 16:58:01 - train: epoch 0086, iter [01090, 01251], lr: 0.000036, loss: 0.4090
2022-10-04 16:58:20 - train: epoch 0086, iter [01100, 01251], lr: 0.000036, loss: 0.3967
2022-10-04 16:58:40 - train: epoch 0086, iter [01110, 01251], lr: 0.000036, loss: 0.3988
2022-10-04 16:58:59 - train: epoch 0086, iter [01120, 01251], lr: 0.000036, loss: 0.4131
2022-10-04 16:59:18 - train: epoch 0086, iter [01130, 01251], lr: 0.000036, loss: 0.4151
2022-10-04 16:59:38 - train: epoch 0086, iter [01140, 01251], lr: 0.000036, loss: 0.3775
2022-10-04 16:59:57 - train: epoch 0086, iter [01150, 01251], lr: 0.000036, loss: 0.3988
2022-10-04 17:00:16 - train: epoch 0086, iter [01160, 01251], lr: 0.000035, loss: 0.4119
2022-10-04 17:00:36 - train: epoch 0086, iter [01170, 01251], lr: 0.000035, loss: 0.3915
2022-10-04 17:00:54 - train: epoch 0086, iter [01180, 01251], lr: 0.000035, loss: 0.4039
2022-10-04 17:01:14 - train: epoch 0086, iter [01190, 01251], lr: 0.000035, loss: 0.3928
2022-10-04 17:01:33 - train: epoch 0086, iter [01200, 01251], lr: 0.000035, loss: 0.4102
2022-10-04 17:01:52 - train: epoch 0086, iter [01210, 01251], lr: 0.000035, loss: 0.4201
2022-10-04 17:02:12 - train: epoch 0086, iter [01220, 01251], lr: 0.000035, loss: 0.3847
2022-10-04 17:02:31 - train: epoch 0086, iter [01230, 01251], lr: 0.000035, loss: 0.3965
2022-10-04 17:02:50 - train: epoch 0086, iter [01240, 01251], lr: 0.000035, loss: 0.4018
2022-10-04 17:03:08 - train: epoch 0086, iter [01250, 01251], lr: 0.000035, loss: 0.3912
2022-10-04 17:03:13 - train: epoch 086, train_loss: 0.4000
2022-10-04 17:03:17 - until epoch: 086, best_loss: 0.4000
2022-10-04 17:03:17 - epoch 087 lr: 0.000035
2022-10-04 17:03:42 - train: epoch 0087, iter [00010, 01251], lr: 0.000035, loss: 0.3885
2022-10-04 17:04:01 - train: epoch 0087, iter [00020, 01251], lr: 0.000035, loss: 0.3980
2022-10-04 17:04:21 - train: epoch 0087, iter [00030, 01251], lr: 0.000035, loss: 0.4351
2022-10-04 17:04:40 - train: epoch 0087, iter [00040, 01251], lr: 0.000035, loss: 0.3892
2022-10-04 17:04:59 - train: epoch 0087, iter [00050, 01251], lr: 0.000035, loss: 0.4291
2022-10-04 17:05:18 - train: epoch 0087, iter [00060, 01251], lr: 0.000035, loss: 0.3773
2022-10-04 17:05:38 - train: epoch 0087, iter [00070, 01251], lr: 0.000035, loss: 0.3957
2022-10-04 17:05:57 - train: epoch 0087, iter [00080, 01251], lr: 0.000035, loss: 0.4153
2022-10-04 17:06:16 - train: epoch 0087, iter [00090, 01251], lr: 0.000035, loss: 0.3868
2022-10-04 17:06:35 - train: epoch 0087, iter [00100, 01251], lr: 0.000035, loss: 0.4018
2022-10-04 17:06:54 - train: epoch 0087, iter [00110, 01251], lr: 0.000035, loss: 0.3951
2022-10-04 17:07:13 - train: epoch 0087, iter [00120, 01251], lr: 0.000035, loss: 0.4141
2022-10-04 17:07:32 - train: epoch 0087, iter [00130, 01251], lr: 0.000035, loss: 0.4026
2022-10-04 17:07:51 - train: epoch 0087, iter [00140, 01251], lr: 0.000035, loss: 0.4029
2022-10-04 17:08:10 - train: epoch 0087, iter [00150, 01251], lr: 0.000035, loss: 0.4096
2022-10-04 17:08:29 - train: epoch 0087, iter [00160, 01251], lr: 0.000034, loss: 0.3932
2022-10-04 17:08:48 - train: epoch 0087, iter [00170, 01251], lr: 0.000034, loss: 0.4069
2022-10-04 17:09:07 - train: epoch 0087, iter [00180, 01251], lr: 0.000034, loss: 0.3934
2022-10-04 17:09:26 - train: epoch 0087, iter [00190, 01251], lr: 0.000034, loss: 0.4058
2022-10-04 17:09:45 - train: epoch 0087, iter [00200, 01251], lr: 0.000034, loss: 0.3970
2022-10-04 17:10:05 - train: epoch 0087, iter [00210, 01251], lr: 0.000034, loss: 0.4079
2022-10-04 17:10:24 - train: epoch 0087, iter [00220, 01251], lr: 0.000034, loss: 0.4093
2022-10-04 17:10:43 - train: epoch 0087, iter [00230, 01251], lr: 0.000034, loss: 0.4094
2022-10-04 17:11:02 - train: epoch 0087, iter [00240, 01251], lr: 0.000034, loss: 0.4064
2022-10-04 17:11:21 - train: epoch 0087, iter [00250, 01251], lr: 0.000034, loss: 0.4104
2022-10-04 17:11:40 - train: epoch 0087, iter [00260, 01251], lr: 0.000034, loss: 0.3784
2022-10-04 17:11:59 - train: epoch 0087, iter [00270, 01251], lr: 0.000034, loss: 0.3894
2022-10-04 17:12:18 - train: epoch 0087, iter [00280, 01251], lr: 0.000034, loss: 0.3995
2022-10-04 17:12:37 - train: epoch 0087, iter [00290, 01251], lr: 0.000034, loss: 0.3727
2022-10-04 17:12:57 - train: epoch 0087, iter [00300, 01251], lr: 0.000034, loss: 0.3948
2022-10-04 17:13:16 - train: epoch 0087, iter [00310, 01251], lr: 0.000034, loss: 0.3947
2022-10-04 17:13:35 - train: epoch 0087, iter [00320, 01251], lr: 0.000034, loss: 0.3867
2022-10-04 17:13:54 - train: epoch 0087, iter [00330, 01251], lr: 0.000034, loss: 0.4208
2022-10-04 17:14:13 - train: epoch 0087, iter [00340, 01251], lr: 0.000034, loss: 0.3990
2022-10-04 17:14:32 - train: epoch 0087, iter [00350, 01251], lr: 0.000034, loss: 0.4327
2022-10-04 17:14:51 - train: epoch 0087, iter [00360, 01251], lr: 0.000034, loss: 0.4017
2022-10-04 17:15:10 - train: epoch 0087, iter [00370, 01251], lr: 0.000034, loss: 0.3854
2022-10-04 17:15:29 - train: epoch 0087, iter [00380, 01251], lr: 0.000034, loss: 0.3903
2022-10-04 17:15:48 - train: epoch 0087, iter [00390, 01251], lr: 0.000034, loss: 0.4118
2022-10-04 17:16:07 - train: epoch 0087, iter [00400, 01251], lr: 0.000034, loss: 0.4008
2022-10-04 17:16:27 - train: epoch 0087, iter [00410, 01251], lr: 0.000034, loss: 0.3793
2022-10-04 17:16:46 - train: epoch 0087, iter [00420, 01251], lr: 0.000033, loss: 0.3841
2022-10-04 17:17:04 - train: epoch 0087, iter [00430, 01251], lr: 0.000033, loss: 0.4067
2022-10-04 17:17:23 - train: epoch 0087, iter [00440, 01251], lr: 0.000033, loss: 0.4126
2022-10-04 17:17:42 - train: epoch 0087, iter [00450, 01251], lr: 0.000033, loss: 0.3958
2022-10-04 17:18:01 - train: epoch 0087, iter [00460, 01251], lr: 0.000033, loss: 0.4090
2022-10-04 17:18:20 - train: epoch 0087, iter [00470, 01251], lr: 0.000033, loss: 0.4024
2022-10-04 17:18:39 - train: epoch 0087, iter [00480, 01251], lr: 0.000033, loss: 0.3898
2022-10-04 17:18:58 - train: epoch 0087, iter [00490, 01251], lr: 0.000033, loss: 0.4162
2022-10-04 17:19:16 - train: epoch 0087, iter [00500, 01251], lr: 0.000033, loss: 0.4061
2022-10-04 17:19:35 - train: epoch 0087, iter [00510, 01251], lr: 0.000033, loss: 0.3901
2022-10-04 17:19:54 - train: epoch 0087, iter [00520, 01251], lr: 0.000033, loss: 0.3774
2022-10-04 17:20:13 - train: epoch 0087, iter [00530, 01251], lr: 0.000033, loss: 0.3913
2022-10-04 17:20:32 - train: epoch 0087, iter [00540, 01251], lr: 0.000033, loss: 0.3782
2022-10-04 17:20:51 - train: epoch 0087, iter [00550, 01251], lr: 0.000033, loss: 0.3838
2022-10-04 17:21:11 - train: epoch 0087, iter [00560, 01251], lr: 0.000033, loss: 0.3971
2022-10-04 17:21:30 - train: epoch 0087, iter [00570, 01251], lr: 0.000033, loss: 0.4142
2022-10-04 17:21:49 - train: epoch 0087, iter [00580, 01251], lr: 0.000033, loss: 0.4189
2022-10-04 17:22:07 - train: epoch 0087, iter [00590, 01251], lr: 0.000033, loss: 0.3996
2022-10-04 17:22:27 - train: epoch 0087, iter [00600, 01251], lr: 0.000033, loss: 0.4033
2022-10-04 17:22:46 - train: epoch 0087, iter [00610, 01251], lr: 0.000033, loss: 0.4072
2022-10-04 17:23:05 - train: epoch 0087, iter [00620, 01251], lr: 0.000033, loss: 0.4260
2022-10-04 17:23:24 - train: epoch 0087, iter [00630, 01251], lr: 0.000033, loss: 0.3969
2022-10-04 17:23:42 - train: epoch 0087, iter [00640, 01251], lr: 0.000033, loss: 0.4020
2022-10-04 17:24:02 - train: epoch 0087, iter [00650, 01251], lr: 0.000033, loss: 0.3930
2022-10-04 17:24:21 - train: epoch 0087, iter [00660, 01251], lr: 0.000033, loss: 0.4045
2022-10-04 17:24:39 - train: epoch 0087, iter [00670, 01251], lr: 0.000033, loss: 0.3956
2022-10-04 17:24:58 - train: epoch 0087, iter [00680, 01251], lr: 0.000032, loss: 0.3986
2022-10-04 17:25:17 - train: epoch 0087, iter [00690, 01251], lr: 0.000032, loss: 0.3779
2022-10-04 17:25:36 - train: epoch 0087, iter [00700, 01251], lr: 0.000032, loss: 0.3988
2022-10-04 17:25:55 - train: epoch 0087, iter [00710, 01251], lr: 0.000032, loss: 0.4025
2022-10-04 17:26:15 - train: epoch 0087, iter [00720, 01251], lr: 0.000032, loss: 0.3860
2022-10-04 17:26:34 - train: epoch 0087, iter [00730, 01251], lr: 0.000032, loss: 0.3968
2022-10-04 17:26:53 - train: epoch 0087, iter [00740, 01251], lr: 0.000032, loss: 0.3842
2022-10-04 17:27:12 - train: epoch 0087, iter [00750, 01251], lr: 0.000032, loss: 0.3950
2022-10-04 17:27:31 - train: epoch 0087, iter [00760, 01251], lr: 0.000032, loss: 0.4148
2022-10-04 17:27:50 - train: epoch 0087, iter [00770, 01251], lr: 0.000032, loss: 0.4080
2022-10-04 17:28:09 - train: epoch 0087, iter [00780, 01251], lr: 0.000032, loss: 0.3736
2022-10-04 17:28:29 - train: epoch 0087, iter [00790, 01251], lr: 0.000032, loss: 0.3787
2022-10-04 17:28:48 - train: epoch 0087, iter [00800, 01251], lr: 0.000032, loss: 0.3834
2022-10-04 17:29:06 - train: epoch 0087, iter [00810, 01251], lr: 0.000032, loss: 0.4097
2022-10-04 17:29:26 - train: epoch 0087, iter [00820, 01251], lr: 0.000032, loss: 0.3980
2022-10-04 17:29:45 - train: epoch 0087, iter [00830, 01251], lr: 0.000032, loss: 0.4123
2022-10-04 17:30:04 - train: epoch 0087, iter [00840, 01251], lr: 0.000032, loss: 0.3888
2022-10-04 17:30:23 - train: epoch 0087, iter [00850, 01251], lr: 0.000032, loss: 0.4078
2022-10-04 17:30:42 - train: epoch 0087, iter [00860, 01251], lr: 0.000032, loss: 0.4072
2022-10-04 17:31:01 - train: epoch 0087, iter [00870, 01251], lr: 0.000032, loss: 0.4075
2022-10-04 17:31:19 - train: epoch 0087, iter [00880, 01251], lr: 0.000032, loss: 0.3981
2022-10-04 17:31:39 - train: epoch 0087, iter [00890, 01251], lr: 0.000032, loss: 0.4092
2022-10-04 17:31:57 - train: epoch 0087, iter [00900, 01251], lr: 0.000032, loss: 0.4297
2022-10-04 17:32:17 - train: epoch 0087, iter [00910, 01251], lr: 0.000032, loss: 0.3980
2022-10-04 17:32:37 - train: epoch 0087, iter [00920, 01251], lr: 0.000032, loss: 0.4030
2022-10-04 17:32:55 - train: epoch 0087, iter [00930, 01251], lr: 0.000032, loss: 0.4054
2022-10-04 17:33:14 - train: epoch 0087, iter [00940, 01251], lr: 0.000032, loss: 0.3939
2022-10-04 17:33:33 - train: epoch 0087, iter [00950, 01251], lr: 0.000031, loss: 0.4028
2022-10-04 17:33:52 - train: epoch 0087, iter [00960, 01251], lr: 0.000031, loss: 0.4037
2022-10-04 17:34:12 - train: epoch 0087, iter [00970, 01251], lr: 0.000031, loss: 0.3810
2022-10-04 17:34:30 - train: epoch 0087, iter [00980, 01251], lr: 0.000031, loss: 0.4096
2022-10-04 17:34:49 - train: epoch 0087, iter [00990, 01251], lr: 0.000031, loss: 0.4100
2022-10-04 17:35:09 - train: epoch 0087, iter [01000, 01251], lr: 0.000031, loss: 0.4191
2022-10-04 17:35:28 - train: epoch 0087, iter [01010, 01251], lr: 0.000031, loss: 0.3937
2022-10-04 17:35:47 - train: epoch 0087, iter [01020, 01251], lr: 0.000031, loss: 0.3729
2022-10-04 17:36:06 - train: epoch 0087, iter [01030, 01251], lr: 0.000031, loss: 0.4160
2022-10-04 17:36:26 - train: epoch 0087, iter [01040, 01251], lr: 0.000031, loss: 0.4010
2022-10-04 17:36:44 - train: epoch 0087, iter [01050, 01251], lr: 0.000031, loss: 0.4106
2022-10-04 17:37:04 - train: epoch 0087, iter [01060, 01251], lr: 0.000031, loss: 0.4006
2022-10-04 17:37:23 - train: epoch 0087, iter [01070, 01251], lr: 0.000031, loss: 0.3824
2022-10-04 17:37:42 - train: epoch 0087, iter [01080, 01251], lr: 0.000031, loss: 0.3920
2022-10-04 17:38:01 - train: epoch 0087, iter [01090, 01251], lr: 0.000031, loss: 0.3884
2022-10-04 17:38:20 - train: epoch 0087, iter [01100, 01251], lr: 0.000031, loss: 0.3961
2022-10-04 17:38:39 - train: epoch 0087, iter [01110, 01251], lr: 0.000031, loss: 0.4138
2022-10-04 17:38:58 - train: epoch 0087, iter [01120, 01251], lr: 0.000031, loss: 0.3975
2022-10-04 17:39:17 - train: epoch 0087, iter [01130, 01251], lr: 0.000031, loss: 0.4062
2022-10-04 17:39:37 - train: epoch 0087, iter [01140, 01251], lr: 0.000031, loss: 0.4040
2022-10-04 17:39:56 - train: epoch 0087, iter [01150, 01251], lr: 0.000031, loss: 0.4096
2022-10-04 17:40:15 - train: epoch 0087, iter [01160, 01251], lr: 0.000031, loss: 0.3901
2022-10-04 17:40:34 - train: epoch 0087, iter [01170, 01251], lr: 0.000031, loss: 0.3978
2022-10-04 17:40:53 - train: epoch 0087, iter [01180, 01251], lr: 0.000031, loss: 0.4033
2022-10-04 17:41:12 - train: epoch 0087, iter [01190, 01251], lr: 0.000031, loss: 0.4271
2022-10-04 17:41:31 - train: epoch 0087, iter [01200, 01251], lr: 0.000031, loss: 0.3985
2022-10-04 17:41:50 - train: epoch 0087, iter [01210, 01251], lr: 0.000031, loss: 0.3908
2022-10-04 17:42:08 - train: epoch 0087, iter [01220, 01251], lr: 0.000030, loss: 0.3704
2022-10-04 17:42:27 - train: epoch 0087, iter [01230, 01251], lr: 0.000030, loss: 0.4025
2022-10-04 17:42:47 - train: epoch 0087, iter [01240, 01251], lr: 0.000030, loss: 0.3940
2022-10-04 17:43:05 - train: epoch 0087, iter [01250, 01251], lr: 0.000030, loss: 0.3957
2022-10-04 17:43:10 - train: epoch 087, train_loss: 0.3997
2022-10-04 17:43:14 - until epoch: 087, best_loss: 0.3997
2022-10-04 17:43:14 - epoch 088 lr: 0.000030
2022-10-04 17:43:39 - train: epoch 0088, iter [00010, 01251], lr: 0.000030, loss: 0.4156
2022-10-04 17:43:58 - train: epoch 0088, iter [00020, 01251], lr: 0.000030, loss: 0.3989
2022-10-04 17:44:17 - train: epoch 0088, iter [00030, 01251], lr: 0.000030, loss: 0.4284
2022-10-04 17:44:37 - train: epoch 0088, iter [00040, 01251], lr: 0.000030, loss: 0.4137
2022-10-04 17:44:55 - train: epoch 0088, iter [00050, 01251], lr: 0.000030, loss: 0.3925
2022-10-04 17:45:14 - train: epoch 0088, iter [00060, 01251], lr: 0.000030, loss: 0.4082
2022-10-04 17:45:33 - train: epoch 0088, iter [00070, 01251], lr: 0.000030, loss: 0.3929
2022-10-04 17:45:51 - train: epoch 0088, iter [00080, 01251], lr: 0.000030, loss: 0.3948
2022-10-04 17:46:11 - train: epoch 0088, iter [00090, 01251], lr: 0.000030, loss: 0.4006
2022-10-04 17:46:30 - train: epoch 0088, iter [00100, 01251], lr: 0.000030, loss: 0.4042
2022-10-04 17:46:49 - train: epoch 0088, iter [00110, 01251], lr: 0.000030, loss: 0.4053
2022-10-04 17:47:08 - train: epoch 0088, iter [00120, 01251], lr: 0.000030, loss: 0.4104
2022-10-04 17:47:26 - train: epoch 0088, iter [00130, 01251], lr: 0.000030, loss: 0.4008
2022-10-04 17:47:45 - train: epoch 0088, iter [00140, 01251], lr: 0.000030, loss: 0.4115
2022-10-04 17:48:04 - train: epoch 0088, iter [00150, 01251], lr: 0.000030, loss: 0.3949
2022-10-04 17:48:23 - train: epoch 0088, iter [00160, 01251], lr: 0.000030, loss: 0.4003
2022-10-04 17:48:42 - train: epoch 0088, iter [00170, 01251], lr: 0.000030, loss: 0.3834
2022-10-04 17:49:01 - train: epoch 0088, iter [00180, 01251], lr: 0.000030, loss: 0.3788
2022-10-04 17:49:20 - train: epoch 0088, iter [00190, 01251], lr: 0.000030, loss: 0.3841
2022-10-04 17:49:39 - train: epoch 0088, iter [00200, 01251], lr: 0.000030, loss: 0.3985
2022-10-04 17:49:58 - train: epoch 0088, iter [00210, 01251], lr: 0.000030, loss: 0.3964
2022-10-04 17:50:18 - train: epoch 0088, iter [00220, 01251], lr: 0.000030, loss: 0.4137
2022-10-04 17:50:37 - train: epoch 0088, iter [00230, 01251], lr: 0.000030, loss: 0.3917
2022-10-04 17:50:56 - train: epoch 0088, iter [00240, 01251], lr: 0.000029, loss: 0.3985
2022-10-04 17:51:15 - train: epoch 0088, iter [00250, 01251], lr: 0.000029, loss: 0.3876
2022-10-04 17:51:34 - train: epoch 0088, iter [00260, 01251], lr: 0.000029, loss: 0.3944
2022-10-04 17:51:53 - train: epoch 0088, iter [00270, 01251], lr: 0.000029, loss: 0.3699
2022-10-04 17:52:12 - train: epoch 0088, iter [00280, 01251], lr: 0.000029, loss: 0.4084
2022-10-04 17:52:31 - train: epoch 0088, iter [00290, 01251], lr: 0.000029, loss: 0.4075
2022-10-04 17:52:50 - train: epoch 0088, iter [00300, 01251], lr: 0.000029, loss: 0.3787
2022-10-04 17:53:09 - train: epoch 0088, iter [00310, 01251], lr: 0.000029, loss: 0.3942
2022-10-04 17:53:28 - train: epoch 0088, iter [00320, 01251], lr: 0.000029, loss: 0.3994
2022-10-04 17:53:47 - train: epoch 0088, iter [00330, 01251], lr: 0.000029, loss: 0.3959
2022-10-04 17:54:06 - train: epoch 0088, iter [00340, 01251], lr: 0.000029, loss: 0.3754
2022-10-04 17:54:24 - train: epoch 0088, iter [00350, 01251], lr: 0.000029, loss: 0.3797
2022-10-04 17:54:43 - train: epoch 0088, iter [00360, 01251], lr: 0.000029, loss: 0.4019
2022-10-04 17:55:03 - train: epoch 0088, iter [00370, 01251], lr: 0.000029, loss: 0.4149
2022-10-04 17:55:22 - train: epoch 0088, iter [00380, 01251], lr: 0.000029, loss: 0.4077
2022-10-04 17:55:41 - train: epoch 0088, iter [00390, 01251], lr: 0.000029, loss: 0.3940
2022-10-04 17:56:01 - train: epoch 0088, iter [00400, 01251], lr: 0.000029, loss: 0.3982
2022-10-04 17:56:20 - train: epoch 0088, iter [00410, 01251], lr: 0.000029, loss: 0.4005
2022-10-04 17:56:39 - train: epoch 0088, iter [00420, 01251], lr: 0.000029, loss: 0.4114
2022-10-04 17:56:57 - train: epoch 0088, iter [00430, 01251], lr: 0.000029, loss: 0.3970
2022-10-04 17:57:17 - train: epoch 0088, iter [00440, 01251], lr: 0.000029, loss: 0.4081
2022-10-04 17:57:35 - train: epoch 0088, iter [00450, 01251], lr: 0.000029, loss: 0.4003
2022-10-04 17:57:55 - train: epoch 0088, iter [00460, 01251], lr: 0.000029, loss: 0.3979
2022-10-04 17:58:14 - train: epoch 0088, iter [00470, 01251], lr: 0.000029, loss: 0.3854
2022-10-04 17:58:34 - train: epoch 0088, iter [00480, 01251], lr: 0.000029, loss: 0.4159
2022-10-04 17:58:53 - train: epoch 0088, iter [00490, 01251], lr: 0.000029, loss: 0.3964
2022-10-04 17:59:12 - train: epoch 0088, iter [00500, 01251], lr: 0.000029, loss: 0.3854
2022-10-04 17:59:32 - train: epoch 0088, iter [00510, 01251], lr: 0.000029, loss: 0.3914
2022-10-04 17:59:51 - train: epoch 0088, iter [00520, 01251], lr: 0.000028, loss: 0.3917
2022-10-04 18:00:10 - train: epoch 0088, iter [00530, 01251], lr: 0.000028, loss: 0.3946
2022-10-04 18:00:30 - train: epoch 0088, iter [00540, 01251], lr: 0.000028, loss: 0.3865
2022-10-04 18:00:48 - train: epoch 0088, iter [00550, 01251], lr: 0.000028, loss: 0.4361
2022-10-04 18:01:08 - train: epoch 0088, iter [00560, 01251], lr: 0.000028, loss: 0.4068
2022-10-04 18:01:28 - train: epoch 0088, iter [00570, 01251], lr: 0.000028, loss: 0.3976
2022-10-04 18:01:47 - train: epoch 0088, iter [00580, 01251], lr: 0.000028, loss: 0.3935
2022-10-04 18:02:06 - train: epoch 0088, iter [00590, 01251], lr: 0.000028, loss: 0.4129
2022-10-04 18:02:25 - train: epoch 0088, iter [00600, 01251], lr: 0.000028, loss: 0.3958
2022-10-04 18:02:44 - train: epoch 0088, iter [00610, 01251], lr: 0.000028, loss: 0.3980
2022-10-04 18:03:03 - train: epoch 0088, iter [00620, 01251], lr: 0.000028, loss: 0.4012
2022-10-04 18:03:22 - train: epoch 0088, iter [00630, 01251], lr: 0.000028, loss: 0.4211
2022-10-04 18:03:41 - train: epoch 0088, iter [00640, 01251], lr: 0.000028, loss: 0.4005
2022-10-04 18:04:01 - train: epoch 0088, iter [00650, 01251], lr: 0.000028, loss: 0.3935
2022-10-04 18:04:20 - train: epoch 0088, iter [00660, 01251], lr: 0.000028, loss: 0.4011
2022-10-04 18:04:39 - train: epoch 0088, iter [00670, 01251], lr: 0.000028, loss: 0.4053
2022-10-04 18:04:58 - train: epoch 0088, iter [00680, 01251], lr: 0.000028, loss: 0.3917
2022-10-04 18:05:17 - train: epoch 0088, iter [00690, 01251], lr: 0.000028, loss: 0.4129
2022-10-04 18:05:36 - train: epoch 0088, iter [00700, 01251], lr: 0.000028, loss: 0.3807
2022-10-04 18:05:55 - train: epoch 0088, iter [00710, 01251], lr: 0.000028, loss: 0.4112
2022-10-04 18:06:14 - train: epoch 0088, iter [00720, 01251], lr: 0.000028, loss: 0.4088
2022-10-04 18:06:33 - train: epoch 0088, iter [00730, 01251], lr: 0.000028, loss: 0.4304
2022-10-04 18:06:52 - train: epoch 0088, iter [00740, 01251], lr: 0.000028, loss: 0.3762
2022-10-04 18:07:12 - train: epoch 0088, iter [00750, 01251], lr: 0.000028, loss: 0.4183
2022-10-04 18:07:31 - train: epoch 0088, iter [00760, 01251], lr: 0.000028, loss: 0.3889
2022-10-04 18:07:50 - train: epoch 0088, iter [00770, 01251], lr: 0.000028, loss: 0.3950
2022-10-04 18:08:10 - train: epoch 0088, iter [00780, 01251], lr: 0.000028, loss: 0.3881
2022-10-04 18:08:29 - train: epoch 0088, iter [00790, 01251], lr: 0.000028, loss: 0.3953
2022-10-04 18:08:48 - train: epoch 0088, iter [00800, 01251], lr: 0.000027, loss: 0.3856
2022-10-04 18:09:07 - train: epoch 0088, iter [00810, 01251], lr: 0.000027, loss: 0.3891
2022-10-04 18:09:26 - train: epoch 0088, iter [00820, 01251], lr: 0.000027, loss: 0.3961
2022-10-04 18:09:46 - train: epoch 0088, iter [00830, 01251], lr: 0.000027, loss: 0.4044
2022-10-04 18:10:05 - train: epoch 0088, iter [00840, 01251], lr: 0.000027, loss: 0.3958
2022-10-04 18:10:24 - train: epoch 0088, iter [00850, 01251], lr: 0.000027, loss: 0.3896
2022-10-04 18:10:43 - train: epoch 0088, iter [00860, 01251], lr: 0.000027, loss: 0.4081
2022-10-04 18:11:03 - train: epoch 0088, iter [00870, 01251], lr: 0.000027, loss: 0.4102
2022-10-04 18:11:21 - train: epoch 0088, iter [00880, 01251], lr: 0.000027, loss: 0.4075
2022-10-04 18:11:41 - train: epoch 0088, iter [00890, 01251], lr: 0.000027, loss: 0.3900
2022-10-04 18:12:00 - train: epoch 0088, iter [00900, 01251], lr: 0.000027, loss: 0.3964
2022-10-04 18:12:19 - train: epoch 0088, iter [00910, 01251], lr: 0.000027, loss: 0.4187
2022-10-04 18:12:38 - train: epoch 0088, iter [00920, 01251], lr: 0.000027, loss: 0.4065
2022-10-04 18:12:57 - train: epoch 0088, iter [00930, 01251], lr: 0.000027, loss: 0.4055
2022-10-04 18:13:16 - train: epoch 0088, iter [00940, 01251], lr: 0.000027, loss: 0.3963
2022-10-04 18:13:34 - train: epoch 0088, iter [00950, 01251], lr: 0.000027, loss: 0.3893
2022-10-04 18:13:53 - train: epoch 0088, iter [00960, 01251], lr: 0.000027, loss: 0.4012
2022-10-04 18:14:12 - train: epoch 0088, iter [00970, 01251], lr: 0.000027, loss: 0.3856
2022-10-04 18:14:31 - train: epoch 0088, iter [00980, 01251], lr: 0.000027, loss: 0.3900
2022-10-04 18:14:50 - train: epoch 0088, iter [00990, 01251], lr: 0.000027, loss: 0.4117
2022-10-04 18:15:09 - train: epoch 0088, iter [01000, 01251], lr: 0.000027, loss: 0.4064
2022-10-04 18:15:27 - train: epoch 0088, iter [01010, 01251], lr: 0.000027, loss: 0.3871
2022-10-04 18:15:47 - train: epoch 0088, iter [01020, 01251], lr: 0.000027, loss: 0.3913
2022-10-04 18:16:06 - train: epoch 0088, iter [01030, 01251], lr: 0.000027, loss: 0.4006
2022-10-04 18:16:25 - train: epoch 0088, iter [01040, 01251], lr: 0.000027, loss: 0.4043
2022-10-04 18:16:44 - train: epoch 0088, iter [01050, 01251], lr: 0.000027, loss: 0.3792
2022-10-04 18:17:03 - train: epoch 0088, iter [01060, 01251], lr: 0.000027, loss: 0.3930
2022-10-04 18:17:22 - train: epoch 0088, iter [01070, 01251], lr: 0.000027, loss: 0.4028
2022-10-04 18:17:42 - train: epoch 0088, iter [01080, 01251], lr: 0.000027, loss: 0.3894
2022-10-04 18:18:01 - train: epoch 0088, iter [01090, 01251], lr: 0.000026, loss: 0.3892
2022-10-04 18:18:20 - train: epoch 0088, iter [01100, 01251], lr: 0.000026, loss: 0.4106
2022-10-04 18:18:39 - train: epoch 0088, iter [01110, 01251], lr: 0.000026, loss: 0.3872
2022-10-04 18:18:59 - train: epoch 0088, iter [01120, 01251], lr: 0.000026, loss: 0.3915
2022-10-04 18:19:18 - train: epoch 0088, iter [01130, 01251], lr: 0.000026, loss: 0.3904
2022-10-04 18:19:37 - train: epoch 0088, iter [01140, 01251], lr: 0.000026, loss: 0.4166
2022-10-04 18:19:56 - train: epoch 0088, iter [01150, 01251], lr: 0.000026, loss: 0.4115
2022-10-04 18:20:14 - train: epoch 0088, iter [01160, 01251], lr: 0.000026, loss: 0.3862
2022-10-04 18:20:34 - train: epoch 0088, iter [01170, 01251], lr: 0.000026, loss: 0.3942
2022-10-04 18:20:53 - train: epoch 0088, iter [01180, 01251], lr: 0.000026, loss: 0.3994
2022-10-04 18:21:12 - train: epoch 0088, iter [01190, 01251], lr: 0.000026, loss: 0.3900
2022-10-04 18:21:31 - train: epoch 0088, iter [01200, 01251], lr: 0.000026, loss: 0.3915
2022-10-04 18:21:51 - train: epoch 0088, iter [01210, 01251], lr: 0.000026, loss: 0.4046
2022-10-04 18:22:10 - train: epoch 0088, iter [01220, 01251], lr: 0.000026, loss: 0.4086
2022-10-04 18:22:29 - train: epoch 0088, iter [01230, 01251], lr: 0.000026, loss: 0.4149
2022-10-04 18:22:48 - train: epoch 0088, iter [01240, 01251], lr: 0.000026, loss: 0.3887
2022-10-04 18:23:07 - train: epoch 0088, iter [01250, 01251], lr: 0.000026, loss: 0.4028
2022-10-04 18:23:12 - train: epoch 088, train_loss: 0.3996
2022-10-04 18:23:16 - until epoch: 088, best_loss: 0.3996
2022-10-04 18:23:16 - epoch 089 lr: 0.000026
2022-10-04 18:23:42 - train: epoch 0089, iter [00010, 01251], lr: 0.000026, loss: 0.4000
2022-10-04 18:24:02 - train: epoch 0089, iter [00020, 01251], lr: 0.000026, loss: 0.4100
2022-10-04 18:24:21 - train: epoch 0089, iter [00030, 01251], lr: 0.000026, loss: 0.3963
2022-10-04 18:24:41 - train: epoch 0089, iter [00040, 01251], lr: 0.000026, loss: 0.4158
2022-10-04 18:25:00 - train: epoch 0089, iter [00050, 01251], lr: 0.000026, loss: 0.3901
2022-10-04 18:25:19 - train: epoch 0089, iter [00060, 01251], lr: 0.000026, loss: 0.3939
2022-10-04 18:25:39 - train: epoch 0089, iter [00070, 01251], lr: 0.000026, loss: 0.4131
2022-10-04 18:25:58 - train: epoch 0089, iter [00080, 01251], lr: 0.000026, loss: 0.3958
2022-10-04 18:26:17 - train: epoch 0089, iter [00090, 01251], lr: 0.000026, loss: 0.4006
2022-10-04 18:26:37 - train: epoch 0089, iter [00100, 01251], lr: 0.000026, loss: 0.4146
2022-10-04 18:26:56 - train: epoch 0089, iter [00110, 01251], lr: 0.000026, loss: 0.4132
2022-10-04 18:27:15 - train: epoch 0089, iter [00120, 01251], lr: 0.000026, loss: 0.4084
2022-10-04 18:27:35 - train: epoch 0089, iter [00130, 01251], lr: 0.000025, loss: 0.3917
2022-10-04 18:27:54 - train: epoch 0089, iter [00140, 01251], lr: 0.000025, loss: 0.4092
2022-10-04 18:28:13 - train: epoch 0089, iter [00150, 01251], lr: 0.000025, loss: 0.3836
2022-10-04 18:28:33 - train: epoch 0089, iter [00160, 01251], lr: 0.000025, loss: 0.3945
2022-10-04 18:28:53 - train: epoch 0089, iter [00170, 01251], lr: 0.000025, loss: 0.4016
2022-10-04 18:29:12 - train: epoch 0089, iter [00180, 01251], lr: 0.000025, loss: 0.3972
2022-10-04 18:29:32 - train: epoch 0089, iter [00190, 01251], lr: 0.000025, loss: 0.4032
2022-10-04 18:29:51 - train: epoch 0089, iter [00200, 01251], lr: 0.000025, loss: 0.4010
2022-10-04 18:30:10 - train: epoch 0089, iter [00210, 01251], lr: 0.000025, loss: 0.3900
2022-10-04 18:30:29 - train: epoch 0089, iter [00220, 01251], lr: 0.000025, loss: 0.3933
2022-10-04 18:30:48 - train: epoch 0089, iter [00230, 01251], lr: 0.000025, loss: 0.4033
2022-10-04 18:31:07 - train: epoch 0089, iter [00240, 01251], lr: 0.000025, loss: 0.4008
2022-10-04 18:31:27 - train: epoch 0089, iter [00250, 01251], lr: 0.000025, loss: 0.4096
2022-10-04 18:31:46 - train: epoch 0089, iter [00260, 01251], lr: 0.000025, loss: 0.4148
2022-10-04 18:32:05 - train: epoch 0089, iter [00270, 01251], lr: 0.000025, loss: 0.4138
2022-10-04 18:32:24 - train: epoch 0089, iter [00280, 01251], lr: 0.000025, loss: 0.3858
2022-10-04 18:32:43 - train: epoch 0089, iter [00290, 01251], lr: 0.000025, loss: 0.3880
2022-10-04 18:33:02 - train: epoch 0089, iter [00300, 01251], lr: 0.000025, loss: 0.4113
2022-10-04 18:33:20 - train: epoch 0089, iter [00310, 01251], lr: 0.000025, loss: 0.4071
2022-10-04 18:33:39 - train: epoch 0089, iter [00320, 01251], lr: 0.000025, loss: 0.3961
2022-10-04 18:33:58 - train: epoch 0089, iter [00330, 01251], lr: 0.000025, loss: 0.4084
2022-10-04 18:34:17 - train: epoch 0089, iter [00340, 01251], lr: 0.000025, loss: 0.4015
2022-10-04 18:34:36 - train: epoch 0089, iter [00350, 01251], lr: 0.000025, loss: 0.3909
2022-10-04 18:34:55 - train: epoch 0089, iter [00360, 01251], lr: 0.000025, loss: 0.4029
2022-10-04 18:35:14 - train: epoch 0089, iter [00370, 01251], lr: 0.000025, loss: 0.3861
2022-10-04 18:35:33 - train: epoch 0089, iter [00380, 01251], lr: 0.000025, loss: 0.3954
2022-10-04 18:35:52 - train: epoch 0089, iter [00390, 01251], lr: 0.000025, loss: 0.3984
2022-10-04 18:36:12 - train: epoch 0089, iter [00400, 01251], lr: 0.000025, loss: 0.4034
2022-10-04 18:36:31 - train: epoch 0089, iter [00410, 01251], lr: 0.000025, loss: 0.3872
2022-10-04 18:36:50 - train: epoch 0089, iter [00420, 01251], lr: 0.000025, loss: 0.3971
2022-10-04 18:37:09 - train: epoch 0089, iter [00430, 01251], lr: 0.000024, loss: 0.3860
2022-10-04 18:37:28 - train: epoch 0089, iter [00440, 01251], lr: 0.000024, loss: 0.3883
2022-10-04 18:37:48 - train: epoch 0089, iter [00450, 01251], lr: 0.000024, loss: 0.4106
2022-10-04 18:38:07 - train: epoch 0089, iter [00460, 01251], lr: 0.000024, loss: 0.3937
2022-10-04 18:38:26 - train: epoch 0089, iter [00470, 01251], lr: 0.000024, loss: 0.4063
2022-10-04 18:38:45 - train: epoch 0089, iter [00480, 01251], lr: 0.000024, loss: 0.3964
2022-10-04 18:39:04 - train: epoch 0089, iter [00490, 01251], lr: 0.000024, loss: 0.4042
2022-10-04 18:39:23 - train: epoch 0089, iter [00500, 01251], lr: 0.000024, loss: 0.4088
2022-10-04 18:39:42 - train: epoch 0089, iter [00510, 01251], lr: 0.000024, loss: 0.3948
2022-10-04 18:40:01 - train: epoch 0089, iter [00520, 01251], lr: 0.000024, loss: 0.4061
2022-10-04 18:40:19 - train: epoch 0089, iter [00530, 01251], lr: 0.000024, loss: 0.3834
2022-10-04 18:40:38 - train: epoch 0089, iter [00540, 01251], lr: 0.000024, loss: 0.4085
2022-10-04 18:40:57 - train: epoch 0089, iter [00550, 01251], lr: 0.000024, loss: 0.3884
2022-10-04 18:41:16 - train: epoch 0089, iter [00560, 01251], lr: 0.000024, loss: 0.3961
2022-10-04 18:41:35 - train: epoch 0089, iter [00570, 01251], lr: 0.000024, loss: 0.4058
2022-10-04 18:41:54 - train: epoch 0089, iter [00580, 01251], lr: 0.000024, loss: 0.3989
2022-10-04 18:42:13 - train: epoch 0089, iter [00590, 01251], lr: 0.000024, loss: 0.4057
2022-10-04 18:42:33 - train: epoch 0089, iter [00600, 01251], lr: 0.000024, loss: 0.4306
2022-10-04 18:42:52 - train: epoch 0089, iter [00610, 01251], lr: 0.000024, loss: 0.4160
2022-10-04 18:43:11 - train: epoch 0089, iter [00620, 01251], lr: 0.000024, loss: 0.3965
2022-10-04 18:43:30 - train: epoch 0089, iter [00630, 01251], lr: 0.000024, loss: 0.4023
2022-10-04 18:43:49 - train: epoch 0089, iter [00640, 01251], lr: 0.000024, loss: 0.3910
2022-10-04 18:44:07 - train: epoch 0089, iter [00650, 01251], lr: 0.000024, loss: 0.4137
2022-10-04 18:44:26 - train: epoch 0089, iter [00660, 01251], lr: 0.000024, loss: 0.3928
2022-10-04 18:44:45 - train: epoch 0089, iter [00670, 01251], lr: 0.000024, loss: 0.3711
2022-10-04 18:45:04 - train: epoch 0089, iter [00680, 01251], lr: 0.000024, loss: 0.3893
2022-10-04 18:45:23 - train: epoch 0089, iter [00690, 01251], lr: 0.000024, loss: 0.4143
2022-10-04 18:45:41 - train: epoch 0089, iter [00700, 01251], lr: 0.000024, loss: 0.4093
2022-10-04 18:46:00 - train: epoch 0089, iter [00710, 01251], lr: 0.000024, loss: 0.3857
2022-10-04 18:46:19 - train: epoch 0089, iter [00720, 01251], lr: 0.000024, loss: 0.4064
2022-10-04 18:46:38 - train: epoch 0089, iter [00730, 01251], lr: 0.000024, loss: 0.3813
2022-10-04 18:46:58 - train: epoch 0089, iter [00740, 01251], lr: 0.000023, loss: 0.3969
2022-10-04 18:47:17 - train: epoch 0089, iter [00750, 01251], lr: 0.000023, loss: 0.3804
2022-10-04 18:47:36 - train: epoch 0089, iter [00760, 01251], lr: 0.000023, loss: 0.4056
2022-10-04 18:47:55 - train: epoch 0089, iter [00770, 01251], lr: 0.000023, loss: 0.4064
2022-10-04 18:48:14 - train: epoch 0089, iter [00780, 01251], lr: 0.000023, loss: 0.3969
2022-10-04 18:48:33 - train: epoch 0089, iter [00790, 01251], lr: 0.000023, loss: 0.4034
2022-10-04 18:48:52 - train: epoch 0089, iter [00800, 01251], lr: 0.000023, loss: 0.3971
2022-10-04 18:49:10 - train: epoch 0089, iter [00810, 01251], lr: 0.000023, loss: 0.4059
2022-10-04 18:49:30 - train: epoch 0089, iter [00820, 01251], lr: 0.000023, loss: 0.4207
2022-10-04 18:49:48 - train: epoch 0089, iter [00830, 01251], lr: 0.000023, loss: 0.3872
2022-10-04 18:50:07 - train: epoch 0089, iter [00840, 01251], lr: 0.000023, loss: 0.4175
2022-10-04 18:50:26 - train: epoch 0089, iter [00850, 01251], lr: 0.000023, loss: 0.4129
2022-10-04 18:50:45 - train: epoch 0089, iter [00860, 01251], lr: 0.000023, loss: 0.3999
2022-10-04 18:51:04 - train: epoch 0089, iter [00870, 01251], lr: 0.000023, loss: 0.3884
2022-10-04 18:51:24 - train: epoch 0089, iter [00880, 01251], lr: 0.000023, loss: 0.3802
2022-10-04 18:51:44 - train: epoch 0089, iter [00890, 01251], lr: 0.000023, loss: 0.4031
2022-10-04 18:52:03 - train: epoch 0089, iter [00900, 01251], lr: 0.000023, loss: 0.3904
2022-10-04 18:52:22 - train: epoch 0089, iter [00910, 01251], lr: 0.000023, loss: 0.3904
2022-10-04 18:52:41 - train: epoch 0089, iter [00920, 01251], lr: 0.000023, loss: 0.3774
2022-10-04 18:53:00 - train: epoch 0089, iter [00930, 01251], lr: 0.000023, loss: 0.3967
2022-10-04 18:53:20 - train: epoch 0089, iter [00940, 01251], lr: 0.000023, loss: 0.3843
2022-10-04 18:53:38 - train: epoch 0089, iter [00950, 01251], lr: 0.000023, loss: 0.3946
2022-10-04 18:53:58 - train: epoch 0089, iter [00960, 01251], lr: 0.000023, loss: 0.3922
2022-10-04 18:54:17 - train: epoch 0089, iter [00970, 01251], lr: 0.000023, loss: 0.3765
2022-10-04 18:54:36 - train: epoch 0089, iter [00980, 01251], lr: 0.000023, loss: 0.4090
2022-10-04 18:54:55 - train: epoch 0089, iter [00990, 01251], lr: 0.000023, loss: 0.3904
2022-10-04 18:55:14 - train: epoch 0089, iter [01000, 01251], lr: 0.000023, loss: 0.4103
2022-10-04 18:55:33 - train: epoch 0089, iter [01010, 01251], lr: 0.000023, loss: 0.4189
2022-10-04 18:55:52 - train: epoch 0089, iter [01020, 01251], lr: 0.000023, loss: 0.4252
2022-10-04 18:56:11 - train: epoch 0089, iter [01030, 01251], lr: 0.000023, loss: 0.4046
2022-10-04 18:56:30 - train: epoch 0089, iter [01040, 01251], lr: 0.000023, loss: 0.4043
2022-10-04 18:56:49 - train: epoch 0089, iter [01050, 01251], lr: 0.000022, loss: 0.3956
2022-10-04 18:57:08 - train: epoch 0089, iter [01060, 01251], lr: 0.000022, loss: 0.3968
2022-10-04 18:57:27 - train: epoch 0089, iter [01070, 01251], lr: 0.000022, loss: 0.4205
2022-10-04 18:57:46 - train: epoch 0089, iter [01080, 01251], lr: 0.000022, loss: 0.4016
2022-10-04 18:58:05 - train: epoch 0089, iter [01090, 01251], lr: 0.000022, loss: 0.3996
2022-10-04 18:58:25 - train: epoch 0089, iter [01100, 01251], lr: 0.000022, loss: 0.3891
2022-10-04 18:58:43 - train: epoch 0089, iter [01110, 01251], lr: 0.000022, loss: 0.3958
2022-10-04 18:59:02 - train: epoch 0089, iter [01120, 01251], lr: 0.000022, loss: 0.3998
2022-10-04 18:59:21 - train: epoch 0089, iter [01130, 01251], lr: 0.000022, loss: 0.4140
2022-10-04 18:59:40 - train: epoch 0089, iter [01140, 01251], lr: 0.000022, loss: 0.3867
2022-10-04 18:59:59 - train: epoch 0089, iter [01150, 01251], lr: 0.000022, loss: 0.3969
2022-10-04 19:00:18 - train: epoch 0089, iter [01160, 01251], lr: 0.000022, loss: 0.3845
2022-10-04 19:00:37 - train: epoch 0089, iter [01170, 01251], lr: 0.000022, loss: 0.4108
2022-10-04 19:00:57 - train: epoch 0089, iter [01180, 01251], lr: 0.000022, loss: 0.3835
2022-10-04 19:01:16 - train: epoch 0089, iter [01190, 01251], lr: 0.000022, loss: 0.3899
2022-10-04 19:01:35 - train: epoch 0089, iter [01200, 01251], lr: 0.000022, loss: 0.4324
2022-10-04 19:01:54 - train: epoch 0089, iter [01210, 01251], lr: 0.000022, loss: 0.3751
2022-10-04 19:02:14 - train: epoch 0089, iter [01220, 01251], lr: 0.000022, loss: 0.3837
2022-10-04 19:02:33 - train: epoch 0089, iter [01230, 01251], lr: 0.000022, loss: 0.3898
2022-10-04 19:02:52 - train: epoch 0089, iter [01240, 01251], lr: 0.000022, loss: 0.4041
2022-10-04 19:03:10 - train: epoch 0089, iter [01250, 01251], lr: 0.000022, loss: 0.4048
2022-10-04 19:03:16 - train: epoch 089, train_loss: 0.3994
2022-10-04 19:03:19 - until epoch: 089, best_loss: 0.3994
2022-10-04 19:03:19 - epoch 090 lr: 0.000022
2022-10-04 19:03:46 - train: epoch 0090, iter [00010, 01251], lr: 0.000022, loss: 0.3827
2022-10-04 19:04:05 - train: epoch 0090, iter [00020, 01251], lr: 0.000022, loss: 0.3950
2022-10-04 19:04:25 - train: epoch 0090, iter [00030, 01251], lr: 0.000022, loss: 0.4028
2022-10-04 19:04:45 - train: epoch 0090, iter [00040, 01251], lr: 0.000022, loss: 0.4079
2022-10-04 19:05:04 - train: epoch 0090, iter [00050, 01251], lr: 0.000022, loss: 0.3952
2022-10-04 19:05:23 - train: epoch 0090, iter [00060, 01251], lr: 0.000022, loss: 0.4027
2022-10-04 19:05:42 - train: epoch 0090, iter [00070, 01251], lr: 0.000022, loss: 0.4266
2022-10-04 19:06:01 - train: epoch 0090, iter [00080, 01251], lr: 0.000022, loss: 0.4039
2022-10-04 19:06:20 - train: epoch 0090, iter [00090, 01251], lr: 0.000022, loss: 0.3802
2022-10-04 19:06:39 - train: epoch 0090, iter [00100, 01251], lr: 0.000022, loss: 0.3988
2022-10-04 19:06:58 - train: epoch 0090, iter [00110, 01251], lr: 0.000022, loss: 0.3987
2022-10-04 19:07:17 - train: epoch 0090, iter [00120, 01251], lr: 0.000021, loss: 0.4131
2022-10-04 19:07:36 - train: epoch 0090, iter [00130, 01251], lr: 0.000021, loss: 0.4074
2022-10-04 19:07:55 - train: epoch 0090, iter [00140, 01251], lr: 0.000021, loss: 0.4065
2022-10-04 19:08:14 - train: epoch 0090, iter [00150, 01251], lr: 0.000021, loss: 0.4141
2022-10-04 19:08:33 - train: epoch 0090, iter [00160, 01251], lr: 0.000021, loss: 0.4115
2022-10-04 19:08:52 - train: epoch 0090, iter [00170, 01251], lr: 0.000021, loss: 0.4184
2022-10-04 19:09:11 - train: epoch 0090, iter [00180, 01251], lr: 0.000021, loss: 0.4197
2022-10-04 19:09:30 - train: epoch 0090, iter [00190, 01251], lr: 0.000021, loss: 0.4253
2022-10-04 19:09:49 - train: epoch 0090, iter [00200, 01251], lr: 0.000021, loss: 0.4023
2022-10-04 19:10:08 - train: epoch 0090, iter [00210, 01251], lr: 0.000021, loss: 0.4070
2022-10-04 19:10:27 - train: epoch 0090, iter [00220, 01251], lr: 0.000021, loss: 0.3844
2022-10-04 19:10:46 - train: epoch 0090, iter [00230, 01251], lr: 0.000021, loss: 0.3833
2022-10-04 19:11:05 - train: epoch 0090, iter [00240, 01251], lr: 0.000021, loss: 0.3946
2022-10-04 19:11:24 - train: epoch 0090, iter [00250, 01251], lr: 0.000021, loss: 0.4081
2022-10-04 19:11:43 - train: epoch 0090, iter [00260, 01251], lr: 0.000021, loss: 0.3972
2022-10-04 19:12:02 - train: epoch 0090, iter [00270, 01251], lr: 0.000021, loss: 0.3984
2022-10-04 19:12:21 - train: epoch 0090, iter [00280, 01251], lr: 0.000021, loss: 0.3822
2022-10-04 19:12:40 - train: epoch 0090, iter [00290, 01251], lr: 0.000021, loss: 0.3974
2022-10-04 19:12:59 - train: epoch 0090, iter [00300, 01251], lr: 0.000021, loss: 0.3919
2022-10-04 19:13:18 - train: epoch 0090, iter [00310, 01251], lr: 0.000021, loss: 0.4263
2022-10-04 19:13:37 - train: epoch 0090, iter [00320, 01251], lr: 0.000021, loss: 0.3867
2022-10-04 19:13:56 - train: epoch 0090, iter [00330, 01251], lr: 0.000021, loss: 0.3933
2022-10-04 19:14:15 - train: epoch 0090, iter [00340, 01251], lr: 0.000021, loss: 0.3914
2022-10-04 19:14:34 - train: epoch 0090, iter [00350, 01251], lr: 0.000021, loss: 0.4034
2022-10-04 19:14:52 - train: epoch 0090, iter [00360, 01251], lr: 0.000021, loss: 0.3964
2022-10-04 19:15:12 - train: epoch 0090, iter [00370, 01251], lr: 0.000021, loss: 0.4186
2022-10-04 19:15:31 - train: epoch 0090, iter [00380, 01251], lr: 0.000021, loss: 0.3946
2022-10-04 19:15:50 - train: epoch 0090, iter [00390, 01251], lr: 0.000021, loss: 0.4046
2022-10-04 19:16:09 - train: epoch 0090, iter [00400, 01251], lr: 0.000021, loss: 0.3780
2022-10-04 19:16:28 - train: epoch 0090, iter [00410, 01251], lr: 0.000021, loss: 0.3779
2022-10-04 19:16:46 - train: epoch 0090, iter [00420, 01251], lr: 0.000021, loss: 0.4049
2022-10-04 19:17:06 - train: epoch 0090, iter [00430, 01251], lr: 0.000021, loss: 0.4162
2022-10-04 19:17:25 - train: epoch 0090, iter [00440, 01251], lr: 0.000020, loss: 0.3962
2022-10-04 19:17:44 - train: epoch 0090, iter [00450, 01251], lr: 0.000020, loss: 0.4076
2022-10-04 19:18:03 - train: epoch 0090, iter [00460, 01251], lr: 0.000020, loss: 0.4134
2022-10-04 19:18:22 - train: epoch 0090, iter [00470, 01251], lr: 0.000020, loss: 0.4001
2022-10-04 19:18:41 - train: epoch 0090, iter [00480, 01251], lr: 0.000020, loss: 0.3946
2022-10-04 19:19:00 - train: epoch 0090, iter [00490, 01251], lr: 0.000020, loss: 0.4056
2022-10-04 19:19:19 - train: epoch 0090, iter [00500, 01251], lr: 0.000020, loss: 0.4030
2022-10-04 19:19:38 - train: epoch 0090, iter [00510, 01251], lr: 0.000020, loss: 0.4002
2022-10-04 19:19:57 - train: epoch 0090, iter [00520, 01251], lr: 0.000020, loss: 0.4030
2022-10-04 19:20:16 - train: epoch 0090, iter [00530, 01251], lr: 0.000020, loss: 0.4031
2022-10-04 19:20:35 - train: epoch 0090, iter [00540, 01251], lr: 0.000020, loss: 0.3990
2022-10-04 19:20:53 - train: epoch 0090, iter [00550, 01251], lr: 0.000020, loss: 0.4093
2022-10-04 19:21:12 - train: epoch 0090, iter [00560, 01251], lr: 0.000020, loss: 0.3828
2022-10-04 19:21:31 - train: epoch 0090, iter [00570, 01251], lr: 0.000020, loss: 0.3880
2022-10-04 19:21:50 - train: epoch 0090, iter [00580, 01251], lr: 0.000020, loss: 0.3914
2022-10-04 19:22:09 - train: epoch 0090, iter [00590, 01251], lr: 0.000020, loss: 0.4129
2022-10-04 19:22:28 - train: epoch 0090, iter [00600, 01251], lr: 0.000020, loss: 0.4041
2022-10-04 19:22:47 - train: epoch 0090, iter [00610, 01251], lr: 0.000020, loss: 0.3942
2022-10-04 19:23:06 - train: epoch 0090, iter [00620, 01251], lr: 0.000020, loss: 0.3936
2022-10-04 19:23:25 - train: epoch 0090, iter [00630, 01251], lr: 0.000020, loss: 0.3967
2022-10-04 19:23:44 - train: epoch 0090, iter [00640, 01251], lr: 0.000020, loss: 0.4036
2022-10-04 19:24:03 - train: epoch 0090, iter [00650, 01251], lr: 0.000020, loss: 0.3812
2022-10-04 19:24:22 - train: epoch 0090, iter [00660, 01251], lr: 0.000020, loss: 0.4057
2022-10-04 19:24:41 - train: epoch 0090, iter [00670, 01251], lr: 0.000020, loss: 0.3935
2022-10-04 19:24:59 - train: epoch 0090, iter [00680, 01251], lr: 0.000020, loss: 0.3944
2022-10-04 19:25:18 - train: epoch 0090, iter [00690, 01251], lr: 0.000020, loss: 0.4193
2022-10-04 19:25:37 - train: epoch 0090, iter [00700, 01251], lr: 0.000020, loss: 0.4001
2022-10-04 19:25:56 - train: epoch 0090, iter [00710, 01251], lr: 0.000020, loss: 0.3945
2022-10-04 19:26:15 - train: epoch 0090, iter [00720, 01251], lr: 0.000020, loss: 0.3958
2022-10-04 19:26:35 - train: epoch 0090, iter [00730, 01251], lr: 0.000020, loss: 0.3972
2022-10-04 19:26:54 - train: epoch 0090, iter [00740, 01251], lr: 0.000020, loss: 0.4014
2022-10-04 19:27:12 - train: epoch 0090, iter [00750, 01251], lr: 0.000020, loss: 0.4115
2022-10-04 19:27:32 - train: epoch 0090, iter [00760, 01251], lr: 0.000020, loss: 0.3783
2022-10-04 19:27:51 - train: epoch 0090, iter [00770, 01251], lr: 0.000019, loss: 0.3971
2022-10-04 19:28:10 - train: epoch 0090, iter [00780, 01251], lr: 0.000019, loss: 0.4200
2022-10-04 19:28:29 - train: epoch 0090, iter [00790, 01251], lr: 0.000019, loss: 0.4032
2022-10-04 19:28:48 - train: epoch 0090, iter [00800, 01251], lr: 0.000019, loss: 0.3993
2022-10-04 19:29:07 - train: epoch 0090, iter [00810, 01251], lr: 0.000019, loss: 0.4063
2022-10-04 19:29:25 - train: epoch 0090, iter [00820, 01251], lr: 0.000019, loss: 0.4115
2022-10-04 19:29:44 - train: epoch 0090, iter [00830, 01251], lr: 0.000019, loss: 0.3908
2022-10-04 19:30:03 - train: epoch 0090, iter [00840, 01251], lr: 0.000019, loss: 0.4050
2022-10-04 19:30:22 - train: epoch 0090, iter [00850, 01251], lr: 0.000019, loss: 0.4123
2022-10-04 19:30:41 - train: epoch 0090, iter [00860, 01251], lr: 0.000019, loss: 0.3829
2022-10-04 19:31:00 - train: epoch 0090, iter [00870, 01251], lr: 0.000019, loss: 0.4036
2022-10-04 19:31:19 - train: epoch 0090, iter [00880, 01251], lr: 0.000019, loss: 0.3944
2022-10-04 19:31:38 - train: epoch 0090, iter [00890, 01251], lr: 0.000019, loss: 0.3832
2022-10-04 19:31:57 - train: epoch 0090, iter [00900, 01251], lr: 0.000019, loss: 0.4215
2022-10-04 19:32:16 - train: epoch 0090, iter [00910, 01251], lr: 0.000019, loss: 0.3838
2022-10-04 19:32:34 - train: epoch 0090, iter [00920, 01251], lr: 0.000019, loss: 0.3914
2022-10-04 19:32:53 - train: epoch 0090, iter [00930, 01251], lr: 0.000019, loss: 0.3947
2022-10-04 19:33:12 - train: epoch 0090, iter [00940, 01251], lr: 0.000019, loss: 0.3801
2022-10-04 19:33:30 - train: epoch 0090, iter [00950, 01251], lr: 0.000019, loss: 0.4010
2022-10-04 19:33:49 - train: epoch 0090, iter [00960, 01251], lr: 0.000019, loss: 0.4002
2022-10-04 19:34:08 - train: epoch 0090, iter [00970, 01251], lr: 0.000019, loss: 0.4096
2022-10-04 19:34:27 - train: epoch 0090, iter [00980, 01251], lr: 0.000019, loss: 0.4057
2022-10-04 19:34:46 - train: epoch 0090, iter [00990, 01251], lr: 0.000019, loss: 0.4161
2022-10-04 19:35:05 - train: epoch 0090, iter [01000, 01251], lr: 0.000019, loss: 0.3987
2022-10-04 19:35:25 - train: epoch 0090, iter [01010, 01251], lr: 0.000019, loss: 0.4116
2022-10-04 19:35:43 - train: epoch 0090, iter [01020, 01251], lr: 0.000019, loss: 0.4054
2022-10-04 19:36:02 - train: epoch 0090, iter [01030, 01251], lr: 0.000019, loss: 0.4265
2022-10-04 19:36:21 - train: epoch 0090, iter [01040, 01251], lr: 0.000019, loss: 0.4152
2022-10-04 19:36:40 - train: epoch 0090, iter [01050, 01251], lr: 0.000019, loss: 0.3973
2022-10-04 19:36:59 - train: epoch 0090, iter [01060, 01251], lr: 0.000019, loss: 0.3783
2022-10-04 19:37:17 - train: epoch 0090, iter [01070, 01251], lr: 0.000019, loss: 0.3927
2022-10-04 19:37:36 - train: epoch 0090, iter [01080, 01251], lr: 0.000019, loss: 0.4015
2022-10-04 19:37:55 - train: epoch 0090, iter [01090, 01251], lr: 0.000019, loss: 0.3819
2022-10-04 19:38:14 - train: epoch 0090, iter [01100, 01251], lr: 0.000019, loss: 0.4166
2022-10-04 19:38:33 - train: epoch 0090, iter [01110, 01251], lr: 0.000018, loss: 0.3875
2022-10-04 19:38:52 - train: epoch 0090, iter [01120, 01251], lr: 0.000018, loss: 0.3917
2022-10-04 19:39:10 - train: epoch 0090, iter [01130, 01251], lr: 0.000018, loss: 0.3859
2022-10-04 19:39:29 - train: epoch 0090, iter [01140, 01251], lr: 0.000018, loss: 0.3918
2022-10-04 19:39:48 - train: epoch 0090, iter [01150, 01251], lr: 0.000018, loss: 0.4066
2022-10-04 19:40:07 - train: epoch 0090, iter [01160, 01251], lr: 0.000018, loss: 0.3926
2022-10-04 19:40:26 - train: epoch 0090, iter [01170, 01251], lr: 0.000018, loss: 0.3952
2022-10-04 19:40:45 - train: epoch 0090, iter [01180, 01251], lr: 0.000018, loss: 0.4055
2022-10-04 19:41:04 - train: epoch 0090, iter [01190, 01251], lr: 0.000018, loss: 0.4077
2022-10-04 19:41:22 - train: epoch 0090, iter [01200, 01251], lr: 0.000018, loss: 0.3932
2022-10-04 19:41:41 - train: epoch 0090, iter [01210, 01251], lr: 0.000018, loss: 0.3842
2022-10-04 19:42:00 - train: epoch 0090, iter [01220, 01251], lr: 0.000018, loss: 0.3937
2022-10-04 19:42:19 - train: epoch 0090, iter [01230, 01251], lr: 0.000018, loss: 0.3740
2022-10-04 19:42:38 - train: epoch 0090, iter [01240, 01251], lr: 0.000018, loss: 0.4046
2022-10-04 19:42:56 - train: epoch 0090, iter [01250, 01251], lr: 0.000018, loss: 0.3962
2022-10-04 19:43:01 - train: epoch 090, train_loss: 0.3993
2022-10-04 19:43:05 - until epoch: 090, best_loss: 0.3993
2022-10-04 19:43:05 - epoch 091 lr: 0.000018
2022-10-04 19:43:30 - train: epoch 0091, iter [00010, 01251], lr: 0.000018, loss: 0.4079
2022-10-04 19:43:48 - train: epoch 0091, iter [00020, 01251], lr: 0.000018, loss: 0.4022
2022-10-04 19:44:07 - train: epoch 0091, iter [00030, 01251], lr: 0.000018, loss: 0.3981
2022-10-04 19:44:26 - train: epoch 0091, iter [00040, 01251], lr: 0.000018, loss: 0.4185
2022-10-04 19:44:45 - train: epoch 0091, iter [00050, 01251], lr: 0.000018, loss: 0.3897
2022-10-04 19:45:04 - train: epoch 0091, iter [00060, 01251], lr: 0.000018, loss: 0.3939
2022-10-04 19:45:23 - train: epoch 0091, iter [00070, 01251], lr: 0.000018, loss: 0.4110
2022-10-04 19:45:42 - train: epoch 0091, iter [00080, 01251], lr: 0.000018, loss: 0.3970
2022-10-04 19:46:00 - train: epoch 0091, iter [00090, 01251], lr: 0.000018, loss: 0.4138
2022-10-04 19:46:19 - train: epoch 0091, iter [00100, 01251], lr: 0.000018, loss: 0.4032
2022-10-04 19:46:38 - train: epoch 0091, iter [00110, 01251], lr: 0.000018, loss: 0.4023
2022-10-04 19:46:57 - train: epoch 0091, iter [00120, 01251], lr: 0.000018, loss: 0.4079
2022-10-04 19:47:16 - train: epoch 0091, iter [00130, 01251], lr: 0.000018, loss: 0.3831
2022-10-04 19:47:35 - train: epoch 0091, iter [00140, 01251], lr: 0.000018, loss: 0.4020
2022-10-04 19:47:54 - train: epoch 0091, iter [00150, 01251], lr: 0.000018, loss: 0.3912
2022-10-04 19:48:12 - train: epoch 0091, iter [00160, 01251], lr: 0.000018, loss: 0.4100
2022-10-04 19:48:31 - train: epoch 0091, iter [00170, 01251], lr: 0.000018, loss: 0.4041
2022-10-04 19:48:50 - train: epoch 0091, iter [00180, 01251], lr: 0.000018, loss: 0.3879
2022-10-04 19:49:09 - train: epoch 0091, iter [00190, 01251], lr: 0.000018, loss: 0.3983
2022-10-04 19:49:28 - train: epoch 0091, iter [00200, 01251], lr: 0.000018, loss: 0.3985
2022-10-04 19:49:46 - train: epoch 0091, iter [00210, 01251], lr: 0.000017, loss: 0.3985
2022-10-04 19:50:05 - train: epoch 0091, iter [00220, 01251], lr: 0.000017, loss: 0.3959
2022-10-04 19:50:24 - train: epoch 0091, iter [00230, 01251], lr: 0.000017, loss: 0.4001
2022-10-04 19:50:43 - train: epoch 0091, iter [00240, 01251], lr: 0.000017, loss: 0.4216
2022-10-04 19:51:03 - train: epoch 0091, iter [00250, 01251], lr: 0.000017, loss: 0.3888
2022-10-04 19:51:21 - train: epoch 0091, iter [00260, 01251], lr: 0.000017, loss: 0.4027
2022-10-04 19:51:41 - train: epoch 0091, iter [00270, 01251], lr: 0.000017, loss: 0.3879
2022-10-04 19:52:00 - train: epoch 0091, iter [00280, 01251], lr: 0.000017, loss: 0.4083
2022-10-04 19:52:19 - train: epoch 0091, iter [00290, 01251], lr: 0.000017, loss: 0.3974
2022-10-04 19:52:39 - train: epoch 0091, iter [00300, 01251], lr: 0.000017, loss: 0.3885
2022-10-04 19:52:58 - train: epoch 0091, iter [00310, 01251], lr: 0.000017, loss: 0.3986
2022-10-04 19:53:16 - train: epoch 0091, iter [00320, 01251], lr: 0.000017, loss: 0.4235
2022-10-04 19:53:36 - train: epoch 0091, iter [00330, 01251], lr: 0.000017, loss: 0.4130
2022-10-04 19:53:54 - train: epoch 0091, iter [00340, 01251], lr: 0.000017, loss: 0.3994
2022-10-04 19:54:13 - train: epoch 0091, iter [00350, 01251], lr: 0.000017, loss: 0.3932
2022-10-04 19:54:32 - train: epoch 0091, iter [00360, 01251], lr: 0.000017, loss: 0.3893
2022-10-04 19:54:51 - train: epoch 0091, iter [00370, 01251], lr: 0.000017, loss: 0.3817
2022-10-04 19:55:10 - train: epoch 0091, iter [00380, 01251], lr: 0.000017, loss: 0.3951
2022-10-04 19:55:29 - train: epoch 0091, iter [00390, 01251], lr: 0.000017, loss: 0.3866
2022-10-04 19:55:48 - train: epoch 0091, iter [00400, 01251], lr: 0.000017, loss: 0.3972
2022-10-04 19:56:07 - train: epoch 0091, iter [00410, 01251], lr: 0.000017, loss: 0.3927
2022-10-04 19:56:26 - train: epoch 0091, iter [00420, 01251], lr: 0.000017, loss: 0.3802
2022-10-04 19:56:45 - train: epoch 0091, iter [00430, 01251], lr: 0.000017, loss: 0.4193
2022-10-04 19:57:03 - train: epoch 0091, iter [00440, 01251], lr: 0.000017, loss: 0.4067
2022-10-04 19:57:22 - train: epoch 0091, iter [00450, 01251], lr: 0.000017, loss: 0.3935
2022-10-04 19:57:41 - train: epoch 0091, iter [00460, 01251], lr: 0.000017, loss: 0.4040
2022-10-04 19:58:00 - train: epoch 0091, iter [00470, 01251], lr: 0.000017, loss: 0.3752
2022-10-04 19:58:19 - train: epoch 0091, iter [00480, 01251], lr: 0.000017, loss: 0.4023
2022-10-04 19:58:39 - train: epoch 0091, iter [00490, 01251], lr: 0.000017, loss: 0.3983
2022-10-04 19:58:57 - train: epoch 0091, iter [00500, 01251], lr: 0.000017, loss: 0.3823
2022-10-04 19:59:16 - train: epoch 0091, iter [00510, 01251], lr: 0.000017, loss: 0.4262
2022-10-04 19:59:35 - train: epoch 0091, iter [00520, 01251], lr: 0.000017, loss: 0.3968
2022-10-04 19:59:54 - train: epoch 0091, iter [00530, 01251], lr: 0.000017, loss: 0.3993
2022-10-04 20:00:13 - train: epoch 0091, iter [00540, 01251], lr: 0.000017, loss: 0.4023
2022-10-04 20:00:31 - train: epoch 0091, iter [00550, 01251], lr: 0.000017, loss: 0.3763
2022-10-04 20:00:50 - train: epoch 0091, iter [00560, 01251], lr: 0.000017, loss: 0.4183
2022-10-04 20:01:08 - train: epoch 0091, iter [00570, 01251], lr: 0.000016, loss: 0.3741
2022-10-04 20:01:28 - train: epoch 0091, iter [00580, 01251], lr: 0.000016, loss: 0.4015
2022-10-04 20:01:47 - train: epoch 0091, iter [00590, 01251], lr: 0.000016, loss: 0.3890
2022-10-04 20:02:06 - train: epoch 0091, iter [00600, 01251], lr: 0.000016, loss: 0.3935
2022-10-04 20:02:26 - train: epoch 0091, iter [00610, 01251], lr: 0.000016, loss: 0.3972
2022-10-04 20:02:45 - train: epoch 0091, iter [00620, 01251], lr: 0.000016, loss: 0.3932
2022-10-04 20:03:04 - train: epoch 0091, iter [00630, 01251], lr: 0.000016, loss: 0.4027
2022-10-04 20:03:24 - train: epoch 0091, iter [00640, 01251], lr: 0.000016, loss: 0.4038
2022-10-04 20:03:42 - train: epoch 0091, iter [00650, 01251], lr: 0.000016, loss: 0.4034
2022-10-04 20:04:01 - train: epoch 0091, iter [00660, 01251], lr: 0.000016, loss: 0.3920
2022-10-04 20:04:20 - train: epoch 0091, iter [00670, 01251], lr: 0.000016, loss: 0.3923
2022-10-04 20:04:40 - train: epoch 0091, iter [00680, 01251], lr: 0.000016, loss: 0.3882
2022-10-04 20:04:59 - train: epoch 0091, iter [00690, 01251], lr: 0.000016, loss: 0.4094
2022-10-04 20:05:18 - train: epoch 0091, iter [00700, 01251], lr: 0.000016, loss: 0.4005
2022-10-04 20:05:37 - train: epoch 0091, iter [00710, 01251], lr: 0.000016, loss: 0.4002
2022-10-04 20:05:57 - train: epoch 0091, iter [00720, 01251], lr: 0.000016, loss: 0.3966
2022-10-04 20:06:17 - train: epoch 0091, iter [00730, 01251], lr: 0.000016, loss: 0.4027
2022-10-04 20:06:36 - train: epoch 0091, iter [00740, 01251], lr: 0.000016, loss: 0.3937
2022-10-04 20:06:54 - train: epoch 0091, iter [00750, 01251], lr: 0.000016, loss: 0.3972
2022-10-04 20:07:13 - train: epoch 0091, iter [00760, 01251], lr: 0.000016, loss: 0.4076
2022-10-04 20:07:32 - train: epoch 0091, iter [00770, 01251], lr: 0.000016, loss: 0.3820
2022-10-04 20:07:51 - train: epoch 0091, iter [00780, 01251], lr: 0.000016, loss: 0.3850
2022-10-04 20:08:10 - train: epoch 0091, iter [00790, 01251], lr: 0.000016, loss: 0.4076
2022-10-04 20:08:29 - train: epoch 0091, iter [00800, 01251], lr: 0.000016, loss: 0.3892
2022-10-04 20:08:48 - train: epoch 0091, iter [00810, 01251], lr: 0.000016, loss: 0.4194
2022-10-04 20:09:07 - train: epoch 0091, iter [00820, 01251], lr: 0.000016, loss: 0.3996
2022-10-04 20:09:26 - train: epoch 0091, iter [00830, 01251], lr: 0.000016, loss: 0.3901
2022-10-04 20:09:44 - train: epoch 0091, iter [00840, 01251], lr: 0.000016, loss: 0.3765
2022-10-04 20:10:03 - train: epoch 0091, iter [00850, 01251], lr: 0.000016, loss: 0.3920
2022-10-04 20:10:22 - train: epoch 0091, iter [00860, 01251], lr: 0.000016, loss: 0.3706
2022-10-04 20:10:42 - train: epoch 0091, iter [00870, 01251], lr: 0.000016, loss: 0.3998
2022-10-04 20:11:00 - train: epoch 0091, iter [00880, 01251], lr: 0.000016, loss: 0.4049
2022-10-04 20:11:19 - train: epoch 0091, iter [00890, 01251], lr: 0.000016, loss: 0.4018
2022-10-04 20:11:39 - train: epoch 0091, iter [00900, 01251], lr: 0.000016, loss: 0.4242
2022-10-04 20:11:58 - train: epoch 0091, iter [00910, 01251], lr: 0.000016, loss: 0.4062
2022-10-04 20:12:17 - train: epoch 0091, iter [00920, 01251], lr: 0.000016, loss: 0.4026
2022-10-04 20:12:36 - train: epoch 0091, iter [00930, 01251], lr: 0.000016, loss: 0.4009
2022-10-04 20:12:55 - train: epoch 0091, iter [00940, 01251], lr: 0.000015, loss: 0.4123
2022-10-04 20:13:14 - train: epoch 0091, iter [00950, 01251], lr: 0.000015, loss: 0.3903
2022-10-04 20:13:33 - train: epoch 0091, iter [00960, 01251], lr: 0.000015, loss: 0.4093
2022-10-04 20:13:52 - train: epoch 0091, iter [00970, 01251], lr: 0.000015, loss: 0.3823
2022-10-04 20:14:11 - train: epoch 0091, iter [00980, 01251], lr: 0.000015, loss: 0.3854
2022-10-04 20:14:30 - train: epoch 0091, iter [00990, 01251], lr: 0.000015, loss: 0.3923
2022-10-04 20:14:49 - train: epoch 0091, iter [01000, 01251], lr: 0.000015, loss: 0.4079
2022-10-04 20:15:09 - train: epoch 0091, iter [01010, 01251], lr: 0.000015, loss: 0.4169
2022-10-04 20:15:28 - train: epoch 0091, iter [01020, 01251], lr: 0.000015, loss: 0.3853
2022-10-04 20:15:47 - train: epoch 0091, iter [01030, 01251], lr: 0.000015, loss: 0.4044
2022-10-04 20:16:06 - train: epoch 0091, iter [01040, 01251], lr: 0.000015, loss: 0.3850
2022-10-04 20:16:25 - train: epoch 0091, iter [01050, 01251], lr: 0.000015, loss: 0.4153
2022-10-04 20:16:44 - train: epoch 0091, iter [01060, 01251], lr: 0.000015, loss: 0.3950
2022-10-04 20:17:03 - train: epoch 0091, iter [01070, 01251], lr: 0.000015, loss: 0.4068
2022-10-04 20:17:22 - train: epoch 0091, iter [01080, 01251], lr: 0.000015, loss: 0.4052
2022-10-04 20:17:41 - train: epoch 0091, iter [01090, 01251], lr: 0.000015, loss: 0.3910
2022-10-04 20:18:00 - train: epoch 0091, iter [01100, 01251], lr: 0.000015, loss: 0.3956
2022-10-04 20:18:19 - train: epoch 0091, iter [01110, 01251], lr: 0.000015, loss: 0.4023
2022-10-04 20:18:38 - train: epoch 0091, iter [01120, 01251], lr: 0.000015, loss: 0.4010
2022-10-04 20:18:57 - train: epoch 0091, iter [01130, 01251], lr: 0.000015, loss: 0.3893
2022-10-04 20:19:16 - train: epoch 0091, iter [01140, 01251], lr: 0.000015, loss: 0.3946
2022-10-04 20:19:35 - train: epoch 0091, iter [01150, 01251], lr: 0.000015, loss: 0.3966
2022-10-04 20:19:54 - train: epoch 0091, iter [01160, 01251], lr: 0.000015, loss: 0.3980
2022-10-04 20:20:13 - train: epoch 0091, iter [01170, 01251], lr: 0.000015, loss: 0.3983
2022-10-04 20:20:32 - train: epoch 0091, iter [01180, 01251], lr: 0.000015, loss: 0.4022
2022-10-04 20:20:51 - train: epoch 0091, iter [01190, 01251], lr: 0.000015, loss: 0.3930
2022-10-04 20:21:10 - train: epoch 0091, iter [01200, 01251], lr: 0.000015, loss: 0.3893
2022-10-04 20:21:29 - train: epoch 0091, iter [01210, 01251], lr: 0.000015, loss: 0.3835
2022-10-04 20:21:48 - train: epoch 0091, iter [01220, 01251], lr: 0.000015, loss: 0.3875
2022-10-04 20:22:07 - train: epoch 0091, iter [01230, 01251], lr: 0.000015, loss: 0.4036
2022-10-04 20:22:26 - train: epoch 0091, iter [01240, 01251], lr: 0.000015, loss: 0.3768
2022-10-04 20:22:44 - train: epoch 0091, iter [01250, 01251], lr: 0.000015, loss: 0.3938
2022-10-04 20:22:49 - train: epoch 091, train_loss: 0.3990
2022-10-04 20:22:53 - until epoch: 091, best_loss: 0.3990
2022-10-04 20:22:53 - epoch 092 lr: 0.000015
2022-10-04 20:23:18 - train: epoch 0092, iter [00010, 01251], lr: 0.000015, loss: 0.3900
2022-10-04 20:23:37 - train: epoch 0092, iter [00020, 01251], lr: 0.000015, loss: 0.3909
2022-10-04 20:23:56 - train: epoch 0092, iter [00030, 01251], lr: 0.000015, loss: 0.3886
2022-10-04 20:24:15 - train: epoch 0092, iter [00040, 01251], lr: 0.000015, loss: 0.3896
2022-10-04 20:24:34 - train: epoch 0092, iter [00050, 01251], lr: 0.000015, loss: 0.3911
2022-10-04 20:24:53 - train: epoch 0092, iter [00060, 01251], lr: 0.000015, loss: 0.4059
2022-10-04 20:25:12 - train: epoch 0092, iter [00070, 01251], lr: 0.000015, loss: 0.3873
2022-10-04 20:25:31 - train: epoch 0092, iter [00080, 01251], lr: 0.000014, loss: 0.4024
2022-10-04 20:25:50 - train: epoch 0092, iter [00090, 01251], lr: 0.000014, loss: 0.4103
2022-10-04 20:26:09 - train: epoch 0092, iter [00100, 01251], lr: 0.000014, loss: 0.3986
2022-10-04 20:26:28 - train: epoch 0092, iter [00110, 01251], lr: 0.000014, loss: 0.3967
2022-10-04 20:26:47 - train: epoch 0092, iter [00120, 01251], lr: 0.000014, loss: 0.4046
2022-10-04 20:27:06 - train: epoch 0092, iter [00130, 01251], lr: 0.000014, loss: 0.3945
2022-10-04 20:27:25 - train: epoch 0092, iter [00140, 01251], lr: 0.000014, loss: 0.3919
2022-10-04 20:27:44 - train: epoch 0092, iter [00150, 01251], lr: 0.000014, loss: 0.3915
2022-10-04 20:28:03 - train: epoch 0092, iter [00160, 01251], lr: 0.000014, loss: 0.3921
2022-10-04 20:28:22 - train: epoch 0092, iter [00170, 01251], lr: 0.000014, loss: 0.4188
2022-10-04 20:28:41 - train: epoch 0092, iter [00180, 01251], lr: 0.000014, loss: 0.3984
2022-10-04 20:29:01 - train: epoch 0092, iter [00190, 01251], lr: 0.000014, loss: 0.3933
2022-10-04 20:29:20 - train: epoch 0092, iter [00200, 01251], lr: 0.000014, loss: 0.4075
2022-10-04 20:29:39 - train: epoch 0092, iter [00210, 01251], lr: 0.000014, loss: 0.4026
2022-10-04 20:29:58 - train: epoch 0092, iter [00220, 01251], lr: 0.000014, loss: 0.3994
2022-10-04 20:30:17 - train: epoch 0092, iter [00230, 01251], lr: 0.000014, loss: 0.3951
2022-10-04 20:30:36 - train: epoch 0092, iter [00240, 01251], lr: 0.000014, loss: 0.3967
2022-10-04 20:30:56 - train: epoch 0092, iter [00250, 01251], lr: 0.000014, loss: 0.3957
2022-10-04 20:31:15 - train: epoch 0092, iter [00260, 01251], lr: 0.000014, loss: 0.3872
2022-10-04 20:31:34 - train: epoch 0092, iter [00270, 01251], lr: 0.000014, loss: 0.3964
2022-10-04 20:31:53 - train: epoch 0092, iter [00280, 01251], lr: 0.000014, loss: 0.4075
2022-10-04 20:32:13 - train: epoch 0092, iter [00290, 01251], lr: 0.000014, loss: 0.4140
2022-10-04 20:32:32 - train: epoch 0092, iter [00300, 01251], lr: 0.000014, loss: 0.4001
2022-10-04 20:32:51 - train: epoch 0092, iter [00310, 01251], lr: 0.000014, loss: 0.3889
2022-10-04 20:33:10 - train: epoch 0092, iter [00320, 01251], lr: 0.000014, loss: 0.3967
2022-10-04 20:33:29 - train: epoch 0092, iter [00330, 01251], lr: 0.000014, loss: 0.3958
2022-10-04 20:33:49 - train: epoch 0092, iter [00340, 01251], lr: 0.000014, loss: 0.4071
2022-10-04 20:34:08 - train: epoch 0092, iter [00350, 01251], lr: 0.000014, loss: 0.4061
2022-10-04 20:34:28 - train: epoch 0092, iter [00360, 01251], lr: 0.000014, loss: 0.4030
2022-10-04 20:34:47 - train: epoch 0092, iter [00370, 01251], lr: 0.000014, loss: 0.4042
2022-10-04 20:35:06 - train: epoch 0092, iter [00380, 01251], lr: 0.000014, loss: 0.4003
2022-10-04 20:35:26 - train: epoch 0092, iter [00390, 01251], lr: 0.000014, loss: 0.4079
2022-10-04 20:35:45 - train: epoch 0092, iter [00400, 01251], lr: 0.000014, loss: 0.4089
2022-10-04 20:36:04 - train: epoch 0092, iter [00410, 01251], lr: 0.000014, loss: 0.3866
2022-10-04 20:36:23 - train: epoch 0092, iter [00420, 01251], lr: 0.000014, loss: 0.3936
2022-10-04 20:36:43 - train: epoch 0092, iter [00430, 01251], lr: 0.000014, loss: 0.4043
2022-10-04 20:37:02 - train: epoch 0092, iter [00440, 01251], lr: 0.000014, loss: 0.3937
2022-10-04 20:37:21 - train: epoch 0092, iter [00450, 01251], lr: 0.000014, loss: 0.3993
2022-10-04 20:37:41 - train: epoch 0092, iter [00460, 01251], lr: 0.000014, loss: 0.4046
2022-10-04 20:38:00 - train: epoch 0092, iter [00470, 01251], lr: 0.000013, loss: 0.4151
2022-10-04 20:38:19 - train: epoch 0092, iter [00480, 01251], lr: 0.000013, loss: 0.3962
2022-10-04 20:38:38 - train: epoch 0092, iter [00490, 01251], lr: 0.000013, loss: 0.3860
2022-10-04 20:38:57 - train: epoch 0092, iter [00500, 01251], lr: 0.000013, loss: 0.4006
2022-10-04 20:39:17 - train: epoch 0092, iter [00510, 01251], lr: 0.000013, loss: 0.3974
2022-10-04 20:39:36 - train: epoch 0092, iter [00520, 01251], lr: 0.000013, loss: 0.3874
2022-10-04 20:39:56 - train: epoch 0092, iter [00530, 01251], lr: 0.000013, loss: 0.4101
2022-10-04 20:40:15 - train: epoch 0092, iter [00540, 01251], lr: 0.000013, loss: 0.4047
2022-10-04 20:40:34 - train: epoch 0092, iter [00550, 01251], lr: 0.000013, loss: 0.3851
2022-10-04 20:40:54 - train: epoch 0092, iter [00560, 01251], lr: 0.000013, loss: 0.4278
2022-10-04 20:41:13 - train: epoch 0092, iter [00570, 01251], lr: 0.000013, loss: 0.4021
2022-10-04 20:41:32 - train: epoch 0092, iter [00580, 01251], lr: 0.000013, loss: 0.3827
2022-10-04 20:41:51 - train: epoch 0092, iter [00590, 01251], lr: 0.000013, loss: 0.3876
2022-10-04 20:42:10 - train: epoch 0092, iter [00600, 01251], lr: 0.000013, loss: 0.3816
2022-10-04 20:42:30 - train: epoch 0092, iter [00610, 01251], lr: 0.000013, loss: 0.4012
2022-10-04 20:42:49 - train: epoch 0092, iter [00620, 01251], lr: 0.000013, loss: 0.3972
2022-10-04 20:43:08 - train: epoch 0092, iter [00630, 01251], lr: 0.000013, loss: 0.4085
2022-10-04 20:43:28 - train: epoch 0092, iter [00640, 01251], lr: 0.000013, loss: 0.3970
2022-10-04 20:43:47 - train: epoch 0092, iter [00650, 01251], lr: 0.000013, loss: 0.3881
2022-10-04 20:44:07 - train: epoch 0092, iter [00660, 01251], lr: 0.000013, loss: 0.3902
2022-10-04 20:44:26 - train: epoch 0092, iter [00670, 01251], lr: 0.000013, loss: 0.3771
2022-10-04 20:44:45 - train: epoch 0092, iter [00680, 01251], lr: 0.000013, loss: 0.4277
2022-10-04 20:45:04 - train: epoch 0092, iter [00690, 01251], lr: 0.000013, loss: 0.4043
2022-10-04 20:45:24 - train: epoch 0092, iter [00700, 01251], lr: 0.000013, loss: 0.3979
2022-10-04 20:45:43 - train: epoch 0092, iter [00710, 01251], lr: 0.000013, loss: 0.4011
2022-10-04 20:46:02 - train: epoch 0092, iter [00720, 01251], lr: 0.000013, loss: 0.4099
2022-10-04 20:46:21 - train: epoch 0092, iter [00730, 01251], lr: 0.000013, loss: 0.4121
2022-10-04 20:46:40 - train: epoch 0092, iter [00740, 01251], lr: 0.000013, loss: 0.3850
2022-10-04 20:46:59 - train: epoch 0092, iter [00750, 01251], lr: 0.000013, loss: 0.4006
2022-10-04 20:47:19 - train: epoch 0092, iter [00760, 01251], lr: 0.000013, loss: 0.3863
2022-10-04 20:47:38 - train: epoch 0092, iter [00770, 01251], lr: 0.000013, loss: 0.3903
2022-10-04 20:47:57 - train: epoch 0092, iter [00780, 01251], lr: 0.000013, loss: 0.3817
2022-10-04 20:48:17 - train: epoch 0092, iter [00790, 01251], lr: 0.000013, loss: 0.3974
2022-10-04 20:48:36 - train: epoch 0092, iter [00800, 01251], lr: 0.000013, loss: 0.4036
2022-10-04 20:48:55 - train: epoch 0092, iter [00810, 01251], lr: 0.000013, loss: 0.3928
2022-10-04 20:49:15 - train: epoch 0092, iter [00820, 01251], lr: 0.000013, loss: 0.4036
2022-10-04 20:49:34 - train: epoch 0092, iter [00830, 01251], lr: 0.000013, loss: 0.3930
2022-10-04 20:49:53 - train: epoch 0092, iter [00840, 01251], lr: 0.000013, loss: 0.3990
2022-10-04 20:50:13 - train: epoch 0092, iter [00850, 01251], lr: 0.000013, loss: 0.4093
2022-10-04 20:50:32 - train: epoch 0092, iter [00860, 01251], lr: 0.000013, loss: 0.3910
2022-10-04 20:50:51 - train: epoch 0092, iter [00870, 01251], lr: 0.000013, loss: 0.3880
2022-10-04 20:51:10 - train: epoch 0092, iter [00880, 01251], lr: 0.000012, loss: 0.3966
2022-10-04 20:51:30 - train: epoch 0092, iter [00890, 01251], lr: 0.000012, loss: 0.3960
2022-10-04 20:51:49 - train: epoch 0092, iter [00900, 01251], lr: 0.000012, loss: 0.4049
2022-10-04 20:52:08 - train: epoch 0092, iter [00910, 01251], lr: 0.000012, loss: 0.3862
2022-10-04 20:52:28 - train: epoch 0092, iter [00920, 01251], lr: 0.000012, loss: 0.3928
2022-10-04 20:52:47 - train: epoch 0092, iter [00930, 01251], lr: 0.000012, loss: 0.4123
2022-10-04 20:53:06 - train: epoch 0092, iter [00940, 01251], lr: 0.000012, loss: 0.3941
2022-10-04 20:53:25 - train: epoch 0092, iter [00950, 01251], lr: 0.000012, loss: 0.3941
2022-10-04 20:53:45 - train: epoch 0092, iter [00960, 01251], lr: 0.000012, loss: 0.4052
2022-10-04 20:54:04 - train: epoch 0092, iter [00970, 01251], lr: 0.000012, loss: 0.3995
2022-10-04 20:54:23 - train: epoch 0092, iter [00980, 01251], lr: 0.000012, loss: 0.3805
2022-10-04 20:54:43 - train: epoch 0092, iter [00990, 01251], lr: 0.000012, loss: 0.4008
2022-10-04 20:55:02 - train: epoch 0092, iter [01000, 01251], lr: 0.000012, loss: 0.3947
2022-10-04 20:55:21 - train: epoch 0092, iter [01010, 01251], lr: 0.000012, loss: 0.4327
2022-10-04 20:55:40 - train: epoch 0092, iter [01020, 01251], lr: 0.000012, loss: 0.4016
2022-10-04 20:56:00 - train: epoch 0092, iter [01030, 01251], lr: 0.000012, loss: 0.4054
2022-10-04 20:56:19 - train: epoch 0092, iter [01040, 01251], lr: 0.000012, loss: 0.3873
2022-10-04 20:56:38 - train: epoch 0092, iter [01050, 01251], lr: 0.000012, loss: 0.4081
2022-10-04 20:56:58 - train: epoch 0092, iter [01060, 01251], lr: 0.000012, loss: 0.4206
2022-10-04 20:57:17 - train: epoch 0092, iter [01070, 01251], lr: 0.000012, loss: 0.4063
2022-10-04 20:57:37 - train: epoch 0092, iter [01080, 01251], lr: 0.000012, loss: 0.4057
2022-10-04 20:57:56 - train: epoch 0092, iter [01090, 01251], lr: 0.000012, loss: 0.3712
2022-10-04 20:58:15 - train: epoch 0092, iter [01100, 01251], lr: 0.000012, loss: 0.3856
2022-10-04 20:58:35 - train: epoch 0092, iter [01110, 01251], lr: 0.000012, loss: 0.4128
2022-10-04 20:58:54 - train: epoch 0092, iter [01120, 01251], lr: 0.000012, loss: 0.3876
2022-10-04 20:59:13 - train: epoch 0092, iter [01130, 01251], lr: 0.000012, loss: 0.4076
2022-10-04 20:59:33 - train: epoch 0092, iter [01140, 01251], lr: 0.000012, loss: 0.3900
2022-10-04 20:59:52 - train: epoch 0092, iter [01150, 01251], lr: 0.000012, loss: 0.4034
2022-10-04 21:00:12 - train: epoch 0092, iter [01160, 01251], lr: 0.000012, loss: 0.3756
2022-10-04 21:00:31 - train: epoch 0092, iter [01170, 01251], lr: 0.000012, loss: 0.3939
2022-10-04 21:00:50 - train: epoch 0092, iter [01180, 01251], lr: 0.000012, loss: 0.3984
2022-10-04 21:01:10 - train: epoch 0092, iter [01190, 01251], lr: 0.000012, loss: 0.4203
2022-10-04 21:01:29 - train: epoch 0092, iter [01200, 01251], lr: 0.000012, loss: 0.3964
2022-10-04 21:01:49 - train: epoch 0092, iter [01210, 01251], lr: 0.000012, loss: 0.4036
2022-10-04 21:02:08 - train: epoch 0092, iter [01220, 01251], lr: 0.000012, loss: 0.4014
2022-10-04 21:02:28 - train: epoch 0092, iter [01230, 01251], lr: 0.000012, loss: 0.4028
2022-10-04 21:02:47 - train: epoch 0092, iter [01240, 01251], lr: 0.000012, loss: 0.3763
2022-10-04 21:03:06 - train: epoch 0092, iter [01250, 01251], lr: 0.000012, loss: 0.3953
2022-10-04 21:03:09 - train: epoch 092, train_loss: 0.3990
2022-10-04 21:03:14 - until epoch: 092, best_loss: 0.3990
2022-10-04 21:03:14 - epoch 093 lr: 0.000012
2022-10-04 21:03:39 - train: epoch 0093, iter [00010, 01251], lr: 0.000012, loss: 0.3978
2022-10-04 21:03:59 - train: epoch 0093, iter [00020, 01251], lr: 0.000012, loss: 0.3914
2022-10-04 21:04:18 - train: epoch 0093, iter [00030, 01251], lr: 0.000012, loss: 0.4192
2022-10-04 21:04:37 - train: epoch 0093, iter [00040, 01251], lr: 0.000012, loss: 0.4007
2022-10-04 21:04:56 - train: epoch 0093, iter [00050, 01251], lr: 0.000012, loss: 0.3765
2022-10-04 21:05:15 - train: epoch 0093, iter [00060, 01251], lr: 0.000011, loss: 0.4257
2022-10-04 21:05:35 - train: epoch 0093, iter [00070, 01251], lr: 0.000011, loss: 0.4000
2022-10-04 21:05:54 - train: epoch 0093, iter [00080, 01251], lr: 0.000011, loss: 0.4126
2022-10-04 21:06:13 - train: epoch 0093, iter [00090, 01251], lr: 0.000011, loss: 0.4116
2022-10-04 21:06:32 - train: epoch 0093, iter [00100, 01251], lr: 0.000011, loss: 0.4113
2022-10-04 21:06:51 - train: epoch 0093, iter [00110, 01251], lr: 0.000011, loss: 0.3907
2022-10-04 21:07:11 - train: epoch 0093, iter [00120, 01251], lr: 0.000011, loss: 0.3969
2022-10-04 21:07:29 - train: epoch 0093, iter [00130, 01251], lr: 0.000011, loss: 0.3840
2022-10-04 21:07:48 - train: epoch 0093, iter [00140, 01251], lr: 0.000011, loss: 0.3992
2022-10-04 21:08:07 - train: epoch 0093, iter [00150, 01251], lr: 0.000011, loss: 0.3895
2022-10-04 21:08:27 - train: epoch 0093, iter [00160, 01251], lr: 0.000011, loss: 0.3993
2022-10-04 21:08:46 - train: epoch 0093, iter [00170, 01251], lr: 0.000011, loss: 0.4051
2022-10-04 21:09:05 - train: epoch 0093, iter [00180, 01251], lr: 0.000011, loss: 0.4127
2022-10-04 21:09:24 - train: epoch 0093, iter [00190, 01251], lr: 0.000011, loss: 0.3974
2022-10-04 21:09:43 - train: epoch 0093, iter [00200, 01251], lr: 0.000011, loss: 0.4137
2022-10-04 21:10:02 - train: epoch 0093, iter [00210, 01251], lr: 0.000011, loss: 0.3835
2022-10-04 21:10:21 - train: epoch 0093, iter [00220, 01251], lr: 0.000011, loss: 0.3987
2022-10-04 21:10:40 - train: epoch 0093, iter [00230, 01251], lr: 0.000011, loss: 0.3812
2022-10-04 21:10:58 - train: epoch 0093, iter [00240, 01251], lr: 0.000011, loss: 0.4069
2022-10-04 21:11:17 - train: epoch 0093, iter [00250, 01251], lr: 0.000011, loss: 0.4128
2022-10-04 21:11:37 - train: epoch 0093, iter [00260, 01251], lr: 0.000011, loss: 0.3883
2022-10-04 21:11:56 - train: epoch 0093, iter [00270, 01251], lr: 0.000011, loss: 0.4088
2022-10-04 21:12:15 - train: epoch 0093, iter [00280, 01251], lr: 0.000011, loss: 0.4132
2022-10-04 21:12:34 - train: epoch 0093, iter [00290, 01251], lr: 0.000011, loss: 0.4075
2022-10-04 21:12:53 - train: epoch 0093, iter [00300, 01251], lr: 0.000011, loss: 0.4167
2022-10-04 21:13:12 - train: epoch 0093, iter [00310, 01251], lr: 0.000011, loss: 0.4068
2022-10-04 21:13:32 - train: epoch 0093, iter [00320, 01251], lr: 0.000011, loss: 0.3909
2022-10-04 21:13:51 - train: epoch 0093, iter [00330, 01251], lr: 0.000011, loss: 0.3876
2022-10-04 21:14:10 - train: epoch 0093, iter [00340, 01251], lr: 0.000011, loss: 0.4012
2022-10-04 21:14:29 - train: epoch 0093, iter [00350, 01251], lr: 0.000011, loss: 0.4009
2022-10-04 21:14:48 - train: epoch 0093, iter [00360, 01251], lr: 0.000011, loss: 0.3842
2022-10-04 21:15:07 - train: epoch 0093, iter [00370, 01251], lr: 0.000011, loss: 0.4006
2022-10-04 21:15:26 - train: epoch 0093, iter [00380, 01251], lr: 0.000011, loss: 0.3940
2022-10-04 21:15:45 - train: epoch 0093, iter [00390, 01251], lr: 0.000011, loss: 0.3891
2022-10-04 21:16:03 - train: epoch 0093, iter [00400, 01251], lr: 0.000011, loss: 0.4072
2022-10-04 21:16:22 - train: epoch 0093, iter [00410, 01251], lr: 0.000011, loss: 0.4026
2022-10-04 21:16:41 - train: epoch 0093, iter [00420, 01251], lr: 0.000011, loss: 0.4055
2022-10-04 21:16:59 - train: epoch 0093, iter [00430, 01251], lr: 0.000011, loss: 0.3995
2022-10-04 21:17:18 - train: epoch 0093, iter [00440, 01251], lr: 0.000011, loss: 0.3970
2022-10-04 21:17:37 - train: epoch 0093, iter [00450, 01251], lr: 0.000011, loss: 0.4041
2022-10-04 21:17:56 - train: epoch 0093, iter [00460, 01251], lr: 0.000011, loss: 0.3866
2022-10-04 21:18:15 - train: epoch 0093, iter [00470, 01251], lr: 0.000011, loss: 0.3868
2022-10-04 21:18:34 - train: epoch 0093, iter [00480, 01251], lr: 0.000011, loss: 0.3978
2022-10-04 21:18:53 - train: epoch 0093, iter [00490, 01251], lr: 0.000011, loss: 0.4005
2022-10-04 21:19:11 - train: epoch 0093, iter [00500, 01251], lr: 0.000010, loss: 0.3802
2022-10-04 21:19:31 - train: epoch 0093, iter [00510, 01251], lr: 0.000010, loss: 0.3930
2022-10-04 21:19:50 - train: epoch 0093, iter [00520, 01251], lr: 0.000010, loss: 0.4141
2022-10-04 21:20:08 - train: epoch 0093, iter [00530, 01251], lr: 0.000010, loss: 0.3838
2022-10-04 21:20:27 - train: epoch 0093, iter [00540, 01251], lr: 0.000010, loss: 0.3836
2022-10-04 21:20:46 - train: epoch 0093, iter [00550, 01251], lr: 0.000010, loss: 0.4067
2022-10-04 21:21:05 - train: epoch 0093, iter [00560, 01251], lr: 0.000010, loss: 0.3926
2022-10-04 21:21:24 - train: epoch 0093, iter [00570, 01251], lr: 0.000010, loss: 0.3973
2022-10-04 21:21:43 - train: epoch 0093, iter [00580, 01251], lr: 0.000010, loss: 0.4065
2022-10-04 21:22:02 - train: epoch 0093, iter [00590, 01251], lr: 0.000010, loss: 0.4140
2022-10-04 21:22:21 - train: epoch 0093, iter [00600, 01251], lr: 0.000010, loss: 0.4139
2022-10-04 21:22:40 - train: epoch 0093, iter [00610, 01251], lr: 0.000010, loss: 0.4101
2022-10-04 21:22:59 - train: epoch 0093, iter [00620, 01251], lr: 0.000010, loss: 0.3673
2022-10-04 21:23:18 - train: epoch 0093, iter [00630, 01251], lr: 0.000010, loss: 0.4069
2022-10-04 21:23:37 - train: epoch 0093, iter [00640, 01251], lr: 0.000010, loss: 0.3988
2022-10-04 21:23:56 - train: epoch 0093, iter [00650, 01251], lr: 0.000010, loss: 0.3973
2022-10-04 21:24:16 - train: epoch 0093, iter [00660, 01251], lr: 0.000010, loss: 0.4085
2022-10-04 21:24:34 - train: epoch 0093, iter [00670, 01251], lr: 0.000010, loss: 0.4033
2022-10-04 21:24:53 - train: epoch 0093, iter [00680, 01251], lr: 0.000010, loss: 0.3982
2022-10-04 21:25:13 - train: epoch 0093, iter [00690, 01251], lr: 0.000010, loss: 0.4159
2022-10-04 21:25:32 - train: epoch 0093, iter [00700, 01251], lr: 0.000010, loss: 0.3991
2022-10-04 21:25:51 - train: epoch 0093, iter [00710, 01251], lr: 0.000010, loss: 0.4010
2022-10-04 21:26:10 - train: epoch 0093, iter [00720, 01251], lr: 0.000010, loss: 0.4063
2022-10-04 21:26:29 - train: epoch 0093, iter [00730, 01251], lr: 0.000010, loss: 0.3975
2022-10-04 21:26:48 - train: epoch 0093, iter [00740, 01251], lr: 0.000010, loss: 0.4107
2022-10-04 21:27:07 - train: epoch 0093, iter [00750, 01251], lr: 0.000010, loss: 0.3961
2022-10-04 21:27:26 - train: epoch 0093, iter [00760, 01251], lr: 0.000010, loss: 0.4037
2022-10-04 21:27:45 - train: epoch 0093, iter [00770, 01251], lr: 0.000010, loss: 0.3872
2022-10-04 21:28:04 - train: epoch 0093, iter [00780, 01251], lr: 0.000010, loss: 0.3953
2022-10-04 21:28:24 - train: epoch 0093, iter [00790, 01251], lr: 0.000010, loss: 0.4035
2022-10-04 21:28:43 - train: epoch 0093, iter [00800, 01251], lr: 0.000010, loss: 0.4039
2022-10-04 21:29:01 - train: epoch 0093, iter [00810, 01251], lr: 0.000010, loss: 0.3833
2022-10-04 21:29:21 - train: epoch 0093, iter [00820, 01251], lr: 0.000010, loss: 0.3922
2022-10-04 21:29:39 - train: epoch 0093, iter [00830, 01251], lr: 0.000010, loss: 0.3992
2022-10-04 21:29:58 - train: epoch 0093, iter [00840, 01251], lr: 0.000010, loss: 0.4045
2022-10-04 21:30:18 - train: epoch 0093, iter [00850, 01251], lr: 0.000010, loss: 0.4032
2022-10-04 21:30:37 - train: epoch 0093, iter [00860, 01251], lr: 0.000010, loss: 0.4103
2022-10-04 21:30:56 - train: epoch 0093, iter [00870, 01251], lr: 0.000010, loss: 0.3818
2022-10-04 21:31:15 - train: epoch 0093, iter [00880, 01251], lr: 0.000010, loss: 0.4013
2022-10-04 21:31:34 - train: epoch 0093, iter [00890, 01251], lr: 0.000010, loss: 0.4050
2022-10-04 21:31:53 - train: epoch 0093, iter [00900, 01251], lr: 0.000010, loss: 0.4081
2022-10-04 21:32:12 - train: epoch 0093, iter [00910, 01251], lr: 0.000010, loss: 0.3797
2022-10-04 21:32:31 - train: epoch 0093, iter [00920, 01251], lr: 0.000010, loss: 0.3860
2022-10-04 21:32:50 - train: epoch 0093, iter [00930, 01251], lr: 0.000010, loss: 0.4001
2022-10-04 21:33:09 - train: epoch 0093, iter [00940, 01251], lr: 0.000010, loss: 0.3932
2022-10-04 21:33:28 - train: epoch 0093, iter [00950, 01251], lr: 0.000010, loss: 0.4005
2022-10-04 21:33:48 - train: epoch 0093, iter [00960, 01251], lr: 0.000010, loss: 0.3961
2022-10-04 21:34:07 - train: epoch 0093, iter [00970, 01251], lr: 0.000009, loss: 0.4040
2022-10-04 21:34:25 - train: epoch 0093, iter [00980, 01251], lr: 0.000009, loss: 0.3973
2022-10-04 21:34:45 - train: epoch 0093, iter [00990, 01251], lr: 0.000009, loss: 0.3868
2022-10-04 21:35:04 - train: epoch 0093, iter [01000, 01251], lr: 0.000009, loss: 0.3824
2022-10-04 21:35:23 - train: epoch 0093, iter [01010, 01251], lr: 0.000009, loss: 0.4100
2022-10-04 21:35:42 - train: epoch 0093, iter [01020, 01251], lr: 0.000009, loss: 0.4128
2022-10-04 21:36:01 - train: epoch 0093, iter [01030, 01251], lr: 0.000009, loss: 0.4020
2022-10-04 21:36:20 - train: epoch 0093, iter [01040, 01251], lr: 0.000009, loss: 0.4044
2022-10-04 21:36:39 - train: epoch 0093, iter [01050, 01251], lr: 0.000009, loss: 0.3962
2022-10-04 21:36:58 - train: epoch 0093, iter [01060, 01251], lr: 0.000009, loss: 0.4150
2022-10-04 21:37:17 - train: epoch 0093, iter [01070, 01251], lr: 0.000009, loss: 0.3918
2022-10-04 21:37:36 - train: epoch 0093, iter [01080, 01251], lr: 0.000009, loss: 0.3857
2022-10-04 21:37:56 - train: epoch 0093, iter [01090, 01251], lr: 0.000009, loss: 0.4004
2022-10-04 21:38:15 - train: epoch 0093, iter [01100, 01251], lr: 0.000009, loss: 0.4196
2022-10-04 21:38:33 - train: epoch 0093, iter [01110, 01251], lr: 0.000009, loss: 0.4071
2022-10-04 21:38:53 - train: epoch 0093, iter [01120, 01251], lr: 0.000009, loss: 0.4011
2022-10-04 21:39:12 - train: epoch 0093, iter [01130, 01251], lr: 0.000009, loss: 0.3926
2022-10-04 21:39:31 - train: epoch 0093, iter [01140, 01251], lr: 0.000009, loss: 0.3916
2022-10-04 21:39:50 - train: epoch 0093, iter [01150, 01251], lr: 0.000009, loss: 0.4220
2022-10-04 21:40:09 - train: epoch 0093, iter [01160, 01251], lr: 0.000009, loss: 0.4006
2022-10-04 21:40:28 - train: epoch 0093, iter [01170, 01251], lr: 0.000009, loss: 0.3964
2022-10-04 21:40:47 - train: epoch 0093, iter [01180, 01251], lr: 0.000009, loss: 0.4053
2022-10-04 21:41:06 - train: epoch 0093, iter [01190, 01251], lr: 0.000009, loss: 0.4156
2022-10-04 21:41:26 - train: epoch 0093, iter [01200, 01251], lr: 0.000009, loss: 0.3905
2022-10-04 21:41:44 - train: epoch 0093, iter [01210, 01251], lr: 0.000009, loss: 0.3887
2022-10-04 21:42:03 - train: epoch 0093, iter [01220, 01251], lr: 0.000009, loss: 0.3756
2022-10-04 21:42:22 - train: epoch 0093, iter [01230, 01251], lr: 0.000009, loss: 0.3963
2022-10-04 21:42:41 - train: epoch 0093, iter [01240, 01251], lr: 0.000009, loss: 0.3812
2022-10-04 21:43:00 - train: epoch 0093, iter [01250, 01251], lr: 0.000009, loss: 0.3944
2022-10-04 21:43:05 - train: epoch 093, train_loss: 0.3989
2022-10-04 21:43:09 - until epoch: 093, best_loss: 0.3989
2022-10-04 21:43:09 - epoch 094 lr: 0.000009
2022-10-04 21:43:35 - train: epoch 0094, iter [00010, 01251], lr: 0.000009, loss: 0.3956
2022-10-04 21:43:54 - train: epoch 0094, iter [00020, 01251], lr: 0.000009, loss: 0.4163
2022-10-04 21:44:13 - train: epoch 0094, iter [00030, 01251], lr: 0.000009, loss: 0.3977
2022-10-04 21:44:33 - train: epoch 0094, iter [00040, 01251], lr: 0.000009, loss: 0.4028
2022-10-04 21:44:52 - train: epoch 0094, iter [00050, 01251], lr: 0.000009, loss: 0.3917
2022-10-04 21:45:12 - train: epoch 0094, iter [00060, 01251], lr: 0.000009, loss: 0.4157
2022-10-04 21:45:31 - train: epoch 0094, iter [00070, 01251], lr: 0.000009, loss: 0.3942
2022-10-04 21:45:50 - train: epoch 0094, iter [00080, 01251], lr: 0.000009, loss: 0.4085
2022-10-04 21:46:09 - train: epoch 0094, iter [00090, 01251], lr: 0.000009, loss: 0.3897
2022-10-04 21:46:28 - train: epoch 0094, iter [00100, 01251], lr: 0.000009, loss: 0.4082
2022-10-04 21:46:48 - train: epoch 0094, iter [00110, 01251], lr: 0.000009, loss: 0.3861
2022-10-04 21:47:07 - train: epoch 0094, iter [00120, 01251], lr: 0.000009, loss: 0.4107
2022-10-04 21:47:26 - train: epoch 0094, iter [00130, 01251], lr: 0.000009, loss: 0.4202
2022-10-04 21:47:46 - train: epoch 0094, iter [00140, 01251], lr: 0.000009, loss: 0.4118
2022-10-04 21:48:05 - train: epoch 0094, iter [00150, 01251], lr: 0.000009, loss: 0.3910
2022-10-04 21:48:24 - train: epoch 0094, iter [00160, 01251], lr: 0.000009, loss: 0.3900
2022-10-04 21:48:44 - train: epoch 0094, iter [00170, 01251], lr: 0.000009, loss: 0.4038
2022-10-04 21:49:03 - train: epoch 0094, iter [00180, 01251], lr: 0.000009, loss: 0.3927
2022-10-04 21:49:22 - train: epoch 0094, iter [00190, 01251], lr: 0.000009, loss: 0.4007
2022-10-04 21:49:42 - train: epoch 0094, iter [00200, 01251], lr: 0.000009, loss: 0.4033
2022-10-04 21:50:01 - train: epoch 0094, iter [00210, 01251], lr: 0.000008, loss: 0.4131
2022-10-04 21:50:20 - train: epoch 0094, iter [00220, 01251], lr: 0.000008, loss: 0.3793
2022-10-04 21:50:39 - train: epoch 0094, iter [00230, 01251], lr: 0.000008, loss: 0.3954
2022-10-04 21:50:59 - train: epoch 0094, iter [00240, 01251], lr: 0.000008, loss: 0.4253
2022-10-04 21:51:18 - train: epoch 0094, iter [00250, 01251], lr: 0.000008, loss: 0.3964
2022-10-04 21:51:37 - train: epoch 0094, iter [00260, 01251], lr: 0.000008, loss: 0.3908
2022-10-04 21:51:56 - train: epoch 0094, iter [00270, 01251], lr: 0.000008, loss: 0.3881
2022-10-04 21:52:16 - train: epoch 0094, iter [00280, 01251], lr: 0.000008, loss: 0.3950
2022-10-04 21:52:35 - train: epoch 0094, iter [00290, 01251], lr: 0.000008, loss: 0.4014
2022-10-04 21:52:54 - train: epoch 0094, iter [00300, 01251], lr: 0.000008, loss: 0.3857
2022-10-04 21:53:13 - train: epoch 0094, iter [00310, 01251], lr: 0.000008, loss: 0.4090
2022-10-04 21:53:33 - train: epoch 0094, iter [00320, 01251], lr: 0.000008, loss: 0.3946
2022-10-04 21:53:52 - train: epoch 0094, iter [00330, 01251], lr: 0.000008, loss: 0.3964
2022-10-04 21:54:11 - train: epoch 0094, iter [00340, 01251], lr: 0.000008, loss: 0.3840
2022-10-04 21:54:31 - train: epoch 0094, iter [00350, 01251], lr: 0.000008, loss: 0.3971
2022-10-04 21:54:50 - train: epoch 0094, iter [00360, 01251], lr: 0.000008, loss: 0.3917
2022-10-04 21:55:09 - train: epoch 0094, iter [00370, 01251], lr: 0.000008, loss: 0.4125
2022-10-04 21:55:28 - train: epoch 0094, iter [00380, 01251], lr: 0.000008, loss: 0.3976
2022-10-04 21:55:47 - train: epoch 0094, iter [00390, 01251], lr: 0.000008, loss: 0.4182
2022-10-04 21:56:07 - train: epoch 0094, iter [00400, 01251], lr: 0.000008, loss: 0.3986
2022-10-04 21:56:26 - train: epoch 0094, iter [00410, 01251], lr: 0.000008, loss: 0.4121
2022-10-04 21:56:45 - train: epoch 0094, iter [00420, 01251], lr: 0.000008, loss: 0.3975
2022-10-04 21:57:04 - train: epoch 0094, iter [00430, 01251], lr: 0.000008, loss: 0.3736
2022-10-04 21:57:24 - train: epoch 0094, iter [00440, 01251], lr: 0.000008, loss: 0.3991
2022-10-04 21:57:43 - train: epoch 0094, iter [00450, 01251], lr: 0.000008, loss: 0.3960
2022-10-04 21:58:02 - train: epoch 0094, iter [00460, 01251], lr: 0.000008, loss: 0.3997
2022-10-04 21:58:22 - train: epoch 0094, iter [00470, 01251], lr: 0.000008, loss: 0.4045
2022-10-04 21:58:41 - train: epoch 0094, iter [00480, 01251], lr: 0.000008, loss: 0.4027
2022-10-04 21:59:00 - train: epoch 0094, iter [00490, 01251], lr: 0.000008, loss: 0.3928
2022-10-04 21:59:19 - train: epoch 0094, iter [00500, 01251], lr: 0.000008, loss: 0.4217
2022-10-04 21:59:38 - train: epoch 0094, iter [00510, 01251], lr: 0.000008, loss: 0.3893
2022-10-04 21:59:58 - train: epoch 0094, iter [00520, 01251], lr: 0.000008, loss: 0.4231
2022-10-04 22:00:17 - train: epoch 0094, iter [00530, 01251], lr: 0.000008, loss: 0.3843
2022-10-04 22:00:36 - train: epoch 0094, iter [00540, 01251], lr: 0.000008, loss: 0.4032
2022-10-04 22:00:55 - train: epoch 0094, iter [00550, 01251], lr: 0.000008, loss: 0.4037
2022-10-04 22:01:15 - train: epoch 0094, iter [00560, 01251], lr: 0.000008, loss: 0.3989
2022-10-04 22:01:34 - train: epoch 0094, iter [00570, 01251], lr: 0.000008, loss: 0.4083
2022-10-04 22:01:54 - train: epoch 0094, iter [00580, 01251], lr: 0.000008, loss: 0.4000
2022-10-04 22:02:13 - train: epoch 0094, iter [00590, 01251], lr: 0.000008, loss: 0.3772
2022-10-04 22:02:32 - train: epoch 0094, iter [00600, 01251], lr: 0.000008, loss: 0.3949
2022-10-04 22:02:51 - train: epoch 0094, iter [00610, 01251], lr: 0.000008, loss: 0.3866
2022-10-04 22:03:11 - train: epoch 0094, iter [00620, 01251], lr: 0.000008, loss: 0.4043
2022-10-04 22:03:30 - train: epoch 0094, iter [00630, 01251], lr: 0.000008, loss: 0.3915
2022-10-04 22:03:49 - train: epoch 0094, iter [00640, 01251], lr: 0.000008, loss: 0.3975
2022-10-04 22:04:08 - train: epoch 0094, iter [00650, 01251], lr: 0.000008, loss: 0.4098
2022-10-04 22:04:28 - train: epoch 0094, iter [00660, 01251], lr: 0.000008, loss: 0.3930
2022-10-04 22:04:47 - train: epoch 0094, iter [00670, 01251], lr: 0.000008, loss: 0.4003
2022-10-04 22:05:07 - train: epoch 0094, iter [00680, 01251], lr: 0.000008, loss: 0.3959
2022-10-04 22:05:26 - train: epoch 0094, iter [00690, 01251], lr: 0.000008, loss: 0.4093
2022-10-04 22:05:45 - train: epoch 0094, iter [00700, 01251], lr: 0.000008, loss: 0.3804
2022-10-04 22:06:04 - train: epoch 0094, iter [00710, 01251], lr: 0.000008, loss: 0.4021
2022-10-04 22:06:24 - train: epoch 0094, iter [00720, 01251], lr: 0.000008, loss: 0.3954
2022-10-04 22:06:43 - train: epoch 0094, iter [00730, 01251], lr: 0.000007, loss: 0.3996
2022-10-04 22:07:02 - train: epoch 0094, iter [00740, 01251], lr: 0.000007, loss: 0.4214
2022-10-04 22:07:22 - train: epoch 0094, iter [00750, 01251], lr: 0.000007, loss: 0.3910
2022-10-04 22:07:41 - train: epoch 0094, iter [00760, 01251], lr: 0.000007, loss: 0.4321
2022-10-04 22:08:00 - train: epoch 0094, iter [00770, 01251], lr: 0.000007, loss: 0.3938
2022-10-04 22:08:19 - train: epoch 0094, iter [00780, 01251], lr: 0.000007, loss: 0.3624
2022-10-04 22:08:39 - train: epoch 0094, iter [00790, 01251], lr: 0.000007, loss: 0.4076
2022-10-04 22:08:58 - train: epoch 0094, iter [00800, 01251], lr: 0.000007, loss: 0.3946
2022-10-04 22:09:17 - train: epoch 0094, iter [00810, 01251], lr: 0.000007, loss: 0.3926
2022-10-04 22:09:36 - train: epoch 0094, iter [00820, 01251], lr: 0.000007, loss: 0.4003
2022-10-04 22:09:56 - train: epoch 0094, iter [00830, 01251], lr: 0.000007, loss: 0.4036
2022-10-04 22:10:15 - train: epoch 0094, iter [00840, 01251], lr: 0.000007, loss: 0.3791
2022-10-04 22:10:34 - train: epoch 0094, iter [00850, 01251], lr: 0.000007, loss: 0.4001
2022-10-04 22:10:53 - train: epoch 0094, iter [00860, 01251], lr: 0.000007, loss: 0.3953
2022-10-04 22:11:13 - train: epoch 0094, iter [00870, 01251], lr: 0.000007, loss: 0.4181
2022-10-04 22:11:32 - train: epoch 0094, iter [00880, 01251], lr: 0.000007, loss: 0.4068
2022-10-04 22:11:51 - train: epoch 0094, iter [00890, 01251], lr: 0.000007, loss: 0.4093
2022-10-04 22:12:11 - train: epoch 0094, iter [00900, 01251], lr: 0.000007, loss: 0.3748
2022-10-04 22:12:30 - train: epoch 0094, iter [00910, 01251], lr: 0.000007, loss: 0.3912
2022-10-04 22:12:49 - train: epoch 0094, iter [00920, 01251], lr: 0.000007, loss: 0.4118
2022-10-04 22:13:08 - train: epoch 0094, iter [00930, 01251], lr: 0.000007, loss: 0.3942
2022-10-04 22:13:27 - train: epoch 0094, iter [00940, 01251], lr: 0.000007, loss: 0.3967
2022-10-04 22:13:47 - train: epoch 0094, iter [00950, 01251], lr: 0.000007, loss: 0.4046
2022-10-04 22:14:07 - train: epoch 0094, iter [00960, 01251], lr: 0.000007, loss: 0.4100
2022-10-04 22:14:26 - train: epoch 0094, iter [00970, 01251], lr: 0.000007, loss: 0.4017
2022-10-04 22:14:45 - train: epoch 0094, iter [00980, 01251], lr: 0.000007, loss: 0.3785
2022-10-04 22:15:04 - train: epoch 0094, iter [00990, 01251], lr: 0.000007, loss: 0.3978
2022-10-04 22:15:24 - train: epoch 0094, iter [01000, 01251], lr: 0.000007, loss: 0.3823
2022-10-04 22:15:43 - train: epoch 0094, iter [01010, 01251], lr: 0.000007, loss: 0.4019
2022-10-04 22:16:02 - train: epoch 0094, iter [01020, 01251], lr: 0.000007, loss: 0.4009
2022-10-04 22:16:21 - train: epoch 0094, iter [01030, 01251], lr: 0.000007, loss: 0.4131
2022-10-04 22:16:41 - train: epoch 0094, iter [01040, 01251], lr: 0.000007, loss: 0.4055
2022-10-04 22:17:00 - train: epoch 0094, iter [01050, 01251], lr: 0.000007, loss: 0.3978
2022-10-04 22:17:19 - train: epoch 0094, iter [01060, 01251], lr: 0.000007, loss: 0.3982
2022-10-04 22:17:39 - train: epoch 0094, iter [01070, 01251], lr: 0.000007, loss: 0.4038
2022-10-04 22:17:58 - train: epoch 0094, iter [01080, 01251], lr: 0.000007, loss: 0.3884
2022-10-04 22:18:18 - train: epoch 0094, iter [01090, 01251], lr: 0.000007, loss: 0.4012
2022-10-04 22:18:37 - train: epoch 0094, iter [01100, 01251], lr: 0.000007, loss: 0.4033
2022-10-04 22:18:56 - train: epoch 0094, iter [01110, 01251], lr: 0.000007, loss: 0.4144
2022-10-04 22:19:16 - train: epoch 0094, iter [01120, 01251], lr: 0.000007, loss: 0.3926
2022-10-04 22:19:35 - train: epoch 0094, iter [01130, 01251], lr: 0.000007, loss: 0.4071
2022-10-04 22:19:54 - train: epoch 0094, iter [01140, 01251], lr: 0.000007, loss: 0.3881
2022-10-04 22:20:13 - train: epoch 0094, iter [01150, 01251], lr: 0.000007, loss: 0.3973
2022-10-04 22:20:32 - train: epoch 0094, iter [01160, 01251], lr: 0.000007, loss: 0.3957
2022-10-04 22:20:52 - train: epoch 0094, iter [01170, 01251], lr: 0.000007, loss: 0.4059
2022-10-04 22:21:11 - train: epoch 0094, iter [01180, 01251], lr: 0.000007, loss: 0.3952
2022-10-04 22:21:30 - train: epoch 0094, iter [01190, 01251], lr: 0.000007, loss: 0.3944
2022-10-04 22:21:49 - train: epoch 0094, iter [01200, 01251], lr: 0.000007, loss: 0.3919
2022-10-04 22:22:09 - train: epoch 0094, iter [01210, 01251], lr: 0.000007, loss: 0.3880
2022-10-04 22:22:28 - train: epoch 0094, iter [01220, 01251], lr: 0.000007, loss: 0.3855
2022-10-04 22:22:47 - train: epoch 0094, iter [01230, 01251], lr: 0.000007, loss: 0.3955
2022-10-04 22:23:06 - train: epoch 0094, iter [01240, 01251], lr: 0.000007, loss: 0.3948
2022-10-04 22:23:25 - train: epoch 0094, iter [01250, 01251], lr: 0.000007, loss: 0.4092
2022-10-04 22:23:29 - train: epoch 094, train_loss: 0.3988
2022-10-04 22:23:33 - until epoch: 094, best_loss: 0.3988
2022-10-04 22:23:33 - epoch 095 lr: 0.000007
2022-10-04 22:23:58 - train: epoch 0095, iter [00010, 01251], lr: 0.000007, loss: 0.3911
2022-10-04 22:24:17 - train: epoch 0095, iter [00020, 01251], lr: 0.000007, loss: 0.3898
2022-10-04 22:24:35 - train: epoch 0095, iter [00030, 01251], lr: 0.000007, loss: 0.3843
2022-10-04 22:24:54 - train: epoch 0095, iter [00040, 01251], lr: 0.000006, loss: 0.3753
2022-10-04 22:25:13 - train: epoch 0095, iter [00050, 01251], lr: 0.000006, loss: 0.3943
2022-10-04 22:25:32 - train: epoch 0095, iter [00060, 01251], lr: 0.000006, loss: 0.4053
2022-10-04 22:25:51 - train: epoch 0095, iter [00070, 01251], lr: 0.000006, loss: 0.3983
2022-10-04 22:26:10 - train: epoch 0095, iter [00080, 01251], lr: 0.000006, loss: 0.3899
2022-10-04 22:26:29 - train: epoch 0095, iter [00090, 01251], lr: 0.000006, loss: 0.3718
2022-10-04 22:26:47 - train: epoch 0095, iter [00100, 01251], lr: 0.000006, loss: 0.3922
2022-10-04 22:27:06 - train: epoch 0095, iter [00110, 01251], lr: 0.000006, loss: 0.4155
2022-10-04 22:27:25 - train: epoch 0095, iter [00120, 01251], lr: 0.000006, loss: 0.3803
2022-10-04 22:27:44 - train: epoch 0095, iter [00130, 01251], lr: 0.000006, loss: 0.4066
2022-10-04 22:28:03 - train: epoch 0095, iter [00140, 01251], lr: 0.000006, loss: 0.3775
2022-10-04 22:28:23 - train: epoch 0095, iter [00150, 01251], lr: 0.000006, loss: 0.4166
2022-10-04 22:28:42 - train: epoch 0095, iter [00160, 01251], lr: 0.000006, loss: 0.4030
2022-10-04 22:29:01 - train: epoch 0095, iter [00170, 01251], lr: 0.000006, loss: 0.4193
2022-10-04 22:29:20 - train: epoch 0095, iter [00180, 01251], lr: 0.000006, loss: 0.3937
2022-10-04 22:29:40 - train: epoch 0095, iter [00190, 01251], lr: 0.000006, loss: 0.3863
2022-10-04 22:29:59 - train: epoch 0095, iter [00200, 01251], lr: 0.000006, loss: 0.4110
2022-10-04 22:30:19 - train: epoch 0095, iter [00210, 01251], lr: 0.000006, loss: 0.4015
2022-10-04 22:30:38 - train: epoch 0095, iter [00220, 01251], lr: 0.000006, loss: 0.3787
2022-10-04 22:30:58 - train: epoch 0095, iter [00230, 01251], lr: 0.000006, loss: 0.4033
2022-10-04 22:31:17 - train: epoch 0095, iter [00240, 01251], lr: 0.000006, loss: 0.3993
2022-10-04 22:31:36 - train: epoch 0095, iter [00250, 01251], lr: 0.000006, loss: 0.3917
2022-10-04 22:31:55 - train: epoch 0095, iter [00260, 01251], lr: 0.000006, loss: 0.3917
2022-10-04 22:32:15 - train: epoch 0095, iter [00270, 01251], lr: 0.000006, loss: 0.3895
2022-10-04 22:32:34 - train: epoch 0095, iter [00280, 01251], lr: 0.000006, loss: 0.4246
2022-10-04 22:32:53 - train: epoch 0095, iter [00290, 01251], lr: 0.000006, loss: 0.3883
2022-10-04 22:33:12 - train: epoch 0095, iter [00300, 01251], lr: 0.000006, loss: 0.3924
2022-10-04 22:33:32 - train: epoch 0095, iter [00310, 01251], lr: 0.000006, loss: 0.3926
2022-10-04 22:33:51 - train: epoch 0095, iter [00320, 01251], lr: 0.000006, loss: 0.4028
2022-10-04 22:34:10 - train: epoch 0095, iter [00330, 01251], lr: 0.000006, loss: 0.4069
2022-10-04 22:34:29 - train: epoch 0095, iter [00340, 01251], lr: 0.000006, loss: 0.3988
2022-10-04 22:34:48 - train: epoch 0095, iter [00350, 01251], lr: 0.000006, loss: 0.3902
2022-10-04 22:35:07 - train: epoch 0095, iter [00360, 01251], lr: 0.000006, loss: 0.3992
2022-10-04 22:35:27 - train: epoch 0095, iter [00370, 01251], lr: 0.000006, loss: 0.4107
2022-10-04 22:35:46 - train: epoch 0095, iter [00380, 01251], lr: 0.000006, loss: 0.4068
2022-10-04 22:36:05 - train: epoch 0095, iter [00390, 01251], lr: 0.000006, loss: 0.4004
2022-10-04 22:36:24 - train: epoch 0095, iter [00400, 01251], lr: 0.000006, loss: 0.4173
2022-10-04 22:36:44 - train: epoch 0095, iter [00410, 01251], lr: 0.000006, loss: 0.3781
2022-10-04 22:37:03 - train: epoch 0095, iter [00420, 01251], lr: 0.000006, loss: 0.3989
2022-10-04 22:37:22 - train: epoch 0095, iter [00430, 01251], lr: 0.000006, loss: 0.3944
2022-10-04 22:37:41 - train: epoch 0095, iter [00440, 01251], lr: 0.000006, loss: 0.3847
2022-10-04 22:38:00 - train: epoch 0095, iter [00450, 01251], lr: 0.000006, loss: 0.3993
2022-10-04 22:38:20 - train: epoch 0095, iter [00460, 01251], lr: 0.000006, loss: 0.4174
2022-10-04 22:38:39 - train: epoch 0095, iter [00470, 01251], lr: 0.000006, loss: 0.3998
2022-10-04 22:38:58 - train: epoch 0095, iter [00480, 01251], lr: 0.000006, loss: 0.3989
2022-10-04 22:39:18 - train: epoch 0095, iter [00490, 01251], lr: 0.000006, loss: 0.3732
2022-10-04 22:39:37 - train: epoch 0095, iter [00500, 01251], lr: 0.000006, loss: 0.3846
2022-10-04 22:39:56 - train: epoch 0095, iter [00510, 01251], lr: 0.000006, loss: 0.4045
2022-10-04 22:40:16 - train: epoch 0095, iter [00520, 01251], lr: 0.000006, loss: 0.4028
2022-10-04 22:40:35 - train: epoch 0095, iter [00530, 01251], lr: 0.000006, loss: 0.3884
2022-10-04 22:40:54 - train: epoch 0095, iter [00540, 01251], lr: 0.000006, loss: 0.3911
2022-10-04 22:41:14 - train: epoch 0095, iter [00550, 01251], lr: 0.000006, loss: 0.4112
2022-10-04 22:41:33 - train: epoch 0095, iter [00560, 01251], lr: 0.000006, loss: 0.3881
2022-10-04 22:41:53 - train: epoch 0095, iter [00570, 01251], lr: 0.000006, loss: 0.4009
2022-10-04 22:42:12 - train: epoch 0095, iter [00580, 01251], lr: 0.000006, loss: 0.4007
2022-10-04 22:42:32 - train: epoch 0095, iter [00590, 01251], lr: 0.000006, loss: 0.3977
2022-10-04 22:42:51 - train: epoch 0095, iter [00600, 01251], lr: 0.000006, loss: 0.4090
2022-10-04 22:43:10 - train: epoch 0095, iter [00610, 01251], lr: 0.000006, loss: 0.3765
2022-10-04 22:43:30 - train: epoch 0095, iter [00620, 01251], lr: 0.000006, loss: 0.4090
2022-10-04 22:43:49 - train: epoch 0095, iter [00630, 01251], lr: 0.000006, loss: 0.4140
2022-10-04 22:44:08 - train: epoch 0095, iter [00640, 01251], lr: 0.000005, loss: 0.4032
2022-10-04 22:44:28 - train: epoch 0095, iter [00650, 01251], lr: 0.000005, loss: 0.4034
2022-10-04 22:44:47 - train: epoch 0095, iter [00660, 01251], lr: 0.000005, loss: 0.4073
2022-10-04 22:45:06 - train: epoch 0095, iter [00670, 01251], lr: 0.000005, loss: 0.4128
2022-10-04 22:45:26 - train: epoch 0095, iter [00680, 01251], lr: 0.000005, loss: 0.4169
2022-10-04 22:45:45 - train: epoch 0095, iter [00690, 01251], lr: 0.000005, loss: 0.3789
2022-10-04 22:46:04 - train: epoch 0095, iter [00700, 01251], lr: 0.000005, loss: 0.3929
2022-10-04 22:46:24 - train: epoch 0095, iter [00710, 01251], lr: 0.000005, loss: 0.4092
2022-10-04 22:46:43 - train: epoch 0095, iter [00720, 01251], lr: 0.000005, loss: 0.3943
2022-10-04 22:47:02 - train: epoch 0095, iter [00730, 01251], lr: 0.000005, loss: 0.4105
2022-10-04 22:47:22 - train: epoch 0095, iter [00740, 01251], lr: 0.000005, loss: 0.3905
2022-10-04 22:47:41 - train: epoch 0095, iter [00750, 01251], lr: 0.000005, loss: 0.3983
2022-10-04 22:48:00 - train: epoch 0095, iter [00760, 01251], lr: 0.000005, loss: 0.3864
2022-10-04 22:48:19 - train: epoch 0095, iter [00770, 01251], lr: 0.000005, loss: 0.3896
2022-10-04 22:48:39 - train: epoch 0095, iter [00780, 01251], lr: 0.000005, loss: 0.3905
2022-10-04 22:48:58 - train: epoch 0095, iter [00790, 01251], lr: 0.000005, loss: 0.3849
2022-10-04 22:49:17 - train: epoch 0095, iter [00800, 01251], lr: 0.000005, loss: 0.4086
2022-10-04 22:49:37 - train: epoch 0095, iter [00810, 01251], lr: 0.000005, loss: 0.3774
2022-10-04 22:49:56 - train: epoch 0095, iter [00820, 01251], lr: 0.000005, loss: 0.4161
2022-10-04 22:50:15 - train: epoch 0095, iter [00830, 01251], lr: 0.000005, loss: 0.3894
2022-10-04 22:50:35 - train: epoch 0095, iter [00840, 01251], lr: 0.000005, loss: 0.4023
2022-10-04 22:50:54 - train: epoch 0095, iter [00850, 01251], lr: 0.000005, loss: 0.4009
2022-10-04 22:51:13 - train: epoch 0095, iter [00860, 01251], lr: 0.000005, loss: 0.4017
2022-10-04 22:51:33 - train: epoch 0095, iter [00870, 01251], lr: 0.000005, loss: 0.3795
2022-10-04 22:51:52 - train: epoch 0095, iter [00880, 01251], lr: 0.000005, loss: 0.3934
2022-10-04 22:52:11 - train: epoch 0095, iter [00890, 01251], lr: 0.000005, loss: 0.3908
2022-10-04 22:52:31 - train: epoch 0095, iter [00900, 01251], lr: 0.000005, loss: 0.4135
2022-10-04 22:52:50 - train: epoch 0095, iter [00910, 01251], lr: 0.000005, loss: 0.3923
2022-10-04 22:53:09 - train: epoch 0095, iter [00920, 01251], lr: 0.000005, loss: 0.4057
2022-10-04 22:53:29 - train: epoch 0095, iter [00930, 01251], lr: 0.000005, loss: 0.4018
2022-10-04 22:53:48 - train: epoch 0095, iter [00940, 01251], lr: 0.000005, loss: 0.3814
2022-10-04 22:54:07 - train: epoch 0095, iter [00950, 01251], lr: 0.000005, loss: 0.3969
2022-10-04 22:54:27 - train: epoch 0095, iter [00960, 01251], lr: 0.000005, loss: 0.3914
2022-10-04 22:54:46 - train: epoch 0095, iter [00970, 01251], lr: 0.000005, loss: 0.4000
2022-10-04 22:55:05 - train: epoch 0095, iter [00980, 01251], lr: 0.000005, loss: 0.4033
2022-10-04 22:55:24 - train: epoch 0095, iter [00990, 01251], lr: 0.000005, loss: 0.3914
2022-10-04 22:55:43 - train: epoch 0095, iter [01000, 01251], lr: 0.000005, loss: 0.3906
2022-10-04 22:56:02 - train: epoch 0095, iter [01010, 01251], lr: 0.000005, loss: 0.4195
2022-10-04 22:56:22 - train: epoch 0095, iter [01020, 01251], lr: 0.000005, loss: 0.4063
2022-10-04 22:56:41 - train: epoch 0095, iter [01030, 01251], lr: 0.000005, loss: 0.3831
2022-10-04 22:57:00 - train: epoch 0095, iter [01040, 01251], lr: 0.000005, loss: 0.4011
2022-10-04 22:57:20 - train: epoch 0095, iter [01050, 01251], lr: 0.000005, loss: 0.4055
2022-10-04 22:57:39 - train: epoch 0095, iter [01060, 01251], lr: 0.000005, loss: 0.3961
2022-10-04 22:57:59 - train: epoch 0095, iter [01070, 01251], lr: 0.000005, loss: 0.4016
2022-10-04 22:58:18 - train: epoch 0095, iter [01080, 01251], lr: 0.000005, loss: 0.3996
2022-10-04 22:58:37 - train: epoch 0095, iter [01090, 01251], lr: 0.000005, loss: 0.4006
2022-10-04 22:58:56 - train: epoch 0095, iter [01100, 01251], lr: 0.000005, loss: 0.3972
2022-10-04 22:59:16 - train: epoch 0095, iter [01110, 01251], lr: 0.000005, loss: 0.3887
2022-10-04 22:59:35 - train: epoch 0095, iter [01120, 01251], lr: 0.000005, loss: 0.4124
2022-10-04 22:59:54 - train: epoch 0095, iter [01130, 01251], lr: 0.000005, loss: 0.4088
2022-10-04 23:00:14 - train: epoch 0095, iter [01140, 01251], lr: 0.000005, loss: 0.3934
2022-10-04 23:00:33 - train: epoch 0095, iter [01150, 01251], lr: 0.000005, loss: 0.4173
2022-10-04 23:00:52 - train: epoch 0095, iter [01160, 01251], lr: 0.000005, loss: 0.3901
2022-10-04 23:01:12 - train: epoch 0095, iter [01170, 01251], lr: 0.000005, loss: 0.4217
2022-10-04 23:01:31 - train: epoch 0095, iter [01180, 01251], lr: 0.000005, loss: 0.4138
2022-10-04 23:01:50 - train: epoch 0095, iter [01190, 01251], lr: 0.000005, loss: 0.4064
2022-10-04 23:02:09 - train: epoch 0095, iter [01200, 01251], lr: 0.000005, loss: 0.3916
2022-10-04 23:02:29 - train: epoch 0095, iter [01210, 01251], lr: 0.000005, loss: 0.4053
2022-10-04 23:02:48 - train: epoch 0095, iter [01220, 01251], lr: 0.000005, loss: 0.3888
2022-10-04 23:03:07 - train: epoch 0095, iter [01230, 01251], lr: 0.000005, loss: 0.3831
2022-10-04 23:03:27 - train: epoch 0095, iter [01240, 01251], lr: 0.000005, loss: 0.4155
2022-10-04 23:03:45 - train: epoch 0095, iter [01250, 01251], lr: 0.000005, loss: 0.3627
2022-10-04 23:03:49 - train: epoch 095, train_loss: 0.3986
2022-10-04 23:03:53 - until epoch: 095, best_loss: 0.3986
2022-10-04 23:03:53 - epoch 096 lr: 0.000005
2022-10-04 23:04:20 - train: epoch 0096, iter [00010, 01251], lr: 0.000005, loss: 0.4000
2022-10-04 23:04:39 - train: epoch 0096, iter [00020, 01251], lr: 0.000005, loss: 0.4067
2022-10-04 23:04:58 - train: epoch 0096, iter [00030, 01251], lr: 0.000005, loss: 0.3910
2022-10-04 23:05:18 - train: epoch 0096, iter [00040, 01251], lr: 0.000004, loss: 0.4181
2022-10-04 23:05:37 - train: epoch 0096, iter [00050, 01251], lr: 0.000004, loss: 0.4017
2022-10-04 23:05:57 - train: epoch 0096, iter [00060, 01251], lr: 0.000004, loss: 0.4041
2022-10-04 23:06:16 - train: epoch 0096, iter [00070, 01251], lr: 0.000004, loss: 0.3868
2022-10-04 23:06:35 - train: epoch 0096, iter [00080, 01251], lr: 0.000004, loss: 0.3826
2022-10-04 23:06:55 - train: epoch 0096, iter [00090, 01251], lr: 0.000004, loss: 0.4124
2022-10-04 23:07:14 - train: epoch 0096, iter [00100, 01251], lr: 0.000004, loss: 0.3980
2022-10-04 23:07:34 - train: epoch 0096, iter [00110, 01251], lr: 0.000004, loss: 0.4049
2022-10-04 23:07:53 - train: epoch 0096, iter [00120, 01251], lr: 0.000004, loss: 0.3889
2022-10-04 23:08:13 - train: epoch 0096, iter [00130, 01251], lr: 0.000004, loss: 0.3818
2022-10-04 23:08:32 - train: epoch 0096, iter [00140, 01251], lr: 0.000004, loss: 0.3746
2022-10-04 23:08:52 - train: epoch 0096, iter [00150, 01251], lr: 0.000004, loss: 0.3880
2022-10-04 23:09:11 - train: epoch 0096, iter [00160, 01251], lr: 0.000004, loss: 0.3985
2022-10-04 23:09:30 - train: epoch 0096, iter [00170, 01251], lr: 0.000004, loss: 0.3785
2022-10-04 23:09:50 - train: epoch 0096, iter [00180, 01251], lr: 0.000004, loss: 0.3973
2022-10-04 23:10:09 - train: epoch 0096, iter [00190, 01251], lr: 0.000004, loss: 0.4072
2022-10-04 23:10:29 - train: epoch 0096, iter [00200, 01251], lr: 0.000004, loss: 0.4042
2022-10-04 23:10:48 - train: epoch 0096, iter [00210, 01251], lr: 0.000004, loss: 0.3974
2022-10-04 23:11:07 - train: epoch 0096, iter [00220, 01251], lr: 0.000004, loss: 0.4047
2022-10-04 23:11:27 - train: epoch 0096, iter [00230, 01251], lr: 0.000004, loss: 0.4242
2022-10-04 23:11:46 - train: epoch 0096, iter [00240, 01251], lr: 0.000004, loss: 0.4003
2022-10-04 23:12:05 - train: epoch 0096, iter [00250, 01251], lr: 0.000004, loss: 0.3943
2022-10-04 23:12:25 - train: epoch 0096, iter [00260, 01251], lr: 0.000004, loss: 0.3842
2022-10-04 23:12:44 - train: epoch 0096, iter [00270, 01251], lr: 0.000004, loss: 0.3998
2022-10-04 23:13:03 - train: epoch 0096, iter [00280, 01251], lr: 0.000004, loss: 0.3815
2022-10-04 23:13:23 - train: epoch 0096, iter [00290, 01251], lr: 0.000004, loss: 0.3842
2022-10-04 23:13:42 - train: epoch 0096, iter [00300, 01251], lr: 0.000004, loss: 0.4128
2022-10-04 23:14:02 - train: epoch 0096, iter [00310, 01251], lr: 0.000004, loss: 0.3894
2022-10-04 23:14:21 - train: epoch 0096, iter [00320, 01251], lr: 0.000004, loss: 0.4008
2022-10-04 23:14:40 - train: epoch 0096, iter [00330, 01251], lr: 0.000004, loss: 0.3946
2022-10-04 23:15:00 - train: epoch 0096, iter [00340, 01251], lr: 0.000004, loss: 0.3998
2022-10-04 23:15:19 - train: epoch 0096, iter [00350, 01251], lr: 0.000004, loss: 0.4045
2022-10-04 23:15:38 - train: epoch 0096, iter [00360, 01251], lr: 0.000004, loss: 0.3871
2022-10-04 23:15:58 - train: epoch 0096, iter [00370, 01251], lr: 0.000004, loss: 0.4031
2022-10-04 23:16:17 - train: epoch 0096, iter [00380, 01251], lr: 0.000004, loss: 0.4231
2022-10-04 23:16:36 - train: epoch 0096, iter [00390, 01251], lr: 0.000004, loss: 0.3990
2022-10-04 23:16:56 - train: epoch 0096, iter [00400, 01251], lr: 0.000004, loss: 0.4086
2022-10-04 23:17:15 - train: epoch 0096, iter [00410, 01251], lr: 0.000004, loss: 0.3977
2022-10-04 23:17:35 - train: epoch 0096, iter [00420, 01251], lr: 0.000004, loss: 0.4065
2022-10-04 23:17:54 - train: epoch 0096, iter [00430, 01251], lr: 0.000004, loss: 0.4019
2022-10-04 23:18:13 - train: epoch 0096, iter [00440, 01251], lr: 0.000004, loss: 0.3978
2022-10-04 23:18:33 - train: epoch 0096, iter [00450, 01251], lr: 0.000004, loss: 0.3792
2022-10-04 23:18:52 - train: epoch 0096, iter [00460, 01251], lr: 0.000004, loss: 0.3947
2022-10-04 23:19:11 - train: epoch 0096, iter [00470, 01251], lr: 0.000004, loss: 0.4071
2022-10-04 23:19:31 - train: epoch 0096, iter [00480, 01251], lr: 0.000004, loss: 0.3913
2022-10-04 23:19:50 - train: epoch 0096, iter [00490, 01251], lr: 0.000004, loss: 0.3932
2022-10-04 23:20:09 - train: epoch 0096, iter [00500, 01251], lr: 0.000004, loss: 0.3899
2022-10-04 23:20:29 - train: epoch 0096, iter [00510, 01251], lr: 0.000004, loss: 0.3995
2022-10-04 23:20:48 - train: epoch 0096, iter [00520, 01251], lr: 0.000004, loss: 0.3900
2022-10-04 23:21:08 - train: epoch 0096, iter [00530, 01251], lr: 0.000004, loss: 0.4044
2022-10-04 23:21:27 - train: epoch 0096, iter [00540, 01251], lr: 0.000004, loss: 0.4152
2022-10-04 23:21:47 - train: epoch 0096, iter [00550, 01251], lr: 0.000004, loss: 0.3873
2022-10-04 23:22:06 - train: epoch 0096, iter [00560, 01251], lr: 0.000004, loss: 0.4191
2022-10-04 23:22:25 - train: epoch 0096, iter [00570, 01251], lr: 0.000004, loss: 0.3965
2022-10-04 23:22:45 - train: epoch 0096, iter [00580, 01251], lr: 0.000004, loss: 0.4251
2022-10-04 23:23:04 - train: epoch 0096, iter [00590, 01251], lr: 0.000004, loss: 0.4015
2022-10-04 23:23:23 - train: epoch 0096, iter [00600, 01251], lr: 0.000004, loss: 0.4179
2022-10-04 23:23:42 - train: epoch 0096, iter [00610, 01251], lr: 0.000004, loss: 0.3901
2022-10-04 23:24:02 - train: epoch 0096, iter [00620, 01251], lr: 0.000004, loss: 0.3826
2022-10-04 23:24:21 - train: epoch 0096, iter [00630, 01251], lr: 0.000004, loss: 0.3980
2022-10-04 23:24:41 - train: epoch 0096, iter [00640, 01251], lr: 0.000004, loss: 0.3988
2022-10-04 23:25:00 - train: epoch 0096, iter [00650, 01251], lr: 0.000004, loss: 0.3960
2022-10-04 23:25:19 - train: epoch 0096, iter [00660, 01251], lr: 0.000004, loss: 0.3852
2022-10-04 23:25:39 - train: epoch 0096, iter [00670, 01251], lr: 0.000004, loss: 0.4057
2022-10-04 23:25:58 - train: epoch 0096, iter [00680, 01251], lr: 0.000004, loss: 0.4085
2022-10-04 23:26:17 - train: epoch 0096, iter [00690, 01251], lr: 0.000004, loss: 0.4019
2022-10-04 23:26:37 - train: epoch 0096, iter [00700, 01251], lr: 0.000004, loss: 0.3809
2022-10-04 23:26:56 - train: epoch 0096, iter [00710, 01251], lr: 0.000004, loss: 0.3888
2022-10-04 23:27:15 - train: epoch 0096, iter [00720, 01251], lr: 0.000004, loss: 0.3984
2022-10-04 23:27:35 - train: epoch 0096, iter [00730, 01251], lr: 0.000004, loss: 0.3799
2022-10-04 23:27:54 - train: epoch 0096, iter [00740, 01251], lr: 0.000004, loss: 0.3994
2022-10-04 23:28:14 - train: epoch 0096, iter [00750, 01251], lr: 0.000004, loss: 0.3977
2022-10-04 23:28:33 - train: epoch 0096, iter [00760, 01251], lr: 0.000004, loss: 0.4034
2022-10-04 23:28:53 - train: epoch 0096, iter [00770, 01251], lr: 0.000004, loss: 0.4085
2022-10-04 23:29:12 - train: epoch 0096, iter [00780, 01251], lr: 0.000003, loss: 0.4013
2022-10-04 23:29:32 - train: epoch 0096, iter [00790, 01251], lr: 0.000003, loss: 0.3987
2022-10-04 23:29:51 - train: epoch 0096, iter [00800, 01251], lr: 0.000003, loss: 0.4038
2022-10-04 23:30:11 - train: epoch 0096, iter [00810, 01251], lr: 0.000003, loss: 0.3969
2022-10-04 23:30:30 - train: epoch 0096, iter [00820, 01251], lr: 0.000003, loss: 0.3932
2022-10-04 23:30:49 - train: epoch 0096, iter [00830, 01251], lr: 0.000003, loss: 0.4011
2022-10-04 23:31:09 - train: epoch 0096, iter [00840, 01251], lr: 0.000003, loss: 0.3978
2022-10-04 23:31:28 - train: epoch 0096, iter [00850, 01251], lr: 0.000003, loss: 0.4041
2022-10-04 23:31:48 - train: epoch 0096, iter [00860, 01251], lr: 0.000003, loss: 0.3945
2022-10-04 23:32:07 - train: epoch 0096, iter [00870, 01251], lr: 0.000003, loss: 0.3874
2022-10-04 23:32:27 - train: epoch 0096, iter [00880, 01251], lr: 0.000003, loss: 0.3848
2022-10-04 23:32:46 - train: epoch 0096, iter [00890, 01251], lr: 0.000003, loss: 0.4222
2022-10-04 23:33:06 - train: epoch 0096, iter [00900, 01251], lr: 0.000003, loss: 0.3827
2022-10-04 23:33:25 - train: epoch 0096, iter [00910, 01251], lr: 0.000003, loss: 0.4194
2022-10-04 23:33:44 - train: epoch 0096, iter [00920, 01251], lr: 0.000003, loss: 0.3781
2022-10-04 23:34:04 - train: epoch 0096, iter [00930, 01251], lr: 0.000003, loss: 0.4067
2022-10-04 23:34:23 - train: epoch 0096, iter [00940, 01251], lr: 0.000003, loss: 0.4331
2022-10-04 23:34:42 - train: epoch 0096, iter [00950, 01251], lr: 0.000003, loss: 0.4001
2022-10-04 23:35:02 - train: epoch 0096, iter [00960, 01251], lr: 0.000003, loss: 0.4202
2022-10-04 23:35:21 - train: epoch 0096, iter [00970, 01251], lr: 0.000003, loss: 0.3765
2022-10-04 23:35:41 - train: epoch 0096, iter [00980, 01251], lr: 0.000003, loss: 0.3994
2022-10-04 23:36:00 - train: epoch 0096, iter [00990, 01251], lr: 0.000003, loss: 0.3927
2022-10-04 23:36:20 - train: epoch 0096, iter [01000, 01251], lr: 0.000003, loss: 0.3974
2022-10-04 23:36:39 - train: epoch 0096, iter [01010, 01251], lr: 0.000003, loss: 0.3979
2022-10-04 23:36:59 - train: epoch 0096, iter [01020, 01251], lr: 0.000003, loss: 0.4047
2022-10-04 23:37:18 - train: epoch 0096, iter [01030, 01251], lr: 0.000003, loss: 0.4091
2022-10-04 23:37:38 - train: epoch 0096, iter [01040, 01251], lr: 0.000003, loss: 0.4056
2022-10-04 23:37:57 - train: epoch 0096, iter [01050, 01251], lr: 0.000003, loss: 0.4098
2022-10-04 23:38:16 - train: epoch 0096, iter [01060, 01251], lr: 0.000003, loss: 0.4011
2022-10-04 23:38:36 - train: epoch 0096, iter [01070, 01251], lr: 0.000003, loss: 0.4140
2022-10-04 23:38:55 - train: epoch 0096, iter [01080, 01251], lr: 0.000003, loss: 0.4029
2022-10-04 23:39:14 - train: epoch 0096, iter [01090, 01251], lr: 0.000003, loss: 0.4114
2022-10-04 23:39:34 - train: epoch 0096, iter [01100, 01251], lr: 0.000003, loss: 0.3934
2022-10-04 23:39:53 - train: epoch 0096, iter [01110, 01251], lr: 0.000003, loss: 0.3900
2022-10-04 23:40:12 - train: epoch 0096, iter [01120, 01251], lr: 0.000003, loss: 0.3769
2022-10-04 23:40:32 - train: epoch 0096, iter [01130, 01251], lr: 0.000003, loss: 0.3857
2022-10-04 23:40:51 - train: epoch 0096, iter [01140, 01251], lr: 0.000003, loss: 0.4006
2022-10-04 23:41:10 - train: epoch 0096, iter [01150, 01251], lr: 0.000003, loss: 0.4127
2022-10-04 23:41:30 - train: epoch 0096, iter [01160, 01251], lr: 0.000003, loss: 0.4069
2022-10-04 23:41:49 - train: epoch 0096, iter [01170, 01251], lr: 0.000003, loss: 0.3983
2022-10-04 23:42:08 - train: epoch 0096, iter [01180, 01251], lr: 0.000003, loss: 0.4099
2022-10-04 23:42:28 - train: epoch 0096, iter [01190, 01251], lr: 0.000003, loss: 0.4112
2022-10-04 23:42:48 - train: epoch 0096, iter [01200, 01251], lr: 0.000003, loss: 0.3913
2022-10-04 23:43:07 - train: epoch 0096, iter [01210, 01251], lr: 0.000003, loss: 0.3843
2022-10-04 23:43:26 - train: epoch 0096, iter [01220, 01251], lr: 0.000003, loss: 0.3954
2022-10-04 23:43:46 - train: epoch 0096, iter [01230, 01251], lr: 0.000003, loss: 0.3989
2022-10-04 23:44:05 - train: epoch 0096, iter [01240, 01251], lr: 0.000003, loss: 0.4041
2022-10-04 23:44:24 - train: epoch 0096, iter [01250, 01251], lr: 0.000003, loss: 0.3929
2022-10-04 23:44:28 - train: epoch 096, train_loss: 0.3987
2022-10-04 23:44:30 - until epoch: 096, best_loss: 0.3986
2022-10-04 23:44:30 - epoch 097 lr: 0.000003
2022-10-04 23:44:58 - train: epoch 0097, iter [00010, 01251], lr: 0.000003, loss: 0.3858
2022-10-04 23:45:18 - train: epoch 0097, iter [00020, 01251], lr: 0.000003, loss: 0.4123
2022-10-04 23:45:38 - train: epoch 0097, iter [00030, 01251], lr: 0.000003, loss: 0.4103
2022-10-04 23:45:57 - train: epoch 0097, iter [00040, 01251], lr: 0.000003, loss: 0.3813
2022-10-04 23:46:17 - train: epoch 0097, iter [00050, 01251], lr: 0.000003, loss: 0.4031
2022-10-04 23:46:37 - train: epoch 0097, iter [00060, 01251], lr: 0.000003, loss: 0.4041
2022-10-04 23:46:56 - train: epoch 0097, iter [00070, 01251], lr: 0.000003, loss: 0.4072
2022-10-04 23:47:16 - train: epoch 0097, iter [00080, 01251], lr: 0.000003, loss: 0.3954
2022-10-04 23:47:36 - train: epoch 0097, iter [00090, 01251], lr: 0.000003, loss: 0.3980
2022-10-04 23:47:56 - train: epoch 0097, iter [00100, 01251], lr: 0.000003, loss: 0.3901
2022-10-04 23:48:15 - train: epoch 0097, iter [00110, 01251], lr: 0.000003, loss: 0.3962
2022-10-04 23:48:35 - train: epoch 0097, iter [00120, 01251], lr: 0.000003, loss: 0.3905
2022-10-04 23:48:54 - train: epoch 0097, iter [00130, 01251], lr: 0.000003, loss: 0.3951
2022-10-04 23:49:14 - train: epoch 0097, iter [00140, 01251], lr: 0.000003, loss: 0.3994
2022-10-04 23:49:33 - train: epoch 0097, iter [00150, 01251], lr: 0.000003, loss: 0.3979
2022-10-04 23:49:53 - train: epoch 0097, iter [00160, 01251], lr: 0.000003, loss: 0.3978
2022-10-04 23:50:13 - train: epoch 0097, iter [00170, 01251], lr: 0.000003, loss: 0.4048
2022-10-04 23:50:32 - train: epoch 0097, iter [00180, 01251], lr: 0.000003, loss: 0.3972
2022-10-04 23:50:52 - train: epoch 0097, iter [00190, 01251], lr: 0.000003, loss: 0.3849
2022-10-04 23:51:12 - train: epoch 0097, iter [00200, 01251], lr: 0.000003, loss: 0.3970
2022-10-04 23:51:32 - train: epoch 0097, iter [00210, 01251], lr: 0.000003, loss: 0.3702
2022-10-04 23:51:51 - train: epoch 0097, iter [00220, 01251], lr: 0.000003, loss: 0.4156
2022-10-04 23:52:10 - train: epoch 0097, iter [00230, 01251], lr: 0.000003, loss: 0.3930
2022-10-04 23:52:30 - train: epoch 0097, iter [00240, 01251], lr: 0.000003, loss: 0.3856
2022-10-04 23:52:50 - train: epoch 0097, iter [00250, 01251], lr: 0.000003, loss: 0.4157
2022-10-04 23:53:09 - train: epoch 0097, iter [00260, 01251], lr: 0.000003, loss: 0.4140
2022-10-04 23:53:29 - train: epoch 0097, iter [00270, 01251], lr: 0.000003, loss: 0.4212
2022-10-04 23:53:49 - train: epoch 0097, iter [00280, 01251], lr: 0.000003, loss: 0.4052
2022-10-04 23:54:09 - train: epoch 0097, iter [00290, 01251], lr: 0.000003, loss: 0.3993
2022-10-04 23:54:28 - train: epoch 0097, iter [00300, 01251], lr: 0.000003, loss: 0.4011
2022-10-04 23:54:48 - train: epoch 0097, iter [00310, 01251], lr: 0.000003, loss: 0.3944
2022-10-04 23:55:07 - train: epoch 0097, iter [00320, 01251], lr: 0.000003, loss: 0.4073
2022-10-04 23:55:27 - train: epoch 0097, iter [00330, 01251], lr: 0.000003, loss: 0.4042
2022-10-04 23:55:47 - train: epoch 0097, iter [00340, 01251], lr: 0.000003, loss: 0.4127
2022-10-04 23:56:07 - train: epoch 0097, iter [00350, 01251], lr: 0.000003, loss: 0.3904
2022-10-04 23:56:26 - train: epoch 0097, iter [00360, 01251], lr: 0.000003, loss: 0.4207
2022-10-04 23:56:46 - train: epoch 0097, iter [00370, 01251], lr: 0.000003, loss: 0.4147
2022-10-04 23:57:05 - train: epoch 0097, iter [00380, 01251], lr: 0.000002, loss: 0.4061
2022-10-04 23:57:25 - train: epoch 0097, iter [00390, 01251], lr: 0.000002, loss: 0.3931
2022-10-04 23:57:45 - train: epoch 0097, iter [00400, 01251], lr: 0.000002, loss: 0.4116
2022-10-04 23:58:05 - train: epoch 0097, iter [00410, 01251], lr: 0.000002, loss: 0.3855
2022-10-04 23:58:24 - train: epoch 0097, iter [00420, 01251], lr: 0.000002, loss: 0.4006
2022-10-04 23:58:44 - train: epoch 0097, iter [00430, 01251], lr: 0.000002, loss: 0.3851
2022-10-04 23:59:03 - train: epoch 0097, iter [00440, 01251], lr: 0.000002, loss: 0.4122
2022-10-04 23:59:23 - train: epoch 0097, iter [00450, 01251], lr: 0.000002, loss: 0.4023
2022-10-04 23:59:43 - train: epoch 0097, iter [00460, 01251], lr: 0.000002, loss: 0.4002
2022-10-05 00:00:02 - train: epoch 0097, iter [00470, 01251], lr: 0.000002, loss: 0.3960
2022-10-05 00:00:22 - train: epoch 0097, iter [00480, 01251], lr: 0.000002, loss: 0.4075
2022-10-05 00:00:41 - train: epoch 0097, iter [00490, 01251], lr: 0.000002, loss: 0.4089
2022-10-05 00:01:01 - train: epoch 0097, iter [00500, 01251], lr: 0.000002, loss: 0.4090
2022-10-05 00:01:20 - train: epoch 0097, iter [00510, 01251], lr: 0.000002, loss: 0.3834
2022-10-05 00:01:40 - train: epoch 0097, iter [00520, 01251], lr: 0.000002, loss: 0.3959
2022-10-05 00:02:00 - train: epoch 0097, iter [00530, 01251], lr: 0.000002, loss: 0.3856
2022-10-05 00:02:19 - train: epoch 0097, iter [00540, 01251], lr: 0.000002, loss: 0.3965
2022-10-05 00:02:38 - train: epoch 0097, iter [00550, 01251], lr: 0.000002, loss: 0.4125
2022-10-05 00:02:58 - train: epoch 0097, iter [00560, 01251], lr: 0.000002, loss: 0.3898
2022-10-05 00:03:18 - train: epoch 0097, iter [00570, 01251], lr: 0.000002, loss: 0.3925
2022-10-05 00:03:37 - train: epoch 0097, iter [00580, 01251], lr: 0.000002, loss: 0.3998
2022-10-05 00:03:57 - train: epoch 0097, iter [00590, 01251], lr: 0.000002, loss: 0.3844
2022-10-05 00:04:16 - train: epoch 0097, iter [00600, 01251], lr: 0.000002, loss: 0.3974
2022-10-05 00:04:36 - train: epoch 0097, iter [00610, 01251], lr: 0.000002, loss: 0.4000
2022-10-05 00:04:55 - train: epoch 0097, iter [00620, 01251], lr: 0.000002, loss: 0.3881
2022-10-05 00:05:15 - train: epoch 0097, iter [00630, 01251], lr: 0.000002, loss: 0.4144
2022-10-05 00:05:34 - train: epoch 0097, iter [00640, 01251], lr: 0.000002, loss: 0.3872
2022-10-05 00:05:54 - train: epoch 0097, iter [00650, 01251], lr: 0.000002, loss: 0.3930
2022-10-05 00:06:13 - train: epoch 0097, iter [00660, 01251], lr: 0.000002, loss: 0.3778
2022-10-05 00:06:33 - train: epoch 0097, iter [00670, 01251], lr: 0.000002, loss: 0.4013
2022-10-05 00:06:52 - train: epoch 0097, iter [00680, 01251], lr: 0.000002, loss: 0.4228
2022-10-05 00:07:12 - train: epoch 0097, iter [00690, 01251], lr: 0.000002, loss: 0.4048
2022-10-05 00:07:31 - train: epoch 0097, iter [00700, 01251], lr: 0.000002, loss: 0.3822
2022-10-05 00:07:51 - train: epoch 0097, iter [00710, 01251], lr: 0.000002, loss: 0.4021
2022-10-05 00:08:11 - train: epoch 0097, iter [00720, 01251], lr: 0.000002, loss: 0.4046
2022-10-05 00:08:30 - train: epoch 0097, iter [00730, 01251], lr: 0.000002, loss: 0.4044
2022-10-05 00:08:49 - train: epoch 0097, iter [00740, 01251], lr: 0.000002, loss: 0.3903
2022-10-05 00:09:09 - train: epoch 0097, iter [00750, 01251], lr: 0.000002, loss: 0.3943
2022-10-05 00:09:28 - train: epoch 0097, iter [00760, 01251], lr: 0.000002, loss: 0.3981
2022-10-05 00:09:47 - train: epoch 0097, iter [00770, 01251], lr: 0.000002, loss: 0.3828
2022-10-05 00:10:07 - train: epoch 0097, iter [00780, 01251], lr: 0.000002, loss: 0.3819
2022-10-05 00:10:26 - train: epoch 0097, iter [00790, 01251], lr: 0.000002, loss: 0.4184
2022-10-05 00:10:46 - train: epoch 0097, iter [00800, 01251], lr: 0.000002, loss: 0.3836
2022-10-05 00:11:06 - train: epoch 0097, iter [00810, 01251], lr: 0.000002, loss: 0.3844
2022-10-05 00:11:25 - train: epoch 0097, iter [00820, 01251], lr: 0.000002, loss: 0.4063
2022-10-05 00:11:44 - train: epoch 0097, iter [00830, 01251], lr: 0.000002, loss: 0.3972
2022-10-05 00:12:04 - train: epoch 0097, iter [00840, 01251], lr: 0.000002, loss: 0.3856
2022-10-05 00:12:23 - train: epoch 0097, iter [00850, 01251], lr: 0.000002, loss: 0.4060
2022-10-05 00:12:43 - train: epoch 0097, iter [00860, 01251], lr: 0.000002, loss: 0.3948
2022-10-05 00:13:02 - train: epoch 0097, iter [00870, 01251], lr: 0.000002, loss: 0.3989
2022-10-05 00:13:22 - train: epoch 0097, iter [00880, 01251], lr: 0.000002, loss: 0.3917
2022-10-05 00:13:41 - train: epoch 0097, iter [00890, 01251], lr: 0.000002, loss: 0.3790
2022-10-05 00:14:01 - train: epoch 0097, iter [00900, 01251], lr: 0.000002, loss: 0.3917
2022-10-05 00:14:20 - train: epoch 0097, iter [00910, 01251], lr: 0.000002, loss: 0.4116
2022-10-05 00:14:40 - train: epoch 0097, iter [00920, 01251], lr: 0.000002, loss: 0.4053
2022-10-05 00:14:59 - train: epoch 0097, iter [00930, 01251], lr: 0.000002, loss: 0.4081
2022-10-05 00:15:18 - train: epoch 0097, iter [00940, 01251], lr: 0.000002, loss: 0.3812
2022-10-05 00:15:38 - train: epoch 0097, iter [00950, 01251], lr: 0.000002, loss: 0.3904
2022-10-05 00:15:57 - train: epoch 0097, iter [00960, 01251], lr: 0.000002, loss: 0.4119
2022-10-05 00:16:16 - train: epoch 0097, iter [00970, 01251], lr: 0.000002, loss: 0.4149
2022-10-05 00:16:36 - train: epoch 0097, iter [00980, 01251], lr: 0.000002, loss: 0.4081
2022-10-05 00:16:55 - train: epoch 0097, iter [00990, 01251], lr: 0.000002, loss: 0.4058
2022-10-05 00:17:15 - train: epoch 0097, iter [01000, 01251], lr: 0.000002, loss: 0.4070
2022-10-05 00:17:34 - train: epoch 0097, iter [01010, 01251], lr: 0.000002, loss: 0.3831
2022-10-05 00:17:54 - train: epoch 0097, iter [01020, 01251], lr: 0.000002, loss: 0.4149
2022-10-05 00:18:13 - train: epoch 0097, iter [01030, 01251], lr: 0.000002, loss: 0.3919
2022-10-05 00:18:32 - train: epoch 0097, iter [01040, 01251], lr: 0.000002, loss: 0.3890
2022-10-05 00:18:52 - train: epoch 0097, iter [01050, 01251], lr: 0.000002, loss: 0.4014
2022-10-05 00:19:12 - train: epoch 0097, iter [01060, 01251], lr: 0.000002, loss: 0.3881
2022-10-05 00:19:31 - train: epoch 0097, iter [01070, 01251], lr: 0.000002, loss: 0.3887
2022-10-05 00:19:51 - train: epoch 0097, iter [01080, 01251], lr: 0.000002, loss: 0.3986
2022-10-05 00:20:10 - train: epoch 0097, iter [01090, 01251], lr: 0.000002, loss: 0.3868
2022-10-05 00:20:30 - train: epoch 0097, iter [01100, 01251], lr: 0.000002, loss: 0.4045
2022-10-05 00:20:49 - train: epoch 0097, iter [01110, 01251], lr: 0.000002, loss: 0.3836
2022-10-05 00:21:08 - train: epoch 0097, iter [01120, 01251], lr: 0.000002, loss: 0.3805
2022-10-05 00:21:28 - train: epoch 0097, iter [01130, 01251], lr: 0.000002, loss: 0.3986
2022-10-05 00:21:47 - train: epoch 0097, iter [01140, 01251], lr: 0.000002, loss: 0.3885
2022-10-05 00:22:07 - train: epoch 0097, iter [01150, 01251], lr: 0.000002, loss: 0.3995
2022-10-05 00:22:26 - train: epoch 0097, iter [01160, 01251], lr: 0.000002, loss: 0.3956
2022-10-05 00:22:46 - train: epoch 0097, iter [01170, 01251], lr: 0.000002, loss: 0.3855
2022-10-05 00:23:06 - train: epoch 0097, iter [01180, 01251], lr: 0.000002, loss: 0.4015
2022-10-05 00:23:25 - train: epoch 0097, iter [01190, 01251], lr: 0.000002, loss: 0.3974
2022-10-05 00:23:45 - train: epoch 0097, iter [01200, 01251], lr: 0.000002, loss: 0.3905
2022-10-05 00:24:05 - train: epoch 0097, iter [01210, 01251], lr: 0.000002, loss: 0.4219
2022-10-05 00:24:24 - train: epoch 0097, iter [01220, 01251], lr: 0.000002, loss: 0.3964
2022-10-05 00:24:43 - train: epoch 0097, iter [01230, 01251], lr: 0.000002, loss: 0.3929
2022-10-05 00:25:03 - train: epoch 0097, iter [01240, 01251], lr: 0.000002, loss: 0.4041
2022-10-05 00:25:22 - train: epoch 0097, iter [01250, 01251], lr: 0.000002, loss: 0.3949
2022-10-05 00:25:26 - train: epoch 097, train_loss: 0.3986
2022-10-05 00:25:30 - until epoch: 097, best_loss: 0.3986
2022-10-05 00:25:30 - epoch 098 lr: 0.000002
2022-10-05 00:25:56 - train: epoch 0098, iter [00010, 01251], lr: 0.000002, loss: 0.4187
2022-10-05 00:26:15 - train: epoch 0098, iter [00020, 01251], lr: 0.000002, loss: 0.3996
2022-10-05 00:26:35 - train: epoch 0098, iter [00030, 01251], lr: 0.000002, loss: 0.3867
2022-10-05 00:26:55 - train: epoch 0098, iter [00040, 01251], lr: 0.000002, loss: 0.3992
2022-10-05 00:27:14 - train: epoch 0098, iter [00050, 01251], lr: 0.000002, loss: 0.3967
2022-10-05 00:27:34 - train: epoch 0098, iter [00060, 01251], lr: 0.000002, loss: 0.4118
2022-10-05 00:27:54 - train: epoch 0098, iter [00070, 01251], lr: 0.000002, loss: 0.3756
2022-10-05 00:28:13 - train: epoch 0098, iter [00080, 01251], lr: 0.000002, loss: 0.3990
2022-10-05 00:28:33 - train: epoch 0098, iter [00090, 01251], lr: 0.000002, loss: 0.3838
2022-10-05 00:28:53 - train: epoch 0098, iter [00100, 01251], lr: 0.000002, loss: 0.3881
2022-10-05 00:29:12 - train: epoch 0098, iter [00110, 01251], lr: 0.000002, loss: 0.3923
2022-10-05 00:29:32 - train: epoch 0098, iter [00120, 01251], lr: 0.000002, loss: 0.4086
2022-10-05 00:29:52 - train: epoch 0098, iter [00130, 01251], lr: 0.000002, loss: 0.4010
2022-10-05 00:30:11 - train: epoch 0098, iter [00140, 01251], lr: 0.000002, loss: 0.4157
2022-10-05 00:30:31 - train: epoch 0098, iter [00150, 01251], lr: 0.000002, loss: 0.4115
2022-10-05 00:30:50 - train: epoch 0098, iter [00160, 01251], lr: 0.000002, loss: 0.4094
2022-10-05 00:31:10 - train: epoch 0098, iter [00170, 01251], lr: 0.000001, loss: 0.3862
2022-10-05 00:31:30 - train: epoch 0098, iter [00180, 01251], lr: 0.000001, loss: 0.4097
2022-10-05 00:31:49 - train: epoch 0098, iter [00190, 01251], lr: 0.000001, loss: 0.4231
2022-10-05 00:32:08 - train: epoch 0098, iter [00200, 01251], lr: 0.000001, loss: 0.4099
2022-10-05 00:32:28 - train: epoch 0098, iter [00210, 01251], lr: 0.000001, loss: 0.3957
2022-10-05 00:32:48 - train: epoch 0098, iter [00220, 01251], lr: 0.000001, loss: 0.3924
2022-10-05 00:33:07 - train: epoch 0098, iter [00230, 01251], lr: 0.000001, loss: 0.4226
2022-10-05 00:33:27 - train: epoch 0098, iter [00240, 01251], lr: 0.000001, loss: 0.4001
2022-10-05 00:33:47 - train: epoch 0098, iter [00250, 01251], lr: 0.000001, loss: 0.4083
2022-10-05 00:34:06 - train: epoch 0098, iter [00260, 01251], lr: 0.000001, loss: 0.4232
2022-10-05 00:34:26 - train: epoch 0098, iter [00270, 01251], lr: 0.000001, loss: 0.3992
2022-10-05 00:34:45 - train: epoch 0098, iter [00280, 01251], lr: 0.000001, loss: 0.4265
2022-10-05 00:35:05 - train: epoch 0098, iter [00290, 01251], lr: 0.000001, loss: 0.3903
2022-10-05 00:35:24 - train: epoch 0098, iter [00300, 01251], lr: 0.000001, loss: 0.3970
2022-10-05 00:35:44 - train: epoch 0098, iter [00310, 01251], lr: 0.000001, loss: 0.4098
2022-10-05 00:36:04 - train: epoch 0098, iter [00320, 01251], lr: 0.000001, loss: 0.3964
2022-10-05 00:36:23 - train: epoch 0098, iter [00330, 01251], lr: 0.000001, loss: 0.3969
2022-10-05 00:36:43 - train: epoch 0098, iter [00340, 01251], lr: 0.000001, loss: 0.3914
2022-10-05 00:37:02 - train: epoch 0098, iter [00350, 01251], lr: 0.000001, loss: 0.4141
2022-10-05 00:37:22 - train: epoch 0098, iter [00360, 01251], lr: 0.000001, loss: 0.3938
2022-10-05 00:37:42 - train: epoch 0098, iter [00370, 01251], lr: 0.000001, loss: 0.4069
2022-10-05 00:38:01 - train: epoch 0098, iter [00380, 01251], lr: 0.000001, loss: 0.3937
2022-10-05 00:38:20 - train: epoch 0098, iter [00390, 01251], lr: 0.000001, loss: 0.4008
2022-10-05 00:38:40 - train: epoch 0098, iter [00400, 01251], lr: 0.000001, loss: 0.3986
2022-10-05 00:39:00 - train: epoch 0098, iter [00410, 01251], lr: 0.000001, loss: 0.4151
2022-10-05 00:39:19 - train: epoch 0098, iter [00420, 01251], lr: 0.000001, loss: 0.3902
2022-10-05 00:39:39 - train: epoch 0098, iter [00430, 01251], lr: 0.000001, loss: 0.4262
2022-10-05 00:39:58 - train: epoch 0098, iter [00440, 01251], lr: 0.000001, loss: 0.4047
2022-10-05 00:40:18 - train: epoch 0098, iter [00450, 01251], lr: 0.000001, loss: 0.3854
2022-10-05 00:40:38 - train: epoch 0098, iter [00460, 01251], lr: 0.000001, loss: 0.3866
2022-10-05 00:40:57 - train: epoch 0098, iter [00470, 01251], lr: 0.000001, loss: 0.3880
2022-10-05 00:41:17 - train: epoch 0098, iter [00480, 01251], lr: 0.000001, loss: 0.3987
2022-10-05 00:41:37 - train: epoch 0098, iter [00490, 01251], lr: 0.000001, loss: 0.4030
2022-10-05 00:41:56 - train: epoch 0098, iter [00500, 01251], lr: 0.000001, loss: 0.3934
2022-10-05 00:42:16 - train: epoch 0098, iter [00510, 01251], lr: 0.000001, loss: 0.4000
2022-10-05 00:42:36 - train: epoch 0098, iter [00520, 01251], lr: 0.000001, loss: 0.3997
2022-10-05 00:42:55 - train: epoch 0098, iter [00530, 01251], lr: 0.000001, loss: 0.3940
2022-10-05 00:43:15 - train: epoch 0098, iter [00540, 01251], lr: 0.000001, loss: 0.4180
2022-10-05 00:43:34 - train: epoch 0098, iter [00550, 01251], lr: 0.000001, loss: 0.3792
2022-10-05 00:43:54 - train: epoch 0098, iter [00560, 01251], lr: 0.000001, loss: 0.3874
2022-10-05 00:44:13 - train: epoch 0098, iter [00570, 01251], lr: 0.000001, loss: 0.3980
2022-10-05 00:44:33 - train: epoch 0098, iter [00580, 01251], lr: 0.000001, loss: 0.3972
2022-10-05 00:44:52 - train: epoch 0098, iter [00590, 01251], lr: 0.000001, loss: 0.3946
2022-10-05 00:45:12 - train: epoch 0098, iter [00600, 01251], lr: 0.000001, loss: 0.4144
2022-10-05 00:45:31 - train: epoch 0098, iter [00610, 01251], lr: 0.000001, loss: 0.4078
2022-10-05 00:45:51 - train: epoch 0098, iter [00620, 01251], lr: 0.000001, loss: 0.3896
2022-10-05 00:46:11 - train: epoch 0098, iter [00630, 01251], lr: 0.000001, loss: 0.4043
2022-10-05 00:46:30 - train: epoch 0098, iter [00640, 01251], lr: 0.000001, loss: 0.4108
2022-10-05 00:46:49 - train: epoch 0098, iter [00650, 01251], lr: 0.000001, loss: 0.4142
2022-10-05 00:47:10 - train: epoch 0098, iter [00660, 01251], lr: 0.000001, loss: 0.3888
2022-10-05 00:47:29 - train: epoch 0098, iter [00670, 01251], lr: 0.000001, loss: 0.3921
2022-10-05 00:47:48 - train: epoch 0098, iter [00680, 01251], lr: 0.000001, loss: 0.3916
2022-10-05 00:48:08 - train: epoch 0098, iter [00690, 01251], lr: 0.000001, loss: 0.3966
2022-10-05 00:48:27 - train: epoch 0098, iter [00700, 01251], lr: 0.000001, loss: 0.3997
2022-10-05 00:48:47 - train: epoch 0098, iter [00710, 01251], lr: 0.000001, loss: 0.3930
2022-10-05 00:49:07 - train: epoch 0098, iter [00720, 01251], lr: 0.000001, loss: 0.3827
2022-10-05 00:49:26 - train: epoch 0098, iter [00730, 01251], lr: 0.000001, loss: 0.3990
2022-10-05 00:49:46 - train: epoch 0098, iter [00740, 01251], lr: 0.000001, loss: 0.4124
2022-10-05 00:50:06 - train: epoch 0098, iter [00750, 01251], lr: 0.000001, loss: 0.4014
2022-10-05 00:50:25 - train: epoch 0098, iter [00760, 01251], lr: 0.000001, loss: 0.4041
2022-10-05 00:50:45 - train: epoch 0098, iter [00770, 01251], lr: 0.000001, loss: 0.4018
2022-10-05 00:51:04 - train: epoch 0098, iter [00780, 01251], lr: 0.000001, loss: 0.3949
2022-10-05 00:51:24 - train: epoch 0098, iter [00790, 01251], lr: 0.000001, loss: 0.4064
2022-10-05 00:51:43 - train: epoch 0098, iter [00800, 01251], lr: 0.000001, loss: 0.3899
2022-10-05 00:52:03 - train: epoch 0098, iter [00810, 01251], lr: 0.000001, loss: 0.4001
2022-10-05 00:52:22 - train: epoch 0098, iter [00820, 01251], lr: 0.000001, loss: 0.4095
2022-10-05 00:52:42 - train: epoch 0098, iter [00830, 01251], lr: 0.000001, loss: 0.3964
2022-10-05 00:53:01 - train: epoch 0098, iter [00840, 01251], lr: 0.000001, loss: 0.3795
2022-10-05 00:53:20 - train: epoch 0098, iter [00850, 01251], lr: 0.000001, loss: 0.3674
2022-10-05 00:53:40 - train: epoch 0098, iter [00860, 01251], lr: 0.000001, loss: 0.4086
2022-10-05 00:53:59 - train: epoch 0098, iter [00870, 01251], lr: 0.000001, loss: 0.4098
2022-10-05 00:54:19 - train: epoch 0098, iter [00880, 01251], lr: 0.000001, loss: 0.3884
2022-10-05 00:54:38 - train: epoch 0098, iter [00890, 01251], lr: 0.000001, loss: 0.4182
2022-10-05 00:54:58 - train: epoch 0098, iter [00900, 01251], lr: 0.000001, loss: 0.3962
2022-10-05 00:55:18 - train: epoch 0098, iter [00910, 01251], lr: 0.000001, loss: 0.3961
2022-10-05 00:55:37 - train: epoch 0098, iter [00920, 01251], lr: 0.000001, loss: 0.3995
2022-10-05 00:55:57 - train: epoch 0098, iter [00930, 01251], lr: 0.000001, loss: 0.3889
2022-10-05 00:56:16 - train: epoch 0098, iter [00940, 01251], lr: 0.000001, loss: 0.3882
2022-10-05 00:56:36 - train: epoch 0098, iter [00950, 01251], lr: 0.000001, loss: 0.3985
2022-10-05 00:56:55 - train: epoch 0098, iter [00960, 01251], lr: 0.000001, loss: 0.3991
2022-10-05 00:57:15 - train: epoch 0098, iter [00970, 01251], lr: 0.000001, loss: 0.3950
2022-10-05 00:57:34 - train: epoch 0098, iter [00980, 01251], lr: 0.000001, loss: 0.3966
2022-10-05 00:57:54 - train: epoch 0098, iter [00990, 01251], lr: 0.000001, loss: 0.3820
2022-10-05 00:58:14 - train: epoch 0098, iter [01000, 01251], lr: 0.000001, loss: 0.4064
2022-10-05 00:58:33 - train: epoch 0098, iter [01010, 01251], lr: 0.000001, loss: 0.4024
2022-10-05 00:58:53 - train: epoch 0098, iter [01020, 01251], lr: 0.000001, loss: 0.3916
2022-10-05 00:59:12 - train: epoch 0098, iter [01030, 01251], lr: 0.000001, loss: 0.4171
2022-10-05 00:59:32 - train: epoch 0098, iter [01040, 01251], lr: 0.000001, loss: 0.3976
2022-10-05 00:59:51 - train: epoch 0098, iter [01050, 01251], lr: 0.000001, loss: 0.4095
2022-10-05 01:00:10 - train: epoch 0098, iter [01060, 01251], lr: 0.000001, loss: 0.3674
2022-10-05 01:00:30 - train: epoch 0098, iter [01070, 01251], lr: 0.000001, loss: 0.4083
2022-10-05 01:00:50 - train: epoch 0098, iter [01080, 01251], lr: 0.000001, loss: 0.3975
2022-10-05 01:01:10 - train: epoch 0098, iter [01090, 01251], lr: 0.000001, loss: 0.3859
2022-10-05 01:01:29 - train: epoch 0098, iter [01100, 01251], lr: 0.000001, loss: 0.4007
2022-10-05 01:01:49 - train: epoch 0098, iter [01110, 01251], lr: 0.000001, loss: 0.3754
2022-10-05 01:02:08 - train: epoch 0098, iter [01120, 01251], lr: 0.000001, loss: 0.4140
2022-10-05 01:02:27 - train: epoch 0098, iter [01130, 01251], lr: 0.000001, loss: 0.3834
2022-10-05 01:02:47 - train: epoch 0098, iter [01140, 01251], lr: 0.000001, loss: 0.3907
2022-10-05 01:03:07 - train: epoch 0098, iter [01150, 01251], lr: 0.000001, loss: 0.4030
2022-10-05 01:03:26 - train: epoch 0098, iter [01160, 01251], lr: 0.000001, loss: 0.4099
2022-10-05 01:03:46 - train: epoch 0098, iter [01170, 01251], lr: 0.000001, loss: 0.3920
2022-10-05 01:04:06 - train: epoch 0098, iter [01180, 01251], lr: 0.000001, loss: 0.4014
2022-10-05 01:04:25 - train: epoch 0098, iter [01190, 01251], lr: 0.000001, loss: 0.4026
2022-10-05 01:04:44 - train: epoch 0098, iter [01200, 01251], lr: 0.000001, loss: 0.3945
2022-10-05 01:05:04 - train: epoch 0098, iter [01210, 01251], lr: 0.000001, loss: 0.3973
2022-10-05 01:05:23 - train: epoch 0098, iter [01220, 01251], lr: 0.000001, loss: 0.4012
2022-10-05 01:05:43 - train: epoch 0098, iter [01230, 01251], lr: 0.000001, loss: 0.3997
2022-10-05 01:06:02 - train: epoch 0098, iter [01240, 01251], lr: 0.000001, loss: 0.4011
2022-10-05 01:06:21 - train: epoch 0098, iter [01250, 01251], lr: 0.000001, loss: 0.3940
2022-10-05 01:06:25 - train: epoch 098, train_loss: 0.3986
2022-10-05 01:06:29 - until epoch: 098, best_loss: 0.3986
2022-10-05 01:06:29 - epoch 099 lr: 0.000001
2022-10-05 01:06:56 - train: epoch 0099, iter [00010, 01251], lr: 0.000001, loss: 0.3937
2022-10-05 01:07:15 - train: epoch 0099, iter [00020, 01251], lr: 0.000001, loss: 0.4043
2022-10-05 01:07:35 - train: epoch 0099, iter [00030, 01251], lr: 0.000001, loss: 0.3844
2022-10-05 01:07:54 - train: epoch 0099, iter [00040, 01251], lr: 0.000001, loss: 0.4146
2022-10-05 01:08:14 - train: epoch 0099, iter [00050, 01251], lr: 0.000001, loss: 0.3960
2022-10-05 01:08:33 - train: epoch 0099, iter [00060, 01251], lr: 0.000001, loss: 0.3933
2022-10-05 01:08:53 - train: epoch 0099, iter [00070, 01251], lr: 0.000001, loss: 0.4103
2022-10-05 01:09:12 - train: epoch 0099, iter [00080, 01251], lr: 0.000001, loss: 0.3822
2022-10-05 01:09:32 - train: epoch 0099, iter [00090, 01251], lr: 0.000001, loss: 0.3866
2022-10-05 01:09:52 - train: epoch 0099, iter [00100, 01251], lr: 0.000001, loss: 0.3878
2022-10-05 01:10:11 - train: epoch 0099, iter [00110, 01251], lr: 0.000001, loss: 0.3798
2022-10-05 01:10:31 - train: epoch 0099, iter [00120, 01251], lr: 0.000001, loss: 0.3878
2022-10-05 01:10:50 - train: epoch 0099, iter [00130, 01251], lr: 0.000001, loss: 0.4045
2022-10-05 01:11:10 - train: epoch 0099, iter [00140, 01251], lr: 0.000001, loss: 0.3888
2022-10-05 01:11:29 - train: epoch 0099, iter [00150, 01251], lr: 0.000001, loss: 0.3923
2022-10-05 01:11:49 - train: epoch 0099, iter [00160, 01251], lr: 0.000001, loss: 0.4275
2022-10-05 01:12:09 - train: epoch 0099, iter [00170, 01251], lr: 0.000001, loss: 0.4016
2022-10-05 01:12:28 - train: epoch 0099, iter [00180, 01251], lr: 0.000001, loss: 0.4011
2022-10-05 01:12:48 - train: epoch 0099, iter [00190, 01251], lr: 0.000001, loss: 0.3903
2022-10-05 01:13:07 - train: epoch 0099, iter [00200, 01251], lr: 0.000001, loss: 0.3797
2022-10-05 01:13:27 - train: epoch 0099, iter [00210, 01251], lr: 0.000001, loss: 0.3941
2022-10-05 01:13:46 - train: epoch 0099, iter [00220, 01251], lr: 0.000001, loss: 0.3962
2022-10-05 01:14:06 - train: epoch 0099, iter [00230, 01251], lr: 0.000001, loss: 0.4211
2022-10-05 01:14:25 - train: epoch 0099, iter [00240, 01251], lr: 0.000001, loss: 0.3986
2022-10-05 01:14:45 - train: epoch 0099, iter [00250, 01251], lr: 0.000001, loss: 0.3968
2022-10-05 01:15:04 - train: epoch 0099, iter [00260, 01251], lr: 0.000001, loss: 0.3921
2022-10-05 01:15:24 - train: epoch 0099, iter [00270, 01251], lr: 0.000001, loss: 0.3873
2022-10-05 01:15:44 - train: epoch 0099, iter [00280, 01251], lr: 0.000001, loss: 0.4000
2022-10-05 01:16:03 - train: epoch 0099, iter [00290, 01251], lr: 0.000001, loss: 0.3980
2022-10-05 01:16:23 - train: epoch 0099, iter [00300, 01251], lr: 0.000001, loss: 0.4031
2022-10-05 01:16:42 - train: epoch 0099, iter [00310, 01251], lr: 0.000001, loss: 0.3943
2022-10-05 01:17:02 - train: epoch 0099, iter [00320, 01251], lr: 0.000001, loss: 0.4137
2022-10-05 01:17:22 - train: epoch 0099, iter [00330, 01251], lr: 0.000001, loss: 0.4204
2022-10-05 01:17:41 - train: epoch 0099, iter [00340, 01251], lr: 0.000001, loss: 0.3806
2022-10-05 01:18:01 - train: epoch 0099, iter [00350, 01251], lr: 0.000001, loss: 0.3862
2022-10-05 01:18:20 - train: epoch 0099, iter [00360, 01251], lr: 0.000001, loss: 0.4039
2022-10-05 01:18:40 - train: epoch 0099, iter [00370, 01251], lr: 0.000001, loss: 0.4194
2022-10-05 01:18:59 - train: epoch 0099, iter [00380, 01251], lr: 0.000001, loss: 0.4064
2022-10-05 01:19:19 - train: epoch 0099, iter [00390, 01251], lr: 0.000001, loss: 0.4002
2022-10-05 01:19:38 - train: epoch 0099, iter [00400, 01251], lr: 0.000001, loss: 0.3851
2022-10-05 01:19:57 - train: epoch 0099, iter [00410, 01251], lr: 0.000001, loss: 0.3736
2022-10-05 01:20:17 - train: epoch 0099, iter [00420, 01251], lr: 0.000001, loss: 0.3925
2022-10-05 01:20:36 - train: epoch 0099, iter [00430, 01251], lr: 0.000001, loss: 0.3949
2022-10-05 01:20:56 - train: epoch 0099, iter [00440, 01251], lr: 0.000000, loss: 0.3976
2022-10-05 01:21:15 - train: epoch 0099, iter [00450, 01251], lr: 0.000000, loss: 0.3967
2022-10-05 01:21:35 - train: epoch 0099, iter [00460, 01251], lr: 0.000000, loss: 0.3835
2022-10-05 01:21:55 - train: epoch 0099, iter [00470, 01251], lr: 0.000000, loss: 0.3891
2022-10-05 01:22:14 - train: epoch 0099, iter [00480, 01251], lr: 0.000000, loss: 0.3973
2022-10-05 01:22:34 - train: epoch 0099, iter [00490, 01251], lr: 0.000000, loss: 0.4003
2022-10-05 01:22:53 - train: epoch 0099, iter [00500, 01251], lr: 0.000000, loss: 0.4035
2022-10-05 01:23:13 - train: epoch 0099, iter [00510, 01251], lr: 0.000000, loss: 0.4089
2022-10-05 01:23:33 - train: epoch 0099, iter [00520, 01251], lr: 0.000000, loss: 0.3997
2022-10-05 01:23:52 - train: epoch 0099, iter [00530, 01251], lr: 0.000000, loss: 0.3842
2022-10-05 01:24:12 - train: epoch 0099, iter [00540, 01251], lr: 0.000000, loss: 0.3858
2022-10-05 01:24:31 - train: epoch 0099, iter [00550, 01251], lr: 0.000000, loss: 0.3849
2022-10-05 01:24:51 - train: epoch 0099, iter [00560, 01251], lr: 0.000000, loss: 0.3936
2022-10-05 01:25:11 - train: epoch 0099, iter [00570, 01251], lr: 0.000000, loss: 0.4115
2022-10-05 01:25:30 - train: epoch 0099, iter [00580, 01251], lr: 0.000000, loss: 0.4003
2022-10-05 01:25:50 - train: epoch 0099, iter [00590, 01251], lr: 0.000000, loss: 0.4005
2022-10-05 01:26:09 - train: epoch 0099, iter [00600, 01251], lr: 0.000000, loss: 0.4043
2022-10-05 01:26:29 - train: epoch 0099, iter [00610, 01251], lr: 0.000000, loss: 0.3957
2022-10-05 01:26:48 - train: epoch 0099, iter [00620, 01251], lr: 0.000000, loss: 0.4108
2022-10-05 01:27:08 - train: epoch 0099, iter [00630, 01251], lr: 0.000000, loss: 0.3844
2022-10-05 01:27:28 - train: epoch 0099, iter [00640, 01251], lr: 0.000000, loss: 0.3928
2022-10-05 01:27:47 - train: epoch 0099, iter [00650, 01251], lr: 0.000000, loss: 0.3899
2022-10-05 01:28:07 - train: epoch 0099, iter [00660, 01251], lr: 0.000000, loss: 0.4141
2022-10-05 01:28:26 - train: epoch 0099, iter [00670, 01251], lr: 0.000000, loss: 0.3831
2022-10-05 01:28:46 - train: epoch 0099, iter [00680, 01251], lr: 0.000000, loss: 0.3964
2022-10-05 01:29:06 - train: epoch 0099, iter [00690, 01251], lr: 0.000000, loss: 0.3917
2022-10-05 01:29:25 - train: epoch 0099, iter [00700, 01251], lr: 0.000000, loss: 0.3792
2022-10-05 01:29:45 - train: epoch 0099, iter [00710, 01251], lr: 0.000000, loss: 0.3822
2022-10-05 01:30:04 - train: epoch 0099, iter [00720, 01251], lr: 0.000000, loss: 0.3980
2022-10-05 01:30:24 - train: epoch 0099, iter [00730, 01251], lr: 0.000000, loss: 0.4127
2022-10-05 01:30:43 - train: epoch 0099, iter [00740, 01251], lr: 0.000000, loss: 0.4002
2022-10-05 01:31:02 - train: epoch 0099, iter [00750, 01251], lr: 0.000000, loss: 0.3724
2022-10-05 01:31:22 - train: epoch 0099, iter [00760, 01251], lr: 0.000000, loss: 0.4042
2022-10-05 01:31:42 - train: epoch 0099, iter [00770, 01251], lr: 0.000000, loss: 0.4107
2022-10-05 01:32:01 - train: epoch 0099, iter [00780, 01251], lr: 0.000000, loss: 0.4026
2022-10-05 01:32:21 - train: epoch 0099, iter [00790, 01251], lr: 0.000000, loss: 0.4221
2022-10-05 01:32:40 - train: epoch 0099, iter [00800, 01251], lr: 0.000000, loss: 0.3826
2022-10-05 01:33:00 - train: epoch 0099, iter [00810, 01251], lr: 0.000000, loss: 0.3858
2022-10-05 01:33:19 - train: epoch 0099, iter [00820, 01251], lr: 0.000000, loss: 0.4155
2022-10-05 01:33:39 - train: epoch 0099, iter [00830, 01251], lr: 0.000000, loss: 0.4041
2022-10-05 01:33:59 - train: epoch 0099, iter [00840, 01251], lr: 0.000000, loss: 0.4134
2022-10-05 01:34:18 - train: epoch 0099, iter [00850, 01251], lr: 0.000000, loss: 0.4163
2022-10-05 01:34:38 - train: epoch 0099, iter [00860, 01251], lr: 0.000000, loss: 0.4124
2022-10-05 01:34:57 - train: epoch 0099, iter [00870, 01251], lr: 0.000000, loss: 0.3990
2022-10-05 01:35:16 - train: epoch 0099, iter [00880, 01251], lr: 0.000000, loss: 0.3915
2022-10-05 01:35:36 - train: epoch 0099, iter [00890, 01251], lr: 0.000000, loss: 0.4002
2022-10-05 01:35:56 - train: epoch 0099, iter [00900, 01251], lr: 0.000000, loss: 0.4110
2022-10-05 01:36:15 - train: epoch 0099, iter [00910, 01251], lr: 0.000000, loss: 0.4071
2022-10-05 01:36:34 - train: epoch 0099, iter [00920, 01251], lr: 0.000000, loss: 0.3980
2022-10-05 01:36:54 - train: epoch 0099, iter [00930, 01251], lr: 0.000000, loss: 0.3925
2022-10-05 01:37:14 - train: epoch 0099, iter [00940, 01251], lr: 0.000000, loss: 0.3984
2022-10-05 01:37:33 - train: epoch 0099, iter [00950, 01251], lr: 0.000000, loss: 0.4020
2022-10-05 01:37:53 - train: epoch 0099, iter [00960, 01251], lr: 0.000000, loss: 0.3833
2022-10-05 01:38:12 - train: epoch 0099, iter [00970, 01251], lr: 0.000000, loss: 0.4035
2022-10-05 01:38:32 - train: epoch 0099, iter [00980, 01251], lr: 0.000000, loss: 0.4049
2022-10-05 01:38:52 - train: epoch 0099, iter [00990, 01251], lr: 0.000000, loss: 0.4002
2022-10-05 01:39:11 - train: epoch 0099, iter [01000, 01251], lr: 0.000000, loss: 0.3723
2022-10-05 01:39:31 - train: epoch 0099, iter [01010, 01251], lr: 0.000000, loss: 0.4089
2022-10-05 01:39:50 - train: epoch 0099, iter [01020, 01251], lr: 0.000000, loss: 0.3920
2022-10-05 01:40:10 - train: epoch 0099, iter [01030, 01251], lr: 0.000000, loss: 0.4158
2022-10-05 01:40:29 - train: epoch 0099, iter [01040, 01251], lr: 0.000000, loss: 0.3966
2022-10-05 01:40:49 - train: epoch 0099, iter [01050, 01251], lr: 0.000000, loss: 0.4029
2022-10-05 01:41:08 - train: epoch 0099, iter [01060, 01251], lr: 0.000000, loss: 0.4123
2022-10-05 01:41:28 - train: epoch 0099, iter [01070, 01251], lr: 0.000000, loss: 0.4211
2022-10-05 01:41:47 - train: epoch 0099, iter [01080, 01251], lr: 0.000000, loss: 0.3974
2022-10-05 01:42:07 - train: epoch 0099, iter [01090, 01251], lr: 0.000000, loss: 0.3876
2022-10-05 01:42:27 - train: epoch 0099, iter [01100, 01251], lr: 0.000000, loss: 0.4277
2022-10-05 01:42:46 - train: epoch 0099, iter [01110, 01251], lr: 0.000000, loss: 0.4072
2022-10-05 01:43:05 - train: epoch 0099, iter [01120, 01251], lr: 0.000000, loss: 0.3825
2022-10-05 01:43:25 - train: epoch 0099, iter [01130, 01251], lr: 0.000000, loss: 0.3939
2022-10-05 01:43:45 - train: epoch 0099, iter [01140, 01251], lr: 0.000000, loss: 0.3936
2022-10-05 01:44:04 - train: epoch 0099, iter [01150, 01251], lr: 0.000000, loss: 0.4003
2022-10-05 01:44:24 - train: epoch 0099, iter [01160, 01251], lr: 0.000000, loss: 0.3969
2022-10-05 01:44:43 - train: epoch 0099, iter [01170, 01251], lr: 0.000000, loss: 0.3884
2022-10-05 01:45:03 - train: epoch 0099, iter [01180, 01251], lr: 0.000000, loss: 0.3968
2022-10-05 01:45:22 - train: epoch 0099, iter [01190, 01251], lr: 0.000000, loss: 0.3862
2022-10-05 01:45:42 - train: epoch 0099, iter [01200, 01251], lr: 0.000000, loss: 0.3992
2022-10-05 01:46:02 - train: epoch 0099, iter [01210, 01251], lr: 0.000000, loss: 0.4002
2022-10-05 01:46:21 - train: epoch 0099, iter [01220, 01251], lr: 0.000000, loss: 0.3862
2022-10-05 01:46:41 - train: epoch 0099, iter [01230, 01251], lr: 0.000000, loss: 0.4068
2022-10-05 01:47:00 - train: epoch 0099, iter [01240, 01251], lr: 0.000000, loss: 0.4054
2022-10-05 01:47:19 - train: epoch 0099, iter [01250, 01251], lr: 0.000000, loss: 0.4082
2022-10-05 01:47:23 - train: epoch 099, train_loss: 0.3986
2022-10-05 01:47:26 - until epoch: 099, best_loss: 0.3986
2022-10-05 01:47:26 - epoch 100 lr: 0.000000
2022-10-05 01:47:53 - train: epoch 0100, iter [00010, 01251], lr: 0.000000, loss: 0.4186
2022-10-05 01:48:13 - train: epoch 0100, iter [00020, 01251], lr: 0.000000, loss: 0.4012
2022-10-05 01:48:33 - train: epoch 0100, iter [00030, 01251], lr: 0.000000, loss: 0.4107
2022-10-05 01:48:52 - train: epoch 0100, iter [00040, 01251], lr: 0.000000, loss: 0.4269
2022-10-05 01:49:12 - train: epoch 0100, iter [00050, 01251], lr: 0.000000, loss: 0.3741
2022-10-05 01:49:31 - train: epoch 0100, iter [00060, 01251], lr: 0.000000, loss: 0.4099
2022-10-05 01:49:51 - train: epoch 0100, iter [00070, 01251], lr: 0.000000, loss: 0.3796
2022-10-05 01:50:10 - train: epoch 0100, iter [00080, 01251], lr: 0.000000, loss: 0.3926
2022-10-05 01:50:30 - train: epoch 0100, iter [00090, 01251], lr: 0.000000, loss: 0.3969
2022-10-05 01:50:50 - train: epoch 0100, iter [00100, 01251], lr: 0.000000, loss: 0.4047
2022-10-05 01:51:10 - train: epoch 0100, iter [00110, 01251], lr: 0.000000, loss: 0.3989
2022-10-05 01:51:29 - train: epoch 0100, iter [00120, 01251], lr: 0.000000, loss: 0.3972
2022-10-05 01:51:48 - train: epoch 0100, iter [00130, 01251], lr: 0.000000, loss: 0.4081
2022-10-05 01:52:08 - train: epoch 0100, iter [00140, 01251], lr: 0.000000, loss: 0.3995
2022-10-05 01:52:28 - train: epoch 0100, iter [00150, 01251], lr: 0.000000, loss: 0.4052
2022-10-05 01:52:47 - train: epoch 0100, iter [00160, 01251], lr: 0.000000, loss: 0.3915
2022-10-05 01:53:07 - train: epoch 0100, iter [00170, 01251], lr: 0.000000, loss: 0.3805
2022-10-05 01:53:27 - train: epoch 0100, iter [00180, 01251], lr: 0.000000, loss: 0.3899
2022-10-05 01:53:46 - train: epoch 0100, iter [00190, 01251], lr: 0.000000, loss: 0.4162
2022-10-05 01:54:06 - train: epoch 0100, iter [00200, 01251], lr: 0.000000, loss: 0.3968
2022-10-05 01:54:25 - train: epoch 0100, iter [00210, 01251], lr: 0.000000, loss: 0.4050
2022-10-05 01:54:45 - train: epoch 0100, iter [00220, 01251], lr: 0.000000, loss: 0.4029
2022-10-05 01:55:05 - train: epoch 0100, iter [00230, 01251], lr: 0.000000, loss: 0.3963
2022-10-05 01:55:25 - train: epoch 0100, iter [00240, 01251], lr: 0.000000, loss: 0.3969
2022-10-05 01:55:44 - train: epoch 0100, iter [00250, 01251], lr: 0.000000, loss: 0.4024
2022-10-05 01:56:04 - train: epoch 0100, iter [00260, 01251], lr: 0.000000, loss: 0.3830
2022-10-05 01:56:24 - train: epoch 0100, iter [00270, 01251], lr: 0.000000, loss: 0.3921
2022-10-05 01:56:43 - train: epoch 0100, iter [00280, 01251], lr: 0.000000, loss: 0.3966
2022-10-05 01:57:03 - train: epoch 0100, iter [00290, 01251], lr: 0.000000, loss: 0.3967
2022-10-05 01:57:22 - train: epoch 0100, iter [00300, 01251], lr: 0.000000, loss: 0.3857
2022-10-05 01:57:42 - train: epoch 0100, iter [00310, 01251], lr: 0.000000, loss: 0.4077
2022-10-05 01:58:01 - train: epoch 0100, iter [00320, 01251], lr: 0.000000, loss: 0.3996
2022-10-05 01:58:21 - train: epoch 0100, iter [00330, 01251], lr: 0.000000, loss: 0.4246
2022-10-05 01:58:41 - train: epoch 0100, iter [00340, 01251], lr: 0.000000, loss: 0.4017
2022-10-05 01:59:00 - train: epoch 0100, iter [00350, 01251], lr: 0.000000, loss: 0.3877
2022-10-05 01:59:20 - train: epoch 0100, iter [00360, 01251], lr: 0.000000, loss: 0.3978
2022-10-05 01:59:39 - train: epoch 0100, iter [00370, 01251], lr: 0.000000, loss: 0.4120
2022-10-05 01:59:59 - train: epoch 0100, iter [00380, 01251], lr: 0.000000, loss: 0.3979
2022-10-05 02:00:19 - train: epoch 0100, iter [00390, 01251], lr: 0.000000, loss: 0.3887
2022-10-05 02:00:38 - train: epoch 0100, iter [00400, 01251], lr: 0.000000, loss: 0.3842
2022-10-05 02:00:58 - train: epoch 0100, iter [00410, 01251], lr: 0.000000, loss: 0.3979
2022-10-05 02:01:17 - train: epoch 0100, iter [00420, 01251], lr: 0.000000, loss: 0.3851
2022-10-05 02:01:37 - train: epoch 0100, iter [00430, 01251], lr: 0.000000, loss: 0.3964
2022-10-05 02:01:56 - train: epoch 0100, iter [00440, 01251], lr: 0.000000, loss: 0.3862
2022-10-05 02:02:16 - train: epoch 0100, iter [00450, 01251], lr: 0.000000, loss: 0.3942
2022-10-05 02:02:35 - train: epoch 0100, iter [00460, 01251], lr: 0.000000, loss: 0.4038
2022-10-05 02:02:54 - train: epoch 0100, iter [00470, 01251], lr: 0.000000, loss: 0.3892
2022-10-05 02:03:14 - train: epoch 0100, iter [00480, 01251], lr: 0.000000, loss: 0.3862
2022-10-05 02:03:33 - train: epoch 0100, iter [00490, 01251], lr: 0.000000, loss: 0.3960
2022-10-05 02:03:53 - train: epoch 0100, iter [00500, 01251], lr: 0.000000, loss: 0.4228
2022-10-05 02:04:13 - train: epoch 0100, iter [00510, 01251], lr: 0.000000, loss: 0.3907
2022-10-05 02:04:33 - train: epoch 0100, iter [00520, 01251], lr: 0.000000, loss: 0.4011
2022-10-05 02:04:52 - train: epoch 0100, iter [00530, 01251], lr: 0.000000, loss: 0.3808
2022-10-05 02:05:12 - train: epoch 0100, iter [00540, 01251], lr: 0.000000, loss: 0.3856
2022-10-05 02:05:32 - train: epoch 0100, iter [00550, 01251], lr: 0.000000, loss: 0.4083
2022-10-05 02:05:51 - train: epoch 0100, iter [00560, 01251], lr: 0.000000, loss: 0.4035
2022-10-05 02:06:11 - train: epoch 0100, iter [00570, 01251], lr: 0.000000, loss: 0.3853
2022-10-05 02:06:30 - train: epoch 0100, iter [00580, 01251], lr: 0.000000, loss: 0.4008
2022-10-05 02:06:50 - train: epoch 0100, iter [00590, 01251], lr: 0.000000, loss: 0.3948
2022-10-05 02:07:09 - train: epoch 0100, iter [00600, 01251], lr: 0.000000, loss: 0.3936
2022-10-05 02:07:29 - train: epoch 0100, iter [00610, 01251], lr: 0.000000, loss: 0.3994
2022-10-05 02:07:49 - train: epoch 0100, iter [00620, 01251], lr: 0.000000, loss: 0.3837
2022-10-05 02:08:09 - train: epoch 0100, iter [00630, 01251], lr: 0.000000, loss: 0.4144
2022-10-05 02:08:28 - train: epoch 0100, iter [00640, 01251], lr: 0.000000, loss: 0.3921
2022-10-05 02:08:48 - train: epoch 0100, iter [00650, 01251], lr: 0.000000, loss: 0.3938
2022-10-05 02:09:07 - train: epoch 0100, iter [00660, 01251], lr: 0.000000, loss: 0.3969
2022-10-05 02:09:27 - train: epoch 0100, iter [00670, 01251], lr: 0.000000, loss: 0.3794
2022-10-05 02:09:46 - train: epoch 0100, iter [00680, 01251], lr: 0.000000, loss: 0.4043
2022-10-05 02:10:06 - train: epoch 0100, iter [00690, 01251], lr: 0.000000, loss: 0.4070
2022-10-05 02:10:25 - train: epoch 0100, iter [00700, 01251], lr: 0.000000, loss: 0.3893
2022-10-05 02:10:45 - train: epoch 0100, iter [00710, 01251], lr: 0.000000, loss: 0.3885
2022-10-05 02:11:05 - train: epoch 0100, iter [00720, 01251], lr: 0.000000, loss: 0.3970
2022-10-05 02:11:24 - train: epoch 0100, iter [00730, 01251], lr: 0.000000, loss: 0.4125
2022-10-05 02:11:44 - train: epoch 0100, iter [00740, 01251], lr: 0.000000, loss: 0.3960
2022-10-05 02:12:03 - train: epoch 0100, iter [00750, 01251], lr: 0.000000, loss: 0.4091
2022-10-05 02:12:23 - train: epoch 0100, iter [00760, 01251], lr: 0.000000, loss: 0.4037
2022-10-05 02:12:42 - train: epoch 0100, iter [00770, 01251], lr: 0.000000, loss: 0.3977
2022-10-05 02:13:02 - train: epoch 0100, iter [00780, 01251], lr: 0.000000, loss: 0.3790
2022-10-05 02:13:21 - train: epoch 0100, iter [00790, 01251], lr: 0.000000, loss: 0.4066
2022-10-05 02:13:41 - train: epoch 0100, iter [00800, 01251], lr: 0.000000, loss: 0.3886
2022-10-05 02:14:01 - train: epoch 0100, iter [00810, 01251], lr: 0.000000, loss: 0.3876
2022-10-05 02:14:20 - train: epoch 0100, iter [00820, 01251], lr: 0.000000, loss: 0.3984
2022-10-05 02:14:40 - train: epoch 0100, iter [00830, 01251], lr: 0.000000, loss: 0.3805
2022-10-05 02:14:59 - train: epoch 0100, iter [00840, 01251], lr: 0.000000, loss: 0.4025
2022-10-05 02:15:19 - train: epoch 0100, iter [00850, 01251], lr: 0.000000, loss: 0.3956
2022-10-05 02:15:38 - train: epoch 0100, iter [00860, 01251], lr: 0.000000, loss: 0.3856
2022-10-05 02:15:58 - train: epoch 0100, iter [00870, 01251], lr: 0.000000, loss: 0.3936
2022-10-05 02:16:17 - train: epoch 0100, iter [00880, 01251], lr: 0.000000, loss: 0.3991
2022-10-05 02:16:37 - train: epoch 0100, iter [00890, 01251], lr: 0.000000, loss: 0.3971
2022-10-05 02:16:56 - train: epoch 0100, iter [00900, 01251], lr: 0.000000, loss: 0.3977
2022-10-05 02:17:16 - train: epoch 0100, iter [00910, 01251], lr: 0.000000, loss: 0.4119
2022-10-05 02:17:35 - train: epoch 0100, iter [00920, 01251], lr: 0.000000, loss: 0.3948
2022-10-05 02:17:55 - train: epoch 0100, iter [00930, 01251], lr: 0.000000, loss: 0.4172
2022-10-05 02:18:14 - train: epoch 0100, iter [00940, 01251], lr: 0.000000, loss: 0.3865
2022-10-05 02:18:34 - train: epoch 0100, iter [00950, 01251], lr: 0.000000, loss: 0.4114
2022-10-05 02:18:53 - train: epoch 0100, iter [00960, 01251], lr: 0.000000, loss: 0.3897
2022-10-05 02:19:13 - train: epoch 0100, iter [00970, 01251], lr: 0.000000, loss: 0.4016
2022-10-05 02:19:32 - train: epoch 0100, iter [00980, 01251], lr: 0.000000, loss: 0.4215
2022-10-05 02:19:51 - train: epoch 0100, iter [00990, 01251], lr: 0.000000, loss: 0.3903
2022-10-05 02:20:11 - train: epoch 0100, iter [01000, 01251], lr: 0.000000, loss: 0.3868
2022-10-05 02:20:31 - train: epoch 0100, iter [01010, 01251], lr: 0.000000, loss: 0.3903
2022-10-05 02:20:50 - train: epoch 0100, iter [01020, 01251], lr: 0.000000, loss: 0.4138
2022-10-05 02:21:10 - train: epoch 0100, iter [01030, 01251], lr: 0.000000, loss: 0.4113
2022-10-05 02:21:29 - train: epoch 0100, iter [01040, 01251], lr: 0.000000, loss: 0.4078
2022-10-05 02:21:48 - train: epoch 0100, iter [01050, 01251], lr: 0.000000, loss: 0.3942
2022-10-05 02:22:08 - train: epoch 0100, iter [01060, 01251], lr: 0.000000, loss: 0.4047
2022-10-05 02:22:28 - train: epoch 0100, iter [01070, 01251], lr: 0.000000, loss: 0.4139
2022-10-05 02:22:47 - train: epoch 0100, iter [01080, 01251], lr: 0.000000, loss: 0.4022
2022-10-05 02:23:06 - train: epoch 0100, iter [01090, 01251], lr: 0.000000, loss: 0.3865
2022-10-05 02:23:26 - train: epoch 0100, iter [01100, 01251], lr: 0.000000, loss: 0.3902
2022-10-05 02:23:45 - train: epoch 0100, iter [01110, 01251], lr: 0.000000, loss: 0.3872
2022-10-05 02:24:05 - train: epoch 0100, iter [01120, 01251], lr: 0.000000, loss: 0.3913
2022-10-05 02:24:24 - train: epoch 0100, iter [01130, 01251], lr: 0.000000, loss: 0.3931
2022-10-05 02:24:44 - train: epoch 0100, iter [01140, 01251], lr: 0.000000, loss: 0.4092
2022-10-05 02:25:03 - train: epoch 0100, iter [01150, 01251], lr: 0.000000, loss: 0.4177
2022-10-05 02:25:22 - train: epoch 0100, iter [01160, 01251], lr: 0.000000, loss: 0.3902
2022-10-05 02:25:42 - train: epoch 0100, iter [01170, 01251], lr: 0.000000, loss: 0.3713
2022-10-05 02:26:01 - train: epoch 0100, iter [01180, 01251], lr: 0.000000, loss: 0.3928
2022-10-05 02:26:21 - train: epoch 0100, iter [01190, 01251], lr: 0.000000, loss: 0.3990
2022-10-05 02:26:40 - train: epoch 0100, iter [01200, 01251], lr: 0.000000, loss: 0.4112
2022-10-05 02:26:59 - train: epoch 0100, iter [01210, 01251], lr: 0.000000, loss: 0.3979
2022-10-05 02:27:19 - train: epoch 0100, iter [01220, 01251], lr: 0.000000, loss: 0.4075
2022-10-05 02:27:38 - train: epoch 0100, iter [01230, 01251], lr: 0.000000, loss: 0.3766
2022-10-05 02:27:58 - train: epoch 0100, iter [01240, 01251], lr: 0.000000, loss: 0.4058
2022-10-05 02:28:16 - train: epoch 0100, iter [01250, 01251], lr: 0.000000, loss: 0.4016
2022-10-05 02:28:20 - train: epoch 100, train_loss: 0.3987
2022-10-05 02:28:22 - until epoch: 100, best_loss: 0.3986
2022-10-05 02:28:22 - train done. model: vit_base_patch16_224_mae_pretrain_model, train time: 66.998 hours, best_loss: 0.3986
