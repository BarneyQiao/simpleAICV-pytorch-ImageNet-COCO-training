2022-10-04 00:00:02 - train: epoch 0050, iter [01240, 01251], lr: 0.000352, loss: 0.0943
2022-10-04 00:00:30 - train: epoch 0050, iter [01250, 01251], lr: 0.000352, loss: 0.0951
2022-10-04 00:00:34 - train: epoch 050, train_loss: 0.0898
2022-10-04 00:00:36 - until epoch: 050, best_loss: 0.0898
2022-10-04 00:00:36 - epoch 051 lr: 0.000352
2022-10-04 00:01:11 - train: epoch 0051, iter [00010, 01251], lr: 0.000352, loss: 0.0790
2022-10-04 00:01:40 - train: epoch 0051, iter [00020, 01251], lr: 0.000352, loss: 0.0884
2022-10-04 00:02:08 - train: epoch 0051, iter [00030, 01251], lr: 0.000352, loss: 0.0851
2022-10-04 00:02:36 - train: epoch 0051, iter [00040, 01251], lr: 0.000352, loss: 0.0959
2022-10-04 00:03:04 - train: epoch 0051, iter [00050, 01251], lr: 0.000352, loss: 0.0953
2022-10-04 00:03:33 - train: epoch 0051, iter [00060, 01251], lr: 0.000352, loss: 0.0887
2022-10-04 00:04:01 - train: epoch 0051, iter [00070, 01251], lr: 0.000352, loss: 0.0885
2022-10-04 00:04:29 - train: epoch 0051, iter [00080, 01251], lr: 0.000351, loss: 0.0929
2022-10-04 00:04:57 - train: epoch 0051, iter [00090, 01251], lr: 0.000351, loss: 0.0906
2022-10-04 00:05:25 - train: epoch 0051, iter [00100, 01251], lr: 0.000351, loss: 0.0911
2022-10-04 00:05:53 - train: epoch 0051, iter [00110, 01251], lr: 0.000351, loss: 0.0854
2022-10-04 00:06:21 - train: epoch 0051, iter [00120, 01251], lr: 0.000351, loss: 0.0855
2022-10-04 00:06:50 - train: epoch 0051, iter [00130, 01251], lr: 0.000351, loss: 0.0922
2022-10-04 00:07:18 - train: epoch 0051, iter [00140, 01251], lr: 0.000351, loss: 0.0900
2022-10-04 00:07:46 - train: epoch 0051, iter [00150, 01251], lr: 0.000351, loss: 0.0954
2022-10-04 00:08:14 - train: epoch 0051, iter [00160, 01251], lr: 0.000351, loss: 0.0958
2022-10-04 00:08:42 - train: epoch 0051, iter [00170, 01251], lr: 0.000351, loss: 0.0873
2022-10-04 00:09:10 - train: epoch 0051, iter [00180, 01251], lr: 0.000351, loss: 0.0893
2022-10-04 00:09:39 - train: epoch 0051, iter [00190, 01251], lr: 0.000351, loss: 0.0832
2022-10-04 00:10:07 - train: epoch 0051, iter [00200, 01251], lr: 0.000350, loss: 0.0848
2022-10-04 00:10:35 - train: epoch 0051, iter [00210, 01251], lr: 0.000350, loss: 0.0814
2022-10-04 00:11:03 - train: epoch 0051, iter [00220, 01251], lr: 0.000350, loss: 0.0876
2022-10-04 00:11:31 - train: epoch 0051, iter [00230, 01251], lr: 0.000350, loss: 0.0872
2022-10-04 00:11:59 - train: epoch 0051, iter [00240, 01251], lr: 0.000350, loss: 0.0901
2022-10-04 00:12:27 - train: epoch 0051, iter [00250, 01251], lr: 0.000350, loss: 0.0845
2022-10-04 00:12:56 - train: epoch 0051, iter [00260, 01251], lr: 0.000350, loss: 0.0881
2022-10-04 00:13:24 - train: epoch 0051, iter [00270, 01251], lr: 0.000350, loss: 0.0989
2022-10-04 00:13:52 - train: epoch 0051, iter [00280, 01251], lr: 0.000350, loss: 0.0901
2022-10-04 00:14:20 - train: epoch 0051, iter [00290, 01251], lr: 0.000350, loss: 0.0931
2022-10-04 00:14:48 - train: epoch 0051, iter [00300, 01251], lr: 0.000350, loss: 0.0883
2022-10-04 00:15:16 - train: epoch 0051, iter [00310, 01251], lr: 0.000350, loss: 0.0933
2022-10-04 00:15:44 - train: epoch 0051, iter [00320, 01251], lr: 0.000349, loss: 0.0798
2022-10-04 00:16:13 - train: epoch 0051, iter [00330, 01251], lr: 0.000349, loss: 0.0917
2022-10-04 00:16:41 - train: epoch 0051, iter [00340, 01251], lr: 0.000349, loss: 0.0905
2022-10-04 00:17:09 - train: epoch 0051, iter [00350, 01251], lr: 0.000349, loss: 0.0858
2022-10-04 00:17:37 - train: epoch 0051, iter [00360, 01251], lr: 0.000349, loss: 0.0897
2022-10-04 00:18:06 - train: epoch 0051, iter [00370, 01251], lr: 0.000349, loss: 0.0918
2022-10-04 00:18:34 - train: epoch 0051, iter [00380, 01251], lr: 0.000349, loss: 0.0824
2022-10-04 00:19:02 - train: epoch 0051, iter [00390, 01251], lr: 0.000349, loss: 0.0927
2022-10-04 00:19:30 - train: epoch 0051, iter [00400, 01251], lr: 0.000349, loss: 0.0937
2022-10-04 00:19:59 - train: epoch 0051, iter [00410, 01251], lr: 0.000349, loss: 0.0932
2022-10-04 00:20:27 - train: epoch 0051, iter [00420, 01251], lr: 0.000349, loss: 0.0834
2022-10-04 00:20:55 - train: epoch 0051, iter [00430, 01251], lr: 0.000349, loss: 0.0840
2022-10-04 00:21:23 - train: epoch 0051, iter [00440, 01251], lr: 0.000348, loss: 0.0923
2022-10-04 00:21:51 - train: epoch 0051, iter [00450, 01251], lr: 0.000348, loss: 0.0942
2022-10-04 00:22:19 - train: epoch 0051, iter [00460, 01251], lr: 0.000348, loss: 0.0845
2022-10-04 00:22:48 - train: epoch 0051, iter [00470, 01251], lr: 0.000348, loss: 0.0863
2022-10-04 00:23:16 - train: epoch 0051, iter [00480, 01251], lr: 0.000348, loss: 0.0973
2022-10-04 00:23:44 - train: epoch 0051, iter [00490, 01251], lr: 0.000348, loss: 0.0909
2022-10-04 00:24:12 - train: epoch 0051, iter [00500, 01251], lr: 0.000348, loss: 0.0845
2022-10-04 00:24:40 - train: epoch 0051, iter [00510, 01251], lr: 0.000348, loss: 0.0903
2022-10-04 00:25:08 - train: epoch 0051, iter [00520, 01251], lr: 0.000348, loss: 0.0923
2022-10-04 00:25:37 - train: epoch 0051, iter [00530, 01251], lr: 0.000348, loss: 0.0909
2022-10-04 00:26:05 - train: epoch 0051, iter [00540, 01251], lr: 0.000348, loss: 0.0905
2022-10-04 00:26:33 - train: epoch 0051, iter [00550, 01251], lr: 0.000348, loss: 0.0953
2022-10-04 00:27:01 - train: epoch 0051, iter [00560, 01251], lr: 0.000347, loss: 0.0978
2022-10-04 00:27:29 - train: epoch 0051, iter [00570, 01251], lr: 0.000347, loss: 0.0895
2022-10-04 00:27:57 - train: epoch 0051, iter [00580, 01251], lr: 0.000347, loss: 0.0918
2022-10-04 00:28:25 - train: epoch 0051, iter [00590, 01251], lr: 0.000347, loss: 0.0896
2022-10-04 00:28:54 - train: epoch 0051, iter [00600, 01251], lr: 0.000347, loss: 0.0834
2022-10-04 00:29:22 - train: epoch 0051, iter [00610, 01251], lr: 0.000347, loss: 0.0865
2022-10-04 00:29:50 - train: epoch 0051, iter [00620, 01251], lr: 0.000347, loss: 0.0892
2022-10-04 00:30:18 - train: epoch 0051, iter [00630, 01251], lr: 0.000347, loss: 0.0968
2022-10-04 00:30:46 - train: epoch 0051, iter [00640, 01251], lr: 0.000347, loss: 0.0870
2022-10-04 00:31:15 - train: epoch 0051, iter [00650, 01251], lr: 0.000347, loss: 0.0886
2022-10-04 00:31:43 - train: epoch 0051, iter [00660, 01251], lr: 0.000347, loss: 0.0862
2022-10-04 00:32:11 - train: epoch 0051, iter [00670, 01251], lr: 0.000347, loss: 0.0886
2022-10-04 00:32:39 - train: epoch 0051, iter [00680, 01251], lr: 0.000346, loss: 0.0837
2022-10-04 00:33:07 - train: epoch 0051, iter [00690, 01251], lr: 0.000346, loss: 0.0871
2022-10-04 00:33:35 - train: epoch 0051, iter [00700, 01251], lr: 0.000346, loss: 0.0926
2022-10-04 00:34:04 - train: epoch 0051, iter [00710, 01251], lr: 0.000346, loss: 0.0989
2022-10-04 00:34:32 - train: epoch 0051, iter [00720, 01251], lr: 0.000346, loss: 0.0874
2022-10-04 00:35:00 - train: epoch 0051, iter [00730, 01251], lr: 0.000346, loss: 0.0920
2022-10-04 00:35:29 - train: epoch 0051, iter [00740, 01251], lr: 0.000346, loss: 0.0819
2022-10-04 00:35:57 - train: epoch 0051, iter [00750, 01251], lr: 0.000346, loss: 0.0906
2022-10-04 00:36:25 - train: epoch 0051, iter [00760, 01251], lr: 0.000346, loss: 0.0925
2022-10-04 00:36:53 - train: epoch 0051, iter [00770, 01251], lr: 0.000346, loss: 0.0869
2022-10-04 00:37:21 - train: epoch 0051, iter [00780, 01251], lr: 0.000346, loss: 0.0917
2022-10-04 00:37:49 - train: epoch 0051, iter [00790, 01251], lr: 0.000346, loss: 0.0886
2022-10-04 00:38:17 - train: epoch 0051, iter [00800, 01251], lr: 0.000345, loss: 0.0887
2022-10-04 00:38:45 - train: epoch 0051, iter [00810, 01251], lr: 0.000345, loss: 0.0885
2022-10-04 00:39:14 - train: epoch 0051, iter [00820, 01251], lr: 0.000345, loss: 0.0856
2022-10-04 00:39:42 - train: epoch 0051, iter [00830, 01251], lr: 0.000345, loss: 0.0825
2022-10-04 00:40:10 - train: epoch 0051, iter [00840, 01251], lr: 0.000345, loss: 0.0940
2022-10-04 00:40:38 - train: epoch 0051, iter [00850, 01251], lr: 0.000345, loss: 0.0829
2022-10-04 00:41:06 - train: epoch 0051, iter [00860, 01251], lr: 0.000345, loss: 0.0979
2022-10-04 00:41:34 - train: epoch 0051, iter [00870, 01251], lr: 0.000345, loss: 0.0867
2022-10-04 00:42:03 - train: epoch 0051, iter [00880, 01251], lr: 0.000345, loss: 0.0860
2022-10-04 00:42:31 - train: epoch 0051, iter [00890, 01251], lr: 0.000345, loss: 0.0935
2022-10-04 00:42:59 - train: epoch 0051, iter [00900, 01251], lr: 0.000345, loss: 0.0937
2022-10-04 00:43:27 - train: epoch 0051, iter [00910, 01251], lr: 0.000345, loss: 0.0878
2022-10-04 00:43:55 - train: epoch 0051, iter [00920, 01251], lr: 0.000344, loss: 0.0861
2022-10-04 00:44:23 - train: epoch 0051, iter [00930, 01251], lr: 0.000344, loss: 0.0909
2022-10-04 00:44:51 - train: epoch 0051, iter [00940, 01251], lr: 0.000344, loss: 0.0893
2022-10-04 00:45:19 - train: epoch 0051, iter [00950, 01251], lr: 0.000344, loss: 0.0841
2022-10-04 00:45:48 - train: epoch 0051, iter [00960, 01251], lr: 0.000344, loss: 0.0886
2022-10-04 00:46:16 - train: epoch 0051, iter [00970, 01251], lr: 0.000344, loss: 0.0928
2022-10-04 00:46:44 - train: epoch 0051, iter [00980, 01251], lr: 0.000344, loss: 0.0861
2022-10-04 00:47:12 - train: epoch 0051, iter [00990, 01251], lr: 0.000344, loss: 0.0763
2022-10-04 00:47:40 - train: epoch 0051, iter [01000, 01251], lr: 0.000344, loss: 0.0864
2022-10-04 00:48:08 - train: epoch 0051, iter [01010, 01251], lr: 0.000344, loss: 0.0943
2022-10-04 00:48:36 - train: epoch 0051, iter [01020, 01251], lr: 0.000344, loss: 0.0876
2022-10-04 00:49:04 - train: epoch 0051, iter [01030, 01251], lr: 0.000344, loss: 0.0917
2022-10-04 00:49:33 - train: epoch 0051, iter [01040, 01251], lr: 0.000344, loss: 0.0853
2022-10-04 00:50:01 - train: epoch 0051, iter [01050, 01251], lr: 0.000343, loss: 0.0933
2022-10-04 00:50:29 - train: epoch 0051, iter [01060, 01251], lr: 0.000343, loss: 0.0949
2022-10-04 00:50:57 - train: epoch 0051, iter [01070, 01251], lr: 0.000343, loss: 0.0955
2022-10-04 00:51:25 - train: epoch 0051, iter [01080, 01251], lr: 0.000343, loss: 0.0960
2022-10-04 00:51:53 - train: epoch 0051, iter [01090, 01251], lr: 0.000343, loss: 0.0890
2022-10-04 00:52:21 - train: epoch 0051, iter [01100, 01251], lr: 0.000343, loss: 0.0842
2022-10-04 00:52:50 - train: epoch 0051, iter [01110, 01251], lr: 0.000343, loss: 0.0824
2022-10-04 00:53:18 - train: epoch 0051, iter [01120, 01251], lr: 0.000343, loss: 0.0880
2022-10-04 00:53:46 - train: epoch 0051, iter [01130, 01251], lr: 0.000343, loss: 0.0910
2022-10-04 00:54:14 - train: epoch 0051, iter [01140, 01251], lr: 0.000343, loss: 0.0886
2022-10-04 00:54:42 - train: epoch 0051, iter [01150, 01251], lr: 0.000343, loss: 0.0838
2022-10-04 00:55:10 - train: epoch 0051, iter [01160, 01251], lr: 0.000343, loss: 0.0876
2022-10-04 00:55:38 - train: epoch 0051, iter [01170, 01251], lr: 0.000342, loss: 0.0875
2022-10-04 00:56:07 - train: epoch 0051, iter [01180, 01251], lr: 0.000342, loss: 0.0835
2022-10-04 00:56:35 - train: epoch 0051, iter [01190, 01251], lr: 0.000342, loss: 0.0928
2022-10-04 00:57:03 - train: epoch 0051, iter [01200, 01251], lr: 0.000342, loss: 0.0798
2022-10-04 00:57:31 - train: epoch 0051, iter [01210, 01251], lr: 0.000342, loss: 0.0973
2022-10-04 00:57:59 - train: epoch 0051, iter [01220, 01251], lr: 0.000342, loss: 0.0887
2022-10-04 00:58:27 - train: epoch 0051, iter [01230, 01251], lr: 0.000342, loss: 0.0873
2022-10-04 00:58:56 - train: epoch 0051, iter [01240, 01251], lr: 0.000342, loss: 0.0845
2022-10-04 00:59:23 - train: epoch 0051, iter [01250, 01251], lr: 0.000342, loss: 0.0900
2022-10-04 00:59:28 - train: epoch 051, train_loss: 0.0895
2022-10-04 00:59:30 - until epoch: 051, best_loss: 0.0895
2022-10-04 00:59:30 - epoch 052 lr: 0.000342
2022-10-04 01:00:05 - train: epoch 0052, iter [00010, 01251], lr: 0.000342, loss: 0.0949
2022-10-04 01:00:33 - train: epoch 0052, iter [00020, 01251], lr: 0.000342, loss: 0.0956
2022-10-04 01:01:02 - train: epoch 0052, iter [00030, 01251], lr: 0.000342, loss: 0.0903
2022-10-04 01:01:30 - train: epoch 0052, iter [00040, 01251], lr: 0.000341, loss: 0.0911
2022-10-04 01:01:59 - train: epoch 0052, iter [00050, 01251], lr: 0.000341, loss: 0.0942
2022-10-04 01:02:27 - train: epoch 0052, iter [00060, 01251], lr: 0.000341, loss: 0.0821
2022-10-04 01:02:55 - train: epoch 0052, iter [00070, 01251], lr: 0.000341, loss: 0.0927
2022-10-04 01:03:23 - train: epoch 0052, iter [00080, 01251], lr: 0.000341, loss: 0.0968
2022-10-04 01:03:51 - train: epoch 0052, iter [00090, 01251], lr: 0.000341, loss: 0.0846
2022-10-04 01:04:20 - train: epoch 0052, iter [00100, 01251], lr: 0.000341, loss: 0.0816
2022-10-04 01:04:48 - train: epoch 0052, iter [00110, 01251], lr: 0.000341, loss: 0.0836
2022-10-04 01:05:16 - train: epoch 0052, iter [00120, 01251], lr: 0.000341, loss: 0.0973
2022-10-04 01:05:44 - train: epoch 0052, iter [00130, 01251], lr: 0.000341, loss: 0.0931
2022-10-04 01:06:12 - train: epoch 0052, iter [00140, 01251], lr: 0.000341, loss: 0.0851
2022-10-04 01:06:40 - train: epoch 0052, iter [00150, 01251], lr: 0.000341, loss: 0.0909
2022-10-04 01:07:09 - train: epoch 0052, iter [00160, 01251], lr: 0.000340, loss: 0.0798
2022-10-04 01:07:37 - train: epoch 0052, iter [00170, 01251], lr: 0.000340, loss: 0.0830
2022-10-04 01:08:05 - train: epoch 0052, iter [00180, 01251], lr: 0.000340, loss: 0.0899
2022-10-04 01:08:33 - train: epoch 0052, iter [00190, 01251], lr: 0.000340, loss: 0.0875
2022-10-04 01:09:01 - train: epoch 0052, iter [00200, 01251], lr: 0.000340, loss: 0.0857
2022-10-04 01:09:29 - train: epoch 0052, iter [00210, 01251], lr: 0.000340, loss: 0.0890
2022-10-04 01:09:57 - train: epoch 0052, iter [00220, 01251], lr: 0.000340, loss: 0.0836
2022-10-04 01:10:25 - train: epoch 0052, iter [00230, 01251], lr: 0.000340, loss: 0.0850
2022-10-04 01:10:53 - train: epoch 0052, iter [00240, 01251], lr: 0.000340, loss: 0.0966
2022-10-04 01:11:22 - train: epoch 0052, iter [00250, 01251], lr: 0.000340, loss: 0.0887
2022-10-04 01:11:50 - train: epoch 0052, iter [00260, 01251], lr: 0.000340, loss: 0.0822
2022-10-04 01:12:18 - train: epoch 0052, iter [00270, 01251], lr: 0.000340, loss: 0.0903
2022-10-04 01:12:46 - train: epoch 0052, iter [00280, 01251], lr: 0.000339, loss: 0.0828
2022-10-04 01:13:14 - train: epoch 0052, iter [00290, 01251], lr: 0.000339, loss: 0.0846
2022-10-04 01:13:42 - train: epoch 0052, iter [00300, 01251], lr: 0.000339, loss: 0.0866
2022-10-04 01:14:10 - train: epoch 0052, iter [00310, 01251], lr: 0.000339, loss: 0.0966
2022-10-04 01:14:38 - train: epoch 0052, iter [00320, 01251], lr: 0.000339, loss: 0.0913
2022-10-04 01:15:06 - train: epoch 0052, iter [00330, 01251], lr: 0.000339, loss: 0.0985
2022-10-04 01:15:35 - train: epoch 0052, iter [00340, 01251], lr: 0.000339, loss: 0.0845
2022-10-04 01:16:03 - train: epoch 0052, iter [00350, 01251], lr: 0.000339, loss: 0.0874
2022-10-04 01:16:31 - train: epoch 0052, iter [00360, 01251], lr: 0.000339, loss: 0.0882
2022-10-04 01:16:59 - train: epoch 0052, iter [00370, 01251], lr: 0.000339, loss: 0.0869
2022-10-04 01:17:27 - train: epoch 0052, iter [00380, 01251], lr: 0.000339, loss: 0.0893
2022-10-04 01:17:55 - train: epoch 0052, iter [00390, 01251], lr: 0.000339, loss: 0.0821
2022-10-04 01:18:23 - train: epoch 0052, iter [00400, 01251], lr: 0.000338, loss: 0.0899
2022-10-04 01:18:51 - train: epoch 0052, iter [00410, 01251], lr: 0.000338, loss: 0.0878
2022-10-04 01:19:19 - train: epoch 0052, iter [00420, 01251], lr: 0.000338, loss: 0.0908
2022-10-04 01:19:47 - train: epoch 0052, iter [00430, 01251], lr: 0.000338, loss: 0.0861
2022-10-04 01:20:15 - train: epoch 0052, iter [00440, 01251], lr: 0.000338, loss: 0.0805
2022-10-04 01:20:43 - train: epoch 0052, iter [00450, 01251], lr: 0.000338, loss: 0.0931
2022-10-04 01:21:12 - train: epoch 0052, iter [00460, 01251], lr: 0.000338, loss: 0.0826
2022-10-04 01:21:40 - train: epoch 0052, iter [00470, 01251], lr: 0.000338, loss: 0.0895
2022-10-04 01:22:08 - train: epoch 0052, iter [00480, 01251], lr: 0.000338, loss: 0.0839
2022-10-04 01:22:37 - train: epoch 0052, iter [00490, 01251], lr: 0.000338, loss: 0.0919
2022-10-04 01:23:05 - train: epoch 0052, iter [00500, 01251], lr: 0.000338, loss: 0.0915
2022-10-04 01:23:33 - train: epoch 0052, iter [00510, 01251], lr: 0.000338, loss: 0.0850
2022-10-04 01:24:01 - train: epoch 0052, iter [00520, 01251], lr: 0.000337, loss: 0.0965
2022-10-04 01:24:29 - train: epoch 0052, iter [00530, 01251], lr: 0.000337, loss: 0.0918
2022-10-04 01:24:57 - train: epoch 0052, iter [00540, 01251], lr: 0.000337, loss: 0.0895
2022-10-04 01:25:25 - train: epoch 0052, iter [00550, 01251], lr: 0.000337, loss: 0.0889
2022-10-04 01:25:54 - train: epoch 0052, iter [00560, 01251], lr: 0.000337, loss: 0.0947
2022-10-04 01:26:22 - train: epoch 0052, iter [00570, 01251], lr: 0.000337, loss: 0.0843
2022-10-04 01:26:50 - train: epoch 0052, iter [00580, 01251], lr: 0.000337, loss: 0.0906
2022-10-04 01:27:18 - train: epoch 0052, iter [00590, 01251], lr: 0.000337, loss: 0.0897
2022-10-04 01:27:46 - train: epoch 0052, iter [00600, 01251], lr: 0.000337, loss: 0.0905
2022-10-04 01:28:14 - train: epoch 0052, iter [00610, 01251], lr: 0.000337, loss: 0.0872
2022-10-04 01:28:42 - train: epoch 0052, iter [00620, 01251], lr: 0.000337, loss: 0.0906
2022-10-04 01:29:10 - train: epoch 0052, iter [00630, 01251], lr: 0.000337, loss: 0.0822
2022-10-04 01:29:38 - train: epoch 0052, iter [00640, 01251], lr: 0.000336, loss: 0.0848
2022-10-04 01:30:06 - train: epoch 0052, iter [00650, 01251], lr: 0.000336, loss: 0.0849
2022-10-04 01:30:34 - train: epoch 0052, iter [00660, 01251], lr: 0.000336, loss: 0.0903
2022-10-04 01:31:02 - train: epoch 0052, iter [00670, 01251], lr: 0.000336, loss: 0.0906
2022-10-04 01:31:30 - train: epoch 0052, iter [00680, 01251], lr: 0.000336, loss: 0.0958
2022-10-04 01:31:58 - train: epoch 0052, iter [00690, 01251], lr: 0.000336, loss: 0.0882
2022-10-04 01:32:27 - train: epoch 0052, iter [00700, 01251], lr: 0.000336, loss: 0.0906
2022-10-04 01:32:55 - train: epoch 0052, iter [00710, 01251], lr: 0.000336, loss: 0.0919
2022-10-04 01:33:23 - train: epoch 0052, iter [00720, 01251], lr: 0.000336, loss: 0.0836
2022-10-04 01:33:51 - train: epoch 0052, iter [00730, 01251], lr: 0.000336, loss: 0.0900
2022-10-04 01:34:19 - train: epoch 0052, iter [00740, 01251], lr: 0.000336, loss: 0.0862
2022-10-04 01:34:47 - train: epoch 0052, iter [00750, 01251], lr: 0.000336, loss: 0.0924
2022-10-04 01:35:16 - train: epoch 0052, iter [00760, 01251], lr: 0.000335, loss: 0.0924
2022-10-04 01:35:44 - train: epoch 0052, iter [00770, 01251], lr: 0.000335, loss: 0.0928
2022-10-04 01:36:12 - train: epoch 0052, iter [00780, 01251], lr: 0.000335, loss: 0.0901
2022-10-04 01:36:40 - train: epoch 0052, iter [00790, 01251], lr: 0.000335, loss: 0.0903
2022-10-04 01:37:08 - train: epoch 0052, iter [00800, 01251], lr: 0.000335, loss: 0.0931
2022-10-04 01:37:37 - train: epoch 0052, iter [00810, 01251], lr: 0.000335, loss: 0.0861
2022-10-04 01:38:05 - train: epoch 0052, iter [00820, 01251], lr: 0.000335, loss: 0.0868
2022-10-04 01:38:33 - train: epoch 0052, iter [00830, 01251], lr: 0.000335, loss: 0.0876
2022-10-04 01:39:01 - train: epoch 0052, iter [00840, 01251], lr: 0.000335, loss: 0.0865
2022-10-04 01:39:29 - train: epoch 0052, iter [00850, 01251], lr: 0.000335, loss: 0.0927
2022-10-04 01:39:57 - train: epoch 0052, iter [00860, 01251], lr: 0.000335, loss: 0.0888
2022-10-04 01:40:25 - train: epoch 0052, iter [00870, 01251], lr: 0.000335, loss: 0.0856
2022-10-04 01:40:54 - train: epoch 0052, iter [00880, 01251], lr: 0.000334, loss: 0.0897
2022-10-04 01:41:22 - train: epoch 0052, iter [00890, 01251], lr: 0.000334, loss: 0.0884
2022-10-04 01:41:50 - train: epoch 0052, iter [00900, 01251], lr: 0.000334, loss: 0.0843
2022-10-04 01:42:18 - train: epoch 0052, iter [00910, 01251], lr: 0.000334, loss: 0.0931
2022-10-04 01:42:46 - train: epoch 0052, iter [00920, 01251], lr: 0.000334, loss: 0.0832
2022-10-04 01:43:14 - train: epoch 0052, iter [00930, 01251], lr: 0.000334, loss: 0.0920
2022-10-04 01:43:42 - train: epoch 0052, iter [00940, 01251], lr: 0.000334, loss: 0.0925
2022-10-04 01:44:10 - train: epoch 0052, iter [00950, 01251], lr: 0.000334, loss: 0.0938
2022-10-04 01:44:38 - train: epoch 0052, iter [00960, 01251], lr: 0.000334, loss: 0.0905
2022-10-04 01:45:06 - train: epoch 0052, iter [00970, 01251], lr: 0.000334, loss: 0.0843
2022-10-04 01:45:34 - train: epoch 0052, iter [00980, 01251], lr: 0.000334, loss: 0.0795
2022-10-04 01:46:02 - train: epoch 0052, iter [00990, 01251], lr: 0.000334, loss: 0.0911
2022-10-04 01:46:30 - train: epoch 0052, iter [01000, 01251], lr: 0.000333, loss: 0.0874
2022-10-04 01:46:58 - train: epoch 0052, iter [01010, 01251], lr: 0.000333, loss: 0.0839
2022-10-04 01:47:26 - train: epoch 0052, iter [01020, 01251], lr: 0.000333, loss: 0.0986
2022-10-04 01:47:54 - train: epoch 0052, iter [01030, 01251], lr: 0.000333, loss: 0.0796
2022-10-04 01:48:22 - train: epoch 0052, iter [01040, 01251], lr: 0.000333, loss: 0.0924
2022-10-04 01:48:50 - train: epoch 0052, iter [01050, 01251], lr: 0.000333, loss: 0.0809
2022-10-04 01:49:18 - train: epoch 0052, iter [01060, 01251], lr: 0.000333, loss: 0.0940
2022-10-04 01:49:46 - train: epoch 0052, iter [01070, 01251], lr: 0.000333, loss: 0.0937
2022-10-04 01:50:14 - train: epoch 0052, iter [01080, 01251], lr: 0.000333, loss: 0.0939
2022-10-04 01:50:42 - train: epoch 0052, iter [01090, 01251], lr: 0.000333, loss: 0.0868
2022-10-04 01:51:10 - train: epoch 0052, iter [01100, 01251], lr: 0.000333, loss: 0.0831
2022-10-04 01:51:38 - train: epoch 0052, iter [01110, 01251], lr: 0.000333, loss: 0.0920
2022-10-04 01:52:06 - train: epoch 0052, iter [01120, 01251], lr: 0.000332, loss: 0.0896
2022-10-04 01:52:34 - train: epoch 0052, iter [01130, 01251], lr: 0.000332, loss: 0.0871
2022-10-04 01:53:02 - train: epoch 0052, iter [01140, 01251], lr: 0.000332, loss: 0.0933
2022-10-04 01:53:30 - train: epoch 0052, iter [01150, 01251], lr: 0.000332, loss: 0.0812
2022-10-04 01:53:58 - train: epoch 0052, iter [01160, 01251], lr: 0.000332, loss: 0.0865
2022-10-04 01:54:26 - train: epoch 0052, iter [01170, 01251], lr: 0.000332, loss: 0.0870
2022-10-04 01:54:54 - train: epoch 0052, iter [01180, 01251], lr: 0.000332, loss: 0.0915
2022-10-04 01:55:22 - train: epoch 0052, iter [01190, 01251], lr: 0.000332, loss: 0.0885
2022-10-04 01:55:50 - train: epoch 0052, iter [01200, 01251], lr: 0.000332, loss: 0.0928
2022-10-04 01:56:19 - train: epoch 0052, iter [01210, 01251], lr: 0.000332, loss: 0.0845
2022-10-04 01:56:47 - train: epoch 0052, iter [01220, 01251], lr: 0.000332, loss: 0.0846
2022-10-04 01:57:15 - train: epoch 0052, iter [01230, 01251], lr: 0.000332, loss: 0.0842
2022-10-04 01:57:43 - train: epoch 0052, iter [01240, 01251], lr: 0.000331, loss: 0.0863
2022-10-04 01:58:10 - train: epoch 0052, iter [01250, 01251], lr: 0.000331, loss: 0.0861
2022-10-04 01:58:15 - train: epoch 052, train_loss: 0.0892
2022-10-04 01:58:17 - until epoch: 052, best_loss: 0.0892
2022-10-04 01:58:17 - epoch 053 lr: 0.000331
2022-10-04 01:58:52 - train: epoch 0053, iter [00010, 01251], lr: 0.000331, loss: 0.0884
2022-10-04 01:59:20 - train: epoch 0053, iter [00020, 01251], lr: 0.000331, loss: 0.0954
2022-10-04 01:59:48 - train: epoch 0053, iter [00030, 01251], lr: 0.000331, loss: 0.0883
2022-10-04 02:00:17 - train: epoch 0053, iter [00040, 01251], lr: 0.000331, loss: 0.0891
2022-10-04 02:00:45 - train: epoch 0053, iter [00050, 01251], lr: 0.000331, loss: 0.0861
2022-10-04 02:01:13 - train: epoch 0053, iter [00060, 01251], lr: 0.000331, loss: 0.1023
2022-10-04 02:01:41 - train: epoch 0053, iter [00070, 01251], lr: 0.000331, loss: 0.0926
2022-10-04 02:02:10 - train: epoch 0053, iter [00080, 01251], lr: 0.000331, loss: 0.0904
2022-10-04 02:02:38 - train: epoch 0053, iter [00090, 01251], lr: 0.000331, loss: 0.0828
2022-10-04 02:03:06 - train: epoch 0053, iter [00100, 01251], lr: 0.000331, loss: 0.0893
2022-10-04 02:03:34 - train: epoch 0053, iter [00110, 01251], lr: 0.000330, loss: 0.0897
2022-10-04 02:04:02 - train: epoch 0053, iter [00120, 01251], lr: 0.000330, loss: 0.0930
2022-10-04 02:04:30 - train: epoch 0053, iter [00130, 01251], lr: 0.000330, loss: 0.0868
2022-10-04 02:04:58 - train: epoch 0053, iter [00140, 01251], lr: 0.000330, loss: 0.0901
2022-10-04 02:05:26 - train: epoch 0053, iter [00150, 01251], lr: 0.000330, loss: 0.0940
2022-10-04 02:05:55 - train: epoch 0053, iter [00160, 01251], lr: 0.000330, loss: 0.0942
2022-10-04 02:06:23 - train: epoch 0053, iter [00170, 01251], lr: 0.000330, loss: 0.0878
2022-10-04 02:06:51 - train: epoch 0053, iter [00180, 01251], lr: 0.000330, loss: 0.0767
2022-10-04 02:07:19 - train: epoch 0053, iter [00190, 01251], lr: 0.000330, loss: 0.0901
2022-10-04 02:07:47 - train: epoch 0053, iter [00200, 01251], lr: 0.000330, loss: 0.0977
2022-10-04 02:08:16 - train: epoch 0053, iter [00210, 01251], lr: 0.000330, loss: 0.0940
2022-10-04 02:08:44 - train: epoch 0053, iter [00220, 01251], lr: 0.000330, loss: 0.0976
2022-10-04 02:09:12 - train: epoch 0053, iter [00230, 01251], lr: 0.000329, loss: 0.0941
2022-10-04 02:09:40 - train: epoch 0053, iter [00240, 01251], lr: 0.000329, loss: 0.0919
2022-10-04 02:10:09 - train: epoch 0053, iter [00250, 01251], lr: 0.000329, loss: 0.0912
2022-10-04 02:10:37 - train: epoch 0053, iter [00260, 01251], lr: 0.000329, loss: 0.0983
2022-10-04 02:11:05 - train: epoch 0053, iter [00270, 01251], lr: 0.000329, loss: 0.0910
2022-10-04 02:11:34 - train: epoch 0053, iter [00280, 01251], lr: 0.000329, loss: 0.0889
2022-10-04 02:12:02 - train: epoch 0053, iter [00290, 01251], lr: 0.000329, loss: 0.0887
2022-10-04 02:12:30 - train: epoch 0053, iter [00300, 01251], lr: 0.000329, loss: 0.0923
2022-10-04 02:12:58 - train: epoch 0053, iter [00310, 01251], lr: 0.000329, loss: 0.0910
2022-10-04 02:13:27 - train: epoch 0053, iter [00320, 01251], lr: 0.000329, loss: 0.0919
2022-10-04 02:13:55 - train: epoch 0053, iter [00330, 01251], lr: 0.000329, loss: 0.0944
2022-10-04 02:14:23 - train: epoch 0053, iter [00340, 01251], lr: 0.000329, loss: 0.0925
2022-10-04 02:14:51 - train: epoch 0053, iter [00350, 01251], lr: 0.000328, loss: 0.0877
2022-10-04 02:15:19 - train: epoch 0053, iter [00360, 01251], lr: 0.000328, loss: 0.0927
2022-10-04 02:15:48 - train: epoch 0053, iter [00370, 01251], lr: 0.000328, loss: 0.0891
2022-10-04 02:16:16 - train: epoch 0053, iter [00380, 01251], lr: 0.000328, loss: 0.0931
2022-10-04 02:16:44 - train: epoch 0053, iter [00390, 01251], lr: 0.000328, loss: 0.0843
2022-10-04 02:17:12 - train: epoch 0053, iter [00400, 01251], lr: 0.000328, loss: 0.0907
2022-10-04 02:17:41 - train: epoch 0053, iter [00410, 01251], lr: 0.000328, loss: 0.0872
2022-10-04 02:18:09 - train: epoch 0053, iter [00420, 01251], lr: 0.000328, loss: 0.0930
2022-10-04 02:18:37 - train: epoch 0053, iter [00430, 01251], lr: 0.000328, loss: 0.0921
2022-10-04 02:19:05 - train: epoch 0053, iter [00440, 01251], lr: 0.000328, loss: 0.0889
2022-10-04 02:19:33 - train: epoch 0053, iter [00450, 01251], lr: 0.000328, loss: 0.0909
2022-10-04 02:20:02 - train: epoch 0053, iter [00460, 01251], lr: 0.000328, loss: 0.0944
2022-10-04 02:20:30 - train: epoch 0053, iter [00470, 01251], lr: 0.000327, loss: 0.0877
2022-10-04 02:20:58 - train: epoch 0053, iter [00480, 01251], lr: 0.000327, loss: 0.0889
2022-10-04 02:21:26 - train: epoch 0053, iter [00490, 01251], lr: 0.000327, loss: 0.0795
2022-10-04 02:21:54 - train: epoch 0053, iter [00500, 01251], lr: 0.000327, loss: 0.0910
2022-10-04 02:22:22 - train: epoch 0053, iter [00510, 01251], lr: 0.000327, loss: 0.0959
2022-10-04 02:22:50 - train: epoch 0053, iter [00520, 01251], lr: 0.000327, loss: 0.0893
2022-10-04 02:23:19 - train: epoch 0053, iter [00530, 01251], lr: 0.000327, loss: 0.0854
2022-10-04 02:23:47 - train: epoch 0053, iter [00540, 01251], lr: 0.000327, loss: 0.0812
2022-10-04 02:24:15 - train: epoch 0053, iter [00550, 01251], lr: 0.000327, loss: 0.1010
2022-10-04 02:24:43 - train: epoch 0053, iter [00560, 01251], lr: 0.000327, loss: 0.0904
2022-10-04 02:25:11 - train: epoch 0053, iter [00570, 01251], lr: 0.000327, loss: 0.0930
2022-10-04 02:25:39 - train: epoch 0053, iter [00580, 01251], lr: 0.000327, loss: 0.0872
2022-10-04 02:26:07 - train: epoch 0053, iter [00590, 01251], lr: 0.000326, loss: 0.0880
2022-10-04 02:26:36 - train: epoch 0053, iter [00600, 01251], lr: 0.000326, loss: 0.0821
2022-10-04 02:27:04 - train: epoch 0053, iter [00610, 01251], lr: 0.000326, loss: 0.0884
2022-10-04 02:27:32 - train: epoch 0053, iter [00620, 01251], lr: 0.000326, loss: 0.0825
2022-10-04 02:28:00 - train: epoch 0053, iter [00630, 01251], lr: 0.000326, loss: 0.0877
2022-10-04 02:28:28 - train: epoch 0053, iter [00640, 01251], lr: 0.000326, loss: 0.0944
2022-10-04 02:28:56 - train: epoch 0053, iter [00650, 01251], lr: 0.000326, loss: 0.0879
2022-10-04 02:29:25 - train: epoch 0053, iter [00660, 01251], lr: 0.000326, loss: 0.0947
2022-10-04 02:29:53 - train: epoch 0053, iter [00670, 01251], lr: 0.000326, loss: 0.0892
2022-10-04 02:30:21 - train: epoch 0053, iter [00680, 01251], lr: 0.000326, loss: 0.0818
2022-10-04 02:30:49 - train: epoch 0053, iter [00690, 01251], lr: 0.000326, loss: 0.0858
2022-10-04 02:31:17 - train: epoch 0053, iter [00700, 01251], lr: 0.000326, loss: 0.0906
2022-10-04 02:31:45 - train: epoch 0053, iter [00710, 01251], lr: 0.000325, loss: 0.0858
2022-10-04 02:32:13 - train: epoch 0053, iter [00720, 01251], lr: 0.000325, loss: 0.0944
2022-10-04 02:32:42 - train: epoch 0053, iter [00730, 01251], lr: 0.000325, loss: 0.0854
2022-10-04 02:33:10 - train: epoch 0053, iter [00740, 01251], lr: 0.000325, loss: 0.0822
2022-10-04 02:33:38 - train: epoch 0053, iter [00750, 01251], lr: 0.000325, loss: 0.0904
2022-10-04 02:34:06 - train: epoch 0053, iter [00760, 01251], lr: 0.000325, loss: 0.0851
2022-10-04 02:34:34 - train: epoch 0053, iter [00770, 01251], lr: 0.000325, loss: 0.0837
2022-10-04 02:35:03 - train: epoch 0053, iter [00780, 01251], lr: 0.000325, loss: 0.0909
2022-10-04 02:35:31 - train: epoch 0053, iter [00790, 01251], lr: 0.000325, loss: 0.0814
2022-10-04 02:35:59 - train: epoch 0053, iter [00800, 01251], lr: 0.000325, loss: 0.0832
2022-10-04 02:36:27 - train: epoch 0053, iter [00810, 01251], lr: 0.000325, loss: 0.0853
2022-10-04 02:36:55 - train: epoch 0053, iter [00820, 01251], lr: 0.000325, loss: 0.0913
2022-10-04 02:37:23 - train: epoch 0053, iter [00830, 01251], lr: 0.000324, loss: 0.0967
2022-10-04 02:37:51 - train: epoch 0053, iter [00840, 01251], lr: 0.000324, loss: 0.0925
2022-10-04 02:38:20 - train: epoch 0053, iter [00850, 01251], lr: 0.000324, loss: 0.0917
2022-10-04 02:38:48 - train: epoch 0053, iter [00860, 01251], lr: 0.000324, loss: 0.0841
2022-10-04 02:39:16 - train: epoch 0053, iter [00870, 01251], lr: 0.000324, loss: 0.0947
2022-10-04 02:39:44 - train: epoch 0053, iter [00880, 01251], lr: 0.000324, loss: 0.0812
2022-10-04 02:40:12 - train: epoch 0053, iter [00890, 01251], lr: 0.000324, loss: 0.0833
2022-10-04 02:40:41 - train: epoch 0053, iter [00900, 01251], lr: 0.000324, loss: 0.0969
2022-10-04 02:41:09 - train: epoch 0053, iter [00910, 01251], lr: 0.000324, loss: 0.0836
2022-10-04 02:41:37 - train: epoch 0053, iter [00920, 01251], lr: 0.000324, loss: 0.0914
2022-10-04 02:42:05 - train: epoch 0053, iter [00930, 01251], lr: 0.000324, loss: 0.0906
2022-10-04 02:42:33 - train: epoch 0053, iter [00940, 01251], lr: 0.000324, loss: 0.0835
2022-10-04 02:43:02 - train: epoch 0053, iter [00950, 01251], lr: 0.000323, loss: 0.0850
2022-10-04 02:43:30 - train: epoch 0053, iter [00960, 01251], lr: 0.000323, loss: 0.0849
2022-10-04 02:43:58 - train: epoch 0053, iter [00970, 01251], lr: 0.000323, loss: 0.0906
2022-10-04 02:44:26 - train: epoch 0053, iter [00980, 01251], lr: 0.000323, loss: 0.0908
2022-10-04 02:44:54 - train: epoch 0053, iter [00990, 01251], lr: 0.000323, loss: 0.0854
2022-10-04 02:45:22 - train: epoch 0053, iter [01000, 01251], lr: 0.000323, loss: 0.0858
2022-10-04 02:45:50 - train: epoch 0053, iter [01010, 01251], lr: 0.000323, loss: 0.0850
2022-10-04 02:46:18 - train: epoch 0053, iter [01020, 01251], lr: 0.000323, loss: 0.0927
2022-10-04 02:46:47 - train: epoch 0053, iter [01030, 01251], lr: 0.000323, loss: 0.0806
2022-10-04 02:47:15 - train: epoch 0053, iter [01040, 01251], lr: 0.000323, loss: 0.0875
2022-10-04 02:47:43 - train: epoch 0053, iter [01050, 01251], lr: 0.000323, loss: 0.0935
2022-10-04 02:48:11 - train: epoch 0053, iter [01060, 01251], lr: 0.000323, loss: 0.0882
2022-10-04 02:48:39 - train: epoch 0053, iter [01070, 01251], lr: 0.000322, loss: 0.0915
2022-10-04 02:49:07 - train: epoch 0053, iter [01080, 01251], lr: 0.000322, loss: 0.0856
2022-10-04 02:49:35 - train: epoch 0053, iter [01090, 01251], lr: 0.000322, loss: 0.0921
2022-10-04 02:50:04 - train: epoch 0053, iter [01100, 01251], lr: 0.000322, loss: 0.0961
2022-10-04 02:50:32 - train: epoch 0053, iter [01110, 01251], lr: 0.000322, loss: 0.0903
2022-10-04 02:51:00 - train: epoch 0053, iter [01120, 01251], lr: 0.000322, loss: 0.0936
2022-10-04 02:51:28 - train: epoch 0053, iter [01130, 01251], lr: 0.000322, loss: 0.0889
2022-10-04 02:51:56 - train: epoch 0053, iter [01140, 01251], lr: 0.000322, loss: 0.0851
2022-10-04 02:52:24 - train: epoch 0053, iter [01150, 01251], lr: 0.000322, loss: 0.0865
2022-10-04 02:52:52 - train: epoch 0053, iter [01160, 01251], lr: 0.000322, loss: 0.0916
2022-10-04 02:53:20 - train: epoch 0053, iter [01170, 01251], lr: 0.000322, loss: 0.0874
2022-10-04 02:53:49 - train: epoch 0053, iter [01180, 01251], lr: 0.000322, loss: 0.0878
2022-10-04 02:54:17 - train: epoch 0053, iter [01190, 01251], lr: 0.000321, loss: 0.0838
2022-10-04 02:54:45 - train: epoch 0053, iter [01200, 01251], lr: 0.000321, loss: 0.0838
2022-10-04 02:55:13 - train: epoch 0053, iter [01210, 01251], lr: 0.000321, loss: 0.0959
2022-10-04 02:55:41 - train: epoch 0053, iter [01220, 01251], lr: 0.000321, loss: 0.0861
2022-10-04 02:56:09 - train: epoch 0053, iter [01230, 01251], lr: 0.000321, loss: 0.0890
2022-10-04 02:56:38 - train: epoch 0053, iter [01240, 01251], lr: 0.000321, loss: 0.0890
2022-10-04 02:57:05 - train: epoch 0053, iter [01250, 01251], lr: 0.000321, loss: 0.0863
2022-10-04 02:57:10 - train: epoch 053, train_loss: 0.0889
2022-10-04 02:57:11 - until epoch: 053, best_loss: 0.0889
2022-10-04 02:57:11 - epoch 054 lr: 0.000321
2022-10-04 02:57:46 - train: epoch 0054, iter [00010, 01251], lr: 0.000321, loss: 0.0855
2022-10-04 02:58:14 - train: epoch 0054, iter [00020, 01251], lr: 0.000321, loss: 0.0921
2022-10-04 02:58:43 - train: epoch 0054, iter [00030, 01251], lr: 0.000321, loss: 0.0877
2022-10-04 02:59:11 - train: epoch 0054, iter [00040, 01251], lr: 0.000321, loss: 0.0788
2022-10-04 02:59:39 - train: epoch 0054, iter [00050, 01251], lr: 0.000321, loss: 0.0899
2022-10-04 03:00:07 - train: epoch 0054, iter [00060, 01251], lr: 0.000320, loss: 0.0815
2022-10-04 03:00:36 - train: epoch 0054, iter [00070, 01251], lr: 0.000320, loss: 0.0850
2022-10-04 03:01:04 - train: epoch 0054, iter [00080, 01251], lr: 0.000320, loss: 0.0962
2022-10-04 03:01:32 - train: epoch 0054, iter [00090, 01251], lr: 0.000320, loss: 0.0913
2022-10-04 03:02:00 - train: epoch 0054, iter [00100, 01251], lr: 0.000320, loss: 0.0835
2022-10-04 03:02:28 - train: epoch 0054, iter [00110, 01251], lr: 0.000320, loss: 0.0880
2022-10-04 03:02:57 - train: epoch 0054, iter [00120, 01251], lr: 0.000320, loss: 0.0874
2022-10-04 03:03:25 - train: epoch 0054, iter [00130, 01251], lr: 0.000320, loss: 0.0858
2022-10-04 03:03:53 - train: epoch 0054, iter [00140, 01251], lr: 0.000320, loss: 0.0903
2022-10-04 03:04:21 - train: epoch 0054, iter [00150, 01251], lr: 0.000320, loss: 0.0869
2022-10-04 03:04:49 - train: epoch 0054, iter [00160, 01251], lr: 0.000320, loss: 0.0924
2022-10-04 03:05:17 - train: epoch 0054, iter [00170, 01251], lr: 0.000320, loss: 0.0844
2022-10-04 03:05:46 - train: epoch 0054, iter [00180, 01251], lr: 0.000319, loss: 0.0866
2022-10-04 03:06:14 - train: epoch 0054, iter [00190, 01251], lr: 0.000319, loss: 0.0854
2022-10-04 03:06:42 - train: epoch 0054, iter [00200, 01251], lr: 0.000319, loss: 0.0863
2022-10-04 03:07:11 - train: epoch 0054, iter [00210, 01251], lr: 0.000319, loss: 0.0864
2022-10-04 03:07:39 - train: epoch 0054, iter [00220, 01251], lr: 0.000319, loss: 0.0842
2022-10-04 03:08:07 - train: epoch 0054, iter [00230, 01251], lr: 0.000319, loss: 0.0813
2022-10-04 03:08:35 - train: epoch 0054, iter [00240, 01251], lr: 0.000319, loss: 0.0852
2022-10-04 03:09:03 - train: epoch 0054, iter [00250, 01251], lr: 0.000319, loss: 0.0826
2022-10-04 03:09:31 - train: epoch 0054, iter [00260, 01251], lr: 0.000319, loss: 0.0910
2022-10-04 03:10:00 - train: epoch 0054, iter [00270, 01251], lr: 0.000319, loss: 0.0832
2022-10-04 03:10:28 - train: epoch 0054, iter [00280, 01251], lr: 0.000319, loss: 0.0912
2022-10-04 03:10:56 - train: epoch 0054, iter [00290, 01251], lr: 0.000319, loss: 0.0884
2022-10-04 03:11:24 - train: epoch 0054, iter [00300, 01251], lr: 0.000318, loss: 0.0805
2022-10-04 03:11:53 - train: epoch 0054, iter [00310, 01251], lr: 0.000318, loss: 0.0932
2022-10-04 03:12:21 - train: epoch 0054, iter [00320, 01251], lr: 0.000318, loss: 0.0929
2022-10-04 03:12:49 - train: epoch 0054, iter [00330, 01251], lr: 0.000318, loss: 0.0864
2022-10-04 03:13:17 - train: epoch 0054, iter [00340, 01251], lr: 0.000318, loss: 0.0822
2022-10-04 03:13:46 - train: epoch 0054, iter [00350, 01251], lr: 0.000318, loss: 0.0833
2022-10-04 03:14:14 - train: epoch 0054, iter [00360, 01251], lr: 0.000318, loss: 0.0851
2022-10-04 03:14:42 - train: epoch 0054, iter [00370, 01251], lr: 0.000318, loss: 0.0942
2022-10-04 03:15:11 - train: epoch 0054, iter [00380, 01251], lr: 0.000318, loss: 0.0904
2022-10-04 03:15:39 - train: epoch 0054, iter [00390, 01251], lr: 0.000318, loss: 0.0863
2022-10-04 03:16:07 - train: epoch 0054, iter [00400, 01251], lr: 0.000318, loss: 0.0857
2022-10-04 03:16:35 - train: epoch 0054, iter [00410, 01251], lr: 0.000318, loss: 0.0869
2022-10-04 03:17:03 - train: epoch 0054, iter [00420, 01251], lr: 0.000317, loss: 0.0880
2022-10-04 03:17:31 - train: epoch 0054, iter [00430, 01251], lr: 0.000317, loss: 0.0874
2022-10-04 03:18:00 - train: epoch 0054, iter [00440, 01251], lr: 0.000317, loss: 0.0901
2022-10-04 03:18:28 - train: epoch 0054, iter [00450, 01251], lr: 0.000317, loss: 0.0824
2022-10-04 03:18:56 - train: epoch 0054, iter [00460, 01251], lr: 0.000317, loss: 0.0920
2022-10-04 03:19:25 - train: epoch 0054, iter [00470, 01251], lr: 0.000317, loss: 0.0915
2022-10-04 03:19:53 - train: epoch 0054, iter [00480, 01251], lr: 0.000317, loss: 0.0888
2022-10-04 03:20:21 - train: epoch 0054, iter [00490, 01251], lr: 0.000317, loss: 0.0904
2022-10-04 03:20:49 - train: epoch 0054, iter [00500, 01251], lr: 0.000317, loss: 0.0834
2022-10-04 03:21:17 - train: epoch 0054, iter [00510, 01251], lr: 0.000317, loss: 0.0889
2022-10-04 03:21:45 - train: epoch 0054, iter [00520, 01251], lr: 0.000317, loss: 0.0846
2022-10-04 03:22:13 - train: epoch 0054, iter [00530, 01251], lr: 0.000316, loss: 0.0896
2022-10-04 03:22:42 - train: epoch 0054, iter [00540, 01251], lr: 0.000316, loss: 0.0908
2022-10-04 03:23:10 - train: epoch 0054, iter [00550, 01251], lr: 0.000316, loss: 0.0837
2022-10-04 03:23:38 - train: epoch 0054, iter [00560, 01251], lr: 0.000316, loss: 0.0943
2022-10-04 03:24:06 - train: epoch 0054, iter [00570, 01251], lr: 0.000316, loss: 0.0870
2022-10-04 03:24:34 - train: epoch 0054, iter [00580, 01251], lr: 0.000316, loss: 0.0982
2022-10-04 03:25:02 - train: epoch 0054, iter [00590, 01251], lr: 0.000316, loss: 0.0815
2022-10-04 03:25:31 - train: epoch 0054, iter [00600, 01251], lr: 0.000316, loss: 0.0902
2022-10-04 03:25:59 - train: epoch 0054, iter [00610, 01251], lr: 0.000316, loss: 0.0967
2022-10-04 03:26:27 - train: epoch 0054, iter [00620, 01251], lr: 0.000316, loss: 0.0878
2022-10-04 03:26:55 - train: epoch 0054, iter [00630, 01251], lr: 0.000316, loss: 0.0943
2022-10-04 03:27:23 - train: epoch 0054, iter [00640, 01251], lr: 0.000316, loss: 0.0915
2022-10-04 03:27:51 - train: epoch 0054, iter [00650, 01251], lr: 0.000315, loss: 0.0895
2022-10-04 03:28:20 - train: epoch 0054, iter [00660, 01251], lr: 0.000315, loss: 0.0851
2022-10-04 03:28:48 - train: epoch 0054, iter [00670, 01251], lr: 0.000315, loss: 0.0906
2022-10-04 03:29:16 - train: epoch 0054, iter [00680, 01251], lr: 0.000315, loss: 0.0869
2022-10-04 03:29:44 - train: epoch 0054, iter [00690, 01251], lr: 0.000315, loss: 0.0821
2022-10-04 03:30:13 - train: epoch 0054, iter [00700, 01251], lr: 0.000315, loss: 0.0985
2022-10-04 03:30:41 - train: epoch 0054, iter [00710, 01251], lr: 0.000315, loss: 0.0916
2022-10-04 03:31:09 - train: epoch 0054, iter [00720, 01251], lr: 0.000315, loss: 0.0889
2022-10-04 03:31:38 - train: epoch 0054, iter [00730, 01251], lr: 0.000315, loss: 0.0842
2022-10-04 03:32:06 - train: epoch 0054, iter [00740, 01251], lr: 0.000315, loss: 0.0843
2022-10-04 03:32:34 - train: epoch 0054, iter [00750, 01251], lr: 0.000315, loss: 0.0908
2022-10-04 03:33:02 - train: epoch 0054, iter [00760, 01251], lr: 0.000315, loss: 0.0900
2022-10-04 03:33:31 - train: epoch 0054, iter [00770, 01251], lr: 0.000314, loss: 0.0787
2022-10-04 03:33:59 - train: epoch 0054, iter [00780, 01251], lr: 0.000314, loss: 0.0899
2022-10-04 03:34:27 - train: epoch 0054, iter [00790, 01251], lr: 0.000314, loss: 0.0797
2022-10-04 03:34:55 - train: epoch 0054, iter [00800, 01251], lr: 0.000314, loss: 0.0898
2022-10-04 03:35:23 - train: epoch 0054, iter [00810, 01251], lr: 0.000314, loss: 0.0864
2022-10-04 03:35:52 - train: epoch 0054, iter [00820, 01251], lr: 0.000314, loss: 0.0813
2022-10-04 03:36:20 - train: epoch 0054, iter [00830, 01251], lr: 0.000314, loss: 0.0892
2022-10-04 03:36:48 - train: epoch 0054, iter [00840, 01251], lr: 0.000314, loss: 0.0905
2022-10-04 03:37:16 - train: epoch 0054, iter [00850, 01251], lr: 0.000314, loss: 0.0879
2022-10-04 03:37:43 - train: epoch 0054, iter [00860, 01251], lr: 0.000314, loss: 0.0889
2022-10-04 03:38:11 - train: epoch 0054, iter [00870, 01251], lr: 0.000314, loss: 0.0908
2022-10-04 03:38:39 - train: epoch 0054, iter [00880, 01251], lr: 0.000314, loss: 0.0961
2022-10-04 03:39:07 - train: epoch 0054, iter [00890, 01251], lr: 0.000313, loss: 0.0990
2022-10-04 03:39:35 - train: epoch 0054, iter [00900, 01251], lr: 0.000313, loss: 0.0896
2022-10-04 03:40:03 - train: epoch 0054, iter [00910, 01251], lr: 0.000313, loss: 0.0882
2022-10-04 03:40:31 - train: epoch 0054, iter [00920, 01251], lr: 0.000313, loss: 0.0841
2022-10-04 03:40:59 - train: epoch 0054, iter [00930, 01251], lr: 0.000313, loss: 0.0916
2022-10-04 03:41:27 - train: epoch 0054, iter [00940, 01251], lr: 0.000313, loss: 0.0818
2022-10-04 03:41:55 - train: epoch 0054, iter [00950, 01251], lr: 0.000313, loss: 0.0871
2022-10-04 03:42:23 - train: epoch 0054, iter [00960, 01251], lr: 0.000313, loss: 0.0921
2022-10-04 03:42:51 - train: epoch 0054, iter [00970, 01251], lr: 0.000313, loss: 0.0927
2022-10-04 03:43:19 - train: epoch 0054, iter [00980, 01251], lr: 0.000313, loss: 0.0859
2022-10-04 03:43:47 - train: epoch 0054, iter [00990, 01251], lr: 0.000313, loss: 0.0818
2022-10-04 03:44:15 - train: epoch 0054, iter [01000, 01251], lr: 0.000313, loss: 0.0967
2022-10-04 03:44:43 - train: epoch 0054, iter [01010, 01251], lr: 0.000312, loss: 0.0899
2022-10-04 03:45:11 - train: epoch 0054, iter [01020, 01251], lr: 0.000312, loss: 0.0915
2022-10-04 03:45:39 - train: epoch 0054, iter [01030, 01251], lr: 0.000312, loss: 0.0859
2022-10-04 03:46:07 - train: epoch 0054, iter [01040, 01251], lr: 0.000312, loss: 0.0881
2022-10-04 03:46:35 - train: epoch 0054, iter [01050, 01251], lr: 0.000312, loss: 0.0869
2022-10-04 03:47:03 - train: epoch 0054, iter [01060, 01251], lr: 0.000312, loss: 0.0853
2022-10-04 03:47:31 - train: epoch 0054, iter [01070, 01251], lr: 0.000312, loss: 0.0866
2022-10-04 03:47:59 - train: epoch 0054, iter [01080, 01251], lr: 0.000312, loss: 0.0816
2022-10-04 03:48:27 - train: epoch 0054, iter [01090, 01251], lr: 0.000312, loss: 0.0870
2022-10-04 03:48:55 - train: epoch 0054, iter [01100, 01251], lr: 0.000312, loss: 0.0800
2022-10-04 03:49:23 - train: epoch 0054, iter [01110, 01251], lr: 0.000312, loss: 0.0931
2022-10-04 03:49:51 - train: epoch 0054, iter [01120, 01251], lr: 0.000312, loss: 0.0820
2022-10-04 03:50:19 - train: epoch 0054, iter [01130, 01251], lr: 0.000311, loss: 0.0914
2022-10-04 03:50:48 - train: epoch 0054, iter [01140, 01251], lr: 0.000311, loss: 0.0841
2022-10-04 03:51:16 - train: epoch 0054, iter [01150, 01251], lr: 0.000311, loss: 0.0874
2022-10-04 03:51:44 - train: epoch 0054, iter [01160, 01251], lr: 0.000311, loss: 0.0847
2022-10-04 03:52:12 - train: epoch 0054, iter [01170, 01251], lr: 0.000311, loss: 0.0917
2022-10-04 03:52:40 - train: epoch 0054, iter [01180, 01251], lr: 0.000311, loss: 0.0885
2022-10-04 03:53:08 - train: epoch 0054, iter [01190, 01251], lr: 0.000311, loss: 0.0870
2022-10-04 03:53:35 - train: epoch 0054, iter [01200, 01251], lr: 0.000311, loss: 0.0892
2022-10-04 03:54:03 - train: epoch 0054, iter [01210, 01251], lr: 0.000311, loss: 0.0871
2022-10-04 03:54:31 - train: epoch 0054, iter [01220, 01251], lr: 0.000311, loss: 0.0926
2022-10-04 03:54:59 - train: epoch 0054, iter [01230, 01251], lr: 0.000311, loss: 0.0950
2022-10-04 03:55:27 - train: epoch 0054, iter [01240, 01251], lr: 0.000311, loss: 0.0900
2022-10-04 03:55:55 - train: epoch 0054, iter [01250, 01251], lr: 0.000310, loss: 0.0870
2022-10-04 03:55:59 - train: epoch 054, train_loss: 0.0887
2022-10-04 03:56:01 - until epoch: 054, best_loss: 0.0887
2022-10-04 03:56:01 - epoch 055 lr: 0.000310
2022-10-04 03:56:36 - train: epoch 0055, iter [00010, 01251], lr: 0.000310, loss: 0.0897
2022-10-04 03:57:05 - train: epoch 0055, iter [00020, 01251], lr: 0.000310, loss: 0.0901
2022-10-04 03:57:33 - train: epoch 0055, iter [00030, 01251], lr: 0.000310, loss: 0.0925
2022-10-04 03:58:01 - train: epoch 0055, iter [00040, 01251], lr: 0.000310, loss: 0.0884
2022-10-04 03:58:30 - train: epoch 0055, iter [00050, 01251], lr: 0.000310, loss: 0.0928
2022-10-04 03:58:58 - train: epoch 0055, iter [00060, 01251], lr: 0.000310, loss: 0.0904
2022-10-04 03:59:26 - train: epoch 0055, iter [00070, 01251], lr: 0.000310, loss: 0.0823
2022-10-04 03:59:55 - train: epoch 0055, iter [00080, 01251], lr: 0.000310, loss: 0.0836
2022-10-04 04:00:23 - train: epoch 0055, iter [00090, 01251], lr: 0.000310, loss: 0.0904
2022-10-04 04:00:51 - train: epoch 0055, iter [00100, 01251], lr: 0.000310, loss: 0.0846
2022-10-04 04:01:20 - train: epoch 0055, iter [00110, 01251], lr: 0.000310, loss: 0.0959
2022-10-04 04:01:48 - train: epoch 0055, iter [00120, 01251], lr: 0.000309, loss: 0.0893
2022-10-04 04:02:16 - train: epoch 0055, iter [00130, 01251], lr: 0.000309, loss: 0.0895
2022-10-04 04:02:44 - train: epoch 0055, iter [00140, 01251], lr: 0.000309, loss: 0.0837
2022-10-04 04:03:13 - train: epoch 0055, iter [00150, 01251], lr: 0.000309, loss: 0.0846
2022-10-04 04:03:41 - train: epoch 0055, iter [00160, 01251], lr: 0.000309, loss: 0.0910
2022-10-04 04:04:09 - train: epoch 0055, iter [00170, 01251], lr: 0.000309, loss: 0.0863
2022-10-04 04:04:37 - train: epoch 0055, iter [00180, 01251], lr: 0.000309, loss: 0.0899
2022-10-04 04:05:05 - train: epoch 0055, iter [00190, 01251], lr: 0.000309, loss: 0.0920
2022-10-04 04:05:34 - train: epoch 0055, iter [00200, 01251], lr: 0.000309, loss: 0.0809
2022-10-04 04:06:02 - train: epoch 0055, iter [00210, 01251], lr: 0.000309, loss: 0.0892
2022-10-04 04:06:30 - train: epoch 0055, iter [00220, 01251], lr: 0.000309, loss: 0.0922
2022-10-04 04:06:58 - train: epoch 0055, iter [00230, 01251], lr: 0.000309, loss: 0.0807
2022-10-04 04:07:27 - train: epoch 0055, iter [00240, 01251], lr: 0.000308, loss: 0.0860
2022-10-04 04:07:55 - train: epoch 0055, iter [00250, 01251], lr: 0.000308, loss: 0.0848
2022-10-04 04:08:23 - train: epoch 0055, iter [00260, 01251], lr: 0.000308, loss: 0.0871
2022-10-04 04:08:51 - train: epoch 0055, iter [00270, 01251], lr: 0.000308, loss: 0.0859
2022-10-04 04:09:19 - train: epoch 0055, iter [00280, 01251], lr: 0.000308, loss: 0.0916
2022-10-04 04:09:47 - train: epoch 0055, iter [00290, 01251], lr: 0.000308, loss: 0.0962
2022-10-04 04:10:15 - train: epoch 0055, iter [00300, 01251], lr: 0.000308, loss: 0.0969
2022-10-04 04:10:43 - train: epoch 0055, iter [00310, 01251], lr: 0.000308, loss: 0.0879
2022-10-04 04:11:12 - train: epoch 0055, iter [00320, 01251], lr: 0.000308, loss: 0.0936
2022-10-04 04:11:40 - train: epoch 0055, iter [00330, 01251], lr: 0.000308, loss: 0.0922
2022-10-04 04:12:08 - train: epoch 0055, iter [00340, 01251], lr: 0.000308, loss: 0.0921
2022-10-04 04:12:36 - train: epoch 0055, iter [00350, 01251], lr: 0.000308, loss: 0.0855
2022-10-04 04:13:04 - train: epoch 0055, iter [00360, 01251], lr: 0.000307, loss: 0.0916
2022-10-04 04:13:32 - train: epoch 0055, iter [00370, 01251], lr: 0.000307, loss: 0.0876
2022-10-04 04:14:00 - train: epoch 0055, iter [00380, 01251], lr: 0.000307, loss: 0.0872
2022-10-04 04:14:28 - train: epoch 0055, iter [00390, 01251], lr: 0.000307, loss: 0.0844
2022-10-04 04:14:57 - train: epoch 0055, iter [00400, 01251], lr: 0.000307, loss: 0.0863
2022-10-04 04:15:25 - train: epoch 0055, iter [00410, 01251], lr: 0.000307, loss: 0.0892
2022-10-04 04:15:53 - train: epoch 0055, iter [00420, 01251], lr: 0.000307, loss: 0.0842
2022-10-04 04:16:21 - train: epoch 0055, iter [00430, 01251], lr: 0.000307, loss: 0.0907
2022-10-04 04:16:50 - train: epoch 0055, iter [00440, 01251], lr: 0.000307, loss: 0.0832
2022-10-04 04:17:18 - train: epoch 0055, iter [00450, 01251], lr: 0.000307, loss: 0.0874
2022-10-04 04:17:46 - train: epoch 0055, iter [00460, 01251], lr: 0.000307, loss: 0.0860
2022-10-04 04:18:14 - train: epoch 0055, iter [00470, 01251], lr: 0.000307, loss: 0.0830
2022-10-04 04:18:43 - train: epoch 0055, iter [00480, 01251], lr: 0.000306, loss: 0.0874
2022-10-04 04:19:11 - train: epoch 0055, iter [00490, 01251], lr: 0.000306, loss: 0.0937
2022-10-04 04:19:39 - train: epoch 0055, iter [00500, 01251], lr: 0.000306, loss: 0.0868
2022-10-04 04:20:07 - train: epoch 0055, iter [00510, 01251], lr: 0.000306, loss: 0.0895
2022-10-04 04:20:36 - train: epoch 0055, iter [00520, 01251], lr: 0.000306, loss: 0.0852
2022-10-04 04:21:04 - train: epoch 0055, iter [00530, 01251], lr: 0.000306, loss: 0.0819
2022-10-04 04:21:32 - train: epoch 0055, iter [00540, 01251], lr: 0.000306, loss: 0.0861
2022-10-04 04:22:00 - train: epoch 0055, iter [00550, 01251], lr: 0.000306, loss: 0.0832
2022-10-04 04:22:28 - train: epoch 0055, iter [00560, 01251], lr: 0.000306, loss: 0.0890
2022-10-04 04:22:57 - train: epoch 0055, iter [00570, 01251], lr: 0.000306, loss: 0.0917
2022-10-04 04:23:25 - train: epoch 0055, iter [00580, 01251], lr: 0.000306, loss: 0.0904
2022-10-04 04:23:53 - train: epoch 0055, iter [00590, 01251], lr: 0.000306, loss: 0.0914
2022-10-04 04:24:21 - train: epoch 0055, iter [00600, 01251], lr: 0.000305, loss: 0.0812
2022-10-04 04:24:49 - train: epoch 0055, iter [00610, 01251], lr: 0.000305, loss: 0.0844
2022-10-04 04:25:17 - train: epoch 0055, iter [00620, 01251], lr: 0.000305, loss: 0.0997
2022-10-04 04:25:45 - train: epoch 0055, iter [00630, 01251], lr: 0.000305, loss: 0.0929
2022-10-04 04:26:14 - train: epoch 0055, iter [00640, 01251], lr: 0.000305, loss: 0.0939
2022-10-04 04:26:41 - train: epoch 0055, iter [00650, 01251], lr: 0.000305, loss: 0.0892
2022-10-04 04:27:09 - train: epoch 0055, iter [00660, 01251], lr: 0.000305, loss: 0.0883
2022-10-04 04:27:37 - train: epoch 0055, iter [00670, 01251], lr: 0.000305, loss: 0.0967
2022-10-04 04:28:05 - train: epoch 0055, iter [00680, 01251], lr: 0.000305, loss: 0.0824
2022-10-04 04:28:33 - train: epoch 0055, iter [00690, 01251], lr: 0.000305, loss: 0.0860
2022-10-04 04:29:01 - train: epoch 0055, iter [00700, 01251], lr: 0.000305, loss: 0.0891
2022-10-04 04:29:29 - train: epoch 0055, iter [00710, 01251], lr: 0.000305, loss: 0.0885
2022-10-04 04:29:57 - train: epoch 0055, iter [00720, 01251], lr: 0.000304, loss: 0.0908
2022-10-04 04:30:26 - train: epoch 0055, iter [00730, 01251], lr: 0.000304, loss: 0.0890
2022-10-04 04:30:54 - train: epoch 0055, iter [00740, 01251], lr: 0.000304, loss: 0.0913
2022-10-04 04:31:22 - train: epoch 0055, iter [00750, 01251], lr: 0.000304, loss: 0.0884
2022-10-04 04:31:50 - train: epoch 0055, iter [00760, 01251], lr: 0.000304, loss: 0.0875
2022-10-04 04:32:18 - train: epoch 0055, iter [00770, 01251], lr: 0.000304, loss: 0.0887
2022-10-04 04:32:47 - train: epoch 0055, iter [00780, 01251], lr: 0.000304, loss: 0.0895
2022-10-04 04:33:15 - train: epoch 0055, iter [00790, 01251], lr: 0.000304, loss: 0.0876
2022-10-04 04:33:43 - train: epoch 0055, iter [00800, 01251], lr: 0.000304, loss: 0.0856
2022-10-04 04:34:11 - train: epoch 0055, iter [00810, 01251], lr: 0.000304, loss: 0.0860
2022-10-04 04:34:40 - train: epoch 0055, iter [00820, 01251], lr: 0.000304, loss: 0.0866
2022-10-04 04:35:08 - train: epoch 0055, iter [00830, 01251], lr: 0.000304, loss: 0.0945
2022-10-04 04:35:36 - train: epoch 0055, iter [00840, 01251], lr: 0.000303, loss: 0.0865
2022-10-04 04:36:04 - train: epoch 0055, iter [00850, 01251], lr: 0.000303, loss: 0.0859
2022-10-04 04:36:32 - train: epoch 0055, iter [00860, 01251], lr: 0.000303, loss: 0.0871
2022-10-04 04:37:00 - train: epoch 0055, iter [00870, 01251], lr: 0.000303, loss: 0.0889
2022-10-04 04:37:28 - train: epoch 0055, iter [00880, 01251], lr: 0.000303, loss: 0.0823
2022-10-04 04:37:56 - train: epoch 0055, iter [00890, 01251], lr: 0.000303, loss: 0.0877
2022-10-04 04:38:24 - train: epoch 0055, iter [00900, 01251], lr: 0.000303, loss: 0.0838
2022-10-04 04:38:53 - train: epoch 0055, iter [00910, 01251], lr: 0.000303, loss: 0.0850
2022-10-04 04:39:21 - train: epoch 0055, iter [00920, 01251], lr: 0.000303, loss: 0.0879
2022-10-04 04:39:49 - train: epoch 0055, iter [00930, 01251], lr: 0.000303, loss: 0.0945
2022-10-04 04:40:17 - train: epoch 0055, iter [00940, 01251], lr: 0.000303, loss: 0.0925
2022-10-04 04:40:45 - train: epoch 0055, iter [00950, 01251], lr: 0.000303, loss: 0.0891
2022-10-04 04:41:13 - train: epoch 0055, iter [00960, 01251], lr: 0.000302, loss: 0.0834
2022-10-04 04:41:41 - train: epoch 0055, iter [00970, 01251], lr: 0.000302, loss: 0.0855
2022-10-04 04:42:09 - train: epoch 0055, iter [00980, 01251], lr: 0.000302, loss: 0.0893
2022-10-04 04:42:37 - train: epoch 0055, iter [00990, 01251], lr: 0.000302, loss: 0.0924
2022-10-04 04:43:06 - train: epoch 0055, iter [01000, 01251], lr: 0.000302, loss: 0.0889
2022-10-04 04:43:34 - train: epoch 0055, iter [01010, 01251], lr: 0.000302, loss: 0.0899
2022-10-04 04:44:02 - train: epoch 0055, iter [01020, 01251], lr: 0.000302, loss: 0.0844
2022-10-04 04:44:30 - train: epoch 0055, iter [01030, 01251], lr: 0.000302, loss: 0.0933
2022-10-04 04:44:58 - train: epoch 0055, iter [01040, 01251], lr: 0.000302, loss: 0.0891
2022-10-04 04:45:26 - train: epoch 0055, iter [01050, 01251], lr: 0.000302, loss: 0.0847
2022-10-04 04:45:54 - train: epoch 0055, iter [01060, 01251], lr: 0.000302, loss: 0.0799
2022-10-04 04:46:22 - train: epoch 0055, iter [01070, 01251], lr: 0.000302, loss: 0.1008
2022-10-04 04:46:50 - train: epoch 0055, iter [01080, 01251], lr: 0.000301, loss: 0.0887
2022-10-04 04:47:19 - train: epoch 0055, iter [01090, 01251], lr: 0.000301, loss: 0.0801
2022-10-04 04:47:47 - train: epoch 0055, iter [01100, 01251], lr: 0.000301, loss: 0.0881
2022-10-04 04:48:15 - train: epoch 0055, iter [01110, 01251], lr: 0.000301, loss: 0.0898
2022-10-04 04:48:43 - train: epoch 0055, iter [01120, 01251], lr: 0.000301, loss: 0.0840
2022-10-04 04:49:11 - train: epoch 0055, iter [01130, 01251], lr: 0.000301, loss: 0.0930
2022-10-04 04:49:39 - train: epoch 0055, iter [01140, 01251], lr: 0.000301, loss: 0.0901
2022-10-04 04:50:08 - train: epoch 0055, iter [01150, 01251], lr: 0.000301, loss: 0.1007
2022-10-04 04:50:36 - train: epoch 0055, iter [01160, 01251], lr: 0.000301, loss: 0.0873
2022-10-04 04:51:04 - train: epoch 0055, iter [01170, 01251], lr: 0.000301, loss: 0.0839
2022-10-04 04:51:32 - train: epoch 0055, iter [01180, 01251], lr: 0.000301, loss: 0.0869
2022-10-04 04:52:01 - train: epoch 0055, iter [01190, 01251], lr: 0.000301, loss: 0.0866
2022-10-04 04:52:29 - train: epoch 0055, iter [01200, 01251], lr: 0.000300, loss: 0.0794
2022-10-04 04:52:57 - train: epoch 0055, iter [01210, 01251], lr: 0.000300, loss: 0.0951
2022-10-04 04:53:25 - train: epoch 0055, iter [01220, 01251], lr: 0.000300, loss: 0.0873
2022-10-04 04:53:53 - train: epoch 0055, iter [01230, 01251], lr: 0.000300, loss: 0.0896
2022-10-04 04:54:21 - train: epoch 0055, iter [01240, 01251], lr: 0.000300, loss: 0.0903
2022-10-04 04:54:49 - train: epoch 0055, iter [01250, 01251], lr: 0.000300, loss: 0.0892
2022-10-04 04:54:53 - train: epoch 055, train_loss: 0.0886
2022-10-04 04:54:55 - until epoch: 055, best_loss: 0.0886
2022-10-04 04:54:55 - epoch 056 lr: 0.000300
2022-10-04 04:55:30 - train: epoch 0056, iter [00010, 01251], lr: 0.000300, loss: 0.0837
2022-10-04 04:55:58 - train: epoch 0056, iter [00020, 01251], lr: 0.000300, loss: 0.0899
2022-10-04 04:56:27 - train: epoch 0056, iter [00030, 01251], lr: 0.000300, loss: 0.0866
2022-10-04 04:56:55 - train: epoch 0056, iter [00040, 01251], lr: 0.000300, loss: 0.0929
2022-10-04 04:57:23 - train: epoch 0056, iter [00050, 01251], lr: 0.000300, loss: 0.0838
2022-10-04 04:57:52 - train: epoch 0056, iter [00060, 01251], lr: 0.000299, loss: 0.0949
2022-10-04 04:58:20 - train: epoch 0056, iter [00070, 01251], lr: 0.000299, loss: 0.0931
2022-10-04 04:58:48 - train: epoch 0056, iter [00080, 01251], lr: 0.000299, loss: 0.0864
2022-10-04 04:59:16 - train: epoch 0056, iter [00090, 01251], lr: 0.000299, loss: 0.0877
2022-10-04 04:59:45 - train: epoch 0056, iter [00100, 01251], lr: 0.000299, loss: 0.0804
2022-10-04 05:00:13 - train: epoch 0056, iter [00110, 01251], lr: 0.000299, loss: 0.0853
2022-10-04 05:00:41 - train: epoch 0056, iter [00120, 01251], lr: 0.000299, loss: 0.0845
2022-10-04 05:01:09 - train: epoch 0056, iter [00130, 01251], lr: 0.000299, loss: 0.0855
2022-10-04 05:01:37 - train: epoch 0056, iter [00140, 01251], lr: 0.000299, loss: 0.0843
2022-10-04 05:02:05 - train: epoch 0056, iter [00150, 01251], lr: 0.000299, loss: 0.1007
2022-10-04 05:02:34 - train: epoch 0056, iter [00160, 01251], lr: 0.000299, loss: 0.0845
2022-10-04 05:03:02 - train: epoch 0056, iter [00170, 01251], lr: 0.000299, loss: 0.0926
2022-10-04 05:03:30 - train: epoch 0056, iter [00180, 01251], lr: 0.000298, loss: 0.0873
2022-10-04 05:03:58 - train: epoch 0056, iter [00190, 01251], lr: 0.000298, loss: 0.0887
2022-10-04 05:04:27 - train: epoch 0056, iter [00200, 01251], lr: 0.000298, loss: 0.0844
2022-10-04 05:04:55 - train: epoch 0056, iter [00210, 01251], lr: 0.000298, loss: 0.0893
2022-10-04 05:05:23 - train: epoch 0056, iter [00220, 01251], lr: 0.000298, loss: 0.0863
2022-10-04 05:05:51 - train: epoch 0056, iter [00230, 01251], lr: 0.000298, loss: 0.0846
2022-10-04 05:06:19 - train: epoch 0056, iter [00240, 01251], lr: 0.000298, loss: 0.0873
2022-10-04 05:06:48 - train: epoch 0056, iter [00250, 01251], lr: 0.000298, loss: 0.0884
2022-10-04 05:07:16 - train: epoch 0056, iter [00260, 01251], lr: 0.000298, loss: 0.0873
2022-10-04 05:07:44 - train: epoch 0056, iter [00270, 01251], lr: 0.000298, loss: 0.0835
2022-10-04 05:08:13 - train: epoch 0056, iter [00280, 01251], lr: 0.000298, loss: 0.0854
2022-10-04 05:08:41 - train: epoch 0056, iter [00290, 01251], lr: 0.000298, loss: 0.0809
2022-10-04 05:09:09 - train: epoch 0056, iter [00300, 01251], lr: 0.000297, loss: 0.0864
2022-10-04 05:09:37 - train: epoch 0056, iter [00310, 01251], lr: 0.000297, loss: 0.0891
2022-10-04 05:10:05 - train: epoch 0056, iter [00320, 01251], lr: 0.000297, loss: 0.0859
2022-10-04 05:10:33 - train: epoch 0056, iter [00330, 01251], lr: 0.000297, loss: 0.0867
2022-10-04 05:11:01 - train: epoch 0056, iter [00340, 01251], lr: 0.000297, loss: 0.0847
2022-10-04 05:11:29 - train: epoch 0056, iter [00350, 01251], lr: 0.000297, loss: 0.0885
2022-10-04 05:11:58 - train: epoch 0056, iter [00360, 01251], lr: 0.000297, loss: 0.0924
2022-10-04 05:12:26 - train: epoch 0056, iter [00370, 01251], lr: 0.000297, loss: 0.0891
2022-10-04 05:12:54 - train: epoch 0056, iter [00380, 01251], lr: 0.000297, loss: 0.0930
2022-10-04 05:13:22 - train: epoch 0056, iter [00390, 01251], lr: 0.000297, loss: 0.0883
2022-10-04 05:13:50 - train: epoch 0056, iter [00400, 01251], lr: 0.000297, loss: 0.0901
2022-10-04 05:14:18 - train: epoch 0056, iter [00410, 01251], lr: 0.000297, loss: 0.0867
2022-10-04 05:14:46 - train: epoch 0056, iter [00420, 01251], lr: 0.000296, loss: 0.0919
2022-10-04 05:15:14 - train: epoch 0056, iter [00430, 01251], lr: 0.000296, loss: 0.0898
2022-10-04 05:15:42 - train: epoch 0056, iter [00440, 01251], lr: 0.000296, loss: 0.0949
2022-10-04 05:16:10 - train: epoch 0056, iter [00450, 01251], lr: 0.000296, loss: 0.0887
2022-10-04 05:16:39 - train: epoch 0056, iter [00460, 01251], lr: 0.000296, loss: 0.0775
2022-10-04 05:17:07 - train: epoch 0056, iter [00470, 01251], lr: 0.000296, loss: 0.0886
2022-10-04 05:17:35 - train: epoch 0056, iter [00480, 01251], lr: 0.000296, loss: 0.0933
2022-10-04 05:18:03 - train: epoch 0056, iter [00490, 01251], lr: 0.000296, loss: 0.0846
2022-10-04 05:18:31 - train: epoch 0056, iter [00500, 01251], lr: 0.000296, loss: 0.0853
2022-10-04 05:18:59 - train: epoch 0056, iter [00510, 01251], lr: 0.000296, loss: 0.0794
2022-10-04 05:19:27 - train: epoch 0056, iter [00520, 01251], lr: 0.000296, loss: 0.0922
2022-10-04 05:19:55 - train: epoch 0056, iter [00530, 01251], lr: 0.000296, loss: 0.0908
2022-10-04 05:20:23 - train: epoch 0056, iter [00540, 01251], lr: 0.000295, loss: 0.0915
2022-10-04 05:20:51 - train: epoch 0056, iter [00550, 01251], lr: 0.000295, loss: 0.0863
2022-10-04 05:21:19 - train: epoch 0056, iter [00560, 01251], lr: 0.000295, loss: 0.0843
2022-10-04 05:21:48 - train: epoch 0056, iter [00570, 01251], lr: 0.000295, loss: 0.0918
2022-10-04 05:22:16 - train: epoch 0056, iter [00580, 01251], lr: 0.000295, loss: 0.0891
2022-10-04 05:22:44 - train: epoch 0056, iter [00590, 01251], lr: 0.000295, loss: 0.0871
2022-10-04 05:23:12 - train: epoch 0056, iter [00600, 01251], lr: 0.000295, loss: 0.0873
2022-10-04 05:23:41 - train: epoch 0056, iter [00610, 01251], lr: 0.000295, loss: 0.0904
2022-10-04 05:24:09 - train: epoch 0056, iter [00620, 01251], lr: 0.000295, loss: 0.0858
2022-10-04 05:24:37 - train: epoch 0056, iter [00630, 01251], lr: 0.000295, loss: 0.0882
2022-10-04 05:25:05 - train: epoch 0056, iter [00640, 01251], lr: 0.000295, loss: 0.0898
2022-10-04 05:25:34 - train: epoch 0056, iter [00650, 01251], lr: 0.000295, loss: 0.0875
2022-10-04 05:26:02 - train: epoch 0056, iter [00660, 01251], lr: 0.000294, loss: 0.0831
2022-10-04 05:26:30 - train: epoch 0056, iter [00670, 01251], lr: 0.000294, loss: 0.1000
2022-10-04 05:26:58 - train: epoch 0056, iter [00680, 01251], lr: 0.000294, loss: 0.0853
2022-10-04 05:27:26 - train: epoch 0056, iter [00690, 01251], lr: 0.000294, loss: 0.0859
2022-10-04 05:27:54 - train: epoch 0056, iter [00700, 01251], lr: 0.000294, loss: 0.0845
2022-10-04 05:28:22 - train: epoch 0056, iter [00710, 01251], lr: 0.000294, loss: 0.0857
2022-10-04 05:28:51 - train: epoch 0056, iter [00720, 01251], lr: 0.000294, loss: 0.0893
2022-10-04 05:29:19 - train: epoch 0056, iter [00730, 01251], lr: 0.000294, loss: 0.0863
2022-10-04 05:29:47 - train: epoch 0056, iter [00740, 01251], lr: 0.000294, loss: 0.0950
2022-10-04 05:30:15 - train: epoch 0056, iter [00750, 01251], lr: 0.000294, loss: 0.0889
2022-10-04 05:30:43 - train: epoch 0056, iter [00760, 01251], lr: 0.000294, loss: 0.0835
2022-10-04 05:31:11 - train: epoch 0056, iter [00770, 01251], lr: 0.000294, loss: 0.0867
2022-10-04 05:31:40 - train: epoch 0056, iter [00780, 01251], lr: 0.000293, loss: 0.0852
2022-10-04 05:32:08 - train: epoch 0056, iter [00790, 01251], lr: 0.000293, loss: 0.0881
2022-10-04 05:32:36 - train: epoch 0056, iter [00800, 01251], lr: 0.000293, loss: 0.0894
2022-10-04 05:33:04 - train: epoch 0056, iter [00810, 01251], lr: 0.000293, loss: 0.0891
2022-10-04 05:33:32 - train: epoch 0056, iter [00820, 01251], lr: 0.000293, loss: 0.0895
2022-10-04 05:34:01 - train: epoch 0056, iter [00830, 01251], lr: 0.000293, loss: 0.0893
2022-10-04 05:34:29 - train: epoch 0056, iter [00840, 01251], lr: 0.000293, loss: 0.0870
2022-10-04 05:34:57 - train: epoch 0056, iter [00850, 01251], lr: 0.000293, loss: 0.0837
2022-10-04 05:35:25 - train: epoch 0056, iter [00860, 01251], lr: 0.000293, loss: 0.0960
2022-10-04 05:35:53 - train: epoch 0056, iter [00870, 01251], lr: 0.000293, loss: 0.0924
2022-10-04 05:36:22 - train: epoch 0056, iter [00880, 01251], lr: 0.000293, loss: 0.0866
2022-10-04 05:36:50 - train: epoch 0056, iter [00890, 01251], lr: 0.000293, loss: 0.0853
2022-10-04 05:37:18 - train: epoch 0056, iter [00900, 01251], lr: 0.000292, loss: 0.0929
2022-10-04 05:37:46 - train: epoch 0056, iter [00910, 01251], lr: 0.000292, loss: 0.0874
2022-10-04 05:38:15 - train: epoch 0056, iter [00920, 01251], lr: 0.000292, loss: 0.0868
2022-10-04 05:38:43 - train: epoch 0056, iter [00930, 01251], lr: 0.000292, loss: 0.0909
2022-10-04 05:39:11 - train: epoch 0056, iter [00940, 01251], lr: 0.000292, loss: 0.0905
2022-10-04 05:39:39 - train: epoch 0056, iter [00950, 01251], lr: 0.000292, loss: 0.0865
2022-10-04 05:40:07 - train: epoch 0056, iter [00960, 01251], lr: 0.000292, loss: 0.0788
2022-10-04 05:40:35 - train: epoch 0056, iter [00970, 01251], lr: 0.000292, loss: 0.0930
2022-10-04 05:41:04 - train: epoch 0056, iter [00980, 01251], lr: 0.000292, loss: 0.0896
2022-10-04 05:41:32 - train: epoch 0056, iter [00990, 01251], lr: 0.000292, loss: 0.0891
2022-10-04 05:42:00 - train: epoch 0056, iter [01000, 01251], lr: 0.000292, loss: 0.0881
2022-10-04 05:42:28 - train: epoch 0056, iter [01010, 01251], lr: 0.000292, loss: 0.0928
2022-10-04 05:42:56 - train: epoch 0056, iter [01020, 01251], lr: 0.000291, loss: 0.0838
2022-10-04 05:43:24 - train: epoch 0056, iter [01030, 01251], lr: 0.000291, loss: 0.0863
2022-10-04 05:43:52 - train: epoch 0056, iter [01040, 01251], lr: 0.000291, loss: 0.0944
2022-10-04 05:44:21 - train: epoch 0056, iter [01050, 01251], lr: 0.000291, loss: 0.0828
2022-10-04 05:44:49 - train: epoch 0056, iter [01060, 01251], lr: 0.000291, loss: 0.0905
2022-10-04 05:45:17 - train: epoch 0056, iter [01070, 01251], lr: 0.000291, loss: 0.0902
2022-10-04 05:45:45 - train: epoch 0056, iter [01080, 01251], lr: 0.000291, loss: 0.0872
2022-10-04 05:46:13 - train: epoch 0056, iter [01090, 01251], lr: 0.000291, loss: 0.0843
2022-10-04 05:46:42 - train: epoch 0056, iter [01100, 01251], lr: 0.000291, loss: 0.0954
2022-10-04 05:47:10 - train: epoch 0056, iter [01110, 01251], lr: 0.000291, loss: 0.0912
2022-10-04 05:47:38 - train: epoch 0056, iter [01120, 01251], lr: 0.000291, loss: 0.0906
2022-10-04 05:48:06 - train: epoch 0056, iter [01130, 01251], lr: 0.000291, loss: 0.0840
2022-10-04 05:48:34 - train: epoch 0056, iter [01140, 01251], lr: 0.000290, loss: 0.0817
2022-10-04 05:49:02 - train: epoch 0056, iter [01150, 01251], lr: 0.000290, loss: 0.0932
2022-10-04 05:49:31 - train: epoch 0056, iter [01160, 01251], lr: 0.000290, loss: 0.0833
2022-10-04 05:49:59 - train: epoch 0056, iter [01170, 01251], lr: 0.000290, loss: 0.0845
2022-10-04 05:50:27 - train: epoch 0056, iter [01180, 01251], lr: 0.000290, loss: 0.0899
2022-10-04 05:50:55 - train: epoch 0056, iter [01190, 01251], lr: 0.000290, loss: 0.0942
2022-10-04 05:51:23 - train: epoch 0056, iter [01200, 01251], lr: 0.000290, loss: 0.0752
2022-10-04 05:51:51 - train: epoch 0056, iter [01210, 01251], lr: 0.000290, loss: 0.0886
2022-10-04 05:52:20 - train: epoch 0056, iter [01220, 01251], lr: 0.000290, loss: 0.0916
2022-10-04 05:52:48 - train: epoch 0056, iter [01230, 01251], lr: 0.000290, loss: 0.0867
2022-10-04 05:53:16 - train: epoch 0056, iter [01240, 01251], lr: 0.000290, loss: 0.0896
2022-10-04 05:53:44 - train: epoch 0056, iter [01250, 01251], lr: 0.000290, loss: 0.0811
2022-10-04 05:53:48 - train: epoch 056, train_loss: 0.0881
2022-10-04 05:53:50 - until epoch: 056, best_loss: 0.0881
2022-10-04 05:53:50 - epoch 057 lr: 0.000290
2022-10-04 05:54:25 - train: epoch 0057, iter [00010, 01251], lr: 0.000289, loss: 0.0806
2022-10-04 05:54:54 - train: epoch 0057, iter [00020, 01251], lr: 0.000289, loss: 0.0888
2022-10-04 05:55:22 - train: epoch 0057, iter [00030, 01251], lr: 0.000289, loss: 0.0855
2022-10-04 05:55:50 - train: epoch 0057, iter [00040, 01251], lr: 0.000289, loss: 0.0934
2022-10-04 05:56:18 - train: epoch 0057, iter [00050, 01251], lr: 0.000289, loss: 0.0921
2022-10-04 05:56:46 - train: epoch 0057, iter [00060, 01251], lr: 0.000289, loss: 0.0849
2022-10-04 05:57:15 - train: epoch 0057, iter [00070, 01251], lr: 0.000289, loss: 0.0888
2022-10-04 05:57:43 - train: epoch 0057, iter [00080, 01251], lr: 0.000289, loss: 0.0927
2022-10-04 05:58:11 - train: epoch 0057, iter [00090, 01251], lr: 0.000289, loss: 0.0840
2022-10-04 05:58:39 - train: epoch 0057, iter [00100, 01251], lr: 0.000289, loss: 0.0906
2022-10-04 05:59:08 - train: epoch 0057, iter [00110, 01251], lr: 0.000289, loss: 0.0842
2022-10-04 05:59:36 - train: epoch 0057, iter [00120, 01251], lr: 0.000289, loss: 0.0895
2022-10-04 06:00:04 - train: epoch 0057, iter [00130, 01251], lr: 0.000288, loss: 0.0868
2022-10-04 06:00:32 - train: epoch 0057, iter [00140, 01251], lr: 0.000288, loss: 0.0973
2022-10-04 06:01:00 - train: epoch 0057, iter [00150, 01251], lr: 0.000288, loss: 0.0858
2022-10-04 06:01:28 - train: epoch 0057, iter [00160, 01251], lr: 0.000288, loss: 0.0958
2022-10-04 06:01:56 - train: epoch 0057, iter [00170, 01251], lr: 0.000288, loss: 0.0864
2022-10-04 06:02:24 - train: epoch 0057, iter [00180, 01251], lr: 0.000288, loss: 0.0925
2022-10-04 06:02:53 - train: epoch 0057, iter [00190, 01251], lr: 0.000288, loss: 0.0868
2022-10-04 06:03:21 - train: epoch 0057, iter [00200, 01251], lr: 0.000288, loss: 0.0879
2022-10-04 06:03:49 - train: epoch 0057, iter [00210, 01251], lr: 0.000288, loss: 0.0912
2022-10-04 06:04:17 - train: epoch 0057, iter [00220, 01251], lr: 0.000288, loss: 0.0905
2022-10-04 06:04:45 - train: epoch 0057, iter [00230, 01251], lr: 0.000288, loss: 0.0896
2022-10-04 06:05:13 - train: epoch 0057, iter [00240, 01251], lr: 0.000288, loss: 0.0893
2022-10-04 06:05:42 - train: epoch 0057, iter [00250, 01251], lr: 0.000287, loss: 0.0880
2022-10-04 06:06:10 - train: epoch 0057, iter [00260, 01251], lr: 0.000287, loss: 0.0910
2022-10-04 06:06:38 - train: epoch 0057, iter [00270, 01251], lr: 0.000287, loss: 0.0919
2022-10-04 06:07:06 - train: epoch 0057, iter [00280, 01251], lr: 0.000287, loss: 0.0874
2022-10-04 06:07:34 - train: epoch 0057, iter [00290, 01251], lr: 0.000287, loss: 0.0936
2022-10-04 06:08:03 - train: epoch 0057, iter [00300, 01251], lr: 0.000287, loss: 0.0918
2022-10-04 06:08:31 - train: epoch 0057, iter [00310, 01251], lr: 0.000287, loss: 0.0855
2022-10-04 06:08:59 - train: epoch 0057, iter [00320, 01251], lr: 0.000287, loss: 0.0894
2022-10-04 06:09:27 - train: epoch 0057, iter [00330, 01251], lr: 0.000287, loss: 0.0874
2022-10-04 06:09:56 - train: epoch 0057, iter [00340, 01251], lr: 0.000287, loss: 0.0931
2022-10-04 06:10:24 - train: epoch 0057, iter [00350, 01251], lr: 0.000287, loss: 0.0840
2022-10-04 06:10:52 - train: epoch 0057, iter [00360, 01251], lr: 0.000287, loss: 0.0850
2022-10-04 06:11:21 - train: epoch 0057, iter [00370, 01251], lr: 0.000286, loss: 0.0960
2022-10-04 06:11:49 - train: epoch 0057, iter [00380, 01251], lr: 0.000286, loss: 0.0862
2022-10-04 06:12:17 - train: epoch 0057, iter [00390, 01251], lr: 0.000286, loss: 0.0844
2022-10-04 06:12:45 - train: epoch 0057, iter [00400, 01251], lr: 0.000286, loss: 0.0820
2022-10-04 06:13:14 - train: epoch 0057, iter [00410, 01251], lr: 0.000286, loss: 0.0895
2022-10-04 06:13:42 - train: epoch 0057, iter [00420, 01251], lr: 0.000286, loss: 0.0936
2022-10-04 06:14:10 - train: epoch 0057, iter [00430, 01251], lr: 0.000286, loss: 0.0921
2022-10-04 06:14:38 - train: epoch 0057, iter [00440, 01251], lr: 0.000286, loss: 0.0809
2022-10-04 06:15:06 - train: epoch 0057, iter [00450, 01251], lr: 0.000286, loss: 0.0888
2022-10-04 06:15:35 - train: epoch 0057, iter [00460, 01251], lr: 0.000286, loss: 0.0876
2022-10-04 06:16:03 - train: epoch 0057, iter [00470, 01251], lr: 0.000286, loss: 0.0869
2022-10-04 06:16:31 - train: epoch 0057, iter [00480, 01251], lr: 0.000286, loss: 0.0912
2022-10-04 06:16:59 - train: epoch 0057, iter [00490, 01251], lr: 0.000285, loss: 0.0867
2022-10-04 06:17:27 - train: epoch 0057, iter [00500, 01251], lr: 0.000285, loss: 0.0808
2022-10-04 06:17:55 - train: epoch 0057, iter [00510, 01251], lr: 0.000285, loss: 0.0847
2022-10-04 06:18:23 - train: epoch 0057, iter [00520, 01251], lr: 0.000285, loss: 0.0925
2022-10-04 06:18:51 - train: epoch 0057, iter [00530, 01251], lr: 0.000285, loss: 0.0885
2022-10-04 06:19:19 - train: epoch 0057, iter [00540, 01251], lr: 0.000285, loss: 0.0850
2022-10-04 06:19:48 - train: epoch 0057, iter [00550, 01251], lr: 0.000285, loss: 0.0866
2022-10-04 06:20:16 - train: epoch 0057, iter [00560, 01251], lr: 0.000285, loss: 0.0886
2022-10-04 06:20:44 - train: epoch 0057, iter [00570, 01251], lr: 0.000285, loss: 0.0908
2022-10-04 06:21:12 - train: epoch 0057, iter [00580, 01251], lr: 0.000285, loss: 0.0859
2022-10-04 06:21:40 - train: epoch 0057, iter [00590, 01251], lr: 0.000285, loss: 0.0873
2022-10-04 06:22:08 - train: epoch 0057, iter [00600, 01251], lr: 0.000285, loss: 0.0935
2022-10-04 06:22:36 - train: epoch 0057, iter [00610, 01251], lr: 0.000284, loss: 0.0887
2022-10-04 06:23:04 - train: epoch 0057, iter [00620, 01251], lr: 0.000284, loss: 0.0900
2022-10-04 06:23:32 - train: epoch 0057, iter [00630, 01251], lr: 0.000284, loss: 0.0868
2022-10-04 06:24:01 - train: epoch 0057, iter [00640, 01251], lr: 0.000284, loss: 0.0918
2022-10-04 06:24:29 - train: epoch 0057, iter [00650, 01251], lr: 0.000284, loss: 0.0926
2022-10-04 06:24:57 - train: epoch 0057, iter [00660, 01251], lr: 0.000284, loss: 0.0813
2022-10-04 06:25:25 - train: epoch 0057, iter [00670, 01251], lr: 0.000284, loss: 0.0890
2022-10-04 06:25:53 - train: epoch 0057, iter [00680, 01251], lr: 0.000284, loss: 0.0857
2022-10-04 06:26:21 - train: epoch 0057, iter [00690, 01251], lr: 0.000284, loss: 0.0849
2022-10-04 06:26:50 - train: epoch 0057, iter [00700, 01251], lr: 0.000284, loss: 0.0891
2022-10-04 06:27:18 - train: epoch 0057, iter [00710, 01251], lr: 0.000284, loss: 0.0896
2022-10-04 06:27:46 - train: epoch 0057, iter [00720, 01251], lr: 0.000284, loss: 0.0833
2022-10-04 06:28:15 - train: epoch 0057, iter [00730, 01251], lr: 0.000283, loss: 0.0869
2022-10-04 06:28:43 - train: epoch 0057, iter [00740, 01251], lr: 0.000283, loss: 0.0835
2022-10-04 06:29:11 - train: epoch 0057, iter [00750, 01251], lr: 0.000283, loss: 0.0823
2022-10-04 06:29:39 - train: epoch 0057, iter [00760, 01251], lr: 0.000283, loss: 0.0940
2022-10-04 06:30:07 - train: epoch 0057, iter [00770, 01251], lr: 0.000283, loss: 0.0941
2022-10-04 06:30:35 - train: epoch 0057, iter [00780, 01251], lr: 0.000283, loss: 0.0910
2022-10-04 06:31:03 - train: epoch 0057, iter [00790, 01251], lr: 0.000283, loss: 0.0771
2022-10-04 06:31:31 - train: epoch 0057, iter [00800, 01251], lr: 0.000283, loss: 0.0895
2022-10-04 06:31:59 - train: epoch 0057, iter [00810, 01251], lr: 0.000283, loss: 0.0871
2022-10-04 06:32:27 - train: epoch 0057, iter [00820, 01251], lr: 0.000283, loss: 0.0919
2022-10-04 06:32:55 - train: epoch 0057, iter [00830, 01251], lr: 0.000283, loss: 0.0842
2022-10-04 06:33:23 - train: epoch 0057, iter [00840, 01251], lr: 0.000283, loss: 0.0813
2022-10-04 06:33:51 - train: epoch 0057, iter [00850, 01251], lr: 0.000282, loss: 0.0922
2022-10-04 06:34:19 - train: epoch 0057, iter [00860, 01251], lr: 0.000282, loss: 0.0896
2022-10-04 06:34:47 - train: epoch 0057, iter [00870, 01251], lr: 0.000282, loss: 0.0888
2022-10-04 06:35:15 - train: epoch 0057, iter [00880, 01251], lr: 0.000282, loss: 0.0966
2022-10-04 06:35:43 - train: epoch 0057, iter [00890, 01251], lr: 0.000282, loss: 0.0888
2022-10-04 06:36:11 - train: epoch 0057, iter [00900, 01251], lr: 0.000282, loss: 0.0809
2022-10-04 06:36:40 - train: epoch 0057, iter [00910, 01251], lr: 0.000282, loss: 0.0893
2022-10-04 06:37:07 - train: epoch 0057, iter [00920, 01251], lr: 0.000282, loss: 0.0864
2022-10-04 06:37:36 - train: epoch 0057, iter [00930, 01251], lr: 0.000282, loss: 0.0921
2022-10-04 06:38:04 - train: epoch 0057, iter [00940, 01251], lr: 0.000282, loss: 0.0845
2022-10-04 06:38:32 - train: epoch 0057, iter [00950, 01251], lr: 0.000282, loss: 0.0869
2022-10-04 06:39:00 - train: epoch 0057, iter [00960, 01251], lr: 0.000282, loss: 0.0898
2022-10-04 06:39:28 - train: epoch 0057, iter [00970, 01251], lr: 0.000281, loss: 0.0923
2022-10-04 06:39:56 - train: epoch 0057, iter [00980, 01251], lr: 0.000281, loss: 0.0857
2022-10-04 06:40:24 - train: epoch 0057, iter [00990, 01251], lr: 0.000281, loss: 0.0885
2022-10-04 06:40:52 - train: epoch 0057, iter [01000, 01251], lr: 0.000281, loss: 0.0819
2022-10-04 06:41:20 - train: epoch 0057, iter [01010, 01251], lr: 0.000281, loss: 0.0902
2022-10-04 06:41:48 - train: epoch 0057, iter [01020, 01251], lr: 0.000281, loss: 0.0897
2022-10-04 06:42:16 - train: epoch 0057, iter [01030, 01251], lr: 0.000281, loss: 0.0877
2022-10-04 06:42:44 - train: epoch 0057, iter [01040, 01251], lr: 0.000281, loss: 0.0900
2022-10-04 06:43:13 - train: epoch 0057, iter [01050, 01251], lr: 0.000281, loss: 0.0792
2022-10-04 06:43:41 - train: epoch 0057, iter [01060, 01251], lr: 0.000281, loss: 0.0914
2022-10-04 06:44:09 - train: epoch 0057, iter [01070, 01251], lr: 0.000281, loss: 0.0844
2022-10-04 06:44:37 - train: epoch 0057, iter [01080, 01251], lr: 0.000281, loss: 0.0835
2022-10-04 06:45:05 - train: epoch 0057, iter [01090, 01251], lr: 0.000280, loss: 0.0880
2022-10-04 06:45:33 - train: epoch 0057, iter [01100, 01251], lr: 0.000280, loss: 0.0851
2022-10-04 06:46:01 - train: epoch 0057, iter [01110, 01251], lr: 0.000280, loss: 0.0895
2022-10-04 06:46:29 - train: epoch 0057, iter [01120, 01251], lr: 0.000280, loss: 0.0898
2022-10-04 06:46:57 - train: epoch 0057, iter [01130, 01251], lr: 0.000280, loss: 0.0811
2022-10-04 06:47:25 - train: epoch 0057, iter [01140, 01251], lr: 0.000280, loss: 0.0823
2022-10-04 06:47:53 - train: epoch 0057, iter [01150, 01251], lr: 0.000280, loss: 0.0871
2022-10-04 06:48:21 - train: epoch 0057, iter [01160, 01251], lr: 0.000280, loss: 0.0825
2022-10-04 06:48:49 - train: epoch 0057, iter [01170, 01251], lr: 0.000280, loss: 0.0801
2022-10-04 06:49:18 - train: epoch 0057, iter [01180, 01251], lr: 0.000280, loss: 0.0907
2022-10-04 06:49:46 - train: epoch 0057, iter [01190, 01251], lr: 0.000280, loss: 0.0871
2022-10-04 06:50:14 - train: epoch 0057, iter [01200, 01251], lr: 0.000279, loss: 0.0872
2022-10-04 06:50:42 - train: epoch 0057, iter [01210, 01251], lr: 0.000279, loss: 0.0906
2022-10-04 06:51:10 - train: epoch 0057, iter [01220, 01251], lr: 0.000279, loss: 0.0906
2022-10-04 06:51:38 - train: epoch 0057, iter [01230, 01251], lr: 0.000279, loss: 0.0842
2022-10-04 06:52:06 - train: epoch 0057, iter [01240, 01251], lr: 0.000279, loss: 0.0860
2022-10-04 06:52:33 - train: epoch 0057, iter [01250, 01251], lr: 0.000279, loss: 0.0886
2022-10-04 06:52:38 - train: epoch 057, train_loss: 0.0878
2022-10-04 06:52:39 - until epoch: 057, best_loss: 0.0878
2022-10-04 06:52:39 - epoch 058 lr: 0.000279
2022-10-04 06:53:15 - train: epoch 0058, iter [00010, 01251], lr: 0.000279, loss: 0.0831
2022-10-04 06:53:43 - train: epoch 0058, iter [00020, 01251], lr: 0.000279, loss: 0.0938
2022-10-04 06:54:11 - train: epoch 0058, iter [00030, 01251], lr: 0.000279, loss: 0.0913
2022-10-04 06:54:39 - train: epoch 0058, iter [00040, 01251], lr: 0.000279, loss: 0.0958
2022-10-04 06:55:08 - train: epoch 0058, iter [00050, 01251], lr: 0.000279, loss: 0.0920
2022-10-04 06:55:36 - train: epoch 0058, iter [00060, 01251], lr: 0.000279, loss: 0.0908
2022-10-04 06:56:04 - train: epoch 0058, iter [00070, 01251], lr: 0.000278, loss: 0.0873
2022-10-04 06:56:33 - train: epoch 0058, iter [00080, 01251], lr: 0.000278, loss: 0.0864
2022-10-04 06:57:01 - train: epoch 0058, iter [00090, 01251], lr: 0.000278, loss: 0.0917
2022-10-04 06:57:30 - train: epoch 0058, iter [00100, 01251], lr: 0.000278, loss: 0.0830
2022-10-04 06:57:58 - train: epoch 0058, iter [00110, 01251], lr: 0.000278, loss: 0.0886
2022-10-04 06:58:27 - train: epoch 0058, iter [00120, 01251], lr: 0.000278, loss: 0.0850
2022-10-04 06:58:55 - train: epoch 0058, iter [00130, 01251], lr: 0.000278, loss: 0.0890
2022-10-04 06:59:23 - train: epoch 0058, iter [00140, 01251], lr: 0.000278, loss: 0.0861
2022-10-04 06:59:52 - train: epoch 0058, iter [00150, 01251], lr: 0.000278, loss: 0.0846
2022-10-04 07:00:20 - train: epoch 0058, iter [00160, 01251], lr: 0.000278, loss: 0.0910
2022-10-04 07:00:48 - train: epoch 0058, iter [00170, 01251], lr: 0.000278, loss: 0.0905
2022-10-04 07:01:16 - train: epoch 0058, iter [00180, 01251], lr: 0.000278, loss: 0.0820
2022-10-04 07:01:45 - train: epoch 0058, iter [00190, 01251], lr: 0.000277, loss: 0.0810
2022-10-04 07:02:13 - train: epoch 0058, iter [00200, 01251], lr: 0.000277, loss: 0.0865
2022-10-04 07:02:42 - train: epoch 0058, iter [00210, 01251], lr: 0.000277, loss: 0.0922
2022-10-04 07:03:10 - train: epoch 0058, iter [00220, 01251], lr: 0.000277, loss: 0.0867
2022-10-04 07:03:38 - train: epoch 0058, iter [00230, 01251], lr: 0.000277, loss: 0.0861
2022-10-04 07:04:06 - train: epoch 0058, iter [00240, 01251], lr: 0.000277, loss: 0.0915
2022-10-04 07:04:34 - train: epoch 0058, iter [00250, 01251], lr: 0.000277, loss: 0.0921
2022-10-04 07:05:03 - train: epoch 0058, iter [00260, 01251], lr: 0.000277, loss: 0.0960
2022-10-04 07:05:31 - train: epoch 0058, iter [00270, 01251], lr: 0.000277, loss: 0.0948
2022-10-04 07:05:59 - train: epoch 0058, iter [00280, 01251], lr: 0.000277, loss: 0.0890
2022-10-04 07:06:27 - train: epoch 0058, iter [00290, 01251], lr: 0.000277, loss: 0.0851
2022-10-04 07:06:56 - train: epoch 0058, iter [00300, 01251], lr: 0.000277, loss: 0.0854
2022-10-04 07:07:24 - train: epoch 0058, iter [00310, 01251], lr: 0.000276, loss: 0.0844
2022-10-04 07:07:52 - train: epoch 0058, iter [00320, 01251], lr: 0.000276, loss: 0.0921
2022-10-04 07:08:20 - train: epoch 0058, iter [00330, 01251], lr: 0.000276, loss: 0.0822
2022-10-04 07:08:49 - train: epoch 0058, iter [00340, 01251], lr: 0.000276, loss: 0.0935
2022-10-04 07:09:17 - train: epoch 0058, iter [00350, 01251], lr: 0.000276, loss: 0.0875
2022-10-04 07:09:45 - train: epoch 0058, iter [00360, 01251], lr: 0.000276, loss: 0.0876
2022-10-04 07:10:14 - train: epoch 0058, iter [00370, 01251], lr: 0.000276, loss: 0.0899
2022-10-04 07:10:42 - train: epoch 0058, iter [00380, 01251], lr: 0.000276, loss: 0.0895
2022-10-04 07:11:10 - train: epoch 0058, iter [00390, 01251], lr: 0.000276, loss: 0.0812
2022-10-04 07:11:38 - train: epoch 0058, iter [00400, 01251], lr: 0.000276, loss: 0.0907
2022-10-04 07:12:07 - train: epoch 0058, iter [00410, 01251], lr: 0.000276, loss: 0.0856
2022-10-04 07:12:35 - train: epoch 0058, iter [00420, 01251], lr: 0.000276, loss: 0.0836
2022-10-04 07:13:03 - train: epoch 0058, iter [00430, 01251], lr: 0.000275, loss: 0.0910
2022-10-04 07:13:31 - train: epoch 0058, iter [00440, 01251], lr: 0.000275, loss: 0.0907
2022-10-04 07:13:59 - train: epoch 0058, iter [00450, 01251], lr: 0.000275, loss: 0.0843
2022-10-04 07:14:28 - train: epoch 0058, iter [00460, 01251], lr: 0.000275, loss: 0.0853
2022-10-04 07:14:56 - train: epoch 0058, iter [00470, 01251], lr: 0.000275, loss: 0.0813
2022-10-04 07:15:25 - train: epoch 0058, iter [00480, 01251], lr: 0.000275, loss: 0.0826
2022-10-04 07:15:53 - train: epoch 0058, iter [00490, 01251], lr: 0.000275, loss: 0.0861
2022-10-04 07:16:21 - train: epoch 0058, iter [00500, 01251], lr: 0.000275, loss: 0.0880
2022-10-04 07:16:50 - train: epoch 0058, iter [00510, 01251], lr: 0.000275, loss: 0.0853
2022-10-04 07:17:18 - train: epoch 0058, iter [00520, 01251], lr: 0.000275, loss: 0.0938
2022-10-04 07:17:46 - train: epoch 0058, iter [00530, 01251], lr: 0.000275, loss: 0.0832
2022-10-04 07:18:14 - train: epoch 0058, iter [00540, 01251], lr: 0.000275, loss: 0.0889
2022-10-04 07:18:42 - train: epoch 0058, iter [00550, 01251], lr: 0.000274, loss: 0.0858
2022-10-04 07:19:10 - train: epoch 0058, iter [00560, 01251], lr: 0.000274, loss: 0.0885
2022-10-04 07:19:38 - train: epoch 0058, iter [00570, 01251], lr: 0.000274, loss: 0.0963
2022-10-04 07:20:06 - train: epoch 0058, iter [00580, 01251], lr: 0.000274, loss: 0.0872
2022-10-04 07:20:34 - train: epoch 0058, iter [00590, 01251], lr: 0.000274, loss: 0.0866
2022-10-04 07:21:02 - train: epoch 0058, iter [00600, 01251], lr: 0.000274, loss: 0.0880
2022-10-04 07:21:30 - train: epoch 0058, iter [00610, 01251], lr: 0.000274, loss: 0.0859
2022-10-04 07:21:58 - train: epoch 0058, iter [00620, 01251], lr: 0.000274, loss: 0.0771
2022-10-04 07:22:26 - train: epoch 0058, iter [00630, 01251], lr: 0.000274, loss: 0.0891
2022-10-04 07:22:55 - train: epoch 0058, iter [00640, 01251], lr: 0.000274, loss: 0.0820
2022-10-04 07:23:23 - train: epoch 0058, iter [00650, 01251], lr: 0.000274, loss: 0.0915
2022-10-04 07:23:51 - train: epoch 0058, iter [00660, 01251], lr: 0.000274, loss: 0.0891
2022-10-04 07:24:19 - train: epoch 0058, iter [00670, 01251], lr: 0.000273, loss: 0.0875
2022-10-04 07:24:47 - train: epoch 0058, iter [00680, 01251], lr: 0.000273, loss: 0.0886
2022-10-04 07:25:15 - train: epoch 0058, iter [00690, 01251], lr: 0.000273, loss: 0.0877
2022-10-04 07:25:43 - train: epoch 0058, iter [00700, 01251], lr: 0.000273, loss: 0.0850
2022-10-04 07:26:11 - train: epoch 0058, iter [00710, 01251], lr: 0.000273, loss: 0.0885
2022-10-04 07:26:39 - train: epoch 0058, iter [00720, 01251], lr: 0.000273, loss: 0.0859
2022-10-04 07:27:07 - train: epoch 0058, iter [00730, 01251], lr: 0.000273, loss: 0.0871
2022-10-04 07:27:35 - train: epoch 0058, iter [00740, 01251], lr: 0.000273, loss: 0.0872
2022-10-04 07:28:04 - train: epoch 0058, iter [00750, 01251], lr: 0.000273, loss: 0.0887
2022-10-04 07:28:32 - train: epoch 0058, iter [00760, 01251], lr: 0.000273, loss: 0.0826
2022-10-04 07:29:00 - train: epoch 0058, iter [00770, 01251], lr: 0.000273, loss: 0.0834
2022-10-04 07:29:28 - train: epoch 0058, iter [00780, 01251], lr: 0.000273, loss: 0.0824
2022-10-04 07:29:56 - train: epoch 0058, iter [00790, 01251], lr: 0.000272, loss: 0.0877
2022-10-04 07:30:24 - train: epoch 0058, iter [00800, 01251], lr: 0.000272, loss: 0.0884
2022-10-04 07:30:52 - train: epoch 0058, iter [00810, 01251], lr: 0.000272, loss: 0.0842
2022-10-04 07:31:21 - train: epoch 0058, iter [00820, 01251], lr: 0.000272, loss: 0.0847
2022-10-04 07:31:49 - train: epoch 0058, iter [00830, 01251], lr: 0.000272, loss: 0.0801
2022-10-04 07:32:17 - train: epoch 0058, iter [00840, 01251], lr: 0.000272, loss: 0.0828
2022-10-04 07:32:46 - train: epoch 0058, iter [00850, 01251], lr: 0.000272, loss: 0.0848
2022-10-04 07:33:14 - train: epoch 0058, iter [00860, 01251], lr: 0.000272, loss: 0.0848
2022-10-04 07:33:42 - train: epoch 0058, iter [00870, 01251], lr: 0.000272, loss: 0.0895
2022-10-04 07:34:10 - train: epoch 0058, iter [00880, 01251], lr: 0.000272, loss: 0.0851
2022-10-04 07:34:39 - train: epoch 0058, iter [00890, 01251], lr: 0.000272, loss: 0.0896
2022-10-04 07:35:07 - train: epoch 0058, iter [00900, 01251], lr: 0.000272, loss: 0.0843
2022-10-04 07:35:35 - train: epoch 0058, iter [00910, 01251], lr: 0.000271, loss: 0.0845
2022-10-04 07:36:03 - train: epoch 0058, iter [00920, 01251], lr: 0.000271, loss: 0.0933
2022-10-04 07:36:31 - train: epoch 0058, iter [00930, 01251], lr: 0.000271, loss: 0.0881
2022-10-04 07:36:59 - train: epoch 0058, iter [00940, 01251], lr: 0.000271, loss: 0.0862
2022-10-04 07:37:28 - train: epoch 0058, iter [00950, 01251], lr: 0.000271, loss: 0.0823
2022-10-04 07:37:56 - train: epoch 0058, iter [00960, 01251], lr: 0.000271, loss: 0.0912
2022-10-04 07:38:24 - train: epoch 0058, iter [00970, 01251], lr: 0.000271, loss: 0.0970
2022-10-04 07:38:52 - train: epoch 0058, iter [00980, 01251], lr: 0.000271, loss: 0.0892
2022-10-04 07:39:20 - train: epoch 0058, iter [00990, 01251], lr: 0.000271, loss: 0.0815
2022-10-04 07:39:48 - train: epoch 0058, iter [01000, 01251], lr: 0.000271, loss: 0.0914
2022-10-04 07:40:17 - train: epoch 0058, iter [01010, 01251], lr: 0.000271, loss: 0.0912
2022-10-04 07:40:45 - train: epoch 0058, iter [01020, 01251], lr: 0.000271, loss: 0.0933
2022-10-04 07:41:13 - train: epoch 0058, iter [01030, 01251], lr: 0.000270, loss: 0.0853
2022-10-04 07:41:41 - train: epoch 0058, iter [01040, 01251], lr: 0.000270, loss: 0.0847
2022-10-04 07:42:09 - train: epoch 0058, iter [01050, 01251], lr: 0.000270, loss: 0.0877
2022-10-04 07:42:37 - train: epoch 0058, iter [01060, 01251], lr: 0.000270, loss: 0.0861
2022-10-04 07:43:05 - train: epoch 0058, iter [01070, 01251], lr: 0.000270, loss: 0.0810
2022-10-04 07:43:33 - train: epoch 0058, iter [01080, 01251], lr: 0.000270, loss: 0.0904
2022-10-04 07:44:01 - train: epoch 0058, iter [01090, 01251], lr: 0.000270, loss: 0.0867
2022-10-04 07:44:29 - train: epoch 0058, iter [01100, 01251], lr: 0.000270, loss: 0.0865
2022-10-04 07:44:58 - train: epoch 0058, iter [01110, 01251], lr: 0.000270, loss: 0.0873
2022-10-04 07:45:26 - train: epoch 0058, iter [01120, 01251], lr: 0.000270, loss: 0.0886
2022-10-04 07:45:54 - train: epoch 0058, iter [01130, 01251], lr: 0.000270, loss: 0.0889
2022-10-04 07:46:22 - train: epoch 0058, iter [01140, 01251], lr: 0.000270, loss: 0.0836
2022-10-04 07:46:51 - train: epoch 0058, iter [01150, 01251], lr: 0.000269, loss: 0.0861
2022-10-04 07:47:19 - train: epoch 0058, iter [01160, 01251], lr: 0.000269, loss: 0.0856
2022-10-04 07:47:47 - train: epoch 0058, iter [01170, 01251], lr: 0.000269, loss: 0.0894
2022-10-04 07:48:15 - train: epoch 0058, iter [01180, 01251], lr: 0.000269, loss: 0.0897
2022-10-04 07:48:44 - train: epoch 0058, iter [01190, 01251], lr: 0.000269, loss: 0.0852
2022-10-04 07:49:12 - train: epoch 0058, iter [01200, 01251], lr: 0.000269, loss: 0.0834
2022-10-04 07:49:40 - train: epoch 0058, iter [01210, 01251], lr: 0.000269, loss: 0.0893
2022-10-04 07:50:08 - train: epoch 0058, iter [01220, 01251], lr: 0.000269, loss: 0.0823
2022-10-04 07:50:37 - train: epoch 0058, iter [01230, 01251], lr: 0.000269, loss: 0.0902
2022-10-04 07:51:05 - train: epoch 0058, iter [01240, 01251], lr: 0.000269, loss: 0.0850
2022-10-04 07:51:33 - train: epoch 0058, iter [01250, 01251], lr: 0.000269, loss: 0.0859
2022-10-04 07:51:37 - train: epoch 058, train_loss: 0.0876
2022-10-04 07:51:39 - until epoch: 058, best_loss: 0.0876
2022-10-04 07:51:39 - epoch 059 lr: 0.000269
2022-10-04 07:52:14 - train: epoch 0059, iter [00010, 01251], lr: 0.000269, loss: 0.0858
2022-10-04 07:52:42 - train: epoch 0059, iter [00020, 01251], lr: 0.000268, loss: 0.0828
2022-10-04 07:53:11 - train: epoch 0059, iter [00030, 01251], lr: 0.000268, loss: 0.0760
2022-10-04 07:53:39 - train: epoch 0059, iter [00040, 01251], lr: 0.000268, loss: 0.0824
2022-10-04 07:54:07 - train: epoch 0059, iter [00050, 01251], lr: 0.000268, loss: 0.0801
2022-10-04 07:54:36 - train: epoch 0059, iter [00060, 01251], lr: 0.000268, loss: 0.0931
2022-10-04 07:55:04 - train: epoch 0059, iter [00070, 01251], lr: 0.000268, loss: 0.0895
2022-10-04 07:55:32 - train: epoch 0059, iter [00080, 01251], lr: 0.000268, loss: 0.0829
2022-10-04 07:56:01 - train: epoch 0059, iter [00090, 01251], lr: 0.000268, loss: 0.0892
2022-10-04 07:56:29 - train: epoch 0059, iter [00100, 01251], lr: 0.000268, loss: 0.0828
2022-10-04 07:56:57 - train: epoch 0059, iter [00110, 01251], lr: 0.000268, loss: 0.0846
2022-10-04 07:57:26 - train: epoch 0059, iter [00120, 01251], lr: 0.000268, loss: 0.0855
2022-10-04 07:57:54 - train: epoch 0059, iter [00130, 01251], lr: 0.000268, loss: 0.0860
2022-10-04 07:58:22 - train: epoch 0059, iter [00140, 01251], lr: 0.000267, loss: 0.0888
2022-10-04 07:58:50 - train: epoch 0059, iter [00150, 01251], lr: 0.000267, loss: 0.0858
2022-10-04 07:59:18 - train: epoch 0059, iter [00160, 01251], lr: 0.000267, loss: 0.0949
2022-10-04 07:59:47 - train: epoch 0059, iter [00170, 01251], lr: 0.000267, loss: 0.0961
2022-10-04 08:00:15 - train: epoch 0059, iter [00180, 01251], lr: 0.000267, loss: 0.0849
2022-10-04 08:00:43 - train: epoch 0059, iter [00190, 01251], lr: 0.000267, loss: 0.0897
2022-10-04 08:01:11 - train: epoch 0059, iter [00200, 01251], lr: 0.000267, loss: 0.0913
2022-10-04 08:01:39 - train: epoch 0059, iter [00210, 01251], lr: 0.000267, loss: 0.0862
2022-10-04 08:02:08 - train: epoch 0059, iter [00220, 01251], lr: 0.000267, loss: 0.0888
2022-10-04 08:02:36 - train: epoch 0059, iter [00230, 01251], lr: 0.000267, loss: 0.0918
2022-10-04 08:03:04 - train: epoch 0059, iter [00240, 01251], lr: 0.000267, loss: 0.0945
2022-10-04 08:03:32 - train: epoch 0059, iter [00250, 01251], lr: 0.000267, loss: 0.0868
2022-10-04 08:04:00 - train: epoch 0059, iter [00260, 01251], lr: 0.000266, loss: 0.0839
2022-10-04 08:04:29 - train: epoch 0059, iter [00270, 01251], lr: 0.000266, loss: 0.0837
2022-10-04 08:04:57 - train: epoch 0059, iter [00280, 01251], lr: 0.000266, loss: 0.0866
2022-10-04 08:05:25 - train: epoch 0059, iter [00290, 01251], lr: 0.000266, loss: 0.0821
2022-10-04 08:05:53 - train: epoch 0059, iter [00300, 01251], lr: 0.000266, loss: 0.0891
2022-10-04 08:06:22 - train: epoch 0059, iter [00310, 01251], lr: 0.000266, loss: 0.0936
2022-10-04 08:06:50 - train: epoch 0059, iter [00320, 01251], lr: 0.000266, loss: 0.0816
2022-10-04 08:07:18 - train: epoch 0059, iter [00330, 01251], lr: 0.000266, loss: 0.0869
2022-10-04 08:07:46 - train: epoch 0059, iter [00340, 01251], lr: 0.000266, loss: 0.0768
2022-10-04 08:08:15 - train: epoch 0059, iter [00350, 01251], lr: 0.000266, loss: 0.0867
2022-10-04 08:08:43 - train: epoch 0059, iter [00360, 01251], lr: 0.000266, loss: 0.0882
2022-10-04 08:09:11 - train: epoch 0059, iter [00370, 01251], lr: 0.000266, loss: 0.0899
2022-10-04 08:09:40 - train: epoch 0059, iter [00380, 01251], lr: 0.000265, loss: 0.0948
2022-10-04 08:10:08 - train: epoch 0059, iter [00390, 01251], lr: 0.000265, loss: 0.0924
2022-10-04 08:10:36 - train: epoch 0059, iter [00400, 01251], lr: 0.000265, loss: 0.0841
2022-10-04 08:11:04 - train: epoch 0059, iter [00410, 01251], lr: 0.000265, loss: 0.0915
2022-10-04 08:11:32 - train: epoch 0059, iter [00420, 01251], lr: 0.000265, loss: 0.0822
2022-10-04 08:12:00 - train: epoch 0059, iter [00430, 01251], lr: 0.000265, loss: 0.0904
2022-10-04 08:12:28 - train: epoch 0059, iter [00440, 01251], lr: 0.000265, loss: 0.0844
2022-10-04 08:12:57 - train: epoch 0059, iter [00450, 01251], lr: 0.000265, loss: 0.0935
2022-10-04 08:13:25 - train: epoch 0059, iter [00460, 01251], lr: 0.000265, loss: 0.0881
2022-10-04 08:13:53 - train: epoch 0059, iter [00470, 01251], lr: 0.000265, loss: 0.0919
2022-10-04 08:14:21 - train: epoch 0059, iter [00480, 01251], lr: 0.000265, loss: 0.0935
2022-10-04 08:14:49 - train: epoch 0059, iter [00490, 01251], lr: 0.000265, loss: 0.0839
2022-10-04 08:15:17 - train: epoch 0059, iter [00500, 01251], lr: 0.000264, loss: 0.0936
2022-10-04 08:15:45 - train: epoch 0059, iter [00510, 01251], lr: 0.000264, loss: 0.0878
2022-10-04 08:16:13 - train: epoch 0059, iter [00520, 01251], lr: 0.000264, loss: 0.0863
2022-10-04 08:16:42 - train: epoch 0059, iter [00530, 01251], lr: 0.000264, loss: 0.0848
2022-10-04 08:17:10 - train: epoch 0059, iter [00540, 01251], lr: 0.000264, loss: 0.0945
2022-10-04 08:17:38 - train: epoch 0059, iter [00550, 01251], lr: 0.000264, loss: 0.0875
2022-10-04 08:18:06 - train: epoch 0059, iter [00560, 01251], lr: 0.000264, loss: 0.0877
2022-10-04 08:18:34 - train: epoch 0059, iter [00570, 01251], lr: 0.000264, loss: 0.0831
2022-10-04 08:19:02 - train: epoch 0059, iter [00580, 01251], lr: 0.000264, loss: 0.0856
2022-10-04 08:19:31 - train: epoch 0059, iter [00590, 01251], lr: 0.000264, loss: 0.0906
2022-10-04 08:19:59 - train: epoch 0059, iter [00600, 01251], lr: 0.000264, loss: 0.0855
2022-10-04 08:20:27 - train: epoch 0059, iter [00610, 01251], lr: 0.000264, loss: 0.0794
2022-10-04 08:20:55 - train: epoch 0059, iter [00620, 01251], lr: 0.000263, loss: 0.0862
2022-10-04 08:21:23 - train: epoch 0059, iter [00630, 01251], lr: 0.000263, loss: 0.0864
2022-10-04 08:21:52 - train: epoch 0059, iter [00640, 01251], lr: 0.000263, loss: 0.0915
2022-10-04 08:22:20 - train: epoch 0059, iter [00650, 01251], lr: 0.000263, loss: 0.0923
2022-10-04 08:22:48 - train: epoch 0059, iter [00660, 01251], lr: 0.000263, loss: 0.0871
2022-10-04 08:23:16 - train: epoch 0059, iter [00670, 01251], lr: 0.000263, loss: 0.0875
2022-10-04 08:23:45 - train: epoch 0059, iter [00680, 01251], lr: 0.000263, loss: 0.0822
2022-10-04 08:24:13 - train: epoch 0059, iter [00690, 01251], lr: 0.000263, loss: 0.0908
2022-10-04 08:24:41 - train: epoch 0059, iter [00700, 01251], lr: 0.000263, loss: 0.0848
2022-10-04 08:25:09 - train: epoch 0059, iter [00710, 01251], lr: 0.000263, loss: 0.0920
2022-10-04 08:25:38 - train: epoch 0059, iter [00720, 01251], lr: 0.000263, loss: 0.0927
2022-10-04 08:26:06 - train: epoch 0059, iter [00730, 01251], lr: 0.000263, loss: 0.0883
2022-10-04 08:26:34 - train: epoch 0059, iter [00740, 01251], lr: 0.000262, loss: 0.0862
2022-10-04 08:27:02 - train: epoch 0059, iter [00750, 01251], lr: 0.000262, loss: 0.0949
2022-10-04 08:27:31 - train: epoch 0059, iter [00760, 01251], lr: 0.000262, loss: 0.0930
2022-10-04 08:27:59 - train: epoch 0059, iter [00770, 01251], lr: 0.000262, loss: 0.0900
2022-10-04 08:28:27 - train: epoch 0059, iter [00780, 01251], lr: 0.000262, loss: 0.0877
2022-10-04 08:28:55 - train: epoch 0059, iter [00790, 01251], lr: 0.000262, loss: 0.0859
2022-10-04 08:29:24 - train: epoch 0059, iter [00800, 01251], lr: 0.000262, loss: 0.0870
2022-10-04 08:29:52 - train: epoch 0059, iter [00810, 01251], lr: 0.000262, loss: 0.0787
2022-10-04 08:30:20 - train: epoch 0059, iter [00820, 01251], lr: 0.000262, loss: 0.0831
2022-10-04 08:30:48 - train: epoch 0059, iter [00830, 01251], lr: 0.000262, loss: 0.0914
2022-10-04 08:31:17 - train: epoch 0059, iter [00840, 01251], lr: 0.000262, loss: 0.0881
2022-10-04 08:31:45 - train: epoch 0059, iter [00850, 01251], lr: 0.000262, loss: 0.0884
2022-10-04 08:32:13 - train: epoch 0059, iter [00860, 01251], lr: 0.000261, loss: 0.0938
2022-10-04 08:32:41 - train: epoch 0059, iter [00870, 01251], lr: 0.000261, loss: 0.0913
2022-10-04 08:33:09 - train: epoch 0059, iter [00880, 01251], lr: 0.000261, loss: 0.0895
2022-10-04 08:33:37 - train: epoch 0059, iter [00890, 01251], lr: 0.000261, loss: 0.0862
2022-10-04 08:34:05 - train: epoch 0059, iter [00900, 01251], lr: 0.000261, loss: 0.0815
2022-10-04 08:34:34 - train: epoch 0059, iter [00910, 01251], lr: 0.000261, loss: 0.0872
2022-10-04 08:35:02 - train: epoch 0059, iter [00920, 01251], lr: 0.000261, loss: 0.0879
2022-10-04 08:35:30 - train: epoch 0059, iter [00930, 01251], lr: 0.000261, loss: 0.0851
2022-10-04 08:35:58 - train: epoch 0059, iter [00940, 01251], lr: 0.000261, loss: 0.0868
2022-10-04 08:36:26 - train: epoch 0059, iter [00950, 01251], lr: 0.000261, loss: 0.0799
2022-10-04 08:36:55 - train: epoch 0059, iter [00960, 01251], lr: 0.000261, loss: 0.0874
2022-10-04 08:37:23 - train: epoch 0059, iter [00970, 01251], lr: 0.000261, loss: 0.0878
2022-10-04 08:37:51 - train: epoch 0059, iter [00980, 01251], lr: 0.000260, loss: 0.0801
2022-10-04 08:38:19 - train: epoch 0059, iter [00990, 01251], lr: 0.000260, loss: 0.0902
2022-10-04 08:38:48 - train: epoch 0059, iter [01000, 01251], lr: 0.000260, loss: 0.0927
2022-10-04 08:39:16 - train: epoch 0059, iter [01010, 01251], lr: 0.000260, loss: 0.0941
2022-10-04 08:39:44 - train: epoch 0059, iter [01020, 01251], lr: 0.000260, loss: 0.0889
2022-10-04 08:40:12 - train: epoch 0059, iter [01030, 01251], lr: 0.000260, loss: 0.0821
2022-10-04 08:40:41 - train: epoch 0059, iter [01040, 01251], lr: 0.000260, loss: 0.1010
2022-10-04 08:41:09 - train: epoch 0059, iter [01050, 01251], lr: 0.000260, loss: 0.0882
2022-10-04 08:41:37 - train: epoch 0059, iter [01060, 01251], lr: 0.000260, loss: 0.0874
2022-10-04 08:42:05 - train: epoch 0059, iter [01070, 01251], lr: 0.000260, loss: 0.0806
2022-10-04 08:42:33 - train: epoch 0059, iter [01080, 01251], lr: 0.000260, loss: 0.0830
2022-10-04 08:43:02 - train: epoch 0059, iter [01090, 01251], lr: 0.000260, loss: 0.0907
2022-10-04 08:43:30 - train: epoch 0059, iter [01100, 01251], lr: 0.000260, loss: 0.0907
2022-10-04 08:43:58 - train: epoch 0059, iter [01110, 01251], lr: 0.000259, loss: 0.0895
2022-10-04 08:44:26 - train: epoch 0059, iter [01120, 01251], lr: 0.000259, loss: 0.0906
2022-10-04 08:44:54 - train: epoch 0059, iter [01130, 01251], lr: 0.000259, loss: 0.0913
2022-10-04 08:45:22 - train: epoch 0059, iter [01140, 01251], lr: 0.000259, loss: 0.0815
2022-10-04 08:45:51 - train: epoch 0059, iter [01150, 01251], lr: 0.000259, loss: 0.0887
2022-10-04 08:46:19 - train: epoch 0059, iter [01160, 01251], lr: 0.000259, loss: 0.0874
2022-10-04 08:46:47 - train: epoch 0059, iter [01170, 01251], lr: 0.000259, loss: 0.0881
2022-10-04 08:47:15 - train: epoch 0059, iter [01180, 01251], lr: 0.000259, loss: 0.0891
2022-10-04 08:47:43 - train: epoch 0059, iter [01190, 01251], lr: 0.000259, loss: 0.0787
2022-10-04 08:48:11 - train: epoch 0059, iter [01200, 01251], lr: 0.000259, loss: 0.0844
2022-10-04 08:48:39 - train: epoch 0059, iter [01210, 01251], lr: 0.000259, loss: 0.0863
2022-10-04 08:49:08 - train: epoch 0059, iter [01220, 01251], lr: 0.000259, loss: 0.0939
2022-10-04 08:49:36 - train: epoch 0059, iter [01230, 01251], lr: 0.000258, loss: 0.0892
2022-10-04 08:50:04 - train: epoch 0059, iter [01240, 01251], lr: 0.000258, loss: 0.0863
2022-10-04 08:50:32 - train: epoch 0059, iter [01250, 01251], lr: 0.000258, loss: 0.0814
2022-10-04 08:50:37 - train: epoch 059, train_loss: 0.0875
2022-10-04 08:50:38 - until epoch: 059, best_loss: 0.0875
2022-10-04 08:50:38 - epoch 060 lr: 0.000258
2022-10-04 08:51:13 - train: epoch 0060, iter [00010, 01251], lr: 0.000258, loss: 0.0867
2022-10-04 08:51:41 - train: epoch 0060, iter [00020, 01251], lr: 0.000258, loss: 0.0873
2022-10-04 08:52:09 - train: epoch 0060, iter [00030, 01251], lr: 0.000258, loss: 0.0876
2022-10-04 08:52:37 - train: epoch 0060, iter [00040, 01251], lr: 0.000258, loss: 0.0852
2022-10-04 08:53:06 - train: epoch 0060, iter [00050, 01251], lr: 0.000258, loss: 0.0863
2022-10-04 08:53:34 - train: epoch 0060, iter [00060, 01251], lr: 0.000258, loss: 0.0948
2022-10-04 08:54:02 - train: epoch 0060, iter [00070, 01251], lr: 0.000258, loss: 0.0888
2022-10-04 08:54:31 - train: epoch 0060, iter [00080, 01251], lr: 0.000258, loss: 0.0928
2022-10-04 08:54:59 - train: epoch 0060, iter [00090, 01251], lr: 0.000258, loss: 0.0844
2022-10-04 08:55:27 - train: epoch 0060, iter [00100, 01251], lr: 0.000257, loss: 0.0986
2022-10-04 08:55:55 - train: epoch 0060, iter [00110, 01251], lr: 0.000257, loss: 0.0864
2022-10-04 08:56:23 - train: epoch 0060, iter [00120, 01251], lr: 0.000257, loss: 0.0859
2022-10-04 08:56:52 - train: epoch 0060, iter [00130, 01251], lr: 0.000257, loss: 0.0918
2022-10-04 08:57:20 - train: epoch 0060, iter [00140, 01251], lr: 0.000257, loss: 0.0874
2022-10-04 08:57:48 - train: epoch 0060, iter [00150, 01251], lr: 0.000257, loss: 0.0888
2022-10-04 08:58:16 - train: epoch 0060, iter [00160, 01251], lr: 0.000257, loss: 0.0857
2022-10-04 08:58:44 - train: epoch 0060, iter [00170, 01251], lr: 0.000257, loss: 0.0845
2022-10-04 08:59:12 - train: epoch 0060, iter [00180, 01251], lr: 0.000257, loss: 0.0819
2022-10-04 08:59:41 - train: epoch 0060, iter [00190, 01251], lr: 0.000257, loss: 0.0820
2022-10-04 09:00:09 - train: epoch 0060, iter [00200, 01251], lr: 0.000257, loss: 0.0827
2022-10-04 09:00:37 - train: epoch 0060, iter [00210, 01251], lr: 0.000257, loss: 0.0809
2022-10-04 09:01:05 - train: epoch 0060, iter [00220, 01251], lr: 0.000256, loss: 0.0910
2022-10-04 09:01:33 - train: epoch 0060, iter [00230, 01251], lr: 0.000256, loss: 0.0844
2022-10-04 09:02:01 - train: epoch 0060, iter [00240, 01251], lr: 0.000256, loss: 0.0825
2022-10-04 09:02:29 - train: epoch 0060, iter [00250, 01251], lr: 0.000256, loss: 0.0862
2022-10-04 09:02:57 - train: epoch 0060, iter [00260, 01251], lr: 0.000256, loss: 0.0939
2022-10-04 09:03:25 - train: epoch 0060, iter [00270, 01251], lr: 0.000256, loss: 0.0870
2022-10-04 09:03:53 - train: epoch 0060, iter [00280, 01251], lr: 0.000256, loss: 0.0806
2022-10-04 09:04:21 - train: epoch 0060, iter [00290, 01251], lr: 0.000256, loss: 0.0837
2022-10-04 09:04:49 - train: epoch 0060, iter [00300, 01251], lr: 0.000256, loss: 0.0890
2022-10-04 09:05:17 - train: epoch 0060, iter [00310, 01251], lr: 0.000256, loss: 0.0945
2022-10-04 09:05:45 - train: epoch 0060, iter [00320, 01251], lr: 0.000256, loss: 0.0799
2022-10-04 09:06:14 - train: epoch 0060, iter [00330, 01251], lr: 0.000256, loss: 0.0869
2022-10-04 09:06:42 - train: epoch 0060, iter [00340, 01251], lr: 0.000255, loss: 0.0863
2022-10-04 09:07:10 - train: epoch 0060, iter [00350, 01251], lr: 0.000255, loss: 0.0925
2022-10-04 09:07:38 - train: epoch 0060, iter [00360, 01251], lr: 0.000255, loss: 0.0943
2022-10-04 09:08:06 - train: epoch 0060, iter [00370, 01251], lr: 0.000255, loss: 0.0823
2022-10-04 09:08:34 - train: epoch 0060, iter [00380, 01251], lr: 0.000255, loss: 0.0830
2022-10-04 09:09:02 - train: epoch 0060, iter [00390, 01251], lr: 0.000255, loss: 0.0897
2022-10-04 09:09:30 - train: epoch 0060, iter [00400, 01251], lr: 0.000255, loss: 0.0905
2022-10-04 09:09:58 - train: epoch 0060, iter [00410, 01251], lr: 0.000255, loss: 0.0871
2022-10-04 09:10:26 - train: epoch 0060, iter [00420, 01251], lr: 0.000255, loss: 0.0918
2022-10-04 09:10:54 - train: epoch 0060, iter [00430, 01251], lr: 0.000255, loss: 0.0907
2022-10-04 09:11:22 - train: epoch 0060, iter [00440, 01251], lr: 0.000255, loss: 0.0891
2022-10-04 09:11:50 - train: epoch 0060, iter [00450, 01251], lr: 0.000255, loss: 0.0817
2022-10-04 09:12:18 - train: epoch 0060, iter [00460, 01251], lr: 0.000254, loss: 0.0822
2022-10-04 09:12:47 - train: epoch 0060, iter [00470, 01251], lr: 0.000254, loss: 0.0844
2022-10-04 09:13:15 - train: epoch 0060, iter [00480, 01251], lr: 0.000254, loss: 0.0918
2022-10-04 09:13:43 - train: epoch 0060, iter [00490, 01251], lr: 0.000254, loss: 0.0885
2022-10-04 09:14:11 - train: epoch 0060, iter [00500, 01251], lr: 0.000254, loss: 0.0865
2022-10-04 09:14:39 - train: epoch 0060, iter [00510, 01251], lr: 0.000254, loss: 0.0934
2022-10-04 09:15:07 - train: epoch 0060, iter [00520, 01251], lr: 0.000254, loss: 0.0886
2022-10-04 09:15:35 - train: epoch 0060, iter [00530, 01251], lr: 0.000254, loss: 0.0920
2022-10-04 09:16:03 - train: epoch 0060, iter [00540, 01251], lr: 0.000254, loss: 0.0897
2022-10-04 09:16:31 - train: epoch 0060, iter [00550, 01251], lr: 0.000254, loss: 0.0891
2022-10-04 09:16:59 - train: epoch 0060, iter [00560, 01251], lr: 0.000254, loss: 0.0840
2022-10-04 09:17:27 - train: epoch 0060, iter [00570, 01251], lr: 0.000254, loss: 0.0816
2022-10-04 09:17:55 - train: epoch 0060, iter [00580, 01251], lr: 0.000253, loss: 0.0847
2022-10-04 09:18:23 - train: epoch 0060, iter [00590, 01251], lr: 0.000253, loss: 0.0865
2022-10-04 09:18:51 - train: epoch 0060, iter [00600, 01251], lr: 0.000253, loss: 0.0843
2022-10-04 09:19:19 - train: epoch 0060, iter [00610, 01251], lr: 0.000253, loss: 0.0936
2022-10-04 09:19:47 - train: epoch 0060, iter [00620, 01251], lr: 0.000253, loss: 0.0845
2022-10-04 09:20:15 - train: epoch 0060, iter [00630, 01251], lr: 0.000253, loss: 0.0848
2022-10-04 09:20:43 - train: epoch 0060, iter [00640, 01251], lr: 0.000253, loss: 0.0928
2022-10-04 09:21:11 - train: epoch 0060, iter [00650, 01251], lr: 0.000253, loss: 0.0817
2022-10-04 09:21:39 - train: epoch 0060, iter [00660, 01251], lr: 0.000253, loss: 0.0912
2022-10-04 09:22:08 - train: epoch 0060, iter [00670, 01251], lr: 0.000253, loss: 0.0884
2022-10-04 09:22:36 - train: epoch 0060, iter [00680, 01251], lr: 0.000253, loss: 0.0911
2022-10-04 09:23:04 - train: epoch 0060, iter [00690, 01251], lr: 0.000253, loss: 0.0918
2022-10-04 09:23:32 - train: epoch 0060, iter [00700, 01251], lr: 0.000252, loss: 0.0829
2022-10-04 09:24:01 - train: epoch 0060, iter [00710, 01251], lr: 0.000252, loss: 0.0870
2022-10-04 09:24:29 - train: epoch 0060, iter [00720, 01251], lr: 0.000252, loss: 0.0867
2022-10-04 09:24:57 - train: epoch 0060, iter [00730, 01251], lr: 0.000252, loss: 0.0857
2022-10-04 09:25:25 - train: epoch 0060, iter [00740, 01251], lr: 0.000252, loss: 0.0880
2022-10-04 09:25:54 - train: epoch 0060, iter [00750, 01251], lr: 0.000252, loss: 0.0862
2022-10-04 09:26:22 - train: epoch 0060, iter [00760, 01251], lr: 0.000252, loss: 0.0957
2022-10-04 09:26:50 - train: epoch 0060, iter [00770, 01251], lr: 0.000252, loss: 0.0907
2022-10-04 09:27:18 - train: epoch 0060, iter [00780, 01251], lr: 0.000252, loss: 0.0793
2022-10-04 09:27:47 - train: epoch 0060, iter [00790, 01251], lr: 0.000252, loss: 0.0873
2022-10-04 09:28:15 - train: epoch 0060, iter [00800, 01251], lr: 0.000252, loss: 0.0890
2022-10-04 09:28:43 - train: epoch 0060, iter [00810, 01251], lr: 0.000252, loss: 0.0959
2022-10-04 09:29:11 - train: epoch 0060, iter [00820, 01251], lr: 0.000251, loss: 0.0835
2022-10-04 09:29:39 - train: epoch 0060, iter [00830, 01251], lr: 0.000251, loss: 0.0866
2022-10-04 09:30:07 - train: epoch 0060, iter [00840, 01251], lr: 0.000251, loss: 0.0782
2022-10-04 09:30:35 - train: epoch 0060, iter [00850, 01251], lr: 0.000251, loss: 0.0860
2022-10-04 09:31:04 - train: epoch 0060, iter [00860, 01251], lr: 0.000251, loss: 0.0856
2022-10-04 09:31:32 - train: epoch 0060, iter [00870, 01251], lr: 0.000251, loss: 0.0888
2022-10-04 09:32:00 - train: epoch 0060, iter [00880, 01251], lr: 0.000251, loss: 0.0901
2022-10-04 09:32:28 - train: epoch 0060, iter [00890, 01251], lr: 0.000251, loss: 0.0881
2022-10-04 09:32:56 - train: epoch 0060, iter [00900, 01251], lr: 0.000251, loss: 0.0828
2022-10-04 09:33:24 - train: epoch 0060, iter [00910, 01251], lr: 0.000251, loss: 0.0948
2022-10-04 09:33:52 - train: epoch 0060, iter [00920, 01251], lr: 0.000251, loss: 0.0868
2022-10-04 09:34:20 - train: epoch 0060, iter [00930, 01251], lr: 0.000251, loss: 0.0880
2022-10-04 09:34:48 - train: epoch 0060, iter [00940, 01251], lr: 0.000250, loss: 0.0859
2022-10-04 09:35:16 - train: epoch 0060, iter [00950, 01251], lr: 0.000250, loss: 0.0866
2022-10-04 09:35:44 - train: epoch 0060, iter [00960, 01251], lr: 0.000250, loss: 0.0850
2022-10-04 09:36:12 - train: epoch 0060, iter [00970, 01251], lr: 0.000250, loss: 0.0820
2022-10-04 09:36:40 - train: epoch 0060, iter [00980, 01251], lr: 0.000250, loss: 0.0915
2022-10-04 09:37:09 - train: epoch 0060, iter [00990, 01251], lr: 0.000250, loss: 0.0883
2022-10-04 09:37:37 - train: epoch 0060, iter [01000, 01251], lr: 0.000250, loss: 0.0909
2022-10-04 09:38:05 - train: epoch 0060, iter [01010, 01251], lr: 0.000250, loss: 0.0866
2022-10-04 09:38:33 - train: epoch 0060, iter [01020, 01251], lr: 0.000250, loss: 0.0861
2022-10-04 09:39:02 - train: epoch 0060, iter [01030, 01251], lr: 0.000250, loss: 0.0851
2022-10-04 09:39:30 - train: epoch 0060, iter [01040, 01251], lr: 0.000250, loss: 0.0874
2022-10-04 09:39:58 - train: epoch 0060, iter [01050, 01251], lr: 0.000250, loss: 0.0811
2022-10-04 09:40:26 - train: epoch 0060, iter [01060, 01251], lr: 0.000249, loss: 0.0829
2022-10-04 09:40:54 - train: epoch 0060, iter [01070, 01251], lr: 0.000249, loss: 0.0937
2022-10-04 09:41:22 - train: epoch 0060, iter [01080, 01251], lr: 0.000249, loss: 0.0890
2022-10-04 09:41:51 - train: epoch 0060, iter [01090, 01251], lr: 0.000249, loss: 0.0838
2022-10-04 09:42:19 - train: epoch 0060, iter [01100, 01251], lr: 0.000249, loss: 0.0859
2022-10-04 09:42:47 - train: epoch 0060, iter [01110, 01251], lr: 0.000249, loss: 0.0830
2022-10-04 09:43:15 - train: epoch 0060, iter [01120, 01251], lr: 0.000249, loss: 0.0850
2022-10-04 09:43:43 - train: epoch 0060, iter [01130, 01251], lr: 0.000249, loss: 0.0830
2022-10-04 09:44:11 - train: epoch 0060, iter [01140, 01251], lr: 0.000249, loss: 0.0889
2022-10-04 09:44:39 - train: epoch 0060, iter [01150, 01251], lr: 0.000249, loss: 0.0849
2022-10-04 09:45:07 - train: epoch 0060, iter [01160, 01251], lr: 0.000249, loss: 0.0939
2022-10-04 09:45:35 - train: epoch 0060, iter [01170, 01251], lr: 0.000249, loss: 0.0872
2022-10-04 09:46:03 - train: epoch 0060, iter [01180, 01251], lr: 0.000248, loss: 0.0827
2022-10-04 09:46:31 - train: epoch 0060, iter [01190, 01251], lr: 0.000248, loss: 0.0792
2022-10-04 09:46:59 - train: epoch 0060, iter [01200, 01251], lr: 0.000248, loss: 0.0844
2022-10-04 09:47:27 - train: epoch 0060, iter [01210, 01251], lr: 0.000248, loss: 0.0856
2022-10-04 09:47:55 - train: epoch 0060, iter [01220, 01251], lr: 0.000248, loss: 0.0818
2022-10-04 09:48:23 - train: epoch 0060, iter [01230, 01251], lr: 0.000248, loss: 0.0844
2022-10-04 09:48:51 - train: epoch 0060, iter [01240, 01251], lr: 0.000248, loss: 0.0885
2022-10-04 09:49:19 - train: epoch 0060, iter [01250, 01251], lr: 0.000248, loss: 0.0834
2022-10-04 09:49:23 - train: epoch 060, train_loss: 0.0871
2022-10-04 09:49:25 - until epoch: 060, best_loss: 0.0871
2022-10-04 09:49:25 - epoch 061 lr: 0.000248
2022-10-04 09:50:00 - train: epoch 0061, iter [00010, 01251], lr: 0.000248, loss: 0.0802
2022-10-04 09:50:28 - train: epoch 0061, iter [00020, 01251], lr: 0.000248, loss: 0.0881
2022-10-04 09:50:56 - train: epoch 0061, iter [00030, 01251], lr: 0.000248, loss: 0.0802
2022-10-04 09:51:24 - train: epoch 0061, iter [00040, 01251], lr: 0.000248, loss: 0.0888
2022-10-04 09:51:53 - train: epoch 0061, iter [00050, 01251], lr: 0.000247, loss: 0.0932
2022-10-04 09:52:21 - train: epoch 0061, iter [00060, 01251], lr: 0.000247, loss: 0.0869
2022-10-04 09:52:49 - train: epoch 0061, iter [00070, 01251], lr: 0.000247, loss: 0.0913
2022-10-04 09:53:17 - train: epoch 0061, iter [00080, 01251], lr: 0.000247, loss: 0.0872
2022-10-04 09:53:46 - train: epoch 0061, iter [00090, 01251], lr: 0.000247, loss: 0.0924
2022-10-04 09:54:14 - train: epoch 0061, iter [00100, 01251], lr: 0.000247, loss: 0.0893
2022-10-04 09:54:42 - train: epoch 0061, iter [00110, 01251], lr: 0.000247, loss: 0.0910
2022-10-04 09:55:10 - train: epoch 0061, iter [00120, 01251], lr: 0.000247, loss: 0.0789
2022-10-04 09:55:38 - train: epoch 0061, iter [00130, 01251], lr: 0.000247, loss: 0.0811
2022-10-04 09:56:07 - train: epoch 0061, iter [00140, 01251], lr: 0.000247, loss: 0.0903
2022-10-04 09:56:35 - train: epoch 0061, iter [00150, 01251], lr: 0.000247, loss: 0.0857
2022-10-04 09:57:03 - train: epoch 0061, iter [00160, 01251], lr: 0.000247, loss: 0.0827
2022-10-04 09:57:32 - train: epoch 0061, iter [00170, 01251], lr: 0.000247, loss: 0.0838
2022-10-04 09:58:00 - train: epoch 0061, iter [00180, 01251], lr: 0.000246, loss: 0.0904
2022-10-04 09:58:28 - train: epoch 0061, iter [00190, 01251], lr: 0.000246, loss: 0.0785
2022-10-04 09:58:56 - train: epoch 0061, iter [00200, 01251], lr: 0.000246, loss: 0.0807
2022-10-04 09:59:25 - train: epoch 0061, iter [00210, 01251], lr: 0.000246, loss: 0.0962
2022-10-04 09:59:53 - train: epoch 0061, iter [00220, 01251], lr: 0.000246, loss: 0.0858
2022-10-04 10:00:21 - train: epoch 0061, iter [00230, 01251], lr: 0.000246, loss: 0.0936
2022-10-04 10:00:49 - train: epoch 0061, iter [00240, 01251], lr: 0.000246, loss: 0.0784
2022-10-04 10:01:17 - train: epoch 0061, iter [00250, 01251], lr: 0.000246, loss: 0.0893
2022-10-04 10:01:45 - train: epoch 0061, iter [00260, 01251], lr: 0.000246, loss: 0.0880
2022-10-04 10:02:14 - train: epoch 0061, iter [00270, 01251], lr: 0.000246, loss: 0.0843
2022-10-04 10:02:42 - train: epoch 0061, iter [00280, 01251], lr: 0.000246, loss: 0.0824
2022-10-04 10:03:10 - train: epoch 0061, iter [00290, 01251], lr: 0.000246, loss: 0.0825
2022-10-04 10:03:38 - train: epoch 0061, iter [00300, 01251], lr: 0.000245, loss: 0.0887
2022-10-04 10:04:06 - train: epoch 0061, iter [00310, 01251], lr: 0.000245, loss: 0.0823
2022-10-04 10:04:34 - train: epoch 0061, iter [00320, 01251], lr: 0.000245, loss: 0.0864
2022-10-04 10:05:02 - train: epoch 0061, iter [00330, 01251], lr: 0.000245, loss: 0.0877
2022-10-04 10:05:30 - train: epoch 0061, iter [00340, 01251], lr: 0.000245, loss: 0.0831
2022-10-04 10:05:58 - train: epoch 0061, iter [00350, 01251], lr: 0.000245, loss: 0.0864
2022-10-04 10:06:27 - train: epoch 0061, iter [00360, 01251], lr: 0.000245, loss: 0.0888
2022-10-04 10:06:55 - train: epoch 0061, iter [00370, 01251], lr: 0.000245, loss: 0.0800
2022-10-04 10:07:23 - train: epoch 0061, iter [00380, 01251], lr: 0.000245, loss: 0.0830
2022-10-04 10:07:51 - train: epoch 0061, iter [00390, 01251], lr: 0.000245, loss: 0.0956
2022-10-04 10:08:19 - train: epoch 0061, iter [00400, 01251], lr: 0.000245, loss: 0.0840
2022-10-04 10:08:47 - train: epoch 0061, iter [00410, 01251], lr: 0.000245, loss: 0.0881
2022-10-04 10:09:15 - train: epoch 0061, iter [00420, 01251], lr: 0.000244, loss: 0.0825
2022-10-04 10:09:43 - train: epoch 0061, iter [00430, 01251], lr: 0.000244, loss: 0.0846
2022-10-04 10:10:11 - train: epoch 0061, iter [00440, 01251], lr: 0.000244, loss: 0.0761
2022-10-04 10:10:40 - train: epoch 0061, iter [00450, 01251], lr: 0.000244, loss: 0.0841
2022-10-04 10:11:08 - train: epoch 0061, iter [00460, 01251], lr: 0.000244, loss: 0.0863
2022-10-04 10:11:36 - train: epoch 0061, iter [00470, 01251], lr: 0.000244, loss: 0.0815
2022-10-04 10:12:05 - train: epoch 0061, iter [00480, 01251], lr: 0.000244, loss: 0.0803
2022-10-04 10:12:33 - train: epoch 0061, iter [00490, 01251], lr: 0.000244, loss: 0.0822
2022-10-04 10:13:01 - train: epoch 0061, iter [00500, 01251], lr: 0.000244, loss: 0.0863
2022-10-04 10:13:29 - train: epoch 0061, iter [00510, 01251], lr: 0.000244, loss: 0.0915
2022-10-04 10:13:58 - train: epoch 0061, iter [00520, 01251], lr: 0.000244, loss: 0.0912
2022-10-04 10:14:26 - train: epoch 0061, iter [00530, 01251], lr: 0.000244, loss: 0.0912
2022-10-04 10:14:54 - train: epoch 0061, iter [00540, 01251], lr: 0.000243, loss: 0.0891
2022-10-04 10:15:22 - train: epoch 0061, iter [00550, 01251], lr: 0.000243, loss: 0.0856
2022-10-04 10:15:50 - train: epoch 0061, iter [00560, 01251], lr: 0.000243, loss: 0.0914
2022-10-04 10:16:18 - train: epoch 0061, iter [00570, 01251], lr: 0.000243, loss: 0.0887
2022-10-04 10:16:47 - train: epoch 0061, iter [00580, 01251], lr: 0.000243, loss: 0.0816
2022-10-04 10:17:15 - train: epoch 0061, iter [00590, 01251], lr: 0.000243, loss: 0.0853
2022-10-04 10:17:43 - train: epoch 0061, iter [00600, 01251], lr: 0.000243, loss: 0.0929
2022-10-04 10:18:11 - train: epoch 0061, iter [00610, 01251], lr: 0.000243, loss: 0.0842
2022-10-04 10:18:39 - train: epoch 0061, iter [00620, 01251], lr: 0.000243, loss: 0.0824
2022-10-04 10:19:07 - train: epoch 0061, iter [00630, 01251], lr: 0.000243, loss: 0.0799
2022-10-04 10:19:35 - train: epoch 0061, iter [00640, 01251], lr: 0.000243, loss: 0.0878
2022-10-04 10:20:03 - train: epoch 0061, iter [00650, 01251], lr: 0.000243, loss: 0.0897
2022-10-04 10:20:31 - train: epoch 0061, iter [00660, 01251], lr: 0.000242, loss: 0.0860
2022-10-04 10:20:59 - train: epoch 0061, iter [00670, 01251], lr: 0.000242, loss: 0.0872
2022-10-04 10:21:27 - train: epoch 0061, iter [00680, 01251], lr: 0.000242, loss: 0.0835
2022-10-04 10:21:55 - train: epoch 0061, iter [00690, 01251], lr: 0.000242, loss: 0.0853
2022-10-04 10:22:23 - train: epoch 0061, iter [00700, 01251], lr: 0.000242, loss: 0.0818
2022-10-04 10:22:51 - train: epoch 0061, iter [00710, 01251], lr: 0.000242, loss: 0.0884
2022-10-04 10:23:19 - train: epoch 0061, iter [00720, 01251], lr: 0.000242, loss: 0.0848
2022-10-04 10:23:47 - train: epoch 0061, iter [00730, 01251], lr: 0.000242, loss: 0.0929
2022-10-04 10:24:16 - train: epoch 0061, iter [00740, 01251], lr: 0.000242, loss: 0.0836
2022-10-04 10:24:44 - train: epoch 0061, iter [00750, 01251], lr: 0.000242, loss: 0.0846
2022-10-04 10:25:12 - train: epoch 0061, iter [00760, 01251], lr: 0.000242, loss: 0.0809
2022-10-04 10:25:40 - train: epoch 0061, iter [00770, 01251], lr: 0.000242, loss: 0.0818
2022-10-04 10:26:09 - train: epoch 0061, iter [00780, 01251], lr: 0.000241, loss: 0.0953
2022-10-04 10:26:37 - train: epoch 0061, iter [00790, 01251], lr: 0.000241, loss: 0.0851
2022-10-04 10:27:05 - train: epoch 0061, iter [00800, 01251], lr: 0.000241, loss: 0.0818
2022-10-04 10:27:33 - train: epoch 0061, iter [00810, 01251], lr: 0.000241, loss: 0.0894
2022-10-04 10:28:01 - train: epoch 0061, iter [00820, 01251], lr: 0.000241, loss: 0.0922
2022-10-04 10:28:30 - train: epoch 0061, iter [00830, 01251], lr: 0.000241, loss: 0.0791
2022-10-04 10:28:58 - train: epoch 0061, iter [00840, 01251], lr: 0.000241, loss: 0.0859
2022-10-04 10:29:26 - train: epoch 0061, iter [00850, 01251], lr: 0.000241, loss: 0.0913
2022-10-04 10:29:55 - train: epoch 0061, iter [00860, 01251], lr: 0.000241, loss: 0.0883
2022-10-04 10:30:23 - train: epoch 0061, iter [00870, 01251], lr: 0.000241, loss: 0.0836
2022-10-04 10:30:51 - train: epoch 0061, iter [00880, 01251], lr: 0.000241, loss: 0.0859
2022-10-04 10:31:19 - train: epoch 0061, iter [00890, 01251], lr: 0.000241, loss: 0.0826
2022-10-04 10:31:48 - train: epoch 0061, iter [00900, 01251], lr: 0.000241, loss: 0.0886
2022-10-04 10:32:16 - train: epoch 0061, iter [00910, 01251], lr: 0.000240, loss: 0.0936
2022-10-04 10:32:44 - train: epoch 0061, iter [00920, 01251], lr: 0.000240, loss: 0.0916
2022-10-04 10:33:12 - train: epoch 0061, iter [00930, 01251], lr: 0.000240, loss: 0.0863
2022-10-04 10:33:41 - train: epoch 0061, iter [00940, 01251], lr: 0.000240, loss: 0.0889
2022-10-04 10:34:09 - train: epoch 0061, iter [00950, 01251], lr: 0.000240, loss: 0.0886
2022-10-04 10:34:37 - train: epoch 0061, iter [00960, 01251], lr: 0.000240, loss: 0.0837
2022-10-04 10:35:05 - train: epoch 0061, iter [00970, 01251], lr: 0.000240, loss: 0.0787
2022-10-04 10:35:33 - train: epoch 0061, iter [00980, 01251], lr: 0.000240, loss: 0.0866
2022-10-04 10:36:02 - train: epoch 0061, iter [00990, 01251], lr: 0.000240, loss: 0.0811
2022-10-04 10:36:30 - train: epoch 0061, iter [01000, 01251], lr: 0.000240, loss: 0.0852
2022-10-04 10:36:58 - train: epoch 0061, iter [01010, 01251], lr: 0.000240, loss: 0.0877
2022-10-04 10:37:26 - train: epoch 0061, iter [01020, 01251], lr: 0.000240, loss: 0.0900
2022-10-04 10:37:54 - train: epoch 0061, iter [01030, 01251], lr: 0.000239, loss: 0.0894
2022-10-04 10:38:22 - train: epoch 0061, iter [01040, 01251], lr: 0.000239, loss: 0.0898
2022-10-04 10:38:50 - train: epoch 0061, iter [01050, 01251], lr: 0.000239, loss: 0.0945
2022-10-04 10:39:18 - train: epoch 0061, iter [01060, 01251], lr: 0.000239, loss: 0.0912
2022-10-04 10:39:46 - train: epoch 0061, iter [01070, 01251], lr: 0.000239, loss: 0.0839
2022-10-04 10:40:14 - train: epoch 0061, iter [01080, 01251], lr: 0.000239, loss: 0.0839
2022-10-04 10:40:42 - train: epoch 0061, iter [01090, 01251], lr: 0.000239, loss: 0.0849
2022-10-04 10:41:10 - train: epoch 0061, iter [01100, 01251], lr: 0.000239, loss: 0.0868
2022-10-04 10:41:38 - train: epoch 0061, iter [01110, 01251], lr: 0.000239, loss: 0.0798
2022-10-04 10:42:06 - train: epoch 0061, iter [01120, 01251], lr: 0.000239, loss: 0.0873
2022-10-04 10:42:34 - train: epoch 0061, iter [01130, 01251], lr: 0.000239, loss: 0.0844
2022-10-04 10:43:02 - train: epoch 0061, iter [01140, 01251], lr: 0.000239, loss: 0.0941
2022-10-04 10:43:30 - train: epoch 0061, iter [01150, 01251], lr: 0.000238, loss: 0.0857
2022-10-04 10:43:58 - train: epoch 0061, iter [01160, 01251], lr: 0.000238, loss: 0.0813
2022-10-04 10:44:27 - train: epoch 0061, iter [01170, 01251], lr: 0.000238, loss: 0.0828
2022-10-04 10:44:55 - train: epoch 0061, iter [01180, 01251], lr: 0.000238, loss: 0.0895
2022-10-04 10:45:23 - train: epoch 0061, iter [01190, 01251], lr: 0.000238, loss: 0.0859
2022-10-04 10:45:51 - train: epoch 0061, iter [01200, 01251], lr: 0.000238, loss: 0.0823
2022-10-04 10:46:19 - train: epoch 0061, iter [01210, 01251], lr: 0.000238, loss: 0.0813
2022-10-04 10:46:47 - train: epoch 0061, iter [01220, 01251], lr: 0.000238, loss: 0.1011
2022-10-04 10:47:16 - train: epoch 0061, iter [01230, 01251], lr: 0.000238, loss: 0.0895
2022-10-04 10:47:44 - train: epoch 0061, iter [01240, 01251], lr: 0.000238, loss: 0.0878
2022-10-04 10:48:12 - train: epoch 0061, iter [01250, 01251], lr: 0.000238, loss: 0.0860
2022-10-04 10:48:16 - train: epoch 061, train_loss: 0.0868
2022-10-04 10:48:18 - until epoch: 061, best_loss: 0.0868
2022-10-04 10:48:18 - epoch 062 lr: 0.000238
2022-10-04 10:48:53 - train: epoch 0062, iter [00010, 01251], lr: 0.000238, loss: 0.0785
2022-10-04 10:49:21 - train: epoch 0062, iter [00020, 01251], lr: 0.000237, loss: 0.0903
2022-10-04 10:49:49 - train: epoch 0062, iter [00030, 01251], lr: 0.000237, loss: 0.0849
2022-10-04 10:50:17 - train: epoch 0062, iter [00040, 01251], lr: 0.000237, loss: 0.0831
2022-10-04 10:50:46 - train: epoch 0062, iter [00050, 01251], lr: 0.000237, loss: 0.0843
2022-10-04 10:51:14 - train: epoch 0062, iter [00060, 01251], lr: 0.000237, loss: 0.0918
2022-10-04 10:51:42 - train: epoch 0062, iter [00070, 01251], lr: 0.000237, loss: 0.0812
2022-10-04 10:52:11 - train: epoch 0062, iter [00080, 01251], lr: 0.000237, loss: 0.0911
2022-10-04 10:52:39 - train: epoch 0062, iter [00090, 01251], lr: 0.000237, loss: 0.0876
2022-10-04 10:53:07 - train: epoch 0062, iter [00100, 01251], lr: 0.000237, loss: 0.0934
2022-10-04 10:53:36 - train: epoch 0062, iter [00110, 01251], lr: 0.000237, loss: 0.0832
2022-10-04 10:54:04 - train: epoch 0062, iter [00120, 01251], lr: 0.000237, loss: 0.0876
2022-10-04 10:54:32 - train: epoch 0062, iter [00130, 01251], lr: 0.000237, loss: 0.0797
2022-10-04 10:55:01 - train: epoch 0062, iter [00140, 01251], lr: 0.000236, loss: 0.0821
2022-10-04 10:55:29 - train: epoch 0062, iter [00150, 01251], lr: 0.000236, loss: 0.0785
2022-10-04 10:55:57 - train: epoch 0062, iter [00160, 01251], lr: 0.000236, loss: 0.0857
2022-10-04 10:56:26 - train: epoch 0062, iter [00170, 01251], lr: 0.000236, loss: 0.0839
2022-10-04 10:56:54 - train: epoch 0062, iter [00180, 01251], lr: 0.000236, loss: 0.0854
2022-10-04 10:57:22 - train: epoch 0062, iter [00190, 01251], lr: 0.000236, loss: 0.0898
2022-10-04 10:57:51 - train: epoch 0062, iter [00200, 01251], lr: 0.000236, loss: 0.0891
2022-10-04 10:58:19 - train: epoch 0062, iter [00210, 01251], lr: 0.000236, loss: 0.0885
2022-10-04 10:58:48 - train: epoch 0062, iter [00220, 01251], lr: 0.000236, loss: 0.0989
2022-10-04 10:59:16 - train: epoch 0062, iter [00230, 01251], lr: 0.000236, loss: 0.0919
2022-10-04 10:59:44 - train: epoch 0062, iter [00240, 01251], lr: 0.000236, loss: 0.0838
2022-10-04 11:00:13 - train: epoch 0062, iter [00250, 01251], lr: 0.000236, loss: 0.0818
2022-10-04 11:00:41 - train: epoch 0062, iter [00260, 01251], lr: 0.000235, loss: 0.0989
2022-10-04 11:01:09 - train: epoch 0062, iter [00270, 01251], lr: 0.000235, loss: 0.0950
2022-10-04 11:01:38 - train: epoch 0062, iter [00280, 01251], lr: 0.000235, loss: 0.0886
2022-10-04 11:02:06 - train: epoch 0062, iter [00290, 01251], lr: 0.000235, loss: 0.0879
2022-10-04 11:02:34 - train: epoch 0062, iter [00300, 01251], lr: 0.000235, loss: 0.0845
2022-10-04 11:03:02 - train: epoch 0062, iter [00310, 01251], lr: 0.000235, loss: 0.0816
2022-10-04 11:03:31 - train: epoch 0062, iter [00320, 01251], lr: 0.000235, loss: 0.0761
2022-10-04 11:03:59 - train: epoch 0062, iter [00330, 01251], lr: 0.000235, loss: 0.0904
2022-10-04 11:04:27 - train: epoch 0062, iter [00340, 01251], lr: 0.000235, loss: 0.0868
2022-10-04 11:04:56 - train: epoch 0062, iter [00350, 01251], lr: 0.000235, loss: 0.0852
2022-10-04 11:05:24 - train: epoch 0062, iter [00360, 01251], lr: 0.000235, loss: 0.0876
2022-10-04 11:05:52 - train: epoch 0062, iter [00370, 01251], lr: 0.000235, loss: 0.0900
2022-10-04 11:06:21 - train: epoch 0062, iter [00380, 01251], lr: 0.000235, loss: 0.0940
2022-10-04 11:06:49 - train: epoch 0062, iter [00390, 01251], lr: 0.000234, loss: 0.0926
2022-10-04 11:07:17 - train: epoch 0062, iter [00400, 01251], lr: 0.000234, loss: 0.0880
2022-10-04 11:07:46 - train: epoch 0062, iter [00410, 01251], lr: 0.000234, loss: 0.0896
2022-10-04 11:08:14 - train: epoch 0062, iter [00420, 01251], lr: 0.000234, loss: 0.0910
2022-10-04 11:08:43 - train: epoch 0062, iter [00430, 01251], lr: 0.000234, loss: 0.0865
2022-10-04 11:09:11 - train: epoch 0062, iter [00440, 01251], lr: 0.000234, loss: 0.0879
2022-10-04 11:09:39 - train: epoch 0062, iter [00450, 01251], lr: 0.000234, loss: 0.0832
2022-10-04 11:10:07 - train: epoch 0062, iter [00460, 01251], lr: 0.000234, loss: 0.0878
2022-10-04 11:10:36 - train: epoch 0062, iter [00470, 01251], lr: 0.000234, loss: 0.0908
2022-10-04 11:11:04 - train: epoch 0062, iter [00480, 01251], lr: 0.000234, loss: 0.0879
2022-10-04 11:11:32 - train: epoch 0062, iter [00490, 01251], lr: 0.000234, loss: 0.0904
2022-10-04 11:12:00 - train: epoch 0062, iter [00500, 01251], lr: 0.000234, loss: 0.0869
2022-10-04 11:12:29 - train: epoch 0062, iter [00510, 01251], lr: 0.000233, loss: 0.0874
2022-10-04 11:12:57 - train: epoch 0062, iter [00520, 01251], lr: 0.000233, loss: 0.0911
2022-10-04 11:13:25 - train: epoch 0062, iter [00530, 01251], lr: 0.000233, loss: 0.0858
2022-10-04 11:13:53 - train: epoch 0062, iter [00540, 01251], lr: 0.000233, loss: 0.0870
2022-10-04 11:14:22 - train: epoch 0062, iter [00550, 01251], lr: 0.000233, loss: 0.0817
2022-10-04 11:14:50 - train: epoch 0062, iter [00560, 01251], lr: 0.000233, loss: 0.0793
2022-10-04 11:15:18 - train: epoch 0062, iter [00570, 01251], lr: 0.000233, loss: 0.0894
2022-10-04 11:15:46 - train: epoch 0062, iter [00580, 01251], lr: 0.000233, loss: 0.0875
2022-10-04 11:16:15 - train: epoch 0062, iter [00590, 01251], lr: 0.000233, loss: 0.0901
2022-10-04 11:16:43 - train: epoch 0062, iter [00600, 01251], lr: 0.000233, loss: 0.0863
2022-10-04 11:17:11 - train: epoch 0062, iter [00610, 01251], lr: 0.000233, loss: 0.0913
2022-10-04 11:17:40 - train: epoch 0062, iter [00620, 01251], lr: 0.000233, loss: 0.0862
2022-10-04 11:18:08 - train: epoch 0062, iter [00630, 01251], lr: 0.000232, loss: 0.0896
2022-10-04 11:18:36 - train: epoch 0062, iter [00640, 01251], lr: 0.000232, loss: 0.0938
2022-10-04 11:19:04 - train: epoch 0062, iter [00650, 01251], lr: 0.000232, loss: 0.0866
2022-10-04 11:19:33 - train: epoch 0062, iter [00660, 01251], lr: 0.000232, loss: 0.0859
2022-10-04 11:20:01 - train: epoch 0062, iter [00670, 01251], lr: 0.000232, loss: 0.0863
2022-10-04 11:20:29 - train: epoch 0062, iter [00680, 01251], lr: 0.000232, loss: 0.0766
2022-10-04 11:20:58 - train: epoch 0062, iter [00690, 01251], lr: 0.000232, loss: 0.0853
2022-10-04 11:21:26 - train: epoch 0062, iter [00700, 01251], lr: 0.000232, loss: 0.0874
2022-10-04 11:21:54 - train: epoch 0062, iter [00710, 01251], lr: 0.000232, loss: 0.0868
2022-10-04 11:22:22 - train: epoch 0062, iter [00720, 01251], lr: 0.000232, loss: 0.0906
2022-10-04 11:22:50 - train: epoch 0062, iter [00730, 01251], lr: 0.000232, loss: 0.0847
2022-10-04 11:23:18 - train: epoch 0062, iter [00740, 01251], lr: 0.000232, loss: 0.0871
2022-10-04 11:23:47 - train: epoch 0062, iter [00750, 01251], lr: 0.000231, loss: 0.0815
2022-10-04 11:24:15 - train: epoch 0062, iter [00760, 01251], lr: 0.000231, loss: 0.0858
2022-10-04 11:24:43 - train: epoch 0062, iter [00770, 01251], lr: 0.000231, loss: 0.0840
2022-10-04 11:25:12 - train: epoch 0062, iter [00780, 01251], lr: 0.000231, loss: 0.0864
2022-10-04 11:25:40 - train: epoch 0062, iter [00790, 01251], lr: 0.000231, loss: 0.0883
2022-10-04 11:26:09 - train: epoch 0062, iter [00800, 01251], lr: 0.000231, loss: 0.0883
2022-10-04 11:26:37 - train: epoch 0062, iter [00810, 01251], lr: 0.000231, loss: 0.0820
2022-10-04 11:27:06 - train: epoch 0062, iter [00820, 01251], lr: 0.000231, loss: 0.0916
2022-10-04 11:27:34 - train: epoch 0062, iter [00830, 01251], lr: 0.000231, loss: 0.1000
2022-10-04 11:28:02 - train: epoch 0062, iter [00840, 01251], lr: 0.000231, loss: 0.0865
2022-10-04 11:28:30 - train: epoch 0062, iter [00850, 01251], lr: 0.000231, loss: 0.0891
2022-10-04 11:28:59 - train: epoch 0062, iter [00860, 01251], lr: 0.000231, loss: 0.0943
2022-10-04 11:29:27 - train: epoch 0062, iter [00870, 01251], lr: 0.000231, loss: 0.0830
2022-10-04 11:29:55 - train: epoch 0062, iter [00880, 01251], lr: 0.000230, loss: 0.0863
2022-10-04 11:30:24 - train: epoch 0062, iter [00890, 01251], lr: 0.000230, loss: 0.0947
2022-10-04 11:30:52 - train: epoch 0062, iter [00900, 01251], lr: 0.000230, loss: 0.0898
2022-10-04 11:31:20 - train: epoch 0062, iter [00910, 01251], lr: 0.000230, loss: 0.0873
2022-10-04 11:31:49 - train: epoch 0062, iter [00920, 01251], lr: 0.000230, loss: 0.0803
2022-10-04 11:32:17 - train: epoch 0062, iter [00930, 01251], lr: 0.000230, loss: 0.0860
2022-10-04 11:32:45 - train: epoch 0062, iter [00940, 01251], lr: 0.000230, loss: 0.0817
2022-10-04 11:33:13 - train: epoch 0062, iter [00950, 01251], lr: 0.000230, loss: 0.0875
2022-10-04 11:33:42 - train: epoch 0062, iter [00960, 01251], lr: 0.000230, loss: 0.0857
2022-10-04 11:34:10 - train: epoch 0062, iter [00970, 01251], lr: 0.000230, loss: 0.0839
2022-10-04 11:34:38 - train: epoch 0062, iter [00980, 01251], lr: 0.000230, loss: 0.0841
2022-10-04 11:35:06 - train: epoch 0062, iter [00990, 01251], lr: 0.000230, loss: 0.0844
2022-10-04 11:35:35 - train: epoch 0062, iter [01000, 01251], lr: 0.000229, loss: 0.0847
2022-10-04 11:36:03 - train: epoch 0062, iter [01010, 01251], lr: 0.000229, loss: 0.0815
2022-10-04 11:36:32 - train: epoch 0062, iter [01020, 01251], lr: 0.000229, loss: 0.0854
2022-10-04 11:37:00 - train: epoch 0062, iter [01030, 01251], lr: 0.000229, loss: 0.0823
2022-10-04 11:37:28 - train: epoch 0062, iter [01040, 01251], lr: 0.000229, loss: 0.0851
2022-10-04 11:37:57 - train: epoch 0062, iter [01050, 01251], lr: 0.000229, loss: 0.0841
2022-10-04 11:38:25 - train: epoch 0062, iter [01060, 01251], lr: 0.000229, loss: 0.0926
2022-10-04 11:38:54 - train: epoch 0062, iter [01070, 01251], lr: 0.000229, loss: 0.0807
2022-10-04 11:39:22 - train: epoch 0062, iter [01080, 01251], lr: 0.000229, loss: 0.0883
2022-10-04 11:39:50 - train: epoch 0062, iter [01090, 01251], lr: 0.000229, loss: 0.0854
2022-10-04 11:40:19 - train: epoch 0062, iter [01100, 01251], lr: 0.000229, loss: 0.0811
2022-10-04 11:40:47 - train: epoch 0062, iter [01110, 01251], lr: 0.000229, loss: 0.0881
2022-10-04 11:41:15 - train: epoch 0062, iter [01120, 01251], lr: 0.000228, loss: 0.0855
2022-10-04 11:41:44 - train: epoch 0062, iter [01130, 01251], lr: 0.000228, loss: 0.0726
2022-10-04 11:42:12 - train: epoch 0062, iter [01140, 01251], lr: 0.000228, loss: 0.0817
2022-10-04 11:42:40 - train: epoch 0062, iter [01150, 01251], lr: 0.000228, loss: 0.0803
2022-10-04 11:43:08 - train: epoch 0062, iter [01160, 01251], lr: 0.000228, loss: 0.0876
2022-10-04 11:43:36 - train: epoch 0062, iter [01170, 01251], lr: 0.000228, loss: 0.0839
2022-10-04 11:44:05 - train: epoch 0062, iter [01180, 01251], lr: 0.000228, loss: 0.0828
2022-10-04 11:44:33 - train: epoch 0062, iter [01190, 01251], lr: 0.000228, loss: 0.0807
2022-10-04 11:45:01 - train: epoch 0062, iter [01200, 01251], lr: 0.000228, loss: 0.0837
2022-10-04 11:45:30 - train: epoch 0062, iter [01210, 01251], lr: 0.000228, loss: 0.0897
2022-10-04 11:45:58 - train: epoch 0062, iter [01220, 01251], lr: 0.000228, loss: 0.0827
2022-10-04 11:46:26 - train: epoch 0062, iter [01230, 01251], lr: 0.000228, loss: 0.0838
2022-10-04 11:46:55 - train: epoch 0062, iter [01240, 01251], lr: 0.000228, loss: 0.0947
2022-10-04 11:47:23 - train: epoch 0062, iter [01250, 01251], lr: 0.000227, loss: 0.0838
2022-10-04 11:47:27 - train: epoch 062, train_loss: 0.0866
2022-10-04 11:47:29 - until epoch: 062, best_loss: 0.0866
2022-10-04 11:47:29 - epoch 063 lr: 0.000227
2022-10-04 11:48:03 - train: epoch 0063, iter [00010, 01251], lr: 0.000227, loss: 0.0841
2022-10-04 11:48:31 - train: epoch 0063, iter [00020, 01251], lr: 0.000227, loss: 0.0799
2022-10-04 11:48:59 - train: epoch 0063, iter [00030, 01251], lr: 0.000227, loss: 0.0806
2022-10-04 11:49:28 - train: epoch 0063, iter [00040, 01251], lr: 0.000227, loss: 0.0872
2022-10-04 11:49:56 - train: epoch 0063, iter [00050, 01251], lr: 0.000227, loss: 0.0941
2022-10-04 11:50:24 - train: epoch 0063, iter [00060, 01251], lr: 0.000227, loss: 0.0873
2022-10-04 11:50:52 - train: epoch 0063, iter [00070, 01251], lr: 0.000227, loss: 0.0874
2022-10-04 11:51:21 - train: epoch 0063, iter [00080, 01251], lr: 0.000227, loss: 0.0860
2022-10-04 11:51:49 - train: epoch 0063, iter [00090, 01251], lr: 0.000227, loss: 0.0823
2022-10-04 11:52:17 - train: epoch 0063, iter [00100, 01251], lr: 0.000227, loss: 0.0891
2022-10-04 11:52:46 - train: epoch 0063, iter [00110, 01251], lr: 0.000227, loss: 0.0874
2022-10-04 11:53:14 - train: epoch 0063, iter [00120, 01251], lr: 0.000226, loss: 0.0922
2022-10-04 11:53:42 - train: epoch 0063, iter [00130, 01251], lr: 0.000226, loss: 0.0921
2022-10-04 11:54:10 - train: epoch 0063, iter [00140, 01251], lr: 0.000226, loss: 0.0840
2022-10-04 11:54:39 - train: epoch 0063, iter [00150, 01251], lr: 0.000226, loss: 0.0825
2022-10-04 11:55:07 - train: epoch 0063, iter [00160, 01251], lr: 0.000226, loss: 0.0841
2022-10-04 11:55:36 - train: epoch 0063, iter [00170, 01251], lr: 0.000226, loss: 0.0831
2022-10-04 11:56:04 - train: epoch 0063, iter [00180, 01251], lr: 0.000226, loss: 0.0836
2022-10-04 11:56:32 - train: epoch 0063, iter [00190, 01251], lr: 0.000226, loss: 0.0823
2022-10-04 11:57:01 - train: epoch 0063, iter [00200, 01251], lr: 0.000226, loss: 0.0892
2022-10-04 11:57:29 - train: epoch 0063, iter [00210, 01251], lr: 0.000226, loss: 0.0912
2022-10-04 11:57:57 - train: epoch 0063, iter [00220, 01251], lr: 0.000226, loss: 0.0871
2022-10-04 11:58:26 - train: epoch 0063, iter [00230, 01251], lr: 0.000226, loss: 0.0846
2022-10-04 11:58:54 - train: epoch 0063, iter [00240, 01251], lr: 0.000225, loss: 0.0798
2022-10-04 11:59:22 - train: epoch 0063, iter [00250, 01251], lr: 0.000225, loss: 0.0828
2022-10-04 11:59:51 - train: epoch 0063, iter [00260, 01251], lr: 0.000225, loss: 0.0847
2022-10-04 12:00:19 - train: epoch 0063, iter [00270, 01251], lr: 0.000225, loss: 0.0892
2022-10-04 12:00:47 - train: epoch 0063, iter [00280, 01251], lr: 0.000225, loss: 0.0871
2022-10-04 12:01:15 - train: epoch 0063, iter [00290, 01251], lr: 0.000225, loss: 0.0993
2022-10-04 12:01:44 - train: epoch 0063, iter [00300, 01251], lr: 0.000225, loss: 0.0913
2022-10-04 12:02:12 - train: epoch 0063, iter [00310, 01251], lr: 0.000225, loss: 0.0793
2022-10-04 12:02:40 - train: epoch 0063, iter [00320, 01251], lr: 0.000225, loss: 0.0853
2022-10-04 12:03:09 - train: epoch 0063, iter [00330, 01251], lr: 0.000225, loss: 0.0866
2022-10-04 12:03:37 - train: epoch 0063, iter [00340, 01251], lr: 0.000225, loss: 0.0911
2022-10-04 12:04:05 - train: epoch 0063, iter [00350, 01251], lr: 0.000225, loss: 0.0904
2022-10-04 12:04:34 - train: epoch 0063, iter [00360, 01251], lr: 0.000225, loss: 0.0942
2022-10-04 12:05:02 - train: epoch 0063, iter [00370, 01251], lr: 0.000224, loss: 0.0852
2022-10-04 12:05:30 - train: epoch 0063, iter [00380, 01251], lr: 0.000224, loss: 0.0853
2022-10-04 12:05:59 - train: epoch 0063, iter [00390, 01251], lr: 0.000224, loss: 0.0866
2022-10-04 12:06:27 - train: epoch 0063, iter [00400, 01251], lr: 0.000224, loss: 0.0872
2022-10-04 12:06:56 - train: epoch 0063, iter [00410, 01251], lr: 0.000224, loss: 0.0888
2022-10-04 12:07:24 - train: epoch 0063, iter [00420, 01251], lr: 0.000224, loss: 0.0814
2022-10-04 12:07:52 - train: epoch 0063, iter [00430, 01251], lr: 0.000224, loss: 0.0814
2022-10-04 12:08:20 - train: epoch 0063, iter [00440, 01251], lr: 0.000224, loss: 0.0778
2022-10-04 12:08:49 - train: epoch 0063, iter [00450, 01251], lr: 0.000224, loss: 0.0817
2022-10-04 12:09:17 - train: epoch 0063, iter [00460, 01251], lr: 0.000224, loss: 0.0909
2022-10-04 12:09:46 - train: epoch 0063, iter [00470, 01251], lr: 0.000224, loss: 0.0885
2022-10-04 12:10:14 - train: epoch 0063, iter [00480, 01251], lr: 0.000224, loss: 0.0872
2022-10-04 12:10:42 - train: epoch 0063, iter [00490, 01251], lr: 0.000223, loss: 0.0911
2022-10-04 12:11:11 - train: epoch 0063, iter [00500, 01251], lr: 0.000223, loss: 0.0848
2022-10-04 12:11:39 - train: epoch 0063, iter [00510, 01251], lr: 0.000223, loss: 0.0835
2022-10-04 12:12:07 - train: epoch 0063, iter [00520, 01251], lr: 0.000223, loss: 0.0901
2022-10-04 12:12:36 - train: epoch 0063, iter [00530, 01251], lr: 0.000223, loss: 0.0912
2022-10-04 12:13:04 - train: epoch 0063, iter [00540, 01251], lr: 0.000223, loss: 0.0901
2022-10-04 12:13:33 - train: epoch 0063, iter [00550, 01251], lr: 0.000223, loss: 0.0865
2022-10-04 12:14:01 - train: epoch 0063, iter [00560, 01251], lr: 0.000223, loss: 0.0888
2022-10-04 12:14:29 - train: epoch 0063, iter [00570, 01251], lr: 0.000223, loss: 0.0871
2022-10-04 12:14:58 - train: epoch 0063, iter [00580, 01251], lr: 0.000223, loss: 0.0932
2022-10-04 12:15:26 - train: epoch 0063, iter [00590, 01251], lr: 0.000223, loss: 0.0786
2022-10-04 12:15:55 - train: epoch 0063, iter [00600, 01251], lr: 0.000223, loss: 0.0852
2022-10-04 12:16:23 - train: epoch 0063, iter [00610, 01251], lr: 0.000222, loss: 0.0883
2022-10-04 12:16:51 - train: epoch 0063, iter [00620, 01251], lr: 0.000222, loss: 0.0788
2022-10-04 12:17:19 - train: epoch 0063, iter [00630, 01251], lr: 0.000222, loss: 0.0837
2022-10-04 12:17:48 - train: epoch 0063, iter [00640, 01251], lr: 0.000222, loss: 0.0859
2022-10-04 12:18:16 - train: epoch 0063, iter [00650, 01251], lr: 0.000222, loss: 0.0910
2022-10-04 12:18:44 - train: epoch 0063, iter [00660, 01251], lr: 0.000222, loss: 0.0941
2022-10-04 12:19:13 - train: epoch 0063, iter [00670, 01251], lr: 0.000222, loss: 0.0876
2022-10-04 12:19:41 - train: epoch 0063, iter [00680, 01251], lr: 0.000222, loss: 0.0825
2022-10-04 12:20:09 - train: epoch 0063, iter [00690, 01251], lr: 0.000222, loss: 0.0918
2022-10-04 12:20:38 - train: epoch 0063, iter [00700, 01251], lr: 0.000222, loss: 0.0808
2022-10-04 12:21:06 - train: epoch 0063, iter [00710, 01251], lr: 0.000222, loss: 0.0860
2022-10-04 12:21:34 - train: epoch 0063, iter [00720, 01251], lr: 0.000222, loss: 0.0974
2022-10-04 12:22:03 - train: epoch 0063, iter [00730, 01251], lr: 0.000222, loss: 0.0951
2022-10-04 12:22:31 - train: epoch 0063, iter [00740, 01251], lr: 0.000221, loss: 0.0814
2022-10-04 12:22:59 - train: epoch 0063, iter [00750, 01251], lr: 0.000221, loss: 0.0874
2022-10-04 12:23:28 - train: epoch 0063, iter [00760, 01251], lr: 0.000221, loss: 0.0834
2022-10-04 12:23:56 - train: epoch 0063, iter [00770, 01251], lr: 0.000221, loss: 0.0858
2022-10-04 12:24:24 - train: epoch 0063, iter [00780, 01251], lr: 0.000221, loss: 0.0802
2022-10-04 12:24:52 - train: epoch 0063, iter [00790, 01251], lr: 0.000221, loss: 0.0867
2022-10-04 12:25:21 - train: epoch 0063, iter [00800, 01251], lr: 0.000221, loss: 0.0904
2022-10-04 12:25:49 - train: epoch 0063, iter [00810, 01251], lr: 0.000221, loss: 0.0907
2022-10-04 12:26:18 - train: epoch 0063, iter [00820, 01251], lr: 0.000221, loss: 0.0883
2022-10-04 12:26:46 - train: epoch 0063, iter [00830, 01251], lr: 0.000221, loss: 0.0906
2022-10-04 12:27:14 - train: epoch 0063, iter [00840, 01251], lr: 0.000221, loss: 0.0811
2022-10-04 12:27:43 - train: epoch 0063, iter [00850, 01251], lr: 0.000221, loss: 0.0837
2022-10-04 12:28:11 - train: epoch 0063, iter [00860, 01251], lr: 0.000220, loss: 0.0810
2022-10-04 12:28:39 - train: epoch 0063, iter [00870, 01251], lr: 0.000220, loss: 0.0927
2022-10-04 12:29:07 - train: epoch 0063, iter [00880, 01251], lr: 0.000220, loss: 0.0814
2022-10-04 12:29:35 - train: epoch 0063, iter [00890, 01251], lr: 0.000220, loss: 0.0957
2022-10-04 12:30:03 - train: epoch 0063, iter [00900, 01251], lr: 0.000220, loss: 0.0857
2022-10-04 12:30:32 - train: epoch 0063, iter [00910, 01251], lr: 0.000220, loss: 0.0872
2022-10-04 12:31:00 - train: epoch 0063, iter [00920, 01251], lr: 0.000220, loss: 0.0783
2022-10-04 12:31:28 - train: epoch 0063, iter [00930, 01251], lr: 0.000220, loss: 0.0833
2022-10-04 12:31:56 - train: epoch 0063, iter [00940, 01251], lr: 0.000220, loss: 0.0878
2022-10-04 12:32:24 - train: epoch 0063, iter [00950, 01251], lr: 0.000220, loss: 0.0851
2022-10-04 12:32:53 - train: epoch 0063, iter [00960, 01251], lr: 0.000220, loss: 0.0887
2022-10-04 12:33:21 - train: epoch 0063, iter [00970, 01251], lr: 0.000220, loss: 0.0846
2022-10-04 12:33:49 - train: epoch 0063, iter [00980, 01251], lr: 0.000219, loss: 0.0858
2022-10-04 12:34:17 - train: epoch 0063, iter [00990, 01251], lr: 0.000219, loss: 0.0829
2022-10-04 12:34:46 - train: epoch 0063, iter [01000, 01251], lr: 0.000219, loss: 0.0820
2022-10-04 12:35:14 - train: epoch 0063, iter [01010, 01251], lr: 0.000219, loss: 0.0835
2022-10-04 12:35:42 - train: epoch 0063, iter [01020, 01251], lr: 0.000219, loss: 0.0809
2022-10-04 12:36:10 - train: epoch 0063, iter [01030, 01251], lr: 0.000219, loss: 0.0944
2022-10-04 12:36:39 - train: epoch 0063, iter [01040, 01251], lr: 0.000219, loss: 0.0766
2022-10-04 12:37:07 - train: epoch 0063, iter [01050, 01251], lr: 0.000219, loss: 0.0901
2022-10-04 12:37:35 - train: epoch 0063, iter [01060, 01251], lr: 0.000219, loss: 0.0870
2022-10-04 12:38:04 - train: epoch 0063, iter [01070, 01251], lr: 0.000219, loss: 0.0860
2022-10-04 12:38:32 - train: epoch 0063, iter [01080, 01251], lr: 0.000219, loss: 0.0834
2022-10-04 12:39:00 - train: epoch 0063, iter [01090, 01251], lr: 0.000219, loss: 0.0887
2022-10-04 12:39:28 - train: epoch 0063, iter [01100, 01251], lr: 0.000219, loss: 0.0849
2022-10-04 12:39:57 - train: epoch 0063, iter [01110, 01251], lr: 0.000218, loss: 0.0897
2022-10-04 12:40:25 - train: epoch 0063, iter [01120, 01251], lr: 0.000218, loss: 0.0910
2022-10-04 12:40:53 - train: epoch 0063, iter [01130, 01251], lr: 0.000218, loss: 0.0910
2022-10-04 12:41:22 - train: epoch 0063, iter [01140, 01251], lr: 0.000218, loss: 0.0823
2022-10-04 12:41:50 - train: epoch 0063, iter [01150, 01251], lr: 0.000218, loss: 0.0848
2022-10-04 12:42:18 - train: epoch 0063, iter [01160, 01251], lr: 0.000218, loss: 0.0869
2022-10-04 12:42:46 - train: epoch 0063, iter [01170, 01251], lr: 0.000218, loss: 0.0816
2022-10-04 12:43:15 - train: epoch 0063, iter [01180, 01251], lr: 0.000218, loss: 0.0804
2022-10-04 12:43:43 - train: epoch 0063, iter [01190, 01251], lr: 0.000218, loss: 0.0812
2022-10-04 12:44:11 - train: epoch 0063, iter [01200, 01251], lr: 0.000218, loss: 0.0898
2022-10-04 12:44:39 - train: epoch 0063, iter [01210, 01251], lr: 0.000218, loss: 0.0825
2022-10-04 12:45:08 - train: epoch 0063, iter [01220, 01251], lr: 0.000218, loss: 0.0846
2022-10-04 12:45:36 - train: epoch 0063, iter [01230, 01251], lr: 0.000217, loss: 0.0888
2022-10-04 12:46:05 - train: epoch 0063, iter [01240, 01251], lr: 0.000217, loss: 0.0862
2022-10-04 12:46:33 - train: epoch 0063, iter [01250, 01251], lr: 0.000217, loss: 0.0866
2022-10-04 12:46:37 - train: epoch 063, train_loss: 0.0864
2022-10-04 12:46:38 - until epoch: 063, best_loss: 0.0864
2022-10-04 12:46:38 - epoch 064 lr: 0.000217
2022-10-04 12:47:14 - train: epoch 0064, iter [00010, 01251], lr: 0.000217, loss: 0.0819
2022-10-04 12:47:42 - train: epoch 0064, iter [00020, 01251], lr: 0.000217, loss: 0.0813
2022-10-04 12:48:10 - train: epoch 0064, iter [00030, 01251], lr: 0.000217, loss: 0.0815
2022-10-04 12:48:38 - train: epoch 0064, iter [00040, 01251], lr: 0.000217, loss: 0.0874
2022-10-04 12:49:06 - train: epoch 0064, iter [00050, 01251], lr: 0.000217, loss: 0.0774
2022-10-04 12:49:34 - train: epoch 0064, iter [00060, 01251], lr: 0.000217, loss: 0.0921
2022-10-04 12:50:03 - train: epoch 0064, iter [00070, 01251], lr: 0.000217, loss: 0.0852
2022-10-04 12:50:31 - train: epoch 0064, iter [00080, 01251], lr: 0.000217, loss: 0.0949
2022-10-04 12:50:59 - train: epoch 0064, iter [00090, 01251], lr: 0.000217, loss: 0.0820
2022-10-04 12:51:28 - train: epoch 0064, iter [00100, 01251], lr: 0.000217, loss: 0.0916
2022-10-04 12:51:56 - train: epoch 0064, iter [00110, 01251], lr: 0.000216, loss: 0.0850
2022-10-04 12:52:24 - train: epoch 0064, iter [00120, 01251], lr: 0.000216, loss: 0.0848
2022-10-04 12:52:52 - train: epoch 0064, iter [00130, 01251], lr: 0.000216, loss: 0.0789
2022-10-04 12:53:20 - train: epoch 0064, iter [00140, 01251], lr: 0.000216, loss: 0.0860
2022-10-04 12:53:49 - train: epoch 0064, iter [00150, 01251], lr: 0.000216, loss: 0.0841
2022-10-04 12:54:17 - train: epoch 0064, iter [00160, 01251], lr: 0.000216, loss: 0.0855
2022-10-04 12:54:45 - train: epoch 0064, iter [00170, 01251], lr: 0.000216, loss: 0.0860
2022-10-04 12:55:14 - train: epoch 0064, iter [00180, 01251], lr: 0.000216, loss: 0.0884
2022-10-04 12:55:42 - train: epoch 0064, iter [00190, 01251], lr: 0.000216, loss: 0.0930
2022-10-04 12:56:10 - train: epoch 0064, iter [00200, 01251], lr: 0.000216, loss: 0.0925
2022-10-04 12:56:38 - train: epoch 0064, iter [00210, 01251], lr: 0.000216, loss: 0.0954
2022-10-04 12:57:07 - train: epoch 0064, iter [00220, 01251], lr: 0.000216, loss: 0.0860
2022-10-04 12:57:35 - train: epoch 0064, iter [00230, 01251], lr: 0.000215, loss: 0.0842
2022-10-04 12:58:03 - train: epoch 0064, iter [00240, 01251], lr: 0.000215, loss: 0.1018
2022-10-04 12:58:31 - train: epoch 0064, iter [00250, 01251], lr: 0.000215, loss: 0.0857
2022-10-04 12:59:00 - train: epoch 0064, iter [00260, 01251], lr: 0.000215, loss: 0.0829
2022-10-04 12:59:28 - train: epoch 0064, iter [00270, 01251], lr: 0.000215, loss: 0.0824
2022-10-04 12:59:56 - train: epoch 0064, iter [00280, 01251], lr: 0.000215, loss: 0.0860
2022-10-04 13:00:25 - train: epoch 0064, iter [00290, 01251], lr: 0.000215, loss: 0.0803
2022-10-04 13:00:53 - train: epoch 0064, iter [00300, 01251], lr: 0.000215, loss: 0.0892
2022-10-04 13:01:21 - train: epoch 0064, iter [00310, 01251], lr: 0.000215, loss: 0.0966
2022-10-04 13:01:50 - train: epoch 0064, iter [00320, 01251], lr: 0.000215, loss: 0.0811
2022-10-04 13:02:18 - train: epoch 0064, iter [00330, 01251], lr: 0.000215, loss: 0.0774
2022-10-04 13:02:46 - train: epoch 0064, iter [00340, 01251], lr: 0.000215, loss: 0.0861
2022-10-04 13:03:14 - train: epoch 0064, iter [00350, 01251], lr: 0.000214, loss: 0.0804
2022-10-04 13:03:43 - train: epoch 0064, iter [00360, 01251], lr: 0.000214, loss: 0.0817
2022-10-04 13:04:11 - train: epoch 0064, iter [00370, 01251], lr: 0.000214, loss: 0.0832
2022-10-04 13:04:39 - train: epoch 0064, iter [00380, 01251], lr: 0.000214, loss: 0.0849
2022-10-04 13:05:08 - train: epoch 0064, iter [00390, 01251], lr: 0.000214, loss: 0.0892
2022-10-04 13:05:36 - train: epoch 0064, iter [00400, 01251], lr: 0.000214, loss: 0.0870
2022-10-04 13:06:04 - train: epoch 0064, iter [00410, 01251], lr: 0.000214, loss: 0.0874
2022-10-04 13:06:33 - train: epoch 0064, iter [00420, 01251], lr: 0.000214, loss: 0.0890
2022-10-04 13:07:01 - train: epoch 0064, iter [00430, 01251], lr: 0.000214, loss: 0.0870
2022-10-04 13:07:29 - train: epoch 0064, iter [00440, 01251], lr: 0.000214, loss: 0.0856
2022-10-04 13:07:57 - train: epoch 0064, iter [00450, 01251], lr: 0.000214, loss: 0.0864
2022-10-04 13:08:26 - train: epoch 0064, iter [00460, 01251], lr: 0.000214, loss: 0.0862
2022-10-04 13:08:54 - train: epoch 0064, iter [00470, 01251], lr: 0.000214, loss: 0.0860
2022-10-04 13:09:22 - train: epoch 0064, iter [00480, 01251], lr: 0.000213, loss: 0.0840
2022-10-04 13:09:51 - train: epoch 0064, iter [00490, 01251], lr: 0.000213, loss: 0.0923
2022-10-04 13:10:19 - train: epoch 0064, iter [00500, 01251], lr: 0.000213, loss: 0.0873
2022-10-04 13:10:47 - train: epoch 0064, iter [00510, 01251], lr: 0.000213, loss: 0.0849
2022-10-04 13:11:15 - train: epoch 0064, iter [00520, 01251], lr: 0.000213, loss: 0.0825
2022-10-04 13:11:44 - train: epoch 0064, iter [00530, 01251], lr: 0.000213, loss: 0.0817
2022-10-04 13:12:12 - train: epoch 0064, iter [00540, 01251], lr: 0.000213, loss: 0.0852
2022-10-04 13:12:41 - train: epoch 0064, iter [00550, 01251], lr: 0.000213, loss: 0.0932
2022-10-04 13:13:09 - train: epoch 0064, iter [00560, 01251], lr: 0.000213, loss: 0.0837
2022-10-04 13:13:37 - train: epoch 0064, iter [00570, 01251], lr: 0.000213, loss: 0.0925
2022-10-04 13:14:05 - train: epoch 0064, iter [00580, 01251], lr: 0.000213, loss: 0.0848
2022-10-04 13:14:34 - train: epoch 0064, iter [00590, 01251], lr: 0.000213, loss: 0.0870
2022-10-04 13:15:02 - train: epoch 0064, iter [00600, 01251], lr: 0.000212, loss: 0.0811
2022-10-04 13:15:30 - train: epoch 0064, iter [00610, 01251], lr: 0.000212, loss: 0.0827
2022-10-04 13:15:59 - train: epoch 0064, iter [00620, 01251], lr: 0.000212, loss: 0.0802
2022-10-04 13:16:27 - train: epoch 0064, iter [00630, 01251], lr: 0.000212, loss: 0.0816
2022-10-04 13:16:55 - train: epoch 0064, iter [00640, 01251], lr: 0.000212, loss: 0.0825
2022-10-04 13:17:24 - train: epoch 0064, iter [00650, 01251], lr: 0.000212, loss: 0.0873
2022-10-04 13:17:52 - train: epoch 0064, iter [00660, 01251], lr: 0.000212, loss: 0.0799
2022-10-04 13:18:20 - train: epoch 0064, iter [00670, 01251], lr: 0.000212, loss: 0.0899
2022-10-04 13:18:48 - train: epoch 0064, iter [00680, 01251], lr: 0.000212, loss: 0.0839
2022-10-04 13:19:17 - train: epoch 0064, iter [00690, 01251], lr: 0.000212, loss: 0.0882
2022-10-04 13:19:45 - train: epoch 0064, iter [00700, 01251], lr: 0.000212, loss: 0.0794
2022-10-04 13:20:14 - train: epoch 0064, iter [00710, 01251], lr: 0.000212, loss: 0.0935
2022-10-04 13:20:42 - train: epoch 0064, iter [00720, 01251], lr: 0.000212, loss: 0.0907
2022-10-04 13:21:10 - train: epoch 0064, iter [00730, 01251], lr: 0.000211, loss: 0.0806
2022-10-04 13:21:38 - train: epoch 0064, iter [00740, 01251], lr: 0.000211, loss: 0.0875
2022-10-04 13:22:07 - train: epoch 0064, iter [00750, 01251], lr: 0.000211, loss: 0.0871
2022-10-04 13:22:35 - train: epoch 0064, iter [00760, 01251], lr: 0.000211, loss: 0.0810
2022-10-04 13:23:03 - train: epoch 0064, iter [00770, 01251], lr: 0.000211, loss: 0.0839
2022-10-04 13:23:31 - train: epoch 0064, iter [00780, 01251], lr: 0.000211, loss: 0.0827
2022-10-04 13:24:00 - train: epoch 0064, iter [00790, 01251], lr: 0.000211, loss: 0.0840
2022-10-04 13:24:28 - train: epoch 0064, iter [00800, 01251], lr: 0.000211, loss: 0.0884
2022-10-04 13:24:56 - train: epoch 0064, iter [00810, 01251], lr: 0.000211, loss: 0.0870
2022-10-04 13:25:24 - train: epoch 0064, iter [00820, 01251], lr: 0.000211, loss: 0.0833
2022-10-04 13:25:53 - train: epoch 0064, iter [00830, 01251], lr: 0.000211, loss: 0.0818
2022-10-04 13:26:21 - train: epoch 0064, iter [00840, 01251], lr: 0.000211, loss: 0.0827
2022-10-04 13:26:49 - train: epoch 0064, iter [00850, 01251], lr: 0.000210, loss: 0.0845
2022-10-04 13:27:18 - train: epoch 0064, iter [00860, 01251], lr: 0.000210, loss: 0.0887
2022-10-04 13:27:46 - train: epoch 0064, iter [00870, 01251], lr: 0.000210, loss: 0.0870
2022-10-04 13:28:14 - train: epoch 0064, iter [00880, 01251], lr: 0.000210, loss: 0.0805
2022-10-04 13:28:43 - train: epoch 0064, iter [00890, 01251], lr: 0.000210, loss: 0.0820
2022-10-04 13:29:11 - train: epoch 0064, iter [00900, 01251], lr: 0.000210, loss: 0.0804
2022-10-04 13:29:39 - train: epoch 0064, iter [00910, 01251], lr: 0.000210, loss: 0.0855
2022-10-04 13:30:07 - train: epoch 0064, iter [00920, 01251], lr: 0.000210, loss: 0.0922
2022-10-04 13:30:35 - train: epoch 0064, iter [00930, 01251], lr: 0.000210, loss: 0.0811
2022-10-04 13:31:03 - train: epoch 0064, iter [00940, 01251], lr: 0.000210, loss: 0.0778
2022-10-04 13:31:32 - train: epoch 0064, iter [00950, 01251], lr: 0.000210, loss: 0.0838
2022-10-04 13:32:00 - train: epoch 0064, iter [00960, 01251], lr: 0.000210, loss: 0.0825
2022-10-04 13:32:29 - train: epoch 0064, iter [00970, 01251], lr: 0.000210, loss: 0.0826
2022-10-04 13:32:57 - train: epoch 0064, iter [00980, 01251], lr: 0.000209, loss: 0.0797
2022-10-04 13:33:26 - train: epoch 0064, iter [00990, 01251], lr: 0.000209, loss: 0.0910
2022-10-04 13:33:54 - train: epoch 0064, iter [01000, 01251], lr: 0.000209, loss: 0.0832
2022-10-04 13:34:23 - train: epoch 0064, iter [01010, 01251], lr: 0.000209, loss: 0.0849
2022-10-04 13:34:51 - train: epoch 0064, iter [01020, 01251], lr: 0.000209, loss: 0.0866
2022-10-04 13:35:19 - train: epoch 0064, iter [01030, 01251], lr: 0.000209, loss: 0.0928
2022-10-04 13:35:47 - train: epoch 0064, iter [01040, 01251], lr: 0.000209, loss: 0.0878
2022-10-04 13:36:16 - train: epoch 0064, iter [01050, 01251], lr: 0.000209, loss: 0.0873
2022-10-04 13:36:44 - train: epoch 0064, iter [01060, 01251], lr: 0.000209, loss: 0.0868
2022-10-04 13:37:13 - train: epoch 0064, iter [01070, 01251], lr: 0.000209, loss: 0.0880
2022-10-04 13:37:41 - train: epoch 0064, iter [01080, 01251], lr: 0.000209, loss: 0.0934
2022-10-04 13:38:09 - train: epoch 0064, iter [01090, 01251], lr: 0.000209, loss: 0.0865
2022-10-04 13:38:38 - train: epoch 0064, iter [01100, 01251], lr: 0.000208, loss: 0.0810
2022-10-04 13:39:06 - train: epoch 0064, iter [01110, 01251], lr: 0.000208, loss: 0.0817
2022-10-04 13:39:34 - train: epoch 0064, iter [01120, 01251], lr: 0.000208, loss: 0.0853
2022-10-04 13:40:02 - train: epoch 0064, iter [01130, 01251], lr: 0.000208, loss: 0.0909
2022-10-04 13:40:31 - train: epoch 0064, iter [01140, 01251], lr: 0.000208, loss: 0.0901
2022-10-04 13:40:59 - train: epoch 0064, iter [01150, 01251], lr: 0.000208, loss: 0.0825
2022-10-04 13:41:28 - train: epoch 0064, iter [01160, 01251], lr: 0.000208, loss: 0.0910
2022-10-04 13:41:56 - train: epoch 0064, iter [01170, 01251], lr: 0.000208, loss: 0.0907
2022-10-04 13:42:25 - train: epoch 0064, iter [01180, 01251], lr: 0.000208, loss: 0.0894
2022-10-04 13:42:53 - train: epoch 0064, iter [01190, 01251], lr: 0.000208, loss: 0.0855
2022-10-04 13:43:21 - train: epoch 0064, iter [01200, 01251], lr: 0.000208, loss: 0.0930
2022-10-04 13:43:49 - train: epoch 0064, iter [01210, 01251], lr: 0.000208, loss: 0.0823
2022-10-04 13:44:18 - train: epoch 0064, iter [01220, 01251], lr: 0.000208, loss: 0.0788
2022-10-04 13:44:46 - train: epoch 0064, iter [01230, 01251], lr: 0.000207, loss: 0.0901
2022-10-04 13:45:14 - train: epoch 0064, iter [01240, 01251], lr: 0.000207, loss: 0.0928
2022-10-04 13:45:42 - train: epoch 0064, iter [01250, 01251], lr: 0.000207, loss: 0.0826
2022-10-04 13:45:46 - train: epoch 064, train_loss: 0.0861
2022-10-04 13:45:48 - until epoch: 064, best_loss: 0.0861
2022-10-04 13:45:48 - epoch 065 lr: 0.000207
2022-10-04 13:46:24 - train: epoch 0065, iter [00010, 01251], lr: 0.000207, loss: 0.0813
2022-10-04 13:46:51 - train: epoch 0065, iter [00020, 01251], lr: 0.000207, loss: 0.0977
2022-10-04 13:47:20 - train: epoch 0065, iter [00030, 01251], lr: 0.000207, loss: 0.0816
2022-10-04 13:47:48 - train: epoch 0065, iter [00040, 01251], lr: 0.000207, loss: 0.0839
2022-10-04 13:48:16 - train: epoch 0065, iter [00050, 01251], lr: 0.000207, loss: 0.0827
2022-10-04 13:48:44 - train: epoch 0065, iter [00060, 01251], lr: 0.000207, loss: 0.0834
2022-10-04 13:49:13 - train: epoch 0065, iter [00070, 01251], lr: 0.000207, loss: 0.0821
2022-10-04 13:49:41 - train: epoch 0065, iter [00080, 01251], lr: 0.000207, loss: 0.0866
2022-10-04 13:50:09 - train: epoch 0065, iter [00090, 01251], lr: 0.000207, loss: 0.0910
2022-10-04 13:50:37 - train: epoch 0065, iter [00100, 01251], lr: 0.000206, loss: 0.0814
2022-10-04 13:51:05 - train: epoch 0065, iter [00110, 01251], lr: 0.000206, loss: 0.0837
2022-10-04 13:51:33 - train: epoch 0065, iter [00120, 01251], lr: 0.000206, loss: 0.0848
2022-10-04 13:52:02 - train: epoch 0065, iter [00130, 01251], lr: 0.000206, loss: 0.0888
2022-10-04 13:52:30 - train: epoch 0065, iter [00140, 01251], lr: 0.000206, loss: 0.0874
2022-10-04 13:52:58 - train: epoch 0065, iter [00150, 01251], lr: 0.000206, loss: 0.0837
2022-10-04 13:53:26 - train: epoch 0065, iter [00160, 01251], lr: 0.000206, loss: 0.0910
2022-10-04 13:53:55 - train: epoch 0065, iter [00170, 01251], lr: 0.000206, loss: 0.0844
2022-10-04 13:54:23 - train: epoch 0065, iter [00180, 01251], lr: 0.000206, loss: 0.0765
2022-10-04 13:54:51 - train: epoch 0065, iter [00190, 01251], lr: 0.000206, loss: 0.0780
2022-10-04 13:55:19 - train: epoch 0065, iter [00200, 01251], lr: 0.000206, loss: 0.0874
2022-10-04 13:55:48 - train: epoch 0065, iter [00210, 01251], lr: 0.000206, loss: 0.0847
2022-10-04 13:56:16 - train: epoch 0065, iter [00220, 01251], lr: 0.000206, loss: 0.0868
2022-10-04 13:56:44 - train: epoch 0065, iter [00230, 01251], lr: 0.000205, loss: 0.0790
2022-10-04 13:57:12 - train: epoch 0065, iter [00240, 01251], lr: 0.000205, loss: 0.0818
2022-10-04 13:57:40 - train: epoch 0065, iter [00250, 01251], lr: 0.000205, loss: 0.0854
2022-10-04 13:58:09 - train: epoch 0065, iter [00260, 01251], lr: 0.000205, loss: 0.0847
2022-10-04 13:58:37 - train: epoch 0065, iter [00270, 01251], lr: 0.000205, loss: 0.0906
2022-10-04 13:59:05 - train: epoch 0065, iter [00280, 01251], lr: 0.000205, loss: 0.0864
2022-10-04 13:59:33 - train: epoch 0065, iter [00290, 01251], lr: 0.000205, loss: 0.0812
2022-10-04 14:00:01 - train: epoch 0065, iter [00300, 01251], lr: 0.000205, loss: 0.0863
2022-10-04 14:00:30 - train: epoch 0065, iter [00310, 01251], lr: 0.000205, loss: 0.0873
2022-10-04 14:00:58 - train: epoch 0065, iter [00320, 01251], lr: 0.000205, loss: 0.0885
2022-10-04 14:01:26 - train: epoch 0065, iter [00330, 01251], lr: 0.000205, loss: 0.0890
2022-10-04 14:01:54 - train: epoch 0065, iter [00340, 01251], lr: 0.000205, loss: 0.0822
2022-10-04 14:02:23 - train: epoch 0065, iter [00350, 01251], lr: 0.000205, loss: 0.0838
2022-10-04 14:02:51 - train: epoch 0065, iter [00360, 01251], lr: 0.000204, loss: 0.0855
2022-10-04 14:03:19 - train: epoch 0065, iter [00370, 01251], lr: 0.000204, loss: 0.0891
2022-10-04 14:03:47 - train: epoch 0065, iter [00380, 01251], lr: 0.000204, loss: 0.0860
2022-10-04 14:04:15 - train: epoch 0065, iter [00390, 01251], lr: 0.000204, loss: 0.0865
2022-10-04 14:04:43 - train: epoch 0065, iter [00400, 01251], lr: 0.000204, loss: 0.0786
2022-10-04 14:05:12 - train: epoch 0065, iter [00410, 01251], lr: 0.000204, loss: 0.0857
2022-10-04 14:05:40 - train: epoch 0065, iter [00420, 01251], lr: 0.000204, loss: 0.0823
2022-10-04 14:06:08 - train: epoch 0065, iter [00430, 01251], lr: 0.000204, loss: 0.0853
2022-10-04 14:06:36 - train: epoch 0065, iter [00440, 01251], lr: 0.000204, loss: 0.0830
2022-10-04 14:07:04 - train: epoch 0065, iter [00450, 01251], lr: 0.000204, loss: 0.0827
2022-10-04 14:07:32 - train: epoch 0065, iter [00460, 01251], lr: 0.000204, loss: 0.0877
2022-10-04 14:08:00 - train: epoch 0065, iter [00470, 01251], lr: 0.000204, loss: 0.0900
2022-10-04 14:08:28 - train: epoch 0065, iter [00480, 01251], lr: 0.000203, loss: 0.0964
2022-10-04 14:08:57 - train: epoch 0065, iter [00490, 01251], lr: 0.000203, loss: 0.0846
2022-10-04 14:09:25 - train: epoch 0065, iter [00500, 01251], lr: 0.000203, loss: 0.0909
2022-10-04 14:09:53 - train: epoch 0065, iter [00510, 01251], lr: 0.000203, loss: 0.0880
2022-10-04 14:10:22 - train: epoch 0065, iter [00520, 01251], lr: 0.000203, loss: 0.0850
2022-10-04 14:10:50 - train: epoch 0065, iter [00530, 01251], lr: 0.000203, loss: 0.0841
2022-10-04 14:11:18 - train: epoch 0065, iter [00540, 01251], lr: 0.000203, loss: 0.0934
2022-10-04 14:11:46 - train: epoch 0065, iter [00550, 01251], lr: 0.000203, loss: 0.0873
2022-10-04 14:12:14 - train: epoch 0065, iter [00560, 01251], lr: 0.000203, loss: 0.0881
2022-10-04 14:12:43 - train: epoch 0065, iter [00570, 01251], lr: 0.000203, loss: 0.0842
2022-10-04 14:13:11 - train: epoch 0065, iter [00580, 01251], lr: 0.000203, loss: 0.0807
2022-10-04 14:13:39 - train: epoch 0065, iter [00590, 01251], lr: 0.000203, loss: 0.0854
2022-10-04 14:14:07 - train: epoch 0065, iter [00600, 01251], lr: 0.000203, loss: 0.0820
2022-10-04 14:14:36 - train: epoch 0065, iter [00610, 01251], lr: 0.000202, loss: 0.0837
2022-10-04 14:15:04 - train: epoch 0065, iter [00620, 01251], lr: 0.000202, loss: 0.0884
2022-10-04 14:15:32 - train: epoch 0065, iter [00630, 01251], lr: 0.000202, loss: 0.0830
2022-10-04 14:16:00 - train: epoch 0065, iter [00640, 01251], lr: 0.000202, loss: 0.0846
2022-10-04 14:16:28 - train: epoch 0065, iter [00650, 01251], lr: 0.000202, loss: 0.0852
2022-10-04 14:16:57 - train: epoch 0065, iter [00660, 01251], lr: 0.000202, loss: 0.0811
2022-10-04 14:17:25 - train: epoch 0065, iter [00670, 01251], lr: 0.000202, loss: 0.0927
2022-10-04 14:17:54 - train: epoch 0065, iter [00680, 01251], lr: 0.000202, loss: 0.0796
2022-10-04 14:18:22 - train: epoch 0065, iter [00690, 01251], lr: 0.000202, loss: 0.0837
2022-10-04 14:18:50 - train: epoch 0065, iter [00700, 01251], lr: 0.000202, loss: 0.0828
2022-10-04 14:19:18 - train: epoch 0065, iter [00710, 01251], lr: 0.000202, loss: 0.0827
2022-10-04 14:19:46 - train: epoch 0065, iter [00720, 01251], lr: 0.000202, loss: 0.0818
2022-10-04 14:20:15 - train: epoch 0065, iter [00730, 01251], lr: 0.000202, loss: 0.0807
2022-10-04 14:20:43 - train: epoch 0065, iter [00740, 01251], lr: 0.000201, loss: 0.0863
2022-10-04 14:21:11 - train: epoch 0065, iter [00750, 01251], lr: 0.000201, loss: 0.0843
2022-10-04 14:21:39 - train: epoch 0065, iter [00760, 01251], lr: 0.000201, loss: 0.0893
2022-10-04 14:22:08 - train: epoch 0065, iter [00770, 01251], lr: 0.000201, loss: 0.0813
2022-10-04 14:22:36 - train: epoch 0065, iter [00780, 01251], lr: 0.000201, loss: 0.0893
2022-10-04 14:23:04 - train: epoch 0065, iter [00790, 01251], lr: 0.000201, loss: 0.0846
2022-10-04 14:23:32 - train: epoch 0065, iter [00800, 01251], lr: 0.000201, loss: 0.0818
2022-10-04 14:24:01 - train: epoch 0065, iter [00810, 01251], lr: 0.000201, loss: 0.0869
2022-10-04 14:24:29 - train: epoch 0065, iter [00820, 01251], lr: 0.000201, loss: 0.0790
2022-10-04 14:24:57 - train: epoch 0065, iter [00830, 01251], lr: 0.000201, loss: 0.0784
2022-10-04 14:25:26 - train: epoch 0065, iter [00840, 01251], lr: 0.000201, loss: 0.0785
2022-10-04 14:25:54 - train: epoch 0065, iter [00850, 01251], lr: 0.000201, loss: 0.0862
2022-10-04 14:26:22 - train: epoch 0065, iter [00860, 01251], lr: 0.000200, loss: 0.0867
2022-10-04 14:26:50 - train: epoch 0065, iter [00870, 01251], lr: 0.000200, loss: 0.0877
2022-10-04 14:27:18 - train: epoch 0065, iter [00880, 01251], lr: 0.000200, loss: 0.0838
2022-10-04 14:27:46 - train: epoch 0065, iter [00890, 01251], lr: 0.000200, loss: 0.0821
2022-10-04 14:28:15 - train: epoch 0065, iter [00900, 01251], lr: 0.000200, loss: 0.0834
2022-10-04 14:28:43 - train: epoch 0065, iter [00910, 01251], lr: 0.000200, loss: 0.0835
2022-10-04 14:29:11 - train: epoch 0065, iter [00920, 01251], lr: 0.000200, loss: 0.0796
2022-10-04 14:29:40 - train: epoch 0065, iter [00930, 01251], lr: 0.000200, loss: 0.0904
2022-10-04 14:30:08 - train: epoch 0065, iter [00940, 01251], lr: 0.000200, loss: 0.0833
2022-10-04 14:30:37 - train: epoch 0065, iter [00950, 01251], lr: 0.000200, loss: 0.0810
2022-10-04 14:31:05 - train: epoch 0065, iter [00960, 01251], lr: 0.000200, loss: 0.0825
2022-10-04 14:31:33 - train: epoch 0065, iter [00970, 01251], lr: 0.000200, loss: 0.0922
2022-10-04 14:32:02 - train: epoch 0065, iter [00980, 01251], lr: 0.000200, loss: 0.0884
2022-10-04 14:32:30 - train: epoch 0065, iter [00990, 01251], lr: 0.000199, loss: 0.0865
2022-10-04 14:32:58 - train: epoch 0065, iter [01000, 01251], lr: 0.000199, loss: 0.0927
2022-10-04 14:33:26 - train: epoch 0065, iter [01010, 01251], lr: 0.000199, loss: 0.0852
2022-10-04 14:33:55 - train: epoch 0065, iter [01020, 01251], lr: 0.000199, loss: 0.0835
2022-10-04 14:34:23 - train: epoch 0065, iter [01030, 01251], lr: 0.000199, loss: 0.0879
2022-10-04 14:34:51 - train: epoch 0065, iter [01040, 01251], lr: 0.000199, loss: 0.0801
2022-10-04 14:35:19 - train: epoch 0065, iter [01050, 01251], lr: 0.000199, loss: 0.0864
2022-10-04 14:35:48 - train: epoch 0065, iter [01060, 01251], lr: 0.000199, loss: 0.0869
2022-10-04 14:36:16 - train: epoch 0065, iter [01070, 01251], lr: 0.000199, loss: 0.0838
2022-10-04 14:36:44 - train: epoch 0065, iter [01080, 01251], lr: 0.000199, loss: 0.0846
2022-10-04 14:37:13 - train: epoch 0065, iter [01090, 01251], lr: 0.000199, loss: 0.0827
2022-10-04 14:37:41 - train: epoch 0065, iter [01100, 01251], lr: 0.000199, loss: 0.0849
2022-10-04 14:38:09 - train: epoch 0065, iter [01110, 01251], lr: 0.000199, loss: 0.0876
2022-10-04 14:38:37 - train: epoch 0065, iter [01120, 01251], lr: 0.000198, loss: 0.0857
2022-10-04 14:39:05 - train: epoch 0065, iter [01130, 01251], lr: 0.000198, loss: 0.0811
2022-10-04 14:39:34 - train: epoch 0065, iter [01140, 01251], lr: 0.000198, loss: 0.0809
2022-10-04 14:40:02 - train: epoch 0065, iter [01150, 01251], lr: 0.000198, loss: 0.0830
2022-10-04 14:40:30 - train: epoch 0065, iter [01160, 01251], lr: 0.000198, loss: 0.0850
2022-10-04 14:40:59 - train: epoch 0065, iter [01170, 01251], lr: 0.000198, loss: 0.0807
2022-10-04 14:41:27 - train: epoch 0065, iter [01180, 01251], lr: 0.000198, loss: 0.0836
2022-10-04 14:41:55 - train: epoch 0065, iter [01190, 01251], lr: 0.000198, loss: 0.0877
2022-10-04 14:42:24 - train: epoch 0065, iter [01200, 01251], lr: 0.000198, loss: 0.0916
2022-10-04 14:42:52 - train: epoch 0065, iter [01210, 01251], lr: 0.000198, loss: 0.0853
2022-10-04 14:43:21 - train: epoch 0065, iter [01220, 01251], lr: 0.000198, loss: 0.0848
2022-10-04 14:43:49 - train: epoch 0065, iter [01230, 01251], lr: 0.000198, loss: 0.0866
2022-10-04 14:44:17 - train: epoch 0065, iter [01240, 01251], lr: 0.000197, loss: 0.0957
2022-10-04 14:44:45 - train: epoch 0065, iter [01250, 01251], lr: 0.000197, loss: 0.0821
2022-10-04 14:44:49 - train: epoch 065, train_loss: 0.0859
2022-10-04 14:44:51 - until epoch: 065, best_loss: 0.0859
2022-10-04 14:44:51 - epoch 066 lr: 0.000197
2022-10-04 14:45:26 - train: epoch 0066, iter [00010, 01251], lr: 0.000197, loss: 0.0831
2022-10-04 14:45:54 - train: epoch 0066, iter [00020, 01251], lr: 0.000197, loss: 0.0789
2022-10-04 14:46:23 - train: epoch 0066, iter [00030, 01251], lr: 0.000197, loss: 0.0873
2022-10-04 14:46:51 - train: epoch 0066, iter [00040, 01251], lr: 0.000197, loss: 0.0881
2022-10-04 14:47:19 - train: epoch 0066, iter [00050, 01251], lr: 0.000197, loss: 0.0840
2022-10-04 14:47:47 - train: epoch 0066, iter [00060, 01251], lr: 0.000197, loss: 0.0831
2022-10-04 14:48:16 - train: epoch 0066, iter [00070, 01251], lr: 0.000197, loss: 0.0815
2022-10-04 14:48:44 - train: epoch 0066, iter [00080, 01251], lr: 0.000197, loss: 0.0832
2022-10-04 14:49:12 - train: epoch 0066, iter [00090, 01251], lr: 0.000197, loss: 0.0849
2022-10-04 14:49:40 - train: epoch 0066, iter [00100, 01251], lr: 0.000197, loss: 0.0808
2022-10-04 14:50:09 - train: epoch 0066, iter [00110, 01251], lr: 0.000197, loss: 0.0999
2022-10-04 14:50:37 - train: epoch 0066, iter [00120, 01251], lr: 0.000196, loss: 0.0857
2022-10-04 14:51:05 - train: epoch 0066, iter [00130, 01251], lr: 0.000196, loss: 0.0835
2022-10-04 14:51:34 - train: epoch 0066, iter [00140, 01251], lr: 0.000196, loss: 0.0756
2022-10-04 14:52:02 - train: epoch 0066, iter [00150, 01251], lr: 0.000196, loss: 0.0889
2022-10-04 14:52:30 - train: epoch 0066, iter [00160, 01251], lr: 0.000196, loss: 0.0834
2022-10-04 14:52:58 - train: epoch 0066, iter [00170, 01251], lr: 0.000196, loss: 0.0862
2022-10-04 14:53:27 - train: epoch 0066, iter [00180, 01251], lr: 0.000196, loss: 0.0880
2022-10-04 14:53:55 - train: epoch 0066, iter [00190, 01251], lr: 0.000196, loss: 0.0904
2022-10-04 14:54:23 - train: epoch 0066, iter [00200, 01251], lr: 0.000196, loss: 0.0855
2022-10-04 14:54:52 - train: epoch 0066, iter [00210, 01251], lr: 0.000196, loss: 0.0835
2022-10-04 14:55:20 - train: epoch 0066, iter [00220, 01251], lr: 0.000196, loss: 0.0868
2022-10-04 14:55:48 - train: epoch 0066, iter [00230, 01251], lr: 0.000196, loss: 0.0812
2022-10-04 14:56:17 - train: epoch 0066, iter [00240, 01251], lr: 0.000196, loss: 0.0928
2022-10-04 14:56:45 - train: epoch 0066, iter [00250, 01251], lr: 0.000195, loss: 0.0885
2022-10-04 14:57:14 - train: epoch 0066, iter [00260, 01251], lr: 0.000195, loss: 0.0865
2022-10-04 14:57:42 - train: epoch 0066, iter [00270, 01251], lr: 0.000195, loss: 0.0794
2022-10-04 14:58:10 - train: epoch 0066, iter [00280, 01251], lr: 0.000195, loss: 0.0794
2022-10-04 14:58:39 - train: epoch 0066, iter [00290, 01251], lr: 0.000195, loss: 0.0873
2022-10-04 14:59:07 - train: epoch 0066, iter [00300, 01251], lr: 0.000195, loss: 0.0862
2022-10-04 14:59:35 - train: epoch 0066, iter [00310, 01251], lr: 0.000195, loss: 0.0901
2022-10-04 15:00:03 - train: epoch 0066, iter [00320, 01251], lr: 0.000195, loss: 0.0888
2022-10-04 15:00:32 - train: epoch 0066, iter [00330, 01251], lr: 0.000195, loss: 0.0880
2022-10-04 15:01:00 - train: epoch 0066, iter [00340, 01251], lr: 0.000195, loss: 0.0861
2022-10-04 15:01:29 - train: epoch 0066, iter [00350, 01251], lr: 0.000195, loss: 0.0869
2022-10-04 15:01:57 - train: epoch 0066, iter [00360, 01251], lr: 0.000195, loss: 0.0858
2022-10-04 15:02:25 - train: epoch 0066, iter [00370, 01251], lr: 0.000194, loss: 0.0843
2022-10-04 15:02:53 - train: epoch 0066, iter [00380, 01251], lr: 0.000194, loss: 0.0812
2022-10-04 15:03:21 - train: epoch 0066, iter [00390, 01251], lr: 0.000194, loss: 0.0820
2022-10-04 15:03:49 - train: epoch 0066, iter [00400, 01251], lr: 0.000194, loss: 0.0797
2022-10-04 15:04:18 - train: epoch 0066, iter [00410, 01251], lr: 0.000194, loss: 0.0865
2022-10-04 15:04:46 - train: epoch 0066, iter [00420, 01251], lr: 0.000194, loss: 0.0868
2022-10-04 15:05:14 - train: epoch 0066, iter [00430, 01251], lr: 0.000194, loss: 0.0818
2022-10-04 15:05:42 - train: epoch 0066, iter [00440, 01251], lr: 0.000194, loss: 0.0881
2022-10-04 15:06:10 - train: epoch 0066, iter [00450, 01251], lr: 0.000194, loss: 0.0874
2022-10-04 15:06:39 - train: epoch 0066, iter [00460, 01251], lr: 0.000194, loss: 0.0874
2022-10-04 15:07:07 - train: epoch 0066, iter [00470, 01251], lr: 0.000194, loss: 0.0931
2022-10-04 15:07:35 - train: epoch 0066, iter [00480, 01251], lr: 0.000194, loss: 0.0800
2022-10-04 15:08:03 - train: epoch 0066, iter [00490, 01251], lr: 0.000194, loss: 0.0784
2022-10-04 15:08:31 - train: epoch 0066, iter [00500, 01251], lr: 0.000193, loss: 0.0854
2022-10-04 15:09:00 - train: epoch 0066, iter [00510, 01251], lr: 0.000193, loss: 0.0776
2022-10-04 15:09:28 - train: epoch 0066, iter [00520, 01251], lr: 0.000193, loss: 0.0930
2022-10-04 15:09:56 - train: epoch 0066, iter [00530, 01251], lr: 0.000193, loss: 0.0860
2022-10-04 15:10:24 - train: epoch 0066, iter [00540, 01251], lr: 0.000193, loss: 0.0865
2022-10-04 15:10:53 - train: epoch 0066, iter [00550, 01251], lr: 0.000193, loss: 0.0891
2022-10-04 15:11:21 - train: epoch 0066, iter [00560, 01251], lr: 0.000193, loss: 0.0785
2022-10-04 15:11:49 - train: epoch 0066, iter [00570, 01251], lr: 0.000193, loss: 0.0834
2022-10-04 15:12:17 - train: epoch 0066, iter [00580, 01251], lr: 0.000193, loss: 0.0775
2022-10-04 15:12:46 - train: epoch 0066, iter [00590, 01251], lr: 0.000193, loss: 0.0853
2022-10-04 15:13:14 - train: epoch 0066, iter [00600, 01251], lr: 0.000193, loss: 0.0735
2022-10-04 15:13:42 - train: epoch 0066, iter [00610, 01251], lr: 0.000193, loss: 0.0906
2022-10-04 15:14:11 - train: epoch 0066, iter [00620, 01251], lr: 0.000193, loss: 0.0876
2022-10-04 15:14:39 - train: epoch 0066, iter [00630, 01251], lr: 0.000192, loss: 0.0872
2022-10-04 15:15:07 - train: epoch 0066, iter [00640, 01251], lr: 0.000192, loss: 0.0828
2022-10-04 15:15:35 - train: epoch 0066, iter [00650, 01251], lr: 0.000192, loss: 0.0811
2022-10-04 15:16:03 - train: epoch 0066, iter [00660, 01251], lr: 0.000192, loss: 0.0866
2022-10-04 15:16:31 - train: epoch 0066, iter [00670, 01251], lr: 0.000192, loss: 0.0896
2022-10-04 15:17:00 - train: epoch 0066, iter [00680, 01251], lr: 0.000192, loss: 0.0864
2022-10-04 15:17:28 - train: epoch 0066, iter [00690, 01251], lr: 0.000192, loss: 0.0940
2022-10-04 15:17:56 - train: epoch 0066, iter [00700, 01251], lr: 0.000192, loss: 0.0894
2022-10-04 15:18:24 - train: epoch 0066, iter [00710, 01251], lr: 0.000192, loss: 0.0804
2022-10-04 15:18:52 - train: epoch 0066, iter [00720, 01251], lr: 0.000192, loss: 0.0840
2022-10-04 15:19:21 - train: epoch 0066, iter [00730, 01251], lr: 0.000192, loss: 0.0830
2022-10-04 15:19:49 - train: epoch 0066, iter [00740, 01251], lr: 0.000192, loss: 0.0901
2022-10-04 15:20:17 - train: epoch 0066, iter [00750, 01251], lr: 0.000192, loss: 0.0876
2022-10-04 15:20:46 - train: epoch 0066, iter [00760, 01251], lr: 0.000191, loss: 0.0793
2022-10-04 15:21:14 - train: epoch 0066, iter [00770, 01251], lr: 0.000191, loss: 0.0811
2022-10-04 15:21:42 - train: epoch 0066, iter [00780, 01251], lr: 0.000191, loss: 0.0931
2022-10-04 15:22:10 - train: epoch 0066, iter [00790, 01251], lr: 0.000191, loss: 0.0824
2022-10-04 15:22:39 - train: epoch 0066, iter [00800, 01251], lr: 0.000191, loss: 0.0801
2022-10-04 15:23:07 - train: epoch 0066, iter [00810, 01251], lr: 0.000191, loss: 0.0888
2022-10-04 15:23:35 - train: epoch 0066, iter [00820, 01251], lr: 0.000191, loss: 0.0920
2022-10-04 15:24:04 - train: epoch 0066, iter [00830, 01251], lr: 0.000191, loss: 0.0873
2022-10-04 15:24:32 - train: epoch 0066, iter [00840, 01251], lr: 0.000191, loss: 0.0866
2022-10-04 15:25:00 - train: epoch 0066, iter [00850, 01251], lr: 0.000191, loss: 0.0866
2022-10-04 15:25:29 - train: epoch 0066, iter [00860, 01251], lr: 0.000191, loss: 0.0840
2022-10-04 15:25:57 - train: epoch 0066, iter [00870, 01251], lr: 0.000191, loss: 0.0929
2022-10-04 15:26:25 - train: epoch 0066, iter [00880, 01251], lr: 0.000191, loss: 0.0847
2022-10-04 15:26:54 - train: epoch 0066, iter [00890, 01251], lr: 0.000190, loss: 0.0832
2022-10-04 15:27:22 - train: epoch 0066, iter [00900, 01251], lr: 0.000190, loss: 0.0858
2022-10-04 15:27:50 - train: epoch 0066, iter [00910, 01251], lr: 0.000190, loss: 0.0791
2022-10-04 15:28:19 - train: epoch 0066, iter [00920, 01251], lr: 0.000190, loss: 0.0779
2022-10-04 15:28:47 - train: epoch 0066, iter [00930, 01251], lr: 0.000190, loss: 0.0888
2022-10-04 15:29:15 - train: epoch 0066, iter [00940, 01251], lr: 0.000190, loss: 0.0895
2022-10-04 15:29:43 - train: epoch 0066, iter [00950, 01251], lr: 0.000190, loss: 0.0873
2022-10-04 15:30:11 - train: epoch 0066, iter [00960, 01251], lr: 0.000190, loss: 0.0790
2022-10-04 15:30:40 - train: epoch 0066, iter [00970, 01251], lr: 0.000190, loss: 0.0819
2022-10-04 15:31:08 - train: epoch 0066, iter [00980, 01251], lr: 0.000190, loss: 0.0827
2022-10-04 15:31:36 - train: epoch 0066, iter [00990, 01251], lr: 0.000190, loss: 0.0874
2022-10-04 15:32:04 - train: epoch 0066, iter [01000, 01251], lr: 0.000190, loss: 0.0825
2022-10-04 15:32:33 - train: epoch 0066, iter [01010, 01251], lr: 0.000189, loss: 0.0855
2022-10-04 15:33:01 - train: epoch 0066, iter [01020, 01251], lr: 0.000189, loss: 0.0821
2022-10-04 15:33:29 - train: epoch 0066, iter [01030, 01251], lr: 0.000189, loss: 0.0841
2022-10-04 15:33:57 - train: epoch 0066, iter [01040, 01251], lr: 0.000189, loss: 0.0900
2022-10-04 15:34:25 - train: epoch 0066, iter [01050, 01251], lr: 0.000189, loss: 0.0874
2022-10-04 15:34:54 - train: epoch 0066, iter [01060, 01251], lr: 0.000189, loss: 0.0844
2022-10-04 15:35:22 - train: epoch 0066, iter [01070, 01251], lr: 0.000189, loss: 0.0882
2022-10-04 15:35:50 - train: epoch 0066, iter [01080, 01251], lr: 0.000189, loss: 0.0826
2022-10-04 15:36:19 - train: epoch 0066, iter [01090, 01251], lr: 0.000189, loss: 0.0884
2022-10-04 15:36:47 - train: epoch 0066, iter [01100, 01251], lr: 0.000189, loss: 0.0841
2022-10-04 15:37:15 - train: epoch 0066, iter [01110, 01251], lr: 0.000189, loss: 0.0896
2022-10-04 15:37:43 - train: epoch 0066, iter [01120, 01251], lr: 0.000189, loss: 0.0850
2022-10-04 15:38:12 - train: epoch 0066, iter [01130, 01251], lr: 0.000189, loss: 0.0877
2022-10-04 15:38:40 - train: epoch 0066, iter [01140, 01251], lr: 0.000188, loss: 0.0899
2022-10-04 15:39:08 - train: epoch 0066, iter [01150, 01251], lr: 0.000188, loss: 0.0909
2022-10-04 15:39:37 - train: epoch 0066, iter [01160, 01251], lr: 0.000188, loss: 0.0845
2022-10-04 15:40:05 - train: epoch 0066, iter [01170, 01251], lr: 0.000188, loss: 0.0948
2022-10-04 15:40:33 - train: epoch 0066, iter [01180, 01251], lr: 0.000188, loss: 0.0854
2022-10-04 15:41:01 - train: epoch 0066, iter [01190, 01251], lr: 0.000188, loss: 0.0838
2022-10-04 15:41:30 - train: epoch 0066, iter [01200, 01251], lr: 0.000188, loss: 0.0813
2022-10-04 15:41:58 - train: epoch 0066, iter [01210, 01251], lr: 0.000188, loss: 0.0809
2022-10-04 15:42:26 - train: epoch 0066, iter [01220, 01251], lr: 0.000188, loss: 0.0816
2022-10-04 15:42:54 - train: epoch 0066, iter [01230, 01251], lr: 0.000188, loss: 0.0884
2022-10-04 15:43:23 - train: epoch 0066, iter [01240, 01251], lr: 0.000188, loss: 0.0844
2022-10-04 15:43:51 - train: epoch 0066, iter [01250, 01251], lr: 0.000188, loss: 0.0893
2022-10-04 15:43:55 - train: epoch 066, train_loss: 0.0856
2022-10-04 15:43:57 - until epoch: 066, best_loss: 0.0856
2022-10-04 15:43:57 - epoch 067 lr: 0.000188
2022-10-04 15:44:32 - train: epoch 0067, iter [00010, 01251], lr: 0.000188, loss: 0.0782
2022-10-04 15:45:00 - train: epoch 0067, iter [00020, 01251], lr: 0.000187, loss: 0.0847
2022-10-04 15:45:28 - train: epoch 0067, iter [00030, 01251], lr: 0.000187, loss: 0.0845
2022-10-04 15:45:56 - train: epoch 0067, iter [00040, 01251], lr: 0.000187, loss: 0.0867
2022-10-04 15:46:25 - train: epoch 0067, iter [00050, 01251], lr: 0.000187, loss: 0.0882
2022-10-04 15:46:53 - train: epoch 0067, iter [00060, 01251], lr: 0.000187, loss: 0.0859
2022-10-04 15:47:21 - train: epoch 0067, iter [00070, 01251], lr: 0.000187, loss: 0.0860
2022-10-04 15:47:49 - train: epoch 0067, iter [00080, 01251], lr: 0.000187, loss: 0.0857
2022-10-04 15:48:18 - train: epoch 0067, iter [00090, 01251], lr: 0.000187, loss: 0.0822
2022-10-04 15:48:46 - train: epoch 0067, iter [00100, 01251], lr: 0.000187, loss: 0.0835
2022-10-04 15:49:14 - train: epoch 0067, iter [00110, 01251], lr: 0.000187, loss: 0.0879
2022-10-04 15:49:42 - train: epoch 0067, iter [00120, 01251], lr: 0.000187, loss: 0.0816
2022-10-04 15:50:10 - train: epoch 0067, iter [00130, 01251], lr: 0.000187, loss: 0.0860
2022-10-04 15:50:39 - train: epoch 0067, iter [00140, 01251], lr: 0.000187, loss: 0.0883
2022-10-04 15:51:07 - train: epoch 0067, iter [00150, 01251], lr: 0.000186, loss: 0.0880
2022-10-04 15:51:35 - train: epoch 0067, iter [00160, 01251], lr: 0.000186, loss: 0.0873
2022-10-04 15:52:03 - train: epoch 0067, iter [00170, 01251], lr: 0.000186, loss: 0.0788
2022-10-04 15:52:32 - train: epoch 0067, iter [00180, 01251], lr: 0.000186, loss: 0.0808
2022-10-04 15:53:00 - train: epoch 0067, iter [00190, 01251], lr: 0.000186, loss: 0.0885
2022-10-04 15:53:28 - train: epoch 0067, iter [00200, 01251], lr: 0.000186, loss: 0.0789
2022-10-04 15:53:56 - train: epoch 0067, iter [00210, 01251], lr: 0.000186, loss: 0.0819
2022-10-04 15:54:25 - train: epoch 0067, iter [00220, 01251], lr: 0.000186, loss: 0.0791
2022-10-04 15:54:53 - train: epoch 0067, iter [00230, 01251], lr: 0.000186, loss: 0.0851
2022-10-04 15:55:21 - train: epoch 0067, iter [00240, 01251], lr: 0.000186, loss: 0.0830
2022-10-04 15:55:49 - train: epoch 0067, iter [00250, 01251], lr: 0.000186, loss: 0.0791
2022-10-04 15:56:18 - train: epoch 0067, iter [00260, 01251], lr: 0.000186, loss: 0.0847
2022-10-04 15:56:46 - train: epoch 0067, iter [00270, 01251], lr: 0.000186, loss: 0.0826
2022-10-04 15:57:14 - train: epoch 0067, iter [00280, 01251], lr: 0.000185, loss: 0.0850
2022-10-04 15:57:42 - train: epoch 0067, iter [00290, 01251], lr: 0.000185, loss: 0.0836
2022-10-04 15:58:10 - train: epoch 0067, iter [00300, 01251], lr: 0.000185, loss: 0.0935
2022-10-04 15:58:39 - train: epoch 0067, iter [00310, 01251], lr: 0.000185, loss: 0.0860
2022-10-04 15:59:07 - train: epoch 0067, iter [00320, 01251], lr: 0.000185, loss: 0.0869
2022-10-04 15:59:35 - train: epoch 0067, iter [00330, 01251], lr: 0.000185, loss: 0.0896
2022-10-04 16:00:03 - train: epoch 0067, iter [00340, 01251], lr: 0.000185, loss: 0.0826
2022-10-04 16:00:31 - train: epoch 0067, iter [00350, 01251], lr: 0.000185, loss: 0.0774
2022-10-04 16:01:00 - train: epoch 0067, iter [00360, 01251], lr: 0.000185, loss: 0.0872
2022-10-04 16:01:28 - train: epoch 0067, iter [00370, 01251], lr: 0.000185, loss: 0.0867
2022-10-04 16:01:56 - train: epoch 0067, iter [00380, 01251], lr: 0.000185, loss: 0.0894
2022-10-04 16:02:24 - train: epoch 0067, iter [00390, 01251], lr: 0.000185, loss: 0.0826
2022-10-04 16:02:53 - train: epoch 0067, iter [00400, 01251], lr: 0.000185, loss: 0.0896
2022-10-04 16:03:21 - train: epoch 0067, iter [00410, 01251], lr: 0.000184, loss: 0.0823
2022-10-04 16:03:49 - train: epoch 0067, iter [00420, 01251], lr: 0.000184, loss: 0.0924
2022-10-04 16:04:18 - train: epoch 0067, iter [00430, 01251], lr: 0.000184, loss: 0.0843
2022-10-04 16:04:46 - train: epoch 0067, iter [00440, 01251], lr: 0.000184, loss: 0.0891
2022-10-04 16:05:14 - train: epoch 0067, iter [00450, 01251], lr: 0.000184, loss: 0.0857
2022-10-04 16:05:42 - train: epoch 0067, iter [00460, 01251], lr: 0.000184, loss: 0.0890
2022-10-04 16:06:11 - train: epoch 0067, iter [00470, 01251], lr: 0.000184, loss: 0.0747
2022-10-04 16:06:39 - train: epoch 0067, iter [00480, 01251], lr: 0.000184, loss: 0.0814
2022-10-04 16:07:08 - train: epoch 0067, iter [00490, 01251], lr: 0.000184, loss: 0.0826
2022-10-04 16:07:36 - train: epoch 0067, iter [00500, 01251], lr: 0.000184, loss: 0.0878
2022-10-04 16:08:04 - train: epoch 0067, iter [00510, 01251], lr: 0.000184, loss: 0.0878
2022-10-04 16:08:32 - train: epoch 0067, iter [00520, 01251], lr: 0.000184, loss: 0.0902
2022-10-04 16:09:00 - train: epoch 0067, iter [00530, 01251], lr: 0.000184, loss: 0.0824
2022-10-04 16:09:28 - train: epoch 0067, iter [00540, 01251], lr: 0.000183, loss: 0.0823
2022-10-04 16:09:57 - train: epoch 0067, iter [00550, 01251], lr: 0.000183, loss: 0.0881
2022-10-04 16:10:25 - train: epoch 0067, iter [00560, 01251], lr: 0.000183, loss: 0.0799
2022-10-04 16:10:53 - train: epoch 0067, iter [00570, 01251], lr: 0.000183, loss: 0.0833
2022-10-04 16:11:22 - train: epoch 0067, iter [00580, 01251], lr: 0.000183, loss: 0.0883
2022-10-04 16:11:50 - train: epoch 0067, iter [00590, 01251], lr: 0.000183, loss: 0.0947
2022-10-04 16:12:18 - train: epoch 0067, iter [00600, 01251], lr: 0.000183, loss: 0.0893
2022-10-04 16:12:47 - train: epoch 0067, iter [00610, 01251], lr: 0.000183, loss: 0.0840
2022-10-04 16:13:15 - train: epoch 0067, iter [00620, 01251], lr: 0.000183, loss: 0.0875
2022-10-04 16:13:43 - train: epoch 0067, iter [00630, 01251], lr: 0.000183, loss: 0.0898
2022-10-04 16:14:11 - train: epoch 0067, iter [00640, 01251], lr: 0.000183, loss: 0.0871
2022-10-04 16:14:40 - train: epoch 0067, iter [00650, 01251], lr: 0.000183, loss: 0.0810
2022-10-04 16:15:08 - train: epoch 0067, iter [00660, 01251], lr: 0.000183, loss: 0.0967
2022-10-04 16:15:36 - train: epoch 0067, iter [00670, 01251], lr: 0.000182, loss: 0.0942
2022-10-04 16:16:05 - train: epoch 0067, iter [00680, 01251], lr: 0.000182, loss: 0.0892
2022-10-04 16:16:33 - train: epoch 0067, iter [00690, 01251], lr: 0.000182, loss: 0.0844
2022-10-04 16:17:01 - train: epoch 0067, iter [00700, 01251], lr: 0.000182, loss: 0.0819
2022-10-04 16:17:29 - train: epoch 0067, iter [00710, 01251], lr: 0.000182, loss: 0.0827
2022-10-04 16:17:58 - train: epoch 0067, iter [00720, 01251], lr: 0.000182, loss: 0.0845
2022-10-04 16:18:26 - train: epoch 0067, iter [00730, 01251], lr: 0.000182, loss: 0.0829
2022-10-04 16:18:55 - train: epoch 0067, iter [00740, 01251], lr: 0.000182, loss: 0.0829
2022-10-04 16:19:23 - train: epoch 0067, iter [00750, 01251], lr: 0.000182, loss: 0.0943
2022-10-04 16:19:51 - train: epoch 0067, iter [00760, 01251], lr: 0.000182, loss: 0.0812
2022-10-04 16:20:20 - train: epoch 0067, iter [00770, 01251], lr: 0.000182, loss: 0.0892
2022-10-04 16:20:48 - train: epoch 0067, iter [00780, 01251], lr: 0.000182, loss: 0.0886
2022-10-04 16:21:16 - train: epoch 0067, iter [00790, 01251], lr: 0.000182, loss: 0.0810
2022-10-04 16:21:45 - train: epoch 0067, iter [00800, 01251], lr: 0.000181, loss: 0.0920
2022-10-04 16:22:13 - train: epoch 0067, iter [00810, 01251], lr: 0.000181, loss: 0.0786
2022-10-04 16:22:41 - train: epoch 0067, iter [00820, 01251], lr: 0.000181, loss: 0.0814
2022-10-04 16:23:09 - train: epoch 0067, iter [00830, 01251], lr: 0.000181, loss: 0.0883
2022-10-04 16:23:37 - train: epoch 0067, iter [00840, 01251], lr: 0.000181, loss: 0.0863
2022-10-04 16:24:06 - train: epoch 0067, iter [00850, 01251], lr: 0.000181, loss: 0.0883
2022-10-04 16:24:34 - train: epoch 0067, iter [00860, 01251], lr: 0.000181, loss: 0.0867
2022-10-04 16:25:02 - train: epoch 0067, iter [00870, 01251], lr: 0.000181, loss: 0.0785
2022-10-04 16:25:30 - train: epoch 0067, iter [00880, 01251], lr: 0.000181, loss: 0.0809
2022-10-04 16:25:59 - train: epoch 0067, iter [00890, 01251], lr: 0.000181, loss: 0.0819
2022-10-04 16:26:27 - train: epoch 0067, iter [00900, 01251], lr: 0.000181, loss: 0.0877
2022-10-04 16:26:55 - train: epoch 0067, iter [00910, 01251], lr: 0.000181, loss: 0.0882
2022-10-04 16:27:24 - train: epoch 0067, iter [00920, 01251], lr: 0.000181, loss: 0.0828
2022-10-04 16:27:52 - train: epoch 0067, iter [00930, 01251], lr: 0.000180, loss: 0.0931
2022-10-04 16:28:20 - train: epoch 0067, iter [00940, 01251], lr: 0.000180, loss: 0.0949
2022-10-04 16:28:49 - train: epoch 0067, iter [00950, 01251], lr: 0.000180, loss: 0.0778
2022-10-04 16:29:17 - train: epoch 0067, iter [00960, 01251], lr: 0.000180, loss: 0.0784
2022-10-04 16:29:45 - train: epoch 0067, iter [00970, 01251], lr: 0.000180, loss: 0.0943
2022-10-04 16:30:14 - train: epoch 0067, iter [00980, 01251], lr: 0.000180, loss: 0.0892
2022-10-04 16:30:42 - train: epoch 0067, iter [00990, 01251], lr: 0.000180, loss: 0.0819
2022-10-04 16:31:10 - train: epoch 0067, iter [01000, 01251], lr: 0.000180, loss: 0.0878
2022-10-04 16:31:39 - train: epoch 0067, iter [01010, 01251], lr: 0.000180, loss: 0.0913
2022-10-04 16:32:07 - train: epoch 0067, iter [01020, 01251], lr: 0.000180, loss: 0.0820
2022-10-04 16:32:35 - train: epoch 0067, iter [01030, 01251], lr: 0.000180, loss: 0.0861
2022-10-04 16:33:03 - train: epoch 0067, iter [01040, 01251], lr: 0.000180, loss: 0.0829
2022-10-04 16:33:31 - train: epoch 0067, iter [01050, 01251], lr: 0.000180, loss: 0.0883
2022-10-04 16:34:00 - train: epoch 0067, iter [01060, 01251], lr: 0.000179, loss: 0.0948
2022-10-04 16:34:28 - train: epoch 0067, iter [01070, 01251], lr: 0.000179, loss: 0.0800
2022-10-04 16:34:56 - train: epoch 0067, iter [01080, 01251], lr: 0.000179, loss: 0.0941
2022-10-04 16:35:24 - train: epoch 0067, iter [01090, 01251], lr: 0.000179, loss: 0.0816
2022-10-04 16:35:52 - train: epoch 0067, iter [01100, 01251], lr: 0.000179, loss: 0.0822
2022-10-04 16:36:21 - train: epoch 0067, iter [01110, 01251], lr: 0.000179, loss: 0.0835
2022-10-04 16:36:49 - train: epoch 0067, iter [01120, 01251], lr: 0.000179, loss: 0.0851
2022-10-04 16:37:17 - train: epoch 0067, iter [01130, 01251], lr: 0.000179, loss: 0.0780
2022-10-04 16:37:46 - train: epoch 0067, iter [01140, 01251], lr: 0.000179, loss: 0.0932
2022-10-04 16:38:14 - train: epoch 0067, iter [01150, 01251], lr: 0.000179, loss: 0.0906
2022-10-04 16:38:42 - train: epoch 0067, iter [01160, 01251], lr: 0.000179, loss: 0.0890
2022-10-04 16:39:10 - train: epoch 0067, iter [01170, 01251], lr: 0.000179, loss: 0.0770
2022-10-04 16:39:38 - train: epoch 0067, iter [01180, 01251], lr: 0.000179, loss: 0.0872
2022-10-04 16:40:06 - train: epoch 0067, iter [01190, 01251], lr: 0.000178, loss: 0.0855
2022-10-04 16:40:35 - train: epoch 0067, iter [01200, 01251], lr: 0.000178, loss: 0.0860
2022-10-04 16:41:03 - train: epoch 0067, iter [01210, 01251], lr: 0.000178, loss: 0.0842
2022-10-04 16:41:31 - train: epoch 0067, iter [01220, 01251], lr: 0.000178, loss: 0.0867
2022-10-04 16:41:59 - train: epoch 0067, iter [01230, 01251], lr: 0.000178, loss: 0.0860
2022-10-04 16:42:28 - train: epoch 0067, iter [01240, 01251], lr: 0.000178, loss: 0.0880
2022-10-04 16:42:56 - train: epoch 0067, iter [01250, 01251], lr: 0.000178, loss: 0.0932
2022-10-04 16:43:00 - train: epoch 067, train_loss: 0.0853
2022-10-04 16:43:02 - until epoch: 067, best_loss: 0.0853
2022-10-04 16:43:02 - epoch 068 lr: 0.000178
2022-10-04 16:43:37 - train: epoch 0068, iter [00010, 01251], lr: 0.000178, loss: 0.0833
2022-10-04 16:44:05 - train: epoch 0068, iter [00020, 01251], lr: 0.000178, loss: 0.0859
2022-10-04 16:44:33 - train: epoch 0068, iter [00030, 01251], lr: 0.000178, loss: 0.0864
2022-10-04 16:45:01 - train: epoch 0068, iter [00040, 01251], lr: 0.000178, loss: 0.0884
2022-10-04 16:45:29 - train: epoch 0068, iter [00050, 01251], lr: 0.000178, loss: 0.0848
2022-10-04 16:45:57 - train: epoch 0068, iter [00060, 01251], lr: 0.000178, loss: 0.0816
2022-10-04 16:46:26 - train: epoch 0068, iter [00070, 01251], lr: 0.000177, loss: 0.0839
2022-10-04 16:46:54 - train: epoch 0068, iter [00080, 01251], lr: 0.000177, loss: 0.0883
2022-10-04 16:47:22 - train: epoch 0068, iter [00090, 01251], lr: 0.000177, loss: 0.0770
2022-10-04 16:47:50 - train: epoch 0068, iter [00100, 01251], lr: 0.000177, loss: 0.0850
2022-10-04 16:48:19 - train: epoch 0068, iter [00110, 01251], lr: 0.000177, loss: 0.0800
2022-10-04 16:48:47 - train: epoch 0068, iter [00120, 01251], lr: 0.000177, loss: 0.0817
2022-10-04 16:49:15 - train: epoch 0068, iter [00130, 01251], lr: 0.000177, loss: 0.0833
2022-10-04 16:49:43 - train: epoch 0068, iter [00140, 01251], lr: 0.000177, loss: 0.0905
2022-10-04 16:50:11 - train: epoch 0068, iter [00150, 01251], lr: 0.000177, loss: 0.0842
2022-10-04 16:50:39 - train: epoch 0068, iter [00160, 01251], lr: 0.000177, loss: 0.0947
2022-10-04 16:51:08 - train: epoch 0068, iter [00170, 01251], lr: 0.000177, loss: 0.0914
2022-10-04 16:51:36 - train: epoch 0068, iter [00180, 01251], lr: 0.000177, loss: 0.0906
2022-10-04 16:52:04 - train: epoch 0068, iter [00190, 01251], lr: 0.000177, loss: 0.0865
2022-10-04 16:52:32 - train: epoch 0068, iter [00200, 01251], lr: 0.000176, loss: 0.0882
2022-10-04 16:53:01 - train: epoch 0068, iter [00210, 01251], lr: 0.000176, loss: 0.0883
2022-10-04 16:53:29 - train: epoch 0068, iter [00220, 01251], lr: 0.000176, loss: 0.0904
2022-10-04 16:53:57 - train: epoch 0068, iter [00230, 01251], lr: 0.000176, loss: 0.0880
2022-10-04 16:54:26 - train: epoch 0068, iter [00240, 01251], lr: 0.000176, loss: 0.0782
2022-10-04 16:54:54 - train: epoch 0068, iter [00250, 01251], lr: 0.000176, loss: 0.0882
2022-10-04 16:55:22 - train: epoch 0068, iter [00260, 01251], lr: 0.000176, loss: 0.0796
2022-10-04 16:55:50 - train: epoch 0068, iter [00270, 01251], lr: 0.000176, loss: 0.0843
2022-10-04 16:56:19 - train: epoch 0068, iter [00280, 01251], lr: 0.000176, loss: 0.0907
2022-10-04 16:56:47 - train: epoch 0068, iter [00290, 01251], lr: 0.000176, loss: 0.0815
2022-10-04 16:57:15 - train: epoch 0068, iter [00300, 01251], lr: 0.000176, loss: 0.0863
2022-10-04 16:57:44 - train: epoch 0068, iter [00310, 01251], lr: 0.000176, loss: 0.0879
2022-10-04 16:58:11 - train: epoch 0068, iter [00320, 01251], lr: 0.000176, loss: 0.0922
2022-10-04 16:58:40 - train: epoch 0068, iter [00330, 01251], lr: 0.000175, loss: 0.0843
2022-10-04 16:59:08 - train: epoch 0068, iter [00340, 01251], lr: 0.000175, loss: 0.0848
2022-10-04 16:59:36 - train: epoch 0068, iter [00350, 01251], lr: 0.000175, loss: 0.0837
2022-10-04 17:00:05 - train: epoch 0068, iter [00360, 01251], lr: 0.000175, loss: 0.0794
2022-10-04 17:00:33 - train: epoch 0068, iter [00370, 01251], lr: 0.000175, loss: 0.0860
2022-10-04 17:01:01 - train: epoch 0068, iter [00380, 01251], lr: 0.000175, loss: 0.0828
2022-10-04 17:01:29 - train: epoch 0068, iter [00390, 01251], lr: 0.000175, loss: 0.0857
2022-10-04 17:01:58 - train: epoch 0068, iter [00400, 01251], lr: 0.000175, loss: 0.0833
2022-10-04 17:02:26 - train: epoch 0068, iter [00410, 01251], lr: 0.000175, loss: 0.0908
2022-10-04 17:02:54 - train: epoch 0068, iter [00420, 01251], lr: 0.000175, loss: 0.0867
2022-10-04 17:03:23 - train: epoch 0068, iter [00430, 01251], lr: 0.000175, loss: 0.0834
2022-10-04 17:03:51 - train: epoch 0068, iter [00440, 01251], lr: 0.000175, loss: 0.0881
2022-10-04 17:04:19 - train: epoch 0068, iter [00450, 01251], lr: 0.000175, loss: 0.0886
2022-10-04 17:04:47 - train: epoch 0068, iter [00460, 01251], lr: 0.000174, loss: 0.0817
2022-10-04 17:05:15 - train: epoch 0068, iter [00470, 01251], lr: 0.000174, loss: 0.0841
2022-10-04 17:05:44 - train: epoch 0068, iter [00480, 01251], lr: 0.000174, loss: 0.0786
2022-10-04 17:06:12 - train: epoch 0068, iter [00490, 01251], lr: 0.000174, loss: 0.0840
2022-10-04 17:06:40 - train: epoch 0068, iter [00500, 01251], lr: 0.000174, loss: 0.0763
2022-10-04 17:07:08 - train: epoch 0068, iter [00510, 01251], lr: 0.000174, loss: 0.0945
2022-10-04 17:07:37 - train: epoch 0068, iter [00520, 01251], lr: 0.000174, loss: 0.0869
2022-10-04 17:08:05 - train: epoch 0068, iter [00530, 01251], lr: 0.000174, loss: 0.0919
2022-10-04 17:08:33 - train: epoch 0068, iter [00540, 01251], lr: 0.000174, loss: 0.0859
2022-10-04 17:09:01 - train: epoch 0068, iter [00550, 01251], lr: 0.000174, loss: 0.0890
2022-10-04 17:09:29 - train: epoch 0068, iter [00560, 01251], lr: 0.000174, loss: 0.0904
2022-10-04 17:09:58 - train: epoch 0068, iter [00570, 01251], lr: 0.000174, loss: 0.0864
2022-10-04 17:10:26 - train: epoch 0068, iter [00580, 01251], lr: 0.000174, loss: 0.0834
2022-10-04 17:10:54 - train: epoch 0068, iter [00590, 01251], lr: 0.000173, loss: 0.0872
2022-10-04 17:11:22 - train: epoch 0068, iter [00600, 01251], lr: 0.000173, loss: 0.0745
2022-10-04 17:11:51 - train: epoch 0068, iter [00610, 01251], lr: 0.000173, loss: 0.0835
2022-10-04 17:12:19 - train: epoch 0068, iter [00620, 01251], lr: 0.000173, loss: 0.0885
2022-10-04 17:12:47 - train: epoch 0068, iter [00630, 01251], lr: 0.000173, loss: 0.0906
2022-10-04 17:13:16 - train: epoch 0068, iter [00640, 01251], lr: 0.000173, loss: 0.0953
2022-10-04 17:13:44 - train: epoch 0068, iter [00650, 01251], lr: 0.000173, loss: 0.0855
2022-10-04 17:14:12 - train: epoch 0068, iter [00660, 01251], lr: 0.000173, loss: 0.0799
2022-10-04 17:14:40 - train: epoch 0068, iter [00670, 01251], lr: 0.000173, loss: 0.0815
2022-10-04 17:15:09 - train: epoch 0068, iter [00680, 01251], lr: 0.000173, loss: 0.0828
2022-10-04 17:15:37 - train: epoch 0068, iter [00690, 01251], lr: 0.000173, loss: 0.0850
2022-10-04 17:16:05 - train: epoch 0068, iter [00700, 01251], lr: 0.000173, loss: 0.0826
2022-10-04 17:16:33 - train: epoch 0068, iter [00710, 01251], lr: 0.000173, loss: 0.0821
2022-10-04 17:17:02 - train: epoch 0068, iter [00720, 01251], lr: 0.000172, loss: 0.0804
2022-10-04 17:17:30 - train: epoch 0068, iter [00730, 01251], lr: 0.000172, loss: 0.0873
2022-10-04 17:17:58 - train: epoch 0068, iter [00740, 01251], lr: 0.000172, loss: 0.0887
2022-10-04 17:18:26 - train: epoch 0068, iter [00750, 01251], lr: 0.000172, loss: 0.0773
2022-10-04 17:18:55 - train: epoch 0068, iter [00760, 01251], lr: 0.000172, loss: 0.0882
2022-10-04 17:19:23 - train: epoch 0068, iter [00770, 01251], lr: 0.000172, loss: 0.0831
2022-10-04 17:19:51 - train: epoch 0068, iter [00780, 01251], lr: 0.000172, loss: 0.0895
2022-10-04 17:20:20 - train: epoch 0068, iter [00790, 01251], lr: 0.000172, loss: 0.0846
2022-10-04 17:20:48 - train: epoch 0068, iter [00800, 01251], lr: 0.000172, loss: 0.0832
2022-10-04 17:21:16 - train: epoch 0068, iter [00810, 01251], lr: 0.000172, loss: 0.0799
2022-10-04 17:21:44 - train: epoch 0068, iter [00820, 01251], lr: 0.000172, loss: 0.0826
2022-10-04 17:22:12 - train: epoch 0068, iter [00830, 01251], lr: 0.000172, loss: 0.0841
2022-10-04 17:22:40 - train: epoch 0068, iter [00840, 01251], lr: 0.000172, loss: 0.0859
2022-10-04 17:23:09 - train: epoch 0068, iter [00850, 01251], lr: 0.000172, loss: 0.0863
2022-10-04 17:23:37 - train: epoch 0068, iter [00860, 01251], lr: 0.000171, loss: 0.0815
2022-10-04 17:24:05 - train: epoch 0068, iter [00870, 01251], lr: 0.000171, loss: 0.0827
2022-10-04 17:24:33 - train: epoch 0068, iter [00880, 01251], lr: 0.000171, loss: 0.0864
2022-10-04 17:25:02 - train: epoch 0068, iter [00890, 01251], lr: 0.000171, loss: 0.0891
2022-10-04 17:25:30 - train: epoch 0068, iter [00900, 01251], lr: 0.000171, loss: 0.0814
2022-10-04 17:25:58 - train: epoch 0068, iter [00910, 01251], lr: 0.000171, loss: 0.0882
2022-10-04 17:26:26 - train: epoch 0068, iter [00920, 01251], lr: 0.000171, loss: 0.0841
2022-10-04 17:26:54 - train: epoch 0068, iter [00930, 01251], lr: 0.000171, loss: 0.0885
2022-10-04 17:27:22 - train: epoch 0068, iter [00940, 01251], lr: 0.000171, loss: 0.0880
2022-10-04 17:27:51 - train: epoch 0068, iter [00950, 01251], lr: 0.000171, loss: 0.0830
2022-10-04 17:28:19 - train: epoch 0068, iter [00960, 01251], lr: 0.000171, loss: 0.0876
2022-10-04 17:28:47 - train: epoch 0068, iter [00970, 01251], lr: 0.000171, loss: 0.0891
2022-10-04 17:29:15 - train: epoch 0068, iter [00980, 01251], lr: 0.000171, loss: 0.0813
2022-10-04 17:29:44 - train: epoch 0068, iter [00990, 01251], lr: 0.000170, loss: 0.0819
2022-10-04 17:30:12 - train: epoch 0068, iter [01000, 01251], lr: 0.000170, loss: 0.0873
2022-10-04 17:30:40 - train: epoch 0068, iter [01010, 01251], lr: 0.000170, loss: 0.0848
2022-10-04 17:31:08 - train: epoch 0068, iter [01020, 01251], lr: 0.000170, loss: 0.0798
2022-10-04 17:31:36 - train: epoch 0068, iter [01030, 01251], lr: 0.000170, loss: 0.0883
2022-10-04 17:32:04 - train: epoch 0068, iter [01040, 01251], lr: 0.000170, loss: 0.0860
2022-10-04 17:32:33 - train: epoch 0068, iter [01050, 01251], lr: 0.000170, loss: 0.0780
2022-10-04 17:33:01 - train: epoch 0068, iter [01060, 01251], lr: 0.000170, loss: 0.0752
2022-10-04 17:33:29 - train: epoch 0068, iter [01070, 01251], lr: 0.000170, loss: 0.0844
2022-10-04 17:33:57 - train: epoch 0068, iter [01080, 01251], lr: 0.000170, loss: 0.0857
2022-10-04 17:34:25 - train: epoch 0068, iter [01090, 01251], lr: 0.000170, loss: 0.0775
2022-10-04 17:34:53 - train: epoch 0068, iter [01100, 01251], lr: 0.000170, loss: 0.0820
2022-10-04 17:35:22 - train: epoch 0068, iter [01110, 01251], lr: 0.000170, loss: 0.0953
2022-10-04 17:35:50 - train: epoch 0068, iter [01120, 01251], lr: 0.000169, loss: 0.0842
2022-10-04 17:36:18 - train: epoch 0068, iter [01130, 01251], lr: 0.000169, loss: 0.0906
2022-10-04 17:36:46 - train: epoch 0068, iter [01140, 01251], lr: 0.000169, loss: 0.0780
2022-10-04 17:37:14 - train: epoch 0068, iter [01150, 01251], lr: 0.000169, loss: 0.0859
2022-10-04 17:37:42 - train: epoch 0068, iter [01160, 01251], lr: 0.000169, loss: 0.0869
2022-10-04 17:38:10 - train: epoch 0068, iter [01170, 01251], lr: 0.000169, loss: 0.0861
2022-10-04 17:38:39 - train: epoch 0068, iter [01180, 01251], lr: 0.000169, loss: 0.0827
2022-10-04 17:39:07 - train: epoch 0068, iter [01190, 01251], lr: 0.000169, loss: 0.0954
2022-10-04 17:39:35 - train: epoch 0068, iter [01200, 01251], lr: 0.000169, loss: 0.0867
2022-10-04 17:40:03 - train: epoch 0068, iter [01210, 01251], lr: 0.000169, loss: 0.0778
2022-10-04 17:40:31 - train: epoch 0068, iter [01220, 01251], lr: 0.000169, loss: 0.0816
2022-10-04 17:40:59 - train: epoch 0068, iter [01230, 01251], lr: 0.000169, loss: 0.0823
2022-10-04 17:41:27 - train: epoch 0068, iter [01240, 01251], lr: 0.000169, loss: 0.0843
2022-10-04 17:41:54 - train: epoch 0068, iter [01250, 01251], lr: 0.000168, loss: 0.0864
2022-10-04 17:41:58 - train: epoch 068, train_loss: 0.0852
2022-10-04 17:42:00 - until epoch: 068, best_loss: 0.0852
2022-10-04 17:42:00 - epoch 069 lr: 0.000168
2022-10-04 17:42:36 - train: epoch 0069, iter [00010, 01251], lr: 0.000168, loss: 0.0856
2022-10-04 17:43:04 - train: epoch 0069, iter [00020, 01251], lr: 0.000168, loss: 0.0806
2022-10-04 17:43:32 - train: epoch 0069, iter [00030, 01251], lr: 0.000168, loss: 0.0888
2022-10-04 17:44:00 - train: epoch 0069, iter [00040, 01251], lr: 0.000168, loss: 0.0884
2022-10-04 17:44:28 - train: epoch 0069, iter [00050, 01251], lr: 0.000168, loss: 0.0824
2022-10-04 17:44:56 - train: epoch 0069, iter [00060, 01251], lr: 0.000168, loss: 0.0859
2022-10-04 17:45:24 - train: epoch 0069, iter [00070, 01251], lr: 0.000168, loss: 0.0822
2022-10-04 17:45:52 - train: epoch 0069, iter [00080, 01251], lr: 0.000168, loss: 0.0821
2022-10-04 17:46:20 - train: epoch 0069, iter [00090, 01251], lr: 0.000168, loss: 0.0776
2022-10-04 17:46:48 - train: epoch 0069, iter [00100, 01251], lr: 0.000168, loss: 0.0830
2022-10-04 17:47:16 - train: epoch 0069, iter [00110, 01251], lr: 0.000168, loss: 0.0933
2022-10-04 17:47:44 - train: epoch 0069, iter [00120, 01251], lr: 0.000168, loss: 0.0864
2022-10-04 17:48:12 - train: epoch 0069, iter [00130, 01251], lr: 0.000168, loss: 0.0860
2022-10-04 17:48:41 - train: epoch 0069, iter [00140, 01251], lr: 0.000167, loss: 0.0808
2022-10-04 17:49:09 - train: epoch 0069, iter [00150, 01251], lr: 0.000167, loss: 0.0873
2022-10-04 17:49:37 - train: epoch 0069, iter [00160, 01251], lr: 0.000167, loss: 0.0865
2022-10-04 17:50:05 - train: epoch 0069, iter [00170, 01251], lr: 0.000167, loss: 0.0869
2022-10-04 17:50:33 - train: epoch 0069, iter [00180, 01251], lr: 0.000167, loss: 0.0875
2022-10-04 17:51:02 - train: epoch 0069, iter [00190, 01251], lr: 0.000167, loss: 0.0835
2022-10-04 17:51:30 - train: epoch 0069, iter [00200, 01251], lr: 0.000167, loss: 0.0791
2022-10-04 17:51:58 - train: epoch 0069, iter [00210, 01251], lr: 0.000167, loss: 0.0844
2022-10-04 17:52:26 - train: epoch 0069, iter [00220, 01251], lr: 0.000167, loss: 0.0780
2022-10-04 17:52:54 - train: epoch 0069, iter [00230, 01251], lr: 0.000167, loss: 0.0849
2022-10-04 17:53:22 - train: epoch 0069, iter [00240, 01251], lr: 0.000167, loss: 0.0842
2022-10-04 17:53:50 - train: epoch 0069, iter [00250, 01251], lr: 0.000167, loss: 0.0873
2022-10-04 17:54:18 - train: epoch 0069, iter [00260, 01251], lr: 0.000167, loss: 0.0938
2022-10-04 17:54:46 - train: epoch 0069, iter [00270, 01251], lr: 0.000166, loss: 0.0835
2022-10-04 17:55:14 - train: epoch 0069, iter [00280, 01251], lr: 0.000166, loss: 0.0864
2022-10-04 17:55:43 - train: epoch 0069, iter [00290, 01251], lr: 0.000166, loss: 0.0833
2022-10-04 17:56:11 - train: epoch 0069, iter [00300, 01251], lr: 0.000166, loss: 0.0824
2022-10-04 17:56:39 - train: epoch 0069, iter [00310, 01251], lr: 0.000166, loss: 0.0866
2022-10-04 17:57:07 - train: epoch 0069, iter [00320, 01251], lr: 0.000166, loss: 0.0936
2022-10-04 17:57:35 - train: epoch 0069, iter [00330, 01251], lr: 0.000166, loss: 0.0856
2022-10-04 17:58:03 - train: epoch 0069, iter [00340, 01251], lr: 0.000166, loss: 0.0960
2022-10-04 17:58:31 - train: epoch 0069, iter [00350, 01251], lr: 0.000166, loss: 0.0841
2022-10-04 17:58:59 - train: epoch 0069, iter [00360, 01251], lr: 0.000166, loss: 0.0903
2022-10-04 17:59:27 - train: epoch 0069, iter [00370, 01251], lr: 0.000166, loss: 0.0819
2022-10-04 17:59:55 - train: epoch 0069, iter [00380, 01251], lr: 0.000166, loss: 0.0875
2022-10-04 18:00:23 - train: epoch 0069, iter [00390, 01251], lr: 0.000166, loss: 0.0865
2022-10-04 18:00:51 - train: epoch 0069, iter [00400, 01251], lr: 0.000165, loss: 0.0864
2022-10-04 18:01:19 - train: epoch 0069, iter [00410, 01251], lr: 0.000165, loss: 0.0787
2022-10-04 18:01:47 - train: epoch 0069, iter [00420, 01251], lr: 0.000165, loss: 0.0837
2022-10-04 18:02:14 - train: epoch 0069, iter [00430, 01251], lr: 0.000165, loss: 0.0858
2022-10-04 18:02:42 - train: epoch 0069, iter [00440, 01251], lr: 0.000165, loss: 0.0804
2022-10-04 18:03:10 - train: epoch 0069, iter [00450, 01251], lr: 0.000165, loss: 0.0837
2022-10-04 18:03:38 - train: epoch 0069, iter [00460, 01251], lr: 0.000165, loss: 0.0853
2022-10-04 18:04:06 - train: epoch 0069, iter [00470, 01251], lr: 0.000165, loss: 0.0788
2022-10-04 18:04:34 - train: epoch 0069, iter [00480, 01251], lr: 0.000165, loss: 0.0897
2022-10-04 18:05:02 - train: epoch 0069, iter [00490, 01251], lr: 0.000165, loss: 0.0850
2022-10-04 18:05:30 - train: epoch 0069, iter [00500, 01251], lr: 0.000165, loss: 0.0908
2022-10-04 18:05:58 - train: epoch 0069, iter [00510, 01251], lr: 0.000165, loss: 0.0792
2022-10-04 18:06:26 - train: epoch 0069, iter [00520, 01251], lr: 0.000165, loss: 0.0850
2022-10-04 18:06:54 - train: epoch 0069, iter [00530, 01251], lr: 0.000165, loss: 0.0905
2022-10-04 18:07:22 - train: epoch 0069, iter [00540, 01251], lr: 0.000164, loss: 0.0858
2022-10-04 18:07:50 - train: epoch 0069, iter [00550, 01251], lr: 0.000164, loss: 0.0899
2022-10-04 18:08:18 - train: epoch 0069, iter [00560, 01251], lr: 0.000164, loss: 0.0824
2022-10-04 18:08:46 - train: epoch 0069, iter [00570, 01251], lr: 0.000164, loss: 0.0867
2022-10-04 18:09:14 - train: epoch 0069, iter [00580, 01251], lr: 0.000164, loss: 0.0842
2022-10-04 18:09:42 - train: epoch 0069, iter [00590, 01251], lr: 0.000164, loss: 0.0831
2022-10-04 18:10:10 - train: epoch 0069, iter [00600, 01251], lr: 0.000164, loss: 0.0789
2022-10-04 18:10:38 - train: epoch 0069, iter [00610, 01251], lr: 0.000164, loss: 0.0841
2022-10-04 18:11:06 - train: epoch 0069, iter [00620, 01251], lr: 0.000164, loss: 0.0840
2022-10-04 18:11:34 - train: epoch 0069, iter [00630, 01251], lr: 0.000164, loss: 0.0890
2022-10-04 18:12:02 - train: epoch 0069, iter [00640, 01251], lr: 0.000164, loss: 0.0814
2022-10-04 18:12:30 - train: epoch 0069, iter [00650, 01251], lr: 0.000164, loss: 0.0906
2022-10-04 18:12:58 - train: epoch 0069, iter [00660, 01251], lr: 0.000164, loss: 0.0871
2022-10-04 18:13:26 - train: epoch 0069, iter [00670, 01251], lr: 0.000163, loss: 0.0851
2022-10-04 18:13:54 - train: epoch 0069, iter [00680, 01251], lr: 0.000163, loss: 0.0873
2022-10-04 18:14:22 - train: epoch 0069, iter [00690, 01251], lr: 0.000163, loss: 0.0874
2022-10-04 18:14:50 - train: epoch 0069, iter [00700, 01251], lr: 0.000163, loss: 0.0855
2022-10-04 18:15:18 - train: epoch 0069, iter [00710, 01251], lr: 0.000163, loss: 0.0913
2022-10-04 18:15:46 - train: epoch 0069, iter [00720, 01251], lr: 0.000163, loss: 0.0894
2022-10-04 18:16:14 - train: epoch 0069, iter [00730, 01251], lr: 0.000163, loss: 0.0904
2022-10-04 18:16:42 - train: epoch 0069, iter [00740, 01251], lr: 0.000163, loss: 0.0767
2022-10-04 18:17:10 - train: epoch 0069, iter [00750, 01251], lr: 0.000163, loss: 0.0832
2022-10-04 18:17:38 - train: epoch 0069, iter [00760, 01251], lr: 0.000163, loss: 0.0798
2022-10-04 18:18:06 - train: epoch 0069, iter [00770, 01251], lr: 0.000163, loss: 0.0853
2022-10-04 18:18:34 - train: epoch 0069, iter [00780, 01251], lr: 0.000163, loss: 0.0846
2022-10-04 18:19:02 - train: epoch 0069, iter [00790, 01251], lr: 0.000163, loss: 0.0902
2022-10-04 18:19:30 - train: epoch 0069, iter [00800, 01251], lr: 0.000163, loss: 0.1010
2022-10-04 18:19:58 - train: epoch 0069, iter [00810, 01251], lr: 0.000162, loss: 0.0883
2022-10-04 18:20:26 - train: epoch 0069, iter [00820, 01251], lr: 0.000162, loss: 0.0813
2022-10-04 18:20:53 - train: epoch 0069, iter [00830, 01251], lr: 0.000162, loss: 0.0818
2022-10-04 18:21:21 - train: epoch 0069, iter [00840, 01251], lr: 0.000162, loss: 0.0872
2022-10-04 18:21:49 - train: epoch 0069, iter [00850, 01251], lr: 0.000162, loss: 0.0807
2022-10-04 18:22:17 - train: epoch 0069, iter [00860, 01251], lr: 0.000162, loss: 0.0818
2022-10-04 18:22:45 - train: epoch 0069, iter [00870, 01251], lr: 0.000162, loss: 0.0787
2022-10-04 18:23:13 - train: epoch 0069, iter [00880, 01251], lr: 0.000162, loss: 0.0819
2022-10-04 18:23:41 - train: epoch 0069, iter [00890, 01251], lr: 0.000162, loss: 0.0828
2022-10-04 18:24:09 - train: epoch 0069, iter [00900, 01251], lr: 0.000162, loss: 0.0869
2022-10-04 18:24:37 - train: epoch 0069, iter [00910, 01251], lr: 0.000162, loss: 0.0921
2022-10-04 18:25:05 - train: epoch 0069, iter [00920, 01251], lr: 0.000162, loss: 0.0908
2022-10-04 18:25:34 - train: epoch 0069, iter [00930, 01251], lr: 0.000162, loss: 0.0866
2022-10-04 18:26:02 - train: epoch 0069, iter [00940, 01251], lr: 0.000161, loss: 0.0922
2022-10-04 18:26:30 - train: epoch 0069, iter [00950, 01251], lr: 0.000161, loss: 0.0905
2022-10-04 18:26:58 - train: epoch 0069, iter [00960, 01251], lr: 0.000161, loss: 0.0821
2022-10-04 18:27:26 - train: epoch 0069, iter [00970, 01251], lr: 0.000161, loss: 0.0846
2022-10-04 18:27:54 - train: epoch 0069, iter [00980, 01251], lr: 0.000161, loss: 0.0809
2022-10-04 18:28:22 - train: epoch 0069, iter [00990, 01251], lr: 0.000161, loss: 0.0834
2022-10-04 18:28:50 - train: epoch 0069, iter [01000, 01251], lr: 0.000161, loss: 0.0773
2022-10-04 18:29:18 - train: epoch 0069, iter [01010, 01251], lr: 0.000161, loss: 0.0839
2022-10-04 18:29:46 - train: epoch 0069, iter [01020, 01251], lr: 0.000161, loss: 0.0817
2022-10-04 18:30:14 - train: epoch 0069, iter [01030, 01251], lr: 0.000161, loss: 0.0842
2022-10-04 18:30:42 - train: epoch 0069, iter [01040, 01251], lr: 0.000161, loss: 0.0829
2022-10-04 18:31:10 - train: epoch 0069, iter [01050, 01251], lr: 0.000161, loss: 0.0901
2022-10-04 18:31:38 - train: epoch 0069, iter [01060, 01251], lr: 0.000161, loss: 0.0905
2022-10-04 18:32:06 - train: epoch 0069, iter [01070, 01251], lr: 0.000160, loss: 0.0797
2022-10-04 18:32:34 - train: epoch 0069, iter [01080, 01251], lr: 0.000160, loss: 0.0907
2022-10-04 18:33:02 - train: epoch 0069, iter [01090, 01251], lr: 0.000160, loss: 0.0897
2022-10-04 18:33:30 - train: epoch 0069, iter [01100, 01251], lr: 0.000160, loss: 0.0916
2022-10-04 18:33:58 - train: epoch 0069, iter [01110, 01251], lr: 0.000160, loss: 0.0857
2022-10-04 18:34:26 - train: epoch 0069, iter [01120, 01251], lr: 0.000160, loss: 0.0904
2022-10-04 18:34:54 - train: epoch 0069, iter [01130, 01251], lr: 0.000160, loss: 0.0917
2022-10-04 18:35:22 - train: epoch 0069, iter [01140, 01251], lr: 0.000160, loss: 0.0794
2022-10-04 18:35:50 - train: epoch 0069, iter [01150, 01251], lr: 0.000160, loss: 0.0823
2022-10-04 18:36:18 - train: epoch 0069, iter [01160, 01251], lr: 0.000160, loss: 0.0894
2022-10-04 18:36:46 - train: epoch 0069, iter [01170, 01251], lr: 0.000160, loss: 0.0888
2022-10-04 18:37:14 - train: epoch 0069, iter [01180, 01251], lr: 0.000160, loss: 0.0853
2022-10-04 18:37:42 - train: epoch 0069, iter [01190, 01251], lr: 0.000160, loss: 0.0935
2022-10-04 18:38:11 - train: epoch 0069, iter [01200, 01251], lr: 0.000160, loss: 0.0829
2022-10-04 18:38:39 - train: epoch 0069, iter [01210, 01251], lr: 0.000159, loss: 0.0872
2022-10-04 18:39:07 - train: epoch 0069, iter [01220, 01251], lr: 0.000159, loss: 0.0813
2022-10-04 18:39:35 - train: epoch 0069, iter [01230, 01251], lr: 0.000159, loss: 0.0873
2022-10-04 18:40:03 - train: epoch 0069, iter [01240, 01251], lr: 0.000159, loss: 0.0862
2022-10-04 18:40:30 - train: epoch 0069, iter [01250, 01251], lr: 0.000159, loss: 0.0851
2022-10-04 18:40:35 - train: epoch 069, train_loss: 0.0851
2022-10-04 18:40:37 - until epoch: 069, best_loss: 0.0851
2022-10-04 18:40:37 - epoch 070 lr: 0.000159
2022-10-04 18:41:13 - train: epoch 0070, iter [00010, 01251], lr: 0.000159, loss: 0.0853
2022-10-04 18:41:41 - train: epoch 0070, iter [00020, 01251], lr: 0.000159, loss: 0.0895
2022-10-04 18:42:09 - train: epoch 0070, iter [00030, 01251], lr: 0.000159, loss: 0.0828
2022-10-04 18:42:37 - train: epoch 0070, iter [00040, 01251], lr: 0.000159, loss: 0.0917
2022-10-04 18:43:05 - train: epoch 0070, iter [00050, 01251], lr: 0.000159, loss: 0.0750
2022-10-04 18:43:33 - train: epoch 0070, iter [00060, 01251], lr: 0.000159, loss: 0.0809
2022-10-04 18:44:01 - train: epoch 0070, iter [00070, 01251], lr: 0.000159, loss: 0.0817
2022-10-04 18:44:29 - train: epoch 0070, iter [00080, 01251], lr: 0.000159, loss: 0.0787
2022-10-04 18:44:57 - train: epoch 0070, iter [00090, 01251], lr: 0.000158, loss: 0.0859
2022-10-04 18:45:24 - train: epoch 0070, iter [00100, 01251], lr: 0.000158, loss: 0.0839
2022-10-04 18:45:52 - train: epoch 0070, iter [00110, 01251], lr: 0.000158, loss: 0.0887
2022-10-04 18:46:20 - train: epoch 0070, iter [00120, 01251], lr: 0.000158, loss: 0.0828
2022-10-04 18:46:48 - train: epoch 0070, iter [00130, 01251], lr: 0.000158, loss: 0.0795
2022-10-04 18:47:16 - train: epoch 0070, iter [00140, 01251], lr: 0.000158, loss: 0.0815
2022-10-04 18:47:44 - train: epoch 0070, iter [00150, 01251], lr: 0.000158, loss: 0.0814
2022-10-04 18:48:12 - train: epoch 0070, iter [00160, 01251], lr: 0.000158, loss: 0.0834
2022-10-04 18:48:40 - train: epoch 0070, iter [00170, 01251], lr: 0.000158, loss: 0.0825
2022-10-04 18:49:08 - train: epoch 0070, iter [00180, 01251], lr: 0.000158, loss: 0.0879
2022-10-04 18:49:36 - train: epoch 0070, iter [00190, 01251], lr: 0.000158, loss: 0.0854
2022-10-04 18:50:04 - train: epoch 0070, iter [00200, 01251], lr: 0.000158, loss: 0.0846
2022-10-04 18:50:32 - train: epoch 0070, iter [00210, 01251], lr: 0.000158, loss: 0.0889
2022-10-04 18:51:00 - train: epoch 0070, iter [00220, 01251], lr: 0.000158, loss: 0.0811
2022-10-04 18:51:28 - train: epoch 0070, iter [00230, 01251], lr: 0.000157, loss: 0.0872
2022-10-04 18:51:56 - train: epoch 0070, iter [00240, 01251], lr: 0.000157, loss: 0.0806
2022-10-04 18:52:24 - train: epoch 0070, iter [00250, 01251], lr: 0.000157, loss: 0.0925
2022-10-04 18:52:52 - train: epoch 0070, iter [00260, 01251], lr: 0.000157, loss: 0.0851
2022-10-04 18:53:20 - train: epoch 0070, iter [00270, 01251], lr: 0.000157, loss: 0.0811
2022-10-04 18:53:47 - train: epoch 0070, iter [00280, 01251], lr: 0.000157, loss: 0.0832
2022-10-04 18:54:15 - train: epoch 0070, iter [00290, 01251], lr: 0.000157, loss: 0.0838
2022-10-04 18:54:43 - train: epoch 0070, iter [00300, 01251], lr: 0.000157, loss: 0.0873
2022-10-04 18:55:11 - train: epoch 0070, iter [00310, 01251], lr: 0.000157, loss: 0.0810
2022-10-04 18:55:39 - train: epoch 0070, iter [00320, 01251], lr: 0.000157, loss: 0.0866
2022-10-04 18:56:07 - train: epoch 0070, iter [00330, 01251], lr: 0.000157, loss: 0.0819
2022-10-04 18:56:35 - train: epoch 0070, iter [00340, 01251], lr: 0.000157, loss: 0.0872
2022-10-04 18:57:03 - train: epoch 0070, iter [00350, 01251], lr: 0.000157, loss: 0.0915
2022-10-04 18:57:31 - train: epoch 0070, iter [00360, 01251], lr: 0.000157, loss: 0.0953
2022-10-04 18:57:59 - train: epoch 0070, iter [00370, 01251], lr: 0.000156, loss: 0.0882
2022-10-04 18:58:27 - train: epoch 0070, iter [00380, 01251], lr: 0.000156, loss: 0.0871
2022-10-04 18:58:55 - train: epoch 0070, iter [00390, 01251], lr: 0.000156, loss: 0.0844
2022-10-04 18:59:23 - train: epoch 0070, iter [00400, 01251], lr: 0.000156, loss: 0.0853
2022-10-04 18:59:51 - train: epoch 0070, iter [00410, 01251], lr: 0.000156, loss: 0.0784
2022-10-04 19:00:19 - train: epoch 0070, iter [00420, 01251], lr: 0.000156, loss: 0.0846
2022-10-04 19:00:47 - train: epoch 0070, iter [00430, 01251], lr: 0.000156, loss: 0.0893
2022-10-04 19:01:16 - train: epoch 0070, iter [00440, 01251], lr: 0.000156, loss: 0.0845
2022-10-04 19:01:44 - train: epoch 0070, iter [00450, 01251], lr: 0.000156, loss: 0.0787
2022-10-04 19:02:12 - train: epoch 0070, iter [00460, 01251], lr: 0.000156, loss: 0.0828
2022-10-04 19:02:40 - train: epoch 0070, iter [00470, 01251], lr: 0.000156, loss: 0.0770
2022-10-04 19:03:08 - train: epoch 0070, iter [00480, 01251], lr: 0.000156, loss: 0.0839
2022-10-04 19:03:36 - train: epoch 0070, iter [00490, 01251], lr: 0.000156, loss: 0.0883
2022-10-04 19:04:04 - train: epoch 0070, iter [00500, 01251], lr: 0.000155, loss: 0.0828
2022-10-04 19:04:33 - train: epoch 0070, iter [00510, 01251], lr: 0.000155, loss: 0.0806
2022-10-04 19:05:01 - train: epoch 0070, iter [00520, 01251], lr: 0.000155, loss: 0.0888
2022-10-04 19:05:28 - train: epoch 0070, iter [00530, 01251], lr: 0.000155, loss: 0.0847
2022-10-04 19:05:57 - train: epoch 0070, iter [00540, 01251], lr: 0.000155, loss: 0.0887
2022-10-04 19:06:25 - train: epoch 0070, iter [00550, 01251], lr: 0.000155, loss: 0.0931
2022-10-04 19:06:53 - train: epoch 0070, iter [00560, 01251], lr: 0.000155, loss: 0.0766
2022-10-04 19:07:21 - train: epoch 0070, iter [00570, 01251], lr: 0.000155, loss: 0.0810
2022-10-04 19:07:48 - train: epoch 0070, iter [00580, 01251], lr: 0.000155, loss: 0.0827
2022-10-04 19:08:16 - train: epoch 0070, iter [00590, 01251], lr: 0.000155, loss: 0.0898
2022-10-04 19:08:44 - train: epoch 0070, iter [00600, 01251], lr: 0.000155, loss: 0.0842
2022-10-04 19:09:12 - train: epoch 0070, iter [00610, 01251], lr: 0.000155, loss: 0.0844
2022-10-04 19:09:40 - train: epoch 0070, iter [00620, 01251], lr: 0.000155, loss: 0.0890
2022-10-04 19:10:08 - train: epoch 0070, iter [00630, 01251], lr: 0.000155, loss: 0.0812
2022-10-04 19:10:36 - train: epoch 0070, iter [00640, 01251], lr: 0.000154, loss: 0.0827
2022-10-04 19:11:04 - train: epoch 0070, iter [00650, 01251], lr: 0.000154, loss: 0.0904
2022-10-04 19:11:32 - train: epoch 0070, iter [00660, 01251], lr: 0.000154, loss: 0.0826
2022-10-04 19:12:00 - train: epoch 0070, iter [00670, 01251], lr: 0.000154, loss: 0.0832
2022-10-04 19:12:28 - train: epoch 0070, iter [00680, 01251], lr: 0.000154, loss: 0.0853
2022-10-04 19:12:56 - train: epoch 0070, iter [00690, 01251], lr: 0.000154, loss: 0.0847
2022-10-04 19:13:24 - train: epoch 0070, iter [00700, 01251], lr: 0.000154, loss: 0.0855
2022-10-04 19:13:52 - train: epoch 0070, iter [00710, 01251], lr: 0.000154, loss: 0.0793
2022-10-04 19:14:20 - train: epoch 0070, iter [00720, 01251], lr: 0.000154, loss: 0.0782
2022-10-04 19:14:48 - train: epoch 0070, iter [00730, 01251], lr: 0.000154, loss: 0.0847
2022-10-04 19:15:16 - train: epoch 0070, iter [00740, 01251], lr: 0.000154, loss: 0.0898
2022-10-04 19:15:44 - train: epoch 0070, iter [00750, 01251], lr: 0.000154, loss: 0.0863
2022-10-04 19:16:13 - train: epoch 0070, iter [00760, 01251], lr: 0.000154, loss: 0.0841
2022-10-04 19:16:41 - train: epoch 0070, iter [00770, 01251], lr: 0.000154, loss: 0.0890
2022-10-04 19:17:09 - train: epoch 0070, iter [00780, 01251], lr: 0.000153, loss: 0.0797
2022-10-04 19:17:37 - train: epoch 0070, iter [00790, 01251], lr: 0.000153, loss: 0.0861
2022-10-04 19:18:05 - train: epoch 0070, iter [00800, 01251], lr: 0.000153, loss: 0.0746
2022-10-04 19:18:33 - train: epoch 0070, iter [00810, 01251], lr: 0.000153, loss: 0.0868
2022-10-04 19:19:01 - train: epoch 0070, iter [00820, 01251], lr: 0.000153, loss: 0.0847
2022-10-04 19:19:29 - train: epoch 0070, iter [00830, 01251], lr: 0.000153, loss: 0.0821
2022-10-04 19:19:57 - train: epoch 0070, iter [00840, 01251], lr: 0.000153, loss: 0.0849
2022-10-04 19:20:25 - train: epoch 0070, iter [00850, 01251], lr: 0.000153, loss: 0.0796
2022-10-04 19:20:53 - train: epoch 0070, iter [00860, 01251], lr: 0.000153, loss: 0.0917
2022-10-04 19:21:21 - train: epoch 0070, iter [00870, 01251], lr: 0.000153, loss: 0.0784
2022-10-04 19:21:49 - train: epoch 0070, iter [00880, 01251], lr: 0.000153, loss: 0.0870
2022-10-04 19:22:17 - train: epoch 0070, iter [00890, 01251], lr: 0.000153, loss: 0.0872
2022-10-04 19:22:45 - train: epoch 0070, iter [00900, 01251], lr: 0.000153, loss: 0.0849
2022-10-04 19:23:14 - train: epoch 0070, iter [00910, 01251], lr: 0.000152, loss: 0.0829
2022-10-04 19:23:42 - train: epoch 0070, iter [00920, 01251], lr: 0.000152, loss: 0.0918
2022-10-04 19:24:10 - train: epoch 0070, iter [00930, 01251], lr: 0.000152, loss: 0.0817
2022-10-04 19:24:38 - train: epoch 0070, iter [00940, 01251], lr: 0.000152, loss: 0.0828
2022-10-04 19:25:06 - train: epoch 0070, iter [00950, 01251], lr: 0.000152, loss: 0.0945
2022-10-04 19:25:34 - train: epoch 0070, iter [00960, 01251], lr: 0.000152, loss: 0.0835
2022-10-04 19:26:02 - train: epoch 0070, iter [00970, 01251], lr: 0.000152, loss: 0.0969
2022-10-04 19:26:30 - train: epoch 0070, iter [00980, 01251], lr: 0.000152, loss: 0.0880
2022-10-04 19:26:58 - train: epoch 0070, iter [00990, 01251], lr: 0.000152, loss: 0.0910
2022-10-04 19:27:26 - train: epoch 0070, iter [01000, 01251], lr: 0.000152, loss: 0.0851
2022-10-04 19:27:54 - train: epoch 0070, iter [01010, 01251], lr: 0.000152, loss: 0.0773
2022-10-04 19:28:22 - train: epoch 0070, iter [01020, 01251], lr: 0.000152, loss: 0.0822
2022-10-04 19:28:50 - train: epoch 0070, iter [01030, 01251], lr: 0.000152, loss: 0.0840
2022-10-04 19:29:18 - train: epoch 0070, iter [01040, 01251], lr: 0.000152, loss: 0.0868
2022-10-04 19:29:47 - train: epoch 0070, iter [01050, 01251], lr: 0.000151, loss: 0.0897
2022-10-04 19:30:15 - train: epoch 0070, iter [01060, 01251], lr: 0.000151, loss: 0.0923
2022-10-04 19:30:43 - train: epoch 0070, iter [01070, 01251], lr: 0.000151, loss: 0.0834
2022-10-04 19:31:11 - train: epoch 0070, iter [01080, 01251], lr: 0.000151, loss: 0.0799
2022-10-04 19:31:39 - train: epoch 0070, iter [01090, 01251], lr: 0.000151, loss: 0.0839
2022-10-04 19:32:07 - train: epoch 0070, iter [01100, 01251], lr: 0.000151, loss: 0.0879
2022-10-04 19:32:35 - train: epoch 0070, iter [01110, 01251], lr: 0.000151, loss: 0.0873
2022-10-04 19:33:03 - train: epoch 0070, iter [01120, 01251], lr: 0.000151, loss: 0.0814
2022-10-04 19:33:31 - train: epoch 0070, iter [01130, 01251], lr: 0.000151, loss: 0.0841
2022-10-04 19:33:59 - train: epoch 0070, iter [01140, 01251], lr: 0.000151, loss: 0.0867
2022-10-04 19:34:27 - train: epoch 0070, iter [01150, 01251], lr: 0.000151, loss: 0.0818
2022-10-04 19:34:55 - train: epoch 0070, iter [01160, 01251], lr: 0.000151, loss: 0.0799
2022-10-04 19:35:23 - train: epoch 0070, iter [01170, 01251], lr: 0.000151, loss: 0.0904
2022-10-04 19:35:51 - train: epoch 0070, iter [01180, 01251], lr: 0.000151, loss: 0.0773
2022-10-04 19:36:19 - train: epoch 0070, iter [01190, 01251], lr: 0.000150, loss: 0.0846
2022-10-04 19:36:47 - train: epoch 0070, iter [01200, 01251], lr: 0.000150, loss: 0.0806
2022-10-04 19:37:15 - train: epoch 0070, iter [01210, 01251], lr: 0.000150, loss: 0.0870
2022-10-04 19:37:43 - train: epoch 0070, iter [01220, 01251], lr: 0.000150, loss: 0.0930
2022-10-04 19:38:11 - train: epoch 0070, iter [01230, 01251], lr: 0.000150, loss: 0.0844
2022-10-04 19:38:40 - train: epoch 0070, iter [01240, 01251], lr: 0.000150, loss: 0.0832
2022-10-04 19:39:07 - train: epoch 0070, iter [01250, 01251], lr: 0.000150, loss: 0.0871
2022-10-04 19:39:12 - train: epoch 070, train_loss: 0.0848
2022-10-04 19:39:14 - until epoch: 070, best_loss: 0.0848
2022-10-04 19:39:14 - epoch 071 lr: 0.000150
2022-10-04 19:39:49 - train: epoch 0071, iter [00010, 01251], lr: 0.000150, loss: 0.0870
2022-10-04 19:40:17 - train: epoch 0071, iter [00020, 01251], lr: 0.000150, loss: 0.0837
2022-10-04 19:40:45 - train: epoch 0071, iter [00030, 01251], lr: 0.000150, loss: 0.0854
2022-10-04 19:41:13 - train: epoch 0071, iter [00040, 01251], lr: 0.000150, loss: 0.0866
2022-10-04 19:41:41 - train: epoch 0071, iter [00050, 01251], lr: 0.000150, loss: 0.0852
2022-10-04 19:42:10 - train: epoch 0071, iter [00060, 01251], lr: 0.000150, loss: 0.0872
2022-10-04 19:42:38 - train: epoch 0071, iter [00070, 01251], lr: 0.000149, loss: 0.0883
2022-10-04 19:43:06 - train: epoch 0071, iter [00080, 01251], lr: 0.000149, loss: 0.0890
2022-10-04 19:43:34 - train: epoch 0071, iter [00090, 01251], lr: 0.000149, loss: 0.0833
2022-10-04 19:44:02 - train: epoch 0071, iter [00100, 01251], lr: 0.000149, loss: 0.0866
2022-10-04 19:44:30 - train: epoch 0071, iter [00110, 01251], lr: 0.000149, loss: 0.0819
2022-10-04 19:44:58 - train: epoch 0071, iter [00120, 01251], lr: 0.000149, loss: 0.0785
2022-10-04 19:45:26 - train: epoch 0071, iter [00130, 01251], lr: 0.000149, loss: 0.0877
2022-10-04 19:45:54 - train: epoch 0071, iter [00140, 01251], lr: 0.000149, loss: 0.0841
2022-10-04 19:46:22 - train: epoch 0071, iter [00150, 01251], lr: 0.000149, loss: 0.0892
2022-10-04 19:46:51 - train: epoch 0071, iter [00160, 01251], lr: 0.000149, loss: 0.0913
2022-10-04 19:47:19 - train: epoch 0071, iter [00170, 01251], lr: 0.000149, loss: 0.0872
2022-10-04 19:47:47 - train: epoch 0071, iter [00180, 01251], lr: 0.000149, loss: 0.0838
2022-10-04 19:48:15 - train: epoch 0071, iter [00190, 01251], lr: 0.000149, loss: 0.0803
2022-10-04 19:48:43 - train: epoch 0071, iter [00200, 01251], lr: 0.000149, loss: 0.0800
2022-10-04 19:49:11 - train: epoch 0071, iter [00210, 01251], lr: 0.000148, loss: 0.0820
2022-10-04 19:49:39 - train: epoch 0071, iter [00220, 01251], lr: 0.000148, loss: 0.0862
2022-10-04 19:50:07 - train: epoch 0071, iter [00230, 01251], lr: 0.000148, loss: 0.0835
2022-10-04 19:50:35 - train: epoch 0071, iter [00240, 01251], lr: 0.000148, loss: 0.0815
2022-10-04 19:51:03 - train: epoch 0071, iter [00250, 01251], lr: 0.000148, loss: 0.0832
2022-10-04 19:51:31 - train: epoch 0071, iter [00260, 01251], lr: 0.000148, loss: 0.0820
2022-10-04 19:51:59 - train: epoch 0071, iter [00270, 01251], lr: 0.000148, loss: 0.0858
2022-10-04 19:52:27 - train: epoch 0071, iter [00280, 01251], lr: 0.000148, loss: 0.0855
2022-10-04 19:52:55 - train: epoch 0071, iter [00290, 01251], lr: 0.000148, loss: 0.0873
2022-10-04 19:53:23 - train: epoch 0071, iter [00300, 01251], lr: 0.000148, loss: 0.0836
2022-10-04 19:53:51 - train: epoch 0071, iter [00310, 01251], lr: 0.000148, loss: 0.0798
2022-10-04 19:54:19 - train: epoch 0071, iter [00320, 01251], lr: 0.000148, loss: 0.0878
2022-10-04 19:54:47 - train: epoch 0071, iter [00330, 01251], lr: 0.000148, loss: 0.0870
2022-10-04 19:55:15 - train: epoch 0071, iter [00340, 01251], lr: 0.000148, loss: 0.0873
2022-10-04 19:55:44 - train: epoch 0071, iter [00350, 01251], lr: 0.000147, loss: 0.0878
2022-10-04 19:56:12 - train: epoch 0071, iter [00360, 01251], lr: 0.000147, loss: 0.0953
2022-10-04 19:56:40 - train: epoch 0071, iter [00370, 01251], lr: 0.000147, loss: 0.0820
2022-10-04 19:57:08 - train: epoch 0071, iter [00380, 01251], lr: 0.000147, loss: 0.0891
2022-10-04 19:57:36 - train: epoch 0071, iter [00390, 01251], lr: 0.000147, loss: 0.0867
2022-10-04 19:58:04 - train: epoch 0071, iter [00400, 01251], lr: 0.000147, loss: 0.0843
2022-10-04 19:58:32 - train: epoch 0071, iter [00410, 01251], lr: 0.000147, loss: 0.0841
2022-10-04 19:59:00 - train: epoch 0071, iter [00420, 01251], lr: 0.000147, loss: 0.0795
2022-10-04 19:59:29 - train: epoch 0071, iter [00430, 01251], lr: 0.000147, loss: 0.0898
2022-10-04 19:59:57 - train: epoch 0071, iter [00440, 01251], lr: 0.000147, loss: 0.0848
2022-10-04 20:00:25 - train: epoch 0071, iter [00450, 01251], lr: 0.000147, loss: 0.0774
2022-10-04 20:00:53 - train: epoch 0071, iter [00460, 01251], lr: 0.000147, loss: 0.0886
2022-10-04 20:01:21 - train: epoch 0071, iter [00470, 01251], lr: 0.000147, loss: 0.0815
2022-10-04 20:01:49 - train: epoch 0071, iter [00480, 01251], lr: 0.000147, loss: 0.0850
2022-10-04 20:02:17 - train: epoch 0071, iter [00490, 01251], lr: 0.000146, loss: 0.0796
2022-10-04 20:02:46 - train: epoch 0071, iter [00500, 01251], lr: 0.000146, loss: 0.0847
2022-10-04 20:03:14 - train: epoch 0071, iter [00510, 01251], lr: 0.000146, loss: 0.0812
2022-10-04 20:03:42 - train: epoch 0071, iter [00520, 01251], lr: 0.000146, loss: 0.0808
2022-10-04 20:04:10 - train: epoch 0071, iter [00530, 01251], lr: 0.000146, loss: 0.0854
2022-10-04 20:04:38 - train: epoch 0071, iter [00540, 01251], lr: 0.000146, loss: 0.0833
2022-10-04 20:05:06 - train: epoch 0071, iter [00550, 01251], lr: 0.000146, loss: 0.0777
2022-10-04 20:05:34 - train: epoch 0071, iter [00560, 01251], lr: 0.000146, loss: 0.0903
2022-10-04 20:06:02 - train: epoch 0071, iter [00570, 01251], lr: 0.000146, loss: 0.0827
2022-10-04 20:06:30 - train: epoch 0071, iter [00580, 01251], lr: 0.000146, loss: 0.0860
2022-10-04 20:06:58 - train: epoch 0071, iter [00590, 01251], lr: 0.000146, loss: 0.0816
2022-10-04 20:07:26 - train: epoch 0071, iter [00600, 01251], lr: 0.000146, loss: 0.0831
2022-10-04 20:07:54 - train: epoch 0071, iter [00610, 01251], lr: 0.000146, loss: 0.0878
2022-10-04 20:08:22 - train: epoch 0071, iter [00620, 01251], lr: 0.000146, loss: 0.0858
2022-10-04 20:08:50 - train: epoch 0071, iter [00630, 01251], lr: 0.000145, loss: 0.0907
2022-10-04 20:09:18 - train: epoch 0071, iter [00640, 01251], lr: 0.000145, loss: 0.0883
2022-10-04 20:09:46 - train: epoch 0071, iter [00650, 01251], lr: 0.000145, loss: 0.0858
2022-10-04 20:10:14 - train: epoch 0071, iter [00660, 01251], lr: 0.000145, loss: 0.0867
2022-10-04 20:10:42 - train: epoch 0071, iter [00670, 01251], lr: 0.000145, loss: 0.0806
2022-10-04 20:11:10 - train: epoch 0071, iter [00680, 01251], lr: 0.000145, loss: 0.0841
2022-10-04 20:11:38 - train: epoch 0071, iter [00690, 01251], lr: 0.000145, loss: 0.0832
2022-10-04 20:12:06 - train: epoch 0071, iter [00700, 01251], lr: 0.000145, loss: 0.0857
2022-10-04 20:12:34 - train: epoch 0071, iter [00710, 01251], lr: 0.000145, loss: 0.0787
2022-10-04 20:13:02 - train: epoch 0071, iter [00720, 01251], lr: 0.000145, loss: 0.0847
2022-10-04 20:13:30 - train: epoch 0071, iter [00730, 01251], lr: 0.000145, loss: 0.0889
2022-10-04 20:13:58 - train: epoch 0071, iter [00740, 01251], lr: 0.000145, loss: 0.0794
2022-10-04 20:14:26 - train: epoch 0071, iter [00750, 01251], lr: 0.000145, loss: 0.0782
2022-10-04 20:14:54 - train: epoch 0071, iter [00760, 01251], lr: 0.000145, loss: 0.0831
2022-10-04 20:15:22 - train: epoch 0071, iter [00770, 01251], lr: 0.000144, loss: 0.0922
2022-10-04 20:15:50 - train: epoch 0071, iter [00780, 01251], lr: 0.000144, loss: 0.0777
2022-10-04 20:16:17 - train: epoch 0071, iter [00790, 01251], lr: 0.000144, loss: 0.0818
2022-10-04 20:16:45 - train: epoch 0071, iter [00800, 01251], lr: 0.000144, loss: 0.0852
2022-10-04 20:17:13 - train: epoch 0071, iter [00810, 01251], lr: 0.000144, loss: 0.0818
2022-10-04 20:17:41 - train: epoch 0071, iter [00820, 01251], lr: 0.000144, loss: 0.0902
2022-10-04 20:18:09 - train: epoch 0071, iter [00830, 01251], lr: 0.000144, loss: 0.0922
2022-10-04 20:18:37 - train: epoch 0071, iter [00840, 01251], lr: 0.000144, loss: 0.0827
2022-10-04 20:19:05 - train: epoch 0071, iter [00850, 01251], lr: 0.000144, loss: 0.0868
2022-10-04 20:19:33 - train: epoch 0071, iter [00860, 01251], lr: 0.000144, loss: 0.0827
2022-10-04 20:20:01 - train: epoch 0071, iter [00870, 01251], lr: 0.000144, loss: 0.0845
2022-10-04 20:20:29 - train: epoch 0071, iter [00880, 01251], lr: 0.000144, loss: 0.0969
2022-10-04 20:20:57 - train: epoch 0071, iter [00890, 01251], lr: 0.000144, loss: 0.0890
2022-10-04 20:21:25 - train: epoch 0071, iter [00900, 01251], lr: 0.000144, loss: 0.0823
2022-10-04 20:21:53 - train: epoch 0071, iter [00910, 01251], lr: 0.000143, loss: 0.0865
2022-10-04 20:22:21 - train: epoch 0071, iter [00920, 01251], lr: 0.000143, loss: 0.0814
2022-10-04 20:22:49 - train: epoch 0071, iter [00930, 01251], lr: 0.000143, loss: 0.0861
2022-10-04 20:23:17 - train: epoch 0071, iter [00940, 01251], lr: 0.000143, loss: 0.0760
2022-10-04 20:23:45 - train: epoch 0071, iter [00950, 01251], lr: 0.000143, loss: 0.0886
2022-10-04 20:24:13 - train: epoch 0071, iter [00960, 01251], lr: 0.000143, loss: 0.0851
2022-10-04 20:24:41 - train: epoch 0071, iter [00970, 01251], lr: 0.000143, loss: 0.0837
2022-10-04 20:25:09 - train: epoch 0071, iter [00980, 01251], lr: 0.000143, loss: 0.0789
2022-10-04 20:25:37 - train: epoch 0071, iter [00990, 01251], lr: 0.000143, loss: 0.0927
2022-10-04 20:26:05 - train: epoch 0071, iter [01000, 01251], lr: 0.000143, loss: 0.0823
2022-10-04 20:26:33 - train: epoch 0071, iter [01010, 01251], lr: 0.000143, loss: 0.0802
2022-10-04 20:27:01 - train: epoch 0071, iter [01020, 01251], lr: 0.000143, loss: 0.0849
2022-10-04 20:27:29 - train: epoch 0071, iter [01030, 01251], lr: 0.000143, loss: 0.0847
2022-10-04 20:27:57 - train: epoch 0071, iter [01040, 01251], lr: 0.000143, loss: 0.0780
2022-10-04 20:28:25 - train: epoch 0071, iter [01050, 01251], lr: 0.000142, loss: 0.0818
2022-10-04 20:28:53 - train: epoch 0071, iter [01060, 01251], lr: 0.000142, loss: 0.0896
2022-10-04 20:29:21 - train: epoch 0071, iter [01070, 01251], lr: 0.000142, loss: 0.0770
2022-10-04 20:29:49 - train: epoch 0071, iter [01080, 01251], lr: 0.000142, loss: 0.0800
2022-10-04 20:30:17 - train: epoch 0071, iter [01090, 01251], lr: 0.000142, loss: 0.0874
2022-10-04 20:30:45 - train: epoch 0071, iter [01100, 01251], lr: 0.000142, loss: 0.0807
2022-10-04 20:31:13 - train: epoch 0071, iter [01110, 01251], lr: 0.000142, loss: 0.0866
2022-10-04 20:31:41 - train: epoch 0071, iter [01120, 01251], lr: 0.000142, loss: 0.0861
2022-10-04 20:32:09 - train: epoch 0071, iter [01130, 01251], lr: 0.000142, loss: 0.0809
2022-10-04 20:32:37 - train: epoch 0071, iter [01140, 01251], lr: 0.000142, loss: 0.0888
2022-10-04 20:33:05 - train: epoch 0071, iter [01150, 01251], lr: 0.000142, loss: 0.0866
2022-10-04 20:33:33 - train: epoch 0071, iter [01160, 01251], lr: 0.000142, loss: 0.0783
2022-10-04 20:34:01 - train: epoch 0071, iter [01170, 01251], lr: 0.000142, loss: 0.0915
2022-10-04 20:34:29 - train: epoch 0071, iter [01180, 01251], lr: 0.000142, loss: 0.0833
2022-10-04 20:34:57 - train: epoch 0071, iter [01190, 01251], lr: 0.000141, loss: 0.0862
2022-10-04 20:35:25 - train: epoch 0071, iter [01200, 01251], lr: 0.000141, loss: 0.0834
2022-10-04 20:35:53 - train: epoch 0071, iter [01210, 01251], lr: 0.000141, loss: 0.0842
2022-10-04 20:36:21 - train: epoch 0071, iter [01220, 01251], lr: 0.000141, loss: 0.0874
2022-10-04 20:36:49 - train: epoch 0071, iter [01230, 01251], lr: 0.000141, loss: 0.0910
2022-10-04 20:37:17 - train: epoch 0071, iter [01240, 01251], lr: 0.000141, loss: 0.0856
2022-10-04 20:37:45 - train: epoch 0071, iter [01250, 01251], lr: 0.000141, loss: 0.0862
2022-10-04 20:37:49 - train: epoch 071, train_loss: 0.0846
2022-10-04 20:37:51 - until epoch: 071, best_loss: 0.0846
2022-10-04 20:37:51 - epoch 072 lr: 0.000141
2022-10-04 20:38:26 - train: epoch 0072, iter [00010, 01251], lr: 0.000141, loss: 0.0822
2022-10-04 20:38:53 - train: epoch 0072, iter [00020, 01251], lr: 0.000141, loss: 0.0860
2022-10-04 20:39:21 - train: epoch 0072, iter [00030, 01251], lr: 0.000141, loss: 0.0798
2022-10-04 20:39:49 - train: epoch 0072, iter [00040, 01251], lr: 0.000141, loss: 0.0910
2022-10-04 20:40:18 - train: epoch 0072, iter [00050, 01251], lr: 0.000141, loss: 0.0942
2022-10-04 20:40:45 - train: epoch 0072, iter [00060, 01251], lr: 0.000141, loss: 0.0836
2022-10-04 20:41:13 - train: epoch 0072, iter [00070, 01251], lr: 0.000141, loss: 0.0820
2022-10-04 20:41:41 - train: epoch 0072, iter [00080, 01251], lr: 0.000140, loss: 0.0828
2022-10-04 20:42:09 - train: epoch 0072, iter [00090, 01251], lr: 0.000140, loss: 0.0904
2022-10-04 20:42:37 - train: epoch 0072, iter [00100, 01251], lr: 0.000140, loss: 0.0842
2022-10-04 20:43:05 - train: epoch 0072, iter [00110, 01251], lr: 0.000140, loss: 0.0851
2022-10-04 20:43:33 - train: epoch 0072, iter [00120, 01251], lr: 0.000140, loss: 0.0782
2022-10-04 20:44:01 - train: epoch 0072, iter [00130, 01251], lr: 0.000140, loss: 0.0856
2022-10-04 20:44:29 - train: epoch 0072, iter [00140, 01251], lr: 0.000140, loss: 0.0859
2022-10-04 20:44:57 - train: epoch 0072, iter [00150, 01251], lr: 0.000140, loss: 0.0770
2022-10-04 20:45:25 - train: epoch 0072, iter [00160, 01251], lr: 0.000140, loss: 0.0840
2022-10-04 20:45:53 - train: epoch 0072, iter [00170, 01251], lr: 0.000140, loss: 0.0949
2022-10-04 20:46:21 - train: epoch 0072, iter [00180, 01251], lr: 0.000140, loss: 0.0936
2022-10-04 20:46:49 - train: epoch 0072, iter [00190, 01251], lr: 0.000140, loss: 0.0945
2022-10-04 20:47:17 - train: epoch 0072, iter [00200, 01251], lr: 0.000140, loss: 0.0876
2022-10-04 20:47:45 - train: epoch 0072, iter [00210, 01251], lr: 0.000140, loss: 0.0835
2022-10-04 20:48:13 - train: epoch 0072, iter [00220, 01251], lr: 0.000139, loss: 0.0792
2022-10-04 20:48:40 - train: epoch 0072, iter [00230, 01251], lr: 0.000139, loss: 0.0864
2022-10-04 20:49:08 - train: epoch 0072, iter [00240, 01251], lr: 0.000139, loss: 0.0846
2022-10-04 20:49:36 - train: epoch 0072, iter [00250, 01251], lr: 0.000139, loss: 0.0818
2022-10-04 20:50:04 - train: epoch 0072, iter [00260, 01251], lr: 0.000139, loss: 0.0855
2022-10-04 20:50:32 - train: epoch 0072, iter [00270, 01251], lr: 0.000139, loss: 0.0816
2022-10-04 20:51:00 - train: epoch 0072, iter [00280, 01251], lr: 0.000139, loss: 0.0832
2022-10-04 20:51:28 - train: epoch 0072, iter [00290, 01251], lr: 0.000139, loss: 0.0850
2022-10-04 20:51:56 - train: epoch 0072, iter [00300, 01251], lr: 0.000139, loss: 0.0842
2022-10-04 20:52:24 - train: epoch 0072, iter [00310, 01251], lr: 0.000139, loss: 0.0819
2022-10-04 20:52:52 - train: epoch 0072, iter [00320, 01251], lr: 0.000139, loss: 0.0885
2022-10-04 20:53:20 - train: epoch 0072, iter [00330, 01251], lr: 0.000139, loss: 0.0855
2022-10-04 20:53:48 - train: epoch 0072, iter [00340, 01251], lr: 0.000139, loss: 0.0868
2022-10-04 20:54:16 - train: epoch 0072, iter [00350, 01251], lr: 0.000139, loss: 0.0766
2022-10-04 20:54:44 - train: epoch 0072, iter [00360, 01251], lr: 0.000138, loss: 0.0851
2022-10-04 20:55:12 - train: epoch 0072, iter [00370, 01251], lr: 0.000138, loss: 0.0892
2022-10-04 20:55:40 - train: epoch 0072, iter [00380, 01251], lr: 0.000138, loss: 0.0866
2022-10-04 20:56:08 - train: epoch 0072, iter [00390, 01251], lr: 0.000138, loss: 0.0853
2022-10-04 20:56:36 - train: epoch 0072, iter [00400, 01251], lr: 0.000138, loss: 0.0870
2022-10-04 20:57:04 - train: epoch 0072, iter [00410, 01251], lr: 0.000138, loss: 0.0942
2022-10-04 20:57:32 - train: epoch 0072, iter [00420, 01251], lr: 0.000138, loss: 0.0888
2022-10-04 20:58:00 - train: epoch 0072, iter [00430, 01251], lr: 0.000138, loss: 0.0823
2022-10-04 20:58:28 - train: epoch 0072, iter [00440, 01251], lr: 0.000138, loss: 0.0798
2022-10-04 20:58:56 - train: epoch 0072, iter [00450, 01251], lr: 0.000138, loss: 0.0850
2022-10-04 20:59:24 - train: epoch 0072, iter [00460, 01251], lr: 0.000138, loss: 0.0826
2022-10-04 20:59:52 - train: epoch 0072, iter [00470, 01251], lr: 0.000138, loss: 0.0821
2022-10-04 21:00:20 - train: epoch 0072, iter [00480, 01251], lr: 0.000138, loss: 0.0903
2022-10-04 21:00:48 - train: epoch 0072, iter [00490, 01251], lr: 0.000138, loss: 0.0777
2022-10-04 21:01:16 - train: epoch 0072, iter [00500, 01251], lr: 0.000137, loss: 0.0746
2022-10-04 21:01:44 - train: epoch 0072, iter [00510, 01251], lr: 0.000137, loss: 0.0764
2022-10-04 21:02:12 - train: epoch 0072, iter [00520, 01251], lr: 0.000137, loss: 0.0916
2022-10-04 21:02:40 - train: epoch 0072, iter [00530, 01251], lr: 0.000137, loss: 0.0868
2022-10-04 21:03:08 - train: epoch 0072, iter [00540, 01251], lr: 0.000137, loss: 0.0873
2022-10-04 21:03:36 - train: epoch 0072, iter [00550, 01251], lr: 0.000137, loss: 0.0833
2022-10-04 21:04:04 - train: epoch 0072, iter [00560, 01251], lr: 0.000137, loss: 0.0824
2022-10-04 21:04:32 - train: epoch 0072, iter [00570, 01251], lr: 0.000137, loss: 0.0848
2022-10-04 21:05:00 - train: epoch 0072, iter [00580, 01251], lr: 0.000137, loss: 0.0807
2022-10-04 21:05:28 - train: epoch 0072, iter [00590, 01251], lr: 0.000137, loss: 0.0838
2022-10-04 21:05:56 - train: epoch 0072, iter [00600, 01251], lr: 0.000137, loss: 0.0761
2022-10-04 21:06:24 - train: epoch 0072, iter [00610, 01251], lr: 0.000137, loss: 0.0911
2022-10-04 21:06:52 - train: epoch 0072, iter [00620, 01251], lr: 0.000137, loss: 0.0886
2022-10-04 21:07:20 - train: epoch 0072, iter [00630, 01251], lr: 0.000137, loss: 0.0862
2022-10-04 21:07:48 - train: epoch 0072, iter [00640, 01251], lr: 0.000137, loss: 0.0836
2022-10-04 21:08:16 - train: epoch 0072, iter [00650, 01251], lr: 0.000136, loss: 0.0781
2022-10-04 21:08:44 - train: epoch 0072, iter [00660, 01251], lr: 0.000136, loss: 0.0865
2022-10-04 21:09:12 - train: epoch 0072, iter [00670, 01251], lr: 0.000136, loss: 0.0863
2022-10-04 21:09:40 - train: epoch 0072, iter [00680, 01251], lr: 0.000136, loss: 0.0862
2022-10-04 21:10:08 - train: epoch 0072, iter [00690, 01251], lr: 0.000136, loss: 0.0831
2022-10-04 21:10:36 - train: epoch 0072, iter [00700, 01251], lr: 0.000136, loss: 0.0824
2022-10-04 21:11:04 - train: epoch 0072, iter [00710, 01251], lr: 0.000136, loss: 0.0871
2022-10-04 21:11:32 - train: epoch 0072, iter [00720, 01251], lr: 0.000136, loss: 0.0859
2022-10-04 21:12:00 - train: epoch 0072, iter [00730, 01251], lr: 0.000136, loss: 0.0856
2022-10-04 21:12:28 - train: epoch 0072, iter [00740, 01251], lr: 0.000136, loss: 0.0823
2022-10-04 21:12:56 - train: epoch 0072, iter [00750, 01251], lr: 0.000136, loss: 0.0834
2022-10-04 21:13:24 - train: epoch 0072, iter [00760, 01251], lr: 0.000136, loss: 0.0840
2022-10-04 21:13:52 - train: epoch 0072, iter [00770, 01251], lr: 0.000136, loss: 0.0894
2022-10-04 21:14:20 - train: epoch 0072, iter [00780, 01251], lr: 0.000136, loss: 0.0822
2022-10-04 21:14:48 - train: epoch 0072, iter [00790, 01251], lr: 0.000135, loss: 0.0872
2022-10-04 21:15:16 - train: epoch 0072, iter [00800, 01251], lr: 0.000135, loss: 0.0847
2022-10-04 21:15:44 - train: epoch 0072, iter [00810, 01251], lr: 0.000135, loss: 0.0761
2022-10-04 21:16:12 - train: epoch 0072, iter [00820, 01251], lr: 0.000135, loss: 0.0767
2022-10-04 21:16:40 - train: epoch 0072, iter [00830, 01251], lr: 0.000135, loss: 0.0850
2022-10-04 21:17:08 - train: epoch 0072, iter [00840, 01251], lr: 0.000135, loss: 0.0907
2022-10-04 21:17:36 - train: epoch 0072, iter [00850, 01251], lr: 0.000135, loss: 0.0853
2022-10-04 21:18:05 - train: epoch 0072, iter [00860, 01251], lr: 0.000135, loss: 0.0910
2022-10-04 21:18:33 - train: epoch 0072, iter [00870, 01251], lr: 0.000135, loss: 0.0818
2022-10-04 21:19:00 - train: epoch 0072, iter [00880, 01251], lr: 0.000135, loss: 0.0860
2022-10-04 21:19:29 - train: epoch 0072, iter [00890, 01251], lr: 0.000135, loss: 0.0892
2022-10-04 21:19:57 - train: epoch 0072, iter [00900, 01251], lr: 0.000135, loss: 0.0849
2022-10-04 21:20:25 - train: epoch 0072, iter [00910, 01251], lr: 0.000135, loss: 0.0859
2022-10-04 21:20:53 - train: epoch 0072, iter [00920, 01251], lr: 0.000135, loss: 0.0863
2022-10-04 21:21:21 - train: epoch 0072, iter [00930, 01251], lr: 0.000134, loss: 0.0818
2022-10-04 21:21:49 - train: epoch 0072, iter [00940, 01251], lr: 0.000134, loss: 0.0795
2022-10-04 21:22:17 - train: epoch 0072, iter [00950, 01251], lr: 0.000134, loss: 0.0850
2022-10-04 21:22:45 - train: epoch 0072, iter [00960, 01251], lr: 0.000134, loss: 0.0819
2022-10-04 21:23:13 - train: epoch 0072, iter [00970, 01251], lr: 0.000134, loss: 0.0827
2022-10-04 21:23:41 - train: epoch 0072, iter [00980, 01251], lr: 0.000134, loss: 0.0868
2022-10-04 21:24:09 - train: epoch 0072, iter [00990, 01251], lr: 0.000134, loss: 0.0814
2022-10-04 21:24:37 - train: epoch 0072, iter [01000, 01251], lr: 0.000134, loss: 0.0888
2022-10-04 21:25:05 - train: epoch 0072, iter [01010, 01251], lr: 0.000134, loss: 0.0829
2022-10-04 21:25:34 - train: epoch 0072, iter [01020, 01251], lr: 0.000134, loss: 0.0825
2022-10-04 21:26:02 - train: epoch 0072, iter [01030, 01251], lr: 0.000134, loss: 0.0830
2022-10-04 21:26:30 - train: epoch 0072, iter [01040, 01251], lr: 0.000134, loss: 0.0902
2022-10-04 21:26:58 - train: epoch 0072, iter [01050, 01251], lr: 0.000134, loss: 0.0861
2022-10-04 21:27:26 - train: epoch 0072, iter [01060, 01251], lr: 0.000134, loss: 0.0847
2022-10-04 21:27:54 - train: epoch 0072, iter [01070, 01251], lr: 0.000134, loss: 0.0792
2022-10-04 21:28:22 - train: epoch 0072, iter [01080, 01251], lr: 0.000133, loss: 0.0838
2022-10-04 21:28:50 - train: epoch 0072, iter [01090, 01251], lr: 0.000133, loss: 0.0933
2022-10-04 21:29:18 - train: epoch 0072, iter [01100, 01251], lr: 0.000133, loss: 0.0832
2022-10-04 21:29:46 - train: epoch 0072, iter [01110, 01251], lr: 0.000133, loss: 0.0871
2022-10-04 21:30:15 - train: epoch 0072, iter [01120, 01251], lr: 0.000133, loss: 0.0835
2022-10-04 21:30:43 - train: epoch 0072, iter [01130, 01251], lr: 0.000133, loss: 0.0837
2022-10-04 21:31:11 - train: epoch 0072, iter [01140, 01251], lr: 0.000133, loss: 0.0851
2022-10-04 21:31:39 - train: epoch 0072, iter [01150, 01251], lr: 0.000133, loss: 0.0856
2022-10-04 21:32:07 - train: epoch 0072, iter [01160, 01251], lr: 0.000133, loss: 0.0879
2022-10-04 21:32:36 - train: epoch 0072, iter [01170, 01251], lr: 0.000133, loss: 0.0858
2022-10-04 21:33:04 - train: epoch 0072, iter [01180, 01251], lr: 0.000133, loss: 0.0874
2022-10-04 21:33:32 - train: epoch 0072, iter [01190, 01251], lr: 0.000133, loss: 0.0775
2022-10-04 21:34:00 - train: epoch 0072, iter [01200, 01251], lr: 0.000133, loss: 0.0844
2022-10-04 21:34:28 - train: epoch 0072, iter [01210, 01251], lr: 0.000133, loss: 0.0900
2022-10-04 21:34:56 - train: epoch 0072, iter [01220, 01251], lr: 0.000132, loss: 0.0787
2022-10-04 21:35:25 - train: epoch 0072, iter [01230, 01251], lr: 0.000132, loss: 0.0795
2022-10-04 21:35:53 - train: epoch 0072, iter [01240, 01251], lr: 0.000132, loss: 0.0878
2022-10-04 21:36:21 - train: epoch 0072, iter [01250, 01251], lr: 0.000132, loss: 0.0812
2022-10-04 21:36:25 - train: epoch 072, train_loss: 0.0844
2022-10-04 21:36:27 - until epoch: 072, best_loss: 0.0844
2022-10-04 21:36:27 - epoch 073 lr: 0.000132
2022-10-04 21:37:02 - train: epoch 0073, iter [00010, 01251], lr: 0.000132, loss: 0.0802
2022-10-04 21:37:30 - train: epoch 0073, iter [00020, 01251], lr: 0.000132, loss: 0.0853
2022-10-04 21:37:58 - train: epoch 0073, iter [00030, 01251], lr: 0.000132, loss: 0.0834
2022-10-04 21:38:26 - train: epoch 0073, iter [00040, 01251], lr: 0.000132, loss: 0.0899
2022-10-04 21:38:54 - train: epoch 0073, iter [00050, 01251], lr: 0.000132, loss: 0.0817
2022-10-04 21:39:22 - train: epoch 0073, iter [00060, 01251], lr: 0.000132, loss: 0.0864
2022-10-04 21:39:50 - train: epoch 0073, iter [00070, 01251], lr: 0.000132, loss: 0.0863
2022-10-04 21:40:18 - train: epoch 0073, iter [00080, 01251], lr: 0.000132, loss: 0.0852
2022-10-04 21:40:46 - train: epoch 0073, iter [00090, 01251], lr: 0.000132, loss: 0.0831
2022-10-04 21:41:14 - train: epoch 0073, iter [00100, 01251], lr: 0.000132, loss: 0.0851
2022-10-04 21:41:42 - train: epoch 0073, iter [00110, 01251], lr: 0.000131, loss: 0.0820
2022-10-04 21:42:10 - train: epoch 0073, iter [00120, 01251], lr: 0.000131, loss: 0.0852
2022-10-04 21:42:38 - train: epoch 0073, iter [00130, 01251], lr: 0.000131, loss: 0.0821
2022-10-04 21:43:06 - train: epoch 0073, iter [00140, 01251], lr: 0.000131, loss: 0.0879
2022-10-04 21:43:34 - train: epoch 0073, iter [00150, 01251], lr: 0.000131, loss: 0.0819
2022-10-04 21:44:02 - train: epoch 0073, iter [00160, 01251], lr: 0.000131, loss: 0.0848
2022-10-04 21:44:30 - train: epoch 0073, iter [00170, 01251], lr: 0.000131, loss: 0.0810
2022-10-04 21:44:58 - train: epoch 0073, iter [00180, 01251], lr: 0.000131, loss: 0.0867
2022-10-04 21:45:26 - train: epoch 0073, iter [00190, 01251], lr: 0.000131, loss: 0.0813
2022-10-04 21:45:54 - train: epoch 0073, iter [00200, 01251], lr: 0.000131, loss: 0.0878
2022-10-04 21:46:22 - train: epoch 0073, iter [00210, 01251], lr: 0.000131, loss: 0.0797
2022-10-04 21:46:50 - train: epoch 0073, iter [00220, 01251], lr: 0.000131, loss: 0.0869
2022-10-04 21:47:18 - train: epoch 0073, iter [00230, 01251], lr: 0.000131, loss: 0.0847
2022-10-04 21:47:46 - train: epoch 0073, iter [00240, 01251], lr: 0.000131, loss: 0.0773
2022-10-04 21:48:14 - train: epoch 0073, iter [00250, 01251], lr: 0.000131, loss: 0.0842
2022-10-04 21:48:42 - train: epoch 0073, iter [00260, 01251], lr: 0.000130, loss: 0.0897
2022-10-04 21:49:10 - train: epoch 0073, iter [00270, 01251], lr: 0.000130, loss: 0.0877
2022-10-04 21:49:39 - train: epoch 0073, iter [00280, 01251], lr: 0.000130, loss: 0.0828
2022-10-04 21:50:07 - train: epoch 0073, iter [00290, 01251], lr: 0.000130, loss: 0.0859
2022-10-04 21:50:35 - train: epoch 0073, iter [00300, 01251], lr: 0.000130, loss: 0.0859
2022-10-04 21:51:03 - train: epoch 0073, iter [00310, 01251], lr: 0.000130, loss: 0.0860
2022-10-04 21:51:31 - train: epoch 0073, iter [00320, 01251], lr: 0.000130, loss: 0.0828
2022-10-04 21:51:59 - train: epoch 0073, iter [00330, 01251], lr: 0.000130, loss: 0.0879
2022-10-04 21:52:27 - train: epoch 0073, iter [00340, 01251], lr: 0.000130, loss: 0.0951
2022-10-04 21:52:55 - train: epoch 0073, iter [00350, 01251], lr: 0.000130, loss: 0.0789
2022-10-04 21:53:23 - train: epoch 0073, iter [00360, 01251], lr: 0.000130, loss: 0.0785
2022-10-04 21:53:51 - train: epoch 0073, iter [00370, 01251], lr: 0.000130, loss: 0.0842
2022-10-04 21:54:19 - train: epoch 0073, iter [00380, 01251], lr: 0.000130, loss: 0.0801
2022-10-04 21:54:47 - train: epoch 0073, iter [00390, 01251], lr: 0.000130, loss: 0.0826
2022-10-04 21:55:15 - train: epoch 0073, iter [00400, 01251], lr: 0.000129, loss: 0.0860
2022-10-04 21:55:44 - train: epoch 0073, iter [00410, 01251], lr: 0.000129, loss: 0.0820
2022-10-04 21:56:12 - train: epoch 0073, iter [00420, 01251], lr: 0.000129, loss: 0.0935
2022-10-04 21:56:40 - train: epoch 0073, iter [00430, 01251], lr: 0.000129, loss: 0.0822
2022-10-04 21:57:08 - train: epoch 0073, iter [00440, 01251], lr: 0.000129, loss: 0.0847
2022-10-04 21:57:36 - train: epoch 0073, iter [00450, 01251], lr: 0.000129, loss: 0.0886
2022-10-04 21:58:04 - train: epoch 0073, iter [00460, 01251], lr: 0.000129, loss: 0.0802
2022-10-04 21:58:32 - train: epoch 0073, iter [00470, 01251], lr: 0.000129, loss: 0.0814
2022-10-04 21:59:00 - train: epoch 0073, iter [00480, 01251], lr: 0.000129, loss: 0.0880
2022-10-04 21:59:28 - train: epoch 0073, iter [00490, 01251], lr: 0.000129, loss: 0.0910
2022-10-04 21:59:56 - train: epoch 0073, iter [00500, 01251], lr: 0.000129, loss: 0.0914
2022-10-04 22:00:24 - train: epoch 0073, iter [00510, 01251], lr: 0.000129, loss: 0.0829
2022-10-04 22:00:52 - train: epoch 0073, iter [00520, 01251], lr: 0.000129, loss: 0.0878
2022-10-04 22:01:20 - train: epoch 0073, iter [00530, 01251], lr: 0.000129, loss: 0.0803
2022-10-04 22:01:48 - train: epoch 0073, iter [00540, 01251], lr: 0.000129, loss: 0.0843
2022-10-04 22:02:16 - train: epoch 0073, iter [00550, 01251], lr: 0.000128, loss: 0.0823
2022-10-04 22:02:44 - train: epoch 0073, iter [00560, 01251], lr: 0.000128, loss: 0.0895
2022-10-04 22:03:12 - train: epoch 0073, iter [00570, 01251], lr: 0.000128, loss: 0.0803
2022-10-04 22:03:40 - train: epoch 0073, iter [00580, 01251], lr: 0.000128, loss: 0.0842
2022-10-04 22:04:08 - train: epoch 0073, iter [00590, 01251], lr: 0.000128, loss: 0.0836
2022-10-04 22:04:36 - train: epoch 0073, iter [00600, 01251], lr: 0.000128, loss: 0.0850
2022-10-04 22:05:04 - train: epoch 0073, iter [00610, 01251], lr: 0.000128, loss: 0.0828
2022-10-04 22:05:33 - train: epoch 0073, iter [00620, 01251], lr: 0.000128, loss: 0.0795
2022-10-04 22:06:01 - train: epoch 0073, iter [00630, 01251], lr: 0.000128, loss: 0.0785
2022-10-04 22:06:29 - train: epoch 0073, iter [00640, 01251], lr: 0.000128, loss: 0.0877
2022-10-04 22:06:57 - train: epoch 0073, iter [00650, 01251], lr: 0.000128, loss: 0.0814
2022-10-04 22:07:25 - train: epoch 0073, iter [00660, 01251], lr: 0.000128, loss: 0.0884
2022-10-04 22:07:53 - train: epoch 0073, iter [00670, 01251], lr: 0.000128, loss: 0.0840
2022-10-04 22:08:21 - train: epoch 0073, iter [00680, 01251], lr: 0.000128, loss: 0.0842
2022-10-04 22:08:50 - train: epoch 0073, iter [00690, 01251], lr: 0.000127, loss: 0.0926
2022-10-04 22:09:18 - train: epoch 0073, iter [00700, 01251], lr: 0.000127, loss: 0.0880
2022-10-04 22:09:46 - train: epoch 0073, iter [00710, 01251], lr: 0.000127, loss: 0.0862
2022-10-04 22:10:14 - train: epoch 0073, iter [00720, 01251], lr: 0.000127, loss: 0.0872
2022-10-04 22:10:42 - train: epoch 0073, iter [00730, 01251], lr: 0.000127, loss: 0.0788
2022-10-04 22:11:10 - train: epoch 0073, iter [00740, 01251], lr: 0.000127, loss: 0.0855
2022-10-04 22:11:38 - train: epoch 0073, iter [00750, 01251], lr: 0.000127, loss: 0.0820
2022-10-04 22:12:06 - train: epoch 0073, iter [00760, 01251], lr: 0.000127, loss: 0.0834
2022-10-04 22:12:34 - train: epoch 0073, iter [00770, 01251], lr: 0.000127, loss: 0.0812
2022-10-04 22:13:02 - train: epoch 0073, iter [00780, 01251], lr: 0.000127, loss: 0.0826
2022-10-04 22:13:30 - train: epoch 0073, iter [00790, 01251], lr: 0.000127, loss: 0.0859
2022-10-04 22:13:58 - train: epoch 0073, iter [00800, 01251], lr: 0.000127, loss: 0.0830
2022-10-04 22:14:26 - train: epoch 0073, iter [00810, 01251], lr: 0.000127, loss: 0.0829
2022-10-04 22:14:54 - train: epoch 0073, iter [00820, 01251], lr: 0.000127, loss: 0.0888
2022-10-04 22:15:22 - train: epoch 0073, iter [00830, 01251], lr: 0.000127, loss: 0.0870
2022-10-04 22:15:50 - train: epoch 0073, iter [00840, 01251], lr: 0.000126, loss: 0.0902
2022-10-04 22:16:18 - train: epoch 0073, iter [00850, 01251], lr: 0.000126, loss: 0.0833
2022-10-04 22:16:46 - train: epoch 0073, iter [00860, 01251], lr: 0.000126, loss: 0.0765
2022-10-04 22:17:14 - train: epoch 0073, iter [00870, 01251], lr: 0.000126, loss: 0.0802
2022-10-04 22:17:42 - train: epoch 0073, iter [00880, 01251], lr: 0.000126, loss: 0.0825
2022-10-04 22:18:10 - train: epoch 0073, iter [00890, 01251], lr: 0.000126, loss: 0.0908
2022-10-04 22:18:38 - train: epoch 0073, iter [00900, 01251], lr: 0.000126, loss: 0.0827
2022-10-04 22:19:06 - train: epoch 0073, iter [00910, 01251], lr: 0.000126, loss: 0.0855
2022-10-04 22:19:34 - train: epoch 0073, iter [00920, 01251], lr: 0.000126, loss: 0.0890
2022-10-04 22:20:02 - train: epoch 0073, iter [00930, 01251], lr: 0.000126, loss: 0.0850
2022-10-04 22:20:30 - train: epoch 0073, iter [00940, 01251], lr: 0.000126, loss: 0.0837
2022-10-04 22:20:58 - train: epoch 0073, iter [00950, 01251], lr: 0.000126, loss: 0.0737
2022-10-04 22:21:26 - train: epoch 0073, iter [00960, 01251], lr: 0.000126, loss: 0.0802
2022-10-04 22:21:54 - train: epoch 0073, iter [00970, 01251], lr: 0.000126, loss: 0.0828
2022-10-04 22:22:22 - train: epoch 0073, iter [00980, 01251], lr: 0.000126, loss: 0.0761
2022-10-04 22:22:50 - train: epoch 0073, iter [00990, 01251], lr: 0.000125, loss: 0.0987
2022-10-04 22:23:18 - train: epoch 0073, iter [01000, 01251], lr: 0.000125, loss: 0.0845
2022-10-04 22:23:46 - train: epoch 0073, iter [01010, 01251], lr: 0.000125, loss: 0.0754
2022-10-04 22:24:14 - train: epoch 0073, iter [01020, 01251], lr: 0.000125, loss: 0.0788
2022-10-04 22:24:42 - train: epoch 0073, iter [01030, 01251], lr: 0.000125, loss: 0.0855
2022-10-04 22:25:10 - train: epoch 0073, iter [01040, 01251], lr: 0.000125, loss: 0.0851
2022-10-04 22:25:38 - train: epoch 0073, iter [01050, 01251], lr: 0.000125, loss: 0.0846
2022-10-04 22:26:06 - train: epoch 0073, iter [01060, 01251], lr: 0.000125, loss: 0.0778
2022-10-04 22:26:34 - train: epoch 0073, iter [01070, 01251], lr: 0.000125, loss: 0.0898
2022-10-04 22:27:02 - train: epoch 0073, iter [01080, 01251], lr: 0.000125, loss: 0.0832
2022-10-04 22:27:30 - train: epoch 0073, iter [01090, 01251], lr: 0.000125, loss: 0.0793
2022-10-04 22:27:58 - train: epoch 0073, iter [01100, 01251], lr: 0.000125, loss: 0.0817
2022-10-04 22:28:27 - train: epoch 0073, iter [01110, 01251], lr: 0.000125, loss: 0.0823
2022-10-04 22:28:55 - train: epoch 0073, iter [01120, 01251], lr: 0.000125, loss: 0.0858
2022-10-04 22:29:23 - train: epoch 0073, iter [01130, 01251], lr: 0.000124, loss: 0.0848
2022-10-04 22:29:51 - train: epoch 0073, iter [01140, 01251], lr: 0.000124, loss: 0.0849
2022-10-04 22:30:19 - train: epoch 0073, iter [01150, 01251], lr: 0.000124, loss: 0.0839
2022-10-04 22:30:47 - train: epoch 0073, iter [01160, 01251], lr: 0.000124, loss: 0.0880
2022-10-04 22:31:15 - train: epoch 0073, iter [01170, 01251], lr: 0.000124, loss: 0.0868
2022-10-04 22:31:43 - train: epoch 0073, iter [01180, 01251], lr: 0.000124, loss: 0.0872
2022-10-04 22:32:11 - train: epoch 0073, iter [01190, 01251], lr: 0.000124, loss: 0.0818
2022-10-04 22:32:39 - train: epoch 0073, iter [01200, 01251], lr: 0.000124, loss: 0.0840
2022-10-04 22:33:07 - train: epoch 0073, iter [01210, 01251], lr: 0.000124, loss: 0.0886
2022-10-04 22:33:35 - train: epoch 0073, iter [01220, 01251], lr: 0.000124, loss: 0.0841
2022-10-04 22:34:03 - train: epoch 0073, iter [01230, 01251], lr: 0.000124, loss: 0.0855
2022-10-04 22:34:31 - train: epoch 0073, iter [01240, 01251], lr: 0.000124, loss: 0.0871
2022-10-04 22:34:59 - train: epoch 0073, iter [01250, 01251], lr: 0.000124, loss: 0.0794
2022-10-04 22:35:03 - train: epoch 073, train_loss: 0.0842
2022-10-04 22:35:05 - until epoch: 073, best_loss: 0.0842
2022-10-04 22:35:05 - epoch 074 lr: 0.000124
2022-10-04 22:35:40 - train: epoch 0074, iter [00010, 01251], lr: 0.000124, loss: 0.0904
2022-10-04 22:36:08 - train: epoch 0074, iter [00020, 01251], lr: 0.000124, loss: 0.0811
2022-10-04 22:36:35 - train: epoch 0074, iter [00030, 01251], lr: 0.000123, loss: 0.0800
2022-10-04 22:37:03 - train: epoch 0074, iter [00040, 01251], lr: 0.000123, loss: 0.0921
2022-10-04 22:37:31 - train: epoch 0074, iter [00050, 01251], lr: 0.000123, loss: 0.0792
2022-10-04 22:37:59 - train: epoch 0074, iter [00060, 01251], lr: 0.000123, loss: 0.0813
2022-10-04 22:38:27 - train: epoch 0074, iter [00070, 01251], lr: 0.000123, loss: 0.0879
2022-10-04 22:38:55 - train: epoch 0074, iter [00080, 01251], lr: 0.000123, loss: 0.0832
2022-10-04 22:39:23 - train: epoch 0074, iter [00090, 01251], lr: 0.000123, loss: 0.0847
2022-10-04 22:39:51 - train: epoch 0074, iter [00100, 01251], lr: 0.000123, loss: 0.0819
2022-10-04 22:40:19 - train: epoch 0074, iter [00110, 01251], lr: 0.000123, loss: 0.0866
2022-10-04 22:40:47 - train: epoch 0074, iter [00120, 01251], lr: 0.000123, loss: 0.0809
2022-10-04 22:41:15 - train: epoch 0074, iter [00130, 01251], lr: 0.000123, loss: 0.0855
2022-10-04 22:41:43 - train: epoch 0074, iter [00140, 01251], lr: 0.000123, loss: 0.0878
2022-10-04 22:42:11 - train: epoch 0074, iter [00150, 01251], lr: 0.000123, loss: 0.0830
2022-10-04 22:42:39 - train: epoch 0074, iter [00160, 01251], lr: 0.000123, loss: 0.0853
2022-10-04 22:43:07 - train: epoch 0074, iter [00170, 01251], lr: 0.000123, loss: 0.0868
2022-10-04 22:43:35 - train: epoch 0074, iter [00180, 01251], lr: 0.000122, loss: 0.0827
2022-10-04 22:44:03 - train: epoch 0074, iter [00190, 01251], lr: 0.000122, loss: 0.0836
2022-10-04 22:44:31 - train: epoch 0074, iter [00200, 01251], lr: 0.000122, loss: 0.0821
2022-10-04 22:44:59 - train: epoch 0074, iter [00210, 01251], lr: 0.000122, loss: 0.0838
2022-10-04 22:45:27 - train: epoch 0074, iter [00220, 01251], lr: 0.000122, loss: 0.0834
2022-10-04 22:45:55 - train: epoch 0074, iter [00230, 01251], lr: 0.000122, loss: 0.0883
2022-10-04 22:46:23 - train: epoch 0074, iter [00240, 01251], lr: 0.000122, loss: 0.0870
2022-10-04 22:46:51 - train: epoch 0074, iter [00250, 01251], lr: 0.000122, loss: 0.0874
2022-10-04 22:47:19 - train: epoch 0074, iter [00260, 01251], lr: 0.000122, loss: 0.0882
2022-10-04 22:47:47 - train: epoch 0074, iter [00270, 01251], lr: 0.000122, loss: 0.0837
2022-10-04 22:48:14 - train: epoch 0074, iter [00280, 01251], lr: 0.000122, loss: 0.0774
2022-10-04 22:48:42 - train: epoch 0074, iter [00290, 01251], lr: 0.000122, loss: 0.0806
2022-10-04 22:49:10 - train: epoch 0074, iter [00300, 01251], lr: 0.000122, loss: 0.0818
2022-10-04 22:49:39 - train: epoch 0074, iter [00310, 01251], lr: 0.000122, loss: 0.0909
2022-10-04 22:50:07 - train: epoch 0074, iter [00320, 01251], lr: 0.000122, loss: 0.0871
2022-10-04 22:50:35 - train: epoch 0074, iter [00330, 01251], lr: 0.000121, loss: 0.0838
2022-10-04 22:51:03 - train: epoch 0074, iter [00340, 01251], lr: 0.000121, loss: 0.0839
2022-10-04 22:51:31 - train: epoch 0074, iter [00350, 01251], lr: 0.000121, loss: 0.0859
2022-10-04 22:51:59 - train: epoch 0074, iter [00360, 01251], lr: 0.000121, loss: 0.0814
2022-10-04 22:52:27 - train: epoch 0074, iter [00370, 01251], lr: 0.000121, loss: 0.0865
2022-10-04 22:52:55 - train: epoch 0074, iter [00380, 01251], lr: 0.000121, loss: 0.0830
2022-10-04 22:53:23 - train: epoch 0074, iter [00390, 01251], lr: 0.000121, loss: 0.0844
2022-10-04 22:53:51 - train: epoch 0074, iter [00400, 01251], lr: 0.000121, loss: 0.0870
2022-10-04 22:54:18 - train: epoch 0074, iter [00410, 01251], lr: 0.000121, loss: 0.0856
2022-10-04 22:54:46 - train: epoch 0074, iter [00420, 01251], lr: 0.000121, loss: 0.0786
2022-10-04 22:55:15 - train: epoch 0074, iter [00430, 01251], lr: 0.000121, loss: 0.0854
2022-10-04 22:55:43 - train: epoch 0074, iter [00440, 01251], lr: 0.000121, loss: 0.0808
2022-10-04 22:56:11 - train: epoch 0074, iter [00450, 01251], lr: 0.000121, loss: 0.0846
2022-10-04 22:56:39 - train: epoch 0074, iter [00460, 01251], lr: 0.000121, loss: 0.0872
2022-10-04 22:57:07 - train: epoch 0074, iter [00470, 01251], lr: 0.000120, loss: 0.0797
2022-10-04 22:57:35 - train: epoch 0074, iter [00480, 01251], lr: 0.000120, loss: 0.0832
2022-10-04 22:58:03 - train: epoch 0074, iter [00490, 01251], lr: 0.000120, loss: 0.0818
2022-10-04 22:58:31 - train: epoch 0074, iter [00500, 01251], lr: 0.000120, loss: 0.0929
2022-10-04 22:58:59 - train: epoch 0074, iter [00510, 01251], lr: 0.000120, loss: 0.0864
2022-10-04 22:59:27 - train: epoch 0074, iter [00520, 01251], lr: 0.000120, loss: 0.0817
2022-10-04 22:59:55 - train: epoch 0074, iter [00530, 01251], lr: 0.000120, loss: 0.0934
2022-10-04 23:00:23 - train: epoch 0074, iter [00540, 01251], lr: 0.000120, loss: 0.0841
2022-10-04 23:00:51 - train: epoch 0074, iter [00550, 01251], lr: 0.000120, loss: 0.0833
2022-10-04 23:01:19 - train: epoch 0074, iter [00560, 01251], lr: 0.000120, loss: 0.0850
2022-10-04 23:01:47 - train: epoch 0074, iter [00570, 01251], lr: 0.000120, loss: 0.0833
2022-10-04 23:02:15 - train: epoch 0074, iter [00580, 01251], lr: 0.000120, loss: 0.0883
2022-10-04 23:02:43 - train: epoch 0074, iter [00590, 01251], lr: 0.000120, loss: 0.0849
2022-10-04 23:03:11 - train: epoch 0074, iter [00600, 01251], lr: 0.000120, loss: 0.0884
2022-10-04 23:03:39 - train: epoch 0074, iter [00610, 01251], lr: 0.000120, loss: 0.0874
2022-10-04 23:04:07 - train: epoch 0074, iter [00620, 01251], lr: 0.000119, loss: 0.0838
2022-10-04 23:04:36 - train: epoch 0074, iter [00630, 01251], lr: 0.000119, loss: 0.0900
2022-10-04 23:05:03 - train: epoch 0074, iter [00640, 01251], lr: 0.000119, loss: 0.0848
2022-10-04 23:05:31 - train: epoch 0074, iter [00650, 01251], lr: 0.000119, loss: 0.0836
2022-10-04 23:05:59 - train: epoch 0074, iter [00660, 01251], lr: 0.000119, loss: 0.0874
2022-10-04 23:06:27 - train: epoch 0074, iter [00670, 01251], lr: 0.000119, loss: 0.0784
2022-10-04 23:06:55 - train: epoch 0074, iter [00680, 01251], lr: 0.000119, loss: 0.0846
2022-10-04 23:07:23 - train: epoch 0074, iter [00690, 01251], lr: 0.000119, loss: 0.0869
2022-10-04 23:07:51 - train: epoch 0074, iter [00700, 01251], lr: 0.000119, loss: 0.0877
2022-10-04 23:08:19 - train: epoch 0074, iter [00710, 01251], lr: 0.000119, loss: 0.0737
2022-10-04 23:08:47 - train: epoch 0074, iter [00720, 01251], lr: 0.000119, loss: 0.0782
2022-10-04 23:09:16 - train: epoch 0074, iter [00730, 01251], lr: 0.000119, loss: 0.0826
2022-10-04 23:09:44 - train: epoch 0074, iter [00740, 01251], lr: 0.000119, loss: 0.0891
2022-10-04 23:10:12 - train: epoch 0074, iter [00750, 01251], lr: 0.000119, loss: 0.0840
2022-10-04 23:10:40 - train: epoch 0074, iter [00760, 01251], lr: 0.000119, loss: 0.0799
2022-10-04 23:11:08 - train: epoch 0074, iter [00770, 01251], lr: 0.000118, loss: 0.0850
2022-10-04 23:11:36 - train: epoch 0074, iter [00780, 01251], lr: 0.000118, loss: 0.0852
2022-10-04 23:12:04 - train: epoch 0074, iter [00790, 01251], lr: 0.000118, loss: 0.0785
2022-10-04 23:12:32 - train: epoch 0074, iter [00800, 01251], lr: 0.000118, loss: 0.0838
2022-10-04 23:13:00 - train: epoch 0074, iter [00810, 01251], lr: 0.000118, loss: 0.0852
2022-10-04 23:13:28 - train: epoch 0074, iter [00820, 01251], lr: 0.000118, loss: 0.0871
2022-10-04 23:13:56 - train: epoch 0074, iter [00830, 01251], lr: 0.000118, loss: 0.0823
2022-10-04 23:14:24 - train: epoch 0074, iter [00840, 01251], lr: 0.000118, loss: 0.0817
2022-10-04 23:14:52 - train: epoch 0074, iter [00850, 01251], lr: 0.000118, loss: 0.0774
2022-10-04 23:15:20 - train: epoch 0074, iter [00860, 01251], lr: 0.000118, loss: 0.0786
2022-10-04 23:15:48 - train: epoch 0074, iter [00870, 01251], lr: 0.000118, loss: 0.0809
2022-10-04 23:16:17 - train: epoch 0074, iter [00880, 01251], lr: 0.000118, loss: 0.0883
2022-10-04 23:16:45 - train: epoch 0074, iter [00890, 01251], lr: 0.000118, loss: 0.0907
2022-10-04 23:17:13 - train: epoch 0074, iter [00900, 01251], lr: 0.000118, loss: 0.0852
2022-10-04 23:17:41 - train: epoch 0074, iter [00910, 01251], lr: 0.000118, loss: 0.0840
2022-10-04 23:18:09 - train: epoch 0074, iter [00920, 01251], lr: 0.000117, loss: 0.0863
2022-10-04 23:18:37 - train: epoch 0074, iter [00930, 01251], lr: 0.000117, loss: 0.0870
2022-10-04 23:19:05 - train: epoch 0074, iter [00940, 01251], lr: 0.000117, loss: 0.0776
2022-10-04 23:19:33 - train: epoch 0074, iter [00950, 01251], lr: 0.000117, loss: 0.0748
2022-10-04 23:20:01 - train: epoch 0074, iter [00960, 01251], lr: 0.000117, loss: 0.0826
2022-10-04 23:20:30 - train: epoch 0074, iter [00970, 01251], lr: 0.000117, loss: 0.0865
2022-10-04 23:20:58 - train: epoch 0074, iter [00980, 01251], lr: 0.000117, loss: 0.0783
2022-10-04 23:21:26 - train: epoch 0074, iter [00990, 01251], lr: 0.000117, loss: 0.0785
2022-10-04 23:21:54 - train: epoch 0074, iter [01000, 01251], lr: 0.000117, loss: 0.0901
2022-10-04 23:22:22 - train: epoch 0074, iter [01010, 01251], lr: 0.000117, loss: 0.0880
2022-10-04 23:22:50 - train: epoch 0074, iter [01020, 01251], lr: 0.000117, loss: 0.0919
2022-10-04 23:23:18 - train: epoch 0074, iter [01030, 01251], lr: 0.000117, loss: 0.0760
2022-10-04 23:23:46 - train: epoch 0074, iter [01040, 01251], lr: 0.000117, loss: 0.0818
2022-10-04 23:24:14 - train: epoch 0074, iter [01050, 01251], lr: 0.000117, loss: 0.0875
2022-10-04 23:24:42 - train: epoch 0074, iter [01060, 01251], lr: 0.000117, loss: 0.0931
2022-10-04 23:25:10 - train: epoch 0074, iter [01070, 01251], lr: 0.000116, loss: 0.0855
2022-10-04 23:25:39 - train: epoch 0074, iter [01080, 01251], lr: 0.000116, loss: 0.0863
2022-10-04 23:26:07 - train: epoch 0074, iter [01090, 01251], lr: 0.000116, loss: 0.0786
2022-10-04 23:26:35 - train: epoch 0074, iter [01100, 01251], lr: 0.000116, loss: 0.0860
2022-10-04 23:27:03 - train: epoch 0074, iter [01110, 01251], lr: 0.000116, loss: 0.0862
2022-10-04 23:27:31 - train: epoch 0074, iter [01120, 01251], lr: 0.000116, loss: 0.0733
2022-10-04 23:27:59 - train: epoch 0074, iter [01130, 01251], lr: 0.000116, loss: 0.0788
2022-10-04 23:28:27 - train: epoch 0074, iter [01140, 01251], lr: 0.000116, loss: 0.0848
2022-10-04 23:28:55 - train: epoch 0074, iter [01150, 01251], lr: 0.000116, loss: 0.0889
2022-10-04 23:29:23 - train: epoch 0074, iter [01160, 01251], lr: 0.000116, loss: 0.0813
2022-10-04 23:29:51 - train: epoch 0074, iter [01170, 01251], lr: 0.000116, loss: 0.0786
2022-10-04 23:30:19 - train: epoch 0074, iter [01180, 01251], lr: 0.000116, loss: 0.0867
2022-10-04 23:30:47 - train: epoch 0074, iter [01190, 01251], lr: 0.000116, loss: 0.0827
2022-10-04 23:31:15 - train: epoch 0074, iter [01200, 01251], lr: 0.000116, loss: 0.0812
2022-10-04 23:31:44 - train: epoch 0074, iter [01210, 01251], lr: 0.000116, loss: 0.0943
2022-10-04 23:32:12 - train: epoch 0074, iter [01220, 01251], lr: 0.000116, loss: 0.0847
2022-10-04 23:32:40 - train: epoch 0074, iter [01230, 01251], lr: 0.000115, loss: 0.0826
2022-10-04 23:33:08 - train: epoch 0074, iter [01240, 01251], lr: 0.000115, loss: 0.0882
2022-10-04 23:33:36 - train: epoch 0074, iter [01250, 01251], lr: 0.000115, loss: 0.0881
2022-10-04 23:33:41 - train: epoch 074, train_loss: 0.0840
2022-10-04 23:33:42 - until epoch: 074, best_loss: 0.0840
2022-10-04 23:33:42 - epoch 075 lr: 0.000115
2022-10-04 23:34:17 - train: epoch 0075, iter [00010, 01251], lr: 0.000115, loss: 0.0857
2022-10-04 23:34:45 - train: epoch 0075, iter [00020, 01251], lr: 0.000115, loss: 0.0844
2022-10-04 23:35:13 - train: epoch 0075, iter [00030, 01251], lr: 0.000115, loss: 0.0813
2022-10-04 23:35:41 - train: epoch 0075, iter [00040, 01251], lr: 0.000115, loss: 0.0793
2022-10-04 23:36:09 - train: epoch 0075, iter [00050, 01251], lr: 0.000115, loss: 0.0793
2022-10-04 23:36:37 - train: epoch 0075, iter [00060, 01251], lr: 0.000115, loss: 0.0816
2022-10-04 23:37:05 - train: epoch 0075, iter [00070, 01251], lr: 0.000115, loss: 0.0844
2022-10-04 23:37:33 - train: epoch 0075, iter [00080, 01251], lr: 0.000115, loss: 0.0828
2022-10-04 23:38:01 - train: epoch 0075, iter [00090, 01251], lr: 0.000115, loss: 0.0823
2022-10-04 23:38:28 - train: epoch 0075, iter [00100, 01251], lr: 0.000115, loss: 0.0803
2022-10-04 23:38:56 - train: epoch 0075, iter [00110, 01251], lr: 0.000115, loss: 0.0887
2022-10-04 23:39:24 - train: epoch 0075, iter [00120, 01251], lr: 0.000115, loss: 0.0867
2022-10-04 23:39:52 - train: epoch 0075, iter [00130, 01251], lr: 0.000114, loss: 0.0826
2022-10-04 23:40:20 - train: epoch 0075, iter [00140, 01251], lr: 0.000114, loss: 0.0871
2022-10-04 23:40:48 - train: epoch 0075, iter [00150, 01251], lr: 0.000114, loss: 0.0944
2022-10-04 23:41:16 - train: epoch 0075, iter [00160, 01251], lr: 0.000114, loss: 0.0867
2022-10-04 23:41:44 - train: epoch 0075, iter [00170, 01251], lr: 0.000114, loss: 0.0864
2022-10-04 23:42:12 - train: epoch 0075, iter [00180, 01251], lr: 0.000114, loss: 0.0854
2022-10-04 23:42:40 - train: epoch 0075, iter [00190, 01251], lr: 0.000114, loss: 0.0832
2022-10-04 23:43:08 - train: epoch 0075, iter [00200, 01251], lr: 0.000114, loss: 0.0779
2022-10-04 23:43:36 - train: epoch 0075, iter [00210, 01251], lr: 0.000114, loss: 0.0876
2022-10-04 23:44:04 - train: epoch 0075, iter [00220, 01251], lr: 0.000114, loss: 0.0764
2022-10-04 23:44:32 - train: epoch 0075, iter [00230, 01251], lr: 0.000114, loss: 0.0873
2022-10-04 23:44:59 - train: epoch 0075, iter [00240, 01251], lr: 0.000114, loss: 0.0795
2022-10-04 23:45:27 - train: epoch 0075, iter [00250, 01251], lr: 0.000114, loss: 0.0868
2022-10-04 23:45:55 - train: epoch 0075, iter [00260, 01251], lr: 0.000114, loss: 0.0859
2022-10-04 23:46:23 - train: epoch 0075, iter [00270, 01251], lr: 0.000114, loss: 0.0775
2022-10-04 23:46:51 - train: epoch 0075, iter [00280, 01251], lr: 0.000113, loss: 0.0899
2022-10-04 23:47:19 - train: epoch 0075, iter [00290, 01251], lr: 0.000113, loss: 0.0779
2022-10-04 23:47:47 - train: epoch 0075, iter [00300, 01251], lr: 0.000113, loss: 0.0772
2022-10-04 23:48:15 - train: epoch 0075, iter [00310, 01251], lr: 0.000113, loss: 0.0820
2022-10-04 23:48:43 - train: epoch 0075, iter [00320, 01251], lr: 0.000113, loss: 0.0791
2022-10-04 23:49:11 - train: epoch 0075, iter [00330, 01251], lr: 0.000113, loss: 0.0843
2022-10-04 23:49:39 - train: epoch 0075, iter [00340, 01251], lr: 0.000113, loss: 0.0851
2022-10-04 23:50:07 - train: epoch 0075, iter [00350, 01251], lr: 0.000113, loss: 0.0829
2022-10-04 23:50:35 - train: epoch 0075, iter [00360, 01251], lr: 0.000113, loss: 0.0892
2022-10-04 23:51:03 - train: epoch 0075, iter [00370, 01251], lr: 0.000113, loss: 0.0821
2022-10-04 23:51:31 - train: epoch 0075, iter [00380, 01251], lr: 0.000113, loss: 0.0867
2022-10-04 23:51:59 - train: epoch 0075, iter [00390, 01251], lr: 0.000113, loss: 0.0880
2022-10-04 23:52:27 - train: epoch 0075, iter [00400, 01251], lr: 0.000113, loss: 0.0823
2022-10-04 23:52:55 - train: epoch 0075, iter [00410, 01251], lr: 0.000113, loss: 0.0855
2022-10-04 23:53:23 - train: epoch 0075, iter [00420, 01251], lr: 0.000113, loss: 0.0869
2022-10-04 23:53:51 - train: epoch 0075, iter [00430, 01251], lr: 0.000112, loss: 0.0777
2022-10-04 23:54:19 - train: epoch 0075, iter [00440, 01251], lr: 0.000112, loss: 0.0872
2022-10-04 23:54:47 - train: epoch 0075, iter [00450, 01251], lr: 0.000112, loss: 0.0810
2022-10-04 23:55:15 - train: epoch 0075, iter [00460, 01251], lr: 0.000112, loss: 0.0867
2022-10-04 23:55:43 - train: epoch 0075, iter [00470, 01251], lr: 0.000112, loss: 0.0850
2022-10-04 23:56:11 - train: epoch 0075, iter [00480, 01251], lr: 0.000112, loss: 0.0952
2022-10-04 23:56:39 - train: epoch 0075, iter [00490, 01251], lr: 0.000112, loss: 0.0822
2022-10-04 23:57:07 - train: epoch 0075, iter [00500, 01251], lr: 0.000112, loss: 0.0858
2022-10-04 23:57:35 - train: epoch 0075, iter [00510, 01251], lr: 0.000112, loss: 0.0853
2022-10-04 23:58:03 - train: epoch 0075, iter [00520, 01251], lr: 0.000112, loss: 0.0803
2022-10-04 23:58:31 - train: epoch 0075, iter [00530, 01251], lr: 0.000112, loss: 0.0851
2022-10-04 23:58:59 - train: epoch 0075, iter [00540, 01251], lr: 0.000112, loss: 0.0832
2022-10-04 23:59:27 - train: epoch 0075, iter [00550, 01251], lr: 0.000112, loss: 0.0832
2022-10-04 23:59:55 - train: epoch 0075, iter [00560, 01251], lr: 0.000112, loss: 0.0847
2022-10-05 00:00:23 - train: epoch 0075, iter [00570, 01251], lr: 0.000112, loss: 0.0784
2022-10-05 00:00:51 - train: epoch 0075, iter [00580, 01251], lr: 0.000112, loss: 0.0828
2022-10-05 00:01:19 - train: epoch 0075, iter [00590, 01251], lr: 0.000111, loss: 0.0833
2022-10-05 00:01:47 - train: epoch 0075, iter [00600, 01251], lr: 0.000111, loss: 0.0899
2022-10-05 00:02:15 - train: epoch 0075, iter [00610, 01251], lr: 0.000111, loss: 0.0862
2022-10-05 00:02:43 - train: epoch 0075, iter [00620, 01251], lr: 0.000111, loss: 0.0801
2022-10-05 00:03:11 - train: epoch 0075, iter [00630, 01251], lr: 0.000111, loss: 0.0797
2022-10-05 00:03:39 - train: epoch 0075, iter [00640, 01251], lr: 0.000111, loss: 0.0858
2022-10-05 00:04:07 - train: epoch 0075, iter [00650, 01251], lr: 0.000111, loss: 0.0872
2022-10-05 00:04:36 - train: epoch 0075, iter [00660, 01251], lr: 0.000111, loss: 0.0921
2022-10-05 00:05:04 - train: epoch 0075, iter [00670, 01251], lr: 0.000111, loss: 0.0937
2022-10-05 00:05:32 - train: epoch 0075, iter [00680, 01251], lr: 0.000111, loss: 0.0870
2022-10-05 00:06:00 - train: epoch 0075, iter [00690, 01251], lr: 0.000111, loss: 0.0856
2022-10-05 00:06:28 - train: epoch 0075, iter [00700, 01251], lr: 0.000111, loss: 0.0852
2022-10-05 00:06:56 - train: epoch 0075, iter [00710, 01251], lr: 0.000111, loss: 0.0842
2022-10-05 00:07:24 - train: epoch 0075, iter [00720, 01251], lr: 0.000111, loss: 0.0882
2022-10-05 00:07:52 - train: epoch 0075, iter [00730, 01251], lr: 0.000111, loss: 0.0812
2022-10-05 00:08:20 - train: epoch 0075, iter [00740, 01251], lr: 0.000110, loss: 0.0786
2022-10-05 00:08:48 - train: epoch 0075, iter [00750, 01251], lr: 0.000110, loss: 0.0799
2022-10-05 00:09:16 - train: epoch 0075, iter [00760, 01251], lr: 0.000110, loss: 0.0856
2022-10-05 00:09:44 - train: epoch 0075, iter [00770, 01251], lr: 0.000110, loss: 0.0830
2022-10-05 00:10:12 - train: epoch 0075, iter [00780, 01251], lr: 0.000110, loss: 0.0873
2022-10-05 00:10:40 - train: epoch 0075, iter [00790, 01251], lr: 0.000110, loss: 0.0852
2022-10-05 00:11:08 - train: epoch 0075, iter [00800, 01251], lr: 0.000110, loss: 0.0838
2022-10-05 00:11:36 - train: epoch 0075, iter [00810, 01251], lr: 0.000110, loss: 0.0809
2022-10-05 00:12:04 - train: epoch 0075, iter [00820, 01251], lr: 0.000110, loss: 0.0903
2022-10-05 00:12:32 - train: epoch 0075, iter [00830, 01251], lr: 0.000110, loss: 0.0893
2022-10-05 00:13:00 - train: epoch 0075, iter [00840, 01251], lr: 0.000110, loss: 0.0795
2022-10-05 00:13:28 - train: epoch 0075, iter [00850, 01251], lr: 0.000110, loss: 0.0847
2022-10-05 00:13:56 - train: epoch 0075, iter [00860, 01251], lr: 0.000110, loss: 0.0805
2022-10-05 00:14:24 - train: epoch 0075, iter [00870, 01251], lr: 0.000110, loss: 0.0814
2022-10-05 00:14:53 - train: epoch 0075, iter [00880, 01251], lr: 0.000110, loss: 0.0851
2022-10-05 00:15:21 - train: epoch 0075, iter [00890, 01251], lr: 0.000109, loss: 0.0856
2022-10-05 00:15:49 - train: epoch 0075, iter [00900, 01251], lr: 0.000109, loss: 0.0876
2022-10-05 00:16:17 - train: epoch 0075, iter [00910, 01251], lr: 0.000109, loss: 0.0817
2022-10-05 00:16:45 - train: epoch 0075, iter [00920, 01251], lr: 0.000109, loss: 0.0738
2022-10-05 00:17:13 - train: epoch 0075, iter [00930, 01251], lr: 0.000109, loss: 0.0808
2022-10-05 00:17:41 - train: epoch 0075, iter [00940, 01251], lr: 0.000109, loss: 0.0832
2022-10-05 00:18:09 - train: epoch 0075, iter [00950, 01251], lr: 0.000109, loss: 0.0791
2022-10-05 00:18:37 - train: epoch 0075, iter [00960, 01251], lr: 0.000109, loss: 0.0819
2022-10-05 00:19:05 - train: epoch 0075, iter [00970, 01251], lr: 0.000109, loss: 0.0868
2022-10-05 00:19:33 - train: epoch 0075, iter [00980, 01251], lr: 0.000109, loss: 0.0856
2022-10-05 00:20:01 - train: epoch 0075, iter [00990, 01251], lr: 0.000109, loss: 0.0910
2022-10-05 00:20:29 - train: epoch 0075, iter [01000, 01251], lr: 0.000109, loss: 0.0761
2022-10-05 00:20:57 - train: epoch 0075, iter [01010, 01251], lr: 0.000109, loss: 0.0814
2022-10-05 00:21:25 - train: epoch 0075, iter [01020, 01251], lr: 0.000109, loss: 0.0817
2022-10-05 00:21:54 - train: epoch 0075, iter [01030, 01251], lr: 0.000109, loss: 0.0860
2022-10-05 00:22:22 - train: epoch 0075, iter [01040, 01251], lr: 0.000109, loss: 0.0887
2022-10-05 00:22:50 - train: epoch 0075, iter [01050, 01251], lr: 0.000108, loss: 0.0806
2022-10-05 00:23:18 - train: epoch 0075, iter [01060, 01251], lr: 0.000108, loss: 0.0837
2022-10-05 00:23:46 - train: epoch 0075, iter [01070, 01251], lr: 0.000108, loss: 0.0772
2022-10-05 00:24:14 - train: epoch 0075, iter [01080, 01251], lr: 0.000108, loss: 0.0838
2022-10-05 00:24:42 - train: epoch 0075, iter [01090, 01251], lr: 0.000108, loss: 0.0813
2022-10-05 00:25:10 - train: epoch 0075, iter [01100, 01251], lr: 0.000108, loss: 0.0796
2022-10-05 00:25:38 - train: epoch 0075, iter [01110, 01251], lr: 0.000108, loss: 0.0819
2022-10-05 00:26:06 - train: epoch 0075, iter [01120, 01251], lr: 0.000108, loss: 0.0904
2022-10-05 00:26:34 - train: epoch 0075, iter [01130, 01251], lr: 0.000108, loss: 0.0837
2022-10-05 00:27:02 - train: epoch 0075, iter [01140, 01251], lr: 0.000108, loss: 0.0797
2022-10-05 00:27:30 - train: epoch 0075, iter [01150, 01251], lr: 0.000108, loss: 0.0803
2022-10-05 00:27:58 - train: epoch 0075, iter [01160, 01251], lr: 0.000108, loss: 0.0846
2022-10-05 00:28:27 - train: epoch 0075, iter [01170, 01251], lr: 0.000108, loss: 0.0840
2022-10-05 00:28:55 - train: epoch 0075, iter [01180, 01251], lr: 0.000108, loss: 0.0847
2022-10-05 00:29:23 - train: epoch 0075, iter [01190, 01251], lr: 0.000108, loss: 0.0845
2022-10-05 00:29:51 - train: epoch 0075, iter [01200, 01251], lr: 0.000107, loss: 0.0786
2022-10-05 00:30:19 - train: epoch 0075, iter [01210, 01251], lr: 0.000107, loss: 0.0935
2022-10-05 00:30:47 - train: epoch 0075, iter [01220, 01251], lr: 0.000107, loss: 0.0804
2022-10-05 00:31:15 - train: epoch 0075, iter [01230, 01251], lr: 0.000107, loss: 0.0750
2022-10-05 00:31:43 - train: epoch 0075, iter [01240, 01251], lr: 0.000107, loss: 0.0736
2022-10-05 00:32:11 - train: epoch 0075, iter [01250, 01251], lr: 0.000107, loss: 0.0772
2022-10-05 00:32:15 - train: epoch 075, train_loss: 0.0838
2022-10-05 00:32:17 - until epoch: 075, best_loss: 0.0838
2022-10-05 00:32:17 - epoch 076 lr: 0.000107
2022-10-05 00:32:52 - train: epoch 0076, iter [00010, 01251], lr: 0.000107, loss: 0.0862
2022-10-05 00:33:21 - train: epoch 0076, iter [00020, 01251], lr: 0.000107, loss: 0.0796
2022-10-05 00:33:48 - train: epoch 0076, iter [00030, 01251], lr: 0.000107, loss: 0.0771
2022-10-05 00:34:16 - train: epoch 0076, iter [00040, 01251], lr: 0.000107, loss: 0.0886
2022-10-05 00:34:44 - train: epoch 0076, iter [00050, 01251], lr: 0.000107, loss: 0.0865
2022-10-05 00:35:12 - train: epoch 0076, iter [00060, 01251], lr: 0.000107, loss: 0.0899
2022-10-05 00:35:40 - train: epoch 0076, iter [00070, 01251], lr: 0.000107, loss: 0.0852
2022-10-05 00:36:08 - train: epoch 0076, iter [00080, 01251], lr: 0.000107, loss: 0.0815
2022-10-05 00:36:36 - train: epoch 0076, iter [00090, 01251], lr: 0.000107, loss: 0.0843
2022-10-05 00:37:04 - train: epoch 0076, iter [00100, 01251], lr: 0.000107, loss: 0.0790
2022-10-05 00:37:32 - train: epoch 0076, iter [00110, 01251], lr: 0.000106, loss: 0.0956
2022-10-05 00:38:00 - train: epoch 0076, iter [00120, 01251], lr: 0.000106, loss: 0.0809
2022-10-05 00:38:29 - train: epoch 0076, iter [00130, 01251], lr: 0.000106, loss: 0.0709
2022-10-05 00:38:57 - train: epoch 0076, iter [00140, 01251], lr: 0.000106, loss: 0.0801
2022-10-05 00:39:25 - train: epoch 0076, iter [00150, 01251], lr: 0.000106, loss: 0.0803
2022-10-05 00:39:53 - train: epoch 0076, iter [00160, 01251], lr: 0.000106, loss: 0.0848
2022-10-05 00:40:21 - train: epoch 0076, iter [00170, 01251], lr: 0.000106, loss: 0.0784
2022-10-05 00:40:49 - train: epoch 0076, iter [00180, 01251], lr: 0.000106, loss: 0.0837
2022-10-05 00:41:17 - train: epoch 0076, iter [00190, 01251], lr: 0.000106, loss: 0.0867
2022-10-05 00:41:45 - train: epoch 0076, iter [00200, 01251], lr: 0.000106, loss: 0.0869
2022-10-05 00:42:13 - train: epoch 0076, iter [00210, 01251], lr: 0.000106, loss: 0.0840
2022-10-05 00:42:41 - train: epoch 0076, iter [00220, 01251], lr: 0.000106, loss: 0.0750
2022-10-05 00:43:09 - train: epoch 0076, iter [00230, 01251], lr: 0.000106, loss: 0.0838
2022-10-05 00:43:37 - train: epoch 0076, iter [00240, 01251], lr: 0.000106, loss: 0.0894
2022-10-05 00:44:05 - train: epoch 0076, iter [00250, 01251], lr: 0.000106, loss: 0.0834
2022-10-05 00:44:33 - train: epoch 0076, iter [00260, 01251], lr: 0.000106, loss: 0.0859
2022-10-05 00:45:01 - train: epoch 0076, iter [00270, 01251], lr: 0.000105, loss: 0.0883
2022-10-05 00:45:29 - train: epoch 0076, iter [00280, 01251], lr: 0.000105, loss: 0.0806
2022-10-05 00:45:57 - train: epoch 0076, iter [00290, 01251], lr: 0.000105, loss: 0.0803
2022-10-05 00:46:25 - train: epoch 0076, iter [00300, 01251], lr: 0.000105, loss: 0.0809
2022-10-05 00:46:53 - train: epoch 0076, iter [00310, 01251], lr: 0.000105, loss: 0.0840
2022-10-05 00:47:21 - train: epoch 0076, iter [00320, 01251], lr: 0.000105, loss: 0.0775
2022-10-05 00:47:49 - train: epoch 0076, iter [00330, 01251], lr: 0.000105, loss: 0.0786
2022-10-05 00:48:17 - train: epoch 0076, iter [00340, 01251], lr: 0.000105, loss: 0.0865
2022-10-05 00:48:45 - train: epoch 0076, iter [00350, 01251], lr: 0.000105, loss: 0.0845
2022-10-05 00:49:13 - train: epoch 0076, iter [00360, 01251], lr: 0.000105, loss: 0.0827
2022-10-05 00:49:41 - train: epoch 0076, iter [00370, 01251], lr: 0.000105, loss: 0.0807
2022-10-05 00:50:09 - train: epoch 0076, iter [00380, 01251], lr: 0.000105, loss: 0.0855
2022-10-05 00:50:37 - train: epoch 0076, iter [00390, 01251], lr: 0.000105, loss: 0.0847
2022-10-05 00:51:06 - train: epoch 0076, iter [00400, 01251], lr: 0.000105, loss: 0.0848
2022-10-05 00:51:34 - train: epoch 0076, iter [00410, 01251], lr: 0.000105, loss: 0.0829
2022-10-05 00:52:02 - train: epoch 0076, iter [00420, 01251], lr: 0.000104, loss: 0.0863
2022-10-05 00:52:30 - train: epoch 0076, iter [00430, 01251], lr: 0.000104, loss: 0.0793
2022-10-05 00:52:58 - train: epoch 0076, iter [00440, 01251], lr: 0.000104, loss: 0.0877
2022-10-05 00:53:26 - train: epoch 0076, iter [00450, 01251], lr: 0.000104, loss: 0.0840
2022-10-05 00:53:54 - train: epoch 0076, iter [00460, 01251], lr: 0.000104, loss: 0.0884
2022-10-05 00:54:22 - train: epoch 0076, iter [00470, 01251], lr: 0.000104, loss: 0.0854
2022-10-05 00:54:50 - train: epoch 0076, iter [00480, 01251], lr: 0.000104, loss: 0.0869
2022-10-05 00:55:18 - train: epoch 0076, iter [00490, 01251], lr: 0.000104, loss: 0.0889
2022-10-05 00:55:46 - train: epoch 0076, iter [00500, 01251], lr: 0.000104, loss: 0.0811
2022-10-05 00:56:14 - train: epoch 0076, iter [00510, 01251], lr: 0.000104, loss: 0.0819
2022-10-05 00:56:42 - train: epoch 0076, iter [00520, 01251], lr: 0.000104, loss: 0.0826
2022-10-05 00:57:10 - train: epoch 0076, iter [00530, 01251], lr: 0.000104, loss: 0.0885
2022-10-05 00:57:38 - train: epoch 0076, iter [00540, 01251], lr: 0.000104, loss: 0.0845
2022-10-05 00:58:06 - train: epoch 0076, iter [00550, 01251], lr: 0.000104, loss: 0.0848
2022-10-05 00:58:34 - train: epoch 0076, iter [00560, 01251], lr: 0.000104, loss: 0.0874
2022-10-05 00:59:02 - train: epoch 0076, iter [00570, 01251], lr: 0.000104, loss: 0.0779
2022-10-05 00:59:30 - train: epoch 0076, iter [00580, 01251], lr: 0.000103, loss: 0.0843
2022-10-05 00:59:58 - train: epoch 0076, iter [00590, 01251], lr: 0.000103, loss: 0.0824
2022-10-05 01:00:26 - train: epoch 0076, iter [00600, 01251], lr: 0.000103, loss: 0.0803
2022-10-05 01:00:54 - train: epoch 0076, iter [00610, 01251], lr: 0.000103, loss: 0.0804
2022-10-05 01:01:22 - train: epoch 0076, iter [00620, 01251], lr: 0.000103, loss: 0.0890
2022-10-05 01:01:50 - train: epoch 0076, iter [00630, 01251], lr: 0.000103, loss: 0.0813
2022-10-05 01:02:18 - train: epoch 0076, iter [00640, 01251], lr: 0.000103, loss: 0.0897
2022-10-05 01:02:46 - train: epoch 0076, iter [00650, 01251], lr: 0.000103, loss: 0.0820
2022-10-05 01:03:14 - train: epoch 0076, iter [00660, 01251], lr: 0.000103, loss: 0.0914
2022-10-05 01:03:42 - train: epoch 0076, iter [00670, 01251], lr: 0.000103, loss: 0.0860
2022-10-05 01:04:11 - train: epoch 0076, iter [00680, 01251], lr: 0.000103, loss: 0.0869
2022-10-05 01:04:39 - train: epoch 0076, iter [00690, 01251], lr: 0.000103, loss: 0.0819
2022-10-05 01:05:07 - train: epoch 0076, iter [00700, 01251], lr: 0.000103, loss: 0.0865
2022-10-05 01:05:35 - train: epoch 0076, iter [00710, 01251], lr: 0.000103, loss: 0.0777
2022-10-05 01:06:03 - train: epoch 0076, iter [00720, 01251], lr: 0.000103, loss: 0.0827
2022-10-05 01:06:31 - train: epoch 0076, iter [00730, 01251], lr: 0.000103, loss: 0.0779
2022-10-05 01:06:59 - train: epoch 0076, iter [00740, 01251], lr: 0.000102, loss: 0.0807
2022-10-05 01:07:27 - train: epoch 0076, iter [00750, 01251], lr: 0.000102, loss: 0.0858
2022-10-05 01:07:55 - train: epoch 0076, iter [00760, 01251], lr: 0.000102, loss: 0.0771
2022-10-05 01:08:23 - train: epoch 0076, iter [00770, 01251], lr: 0.000102, loss: 0.0837
2022-10-05 01:08:51 - train: epoch 0076, iter [00780, 01251], lr: 0.000102, loss: 0.0902
2022-10-05 01:09:20 - train: epoch 0076, iter [00790, 01251], lr: 0.000102, loss: 0.0831
2022-10-05 01:09:48 - train: epoch 0076, iter [00800, 01251], lr: 0.000102, loss: 0.0793
2022-10-05 01:10:16 - train: epoch 0076, iter [00810, 01251], lr: 0.000102, loss: 0.0838
2022-10-05 01:10:44 - train: epoch 0076, iter [00820, 01251], lr: 0.000102, loss: 0.0803
2022-10-05 01:11:12 - train: epoch 0076, iter [00830, 01251], lr: 0.000102, loss: 0.0820
2022-10-05 01:11:40 - train: epoch 0076, iter [00840, 01251], lr: 0.000102, loss: 0.0766
2022-10-05 01:12:08 - train: epoch 0076, iter [00850, 01251], lr: 0.000102, loss: 0.0805
2022-10-05 01:12:36 - train: epoch 0076, iter [00860, 01251], lr: 0.000102, loss: 0.0899
2022-10-05 01:13:04 - train: epoch 0076, iter [00870, 01251], lr: 0.000102, loss: 0.0856
2022-10-05 01:13:32 - train: epoch 0076, iter [00880, 01251], lr: 0.000102, loss: 0.0843
2022-10-05 01:14:00 - train: epoch 0076, iter [00890, 01251], lr: 0.000102, loss: 0.0861
2022-10-05 01:14:29 - train: epoch 0076, iter [00900, 01251], lr: 0.000101, loss: 0.0832
2022-10-05 01:14:57 - train: epoch 0076, iter [00910, 01251], lr: 0.000101, loss: 0.0808
2022-10-05 01:15:25 - train: epoch 0076, iter [00920, 01251], lr: 0.000101, loss: 0.0779
2022-10-05 01:15:53 - train: epoch 0076, iter [00930, 01251], lr: 0.000101, loss: 0.0833
2022-10-05 01:16:21 - train: epoch 0076, iter [00940, 01251], lr: 0.000101, loss: 0.0842
2022-10-05 01:16:49 - train: epoch 0076, iter [00950, 01251], lr: 0.000101, loss: 0.0859
2022-10-05 01:17:17 - train: epoch 0076, iter [00960, 01251], lr: 0.000101, loss: 0.0845
2022-10-05 01:17:45 - train: epoch 0076, iter [00970, 01251], lr: 0.000101, loss: 0.0908
2022-10-05 01:18:13 - train: epoch 0076, iter [00980, 01251], lr: 0.000101, loss: 0.0838
2022-10-05 01:18:41 - train: epoch 0076, iter [00990, 01251], lr: 0.000101, loss: 0.0751
2022-10-05 01:19:10 - train: epoch 0076, iter [01000, 01251], lr: 0.000101, loss: 0.0828
2022-10-05 01:19:38 - train: epoch 0076, iter [01010, 01251], lr: 0.000101, loss: 0.0746
2022-10-05 01:20:06 - train: epoch 0076, iter [01020, 01251], lr: 0.000101, loss: 0.0873
2022-10-05 01:20:34 - train: epoch 0076, iter [01030, 01251], lr: 0.000101, loss: 0.0891
2022-10-05 01:21:02 - train: epoch 0076, iter [01040, 01251], lr: 0.000101, loss: 0.0753
2022-10-05 01:21:30 - train: epoch 0076, iter [01050, 01251], lr: 0.000101, loss: 0.0796
2022-10-05 01:21:58 - train: epoch 0076, iter [01060, 01251], lr: 0.000100, loss: 0.0835
2022-10-05 01:22:26 - train: epoch 0076, iter [01070, 01251], lr: 0.000100, loss: 0.0798
2022-10-05 01:22:54 - train: epoch 0076, iter [01080, 01251], lr: 0.000100, loss: 0.0858
2022-10-05 01:23:22 - train: epoch 0076, iter [01090, 01251], lr: 0.000100, loss: 0.0827
2022-10-05 01:23:50 - train: epoch 0076, iter [01100, 01251], lr: 0.000100, loss: 0.0832
2022-10-05 01:24:18 - train: epoch 0076, iter [01110, 01251], lr: 0.000100, loss: 0.0877
2022-10-05 01:24:46 - train: epoch 0076, iter [01120, 01251], lr: 0.000100, loss: 0.0795
2022-10-05 01:25:14 - train: epoch 0076, iter [01130, 01251], lr: 0.000100, loss: 0.0812
2022-10-05 01:25:42 - train: epoch 0076, iter [01140, 01251], lr: 0.000100, loss: 0.0851
2022-10-05 01:26:10 - train: epoch 0076, iter [01150, 01251], lr: 0.000100, loss: 0.0808
2022-10-05 01:26:38 - train: epoch 0076, iter [01160, 01251], lr: 0.000100, loss: 0.0877
2022-10-05 01:27:06 - train: epoch 0076, iter [01170, 01251], lr: 0.000100, loss: 0.0840
2022-10-05 01:27:34 - train: epoch 0076, iter [01180, 01251], lr: 0.000100, loss: 0.0817
2022-10-05 01:28:02 - train: epoch 0076, iter [01190, 01251], lr: 0.000100, loss: 0.0928
2022-10-05 01:28:30 - train: epoch 0076, iter [01200, 01251], lr: 0.000100, loss: 0.0783
2022-10-05 01:28:58 - train: epoch 0076, iter [01210, 01251], lr: 0.000100, loss: 0.0838
2022-10-05 01:29:26 - train: epoch 0076, iter [01220, 01251], lr: 0.000099, loss: 0.0808
2022-10-05 01:29:54 - train: epoch 0076, iter [01230, 01251], lr: 0.000099, loss: 0.0877
2022-10-05 01:30:22 - train: epoch 0076, iter [01240, 01251], lr: 0.000099, loss: 0.0947
2022-10-05 01:30:50 - train: epoch 0076, iter [01250, 01251], lr: 0.000099, loss: 0.0769
2022-10-05 01:30:54 - train: epoch 076, train_loss: 0.0836
2022-10-05 01:30:56 - until epoch: 076, best_loss: 0.0836
2022-10-05 01:30:56 - epoch 077 lr: 0.000099
2022-10-05 01:31:31 - train: epoch 0077, iter [00010, 01251], lr: 0.000099, loss: 0.0863
2022-10-05 01:31:59 - train: epoch 0077, iter [00020, 01251], lr: 0.000099, loss: 0.0856
2022-10-05 01:32:27 - train: epoch 0077, iter [00030, 01251], lr: 0.000099, loss: 0.0879
2022-10-05 01:32:55 - train: epoch 0077, iter [00040, 01251], lr: 0.000099, loss: 0.0804
2022-10-05 01:33:23 - train: epoch 0077, iter [00050, 01251], lr: 0.000099, loss: 0.0777
2022-10-05 01:33:51 - train: epoch 0077, iter [00060, 01251], lr: 0.000099, loss: 0.0787
2022-10-05 01:34:19 - train: epoch 0077, iter [00070, 01251], lr: 0.000099, loss: 0.0759
2022-10-05 01:34:47 - train: epoch 0077, iter [00080, 01251], lr: 0.000099, loss: 0.0796
2022-10-05 01:35:15 - train: epoch 0077, iter [00090, 01251], lr: 0.000099, loss: 0.0742
2022-10-05 01:35:43 - train: epoch 0077, iter [00100, 01251], lr: 0.000099, loss: 0.0862
2022-10-05 01:36:11 - train: epoch 0077, iter [00110, 01251], lr: 0.000099, loss: 0.0835
2022-10-05 01:36:39 - train: epoch 0077, iter [00120, 01251], lr: 0.000099, loss: 0.0813
2022-10-05 01:37:07 - train: epoch 0077, iter [00130, 01251], lr: 0.000098, loss: 0.0802
2022-10-05 01:37:35 - train: epoch 0077, iter [00140, 01251], lr: 0.000098, loss: 0.0758
2022-10-05 01:38:02 - train: epoch 0077, iter [00150, 01251], lr: 0.000098, loss: 0.0862
2022-10-05 01:38:31 - train: epoch 0077, iter [00160, 01251], lr: 0.000098, loss: 0.0814
2022-10-05 01:38:58 - train: epoch 0077, iter [00170, 01251], lr: 0.000098, loss: 0.0774
2022-10-05 01:39:26 - train: epoch 0077, iter [00180, 01251], lr: 0.000098, loss: 0.0799
2022-10-05 01:39:54 - train: epoch 0077, iter [00190, 01251], lr: 0.000098, loss: 0.0774
2022-10-05 01:40:23 - train: epoch 0077, iter [00200, 01251], lr: 0.000098, loss: 0.0886
2022-10-05 01:40:51 - train: epoch 0077, iter [00210, 01251], lr: 0.000098, loss: 0.0830
2022-10-05 01:41:19 - train: epoch 0077, iter [00220, 01251], lr: 0.000098, loss: 0.0845
2022-10-05 01:41:47 - train: epoch 0077, iter [00230, 01251], lr: 0.000098, loss: 0.0763
2022-10-05 01:42:15 - train: epoch 0077, iter [00240, 01251], lr: 0.000098, loss: 0.0784
2022-10-05 01:42:43 - train: epoch 0077, iter [00250, 01251], lr: 0.000098, loss: 0.0950
2022-10-05 01:43:11 - train: epoch 0077, iter [00260, 01251], lr: 0.000098, loss: 0.0842
2022-10-05 01:43:39 - train: epoch 0077, iter [00270, 01251], lr: 0.000098, loss: 0.0846
2022-10-05 01:44:07 - train: epoch 0077, iter [00280, 01251], lr: 0.000098, loss: 0.0938
2022-10-05 01:44:35 - train: epoch 0077, iter [00290, 01251], lr: 0.000097, loss: 0.0824
2022-10-05 01:45:03 - train: epoch 0077, iter [00300, 01251], lr: 0.000097, loss: 0.0802
2022-10-05 01:45:31 - train: epoch 0077, iter [00310, 01251], lr: 0.000097, loss: 0.0782
2022-10-05 01:45:59 - train: epoch 0077, iter [00320, 01251], lr: 0.000097, loss: 0.0857
2022-10-05 01:46:27 - train: epoch 0077, iter [00330, 01251], lr: 0.000097, loss: 0.0827
2022-10-05 01:46:55 - train: epoch 0077, iter [00340, 01251], lr: 0.000097, loss: 0.0849
2022-10-05 01:47:23 - train: epoch 0077, iter [00350, 01251], lr: 0.000097, loss: 0.0894
2022-10-05 01:47:51 - train: epoch 0077, iter [00360, 01251], lr: 0.000097, loss: 0.0872
2022-10-05 01:48:19 - train: epoch 0077, iter [00370, 01251], lr: 0.000097, loss: 0.0852
2022-10-05 01:48:47 - train: epoch 0077, iter [00380, 01251], lr: 0.000097, loss: 0.0840
2022-10-05 01:49:15 - train: epoch 0077, iter [00390, 01251], lr: 0.000097, loss: 0.0864
2022-10-05 01:49:43 - train: epoch 0077, iter [00400, 01251], lr: 0.000097, loss: 0.0848
2022-10-05 01:50:11 - train: epoch 0077, iter [00410, 01251], lr: 0.000097, loss: 0.0877
2022-10-05 01:50:39 - train: epoch 0077, iter [00420, 01251], lr: 0.000097, loss: 0.0797
2022-10-05 01:51:07 - train: epoch 0077, iter [00430, 01251], lr: 0.000097, loss: 0.0836
2022-10-05 01:51:35 - train: epoch 0077, iter [00440, 01251], lr: 0.000097, loss: 0.0818
2022-10-05 01:52:03 - train: epoch 0077, iter [00450, 01251], lr: 0.000096, loss: 0.0836
2022-10-05 01:52:31 - train: epoch 0077, iter [00460, 01251], lr: 0.000096, loss: 0.0845
2022-10-05 01:52:59 - train: epoch 0077, iter [00470, 01251], lr: 0.000096, loss: 0.0886
2022-10-05 01:53:27 - train: epoch 0077, iter [00480, 01251], lr: 0.000096, loss: 0.0952
2022-10-05 01:53:55 - train: epoch 0077, iter [00490, 01251], lr: 0.000096, loss: 0.0868
2022-10-05 01:54:23 - train: epoch 0077, iter [00500, 01251], lr: 0.000096, loss: 0.0815
2022-10-05 01:54:51 - train: epoch 0077, iter [00510, 01251], lr: 0.000096, loss: 0.0889
2022-10-05 01:55:19 - train: epoch 0077, iter [00520, 01251], lr: 0.000096, loss: 0.0877
2022-10-05 01:55:47 - train: epoch 0077, iter [00530, 01251], lr: 0.000096, loss: 0.0824
2022-10-05 01:56:15 - train: epoch 0077, iter [00540, 01251], lr: 0.000096, loss: 0.0842
2022-10-05 01:56:43 - train: epoch 0077, iter [00550, 01251], lr: 0.000096, loss: 0.0908
2022-10-05 01:57:11 - train: epoch 0077, iter [00560, 01251], lr: 0.000096, loss: 0.0820
2022-10-05 01:57:39 - train: epoch 0077, iter [00570, 01251], lr: 0.000096, loss: 0.0781
2022-10-05 01:58:07 - train: epoch 0077, iter [00580, 01251], lr: 0.000096, loss: 0.0903
2022-10-05 01:58:35 - train: epoch 0077, iter [00590, 01251], lr: 0.000096, loss: 0.0812
2022-10-05 01:59:03 - train: epoch 0077, iter [00600, 01251], lr: 0.000096, loss: 0.0880
2022-10-05 01:59:31 - train: epoch 0077, iter [00610, 01251], lr: 0.000095, loss: 0.0749
2022-10-05 01:59:59 - train: epoch 0077, iter [00620, 01251], lr: 0.000095, loss: 0.0857
2022-10-05 02:00:27 - train: epoch 0077, iter [00630, 01251], lr: 0.000095, loss: 0.0826
2022-10-05 02:00:55 - train: epoch 0077, iter [00640, 01251], lr: 0.000095, loss: 0.0776
2022-10-05 02:01:22 - train: epoch 0077, iter [00650, 01251], lr: 0.000095, loss: 0.0855
2022-10-05 02:01:50 - train: epoch 0077, iter [00660, 01251], lr: 0.000095, loss: 0.0784
2022-10-05 02:02:18 - train: epoch 0077, iter [00670, 01251], lr: 0.000095, loss: 0.0849
2022-10-05 02:02:46 - train: epoch 0077, iter [00680, 01251], lr: 0.000095, loss: 0.0785
2022-10-05 02:03:14 - train: epoch 0077, iter [00690, 01251], lr: 0.000095, loss: 0.0803
2022-10-05 02:03:42 - train: epoch 0077, iter [00700, 01251], lr: 0.000095, loss: 0.0783
2022-10-05 02:04:10 - train: epoch 0077, iter [00710, 01251], lr: 0.000095, loss: 0.0788
2022-10-05 02:04:38 - train: epoch 0077, iter [00720, 01251], lr: 0.000095, loss: 0.0864
2022-10-05 02:05:06 - train: epoch 0077, iter [00730, 01251], lr: 0.000095, loss: 0.0845
2022-10-05 02:05:34 - train: epoch 0077, iter [00740, 01251], lr: 0.000095, loss: 0.0747
2022-10-05 02:06:01 - train: epoch 0077, iter [00750, 01251], lr: 0.000095, loss: 0.0822
2022-10-05 02:06:30 - train: epoch 0077, iter [00760, 01251], lr: 0.000095, loss: 0.0808
2022-10-05 02:06:58 - train: epoch 0077, iter [00770, 01251], lr: 0.000095, loss: 0.0801
2022-10-05 02:07:26 - train: epoch 0077, iter [00780, 01251], lr: 0.000094, loss: 0.0818
2022-10-05 02:07:53 - train: epoch 0077, iter [00790, 01251], lr: 0.000094, loss: 0.0822
2022-10-05 02:08:22 - train: epoch 0077, iter [00800, 01251], lr: 0.000094, loss: 0.0815
2022-10-05 02:08:49 - train: epoch 0077, iter [00810, 01251], lr: 0.000094, loss: 0.0885
2022-10-05 02:09:17 - train: epoch 0077, iter [00820, 01251], lr: 0.000094, loss: 0.0874
2022-10-05 02:09:45 - train: epoch 0077, iter [00830, 01251], lr: 0.000094, loss: 0.0833
2022-10-05 02:10:13 - train: epoch 0077, iter [00840, 01251], lr: 0.000094, loss: 0.0844
2022-10-05 02:10:41 - train: epoch 0077, iter [00850, 01251], lr: 0.000094, loss: 0.0773
2022-10-05 02:11:09 - train: epoch 0077, iter [00860, 01251], lr: 0.000094, loss: 0.0854
2022-10-05 02:11:37 - train: epoch 0077, iter [00870, 01251], lr: 0.000094, loss: 0.0822
2022-10-05 02:12:05 - train: epoch 0077, iter [00880, 01251], lr: 0.000094, loss: 0.0890
2022-10-05 02:12:33 - train: epoch 0077, iter [00890, 01251], lr: 0.000094, loss: 0.0839
2022-10-05 02:13:01 - train: epoch 0077, iter [00900, 01251], lr: 0.000094, loss: 0.0865
2022-10-05 02:13:29 - train: epoch 0077, iter [00910, 01251], lr: 0.000094, loss: 0.0823
2022-10-05 02:13:57 - train: epoch 0077, iter [00920, 01251], lr: 0.000094, loss: 0.0794
2022-10-05 02:14:25 - train: epoch 0077, iter [00930, 01251], lr: 0.000094, loss: 0.0812
2022-10-05 02:14:53 - train: epoch 0077, iter [00940, 01251], lr: 0.000093, loss: 0.0908
2022-10-05 02:15:20 - train: epoch 0077, iter [00950, 01251], lr: 0.000093, loss: 0.0803
2022-10-05 02:15:48 - train: epoch 0077, iter [00960, 01251], lr: 0.000093, loss: 0.0850
2022-10-05 02:16:16 - train: epoch 0077, iter [00970, 01251], lr: 0.000093, loss: 0.0853
2022-10-05 02:16:44 - train: epoch 0077, iter [00980, 01251], lr: 0.000093, loss: 0.0844
2022-10-05 02:17:12 - train: epoch 0077, iter [00990, 01251], lr: 0.000093, loss: 0.0802
2022-10-05 02:17:40 - train: epoch 0077, iter [01000, 01251], lr: 0.000093, loss: 0.0841
2022-10-05 02:18:08 - train: epoch 0077, iter [01010, 01251], lr: 0.000093, loss: 0.0798
2022-10-05 02:18:36 - train: epoch 0077, iter [01020, 01251], lr: 0.000093, loss: 0.0831
2022-10-05 02:19:04 - train: epoch 0077, iter [01030, 01251], lr: 0.000093, loss: 0.0783
2022-10-05 02:19:32 - train: epoch 0077, iter [01040, 01251], lr: 0.000093, loss: 0.0815
2022-10-05 02:20:00 - train: epoch 0077, iter [01050, 01251], lr: 0.000093, loss: 0.0788
2022-10-05 02:20:28 - train: epoch 0077, iter [01060, 01251], lr: 0.000093, loss: 0.0795
2022-10-05 02:20:56 - train: epoch 0077, iter [01070, 01251], lr: 0.000093, loss: 0.0871
2022-10-05 02:21:24 - train: epoch 0077, iter [01080, 01251], lr: 0.000093, loss: 0.0770
2022-10-05 02:21:52 - train: epoch 0077, iter [01090, 01251], lr: 0.000093, loss: 0.0780
2022-10-05 02:22:20 - train: epoch 0077, iter [01100, 01251], lr: 0.000093, loss: 0.0834
2022-10-05 02:22:48 - train: epoch 0077, iter [01110, 01251], lr: 0.000092, loss: 0.0830
2022-10-05 02:23:16 - train: epoch 0077, iter [01120, 01251], lr: 0.000092, loss: 0.0953
2022-10-05 02:23:44 - train: epoch 0077, iter [01130, 01251], lr: 0.000092, loss: 0.0839
2022-10-05 02:24:12 - train: epoch 0077, iter [01140, 01251], lr: 0.000092, loss: 0.0802
2022-10-05 02:24:40 - train: epoch 0077, iter [01150, 01251], lr: 0.000092, loss: 0.0782
2022-10-05 02:25:08 - train: epoch 0077, iter [01160, 01251], lr: 0.000092, loss: 0.0832
2022-10-05 02:25:36 - train: epoch 0077, iter [01170, 01251], lr: 0.000092, loss: 0.0817
2022-10-05 02:26:04 - train: epoch 0077, iter [01180, 01251], lr: 0.000092, loss: 0.0796
2022-10-05 02:26:32 - train: epoch 0077, iter [01190, 01251], lr: 0.000092, loss: 0.0900
2022-10-05 02:27:00 - train: epoch 0077, iter [01200, 01251], lr: 0.000092, loss: 0.0833
2022-10-05 02:27:28 - train: epoch 0077, iter [01210, 01251], lr: 0.000092, loss: 0.0785
2022-10-05 02:27:56 - train: epoch 0077, iter [01220, 01251], lr: 0.000092, loss: 0.0809
2022-10-05 02:28:24 - train: epoch 0077, iter [01230, 01251], lr: 0.000092, loss: 0.0827
2022-10-05 02:28:52 - train: epoch 0077, iter [01240, 01251], lr: 0.000092, loss: 0.0798
2022-10-05 02:29:19 - train: epoch 0077, iter [01250, 01251], lr: 0.000092, loss: 0.0802
2022-10-05 02:29:24 - train: epoch 077, train_loss: 0.0834
2022-10-05 02:29:25 - until epoch: 077, best_loss: 0.0834
2022-10-05 02:29:25 - epoch 078 lr: 0.000092
2022-10-05 02:30:01 - train: epoch 0078, iter [00010, 01251], lr: 0.000092, loss: 0.0894
2022-10-05 02:30:29 - train: epoch 0078, iter [00020, 01251], lr: 0.000091, loss: 0.0769
2022-10-05 02:30:57 - train: epoch 0078, iter [00030, 01251], lr: 0.000091, loss: 0.0869
2022-10-05 02:31:25 - train: epoch 0078, iter [00040, 01251], lr: 0.000091, loss: 0.0816
2022-10-05 02:31:53 - train: epoch 0078, iter [00050, 01251], lr: 0.000091, loss: 0.0814
2022-10-05 02:32:21 - train: epoch 0078, iter [00060, 01251], lr: 0.000091, loss: 0.0883
2022-10-05 02:32:49 - train: epoch 0078, iter [00070, 01251], lr: 0.000091, loss: 0.0883
2022-10-05 02:33:17 - train: epoch 0078, iter [00080, 01251], lr: 0.000091, loss: 0.0969
2022-10-05 02:33:45 - train: epoch 0078, iter [00090, 01251], lr: 0.000091, loss: 0.0858
2022-10-05 02:34:13 - train: epoch 0078, iter [00100, 01251], lr: 0.000091, loss: 0.0869
2022-10-05 02:34:41 - train: epoch 0078, iter [00110, 01251], lr: 0.000091, loss: 0.0877
2022-10-05 02:35:08 - train: epoch 0078, iter [00120, 01251], lr: 0.000091, loss: 0.0839
2022-10-05 02:35:36 - train: epoch 0078, iter [00130, 01251], lr: 0.000091, loss: 0.0910
2022-10-05 02:36:04 - train: epoch 0078, iter [00140, 01251], lr: 0.000091, loss: 0.0786
2022-10-05 02:36:32 - train: epoch 0078, iter [00150, 01251], lr: 0.000091, loss: 0.0842
2022-10-05 02:37:00 - train: epoch 0078, iter [00160, 01251], lr: 0.000091, loss: 0.0847
2022-10-05 02:37:29 - train: epoch 0078, iter [00170, 01251], lr: 0.000091, loss: 0.0781
2022-10-05 02:37:57 - train: epoch 0078, iter [00180, 01251], lr: 0.000091, loss: 0.0804
2022-10-05 02:38:25 - train: epoch 0078, iter [00190, 01251], lr: 0.000090, loss: 0.0784
2022-10-05 02:38:53 - train: epoch 0078, iter [00200, 01251], lr: 0.000090, loss: 0.0848
2022-10-05 02:39:21 - train: epoch 0078, iter [00210, 01251], lr: 0.000090, loss: 0.0818
2022-10-05 02:39:49 - train: epoch 0078, iter [00220, 01251], lr: 0.000090, loss: 0.0867
2022-10-05 02:40:17 - train: epoch 0078, iter [00230, 01251], lr: 0.000090, loss: 0.0856
2022-10-05 02:40:45 - train: epoch 0078, iter [00240, 01251], lr: 0.000090, loss: 0.0868
2022-10-05 02:41:13 - train: epoch 0078, iter [00250, 01251], lr: 0.000090, loss: 0.0858
2022-10-05 02:41:41 - train: epoch 0078, iter [00260, 01251], lr: 0.000090, loss: 0.0869
2022-10-05 02:42:09 - train: epoch 0078, iter [00270, 01251], lr: 0.000090, loss: 0.0808
2022-10-05 02:42:37 - train: epoch 0078, iter [00280, 01251], lr: 0.000090, loss: 0.0833
2022-10-05 02:43:05 - train: epoch 0078, iter [00290, 01251], lr: 0.000090, loss: 0.0831
2022-10-05 02:43:33 - train: epoch 0078, iter [00300, 01251], lr: 0.000090, loss: 0.0843
2022-10-05 02:44:01 - train: epoch 0078, iter [00310, 01251], lr: 0.000090, loss: 0.0839
2022-10-05 02:44:30 - train: epoch 0078, iter [00320, 01251], lr: 0.000090, loss: 0.0777
2022-10-05 02:44:58 - train: epoch 0078, iter [00330, 01251], lr: 0.000090, loss: 0.0792
2022-10-05 02:45:26 - train: epoch 0078, iter [00340, 01251], lr: 0.000090, loss: 0.0822
2022-10-05 02:45:54 - train: epoch 0078, iter [00350, 01251], lr: 0.000090, loss: 0.0798
2022-10-05 02:46:22 - train: epoch 0078, iter [00360, 01251], lr: 0.000089, loss: 0.0809
2022-10-05 02:46:51 - train: epoch 0078, iter [00370, 01251], lr: 0.000089, loss: 0.0825
2022-10-05 02:47:19 - train: epoch 0078, iter [00380, 01251], lr: 0.000089, loss: 0.0822
2022-10-05 02:47:47 - train: epoch 0078, iter [00390, 01251], lr: 0.000089, loss: 0.0790
2022-10-05 02:48:15 - train: epoch 0078, iter [00400, 01251], lr: 0.000089, loss: 0.0861
2022-10-05 02:48:43 - train: epoch 0078, iter [00410, 01251], lr: 0.000089, loss: 0.0846
2022-10-05 02:49:11 - train: epoch 0078, iter [00420, 01251], lr: 0.000089, loss: 0.0819
2022-10-05 02:49:39 - train: epoch 0078, iter [00430, 01251], lr: 0.000089, loss: 0.0825
2022-10-05 02:50:07 - train: epoch 0078, iter [00440, 01251], lr: 0.000089, loss: 0.0811
2022-10-05 02:50:35 - train: epoch 0078, iter [00450, 01251], lr: 0.000089, loss: 0.0878
2022-10-05 02:51:03 - train: epoch 0078, iter [00460, 01251], lr: 0.000089, loss: 0.0809
2022-10-05 02:51:31 - train: epoch 0078, iter [00470, 01251], lr: 0.000089, loss: 0.0798
2022-10-05 02:51:59 - train: epoch 0078, iter [00480, 01251], lr: 0.000089, loss: 0.0836
2022-10-05 02:52:27 - train: epoch 0078, iter [00490, 01251], lr: 0.000089, loss: 0.0794
2022-10-05 02:52:55 - train: epoch 0078, iter [00500, 01251], lr: 0.000089, loss: 0.0786
2022-10-05 02:53:24 - train: epoch 0078, iter [00510, 01251], lr: 0.000089, loss: 0.0829
2022-10-05 02:53:52 - train: epoch 0078, iter [00520, 01251], lr: 0.000088, loss: 0.0789
2022-10-05 02:54:20 - train: epoch 0078, iter [00530, 01251], lr: 0.000088, loss: 0.0866
2022-10-05 02:54:48 - train: epoch 0078, iter [00540, 01251], lr: 0.000088, loss: 0.0766
2022-10-05 02:55:16 - train: epoch 0078, iter [00550, 01251], lr: 0.000088, loss: 0.0790
2022-10-05 02:55:44 - train: epoch 0078, iter [00560, 01251], lr: 0.000088, loss: 0.0794
2022-10-05 02:56:12 - train: epoch 0078, iter [00570, 01251], lr: 0.000088, loss: 0.0819
2022-10-05 02:56:40 - train: epoch 0078, iter [00580, 01251], lr: 0.000088, loss: 0.0849
2022-10-05 02:57:08 - train: epoch 0078, iter [00590, 01251], lr: 0.000088, loss: 0.0869
2022-10-05 02:57:36 - train: epoch 0078, iter [00600, 01251], lr: 0.000088, loss: 0.0860
2022-10-05 02:58:04 - train: epoch 0078, iter [00610, 01251], lr: 0.000088, loss: 0.0875
2022-10-05 02:58:33 - train: epoch 0078, iter [00620, 01251], lr: 0.000088, loss: 0.0805
2022-10-05 02:59:00 - train: epoch 0078, iter [00630, 01251], lr: 0.000088, loss: 0.0905
2022-10-05 02:59:29 - train: epoch 0078, iter [00640, 01251], lr: 0.000088, loss: 0.0857
2022-10-05 02:59:57 - train: epoch 0078, iter [00650, 01251], lr: 0.000088, loss: 0.0881
2022-10-05 03:00:25 - train: epoch 0078, iter [00660, 01251], lr: 0.000088, loss: 0.0859
2022-10-05 03:00:53 - train: epoch 0078, iter [00670, 01251], lr: 0.000088, loss: 0.0799
2022-10-05 03:01:21 - train: epoch 0078, iter [00680, 01251], lr: 0.000088, loss: 0.0788
2022-10-05 03:01:49 - train: epoch 0078, iter [00690, 01251], lr: 0.000087, loss: 0.0839
2022-10-05 03:02:17 - train: epoch 0078, iter [00700, 01251], lr: 0.000087, loss: 0.0778
2022-10-05 03:02:45 - train: epoch 0078, iter [00710, 01251], lr: 0.000087, loss: 0.0836
2022-10-05 03:03:13 - train: epoch 0078, iter [00720, 01251], lr: 0.000087, loss: 0.0760
2022-10-05 03:03:41 - train: epoch 0078, iter [00730, 01251], lr: 0.000087, loss: 0.0883
2022-10-05 03:04:09 - train: epoch 0078, iter [00740, 01251], lr: 0.000087, loss: 0.0785
2022-10-05 03:04:37 - train: epoch 0078, iter [00750, 01251], lr: 0.000087, loss: 0.0880
2022-10-05 03:05:05 - train: epoch 0078, iter [00760, 01251], lr: 0.000087, loss: 0.0816
2022-10-05 03:05:34 - train: epoch 0078, iter [00770, 01251], lr: 0.000087, loss: 0.0827
2022-10-05 03:06:02 - train: epoch 0078, iter [00780, 01251], lr: 0.000087, loss: 0.0801
2022-10-05 03:06:30 - train: epoch 0078, iter [00790, 01251], lr: 0.000087, loss: 0.0868
2022-10-05 03:06:58 - train: epoch 0078, iter [00800, 01251], lr: 0.000087, loss: 0.0818
2022-10-05 03:07:26 - train: epoch 0078, iter [00810, 01251], lr: 0.000087, loss: 0.0895
2022-10-05 03:07:54 - train: epoch 0078, iter [00820, 01251], lr: 0.000087, loss: 0.0761
2022-10-05 03:08:22 - train: epoch 0078, iter [00830, 01251], lr: 0.000087, loss: 0.0785
2022-10-05 03:08:50 - train: epoch 0078, iter [00840, 01251], lr: 0.000087, loss: 0.0761
2022-10-05 03:09:18 - train: epoch 0078, iter [00850, 01251], lr: 0.000087, loss: 0.0893
2022-10-05 03:09:46 - train: epoch 0078, iter [00860, 01251], lr: 0.000086, loss: 0.0872
2022-10-05 03:10:14 - train: epoch 0078, iter [00870, 01251], lr: 0.000086, loss: 0.0877
2022-10-05 03:10:42 - train: epoch 0078, iter [00880, 01251], lr: 0.000086, loss: 0.0806
2022-10-05 03:11:10 - train: epoch 0078, iter [00890, 01251], lr: 0.000086, loss: 0.0850
2022-10-05 03:11:38 - train: epoch 0078, iter [00900, 01251], lr: 0.000086, loss: 0.0883
2022-10-05 03:12:06 - train: epoch 0078, iter [00910, 01251], lr: 0.000086, loss: 0.0784
2022-10-05 03:12:34 - train: epoch 0078, iter [00920, 01251], lr: 0.000086, loss: 0.0836
2022-10-05 03:13:02 - train: epoch 0078, iter [00930, 01251], lr: 0.000086, loss: 0.0796
2022-10-05 03:13:30 - train: epoch 0078, iter [00940, 01251], lr: 0.000086, loss: 0.0821
2022-10-05 03:13:58 - train: epoch 0078, iter [00950, 01251], lr: 0.000086, loss: 0.0872
2022-10-05 03:14:26 - train: epoch 0078, iter [00960, 01251], lr: 0.000086, loss: 0.0795
2022-10-05 03:14:54 - train: epoch 0078, iter [00970, 01251], lr: 0.000086, loss: 0.0835
2022-10-05 03:15:22 - train: epoch 0078, iter [00980, 01251], lr: 0.000086, loss: 0.0786
2022-10-05 03:15:50 - train: epoch 0078, iter [00990, 01251], lr: 0.000086, loss: 0.0864
2022-10-05 03:16:19 - train: epoch 0078, iter [01000, 01251], lr: 0.000086, loss: 0.0803
2022-10-05 03:16:47 - train: epoch 0078, iter [01010, 01251], lr: 0.000086, loss: 0.0783
2022-10-05 03:17:15 - train: epoch 0078, iter [01020, 01251], lr: 0.000086, loss: 0.0900
2022-10-05 03:17:43 - train: epoch 0078, iter [01030, 01251], lr: 0.000085, loss: 0.0870
2022-10-05 03:18:11 - train: epoch 0078, iter [01040, 01251], lr: 0.000085, loss: 0.0844
2022-10-05 03:18:39 - train: epoch 0078, iter [01050, 01251], lr: 0.000085, loss: 0.0816
2022-10-05 03:19:08 - train: epoch 0078, iter [01060, 01251], lr: 0.000085, loss: 0.0812
2022-10-05 03:19:36 - train: epoch 0078, iter [01070, 01251], lr: 0.000085, loss: 0.0825
2022-10-05 03:20:04 - train: epoch 0078, iter [01080, 01251], lr: 0.000085, loss: 0.0808
2022-10-05 03:20:32 - train: epoch 0078, iter [01090, 01251], lr: 0.000085, loss: 0.0884
2022-10-05 03:21:00 - train: epoch 0078, iter [01100, 01251], lr: 0.000085, loss: 0.0904
2022-10-05 03:21:28 - train: epoch 0078, iter [01110, 01251], lr: 0.000085, loss: 0.0858
2022-10-05 03:21:56 - train: epoch 0078, iter [01120, 01251], lr: 0.000085, loss: 0.0837
2022-10-05 03:22:24 - train: epoch 0078, iter [01130, 01251], lr: 0.000085, loss: 0.0863
2022-10-05 03:22:52 - train: epoch 0078, iter [01140, 01251], lr: 0.000085, loss: 0.0825
2022-10-05 03:23:20 - train: epoch 0078, iter [01150, 01251], lr: 0.000085, loss: 0.0814
2022-10-05 03:23:48 - train: epoch 0078, iter [01160, 01251], lr: 0.000085, loss: 0.0809
2022-10-05 03:24:16 - train: epoch 0078, iter [01170, 01251], lr: 0.000085, loss: 0.0779
2022-10-05 03:24:44 - train: epoch 0078, iter [01180, 01251], lr: 0.000085, loss: 0.0857
2022-10-05 03:25:12 - train: epoch 0078, iter [01190, 01251], lr: 0.000085, loss: 0.0787
2022-10-05 03:25:40 - train: epoch 0078, iter [01200, 01251], lr: 0.000084, loss: 0.0847
2022-10-05 03:26:08 - train: epoch 0078, iter [01210, 01251], lr: 0.000084, loss: 0.0807
2022-10-05 03:26:37 - train: epoch 0078, iter [01220, 01251], lr: 0.000084, loss: 0.0882
2022-10-05 03:27:05 - train: epoch 0078, iter [01230, 01251], lr: 0.000084, loss: 0.0836
2022-10-05 03:27:33 - train: epoch 0078, iter [01240, 01251], lr: 0.000084, loss: 0.0802
2022-10-05 03:28:00 - train: epoch 0078, iter [01250, 01251], lr: 0.000084, loss: 0.0808
2022-10-05 03:28:04 - train: epoch 078, train_loss: 0.0832
2022-10-05 03:28:06 - until epoch: 078, best_loss: 0.0832
2022-10-05 03:28:06 - epoch 079 lr: 0.000084
2022-10-05 03:28:41 - train: epoch 0079, iter [00010, 01251], lr: 0.000084, loss: 0.0866
2022-10-05 03:29:09 - train: epoch 0079, iter [00020, 01251], lr: 0.000084, loss: 0.0794
2022-10-05 03:29:37 - train: epoch 0079, iter [00030, 01251], lr: 0.000084, loss: 0.0860
2022-10-05 03:30:05 - train: epoch 0079, iter [00040, 01251], lr: 0.000084, loss: 0.0756
2022-10-05 03:30:33 - train: epoch 0079, iter [00050, 01251], lr: 0.000084, loss: 0.0849
2022-10-05 03:31:01 - train: epoch 0079, iter [00060, 01251], lr: 0.000084, loss: 0.0811
2022-10-05 03:31:29 - train: epoch 0079, iter [00070, 01251], lr: 0.000084, loss: 0.0844
2022-10-05 03:31:58 - train: epoch 0079, iter [00080, 01251], lr: 0.000084, loss: 0.0831
2022-10-05 03:32:26 - train: epoch 0079, iter [00090, 01251], lr: 0.000084, loss: 0.0805
2022-10-05 03:32:54 - train: epoch 0079, iter [00100, 01251], lr: 0.000084, loss: 0.0835
2022-10-05 03:33:22 - train: epoch 0079, iter [00110, 01251], lr: 0.000084, loss: 0.0837
2022-10-05 03:33:50 - train: epoch 0079, iter [00120, 01251], lr: 0.000084, loss: 0.0814
2022-10-05 03:34:18 - train: epoch 0079, iter [00130, 01251], lr: 0.000083, loss: 0.0859
2022-10-05 03:34:46 - train: epoch 0079, iter [00140, 01251], lr: 0.000083, loss: 0.0900
2022-10-05 03:35:14 - train: epoch 0079, iter [00150, 01251], lr: 0.000083, loss: 0.0867
2022-10-05 03:35:42 - train: epoch 0079, iter [00160, 01251], lr: 0.000083, loss: 0.0792
2022-10-05 03:36:10 - train: epoch 0079, iter [00170, 01251], lr: 0.000083, loss: 0.0916
2022-10-05 03:36:39 - train: epoch 0079, iter [00180, 01251], lr: 0.000083, loss: 0.0824
2022-10-05 03:37:06 - train: epoch 0079, iter [00190, 01251], lr: 0.000083, loss: 0.0907
2022-10-05 03:37:34 - train: epoch 0079, iter [00200, 01251], lr: 0.000083, loss: 0.0878
2022-10-05 03:38:03 - train: epoch 0079, iter [00210, 01251], lr: 0.000083, loss: 0.0845
2022-10-05 03:38:31 - train: epoch 0079, iter [00220, 01251], lr: 0.000083, loss: 0.0808
2022-10-05 03:38:59 - train: epoch 0079, iter [00230, 01251], lr: 0.000083, loss: 0.0890
2022-10-05 03:39:27 - train: epoch 0079, iter [00240, 01251], lr: 0.000083, loss: 0.0835
2022-10-05 03:39:55 - train: epoch 0079, iter [00250, 01251], lr: 0.000083, loss: 0.0820
2022-10-05 03:40:23 - train: epoch 0079, iter [00260, 01251], lr: 0.000083, loss: 0.0817
2022-10-05 03:40:51 - train: epoch 0079, iter [00270, 01251], lr: 0.000083, loss: 0.0804
2022-10-05 03:41:19 - train: epoch 0079, iter [00280, 01251], lr: 0.000083, loss: 0.0885
2022-10-05 03:41:47 - train: epoch 0079, iter [00290, 01251], lr: 0.000083, loss: 0.0773
2022-10-05 03:42:15 - train: epoch 0079, iter [00300, 01251], lr: 0.000082, loss: 0.0842
2022-10-05 03:42:44 - train: epoch 0079, iter [00310, 01251], lr: 0.000082, loss: 0.0935
2022-10-05 03:43:12 - train: epoch 0079, iter [00320, 01251], lr: 0.000082, loss: 0.0834
2022-10-05 03:43:40 - train: epoch 0079, iter [00330, 01251], lr: 0.000082, loss: 0.0886
2022-10-05 03:44:08 - train: epoch 0079, iter [00340, 01251], lr: 0.000082, loss: 0.0814
2022-10-05 03:44:36 - train: epoch 0079, iter [00350, 01251], lr: 0.000082, loss: 0.0812
2022-10-05 03:45:04 - train: epoch 0079, iter [00360, 01251], lr: 0.000082, loss: 0.0825
2022-10-05 03:45:32 - train: epoch 0079, iter [00370, 01251], lr: 0.000082, loss: 0.0834
2022-10-05 03:46:00 - train: epoch 0079, iter [00380, 01251], lr: 0.000082, loss: 0.0754
2022-10-05 03:46:28 - train: epoch 0079, iter [00390, 01251], lr: 0.000082, loss: 0.0829
2022-10-05 03:46:57 - train: epoch 0079, iter [00400, 01251], lr: 0.000082, loss: 0.0808
2022-10-05 03:47:25 - train: epoch 0079, iter [00410, 01251], lr: 0.000082, loss: 0.0755
2022-10-05 03:47:53 - train: epoch 0079, iter [00420, 01251], lr: 0.000082, loss: 0.0827
2022-10-05 03:48:21 - train: epoch 0079, iter [00430, 01251], lr: 0.000082, loss: 0.0886
2022-10-05 03:48:49 - train: epoch 0079, iter [00440, 01251], lr: 0.000082, loss: 0.0851
2022-10-05 03:49:17 - train: epoch 0079, iter [00450, 01251], lr: 0.000082, loss: 0.0818
2022-10-05 03:49:46 - train: epoch 0079, iter [00460, 01251], lr: 0.000082, loss: 0.0813
2022-10-05 03:50:14 - train: epoch 0079, iter [00470, 01251], lr: 0.000081, loss: 0.0829
2022-10-05 03:50:42 - train: epoch 0079, iter [00480, 01251], lr: 0.000081, loss: 0.0769
2022-10-05 03:51:10 - train: epoch 0079, iter [00490, 01251], lr: 0.000081, loss: 0.0788
2022-10-05 03:51:38 - train: epoch 0079, iter [00500, 01251], lr: 0.000081, loss: 0.0890
2022-10-05 03:52:06 - train: epoch 0079, iter [00510, 01251], lr: 0.000081, loss: 0.0896
2022-10-05 03:52:34 - train: epoch 0079, iter [00520, 01251], lr: 0.000081, loss: 0.0764
2022-10-05 03:53:02 - train: epoch 0079, iter [00530, 01251], lr: 0.000081, loss: 0.0894
2022-10-05 03:53:30 - train: epoch 0079, iter [00540, 01251], lr: 0.000081, loss: 0.0860
2022-10-05 03:53:58 - train: epoch 0079, iter [00550, 01251], lr: 0.000081, loss: 0.0815
2022-10-05 03:54:26 - train: epoch 0079, iter [00560, 01251], lr: 0.000081, loss: 0.0887
2022-10-05 03:54:54 - train: epoch 0079, iter [00570, 01251], lr: 0.000081, loss: 0.0787
2022-10-05 03:55:23 - train: epoch 0079, iter [00580, 01251], lr: 0.000081, loss: 0.0806
2022-10-05 03:55:51 - train: epoch 0079, iter [00590, 01251], lr: 0.000081, loss: 0.0873
2022-10-05 03:56:19 - train: epoch 0079, iter [00600, 01251], lr: 0.000081, loss: 0.0873
2022-10-05 03:56:47 - train: epoch 0079, iter [00610, 01251], lr: 0.000081, loss: 0.0822
2022-10-05 03:57:15 - train: epoch 0079, iter [00620, 01251], lr: 0.000081, loss: 0.0841
2022-10-05 03:57:43 - train: epoch 0079, iter [00630, 01251], lr: 0.000081, loss: 0.0797
2022-10-05 03:58:11 - train: epoch 0079, iter [00640, 01251], lr: 0.000081, loss: 0.0832
2022-10-05 03:58:39 - train: epoch 0079, iter [00650, 01251], lr: 0.000080, loss: 0.0800
2022-10-05 03:59:07 - train: epoch 0079, iter [00660, 01251], lr: 0.000080, loss: 0.0771
2022-10-05 03:59:35 - train: epoch 0079, iter [00670, 01251], lr: 0.000080, loss: 0.0876
2022-10-05 04:00:03 - train: epoch 0079, iter [00680, 01251], lr: 0.000080, loss: 0.0772
2022-10-05 04:00:31 - train: epoch 0079, iter [00690, 01251], lr: 0.000080, loss: 0.0826
2022-10-05 04:00:59 - train: epoch 0079, iter [00700, 01251], lr: 0.000080, loss: 0.0803
2022-10-05 04:01:27 - train: epoch 0079, iter [00710, 01251], lr: 0.000080, loss: 0.0838
2022-10-05 04:01:55 - train: epoch 0079, iter [00720, 01251], lr: 0.000080, loss: 0.0782
2022-10-05 04:02:23 - train: epoch 0079, iter [00730, 01251], lr: 0.000080, loss: 0.0858
2022-10-05 04:02:51 - train: epoch 0079, iter [00740, 01251], lr: 0.000080, loss: 0.0810
2022-10-05 04:03:19 - train: epoch 0079, iter [00750, 01251], lr: 0.000080, loss: 0.0819
2022-10-05 04:03:47 - train: epoch 0079, iter [00760, 01251], lr: 0.000080, loss: 0.0854
2022-10-05 04:04:16 - train: epoch 0079, iter [00770, 01251], lr: 0.000080, loss: 0.0873
2022-10-05 04:04:44 - train: epoch 0079, iter [00780, 01251], lr: 0.000080, loss: 0.0781
2022-10-05 04:05:12 - train: epoch 0079, iter [00790, 01251], lr: 0.000080, loss: 0.0796
2022-10-05 04:05:40 - train: epoch 0079, iter [00800, 01251], lr: 0.000080, loss: 0.0792
2022-10-05 04:06:08 - train: epoch 0079, iter [00810, 01251], lr: 0.000080, loss: 0.0857
2022-10-05 04:06:36 - train: epoch 0079, iter [00820, 01251], lr: 0.000079, loss: 0.0790
2022-10-05 04:07:04 - train: epoch 0079, iter [00830, 01251], lr: 0.000079, loss: 0.0834
2022-10-05 04:07:32 - train: epoch 0079, iter [00840, 01251], lr: 0.000079, loss: 0.0763
2022-10-05 04:08:00 - train: epoch 0079, iter [00850, 01251], lr: 0.000079, loss: 0.0705
2022-10-05 04:08:28 - train: epoch 0079, iter [00860, 01251], lr: 0.000079, loss: 0.0856
2022-10-05 04:08:56 - train: epoch 0079, iter [00870, 01251], lr: 0.000079, loss: 0.0771
2022-10-05 04:09:24 - train: epoch 0079, iter [00880, 01251], lr: 0.000079, loss: 0.0866
2022-10-05 04:09:52 - train: epoch 0079, iter [00890, 01251], lr: 0.000079, loss: 0.0817
2022-10-05 04:10:20 - train: epoch 0079, iter [00900, 01251], lr: 0.000079, loss: 0.0820
2022-10-05 04:10:48 - train: epoch 0079, iter [00910, 01251], lr: 0.000079, loss: 0.0892
2022-10-05 04:11:16 - train: epoch 0079, iter [00920, 01251], lr: 0.000079, loss: 0.0818
2022-10-05 04:11:44 - train: epoch 0079, iter [00930, 01251], lr: 0.000079, loss: 0.0834
2022-10-05 04:12:12 - train: epoch 0079, iter [00940, 01251], lr: 0.000079, loss: 0.0803
2022-10-05 04:12:40 - train: epoch 0079, iter [00950, 01251], lr: 0.000079, loss: 0.0817
2022-10-05 04:13:08 - train: epoch 0079, iter [00960, 01251], lr: 0.000079, loss: 0.0811
2022-10-05 04:13:36 - train: epoch 0079, iter [00970, 01251], lr: 0.000079, loss: 0.0856
2022-10-05 04:14:04 - train: epoch 0079, iter [00980, 01251], lr: 0.000079, loss: 0.0859
2022-10-05 04:14:33 - train: epoch 0079, iter [00990, 01251], lr: 0.000079, loss: 0.0858
2022-10-05 04:15:01 - train: epoch 0079, iter [01000, 01251], lr: 0.000078, loss: 0.0835
2022-10-05 04:15:29 - train: epoch 0079, iter [01010, 01251], lr: 0.000078, loss: 0.0838
2022-10-05 04:15:57 - train: epoch 0079, iter [01020, 01251], lr: 0.000078, loss: 0.0874
2022-10-05 04:16:25 - train: epoch 0079, iter [01030, 01251], lr: 0.000078, loss: 0.0819
2022-10-05 04:16:53 - train: epoch 0079, iter [01040, 01251], lr: 0.000078, loss: 0.0880
2022-10-05 04:17:21 - train: epoch 0079, iter [01050, 01251], lr: 0.000078, loss: 0.0840
2022-10-05 04:17:49 - train: epoch 0079, iter [01060, 01251], lr: 0.000078, loss: 0.0742
2022-10-05 04:18:18 - train: epoch 0079, iter [01070, 01251], lr: 0.000078, loss: 0.0902
2022-10-05 04:18:46 - train: epoch 0079, iter [01080, 01251], lr: 0.000078, loss: 0.0856
2022-10-05 04:19:14 - train: epoch 0079, iter [01090, 01251], lr: 0.000078, loss: 0.0754
2022-10-05 04:19:42 - train: epoch 0079, iter [01100, 01251], lr: 0.000078, loss: 0.0834
2022-10-05 04:20:10 - train: epoch 0079, iter [01110, 01251], lr: 0.000078, loss: 0.0775
2022-10-05 04:20:38 - train: epoch 0079, iter [01120, 01251], lr: 0.000078, loss: 0.0833
2022-10-05 04:21:06 - train: epoch 0079, iter [01130, 01251], lr: 0.000078, loss: 0.0799
2022-10-05 04:21:34 - train: epoch 0079, iter [01140, 01251], lr: 0.000078, loss: 0.0818
2022-10-05 04:22:02 - train: epoch 0079, iter [01150, 01251], lr: 0.000078, loss: 0.0793
2022-10-05 04:22:31 - train: epoch 0079, iter [01160, 01251], lr: 0.000078, loss: 0.0803
2022-10-05 04:22:59 - train: epoch 0079, iter [01170, 01251], lr: 0.000078, loss: 0.0816
2022-10-05 04:23:27 - train: epoch 0079, iter [01180, 01251], lr: 0.000077, loss: 0.0860
2022-10-05 04:23:55 - train: epoch 0079, iter [01190, 01251], lr: 0.000077, loss: 0.0879
2022-10-05 04:24:23 - train: epoch 0079, iter [01200, 01251], lr: 0.000077, loss: 0.0778
2022-10-05 04:24:51 - train: epoch 0079, iter [01210, 01251], lr: 0.000077, loss: 0.0851
2022-10-05 04:25:19 - train: epoch 0079, iter [01220, 01251], lr: 0.000077, loss: 0.0850
2022-10-05 04:25:47 - train: epoch 0079, iter [01230, 01251], lr: 0.000077, loss: 0.0843
2022-10-05 04:26:15 - train: epoch 0079, iter [01240, 01251], lr: 0.000077, loss: 0.0839
2022-10-05 04:26:43 - train: epoch 0079, iter [01250, 01251], lr: 0.000077, loss: 0.0839
2022-10-05 04:26:48 - train: epoch 079, train_loss: 0.0830
2022-10-05 04:26:50 - until epoch: 079, best_loss: 0.0830
2022-10-05 04:26:50 - epoch 080 lr: 0.000077
2022-10-05 04:27:24 - train: epoch 0080, iter [00010, 01251], lr: 0.000077, loss: 0.0835
2022-10-05 04:27:52 - train: epoch 0080, iter [00020, 01251], lr: 0.000077, loss: 0.0791
2022-10-05 04:28:20 - train: epoch 0080, iter [00030, 01251], lr: 0.000077, loss: 0.0835
2022-10-05 04:28:48 - train: epoch 0080, iter [00040, 01251], lr: 0.000077, loss: 0.0804
2022-10-05 04:29:16 - train: epoch 0080, iter [00050, 01251], lr: 0.000077, loss: 0.0803
2022-10-05 04:29:44 - train: epoch 0080, iter [00060, 01251], lr: 0.000077, loss: 0.0775
2022-10-05 04:30:12 - train: epoch 0080, iter [00070, 01251], lr: 0.000077, loss: 0.0810
2022-10-05 04:30:40 - train: epoch 0080, iter [00080, 01251], lr: 0.000077, loss: 0.0858
2022-10-05 04:31:08 - train: epoch 0080, iter [00090, 01251], lr: 0.000077, loss: 0.0828
2022-10-05 04:31:36 - train: epoch 0080, iter [00100, 01251], lr: 0.000076, loss: 0.0834
2022-10-05 04:32:04 - train: epoch 0080, iter [00110, 01251], lr: 0.000076, loss: 0.0766
2022-10-05 04:32:32 - train: epoch 0080, iter [00120, 01251], lr: 0.000076, loss: 0.0816
2022-10-05 04:33:00 - train: epoch 0080, iter [00130, 01251], lr: 0.000076, loss: 0.0831
2022-10-05 04:33:27 - train: epoch 0080, iter [00140, 01251], lr: 0.000076, loss: 0.0813
2022-10-05 04:33:55 - train: epoch 0080, iter [00150, 01251], lr: 0.000076, loss: 0.0827
2022-10-05 04:34:23 - train: epoch 0080, iter [00160, 01251], lr: 0.000076, loss: 0.0809
2022-10-05 04:34:51 - train: epoch 0080, iter [00170, 01251], lr: 0.000076, loss: 0.0843
2022-10-05 04:35:19 - train: epoch 0080, iter [00180, 01251], lr: 0.000076, loss: 0.0836
2022-10-05 04:35:47 - train: epoch 0080, iter [00190, 01251], lr: 0.000076, loss: 0.0920
2022-10-05 04:36:15 - train: epoch 0080, iter [00200, 01251], lr: 0.000076, loss: 0.0863
2022-10-05 04:36:43 - train: epoch 0080, iter [00210, 01251], lr: 0.000076, loss: 0.0842
2022-10-05 04:37:11 - train: epoch 0080, iter [00220, 01251], lr: 0.000076, loss: 0.0846
2022-10-05 04:37:39 - train: epoch 0080, iter [00230, 01251], lr: 0.000076, loss: 0.0760
2022-10-05 04:38:08 - train: epoch 0080, iter [00240, 01251], lr: 0.000076, loss: 0.0762
2022-10-05 04:38:36 - train: epoch 0080, iter [00250, 01251], lr: 0.000076, loss: 0.0814
2022-10-05 04:39:04 - train: epoch 0080, iter [00260, 01251], lr: 0.000076, loss: 0.0891
2022-10-05 04:39:32 - train: epoch 0080, iter [00270, 01251], lr: 0.000076, loss: 0.0790
2022-10-05 04:40:00 - train: epoch 0080, iter [00280, 01251], lr: 0.000075, loss: 0.0816
2022-10-05 04:40:28 - train: epoch 0080, iter [00290, 01251], lr: 0.000075, loss: 0.0831
2022-10-05 04:40:56 - train: epoch 0080, iter [00300, 01251], lr: 0.000075, loss: 0.0906
2022-10-05 04:41:24 - train: epoch 0080, iter [00310, 01251], lr: 0.000075, loss: 0.0783
2022-10-05 04:41:52 - train: epoch 0080, iter [00320, 01251], lr: 0.000075, loss: 0.0794
2022-10-05 04:42:20 - train: epoch 0080, iter [00330, 01251], lr: 0.000075, loss: 0.0779
2022-10-05 04:42:48 - train: epoch 0080, iter [00340, 01251], lr: 0.000075, loss: 0.0799
2022-10-05 04:43:17 - train: epoch 0080, iter [00350, 01251], lr: 0.000075, loss: 0.0743
2022-10-05 04:43:45 - train: epoch 0080, iter [00360, 01251], lr: 0.000075, loss: 0.0799
2022-10-05 04:44:12 - train: epoch 0080, iter [00370, 01251], lr: 0.000075, loss: 0.0839
2022-10-05 04:44:40 - train: epoch 0080, iter [00380, 01251], lr: 0.000075, loss: 0.0822
2022-10-05 04:45:08 - train: epoch 0080, iter [00390, 01251], lr: 0.000075, loss: 0.0840
2022-10-05 04:45:37 - train: epoch 0080, iter [00400, 01251], lr: 0.000075, loss: 0.0807
2022-10-05 04:46:05 - train: epoch 0080, iter [00410, 01251], lr: 0.000075, loss: 0.0770
2022-10-05 04:46:33 - train: epoch 0080, iter [00420, 01251], lr: 0.000075, loss: 0.0873
2022-10-05 04:47:01 - train: epoch 0080, iter [00430, 01251], lr: 0.000075, loss: 0.0782
2022-10-05 04:47:29 - train: epoch 0080, iter [00440, 01251], lr: 0.000075, loss: 0.0772
2022-10-05 04:47:57 - train: epoch 0080, iter [00450, 01251], lr: 0.000075, loss: 0.0771
2022-10-05 04:48:25 - train: epoch 0080, iter [00460, 01251], lr: 0.000074, loss: 0.0832
2022-10-05 04:48:53 - train: epoch 0080, iter [00470, 01251], lr: 0.000074, loss: 0.0802
2022-10-05 04:49:21 - train: epoch 0080, iter [00480, 01251], lr: 0.000074, loss: 0.0806
2022-10-05 04:49:49 - train: epoch 0080, iter [00490, 01251], lr: 0.000074, loss: 0.0925
2022-10-05 04:50:17 - train: epoch 0080, iter [00500, 01251], lr: 0.000074, loss: 0.0785
2022-10-05 04:50:45 - train: epoch 0080, iter [00510, 01251], lr: 0.000074, loss: 0.0850
2022-10-05 04:51:12 - train: epoch 0080, iter [00520, 01251], lr: 0.000074, loss: 0.0832
2022-10-05 04:51:40 - train: epoch 0080, iter [00530, 01251], lr: 0.000074, loss: 0.0809
2022-10-05 04:52:08 - train: epoch 0080, iter [00540, 01251], lr: 0.000074, loss: 0.0804
2022-10-05 04:52:36 - train: epoch 0080, iter [00550, 01251], lr: 0.000074, loss: 0.0862
2022-10-05 04:53:04 - train: epoch 0080, iter [00560, 01251], lr: 0.000074, loss: 0.0819
2022-10-05 04:53:32 - train: epoch 0080, iter [00570, 01251], lr: 0.000074, loss: 0.0823
2022-10-05 04:54:00 - train: epoch 0080, iter [00580, 01251], lr: 0.000074, loss: 0.0791
2022-10-05 04:54:28 - train: epoch 0080, iter [00590, 01251], lr: 0.000074, loss: 0.0869
2022-10-05 04:54:56 - train: epoch 0080, iter [00600, 01251], lr: 0.000074, loss: 0.0925
2022-10-05 04:55:24 - train: epoch 0080, iter [00610, 01251], lr: 0.000074, loss: 0.0856
2022-10-05 04:55:52 - train: epoch 0080, iter [00620, 01251], lr: 0.000074, loss: 0.0855
2022-10-05 04:56:20 - train: epoch 0080, iter [00630, 01251], lr: 0.000074, loss: 0.0789
2022-10-05 04:56:48 - train: epoch 0080, iter [00640, 01251], lr: 0.000074, loss: 0.0788
2022-10-05 04:57:16 - train: epoch 0080, iter [00650, 01251], lr: 0.000073, loss: 0.0851
2022-10-05 04:57:44 - train: epoch 0080, iter [00660, 01251], lr: 0.000073, loss: 0.0797
2022-10-05 04:58:12 - train: epoch 0080, iter [00670, 01251], lr: 0.000073, loss: 0.0790
2022-10-05 04:58:40 - train: epoch 0080, iter [00680, 01251], lr: 0.000073, loss: 0.0758
2022-10-05 04:59:08 - train: epoch 0080, iter [00690, 01251], lr: 0.000073, loss: 0.0775
2022-10-05 04:59:36 - train: epoch 0080, iter [00700, 01251], lr: 0.000073, loss: 0.0822
2022-10-05 05:00:04 - train: epoch 0080, iter [00710, 01251], lr: 0.000073, loss: 0.0866
2022-10-05 05:00:32 - train: epoch 0080, iter [00720, 01251], lr: 0.000073, loss: 0.0832
2022-10-05 05:01:00 - train: epoch 0080, iter [00730, 01251], lr: 0.000073, loss: 0.0754
2022-10-05 05:01:28 - train: epoch 0080, iter [00740, 01251], lr: 0.000073, loss: 0.0830
2022-10-05 05:01:56 - train: epoch 0080, iter [00750, 01251], lr: 0.000073, loss: 0.0825
2022-10-05 05:02:24 - train: epoch 0080, iter [00760, 01251], lr: 0.000073, loss: 0.0781
2022-10-05 05:02:51 - train: epoch 0080, iter [00770, 01251], lr: 0.000073, loss: 0.0834
2022-10-05 05:03:19 - train: epoch 0080, iter [00780, 01251], lr: 0.000073, loss: 0.0825
2022-10-05 05:03:47 - train: epoch 0080, iter [00790, 01251], lr: 0.000073, loss: 0.0837
2022-10-05 05:04:15 - train: epoch 0080, iter [00800, 01251], lr: 0.000073, loss: 0.0759
2022-10-05 05:04:43 - train: epoch 0080, iter [00810, 01251], lr: 0.000073, loss: 0.0849
2022-10-05 05:05:11 - train: epoch 0080, iter [00820, 01251], lr: 0.000073, loss: 0.0799
2022-10-05 05:05:39 - train: epoch 0080, iter [00830, 01251], lr: 0.000072, loss: 0.0819
2022-10-05 05:06:07 - train: epoch 0080, iter [00840, 01251], lr: 0.000072, loss: 0.0785
2022-10-05 05:06:35 - train: epoch 0080, iter [00850, 01251], lr: 0.000072, loss: 0.0918
2022-10-05 05:07:03 - train: epoch 0080, iter [00860, 01251], lr: 0.000072, loss: 0.0805
2022-10-05 05:07:31 - train: epoch 0080, iter [00870, 01251], lr: 0.000072, loss: 0.0858
2022-10-05 05:07:59 - train: epoch 0080, iter [00880, 01251], lr: 0.000072, loss: 0.0808
2022-10-05 05:08:26 - train: epoch 0080, iter [00890, 01251], lr: 0.000072, loss: 0.0722
2022-10-05 05:08:54 - train: epoch 0080, iter [00900, 01251], lr: 0.000072, loss: 0.0901
2022-10-05 05:09:22 - train: epoch 0080, iter [00910, 01251], lr: 0.000072, loss: 0.0778
2022-10-05 05:09:50 - train: epoch 0080, iter [00920, 01251], lr: 0.000072, loss: 0.0781
2022-10-05 05:10:18 - train: epoch 0080, iter [00930, 01251], lr: 0.000072, loss: 0.0863
2022-10-05 05:10:46 - train: epoch 0080, iter [00940, 01251], lr: 0.000072, loss: 0.0809
2022-10-05 05:11:14 - train: epoch 0080, iter [00950, 01251], lr: 0.000072, loss: 0.0846
2022-10-05 05:11:42 - train: epoch 0080, iter [00960, 01251], lr: 0.000072, loss: 0.0836
2022-10-05 05:12:10 - train: epoch 0080, iter [00970, 01251], lr: 0.000072, loss: 0.0763
2022-10-05 05:12:38 - train: epoch 0080, iter [00980, 01251], lr: 0.000072, loss: 0.0804
2022-10-05 05:13:06 - train: epoch 0080, iter [00990, 01251], lr: 0.000072, loss: 0.0785
2022-10-05 05:13:34 - train: epoch 0080, iter [01000, 01251], lr: 0.000072, loss: 0.0840
2022-10-05 05:14:02 - train: epoch 0080, iter [01010, 01251], lr: 0.000071, loss: 0.0854
2022-10-05 05:14:30 - train: epoch 0080, iter [01020, 01251], lr: 0.000071, loss: 0.0781
2022-10-05 05:14:57 - train: epoch 0080, iter [01030, 01251], lr: 0.000071, loss: 0.0791
2022-10-05 05:15:26 - train: epoch 0080, iter [01040, 01251], lr: 0.000071, loss: 0.0829
2022-10-05 05:15:53 - train: epoch 0080, iter [01050, 01251], lr: 0.000071, loss: 0.0785
2022-10-05 05:16:21 - train: epoch 0080, iter [01060, 01251], lr: 0.000071, loss: 0.0850
2022-10-05 05:16:49 - train: epoch 0080, iter [01070, 01251], lr: 0.000071, loss: 0.0864
2022-10-05 05:17:17 - train: epoch 0080, iter [01080, 01251], lr: 0.000071, loss: 0.0720
2022-10-05 05:17:45 - train: epoch 0080, iter [01090, 01251], lr: 0.000071, loss: 0.0825
2022-10-05 05:18:13 - train: epoch 0080, iter [01100, 01251], lr: 0.000071, loss: 0.0825
2022-10-05 05:18:41 - train: epoch 0080, iter [01110, 01251], lr: 0.000071, loss: 0.0795
2022-10-05 05:19:09 - train: epoch 0080, iter [01120, 01251], lr: 0.000071, loss: 0.0817
2022-10-05 05:19:37 - train: epoch 0080, iter [01130, 01251], lr: 0.000071, loss: 0.0930
2022-10-05 05:20:05 - train: epoch 0080, iter [01140, 01251], lr: 0.000071, loss: 0.0847
2022-10-05 05:20:33 - train: epoch 0080, iter [01150, 01251], lr: 0.000071, loss: 0.0872
2022-10-05 05:21:01 - train: epoch 0080, iter [01160, 01251], lr: 0.000071, loss: 0.0845
2022-10-05 05:21:29 - train: epoch 0080, iter [01170, 01251], lr: 0.000071, loss: 0.0855
2022-10-05 05:21:57 - train: epoch 0080, iter [01180, 01251], lr: 0.000071, loss: 0.0836
2022-10-05 05:22:25 - train: epoch 0080, iter [01190, 01251], lr: 0.000071, loss: 0.0737
2022-10-05 05:22:53 - train: epoch 0080, iter [01200, 01251], lr: 0.000070, loss: 0.0789
2022-10-05 05:23:20 - train: epoch 0080, iter [01210, 01251], lr: 0.000070, loss: 0.0819
2022-10-05 05:23:48 - train: epoch 0080, iter [01220, 01251], lr: 0.000070, loss: 0.0795
2022-10-05 05:24:16 - train: epoch 0080, iter [01230, 01251], lr: 0.000070, loss: 0.0842
2022-10-05 05:24:44 - train: epoch 0080, iter [01240, 01251], lr: 0.000070, loss: 0.0866
2022-10-05 05:25:12 - train: epoch 0080, iter [01250, 01251], lr: 0.000070, loss: 0.0793
2022-10-05 05:25:16 - train: epoch 080, train_loss: 0.0828
2022-10-05 05:25:18 - until epoch: 080, best_loss: 0.0828
2022-10-05 05:25:18 - epoch 081 lr: 0.000070
2022-10-05 05:25:53 - train: epoch 0081, iter [00010, 01251], lr: 0.000070, loss: 0.0833
2022-10-05 05:26:21 - train: epoch 0081, iter [00020, 01251], lr: 0.000070, loss: 0.0776
2022-10-05 05:26:49 - train: epoch 0081, iter [00030, 01251], lr: 0.000070, loss: 0.0848
2022-10-05 05:27:17 - train: epoch 0081, iter [00040, 01251], lr: 0.000070, loss: 0.0900
2022-10-05 05:27:45 - train: epoch 0081, iter [00050, 01251], lr: 0.000070, loss: 0.0793
2022-10-05 05:28:13 - train: epoch 0081, iter [00060, 01251], lr: 0.000070, loss: 0.0797
2022-10-05 05:28:41 - train: epoch 0081, iter [00070, 01251], lr: 0.000070, loss: 0.0861
2022-10-05 05:29:09 - train: epoch 0081, iter [00080, 01251], lr: 0.000070, loss: 0.0872
2022-10-05 05:29:37 - train: epoch 0081, iter [00090, 01251], lr: 0.000070, loss: 0.0820
2022-10-05 05:30:04 - train: epoch 0081, iter [00100, 01251], lr: 0.000070, loss: 0.0807
2022-10-05 05:30:32 - train: epoch 0081, iter [00110, 01251], lr: 0.000070, loss: 0.0793
2022-10-05 05:31:00 - train: epoch 0081, iter [00120, 01251], lr: 0.000070, loss: 0.0750
2022-10-05 05:31:28 - train: epoch 0081, iter [00130, 01251], lr: 0.000069, loss: 0.0893
2022-10-05 05:31:56 - train: epoch 0081, iter [00140, 01251], lr: 0.000069, loss: 0.0856
2022-10-05 05:32:24 - train: epoch 0081, iter [00150, 01251], lr: 0.000069, loss: 0.0830
2022-10-05 05:32:52 - train: epoch 0081, iter [00160, 01251], lr: 0.000069, loss: 0.0833
2022-10-05 05:33:20 - train: epoch 0081, iter [00170, 01251], lr: 0.000069, loss: 0.0814
2022-10-05 05:33:48 - train: epoch 0081, iter [00180, 01251], lr: 0.000069, loss: 0.0804
2022-10-05 05:34:15 - train: epoch 0081, iter [00190, 01251], lr: 0.000069, loss: 0.0808
2022-10-05 05:34:43 - train: epoch 0081, iter [00200, 01251], lr: 0.000069, loss: 0.0865
2022-10-05 05:35:11 - train: epoch 0081, iter [00210, 01251], lr: 0.000069, loss: 0.0819
2022-10-05 05:35:39 - train: epoch 0081, iter [00220, 01251], lr: 0.000069, loss: 0.0815
2022-10-05 05:36:07 - train: epoch 0081, iter [00230, 01251], lr: 0.000069, loss: 0.0814
2022-10-05 05:36:35 - train: epoch 0081, iter [00240, 01251], lr: 0.000069, loss: 0.0840
2022-10-05 05:37:03 - train: epoch 0081, iter [00250, 01251], lr: 0.000069, loss: 0.0794
2022-10-05 05:37:31 - train: epoch 0081, iter [00260, 01251], lr: 0.000069, loss: 0.0848
2022-10-05 05:37:59 - train: epoch 0081, iter [00270, 01251], lr: 0.000069, loss: 0.0816
2022-10-05 05:38:27 - train: epoch 0081, iter [00280, 01251], lr: 0.000069, loss: 0.0878
2022-10-05 05:38:55 - train: epoch 0081, iter [00290, 01251], lr: 0.000069, loss: 0.0875
2022-10-05 05:39:23 - train: epoch 0081, iter [00300, 01251], lr: 0.000069, loss: 0.0850
2022-10-05 05:39:51 - train: epoch 0081, iter [00310, 01251], lr: 0.000069, loss: 0.0835
2022-10-05 05:40:19 - train: epoch 0081, iter [00320, 01251], lr: 0.000068, loss: 0.0821
2022-10-05 05:40:47 - train: epoch 0081, iter [00330, 01251], lr: 0.000068, loss: 0.0757
2022-10-05 05:41:15 - train: epoch 0081, iter [00340, 01251], lr: 0.000068, loss: 0.0799
2022-10-05 05:41:43 - train: epoch 0081, iter [00350, 01251], lr: 0.000068, loss: 0.0870
2022-10-05 05:42:11 - train: epoch 0081, iter [00360, 01251], lr: 0.000068, loss: 0.0806
2022-10-05 05:42:39 - train: epoch 0081, iter [00370, 01251], lr: 0.000068, loss: 0.0831
2022-10-05 05:43:07 - train: epoch 0081, iter [00380, 01251], lr: 0.000068, loss: 0.0863
2022-10-05 05:43:35 - train: epoch 0081, iter [00390, 01251], lr: 0.000068, loss: 0.0909
2022-10-05 05:44:03 - train: epoch 0081, iter [00400, 01251], lr: 0.000068, loss: 0.0821
2022-10-05 05:44:31 - train: epoch 0081, iter [00410, 01251], lr: 0.000068, loss: 0.0825
2022-10-05 05:44:59 - train: epoch 0081, iter [00420, 01251], lr: 0.000068, loss: 0.0876
2022-10-05 05:45:27 - train: epoch 0081, iter [00430, 01251], lr: 0.000068, loss: 0.0715
2022-10-05 05:45:55 - train: epoch 0081, iter [00440, 01251], lr: 0.000068, loss: 0.0879
2022-10-05 05:46:23 - train: epoch 0081, iter [00450, 01251], lr: 0.000068, loss: 0.0836
2022-10-05 05:46:51 - train: epoch 0081, iter [00460, 01251], lr: 0.000068, loss: 0.0805
2022-10-05 05:47:19 - train: epoch 0081, iter [00470, 01251], lr: 0.000068, loss: 0.0862
2022-10-05 05:47:47 - train: epoch 0081, iter [00480, 01251], lr: 0.000068, loss: 0.0772
2022-10-05 05:48:15 - train: epoch 0081, iter [00490, 01251], lr: 0.000068, loss: 0.0804
2022-10-05 05:48:43 - train: epoch 0081, iter [00500, 01251], lr: 0.000068, loss: 0.0816
2022-10-05 05:49:11 - train: epoch 0081, iter [00510, 01251], lr: 0.000067, loss: 0.0840
2022-10-05 05:49:39 - train: epoch 0081, iter [00520, 01251], lr: 0.000067, loss: 0.0908
2022-10-05 05:50:07 - train: epoch 0081, iter [00530, 01251], lr: 0.000067, loss: 0.0803
2022-10-05 05:50:35 - train: epoch 0081, iter [00540, 01251], lr: 0.000067, loss: 0.0904
2022-10-05 05:51:03 - train: epoch 0081, iter [00550, 01251], lr: 0.000067, loss: 0.0841
2022-10-05 05:51:31 - train: epoch 0081, iter [00560, 01251], lr: 0.000067, loss: 0.0866
2022-10-05 05:51:59 - train: epoch 0081, iter [00570, 01251], lr: 0.000067, loss: 0.0784
2022-10-05 05:52:27 - train: epoch 0081, iter [00580, 01251], lr: 0.000067, loss: 0.0760
2022-10-05 05:52:55 - train: epoch 0081, iter [00590, 01251], lr: 0.000067, loss: 0.0784
2022-10-05 05:53:23 - train: epoch 0081, iter [00600, 01251], lr: 0.000067, loss: 0.0792
2022-10-05 05:53:51 - train: epoch 0081, iter [00610, 01251], lr: 0.000067, loss: 0.0782
2022-10-05 05:54:19 - train: epoch 0081, iter [00620, 01251], lr: 0.000067, loss: 0.0823
2022-10-05 05:54:47 - train: epoch 0081, iter [00630, 01251], lr: 0.000067, loss: 0.0808
2022-10-05 05:55:15 - train: epoch 0081, iter [00640, 01251], lr: 0.000067, loss: 0.0833
2022-10-05 05:55:43 - train: epoch 0081, iter [00650, 01251], lr: 0.000067, loss: 0.0837
2022-10-05 05:56:11 - train: epoch 0081, iter [00660, 01251], lr: 0.000067, loss: 0.0821
2022-10-05 05:56:39 - train: epoch 0081, iter [00670, 01251], lr: 0.000067, loss: 0.0834
2022-10-05 05:57:07 - train: epoch 0081, iter [00680, 01251], lr: 0.000067, loss: 0.0840
2022-10-05 05:57:36 - train: epoch 0081, iter [00690, 01251], lr: 0.000067, loss: 0.0787
2022-10-05 05:58:04 - train: epoch 0081, iter [00700, 01251], lr: 0.000066, loss: 0.0885
2022-10-05 05:58:32 - train: epoch 0081, iter [00710, 01251], lr: 0.000066, loss: 0.0781
2022-10-05 05:59:00 - train: epoch 0081, iter [00720, 01251], lr: 0.000066, loss: 0.0769
2022-10-05 05:59:28 - train: epoch 0081, iter [00730, 01251], lr: 0.000066, loss: 0.0821
2022-10-05 05:59:55 - train: epoch 0081, iter [00740, 01251], lr: 0.000066, loss: 0.0826
2022-10-05 06:00:23 - train: epoch 0081, iter [00750, 01251], lr: 0.000066, loss: 0.0775
2022-10-05 06:00:52 - train: epoch 0081, iter [00760, 01251], lr: 0.000066, loss: 0.0806
2022-10-05 06:01:20 - train: epoch 0081, iter [00770, 01251], lr: 0.000066, loss: 0.0809
2022-10-05 06:01:48 - train: epoch 0081, iter [00780, 01251], lr: 0.000066, loss: 0.0796
2022-10-05 06:02:16 - train: epoch 0081, iter [00790, 01251], lr: 0.000066, loss: 0.0862
2022-10-05 06:02:44 - train: epoch 0081, iter [00800, 01251], lr: 0.000066, loss: 0.0811
2022-10-05 06:03:12 - train: epoch 0081, iter [00810, 01251], lr: 0.000066, loss: 0.0837
2022-10-05 06:03:40 - train: epoch 0081, iter [00820, 01251], lr: 0.000066, loss: 0.0853
2022-10-05 06:04:08 - train: epoch 0081, iter [00830, 01251], lr: 0.000066, loss: 0.0773
2022-10-05 06:04:36 - train: epoch 0081, iter [00840, 01251], lr: 0.000066, loss: 0.0767
2022-10-05 06:05:04 - train: epoch 0081, iter [00850, 01251], lr: 0.000066, loss: 0.0792
2022-10-05 06:05:32 - train: epoch 0081, iter [00860, 01251], lr: 0.000066, loss: 0.0783
2022-10-05 06:06:00 - train: epoch 0081, iter [00870, 01251], lr: 0.000066, loss: 0.0848
2022-10-05 06:06:28 - train: epoch 0081, iter [00880, 01251], lr: 0.000066, loss: 0.0801
2022-10-05 06:06:56 - train: epoch 0081, iter [00890, 01251], lr: 0.000065, loss: 0.0853
2022-10-05 06:07:25 - train: epoch 0081, iter [00900, 01251], lr: 0.000065, loss: 0.0850
2022-10-05 06:07:53 - train: epoch 0081, iter [00910, 01251], lr: 0.000065, loss: 0.0785
2022-10-05 06:08:21 - train: epoch 0081, iter [00920, 01251], lr: 0.000065, loss: 0.0806
2022-10-05 06:08:49 - train: epoch 0081, iter [00930, 01251], lr: 0.000065, loss: 0.0878
2022-10-05 06:09:17 - train: epoch 0081, iter [00940, 01251], lr: 0.000065, loss: 0.0828
2022-10-05 06:09:45 - train: epoch 0081, iter [00950, 01251], lr: 0.000065, loss: 0.0868
2022-10-05 06:10:13 - train: epoch 0081, iter [00960, 01251], lr: 0.000065, loss: 0.0832
2022-10-05 06:10:41 - train: epoch 0081, iter [00970, 01251], lr: 0.000065, loss: 0.0871
2022-10-05 06:11:09 - train: epoch 0081, iter [00980, 01251], lr: 0.000065, loss: 0.0768
2022-10-05 06:11:37 - train: epoch 0081, iter [00990, 01251], lr: 0.000065, loss: 0.0869
2022-10-05 06:12:05 - train: epoch 0081, iter [01000, 01251], lr: 0.000065, loss: 0.0897
2022-10-05 06:12:33 - train: epoch 0081, iter [01010, 01251], lr: 0.000065, loss: 0.0812
2022-10-05 06:13:01 - train: epoch 0081, iter [01020, 01251], lr: 0.000065, loss: 0.0785
2022-10-05 06:13:29 - train: epoch 0081, iter [01030, 01251], lr: 0.000065, loss: 0.0836
2022-10-05 06:13:57 - train: epoch 0081, iter [01040, 01251], lr: 0.000065, loss: 0.0786
2022-10-05 06:14:25 - train: epoch 0081, iter [01050, 01251], lr: 0.000065, loss: 0.0849
2022-10-05 06:14:53 - train: epoch 0081, iter [01060, 01251], lr: 0.000065, loss: 0.0861
2022-10-05 06:15:21 - train: epoch 0081, iter [01070, 01251], lr: 0.000065, loss: 0.0895
2022-10-05 06:15:49 - train: epoch 0081, iter [01080, 01251], lr: 0.000064, loss: 0.0801
2022-10-05 06:16:17 - train: epoch 0081, iter [01090, 01251], lr: 0.000064, loss: 0.0839
2022-10-05 06:16:45 - train: epoch 0081, iter [01100, 01251], lr: 0.000064, loss: 0.0873
2022-10-05 06:17:13 - train: epoch 0081, iter [01110, 01251], lr: 0.000064, loss: 0.0904
2022-10-05 06:17:41 - train: epoch 0081, iter [01120, 01251], lr: 0.000064, loss: 0.0803
2022-10-05 06:18:09 - train: epoch 0081, iter [01130, 01251], lr: 0.000064, loss: 0.0839
2022-10-05 06:18:38 - train: epoch 0081, iter [01140, 01251], lr: 0.000064, loss: 0.0859
2022-10-05 06:19:06 - train: epoch 0081, iter [01150, 01251], lr: 0.000064, loss: 0.0853
2022-10-05 06:19:34 - train: epoch 0081, iter [01160, 01251], lr: 0.000064, loss: 0.0834
2022-10-05 06:20:02 - train: epoch 0081, iter [01170, 01251], lr: 0.000064, loss: 0.0866
2022-10-05 06:20:30 - train: epoch 0081, iter [01180, 01251], lr: 0.000064, loss: 0.0860
2022-10-05 06:20:58 - train: epoch 0081, iter [01190, 01251], lr: 0.000064, loss: 0.0760
2022-10-05 06:21:26 - train: epoch 0081, iter [01200, 01251], lr: 0.000064, loss: 0.0820
2022-10-05 06:21:54 - train: epoch 0081, iter [01210, 01251], lr: 0.000064, loss: 0.0722
2022-10-05 06:22:22 - train: epoch 0081, iter [01220, 01251], lr: 0.000064, loss: 0.0869
2022-10-05 06:22:50 - train: epoch 0081, iter [01230, 01251], lr: 0.000064, loss: 0.0771
2022-10-05 06:23:18 - train: epoch 0081, iter [01240, 01251], lr: 0.000064, loss: 0.0806
2022-10-05 06:23:45 - train: epoch 0081, iter [01250, 01251], lr: 0.000064, loss: 0.0868
2022-10-05 06:23:50 - train: epoch 081, train_loss: 0.0827
2022-10-05 06:23:52 - until epoch: 081, best_loss: 0.0827
2022-10-05 06:23:52 - epoch 082 lr: 0.000064
2022-10-05 06:24:27 - train: epoch 0082, iter [00010, 01251], lr: 0.000064, loss: 0.0922
2022-10-05 06:24:55 - train: epoch 0082, iter [00020, 01251], lr: 0.000063, loss: 0.0849
2022-10-05 06:25:22 - train: epoch 0082, iter [00030, 01251], lr: 0.000063, loss: 0.0753
2022-10-05 06:25:50 - train: epoch 0082, iter [00040, 01251], lr: 0.000063, loss: 0.0797
2022-10-05 06:26:18 - train: epoch 0082, iter [00050, 01251], lr: 0.000063, loss: 0.0817
2022-10-05 06:26:46 - train: epoch 0082, iter [00060, 01251], lr: 0.000063, loss: 0.0829
2022-10-05 06:27:14 - train: epoch 0082, iter [00070, 01251], lr: 0.000063, loss: 0.0919
2022-10-05 06:27:42 - train: epoch 0082, iter [00080, 01251], lr: 0.000063, loss: 0.0834
2022-10-05 06:28:10 - train: epoch 0082, iter [00090, 01251], lr: 0.000063, loss: 0.0836
2022-10-05 06:28:38 - train: epoch 0082, iter [00100, 01251], lr: 0.000063, loss: 0.0871
2022-10-05 06:29:05 - train: epoch 0082, iter [00110, 01251], lr: 0.000063, loss: 0.0796
2022-10-05 06:29:33 - train: epoch 0082, iter [00120, 01251], lr: 0.000063, loss: 0.0839
2022-10-05 06:30:01 - train: epoch 0082, iter [00130, 01251], lr: 0.000063, loss: 0.0789
2022-10-05 06:30:29 - train: epoch 0082, iter [00140, 01251], lr: 0.000063, loss: 0.0819
2022-10-05 06:30:57 - train: epoch 0082, iter [00150, 01251], lr: 0.000063, loss: 0.0848
2022-10-05 06:31:25 - train: epoch 0082, iter [00160, 01251], lr: 0.000063, loss: 0.0820
2022-10-05 06:31:53 - train: epoch 0082, iter [00170, 01251], lr: 0.000063, loss: 0.0912
2022-10-05 06:32:21 - train: epoch 0082, iter [00180, 01251], lr: 0.000063, loss: 0.0831
2022-10-05 06:32:49 - train: epoch 0082, iter [00190, 01251], lr: 0.000063, loss: 0.0809
2022-10-05 06:33:17 - train: epoch 0082, iter [00200, 01251], lr: 0.000063, loss: 0.0824
2022-10-05 06:33:45 - train: epoch 0082, iter [00210, 01251], lr: 0.000063, loss: 0.0868
2022-10-05 06:34:13 - train: epoch 0082, iter [00220, 01251], lr: 0.000062, loss: 0.0831
2022-10-05 06:34:41 - train: epoch 0082, iter [00230, 01251], lr: 0.000062, loss: 0.0808
2022-10-05 06:35:09 - train: epoch 0082, iter [00240, 01251], lr: 0.000062, loss: 0.0781
2022-10-05 06:35:37 - train: epoch 0082, iter [00250, 01251], lr: 0.000062, loss: 0.0821
2022-10-05 06:36:05 - train: epoch 0082, iter [00260, 01251], lr: 0.000062, loss: 0.0832
2022-10-05 06:36:33 - train: epoch 0082, iter [00270, 01251], lr: 0.000062, loss: 0.0742
2022-10-05 06:37:01 - train: epoch 0082, iter [00280, 01251], lr: 0.000062, loss: 0.0860
2022-10-05 06:37:29 - train: epoch 0082, iter [00290, 01251], lr: 0.000062, loss: 0.0835
2022-10-05 06:37:57 - train: epoch 0082, iter [00300, 01251], lr: 0.000062, loss: 0.0862
2022-10-05 06:38:25 - train: epoch 0082, iter [00310, 01251], lr: 0.000062, loss: 0.0869
2022-10-05 06:38:53 - train: epoch 0082, iter [00320, 01251], lr: 0.000062, loss: 0.0807
2022-10-05 06:39:21 - train: epoch 0082, iter [00330, 01251], lr: 0.000062, loss: 0.0867
2022-10-05 06:39:49 - train: epoch 0082, iter [00340, 01251], lr: 0.000062, loss: 0.0847
2022-10-05 06:40:17 - train: epoch 0082, iter [00350, 01251], lr: 0.000062, loss: 0.0846
2022-10-05 06:40:45 - train: epoch 0082, iter [00360, 01251], lr: 0.000062, loss: 0.0879
2022-10-05 06:41:13 - train: epoch 0082, iter [00370, 01251], lr: 0.000062, loss: 0.0839
2022-10-05 06:41:41 - train: epoch 0082, iter [00380, 01251], lr: 0.000062, loss: 0.0783
2022-10-05 06:42:09 - train: epoch 0082, iter [00390, 01251], lr: 0.000062, loss: 0.0899
2022-10-05 06:42:37 - train: epoch 0082, iter [00400, 01251], lr: 0.000062, loss: 0.0773
2022-10-05 06:43:05 - train: epoch 0082, iter [00410, 01251], lr: 0.000061, loss: 0.0824
2022-10-05 06:43:33 - train: epoch 0082, iter [00420, 01251], lr: 0.000061, loss: 0.0834
2022-10-05 06:44:01 - train: epoch 0082, iter [00430, 01251], lr: 0.000061, loss: 0.0762
2022-10-05 06:44:29 - train: epoch 0082, iter [00440, 01251], lr: 0.000061, loss: 0.0821
2022-10-05 06:44:57 - train: epoch 0082, iter [00450, 01251], lr: 0.000061, loss: 0.0792
2022-10-05 06:45:25 - train: epoch 0082, iter [00460, 01251], lr: 0.000061, loss: 0.0820
2022-10-05 06:45:53 - train: epoch 0082, iter [00470, 01251], lr: 0.000061, loss: 0.0765
2022-10-05 06:46:21 - train: epoch 0082, iter [00480, 01251], lr: 0.000061, loss: 0.0817
2022-10-05 06:46:49 - train: epoch 0082, iter [00490, 01251], lr: 0.000061, loss: 0.0829
2022-10-05 06:47:17 - train: epoch 0082, iter [00500, 01251], lr: 0.000061, loss: 0.0775
2022-10-05 06:47:45 - train: epoch 0082, iter [00510, 01251], lr: 0.000061, loss: 0.0741
2022-10-05 06:48:13 - train: epoch 0082, iter [00520, 01251], lr: 0.000061, loss: 0.0840
2022-10-05 06:48:41 - train: epoch 0082, iter [00530, 01251], lr: 0.000061, loss: 0.0863
2022-10-05 06:49:09 - train: epoch 0082, iter [00540, 01251], lr: 0.000061, loss: 0.0762
2022-10-05 06:49:37 - train: epoch 0082, iter [00550, 01251], lr: 0.000061, loss: 0.0821
2022-10-05 06:50:05 - train: epoch 0082, iter [00560, 01251], lr: 0.000061, loss: 0.0809
2022-10-05 06:50:33 - train: epoch 0082, iter [00570, 01251], lr: 0.000061, loss: 0.0789
2022-10-05 06:51:01 - train: epoch 0082, iter [00580, 01251], lr: 0.000061, loss: 0.0847
2022-10-05 06:51:29 - train: epoch 0082, iter [00590, 01251], lr: 0.000061, loss: 0.0796
2022-10-05 06:51:57 - train: epoch 0082, iter [00600, 01251], lr: 0.000061, loss: 0.0774
2022-10-05 06:52:25 - train: epoch 0082, iter [00610, 01251], lr: 0.000060, loss: 0.0862
2022-10-05 06:52:53 - train: epoch 0082, iter [00620, 01251], lr: 0.000060, loss: 0.0747
2022-10-05 06:53:21 - train: epoch 0082, iter [00630, 01251], lr: 0.000060, loss: 0.0822
2022-10-05 06:53:49 - train: epoch 0082, iter [00640, 01251], lr: 0.000060, loss: 0.0831
2022-10-05 06:54:17 - train: epoch 0082, iter [00650, 01251], lr: 0.000060, loss: 0.0886
2022-10-05 06:54:45 - train: epoch 0082, iter [00660, 01251], lr: 0.000060, loss: 0.0804
2022-10-05 06:55:13 - train: epoch 0082, iter [00670, 01251], lr: 0.000060, loss: 0.0790
2022-10-05 06:55:41 - train: epoch 0082, iter [00680, 01251], lr: 0.000060, loss: 0.0833
2022-10-05 06:56:09 - train: epoch 0082, iter [00690, 01251], lr: 0.000060, loss: 0.0817
2022-10-05 06:56:38 - train: epoch 0082, iter [00700, 01251], lr: 0.000060, loss: 0.0836
2022-10-05 06:57:06 - train: epoch 0082, iter [00710, 01251], lr: 0.000060, loss: 0.0903
2022-10-05 06:57:34 - train: epoch 0082, iter [00720, 01251], lr: 0.000060, loss: 0.0872
2022-10-05 06:58:02 - train: epoch 0082, iter [00730, 01251], lr: 0.000060, loss: 0.0918
2022-10-05 06:58:30 - train: epoch 0082, iter [00740, 01251], lr: 0.000060, loss: 0.0881
2022-10-05 06:58:58 - train: epoch 0082, iter [00750, 01251], lr: 0.000060, loss: 0.0860
2022-10-05 06:59:26 - train: epoch 0082, iter [00760, 01251], lr: 0.000060, loss: 0.0852
2022-10-05 06:59:54 - train: epoch 0082, iter [00770, 01251], lr: 0.000060, loss: 0.0889
2022-10-05 07:00:22 - train: epoch 0082, iter [00780, 01251], lr: 0.000060, loss: 0.0797
2022-10-05 07:00:50 - train: epoch 0082, iter [00790, 01251], lr: 0.000060, loss: 0.0747
2022-10-05 07:01:18 - train: epoch 0082, iter [00800, 01251], lr: 0.000060, loss: 0.0734
2022-10-05 07:01:46 - train: epoch 0082, iter [00810, 01251], lr: 0.000059, loss: 0.0823
2022-10-05 07:02:14 - train: epoch 0082, iter [00820, 01251], lr: 0.000059, loss: 0.0803
2022-10-05 07:02:42 - train: epoch 0082, iter [00830, 01251], lr: 0.000059, loss: 0.0805
2022-10-05 07:03:10 - train: epoch 0082, iter [00840, 01251], lr: 0.000059, loss: 0.0790
2022-10-05 07:03:38 - train: epoch 0082, iter [00850, 01251], lr: 0.000059, loss: 0.0840
2022-10-05 07:04:06 - train: epoch 0082, iter [00860, 01251], lr: 0.000059, loss: 0.0818
2022-10-05 07:04:34 - train: epoch 0082, iter [00870, 01251], lr: 0.000059, loss: 0.0806
2022-10-05 07:05:02 - train: epoch 0082, iter [00880, 01251], lr: 0.000059, loss: 0.0892
2022-10-05 07:05:30 - train: epoch 0082, iter [00890, 01251], lr: 0.000059, loss: 0.0818
2022-10-05 07:05:58 - train: epoch 0082, iter [00900, 01251], lr: 0.000059, loss: 0.0827
2022-10-05 07:06:26 - train: epoch 0082, iter [00910, 01251], lr: 0.000059, loss: 0.0880
2022-10-05 07:06:54 - train: epoch 0082, iter [00920, 01251], lr: 0.000059, loss: 0.0840
2022-10-05 07:07:22 - train: epoch 0082, iter [00930, 01251], lr: 0.000059, loss: 0.0798
2022-10-05 07:07:50 - train: epoch 0082, iter [00940, 01251], lr: 0.000059, loss: 0.0778
2022-10-05 07:08:18 - train: epoch 0082, iter [00950, 01251], lr: 0.000059, loss: 0.0893
2022-10-05 07:08:46 - train: epoch 0082, iter [00960, 01251], lr: 0.000059, loss: 0.0824
2022-10-05 07:09:14 - train: epoch 0082, iter [00970, 01251], lr: 0.000059, loss: 0.0862
2022-10-05 07:09:42 - train: epoch 0082, iter [00980, 01251], lr: 0.000059, loss: 0.0801
2022-10-05 07:10:10 - train: epoch 0082, iter [00990, 01251], lr: 0.000059, loss: 0.0766
2022-10-05 07:10:38 - train: epoch 0082, iter [01000, 01251], lr: 0.000059, loss: 0.0810
2022-10-05 07:11:06 - train: epoch 0082, iter [01010, 01251], lr: 0.000058, loss: 0.0860
2022-10-05 07:11:34 - train: epoch 0082, iter [01020, 01251], lr: 0.000058, loss: 0.0838
2022-10-05 07:12:02 - train: epoch 0082, iter [01030, 01251], lr: 0.000058, loss: 0.0766
2022-10-05 07:12:30 - train: epoch 0082, iter [01040, 01251], lr: 0.000058, loss: 0.0876
2022-10-05 07:12:58 - train: epoch 0082, iter [01050, 01251], lr: 0.000058, loss: 0.0775
2022-10-05 07:13:27 - train: epoch 0082, iter [01060, 01251], lr: 0.000058, loss: 0.0801
2022-10-05 07:13:55 - train: epoch 0082, iter [01070, 01251], lr: 0.000058, loss: 0.0792
2022-10-05 07:14:23 - train: epoch 0082, iter [01080, 01251], lr: 0.000058, loss: 0.0814
2022-10-05 07:14:51 - train: epoch 0082, iter [01090, 01251], lr: 0.000058, loss: 0.0823
2022-10-05 07:15:19 - train: epoch 0082, iter [01100, 01251], lr: 0.000058, loss: 0.0900
2022-10-05 07:15:47 - train: epoch 0082, iter [01110, 01251], lr: 0.000058, loss: 0.0867
2022-10-05 07:16:15 - train: epoch 0082, iter [01120, 01251], lr: 0.000058, loss: 0.0799
2022-10-05 07:16:43 - train: epoch 0082, iter [01130, 01251], lr: 0.000058, loss: 0.0855
2022-10-05 07:17:11 - train: epoch 0082, iter [01140, 01251], lr: 0.000058, loss: 0.0797
2022-10-05 07:17:39 - train: epoch 0082, iter [01150, 01251], lr: 0.000058, loss: 0.0852
2022-10-05 07:18:07 - train: epoch 0082, iter [01160, 01251], lr: 0.000058, loss: 0.0772
2022-10-05 07:18:35 - train: epoch 0082, iter [01170, 01251], lr: 0.000058, loss: 0.0794
2022-10-05 07:19:03 - train: epoch 0082, iter [01180, 01251], lr: 0.000058, loss: 0.0782
2022-10-05 07:19:31 - train: epoch 0082, iter [01190, 01251], lr: 0.000058, loss: 0.0829
2022-10-05 07:19:59 - train: epoch 0082, iter [01200, 01251], lr: 0.000058, loss: 0.0817
2022-10-05 07:20:27 - train: epoch 0082, iter [01210, 01251], lr: 0.000057, loss: 0.0712
2022-10-05 07:20:55 - train: epoch 0082, iter [01220, 01251], lr: 0.000057, loss: 0.0828
2022-10-05 07:21:23 - train: epoch 0082, iter [01230, 01251], lr: 0.000057, loss: 0.0793
2022-10-05 07:21:51 - train: epoch 0082, iter [01240, 01251], lr: 0.000057, loss: 0.0746
2022-10-05 07:22:19 - train: epoch 0082, iter [01250, 01251], lr: 0.000057, loss: 0.0737
2022-10-05 07:22:24 - train: epoch 082, train_loss: 0.0824
2022-10-05 07:22:26 - until epoch: 082, best_loss: 0.0824
2022-10-05 07:22:26 - epoch 083 lr: 0.000057
2022-10-05 07:23:01 - train: epoch 0083, iter [00010, 01251], lr: 0.000057, loss: 0.0783
2022-10-05 07:23:29 - train: epoch 0083, iter [00020, 01251], lr: 0.000057, loss: 0.0875
2022-10-05 07:23:57 - train: epoch 0083, iter [00030, 01251], lr: 0.000057, loss: 0.0823
2022-10-05 07:24:25 - train: epoch 0083, iter [00040, 01251], lr: 0.000057, loss: 0.0850
2022-10-05 07:24:52 - train: epoch 0083, iter [00050, 01251], lr: 0.000057, loss: 0.0851
2022-10-05 07:25:20 - train: epoch 0083, iter [00060, 01251], lr: 0.000057, loss: 0.0794
2022-10-05 07:25:49 - train: epoch 0083, iter [00070, 01251], lr: 0.000057, loss: 0.0838
2022-10-05 07:26:17 - train: epoch 0083, iter [00080, 01251], lr: 0.000057, loss: 0.0855
2022-10-05 07:26:45 - train: epoch 0083, iter [00090, 01251], lr: 0.000057, loss: 0.0858
2022-10-05 07:27:13 - train: epoch 0083, iter [00100, 01251], lr: 0.000057, loss: 0.0831
2022-10-05 07:27:41 - train: epoch 0083, iter [00110, 01251], lr: 0.000057, loss: 0.0817
2022-10-05 07:28:09 - train: epoch 0083, iter [00120, 01251], lr: 0.000057, loss: 0.0855
2022-10-05 07:28:37 - train: epoch 0083, iter [00130, 01251], lr: 0.000057, loss: 0.0809
2022-10-05 07:29:04 - train: epoch 0083, iter [00140, 01251], lr: 0.000057, loss: 0.0795
2022-10-05 07:29:32 - train: epoch 0083, iter [00150, 01251], lr: 0.000057, loss: 0.0793
2022-10-05 07:30:00 - train: epoch 0083, iter [00160, 01251], lr: 0.000057, loss: 0.0862
2022-10-05 07:30:28 - train: epoch 0083, iter [00170, 01251], lr: 0.000056, loss: 0.0819
2022-10-05 07:30:56 - train: epoch 0083, iter [00180, 01251], lr: 0.000056, loss: 0.0886
2022-10-05 07:31:24 - train: epoch 0083, iter [00190, 01251], lr: 0.000056, loss: 0.0812
2022-10-05 07:31:52 - train: epoch 0083, iter [00200, 01251], lr: 0.000056, loss: 0.0715
2022-10-05 07:32:20 - train: epoch 0083, iter [00210, 01251], lr: 0.000056, loss: 0.0856
2022-10-05 07:32:48 - train: epoch 0083, iter [00220, 01251], lr: 0.000056, loss: 0.0764
2022-10-05 07:33:16 - train: epoch 0083, iter [00230, 01251], lr: 0.000056, loss: 0.0831
2022-10-05 07:33:44 - train: epoch 0083, iter [00240, 01251], lr: 0.000056, loss: 0.0813
2022-10-05 07:34:13 - train: epoch 0083, iter [00250, 01251], lr: 0.000056, loss: 0.0844
2022-10-05 07:34:41 - train: epoch 0083, iter [00260, 01251], lr: 0.000056, loss: 0.0902
2022-10-05 07:35:09 - train: epoch 0083, iter [00270, 01251], lr: 0.000056, loss: 0.0895
2022-10-05 07:35:37 - train: epoch 0083, iter [00280, 01251], lr: 0.000056, loss: 0.0859
2022-10-05 07:36:05 - train: epoch 0083, iter [00290, 01251], lr: 0.000056, loss: 0.0845
2022-10-05 07:36:33 - train: epoch 0083, iter [00300, 01251], lr: 0.000056, loss: 0.0778
2022-10-05 07:37:01 - train: epoch 0083, iter [00310, 01251], lr: 0.000056, loss: 0.0839
2022-10-05 07:37:29 - train: epoch 0083, iter [00320, 01251], lr: 0.000056, loss: 0.0796
2022-10-05 07:37:57 - train: epoch 0083, iter [00330, 01251], lr: 0.000056, loss: 0.0779
2022-10-05 07:38:25 - train: epoch 0083, iter [00340, 01251], lr: 0.000056, loss: 0.0898
2022-10-05 07:38:53 - train: epoch 0083, iter [00350, 01251], lr: 0.000056, loss: 0.0864
2022-10-05 07:39:21 - train: epoch 0083, iter [00360, 01251], lr: 0.000056, loss: 0.0826
2022-10-05 07:39:49 - train: epoch 0083, iter [00370, 01251], lr: 0.000055, loss: 0.0881
2022-10-05 07:40:17 - train: epoch 0083, iter [00380, 01251], lr: 0.000055, loss: 0.0779
2022-10-05 07:40:45 - train: epoch 0083, iter [00390, 01251], lr: 0.000055, loss: 0.0825
2022-10-05 07:41:13 - train: epoch 0083, iter [00400, 01251], lr: 0.000055, loss: 0.0893
2022-10-05 07:41:41 - train: epoch 0083, iter [00410, 01251], lr: 0.000055, loss: 0.0814
2022-10-05 07:42:09 - train: epoch 0083, iter [00420, 01251], lr: 0.000055, loss: 0.0742
2022-10-05 07:42:37 - train: epoch 0083, iter [00430, 01251], lr: 0.000055, loss: 0.0890
2022-10-05 07:43:05 - train: epoch 0083, iter [00440, 01251], lr: 0.000055, loss: 0.0777
2022-10-05 07:43:33 - train: epoch 0083, iter [00450, 01251], lr: 0.000055, loss: 0.0789
2022-10-05 07:44:01 - train: epoch 0083, iter [00460, 01251], lr: 0.000055, loss: 0.0774
2022-10-05 07:44:30 - train: epoch 0083, iter [00470, 01251], lr: 0.000055, loss: 0.0902
2022-10-05 07:44:58 - train: epoch 0083, iter [00480, 01251], lr: 0.000055, loss: 0.0859
2022-10-05 07:45:25 - train: epoch 0083, iter [00490, 01251], lr: 0.000055, loss: 0.0853
2022-10-05 07:45:53 - train: epoch 0083, iter [00500, 01251], lr: 0.000055, loss: 0.0864
2022-10-05 07:46:21 - train: epoch 0083, iter [00510, 01251], lr: 0.000055, loss: 0.0849
2022-10-05 07:46:49 - train: epoch 0083, iter [00520, 01251], lr: 0.000055, loss: 0.0791
2022-10-05 07:47:17 - train: epoch 0083, iter [00530, 01251], lr: 0.000055, loss: 0.0890
2022-10-05 07:47:45 - train: epoch 0083, iter [00540, 01251], lr: 0.000055, loss: 0.0869
2022-10-05 07:48:13 - train: epoch 0083, iter [00550, 01251], lr: 0.000055, loss: 0.0784
2022-10-05 07:48:41 - train: epoch 0083, iter [00560, 01251], lr: 0.000055, loss: 0.0807
2022-10-05 07:49:09 - train: epoch 0083, iter [00570, 01251], lr: 0.000055, loss: 0.0776
2022-10-05 07:49:37 - train: epoch 0083, iter [00580, 01251], lr: 0.000054, loss: 0.0834
2022-10-05 07:50:05 - train: epoch 0083, iter [00590, 01251], lr: 0.000054, loss: 0.0812
2022-10-05 07:50:33 - train: epoch 0083, iter [00600, 01251], lr: 0.000054, loss: 0.0844
2022-10-05 07:51:01 - train: epoch 0083, iter [00610, 01251], lr: 0.000054, loss: 0.0773
2022-10-05 07:51:29 - train: epoch 0083, iter [00620, 01251], lr: 0.000054, loss: 0.0883
2022-10-05 07:51:57 - train: epoch 0083, iter [00630, 01251], lr: 0.000054, loss: 0.0823
2022-10-05 07:52:25 - train: epoch 0083, iter [00640, 01251], lr: 0.000054, loss: 0.0927
2022-10-05 07:52:53 - train: epoch 0083, iter [00650, 01251], lr: 0.000054, loss: 0.0790
2022-10-05 07:53:21 - train: epoch 0083, iter [00660, 01251], lr: 0.000054, loss: 0.0848
2022-10-05 07:53:49 - train: epoch 0083, iter [00670, 01251], lr: 0.000054, loss: 0.0894
2022-10-05 07:54:17 - train: epoch 0083, iter [00680, 01251], lr: 0.000054, loss: 0.0839
2022-10-05 07:54:45 - train: epoch 0083, iter [00690, 01251], lr: 0.000054, loss: 0.0884
2022-10-05 07:55:13 - train: epoch 0083, iter [00700, 01251], lr: 0.000054, loss: 0.0747
2022-10-05 07:55:41 - train: epoch 0083, iter [00710, 01251], lr: 0.000054, loss: 0.0889
2022-10-05 07:56:09 - train: epoch 0083, iter [00720, 01251], lr: 0.000054, loss: 0.0862
2022-10-05 07:56:37 - train: epoch 0083, iter [00730, 01251], lr: 0.000054, loss: 0.0766
2022-10-05 07:57:05 - train: epoch 0083, iter [00740, 01251], lr: 0.000054, loss: 0.0817
2022-10-05 07:57:33 - train: epoch 0083, iter [00750, 01251], lr: 0.000054, loss: 0.0720
2022-10-05 07:58:01 - train: epoch 0083, iter [00760, 01251], lr: 0.000054, loss: 0.0839
2022-10-05 07:58:29 - train: epoch 0083, iter [00770, 01251], lr: 0.000054, loss: 0.0820
2022-10-05 07:58:57 - train: epoch 0083, iter [00780, 01251], lr: 0.000054, loss: 0.0851
2022-10-05 07:59:25 - train: epoch 0083, iter [00790, 01251], lr: 0.000053, loss: 0.0858
2022-10-05 07:59:53 - train: epoch 0083, iter [00800, 01251], lr: 0.000053, loss: 0.0842
2022-10-05 08:00:21 - train: epoch 0083, iter [00810, 01251], lr: 0.000053, loss: 0.0777
2022-10-05 08:00:49 - train: epoch 0083, iter [00820, 01251], lr: 0.000053, loss: 0.0789
2022-10-05 08:01:17 - train: epoch 0083, iter [00830, 01251], lr: 0.000053, loss: 0.0800
2022-10-05 08:01:46 - train: epoch 0083, iter [00840, 01251], lr: 0.000053, loss: 0.0845
2022-10-05 08:02:14 - train: epoch 0083, iter [00850, 01251], lr: 0.000053, loss: 0.0889
2022-10-05 08:02:42 - train: epoch 0083, iter [00860, 01251], lr: 0.000053, loss: 0.0832
2022-10-05 08:03:10 - train: epoch 0083, iter [00870, 01251], lr: 0.000053, loss: 0.0802
2022-10-05 08:03:38 - train: epoch 0083, iter [00880, 01251], lr: 0.000053, loss: 0.0831
2022-10-05 08:04:06 - train: epoch 0083, iter [00890, 01251], lr: 0.000053, loss: 0.0796
2022-10-05 08:04:34 - train: epoch 0083, iter [00900, 01251], lr: 0.000053, loss: 0.0793
2022-10-05 08:05:02 - train: epoch 0083, iter [00910, 01251], lr: 0.000053, loss: 0.0838
2022-10-05 08:05:30 - train: epoch 0083, iter [00920, 01251], lr: 0.000053, loss: 0.0841
2022-10-05 08:05:58 - train: epoch 0083, iter [00930, 01251], lr: 0.000053, loss: 0.0850
2022-10-05 08:06:27 - train: epoch 0083, iter [00940, 01251], lr: 0.000053, loss: 0.0835
2022-10-05 08:06:55 - train: epoch 0083, iter [00950, 01251], lr: 0.000053, loss: 0.0846
2022-10-05 08:07:23 - train: epoch 0083, iter [00960, 01251], lr: 0.000053, loss: 0.0806
2022-10-05 08:07:51 - train: epoch 0083, iter [00970, 01251], lr: 0.000053, loss: 0.0778
2022-10-05 08:08:19 - train: epoch 0083, iter [00980, 01251], lr: 0.000053, loss: 0.0806
2022-10-05 08:08:47 - train: epoch 0083, iter [00990, 01251], lr: 0.000053, loss: 0.0855
2022-10-05 08:09:15 - train: epoch 0083, iter [01000, 01251], lr: 0.000052, loss: 0.0806
2022-10-05 08:09:43 - train: epoch 0083, iter [01010, 01251], lr: 0.000052, loss: 0.0842
2022-10-05 08:10:11 - train: epoch 0083, iter [01020, 01251], lr: 0.000052, loss: 0.0815
2022-10-05 08:10:39 - train: epoch 0083, iter [01030, 01251], lr: 0.000052, loss: 0.0866
2022-10-05 08:11:08 - train: epoch 0083, iter [01040, 01251], lr: 0.000052, loss: 0.0784
2022-10-05 08:11:35 - train: epoch 0083, iter [01050, 01251], lr: 0.000052, loss: 0.0898
2022-10-05 08:12:04 - train: epoch 0083, iter [01060, 01251], lr: 0.000052, loss: 0.0793
2022-10-05 08:12:32 - train: epoch 0083, iter [01070, 01251], lr: 0.000052, loss: 0.0832
2022-10-05 08:13:00 - train: epoch 0083, iter [01080, 01251], lr: 0.000052, loss: 0.0788
2022-10-05 08:13:28 - train: epoch 0083, iter [01090, 01251], lr: 0.000052, loss: 0.0756
2022-10-05 08:13:56 - train: epoch 0083, iter [01100, 01251], lr: 0.000052, loss: 0.0808
2022-10-05 08:14:24 - train: epoch 0083, iter [01110, 01251], lr: 0.000052, loss: 0.0832
2022-10-05 08:14:52 - train: epoch 0083, iter [01120, 01251], lr: 0.000052, loss: 0.0794
2022-10-05 08:15:20 - train: epoch 0083, iter [01130, 01251], lr: 0.000052, loss: 0.0825
2022-10-05 08:15:48 - train: epoch 0083, iter [01140, 01251], lr: 0.000052, loss: 0.0826
2022-10-05 08:16:16 - train: epoch 0083, iter [01150, 01251], lr: 0.000052, loss: 0.0810
2022-10-05 08:16:44 - train: epoch 0083, iter [01160, 01251], lr: 0.000052, loss: 0.0856
2022-10-05 08:17:12 - train: epoch 0083, iter [01170, 01251], lr: 0.000052, loss: 0.0777
2022-10-05 08:17:40 - train: epoch 0083, iter [01180, 01251], lr: 0.000052, loss: 0.0804
2022-10-05 08:18:08 - train: epoch 0083, iter [01190, 01251], lr: 0.000052, loss: 0.0821
2022-10-05 08:18:37 - train: epoch 0083, iter [01200, 01251], lr: 0.000052, loss: 0.0853
2022-10-05 08:19:05 - train: epoch 0083, iter [01210, 01251], lr: 0.000051, loss: 0.0862
2022-10-05 08:19:33 - train: epoch 0083, iter [01220, 01251], lr: 0.000051, loss: 0.0809
2022-10-05 08:20:01 - train: epoch 0083, iter [01230, 01251], lr: 0.000051, loss: 0.0808
2022-10-05 08:20:29 - train: epoch 0083, iter [01240, 01251], lr: 0.000051, loss: 0.0835
2022-10-05 08:20:57 - train: epoch 0083, iter [01250, 01251], lr: 0.000051, loss: 0.0799
2022-10-05 08:21:01 - train: epoch 083, train_loss: 0.0823
2022-10-05 08:21:03 - until epoch: 083, best_loss: 0.0823
2022-10-05 08:21:03 - epoch 084 lr: 0.000051
2022-10-05 08:21:38 - train: epoch 0084, iter [00010, 01251], lr: 0.000051, loss: 0.0728
2022-10-05 08:22:06 - train: epoch 0084, iter [00020, 01251], lr: 0.000051, loss: 0.0859
2022-10-05 08:22:34 - train: epoch 0084, iter [00030, 01251], lr: 0.000051, loss: 0.0859
2022-10-05 08:23:02 - train: epoch 0084, iter [00040, 01251], lr: 0.000051, loss: 0.0786
2022-10-05 08:23:30 - train: epoch 0084, iter [00050, 01251], lr: 0.000051, loss: 0.0805
2022-10-05 08:23:57 - train: epoch 0084, iter [00060, 01251], lr: 0.000051, loss: 0.0812
2022-10-05 08:24:25 - train: epoch 0084, iter [00070, 01251], lr: 0.000051, loss: 0.0860
2022-10-05 08:24:53 - train: epoch 0084, iter [00080, 01251], lr: 0.000051, loss: 0.0813
2022-10-05 08:25:21 - train: epoch 0084, iter [00090, 01251], lr: 0.000051, loss: 0.0826
2022-10-05 08:25:49 - train: epoch 0084, iter [00100, 01251], lr: 0.000051, loss: 0.0843
2022-10-05 08:26:17 - train: epoch 0084, iter [00110, 01251], lr: 0.000051, loss: 0.0899
2022-10-05 08:26:45 - train: epoch 0084, iter [00120, 01251], lr: 0.000051, loss: 0.0814
2022-10-05 08:27:13 - train: epoch 0084, iter [00130, 01251], lr: 0.000051, loss: 0.0771
2022-10-05 08:27:41 - train: epoch 0084, iter [00140, 01251], lr: 0.000051, loss: 0.0812
2022-10-05 08:28:09 - train: epoch 0084, iter [00150, 01251], lr: 0.000051, loss: 0.0833
2022-10-05 08:28:37 - train: epoch 0084, iter [00160, 01251], lr: 0.000051, loss: 0.0882
2022-10-05 08:29:05 - train: epoch 0084, iter [00170, 01251], lr: 0.000050, loss: 0.0831
2022-10-05 08:29:33 - train: epoch 0084, iter [00180, 01251], lr: 0.000050, loss: 0.0779
2022-10-05 08:30:01 - train: epoch 0084, iter [00190, 01251], lr: 0.000050, loss: 0.0859
2022-10-05 08:30:29 - train: epoch 0084, iter [00200, 01251], lr: 0.000050, loss: 0.0810
2022-10-05 08:30:57 - train: epoch 0084, iter [00210, 01251], lr: 0.000050, loss: 0.0903
2022-10-05 08:31:25 - train: epoch 0084, iter [00220, 01251], lr: 0.000050, loss: 0.0803
2022-10-05 08:31:53 - train: epoch 0084, iter [00230, 01251], lr: 0.000050, loss: 0.0822
2022-10-05 08:32:21 - train: epoch 0084, iter [00240, 01251], lr: 0.000050, loss: 0.0808
2022-10-05 08:32:49 - train: epoch 0084, iter [00250, 01251], lr: 0.000050, loss: 0.0867
2022-10-05 08:33:17 - train: epoch 0084, iter [00260, 01251], lr: 0.000050, loss: 0.0785
2022-10-05 08:33:45 - train: epoch 0084, iter [00270, 01251], lr: 0.000050, loss: 0.0810
2022-10-05 08:34:13 - train: epoch 0084, iter [00280, 01251], lr: 0.000050, loss: 0.0861
2022-10-05 08:34:41 - train: epoch 0084, iter [00290, 01251], lr: 0.000050, loss: 0.0818
2022-10-05 08:35:10 - train: epoch 0084, iter [00300, 01251], lr: 0.000050, loss: 0.0806
2022-10-05 08:35:38 - train: epoch 0084, iter [00310, 01251], lr: 0.000050, loss: 0.0864
2022-10-05 08:36:06 - train: epoch 0084, iter [00320, 01251], lr: 0.000050, loss: 0.0867
2022-10-05 08:36:34 - train: epoch 0084, iter [00330, 01251], lr: 0.000050, loss: 0.0806
2022-10-05 08:37:02 - train: epoch 0084, iter [00340, 01251], lr: 0.000050, loss: 0.0864
2022-10-05 08:37:30 - train: epoch 0084, iter [00350, 01251], lr: 0.000050, loss: 0.0827
2022-10-05 08:37:58 - train: epoch 0084, iter [00360, 01251], lr: 0.000050, loss: 0.0784
2022-10-05 08:38:26 - train: epoch 0084, iter [00370, 01251], lr: 0.000050, loss: 0.0815
2022-10-05 08:38:54 - train: epoch 0084, iter [00380, 01251], lr: 0.000050, loss: 0.0868
2022-10-05 08:39:22 - train: epoch 0084, iter [00390, 01251], lr: 0.000049, loss: 0.0832
2022-10-05 08:39:50 - train: epoch 0084, iter [00400, 01251], lr: 0.000049, loss: 0.0787
2022-10-05 08:40:18 - train: epoch 0084, iter [00410, 01251], lr: 0.000049, loss: 0.0864
2022-10-05 08:40:46 - train: epoch 0084, iter [00420, 01251], lr: 0.000049, loss: 0.0820
2022-10-05 08:41:14 - train: epoch 0084, iter [00430, 01251], lr: 0.000049, loss: 0.0793
2022-10-05 08:41:42 - train: epoch 0084, iter [00440, 01251], lr: 0.000049, loss: 0.0833
2022-10-05 08:42:10 - train: epoch 0084, iter [00450, 01251], lr: 0.000049, loss: 0.0787
2022-10-05 08:42:38 - train: epoch 0084, iter [00460, 01251], lr: 0.000049, loss: 0.0883
2022-10-05 08:43:06 - train: epoch 0084, iter [00470, 01251], lr: 0.000049, loss: 0.0857
2022-10-05 08:43:34 - train: epoch 0084, iter [00480, 01251], lr: 0.000049, loss: 0.0810
2022-10-05 08:44:03 - train: epoch 0084, iter [00490, 01251], lr: 0.000049, loss: 0.0819
2022-10-05 08:44:31 - train: epoch 0084, iter [00500, 01251], lr: 0.000049, loss: 0.0836
2022-10-05 08:44:59 - train: epoch 0084, iter [00510, 01251], lr: 0.000049, loss: 0.0774
2022-10-05 08:45:27 - train: epoch 0084, iter [00520, 01251], lr: 0.000049, loss: 0.0816
2022-10-05 08:45:55 - train: epoch 0084, iter [00530, 01251], lr: 0.000049, loss: 0.0864
2022-10-05 08:46:23 - train: epoch 0084, iter [00540, 01251], lr: 0.000049, loss: 0.0844
2022-10-05 08:46:51 - train: epoch 0084, iter [00550, 01251], lr: 0.000049, loss: 0.0802
2022-10-05 08:47:19 - train: epoch 0084, iter [00560, 01251], lr: 0.000049, loss: 0.0796
2022-10-05 08:47:47 - train: epoch 0084, iter [00570, 01251], lr: 0.000049, loss: 0.0843
2022-10-05 08:48:15 - train: epoch 0084, iter [00580, 01251], lr: 0.000049, loss: 0.0870
2022-10-05 08:48:43 - train: epoch 0084, iter [00590, 01251], lr: 0.000049, loss: 0.0851
2022-10-05 08:49:11 - train: epoch 0084, iter [00600, 01251], lr: 0.000049, loss: 0.0780
2022-10-05 08:49:39 - train: epoch 0084, iter [00610, 01251], lr: 0.000048, loss: 0.0808
2022-10-05 08:50:08 - train: epoch 0084, iter [00620, 01251], lr: 0.000048, loss: 0.0889
2022-10-05 08:50:36 - train: epoch 0084, iter [00630, 01251], lr: 0.000048, loss: 0.0795
2022-10-05 08:51:04 - train: epoch 0084, iter [00640, 01251], lr: 0.000048, loss: 0.0839
2022-10-05 08:51:32 - train: epoch 0084, iter [00650, 01251], lr: 0.000048, loss: 0.0805
2022-10-05 08:52:00 - train: epoch 0084, iter [00660, 01251], lr: 0.000048, loss: 0.0807
2022-10-05 08:52:28 - train: epoch 0084, iter [00670, 01251], lr: 0.000048, loss: 0.0832
2022-10-05 08:52:56 - train: epoch 0084, iter [00680, 01251], lr: 0.000048, loss: 0.0898
2022-10-05 08:53:25 - train: epoch 0084, iter [00690, 01251], lr: 0.000048, loss: 0.0792
2022-10-05 08:53:53 - train: epoch 0084, iter [00700, 01251], lr: 0.000048, loss: 0.0820
2022-10-05 08:54:21 - train: epoch 0084, iter [00710, 01251], lr: 0.000048, loss: 0.0830
2022-10-05 08:54:49 - train: epoch 0084, iter [00720, 01251], lr: 0.000048, loss: 0.0793
2022-10-05 08:55:17 - train: epoch 0084, iter [00730, 01251], lr: 0.000048, loss: 0.0895
2022-10-05 08:55:45 - train: epoch 0084, iter [00740, 01251], lr: 0.000048, loss: 0.0822
2022-10-05 08:56:13 - train: epoch 0084, iter [00750, 01251], lr: 0.000048, loss: 0.0819
2022-10-05 08:56:41 - train: epoch 0084, iter [00760, 01251], lr: 0.000048, loss: 0.0824
2022-10-05 08:57:09 - train: epoch 0084, iter [00770, 01251], lr: 0.000048, loss: 0.0888
2022-10-05 08:57:38 - train: epoch 0084, iter [00780, 01251], lr: 0.000048, loss: 0.0843
2022-10-05 08:58:06 - train: epoch 0084, iter [00790, 01251], lr: 0.000048, loss: 0.0788
2022-10-05 08:58:34 - train: epoch 0084, iter [00800, 01251], lr: 0.000048, loss: 0.0826
2022-10-05 08:59:02 - train: epoch 0084, iter [00810, 01251], lr: 0.000048, loss: 0.0826
2022-10-05 08:59:30 - train: epoch 0084, iter [00820, 01251], lr: 0.000048, loss: 0.0896
2022-10-05 08:59:59 - train: epoch 0084, iter [00830, 01251], lr: 0.000047, loss: 0.0800
2022-10-05 09:00:27 - train: epoch 0084, iter [00840, 01251], lr: 0.000047, loss: 0.0759
2022-10-05 09:00:55 - train: epoch 0084, iter [00850, 01251], lr: 0.000047, loss: 0.0828
2022-10-05 09:01:23 - train: epoch 0084, iter [00860, 01251], lr: 0.000047, loss: 0.0784
2022-10-05 09:01:51 - train: epoch 0084, iter [00870, 01251], lr: 0.000047, loss: 0.0746
2022-10-05 09:02:19 - train: epoch 0084, iter [00880, 01251], lr: 0.000047, loss: 0.0867
2022-10-05 09:02:47 - train: epoch 0084, iter [00890, 01251], lr: 0.000047, loss: 0.0833
2022-10-05 09:03:15 - train: epoch 0084, iter [00900, 01251], lr: 0.000047, loss: 0.0760
2022-10-05 09:03:43 - train: epoch 0084, iter [00910, 01251], lr: 0.000047, loss: 0.0857
2022-10-05 09:04:11 - train: epoch 0084, iter [00920, 01251], lr: 0.000047, loss: 0.0798
2022-10-05 09:04:39 - train: epoch 0084, iter [00930, 01251], lr: 0.000047, loss: 0.0849
2022-10-05 09:05:07 - train: epoch 0084, iter [00940, 01251], lr: 0.000047, loss: 0.0788
2022-10-05 09:05:35 - train: epoch 0084, iter [00950, 01251], lr: 0.000047, loss: 0.0803
2022-10-05 09:06:03 - train: epoch 0084, iter [00960, 01251], lr: 0.000047, loss: 0.0900
2022-10-05 09:06:31 - train: epoch 0084, iter [00970, 01251], lr: 0.000047, loss: 0.0773
2022-10-05 09:06:59 - train: epoch 0084, iter [00980, 01251], lr: 0.000047, loss: 0.0820
2022-10-05 09:07:27 - train: epoch 0084, iter [00990, 01251], lr: 0.000047, loss: 0.0794
2022-10-05 09:07:55 - train: epoch 0084, iter [01000, 01251], lr: 0.000047, loss: 0.0746
2022-10-05 09:08:23 - train: epoch 0084, iter [01010, 01251], lr: 0.000047, loss: 0.0837
2022-10-05 09:08:51 - train: epoch 0084, iter [01020, 01251], lr: 0.000047, loss: 0.0822
2022-10-05 09:09:20 - train: epoch 0084, iter [01030, 01251], lr: 0.000047, loss: 0.0758
2022-10-05 09:09:48 - train: epoch 0084, iter [01040, 01251], lr: 0.000047, loss: 0.0777
2022-10-05 09:10:16 - train: epoch 0084, iter [01050, 01251], lr: 0.000046, loss: 0.0801
2022-10-05 09:10:44 - train: epoch 0084, iter [01060, 01251], lr: 0.000046, loss: 0.0849
2022-10-05 09:11:12 - train: epoch 0084, iter [01070, 01251], lr: 0.000046, loss: 0.0871
2022-10-05 09:11:40 - train: epoch 0084, iter [01080, 01251], lr: 0.000046, loss: 0.0776
2022-10-05 09:12:08 - train: epoch 0084, iter [01090, 01251], lr: 0.000046, loss: 0.0827
2022-10-05 09:12:36 - train: epoch 0084, iter [01100, 01251], lr: 0.000046, loss: 0.0816
2022-10-05 09:13:04 - train: epoch 0084, iter [01110, 01251], lr: 0.000046, loss: 0.0773
2022-10-05 09:13:32 - train: epoch 0084, iter [01120, 01251], lr: 0.000046, loss: 0.0820
2022-10-05 09:14:00 - train: epoch 0084, iter [01130, 01251], lr: 0.000046, loss: 0.0822
2022-10-05 09:14:28 - train: epoch 0084, iter [01140, 01251], lr: 0.000046, loss: 0.0836
2022-10-05 09:14:56 - train: epoch 0084, iter [01150, 01251], lr: 0.000046, loss: 0.0835
2022-10-05 09:15:24 - train: epoch 0084, iter [01160, 01251], lr: 0.000046, loss: 0.0775
2022-10-05 09:15:52 - train: epoch 0084, iter [01170, 01251], lr: 0.000046, loss: 0.0800
2022-10-05 09:16:20 - train: epoch 0084, iter [01180, 01251], lr: 0.000046, loss: 0.0750
2022-10-05 09:16:48 - train: epoch 0084, iter [01190, 01251], lr: 0.000046, loss: 0.0834
2022-10-05 09:17:16 - train: epoch 0084, iter [01200, 01251], lr: 0.000046, loss: 0.0842
2022-10-05 09:17:44 - train: epoch 0084, iter [01210, 01251], lr: 0.000046, loss: 0.0819
2022-10-05 09:18:12 - train: epoch 0084, iter [01220, 01251], lr: 0.000046, loss: 0.0843
2022-10-05 09:18:40 - train: epoch 0084, iter [01230, 01251], lr: 0.000046, loss: 0.0775
2022-10-05 09:19:08 - train: epoch 0084, iter [01240, 01251], lr: 0.000046, loss: 0.0803
2022-10-05 09:19:36 - train: epoch 0084, iter [01250, 01251], lr: 0.000046, loss: 0.0744
2022-10-05 09:19:41 - train: epoch 084, train_loss: 0.0822
2022-10-05 09:19:43 - until epoch: 084, best_loss: 0.0822
2022-10-05 09:19:43 - epoch 085 lr: 0.000046
2022-10-05 09:20:17 - train: epoch 0085, iter [00010, 01251], lr: 0.000046, loss: 0.0848
2022-10-05 09:20:45 - train: epoch 0085, iter [00020, 01251], lr: 0.000045, loss: 0.0829
2022-10-05 09:21:13 - train: epoch 0085, iter [00030, 01251], lr: 0.000045, loss: 0.0821
2022-10-05 09:21:41 - train: epoch 0085, iter [00040, 01251], lr: 0.000045, loss: 0.0787
2022-10-05 09:22:09 - train: epoch 0085, iter [00050, 01251], lr: 0.000045, loss: 0.0826
2022-10-05 09:22:37 - train: epoch 0085, iter [00060, 01251], lr: 0.000045, loss: 0.0853
2022-10-05 09:23:05 - train: epoch 0085, iter [00070, 01251], lr: 0.000045, loss: 0.0783
2022-10-05 09:23:33 - train: epoch 0085, iter [00080, 01251], lr: 0.000045, loss: 0.0812
2022-10-05 09:24:01 - train: epoch 0085, iter [00090, 01251], lr: 0.000045, loss: 0.0822
2022-10-05 09:24:29 - train: epoch 0085, iter [00100, 01251], lr: 0.000045, loss: 0.0801
2022-10-05 09:24:57 - train: epoch 0085, iter [00110, 01251], lr: 0.000045, loss: 0.0871
2022-10-05 09:25:25 - train: epoch 0085, iter [00120, 01251], lr: 0.000045, loss: 0.0850
2022-10-05 09:25:53 - train: epoch 0085, iter [00130, 01251], lr: 0.000045, loss: 0.0784
2022-10-05 09:26:22 - train: epoch 0085, iter [00140, 01251], lr: 0.000045, loss: 0.0799
2022-10-05 09:26:50 - train: epoch 0085, iter [00150, 01251], lr: 0.000045, loss: 0.0792
2022-10-05 09:27:18 - train: epoch 0085, iter [00160, 01251], lr: 0.000045, loss: 0.0797
2022-10-05 09:27:46 - train: epoch 0085, iter [00170, 01251], lr: 0.000045, loss: 0.0859
2022-10-05 09:28:14 - train: epoch 0085, iter [00180, 01251], lr: 0.000045, loss: 0.0863
2022-10-05 09:28:42 - train: epoch 0085, iter [00190, 01251], lr: 0.000045, loss: 0.0811
2022-10-05 09:29:10 - train: epoch 0085, iter [00200, 01251], lr: 0.000045, loss: 0.0918
2022-10-05 09:29:38 - train: epoch 0085, iter [00210, 01251], lr: 0.000045, loss: 0.0870
2022-10-05 09:30:06 - train: epoch 0085, iter [00220, 01251], lr: 0.000045, loss: 0.0788
2022-10-05 09:30:34 - train: epoch 0085, iter [00230, 01251], lr: 0.000045, loss: 0.0818
2022-10-05 09:31:02 - train: epoch 0085, iter [00240, 01251], lr: 0.000045, loss: 0.0813
2022-10-05 09:31:31 - train: epoch 0085, iter [00250, 01251], lr: 0.000044, loss: 0.0814
2022-10-05 09:31:59 - train: epoch 0085, iter [00260, 01251], lr: 0.000044, loss: 0.0862
2022-10-05 09:32:27 - train: epoch 0085, iter [00270, 01251], lr: 0.000044, loss: 0.0827
2022-10-05 09:32:55 - train: epoch 0085, iter [00280, 01251], lr: 0.000044, loss: 0.0796
2022-10-05 09:33:23 - train: epoch 0085, iter [00290, 01251], lr: 0.000044, loss: 0.0791
2022-10-05 09:33:51 - train: epoch 0085, iter [00300, 01251], lr: 0.000044, loss: 0.0909
2022-10-05 09:34:19 - train: epoch 0085, iter [00310, 01251], lr: 0.000044, loss: 0.0800
2022-10-05 09:34:47 - train: epoch 0085, iter [00320, 01251], lr: 0.000044, loss: 0.0829
2022-10-05 09:35:16 - train: epoch 0085, iter [00330, 01251], lr: 0.000044, loss: 0.0785
2022-10-05 09:35:44 - train: epoch 0085, iter [00340, 01251], lr: 0.000044, loss: 0.0821
2022-10-05 09:36:12 - train: epoch 0085, iter [00350, 01251], lr: 0.000044, loss: 0.0852
2022-10-05 09:36:40 - train: epoch 0085, iter [00360, 01251], lr: 0.000044, loss: 0.0833
2022-10-05 09:37:08 - train: epoch 0085, iter [00370, 01251], lr: 0.000044, loss: 0.0852
2022-10-05 09:37:36 - train: epoch 0085, iter [00380, 01251], lr: 0.000044, loss: 0.0753
2022-10-05 09:38:05 - train: epoch 0085, iter [00390, 01251], lr: 0.000044, loss: 0.0896
2022-10-05 09:38:32 - train: epoch 0085, iter [00400, 01251], lr: 0.000044, loss: 0.0779
2022-10-05 09:39:01 - train: epoch 0085, iter [00410, 01251], lr: 0.000044, loss: 0.0796
2022-10-05 09:39:29 - train: epoch 0085, iter [00420, 01251], lr: 0.000044, loss: 0.0872
2022-10-05 09:39:57 - train: epoch 0085, iter [00430, 01251], lr: 0.000044, loss: 0.0803
2022-10-05 09:40:25 - train: epoch 0085, iter [00440, 01251], lr: 0.000044, loss: 0.0830
2022-10-05 09:40:53 - train: epoch 0085, iter [00450, 01251], lr: 0.000044, loss: 0.0813
2022-10-05 09:41:21 - train: epoch 0085, iter [00460, 01251], lr: 0.000044, loss: 0.0893
2022-10-05 09:41:49 - train: epoch 0085, iter [00470, 01251], lr: 0.000044, loss: 0.0865
2022-10-05 09:42:17 - train: epoch 0085, iter [00480, 01251], lr: 0.000043, loss: 0.0840
2022-10-05 09:42:45 - train: epoch 0085, iter [00490, 01251], lr: 0.000043, loss: 0.0760
2022-10-05 09:43:13 - train: epoch 0085, iter [00500, 01251], lr: 0.000043, loss: 0.0772
2022-10-05 09:43:41 - train: epoch 0085, iter [00510, 01251], lr: 0.000043, loss: 0.0883
2022-10-05 09:44:09 - train: epoch 0085, iter [00520, 01251], lr: 0.000043, loss: 0.0835
2022-10-05 09:44:37 - train: epoch 0085, iter [00530, 01251], lr: 0.000043, loss: 0.0900
2022-10-05 09:45:06 - train: epoch 0085, iter [00540, 01251], lr: 0.000043, loss: 0.0785
2022-10-05 09:45:34 - train: epoch 0085, iter [00550, 01251], lr: 0.000043, loss: 0.0842
2022-10-05 09:46:02 - train: epoch 0085, iter [00560, 01251], lr: 0.000043, loss: 0.0794
2022-10-05 09:46:30 - train: epoch 0085, iter [00570, 01251], lr: 0.000043, loss: 0.0846
2022-10-05 09:46:58 - train: epoch 0085, iter [00580, 01251], lr: 0.000043, loss: 0.0900
2022-10-05 09:47:26 - train: epoch 0085, iter [00590, 01251], lr: 0.000043, loss: 0.0860
2022-10-05 09:47:54 - train: epoch 0085, iter [00600, 01251], lr: 0.000043, loss: 0.0733
2022-10-05 09:48:22 - train: epoch 0085, iter [00610, 01251], lr: 0.000043, loss: 0.0820
2022-10-05 09:48:50 - train: epoch 0085, iter [00620, 01251], lr: 0.000043, loss: 0.0775
2022-10-05 09:49:18 - train: epoch 0085, iter [00630, 01251], lr: 0.000043, loss: 0.0788
2022-10-05 09:49:46 - train: epoch 0085, iter [00640, 01251], lr: 0.000043, loss: 0.0926
2022-10-05 09:50:14 - train: epoch 0085, iter [00650, 01251], lr: 0.000043, loss: 0.0841
2022-10-05 09:50:43 - train: epoch 0085, iter [00660, 01251], lr: 0.000043, loss: 0.0924
2022-10-05 09:51:10 - train: epoch 0085, iter [00670, 01251], lr: 0.000043, loss: 0.0838
2022-10-05 09:51:39 - train: epoch 0085, iter [00680, 01251], lr: 0.000043, loss: 0.0808
2022-10-05 09:52:07 - train: epoch 0085, iter [00690, 01251], lr: 0.000043, loss: 0.0747
2022-10-05 09:52:35 - train: epoch 0085, iter [00700, 01251], lr: 0.000043, loss: 0.0801
2022-10-05 09:53:03 - train: epoch 0085, iter [00710, 01251], lr: 0.000042, loss: 0.0828
2022-10-05 09:53:31 - train: epoch 0085, iter [00720, 01251], lr: 0.000042, loss: 0.0908
2022-10-05 09:53:59 - train: epoch 0085, iter [00730, 01251], lr: 0.000042, loss: 0.0807
2022-10-05 09:54:27 - train: epoch 0085, iter [00740, 01251], lr: 0.000042, loss: 0.0868
2022-10-05 09:54:56 - train: epoch 0085, iter [00750, 01251], lr: 0.000042, loss: 0.0866
2022-10-05 09:55:24 - train: epoch 0085, iter [00760, 01251], lr: 0.000042, loss: 0.0849
2022-10-05 09:55:52 - train: epoch 0085, iter [00770, 01251], lr: 0.000042, loss: 0.0827
2022-10-05 09:56:20 - train: epoch 0085, iter [00780, 01251], lr: 0.000042, loss: 0.0825
2022-10-05 09:56:48 - train: epoch 0085, iter [00790, 01251], lr: 0.000042, loss: 0.0821
2022-10-05 09:57:16 - train: epoch 0085, iter [00800, 01251], lr: 0.000042, loss: 0.0820
2022-10-05 09:57:44 - train: epoch 0085, iter [00810, 01251], lr: 0.000042, loss: 0.0810
2022-10-05 09:58:12 - train: epoch 0085, iter [00820, 01251], lr: 0.000042, loss: 0.0817
2022-10-05 09:58:40 - train: epoch 0085, iter [00830, 01251], lr: 0.000042, loss: 0.0832
2022-10-05 09:59:08 - train: epoch 0085, iter [00840, 01251], lr: 0.000042, loss: 0.0713
2022-10-05 09:59:36 - train: epoch 0085, iter [00850, 01251], lr: 0.000042, loss: 0.0719
2022-10-05 10:00:04 - train: epoch 0085, iter [00860, 01251], lr: 0.000042, loss: 0.0781
2022-10-05 10:00:32 - train: epoch 0085, iter [00870, 01251], lr: 0.000042, loss: 0.0801
2022-10-05 10:01:00 - train: epoch 0085, iter [00880, 01251], lr: 0.000042, loss: 0.0797
2022-10-05 10:01:28 - train: epoch 0085, iter [00890, 01251], lr: 0.000042, loss: 0.0838
2022-10-05 10:01:56 - train: epoch 0085, iter [00900, 01251], lr: 0.000042, loss: 0.0767
2022-10-05 10:02:24 - train: epoch 0085, iter [00910, 01251], lr: 0.000042, loss: 0.0776
2022-10-05 10:02:52 - train: epoch 0085, iter [00920, 01251], lr: 0.000042, loss: 0.0811
2022-10-05 10:03:21 - train: epoch 0085, iter [00930, 01251], lr: 0.000042, loss: 0.0834
2022-10-05 10:03:49 - train: epoch 0085, iter [00940, 01251], lr: 0.000042, loss: 0.0813
2022-10-05 10:04:17 - train: epoch 0085, iter [00950, 01251], lr: 0.000041, loss: 0.0848
2022-10-05 10:04:45 - train: epoch 0085, iter [00960, 01251], lr: 0.000041, loss: 0.0768
2022-10-05 10:05:13 - train: epoch 0085, iter [00970, 01251], lr: 0.000041, loss: 0.0738
2022-10-05 10:05:41 - train: epoch 0085, iter [00980, 01251], lr: 0.000041, loss: 0.0807
2022-10-05 10:06:09 - train: epoch 0085, iter [00990, 01251], lr: 0.000041, loss: 0.0892
2022-10-05 10:06:37 - train: epoch 0085, iter [01000, 01251], lr: 0.000041, loss: 0.0826
2022-10-05 10:07:05 - train: epoch 0085, iter [01010, 01251], lr: 0.000041, loss: 0.0832
2022-10-05 10:07:33 - train: epoch 0085, iter [01020, 01251], lr: 0.000041, loss: 0.0865
2022-10-05 10:08:01 - train: epoch 0085, iter [01030, 01251], lr: 0.000041, loss: 0.0794
2022-10-05 10:08:29 - train: epoch 0085, iter [01040, 01251], lr: 0.000041, loss: 0.0815
2022-10-05 10:08:57 - train: epoch 0085, iter [01050, 01251], lr: 0.000041, loss: 0.0865
2022-10-05 10:09:25 - train: epoch 0085, iter [01060, 01251], lr: 0.000041, loss: 0.0887
2022-10-05 10:09:53 - train: epoch 0085, iter [01070, 01251], lr: 0.000041, loss: 0.0801
2022-10-05 10:10:21 - train: epoch 0085, iter [01080, 01251], lr: 0.000041, loss: 0.0774
2022-10-05 10:10:50 - train: epoch 0085, iter [01090, 01251], lr: 0.000041, loss: 0.0880
2022-10-05 10:11:18 - train: epoch 0085, iter [01100, 01251], lr: 0.000041, loss: 0.0783
2022-10-05 10:11:46 - train: epoch 0085, iter [01110, 01251], lr: 0.000041, loss: 0.0748
2022-10-05 10:12:14 - train: epoch 0085, iter [01120, 01251], lr: 0.000041, loss: 0.0836
2022-10-05 10:12:42 - train: epoch 0085, iter [01130, 01251], lr: 0.000041, loss: 0.0815
2022-10-05 10:13:10 - train: epoch 0085, iter [01140, 01251], lr: 0.000041, loss: 0.0799
2022-10-05 10:13:38 - train: epoch 0085, iter [01150, 01251], lr: 0.000041, loss: 0.0872
2022-10-05 10:14:06 - train: epoch 0085, iter [01160, 01251], lr: 0.000041, loss: 0.0836
2022-10-05 10:14:34 - train: epoch 0085, iter [01170, 01251], lr: 0.000041, loss: 0.0815
2022-10-05 10:15:02 - train: epoch 0085, iter [01180, 01251], lr: 0.000040, loss: 0.0807
2022-10-05 10:15:30 - train: epoch 0085, iter [01190, 01251], lr: 0.000040, loss: 0.0897
2022-10-05 10:15:58 - train: epoch 0085, iter [01200, 01251], lr: 0.000040, loss: 0.0873
2022-10-05 10:16:26 - train: epoch 0085, iter [01210, 01251], lr: 0.000040, loss: 0.0860
2022-10-05 10:16:54 - train: epoch 0085, iter [01220, 01251], lr: 0.000040, loss: 0.0832
2022-10-05 10:17:23 - train: epoch 0085, iter [01230, 01251], lr: 0.000040, loss: 0.0774
2022-10-05 10:17:51 - train: epoch 0085, iter [01240, 01251], lr: 0.000040, loss: 0.0866
2022-10-05 10:18:18 - train: epoch 0085, iter [01250, 01251], lr: 0.000040, loss: 0.0756
2022-10-05 10:18:23 - train: epoch 085, train_loss: 0.0821
2022-10-05 10:18:25 - until epoch: 085, best_loss: 0.0821
2022-10-05 10:18:25 - epoch 086 lr: 0.000040
2022-10-05 10:19:00 - train: epoch 0086, iter [00010, 01251], lr: 0.000040, loss: 0.0784
2022-10-05 10:19:28 - train: epoch 0086, iter [00020, 01251], lr: 0.000040, loss: 0.0792
2022-10-05 10:19:57 - train: epoch 0086, iter [00030, 01251], lr: 0.000040, loss: 0.0798
2022-10-05 10:20:25 - train: epoch 0086, iter [00040, 01251], lr: 0.000040, loss: 0.0838
2022-10-05 10:20:53 - train: epoch 0086, iter [00050, 01251], lr: 0.000040, loss: 0.0836
2022-10-05 10:21:21 - train: epoch 0086, iter [00060, 01251], lr: 0.000040, loss: 0.0816
2022-10-05 10:21:49 - train: epoch 0086, iter [00070, 01251], lr: 0.000040, loss: 0.0858
2022-10-05 10:22:16 - train: epoch 0086, iter [00080, 01251], lr: 0.000040, loss: 0.0830
2022-10-05 10:22:44 - train: epoch 0086, iter [00090, 01251], lr: 0.000040, loss: 0.0767
2022-10-05 10:23:12 - train: epoch 0086, iter [00100, 01251], lr: 0.000040, loss: 0.0777
2022-10-05 10:23:40 - train: epoch 0086, iter [00110, 01251], lr: 0.000040, loss: 0.0823
2022-10-05 10:24:08 - train: epoch 0086, iter [00120, 01251], lr: 0.000040, loss: 0.0848
2022-10-05 10:24:36 - train: epoch 0086, iter [00130, 01251], lr: 0.000040, loss: 0.0805
2022-10-05 10:25:04 - train: epoch 0086, iter [00140, 01251], lr: 0.000040, loss: 0.0799
2022-10-05 10:25:32 - train: epoch 0086, iter [00150, 01251], lr: 0.000040, loss: 0.0793
2022-10-05 10:26:00 - train: epoch 0086, iter [00160, 01251], lr: 0.000040, loss: 0.0865
2022-10-05 10:26:28 - train: epoch 0086, iter [00170, 01251], lr: 0.000039, loss: 0.0790
2022-10-05 10:26:56 - train: epoch 0086, iter [00180, 01251], lr: 0.000039, loss: 0.0878
2022-10-05 10:27:24 - train: epoch 0086, iter [00190, 01251], lr: 0.000039, loss: 0.0756
2022-10-05 10:27:52 - train: epoch 0086, iter [00200, 01251], lr: 0.000039, loss: 0.0876
2022-10-05 10:28:19 - train: epoch 0086, iter [00210, 01251], lr: 0.000039, loss: 0.0839
2022-10-05 10:28:47 - train: epoch 0086, iter [00220, 01251], lr: 0.000039, loss: 0.0791
2022-10-05 10:29:15 - train: epoch 0086, iter [00230, 01251], lr: 0.000039, loss: 0.0865
2022-10-05 10:29:43 - train: epoch 0086, iter [00240, 01251], lr: 0.000039, loss: 0.0774
2022-10-05 10:30:11 - train: epoch 0086, iter [00250, 01251], lr: 0.000039, loss: 0.0859
2022-10-05 10:30:39 - train: epoch 0086, iter [00260, 01251], lr: 0.000039, loss: 0.0819
2022-10-05 10:31:07 - train: epoch 0086, iter [00270, 01251], lr: 0.000039, loss: 0.0759
2022-10-05 10:31:35 - train: epoch 0086, iter [00280, 01251], lr: 0.000039, loss: 0.0883
2022-10-05 10:32:03 - train: epoch 0086, iter [00290, 01251], lr: 0.000039, loss: 0.0876
2022-10-05 10:32:32 - train: epoch 0086, iter [00300, 01251], lr: 0.000039, loss: 0.0882
2022-10-05 10:32:59 - train: epoch 0086, iter [00310, 01251], lr: 0.000039, loss: 0.0920
2022-10-05 10:33:27 - train: epoch 0086, iter [00320, 01251], lr: 0.000039, loss: 0.0759
2022-10-05 10:33:55 - train: epoch 0086, iter [00330, 01251], lr: 0.000039, loss: 0.0810
2022-10-05 10:34:24 - train: epoch 0086, iter [00340, 01251], lr: 0.000039, loss: 0.0850
2022-10-05 10:34:51 - train: epoch 0086, iter [00350, 01251], lr: 0.000039, loss: 0.0756
2022-10-05 10:35:19 - train: epoch 0086, iter [00360, 01251], lr: 0.000039, loss: 0.0824
2022-10-05 10:35:47 - train: epoch 0086, iter [00370, 01251], lr: 0.000039, loss: 0.0868
2022-10-05 10:36:15 - train: epoch 0086, iter [00380, 01251], lr: 0.000039, loss: 0.0845
2022-10-05 10:36:43 - train: epoch 0086, iter [00390, 01251], lr: 0.000039, loss: 0.0876
2022-10-05 10:37:12 - train: epoch 0086, iter [00400, 01251], lr: 0.000039, loss: 0.0801
2022-10-05 10:37:39 - train: epoch 0086, iter [00410, 01251], lr: 0.000038, loss: 0.0775
2022-10-05 10:38:08 - train: epoch 0086, iter [00420, 01251], lr: 0.000038, loss: 0.0809
2022-10-05 10:38:35 - train: epoch 0086, iter [00430, 01251], lr: 0.000038, loss: 0.0808
2022-10-05 10:39:03 - train: epoch 0086, iter [00440, 01251], lr: 0.000038, loss: 0.0809
2022-10-05 10:39:31 - train: epoch 0086, iter [00450, 01251], lr: 0.000038, loss: 0.0810
2022-10-05 10:39:59 - train: epoch 0086, iter [00460, 01251], lr: 0.000038, loss: 0.0798
2022-10-05 10:40:27 - train: epoch 0086, iter [00470, 01251], lr: 0.000038, loss: 0.0747
2022-10-05 10:40:55 - train: epoch 0086, iter [00480, 01251], lr: 0.000038, loss: 0.0796
2022-10-05 10:41:23 - train: epoch 0086, iter [00490, 01251], lr: 0.000038, loss: 0.0784
2022-10-05 10:41:51 - train: epoch 0086, iter [00500, 01251], lr: 0.000038, loss: 0.0787
2022-10-05 10:42:19 - train: epoch 0086, iter [00510, 01251], lr: 0.000038, loss: 0.0829
2022-10-05 10:42:47 - train: epoch 0086, iter [00520, 01251], lr: 0.000038, loss: 0.0818
2022-10-05 10:43:15 - train: epoch 0086, iter [00530, 01251], lr: 0.000038, loss: 0.0782
2022-10-05 10:43:43 - train: epoch 0086, iter [00540, 01251], lr: 0.000038, loss: 0.0848
2022-10-05 10:44:11 - train: epoch 0086, iter [00550, 01251], lr: 0.000038, loss: 0.0760
2022-10-05 10:44:39 - train: epoch 0086, iter [00560, 01251], lr: 0.000038, loss: 0.0896
2022-10-05 10:45:07 - train: epoch 0086, iter [00570, 01251], lr: 0.000038, loss: 0.0802
2022-10-05 10:45:35 - train: epoch 0086, iter [00580, 01251], lr: 0.000038, loss: 0.0783
2022-10-05 10:46:03 - train: epoch 0086, iter [00590, 01251], lr: 0.000038, loss: 0.0761
2022-10-05 10:46:31 - train: epoch 0086, iter [00600, 01251], lr: 0.000038, loss: 0.0810
2022-10-05 10:46:59 - train: epoch 0086, iter [00610, 01251], lr: 0.000038, loss: 0.0780
2022-10-05 10:47:27 - train: epoch 0086, iter [00620, 01251], lr: 0.000038, loss: 0.0886
2022-10-05 10:47:55 - train: epoch 0086, iter [00630, 01251], lr: 0.000038, loss: 0.0859
2022-10-05 10:48:23 - train: epoch 0086, iter [00640, 01251], lr: 0.000038, loss: 0.0881
2022-10-05 10:48:51 - train: epoch 0086, iter [00650, 01251], lr: 0.000038, loss: 0.0840
2022-10-05 10:49:19 - train: epoch 0086, iter [00660, 01251], lr: 0.000037, loss: 0.0889
2022-10-05 10:49:47 - train: epoch 0086, iter [00670, 01251], lr: 0.000037, loss: 0.0835
2022-10-05 10:50:15 - train: epoch 0086, iter [00680, 01251], lr: 0.000037, loss: 0.0794
2022-10-05 10:50:43 - train: epoch 0086, iter [00690, 01251], lr: 0.000037, loss: 0.0788
2022-10-05 10:51:11 - train: epoch 0086, iter [00700, 01251], lr: 0.000037, loss: 0.0879
2022-10-05 10:51:40 - train: epoch 0086, iter [00710, 01251], lr: 0.000037, loss: 0.0822
2022-10-05 10:52:07 - train: epoch 0086, iter [00720, 01251], lr: 0.000037, loss: 0.0837
2022-10-05 10:52:36 - train: epoch 0086, iter [00730, 01251], lr: 0.000037, loss: 0.0735
2022-10-05 10:53:04 - train: epoch 0086, iter [00740, 01251], lr: 0.000037, loss: 0.0806
2022-10-05 10:53:32 - train: epoch 0086, iter [00750, 01251], lr: 0.000037, loss: 0.0803
2022-10-05 10:53:59 - train: epoch 0086, iter [00760, 01251], lr: 0.000037, loss: 0.0808
2022-10-05 10:54:27 - train: epoch 0086, iter [00770, 01251], lr: 0.000037, loss: 0.0811
2022-10-05 10:54:56 - train: epoch 0086, iter [00780, 01251], lr: 0.000037, loss: 0.0811
2022-10-05 10:55:24 - train: epoch 0086, iter [00790, 01251], lr: 0.000037, loss: 0.0811
2022-10-05 10:55:52 - train: epoch 0086, iter [00800, 01251], lr: 0.000037, loss: 0.0746
2022-10-05 10:56:20 - train: epoch 0086, iter [00810, 01251], lr: 0.000037, loss: 0.0813
2022-10-05 10:56:48 - train: epoch 0086, iter [00820, 01251], lr: 0.000037, loss: 0.0808
2022-10-05 10:57:16 - train: epoch 0086, iter [00830, 01251], lr: 0.000037, loss: 0.0777
2022-10-05 10:57:43 - train: epoch 0086, iter [00840, 01251], lr: 0.000037, loss: 0.0841
2022-10-05 10:58:12 - train: epoch 0086, iter [00850, 01251], lr: 0.000037, loss: 0.0840
2022-10-05 10:58:40 - train: epoch 0086, iter [00860, 01251], lr: 0.000037, loss: 0.0806
2022-10-05 10:59:08 - train: epoch 0086, iter [00870, 01251], lr: 0.000037, loss: 0.0818
2022-10-05 10:59:36 - train: epoch 0086, iter [00880, 01251], lr: 0.000037, loss: 0.0828
2022-10-05 11:00:04 - train: epoch 0086, iter [00890, 01251], lr: 0.000037, loss: 0.0864
2022-10-05 11:00:31 - train: epoch 0086, iter [00900, 01251], lr: 0.000037, loss: 0.0841
2022-10-05 11:00:59 - train: epoch 0086, iter [00910, 01251], lr: 0.000036, loss: 0.0764
2022-10-05 11:01:28 - train: epoch 0086, iter [00920, 01251], lr: 0.000036, loss: 0.0800
2022-10-05 11:01:55 - train: epoch 0086, iter [00930, 01251], lr: 0.000036, loss: 0.0789
2022-10-05 11:02:24 - train: epoch 0086, iter [00940, 01251], lr: 0.000036, loss: 0.0838
2022-10-05 11:02:52 - train: epoch 0086, iter [00950, 01251], lr: 0.000036, loss: 0.0822
2022-10-05 11:03:20 - train: epoch 0086, iter [00960, 01251], lr: 0.000036, loss: 0.0852
2022-10-05 11:03:48 - train: epoch 0086, iter [00970, 01251], lr: 0.000036, loss: 0.0816
2022-10-05 11:04:16 - train: epoch 0086, iter [00980, 01251], lr: 0.000036, loss: 0.0822
2022-10-05 11:04:44 - train: epoch 0086, iter [00990, 01251], lr: 0.000036, loss: 0.0834
2022-10-05 11:05:12 - train: epoch 0086, iter [01000, 01251], lr: 0.000036, loss: 0.0907
2022-10-05 11:05:40 - train: epoch 0086, iter [01010, 01251], lr: 0.000036, loss: 0.0817
2022-10-05 11:06:08 - train: epoch 0086, iter [01020, 01251], lr: 0.000036, loss: 0.0891
2022-10-05 11:06:36 - train: epoch 0086, iter [01030, 01251], lr: 0.000036, loss: 0.0834
2022-10-05 11:07:04 - train: epoch 0086, iter [01040, 01251], lr: 0.000036, loss: 0.0854
2022-10-05 11:07:32 - train: epoch 0086, iter [01050, 01251], lr: 0.000036, loss: 0.0776
2022-10-05 11:08:00 - train: epoch 0086, iter [01060, 01251], lr: 0.000036, loss: 0.0760
2022-10-05 11:08:28 - train: epoch 0086, iter [01070, 01251], lr: 0.000036, loss: 0.0845
2022-10-05 11:08:56 - train: epoch 0086, iter [01080, 01251], lr: 0.000036, loss: 0.0761
2022-10-05 11:09:24 - train: epoch 0086, iter [01090, 01251], lr: 0.000036, loss: 0.0849
2022-10-05 11:09:52 - train: epoch 0086, iter [01100, 01251], lr: 0.000036, loss: 0.0852
2022-10-05 11:10:20 - train: epoch 0086, iter [01110, 01251], lr: 0.000036, loss: 0.0831
2022-10-05 11:10:48 - train: epoch 0086, iter [01120, 01251], lr: 0.000036, loss: 0.0856
2022-10-05 11:11:16 - train: epoch 0086, iter [01130, 01251], lr: 0.000036, loss: 0.0885
2022-10-05 11:11:43 - train: epoch 0086, iter [01140, 01251], lr: 0.000036, loss: 0.0795
2022-10-05 11:12:11 - train: epoch 0086, iter [01150, 01251], lr: 0.000036, loss: 0.0809
2022-10-05 11:12:39 - train: epoch 0086, iter [01160, 01251], lr: 0.000035, loss: 0.0872
2022-10-05 11:13:07 - train: epoch 0086, iter [01170, 01251], lr: 0.000035, loss: 0.0751
2022-10-05 11:13:35 - train: epoch 0086, iter [01180, 01251], lr: 0.000035, loss: 0.0882
2022-10-05 11:14:04 - train: epoch 0086, iter [01190, 01251], lr: 0.000035, loss: 0.0797
2022-10-05 11:14:32 - train: epoch 0086, iter [01200, 01251], lr: 0.000035, loss: 0.0797
2022-10-05 11:15:00 - train: epoch 0086, iter [01210, 01251], lr: 0.000035, loss: 0.0829
2022-10-05 11:15:28 - train: epoch 0086, iter [01220, 01251], lr: 0.000035, loss: 0.0800
2022-10-05 11:15:56 - train: epoch 0086, iter [01230, 01251], lr: 0.000035, loss: 0.0814
2022-10-05 11:16:24 - train: epoch 0086, iter [01240, 01251], lr: 0.000035, loss: 0.0778
2022-10-05 11:16:51 - train: epoch 0086, iter [01250, 01251], lr: 0.000035, loss: 0.0785
2022-10-05 11:16:56 - train: epoch 086, train_loss: 0.0819
2022-10-05 11:16:57 - until epoch: 086, best_loss: 0.0819
2022-10-05 11:16:57 - epoch 087 lr: 0.000035
2022-10-05 11:17:32 - train: epoch 0087, iter [00010, 01251], lr: 0.000035, loss: 0.0745
2022-10-05 11:18:00 - train: epoch 0087, iter [00020, 01251], lr: 0.000035, loss: 0.0808
2022-10-05 11:18:28 - train: epoch 0087, iter [00030, 01251], lr: 0.000035, loss: 0.0914
2022-10-05 11:18:56 - train: epoch 0087, iter [00040, 01251], lr: 0.000035, loss: 0.0776
2022-10-05 11:19:24 - train: epoch 0087, iter [00050, 01251], lr: 0.000035, loss: 0.0885
2022-10-05 11:19:52 - train: epoch 0087, iter [00060, 01251], lr: 0.000035, loss: 0.0743
2022-10-05 11:20:20 - train: epoch 0087, iter [00070, 01251], lr: 0.000035, loss: 0.0834
2022-10-05 11:20:48 - train: epoch 0087, iter [00080, 01251], lr: 0.000035, loss: 0.0874
2022-10-05 11:21:16 - train: epoch 0087, iter [00090, 01251], lr: 0.000035, loss: 0.0760
2022-10-05 11:21:44 - train: epoch 0087, iter [00100, 01251], lr: 0.000035, loss: 0.0852
2022-10-05 11:22:12 - train: epoch 0087, iter [00110, 01251], lr: 0.000035, loss: 0.0810
2022-10-05 11:22:40 - train: epoch 0087, iter [00120, 01251], lr: 0.000035, loss: 0.0886
2022-10-05 11:23:08 - train: epoch 0087, iter [00130, 01251], lr: 0.000035, loss: 0.0802
2022-10-05 11:23:36 - train: epoch 0087, iter [00140, 01251], lr: 0.000035, loss: 0.0864
2022-10-05 11:24:04 - train: epoch 0087, iter [00150, 01251], lr: 0.000035, loss: 0.0847
2022-10-05 11:24:32 - train: epoch 0087, iter [00160, 01251], lr: 0.000034, loss: 0.0779
2022-10-05 11:25:00 - train: epoch 0087, iter [00170, 01251], lr: 0.000034, loss: 0.0828
2022-10-05 11:25:28 - train: epoch 0087, iter [00180, 01251], lr: 0.000034, loss: 0.0786
2022-10-05 11:25:56 - train: epoch 0087, iter [00190, 01251], lr: 0.000034, loss: 0.0863
2022-10-05 11:26:24 - train: epoch 0087, iter [00200, 01251], lr: 0.000034, loss: 0.0766
2022-10-05 11:26:52 - train: epoch 0087, iter [00210, 01251], lr: 0.000034, loss: 0.0846
2022-10-05 11:27:20 - train: epoch 0087, iter [00220, 01251], lr: 0.000034, loss: 0.0835
2022-10-05 11:27:48 - train: epoch 0087, iter [00230, 01251], lr: 0.000034, loss: 0.0856
2022-10-05 11:28:16 - train: epoch 0087, iter [00240, 01251], lr: 0.000034, loss: 0.0829
2022-10-05 11:28:44 - train: epoch 0087, iter [00250, 01251], lr: 0.000034, loss: 0.0830
2022-10-05 11:29:12 - train: epoch 0087, iter [00260, 01251], lr: 0.000034, loss: 0.0765
2022-10-05 11:29:40 - train: epoch 0087, iter [00270, 01251], lr: 0.000034, loss: 0.0791
2022-10-05 11:30:08 - train: epoch 0087, iter [00280, 01251], lr: 0.000034, loss: 0.0818
2022-10-05 11:30:36 - train: epoch 0087, iter [00290, 01251], lr: 0.000034, loss: 0.0747
2022-10-05 11:31:04 - train: epoch 0087, iter [00300, 01251], lr: 0.000034, loss: 0.0820
2022-10-05 11:31:32 - train: epoch 0087, iter [00310, 01251], lr: 0.000034, loss: 0.0790
2022-10-05 11:32:00 - train: epoch 0087, iter [00320, 01251], lr: 0.000034, loss: 0.0817
2022-10-05 11:32:28 - train: epoch 0087, iter [00330, 01251], lr: 0.000034, loss: 0.0882
2022-10-05 11:32:56 - train: epoch 0087, iter [00340, 01251], lr: 0.000034, loss: 0.0864
2022-10-05 11:33:24 - train: epoch 0087, iter [00350, 01251], lr: 0.000034, loss: 0.0909
2022-10-05 11:33:52 - train: epoch 0087, iter [00360, 01251], lr: 0.000034, loss: 0.0782
2022-10-05 11:34:20 - train: epoch 0087, iter [00370, 01251], lr: 0.000034, loss: 0.0752
2022-10-05 11:34:48 - train: epoch 0087, iter [00380, 01251], lr: 0.000034, loss: 0.0820
2022-10-05 11:35:16 - train: epoch 0087, iter [00390, 01251], lr: 0.000034, loss: 0.0838
2022-10-05 11:35:44 - train: epoch 0087, iter [00400, 01251], lr: 0.000034, loss: 0.0807
2022-10-05 11:36:12 - train: epoch 0087, iter [00410, 01251], lr: 0.000034, loss: 0.0724
2022-10-05 11:36:40 - train: epoch 0087, iter [00420, 01251], lr: 0.000033, loss: 0.0800
2022-10-05 11:37:08 - train: epoch 0087, iter [00430, 01251], lr: 0.000033, loss: 0.0788
2022-10-05 11:37:37 - train: epoch 0087, iter [00440, 01251], lr: 0.000033, loss: 0.0872
2022-10-05 11:38:05 - train: epoch 0087, iter [00450, 01251], lr: 0.000033, loss: 0.0821
2022-10-05 11:38:33 - train: epoch 0087, iter [00460, 01251], lr: 0.000033, loss: 0.0854
2022-10-05 11:39:01 - train: epoch 0087, iter [00470, 01251], lr: 0.000033, loss: 0.0798
2022-10-05 11:39:29 - train: epoch 0087, iter [00480, 01251], lr: 0.000033, loss: 0.0748
2022-10-05 11:39:57 - train: epoch 0087, iter [00490, 01251], lr: 0.000033, loss: 0.0834
2022-10-05 11:40:25 - train: epoch 0087, iter [00500, 01251], lr: 0.000033, loss: 0.0806
2022-10-05 11:40:53 - train: epoch 0087, iter [00510, 01251], lr: 0.000033, loss: 0.0788
2022-10-05 11:41:21 - train: epoch 0087, iter [00520, 01251], lr: 0.000033, loss: 0.0738
2022-10-05 11:41:49 - train: epoch 0087, iter [00530, 01251], lr: 0.000033, loss: 0.0852
2022-10-05 11:42:17 - train: epoch 0087, iter [00540, 01251], lr: 0.000033, loss: 0.0766
2022-10-05 11:42:45 - train: epoch 0087, iter [00550, 01251], lr: 0.000033, loss: 0.0765
2022-10-05 11:43:13 - train: epoch 0087, iter [00560, 01251], lr: 0.000033, loss: 0.0803
2022-10-05 11:43:41 - train: epoch 0087, iter [00570, 01251], lr: 0.000033, loss: 0.0856
2022-10-05 11:44:09 - train: epoch 0087, iter [00580, 01251], lr: 0.000033, loss: 0.0835
2022-10-05 11:44:37 - train: epoch 0087, iter [00590, 01251], lr: 0.000033, loss: 0.0898
2022-10-05 11:45:05 - train: epoch 0087, iter [00600, 01251], lr: 0.000033, loss: 0.0834
2022-10-05 11:45:33 - train: epoch 0087, iter [00610, 01251], lr: 0.000033, loss: 0.0854
2022-10-05 11:46:01 - train: epoch 0087, iter [00620, 01251], lr: 0.000033, loss: 0.0819
2022-10-05 11:46:29 - train: epoch 0087, iter [00630, 01251], lr: 0.000033, loss: 0.0781
2022-10-05 11:46:58 - train: epoch 0087, iter [00640, 01251], lr: 0.000033, loss: 0.0815
2022-10-05 11:47:26 - train: epoch 0087, iter [00650, 01251], lr: 0.000033, loss: 0.0769
2022-10-05 11:47:54 - train: epoch 0087, iter [00660, 01251], lr: 0.000033, loss: 0.0842
2022-10-05 11:48:22 - train: epoch 0087, iter [00670, 01251], lr: 0.000033, loss: 0.0810
2022-10-05 11:48:50 - train: epoch 0087, iter [00680, 01251], lr: 0.000032, loss: 0.0810
2022-10-05 11:49:18 - train: epoch 0087, iter [00690, 01251], lr: 0.000032, loss: 0.0797
2022-10-05 11:49:46 - train: epoch 0087, iter [00700, 01251], lr: 0.000032, loss: 0.0791
2022-10-05 11:50:14 - train: epoch 0087, iter [00710, 01251], lr: 0.000032, loss: 0.0790
2022-10-05 11:50:41 - train: epoch 0087, iter [00720, 01251], lr: 0.000032, loss: 0.0794
2022-10-05 11:51:09 - train: epoch 0087, iter [00730, 01251], lr: 0.000032, loss: 0.0806
2022-10-05 11:51:38 - train: epoch 0087, iter [00740, 01251], lr: 0.000032, loss: 0.0751
2022-10-05 11:52:06 - train: epoch 0087, iter [00750, 01251], lr: 0.000032, loss: 0.0766
2022-10-05 11:52:34 - train: epoch 0087, iter [00760, 01251], lr: 0.000032, loss: 0.0918
2022-10-05 11:53:02 - train: epoch 0087, iter [00770, 01251], lr: 0.000032, loss: 0.0840
2022-10-05 11:53:30 - train: epoch 0087, iter [00780, 01251], lr: 0.000032, loss: 0.0733
2022-10-05 11:53:58 - train: epoch 0087, iter [00790, 01251], lr: 0.000032, loss: 0.0747
2022-10-05 11:54:26 - train: epoch 0087, iter [00800, 01251], lr: 0.000032, loss: 0.0812
2022-10-05 11:54:54 - train: epoch 0087, iter [00810, 01251], lr: 0.000032, loss: 0.0857
2022-10-05 11:55:22 - train: epoch 0087, iter [00820, 01251], lr: 0.000032, loss: 0.0797
2022-10-05 11:55:50 - train: epoch 0087, iter [00830, 01251], lr: 0.000032, loss: 0.0826
2022-10-05 11:56:18 - train: epoch 0087, iter [00840, 01251], lr: 0.000032, loss: 0.0825
2022-10-05 11:56:46 - train: epoch 0087, iter [00850, 01251], lr: 0.000032, loss: 0.0854
2022-10-05 11:57:14 - train: epoch 0087, iter [00860, 01251], lr: 0.000032, loss: 0.0831
2022-10-05 11:57:42 - train: epoch 0087, iter [00870, 01251], lr: 0.000032, loss: 0.0813
2022-10-05 11:58:10 - train: epoch 0087, iter [00880, 01251], lr: 0.000032, loss: 0.0816
2022-10-05 11:58:38 - train: epoch 0087, iter [00890, 01251], lr: 0.000032, loss: 0.0829
2022-10-05 11:59:06 - train: epoch 0087, iter [00900, 01251], lr: 0.000032, loss: 0.0899
2022-10-05 11:59:34 - train: epoch 0087, iter [00910, 01251], lr: 0.000032, loss: 0.0775
2022-10-05 12:00:02 - train: epoch 0087, iter [00920, 01251], lr: 0.000032, loss: 0.0809
2022-10-05 12:00:30 - train: epoch 0087, iter [00930, 01251], lr: 0.000032, loss: 0.0831
2022-10-05 12:00:58 - train: epoch 0087, iter [00940, 01251], lr: 0.000032, loss: 0.0817
2022-10-05 12:01:26 - train: epoch 0087, iter [00950, 01251], lr: 0.000031, loss: 0.0847
2022-10-05 12:01:54 - train: epoch 0087, iter [00960, 01251], lr: 0.000031, loss: 0.0831
2022-10-05 12:02:22 - train: epoch 0087, iter [00970, 01251], lr: 0.000031, loss: 0.0700
2022-10-05 12:02:50 - train: epoch 0087, iter [00980, 01251], lr: 0.000031, loss: 0.0816
2022-10-05 12:03:18 - train: epoch 0087, iter [00990, 01251], lr: 0.000031, loss: 0.0839
2022-10-05 12:03:46 - train: epoch 0087, iter [01000, 01251], lr: 0.000031, loss: 0.0885
2022-10-05 12:04:14 - train: epoch 0087, iter [01010, 01251], lr: 0.000031, loss: 0.0801
2022-10-05 12:04:43 - train: epoch 0087, iter [01020, 01251], lr: 0.000031, loss: 0.0734
2022-10-05 12:05:11 - train: epoch 0087, iter [01030, 01251], lr: 0.000031, loss: 0.0824
2022-10-05 12:05:39 - train: epoch 0087, iter [01040, 01251], lr: 0.000031, loss: 0.0838
2022-10-05 12:06:07 - train: epoch 0087, iter [01050, 01251], lr: 0.000031, loss: 0.0913
2022-10-05 12:06:35 - train: epoch 0087, iter [01060, 01251], lr: 0.000031, loss: 0.0777
2022-10-05 12:07:03 - train: epoch 0087, iter [01070, 01251], lr: 0.000031, loss: 0.0767
2022-10-05 12:07:31 - train: epoch 0087, iter [01080, 01251], lr: 0.000031, loss: 0.0817
2022-10-05 12:07:59 - train: epoch 0087, iter [01090, 01251], lr: 0.000031, loss: 0.0771
2022-10-05 12:08:27 - train: epoch 0087, iter [01100, 01251], lr: 0.000031, loss: 0.0780
2022-10-05 12:08:55 - train: epoch 0087, iter [01110, 01251], lr: 0.000031, loss: 0.0880
2022-10-05 12:09:23 - train: epoch 0087, iter [01120, 01251], lr: 0.000031, loss: 0.0799
2022-10-05 12:09:51 - train: epoch 0087, iter [01130, 01251], lr: 0.000031, loss: 0.0802
2022-10-05 12:10:19 - train: epoch 0087, iter [01140, 01251], lr: 0.000031, loss: 0.0843
2022-10-05 12:10:47 - train: epoch 0087, iter [01150, 01251], lr: 0.000031, loss: 0.0843
2022-10-05 12:11:15 - train: epoch 0087, iter [01160, 01251], lr: 0.000031, loss: 0.0870
2022-10-05 12:11:43 - train: epoch 0087, iter [01170, 01251], lr: 0.000031, loss: 0.0785
2022-10-05 12:12:11 - train: epoch 0087, iter [01180, 01251], lr: 0.000031, loss: 0.0870
2022-10-05 12:12:40 - train: epoch 0087, iter [01190, 01251], lr: 0.000031, loss: 0.0933
2022-10-05 12:13:08 - train: epoch 0087, iter [01200, 01251], lr: 0.000031, loss: 0.0867
2022-10-05 12:13:36 - train: epoch 0087, iter [01210, 01251], lr: 0.000031, loss: 0.0788
2022-10-05 12:14:04 - train: epoch 0087, iter [01220, 01251], lr: 0.000030, loss: 0.0727
2022-10-05 12:14:32 - train: epoch 0087, iter [01230, 01251], lr: 0.000030, loss: 0.0782
2022-10-05 12:15:00 - train: epoch 0087, iter [01240, 01251], lr: 0.000030, loss: 0.0781
2022-10-05 12:15:28 - train: epoch 0087, iter [01250, 01251], lr: 0.000030, loss: 0.0806
2022-10-05 12:15:32 - train: epoch 087, train_loss: 0.0817
2022-10-05 12:15:34 - until epoch: 087, best_loss: 0.0817
2022-10-05 12:15:34 - epoch 088 lr: 0.000030
2022-10-05 12:16:10 - train: epoch 0088, iter [00010, 01251], lr: 0.000030, loss: 0.0773
2022-10-05 12:16:38 - train: epoch 0088, iter [00020, 01251], lr: 0.000030, loss: 0.0823
2022-10-05 12:17:06 - train: epoch 0088, iter [00030, 01251], lr: 0.000030, loss: 0.0887
2022-10-05 12:17:34 - train: epoch 0088, iter [00040, 01251], lr: 0.000030, loss: 0.0871
2022-10-05 12:18:02 - train: epoch 0088, iter [00050, 01251], lr: 0.000030, loss: 0.0744
2022-10-05 12:18:29 - train: epoch 0088, iter [00060, 01251], lr: 0.000030, loss: 0.0923
2022-10-05 12:18:57 - train: epoch 0088, iter [00070, 01251], lr: 0.000030, loss: 0.0777
2022-10-05 12:19:25 - train: epoch 0088, iter [00080, 01251], lr: 0.000030, loss: 0.0795
2022-10-05 12:19:53 - train: epoch 0088, iter [00090, 01251], lr: 0.000030, loss: 0.0840
2022-10-05 12:20:21 - train: epoch 0088, iter [00100, 01251], lr: 0.000030, loss: 0.0803
2022-10-05 12:20:49 - train: epoch 0088, iter [00110, 01251], lr: 0.000030, loss: 0.0814
2022-10-05 12:21:17 - train: epoch 0088, iter [00120, 01251], lr: 0.000030, loss: 0.0846
2022-10-05 12:21:45 - train: epoch 0088, iter [00130, 01251], lr: 0.000030, loss: 0.0834
2022-10-05 12:22:13 - train: epoch 0088, iter [00140, 01251], lr: 0.000030, loss: 0.0785
2022-10-05 12:22:41 - train: epoch 0088, iter [00150, 01251], lr: 0.000030, loss: 0.0793
2022-10-05 12:23:09 - train: epoch 0088, iter [00160, 01251], lr: 0.000030, loss: 0.0782
2022-10-05 12:23:37 - train: epoch 0088, iter [00170, 01251], lr: 0.000030, loss: 0.0783
2022-10-05 12:24:05 - train: epoch 0088, iter [00180, 01251], lr: 0.000030, loss: 0.0769
2022-10-05 12:24:33 - train: epoch 0088, iter [00190, 01251], lr: 0.000030, loss: 0.0764
2022-10-05 12:25:01 - train: epoch 0088, iter [00200, 01251], lr: 0.000030, loss: 0.0817
2022-10-05 12:25:28 - train: epoch 0088, iter [00210, 01251], lr: 0.000030, loss: 0.0794
2022-10-05 12:25:56 - train: epoch 0088, iter [00220, 01251], lr: 0.000030, loss: 0.0873
2022-10-05 12:26:24 - train: epoch 0088, iter [00230, 01251], lr: 0.000030, loss: 0.0815
2022-10-05 12:26:52 - train: epoch 0088, iter [00240, 01251], lr: 0.000029, loss: 0.0778
2022-10-05 12:27:20 - train: epoch 0088, iter [00250, 01251], lr: 0.000029, loss: 0.0821
2022-10-05 12:27:48 - train: epoch 0088, iter [00260, 01251], lr: 0.000029, loss: 0.0749
2022-10-05 12:28:16 - train: epoch 0088, iter [00270, 01251], lr: 0.000029, loss: 0.0687
2022-10-05 12:28:43 - train: epoch 0088, iter [00280, 01251], lr: 0.000029, loss: 0.0816
2022-10-05 12:29:12 - train: epoch 0088, iter [00290, 01251], lr: 0.000029, loss: 0.0838
2022-10-05 12:29:40 - train: epoch 0088, iter [00300, 01251], lr: 0.000029, loss: 0.0782
2022-10-05 12:30:07 - train: epoch 0088, iter [00310, 01251], lr: 0.000029, loss: 0.0805
2022-10-05 12:30:35 - train: epoch 0088, iter [00320, 01251], lr: 0.000029, loss: 0.0780
2022-10-05 12:31:03 - train: epoch 0088, iter [00330, 01251], lr: 0.000029, loss: 0.0788
2022-10-05 12:31:31 - train: epoch 0088, iter [00340, 01251], lr: 0.000029, loss: 0.0693
2022-10-05 12:31:59 - train: epoch 0088, iter [00350, 01251], lr: 0.000029, loss: 0.0768
2022-10-05 12:32:27 - train: epoch 0088, iter [00360, 01251], lr: 0.000029, loss: 0.0874
2022-10-05 12:32:55 - train: epoch 0088, iter [00370, 01251], lr: 0.000029, loss: 0.0802
2022-10-05 12:33:23 - train: epoch 0088, iter [00380, 01251], lr: 0.000029, loss: 0.0823
2022-10-05 12:33:51 - train: epoch 0088, iter [00390, 01251], lr: 0.000029, loss: 0.0785
2022-10-05 12:34:19 - train: epoch 0088, iter [00400, 01251], lr: 0.000029, loss: 0.0849
2022-10-05 12:34:47 - train: epoch 0088, iter [00410, 01251], lr: 0.000029, loss: 0.0813
2022-10-05 12:35:15 - train: epoch 0088, iter [00420, 01251], lr: 0.000029, loss: 0.0886
2022-10-05 12:35:43 - train: epoch 0088, iter [00430, 01251], lr: 0.000029, loss: 0.0748
2022-10-05 12:36:11 - train: epoch 0088, iter [00440, 01251], lr: 0.000029, loss: 0.0805
2022-10-05 12:36:39 - train: epoch 0088, iter [00450, 01251], lr: 0.000029, loss: 0.0795
2022-10-05 12:37:06 - train: epoch 0088, iter [00460, 01251], lr: 0.000029, loss: 0.0855
2022-10-05 12:37:34 - train: epoch 0088, iter [00470, 01251], lr: 0.000029, loss: 0.0777
2022-10-05 12:38:02 - train: epoch 0088, iter [00480, 01251], lr: 0.000029, loss: 0.0885
2022-10-05 12:38:30 - train: epoch 0088, iter [00490, 01251], lr: 0.000029, loss: 0.0840
2022-10-05 12:38:58 - train: epoch 0088, iter [00500, 01251], lr: 0.000029, loss: 0.0821
2022-10-05 12:39:26 - train: epoch 0088, iter [00510, 01251], lr: 0.000029, loss: 0.0811
2022-10-05 12:39:54 - train: epoch 0088, iter [00520, 01251], lr: 0.000028, loss: 0.0791
2022-10-05 12:40:22 - train: epoch 0088, iter [00530, 01251], lr: 0.000028, loss: 0.0780
2022-10-05 12:40:50 - train: epoch 0088, iter [00540, 01251], lr: 0.000028, loss: 0.0781
2022-10-05 12:41:18 - train: epoch 0088, iter [00550, 01251], lr: 0.000028, loss: 0.0937
2022-10-05 12:41:46 - train: epoch 0088, iter [00560, 01251], lr: 0.000028, loss: 0.0796
2022-10-05 12:42:14 - train: epoch 0088, iter [00570, 01251], lr: 0.000028, loss: 0.0806
2022-10-05 12:42:42 - train: epoch 0088, iter [00580, 01251], lr: 0.000028, loss: 0.0838
2022-10-05 12:43:10 - train: epoch 0088, iter [00590, 01251], lr: 0.000028, loss: 0.0828
2022-10-05 12:43:38 - train: epoch 0088, iter [00600, 01251], lr: 0.000028, loss: 0.0851
2022-10-05 12:44:06 - train: epoch 0088, iter [00610, 01251], lr: 0.000028, loss: 0.0799
2022-10-05 12:44:34 - train: epoch 0088, iter [00620, 01251], lr: 0.000028, loss: 0.0839
2022-10-05 12:45:02 - train: epoch 0088, iter [00630, 01251], lr: 0.000028, loss: 0.0934
2022-10-05 12:45:30 - train: epoch 0088, iter [00640, 01251], lr: 0.000028, loss: 0.0791
2022-10-05 12:45:58 - train: epoch 0088, iter [00650, 01251], lr: 0.000028, loss: 0.0760
2022-10-05 12:46:26 - train: epoch 0088, iter [00660, 01251], lr: 0.000028, loss: 0.0845
2022-10-05 12:46:54 - train: epoch 0088, iter [00670, 01251], lr: 0.000028, loss: 0.0888
2022-10-05 12:47:22 - train: epoch 0088, iter [00680, 01251], lr: 0.000028, loss: 0.0777
2022-10-05 12:47:50 - train: epoch 0088, iter [00690, 01251], lr: 0.000028, loss: 0.0823
2022-10-05 12:48:18 - train: epoch 0088, iter [00700, 01251], lr: 0.000028, loss: 0.0788
2022-10-05 12:48:46 - train: epoch 0088, iter [00710, 01251], lr: 0.000028, loss: 0.0885
2022-10-05 12:49:14 - train: epoch 0088, iter [00720, 01251], lr: 0.000028, loss: 0.0842
2022-10-05 12:49:42 - train: epoch 0088, iter [00730, 01251], lr: 0.000028, loss: 0.0941
2022-10-05 12:50:10 - train: epoch 0088, iter [00740, 01251], lr: 0.000028, loss: 0.0750
2022-10-05 12:50:38 - train: epoch 0088, iter [00750, 01251], lr: 0.000028, loss: 0.0839
2022-10-05 12:51:06 - train: epoch 0088, iter [00760, 01251], lr: 0.000028, loss: 0.0755
2022-10-05 12:51:34 - train: epoch 0088, iter [00770, 01251], lr: 0.000028, loss: 0.0796
2022-10-05 12:52:02 - train: epoch 0088, iter [00780, 01251], lr: 0.000028, loss: 0.0804
2022-10-05 12:52:29 - train: epoch 0088, iter [00790, 01251], lr: 0.000028, loss: 0.0815
2022-10-05 12:52:57 - train: epoch 0088, iter [00800, 01251], lr: 0.000027, loss: 0.0785
2022-10-05 12:53:25 - train: epoch 0088, iter [00810, 01251], lr: 0.000027, loss: 0.0786
2022-10-05 12:53:53 - train: epoch 0088, iter [00820, 01251], lr: 0.000027, loss: 0.0774
2022-10-05 12:54:21 - train: epoch 0088, iter [00830, 01251], lr: 0.000027, loss: 0.0854
2022-10-05 12:54:49 - train: epoch 0088, iter [00840, 01251], lr: 0.000027, loss: 0.0749
2022-10-05 12:55:17 - train: epoch 0088, iter [00850, 01251], lr: 0.000027, loss: 0.0823
2022-10-05 12:55:46 - train: epoch 0088, iter [00860, 01251], lr: 0.000027, loss: 0.0848
2022-10-05 12:56:14 - train: epoch 0088, iter [00870, 01251], lr: 0.000027, loss: 0.0838
2022-10-05 12:56:41 - train: epoch 0088, iter [00880, 01251], lr: 0.000027, loss: 0.0843
2022-10-05 12:57:09 - train: epoch 0088, iter [00890, 01251], lr: 0.000027, loss: 0.0786
2022-10-05 12:57:37 - train: epoch 0088, iter [00900, 01251], lr: 0.000027, loss: 0.0805
2022-10-05 12:58:05 - train: epoch 0088, iter [00910, 01251], lr: 0.000027, loss: 0.0876
2022-10-05 12:58:33 - train: epoch 0088, iter [00920, 01251], lr: 0.000027, loss: 0.0842
2022-10-05 12:59:01 - train: epoch 0088, iter [00930, 01251], lr: 0.000027, loss: 0.0827
2022-10-05 12:59:29 - train: epoch 0088, iter [00940, 01251], lr: 0.000027, loss: 0.0809
2022-10-05 12:59:57 - train: epoch 0088, iter [00950, 01251], lr: 0.000027, loss: 0.0758
2022-10-05 13:00:25 - train: epoch 0088, iter [00960, 01251], lr: 0.000027, loss: 0.0815
2022-10-05 13:00:53 - train: epoch 0088, iter [00970, 01251], lr: 0.000027, loss: 0.0808
2022-10-05 13:01:21 - train: epoch 0088, iter [00980, 01251], lr: 0.000027, loss: 0.0752
2022-10-05 13:01:49 - train: epoch 0088, iter [00990, 01251], lr: 0.000027, loss: 0.0837
2022-10-05 13:02:17 - train: epoch 0088, iter [01000, 01251], lr: 0.000027, loss: 0.0839
2022-10-05 13:02:45 - train: epoch 0088, iter [01010, 01251], lr: 0.000027, loss: 0.0799
2022-10-05 13:03:13 - train: epoch 0088, iter [01020, 01251], lr: 0.000027, loss: 0.0810
2022-10-05 13:03:41 - train: epoch 0088, iter [01030, 01251], lr: 0.000027, loss: 0.0797
2022-10-05 13:04:09 - train: epoch 0088, iter [01040, 01251], lr: 0.000027, loss: 0.0872
2022-10-05 13:04:37 - train: epoch 0088, iter [01050, 01251], lr: 0.000027, loss: 0.0758
2022-10-05 13:05:05 - train: epoch 0088, iter [01060, 01251], lr: 0.000027, loss: 0.0822
2022-10-05 13:05:33 - train: epoch 0088, iter [01070, 01251], lr: 0.000027, loss: 0.0808
2022-10-05 13:06:01 - train: epoch 0088, iter [01080, 01251], lr: 0.000027, loss: 0.0772
2022-10-05 13:06:29 - train: epoch 0088, iter [01090, 01251], lr: 0.000026, loss: 0.0803
2022-10-05 13:06:57 - train: epoch 0088, iter [01100, 01251], lr: 0.000026, loss: 0.0832
2022-10-05 13:07:25 - train: epoch 0088, iter [01110, 01251], lr: 0.000026, loss: 0.0778
2022-10-05 13:07:53 - train: epoch 0088, iter [01120, 01251], lr: 0.000026, loss: 0.0766
2022-10-05 13:08:21 - train: epoch 0088, iter [01130, 01251], lr: 0.000026, loss: 0.0752
2022-10-05 13:08:49 - train: epoch 0088, iter [01140, 01251], lr: 0.000026, loss: 0.0847
2022-10-05 13:09:18 - train: epoch 0088, iter [01150, 01251], lr: 0.000026, loss: 0.0845
2022-10-05 13:09:45 - train: epoch 0088, iter [01160, 01251], lr: 0.000026, loss: 0.0749
2022-10-05 13:10:13 - train: epoch 0088, iter [01170, 01251], lr: 0.000026, loss: 0.0780
2022-10-05 13:10:41 - train: epoch 0088, iter [01180, 01251], lr: 0.000026, loss: 0.0811
2022-10-05 13:11:10 - train: epoch 0088, iter [01190, 01251], lr: 0.000026, loss: 0.0777
2022-10-05 13:11:38 - train: epoch 0088, iter [01200, 01251], lr: 0.000026, loss: 0.0772
2022-10-05 13:12:06 - train: epoch 0088, iter [01210, 01251], lr: 0.000026, loss: 0.0754
2022-10-05 13:12:34 - train: epoch 0088, iter [01220, 01251], lr: 0.000026, loss: 0.0824
2022-10-05 13:13:02 - train: epoch 0088, iter [01230, 01251], lr: 0.000026, loss: 0.0841
2022-10-05 13:13:30 - train: epoch 0088, iter [01240, 01251], lr: 0.000026, loss: 0.0771
2022-10-05 13:13:57 - train: epoch 0088, iter [01250, 01251], lr: 0.000026, loss: 0.0782
2022-10-05 13:14:02 - train: epoch 088, train_loss: 0.0816
2022-10-05 13:14:03 - until epoch: 088, best_loss: 0.0816
2022-10-05 13:14:03 - epoch 089 lr: 0.000026
2022-10-05 13:14:38 - train: epoch 0089, iter [00010, 01251], lr: 0.000026, loss: 0.0842
2022-10-05 13:15:06 - train: epoch 0089, iter [00020, 01251], lr: 0.000026, loss: 0.0873
2022-10-05 13:15:35 - train: epoch 0089, iter [00030, 01251], lr: 0.000026, loss: 0.0813
2022-10-05 13:16:03 - train: epoch 0089, iter [00040, 01251], lr: 0.000026, loss: 0.0871
2022-10-05 13:16:31 - train: epoch 0089, iter [00050, 01251], lr: 0.000026, loss: 0.0811
2022-10-05 13:16:59 - train: epoch 0089, iter [00060, 01251], lr: 0.000026, loss: 0.0819
2022-10-05 13:17:27 - train: epoch 0089, iter [00070, 01251], lr: 0.000026, loss: 0.0855
2022-10-05 13:17:55 - train: epoch 0089, iter [00080, 01251], lr: 0.000026, loss: 0.0797
2022-10-05 13:18:23 - train: epoch 0089, iter [00090, 01251], lr: 0.000026, loss: 0.0803
2022-10-05 13:18:51 - train: epoch 0089, iter [00100, 01251], lr: 0.000026, loss: 0.0878
2022-10-05 13:19:19 - train: epoch 0089, iter [00110, 01251], lr: 0.000026, loss: 0.0866
2022-10-05 13:19:47 - train: epoch 0089, iter [00120, 01251], lr: 0.000026, loss: 0.0800
2022-10-05 13:20:15 - train: epoch 0089, iter [00130, 01251], lr: 0.000025, loss: 0.0749
2022-10-05 13:20:43 - train: epoch 0089, iter [00140, 01251], lr: 0.000025, loss: 0.0813
2022-10-05 13:21:11 - train: epoch 0089, iter [00150, 01251], lr: 0.000025, loss: 0.0772
2022-10-05 13:21:39 - train: epoch 0089, iter [00160, 01251], lr: 0.000025, loss: 0.0745
2022-10-05 13:22:07 - train: epoch 0089, iter [00170, 01251], lr: 0.000025, loss: 0.0832
2022-10-05 13:22:35 - train: epoch 0089, iter [00180, 01251], lr: 0.000025, loss: 0.0785
2022-10-05 13:23:03 - train: epoch 0089, iter [00190, 01251], lr: 0.000025, loss: 0.0809
2022-10-05 13:23:31 - train: epoch 0089, iter [00200, 01251], lr: 0.000025, loss: 0.0867
2022-10-05 13:23:59 - train: epoch 0089, iter [00210, 01251], lr: 0.000025, loss: 0.0798
2022-10-05 13:24:28 - train: epoch 0089, iter [00220, 01251], lr: 0.000025, loss: 0.0769
2022-10-05 13:24:56 - train: epoch 0089, iter [00230, 01251], lr: 0.000025, loss: 0.0859
2022-10-05 13:25:24 - train: epoch 0089, iter [00240, 01251], lr: 0.000025, loss: 0.0761
2022-10-05 13:25:52 - train: epoch 0089, iter [00250, 01251], lr: 0.000025, loss: 0.0831
2022-10-05 13:26:20 - train: epoch 0089, iter [00260, 01251], lr: 0.000025, loss: 0.0854
2022-10-05 13:26:48 - train: epoch 0089, iter [00270, 01251], lr: 0.000025, loss: 0.0865
2022-10-05 13:27:16 - train: epoch 0089, iter [00280, 01251], lr: 0.000025, loss: 0.0776
2022-10-05 13:27:44 - train: epoch 0089, iter [00290, 01251], lr: 0.000025, loss: 0.0793
2022-10-05 13:28:13 - train: epoch 0089, iter [00300, 01251], lr: 0.000025, loss: 0.0855
2022-10-05 13:28:41 - train: epoch 0089, iter [00310, 01251], lr: 0.000025, loss: 0.0848
2022-10-05 13:29:09 - train: epoch 0089, iter [00320, 01251], lr: 0.000025, loss: 0.0794
2022-10-05 13:29:37 - train: epoch 0089, iter [00330, 01251], lr: 0.000025, loss: 0.0880
2022-10-05 13:30:05 - train: epoch 0089, iter [00340, 01251], lr: 0.000025, loss: 0.0832
2022-10-05 13:30:33 - train: epoch 0089, iter [00350, 01251], lr: 0.000025, loss: 0.0784
2022-10-05 13:31:01 - train: epoch 0089, iter [00360, 01251], lr: 0.000025, loss: 0.0850
2022-10-05 13:31:29 - train: epoch 0089, iter [00370, 01251], lr: 0.000025, loss: 0.0775
2022-10-05 13:31:57 - train: epoch 0089, iter [00380, 01251], lr: 0.000025, loss: 0.0856
2022-10-05 13:32:26 - train: epoch 0089, iter [00390, 01251], lr: 0.000025, loss: 0.0775
2022-10-05 13:32:54 - train: epoch 0089, iter [00400, 01251], lr: 0.000025, loss: 0.0830
2022-10-05 13:33:22 - train: epoch 0089, iter [00410, 01251], lr: 0.000025, loss: 0.0830
2022-10-05 13:33:50 - train: epoch 0089, iter [00420, 01251], lr: 0.000025, loss: 0.0817
2022-10-05 13:34:18 - train: epoch 0089, iter [00430, 01251], lr: 0.000024, loss: 0.0795
2022-10-05 13:34:46 - train: epoch 0089, iter [00440, 01251], lr: 0.000024, loss: 0.0777
2022-10-05 13:35:14 - train: epoch 0089, iter [00450, 01251], lr: 0.000024, loss: 0.0849
2022-10-05 13:35:42 - train: epoch 0089, iter [00460, 01251], lr: 0.000024, loss: 0.0813
2022-10-05 13:36:10 - train: epoch 0089, iter [00470, 01251], lr: 0.000024, loss: 0.0825
2022-10-05 13:36:38 - train: epoch 0089, iter [00480, 01251], lr: 0.000024, loss: 0.0783
2022-10-05 13:37:07 - train: epoch 0089, iter [00490, 01251], lr: 0.000024, loss: 0.0810
2022-10-05 13:37:35 - train: epoch 0089, iter [00500, 01251], lr: 0.000024, loss: 0.0844
2022-10-05 13:38:03 - train: epoch 0089, iter [00510, 01251], lr: 0.000024, loss: 0.0773
2022-10-05 13:38:31 - train: epoch 0089, iter [00520, 01251], lr: 0.000024, loss: 0.0875
2022-10-05 13:38:59 - train: epoch 0089, iter [00530, 01251], lr: 0.000024, loss: 0.0747
2022-10-05 13:39:28 - train: epoch 0089, iter [00540, 01251], lr: 0.000024, loss: 0.0869
2022-10-05 13:39:56 - train: epoch 0089, iter [00550, 01251], lr: 0.000024, loss: 0.0815
2022-10-05 13:40:24 - train: epoch 0089, iter [00560, 01251], lr: 0.000024, loss: 0.0816
2022-10-05 13:40:52 - train: epoch 0089, iter [00570, 01251], lr: 0.000024, loss: 0.0825
2022-10-05 13:41:20 - train: epoch 0089, iter [00580, 01251], lr: 0.000024, loss: 0.0826
2022-10-05 13:41:48 - train: epoch 0089, iter [00590, 01251], lr: 0.000024, loss: 0.0795
2022-10-05 13:42:16 - train: epoch 0089, iter [00600, 01251], lr: 0.000024, loss: 0.0870
2022-10-05 13:42:44 - train: epoch 0089, iter [00610, 01251], lr: 0.000024, loss: 0.0824
2022-10-05 13:43:12 - train: epoch 0089, iter [00620, 01251], lr: 0.000024, loss: 0.0871
2022-10-05 13:43:40 - train: epoch 0089, iter [00630, 01251], lr: 0.000024, loss: 0.0844
2022-10-05 13:44:08 - train: epoch 0089, iter [00640, 01251], lr: 0.000024, loss: 0.0812
2022-10-05 13:44:36 - train: epoch 0089, iter [00650, 01251], lr: 0.000024, loss: 0.0838
2022-10-05 13:45:05 - train: epoch 0089, iter [00660, 01251], lr: 0.000024, loss: 0.0822
2022-10-05 13:45:32 - train: epoch 0089, iter [00670, 01251], lr: 0.000024, loss: 0.0725
2022-10-05 13:46:01 - train: epoch 0089, iter [00680, 01251], lr: 0.000024, loss: 0.0822
2022-10-05 13:46:29 - train: epoch 0089, iter [00690, 01251], lr: 0.000024, loss: 0.0920
2022-10-05 13:46:57 - train: epoch 0089, iter [00700, 01251], lr: 0.000024, loss: 0.0857
2022-10-05 13:47:25 - train: epoch 0089, iter [00710, 01251], lr: 0.000024, loss: 0.0770
2022-10-05 13:47:53 - train: epoch 0089, iter [00720, 01251], lr: 0.000024, loss: 0.0818
2022-10-05 13:48:21 - train: epoch 0089, iter [00730, 01251], lr: 0.000024, loss: 0.0785
2022-10-05 13:48:50 - train: epoch 0089, iter [00740, 01251], lr: 0.000023, loss: 0.0832
2022-10-05 13:49:18 - train: epoch 0089, iter [00750, 01251], lr: 0.000023, loss: 0.0749
2022-10-05 13:49:46 - train: epoch 0089, iter [00760, 01251], lr: 0.000023, loss: 0.0873
2022-10-05 13:50:14 - train: epoch 0089, iter [00770, 01251], lr: 0.000023, loss: 0.0853
2022-10-05 13:50:42 - train: epoch 0089, iter [00780, 01251], lr: 0.000023, loss: 0.0797
2022-10-05 13:51:10 - train: epoch 0089, iter [00790, 01251], lr: 0.000023, loss: 0.0841
2022-10-05 13:51:38 - train: epoch 0089, iter [00800, 01251], lr: 0.000023, loss: 0.0825
2022-10-05 13:52:06 - train: epoch 0089, iter [00810, 01251], lr: 0.000023, loss: 0.0826
2022-10-05 13:52:35 - train: epoch 0089, iter [00820, 01251], lr: 0.000023, loss: 0.0879
2022-10-05 13:53:02 - train: epoch 0089, iter [00830, 01251], lr: 0.000023, loss: 0.0812
2022-10-05 13:53:30 - train: epoch 0089, iter [00840, 01251], lr: 0.000023, loss: 0.0874
2022-10-05 13:53:59 - train: epoch 0089, iter [00850, 01251], lr: 0.000023, loss: 0.0892
2022-10-05 13:54:27 - train: epoch 0089, iter [00860, 01251], lr: 0.000023, loss: 0.0849
2022-10-05 13:54:55 - train: epoch 0089, iter [00870, 01251], lr: 0.000023, loss: 0.0819
2022-10-05 13:55:23 - train: epoch 0089, iter [00880, 01251], lr: 0.000023, loss: 0.0821
2022-10-05 13:55:51 - train: epoch 0089, iter [00890, 01251], lr: 0.000023, loss: 0.0845
2022-10-05 13:56:19 - train: epoch 0089, iter [00900, 01251], lr: 0.000023, loss: 0.0829
2022-10-05 13:56:47 - train: epoch 0089, iter [00910, 01251], lr: 0.000023, loss: 0.0784
2022-10-05 13:57:15 - train: epoch 0089, iter [00920, 01251], lr: 0.000023, loss: 0.0762
2022-10-05 13:57:43 - train: epoch 0089, iter [00930, 01251], lr: 0.000023, loss: 0.0797
2022-10-05 13:58:11 - train: epoch 0089, iter [00940, 01251], lr: 0.000023, loss: 0.0724
2022-10-05 13:58:40 - train: epoch 0089, iter [00950, 01251], lr: 0.000023, loss: 0.0833
2022-10-05 13:59:08 - train: epoch 0089, iter [00960, 01251], lr: 0.000023, loss: 0.0806
2022-10-05 13:59:36 - train: epoch 0089, iter [00970, 01251], lr: 0.000023, loss: 0.0766
2022-10-05 14:00:04 - train: epoch 0089, iter [00980, 01251], lr: 0.000023, loss: 0.0812
2022-10-05 14:00:32 - train: epoch 0089, iter [00990, 01251], lr: 0.000023, loss: 0.0770
2022-10-05 14:01:00 - train: epoch 0089, iter [01000, 01251], lr: 0.000023, loss: 0.0822
2022-10-05 14:01:28 - train: epoch 0089, iter [01010, 01251], lr: 0.000023, loss: 0.0881
2022-10-05 14:01:57 - train: epoch 0089, iter [01020, 01251], lr: 0.000023, loss: 0.0903
2022-10-05 14:02:25 - train: epoch 0089, iter [01030, 01251], lr: 0.000023, loss: 0.0828
2022-10-05 14:02:53 - train: epoch 0089, iter [01040, 01251], lr: 0.000023, loss: 0.0831
2022-10-05 14:03:21 - train: epoch 0089, iter [01050, 01251], lr: 0.000022, loss: 0.0756
2022-10-05 14:03:49 - train: epoch 0089, iter [01060, 01251], lr: 0.000022, loss: 0.0783
2022-10-05 14:04:17 - train: epoch 0089, iter [01070, 01251], lr: 0.000022, loss: 0.0913
2022-10-05 14:04:45 - train: epoch 0089, iter [01080, 01251], lr: 0.000022, loss: 0.0784
2022-10-05 14:05:13 - train: epoch 0089, iter [01090, 01251], lr: 0.000022, loss: 0.0827
2022-10-05 14:05:41 - train: epoch 0089, iter [01100, 01251], lr: 0.000022, loss: 0.0793
2022-10-05 14:06:10 - train: epoch 0089, iter [01110, 01251], lr: 0.000022, loss: 0.0840
2022-10-05 14:06:38 - train: epoch 0089, iter [01120, 01251], lr: 0.000022, loss: 0.0792
2022-10-05 14:07:06 - train: epoch 0089, iter [01130, 01251], lr: 0.000022, loss: 0.0838
2022-10-05 14:07:34 - train: epoch 0089, iter [01140, 01251], lr: 0.000022, loss: 0.0772
2022-10-05 14:08:02 - train: epoch 0089, iter [01150, 01251], lr: 0.000022, loss: 0.0792
2022-10-05 14:08:30 - train: epoch 0089, iter [01160, 01251], lr: 0.000022, loss: 0.0771
2022-10-05 14:08:59 - train: epoch 0089, iter [01170, 01251], lr: 0.000022, loss: 0.0823
2022-10-05 14:09:27 - train: epoch 0089, iter [01180, 01251], lr: 0.000022, loss: 0.0779
2022-10-05 14:09:55 - train: epoch 0089, iter [01190, 01251], lr: 0.000022, loss: 0.0807
2022-10-05 14:10:23 - train: epoch 0089, iter [01200, 01251], lr: 0.000022, loss: 0.0929
2022-10-05 14:10:51 - train: epoch 0089, iter [01210, 01251], lr: 0.000022, loss: 0.0743
2022-10-05 14:11:19 - train: epoch 0089, iter [01220, 01251], lr: 0.000022, loss: 0.0798
2022-10-05 14:11:47 - train: epoch 0089, iter [01230, 01251], lr: 0.000022, loss: 0.0814
2022-10-05 14:12:16 - train: epoch 0089, iter [01240, 01251], lr: 0.000022, loss: 0.0821
2022-10-05 14:12:43 - train: epoch 0089, iter [01250, 01251], lr: 0.000022, loss: 0.0861
2022-10-05 14:12:48 - train: epoch 089, train_loss: 0.0815
2022-10-05 14:12:49 - until epoch: 089, best_loss: 0.0815
2022-10-05 14:12:49 - epoch 090 lr: 0.000022
2022-10-05 14:13:25 - train: epoch 0090, iter [00010, 01251], lr: 0.000022, loss: 0.0763
2022-10-05 14:13:53 - train: epoch 0090, iter [00020, 01251], lr: 0.000022, loss: 0.0797
2022-10-05 14:14:21 - train: epoch 0090, iter [00030, 01251], lr: 0.000022, loss: 0.0822
2022-10-05 14:14:49 - train: epoch 0090, iter [00040, 01251], lr: 0.000022, loss: 0.0907
2022-10-05 14:15:17 - train: epoch 0090, iter [00050, 01251], lr: 0.000022, loss: 0.0814
2022-10-05 14:15:45 - train: epoch 0090, iter [00060, 01251], lr: 0.000022, loss: 0.0802
2022-10-05 14:16:13 - train: epoch 0090, iter [00070, 01251], lr: 0.000022, loss: 0.0903
2022-10-05 14:16:41 - train: epoch 0090, iter [00080, 01251], lr: 0.000022, loss: 0.0771
2022-10-05 14:17:09 - train: epoch 0090, iter [00090, 01251], lr: 0.000022, loss: 0.0801
2022-10-05 14:17:37 - train: epoch 0090, iter [00100, 01251], lr: 0.000022, loss: 0.0786
2022-10-05 14:18:05 - train: epoch 0090, iter [00110, 01251], lr: 0.000022, loss: 0.0795
2022-10-05 14:18:33 - train: epoch 0090, iter [00120, 01251], lr: 0.000021, loss: 0.0781
2022-10-05 14:19:01 - train: epoch 0090, iter [00130, 01251], lr: 0.000021, loss: 0.0796
2022-10-05 14:19:29 - train: epoch 0090, iter [00140, 01251], lr: 0.000021, loss: 0.0854
2022-10-05 14:19:57 - train: epoch 0090, iter [00150, 01251], lr: 0.000021, loss: 0.0842
2022-10-05 14:20:25 - train: epoch 0090, iter [00160, 01251], lr: 0.000021, loss: 0.0846
2022-10-05 14:20:53 - train: epoch 0090, iter [00170, 01251], lr: 0.000021, loss: 0.0912
2022-10-05 14:21:21 - train: epoch 0090, iter [00180, 01251], lr: 0.000021, loss: 0.0859
2022-10-05 14:21:49 - train: epoch 0090, iter [00190, 01251], lr: 0.000021, loss: 0.0924
2022-10-05 14:22:17 - train: epoch 0090, iter [00200, 01251], lr: 0.000021, loss: 0.0792
2022-10-05 14:22:45 - train: epoch 0090, iter [00210, 01251], lr: 0.000021, loss: 0.0867
2022-10-05 14:23:13 - train: epoch 0090, iter [00220, 01251], lr: 0.000021, loss: 0.0819
2022-10-05 14:23:41 - train: epoch 0090, iter [00230, 01251], lr: 0.000021, loss: 0.0785
2022-10-05 14:24:09 - train: epoch 0090, iter [00240, 01251], lr: 0.000021, loss: 0.0808
2022-10-05 14:24:37 - train: epoch 0090, iter [00250, 01251], lr: 0.000021, loss: 0.0859
2022-10-05 14:25:05 - train: epoch 0090, iter [00260, 01251], lr: 0.000021, loss: 0.0797
2022-10-05 14:25:33 - train: epoch 0090, iter [00270, 01251], lr: 0.000021, loss: 0.0842
2022-10-05 14:26:01 - train: epoch 0090, iter [00280, 01251], lr: 0.000021, loss: 0.0791
2022-10-05 14:26:29 - train: epoch 0090, iter [00290, 01251], lr: 0.000021, loss: 0.0767
2022-10-05 14:26:57 - train: epoch 0090, iter [00300, 01251], lr: 0.000021, loss: 0.0815
2022-10-05 14:27:25 - train: epoch 0090, iter [00310, 01251], lr: 0.000021, loss: 0.0922
2022-10-05 14:27:53 - train: epoch 0090, iter [00320, 01251], lr: 0.000021, loss: 0.0814
2022-10-05 14:28:21 - train: epoch 0090, iter [00330, 01251], lr: 0.000021, loss: 0.0817
2022-10-05 14:28:50 - train: epoch 0090, iter [00340, 01251], lr: 0.000021, loss: 0.0750
2022-10-05 14:29:18 - train: epoch 0090, iter [00350, 01251], lr: 0.000021, loss: 0.0856
2022-10-05 14:29:46 - train: epoch 0090, iter [00360, 01251], lr: 0.000021, loss: 0.0834
2022-10-05 14:30:14 - train: epoch 0090, iter [00370, 01251], lr: 0.000021, loss: 0.0869
2022-10-05 14:30:42 - train: epoch 0090, iter [00380, 01251], lr: 0.000021, loss: 0.0795
2022-10-05 14:31:10 - train: epoch 0090, iter [00390, 01251], lr: 0.000021, loss: 0.0818
2022-10-05 14:31:38 - train: epoch 0090, iter [00400, 01251], lr: 0.000021, loss: 0.0787
2022-10-05 14:32:06 - train: epoch 0090, iter [00410, 01251], lr: 0.000021, loss: 0.0697
2022-10-05 14:32:34 - train: epoch 0090, iter [00420, 01251], lr: 0.000021, loss: 0.0817
2022-10-05 14:33:02 - train: epoch 0090, iter [00430, 01251], lr: 0.000021, loss: 0.0846
2022-10-05 14:33:30 - train: epoch 0090, iter [00440, 01251], lr: 0.000020, loss: 0.0781
2022-10-05 14:33:58 - train: epoch 0090, iter [00450, 01251], lr: 0.000020, loss: 0.0862
2022-10-05 14:34:26 - train: epoch 0090, iter [00460, 01251], lr: 0.000020, loss: 0.0880
2022-10-05 14:34:54 - train: epoch 0090, iter [00470, 01251], lr: 0.000020, loss: 0.0799
2022-10-05 14:35:22 - train: epoch 0090, iter [00480, 01251], lr: 0.000020, loss: 0.0766
2022-10-05 14:35:50 - train: epoch 0090, iter [00490, 01251], lr: 0.000020, loss: 0.0833
2022-10-05 14:36:18 - train: epoch 0090, iter [00500, 01251], lr: 0.000020, loss: 0.0845
2022-10-05 14:36:46 - train: epoch 0090, iter [00510, 01251], lr: 0.000020, loss: 0.0793
2022-10-05 14:37:14 - train: epoch 0090, iter [00520, 01251], lr: 0.000020, loss: 0.0845
2022-10-05 14:37:42 - train: epoch 0090, iter [00530, 01251], lr: 0.000020, loss: 0.0786
2022-10-05 14:38:10 - train: epoch 0090, iter [00540, 01251], lr: 0.000020, loss: 0.0803
2022-10-05 14:38:38 - train: epoch 0090, iter [00550, 01251], lr: 0.000020, loss: 0.0862
2022-10-05 14:39:07 - train: epoch 0090, iter [00560, 01251], lr: 0.000020, loss: 0.0749
2022-10-05 14:39:35 - train: epoch 0090, iter [00570, 01251], lr: 0.000020, loss: 0.0798
2022-10-05 14:40:03 - train: epoch 0090, iter [00580, 01251], lr: 0.000020, loss: 0.0828
2022-10-05 14:40:31 - train: epoch 0090, iter [00590, 01251], lr: 0.000020, loss: 0.0816
2022-10-05 14:40:59 - train: epoch 0090, iter [00600, 01251], lr: 0.000020, loss: 0.0868
2022-10-05 14:41:27 - train: epoch 0090, iter [00610, 01251], lr: 0.000020, loss: 0.0816
2022-10-05 14:41:55 - train: epoch 0090, iter [00620, 01251], lr: 0.000020, loss: 0.0778
2022-10-05 14:42:23 - train: epoch 0090, iter [00630, 01251], lr: 0.000020, loss: 0.0816
2022-10-05 14:42:51 - train: epoch 0090, iter [00640, 01251], lr: 0.000020, loss: 0.0827
2022-10-05 14:43:19 - train: epoch 0090, iter [00650, 01251], lr: 0.000020, loss: 0.0729
2022-10-05 14:43:47 - train: epoch 0090, iter [00660, 01251], lr: 0.000020, loss: 0.0836
2022-10-05 14:44:15 - train: epoch 0090, iter [00670, 01251], lr: 0.000020, loss: 0.0772
2022-10-05 14:44:44 - train: epoch 0090, iter [00680, 01251], lr: 0.000020, loss: 0.0790
2022-10-05 14:45:12 - train: epoch 0090, iter [00690, 01251], lr: 0.000020, loss: 0.0902
2022-10-05 14:45:40 - train: epoch 0090, iter [00700, 01251], lr: 0.000020, loss: 0.0800
2022-10-05 14:46:08 - train: epoch 0090, iter [00710, 01251], lr: 0.000020, loss: 0.0777
2022-10-05 14:46:36 - train: epoch 0090, iter [00720, 01251], lr: 0.000020, loss: 0.0795
2022-10-05 14:47:04 - train: epoch 0090, iter [00730, 01251], lr: 0.000020, loss: 0.0803
2022-10-05 14:47:32 - train: epoch 0090, iter [00740, 01251], lr: 0.000020, loss: 0.0788
2022-10-05 14:48:00 - train: epoch 0090, iter [00750, 01251], lr: 0.000020, loss: 0.0841
2022-10-05 14:48:28 - train: epoch 0090, iter [00760, 01251], lr: 0.000020, loss: 0.0765
2022-10-05 14:48:56 - train: epoch 0090, iter [00770, 01251], lr: 0.000019, loss: 0.0857
2022-10-05 14:49:25 - train: epoch 0090, iter [00780, 01251], lr: 0.000019, loss: 0.0843
2022-10-05 14:49:53 - train: epoch 0090, iter [00790, 01251], lr: 0.000019, loss: 0.0818
2022-10-05 14:50:21 - train: epoch 0090, iter [00800, 01251], lr: 0.000019, loss: 0.0790
2022-10-05 14:50:49 - train: epoch 0090, iter [00810, 01251], lr: 0.000019, loss: 0.0845
2022-10-05 14:51:17 - train: epoch 0090, iter [00820, 01251], lr: 0.000019, loss: 0.0831
2022-10-05 14:51:45 - train: epoch 0090, iter [00830, 01251], lr: 0.000019, loss: 0.0784
2022-10-05 14:52:13 - train: epoch 0090, iter [00840, 01251], lr: 0.000019, loss: 0.0856
2022-10-05 14:52:41 - train: epoch 0090, iter [00850, 01251], lr: 0.000019, loss: 0.0787
2022-10-05 14:53:09 - train: epoch 0090, iter [00860, 01251], lr: 0.000019, loss: 0.0755
2022-10-05 14:53:37 - train: epoch 0090, iter [00870, 01251], lr: 0.000019, loss: 0.0841
2022-10-05 14:54:05 - train: epoch 0090, iter [00880, 01251], lr: 0.000019, loss: 0.0806
2022-10-05 14:54:33 - train: epoch 0090, iter [00890, 01251], lr: 0.000019, loss: 0.0810
2022-10-05 14:55:02 - train: epoch 0090, iter [00900, 01251], lr: 0.000019, loss: 0.0870
2022-10-05 14:55:30 - train: epoch 0090, iter [00910, 01251], lr: 0.000019, loss: 0.0793
2022-10-05 14:55:58 - train: epoch 0090, iter [00920, 01251], lr: 0.000019, loss: 0.0766
2022-10-05 14:56:26 - train: epoch 0090, iter [00930, 01251], lr: 0.000019, loss: 0.0800
2022-10-05 14:56:54 - train: epoch 0090, iter [00940, 01251], lr: 0.000019, loss: 0.0753
2022-10-05 14:57:22 - train: epoch 0090, iter [00950, 01251], lr: 0.000019, loss: 0.0849
2022-10-05 14:57:51 - train: epoch 0090, iter [00960, 01251], lr: 0.000019, loss: 0.0839
2022-10-05 14:58:19 - train: epoch 0090, iter [00970, 01251], lr: 0.000019, loss: 0.0858
2022-10-05 14:58:47 - train: epoch 0090, iter [00980, 01251], lr: 0.000019, loss: 0.0870
2022-10-05 14:59:15 - train: epoch 0090, iter [00990, 01251], lr: 0.000019, loss: 0.0797
2022-10-05 14:59:43 - train: epoch 0090, iter [01000, 01251], lr: 0.000019, loss: 0.0792
2022-10-05 15:00:12 - train: epoch 0090, iter [01010, 01251], lr: 0.000019, loss: 0.0827
2022-10-05 15:00:40 - train: epoch 0090, iter [01020, 01251], lr: 0.000019, loss: 0.0843
2022-10-05 15:01:08 - train: epoch 0090, iter [01030, 01251], lr: 0.000019, loss: 0.0916
2022-10-05 15:01:36 - train: epoch 0090, iter [01040, 01251], lr: 0.000019, loss: 0.0869
2022-10-05 15:02:04 - train: epoch 0090, iter [01050, 01251], lr: 0.000019, loss: 0.0799
2022-10-05 15:02:33 - train: epoch 0090, iter [01060, 01251], lr: 0.000019, loss: 0.0778
2022-10-05 15:03:01 - train: epoch 0090, iter [01070, 01251], lr: 0.000019, loss: 0.0826
2022-10-05 15:03:29 - train: epoch 0090, iter [01080, 01251], lr: 0.000019, loss: 0.0809
2022-10-05 15:03:57 - train: epoch 0090, iter [01090, 01251], lr: 0.000019, loss: 0.0765
2022-10-05 15:04:25 - train: epoch 0090, iter [01100, 01251], lr: 0.000019, loss: 0.0820
2022-10-05 15:04:53 - train: epoch 0090, iter [01110, 01251], lr: 0.000018, loss: 0.0782
2022-10-05 15:05:21 - train: epoch 0090, iter [01120, 01251], lr: 0.000018, loss: 0.0824
2022-10-05 15:05:49 - train: epoch 0090, iter [01130, 01251], lr: 0.000018, loss: 0.0769
2022-10-05 15:06:17 - train: epoch 0090, iter [01140, 01251], lr: 0.000018, loss: 0.0796
2022-10-05 15:06:46 - train: epoch 0090, iter [01150, 01251], lr: 0.000018, loss: 0.0809
2022-10-05 15:07:14 - train: epoch 0090, iter [01160, 01251], lr: 0.000018, loss: 0.0816
2022-10-05 15:07:42 - train: epoch 0090, iter [01170, 01251], lr: 0.000018, loss: 0.0825
2022-10-05 15:08:10 - train: epoch 0090, iter [01180, 01251], lr: 0.000018, loss: 0.0838
2022-10-05 15:08:38 - train: epoch 0090, iter [01190, 01251], lr: 0.000018, loss: 0.0835
2022-10-05 15:09:06 - train: epoch 0090, iter [01200, 01251], lr: 0.000018, loss: 0.0778
2022-10-05 15:09:34 - train: epoch 0090, iter [01210, 01251], lr: 0.000018, loss: 0.0787
2022-10-05 15:10:02 - train: epoch 0090, iter [01220, 01251], lr: 0.000018, loss: 0.0819
2022-10-05 15:10:30 - train: epoch 0090, iter [01230, 01251], lr: 0.000018, loss: 0.0743
2022-10-05 15:10:58 - train: epoch 0090, iter [01240, 01251], lr: 0.000018, loss: 0.0790
2022-10-05 15:11:26 - train: epoch 0090, iter [01250, 01251], lr: 0.000018, loss: 0.0770
2022-10-05 15:11:31 - train: epoch 090, train_loss: 0.0814
2022-10-05 15:11:33 - until epoch: 090, best_loss: 0.0814
2022-10-05 15:11:33 - epoch 091 lr: 0.000018
2022-10-05 15:12:08 - train: epoch 0091, iter [00010, 01251], lr: 0.000018, loss: 0.0834
2022-10-05 15:12:36 - train: epoch 0091, iter [00020, 01251], lr: 0.000018, loss: 0.0875
2022-10-05 15:13:04 - train: epoch 0091, iter [00030, 01251], lr: 0.000018, loss: 0.0820
2022-10-05 15:13:32 - train: epoch 0091, iter [00040, 01251], lr: 0.000018, loss: 0.0829
2022-10-05 15:14:00 - train: epoch 0091, iter [00050, 01251], lr: 0.000018, loss: 0.0756
2022-10-05 15:14:28 - train: epoch 0091, iter [00060, 01251], lr: 0.000018, loss: 0.0772
2022-10-05 15:14:56 - train: epoch 0091, iter [00070, 01251], lr: 0.000018, loss: 0.0795
2022-10-05 15:15:24 - train: epoch 0091, iter [00080, 01251], lr: 0.000018, loss: 0.0810
2022-10-05 15:15:52 - train: epoch 0091, iter [00090, 01251], lr: 0.000018, loss: 0.0870
2022-10-05 15:16:20 - train: epoch 0091, iter [00100, 01251], lr: 0.000018, loss: 0.0807
2022-10-05 15:16:48 - train: epoch 0091, iter [00110, 01251], lr: 0.000018, loss: 0.0824
2022-10-05 15:17:16 - train: epoch 0091, iter [00120, 01251], lr: 0.000018, loss: 0.0825
2022-10-05 15:17:44 - train: epoch 0091, iter [00130, 01251], lr: 0.000018, loss: 0.0792
2022-10-05 15:18:12 - train: epoch 0091, iter [00140, 01251], lr: 0.000018, loss: 0.0813
2022-10-05 15:18:40 - train: epoch 0091, iter [00150, 01251], lr: 0.000018, loss: 0.0790
2022-10-05 15:19:08 - train: epoch 0091, iter [00160, 01251], lr: 0.000018, loss: 0.0836
2022-10-05 15:19:36 - train: epoch 0091, iter [00170, 01251], lr: 0.000018, loss: 0.0841
2022-10-05 15:20:04 - train: epoch 0091, iter [00180, 01251], lr: 0.000018, loss: 0.0784
2022-10-05 15:20:33 - train: epoch 0091, iter [00190, 01251], lr: 0.000018, loss: 0.0867
2022-10-05 15:21:01 - train: epoch 0091, iter [00200, 01251], lr: 0.000018, loss: 0.0840
2022-10-05 15:21:29 - train: epoch 0091, iter [00210, 01251], lr: 0.000017, loss: 0.0817
2022-10-05 15:21:57 - train: epoch 0091, iter [00220, 01251], lr: 0.000017, loss: 0.0788
2022-10-05 15:22:25 - train: epoch 0091, iter [00230, 01251], lr: 0.000017, loss: 0.0784
2022-10-05 15:22:53 - train: epoch 0091, iter [00240, 01251], lr: 0.000017, loss: 0.0872
2022-10-05 15:23:21 - train: epoch 0091, iter [00250, 01251], lr: 0.000017, loss: 0.0771
2022-10-05 15:23:49 - train: epoch 0091, iter [00260, 01251], lr: 0.000017, loss: 0.0797
2022-10-05 15:24:17 - train: epoch 0091, iter [00270, 01251], lr: 0.000017, loss: 0.0772
2022-10-05 15:24:45 - train: epoch 0091, iter [00280, 01251], lr: 0.000017, loss: 0.0810
2022-10-05 15:25:13 - train: epoch 0091, iter [00290, 01251], lr: 0.000017, loss: 0.0814
2022-10-05 15:25:41 - train: epoch 0091, iter [00300, 01251], lr: 0.000017, loss: 0.0815
2022-10-05 15:26:09 - train: epoch 0091, iter [00310, 01251], lr: 0.000017, loss: 0.0827
2022-10-05 15:26:37 - train: epoch 0091, iter [00320, 01251], lr: 0.000017, loss: 0.0907
2022-10-05 15:27:05 - train: epoch 0091, iter [00330, 01251], lr: 0.000017, loss: 0.0903
2022-10-05 15:27:33 - train: epoch 0091, iter [00340, 01251], lr: 0.000017, loss: 0.0801
2022-10-05 15:28:01 - train: epoch 0091, iter [00350, 01251], lr: 0.000017, loss: 0.0802
2022-10-05 15:28:29 - train: epoch 0091, iter [00360, 01251], lr: 0.000017, loss: 0.0787
2022-10-05 15:28:57 - train: epoch 0091, iter [00370, 01251], lr: 0.000017, loss: 0.0795
2022-10-05 15:29:25 - train: epoch 0091, iter [00380, 01251], lr: 0.000017, loss: 0.0784
2022-10-05 15:29:53 - train: epoch 0091, iter [00390, 01251], lr: 0.000017, loss: 0.0798
2022-10-05 15:30:21 - train: epoch 0091, iter [00400, 01251], lr: 0.000017, loss: 0.0824
2022-10-05 15:30:49 - train: epoch 0091, iter [00410, 01251], lr: 0.000017, loss: 0.0730
2022-10-05 15:31:17 - train: epoch 0091, iter [00420, 01251], lr: 0.000017, loss: 0.0772
2022-10-05 15:31:45 - train: epoch 0091, iter [00430, 01251], lr: 0.000017, loss: 0.0881
2022-10-05 15:32:13 - train: epoch 0091, iter [00440, 01251], lr: 0.000017, loss: 0.0865
2022-10-05 15:32:41 - train: epoch 0091, iter [00450, 01251], lr: 0.000017, loss: 0.0843
2022-10-05 15:33:09 - train: epoch 0091, iter [00460, 01251], lr: 0.000017, loss: 0.0832
2022-10-05 15:33:37 - train: epoch 0091, iter [00470, 01251], lr: 0.000017, loss: 0.0730
2022-10-05 15:34:05 - train: epoch 0091, iter [00480, 01251], lr: 0.000017, loss: 0.0829
2022-10-05 15:34:33 - train: epoch 0091, iter [00490, 01251], lr: 0.000017, loss: 0.0859
2022-10-05 15:35:01 - train: epoch 0091, iter [00500, 01251], lr: 0.000017, loss: 0.0817
2022-10-05 15:35:29 - train: epoch 0091, iter [00510, 01251], lr: 0.000017, loss: 0.0880
2022-10-05 15:35:57 - train: epoch 0091, iter [00520, 01251], lr: 0.000017, loss: 0.0795
2022-10-05 15:36:25 - train: epoch 0091, iter [00530, 01251], lr: 0.000017, loss: 0.0796
2022-10-05 15:36:53 - train: epoch 0091, iter [00540, 01251], lr: 0.000017, loss: 0.0764
2022-10-05 15:37:21 - train: epoch 0091, iter [00550, 01251], lr: 0.000017, loss: 0.0761
2022-10-05 15:37:49 - train: epoch 0091, iter [00560, 01251], lr: 0.000017, loss: 0.0880
2022-10-05 15:38:17 - train: epoch 0091, iter [00570, 01251], lr: 0.000016, loss: 0.0754
2022-10-05 15:38:45 - train: epoch 0091, iter [00580, 01251], lr: 0.000016, loss: 0.0848
2022-10-05 15:39:13 - train: epoch 0091, iter [00590, 01251], lr: 0.000016, loss: 0.0768
2022-10-05 15:39:41 - train: epoch 0091, iter [00600, 01251], lr: 0.000016, loss: 0.0826
2022-10-05 15:40:09 - train: epoch 0091, iter [00610, 01251], lr: 0.000016, loss: 0.0787
2022-10-05 15:40:36 - train: epoch 0091, iter [00620, 01251], lr: 0.000016, loss: 0.0814
2022-10-05 15:41:04 - train: epoch 0091, iter [00630, 01251], lr: 0.000016, loss: 0.0859
2022-10-05 15:41:33 - train: epoch 0091, iter [00640, 01251], lr: 0.000016, loss: 0.0823
2022-10-05 15:42:01 - train: epoch 0091, iter [00650, 01251], lr: 0.000016, loss: 0.0850
2022-10-05 15:42:28 - train: epoch 0091, iter [00660, 01251], lr: 0.000016, loss: 0.0770
2022-10-05 15:42:56 - train: epoch 0091, iter [00670, 01251], lr: 0.000016, loss: 0.0788
2022-10-05 15:43:24 - train: epoch 0091, iter [00680, 01251], lr: 0.000016, loss: 0.0782
2022-10-05 15:43:52 - train: epoch 0091, iter [00690, 01251], lr: 0.000016, loss: 0.0807
2022-10-05 15:44:20 - train: epoch 0091, iter [00700, 01251], lr: 0.000016, loss: 0.0818
2022-10-05 15:44:48 - train: epoch 0091, iter [00710, 01251], lr: 0.000016, loss: 0.0786
2022-10-05 15:45:16 - train: epoch 0091, iter [00720, 01251], lr: 0.000016, loss: 0.0860
2022-10-05 15:45:44 - train: epoch 0091, iter [00730, 01251], lr: 0.000016, loss: 0.0829
2022-10-05 15:46:12 - train: epoch 0091, iter [00740, 01251], lr: 0.000016, loss: 0.0844
2022-10-05 15:46:40 - train: epoch 0091, iter [00750, 01251], lr: 0.000016, loss: 0.0762
2022-10-05 15:47:08 - train: epoch 0091, iter [00760, 01251], lr: 0.000016, loss: 0.0852
2022-10-05 15:47:36 - train: epoch 0091, iter [00770, 01251], lr: 0.000016, loss: 0.0788
2022-10-05 15:48:04 - train: epoch 0091, iter [00780, 01251], lr: 0.000016, loss: 0.0748
2022-10-05 15:48:32 - train: epoch 0091, iter [00790, 01251], lr: 0.000016, loss: 0.0885
2022-10-05 15:49:00 - train: epoch 0091, iter [00800, 01251], lr: 0.000016, loss: 0.0751
2022-10-05 15:49:28 - train: epoch 0091, iter [00810, 01251], lr: 0.000016, loss: 0.0827
2022-10-05 15:49:56 - train: epoch 0091, iter [00820, 01251], lr: 0.000016, loss: 0.0810
2022-10-05 15:50:24 - train: epoch 0091, iter [00830, 01251], lr: 0.000016, loss: 0.0780
2022-10-05 15:50:52 - train: epoch 0091, iter [00840, 01251], lr: 0.000016, loss: 0.0728
2022-10-05 15:51:20 - train: epoch 0091, iter [00850, 01251], lr: 0.000016, loss: 0.0769
2022-10-05 15:51:48 - train: epoch 0091, iter [00860, 01251], lr: 0.000016, loss: 0.0695
2022-10-05 15:52:16 - train: epoch 0091, iter [00870, 01251], lr: 0.000016, loss: 0.0778
2022-10-05 15:52:44 - train: epoch 0091, iter [00880, 01251], lr: 0.000016, loss: 0.0875
2022-10-05 15:53:12 - train: epoch 0091, iter [00890, 01251], lr: 0.000016, loss: 0.0790
2022-10-05 15:53:40 - train: epoch 0091, iter [00900, 01251], lr: 0.000016, loss: 0.0871
2022-10-05 15:54:08 - train: epoch 0091, iter [00910, 01251], lr: 0.000016, loss: 0.0788
2022-10-05 15:54:36 - train: epoch 0091, iter [00920, 01251], lr: 0.000016, loss: 0.0824
2022-10-05 15:55:04 - train: epoch 0091, iter [00930, 01251], lr: 0.000016, loss: 0.0792
2022-10-05 15:55:32 - train: epoch 0091, iter [00940, 01251], lr: 0.000015, loss: 0.0878
2022-10-05 15:56:00 - train: epoch 0091, iter [00950, 01251], lr: 0.000015, loss: 0.0806
2022-10-05 15:56:28 - train: epoch 0091, iter [00960, 01251], lr: 0.000015, loss: 0.0835
2022-10-05 15:56:56 - train: epoch 0091, iter [00970, 01251], lr: 0.000015, loss: 0.0737
2022-10-05 15:57:24 - train: epoch 0091, iter [00980, 01251], lr: 0.000015, loss: 0.0737
2022-10-05 15:57:52 - train: epoch 0091, iter [00990, 01251], lr: 0.000015, loss: 0.0827
2022-10-05 15:58:20 - train: epoch 0091, iter [01000, 01251], lr: 0.000015, loss: 0.0775
2022-10-05 15:58:48 - train: epoch 0091, iter [01010, 01251], lr: 0.000015, loss: 0.0889
2022-10-05 15:59:16 - train: epoch 0091, iter [01020, 01251], lr: 0.000015, loss: 0.0771
2022-10-05 15:59:44 - train: epoch 0091, iter [01030, 01251], lr: 0.000015, loss: 0.0855
2022-10-05 16:00:12 - train: epoch 0091, iter [01040, 01251], lr: 0.000015, loss: 0.0797
2022-10-05 16:00:40 - train: epoch 0091, iter [01050, 01251], lr: 0.000015, loss: 0.0831
2022-10-05 16:01:08 - train: epoch 0091, iter [01060, 01251], lr: 0.000015, loss: 0.0804
2022-10-05 16:01:36 - train: epoch 0091, iter [01070, 01251], lr: 0.000015, loss: 0.0855
2022-10-05 16:02:04 - train: epoch 0091, iter [01080, 01251], lr: 0.000015, loss: 0.0788
2022-10-05 16:02:32 - train: epoch 0091, iter [01090, 01251], lr: 0.000015, loss: 0.0767
2022-10-05 16:03:00 - train: epoch 0091, iter [01100, 01251], lr: 0.000015, loss: 0.0828
2022-10-05 16:03:28 - train: epoch 0091, iter [01110, 01251], lr: 0.000015, loss: 0.0760
2022-10-05 16:03:56 - train: epoch 0091, iter [01120, 01251], lr: 0.000015, loss: 0.0827
2022-10-05 16:04:24 - train: epoch 0091, iter [01130, 01251], lr: 0.000015, loss: 0.0790
2022-10-05 16:04:52 - train: epoch 0091, iter [01140, 01251], lr: 0.000015, loss: 0.0781
2022-10-05 16:05:20 - train: epoch 0091, iter [01150, 01251], lr: 0.000015, loss: 0.0842
2022-10-05 16:05:48 - train: epoch 0091, iter [01160, 01251], lr: 0.000015, loss: 0.0815
2022-10-05 16:06:16 - train: epoch 0091, iter [01170, 01251], lr: 0.000015, loss: 0.0793
2022-10-05 16:06:44 - train: epoch 0091, iter [01180, 01251], lr: 0.000015, loss: 0.0855
2022-10-05 16:07:12 - train: epoch 0091, iter [01190, 01251], lr: 0.000015, loss: 0.0776
2022-10-05 16:07:40 - train: epoch 0091, iter [01200, 01251], lr: 0.000015, loss: 0.0778
2022-10-05 16:08:08 - train: epoch 0091, iter [01210, 01251], lr: 0.000015, loss: 0.0765
2022-10-05 16:08:36 - train: epoch 0091, iter [01220, 01251], lr: 0.000015, loss: 0.0775
2022-10-05 16:09:04 - train: epoch 0091, iter [01230, 01251], lr: 0.000015, loss: 0.0778
2022-10-05 16:09:32 - train: epoch 0091, iter [01240, 01251], lr: 0.000015, loss: 0.0762
2022-10-05 16:10:00 - train: epoch 0091, iter [01250, 01251], lr: 0.000015, loss: 0.0799
2022-10-05 16:10:05 - train: epoch 091, train_loss: 0.0813
2022-10-05 16:10:06 - until epoch: 091, best_loss: 0.0813
2022-10-05 16:10:06 - epoch 092 lr: 0.000015
2022-10-05 16:10:42 - train: epoch 0092, iter [00010, 01251], lr: 0.000015, loss: 0.0780
2022-10-05 16:11:10 - train: epoch 0092, iter [00020, 01251], lr: 0.000015, loss: 0.0730
2022-10-05 16:11:38 - train: epoch 0092, iter [00030, 01251], lr: 0.000015, loss: 0.0770
2022-10-05 16:12:06 - train: epoch 0092, iter [00040, 01251], lr: 0.000015, loss: 0.0755
2022-10-05 16:12:34 - train: epoch 0092, iter [00050, 01251], lr: 0.000015, loss: 0.0811
2022-10-05 16:13:01 - train: epoch 0092, iter [00060, 01251], lr: 0.000015, loss: 0.0847
2022-10-05 16:13:29 - train: epoch 0092, iter [00070, 01251], lr: 0.000015, loss: 0.0774
2022-10-05 16:13:57 - train: epoch 0092, iter [00080, 01251], lr: 0.000014, loss: 0.0764
2022-10-05 16:14:25 - train: epoch 0092, iter [00090, 01251], lr: 0.000014, loss: 0.0799
2022-10-05 16:14:53 - train: epoch 0092, iter [00100, 01251], lr: 0.000014, loss: 0.0792
2022-10-05 16:15:21 - train: epoch 0092, iter [00110, 01251], lr: 0.000014, loss: 0.0778
2022-10-05 16:15:49 - train: epoch 0092, iter [00120, 01251], lr: 0.000014, loss: 0.0843
2022-10-05 16:16:17 - train: epoch 0092, iter [00130, 01251], lr: 0.000014, loss: 0.0815
2022-10-05 16:16:45 - train: epoch 0092, iter [00140, 01251], lr: 0.000014, loss: 0.0782
2022-10-05 16:17:13 - train: epoch 0092, iter [00150, 01251], lr: 0.000014, loss: 0.0786
2022-10-05 16:17:41 - train: epoch 0092, iter [00160, 01251], lr: 0.000014, loss: 0.0845
2022-10-05 16:18:09 - train: epoch 0092, iter [00170, 01251], lr: 0.000014, loss: 0.0866
2022-10-05 16:18:37 - train: epoch 0092, iter [00180, 01251], lr: 0.000014, loss: 0.0783
2022-10-05 16:19:05 - train: epoch 0092, iter [00190, 01251], lr: 0.000014, loss: 0.0828
2022-10-05 16:19:33 - train: epoch 0092, iter [00200, 01251], lr: 0.000014, loss: 0.0805
2022-10-05 16:20:01 - train: epoch 0092, iter [00210, 01251], lr: 0.000014, loss: 0.0824
2022-10-05 16:20:29 - train: epoch 0092, iter [00220, 01251], lr: 0.000014, loss: 0.0771
2022-10-05 16:20:57 - train: epoch 0092, iter [00230, 01251], lr: 0.000014, loss: 0.0795
2022-10-05 16:21:25 - train: epoch 0092, iter [00240, 01251], lr: 0.000014, loss: 0.0830
2022-10-05 16:21:53 - train: epoch 0092, iter [00250, 01251], lr: 0.000014, loss: 0.0718
2022-10-05 16:22:21 - train: epoch 0092, iter [00260, 01251], lr: 0.000014, loss: 0.0776
2022-10-05 16:22:49 - train: epoch 0092, iter [00270, 01251], lr: 0.000014, loss: 0.0804
2022-10-05 16:23:17 - train: epoch 0092, iter [00280, 01251], lr: 0.000014, loss: 0.0798
2022-10-05 16:23:44 - train: epoch 0092, iter [00290, 01251], lr: 0.000014, loss: 0.0855
2022-10-05 16:24:12 - train: epoch 0092, iter [00300, 01251], lr: 0.000014, loss: 0.0823
2022-10-05 16:24:40 - train: epoch 0092, iter [00310, 01251], lr: 0.000014, loss: 0.0779
2022-10-05 16:25:08 - train: epoch 0092, iter [00320, 01251], lr: 0.000014, loss: 0.0815
2022-10-05 16:25:36 - train: epoch 0092, iter [00330, 01251], lr: 0.000014, loss: 0.0835
2022-10-05 16:26:04 - train: epoch 0092, iter [00340, 01251], lr: 0.000014, loss: 0.0865
2022-10-05 16:26:32 - train: epoch 0092, iter [00350, 01251], lr: 0.000014, loss: 0.0833
2022-10-05 16:27:00 - train: epoch 0092, iter [00360, 01251], lr: 0.000014, loss: 0.0872
2022-10-05 16:27:28 - train: epoch 0092, iter [00370, 01251], lr: 0.000014, loss: 0.0833
2022-10-05 16:27:56 - train: epoch 0092, iter [00380, 01251], lr: 0.000014, loss: 0.0834
2022-10-05 16:28:24 - train: epoch 0092, iter [00390, 01251], lr: 0.000014, loss: 0.0820
2022-10-05 16:28:52 - train: epoch 0092, iter [00400, 01251], lr: 0.000014, loss: 0.0909
2022-10-05 16:29:20 - train: epoch 0092, iter [00410, 01251], lr: 0.000014, loss: 0.0832
2022-10-05 16:29:48 - train: epoch 0092, iter [00420, 01251], lr: 0.000014, loss: 0.0798
2022-10-05 16:30:16 - train: epoch 0092, iter [00430, 01251], lr: 0.000014, loss: 0.0899
2022-10-05 16:30:44 - train: epoch 0092, iter [00440, 01251], lr: 0.000014, loss: 0.0806
2022-10-05 16:31:12 - train: epoch 0092, iter [00450, 01251], lr: 0.000014, loss: 0.0836
2022-10-05 16:31:40 - train: epoch 0092, iter [00460, 01251], lr: 0.000014, loss: 0.0816
2022-10-05 16:32:08 - train: epoch 0092, iter [00470, 01251], lr: 0.000013, loss: 0.0838
2022-10-05 16:32:36 - train: epoch 0092, iter [00480, 01251], lr: 0.000013, loss: 0.0803
2022-10-05 16:33:04 - train: epoch 0092, iter [00490, 01251], lr: 0.000013, loss: 0.0755
2022-10-05 16:33:32 - train: epoch 0092, iter [00500, 01251], lr: 0.000013, loss: 0.0770
2022-10-05 16:34:00 - train: epoch 0092, iter [00510, 01251], lr: 0.000013, loss: 0.0806
2022-10-05 16:34:28 - train: epoch 0092, iter [00520, 01251], lr: 0.000013, loss: 0.0771
2022-10-05 16:34:56 - train: epoch 0092, iter [00530, 01251], lr: 0.000013, loss: 0.0867
2022-10-05 16:35:24 - train: epoch 0092, iter [00540, 01251], lr: 0.000013, loss: 0.0810
2022-10-05 16:35:52 - train: epoch 0092, iter [00550, 01251], lr: 0.000013, loss: 0.0736
2022-10-05 16:36:20 - train: epoch 0092, iter [00560, 01251], lr: 0.000013, loss: 0.0915
2022-10-05 16:36:48 - train: epoch 0092, iter [00570, 01251], lr: 0.000013, loss: 0.0843
2022-10-05 16:37:16 - train: epoch 0092, iter [00580, 01251], lr: 0.000013, loss: 0.0749
2022-10-05 16:37:44 - train: epoch 0092, iter [00590, 01251], lr: 0.000013, loss: 0.0780
2022-10-05 16:38:12 - train: epoch 0092, iter [00600, 01251], lr: 0.000013, loss: 0.0770
2022-10-05 16:38:41 - train: epoch 0092, iter [00610, 01251], lr: 0.000013, loss: 0.0817
2022-10-05 16:39:09 - train: epoch 0092, iter [00620, 01251], lr: 0.000013, loss: 0.0790
2022-10-05 16:39:37 - train: epoch 0092, iter [00630, 01251], lr: 0.000013, loss: 0.0855
2022-10-05 16:40:05 - train: epoch 0092, iter [00640, 01251], lr: 0.000013, loss: 0.0852
2022-10-05 16:40:33 - train: epoch 0092, iter [00650, 01251], lr: 0.000013, loss: 0.0822
2022-10-05 16:41:01 - train: epoch 0092, iter [00660, 01251], lr: 0.000013, loss: 0.0796
2022-10-05 16:41:28 - train: epoch 0092, iter [00670, 01251], lr: 0.000013, loss: 0.0744
2022-10-05 16:41:56 - train: epoch 0092, iter [00680, 01251], lr: 0.000013, loss: 0.0875
2022-10-05 16:42:24 - train: epoch 0092, iter [00690, 01251], lr: 0.000013, loss: 0.0856
2022-10-05 16:42:52 - train: epoch 0092, iter [00700, 01251], lr: 0.000013, loss: 0.0811
2022-10-05 16:43:20 - train: epoch 0092, iter [00710, 01251], lr: 0.000013, loss: 0.0788
2022-10-05 16:43:48 - train: epoch 0092, iter [00720, 01251], lr: 0.000013, loss: 0.0877
2022-10-05 16:44:16 - train: epoch 0092, iter [00730, 01251], lr: 0.000013, loss: 0.0858
2022-10-05 16:44:45 - train: epoch 0092, iter [00740, 01251], lr: 0.000013, loss: 0.0754
2022-10-05 16:45:13 - train: epoch 0092, iter [00750, 01251], lr: 0.000013, loss: 0.0825
2022-10-05 16:45:41 - train: epoch 0092, iter [00760, 01251], lr: 0.000013, loss: 0.0777
2022-10-05 16:46:09 - train: epoch 0092, iter [00770, 01251], lr: 0.000013, loss: 0.0815
2022-10-05 16:46:36 - train: epoch 0092, iter [00780, 01251], lr: 0.000013, loss: 0.0769
2022-10-05 16:47:04 - train: epoch 0092, iter [00790, 01251], lr: 0.000013, loss: 0.0825
2022-10-05 16:47:32 - train: epoch 0092, iter [00800, 01251], lr: 0.000013, loss: 0.0816
2022-10-05 16:48:00 - train: epoch 0092, iter [00810, 01251], lr: 0.000013, loss: 0.0773
2022-10-05 16:48:29 - train: epoch 0092, iter [00820, 01251], lr: 0.000013, loss: 0.0898
2022-10-05 16:48:57 - train: epoch 0092, iter [00830, 01251], lr: 0.000013, loss: 0.0773
2022-10-05 16:49:25 - train: epoch 0092, iter [00840, 01251], lr: 0.000013, loss: 0.0819
2022-10-05 16:49:53 - train: epoch 0092, iter [00850, 01251], lr: 0.000013, loss: 0.0866
2022-10-05 16:50:20 - train: epoch 0092, iter [00860, 01251], lr: 0.000013, loss: 0.0792
2022-10-05 16:50:48 - train: epoch 0092, iter [00870, 01251], lr: 0.000013, loss: 0.0748
2022-10-05 16:51:16 - train: epoch 0092, iter [00880, 01251], lr: 0.000012, loss: 0.0784
2022-10-05 16:51:45 - train: epoch 0092, iter [00890, 01251], lr: 0.000012, loss: 0.0811
2022-10-05 16:52:13 - train: epoch 0092, iter [00900, 01251], lr: 0.000012, loss: 0.0795
2022-10-05 16:52:41 - train: epoch 0092, iter [00910, 01251], lr: 0.000012, loss: 0.0780
2022-10-05 16:53:09 - train: epoch 0092, iter [00920, 01251], lr: 0.000012, loss: 0.0790
2022-10-05 16:53:37 - train: epoch 0092, iter [00930, 01251], lr: 0.000012, loss: 0.0904
2022-10-05 16:54:05 - train: epoch 0092, iter [00940, 01251], lr: 0.000012, loss: 0.0763
2022-10-05 16:54:33 - train: epoch 0092, iter [00950, 01251], lr: 0.000012, loss: 0.0813
2022-10-05 16:55:01 - train: epoch 0092, iter [00960, 01251], lr: 0.000012, loss: 0.0827
2022-10-05 16:55:29 - train: epoch 0092, iter [00970, 01251], lr: 0.000012, loss: 0.0839
2022-10-05 16:55:57 - train: epoch 0092, iter [00980, 01251], lr: 0.000012, loss: 0.0748
2022-10-05 16:56:25 - train: epoch 0092, iter [00990, 01251], lr: 0.000012, loss: 0.0830
2022-10-05 16:56:53 - train: epoch 0092, iter [01000, 01251], lr: 0.000012, loss: 0.0804
2022-10-05 16:57:21 - train: epoch 0092, iter [01010, 01251], lr: 0.000012, loss: 0.0926
2022-10-05 16:57:49 - train: epoch 0092, iter [01020, 01251], lr: 0.000012, loss: 0.0815
2022-10-05 16:58:17 - train: epoch 0092, iter [01030, 01251], lr: 0.000012, loss: 0.0887
2022-10-05 16:58:45 - train: epoch 0092, iter [01040, 01251], lr: 0.000012, loss: 0.0773
2022-10-05 16:59:13 - train: epoch 0092, iter [01050, 01251], lr: 0.000012, loss: 0.0863
2022-10-05 16:59:41 - train: epoch 0092, iter [01060, 01251], lr: 0.000012, loss: 0.0851
2022-10-05 17:00:09 - train: epoch 0092, iter [01070, 01251], lr: 0.000012, loss: 0.0867
2022-10-05 17:00:38 - train: epoch 0092, iter [01080, 01251], lr: 0.000012, loss: 0.0867
2022-10-05 17:01:05 - train: epoch 0092, iter [01090, 01251], lr: 0.000012, loss: 0.0732
2022-10-05 17:01:33 - train: epoch 0092, iter [01100, 01251], lr: 0.000012, loss: 0.0737
2022-10-05 17:02:01 - train: epoch 0092, iter [01110, 01251], lr: 0.000012, loss: 0.0851
2022-10-05 17:02:29 - train: epoch 0092, iter [01120, 01251], lr: 0.000012, loss: 0.0821
2022-10-05 17:02:57 - train: epoch 0092, iter [01130, 01251], lr: 0.000012, loss: 0.0805
2022-10-05 17:03:25 - train: epoch 0092, iter [01140, 01251], lr: 0.000012, loss: 0.0853
2022-10-05 17:03:53 - train: epoch 0092, iter [01150, 01251], lr: 0.000012, loss: 0.0805
2022-10-05 17:04:21 - train: epoch 0092, iter [01160, 01251], lr: 0.000012, loss: 0.0771
2022-10-05 17:04:49 - train: epoch 0092, iter [01170, 01251], lr: 0.000012, loss: 0.0771
2022-10-05 17:05:17 - train: epoch 0092, iter [01180, 01251], lr: 0.000012, loss: 0.0794
2022-10-05 17:05:46 - train: epoch 0092, iter [01190, 01251], lr: 0.000012, loss: 0.0873
2022-10-05 17:06:14 - train: epoch 0092, iter [01200, 01251], lr: 0.000012, loss: 0.0744
2022-10-05 17:06:42 - train: epoch 0092, iter [01210, 01251], lr: 0.000012, loss: 0.0803
2022-10-05 17:07:10 - train: epoch 0092, iter [01220, 01251], lr: 0.000012, loss: 0.0835
2022-10-05 17:07:38 - train: epoch 0092, iter [01230, 01251], lr: 0.000012, loss: 0.0827
2022-10-05 17:08:06 - train: epoch 0092, iter [01240, 01251], lr: 0.000012, loss: 0.0724
2022-10-05 17:08:34 - train: epoch 0092, iter [01250, 01251], lr: 0.000012, loss: 0.0817
2022-10-05 17:08:38 - train: epoch 092, train_loss: 0.0812
2022-10-05 17:08:40 - until epoch: 092, best_loss: 0.0812
2022-10-05 17:08:40 - epoch 093 lr: 0.000012
2022-10-05 17:09:15 - train: epoch 0093, iter [00010, 01251], lr: 0.000012, loss: 0.0844
2022-10-05 17:09:43 - train: epoch 0093, iter [00020, 01251], lr: 0.000012, loss: 0.0771
2022-10-05 17:10:11 - train: epoch 0093, iter [00030, 01251], lr: 0.000012, loss: 0.0869
2022-10-05 17:10:39 - train: epoch 0093, iter [00040, 01251], lr: 0.000012, loss: 0.0810
2022-10-05 17:11:07 - train: epoch 0093, iter [00050, 01251], lr: 0.000012, loss: 0.0749
2022-10-05 17:11:35 - train: epoch 0093, iter [00060, 01251], lr: 0.000011, loss: 0.0902
2022-10-05 17:12:03 - train: epoch 0093, iter [00070, 01251], lr: 0.000011, loss: 0.0824
2022-10-05 17:12:31 - train: epoch 0093, iter [00080, 01251], lr: 0.000011, loss: 0.0916
2022-10-05 17:12:59 - train: epoch 0093, iter [00090, 01251], lr: 0.000011, loss: 0.0874
2022-10-05 17:13:26 - train: epoch 0093, iter [00100, 01251], lr: 0.000011, loss: 0.0843
2022-10-05 17:13:55 - train: epoch 0093, iter [00110, 01251], lr: 0.000011, loss: 0.0776
2022-10-05 17:14:23 - train: epoch 0093, iter [00120, 01251], lr: 0.000011, loss: 0.0787
2022-10-05 17:14:51 - train: epoch 0093, iter [00130, 01251], lr: 0.000011, loss: 0.0749
2022-10-05 17:15:19 - train: epoch 0093, iter [00140, 01251], lr: 0.000011, loss: 0.0777
2022-10-05 17:15:47 - train: epoch 0093, iter [00150, 01251], lr: 0.000011, loss: 0.0753
2022-10-05 17:16:15 - train: epoch 0093, iter [00160, 01251], lr: 0.000011, loss: 0.0803
2022-10-05 17:16:42 - train: epoch 0093, iter [00170, 01251], lr: 0.000011, loss: 0.0830
2022-10-05 17:17:10 - train: epoch 0093, iter [00180, 01251], lr: 0.000011, loss: 0.0827
2022-10-05 17:17:38 - train: epoch 0093, iter [00190, 01251], lr: 0.000011, loss: 0.0835
2022-10-05 17:18:06 - train: epoch 0093, iter [00200, 01251], lr: 0.000011, loss: 0.0881
2022-10-05 17:18:34 - train: epoch 0093, iter [00210, 01251], lr: 0.000011, loss: 0.0747
2022-10-05 17:19:02 - train: epoch 0093, iter [00220, 01251], lr: 0.000011, loss: 0.0763
2022-10-05 17:19:30 - train: epoch 0093, iter [00230, 01251], lr: 0.000011, loss: 0.0735
2022-10-05 17:19:58 - train: epoch 0093, iter [00240, 01251], lr: 0.000011, loss: 0.0788
2022-10-05 17:20:26 - train: epoch 0093, iter [00250, 01251], lr: 0.000011, loss: 0.0835
2022-10-05 17:20:54 - train: epoch 0093, iter [00260, 01251], lr: 0.000011, loss: 0.0797
2022-10-05 17:21:22 - train: epoch 0093, iter [00270, 01251], lr: 0.000011, loss: 0.0852
2022-10-05 17:21:50 - train: epoch 0093, iter [00280, 01251], lr: 0.000011, loss: 0.0832
2022-10-05 17:22:18 - train: epoch 0093, iter [00290, 01251], lr: 0.000011, loss: 0.0873
2022-10-05 17:22:46 - train: epoch 0093, iter [00300, 01251], lr: 0.000011, loss: 0.0875
2022-10-05 17:23:14 - train: epoch 0093, iter [00310, 01251], lr: 0.000011, loss: 0.0858
2022-10-05 17:23:42 - train: epoch 0093, iter [00320, 01251], lr: 0.000011, loss: 0.0780
2022-10-05 17:24:10 - train: epoch 0093, iter [00330, 01251], lr: 0.000011, loss: 0.0772
2022-10-05 17:24:38 - train: epoch 0093, iter [00340, 01251], lr: 0.000011, loss: 0.0835
2022-10-05 17:25:06 - train: epoch 0093, iter [00350, 01251], lr: 0.000011, loss: 0.0831
2022-10-05 17:25:34 - train: epoch 0093, iter [00360, 01251], lr: 0.000011, loss: 0.0770
2022-10-05 17:26:02 - train: epoch 0093, iter [00370, 01251], lr: 0.000011, loss: 0.0804
2022-10-05 17:26:30 - train: epoch 0093, iter [00380, 01251], lr: 0.000011, loss: 0.0805
2022-10-05 17:26:58 - train: epoch 0093, iter [00390, 01251], lr: 0.000011, loss: 0.0775
2022-10-05 17:27:26 - train: epoch 0093, iter [00400, 01251], lr: 0.000011, loss: 0.0794
2022-10-05 17:27:54 - train: epoch 0093, iter [00410, 01251], lr: 0.000011, loss: 0.0899
2022-10-05 17:28:22 - train: epoch 0093, iter [00420, 01251], lr: 0.000011, loss: 0.0836
2022-10-05 17:28:50 - train: epoch 0093, iter [00430, 01251], lr: 0.000011, loss: 0.0829
2022-10-05 17:29:17 - train: epoch 0093, iter [00440, 01251], lr: 0.000011, loss: 0.0842
2022-10-05 17:29:45 - train: epoch 0093, iter [00450, 01251], lr: 0.000011, loss: 0.0817
2022-10-05 17:30:13 - train: epoch 0093, iter [00460, 01251], lr: 0.000011, loss: 0.0792
2022-10-05 17:30:41 - train: epoch 0093, iter [00470, 01251], lr: 0.000011, loss: 0.0807
2022-10-05 17:31:09 - train: epoch 0093, iter [00480, 01251], lr: 0.000011, loss: 0.0841
2022-10-05 17:31:37 - train: epoch 0093, iter [00490, 01251], lr: 0.000011, loss: 0.0829
2022-10-05 17:32:05 - train: epoch 0093, iter [00500, 01251], lr: 0.000010, loss: 0.0763
2022-10-05 17:32:33 - train: epoch 0093, iter [00510, 01251], lr: 0.000010, loss: 0.0828
2022-10-05 17:33:01 - train: epoch 0093, iter [00520, 01251], lr: 0.000010, loss: 0.0856
2022-10-05 17:33:29 - train: epoch 0093, iter [00530, 01251], lr: 0.000010, loss: 0.0746
2022-10-05 17:33:57 - train: epoch 0093, iter [00540, 01251], lr: 0.000010, loss: 0.0805
2022-10-05 17:34:25 - train: epoch 0093, iter [00550, 01251], lr: 0.000010, loss: 0.0802
2022-10-05 17:34:53 - train: epoch 0093, iter [00560, 01251], lr: 0.000010, loss: 0.0829
2022-10-05 17:35:21 - train: epoch 0093, iter [00570, 01251], lr: 0.000010, loss: 0.0767
2022-10-05 17:35:49 - train: epoch 0093, iter [00580, 01251], lr: 0.000010, loss: 0.0833
2022-10-05 17:36:17 - train: epoch 0093, iter [00590, 01251], lr: 0.000010, loss: 0.0884
2022-10-05 17:36:45 - train: epoch 0093, iter [00600, 01251], lr: 0.000010, loss: 0.0809
2022-10-05 17:37:13 - train: epoch 0093, iter [00610, 01251], lr: 0.000010, loss: 0.0816
2022-10-05 17:37:41 - train: epoch 0093, iter [00620, 01251], lr: 0.000010, loss: 0.0807
2022-10-05 17:38:09 - train: epoch 0093, iter [00630, 01251], lr: 0.000010, loss: 0.0771
2022-10-05 17:38:37 - train: epoch 0093, iter [00640, 01251], lr: 0.000010, loss: 0.0779
2022-10-05 17:39:05 - train: epoch 0093, iter [00650, 01251], lr: 0.000010, loss: 0.0860
2022-10-05 17:39:33 - train: epoch 0093, iter [00660, 01251], lr: 0.000010, loss: 0.0814
2022-10-05 17:40:01 - train: epoch 0093, iter [00670, 01251], lr: 0.000010, loss: 0.0830
2022-10-05 17:40:29 - train: epoch 0093, iter [00680, 01251], lr: 0.000010, loss: 0.0786
2022-10-05 17:40:57 - train: epoch 0093, iter [00690, 01251], lr: 0.000010, loss: 0.0854
2022-10-05 17:41:25 - train: epoch 0093, iter [00700, 01251], lr: 0.000010, loss: 0.0804
2022-10-05 17:41:53 - train: epoch 0093, iter [00710, 01251], lr: 0.000010, loss: 0.0814
2022-10-05 17:42:21 - train: epoch 0093, iter [00720, 01251], lr: 0.000010, loss: 0.0845
2022-10-05 17:42:49 - train: epoch 0093, iter [00730, 01251], lr: 0.000010, loss: 0.0827
2022-10-05 17:43:18 - train: epoch 0093, iter [00740, 01251], lr: 0.000010, loss: 0.0861
2022-10-05 17:43:46 - train: epoch 0093, iter [00750, 01251], lr: 0.000010, loss: 0.0816
2022-10-05 17:44:14 - train: epoch 0093, iter [00760, 01251], lr: 0.000010, loss: 0.0799
2022-10-05 17:44:42 - train: epoch 0093, iter [00770, 01251], lr: 0.000010, loss: 0.0751
2022-10-05 17:45:10 - train: epoch 0093, iter [00780, 01251], lr: 0.000010, loss: 0.0828
2022-10-05 17:45:38 - train: epoch 0093, iter [00790, 01251], lr: 0.000010, loss: 0.0808
2022-10-05 17:46:06 - train: epoch 0093, iter [00800, 01251], lr: 0.000010, loss: 0.0854
2022-10-05 17:46:34 - train: epoch 0093, iter [00810, 01251], lr: 0.000010, loss: 0.0794
2022-10-05 17:47:02 - train: epoch 0093, iter [00820, 01251], lr: 0.000010, loss: 0.0788
2022-10-05 17:47:30 - train: epoch 0093, iter [00830, 01251], lr: 0.000010, loss: 0.0836
2022-10-05 17:47:58 - train: epoch 0093, iter [00840, 01251], lr: 0.000010, loss: 0.0782
2022-10-05 17:48:26 - train: epoch 0093, iter [00850, 01251], lr: 0.000010, loss: 0.0826
2022-10-05 17:48:54 - train: epoch 0093, iter [00860, 01251], lr: 0.000010, loss: 0.0831
2022-10-05 17:49:22 - train: epoch 0093, iter [00870, 01251], lr: 0.000010, loss: 0.0761
2022-10-05 17:49:50 - train: epoch 0093, iter [00880, 01251], lr: 0.000010, loss: 0.0807
2022-10-05 17:50:18 - train: epoch 0093, iter [00890, 01251], lr: 0.000010, loss: 0.0802
2022-10-05 17:50:46 - train: epoch 0093, iter [00900, 01251], lr: 0.000010, loss: 0.0780
2022-10-05 17:51:14 - train: epoch 0093, iter [00910, 01251], lr: 0.000010, loss: 0.0775
2022-10-05 17:51:42 - train: epoch 0093, iter [00920, 01251], lr: 0.000010, loss: 0.0811
2022-10-05 17:52:10 - train: epoch 0093, iter [00930, 01251], lr: 0.000010, loss: 0.0868
2022-10-05 17:52:38 - train: epoch 0093, iter [00940, 01251], lr: 0.000010, loss: 0.0848
2022-10-05 17:53:06 - train: epoch 0093, iter [00950, 01251], lr: 0.000010, loss: 0.0804
2022-10-05 17:53:34 - train: epoch 0093, iter [00960, 01251], lr: 0.000010, loss: 0.0786
2022-10-05 17:54:02 - train: epoch 0093, iter [00970, 01251], lr: 0.000009, loss: 0.0854
2022-10-05 17:54:30 - train: epoch 0093, iter [00980, 01251], lr: 0.000009, loss: 0.0793
2022-10-05 17:54:59 - train: epoch 0093, iter [00990, 01251], lr: 0.000009, loss: 0.0750
2022-10-05 17:55:27 - train: epoch 0093, iter [01000, 01251], lr: 0.000009, loss: 0.0777
2022-10-05 17:55:56 - train: epoch 0093, iter [01010, 01251], lr: 0.000009, loss: 0.0845
2022-10-05 17:56:23 - train: epoch 0093, iter [01020, 01251], lr: 0.000009, loss: 0.0825
2022-10-05 17:56:52 - train: epoch 0093, iter [01030, 01251], lr: 0.000009, loss: 0.0888
2022-10-05 17:57:20 - train: epoch 0093, iter [01040, 01251], lr: 0.000009, loss: 0.0874
2022-10-05 17:57:48 - train: epoch 0093, iter [01050, 01251], lr: 0.000009, loss: 0.0749
2022-10-05 17:58:16 - train: epoch 0093, iter [01060, 01251], lr: 0.000009, loss: 0.0815
2022-10-05 17:58:44 - train: epoch 0093, iter [01070, 01251], lr: 0.000009, loss: 0.0823
2022-10-05 17:59:12 - train: epoch 0093, iter [01080, 01251], lr: 0.000009, loss: 0.0743
2022-10-05 17:59:40 - train: epoch 0093, iter [01090, 01251], lr: 0.000009, loss: 0.0820
2022-10-05 18:00:09 - train: epoch 0093, iter [01100, 01251], lr: 0.000009, loss: 0.0875
2022-10-05 18:00:37 - train: epoch 0093, iter [01110, 01251], lr: 0.000009, loss: 0.0804
2022-10-05 18:01:05 - train: epoch 0093, iter [01120, 01251], lr: 0.000009, loss: 0.0810
2022-10-05 18:01:33 - train: epoch 0093, iter [01130, 01251], lr: 0.000009, loss: 0.0846
2022-10-05 18:02:01 - train: epoch 0093, iter [01140, 01251], lr: 0.000009, loss: 0.0765
2022-10-05 18:02:29 - train: epoch 0093, iter [01150, 01251], lr: 0.000009, loss: 0.0901
2022-10-05 18:02:57 - train: epoch 0093, iter [01160, 01251], lr: 0.000009, loss: 0.0842
2022-10-05 18:03:25 - train: epoch 0093, iter [01170, 01251], lr: 0.000009, loss: 0.0796
2022-10-05 18:03:53 - train: epoch 0093, iter [01180, 01251], lr: 0.000009, loss: 0.0826
2022-10-05 18:04:22 - train: epoch 0093, iter [01190, 01251], lr: 0.000009, loss: 0.0823
2022-10-05 18:04:50 - train: epoch 0093, iter [01200, 01251], lr: 0.000009, loss: 0.0827
2022-10-05 18:05:18 - train: epoch 0093, iter [01210, 01251], lr: 0.000009, loss: 0.0789
2022-10-05 18:05:46 - train: epoch 0093, iter [01220, 01251], lr: 0.000009, loss: 0.0719
2022-10-05 18:06:14 - train: epoch 0093, iter [01230, 01251], lr: 0.000009, loss: 0.0855
2022-10-05 18:06:43 - train: epoch 0093, iter [01240, 01251], lr: 0.000009, loss: 0.0736
2022-10-05 18:07:11 - train: epoch 0093, iter [01250, 01251], lr: 0.000009, loss: 0.0819
2022-10-05 18:07:15 - train: epoch 093, train_loss: 0.0811
2022-10-05 18:07:16 - until epoch: 093, best_loss: 0.0811
2022-10-05 18:07:16 - epoch 094 lr: 0.000009
2022-10-05 18:07:52 - train: epoch 0094, iter [00010, 01251], lr: 0.000009, loss: 0.0762
2022-10-05 18:08:20 - train: epoch 0094, iter [00020, 01251], lr: 0.000009, loss: 0.0851
2022-10-05 18:08:48 - train: epoch 0094, iter [00030, 01251], lr: 0.000009, loss: 0.0816
2022-10-05 18:09:16 - train: epoch 0094, iter [00040, 01251], lr: 0.000009, loss: 0.0809
2022-10-05 18:09:44 - train: epoch 0094, iter [00050, 01251], lr: 0.000009, loss: 0.0777
2022-10-05 18:10:12 - train: epoch 0094, iter [00060, 01251], lr: 0.000009, loss: 0.0864
2022-10-05 18:10:40 - train: epoch 0094, iter [00070, 01251], lr: 0.000009, loss: 0.0819
2022-10-05 18:11:08 - train: epoch 0094, iter [00080, 01251], lr: 0.000009, loss: 0.0806
2022-10-05 18:11:36 - train: epoch 0094, iter [00090, 01251], lr: 0.000009, loss: 0.0801
2022-10-05 18:12:05 - train: epoch 0094, iter [00100, 01251], lr: 0.000009, loss: 0.0893
2022-10-05 18:12:33 - train: epoch 0094, iter [00110, 01251], lr: 0.000009, loss: 0.0774
2022-10-05 18:13:01 - train: epoch 0094, iter [00120, 01251], lr: 0.000009, loss: 0.0872
2022-10-05 18:13:30 - train: epoch 0094, iter [00130, 01251], lr: 0.000009, loss: 0.0846
2022-10-05 18:13:58 - train: epoch 0094, iter [00140, 01251], lr: 0.000009, loss: 0.0822
2022-10-05 18:14:26 - train: epoch 0094, iter [00150, 01251], lr: 0.000009, loss: 0.0780
2022-10-05 18:14:54 - train: epoch 0094, iter [00160, 01251], lr: 0.000009, loss: 0.0772
2022-10-05 18:15:22 - train: epoch 0094, iter [00170, 01251], lr: 0.000009, loss: 0.0846
2022-10-05 18:15:51 - train: epoch 0094, iter [00180, 01251], lr: 0.000009, loss: 0.0763
2022-10-05 18:16:19 - train: epoch 0094, iter [00190, 01251], lr: 0.000009, loss: 0.0776
2022-10-05 18:16:47 - train: epoch 0094, iter [00200, 01251], lr: 0.000009, loss: 0.0864
2022-10-05 18:17:15 - train: epoch 0094, iter [00210, 01251], lr: 0.000008, loss: 0.0861
2022-10-05 18:17:43 - train: epoch 0094, iter [00220, 01251], lr: 0.000008, loss: 0.0809
2022-10-05 18:18:11 - train: epoch 0094, iter [00230, 01251], lr: 0.000008, loss: 0.0809
2022-10-05 18:18:39 - train: epoch 0094, iter [00240, 01251], lr: 0.000008, loss: 0.0870
2022-10-05 18:19:07 - train: epoch 0094, iter [00250, 01251], lr: 0.000008, loss: 0.0802
2022-10-05 18:19:35 - train: epoch 0094, iter [00260, 01251], lr: 0.000008, loss: 0.0815
2022-10-05 18:20:03 - train: epoch 0094, iter [00270, 01251], lr: 0.000008, loss: 0.0800
2022-10-05 18:20:31 - train: epoch 0094, iter [00280, 01251], lr: 0.000008, loss: 0.0841
2022-10-05 18:20:59 - train: epoch 0094, iter [00290, 01251], lr: 0.000008, loss: 0.0879
2022-10-05 18:21:27 - train: epoch 0094, iter [00300, 01251], lr: 0.000008, loss: 0.0788
2022-10-05 18:21:55 - train: epoch 0094, iter [00310, 01251], lr: 0.000008, loss: 0.0799
2022-10-05 18:22:23 - train: epoch 0094, iter [00320, 01251], lr: 0.000008, loss: 0.0822
2022-10-05 18:22:51 - train: epoch 0094, iter [00330, 01251], lr: 0.000008, loss: 0.0795
2022-10-05 18:23:19 - train: epoch 0094, iter [00340, 01251], lr: 0.000008, loss: 0.0721
2022-10-05 18:23:47 - train: epoch 0094, iter [00350, 01251], lr: 0.000008, loss: 0.0816
2022-10-05 18:24:15 - train: epoch 0094, iter [00360, 01251], lr: 0.000008, loss: 0.0810
2022-10-05 18:24:43 - train: epoch 0094, iter [00370, 01251], lr: 0.000008, loss: 0.0835
2022-10-05 18:25:11 - train: epoch 0094, iter [00380, 01251], lr: 0.000008, loss: 0.0855
2022-10-05 18:25:39 - train: epoch 0094, iter [00390, 01251], lr: 0.000008, loss: 0.0864
2022-10-05 18:26:07 - train: epoch 0094, iter [00400, 01251], lr: 0.000008, loss: 0.0802
2022-10-05 18:26:35 - train: epoch 0094, iter [00410, 01251], lr: 0.000008, loss: 0.0837
2022-10-05 18:27:03 - train: epoch 0094, iter [00420, 01251], lr: 0.000008, loss: 0.0796
2022-10-05 18:27:31 - train: epoch 0094, iter [00430, 01251], lr: 0.000008, loss: 0.0727
2022-10-05 18:27:59 - train: epoch 0094, iter [00440, 01251], lr: 0.000008, loss: 0.0838
2022-10-05 18:28:27 - train: epoch 0094, iter [00450, 01251], lr: 0.000008, loss: 0.0804
2022-10-05 18:28:55 - train: epoch 0094, iter [00460, 01251], lr: 0.000008, loss: 0.0771
2022-10-05 18:29:23 - train: epoch 0094, iter [00470, 01251], lr: 0.000008, loss: 0.0817
2022-10-05 18:29:51 - train: epoch 0094, iter [00480, 01251], lr: 0.000008, loss: 0.0852
2022-10-05 18:30:19 - train: epoch 0094, iter [00490, 01251], lr: 0.000008, loss: 0.0787
2022-10-05 18:30:47 - train: epoch 0094, iter [00500, 01251], lr: 0.000008, loss: 0.0860
2022-10-05 18:31:15 - train: epoch 0094, iter [00510, 01251], lr: 0.000008, loss: 0.0766
2022-10-05 18:31:43 - train: epoch 0094, iter [00520, 01251], lr: 0.000008, loss: 0.0848
2022-10-05 18:32:11 - train: epoch 0094, iter [00530, 01251], lr: 0.000008, loss: 0.0738
2022-10-05 18:32:39 - train: epoch 0094, iter [00540, 01251], lr: 0.000008, loss: 0.0804
2022-10-05 18:33:07 - train: epoch 0094, iter [00550, 01251], lr: 0.000008, loss: 0.0844
2022-10-05 18:33:35 - train: epoch 0094, iter [00560, 01251], lr: 0.000008, loss: 0.0816
2022-10-05 18:34:03 - train: epoch 0094, iter [00570, 01251], lr: 0.000008, loss: 0.0808
2022-10-05 18:34:31 - train: epoch 0094, iter [00580, 01251], lr: 0.000008, loss: 0.0801
2022-10-05 18:34:59 - train: epoch 0094, iter [00590, 01251], lr: 0.000008, loss: 0.0751
2022-10-05 18:35:27 - train: epoch 0094, iter [00600, 01251], lr: 0.000008, loss: 0.0799
2022-10-05 18:35:55 - train: epoch 0094, iter [00610, 01251], lr: 0.000008, loss: 0.0818
2022-10-05 18:36:23 - train: epoch 0094, iter [00620, 01251], lr: 0.000008, loss: 0.0865
2022-10-05 18:36:51 - train: epoch 0094, iter [00630, 01251], lr: 0.000008, loss: 0.0796
2022-10-05 18:37:19 - train: epoch 0094, iter [00640, 01251], lr: 0.000008, loss: 0.0838
2022-10-05 18:37:47 - train: epoch 0094, iter [00650, 01251], lr: 0.000008, loss: 0.0952
2022-10-05 18:38:15 - train: epoch 0094, iter [00660, 01251], lr: 0.000008, loss: 0.0771
2022-10-05 18:38:43 - train: epoch 0094, iter [00670, 01251], lr: 0.000008, loss: 0.0852
2022-10-05 18:39:11 - train: epoch 0094, iter [00680, 01251], lr: 0.000008, loss: 0.0753
2022-10-05 18:39:39 - train: epoch 0094, iter [00690, 01251], lr: 0.000008, loss: 0.0818
2022-10-05 18:40:06 - train: epoch 0094, iter [00700, 01251], lr: 0.000008, loss: 0.0773
2022-10-05 18:40:34 - train: epoch 0094, iter [00710, 01251], lr: 0.000008, loss: 0.0850
2022-10-05 18:41:02 - train: epoch 0094, iter [00720, 01251], lr: 0.000008, loss: 0.0780
2022-10-05 18:41:30 - train: epoch 0094, iter [00730, 01251], lr: 0.000007, loss: 0.0776
2022-10-05 18:41:58 - train: epoch 0094, iter [00740, 01251], lr: 0.000007, loss: 0.0848
2022-10-05 18:42:27 - train: epoch 0094, iter [00750, 01251], lr: 0.000007, loss: 0.0757
2022-10-05 18:42:55 - train: epoch 0094, iter [00760, 01251], lr: 0.000007, loss: 0.0859
2022-10-05 18:43:22 - train: epoch 0094, iter [00770, 01251], lr: 0.000007, loss: 0.0771
2022-10-05 18:43:50 - train: epoch 0094, iter [00780, 01251], lr: 0.000007, loss: 0.0688
2022-10-05 18:44:18 - train: epoch 0094, iter [00790, 01251], lr: 0.000007, loss: 0.0812
2022-10-05 18:44:46 - train: epoch 0094, iter [00800, 01251], lr: 0.000007, loss: 0.0794
2022-10-05 18:45:14 - train: epoch 0094, iter [00810, 01251], lr: 0.000007, loss: 0.0790
2022-10-05 18:45:42 - train: epoch 0094, iter [00820, 01251], lr: 0.000007, loss: 0.0810
2022-10-05 18:46:10 - train: epoch 0094, iter [00830, 01251], lr: 0.000007, loss: 0.0810
2022-10-05 18:46:38 - train: epoch 0094, iter [00840, 01251], lr: 0.000007, loss: 0.0739
2022-10-05 18:47:06 - train: epoch 0094, iter [00850, 01251], lr: 0.000007, loss: 0.0827
2022-10-05 18:47:34 - train: epoch 0094, iter [00860, 01251], lr: 0.000007, loss: 0.0770
2022-10-05 18:48:02 - train: epoch 0094, iter [00870, 01251], lr: 0.000007, loss: 0.0897
2022-10-05 18:48:30 - train: epoch 0094, iter [00880, 01251], lr: 0.000007, loss: 0.0794
2022-10-05 18:48:58 - train: epoch 0094, iter [00890, 01251], lr: 0.000007, loss: 0.0846
2022-10-05 18:49:26 - train: epoch 0094, iter [00900, 01251], lr: 0.000007, loss: 0.0732
2022-10-05 18:49:54 - train: epoch 0094, iter [00910, 01251], lr: 0.000007, loss: 0.0771
2022-10-05 18:50:22 - train: epoch 0094, iter [00920, 01251], lr: 0.000007, loss: 0.0843
2022-10-05 18:50:50 - train: epoch 0094, iter [00930, 01251], lr: 0.000007, loss: 0.0800
2022-10-05 18:51:18 - train: epoch 0094, iter [00940, 01251], lr: 0.000007, loss: 0.0818
2022-10-05 18:51:46 - train: epoch 0094, iter [00950, 01251], lr: 0.000007, loss: 0.0838
2022-10-05 18:52:14 - train: epoch 0094, iter [00960, 01251], lr: 0.000007, loss: 0.0850
2022-10-05 18:52:42 - train: epoch 0094, iter [00970, 01251], lr: 0.000007, loss: 0.0846
2022-10-05 18:53:10 - train: epoch 0094, iter [00980, 01251], lr: 0.000007, loss: 0.0744
2022-10-05 18:53:38 - train: epoch 0094, iter [00990, 01251], lr: 0.000007, loss: 0.0815
2022-10-05 18:54:06 - train: epoch 0094, iter [01000, 01251], lr: 0.000007, loss: 0.0750
2022-10-05 18:54:34 - train: epoch 0094, iter [01010, 01251], lr: 0.000007, loss: 0.0806
2022-10-05 18:55:02 - train: epoch 0094, iter [01020, 01251], lr: 0.000007, loss: 0.0796
2022-10-05 18:55:30 - train: epoch 0094, iter [01030, 01251], lr: 0.000007, loss: 0.0865
2022-10-05 18:55:58 - train: epoch 0094, iter [01040, 01251], lr: 0.000007, loss: 0.0849
2022-10-05 18:56:26 - train: epoch 0094, iter [01050, 01251], lr: 0.000007, loss: 0.0812
2022-10-05 18:56:54 - train: epoch 0094, iter [01060, 01251], lr: 0.000007, loss: 0.0833
2022-10-05 18:57:22 - train: epoch 0094, iter [01070, 01251], lr: 0.000007, loss: 0.0814
2022-10-05 18:57:50 - train: epoch 0094, iter [01080, 01251], lr: 0.000007, loss: 0.0759
2022-10-05 18:58:18 - train: epoch 0094, iter [01090, 01251], lr: 0.000007, loss: 0.0802
2022-10-05 18:58:46 - train: epoch 0094, iter [01100, 01251], lr: 0.000007, loss: 0.0806
2022-10-05 18:59:14 - train: epoch 0094, iter [01110, 01251], lr: 0.000007, loss: 0.0849
2022-10-05 18:59:42 - train: epoch 0094, iter [01120, 01251], lr: 0.000007, loss: 0.0776
2022-10-05 19:00:10 - train: epoch 0094, iter [01130, 01251], lr: 0.000007, loss: 0.0861
2022-10-05 19:00:38 - train: epoch 0094, iter [01140, 01251], lr: 0.000007, loss: 0.0793
2022-10-05 19:01:05 - train: epoch 0094, iter [01150, 01251], lr: 0.000007, loss: 0.0838
2022-10-05 19:01:33 - train: epoch 0094, iter [01160, 01251], lr: 0.000007, loss: 0.0762
2022-10-05 19:02:01 - train: epoch 0094, iter [01170, 01251], lr: 0.000007, loss: 0.0858
2022-10-05 19:02:29 - train: epoch 0094, iter [01180, 01251], lr: 0.000007, loss: 0.0787
2022-10-05 19:02:57 - train: epoch 0094, iter [01190, 01251], lr: 0.000007, loss: 0.0827
2022-10-05 19:03:25 - train: epoch 0094, iter [01200, 01251], lr: 0.000007, loss: 0.0803
2022-10-05 19:03:53 - train: epoch 0094, iter [01210, 01251], lr: 0.000007, loss: 0.0821
2022-10-05 19:04:20 - train: epoch 0094, iter [01220, 01251], lr: 0.000007, loss: 0.0804
2022-10-05 19:04:48 - train: epoch 0094, iter [01230, 01251], lr: 0.000007, loss: 0.0768
2022-10-05 19:05:16 - train: epoch 0094, iter [01240, 01251], lr: 0.000007, loss: 0.0800
2022-10-05 19:05:44 - train: epoch 0094, iter [01250, 01251], lr: 0.000007, loss: 0.0851
2022-10-05 19:05:48 - train: epoch 094, train_loss: 0.0811
2022-10-05 19:05:50 - until epoch: 094, best_loss: 0.0811
2022-10-05 19:05:50 - epoch 095 lr: 0.000007
2022-10-05 19:06:26 - train: epoch 0095, iter [00010, 01251], lr: 0.000007, loss: 0.0815
2022-10-05 19:06:54 - train: epoch 0095, iter [00020, 01251], lr: 0.000007, loss: 0.0759
2022-10-05 19:07:22 - train: epoch 0095, iter [00030, 01251], lr: 0.000007, loss: 0.0726
2022-10-05 19:07:50 - train: epoch 0095, iter [00040, 01251], lr: 0.000006, loss: 0.0772
2022-10-05 19:08:18 - train: epoch 0095, iter [00050, 01251], lr: 0.000006, loss: 0.0825
2022-10-05 19:08:46 - train: epoch 0095, iter [00060, 01251], lr: 0.000006, loss: 0.0856
2022-10-05 19:09:14 - train: epoch 0095, iter [00070, 01251], lr: 0.000006, loss: 0.0821
2022-10-05 19:09:42 - train: epoch 0095, iter [00080, 01251], lr: 0.000006, loss: 0.0769
2022-10-05 19:10:10 - train: epoch 0095, iter [00090, 01251], lr: 0.000006, loss: 0.0710
2022-10-05 19:10:38 - train: epoch 0095, iter [00100, 01251], lr: 0.000006, loss: 0.0781
2022-10-05 19:11:06 - train: epoch 0095, iter [00110, 01251], lr: 0.000006, loss: 0.0844
2022-10-05 19:11:33 - train: epoch 0095, iter [00120, 01251], lr: 0.000006, loss: 0.0757
2022-10-05 19:12:01 - train: epoch 0095, iter [00130, 01251], lr: 0.000006, loss: 0.0817
2022-10-05 19:12:29 - train: epoch 0095, iter [00140, 01251], lr: 0.000006, loss: 0.0772
2022-10-05 19:12:57 - train: epoch 0095, iter [00150, 01251], lr: 0.000006, loss: 0.0852
2022-10-05 19:13:25 - train: epoch 0095, iter [00160, 01251], lr: 0.000006, loss: 0.0813
2022-10-05 19:13:53 - train: epoch 0095, iter [00170, 01251], lr: 0.000006, loss: 0.0916
2022-10-05 19:14:21 - train: epoch 0095, iter [00180, 01251], lr: 0.000006, loss: 0.0792
2022-10-05 19:14:50 - train: epoch 0095, iter [00190, 01251], lr: 0.000006, loss: 0.0805
2022-10-05 19:15:18 - train: epoch 0095, iter [00200, 01251], lr: 0.000006, loss: 0.0846
2022-10-05 19:15:46 - train: epoch 0095, iter [00210, 01251], lr: 0.000006, loss: 0.0790
2022-10-05 19:16:13 - train: epoch 0095, iter [00220, 01251], lr: 0.000006, loss: 0.0770
2022-10-05 19:16:41 - train: epoch 0095, iter [00230, 01251], lr: 0.000006, loss: 0.0808
2022-10-05 19:17:09 - train: epoch 0095, iter [00240, 01251], lr: 0.000006, loss: 0.0804
2022-10-05 19:17:37 - train: epoch 0095, iter [00250, 01251], lr: 0.000006, loss: 0.0785
2022-10-05 19:18:05 - train: epoch 0095, iter [00260, 01251], lr: 0.000006, loss: 0.0799
2022-10-05 19:18:33 - train: epoch 0095, iter [00270, 01251], lr: 0.000006, loss: 0.0790
2022-10-05 19:19:01 - train: epoch 0095, iter [00280, 01251], lr: 0.000006, loss: 0.0869
2022-10-05 19:19:29 - train: epoch 0095, iter [00290, 01251], lr: 0.000006, loss: 0.0755
2022-10-05 19:19:57 - train: epoch 0095, iter [00300, 01251], lr: 0.000006, loss: 0.0819
2022-10-05 19:20:25 - train: epoch 0095, iter [00310, 01251], lr: 0.000006, loss: 0.0787
2022-10-05 19:20:53 - train: epoch 0095, iter [00320, 01251], lr: 0.000006, loss: 0.0815
2022-10-05 19:21:21 - train: epoch 0095, iter [00330, 01251], lr: 0.000006, loss: 0.0826
2022-10-05 19:21:49 - train: epoch 0095, iter [00340, 01251], lr: 0.000006, loss: 0.0781
2022-10-05 19:22:17 - train: epoch 0095, iter [00350, 01251], lr: 0.000006, loss: 0.0799
2022-10-05 19:22:45 - train: epoch 0095, iter [00360, 01251], lr: 0.000006, loss: 0.0798
2022-10-05 19:23:13 - train: epoch 0095, iter [00370, 01251], lr: 0.000006, loss: 0.0815
2022-10-05 19:23:41 - train: epoch 0095, iter [00380, 01251], lr: 0.000006, loss: 0.0808
2022-10-05 19:24:09 - train: epoch 0095, iter [00390, 01251], lr: 0.000006, loss: 0.0801
2022-10-05 19:24:37 - train: epoch 0095, iter [00400, 01251], lr: 0.000006, loss: 0.0885
2022-10-05 19:25:06 - train: epoch 0095, iter [00410, 01251], lr: 0.000006, loss: 0.0755
2022-10-05 19:25:34 - train: epoch 0095, iter [00420, 01251], lr: 0.000006, loss: 0.0804
2022-10-05 19:26:02 - train: epoch 0095, iter [00430, 01251], lr: 0.000006, loss: 0.0770
2022-10-05 19:26:30 - train: epoch 0095, iter [00440, 01251], lr: 0.000006, loss: 0.0744
2022-10-05 19:26:58 - train: epoch 0095, iter [00450, 01251], lr: 0.000006, loss: 0.0834
2022-10-05 19:27:26 - train: epoch 0095, iter [00460, 01251], lr: 0.000006, loss: 0.0814
2022-10-05 19:27:54 - train: epoch 0095, iter [00470, 01251], lr: 0.000006, loss: 0.0832
2022-10-05 19:28:22 - train: epoch 0095, iter [00480, 01251], lr: 0.000006, loss: 0.0857
2022-10-05 19:28:50 - train: epoch 0095, iter [00490, 01251], lr: 0.000006, loss: 0.0712
2022-10-05 19:29:18 - train: epoch 0095, iter [00500, 01251], lr: 0.000006, loss: 0.0757
2022-10-05 19:29:46 - train: epoch 0095, iter [00510, 01251], lr: 0.000006, loss: 0.0803
2022-10-05 19:30:14 - train: epoch 0095, iter [00520, 01251], lr: 0.000006, loss: 0.0782
2022-10-05 19:30:42 - train: epoch 0095, iter [00530, 01251], lr: 0.000006, loss: 0.0771
2022-10-05 19:31:10 - train: epoch 0095, iter [00540, 01251], lr: 0.000006, loss: 0.0833
2022-10-05 19:31:38 - train: epoch 0095, iter [00550, 01251], lr: 0.000006, loss: 0.0876
2022-10-05 19:32:06 - train: epoch 0095, iter [00560, 01251], lr: 0.000006, loss: 0.0733
2022-10-05 19:32:34 - train: epoch 0095, iter [00570, 01251], lr: 0.000006, loss: 0.0833
2022-10-05 19:33:02 - train: epoch 0095, iter [00580, 01251], lr: 0.000006, loss: 0.0857
2022-10-05 19:33:30 - train: epoch 0095, iter [00590, 01251], lr: 0.000006, loss: 0.0803
2022-10-05 19:33:58 - train: epoch 0095, iter [00600, 01251], lr: 0.000006, loss: 0.0884
2022-10-05 19:34:26 - train: epoch 0095, iter [00610, 01251], lr: 0.000006, loss: 0.0750
2022-10-05 19:34:54 - train: epoch 0095, iter [00620, 01251], lr: 0.000006, loss: 0.0846
2022-10-05 19:35:22 - train: epoch 0095, iter [00630, 01251], lr: 0.000006, loss: 0.0884
2022-10-05 19:35:50 - train: epoch 0095, iter [00640, 01251], lr: 0.000005, loss: 0.0807
2022-10-05 19:36:18 - train: epoch 0095, iter [00650, 01251], lr: 0.000005, loss: 0.0785
2022-10-05 19:36:45 - train: epoch 0095, iter [00660, 01251], lr: 0.000005, loss: 0.0785
2022-10-05 19:37:14 - train: epoch 0095, iter [00670, 01251], lr: 0.000005, loss: 0.0864
2022-10-05 19:37:42 - train: epoch 0095, iter [00680, 01251], lr: 0.000005, loss: 0.0837
2022-10-05 19:38:10 - train: epoch 0095, iter [00690, 01251], lr: 0.000005, loss: 0.0794
2022-10-05 19:38:38 - train: epoch 0095, iter [00700, 01251], lr: 0.000005, loss: 0.0729
2022-10-05 19:39:06 - train: epoch 0095, iter [00710, 01251], lr: 0.000005, loss: 0.0828
2022-10-05 19:39:34 - train: epoch 0095, iter [00720, 01251], lr: 0.000005, loss: 0.0795
2022-10-05 19:40:02 - train: epoch 0095, iter [00730, 01251], lr: 0.000005, loss: 0.0819
2022-10-05 19:40:30 - train: epoch 0095, iter [00740, 01251], lr: 0.000005, loss: 0.0774
2022-10-05 19:40:58 - train: epoch 0095, iter [00750, 01251], lr: 0.000005, loss: 0.0802
2022-10-05 19:41:26 - train: epoch 0095, iter [00760, 01251], lr: 0.000005, loss: 0.0791
2022-10-05 19:41:54 - train: epoch 0095, iter [00770, 01251], lr: 0.000005, loss: 0.0766
2022-10-05 19:42:22 - train: epoch 0095, iter [00780, 01251], lr: 0.000005, loss: 0.0816
2022-10-05 19:42:50 - train: epoch 0095, iter [00790, 01251], lr: 0.000005, loss: 0.0734
2022-10-05 19:43:18 - train: epoch 0095, iter [00800, 01251], lr: 0.000005, loss: 0.0773
2022-10-05 19:43:46 - train: epoch 0095, iter [00810, 01251], lr: 0.000005, loss: 0.0758
2022-10-05 19:44:14 - train: epoch 0095, iter [00820, 01251], lr: 0.000005, loss: 0.0853
2022-10-05 19:44:42 - train: epoch 0095, iter [00830, 01251], lr: 0.000005, loss: 0.0771
2022-10-05 19:45:10 - train: epoch 0095, iter [00840, 01251], lr: 0.000005, loss: 0.0799
2022-10-05 19:45:38 - train: epoch 0095, iter [00850, 01251], lr: 0.000005, loss: 0.0850
2022-10-05 19:46:06 - train: epoch 0095, iter [00860, 01251], lr: 0.000005, loss: 0.0821
2022-10-05 19:46:34 - train: epoch 0095, iter [00870, 01251], lr: 0.000005, loss: 0.0738
2022-10-05 19:47:02 - train: epoch 0095, iter [00880, 01251], lr: 0.000005, loss: 0.0779
2022-10-05 19:47:30 - train: epoch 0095, iter [00890, 01251], lr: 0.000005, loss: 0.0824
2022-10-05 19:47:58 - train: epoch 0095, iter [00900, 01251], lr: 0.000005, loss: 0.0815
2022-10-05 19:48:26 - train: epoch 0095, iter [00910, 01251], lr: 0.000005, loss: 0.0798
2022-10-05 19:48:54 - train: epoch 0095, iter [00920, 01251], lr: 0.000005, loss: 0.0825
2022-10-05 19:49:22 - train: epoch 0095, iter [00930, 01251], lr: 0.000005, loss: 0.0823
2022-10-05 19:49:50 - train: epoch 0095, iter [00940, 01251], lr: 0.000005, loss: 0.0769
2022-10-05 19:50:18 - train: epoch 0095, iter [00950, 01251], lr: 0.000005, loss: 0.0773
2022-10-05 19:50:46 - train: epoch 0095, iter [00960, 01251], lr: 0.000005, loss: 0.0863
2022-10-05 19:51:13 - train: epoch 0095, iter [00970, 01251], lr: 0.000005, loss: 0.0781
2022-10-05 19:51:41 - train: epoch 0095, iter [00980, 01251], lr: 0.000005, loss: 0.0863
2022-10-05 19:52:09 - train: epoch 0095, iter [00990, 01251], lr: 0.000005, loss: 0.0816
2022-10-05 19:52:37 - train: epoch 0095, iter [01000, 01251], lr: 0.000005, loss: 0.0772
2022-10-05 19:53:06 - train: epoch 0095, iter [01010, 01251], lr: 0.000005, loss: 0.0918
2022-10-05 19:53:34 - train: epoch 0095, iter [01020, 01251], lr: 0.000005, loss: 0.0894
2022-10-05 19:54:02 - train: epoch 0095, iter [01030, 01251], lr: 0.000005, loss: 0.0783
2022-10-05 19:54:30 - train: epoch 0095, iter [01040, 01251], lr: 0.000005, loss: 0.0819
2022-10-05 19:54:58 - train: epoch 0095, iter [01050, 01251], lr: 0.000005, loss: 0.0825
2022-10-05 19:55:26 - train: epoch 0095, iter [01060, 01251], lr: 0.000005, loss: 0.0826
2022-10-05 19:55:53 - train: epoch 0095, iter [01070, 01251], lr: 0.000005, loss: 0.0809
2022-10-05 19:56:21 - train: epoch 0095, iter [01080, 01251], lr: 0.000005, loss: 0.0843
2022-10-05 19:56:50 - train: epoch 0095, iter [01090, 01251], lr: 0.000005, loss: 0.0837
2022-10-05 19:57:18 - train: epoch 0095, iter [01100, 01251], lr: 0.000005, loss: 0.0785
2022-10-05 19:57:46 - train: epoch 0095, iter [01110, 01251], lr: 0.000005, loss: 0.0780
2022-10-05 19:58:14 - train: epoch 0095, iter [01120, 01251], lr: 0.000005, loss: 0.0903
2022-10-05 19:58:42 - train: epoch 0095, iter [01130, 01251], lr: 0.000005, loss: 0.0821
2022-10-05 19:59:10 - train: epoch 0095, iter [01140, 01251], lr: 0.000005, loss: 0.0866
2022-10-05 19:59:38 - train: epoch 0095, iter [01150, 01251], lr: 0.000005, loss: 0.0842
2022-10-05 20:00:06 - train: epoch 0095, iter [01160, 01251], lr: 0.000005, loss: 0.0794
2022-10-05 20:00:34 - train: epoch 0095, iter [01170, 01251], lr: 0.000005, loss: 0.0861
2022-10-05 20:01:02 - train: epoch 0095, iter [01180, 01251], lr: 0.000005, loss: 0.0884
2022-10-05 20:01:30 - train: epoch 0095, iter [01190, 01251], lr: 0.000005, loss: 0.0821
2022-10-05 20:01:58 - train: epoch 0095, iter [01200, 01251], lr: 0.000005, loss: 0.0806
2022-10-05 20:02:26 - train: epoch 0095, iter [01210, 01251], lr: 0.000005, loss: 0.0835
2022-10-05 20:02:54 - train: epoch 0095, iter [01220, 01251], lr: 0.000005, loss: 0.0773
2022-10-05 20:03:22 - train: epoch 0095, iter [01230, 01251], lr: 0.000005, loss: 0.0828
2022-10-05 20:03:50 - train: epoch 0095, iter [01240, 01251], lr: 0.000005, loss: 0.0832
2022-10-05 20:04:18 - train: epoch 0095, iter [01250, 01251], lr: 0.000005, loss: 0.0742
2022-10-05 20:04:22 - train: epoch 095, train_loss: 0.0810
2022-10-05 20:04:23 - until epoch: 095, best_loss: 0.0810
2022-10-05 20:04:23 - epoch 096 lr: 0.000005
2022-10-05 20:04:59 - train: epoch 0096, iter [00010, 01251], lr: 0.000005, loss: 0.0752
2022-10-05 20:05:27 - train: epoch 0096, iter [00020, 01251], lr: 0.000005, loss: 0.0853
2022-10-05 20:05:55 - train: epoch 0096, iter [00030, 01251], lr: 0.000005, loss: 0.0758
2022-10-05 20:06:23 - train: epoch 0096, iter [00040, 01251], lr: 0.000004, loss: 0.0900
2022-10-05 20:06:51 - train: epoch 0096, iter [00050, 01251], lr: 0.000004, loss: 0.0846
2022-10-05 20:07:18 - train: epoch 0096, iter [00060, 01251], lr: 0.000004, loss: 0.0829
2022-10-05 20:07:46 - train: epoch 0096, iter [00070, 01251], lr: 0.000004, loss: 0.0770
2022-10-05 20:08:14 - train: epoch 0096, iter [00080, 01251], lr: 0.000004, loss: 0.0780
2022-10-05 20:08:42 - train: epoch 0096, iter [00090, 01251], lr: 0.000004, loss: 0.0840
2022-10-05 20:09:10 - train: epoch 0096, iter [00100, 01251], lr: 0.000004, loss: 0.0825
2022-10-05 20:09:38 - train: epoch 0096, iter [00110, 01251], lr: 0.000004, loss: 0.0783
2022-10-05 20:10:06 - train: epoch 0096, iter [00120, 01251], lr: 0.000004, loss: 0.0784
2022-10-05 20:10:33 - train: epoch 0096, iter [00130, 01251], lr: 0.000004, loss: 0.0777
2022-10-05 20:11:01 - train: epoch 0096, iter [00140, 01251], lr: 0.000004, loss: 0.0734
2022-10-05 20:11:29 - train: epoch 0096, iter [00150, 01251], lr: 0.000004, loss: 0.0780
2022-10-05 20:11:57 - train: epoch 0096, iter [00160, 01251], lr: 0.000004, loss: 0.0815
2022-10-05 20:12:25 - train: epoch 0096, iter [00170, 01251], lr: 0.000004, loss: 0.0812
2022-10-05 20:12:52 - train: epoch 0096, iter [00180, 01251], lr: 0.000004, loss: 0.0765
2022-10-05 20:13:20 - train: epoch 0096, iter [00190, 01251], lr: 0.000004, loss: 0.0761
2022-10-05 20:13:48 - train: epoch 0096, iter [00200, 01251], lr: 0.000004, loss: 0.0872
2022-10-05 20:14:16 - train: epoch 0096, iter [00210, 01251], lr: 0.000004, loss: 0.0766
2022-10-05 20:14:44 - train: epoch 0096, iter [00220, 01251], lr: 0.000004, loss: 0.0818
2022-10-05 20:15:11 - train: epoch 0096, iter [00230, 01251], lr: 0.000004, loss: 0.0891
2022-10-05 20:15:39 - train: epoch 0096, iter [00240, 01251], lr: 0.000004, loss: 0.0841
2022-10-05 20:16:07 - train: epoch 0096, iter [00250, 01251], lr: 0.000004, loss: 0.0771
2022-10-05 20:16:35 - train: epoch 0096, iter [00260, 01251], lr: 0.000004, loss: 0.0736
2022-10-05 20:17:03 - train: epoch 0096, iter [00270, 01251], lr: 0.000004, loss: 0.0833
2022-10-05 20:17:31 - train: epoch 0096, iter [00280, 01251], lr: 0.000004, loss: 0.0779
2022-10-05 20:17:59 - train: epoch 0096, iter [00290, 01251], lr: 0.000004, loss: 0.0793
2022-10-05 20:18:26 - train: epoch 0096, iter [00300, 01251], lr: 0.000004, loss: 0.0872
2022-10-05 20:18:54 - train: epoch 0096, iter [00310, 01251], lr: 0.000004, loss: 0.0751
2022-10-05 20:19:22 - train: epoch 0096, iter [00320, 01251], lr: 0.000004, loss: 0.0819
2022-10-05 20:19:50 - train: epoch 0096, iter [00330, 01251], lr: 0.000004, loss: 0.0764
2022-10-05 20:20:18 - train: epoch 0096, iter [00340, 01251], lr: 0.000004, loss: 0.0795
2022-10-05 20:20:46 - train: epoch 0096, iter [00350, 01251], lr: 0.000004, loss: 0.0794
2022-10-05 20:21:14 - train: epoch 0096, iter [00360, 01251], lr: 0.000004, loss: 0.0757
2022-10-05 20:21:42 - train: epoch 0096, iter [00370, 01251], lr: 0.000004, loss: 0.0786
2022-10-05 20:22:10 - train: epoch 0096, iter [00380, 01251], lr: 0.000004, loss: 0.0915
2022-10-05 20:22:38 - train: epoch 0096, iter [00390, 01251], lr: 0.000004, loss: 0.0845
2022-10-05 20:23:06 - train: epoch 0096, iter [00400, 01251], lr: 0.000004, loss: 0.0834
2022-10-05 20:23:33 - train: epoch 0096, iter [00410, 01251], lr: 0.000004, loss: 0.0754
2022-10-05 20:24:01 - train: epoch 0096, iter [00420, 01251], lr: 0.000004, loss: 0.0847
2022-10-05 20:24:29 - train: epoch 0096, iter [00430, 01251], lr: 0.000004, loss: 0.0785
2022-10-05 20:24:57 - train: epoch 0096, iter [00440, 01251], lr: 0.000004, loss: 0.0797
2022-10-05 20:25:25 - train: epoch 0096, iter [00450, 01251], lr: 0.000004, loss: 0.0761
2022-10-05 20:25:53 - train: epoch 0096, iter [00460, 01251], lr: 0.000004, loss: 0.0865
2022-10-05 20:26:21 - train: epoch 0096, iter [00470, 01251], lr: 0.000004, loss: 0.0846
2022-10-05 20:26:48 - train: epoch 0096, iter [00480, 01251], lr: 0.000004, loss: 0.0799
2022-10-05 20:27:16 - train: epoch 0096, iter [00490, 01251], lr: 0.000004, loss: 0.0790
2022-10-05 20:27:44 - train: epoch 0096, iter [00500, 01251], lr: 0.000004, loss: 0.0782
2022-10-05 20:28:12 - train: epoch 0096, iter [00510, 01251], lr: 0.000004, loss: 0.0841
2022-10-05 20:28:39 - train: epoch 0096, iter [00520, 01251], lr: 0.000004, loss: 0.0762
2022-10-05 20:29:07 - train: epoch 0096, iter [00530, 01251], lr: 0.000004, loss: 0.0825
2022-10-05 20:29:35 - train: epoch 0096, iter [00540, 01251], lr: 0.000004, loss: 0.0850
2022-10-05 20:30:03 - train: epoch 0096, iter [00550, 01251], lr: 0.000004, loss: 0.0774
2022-10-05 20:30:31 - train: epoch 0096, iter [00560, 01251], lr: 0.000004, loss: 0.0847
2022-10-05 20:30:59 - train: epoch 0096, iter [00570, 01251], lr: 0.000004, loss: 0.0818
2022-10-05 20:31:27 - train: epoch 0096, iter [00580, 01251], lr: 0.000004, loss: 0.0830
2022-10-05 20:31:54 - train: epoch 0096, iter [00590, 01251], lr: 0.000004, loss: 0.0821
2022-10-05 20:32:22 - train: epoch 0096, iter [00600, 01251], lr: 0.000004, loss: 0.0844
2022-10-05 20:32:50 - train: epoch 0096, iter [00610, 01251], lr: 0.000004, loss: 0.0793
2022-10-05 20:33:18 - train: epoch 0096, iter [00620, 01251], lr: 0.000004, loss: 0.0738
2022-10-05 20:33:45 - train: epoch 0096, iter [00630, 01251], lr: 0.000004, loss: 0.0799
2022-10-05 20:34:13 - train: epoch 0096, iter [00640, 01251], lr: 0.000004, loss: 0.0854
2022-10-05 20:34:41 - train: epoch 0096, iter [00650, 01251], lr: 0.000004, loss: 0.0827
2022-10-05 20:35:09 - train: epoch 0096, iter [00660, 01251], lr: 0.000004, loss: 0.0751
2022-10-05 20:35:36 - train: epoch 0096, iter [00670, 01251], lr: 0.000004, loss: 0.0814
2022-10-05 20:36:04 - train: epoch 0096, iter [00680, 01251], lr: 0.000004, loss: 0.0814
2022-10-05 20:36:32 - train: epoch 0096, iter [00690, 01251], lr: 0.000004, loss: 0.0857
2022-10-05 20:37:00 - train: epoch 0096, iter [00700, 01251], lr: 0.000004, loss: 0.0752
2022-10-05 20:37:27 - train: epoch 0096, iter [00710, 01251], lr: 0.000004, loss: 0.0751
2022-10-05 20:37:55 - train: epoch 0096, iter [00720, 01251], lr: 0.000004, loss: 0.0802
2022-10-05 20:38:23 - train: epoch 0096, iter [00730, 01251], lr: 0.000004, loss: 0.0769
2022-10-05 20:38:51 - train: epoch 0096, iter [00740, 01251], lr: 0.000004, loss: 0.0821
2022-10-05 20:39:19 - train: epoch 0096, iter [00750, 01251], lr: 0.000004, loss: 0.0782
2022-10-05 20:39:47 - train: epoch 0096, iter [00760, 01251], lr: 0.000004, loss: 0.0859
2022-10-05 20:40:15 - train: epoch 0096, iter [00770, 01251], lr: 0.000004, loss: 0.0863
2022-10-05 20:40:43 - train: epoch 0096, iter [00780, 01251], lr: 0.000003, loss: 0.0878
2022-10-05 20:41:10 - train: epoch 0096, iter [00790, 01251], lr: 0.000003, loss: 0.0828
2022-10-05 20:41:38 - train: epoch 0096, iter [00800, 01251], lr: 0.000003, loss: 0.0806
2022-10-05 20:42:06 - train: epoch 0096, iter [00810, 01251], lr: 0.000003, loss: 0.0809
2022-10-05 20:42:34 - train: epoch 0096, iter [00820, 01251], lr: 0.000003, loss: 0.0780
2022-10-05 20:43:02 - train: epoch 0096, iter [00830, 01251], lr: 0.000003, loss: 0.0777
2022-10-05 20:43:30 - train: epoch 0096, iter [00840, 01251], lr: 0.000003, loss: 0.0807
2022-10-05 20:43:58 - train: epoch 0096, iter [00850, 01251], lr: 0.000003, loss: 0.0823
2022-10-05 20:44:26 - train: epoch 0096, iter [00860, 01251], lr: 0.000003, loss: 0.0779
2022-10-05 20:44:53 - train: epoch 0096, iter [00870, 01251], lr: 0.000003, loss: 0.0764
2022-10-05 20:45:21 - train: epoch 0096, iter [00880, 01251], lr: 0.000003, loss: 0.0771
2022-10-05 20:45:49 - train: epoch 0096, iter [00890, 01251], lr: 0.000003, loss: 0.0869
2022-10-05 20:46:17 - train: epoch 0096, iter [00900, 01251], lr: 0.000003, loss: 0.0730
2022-10-05 20:46:45 - train: epoch 0096, iter [00910, 01251], lr: 0.000003, loss: 0.0898
2022-10-05 20:47:13 - train: epoch 0096, iter [00920, 01251], lr: 0.000003, loss: 0.0809
2022-10-05 20:47:41 - train: epoch 0096, iter [00930, 01251], lr: 0.000003, loss: 0.0870
2022-10-05 20:48:09 - train: epoch 0096, iter [00940, 01251], lr: 0.000003, loss: 0.0940
2022-10-05 20:48:36 - train: epoch 0096, iter [00950, 01251], lr: 0.000003, loss: 0.0762
2022-10-05 20:49:04 - train: epoch 0096, iter [00960, 01251], lr: 0.000003, loss: 0.0903
2022-10-05 20:49:32 - train: epoch 0096, iter [00970, 01251], lr: 0.000003, loss: 0.0763
2022-10-05 20:50:00 - train: epoch 0096, iter [00980, 01251], lr: 0.000003, loss: 0.0819
2022-10-05 20:50:28 - train: epoch 0096, iter [00990, 01251], lr: 0.000003, loss: 0.0818
2022-10-05 20:50:55 - train: epoch 0096, iter [01000, 01251], lr: 0.000003, loss: 0.0827
2022-10-05 20:51:23 - train: epoch 0096, iter [01010, 01251], lr: 0.000003, loss: 0.0834
2022-10-05 20:51:51 - train: epoch 0096, iter [01020, 01251], lr: 0.000003, loss: 0.0844
2022-10-05 20:52:19 - train: epoch 0096, iter [01030, 01251], lr: 0.000003, loss: 0.0818
2022-10-05 20:52:47 - train: epoch 0096, iter [01040, 01251], lr: 0.000003, loss: 0.0814
2022-10-05 20:53:15 - train: epoch 0096, iter [01050, 01251], lr: 0.000003, loss: 0.0852
2022-10-05 20:53:43 - train: epoch 0096, iter [01060, 01251], lr: 0.000003, loss: 0.0908
2022-10-05 20:54:10 - train: epoch 0096, iter [01070, 01251], lr: 0.000003, loss: 0.0933
2022-10-05 20:54:38 - train: epoch 0096, iter [01080, 01251], lr: 0.000003, loss: 0.0822
2022-10-05 20:55:06 - train: epoch 0096, iter [01090, 01251], lr: 0.000003, loss: 0.0875
2022-10-05 20:55:34 - train: epoch 0096, iter [01100, 01251], lr: 0.000003, loss: 0.0735
2022-10-05 20:56:02 - train: epoch 0096, iter [01110, 01251], lr: 0.000003, loss: 0.0774
2022-10-05 20:56:30 - train: epoch 0096, iter [01120, 01251], lr: 0.000003, loss: 0.0743
2022-10-05 20:56:57 - train: epoch 0096, iter [01130, 01251], lr: 0.000003, loss: 0.0803
2022-10-05 20:57:25 - train: epoch 0096, iter [01140, 01251], lr: 0.000003, loss: 0.0859
2022-10-05 20:57:53 - train: epoch 0096, iter [01150, 01251], lr: 0.000003, loss: 0.0830
2022-10-05 20:58:21 - train: epoch 0096, iter [01160, 01251], lr: 0.000003, loss: 0.0830
2022-10-05 20:58:49 - train: epoch 0096, iter [01170, 01251], lr: 0.000003, loss: 0.0794
2022-10-05 20:59:17 - train: epoch 0096, iter [01180, 01251], lr: 0.000003, loss: 0.0853
2022-10-05 20:59:45 - train: epoch 0096, iter [01190, 01251], lr: 0.000003, loss: 0.0883
2022-10-05 21:00:13 - train: epoch 0096, iter [01200, 01251], lr: 0.000003, loss: 0.0758
2022-10-05 21:00:41 - train: epoch 0096, iter [01210, 01251], lr: 0.000003, loss: 0.0808
2022-10-05 21:01:08 - train: epoch 0096, iter [01220, 01251], lr: 0.000003, loss: 0.0806
2022-10-05 21:01:36 - train: epoch 0096, iter [01230, 01251], lr: 0.000003, loss: 0.0766
2022-10-05 21:02:04 - train: epoch 0096, iter [01240, 01251], lr: 0.000003, loss: 0.0881
2022-10-05 21:02:31 - train: epoch 0096, iter [01250, 01251], lr: 0.000003, loss: 0.0816
2022-10-05 21:02:36 - train: epoch 096, train_loss: 0.0810
2022-10-05 21:02:37 - until epoch: 096, best_loss: 0.0810
2022-10-05 21:02:37 - epoch 097 lr: 0.000003
2022-10-05 21:03:12 - train: epoch 0097, iter [00010, 01251], lr: 0.000003, loss: 0.0780
2022-10-05 21:03:40 - train: epoch 0097, iter [00020, 01251], lr: 0.000003, loss: 0.0852
2022-10-05 21:04:08 - train: epoch 0097, iter [00030, 01251], lr: 0.000003, loss: 0.0889
2022-10-05 21:04:36 - train: epoch 0097, iter [00040, 01251], lr: 0.000003, loss: 0.0756
2022-10-05 21:05:04 - train: epoch 0097, iter [00050, 01251], lr: 0.000003, loss: 0.0820
2022-10-05 21:05:31 - train: epoch 0097, iter [00060, 01251], lr: 0.000003, loss: 0.0804
2022-10-05 21:05:59 - train: epoch 0097, iter [00070, 01251], lr: 0.000003, loss: 0.0869
2022-10-05 21:06:27 - train: epoch 0097, iter [00080, 01251], lr: 0.000003, loss: 0.0752
2022-10-05 21:06:55 - train: epoch 0097, iter [00090, 01251], lr: 0.000003, loss: 0.0829
2022-10-05 21:07:22 - train: epoch 0097, iter [00100, 01251], lr: 0.000003, loss: 0.0815
2022-10-05 21:07:50 - train: epoch 0097, iter [00110, 01251], lr: 0.000003, loss: 0.0768
2022-10-05 21:08:18 - train: epoch 0097, iter [00120, 01251], lr: 0.000003, loss: 0.0751
2022-10-05 21:08:45 - train: epoch 0097, iter [00130, 01251], lr: 0.000003, loss: 0.0766
2022-10-05 21:09:13 - train: epoch 0097, iter [00140, 01251], lr: 0.000003, loss: 0.0828
2022-10-05 21:09:41 - train: epoch 0097, iter [00150, 01251], lr: 0.000003, loss: 0.0777
2022-10-05 21:10:09 - train: epoch 0097, iter [00160, 01251], lr: 0.000003, loss: 0.0772
2022-10-05 21:10:37 - train: epoch 0097, iter [00170, 01251], lr: 0.000003, loss: 0.0853
2022-10-05 21:11:05 - train: epoch 0097, iter [00180, 01251], lr: 0.000003, loss: 0.0786
2022-10-05 21:11:32 - train: epoch 0097, iter [00190, 01251], lr: 0.000003, loss: 0.0801
2022-10-05 21:12:00 - train: epoch 0097, iter [00200, 01251], lr: 0.000003, loss: 0.0785
2022-10-05 21:12:28 - train: epoch 0097, iter [00210, 01251], lr: 0.000003, loss: 0.0699
2022-10-05 21:12:56 - train: epoch 0097, iter [00220, 01251], lr: 0.000003, loss: 0.0859
2022-10-05 21:13:24 - train: epoch 0097, iter [00230, 01251], lr: 0.000003, loss: 0.0768
2022-10-05 21:13:52 - train: epoch 0097, iter [00240, 01251], lr: 0.000003, loss: 0.0741
2022-10-05 21:14:19 - train: epoch 0097, iter [00250, 01251], lr: 0.000003, loss: 0.0855
2022-10-05 21:14:47 - train: epoch 0097, iter [00260, 01251], lr: 0.000003, loss: 0.0858
2022-10-05 21:15:15 - train: epoch 0097, iter [00270, 01251], lr: 0.000003, loss: 0.0892
2022-10-05 21:15:43 - train: epoch 0097, iter [00280, 01251], lr: 0.000003, loss: 0.0831
2022-10-05 21:16:11 - train: epoch 0097, iter [00290, 01251], lr: 0.000003, loss: 0.0849
2022-10-05 21:16:38 - train: epoch 0097, iter [00300, 01251], lr: 0.000003, loss: 0.0887
2022-10-05 21:17:06 - train: epoch 0097, iter [00310, 01251], lr: 0.000003, loss: 0.0816
2022-10-05 21:17:34 - train: epoch 0097, iter [00320, 01251], lr: 0.000003, loss: 0.0875
2022-10-05 21:18:02 - train: epoch 0097, iter [00330, 01251], lr: 0.000003, loss: 0.0782
2022-10-05 21:18:30 - train: epoch 0097, iter [00340, 01251], lr: 0.000003, loss: 0.0809
2022-10-05 21:18:57 - train: epoch 0097, iter [00350, 01251], lr: 0.000003, loss: 0.0762
2022-10-05 21:19:25 - train: epoch 0097, iter [00360, 01251], lr: 0.000003, loss: 0.0884
2022-10-05 21:19:53 - train: epoch 0097, iter [00370, 01251], lr: 0.000003, loss: 0.0848
2022-10-05 21:20:21 - train: epoch 0097, iter [00380, 01251], lr: 0.000002, loss: 0.0838
2022-10-05 21:20:49 - train: epoch 0097, iter [00390, 01251], lr: 0.000002, loss: 0.0788
2022-10-05 21:21:17 - train: epoch 0097, iter [00400, 01251], lr: 0.000002, loss: 0.0853
2022-10-05 21:21:44 - train: epoch 0097, iter [00410, 01251], lr: 0.000002, loss: 0.0808
2022-10-05 21:22:12 - train: epoch 0097, iter [00420, 01251], lr: 0.000002, loss: 0.0831
2022-10-05 21:22:40 - train: epoch 0097, iter [00430, 01251], lr: 0.000002, loss: 0.0735
2022-10-05 21:23:08 - train: epoch 0097, iter [00440, 01251], lr: 0.000002, loss: 0.0768
2022-10-05 21:23:35 - train: epoch 0097, iter [00450, 01251], lr: 0.000002, loss: 0.0827
2022-10-05 21:24:03 - train: epoch 0097, iter [00460, 01251], lr: 0.000002, loss: 0.0850
2022-10-05 21:24:31 - train: epoch 0097, iter [00470, 01251], lr: 0.000002, loss: 0.0772
2022-10-05 21:24:59 - train: epoch 0097, iter [00480, 01251], lr: 0.000002, loss: 0.0802
2022-10-05 21:25:27 - train: epoch 0097, iter [00490, 01251], lr: 0.000002, loss: 0.0816
2022-10-05 21:25:55 - train: epoch 0097, iter [00500, 01251], lr: 0.000002, loss: 0.0814
2022-10-05 21:26:22 - train: epoch 0097, iter [00510, 01251], lr: 0.000002, loss: 0.0810
2022-10-05 21:26:50 - train: epoch 0097, iter [00520, 01251], lr: 0.000002, loss: 0.0770
2022-10-05 21:27:18 - train: epoch 0097, iter [00530, 01251], lr: 0.000002, loss: 0.0796
2022-10-05 21:27:46 - train: epoch 0097, iter [00540, 01251], lr: 0.000002, loss: 0.0829
2022-10-05 21:28:14 - train: epoch 0097, iter [00550, 01251], lr: 0.000002, loss: 0.0888
2022-10-05 21:28:42 - train: epoch 0097, iter [00560, 01251], lr: 0.000002, loss: 0.0778
2022-10-05 21:29:10 - train: epoch 0097, iter [00570, 01251], lr: 0.000002, loss: 0.0763
2022-10-05 21:29:38 - train: epoch 0097, iter [00580, 01251], lr: 0.000002, loss: 0.0828
2022-10-05 21:30:06 - train: epoch 0097, iter [00590, 01251], lr: 0.000002, loss: 0.0742
2022-10-05 21:30:33 - train: epoch 0097, iter [00600, 01251], lr: 0.000002, loss: 0.0767
2022-10-05 21:31:01 - train: epoch 0097, iter [00610, 01251], lr: 0.000002, loss: 0.0810
2022-10-05 21:31:29 - train: epoch 0097, iter [00620, 01251], lr: 0.000002, loss: 0.0757
2022-10-05 21:31:57 - train: epoch 0097, iter [00630, 01251], lr: 0.000002, loss: 0.0929
2022-10-05 21:32:25 - train: epoch 0097, iter [00640, 01251], lr: 0.000002, loss: 0.0818
2022-10-05 21:32:53 - train: epoch 0097, iter [00650, 01251], lr: 0.000002, loss: 0.0761
2022-10-05 21:33:21 - train: epoch 0097, iter [00660, 01251], lr: 0.000002, loss: 0.0759
2022-10-05 21:33:49 - train: epoch 0097, iter [00670, 01251], lr: 0.000002, loss: 0.0822
2022-10-05 21:34:16 - train: epoch 0097, iter [00680, 01251], lr: 0.000002, loss: 0.0891
2022-10-05 21:34:44 - train: epoch 0097, iter [00690, 01251], lr: 0.000002, loss: 0.0853
2022-10-05 21:35:12 - train: epoch 0097, iter [00700, 01251], lr: 0.000002, loss: 0.0762
2022-10-05 21:35:40 - train: epoch 0097, iter [00710, 01251], lr: 0.000002, loss: 0.0896
2022-10-05 21:36:07 - train: epoch 0097, iter [00720, 01251], lr: 0.000002, loss: 0.0851
2022-10-05 21:36:35 - train: epoch 0097, iter [00730, 01251], lr: 0.000002, loss: 0.0832
2022-10-05 21:37:03 - train: epoch 0097, iter [00740, 01251], lr: 0.000002, loss: 0.0729
2022-10-05 21:37:31 - train: epoch 0097, iter [00750, 01251], lr: 0.000002, loss: 0.0784
2022-10-05 21:37:59 - train: epoch 0097, iter [00760, 01251], lr: 0.000002, loss: 0.0812
2022-10-05 21:38:27 - train: epoch 0097, iter [00770, 01251], lr: 0.000002, loss: 0.0780
2022-10-05 21:38:54 - train: epoch 0097, iter [00780, 01251], lr: 0.000002, loss: 0.0729
2022-10-05 21:39:22 - train: epoch 0097, iter [00790, 01251], lr: 0.000002, loss: 0.0853
2022-10-05 21:39:50 - train: epoch 0097, iter [00800, 01251], lr: 0.000002, loss: 0.0764
2022-10-05 21:40:18 - train: epoch 0097, iter [00810, 01251], lr: 0.000002, loss: 0.0822
2022-10-05 21:40:45 - train: epoch 0097, iter [00820, 01251], lr: 0.000002, loss: 0.0834
2022-10-05 21:41:13 - train: epoch 0097, iter [00830, 01251], lr: 0.000002, loss: 0.0830
2022-10-05 21:41:41 - train: epoch 0097, iter [00840, 01251], lr: 0.000002, loss: 0.0759
2022-10-05 21:42:09 - train: epoch 0097, iter [00850, 01251], lr: 0.000002, loss: 0.0845
2022-10-05 21:42:36 - train: epoch 0097, iter [00860, 01251], lr: 0.000002, loss: 0.0788
2022-10-05 21:43:04 - train: epoch 0097, iter [00870, 01251], lr: 0.000002, loss: 0.0802
2022-10-05 21:43:32 - train: epoch 0097, iter [00880, 01251], lr: 0.000002, loss: 0.0781
2022-10-05 21:44:00 - train: epoch 0097, iter [00890, 01251], lr: 0.000002, loss: 0.0791
2022-10-05 21:44:28 - train: epoch 0097, iter [00900, 01251], lr: 0.000002, loss: 0.0743
2022-10-05 21:44:56 - train: epoch 0097, iter [00910, 01251], lr: 0.000002, loss: 0.0838
2022-10-05 21:45:23 - train: epoch 0097, iter [00920, 01251], lr: 0.000002, loss: 0.0805
2022-10-05 21:45:51 - train: epoch 0097, iter [00930, 01251], lr: 0.000002, loss: 0.0825
2022-10-05 21:46:19 - train: epoch 0097, iter [00940, 01251], lr: 0.000002, loss: 0.0799
2022-10-05 21:46:47 - train: epoch 0097, iter [00950, 01251], lr: 0.000002, loss: 0.0768
2022-10-05 21:47:14 - train: epoch 0097, iter [00960, 01251], lr: 0.000002, loss: 0.0842
2022-10-05 21:47:42 - train: epoch 0097, iter [00970, 01251], lr: 0.000002, loss: 0.0853
2022-10-05 21:48:10 - train: epoch 0097, iter [00980, 01251], lr: 0.000002, loss: 0.0839
2022-10-05 21:48:38 - train: epoch 0097, iter [00990, 01251], lr: 0.000002, loss: 0.0819
2022-10-05 21:49:06 - train: epoch 0097, iter [01000, 01251], lr: 0.000002, loss: 0.0798
2022-10-05 21:49:33 - train: epoch 0097, iter [01010, 01251], lr: 0.000002, loss: 0.0756
2022-10-05 21:50:01 - train: epoch 0097, iter [01020, 01251], lr: 0.000002, loss: 0.0827
2022-10-05 21:50:29 - train: epoch 0097, iter [01030, 01251], lr: 0.000002, loss: 0.0783
2022-10-05 21:50:57 - train: epoch 0097, iter [01040, 01251], lr: 0.000002, loss: 0.0814
2022-10-05 21:51:25 - train: epoch 0097, iter [01050, 01251], lr: 0.000002, loss: 0.0874
2022-10-05 21:51:53 - train: epoch 0097, iter [01060, 01251], lr: 0.000002, loss: 0.0794
2022-10-05 21:52:20 - train: epoch 0097, iter [01070, 01251], lr: 0.000002, loss: 0.0788
2022-10-05 21:52:48 - train: epoch 0097, iter [01080, 01251], lr: 0.000002, loss: 0.0821
2022-10-05 21:53:16 - train: epoch 0097, iter [01090, 01251], lr: 0.000002, loss: 0.0771
2022-10-05 21:53:44 - train: epoch 0097, iter [01100, 01251], lr: 0.000002, loss: 0.0852
2022-10-05 21:54:12 - train: epoch 0097, iter [01110, 01251], lr: 0.000002, loss: 0.0796
2022-10-05 21:54:40 - train: epoch 0097, iter [01120, 01251], lr: 0.000002, loss: 0.0709
2022-10-05 21:55:08 - train: epoch 0097, iter [01130, 01251], lr: 0.000002, loss: 0.0791
2022-10-05 21:55:36 - train: epoch 0097, iter [01140, 01251], lr: 0.000002, loss: 0.0812
2022-10-05 21:56:04 - train: epoch 0097, iter [01150, 01251], lr: 0.000002, loss: 0.0804
2022-10-05 21:56:31 - train: epoch 0097, iter [01160, 01251], lr: 0.000002, loss: 0.0767
2022-10-05 21:56:59 - train: epoch 0097, iter [01170, 01251], lr: 0.000002, loss: 0.0777
2022-10-05 21:57:27 - train: epoch 0097, iter [01180, 01251], lr: 0.000002, loss: 0.0823
2022-10-05 21:57:55 - train: epoch 0097, iter [01190, 01251], lr: 0.000002, loss: 0.0799
2022-10-05 21:58:23 - train: epoch 0097, iter [01200, 01251], lr: 0.000002, loss: 0.0768
2022-10-05 21:58:51 - train: epoch 0097, iter [01210, 01251], lr: 0.000002, loss: 0.0890
2022-10-05 21:59:19 - train: epoch 0097, iter [01220, 01251], lr: 0.000002, loss: 0.0761
2022-10-05 21:59:46 - train: epoch 0097, iter [01230, 01251], lr: 0.000002, loss: 0.0781
2022-10-05 22:00:14 - train: epoch 0097, iter [01240, 01251], lr: 0.000002, loss: 0.0843
2022-10-05 22:00:42 - train: epoch 0097, iter [01250, 01251], lr: 0.000002, loss: 0.0812
2022-10-05 22:00:46 - train: epoch 097, train_loss: 0.0809
2022-10-05 22:00:48 - until epoch: 097, best_loss: 0.0809
2022-10-05 22:00:48 - epoch 098 lr: 0.000002
2022-10-05 22:01:24 - train: epoch 0098, iter [00010, 01251], lr: 0.000002, loss: 0.0894
2022-10-05 22:01:51 - train: epoch 0098, iter [00020, 01251], lr: 0.000002, loss: 0.0779
2022-10-05 22:02:19 - train: epoch 0098, iter [00030, 01251], lr: 0.000002, loss: 0.0747
2022-10-05 22:02:47 - train: epoch 0098, iter [00040, 01251], lr: 0.000002, loss: 0.0808
2022-10-05 22:03:15 - train: epoch 0098, iter [00050, 01251], lr: 0.000002, loss: 0.0786
2022-10-05 22:03:43 - train: epoch 0098, iter [00060, 01251], lr: 0.000002, loss: 0.0817
2022-10-05 22:04:11 - train: epoch 0098, iter [00070, 01251], lr: 0.000002, loss: 0.0737
2022-10-05 22:04:38 - train: epoch 0098, iter [00080, 01251], lr: 0.000002, loss: 0.0804
2022-10-05 22:05:06 - train: epoch 0098, iter [00090, 01251], lr: 0.000002, loss: 0.0723
2022-10-05 22:05:34 - train: epoch 0098, iter [00100, 01251], lr: 0.000002, loss: 0.0768
2022-10-05 22:06:01 - train: epoch 0098, iter [00110, 01251], lr: 0.000002, loss: 0.0746
2022-10-05 22:06:29 - train: epoch 0098, iter [00120, 01251], lr: 0.000002, loss: 0.0820
2022-10-05 22:06:57 - train: epoch 0098, iter [00130, 01251], lr: 0.000002, loss: 0.0787
2022-10-05 22:07:25 - train: epoch 0098, iter [00140, 01251], lr: 0.000002, loss: 0.0831
2022-10-05 22:07:52 - train: epoch 0098, iter [00150, 01251], lr: 0.000002, loss: 0.0828
2022-10-05 22:08:20 - train: epoch 0098, iter [00160, 01251], lr: 0.000002, loss: 0.0864
2022-10-05 22:08:48 - train: epoch 0098, iter [00170, 01251], lr: 0.000001, loss: 0.0746
2022-10-05 22:09:16 - train: epoch 0098, iter [00180, 01251], lr: 0.000001, loss: 0.0841
2022-10-05 22:09:44 - train: epoch 0098, iter [00190, 01251], lr: 0.000001, loss: 0.0888
2022-10-05 22:10:11 - train: epoch 0098, iter [00200, 01251], lr: 0.000001, loss: 0.0765
2022-10-05 22:10:39 - train: epoch 0098, iter [00210, 01251], lr: 0.000001, loss: 0.0815
2022-10-05 22:11:07 - train: epoch 0098, iter [00220, 01251], lr: 0.000001, loss: 0.0781
2022-10-05 22:11:35 - train: epoch 0098, iter [00230, 01251], lr: 0.000001, loss: 0.0858
2022-10-05 22:12:03 - train: epoch 0098, iter [00240, 01251], lr: 0.000001, loss: 0.0822
2022-10-05 22:12:30 - train: epoch 0098, iter [00250, 01251], lr: 0.000001, loss: 0.0845
2022-10-05 22:12:58 - train: epoch 0098, iter [00260, 01251], lr: 0.000001, loss: 0.0897
2022-10-05 22:13:26 - train: epoch 0098, iter [00270, 01251], lr: 0.000001, loss: 0.0809
2022-10-05 22:13:54 - train: epoch 0098, iter [00280, 01251], lr: 0.000001, loss: 0.0903
2022-10-05 22:14:22 - train: epoch 0098, iter [00290, 01251], lr: 0.000001, loss: 0.0777
2022-10-05 22:14:50 - train: epoch 0098, iter [00300, 01251], lr: 0.000001, loss: 0.0811
2022-10-05 22:15:18 - train: epoch 0098, iter [00310, 01251], lr: 0.000001, loss: 0.0856
2022-10-05 22:15:46 - train: epoch 0098, iter [00320, 01251], lr: 0.000001, loss: 0.0834
2022-10-05 22:16:13 - train: epoch 0098, iter [00330, 01251], lr: 0.000001, loss: 0.0781
2022-10-05 22:16:41 - train: epoch 0098, iter [00340, 01251], lr: 0.000001, loss: 0.0757
2022-10-05 22:17:09 - train: epoch 0098, iter [00350, 01251], lr: 0.000001, loss: 0.0828
2022-10-05 22:17:37 - train: epoch 0098, iter [00360, 01251], lr: 0.000001, loss: 0.0799
2022-10-05 22:18:04 - train: epoch 0098, iter [00370, 01251], lr: 0.000001, loss: 0.0806
2022-10-05 22:18:32 - train: epoch 0098, iter [00380, 01251], lr: 0.000001, loss: 0.0829
2022-10-05 22:19:00 - train: epoch 0098, iter [00390, 01251], lr: 0.000001, loss: 0.0791
2022-10-05 22:19:27 - train: epoch 0098, iter [00400, 01251], lr: 0.000001, loss: 0.0761
2022-10-05 22:19:55 - train: epoch 0098, iter [00410, 01251], lr: 0.000001, loss: 0.0887
2022-10-05 22:20:23 - train: epoch 0098, iter [00420, 01251], lr: 0.000001, loss: 0.0777
2022-10-05 22:20:51 - train: epoch 0098, iter [00430, 01251], lr: 0.000001, loss: 0.0855
2022-10-05 22:21:19 - train: epoch 0098, iter [00440, 01251], lr: 0.000001, loss: 0.0794
2022-10-05 22:21:46 - train: epoch 0098, iter [00450, 01251], lr: 0.000001, loss: 0.0757
2022-10-05 22:22:14 - train: epoch 0098, iter [00460, 01251], lr: 0.000001, loss: 0.0770
2022-10-05 22:22:42 - train: epoch 0098, iter [00470, 01251], lr: 0.000001, loss: 0.0775
2022-10-05 22:23:10 - train: epoch 0098, iter [00480, 01251], lr: 0.000001, loss: 0.0780
2022-10-05 22:23:38 - train: epoch 0098, iter [00490, 01251], lr: 0.000001, loss: 0.0805
2022-10-05 22:24:06 - train: epoch 0098, iter [00500, 01251], lr: 0.000001, loss: 0.0842
2022-10-05 22:24:33 - train: epoch 0098, iter [00510, 01251], lr: 0.000001, loss: 0.0792
2022-10-05 22:25:01 - train: epoch 0098, iter [00520, 01251], lr: 0.000001, loss: 0.0792
2022-10-05 22:25:29 - train: epoch 0098, iter [00530, 01251], lr: 0.000001, loss: 0.0786
2022-10-05 22:25:57 - train: epoch 0098, iter [00540, 01251], lr: 0.000001, loss: 0.0923
2022-10-05 22:26:25 - train: epoch 0098, iter [00550, 01251], lr: 0.000001, loss: 0.0755
2022-10-05 22:26:53 - train: epoch 0098, iter [00560, 01251], lr: 0.000001, loss: 0.0817
2022-10-05 22:27:20 - train: epoch 0098, iter [00570, 01251], lr: 0.000001, loss: 0.0780
2022-10-05 22:27:48 - train: epoch 0098, iter [00580, 01251], lr: 0.000001, loss: 0.0857
2022-10-05 22:28:16 - train: epoch 0098, iter [00590, 01251], lr: 0.000001, loss: 0.0804
2022-10-05 22:28:44 - train: epoch 0098, iter [00600, 01251], lr: 0.000001, loss: 0.0826
2022-10-05 22:29:12 - train: epoch 0098, iter [00610, 01251], lr: 0.000001, loss: 0.0889
2022-10-05 22:29:40 - train: epoch 0098, iter [00620, 01251], lr: 0.000001, loss: 0.0804
2022-10-05 22:30:07 - train: epoch 0098, iter [00630, 01251], lr: 0.000001, loss: 0.0888
2022-10-05 22:30:35 - train: epoch 0098, iter [00640, 01251], lr: 0.000001, loss: 0.0839
2022-10-05 22:31:03 - train: epoch 0098, iter [00650, 01251], lr: 0.000001, loss: 0.0853
2022-10-05 22:31:31 - train: epoch 0098, iter [00660, 01251], lr: 0.000001, loss: 0.0795
2022-10-05 22:31:58 - train: epoch 0098, iter [00670, 01251], lr: 0.000001, loss: 0.0761
2022-10-05 22:32:26 - train: epoch 0098, iter [00680, 01251], lr: 0.000001, loss: 0.0832
2022-10-05 22:32:54 - train: epoch 0098, iter [00690, 01251], lr: 0.000001, loss: 0.0799
2022-10-05 22:33:22 - train: epoch 0098, iter [00700, 01251], lr: 0.000001, loss: 0.0815
2022-10-05 22:33:50 - train: epoch 0098, iter [00710, 01251], lr: 0.000001, loss: 0.0752
2022-10-05 22:34:18 - train: epoch 0098, iter [00720, 01251], lr: 0.000001, loss: 0.0754
2022-10-05 22:34:46 - train: epoch 0098, iter [00730, 01251], lr: 0.000001, loss: 0.0803
2022-10-05 22:35:14 - train: epoch 0098, iter [00740, 01251], lr: 0.000001, loss: 0.0843
2022-10-05 22:35:41 - train: epoch 0098, iter [00750, 01251], lr: 0.000001, loss: 0.0789
2022-10-05 22:36:09 - train: epoch 0098, iter [00760, 01251], lr: 0.000001, loss: 0.0828
2022-10-05 22:36:37 - train: epoch 0098, iter [00770, 01251], lr: 0.000001, loss: 0.0815
2022-10-05 22:37:05 - train: epoch 0098, iter [00780, 01251], lr: 0.000001, loss: 0.0804
2022-10-05 22:37:33 - train: epoch 0098, iter [00790, 01251], lr: 0.000001, loss: 0.0848
2022-10-05 22:38:01 - train: epoch 0098, iter [00800, 01251], lr: 0.000001, loss: 0.0718
2022-10-05 22:38:28 - train: epoch 0098, iter [00810, 01251], lr: 0.000001, loss: 0.0793
2022-10-05 22:38:56 - train: epoch 0098, iter [00820, 01251], lr: 0.000001, loss: 0.0836
2022-10-05 22:39:24 - train: epoch 0098, iter [00830, 01251], lr: 0.000001, loss: 0.0825
2022-10-05 22:39:52 - train: epoch 0098, iter [00840, 01251], lr: 0.000001, loss: 0.0762
2022-10-05 22:40:19 - train: epoch 0098, iter [00850, 01251], lr: 0.000001, loss: 0.0744
2022-10-05 22:40:47 - train: epoch 0098, iter [00860, 01251], lr: 0.000001, loss: 0.0793
2022-10-05 22:41:15 - train: epoch 0098, iter [00870, 01251], lr: 0.000001, loss: 0.0779
2022-10-05 22:41:43 - train: epoch 0098, iter [00880, 01251], lr: 0.000001, loss: 0.0781
2022-10-05 22:42:10 - train: epoch 0098, iter [00890, 01251], lr: 0.000001, loss: 0.0896
2022-10-05 22:42:38 - train: epoch 0098, iter [00900, 01251], lr: 0.000001, loss: 0.0829
2022-10-05 22:43:06 - train: epoch 0098, iter [00910, 01251], lr: 0.000001, loss: 0.0846
2022-10-05 22:43:34 - train: epoch 0098, iter [00920, 01251], lr: 0.000001, loss: 0.0803
2022-10-05 22:44:01 - train: epoch 0098, iter [00930, 01251], lr: 0.000001, loss: 0.0743
2022-10-05 22:44:29 - train: epoch 0098, iter [00940, 01251], lr: 0.000001, loss: 0.0726
2022-10-05 22:44:57 - train: epoch 0098, iter [00950, 01251], lr: 0.000001, loss: 0.0781
2022-10-05 22:45:25 - train: epoch 0098, iter [00960, 01251], lr: 0.000001, loss: 0.0832
2022-10-05 22:45:53 - train: epoch 0098, iter [00970, 01251], lr: 0.000001, loss: 0.0777
2022-10-05 22:46:21 - train: epoch 0098, iter [00980, 01251], lr: 0.000001, loss: 0.0774
2022-10-05 22:46:49 - train: epoch 0098, iter [00990, 01251], lr: 0.000001, loss: 0.0739
2022-10-05 22:47:17 - train: epoch 0098, iter [01000, 01251], lr: 0.000001, loss: 0.0835
2022-10-05 22:47:45 - train: epoch 0098, iter [01010, 01251], lr: 0.000001, loss: 0.0746
2022-10-05 22:48:12 - train: epoch 0098, iter [01020, 01251], lr: 0.000001, loss: 0.0793
2022-10-05 22:48:40 - train: epoch 0098, iter [01030, 01251], lr: 0.000001, loss: 0.0842
2022-10-05 22:49:08 - train: epoch 0098, iter [01040, 01251], lr: 0.000001, loss: 0.0866
2022-10-05 22:49:36 - train: epoch 0098, iter [01050, 01251], lr: 0.000001, loss: 0.0831
2022-10-05 22:50:04 - train: epoch 0098, iter [01060, 01251], lr: 0.000001, loss: 0.0737
2022-10-05 22:50:32 - train: epoch 0098, iter [01070, 01251], lr: 0.000001, loss: 0.0821
2022-10-05 22:51:00 - train: epoch 0098, iter [01080, 01251], lr: 0.000001, loss: 0.0851
2022-10-05 22:51:27 - train: epoch 0098, iter [01090, 01251], lr: 0.000001, loss: 0.0813
2022-10-05 22:51:55 - train: epoch 0098, iter [01100, 01251], lr: 0.000001, loss: 0.0784
2022-10-05 22:52:23 - train: epoch 0098, iter [01110, 01251], lr: 0.000001, loss: 0.0706
2022-10-05 22:52:51 - train: epoch 0098, iter [01120, 01251], lr: 0.000001, loss: 0.0875
2022-10-05 22:53:19 - train: epoch 0098, iter [01130, 01251], lr: 0.000001, loss: 0.0764
2022-10-05 22:53:47 - train: epoch 0098, iter [01140, 01251], lr: 0.000001, loss: 0.0803
2022-10-05 22:54:15 - train: epoch 0098, iter [01150, 01251], lr: 0.000001, loss: 0.0798
2022-10-05 22:54:42 - train: epoch 0098, iter [01160, 01251], lr: 0.000001, loss: 0.0793
2022-10-05 22:55:10 - train: epoch 0098, iter [01170, 01251], lr: 0.000001, loss: 0.0781
2022-10-05 22:55:38 - train: epoch 0098, iter [01180, 01251], lr: 0.000001, loss: 0.0793
2022-10-05 22:56:06 - train: epoch 0098, iter [01190, 01251], lr: 0.000001, loss: 0.0803
2022-10-05 22:56:34 - train: epoch 0098, iter [01200, 01251], lr: 0.000001, loss: 0.0825
2022-10-05 22:57:01 - train: epoch 0098, iter [01210, 01251], lr: 0.000001, loss: 0.0811
2022-10-05 22:57:29 - train: epoch 0098, iter [01220, 01251], lr: 0.000001, loss: 0.0833
2022-10-05 22:57:57 - train: epoch 0098, iter [01230, 01251], lr: 0.000001, loss: 0.0797
2022-10-05 22:58:25 - train: epoch 0098, iter [01240, 01251], lr: 0.000001, loss: 0.0819
2022-10-05 22:58:53 - train: epoch 0098, iter [01250, 01251], lr: 0.000001, loss: 0.0771
2022-10-05 22:58:57 - train: epoch 098, train_loss: 0.0809
2022-10-05 22:58:59 - until epoch: 098, best_loss: 0.0809
2022-10-05 22:58:59 - epoch 099 lr: 0.000001
2022-10-05 22:59:34 - train: epoch 0099, iter [00010, 01251], lr: 0.000001, loss: 0.0799
2022-10-05 23:00:02 - train: epoch 0099, iter [00020, 01251], lr: 0.000001, loss: 0.0828
2022-10-05 23:00:30 - train: epoch 0099, iter [00030, 01251], lr: 0.000001, loss: 0.0777
2022-10-05 23:00:58 - train: epoch 0099, iter [00040, 01251], lr: 0.000001, loss: 0.0841
2022-10-05 23:01:25 - train: epoch 0099, iter [00050, 01251], lr: 0.000001, loss: 0.0801
2022-10-05 23:01:53 - train: epoch 0099, iter [00060, 01251], lr: 0.000001, loss: 0.0800
2022-10-05 23:02:21 - train: epoch 0099, iter [00070, 01251], lr: 0.000001, loss: 0.0798
2022-10-05 23:02:49 - train: epoch 0099, iter [00080, 01251], lr: 0.000001, loss: 0.0731
2022-10-05 23:03:17 - train: epoch 0099, iter [00090, 01251], lr: 0.000001, loss: 0.0782
2022-10-05 23:03:45 - train: epoch 0099, iter [00100, 01251], lr: 0.000001, loss: 0.0774
2022-10-05 23:04:12 - train: epoch 0099, iter [00110, 01251], lr: 0.000001, loss: 0.0751
2022-10-05 23:04:40 - train: epoch 0099, iter [00120, 01251], lr: 0.000001, loss: 0.0813
2022-10-05 23:05:08 - train: epoch 0099, iter [00130, 01251], lr: 0.000001, loss: 0.0800
2022-10-05 23:05:36 - train: epoch 0099, iter [00140, 01251], lr: 0.000001, loss: 0.0782
2022-10-05 23:06:03 - train: epoch 0099, iter [00150, 01251], lr: 0.000001, loss: 0.0771
2022-10-05 23:06:31 - train: epoch 0099, iter [00160, 01251], lr: 0.000001, loss: 0.0885
2022-10-05 23:06:59 - train: epoch 0099, iter [00170, 01251], lr: 0.000001, loss: 0.0803
2022-10-05 23:07:27 - train: epoch 0099, iter [00180, 01251], lr: 0.000001, loss: 0.0889
2022-10-05 23:07:54 - train: epoch 0099, iter [00190, 01251], lr: 0.000001, loss: 0.0759
2022-10-05 23:08:22 - train: epoch 0099, iter [00200, 01251], lr: 0.000001, loss: 0.0770
2022-10-05 23:08:50 - train: epoch 0099, iter [00210, 01251], lr: 0.000001, loss: 0.0788
2022-10-05 23:09:18 - train: epoch 0099, iter [00220, 01251], lr: 0.000001, loss: 0.0798
2022-10-05 23:09:46 - train: epoch 0099, iter [00230, 01251], lr: 0.000001, loss: 0.0859
2022-10-05 23:10:14 - train: epoch 0099, iter [00240, 01251], lr: 0.000001, loss: 0.0810
2022-10-05 23:10:42 - train: epoch 0099, iter [00250, 01251], lr: 0.000001, loss: 0.0772
2022-10-05 23:11:09 - train: epoch 0099, iter [00260, 01251], lr: 0.000001, loss: 0.0780
2022-10-05 23:11:37 - train: epoch 0099, iter [00270, 01251], lr: 0.000001, loss: 0.0754
2022-10-05 23:12:05 - train: epoch 0099, iter [00280, 01251], lr: 0.000001, loss: 0.0843
2022-10-05 23:12:33 - train: epoch 0099, iter [00290, 01251], lr: 0.000001, loss: 0.0784
2022-10-05 23:13:01 - train: epoch 0099, iter [00300, 01251], lr: 0.000001, loss: 0.0810
2022-10-05 23:13:29 - train: epoch 0099, iter [00310, 01251], lr: 0.000001, loss: 0.0824
2022-10-05 23:13:56 - train: epoch 0099, iter [00320, 01251], lr: 0.000001, loss: 0.0841
2022-10-05 23:14:24 - train: epoch 0099, iter [00330, 01251], lr: 0.000001, loss: 0.0902
2022-10-05 23:14:52 - train: epoch 0099, iter [00340, 01251], lr: 0.000001, loss: 0.0738
2022-10-05 23:15:20 - train: epoch 0099, iter [00350, 01251], lr: 0.000001, loss: 0.0784
2022-10-05 23:15:47 - train: epoch 0099, iter [00360, 01251], lr: 0.000001, loss: 0.0828
2022-10-05 23:16:15 - train: epoch 0099, iter [00370, 01251], lr: 0.000001, loss: 0.0901
2022-10-05 23:16:43 - train: epoch 0099, iter [00380, 01251], lr: 0.000001, loss: 0.0827
2022-10-05 23:17:11 - train: epoch 0099, iter [00390, 01251], lr: 0.000001, loss: 0.0883
2022-10-05 23:17:39 - train: epoch 0099, iter [00400, 01251], lr: 0.000001, loss: 0.0733
2022-10-05 23:18:06 - train: epoch 0099, iter [00410, 01251], lr: 0.000001, loss: 0.0752
2022-10-05 23:18:34 - train: epoch 0099, iter [00420, 01251], lr: 0.000001, loss: 0.0819
2022-10-05 23:19:02 - train: epoch 0099, iter [00430, 01251], lr: 0.000001, loss: 0.0794
2022-10-05 23:19:30 - train: epoch 0099, iter [00440, 01251], lr: 0.000000, loss: 0.0829
2022-10-05 23:19:57 - train: epoch 0099, iter [00450, 01251], lr: 0.000000, loss: 0.0771
2022-10-05 23:20:25 - train: epoch 0099, iter [00460, 01251], lr: 0.000000, loss: 0.0749
2022-10-05 23:20:53 - train: epoch 0099, iter [00470, 01251], lr: 0.000000, loss: 0.0805
2022-10-05 23:21:21 - train: epoch 0099, iter [00480, 01251], lr: 0.000000, loss: 0.0808
2022-10-05 23:21:48 - train: epoch 0099, iter [00490, 01251], lr: 0.000000, loss: 0.0799
2022-10-05 23:22:16 - train: epoch 0099, iter [00500, 01251], lr: 0.000000, loss: 0.0878
2022-10-05 23:22:44 - train: epoch 0099, iter [00510, 01251], lr: 0.000000, loss: 0.0835
2022-10-05 23:23:12 - train: epoch 0099, iter [00520, 01251], lr: 0.000000, loss: 0.0859
2022-10-05 23:23:40 - train: epoch 0099, iter [00530, 01251], lr: 0.000000, loss: 0.0749
2022-10-05 23:24:07 - train: epoch 0099, iter [00540, 01251], lr: 0.000000, loss: 0.0770
2022-10-05 23:24:35 - train: epoch 0099, iter [00550, 01251], lr: 0.000000, loss: 0.0781
2022-10-05 23:25:03 - train: epoch 0099, iter [00560, 01251], lr: 0.000000, loss: 0.0799
2022-10-05 23:25:31 - train: epoch 0099, iter [00570, 01251], lr: 0.000000, loss: 0.0858
2022-10-05 23:25:59 - train: epoch 0099, iter [00580, 01251], lr: 0.000000, loss: 0.0819
2022-10-05 23:26:27 - train: epoch 0099, iter [00590, 01251], lr: 0.000000, loss: 0.0851
2022-10-05 23:26:54 - train: epoch 0099, iter [00600, 01251], lr: 0.000000, loss: 0.0837
2022-10-05 23:27:22 - train: epoch 0099, iter [00610, 01251], lr: 0.000000, loss: 0.0817
2022-10-05 23:27:50 - train: epoch 0099, iter [00620, 01251], lr: 0.000000, loss: 0.0842
2022-10-05 23:28:18 - train: epoch 0099, iter [00630, 01251], lr: 0.000000, loss: 0.0760
2022-10-05 23:28:45 - train: epoch 0099, iter [00640, 01251], lr: 0.000000, loss: 0.0805
2022-10-05 23:29:13 - train: epoch 0099, iter [00650, 01251], lr: 0.000000, loss: 0.0831
2022-10-05 23:29:41 - train: epoch 0099, iter [00660, 01251], lr: 0.000000, loss: 0.0786
2022-10-05 23:30:09 - train: epoch 0099, iter [00670, 01251], lr: 0.000000, loss: 0.0758
2022-10-05 23:30:37 - train: epoch 0099, iter [00680, 01251], lr: 0.000000, loss: 0.0810
2022-10-05 23:31:04 - train: epoch 0099, iter [00690, 01251], lr: 0.000000, loss: 0.0851
2022-10-05 23:31:32 - train: epoch 0099, iter [00700, 01251], lr: 0.000000, loss: 0.0777
2022-10-05 23:32:00 - train: epoch 0099, iter [00710, 01251], lr: 0.000000, loss: 0.0749
2022-10-05 23:32:28 - train: epoch 0099, iter [00720, 01251], lr: 0.000000, loss: 0.0795
2022-10-05 23:32:56 - train: epoch 0099, iter [00730, 01251], lr: 0.000000, loss: 0.0859
2022-10-05 23:33:23 - train: epoch 0099, iter [00740, 01251], lr: 0.000000, loss: 0.0839
2022-10-05 23:33:51 - train: epoch 0099, iter [00750, 01251], lr: 0.000000, loss: 0.0737
2022-10-05 23:34:19 - train: epoch 0099, iter [00760, 01251], lr: 0.000000, loss: 0.0852
2022-10-05 23:34:47 - train: epoch 0099, iter [00770, 01251], lr: 0.000000, loss: 0.0839
2022-10-05 23:35:15 - train: epoch 0099, iter [00780, 01251], lr: 0.000000, loss: 0.0781
2022-10-05 23:35:42 - train: epoch 0099, iter [00790, 01251], lr: 0.000000, loss: 0.0906
2022-10-05 23:36:10 - train: epoch 0099, iter [00800, 01251], lr: 0.000000, loss: 0.0751
2022-10-05 23:36:38 - train: epoch 0099, iter [00810, 01251], lr: 0.000000, loss: 0.0804
2022-10-05 23:37:06 - train: epoch 0099, iter [00820, 01251], lr: 0.000000, loss: 0.0917
2022-10-05 23:37:33 - train: epoch 0099, iter [00830, 01251], lr: 0.000000, loss: 0.0812
2022-10-05 23:38:01 - train: epoch 0099, iter [00840, 01251], lr: 0.000000, loss: 0.0855
2022-10-05 23:38:29 - train: epoch 0099, iter [00850, 01251], lr: 0.000000, loss: 0.0866
2022-10-05 23:38:57 - train: epoch 0099, iter [00860, 01251], lr: 0.000000, loss: 0.0832
2022-10-05 23:39:25 - train: epoch 0099, iter [00870, 01251], lr: 0.000000, loss: 0.0851
2022-10-05 23:39:53 - train: epoch 0099, iter [00880, 01251], lr: 0.000000, loss: 0.0819
2022-10-05 23:40:20 - train: epoch 0099, iter [00890, 01251], lr: 0.000000, loss: 0.0789
2022-10-05 23:40:48 - train: epoch 0099, iter [00900, 01251], lr: 0.000000, loss: 0.0861
2022-10-05 23:41:16 - train: epoch 0099, iter [00910, 01251], lr: 0.000000, loss: 0.0809
2022-10-05 23:41:44 - train: epoch 0099, iter [00920, 01251], lr: 0.000000, loss: 0.0777
2022-10-05 23:42:11 - train: epoch 0099, iter [00930, 01251], lr: 0.000000, loss: 0.0808
2022-10-05 23:42:39 - train: epoch 0099, iter [00940, 01251], lr: 0.000000, loss: 0.0758
2022-10-05 23:43:07 - train: epoch 0099, iter [00950, 01251], lr: 0.000000, loss: 0.0823
2022-10-05 23:43:35 - train: epoch 0099, iter [00960, 01251], lr: 0.000000, loss: 0.0763
2022-10-05 23:44:03 - train: epoch 0099, iter [00970, 01251], lr: 0.000000, loss: 0.0780
2022-10-05 23:44:31 - train: epoch 0099, iter [00980, 01251], lr: 0.000000, loss: 0.0823
2022-10-05 23:44:59 - train: epoch 0099, iter [00990, 01251], lr: 0.000000, loss: 0.0829
2022-10-05 23:45:26 - train: epoch 0099, iter [01000, 01251], lr: 0.000000, loss: 0.0706
2022-10-05 23:45:54 - train: epoch 0099, iter [01010, 01251], lr: 0.000000, loss: 0.0841
2022-10-05 23:46:22 - train: epoch 0099, iter [01020, 01251], lr: 0.000000, loss: 0.0792
2022-10-05 23:46:50 - train: epoch 0099, iter [01030, 01251], lr: 0.000000, loss: 0.0863
2022-10-05 23:47:17 - train: epoch 0099, iter [01040, 01251], lr: 0.000000, loss: 0.0857
2022-10-05 23:47:45 - train: epoch 0099, iter [01050, 01251], lr: 0.000000, loss: 0.0812
2022-10-05 23:48:13 - train: epoch 0099, iter [01060, 01251], lr: 0.000000, loss: 0.0861
2022-10-05 23:48:41 - train: epoch 0099, iter [01070, 01251], lr: 0.000000, loss: 0.0861
2022-10-05 23:49:08 - train: epoch 0099, iter [01080, 01251], lr: 0.000000, loss: 0.0783
2022-10-05 23:49:36 - train: epoch 0099, iter [01090, 01251], lr: 0.000000, loss: 0.0800
2022-10-05 23:50:04 - train: epoch 0099, iter [01100, 01251], lr: 0.000000, loss: 0.0860
2022-10-05 23:50:32 - train: epoch 0099, iter [01110, 01251], lr: 0.000000, loss: 0.0812
2022-10-05 23:51:00 - train: epoch 0099, iter [01120, 01251], lr: 0.000000, loss: 0.0817
2022-10-05 23:51:28 - train: epoch 0099, iter [01130, 01251], lr: 0.000000, loss: 0.0811
2022-10-05 23:51:55 - train: epoch 0099, iter [01140, 01251], lr: 0.000000, loss: 0.0775
2022-10-05 23:52:23 - train: epoch 0099, iter [01150, 01251], lr: 0.000000, loss: 0.0826
2022-10-05 23:52:51 - train: epoch 0099, iter [01160, 01251], lr: 0.000000, loss: 0.0780
2022-10-05 23:53:19 - train: epoch 0099, iter [01170, 01251], lr: 0.000000, loss: 0.0785
2022-10-05 23:53:47 - train: epoch 0099, iter [01180, 01251], lr: 0.000000, loss: 0.0767
2022-10-05 23:54:15 - train: epoch 0099, iter [01190, 01251], lr: 0.000000, loss: 0.0771
2022-10-05 23:54:42 - train: epoch 0099, iter [01200, 01251], lr: 0.000000, loss: 0.0807
2022-10-05 23:55:10 - train: epoch 0099, iter [01210, 01251], lr: 0.000000, loss: 0.0796
2022-10-05 23:55:38 - train: epoch 0099, iter [01220, 01251], lr: 0.000000, loss: 0.0838
2022-10-05 23:56:06 - train: epoch 0099, iter [01230, 01251], lr: 0.000000, loss: 0.0908
2022-10-05 23:56:34 - train: epoch 0099, iter [01240, 01251], lr: 0.000000, loss: 0.0839
2022-10-05 23:57:01 - train: epoch 0099, iter [01250, 01251], lr: 0.000000, loss: 0.0892
2022-10-05 23:57:05 - train: epoch 099, train_loss: 0.0809
2022-10-05 23:57:07 - until epoch: 099, best_loss: 0.0809
2022-10-05 23:57:07 - epoch 100 lr: 0.000000
2022-10-05 23:57:42 - train: epoch 0100, iter [00010, 01251], lr: 0.000000, loss: 0.0869
2022-10-05 23:58:10 - train: epoch 0100, iter [00020, 01251], lr: 0.000000, loss: 0.0815
2022-10-05 23:58:38 - train: epoch 0100, iter [00030, 01251], lr: 0.000000, loss: 0.0825
2022-10-05 23:59:06 - train: epoch 0100, iter [00040, 01251], lr: 0.000000, loss: 0.0887
2022-10-05 23:59:33 - train: epoch 0100, iter [00050, 01251], lr: 0.000000, loss: 0.0757
2022-10-06 00:00:01 - train: epoch 0100, iter [00060, 01251], lr: 0.000000, loss: 0.0848
2022-10-06 00:00:29 - train: epoch 0100, iter [00070, 01251], lr: 0.000000, loss: 0.0775
2022-10-06 00:00:57 - train: epoch 0100, iter [00080, 01251], lr: 0.000000, loss: 0.0796
2022-10-06 00:01:25 - train: epoch 0100, iter [00090, 01251], lr: 0.000000, loss: 0.0814
2022-10-06 00:01:53 - train: epoch 0100, iter [00100, 01251], lr: 0.000000, loss: 0.0828
2022-10-06 00:02:20 - train: epoch 0100, iter [00110, 01251], lr: 0.000000, loss: 0.0760
2022-10-06 00:02:48 - train: epoch 0100, iter [00120, 01251], lr: 0.000000, loss: 0.0757
2022-10-06 00:03:16 - train: epoch 0100, iter [00130, 01251], lr: 0.000000, loss: 0.0841
2022-10-06 00:03:44 - train: epoch 0100, iter [00140, 01251], lr: 0.000000, loss: 0.0818
2022-10-06 00:04:11 - train: epoch 0100, iter [00150, 01251], lr: 0.000000, loss: 0.0826
2022-10-06 00:04:39 - train: epoch 0100, iter [00160, 01251], lr: 0.000000, loss: 0.0781
2022-10-06 00:05:07 - train: epoch 0100, iter [00170, 01251], lr: 0.000000, loss: 0.0716
2022-10-06 00:05:35 - train: epoch 0100, iter [00180, 01251], lr: 0.000000, loss: 0.0796
2022-10-06 00:06:03 - train: epoch 0100, iter [00190, 01251], lr: 0.000000, loss: 0.0849
2022-10-06 00:06:31 - train: epoch 0100, iter [00200, 01251], lr: 0.000000, loss: 0.0772
2022-10-06 00:06:59 - train: epoch 0100, iter [00210, 01251], lr: 0.000000, loss: 0.0795
2022-10-06 00:07:26 - train: epoch 0100, iter [00220, 01251], lr: 0.000000, loss: 0.0863
2022-10-06 00:07:54 - train: epoch 0100, iter [00230, 01251], lr: 0.000000, loss: 0.0836
2022-10-06 00:08:22 - train: epoch 0100, iter [00240, 01251], lr: 0.000000, loss: 0.0815
2022-10-06 00:08:50 - train: epoch 0100, iter [00250, 01251], lr: 0.000000, loss: 0.0860
2022-10-06 00:09:18 - train: epoch 0100, iter [00260, 01251], lr: 0.000000, loss: 0.0740
2022-10-06 00:09:46 - train: epoch 0100, iter [00270, 01251], lr: 0.000000, loss: 0.0785
2022-10-06 00:10:14 - train: epoch 0100, iter [00280, 01251], lr: 0.000000, loss: 0.0816
2022-10-06 00:10:42 - train: epoch 0100, iter [00290, 01251], lr: 0.000000, loss: 0.0773
2022-10-06 00:11:10 - train: epoch 0100, iter [00300, 01251], lr: 0.000000, loss: 0.0760
2022-10-06 00:11:37 - train: epoch 0100, iter [00310, 01251], lr: 0.000000, loss: 0.0796
2022-10-06 00:12:05 - train: epoch 0100, iter [00320, 01251], lr: 0.000000, loss: 0.0823
2022-10-06 00:12:33 - train: epoch 0100, iter [00330, 01251], lr: 0.000000, loss: 0.0918
2022-10-06 00:13:01 - train: epoch 0100, iter [00340, 01251], lr: 0.000000, loss: 0.0833
2022-10-06 00:13:29 - train: epoch 0100, iter [00350, 01251], lr: 0.000000, loss: 0.0748
2022-10-06 00:13:56 - train: epoch 0100, iter [00360, 01251], lr: 0.000000, loss: 0.0731
2022-10-06 00:14:24 - train: epoch 0100, iter [00370, 01251], lr: 0.000000, loss: 0.0934
2022-10-06 00:14:52 - train: epoch 0100, iter [00380, 01251], lr: 0.000000, loss: 0.0785
2022-10-06 00:15:20 - train: epoch 0100, iter [00390, 01251], lr: 0.000000, loss: 0.0805
2022-10-06 00:15:48 - train: epoch 0100, iter [00400, 01251], lr: 0.000000, loss: 0.0743
2022-10-06 00:16:15 - train: epoch 0100, iter [00410, 01251], lr: 0.000000, loss: 0.0776
2022-10-06 00:16:43 - train: epoch 0100, iter [00420, 01251], lr: 0.000000, loss: 0.0778
2022-10-06 00:17:11 - train: epoch 0100, iter [00430, 01251], lr: 0.000000, loss: 0.0805
2022-10-06 00:17:39 - train: epoch 0100, iter [00440, 01251], lr: 0.000000, loss: 0.0769
2022-10-06 00:18:07 - train: epoch 0100, iter [00450, 01251], lr: 0.000000, loss: 0.0756
2022-10-06 00:18:34 - train: epoch 0100, iter [00460, 01251], lr: 0.000000, loss: 0.0835
2022-10-06 00:19:02 - train: epoch 0100, iter [00470, 01251], lr: 0.000000, loss: 0.0766
2022-10-06 00:19:30 - train: epoch 0100, iter [00480, 01251], lr: 0.000000, loss: 0.0758
2022-10-06 00:19:58 - train: epoch 0100, iter [00490, 01251], lr: 0.000000, loss: 0.0802
2022-10-06 00:20:26 - train: epoch 0100, iter [00500, 01251], lr: 0.000000, loss: 0.0911
2022-10-06 00:20:54 - train: epoch 0100, iter [00510, 01251], lr: 0.000000, loss: 0.0800
2022-10-06 00:21:22 - train: epoch 0100, iter [00520, 01251], lr: 0.000000, loss: 0.0817
2022-10-06 00:21:49 - train: epoch 0100, iter [00530, 01251], lr: 0.000000, loss: 0.0739
2022-10-06 00:22:17 - train: epoch 0100, iter [00540, 01251], lr: 0.000000, loss: 0.0750
2022-10-06 00:22:45 - train: epoch 0100, iter [00550, 01251], lr: 0.000000, loss: 0.0852
2022-10-06 00:23:13 - train: epoch 0100, iter [00560, 01251], lr: 0.000000, loss: 0.0836
2022-10-06 00:23:41 - train: epoch 0100, iter [00570, 01251], lr: 0.000000, loss: 0.0766
2022-10-06 00:24:09 - train: epoch 0100, iter [00580, 01251], lr: 0.000000, loss: 0.0832
2022-10-06 00:24:36 - train: epoch 0100, iter [00590, 01251], lr: 0.000000, loss: 0.0811
2022-10-06 00:25:04 - train: epoch 0100, iter [00600, 01251], lr: 0.000000, loss: 0.0827
2022-10-06 00:25:32 - train: epoch 0100, iter [00610, 01251], lr: 0.000000, loss: 0.0842
2022-10-06 00:26:00 - train: epoch 0100, iter [00620, 01251], lr: 0.000000, loss: 0.0759
2022-10-06 00:26:28 - train: epoch 0100, iter [00630, 01251], lr: 0.000000, loss: 0.0896
2022-10-06 00:26:56 - train: epoch 0100, iter [00640, 01251], lr: 0.000000, loss: 0.0782
2022-10-06 00:27:24 - train: epoch 0100, iter [00650, 01251], lr: 0.000000, loss: 0.0789
2022-10-06 00:27:52 - train: epoch 0100, iter [00660, 01251], lr: 0.000000, loss: 0.0827
2022-10-06 00:28:19 - train: epoch 0100, iter [00670, 01251], lr: 0.000000, loss: 0.0768
2022-10-06 00:28:47 - train: epoch 0100, iter [00680, 01251], lr: 0.000000, loss: 0.0829
2022-10-06 00:29:15 - train: epoch 0100, iter [00690, 01251], lr: 0.000000, loss: 0.0877
2022-10-06 00:29:43 - train: epoch 0100, iter [00700, 01251], lr: 0.000000, loss: 0.0762
2022-10-06 00:30:10 - train: epoch 0100, iter [00710, 01251], lr: 0.000000, loss: 0.0790
2022-10-06 00:30:38 - train: epoch 0100, iter [00720, 01251], lr: 0.000000, loss: 0.0788
2022-10-06 00:31:06 - train: epoch 0100, iter [00730, 01251], lr: 0.000000, loss: 0.0846
2022-10-06 00:31:34 - train: epoch 0100, iter [00740, 01251], lr: 0.000000, loss: 0.0788
2022-10-06 00:32:02 - train: epoch 0100, iter [00750, 01251], lr: 0.000000, loss: 0.0830
2022-10-06 00:32:30 - train: epoch 0100, iter [00760, 01251], lr: 0.000000, loss: 0.0780
2022-10-06 00:32:58 - train: epoch 0100, iter [00770, 01251], lr: 0.000000, loss: 0.0813
2022-10-06 00:33:25 - train: epoch 0100, iter [00780, 01251], lr: 0.000000, loss: 0.0777
2022-10-06 00:33:53 - train: epoch 0100, iter [00790, 01251], lr: 0.000000, loss: 0.0867
2022-10-06 00:34:21 - train: epoch 0100, iter [00800, 01251], lr: 0.000000, loss: 0.0767
2022-10-06 00:34:49 - train: epoch 0100, iter [00810, 01251], lr: 0.000000, loss: 0.0725
2022-10-06 00:35:17 - train: epoch 0100, iter [00820, 01251], lr: 0.000000, loss: 0.0797
2022-10-06 00:35:45 - train: epoch 0100, iter [00830, 01251], lr: 0.000000, loss: 0.0803
2022-10-06 00:36:12 - train: epoch 0100, iter [00840, 01251], lr: 0.000000, loss: 0.0801
2022-10-06 00:36:40 - train: epoch 0100, iter [00850, 01251], lr: 0.000000, loss: 0.0781
2022-10-06 00:37:08 - train: epoch 0100, iter [00860, 01251], lr: 0.000000, loss: 0.0764
2022-10-06 00:37:36 - train: epoch 0100, iter [00870, 01251], lr: 0.000000, loss: 0.0830
2022-10-06 00:38:04 - train: epoch 0100, iter [00880, 01251], lr: 0.000000, loss: 0.0777
2022-10-06 00:38:32 - train: epoch 0100, iter [00890, 01251], lr: 0.000000, loss: 0.0837
2022-10-06 00:39:00 - train: epoch 0100, iter [00900, 01251], lr: 0.000000, loss: 0.0835
2022-10-06 00:39:28 - train: epoch 0100, iter [00910, 01251], lr: 0.000000, loss: 0.0816
2022-10-06 00:39:56 - train: epoch 0100, iter [00920, 01251], lr: 0.000000, loss: 0.0803
2022-10-06 00:40:24 - train: epoch 0100, iter [00930, 01251], lr: 0.000000, loss: 0.0886
2022-10-06 00:40:52 - train: epoch 0100, iter [00940, 01251], lr: 0.000000, loss: 0.0785
2022-10-06 00:41:19 - train: epoch 0100, iter [00950, 01251], lr: 0.000000, loss: 0.0806
2022-10-06 00:41:47 - train: epoch 0100, iter [00960, 01251], lr: 0.000000, loss: 0.0844
2022-10-06 00:42:15 - train: epoch 0100, iter [00970, 01251], lr: 0.000000, loss: 0.0782
2022-10-06 00:42:44 - train: epoch 0100, iter [00980, 01251], lr: 0.000000, loss: 0.0867
2022-10-06 00:43:11 - train: epoch 0100, iter [00990, 01251], lr: 0.000000, loss: 0.0819
2022-10-06 00:43:39 - train: epoch 0100, iter [01000, 01251], lr: 0.000000, loss: 0.0792
2022-10-06 00:44:07 - train: epoch 0100, iter [01010, 01251], lr: 0.000000, loss: 0.0784
2022-10-06 00:44:35 - train: epoch 0100, iter [01020, 01251], lr: 0.000000, loss: 0.0841
2022-10-06 00:45:03 - train: epoch 0100, iter [01030, 01251], lr: 0.000000, loss: 0.0828
2022-10-06 00:45:31 - train: epoch 0100, iter [01040, 01251], lr: 0.000000, loss: 0.0826
2022-10-06 00:45:59 - train: epoch 0100, iter [01050, 01251], lr: 0.000000, loss: 0.0828
2022-10-06 00:46:27 - train: epoch 0100, iter [01060, 01251], lr: 0.000000, loss: 0.0779
2022-10-06 00:46:55 - train: epoch 0100, iter [01070, 01251], lr: 0.000000, loss: 0.0853
2022-10-06 00:47:22 - train: epoch 0100, iter [01080, 01251], lr: 0.000000, loss: 0.0793
2022-10-06 00:47:50 - train: epoch 0100, iter [01090, 01251], lr: 0.000000, loss: 0.0749
2022-10-06 00:48:18 - train: epoch 0100, iter [01100, 01251], lr: 0.000000, loss: 0.0779
2022-10-06 00:48:46 - train: epoch 0100, iter [01110, 01251], lr: 0.000000, loss: 0.0799
2022-10-06 00:49:14 - train: epoch 0100, iter [01120, 01251], lr: 0.000000, loss: 0.0749
2022-10-06 00:49:42 - train: epoch 0100, iter [01130, 01251], lr: 0.000000, loss: 0.0774
2022-10-06 00:50:09 - train: epoch 0100, iter [01140, 01251], lr: 0.000000, loss: 0.0798
2022-10-06 00:50:37 - train: epoch 0100, iter [01150, 01251], lr: 0.000000, loss: 0.0821
2022-10-06 00:51:05 - train: epoch 0100, iter [01160, 01251], lr: 0.000000, loss: 0.0830
2022-10-06 00:51:33 - train: epoch 0100, iter [01170, 01251], lr: 0.000000, loss: 0.0778
2022-10-06 00:52:01 - train: epoch 0100, iter [01180, 01251], lr: 0.000000, loss: 0.0800
2022-10-06 00:52:28 - train: epoch 0100, iter [01190, 01251], lr: 0.000000, loss: 0.0851
2022-10-06 00:52:56 - train: epoch 0100, iter [01200, 01251], lr: 0.000000, loss: 0.0812
2022-10-06 00:53:24 - train: epoch 0100, iter [01210, 01251], lr: 0.000000, loss: 0.0809
2022-10-06 00:53:52 - train: epoch 0100, iter [01220, 01251], lr: 0.000000, loss: 0.0863
2022-10-06 00:54:19 - train: epoch 0100, iter [01230, 01251], lr: 0.000000, loss: 0.0750
2022-10-06 00:54:47 - train: epoch 0100, iter [01240, 01251], lr: 0.000000, loss: 0.0810
2022-10-06 00:55:14 - train: epoch 0100, iter [01250, 01251], lr: 0.000000, loss: 0.0772
2022-10-06 00:55:19 - train: epoch 100, train_loss: 0.0809
2022-10-06 00:55:20 - until epoch: 100, best_loss: 0.0809
2022-10-06 00:55:20 - train done. model: poolformer_s36_patch32_224_mae_pretrain_model, train time: 97.891 hours, best_loss: 0.0809
