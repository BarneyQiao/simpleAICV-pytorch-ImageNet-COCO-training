2022-09-20 22:22:15 - network: vit_base_patch16_224_mae_pretrain_model
2022-09-20 22:22:15 - input_image_size: 224
2022-09-20 22:22:15 - scale: 1.1428571428571428
2022-09-20 22:22:15 - trained_model_path: 
2022-09-20 22:22:15 - train_criterion: MSELoss()
2022-09-20 22:22:15 - train_dataset: <simpleAICV.classification.datasets.ilsvrc2012dataset.ILSVRC2012Dataset object at 0x7f207013dd60>
2022-09-20 22:22:15 - train_collater: <simpleAICV.self_supervised_learning.common.MAESelfSupervisedPretrainCollater object at 0x7f207013dd90>
2022-09-20 22:22:15 - seed: 0
2022-09-20 22:22:15 - batch_size: 256
2022-09-20 22:22:15 - num_workers: 32
2022-09-20 22:22:15 - accumulation_steps: 4
2022-09-20 22:22:15 - optimizer: ('AdamW', {'lr': 0.0012, 'global_weight_decay': False, 'weight_decay': 0.05, 'no_weight_decay_layer_name_list': [], 'beta1': 0.9, 'beta2': 0.95})
2022-09-20 22:22:15 - scheduler: ('CosineLR', {'warm_up_epochs': 40})
2022-09-20 22:22:15 - epochs: 400
2022-09-20 22:22:15 - print_interval: 10
2022-09-20 22:22:15 - sync_bn: False
2022-09-20 22:22:15 - apex: True
2022-09-20 22:22:15 - use_ema_model: False
2022-09-20 22:22:15 - ema_model_decay: 0.9999
2022-09-20 22:22:15 - gpus_type: NVIDIA RTX A5000
2022-09-20 22:22:15 - gpus_num: 2
2022-09-20 22:22:15 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f203c276170>
2022-09-20 22:22:15 - --------------------parameters--------------------
2022-09-20 22:22:15 - name: encoder.cls_token, grad: True
2022-09-20 22:22:15 - name: encoder.position_encoding, grad: False
2022-09-20 22:22:15 - name: encoder.patch_embedding.conv.weight, grad: True
2022-09-20 22:22:15 - name: encoder.patch_embedding.conv.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.0.norm1.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.0.norm1.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.0.attention.qkv_linear.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.0.attention.qkv_linear.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.0.attention.out_linear.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.0.attention.out_linear.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.0.norm2.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.0.norm2.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.0.feed_forward.fc1.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.0.feed_forward.fc1.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.0.feed_forward.fc2.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.0.feed_forward.fc2.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.1.norm1.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.1.norm1.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.1.attention.qkv_linear.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.1.attention.qkv_linear.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.1.attention.out_linear.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.1.attention.out_linear.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.1.norm2.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.1.norm2.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.1.feed_forward.fc1.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.1.feed_forward.fc1.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.1.feed_forward.fc2.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.1.feed_forward.fc2.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.2.norm1.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.2.norm1.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.2.attention.qkv_linear.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.2.attention.qkv_linear.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.2.attention.out_linear.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.2.attention.out_linear.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.2.norm2.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.2.norm2.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.2.feed_forward.fc1.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.2.feed_forward.fc1.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.2.feed_forward.fc2.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.2.feed_forward.fc2.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.3.norm1.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.3.norm1.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.3.attention.qkv_linear.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.3.attention.qkv_linear.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.3.attention.out_linear.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.3.attention.out_linear.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.3.norm2.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.3.norm2.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.3.feed_forward.fc1.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.3.feed_forward.fc1.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.3.feed_forward.fc2.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.3.feed_forward.fc2.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.4.norm1.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.4.norm1.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.4.attention.qkv_linear.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.4.attention.qkv_linear.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.4.attention.out_linear.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.4.attention.out_linear.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.4.norm2.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.4.norm2.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.4.feed_forward.fc1.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.4.feed_forward.fc1.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.4.feed_forward.fc2.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.4.feed_forward.fc2.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.5.norm1.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.5.norm1.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.5.attention.qkv_linear.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.5.attention.qkv_linear.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.5.attention.out_linear.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.5.attention.out_linear.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.5.norm2.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.5.norm2.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.5.feed_forward.fc1.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.5.feed_forward.fc1.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.5.feed_forward.fc2.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.5.feed_forward.fc2.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.6.norm1.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.6.norm1.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.6.attention.qkv_linear.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.6.attention.qkv_linear.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.6.attention.out_linear.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.6.attention.out_linear.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.6.norm2.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.6.norm2.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.6.feed_forward.fc1.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.6.feed_forward.fc1.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.6.feed_forward.fc2.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.6.feed_forward.fc2.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.7.norm1.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.7.norm1.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.7.attention.qkv_linear.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.7.attention.qkv_linear.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.7.attention.out_linear.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.7.attention.out_linear.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.7.norm2.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.7.norm2.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.7.feed_forward.fc1.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.7.feed_forward.fc1.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.7.feed_forward.fc2.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.7.feed_forward.fc2.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.8.norm1.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.8.norm1.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.8.attention.qkv_linear.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.8.attention.qkv_linear.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.8.attention.out_linear.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.8.attention.out_linear.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.8.norm2.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.8.norm2.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.8.feed_forward.fc1.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.8.feed_forward.fc1.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.8.feed_forward.fc2.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.8.feed_forward.fc2.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.9.norm1.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.9.norm1.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.9.attention.qkv_linear.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.9.attention.qkv_linear.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.9.attention.out_linear.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.9.attention.out_linear.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.9.norm2.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.9.norm2.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.9.feed_forward.fc1.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.9.feed_forward.fc1.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.9.feed_forward.fc2.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.9.feed_forward.fc2.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.10.norm1.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.10.norm1.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.10.attention.qkv_linear.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.10.attention.qkv_linear.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.10.attention.out_linear.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.10.attention.out_linear.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.10.norm2.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.10.norm2.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.10.feed_forward.fc1.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.10.feed_forward.fc1.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.10.feed_forward.fc2.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.10.feed_forward.fc2.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.11.norm1.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.11.norm1.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.11.attention.qkv_linear.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.11.attention.qkv_linear.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.11.attention.out_linear.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.11.attention.out_linear.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.11.norm2.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.11.norm2.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.11.feed_forward.fc1.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.11.feed_forward.fc1.bias, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.11.feed_forward.fc2.weight, grad: True
2022-09-20 22:22:15 - name: encoder.blocks.11.feed_forward.fc2.bias, grad: True
2022-09-20 22:22:15 - name: encoder.norm.weight, grad: True
2022-09-20 22:22:15 - name: encoder.norm.bias, grad: True
2022-09-20 22:22:15 - name: decoder.mask_token, grad: True
2022-09-20 22:22:15 - name: decoder.position_encoding, grad: False
2022-09-20 22:22:15 - name: decoder.blocks.0.norm1.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.0.norm1.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.0.attention.qkv_linear.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.0.attention.qkv_linear.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.0.attention.out_linear.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.0.attention.out_linear.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.0.norm2.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.0.norm2.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.0.feed_forward.fc1.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.0.feed_forward.fc1.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.0.feed_forward.fc2.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.0.feed_forward.fc2.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.1.norm1.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.1.norm1.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.1.attention.qkv_linear.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.1.attention.qkv_linear.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.1.attention.out_linear.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.1.attention.out_linear.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.1.norm2.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.1.norm2.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.1.feed_forward.fc1.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.1.feed_forward.fc1.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.1.feed_forward.fc2.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.1.feed_forward.fc2.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.2.norm1.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.2.norm1.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.2.attention.qkv_linear.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.2.attention.qkv_linear.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.2.attention.out_linear.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.2.attention.out_linear.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.2.norm2.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.2.norm2.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.2.feed_forward.fc1.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.2.feed_forward.fc1.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.2.feed_forward.fc2.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.2.feed_forward.fc2.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.3.norm1.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.3.norm1.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.3.attention.qkv_linear.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.3.attention.qkv_linear.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.3.attention.out_linear.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.3.attention.out_linear.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.3.norm2.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.3.norm2.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.3.feed_forward.fc1.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.3.feed_forward.fc1.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.3.feed_forward.fc2.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.3.feed_forward.fc2.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.4.norm1.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.4.norm1.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.4.attention.qkv_linear.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.4.attention.qkv_linear.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.4.attention.out_linear.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.4.attention.out_linear.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.4.norm2.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.4.norm2.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.4.feed_forward.fc1.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.4.feed_forward.fc1.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.4.feed_forward.fc2.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.4.feed_forward.fc2.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.5.norm1.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.5.norm1.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.5.attention.qkv_linear.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.5.attention.qkv_linear.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.5.attention.out_linear.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.5.attention.out_linear.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.5.norm2.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.5.norm2.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.5.feed_forward.fc1.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.5.feed_forward.fc1.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.5.feed_forward.fc2.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.5.feed_forward.fc2.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.6.norm1.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.6.norm1.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.6.attention.qkv_linear.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.6.attention.qkv_linear.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.6.attention.out_linear.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.6.attention.out_linear.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.6.norm2.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.6.norm2.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.6.feed_forward.fc1.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.6.feed_forward.fc1.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.6.feed_forward.fc2.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.6.feed_forward.fc2.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.7.norm1.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.7.norm1.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.7.attention.qkv_linear.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.7.attention.qkv_linear.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.7.attention.out_linear.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.7.attention.out_linear.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.7.norm2.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.7.norm2.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.7.feed_forward.fc1.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.7.feed_forward.fc1.bias, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.7.feed_forward.fc2.weight, grad: True
2022-09-20 22:22:15 - name: decoder.blocks.7.feed_forward.fc2.bias, grad: True
2022-09-20 22:22:15 - name: decoder.norm.weight, grad: True
2022-09-20 22:22:15 - name: decoder.norm.bias, grad: True
2022-09-20 22:22:15 - name: decoder.fc.weight, grad: True
2022-09-20 22:22:15 - name: decoder.fc.bias, grad: True
2022-09-20 22:22:15 - name: encoder_to_decoder.weight, grad: True
2022-09-20 22:22:15 - name: encoder_to_decoder.bias, grad: True
2022-09-20 22:22:15 - --------------------buffers--------------------
2022-09-20 22:22:15 - -----------no weight decay layers--------------
2022-09-20 22:22:15 - name: encoder.patch_embedding.conv.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.0.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.0.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.0.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.0.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.0.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.0.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.0.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.0.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.1.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.1.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.1.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.1.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.1.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.1.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.1.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.1.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.2.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.2.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.2.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.2.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.2.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.2.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.2.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.2.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.3.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.3.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.3.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.3.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.3.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.3.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.3.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.3.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.4.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.4.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.4.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.4.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.4.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.4.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.4.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.4.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.5.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.5.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.5.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.5.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.5.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.5.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.5.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.5.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.6.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.6.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.6.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.6.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.6.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.6.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.6.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.6.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.7.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.7.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.7.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.7.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.7.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.7.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.7.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.7.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.8.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.8.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.8.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.8.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.8.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.8.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.8.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.8.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.9.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.9.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.9.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.9.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.9.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.9.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.9.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.9.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.10.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.10.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.10.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.10.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.10.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.10.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.10.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.10.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.11.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.11.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.11.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.11.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.11.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.11.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.11.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.11.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.norm.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.norm.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.0.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.0.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.0.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.0.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.0.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.0.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.0.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.0.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.1.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.1.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.1.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.1.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.1.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.1.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.1.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.1.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.2.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.2.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.2.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.2.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.2.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.2.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.2.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.2.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.3.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.3.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.3.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.3.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.3.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.3.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.3.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.3.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.4.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.4.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.4.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.4.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.4.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.4.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.4.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.4.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.5.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.5.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.5.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.5.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.5.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.5.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.5.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.5.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.6.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.6.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.6.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.6.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.6.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.6.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.6.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.6.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.7.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.7.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.7.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.7.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.7.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.7.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.7.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.7.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.norm.weight, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.norm.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.fc.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder_to_decoder.bias, weight_decay: 0.0, lr_scale: not setting!
2022-09-20 22:22:15 - -------------weight decay layers---------------
2022-09-20 22:22:15 - name: encoder.cls_token, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.patch_embedding.conv.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.0.attention.qkv_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.0.attention.out_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.0.feed_forward.fc1.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.0.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.1.attention.qkv_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.1.attention.out_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.1.feed_forward.fc1.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.1.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.2.attention.qkv_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.2.attention.out_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.2.feed_forward.fc1.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.2.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.3.attention.qkv_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.3.attention.out_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.3.feed_forward.fc1.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.3.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.4.attention.qkv_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.4.attention.out_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.4.feed_forward.fc1.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.4.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.5.attention.qkv_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.5.attention.out_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.5.feed_forward.fc1.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.5.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.6.attention.qkv_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.6.attention.out_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.6.feed_forward.fc1.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.6.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.7.attention.qkv_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.7.attention.out_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.7.feed_forward.fc1.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.7.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.8.attention.qkv_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.8.attention.out_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.8.feed_forward.fc1.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.8.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.9.attention.qkv_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.9.attention.out_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.9.feed_forward.fc1.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.9.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.10.attention.qkv_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.10.attention.out_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.10.feed_forward.fc1.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.10.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.11.attention.qkv_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.11.attention.out_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.11.feed_forward.fc1.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder.blocks.11.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.mask_token, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.0.attention.qkv_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.0.attention.out_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.0.feed_forward.fc1.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.0.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.1.attention.qkv_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.1.attention.out_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.1.feed_forward.fc1.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.1.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.2.attention.qkv_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.2.attention.out_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.2.feed_forward.fc1.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.2.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.3.attention.qkv_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.3.attention.out_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.3.feed_forward.fc1.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.3.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.4.attention.qkv_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.4.attention.out_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.4.feed_forward.fc1.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.4.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.5.attention.qkv_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.5.attention.out_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.5.feed_forward.fc1.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.5.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.6.attention.qkv_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.6.attention.out_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.6.feed_forward.fc1.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.6.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.7.attention.qkv_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.7.attention.out_linear.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.7.feed_forward.fc1.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.blocks.7.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: decoder.fc.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:15 - name: encoder_to_decoder.weight, weight_decay: 0.05, lr_scale: not setting!
2022-09-20 22:22:16 - epoch 001 lr: 0.001200
2022-09-20 22:22:56 - train: epoch 0001, iter [00010, 01251], lr: 0.000030, loss: 1.3588
2022-09-20 22:23:16 - train: epoch 0001, iter [00020, 01251], lr: 0.000030, loss: 1.1101
2022-09-20 22:23:37 - train: epoch 0001, iter [00030, 01251], lr: 0.000031, loss: 1.0092
2022-09-20 22:23:58 - train: epoch 0001, iter [00040, 01251], lr: 0.000031, loss: 0.9491
2022-09-20 22:24:18 - train: epoch 0001, iter [00050, 01251], lr: 0.000031, loss: 0.9242
2022-09-20 22:24:39 - train: epoch 0001, iter [00060, 01251], lr: 0.000031, loss: 0.9061
2022-09-20 22:24:59 - train: epoch 0001, iter [00070, 01251], lr: 0.000032, loss: 0.8832
2022-09-20 22:25:20 - train: epoch 0001, iter [00080, 01251], lr: 0.000032, loss: 0.8807
2022-09-20 22:25:40 - train: epoch 0001, iter [00090, 01251], lr: 0.000032, loss: 0.8254
2022-09-20 22:26:01 - train: epoch 0001, iter [00100, 01251], lr: 0.000032, loss: 0.8420
2022-09-20 22:26:21 - train: epoch 0001, iter [00110, 01251], lr: 0.000033, loss: 0.8079
2022-09-20 22:26:42 - train: epoch 0001, iter [00120, 01251], lr: 0.000033, loss: 0.8195
2022-09-20 22:27:02 - train: epoch 0001, iter [00130, 01251], lr: 0.000033, loss: 0.8069
2022-09-20 22:27:23 - train: epoch 0001, iter [00140, 01251], lr: 0.000033, loss: 0.8316
2022-09-20 22:27:43 - train: epoch 0001, iter [00150, 01251], lr: 0.000034, loss: 0.8158
2022-09-20 22:28:04 - train: epoch 0001, iter [00160, 01251], lr: 0.000034, loss: 0.8106
2022-09-20 22:28:24 - train: epoch 0001, iter [00170, 01251], lr: 0.000034, loss: 0.7770
2022-09-20 22:28:45 - train: epoch 0001, iter [00180, 01251], lr: 0.000034, loss: 0.7917
2022-09-20 22:29:06 - train: epoch 0001, iter [00190, 01251], lr: 0.000035, loss: 0.7899
2022-09-20 22:29:26 - train: epoch 0001, iter [00200, 01251], lr: 0.000035, loss: 0.8010
2022-09-20 22:29:47 - train: epoch 0001, iter [00210, 01251], lr: 0.000035, loss: 0.8076
2022-09-20 22:30:07 - train: epoch 0001, iter [00220, 01251], lr: 0.000035, loss: 0.7955
2022-09-20 22:30:28 - train: epoch 0001, iter [00230, 01251], lr: 0.000036, loss: 0.7875
2022-09-20 22:30:48 - train: epoch 0001, iter [00240, 01251], lr: 0.000036, loss: 0.7887
2022-09-20 22:31:09 - train: epoch 0001, iter [00250, 01251], lr: 0.000036, loss: 0.7751
2022-09-20 22:31:29 - train: epoch 0001, iter [00260, 01251], lr: 0.000036, loss: 0.7639
2022-09-20 22:31:50 - train: epoch 0001, iter [00270, 01251], lr: 0.000036, loss: 0.7553
2022-09-20 22:32:11 - train: epoch 0001, iter [00280, 01251], lr: 0.000037, loss: 0.7369
2022-09-20 22:32:31 - train: epoch 0001, iter [00290, 01251], lr: 0.000037, loss: 0.7575
2022-09-20 22:32:52 - train: epoch 0001, iter [00300, 01251], lr: 0.000037, loss: 0.7526
2022-09-20 22:33:12 - train: epoch 0001, iter [00310, 01251], lr: 0.000037, loss: 0.7295
2022-09-20 22:33:33 - train: epoch 0001, iter [00320, 01251], lr: 0.000038, loss: 0.7454
2022-09-20 22:33:54 - train: epoch 0001, iter [00330, 01251], lr: 0.000038, loss: 0.7470
2022-09-20 22:34:14 - train: epoch 0001, iter [00340, 01251], lr: 0.000038, loss: 0.7273
2022-09-20 22:34:35 - train: epoch 0001, iter [00350, 01251], lr: 0.000038, loss: 0.7180
2022-09-20 22:34:56 - train: epoch 0001, iter [00360, 01251], lr: 0.000039, loss: 0.7136
2022-09-20 22:35:16 - train: epoch 0001, iter [00370, 01251], lr: 0.000039, loss: 0.6929
2022-09-20 22:35:37 - train: epoch 0001, iter [00380, 01251], lr: 0.000039, loss: 0.7223
2022-09-20 22:35:57 - train: epoch 0001, iter [00390, 01251], lr: 0.000039, loss: 0.7060
2022-09-20 22:36:18 - train: epoch 0001, iter [00400, 01251], lr: 0.000040, loss: 0.7280
2022-09-20 22:36:38 - train: epoch 0001, iter [00410, 01251], lr: 0.000040, loss: 0.7233
2022-09-20 22:36:59 - train: epoch 0001, iter [00420, 01251], lr: 0.000040, loss: 0.7024
2022-09-20 22:37:19 - train: epoch 0001, iter [00430, 01251], lr: 0.000040, loss: 0.6940
2022-09-20 22:37:40 - train: epoch 0001, iter [00440, 01251], lr: 0.000041, loss: 0.6779
2022-09-20 22:38:01 - train: epoch 0001, iter [00450, 01251], lr: 0.000041, loss: 0.7092
2022-09-20 22:38:21 - train: epoch 0001, iter [00460, 01251], lr: 0.000041, loss: 0.6988
2022-09-20 22:38:41 - train: epoch 0001, iter [00470, 01251], lr: 0.000041, loss: 0.6870
2022-09-20 22:39:02 - train: epoch 0001, iter [00480, 01251], lr: 0.000042, loss: 0.7074
2022-09-20 22:39:23 - train: epoch 0001, iter [00490, 01251], lr: 0.000042, loss: 0.7072
2022-09-20 22:39:43 - train: epoch 0001, iter [00500, 01251], lr: 0.000042, loss: 0.7010
2022-09-20 22:40:04 - train: epoch 0001, iter [00510, 01251], lr: 0.000042, loss: 0.6789
2022-09-20 22:40:24 - train: epoch 0001, iter [00520, 01251], lr: 0.000042, loss: 0.6763
2022-09-20 22:40:45 - train: epoch 0001, iter [00530, 01251], lr: 0.000043, loss: 0.6947
2022-09-20 22:41:05 - train: epoch 0001, iter [00540, 01251], lr: 0.000043, loss: 0.6714
2022-09-20 22:41:26 - train: epoch 0001, iter [00550, 01251], lr: 0.000043, loss: 0.6845
2022-09-20 22:41:46 - train: epoch 0001, iter [00560, 01251], lr: 0.000043, loss: 0.6814
2022-09-20 22:42:07 - train: epoch 0001, iter [00570, 01251], lr: 0.000044, loss: 0.7025
2022-09-20 22:42:27 - train: epoch 0001, iter [00580, 01251], lr: 0.000044, loss: 0.6882
2022-09-20 22:42:48 - train: epoch 0001, iter [00590, 01251], lr: 0.000044, loss: 0.6872
2022-09-20 22:43:09 - train: epoch 0001, iter [00600, 01251], lr: 0.000044, loss: 0.6931
2022-09-20 22:43:29 - train: epoch 0001, iter [00610, 01251], lr: 0.000045, loss: 0.6432
2022-09-20 22:43:50 - train: epoch 0001, iter [00620, 01251], lr: 0.000045, loss: 0.6836
2022-09-20 22:44:11 - train: epoch 0001, iter [00630, 01251], lr: 0.000045, loss: 0.6841
2022-09-20 22:44:31 - train: epoch 0001, iter [00640, 01251], lr: 0.000045, loss: 0.6908
2022-09-20 22:44:52 - train: epoch 0001, iter [00650, 01251], lr: 0.000046, loss: 0.6775
2022-09-20 22:45:13 - train: epoch 0001, iter [00660, 01251], lr: 0.000046, loss: 0.6692
2022-09-20 22:45:33 - train: epoch 0001, iter [00670, 01251], lr: 0.000046, loss: 0.6512
2022-09-20 22:45:54 - train: epoch 0001, iter [00680, 01251], lr: 0.000046, loss: 0.6903
2022-09-20 22:46:14 - train: epoch 0001, iter [00690, 01251], lr: 0.000047, loss: 0.6728
2022-09-20 22:46:35 - train: epoch 0001, iter [00700, 01251], lr: 0.000047, loss: 0.6789
2022-09-20 22:46:55 - train: epoch 0001, iter [00710, 01251], lr: 0.000047, loss: 0.6458
2022-09-20 22:47:16 - train: epoch 0001, iter [00720, 01251], lr: 0.000047, loss: 0.6728
2022-09-20 22:47:37 - train: epoch 0001, iter [00730, 01251], lr: 0.000048, loss: 0.6601
2022-09-20 22:47:57 - train: epoch 0001, iter [00740, 01251], lr: 0.000048, loss: 0.6771
2022-09-20 22:48:18 - train: epoch 0001, iter [00750, 01251], lr: 0.000048, loss: 0.6698
2022-09-20 22:48:38 - train: epoch 0001, iter [00760, 01251], lr: 0.000048, loss: 0.6636
2022-09-20 22:48:59 - train: epoch 0001, iter [00770, 01251], lr: 0.000048, loss: 0.6640
2022-09-20 22:49:20 - train: epoch 0001, iter [00780, 01251], lr: 0.000049, loss: 0.6524
2022-09-20 22:49:41 - train: epoch 0001, iter [00790, 01251], lr: 0.000049, loss: 0.6398
2022-09-20 22:50:02 - train: epoch 0001, iter [00800, 01251], lr: 0.000049, loss: 0.6524
2022-09-20 22:50:23 - train: epoch 0001, iter [00810, 01251], lr: 0.000049, loss: 0.6655
2022-09-20 22:50:44 - train: epoch 0001, iter [00820, 01251], lr: 0.000050, loss: 0.6652
2022-09-20 22:51:05 - train: epoch 0001, iter [00830, 01251], lr: 0.000050, loss: 0.6326
2022-09-20 22:51:26 - train: epoch 0001, iter [00840, 01251], lr: 0.000050, loss: 0.6523
2022-09-20 22:51:46 - train: epoch 0001, iter [00850, 01251], lr: 0.000050, loss: 0.6373
2022-09-20 22:52:08 - train: epoch 0001, iter [00860, 01251], lr: 0.000051, loss: 0.6292
2022-09-20 22:52:28 - train: epoch 0001, iter [00870, 01251], lr: 0.000051, loss: 0.6500
2022-09-20 22:52:49 - train: epoch 0001, iter [00880, 01251], lr: 0.000051, loss: 0.6353
2022-09-20 22:53:10 - train: epoch 0001, iter [00890, 01251], lr: 0.000051, loss: 0.6271
2022-09-20 22:53:31 - train: epoch 0001, iter [00900, 01251], lr: 0.000052, loss: 0.6640
2022-09-20 22:53:52 - train: epoch 0001, iter [00910, 01251], lr: 0.000052, loss: 0.6470
2022-09-20 22:54:13 - train: epoch 0001, iter [00920, 01251], lr: 0.000052, loss: 0.6287
2022-09-20 22:54:34 - train: epoch 0001, iter [00930, 01251], lr: 0.000052, loss: 0.6552
2022-09-20 22:54:55 - train: epoch 0001, iter [00940, 01251], lr: 0.000053, loss: 0.6733
2022-09-20 22:55:16 - train: epoch 0001, iter [00950, 01251], lr: 0.000053, loss: 0.6251
2022-09-20 22:55:37 - train: epoch 0001, iter [00960, 01251], lr: 0.000053, loss: 0.6336
2022-09-20 22:55:58 - train: epoch 0001, iter [00970, 01251], lr: 0.000053, loss: 0.6472
2022-09-20 22:56:19 - train: epoch 0001, iter [00980, 01251], lr: 0.000054, loss: 0.6189
2022-09-20 22:56:40 - train: epoch 0001, iter [00990, 01251], lr: 0.000054, loss: 0.6340
2022-09-20 22:57:01 - train: epoch 0001, iter [01000, 01251], lr: 0.000054, loss: 0.6381
2022-09-20 22:57:22 - train: epoch 0001, iter [01010, 01251], lr: 0.000054, loss: 0.6177
2022-09-20 22:57:43 - train: epoch 0001, iter [01020, 01251], lr: 0.000054, loss: 0.6166
2022-09-20 22:58:04 - train: epoch 0001, iter [01030, 01251], lr: 0.000055, loss: 0.6283
2022-09-20 22:58:25 - train: epoch 0001, iter [01040, 01251], lr: 0.000055, loss: 0.6279
2022-09-20 22:58:45 - train: epoch 0001, iter [01050, 01251], lr: 0.000055, loss: 0.6217
2022-09-20 22:59:06 - train: epoch 0001, iter [01060, 01251], lr: 0.000055, loss: 0.6298
2022-09-20 22:59:27 - train: epoch 0001, iter [01070, 01251], lr: 0.000056, loss: 0.6206
2022-09-20 22:59:48 - train: epoch 0001, iter [01080, 01251], lr: 0.000056, loss: 0.6283
2022-09-20 23:00:09 - train: epoch 0001, iter [01090, 01251], lr: 0.000056, loss: 0.6149
2022-09-20 23:00:30 - train: epoch 0001, iter [01100, 01251], lr: 0.000056, loss: 0.6283
2022-09-20 23:00:51 - train: epoch 0001, iter [01110, 01251], lr: 0.000057, loss: 0.6183
2022-09-20 23:01:12 - train: epoch 0001, iter [01120, 01251], lr: 0.000057, loss: 0.6211
2022-09-20 23:01:33 - train: epoch 0001, iter [01130, 01251], lr: 0.000057, loss: 0.6077
2022-09-20 23:01:54 - train: epoch 0001, iter [01140, 01251], lr: 0.000057, loss: 0.6225
2022-09-20 23:02:15 - train: epoch 0001, iter [01150, 01251], lr: 0.000058, loss: 0.6149
2022-09-20 23:02:36 - train: epoch 0001, iter [01160, 01251], lr: 0.000058, loss: 0.6423
2022-09-20 23:02:57 - train: epoch 0001, iter [01170, 01251], lr: 0.000058, loss: 0.6167
2022-09-20 23:03:18 - train: epoch 0001, iter [01180, 01251], lr: 0.000058, loss: 0.5977
2022-09-20 23:03:39 - train: epoch 0001, iter [01190, 01251], lr: 0.000059, loss: 0.6253
2022-09-20 23:04:00 - train: epoch 0001, iter [01200, 01251], lr: 0.000059, loss: 0.6197
2022-09-20 23:04:21 - train: epoch 0001, iter [01210, 01251], lr: 0.000059, loss: 0.6141
2022-09-20 23:04:42 - train: epoch 0001, iter [01220, 01251], lr: 0.000059, loss: 0.6079
2022-09-20 23:05:03 - train: epoch 0001, iter [01230, 01251], lr: 0.000059, loss: 0.6319
2022-09-20 23:05:24 - train: epoch 0001, iter [01240, 01251], lr: 0.000060, loss: 0.5967
2022-09-20 23:05:44 - train: epoch 0001, iter [01250, 01251], lr: 0.000060, loss: 0.5994
2022-09-20 23:05:48 - train: epoch 001, train_loss: 0.7091
2022-09-20 23:05:52 - until epoch: 001, best_loss: 0.7091
2022-09-20 23:05:52 - epoch 002 lr: 0.000060
2022-09-20 23:06:31 - train: epoch 0002, iter [00010, 01251], lr: 0.000060, loss: 0.6004
2022-09-20 23:06:52 - train: epoch 0002, iter [00020, 01251], lr: 0.000060, loss: 0.5974
2022-09-20 23:07:12 - train: epoch 0002, iter [00030, 01251], lr: 0.000061, loss: 0.5974
2022-09-20 23:07:33 - train: epoch 0002, iter [00040, 01251], lr: 0.000061, loss: 0.6199
2022-09-20 23:07:54 - train: epoch 0002, iter [00050, 01251], lr: 0.000061, loss: 0.5998
2022-09-20 23:08:14 - train: epoch 0002, iter [00060, 01251], lr: 0.000061, loss: 0.6126
2022-09-20 23:08:35 - train: epoch 0002, iter [00070, 01251], lr: 0.000062, loss: 0.6034
2022-09-20 23:08:56 - train: epoch 0002, iter [00080, 01251], lr: 0.000062, loss: 0.6015
2022-09-20 23:09:17 - train: epoch 0002, iter [00090, 01251], lr: 0.000062, loss: 0.6066
2022-09-20 23:09:38 - train: epoch 0002, iter [00100, 01251], lr: 0.000062, loss: 0.5964
2022-09-20 23:09:58 - train: epoch 0002, iter [00110, 01251], lr: 0.000063, loss: 0.6052
2022-09-20 23:10:19 - train: epoch 0002, iter [00120, 01251], lr: 0.000063, loss: 0.5930
2022-09-20 23:10:40 - train: epoch 0002, iter [00130, 01251], lr: 0.000063, loss: 0.6218
2022-09-20 23:11:01 - train: epoch 0002, iter [00140, 01251], lr: 0.000063, loss: 0.6048
2022-09-20 23:11:22 - train: epoch 0002, iter [00150, 01251], lr: 0.000064, loss: 0.5965
2022-09-20 23:11:43 - train: epoch 0002, iter [00160, 01251], lr: 0.000064, loss: 0.5712
2022-09-20 23:12:04 - train: epoch 0002, iter [00170, 01251], lr: 0.000064, loss: 0.5938
2022-09-20 23:12:25 - train: epoch 0002, iter [00180, 01251], lr: 0.000064, loss: 0.5996
2022-09-20 23:12:46 - train: epoch 0002, iter [00190, 01251], lr: 0.000065, loss: 0.5723
2022-09-20 23:13:06 - train: epoch 0002, iter [00200, 01251], lr: 0.000065, loss: 0.6000
2022-09-20 23:13:27 - train: epoch 0002, iter [00210, 01251], lr: 0.000065, loss: 0.5742
2022-09-20 23:13:48 - train: epoch 0002, iter [00220, 01251], lr: 0.000065, loss: 0.6140
2022-09-20 23:14:09 - train: epoch 0002, iter [00230, 01251], lr: 0.000066, loss: 0.6009
2022-09-20 23:14:30 - train: epoch 0002, iter [00240, 01251], lr: 0.000066, loss: 0.6001
2022-09-20 23:14:50 - train: epoch 0002, iter [00250, 01251], lr: 0.000066, loss: 0.5847
2022-09-20 23:15:11 - train: epoch 0002, iter [00260, 01251], lr: 0.000066, loss: 0.5879
2022-09-20 23:15:32 - train: epoch 0002, iter [00270, 01251], lr: 0.000066, loss: 0.5793
2022-09-20 23:15:53 - train: epoch 0002, iter [00280, 01251], lr: 0.000067, loss: 0.5948
2022-09-20 23:16:14 - train: epoch 0002, iter [00290, 01251], lr: 0.000067, loss: 0.6053
2022-09-20 23:16:34 - train: epoch 0002, iter [00300, 01251], lr: 0.000067, loss: 0.5908
2022-09-20 23:16:55 - train: epoch 0002, iter [00310, 01251], lr: 0.000067, loss: 0.5945
2022-09-20 23:17:16 - train: epoch 0002, iter [00320, 01251], lr: 0.000068, loss: 0.5780
2022-09-20 23:17:37 - train: epoch 0002, iter [00330, 01251], lr: 0.000068, loss: 0.5910
2022-09-20 23:17:58 - train: epoch 0002, iter [00340, 01251], lr: 0.000068, loss: 0.5713
2022-09-20 23:18:18 - train: epoch 0002, iter [00350, 01251], lr: 0.000068, loss: 0.5704
2022-09-20 23:18:40 - train: epoch 0002, iter [00360, 01251], lr: 0.000069, loss: 0.5871
2022-09-20 23:19:00 - train: epoch 0002, iter [00370, 01251], lr: 0.000069, loss: 0.5708
2022-09-20 23:19:21 - train: epoch 0002, iter [00380, 01251], lr: 0.000069, loss: 0.5941
2022-09-20 23:19:42 - train: epoch 0002, iter [00390, 01251], lr: 0.000069, loss: 0.5690
2022-09-20 23:20:03 - train: epoch 0002, iter [00400, 01251], lr: 0.000070, loss: 0.5722
2022-09-20 23:20:24 - train: epoch 0002, iter [00410, 01251], lr: 0.000070, loss: 0.5899
2022-09-20 23:20:45 - train: epoch 0002, iter [00420, 01251], lr: 0.000070, loss: 0.5831
2022-09-20 23:21:05 - train: epoch 0002, iter [00430, 01251], lr: 0.000070, loss: 0.5790
2022-09-20 23:21:26 - train: epoch 0002, iter [00440, 01251], lr: 0.000071, loss: 0.5740
2022-09-20 23:21:47 - train: epoch 0002, iter [00450, 01251], lr: 0.000071, loss: 0.5591
2022-09-20 23:22:08 - train: epoch 0002, iter [00460, 01251], lr: 0.000071, loss: 0.5693
2022-09-20 23:22:29 - train: epoch 0002, iter [00470, 01251], lr: 0.000071, loss: 0.5797
2022-09-20 23:22:49 - train: epoch 0002, iter [00480, 01251], lr: 0.000072, loss: 0.5803
2022-09-20 23:23:10 - train: epoch 0002, iter [00490, 01251], lr: 0.000072, loss: 0.5539
2022-09-20 23:23:31 - train: epoch 0002, iter [00500, 01251], lr: 0.000072, loss: 0.5831
2022-09-20 23:23:51 - train: epoch 0002, iter [00510, 01251], lr: 0.000072, loss: 0.5966
2022-09-20 23:24:12 - train: epoch 0002, iter [00520, 01251], lr: 0.000072, loss: 0.5654
2022-09-20 23:24:33 - train: epoch 0002, iter [00530, 01251], lr: 0.000073, loss: 0.5601
2022-09-20 23:24:54 - train: epoch 0002, iter [00540, 01251], lr: 0.000073, loss: 0.5679
2022-09-20 23:25:15 - train: epoch 0002, iter [00550, 01251], lr: 0.000073, loss: 0.5795
2022-09-20 23:25:36 - train: epoch 0002, iter [00560, 01251], lr: 0.000073, loss: 0.5744
2022-09-20 23:25:57 - train: epoch 0002, iter [00570, 01251], lr: 0.000074, loss: 0.5616
2022-09-20 23:26:18 - train: epoch 0002, iter [00580, 01251], lr: 0.000074, loss: 0.5616
2022-09-20 23:26:39 - train: epoch 0002, iter [00590, 01251], lr: 0.000074, loss: 0.5617
2022-09-20 23:26:59 - train: epoch 0002, iter [00600, 01251], lr: 0.000074, loss: 0.5773
2022-09-20 23:27:20 - train: epoch 0002, iter [00610, 01251], lr: 0.000075, loss: 0.5499
2022-09-20 23:27:41 - train: epoch 0002, iter [00620, 01251], lr: 0.000075, loss: 0.5578
2022-09-20 23:28:02 - train: epoch 0002, iter [00630, 01251], lr: 0.000075, loss: 0.5703
2022-09-20 23:28:23 - train: epoch 0002, iter [00640, 01251], lr: 0.000075, loss: 0.5583
2022-09-20 23:28:44 - train: epoch 0002, iter [00650, 01251], lr: 0.000076, loss: 0.5567
2022-09-20 23:29:05 - train: epoch 0002, iter [00660, 01251], lr: 0.000076, loss: 0.5481
2022-09-20 23:29:26 - train: epoch 0002, iter [00670, 01251], lr: 0.000076, loss: 0.5610
2022-09-20 23:29:47 - train: epoch 0002, iter [00680, 01251], lr: 0.000076, loss: 0.5606
2022-09-20 23:30:07 - train: epoch 0002, iter [00690, 01251], lr: 0.000077, loss: 0.5665
2022-09-20 23:30:28 - train: epoch 0002, iter [00700, 01251], lr: 0.000077, loss: 0.5515
2022-09-20 23:30:49 - train: epoch 0002, iter [00710, 01251], lr: 0.000077, loss: 0.5543
2022-09-20 23:31:10 - train: epoch 0002, iter [00720, 01251], lr: 0.000077, loss: 0.5593
2022-09-20 23:31:31 - train: epoch 0002, iter [00730, 01251], lr: 0.000078, loss: 0.5718
2022-09-20 23:31:52 - train: epoch 0002, iter [00740, 01251], lr: 0.000078, loss: 0.5612
2022-09-20 23:32:13 - train: epoch 0002, iter [00750, 01251], lr: 0.000078, loss: 0.5886
2022-09-20 23:32:34 - train: epoch 0002, iter [00760, 01251], lr: 0.000078, loss: 0.5554
2022-09-20 23:32:55 - train: epoch 0002, iter [00770, 01251], lr: 0.000078, loss: 0.5651
2022-09-20 23:33:16 - train: epoch 0002, iter [00780, 01251], lr: 0.000079, loss: 0.5538
2022-09-20 23:33:37 - train: epoch 0002, iter [00790, 01251], lr: 0.000079, loss: 0.5517
2022-09-20 23:33:58 - train: epoch 0002, iter [00800, 01251], lr: 0.000079, loss: 0.5462
2022-09-20 23:34:19 - train: epoch 0002, iter [00810, 01251], lr: 0.000079, loss: 0.5697
2022-09-20 23:34:40 - train: epoch 0002, iter [00820, 01251], lr: 0.000080, loss: 0.5414
2022-09-20 23:35:01 - train: epoch 0002, iter [00830, 01251], lr: 0.000080, loss: 0.5636
2022-09-20 23:35:22 - train: epoch 0002, iter [00840, 01251], lr: 0.000080, loss: 0.5661
2022-09-20 23:35:43 - train: epoch 0002, iter [00850, 01251], lr: 0.000080, loss: 0.5551
2022-09-20 23:36:04 - train: epoch 0002, iter [00860, 01251], lr: 0.000081, loss: 0.5553
2022-09-20 23:36:25 - train: epoch 0002, iter [00870, 01251], lr: 0.000081, loss: 0.5646
2022-09-20 23:36:46 - train: epoch 0002, iter [00880, 01251], lr: 0.000081, loss: 0.5342
2022-09-20 23:37:07 - train: epoch 0002, iter [00890, 01251], lr: 0.000081, loss: 0.5550
2022-09-20 23:37:28 - train: epoch 0002, iter [00900, 01251], lr: 0.000082, loss: 0.5638
2022-09-20 23:37:49 - train: epoch 0002, iter [00910, 01251], lr: 0.000082, loss: 0.5334
2022-09-20 23:38:10 - train: epoch 0002, iter [00920, 01251], lr: 0.000082, loss: 0.5454
2022-09-20 23:38:31 - train: epoch 0002, iter [00930, 01251], lr: 0.000082, loss: 0.5472
2022-09-20 23:38:52 - train: epoch 0002, iter [00940, 01251], lr: 0.000083, loss: 0.5422
2022-09-20 23:39:13 - train: epoch 0002, iter [00950, 01251], lr: 0.000083, loss: 0.5527
2022-09-20 23:39:34 - train: epoch 0002, iter [00960, 01251], lr: 0.000083, loss: 0.5667
2022-09-20 23:39:55 - train: epoch 0002, iter [00970, 01251], lr: 0.000083, loss: 0.5454
2022-09-20 23:40:16 - train: epoch 0002, iter [00980, 01251], lr: 0.000084, loss: 0.5313
2022-09-20 23:40:36 - train: epoch 0002, iter [00990, 01251], lr: 0.000084, loss: 0.5480
2022-09-20 23:40:57 - train: epoch 0002, iter [01000, 01251], lr: 0.000084, loss: 0.5504
2022-09-20 23:41:18 - train: epoch 0002, iter [01010, 01251], lr: 0.000084, loss: 0.5495
2022-09-20 23:41:39 - train: epoch 0002, iter [01020, 01251], lr: 0.000084, loss: 0.5453
2022-09-20 23:42:00 - train: epoch 0002, iter [01030, 01251], lr: 0.000085, loss: 0.5335
2022-09-20 23:42:22 - train: epoch 0002, iter [01040, 01251], lr: 0.000085, loss: 0.5498
2022-09-20 23:42:43 - train: epoch 0002, iter [01050, 01251], lr: 0.000085, loss: 0.5565
2022-09-20 23:43:04 - train: epoch 0002, iter [01060, 01251], lr: 0.000085, loss: 0.5433
2022-09-20 23:43:25 - train: epoch 0002, iter [01070, 01251], lr: 0.000086, loss: 0.5426
2022-09-20 23:43:46 - train: epoch 0002, iter [01080, 01251], lr: 0.000086, loss: 0.5556
2022-09-20 23:44:07 - train: epoch 0002, iter [01090, 01251], lr: 0.000086, loss: 0.5576
2022-09-20 23:44:28 - train: epoch 0002, iter [01100, 01251], lr: 0.000086, loss: 0.5391
2022-09-20 23:44:49 - train: epoch 0002, iter [01110, 01251], lr: 0.000087, loss: 0.5620
2022-09-20 23:45:11 - train: epoch 0002, iter [01120, 01251], lr: 0.000087, loss: 0.5492
2022-09-20 23:45:32 - train: epoch 0002, iter [01130, 01251], lr: 0.000087, loss: 0.5672
2022-09-20 23:45:53 - train: epoch 0002, iter [01140, 01251], lr: 0.000087, loss: 0.5319
2022-09-20 23:46:14 - train: epoch 0002, iter [01150, 01251], lr: 0.000088, loss: 0.5231
2022-09-20 23:46:36 - train: epoch 0002, iter [01160, 01251], lr: 0.000088, loss: 0.5629
2022-09-20 23:46:57 - train: epoch 0002, iter [01170, 01251], lr: 0.000088, loss: 0.5437
2022-09-20 23:47:18 - train: epoch 0002, iter [01180, 01251], lr: 0.000088, loss: 0.5472
2022-09-20 23:47:39 - train: epoch 0002, iter [01190, 01251], lr: 0.000089, loss: 0.5369
2022-09-20 23:48:00 - train: epoch 0002, iter [01200, 01251], lr: 0.000089, loss: 0.5412
2022-09-20 23:48:21 - train: epoch 0002, iter [01210, 01251], lr: 0.000089, loss: 0.5211
2022-09-20 23:48:42 - train: epoch 0002, iter [01220, 01251], lr: 0.000089, loss: 0.5393
2022-09-20 23:49:04 - train: epoch 0002, iter [01230, 01251], lr: 0.000089, loss: 0.5467
2022-09-20 23:49:25 - train: epoch 0002, iter [01240, 01251], lr: 0.000090, loss: 0.5347
2022-09-20 23:49:45 - train: epoch 0002, iter [01250, 01251], lr: 0.000090, loss: 0.5469
2022-09-20 23:49:50 - train: epoch 002, train_loss: 0.5682
2022-09-20 23:49:55 - until epoch: 002, best_loss: 0.5682
2022-09-20 23:49:55 - epoch 003 lr: 0.000090
2022-09-20 23:50:31 - train: epoch 0003, iter [00010, 01251], lr: 0.000090, loss: 0.5400
2022-09-20 23:50:52 - train: epoch 0003, iter [00020, 01251], lr: 0.000090, loss: 0.5211
2022-09-20 23:51:13 - train: epoch 0003, iter [00030, 01251], lr: 0.000091, loss: 0.5359
2022-09-20 23:51:34 - train: epoch 0003, iter [00040, 01251], lr: 0.000091, loss: 0.5337
2022-09-20 23:51:55 - train: epoch 0003, iter [00050, 01251], lr: 0.000091, loss: 0.5250
2022-09-20 23:52:16 - train: epoch 0003, iter [00060, 01251], lr: 0.000091, loss: 0.5394
2022-09-20 23:52:37 - train: epoch 0003, iter [00070, 01251], lr: 0.000092, loss: 0.5237
2022-09-20 23:52:58 - train: epoch 0003, iter [00080, 01251], lr: 0.000092, loss: 0.5242
2022-09-20 23:53:19 - train: epoch 0003, iter [00090, 01251], lr: 0.000092, loss: 0.5371
2022-09-20 23:53:40 - train: epoch 0003, iter [00100, 01251], lr: 0.000092, loss: 0.5315
2022-09-20 23:54:01 - train: epoch 0003, iter [00110, 01251], lr: 0.000093, loss: 0.5233
2022-09-20 23:54:22 - train: epoch 0003, iter [00120, 01251], lr: 0.000093, loss: 0.5407
2022-09-20 23:54:43 - train: epoch 0003, iter [00130, 01251], lr: 0.000093, loss: 0.5140
2022-09-20 23:55:04 - train: epoch 0003, iter [00140, 01251], lr: 0.000093, loss: 0.5306
2022-09-20 23:55:25 - train: epoch 0003, iter [00150, 01251], lr: 0.000094, loss: 0.5356
2022-09-20 23:55:46 - train: epoch 0003, iter [00160, 01251], lr: 0.000094, loss: 0.5335
2022-09-20 23:56:07 - train: epoch 0003, iter [00170, 01251], lr: 0.000094, loss: 0.5442
2022-09-20 23:56:28 - train: epoch 0003, iter [00180, 01251], lr: 0.000094, loss: 0.5291
2022-09-20 23:56:50 - train: epoch 0003, iter [00190, 01251], lr: 0.000095, loss: 0.5232
2022-09-20 23:57:11 - train: epoch 0003, iter [00200, 01251], lr: 0.000095, loss: 0.5306
2022-09-20 23:57:32 - train: epoch 0003, iter [00210, 01251], lr: 0.000095, loss: 0.5273
2022-09-20 23:57:53 - train: epoch 0003, iter [00220, 01251], lr: 0.000095, loss: 0.5476
2022-09-20 23:58:15 - train: epoch 0003, iter [00230, 01251], lr: 0.000096, loss: 0.5255
2022-09-20 23:58:36 - train: epoch 0003, iter [00240, 01251], lr: 0.000096, loss: 0.5313
2022-09-20 23:58:57 - train: epoch 0003, iter [00250, 01251], lr: 0.000096, loss: 0.5227
2022-09-20 23:59:18 - train: epoch 0003, iter [00260, 01251], lr: 0.000096, loss: 0.5343
2022-09-20 23:59:39 - train: epoch 0003, iter [00270, 01251], lr: 0.000096, loss: 0.5288
2022-09-21 00:00:00 - train: epoch 0003, iter [00280, 01251], lr: 0.000097, loss: 0.5394
2022-09-21 00:00:22 - train: epoch 0003, iter [00290, 01251], lr: 0.000097, loss: 0.5550
2022-09-21 00:00:43 - train: epoch 0003, iter [00300, 01251], lr: 0.000097, loss: 0.5427
2022-09-21 00:01:04 - train: epoch 0003, iter [00310, 01251], lr: 0.000097, loss: 0.5286
2022-09-21 00:01:25 - train: epoch 0003, iter [00320, 01251], lr: 0.000098, loss: 0.5424
2022-09-21 00:01:46 - train: epoch 0003, iter [00330, 01251], lr: 0.000098, loss: 0.5282
2022-09-21 00:02:07 - train: epoch 0003, iter [00340, 01251], lr: 0.000098, loss: 0.5152
2022-09-21 00:02:28 - train: epoch 0003, iter [00350, 01251], lr: 0.000098, loss: 0.5240
2022-09-21 00:02:49 - train: epoch 0003, iter [00360, 01251], lr: 0.000099, loss: 0.5332
2022-09-21 00:03:10 - train: epoch 0003, iter [00370, 01251], lr: 0.000099, loss: 0.5410
2022-09-21 00:03:31 - train: epoch 0003, iter [00380, 01251], lr: 0.000099, loss: 0.5209
2022-09-21 00:03:53 - train: epoch 0003, iter [00390, 01251], lr: 0.000099, loss: 0.5475
2022-09-21 00:04:14 - train: epoch 0003, iter [00400, 01251], lr: 0.000100, loss: 0.5298
2022-09-21 00:04:35 - train: epoch 0003, iter [00410, 01251], lr: 0.000100, loss: 0.5335
2022-09-21 00:04:56 - train: epoch 0003, iter [00420, 01251], lr: 0.000100, loss: 0.5180
2022-09-21 00:05:17 - train: epoch 0003, iter [00430, 01251], lr: 0.000100, loss: 0.5183
2022-09-21 00:05:38 - train: epoch 0003, iter [00440, 01251], lr: 0.000101, loss: 0.5296
2022-09-21 00:05:59 - train: epoch 0003, iter [00450, 01251], lr: 0.000101, loss: 0.5368
2022-09-21 00:06:20 - train: epoch 0003, iter [00460, 01251], lr: 0.000101, loss: 0.5239
2022-09-21 00:06:41 - train: epoch 0003, iter [00470, 01251], lr: 0.000101, loss: 0.5227
2022-09-21 00:07:03 - train: epoch 0003, iter [00480, 01251], lr: 0.000102, loss: 0.5345
2022-09-21 00:07:24 - train: epoch 0003, iter [00490, 01251], lr: 0.000102, loss: 0.5306
2022-09-21 00:07:45 - train: epoch 0003, iter [00500, 01251], lr: 0.000102, loss: 0.5269
2022-09-21 00:08:06 - train: epoch 0003, iter [00510, 01251], lr: 0.000102, loss: 0.5374
2022-09-21 00:08:28 - train: epoch 0003, iter [00520, 01251], lr: 0.000102, loss: 0.5195
2022-09-21 00:08:49 - train: epoch 0003, iter [00530, 01251], lr: 0.000103, loss: 0.5177
2022-09-21 00:09:10 - train: epoch 0003, iter [00540, 01251], lr: 0.000103, loss: 0.5129
2022-09-21 00:09:31 - train: epoch 0003, iter [00550, 01251], lr: 0.000103, loss: 0.5035
2022-09-21 00:09:52 - train: epoch 0003, iter [00560, 01251], lr: 0.000103, loss: 0.5355
2022-09-21 00:10:13 - train: epoch 0003, iter [00570, 01251], lr: 0.000104, loss: 0.5033
2022-09-21 00:10:34 - train: epoch 0003, iter [00580, 01251], lr: 0.000104, loss: 0.5250
2022-09-21 00:10:55 - train: epoch 0003, iter [00590, 01251], lr: 0.000104, loss: 0.5420
2022-09-21 00:11:16 - train: epoch 0003, iter [00600, 01251], lr: 0.000104, loss: 0.5476
2022-09-21 00:11:38 - train: epoch 0003, iter [00610, 01251], lr: 0.000105, loss: 0.5259
2022-09-21 00:11:59 - train: epoch 0003, iter [00620, 01251], lr: 0.000105, loss: 0.5214
2022-09-21 00:12:20 - train: epoch 0003, iter [00630, 01251], lr: 0.000105, loss: 0.5134
2022-09-21 00:12:41 - train: epoch 0003, iter [00640, 01251], lr: 0.000105, loss: 0.5263
2022-09-21 00:13:03 - train: epoch 0003, iter [00650, 01251], lr: 0.000106, loss: 0.5080
2022-09-21 00:13:24 - train: epoch 0003, iter [00660, 01251], lr: 0.000106, loss: 0.5107
2022-09-21 00:13:45 - train: epoch 0003, iter [00670, 01251], lr: 0.000106, loss: 0.5245
2022-09-21 00:14:07 - train: epoch 0003, iter [00680, 01251], lr: 0.000106, loss: 0.5311
2022-09-21 00:14:28 - train: epoch 0003, iter [00690, 01251], lr: 0.000107, loss: 0.5232
2022-09-21 00:14:49 - train: epoch 0003, iter [00700, 01251], lr: 0.000107, loss: 0.5377
2022-09-21 00:15:10 - train: epoch 0003, iter [00710, 01251], lr: 0.000107, loss: 0.5269
2022-09-21 00:15:32 - train: epoch 0003, iter [00720, 01251], lr: 0.000107, loss: 0.5159
2022-09-21 00:15:53 - train: epoch 0003, iter [00730, 01251], lr: 0.000108, loss: 0.4944
2022-09-21 00:16:14 - train: epoch 0003, iter [00740, 01251], lr: 0.000108, loss: 0.4992
2022-09-21 00:16:36 - train: epoch 0003, iter [00750, 01251], lr: 0.000108, loss: 0.5136
2022-09-21 00:16:57 - train: epoch 0003, iter [00760, 01251], lr: 0.000108, loss: 0.5066
2022-09-21 00:17:18 - train: epoch 0003, iter [00770, 01251], lr: 0.000108, loss: 0.5049
2022-09-21 00:17:39 - train: epoch 0003, iter [00780, 01251], lr: 0.000109, loss: 0.5199
2022-09-21 00:18:01 - train: epoch 0003, iter [00790, 01251], lr: 0.000109, loss: 0.5135
2022-09-21 00:18:22 - train: epoch 0003, iter [00800, 01251], lr: 0.000109, loss: 0.5174
2022-09-21 00:18:43 - train: epoch 0003, iter [00810, 01251], lr: 0.000109, loss: 0.5108
2022-09-21 00:19:04 - train: epoch 0003, iter [00820, 01251], lr: 0.000110, loss: 0.5208
2022-09-21 00:19:25 - train: epoch 0003, iter [00830, 01251], lr: 0.000110, loss: 0.5400
2022-09-21 00:19:46 - train: epoch 0003, iter [00840, 01251], lr: 0.000110, loss: 0.5244
2022-09-21 00:20:08 - train: epoch 0003, iter [00850, 01251], lr: 0.000110, loss: 0.5125
2022-09-21 00:20:29 - train: epoch 0003, iter [00860, 01251], lr: 0.000111, loss: 0.5466
2022-09-21 00:20:50 - train: epoch 0003, iter [00870, 01251], lr: 0.000111, loss: 0.5284
2022-09-21 00:21:11 - train: epoch 0003, iter [00880, 01251], lr: 0.000111, loss: 0.5268
2022-09-21 00:21:33 - train: epoch 0003, iter [00890, 01251], lr: 0.000111, loss: 0.5105
2022-09-21 00:21:54 - train: epoch 0003, iter [00900, 01251], lr: 0.000112, loss: 0.5280
2022-09-21 00:22:15 - train: epoch 0003, iter [00910, 01251], lr: 0.000112, loss: 0.5154
2022-09-21 00:22:36 - train: epoch 0003, iter [00920, 01251], lr: 0.000112, loss: 0.5124
2022-09-21 00:22:58 - train: epoch 0003, iter [00930, 01251], lr: 0.000112, loss: 0.5213
2022-09-21 00:23:19 - train: epoch 0003, iter [00940, 01251], lr: 0.000113, loss: 0.5307
2022-09-21 00:23:40 - train: epoch 0003, iter [00950, 01251], lr: 0.000113, loss: 0.5013
2022-09-21 00:24:01 - train: epoch 0003, iter [00960, 01251], lr: 0.000113, loss: 0.5498
2022-09-21 00:24:23 - train: epoch 0003, iter [00970, 01251], lr: 0.000113, loss: 0.5227
2022-09-21 00:24:44 - train: epoch 0003, iter [00980, 01251], lr: 0.000114, loss: 0.5179
2022-09-21 00:25:05 - train: epoch 0003, iter [00990, 01251], lr: 0.000114, loss: 0.5088
2022-09-21 00:25:27 - train: epoch 0003, iter [01000, 01251], lr: 0.000114, loss: 0.5106
2022-09-21 00:25:48 - train: epoch 0003, iter [01010, 01251], lr: 0.000114, loss: 0.5053
2022-09-21 00:26:09 - train: epoch 0003, iter [01020, 01251], lr: 0.000114, loss: 0.5005
2022-09-21 00:26:30 - train: epoch 0003, iter [01030, 01251], lr: 0.000115, loss: 0.5269
2022-09-21 00:26:52 - train: epoch 0003, iter [01040, 01251], lr: 0.000115, loss: 0.5282
2022-09-21 00:27:13 - train: epoch 0003, iter [01050, 01251], lr: 0.000115, loss: 0.5160
2022-09-21 00:27:34 - train: epoch 0003, iter [01060, 01251], lr: 0.000115, loss: 0.5131
2022-09-21 00:27:56 - train: epoch 0003, iter [01070, 01251], lr: 0.000116, loss: 0.5205
2022-09-21 00:28:17 - train: epoch 0003, iter [01080, 01251], lr: 0.000116, loss: 0.5173
2022-09-21 00:28:38 - train: epoch 0003, iter [01090, 01251], lr: 0.000116, loss: 0.5110
2022-09-21 00:28:59 - train: epoch 0003, iter [01100, 01251], lr: 0.000116, loss: 0.5174
2022-09-21 00:29:21 - train: epoch 0003, iter [01110, 01251], lr: 0.000117, loss: 0.4896
2022-09-21 00:29:42 - train: epoch 0003, iter [01120, 01251], lr: 0.000117, loss: 0.5067
2022-09-21 00:30:03 - train: epoch 0003, iter [01130, 01251], lr: 0.000117, loss: 0.5048
2022-09-21 00:30:25 - train: epoch 0003, iter [01140, 01251], lr: 0.000117, loss: 0.4999
2022-09-21 00:30:46 - train: epoch 0003, iter [01150, 01251], lr: 0.000118, loss: 0.5052
2022-09-21 00:31:07 - train: epoch 0003, iter [01160, 01251], lr: 0.000118, loss: 0.4981
2022-09-21 00:31:28 - train: epoch 0003, iter [01170, 01251], lr: 0.000118, loss: 0.4994
2022-09-21 00:31:50 - train: epoch 0003, iter [01180, 01251], lr: 0.000118, loss: 0.4910
2022-09-21 00:32:11 - train: epoch 0003, iter [01190, 01251], lr: 0.000119, loss: 0.4935
2022-09-21 00:32:32 - train: epoch 0003, iter [01200, 01251], lr: 0.000119, loss: 0.5206
2022-09-21 00:32:53 - train: epoch 0003, iter [01210, 01251], lr: 0.000119, loss: 0.5095
2022-09-21 00:33:14 - train: epoch 0003, iter [01220, 01251], lr: 0.000119, loss: 0.5084
2022-09-21 00:33:36 - train: epoch 0003, iter [01230, 01251], lr: 0.000119, loss: 0.5028
2022-09-21 00:33:57 - train: epoch 0003, iter [01240, 01251], lr: 0.000120, loss: 0.5272
2022-09-21 00:34:17 - train: epoch 0003, iter [01250, 01251], lr: 0.000120, loss: 0.5258
2022-09-21 00:34:22 - train: epoch 003, train_loss: 0.5232
2022-09-21 00:34:27 - until epoch: 003, best_loss: 0.5232
2022-09-21 00:34:27 - epoch 004 lr: 0.000120
2022-09-21 00:35:03 - train: epoch 0004, iter [00010, 01251], lr: 0.000120, loss: 0.5269
2022-09-21 00:35:24 - train: epoch 0004, iter [00020, 01251], lr: 0.000120, loss: 0.5021
2022-09-21 00:35:45 - train: epoch 0004, iter [00030, 01251], lr: 0.000121, loss: 0.5154
2022-09-21 00:36:06 - train: epoch 0004, iter [00040, 01251], lr: 0.000121, loss: 0.5200
2022-09-21 00:36:27 - train: epoch 0004, iter [00050, 01251], lr: 0.000121, loss: 0.5253
2022-09-21 00:36:48 - train: epoch 0004, iter [00060, 01251], lr: 0.000121, loss: 0.5322
2022-09-21 00:37:10 - train: epoch 0004, iter [00070, 01251], lr: 0.000122, loss: 0.5150
2022-09-21 00:37:31 - train: epoch 0004, iter [00080, 01251], lr: 0.000122, loss: 0.5083
2022-09-21 00:37:52 - train: epoch 0004, iter [00090, 01251], lr: 0.000122, loss: 0.5138
2022-09-21 00:38:13 - train: epoch 0004, iter [00100, 01251], lr: 0.000122, loss: 0.5098
2022-09-21 00:38:34 - train: epoch 0004, iter [00110, 01251], lr: 0.000123, loss: 0.5146
2022-09-21 00:38:56 - train: epoch 0004, iter [00120, 01251], lr: 0.000123, loss: 0.4944
2022-09-21 00:39:17 - train: epoch 0004, iter [00130, 01251], lr: 0.000123, loss: 0.5046
2022-09-21 00:39:38 - train: epoch 0004, iter [00140, 01251], lr: 0.000123, loss: 0.5135
2022-09-21 00:39:59 - train: epoch 0004, iter [00150, 01251], lr: 0.000124, loss: 0.5049
2022-09-21 00:40:20 - train: epoch 0004, iter [00160, 01251], lr: 0.000124, loss: 0.5025
2022-09-21 00:40:41 - train: epoch 0004, iter [00170, 01251], lr: 0.000124, loss: 0.4884
2022-09-21 00:41:03 - train: epoch 0004, iter [00180, 01251], lr: 0.000124, loss: 0.4916
2022-09-21 00:41:24 - train: epoch 0004, iter [00190, 01251], lr: 0.000125, loss: 0.4905
2022-09-21 00:41:45 - train: epoch 0004, iter [00200, 01251], lr: 0.000125, loss: 0.5122
2022-09-21 00:42:06 - train: epoch 0004, iter [00210, 01251], lr: 0.000125, loss: 0.4945
2022-09-21 00:42:27 - train: epoch 0004, iter [00220, 01251], lr: 0.000125, loss: 0.5172
2022-09-21 00:42:48 - train: epoch 0004, iter [00230, 01251], lr: 0.000126, loss: 0.5098
2022-09-21 00:43:09 - train: epoch 0004, iter [00240, 01251], lr: 0.000126, loss: 0.4883
2022-09-21 00:43:31 - train: epoch 0004, iter [00250, 01251], lr: 0.000126, loss: 0.5005
2022-09-21 00:43:52 - train: epoch 0004, iter [00260, 01251], lr: 0.000126, loss: 0.5079
2022-09-21 00:44:13 - train: epoch 0004, iter [00270, 01251], lr: 0.000126, loss: 0.5035
2022-09-21 00:44:34 - train: epoch 0004, iter [00280, 01251], lr: 0.000127, loss: 0.5245
2022-09-21 00:44:55 - train: epoch 0004, iter [00290, 01251], lr: 0.000127, loss: 0.4794
2022-09-21 00:45:17 - train: epoch 0004, iter [00300, 01251], lr: 0.000127, loss: 0.5038
2022-09-21 00:45:38 - train: epoch 0004, iter [00310, 01251], lr: 0.000127, loss: 0.5032
2022-09-21 00:46:00 - train: epoch 0004, iter [00320, 01251], lr: 0.000128, loss: 0.4935
2022-09-21 00:46:21 - train: epoch 0004, iter [00330, 01251], lr: 0.000128, loss: 0.5008
2022-09-21 00:46:42 - train: epoch 0004, iter [00340, 01251], lr: 0.000128, loss: 0.5190
2022-09-21 00:47:04 - train: epoch 0004, iter [00350, 01251], lr: 0.000128, loss: 0.4978
2022-09-21 00:47:25 - train: epoch 0004, iter [00360, 01251], lr: 0.000129, loss: 0.5105
2022-09-21 00:47:46 - train: epoch 0004, iter [00370, 01251], lr: 0.000129, loss: 0.4998
2022-09-21 00:48:07 - train: epoch 0004, iter [00380, 01251], lr: 0.000129, loss: 0.4918
2022-09-21 00:48:29 - train: epoch 0004, iter [00390, 01251], lr: 0.000129, loss: 0.5152
2022-09-21 00:48:50 - train: epoch 0004, iter [00400, 01251], lr: 0.000130, loss: 0.5053
2022-09-21 00:49:11 - train: epoch 0004, iter [00410, 01251], lr: 0.000130, loss: 0.5076
2022-09-21 00:49:32 - train: epoch 0004, iter [00420, 01251], lr: 0.000130, loss: 0.5144
2022-09-21 00:49:53 - train: epoch 0004, iter [00430, 01251], lr: 0.000130, loss: 0.4981
2022-09-21 00:50:15 - train: epoch 0004, iter [00440, 01251], lr: 0.000131, loss: 0.4813
2022-09-21 00:50:36 - train: epoch 0004, iter [00450, 01251], lr: 0.000131, loss: 0.5112
2022-09-21 00:50:57 - train: epoch 0004, iter [00460, 01251], lr: 0.000131, loss: 0.4912
2022-09-21 00:51:18 - train: epoch 0004, iter [00470, 01251], lr: 0.000131, loss: 0.5064
2022-09-21 00:51:39 - train: epoch 0004, iter [00480, 01251], lr: 0.000132, loss: 0.4724
2022-09-21 00:52:01 - train: epoch 0004, iter [00490, 01251], lr: 0.000132, loss: 0.4896
2022-09-21 00:52:22 - train: epoch 0004, iter [00500, 01251], lr: 0.000132, loss: 0.4967
2022-09-21 00:52:43 - train: epoch 0004, iter [00510, 01251], lr: 0.000132, loss: 0.4846
2022-09-21 00:53:04 - train: epoch 0004, iter [00520, 01251], lr: 0.000132, loss: 0.5141
2022-09-21 00:53:25 - train: epoch 0004, iter [00530, 01251], lr: 0.000133, loss: 0.5019
2022-09-21 00:53:47 - train: epoch 0004, iter [00540, 01251], lr: 0.000133, loss: 0.4897
2022-09-21 00:54:08 - train: epoch 0004, iter [00550, 01251], lr: 0.000133, loss: 0.4810
2022-09-21 00:54:29 - train: epoch 0004, iter [00560, 01251], lr: 0.000133, loss: 0.4860
2022-09-21 00:54:50 - train: epoch 0004, iter [00570, 01251], lr: 0.000134, loss: 0.4831
2022-09-21 00:55:12 - train: epoch 0004, iter [00580, 01251], lr: 0.000134, loss: 0.5064
2022-09-21 00:55:33 - train: epoch 0004, iter [00590, 01251], lr: 0.000134, loss: 0.4933
2022-09-21 00:55:54 - train: epoch 0004, iter [00600, 01251], lr: 0.000134, loss: 0.5011
2022-09-21 00:56:15 - train: epoch 0004, iter [00610, 01251], lr: 0.000135, loss: 0.4886
2022-09-21 00:56:37 - train: epoch 0004, iter [00620, 01251], lr: 0.000135, loss: 0.4885
2022-09-21 00:56:58 - train: epoch 0004, iter [00630, 01251], lr: 0.000135, loss: 0.5011
2022-09-21 00:57:19 - train: epoch 0004, iter [00640, 01251], lr: 0.000135, loss: 0.5089
2022-09-21 00:57:40 - train: epoch 0004, iter [00650, 01251], lr: 0.000136, loss: 0.4522
2022-09-21 00:58:02 - train: epoch 0004, iter [00660, 01251], lr: 0.000136, loss: 0.5088
2022-09-21 00:58:23 - train: epoch 0004, iter [00670, 01251], lr: 0.000136, loss: 0.5261
2022-09-21 00:58:44 - train: epoch 0004, iter [00680, 01251], lr: 0.000136, loss: 0.4956
2022-09-21 00:59:05 - train: epoch 0004, iter [00690, 01251], lr: 0.000137, loss: 0.4920
2022-09-21 00:59:26 - train: epoch 0004, iter [00700, 01251], lr: 0.000137, loss: 0.5120
2022-09-21 00:59:48 - train: epoch 0004, iter [00710, 01251], lr: 0.000137, loss: 0.5052
2022-09-21 01:00:09 - train: epoch 0004, iter [00720, 01251], lr: 0.000137, loss: 0.4851
2022-09-21 01:00:30 - train: epoch 0004, iter [00730, 01251], lr: 0.000138, loss: 0.4876
2022-09-21 01:00:51 - train: epoch 0004, iter [00740, 01251], lr: 0.000138, loss: 0.5114
2022-09-21 01:01:13 - train: epoch 0004, iter [00750, 01251], lr: 0.000138, loss: 0.4987
2022-09-21 01:01:34 - train: epoch 0004, iter [00760, 01251], lr: 0.000138, loss: 0.5016
2022-09-21 01:01:55 - train: epoch 0004, iter [00770, 01251], lr: 0.000138, loss: 0.4956
2022-09-21 01:02:17 - train: epoch 0004, iter [00780, 01251], lr: 0.000139, loss: 0.5095
2022-09-21 01:02:38 - train: epoch 0004, iter [00790, 01251], lr: 0.000139, loss: 0.5009
2022-09-21 01:03:00 - train: epoch 0004, iter [00800, 01251], lr: 0.000139, loss: 0.4902
2022-09-21 01:03:21 - train: epoch 0004, iter [00810, 01251], lr: 0.000139, loss: 0.4950
2022-09-21 01:03:42 - train: epoch 0004, iter [00820, 01251], lr: 0.000140, loss: 0.4875
2022-09-21 01:04:04 - train: epoch 0004, iter [00830, 01251], lr: 0.000140, loss: 0.4653
2022-09-21 01:04:25 - train: epoch 0004, iter [00840, 01251], lr: 0.000140, loss: 0.5076
2022-09-21 01:04:46 - train: epoch 0004, iter [00850, 01251], lr: 0.000140, loss: 0.4961
2022-09-21 01:05:07 - train: epoch 0004, iter [00860, 01251], lr: 0.000141, loss: 0.5128
2022-09-21 01:05:28 - train: epoch 0004, iter [00870, 01251], lr: 0.000141, loss: 0.5251
2022-09-21 01:05:50 - train: epoch 0004, iter [00880, 01251], lr: 0.000141, loss: 0.4962
2022-09-21 01:06:11 - train: epoch 0004, iter [00890, 01251], lr: 0.000141, loss: 0.4931
2022-09-21 01:06:32 - train: epoch 0004, iter [00900, 01251], lr: 0.000142, loss: 0.4984
2022-09-21 01:06:53 - train: epoch 0004, iter [00910, 01251], lr: 0.000142, loss: 0.5166
2022-09-21 01:07:15 - train: epoch 0004, iter [00920, 01251], lr: 0.000142, loss: 0.5022
2022-09-21 01:07:36 - train: epoch 0004, iter [00930, 01251], lr: 0.000142, loss: 0.4855
2022-09-21 01:07:57 - train: epoch 0004, iter [00940, 01251], lr: 0.000143, loss: 0.5160
2022-09-21 01:08:19 - train: epoch 0004, iter [00950, 01251], lr: 0.000143, loss: 0.4945
2022-09-21 01:08:40 - train: epoch 0004, iter [00960, 01251], lr: 0.000143, loss: 0.4968
2022-09-21 01:09:01 - train: epoch 0004, iter [00970, 01251], lr: 0.000143, loss: 0.4832
2022-09-21 01:09:22 - train: epoch 0004, iter [00980, 01251], lr: 0.000144, loss: 0.5062
2022-09-21 01:09:44 - train: epoch 0004, iter [00990, 01251], lr: 0.000144, loss: 0.4831
2022-09-21 01:10:05 - train: epoch 0004, iter [01000, 01251], lr: 0.000144, loss: 0.4966
2022-09-21 01:10:26 - train: epoch 0004, iter [01010, 01251], lr: 0.000144, loss: 0.4944
2022-09-21 01:10:47 - train: epoch 0004, iter [01020, 01251], lr: 0.000144, loss: 0.4900
2022-09-21 01:11:09 - train: epoch 0004, iter [01030, 01251], lr: 0.000145, loss: 0.4732
2022-09-21 01:11:30 - train: epoch 0004, iter [01040, 01251], lr: 0.000145, loss: 0.4951
2022-09-21 01:11:51 - train: epoch 0004, iter [01050, 01251], lr: 0.000145, loss: 0.4832
2022-09-21 01:12:12 - train: epoch 0004, iter [01060, 01251], lr: 0.000145, loss: 0.4837
2022-09-21 01:12:34 - train: epoch 0004, iter [01070, 01251], lr: 0.000146, loss: 0.4849
2022-09-21 01:12:55 - train: epoch 0004, iter [01080, 01251], lr: 0.000146, loss: 0.4997
2022-09-21 01:13:16 - train: epoch 0004, iter [01090, 01251], lr: 0.000146, loss: 0.4818
2022-09-21 01:13:38 - train: epoch 0004, iter [01100, 01251], lr: 0.000146, loss: 0.4956
2022-09-21 01:13:59 - train: epoch 0004, iter [01110, 01251], lr: 0.000147, loss: 0.4706
2022-09-21 01:14:20 - train: epoch 0004, iter [01120, 01251], lr: 0.000147, loss: 0.4933
2022-09-21 01:14:41 - train: epoch 0004, iter [01130, 01251], lr: 0.000147, loss: 0.5145
2022-09-21 01:15:02 - train: epoch 0004, iter [01140, 01251], lr: 0.000147, loss: 0.4718
2022-09-21 01:15:24 - train: epoch 0004, iter [01150, 01251], lr: 0.000148, loss: 0.5130
2022-09-21 01:15:45 - train: epoch 0004, iter [01160, 01251], lr: 0.000148, loss: 0.4835
2022-09-21 01:16:06 - train: epoch 0004, iter [01170, 01251], lr: 0.000148, loss: 0.4849
2022-09-21 01:16:27 - train: epoch 0004, iter [01180, 01251], lr: 0.000148, loss: 0.4830
2022-09-21 01:16:49 - train: epoch 0004, iter [01190, 01251], lr: 0.000149, loss: 0.5097
2022-09-21 01:17:10 - train: epoch 0004, iter [01200, 01251], lr: 0.000149, loss: 0.5037
2022-09-21 01:17:31 - train: epoch 0004, iter [01210, 01251], lr: 0.000149, loss: 0.4947
2022-09-21 01:17:52 - train: epoch 0004, iter [01220, 01251], lr: 0.000149, loss: 0.4834
2022-09-21 01:18:13 - train: epoch 0004, iter [01230, 01251], lr: 0.000149, loss: 0.4734
2022-09-21 01:18:35 - train: epoch 0004, iter [01240, 01251], lr: 0.000150, loss: 0.4911
2022-09-21 01:18:55 - train: epoch 0004, iter [01250, 01251], lr: 0.000150, loss: 0.4918
2022-09-21 01:19:00 - train: epoch 004, train_loss: 0.4996
2022-09-21 01:19:05 - until epoch: 004, best_loss: 0.4996
2022-09-21 01:19:05 - epoch 005 lr: 0.000150
2022-09-21 01:19:41 - train: epoch 0005, iter [00010, 01251], lr: 0.000150, loss: 0.4895
2022-09-21 01:20:02 - train: epoch 0005, iter [00020, 01251], lr: 0.000150, loss: 0.5132
2022-09-21 01:20:22 - train: epoch 0005, iter [00030, 01251], lr: 0.000151, loss: 0.4936
2022-09-21 01:20:43 - train: epoch 0005, iter [00040, 01251], lr: 0.000151, loss: 0.5072
2022-09-21 01:21:04 - train: epoch 0005, iter [00050, 01251], lr: 0.000151, loss: 0.5111
2022-09-21 01:21:25 - train: epoch 0005, iter [00060, 01251], lr: 0.000151, loss: 0.4979
2022-09-21 01:21:46 - train: epoch 0005, iter [00070, 01251], lr: 0.000152, loss: 0.4878
2022-09-21 01:22:07 - train: epoch 0005, iter [00080, 01251], lr: 0.000152, loss: 0.4874
2022-09-21 01:22:28 - train: epoch 0005, iter [00090, 01251], lr: 0.000152, loss: 0.4829
2022-09-21 01:22:49 - train: epoch 0005, iter [00100, 01251], lr: 0.000152, loss: 0.5052
2022-09-21 01:23:10 - train: epoch 0005, iter [00110, 01251], lr: 0.000153, loss: 0.4973
2022-09-21 01:23:31 - train: epoch 0005, iter [00120, 01251], lr: 0.000153, loss: 0.4804
2022-09-21 01:23:52 - train: epoch 0005, iter [00130, 01251], lr: 0.000153, loss: 0.5153
2022-09-21 01:24:13 - train: epoch 0005, iter [00140, 01251], lr: 0.000153, loss: 0.5011
2022-09-21 01:24:34 - train: epoch 0005, iter [00150, 01251], lr: 0.000154, loss: 0.5030
2022-09-21 01:24:55 - train: epoch 0005, iter [00160, 01251], lr: 0.000154, loss: 0.4947
2022-09-21 01:25:16 - train: epoch 0005, iter [00170, 01251], lr: 0.000154, loss: 0.4932
2022-09-21 01:25:37 - train: epoch 0005, iter [00180, 01251], lr: 0.000154, loss: 0.4960
2022-09-21 01:25:58 - train: epoch 0005, iter [00190, 01251], lr: 0.000155, loss: 0.4994
2022-09-21 01:26:19 - train: epoch 0005, iter [00200, 01251], lr: 0.000155, loss: 0.4680
2022-09-21 01:26:40 - train: epoch 0005, iter [00210, 01251], lr: 0.000155, loss: 0.4910
2022-09-21 01:27:01 - train: epoch 0005, iter [00220, 01251], lr: 0.000155, loss: 0.4935
2022-09-21 01:27:22 - train: epoch 0005, iter [00230, 01251], lr: 0.000156, loss: 0.4974
2022-09-21 01:27:43 - train: epoch 0005, iter [00240, 01251], lr: 0.000156, loss: 0.4911
2022-09-21 01:28:04 - train: epoch 0005, iter [00250, 01251], lr: 0.000156, loss: 0.4863
2022-09-21 01:28:25 - train: epoch 0005, iter [00260, 01251], lr: 0.000156, loss: 0.4715
2022-09-21 01:28:46 - train: epoch 0005, iter [00270, 01251], lr: 0.000156, loss: 0.4981
2022-09-21 01:29:07 - train: epoch 0005, iter [00280, 01251], lr: 0.000157, loss: 0.4863
2022-09-21 01:29:29 - train: epoch 0005, iter [00290, 01251], lr: 0.000157, loss: 0.4937
2022-09-21 01:29:50 - train: epoch 0005, iter [00300, 01251], lr: 0.000157, loss: 0.4690
2022-09-21 01:30:11 - train: epoch 0005, iter [00310, 01251], lr: 0.000157, loss: 0.4960
2022-09-21 01:30:32 - train: epoch 0005, iter [00320, 01251], lr: 0.000158, loss: 0.4948
2022-09-21 01:30:53 - train: epoch 0005, iter [00330, 01251], lr: 0.000158, loss: 0.4901
2022-09-21 01:31:15 - train: epoch 0005, iter [00340, 01251], lr: 0.000158, loss: 0.4829
2022-09-21 01:31:36 - train: epoch 0005, iter [00350, 01251], lr: 0.000158, loss: 0.4743
2022-09-21 01:31:57 - train: epoch 0005, iter [00360, 01251], lr: 0.000159, loss: 0.4987
2022-09-21 01:32:18 - train: epoch 0005, iter [00370, 01251], lr: 0.000159, loss: 0.4867
2022-09-21 01:32:40 - train: epoch 0005, iter [00380, 01251], lr: 0.000159, loss: 0.5054
2022-09-21 01:33:01 - train: epoch 0005, iter [00390, 01251], lr: 0.000159, loss: 0.4910
2022-09-21 01:33:22 - train: epoch 0005, iter [00400, 01251], lr: 0.000160, loss: 0.5076
2022-09-21 01:33:43 - train: epoch 0005, iter [00410, 01251], lr: 0.000160, loss: 0.5024
2022-09-21 01:34:05 - train: epoch 0005, iter [00420, 01251], lr: 0.000160, loss: 0.4773
2022-09-21 01:34:26 - train: epoch 0005, iter [00430, 01251], lr: 0.000160, loss: 0.4604
2022-09-21 01:34:48 - train: epoch 0005, iter [00440, 01251], lr: 0.000161, loss: 0.4874
2022-09-21 01:35:09 - train: epoch 0005, iter [00450, 01251], lr: 0.000161, loss: 0.4877
2022-09-21 01:35:30 - train: epoch 0005, iter [00460, 01251], lr: 0.000161, loss: 0.4705
2022-09-21 01:35:51 - train: epoch 0005, iter [00470, 01251], lr: 0.000161, loss: 0.4816
2022-09-21 01:36:13 - train: epoch 0005, iter [00480, 01251], lr: 0.000162, loss: 0.5035
2022-09-21 01:36:34 - train: epoch 0005, iter [00490, 01251], lr: 0.000162, loss: 0.4882
2022-09-21 01:36:55 - train: epoch 0005, iter [00500, 01251], lr: 0.000162, loss: 0.5056
2022-09-21 01:37:16 - train: epoch 0005, iter [00510, 01251], lr: 0.000162, loss: 0.5129
2022-09-21 01:37:38 - train: epoch 0005, iter [00520, 01251], lr: 0.000162, loss: 0.5025
2022-09-21 01:37:59 - train: epoch 0005, iter [00530, 01251], lr: 0.000163, loss: 0.4789
2022-09-21 01:38:20 - train: epoch 0005, iter [00540, 01251], lr: 0.000163, loss: 0.4872
2022-09-21 01:38:42 - train: epoch 0005, iter [00550, 01251], lr: 0.000163, loss: 0.5059
2022-09-21 01:39:03 - train: epoch 0005, iter [00560, 01251], lr: 0.000163, loss: 0.4990
2022-09-21 01:39:25 - train: epoch 0005, iter [00570, 01251], lr: 0.000164, loss: 0.4964
2022-09-21 01:39:46 - train: epoch 0005, iter [00580, 01251], lr: 0.000164, loss: 0.4911
2022-09-21 01:40:08 - train: epoch 0005, iter [00590, 01251], lr: 0.000164, loss: 0.4910
2022-09-21 01:40:29 - train: epoch 0005, iter [00600, 01251], lr: 0.000164, loss: 0.4924
2022-09-21 01:40:51 - train: epoch 0005, iter [00610, 01251], lr: 0.000165, loss: 0.4983
2022-09-21 01:41:12 - train: epoch 0005, iter [00620, 01251], lr: 0.000165, loss: 0.4534
2022-09-21 01:41:33 - train: epoch 0005, iter [00630, 01251], lr: 0.000165, loss: 0.4808
2022-09-21 01:41:55 - train: epoch 0005, iter [00640, 01251], lr: 0.000165, loss: 0.4832
2022-09-21 01:42:16 - train: epoch 0005, iter [00650, 01251], lr: 0.000166, loss: 0.5074
2022-09-21 01:42:37 - train: epoch 0005, iter [00660, 01251], lr: 0.000166, loss: 0.4910
2022-09-21 01:42:58 - train: epoch 0005, iter [00670, 01251], lr: 0.000166, loss: 0.4727
2022-09-21 01:43:20 - train: epoch 0005, iter [00680, 01251], lr: 0.000166, loss: 0.4857
2022-09-21 01:43:41 - train: epoch 0005, iter [00690, 01251], lr: 0.000167, loss: 0.4745
2022-09-21 01:44:02 - train: epoch 0005, iter [00700, 01251], lr: 0.000167, loss: 0.4753
2022-09-21 01:44:24 - train: epoch 0005, iter [00710, 01251], lr: 0.000167, loss: 0.4889
2022-09-21 01:44:45 - train: epoch 0005, iter [00720, 01251], lr: 0.000167, loss: 0.4901
2022-09-21 01:45:07 - train: epoch 0005, iter [00730, 01251], lr: 0.000168, loss: 0.4781
2022-09-21 01:45:28 - train: epoch 0005, iter [00740, 01251], lr: 0.000168, loss: 0.4944
2022-09-21 01:45:50 - train: epoch 0005, iter [00750, 01251], lr: 0.000168, loss: 0.5014
2022-09-21 01:46:11 - train: epoch 0005, iter [00760, 01251], lr: 0.000168, loss: 0.4783
2022-09-21 01:46:33 - train: epoch 0005, iter [00770, 01251], lr: 0.000168, loss: 0.4912
2022-09-21 01:46:54 - train: epoch 0005, iter [00780, 01251], lr: 0.000169, loss: 0.4792
2022-09-21 01:47:15 - train: epoch 0005, iter [00790, 01251], lr: 0.000169, loss: 0.4772
2022-09-21 01:47:37 - train: epoch 0005, iter [00800, 01251], lr: 0.000169, loss: 0.4799
2022-09-21 01:47:58 - train: epoch 0005, iter [00810, 01251], lr: 0.000169, loss: 0.4764
2022-09-21 01:48:20 - train: epoch 0005, iter [00820, 01251], lr: 0.000170, loss: 0.4838
2022-09-21 01:48:41 - train: epoch 0005, iter [00830, 01251], lr: 0.000170, loss: 0.4691
2022-09-21 01:49:02 - train: epoch 0005, iter [00840, 01251], lr: 0.000170, loss: 0.4839
2022-09-21 01:49:23 - train: epoch 0005, iter [00850, 01251], lr: 0.000170, loss: 0.4934
2022-09-21 01:49:44 - train: epoch 0005, iter [00860, 01251], lr: 0.000171, loss: 0.4634
2022-09-21 01:50:05 - train: epoch 0005, iter [00870, 01251], lr: 0.000171, loss: 0.5150
2022-09-21 01:50:27 - train: epoch 0005, iter [00880, 01251], lr: 0.000171, loss: 0.4881
2022-09-21 01:50:48 - train: epoch 0005, iter [00890, 01251], lr: 0.000171, loss: 0.4871
2022-09-21 01:51:09 - train: epoch 0005, iter [00900, 01251], lr: 0.000172, loss: 0.4764
2022-09-21 01:51:30 - train: epoch 0005, iter [00910, 01251], lr: 0.000172, loss: 0.4761
2022-09-21 01:51:52 - train: epoch 0005, iter [00920, 01251], lr: 0.000172, loss: 0.4954
2022-09-21 01:52:13 - train: epoch 0005, iter [00930, 01251], lr: 0.000172, loss: 0.5078
2022-09-21 01:52:34 - train: epoch 0005, iter [00940, 01251], lr: 0.000173, loss: 0.4963
2022-09-21 01:52:56 - train: epoch 0005, iter [00950, 01251], lr: 0.000173, loss: 0.4807
2022-09-21 01:53:17 - train: epoch 0005, iter [00960, 01251], lr: 0.000173, loss: 0.4724
2022-09-21 01:53:39 - train: epoch 0005, iter [00970, 01251], lr: 0.000173, loss: 0.4607
2022-09-21 01:54:00 - train: epoch 0005, iter [00980, 01251], lr: 0.000174, loss: 0.4974
2022-09-21 01:54:21 - train: epoch 0005, iter [00990, 01251], lr: 0.000174, loss: 0.4995
2022-09-21 01:54:42 - train: epoch 0005, iter [01000, 01251], lr: 0.000174, loss: 0.4665
2022-09-21 01:55:04 - train: epoch 0005, iter [01010, 01251], lr: 0.000174, loss: 0.4886
2022-09-21 01:55:25 - train: epoch 0005, iter [01020, 01251], lr: 0.000174, loss: 0.4765
2022-09-21 01:55:47 - train: epoch 0005, iter [01030, 01251], lr: 0.000175, loss: 0.4700
2022-09-21 01:56:08 - train: epoch 0005, iter [01040, 01251], lr: 0.000175, loss: 0.4869
2022-09-21 01:56:29 - train: epoch 0005, iter [01050, 01251], lr: 0.000175, loss: 0.4870
2022-09-21 01:56:51 - train: epoch 0005, iter [01060, 01251], lr: 0.000175, loss: 0.4634
2022-09-21 01:57:12 - train: epoch 0005, iter [01070, 01251], lr: 0.000176, loss: 0.4753
2022-09-21 01:57:33 - train: epoch 0005, iter [01080, 01251], lr: 0.000176, loss: 0.4777
2022-09-21 01:57:54 - train: epoch 0005, iter [01090, 01251], lr: 0.000176, loss: 0.4767
2022-09-21 01:58:16 - train: epoch 0005, iter [01100, 01251], lr: 0.000176, loss: 0.4895
2022-09-21 01:58:37 - train: epoch 0005, iter [01110, 01251], lr: 0.000177, loss: 0.4667
2022-09-21 01:58:58 - train: epoch 0005, iter [01120, 01251], lr: 0.000177, loss: 0.4897
2022-09-21 01:59:20 - train: epoch 0005, iter [01130, 01251], lr: 0.000177, loss: 0.4620
2022-09-21 01:59:41 - train: epoch 0005, iter [01140, 01251], lr: 0.000177, loss: 0.4846
2022-09-21 02:00:02 - train: epoch 0005, iter [01150, 01251], lr: 0.000178, loss: 0.4747
2022-09-21 02:00:24 - train: epoch 0005, iter [01160, 01251], lr: 0.000178, loss: 0.4967
2022-09-21 02:00:45 - train: epoch 0005, iter [01170, 01251], lr: 0.000178, loss: 0.4873
2022-09-21 02:01:06 - train: epoch 0005, iter [01180, 01251], lr: 0.000178, loss: 0.4587
2022-09-21 02:01:28 - train: epoch 0005, iter [01190, 01251], lr: 0.000179, loss: 0.4858
2022-09-21 02:01:49 - train: epoch 0005, iter [01200, 01251], lr: 0.000179, loss: 0.4850
2022-09-21 02:02:10 - train: epoch 0005, iter [01210, 01251], lr: 0.000179, loss: 0.4991
2022-09-21 02:02:32 - train: epoch 0005, iter [01220, 01251], lr: 0.000179, loss: 0.4824
2022-09-21 02:02:53 - train: epoch 0005, iter [01230, 01251], lr: 0.000179, loss: 0.4547
2022-09-21 02:03:14 - train: epoch 0005, iter [01240, 01251], lr: 0.000180, loss: 0.4758
2022-09-21 02:03:35 - train: epoch 0005, iter [01250, 01251], lr: 0.000180, loss: 0.4750
2022-09-21 02:03:39 - train: epoch 005, train_loss: 0.4858
2022-09-21 02:03:44 - until epoch: 005, best_loss: 0.4858
2022-09-21 02:03:44 - epoch 006 lr: 0.000180
2022-09-21 02:04:21 - train: epoch 0006, iter [00010, 01251], lr: 0.000180, loss: 0.4970
2022-09-21 02:04:42 - train: epoch 0006, iter [00020, 01251], lr: 0.000180, loss: 0.4691
2022-09-21 02:05:03 - train: epoch 0006, iter [00030, 01251], lr: 0.000181, loss: 0.4794
2022-09-21 02:05:24 - train: epoch 0006, iter [00040, 01251], lr: 0.000181, loss: 0.4730
2022-09-21 02:05:45 - train: epoch 0006, iter [00050, 01251], lr: 0.000181, loss: 0.4845
2022-09-21 02:06:06 - train: epoch 0006, iter [00060, 01251], lr: 0.000181, loss: 0.4889
2022-09-21 02:06:27 - train: epoch 0006, iter [00070, 01251], lr: 0.000182, loss: 0.4768
2022-09-21 02:06:48 - train: epoch 0006, iter [00080, 01251], lr: 0.000182, loss: 0.4671
2022-09-21 02:07:09 - train: epoch 0006, iter [00090, 01251], lr: 0.000182, loss: 0.4631
2022-09-21 02:07:30 - train: epoch 0006, iter [00100, 01251], lr: 0.000182, loss: 0.4804
2022-09-21 02:07:51 - train: epoch 0006, iter [00110, 01251], lr: 0.000183, loss: 0.4755
2022-09-21 02:08:12 - train: epoch 0006, iter [00120, 01251], lr: 0.000183, loss: 0.4748
2022-09-21 02:08:34 - train: epoch 0006, iter [00130, 01251], lr: 0.000183, loss: 0.4663
2022-09-21 02:08:55 - train: epoch 0006, iter [00140, 01251], lr: 0.000183, loss: 0.4855
2022-09-21 02:09:16 - train: epoch 0006, iter [00150, 01251], lr: 0.000184, loss: 0.4735
2022-09-21 02:09:37 - train: epoch 0006, iter [00160, 01251], lr: 0.000184, loss: 0.4656
2022-09-21 02:09:58 - train: epoch 0006, iter [00170, 01251], lr: 0.000184, loss: 0.4855
2022-09-21 02:10:19 - train: epoch 0006, iter [00180, 01251], lr: 0.000184, loss: 0.4973
2022-09-21 02:10:40 - train: epoch 0006, iter [00190, 01251], lr: 0.000185, loss: 0.4736
2022-09-21 02:11:01 - train: epoch 0006, iter [00200, 01251], lr: 0.000185, loss: 0.4734
2022-09-21 02:11:22 - train: epoch 0006, iter [00210, 01251], lr: 0.000185, loss: 0.4843
2022-09-21 02:11:43 - train: epoch 0006, iter [00220, 01251], lr: 0.000185, loss: 0.4700
2022-09-21 02:12:04 - train: epoch 0006, iter [00230, 01251], lr: 0.000186, loss: 0.5013
2022-09-21 02:12:26 - train: epoch 0006, iter [00240, 01251], lr: 0.000186, loss: 0.4778
2022-09-21 02:12:47 - train: epoch 0006, iter [00250, 01251], lr: 0.000186, loss: 0.4714
2022-09-21 02:13:08 - train: epoch 0006, iter [00260, 01251], lr: 0.000186, loss: 0.4882
2022-09-21 02:13:29 - train: epoch 0006, iter [00270, 01251], lr: 0.000186, loss: 0.4707
2022-09-21 02:13:50 - train: epoch 0006, iter [00280, 01251], lr: 0.000187, loss: 0.4796
2022-09-21 02:14:11 - train: epoch 0006, iter [00290, 01251], lr: 0.000187, loss: 0.4763
2022-09-21 02:14:32 - train: epoch 0006, iter [00300, 01251], lr: 0.000187, loss: 0.4687
2022-09-21 02:14:53 - train: epoch 0006, iter [00310, 01251], lr: 0.000187, loss: 0.4803
2022-09-21 02:15:15 - train: epoch 0006, iter [00320, 01251], lr: 0.000188, loss: 0.4765
2022-09-21 02:15:36 - train: epoch 0006, iter [00330, 01251], lr: 0.000188, loss: 0.4727
2022-09-21 02:15:57 - train: epoch 0006, iter [00340, 01251], lr: 0.000188, loss: 0.4837
2022-09-21 02:16:18 - train: epoch 0006, iter [00350, 01251], lr: 0.000188, loss: 0.4816
2022-09-21 02:16:39 - train: epoch 0006, iter [00360, 01251], lr: 0.000189, loss: 0.4851
2022-09-21 02:17:01 - train: epoch 0006, iter [00370, 01251], lr: 0.000189, loss: 0.5037
2022-09-21 02:17:22 - train: epoch 0006, iter [00380, 01251], lr: 0.000189, loss: 0.4807
2022-09-21 02:17:44 - train: epoch 0006, iter [00390, 01251], lr: 0.000189, loss: 0.4716
2022-09-21 02:18:05 - train: epoch 0006, iter [00400, 01251], lr: 0.000190, loss: 0.4806
2022-09-21 02:18:27 - train: epoch 0006, iter [00410, 01251], lr: 0.000190, loss: 0.4800
2022-09-21 02:18:48 - train: epoch 0006, iter [00420, 01251], lr: 0.000190, loss: 0.4843
2022-09-21 02:19:09 - train: epoch 0006, iter [00430, 01251], lr: 0.000190, loss: 0.4881
2022-09-21 02:19:30 - train: epoch 0006, iter [00440, 01251], lr: 0.000191, loss: 0.4877
2022-09-21 02:19:51 - train: epoch 0006, iter [00450, 01251], lr: 0.000191, loss: 0.4983
2022-09-21 02:20:12 - train: epoch 0006, iter [00460, 01251], lr: 0.000191, loss: 0.4874
2022-09-21 02:20:33 - train: epoch 0006, iter [00470, 01251], lr: 0.000191, loss: 0.4797
2022-09-21 02:20:54 - train: epoch 0006, iter [00480, 01251], lr: 0.000192, loss: 0.4598
2022-09-21 02:21:16 - train: epoch 0006, iter [00490, 01251], lr: 0.000192, loss: 0.4800
2022-09-21 02:21:37 - train: epoch 0006, iter [00500, 01251], lr: 0.000192, loss: 0.4962
2022-09-21 02:21:58 - train: epoch 0006, iter [00510, 01251], lr: 0.000192, loss: 0.4846
2022-09-21 02:22:19 - train: epoch 0006, iter [00520, 01251], lr: 0.000192, loss: 0.4639
2022-09-21 02:22:40 - train: epoch 0006, iter [00530, 01251], lr: 0.000193, loss: 0.5031
2022-09-21 02:23:01 - train: epoch 0006, iter [00540, 01251], lr: 0.000193, loss: 0.4784
2022-09-21 02:23:22 - train: epoch 0006, iter [00550, 01251], lr: 0.000193, loss: 0.4626
2022-09-21 02:23:44 - train: epoch 0006, iter [00560, 01251], lr: 0.000193, loss: 0.4783
2022-09-21 02:24:05 - train: epoch 0006, iter [00570, 01251], lr: 0.000194, loss: 0.4464
2022-09-21 02:24:26 - train: epoch 0006, iter [00580, 01251], lr: 0.000194, loss: 0.4635
2022-09-21 02:24:47 - train: epoch 0006, iter [00590, 01251], lr: 0.000194, loss: 0.4780
2022-09-21 02:25:08 - train: epoch 0006, iter [00600, 01251], lr: 0.000194, loss: 0.5013
2022-09-21 02:25:30 - train: epoch 0006, iter [00610, 01251], lr: 0.000195, loss: 0.4893
2022-09-21 02:25:51 - train: epoch 0006, iter [00620, 01251], lr: 0.000195, loss: 0.4710
2022-09-21 02:26:12 - train: epoch 0006, iter [00630, 01251], lr: 0.000195, loss: 0.4299
2022-09-21 02:26:33 - train: epoch 0006, iter [00640, 01251], lr: 0.000195, loss: 0.4806
2022-09-21 02:26:55 - train: epoch 0006, iter [00650, 01251], lr: 0.000196, loss: 0.4899
2022-09-21 02:27:16 - train: epoch 0006, iter [00660, 01251], lr: 0.000196, loss: 0.4753
2022-09-21 02:27:37 - train: epoch 0006, iter [00670, 01251], lr: 0.000196, loss: 0.4745
2022-09-21 02:27:58 - train: epoch 0006, iter [00680, 01251], lr: 0.000196, loss: 0.4877
2022-09-21 02:28:19 - train: epoch 0006, iter [00690, 01251], lr: 0.000197, loss: 0.4626
2022-09-21 02:28:41 - train: epoch 0006, iter [00700, 01251], lr: 0.000197, loss: 0.4714
2022-09-21 02:29:02 - train: epoch 0006, iter [00710, 01251], lr: 0.000197, loss: 0.4943
2022-09-21 02:29:23 - train: epoch 0006, iter [00720, 01251], lr: 0.000197, loss: 0.4852
2022-09-21 02:29:44 - train: epoch 0006, iter [00730, 01251], lr: 0.000198, loss: 0.4848
2022-09-21 02:30:05 - train: epoch 0006, iter [00740, 01251], lr: 0.000198, loss: 0.4589
2022-09-21 02:30:26 - train: epoch 0006, iter [00750, 01251], lr: 0.000198, loss: 0.4623
2022-09-21 02:30:47 - train: epoch 0006, iter [00760, 01251], lr: 0.000198, loss: 0.4614
2022-09-21 02:31:08 - train: epoch 0006, iter [00770, 01251], lr: 0.000198, loss: 0.4659
2022-09-21 02:31:30 - train: epoch 0006, iter [00780, 01251], lr: 0.000199, loss: 0.4805
2022-09-21 02:31:51 - train: epoch 0006, iter [00790, 01251], lr: 0.000199, loss: 0.4968
2022-09-21 02:32:12 - train: epoch 0006, iter [00800, 01251], lr: 0.000199, loss: 0.4563
2022-09-21 02:32:33 - train: epoch 0006, iter [00810, 01251], lr: 0.000199, loss: 0.4894
2022-09-21 02:32:54 - train: epoch 0006, iter [00820, 01251], lr: 0.000200, loss: 0.4809
2022-09-21 02:33:15 - train: epoch 0006, iter [00830, 01251], lr: 0.000200, loss: 0.4593
2022-09-21 02:33:37 - train: epoch 0006, iter [00840, 01251], lr: 0.000200, loss: 0.4407
2022-09-21 02:33:58 - train: epoch 0006, iter [00850, 01251], lr: 0.000200, loss: 0.4882
2022-09-21 02:34:20 - train: epoch 0006, iter [00860, 01251], lr: 0.000201, loss: 0.4745
2022-09-21 02:34:41 - train: epoch 0006, iter [00870, 01251], lr: 0.000201, loss: 0.4528
2022-09-21 02:35:02 - train: epoch 0006, iter [00880, 01251], lr: 0.000201, loss: 0.4859
2022-09-21 02:35:23 - train: epoch 0006, iter [00890, 01251], lr: 0.000201, loss: 0.4770
2022-09-21 02:35:44 - train: epoch 0006, iter [00900, 01251], lr: 0.000202, loss: 0.4696
2022-09-21 02:36:05 - train: epoch 0006, iter [00910, 01251], lr: 0.000202, loss: 0.4685
2022-09-21 02:36:26 - train: epoch 0006, iter [00920, 01251], lr: 0.000202, loss: 0.4760
2022-09-21 02:36:47 - train: epoch 0006, iter [00930, 01251], lr: 0.000202, loss: 0.4807
2022-09-21 02:37:09 - train: epoch 0006, iter [00940, 01251], lr: 0.000203, loss: 0.4618
2022-09-21 02:37:30 - train: epoch 0006, iter [00950, 01251], lr: 0.000203, loss: 0.4622
2022-09-21 02:37:51 - train: epoch 0006, iter [00960, 01251], lr: 0.000203, loss: 0.4881
2022-09-21 02:38:12 - train: epoch 0006, iter [00970, 01251], lr: 0.000203, loss: 0.4574
2022-09-21 02:38:34 - train: epoch 0006, iter [00980, 01251], lr: 0.000204, loss: 0.4667
2022-09-21 02:38:55 - train: epoch 0006, iter [00990, 01251], lr: 0.000204, loss: 0.4878
2022-09-21 02:39:16 - train: epoch 0006, iter [01000, 01251], lr: 0.000204, loss: 0.4583
2022-09-21 02:39:37 - train: epoch 0006, iter [01010, 01251], lr: 0.000204, loss: 0.4925
2022-09-21 02:39:58 - train: epoch 0006, iter [01020, 01251], lr: 0.000204, loss: 0.4424
2022-09-21 02:40:19 - train: epoch 0006, iter [01030, 01251], lr: 0.000205, loss: 0.4699
2022-09-21 02:40:40 - train: epoch 0006, iter [01040, 01251], lr: 0.000205, loss: 0.4678
2022-09-21 02:41:02 - train: epoch 0006, iter [01050, 01251], lr: 0.000205, loss: 0.4748
2022-09-21 02:41:23 - train: epoch 0006, iter [01060, 01251], lr: 0.000205, loss: 0.4825
2022-09-21 02:41:44 - train: epoch 0006, iter [01070, 01251], lr: 0.000206, loss: 0.4761
2022-09-21 02:42:05 - train: epoch 0006, iter [01080, 01251], lr: 0.000206, loss: 0.4855
2022-09-21 02:42:26 - train: epoch 0006, iter [01090, 01251], lr: 0.000206, loss: 0.4711
2022-09-21 02:42:47 - train: epoch 0006, iter [01100, 01251], lr: 0.000206, loss: 0.4725
2022-09-21 02:43:09 - train: epoch 0006, iter [01110, 01251], lr: 0.000207, loss: 0.4857
2022-09-21 02:43:30 - train: epoch 0006, iter [01120, 01251], lr: 0.000207, loss: 0.4503
2022-09-21 02:43:51 - train: epoch 0006, iter [01130, 01251], lr: 0.000207, loss: 0.4770
2022-09-21 02:44:12 - train: epoch 0006, iter [01140, 01251], lr: 0.000207, loss: 0.4840
2022-09-21 02:44:33 - train: epoch 0006, iter [01150, 01251], lr: 0.000208, loss: 0.4816
2022-09-21 02:44:54 - train: epoch 0006, iter [01160, 01251], lr: 0.000208, loss: 0.4749
2022-09-21 02:45:16 - train: epoch 0006, iter [01170, 01251], lr: 0.000208, loss: 0.4778
2022-09-21 02:45:37 - train: epoch 0006, iter [01180, 01251], lr: 0.000208, loss: 0.4573
2022-09-21 02:45:58 - train: epoch 0006, iter [01190, 01251], lr: 0.000209, loss: 0.4927
2022-09-21 02:46:19 - train: epoch 0006, iter [01200, 01251], lr: 0.000209, loss: 0.4643
2022-09-21 02:46:40 - train: epoch 0006, iter [01210, 01251], lr: 0.000209, loss: 0.4516
2022-09-21 02:47:02 - train: epoch 0006, iter [01220, 01251], lr: 0.000209, loss: 0.4889
2022-09-21 02:47:23 - train: epoch 0006, iter [01230, 01251], lr: 0.000209, loss: 0.4752
2022-09-21 02:47:44 - train: epoch 0006, iter [01240, 01251], lr: 0.000210, loss: 0.4756
2022-09-21 02:48:04 - train: epoch 0006, iter [01250, 01251], lr: 0.000210, loss: 0.4844
2022-09-21 02:48:09 - train: epoch 006, train_loss: 0.4760
2022-09-21 02:48:14 - until epoch: 006, best_loss: 0.4760
2022-09-21 02:48:14 - epoch 007 lr: 0.000210
2022-09-21 02:48:52 - train: epoch 0007, iter [00010, 01251], lr: 0.000210, loss: 0.4678
2022-09-21 02:49:13 - train: epoch 0007, iter [00020, 01251], lr: 0.000210, loss: 0.4657
2022-09-21 02:49:34 - train: epoch 0007, iter [00030, 01251], lr: 0.000211, loss: 0.4668
2022-09-21 02:49:56 - train: epoch 0007, iter [00040, 01251], lr: 0.000211, loss: 0.4538
2022-09-21 02:50:17 - train: epoch 0007, iter [00050, 01251], lr: 0.000211, loss: 0.4617
2022-09-21 02:50:38 - train: epoch 0007, iter [00060, 01251], lr: 0.000211, loss: 0.4765
2022-09-21 02:50:59 - train: epoch 0007, iter [00070, 01251], lr: 0.000212, loss: 0.4628
2022-09-21 02:51:20 - train: epoch 0007, iter [00080, 01251], lr: 0.000212, loss: 0.4720
2022-09-21 02:51:41 - train: epoch 0007, iter [00090, 01251], lr: 0.000212, loss: 0.4649
2022-09-21 02:52:02 - train: epoch 0007, iter [00100, 01251], lr: 0.000212, loss: 0.5008
2022-09-21 02:52:23 - train: epoch 0007, iter [00110, 01251], lr: 0.000213, loss: 0.4731
2022-09-21 02:52:44 - train: epoch 0007, iter [00120, 01251], lr: 0.000213, loss: 0.4698
2022-09-21 02:53:05 - train: epoch 0007, iter [00130, 01251], lr: 0.000213, loss: 0.4537
2022-09-21 02:53:26 - train: epoch 0007, iter [00140, 01251], lr: 0.000213, loss: 0.4632
2022-09-21 02:53:47 - train: epoch 0007, iter [00150, 01251], lr: 0.000214, loss: 0.4856
2022-09-21 02:54:08 - train: epoch 0007, iter [00160, 01251], lr: 0.000214, loss: 0.4645
2022-09-21 02:54:29 - train: epoch 0007, iter [00170, 01251], lr: 0.000214, loss: 0.4752
2022-09-21 02:54:50 - train: epoch 0007, iter [00180, 01251], lr: 0.000214, loss: 0.4789
2022-09-21 02:55:11 - train: epoch 0007, iter [00190, 01251], lr: 0.000215, loss: 0.4610
2022-09-21 02:55:32 - train: epoch 0007, iter [00200, 01251], lr: 0.000215, loss: 0.4548
2022-09-21 02:55:53 - train: epoch 0007, iter [00210, 01251], lr: 0.000215, loss: 0.4609
2022-09-21 02:56:15 - train: epoch 0007, iter [00220, 01251], lr: 0.000215, loss: 0.4942
2022-09-21 02:56:36 - train: epoch 0007, iter [00230, 01251], lr: 0.000216, loss: 0.4583
2022-09-21 02:56:56 - train: epoch 0007, iter [00240, 01251], lr: 0.000216, loss: 0.4596
2022-09-21 02:57:18 - train: epoch 0007, iter [00250, 01251], lr: 0.000216, loss: 0.4763
2022-09-21 02:57:39 - train: epoch 0007, iter [00260, 01251], lr: 0.000216, loss: 0.4790
2022-09-21 02:58:00 - train: epoch 0007, iter [00270, 01251], lr: 0.000216, loss: 0.4725
2022-09-21 02:58:21 - train: epoch 0007, iter [00280, 01251], lr: 0.000217, loss: 0.4640
2022-09-21 02:58:42 - train: epoch 0007, iter [00290, 01251], lr: 0.000217, loss: 0.4483
2022-09-21 02:59:03 - train: epoch 0007, iter [00300, 01251], lr: 0.000217, loss: 0.4646
2022-09-21 02:59:25 - train: epoch 0007, iter [00310, 01251], lr: 0.000217, loss: 0.4838
2022-09-21 02:59:46 - train: epoch 0007, iter [00320, 01251], lr: 0.000218, loss: 0.4625
2022-09-21 03:00:07 - train: epoch 0007, iter [00330, 01251], lr: 0.000218, loss: 0.4851
2022-09-21 03:00:28 - train: epoch 0007, iter [00340, 01251], lr: 0.000218, loss: 0.4542
2022-09-21 03:00:49 - train: epoch 0007, iter [00350, 01251], lr: 0.000218, loss: 0.4647
2022-09-21 03:01:10 - train: epoch 0007, iter [00360, 01251], lr: 0.000219, loss: 0.4757
2022-09-21 03:01:32 - train: epoch 0007, iter [00370, 01251], lr: 0.000219, loss: 0.4599
2022-09-21 03:01:53 - train: epoch 0007, iter [00380, 01251], lr: 0.000219, loss: 0.4711
2022-09-21 03:02:14 - train: epoch 0007, iter [00390, 01251], lr: 0.000219, loss: 0.4573
2022-09-21 03:02:35 - train: epoch 0007, iter [00400, 01251], lr: 0.000220, loss: 0.4776
2022-09-21 03:02:57 - train: epoch 0007, iter [00410, 01251], lr: 0.000220, loss: 0.4568
2022-09-21 03:03:18 - train: epoch 0007, iter [00420, 01251], lr: 0.000220, loss: 0.4665
2022-09-21 03:03:39 - train: epoch 0007, iter [00430, 01251], lr: 0.000220, loss: 0.4532
2022-09-21 03:04:00 - train: epoch 0007, iter [00440, 01251], lr: 0.000221, loss: 0.4574
2022-09-21 03:04:22 - train: epoch 0007, iter [00450, 01251], lr: 0.000221, loss: 0.4481
2022-09-21 03:04:43 - train: epoch 0007, iter [00460, 01251], lr: 0.000221, loss: 0.4531
2022-09-21 03:05:05 - train: epoch 0007, iter [00470, 01251], lr: 0.000221, loss: 0.4779
2022-09-21 03:05:26 - train: epoch 0007, iter [00480, 01251], lr: 0.000222, loss: 0.4696
2022-09-21 03:05:47 - train: epoch 0007, iter [00490, 01251], lr: 0.000222, loss: 0.4698
2022-09-21 03:06:08 - train: epoch 0007, iter [00500, 01251], lr: 0.000222, loss: 0.4650
2022-09-21 03:06:30 - train: epoch 0007, iter [00510, 01251], lr: 0.000222, loss: 0.4708
2022-09-21 03:06:51 - train: epoch 0007, iter [00520, 01251], lr: 0.000222, loss: 0.4726
2022-09-21 03:07:12 - train: epoch 0007, iter [00530, 01251], lr: 0.000223, loss: 0.4710
2022-09-21 03:07:33 - train: epoch 0007, iter [00540, 01251], lr: 0.000223, loss: 0.4563
2022-09-21 03:07:54 - train: epoch 0007, iter [00550, 01251], lr: 0.000223, loss: 0.4764
2022-09-21 03:08:15 - train: epoch 0007, iter [00560, 01251], lr: 0.000223, loss: 0.4621
2022-09-21 03:08:36 - train: epoch 0007, iter [00570, 01251], lr: 0.000224, loss: 0.4855
2022-09-21 03:08:58 - train: epoch 0007, iter [00580, 01251], lr: 0.000224, loss: 0.4799
2022-09-21 03:09:19 - train: epoch 0007, iter [00590, 01251], lr: 0.000224, loss: 0.4779
2022-09-21 03:09:40 - train: epoch 0007, iter [00600, 01251], lr: 0.000224, loss: 0.4940
2022-09-21 03:10:01 - train: epoch 0007, iter [00610, 01251], lr: 0.000225, loss: 0.4413
2022-09-21 03:10:23 - train: epoch 0007, iter [00620, 01251], lr: 0.000225, loss: 0.4616
2022-09-21 03:10:44 - train: epoch 0007, iter [00630, 01251], lr: 0.000225, loss: 0.4615
2022-09-21 03:11:05 - train: epoch 0007, iter [00640, 01251], lr: 0.000225, loss: 0.4613
2022-09-21 03:11:26 - train: epoch 0007, iter [00650, 01251], lr: 0.000226, loss: 0.4835
2022-09-21 03:11:48 - train: epoch 0007, iter [00660, 01251], lr: 0.000226, loss: 0.4632
2022-09-21 03:12:09 - train: epoch 0007, iter [00670, 01251], lr: 0.000226, loss: 0.4567
2022-09-21 03:12:30 - train: epoch 0007, iter [00680, 01251], lr: 0.000226, loss: 0.4716
2022-09-21 03:12:52 - train: epoch 0007, iter [00690, 01251], lr: 0.000227, loss: 0.4646
2022-09-21 03:13:13 - train: epoch 0007, iter [00700, 01251], lr: 0.000227, loss: 0.4906
2022-09-21 03:13:34 - train: epoch 0007, iter [00710, 01251], lr: 0.000227, loss: 0.4632
2022-09-21 03:13:56 - train: epoch 0007, iter [00720, 01251], lr: 0.000227, loss: 0.4605
2022-09-21 03:14:17 - train: epoch 0007, iter [00730, 01251], lr: 0.000228, loss: 0.4735
2022-09-21 03:14:39 - train: epoch 0007, iter [00740, 01251], lr: 0.000228, loss: 0.4559
2022-09-21 03:15:00 - train: epoch 0007, iter [00750, 01251], lr: 0.000228, loss: 0.4638
2022-09-21 03:15:21 - train: epoch 0007, iter [00760, 01251], lr: 0.000228, loss: 0.4614
2022-09-21 03:15:42 - train: epoch 0007, iter [00770, 01251], lr: 0.000228, loss: 0.4539
2022-09-21 03:16:04 - train: epoch 0007, iter [00780, 01251], lr: 0.000229, loss: 0.4550
2022-09-21 03:16:25 - train: epoch 0007, iter [00790, 01251], lr: 0.000229, loss: 0.4572
2022-09-21 03:16:46 - train: epoch 0007, iter [00800, 01251], lr: 0.000229, loss: 0.4532
2022-09-21 03:17:08 - train: epoch 0007, iter [00810, 01251], lr: 0.000229, loss: 0.4634
2022-09-21 03:17:29 - train: epoch 0007, iter [00820, 01251], lr: 0.000230, loss: 0.4665
2022-09-21 03:17:51 - train: epoch 0007, iter [00830, 01251], lr: 0.000230, loss: 0.4567
2022-09-21 03:18:12 - train: epoch 0007, iter [00840, 01251], lr: 0.000230, loss: 0.4689
2022-09-21 03:18:33 - train: epoch 0007, iter [00850, 01251], lr: 0.000230, loss: 0.4734
2022-09-21 03:18:54 - train: epoch 0007, iter [00860, 01251], lr: 0.000231, loss: 0.4719
2022-09-21 03:19:16 - train: epoch 0007, iter [00870, 01251], lr: 0.000231, loss: 0.4574
2022-09-21 03:19:37 - train: epoch 0007, iter [00880, 01251], lr: 0.000231, loss: 0.4595
2022-09-21 03:19:58 - train: epoch 0007, iter [00890, 01251], lr: 0.000231, loss: 0.4829
2022-09-21 03:20:19 - train: epoch 0007, iter [00900, 01251], lr: 0.000232, loss: 0.4685
2022-09-21 03:20:41 - train: epoch 0007, iter [00910, 01251], lr: 0.000232, loss: 0.4613
2022-09-21 03:21:02 - train: epoch 0007, iter [00920, 01251], lr: 0.000232, loss: 0.4750
2022-09-21 03:21:24 - train: epoch 0007, iter [00930, 01251], lr: 0.000232, loss: 0.4630
2022-09-21 03:21:45 - train: epoch 0007, iter [00940, 01251], lr: 0.000233, loss: 0.4620
2022-09-21 03:22:06 - train: epoch 0007, iter [00950, 01251], lr: 0.000233, loss: 0.4682
2022-09-21 03:22:28 - train: epoch 0007, iter [00960, 01251], lr: 0.000233, loss: 0.4612
2022-09-21 03:22:49 - train: epoch 0007, iter [00970, 01251], lr: 0.000233, loss: 0.4727
2022-09-21 03:23:11 - train: epoch 0007, iter [00980, 01251], lr: 0.000234, loss: 0.4556
2022-09-21 03:23:32 - train: epoch 0007, iter [00990, 01251], lr: 0.000234, loss: 0.4721
2022-09-21 03:23:54 - train: epoch 0007, iter [01000, 01251], lr: 0.000234, loss: 0.4632
2022-09-21 03:24:15 - train: epoch 0007, iter [01010, 01251], lr: 0.000234, loss: 0.4600
2022-09-21 03:24:36 - train: epoch 0007, iter [01020, 01251], lr: 0.000234, loss: 0.4810
2022-09-21 03:24:58 - train: epoch 0007, iter [01030, 01251], lr: 0.000235, loss: 0.4649
2022-09-21 03:25:19 - train: epoch 0007, iter [01040, 01251], lr: 0.000235, loss: 0.4763
2022-09-21 03:25:41 - train: epoch 0007, iter [01050, 01251], lr: 0.000235, loss: 0.4712
2022-09-21 03:26:02 - train: epoch 0007, iter [01060, 01251], lr: 0.000235, loss: 0.4721
2022-09-21 03:26:24 - train: epoch 0007, iter [01070, 01251], lr: 0.000236, loss: 0.4676
2022-09-21 03:26:46 - train: epoch 0007, iter [01080, 01251], lr: 0.000236, loss: 0.4590
2022-09-21 03:27:07 - train: epoch 0007, iter [01090, 01251], lr: 0.000236, loss: 0.4458
2022-09-21 03:27:28 - train: epoch 0007, iter [01100, 01251], lr: 0.000236, loss: 0.4870
2022-09-21 03:27:50 - train: epoch 0007, iter [01110, 01251], lr: 0.000237, loss: 0.4680
2022-09-21 03:28:11 - train: epoch 0007, iter [01120, 01251], lr: 0.000237, loss: 0.4672
2022-09-21 03:28:33 - train: epoch 0007, iter [01130, 01251], lr: 0.000237, loss: 0.4647
2022-09-21 03:28:54 - train: epoch 0007, iter [01140, 01251], lr: 0.000237, loss: 0.4955
2022-09-21 03:29:15 - train: epoch 0007, iter [01150, 01251], lr: 0.000238, loss: 0.4531
2022-09-21 03:29:37 - train: epoch 0007, iter [01160, 01251], lr: 0.000238, loss: 0.4667
2022-09-21 03:29:58 - train: epoch 0007, iter [01170, 01251], lr: 0.000238, loss: 0.4607
2022-09-21 03:30:19 - train: epoch 0007, iter [01180, 01251], lr: 0.000238, loss: 0.4777
2022-09-21 03:30:41 - train: epoch 0007, iter [01190, 01251], lr: 0.000239, loss: 0.4568
2022-09-21 03:31:02 - train: epoch 0007, iter [01200, 01251], lr: 0.000239, loss: 0.4557
2022-09-21 03:31:24 - train: epoch 0007, iter [01210, 01251], lr: 0.000239, loss: 0.4624
2022-09-21 03:31:45 - train: epoch 0007, iter [01220, 01251], lr: 0.000239, loss: 0.4501
2022-09-21 03:32:06 - train: epoch 0007, iter [01230, 01251], lr: 0.000239, loss: 0.4688
2022-09-21 03:32:28 - train: epoch 0007, iter [01240, 01251], lr: 0.000240, loss: 0.4700
2022-09-21 03:32:48 - train: epoch 0007, iter [01250, 01251], lr: 0.000240, loss: 0.4706
2022-09-21 03:32:53 - train: epoch 007, train_loss: 0.4680
2022-09-21 03:32:58 - until epoch: 007, best_loss: 0.4680
2022-09-21 03:32:58 - epoch 008 lr: 0.000240
2022-09-21 03:33:35 - train: epoch 0008, iter [00010, 01251], lr: 0.000240, loss: 0.4691
2022-09-21 03:33:56 - train: epoch 0008, iter [00020, 01251], lr: 0.000240, loss: 0.4580
2022-09-21 03:34:16 - train: epoch 0008, iter [00030, 01251], lr: 0.000241, loss: 0.4773
2022-09-21 03:34:37 - train: epoch 0008, iter [00040, 01251], lr: 0.000241, loss: 0.4568
2022-09-21 03:34:59 - train: epoch 0008, iter [00050, 01251], lr: 0.000241, loss: 0.4643
2022-09-21 03:35:20 - train: epoch 0008, iter [00060, 01251], lr: 0.000241, loss: 0.4697
2022-09-21 03:35:41 - train: epoch 0008, iter [00070, 01251], lr: 0.000242, loss: 0.4555
2022-09-21 03:36:02 - train: epoch 0008, iter [00080, 01251], lr: 0.000242, loss: 0.4520
2022-09-21 03:36:24 - train: epoch 0008, iter [00090, 01251], lr: 0.000242, loss: 0.4629
2022-09-21 03:36:45 - train: epoch 0008, iter [00100, 01251], lr: 0.000242, loss: 0.4642
2022-09-21 03:37:06 - train: epoch 0008, iter [00110, 01251], lr: 0.000243, loss: 0.4513
2022-09-21 03:37:27 - train: epoch 0008, iter [00120, 01251], lr: 0.000243, loss: 0.4793
2022-09-21 03:37:48 - train: epoch 0008, iter [00130, 01251], lr: 0.000243, loss: 0.4682
2022-09-21 03:38:09 - train: epoch 0008, iter [00140, 01251], lr: 0.000243, loss: 0.4547
2022-09-21 03:38:30 - train: epoch 0008, iter [00150, 01251], lr: 0.000244, loss: 0.4521
2022-09-21 03:38:50 - train: epoch 0008, iter [00160, 01251], lr: 0.000244, loss: 0.4831
2022-09-21 03:39:11 - train: epoch 0008, iter [00170, 01251], lr: 0.000244, loss: 0.4486
2022-09-21 03:39:32 - train: epoch 0008, iter [00180, 01251], lr: 0.000244, loss: 0.4480
2022-09-21 03:39:53 - train: epoch 0008, iter [00190, 01251], lr: 0.000245, loss: 0.4548
2022-09-21 03:40:14 - train: epoch 0008, iter [00200, 01251], lr: 0.000245, loss: 0.4697
2022-09-21 03:40:35 - train: epoch 0008, iter [00210, 01251], lr: 0.000245, loss: 0.4421
2022-09-21 03:40:56 - train: epoch 0008, iter [00220, 01251], lr: 0.000245, loss: 0.4721
2022-09-21 03:41:16 - train: epoch 0008, iter [00230, 01251], lr: 0.000246, loss: 0.4487
2022-09-21 03:41:37 - train: epoch 0008, iter [00240, 01251], lr: 0.000246, loss: 0.4450
2022-09-21 03:41:58 - train: epoch 0008, iter [00250, 01251], lr: 0.000246, loss: 0.4444
2022-09-21 03:42:19 - train: epoch 0008, iter [00260, 01251], lr: 0.000246, loss: 0.4793
2022-09-21 03:42:40 - train: epoch 0008, iter [00270, 01251], lr: 0.000246, loss: 0.4682
2022-09-21 03:43:01 - train: epoch 0008, iter [00280, 01251], lr: 0.000247, loss: 0.4496
2022-09-21 03:43:22 - train: epoch 0008, iter [00290, 01251], lr: 0.000247, loss: 0.4577
2022-09-21 03:43:43 - train: epoch 0008, iter [00300, 01251], lr: 0.000247, loss: 0.4615
2022-09-21 03:44:04 - train: epoch 0008, iter [00310, 01251], lr: 0.000247, loss: 0.4728
2022-09-21 03:44:25 - train: epoch 0008, iter [00320, 01251], lr: 0.000248, loss: 0.4629
2022-09-21 03:44:46 - train: epoch 0008, iter [00330, 01251], lr: 0.000248, loss: 0.4492
2022-09-21 03:45:07 - train: epoch 0008, iter [00340, 01251], lr: 0.000248, loss: 0.4711
2022-09-21 03:45:28 - train: epoch 0008, iter [00350, 01251], lr: 0.000248, loss: 0.4559
2022-09-21 03:45:49 - train: epoch 0008, iter [00360, 01251], lr: 0.000249, loss: 0.4427
2022-09-21 03:46:09 - train: epoch 0008, iter [00370, 01251], lr: 0.000249, loss: 0.4541
2022-09-21 03:46:31 - train: epoch 0008, iter [00380, 01251], lr: 0.000249, loss: 0.4772
2022-09-21 03:46:52 - train: epoch 0008, iter [00390, 01251], lr: 0.000249, loss: 0.4649
2022-09-21 03:47:13 - train: epoch 0008, iter [00400, 01251], lr: 0.000250, loss: 0.4469
2022-09-21 03:47:34 - train: epoch 0008, iter [00410, 01251], lr: 0.000250, loss: 0.4591
2022-09-21 03:47:54 - train: epoch 0008, iter [00420, 01251], lr: 0.000250, loss: 0.4573
2022-09-21 03:48:15 - train: epoch 0008, iter [00430, 01251], lr: 0.000250, loss: 0.4843
2022-09-21 03:48:36 - train: epoch 0008, iter [00440, 01251], lr: 0.000251, loss: 0.4452
2022-09-21 03:48:57 - train: epoch 0008, iter [00450, 01251], lr: 0.000251, loss: 0.4694
2022-09-21 03:49:18 - train: epoch 0008, iter [00460, 01251], lr: 0.000251, loss: 0.4464
2022-09-21 03:49:39 - train: epoch 0008, iter [00470, 01251], lr: 0.000251, loss: 0.4523
2022-09-21 03:50:01 - train: epoch 0008, iter [00480, 01251], lr: 0.000252, loss: 0.4783
2022-09-21 03:50:22 - train: epoch 0008, iter [00490, 01251], lr: 0.000252, loss: 0.4717
2022-09-21 03:50:43 - train: epoch 0008, iter [00500, 01251], lr: 0.000252, loss: 0.4628
2022-09-21 03:51:04 - train: epoch 0008, iter [00510, 01251], lr: 0.000252, loss: 0.4739
2022-09-21 03:51:26 - train: epoch 0008, iter [00520, 01251], lr: 0.000252, loss: 0.4473
2022-09-21 03:51:47 - train: epoch 0008, iter [00530, 01251], lr: 0.000253, loss: 0.4530
2022-09-21 03:52:08 - train: epoch 0008, iter [00540, 01251], lr: 0.000253, loss: 0.4683
2022-09-21 03:52:29 - train: epoch 0008, iter [00550, 01251], lr: 0.000253, loss: 0.4597
2022-09-21 03:52:50 - train: epoch 0008, iter [00560, 01251], lr: 0.000253, loss: 0.4622
2022-09-21 03:53:11 - train: epoch 0008, iter [00570, 01251], lr: 0.000254, loss: 0.4477
2022-09-21 03:53:32 - train: epoch 0008, iter [00580, 01251], lr: 0.000254, loss: 0.4793
2022-09-21 03:53:53 - train: epoch 0008, iter [00590, 01251], lr: 0.000254, loss: 0.4570
2022-09-21 03:54:14 - train: epoch 0008, iter [00600, 01251], lr: 0.000254, loss: 0.4501
2022-09-21 03:54:35 - train: epoch 0008, iter [00610, 01251], lr: 0.000255, loss: 0.4619
2022-09-21 03:54:56 - train: epoch 0008, iter [00620, 01251], lr: 0.000255, loss: 0.4621
2022-09-21 03:55:18 - train: epoch 0008, iter [00630, 01251], lr: 0.000255, loss: 0.4466
2022-09-21 03:55:39 - train: epoch 0008, iter [00640, 01251], lr: 0.000255, loss: 0.4612
2022-09-21 03:56:00 - train: epoch 0008, iter [00650, 01251], lr: 0.000256, loss: 0.4567
2022-09-21 03:56:21 - train: epoch 0008, iter [00660, 01251], lr: 0.000256, loss: 0.4559
2022-09-21 03:56:42 - train: epoch 0008, iter [00670, 01251], lr: 0.000256, loss: 0.4693
2022-09-21 03:57:03 - train: epoch 0008, iter [00680, 01251], lr: 0.000256, loss: 0.4630
2022-09-21 03:57:24 - train: epoch 0008, iter [00690, 01251], lr: 0.000257, loss: 0.4767
2022-09-21 03:57:45 - train: epoch 0008, iter [00700, 01251], lr: 0.000257, loss: 0.4617
2022-09-21 03:58:06 - train: epoch 0008, iter [00710, 01251], lr: 0.000257, loss: 0.4539
2022-09-21 03:58:27 - train: epoch 0008, iter [00720, 01251], lr: 0.000257, loss: 0.4682
2022-09-21 03:58:48 - train: epoch 0008, iter [00730, 01251], lr: 0.000258, loss: 0.4637
2022-09-21 03:59:09 - train: epoch 0008, iter [00740, 01251], lr: 0.000258, loss: 0.4621
2022-09-21 03:59:31 - train: epoch 0008, iter [00750, 01251], lr: 0.000258, loss: 0.4483
2022-09-21 03:59:52 - train: epoch 0008, iter [00760, 01251], lr: 0.000258, loss: 0.4605
2022-09-21 04:00:13 - train: epoch 0008, iter [00770, 01251], lr: 0.000258, loss: 0.4667
2022-09-21 04:00:34 - train: epoch 0008, iter [00780, 01251], lr: 0.000259, loss: 0.4626
2022-09-21 04:00:55 - train: epoch 0008, iter [00790, 01251], lr: 0.000259, loss: 0.4809
2022-09-21 04:01:16 - train: epoch 0008, iter [00800, 01251], lr: 0.000259, loss: 0.4670
2022-09-21 04:01:37 - train: epoch 0008, iter [00810, 01251], lr: 0.000259, loss: 0.4739
2022-09-21 04:01:59 - train: epoch 0008, iter [00820, 01251], lr: 0.000260, loss: 0.4669
2022-09-21 04:02:19 - train: epoch 0008, iter [00830, 01251], lr: 0.000260, loss: 0.4606
2022-09-21 04:02:41 - train: epoch 0008, iter [00840, 01251], lr: 0.000260, loss: 0.4661
2022-09-21 04:03:02 - train: epoch 0008, iter [00850, 01251], lr: 0.000260, loss: 0.4544
2022-09-21 04:03:23 - train: epoch 0008, iter [00860, 01251], lr: 0.000261, loss: 0.4560
2022-09-21 04:03:44 - train: epoch 0008, iter [00870, 01251], lr: 0.000261, loss: 0.4587
2022-09-21 04:04:06 - train: epoch 0008, iter [00880, 01251], lr: 0.000261, loss: 0.4654
2022-09-21 04:04:27 - train: epoch 0008, iter [00890, 01251], lr: 0.000261, loss: 0.4598
2022-09-21 04:04:48 - train: epoch 0008, iter [00900, 01251], lr: 0.000262, loss: 0.4482
2022-09-21 04:05:09 - train: epoch 0008, iter [00910, 01251], lr: 0.000262, loss: 0.4585
2022-09-21 04:05:30 - train: epoch 0008, iter [00920, 01251], lr: 0.000262, loss: 0.4681
2022-09-21 04:05:52 - train: epoch 0008, iter [00930, 01251], lr: 0.000262, loss: 0.4643
2022-09-21 04:06:13 - train: epoch 0008, iter [00940, 01251], lr: 0.000263, loss: 0.4559
2022-09-21 04:06:34 - train: epoch 0008, iter [00950, 01251], lr: 0.000263, loss: 0.4600
2022-09-21 04:06:55 - train: epoch 0008, iter [00960, 01251], lr: 0.000263, loss: 0.4460
2022-09-21 04:07:17 - train: epoch 0008, iter [00970, 01251], lr: 0.000263, loss: 0.4758
2022-09-21 04:07:38 - train: epoch 0008, iter [00980, 01251], lr: 0.000264, loss: 0.4588
2022-09-21 04:07:59 - train: epoch 0008, iter [00990, 01251], lr: 0.000264, loss: 0.4462
2022-09-21 04:08:20 - train: epoch 0008, iter [01000, 01251], lr: 0.000264, loss: 0.4520
2022-09-21 04:08:41 - train: epoch 0008, iter [01010, 01251], lr: 0.000264, loss: 0.4603
2022-09-21 04:09:02 - train: epoch 0008, iter [01020, 01251], lr: 0.000264, loss: 0.4515
2022-09-21 04:09:23 - train: epoch 0008, iter [01030, 01251], lr: 0.000265, loss: 0.4767
2022-09-21 04:09:44 - train: epoch 0008, iter [01040, 01251], lr: 0.000265, loss: 0.4876
2022-09-21 04:10:05 - train: epoch 0008, iter [01050, 01251], lr: 0.000265, loss: 0.4683
2022-09-21 04:10:26 - train: epoch 0008, iter [01060, 01251], lr: 0.000265, loss: 0.4415
2022-09-21 04:10:47 - train: epoch 0008, iter [01070, 01251], lr: 0.000266, loss: 0.4628
2022-09-21 04:11:08 - train: epoch 0008, iter [01080, 01251], lr: 0.000266, loss: 0.4722
2022-09-21 04:11:29 - train: epoch 0008, iter [01090, 01251], lr: 0.000266, loss: 0.4565
2022-09-21 04:11:51 - train: epoch 0008, iter [01100, 01251], lr: 0.000266, loss: 0.4704
2022-09-21 04:12:12 - train: epoch 0008, iter [01110, 01251], lr: 0.000267, loss: 0.4641
2022-09-21 04:12:33 - train: epoch 0008, iter [01120, 01251], lr: 0.000267, loss: 0.4661
2022-09-21 04:12:54 - train: epoch 0008, iter [01130, 01251], lr: 0.000267, loss: 0.4580
2022-09-21 04:13:15 - train: epoch 0008, iter [01140, 01251], lr: 0.000267, loss: 0.4660
2022-09-21 04:13:36 - train: epoch 0008, iter [01150, 01251], lr: 0.000268, loss: 0.4665
2022-09-21 04:13:57 - train: epoch 0008, iter [01160, 01251], lr: 0.000268, loss: 0.4701
2022-09-21 04:14:19 - train: epoch 0008, iter [01170, 01251], lr: 0.000268, loss: 0.4739
2022-09-21 04:14:40 - train: epoch 0008, iter [01180, 01251], lr: 0.000268, loss: 0.4603
2022-09-21 04:15:01 - train: epoch 0008, iter [01190, 01251], lr: 0.000269, loss: 0.4508
2022-09-21 04:15:23 - train: epoch 0008, iter [01200, 01251], lr: 0.000269, loss: 0.4762
2022-09-21 04:15:44 - train: epoch 0008, iter [01210, 01251], lr: 0.000269, loss: 0.4550
2022-09-21 04:16:05 - train: epoch 0008, iter [01220, 01251], lr: 0.000269, loss: 0.4580
2022-09-21 04:16:26 - train: epoch 0008, iter [01230, 01251], lr: 0.000269, loss: 0.4483
2022-09-21 04:16:47 - train: epoch 0008, iter [01240, 01251], lr: 0.000270, loss: 0.4633
2022-09-21 04:17:08 - train: epoch 0008, iter [01250, 01251], lr: 0.000270, loss: 0.4581
2022-09-21 04:17:13 - train: epoch 008, train_loss: 0.4617
2022-09-21 04:17:18 - until epoch: 008, best_loss: 0.4617
2022-09-21 04:17:18 - epoch 009 lr: 0.000270
2022-09-21 04:17:55 - train: epoch 0009, iter [00010, 01251], lr: 0.000270, loss: 0.4495
2022-09-21 04:18:16 - train: epoch 0009, iter [00020, 01251], lr: 0.000270, loss: 0.4651
2022-09-21 04:18:36 - train: epoch 0009, iter [00030, 01251], lr: 0.000271, loss: 0.4350
2022-09-21 04:18:57 - train: epoch 0009, iter [00040, 01251], lr: 0.000271, loss: 0.4521
2022-09-21 04:19:18 - train: epoch 0009, iter [00050, 01251], lr: 0.000271, loss: 0.4442
2022-09-21 04:19:39 - train: epoch 0009, iter [00060, 01251], lr: 0.000271, loss: 0.4606
2022-09-21 04:20:00 - train: epoch 0009, iter [00070, 01251], lr: 0.000272, loss: 0.4473
2022-09-21 04:20:21 - train: epoch 0009, iter [00080, 01251], lr: 0.000272, loss: 0.4413
2022-09-21 04:20:43 - train: epoch 0009, iter [00090, 01251], lr: 0.000272, loss: 0.4610
2022-09-21 04:21:04 - train: epoch 0009, iter [00100, 01251], lr: 0.000272, loss: 0.4492
2022-09-21 04:21:26 - train: epoch 0009, iter [00110, 01251], lr: 0.000273, loss: 0.4591
2022-09-21 04:21:47 - train: epoch 0009, iter [00120, 01251], lr: 0.000273, loss: 0.4364
2022-09-21 04:22:08 - train: epoch 0009, iter [00130, 01251], lr: 0.000273, loss: 0.4674
2022-09-21 04:22:29 - train: epoch 0009, iter [00140, 01251], lr: 0.000273, loss: 0.4629
2022-09-21 04:22:51 - train: epoch 0009, iter [00150, 01251], lr: 0.000274, loss: 0.4552
2022-09-21 04:23:11 - train: epoch 0009, iter [00160, 01251], lr: 0.000274, loss: 0.4537
2022-09-21 04:23:32 - train: epoch 0009, iter [00170, 01251], lr: 0.000274, loss: 0.4484
2022-09-21 04:23:54 - train: epoch 0009, iter [00180, 01251], lr: 0.000274, loss: 0.4446
2022-09-21 04:24:15 - train: epoch 0009, iter [00190, 01251], lr: 0.000275, loss: 0.4338
2022-09-21 04:24:36 - train: epoch 0009, iter [00200, 01251], lr: 0.000275, loss: 0.4543
2022-09-21 04:24:57 - train: epoch 0009, iter [00210, 01251], lr: 0.000275, loss: 0.4780
2022-09-21 04:25:18 - train: epoch 0009, iter [00220, 01251], lr: 0.000275, loss: 0.4599
2022-09-21 04:25:40 - train: epoch 0009, iter [00230, 01251], lr: 0.000276, loss: 0.4505
2022-09-21 04:26:01 - train: epoch 0009, iter [00240, 01251], lr: 0.000276, loss: 0.4550
2022-09-21 04:26:22 - train: epoch 0009, iter [00250, 01251], lr: 0.000276, loss: 0.4576
2022-09-21 04:26:43 - train: epoch 0009, iter [00260, 01251], lr: 0.000276, loss: 0.4563
2022-09-21 04:27:04 - train: epoch 0009, iter [00270, 01251], lr: 0.000276, loss: 0.4475
2022-09-21 04:27:25 - train: epoch 0009, iter [00280, 01251], lr: 0.000277, loss: 0.4621
2022-09-21 04:27:46 - train: epoch 0009, iter [00290, 01251], lr: 0.000277, loss: 0.4653
2022-09-21 04:28:08 - train: epoch 0009, iter [00300, 01251], lr: 0.000277, loss: 0.4371
2022-09-21 04:28:29 - train: epoch 0009, iter [00310, 01251], lr: 0.000277, loss: 0.4479
2022-09-21 04:28:50 - train: epoch 0009, iter [00320, 01251], lr: 0.000278, loss: 0.4539
2022-09-21 04:29:11 - train: epoch 0009, iter [00330, 01251], lr: 0.000278, loss: 0.4488
2022-09-21 04:29:33 - train: epoch 0009, iter [00340, 01251], lr: 0.000278, loss: 0.4690
2022-09-21 04:29:54 - train: epoch 0009, iter [00350, 01251], lr: 0.000278, loss: 0.4590
2022-09-21 04:30:15 - train: epoch 0009, iter [00360, 01251], lr: 0.000279, loss: 0.4215
2022-09-21 04:30:36 - train: epoch 0009, iter [00370, 01251], lr: 0.000279, loss: 0.4599
2022-09-21 04:30:58 - train: epoch 0009, iter [00380, 01251], lr: 0.000279, loss: 0.4551
2022-09-21 04:31:19 - train: epoch 0009, iter [00390, 01251], lr: 0.000279, loss: 0.4310
2022-09-21 04:31:40 - train: epoch 0009, iter [00400, 01251], lr: 0.000280, loss: 0.4552
2022-09-21 04:32:01 - train: epoch 0009, iter [00410, 01251], lr: 0.000280, loss: 0.4461
2022-09-21 04:32:23 - train: epoch 0009, iter [00420, 01251], lr: 0.000280, loss: 0.4608
2022-09-21 04:32:44 - train: epoch 0009, iter [00430, 01251], lr: 0.000280, loss: 0.4620
2022-09-21 04:33:05 - train: epoch 0009, iter [00440, 01251], lr: 0.000281, loss: 0.4553
2022-09-21 04:33:26 - train: epoch 0009, iter [00450, 01251], lr: 0.000281, loss: 0.4616
2022-09-21 04:33:47 - train: epoch 0009, iter [00460, 01251], lr: 0.000281, loss: 0.4814
2022-09-21 04:34:08 - train: epoch 0009, iter [00470, 01251], lr: 0.000281, loss: 0.4695
2022-09-21 04:34:30 - train: epoch 0009, iter [00480, 01251], lr: 0.000282, loss: 0.4722
2022-09-21 04:34:51 - train: epoch 0009, iter [00490, 01251], lr: 0.000282, loss: 0.4725
2022-09-21 04:35:12 - train: epoch 0009, iter [00500, 01251], lr: 0.000282, loss: 0.4564
2022-09-21 04:35:33 - train: epoch 0009, iter [00510, 01251], lr: 0.000282, loss: 0.4685
2022-09-21 04:35:55 - train: epoch 0009, iter [00520, 01251], lr: 0.000282, loss: 0.4539
2022-09-21 04:36:16 - train: epoch 0009, iter [00530, 01251], lr: 0.000283, loss: 0.4636
2022-09-21 04:36:37 - train: epoch 0009, iter [00540, 01251], lr: 0.000283, loss: 0.4474
2022-09-21 04:36:58 - train: epoch 0009, iter [00550, 01251], lr: 0.000283, loss: 0.4465
2022-09-21 04:37:19 - train: epoch 0009, iter [00560, 01251], lr: 0.000283, loss: 0.4715
2022-09-21 04:37:41 - train: epoch 0009, iter [00570, 01251], lr: 0.000284, loss: 0.4437
2022-09-21 04:38:02 - train: epoch 0009, iter [00580, 01251], lr: 0.000284, loss: 0.4721
2022-09-21 04:38:23 - train: epoch 0009, iter [00590, 01251], lr: 0.000284, loss: 0.4503
2022-09-21 04:38:44 - train: epoch 0009, iter [00600, 01251], lr: 0.000284, loss: 0.4643
2022-09-21 04:39:05 - train: epoch 0009, iter [00610, 01251], lr: 0.000285, loss: 0.4727
2022-09-21 04:39:26 - train: epoch 0009, iter [00620, 01251], lr: 0.000285, loss: 0.4509
2022-09-21 04:39:47 - train: epoch 0009, iter [00630, 01251], lr: 0.000285, loss: 0.4567
2022-09-21 04:40:08 - train: epoch 0009, iter [00640, 01251], lr: 0.000285, loss: 0.4692
2022-09-21 04:40:29 - train: epoch 0009, iter [00650, 01251], lr: 0.000286, loss: 0.4541
2022-09-21 04:40:51 - train: epoch 0009, iter [00660, 01251], lr: 0.000286, loss: 0.4713
2022-09-21 04:41:12 - train: epoch 0009, iter [00670, 01251], lr: 0.000286, loss: 0.4636
2022-09-21 04:41:33 - train: epoch 0009, iter [00680, 01251], lr: 0.000286, loss: 0.4516
2022-09-21 04:41:54 - train: epoch 0009, iter [00690, 01251], lr: 0.000287, loss: 0.4538
2022-09-21 04:42:15 - train: epoch 0009, iter [00700, 01251], lr: 0.000287, loss: 0.4772
2022-09-21 04:42:36 - train: epoch 0009, iter [00710, 01251], lr: 0.000287, loss: 0.4418
2022-09-21 04:42:58 - train: epoch 0009, iter [00720, 01251], lr: 0.000287, loss: 0.4562
2022-09-21 04:43:19 - train: epoch 0009, iter [00730, 01251], lr: 0.000288, loss: 0.4384
2022-09-21 04:43:40 - train: epoch 0009, iter [00740, 01251], lr: 0.000288, loss: 0.4608
2022-09-21 04:44:01 - train: epoch 0009, iter [00750, 01251], lr: 0.000288, loss: 0.4465
2022-09-21 04:44:22 - train: epoch 0009, iter [00760, 01251], lr: 0.000288, loss: 0.4325
2022-09-21 04:44:43 - train: epoch 0009, iter [00770, 01251], lr: 0.000288, loss: 0.4486
2022-09-21 04:45:04 - train: epoch 0009, iter [00780, 01251], lr: 0.000289, loss: 0.4337
2022-09-21 04:45:25 - train: epoch 0009, iter [00790, 01251], lr: 0.000289, loss: 0.4677
2022-09-21 04:45:47 - train: epoch 0009, iter [00800, 01251], lr: 0.000289, loss: 0.4637
2022-09-21 04:46:08 - train: epoch 0009, iter [00810, 01251], lr: 0.000289, loss: 0.4508
2022-09-21 04:46:29 - train: epoch 0009, iter [00820, 01251], lr: 0.000290, loss: 0.4386
2022-09-21 04:46:50 - train: epoch 0009, iter [00830, 01251], lr: 0.000290, loss: 0.4700
2022-09-21 04:47:11 - train: epoch 0009, iter [00840, 01251], lr: 0.000290, loss: 0.4471
2022-09-21 04:47:32 - train: epoch 0009, iter [00850, 01251], lr: 0.000290, loss: 0.4612
2022-09-21 04:47:53 - train: epoch 0009, iter [00860, 01251], lr: 0.000291, loss: 0.4489
2022-09-21 04:48:14 - train: epoch 0009, iter [00870, 01251], lr: 0.000291, loss: 0.4660
2022-09-21 04:48:35 - train: epoch 0009, iter [00880, 01251], lr: 0.000291, loss: 0.4793
2022-09-21 04:48:56 - train: epoch 0009, iter [00890, 01251], lr: 0.000291, loss: 0.4654
2022-09-21 04:49:18 - train: epoch 0009, iter [00900, 01251], lr: 0.000292, loss: 0.4630
2022-09-21 04:49:39 - train: epoch 0009, iter [00910, 01251], lr: 0.000292, loss: 0.4520
2022-09-21 04:50:00 - train: epoch 0009, iter [00920, 01251], lr: 0.000292, loss: 0.4320
2022-09-21 04:50:21 - train: epoch 0009, iter [00930, 01251], lr: 0.000292, loss: 0.4606
2022-09-21 04:50:42 - train: epoch 0009, iter [00940, 01251], lr: 0.000293, loss: 0.4536
2022-09-21 04:51:04 - train: epoch 0009, iter [00950, 01251], lr: 0.000293, loss: 0.4464
2022-09-21 04:51:25 - train: epoch 0009, iter [00960, 01251], lr: 0.000293, loss: 0.4523
2022-09-21 04:51:46 - train: epoch 0009, iter [00970, 01251], lr: 0.000293, loss: 0.4372
2022-09-21 04:52:08 - train: epoch 0009, iter [00980, 01251], lr: 0.000294, loss: 0.4629
2022-09-21 04:52:29 - train: epoch 0009, iter [00990, 01251], lr: 0.000294, loss: 0.4526
2022-09-21 04:52:50 - train: epoch 0009, iter [01000, 01251], lr: 0.000294, loss: 0.4663
2022-09-21 04:53:11 - train: epoch 0009, iter [01010, 01251], lr: 0.000294, loss: 0.4641
2022-09-21 04:53:32 - train: epoch 0009, iter [01020, 01251], lr: 0.000294, loss: 0.4389
2022-09-21 04:53:53 - train: epoch 0009, iter [01030, 01251], lr: 0.000295, loss: 0.4555
2022-09-21 04:54:15 - train: epoch 0009, iter [01040, 01251], lr: 0.000295, loss: 0.4684
2022-09-21 04:54:36 - train: epoch 0009, iter [01050, 01251], lr: 0.000295, loss: 0.4568
2022-09-21 04:54:57 - train: epoch 0009, iter [01060, 01251], lr: 0.000295, loss: 0.4430
2022-09-21 04:55:18 - train: epoch 0009, iter [01070, 01251], lr: 0.000296, loss: 0.4420
2022-09-21 04:55:39 - train: epoch 0009, iter [01080, 01251], lr: 0.000296, loss: 0.4638
2022-09-21 04:56:00 - train: epoch 0009, iter [01090, 01251], lr: 0.000296, loss: 0.4667
2022-09-21 04:56:22 - train: epoch 0009, iter [01100, 01251], lr: 0.000296, loss: 0.4592
2022-09-21 04:56:43 - train: epoch 0009, iter [01110, 01251], lr: 0.000297, loss: 0.4520
2022-09-21 04:57:04 - train: epoch 0009, iter [01120, 01251], lr: 0.000297, loss: 0.4521
2022-09-21 04:57:25 - train: epoch 0009, iter [01130, 01251], lr: 0.000297, loss: 0.4577
2022-09-21 04:57:47 - train: epoch 0009, iter [01140, 01251], lr: 0.000297, loss: 0.4546
2022-09-21 04:58:08 - train: epoch 0009, iter [01150, 01251], lr: 0.000298, loss: 0.4340
2022-09-21 04:58:29 - train: epoch 0009, iter [01160, 01251], lr: 0.000298, loss: 0.4497
2022-09-21 04:58:50 - train: epoch 0009, iter [01170, 01251], lr: 0.000298, loss: 0.4790
2022-09-21 04:59:12 - train: epoch 0009, iter [01180, 01251], lr: 0.000298, loss: 0.4525
2022-09-21 04:59:33 - train: epoch 0009, iter [01190, 01251], lr: 0.000299, loss: 0.4492
2022-09-21 04:59:54 - train: epoch 0009, iter [01200, 01251], lr: 0.000299, loss: 0.4540
2022-09-21 05:00:15 - train: epoch 0009, iter [01210, 01251], lr: 0.000299, loss: 0.4583
2022-09-21 05:00:36 - train: epoch 0009, iter [01220, 01251], lr: 0.000299, loss: 0.4614
2022-09-21 05:00:58 - train: epoch 0009, iter [01230, 01251], lr: 0.000299, loss: 0.4688
2022-09-21 05:01:19 - train: epoch 0009, iter [01240, 01251], lr: 0.000300, loss: 0.4380
2022-09-21 05:01:39 - train: epoch 0009, iter [01250, 01251], lr: 0.000300, loss: 0.4440
2022-09-21 05:01:45 - train: epoch 009, train_loss: 0.4568
2022-09-21 05:01:50 - until epoch: 009, best_loss: 0.4568
2022-09-21 05:01:50 - epoch 010 lr: 0.000300
2022-09-21 05:02:26 - train: epoch 0010, iter [00010, 01251], lr: 0.000300, loss: 0.4505
2022-09-21 05:02:47 - train: epoch 0010, iter [00020, 01251], lr: 0.000300, loss: 0.4506
2022-09-21 05:03:08 - train: epoch 0010, iter [00030, 01251], lr: 0.000301, loss: 0.4585
2022-09-21 05:03:29 - train: epoch 0010, iter [00040, 01251], lr: 0.000301, loss: 0.4464
2022-09-21 05:03:50 - train: epoch 0010, iter [00050, 01251], lr: 0.000301, loss: 0.4396
2022-09-21 05:04:11 - train: epoch 0010, iter [00060, 01251], lr: 0.000301, loss: 0.4580
2022-09-21 05:04:32 - train: epoch 0010, iter [00070, 01251], lr: 0.000302, loss: 0.4646
2022-09-21 05:04:53 - train: epoch 0010, iter [00080, 01251], lr: 0.000302, loss: 0.4688
2022-09-21 05:05:14 - train: epoch 0010, iter [00090, 01251], lr: 0.000302, loss: 0.4781
2022-09-21 05:05:35 - train: epoch 0010, iter [00100, 01251], lr: 0.000302, loss: 0.4481
2022-09-21 05:05:56 - train: epoch 0010, iter [00110, 01251], lr: 0.000303, loss: 0.4589
2022-09-21 05:06:18 - train: epoch 0010, iter [00120, 01251], lr: 0.000303, loss: 0.4439
2022-09-21 05:06:39 - train: epoch 0010, iter [00130, 01251], lr: 0.000303, loss: 0.4448
2022-09-21 05:07:01 - train: epoch 0010, iter [00140, 01251], lr: 0.000303, loss: 0.4523
2022-09-21 05:07:22 - train: epoch 0010, iter [00150, 01251], lr: 0.000304, loss: 0.4599
2022-09-21 05:07:43 - train: epoch 0010, iter [00160, 01251], lr: 0.000304, loss: 0.4659
2022-09-21 05:08:05 - train: epoch 0010, iter [00170, 01251], lr: 0.000304, loss: 0.4572
2022-09-21 05:08:26 - train: epoch 0010, iter [00180, 01251], lr: 0.000304, loss: 0.4694
2022-09-21 05:08:47 - train: epoch 0010, iter [00190, 01251], lr: 0.000305, loss: 0.4490
2022-09-21 05:09:09 - train: epoch 0010, iter [00200, 01251], lr: 0.000305, loss: 0.4558
2022-09-21 05:09:30 - train: epoch 0010, iter [00210, 01251], lr: 0.000305, loss: 0.4498
2022-09-21 05:09:51 - train: epoch 0010, iter [00220, 01251], lr: 0.000305, loss: 0.4532
2022-09-21 05:10:12 - train: epoch 0010, iter [00230, 01251], lr: 0.000306, loss: 0.4648
2022-09-21 05:10:33 - train: epoch 0010, iter [00240, 01251], lr: 0.000306, loss: 0.4387
2022-09-21 05:10:54 - train: epoch 0010, iter [00250, 01251], lr: 0.000306, loss: 0.4422
2022-09-21 05:11:16 - train: epoch 0010, iter [00260, 01251], lr: 0.000306, loss: 0.4379
2022-09-21 05:11:37 - train: epoch 0010, iter [00270, 01251], lr: 0.000306, loss: 0.4598
2022-09-21 05:11:58 - train: epoch 0010, iter [00280, 01251], lr: 0.000307, loss: 0.4675
2022-09-21 05:12:19 - train: epoch 0010, iter [00290, 01251], lr: 0.000307, loss: 0.4463
2022-09-21 05:12:40 - train: epoch 0010, iter [00300, 01251], lr: 0.000307, loss: 0.4531
2022-09-21 05:13:01 - train: epoch 0010, iter [00310, 01251], lr: 0.000307, loss: 0.4488
2022-09-21 05:13:23 - train: epoch 0010, iter [00320, 01251], lr: 0.000308, loss: 0.4608
2022-09-21 05:13:44 - train: epoch 0010, iter [00330, 01251], lr: 0.000308, loss: 0.4749
2022-09-21 05:14:05 - train: epoch 0010, iter [00340, 01251], lr: 0.000308, loss: 0.4539
2022-09-21 05:14:26 - train: epoch 0010, iter [00350, 01251], lr: 0.000308, loss: 0.4406
2022-09-21 05:14:47 - train: epoch 0010, iter [00360, 01251], lr: 0.000309, loss: 0.4806
2022-09-21 05:15:08 - train: epoch 0010, iter [00370, 01251], lr: 0.000309, loss: 0.4765
2022-09-21 05:15:29 - train: epoch 0010, iter [00380, 01251], lr: 0.000309, loss: 0.4648
2022-09-21 05:15:50 - train: epoch 0010, iter [00390, 01251], lr: 0.000309, loss: 0.4359
2022-09-21 05:16:11 - train: epoch 0010, iter [00400, 01251], lr: 0.000310, loss: 0.4632
2022-09-21 05:16:32 - train: epoch 0010, iter [00410, 01251], lr: 0.000310, loss: 0.4489
2022-09-21 05:16:54 - train: epoch 0010, iter [00420, 01251], lr: 0.000310, loss: 0.4374
2022-09-21 05:17:15 - train: epoch 0010, iter [00430, 01251], lr: 0.000310, loss: 0.4253
2022-09-21 05:17:36 - train: epoch 0010, iter [00440, 01251], lr: 0.000311, loss: 0.4563
2022-09-21 05:17:57 - train: epoch 0010, iter [00450, 01251], lr: 0.000311, loss: 0.4520
2022-09-21 05:18:19 - train: epoch 0010, iter [00460, 01251], lr: 0.000311, loss: 0.4551
2022-09-21 05:18:40 - train: epoch 0010, iter [00470, 01251], lr: 0.000311, loss: 0.4703
2022-09-21 05:19:01 - train: epoch 0010, iter [00480, 01251], lr: 0.000312, loss: 0.4526
2022-09-21 05:19:22 - train: epoch 0010, iter [00490, 01251], lr: 0.000312, loss: 0.4535
2022-09-21 05:19:43 - train: epoch 0010, iter [00500, 01251], lr: 0.000312, loss: 0.4533
2022-09-21 05:20:04 - train: epoch 0010, iter [00510, 01251], lr: 0.000312, loss: 0.4515
2022-09-21 05:20:26 - train: epoch 0010, iter [00520, 01251], lr: 0.000312, loss: 0.4452
2022-09-21 05:20:47 - train: epoch 0010, iter [00530, 01251], lr: 0.000313, loss: 0.4603
2022-09-21 05:21:08 - train: epoch 0010, iter [00540, 01251], lr: 0.000313, loss: 0.4606
2022-09-21 05:21:29 - train: epoch 0010, iter [00550, 01251], lr: 0.000313, loss: 0.4759
2022-09-21 05:21:51 - train: epoch 0010, iter [00560, 01251], lr: 0.000313, loss: 0.4342
2022-09-21 05:22:12 - train: epoch 0010, iter [00570, 01251], lr: 0.000314, loss: 0.4531
2022-09-21 05:22:34 - train: epoch 0010, iter [00580, 01251], lr: 0.000314, loss: 0.4438
2022-09-21 05:22:55 - train: epoch 0010, iter [00590, 01251], lr: 0.000314, loss: 0.4465
2022-09-21 05:23:17 - train: epoch 0010, iter [00600, 01251], lr: 0.000314, loss: 0.4470
2022-09-21 05:23:39 - train: epoch 0010, iter [00610, 01251], lr: 0.000315, loss: 0.4683
2022-09-21 05:24:00 - train: epoch 0010, iter [00620, 01251], lr: 0.000315, loss: 0.4689
2022-09-21 05:24:21 - train: epoch 0010, iter [00630, 01251], lr: 0.000315, loss: 0.4397
2022-09-21 05:24:43 - train: epoch 0010, iter [00640, 01251], lr: 0.000315, loss: 0.4718
2022-09-21 05:25:04 - train: epoch 0010, iter [00650, 01251], lr: 0.000316, loss: 0.4497
2022-09-21 05:25:25 - train: epoch 0010, iter [00660, 01251], lr: 0.000316, loss: 0.4475
2022-09-21 05:25:46 - train: epoch 0010, iter [00670, 01251], lr: 0.000316, loss: 0.4567
2022-09-21 05:26:07 - train: epoch 0010, iter [00680, 01251], lr: 0.000316, loss: 0.4555
2022-09-21 05:26:28 - train: epoch 0010, iter [00690, 01251], lr: 0.000317, loss: 0.4443
2022-09-21 05:26:49 - train: epoch 0010, iter [00700, 01251], lr: 0.000317, loss: 0.4454
2022-09-21 05:27:11 - train: epoch 0010, iter [00710, 01251], lr: 0.000317, loss: 0.4554
2022-09-21 05:27:32 - train: epoch 0010, iter [00720, 01251], lr: 0.000317, loss: 0.4445
2022-09-21 05:27:53 - train: epoch 0010, iter [00730, 01251], lr: 0.000318, loss: 0.4681
2022-09-21 05:28:14 - train: epoch 0010, iter [00740, 01251], lr: 0.000318, loss: 0.4463
2022-09-21 05:28:35 - train: epoch 0010, iter [00750, 01251], lr: 0.000318, loss: 0.4578
2022-09-21 05:28:56 - train: epoch 0010, iter [00760, 01251], lr: 0.000318, loss: 0.4401
2022-09-21 05:29:17 - train: epoch 0010, iter [00770, 01251], lr: 0.000318, loss: 0.4737
2022-09-21 05:29:39 - train: epoch 0010, iter [00780, 01251], lr: 0.000319, loss: 0.4668
2022-09-21 05:30:00 - train: epoch 0010, iter [00790, 01251], lr: 0.000319, loss: 0.4395
2022-09-21 05:30:21 - train: epoch 0010, iter [00800, 01251], lr: 0.000319, loss: 0.4621
2022-09-21 05:30:42 - train: epoch 0010, iter [00810, 01251], lr: 0.000319, loss: 0.4700
2022-09-21 05:31:03 - train: epoch 0010, iter [00820, 01251], lr: 0.000320, loss: 0.4679
2022-09-21 05:31:25 - train: epoch 0010, iter [00830, 01251], lr: 0.000320, loss: 0.4546
2022-09-21 05:31:46 - train: epoch 0010, iter [00840, 01251], lr: 0.000320, loss: 0.4570
2022-09-21 05:32:07 - train: epoch 0010, iter [00850, 01251], lr: 0.000320, loss: 0.4485
2022-09-21 05:32:28 - train: epoch 0010, iter [00860, 01251], lr: 0.000321, loss: 0.4484
2022-09-21 05:32:49 - train: epoch 0010, iter [00870, 01251], lr: 0.000321, loss: 0.4438
2022-09-21 05:33:10 - train: epoch 0010, iter [00880, 01251], lr: 0.000321, loss: 0.4382
2022-09-21 05:33:31 - train: epoch 0010, iter [00890, 01251], lr: 0.000321, loss: 0.4434
2022-09-21 05:33:52 - train: epoch 0010, iter [00900, 01251], lr: 0.000322, loss: 0.4456
2022-09-21 05:34:13 - train: epoch 0010, iter [00910, 01251], lr: 0.000322, loss: 0.4386
2022-09-21 05:34:35 - train: epoch 0010, iter [00920, 01251], lr: 0.000322, loss: 0.4801
2022-09-21 05:34:56 - train: epoch 0010, iter [00930, 01251], lr: 0.000322, loss: 0.4627
2022-09-21 05:35:17 - train: epoch 0010, iter [00940, 01251], lr: 0.000323, loss: 0.4400
2022-09-21 05:35:38 - train: epoch 0010, iter [00950, 01251], lr: 0.000323, loss: 0.4410
2022-09-21 05:35:59 - train: epoch 0010, iter [00960, 01251], lr: 0.000323, loss: 0.4481
2022-09-21 05:36:20 - train: epoch 0010, iter [00970, 01251], lr: 0.000323, loss: 0.4547
2022-09-21 05:36:41 - train: epoch 0010, iter [00980, 01251], lr: 0.000324, loss: 0.4835
2022-09-21 05:37:02 - train: epoch 0010, iter [00990, 01251], lr: 0.000324, loss: 0.4634
2022-09-21 05:37:23 - train: epoch 0010, iter [01000, 01251], lr: 0.000324, loss: 0.4556
2022-09-21 05:37:44 - train: epoch 0010, iter [01010, 01251], lr: 0.000324, loss: 0.4483
2022-09-21 05:38:05 - train: epoch 0010, iter [01020, 01251], lr: 0.000324, loss: 0.4541
2022-09-21 05:38:27 - train: epoch 0010, iter [01030, 01251], lr: 0.000325, loss: 0.4738
2022-09-21 05:38:48 - train: epoch 0010, iter [01040, 01251], lr: 0.000325, loss: 0.4474
2022-09-21 05:39:10 - train: epoch 0010, iter [01050, 01251], lr: 0.000325, loss: 0.4732
2022-09-21 05:39:31 - train: epoch 0010, iter [01060, 01251], lr: 0.000325, loss: 0.4277
2022-09-21 05:39:52 - train: epoch 0010, iter [01070, 01251], lr: 0.000326, loss: 0.4279
2022-09-21 05:40:13 - train: epoch 0010, iter [01080, 01251], lr: 0.000326, loss: 0.4491
2022-09-21 05:40:35 - train: epoch 0010, iter [01090, 01251], lr: 0.000326, loss: 0.4682
2022-09-21 05:40:56 - train: epoch 0010, iter [01100, 01251], lr: 0.000326, loss: 0.4368
2022-09-21 05:41:17 - train: epoch 0010, iter [01110, 01251], lr: 0.000327, loss: 0.4659
2022-09-21 05:41:38 - train: epoch 0010, iter [01120, 01251], lr: 0.000327, loss: 0.4480
2022-09-21 05:41:59 - train: epoch 0010, iter [01130, 01251], lr: 0.000327, loss: 0.4537
2022-09-21 05:42:20 - train: epoch 0010, iter [01140, 01251], lr: 0.000327, loss: 0.4572
2022-09-21 05:42:41 - train: epoch 0010, iter [01150, 01251], lr: 0.000328, loss: 0.4436
2022-09-21 05:43:02 - train: epoch 0010, iter [01160, 01251], lr: 0.000328, loss: 0.4663
2022-09-21 05:43:23 - train: epoch 0010, iter [01170, 01251], lr: 0.000328, loss: 0.4418
2022-09-21 05:43:44 - train: epoch 0010, iter [01180, 01251], lr: 0.000328, loss: 0.4498
2022-09-21 05:44:05 - train: epoch 0010, iter [01190, 01251], lr: 0.000329, loss: 0.4177
2022-09-21 05:44:26 - train: epoch 0010, iter [01200, 01251], lr: 0.000329, loss: 0.4422
2022-09-21 05:44:47 - train: epoch 0010, iter [01210, 01251], lr: 0.000329, loss: 0.4651
2022-09-21 05:45:08 - train: epoch 0010, iter [01220, 01251], lr: 0.000329, loss: 0.4696
2022-09-21 05:45:29 - train: epoch 0010, iter [01230, 01251], lr: 0.000329, loss: 0.4263
2022-09-21 05:45:50 - train: epoch 0010, iter [01240, 01251], lr: 0.000330, loss: 0.4734
2022-09-21 05:46:10 - train: epoch 0010, iter [01250, 01251], lr: 0.000330, loss: 0.4379
2022-09-21 05:46:15 - train: epoch 010, train_loss: 0.4526
2022-09-21 05:46:20 - until epoch: 010, best_loss: 0.4526
2022-09-21 05:46:20 - epoch 011 lr: 0.000330
2022-09-21 05:46:57 - train: epoch 0011, iter [00010, 01251], lr: 0.000330, loss: 0.4814
2022-09-21 05:47:18 - train: epoch 0011, iter [00020, 01251], lr: 0.000330, loss: 0.4436
2022-09-21 05:47:39 - train: epoch 0011, iter [00030, 01251], lr: 0.000331, loss: 0.4511
2022-09-21 05:48:00 - train: epoch 0011, iter [00040, 01251], lr: 0.000331, loss: 0.4373
2022-09-21 05:48:21 - train: epoch 0011, iter [00050, 01251], lr: 0.000331, loss: 0.4373
2022-09-21 05:48:42 - train: epoch 0011, iter [00060, 01251], lr: 0.000331, loss: 0.4580
2022-09-21 05:49:03 - train: epoch 0011, iter [00070, 01251], lr: 0.000332, loss: 0.4704
2022-09-21 05:49:24 - train: epoch 0011, iter [00080, 01251], lr: 0.000332, loss: 0.4572
2022-09-21 05:49:45 - train: epoch 0011, iter [00090, 01251], lr: 0.000332, loss: 0.4656
2022-09-21 05:50:05 - train: epoch 0011, iter [00100, 01251], lr: 0.000332, loss: 0.4443
2022-09-21 05:50:27 - train: epoch 0011, iter [00110, 01251], lr: 0.000333, loss: 0.4378
2022-09-21 05:50:48 - train: epoch 0011, iter [00120, 01251], lr: 0.000333, loss: 0.4480
2022-09-21 05:51:09 - train: epoch 0011, iter [00130, 01251], lr: 0.000333, loss: 0.4611
2022-09-21 05:51:30 - train: epoch 0011, iter [00140, 01251], lr: 0.000333, loss: 0.4468
2022-09-21 05:51:51 - train: epoch 0011, iter [00150, 01251], lr: 0.000334, loss: 0.4492
2022-09-21 05:52:12 - train: epoch 0011, iter [00160, 01251], lr: 0.000334, loss: 0.4325
2022-09-21 05:52:33 - train: epoch 0011, iter [00170, 01251], lr: 0.000334, loss: 0.4457
2022-09-21 05:52:54 - train: epoch 0011, iter [00180, 01251], lr: 0.000334, loss: 0.4533
2022-09-21 05:53:15 - train: epoch 0011, iter [00190, 01251], lr: 0.000335, loss: 0.4215
2022-09-21 05:53:36 - train: epoch 0011, iter [00200, 01251], lr: 0.000335, loss: 0.4468
2022-09-21 05:53:58 - train: epoch 0011, iter [00210, 01251], lr: 0.000335, loss: 0.4591
2022-09-21 05:54:19 - train: epoch 0011, iter [00220, 01251], lr: 0.000335, loss: 0.4389
2022-09-21 05:54:41 - train: epoch 0011, iter [00230, 01251], lr: 0.000336, loss: 0.4485
2022-09-21 05:55:02 - train: epoch 0011, iter [00240, 01251], lr: 0.000336, loss: 0.4390
2022-09-21 05:55:23 - train: epoch 0011, iter [00250, 01251], lr: 0.000336, loss: 0.4490
2022-09-21 05:55:44 - train: epoch 0011, iter [00260, 01251], lr: 0.000336, loss: 0.4508
2022-09-21 05:56:05 - train: epoch 0011, iter [00270, 01251], lr: 0.000336, loss: 0.4239
2022-09-21 05:56:26 - train: epoch 0011, iter [00280, 01251], lr: 0.000337, loss: 0.4521
2022-09-21 05:56:48 - train: epoch 0011, iter [00290, 01251], lr: 0.000337, loss: 0.4313
2022-09-21 05:57:09 - train: epoch 0011, iter [00300, 01251], lr: 0.000337, loss: 0.4344
2022-09-21 05:57:30 - train: epoch 0011, iter [00310, 01251], lr: 0.000337, loss: 0.4382
2022-09-21 05:57:51 - train: epoch 0011, iter [00320, 01251], lr: 0.000338, loss: 0.4483
2022-09-21 05:58:12 - train: epoch 0011, iter [00330, 01251], lr: 0.000338, loss: 0.4530
2022-09-21 05:58:33 - train: epoch 0011, iter [00340, 01251], lr: 0.000338, loss: 0.4488
2022-09-21 05:58:54 - train: epoch 0011, iter [00350, 01251], lr: 0.000338, loss: 0.4672
2022-09-21 05:59:15 - train: epoch 0011, iter [00360, 01251], lr: 0.000339, loss: 0.4370
2022-09-21 05:59:36 - train: epoch 0011, iter [00370, 01251], lr: 0.000339, loss: 0.4720
2022-09-21 05:59:57 - train: epoch 0011, iter [00380, 01251], lr: 0.000339, loss: 0.4591
2022-09-21 06:00:18 - train: epoch 0011, iter [00390, 01251], lr: 0.000339, loss: 0.4494
2022-09-21 06:00:39 - train: epoch 0011, iter [00400, 01251], lr: 0.000340, loss: 0.4569
2022-09-21 06:01:00 - train: epoch 0011, iter [00410, 01251], lr: 0.000340, loss: 0.4447
2022-09-21 06:01:21 - train: epoch 0011, iter [00420, 01251], lr: 0.000340, loss: 0.4612
2022-09-21 06:01:42 - train: epoch 0011, iter [00430, 01251], lr: 0.000340, loss: 0.4537
2022-09-21 06:02:02 - train: epoch 0011, iter [00440, 01251], lr: 0.000341, loss: 0.4254
2022-09-21 06:02:23 - train: epoch 0011, iter [00450, 01251], lr: 0.000341, loss: 0.4625
2022-09-21 06:02:44 - train: epoch 0011, iter [00460, 01251], lr: 0.000341, loss: 0.4616
2022-09-21 06:03:05 - train: epoch 0011, iter [00470, 01251], lr: 0.000341, loss: 0.4332
2022-09-21 06:03:26 - train: epoch 0011, iter [00480, 01251], lr: 0.000342, loss: 0.4616
2022-09-21 06:03:47 - train: epoch 0011, iter [00490, 01251], lr: 0.000342, loss: 0.4370
2022-09-21 06:04:08 - train: epoch 0011, iter [00500, 01251], lr: 0.000342, loss: 0.4512
2022-09-21 06:04:29 - train: epoch 0011, iter [00510, 01251], lr: 0.000342, loss: 0.4582
2022-09-21 06:04:50 - train: epoch 0011, iter [00520, 01251], lr: 0.000342, loss: 0.4447
2022-09-21 06:05:11 - train: epoch 0011, iter [00530, 01251], lr: 0.000343, loss: 0.4445
2022-09-21 06:05:32 - train: epoch 0011, iter [00540, 01251], lr: 0.000343, loss: 0.4374
2022-09-21 06:05:53 - train: epoch 0011, iter [00550, 01251], lr: 0.000343, loss: 0.4517
2022-09-21 06:06:13 - train: epoch 0011, iter [00560, 01251], lr: 0.000343, loss: 0.4614
2022-09-21 06:06:34 - train: epoch 0011, iter [00570, 01251], lr: 0.000344, loss: 0.4588
2022-09-21 06:06:55 - train: epoch 0011, iter [00580, 01251], lr: 0.000344, loss: 0.4128
2022-09-21 06:07:16 - train: epoch 0011, iter [00590, 01251], lr: 0.000344, loss: 0.4488
2022-09-21 06:07:37 - train: epoch 0011, iter [00600, 01251], lr: 0.000344, loss: 0.4456
2022-09-21 06:07:58 - train: epoch 0011, iter [00610, 01251], lr: 0.000345, loss: 0.4548
2022-09-21 06:08:20 - train: epoch 0011, iter [00620, 01251], lr: 0.000345, loss: 0.4608
2022-09-21 06:08:41 - train: epoch 0011, iter [00630, 01251], lr: 0.000345, loss: 0.4423
2022-09-21 06:09:02 - train: epoch 0011, iter [00640, 01251], lr: 0.000345, loss: 0.4488
2022-09-21 06:09:24 - train: epoch 0011, iter [00650, 01251], lr: 0.000346, loss: 0.4644
2022-09-21 06:09:45 - train: epoch 0011, iter [00660, 01251], lr: 0.000346, loss: 0.4629
2022-09-21 06:10:06 - train: epoch 0011, iter [00670, 01251], lr: 0.000346, loss: 0.4499
2022-09-21 06:10:27 - train: epoch 0011, iter [00680, 01251], lr: 0.000346, loss: 0.4424
2022-09-21 06:10:48 - train: epoch 0011, iter [00690, 01251], lr: 0.000347, loss: 0.4436
2022-09-21 06:11:09 - train: epoch 0011, iter [00700, 01251], lr: 0.000347, loss: 0.4166
2022-09-21 06:11:30 - train: epoch 0011, iter [00710, 01251], lr: 0.000347, loss: 0.4389
2022-09-21 06:11:51 - train: epoch 0011, iter [00720, 01251], lr: 0.000347, loss: 0.4444
2022-09-21 06:12:12 - train: epoch 0011, iter [00730, 01251], lr: 0.000348, loss: 0.4462
2022-09-21 06:12:33 - train: epoch 0011, iter [00740, 01251], lr: 0.000348, loss: 0.4250
2022-09-21 06:12:54 - train: epoch 0011, iter [00750, 01251], lr: 0.000348, loss: 0.4641
2022-09-21 06:13:15 - train: epoch 0011, iter [00760, 01251], lr: 0.000348, loss: 0.4370
2022-09-21 06:13:36 - train: epoch 0011, iter [00770, 01251], lr: 0.000348, loss: 0.4425
2022-09-21 06:13:57 - train: epoch 0011, iter [00780, 01251], lr: 0.000349, loss: 0.4369
2022-09-21 06:14:18 - train: epoch 0011, iter [00790, 01251], lr: 0.000349, loss: 0.4493
2022-09-21 06:14:39 - train: epoch 0011, iter [00800, 01251], lr: 0.000349, loss: 0.4611
2022-09-21 06:15:00 - train: epoch 0011, iter [00810, 01251], lr: 0.000349, loss: 0.4580
2022-09-21 06:15:21 - train: epoch 0011, iter [00820, 01251], lr: 0.000350, loss: 0.4618
2022-09-21 06:15:42 - train: epoch 0011, iter [00830, 01251], lr: 0.000350, loss: 0.4317
2022-09-21 06:16:03 - train: epoch 0011, iter [00840, 01251], lr: 0.000350, loss: 0.4413
2022-09-21 06:16:24 - train: epoch 0011, iter [00850, 01251], lr: 0.000350, loss: 0.4701
2022-09-21 06:16:45 - train: epoch 0011, iter [00860, 01251], lr: 0.000351, loss: 0.4390
2022-09-21 06:17:06 - train: epoch 0011, iter [00870, 01251], lr: 0.000351, loss: 0.4410
2022-09-21 06:17:27 - train: epoch 0011, iter [00880, 01251], lr: 0.000351, loss: 0.4537
2022-09-21 06:17:48 - train: epoch 0011, iter [00890, 01251], lr: 0.000351, loss: 0.4592
2022-09-21 06:18:09 - train: epoch 0011, iter [00900, 01251], lr: 0.000352, loss: 0.4405
2022-09-21 06:18:29 - train: epoch 0011, iter [00910, 01251], lr: 0.000352, loss: 0.4367
2022-09-21 06:18:50 - train: epoch 0011, iter [00920, 01251], lr: 0.000352, loss: 0.4639
2022-09-21 06:19:11 - train: epoch 0011, iter [00930, 01251], lr: 0.000352, loss: 0.4350
2022-09-21 06:19:32 - train: epoch 0011, iter [00940, 01251], lr: 0.000353, loss: 0.4532
2022-09-21 06:19:53 - train: epoch 0011, iter [00950, 01251], lr: 0.000353, loss: 0.4515
2022-09-21 06:20:14 - train: epoch 0011, iter [00960, 01251], lr: 0.000353, loss: 0.4477
2022-09-21 06:20:35 - train: epoch 0011, iter [00970, 01251], lr: 0.000353, loss: 0.4378
2022-09-21 06:20:56 - train: epoch 0011, iter [00980, 01251], lr: 0.000354, loss: 0.4557
2022-09-21 06:21:17 - train: epoch 0011, iter [00990, 01251], lr: 0.000354, loss: 0.4526
2022-09-21 06:21:38 - train: epoch 0011, iter [01000, 01251], lr: 0.000354, loss: 0.4524
2022-09-21 06:21:59 - train: epoch 0011, iter [01010, 01251], lr: 0.000354, loss: 0.4486
2022-09-21 06:22:20 - train: epoch 0011, iter [01020, 01251], lr: 0.000354, loss: 0.4566
2022-09-21 06:22:41 - train: epoch 0011, iter [01030, 01251], lr: 0.000355, loss: 0.4638
2022-09-21 06:23:03 - train: epoch 0011, iter [01040, 01251], lr: 0.000355, loss: 0.4416
2022-09-21 06:23:25 - train: epoch 0011, iter [01050, 01251], lr: 0.000355, loss: 0.4557
2022-09-21 06:23:46 - train: epoch 0011, iter [01060, 01251], lr: 0.000355, loss: 0.4461
2022-09-21 06:24:07 - train: epoch 0011, iter [01070, 01251], lr: 0.000356, loss: 0.4550
2022-09-21 06:24:28 - train: epoch 0011, iter [01080, 01251], lr: 0.000356, loss: 0.4302
2022-09-21 06:24:49 - train: epoch 0011, iter [01090, 01251], lr: 0.000356, loss: 0.4417
2022-09-21 06:25:10 - train: epoch 0011, iter [01100, 01251], lr: 0.000356, loss: 0.4579
2022-09-21 06:25:32 - train: epoch 0011, iter [01110, 01251], lr: 0.000357, loss: 0.4239
2022-09-21 06:25:52 - train: epoch 0011, iter [01120, 01251], lr: 0.000357, loss: 0.4394
2022-09-21 06:26:14 - train: epoch 0011, iter [01130, 01251], lr: 0.000357, loss: 0.4532
2022-09-21 06:26:35 - train: epoch 0011, iter [01140, 01251], lr: 0.000357, loss: 0.4485
2022-09-21 06:26:56 - train: epoch 0011, iter [01150, 01251], lr: 0.000358, loss: 0.4437
2022-09-21 06:27:17 - train: epoch 0011, iter [01160, 01251], lr: 0.000358, loss: 0.4559
2022-09-21 06:27:38 - train: epoch 0011, iter [01170, 01251], lr: 0.000358, loss: 0.4427
2022-09-21 06:27:59 - train: epoch 0011, iter [01180, 01251], lr: 0.000358, loss: 0.4539
2022-09-21 06:28:20 - train: epoch 0011, iter [01190, 01251], lr: 0.000359, loss: 0.4586
2022-09-21 06:28:41 - train: epoch 0011, iter [01200, 01251], lr: 0.000359, loss: 0.4540
2022-09-21 06:29:02 - train: epoch 0011, iter [01210, 01251], lr: 0.000359, loss: 0.4616
2022-09-21 06:29:23 - train: epoch 0011, iter [01220, 01251], lr: 0.000359, loss: 0.4319
2022-09-21 06:29:44 - train: epoch 0011, iter [01230, 01251], lr: 0.000359, loss: 0.4486
2022-09-21 06:30:05 - train: epoch 0011, iter [01240, 01251], lr: 0.000360, loss: 0.4417
2022-09-21 06:30:26 - train: epoch 0011, iter [01250, 01251], lr: 0.000360, loss: 0.4538
2022-09-21 06:30:30 - train: epoch 011, train_loss: 0.4489
2022-09-21 06:30:36 - until epoch: 011, best_loss: 0.4489
2022-09-21 06:53:25 - epoch 012 lr: 0.000360
2022-09-21 06:54:09 - train: epoch 0012, iter [00010, 01251], lr: 0.000360, loss: 0.4261
2022-09-21 06:54:31 - train: epoch 0012, iter [00020, 01251], lr: 0.000360, loss: 0.4459
2022-09-21 06:54:52 - train: epoch 0012, iter [00030, 01251], lr: 0.000361, loss: 0.4469
2022-09-21 06:55:14 - train: epoch 0012, iter [00040, 01251], lr: 0.000361, loss: 0.4485
2022-09-21 06:55:35 - train: epoch 0012, iter [00050, 01251], lr: 0.000361, loss: 0.4496
2022-09-21 06:55:56 - train: epoch 0012, iter [00060, 01251], lr: 0.000361, loss: 0.4469
2022-09-21 06:56:18 - train: epoch 0012, iter [00070, 01251], lr: 0.000362, loss: 0.4374
2022-09-21 06:56:39 - train: epoch 0012, iter [00080, 01251], lr: 0.000362, loss: 0.4420
2022-09-21 06:57:01 - train: epoch 0012, iter [00090, 01251], lr: 0.000362, loss: 0.4364
2022-09-21 06:57:22 - train: epoch 0012, iter [00100, 01251], lr: 0.000362, loss: 0.4472
2022-09-21 06:57:44 - train: epoch 0012, iter [00110, 01251], lr: 0.000363, loss: 0.4490
2022-09-21 06:58:05 - train: epoch 0012, iter [00120, 01251], lr: 0.000363, loss: 0.4728
2022-09-21 06:58:27 - train: epoch 0012, iter [00130, 01251], lr: 0.000363, loss: 0.4407
2022-09-21 06:58:48 - train: epoch 0012, iter [00140, 01251], lr: 0.000363, loss: 0.4228
2022-09-21 06:59:09 - train: epoch 0012, iter [00150, 01251], lr: 0.000364, loss: 0.4467
2022-09-21 06:59:31 - train: epoch 0012, iter [00160, 01251], lr: 0.000364, loss: 0.4718
2022-09-21 06:59:53 - train: epoch 0012, iter [00170, 01251], lr: 0.000364, loss: 0.4340
2022-09-21 07:00:14 - train: epoch 0012, iter [00180, 01251], lr: 0.000364, loss: 0.4818
2022-09-21 07:00:35 - train: epoch 0012, iter [00190, 01251], lr: 0.000365, loss: 0.4501
2022-09-21 07:00:57 - train: epoch 0012, iter [00200, 01251], lr: 0.000365, loss: 0.4342
2022-09-21 07:01:18 - train: epoch 0012, iter [00210, 01251], lr: 0.000365, loss: 0.4691
2022-09-21 07:01:39 - train: epoch 0012, iter [00220, 01251], lr: 0.000365, loss: 0.4542
2022-09-21 07:02:01 - train: epoch 0012, iter [00230, 01251], lr: 0.000366, loss: 0.4602
2022-09-21 07:02:22 - train: epoch 0012, iter [00240, 01251], lr: 0.000366, loss: 0.4731
2022-09-21 07:02:44 - train: epoch 0012, iter [00250, 01251], lr: 0.000366, loss: 0.4335
2022-09-21 07:03:05 - train: epoch 0012, iter [00260, 01251], lr: 0.000366, loss: 0.4485
2022-09-21 07:03:27 - train: epoch 0012, iter [00270, 01251], lr: 0.000366, loss: 0.4380
2022-09-21 07:03:48 - train: epoch 0012, iter [00280, 01251], lr: 0.000367, loss: 0.4456
2022-09-21 07:04:10 - train: epoch 0012, iter [00290, 01251], lr: 0.000367, loss: 0.4482
2022-09-21 07:04:31 - train: epoch 0012, iter [00300, 01251], lr: 0.000367, loss: 0.4435
2022-09-21 07:04:52 - train: epoch 0012, iter [00310, 01251], lr: 0.000367, loss: 0.4475
2022-09-21 07:05:14 - train: epoch 0012, iter [00320, 01251], lr: 0.000368, loss: 0.4431
2022-09-21 07:05:35 - train: epoch 0012, iter [00330, 01251], lr: 0.000368, loss: 0.4356
2022-09-21 07:05:57 - train: epoch 0012, iter [00340, 01251], lr: 0.000368, loss: 0.4530
2022-09-21 07:06:18 - train: epoch 0012, iter [00350, 01251], lr: 0.000368, loss: 0.4443
2022-09-21 07:06:39 - train: epoch 0012, iter [00360, 01251], lr: 0.000369, loss: 0.4400
2022-09-21 07:07:01 - train: epoch 0012, iter [00370, 01251], lr: 0.000369, loss: 0.4398
2022-09-21 07:07:22 - train: epoch 0012, iter [00380, 01251], lr: 0.000369, loss: 0.4454
2022-09-21 07:07:44 - train: epoch 0012, iter [00390, 01251], lr: 0.000369, loss: 0.4467
2022-09-21 07:08:05 - train: epoch 0012, iter [00400, 01251], lr: 0.000370, loss: 0.4433
2022-09-21 07:08:27 - train: epoch 0012, iter [00410, 01251], lr: 0.000370, loss: 0.4458
2022-09-21 07:08:48 - train: epoch 0012, iter [00420, 01251], lr: 0.000370, loss: 0.4586
2022-09-21 07:09:10 - train: epoch 0012, iter [00430, 01251], lr: 0.000370, loss: 0.4328
2022-09-21 07:09:31 - train: epoch 0012, iter [00440, 01251], lr: 0.000371, loss: 0.4535
2022-09-21 07:09:53 - train: epoch 0012, iter [00450, 01251], lr: 0.000371, loss: 0.4357
2022-09-21 07:10:14 - train: epoch 0012, iter [00460, 01251], lr: 0.000371, loss: 0.4380
2022-09-21 07:10:36 - train: epoch 0012, iter [00470, 01251], lr: 0.000371, loss: 0.4355
2022-09-21 07:10:57 - train: epoch 0012, iter [00480, 01251], lr: 0.000372, loss: 0.4434
2022-09-21 07:11:19 - train: epoch 0012, iter [00490, 01251], lr: 0.000372, loss: 0.4367
2022-09-21 07:11:40 - train: epoch 0012, iter [00500, 01251], lr: 0.000372, loss: 0.4209
2022-09-21 07:12:02 - train: epoch 0012, iter [00510, 01251], lr: 0.000372, loss: 0.4402
2022-09-21 07:12:23 - train: epoch 0012, iter [00520, 01251], lr: 0.000372, loss: 0.4448
2022-09-21 07:12:45 - train: epoch 0012, iter [00530, 01251], lr: 0.000373, loss: 0.4343
2022-09-21 07:13:06 - train: epoch 0012, iter [00540, 01251], lr: 0.000373, loss: 0.4467
2022-09-21 07:13:28 - train: epoch 0012, iter [00550, 01251], lr: 0.000373, loss: 0.4540
2022-09-21 07:13:49 - train: epoch 0012, iter [00560, 01251], lr: 0.000373, loss: 0.4358
2022-09-21 07:14:11 - train: epoch 0012, iter [00570, 01251], lr: 0.000374, loss: 0.4455
2022-09-21 07:14:32 - train: epoch 0012, iter [00580, 01251], lr: 0.000374, loss: 0.4662
2022-09-21 07:14:53 - train: epoch 0012, iter [00590, 01251], lr: 0.000374, loss: 0.4712
2022-09-21 07:15:15 - train: epoch 0012, iter [00600, 01251], lr: 0.000374, loss: 0.4580
2022-09-21 07:15:36 - train: epoch 0012, iter [00610, 01251], lr: 0.000375, loss: 0.4225
2022-09-21 07:15:57 - train: epoch 0012, iter [00620, 01251], lr: 0.000375, loss: 0.4485
2022-09-21 07:16:19 - train: epoch 0012, iter [00630, 01251], lr: 0.000375, loss: 0.4273
2022-09-21 07:16:40 - train: epoch 0012, iter [00640, 01251], lr: 0.000375, loss: 0.4283
2022-09-21 07:17:02 - train: epoch 0012, iter [00650, 01251], lr: 0.000376, loss: 0.4605
2022-09-21 07:17:23 - train: epoch 0012, iter [00660, 01251], lr: 0.000376, loss: 0.4251
2022-09-21 07:17:44 - train: epoch 0012, iter [00670, 01251], lr: 0.000376, loss: 0.4499
2022-09-21 07:18:06 - train: epoch 0012, iter [00680, 01251], lr: 0.000376, loss: 0.4557
2022-09-21 07:18:27 - train: epoch 0012, iter [00690, 01251], lr: 0.000377, loss: 0.4521
2022-09-21 07:18:49 - train: epoch 0012, iter [00700, 01251], lr: 0.000377, loss: 0.4278
2022-09-21 07:19:10 - train: epoch 0012, iter [00710, 01251], lr: 0.000377, loss: 0.4417
2022-09-21 07:19:31 - train: epoch 0012, iter [00720, 01251], lr: 0.000377, loss: 0.4331
2022-09-21 07:19:53 - train: epoch 0012, iter [00730, 01251], lr: 0.000378, loss: 0.4358
2022-09-21 07:20:14 - train: epoch 0012, iter [00740, 01251], lr: 0.000378, loss: 0.4246
2022-09-21 07:20:35 - train: epoch 0012, iter [00750, 01251], lr: 0.000378, loss: 0.4297
2022-09-21 07:20:57 - train: epoch 0012, iter [00760, 01251], lr: 0.000378, loss: 0.4522
2022-09-21 07:21:18 - train: epoch 0012, iter [00770, 01251], lr: 0.000378, loss: 0.4335
2022-09-21 07:21:39 - train: epoch 0012, iter [00780, 01251], lr: 0.000379, loss: 0.4389
2022-09-21 07:22:01 - train: epoch 0012, iter [00790, 01251], lr: 0.000379, loss: 0.4493
2022-09-21 07:22:22 - train: epoch 0012, iter [00800, 01251], lr: 0.000379, loss: 0.4432
2022-09-21 07:22:44 - train: epoch 0012, iter [00810, 01251], lr: 0.000379, loss: 0.4632
2022-09-21 07:23:05 - train: epoch 0012, iter [00820, 01251], lr: 0.000380, loss: 0.4452
2022-09-21 07:23:27 - train: epoch 0012, iter [00830, 01251], lr: 0.000380, loss: 0.4433
2022-09-21 07:23:48 - train: epoch 0012, iter [00840, 01251], lr: 0.000380, loss: 0.4566
2022-09-21 07:24:09 - train: epoch 0012, iter [00850, 01251], lr: 0.000380, loss: 0.4283
2022-09-21 07:24:31 - train: epoch 0012, iter [00860, 01251], lr: 0.000381, loss: 0.4523
2022-09-21 07:24:52 - train: epoch 0012, iter [00870, 01251], lr: 0.000381, loss: 0.4420
2022-09-21 07:25:14 - train: epoch 0012, iter [00880, 01251], lr: 0.000381, loss: 0.4350
2022-09-21 07:25:35 - train: epoch 0012, iter [00890, 01251], lr: 0.000381, loss: 0.4616
2022-09-21 07:25:57 - train: epoch 0012, iter [00900, 01251], lr: 0.000382, loss: 0.4296
2022-09-21 07:26:18 - train: epoch 0012, iter [00910, 01251], lr: 0.000382, loss: 0.4439
2022-09-21 07:26:40 - train: epoch 0012, iter [00920, 01251], lr: 0.000382, loss: 0.4423
2022-09-21 07:27:01 - train: epoch 0012, iter [00930, 01251], lr: 0.000382, loss: 0.4448
2022-09-21 07:27:22 - train: epoch 0012, iter [00940, 01251], lr: 0.000383, loss: 0.4643
2022-09-21 07:27:44 - train: epoch 0012, iter [00950, 01251], lr: 0.000383, loss: 0.4399
2022-09-21 07:28:05 - train: epoch 0012, iter [00960, 01251], lr: 0.000383, loss: 0.4590
2022-09-21 07:28:27 - train: epoch 0012, iter [00970, 01251], lr: 0.000383, loss: 0.4461
2022-09-21 07:28:48 - train: epoch 0012, iter [00980, 01251], lr: 0.000384, loss: 0.4499
2022-09-21 07:29:10 - train: epoch 0012, iter [00990, 01251], lr: 0.000384, loss: 0.4615
2022-09-21 07:29:31 - train: epoch 0012, iter [01000, 01251], lr: 0.000384, loss: 0.4530
2022-09-21 07:29:53 - train: epoch 0012, iter [01010, 01251], lr: 0.000384, loss: 0.4518
2022-09-21 07:30:14 - train: epoch 0012, iter [01020, 01251], lr: 0.000384, loss: 0.4361
2022-09-21 07:30:36 - train: epoch 0012, iter [01030, 01251], lr: 0.000385, loss: 0.4635
2022-09-21 07:30:57 - train: epoch 0012, iter [01040, 01251], lr: 0.000385, loss: 0.4244
2022-09-21 07:31:19 - train: epoch 0012, iter [01050, 01251], lr: 0.000385, loss: 0.4465
2022-09-21 07:31:40 - train: epoch 0012, iter [01060, 01251], lr: 0.000385, loss: 0.4369
2022-09-21 07:32:01 - train: epoch 0012, iter [01070, 01251], lr: 0.000386, loss: 0.4507
2022-09-21 07:32:23 - train: epoch 0012, iter [01080, 01251], lr: 0.000386, loss: 0.4347
2022-09-21 07:32:44 - train: epoch 0012, iter [01090, 01251], lr: 0.000386, loss: 0.4390
2022-09-21 07:33:06 - train: epoch 0012, iter [01100, 01251], lr: 0.000386, loss: 0.4494
2022-09-21 07:33:27 - train: epoch 0012, iter [01110, 01251], lr: 0.000387, loss: 0.4600
2022-09-21 07:33:49 - train: epoch 0012, iter [01120, 01251], lr: 0.000387, loss: 0.4373
2022-09-21 07:34:10 - train: epoch 0012, iter [01130, 01251], lr: 0.000387, loss: 0.4347
2022-09-21 07:34:31 - train: epoch 0012, iter [01140, 01251], lr: 0.000387, loss: 0.4451
2022-09-21 07:34:53 - train: epoch 0012, iter [01150, 01251], lr: 0.000388, loss: 0.4455
2022-09-21 07:35:15 - train: epoch 0012, iter [01160, 01251], lr: 0.000388, loss: 0.4576
2022-09-21 07:35:36 - train: epoch 0012, iter [01170, 01251], lr: 0.000388, loss: 0.4516
2022-09-21 07:35:58 - train: epoch 0012, iter [01180, 01251], lr: 0.000388, loss: 0.4247
2022-09-21 07:36:19 - train: epoch 0012, iter [01190, 01251], lr: 0.000389, loss: 0.4303
2022-09-21 07:36:40 - train: epoch 0012, iter [01200, 01251], lr: 0.000389, loss: 0.4591
2022-09-21 07:37:02 - train: epoch 0012, iter [01210, 01251], lr: 0.000389, loss: 0.4562
2022-09-21 07:37:23 - train: epoch 0012, iter [01220, 01251], lr: 0.000389, loss: 0.4461
2022-09-21 07:37:45 - train: epoch 0012, iter [01230, 01251], lr: 0.000389, loss: 0.4559
2022-09-21 07:38:06 - train: epoch 0012, iter [01240, 01251], lr: 0.000390, loss: 0.4435
2022-09-21 07:38:27 - train: epoch 0012, iter [01250, 01251], lr: 0.000390, loss: 0.4445
2022-09-21 07:38:32 - train: epoch 012, train_loss: 0.4459
2022-09-21 07:38:38 - until epoch: 012, best_loss: 0.4459
2022-09-21 07:38:38 - epoch 013 lr: 0.000390
2022-09-21 07:39:15 - train: epoch 0013, iter [00010, 01251], lr: 0.000390, loss: 0.4424
2022-09-21 07:39:37 - train: epoch 0013, iter [00020, 01251], lr: 0.000390, loss: 0.4595
2022-09-21 07:39:58 - train: epoch 0013, iter [00030, 01251], lr: 0.000391, loss: 0.4627
2022-09-21 07:40:19 - train: epoch 0013, iter [00040, 01251], lr: 0.000391, loss: 0.4285
2022-09-21 07:40:40 - train: epoch 0013, iter [00050, 01251], lr: 0.000391, loss: 0.4655
2022-09-21 07:41:02 - train: epoch 0013, iter [00060, 01251], lr: 0.000391, loss: 0.4415
2022-09-21 07:41:23 - train: epoch 0013, iter [00070, 01251], lr: 0.000392, loss: 0.4400
2022-09-21 07:41:44 - train: epoch 0013, iter [00080, 01251], lr: 0.000392, loss: 0.4426
2022-09-21 07:42:05 - train: epoch 0013, iter [00090, 01251], lr: 0.000392, loss: 0.4669
2022-09-21 07:42:26 - train: epoch 0013, iter [00100, 01251], lr: 0.000392, loss: 0.4408
2022-09-21 07:42:48 - train: epoch 0013, iter [00110, 01251], lr: 0.000393, loss: 0.4475
2022-09-21 07:43:09 - train: epoch 0013, iter [00120, 01251], lr: 0.000393, loss: 0.4433
2022-09-21 07:43:30 - train: epoch 0013, iter [00130, 01251], lr: 0.000393, loss: 0.4369
2022-09-21 07:43:51 - train: epoch 0013, iter [00140, 01251], lr: 0.000393, loss: 0.4376
2022-09-21 07:44:13 - train: epoch 0013, iter [00150, 01251], lr: 0.000394, loss: 0.4442
2022-09-21 07:44:34 - train: epoch 0013, iter [00160, 01251], lr: 0.000394, loss: 0.4304
2022-09-21 07:44:55 - train: epoch 0013, iter [00170, 01251], lr: 0.000394, loss: 0.4411
2022-09-21 07:45:16 - train: epoch 0013, iter [00180, 01251], lr: 0.000394, loss: 0.4413
2022-09-21 07:45:38 - train: epoch 0013, iter [00190, 01251], lr: 0.000395, loss: 0.4434
2022-09-21 07:45:59 - train: epoch 0013, iter [00200, 01251], lr: 0.000395, loss: 0.4468
2022-09-21 07:46:20 - train: epoch 0013, iter [00210, 01251], lr: 0.000395, loss: 0.4388
2022-09-21 07:46:41 - train: epoch 0013, iter [00220, 01251], lr: 0.000395, loss: 0.4410
2022-09-21 07:47:02 - train: epoch 0013, iter [00230, 01251], lr: 0.000396, loss: 0.4576
2022-09-21 07:47:24 - train: epoch 0013, iter [00240, 01251], lr: 0.000396, loss: 0.4324
2022-09-21 07:47:45 - train: epoch 0013, iter [00250, 01251], lr: 0.000396, loss: 0.4504
2022-09-21 07:48:06 - train: epoch 0013, iter [00260, 01251], lr: 0.000396, loss: 0.4304
2022-09-21 07:48:27 - train: epoch 0013, iter [00270, 01251], lr: 0.000396, loss: 0.4489
2022-09-21 07:48:48 - train: epoch 0013, iter [00280, 01251], lr: 0.000397, loss: 0.4470
2022-09-21 07:49:09 - train: epoch 0013, iter [00290, 01251], lr: 0.000397, loss: 0.4565
2022-09-21 07:49:30 - train: epoch 0013, iter [00300, 01251], lr: 0.000397, loss: 0.4406
2022-09-21 07:49:52 - train: epoch 0013, iter [00310, 01251], lr: 0.000397, loss: 0.4630
2022-09-21 07:50:13 - train: epoch 0013, iter [00320, 01251], lr: 0.000398, loss: 0.4433
2022-09-21 07:50:34 - train: epoch 0013, iter [00330, 01251], lr: 0.000398, loss: 0.4374
2022-09-21 07:50:56 - train: epoch 0013, iter [00340, 01251], lr: 0.000398, loss: 0.4394
2022-09-21 07:51:17 - train: epoch 0013, iter [00350, 01251], lr: 0.000398, loss: 0.4571
2022-09-21 07:51:38 - train: epoch 0013, iter [00360, 01251], lr: 0.000399, loss: 0.4436
2022-09-21 07:51:59 - train: epoch 0013, iter [00370, 01251], lr: 0.000399, loss: 0.4467
2022-09-21 07:52:20 - train: epoch 0013, iter [00380, 01251], lr: 0.000399, loss: 0.4299
2022-09-21 07:52:41 - train: epoch 0013, iter [00390, 01251], lr: 0.000399, loss: 0.4419
2022-09-21 07:53:02 - train: epoch 0013, iter [00400, 01251], lr: 0.000400, loss: 0.4371
2022-09-21 07:53:24 - train: epoch 0013, iter [00410, 01251], lr: 0.000400, loss: 0.4355
2022-09-21 07:53:45 - train: epoch 0013, iter [00420, 01251], lr: 0.000400, loss: 0.4493
2022-09-21 07:54:06 - train: epoch 0013, iter [00430, 01251], lr: 0.000400, loss: 0.4284
2022-09-21 07:54:28 - train: epoch 0013, iter [00440, 01251], lr: 0.000401, loss: 0.4489
2022-09-21 07:54:49 - train: epoch 0013, iter [00450, 01251], lr: 0.000401, loss: 0.4448
2022-09-21 07:55:10 - train: epoch 0013, iter [00460, 01251], lr: 0.000401, loss: 0.4391
2022-09-21 07:55:31 - train: epoch 0013, iter [00470, 01251], lr: 0.000401, loss: 0.4250
2022-09-21 07:55:52 - train: epoch 0013, iter [00480, 01251], lr: 0.000402, loss: 0.4382
2022-09-21 07:56:14 - train: epoch 0013, iter [00490, 01251], lr: 0.000402, loss: 0.4531
2022-09-21 07:56:35 - train: epoch 0013, iter [00500, 01251], lr: 0.000402, loss: 0.4511
2022-09-21 07:56:57 - train: epoch 0013, iter [00510, 01251], lr: 0.000402, loss: 0.4598
2022-09-21 07:57:18 - train: epoch 0013, iter [00520, 01251], lr: 0.000402, loss: 0.4495
2022-09-21 07:57:39 - train: epoch 0013, iter [00530, 01251], lr: 0.000403, loss: 0.4405
2022-09-21 07:58:01 - train: epoch 0013, iter [00540, 01251], lr: 0.000403, loss: 0.4392
2022-09-21 07:58:22 - train: epoch 0013, iter [00550, 01251], lr: 0.000403, loss: 0.4500
2022-09-21 07:58:43 - train: epoch 0013, iter [00560, 01251], lr: 0.000403, loss: 0.4342
2022-09-21 07:59:04 - train: epoch 0013, iter [00570, 01251], lr: 0.000404, loss: 0.4608
2022-09-21 07:59:26 - train: epoch 0013, iter [00580, 01251], lr: 0.000404, loss: 0.4256
2022-09-21 07:59:47 - train: epoch 0013, iter [00590, 01251], lr: 0.000404, loss: 0.4350
2022-09-21 08:00:09 - train: epoch 0013, iter [00600, 01251], lr: 0.000404, loss: 0.4683
2022-09-21 08:00:30 - train: epoch 0013, iter [00610, 01251], lr: 0.000405, loss: 0.4284
2022-09-21 08:00:51 - train: epoch 0013, iter [00620, 01251], lr: 0.000405, loss: 0.4360
2022-09-21 08:01:12 - train: epoch 0013, iter [00630, 01251], lr: 0.000405, loss: 0.4504
2022-09-21 08:01:33 - train: epoch 0013, iter [00640, 01251], lr: 0.000405, loss: 0.4613
2022-09-21 08:01:55 - train: epoch 0013, iter [00650, 01251], lr: 0.000406, loss: 0.4474
2022-09-21 08:02:16 - train: epoch 0013, iter [00660, 01251], lr: 0.000406, loss: 0.4512
2022-09-21 08:02:38 - train: epoch 0013, iter [00670, 01251], lr: 0.000406, loss: 0.4533
2022-09-21 08:02:59 - train: epoch 0013, iter [00680, 01251], lr: 0.000406, loss: 0.4579
2022-09-21 08:03:20 - train: epoch 0013, iter [00690, 01251], lr: 0.000407, loss: 0.4394
2022-09-21 08:03:41 - train: epoch 0013, iter [00700, 01251], lr: 0.000407, loss: 0.4495
2022-09-21 08:04:03 - train: epoch 0013, iter [00710, 01251], lr: 0.000407, loss: 0.4366
2022-09-21 08:04:24 - train: epoch 0013, iter [00720, 01251], lr: 0.000407, loss: 0.4392
2022-09-21 08:04:45 - train: epoch 0013, iter [00730, 01251], lr: 0.000408, loss: 0.4376
2022-09-21 08:05:06 - train: epoch 0013, iter [00740, 01251], lr: 0.000408, loss: 0.4512
2022-09-21 08:05:28 - train: epoch 0013, iter [00750, 01251], lr: 0.000408, loss: 0.4389
2022-09-21 08:05:49 - train: epoch 0013, iter [00760, 01251], lr: 0.000408, loss: 0.4390
2022-09-21 08:06:11 - train: epoch 0013, iter [00770, 01251], lr: 0.000408, loss: 0.4407
2022-09-21 08:06:32 - train: epoch 0013, iter [00780, 01251], lr: 0.000409, loss: 0.4478
2022-09-21 08:06:53 - train: epoch 0013, iter [00790, 01251], lr: 0.000409, loss: 0.4415
2022-09-21 08:07:15 - train: epoch 0013, iter [00800, 01251], lr: 0.000409, loss: 0.4523
2022-09-21 08:07:36 - train: epoch 0013, iter [00810, 01251], lr: 0.000409, loss: 0.4351
2022-09-21 08:07:57 - train: epoch 0013, iter [00820, 01251], lr: 0.000410, loss: 0.4555
2022-09-21 08:08:19 - train: epoch 0013, iter [00830, 01251], lr: 0.000410, loss: 0.4462
2022-09-21 08:08:40 - train: epoch 0013, iter [00840, 01251], lr: 0.000410, loss: 0.4389
2022-09-21 08:09:01 - train: epoch 0013, iter [00850, 01251], lr: 0.000410, loss: 0.4321
2022-09-21 08:09:22 - train: epoch 0013, iter [00860, 01251], lr: 0.000411, loss: 0.4321
2022-09-21 08:09:44 - train: epoch 0013, iter [00870, 01251], lr: 0.000411, loss: 0.4348
2022-09-21 08:10:05 - train: epoch 0013, iter [00880, 01251], lr: 0.000411, loss: 0.4341
2022-09-21 08:10:26 - train: epoch 0013, iter [00890, 01251], lr: 0.000411, loss: 0.4578
2022-09-21 08:10:48 - train: epoch 0013, iter [00900, 01251], lr: 0.000412, loss: 0.4512
2022-09-21 08:11:09 - train: epoch 0013, iter [00910, 01251], lr: 0.000412, loss: 0.4344
2022-09-21 08:11:30 - train: epoch 0013, iter [00920, 01251], lr: 0.000412, loss: 0.4472
2022-09-21 08:11:52 - train: epoch 0013, iter [00930, 01251], lr: 0.000412, loss: 0.4417
2022-09-21 08:12:13 - train: epoch 0013, iter [00940, 01251], lr: 0.000413, loss: 0.4453
2022-09-21 08:12:34 - train: epoch 0013, iter [00950, 01251], lr: 0.000413, loss: 0.4274
2022-09-21 08:12:55 - train: epoch 0013, iter [00960, 01251], lr: 0.000413, loss: 0.4284
2022-09-21 08:13:17 - train: epoch 0013, iter [00970, 01251], lr: 0.000413, loss: 0.4381
2022-09-21 08:13:38 - train: epoch 0013, iter [00980, 01251], lr: 0.000414, loss: 0.4481
2022-09-21 08:13:59 - train: epoch 0013, iter [00990, 01251], lr: 0.000414, loss: 0.4380
2022-09-21 08:14:21 - train: epoch 0013, iter [01000, 01251], lr: 0.000414, loss: 0.4398
2022-09-21 08:14:42 - train: epoch 0013, iter [01010, 01251], lr: 0.000414, loss: 0.4360
2022-09-21 08:15:03 - train: epoch 0013, iter [01020, 01251], lr: 0.000414, loss: 0.4352
2022-09-21 08:15:24 - train: epoch 0013, iter [01030, 01251], lr: 0.000415, loss: 0.4607
2022-09-21 08:15:46 - train: epoch 0013, iter [01040, 01251], lr: 0.000415, loss: 0.4371
2022-09-21 08:16:07 - train: epoch 0013, iter [01050, 01251], lr: 0.000415, loss: 0.4306
2022-09-21 08:16:29 - train: epoch 0013, iter [01060, 01251], lr: 0.000415, loss: 0.4455
2022-09-21 08:16:50 - train: epoch 0013, iter [01070, 01251], lr: 0.000416, loss: 0.4373
2022-09-21 08:17:11 - train: epoch 0013, iter [01080, 01251], lr: 0.000416, loss: 0.4391
2022-09-21 08:17:32 - train: epoch 0013, iter [01090, 01251], lr: 0.000416, loss: 0.4225
2022-09-21 08:17:54 - train: epoch 0013, iter [01100, 01251], lr: 0.000416, loss: 0.4686
2022-09-21 08:18:15 - train: epoch 0013, iter [01110, 01251], lr: 0.000417, loss: 0.4700
2022-09-21 08:18:36 - train: epoch 0013, iter [01120, 01251], lr: 0.000417, loss: 0.4322
2022-09-21 08:18:58 - train: epoch 0013, iter [01130, 01251], lr: 0.000417, loss: 0.4446
2022-09-21 08:19:19 - train: epoch 0013, iter [01140, 01251], lr: 0.000417, loss: 0.4524
2022-09-21 08:19:40 - train: epoch 0013, iter [01150, 01251], lr: 0.000418, loss: 0.4373
2022-09-21 08:20:02 - train: epoch 0013, iter [01160, 01251], lr: 0.000418, loss: 0.4404
2022-09-21 08:20:23 - train: epoch 0013, iter [01170, 01251], lr: 0.000418, loss: 0.4590
2022-09-21 08:20:44 - train: epoch 0013, iter [01180, 01251], lr: 0.000418, loss: 0.4404
2022-09-21 08:21:06 - train: epoch 0013, iter [01190, 01251], lr: 0.000419, loss: 0.4332
2022-09-21 08:21:27 - train: epoch 0013, iter [01200, 01251], lr: 0.000419, loss: 0.4436
2022-09-21 08:21:48 - train: epoch 0013, iter [01210, 01251], lr: 0.000419, loss: 0.4158
2022-09-21 08:22:10 - train: epoch 0013, iter [01220, 01251], lr: 0.000419, loss: 0.4480
2022-09-21 08:22:31 - train: epoch 0013, iter [01230, 01251], lr: 0.000419, loss: 0.4193
2022-09-21 08:22:52 - train: epoch 0013, iter [01240, 01251], lr: 0.000420, loss: 0.4570
2022-09-21 08:23:13 - train: epoch 0013, iter [01250, 01251], lr: 0.000420, loss: 0.4427
2022-09-21 08:23:18 - train: epoch 013, train_loss: 0.4432
2022-09-21 08:23:24 - until epoch: 013, best_loss: 0.4432
2022-09-21 08:23:24 - epoch 014 lr: 0.000420
2022-09-21 08:24:02 - train: epoch 0014, iter [00010, 01251], lr: 0.000420, loss: 0.4394
2022-09-21 08:24:23 - train: epoch 0014, iter [00020, 01251], lr: 0.000420, loss: 0.4446
2022-09-21 08:24:44 - train: epoch 0014, iter [00030, 01251], lr: 0.000421, loss: 0.4517
2022-09-21 08:25:06 - train: epoch 0014, iter [00040, 01251], lr: 0.000421, loss: 0.4399
2022-09-21 08:25:27 - train: epoch 0014, iter [00050, 01251], lr: 0.000421, loss: 0.4528
2022-09-21 08:25:48 - train: epoch 0014, iter [00060, 01251], lr: 0.000421, loss: 0.4379
2022-09-21 08:26:09 - train: epoch 0014, iter [00070, 01251], lr: 0.000422, loss: 0.4542
2022-09-21 08:26:31 - train: epoch 0014, iter [00080, 01251], lr: 0.000422, loss: 0.4295
2022-09-21 08:26:52 - train: epoch 0014, iter [00090, 01251], lr: 0.000422, loss: 0.4366
2022-09-21 08:27:13 - train: epoch 0014, iter [00100, 01251], lr: 0.000422, loss: 0.4191
2022-09-21 08:27:34 - train: epoch 0014, iter [00110, 01251], lr: 0.000423, loss: 0.4282
2022-09-21 08:27:56 - train: epoch 0014, iter [00120, 01251], lr: 0.000423, loss: 0.4436
2022-09-21 08:28:17 - train: epoch 0014, iter [00130, 01251], lr: 0.000423, loss: 0.4429
2022-09-21 08:28:38 - train: epoch 0014, iter [00140, 01251], lr: 0.000423, loss: 0.4286
2022-09-21 08:28:59 - train: epoch 0014, iter [00150, 01251], lr: 0.000424, loss: 0.4342
2022-09-21 08:29:21 - train: epoch 0014, iter [00160, 01251], lr: 0.000424, loss: 0.4455
2022-09-21 08:29:41 - train: epoch 0014, iter [00170, 01251], lr: 0.000424, loss: 0.4548
2022-09-21 08:30:02 - train: epoch 0014, iter [00180, 01251], lr: 0.000424, loss: 0.4533
2022-09-21 08:30:24 - train: epoch 0014, iter [00190, 01251], lr: 0.000425, loss: 0.4348
2022-09-21 08:30:45 - train: epoch 0014, iter [00200, 01251], lr: 0.000425, loss: 0.4307
2022-09-21 08:31:06 - train: epoch 0014, iter [00210, 01251], lr: 0.000425, loss: 0.4325
2022-09-21 08:31:28 - train: epoch 0014, iter [00220, 01251], lr: 0.000425, loss: 0.4483
2022-09-21 08:31:49 - train: epoch 0014, iter [00230, 01251], lr: 0.000426, loss: 0.4411
2022-09-21 08:32:10 - train: epoch 0014, iter [00240, 01251], lr: 0.000426, loss: 0.4425
2022-09-21 08:32:32 - train: epoch 0014, iter [00250, 01251], lr: 0.000426, loss: 0.4392
2022-09-21 08:32:53 - train: epoch 0014, iter [00260, 01251], lr: 0.000426, loss: 0.4505
2022-09-21 08:33:14 - train: epoch 0014, iter [00270, 01251], lr: 0.000426, loss: 0.4432
2022-09-21 08:33:35 - train: epoch 0014, iter [00280, 01251], lr: 0.000427, loss: 0.4543
2022-09-21 08:33:57 - train: epoch 0014, iter [00290, 01251], lr: 0.000427, loss: 0.4449
2022-09-21 08:34:18 - train: epoch 0014, iter [00300, 01251], lr: 0.000427, loss: 0.4248
2022-09-21 08:34:39 - train: epoch 0014, iter [00310, 01251], lr: 0.000427, loss: 0.4351
2022-09-21 08:35:01 - train: epoch 0014, iter [00320, 01251], lr: 0.000428, loss: 0.4358
2022-09-21 08:35:22 - train: epoch 0014, iter [00330, 01251], lr: 0.000428, loss: 0.4285
2022-09-21 08:35:43 - train: epoch 0014, iter [00340, 01251], lr: 0.000428, loss: 0.4559
2022-09-21 08:36:05 - train: epoch 0014, iter [00350, 01251], lr: 0.000428, loss: 0.4360
2022-09-21 08:36:26 - train: epoch 0014, iter [00360, 01251], lr: 0.000429, loss: 0.4487
2022-09-21 08:36:47 - train: epoch 0014, iter [00370, 01251], lr: 0.000429, loss: 0.4333
2022-09-21 08:37:09 - train: epoch 0014, iter [00380, 01251], lr: 0.000429, loss: 0.4498
2022-09-21 08:37:30 - train: epoch 0014, iter [00390, 01251], lr: 0.000429, loss: 0.4653
2022-09-21 08:37:51 - train: epoch 0014, iter [00400, 01251], lr: 0.000430, loss: 0.4382
2022-09-21 08:38:12 - train: epoch 0014, iter [00410, 01251], lr: 0.000430, loss: 0.4316
2022-09-21 08:38:34 - train: epoch 0014, iter [00420, 01251], lr: 0.000430, loss: 0.4482
2022-09-21 08:38:55 - train: epoch 0014, iter [00430, 01251], lr: 0.000430, loss: 0.4391
2022-09-21 08:39:16 - train: epoch 0014, iter [00440, 01251], lr: 0.000431, loss: 0.4402
2022-09-21 08:39:38 - train: epoch 0014, iter [00450, 01251], lr: 0.000431, loss: 0.4360
2022-09-21 08:39:59 - train: epoch 0014, iter [00460, 01251], lr: 0.000431, loss: 0.4334
2022-09-21 08:40:20 - train: epoch 0014, iter [00470, 01251], lr: 0.000431, loss: 0.4449
2022-09-21 08:40:41 - train: epoch 0014, iter [00480, 01251], lr: 0.000432, loss: 0.4301
2022-09-21 08:41:03 - train: epoch 0014, iter [00490, 01251], lr: 0.000432, loss: 0.4446
2022-09-21 08:41:24 - train: epoch 0014, iter [00500, 01251], lr: 0.000432, loss: 0.4422
2022-09-21 08:41:45 - train: epoch 0014, iter [00510, 01251], lr: 0.000432, loss: 0.4439
2022-09-21 08:42:07 - train: epoch 0014, iter [00520, 01251], lr: 0.000432, loss: 0.4516
2022-09-21 08:42:28 - train: epoch 0014, iter [00530, 01251], lr: 0.000433, loss: 0.4480
2022-09-21 08:42:49 - train: epoch 0014, iter [00540, 01251], lr: 0.000433, loss: 0.4418
2022-09-21 08:43:10 - train: epoch 0014, iter [00550, 01251], lr: 0.000433, loss: 0.4481
2022-09-21 08:43:31 - train: epoch 0014, iter [00560, 01251], lr: 0.000433, loss: 0.4264
2022-09-21 08:43:52 - train: epoch 0014, iter [00570, 01251], lr: 0.000434, loss: 0.4359
2022-09-21 08:44:14 - train: epoch 0014, iter [00580, 01251], lr: 0.000434, loss: 0.4458
2022-09-21 08:44:36 - train: epoch 0014, iter [00590, 01251], lr: 0.000434, loss: 0.4635
2022-09-21 08:44:57 - train: epoch 0014, iter [00600, 01251], lr: 0.000434, loss: 0.4394
2022-09-21 08:45:18 - train: epoch 0014, iter [00610, 01251], lr: 0.000435, loss: 0.4272
2022-09-21 08:45:39 - train: epoch 0014, iter [00620, 01251], lr: 0.000435, loss: 0.4573
2022-09-21 08:46:00 - train: epoch 0014, iter [00630, 01251], lr: 0.000435, loss: 0.4319
2022-09-21 08:46:21 - train: epoch 0014, iter [00640, 01251], lr: 0.000435, loss: 0.4540
2022-09-21 08:46:42 - train: epoch 0014, iter [00650, 01251], lr: 0.000436, loss: 0.4320
2022-09-21 08:47:03 - train: epoch 0014, iter [00660, 01251], lr: 0.000436, loss: 0.4282
2022-09-21 08:47:24 - train: epoch 0014, iter [00670, 01251], lr: 0.000436, loss: 0.4496
2022-09-21 08:47:45 - train: epoch 0014, iter [00680, 01251], lr: 0.000436, loss: 0.4451
2022-09-21 08:48:07 - train: epoch 0014, iter [00690, 01251], lr: 0.000437, loss: 0.4385
2022-09-21 08:48:28 - train: epoch 0014, iter [00700, 01251], lr: 0.000437, loss: 0.4191
2022-09-21 08:48:49 - train: epoch 0014, iter [00710, 01251], lr: 0.000437, loss: 0.4437
2022-09-21 08:49:10 - train: epoch 0014, iter [00720, 01251], lr: 0.000437, loss: 0.4442
2022-09-21 08:49:31 - train: epoch 0014, iter [00730, 01251], lr: 0.000438, loss: 0.4412
2022-09-21 08:49:52 - train: epoch 0014, iter [00740, 01251], lr: 0.000438, loss: 0.4454
2022-09-21 08:50:13 - train: epoch 0014, iter [00750, 01251], lr: 0.000438, loss: 0.4645
2022-09-21 08:50:34 - train: epoch 0014, iter [00760, 01251], lr: 0.000438, loss: 0.4304
2022-09-21 08:50:55 - train: epoch 0014, iter [00770, 01251], lr: 0.000438, loss: 0.4482
2022-09-21 08:51:16 - train: epoch 0014, iter [00780, 01251], lr: 0.000439, loss: 0.4368
2022-09-21 08:51:37 - train: epoch 0014, iter [00790, 01251], lr: 0.000439, loss: 0.4313
2022-09-21 08:51:58 - train: epoch 0014, iter [00800, 01251], lr: 0.000439, loss: 0.4372
2022-09-21 08:52:20 - train: epoch 0014, iter [00810, 01251], lr: 0.000439, loss: 0.4469
2022-09-21 08:52:41 - train: epoch 0014, iter [00820, 01251], lr: 0.000440, loss: 0.4469
2022-09-21 08:53:02 - train: epoch 0014, iter [00830, 01251], lr: 0.000440, loss: 0.4400
2022-09-21 08:53:23 - train: epoch 0014, iter [00840, 01251], lr: 0.000440, loss: 0.4352
2022-09-21 08:53:44 - train: epoch 0014, iter [00850, 01251], lr: 0.000440, loss: 0.4450
2022-09-21 08:54:05 - train: epoch 0014, iter [00860, 01251], lr: 0.000441, loss: 0.4516
2022-09-21 08:54:26 - train: epoch 0014, iter [00870, 01251], lr: 0.000441, loss: 0.4053
2022-09-21 08:54:47 - train: epoch 0014, iter [00880, 01251], lr: 0.000441, loss: 0.4471
2022-09-21 08:55:09 - train: epoch 0014, iter [00890, 01251], lr: 0.000441, loss: 0.4493
2022-09-21 08:55:30 - train: epoch 0014, iter [00900, 01251], lr: 0.000442, loss: 0.4610
2022-09-21 08:55:51 - train: epoch 0014, iter [00910, 01251], lr: 0.000442, loss: 0.4477
2022-09-21 08:56:12 - train: epoch 0014, iter [00920, 01251], lr: 0.000442, loss: 0.4534
2022-09-21 08:56:33 - train: epoch 0014, iter [00930, 01251], lr: 0.000442, loss: 0.4461
2022-09-21 08:56:54 - train: epoch 0014, iter [00940, 01251], lr: 0.000443, loss: 0.4407
2022-09-21 08:57:15 - train: epoch 0014, iter [00950, 01251], lr: 0.000443, loss: 0.4288
2022-09-21 08:57:37 - train: epoch 0014, iter [00960, 01251], lr: 0.000443, loss: 0.4455
2022-09-21 08:57:58 - train: epoch 0014, iter [00970, 01251], lr: 0.000443, loss: 0.4409
2022-09-21 08:58:19 - train: epoch 0014, iter [00980, 01251], lr: 0.000444, loss: 0.4527
2022-09-21 08:58:40 - train: epoch 0014, iter [00990, 01251], lr: 0.000444, loss: 0.4350
2022-09-21 08:59:01 - train: epoch 0014, iter [01000, 01251], lr: 0.000444, loss: 0.4472
2022-09-21 08:59:23 - train: epoch 0014, iter [01010, 01251], lr: 0.000444, loss: 0.4388
2022-09-21 08:59:44 - train: epoch 0014, iter [01020, 01251], lr: 0.000444, loss: 0.4337
2022-09-21 09:00:05 - train: epoch 0014, iter [01030, 01251], lr: 0.000445, loss: 0.4293
2022-09-21 09:00:27 - train: epoch 0014, iter [01040, 01251], lr: 0.000445, loss: 0.4426
2022-09-21 09:00:48 - train: epoch 0014, iter [01050, 01251], lr: 0.000445, loss: 0.4330
2022-09-21 09:01:09 - train: epoch 0014, iter [01060, 01251], lr: 0.000445, loss: 0.4479
2022-09-21 09:01:30 - train: epoch 0014, iter [01070, 01251], lr: 0.000446, loss: 0.4381
2022-09-21 09:01:52 - train: epoch 0014, iter [01080, 01251], lr: 0.000446, loss: 0.4658
2022-09-21 09:02:13 - train: epoch 0014, iter [01090, 01251], lr: 0.000446, loss: 0.4315
2022-09-21 09:02:34 - train: epoch 0014, iter [01100, 01251], lr: 0.000446, loss: 0.4288
2022-09-21 09:02:55 - train: epoch 0014, iter [01110, 01251], lr: 0.000447, loss: 0.4589
2022-09-21 09:03:17 - train: epoch 0014, iter [01120, 01251], lr: 0.000447, loss: 0.4319
2022-09-21 09:03:38 - train: epoch 0014, iter [01130, 01251], lr: 0.000447, loss: 0.4468
2022-09-21 09:03:59 - train: epoch 0014, iter [01140, 01251], lr: 0.000447, loss: 0.4170
2022-09-21 09:04:20 - train: epoch 0014, iter [01150, 01251], lr: 0.000448, loss: 0.4373
2022-09-21 09:04:41 - train: epoch 0014, iter [01160, 01251], lr: 0.000448, loss: 0.4350
2022-09-21 09:05:02 - train: epoch 0014, iter [01170, 01251], lr: 0.000448, loss: 0.4437
2022-09-21 09:05:24 - train: epoch 0014, iter [01180, 01251], lr: 0.000448, loss: 0.4517
2022-09-21 09:05:45 - train: epoch 0014, iter [01190, 01251], lr: 0.000449, loss: 0.4347
2022-09-21 09:06:06 - train: epoch 0014, iter [01200, 01251], lr: 0.000449, loss: 0.4218
2022-09-21 09:06:27 - train: epoch 0014, iter [01210, 01251], lr: 0.000449, loss: 0.4262
2022-09-21 09:06:48 - train: epoch 0014, iter [01220, 01251], lr: 0.000449, loss: 0.4377
2022-09-21 09:07:10 - train: epoch 0014, iter [01230, 01251], lr: 0.000449, loss: 0.4251
2022-09-21 09:07:31 - train: epoch 0014, iter [01240, 01251], lr: 0.000450, loss: 0.4220
2022-09-21 09:07:51 - train: epoch 0014, iter [01250, 01251], lr: 0.000450, loss: 0.4445
2022-09-21 09:07:56 - train: epoch 014, train_loss: 0.4409
2022-09-21 09:08:02 - until epoch: 014, best_loss: 0.4409
2022-09-21 09:08:02 - epoch 015 lr: 0.000450
2022-09-21 09:08:39 - train: epoch 0015, iter [00010, 01251], lr: 0.000450, loss: 0.4273
2022-09-21 09:09:00 - train: epoch 0015, iter [00020, 01251], lr: 0.000450, loss: 0.4390
2022-09-21 09:09:21 - train: epoch 0015, iter [00030, 01251], lr: 0.000451, loss: 0.4161
2022-09-21 09:09:42 - train: epoch 0015, iter [00040, 01251], lr: 0.000451, loss: 0.4278
2022-09-21 09:10:04 - train: epoch 0015, iter [00050, 01251], lr: 0.000451, loss: 0.4278
2022-09-21 09:10:25 - train: epoch 0015, iter [00060, 01251], lr: 0.000451, loss: 0.4376
2022-09-21 09:10:46 - train: epoch 0015, iter [00070, 01251], lr: 0.000452, loss: 0.4514
2022-09-21 09:11:07 - train: epoch 0015, iter [00080, 01251], lr: 0.000452, loss: 0.4426
2022-09-21 09:11:28 - train: epoch 0015, iter [00090, 01251], lr: 0.000452, loss: 0.4398
2022-09-21 09:11:49 - train: epoch 0015, iter [00100, 01251], lr: 0.000452, loss: 0.4510
2022-09-21 09:12:11 - train: epoch 0015, iter [00110, 01251], lr: 0.000453, loss: 0.4642
2022-09-21 09:12:32 - train: epoch 0015, iter [00120, 01251], lr: 0.000453, loss: 0.4467
2022-09-21 09:12:53 - train: epoch 0015, iter [00130, 01251], lr: 0.000453, loss: 0.4314
2022-09-21 09:13:14 - train: epoch 0015, iter [00140, 01251], lr: 0.000453, loss: 0.4443
2022-09-21 09:13:35 - train: epoch 0015, iter [00150, 01251], lr: 0.000454, loss: 0.4470
2022-09-21 09:13:56 - train: epoch 0015, iter [00160, 01251], lr: 0.000454, loss: 0.4244
2022-09-21 09:14:17 - train: epoch 0015, iter [00170, 01251], lr: 0.000454, loss: 0.4544
2022-09-21 09:14:38 - train: epoch 0015, iter [00180, 01251], lr: 0.000454, loss: 0.4574
2022-09-21 09:15:00 - train: epoch 0015, iter [00190, 01251], lr: 0.000455, loss: 0.4458
2022-09-21 09:15:21 - train: epoch 0015, iter [00200, 01251], lr: 0.000455, loss: 0.4463
2022-09-21 09:15:42 - train: epoch 0015, iter [00210, 01251], lr: 0.000455, loss: 0.4431
2022-09-21 09:16:03 - train: epoch 0015, iter [00220, 01251], lr: 0.000455, loss: 0.4393
2022-09-21 09:16:24 - train: epoch 0015, iter [00230, 01251], lr: 0.000456, loss: 0.4329
2022-09-21 09:16:45 - train: epoch 0015, iter [00240, 01251], lr: 0.000456, loss: 0.4502
2022-09-21 09:17:07 - train: epoch 0015, iter [00250, 01251], lr: 0.000456, loss: 0.4382
2022-09-21 09:17:28 - train: epoch 0015, iter [00260, 01251], lr: 0.000456, loss: 0.4504
2022-09-21 09:17:49 - train: epoch 0015, iter [00270, 01251], lr: 0.000456, loss: 0.4505
2022-09-21 09:18:10 - train: epoch 0015, iter [00280, 01251], lr: 0.000457, loss: 0.4640
2022-09-21 09:18:31 - train: epoch 0015, iter [00290, 01251], lr: 0.000457, loss: 0.4331
2022-09-21 09:18:52 - train: epoch 0015, iter [00300, 01251], lr: 0.000457, loss: 0.4415
2022-09-21 09:19:14 - train: epoch 0015, iter [00310, 01251], lr: 0.000457, loss: 0.4308
2022-09-21 09:19:35 - train: epoch 0015, iter [00320, 01251], lr: 0.000458, loss: 0.4273
2022-09-21 09:19:56 - train: epoch 0015, iter [00330, 01251], lr: 0.000458, loss: 0.4531
2022-09-21 09:20:17 - train: epoch 0015, iter [00340, 01251], lr: 0.000458, loss: 0.4383
2022-09-21 09:20:38 - train: epoch 0015, iter [00350, 01251], lr: 0.000458, loss: 0.4249
2022-09-21 09:20:59 - train: epoch 0015, iter [00360, 01251], lr: 0.000459, loss: 0.4442
2022-09-21 09:21:21 - train: epoch 0015, iter [00370, 01251], lr: 0.000459, loss: 0.4553
2022-09-21 09:21:42 - train: epoch 0015, iter [00380, 01251], lr: 0.000459, loss: 0.4349
2022-09-21 09:22:03 - train: epoch 0015, iter [00390, 01251], lr: 0.000459, loss: 0.4410
2022-09-21 09:22:24 - train: epoch 0015, iter [00400, 01251], lr: 0.000460, loss: 0.4567
2022-09-21 09:22:45 - train: epoch 0015, iter [00410, 01251], lr: 0.000460, loss: 0.4500
2022-09-21 09:23:07 - train: epoch 0015, iter [00420, 01251], lr: 0.000460, loss: 0.4525
2022-09-21 09:23:28 - train: epoch 0015, iter [00430, 01251], lr: 0.000460, loss: 0.4500
2022-09-21 09:23:49 - train: epoch 0015, iter [00440, 01251], lr: 0.000461, loss: 0.4484
2022-09-21 09:24:10 - train: epoch 0015, iter [00450, 01251], lr: 0.000461, loss: 0.4487
2022-09-21 09:24:31 - train: epoch 0015, iter [00460, 01251], lr: 0.000461, loss: 0.4241
2022-09-21 09:24:52 - train: epoch 0015, iter [00470, 01251], lr: 0.000461, loss: 0.4440
2022-09-21 09:25:13 - train: epoch 0015, iter [00480, 01251], lr: 0.000462, loss: 0.4215
2022-09-21 09:25:34 - train: epoch 0015, iter [00490, 01251], lr: 0.000462, loss: 0.4306
2022-09-21 09:25:56 - train: epoch 0015, iter [00500, 01251], lr: 0.000462, loss: 0.4244
2022-09-21 09:26:17 - train: epoch 0015, iter [00510, 01251], lr: 0.000462, loss: 0.4394
2022-09-21 09:26:38 - train: epoch 0015, iter [00520, 01251], lr: 0.000462, loss: 0.4470
2022-09-21 09:26:59 - train: epoch 0015, iter [00530, 01251], lr: 0.000463, loss: 0.4411
2022-09-21 09:27:20 - train: epoch 0015, iter [00540, 01251], lr: 0.000463, loss: 0.4375
2022-09-21 09:27:42 - train: epoch 0015, iter [00550, 01251], lr: 0.000463, loss: 0.4313
2022-09-21 09:28:03 - train: epoch 0015, iter [00560, 01251], lr: 0.000463, loss: 0.4155
2022-09-21 09:28:24 - train: epoch 0015, iter [00570, 01251], lr: 0.000464, loss: 0.4298
2022-09-21 09:28:45 - train: epoch 0015, iter [00580, 01251], lr: 0.000464, loss: 0.4445
2022-09-21 09:29:06 - train: epoch 0015, iter [00590, 01251], lr: 0.000464, loss: 0.4283
2022-09-21 09:29:28 - train: epoch 0015, iter [00600, 01251], lr: 0.000464, loss: 0.4320
2022-09-21 09:29:49 - train: epoch 0015, iter [00610, 01251], lr: 0.000465, loss: 0.4413
2022-09-21 09:30:10 - train: epoch 0015, iter [00620, 01251], lr: 0.000465, loss: 0.4454
2022-09-21 09:30:31 - train: epoch 0015, iter [00630, 01251], lr: 0.000465, loss: 0.4208
2022-09-21 09:30:52 - train: epoch 0015, iter [00640, 01251], lr: 0.000465, loss: 0.4513
2022-09-21 09:31:13 - train: epoch 0015, iter [00650, 01251], lr: 0.000466, loss: 0.4313
2022-09-21 09:31:34 - train: epoch 0015, iter [00660, 01251], lr: 0.000466, loss: 0.4421
2022-09-21 09:31:55 - train: epoch 0015, iter [00670, 01251], lr: 0.000466, loss: 0.4252
2022-09-21 09:32:16 - train: epoch 0015, iter [00680, 01251], lr: 0.000466, loss: 0.4260
2022-09-21 09:32:37 - train: epoch 0015, iter [00690, 01251], lr: 0.000467, loss: 0.4490
2022-09-21 09:32:58 - train: epoch 0015, iter [00700, 01251], lr: 0.000467, loss: 0.4330
2022-09-21 09:33:19 - train: epoch 0015, iter [00710, 01251], lr: 0.000467, loss: 0.4473
2022-09-21 09:33:40 - train: epoch 0015, iter [00720, 01251], lr: 0.000467, loss: 0.4325
2022-09-21 09:34:01 - train: epoch 0015, iter [00730, 01251], lr: 0.000468, loss: 0.4455
2022-09-21 09:34:22 - train: epoch 0015, iter [00740, 01251], lr: 0.000468, loss: 0.4275
2022-09-21 09:34:43 - train: epoch 0015, iter [00750, 01251], lr: 0.000468, loss: 0.4567
2022-09-21 09:35:04 - train: epoch 0015, iter [00760, 01251], lr: 0.000468, loss: 0.4374
2022-09-21 09:35:25 - train: epoch 0015, iter [00770, 01251], lr: 0.000468, loss: 0.4457
2022-09-21 09:35:47 - train: epoch 0015, iter [00780, 01251], lr: 0.000469, loss: 0.4297
2022-09-21 09:36:07 - train: epoch 0015, iter [00790, 01251], lr: 0.000469, loss: 0.4441
2022-09-21 09:36:28 - train: epoch 0015, iter [00800, 01251], lr: 0.000469, loss: 0.4371
2022-09-21 09:36:50 - train: epoch 0015, iter [00810, 01251], lr: 0.000469, loss: 0.4559
2022-09-21 09:37:10 - train: epoch 0015, iter [00820, 01251], lr: 0.000470, loss: 0.4396
2022-09-21 09:37:31 - train: epoch 0015, iter [00830, 01251], lr: 0.000470, loss: 0.4357
2022-09-21 09:37:52 - train: epoch 0015, iter [00840, 01251], lr: 0.000470, loss: 0.4337
2022-09-21 09:38:14 - train: epoch 0015, iter [00850, 01251], lr: 0.000470, loss: 0.4430
2022-09-21 09:38:35 - train: epoch 0015, iter [00860, 01251], lr: 0.000471, loss: 0.4287
2022-09-21 09:38:56 - train: epoch 0015, iter [00870, 01251], lr: 0.000471, loss: 0.4329
2022-09-21 09:39:17 - train: epoch 0015, iter [00880, 01251], lr: 0.000471, loss: 0.4292
2022-09-21 09:39:38 - train: epoch 0015, iter [00890, 01251], lr: 0.000471, loss: 0.4149
2022-09-21 09:39:59 - train: epoch 0015, iter [00900, 01251], lr: 0.000472, loss: 0.4345
2022-09-21 09:40:20 - train: epoch 0015, iter [00910, 01251], lr: 0.000472, loss: 0.4407
2022-09-21 09:40:41 - train: epoch 0015, iter [00920, 01251], lr: 0.000472, loss: 0.4177
2022-09-21 09:41:02 - train: epoch 0015, iter [00930, 01251], lr: 0.000472, loss: 0.4359
2022-09-21 09:41:23 - train: epoch 0015, iter [00940, 01251], lr: 0.000473, loss: 0.4522
2022-09-21 09:41:44 - train: epoch 0015, iter [00950, 01251], lr: 0.000473, loss: 0.4341
2022-09-21 09:42:06 - train: epoch 0015, iter [00960, 01251], lr: 0.000473, loss: 0.4639
2022-09-21 09:42:27 - train: epoch 0015, iter [00970, 01251], lr: 0.000473, loss: 0.4191
2022-09-21 09:42:48 - train: epoch 0015, iter [00980, 01251], lr: 0.000474, loss: 0.4364
2022-09-21 09:43:09 - train: epoch 0015, iter [00990, 01251], lr: 0.000474, loss: 0.4418
2022-09-21 09:43:31 - train: epoch 0015, iter [01000, 01251], lr: 0.000474, loss: 0.4261
2022-09-21 09:43:52 - train: epoch 0015, iter [01010, 01251], lr: 0.000474, loss: 0.4258
2022-09-21 09:44:13 - train: epoch 0015, iter [01020, 01251], lr: 0.000474, loss: 0.4423
2022-09-21 09:44:34 - train: epoch 0015, iter [01030, 01251], lr: 0.000475, loss: 0.4487
2022-09-21 09:44:55 - train: epoch 0015, iter [01040, 01251], lr: 0.000475, loss: 0.4414
2022-09-21 09:45:17 - train: epoch 0015, iter [01050, 01251], lr: 0.000475, loss: 0.4453
2022-09-21 09:45:38 - train: epoch 0015, iter [01060, 01251], lr: 0.000475, loss: 0.4552
2022-09-21 09:45:59 - train: epoch 0015, iter [01070, 01251], lr: 0.000476, loss: 0.4264
2022-09-21 09:46:20 - train: epoch 0015, iter [01080, 01251], lr: 0.000476, loss: 0.4536
2022-09-21 09:46:41 - train: epoch 0015, iter [01090, 01251], lr: 0.000476, loss: 0.4233
2022-09-21 09:47:03 - train: epoch 0015, iter [01100, 01251], lr: 0.000476, loss: 0.4492
2022-09-21 09:47:24 - train: epoch 0015, iter [01110, 01251], lr: 0.000477, loss: 0.4466
2022-09-21 09:47:45 - train: epoch 0015, iter [01120, 01251], lr: 0.000477, loss: 0.4529
2022-09-21 09:48:06 - train: epoch 0015, iter [01130, 01251], lr: 0.000477, loss: 0.4437
2022-09-21 09:48:27 - train: epoch 0015, iter [01140, 01251], lr: 0.000477, loss: 0.4295
2022-09-21 09:48:48 - train: epoch 0015, iter [01150, 01251], lr: 0.000478, loss: 0.4425
2022-09-21 09:49:10 - train: epoch 0015, iter [01160, 01251], lr: 0.000478, loss: 0.4448
2022-09-21 09:49:31 - train: epoch 0015, iter [01170, 01251], lr: 0.000478, loss: 0.4584
2022-09-21 09:49:52 - train: epoch 0015, iter [01180, 01251], lr: 0.000478, loss: 0.4142
2022-09-21 09:50:13 - train: epoch 0015, iter [01190, 01251], lr: 0.000479, loss: 0.4691
2022-09-21 09:50:34 - train: epoch 0015, iter [01200, 01251], lr: 0.000479, loss: 0.4470
2022-09-21 09:50:55 - train: epoch 0015, iter [01210, 01251], lr: 0.000479, loss: 0.4515
2022-09-21 09:51:16 - train: epoch 0015, iter [01220, 01251], lr: 0.000479, loss: 0.4389
2022-09-21 09:51:37 - train: epoch 0015, iter [01230, 01251], lr: 0.000479, loss: 0.4351
2022-09-21 09:51:58 - train: epoch 0015, iter [01240, 01251], lr: 0.000480, loss: 0.4446
2022-09-21 09:52:18 - train: epoch 0015, iter [01250, 01251], lr: 0.000480, loss: 0.4577
2022-09-21 09:52:22 - train: epoch 015, train_loss: 0.4389
2022-09-21 09:52:28 - until epoch: 015, best_loss: 0.4389
2022-09-21 09:52:28 - epoch 016 lr: 0.000480
2022-09-21 09:53:05 - train: epoch 0016, iter [00010, 01251], lr: 0.000480, loss: 0.4448
2022-09-21 09:53:25 - train: epoch 0016, iter [00020, 01251], lr: 0.000480, loss: 0.4495
2022-09-21 09:53:46 - train: epoch 0016, iter [00030, 01251], lr: 0.000481, loss: 0.4427
2022-09-21 09:54:08 - train: epoch 0016, iter [00040, 01251], lr: 0.000481, loss: 0.4404
2022-09-21 09:54:29 - train: epoch 0016, iter [00050, 01251], lr: 0.000481, loss: 0.4445
2022-09-21 09:54:50 - train: epoch 0016, iter [00060, 01251], lr: 0.000481, loss: 0.4407
2022-09-21 09:55:11 - train: epoch 0016, iter [00070, 01251], lr: 0.000482, loss: 0.4328
2022-09-21 09:55:32 - train: epoch 0016, iter [00080, 01251], lr: 0.000482, loss: 0.4423
2022-09-21 09:55:54 - train: epoch 0016, iter [00090, 01251], lr: 0.000482, loss: 0.4322
2022-09-21 09:56:15 - train: epoch 0016, iter [00100, 01251], lr: 0.000482, loss: 0.4298
2022-09-21 09:56:36 - train: epoch 0016, iter [00110, 01251], lr: 0.000483, loss: 0.4397
2022-09-21 09:56:57 - train: epoch 0016, iter [00120, 01251], lr: 0.000483, loss: 0.4409
2022-09-21 09:57:18 - train: epoch 0016, iter [00130, 01251], lr: 0.000483, loss: 0.4364
2022-09-21 09:57:39 - train: epoch 0016, iter [00140, 01251], lr: 0.000483, loss: 0.4351
2022-09-21 09:58:00 - train: epoch 0016, iter [00150, 01251], lr: 0.000484, loss: 0.4481
2022-09-21 09:58:21 - train: epoch 0016, iter [00160, 01251], lr: 0.000484, loss: 0.4520
2022-09-21 09:58:42 - train: epoch 0016, iter [00170, 01251], lr: 0.000484, loss: 0.4456
2022-09-21 09:59:03 - train: epoch 0016, iter [00180, 01251], lr: 0.000484, loss: 0.4454
2022-09-21 09:59:25 - train: epoch 0016, iter [00190, 01251], lr: 0.000485, loss: 0.4392
2022-09-21 09:59:46 - train: epoch 0016, iter [00200, 01251], lr: 0.000485, loss: 0.4411
2022-09-21 10:00:07 - train: epoch 0016, iter [00210, 01251], lr: 0.000485, loss: 0.4446
2022-09-21 10:00:28 - train: epoch 0016, iter [00220, 01251], lr: 0.000485, loss: 0.4411
2022-09-21 10:00:49 - train: epoch 0016, iter [00230, 01251], lr: 0.000486, loss: 0.4162
2022-09-21 10:01:10 - train: epoch 0016, iter [00240, 01251], lr: 0.000486, loss: 0.4346
2022-09-21 10:01:31 - train: epoch 0016, iter [00250, 01251], lr: 0.000486, loss: 0.4316
2022-09-21 10:01:52 - train: epoch 0016, iter [00260, 01251], lr: 0.000486, loss: 0.4243
2022-09-21 10:02:13 - train: epoch 0016, iter [00270, 01251], lr: 0.000486, loss: 0.4453
2022-09-21 10:02:34 - train: epoch 0016, iter [00280, 01251], lr: 0.000487, loss: 0.4394
2022-09-21 10:02:55 - train: epoch 0016, iter [00290, 01251], lr: 0.000487, loss: 0.4457
2022-09-21 10:03:17 - train: epoch 0016, iter [00300, 01251], lr: 0.000487, loss: 0.4503
2022-09-21 10:03:38 - train: epoch 0016, iter [00310, 01251], lr: 0.000487, loss: 0.4430
2022-09-21 10:03:59 - train: epoch 0016, iter [00320, 01251], lr: 0.000488, loss: 0.4492
2022-09-21 10:04:20 - train: epoch 0016, iter [00330, 01251], lr: 0.000488, loss: 0.4393
2022-09-21 10:04:41 - train: epoch 0016, iter [00340, 01251], lr: 0.000488, loss: 0.4367
2022-09-21 10:05:02 - train: epoch 0016, iter [00350, 01251], lr: 0.000488, loss: 0.4358
2022-09-21 10:05:23 - train: epoch 0016, iter [00360, 01251], lr: 0.000489, loss: 0.4487
2022-09-21 10:05:43 - train: epoch 0016, iter [00370, 01251], lr: 0.000489, loss: 0.4354
2022-09-21 10:06:04 - train: epoch 0016, iter [00380, 01251], lr: 0.000489, loss: 0.4296
2022-09-21 10:06:25 - train: epoch 0016, iter [00390, 01251], lr: 0.000489, loss: 0.4596
2022-09-21 10:06:46 - train: epoch 0016, iter [00400, 01251], lr: 0.000490, loss: 0.4372
2022-09-21 10:07:07 - train: epoch 0016, iter [00410, 01251], lr: 0.000490, loss: 0.4361
2022-09-21 10:07:29 - train: epoch 0016, iter [00420, 01251], lr: 0.000490, loss: 0.4221
2022-09-21 10:07:50 - train: epoch 0016, iter [00430, 01251], lr: 0.000490, loss: 0.4449
2022-09-21 10:08:11 - train: epoch 0016, iter [00440, 01251], lr: 0.000491, loss: 0.4324
2022-09-21 10:08:32 - train: epoch 0016, iter [00450, 01251], lr: 0.000491, loss: 0.4252
2022-09-21 10:08:53 - train: epoch 0016, iter [00460, 01251], lr: 0.000491, loss: 0.4123
2022-09-21 10:09:14 - train: epoch 0016, iter [00470, 01251], lr: 0.000491, loss: 0.4371
2022-09-21 10:09:35 - train: epoch 0016, iter [00480, 01251], lr: 0.000492, loss: 0.4426
2022-09-21 10:09:56 - train: epoch 0016, iter [00490, 01251], lr: 0.000492, loss: 0.4233
2022-09-21 10:10:18 - train: epoch 0016, iter [00500, 01251], lr: 0.000492, loss: 0.4099
2022-09-21 10:10:38 - train: epoch 0016, iter [00510, 01251], lr: 0.000492, loss: 0.4672
2022-09-21 10:10:59 - train: epoch 0016, iter [00520, 01251], lr: 0.000492, loss: 0.4566
2022-09-21 10:11:20 - train: epoch 0016, iter [00530, 01251], lr: 0.000493, loss: 0.4092
2022-09-21 10:11:41 - train: epoch 0016, iter [00540, 01251], lr: 0.000493, loss: 0.4397
2022-09-21 10:12:02 - train: epoch 0016, iter [00550, 01251], lr: 0.000493, loss: 0.4400
2022-09-21 10:12:23 - train: epoch 0016, iter [00560, 01251], lr: 0.000493, loss: 0.4179
2022-09-21 10:12:43 - train: epoch 0016, iter [00570, 01251], lr: 0.000494, loss: 0.4364
2022-09-21 10:13:04 - train: epoch 0016, iter [00580, 01251], lr: 0.000494, loss: 0.4495
2022-09-21 10:13:25 - train: epoch 0016, iter [00590, 01251], lr: 0.000494, loss: 0.4437
2022-09-21 10:13:46 - train: epoch 0016, iter [00600, 01251], lr: 0.000494, loss: 0.4442
2022-09-21 10:14:07 - train: epoch 0016, iter [00610, 01251], lr: 0.000495, loss: 0.4385
2022-09-21 10:14:28 - train: epoch 0016, iter [00620, 01251], lr: 0.000495, loss: 0.4318
2022-09-21 10:14:49 - train: epoch 0016, iter [00630, 01251], lr: 0.000495, loss: 0.4443
2022-09-21 10:15:10 - train: epoch 0016, iter [00640, 01251], lr: 0.000495, loss: 0.4436
2022-09-21 10:15:30 - train: epoch 0016, iter [00650, 01251], lr: 0.000496, loss: 0.4365
2022-09-21 10:15:51 - train: epoch 0016, iter [00660, 01251], lr: 0.000496, loss: 0.4306
2022-09-21 10:16:12 - train: epoch 0016, iter [00670, 01251], lr: 0.000496, loss: 0.4117
2022-09-21 10:16:33 - train: epoch 0016, iter [00680, 01251], lr: 0.000496, loss: 0.4373
2022-09-21 10:16:54 - train: epoch 0016, iter [00690, 01251], lr: 0.000497, loss: 0.4358
2022-09-21 10:17:14 - train: epoch 0016, iter [00700, 01251], lr: 0.000497, loss: 0.4302
2022-09-21 10:17:35 - train: epoch 0016, iter [00710, 01251], lr: 0.000497, loss: 0.4275
2022-09-21 10:17:56 - train: epoch 0016, iter [00720, 01251], lr: 0.000497, loss: 0.4390
2022-09-21 10:18:17 - train: epoch 0016, iter [00730, 01251], lr: 0.000498, loss: 0.4279
2022-09-21 10:18:38 - train: epoch 0016, iter [00740, 01251], lr: 0.000498, loss: 0.4408
2022-09-21 10:18:59 - train: epoch 0016, iter [00750, 01251], lr: 0.000498, loss: 0.4396
2022-09-21 10:19:20 - train: epoch 0016, iter [00760, 01251], lr: 0.000498, loss: 0.4297
2022-09-21 10:19:41 - train: epoch 0016, iter [00770, 01251], lr: 0.000498, loss: 0.4349
2022-09-21 10:20:02 - train: epoch 0016, iter [00780, 01251], lr: 0.000499, loss: 0.4358
2022-09-21 10:20:23 - train: epoch 0016, iter [00790, 01251], lr: 0.000499, loss: 0.4138
2022-09-21 10:20:44 - train: epoch 0016, iter [00800, 01251], lr: 0.000499, loss: 0.4373
2022-09-21 10:21:05 - train: epoch 0016, iter [00810, 01251], lr: 0.000499, loss: 0.4323
2022-09-21 10:21:26 - train: epoch 0016, iter [00820, 01251], lr: 0.000500, loss: 0.4327
2022-09-21 10:21:47 - train: epoch 0016, iter [00830, 01251], lr: 0.000500, loss: 0.4488
2022-09-21 10:22:08 - train: epoch 0016, iter [00840, 01251], lr: 0.000500, loss: 0.4332
2022-09-21 10:22:29 - train: epoch 0016, iter [00850, 01251], lr: 0.000500, loss: 0.4318
2022-09-21 10:22:50 - train: epoch 0016, iter [00860, 01251], lr: 0.000501, loss: 0.4569
2022-09-21 10:23:11 - train: epoch 0016, iter [00870, 01251], lr: 0.000501, loss: 0.4263
2022-09-21 10:23:32 - train: epoch 0016, iter [00880, 01251], lr: 0.000501, loss: 0.4191
2022-09-21 10:23:53 - train: epoch 0016, iter [00890, 01251], lr: 0.000501, loss: 0.4148
2022-09-21 10:24:14 - train: epoch 0016, iter [00900, 01251], lr: 0.000502, loss: 0.4411
2022-09-21 10:24:35 - train: epoch 0016, iter [00910, 01251], lr: 0.000502, loss: 0.4409
2022-09-21 10:24:56 - train: epoch 0016, iter [00920, 01251], lr: 0.000502, loss: 0.4233
2022-09-21 10:25:17 - train: epoch 0016, iter [00930, 01251], lr: 0.000502, loss: 0.4178
2022-09-21 10:25:38 - train: epoch 0016, iter [00940, 01251], lr: 0.000503, loss: 0.4312
2022-09-21 10:25:59 - train: epoch 0016, iter [00950, 01251], lr: 0.000503, loss: 0.4433
2022-09-21 10:26:20 - train: epoch 0016, iter [00960, 01251], lr: 0.000503, loss: 0.4615
2022-09-21 10:26:41 - train: epoch 0016, iter [00970, 01251], lr: 0.000503, loss: 0.4442
2022-09-21 10:27:02 - train: epoch 0016, iter [00980, 01251], lr: 0.000504, loss: 0.4382
2022-09-21 10:27:23 - train: epoch 0016, iter [00990, 01251], lr: 0.000504, loss: 0.4254
2022-09-21 10:27:44 - train: epoch 0016, iter [01000, 01251], lr: 0.000504, loss: 0.4408
2022-09-21 10:28:05 - train: epoch 0016, iter [01010, 01251], lr: 0.000504, loss: 0.4597
2022-09-21 10:28:26 - train: epoch 0016, iter [01020, 01251], lr: 0.000504, loss: 0.4401
2022-09-21 10:28:47 - train: epoch 0016, iter [01030, 01251], lr: 0.000505, loss: 0.4513
2022-09-21 10:29:08 - train: epoch 0016, iter [01040, 01251], lr: 0.000505, loss: 0.4462
2022-09-21 10:29:29 - train: epoch 0016, iter [01050, 01251], lr: 0.000505, loss: 0.4445
2022-09-21 10:29:51 - train: epoch 0016, iter [01060, 01251], lr: 0.000505, loss: 0.4471
2022-09-21 10:30:12 - train: epoch 0016, iter [01070, 01251], lr: 0.000506, loss: 0.4343
2022-09-21 10:30:33 - train: epoch 0016, iter [01080, 01251], lr: 0.000506, loss: 0.4381
2022-09-21 10:30:55 - train: epoch 0016, iter [01090, 01251], lr: 0.000506, loss: 0.4379
2022-09-21 10:31:16 - train: epoch 0016, iter [01100, 01251], lr: 0.000506, loss: 0.4316
2022-09-21 10:31:37 - train: epoch 0016, iter [01110, 01251], lr: 0.000507, loss: 0.4364
2022-09-21 10:31:59 - train: epoch 0016, iter [01120, 01251], lr: 0.000507, loss: 0.4242
2022-09-21 10:32:20 - train: epoch 0016, iter [01130, 01251], lr: 0.000507, loss: 0.4585
2022-09-21 10:32:41 - train: epoch 0016, iter [01140, 01251], lr: 0.000507, loss: 0.4281
2022-09-21 10:33:03 - train: epoch 0016, iter [01150, 01251], lr: 0.000508, loss: 0.4252
2022-09-21 10:33:24 - train: epoch 0016, iter [01160, 01251], lr: 0.000508, loss: 0.4357
2022-09-21 10:33:45 - train: epoch 0016, iter [01170, 01251], lr: 0.000508, loss: 0.4387
2022-09-21 10:34:06 - train: epoch 0016, iter [01180, 01251], lr: 0.000508, loss: 0.4347
2022-09-21 10:34:27 - train: epoch 0016, iter [01190, 01251], lr: 0.000509, loss: 0.4238
2022-09-21 10:34:49 - train: epoch 0016, iter [01200, 01251], lr: 0.000509, loss: 0.4315
2022-09-21 10:35:09 - train: epoch 0016, iter [01210, 01251], lr: 0.000509, loss: 0.4136
2022-09-21 10:35:31 - train: epoch 0016, iter [01220, 01251], lr: 0.000509, loss: 0.4442
2022-09-21 10:35:52 - train: epoch 0016, iter [01230, 01251], lr: 0.000509, loss: 0.4352
2022-09-21 10:36:13 - train: epoch 0016, iter [01240, 01251], lr: 0.000510, loss: 0.4475
2022-09-21 10:36:33 - train: epoch 0016, iter [01250, 01251], lr: 0.000510, loss: 0.4435
2022-09-21 10:36:38 - train: epoch 016, train_loss: 0.4371
2022-09-21 10:36:44 - until epoch: 016, best_loss: 0.4371
2022-09-21 10:36:44 - epoch 017 lr: 0.000510
2022-09-21 10:37:21 - train: epoch 0017, iter [00010, 01251], lr: 0.000510, loss: 0.4340
2022-09-21 10:37:42 - train: epoch 0017, iter [00020, 01251], lr: 0.000510, loss: 0.4191
2022-09-21 10:38:03 - train: epoch 0017, iter [00030, 01251], lr: 0.000511, loss: 0.4492
2022-09-21 10:38:24 - train: epoch 0017, iter [00040, 01251], lr: 0.000511, loss: 0.4133
2022-09-21 10:38:45 - train: epoch 0017, iter [00050, 01251], lr: 0.000511, loss: 0.4349
2022-09-21 10:39:06 - train: epoch 0017, iter [00060, 01251], lr: 0.000511, loss: 0.4378
2022-09-21 10:39:27 - train: epoch 0017, iter [00070, 01251], lr: 0.000512, loss: 0.4290
2022-09-21 10:39:48 - train: epoch 0017, iter [00080, 01251], lr: 0.000512, loss: 0.4380
2022-09-21 10:40:09 - train: epoch 0017, iter [00090, 01251], lr: 0.000512, loss: 0.4275
2022-09-21 10:40:30 - train: epoch 0017, iter [00100, 01251], lr: 0.000512, loss: 0.4185
2022-09-21 10:40:51 - train: epoch 0017, iter [00110, 01251], lr: 0.000513, loss: 0.4268
2022-09-21 10:41:13 - train: epoch 0017, iter [00120, 01251], lr: 0.000513, loss: 0.4467
2022-09-21 10:41:34 - train: epoch 0017, iter [00130, 01251], lr: 0.000513, loss: 0.4426
2022-09-21 10:41:55 - train: epoch 0017, iter [00140, 01251], lr: 0.000513, loss: 0.4281
2022-09-21 10:42:16 - train: epoch 0017, iter [00150, 01251], lr: 0.000514, loss: 0.4151
2022-09-21 10:42:37 - train: epoch 0017, iter [00160, 01251], lr: 0.000514, loss: 0.4102
2022-09-21 10:42:58 - train: epoch 0017, iter [00170, 01251], lr: 0.000514, loss: 0.4236
2022-09-21 10:43:20 - train: epoch 0017, iter [00180, 01251], lr: 0.000514, loss: 0.4270
2022-09-21 10:43:41 - train: epoch 0017, iter [00190, 01251], lr: 0.000515, loss: 0.4317
2022-09-21 10:44:02 - train: epoch 0017, iter [00200, 01251], lr: 0.000515, loss: 0.4389
2022-09-21 10:44:24 - train: epoch 0017, iter [00210, 01251], lr: 0.000515, loss: 0.4252
2022-09-21 10:44:45 - train: epoch 0017, iter [00220, 01251], lr: 0.000515, loss: 0.4417
2022-09-21 10:45:06 - train: epoch 0017, iter [00230, 01251], lr: 0.000516, loss: 0.4222
2022-09-21 10:45:27 - train: epoch 0017, iter [00240, 01251], lr: 0.000516, loss: 0.4255
2022-09-21 10:45:48 - train: epoch 0017, iter [00250, 01251], lr: 0.000516, loss: 0.4385
2022-09-21 10:46:10 - train: epoch 0017, iter [00260, 01251], lr: 0.000516, loss: 0.4346
2022-09-21 10:46:31 - train: epoch 0017, iter [00270, 01251], lr: 0.000516, loss: 0.4313
2022-09-21 10:46:52 - train: epoch 0017, iter [00280, 01251], lr: 0.000517, loss: 0.4309
2022-09-21 10:47:13 - train: epoch 0017, iter [00290, 01251], lr: 0.000517, loss: 0.4300
2022-09-21 10:47:35 - train: epoch 0017, iter [00300, 01251], lr: 0.000517, loss: 0.4215
2022-09-21 10:47:56 - train: epoch 0017, iter [00310, 01251], lr: 0.000517, loss: 0.4310
2022-09-21 10:48:17 - train: epoch 0017, iter [00320, 01251], lr: 0.000518, loss: 0.4288
2022-09-21 10:48:38 - train: epoch 0017, iter [00330, 01251], lr: 0.000518, loss: 0.4449
2022-09-21 10:49:00 - train: epoch 0017, iter [00340, 01251], lr: 0.000518, loss: 0.4297
2022-09-21 10:49:21 - train: epoch 0017, iter [00350, 01251], lr: 0.000518, loss: 0.4449
2022-09-21 10:49:43 - train: epoch 0017, iter [00360, 01251], lr: 0.000519, loss: 0.4429
2022-09-21 10:50:04 - train: epoch 0017, iter [00370, 01251], lr: 0.000519, loss: 0.4190
2022-09-21 10:50:25 - train: epoch 0017, iter [00380, 01251], lr: 0.000519, loss: 0.4510
2022-09-21 10:50:47 - train: epoch 0017, iter [00390, 01251], lr: 0.000519, loss: 0.4687
2022-09-21 10:51:08 - train: epoch 0017, iter [00400, 01251], lr: 0.000520, loss: 0.4365
2022-09-21 10:51:29 - train: epoch 0017, iter [00410, 01251], lr: 0.000520, loss: 0.4356
2022-09-21 10:51:50 - train: epoch 0017, iter [00420, 01251], lr: 0.000520, loss: 0.4600
2022-09-21 10:52:11 - train: epoch 0017, iter [00430, 01251], lr: 0.000520, loss: 0.4406
2022-09-21 10:52:32 - train: epoch 0017, iter [00440, 01251], lr: 0.000521, loss: 0.4406
2022-09-21 10:52:54 - train: epoch 0017, iter [00450, 01251], lr: 0.000521, loss: 0.4546
2022-09-21 10:53:15 - train: epoch 0017, iter [00460, 01251], lr: 0.000521, loss: 0.4195
2022-09-21 10:53:36 - train: epoch 0017, iter [00470, 01251], lr: 0.000521, loss: 0.4327
2022-09-21 10:53:57 - train: epoch 0017, iter [00480, 01251], lr: 0.000522, loss: 0.4320
2022-09-21 10:54:18 - train: epoch 0017, iter [00490, 01251], lr: 0.000522, loss: 0.4352
2022-09-21 10:54:39 - train: epoch 0017, iter [00500, 01251], lr: 0.000522, loss: 0.4374
2022-09-21 10:55:00 - train: epoch 0017, iter [00510, 01251], lr: 0.000522, loss: 0.4255
2022-09-21 10:55:22 - train: epoch 0017, iter [00520, 01251], lr: 0.000522, loss: 0.4324
2022-09-21 10:55:43 - train: epoch 0017, iter [00530, 01251], lr: 0.000523, loss: 0.4185
2022-09-21 10:56:04 - train: epoch 0017, iter [00540, 01251], lr: 0.000523, loss: 0.4374
2022-09-21 10:56:25 - train: epoch 0017, iter [00550, 01251], lr: 0.000523, loss: 0.4381
2022-09-21 10:56:46 - train: epoch 0017, iter [00560, 01251], lr: 0.000523, loss: 0.4391
2022-09-21 10:57:07 - train: epoch 0017, iter [00570, 01251], lr: 0.000524, loss: 0.4255
2022-09-21 10:57:28 - train: epoch 0017, iter [00580, 01251], lr: 0.000524, loss: 0.4415
2022-09-21 10:57:49 - train: epoch 0017, iter [00590, 01251], lr: 0.000524, loss: 0.4362
2022-09-21 10:58:10 - train: epoch 0017, iter [00600, 01251], lr: 0.000524, loss: 0.4364
2022-09-21 10:58:31 - train: epoch 0017, iter [00610, 01251], lr: 0.000525, loss: 0.4519
2022-09-21 10:58:52 - train: epoch 0017, iter [00620, 01251], lr: 0.000525, loss: 0.4290
2022-09-21 10:59:14 - train: epoch 0017, iter [00630, 01251], lr: 0.000525, loss: 0.4560
2022-09-21 10:59:35 - train: epoch 0017, iter [00640, 01251], lr: 0.000525, loss: 0.4264
2022-09-21 10:59:56 - train: epoch 0017, iter [00650, 01251], lr: 0.000526, loss: 0.4276
2022-09-21 11:00:17 - train: epoch 0017, iter [00660, 01251], lr: 0.000526, loss: 0.4387
2022-09-21 11:00:38 - train: epoch 0017, iter [00670, 01251], lr: 0.000526, loss: 0.4334
2022-09-21 11:00:59 - train: epoch 0017, iter [00680, 01251], lr: 0.000526, loss: 0.4380
2022-09-21 11:01:20 - train: epoch 0017, iter [00690, 01251], lr: 0.000527, loss: 0.4411
2022-09-21 11:01:42 - train: epoch 0017, iter [00700, 01251], lr: 0.000527, loss: 0.4422
2022-09-21 11:02:03 - train: epoch 0017, iter [00710, 01251], lr: 0.000527, loss: 0.4422
2022-09-21 11:02:23 - train: epoch 0017, iter [00720, 01251], lr: 0.000527, loss: 0.4414
2022-09-21 11:02:45 - train: epoch 0017, iter [00730, 01251], lr: 0.000528, loss: 0.4530
2022-09-21 11:03:06 - train: epoch 0017, iter [00740, 01251], lr: 0.000528, loss: 0.4250
2022-09-21 11:03:27 - train: epoch 0017, iter [00750, 01251], lr: 0.000528, loss: 0.4236
2022-09-21 11:03:48 - train: epoch 0017, iter [00760, 01251], lr: 0.000528, loss: 0.4191
2022-09-21 11:04:09 - train: epoch 0017, iter [00770, 01251], lr: 0.000528, loss: 0.4362
2022-09-21 11:04:31 - train: epoch 0017, iter [00780, 01251], lr: 0.000529, loss: 0.4414
2022-09-21 11:04:52 - train: epoch 0017, iter [00790, 01251], lr: 0.000529, loss: 0.4231
2022-09-21 11:05:13 - train: epoch 0017, iter [00800, 01251], lr: 0.000529, loss: 0.4399
2022-09-21 11:05:34 - train: epoch 0017, iter [00810, 01251], lr: 0.000529, loss: 0.4307
2022-09-21 11:05:55 - train: epoch 0017, iter [00820, 01251], lr: 0.000530, loss: 0.4291
2022-09-21 11:06:16 - train: epoch 0017, iter [00830, 01251], lr: 0.000530, loss: 0.4524
2022-09-21 11:06:37 - train: epoch 0017, iter [00840, 01251], lr: 0.000530, loss: 0.4008
2022-09-21 11:06:58 - train: epoch 0017, iter [00850, 01251], lr: 0.000530, loss: 0.4188
2022-09-21 11:07:19 - train: epoch 0017, iter [00860, 01251], lr: 0.000531, loss: 0.4380
2022-09-21 11:07:40 - train: epoch 0017, iter [00870, 01251], lr: 0.000531, loss: 0.4444
2022-09-21 11:08:01 - train: epoch 0017, iter [00880, 01251], lr: 0.000531, loss: 0.4310
2022-09-21 11:08:22 - train: epoch 0017, iter [00890, 01251], lr: 0.000531, loss: 0.4422
2022-09-21 11:08:43 - train: epoch 0017, iter [00900, 01251], lr: 0.000532, loss: 0.4285
2022-09-21 11:09:04 - train: epoch 0017, iter [00910, 01251], lr: 0.000532, loss: 0.4326
2022-09-21 11:09:26 - train: epoch 0017, iter [00920, 01251], lr: 0.000532, loss: 0.4352
2022-09-21 11:09:47 - train: epoch 0017, iter [00930, 01251], lr: 0.000532, loss: 0.4421
2022-09-21 11:10:08 - train: epoch 0017, iter [00940, 01251], lr: 0.000533, loss: 0.4257
2022-09-21 11:10:29 - train: epoch 0017, iter [00950, 01251], lr: 0.000533, loss: 0.4357
2022-09-21 11:10:50 - train: epoch 0017, iter [00960, 01251], lr: 0.000533, loss: 0.4380
2022-09-21 11:11:11 - train: epoch 0017, iter [00970, 01251], lr: 0.000533, loss: 0.4254
2022-09-21 11:11:32 - train: epoch 0017, iter [00980, 01251], lr: 0.000534, loss: 0.4480
2022-09-21 11:11:53 - train: epoch 0017, iter [00990, 01251], lr: 0.000534, loss: 0.4253
2022-09-21 11:12:14 - train: epoch 0017, iter [01000, 01251], lr: 0.000534, loss: 0.4414
2022-09-21 11:12:35 - train: epoch 0017, iter [01010, 01251], lr: 0.000534, loss: 0.4301
2022-09-21 11:12:56 - train: epoch 0017, iter [01020, 01251], lr: 0.000534, loss: 0.4410
2022-09-21 11:13:17 - train: epoch 0017, iter [01030, 01251], lr: 0.000535, loss: 0.4609
2022-09-21 11:13:38 - train: epoch 0017, iter [01040, 01251], lr: 0.000535, loss: 0.4277
2022-09-21 11:13:59 - train: epoch 0017, iter [01050, 01251], lr: 0.000535, loss: 0.4333
2022-09-21 11:14:20 - train: epoch 0017, iter [01060, 01251], lr: 0.000535, loss: 0.4360
2022-09-21 11:14:42 - train: epoch 0017, iter [01070, 01251], lr: 0.000536, loss: 0.4168
2022-09-21 11:15:03 - train: epoch 0017, iter [01080, 01251], lr: 0.000536, loss: 0.4334
2022-09-21 11:15:24 - train: epoch 0017, iter [01090, 01251], lr: 0.000536, loss: 0.4288
2022-09-21 11:15:45 - train: epoch 0017, iter [01100, 01251], lr: 0.000536, loss: 0.4386
2022-09-21 11:16:06 - train: epoch 0017, iter [01110, 01251], lr: 0.000537, loss: 0.4310
2022-09-21 11:16:27 - train: epoch 0017, iter [01120, 01251], lr: 0.000537, loss: 0.4372
2022-09-21 11:16:48 - train: epoch 0017, iter [01130, 01251], lr: 0.000537, loss: 0.4262
2022-09-21 11:17:09 - train: epoch 0017, iter [01140, 01251], lr: 0.000537, loss: 0.4334
2022-09-21 11:17:30 - train: epoch 0017, iter [01150, 01251], lr: 0.000538, loss: 0.4231
2022-09-21 11:17:51 - train: epoch 0017, iter [01160, 01251], lr: 0.000538, loss: 0.4458
2022-09-21 11:18:12 - train: epoch 0017, iter [01170, 01251], lr: 0.000538, loss: 0.4322
2022-09-21 11:18:34 - train: epoch 0017, iter [01180, 01251], lr: 0.000538, loss: 0.4536
2022-09-21 11:18:54 - train: epoch 0017, iter [01190, 01251], lr: 0.000539, loss: 0.4270
2022-09-21 11:19:15 - train: epoch 0017, iter [01200, 01251], lr: 0.000539, loss: 0.4418
2022-09-21 11:19:36 - train: epoch 0017, iter [01210, 01251], lr: 0.000539, loss: 0.4317
2022-09-21 11:19:58 - train: epoch 0017, iter [01220, 01251], lr: 0.000539, loss: 0.4315
2022-09-21 11:20:19 - train: epoch 0017, iter [01230, 01251], lr: 0.000539, loss: 0.4294
2022-09-21 11:20:40 - train: epoch 0017, iter [01240, 01251], lr: 0.000540, loss: 0.4187
2022-09-21 11:21:00 - train: epoch 0017, iter [01250, 01251], lr: 0.000540, loss: 0.4414
2022-09-21 11:21:05 - train: epoch 017, train_loss: 0.4355
2022-09-21 11:21:11 - until epoch: 017, best_loss: 0.4355
2022-09-21 11:21:11 - epoch 018 lr: 0.000540
2022-09-21 11:21:48 - train: epoch 0018, iter [00010, 01251], lr: 0.000540, loss: 0.4233
2022-09-21 11:22:09 - train: epoch 0018, iter [00020, 01251], lr: 0.000540, loss: 0.4387
2022-09-21 11:22:30 - train: epoch 0018, iter [00030, 01251], lr: 0.000541, loss: 0.4232
2022-09-21 11:22:51 - train: epoch 0018, iter [00040, 01251], lr: 0.000541, loss: 0.4273
2022-09-21 11:23:12 - train: epoch 0018, iter [00050, 01251], lr: 0.000541, loss: 0.4283
2022-09-21 11:23:33 - train: epoch 0018, iter [00060, 01251], lr: 0.000541, loss: 0.4422
2022-09-21 11:23:54 - train: epoch 0018, iter [00070, 01251], lr: 0.000542, loss: 0.4290
2022-09-21 11:24:16 - train: epoch 0018, iter [00080, 01251], lr: 0.000542, loss: 0.4451
2022-09-21 11:24:37 - train: epoch 0018, iter [00090, 01251], lr: 0.000542, loss: 0.4263
2022-09-21 11:24:59 - train: epoch 0018, iter [00100, 01251], lr: 0.000542, loss: 0.4094
2022-09-21 11:25:20 - train: epoch 0018, iter [00110, 01251], lr: 0.000543, loss: 0.4515
2022-09-21 11:25:41 - train: epoch 0018, iter [00120, 01251], lr: 0.000543, loss: 0.4239
2022-09-21 11:26:02 - train: epoch 0018, iter [00130, 01251], lr: 0.000543, loss: 0.4295
2022-09-21 11:26:23 - train: epoch 0018, iter [00140, 01251], lr: 0.000543, loss: 0.4322
2022-09-21 11:26:44 - train: epoch 0018, iter [00150, 01251], lr: 0.000544, loss: 0.4454
2022-09-21 11:27:05 - train: epoch 0018, iter [00160, 01251], lr: 0.000544, loss: 0.4280
2022-09-21 11:27:27 - train: epoch 0018, iter [00170, 01251], lr: 0.000544, loss: 0.4270
2022-09-21 11:27:48 - train: epoch 0018, iter [00180, 01251], lr: 0.000544, loss: 0.4400
2022-09-21 11:28:09 - train: epoch 0018, iter [00190, 01251], lr: 0.000545, loss: 0.4449
2022-09-21 11:28:31 - train: epoch 0018, iter [00200, 01251], lr: 0.000545, loss: 0.3971
2022-09-21 11:28:52 - train: epoch 0018, iter [00210, 01251], lr: 0.000545, loss: 0.4266
2022-09-21 11:29:13 - train: epoch 0018, iter [00220, 01251], lr: 0.000545, loss: 0.4388
2022-09-21 11:29:35 - train: epoch 0018, iter [00230, 01251], lr: 0.000546, loss: 0.4414
2022-09-21 11:29:56 - train: epoch 0018, iter [00240, 01251], lr: 0.000546, loss: 0.4339
2022-09-21 11:30:17 - train: epoch 0018, iter [00250, 01251], lr: 0.000546, loss: 0.4230
2022-09-21 11:30:39 - train: epoch 0018, iter [00260, 01251], lr: 0.000546, loss: 0.4478
2022-09-21 11:31:00 - train: epoch 0018, iter [00270, 01251], lr: 0.000546, loss: 0.4490
2022-09-21 11:31:22 - train: epoch 0018, iter [00280, 01251], lr: 0.000547, loss: 0.4318
2022-09-21 11:31:43 - train: epoch 0018, iter [00290, 01251], lr: 0.000547, loss: 0.4263
2022-09-21 11:32:04 - train: epoch 0018, iter [00300, 01251], lr: 0.000547, loss: 0.4166
2022-09-21 11:32:26 - train: epoch 0018, iter [00310, 01251], lr: 0.000547, loss: 0.4479
2022-09-21 11:32:47 - train: epoch 0018, iter [00320, 01251], lr: 0.000548, loss: 0.4462
2022-09-21 11:33:08 - train: epoch 0018, iter [00330, 01251], lr: 0.000548, loss: 0.4282
2022-09-21 11:33:30 - train: epoch 0018, iter [00340, 01251], lr: 0.000548, loss: 0.4301
2022-09-21 11:33:51 - train: epoch 0018, iter [00350, 01251], lr: 0.000548, loss: 0.4521
2022-09-21 11:34:13 - train: epoch 0018, iter [00360, 01251], lr: 0.000549, loss: 0.4528
2022-09-21 11:34:34 - train: epoch 0018, iter [00370, 01251], lr: 0.000549, loss: 0.4241
2022-09-21 11:34:55 - train: epoch 0018, iter [00380, 01251], lr: 0.000549, loss: 0.4470
2022-09-21 11:35:17 - train: epoch 0018, iter [00390, 01251], lr: 0.000549, loss: 0.4384
2022-09-21 11:35:38 - train: epoch 0018, iter [00400, 01251], lr: 0.000550, loss: 0.4332
2022-09-21 11:36:00 - train: epoch 0018, iter [00410, 01251], lr: 0.000550, loss: 0.4425
2022-09-21 11:36:21 - train: epoch 0018, iter [00420, 01251], lr: 0.000550, loss: 0.4267
2022-09-21 11:36:43 - train: epoch 0018, iter [00430, 01251], lr: 0.000550, loss: 0.4234
2022-09-21 11:37:04 - train: epoch 0018, iter [00440, 01251], lr: 0.000551, loss: 0.4359
2022-09-21 11:37:25 - train: epoch 0018, iter [00450, 01251], lr: 0.000551, loss: 0.4313
2022-09-21 11:37:47 - train: epoch 0018, iter [00460, 01251], lr: 0.000551, loss: 0.4098
2022-09-21 11:38:08 - train: epoch 0018, iter [00470, 01251], lr: 0.000551, loss: 0.4271
2022-09-21 11:38:29 - train: epoch 0018, iter [00480, 01251], lr: 0.000552, loss: 0.4518
2022-09-21 11:38:51 - train: epoch 0018, iter [00490, 01251], lr: 0.000552, loss: 0.4334
2022-09-21 11:39:12 - train: epoch 0018, iter [00500, 01251], lr: 0.000552, loss: 0.4264
2022-09-21 11:39:33 - train: epoch 0018, iter [00510, 01251], lr: 0.000552, loss: 0.4495
2022-09-21 11:39:55 - train: epoch 0018, iter [00520, 01251], lr: 0.000552, loss: 0.4523
2022-09-21 11:40:16 - train: epoch 0018, iter [00530, 01251], lr: 0.000553, loss: 0.4348
2022-09-21 11:40:37 - train: epoch 0018, iter [00540, 01251], lr: 0.000553, loss: 0.4370
2022-09-21 11:40:58 - train: epoch 0018, iter [00550, 01251], lr: 0.000553, loss: 0.4105
2022-09-21 11:41:19 - train: epoch 0018, iter [00560, 01251], lr: 0.000553, loss: 0.4529
2022-09-21 11:41:40 - train: epoch 0018, iter [00570, 01251], lr: 0.000554, loss: 0.4008
2022-09-21 11:42:01 - train: epoch 0018, iter [00580, 01251], lr: 0.000554, loss: 0.4253
2022-09-21 11:42:22 - train: epoch 0018, iter [00590, 01251], lr: 0.000554, loss: 0.4193
2022-09-21 11:42:44 - train: epoch 0018, iter [00600, 01251], lr: 0.000554, loss: 0.4109
2022-09-21 11:43:04 - train: epoch 0018, iter [00610, 01251], lr: 0.000555, loss: 0.4190
2022-09-21 11:43:25 - train: epoch 0018, iter [00620, 01251], lr: 0.000555, loss: 0.4390
2022-09-21 11:43:47 - train: epoch 0018, iter [00630, 01251], lr: 0.000555, loss: 0.4326
2022-09-21 11:44:08 - train: epoch 0018, iter [00640, 01251], lr: 0.000555, loss: 0.4295
2022-09-21 11:44:29 - train: epoch 0018, iter [00650, 01251], lr: 0.000556, loss: 0.4381
2022-09-21 11:44:50 - train: epoch 0018, iter [00660, 01251], lr: 0.000556, loss: 0.4334
2022-09-21 11:45:11 - train: epoch 0018, iter [00670, 01251], lr: 0.000556, loss: 0.4321
2022-09-21 11:45:32 - train: epoch 0018, iter [00680, 01251], lr: 0.000556, loss: 0.4233
2022-09-21 11:45:53 - train: epoch 0018, iter [00690, 01251], lr: 0.000557, loss: 0.4412
2022-09-21 11:46:14 - train: epoch 0018, iter [00700, 01251], lr: 0.000557, loss: 0.4488
2022-09-21 11:46:35 - train: epoch 0018, iter [00710, 01251], lr: 0.000557, loss: 0.4517
2022-09-21 11:46:57 - train: epoch 0018, iter [00720, 01251], lr: 0.000557, loss: 0.4336
2022-09-21 11:47:18 - train: epoch 0018, iter [00730, 01251], lr: 0.000558, loss: 0.4373
2022-09-21 11:47:39 - train: epoch 0018, iter [00740, 01251], lr: 0.000558, loss: 0.4199
2022-09-21 11:48:00 - train: epoch 0018, iter [00750, 01251], lr: 0.000558, loss: 0.4543
2022-09-21 11:48:21 - train: epoch 0018, iter [00760, 01251], lr: 0.000558, loss: 0.4334
2022-09-21 11:48:42 - train: epoch 0018, iter [00770, 01251], lr: 0.000558, loss: 0.4189
2022-09-21 11:49:03 - train: epoch 0018, iter [00780, 01251], lr: 0.000559, loss: 0.4433
2022-09-21 11:49:24 - train: epoch 0018, iter [00790, 01251], lr: 0.000559, loss: 0.4141
2022-09-21 11:49:45 - train: epoch 0018, iter [00800, 01251], lr: 0.000559, loss: 0.4183
2022-09-21 11:50:07 - train: epoch 0018, iter [00810, 01251], lr: 0.000559, loss: 0.4244
2022-09-21 11:50:28 - train: epoch 0018, iter [00820, 01251], lr: 0.000560, loss: 0.4291
2022-09-21 11:50:49 - train: epoch 0018, iter [00830, 01251], lr: 0.000560, loss: 0.4465
2022-09-21 11:51:10 - train: epoch 0018, iter [00840, 01251], lr: 0.000560, loss: 0.4370
2022-09-21 11:51:31 - train: epoch 0018, iter [00850, 01251], lr: 0.000560, loss: 0.4392
2022-09-21 11:51:52 - train: epoch 0018, iter [00860, 01251], lr: 0.000561, loss: 0.4329
2022-09-21 11:52:13 - train: epoch 0018, iter [00870, 01251], lr: 0.000561, loss: 0.4159
2022-09-21 11:52:34 - train: epoch 0018, iter [00880, 01251], lr: 0.000561, loss: 0.4340
2022-09-21 11:52:55 - train: epoch 0018, iter [00890, 01251], lr: 0.000561, loss: 0.4269
2022-09-21 11:53:16 - train: epoch 0018, iter [00900, 01251], lr: 0.000562, loss: 0.4360
2022-09-21 11:53:37 - train: epoch 0018, iter [00910, 01251], lr: 0.000562, loss: 0.4410
2022-09-21 11:53:58 - train: epoch 0018, iter [00920, 01251], lr: 0.000562, loss: 0.4347
2022-09-21 11:54:19 - train: epoch 0018, iter [00930, 01251], lr: 0.000562, loss: 0.4400
2022-09-21 11:54:40 - train: epoch 0018, iter [00940, 01251], lr: 0.000563, loss: 0.4339
2022-09-21 11:55:01 - train: epoch 0018, iter [00950, 01251], lr: 0.000563, loss: 0.4309
2022-09-21 11:55:22 - train: epoch 0018, iter [00960, 01251], lr: 0.000563, loss: 0.4204
2022-09-21 11:55:44 - train: epoch 0018, iter [00970, 01251], lr: 0.000563, loss: 0.4350
2022-09-21 11:56:05 - train: epoch 0018, iter [00980, 01251], lr: 0.000564, loss: 0.4511
2022-09-21 11:56:26 - train: epoch 0018, iter [00990, 01251], lr: 0.000564, loss: 0.4331
2022-09-21 11:56:48 - train: epoch 0018, iter [01000, 01251], lr: 0.000564, loss: 0.4341
2022-09-21 11:57:09 - train: epoch 0018, iter [01010, 01251], lr: 0.000564, loss: 0.4261
2022-09-21 11:57:30 - train: epoch 0018, iter [01020, 01251], lr: 0.000564, loss: 0.4346
2022-09-21 11:57:52 - train: epoch 0018, iter [01030, 01251], lr: 0.000565, loss: 0.4297
2022-09-21 11:58:13 - train: epoch 0018, iter [01040, 01251], lr: 0.000565, loss: 0.4414
2022-09-21 11:58:35 - train: epoch 0018, iter [01050, 01251], lr: 0.000565, loss: 0.4453
2022-09-21 11:58:56 - train: epoch 0018, iter [01060, 01251], lr: 0.000565, loss: 0.4306
2022-09-21 11:59:17 - train: epoch 0018, iter [01070, 01251], lr: 0.000566, loss: 0.4385
2022-09-21 11:59:39 - train: epoch 0018, iter [01080, 01251], lr: 0.000566, loss: 0.4684
2022-09-21 12:00:00 - train: epoch 0018, iter [01090, 01251], lr: 0.000566, loss: 0.4114
2022-09-21 12:00:21 - train: epoch 0018, iter [01100, 01251], lr: 0.000566, loss: 0.4460
2022-09-21 12:00:43 - train: epoch 0018, iter [01110, 01251], lr: 0.000567, loss: 0.4647
2022-09-21 12:01:04 - train: epoch 0018, iter [01120, 01251], lr: 0.000567, loss: 0.4289
2022-09-21 12:01:25 - train: epoch 0018, iter [01130, 01251], lr: 0.000567, loss: 0.4348
2022-09-21 12:01:47 - train: epoch 0018, iter [01140, 01251], lr: 0.000567, loss: 0.4197
2022-09-21 12:02:08 - train: epoch 0018, iter [01150, 01251], lr: 0.000568, loss: 0.4624
2022-09-21 12:02:30 - train: epoch 0018, iter [01160, 01251], lr: 0.000568, loss: 0.4445
2022-09-21 12:02:51 - train: epoch 0018, iter [01170, 01251], lr: 0.000568, loss: 0.4214
2022-09-21 12:03:12 - train: epoch 0018, iter [01180, 01251], lr: 0.000568, loss: 0.4367
2022-09-21 12:03:34 - train: epoch 0018, iter [01190, 01251], lr: 0.000569, loss: 0.4434
2022-09-21 12:03:55 - train: epoch 0018, iter [01200, 01251], lr: 0.000569, loss: 0.4411
2022-09-21 12:04:17 - train: epoch 0018, iter [01210, 01251], lr: 0.000569, loss: 0.4229
2022-09-21 12:04:38 - train: epoch 0018, iter [01220, 01251], lr: 0.000569, loss: 0.4280
2022-09-21 12:04:59 - train: epoch 0018, iter [01230, 01251], lr: 0.000569, loss: 0.4383
2022-09-21 12:05:21 - train: epoch 0018, iter [01240, 01251], lr: 0.000570, loss: 0.4264
2022-09-21 12:05:41 - train: epoch 0018, iter [01250, 01251], lr: 0.000570, loss: 0.4132
2022-09-21 12:05:46 - train: epoch 018, train_loss: 0.4341
2022-09-21 12:05:52 - until epoch: 018, best_loss: 0.4341
2022-09-21 12:05:52 - epoch 019 lr: 0.000570
2022-09-21 12:06:29 - train: epoch 0019, iter [00010, 01251], lr: 0.000570, loss: 0.4476
2022-09-21 12:06:50 - train: epoch 0019, iter [00020, 01251], lr: 0.000570, loss: 0.4482
2022-09-21 12:07:11 - train: epoch 0019, iter [00030, 01251], lr: 0.000571, loss: 0.4233
2022-09-21 12:07:33 - train: epoch 0019, iter [00040, 01251], lr: 0.000571, loss: 0.4313
2022-09-21 12:07:54 - train: epoch 0019, iter [00050, 01251], lr: 0.000571, loss: 0.4394
2022-09-21 12:08:15 - train: epoch 0019, iter [00060, 01251], lr: 0.000571, loss: 0.4343
2022-09-21 12:08:36 - train: epoch 0019, iter [00070, 01251], lr: 0.000572, loss: 0.4471
2022-09-21 12:08:57 - train: epoch 0019, iter [00080, 01251], lr: 0.000572, loss: 0.4189
2022-09-21 12:09:18 - train: epoch 0019, iter [00090, 01251], lr: 0.000572, loss: 0.4301
2022-09-21 12:09:39 - train: epoch 0019, iter [00100, 01251], lr: 0.000572, loss: 0.4386
2022-09-21 12:10:00 - train: epoch 0019, iter [00110, 01251], lr: 0.000573, loss: 0.4332
2022-09-21 12:10:21 - train: epoch 0019, iter [00120, 01251], lr: 0.000573, loss: 0.4141
2022-09-21 12:10:43 - train: epoch 0019, iter [00130, 01251], lr: 0.000573, loss: 0.4323
2022-09-21 12:11:04 - train: epoch 0019, iter [00140, 01251], lr: 0.000573, loss: 0.4194
2022-09-21 12:11:25 - train: epoch 0019, iter [00150, 01251], lr: 0.000574, loss: 0.4503
2022-09-21 12:11:46 - train: epoch 0019, iter [00160, 01251], lr: 0.000574, loss: 0.4502
2022-09-21 12:12:08 - train: epoch 0019, iter [00170, 01251], lr: 0.000574, loss: 0.4512
2022-09-21 12:12:29 - train: epoch 0019, iter [00180, 01251], lr: 0.000574, loss: 0.4097
2022-09-21 12:12:50 - train: epoch 0019, iter [00190, 01251], lr: 0.000575, loss: 0.4550
2022-09-21 12:13:10 - train: epoch 0019, iter [00200, 01251], lr: 0.000575, loss: 0.4370
2022-09-21 12:13:31 - train: epoch 0019, iter [00210, 01251], lr: 0.000575, loss: 0.4329
2022-09-21 12:13:52 - train: epoch 0019, iter [00220, 01251], lr: 0.000575, loss: 0.4351
2022-09-21 12:14:13 - train: epoch 0019, iter [00230, 01251], lr: 0.000576, loss: 0.4500
2022-09-21 12:14:34 - train: epoch 0019, iter [00240, 01251], lr: 0.000576, loss: 0.4280
2022-09-21 12:14:55 - train: epoch 0019, iter [00250, 01251], lr: 0.000576, loss: 0.4212
2022-09-21 12:15:16 - train: epoch 0019, iter [00260, 01251], lr: 0.000576, loss: 0.4444
2022-09-21 12:15:38 - train: epoch 0019, iter [00270, 01251], lr: 0.000576, loss: 0.4230
2022-09-21 12:15:59 - train: epoch 0019, iter [00280, 01251], lr: 0.000577, loss: 0.4363
2022-09-21 12:16:20 - train: epoch 0019, iter [00290, 01251], lr: 0.000577, loss: 0.4209
2022-09-21 12:16:41 - train: epoch 0019, iter [00300, 01251], lr: 0.000577, loss: 0.4263
2022-09-21 12:17:02 - train: epoch 0019, iter [00310, 01251], lr: 0.000577, loss: 0.4453
2022-09-21 12:17:23 - train: epoch 0019, iter [00320, 01251], lr: 0.000578, loss: 0.4433
2022-09-21 12:17:45 - train: epoch 0019, iter [00330, 01251], lr: 0.000578, loss: 0.4287
2022-09-21 12:18:06 - train: epoch 0019, iter [00340, 01251], lr: 0.000578, loss: 0.4394
2022-09-21 12:18:27 - train: epoch 0019, iter [00350, 01251], lr: 0.000578, loss: 0.4320
2022-09-21 12:18:48 - train: epoch 0019, iter [00360, 01251], lr: 0.000579, loss: 0.4415
2022-09-21 12:19:09 - train: epoch 0019, iter [00370, 01251], lr: 0.000579, loss: 0.4146
2022-09-21 12:19:30 - train: epoch 0019, iter [00380, 01251], lr: 0.000579, loss: 0.4319
2022-09-21 12:19:51 - train: epoch 0019, iter [00390, 01251], lr: 0.000579, loss: 0.4404
2022-09-21 12:20:12 - train: epoch 0019, iter [00400, 01251], lr: 0.000580, loss: 0.4357
2022-09-21 12:20:33 - train: epoch 0019, iter [00410, 01251], lr: 0.000580, loss: 0.4170
2022-09-21 12:20:54 - train: epoch 0019, iter [00420, 01251], lr: 0.000580, loss: 0.4411
2022-09-21 12:21:16 - train: epoch 0019, iter [00430, 01251], lr: 0.000580, loss: 0.4369
2022-09-21 12:21:37 - train: epoch 0019, iter [00440, 01251], lr: 0.000581, loss: 0.4272
2022-09-21 12:21:58 - train: epoch 0019, iter [00450, 01251], lr: 0.000581, loss: 0.4428
2022-09-21 12:22:19 - train: epoch 0019, iter [00460, 01251], lr: 0.000581, loss: 0.4175
2022-09-21 12:22:41 - train: epoch 0019, iter [00470, 01251], lr: 0.000581, loss: 0.4451
2022-09-21 12:23:02 - train: epoch 0019, iter [00480, 01251], lr: 0.000582, loss: 0.4287
2022-09-21 12:23:23 - train: epoch 0019, iter [00490, 01251], lr: 0.000582, loss: 0.4188
2022-09-21 12:23:44 - train: epoch 0019, iter [00500, 01251], lr: 0.000582, loss: 0.4072
2022-09-21 12:24:06 - train: epoch 0019, iter [00510, 01251], lr: 0.000582, loss: 0.4316
2022-09-21 12:24:27 - train: epoch 0019, iter [00520, 01251], lr: 0.000582, loss: 0.4433
2022-09-21 12:24:48 - train: epoch 0019, iter [00530, 01251], lr: 0.000583, loss: 0.4351
2022-09-21 12:25:09 - train: epoch 0019, iter [00540, 01251], lr: 0.000583, loss: 0.4317
2022-09-21 12:25:31 - train: epoch 0019, iter [00550, 01251], lr: 0.000583, loss: 0.4272
2022-09-21 12:25:52 - train: epoch 0019, iter [00560, 01251], lr: 0.000583, loss: 0.4214
2022-09-21 12:26:13 - train: epoch 0019, iter [00570, 01251], lr: 0.000584, loss: 0.4251
2022-09-21 12:26:34 - train: epoch 0019, iter [00580, 01251], lr: 0.000584, loss: 0.4494
2022-09-21 12:26:56 - train: epoch 0019, iter [00590, 01251], lr: 0.000584, loss: 0.4174
2022-09-21 12:27:17 - train: epoch 0019, iter [00600, 01251], lr: 0.000584, loss: 0.4405
2022-09-21 12:27:38 - train: epoch 0019, iter [00610, 01251], lr: 0.000585, loss: 0.4334
2022-09-21 12:27:59 - train: epoch 0019, iter [00620, 01251], lr: 0.000585, loss: 0.4306
2022-09-21 12:28:20 - train: epoch 0019, iter [00630, 01251], lr: 0.000585, loss: 0.4471
2022-09-21 12:28:42 - train: epoch 0019, iter [00640, 01251], lr: 0.000585, loss: 0.4341
2022-09-21 12:29:03 - train: epoch 0019, iter [00650, 01251], lr: 0.000586, loss: 0.4373
2022-09-21 12:29:24 - train: epoch 0019, iter [00660, 01251], lr: 0.000586, loss: 0.4365
2022-09-21 12:29:45 - train: epoch 0019, iter [00670, 01251], lr: 0.000586, loss: 0.4225
2022-09-21 12:30:06 - train: epoch 0019, iter [00680, 01251], lr: 0.000586, loss: 0.4194
2022-09-21 12:30:28 - train: epoch 0019, iter [00690, 01251], lr: 0.000587, loss: 0.4499
2022-09-21 12:30:49 - train: epoch 0019, iter [00700, 01251], lr: 0.000587, loss: 0.4286
2022-09-21 12:31:10 - train: epoch 0019, iter [00710, 01251], lr: 0.000587, loss: 0.4348
2022-09-21 12:31:32 - train: epoch 0019, iter [00720, 01251], lr: 0.000587, loss: 0.4456
2022-09-21 12:31:53 - train: epoch 0019, iter [00730, 01251], lr: 0.000588, loss: 0.4516
2022-09-21 12:32:14 - train: epoch 0019, iter [00740, 01251], lr: 0.000588, loss: 0.4437
2022-09-21 12:32:35 - train: epoch 0019, iter [00750, 01251], lr: 0.000588, loss: 0.4232
2022-09-21 12:32:56 - train: epoch 0019, iter [00760, 01251], lr: 0.000588, loss: 0.4732
2022-09-21 12:33:17 - train: epoch 0019, iter [00770, 01251], lr: 0.000588, loss: 0.4358
2022-09-21 12:33:38 - train: epoch 0019, iter [00780, 01251], lr: 0.000589, loss: 0.4189
2022-09-21 12:33:59 - train: epoch 0019, iter [00790, 01251], lr: 0.000589, loss: 0.4363
2022-09-21 12:34:20 - train: epoch 0019, iter [00800, 01251], lr: 0.000589, loss: 0.4384
2022-09-21 12:34:41 - train: epoch 0019, iter [00810, 01251], lr: 0.000589, loss: 0.4244
2022-09-21 12:35:02 - train: epoch 0019, iter [00820, 01251], lr: 0.000590, loss: 0.4269
2022-09-21 12:35:23 - train: epoch 0019, iter [00830, 01251], lr: 0.000590, loss: 0.4505
2022-09-21 12:35:44 - train: epoch 0019, iter [00840, 01251], lr: 0.000590, loss: 0.4138
2022-09-21 12:36:05 - train: epoch 0019, iter [00850, 01251], lr: 0.000590, loss: 0.4360
2022-09-21 12:36:26 - train: epoch 0019, iter [00860, 01251], lr: 0.000591, loss: 0.4152
2022-09-21 12:36:47 - train: epoch 0019, iter [00870, 01251], lr: 0.000591, loss: 0.4311
2022-09-21 12:37:08 - train: epoch 0019, iter [00880, 01251], lr: 0.000591, loss: 0.4314
2022-09-21 12:37:29 - train: epoch 0019, iter [00890, 01251], lr: 0.000591, loss: 0.4220
2022-09-21 12:37:49 - train: epoch 0019, iter [00900, 01251], lr: 0.000592, loss: 0.4200
2022-09-21 12:38:10 - train: epoch 0019, iter [00910, 01251], lr: 0.000592, loss: 0.4160
2022-09-21 12:38:31 - train: epoch 0019, iter [00920, 01251], lr: 0.000592, loss: 0.4515
2022-09-21 12:38:52 - train: epoch 0019, iter [00930, 01251], lr: 0.000592, loss: 0.4311
2022-09-21 12:39:13 - train: epoch 0019, iter [00940, 01251], lr: 0.000593, loss: 0.4258
2022-09-21 12:39:34 - train: epoch 0019, iter [00950, 01251], lr: 0.000593, loss: 0.4344
2022-09-21 12:39:55 - train: epoch 0019, iter [00960, 01251], lr: 0.000593, loss: 0.4309
2022-09-21 12:40:16 - train: epoch 0019, iter [00970, 01251], lr: 0.000593, loss: 0.4185
2022-09-21 12:40:37 - train: epoch 0019, iter [00980, 01251], lr: 0.000594, loss: 0.4354
2022-09-21 12:40:58 - train: epoch 0019, iter [00990, 01251], lr: 0.000594, loss: 0.4341
2022-09-21 12:41:19 - train: epoch 0019, iter [01000, 01251], lr: 0.000594, loss: 0.4388
2022-09-21 12:41:40 - train: epoch 0019, iter [01010, 01251], lr: 0.000594, loss: 0.4261
2022-09-21 12:42:01 - train: epoch 0019, iter [01020, 01251], lr: 0.000594, loss: 0.4276
2022-09-21 12:42:22 - train: epoch 0019, iter [01030, 01251], lr: 0.000595, loss: 0.4294
2022-09-21 12:42:43 - train: epoch 0019, iter [01040, 01251], lr: 0.000595, loss: 0.4186
2022-09-21 12:43:04 - train: epoch 0019, iter [01050, 01251], lr: 0.000595, loss: 0.4455
2022-09-21 12:43:25 - train: epoch 0019, iter [01060, 01251], lr: 0.000595, loss: 0.4372
2022-09-21 12:43:46 - train: epoch 0019, iter [01070, 01251], lr: 0.000596, loss: 0.4331
2022-09-21 12:44:07 - train: epoch 0019, iter [01080, 01251], lr: 0.000596, loss: 0.4284
2022-09-21 12:44:28 - train: epoch 0019, iter [01090, 01251], lr: 0.000596, loss: 0.4288
2022-09-21 12:44:49 - train: epoch 0019, iter [01100, 01251], lr: 0.000596, loss: 0.4433
2022-09-21 12:45:10 - train: epoch 0019, iter [01110, 01251], lr: 0.000597, loss: 0.4336
2022-09-21 12:45:30 - train: epoch 0019, iter [01120, 01251], lr: 0.000597, loss: 0.4266
2022-09-21 12:45:51 - train: epoch 0019, iter [01130, 01251], lr: 0.000597, loss: 0.4254
2022-09-21 12:46:12 - train: epoch 0019, iter [01140, 01251], lr: 0.000597, loss: 0.4259
2022-09-21 12:46:33 - train: epoch 0019, iter [01150, 01251], lr: 0.000598, loss: 0.4437
2022-09-21 12:46:54 - train: epoch 0019, iter [01160, 01251], lr: 0.000598, loss: 0.4341
2022-09-21 12:47:15 - train: epoch 0019, iter [01170, 01251], lr: 0.000598, loss: 0.4402
2022-09-21 12:47:36 - train: epoch 0019, iter [01180, 01251], lr: 0.000598, loss: 0.4374
2022-09-21 12:47:57 - train: epoch 0019, iter [01190, 01251], lr: 0.000599, loss: 0.4350
2022-09-21 12:48:18 - train: epoch 0019, iter [01200, 01251], lr: 0.000599, loss: 0.4331
2022-09-21 12:48:39 - train: epoch 0019, iter [01210, 01251], lr: 0.000599, loss: 0.4430
2022-09-21 12:49:00 - train: epoch 0019, iter [01220, 01251], lr: 0.000599, loss: 0.4477
2022-09-21 12:49:21 - train: epoch 0019, iter [01230, 01251], lr: 0.000599, loss: 0.4348
2022-09-21 12:49:42 - train: epoch 0019, iter [01240, 01251], lr: 0.000600, loss: 0.4357
2022-09-21 12:50:02 - train: epoch 0019, iter [01250, 01251], lr: 0.000600, loss: 0.4237
2022-09-21 12:50:07 - train: epoch 019, train_loss: 0.4328
2022-09-21 12:50:13 - until epoch: 019, best_loss: 0.4328
2022-09-21 12:50:13 - epoch 020 lr: 0.000600
2022-09-21 12:50:50 - train: epoch 0020, iter [00010, 01251], lr: 0.000600, loss: 0.4395
2022-09-21 12:51:11 - train: epoch 0020, iter [00020, 01251], lr: 0.000600, loss: 0.4323
2022-09-21 12:51:33 - train: epoch 0020, iter [00030, 01251], lr: 0.000601, loss: 0.4163
2022-09-21 12:51:54 - train: epoch 0020, iter [00040, 01251], lr: 0.000601, loss: 0.4126
2022-09-21 12:52:15 - train: epoch 0020, iter [00050, 01251], lr: 0.000601, loss: 0.4242
2022-09-21 12:52:36 - train: epoch 0020, iter [00060, 01251], lr: 0.000601, loss: 0.4194
2022-09-21 12:52:57 - train: epoch 0020, iter [00070, 01251], lr: 0.000602, loss: 0.4355
2022-09-21 12:53:18 - train: epoch 0020, iter [00080, 01251], lr: 0.000602, loss: 0.4348
2022-09-21 12:53:40 - train: epoch 0020, iter [00090, 01251], lr: 0.000602, loss: 0.4533
2022-09-21 12:54:01 - train: epoch 0020, iter [00100, 01251], lr: 0.000602, loss: 0.4263
2022-09-21 12:54:22 - train: epoch 0020, iter [00110, 01251], lr: 0.000603, loss: 0.4357
2022-09-21 12:54:43 - train: epoch 0020, iter [00120, 01251], lr: 0.000603, loss: 0.4479
2022-09-21 12:55:04 - train: epoch 0020, iter [00130, 01251], lr: 0.000603, loss: 0.4288
2022-09-21 12:55:25 - train: epoch 0020, iter [00140, 01251], lr: 0.000603, loss: 0.4248
2022-09-21 12:55:46 - train: epoch 0020, iter [00150, 01251], lr: 0.000604, loss: 0.4354
2022-09-21 12:56:08 - train: epoch 0020, iter [00160, 01251], lr: 0.000604, loss: 0.4346
2022-09-21 12:56:29 - train: epoch 0020, iter [00170, 01251], lr: 0.000604, loss: 0.4315
2022-09-21 12:56:50 - train: epoch 0020, iter [00180, 01251], lr: 0.000604, loss: 0.4178
2022-09-21 12:57:11 - train: epoch 0020, iter [00190, 01251], lr: 0.000605, loss: 0.4378
2022-09-21 12:57:32 - train: epoch 0020, iter [00200, 01251], lr: 0.000605, loss: 0.4126
2022-09-21 12:57:53 - train: epoch 0020, iter [00210, 01251], lr: 0.000605, loss: 0.4384
2022-09-21 12:58:14 - train: epoch 0020, iter [00220, 01251], lr: 0.000605, loss: 0.4290
2022-09-21 12:58:35 - train: epoch 0020, iter [00230, 01251], lr: 0.000606, loss: 0.4459
2022-09-21 12:58:57 - train: epoch 0020, iter [00240, 01251], lr: 0.000606, loss: 0.4357
2022-09-21 12:59:18 - train: epoch 0020, iter [00250, 01251], lr: 0.000606, loss: 0.4098
2022-09-21 12:59:39 - train: epoch 0020, iter [00260, 01251], lr: 0.000606, loss: 0.4585
2022-09-21 13:00:00 - train: epoch 0020, iter [00270, 01251], lr: 0.000606, loss: 0.4259
2022-09-21 13:00:21 - train: epoch 0020, iter [00280, 01251], lr: 0.000607, loss: 0.4361
2022-09-21 13:00:43 - train: epoch 0020, iter [00290, 01251], lr: 0.000607, loss: 0.4193
2022-09-21 13:01:03 - train: epoch 0020, iter [00300, 01251], lr: 0.000607, loss: 0.4382
2022-09-21 13:01:25 - train: epoch 0020, iter [00310, 01251], lr: 0.000607, loss: 0.4325
2022-09-21 13:01:46 - train: epoch 0020, iter [00320, 01251], lr: 0.000608, loss: 0.4255
2022-09-21 13:02:07 - train: epoch 0020, iter [00330, 01251], lr: 0.000608, loss: 0.4261
2022-09-21 13:02:28 - train: epoch 0020, iter [00340, 01251], lr: 0.000608, loss: 0.4481
2022-09-21 13:02:49 - train: epoch 0020, iter [00350, 01251], lr: 0.000608, loss: 0.4165
2022-09-21 13:03:10 - train: epoch 0020, iter [00360, 01251], lr: 0.000609, loss: 0.4442
2022-09-21 13:03:31 - train: epoch 0020, iter [00370, 01251], lr: 0.000609, loss: 0.4282
2022-09-21 13:03:52 - train: epoch 0020, iter [00380, 01251], lr: 0.000609, loss: 0.4358
2022-09-21 13:04:13 - train: epoch 0020, iter [00390, 01251], lr: 0.000609, loss: 0.4174
2022-09-21 13:04:34 - train: epoch 0020, iter [00400, 01251], lr: 0.000610, loss: 0.4436
2022-09-21 13:04:55 - train: epoch 0020, iter [00410, 01251], lr: 0.000610, loss: 0.4127
2022-09-21 13:05:16 - train: epoch 0020, iter [00420, 01251], lr: 0.000610, loss: 0.4202
2022-09-21 13:05:37 - train: epoch 0020, iter [00430, 01251], lr: 0.000610, loss: 0.4315
2022-09-21 13:05:59 - train: epoch 0020, iter [00440, 01251], lr: 0.000611, loss: 0.4113
2022-09-21 13:06:20 - train: epoch 0020, iter [00450, 01251], lr: 0.000611, loss: 0.4419
2022-09-21 13:06:41 - train: epoch 0020, iter [00460, 01251], lr: 0.000611, loss: 0.4248
2022-09-21 13:07:01 - train: epoch 0020, iter [00470, 01251], lr: 0.000611, loss: 0.4166
2022-09-21 13:07:22 - train: epoch 0020, iter [00480, 01251], lr: 0.000612, loss: 0.4345
2022-09-21 13:07:44 - train: epoch 0020, iter [00490, 01251], lr: 0.000612, loss: 0.4163
2022-09-21 13:08:05 - train: epoch 0020, iter [00500, 01251], lr: 0.000612, loss: 0.4259
2022-09-21 13:08:26 - train: epoch 0020, iter [00510, 01251], lr: 0.000612, loss: 0.4463
2022-09-21 13:08:47 - train: epoch 0020, iter [00520, 01251], lr: 0.000612, loss: 0.4170
2022-09-21 13:09:09 - train: epoch 0020, iter [00530, 01251], lr: 0.000613, loss: 0.4398
2022-09-21 13:09:30 - train: epoch 0020, iter [00540, 01251], lr: 0.000613, loss: 0.4498
2022-09-21 13:09:51 - train: epoch 0020, iter [00550, 01251], lr: 0.000613, loss: 0.4250
2022-09-21 13:10:12 - train: epoch 0020, iter [00560, 01251], lr: 0.000613, loss: 0.4312
2022-09-21 13:10:33 - train: epoch 0020, iter [00570, 01251], lr: 0.000614, loss: 0.4139
2022-09-21 13:10:54 - train: epoch 0020, iter [00580, 01251], lr: 0.000614, loss: 0.4243
2022-09-21 13:11:15 - train: epoch 0020, iter [00590, 01251], lr: 0.000614, loss: 0.4290
2022-09-21 13:11:36 - train: epoch 0020, iter [00600, 01251], lr: 0.000614, loss: 0.4233
2022-09-21 13:11:57 - train: epoch 0020, iter [00610, 01251], lr: 0.000615, loss: 0.4232
2022-09-21 13:12:18 - train: epoch 0020, iter [00620, 01251], lr: 0.000615, loss: 0.4255
2022-09-21 13:12:39 - train: epoch 0020, iter [00630, 01251], lr: 0.000615, loss: 0.4153
2022-09-21 13:13:00 - train: epoch 0020, iter [00640, 01251], lr: 0.000615, loss: 0.4483
2022-09-21 13:13:21 - train: epoch 0020, iter [00650, 01251], lr: 0.000616, loss: 0.4401
2022-09-21 13:13:42 - train: epoch 0020, iter [00660, 01251], lr: 0.000616, loss: 0.4423
2022-09-21 13:14:03 - train: epoch 0020, iter [00670, 01251], lr: 0.000616, loss: 0.4273
2022-09-21 13:14:25 - train: epoch 0020, iter [00680, 01251], lr: 0.000616, loss: 0.4494
2022-09-21 13:14:46 - train: epoch 0020, iter [00690, 01251], lr: 0.000617, loss: 0.4445
2022-09-21 13:15:07 - train: epoch 0020, iter [00700, 01251], lr: 0.000617, loss: 0.4149
2022-09-21 13:15:28 - train: epoch 0020, iter [00710, 01251], lr: 0.000617, loss: 0.4462
2022-09-21 13:15:49 - train: epoch 0020, iter [00720, 01251], lr: 0.000617, loss: 0.4436
2022-09-21 13:16:10 - train: epoch 0020, iter [00730, 01251], lr: 0.000618, loss: 0.4293
2022-09-21 13:16:30 - train: epoch 0020, iter [00740, 01251], lr: 0.000618, loss: 0.4145
2022-09-21 13:16:51 - train: epoch 0020, iter [00750, 01251], lr: 0.000618, loss: 0.4467
2022-09-21 13:17:12 - train: epoch 0020, iter [00760, 01251], lr: 0.000618, loss: 0.4212
2022-09-21 13:17:32 - train: epoch 0020, iter [00770, 01251], lr: 0.000618, loss: 0.4118
2022-09-21 13:17:53 - train: epoch 0020, iter [00780, 01251], lr: 0.000619, loss: 0.4348
2022-09-21 13:18:14 - train: epoch 0020, iter [00790, 01251], lr: 0.000619, loss: 0.4389
2022-09-21 13:18:35 - train: epoch 0020, iter [00800, 01251], lr: 0.000619, loss: 0.4303
2022-09-21 13:18:55 - train: epoch 0020, iter [00810, 01251], lr: 0.000619, loss: 0.4448
2022-09-21 13:19:16 - train: epoch 0020, iter [00820, 01251], lr: 0.000620, loss: 0.4485
2022-09-21 13:19:37 - train: epoch 0020, iter [00830, 01251], lr: 0.000620, loss: 0.4236
2022-09-21 13:19:58 - train: epoch 0020, iter [00840, 01251], lr: 0.000620, loss: 0.4320
2022-09-21 13:20:19 - train: epoch 0020, iter [00850, 01251], lr: 0.000620, loss: 0.4161
2022-09-21 13:20:40 - train: epoch 0020, iter [00860, 01251], lr: 0.000621, loss: 0.4428
2022-09-21 13:21:00 - train: epoch 0020, iter [00870, 01251], lr: 0.000621, loss: 0.4484
2022-09-21 13:21:21 - train: epoch 0020, iter [00880, 01251], lr: 0.000621, loss: 0.4422
2022-09-21 13:21:42 - train: epoch 0020, iter [00890, 01251], lr: 0.000621, loss: 0.4322
2022-09-21 13:22:03 - train: epoch 0020, iter [00900, 01251], lr: 0.000622, loss: 0.4471
2022-09-21 13:22:23 - train: epoch 0020, iter [00910, 01251], lr: 0.000622, loss: 0.4237
2022-09-21 13:22:44 - train: epoch 0020, iter [00920, 01251], lr: 0.000622, loss: 0.4341
2022-09-21 13:23:05 - train: epoch 0020, iter [00930, 01251], lr: 0.000622, loss: 0.4246
2022-09-21 13:23:25 - train: epoch 0020, iter [00940, 01251], lr: 0.000623, loss: 0.4364
2022-09-21 13:23:46 - train: epoch 0020, iter [00950, 01251], lr: 0.000623, loss: 0.4171
2022-09-21 13:24:06 - train: epoch 0020, iter [00960, 01251], lr: 0.000623, loss: 0.4264
2022-09-21 13:24:27 - train: epoch 0020, iter [00970, 01251], lr: 0.000623, loss: 0.4064
2022-09-21 13:24:48 - train: epoch 0020, iter [00980, 01251], lr: 0.000624, loss: 0.4124
2022-09-21 13:25:08 - train: epoch 0020, iter [00990, 01251], lr: 0.000624, loss: 0.4364
2022-09-21 13:25:29 - train: epoch 0020, iter [01000, 01251], lr: 0.000624, loss: 0.4326
2022-09-21 13:25:49 - train: epoch 0020, iter [01010, 01251], lr: 0.000624, loss: 0.4575
2022-09-21 13:26:10 - train: epoch 0020, iter [01020, 01251], lr: 0.000624, loss: 0.4210
2022-09-21 13:26:30 - train: epoch 0020, iter [01030, 01251], lr: 0.000625, loss: 0.4203
2022-09-21 13:26:51 - train: epoch 0020, iter [01040, 01251], lr: 0.000625, loss: 0.4226
2022-09-21 13:27:12 - train: epoch 0020, iter [01050, 01251], lr: 0.000625, loss: 0.4391
2022-09-21 13:27:32 - train: epoch 0020, iter [01060, 01251], lr: 0.000625, loss: 0.4446
2022-09-21 13:27:53 - train: epoch 0020, iter [01070, 01251], lr: 0.000626, loss: 0.4311
2022-09-21 13:28:13 - train: epoch 0020, iter [01080, 01251], lr: 0.000626, loss: 0.4331
2022-09-21 13:28:34 - train: epoch 0020, iter [01090, 01251], lr: 0.000626, loss: 0.4319
2022-09-21 13:28:55 - train: epoch 0020, iter [01100, 01251], lr: 0.000626, loss: 0.4436
2022-09-21 13:29:15 - train: epoch 0020, iter [01110, 01251], lr: 0.000627, loss: 0.4310
2022-09-21 13:29:36 - train: epoch 0020, iter [01120, 01251], lr: 0.000627, loss: 0.4431
2022-09-21 13:29:57 - train: epoch 0020, iter [01130, 01251], lr: 0.000627, loss: 0.4311
2022-09-21 13:30:17 - train: epoch 0020, iter [01140, 01251], lr: 0.000627, loss: 0.4415
2022-09-21 13:30:38 - train: epoch 0020, iter [01150, 01251], lr: 0.000628, loss: 0.4239
2022-09-21 13:30:58 - train: epoch 0020, iter [01160, 01251], lr: 0.000628, loss: 0.4293
2022-09-21 13:31:19 - train: epoch 0020, iter [01170, 01251], lr: 0.000628, loss: 0.4227
2022-09-21 13:31:40 - train: epoch 0020, iter [01180, 01251], lr: 0.000628, loss: 0.4349
2022-09-21 13:32:00 - train: epoch 0020, iter [01190, 01251], lr: 0.000629, loss: 0.4265
2022-09-21 13:32:20 - train: epoch 0020, iter [01200, 01251], lr: 0.000629, loss: 0.4277
2022-09-21 13:32:41 - train: epoch 0020, iter [01210, 01251], lr: 0.000629, loss: 0.4315
2022-09-21 13:33:02 - train: epoch 0020, iter [01220, 01251], lr: 0.000629, loss: 0.4268
2022-09-21 13:33:22 - train: epoch 0020, iter [01230, 01251], lr: 0.000629, loss: 0.4189
2022-09-21 13:33:43 - train: epoch 0020, iter [01240, 01251], lr: 0.000630, loss: 0.4254
2022-09-21 13:34:03 - train: epoch 0020, iter [01250, 01251], lr: 0.000630, loss: 0.4587
2022-09-21 13:34:07 - train: epoch 020, train_loss: 0.4317
2022-09-21 13:34:11 - until epoch: 020, best_loss: 0.4317
2022-09-21 13:34:11 - epoch 021 lr: 0.000630
2022-09-21 13:34:47 - train: epoch 0021, iter [00010, 01251], lr: 0.000630, loss: 0.4243
2022-09-21 13:35:08 - train: epoch 0021, iter [00020, 01251], lr: 0.000630, loss: 0.4326
2022-09-21 13:35:28 - train: epoch 0021, iter [00030, 01251], lr: 0.000631, loss: 0.4329
2022-09-21 13:35:48 - train: epoch 0021, iter [00040, 01251], lr: 0.000631, loss: 0.4275
2022-09-21 13:36:09 - train: epoch 0021, iter [00050, 01251], lr: 0.000631, loss: 0.4152
2022-09-21 13:36:30 - train: epoch 0021, iter [00060, 01251], lr: 0.000631, loss: 0.4230
2022-09-21 13:36:50 - train: epoch 0021, iter [00070, 01251], lr: 0.000632, loss: 0.4369
2022-09-21 13:37:11 - train: epoch 0021, iter [00080, 01251], lr: 0.000632, loss: 0.4420
2022-09-21 13:37:32 - train: epoch 0021, iter [00090, 01251], lr: 0.000632, loss: 0.4472
2022-09-21 13:37:52 - train: epoch 0021, iter [00100, 01251], lr: 0.000632, loss: 0.4435
2022-09-21 13:38:13 - train: epoch 0021, iter [00110, 01251], lr: 0.000633, loss: 0.4272
2022-09-21 13:38:34 - train: epoch 0021, iter [00120, 01251], lr: 0.000633, loss: 0.4397
2022-09-21 13:38:54 - train: epoch 0021, iter [00130, 01251], lr: 0.000633, loss: 0.4327
2022-09-21 13:39:15 - train: epoch 0021, iter [00140, 01251], lr: 0.000633, loss: 0.4479
2022-09-21 13:39:36 - train: epoch 0021, iter [00150, 01251], lr: 0.000634, loss: 0.4179
2022-09-21 13:39:57 - train: epoch 0021, iter [00160, 01251], lr: 0.000634, loss: 0.4208
2022-09-21 13:40:17 - train: epoch 0021, iter [00170, 01251], lr: 0.000634, loss: 0.4311
2022-09-21 13:40:38 - train: epoch 0021, iter [00180, 01251], lr: 0.000634, loss: 0.4150
2022-09-21 13:40:59 - train: epoch 0021, iter [00190, 01251], lr: 0.000635, loss: 0.4345
2022-09-21 13:41:20 - train: epoch 0021, iter [00200, 01251], lr: 0.000635, loss: 0.4350
2022-09-21 13:41:40 - train: epoch 0021, iter [00210, 01251], lr: 0.000635, loss: 0.4495
2022-09-21 13:42:01 - train: epoch 0021, iter [00220, 01251], lr: 0.000635, loss: 0.4273
2022-09-21 13:42:22 - train: epoch 0021, iter [00230, 01251], lr: 0.000636, loss: 0.4097
2022-09-21 13:42:42 - train: epoch 0021, iter [00240, 01251], lr: 0.000636, loss: 0.4318
2022-09-21 13:43:03 - train: epoch 0021, iter [00250, 01251], lr: 0.000636, loss: 0.4477
2022-09-21 13:43:24 - train: epoch 0021, iter [00260, 01251], lr: 0.000636, loss: 0.4317
2022-09-21 13:43:44 - train: epoch 0021, iter [00270, 01251], lr: 0.000636, loss: 0.4343
2022-09-21 13:44:05 - train: epoch 0021, iter [00280, 01251], lr: 0.000637, loss: 0.4240
2022-09-21 13:44:26 - train: epoch 0021, iter [00290, 01251], lr: 0.000637, loss: 0.4300
2022-09-21 13:44:46 - train: epoch 0021, iter [00300, 01251], lr: 0.000637, loss: 0.4334
2022-09-21 13:45:07 - train: epoch 0021, iter [00310, 01251], lr: 0.000637, loss: 0.4213
2022-09-21 13:45:27 - train: epoch 0021, iter [00320, 01251], lr: 0.000638, loss: 0.4168
2022-09-21 13:45:48 - train: epoch 0021, iter [00330, 01251], lr: 0.000638, loss: 0.4182
2022-09-21 13:46:09 - train: epoch 0021, iter [00340, 01251], lr: 0.000638, loss: 0.4443
2022-09-21 13:46:30 - train: epoch 0021, iter [00350, 01251], lr: 0.000638, loss: 0.4229
2022-09-21 13:46:50 - train: epoch 0021, iter [00360, 01251], lr: 0.000639, loss: 0.4079
2022-09-21 13:47:11 - train: epoch 0021, iter [00370, 01251], lr: 0.000639, loss: 0.4320
2022-09-21 13:47:32 - train: epoch 0021, iter [00380, 01251], lr: 0.000639, loss: 0.4360
2022-09-21 13:47:52 - train: epoch 0021, iter [00390, 01251], lr: 0.000639, loss: 0.4366
2022-09-21 13:48:13 - train: epoch 0021, iter [00400, 01251], lr: 0.000640, loss: 0.4180
2022-09-21 13:48:34 - train: epoch 0021, iter [00410, 01251], lr: 0.000640, loss: 0.4291
2022-09-21 13:48:54 - train: epoch 0021, iter [00420, 01251], lr: 0.000640, loss: 0.4177
2022-09-21 13:49:15 - train: epoch 0021, iter [00430, 01251], lr: 0.000640, loss: 0.4296
2022-09-21 13:49:36 - train: epoch 0021, iter [00440, 01251], lr: 0.000641, loss: 0.4288
2022-09-21 13:49:56 - train: epoch 0021, iter [00450, 01251], lr: 0.000641, loss: 0.4306
2022-09-21 13:50:17 - train: epoch 0021, iter [00460, 01251], lr: 0.000641, loss: 0.4158
2022-09-21 13:50:37 - train: epoch 0021, iter [00470, 01251], lr: 0.000641, loss: 0.4138
2022-09-21 13:50:58 - train: epoch 0021, iter [00480, 01251], lr: 0.000642, loss: 0.4406
2022-09-21 13:51:19 - train: epoch 0021, iter [00490, 01251], lr: 0.000642, loss: 0.4426
2022-09-21 13:51:39 - train: epoch 0021, iter [00500, 01251], lr: 0.000642, loss: 0.4144
2022-09-21 13:52:00 - train: epoch 0021, iter [00510, 01251], lr: 0.000642, loss: 0.4409
2022-09-21 13:52:21 - train: epoch 0021, iter [00520, 01251], lr: 0.000642, loss: 0.4178
2022-09-21 13:52:41 - train: epoch 0021, iter [00530, 01251], lr: 0.000643, loss: 0.4279
2022-09-21 13:53:02 - train: epoch 0021, iter [00540, 01251], lr: 0.000643, loss: 0.4273
2022-09-21 13:53:23 - train: epoch 0021, iter [00550, 01251], lr: 0.000643, loss: 0.4279
2022-09-21 13:53:44 - train: epoch 0021, iter [00560, 01251], lr: 0.000643, loss: 0.4347
2022-09-21 13:54:04 - train: epoch 0021, iter [00570, 01251], lr: 0.000644, loss: 0.4373
2022-09-21 13:54:25 - train: epoch 0021, iter [00580, 01251], lr: 0.000644, loss: 0.4391
2022-09-21 13:54:46 - train: epoch 0021, iter [00590, 01251], lr: 0.000644, loss: 0.4347
2022-09-21 13:55:06 - train: epoch 0021, iter [00600, 01251], lr: 0.000644, loss: 0.4303
2022-09-21 13:55:27 - train: epoch 0021, iter [00610, 01251], lr: 0.000645, loss: 0.4459
2022-09-21 13:55:48 - train: epoch 0021, iter [00620, 01251], lr: 0.000645, loss: 0.4227
2022-09-21 13:56:09 - train: epoch 0021, iter [00630, 01251], lr: 0.000645, loss: 0.4478
2022-09-21 13:56:29 - train: epoch 0021, iter [00640, 01251], lr: 0.000645, loss: 0.4353
2022-09-21 13:56:50 - train: epoch 0021, iter [00650, 01251], lr: 0.000646, loss: 0.4455
2022-09-21 13:57:10 - train: epoch 0021, iter [00660, 01251], lr: 0.000646, loss: 0.4372
2022-09-21 13:57:31 - train: epoch 0021, iter [00670, 01251], lr: 0.000646, loss: 0.4196
2022-09-21 13:57:52 - train: epoch 0021, iter [00680, 01251], lr: 0.000646, loss: 0.4266
2022-09-21 13:58:13 - train: epoch 0021, iter [00690, 01251], lr: 0.000647, loss: 0.4317
2022-09-21 13:58:33 - train: epoch 0021, iter [00700, 01251], lr: 0.000647, loss: 0.4300
2022-09-21 13:58:54 - train: epoch 0021, iter [00710, 01251], lr: 0.000647, loss: 0.4250
2022-09-21 13:59:15 - train: epoch 0021, iter [00720, 01251], lr: 0.000647, loss: 0.4146
2022-09-21 13:59:36 - train: epoch 0021, iter [00730, 01251], lr: 0.000648, loss: 0.4269
2022-09-21 13:59:56 - train: epoch 0021, iter [00740, 01251], lr: 0.000648, loss: 0.4269
2022-09-21 14:00:17 - train: epoch 0021, iter [00750, 01251], lr: 0.000648, loss: 0.4263
2022-09-21 14:00:38 - train: epoch 0021, iter [00760, 01251], lr: 0.000648, loss: 0.4267
2022-09-21 14:00:58 - train: epoch 0021, iter [00770, 01251], lr: 0.000648, loss: 0.4534
2022-09-21 14:01:19 - train: epoch 0021, iter [00780, 01251], lr: 0.000649, loss: 0.4195
2022-09-21 14:01:40 - train: epoch 0021, iter [00790, 01251], lr: 0.000649, loss: 0.4262
2022-09-21 14:02:00 - train: epoch 0021, iter [00800, 01251], lr: 0.000649, loss: 0.4144
2022-09-21 14:02:21 - train: epoch 0021, iter [00810, 01251], lr: 0.000649, loss: 0.4415
2022-09-21 14:02:42 - train: epoch 0021, iter [00820, 01251], lr: 0.000650, loss: 0.3993
2022-09-21 14:03:03 - train: epoch 0021, iter [00830, 01251], lr: 0.000650, loss: 0.4356
2022-09-21 14:03:24 - train: epoch 0021, iter [00840, 01251], lr: 0.000650, loss: 0.4393
2022-09-21 14:03:45 - train: epoch 0021, iter [00850, 01251], lr: 0.000650, loss: 0.4258
2022-09-21 14:04:06 - train: epoch 0021, iter [00860, 01251], lr: 0.000651, loss: 0.4459
2022-09-21 14:04:27 - train: epoch 0021, iter [00870, 01251], lr: 0.000651, loss: 0.4151
2022-09-21 14:04:48 - train: epoch 0021, iter [00880, 01251], lr: 0.000651, loss: 0.4490
2022-09-21 14:05:09 - train: epoch 0021, iter [00890, 01251], lr: 0.000651, loss: 0.4436
2022-09-21 14:05:30 - train: epoch 0021, iter [00900, 01251], lr: 0.000652, loss: 0.4480
2022-09-21 14:05:52 - train: epoch 0021, iter [00910, 01251], lr: 0.000652, loss: 0.4315
2022-09-21 14:06:13 - train: epoch 0021, iter [00920, 01251], lr: 0.000652, loss: 0.4265
2022-09-21 14:06:34 - train: epoch 0021, iter [00930, 01251], lr: 0.000652, loss: 0.4493
2022-09-21 14:06:55 - train: epoch 0021, iter [00940, 01251], lr: 0.000653, loss: 0.4301
2022-09-21 14:07:16 - train: epoch 0021, iter [00950, 01251], lr: 0.000653, loss: 0.4312
2022-09-21 14:07:37 - train: epoch 0021, iter [00960, 01251], lr: 0.000653, loss: 0.4508
2022-09-21 14:07:58 - train: epoch 0021, iter [00970, 01251], lr: 0.000653, loss: 0.4385
2022-09-21 14:08:19 - train: epoch 0021, iter [00980, 01251], lr: 0.000654, loss: 0.4278
2022-09-21 14:08:39 - train: epoch 0021, iter [00990, 01251], lr: 0.000654, loss: 0.4143
2022-09-21 14:09:00 - train: epoch 0021, iter [01000, 01251], lr: 0.000654, loss: 0.4364
2022-09-21 14:09:21 - train: epoch 0021, iter [01010, 01251], lr: 0.000654, loss: 0.4254
2022-09-21 14:09:42 - train: epoch 0021, iter [01020, 01251], lr: 0.000654, loss: 0.4390
2022-09-21 14:10:03 - train: epoch 0021, iter [01030, 01251], lr: 0.000655, loss: 0.4131
2022-09-21 14:10:24 - train: epoch 0021, iter [01040, 01251], lr: 0.000655, loss: 0.4230
2022-09-21 14:10:46 - train: epoch 0021, iter [01050, 01251], lr: 0.000655, loss: 0.4377
2022-09-21 14:11:07 - train: epoch 0021, iter [01060, 01251], lr: 0.000655, loss: 0.4320
2022-09-21 14:11:29 - train: epoch 0021, iter [01070, 01251], lr: 0.000656, loss: 0.4167
2022-09-21 14:11:50 - train: epoch 0021, iter [01080, 01251], lr: 0.000656, loss: 0.4382
2022-09-21 14:12:11 - train: epoch 0021, iter [01090, 01251], lr: 0.000656, loss: 0.4207
2022-09-21 14:12:32 - train: epoch 0021, iter [01100, 01251], lr: 0.000656, loss: 0.4386
2022-09-21 14:12:54 - train: epoch 0021, iter [01110, 01251], lr: 0.000657, loss: 0.4336
2022-09-21 14:13:15 - train: epoch 0021, iter [01120, 01251], lr: 0.000657, loss: 0.4611
2022-09-21 14:13:36 - train: epoch 0021, iter [01130, 01251], lr: 0.000657, loss: 0.4256
2022-09-21 14:13:58 - train: epoch 0021, iter [01140, 01251], lr: 0.000657, loss: 0.4256
2022-09-21 14:14:19 - train: epoch 0021, iter [01150, 01251], lr: 0.000658, loss: 0.4251
2022-09-21 14:14:41 - train: epoch 0021, iter [01160, 01251], lr: 0.000658, loss: 0.4249
2022-09-21 14:15:02 - train: epoch 0021, iter [01170, 01251], lr: 0.000658, loss: 0.4303
2022-09-21 14:15:23 - train: epoch 0021, iter [01180, 01251], lr: 0.000658, loss: 0.4182
2022-09-21 14:15:45 - train: epoch 0021, iter [01190, 01251], lr: 0.000659, loss: 0.4217
2022-09-21 14:16:06 - train: epoch 0021, iter [01200, 01251], lr: 0.000659, loss: 0.4362
2022-09-21 14:16:28 - train: epoch 0021, iter [01210, 01251], lr: 0.000659, loss: 0.4278
2022-09-21 14:16:49 - train: epoch 0021, iter [01220, 01251], lr: 0.000659, loss: 0.4164
2022-09-21 14:17:10 - train: epoch 0021, iter [01230, 01251], lr: 0.000659, loss: 0.4245
2022-09-21 14:17:32 - train: epoch 0021, iter [01240, 01251], lr: 0.000660, loss: 0.4153
2022-09-21 14:17:52 - train: epoch 0021, iter [01250, 01251], lr: 0.000660, loss: 0.4374
2022-09-21 14:17:56 - train: epoch 021, train_loss: 0.4306
2022-09-21 14:18:01 - until epoch: 021, best_loss: 0.4306
2022-09-21 14:18:01 - epoch 022 lr: 0.000660
2022-09-21 14:18:38 - train: epoch 0022, iter [00010, 01251], lr: 0.000660, loss: 0.4502
2022-09-21 14:19:00 - train: epoch 0022, iter [00020, 01251], lr: 0.000660, loss: 0.4491
2022-09-21 14:19:21 - train: epoch 0022, iter [00030, 01251], lr: 0.000661, loss: 0.4258
2022-09-21 14:19:42 - train: epoch 0022, iter [00040, 01251], lr: 0.000661, loss: 0.4155
2022-09-21 14:20:03 - train: epoch 0022, iter [00050, 01251], lr: 0.000661, loss: 0.4390
2022-09-21 14:20:24 - train: epoch 0022, iter [00060, 01251], lr: 0.000661, loss: 0.4596
2022-09-21 14:20:46 - train: epoch 0022, iter [00070, 01251], lr: 0.000662, loss: 0.4208
2022-09-21 14:21:07 - train: epoch 0022, iter [00080, 01251], lr: 0.000662, loss: 0.4333
2022-09-21 14:21:28 - train: epoch 0022, iter [00090, 01251], lr: 0.000662, loss: 0.4265
2022-09-21 14:21:50 - train: epoch 0022, iter [00100, 01251], lr: 0.000662, loss: 0.4150
2022-09-21 14:22:12 - train: epoch 0022, iter [00110, 01251], lr: 0.000663, loss: 0.4543
2022-09-21 14:22:33 - train: epoch 0022, iter [00120, 01251], lr: 0.000663, loss: 0.4437
2022-09-21 14:22:54 - train: epoch 0022, iter [00130, 01251], lr: 0.000663, loss: 0.4422
2022-09-21 14:23:15 - train: epoch 0022, iter [00140, 01251], lr: 0.000663, loss: 0.4516
2022-09-21 14:23:36 - train: epoch 0022, iter [00150, 01251], lr: 0.000664, loss: 0.4067
2022-09-21 14:23:57 - train: epoch 0022, iter [00160, 01251], lr: 0.000664, loss: 0.4259
2022-09-21 14:24:18 - train: epoch 0022, iter [00170, 01251], lr: 0.000664, loss: 0.4323
2022-09-21 14:24:39 - train: epoch 0022, iter [00180, 01251], lr: 0.000664, loss: 0.4302
2022-09-21 14:25:01 - train: epoch 0022, iter [00190, 01251], lr: 0.000665, loss: 0.4390
2022-09-21 14:25:22 - train: epoch 0022, iter [00200, 01251], lr: 0.000665, loss: 0.4458
2022-09-21 14:25:44 - train: epoch 0022, iter [00210, 01251], lr: 0.000665, loss: 0.4329
2022-09-21 14:26:06 - train: epoch 0022, iter [00220, 01251], lr: 0.000665, loss: 0.4252
2022-09-21 14:26:27 - train: epoch 0022, iter [00230, 01251], lr: 0.000666, loss: 0.4331
2022-09-21 14:26:49 - train: epoch 0022, iter [00240, 01251], lr: 0.000666, loss: 0.4317
2022-09-21 14:27:11 - train: epoch 0022, iter [00250, 01251], lr: 0.000666, loss: 0.4510
2022-09-21 14:27:33 - train: epoch 0022, iter [00260, 01251], lr: 0.000666, loss: 0.4289
2022-09-21 14:27:55 - train: epoch 0022, iter [00270, 01251], lr: 0.000666, loss: 0.4389
2022-09-21 14:28:17 - train: epoch 0022, iter [00280, 01251], lr: 0.000667, loss: 0.4314
2022-09-21 14:28:38 - train: epoch 0022, iter [00290, 01251], lr: 0.000667, loss: 0.4438
2022-09-21 14:29:00 - train: epoch 0022, iter [00300, 01251], lr: 0.000667, loss: 0.4237
2022-09-21 14:29:22 - train: epoch 0022, iter [00310, 01251], lr: 0.000667, loss: 0.4346
2022-09-21 14:29:44 - train: epoch 0022, iter [00320, 01251], lr: 0.000668, loss: 0.4419
2022-09-21 14:30:06 - train: epoch 0022, iter [00330, 01251], lr: 0.000668, loss: 0.4348
2022-09-21 14:30:28 - train: epoch 0022, iter [00340, 01251], lr: 0.000668, loss: 0.4045
2022-09-21 14:30:50 - train: epoch 0022, iter [00350, 01251], lr: 0.000668, loss: 0.4199
2022-09-21 14:31:12 - train: epoch 0022, iter [00360, 01251], lr: 0.000669, loss: 0.4269
2022-09-21 14:31:34 - train: epoch 0022, iter [00370, 01251], lr: 0.000669, loss: 0.4320
2022-09-21 14:31:56 - train: epoch 0022, iter [00380, 01251], lr: 0.000669, loss: 0.4214
2022-09-21 14:32:18 - train: epoch 0022, iter [00390, 01251], lr: 0.000669, loss: 0.4369
2022-09-21 14:32:40 - train: epoch 0022, iter [00400, 01251], lr: 0.000670, loss: 0.3957
2022-09-21 14:33:02 - train: epoch 0022, iter [00410, 01251], lr: 0.000670, loss: 0.4337
2022-09-21 14:33:24 - train: epoch 0022, iter [00420, 01251], lr: 0.000670, loss: 0.4347
2022-09-21 14:33:46 - train: epoch 0022, iter [00430, 01251], lr: 0.000670, loss: 0.4341
2022-09-21 14:34:08 - train: epoch 0022, iter [00440, 01251], lr: 0.000671, loss: 0.4311
2022-09-21 14:34:30 - train: epoch 0022, iter [00450, 01251], lr: 0.000671, loss: 0.4182
2022-09-21 14:34:52 - train: epoch 0022, iter [00460, 01251], lr: 0.000671, loss: 0.4318
2022-09-21 14:35:14 - train: epoch 0022, iter [00470, 01251], lr: 0.000671, loss: 0.4465
2022-09-21 14:35:37 - train: epoch 0022, iter [00480, 01251], lr: 0.000672, loss: 0.4371
2022-09-21 14:35:58 - train: epoch 0022, iter [00490, 01251], lr: 0.000672, loss: 0.4317
2022-09-21 14:36:20 - train: epoch 0022, iter [00500, 01251], lr: 0.000672, loss: 0.4313
2022-09-21 14:36:43 - train: epoch 0022, iter [00510, 01251], lr: 0.000672, loss: 0.4387
2022-09-21 14:37:04 - train: epoch 0022, iter [00520, 01251], lr: 0.000672, loss: 0.4310
2022-09-21 14:37:25 - train: epoch 0022, iter [00530, 01251], lr: 0.000673, loss: 0.4390
2022-09-21 14:37:46 - train: epoch 0022, iter [00540, 01251], lr: 0.000673, loss: 0.4275
2022-09-21 14:38:07 - train: epoch 0022, iter [00550, 01251], lr: 0.000673, loss: 0.4460
2022-09-21 14:38:28 - train: epoch 0022, iter [00560, 01251], lr: 0.000673, loss: 0.4302
2022-09-21 14:38:50 - train: epoch 0022, iter [00570, 01251], lr: 0.000674, loss: 0.4134
2022-09-21 14:39:11 - train: epoch 0022, iter [00580, 01251], lr: 0.000674, loss: 0.4256
2022-09-21 14:39:32 - train: epoch 0022, iter [00590, 01251], lr: 0.000674, loss: 0.4277
2022-09-21 14:39:53 - train: epoch 0022, iter [00600, 01251], lr: 0.000674, loss: 0.4038
2022-09-21 14:40:15 - train: epoch 0022, iter [00610, 01251], lr: 0.000675, loss: 0.4137
2022-09-21 14:40:36 - train: epoch 0022, iter [00620, 01251], lr: 0.000675, loss: 0.4303
2022-09-21 14:40:57 - train: epoch 0022, iter [00630, 01251], lr: 0.000675, loss: 0.4332
2022-09-21 14:41:19 - train: epoch 0022, iter [00640, 01251], lr: 0.000675, loss: 0.4167
2022-09-21 14:41:40 - train: epoch 0022, iter [00650, 01251], lr: 0.000676, loss: 0.4275
2022-09-21 14:42:01 - train: epoch 0022, iter [00660, 01251], lr: 0.000676, loss: 0.4352
2022-09-21 14:42:23 - train: epoch 0022, iter [00670, 01251], lr: 0.000676, loss: 0.4253
2022-09-21 14:42:44 - train: epoch 0022, iter [00680, 01251], lr: 0.000676, loss: 0.4287
2022-09-21 14:43:05 - train: epoch 0022, iter [00690, 01251], lr: 0.000677, loss: 0.4444
2022-09-21 14:43:27 - train: epoch 0022, iter [00700, 01251], lr: 0.000677, loss: 0.4406
2022-09-21 14:43:48 - train: epoch 0022, iter [00710, 01251], lr: 0.000677, loss: 0.4427
2022-09-21 14:44:09 - train: epoch 0022, iter [00720, 01251], lr: 0.000677, loss: 0.4222
2022-09-21 14:44:31 - train: epoch 0022, iter [00730, 01251], lr: 0.000678, loss: 0.4322
2022-09-21 14:44:52 - train: epoch 0022, iter [00740, 01251], lr: 0.000678, loss: 0.4081
2022-09-21 14:45:13 - train: epoch 0022, iter [00750, 01251], lr: 0.000678, loss: 0.4383
2022-09-21 14:45:35 - train: epoch 0022, iter [00760, 01251], lr: 0.000678, loss: 0.4196
2022-09-21 14:45:56 - train: epoch 0022, iter [00770, 01251], lr: 0.000678, loss: 0.4192
2022-09-21 14:46:18 - train: epoch 0022, iter [00780, 01251], lr: 0.000679, loss: 0.4254
2022-09-21 14:46:39 - train: epoch 0022, iter [00790, 01251], lr: 0.000679, loss: 0.4343
2022-09-21 14:47:01 - train: epoch 0022, iter [00800, 01251], lr: 0.000679, loss: 0.4174
2022-09-21 14:47:22 - train: epoch 0022, iter [00810, 01251], lr: 0.000679, loss: 0.4240
2022-09-21 14:47:43 - train: epoch 0022, iter [00820, 01251], lr: 0.000680, loss: 0.4233
2022-09-21 14:48:04 - train: epoch 0022, iter [00830, 01251], lr: 0.000680, loss: 0.4364
2022-09-21 14:48:26 - train: epoch 0022, iter [00840, 01251], lr: 0.000680, loss: 0.4476
2022-09-21 14:48:47 - train: epoch 0022, iter [00850, 01251], lr: 0.000680, loss: 0.4277
2022-09-21 14:49:08 - train: epoch 0022, iter [00860, 01251], lr: 0.000681, loss: 0.4260
2022-09-21 14:49:29 - train: epoch 0022, iter [00870, 01251], lr: 0.000681, loss: 0.4554
2022-09-21 14:49:51 - train: epoch 0022, iter [00880, 01251], lr: 0.000681, loss: 0.4455
2022-09-21 14:50:12 - train: epoch 0022, iter [00890, 01251], lr: 0.000681, loss: 0.4330
2022-09-21 14:50:33 - train: epoch 0022, iter [00900, 01251], lr: 0.000682, loss: 0.4340
2022-09-21 14:50:54 - train: epoch 0022, iter [00910, 01251], lr: 0.000682, loss: 0.4352
2022-09-21 14:51:15 - train: epoch 0022, iter [00920, 01251], lr: 0.000682, loss: 0.4380
2022-09-21 14:51:37 - train: epoch 0022, iter [00930, 01251], lr: 0.000682, loss: 0.4260
2022-09-21 14:51:57 - train: epoch 0022, iter [00940, 01251], lr: 0.000683, loss: 0.4236
2022-09-21 14:52:19 - train: epoch 0022, iter [00950, 01251], lr: 0.000683, loss: 0.4315
2022-09-21 14:52:39 - train: epoch 0022, iter [00960, 01251], lr: 0.000683, loss: 0.4306
2022-09-21 14:53:01 - train: epoch 0022, iter [00970, 01251], lr: 0.000683, loss: 0.4241
2022-09-21 14:53:22 - train: epoch 0022, iter [00980, 01251], lr: 0.000684, loss: 0.4305
2022-09-21 14:53:43 - train: epoch 0022, iter [00990, 01251], lr: 0.000684, loss: 0.4312
2022-09-21 14:54:04 - train: epoch 0022, iter [01000, 01251], lr: 0.000684, loss: 0.4257
2022-09-21 14:54:25 - train: epoch 0022, iter [01010, 01251], lr: 0.000684, loss: 0.4195
2022-09-21 14:54:46 - train: epoch 0022, iter [01020, 01251], lr: 0.000684, loss: 0.4199
2022-09-21 14:55:07 - train: epoch 0022, iter [01030, 01251], lr: 0.000685, loss: 0.4277
2022-09-21 14:55:29 - train: epoch 0022, iter [01040, 01251], lr: 0.000685, loss: 0.4236
2022-09-21 14:55:50 - train: epoch 0022, iter [01050, 01251], lr: 0.000685, loss: 0.4213
2022-09-21 14:56:11 - train: epoch 0022, iter [01060, 01251], lr: 0.000685, loss: 0.4235
2022-09-21 14:56:32 - train: epoch 0022, iter [01070, 01251], lr: 0.000686, loss: 0.4440
2022-09-21 14:56:53 - train: epoch 0022, iter [01080, 01251], lr: 0.000686, loss: 0.4170
2022-09-21 14:57:14 - train: epoch 0022, iter [01090, 01251], lr: 0.000686, loss: 0.4456
2022-09-21 14:57:36 - train: epoch 0022, iter [01100, 01251], lr: 0.000686, loss: 0.3950
2022-09-21 14:57:57 - train: epoch 0022, iter [01110, 01251], lr: 0.000687, loss: 0.4406
2022-09-21 14:58:18 - train: epoch 0022, iter [01120, 01251], lr: 0.000687, loss: 0.4366
2022-09-21 14:58:39 - train: epoch 0022, iter [01130, 01251], lr: 0.000687, loss: 0.4215
2022-09-21 14:59:00 - train: epoch 0022, iter [01140, 01251], lr: 0.000687, loss: 0.4172
2022-09-21 14:59:21 - train: epoch 0022, iter [01150, 01251], lr: 0.000688, loss: 0.4312
2022-09-21 14:59:42 - train: epoch 0022, iter [01160, 01251], lr: 0.000688, loss: 0.4400
2022-09-21 15:00:03 - train: epoch 0022, iter [01170, 01251], lr: 0.000688, loss: 0.4362
2022-09-21 15:00:24 - train: epoch 0022, iter [01180, 01251], lr: 0.000688, loss: 0.4378
2022-09-21 15:00:46 - train: epoch 0022, iter [01190, 01251], lr: 0.000689, loss: 0.4297
2022-09-21 15:01:06 - train: epoch 0022, iter [01200, 01251], lr: 0.000689, loss: 0.4331
2022-09-21 15:01:27 - train: epoch 0022, iter [01210, 01251], lr: 0.000689, loss: 0.4478
2022-09-21 15:01:48 - train: epoch 0022, iter [01220, 01251], lr: 0.000689, loss: 0.4428
2022-09-21 15:02:09 - train: epoch 0022, iter [01230, 01251], lr: 0.000689, loss: 0.4111
2022-09-21 15:02:31 - train: epoch 0022, iter [01240, 01251], lr: 0.000690, loss: 0.4341
2022-09-21 15:02:51 - train: epoch 0022, iter [01250, 01251], lr: 0.000690, loss: 0.4313
2022-09-21 15:02:55 - train: epoch 022, train_loss: 0.4297
2022-09-21 15:02:59 - until epoch: 022, best_loss: 0.4297
2022-09-21 15:02:59 - epoch 023 lr: 0.000690
2022-09-21 15:03:36 - train: epoch 0023, iter [00010, 01251], lr: 0.000690, loss: 0.4226
2022-09-21 15:03:57 - train: epoch 0023, iter [00020, 01251], lr: 0.000690, loss: 0.4251
2022-09-21 15:04:19 - train: epoch 0023, iter [00030, 01251], lr: 0.000691, loss: 0.4324
2022-09-21 15:04:40 - train: epoch 0023, iter [00040, 01251], lr: 0.000691, loss: 0.4284
2022-09-21 15:05:01 - train: epoch 0023, iter [00050, 01251], lr: 0.000691, loss: 0.4109
2022-09-21 15:05:23 - train: epoch 0023, iter [00060, 01251], lr: 0.000691, loss: 0.4235
2022-09-21 15:05:44 - train: epoch 0023, iter [00070, 01251], lr: 0.000692, loss: 0.4297
2022-09-21 15:06:05 - train: epoch 0023, iter [00080, 01251], lr: 0.000692, loss: 0.4251
2022-09-21 15:06:27 - train: epoch 0023, iter [00090, 01251], lr: 0.000692, loss: 0.4184
2022-09-21 15:06:48 - train: epoch 0023, iter [00100, 01251], lr: 0.000692, loss: 0.4026
2022-09-21 15:07:09 - train: epoch 0023, iter [00110, 01251], lr: 0.000693, loss: 0.4476
2022-09-21 15:07:31 - train: epoch 0023, iter [00120, 01251], lr: 0.000693, loss: 0.4242
2022-09-21 15:07:52 - train: epoch 0023, iter [00130, 01251], lr: 0.000693, loss: 0.4095
2022-09-21 15:08:13 - train: epoch 0023, iter [00140, 01251], lr: 0.000693, loss: 0.4294
2022-09-21 15:08:34 - train: epoch 0023, iter [00150, 01251], lr: 0.000694, loss: 0.4246
2022-09-21 15:08:56 - train: epoch 0023, iter [00160, 01251], lr: 0.000694, loss: 0.4174
2022-09-21 15:09:17 - train: epoch 0023, iter [00170, 01251], lr: 0.000694, loss: 0.4341
2022-09-21 15:09:38 - train: epoch 0023, iter [00180, 01251], lr: 0.000694, loss: 0.4215
2022-09-21 15:09:59 - train: epoch 0023, iter [00190, 01251], lr: 0.000695, loss: 0.4227
2022-09-21 15:10:21 - train: epoch 0023, iter [00200, 01251], lr: 0.000695, loss: 0.4357
2022-09-21 15:10:42 - train: epoch 0023, iter [00210, 01251], lr: 0.000695, loss: 0.4346
2022-09-21 15:11:03 - train: epoch 0023, iter [00220, 01251], lr: 0.000695, loss: 0.4395
2022-09-21 15:11:25 - train: epoch 0023, iter [00230, 01251], lr: 0.000696, loss: 0.4362
2022-09-21 15:11:46 - train: epoch 0023, iter [00240, 01251], lr: 0.000696, loss: 0.4272
2022-09-21 15:12:07 - train: epoch 0023, iter [00250, 01251], lr: 0.000696, loss: 0.4351
2022-09-21 15:12:29 - train: epoch 0023, iter [00260, 01251], lr: 0.000696, loss: 0.4573
2022-09-21 15:12:50 - train: epoch 0023, iter [00270, 01251], lr: 0.000696, loss: 0.4421
2022-09-21 15:13:11 - train: epoch 0023, iter [00280, 01251], lr: 0.000697, loss: 0.4294
2022-09-21 15:13:33 - train: epoch 0023, iter [00290, 01251], lr: 0.000697, loss: 0.4399
2022-09-21 15:13:54 - train: epoch 0023, iter [00300, 01251], lr: 0.000697, loss: 0.4244
2022-09-21 15:14:15 - train: epoch 0023, iter [00310, 01251], lr: 0.000697, loss: 0.4385
2022-09-21 15:14:36 - train: epoch 0023, iter [00320, 01251], lr: 0.000698, loss: 0.4331
2022-09-21 15:14:58 - train: epoch 0023, iter [00330, 01251], lr: 0.000698, loss: 0.4342
2022-09-21 15:15:19 - train: epoch 0023, iter [00340, 01251], lr: 0.000698, loss: 0.4326
2022-09-21 15:15:40 - train: epoch 0023, iter [00350, 01251], lr: 0.000698, loss: 0.4314
2022-09-21 15:16:01 - train: epoch 0023, iter [00360, 01251], lr: 0.000699, loss: 0.4512
2022-09-21 15:16:22 - train: epoch 0023, iter [00370, 01251], lr: 0.000699, loss: 0.4211
2022-09-21 15:16:44 - train: epoch 0023, iter [00380, 01251], lr: 0.000699, loss: 0.4314
2022-09-21 15:17:05 - train: epoch 0023, iter [00390, 01251], lr: 0.000699, loss: 0.4267
2022-09-21 15:17:26 - train: epoch 0023, iter [00400, 01251], lr: 0.000700, loss: 0.4375
2022-09-21 15:17:47 - train: epoch 0023, iter [00410, 01251], lr: 0.000700, loss: 0.4375
2022-09-21 15:18:09 - train: epoch 0023, iter [00420, 01251], lr: 0.000700, loss: 0.4210
2022-09-21 15:18:30 - train: epoch 0023, iter [00430, 01251], lr: 0.000700, loss: 0.4356
2022-09-21 15:18:51 - train: epoch 0023, iter [00440, 01251], lr: 0.000701, loss: 0.4343
2022-09-21 15:19:13 - train: epoch 0023, iter [00450, 01251], lr: 0.000701, loss: 0.4146
2022-09-21 15:19:34 - train: epoch 0023, iter [00460, 01251], lr: 0.000701, loss: 0.4300
2022-09-21 15:19:54 - train: epoch 0023, iter [00470, 01251], lr: 0.000701, loss: 0.4179
2022-09-21 15:20:16 - train: epoch 0023, iter [00480, 01251], lr: 0.000702, loss: 0.4225
2022-09-21 15:20:37 - train: epoch 0023, iter [00490, 01251], lr: 0.000702, loss: 0.4124
2022-09-21 15:20:57 - train: epoch 0023, iter [00500, 01251], lr: 0.000702, loss: 0.4379
2022-09-21 15:21:18 - train: epoch 0023, iter [00510, 01251], lr: 0.000702, loss: 0.4544
2022-09-21 15:21:40 - train: epoch 0023, iter [00520, 01251], lr: 0.000702, loss: 0.4150
2022-09-21 15:22:01 - train: epoch 0023, iter [00530, 01251], lr: 0.000703, loss: 0.4207
2022-09-21 15:22:22 - train: epoch 0023, iter [00540, 01251], lr: 0.000703, loss: 0.4226
2022-09-21 15:22:43 - train: epoch 0023, iter [00550, 01251], lr: 0.000703, loss: 0.4165
2022-09-21 15:23:04 - train: epoch 0023, iter [00560, 01251], lr: 0.000703, loss: 0.4272
2022-09-21 15:23:25 - train: epoch 0023, iter [00570, 01251], lr: 0.000704, loss: 0.4378
2022-09-21 15:23:46 - train: epoch 0023, iter [00580, 01251], lr: 0.000704, loss: 0.4185
2022-09-21 15:24:07 - train: epoch 0023, iter [00590, 01251], lr: 0.000704, loss: 0.4315
2022-09-21 15:24:28 - train: epoch 0023, iter [00600, 01251], lr: 0.000704, loss: 0.4436
2022-09-21 15:24:49 - train: epoch 0023, iter [00610, 01251], lr: 0.000705, loss: 0.4074
2022-09-21 15:25:10 - train: epoch 0023, iter [00620, 01251], lr: 0.000705, loss: 0.4455
2022-09-21 15:25:32 - train: epoch 0023, iter [00630, 01251], lr: 0.000705, loss: 0.4409
2022-09-21 15:25:53 - train: epoch 0023, iter [00640, 01251], lr: 0.000705, loss: 0.4483
2022-09-21 15:26:14 - train: epoch 0023, iter [00650, 01251], lr: 0.000706, loss: 0.4291
2022-09-21 15:26:34 - train: epoch 0023, iter [00660, 01251], lr: 0.000706, loss: 0.4305
2022-09-21 15:26:56 - train: epoch 0023, iter [00670, 01251], lr: 0.000706, loss: 0.4477
2022-09-21 15:27:16 - train: epoch 0023, iter [00680, 01251], lr: 0.000706, loss: 0.4386
2022-09-21 15:27:38 - train: epoch 0023, iter [00690, 01251], lr: 0.000707, loss: 0.4301
2022-09-21 15:27:59 - train: epoch 0023, iter [00700, 01251], lr: 0.000707, loss: 0.4356
2022-09-21 15:28:19 - train: epoch 0023, iter [00710, 01251], lr: 0.000707, loss: 0.4246
2022-09-21 15:28:40 - train: epoch 0023, iter [00720, 01251], lr: 0.000707, loss: 0.4126
2022-09-21 15:29:01 - train: epoch 0023, iter [00730, 01251], lr: 0.000708, loss: 0.4199
2022-09-21 15:29:22 - train: epoch 0023, iter [00740, 01251], lr: 0.000708, loss: 0.4173
2022-09-21 15:29:43 - train: epoch 0023, iter [00750, 01251], lr: 0.000708, loss: 0.4047
2022-09-21 15:30:05 - train: epoch 0023, iter [00760, 01251], lr: 0.000708, loss: 0.4197
2022-09-21 15:30:26 - train: epoch 0023, iter [00770, 01251], lr: 0.000708, loss: 0.4207
2022-09-21 15:30:47 - train: epoch 0023, iter [00780, 01251], lr: 0.000709, loss: 0.4313
2022-09-21 15:31:08 - train: epoch 0023, iter [00790, 01251], lr: 0.000709, loss: 0.4379
2022-09-21 15:31:28 - train: epoch 0023, iter [00800, 01251], lr: 0.000709, loss: 0.4224
2022-09-21 15:31:50 - train: epoch 0023, iter [00810, 01251], lr: 0.000709, loss: 0.4164
2022-09-21 15:32:10 - train: epoch 0023, iter [00820, 01251], lr: 0.000710, loss: 0.4030
2022-09-21 15:32:31 - train: epoch 0023, iter [00830, 01251], lr: 0.000710, loss: 0.4319
2022-09-21 15:32:52 - train: epoch 0023, iter [00840, 01251], lr: 0.000710, loss: 0.4205
2022-09-21 15:33:13 - train: epoch 0023, iter [00850, 01251], lr: 0.000710, loss: 0.4132
2022-09-21 15:33:34 - train: epoch 0023, iter [00860, 01251], lr: 0.000711, loss: 0.4480
2022-09-21 15:33:55 - train: epoch 0023, iter [00870, 01251], lr: 0.000711, loss: 0.4420
2022-09-21 15:34:16 - train: epoch 0023, iter [00880, 01251], lr: 0.000711, loss: 0.4504
2022-09-21 15:34:37 - train: epoch 0023, iter [00890, 01251], lr: 0.000711, loss: 0.4313
2022-09-21 15:34:58 - train: epoch 0023, iter [00900, 01251], lr: 0.000712, loss: 0.4520
2022-09-21 15:35:19 - train: epoch 0023, iter [00910, 01251], lr: 0.000712, loss: 0.4219
2022-09-21 15:35:40 - train: epoch 0023, iter [00920, 01251], lr: 0.000712, loss: 0.4211
2022-09-21 15:36:01 - train: epoch 0023, iter [00930, 01251], lr: 0.000712, loss: 0.4284
2022-09-21 15:36:22 - train: epoch 0023, iter [00940, 01251], lr: 0.000713, loss: 0.4288
2022-09-21 15:36:43 - train: epoch 0023, iter [00950, 01251], lr: 0.000713, loss: 0.4256
2022-09-21 15:37:04 - train: epoch 0023, iter [00960, 01251], lr: 0.000713, loss: 0.4230
2022-09-21 15:37:25 - train: epoch 0023, iter [00970, 01251], lr: 0.000713, loss: 0.4403
2022-09-21 15:37:46 - train: epoch 0023, iter [00980, 01251], lr: 0.000714, loss: 0.4059
2022-09-21 15:38:07 - train: epoch 0023, iter [00990, 01251], lr: 0.000714, loss: 0.4229
2022-09-21 15:38:28 - train: epoch 0023, iter [01000, 01251], lr: 0.000714, loss: 0.4403
2022-09-21 15:38:49 - train: epoch 0023, iter [01010, 01251], lr: 0.000714, loss: 0.4137
2022-09-21 15:39:10 - train: epoch 0023, iter [01020, 01251], lr: 0.000714, loss: 0.4259
2022-09-21 15:39:31 - train: epoch 0023, iter [01030, 01251], lr: 0.000715, loss: 0.4394
2022-09-21 15:39:52 - train: epoch 0023, iter [01040, 01251], lr: 0.000715, loss: 0.4316
2022-09-21 15:40:13 - train: epoch 0023, iter [01050, 01251], lr: 0.000715, loss: 0.4253
2022-09-21 15:40:34 - train: epoch 0023, iter [01060, 01251], lr: 0.000715, loss: 0.4280
2022-09-21 15:40:56 - train: epoch 0023, iter [01070, 01251], lr: 0.000716, loss: 0.4156
2022-09-21 15:41:17 - train: epoch 0023, iter [01080, 01251], lr: 0.000716, loss: 0.4426
2022-09-21 15:41:38 - train: epoch 0023, iter [01090, 01251], lr: 0.000716, loss: 0.4230
2022-09-21 15:41:59 - train: epoch 0023, iter [01100, 01251], lr: 0.000716, loss: 0.4356
2022-09-21 15:42:20 - train: epoch 0023, iter [01110, 01251], lr: 0.000717, loss: 0.4253
2022-09-21 15:42:41 - train: epoch 0023, iter [01120, 01251], lr: 0.000717, loss: 0.4186
2022-09-21 15:43:02 - train: epoch 0023, iter [01130, 01251], lr: 0.000717, loss: 0.4515
2022-09-21 15:43:23 - train: epoch 0023, iter [01140, 01251], lr: 0.000717, loss: 0.4327
2022-09-21 15:43:44 - train: epoch 0023, iter [01150, 01251], lr: 0.000718, loss: 0.4325
2022-09-21 15:44:05 - train: epoch 0023, iter [01160, 01251], lr: 0.000718, loss: 0.4324
2022-09-21 15:44:26 - train: epoch 0023, iter [01170, 01251], lr: 0.000718, loss: 0.4259
2022-09-21 15:44:47 - train: epoch 0023, iter [01180, 01251], lr: 0.000718, loss: 0.4215
2022-09-21 15:45:08 - train: epoch 0023, iter [01190, 01251], lr: 0.000719, loss: 0.4308
2022-09-21 15:45:29 - train: epoch 0023, iter [01200, 01251], lr: 0.000719, loss: 0.4335
2022-09-21 15:45:50 - train: epoch 0023, iter [01210, 01251], lr: 0.000719, loss: 0.4374
2022-09-21 15:46:11 - train: epoch 0023, iter [01220, 01251], lr: 0.000719, loss: 0.4100
2022-09-21 15:46:32 - train: epoch 0023, iter [01230, 01251], lr: 0.000719, loss: 0.4100
2022-09-21 15:46:53 - train: epoch 0023, iter [01240, 01251], lr: 0.000720, loss: 0.4231
2022-09-21 15:47:13 - train: epoch 0023, iter [01250, 01251], lr: 0.000720, loss: 0.4342
2022-09-21 15:47:17 - train: epoch 023, train_loss: 0.4288
2022-09-21 15:47:22 - until epoch: 023, best_loss: 0.4288
2022-09-21 15:47:22 - epoch 024 lr: 0.000720
2022-09-21 15:47:58 - train: epoch 0024, iter [00010, 01251], lr: 0.000720, loss: 0.4246
2022-09-21 15:48:19 - train: epoch 0024, iter [00020, 01251], lr: 0.000720, loss: 0.4457
2022-09-21 15:48:40 - train: epoch 0024, iter [00030, 01251], lr: 0.000721, loss: 0.4379
2022-09-21 15:49:01 - train: epoch 0024, iter [00040, 01251], lr: 0.000721, loss: 0.4254
2022-09-21 15:49:22 - train: epoch 0024, iter [00050, 01251], lr: 0.000721, loss: 0.4340
2022-09-21 15:49:43 - train: epoch 0024, iter [00060, 01251], lr: 0.000721, loss: 0.4267
2022-09-21 15:50:04 - train: epoch 0024, iter [00070, 01251], lr: 0.000722, loss: 0.4100
2022-09-21 15:50:25 - train: epoch 0024, iter [00080, 01251], lr: 0.000722, loss: 0.4386
2022-09-21 15:50:46 - train: epoch 0024, iter [00090, 01251], lr: 0.000722, loss: 0.4034
2022-09-21 15:51:07 - train: epoch 0024, iter [00100, 01251], lr: 0.000722, loss: 0.4367
2022-09-21 15:51:28 - train: epoch 0024, iter [00110, 01251], lr: 0.000723, loss: 0.4065
2022-09-21 15:51:49 - train: epoch 0024, iter [00120, 01251], lr: 0.000723, loss: 0.4255
2022-09-21 15:52:11 - train: epoch 0024, iter [00130, 01251], lr: 0.000723, loss: 0.4477
2022-09-21 15:52:32 - train: epoch 0024, iter [00140, 01251], lr: 0.000723, loss: 0.4415
2022-09-21 15:52:53 - train: epoch 0024, iter [00150, 01251], lr: 0.000724, loss: 0.4318
2022-09-21 15:53:15 - train: epoch 0024, iter [00160, 01251], lr: 0.000724, loss: 0.4290
2022-09-21 15:53:36 - train: epoch 0024, iter [00170, 01251], lr: 0.000724, loss: 0.4434
2022-09-21 15:53:58 - train: epoch 0024, iter [00180, 01251], lr: 0.000724, loss: 0.4438
2022-09-21 15:54:19 - train: epoch 0024, iter [00190, 01251], lr: 0.000725, loss: 0.4115
2022-09-21 15:54:40 - train: epoch 0024, iter [00200, 01251], lr: 0.000725, loss: 0.4549
2022-09-21 15:55:02 - train: epoch 0024, iter [00210, 01251], lr: 0.000725, loss: 0.4445
2022-09-21 15:55:23 - train: epoch 0024, iter [00220, 01251], lr: 0.000725, loss: 0.4191
2022-09-21 15:55:45 - train: epoch 0024, iter [00230, 01251], lr: 0.000726, loss: 0.4142
2022-09-21 15:56:06 - train: epoch 0024, iter [00240, 01251], lr: 0.000726, loss: 0.4363
2022-09-21 15:56:27 - train: epoch 0024, iter [00250, 01251], lr: 0.000726, loss: 0.4223
2022-09-21 15:56:49 - train: epoch 0024, iter [00260, 01251], lr: 0.000726, loss: 0.4419
2022-09-21 15:57:10 - train: epoch 0024, iter [00270, 01251], lr: 0.000726, loss: 0.4264
2022-09-21 15:57:31 - train: epoch 0024, iter [00280, 01251], lr: 0.000727, loss: 0.4265
2022-09-21 15:57:53 - train: epoch 0024, iter [00290, 01251], lr: 0.000727, loss: 0.4365
2022-09-21 15:58:14 - train: epoch 0024, iter [00300, 01251], lr: 0.000727, loss: 0.4244
2022-09-21 15:58:36 - train: epoch 0024, iter [00310, 01251], lr: 0.000727, loss: 0.4489
2022-09-21 15:58:57 - train: epoch 0024, iter [00320, 01251], lr: 0.000728, loss: 0.4100
2022-09-21 15:59:18 - train: epoch 0024, iter [00330, 01251], lr: 0.000728, loss: 0.4280
2022-09-21 15:59:40 - train: epoch 0024, iter [00340, 01251], lr: 0.000728, loss: 0.4423
2022-09-21 16:00:02 - train: epoch 0024, iter [00350, 01251], lr: 0.000728, loss: 0.4485
2022-09-21 16:00:23 - train: epoch 0024, iter [00360, 01251], lr: 0.000729, loss: 0.4203
2022-09-21 16:00:44 - train: epoch 0024, iter [00370, 01251], lr: 0.000729, loss: 0.4267
2022-09-21 16:01:05 - train: epoch 0024, iter [00380, 01251], lr: 0.000729, loss: 0.4357
2022-09-21 16:01:26 - train: epoch 0024, iter [00390, 01251], lr: 0.000729, loss: 0.4157
2022-09-21 16:01:47 - train: epoch 0024, iter [00400, 01251], lr: 0.000730, loss: 0.4276
2022-09-21 16:02:09 - train: epoch 0024, iter [00410, 01251], lr: 0.000730, loss: 0.4267
2022-09-21 16:02:30 - train: epoch 0024, iter [00420, 01251], lr: 0.000730, loss: 0.4318
2022-09-21 16:02:51 - train: epoch 0024, iter [00430, 01251], lr: 0.000730, loss: 0.4441
2022-09-21 16:03:12 - train: epoch 0024, iter [00440, 01251], lr: 0.000731, loss: 0.4268
2022-09-21 16:03:33 - train: epoch 0024, iter [00450, 01251], lr: 0.000731, loss: 0.4307
2022-09-21 16:03:54 - train: epoch 0024, iter [00460, 01251], lr: 0.000731, loss: 0.4243
2022-09-21 16:04:15 - train: epoch 0024, iter [00470, 01251], lr: 0.000731, loss: 0.4322
2022-09-21 16:04:36 - train: epoch 0024, iter [00480, 01251], lr: 0.000732, loss: 0.4207
2022-09-21 16:04:57 - train: epoch 0024, iter [00490, 01251], lr: 0.000732, loss: 0.4085
2022-09-21 16:05:18 - train: epoch 0024, iter [00500, 01251], lr: 0.000732, loss: 0.4112
2022-09-21 16:05:39 - train: epoch 0024, iter [00510, 01251], lr: 0.000732, loss: 0.4353
2022-09-21 16:06:00 - train: epoch 0024, iter [00520, 01251], lr: 0.000732, loss: 0.4167
2022-09-21 16:06:21 - train: epoch 0024, iter [00530, 01251], lr: 0.000733, loss: 0.4335
2022-09-21 16:06:43 - train: epoch 0024, iter [00540, 01251], lr: 0.000733, loss: 0.4326
2022-09-21 16:07:04 - train: epoch 0024, iter [00550, 01251], lr: 0.000733, loss: 0.4269
2022-09-21 16:07:25 - train: epoch 0024, iter [00560, 01251], lr: 0.000733, loss: 0.4267
2022-09-21 16:07:46 - train: epoch 0024, iter [00570, 01251], lr: 0.000734, loss: 0.4268
2022-09-21 16:08:07 - train: epoch 0024, iter [00580, 01251], lr: 0.000734, loss: 0.4197
2022-09-21 16:08:28 - train: epoch 0024, iter [00590, 01251], lr: 0.000734, loss: 0.4558
2022-09-21 16:08:50 - train: epoch 0024, iter [00600, 01251], lr: 0.000734, loss: 0.4187
2022-09-21 16:09:11 - train: epoch 0024, iter [00610, 01251], lr: 0.000735, loss: 0.4291
2022-09-21 16:09:32 - train: epoch 0024, iter [00620, 01251], lr: 0.000735, loss: 0.4140
2022-09-21 16:09:53 - train: epoch 0024, iter [00630, 01251], lr: 0.000735, loss: 0.4270
2022-09-21 16:10:14 - train: epoch 0024, iter [00640, 01251], lr: 0.000735, loss: 0.4348
2022-09-21 16:10:35 - train: epoch 0024, iter [00650, 01251], lr: 0.000736, loss: 0.4293
2022-09-21 16:10:56 - train: epoch 0024, iter [00660, 01251], lr: 0.000736, loss: 0.4241
2022-09-21 16:11:17 - train: epoch 0024, iter [00670, 01251], lr: 0.000736, loss: 0.4491
2022-09-21 16:11:38 - train: epoch 0024, iter [00680, 01251], lr: 0.000736, loss: 0.4304
2022-09-21 16:12:00 - train: epoch 0024, iter [00690, 01251], lr: 0.000737, loss: 0.4198
2022-09-21 16:12:21 - train: epoch 0024, iter [00700, 01251], lr: 0.000737, loss: 0.4320
2022-09-21 16:12:42 - train: epoch 0024, iter [00710, 01251], lr: 0.000737, loss: 0.4211
2022-09-21 16:13:03 - train: epoch 0024, iter [00720, 01251], lr: 0.000737, loss: 0.4261
2022-09-21 16:13:24 - train: epoch 0024, iter [00730, 01251], lr: 0.000738, loss: 0.4147
2022-09-21 16:13:45 - train: epoch 0024, iter [00740, 01251], lr: 0.000738, loss: 0.4386
2022-09-21 16:14:06 - train: epoch 0024, iter [00750, 01251], lr: 0.000738, loss: 0.4023
2022-09-21 16:14:27 - train: epoch 0024, iter [00760, 01251], lr: 0.000738, loss: 0.4232
2022-09-21 16:14:48 - train: epoch 0024, iter [00770, 01251], lr: 0.000738, loss: 0.4329
2022-09-21 16:15:09 - train: epoch 0024, iter [00780, 01251], lr: 0.000739, loss: 0.4164
2022-09-21 16:15:30 - train: epoch 0024, iter [00790, 01251], lr: 0.000739, loss: 0.4430
2022-09-21 16:15:51 - train: epoch 0024, iter [00800, 01251], lr: 0.000739, loss: 0.4339
2022-09-21 16:16:12 - train: epoch 0024, iter [00810, 01251], lr: 0.000739, loss: 0.4245
2022-09-21 16:16:33 - train: epoch 0024, iter [00820, 01251], lr: 0.000740, loss: 0.4325
2022-09-21 16:16:54 - train: epoch 0024, iter [00830, 01251], lr: 0.000740, loss: 0.4295
2022-09-21 16:17:15 - train: epoch 0024, iter [00840, 01251], lr: 0.000740, loss: 0.4319
2022-09-21 16:17:36 - train: epoch 0024, iter [00850, 01251], lr: 0.000740, loss: 0.4109
2022-09-21 16:17:57 - train: epoch 0024, iter [00860, 01251], lr: 0.000741, loss: 0.4259
2022-09-21 16:18:18 - train: epoch 0024, iter [00870, 01251], lr: 0.000741, loss: 0.4173
2022-09-21 16:18:39 - train: epoch 0024, iter [00880, 01251], lr: 0.000741, loss: 0.4513
2022-09-21 16:19:00 - train: epoch 0024, iter [00890, 01251], lr: 0.000741, loss: 0.4174
2022-09-21 16:19:21 - train: epoch 0024, iter [00900, 01251], lr: 0.000742, loss: 0.4414
2022-09-21 16:19:43 - train: epoch 0024, iter [00910, 01251], lr: 0.000742, loss: 0.4302
2022-09-21 16:20:05 - train: epoch 0024, iter [00920, 01251], lr: 0.000742, loss: 0.4321
2022-09-21 16:20:26 - train: epoch 0024, iter [00930, 01251], lr: 0.000742, loss: 0.4374
2022-09-21 16:20:47 - train: epoch 0024, iter [00940, 01251], lr: 0.000743, loss: 0.4351
2022-09-21 16:21:08 - train: epoch 0024, iter [00950, 01251], lr: 0.000743, loss: 0.4083
2022-09-21 16:21:30 - train: epoch 0024, iter [00960, 01251], lr: 0.000743, loss: 0.4290
2022-09-21 16:21:51 - train: epoch 0024, iter [00970, 01251], lr: 0.000743, loss: 0.4187
2022-09-21 16:22:12 - train: epoch 0024, iter [00980, 01251], lr: 0.000744, loss: 0.4256
2022-09-21 16:22:33 - train: epoch 0024, iter [00990, 01251], lr: 0.000744, loss: 0.4202
2022-09-21 16:22:55 - train: epoch 0024, iter [01000, 01251], lr: 0.000744, loss: 0.4317
2022-09-21 16:23:16 - train: epoch 0024, iter [01010, 01251], lr: 0.000744, loss: 0.4292
2022-09-21 16:23:37 - train: epoch 0024, iter [01020, 01251], lr: 0.000744, loss: 0.4379
2022-09-21 16:23:58 - train: epoch 0024, iter [01030, 01251], lr: 0.000745, loss: 0.4316
2022-09-21 16:24:19 - train: epoch 0024, iter [01040, 01251], lr: 0.000745, loss: 0.4282
2022-09-21 16:24:40 - train: epoch 0024, iter [01050, 01251], lr: 0.000745, loss: 0.4017
2022-09-21 16:25:02 - train: epoch 0024, iter [01060, 01251], lr: 0.000745, loss: 0.4289
2022-09-21 16:25:23 - train: epoch 0024, iter [01070, 01251], lr: 0.000746, loss: 0.4066
2022-09-21 16:25:44 - train: epoch 0024, iter [01080, 01251], lr: 0.000746, loss: 0.4234
2022-09-21 16:26:06 - train: epoch 0024, iter [01090, 01251], lr: 0.000746, loss: 0.4139
2022-09-21 16:26:27 - train: epoch 0024, iter [01100, 01251], lr: 0.000746, loss: 0.4421
2022-09-21 16:26:48 - train: epoch 0024, iter [01110, 01251], lr: 0.000747, loss: 0.4267
2022-09-21 16:27:09 - train: epoch 0024, iter [01120, 01251], lr: 0.000747, loss: 0.4429
2022-09-21 16:27:31 - train: epoch 0024, iter [01130, 01251], lr: 0.000747, loss: 0.4298
2022-09-21 16:27:52 - train: epoch 0024, iter [01140, 01251], lr: 0.000747, loss: 0.4413
2022-09-21 16:28:13 - train: epoch 0024, iter [01150, 01251], lr: 0.000748, loss: 0.4392
2022-09-21 16:28:34 - train: epoch 0024, iter [01160, 01251], lr: 0.000748, loss: 0.4289
2022-09-21 16:28:55 - train: epoch 0024, iter [01170, 01251], lr: 0.000748, loss: 0.4028
2022-09-21 16:29:16 - train: epoch 0024, iter [01180, 01251], lr: 0.000748, loss: 0.4130
2022-09-21 16:29:37 - train: epoch 0024, iter [01190, 01251], lr: 0.000749, loss: 0.4299
2022-09-21 16:29:58 - train: epoch 0024, iter [01200, 01251], lr: 0.000749, loss: 0.4324
2022-09-21 16:30:19 - train: epoch 0024, iter [01210, 01251], lr: 0.000749, loss: 0.4264
2022-09-21 16:30:40 - train: epoch 0024, iter [01220, 01251], lr: 0.000749, loss: 0.4210
2022-09-21 16:31:00 - train: epoch 0024, iter [01230, 01251], lr: 0.000749, loss: 0.4174
2022-09-21 16:31:21 - train: epoch 0024, iter [01240, 01251], lr: 0.000750, loss: 0.4230
2022-09-21 16:31:41 - train: epoch 0024, iter [01250, 01251], lr: 0.000750, loss: 0.4358
2022-09-21 16:31:46 - train: epoch 024, train_loss: 0.4280
2022-09-21 16:31:51 - until epoch: 024, best_loss: 0.4280
2022-09-21 16:31:51 - epoch 025 lr: 0.000750
2022-09-21 16:32:29 - train: epoch 0025, iter [00010, 01251], lr: 0.000750, loss: 0.4164
2022-09-21 16:32:50 - train: epoch 0025, iter [00020, 01251], lr: 0.000750, loss: 0.4203
2022-09-21 16:33:11 - train: epoch 0025, iter [00030, 01251], lr: 0.000751, loss: 0.4269
2022-09-21 16:33:31 - train: epoch 0025, iter [00040, 01251], lr: 0.000751, loss: 0.4222
2022-09-21 16:33:52 - train: epoch 0025, iter [00050, 01251], lr: 0.000751, loss: 0.4349
2022-09-21 16:34:13 - train: epoch 0025, iter [00060, 01251], lr: 0.000751, loss: 0.4353
2022-09-21 16:34:34 - train: epoch 0025, iter [00070, 01251], lr: 0.000752, loss: 0.4217
2022-09-21 16:34:55 - train: epoch 0025, iter [00080, 01251], lr: 0.000752, loss: 0.4222
2022-09-21 16:35:16 - train: epoch 0025, iter [00090, 01251], lr: 0.000752, loss: 0.4103
2022-09-21 16:35:36 - train: epoch 0025, iter [00100, 01251], lr: 0.000752, loss: 0.4372
2022-09-21 16:35:57 - train: epoch 0025, iter [00110, 01251], lr: 0.000753, loss: 0.4221
2022-09-21 16:36:18 - train: epoch 0025, iter [00120, 01251], lr: 0.000753, loss: 0.4201
2022-09-21 16:36:39 - train: epoch 0025, iter [00130, 01251], lr: 0.000753, loss: 0.4224
2022-09-21 16:37:00 - train: epoch 0025, iter [00140, 01251], lr: 0.000753, loss: 0.4278
2022-09-21 16:37:21 - train: epoch 0025, iter [00150, 01251], lr: 0.000754, loss: 0.4165
2022-09-21 16:37:41 - train: epoch 0025, iter [00160, 01251], lr: 0.000754, loss: 0.4076
2022-09-21 16:38:02 - train: epoch 0025, iter [00170, 01251], lr: 0.000754, loss: 0.4219
2022-09-21 16:38:23 - train: epoch 0025, iter [00180, 01251], lr: 0.000754, loss: 0.4007
2022-09-21 16:38:44 - train: epoch 0025, iter [00190, 01251], lr: 0.000755, loss: 0.4344
2022-09-21 16:39:05 - train: epoch 0025, iter [00200, 01251], lr: 0.000755, loss: 0.4298
2022-09-21 16:39:26 - train: epoch 0025, iter [00210, 01251], lr: 0.000755, loss: 0.4537
2022-09-21 16:39:47 - train: epoch 0025, iter [00220, 01251], lr: 0.000755, loss: 0.4077
2022-09-21 16:40:08 - train: epoch 0025, iter [00230, 01251], lr: 0.000756, loss: 0.4266
2022-09-21 16:40:29 - train: epoch 0025, iter [00240, 01251], lr: 0.000756, loss: 0.4324
2022-09-21 16:40:50 - train: epoch 0025, iter [00250, 01251], lr: 0.000756, loss: 0.4241
2022-09-21 16:41:11 - train: epoch 0025, iter [00260, 01251], lr: 0.000756, loss: 0.4463
2022-09-21 16:41:32 - train: epoch 0025, iter [00270, 01251], lr: 0.000756, loss: 0.4162
2022-09-21 16:41:53 - train: epoch 0025, iter [00280, 01251], lr: 0.000757, loss: 0.4350
2022-09-21 16:42:14 - train: epoch 0025, iter [00290, 01251], lr: 0.000757, loss: 0.4288
2022-09-21 16:42:35 - train: epoch 0025, iter [00300, 01251], lr: 0.000757, loss: 0.4315
2022-09-21 16:42:56 - train: epoch 0025, iter [00310, 01251], lr: 0.000757, loss: 0.4072
2022-09-21 16:43:17 - train: epoch 0025, iter [00320, 01251], lr: 0.000758, loss: 0.4264
2022-09-21 16:43:38 - train: epoch 0025, iter [00330, 01251], lr: 0.000758, loss: 0.4392
2022-09-21 16:43:58 - train: epoch 0025, iter [00340, 01251], lr: 0.000758, loss: 0.4286
2022-09-21 16:44:19 - train: epoch 0025, iter [00350, 01251], lr: 0.000758, loss: 0.4221
2022-09-21 16:44:40 - train: epoch 0025, iter [00360, 01251], lr: 0.000759, loss: 0.4273
2022-09-21 16:45:01 - train: epoch 0025, iter [00370, 01251], lr: 0.000759, loss: 0.4313
2022-09-21 16:45:22 - train: epoch 0025, iter [00380, 01251], lr: 0.000759, loss: 0.4218
2022-09-21 16:45:43 - train: epoch 0025, iter [00390, 01251], lr: 0.000759, loss: 0.4147
2022-09-21 16:46:04 - train: epoch 0025, iter [00400, 01251], lr: 0.000760, loss: 0.4191
2022-09-21 16:46:25 - train: epoch 0025, iter [00410, 01251], lr: 0.000760, loss: 0.4328
2022-09-21 16:46:46 - train: epoch 0025, iter [00420, 01251], lr: 0.000760, loss: 0.4237
2022-09-21 16:47:07 - train: epoch 0025, iter [00430, 01251], lr: 0.000760, loss: 0.4275
2022-09-21 16:47:28 - train: epoch 0025, iter [00440, 01251], lr: 0.000761, loss: 0.4162
2022-09-21 16:47:49 - train: epoch 0025, iter [00450, 01251], lr: 0.000761, loss: 0.4321
2022-09-21 16:48:10 - train: epoch 0025, iter [00460, 01251], lr: 0.000761, loss: 0.4277
2022-09-21 16:48:31 - train: epoch 0025, iter [00470, 01251], lr: 0.000761, loss: 0.4093
2022-09-21 16:48:52 - train: epoch 0025, iter [00480, 01251], lr: 0.000762, loss: 0.4308
2022-09-21 16:49:13 - train: epoch 0025, iter [00490, 01251], lr: 0.000762, loss: 0.4317
2022-09-21 16:49:34 - train: epoch 0025, iter [00500, 01251], lr: 0.000762, loss: 0.4328
2022-09-21 16:49:55 - train: epoch 0025, iter [00510, 01251], lr: 0.000762, loss: 0.4212
2022-09-21 16:50:16 - train: epoch 0025, iter [00520, 01251], lr: 0.000762, loss: 0.4447
2022-09-21 16:50:37 - train: epoch 0025, iter [00530, 01251], lr: 0.000763, loss: 0.4269
2022-09-21 16:50:58 - train: epoch 0025, iter [00540, 01251], lr: 0.000763, loss: 0.4351
2022-09-21 16:51:19 - train: epoch 0025, iter [00550, 01251], lr: 0.000763, loss: 0.4244
2022-09-21 16:51:40 - train: epoch 0025, iter [00560, 01251], lr: 0.000763, loss: 0.4158
2022-09-21 16:52:01 - train: epoch 0025, iter [00570, 01251], lr: 0.000764, loss: 0.4327
2022-09-21 16:52:22 - train: epoch 0025, iter [00580, 01251], lr: 0.000764, loss: 0.4228
2022-09-21 16:52:43 - train: epoch 0025, iter [00590, 01251], lr: 0.000764, loss: 0.4404
2022-09-21 16:53:04 - train: epoch 0025, iter [00600, 01251], lr: 0.000764, loss: 0.4367
2022-09-21 16:53:25 - train: epoch 0025, iter [00610, 01251], lr: 0.000765, loss: 0.4128
2022-09-21 16:53:46 - train: epoch 0025, iter [00620, 01251], lr: 0.000765, loss: 0.4442
2022-09-21 16:54:07 - train: epoch 0025, iter [00630, 01251], lr: 0.000765, loss: 0.4203
2022-09-21 16:54:27 - train: epoch 0025, iter [00640, 01251], lr: 0.000765, loss: 0.4359
2022-09-21 16:54:48 - train: epoch 0025, iter [00650, 01251], lr: 0.000766, loss: 0.4335
2022-09-21 16:55:10 - train: epoch 0025, iter [00660, 01251], lr: 0.000766, loss: 0.4378
2022-09-21 16:55:30 - train: epoch 0025, iter [00670, 01251], lr: 0.000766, loss: 0.4328
2022-09-21 16:55:51 - train: epoch 0025, iter [00680, 01251], lr: 0.000766, loss: 0.4350
2022-09-21 16:56:13 - train: epoch 0025, iter [00690, 01251], lr: 0.000767, loss: 0.4113
2022-09-21 16:56:34 - train: epoch 0025, iter [00700, 01251], lr: 0.000767, loss: 0.4274
2022-09-21 16:56:54 - train: epoch 0025, iter [00710, 01251], lr: 0.000767, loss: 0.4139
2022-09-21 16:57:15 - train: epoch 0025, iter [00720, 01251], lr: 0.000767, loss: 0.4343
2022-09-21 16:57:36 - train: epoch 0025, iter [00730, 01251], lr: 0.000768, loss: 0.4135
2022-09-21 16:57:57 - train: epoch 0025, iter [00740, 01251], lr: 0.000768, loss: 0.4038
2022-09-21 16:58:18 - train: epoch 0025, iter [00750, 01251], lr: 0.000768, loss: 0.4154
2022-09-21 16:58:39 - train: epoch 0025, iter [00760, 01251], lr: 0.000768, loss: 0.4417
2022-09-21 16:59:00 - train: epoch 0025, iter [00770, 01251], lr: 0.000768, loss: 0.4262
2022-09-21 16:59:22 - train: epoch 0025, iter [00780, 01251], lr: 0.000769, loss: 0.4455
2022-09-21 16:59:43 - train: epoch 0025, iter [00790, 01251], lr: 0.000769, loss: 0.4187
2022-09-21 17:00:04 - train: epoch 0025, iter [00800, 01251], lr: 0.000769, loss: 0.4353
2022-09-21 17:00:24 - train: epoch 0025, iter [00810, 01251], lr: 0.000769, loss: 0.4311
2022-09-21 17:00:45 - train: epoch 0025, iter [00820, 01251], lr: 0.000770, loss: 0.4234
2022-09-21 17:01:06 - train: epoch 0025, iter [00830, 01251], lr: 0.000770, loss: 0.4390
2022-09-21 17:01:27 - train: epoch 0025, iter [00840, 01251], lr: 0.000770, loss: 0.4417
2022-09-21 17:01:48 - train: epoch 0025, iter [00850, 01251], lr: 0.000770, loss: 0.4156
2022-09-21 17:02:09 - train: epoch 0025, iter [00860, 01251], lr: 0.000771, loss: 0.4271
2022-09-21 17:02:30 - train: epoch 0025, iter [00870, 01251], lr: 0.000771, loss: 0.4458
2022-09-21 17:02:51 - train: epoch 0025, iter [00880, 01251], lr: 0.000771, loss: 0.4364
2022-09-21 17:03:12 - train: epoch 0025, iter [00890, 01251], lr: 0.000771, loss: 0.4168
2022-09-21 17:03:33 - train: epoch 0025, iter [00900, 01251], lr: 0.000772, loss: 0.4412
2022-09-21 17:03:54 - train: epoch 0025, iter [00910, 01251], lr: 0.000772, loss: 0.4356
2022-09-21 17:04:15 - train: epoch 0025, iter [00920, 01251], lr: 0.000772, loss: 0.4228
2022-09-21 17:04:36 - train: epoch 0025, iter [00930, 01251], lr: 0.000772, loss: 0.4265
2022-09-21 17:04:57 - train: epoch 0025, iter [00940, 01251], lr: 0.000773, loss: 0.4369
2022-09-21 17:05:18 - train: epoch 0025, iter [00950, 01251], lr: 0.000773, loss: 0.4297
2022-09-21 17:05:39 - train: epoch 0025, iter [00960, 01251], lr: 0.000773, loss: 0.4241
2022-09-21 17:06:00 - train: epoch 0025, iter [00970, 01251], lr: 0.000773, loss: 0.4366
2022-09-21 17:06:21 - train: epoch 0025, iter [00980, 01251], lr: 0.000774, loss: 0.4371
2022-09-21 17:06:42 - train: epoch 0025, iter [00990, 01251], lr: 0.000774, loss: 0.4393
2022-09-21 17:07:03 - train: epoch 0025, iter [01000, 01251], lr: 0.000774, loss: 0.4231
2022-09-21 17:07:24 - train: epoch 0025, iter [01010, 01251], lr: 0.000774, loss: 0.4027
2022-09-21 17:07:45 - train: epoch 0025, iter [01020, 01251], lr: 0.000774, loss: 0.4150
2022-09-21 17:08:06 - train: epoch 0025, iter [01030, 01251], lr: 0.000775, loss: 0.4286
2022-09-21 17:08:27 - train: epoch 0025, iter [01040, 01251], lr: 0.000775, loss: 0.4289
2022-09-21 17:08:47 - train: epoch 0025, iter [01050, 01251], lr: 0.000775, loss: 0.4247
2022-09-21 17:09:08 - train: epoch 0025, iter [01060, 01251], lr: 0.000775, loss: 0.4212
2022-09-21 17:09:29 - train: epoch 0025, iter [01070, 01251], lr: 0.000776, loss: 0.4175
2022-09-21 17:09:50 - train: epoch 0025, iter [01080, 01251], lr: 0.000776, loss: 0.4035
2022-09-21 17:10:10 - train: epoch 0025, iter [01090, 01251], lr: 0.000776, loss: 0.4265
2022-09-21 17:10:31 - train: epoch 0025, iter [01100, 01251], lr: 0.000776, loss: 0.4419
2022-09-21 17:10:52 - train: epoch 0025, iter [01110, 01251], lr: 0.000777, loss: 0.3999
2022-09-21 17:11:13 - train: epoch 0025, iter [01120, 01251], lr: 0.000777, loss: 0.4081
2022-09-21 17:11:34 - train: epoch 0025, iter [01130, 01251], lr: 0.000777, loss: 0.4314
2022-09-21 17:11:54 - train: epoch 0025, iter [01140, 01251], lr: 0.000777, loss: 0.4282
2022-09-21 17:12:15 - train: epoch 0025, iter [01150, 01251], lr: 0.000778, loss: 0.4379
2022-09-21 17:12:36 - train: epoch 0025, iter [01160, 01251], lr: 0.000778, loss: 0.4229
2022-09-21 17:12:56 - train: epoch 0025, iter [01170, 01251], lr: 0.000778, loss: 0.4261
2022-09-21 17:13:17 - train: epoch 0025, iter [01180, 01251], lr: 0.000778, loss: 0.4192
2022-09-21 17:13:38 - train: epoch 0025, iter [01190, 01251], lr: 0.000779, loss: 0.4072
2022-09-21 17:13:59 - train: epoch 0025, iter [01200, 01251], lr: 0.000779, loss: 0.4330
2022-09-21 17:14:20 - train: epoch 0025, iter [01210, 01251], lr: 0.000779, loss: 0.4211
2022-09-21 17:14:41 - train: epoch 0025, iter [01220, 01251], lr: 0.000779, loss: 0.4278
2022-09-21 17:15:02 - train: epoch 0025, iter [01230, 01251], lr: 0.000779, loss: 0.4082
2022-09-21 17:15:23 - train: epoch 0025, iter [01240, 01251], lr: 0.000780, loss: 0.4180
2022-09-21 17:15:43 - train: epoch 0025, iter [01250, 01251], lr: 0.000780, loss: 0.4398
2022-09-21 17:15:48 - train: epoch 025, train_loss: 0.4273
2022-09-21 17:15:52 - until epoch: 025, best_loss: 0.4273
2022-09-21 17:15:52 - epoch 026 lr: 0.000780
2022-09-21 17:16:30 - train: epoch 0026, iter [00010, 01251], lr: 0.000780, loss: 0.4272
2022-09-21 17:16:52 - train: epoch 0026, iter [00020, 01251], lr: 0.000780, loss: 0.4258
2022-09-21 17:17:13 - train: epoch 0026, iter [00030, 01251], lr: 0.000781, loss: 0.4293
2022-09-21 17:17:35 - train: epoch 0026, iter [00040, 01251], lr: 0.000781, loss: 0.4123
2022-09-21 17:17:56 - train: epoch 0026, iter [00050, 01251], lr: 0.000781, loss: 0.4442
2022-09-21 17:18:17 - train: epoch 0026, iter [00060, 01251], lr: 0.000781, loss: 0.4408
2022-09-21 17:18:39 - train: epoch 0026, iter [00070, 01251], lr: 0.000782, loss: 0.4311
2022-09-21 17:19:00 - train: epoch 0026, iter [00080, 01251], lr: 0.000782, loss: 0.4121
2022-09-21 17:19:21 - train: epoch 0026, iter [00090, 01251], lr: 0.000782, loss: 0.4242
2022-09-21 17:19:42 - train: epoch 0026, iter [00100, 01251], lr: 0.000782, loss: 0.4449
2022-09-21 17:20:04 - train: epoch 0026, iter [00110, 01251], lr: 0.000783, loss: 0.4189
2022-09-21 17:20:25 - train: epoch 0026, iter [00120, 01251], lr: 0.000783, loss: 0.4240
2022-09-21 17:20:47 - train: epoch 0026, iter [00130, 01251], lr: 0.000783, loss: 0.4258
2022-09-21 17:21:08 - train: epoch 0026, iter [00140, 01251], lr: 0.000783, loss: 0.4437
2022-09-21 17:21:29 - train: epoch 0026, iter [00150, 01251], lr: 0.000784, loss: 0.4243
2022-09-21 17:21:50 - train: epoch 0026, iter [00160, 01251], lr: 0.000784, loss: 0.4182
2022-09-21 17:22:12 - train: epoch 0026, iter [00170, 01251], lr: 0.000784, loss: 0.4193
2022-09-21 17:22:33 - train: epoch 0026, iter [00180, 01251], lr: 0.000784, loss: 0.4309
2022-09-21 17:22:54 - train: epoch 0026, iter [00190, 01251], lr: 0.000785, loss: 0.4047
2022-09-21 17:23:16 - train: epoch 0026, iter [00200, 01251], lr: 0.000785, loss: 0.4427
2022-09-21 17:23:37 - train: epoch 0026, iter [00210, 01251], lr: 0.000785, loss: 0.4280
2022-09-21 17:23:58 - train: epoch 0026, iter [00220, 01251], lr: 0.000785, loss: 0.4395
2022-09-21 17:24:20 - train: epoch 0026, iter [00230, 01251], lr: 0.000786, loss: 0.4171
2022-09-21 17:24:41 - train: epoch 0026, iter [00240, 01251], lr: 0.000786, loss: 0.4069
2022-09-21 17:25:02 - train: epoch 0026, iter [00250, 01251], lr: 0.000786, loss: 0.4348
2022-09-21 17:25:23 - train: epoch 0026, iter [00260, 01251], lr: 0.000786, loss: 0.4197
2022-09-21 17:25:44 - train: epoch 0026, iter [00270, 01251], lr: 0.000786, loss: 0.4232
2022-09-21 17:26:05 - train: epoch 0026, iter [00280, 01251], lr: 0.000787, loss: 0.4273
2022-09-21 17:26:27 - train: epoch 0026, iter [00290, 01251], lr: 0.000787, loss: 0.4212
2022-09-21 17:26:48 - train: epoch 0026, iter [00300, 01251], lr: 0.000787, loss: 0.4260
2022-09-21 17:27:09 - train: epoch 0026, iter [00310, 01251], lr: 0.000787, loss: 0.4190
2022-09-21 17:27:30 - train: epoch 0026, iter [00320, 01251], lr: 0.000788, loss: 0.4302
2022-09-21 17:27:51 - train: epoch 0026, iter [00330, 01251], lr: 0.000788, loss: 0.4498
2022-09-21 17:28:12 - train: epoch 0026, iter [00340, 01251], lr: 0.000788, loss: 0.4378
2022-09-21 17:28:33 - train: epoch 0026, iter [00350, 01251], lr: 0.000788, loss: 0.4182
2022-09-21 17:28:55 - train: epoch 0026, iter [00360, 01251], lr: 0.000789, loss: 0.4278
2022-09-21 17:29:16 - train: epoch 0026, iter [00370, 01251], lr: 0.000789, loss: 0.4318
2022-09-21 17:29:37 - train: epoch 0026, iter [00380, 01251], lr: 0.000789, loss: 0.4256
2022-09-21 17:29:58 - train: epoch 0026, iter [00390, 01251], lr: 0.000789, loss: 0.4307
2022-09-21 17:30:19 - train: epoch 0026, iter [00400, 01251], lr: 0.000790, loss: 0.4211
2022-09-21 17:30:41 - train: epoch 0026, iter [00410, 01251], lr: 0.000790, loss: 0.4449
2022-09-21 17:31:02 - train: epoch 0026, iter [00420, 01251], lr: 0.000790, loss: 0.4222
2022-09-21 17:31:23 - train: epoch 0026, iter [00430, 01251], lr: 0.000790, loss: 0.4352
2022-09-21 17:31:44 - train: epoch 0026, iter [00440, 01251], lr: 0.000791, loss: 0.4204
2022-09-21 17:32:05 - train: epoch 0026, iter [00450, 01251], lr: 0.000791, loss: 0.4379
2022-09-21 17:32:27 - train: epoch 0026, iter [00460, 01251], lr: 0.000791, loss: 0.4105
2022-09-21 17:32:48 - train: epoch 0026, iter [00470, 01251], lr: 0.000791, loss: 0.4291
2022-09-21 17:33:09 - train: epoch 0026, iter [00480, 01251], lr: 0.000792, loss: 0.4241
2022-09-21 17:33:30 - train: epoch 0026, iter [00490, 01251], lr: 0.000792, loss: 0.4463
2022-09-21 17:33:52 - train: epoch 0026, iter [00500, 01251], lr: 0.000792, loss: 0.4242
2022-09-21 17:34:13 - train: epoch 0026, iter [00510, 01251], lr: 0.000792, loss: 0.4221
2022-09-21 17:34:34 - train: epoch 0026, iter [00520, 01251], lr: 0.000792, loss: 0.4295
2022-09-21 17:34:55 - train: epoch 0026, iter [00530, 01251], lr: 0.000793, loss: 0.4216
2022-09-21 17:35:16 - train: epoch 0026, iter [00540, 01251], lr: 0.000793, loss: 0.4362
2022-09-21 17:35:38 - train: epoch 0026, iter [00550, 01251], lr: 0.000793, loss: 0.4255
2022-09-21 17:35:59 - train: epoch 0026, iter [00560, 01251], lr: 0.000793, loss: 0.4182
2022-09-21 17:36:20 - train: epoch 0026, iter [00570, 01251], lr: 0.000794, loss: 0.4115
2022-09-21 17:36:41 - train: epoch 0026, iter [00580, 01251], lr: 0.000794, loss: 0.4147
2022-09-21 17:37:02 - train: epoch 0026, iter [00590, 01251], lr: 0.000794, loss: 0.4303
2022-09-21 17:37:24 - train: epoch 0026, iter [00600, 01251], lr: 0.000794, loss: 0.4335
2022-09-21 17:37:45 - train: epoch 0026, iter [00610, 01251], lr: 0.000795, loss: 0.4378
2022-09-21 17:38:06 - train: epoch 0026, iter [00620, 01251], lr: 0.000795, loss: 0.4227
2022-09-21 17:38:27 - train: epoch 0026, iter [00630, 01251], lr: 0.000795, loss: 0.4410
2022-09-21 17:38:48 - train: epoch 0026, iter [00640, 01251], lr: 0.000795, loss: 0.4353
2022-09-21 17:39:10 - train: epoch 0026, iter [00650, 01251], lr: 0.000796, loss: 0.4243
2022-09-21 17:39:31 - train: epoch 0026, iter [00660, 01251], lr: 0.000796, loss: 0.4250
2022-09-21 17:39:52 - train: epoch 0026, iter [00670, 01251], lr: 0.000796, loss: 0.4211
2022-09-21 17:40:13 - train: epoch 0026, iter [00680, 01251], lr: 0.000796, loss: 0.4491
2022-09-21 17:40:34 - train: epoch 0026, iter [00690, 01251], lr: 0.000797, loss: 0.4053
2022-09-21 17:40:55 - train: epoch 0026, iter [00700, 01251], lr: 0.000797, loss: 0.4099
2022-09-21 17:41:16 - train: epoch 0026, iter [00710, 01251], lr: 0.000797, loss: 0.4340
2022-09-21 17:41:37 - train: epoch 0026, iter [00720, 01251], lr: 0.000797, loss: 0.4227
2022-09-21 17:41:58 - train: epoch 0026, iter [00730, 01251], lr: 0.000798, loss: 0.4251
2022-09-21 17:42:19 - train: epoch 0026, iter [00740, 01251], lr: 0.000798, loss: 0.4315
2022-09-21 17:42:40 - train: epoch 0026, iter [00750, 01251], lr: 0.000798, loss: 0.4122
2022-09-21 17:43:01 - train: epoch 0026, iter [00760, 01251], lr: 0.000798, loss: 0.4220
2022-09-21 17:43:23 - train: epoch 0026, iter [00770, 01251], lr: 0.000798, loss: 0.4380
2022-09-21 17:43:44 - train: epoch 0026, iter [00780, 01251], lr: 0.000799, loss: 0.4368
2022-09-21 17:44:05 - train: epoch 0026, iter [00790, 01251], lr: 0.000799, loss: 0.4255
2022-09-21 17:44:26 - train: epoch 0026, iter [00800, 01251], lr: 0.000799, loss: 0.4377
2022-09-21 17:44:47 - train: epoch 0026, iter [00810, 01251], lr: 0.000799, loss: 0.4294
2022-09-21 17:45:08 - train: epoch 0026, iter [00820, 01251], lr: 0.000800, loss: 0.4481
2022-09-21 17:45:29 - train: epoch 0026, iter [00830, 01251], lr: 0.000800, loss: 0.4248
2022-09-21 17:45:50 - train: epoch 0026, iter [00840, 01251], lr: 0.000800, loss: 0.4118
2022-09-21 17:46:12 - train: epoch 0026, iter [00850, 01251], lr: 0.000800, loss: 0.4343
2022-09-21 17:46:33 - train: epoch 0026, iter [00860, 01251], lr: 0.000801, loss: 0.4356
2022-09-21 17:46:54 - train: epoch 0026, iter [00870, 01251], lr: 0.000801, loss: 0.4159
2022-09-21 17:47:15 - train: epoch 0026, iter [00880, 01251], lr: 0.000801, loss: 0.4272
2022-09-21 17:47:36 - train: epoch 0026, iter [00890, 01251], lr: 0.000801, loss: 0.4199
2022-09-21 17:47:57 - train: epoch 0026, iter [00900, 01251], lr: 0.000802, loss: 0.4137
2022-09-21 17:48:19 - train: epoch 0026, iter [00910, 01251], lr: 0.000802, loss: 0.4233
2022-09-21 17:48:40 - train: epoch 0026, iter [00920, 01251], lr: 0.000802, loss: 0.4240
2022-09-21 17:49:01 - train: epoch 0026, iter [00930, 01251], lr: 0.000802, loss: 0.4172
2022-09-21 17:49:22 - train: epoch 0026, iter [00940, 01251], lr: 0.000803, loss: 0.4284
2022-09-21 17:49:43 - train: epoch 0026, iter [00950, 01251], lr: 0.000803, loss: 0.4341
2022-09-21 17:50:04 - train: epoch 0026, iter [00960, 01251], lr: 0.000803, loss: 0.4118
2022-09-21 17:50:25 - train: epoch 0026, iter [00970, 01251], lr: 0.000803, loss: 0.4044
2022-09-21 17:50:47 - train: epoch 0026, iter [00980, 01251], lr: 0.000804, loss: 0.4331
2022-09-21 17:51:08 - train: epoch 0026, iter [00990, 01251], lr: 0.000804, loss: 0.4171
2022-09-21 17:51:29 - train: epoch 0026, iter [01000, 01251], lr: 0.000804, loss: 0.4101
2022-09-21 17:51:51 - train: epoch 0026, iter [01010, 01251], lr: 0.000804, loss: 0.4520
2022-09-21 17:52:12 - train: epoch 0026, iter [01020, 01251], lr: 0.000804, loss: 0.4164
2022-09-21 17:52:33 - train: epoch 0026, iter [01030, 01251], lr: 0.000805, loss: 0.4187
2022-09-21 17:52:54 - train: epoch 0026, iter [01040, 01251], lr: 0.000805, loss: 0.4408
2022-09-21 17:53:15 - train: epoch 0026, iter [01050, 01251], lr: 0.000805, loss: 0.4292
2022-09-21 17:53:36 - train: epoch 0026, iter [01060, 01251], lr: 0.000805, loss: 0.4284
2022-09-21 17:53:57 - train: epoch 0026, iter [01070, 01251], lr: 0.000806, loss: 0.4399
2022-09-21 17:54:19 - train: epoch 0026, iter [01080, 01251], lr: 0.000806, loss: 0.4167
2022-09-21 17:54:40 - train: epoch 0026, iter [01090, 01251], lr: 0.000806, loss: 0.4304
2022-09-21 17:55:01 - train: epoch 0026, iter [01100, 01251], lr: 0.000806, loss: 0.4393
2022-09-21 17:55:22 - train: epoch 0026, iter [01110, 01251], lr: 0.000807, loss: 0.4238
2022-09-21 17:55:43 - train: epoch 0026, iter [01120, 01251], lr: 0.000807, loss: 0.4137
2022-09-21 17:56:04 - train: epoch 0026, iter [01130, 01251], lr: 0.000807, loss: 0.4349
2022-09-21 17:56:25 - train: epoch 0026, iter [01140, 01251], lr: 0.000807, loss: 0.4333
2022-09-21 17:56:47 - train: epoch 0026, iter [01150, 01251], lr: 0.000808, loss: 0.4270
2022-09-21 17:57:08 - train: epoch 0026, iter [01160, 01251], lr: 0.000808, loss: 0.4228
2022-09-21 17:57:29 - train: epoch 0026, iter [01170, 01251], lr: 0.000808, loss: 0.4320
2022-09-21 17:57:50 - train: epoch 0026, iter [01180, 01251], lr: 0.000808, loss: 0.4271
2022-09-21 17:58:12 - train: epoch 0026, iter [01190, 01251], lr: 0.000809, loss: 0.4188
2022-09-21 17:58:33 - train: epoch 0026, iter [01200, 01251], lr: 0.000809, loss: 0.4450
2022-09-21 17:58:54 - train: epoch 0026, iter [01210, 01251], lr: 0.000809, loss: 0.4428
2022-09-21 17:59:15 - train: epoch 0026, iter [01220, 01251], lr: 0.000809, loss: 0.4331
2022-09-21 17:59:36 - train: epoch 0026, iter [01230, 01251], lr: 0.000809, loss: 0.4326
2022-09-21 17:59:58 - train: epoch 0026, iter [01240, 01251], lr: 0.000810, loss: 0.4334
2022-09-21 18:00:18 - train: epoch 0026, iter [01250, 01251], lr: 0.000810, loss: 0.4106
2022-09-21 18:00:22 - train: epoch 026, train_loss: 0.4266
2022-09-21 18:00:27 - until epoch: 026, best_loss: 0.4266
2022-09-21 18:00:27 - epoch 027 lr: 0.000810
2022-09-21 18:01:05 - train: epoch 0027, iter [00010, 01251], lr: 0.000810, loss: 0.4272
2022-09-21 18:01:26 - train: epoch 0027, iter [00020, 01251], lr: 0.000810, loss: 0.4144
2022-09-21 18:01:47 - train: epoch 0027, iter [00030, 01251], lr: 0.000811, loss: 0.4398
2022-09-21 18:02:08 - train: epoch 0027, iter [00040, 01251], lr: 0.000811, loss: 0.4315
2022-09-21 18:02:30 - train: epoch 0027, iter [00050, 01251], lr: 0.000811, loss: 0.4227
2022-09-21 18:02:51 - train: epoch 0027, iter [00060, 01251], lr: 0.000811, loss: 0.4158
2022-09-21 18:03:13 - train: epoch 0027, iter [00070, 01251], lr: 0.000812, loss: 0.4219
2022-09-21 18:03:34 - train: epoch 0027, iter [00080, 01251], lr: 0.000812, loss: 0.4266
2022-09-21 18:03:55 - train: epoch 0027, iter [00090, 01251], lr: 0.000812, loss: 0.4201
2022-09-21 18:04:16 - train: epoch 0027, iter [00100, 01251], lr: 0.000812, loss: 0.4461
2022-09-21 18:04:37 - train: epoch 0027, iter [00110, 01251], lr: 0.000813, loss: 0.4312
2022-09-21 18:04:59 - train: epoch 0027, iter [00120, 01251], lr: 0.000813, loss: 0.4352
2022-09-21 18:05:20 - train: epoch 0027, iter [00130, 01251], lr: 0.000813, loss: 0.4214
2022-09-21 18:05:41 - train: epoch 0027, iter [00140, 01251], lr: 0.000813, loss: 0.4278
2022-09-21 18:06:03 - train: epoch 0027, iter [00150, 01251], lr: 0.000814, loss: 0.4293
2022-09-21 18:06:23 - train: epoch 0027, iter [00160, 01251], lr: 0.000814, loss: 0.4382
2022-09-21 18:06:45 - train: epoch 0027, iter [00170, 01251], lr: 0.000814, loss: 0.4115
2022-09-21 18:07:06 - train: epoch 0027, iter [00180, 01251], lr: 0.000814, loss: 0.4231
2022-09-21 18:07:27 - train: epoch 0027, iter [00190, 01251], lr: 0.000815, loss: 0.4501
2022-09-21 18:07:48 - train: epoch 0027, iter [00200, 01251], lr: 0.000815, loss: 0.4190
2022-09-21 18:08:09 - train: epoch 0027, iter [00210, 01251], lr: 0.000815, loss: 0.4283
2022-09-21 18:08:30 - train: epoch 0027, iter [00220, 01251], lr: 0.000815, loss: 0.4243
2022-09-21 18:08:51 - train: epoch 0027, iter [00230, 01251], lr: 0.000816, loss: 0.4362
2022-09-21 18:09:12 - train: epoch 0027, iter [00240, 01251], lr: 0.000816, loss: 0.4224
2022-09-21 18:09:33 - train: epoch 0027, iter [00250, 01251], lr: 0.000816, loss: 0.4275
2022-09-21 18:09:55 - train: epoch 0027, iter [00260, 01251], lr: 0.000816, loss: 0.4224
2022-09-21 18:10:16 - train: epoch 0027, iter [00270, 01251], lr: 0.000816, loss: 0.4379
2022-09-21 18:10:37 - train: epoch 0027, iter [00280, 01251], lr: 0.000817, loss: 0.4282
2022-09-21 18:10:58 - train: epoch 0027, iter [00290, 01251], lr: 0.000817, loss: 0.4135
2022-09-21 18:11:19 - train: epoch 0027, iter [00300, 01251], lr: 0.000817, loss: 0.4267
2022-09-21 18:11:40 - train: epoch 0027, iter [00310, 01251], lr: 0.000817, loss: 0.4364
2022-09-21 18:12:01 - train: epoch 0027, iter [00320, 01251], lr: 0.000818, loss: 0.4198
2022-09-21 18:12:22 - train: epoch 0027, iter [00330, 01251], lr: 0.000818, loss: 0.4330
2022-09-21 18:12:44 - train: epoch 0027, iter [00340, 01251], lr: 0.000818, loss: 0.4289
2022-09-21 18:13:05 - train: epoch 0027, iter [00350, 01251], lr: 0.000818, loss: 0.4352
2022-09-21 18:13:26 - train: epoch 0027, iter [00360, 01251], lr: 0.000819, loss: 0.4447
2022-09-21 18:13:47 - train: epoch 0027, iter [00370, 01251], lr: 0.000819, loss: 0.4331
2022-09-21 18:14:08 - train: epoch 0027, iter [00380, 01251], lr: 0.000819, loss: 0.4242
2022-09-21 18:14:29 - train: epoch 0027, iter [00390, 01251], lr: 0.000819, loss: 0.4227
2022-09-21 18:14:50 - train: epoch 0027, iter [00400, 01251], lr: 0.000820, loss: 0.4409
2022-09-21 18:15:11 - train: epoch 0027, iter [00410, 01251], lr: 0.000820, loss: 0.4234
2022-09-21 18:15:33 - train: epoch 0027, iter [00420, 01251], lr: 0.000820, loss: 0.4472
2022-09-21 18:15:54 - train: epoch 0027, iter [00430, 01251], lr: 0.000820, loss: 0.4205
2022-09-21 18:16:15 - train: epoch 0027, iter [00440, 01251], lr: 0.000821, loss: 0.4195
2022-09-21 18:16:36 - train: epoch 0027, iter [00450, 01251], lr: 0.000821, loss: 0.4112
2022-09-21 18:16:57 - train: epoch 0027, iter [00460, 01251], lr: 0.000821, loss: 0.4146
2022-09-21 18:17:18 - train: epoch 0027, iter [00470, 01251], lr: 0.000821, loss: 0.4175
2022-09-21 18:17:39 - train: epoch 0027, iter [00480, 01251], lr: 0.000822, loss: 0.4063
2022-09-21 18:18:00 - train: epoch 0027, iter [00490, 01251], lr: 0.000822, loss: 0.4302
2022-09-21 18:18:22 - train: epoch 0027, iter [00500, 01251], lr: 0.000822, loss: 0.4420
2022-09-21 18:18:43 - train: epoch 0027, iter [00510, 01251], lr: 0.000822, loss: 0.3947
2022-09-21 18:19:04 - train: epoch 0027, iter [00520, 01251], lr: 0.000822, loss: 0.4310
2022-09-21 18:19:25 - train: epoch 0027, iter [00530, 01251], lr: 0.000823, loss: 0.4503
2022-09-21 18:19:46 - train: epoch 0027, iter [00540, 01251], lr: 0.000823, loss: 0.4359
2022-09-21 18:20:07 - train: epoch 0027, iter [00550, 01251], lr: 0.000823, loss: 0.4266
2022-09-21 18:20:28 - train: epoch 0027, iter [00560, 01251], lr: 0.000823, loss: 0.4310
2022-09-21 18:20:49 - train: epoch 0027, iter [00570, 01251], lr: 0.000824, loss: 0.4285
2022-09-21 18:21:10 - train: epoch 0027, iter [00580, 01251], lr: 0.000824, loss: 0.4514
2022-09-21 18:21:31 - train: epoch 0027, iter [00590, 01251], lr: 0.000824, loss: 0.4208
2022-09-21 18:21:52 - train: epoch 0027, iter [00600, 01251], lr: 0.000824, loss: 0.4285
2022-09-21 18:22:13 - train: epoch 0027, iter [00610, 01251], lr: 0.000825, loss: 0.4009
2022-09-21 18:22:34 - train: epoch 0027, iter [00620, 01251], lr: 0.000825, loss: 0.4165
2022-09-21 18:22:55 - train: epoch 0027, iter [00630, 01251], lr: 0.000825, loss: 0.4360
2022-09-21 18:23:16 - train: epoch 0027, iter [00640, 01251], lr: 0.000825, loss: 0.4435
2022-09-21 18:23:37 - train: epoch 0027, iter [00650, 01251], lr: 0.000826, loss: 0.4304
2022-09-21 18:23:58 - train: epoch 0027, iter [00660, 01251], lr: 0.000826, loss: 0.4333
2022-09-21 18:24:19 - train: epoch 0027, iter [00670, 01251], lr: 0.000826, loss: 0.4223
2022-09-21 18:24:40 - train: epoch 0027, iter [00680, 01251], lr: 0.000826, loss: 0.4314
2022-09-21 18:25:01 - train: epoch 0027, iter [00690, 01251], lr: 0.000827, loss: 0.4213
2022-09-21 18:25:22 - train: epoch 0027, iter [00700, 01251], lr: 0.000827, loss: 0.4250
2022-09-21 18:25:43 - train: epoch 0027, iter [00710, 01251], lr: 0.000827, loss: 0.4418
2022-09-21 18:26:04 - train: epoch 0027, iter [00720, 01251], lr: 0.000827, loss: 0.4330
2022-09-21 18:26:25 - train: epoch 0027, iter [00730, 01251], lr: 0.000828, loss: 0.4342
2022-09-21 18:26:46 - train: epoch 0027, iter [00740, 01251], lr: 0.000828, loss: 0.4239
2022-09-21 18:27:07 - train: epoch 0027, iter [00750, 01251], lr: 0.000828, loss: 0.4252
2022-09-21 18:27:28 - train: epoch 0027, iter [00760, 01251], lr: 0.000828, loss: 0.4459
2022-09-21 18:27:49 - train: epoch 0027, iter [00770, 01251], lr: 0.000828, loss: 0.4328
2022-09-21 18:28:10 - train: epoch 0027, iter [00780, 01251], lr: 0.000829, loss: 0.4438
2022-09-21 18:28:31 - train: epoch 0027, iter [00790, 01251], lr: 0.000829, loss: 0.4052
2022-09-21 18:28:52 - train: epoch 0027, iter [00800, 01251], lr: 0.000829, loss: 0.4248
2022-09-21 18:29:13 - train: epoch 0027, iter [00810, 01251], lr: 0.000829, loss: 0.4361
2022-09-21 18:29:34 - train: epoch 0027, iter [00820, 01251], lr: 0.000830, loss: 0.4481
2022-09-21 18:29:55 - train: epoch 0027, iter [00830, 01251], lr: 0.000830, loss: 0.4036
2022-09-21 18:30:16 - train: epoch 0027, iter [00840, 01251], lr: 0.000830, loss: 0.4517
2022-09-21 18:30:37 - train: epoch 0027, iter [00850, 01251], lr: 0.000830, loss: 0.4013
2022-09-21 18:30:58 - train: epoch 0027, iter [00860, 01251], lr: 0.000831, loss: 0.4398
2022-09-21 18:31:19 - train: epoch 0027, iter [00870, 01251], lr: 0.000831, loss: 0.4396
2022-09-21 18:31:40 - train: epoch 0027, iter [00880, 01251], lr: 0.000831, loss: 0.4214
2022-09-21 18:32:01 - train: epoch 0027, iter [00890, 01251], lr: 0.000831, loss: 0.4445
2022-09-21 18:32:22 - train: epoch 0027, iter [00900, 01251], lr: 0.000832, loss: 0.4285
2022-09-21 18:32:43 - train: epoch 0027, iter [00910, 01251], lr: 0.000832, loss: 0.4119
2022-09-21 18:33:04 - train: epoch 0027, iter [00920, 01251], lr: 0.000832, loss: 0.4291
2022-09-21 18:33:25 - train: epoch 0027, iter [00930, 01251], lr: 0.000832, loss: 0.4143
2022-09-21 18:33:46 - train: epoch 0027, iter [00940, 01251], lr: 0.000833, loss: 0.4391
2022-09-21 18:34:07 - train: epoch 0027, iter [00950, 01251], lr: 0.000833, loss: 0.4233
2022-09-21 18:34:28 - train: epoch 0027, iter [00960, 01251], lr: 0.000833, loss: 0.4204
2022-09-21 18:34:49 - train: epoch 0027, iter [00970, 01251], lr: 0.000833, loss: 0.4173
2022-09-21 18:35:10 - train: epoch 0027, iter [00980, 01251], lr: 0.000834, loss: 0.4321
2022-09-21 18:35:30 - train: epoch 0027, iter [00990, 01251], lr: 0.000834, loss: 0.4241
2022-09-21 18:35:52 - train: epoch 0027, iter [01000, 01251], lr: 0.000834, loss: 0.4327
2022-09-21 18:36:13 - train: epoch 0027, iter [01010, 01251], lr: 0.000834, loss: 0.4213
2022-09-21 18:36:34 - train: epoch 0027, iter [01020, 01251], lr: 0.000834, loss: 0.4158
2022-09-21 18:36:55 - train: epoch 0027, iter [01030, 01251], lr: 0.000835, loss: 0.4210
2022-09-21 18:37:16 - train: epoch 0027, iter [01040, 01251], lr: 0.000835, loss: 0.4064
2022-09-21 18:37:37 - train: epoch 0027, iter [01050, 01251], lr: 0.000835, loss: 0.4206
2022-09-21 18:37:58 - train: epoch 0027, iter [01060, 01251], lr: 0.000835, loss: 0.4436
2022-09-21 18:38:19 - train: epoch 0027, iter [01070, 01251], lr: 0.000836, loss: 0.4349
2022-09-21 18:38:40 - train: epoch 0027, iter [01080, 01251], lr: 0.000836, loss: 0.4129
2022-09-21 18:39:01 - train: epoch 0027, iter [01090, 01251], lr: 0.000836, loss: 0.4202
2022-09-21 18:39:22 - train: epoch 0027, iter [01100, 01251], lr: 0.000836, loss: 0.4274
2022-09-21 18:39:43 - train: epoch 0027, iter [01110, 01251], lr: 0.000837, loss: 0.4197
2022-09-21 18:40:04 - train: epoch 0027, iter [01120, 01251], lr: 0.000837, loss: 0.4138
2022-09-21 18:40:25 - train: epoch 0027, iter [01130, 01251], lr: 0.000837, loss: 0.4222
2022-09-21 18:40:46 - train: epoch 0027, iter [01140, 01251], lr: 0.000837, loss: 0.4296
2022-09-21 18:41:07 - train: epoch 0027, iter [01150, 01251], lr: 0.000838, loss: 0.4328
2022-09-21 18:41:28 - train: epoch 0027, iter [01160, 01251], lr: 0.000838, loss: 0.4099
2022-09-21 18:41:49 - train: epoch 0027, iter [01170, 01251], lr: 0.000838, loss: 0.4405
2022-09-21 18:42:10 - train: epoch 0027, iter [01180, 01251], lr: 0.000838, loss: 0.4425
2022-09-21 18:42:31 - train: epoch 0027, iter [01190, 01251], lr: 0.000839, loss: 0.4001
2022-09-21 18:42:52 - train: epoch 0027, iter [01200, 01251], lr: 0.000839, loss: 0.4298
2022-09-21 18:43:13 - train: epoch 0027, iter [01210, 01251], lr: 0.000839, loss: 0.4259
2022-09-21 18:43:35 - train: epoch 0027, iter [01220, 01251], lr: 0.000839, loss: 0.4316
2022-09-21 18:43:55 - train: epoch 0027, iter [01230, 01251], lr: 0.000839, loss: 0.4240
2022-09-21 18:44:16 - train: epoch 0027, iter [01240, 01251], lr: 0.000840, loss: 0.4157
2022-09-21 18:44:36 - train: epoch 0027, iter [01250, 01251], lr: 0.000840, loss: 0.4253
2022-09-21 18:44:41 - train: epoch 027, train_loss: 0.4260
2022-09-21 18:44:46 - until epoch: 027, best_loss: 0.4260
2022-09-21 18:44:46 - epoch 028 lr: 0.000840
2022-09-21 18:45:24 - train: epoch 0028, iter [00010, 01251], lr: 0.000840, loss: 0.4268
2022-09-21 18:45:45 - train: epoch 0028, iter [00020, 01251], lr: 0.000840, loss: 0.4124
2022-09-21 18:46:07 - train: epoch 0028, iter [00030, 01251], lr: 0.000841, loss: 0.4400
2022-09-21 18:46:28 - train: epoch 0028, iter [00040, 01251], lr: 0.000841, loss: 0.4279
2022-09-21 18:46:49 - train: epoch 0028, iter [00050, 01251], lr: 0.000841, loss: 0.4109
2022-09-21 18:47:11 - train: epoch 0028, iter [00060, 01251], lr: 0.000841, loss: 0.4154
2022-09-21 18:47:32 - train: epoch 0028, iter [00070, 01251], lr: 0.000842, loss: 0.4124
2022-09-21 18:47:54 - train: epoch 0028, iter [00080, 01251], lr: 0.000842, loss: 0.4298
2022-09-21 18:48:15 - train: epoch 0028, iter [00090, 01251], lr: 0.000842, loss: 0.4139
2022-09-21 18:48:36 - train: epoch 0028, iter [00100, 01251], lr: 0.000842, loss: 0.4267
2022-09-21 18:48:58 - train: epoch 0028, iter [00110, 01251], lr: 0.000843, loss: 0.4300
2022-09-21 18:49:19 - train: epoch 0028, iter [00120, 01251], lr: 0.000843, loss: 0.4252
2022-09-21 18:49:40 - train: epoch 0028, iter [00130, 01251], lr: 0.000843, loss: 0.4032
2022-09-21 18:50:01 - train: epoch 0028, iter [00140, 01251], lr: 0.000843, loss: 0.4141
2022-09-21 18:50:23 - train: epoch 0028, iter [00150, 01251], lr: 0.000844, loss: 0.4083
2022-09-21 18:50:44 - train: epoch 0028, iter [00160, 01251], lr: 0.000844, loss: 0.4316
2022-09-21 18:51:06 - train: epoch 0028, iter [00170, 01251], lr: 0.000844, loss: 0.4212
2022-09-21 18:51:27 - train: epoch 0028, iter [00180, 01251], lr: 0.000844, loss: 0.4157
2022-09-21 18:51:48 - train: epoch 0028, iter [00190, 01251], lr: 0.000845, loss: 0.4335
2022-09-21 18:52:10 - train: epoch 0028, iter [00200, 01251], lr: 0.000845, loss: 0.4469
2022-09-21 18:52:31 - train: epoch 0028, iter [00210, 01251], lr: 0.000845, loss: 0.4145
2022-09-21 18:52:52 - train: epoch 0028, iter [00220, 01251], lr: 0.000845, loss: 0.4334
2022-09-21 18:53:13 - train: epoch 0028, iter [00230, 01251], lr: 0.000846, loss: 0.4364
2022-09-21 18:53:34 - train: epoch 0028, iter [00240, 01251], lr: 0.000846, loss: 0.4228
2022-09-21 18:53:55 - train: epoch 0028, iter [00250, 01251], lr: 0.000846, loss: 0.4224
2022-09-21 18:54:17 - train: epoch 0028, iter [00260, 01251], lr: 0.000846, loss: 0.4425
2022-09-21 18:54:38 - train: epoch 0028, iter [00270, 01251], lr: 0.000846, loss: 0.4136
2022-09-21 18:54:59 - train: epoch 0028, iter [00280, 01251], lr: 0.000847, loss: 0.4236
2022-09-21 18:55:20 - train: epoch 0028, iter [00290, 01251], lr: 0.000847, loss: 0.4404
2022-09-21 18:55:41 - train: epoch 0028, iter [00300, 01251], lr: 0.000847, loss: 0.4385
2022-09-21 18:56:02 - train: epoch 0028, iter [00310, 01251], lr: 0.000847, loss: 0.4255
2022-09-21 18:56:23 - train: epoch 0028, iter [00320, 01251], lr: 0.000848, loss: 0.4231
2022-09-21 18:56:45 - train: epoch 0028, iter [00330, 01251], lr: 0.000848, loss: 0.4307
2022-09-21 18:57:05 - train: epoch 0028, iter [00340, 01251], lr: 0.000848, loss: 0.4054
2022-09-21 18:57:26 - train: epoch 0028, iter [00350, 01251], lr: 0.000848, loss: 0.4237
2022-09-21 18:57:48 - train: epoch 0028, iter [00360, 01251], lr: 0.000849, loss: 0.4343
2022-09-21 18:58:09 - train: epoch 0028, iter [00370, 01251], lr: 0.000849, loss: 0.4222
2022-09-21 18:58:30 - train: epoch 0028, iter [00380, 01251], lr: 0.000849, loss: 0.4110
2022-09-21 18:58:51 - train: epoch 0028, iter [00390, 01251], lr: 0.000849, loss: 0.4296
2022-09-21 18:59:12 - train: epoch 0028, iter [00400, 01251], lr: 0.000850, loss: 0.4173
2022-09-21 18:59:33 - train: epoch 0028, iter [00410, 01251], lr: 0.000850, loss: 0.4248
2022-09-21 18:59:54 - train: epoch 0028, iter [00420, 01251], lr: 0.000850, loss: 0.4364
2022-09-21 19:00:15 - train: epoch 0028, iter [00430, 01251], lr: 0.000850, loss: 0.4239
2022-09-21 19:00:36 - train: epoch 0028, iter [00440, 01251], lr: 0.000851, loss: 0.4083
2022-09-21 19:00:57 - train: epoch 0028, iter [00450, 01251], lr: 0.000851, loss: 0.4404
2022-09-21 19:01:18 - train: epoch 0028, iter [00460, 01251], lr: 0.000851, loss: 0.4447
2022-09-21 19:01:38 - train: epoch 0028, iter [00470, 01251], lr: 0.000851, loss: 0.4158
2022-09-21 19:01:59 - train: epoch 0028, iter [00480, 01251], lr: 0.000852, loss: 0.4477
2022-09-21 19:02:20 - train: epoch 0028, iter [00490, 01251], lr: 0.000852, loss: 0.4260
2022-09-21 19:02:41 - train: epoch 0028, iter [00500, 01251], lr: 0.000852, loss: 0.4269
2022-09-21 19:03:02 - train: epoch 0028, iter [00510, 01251], lr: 0.000852, loss: 0.4265
2022-09-21 19:03:22 - train: epoch 0028, iter [00520, 01251], lr: 0.000852, loss: 0.4285
2022-09-21 19:03:43 - train: epoch 0028, iter [00530, 01251], lr: 0.000853, loss: 0.4202
2022-09-21 19:04:04 - train: epoch 0028, iter [00540, 01251], lr: 0.000853, loss: 0.4366
2022-09-21 19:04:25 - train: epoch 0028, iter [00550, 01251], lr: 0.000853, loss: 0.4319
2022-09-21 19:04:46 - train: epoch 0028, iter [00560, 01251], lr: 0.000853, loss: 0.4283
2022-09-21 19:05:07 - train: epoch 0028, iter [00570, 01251], lr: 0.000854, loss: 0.4199
2022-09-21 19:05:28 - train: epoch 0028, iter [00580, 01251], lr: 0.000854, loss: 0.4179
2022-09-21 19:05:49 - train: epoch 0028, iter [00590, 01251], lr: 0.000854, loss: 0.4326
2022-09-21 19:06:09 - train: epoch 0028, iter [00600, 01251], lr: 0.000854, loss: 0.4287
2022-09-21 19:06:30 - train: epoch 0028, iter [00610, 01251], lr: 0.000855, loss: 0.4268
2022-09-21 19:06:51 - train: epoch 0028, iter [00620, 01251], lr: 0.000855, loss: 0.4300
2022-09-21 19:07:12 - train: epoch 0028, iter [00630, 01251], lr: 0.000855, loss: 0.4312
2022-09-21 19:07:32 - train: epoch 0028, iter [00640, 01251], lr: 0.000855, loss: 0.4219
2022-09-21 19:07:53 - train: epoch 0028, iter [00650, 01251], lr: 0.000856, loss: 0.4278
2022-09-21 19:08:14 - train: epoch 0028, iter [00660, 01251], lr: 0.000856, loss: 0.4336
2022-09-21 19:08:35 - train: epoch 0028, iter [00670, 01251], lr: 0.000856, loss: 0.3990
2022-09-21 19:08:56 - train: epoch 0028, iter [00680, 01251], lr: 0.000856, loss: 0.4049
2022-09-21 19:09:17 - train: epoch 0028, iter [00690, 01251], lr: 0.000857, loss: 0.4283
2022-09-21 19:09:38 - train: epoch 0028, iter [00700, 01251], lr: 0.000857, loss: 0.4269
2022-09-21 19:09:58 - train: epoch 0028, iter [00710, 01251], lr: 0.000857, loss: 0.4360
2022-09-21 19:10:19 - train: epoch 0028, iter [00720, 01251], lr: 0.000857, loss: 0.4201
2022-09-21 19:10:39 - train: epoch 0028, iter [00730, 01251], lr: 0.000858, loss: 0.4032
2022-09-21 19:11:00 - train: epoch 0028, iter [00740, 01251], lr: 0.000858, loss: 0.4191
2022-09-21 19:11:21 - train: epoch 0028, iter [00750, 01251], lr: 0.000858, loss: 0.4255
2022-09-21 19:11:41 - train: epoch 0028, iter [00760, 01251], lr: 0.000858, loss: 0.4337
2022-09-21 19:12:02 - train: epoch 0028, iter [00770, 01251], lr: 0.000858, loss: 0.4206
2022-09-21 19:12:23 - train: epoch 0028, iter [00780, 01251], lr: 0.000859, loss: 0.4512
2022-09-21 19:12:44 - train: epoch 0028, iter [00790, 01251], lr: 0.000859, loss: 0.4340
2022-09-21 19:13:04 - train: epoch 0028, iter [00800, 01251], lr: 0.000859, loss: 0.4260
2022-09-21 19:13:25 - train: epoch 0028, iter [00810, 01251], lr: 0.000859, loss: 0.4299
2022-09-21 19:13:45 - train: epoch 0028, iter [00820, 01251], lr: 0.000860, loss: 0.4285
2022-09-21 19:14:06 - train: epoch 0028, iter [00830, 01251], lr: 0.000860, loss: 0.4125
2022-09-21 19:14:26 - train: epoch 0028, iter [00840, 01251], lr: 0.000860, loss: 0.4140
2022-09-21 19:14:47 - train: epoch 0028, iter [00850, 01251], lr: 0.000860, loss: 0.4125
2022-09-21 19:15:08 - train: epoch 0028, iter [00860, 01251], lr: 0.000861, loss: 0.4053
2022-09-21 19:15:28 - train: epoch 0028, iter [00870, 01251], lr: 0.000861, loss: 0.4334
2022-09-21 19:15:49 - train: epoch 0028, iter [00880, 01251], lr: 0.000861, loss: 0.4276
2022-09-21 19:16:10 - train: epoch 0028, iter [00890, 01251], lr: 0.000861, loss: 0.4177
2022-09-21 19:16:30 - train: epoch 0028, iter [00900, 01251], lr: 0.000862, loss: 0.4396
2022-09-21 19:16:51 - train: epoch 0028, iter [00910, 01251], lr: 0.000862, loss: 0.4379
2022-09-21 19:17:12 - train: epoch 0028, iter [00920, 01251], lr: 0.000862, loss: 0.4335
2022-09-21 19:17:32 - train: epoch 0028, iter [00930, 01251], lr: 0.000862, loss: 0.4199
2022-09-21 19:17:53 - train: epoch 0028, iter [00940, 01251], lr: 0.000863, loss: 0.4113
2022-09-21 19:18:14 - train: epoch 0028, iter [00950, 01251], lr: 0.000863, loss: 0.4139
2022-09-21 19:18:34 - train: epoch 0028, iter [00960, 01251], lr: 0.000863, loss: 0.4314
2022-09-21 19:18:55 - train: epoch 0028, iter [00970, 01251], lr: 0.000863, loss: 0.4157
2022-09-21 19:19:16 - train: epoch 0028, iter [00980, 01251], lr: 0.000864, loss: 0.4301
2022-09-21 19:19:37 - train: epoch 0028, iter [00990, 01251], lr: 0.000864, loss: 0.4291
2022-09-21 19:19:57 - train: epoch 0028, iter [01000, 01251], lr: 0.000864, loss: 0.4222
2022-09-21 19:20:18 - train: epoch 0028, iter [01010, 01251], lr: 0.000864, loss: 0.4083
2022-09-21 19:20:38 - train: epoch 0028, iter [01020, 01251], lr: 0.000864, loss: 0.4177
2022-09-21 19:20:59 - train: epoch 0028, iter [01030, 01251], lr: 0.000865, loss: 0.4300
2022-09-21 19:21:19 - train: epoch 0028, iter [01040, 01251], lr: 0.000865, loss: 0.3969
2022-09-21 19:21:40 - train: epoch 0028, iter [01050, 01251], lr: 0.000865, loss: 0.4234
2022-09-21 19:22:01 - train: epoch 0028, iter [01060, 01251], lr: 0.000865, loss: 0.4275
2022-09-21 19:22:21 - train: epoch 0028, iter [01070, 01251], lr: 0.000866, loss: 0.4281
2022-09-21 19:22:42 - train: epoch 0028, iter [01080, 01251], lr: 0.000866, loss: 0.4139
2022-09-21 19:23:03 - train: epoch 0028, iter [01090, 01251], lr: 0.000866, loss: 0.4145
2022-09-21 19:23:23 - train: epoch 0028, iter [01100, 01251], lr: 0.000866, loss: 0.4260
2022-09-21 19:23:44 - train: epoch 0028, iter [01110, 01251], lr: 0.000867, loss: 0.4349
2022-09-21 19:24:05 - train: epoch 0028, iter [01120, 01251], lr: 0.000867, loss: 0.4239
2022-09-21 19:24:26 - train: epoch 0028, iter [01130, 01251], lr: 0.000867, loss: 0.4367
2022-09-21 19:24:46 - train: epoch 0028, iter [01140, 01251], lr: 0.000867, loss: 0.4494
2022-09-21 19:25:07 - train: epoch 0028, iter [01150, 01251], lr: 0.000868, loss: 0.4114
2022-09-21 19:25:28 - train: epoch 0028, iter [01160, 01251], lr: 0.000868, loss: 0.4070
2022-09-21 19:25:48 - train: epoch 0028, iter [01170, 01251], lr: 0.000868, loss: 0.4232
2022-09-21 19:26:09 - train: epoch 0028, iter [01180, 01251], lr: 0.000868, loss: 0.4017
2022-09-21 19:26:30 - train: epoch 0028, iter [01190, 01251], lr: 0.000869, loss: 0.4218
2022-09-21 19:26:50 - train: epoch 0028, iter [01200, 01251], lr: 0.000869, loss: 0.4455
2022-09-21 19:27:11 - train: epoch 0028, iter [01210, 01251], lr: 0.000869, loss: 0.4157
2022-09-21 19:27:32 - train: epoch 0028, iter [01220, 01251], lr: 0.000869, loss: 0.4374
2022-09-21 19:27:52 - train: epoch 0028, iter [01230, 01251], lr: 0.000869, loss: 0.4279
2022-09-21 19:28:13 - train: epoch 0028, iter [01240, 01251], lr: 0.000870, loss: 0.4319
2022-09-21 19:28:33 - train: epoch 0028, iter [01250, 01251], lr: 0.000870, loss: 0.4400
2022-09-21 19:28:37 - train: epoch 028, train_loss: 0.4255
2022-09-21 19:28:42 - until epoch: 028, best_loss: 0.4255
2022-09-21 19:28:42 - epoch 029 lr: 0.000870
2022-09-21 19:29:19 - train: epoch 0029, iter [00010, 01251], lr: 0.000870, loss: 0.4255
2022-09-21 19:29:40 - train: epoch 0029, iter [00020, 01251], lr: 0.000870, loss: 0.4152
2022-09-21 19:30:01 - train: epoch 0029, iter [00030, 01251], lr: 0.000871, loss: 0.4408
2022-09-21 19:30:21 - train: epoch 0029, iter [00040, 01251], lr: 0.000871, loss: 0.4336
2022-09-21 19:30:42 - train: epoch 0029, iter [00050, 01251], lr: 0.000871, loss: 0.4182
2022-09-21 19:31:02 - train: epoch 0029, iter [00060, 01251], lr: 0.000871, loss: 0.4385
2022-09-21 19:31:23 - train: epoch 0029, iter [00070, 01251], lr: 0.000872, loss: 0.4075
2022-09-21 19:31:44 - train: epoch 0029, iter [00080, 01251], lr: 0.000872, loss: 0.4289
2022-09-21 19:32:04 - train: epoch 0029, iter [00090, 01251], lr: 0.000872, loss: 0.4346
2022-09-21 19:32:25 - train: epoch 0029, iter [00100, 01251], lr: 0.000872, loss: 0.4336
2022-09-21 19:32:46 - train: epoch 0029, iter [00110, 01251], lr: 0.000873, loss: 0.4299
2022-09-21 19:33:07 - train: epoch 0029, iter [00120, 01251], lr: 0.000873, loss: 0.4224
2022-09-21 19:33:27 - train: epoch 0029, iter [00130, 01251], lr: 0.000873, loss: 0.4271
2022-09-21 19:33:48 - train: epoch 0029, iter [00140, 01251], lr: 0.000873, loss: 0.4400
2022-09-21 19:34:08 - train: epoch 0029, iter [00150, 01251], lr: 0.000874, loss: 0.4070
2022-09-21 19:34:29 - train: epoch 0029, iter [00160, 01251], lr: 0.000874, loss: 0.4226
2022-09-21 19:34:49 - train: epoch 0029, iter [00170, 01251], lr: 0.000874, loss: 0.4238
2022-09-21 19:35:10 - train: epoch 0029, iter [00180, 01251], lr: 0.000874, loss: 0.4286
2022-09-21 19:35:31 - train: epoch 0029, iter [00190, 01251], lr: 0.000875, loss: 0.4243
2022-09-21 19:35:52 - train: epoch 0029, iter [00200, 01251], lr: 0.000875, loss: 0.4166
2022-09-21 19:36:12 - train: epoch 0029, iter [00210, 01251], lr: 0.000875, loss: 0.4384
2022-09-21 19:36:33 - train: epoch 0029, iter [00220, 01251], lr: 0.000875, loss: 0.4213
2022-09-21 19:36:54 - train: epoch 0029, iter [00230, 01251], lr: 0.000876, loss: 0.4418
2022-09-21 19:37:14 - train: epoch 0029, iter [00240, 01251], lr: 0.000876, loss: 0.4259
2022-09-21 19:37:35 - train: epoch 0029, iter [00250, 01251], lr: 0.000876, loss: 0.4289
2022-09-21 19:37:56 - train: epoch 0029, iter [00260, 01251], lr: 0.000876, loss: 0.4174
2022-09-21 19:38:16 - train: epoch 0029, iter [00270, 01251], lr: 0.000876, loss: 0.4189
2022-09-21 19:38:37 - train: epoch 0029, iter [00280, 01251], lr: 0.000877, loss: 0.4285
2022-09-21 19:38:58 - train: epoch 0029, iter [00290, 01251], lr: 0.000877, loss: 0.4266
2022-09-21 19:39:19 - train: epoch 0029, iter [00300, 01251], lr: 0.000877, loss: 0.4149
2022-09-21 19:39:39 - train: epoch 0029, iter [00310, 01251], lr: 0.000877, loss: 0.4164
2022-09-21 19:40:00 - train: epoch 0029, iter [00320, 01251], lr: 0.000878, loss: 0.4200
2022-09-21 19:40:21 - train: epoch 0029, iter [00330, 01251], lr: 0.000878, loss: 0.4077
2022-09-21 19:40:41 - train: epoch 0029, iter [00340, 01251], lr: 0.000878, loss: 0.4290
2022-09-21 19:41:02 - train: epoch 0029, iter [00350, 01251], lr: 0.000878, loss: 0.4220
2022-09-21 19:41:23 - train: epoch 0029, iter [00360, 01251], lr: 0.000879, loss: 0.4379
2022-09-21 19:41:43 - train: epoch 0029, iter [00370, 01251], lr: 0.000879, loss: 0.4255
2022-09-21 19:42:04 - train: epoch 0029, iter [00380, 01251], lr: 0.000879, loss: 0.4375
2022-09-21 19:42:25 - train: epoch 0029, iter [00390, 01251], lr: 0.000879, loss: 0.4307
2022-09-21 19:42:45 - train: epoch 0029, iter [00400, 01251], lr: 0.000880, loss: 0.4310
2022-09-21 19:43:06 - train: epoch 0029, iter [00410, 01251], lr: 0.000880, loss: 0.4349
2022-09-21 19:43:27 - train: epoch 0029, iter [00420, 01251], lr: 0.000880, loss: 0.4357
2022-09-21 19:43:48 - train: epoch 0029, iter [00430, 01251], lr: 0.000880, loss: 0.4316
2022-09-21 19:44:08 - train: epoch 0029, iter [00440, 01251], lr: 0.000881, loss: 0.4213
2022-09-21 19:44:29 - train: epoch 0029, iter [00450, 01251], lr: 0.000881, loss: 0.4278
2022-09-21 19:44:50 - train: epoch 0029, iter [00460, 01251], lr: 0.000881, loss: 0.4335
2022-09-21 19:45:11 - train: epoch 0029, iter [00470, 01251], lr: 0.000881, loss: 0.4324
2022-09-21 19:45:31 - train: epoch 0029, iter [00480, 01251], lr: 0.000882, loss: 0.4400
2022-09-21 19:45:52 - train: epoch 0029, iter [00490, 01251], lr: 0.000882, loss: 0.4215
2022-09-21 19:46:12 - train: epoch 0029, iter [00500, 01251], lr: 0.000882, loss: 0.4263
2022-09-21 19:46:33 - train: epoch 0029, iter [00510, 01251], lr: 0.000882, loss: 0.4415
2022-09-21 19:46:54 - train: epoch 0029, iter [00520, 01251], lr: 0.000882, loss: 0.4226
2022-09-21 19:47:15 - train: epoch 0029, iter [00530, 01251], lr: 0.000883, loss: 0.4423
2022-09-21 19:47:36 - train: epoch 0029, iter [00540, 01251], lr: 0.000883, loss: 0.4495
2022-09-21 19:47:56 - train: epoch 0029, iter [00550, 01251], lr: 0.000883, loss: 0.4356
2022-09-21 19:48:17 - train: epoch 0029, iter [00560, 01251], lr: 0.000883, loss: 0.4308
2022-09-21 19:48:38 - train: epoch 0029, iter [00570, 01251], lr: 0.000884, loss: 0.4232
2022-09-21 19:48:59 - train: epoch 0029, iter [00580, 01251], lr: 0.000884, loss: 0.3996
2022-09-21 19:49:19 - train: epoch 0029, iter [00590, 01251], lr: 0.000884, loss: 0.4379
2022-09-21 19:49:40 - train: epoch 0029, iter [00600, 01251], lr: 0.000884, loss: 0.4294
2022-09-21 19:50:01 - train: epoch 0029, iter [00610, 01251], lr: 0.000885, loss: 0.4132
2022-09-21 19:50:21 - train: epoch 0029, iter [00620, 01251], lr: 0.000885, loss: 0.4301
2022-09-21 19:50:42 - train: epoch 0029, iter [00630, 01251], lr: 0.000885, loss: 0.4192
2022-09-21 19:51:03 - train: epoch 0029, iter [00640, 01251], lr: 0.000885, loss: 0.4214
2022-09-21 19:51:23 - train: epoch 0029, iter [00650, 01251], lr: 0.000886, loss: 0.4201
2022-09-21 19:51:44 - train: epoch 0029, iter [00660, 01251], lr: 0.000886, loss: 0.4112
2022-09-21 19:52:05 - train: epoch 0029, iter [00670, 01251], lr: 0.000886, loss: 0.4175
2022-09-21 19:52:25 - train: epoch 0029, iter [00680, 01251], lr: 0.000886, loss: 0.4139
2022-09-21 19:52:46 - train: epoch 0029, iter [00690, 01251], lr: 0.000887, loss: 0.4173
2022-09-21 19:53:07 - train: epoch 0029, iter [00700, 01251], lr: 0.000887, loss: 0.4243
2022-09-21 19:53:27 - train: epoch 0029, iter [00710, 01251], lr: 0.000887, loss: 0.4324
2022-09-21 19:53:48 - train: epoch 0029, iter [00720, 01251], lr: 0.000887, loss: 0.4282
2022-09-21 19:54:09 - train: epoch 0029, iter [00730, 01251], lr: 0.000888, loss: 0.4114
2022-09-21 19:54:29 - train: epoch 0029, iter [00740, 01251], lr: 0.000888, loss: 0.4191
2022-09-21 19:54:50 - train: epoch 0029, iter [00750, 01251], lr: 0.000888, loss: 0.4180
2022-09-21 19:55:11 - train: epoch 0029, iter [00760, 01251], lr: 0.000888, loss: 0.4147
2022-09-21 19:55:32 - train: epoch 0029, iter [00770, 01251], lr: 0.000888, loss: 0.4275
2022-09-21 19:55:52 - train: epoch 0029, iter [00780, 01251], lr: 0.000889, loss: 0.4514
2022-09-21 19:56:13 - train: epoch 0029, iter [00790, 01251], lr: 0.000889, loss: 0.4411
2022-09-21 19:56:34 - train: epoch 0029, iter [00800, 01251], lr: 0.000889, loss: 0.4391
2022-09-21 19:56:55 - train: epoch 0029, iter [00810, 01251], lr: 0.000889, loss: 0.4355
2022-09-21 19:57:15 - train: epoch 0029, iter [00820, 01251], lr: 0.000890, loss: 0.4309
2022-09-21 19:57:36 - train: epoch 0029, iter [00830, 01251], lr: 0.000890, loss: 0.4367
2022-09-21 19:57:57 - train: epoch 0029, iter [00840, 01251], lr: 0.000890, loss: 0.4079
2022-09-21 19:58:17 - train: epoch 0029, iter [00850, 01251], lr: 0.000890, loss: 0.4336
2022-09-21 19:58:38 - train: epoch 0029, iter [00860, 01251], lr: 0.000891, loss: 0.4234
2022-09-21 19:58:59 - train: epoch 0029, iter [00870, 01251], lr: 0.000891, loss: 0.4437
2022-09-21 19:59:19 - train: epoch 0029, iter [00880, 01251], lr: 0.000891, loss: 0.4248
2022-09-21 19:59:40 - train: epoch 0029, iter [00890, 01251], lr: 0.000891, loss: 0.4293
2022-09-21 20:00:01 - train: epoch 0029, iter [00900, 01251], lr: 0.000892, loss: 0.4256
2022-09-21 20:00:21 - train: epoch 0029, iter [00910, 01251], lr: 0.000892, loss: 0.4210
2022-09-21 20:00:42 - train: epoch 0029, iter [00920, 01251], lr: 0.000892, loss: 0.4117
2022-09-21 20:01:03 - train: epoch 0029, iter [00930, 01251], lr: 0.000892, loss: 0.4386
2022-09-21 20:01:23 - train: epoch 0029, iter [00940, 01251], lr: 0.000893, loss: 0.4183
2022-09-21 20:01:44 - train: epoch 0029, iter [00950, 01251], lr: 0.000893, loss: 0.4355
2022-09-21 20:02:05 - train: epoch 0029, iter [00960, 01251], lr: 0.000893, loss: 0.4281
2022-09-21 20:02:26 - train: epoch 0029, iter [00970, 01251], lr: 0.000893, loss: 0.4364
2022-09-21 20:02:46 - train: epoch 0029, iter [00980, 01251], lr: 0.000894, loss: 0.4144
2022-09-21 20:03:07 - train: epoch 0029, iter [00990, 01251], lr: 0.000894, loss: 0.4229
2022-09-21 20:03:28 - train: epoch 0029, iter [01000, 01251], lr: 0.000894, loss: 0.4189
2022-09-21 20:03:48 - train: epoch 0029, iter [01010, 01251], lr: 0.000894, loss: 0.4116
2022-09-21 20:04:09 - train: epoch 0029, iter [01020, 01251], lr: 0.000894, loss: 0.4335
2022-09-21 20:04:30 - train: epoch 0029, iter [01030, 01251], lr: 0.000895, loss: 0.4332
2022-09-21 20:04:50 - train: epoch 0029, iter [01040, 01251], lr: 0.000895, loss: 0.4364
2022-09-21 20:05:11 - train: epoch 0029, iter [01050, 01251], lr: 0.000895, loss: 0.4317
2022-09-21 20:05:31 - train: epoch 0029, iter [01060, 01251], lr: 0.000895, loss: 0.4258
2022-09-21 20:05:52 - train: epoch 0029, iter [01070, 01251], lr: 0.000896, loss: 0.4184
2022-09-21 20:06:13 - train: epoch 0029, iter [01080, 01251], lr: 0.000896, loss: 0.4156
2022-09-21 20:06:33 - train: epoch 0029, iter [01090, 01251], lr: 0.000896, loss: 0.4231
2022-09-21 20:06:54 - train: epoch 0029, iter [01100, 01251], lr: 0.000896, loss: 0.4349
2022-09-21 20:07:15 - train: epoch 0029, iter [01110, 01251], lr: 0.000897, loss: 0.4289
2022-09-21 20:07:35 - train: epoch 0029, iter [01120, 01251], lr: 0.000897, loss: 0.4312
2022-09-21 20:07:56 - train: epoch 0029, iter [01130, 01251], lr: 0.000897, loss: 0.4256
2022-09-21 20:08:17 - train: epoch 0029, iter [01140, 01251], lr: 0.000897, loss: 0.4312
2022-09-21 20:08:38 - train: epoch 0029, iter [01150, 01251], lr: 0.000898, loss: 0.4434
2022-09-21 20:08:58 - train: epoch 0029, iter [01160, 01251], lr: 0.000898, loss: 0.4336
2022-09-21 20:09:19 - train: epoch 0029, iter [01170, 01251], lr: 0.000898, loss: 0.4338
2022-09-21 20:09:40 - train: epoch 0029, iter [01180, 01251], lr: 0.000898, loss: 0.4151
2022-09-21 20:10:00 - train: epoch 0029, iter [01190, 01251], lr: 0.000899, loss: 0.4437
2022-09-21 20:10:21 - train: epoch 0029, iter [01200, 01251], lr: 0.000899, loss: 0.4201
2022-09-21 20:10:42 - train: epoch 0029, iter [01210, 01251], lr: 0.000899, loss: 0.4175
2022-09-21 20:11:02 - train: epoch 0029, iter [01220, 01251], lr: 0.000899, loss: 0.4513
2022-09-21 20:11:23 - train: epoch 0029, iter [01230, 01251], lr: 0.000899, loss: 0.4371
2022-09-21 20:11:44 - train: epoch 0029, iter [01240, 01251], lr: 0.000900, loss: 0.4368
2022-09-21 20:12:04 - train: epoch 0029, iter [01250, 01251], lr: 0.000900, loss: 0.4395
2022-09-21 20:12:08 - train: epoch 029, train_loss: 0.4250
2022-09-21 20:12:12 - until epoch: 029, best_loss: 0.4250
2022-09-21 20:12:12 - epoch 030 lr: 0.000900
2022-09-21 20:12:49 - train: epoch 0030, iter [00010, 01251], lr: 0.000900, loss: 0.4096
2022-09-21 20:13:09 - train: epoch 0030, iter [00020, 01251], lr: 0.000900, loss: 0.4166
2022-09-21 20:13:30 - train: epoch 0030, iter [00030, 01251], lr: 0.000901, loss: 0.4199
2022-09-21 20:13:50 - train: epoch 0030, iter [00040, 01251], lr: 0.000901, loss: 0.4365
2022-09-21 20:14:11 - train: epoch 0030, iter [00050, 01251], lr: 0.000901, loss: 0.4161
2022-09-21 20:14:32 - train: epoch 0030, iter [00060, 01251], lr: 0.000901, loss: 0.4239
2022-09-21 20:14:52 - train: epoch 0030, iter [00070, 01251], lr: 0.000902, loss: 0.4240
2022-09-21 20:15:13 - train: epoch 0030, iter [00080, 01251], lr: 0.000902, loss: 0.4313
2022-09-21 20:15:33 - train: epoch 0030, iter [00090, 01251], lr: 0.000902, loss: 0.4210
2022-09-21 20:15:54 - train: epoch 0030, iter [00100, 01251], lr: 0.000902, loss: 0.4288
2022-09-21 20:16:15 - train: epoch 0030, iter [00110, 01251], lr: 0.000903, loss: 0.4203
2022-09-21 20:16:35 - train: epoch 0030, iter [00120, 01251], lr: 0.000903, loss: 0.4317
2022-09-21 20:16:56 - train: epoch 0030, iter [00130, 01251], lr: 0.000903, loss: 0.4430
2022-09-21 20:17:16 - train: epoch 0030, iter [00140, 01251], lr: 0.000903, loss: 0.4341
2022-09-21 20:17:37 - train: epoch 0030, iter [00150, 01251], lr: 0.000904, loss: 0.4427
2022-09-21 20:17:58 - train: epoch 0030, iter [00160, 01251], lr: 0.000904, loss: 0.4319
2022-09-21 20:18:18 - train: epoch 0030, iter [00170, 01251], lr: 0.000904, loss: 0.4266
2022-09-21 20:18:39 - train: epoch 0030, iter [00180, 01251], lr: 0.000904, loss: 0.4186
2022-09-21 20:19:00 - train: epoch 0030, iter [00190, 01251], lr: 0.000905, loss: 0.4203
2022-09-21 20:19:20 - train: epoch 0030, iter [00200, 01251], lr: 0.000905, loss: 0.4181
2022-09-21 20:19:41 - train: epoch 0030, iter [00210, 01251], lr: 0.000905, loss: 0.4344
2022-09-21 20:20:01 - train: epoch 0030, iter [00220, 01251], lr: 0.000905, loss: 0.4168
2022-09-21 20:20:22 - train: epoch 0030, iter [00230, 01251], lr: 0.000906, loss: 0.4219
2022-09-21 20:20:43 - train: epoch 0030, iter [00240, 01251], lr: 0.000906, loss: 0.4314
2022-09-21 20:21:03 - train: epoch 0030, iter [00250, 01251], lr: 0.000906, loss: 0.4202
2022-09-21 20:21:24 - train: epoch 0030, iter [00260, 01251], lr: 0.000906, loss: 0.4138
2022-09-21 20:21:45 - train: epoch 0030, iter [00270, 01251], lr: 0.000906, loss: 0.4247
2022-09-21 20:22:06 - train: epoch 0030, iter [00280, 01251], lr: 0.000907, loss: 0.4224
2022-09-21 20:22:26 - train: epoch 0030, iter [00290, 01251], lr: 0.000907, loss: 0.4075
2022-09-21 20:22:47 - train: epoch 0030, iter [00300, 01251], lr: 0.000907, loss: 0.4055
2022-09-21 20:23:08 - train: epoch 0030, iter [00310, 01251], lr: 0.000907, loss: 0.4311
2022-09-21 20:23:29 - train: epoch 0030, iter [00320, 01251], lr: 0.000908, loss: 0.4162
2022-09-21 20:23:50 - train: epoch 0030, iter [00330, 01251], lr: 0.000908, loss: 0.4332
2022-09-21 20:24:11 - train: epoch 0030, iter [00340, 01251], lr: 0.000908, loss: 0.4052
2022-09-21 20:24:31 - train: epoch 0030, iter [00350, 01251], lr: 0.000908, loss: 0.4260
2022-09-21 20:24:52 - train: epoch 0030, iter [00360, 01251], lr: 0.000909, loss: 0.4108
2022-09-21 20:25:13 - train: epoch 0030, iter [00370, 01251], lr: 0.000909, loss: 0.4288
2022-09-21 20:25:34 - train: epoch 0030, iter [00380, 01251], lr: 0.000909, loss: 0.4244
2022-09-21 20:25:55 - train: epoch 0030, iter [00390, 01251], lr: 0.000909, loss: 0.4354
2022-09-21 20:26:15 - train: epoch 0030, iter [00400, 01251], lr: 0.000910, loss: 0.4266
2022-09-21 20:26:36 - train: epoch 0030, iter [00410, 01251], lr: 0.000910, loss: 0.4332
2022-09-21 20:26:57 - train: epoch 0030, iter [00420, 01251], lr: 0.000910, loss: 0.4250
2022-09-21 20:27:18 - train: epoch 0030, iter [00430, 01251], lr: 0.000910, loss: 0.4132
2022-09-21 20:27:38 - train: epoch 0030, iter [00440, 01251], lr: 0.000911, loss: 0.4171
2022-09-21 20:27:59 - train: epoch 0030, iter [00450, 01251], lr: 0.000911, loss: 0.3939
2022-09-21 20:28:20 - train: epoch 0030, iter [00460, 01251], lr: 0.000911, loss: 0.4159
2022-09-21 20:28:40 - train: epoch 0030, iter [00470, 01251], lr: 0.000911, loss: 0.4210
2022-09-21 20:29:01 - train: epoch 0030, iter [00480, 01251], lr: 0.000912, loss: 0.4065
2022-09-21 20:29:21 - train: epoch 0030, iter [00490, 01251], lr: 0.000912, loss: 0.4217
2022-09-21 20:29:42 - train: epoch 0030, iter [00500, 01251], lr: 0.000912, loss: 0.4246
2022-09-21 20:30:03 - train: epoch 0030, iter [00510, 01251], lr: 0.000912, loss: 0.4442
2022-09-21 20:30:24 - train: epoch 0030, iter [00520, 01251], lr: 0.000912, loss: 0.4104
2022-09-21 20:30:44 - train: epoch 0030, iter [00530, 01251], lr: 0.000913, loss: 0.4276
2022-09-21 20:31:05 - train: epoch 0030, iter [00540, 01251], lr: 0.000913, loss: 0.4295
2022-09-21 20:31:26 - train: epoch 0030, iter [00550, 01251], lr: 0.000913, loss: 0.4194
2022-09-21 20:31:47 - train: epoch 0030, iter [00560, 01251], lr: 0.000913, loss: 0.4014
2022-09-21 20:32:07 - train: epoch 0030, iter [00570, 01251], lr: 0.000914, loss: 0.4122
2022-09-21 20:32:28 - train: epoch 0030, iter [00580, 01251], lr: 0.000914, loss: 0.4255
2022-09-21 20:32:49 - train: epoch 0030, iter [00590, 01251], lr: 0.000914, loss: 0.4394
2022-09-21 20:33:10 - train: epoch 0030, iter [00600, 01251], lr: 0.000914, loss: 0.4074
2022-09-21 20:33:31 - train: epoch 0030, iter [00610, 01251], lr: 0.000915, loss: 0.4367
2022-09-21 20:33:51 - train: epoch 0030, iter [00620, 01251], lr: 0.000915, loss: 0.4460
2022-09-21 20:34:12 - train: epoch 0030, iter [00630, 01251], lr: 0.000915, loss: 0.4420
2022-09-21 20:34:33 - train: epoch 0030, iter [00640, 01251], lr: 0.000915, loss: 0.4366
2022-09-21 20:34:54 - train: epoch 0030, iter [00650, 01251], lr: 0.000916, loss: 0.4131
2022-09-21 20:35:14 - train: epoch 0030, iter [00660, 01251], lr: 0.000916, loss: 0.4174
2022-09-21 20:35:35 - train: epoch 0030, iter [00670, 01251], lr: 0.000916, loss: 0.4272
2022-09-21 20:35:56 - train: epoch 0030, iter [00680, 01251], lr: 0.000916, loss: 0.4353
2022-09-21 20:36:16 - train: epoch 0030, iter [00690, 01251], lr: 0.000917, loss: 0.4232
2022-09-21 20:36:37 - train: epoch 0030, iter [00700, 01251], lr: 0.000917, loss: 0.3989
2022-09-21 20:36:58 - train: epoch 0030, iter [00710, 01251], lr: 0.000917, loss: 0.4280
2022-09-21 20:37:19 - train: epoch 0030, iter [00720, 01251], lr: 0.000917, loss: 0.4230
2022-09-21 20:37:39 - train: epoch 0030, iter [00730, 01251], lr: 0.000918, loss: 0.4368
2022-09-21 20:38:00 - train: epoch 0030, iter [00740, 01251], lr: 0.000918, loss: 0.4079
2022-09-21 20:38:21 - train: epoch 0030, iter [00750, 01251], lr: 0.000918, loss: 0.4230
2022-09-21 20:38:41 - train: epoch 0030, iter [00760, 01251], lr: 0.000918, loss: 0.4198
2022-09-21 20:39:02 - train: epoch 0030, iter [00770, 01251], lr: 0.000918, loss: 0.4277
2022-09-21 20:39:23 - train: epoch 0030, iter [00780, 01251], lr: 0.000919, loss: 0.4109
2022-09-21 20:39:43 - train: epoch 0030, iter [00790, 01251], lr: 0.000919, loss: 0.4218
2022-09-21 20:40:04 - train: epoch 0030, iter [00800, 01251], lr: 0.000919, loss: 0.4215
2022-09-21 20:40:25 - train: epoch 0030, iter [00810, 01251], lr: 0.000919, loss: 0.4277
2022-09-21 20:40:45 - train: epoch 0030, iter [00820, 01251], lr: 0.000920, loss: 0.4191
2022-09-21 20:41:06 - train: epoch 0030, iter [00830, 01251], lr: 0.000920, loss: 0.4529
2022-09-21 20:41:27 - train: epoch 0030, iter [00840, 01251], lr: 0.000920, loss: 0.4187
2022-09-21 20:41:47 - train: epoch 0030, iter [00850, 01251], lr: 0.000920, loss: 0.4228
2022-09-21 20:42:08 - train: epoch 0030, iter [00860, 01251], lr: 0.000921, loss: 0.4428
2022-09-21 20:42:29 - train: epoch 0030, iter [00870, 01251], lr: 0.000921, loss: 0.4159
2022-09-21 20:42:49 - train: epoch 0030, iter [00880, 01251], lr: 0.000921, loss: 0.4323
2022-09-21 20:43:10 - train: epoch 0030, iter [00890, 01251], lr: 0.000921, loss: 0.4290
2022-09-21 20:43:31 - train: epoch 0030, iter [00900, 01251], lr: 0.000922, loss: 0.4275
2022-09-21 20:43:52 - train: epoch 0030, iter [00910, 01251], lr: 0.000922, loss: 0.4295
2022-09-21 20:44:13 - train: epoch 0030, iter [00920, 01251], lr: 0.000922, loss: 0.4332
2022-09-21 20:44:33 - train: epoch 0030, iter [00930, 01251], lr: 0.000922, loss: 0.3938
2022-09-21 20:44:54 - train: epoch 0030, iter [00940, 01251], lr: 0.000923, loss: 0.4337
2022-09-21 20:45:15 - train: epoch 0030, iter [00950, 01251], lr: 0.000923, loss: 0.4108
2022-09-21 20:45:35 - train: epoch 0030, iter [00960, 01251], lr: 0.000923, loss: 0.4299
2022-09-21 20:45:57 - train: epoch 0030, iter [00970, 01251], lr: 0.000923, loss: 0.4368
2022-09-21 20:46:17 - train: epoch 0030, iter [00980, 01251], lr: 0.000924, loss: 0.4377
2022-09-21 20:46:38 - train: epoch 0030, iter [00990, 01251], lr: 0.000924, loss: 0.4262
2022-09-21 20:46:58 - train: epoch 0030, iter [01000, 01251], lr: 0.000924, loss: 0.4300
2022-09-21 20:47:19 - train: epoch 0030, iter [01010, 01251], lr: 0.000924, loss: 0.4409
2022-09-21 20:47:40 - train: epoch 0030, iter [01020, 01251], lr: 0.000924, loss: 0.4490
2022-09-21 20:48:01 - train: epoch 0030, iter [01030, 01251], lr: 0.000925, loss: 0.4230
2022-09-21 20:48:22 - train: epoch 0030, iter [01040, 01251], lr: 0.000925, loss: 0.4151
2022-09-21 20:48:43 - train: epoch 0030, iter [01050, 01251], lr: 0.000925, loss: 0.4283
2022-09-21 20:49:03 - train: epoch 0030, iter [01060, 01251], lr: 0.000925, loss: 0.4133
2022-09-21 20:49:24 - train: epoch 0030, iter [01070, 01251], lr: 0.000926, loss: 0.4127
2022-09-21 20:49:45 - train: epoch 0030, iter [01080, 01251], lr: 0.000926, loss: 0.4466
2022-09-21 20:50:05 - train: epoch 0030, iter [01090, 01251], lr: 0.000926, loss: 0.4235
2022-09-21 20:50:26 - train: epoch 0030, iter [01100, 01251], lr: 0.000926, loss: 0.4142
2022-09-21 20:50:47 - train: epoch 0030, iter [01110, 01251], lr: 0.000927, loss: 0.4055
2022-09-21 20:51:08 - train: epoch 0030, iter [01120, 01251], lr: 0.000927, loss: 0.4268
2022-09-21 20:51:29 - train: epoch 0030, iter [01130, 01251], lr: 0.000927, loss: 0.4182
2022-09-21 20:51:49 - train: epoch 0030, iter [01140, 01251], lr: 0.000927, loss: 0.4269
2022-09-21 20:52:10 - train: epoch 0030, iter [01150, 01251], lr: 0.000928, loss: 0.4273
2022-09-21 20:52:31 - train: epoch 0030, iter [01160, 01251], lr: 0.000928, loss: 0.3950
2022-09-21 20:52:52 - train: epoch 0030, iter [01170, 01251], lr: 0.000928, loss: 0.4258
2022-09-21 20:53:12 - train: epoch 0030, iter [01180, 01251], lr: 0.000928, loss: 0.4168
2022-09-21 20:53:33 - train: epoch 0030, iter [01190, 01251], lr: 0.000929, loss: 0.4202
2022-09-21 20:53:54 - train: epoch 0030, iter [01200, 01251], lr: 0.000929, loss: 0.4309
2022-09-21 20:54:14 - train: epoch 0030, iter [01210, 01251], lr: 0.000929, loss: 0.4352
2022-09-21 20:54:35 - train: epoch 0030, iter [01220, 01251], lr: 0.000929, loss: 0.4171
2022-09-21 20:54:56 - train: epoch 0030, iter [01230, 01251], lr: 0.000929, loss: 0.4444
2022-09-21 20:55:16 - train: epoch 0030, iter [01240, 01251], lr: 0.000930, loss: 0.4320
2022-09-21 20:55:36 - train: epoch 0030, iter [01250, 01251], lr: 0.000930, loss: 0.4384
2022-09-21 20:55:40 - train: epoch 030, train_loss: 0.4245
2022-09-21 20:55:46 - until epoch: 030, best_loss: 0.4245
2022-09-21 20:55:46 - epoch 031 lr: 0.000930
2022-09-21 20:56:22 - train: epoch 0031, iter [00010, 01251], lr: 0.000930, loss: 0.4127
2022-09-21 20:56:43 - train: epoch 0031, iter [00020, 01251], lr: 0.000930, loss: 0.4322
2022-09-21 20:57:03 - train: epoch 0031, iter [00030, 01251], lr: 0.000931, loss: 0.4252
2022-09-21 20:57:24 - train: epoch 0031, iter [00040, 01251], lr: 0.000931, loss: 0.4275
2022-09-21 20:57:45 - train: epoch 0031, iter [00050, 01251], lr: 0.000931, loss: 0.4107
2022-09-21 20:58:07 - train: epoch 0031, iter [00060, 01251], lr: 0.000931, loss: 0.3985
2022-09-21 20:58:28 - train: epoch 0031, iter [00070, 01251], lr: 0.000932, loss: 0.4269
2022-09-21 20:58:49 - train: epoch 0031, iter [00080, 01251], lr: 0.000932, loss: 0.4199
2022-09-21 20:59:10 - train: epoch 0031, iter [00090, 01251], lr: 0.000932, loss: 0.4285
2022-09-21 20:59:33 - train: epoch 0031, iter [00100, 01251], lr: 0.000932, loss: 0.4221
2022-09-21 20:59:55 - train: epoch 0031, iter [00110, 01251], lr: 0.000933, loss: 0.4292
2022-09-21 21:00:16 - train: epoch 0031, iter [00120, 01251], lr: 0.000933, loss: 0.4100
2022-09-21 21:00:36 - train: epoch 0031, iter [00130, 01251], lr: 0.000933, loss: 0.4281
2022-09-21 21:00:57 - train: epoch 0031, iter [00140, 01251], lr: 0.000933, loss: 0.4336
2022-09-21 21:01:18 - train: epoch 0031, iter [00150, 01251], lr: 0.000934, loss: 0.4006
2022-09-21 21:01:38 - train: epoch 0031, iter [00160, 01251], lr: 0.000934, loss: 0.4309
2022-09-21 21:01:59 - train: epoch 0031, iter [00170, 01251], lr: 0.000934, loss: 0.4112
2022-09-21 21:02:19 - train: epoch 0031, iter [00180, 01251], lr: 0.000934, loss: 0.4227
2022-09-21 21:02:40 - train: epoch 0031, iter [00190, 01251], lr: 0.000935, loss: 0.4420
2022-09-21 21:03:01 - train: epoch 0031, iter [00200, 01251], lr: 0.000935, loss: 0.4253
2022-09-21 21:03:22 - train: epoch 0031, iter [00210, 01251], lr: 0.000935, loss: 0.4050
2022-09-21 21:03:42 - train: epoch 0031, iter [00220, 01251], lr: 0.000935, loss: 0.4279
2022-09-21 21:04:03 - train: epoch 0031, iter [00230, 01251], lr: 0.000936, loss: 0.4439
2022-09-21 21:04:24 - train: epoch 0031, iter [00240, 01251], lr: 0.000936, loss: 0.4437
2022-09-21 21:04:44 - train: epoch 0031, iter [00250, 01251], lr: 0.000936, loss: 0.4216
2022-09-21 21:05:05 - train: epoch 0031, iter [00260, 01251], lr: 0.000936, loss: 0.4248
2022-09-21 21:05:26 - train: epoch 0031, iter [00270, 01251], lr: 0.000936, loss: 0.4320
2022-09-21 21:05:46 - train: epoch 0031, iter [00280, 01251], lr: 0.000937, loss: 0.4153
2022-09-21 21:06:07 - train: epoch 0031, iter [00290, 01251], lr: 0.000937, loss: 0.4202
2022-09-21 21:06:28 - train: epoch 0031, iter [00300, 01251], lr: 0.000937, loss: 0.4199
2022-09-21 21:06:48 - train: epoch 0031, iter [00310, 01251], lr: 0.000937, loss: 0.4459
2022-09-21 21:07:09 - train: epoch 0031, iter [00320, 01251], lr: 0.000938, loss: 0.4387
2022-09-21 21:07:30 - train: epoch 0031, iter [00330, 01251], lr: 0.000938, loss: 0.4360
2022-09-21 21:07:51 - train: epoch 0031, iter [00340, 01251], lr: 0.000938, loss: 0.4114
2022-09-21 21:08:11 - train: epoch 0031, iter [00350, 01251], lr: 0.000938, loss: 0.4146
2022-09-21 21:08:32 - train: epoch 0031, iter [00360, 01251], lr: 0.000939, loss: 0.4237
2022-09-21 21:08:53 - train: epoch 0031, iter [00370, 01251], lr: 0.000939, loss: 0.4089
2022-09-21 21:09:13 - train: epoch 0031, iter [00380, 01251], lr: 0.000939, loss: 0.4339
2022-09-21 21:09:34 - train: epoch 0031, iter [00390, 01251], lr: 0.000939, loss: 0.4132
2022-09-21 21:09:55 - train: epoch 0031, iter [00400, 01251], lr: 0.000940, loss: 0.4345
2022-09-21 21:10:15 - train: epoch 0031, iter [00410, 01251], lr: 0.000940, loss: 0.4183
2022-09-21 21:10:36 - train: epoch 0031, iter [00420, 01251], lr: 0.000940, loss: 0.4339
2022-09-21 21:10:57 - train: epoch 0031, iter [00430, 01251], lr: 0.000940, loss: 0.4294
2022-09-21 21:11:17 - train: epoch 0031, iter [00440, 01251], lr: 0.000941, loss: 0.4237
2022-09-21 21:11:38 - train: epoch 0031, iter [00450, 01251], lr: 0.000941, loss: 0.4124
2022-09-21 21:11:59 - train: epoch 0031, iter [00460, 01251], lr: 0.000941, loss: 0.4236
2022-09-21 21:12:20 - train: epoch 0031, iter [00470, 01251], lr: 0.000941, loss: 0.4131
2022-09-21 21:12:40 - train: epoch 0031, iter [00480, 01251], lr: 0.000942, loss: 0.4492
2022-09-21 21:13:01 - train: epoch 0031, iter [00490, 01251], lr: 0.000942, loss: 0.4200
2022-09-21 21:13:21 - train: epoch 0031, iter [00500, 01251], lr: 0.000942, loss: 0.4153
2022-09-21 21:13:42 - train: epoch 0031, iter [00510, 01251], lr: 0.000942, loss: 0.4273
2022-09-21 21:14:02 - train: epoch 0031, iter [00520, 01251], lr: 0.000942, loss: 0.4392
2022-09-21 21:14:23 - train: epoch 0031, iter [00530, 01251], lr: 0.000943, loss: 0.4077
2022-09-21 21:14:43 - train: epoch 0031, iter [00540, 01251], lr: 0.000943, loss: 0.4183
2022-09-21 21:15:04 - train: epoch 0031, iter [00550, 01251], lr: 0.000943, loss: 0.4081
2022-09-21 21:15:24 - train: epoch 0031, iter [00560, 01251], lr: 0.000943, loss: 0.4305
2022-09-21 21:15:45 - train: epoch 0031, iter [00570, 01251], lr: 0.000944, loss: 0.4311
2022-09-21 21:16:06 - train: epoch 0031, iter [00580, 01251], lr: 0.000944, loss: 0.4357
2022-09-21 21:16:27 - train: epoch 0031, iter [00590, 01251], lr: 0.000944, loss: 0.4299
2022-09-21 21:16:47 - train: epoch 0031, iter [00600, 01251], lr: 0.000944, loss: 0.4314
2022-09-21 21:17:08 - train: epoch 0031, iter [00610, 01251], lr: 0.000945, loss: 0.3955
2022-09-21 21:17:29 - train: epoch 0031, iter [00620, 01251], lr: 0.000945, loss: 0.4399
2022-09-21 21:17:50 - train: epoch 0031, iter [00630, 01251], lr: 0.000945, loss: 0.4155
2022-09-21 21:18:10 - train: epoch 0031, iter [00640, 01251], lr: 0.000945, loss: 0.4322
2022-09-21 21:18:31 - train: epoch 0031, iter [00650, 01251], lr: 0.000946, loss: 0.4191
2022-09-21 21:18:52 - train: epoch 0031, iter [00660, 01251], lr: 0.000946, loss: 0.4304
2022-09-21 21:19:13 - train: epoch 0031, iter [00670, 01251], lr: 0.000946, loss: 0.4208
2022-09-21 21:19:33 - train: epoch 0031, iter [00680, 01251], lr: 0.000946, loss: 0.4231
2022-09-21 21:19:54 - train: epoch 0031, iter [00690, 01251], lr: 0.000947, loss: 0.4220
2022-09-21 21:20:15 - train: epoch 0031, iter [00700, 01251], lr: 0.000947, loss: 0.4119
2022-09-21 21:20:36 - train: epoch 0031, iter [00710, 01251], lr: 0.000947, loss: 0.4031
2022-09-21 21:20:56 - train: epoch 0031, iter [00720, 01251], lr: 0.000947, loss: 0.4323
2022-09-21 21:21:17 - train: epoch 0031, iter [00730, 01251], lr: 0.000948, loss: 0.4320
2022-09-21 21:21:38 - train: epoch 0031, iter [00740, 01251], lr: 0.000948, loss: 0.4103
2022-09-21 21:21:59 - train: epoch 0031, iter [00750, 01251], lr: 0.000948, loss: 0.4236
2022-09-21 21:22:19 - train: epoch 0031, iter [00760, 01251], lr: 0.000948, loss: 0.4131
2022-09-21 21:22:40 - train: epoch 0031, iter [00770, 01251], lr: 0.000948, loss: 0.4092
2022-09-21 21:23:01 - train: epoch 0031, iter [00780, 01251], lr: 0.000949, loss: 0.4314
2022-09-21 21:23:22 - train: epoch 0031, iter [00790, 01251], lr: 0.000949, loss: 0.4102
2022-09-21 21:23:43 - train: epoch 0031, iter [00800, 01251], lr: 0.000949, loss: 0.4272
2022-09-21 21:24:03 - train: epoch 0031, iter [00810, 01251], lr: 0.000949, loss: 0.4331
2022-09-21 21:24:24 - train: epoch 0031, iter [00820, 01251], lr: 0.000950, loss: 0.4266
2022-09-21 21:24:45 - train: epoch 0031, iter [00830, 01251], lr: 0.000950, loss: 0.4370
2022-09-21 21:25:06 - train: epoch 0031, iter [00840, 01251], lr: 0.000950, loss: 0.4141
2022-09-21 21:25:26 - train: epoch 0031, iter [00850, 01251], lr: 0.000950, loss: 0.4251
2022-09-21 21:25:47 - train: epoch 0031, iter [00860, 01251], lr: 0.000951, loss: 0.4059
2022-09-21 21:26:08 - train: epoch 0031, iter [00870, 01251], lr: 0.000951, loss: 0.4251
2022-09-21 21:26:29 - train: epoch 0031, iter [00880, 01251], lr: 0.000951, loss: 0.4433
2022-09-21 21:26:50 - train: epoch 0031, iter [00890, 01251], lr: 0.000951, loss: 0.4394
2022-09-21 21:27:10 - train: epoch 0031, iter [00900, 01251], lr: 0.000952, loss: 0.4439
2022-09-21 21:27:31 - train: epoch 0031, iter [00910, 01251], lr: 0.000952, loss: 0.4398
2022-09-21 21:27:52 - train: epoch 0031, iter [00920, 01251], lr: 0.000952, loss: 0.4374
2022-09-21 21:28:12 - train: epoch 0031, iter [00930, 01251], lr: 0.000952, loss: 0.4061
2022-09-21 21:28:33 - train: epoch 0031, iter [00940, 01251], lr: 0.000953, loss: 0.4229
2022-09-21 21:28:54 - train: epoch 0031, iter [00950, 01251], lr: 0.000953, loss: 0.4278
2022-09-21 21:29:15 - train: epoch 0031, iter [00960, 01251], lr: 0.000953, loss: 0.4160
2022-09-21 21:29:35 - train: epoch 0031, iter [00970, 01251], lr: 0.000953, loss: 0.4201
2022-09-21 21:29:56 - train: epoch 0031, iter [00980, 01251], lr: 0.000954, loss: 0.4315
2022-09-21 21:30:17 - train: epoch 0031, iter [00990, 01251], lr: 0.000954, loss: 0.4245
2022-09-21 21:30:38 - train: epoch 0031, iter [01000, 01251], lr: 0.000954, loss: 0.4110
2022-09-21 21:30:58 - train: epoch 0031, iter [01010, 01251], lr: 0.000954, loss: 0.4312
2022-09-21 21:31:19 - train: epoch 0031, iter [01020, 01251], lr: 0.000954, loss: 0.4454
2022-09-21 21:31:40 - train: epoch 0031, iter [01030, 01251], lr: 0.000955, loss: 0.4397
2022-09-21 21:32:00 - train: epoch 0031, iter [01040, 01251], lr: 0.000955, loss: 0.4092
2022-09-21 21:32:21 - train: epoch 0031, iter [01050, 01251], lr: 0.000955, loss: 0.4281
2022-09-21 21:32:42 - train: epoch 0031, iter [01060, 01251], lr: 0.000955, loss: 0.4189
2022-09-21 21:33:03 - train: epoch 0031, iter [01070, 01251], lr: 0.000956, loss: 0.4038
2022-09-21 21:33:24 - train: epoch 0031, iter [01080, 01251], lr: 0.000956, loss: 0.4277
2022-09-21 21:33:44 - train: epoch 0031, iter [01090, 01251], lr: 0.000956, loss: 0.4302
2022-09-21 21:34:05 - train: epoch 0031, iter [01100, 01251], lr: 0.000956, loss: 0.4336
2022-09-21 21:34:26 - train: epoch 0031, iter [01110, 01251], lr: 0.000957, loss: 0.4168
2022-09-21 21:34:47 - train: epoch 0031, iter [01120, 01251], lr: 0.000957, loss: 0.4277
2022-09-21 21:35:07 - train: epoch 0031, iter [01130, 01251], lr: 0.000957, loss: 0.4194
2022-09-21 21:35:28 - train: epoch 0031, iter [01140, 01251], lr: 0.000957, loss: 0.4026
2022-09-21 21:35:49 - train: epoch 0031, iter [01150, 01251], lr: 0.000958, loss: 0.4134
2022-09-21 21:36:10 - train: epoch 0031, iter [01160, 01251], lr: 0.000958, loss: 0.4090
2022-09-21 21:36:31 - train: epoch 0031, iter [01170, 01251], lr: 0.000958, loss: 0.4312
2022-09-21 21:36:51 - train: epoch 0031, iter [01180, 01251], lr: 0.000958, loss: 0.4235
2022-09-21 21:37:12 - train: epoch 0031, iter [01190, 01251], lr: 0.000959, loss: 0.4172
2022-09-21 21:37:33 - train: epoch 0031, iter [01200, 01251], lr: 0.000959, loss: 0.4348
2022-09-21 21:37:54 - train: epoch 0031, iter [01210, 01251], lr: 0.000959, loss: 0.4125
2022-09-21 21:38:14 - train: epoch 0031, iter [01220, 01251], lr: 0.000959, loss: 0.4275
2022-09-21 21:38:35 - train: epoch 0031, iter [01230, 01251], lr: 0.000959, loss: 0.4087
2022-09-21 21:38:56 - train: epoch 0031, iter [01240, 01251], lr: 0.000960, loss: 0.4415
2022-09-21 21:39:16 - train: epoch 0031, iter [01250, 01251], lr: 0.000960, loss: 0.4260
2022-09-21 21:39:20 - train: epoch 031, train_loss: 0.4241
2022-09-21 21:39:25 - until epoch: 031, best_loss: 0.4241
2022-09-21 21:39:25 - epoch 032 lr: 0.000960
2022-09-21 21:40:02 - train: epoch 0032, iter [00010, 01251], lr: 0.000960, loss: 0.4318
2022-09-21 21:40:23 - train: epoch 0032, iter [00020, 01251], lr: 0.000960, loss: 0.4319
2022-09-21 21:40:44 - train: epoch 0032, iter [00030, 01251], lr: 0.000961, loss: 0.4127
2022-09-21 21:41:04 - train: epoch 0032, iter [00040, 01251], lr: 0.000961, loss: 0.4182
2022-09-21 21:41:25 - train: epoch 0032, iter [00050, 01251], lr: 0.000961, loss: 0.4383
2022-09-21 21:41:46 - train: epoch 0032, iter [00060, 01251], lr: 0.000961, loss: 0.4275
2022-09-21 21:42:07 - train: epoch 0032, iter [00070, 01251], lr: 0.000962, loss: 0.4200
2022-09-21 21:42:28 - train: epoch 0032, iter [00080, 01251], lr: 0.000962, loss: 0.4209
2022-09-21 21:42:48 - train: epoch 0032, iter [00090, 01251], lr: 0.000962, loss: 0.4124
2022-09-21 21:43:09 - train: epoch 0032, iter [00100, 01251], lr: 0.000962, loss: 0.4398
2022-09-21 21:43:30 - train: epoch 0032, iter [00110, 01251], lr: 0.000963, loss: 0.4121
2022-09-21 21:43:51 - train: epoch 0032, iter [00120, 01251], lr: 0.000963, loss: 0.4441
2022-09-21 21:44:11 - train: epoch 0032, iter [00130, 01251], lr: 0.000963, loss: 0.4120
2022-09-21 21:44:32 - train: epoch 0032, iter [00140, 01251], lr: 0.000963, loss: 0.4352
2022-09-21 21:44:53 - train: epoch 0032, iter [00150, 01251], lr: 0.000964, loss: 0.4267
2022-09-21 21:45:13 - train: epoch 0032, iter [00160, 01251], lr: 0.000964, loss: 0.4257
2022-09-21 21:45:34 - train: epoch 0032, iter [00170, 01251], lr: 0.000964, loss: 0.4270
2022-09-21 21:45:55 - train: epoch 0032, iter [00180, 01251], lr: 0.000964, loss: 0.4253
2022-09-21 21:46:15 - train: epoch 0032, iter [00190, 01251], lr: 0.000965, loss: 0.4251
2022-09-21 21:46:36 - train: epoch 0032, iter [00200, 01251], lr: 0.000965, loss: 0.4376
2022-09-21 21:46:57 - train: epoch 0032, iter [00210, 01251], lr: 0.000965, loss: 0.4231
2022-09-21 21:47:18 - train: epoch 0032, iter [00220, 01251], lr: 0.000965, loss: 0.4312
2022-09-21 21:47:38 - train: epoch 0032, iter [00230, 01251], lr: 0.000966, loss: 0.4342
2022-09-21 21:47:59 - train: epoch 0032, iter [00240, 01251], lr: 0.000966, loss: 0.4247
2022-09-21 21:48:20 - train: epoch 0032, iter [00250, 01251], lr: 0.000966, loss: 0.4232
2022-09-21 21:48:41 - train: epoch 0032, iter [00260, 01251], lr: 0.000966, loss: 0.4229
2022-09-21 21:49:01 - train: epoch 0032, iter [00270, 01251], lr: 0.000966, loss: 0.4258
2022-09-21 21:49:22 - train: epoch 0032, iter [00280, 01251], lr: 0.000967, loss: 0.4132
2022-09-21 21:49:43 - train: epoch 0032, iter [00290, 01251], lr: 0.000967, loss: 0.4232
2022-09-21 21:50:04 - train: epoch 0032, iter [00300, 01251], lr: 0.000967, loss: 0.4225
2022-09-21 21:50:24 - train: epoch 0032, iter [00310, 01251], lr: 0.000967, loss: 0.4382
2022-09-21 21:50:45 - train: epoch 0032, iter [00320, 01251], lr: 0.000968, loss: 0.4366
2022-09-21 21:51:06 - train: epoch 0032, iter [00330, 01251], lr: 0.000968, loss: 0.4275
2022-09-21 21:51:27 - train: epoch 0032, iter [00340, 01251], lr: 0.000968, loss: 0.4381
2022-09-21 21:51:47 - train: epoch 0032, iter [00350, 01251], lr: 0.000968, loss: 0.4165
2022-09-21 21:52:08 - train: epoch 0032, iter [00360, 01251], lr: 0.000969, loss: 0.4426
2022-09-21 21:52:29 - train: epoch 0032, iter [00370, 01251], lr: 0.000969, loss: 0.4479
2022-09-21 21:52:49 - train: epoch 0032, iter [00380, 01251], lr: 0.000969, loss: 0.4263
2022-09-21 21:53:10 - train: epoch 0032, iter [00390, 01251], lr: 0.000969, loss: 0.4307
2022-09-21 21:53:31 - train: epoch 0032, iter [00400, 01251], lr: 0.000970, loss: 0.4300
2022-09-21 21:53:51 - train: epoch 0032, iter [00410, 01251], lr: 0.000970, loss: 0.4341
2022-09-21 21:54:12 - train: epoch 0032, iter [00420, 01251], lr: 0.000970, loss: 0.4389
2022-09-21 21:54:33 - train: epoch 0032, iter [00430, 01251], lr: 0.000970, loss: 0.4048
2022-09-21 21:54:53 - train: epoch 0032, iter [00440, 01251], lr: 0.000971, loss: 0.4136
2022-09-21 21:55:14 - train: epoch 0032, iter [00450, 01251], lr: 0.000971, loss: 0.4152
2022-09-21 21:55:35 - train: epoch 0032, iter [00460, 01251], lr: 0.000971, loss: 0.4163
2022-09-21 21:55:56 - train: epoch 0032, iter [00470, 01251], lr: 0.000971, loss: 0.4092
2022-09-21 21:56:16 - train: epoch 0032, iter [00480, 01251], lr: 0.000972, loss: 0.4310
2022-09-21 21:56:37 - train: epoch 0032, iter [00490, 01251], lr: 0.000972, loss: 0.4174
2022-09-21 21:56:58 - train: epoch 0032, iter [00500, 01251], lr: 0.000972, loss: 0.4317
2022-09-21 21:57:18 - train: epoch 0032, iter [00510, 01251], lr: 0.000972, loss: 0.4156
2022-09-21 21:57:39 - train: epoch 0032, iter [00520, 01251], lr: 0.000972, loss: 0.4197
2022-09-21 21:58:00 - train: epoch 0032, iter [00530, 01251], lr: 0.000973, loss: 0.3921
2022-09-21 21:58:21 - train: epoch 0032, iter [00540, 01251], lr: 0.000973, loss: 0.4145
2022-09-21 21:58:41 - train: epoch 0032, iter [00550, 01251], lr: 0.000973, loss: 0.4139
2022-09-21 21:59:02 - train: epoch 0032, iter [00560, 01251], lr: 0.000973, loss: 0.4463
2022-09-21 21:59:23 - train: epoch 0032, iter [00570, 01251], lr: 0.000974, loss: 0.4101
2022-09-21 21:59:43 - train: epoch 0032, iter [00580, 01251], lr: 0.000974, loss: 0.4263
2022-09-21 22:00:04 - train: epoch 0032, iter [00590, 01251], lr: 0.000974, loss: 0.4255
2022-09-21 22:00:25 - train: epoch 0032, iter [00600, 01251], lr: 0.000974, loss: 0.4042
2022-09-21 22:00:46 - train: epoch 0032, iter [00610, 01251], lr: 0.000975, loss: 0.4288
2022-09-21 22:01:06 - train: epoch 0032, iter [00620, 01251], lr: 0.000975, loss: 0.4246
2022-09-21 22:01:27 - train: epoch 0032, iter [00630, 01251], lr: 0.000975, loss: 0.4345
2022-09-21 22:01:48 - train: epoch 0032, iter [00640, 01251], lr: 0.000975, loss: 0.3972
2022-09-21 22:02:08 - train: epoch 0032, iter [00650, 01251], lr: 0.000976, loss: 0.4271
2022-09-21 22:02:29 - train: epoch 0032, iter [00660, 01251], lr: 0.000976, loss: 0.4174
2022-09-21 22:02:50 - train: epoch 0032, iter [00670, 01251], lr: 0.000976, loss: 0.4314
2022-09-21 22:03:10 - train: epoch 0032, iter [00680, 01251], lr: 0.000976, loss: 0.4124
2022-09-21 22:03:31 - train: epoch 0032, iter [00690, 01251], lr: 0.000977, loss: 0.4269
2022-09-21 22:03:51 - train: epoch 0032, iter [00700, 01251], lr: 0.000977, loss: 0.4191
2022-09-21 22:04:12 - train: epoch 0032, iter [00710, 01251], lr: 0.000977, loss: 0.4285
2022-09-21 22:04:33 - train: epoch 0032, iter [00720, 01251], lr: 0.000977, loss: 0.4092
2022-09-21 22:04:53 - train: epoch 0032, iter [00730, 01251], lr: 0.000978, loss: 0.4260
2022-09-21 22:05:14 - train: epoch 0032, iter [00740, 01251], lr: 0.000978, loss: 0.4320
2022-09-21 22:05:35 - train: epoch 0032, iter [00750, 01251], lr: 0.000978, loss: 0.4105
2022-09-21 22:05:56 - train: epoch 0032, iter [00760, 01251], lr: 0.000978, loss: 0.4309
2022-09-21 22:06:16 - train: epoch 0032, iter [00770, 01251], lr: 0.000978, loss: 0.4379
2022-09-21 22:06:37 - train: epoch 0032, iter [00780, 01251], lr: 0.000979, loss: 0.4118
2022-09-21 22:06:58 - train: epoch 0032, iter [00790, 01251], lr: 0.000979, loss: 0.4058
2022-09-21 22:07:18 - train: epoch 0032, iter [00800, 01251], lr: 0.000979, loss: 0.4232
2022-09-21 22:07:39 - train: epoch 0032, iter [00810, 01251], lr: 0.000979, loss: 0.4468
2022-09-21 22:08:00 - train: epoch 0032, iter [00820, 01251], lr: 0.000980, loss: 0.4158
2022-09-21 22:08:21 - train: epoch 0032, iter [00830, 01251], lr: 0.000980, loss: 0.4149
2022-09-21 22:08:41 - train: epoch 0032, iter [00840, 01251], lr: 0.000980, loss: 0.3982
2022-09-21 22:09:02 - train: epoch 0032, iter [00850, 01251], lr: 0.000980, loss: 0.4432
2022-09-21 22:09:23 - train: epoch 0032, iter [00860, 01251], lr: 0.000981, loss: 0.4083
2022-09-21 22:09:43 - train: epoch 0032, iter [00870, 01251], lr: 0.000981, loss: 0.4122
2022-09-21 22:10:04 - train: epoch 0032, iter [00880, 01251], lr: 0.000981, loss: 0.4272
2022-09-21 22:10:25 - train: epoch 0032, iter [00890, 01251], lr: 0.000981, loss: 0.4162
2022-09-21 22:10:46 - train: epoch 0032, iter [00900, 01251], lr: 0.000982, loss: 0.4139
2022-09-21 22:11:06 - train: epoch 0032, iter [00910, 01251], lr: 0.000982, loss: 0.4143
2022-09-21 22:11:27 - train: epoch 0032, iter [00920, 01251], lr: 0.000982, loss: 0.4237
2022-09-21 22:11:48 - train: epoch 0032, iter [00930, 01251], lr: 0.000982, loss: 0.4124
2022-09-21 22:12:08 - train: epoch 0032, iter [00940, 01251], lr: 0.000983, loss: 0.4533
2022-09-21 22:12:29 - train: epoch 0032, iter [00950, 01251], lr: 0.000983, loss: 0.4111
2022-09-21 22:12:50 - train: epoch 0032, iter [00960, 01251], lr: 0.000983, loss: 0.4322
2022-09-21 22:13:10 - train: epoch 0032, iter [00970, 01251], lr: 0.000983, loss: 0.4215
2022-09-21 22:13:31 - train: epoch 0032, iter [00980, 01251], lr: 0.000984, loss: 0.4217
2022-09-21 22:13:52 - train: epoch 0032, iter [00990, 01251], lr: 0.000984, loss: 0.4282
2022-09-21 22:14:13 - train: epoch 0032, iter [01000, 01251], lr: 0.000984, loss: 0.4264
2022-09-21 22:14:34 - train: epoch 0032, iter [01010, 01251], lr: 0.000984, loss: 0.4377
2022-09-21 22:14:54 - train: epoch 0032, iter [01020, 01251], lr: 0.000984, loss: 0.4131
2022-09-21 22:15:15 - train: epoch 0032, iter [01030, 01251], lr: 0.000985, loss: 0.4351
2022-09-21 22:15:36 - train: epoch 0032, iter [01040, 01251], lr: 0.000985, loss: 0.4105
2022-09-21 22:15:56 - train: epoch 0032, iter [01050, 01251], lr: 0.000985, loss: 0.4164
2022-09-21 22:16:17 - train: epoch 0032, iter [01060, 01251], lr: 0.000985, loss: 0.4445
2022-09-21 22:16:38 - train: epoch 0032, iter [01070, 01251], lr: 0.000986, loss: 0.4105
2022-09-21 22:16:59 - train: epoch 0032, iter [01080, 01251], lr: 0.000986, loss: 0.4327
2022-09-21 22:17:19 - train: epoch 0032, iter [01090, 01251], lr: 0.000986, loss: 0.4196
2022-09-21 22:17:40 - train: epoch 0032, iter [01100, 01251], lr: 0.000986, loss: 0.4264
2022-09-21 22:18:01 - train: epoch 0032, iter [01110, 01251], lr: 0.000987, loss: 0.4218
2022-09-21 22:18:21 - train: epoch 0032, iter [01120, 01251], lr: 0.000987, loss: 0.4322
2022-09-21 22:18:42 - train: epoch 0032, iter [01130, 01251], lr: 0.000987, loss: 0.4192
2022-09-21 22:19:03 - train: epoch 0032, iter [01140, 01251], lr: 0.000987, loss: 0.4224
2022-09-21 22:19:24 - train: epoch 0032, iter [01150, 01251], lr: 0.000988, loss: 0.4203
2022-09-21 22:19:45 - train: epoch 0032, iter [01160, 01251], lr: 0.000988, loss: 0.4257
2022-09-21 22:20:06 - train: epoch 0032, iter [01170, 01251], lr: 0.000988, loss: 0.4309
2022-09-21 22:20:26 - train: epoch 0032, iter [01180, 01251], lr: 0.000988, loss: 0.4319
2022-09-21 22:20:47 - train: epoch 0032, iter [01190, 01251], lr: 0.000989, loss: 0.4169
2022-09-21 22:21:08 - train: epoch 0032, iter [01200, 01251], lr: 0.000989, loss: 0.4160
2022-09-21 22:21:29 - train: epoch 0032, iter [01210, 01251], lr: 0.000989, loss: 0.4193
2022-09-21 22:21:49 - train: epoch 0032, iter [01220, 01251], lr: 0.000989, loss: 0.4255
2022-09-21 22:22:10 - train: epoch 0032, iter [01230, 01251], lr: 0.000989, loss: 0.4305
2022-09-21 22:22:31 - train: epoch 0032, iter [01240, 01251], lr: 0.000990, loss: 0.4428
2022-09-21 22:22:51 - train: epoch 0032, iter [01250, 01251], lr: 0.000990, loss: 0.4122
2022-09-21 22:22:56 - train: epoch 032, train_loss: 0.4236
2022-09-21 22:23:01 - until epoch: 032, best_loss: 0.4236
2022-09-21 22:23:01 - epoch 033 lr: 0.000990
2022-09-21 22:23:39 - train: epoch 0033, iter [00010, 01251], lr: 0.000990, loss: 0.4289
2022-09-21 22:24:00 - train: epoch 0033, iter [00020, 01251], lr: 0.000990, loss: 0.4210
2022-09-21 22:24:21 - train: epoch 0033, iter [00030, 01251], lr: 0.000991, loss: 0.4295
2022-09-21 22:24:41 - train: epoch 0033, iter [00040, 01251], lr: 0.000991, loss: 0.4061
2022-09-21 22:25:02 - train: epoch 0033, iter [00050, 01251], lr: 0.000991, loss: 0.4447
2022-09-21 22:25:23 - train: epoch 0033, iter [00060, 01251], lr: 0.000991, loss: 0.4315
2022-09-21 22:25:44 - train: epoch 0033, iter [00070, 01251], lr: 0.000992, loss: 0.4083
2022-09-21 22:26:04 - train: epoch 0033, iter [00080, 01251], lr: 0.000992, loss: 0.3999
2022-09-21 22:26:25 - train: epoch 0033, iter [00090, 01251], lr: 0.000992, loss: 0.4485
2022-09-21 22:26:46 - train: epoch 0033, iter [00100, 01251], lr: 0.000992, loss: 0.4151
2022-09-21 22:27:07 - train: epoch 0033, iter [00110, 01251], lr: 0.000993, loss: 0.3948
2022-09-21 22:27:27 - train: epoch 0033, iter [00120, 01251], lr: 0.000993, loss: 0.4184
2022-09-21 22:27:48 - train: epoch 0033, iter [00130, 01251], lr: 0.000993, loss: 0.4187
2022-09-21 22:28:09 - train: epoch 0033, iter [00140, 01251], lr: 0.000993, loss: 0.4323
2022-09-21 22:28:29 - train: epoch 0033, iter [00150, 01251], lr: 0.000994, loss: 0.4600
2022-09-21 22:28:50 - train: epoch 0033, iter [00160, 01251], lr: 0.000994, loss: 0.4166
2022-09-21 22:29:11 - train: epoch 0033, iter [00170, 01251], lr: 0.000994, loss: 0.4162
2022-09-21 22:29:32 - train: epoch 0033, iter [00180, 01251], lr: 0.000994, loss: 0.3947
2022-09-21 22:29:53 - train: epoch 0033, iter [00190, 01251], lr: 0.000995, loss: 0.4208
2022-09-21 22:30:14 - train: epoch 0033, iter [00200, 01251], lr: 0.000995, loss: 0.4451
2022-09-21 22:30:34 - train: epoch 0033, iter [00210, 01251], lr: 0.000995, loss: 0.4377
2022-09-21 22:30:55 - train: epoch 0033, iter [00220, 01251], lr: 0.000995, loss: 0.4170
2022-09-21 22:31:16 - train: epoch 0033, iter [00230, 01251], lr: 0.000996, loss: 0.4185
2022-09-21 22:31:37 - train: epoch 0033, iter [00240, 01251], lr: 0.000996, loss: 0.4237
2022-09-21 22:31:58 - train: epoch 0033, iter [00250, 01251], lr: 0.000996, loss: 0.3962
2022-09-21 22:32:19 - train: epoch 0033, iter [00260, 01251], lr: 0.000996, loss: 0.4196
2022-09-21 22:32:40 - train: epoch 0033, iter [00270, 01251], lr: 0.000996, loss: 0.4143
2022-09-21 22:33:00 - train: epoch 0033, iter [00280, 01251], lr: 0.000997, loss: 0.4118
2022-09-21 22:33:21 - train: epoch 0033, iter [00290, 01251], lr: 0.000997, loss: 0.4306
2022-09-21 22:33:42 - train: epoch 0033, iter [00300, 01251], lr: 0.000997, loss: 0.4181
2022-09-21 22:34:03 - train: epoch 0033, iter [00310, 01251], lr: 0.000997, loss: 0.4347
2022-09-21 22:34:23 - train: epoch 0033, iter [00320, 01251], lr: 0.000998, loss: 0.4349
2022-09-21 22:34:44 - train: epoch 0033, iter [00330, 01251], lr: 0.000998, loss: 0.4253
2022-09-21 22:35:05 - train: epoch 0033, iter [00340, 01251], lr: 0.000998, loss: 0.4178
2022-09-21 22:35:26 - train: epoch 0033, iter [00350, 01251], lr: 0.000998, loss: 0.4262
2022-09-21 22:35:47 - train: epoch 0033, iter [00360, 01251], lr: 0.000999, loss: 0.4219
2022-09-21 22:36:07 - train: epoch 0033, iter [00370, 01251], lr: 0.000999, loss: 0.4477
2022-09-21 22:36:28 - train: epoch 0033, iter [00380, 01251], lr: 0.000999, loss: 0.4102
2022-09-21 22:36:49 - train: epoch 0033, iter [00390, 01251], lr: 0.000999, loss: 0.4215
2022-09-21 22:37:09 - train: epoch 0033, iter [00400, 01251], lr: 0.001000, loss: 0.4219
2022-09-21 22:37:30 - train: epoch 0033, iter [00410, 01251], lr: 0.001000, loss: 0.4139
2022-09-21 22:37:51 - train: epoch 0033, iter [00420, 01251], lr: 0.001000, loss: 0.4192
2022-09-21 22:38:12 - train: epoch 0033, iter [00430, 01251], lr: 0.001000, loss: 0.4442
2022-09-21 22:38:32 - train: epoch 0033, iter [00440, 01251], lr: 0.001001, loss: 0.4233
2022-09-21 22:38:53 - train: epoch 0033, iter [00450, 01251], lr: 0.001001, loss: 0.4131
2022-09-21 22:39:14 - train: epoch 0033, iter [00460, 01251], lr: 0.001001, loss: 0.4147
2022-09-21 22:39:34 - train: epoch 0033, iter [00470, 01251], lr: 0.001001, loss: 0.4551
2022-09-21 22:39:55 - train: epoch 0033, iter [00480, 01251], lr: 0.001002, loss: 0.3996
2022-09-21 22:40:16 - train: epoch 0033, iter [00490, 01251], lr: 0.001002, loss: 0.4183
2022-09-21 22:40:37 - train: epoch 0033, iter [00500, 01251], lr: 0.001002, loss: 0.4434
2022-09-21 22:40:58 - train: epoch 0033, iter [00510, 01251], lr: 0.001002, loss: 0.4469
2022-09-21 22:41:18 - train: epoch 0033, iter [00520, 01251], lr: 0.001002, loss: 0.4419
2022-09-21 22:41:39 - train: epoch 0033, iter [00530, 01251], lr: 0.001003, loss: 0.4227
2022-09-21 22:42:00 - train: epoch 0033, iter [00540, 01251], lr: 0.001003, loss: 0.4246
2022-09-21 22:42:21 - train: epoch 0033, iter [00550, 01251], lr: 0.001003, loss: 0.4332
2022-09-21 22:42:41 - train: epoch 0033, iter [00560, 01251], lr: 0.001003, loss: 0.4039
2022-09-21 22:43:02 - train: epoch 0033, iter [00570, 01251], lr: 0.001004, loss: 0.4119
2022-09-21 22:43:23 - train: epoch 0033, iter [00580, 01251], lr: 0.001004, loss: 0.4201
2022-09-21 22:43:44 - train: epoch 0033, iter [00590, 01251], lr: 0.001004, loss: 0.4240
2022-09-21 22:44:05 - train: epoch 0033, iter [00600, 01251], lr: 0.001004, loss: 0.4204
2022-09-21 22:44:26 - train: epoch 0033, iter [00610, 01251], lr: 0.001005, loss: 0.3970
2022-09-21 22:44:47 - train: epoch 0033, iter [00620, 01251], lr: 0.001005, loss: 0.4204
2022-09-21 22:45:07 - train: epoch 0033, iter [00630, 01251], lr: 0.001005, loss: 0.4129
2022-09-21 22:45:28 - train: epoch 0033, iter [00640, 01251], lr: 0.001005, loss: 0.4267
2022-09-21 22:45:49 - train: epoch 0033, iter [00650, 01251], lr: 0.001006, loss: 0.4247
2022-09-21 22:46:10 - train: epoch 0033, iter [00660, 01251], lr: 0.001006, loss: 0.4354
2022-09-21 22:46:30 - train: epoch 0033, iter [00670, 01251], lr: 0.001006, loss: 0.4216
2022-09-21 22:46:51 - train: epoch 0033, iter [00680, 01251], lr: 0.001006, loss: 0.4089
2022-09-21 22:47:12 - train: epoch 0033, iter [00690, 01251], lr: 0.001007, loss: 0.4336
2022-09-21 22:47:33 - train: epoch 0033, iter [00700, 01251], lr: 0.001007, loss: 0.4527
2022-09-21 22:47:53 - train: epoch 0033, iter [00710, 01251], lr: 0.001007, loss: 0.4163
2022-09-21 22:48:14 - train: epoch 0033, iter [00720, 01251], lr: 0.001007, loss: 0.4309
2022-09-21 22:48:35 - train: epoch 0033, iter [00730, 01251], lr: 0.001008, loss: 0.4199
2022-09-21 22:48:56 - train: epoch 0033, iter [00740, 01251], lr: 0.001008, loss: 0.4239
2022-09-21 22:49:16 - train: epoch 0033, iter [00750, 01251], lr: 0.001008, loss: 0.4386
2022-09-21 22:49:37 - train: epoch 0033, iter [00760, 01251], lr: 0.001008, loss: 0.4441
2022-09-21 22:49:58 - train: epoch 0033, iter [00770, 01251], lr: 0.001008, loss: 0.4263
2022-09-21 22:50:19 - train: epoch 0033, iter [00780, 01251], lr: 0.001009, loss: 0.4442
2022-09-21 22:50:39 - train: epoch 0033, iter [00790, 01251], lr: 0.001009, loss: 0.4158
2022-09-21 22:51:00 - train: epoch 0033, iter [00800, 01251], lr: 0.001009, loss: 0.4380
2022-09-21 22:51:21 - train: epoch 0033, iter [00810, 01251], lr: 0.001009, loss: 0.4322
2022-09-21 22:51:42 - train: epoch 0033, iter [00820, 01251], lr: 0.001010, loss: 0.4440
2022-09-21 22:52:03 - train: epoch 0033, iter [00830, 01251], lr: 0.001010, loss: 0.4254
2022-09-21 22:52:23 - train: epoch 0033, iter [00840, 01251], lr: 0.001010, loss: 0.4394
2022-09-21 22:52:44 - train: epoch 0033, iter [00850, 01251], lr: 0.001010, loss: 0.4417
2022-09-21 22:53:05 - train: epoch 0033, iter [00860, 01251], lr: 0.001011, loss: 0.4266
2022-09-21 22:53:26 - train: epoch 0033, iter [00870, 01251], lr: 0.001011, loss: 0.4194
2022-09-21 22:53:46 - train: epoch 0033, iter [00880, 01251], lr: 0.001011, loss: 0.4211
2022-09-21 22:54:07 - train: epoch 0033, iter [00890, 01251], lr: 0.001011, loss: 0.4064
2022-09-21 22:54:28 - train: epoch 0033, iter [00900, 01251], lr: 0.001012, loss: 0.4162
2022-09-21 22:54:49 - train: epoch 0033, iter [00910, 01251], lr: 0.001012, loss: 0.4151
2022-09-21 22:55:09 - train: epoch 0033, iter [00920, 01251], lr: 0.001012, loss: 0.4228
2022-09-21 22:55:30 - train: epoch 0033, iter [00930, 01251], lr: 0.001012, loss: 0.4134
2022-09-21 22:55:51 - train: epoch 0033, iter [00940, 01251], lr: 0.001013, loss: 0.4521
2022-09-21 22:56:12 - train: epoch 0033, iter [00950, 01251], lr: 0.001013, loss: 0.4322
2022-09-21 22:56:33 - train: epoch 0033, iter [00960, 01251], lr: 0.001013, loss: 0.4266
2022-09-21 22:56:54 - train: epoch 0033, iter [00970, 01251], lr: 0.001013, loss: 0.4287
2022-09-21 22:57:15 - train: epoch 0033, iter [00980, 01251], lr: 0.001014, loss: 0.4202
2022-09-21 22:57:36 - train: epoch 0033, iter [00990, 01251], lr: 0.001014, loss: 0.4255
2022-09-21 22:57:57 - train: epoch 0033, iter [01000, 01251], lr: 0.001014, loss: 0.4316
2022-09-21 22:58:17 - train: epoch 0033, iter [01010, 01251], lr: 0.001014, loss: 0.4152
2022-09-21 22:58:38 - train: epoch 0033, iter [01020, 01251], lr: 0.001014, loss: 0.3995
2022-09-21 22:58:59 - train: epoch 0033, iter [01030, 01251], lr: 0.001015, loss: 0.4108
2022-09-21 22:59:20 - train: epoch 0033, iter [01040, 01251], lr: 0.001015, loss: 0.4258
2022-09-21 22:59:41 - train: epoch 0033, iter [01050, 01251], lr: 0.001015, loss: 0.4379
2022-09-21 23:00:02 - train: epoch 0033, iter [01060, 01251], lr: 0.001015, loss: 0.4354
2022-09-21 23:00:22 - train: epoch 0033, iter [01070, 01251], lr: 0.001016, loss: 0.4321
2022-09-21 23:00:43 - train: epoch 0033, iter [01080, 01251], lr: 0.001016, loss: 0.4373
2022-09-21 23:01:04 - train: epoch 0033, iter [01090, 01251], lr: 0.001016, loss: 0.4124
2022-09-21 23:01:25 - train: epoch 0033, iter [01100, 01251], lr: 0.001016, loss: 0.4340
2022-09-21 23:01:45 - train: epoch 0033, iter [01110, 01251], lr: 0.001017, loss: 0.4311
2022-09-21 23:02:06 - train: epoch 0033, iter [01120, 01251], lr: 0.001017, loss: 0.4113
2022-09-21 23:02:27 - train: epoch 0033, iter [01130, 01251], lr: 0.001017, loss: 0.3955
2022-09-21 23:02:48 - train: epoch 0033, iter [01140, 01251], lr: 0.001017, loss: 0.4142
2022-09-21 23:03:09 - train: epoch 0033, iter [01150, 01251], lr: 0.001018, loss: 0.4150
2022-09-21 23:03:30 - train: epoch 0033, iter [01160, 01251], lr: 0.001018, loss: 0.4084
2022-09-21 23:03:50 - train: epoch 0033, iter [01170, 01251], lr: 0.001018, loss: 0.4125
2022-09-21 23:04:11 - train: epoch 0033, iter [01180, 01251], lr: 0.001018, loss: 0.4283
2022-09-21 23:04:32 - train: epoch 0033, iter [01190, 01251], lr: 0.001019, loss: 0.4170
2022-09-21 23:04:53 - train: epoch 0033, iter [01200, 01251], lr: 0.001019, loss: 0.4249
2022-09-21 23:05:13 - train: epoch 0033, iter [01210, 01251], lr: 0.001019, loss: 0.4337
2022-09-21 23:05:34 - train: epoch 0033, iter [01220, 01251], lr: 0.001019, loss: 0.4232
2022-09-21 23:05:55 - train: epoch 0033, iter [01230, 01251], lr: 0.001019, loss: 0.4200
2022-09-21 23:06:16 - train: epoch 0033, iter [01240, 01251], lr: 0.001020, loss: 0.3874
2022-09-21 23:06:36 - train: epoch 0033, iter [01250, 01251], lr: 0.001020, loss: 0.4301
2022-09-21 23:06:40 - train: epoch 033, train_loss: 0.4233
2022-09-21 23:06:45 - until epoch: 033, best_loss: 0.4233
2022-09-21 23:06:45 - epoch 034 lr: 0.001020
2022-09-21 23:07:23 - train: epoch 0034, iter [00010, 01251], lr: 0.001020, loss: 0.4369
2022-09-21 23:07:44 - train: epoch 0034, iter [00020, 01251], lr: 0.001020, loss: 0.4261
2022-09-21 23:08:05 - train: epoch 0034, iter [00030, 01251], lr: 0.001021, loss: 0.4238
2022-09-21 23:08:25 - train: epoch 0034, iter [00040, 01251], lr: 0.001021, loss: 0.4188
2022-09-21 23:08:46 - train: epoch 0034, iter [00050, 01251], lr: 0.001021, loss: 0.3989
2022-09-21 23:09:07 - train: epoch 0034, iter [00060, 01251], lr: 0.001021, loss: 0.4217
2022-09-21 23:09:28 - train: epoch 0034, iter [00070, 01251], lr: 0.001022, loss: 0.4179
2022-09-21 23:09:48 - train: epoch 0034, iter [00080, 01251], lr: 0.001022, loss: 0.4327
2022-09-21 23:10:09 - train: epoch 0034, iter [00090, 01251], lr: 0.001022, loss: 0.4221
2022-09-21 23:10:30 - train: epoch 0034, iter [00100, 01251], lr: 0.001022, loss: 0.4217
2022-09-21 23:10:50 - train: epoch 0034, iter [00110, 01251], lr: 0.001023, loss: 0.4515
2022-09-21 23:11:11 - train: epoch 0034, iter [00120, 01251], lr: 0.001023, loss: 0.4120
2022-09-21 23:11:32 - train: epoch 0034, iter [00130, 01251], lr: 0.001023, loss: 0.4228
2022-09-21 23:11:52 - train: epoch 0034, iter [00140, 01251], lr: 0.001023, loss: 0.4233
2022-09-21 23:12:13 - train: epoch 0034, iter [00150, 01251], lr: 0.001024, loss: 0.4114
2022-09-21 23:12:33 - train: epoch 0034, iter [00160, 01251], lr: 0.001024, loss: 0.4337
2022-09-21 23:12:54 - train: epoch 0034, iter [00170, 01251], lr: 0.001024, loss: 0.4479
2022-09-21 23:13:15 - train: epoch 0034, iter [00180, 01251], lr: 0.001024, loss: 0.4099
2022-09-21 23:13:35 - train: epoch 0034, iter [00190, 01251], lr: 0.001025, loss: 0.4246
2022-09-21 23:13:56 - train: epoch 0034, iter [00200, 01251], lr: 0.001025, loss: 0.4342
2022-09-21 23:14:17 - train: epoch 0034, iter [00210, 01251], lr: 0.001025, loss: 0.4338
2022-09-21 23:14:37 - train: epoch 0034, iter [00220, 01251], lr: 0.001025, loss: 0.4168
2022-09-21 23:14:58 - train: epoch 0034, iter [00230, 01251], lr: 0.001026, loss: 0.4257
2022-09-21 23:15:18 - train: epoch 0034, iter [00240, 01251], lr: 0.001026, loss: 0.4208
2022-09-21 23:15:39 - train: epoch 0034, iter [00250, 01251], lr: 0.001026, loss: 0.4242
2022-09-21 23:15:59 - train: epoch 0034, iter [00260, 01251], lr: 0.001026, loss: 0.4103
2022-09-21 23:16:20 - train: epoch 0034, iter [00270, 01251], lr: 0.001026, loss: 0.4136
2022-09-21 23:16:41 - train: epoch 0034, iter [00280, 01251], lr: 0.001027, loss: 0.4289
2022-09-21 23:17:01 - train: epoch 0034, iter [00290, 01251], lr: 0.001027, loss: 0.4154
2022-09-21 23:17:22 - train: epoch 0034, iter [00300, 01251], lr: 0.001027, loss: 0.4055
2022-09-21 23:17:42 - train: epoch 0034, iter [00310, 01251], lr: 0.001027, loss: 0.4116
2022-09-21 23:18:03 - train: epoch 0034, iter [00320, 01251], lr: 0.001028, loss: 0.4272
2022-09-21 23:18:23 - train: epoch 0034, iter [00330, 01251], lr: 0.001028, loss: 0.4076
2022-09-21 23:18:44 - train: epoch 0034, iter [00340, 01251], lr: 0.001028, loss: 0.4137
2022-09-21 23:19:05 - train: epoch 0034, iter [00350, 01251], lr: 0.001028, loss: 0.4038
2022-09-21 23:19:25 - train: epoch 0034, iter [00360, 01251], lr: 0.001029, loss: 0.4132
2022-09-21 23:19:46 - train: epoch 0034, iter [00370, 01251], lr: 0.001029, loss: 0.4196
2022-09-21 23:20:07 - train: epoch 0034, iter [00380, 01251], lr: 0.001029, loss: 0.4360
2022-09-21 23:20:27 - train: epoch 0034, iter [00390, 01251], lr: 0.001029, loss: 0.4140
2022-09-21 23:20:48 - train: epoch 0034, iter [00400, 01251], lr: 0.001030, loss: 0.4249
2022-09-21 23:21:08 - train: epoch 0034, iter [00410, 01251], lr: 0.001030, loss: 0.4130
2022-09-21 23:21:29 - train: epoch 0034, iter [00420, 01251], lr: 0.001030, loss: 0.4155
2022-09-21 23:21:50 - train: epoch 0034, iter [00430, 01251], lr: 0.001030, loss: 0.4212
2022-09-21 23:22:10 - train: epoch 0034, iter [00440, 01251], lr: 0.001031, loss: 0.4087
2022-09-21 23:22:31 - train: epoch 0034, iter [00450, 01251], lr: 0.001031, loss: 0.4237
2022-09-21 23:22:51 - train: epoch 0034, iter [00460, 01251], lr: 0.001031, loss: 0.4203
2022-09-21 23:23:12 - train: epoch 0034, iter [00470, 01251], lr: 0.001031, loss: 0.4161
2022-09-21 23:23:33 - train: epoch 0034, iter [00480, 01251], lr: 0.001032, loss: 0.4110
2022-09-21 23:23:53 - train: epoch 0034, iter [00490, 01251], lr: 0.001032, loss: 0.4412
2022-09-21 23:24:14 - train: epoch 0034, iter [00500, 01251], lr: 0.001032, loss: 0.4145
2022-09-21 23:24:34 - train: epoch 0034, iter [00510, 01251], lr: 0.001032, loss: 0.4208
2022-09-21 23:24:55 - train: epoch 0034, iter [00520, 01251], lr: 0.001032, loss: 0.4043
2022-09-21 23:25:15 - train: epoch 0034, iter [00530, 01251], lr: 0.001033, loss: 0.4155
2022-09-21 23:25:36 - train: epoch 0034, iter [00540, 01251], lr: 0.001033, loss: 0.3959
2022-09-21 23:25:57 - train: epoch 0034, iter [00550, 01251], lr: 0.001033, loss: 0.4371
2022-09-21 23:26:17 - train: epoch 0034, iter [00560, 01251], lr: 0.001033, loss: 0.4162
2022-09-21 23:26:38 - train: epoch 0034, iter [00570, 01251], lr: 0.001034, loss: 0.4205
2022-09-21 23:26:59 - train: epoch 0034, iter [00580, 01251], lr: 0.001034, loss: 0.4390
2022-09-21 23:27:19 - train: epoch 0034, iter [00590, 01251], lr: 0.001034, loss: 0.4380
2022-09-21 23:27:40 - train: epoch 0034, iter [00600, 01251], lr: 0.001034, loss: 0.4208
2022-09-21 23:28:00 - train: epoch 0034, iter [00610, 01251], lr: 0.001035, loss: 0.3956
2022-09-21 23:28:21 - train: epoch 0034, iter [00620, 01251], lr: 0.001035, loss: 0.4178
2022-09-21 23:28:42 - train: epoch 0034, iter [00630, 01251], lr: 0.001035, loss: 0.4024
2022-09-21 23:29:02 - train: epoch 0034, iter [00640, 01251], lr: 0.001035, loss: 0.4268
2022-09-21 23:29:23 - train: epoch 0034, iter [00650, 01251], lr: 0.001036, loss: 0.4193
2022-09-21 23:29:43 - train: epoch 0034, iter [00660, 01251], lr: 0.001036, loss: 0.4322
2022-09-21 23:30:04 - train: epoch 0034, iter [00670, 01251], lr: 0.001036, loss: 0.4210
2022-09-21 23:30:25 - train: epoch 0034, iter [00680, 01251], lr: 0.001036, loss: 0.4421
2022-09-21 23:30:45 - train: epoch 0034, iter [00690, 01251], lr: 0.001037, loss: 0.4106
2022-09-21 23:31:06 - train: epoch 0034, iter [00700, 01251], lr: 0.001037, loss: 0.4259
2022-09-21 23:31:26 - train: epoch 0034, iter [00710, 01251], lr: 0.001037, loss: 0.4277
2022-09-21 23:31:47 - train: epoch 0034, iter [00720, 01251], lr: 0.001037, loss: 0.4197
2022-09-21 23:32:08 - train: epoch 0034, iter [00730, 01251], lr: 0.001038, loss: 0.4218
2022-09-21 23:32:28 - train: epoch 0034, iter [00740, 01251], lr: 0.001038, loss: 0.4101
2022-09-21 23:32:49 - train: epoch 0034, iter [00750, 01251], lr: 0.001038, loss: 0.4238
2022-09-21 23:33:09 - train: epoch 0034, iter [00760, 01251], lr: 0.001038, loss: 0.4302
2022-09-21 23:33:30 - train: epoch 0034, iter [00770, 01251], lr: 0.001038, loss: 0.4157
2022-09-21 23:33:51 - train: epoch 0034, iter [00780, 01251], lr: 0.001039, loss: 0.4207
2022-09-21 23:34:11 - train: epoch 0034, iter [00790, 01251], lr: 0.001039, loss: 0.4151
2022-09-21 23:34:32 - train: epoch 0034, iter [00800, 01251], lr: 0.001039, loss: 0.4191
2022-09-21 23:34:53 - train: epoch 0034, iter [00810, 01251], lr: 0.001039, loss: 0.4137
2022-09-21 23:35:13 - train: epoch 0034, iter [00820, 01251], lr: 0.001040, loss: 0.4379
2022-09-21 23:35:34 - train: epoch 0034, iter [00830, 01251], lr: 0.001040, loss: 0.4010
2022-09-21 23:35:55 - train: epoch 0034, iter [00840, 01251], lr: 0.001040, loss: 0.4196
2022-09-21 23:36:15 - train: epoch 0034, iter [00850, 01251], lr: 0.001040, loss: 0.4453
2022-09-21 23:36:36 - train: epoch 0034, iter [00860, 01251], lr: 0.001041, loss: 0.4365
2022-09-21 23:36:57 - train: epoch 0034, iter [00870, 01251], lr: 0.001041, loss: 0.4237
2022-09-21 23:37:17 - train: epoch 0034, iter [00880, 01251], lr: 0.001041, loss: 0.4123
2022-09-21 23:37:38 - train: epoch 0034, iter [00890, 01251], lr: 0.001041, loss: 0.4233
2022-09-21 23:37:59 - train: epoch 0034, iter [00900, 01251], lr: 0.001042, loss: 0.4302
2022-09-21 23:38:19 - train: epoch 0034, iter [00910, 01251], lr: 0.001042, loss: 0.4317
2022-09-21 23:38:40 - train: epoch 0034, iter [00920, 01251], lr: 0.001042, loss: 0.4323
2022-09-21 23:39:00 - train: epoch 0034, iter [00930, 01251], lr: 0.001042, loss: 0.4469
2022-09-21 23:39:21 - train: epoch 0034, iter [00940, 01251], lr: 0.001043, loss: 0.4253
2022-09-21 23:39:41 - train: epoch 0034, iter [00950, 01251], lr: 0.001043, loss: 0.4146
2022-09-21 23:40:02 - train: epoch 0034, iter [00960, 01251], lr: 0.001043, loss: 0.4175
2022-09-21 23:40:23 - train: epoch 0034, iter [00970, 01251], lr: 0.001043, loss: 0.4097
2022-09-21 23:40:43 - train: epoch 0034, iter [00980, 01251], lr: 0.001044, loss: 0.4211
2022-09-21 23:41:04 - train: epoch 0034, iter [00990, 01251], lr: 0.001044, loss: 0.4355
2022-09-21 23:41:24 - train: epoch 0034, iter [01000, 01251], lr: 0.001044, loss: 0.4192
2022-09-21 23:41:45 - train: epoch 0034, iter [01010, 01251], lr: 0.001044, loss: 0.4149
2022-09-21 23:42:06 - train: epoch 0034, iter [01020, 01251], lr: 0.001044, loss: 0.4200
2022-09-21 23:42:26 - train: epoch 0034, iter [01030, 01251], lr: 0.001045, loss: 0.3974
2022-09-21 23:42:47 - train: epoch 0034, iter [01040, 01251], lr: 0.001045, loss: 0.4303
2022-09-21 23:43:07 - train: epoch 0034, iter [01050, 01251], lr: 0.001045, loss: 0.4197
2022-09-21 23:43:28 - train: epoch 0034, iter [01060, 01251], lr: 0.001045, loss: 0.4302
2022-09-21 23:43:49 - train: epoch 0034, iter [01070, 01251], lr: 0.001046, loss: 0.4161
2022-09-21 23:44:09 - train: epoch 0034, iter [01080, 01251], lr: 0.001046, loss: 0.4375
2022-09-21 23:44:30 - train: epoch 0034, iter [01090, 01251], lr: 0.001046, loss: 0.4509
2022-09-21 23:44:51 - train: epoch 0034, iter [01100, 01251], lr: 0.001046, loss: 0.4379
2022-09-21 23:45:11 - train: epoch 0034, iter [01110, 01251], lr: 0.001047, loss: 0.4242
2022-09-21 23:45:32 - train: epoch 0034, iter [01120, 01251], lr: 0.001047, loss: 0.4265
2022-09-21 23:45:52 - train: epoch 0034, iter [01130, 01251], lr: 0.001047, loss: 0.4197
2022-09-21 23:46:13 - train: epoch 0034, iter [01140, 01251], lr: 0.001047, loss: 0.4196
2022-09-21 23:46:34 - train: epoch 0034, iter [01150, 01251], lr: 0.001048, loss: 0.4270
2022-09-21 23:46:54 - train: epoch 0034, iter [01160, 01251], lr: 0.001048, loss: 0.4081
2022-09-21 23:47:15 - train: epoch 0034, iter [01170, 01251], lr: 0.001048, loss: 0.4246
2022-09-21 23:47:35 - train: epoch 0034, iter [01180, 01251], lr: 0.001048, loss: 0.4252
2022-09-21 23:47:56 - train: epoch 0034, iter [01190, 01251], lr: 0.001049, loss: 0.4157
2022-09-21 23:48:17 - train: epoch 0034, iter [01200, 01251], lr: 0.001049, loss: 0.4151
2022-09-21 23:48:37 - train: epoch 0034, iter [01210, 01251], lr: 0.001049, loss: 0.4508
2022-09-21 23:48:58 - train: epoch 0034, iter [01220, 01251], lr: 0.001049, loss: 0.4172
2022-09-21 23:49:19 - train: epoch 0034, iter [01230, 01251], lr: 0.001049, loss: 0.4201
2022-09-21 23:49:39 - train: epoch 0034, iter [01240, 01251], lr: 0.001050, loss: 0.4326
2022-09-21 23:49:59 - train: epoch 0034, iter [01250, 01251], lr: 0.001050, loss: 0.4204
2022-09-21 23:50:04 - train: epoch 034, train_loss: 0.4230
2022-09-21 23:50:08 - until epoch: 034, best_loss: 0.4230
2022-09-21 23:50:08 - epoch 035 lr: 0.001050
2022-09-21 23:50:45 - train: epoch 0035, iter [00010, 01251], lr: 0.001050, loss: 0.4349
2022-09-21 23:51:06 - train: epoch 0035, iter [00020, 01251], lr: 0.001050, loss: 0.4225
2022-09-21 23:51:26 - train: epoch 0035, iter [00030, 01251], lr: 0.001051, loss: 0.4181
2022-09-21 23:51:47 - train: epoch 0035, iter [00040, 01251], lr: 0.001051, loss: 0.4209
2022-09-21 23:52:08 - train: epoch 0035, iter [00050, 01251], lr: 0.001051, loss: 0.4086
2022-09-21 23:52:28 - train: epoch 0035, iter [00060, 01251], lr: 0.001051, loss: 0.4455
2022-09-21 23:52:49 - train: epoch 0035, iter [00070, 01251], lr: 0.001052, loss: 0.4014
2022-09-21 23:53:10 - train: epoch 0035, iter [00080, 01251], lr: 0.001052, loss: 0.4221
2022-09-21 23:53:31 - train: epoch 0035, iter [00090, 01251], lr: 0.001052, loss: 0.4149
2022-09-21 23:53:52 - train: epoch 0035, iter [00100, 01251], lr: 0.001052, loss: 0.4188
2022-09-21 23:54:12 - train: epoch 0035, iter [00110, 01251], lr: 0.001053, loss: 0.4131
2022-09-21 23:54:33 - train: epoch 0035, iter [00120, 01251], lr: 0.001053, loss: 0.4239
2022-09-21 23:54:54 - train: epoch 0035, iter [00130, 01251], lr: 0.001053, loss: 0.4298
2022-09-21 23:55:15 - train: epoch 0035, iter [00140, 01251], lr: 0.001053, loss: 0.4307
2022-09-21 23:55:35 - train: epoch 0035, iter [00150, 01251], lr: 0.001054, loss: 0.4071
2022-09-21 23:55:56 - train: epoch 0035, iter [00160, 01251], lr: 0.001054, loss: 0.4147
2022-09-21 23:56:17 - train: epoch 0035, iter [00170, 01251], lr: 0.001054, loss: 0.4242
2022-09-21 23:56:38 - train: epoch 0035, iter [00180, 01251], lr: 0.001054, loss: 0.4151
2022-09-21 23:56:58 - train: epoch 0035, iter [00190, 01251], lr: 0.001055, loss: 0.4314
2022-09-21 23:57:19 - train: epoch 0035, iter [00200, 01251], lr: 0.001055, loss: 0.4414
2022-09-21 23:57:40 - train: epoch 0035, iter [00210, 01251], lr: 0.001055, loss: 0.4173
2022-09-21 23:58:00 - train: epoch 0035, iter [00220, 01251], lr: 0.001055, loss: 0.4075
2022-09-21 23:58:21 - train: epoch 0035, iter [00230, 01251], lr: 0.001056, loss: 0.3995
2022-09-21 23:58:42 - train: epoch 0035, iter [00240, 01251], lr: 0.001056, loss: 0.4139
2022-09-21 23:59:03 - train: epoch 0035, iter [00250, 01251], lr: 0.001056, loss: 0.4276
2022-09-21 23:59:24 - train: epoch 0035, iter [00260, 01251], lr: 0.001056, loss: 0.4137
2022-09-21 23:59:44 - train: epoch 0035, iter [00270, 01251], lr: 0.001056, loss: 0.4250
2022-09-22 00:00:05 - train: epoch 0035, iter [00280, 01251], lr: 0.001057, loss: 0.4117
2022-09-22 00:00:26 - train: epoch 0035, iter [00290, 01251], lr: 0.001057, loss: 0.4255
2022-09-22 00:00:47 - train: epoch 0035, iter [00300, 01251], lr: 0.001057, loss: 0.4159
2022-09-22 00:01:07 - train: epoch 0035, iter [00310, 01251], lr: 0.001057, loss: 0.4148
2022-09-22 00:01:28 - train: epoch 0035, iter [00320, 01251], lr: 0.001058, loss: 0.4191
2022-09-22 00:01:49 - train: epoch 0035, iter [00330, 01251], lr: 0.001058, loss: 0.4209
2022-09-22 00:02:10 - train: epoch 0035, iter [00340, 01251], lr: 0.001058, loss: 0.4148
2022-09-22 00:02:30 - train: epoch 0035, iter [00350, 01251], lr: 0.001058, loss: 0.4289
2022-09-22 00:02:51 - train: epoch 0035, iter [00360, 01251], lr: 0.001059, loss: 0.4318
2022-09-22 00:03:12 - train: epoch 0035, iter [00370, 01251], lr: 0.001059, loss: 0.4212
2022-09-22 00:03:33 - train: epoch 0035, iter [00380, 01251], lr: 0.001059, loss: 0.4210
2022-09-22 00:03:53 - train: epoch 0035, iter [00390, 01251], lr: 0.001059, loss: 0.4083
2022-09-22 00:04:14 - train: epoch 0035, iter [00400, 01251], lr: 0.001060, loss: 0.4204
2022-09-22 00:04:35 - train: epoch 0035, iter [00410, 01251], lr: 0.001060, loss: 0.4220
2022-09-22 00:04:56 - train: epoch 0035, iter [00420, 01251], lr: 0.001060, loss: 0.4186
2022-09-22 00:05:17 - train: epoch 0035, iter [00430, 01251], lr: 0.001060, loss: 0.4191
2022-09-22 00:05:38 - train: epoch 0035, iter [00440, 01251], lr: 0.001061, loss: 0.4188
2022-09-22 00:05:58 - train: epoch 0035, iter [00450, 01251], lr: 0.001061, loss: 0.4266
2022-09-22 00:06:19 - train: epoch 0035, iter [00460, 01251], lr: 0.001061, loss: 0.4258
2022-09-22 00:06:40 - train: epoch 0035, iter [00470, 01251], lr: 0.001061, loss: 0.4114
2022-09-22 00:07:00 - train: epoch 0035, iter [00480, 01251], lr: 0.001062, loss: 0.4212
2022-09-22 00:07:21 - train: epoch 0035, iter [00490, 01251], lr: 0.001062, loss: 0.4067
2022-09-22 00:07:42 - train: epoch 0035, iter [00500, 01251], lr: 0.001062, loss: 0.4257
2022-09-22 00:08:03 - train: epoch 0035, iter [00510, 01251], lr: 0.001062, loss: 0.4252
2022-09-22 00:08:23 - train: epoch 0035, iter [00520, 01251], lr: 0.001062, loss: 0.4113
2022-09-22 00:08:44 - train: epoch 0035, iter [00530, 01251], lr: 0.001063, loss: 0.4437
2022-09-22 00:09:05 - train: epoch 0035, iter [00540, 01251], lr: 0.001063, loss: 0.4156
2022-09-22 00:09:26 - train: epoch 0035, iter [00550, 01251], lr: 0.001063, loss: 0.4399
2022-09-22 00:09:46 - train: epoch 0035, iter [00560, 01251], lr: 0.001063, loss: 0.4083
2022-09-22 00:10:07 - train: epoch 0035, iter [00570, 01251], lr: 0.001064, loss: 0.4134
2022-09-22 00:10:28 - train: epoch 0035, iter [00580, 01251], lr: 0.001064, loss: 0.4265
2022-09-22 00:10:49 - train: epoch 0035, iter [00590, 01251], lr: 0.001064, loss: 0.4149
2022-09-22 00:11:09 - train: epoch 0035, iter [00600, 01251], lr: 0.001064, loss: 0.4212
2022-09-22 00:11:30 - train: epoch 0035, iter [00610, 01251], lr: 0.001065, loss: 0.4122
2022-09-22 00:11:51 - train: epoch 0035, iter [00620, 01251], lr: 0.001065, loss: 0.4275
2022-09-22 00:12:12 - train: epoch 0035, iter [00630, 01251], lr: 0.001065, loss: 0.4219
2022-09-22 00:12:33 - train: epoch 0035, iter [00640, 01251], lr: 0.001065, loss: 0.4248
2022-09-22 00:12:53 - train: epoch 0035, iter [00650, 01251], lr: 0.001066, loss: 0.4327
2022-09-22 00:13:14 - train: epoch 0035, iter [00660, 01251], lr: 0.001066, loss: 0.4283
2022-09-22 00:13:35 - train: epoch 0035, iter [00670, 01251], lr: 0.001066, loss: 0.4230
2022-09-22 00:13:56 - train: epoch 0035, iter [00680, 01251], lr: 0.001066, loss: 0.4156
2022-09-22 00:14:16 - train: epoch 0035, iter [00690, 01251], lr: 0.001067, loss: 0.4126
2022-09-22 00:14:37 - train: epoch 0035, iter [00700, 01251], lr: 0.001067, loss: 0.4174
2022-09-22 00:14:58 - train: epoch 0035, iter [00710, 01251], lr: 0.001067, loss: 0.4315
2022-09-22 00:15:19 - train: epoch 0035, iter [00720, 01251], lr: 0.001067, loss: 0.4303
2022-09-22 00:15:40 - train: epoch 0035, iter [00730, 01251], lr: 0.001068, loss: 0.4199
2022-09-22 00:16:00 - train: epoch 0035, iter [00740, 01251], lr: 0.001068, loss: 0.4097
2022-09-22 00:16:21 - train: epoch 0035, iter [00750, 01251], lr: 0.001068, loss: 0.4397
2022-09-22 00:16:42 - train: epoch 0035, iter [00760, 01251], lr: 0.001068, loss: 0.4277
2022-09-22 00:17:03 - train: epoch 0035, iter [00770, 01251], lr: 0.001068, loss: 0.4059
2022-09-22 00:17:23 - train: epoch 0035, iter [00780, 01251], lr: 0.001069, loss: 0.4357
2022-09-22 00:17:44 - train: epoch 0035, iter [00790, 01251], lr: 0.001069, loss: 0.4158
2022-09-22 00:18:05 - train: epoch 0035, iter [00800, 01251], lr: 0.001069, loss: 0.4112
2022-09-22 00:18:26 - train: epoch 0035, iter [00810, 01251], lr: 0.001069, loss: 0.4323
2022-09-22 00:18:47 - train: epoch 0035, iter [00820, 01251], lr: 0.001070, loss: 0.4185
2022-09-22 00:19:07 - train: epoch 0035, iter [00830, 01251], lr: 0.001070, loss: 0.4169
2022-09-22 00:19:28 - train: epoch 0035, iter [00840, 01251], lr: 0.001070, loss: 0.4163
2022-09-22 00:19:49 - train: epoch 0035, iter [00850, 01251], lr: 0.001070, loss: 0.4238
2022-09-22 00:20:10 - train: epoch 0035, iter [00860, 01251], lr: 0.001071, loss: 0.4192
2022-09-22 00:20:31 - train: epoch 0035, iter [00870, 01251], lr: 0.001071, loss: 0.4238
2022-09-22 00:20:51 - train: epoch 0035, iter [00880, 01251], lr: 0.001071, loss: 0.4488
2022-09-22 00:21:12 - train: epoch 0035, iter [00890, 01251], lr: 0.001071, loss: 0.4108
2022-09-22 00:21:33 - train: epoch 0035, iter [00900, 01251], lr: 0.001072, loss: 0.4176
2022-09-22 00:21:54 - train: epoch 0035, iter [00910, 01251], lr: 0.001072, loss: 0.4133
2022-09-22 00:22:15 - train: epoch 0035, iter [00920, 01251], lr: 0.001072, loss: 0.4221
2022-09-22 00:22:35 - train: epoch 0035, iter [00930, 01251], lr: 0.001072, loss: 0.4406
2022-09-22 00:22:56 - train: epoch 0035, iter [00940, 01251], lr: 0.001073, loss: 0.4347
2022-09-22 00:23:17 - train: epoch 0035, iter [00950, 01251], lr: 0.001073, loss: 0.4171
2022-09-22 00:23:38 - train: epoch 0035, iter [00960, 01251], lr: 0.001073, loss: 0.4212
2022-09-22 00:23:58 - train: epoch 0035, iter [00970, 01251], lr: 0.001073, loss: 0.4385
2022-09-22 00:24:19 - train: epoch 0035, iter [00980, 01251], lr: 0.001074, loss: 0.4251
2022-09-22 00:24:39 - train: epoch 0035, iter [00990, 01251], lr: 0.001074, loss: 0.4142
2022-09-22 00:25:00 - train: epoch 0035, iter [01000, 01251], lr: 0.001074, loss: 0.4430
2022-09-22 00:25:21 - train: epoch 0035, iter [01010, 01251], lr: 0.001074, loss: 0.4076
2022-09-22 00:25:42 - train: epoch 0035, iter [01020, 01251], lr: 0.001074, loss: 0.4187
2022-09-22 00:26:02 - train: epoch 0035, iter [01030, 01251], lr: 0.001075, loss: 0.4230
2022-09-22 00:26:23 - train: epoch 0035, iter [01040, 01251], lr: 0.001075, loss: 0.4203
2022-09-22 00:26:44 - train: epoch 0035, iter [01050, 01251], lr: 0.001075, loss: 0.4281
2022-09-22 00:27:05 - train: epoch 0035, iter [01060, 01251], lr: 0.001075, loss: 0.4183
2022-09-22 00:27:25 - train: epoch 0035, iter [01070, 01251], lr: 0.001076, loss: 0.4216
2022-09-22 00:27:46 - train: epoch 0035, iter [01080, 01251], lr: 0.001076, loss: 0.4204
2022-09-22 00:28:07 - train: epoch 0035, iter [01090, 01251], lr: 0.001076, loss: 0.4252
2022-09-22 00:28:28 - train: epoch 0035, iter [01100, 01251], lr: 0.001076, loss: 0.4213
2022-09-22 00:28:48 - train: epoch 0035, iter [01110, 01251], lr: 0.001077, loss: 0.4110
2022-09-22 00:29:09 - train: epoch 0035, iter [01120, 01251], lr: 0.001077, loss: 0.4108
2022-09-22 00:29:30 - train: epoch 0035, iter [01130, 01251], lr: 0.001077, loss: 0.4348
2022-09-22 00:29:50 - train: epoch 0035, iter [01140, 01251], lr: 0.001077, loss: 0.4285
2022-09-22 00:30:11 - train: epoch 0035, iter [01150, 01251], lr: 0.001078, loss: 0.4432
2022-09-22 00:30:32 - train: epoch 0035, iter [01160, 01251], lr: 0.001078, loss: 0.4157
2022-09-22 00:30:52 - train: epoch 0035, iter [01170, 01251], lr: 0.001078, loss: 0.4036
2022-09-22 00:31:13 - train: epoch 0035, iter [01180, 01251], lr: 0.001078, loss: 0.4261
2022-09-22 00:31:34 - train: epoch 0035, iter [01190, 01251], lr: 0.001079, loss: 0.4436
2022-09-22 00:31:54 - train: epoch 0035, iter [01200, 01251], lr: 0.001079, loss: 0.4298
2022-09-22 00:32:15 - train: epoch 0035, iter [01210, 01251], lr: 0.001079, loss: 0.4234
2022-09-22 00:32:36 - train: epoch 0035, iter [01220, 01251], lr: 0.001079, loss: 0.4174
2022-09-22 00:32:56 - train: epoch 0035, iter [01230, 01251], lr: 0.001079, loss: 0.4243
2022-09-22 00:33:17 - train: epoch 0035, iter [01240, 01251], lr: 0.001080, loss: 0.4313
2022-09-22 00:33:37 - train: epoch 0035, iter [01250, 01251], lr: 0.001080, loss: 0.4381
2022-09-22 00:33:41 - train: epoch 035, train_loss: 0.4227
2022-09-22 00:33:45 - until epoch: 035, best_loss: 0.4227
2022-09-22 00:33:45 - epoch 036 lr: 0.001080
2022-09-22 00:34:23 - train: epoch 0036, iter [00010, 01251], lr: 0.001080, loss: 0.4328
2022-09-22 00:34:43 - train: epoch 0036, iter [00020, 01251], lr: 0.001080, loss: 0.4298
2022-09-22 00:35:04 - train: epoch 0036, iter [00030, 01251], lr: 0.001081, loss: 0.4139
2022-09-22 00:35:24 - train: epoch 0036, iter [00040, 01251], lr: 0.001081, loss: 0.4475
2022-09-22 00:35:45 - train: epoch 0036, iter [00050, 01251], lr: 0.001081, loss: 0.4080
2022-09-22 00:36:05 - train: epoch 0036, iter [00060, 01251], lr: 0.001081, loss: 0.4271
2022-09-22 00:36:26 - train: epoch 0036, iter [00070, 01251], lr: 0.001082, loss: 0.4096
2022-09-22 00:36:46 - train: epoch 0036, iter [00080, 01251], lr: 0.001082, loss: 0.3893
2022-09-22 00:37:07 - train: epoch 0036, iter [00090, 01251], lr: 0.001082, loss: 0.4145
2022-09-22 00:37:27 - train: epoch 0036, iter [00100, 01251], lr: 0.001082, loss: 0.4121
2022-09-22 00:37:48 - train: epoch 0036, iter [00110, 01251], lr: 0.001083, loss: 0.4205
2022-09-22 00:38:08 - train: epoch 0036, iter [00120, 01251], lr: 0.001083, loss: 0.4245
2022-09-22 00:38:29 - train: epoch 0036, iter [00130, 01251], lr: 0.001083, loss: 0.4268
2022-09-22 00:38:49 - train: epoch 0036, iter [00140, 01251], lr: 0.001083, loss: 0.4208
2022-09-22 00:39:10 - train: epoch 0036, iter [00150, 01251], lr: 0.001084, loss: 0.4321
2022-09-22 00:39:30 - train: epoch 0036, iter [00160, 01251], lr: 0.001084, loss: 0.4478
2022-09-22 00:39:51 - train: epoch 0036, iter [00170, 01251], lr: 0.001084, loss: 0.4212
2022-09-22 00:40:11 - train: epoch 0036, iter [00180, 01251], lr: 0.001084, loss: 0.4354
2022-09-22 00:40:32 - train: epoch 0036, iter [00190, 01251], lr: 0.001085, loss: 0.4160
2022-09-22 00:40:52 - train: epoch 0036, iter [00200, 01251], lr: 0.001085, loss: 0.4369
2022-09-22 00:41:13 - train: epoch 0036, iter [00210, 01251], lr: 0.001085, loss: 0.4176
2022-09-22 00:41:33 - train: epoch 0036, iter [00220, 01251], lr: 0.001085, loss: 0.4424
2022-09-22 00:41:54 - train: epoch 0036, iter [00230, 01251], lr: 0.001086, loss: 0.4156
2022-09-22 00:42:14 - train: epoch 0036, iter [00240, 01251], lr: 0.001086, loss: 0.4364
2022-09-22 00:42:35 - train: epoch 0036, iter [00250, 01251], lr: 0.001086, loss: 0.4157
2022-09-22 00:42:56 - train: epoch 0036, iter [00260, 01251], lr: 0.001086, loss: 0.4397
2022-09-22 00:43:16 - train: epoch 0036, iter [00270, 01251], lr: 0.001086, loss: 0.4188
2022-09-22 00:43:37 - train: epoch 0036, iter [00280, 01251], lr: 0.001087, loss: 0.4219
2022-09-22 00:43:57 - train: epoch 0036, iter [00290, 01251], lr: 0.001087, loss: 0.4285
2022-09-22 00:44:18 - train: epoch 0036, iter [00300, 01251], lr: 0.001087, loss: 0.4237
2022-09-22 00:44:38 - train: epoch 0036, iter [00310, 01251], lr: 0.001087, loss: 0.4255
2022-09-22 00:44:59 - train: epoch 0036, iter [00320, 01251], lr: 0.001088, loss: 0.4141
2022-09-22 00:45:19 - train: epoch 0036, iter [00330, 01251], lr: 0.001088, loss: 0.4020
2022-09-22 00:45:40 - train: epoch 0036, iter [00340, 01251], lr: 0.001088, loss: 0.4367
2022-09-22 00:46:00 - train: epoch 0036, iter [00350, 01251], lr: 0.001088, loss: 0.4151
2022-09-22 00:46:21 - train: epoch 0036, iter [00360, 01251], lr: 0.001089, loss: 0.4320
2022-09-22 00:46:41 - train: epoch 0036, iter [00370, 01251], lr: 0.001089, loss: 0.4247
2022-09-22 00:47:02 - train: epoch 0036, iter [00380, 01251], lr: 0.001089, loss: 0.4181
2022-09-22 00:47:23 - train: epoch 0036, iter [00390, 01251], lr: 0.001089, loss: 0.4423
2022-09-22 00:47:44 - train: epoch 0036, iter [00400, 01251], lr: 0.001090, loss: 0.4226
2022-09-22 00:48:04 - train: epoch 0036, iter [00410, 01251], lr: 0.001090, loss: 0.4240
2022-09-22 00:48:25 - train: epoch 0036, iter [00420, 01251], lr: 0.001090, loss: 0.4286
2022-09-22 00:48:45 - train: epoch 0036, iter [00430, 01251], lr: 0.001090, loss: 0.4079
2022-09-22 00:49:06 - train: epoch 0036, iter [00440, 01251], lr: 0.001091, loss: 0.4362
2022-09-22 00:49:26 - train: epoch 0036, iter [00450, 01251], lr: 0.001091, loss: 0.4254
2022-09-22 00:49:47 - train: epoch 0036, iter [00460, 01251], lr: 0.001091, loss: 0.4165
2022-09-22 00:50:07 - train: epoch 0036, iter [00470, 01251], lr: 0.001091, loss: 0.4166
2022-09-22 00:50:28 - train: epoch 0036, iter [00480, 01251], lr: 0.001092, loss: 0.4107
2022-09-22 00:50:49 - train: epoch 0036, iter [00490, 01251], lr: 0.001092, loss: 0.4433
2022-09-22 00:51:09 - train: epoch 0036, iter [00500, 01251], lr: 0.001092, loss: 0.4336
2022-09-22 00:51:30 - train: epoch 0036, iter [00510, 01251], lr: 0.001092, loss: 0.4213
2022-09-22 00:51:50 - train: epoch 0036, iter [00520, 01251], lr: 0.001092, loss: 0.4178
2022-09-22 00:52:11 - train: epoch 0036, iter [00530, 01251], lr: 0.001093, loss: 0.4198
2022-09-22 00:52:32 - train: epoch 0036, iter [00540, 01251], lr: 0.001093, loss: 0.4231
2022-09-22 00:52:52 - train: epoch 0036, iter [00550, 01251], lr: 0.001093, loss: 0.4120
2022-09-22 00:53:13 - train: epoch 0036, iter [00560, 01251], lr: 0.001093, loss: 0.4284
2022-09-22 00:53:33 - train: epoch 0036, iter [00570, 01251], lr: 0.001094, loss: 0.4268
2022-09-22 00:53:54 - train: epoch 0036, iter [00580, 01251], lr: 0.001094, loss: 0.4456
2022-09-22 00:54:14 - train: epoch 0036, iter [00590, 01251], lr: 0.001094, loss: 0.4264
2022-09-22 00:54:35 - train: epoch 0036, iter [00600, 01251], lr: 0.001094, loss: 0.4244
2022-09-22 00:54:56 - train: epoch 0036, iter [00610, 01251], lr: 0.001095, loss: 0.4099
2022-09-22 00:55:16 - train: epoch 0036, iter [00620, 01251], lr: 0.001095, loss: 0.4107
2022-09-22 00:55:37 - train: epoch 0036, iter [00630, 01251], lr: 0.001095, loss: 0.4163
2022-09-22 00:55:57 - train: epoch 0036, iter [00640, 01251], lr: 0.001095, loss: 0.4233
2022-09-22 00:56:18 - train: epoch 0036, iter [00650, 01251], lr: 0.001096, loss: 0.4147
2022-09-22 00:56:39 - train: epoch 0036, iter [00660, 01251], lr: 0.001096, loss: 0.4292
2022-09-22 00:56:59 - train: epoch 0036, iter [00670, 01251], lr: 0.001096, loss: 0.4325
2022-09-22 00:57:20 - train: epoch 0036, iter [00680, 01251], lr: 0.001096, loss: 0.4262
2022-09-22 00:57:40 - train: epoch 0036, iter [00690, 01251], lr: 0.001097, loss: 0.4554
2022-09-22 00:58:01 - train: epoch 0036, iter [00700, 01251], lr: 0.001097, loss: 0.4047
2022-09-22 00:58:21 - train: epoch 0036, iter [00710, 01251], lr: 0.001097, loss: 0.4211
2022-09-22 00:58:42 - train: epoch 0036, iter [00720, 01251], lr: 0.001097, loss: 0.4188
2022-09-22 00:59:03 - train: epoch 0036, iter [00730, 01251], lr: 0.001098, loss: 0.4281
2022-09-22 00:59:23 - train: epoch 0036, iter [00740, 01251], lr: 0.001098, loss: 0.4378
2022-09-22 00:59:44 - train: epoch 0036, iter [00750, 01251], lr: 0.001098, loss: 0.4439
2022-09-22 01:00:04 - train: epoch 0036, iter [00760, 01251], lr: 0.001098, loss: 0.4150
2022-09-22 01:00:25 - train: epoch 0036, iter [00770, 01251], lr: 0.001098, loss: 0.4221
2022-09-22 01:00:46 - train: epoch 0036, iter [00780, 01251], lr: 0.001099, loss: 0.4115
2022-09-22 01:01:06 - train: epoch 0036, iter [00790, 01251], lr: 0.001099, loss: 0.4110
2022-09-22 01:01:27 - train: epoch 0036, iter [00800, 01251], lr: 0.001099, loss: 0.4073
2022-09-22 01:01:48 - train: epoch 0036, iter [00810, 01251], lr: 0.001099, loss: 0.4215
2022-09-22 01:02:08 - train: epoch 0036, iter [00820, 01251], lr: 0.001100, loss: 0.4119
2022-09-22 01:02:29 - train: epoch 0036, iter [00830, 01251], lr: 0.001100, loss: 0.4040
2022-09-22 01:02:49 - train: epoch 0036, iter [00840, 01251], lr: 0.001100, loss: 0.4320
2022-09-22 01:03:10 - train: epoch 0036, iter [00850, 01251], lr: 0.001100, loss: 0.4323
2022-09-22 01:03:30 - train: epoch 0036, iter [00860, 01251], lr: 0.001101, loss: 0.4125
2022-09-22 01:03:51 - train: epoch 0036, iter [00870, 01251], lr: 0.001101, loss: 0.4370
2022-09-22 01:04:11 - train: epoch 0036, iter [00880, 01251], lr: 0.001101, loss: 0.4322
2022-09-22 01:04:32 - train: epoch 0036, iter [00890, 01251], lr: 0.001101, loss: 0.4087
2022-09-22 01:04:53 - train: epoch 0036, iter [00900, 01251], lr: 0.001102, loss: 0.4234
2022-09-22 01:05:13 - train: epoch 0036, iter [00910, 01251], lr: 0.001102, loss: 0.4301
2022-09-22 01:05:34 - train: epoch 0036, iter [00920, 01251], lr: 0.001102, loss: 0.3964
2022-09-22 01:05:54 - train: epoch 0036, iter [00930, 01251], lr: 0.001102, loss: 0.4203
2022-09-22 01:06:15 - train: epoch 0036, iter [00940, 01251], lr: 0.001103, loss: 0.4280
2022-09-22 01:06:36 - train: epoch 0036, iter [00950, 01251], lr: 0.001103, loss: 0.4444
2022-09-22 01:06:56 - train: epoch 0036, iter [00960, 01251], lr: 0.001103, loss: 0.4202
2022-09-22 01:07:17 - train: epoch 0036, iter [00970, 01251], lr: 0.001103, loss: 0.4138
2022-09-22 01:07:37 - train: epoch 0036, iter [00980, 01251], lr: 0.001104, loss: 0.4200
2022-09-22 01:07:58 - train: epoch 0036, iter [00990, 01251], lr: 0.001104, loss: 0.4275
2022-09-22 01:08:19 - train: epoch 0036, iter [01000, 01251], lr: 0.001104, loss: 0.4076
2022-09-22 01:08:39 - train: epoch 0036, iter [01010, 01251], lr: 0.001104, loss: 0.4295
2022-09-22 01:09:00 - train: epoch 0036, iter [01020, 01251], lr: 0.001104, loss: 0.4104
2022-09-22 01:09:20 - train: epoch 0036, iter [01030, 01251], lr: 0.001105, loss: 0.4121
2022-09-22 01:09:41 - train: epoch 0036, iter [01040, 01251], lr: 0.001105, loss: 0.4238
2022-09-22 01:10:02 - train: epoch 0036, iter [01050, 01251], lr: 0.001105, loss: 0.4089
2022-09-22 01:10:22 - train: epoch 0036, iter [01060, 01251], lr: 0.001105, loss: 0.4126
2022-09-22 01:10:43 - train: epoch 0036, iter [01070, 01251], lr: 0.001106, loss: 0.4344
2022-09-22 01:11:04 - train: epoch 0036, iter [01080, 01251], lr: 0.001106, loss: 0.4221
2022-09-22 01:11:24 - train: epoch 0036, iter [01090, 01251], lr: 0.001106, loss: 0.4359
2022-09-22 01:11:45 - train: epoch 0036, iter [01100, 01251], lr: 0.001106, loss: 0.4119
2022-09-22 01:12:06 - train: epoch 0036, iter [01110, 01251], lr: 0.001107, loss: 0.4251
2022-09-22 01:12:26 - train: epoch 0036, iter [01120, 01251], lr: 0.001107, loss: 0.4280
2022-09-22 01:12:47 - train: epoch 0036, iter [01130, 01251], lr: 0.001107, loss: 0.3976
2022-09-22 01:13:08 - train: epoch 0036, iter [01140, 01251], lr: 0.001107, loss: 0.4275
2022-09-22 01:13:28 - train: epoch 0036, iter [01150, 01251], lr: 0.001108, loss: 0.4313
2022-09-22 01:13:49 - train: epoch 0036, iter [01160, 01251], lr: 0.001108, loss: 0.3997
2022-09-22 01:14:10 - train: epoch 0036, iter [01170, 01251], lr: 0.001108, loss: 0.4353
2022-09-22 01:14:30 - train: epoch 0036, iter [01180, 01251], lr: 0.001108, loss: 0.4265
2022-09-22 01:14:51 - train: epoch 0036, iter [01190, 01251], lr: 0.001109, loss: 0.4187
2022-09-22 01:15:12 - train: epoch 0036, iter [01200, 01251], lr: 0.001109, loss: 0.4287
2022-09-22 01:15:32 - train: epoch 0036, iter [01210, 01251], lr: 0.001109, loss: 0.4174
2022-09-22 01:15:53 - train: epoch 0036, iter [01220, 01251], lr: 0.001109, loss: 0.4082
2022-09-22 01:16:14 - train: epoch 0036, iter [01230, 01251], lr: 0.001109, loss: 0.4323
2022-09-22 01:16:34 - train: epoch 0036, iter [01240, 01251], lr: 0.001110, loss: 0.4360
2022-09-22 01:16:54 - train: epoch 0036, iter [01250, 01251], lr: 0.001110, loss: 0.4221
2022-09-22 01:16:58 - train: epoch 036, train_loss: 0.4224
2022-09-22 01:17:03 - until epoch: 036, best_loss: 0.4224
2022-09-22 01:17:03 - epoch 037 lr: 0.001110
2022-09-22 01:17:41 - train: epoch 0037, iter [00010, 01251], lr: 0.001110, loss: 0.4430
2022-09-22 01:18:01 - train: epoch 0037, iter [00020, 01251], lr: 0.001110, loss: 0.4187
2022-09-22 01:18:22 - train: epoch 0037, iter [00030, 01251], lr: 0.001111, loss: 0.4321
2022-09-22 01:18:42 - train: epoch 0037, iter [00040, 01251], lr: 0.001111, loss: 0.4297
2022-09-22 01:19:03 - train: epoch 0037, iter [00050, 01251], lr: 0.001111, loss: 0.4283
2022-09-22 01:19:23 - train: epoch 0037, iter [00060, 01251], lr: 0.001111, loss: 0.4127
2022-09-22 01:19:44 - train: epoch 0037, iter [00070, 01251], lr: 0.001112, loss: 0.4205
2022-09-22 01:20:05 - train: epoch 0037, iter [00080, 01251], lr: 0.001112, loss: 0.4429
2022-09-22 01:20:25 - train: epoch 0037, iter [00090, 01251], lr: 0.001112, loss: 0.4189
2022-09-22 01:20:46 - train: epoch 0037, iter [00100, 01251], lr: 0.001112, loss: 0.4186
2022-09-22 01:21:06 - train: epoch 0037, iter [00110, 01251], lr: 0.001113, loss: 0.4248
2022-09-22 01:21:27 - train: epoch 0037, iter [00120, 01251], lr: 0.001113, loss: 0.4394
2022-09-22 01:21:47 - train: epoch 0037, iter [00130, 01251], lr: 0.001113, loss: 0.4358
2022-09-22 01:22:08 - train: epoch 0037, iter [00140, 01251], lr: 0.001113, loss: 0.4456
2022-09-22 01:22:29 - train: epoch 0037, iter [00150, 01251], lr: 0.001114, loss: 0.4325
2022-09-22 01:22:49 - train: epoch 0037, iter [00160, 01251], lr: 0.001114, loss: 0.4384
2022-09-22 01:23:10 - train: epoch 0037, iter [00170, 01251], lr: 0.001114, loss: 0.4257
2022-09-22 01:23:30 - train: epoch 0037, iter [00180, 01251], lr: 0.001114, loss: 0.4127
2022-09-22 01:23:51 - train: epoch 0037, iter [00190, 01251], lr: 0.001115, loss: 0.4300
2022-09-22 01:24:12 - train: epoch 0037, iter [00200, 01251], lr: 0.001115, loss: 0.4286
2022-09-22 01:24:33 - train: epoch 0037, iter [00210, 01251], lr: 0.001115, loss: 0.4171
2022-09-22 01:24:53 - train: epoch 0037, iter [00220, 01251], lr: 0.001115, loss: 0.4375
2022-09-22 01:25:14 - train: epoch 0037, iter [00230, 01251], lr: 0.001116, loss: 0.4135
2022-09-22 01:25:34 - train: epoch 0037, iter [00240, 01251], lr: 0.001116, loss: 0.4036
2022-09-22 01:25:55 - train: epoch 0037, iter [00250, 01251], lr: 0.001116, loss: 0.4378
2022-09-22 01:26:16 - train: epoch 0037, iter [00260, 01251], lr: 0.001116, loss: 0.4140
2022-09-22 01:26:36 - train: epoch 0037, iter [00270, 01251], lr: 0.001116, loss: 0.4183
2022-09-22 01:26:57 - train: epoch 0037, iter [00280, 01251], lr: 0.001117, loss: 0.4429
2022-09-22 01:27:17 - train: epoch 0037, iter [00290, 01251], lr: 0.001117, loss: 0.4115
2022-09-22 01:27:38 - train: epoch 0037, iter [00300, 01251], lr: 0.001117, loss: 0.4140
2022-09-22 01:27:59 - train: epoch 0037, iter [00310, 01251], lr: 0.001117, loss: 0.4137
2022-09-22 01:28:20 - train: epoch 0037, iter [00320, 01251], lr: 0.001118, loss: 0.4409
2022-09-22 01:28:40 - train: epoch 0037, iter [00330, 01251], lr: 0.001118, loss: 0.4215
2022-09-22 01:29:01 - train: epoch 0037, iter [00340, 01251], lr: 0.001118, loss: 0.4277
2022-09-22 01:29:22 - train: epoch 0037, iter [00350, 01251], lr: 0.001118, loss: 0.4182
2022-09-22 01:29:43 - train: epoch 0037, iter [00360, 01251], lr: 0.001119, loss: 0.4200
2022-09-22 01:30:03 - train: epoch 0037, iter [00370, 01251], lr: 0.001119, loss: 0.4229
2022-09-22 01:30:24 - train: epoch 0037, iter [00380, 01251], lr: 0.001119, loss: 0.4296
2022-09-22 01:30:44 - train: epoch 0037, iter [00390, 01251], lr: 0.001119, loss: 0.3958
2022-09-22 01:31:05 - train: epoch 0037, iter [00400, 01251], lr: 0.001120, loss: 0.4331
2022-09-22 01:31:26 - train: epoch 0037, iter [00410, 01251], lr: 0.001120, loss: 0.4283
2022-09-22 01:31:46 - train: epoch 0037, iter [00420, 01251], lr: 0.001120, loss: 0.4256
2022-09-22 01:32:07 - train: epoch 0037, iter [00430, 01251], lr: 0.001120, loss: 0.4210
2022-09-22 01:32:27 - train: epoch 0037, iter [00440, 01251], lr: 0.001121, loss: 0.4256
2022-09-22 01:32:48 - train: epoch 0037, iter [00450, 01251], lr: 0.001121, loss: 0.3983
2022-09-22 01:33:09 - train: epoch 0037, iter [00460, 01251], lr: 0.001121, loss: 0.4229
2022-09-22 01:33:29 - train: epoch 0037, iter [00470, 01251], lr: 0.001121, loss: 0.4290
2022-09-22 01:33:50 - train: epoch 0037, iter [00480, 01251], lr: 0.001122, loss: 0.4224
2022-09-22 01:34:11 - train: epoch 0037, iter [00490, 01251], lr: 0.001122, loss: 0.4341
2022-09-22 01:34:32 - train: epoch 0037, iter [00500, 01251], lr: 0.001122, loss: 0.4251
2022-09-22 01:34:52 - train: epoch 0037, iter [00510, 01251], lr: 0.001122, loss: 0.4307
2022-09-22 01:35:13 - train: epoch 0037, iter [00520, 01251], lr: 0.001122, loss: 0.4483
2022-09-22 01:35:33 - train: epoch 0037, iter [00530, 01251], lr: 0.001123, loss: 0.4222
2022-09-22 01:35:54 - train: epoch 0037, iter [00540, 01251], lr: 0.001123, loss: 0.4132
2022-09-22 01:36:15 - train: epoch 0037, iter [00550, 01251], lr: 0.001123, loss: 0.4254
2022-09-22 01:36:36 - train: epoch 0037, iter [00560, 01251], lr: 0.001123, loss: 0.4170
2022-09-22 01:36:57 - train: epoch 0037, iter [00570, 01251], lr: 0.001124, loss: 0.4226
2022-09-22 01:37:17 - train: epoch 0037, iter [00580, 01251], lr: 0.001124, loss: 0.4277
2022-09-22 01:37:38 - train: epoch 0037, iter [00590, 01251], lr: 0.001124, loss: 0.4321
2022-09-22 01:37:59 - train: epoch 0037, iter [00600, 01251], lr: 0.001124, loss: 0.4179
2022-09-22 01:38:19 - train: epoch 0037, iter [00610, 01251], lr: 0.001125, loss: 0.4046
2022-09-22 01:38:40 - train: epoch 0037, iter [00620, 01251], lr: 0.001125, loss: 0.4191
2022-09-22 01:39:01 - train: epoch 0037, iter [00630, 01251], lr: 0.001125, loss: 0.4169
2022-09-22 01:39:21 - train: epoch 0037, iter [00640, 01251], lr: 0.001125, loss: 0.4054
2022-09-22 01:39:42 - train: epoch 0037, iter [00650, 01251], lr: 0.001126, loss: 0.4233
2022-09-22 01:40:03 - train: epoch 0037, iter [00660, 01251], lr: 0.001126, loss: 0.4147
2022-09-22 01:40:23 - train: epoch 0037, iter [00670, 01251], lr: 0.001126, loss: 0.4208
2022-09-22 01:40:44 - train: epoch 0037, iter [00680, 01251], lr: 0.001126, loss: 0.4196
2022-09-22 01:41:05 - train: epoch 0037, iter [00690, 01251], lr: 0.001127, loss: 0.4354
2022-09-22 01:41:26 - train: epoch 0037, iter [00700, 01251], lr: 0.001127, loss: 0.4160
2022-09-22 01:41:46 - train: epoch 0037, iter [00710, 01251], lr: 0.001127, loss: 0.4170
2022-09-22 01:42:07 - train: epoch 0037, iter [00720, 01251], lr: 0.001127, loss: 0.4114
2022-09-22 01:42:28 - train: epoch 0037, iter [00730, 01251], lr: 0.001128, loss: 0.4361
2022-09-22 01:42:49 - train: epoch 0037, iter [00740, 01251], lr: 0.001128, loss: 0.4178
2022-09-22 01:43:09 - train: epoch 0037, iter [00750, 01251], lr: 0.001128, loss: 0.4021
2022-09-22 01:43:30 - train: epoch 0037, iter [00760, 01251], lr: 0.001128, loss: 0.4235
2022-09-22 01:43:51 - train: epoch 0037, iter [00770, 01251], lr: 0.001128, loss: 0.4283
2022-09-22 01:44:12 - train: epoch 0037, iter [00780, 01251], lr: 0.001129, loss: 0.4284
2022-09-22 01:44:32 - train: epoch 0037, iter [00790, 01251], lr: 0.001129, loss: 0.4130
2022-09-22 01:44:53 - train: epoch 0037, iter [00800, 01251], lr: 0.001129, loss: 0.4189
2022-09-22 01:45:14 - train: epoch 0037, iter [00810, 01251], lr: 0.001129, loss: 0.4106
2022-09-22 01:45:35 - train: epoch 0037, iter [00820, 01251], lr: 0.001130, loss: 0.4138
2022-09-22 01:45:56 - train: epoch 0037, iter [00830, 01251], lr: 0.001130, loss: 0.4403
2022-09-22 01:46:16 - train: epoch 0037, iter [00840, 01251], lr: 0.001130, loss: 0.4174
2022-09-22 01:46:37 - train: epoch 0037, iter [00850, 01251], lr: 0.001130, loss: 0.4072
2022-09-22 01:46:58 - train: epoch 0037, iter [00860, 01251], lr: 0.001131, loss: 0.4119
2022-09-22 01:47:19 - train: epoch 0037, iter [00870, 01251], lr: 0.001131, loss: 0.4271
2022-09-22 01:47:39 - train: epoch 0037, iter [00880, 01251], lr: 0.001131, loss: 0.4130
2022-09-22 01:48:00 - train: epoch 0037, iter [00890, 01251], lr: 0.001131, loss: 0.4063
2022-09-22 01:48:21 - train: epoch 0037, iter [00900, 01251], lr: 0.001132, loss: 0.4195
2022-09-22 01:48:42 - train: epoch 0037, iter [00910, 01251], lr: 0.001132, loss: 0.4226
2022-09-22 01:49:02 - train: epoch 0037, iter [00920, 01251], lr: 0.001132, loss: 0.4063
2022-09-22 01:49:23 - train: epoch 0037, iter [00930, 01251], lr: 0.001132, loss: 0.4014
2022-09-22 01:49:44 - train: epoch 0037, iter [00940, 01251], lr: 0.001133, loss: 0.4175
2022-09-22 01:50:05 - train: epoch 0037, iter [00950, 01251], lr: 0.001133, loss: 0.4408
2022-09-22 01:50:26 - train: epoch 0037, iter [00960, 01251], lr: 0.001133, loss: 0.4156
2022-09-22 01:50:47 - train: epoch 0037, iter [00970, 01251], lr: 0.001133, loss: 0.4221
2022-09-22 01:51:07 - train: epoch 0037, iter [00980, 01251], lr: 0.001134, loss: 0.4243
2022-09-22 01:51:28 - train: epoch 0037, iter [00990, 01251], lr: 0.001134, loss: 0.4170
2022-09-22 01:51:48 - train: epoch 0037, iter [01000, 01251], lr: 0.001134, loss: 0.4300
2022-09-22 01:52:09 - train: epoch 0037, iter [01010, 01251], lr: 0.001134, loss: 0.4313
2022-09-22 01:52:30 - train: epoch 0037, iter [01020, 01251], lr: 0.001134, loss: 0.4073
2022-09-22 01:52:50 - train: epoch 0037, iter [01030, 01251], lr: 0.001135, loss: 0.4296
2022-09-22 01:53:11 - train: epoch 0037, iter [01040, 01251], lr: 0.001135, loss: 0.4075
2022-09-22 01:53:32 - train: epoch 0037, iter [01050, 01251], lr: 0.001135, loss: 0.4058
2022-09-22 01:53:52 - train: epoch 0037, iter [01060, 01251], lr: 0.001135, loss: 0.4301
2022-09-22 01:54:13 - train: epoch 0037, iter [01070, 01251], lr: 0.001136, loss: 0.3985
2022-09-22 01:54:34 - train: epoch 0037, iter [01080, 01251], lr: 0.001136, loss: 0.4190
2022-09-22 01:54:54 - train: epoch 0037, iter [01090, 01251], lr: 0.001136, loss: 0.4239
2022-09-22 01:55:15 - train: epoch 0037, iter [01100, 01251], lr: 0.001136, loss: 0.4294
2022-09-22 01:55:36 - train: epoch 0037, iter [01110, 01251], lr: 0.001137, loss: 0.4403
2022-09-22 01:55:57 - train: epoch 0037, iter [01120, 01251], lr: 0.001137, loss: 0.4375
2022-09-22 01:56:17 - train: epoch 0037, iter [01130, 01251], lr: 0.001137, loss: 0.4263
2022-09-22 01:56:38 - train: epoch 0037, iter [01140, 01251], lr: 0.001137, loss: 0.4209
2022-09-22 01:56:59 - train: epoch 0037, iter [01150, 01251], lr: 0.001138, loss: 0.4263
2022-09-22 01:57:20 - train: epoch 0037, iter [01160, 01251], lr: 0.001138, loss: 0.4199
2022-09-22 01:57:40 - train: epoch 0037, iter [01170, 01251], lr: 0.001138, loss: 0.4147
2022-09-22 01:58:01 - train: epoch 0037, iter [01180, 01251], lr: 0.001138, loss: 0.4277
2022-09-22 01:58:22 - train: epoch 0037, iter [01190, 01251], lr: 0.001139, loss: 0.4178
2022-09-22 01:58:42 - train: epoch 0037, iter [01200, 01251], lr: 0.001139, loss: 0.4260
2022-09-22 01:59:03 - train: epoch 0037, iter [01210, 01251], lr: 0.001139, loss: 0.4245
2022-09-22 01:59:24 - train: epoch 0037, iter [01220, 01251], lr: 0.001139, loss: 0.4378
2022-09-22 01:59:45 - train: epoch 0037, iter [01230, 01251], lr: 0.001139, loss: 0.4327
2022-09-22 02:00:05 - train: epoch 0037, iter [01240, 01251], lr: 0.001140, loss: 0.3982
2022-09-22 02:00:25 - train: epoch 0037, iter [01250, 01251], lr: 0.001140, loss: 0.3995
2022-09-22 02:00:29 - train: epoch 037, train_loss: 0.4222
2022-09-22 02:00:34 - until epoch: 037, best_loss: 0.4222
2022-09-22 02:00:34 - epoch 038 lr: 0.001140
2022-09-22 02:01:12 - train: epoch 0038, iter [00010, 01251], lr: 0.001140, loss: 0.4257
2022-09-22 02:01:33 - train: epoch 0038, iter [00020, 01251], lr: 0.001140, loss: 0.4045
2022-09-22 02:01:53 - train: epoch 0038, iter [00030, 01251], lr: 0.001141, loss: 0.4051
2022-09-22 02:02:14 - train: epoch 0038, iter [00040, 01251], lr: 0.001141, loss: 0.4206
2022-09-22 02:02:35 - train: epoch 0038, iter [00050, 01251], lr: 0.001141, loss: 0.4300
2022-09-22 02:02:56 - train: epoch 0038, iter [00060, 01251], lr: 0.001141, loss: 0.4151
2022-09-22 02:03:16 - train: epoch 0038, iter [00070, 01251], lr: 0.001142, loss: 0.4472
2022-09-22 02:03:37 - train: epoch 0038, iter [00080, 01251], lr: 0.001142, loss: 0.4371
2022-09-22 02:03:58 - train: epoch 0038, iter [00090, 01251], lr: 0.001142, loss: 0.4376
2022-09-22 02:04:19 - train: epoch 0038, iter [00100, 01251], lr: 0.001142, loss: 0.4268
2022-09-22 02:04:39 - train: epoch 0038, iter [00110, 01251], lr: 0.001143, loss: 0.4242
2022-09-22 02:05:00 - train: epoch 0038, iter [00120, 01251], lr: 0.001143, loss: 0.4320
2022-09-22 02:05:21 - train: epoch 0038, iter [00130, 01251], lr: 0.001143, loss: 0.4091
2022-09-22 02:05:41 - train: epoch 0038, iter [00140, 01251], lr: 0.001143, loss: 0.4115
2022-09-22 02:06:02 - train: epoch 0038, iter [00150, 01251], lr: 0.001144, loss: 0.4082
2022-09-22 02:06:23 - train: epoch 0038, iter [00160, 01251], lr: 0.001144, loss: 0.4174
2022-09-22 02:06:43 - train: epoch 0038, iter [00170, 01251], lr: 0.001144, loss: 0.4291
2022-09-22 02:07:04 - train: epoch 0038, iter [00180, 01251], lr: 0.001144, loss: 0.4266
2022-09-22 02:07:25 - train: epoch 0038, iter [00190, 01251], lr: 0.001145, loss: 0.4147
2022-09-22 02:07:45 - train: epoch 0038, iter [00200, 01251], lr: 0.001145, loss: 0.4155
2022-09-22 02:08:06 - train: epoch 0038, iter [00210, 01251], lr: 0.001145, loss: 0.4268
2022-09-22 02:08:27 - train: epoch 0038, iter [00220, 01251], lr: 0.001145, loss: 0.4164
2022-09-22 02:08:47 - train: epoch 0038, iter [00230, 01251], lr: 0.001146, loss: 0.4311
2022-09-22 02:09:08 - train: epoch 0038, iter [00240, 01251], lr: 0.001146, loss: 0.4269
2022-09-22 02:09:29 - train: epoch 0038, iter [00250, 01251], lr: 0.001146, loss: 0.4365
2022-09-22 02:09:49 - train: epoch 0038, iter [00260, 01251], lr: 0.001146, loss: 0.4165
2022-09-22 02:10:10 - train: epoch 0038, iter [00270, 01251], lr: 0.001146, loss: 0.4227
2022-09-22 02:10:31 - train: epoch 0038, iter [00280, 01251], lr: 0.001147, loss: 0.4170
2022-09-22 02:10:52 - train: epoch 0038, iter [00290, 01251], lr: 0.001147, loss: 0.4068
2022-09-22 02:11:12 - train: epoch 0038, iter [00300, 01251], lr: 0.001147, loss: 0.4341
2022-09-22 02:11:33 - train: epoch 0038, iter [00310, 01251], lr: 0.001147, loss: 0.4453
2022-09-22 02:11:54 - train: epoch 0038, iter [00320, 01251], lr: 0.001148, loss: 0.4177
2022-09-22 02:12:14 - train: epoch 0038, iter [00330, 01251], lr: 0.001148, loss: 0.4285
2022-09-22 02:12:35 - train: epoch 0038, iter [00340, 01251], lr: 0.001148, loss: 0.4371
2022-09-22 02:12:56 - train: epoch 0038, iter [00350, 01251], lr: 0.001148, loss: 0.4287
2022-09-22 02:13:17 - train: epoch 0038, iter [00360, 01251], lr: 0.001149, loss: 0.4160
2022-09-22 02:13:37 - train: epoch 0038, iter [00370, 01251], lr: 0.001149, loss: 0.4108
2022-09-22 02:13:58 - train: epoch 0038, iter [00380, 01251], lr: 0.001149, loss: 0.4313
2022-09-22 02:14:19 - train: epoch 0038, iter [00390, 01251], lr: 0.001149, loss: 0.3992
2022-09-22 02:14:40 - train: epoch 0038, iter [00400, 01251], lr: 0.001150, loss: 0.4153
2022-09-22 02:15:00 - train: epoch 0038, iter [00410, 01251], lr: 0.001150, loss: 0.4304
2022-09-22 02:15:21 - train: epoch 0038, iter [00420, 01251], lr: 0.001150, loss: 0.4184
2022-09-22 02:15:42 - train: epoch 0038, iter [00430, 01251], lr: 0.001150, loss: 0.4078
2022-09-22 02:16:03 - train: epoch 0038, iter [00440, 01251], lr: 0.001151, loss: 0.4219
2022-09-22 02:16:23 - train: epoch 0038, iter [00450, 01251], lr: 0.001151, loss: 0.4265
2022-09-22 02:16:44 - train: epoch 0038, iter [00460, 01251], lr: 0.001151, loss: 0.4217
2022-09-22 02:17:05 - train: epoch 0038, iter [00470, 01251], lr: 0.001151, loss: 0.4174
2022-09-22 02:17:26 - train: epoch 0038, iter [00480, 01251], lr: 0.001152, loss: 0.4129
2022-09-22 02:17:46 - train: epoch 0038, iter [00490, 01251], lr: 0.001152, loss: 0.4191
2022-09-22 02:18:07 - train: epoch 0038, iter [00500, 01251], lr: 0.001152, loss: 0.4158
2022-09-22 02:18:28 - train: epoch 0038, iter [00510, 01251], lr: 0.001152, loss: 0.4185
2022-09-22 02:18:48 - train: epoch 0038, iter [00520, 01251], lr: 0.001152, loss: 0.4278
2022-09-22 02:19:09 - train: epoch 0038, iter [00530, 01251], lr: 0.001153, loss: 0.4265
2022-09-22 02:19:30 - train: epoch 0038, iter [00540, 01251], lr: 0.001153, loss: 0.4383
2022-09-22 02:19:51 - train: epoch 0038, iter [00550, 01251], lr: 0.001153, loss: 0.4153
2022-09-22 02:20:11 - train: epoch 0038, iter [00560, 01251], lr: 0.001153, loss: 0.4336
2022-09-22 02:20:32 - train: epoch 0038, iter [00570, 01251], lr: 0.001154, loss: 0.4283
2022-09-22 02:20:53 - train: epoch 0038, iter [00580, 01251], lr: 0.001154, loss: 0.4209
2022-09-22 02:21:14 - train: epoch 0038, iter [00590, 01251], lr: 0.001154, loss: 0.4084
2022-09-22 02:21:35 - train: epoch 0038, iter [00600, 01251], lr: 0.001154, loss: 0.4324
2022-09-22 02:21:55 - train: epoch 0038, iter [00610, 01251], lr: 0.001155, loss: 0.3990
2022-09-22 02:22:16 - train: epoch 0038, iter [00620, 01251], lr: 0.001155, loss: 0.4505
2022-09-22 02:22:37 - train: epoch 0038, iter [00630, 01251], lr: 0.001155, loss: 0.4298
2022-09-22 02:22:58 - train: epoch 0038, iter [00640, 01251], lr: 0.001155, loss: 0.4306
2022-09-22 02:23:19 - train: epoch 0038, iter [00650, 01251], lr: 0.001156, loss: 0.4437
2022-09-22 02:23:39 - train: epoch 0038, iter [00660, 01251], lr: 0.001156, loss: 0.4246
2022-09-22 02:24:00 - train: epoch 0038, iter [00670, 01251], lr: 0.001156, loss: 0.4145
2022-09-22 02:24:21 - train: epoch 0038, iter [00680, 01251], lr: 0.001156, loss: 0.4166
2022-09-22 02:24:42 - train: epoch 0038, iter [00690, 01251], lr: 0.001157, loss: 0.4356
2022-09-22 02:25:03 - train: epoch 0038, iter [00700, 01251], lr: 0.001157, loss: 0.4129
2022-09-22 02:25:24 - train: epoch 0038, iter [00710, 01251], lr: 0.001157, loss: 0.4154
2022-09-22 02:25:44 - train: epoch 0038, iter [00720, 01251], lr: 0.001157, loss: 0.4345
2022-09-22 02:26:05 - train: epoch 0038, iter [00730, 01251], lr: 0.001158, loss: 0.4204
2022-09-22 02:26:26 - train: epoch 0038, iter [00740, 01251], lr: 0.001158, loss: 0.4153
2022-09-22 02:26:47 - train: epoch 0038, iter [00750, 01251], lr: 0.001158, loss: 0.4259
2022-09-22 02:27:08 - train: epoch 0038, iter [00760, 01251], lr: 0.001158, loss: 0.4319
2022-09-22 02:27:28 - train: epoch 0038, iter [00770, 01251], lr: 0.001158, loss: 0.4197
2022-09-22 02:27:49 - train: epoch 0038, iter [00780, 01251], lr: 0.001159, loss: 0.4238
2022-09-22 02:28:10 - train: epoch 0038, iter [00790, 01251], lr: 0.001159, loss: 0.4410
2022-09-22 02:28:31 - train: epoch 0038, iter [00800, 01251], lr: 0.001159, loss: 0.4205
2022-09-22 02:28:52 - train: epoch 0038, iter [00810, 01251], lr: 0.001159, loss: 0.4235
2022-09-22 02:29:12 - train: epoch 0038, iter [00820, 01251], lr: 0.001160, loss: 0.4440
2022-09-22 02:29:33 - train: epoch 0038, iter [00830, 01251], lr: 0.001160, loss: 0.4078
2022-09-22 02:29:54 - train: epoch 0038, iter [00840, 01251], lr: 0.001160, loss: 0.4137
2022-09-22 02:30:15 - train: epoch 0038, iter [00850, 01251], lr: 0.001160, loss: 0.4294
2022-09-22 02:30:36 - train: epoch 0038, iter [00860, 01251], lr: 0.001161, loss: 0.4187
2022-09-22 02:30:57 - train: epoch 0038, iter [00870, 01251], lr: 0.001161, loss: 0.4222
2022-09-22 02:31:17 - train: epoch 0038, iter [00880, 01251], lr: 0.001161, loss: 0.4234
2022-09-22 02:31:38 - train: epoch 0038, iter [00890, 01251], lr: 0.001161, loss: 0.4102
2022-09-22 02:31:59 - train: epoch 0038, iter [00900, 01251], lr: 0.001162, loss: 0.4169
2022-09-22 02:32:19 - train: epoch 0038, iter [00910, 01251], lr: 0.001162, loss: 0.4246
2022-09-22 02:32:40 - train: epoch 0038, iter [00920, 01251], lr: 0.001162, loss: 0.4287
2022-09-22 02:33:01 - train: epoch 0038, iter [00930, 01251], lr: 0.001162, loss: 0.4205
2022-09-22 02:33:22 - train: epoch 0038, iter [00940, 01251], lr: 0.001163, loss: 0.4326
2022-09-22 02:33:43 - train: epoch 0038, iter [00950, 01251], lr: 0.001163, loss: 0.4367
2022-09-22 02:34:04 - train: epoch 0038, iter [00960, 01251], lr: 0.001163, loss: 0.4283
2022-09-22 02:34:24 - train: epoch 0038, iter [00970, 01251], lr: 0.001163, loss: 0.4273
2022-09-22 02:34:45 - train: epoch 0038, iter [00980, 01251], lr: 0.001164, loss: 0.4317
2022-09-22 02:35:06 - train: epoch 0038, iter [00990, 01251], lr: 0.001164, loss: 0.4323
2022-09-22 02:35:27 - train: epoch 0038, iter [01000, 01251], lr: 0.001164, loss: 0.4265
2022-09-22 02:35:47 - train: epoch 0038, iter [01010, 01251], lr: 0.001164, loss: 0.4286
2022-09-22 02:36:08 - train: epoch 0038, iter [01020, 01251], lr: 0.001164, loss: 0.4397
2022-09-22 02:36:29 - train: epoch 0038, iter [01030, 01251], lr: 0.001165, loss: 0.4168
2022-09-22 02:36:50 - train: epoch 0038, iter [01040, 01251], lr: 0.001165, loss: 0.4068
2022-09-22 02:37:10 - train: epoch 0038, iter [01050, 01251], lr: 0.001165, loss: 0.3972
2022-09-22 02:37:32 - train: epoch 0038, iter [01060, 01251], lr: 0.001165, loss: 0.4166
2022-09-22 02:37:53 - train: epoch 0038, iter [01070, 01251], lr: 0.001166, loss: 0.4219
2022-09-22 02:38:13 - train: epoch 0038, iter [01080, 01251], lr: 0.001166, loss: 0.4074
2022-09-22 02:38:34 - train: epoch 0038, iter [01090, 01251], lr: 0.001166, loss: 0.4143
2022-09-22 02:38:55 - train: epoch 0038, iter [01100, 01251], lr: 0.001166, loss: 0.4403
2022-09-22 02:39:16 - train: epoch 0038, iter [01110, 01251], lr: 0.001167, loss: 0.4337
2022-09-22 02:39:37 - train: epoch 0038, iter [01120, 01251], lr: 0.001167, loss: 0.4332
2022-09-22 02:39:57 - train: epoch 0038, iter [01130, 01251], lr: 0.001167, loss: 0.4340
2022-09-22 02:40:18 - train: epoch 0038, iter [01140, 01251], lr: 0.001167, loss: 0.4076
2022-09-22 02:40:39 - train: epoch 0038, iter [01150, 01251], lr: 0.001168, loss: 0.4031
2022-09-22 02:41:00 - train: epoch 0038, iter [01160, 01251], lr: 0.001168, loss: 0.4312
2022-09-22 02:41:21 - train: epoch 0038, iter [01170, 01251], lr: 0.001168, loss: 0.4069
2022-09-22 02:41:41 - train: epoch 0038, iter [01180, 01251], lr: 0.001168, loss: 0.4364
2022-09-22 02:42:02 - train: epoch 0038, iter [01190, 01251], lr: 0.001169, loss: 0.4068
2022-09-22 02:42:23 - train: epoch 0038, iter [01200, 01251], lr: 0.001169, loss: 0.4141
2022-09-22 02:42:44 - train: epoch 0038, iter [01210, 01251], lr: 0.001169, loss: 0.4148
2022-09-22 02:43:04 - train: epoch 0038, iter [01220, 01251], lr: 0.001169, loss: 0.4137
2022-09-22 02:43:25 - train: epoch 0038, iter [01230, 01251], lr: 0.001169, loss: 0.4133
2022-09-22 02:43:46 - train: epoch 0038, iter [01240, 01251], lr: 0.001170, loss: 0.4216
2022-09-22 02:44:06 - train: epoch 0038, iter [01250, 01251], lr: 0.001170, loss: 0.4404
2022-09-22 02:44:10 - train: epoch 038, train_loss: 0.4219
2022-09-22 02:44:15 - until epoch: 038, best_loss: 0.4219
2022-09-22 02:44:15 - epoch 039 lr: 0.001170
2022-09-22 02:44:52 - train: epoch 0039, iter [00010, 01251], lr: 0.001170, loss: 0.4214
2022-09-22 02:45:13 - train: epoch 0039, iter [00020, 01251], lr: 0.001170, loss: 0.4186
2022-09-22 02:45:33 - train: epoch 0039, iter [00030, 01251], lr: 0.001171, loss: 0.4173
2022-09-22 02:45:54 - train: epoch 0039, iter [00040, 01251], lr: 0.001171, loss: 0.4390
2022-09-22 02:46:15 - train: epoch 0039, iter [00050, 01251], lr: 0.001171, loss: 0.4384
2022-09-22 02:46:35 - train: epoch 0039, iter [00060, 01251], lr: 0.001171, loss: 0.4209
2022-09-22 02:46:56 - train: epoch 0039, iter [00070, 01251], lr: 0.001172, loss: 0.4083
2022-09-22 02:47:17 - train: epoch 0039, iter [00080, 01251], lr: 0.001172, loss: 0.4347
2022-09-22 02:47:37 - train: epoch 0039, iter [00090, 01251], lr: 0.001172, loss: 0.4100
2022-09-22 02:47:58 - train: epoch 0039, iter [00100, 01251], lr: 0.001172, loss: 0.4294
2022-09-22 02:48:18 - train: epoch 0039, iter [00110, 01251], lr: 0.001173, loss: 0.4358
2022-09-22 02:48:39 - train: epoch 0039, iter [00120, 01251], lr: 0.001173, loss: 0.4264
2022-09-22 02:49:00 - train: epoch 0039, iter [00130, 01251], lr: 0.001173, loss: 0.4149
2022-09-22 02:49:20 - train: epoch 0039, iter [00140, 01251], lr: 0.001173, loss: 0.4153
2022-09-22 02:49:41 - train: epoch 0039, iter [00150, 01251], lr: 0.001174, loss: 0.4248
2022-09-22 02:50:02 - train: epoch 0039, iter [00160, 01251], lr: 0.001174, loss: 0.4127
2022-09-22 02:50:23 - train: epoch 0039, iter [00170, 01251], lr: 0.001174, loss: 0.3973
2022-09-22 02:50:43 - train: epoch 0039, iter [00180, 01251], lr: 0.001174, loss: 0.4198
2022-09-22 02:51:04 - train: epoch 0039, iter [00190, 01251], lr: 0.001175, loss: 0.4090
2022-09-22 02:51:25 - train: epoch 0039, iter [00200, 01251], lr: 0.001175, loss: 0.4097
2022-09-22 02:51:46 - train: epoch 0039, iter [00210, 01251], lr: 0.001175, loss: 0.4326
2022-09-22 02:52:06 - train: epoch 0039, iter [00220, 01251], lr: 0.001175, loss: 0.4233
2022-09-22 02:52:27 - train: epoch 0039, iter [00230, 01251], lr: 0.001176, loss: 0.4145
2022-09-22 02:52:48 - train: epoch 0039, iter [00240, 01251], lr: 0.001176, loss: 0.4202
2022-09-22 02:53:08 - train: epoch 0039, iter [00250, 01251], lr: 0.001176, loss: 0.4192
2022-09-22 02:53:29 - train: epoch 0039, iter [00260, 01251], lr: 0.001176, loss: 0.4231
2022-09-22 02:53:50 - train: epoch 0039, iter [00270, 01251], lr: 0.001176, loss: 0.4219
2022-09-22 02:54:10 - train: epoch 0039, iter [00280, 01251], lr: 0.001177, loss: 0.4158
2022-09-22 02:54:31 - train: epoch 0039, iter [00290, 01251], lr: 0.001177, loss: 0.4209
2022-09-22 02:54:52 - train: epoch 0039, iter [00300, 01251], lr: 0.001177, loss: 0.4170
2022-09-22 02:55:12 - train: epoch 0039, iter [00310, 01251], lr: 0.001177, loss: 0.4265
2022-09-22 02:55:33 - train: epoch 0039, iter [00320, 01251], lr: 0.001178, loss: 0.4176
2022-09-22 02:55:54 - train: epoch 0039, iter [00330, 01251], lr: 0.001178, loss: 0.4235
2022-09-22 02:56:14 - train: epoch 0039, iter [00340, 01251], lr: 0.001178, loss: 0.4248
2022-09-22 02:56:35 - train: epoch 0039, iter [00350, 01251], lr: 0.001178, loss: 0.4204
2022-09-22 02:56:56 - train: epoch 0039, iter [00360, 01251], lr: 0.001179, loss: 0.4184
2022-09-22 02:57:17 - train: epoch 0039, iter [00370, 01251], lr: 0.001179, loss: 0.4179
2022-09-22 02:57:37 - train: epoch 0039, iter [00380, 01251], lr: 0.001179, loss: 0.4058
2022-09-22 02:57:58 - train: epoch 0039, iter [00390, 01251], lr: 0.001179, loss: 0.4133
2022-09-22 02:58:19 - train: epoch 0039, iter [00400, 01251], lr: 0.001180, loss: 0.4235
2022-09-22 02:58:40 - train: epoch 0039, iter [00410, 01251], lr: 0.001180, loss: 0.4213
2022-09-22 02:59:01 - train: epoch 0039, iter [00420, 01251], lr: 0.001180, loss: 0.3978
2022-09-22 02:59:21 - train: epoch 0039, iter [00430, 01251], lr: 0.001180, loss: 0.4223
2022-09-22 02:59:42 - train: epoch 0039, iter [00440, 01251], lr: 0.001181, loss: 0.4356
2022-09-22 03:00:03 - train: epoch 0039, iter [00450, 01251], lr: 0.001181, loss: 0.4173
2022-09-22 03:00:24 - train: epoch 0039, iter [00460, 01251], lr: 0.001181, loss: 0.4170
2022-09-22 03:00:44 - train: epoch 0039, iter [00470, 01251], lr: 0.001181, loss: 0.4026
2022-09-22 03:01:05 - train: epoch 0039, iter [00480, 01251], lr: 0.001182, loss: 0.4140
2022-09-22 03:01:26 - train: epoch 0039, iter [00490, 01251], lr: 0.001182, loss: 0.4192
2022-09-22 03:01:46 - train: epoch 0039, iter [00500, 01251], lr: 0.001182, loss: 0.3910
2022-09-22 03:02:07 - train: epoch 0039, iter [00510, 01251], lr: 0.001182, loss: 0.4153
2022-09-22 03:02:28 - train: epoch 0039, iter [00520, 01251], lr: 0.001182, loss: 0.4158
2022-09-22 03:02:49 - train: epoch 0039, iter [00530, 01251], lr: 0.001183, loss: 0.4338
2022-09-22 03:03:09 - train: epoch 0039, iter [00540, 01251], lr: 0.001183, loss: 0.4268
2022-09-22 03:03:30 - train: epoch 0039, iter [00550, 01251], lr: 0.001183, loss: 0.4141
2022-09-22 03:03:50 - train: epoch 0039, iter [00560, 01251], lr: 0.001183, loss: 0.4264
2022-09-22 03:04:11 - train: epoch 0039, iter [00570, 01251], lr: 0.001184, loss: 0.4217
2022-09-22 03:04:32 - train: epoch 0039, iter [00580, 01251], lr: 0.001184, loss: 0.4311
2022-09-22 03:04:53 - train: epoch 0039, iter [00590, 01251], lr: 0.001184, loss: 0.4365
2022-09-22 03:05:14 - train: epoch 0039, iter [00600, 01251], lr: 0.001184, loss: 0.4123
2022-09-22 03:05:34 - train: epoch 0039, iter [00610, 01251], lr: 0.001185, loss: 0.4041
2022-09-22 03:05:55 - train: epoch 0039, iter [00620, 01251], lr: 0.001185, loss: 0.4428
2022-09-22 03:06:16 - train: epoch 0039, iter [00630, 01251], lr: 0.001185, loss: 0.4353
2022-09-22 03:06:37 - train: epoch 0039, iter [00640, 01251], lr: 0.001185, loss: 0.4165
2022-09-22 03:06:57 - train: epoch 0039, iter [00650, 01251], lr: 0.001186, loss: 0.4227
2022-09-22 03:07:18 - train: epoch 0039, iter [00660, 01251], lr: 0.001186, loss: 0.4224
2022-09-22 03:07:39 - train: epoch 0039, iter [00670, 01251], lr: 0.001186, loss: 0.4306
2022-09-22 03:07:59 - train: epoch 0039, iter [00680, 01251], lr: 0.001186, loss: 0.4269
2022-09-22 03:08:20 - train: epoch 0039, iter [00690, 01251], lr: 0.001187, loss: 0.4374
2022-09-22 03:08:41 - train: epoch 0039, iter [00700, 01251], lr: 0.001187, loss: 0.4341
2022-09-22 03:09:02 - train: epoch 0039, iter [00710, 01251], lr: 0.001187, loss: 0.4396
2022-09-22 03:09:22 - train: epoch 0039, iter [00720, 01251], lr: 0.001187, loss: 0.4164
2022-09-22 03:09:43 - train: epoch 0039, iter [00730, 01251], lr: 0.001188, loss: 0.4298
2022-09-22 03:10:04 - train: epoch 0039, iter [00740, 01251], lr: 0.001188, loss: 0.4219
2022-09-22 03:10:25 - train: epoch 0039, iter [00750, 01251], lr: 0.001188, loss: 0.4278
2022-09-22 03:10:45 - train: epoch 0039, iter [00760, 01251], lr: 0.001188, loss: 0.4026
2022-09-22 03:11:06 - train: epoch 0039, iter [00770, 01251], lr: 0.001188, loss: 0.4355
2022-09-22 03:11:27 - train: epoch 0039, iter [00780, 01251], lr: 0.001189, loss: 0.4136
2022-09-22 03:11:47 - train: epoch 0039, iter [00790, 01251], lr: 0.001189, loss: 0.4263
2022-09-22 03:12:08 - train: epoch 0039, iter [00800, 01251], lr: 0.001189, loss: 0.4502
2022-09-22 03:12:29 - train: epoch 0039, iter [00810, 01251], lr: 0.001189, loss: 0.4264
2022-09-22 03:12:50 - train: epoch 0039, iter [00820, 01251], lr: 0.001190, loss: 0.4208
2022-09-22 03:13:10 - train: epoch 0039, iter [00830, 01251], lr: 0.001190, loss: 0.4154
2022-09-22 03:13:31 - train: epoch 0039, iter [00840, 01251], lr: 0.001190, loss: 0.4188
2022-09-22 03:13:52 - train: epoch 0039, iter [00850, 01251], lr: 0.001190, loss: 0.4309
2022-09-22 03:14:13 - train: epoch 0039, iter [00860, 01251], lr: 0.001191, loss: 0.4395
2022-09-22 03:14:33 - train: epoch 0039, iter [00870, 01251], lr: 0.001191, loss: 0.4196
2022-09-22 03:14:54 - train: epoch 0039, iter [00880, 01251], lr: 0.001191, loss: 0.4179
2022-09-22 03:15:15 - train: epoch 0039, iter [00890, 01251], lr: 0.001191, loss: 0.4303
2022-09-22 03:15:36 - train: epoch 0039, iter [00900, 01251], lr: 0.001192, loss: 0.4168
2022-09-22 03:15:56 - train: epoch 0039, iter [00910, 01251], lr: 0.001192, loss: 0.4105
2022-09-22 03:16:17 - train: epoch 0039, iter [00920, 01251], lr: 0.001192, loss: 0.4314
2022-09-22 03:16:38 - train: epoch 0039, iter [00930, 01251], lr: 0.001192, loss: 0.4231
2022-09-22 03:16:59 - train: epoch 0039, iter [00940, 01251], lr: 0.001193, loss: 0.4360
2022-09-22 03:17:19 - train: epoch 0039, iter [00950, 01251], lr: 0.001193, loss: 0.4133
2022-09-22 03:17:40 - train: epoch 0039, iter [00960, 01251], lr: 0.001193, loss: 0.4028
2022-09-22 03:18:01 - train: epoch 0039, iter [00970, 01251], lr: 0.001193, loss: 0.4188
2022-09-22 03:18:22 - train: epoch 0039, iter [00980, 01251], lr: 0.001194, loss: 0.4191
2022-09-22 03:18:42 - train: epoch 0039, iter [00990, 01251], lr: 0.001194, loss: 0.4184
2022-09-22 03:19:03 - train: epoch 0039, iter [01000, 01251], lr: 0.001194, loss: 0.4333
2022-09-22 03:19:24 - train: epoch 0039, iter [01010, 01251], lr: 0.001194, loss: 0.4093
2022-09-22 03:19:45 - train: epoch 0039, iter [01020, 01251], lr: 0.001194, loss: 0.4381
2022-09-22 03:20:06 - train: epoch 0039, iter [01030, 01251], lr: 0.001195, loss: 0.4200
2022-09-22 03:20:26 - train: epoch 0039, iter [01040, 01251], lr: 0.001195, loss: 0.4493
2022-09-22 03:20:47 - train: epoch 0039, iter [01050, 01251], lr: 0.001195, loss: 0.4177
2022-09-22 03:21:08 - train: epoch 0039, iter [01060, 01251], lr: 0.001195, loss: 0.4128
2022-09-22 03:21:29 - train: epoch 0039, iter [01070, 01251], lr: 0.001196, loss: 0.4118
2022-09-22 03:21:49 - train: epoch 0039, iter [01080, 01251], lr: 0.001196, loss: 0.4404
2022-09-22 03:22:10 - train: epoch 0039, iter [01090, 01251], lr: 0.001196, loss: 0.4114
2022-09-22 03:22:31 - train: epoch 0039, iter [01100, 01251], lr: 0.001196, loss: 0.4518
2022-09-22 03:22:52 - train: epoch 0039, iter [01110, 01251], lr: 0.001197, loss: 0.4270
2022-09-22 03:23:12 - train: epoch 0039, iter [01120, 01251], lr: 0.001197, loss: 0.4293
2022-09-22 03:23:33 - train: epoch 0039, iter [01130, 01251], lr: 0.001197, loss: 0.4099
2022-09-22 03:23:54 - train: epoch 0039, iter [01140, 01251], lr: 0.001197, loss: 0.4221
2022-09-22 03:24:14 - train: epoch 0039, iter [01150, 01251], lr: 0.001198, loss: 0.4103
2022-09-22 03:24:35 - train: epoch 0039, iter [01160, 01251], lr: 0.001198, loss: 0.4042
2022-09-22 03:24:56 - train: epoch 0039, iter [01170, 01251], lr: 0.001198, loss: 0.4286
2022-09-22 03:25:17 - train: epoch 0039, iter [01180, 01251], lr: 0.001198, loss: 0.4295
2022-09-22 03:25:38 - train: epoch 0039, iter [01190, 01251], lr: 0.001199, loss: 0.4062
2022-09-22 03:25:58 - train: epoch 0039, iter [01200, 01251], lr: 0.001199, loss: 0.4204
2022-09-22 03:26:19 - train: epoch 0039, iter [01210, 01251], lr: 0.001199, loss: 0.4247
2022-09-22 03:26:40 - train: epoch 0039, iter [01220, 01251], lr: 0.001199, loss: 0.4293
2022-09-22 03:27:01 - train: epoch 0039, iter [01230, 01251], lr: 0.001199, loss: 0.4194
2022-09-22 03:27:21 - train: epoch 0039, iter [01240, 01251], lr: 0.001200, loss: 0.4173
2022-09-22 03:27:41 - train: epoch 0039, iter [01250, 01251], lr: 0.001200, loss: 0.4256
2022-09-22 03:27:46 - train: epoch 039, train_loss: 0.4217
2022-09-22 03:27:50 - until epoch: 039, best_loss: 0.4217
2022-09-22 03:27:50 - epoch 040 lr: 0.001200
2022-09-22 03:28:27 - train: epoch 0040, iter [00010, 01251], lr: 0.001200, loss: 0.4109
2022-09-22 03:28:47 - train: epoch 0040, iter [00020, 01251], lr: 0.001200, loss: 0.4037
2022-09-22 03:29:08 - train: epoch 0040, iter [00030, 01251], lr: 0.001201, loss: 0.4340
2022-09-22 03:29:28 - train: epoch 0040, iter [00040, 01251], lr: 0.001201, loss: 0.4187
2022-09-22 03:29:49 - train: epoch 0040, iter [00050, 01251], lr: 0.001201, loss: 0.4187
2022-09-22 03:30:10 - train: epoch 0040, iter [00060, 01251], lr: 0.001201, loss: 0.4292
2022-09-22 03:30:30 - train: epoch 0040, iter [00070, 01251], lr: 0.001202, loss: 0.4155
2022-09-22 03:30:51 - train: epoch 0040, iter [00080, 01251], lr: 0.001202, loss: 0.4135
2022-09-22 03:31:11 - train: epoch 0040, iter [00090, 01251], lr: 0.001202, loss: 0.4063
2022-09-22 03:31:32 - train: epoch 0040, iter [00100, 01251], lr: 0.001202, loss: 0.4144
2022-09-22 03:31:53 - train: epoch 0040, iter [00110, 01251], lr: 0.001203, loss: 0.4308
2022-09-22 03:32:13 - train: epoch 0040, iter [00120, 01251], lr: 0.001203, loss: 0.4205
2022-09-22 03:32:34 - train: epoch 0040, iter [00130, 01251], lr: 0.001203, loss: 0.4235
2022-09-22 03:32:54 - train: epoch 0040, iter [00140, 01251], lr: 0.001203, loss: 0.4430
2022-09-22 03:33:15 - train: epoch 0040, iter [00150, 01251], lr: 0.001204, loss: 0.4146
2022-09-22 03:33:35 - train: epoch 0040, iter [00160, 01251], lr: 0.001204, loss: 0.4330
2022-09-22 03:33:56 - train: epoch 0040, iter [00170, 01251], lr: 0.001204, loss: 0.4187
2022-09-22 03:34:16 - train: epoch 0040, iter [00180, 01251], lr: 0.001204, loss: 0.4329
2022-09-22 03:34:37 - train: epoch 0040, iter [00190, 01251], lr: 0.001205, loss: 0.4272
2022-09-22 03:34:58 - train: epoch 0040, iter [00200, 01251], lr: 0.001205, loss: 0.4185
2022-09-22 03:35:18 - train: epoch 0040, iter [00210, 01251], lr: 0.001205, loss: 0.4204
2022-09-22 03:35:39 - train: epoch 0040, iter [00220, 01251], lr: 0.001205, loss: 0.4149
2022-09-22 03:35:59 - train: epoch 0040, iter [00230, 01251], lr: 0.001206, loss: 0.4251
2022-09-22 03:36:20 - train: epoch 0040, iter [00240, 01251], lr: 0.001206, loss: 0.4248
2022-09-22 03:36:40 - train: epoch 0040, iter [00250, 01251], lr: 0.001206, loss: 0.4261
2022-09-22 03:37:01 - train: epoch 0040, iter [00260, 01251], lr: 0.001206, loss: 0.4378
2022-09-22 03:37:21 - train: epoch 0040, iter [00270, 01251], lr: 0.001206, loss: 0.4155
2022-09-22 03:37:42 - train: epoch 0040, iter [00280, 01251], lr: 0.001207, loss: 0.4123
2022-09-22 03:38:02 - train: epoch 0040, iter [00290, 01251], lr: 0.001207, loss: 0.4000
2022-09-22 03:38:23 - train: epoch 0040, iter [00300, 01251], lr: 0.001207, loss: 0.3989
2022-09-22 03:38:44 - train: epoch 0040, iter [00310, 01251], lr: 0.001207, loss: 0.4212
2022-09-22 03:39:04 - train: epoch 0040, iter [00320, 01251], lr: 0.001208, loss: 0.4097
2022-09-22 03:39:25 - train: epoch 0040, iter [00330, 01251], lr: 0.001208, loss: 0.4074
2022-09-22 03:39:45 - train: epoch 0040, iter [00340, 01251], lr: 0.001208, loss: 0.4310
2022-09-22 03:40:06 - train: epoch 0040, iter [00350, 01251], lr: 0.001208, loss: 0.4385
2022-09-22 03:40:26 - train: epoch 0040, iter [00360, 01251], lr: 0.001209, loss: 0.4213
2022-09-22 03:40:47 - train: epoch 0040, iter [00370, 01251], lr: 0.001209, loss: 0.4193
2022-09-22 03:41:08 - train: epoch 0040, iter [00380, 01251], lr: 0.001209, loss: 0.4263
2022-09-22 03:41:28 - train: epoch 0040, iter [00390, 01251], lr: 0.001209, loss: 0.4369
2022-09-22 03:41:49 - train: epoch 0040, iter [00400, 01251], lr: 0.001210, loss: 0.4159
2022-09-22 03:42:09 - train: epoch 0040, iter [00410, 01251], lr: 0.001210, loss: 0.4355
2022-09-22 03:42:30 - train: epoch 0040, iter [00420, 01251], lr: 0.001210, loss: 0.4551
2022-09-22 03:42:51 - train: epoch 0040, iter [00430, 01251], lr: 0.001210, loss: 0.4310
2022-09-22 03:43:11 - train: epoch 0040, iter [00440, 01251], lr: 0.001211, loss: 0.4210
2022-09-22 03:43:32 - train: epoch 0040, iter [00450, 01251], lr: 0.001211, loss: 0.4139
2022-09-22 03:43:53 - train: epoch 0040, iter [00460, 01251], lr: 0.001211, loss: 0.4164
2022-09-22 03:44:13 - train: epoch 0040, iter [00470, 01251], lr: 0.001211, loss: 0.4161
2022-09-22 03:44:34 - train: epoch 0040, iter [00480, 01251], lr: 0.001212, loss: 0.4260
2022-09-22 03:44:54 - train: epoch 0040, iter [00490, 01251], lr: 0.001212, loss: 0.4234
2022-09-22 03:45:15 - train: epoch 0040, iter [00500, 01251], lr: 0.001212, loss: 0.4268
2022-09-22 03:45:35 - train: epoch 0040, iter [00510, 01251], lr: 0.001212, loss: 0.4123
2022-09-22 03:45:56 - train: epoch 0040, iter [00520, 01251], lr: 0.001212, loss: 0.4131
2022-09-22 03:46:16 - train: epoch 0040, iter [00530, 01251], lr: 0.001213, loss: 0.4516
2022-09-22 03:46:37 - train: epoch 0040, iter [00540, 01251], lr: 0.001213, loss: 0.4309
2022-09-22 03:46:57 - train: epoch 0040, iter [00550, 01251], lr: 0.001213, loss: 0.4198
2022-09-22 03:47:18 - train: epoch 0040, iter [00560, 01251], lr: 0.001213, loss: 0.4103
2022-09-22 03:47:39 - train: epoch 0040, iter [00570, 01251], lr: 0.001214, loss: 0.4131
2022-09-22 03:47:59 - train: epoch 0040, iter [00580, 01251], lr: 0.001214, loss: 0.4110
2022-09-22 03:48:20 - train: epoch 0040, iter [00590, 01251], lr: 0.001214, loss: 0.4184
2022-09-22 03:48:40 - train: epoch 0040, iter [00600, 01251], lr: 0.001214, loss: 0.4185
2022-09-22 03:49:01 - train: epoch 0040, iter [00610, 01251], lr: 0.001215, loss: 0.4203
2022-09-22 03:49:21 - train: epoch 0040, iter [00620, 01251], lr: 0.001215, loss: 0.4242
2022-09-22 03:49:42 - train: epoch 0040, iter [00630, 01251], lr: 0.001215, loss: 0.4391
2022-09-22 03:50:03 - train: epoch 0040, iter [00640, 01251], lr: 0.001215, loss: 0.4191
2022-09-22 03:50:23 - train: epoch 0040, iter [00650, 01251], lr: 0.001216, loss: 0.4164
2022-09-22 03:50:44 - train: epoch 0040, iter [00660, 01251], lr: 0.001216, loss: 0.4275
2022-09-22 03:51:05 - train: epoch 0040, iter [00670, 01251], lr: 0.001216, loss: 0.4086
2022-09-22 03:51:25 - train: epoch 0040, iter [00680, 01251], lr: 0.001216, loss: 0.4248
2022-09-22 03:51:46 - train: epoch 0040, iter [00690, 01251], lr: 0.001217, loss: 0.4268
2022-09-22 03:52:06 - train: epoch 0040, iter [00700, 01251], lr: 0.001217, loss: 0.4166
2022-09-22 03:52:27 - train: epoch 0040, iter [00710, 01251], lr: 0.001217, loss: 0.4248
2022-09-22 03:52:48 - train: epoch 0040, iter [00720, 01251], lr: 0.001217, loss: 0.4153
2022-09-22 03:53:08 - train: epoch 0040, iter [00730, 01251], lr: 0.001218, loss: 0.4207
2022-09-22 03:53:29 - train: epoch 0040, iter [00740, 01251], lr: 0.001218, loss: 0.3956
2022-09-22 03:53:50 - train: epoch 0040, iter [00750, 01251], lr: 0.001218, loss: 0.4221
2022-09-22 03:54:10 - train: epoch 0040, iter [00760, 01251], lr: 0.001218, loss: 0.4153
2022-09-22 03:54:31 - train: epoch 0040, iter [00770, 01251], lr: 0.001218, loss: 0.4337
2022-09-22 03:54:51 - train: epoch 0040, iter [00780, 01251], lr: 0.001219, loss: 0.3995
2022-09-22 03:55:12 - train: epoch 0040, iter [00790, 01251], lr: 0.001219, loss: 0.4463
2022-09-22 03:55:32 - train: epoch 0040, iter [00800, 01251], lr: 0.001219, loss: 0.4190
2022-09-22 03:55:53 - train: epoch 0040, iter [00810, 01251], lr: 0.001219, loss: 0.4430
2022-09-22 03:56:14 - train: epoch 0040, iter [00820, 01251], lr: 0.001220, loss: 0.3983
2022-09-22 03:56:34 - train: epoch 0040, iter [00830, 01251], lr: 0.001220, loss: 0.4152
2022-09-22 03:56:55 - train: epoch 0040, iter [00840, 01251], lr: 0.001220, loss: 0.4374
2022-09-22 03:57:16 - train: epoch 0040, iter [00850, 01251], lr: 0.001220, loss: 0.4360
2022-09-22 03:57:36 - train: epoch 0040, iter [00860, 01251], lr: 0.001221, loss: 0.4251
2022-09-22 03:57:57 - train: epoch 0040, iter [00870, 01251], lr: 0.001221, loss: 0.4109
2022-09-22 03:58:18 - train: epoch 0040, iter [00880, 01251], lr: 0.001221, loss: 0.3995
2022-09-22 03:58:38 - train: epoch 0040, iter [00890, 01251], lr: 0.001221, loss: 0.4168
2022-09-22 03:58:59 - train: epoch 0040, iter [00900, 01251], lr: 0.001222, loss: 0.4213
2022-09-22 03:59:20 - train: epoch 0040, iter [00910, 01251], lr: 0.001222, loss: 0.4093
2022-09-22 03:59:40 - train: epoch 0040, iter [00920, 01251], lr: 0.001222, loss: 0.4338
2022-09-22 04:00:01 - train: epoch 0040, iter [00930, 01251], lr: 0.001222, loss: 0.4162
2022-09-22 04:00:22 - train: epoch 0040, iter [00940, 01251], lr: 0.001223, loss: 0.4382
2022-09-22 04:00:42 - train: epoch 0040, iter [00950, 01251], lr: 0.001223, loss: 0.4122
2022-09-22 04:01:03 - train: epoch 0040, iter [00960, 01251], lr: 0.001223, loss: 0.4199
2022-09-22 04:01:24 - train: epoch 0040, iter [00970, 01251], lr: 0.001223, loss: 0.4154
2022-09-22 04:01:44 - train: epoch 0040, iter [00980, 01251], lr: 0.001224, loss: 0.4167
2022-09-22 04:02:05 - train: epoch 0040, iter [00990, 01251], lr: 0.001224, loss: 0.4346
2022-09-22 04:02:26 - train: epoch 0040, iter [01000, 01251], lr: 0.001224, loss: 0.4011
2022-09-22 04:02:46 - train: epoch 0040, iter [01010, 01251], lr: 0.001224, loss: 0.4141
2022-09-22 04:03:07 - train: epoch 0040, iter [01020, 01251], lr: 0.001224, loss: 0.4302
2022-09-22 04:03:28 - train: epoch 0040, iter [01030, 01251], lr: 0.001225, loss: 0.4605
2022-09-22 04:03:49 - train: epoch 0040, iter [01040, 01251], lr: 0.001225, loss: 0.4446
2022-09-22 04:04:09 - train: epoch 0040, iter [01050, 01251], lr: 0.001225, loss: 0.4421
2022-09-22 04:04:30 - train: epoch 0040, iter [01060, 01251], lr: 0.001225, loss: 0.4361
2022-09-22 04:04:51 - train: epoch 0040, iter [01070, 01251], lr: 0.001226, loss: 0.4265
2022-09-22 04:05:11 - train: epoch 0040, iter [01080, 01251], lr: 0.001226, loss: 0.4107
2022-09-22 04:05:32 - train: epoch 0040, iter [01090, 01251], lr: 0.001226, loss: 0.4177
2022-09-22 04:05:53 - train: epoch 0040, iter [01100, 01251], lr: 0.001226, loss: 0.4056
2022-09-22 04:06:13 - train: epoch 0040, iter [01110, 01251], lr: 0.001227, loss: 0.4006
2022-09-22 04:06:34 - train: epoch 0040, iter [01120, 01251], lr: 0.001227, loss: 0.4284
2022-09-22 04:06:54 - train: epoch 0040, iter [01130, 01251], lr: 0.001227, loss: 0.4180
2022-09-22 04:07:15 - train: epoch 0040, iter [01140, 01251], lr: 0.001227, loss: 0.4286
2022-09-22 04:07:36 - train: epoch 0040, iter [01150, 01251], lr: 0.001228, loss: 0.4258
2022-09-22 04:07:57 - train: epoch 0040, iter [01160, 01251], lr: 0.001228, loss: 0.4277
2022-09-22 04:08:17 - train: epoch 0040, iter [01170, 01251], lr: 0.001228, loss: 0.4307
2022-09-22 04:08:38 - train: epoch 0040, iter [01180, 01251], lr: 0.001228, loss: 0.4144
2022-09-22 04:08:58 - train: epoch 0040, iter [01190, 01251], lr: 0.001229, loss: 0.4274
2022-09-22 04:09:19 - train: epoch 0040, iter [01200, 01251], lr: 0.001229, loss: 0.4221
2022-09-22 04:09:40 - train: epoch 0040, iter [01210, 01251], lr: 0.001229, loss: 0.4244
2022-09-22 04:10:01 - train: epoch 0040, iter [01220, 01251], lr: 0.001229, loss: 0.4288
2022-09-22 04:10:21 - train: epoch 0040, iter [01230, 01251], lr: 0.001229, loss: 0.4079
2022-09-22 04:10:42 - train: epoch 0040, iter [01240, 01251], lr: 0.001230, loss: 0.4359
2022-09-22 04:11:02 - train: epoch 0040, iter [01250, 01251], lr: 0.001230, loss: 0.4447
2022-09-22 04:11:06 - train: epoch 040, train_loss: 0.4215
2022-09-22 04:11:11 - until epoch: 040, best_loss: 0.4215
2022-09-22 04:11:11 - epoch 041 lr: 0.001200
2022-09-22 04:11:48 - train: epoch 0041, iter [00010, 01251], lr: 0.001200, loss: 0.4152
2022-09-22 04:12:08 - train: epoch 0041, iter [00020, 01251], lr: 0.001200, loss: 0.4142
2022-09-22 04:12:29 - train: epoch 0041, iter [00030, 01251], lr: 0.001200, loss: 0.4362
2022-09-22 04:12:49 - train: epoch 0041, iter [00040, 01251], lr: 0.001200, loss: 0.4286
2022-09-22 04:13:10 - train: epoch 0041, iter [00050, 01251], lr: 0.001200, loss: 0.4240
2022-09-22 04:13:30 - train: epoch 0041, iter [00060, 01251], lr: 0.001200, loss: 0.4281
2022-09-22 04:13:51 - train: epoch 0041, iter [00070, 01251], lr: 0.001200, loss: 0.4288
2022-09-22 04:14:11 - train: epoch 0041, iter [00080, 01251], lr: 0.001200, loss: 0.4377
2022-09-22 04:14:32 - train: epoch 0041, iter [00090, 01251], lr: 0.001200, loss: 0.4193
2022-09-22 04:14:52 - train: epoch 0041, iter [00100, 01251], lr: 0.001200, loss: 0.4009
2022-09-22 04:15:13 - train: epoch 0041, iter [00110, 01251], lr: 0.001200, loss: 0.4022
2022-09-22 04:15:34 - train: epoch 0041, iter [00120, 01251], lr: 0.001200, loss: 0.4330
2022-09-22 04:15:54 - train: epoch 0041, iter [00130, 01251], lr: 0.001200, loss: 0.4110
2022-09-22 04:16:15 - train: epoch 0041, iter [00140, 01251], lr: 0.001200, loss: 0.4199
2022-09-22 04:16:35 - train: epoch 0041, iter [00150, 01251], lr: 0.001200, loss: 0.4219
2022-09-22 04:16:56 - train: epoch 0041, iter [00160, 01251], lr: 0.001200, loss: 0.4203
2022-09-22 04:17:17 - train: epoch 0041, iter [00170, 01251], lr: 0.001200, loss: 0.4305
2022-09-22 04:17:37 - train: epoch 0041, iter [00180, 01251], lr: 0.001200, loss: 0.4445
2022-09-22 04:17:58 - train: epoch 0041, iter [00190, 01251], lr: 0.001200, loss: 0.4213
2022-09-22 04:18:18 - train: epoch 0041, iter [00200, 01251], lr: 0.001200, loss: 0.4171
2022-09-22 04:18:39 - train: epoch 0041, iter [00210, 01251], lr: 0.001200, loss: 0.4430
2022-09-22 04:19:00 - train: epoch 0041, iter [00220, 01251], lr: 0.001200, loss: 0.4269
2022-09-22 04:19:20 - train: epoch 0041, iter [00230, 01251], lr: 0.001200, loss: 0.4043
2022-09-22 04:19:41 - train: epoch 0041, iter [00240, 01251], lr: 0.001200, loss: 0.4237
2022-09-22 04:20:02 - train: epoch 0041, iter [00250, 01251], lr: 0.001200, loss: 0.4363
2022-09-22 04:20:22 - train: epoch 0041, iter [00260, 01251], lr: 0.001200, loss: 0.4090
2022-09-22 04:20:43 - train: epoch 0041, iter [00270, 01251], lr: 0.001200, loss: 0.4355
2022-09-22 04:21:03 - train: epoch 0041, iter [00280, 01251], lr: 0.001200, loss: 0.4090
2022-09-22 04:21:24 - train: epoch 0041, iter [00290, 01251], lr: 0.001200, loss: 0.4278
2022-09-22 04:21:44 - train: epoch 0041, iter [00300, 01251], lr: 0.001200, loss: 0.4208
2022-09-22 04:22:05 - train: epoch 0041, iter [00310, 01251], lr: 0.001200, loss: 0.4267
2022-09-22 04:22:26 - train: epoch 0041, iter [00320, 01251], lr: 0.001200, loss: 0.4194
2022-09-22 04:22:46 - train: epoch 0041, iter [00330, 01251], lr: 0.001200, loss: 0.4137
2022-09-22 04:23:07 - train: epoch 0041, iter [00340, 01251], lr: 0.001200, loss: 0.4294
2022-09-22 04:23:28 - train: epoch 0041, iter [00350, 01251], lr: 0.001200, loss: 0.4171
2022-09-22 04:23:48 - train: epoch 0041, iter [00360, 01251], lr: 0.001200, loss: 0.4179
2022-09-22 04:24:09 - train: epoch 0041, iter [00370, 01251], lr: 0.001200, loss: 0.4336
2022-09-22 04:24:30 - train: epoch 0041, iter [00380, 01251], lr: 0.001200, loss: 0.4136
2022-09-22 04:24:50 - train: epoch 0041, iter [00390, 01251], lr: 0.001200, loss: 0.4204
2022-09-22 04:25:11 - train: epoch 0041, iter [00400, 01251], lr: 0.001200, loss: 0.4230
2022-09-22 04:25:31 - train: epoch 0041, iter [00410, 01251], lr: 0.001200, loss: 0.4256
2022-09-22 04:25:52 - train: epoch 0041, iter [00420, 01251], lr: 0.001200, loss: 0.4075
2022-09-22 04:26:12 - train: epoch 0041, iter [00430, 01251], lr: 0.001200, loss: 0.4301
2022-09-22 04:26:33 - train: epoch 0041, iter [00440, 01251], lr: 0.001200, loss: 0.4129
2022-09-22 04:26:54 - train: epoch 0041, iter [00450, 01251], lr: 0.001200, loss: 0.4183
2022-09-22 04:27:14 - train: epoch 0041, iter [00460, 01251], lr: 0.001200, loss: 0.4077
2022-09-22 04:27:35 - train: epoch 0041, iter [00470, 01251], lr: 0.001200, loss: 0.4200
2022-09-22 04:27:56 - train: epoch 0041, iter [00480, 01251], lr: 0.001200, loss: 0.4305
2022-09-22 04:28:16 - train: epoch 0041, iter [00490, 01251], lr: 0.001200, loss: 0.3954
2022-09-22 04:28:37 - train: epoch 0041, iter [00500, 01251], lr: 0.001200, loss: 0.4309
2022-09-22 04:28:58 - train: epoch 0041, iter [00510, 01251], lr: 0.001200, loss: 0.4286
2022-09-22 04:29:18 - train: epoch 0041, iter [00520, 01251], lr: 0.001200, loss: 0.4194
2022-09-22 04:29:39 - train: epoch 0041, iter [00530, 01251], lr: 0.001200, loss: 0.4261
2022-09-22 04:30:00 - train: epoch 0041, iter [00540, 01251], lr: 0.001200, loss: 0.4216
2022-09-22 04:30:20 - train: epoch 0041, iter [00550, 01251], lr: 0.001200, loss: 0.4319
2022-09-22 04:30:41 - train: epoch 0041, iter [00560, 01251], lr: 0.001200, loss: 0.4229
2022-09-22 04:31:02 - train: epoch 0041, iter [00570, 01251], lr: 0.001200, loss: 0.4286
2022-09-22 04:31:22 - train: epoch 0041, iter [00580, 01251], lr: 0.001200, loss: 0.4324
2022-09-22 04:31:43 - train: epoch 0041, iter [00590, 01251], lr: 0.001200, loss: 0.4053
2022-09-22 04:32:04 - train: epoch 0041, iter [00600, 01251], lr: 0.001200, loss: 0.4273
2022-09-22 04:32:25 - train: epoch 0041, iter [00610, 01251], lr: 0.001200, loss: 0.4040
2022-09-22 04:32:45 - train: epoch 0041, iter [00620, 01251], lr: 0.001200, loss: 0.4278
2022-09-22 04:33:06 - train: epoch 0041, iter [00630, 01251], lr: 0.001200, loss: 0.4322
2022-09-22 04:33:26 - train: epoch 0041, iter [00640, 01251], lr: 0.001200, loss: 0.4257
2022-09-22 04:33:47 - train: epoch 0041, iter [00650, 01251], lr: 0.001200, loss: 0.4102
2022-09-22 04:34:08 - train: epoch 0041, iter [00660, 01251], lr: 0.001200, loss: 0.4166
2022-09-22 04:34:28 - train: epoch 0041, iter [00670, 01251], lr: 0.001200, loss: 0.4140
2022-09-22 04:34:49 - train: epoch 0041, iter [00680, 01251], lr: 0.001200, loss: 0.4201
2022-09-22 04:35:10 - train: epoch 0041, iter [00690, 01251], lr: 0.001200, loss: 0.4242
2022-09-22 04:35:31 - train: epoch 0041, iter [00700, 01251], lr: 0.001200, loss: 0.4028
2022-09-22 04:35:51 - train: epoch 0041, iter [00710, 01251], lr: 0.001200, loss: 0.4275
2022-09-22 04:36:12 - train: epoch 0041, iter [00720, 01251], lr: 0.001200, loss: 0.4228
2022-09-22 04:36:33 - train: epoch 0041, iter [00730, 01251], lr: 0.001200, loss: 0.4427
2022-09-22 04:36:53 - train: epoch 0041, iter [00740, 01251], lr: 0.001200, loss: 0.4120
2022-09-22 04:37:14 - train: epoch 0041, iter [00750, 01251], lr: 0.001200, loss: 0.4243
2022-09-22 04:37:35 - train: epoch 0041, iter [00760, 01251], lr: 0.001200, loss: 0.4138
2022-09-22 04:37:55 - train: epoch 0041, iter [00770, 01251], lr: 0.001200, loss: 0.4031
2022-09-22 04:38:16 - train: epoch 0041, iter [00780, 01251], lr: 0.001200, loss: 0.4345
2022-09-22 04:38:36 - train: epoch 0041, iter [00790, 01251], lr: 0.001200, loss: 0.4231
2022-09-22 04:38:57 - train: epoch 0041, iter [00800, 01251], lr: 0.001200, loss: 0.4233
2022-09-22 04:39:18 - train: epoch 0041, iter [00810, 01251], lr: 0.001200, loss: 0.4182
2022-09-22 04:39:38 - train: epoch 0041, iter [00820, 01251], lr: 0.001200, loss: 0.4127
2022-09-22 04:39:59 - train: epoch 0041, iter [00830, 01251], lr: 0.001200, loss: 0.4238
2022-09-22 04:40:20 - train: epoch 0041, iter [00840, 01251], lr: 0.001200, loss: 0.4298
2022-09-22 04:40:40 - train: epoch 0041, iter [00850, 01251], lr: 0.001200, loss: 0.4246
2022-09-22 04:41:01 - train: epoch 0041, iter [00860, 01251], lr: 0.001200, loss: 0.4259
2022-09-22 04:41:22 - train: epoch 0041, iter [00870, 01251], lr: 0.001200, loss: 0.4094
2022-09-22 04:41:42 - train: epoch 0041, iter [00880, 01251], lr: 0.001200, loss: 0.4405
2022-09-22 04:42:03 - train: epoch 0041, iter [00890, 01251], lr: 0.001200, loss: 0.4294
2022-09-22 04:42:24 - train: epoch 0041, iter [00900, 01251], lr: 0.001200, loss: 0.4256
2022-09-22 04:42:44 - train: epoch 0041, iter [00910, 01251], lr: 0.001200, loss: 0.4230
2022-09-22 04:43:05 - train: epoch 0041, iter [00920, 01251], lr: 0.001200, loss: 0.4280
2022-09-22 04:43:25 - train: epoch 0041, iter [00930, 01251], lr: 0.001200, loss: 0.3998
2022-09-22 04:43:46 - train: epoch 0041, iter [00940, 01251], lr: 0.001200, loss: 0.4335
2022-09-22 04:44:07 - train: epoch 0041, iter [00950, 01251], lr: 0.001200, loss: 0.4150
2022-09-22 04:44:27 - train: epoch 0041, iter [00960, 01251], lr: 0.001200, loss: 0.4177
2022-09-22 04:44:48 - train: epoch 0041, iter [00970, 01251], lr: 0.001200, loss: 0.4273
2022-09-22 04:45:09 - train: epoch 0041, iter [00980, 01251], lr: 0.001200, loss: 0.4423
2022-09-22 04:45:29 - train: epoch 0041, iter [00990, 01251], lr: 0.001200, loss: 0.4165
2022-09-22 04:45:50 - train: epoch 0041, iter [01000, 01251], lr: 0.001200, loss: 0.4142
2022-09-22 04:46:11 - train: epoch 0041, iter [01010, 01251], lr: 0.001200, loss: 0.4164
2022-09-22 04:46:31 - train: epoch 0041, iter [01020, 01251], lr: 0.001200, loss: 0.4355
2022-09-22 04:46:52 - train: epoch 0041, iter [01030, 01251], lr: 0.001200, loss: 0.4275
2022-09-22 04:47:13 - train: epoch 0041, iter [01040, 01251], lr: 0.001200, loss: 0.4305
2022-09-22 04:47:33 - train: epoch 0041, iter [01050, 01251], lr: 0.001200, loss: 0.4013
2022-09-22 04:47:54 - train: epoch 0041, iter [01060, 01251], lr: 0.001200, loss: 0.4222
2022-09-22 04:48:15 - train: epoch 0041, iter [01070, 01251], lr: 0.001200, loss: 0.4077
2022-09-22 04:48:35 - train: epoch 0041, iter [01080, 01251], lr: 0.001200, loss: 0.4204
2022-09-22 04:48:56 - train: epoch 0041, iter [01090, 01251], lr: 0.001200, loss: 0.4386
2022-09-22 04:49:17 - train: epoch 0041, iter [01100, 01251], lr: 0.001200, loss: 0.4093
2022-09-22 04:49:37 - train: epoch 0041, iter [01110, 01251], lr: 0.001200, loss: 0.4079
2022-09-22 04:49:58 - train: epoch 0041, iter [01120, 01251], lr: 0.001200, loss: 0.4135
2022-09-22 04:50:19 - train: epoch 0041, iter [01130, 01251], lr: 0.001200, loss: 0.4295
2022-09-22 04:50:39 - train: epoch 0041, iter [01140, 01251], lr: 0.001200, loss: 0.4229
2022-09-22 04:51:00 - train: epoch 0041, iter [01150, 01251], lr: 0.001200, loss: 0.4165
2022-09-22 04:51:20 - train: epoch 0041, iter [01160, 01251], lr: 0.001200, loss: 0.4233
2022-09-22 04:51:41 - train: epoch 0041, iter [01170, 01251], lr: 0.001200, loss: 0.4110
2022-09-22 04:52:02 - train: epoch 0041, iter [01180, 01251], lr: 0.001200, loss: 0.4306
2022-09-22 04:52:22 - train: epoch 0041, iter [01190, 01251], lr: 0.001200, loss: 0.4212
2022-09-22 04:52:43 - train: epoch 0041, iter [01200, 01251], lr: 0.001200, loss: 0.4190
2022-09-22 04:53:04 - train: epoch 0041, iter [01210, 01251], lr: 0.001200, loss: 0.4196
2022-09-22 04:53:24 - train: epoch 0041, iter [01220, 01251], lr: 0.001200, loss: 0.4292
2022-09-22 04:53:45 - train: epoch 0041, iter [01230, 01251], lr: 0.001200, loss: 0.4238
2022-09-22 04:54:06 - train: epoch 0041, iter [01240, 01251], lr: 0.001200, loss: 0.4047
2022-09-22 04:54:26 - train: epoch 0041, iter [01250, 01251], lr: 0.001200, loss: 0.4240
2022-09-22 04:54:30 - train: epoch 041, train_loss: 0.4211
2022-09-22 04:54:35 - until epoch: 041, best_loss: 0.4211
2022-09-22 04:54:35 - epoch 042 lr: 0.001200
2022-09-22 04:55:12 - train: epoch 0042, iter [00010, 01251], lr: 0.001200, loss: 0.4160
2022-09-22 04:55:33 - train: epoch 0042, iter [00020, 01251], lr: 0.001200, loss: 0.4189
2022-09-22 04:55:53 - train: epoch 0042, iter [00030, 01251], lr: 0.001200, loss: 0.4159
2022-09-22 04:56:14 - train: epoch 0042, iter [00040, 01251], lr: 0.001200, loss: 0.4059
2022-09-22 04:56:35 - train: epoch 0042, iter [00050, 01251], lr: 0.001200, loss: 0.4125
2022-09-22 04:56:55 - train: epoch 0042, iter [00060, 01251], lr: 0.001200, loss: 0.4180
2022-09-22 04:57:16 - train: epoch 0042, iter [00070, 01251], lr: 0.001200, loss: 0.4054
2022-09-22 04:57:37 - train: epoch 0042, iter [00080, 01251], lr: 0.001200, loss: 0.4151
2022-09-22 04:57:58 - train: epoch 0042, iter [00090, 01251], lr: 0.001200, loss: 0.4106
2022-09-22 04:58:18 - train: epoch 0042, iter [00100, 01251], lr: 0.001200, loss: 0.4023
2022-09-22 04:58:39 - train: epoch 0042, iter [00110, 01251], lr: 0.001200, loss: 0.4100
2022-09-22 04:58:59 - train: epoch 0042, iter [00120, 01251], lr: 0.001200, loss: 0.4296
2022-09-22 04:59:20 - train: epoch 0042, iter [00130, 01251], lr: 0.001200, loss: 0.4373
2022-09-22 04:59:41 - train: epoch 0042, iter [00140, 01251], lr: 0.001200, loss: 0.4204
2022-09-22 05:00:01 - train: epoch 0042, iter [00150, 01251], lr: 0.001200, loss: 0.4128
2022-09-22 05:00:22 - train: epoch 0042, iter [00160, 01251], lr: 0.001200, loss: 0.4104
2022-09-22 05:00:43 - train: epoch 0042, iter [00170, 01251], lr: 0.001200, loss: 0.4280
2022-09-22 05:01:03 - train: epoch 0042, iter [00180, 01251], lr: 0.001200, loss: 0.4141
2022-09-22 05:01:24 - train: epoch 0042, iter [00190, 01251], lr: 0.001200, loss: 0.4292
2022-09-22 05:01:44 - train: epoch 0042, iter [00200, 01251], lr: 0.001200, loss: 0.4340
2022-09-22 05:02:05 - train: epoch 0042, iter [00210, 01251], lr: 0.001200, loss: 0.4218
2022-09-22 05:02:25 - train: epoch 0042, iter [00220, 01251], lr: 0.001200, loss: 0.4277
2022-09-22 05:02:46 - train: epoch 0042, iter [00230, 01251], lr: 0.001200, loss: 0.4194
2022-09-22 05:03:06 - train: epoch 0042, iter [00240, 01251], lr: 0.001200, loss: 0.4093
2022-09-22 05:03:27 - train: epoch 0042, iter [00250, 01251], lr: 0.001200, loss: 0.4332
2022-09-22 05:03:48 - train: epoch 0042, iter [00260, 01251], lr: 0.001200, loss: 0.4076
2022-09-22 05:04:08 - train: epoch 0042, iter [00270, 01251], lr: 0.001200, loss: 0.4263
2022-09-22 05:04:29 - train: epoch 0042, iter [00280, 01251], lr: 0.001200, loss: 0.4264
2022-09-22 05:04:50 - train: epoch 0042, iter [00290, 01251], lr: 0.001200, loss: 0.4179
2022-09-22 05:05:10 - train: epoch 0042, iter [00300, 01251], lr: 0.001200, loss: 0.4256
2022-09-22 05:05:31 - train: epoch 0042, iter [00310, 01251], lr: 0.001200, loss: 0.4039
2022-09-22 05:05:52 - train: epoch 0042, iter [00320, 01251], lr: 0.001200, loss: 0.4100
2022-09-22 05:06:12 - train: epoch 0042, iter [00330, 01251], lr: 0.001200, loss: 0.4426
2022-09-22 05:06:33 - train: epoch 0042, iter [00340, 01251], lr: 0.001200, loss: 0.4064
2022-09-22 05:06:54 - train: epoch 0042, iter [00350, 01251], lr: 0.001200, loss: 0.4335
2022-09-22 05:07:14 - train: epoch 0042, iter [00360, 01251], lr: 0.001200, loss: 0.4295
2022-09-22 05:07:35 - train: epoch 0042, iter [00370, 01251], lr: 0.001200, loss: 0.4216
2022-09-22 05:07:56 - train: epoch 0042, iter [00380, 01251], lr: 0.001200, loss: 0.4164
2022-09-22 05:08:16 - train: epoch 0042, iter [00390, 01251], lr: 0.001200, loss: 0.4089
2022-09-22 05:08:37 - train: epoch 0042, iter [00400, 01251], lr: 0.001200, loss: 0.4432
2022-09-22 05:08:57 - train: epoch 0042, iter [00410, 01251], lr: 0.001200, loss: 0.4191
2022-09-22 05:09:18 - train: epoch 0042, iter [00420, 01251], lr: 0.001200, loss: 0.4239
2022-09-22 05:09:39 - train: epoch 0042, iter [00430, 01251], lr: 0.001200, loss: 0.4280
2022-09-22 05:09:59 - train: epoch 0042, iter [00440, 01251], lr: 0.001200, loss: 0.4308
2022-09-22 05:10:20 - train: epoch 0042, iter [00450, 01251], lr: 0.001200, loss: 0.4218
2022-09-22 05:10:41 - train: epoch 0042, iter [00460, 01251], lr: 0.001200, loss: 0.4024
2022-09-22 05:11:01 - train: epoch 0042, iter [00470, 01251], lr: 0.001200, loss: 0.4158
2022-09-22 05:11:22 - train: epoch 0042, iter [00480, 01251], lr: 0.001200, loss: 0.4277
2022-09-22 05:11:42 - train: epoch 0042, iter [00490, 01251], lr: 0.001200, loss: 0.4136
2022-09-22 05:12:03 - train: epoch 0042, iter [00500, 01251], lr: 0.001200, loss: 0.4074
2022-09-22 05:12:24 - train: epoch 0042, iter [00510, 01251], lr: 0.001200, loss: 0.4219
2022-09-22 05:12:44 - train: epoch 0042, iter [00520, 01251], lr: 0.001200, loss: 0.4250
2022-09-22 05:13:05 - train: epoch 0042, iter [00530, 01251], lr: 0.001200, loss: 0.4137
2022-09-22 05:13:26 - train: epoch 0042, iter [00540, 01251], lr: 0.001200, loss: 0.4154
2022-09-22 05:13:46 - train: epoch 0042, iter [00550, 01251], lr: 0.001200, loss: 0.4238
2022-09-22 05:14:07 - train: epoch 0042, iter [00560, 01251], lr: 0.001200, loss: 0.4143
2022-09-22 05:14:28 - train: epoch 0042, iter [00570, 01251], lr: 0.001200, loss: 0.4248
2022-09-22 05:14:48 - train: epoch 0042, iter [00580, 01251], lr: 0.001200, loss: 0.4125
2022-09-22 05:15:09 - train: epoch 0042, iter [00590, 01251], lr: 0.001200, loss: 0.4147
2022-09-22 05:15:29 - train: epoch 0042, iter [00600, 01251], lr: 0.001200, loss: 0.4172
2022-09-22 05:15:50 - train: epoch 0042, iter [00610, 01251], lr: 0.001200, loss: 0.4282
2022-09-22 05:16:11 - train: epoch 0042, iter [00620, 01251], lr: 0.001200, loss: 0.4247
2022-09-22 05:16:31 - train: epoch 0042, iter [00630, 01251], lr: 0.001200, loss: 0.4176
2022-09-22 05:16:52 - train: epoch 0042, iter [00640, 01251], lr: 0.001200, loss: 0.4203
2022-09-22 05:17:13 - train: epoch 0042, iter [00650, 01251], lr: 0.001200, loss: 0.4011
2022-09-22 05:17:33 - train: epoch 0042, iter [00660, 01251], lr: 0.001200, loss: 0.4131
2022-09-22 05:17:54 - train: epoch 0042, iter [00670, 01251], lr: 0.001200, loss: 0.4171
2022-09-22 05:18:15 - train: epoch 0042, iter [00680, 01251], lr: 0.001200, loss: 0.4258
2022-09-22 05:18:36 - train: epoch 0042, iter [00690, 01251], lr: 0.001200, loss: 0.4419
2022-09-22 05:18:56 - train: epoch 0042, iter [00700, 01251], lr: 0.001200, loss: 0.4421
2022-09-22 05:19:17 - train: epoch 0042, iter [00710, 01251], lr: 0.001200, loss: 0.4240
2022-09-22 05:19:37 - train: epoch 0042, iter [00720, 01251], lr: 0.001200, loss: 0.4140
2022-09-22 05:19:58 - train: epoch 0042, iter [00730, 01251], lr: 0.001200, loss: 0.4168
2022-09-22 05:20:19 - train: epoch 0042, iter [00740, 01251], lr: 0.001200, loss: 0.4085
2022-09-22 05:20:39 - train: epoch 0042, iter [00750, 01251], lr: 0.001200, loss: 0.4190
2022-09-22 05:21:00 - train: epoch 0042, iter [00760, 01251], lr: 0.001200, loss: 0.4233
2022-09-22 05:21:20 - train: epoch 0042, iter [00770, 01251], lr: 0.001200, loss: 0.4200
2022-09-22 05:21:41 - train: epoch 0042, iter [00780, 01251], lr: 0.001200, loss: 0.4309
2022-09-22 05:22:01 - train: epoch 0042, iter [00790, 01251], lr: 0.001200, loss: 0.4332
2022-09-22 05:22:22 - train: epoch 0042, iter [00800, 01251], lr: 0.001200, loss: 0.4053
2022-09-22 05:22:43 - train: epoch 0042, iter [00810, 01251], lr: 0.001200, loss: 0.4126
2022-09-22 05:23:04 - train: epoch 0042, iter [00820, 01251], lr: 0.001200, loss: 0.4226
2022-09-22 05:23:24 - train: epoch 0042, iter [00830, 01251], lr: 0.001200, loss: 0.4243
2022-09-22 05:23:45 - train: epoch 0042, iter [00840, 01251], lr: 0.001200, loss: 0.4138
2022-09-22 05:24:06 - train: epoch 0042, iter [00850, 01251], lr: 0.001200, loss: 0.4322
2022-09-22 05:24:26 - train: epoch 0042, iter [00860, 01251], lr: 0.001200, loss: 0.3978
2022-09-22 05:24:47 - train: epoch 0042, iter [00870, 01251], lr: 0.001200, loss: 0.4381
2022-09-22 05:25:07 - train: epoch 0042, iter [00880, 01251], lr: 0.001200, loss: 0.4112
2022-09-22 05:25:28 - train: epoch 0042, iter [00890, 01251], lr: 0.001200, loss: 0.4198
2022-09-22 05:25:49 - train: epoch 0042, iter [00900, 01251], lr: 0.001200, loss: 0.4246
2022-09-22 05:26:09 - train: epoch 0042, iter [00910, 01251], lr: 0.001200, loss: 0.4159
2022-09-22 05:26:30 - train: epoch 0042, iter [00920, 01251], lr: 0.001200, loss: 0.4210
2022-09-22 05:26:50 - train: epoch 0042, iter [00930, 01251], lr: 0.001200, loss: 0.4247
2022-09-22 05:27:11 - train: epoch 0042, iter [00940, 01251], lr: 0.001200, loss: 0.4257
2022-09-22 05:27:31 - train: epoch 0042, iter [00950, 01251], lr: 0.001200, loss: 0.4150
2022-09-22 05:27:52 - train: epoch 0042, iter [00960, 01251], lr: 0.001200, loss: 0.4141
2022-09-22 05:28:13 - train: epoch 0042, iter [00970, 01251], lr: 0.001200, loss: 0.4076
2022-09-22 05:28:33 - train: epoch 0042, iter [00980, 01251], lr: 0.001200, loss: 0.4079
2022-09-22 05:28:54 - train: epoch 0042, iter [00990, 01251], lr: 0.001200, loss: 0.4123
2022-09-22 05:29:14 - train: epoch 0042, iter [01000, 01251], lr: 0.001200, loss: 0.4343
2022-09-22 05:29:35 - train: epoch 0042, iter [01010, 01251], lr: 0.001200, loss: 0.4087
2022-09-22 05:29:56 - train: epoch 0042, iter [01020, 01251], lr: 0.001200, loss: 0.4068
2022-09-22 05:30:16 - train: epoch 0042, iter [01030, 01251], lr: 0.001200, loss: 0.4187
2022-09-22 05:30:37 - train: epoch 0042, iter [01040, 01251], lr: 0.001200, loss: 0.4323
2022-09-22 05:30:58 - train: epoch 0042, iter [01050, 01251], lr: 0.001200, loss: 0.4227
2022-09-22 05:31:18 - train: epoch 0042, iter [01060, 01251], lr: 0.001200, loss: 0.4246
2022-09-22 05:31:39 - train: epoch 0042, iter [01070, 01251], lr: 0.001200, loss: 0.4325
2022-09-22 05:32:00 - train: epoch 0042, iter [01080, 01251], lr: 0.001200, loss: 0.4356
2022-09-22 05:32:20 - train: epoch 0042, iter [01090, 01251], lr: 0.001200, loss: 0.3999
2022-09-22 05:32:41 - train: epoch 0042, iter [01100, 01251], lr: 0.001200, loss: 0.4112
2022-09-22 05:33:02 - train: epoch 0042, iter [01110, 01251], lr: 0.001200, loss: 0.4249
2022-09-22 05:33:22 - train: epoch 0042, iter [01120, 01251], lr: 0.001200, loss: 0.4183
2022-09-22 05:33:43 - train: epoch 0042, iter [01130, 01251], lr: 0.001200, loss: 0.4029
2022-09-22 05:34:04 - train: epoch 0042, iter [01140, 01251], lr: 0.001200, loss: 0.4228
2022-09-22 05:34:24 - train: epoch 0042, iter [01150, 01251], lr: 0.001200, loss: 0.4187
2022-09-22 05:34:45 - train: epoch 0042, iter [01160, 01251], lr: 0.001200, loss: 0.4218
2022-09-22 05:35:06 - train: epoch 0042, iter [01170, 01251], lr: 0.001200, loss: 0.4092
2022-09-22 05:35:26 - train: epoch 0042, iter [01180, 01251], lr: 0.001200, loss: 0.4099
2022-09-22 05:35:47 - train: epoch 0042, iter [01190, 01251], lr: 0.001200, loss: 0.4088
2022-09-22 05:36:08 - train: epoch 0042, iter [01200, 01251], lr: 0.001200, loss: 0.4233
2022-09-22 05:36:28 - train: epoch 0042, iter [01210, 01251], lr: 0.001200, loss: 0.4110
2022-09-22 05:36:49 - train: epoch 0042, iter [01220, 01251], lr: 0.001200, loss: 0.4291
2022-09-22 05:37:10 - train: epoch 0042, iter [01230, 01251], lr: 0.001200, loss: 0.4497
2022-09-22 05:37:30 - train: epoch 0042, iter [01240, 01251], lr: 0.001200, loss: 0.4091
2022-09-22 05:37:50 - train: epoch 0042, iter [01250, 01251], lr: 0.001200, loss: 0.4092
2022-09-22 05:37:54 - train: epoch 042, train_loss: 0.4207
2022-09-22 05:37:59 - until epoch: 042, best_loss: 0.4207
2022-09-22 05:37:59 - epoch 043 lr: 0.001200
2022-09-22 05:38:37 - train: epoch 0043, iter [00010, 01251], lr: 0.001200, loss: 0.4295
2022-09-22 05:38:58 - train: epoch 0043, iter [00020, 01251], lr: 0.001200, loss: 0.4033
2022-09-22 05:39:19 - train: epoch 0043, iter [00030, 01251], lr: 0.001200, loss: 0.4178
2022-09-22 05:39:40 - train: epoch 0043, iter [00040, 01251], lr: 0.001200, loss: 0.4269
2022-09-22 05:40:01 - train: epoch 0043, iter [00050, 01251], lr: 0.001200, loss: 0.4146
2022-09-22 05:40:22 - train: epoch 0043, iter [00060, 01251], lr: 0.001200, loss: 0.4221
2022-09-22 05:40:42 - train: epoch 0043, iter [00070, 01251], lr: 0.001200, loss: 0.4447
2022-09-22 05:41:03 - train: epoch 0043, iter [00080, 01251], lr: 0.001200, loss: 0.4120
2022-09-22 05:41:24 - train: epoch 0043, iter [00090, 01251], lr: 0.001200, loss: 0.4113
2022-09-22 05:41:45 - train: epoch 0043, iter [00100, 01251], lr: 0.001200, loss: 0.4348
2022-09-22 05:42:05 - train: epoch 0043, iter [00110, 01251], lr: 0.001200, loss: 0.4387
2022-09-22 05:42:26 - train: epoch 0043, iter [00120, 01251], lr: 0.001200, loss: 0.4225
2022-09-22 05:42:47 - train: epoch 0043, iter [00130, 01251], lr: 0.001200, loss: 0.4373
2022-09-22 05:43:07 - train: epoch 0043, iter [00140, 01251], lr: 0.001200, loss: 0.4240
2022-09-22 05:43:28 - train: epoch 0043, iter [00150, 01251], lr: 0.001200, loss: 0.4297
2022-09-22 05:43:49 - train: epoch 0043, iter [00160, 01251], lr: 0.001200, loss: 0.4321
2022-09-22 05:44:09 - train: epoch 0043, iter [00170, 01251], lr: 0.001200, loss: 0.4077
2022-09-22 05:44:30 - train: epoch 0043, iter [00180, 01251], lr: 0.001200, loss: 0.4099
2022-09-22 05:44:50 - train: epoch 0043, iter [00190, 01251], lr: 0.001200, loss: 0.4164
2022-09-22 05:45:11 - train: epoch 0043, iter [00200, 01251], lr: 0.001200, loss: 0.4027
2022-09-22 05:45:32 - train: epoch 0043, iter [00210, 01251], lr: 0.001200, loss: 0.4277
2022-09-22 05:45:52 - train: epoch 0043, iter [00220, 01251], lr: 0.001200, loss: 0.4290
2022-09-22 05:46:13 - train: epoch 0043, iter [00230, 01251], lr: 0.001200, loss: 0.4194
2022-09-22 05:46:34 - train: epoch 0043, iter [00240, 01251], lr: 0.001200, loss: 0.4230
2022-09-22 05:46:54 - train: epoch 0043, iter [00250, 01251], lr: 0.001200, loss: 0.4200
2022-09-22 05:47:15 - train: epoch 0043, iter [00260, 01251], lr: 0.001200, loss: 0.4170
2022-09-22 05:47:36 - train: epoch 0043, iter [00270, 01251], lr: 0.001200, loss: 0.4338
2022-09-22 05:47:56 - train: epoch 0043, iter [00280, 01251], lr: 0.001200, loss: 0.4318
2022-09-22 05:48:17 - train: epoch 0043, iter [00290, 01251], lr: 0.001200, loss: 0.4450
2022-09-22 05:48:38 - train: epoch 0043, iter [00300, 01251], lr: 0.001200, loss: 0.4091
2022-09-22 05:48:58 - train: epoch 0043, iter [00310, 01251], lr: 0.001200, loss: 0.4183
2022-09-22 05:49:19 - train: epoch 0043, iter [00320, 01251], lr: 0.001200, loss: 0.4206
2022-09-22 05:49:39 - train: epoch 0043, iter [00330, 01251], lr: 0.001200, loss: 0.4133
2022-09-22 05:50:00 - train: epoch 0043, iter [00340, 01251], lr: 0.001200, loss: 0.4400
2022-09-22 05:50:21 - train: epoch 0043, iter [00350, 01251], lr: 0.001200, loss: 0.4180
2022-09-22 05:50:41 - train: epoch 0043, iter [00360, 01251], lr: 0.001200, loss: 0.4310
2022-09-22 05:51:02 - train: epoch 0043, iter [00370, 01251], lr: 0.001200, loss: 0.4192
2022-09-22 05:51:22 - train: epoch 0043, iter [00380, 01251], lr: 0.001200, loss: 0.4222
2022-09-22 05:51:43 - train: epoch 0043, iter [00390, 01251], lr: 0.001200, loss: 0.4277
2022-09-22 05:52:04 - train: epoch 0043, iter [00400, 01251], lr: 0.001200, loss: 0.4266
2022-09-22 05:52:24 - train: epoch 0043, iter [00410, 01251], lr: 0.001200, loss: 0.3985
2022-09-22 05:52:45 - train: epoch 0043, iter [00420, 01251], lr: 0.001200, loss: 0.4153
2022-09-22 05:53:06 - train: epoch 0043, iter [00430, 01251], lr: 0.001200, loss: 0.4184
2022-09-22 05:53:26 - train: epoch 0043, iter [00440, 01251], lr: 0.001200, loss: 0.4176
2022-09-22 05:53:47 - train: epoch 0043, iter [00450, 01251], lr: 0.001200, loss: 0.4203
2022-09-22 05:54:08 - train: epoch 0043, iter [00460, 01251], lr: 0.001200, loss: 0.4320
2022-09-22 05:54:28 - train: epoch 0043, iter [00470, 01251], lr: 0.001200, loss: 0.4300
2022-09-22 05:54:49 - train: epoch 0043, iter [00480, 01251], lr: 0.001200, loss: 0.4076
2022-09-22 05:55:10 - train: epoch 0043, iter [00490, 01251], lr: 0.001200, loss: 0.4256
2022-09-22 05:55:30 - train: epoch 0043, iter [00500, 01251], lr: 0.001200, loss: 0.4368
2022-09-22 05:55:51 - train: epoch 0043, iter [00510, 01251], lr: 0.001200, loss: 0.4229
2022-09-22 05:56:11 - train: epoch 0043, iter [00520, 01251], lr: 0.001200, loss: 0.4019
2022-09-22 05:56:32 - train: epoch 0043, iter [00530, 01251], lr: 0.001200, loss: 0.4201
2022-09-22 05:56:53 - train: epoch 0043, iter [00540, 01251], lr: 0.001200, loss: 0.4115
2022-09-22 05:57:13 - train: epoch 0043, iter [00550, 01251], lr: 0.001200, loss: 0.4190
2022-09-22 05:57:34 - train: epoch 0043, iter [00560, 01251], lr: 0.001200, loss: 0.4336
2022-09-22 05:57:55 - train: epoch 0043, iter [00570, 01251], lr: 0.001200, loss: 0.4160
2022-09-22 05:58:15 - train: epoch 0043, iter [00580, 01251], lr: 0.001200, loss: 0.4153
2022-09-22 05:58:36 - train: epoch 0043, iter [00590, 01251], lr: 0.001200, loss: 0.4228
2022-09-22 05:58:57 - train: epoch 0043, iter [00600, 01251], lr: 0.001200, loss: 0.4106
2022-09-22 05:59:17 - train: epoch 0043, iter [00610, 01251], lr: 0.001200, loss: 0.4176
2022-09-22 05:59:38 - train: epoch 0043, iter [00620, 01251], lr: 0.001200, loss: 0.4355
2022-09-22 05:59:58 - train: epoch 0043, iter [00630, 01251], lr: 0.001200, loss: 0.4107
2022-09-22 06:00:19 - train: epoch 0043, iter [00640, 01251], lr: 0.001200, loss: 0.4208
2022-09-22 06:00:40 - train: epoch 0043, iter [00650, 01251], lr: 0.001200, loss: 0.4193
2022-09-22 06:01:00 - train: epoch 0043, iter [00660, 01251], lr: 0.001200, loss: 0.4287
2022-09-22 06:01:21 - train: epoch 0043, iter [00670, 01251], lr: 0.001200, loss: 0.4260
2022-09-22 06:01:42 - train: epoch 0043, iter [00680, 01251], lr: 0.001200, loss: 0.4259
2022-09-22 06:02:02 - train: epoch 0043, iter [00690, 01251], lr: 0.001200, loss: 0.4084
2022-09-22 06:02:23 - train: epoch 0043, iter [00700, 01251], lr: 0.001200, loss: 0.4191
2022-09-22 06:02:44 - train: epoch 0043, iter [00710, 01251], lr: 0.001200, loss: 0.4268
2022-09-22 06:03:04 - train: epoch 0043, iter [00720, 01251], lr: 0.001200, loss: 0.4285
2022-09-22 06:03:25 - train: epoch 0043, iter [00730, 01251], lr: 0.001200, loss: 0.4179
2022-09-22 06:03:46 - train: epoch 0043, iter [00740, 01251], lr: 0.001200, loss: 0.4192
2022-09-22 06:04:07 - train: epoch 0043, iter [00750, 01251], lr: 0.001200, loss: 0.4221
2022-09-22 06:04:27 - train: epoch 0043, iter [00760, 01251], lr: 0.001200, loss: 0.4149
2022-09-22 06:04:48 - train: epoch 0043, iter [00770, 01251], lr: 0.001200, loss: 0.4106
2022-09-22 06:05:09 - train: epoch 0043, iter [00780, 01251], lr: 0.001200, loss: 0.4241
2022-09-22 06:05:29 - train: epoch 0043, iter [00790, 01251], lr: 0.001200, loss: 0.4039
2022-09-22 06:05:50 - train: epoch 0043, iter [00800, 01251], lr: 0.001200, loss: 0.4167
2022-09-22 06:06:10 - train: epoch 0043, iter [00810, 01251], lr: 0.001200, loss: 0.4224
2022-09-22 06:06:31 - train: epoch 0043, iter [00820, 01251], lr: 0.001200, loss: 0.4122
2022-09-22 06:06:52 - train: epoch 0043, iter [00830, 01251], lr: 0.001200, loss: 0.4095
2022-09-22 06:07:12 - train: epoch 0043, iter [00840, 01251], lr: 0.001200, loss: 0.3961
2022-09-22 06:07:33 - train: epoch 0043, iter [00850, 01251], lr: 0.001200, loss: 0.4114
2022-09-22 06:07:54 - train: epoch 0043, iter [00860, 01251], lr: 0.001200, loss: 0.4280
2022-09-22 06:08:14 - train: epoch 0043, iter [00870, 01251], lr: 0.001200, loss: 0.3940
2022-09-22 06:08:35 - train: epoch 0043, iter [00880, 01251], lr: 0.001200, loss: 0.4082
2022-09-22 06:08:56 - train: epoch 0043, iter [00890, 01251], lr: 0.001200, loss: 0.4094
2022-09-22 06:09:16 - train: epoch 0043, iter [00900, 01251], lr: 0.001200, loss: 0.4025
2022-09-22 06:09:37 - train: epoch 0043, iter [00910, 01251], lr: 0.001200, loss: 0.4195
2022-09-22 06:09:58 - train: epoch 0043, iter [00920, 01251], lr: 0.001200, loss: 0.4205
2022-09-22 06:10:18 - train: epoch 0043, iter [00930, 01251], lr: 0.001200, loss: 0.4248
2022-09-22 06:10:39 - train: epoch 0043, iter [00940, 01251], lr: 0.001200, loss: 0.4155
2022-09-22 06:11:00 - train: epoch 0043, iter [00950, 01251], lr: 0.001200, loss: 0.4139
2022-09-22 06:11:21 - train: epoch 0043, iter [00960, 01251], lr: 0.001200, loss: 0.4123
2022-09-22 06:11:41 - train: epoch 0043, iter [00970, 01251], lr: 0.001200, loss: 0.4338
2022-09-22 06:12:02 - train: epoch 0043, iter [00980, 01251], lr: 0.001200, loss: 0.4253
2022-09-22 06:12:23 - train: epoch 0043, iter [00990, 01251], lr: 0.001200, loss: 0.4111
2022-09-22 06:12:43 - train: epoch 0043, iter [01000, 01251], lr: 0.001200, loss: 0.4256
2022-09-22 06:13:04 - train: epoch 0043, iter [01010, 01251], lr: 0.001200, loss: 0.4316
2022-09-22 06:13:25 - train: epoch 0043, iter [01020, 01251], lr: 0.001200, loss: 0.3881
2022-09-22 06:13:45 - train: epoch 0043, iter [01030, 01251], lr: 0.001200, loss: 0.4229
2022-09-22 06:14:06 - train: epoch 0043, iter [01040, 01251], lr: 0.001200, loss: 0.4234
2022-09-22 06:14:27 - train: epoch 0043, iter [01050, 01251], lr: 0.001200, loss: 0.4385
2022-09-22 06:14:47 - train: epoch 0043, iter [01060, 01251], lr: 0.001200, loss: 0.4278
2022-09-22 06:15:08 - train: epoch 0043, iter [01070, 01251], lr: 0.001200, loss: 0.4181
2022-09-22 06:15:29 - train: epoch 0043, iter [01080, 01251], lr: 0.001200, loss: 0.4276
2022-09-22 06:15:49 - train: epoch 0043, iter [01090, 01251], lr: 0.001200, loss: 0.4163
2022-09-22 06:16:10 - train: epoch 0043, iter [01100, 01251], lr: 0.001200, loss: 0.4187
2022-09-22 06:16:31 - train: epoch 0043, iter [01110, 01251], lr: 0.001200, loss: 0.4213
2022-09-22 06:16:51 - train: epoch 0043, iter [01120, 01251], lr: 0.001200, loss: 0.4276
2022-09-22 06:17:12 - train: epoch 0043, iter [01130, 01251], lr: 0.001200, loss: 0.4059
2022-09-22 06:17:33 - train: epoch 0043, iter [01140, 01251], lr: 0.001200, loss: 0.4307
2022-09-22 06:17:53 - train: epoch 0043, iter [01150, 01251], lr: 0.001200, loss: 0.4271
2022-09-22 06:18:14 - train: epoch 0043, iter [01160, 01251], lr: 0.001200, loss: 0.4180
2022-09-22 06:18:35 - train: epoch 0043, iter [01170, 01251], lr: 0.001200, loss: 0.4116
2022-09-22 06:18:56 - train: epoch 0043, iter [01180, 01251], lr: 0.001200, loss: 0.4104
2022-09-22 06:19:16 - train: epoch 0043, iter [01190, 01251], lr: 0.001200, loss: 0.4005
2022-09-22 06:19:37 - train: epoch 0043, iter [01200, 01251], lr: 0.001200, loss: 0.4342
2022-09-22 06:19:58 - train: epoch 0043, iter [01210, 01251], lr: 0.001200, loss: 0.4137
2022-09-22 06:20:18 - train: epoch 0043, iter [01220, 01251], lr: 0.001200, loss: 0.4168
2022-09-22 06:20:39 - train: epoch 0043, iter [01230, 01251], lr: 0.001200, loss: 0.4238
2022-09-22 06:21:00 - train: epoch 0043, iter [01240, 01251], lr: 0.001200, loss: 0.4305
2022-09-22 06:21:20 - train: epoch 0043, iter [01250, 01251], lr: 0.001200, loss: 0.4170
2022-09-22 06:21:24 - train: epoch 043, train_loss: 0.4202
2022-09-22 06:21:28 - until epoch: 043, best_loss: 0.4202
2022-09-22 06:21:28 - epoch 044 lr: 0.001200
2022-09-22 06:22:05 - train: epoch 0044, iter [00010, 01251], lr: 0.001200, loss: 0.4420
2022-09-22 06:22:26 - train: epoch 0044, iter [00020, 01251], lr: 0.001200, loss: 0.4108
2022-09-22 06:22:47 - train: epoch 0044, iter [00030, 01251], lr: 0.001200, loss: 0.4349
2022-09-22 06:23:07 - train: epoch 0044, iter [00040, 01251], lr: 0.001200, loss: 0.4138
2022-09-22 06:23:28 - train: epoch 0044, iter [00050, 01251], lr: 0.001200, loss: 0.4036
2022-09-22 06:23:49 - train: epoch 0044, iter [00060, 01251], lr: 0.001200, loss: 0.4116
2022-09-22 06:24:09 - train: epoch 0044, iter [00070, 01251], lr: 0.001200, loss: 0.4203
2022-09-22 06:24:30 - train: epoch 0044, iter [00080, 01251], lr: 0.001200, loss: 0.4240
2022-09-22 06:24:51 - train: epoch 0044, iter [00090, 01251], lr: 0.001200, loss: 0.4385
2022-09-22 06:25:11 - train: epoch 0044, iter [00100, 01251], lr: 0.001200, loss: 0.4094
2022-09-22 06:25:32 - train: epoch 0044, iter [00110, 01251], lr: 0.001200, loss: 0.3907
2022-09-22 06:25:53 - train: epoch 0044, iter [00120, 01251], lr: 0.001200, loss: 0.3951
2022-09-22 06:26:13 - train: epoch 0044, iter [00130, 01251], lr: 0.001200, loss: 0.4164
2022-09-22 06:26:34 - train: epoch 0044, iter [00140, 01251], lr: 0.001200, loss: 0.4188
2022-09-22 06:26:54 - train: epoch 0044, iter [00150, 01251], lr: 0.001200, loss: 0.4452
2022-09-22 06:27:15 - train: epoch 0044, iter [00160, 01251], lr: 0.001200, loss: 0.4151
2022-09-22 06:27:36 - train: epoch 0044, iter [00170, 01251], lr: 0.001200, loss: 0.4261
2022-09-22 06:27:56 - train: epoch 0044, iter [00180, 01251], lr: 0.001200, loss: 0.4336
2022-09-22 06:28:17 - train: epoch 0044, iter [00190, 01251], lr: 0.001200, loss: 0.4237
2022-09-22 06:28:38 - train: epoch 0044, iter [00200, 01251], lr: 0.001200, loss: 0.4144
2022-09-22 06:28:58 - train: epoch 0044, iter [00210, 01251], lr: 0.001200, loss: 0.4101
2022-09-22 06:29:19 - train: epoch 0044, iter [00220, 01251], lr: 0.001200, loss: 0.4283
2022-09-22 06:29:40 - train: epoch 0044, iter [00230, 01251], lr: 0.001200, loss: 0.4276
2022-09-22 06:30:00 - train: epoch 0044, iter [00240, 01251], lr: 0.001200, loss: 0.4195
2022-09-22 06:30:21 - train: epoch 0044, iter [00250, 01251], lr: 0.001200, loss: 0.4155
2022-09-22 06:30:42 - train: epoch 0044, iter [00260, 01251], lr: 0.001200, loss: 0.4069
2022-09-22 06:31:02 - train: epoch 0044, iter [00270, 01251], lr: 0.001200, loss: 0.4257
2022-09-22 06:31:23 - train: epoch 0044, iter [00280, 01251], lr: 0.001200, loss: 0.4352
2022-09-22 06:31:44 - train: epoch 0044, iter [00290, 01251], lr: 0.001200, loss: 0.4311
2022-09-22 06:32:04 - train: epoch 0044, iter [00300, 01251], lr: 0.001200, loss: 0.4143
2022-09-22 06:32:25 - train: epoch 0044, iter [00310, 01251], lr: 0.001200, loss: 0.4023
2022-09-22 06:32:46 - train: epoch 0044, iter [00320, 01251], lr: 0.001200, loss: 0.4228
2022-09-22 06:33:06 - train: epoch 0044, iter [00330, 01251], lr: 0.001200, loss: 0.4274
2022-09-22 06:33:27 - train: epoch 0044, iter [00340, 01251], lr: 0.001200, loss: 0.4023
2022-09-22 06:33:47 - train: epoch 0044, iter [00350, 01251], lr: 0.001200, loss: 0.3977
2022-09-22 06:34:08 - train: epoch 0044, iter [00360, 01251], lr: 0.001200, loss: 0.4319
2022-09-22 06:34:29 - train: epoch 0044, iter [00370, 01251], lr: 0.001200, loss: 0.4238
2022-09-22 06:34:50 - train: epoch 0044, iter [00380, 01251], lr: 0.001200, loss: 0.4419
2022-09-22 06:35:10 - train: epoch 0044, iter [00390, 01251], lr: 0.001200, loss: 0.4452
2022-09-22 06:35:31 - train: epoch 0044, iter [00400, 01251], lr: 0.001200, loss: 0.4295
2022-09-22 06:35:52 - train: epoch 0044, iter [00410, 01251], lr: 0.001200, loss: 0.4336
2022-09-22 06:36:12 - train: epoch 0044, iter [00420, 01251], lr: 0.001200, loss: 0.4180
2022-09-22 06:36:33 - train: epoch 0044, iter [00430, 01251], lr: 0.001200, loss: 0.4115
2022-09-22 06:36:53 - train: epoch 0044, iter [00440, 01251], lr: 0.001200, loss: 0.4234
2022-09-22 06:37:14 - train: epoch 0044, iter [00450, 01251], lr: 0.001200, loss: 0.4129
2022-09-22 06:37:35 - train: epoch 0044, iter [00460, 01251], lr: 0.001200, loss: 0.4114
2022-09-22 06:37:55 - train: epoch 0044, iter [00470, 01251], lr: 0.001200, loss: 0.4014
2022-09-22 06:38:16 - train: epoch 0044, iter [00480, 01251], lr: 0.001200, loss: 0.4077
2022-09-22 06:38:36 - train: epoch 0044, iter [00490, 01251], lr: 0.001200, loss: 0.4092
2022-09-22 06:38:57 - train: epoch 0044, iter [00500, 01251], lr: 0.001200, loss: 0.4325
2022-09-22 06:39:18 - train: epoch 0044, iter [00510, 01251], lr: 0.001200, loss: 0.4232
2022-09-22 06:39:38 - train: epoch 0044, iter [00520, 01251], lr: 0.001200, loss: 0.4245
2022-09-22 06:39:59 - train: epoch 0044, iter [00530, 01251], lr: 0.001200, loss: 0.4230
2022-09-22 06:40:19 - train: epoch 0044, iter [00540, 01251], lr: 0.001200, loss: 0.4152
2022-09-22 06:40:40 - train: epoch 0044, iter [00550, 01251], lr: 0.001200, loss: 0.4256
2022-09-22 06:41:01 - train: epoch 0044, iter [00560, 01251], lr: 0.001200, loss: 0.4104
2022-09-22 06:41:21 - train: epoch 0044, iter [00570, 01251], lr: 0.001200, loss: 0.4307
2022-09-22 06:41:42 - train: epoch 0044, iter [00580, 01251], lr: 0.001200, loss: 0.4312
2022-09-22 06:42:02 - train: epoch 0044, iter [00590, 01251], lr: 0.001200, loss: 0.4146
2022-09-22 06:42:23 - train: epoch 0044, iter [00600, 01251], lr: 0.001200, loss: 0.4121
2022-09-22 06:42:44 - train: epoch 0044, iter [00610, 01251], lr: 0.001200, loss: 0.4105
2022-09-22 06:43:04 - train: epoch 0044, iter [00620, 01251], lr: 0.001200, loss: 0.4357
2022-09-22 06:43:25 - train: epoch 0044, iter [00630, 01251], lr: 0.001200, loss: 0.4265
2022-09-22 06:43:46 - train: epoch 0044, iter [00640, 01251], lr: 0.001200, loss: 0.4351
2022-09-22 06:44:06 - train: epoch 0044, iter [00650, 01251], lr: 0.001200, loss: 0.4108
2022-09-22 06:44:27 - train: epoch 0044, iter [00660, 01251], lr: 0.001200, loss: 0.4304
2022-09-22 06:44:48 - train: epoch 0044, iter [00670, 01251], lr: 0.001200, loss: 0.4307
2022-09-22 06:45:08 - train: epoch 0044, iter [00680, 01251], lr: 0.001200, loss: 0.4317
2022-09-22 06:45:29 - train: epoch 0044, iter [00690, 01251], lr: 0.001200, loss: 0.4245
2022-09-22 06:45:49 - train: epoch 0044, iter [00700, 01251], lr: 0.001200, loss: 0.4399
2022-09-22 06:46:10 - train: epoch 0044, iter [00710, 01251], lr: 0.001200, loss: 0.4164
2022-09-22 06:46:31 - train: epoch 0044, iter [00720, 01251], lr: 0.001200, loss: 0.4259
2022-09-22 06:46:51 - train: epoch 0044, iter [00730, 01251], lr: 0.001200, loss: 0.4097
2022-09-22 06:47:12 - train: epoch 0044, iter [00740, 01251], lr: 0.001200, loss: 0.4279
2022-09-22 06:47:33 - train: epoch 0044, iter [00750, 01251], lr: 0.001200, loss: 0.4264
2022-09-22 06:47:53 - train: epoch 0044, iter [00760, 01251], lr: 0.001200, loss: 0.4101
2022-09-22 06:48:14 - train: epoch 0044, iter [00770, 01251], lr: 0.001200, loss: 0.4172
2022-09-22 06:48:34 - train: epoch 0044, iter [00780, 01251], lr: 0.001200, loss: 0.4151
2022-09-22 06:48:55 - train: epoch 0044, iter [00790, 01251], lr: 0.001200, loss: 0.4376
2022-09-22 06:49:16 - train: epoch 0044, iter [00800, 01251], lr: 0.001200, loss: 0.4347
2022-09-22 06:49:36 - train: epoch 0044, iter [00810, 01251], lr: 0.001200, loss: 0.4267
2022-09-22 06:49:57 - train: epoch 0044, iter [00820, 01251], lr: 0.001200, loss: 0.3997
2022-09-22 06:50:18 - train: epoch 0044, iter [00830, 01251], lr: 0.001200, loss: 0.4133
2022-09-22 06:50:38 - train: epoch 0044, iter [00840, 01251], lr: 0.001200, loss: 0.4122
2022-09-22 06:50:59 - train: epoch 0044, iter [00850, 01251], lr: 0.001200, loss: 0.4180
2022-09-22 06:51:20 - train: epoch 0044, iter [00860, 01251], lr: 0.001200, loss: 0.3914
2022-09-22 06:51:40 - train: epoch 0044, iter [00870, 01251], lr: 0.001200, loss: 0.4112
2022-09-22 06:52:01 - train: epoch 0044, iter [00880, 01251], lr: 0.001200, loss: 0.4295
2022-09-22 06:52:22 - train: epoch 0044, iter [00890, 01251], lr: 0.001200, loss: 0.4154
2022-09-22 06:52:42 - train: epoch 0044, iter [00900, 01251], lr: 0.001200, loss: 0.4156
2022-09-22 06:53:03 - train: epoch 0044, iter [00910, 01251], lr: 0.001200, loss: 0.4255
2022-09-22 06:53:23 - train: epoch 0044, iter [00920, 01251], lr: 0.001200, loss: 0.4220
2022-09-22 06:53:44 - train: epoch 0044, iter [00930, 01251], lr: 0.001200, loss: 0.4129
2022-09-22 06:54:05 - train: epoch 0044, iter [00940, 01251], lr: 0.001200, loss: 0.4169
2022-09-22 06:54:25 - train: epoch 0044, iter [00950, 01251], lr: 0.001200, loss: 0.4197
2022-09-22 06:54:46 - train: epoch 0044, iter [00960, 01251], lr: 0.001200, loss: 0.4191
2022-09-22 06:55:06 - train: epoch 0044, iter [00970, 01251], lr: 0.001200, loss: 0.4183
2022-09-22 06:55:27 - train: epoch 0044, iter [00980, 01251], lr: 0.001200, loss: 0.4096
2022-09-22 06:55:48 - train: epoch 0044, iter [00990, 01251], lr: 0.001200, loss: 0.4336
2022-09-22 06:56:09 - train: epoch 0044, iter [01000, 01251], lr: 0.001200, loss: 0.4214
2022-09-22 06:56:29 - train: epoch 0044, iter [01010, 01251], lr: 0.001200, loss: 0.4350
2022-09-22 06:56:50 - train: epoch 0044, iter [01020, 01251], lr: 0.001200, loss: 0.4168
2022-09-22 06:57:11 - train: epoch 0044, iter [01030, 01251], lr: 0.001200, loss: 0.4203
2022-09-22 06:57:31 - train: epoch 0044, iter [01040, 01251], lr: 0.001200, loss: 0.4145
2022-09-22 06:57:52 - train: epoch 0044, iter [01050, 01251], lr: 0.001200, loss: 0.3975
2022-09-22 06:58:13 - train: epoch 0044, iter [01060, 01251], lr: 0.001200, loss: 0.4253
2022-09-22 06:58:33 - train: epoch 0044, iter [01070, 01251], lr: 0.001200, loss: 0.4059
2022-09-22 06:58:54 - train: epoch 0044, iter [01080, 01251], lr: 0.001200, loss: 0.4236
2022-09-22 06:59:15 - train: epoch 0044, iter [01090, 01251], lr: 0.001200, loss: 0.4160
2022-09-22 06:59:35 - train: epoch 0044, iter [01100, 01251], lr: 0.001200, loss: 0.4294
2022-09-22 06:59:56 - train: epoch 0044, iter [01110, 01251], lr: 0.001200, loss: 0.4353
2022-09-22 07:00:17 - train: epoch 0044, iter [01120, 01251], lr: 0.001200, loss: 0.4209
2022-09-22 07:00:37 - train: epoch 0044, iter [01130, 01251], lr: 0.001200, loss: 0.4215
2022-09-22 07:00:58 - train: epoch 0044, iter [01140, 01251], lr: 0.001200, loss: 0.4355
2022-09-22 07:01:19 - train: epoch 0044, iter [01150, 01251], lr: 0.001200, loss: 0.4220
2022-09-22 07:01:39 - train: epoch 0044, iter [01160, 01251], lr: 0.001200, loss: 0.4272
2022-09-22 07:02:00 - train: epoch 0044, iter [01170, 01251], lr: 0.001200, loss: 0.4088
2022-09-22 07:02:21 - train: epoch 0044, iter [01180, 01251], lr: 0.001200, loss: 0.4294
2022-09-22 07:02:42 - train: epoch 0044, iter [01190, 01251], lr: 0.001200, loss: 0.4123
2022-09-22 07:03:02 - train: epoch 0044, iter [01200, 01251], lr: 0.001200, loss: 0.4012
2022-09-22 07:03:23 - train: epoch 0044, iter [01210, 01251], lr: 0.001200, loss: 0.4168
2022-09-22 07:03:44 - train: epoch 0044, iter [01220, 01251], lr: 0.001200, loss: 0.4264
2022-09-22 07:04:04 - train: epoch 0044, iter [01230, 01251], lr: 0.001200, loss: 0.4343
2022-09-22 07:04:25 - train: epoch 0044, iter [01240, 01251], lr: 0.001200, loss: 0.4119
2022-09-22 07:04:45 - train: epoch 0044, iter [01250, 01251], lr: 0.001200, loss: 0.4246
2022-09-22 07:04:49 - train: epoch 044, train_loss: 0.4200
2022-09-22 07:04:53 - until epoch: 044, best_loss: 0.4200
2022-09-22 07:04:53 - epoch 045 lr: 0.001200
2022-09-22 07:05:30 - train: epoch 0045, iter [00010, 01251], lr: 0.001200, loss: 0.4303
2022-09-22 07:05:51 - train: epoch 0045, iter [00020, 01251], lr: 0.001200, loss: 0.4006
2022-09-22 07:06:12 - train: epoch 0045, iter [00030, 01251], lr: 0.001200, loss: 0.4267
2022-09-22 07:06:33 - train: epoch 0045, iter [00040, 01251], lr: 0.001200, loss: 0.4262
2022-09-22 07:06:53 - train: epoch 0045, iter [00050, 01251], lr: 0.001200, loss: 0.4175
2022-09-22 07:07:14 - train: epoch 0045, iter [00060, 01251], lr: 0.001200, loss: 0.4118
2022-09-22 07:07:34 - train: epoch 0045, iter [00070, 01251], lr: 0.001200, loss: 0.4247
2022-09-22 07:07:55 - train: epoch 0045, iter [00080, 01251], lr: 0.001200, loss: 0.4161
2022-09-22 07:08:16 - train: epoch 0045, iter [00090, 01251], lr: 0.001200, loss: 0.4211
2022-09-22 07:08:37 - train: epoch 0045, iter [00100, 01251], lr: 0.001200, loss: 0.4222
2022-09-22 07:08:57 - train: epoch 0045, iter [00110, 01251], lr: 0.001200, loss: 0.4238
2022-09-22 07:09:18 - train: epoch 0045, iter [00120, 01251], lr: 0.001200, loss: 0.4419
2022-09-22 07:09:39 - train: epoch 0045, iter [00130, 01251], lr: 0.001200, loss: 0.4428
2022-09-22 07:10:00 - train: epoch 0045, iter [00140, 01251], lr: 0.001200, loss: 0.3945
2022-09-22 07:10:20 - train: epoch 0045, iter [00150, 01251], lr: 0.001200, loss: 0.4022
2022-09-22 07:10:41 - train: epoch 0045, iter [00160, 01251], lr: 0.001200, loss: 0.4044
2022-09-22 07:11:02 - train: epoch 0045, iter [00170, 01251], lr: 0.001200, loss: 0.4278
2022-09-22 07:11:23 - train: epoch 0045, iter [00180, 01251], lr: 0.001200, loss: 0.4200
2022-09-22 07:11:43 - train: epoch 0045, iter [00190, 01251], lr: 0.001200, loss: 0.4103
2022-09-22 07:12:04 - train: epoch 0045, iter [00200, 01251], lr: 0.001200, loss: 0.4169
2022-09-22 07:12:25 - train: epoch 0045, iter [00210, 01251], lr: 0.001200, loss: 0.4175
2022-09-22 07:12:46 - train: epoch 0045, iter [00220, 01251], lr: 0.001200, loss: 0.4203
2022-09-22 07:13:07 - train: epoch 0045, iter [00230, 01251], lr: 0.001200, loss: 0.4135
2022-09-22 07:13:27 - train: epoch 0045, iter [00240, 01251], lr: 0.001200, loss: 0.4414
2022-09-22 07:13:48 - train: epoch 0045, iter [00250, 01251], lr: 0.001200, loss: 0.4348
2022-09-22 07:14:09 - train: epoch 0045, iter [00260, 01251], lr: 0.001200, loss: 0.4218
2022-09-22 07:14:29 - train: epoch 0045, iter [00270, 01251], lr: 0.001200, loss: 0.4167
2022-09-22 07:14:50 - train: epoch 0045, iter [00280, 01251], lr: 0.001200, loss: 0.4061
2022-09-22 07:15:11 - train: epoch 0045, iter [00290, 01251], lr: 0.001200, loss: 0.4390
2022-09-22 07:15:32 - train: epoch 0045, iter [00300, 01251], lr: 0.001200, loss: 0.4323
2022-09-22 07:15:52 - train: epoch 0045, iter [00310, 01251], lr: 0.001200, loss: 0.4168
2022-09-22 07:16:13 - train: epoch 0045, iter [00320, 01251], lr: 0.001200, loss: 0.4169
2022-09-22 07:16:34 - train: epoch 0045, iter [00330, 01251], lr: 0.001200, loss: 0.4108
2022-09-22 07:16:55 - train: epoch 0045, iter [00340, 01251], lr: 0.001200, loss: 0.4361
2022-09-22 07:17:15 - train: epoch 0045, iter [00350, 01251], lr: 0.001200, loss: 0.4145
2022-09-22 07:17:36 - train: epoch 0045, iter [00360, 01251], lr: 0.001200, loss: 0.4418
2022-09-22 07:17:57 - train: epoch 0045, iter [00370, 01251], lr: 0.001200, loss: 0.4079
2022-09-22 07:18:18 - train: epoch 0045, iter [00380, 01251], lr: 0.001200, loss: 0.4324
2022-09-22 07:18:39 - train: epoch 0045, iter [00390, 01251], lr: 0.001200, loss: 0.4195
2022-09-22 07:18:59 - train: epoch 0045, iter [00400, 01251], lr: 0.001200, loss: 0.4090
2022-09-22 07:19:20 - train: epoch 0045, iter [00410, 01251], lr: 0.001200, loss: 0.4052
2022-09-22 07:19:41 - train: epoch 0045, iter [00420, 01251], lr: 0.001200, loss: 0.4380
2022-09-22 07:20:02 - train: epoch 0045, iter [00430, 01251], lr: 0.001200, loss: 0.4203
2022-09-22 07:20:22 - train: epoch 0045, iter [00440, 01251], lr: 0.001200, loss: 0.4196
2022-09-22 07:20:43 - train: epoch 0045, iter [00450, 01251], lr: 0.001200, loss: 0.4212
2022-09-22 07:21:04 - train: epoch 0045, iter [00460, 01251], lr: 0.001200, loss: 0.4362
2022-09-22 07:21:24 - train: epoch 0045, iter [00470, 01251], lr: 0.001200, loss: 0.4297
2022-09-22 07:21:45 - train: epoch 0045, iter [00480, 01251], lr: 0.001200, loss: 0.4318
2022-09-22 07:22:06 - train: epoch 0045, iter [00490, 01251], lr: 0.001200, loss: 0.4399
2022-09-22 07:22:26 - train: epoch 0045, iter [00500, 01251], lr: 0.001200, loss: 0.4260
2022-09-22 07:22:47 - train: epoch 0045, iter [00510, 01251], lr: 0.001200, loss: 0.4090
2022-09-22 07:23:08 - train: epoch 0045, iter [00520, 01251], lr: 0.001200, loss: 0.3930
2022-09-22 07:23:29 - train: epoch 0045, iter [00530, 01251], lr: 0.001200, loss: 0.4022
2022-09-22 07:23:50 - train: epoch 0045, iter [00540, 01251], lr: 0.001200, loss: 0.4175
2022-09-22 07:24:11 - train: epoch 0045, iter [00550, 01251], lr: 0.001200, loss: 0.4117
2022-09-22 07:24:31 - train: epoch 0045, iter [00560, 01251], lr: 0.001200, loss: 0.4076
2022-09-22 07:24:52 - train: epoch 0045, iter [00570, 01251], lr: 0.001200, loss: 0.4134
2022-09-22 07:25:13 - train: epoch 0045, iter [00580, 01251], lr: 0.001200, loss: 0.4344
2022-09-22 07:25:34 - train: epoch 0045, iter [00590, 01251], lr: 0.001200, loss: 0.4147
2022-09-22 07:25:54 - train: epoch 0045, iter [00600, 01251], lr: 0.001200, loss: 0.4238
2022-09-22 07:26:15 - train: epoch 0045, iter [00610, 01251], lr: 0.001200, loss: 0.4103
2022-09-22 07:26:36 - train: epoch 0045, iter [00620, 01251], lr: 0.001200, loss: 0.4208
2022-09-22 07:26:57 - train: epoch 0045, iter [00630, 01251], lr: 0.001200, loss: 0.4338
2022-09-22 07:27:17 - train: epoch 0045, iter [00640, 01251], lr: 0.001200, loss: 0.4279
2022-09-22 07:27:38 - train: epoch 0045, iter [00650, 01251], lr: 0.001200, loss: 0.4163
2022-09-22 07:27:59 - train: epoch 0045, iter [00660, 01251], lr: 0.001200, loss: 0.4081
2022-09-22 07:28:20 - train: epoch 0045, iter [00670, 01251], lr: 0.001200, loss: 0.4163
2022-09-22 07:28:41 - train: epoch 0045, iter [00680, 01251], lr: 0.001200, loss: 0.4343
2022-09-22 07:29:01 - train: epoch 0045, iter [00690, 01251], lr: 0.001200, loss: 0.4074
2022-09-22 07:29:22 - train: epoch 0045, iter [00700, 01251], lr: 0.001200, loss: 0.4204
2022-09-22 07:29:43 - train: epoch 0045, iter [00710, 01251], lr: 0.001200, loss: 0.4166
2022-09-22 07:30:04 - train: epoch 0045, iter [00720, 01251], lr: 0.001200, loss: 0.4192
2022-09-22 07:30:24 - train: epoch 0045, iter [00730, 01251], lr: 0.001200, loss: 0.4214
2022-09-22 07:30:45 - train: epoch 0045, iter [00740, 01251], lr: 0.001200, loss: 0.4296
2022-09-22 07:31:06 - train: epoch 0045, iter [00750, 01251], lr: 0.001200, loss: 0.4108
2022-09-22 07:31:27 - train: epoch 0045, iter [00760, 01251], lr: 0.001200, loss: 0.4236
2022-09-22 07:31:48 - train: epoch 0045, iter [00770, 01251], lr: 0.001200, loss: 0.4085
2022-09-22 07:32:08 - train: epoch 0045, iter [00780, 01251], lr: 0.001200, loss: 0.4178
2022-09-22 07:32:29 - train: epoch 0045, iter [00790, 01251], lr: 0.001200, loss: 0.4100
2022-09-22 07:32:50 - train: epoch 0045, iter [00800, 01251], lr: 0.001200, loss: 0.4304
2022-09-22 07:33:11 - train: epoch 0045, iter [00810, 01251], lr: 0.001200, loss: 0.4048
2022-09-22 07:33:32 - train: epoch 0045, iter [00820, 01251], lr: 0.001200, loss: 0.4278
2022-09-22 07:33:52 - train: epoch 0045, iter [00830, 01251], lr: 0.001200, loss: 0.4186
2022-09-22 07:34:13 - train: epoch 0045, iter [00840, 01251], lr: 0.001200, loss: 0.4300
2022-09-22 07:34:34 - train: epoch 0045, iter [00850, 01251], lr: 0.001199, loss: 0.4092
2022-09-22 07:34:54 - train: epoch 0045, iter [00860, 01251], lr: 0.001199, loss: 0.4046
2022-09-22 07:35:15 - train: epoch 0045, iter [00870, 01251], lr: 0.001199, loss: 0.4435
2022-09-22 07:35:36 - train: epoch 0045, iter [00880, 01251], lr: 0.001199, loss: 0.3998
2022-09-22 07:35:57 - train: epoch 0045, iter [00890, 01251], lr: 0.001199, loss: 0.4320
2022-09-22 07:36:18 - train: epoch 0045, iter [00900, 01251], lr: 0.001199, loss: 0.4068
2022-09-22 07:36:38 - train: epoch 0045, iter [00910, 01251], lr: 0.001199, loss: 0.4103
2022-09-22 07:36:59 - train: epoch 0045, iter [00920, 01251], lr: 0.001199, loss: 0.4474
2022-09-22 07:37:20 - train: epoch 0045, iter [00930, 01251], lr: 0.001199, loss: 0.4182
2022-09-22 07:37:41 - train: epoch 0045, iter [00940, 01251], lr: 0.001199, loss: 0.4238
2022-09-22 07:38:02 - train: epoch 0045, iter [00950, 01251], lr: 0.001199, loss: 0.4037
2022-09-22 07:38:22 - train: epoch 0045, iter [00960, 01251], lr: 0.001199, loss: 0.3901
2022-09-22 07:38:43 - train: epoch 0045, iter [00970, 01251], lr: 0.001199, loss: 0.4246
2022-09-22 07:39:04 - train: epoch 0045, iter [00980, 01251], lr: 0.001199, loss: 0.4101
2022-09-22 07:39:25 - train: epoch 0045, iter [00990, 01251], lr: 0.001199, loss: 0.4292
2022-09-22 07:39:46 - train: epoch 0045, iter [01000, 01251], lr: 0.001199, loss: 0.4121
2022-09-22 07:40:06 - train: epoch 0045, iter [01010, 01251], lr: 0.001199, loss: 0.4248
2022-09-22 07:40:27 - train: epoch 0045, iter [01020, 01251], lr: 0.001199, loss: 0.4065
2022-09-22 07:40:48 - train: epoch 0045, iter [01030, 01251], lr: 0.001199, loss: 0.4091
2022-09-22 07:41:09 - train: epoch 0045, iter [01040, 01251], lr: 0.001199, loss: 0.4436
2022-09-22 07:41:30 - train: epoch 0045, iter [01050, 01251], lr: 0.001199, loss: 0.4300
2022-09-22 07:41:50 - train: epoch 0045, iter [01060, 01251], lr: 0.001199, loss: 0.4355
2022-09-22 07:42:11 - train: epoch 0045, iter [01070, 01251], lr: 0.001199, loss: 0.4116
2022-09-22 07:42:32 - train: epoch 0045, iter [01080, 01251], lr: 0.001199, loss: 0.4099
2022-09-22 07:42:53 - train: epoch 0045, iter [01090, 01251], lr: 0.001199, loss: 0.4367
2022-09-22 07:43:14 - train: epoch 0045, iter [01100, 01251], lr: 0.001199, loss: 0.4213
2022-09-22 07:43:35 - train: epoch 0045, iter [01110, 01251], lr: 0.001199, loss: 0.4192
2022-09-22 07:43:55 - train: epoch 0045, iter [01120, 01251], lr: 0.001199, loss: 0.4146
2022-09-22 07:44:16 - train: epoch 0045, iter [01130, 01251], lr: 0.001199, loss: 0.4205
2022-09-22 07:44:37 - train: epoch 0045, iter [01140, 01251], lr: 0.001199, loss: 0.4426
2022-09-22 07:44:58 - train: epoch 0045, iter [01150, 01251], lr: 0.001199, loss: 0.4197
2022-09-22 07:45:19 - train: epoch 0045, iter [01160, 01251], lr: 0.001199, loss: 0.4058
2022-09-22 07:45:40 - train: epoch 0045, iter [01170, 01251], lr: 0.001199, loss: 0.4288
2022-09-22 07:46:01 - train: epoch 0045, iter [01180, 01251], lr: 0.001199, loss: 0.4326
2022-09-22 07:46:22 - train: epoch 0045, iter [01190, 01251], lr: 0.001199, loss: 0.4260
2022-09-22 07:46:42 - train: epoch 0045, iter [01200, 01251], lr: 0.001199, loss: 0.4370
2022-09-22 07:47:03 - train: epoch 0045, iter [01210, 01251], lr: 0.001199, loss: 0.4179
2022-09-22 07:47:24 - train: epoch 0045, iter [01220, 01251], lr: 0.001199, loss: 0.4149
2022-09-22 07:47:45 - train: epoch 0045, iter [01230, 01251], lr: 0.001199, loss: 0.4304
2022-09-22 07:48:06 - train: epoch 0045, iter [01240, 01251], lr: 0.001199, loss: 0.4198
2022-09-22 07:48:26 - train: epoch 0045, iter [01250, 01251], lr: 0.001199, loss: 0.4149
2022-09-22 07:48:30 - train: epoch 045, train_loss: 0.4196
2022-09-22 07:48:35 - until epoch: 045, best_loss: 0.4196
2022-09-22 07:48:35 - epoch 046 lr: 0.001199
2022-09-22 07:49:13 - train: epoch 0046, iter [00010, 01251], lr: 0.001199, loss: 0.4245
2022-09-22 07:49:33 - train: epoch 0046, iter [00020, 01251], lr: 0.001199, loss: 0.4281
2022-09-22 07:49:54 - train: epoch 0046, iter [00030, 01251], lr: 0.001199, loss: 0.4168
2022-09-22 07:50:15 - train: epoch 0046, iter [00040, 01251], lr: 0.001199, loss: 0.4211
2022-09-22 07:50:36 - train: epoch 0046, iter [00050, 01251], lr: 0.001199, loss: 0.4294
2022-09-22 07:50:56 - train: epoch 0046, iter [00060, 01251], lr: 0.001199, loss: 0.4102
2022-09-22 07:51:17 - train: epoch 0046, iter [00070, 01251], lr: 0.001199, loss: 0.4056
2022-09-22 07:51:38 - train: epoch 0046, iter [00080, 01251], lr: 0.001199, loss: 0.4290
2022-09-22 07:51:58 - train: epoch 0046, iter [00090, 01251], lr: 0.001199, loss: 0.4199
2022-09-22 07:52:19 - train: epoch 0046, iter [00100, 01251], lr: 0.001199, loss: 0.4147
2022-09-22 07:52:40 - train: epoch 0046, iter [00110, 01251], lr: 0.001199, loss: 0.4269
2022-09-22 07:53:00 - train: epoch 0046, iter [00120, 01251], lr: 0.001199, loss: 0.4067
2022-09-22 07:53:21 - train: epoch 0046, iter [00130, 01251], lr: 0.001199, loss: 0.4144
2022-09-22 07:53:42 - train: epoch 0046, iter [00140, 01251], lr: 0.001199, loss: 0.4292
2022-09-22 07:54:02 - train: epoch 0046, iter [00150, 01251], lr: 0.001199, loss: 0.4106
2022-09-22 07:54:23 - train: epoch 0046, iter [00160, 01251], lr: 0.001199, loss: 0.4204
2022-09-22 07:54:43 - train: epoch 0046, iter [00170, 01251], lr: 0.001199, loss: 0.4293
2022-09-22 07:55:04 - train: epoch 0046, iter [00180, 01251], lr: 0.001199, loss: 0.4111
2022-09-22 07:55:25 - train: epoch 0046, iter [00190, 01251], lr: 0.001199, loss: 0.4007
2022-09-22 07:55:45 - train: epoch 0046, iter [00200, 01251], lr: 0.001199, loss: 0.4120
2022-09-22 07:56:06 - train: epoch 0046, iter [00210, 01251], lr: 0.001199, loss: 0.4396
2022-09-22 07:56:27 - train: epoch 0046, iter [00220, 01251], lr: 0.001199, loss: 0.4324
2022-09-22 07:56:48 - train: epoch 0046, iter [00230, 01251], lr: 0.001199, loss: 0.4324
2022-09-22 07:57:08 - train: epoch 0046, iter [00240, 01251], lr: 0.001199, loss: 0.3989
2022-09-22 07:57:29 - train: epoch 0046, iter [00250, 01251], lr: 0.001199, loss: 0.3946
2022-09-22 07:57:49 - train: epoch 0046, iter [00260, 01251], lr: 0.001199, loss: 0.4186
2022-09-22 07:58:10 - train: epoch 0046, iter [00270, 01251], lr: 0.001199, loss: 0.4260
2022-09-22 07:58:31 - train: epoch 0046, iter [00280, 01251], lr: 0.001199, loss: 0.4286
2022-09-22 07:58:52 - train: epoch 0046, iter [00290, 01251], lr: 0.001199, loss: 0.4263
2022-09-22 07:59:12 - train: epoch 0046, iter [00300, 01251], lr: 0.001199, loss: 0.4205
2022-09-22 07:59:33 - train: epoch 0046, iter [00310, 01251], lr: 0.001199, loss: 0.4381
2022-09-22 07:59:53 - train: epoch 0046, iter [00320, 01251], lr: 0.001199, loss: 0.4273
2022-09-22 08:00:14 - train: epoch 0046, iter [00330, 01251], lr: 0.001199, loss: 0.4201
2022-09-22 08:00:35 - train: epoch 0046, iter [00340, 01251], lr: 0.001199, loss: 0.4040
2022-09-22 08:00:55 - train: epoch 0046, iter [00350, 01251], lr: 0.001199, loss: 0.4198
2022-09-22 08:01:16 - train: epoch 0046, iter [00360, 01251], lr: 0.001199, loss: 0.4075
2022-09-22 08:01:36 - train: epoch 0046, iter [00370, 01251], lr: 0.001199, loss: 0.4365
2022-09-22 08:01:57 - train: epoch 0046, iter [00380, 01251], lr: 0.001199, loss: 0.4253
2022-09-22 08:02:18 - train: epoch 0046, iter [00390, 01251], lr: 0.001199, loss: 0.4248
2022-09-22 08:02:38 - train: epoch 0046, iter [00400, 01251], lr: 0.001199, loss: 0.4055
2022-09-22 08:02:59 - train: epoch 0046, iter [00410, 01251], lr: 0.001199, loss: 0.4413
2022-09-22 08:03:20 - train: epoch 0046, iter [00420, 01251], lr: 0.001199, loss: 0.4126
2022-09-22 08:03:40 - train: epoch 0046, iter [00430, 01251], lr: 0.001199, loss: 0.4281
2022-09-22 08:04:01 - train: epoch 0046, iter [00440, 01251], lr: 0.001199, loss: 0.4275
2022-09-22 08:04:21 - train: epoch 0046, iter [00450, 01251], lr: 0.001199, loss: 0.4174
2022-09-22 08:04:42 - train: epoch 0046, iter [00460, 01251], lr: 0.001199, loss: 0.4115
2022-09-22 08:05:03 - train: epoch 0046, iter [00470, 01251], lr: 0.001199, loss: 0.4237
2022-09-22 08:05:23 - train: epoch 0046, iter [00480, 01251], lr: 0.001199, loss: 0.4024
2022-09-22 08:05:44 - train: epoch 0046, iter [00490, 01251], lr: 0.001199, loss: 0.4290
2022-09-22 08:06:05 - train: epoch 0046, iter [00500, 01251], lr: 0.001199, loss: 0.4115
2022-09-22 08:06:25 - train: epoch 0046, iter [00510, 01251], lr: 0.001199, loss: 0.4261
2022-09-22 08:06:46 - train: epoch 0046, iter [00520, 01251], lr: 0.001199, loss: 0.4190
2022-09-22 08:07:06 - train: epoch 0046, iter [00530, 01251], lr: 0.001199, loss: 0.4262
2022-09-22 08:07:27 - train: epoch 0046, iter [00540, 01251], lr: 0.001199, loss: 0.4112
2022-09-22 08:07:48 - train: epoch 0046, iter [00550, 01251], lr: 0.001199, loss: 0.4212
2022-09-22 08:08:08 - train: epoch 0046, iter [00560, 01251], lr: 0.001199, loss: 0.4106
2022-09-22 08:08:29 - train: epoch 0046, iter [00570, 01251], lr: 0.001199, loss: 0.4212
2022-09-22 08:08:50 - train: epoch 0046, iter [00580, 01251], lr: 0.001199, loss: 0.4206
2022-09-22 08:09:11 - train: epoch 0046, iter [00590, 01251], lr: 0.001199, loss: 0.4061
2022-09-22 08:09:31 - train: epoch 0046, iter [00600, 01251], lr: 0.001199, loss: 0.4525
2022-09-22 08:09:52 - train: epoch 0046, iter [00610, 01251], lr: 0.001199, loss: 0.4388
2022-09-22 08:10:13 - train: epoch 0046, iter [00620, 01251], lr: 0.001199, loss: 0.3972
2022-09-22 08:10:34 - train: epoch 0046, iter [00630, 01251], lr: 0.001199, loss: 0.4181
2022-09-22 08:10:54 - train: epoch 0046, iter [00640, 01251], lr: 0.001199, loss: 0.4347
2022-09-22 08:11:15 - train: epoch 0046, iter [00650, 01251], lr: 0.001199, loss: 0.4071
2022-09-22 08:11:36 - train: epoch 0046, iter [00660, 01251], lr: 0.001199, loss: 0.4361
2022-09-22 08:11:56 - train: epoch 0046, iter [00670, 01251], lr: 0.001199, loss: 0.4599
2022-09-22 08:12:17 - train: epoch 0046, iter [00680, 01251], lr: 0.001199, loss: 0.4186
2022-09-22 08:12:38 - train: epoch 0046, iter [00690, 01251], lr: 0.001199, loss: 0.4263
2022-09-22 08:12:58 - train: epoch 0046, iter [00700, 01251], lr: 0.001199, loss: 0.4221
2022-09-22 08:13:19 - train: epoch 0046, iter [00710, 01251], lr: 0.001199, loss: 0.4270
2022-09-22 08:13:40 - train: epoch 0046, iter [00720, 01251], lr: 0.001199, loss: 0.4079
2022-09-22 08:14:00 - train: epoch 0046, iter [00730, 01251], lr: 0.001199, loss: 0.4152
2022-09-22 08:14:21 - train: epoch 0046, iter [00740, 01251], lr: 0.001199, loss: 0.4083
2022-09-22 08:14:42 - train: epoch 0046, iter [00750, 01251], lr: 0.001199, loss: 0.4171
2022-09-22 08:15:02 - train: epoch 0046, iter [00760, 01251], lr: 0.001199, loss: 0.4243
2022-09-22 08:15:23 - train: epoch 0046, iter [00770, 01251], lr: 0.001199, loss: 0.4266
2022-09-22 08:15:44 - train: epoch 0046, iter [00780, 01251], lr: 0.001199, loss: 0.4110
2022-09-22 08:16:04 - train: epoch 0046, iter [00790, 01251], lr: 0.001199, loss: 0.4259
2022-09-22 08:16:25 - train: epoch 0046, iter [00800, 01251], lr: 0.001199, loss: 0.4231
2022-09-22 08:16:46 - train: epoch 0046, iter [00810, 01251], lr: 0.001199, loss: 0.4093
2022-09-22 08:17:06 - train: epoch 0046, iter [00820, 01251], lr: 0.001199, loss: 0.4140
2022-09-22 08:17:27 - train: epoch 0046, iter [00830, 01251], lr: 0.001199, loss: 0.4011
2022-09-22 08:17:48 - train: epoch 0046, iter [00840, 01251], lr: 0.001199, loss: 0.4144
2022-09-22 08:18:08 - train: epoch 0046, iter [00850, 01251], lr: 0.001199, loss: 0.4178
2022-09-22 08:18:28 - train: epoch 0046, iter [00860, 01251], lr: 0.001199, loss: 0.4345
2022-09-22 08:18:49 - train: epoch 0046, iter [00870, 01251], lr: 0.001199, loss: 0.4392
2022-09-22 08:19:10 - train: epoch 0046, iter [00880, 01251], lr: 0.001199, loss: 0.4186
2022-09-22 08:19:31 - train: epoch 0046, iter [00890, 01251], lr: 0.001199, loss: 0.4175
2022-09-22 08:19:52 - train: epoch 0046, iter [00900, 01251], lr: 0.001199, loss: 0.4261
2022-09-22 08:20:12 - train: epoch 0046, iter [00910, 01251], lr: 0.001199, loss: 0.4035
2022-09-22 08:20:33 - train: epoch 0046, iter [00920, 01251], lr: 0.001199, loss: 0.4263
2022-09-22 08:20:53 - train: epoch 0046, iter [00930, 01251], lr: 0.001199, loss: 0.4349
2022-09-22 08:21:14 - train: epoch 0046, iter [00940, 01251], lr: 0.001199, loss: 0.4130
2022-09-22 08:21:35 - train: epoch 0046, iter [00950, 01251], lr: 0.001199, loss: 0.4175
2022-09-22 08:21:55 - train: epoch 0046, iter [00960, 01251], lr: 0.001199, loss: 0.4119
2022-09-22 08:22:16 - train: epoch 0046, iter [00970, 01251], lr: 0.001199, loss: 0.4163
2022-09-22 08:22:36 - train: epoch 0046, iter [00980, 01251], lr: 0.001199, loss: 0.4225
2022-09-22 08:22:57 - train: epoch 0046, iter [00990, 01251], lr: 0.001199, loss: 0.4160
2022-09-22 08:23:18 - train: epoch 0046, iter [01000, 01251], lr: 0.001199, loss: 0.4139
2022-09-22 08:23:38 - train: epoch 0046, iter [01010, 01251], lr: 0.001199, loss: 0.4238
2022-09-22 08:23:59 - train: epoch 0046, iter [01020, 01251], lr: 0.001199, loss: 0.4138
2022-09-22 08:24:20 - train: epoch 0046, iter [01030, 01251], lr: 0.001199, loss: 0.4290
2022-09-22 08:24:40 - train: epoch 0046, iter [01040, 01251], lr: 0.001199, loss: 0.4289
2022-09-22 08:25:01 - train: epoch 0046, iter [01050, 01251], lr: 0.001199, loss: 0.4236
2022-09-22 08:25:21 - train: epoch 0046, iter [01060, 01251], lr: 0.001199, loss: 0.4236
2022-09-22 08:25:42 - train: epoch 0046, iter [01070, 01251], lr: 0.001199, loss: 0.4249
2022-09-22 08:26:02 - train: epoch 0046, iter [01080, 01251], lr: 0.001199, loss: 0.4144
2022-09-22 08:26:23 - train: epoch 0046, iter [01090, 01251], lr: 0.001199, loss: 0.4337
2022-09-22 08:26:44 - train: epoch 0046, iter [01100, 01251], lr: 0.001199, loss: 0.4082
2022-09-22 08:27:04 - train: epoch 0046, iter [01110, 01251], lr: 0.001199, loss: 0.4444
2022-09-22 08:27:25 - train: epoch 0046, iter [01120, 01251], lr: 0.001199, loss: 0.4151
2022-09-22 08:27:45 - train: epoch 0046, iter [01130, 01251], lr: 0.001199, loss: 0.4318
2022-09-22 08:28:06 - train: epoch 0046, iter [01140, 01251], lr: 0.001199, loss: 0.4003
2022-09-22 08:28:27 - train: epoch 0046, iter [01150, 01251], lr: 0.001199, loss: 0.4154
2022-09-22 08:28:47 - train: epoch 0046, iter [01160, 01251], lr: 0.001199, loss: 0.4262
2022-09-22 08:29:08 - train: epoch 0046, iter [01170, 01251], lr: 0.001199, loss: 0.4183
2022-09-22 08:29:29 - train: epoch 0046, iter [01180, 01251], lr: 0.001199, loss: 0.4098
2022-09-22 08:29:49 - train: epoch 0046, iter [01190, 01251], lr: 0.001199, loss: 0.4433
2022-09-22 08:30:10 - train: epoch 0046, iter [01200, 01251], lr: 0.001199, loss: 0.4096
2022-09-22 08:30:31 - train: epoch 0046, iter [01210, 01251], lr: 0.001199, loss: 0.3894
2022-09-22 08:30:51 - train: epoch 0046, iter [01220, 01251], lr: 0.001199, loss: 0.4362
2022-09-22 08:31:12 - train: epoch 0046, iter [01230, 01251], lr: 0.001199, loss: 0.4284
2022-09-22 08:31:32 - train: epoch 0046, iter [01240, 01251], lr: 0.001199, loss: 0.4400
2022-09-22 08:31:52 - train: epoch 0046, iter [01250, 01251], lr: 0.001199, loss: 0.4036
2022-09-22 08:31:57 - train: epoch 046, train_loss: 0.4193
2022-09-22 08:32:02 - until epoch: 046, best_loss: 0.4193
2022-09-22 08:32:02 - epoch 047 lr: 0.001199
2022-09-22 08:32:39 - train: epoch 0047, iter [00010, 01251], lr: 0.001199, loss: 0.4246
2022-09-22 08:33:00 - train: epoch 0047, iter [00020, 01251], lr: 0.001199, loss: 0.4344
2022-09-22 08:33:20 - train: epoch 0047, iter [00030, 01251], lr: 0.001199, loss: 0.4033
2022-09-22 08:33:41 - train: epoch 0047, iter [00040, 01251], lr: 0.001199, loss: 0.4142
2022-09-22 08:34:01 - train: epoch 0047, iter [00050, 01251], lr: 0.001199, loss: 0.4141
2022-09-22 08:34:22 - train: epoch 0047, iter [00060, 01251], lr: 0.001199, loss: 0.4320
2022-09-22 08:34:43 - train: epoch 0047, iter [00070, 01251], lr: 0.001199, loss: 0.4235
2022-09-22 08:35:03 - train: epoch 0047, iter [00080, 01251], lr: 0.001199, loss: 0.4440
2022-09-22 08:35:24 - train: epoch 0047, iter [00090, 01251], lr: 0.001199, loss: 0.4217
2022-09-22 08:35:44 - train: epoch 0047, iter [00100, 01251], lr: 0.001199, loss: 0.4361
2022-09-22 08:36:05 - train: epoch 0047, iter [00110, 01251], lr: 0.001199, loss: 0.3916
2022-09-22 08:36:26 - train: epoch 0047, iter [00120, 01251], lr: 0.001199, loss: 0.4168
2022-09-22 08:36:46 - train: epoch 0047, iter [00130, 01251], lr: 0.001199, loss: 0.4326
2022-09-22 08:37:07 - train: epoch 0047, iter [00140, 01251], lr: 0.001199, loss: 0.4443
2022-09-22 08:37:28 - train: epoch 0047, iter [00150, 01251], lr: 0.001199, loss: 0.4194
2022-09-22 08:37:48 - train: epoch 0047, iter [00160, 01251], lr: 0.001199, loss: 0.4320
2022-09-22 08:38:09 - train: epoch 0047, iter [00170, 01251], lr: 0.001199, loss: 0.4040
2022-09-22 08:38:30 - train: epoch 0047, iter [00180, 01251], lr: 0.001199, loss: 0.4353
2022-09-22 08:38:50 - train: epoch 0047, iter [00190, 01251], lr: 0.001199, loss: 0.4417
2022-09-22 08:39:11 - train: epoch 0047, iter [00200, 01251], lr: 0.001199, loss: 0.3875
2022-09-22 08:39:32 - train: epoch 0047, iter [00210, 01251], lr: 0.001199, loss: 0.4330
2022-09-22 08:39:52 - train: epoch 0047, iter [00220, 01251], lr: 0.001199, loss: 0.4212
2022-09-22 08:40:13 - train: epoch 0047, iter [00230, 01251], lr: 0.001199, loss: 0.4245
2022-09-22 08:40:34 - train: epoch 0047, iter [00240, 01251], lr: 0.001199, loss: 0.4459
2022-09-22 08:40:54 - train: epoch 0047, iter [00250, 01251], lr: 0.001199, loss: 0.4334
2022-09-22 08:41:15 - train: epoch 0047, iter [00260, 01251], lr: 0.001199, loss: 0.4084
2022-09-22 08:41:35 - train: epoch 0047, iter [00270, 01251], lr: 0.001199, loss: 0.4092
2022-09-22 08:41:56 - train: epoch 0047, iter [00280, 01251], lr: 0.001199, loss: 0.4278
2022-09-22 08:42:16 - train: epoch 0047, iter [00290, 01251], lr: 0.001199, loss: 0.4187
2022-09-22 08:42:37 - train: epoch 0047, iter [00300, 01251], lr: 0.001199, loss: 0.4301
2022-09-22 08:42:58 - train: epoch 0047, iter [00310, 01251], lr: 0.001199, loss: 0.4382
2022-09-22 08:43:18 - train: epoch 0047, iter [00320, 01251], lr: 0.001199, loss: 0.4230
2022-09-22 08:43:39 - train: epoch 0047, iter [00330, 01251], lr: 0.001199, loss: 0.4260
2022-09-22 08:44:00 - train: epoch 0047, iter [00340, 01251], lr: 0.001199, loss: 0.4075
2022-09-22 08:44:20 - train: epoch 0047, iter [00350, 01251], lr: 0.001199, loss: 0.4148
2022-09-22 08:44:41 - train: epoch 0047, iter [00360, 01251], lr: 0.001199, loss: 0.4105
2022-09-22 08:45:02 - train: epoch 0047, iter [00370, 01251], lr: 0.001199, loss: 0.4194
2022-09-22 08:45:22 - train: epoch 0047, iter [00380, 01251], lr: 0.001199, loss: 0.4107
2022-09-22 08:45:43 - train: epoch 0047, iter [00390, 01251], lr: 0.001199, loss: 0.3959
2022-09-22 08:46:04 - train: epoch 0047, iter [00400, 01251], lr: 0.001199, loss: 0.4167
2022-09-22 08:46:24 - train: epoch 0047, iter [00410, 01251], lr: 0.001199, loss: 0.4422
2022-09-22 08:46:45 - train: epoch 0047, iter [00420, 01251], lr: 0.001199, loss: 0.4115
2022-09-22 08:47:05 - train: epoch 0047, iter [00430, 01251], lr: 0.001199, loss: 0.4178
2022-09-22 08:47:26 - train: epoch 0047, iter [00440, 01251], lr: 0.001199, loss: 0.4450
2022-09-22 08:47:47 - train: epoch 0047, iter [00450, 01251], lr: 0.001199, loss: 0.4226
2022-09-22 08:48:08 - train: epoch 0047, iter [00460, 01251], lr: 0.001199, loss: 0.4143
2022-09-22 08:48:28 - train: epoch 0047, iter [00470, 01251], lr: 0.001199, loss: 0.4057
2022-09-22 08:48:49 - train: epoch 0047, iter [00480, 01251], lr: 0.001199, loss: 0.4332
2022-09-22 08:49:10 - train: epoch 0047, iter [00490, 01251], lr: 0.001199, loss: 0.3925
2022-09-22 08:49:30 - train: epoch 0047, iter [00500, 01251], lr: 0.001199, loss: 0.4379
2022-09-22 08:49:51 - train: epoch 0047, iter [00510, 01251], lr: 0.001199, loss: 0.4263
2022-09-22 08:50:11 - train: epoch 0047, iter [00520, 01251], lr: 0.001199, loss: 0.4223
2022-09-22 08:50:32 - train: epoch 0047, iter [00530, 01251], lr: 0.001199, loss: 0.4208
2022-09-22 08:50:53 - train: epoch 0047, iter [00540, 01251], lr: 0.001199, loss: 0.4331
2022-09-22 08:51:13 - train: epoch 0047, iter [00550, 01251], lr: 0.001199, loss: 0.4178
2022-09-22 08:51:34 - train: epoch 0047, iter [00560, 01251], lr: 0.001199, loss: 0.4141
2022-09-22 08:51:55 - train: epoch 0047, iter [00570, 01251], lr: 0.001199, loss: 0.4233
2022-09-22 08:52:15 - train: epoch 0047, iter [00580, 01251], lr: 0.001199, loss: 0.4378
2022-09-22 08:52:36 - train: epoch 0047, iter [00590, 01251], lr: 0.001199, loss: 0.4016
2022-09-22 08:52:57 - train: epoch 0047, iter [00600, 01251], lr: 0.001199, loss: 0.4261
2022-09-22 08:53:17 - train: epoch 0047, iter [00610, 01251], lr: 0.001199, loss: 0.4298
2022-09-22 08:53:38 - train: epoch 0047, iter [00620, 01251], lr: 0.001199, loss: 0.4082
2022-09-22 08:53:59 - train: epoch 0047, iter [00630, 01251], lr: 0.001199, loss: 0.4095
2022-09-22 08:54:19 - train: epoch 0047, iter [00640, 01251], lr: 0.001199, loss: 0.4255
2022-09-22 08:54:40 - train: epoch 0047, iter [00650, 01251], lr: 0.001199, loss: 0.4164
2022-09-22 08:55:01 - train: epoch 0047, iter [00660, 01251], lr: 0.001199, loss: 0.4088
2022-09-22 08:55:21 - train: epoch 0047, iter [00670, 01251], lr: 0.001199, loss: 0.4272
2022-09-22 08:55:42 - train: epoch 0047, iter [00680, 01251], lr: 0.001199, loss: 0.4109
2022-09-22 08:56:02 - train: epoch 0047, iter [00690, 01251], lr: 0.001199, loss: 0.4157
2022-09-22 08:56:23 - train: epoch 0047, iter [00700, 01251], lr: 0.001199, loss: 0.4286
2022-09-22 08:56:44 - train: epoch 0047, iter [00710, 01251], lr: 0.001199, loss: 0.4259
2022-09-22 08:57:04 - train: epoch 0047, iter [00720, 01251], lr: 0.001199, loss: 0.4178
2022-09-22 08:57:25 - train: epoch 0047, iter [00730, 01251], lr: 0.001199, loss: 0.4174
2022-09-22 08:57:46 - train: epoch 0047, iter [00740, 01251], lr: 0.001199, loss: 0.4572
2022-09-22 08:58:07 - train: epoch 0047, iter [00750, 01251], lr: 0.001199, loss: 0.4075
2022-09-22 08:58:27 - train: epoch 0047, iter [00760, 01251], lr: 0.001199, loss: 0.4357
2022-09-22 08:58:48 - train: epoch 0047, iter [00770, 01251], lr: 0.001199, loss: 0.4050
2022-09-22 08:59:09 - train: epoch 0047, iter [00780, 01251], lr: 0.001199, loss: 0.4202
2022-09-22 08:59:29 - train: epoch 0047, iter [00790, 01251], lr: 0.001199, loss: 0.4283
2022-09-22 08:59:50 - train: epoch 0047, iter [00800, 01251], lr: 0.001199, loss: 0.4255
2022-09-22 09:00:11 - train: epoch 0047, iter [00810, 01251], lr: 0.001199, loss: 0.4270
2022-09-22 09:00:31 - train: epoch 0047, iter [00820, 01251], lr: 0.001199, loss: 0.4298
2022-09-22 09:00:52 - train: epoch 0047, iter [00830, 01251], lr: 0.001199, loss: 0.4460
2022-09-22 09:01:13 - train: epoch 0047, iter [00840, 01251], lr: 0.001199, loss: 0.4117
2022-09-22 09:01:33 - train: epoch 0047, iter [00850, 01251], lr: 0.001199, loss: 0.4321
2022-09-22 09:01:54 - train: epoch 0047, iter [00860, 01251], lr: 0.001199, loss: 0.4102
2022-09-22 09:02:14 - train: epoch 0047, iter [00870, 01251], lr: 0.001199, loss: 0.4197
2022-09-22 09:02:34 - train: epoch 0047, iter [00880, 01251], lr: 0.001199, loss: 0.4115
2022-09-22 09:02:55 - train: epoch 0047, iter [00890, 01251], lr: 0.001199, loss: 0.4247
2022-09-22 09:03:16 - train: epoch 0047, iter [00900, 01251], lr: 0.001199, loss: 0.4267
2022-09-22 09:03:36 - train: epoch 0047, iter [00910, 01251], lr: 0.001199, loss: 0.4173
2022-09-22 09:03:57 - train: epoch 0047, iter [00920, 01251], lr: 0.001199, loss: 0.4480
2022-09-22 09:04:17 - train: epoch 0047, iter [00930, 01251], lr: 0.001199, loss: 0.4043
2022-09-22 09:04:38 - train: epoch 0047, iter [00940, 01251], lr: 0.001199, loss: 0.4152
2022-09-22 09:04:59 - train: epoch 0047, iter [00950, 01251], lr: 0.001199, loss: 0.4318
2022-09-22 09:05:19 - train: epoch 0047, iter [00960, 01251], lr: 0.001199, loss: 0.3947
2022-09-22 09:05:40 - train: epoch 0047, iter [00970, 01251], lr: 0.001199, loss: 0.4360
2022-09-22 09:06:01 - train: epoch 0047, iter [00980, 01251], lr: 0.001199, loss: 0.4080
2022-09-22 09:06:22 - train: epoch 0047, iter [00990, 01251], lr: 0.001199, loss: 0.4280
2022-09-22 09:06:42 - train: epoch 0047, iter [01000, 01251], lr: 0.001199, loss: 0.4298
2022-09-22 09:07:03 - train: epoch 0047, iter [01010, 01251], lr: 0.001199, loss: 0.4094
2022-09-22 09:07:24 - train: epoch 0047, iter [01020, 01251], lr: 0.001199, loss: 0.4426
2022-09-22 09:07:44 - train: epoch 0047, iter [01030, 01251], lr: 0.001199, loss: 0.4143
2022-09-22 09:08:05 - train: epoch 0047, iter [01040, 01251], lr: 0.001199, loss: 0.4055
2022-09-22 09:08:25 - train: epoch 0047, iter [01050, 01251], lr: 0.001199, loss: 0.3883
2022-09-22 09:08:46 - train: epoch 0047, iter [01060, 01251], lr: 0.001199, loss: 0.4153
2022-09-22 09:09:07 - train: epoch 0047, iter [01070, 01251], lr: 0.001199, loss: 0.4136
2022-09-22 09:09:27 - train: epoch 0047, iter [01080, 01251], lr: 0.001199, loss: 0.4337
2022-09-22 09:09:48 - train: epoch 0047, iter [01090, 01251], lr: 0.001199, loss: 0.4178
2022-09-22 09:10:09 - train: epoch 0047, iter [01100, 01251], lr: 0.001199, loss: 0.4272
2022-09-22 09:10:29 - train: epoch 0047, iter [01110, 01251], lr: 0.001199, loss: 0.4274
2022-09-22 09:10:50 - train: epoch 0047, iter [01120, 01251], lr: 0.001199, loss: 0.4047
2022-09-22 09:11:10 - train: epoch 0047, iter [01130, 01251], lr: 0.001199, loss: 0.4218
2022-09-22 09:11:31 - train: epoch 0047, iter [01140, 01251], lr: 0.001199, loss: 0.4249
2022-09-22 09:11:52 - train: epoch 0047, iter [01150, 01251], lr: 0.001199, loss: 0.4137
2022-09-22 09:12:12 - train: epoch 0047, iter [01160, 01251], lr: 0.001199, loss: 0.4188
2022-09-22 09:12:33 - train: epoch 0047, iter [01170, 01251], lr: 0.001199, loss: 0.4202
2022-09-22 09:12:54 - train: epoch 0047, iter [01180, 01251], lr: 0.001199, loss: 0.4212
2022-09-22 09:13:14 - train: epoch 0047, iter [01190, 01251], lr: 0.001199, loss: 0.3963
2022-09-22 09:13:35 - train: epoch 0047, iter [01200, 01251], lr: 0.001199, loss: 0.4217
2022-09-22 09:13:56 - train: epoch 0047, iter [01210, 01251], lr: 0.001199, loss: 0.4082
2022-09-22 09:14:17 - train: epoch 0047, iter [01220, 01251], lr: 0.001199, loss: 0.4166
2022-09-22 09:14:37 - train: epoch 0047, iter [01230, 01251], lr: 0.001199, loss: 0.4548
2022-09-22 09:14:58 - train: epoch 0047, iter [01240, 01251], lr: 0.001199, loss: 0.4157
2022-09-22 09:15:18 - train: epoch 0047, iter [01250, 01251], lr: 0.001199, loss: 0.4172
2022-09-22 09:15:22 - train: epoch 047, train_loss: 0.4190
2022-09-22 09:15:26 - until epoch: 047, best_loss: 0.4190
2022-09-22 09:15:26 - epoch 048 lr: 0.001199
2022-09-22 09:16:06 - train: epoch 0048, iter [00010, 01251], lr: 0.001199, loss: 0.4205
2022-09-22 09:16:26 - train: epoch 0048, iter [00020, 01251], lr: 0.001199, loss: 0.4135
2022-09-22 09:16:47 - train: epoch 0048, iter [00030, 01251], lr: 0.001199, loss: 0.4301
2022-09-22 09:17:07 - train: epoch 0048, iter [00040, 01251], lr: 0.001199, loss: 0.4128
2022-09-22 09:17:28 - train: epoch 0048, iter [00050, 01251], lr: 0.001199, loss: 0.4205
2022-09-22 09:17:48 - train: epoch 0048, iter [00060, 01251], lr: 0.001199, loss: 0.4244
2022-09-22 09:18:09 - train: epoch 0048, iter [00070, 01251], lr: 0.001199, loss: 0.4043
2022-09-22 09:18:29 - train: epoch 0048, iter [00080, 01251], lr: 0.001199, loss: 0.4266
2022-09-22 09:18:50 - train: epoch 0048, iter [00090, 01251], lr: 0.001199, loss: 0.4312
2022-09-22 09:19:10 - train: epoch 0048, iter [00100, 01251], lr: 0.001199, loss: 0.4102
2022-09-22 09:19:31 - train: epoch 0048, iter [00110, 01251], lr: 0.001199, loss: 0.4194
2022-09-22 09:19:52 - train: epoch 0048, iter [00120, 01251], lr: 0.001199, loss: 0.4162
2022-09-22 09:20:12 - train: epoch 0048, iter [00130, 01251], lr: 0.001199, loss: 0.4112
2022-09-22 09:20:33 - train: epoch 0048, iter [00140, 01251], lr: 0.001199, loss: 0.3968
2022-09-22 09:20:53 - train: epoch 0048, iter [00150, 01251], lr: 0.001199, loss: 0.4234
2022-09-22 09:21:14 - train: epoch 0048, iter [00160, 01251], lr: 0.001199, loss: 0.4296
2022-09-22 09:21:35 - train: epoch 0048, iter [00170, 01251], lr: 0.001199, loss: 0.4190
2022-09-22 09:21:56 - train: epoch 0048, iter [00180, 01251], lr: 0.001199, loss: 0.4365
2022-09-22 09:22:16 - train: epoch 0048, iter [00190, 01251], lr: 0.001199, loss: 0.3941
2022-09-22 09:22:37 - train: epoch 0048, iter [00200, 01251], lr: 0.001199, loss: 0.4174
2022-09-22 09:22:57 - train: epoch 0048, iter [00210, 01251], lr: 0.001199, loss: 0.4173
2022-09-22 09:23:18 - train: epoch 0048, iter [00220, 01251], lr: 0.001199, loss: 0.4091
2022-09-22 09:23:39 - train: epoch 0048, iter [00230, 01251], lr: 0.001199, loss: 0.4187
2022-09-22 09:23:59 - train: epoch 0048, iter [00240, 01251], lr: 0.001199, loss: 0.4185
2022-09-22 09:24:20 - train: epoch 0048, iter [00250, 01251], lr: 0.001199, loss: 0.4263
2022-09-22 09:24:41 - train: epoch 0048, iter [00260, 01251], lr: 0.001199, loss: 0.4345
2022-09-22 09:25:01 - train: epoch 0048, iter [00270, 01251], lr: 0.001199, loss: 0.4340
2022-09-22 09:25:22 - train: epoch 0048, iter [00280, 01251], lr: 0.001199, loss: 0.4226
2022-09-22 09:25:43 - train: epoch 0048, iter [00290, 01251], lr: 0.001199, loss: 0.4311
2022-09-22 09:26:03 - train: epoch 0048, iter [00300, 01251], lr: 0.001199, loss: 0.4133
2022-09-22 09:26:24 - train: epoch 0048, iter [00310, 01251], lr: 0.001199, loss: 0.4376
2022-09-22 09:26:45 - train: epoch 0048, iter [00320, 01251], lr: 0.001199, loss: 0.4275
2022-09-22 09:27:05 - train: epoch 0048, iter [00330, 01251], lr: 0.001199, loss: 0.4295
2022-09-22 09:27:26 - train: epoch 0048, iter [00340, 01251], lr: 0.001199, loss: 0.4082
2022-09-22 09:27:46 - train: epoch 0048, iter [00350, 01251], lr: 0.001199, loss: 0.4311
2022-09-22 09:28:07 - train: epoch 0048, iter [00360, 01251], lr: 0.001199, loss: 0.4296
2022-09-22 09:28:28 - train: epoch 0048, iter [00370, 01251], lr: 0.001199, loss: 0.4126
2022-09-22 09:28:48 - train: epoch 0048, iter [00380, 01251], lr: 0.001199, loss: 0.4211
2022-09-22 09:29:09 - train: epoch 0048, iter [00390, 01251], lr: 0.001199, loss: 0.4199
2022-09-22 09:29:30 - train: epoch 0048, iter [00400, 01251], lr: 0.001199, loss: 0.4214
2022-09-22 09:29:50 - train: epoch 0048, iter [00410, 01251], lr: 0.001199, loss: 0.4361
2022-09-22 09:30:11 - train: epoch 0048, iter [00420, 01251], lr: 0.001199, loss: 0.4295
2022-09-22 09:30:32 - train: epoch 0048, iter [00430, 01251], lr: 0.001199, loss: 0.4137
2022-09-22 09:30:52 - train: epoch 0048, iter [00440, 01251], lr: 0.001199, loss: 0.4115
2022-09-22 09:31:13 - train: epoch 0048, iter [00450, 01251], lr: 0.001199, loss: 0.4232
2022-09-22 09:31:34 - train: epoch 0048, iter [00460, 01251], lr: 0.001199, loss: 0.4104
2022-09-22 09:31:54 - train: epoch 0048, iter [00470, 01251], lr: 0.001199, loss: 0.4146
2022-09-22 09:32:15 - train: epoch 0048, iter [00480, 01251], lr: 0.001199, loss: 0.4042
2022-09-22 09:32:36 - train: epoch 0048, iter [00490, 01251], lr: 0.001199, loss: 0.4324
2022-09-22 09:32:56 - train: epoch 0048, iter [00500, 01251], lr: 0.001199, loss: 0.4207
2022-09-22 09:33:17 - train: epoch 0048, iter [00510, 01251], lr: 0.001199, loss: 0.4003
2022-09-22 09:33:38 - train: epoch 0048, iter [00520, 01251], lr: 0.001199, loss: 0.4086
2022-09-22 09:33:59 - train: epoch 0048, iter [00530, 01251], lr: 0.001199, loss: 0.4327
2022-09-22 09:34:19 - train: epoch 0048, iter [00540, 01251], lr: 0.001199, loss: 0.4258
2022-09-22 09:34:40 - train: epoch 0048, iter [00550, 01251], lr: 0.001199, loss: 0.4218
2022-09-22 09:35:01 - train: epoch 0048, iter [00560, 01251], lr: 0.001199, loss: 0.4106
2022-09-22 09:35:21 - train: epoch 0048, iter [00570, 01251], lr: 0.001199, loss: 0.4098
2022-09-22 09:35:42 - train: epoch 0048, iter [00580, 01251], lr: 0.001199, loss: 0.4022
2022-09-22 09:36:03 - train: epoch 0048, iter [00590, 01251], lr: 0.001199, loss: 0.4148
2022-09-22 09:36:23 - train: epoch 0048, iter [00600, 01251], lr: 0.001199, loss: 0.4228
2022-09-22 09:36:44 - train: epoch 0048, iter [00610, 01251], lr: 0.001199, loss: 0.4117
2022-09-22 09:37:05 - train: epoch 0048, iter [00620, 01251], lr: 0.001199, loss: 0.4198
2022-09-22 09:37:26 - train: epoch 0048, iter [00630, 01251], lr: 0.001199, loss: 0.4311
2022-09-22 09:37:46 - train: epoch 0048, iter [00640, 01251], lr: 0.001199, loss: 0.4033
2022-09-22 09:38:07 - train: epoch 0048, iter [00650, 01251], lr: 0.001199, loss: 0.4409
2022-09-22 09:38:28 - train: epoch 0048, iter [00660, 01251], lr: 0.001199, loss: 0.4336
2022-09-22 09:38:49 - train: epoch 0048, iter [00670, 01251], lr: 0.001199, loss: 0.3973
2022-09-22 09:39:09 - train: epoch 0048, iter [00680, 01251], lr: 0.001199, loss: 0.4257
2022-09-22 09:39:30 - train: epoch 0048, iter [00690, 01251], lr: 0.001199, loss: 0.4370
2022-09-22 09:39:50 - train: epoch 0048, iter [00700, 01251], lr: 0.001199, loss: 0.4228
2022-09-22 09:40:11 - train: epoch 0048, iter [00710, 01251], lr: 0.001199, loss: 0.4281
2022-09-22 09:40:32 - train: epoch 0048, iter [00720, 01251], lr: 0.001199, loss: 0.4165
2022-09-22 09:40:52 - train: epoch 0048, iter [00730, 01251], lr: 0.001199, loss: 0.4354
2022-09-22 09:41:13 - train: epoch 0048, iter [00740, 01251], lr: 0.001199, loss: 0.4118
2022-09-22 09:41:34 - train: epoch 0048, iter [00750, 01251], lr: 0.001199, loss: 0.4161
2022-09-22 09:41:55 - train: epoch 0048, iter [00760, 01251], lr: 0.001199, loss: 0.4416
2022-09-22 09:42:15 - train: epoch 0048, iter [00770, 01251], lr: 0.001199, loss: 0.4318
2022-09-22 09:42:36 - train: epoch 0048, iter [00780, 01251], lr: 0.001199, loss: 0.4306
2022-09-22 09:42:57 - train: epoch 0048, iter [00790, 01251], lr: 0.001199, loss: 0.4140
2022-09-22 09:43:17 - train: epoch 0048, iter [00800, 01251], lr: 0.001199, loss: 0.4102
2022-09-22 09:43:38 - train: epoch 0048, iter [00810, 01251], lr: 0.001199, loss: 0.4344
2022-09-22 09:43:59 - train: epoch 0048, iter [00820, 01251], lr: 0.001199, loss: 0.4275
2022-09-22 09:44:20 - train: epoch 0048, iter [00830, 01251], lr: 0.001199, loss: 0.4196
2022-09-22 09:44:40 - train: epoch 0048, iter [00840, 01251], lr: 0.001199, loss: 0.4129
2022-09-22 09:45:01 - train: epoch 0048, iter [00850, 01251], lr: 0.001199, loss: 0.4128
2022-09-22 09:45:22 - train: epoch 0048, iter [00860, 01251], lr: 0.001199, loss: 0.4320
2022-09-22 09:45:43 - train: epoch 0048, iter [00870, 01251], lr: 0.001199, loss: 0.4295
2022-09-22 09:46:03 - train: epoch 0048, iter [00880, 01251], lr: 0.001199, loss: 0.4250
2022-09-22 09:46:24 - train: epoch 0048, iter [00890, 01251], lr: 0.001199, loss: 0.4248
2022-09-22 09:46:44 - train: epoch 0048, iter [00900, 01251], lr: 0.001199, loss: 0.4217
2022-09-22 09:47:05 - train: epoch 0048, iter [00910, 01251], lr: 0.001199, loss: 0.4217
2022-09-22 09:47:25 - train: epoch 0048, iter [00920, 01251], lr: 0.001199, loss: 0.4121
2022-09-22 09:47:46 - train: epoch 0048, iter [00930, 01251], lr: 0.001199, loss: 0.3918
2022-09-22 09:48:07 - train: epoch 0048, iter [00940, 01251], lr: 0.001199, loss: 0.4201
2022-09-22 09:48:27 - train: epoch 0048, iter [00950, 01251], lr: 0.001199, loss: 0.4304
2022-09-22 09:48:47 - train: epoch 0048, iter [00960, 01251], lr: 0.001199, loss: 0.4123
2022-09-22 09:49:08 - train: epoch 0048, iter [00970, 01251], lr: 0.001199, loss: 0.4392
2022-09-22 09:49:29 - train: epoch 0048, iter [00980, 01251], lr: 0.001199, loss: 0.4342
2022-09-22 09:49:49 - train: epoch 0048, iter [00990, 01251], lr: 0.001199, loss: 0.4191
2022-09-22 09:50:10 - train: epoch 0048, iter [01000, 01251], lr: 0.001199, loss: 0.4306
2022-09-22 09:50:31 - train: epoch 0048, iter [01010, 01251], lr: 0.001199, loss: 0.4097
2022-09-22 09:50:51 - train: epoch 0048, iter [01020, 01251], lr: 0.001199, loss: 0.4012
2022-09-22 09:51:12 - train: epoch 0048, iter [01030, 01251], lr: 0.001199, loss: 0.4100
2022-09-22 09:51:33 - train: epoch 0048, iter [01040, 01251], lr: 0.001199, loss: 0.4280
2022-09-22 09:51:53 - train: epoch 0048, iter [01050, 01251], lr: 0.001199, loss: 0.4419
2022-09-22 09:52:14 - train: epoch 0048, iter [01060, 01251], lr: 0.001199, loss: 0.4364
2022-09-22 09:52:34 - train: epoch 0048, iter [01070, 01251], lr: 0.001199, loss: 0.4086
2022-09-22 09:52:55 - train: epoch 0048, iter [01080, 01251], lr: 0.001199, loss: 0.4407
2022-09-22 09:53:15 - train: epoch 0048, iter [01090, 01251], lr: 0.001199, loss: 0.4258
2022-09-22 09:53:36 - train: epoch 0048, iter [01100, 01251], lr: 0.001199, loss: 0.4250
2022-09-22 09:53:57 - train: epoch 0048, iter [01110, 01251], lr: 0.001199, loss: 0.4269
2022-09-22 09:54:17 - train: epoch 0048, iter [01120, 01251], lr: 0.001199, loss: 0.4122
2022-09-22 09:54:38 - train: epoch 0048, iter [01130, 01251], lr: 0.001199, loss: 0.4383
2022-09-22 09:54:58 - train: epoch 0048, iter [01140, 01251], lr: 0.001199, loss: 0.4278
2022-09-22 09:55:19 - train: epoch 0048, iter [01150, 01251], lr: 0.001199, loss: 0.4242
2022-09-22 09:55:39 - train: epoch 0048, iter [01160, 01251], lr: 0.001199, loss: 0.4050
2022-09-22 09:56:00 - train: epoch 0048, iter [01170, 01251], lr: 0.001199, loss: 0.4221
2022-09-22 09:56:20 - train: epoch 0048, iter [01180, 01251], lr: 0.001199, loss: 0.4145
2022-09-22 09:56:41 - train: epoch 0048, iter [01190, 01251], lr: 0.001199, loss: 0.3987
2022-09-22 09:57:02 - train: epoch 0048, iter [01200, 01251], lr: 0.001199, loss: 0.4267
2022-09-22 09:57:22 - train: epoch 0048, iter [01210, 01251], lr: 0.001199, loss: 0.4233
2022-09-22 09:57:43 - train: epoch 0048, iter [01220, 01251], lr: 0.001199, loss: 0.4124
2022-09-22 09:58:04 - train: epoch 0048, iter [01230, 01251], lr: 0.001199, loss: 0.4128
2022-09-22 09:58:25 - train: epoch 0048, iter [01240, 01251], lr: 0.001199, loss: 0.3996
2022-09-22 09:58:45 - train: epoch 0048, iter [01250, 01251], lr: 0.001199, loss: 0.4233
2022-09-22 09:58:49 - train: epoch 048, train_loss: 0.4188
2022-09-22 09:58:54 - until epoch: 048, best_loss: 0.4188
2022-09-22 09:58:54 - epoch 049 lr: 0.001199
2022-09-22 09:59:32 - train: epoch 0049, iter [00010, 01251], lr: 0.001199, loss: 0.4321
2022-09-22 09:59:52 - train: epoch 0049, iter [00020, 01251], lr: 0.001199, loss: 0.3995
2022-09-22 10:00:13 - train: epoch 0049, iter [00030, 01251], lr: 0.001199, loss: 0.3965
2022-09-22 10:00:34 - train: epoch 0049, iter [00040, 01251], lr: 0.001199, loss: 0.4022
2022-09-22 10:00:55 - train: epoch 0049, iter [00050, 01251], lr: 0.001199, loss: 0.4150
2022-09-22 10:01:15 - train: epoch 0049, iter [00060, 01251], lr: 0.001199, loss: 0.4074
2022-09-22 10:01:36 - train: epoch 0049, iter [00070, 01251], lr: 0.001199, loss: 0.4289
2022-09-22 10:01:56 - train: epoch 0049, iter [00080, 01251], lr: 0.001199, loss: 0.4103
2022-09-22 10:02:17 - train: epoch 0049, iter [00090, 01251], lr: 0.001199, loss: 0.4184
2022-09-22 10:02:38 - train: epoch 0049, iter [00100, 01251], lr: 0.001199, loss: 0.4176
2022-09-22 10:02:58 - train: epoch 0049, iter [00110, 01251], lr: 0.001199, loss: 0.4209
2022-09-22 10:03:19 - train: epoch 0049, iter [00120, 01251], lr: 0.001199, loss: 0.4332
2022-09-22 10:03:40 - train: epoch 0049, iter [00130, 01251], lr: 0.001199, loss: 0.4218
2022-09-22 10:04:01 - train: epoch 0049, iter [00140, 01251], lr: 0.001198, loss: 0.4336
2022-09-22 10:04:21 - train: epoch 0049, iter [00150, 01251], lr: 0.001198, loss: 0.4070
2022-09-22 10:04:42 - train: epoch 0049, iter [00160, 01251], lr: 0.001198, loss: 0.4066
2022-09-22 10:05:03 - train: epoch 0049, iter [00170, 01251], lr: 0.001198, loss: 0.4166
2022-09-22 10:05:24 - train: epoch 0049, iter [00180, 01251], lr: 0.001198, loss: 0.4127
2022-09-22 10:05:44 - train: epoch 0049, iter [00190, 01251], lr: 0.001198, loss: 0.4172
2022-09-22 10:06:05 - train: epoch 0049, iter [00200, 01251], lr: 0.001198, loss: 0.4219
2022-09-22 10:06:25 - train: epoch 0049, iter [00210, 01251], lr: 0.001198, loss: 0.3949
2022-09-22 10:06:46 - train: epoch 0049, iter [00220, 01251], lr: 0.001198, loss: 0.4174
2022-09-22 10:07:07 - train: epoch 0049, iter [00230, 01251], lr: 0.001198, loss: 0.4294
2022-09-22 10:07:28 - train: epoch 0049, iter [00240, 01251], lr: 0.001198, loss: 0.4095
2022-09-22 10:07:48 - train: epoch 0049, iter [00250, 01251], lr: 0.001198, loss: 0.4097
2022-09-22 10:08:09 - train: epoch 0049, iter [00260, 01251], lr: 0.001198, loss: 0.3993
2022-09-22 10:08:30 - train: epoch 0049, iter [00270, 01251], lr: 0.001198, loss: 0.4130
2022-09-22 10:08:50 - train: epoch 0049, iter [00280, 01251], lr: 0.001198, loss: 0.4241
2022-09-22 10:09:11 - train: epoch 0049, iter [00290, 01251], lr: 0.001198, loss: 0.4489
2022-09-22 10:09:32 - train: epoch 0049, iter [00300, 01251], lr: 0.001198, loss: 0.4218
2022-09-22 10:09:53 - train: epoch 0049, iter [00310, 01251], lr: 0.001198, loss: 0.4047
2022-09-22 10:10:13 - train: epoch 0049, iter [00320, 01251], lr: 0.001198, loss: 0.4031
2022-09-22 10:10:34 - train: epoch 0049, iter [00330, 01251], lr: 0.001198, loss: 0.3992
2022-09-22 10:10:55 - train: epoch 0049, iter [00340, 01251], lr: 0.001198, loss: 0.4216
2022-09-22 10:11:15 - train: epoch 0049, iter [00350, 01251], lr: 0.001198, loss: 0.4348
2022-09-22 10:11:36 - train: epoch 0049, iter [00360, 01251], lr: 0.001198, loss: 0.4141
2022-09-22 10:11:57 - train: epoch 0049, iter [00370, 01251], lr: 0.001198, loss: 0.4113
2022-09-22 10:12:18 - train: epoch 0049, iter [00380, 01251], lr: 0.001198, loss: 0.4217
2022-09-22 10:12:38 - train: epoch 0049, iter [00390, 01251], lr: 0.001198, loss: 0.4073
2022-09-22 10:12:59 - train: epoch 0049, iter [00400, 01251], lr: 0.001198, loss: 0.4132
2022-09-22 10:13:20 - train: epoch 0049, iter [00410, 01251], lr: 0.001198, loss: 0.4060
2022-09-22 10:13:40 - train: epoch 0049, iter [00420, 01251], lr: 0.001198, loss: 0.4229
2022-09-22 10:14:00 - train: epoch 0049, iter [00430, 01251], lr: 0.001198, loss: 0.3974
2022-09-22 10:14:21 - train: epoch 0049, iter [00440, 01251], lr: 0.001198, loss: 0.4068
2022-09-22 10:14:41 - train: epoch 0049, iter [00450, 01251], lr: 0.001198, loss: 0.4415
2022-09-22 10:15:01 - train: epoch 0049, iter [00460, 01251], lr: 0.001198, loss: 0.4327
2022-09-22 10:15:22 - train: epoch 0049, iter [00470, 01251], lr: 0.001198, loss: 0.4065
2022-09-22 10:15:42 - train: epoch 0049, iter [00480, 01251], lr: 0.001198, loss: 0.4236
2022-09-22 10:16:02 - train: epoch 0049, iter [00490, 01251], lr: 0.001198, loss: 0.4228
2022-09-22 10:16:23 - train: epoch 0049, iter [00500, 01251], lr: 0.001198, loss: 0.4092
2022-09-22 10:16:43 - train: epoch 0049, iter [00510, 01251], lr: 0.001198, loss: 0.4296
2022-09-22 10:17:04 - train: epoch 0049, iter [00520, 01251], lr: 0.001198, loss: 0.4263
2022-09-22 10:17:24 - train: epoch 0049, iter [00530, 01251], lr: 0.001198, loss: 0.4275
2022-09-22 10:17:44 - train: epoch 0049, iter [00540, 01251], lr: 0.001198, loss: 0.4367
2022-09-22 10:18:05 - train: epoch 0049, iter [00550, 01251], lr: 0.001198, loss: 0.4089
2022-09-22 10:18:25 - train: epoch 0049, iter [00560, 01251], lr: 0.001198, loss: 0.4113
2022-09-22 10:18:45 - train: epoch 0049, iter [00570, 01251], lr: 0.001198, loss: 0.4112
2022-09-22 10:19:06 - train: epoch 0049, iter [00580, 01251], lr: 0.001198, loss: 0.4314
2022-09-22 10:19:26 - train: epoch 0049, iter [00590, 01251], lr: 0.001198, loss: 0.4208
2022-09-22 10:19:46 - train: epoch 0049, iter [00600, 01251], lr: 0.001198, loss: 0.4237
2022-09-22 10:20:07 - train: epoch 0049, iter [00610, 01251], lr: 0.001198, loss: 0.4091
2022-09-22 10:20:27 - train: epoch 0049, iter [00620, 01251], lr: 0.001198, loss: 0.4344
2022-09-22 10:20:48 - train: epoch 0049, iter [00630, 01251], lr: 0.001198, loss: 0.3980
2022-09-22 10:21:08 - train: epoch 0049, iter [00640, 01251], lr: 0.001198, loss: 0.4402
2022-09-22 10:21:29 - train: epoch 0049, iter [00650, 01251], lr: 0.001198, loss: 0.4181
2022-09-22 10:21:49 - train: epoch 0049, iter [00660, 01251], lr: 0.001198, loss: 0.4372
2022-09-22 10:22:09 - train: epoch 0049, iter [00670, 01251], lr: 0.001198, loss: 0.4102
2022-09-22 10:22:30 - train: epoch 0049, iter [00680, 01251], lr: 0.001198, loss: 0.4225
2022-09-22 10:22:50 - train: epoch 0049, iter [00690, 01251], lr: 0.001198, loss: 0.4253
2022-09-22 10:23:11 - train: epoch 0049, iter [00700, 01251], lr: 0.001198, loss: 0.4232
2022-09-22 10:23:31 - train: epoch 0049, iter [00710, 01251], lr: 0.001198, loss: 0.4319
2022-09-22 10:23:52 - train: epoch 0049, iter [00720, 01251], lr: 0.001198, loss: 0.4130
2022-09-22 10:24:12 - train: epoch 0049, iter [00730, 01251], lr: 0.001198, loss: 0.4085
2022-09-22 10:24:33 - train: epoch 0049, iter [00740, 01251], lr: 0.001198, loss: 0.4166
2022-09-22 10:24:53 - train: epoch 0049, iter [00750, 01251], lr: 0.001198, loss: 0.4147
2022-09-22 10:25:13 - train: epoch 0049, iter [00760, 01251], lr: 0.001198, loss: 0.4124
2022-09-22 10:25:34 - train: epoch 0049, iter [00770, 01251], lr: 0.001198, loss: 0.4142
2022-09-22 10:25:54 - train: epoch 0049, iter [00780, 01251], lr: 0.001198, loss: 0.4237
2022-09-22 10:26:15 - train: epoch 0049, iter [00790, 01251], lr: 0.001198, loss: 0.4235
2022-09-22 10:26:35 - train: epoch 0049, iter [00800, 01251], lr: 0.001198, loss: 0.4141
2022-09-22 10:26:55 - train: epoch 0049, iter [00810, 01251], lr: 0.001198, loss: 0.4034
2022-09-22 10:27:16 - train: epoch 0049, iter [00820, 01251], lr: 0.001198, loss: 0.4077
2022-09-22 10:27:36 - train: epoch 0049, iter [00830, 01251], lr: 0.001198, loss: 0.4158
2022-09-22 10:27:56 - train: epoch 0049, iter [00840, 01251], lr: 0.001198, loss: 0.4166
2022-09-22 10:28:17 - train: epoch 0049, iter [00850, 01251], lr: 0.001198, loss: 0.4003
2022-09-22 10:28:37 - train: epoch 0049, iter [00860, 01251], lr: 0.001198, loss: 0.4259
2022-09-22 10:28:58 - train: epoch 0049, iter [00870, 01251], lr: 0.001198, loss: 0.4084
2022-09-22 10:29:18 - train: epoch 0049, iter [00880, 01251], lr: 0.001198, loss: 0.4409
2022-09-22 10:29:39 - train: epoch 0049, iter [00890, 01251], lr: 0.001198, loss: 0.4399
2022-09-22 10:29:59 - train: epoch 0049, iter [00900, 01251], lr: 0.001198, loss: 0.4258
2022-09-22 10:30:20 - train: epoch 0049, iter [00910, 01251], lr: 0.001198, loss: 0.4034
2022-09-22 10:30:40 - train: epoch 0049, iter [00920, 01251], lr: 0.001198, loss: 0.4384
2022-09-22 10:31:00 - train: epoch 0049, iter [00930, 01251], lr: 0.001198, loss: 0.3984
2022-09-22 10:31:21 - train: epoch 0049, iter [00940, 01251], lr: 0.001198, loss: 0.4195
2022-09-22 10:31:41 - train: epoch 0049, iter [00950, 01251], lr: 0.001198, loss: 0.4276
2022-09-22 10:32:02 - train: epoch 0049, iter [00960, 01251], lr: 0.001198, loss: 0.3934
2022-09-22 10:32:22 - train: epoch 0049, iter [00970, 01251], lr: 0.001198, loss: 0.4149
2022-09-22 10:32:43 - train: epoch 0049, iter [00980, 01251], lr: 0.001198, loss: 0.4267
2022-09-22 10:33:04 - train: epoch 0049, iter [00990, 01251], lr: 0.001198, loss: 0.4198
2022-09-22 10:33:24 - train: epoch 0049, iter [01000, 01251], lr: 0.001198, loss: 0.4111
2022-09-22 10:33:45 - train: epoch 0049, iter [01010, 01251], lr: 0.001198, loss: 0.4243
2022-09-22 10:34:05 - train: epoch 0049, iter [01020, 01251], lr: 0.001198, loss: 0.4389
2022-09-22 10:34:26 - train: epoch 0049, iter [01030, 01251], lr: 0.001198, loss: 0.4219
2022-09-22 10:34:47 - train: epoch 0049, iter [01040, 01251], lr: 0.001198, loss: 0.4002
2022-09-22 10:35:08 - train: epoch 0049, iter [01050, 01251], lr: 0.001198, loss: 0.4301
2022-09-22 10:35:28 - train: epoch 0049, iter [01060, 01251], lr: 0.001198, loss: 0.4154
2022-09-22 10:35:49 - train: epoch 0049, iter [01070, 01251], lr: 0.001198, loss: 0.4124
2022-09-22 10:36:10 - train: epoch 0049, iter [01080, 01251], lr: 0.001198, loss: 0.4226
2022-09-22 10:36:31 - train: epoch 0049, iter [01090, 01251], lr: 0.001198, loss: 0.4334
2022-09-22 10:36:51 - train: epoch 0049, iter [01100, 01251], lr: 0.001198, loss: 0.4291
2022-09-22 10:37:12 - train: epoch 0049, iter [01110, 01251], lr: 0.001198, loss: 0.4349
2022-09-22 10:37:33 - train: epoch 0049, iter [01120, 01251], lr: 0.001198, loss: 0.4010
2022-09-22 10:37:54 - train: epoch 0049, iter [01130, 01251], lr: 0.001198, loss: 0.4294
2022-09-22 10:38:14 - train: epoch 0049, iter [01140, 01251], lr: 0.001198, loss: 0.4258
2022-09-22 10:38:35 - train: epoch 0049, iter [01150, 01251], lr: 0.001198, loss: 0.4091
2022-09-22 10:38:56 - train: epoch 0049, iter [01160, 01251], lr: 0.001198, loss: 0.4244
2022-09-22 10:39:17 - train: epoch 0049, iter [01170, 01251], lr: 0.001198, loss: 0.4135
2022-09-22 10:39:37 - train: epoch 0049, iter [01180, 01251], lr: 0.001198, loss: 0.4244
2022-09-22 10:39:58 - train: epoch 0049, iter [01190, 01251], lr: 0.001198, loss: 0.4053
2022-09-22 10:40:19 - train: epoch 0049, iter [01200, 01251], lr: 0.001198, loss: 0.4279
2022-09-22 10:40:40 - train: epoch 0049, iter [01210, 01251], lr: 0.001198, loss: 0.4241
2022-09-22 10:41:01 - train: epoch 0049, iter [01220, 01251], lr: 0.001198, loss: 0.4313
2022-09-22 10:41:21 - train: epoch 0049, iter [01230, 01251], lr: 0.001198, loss: 0.4167
2022-09-22 10:41:42 - train: epoch 0049, iter [01240, 01251], lr: 0.001198, loss: 0.4209
2022-09-22 10:42:02 - train: epoch 0049, iter [01250, 01251], lr: 0.001198, loss: 0.4109
2022-09-22 10:42:06 - train: epoch 049, train_loss: 0.4185
2022-09-22 10:42:11 - until epoch: 049, best_loss: 0.4185
2022-09-22 10:42:11 - epoch 050 lr: 0.001198
2022-09-22 10:42:49 - train: epoch 0050, iter [00010, 01251], lr: 0.001198, loss: 0.4062
2022-09-22 10:43:10 - train: epoch 0050, iter [00020, 01251], lr: 0.001198, loss: 0.4122
2022-09-22 10:43:31 - train: epoch 0050, iter [00030, 01251], lr: 0.001198, loss: 0.4160
2022-09-22 10:43:51 - train: epoch 0050, iter [00040, 01251], lr: 0.001198, loss: 0.4133
2022-09-22 10:44:12 - train: epoch 0050, iter [00050, 01251], lr: 0.001198, loss: 0.4338
2022-09-22 10:44:33 - train: epoch 0050, iter [00060, 01251], lr: 0.001198, loss: 0.4088
2022-09-22 10:44:54 - train: epoch 0050, iter [00070, 01251], lr: 0.001198, loss: 0.4299
2022-09-22 10:45:15 - train: epoch 0050, iter [00080, 01251], lr: 0.001198, loss: 0.4137
2022-09-22 10:45:36 - train: epoch 0050, iter [00090, 01251], lr: 0.001198, loss: 0.4114
2022-09-22 10:45:57 - train: epoch 0050, iter [00100, 01251], lr: 0.001198, loss: 0.4007
2022-09-22 10:46:17 - train: epoch 0050, iter [00110, 01251], lr: 0.001198, loss: 0.4288
2022-09-22 10:46:38 - train: epoch 0050, iter [00120, 01251], lr: 0.001198, loss: 0.4061
2022-09-22 10:46:59 - train: epoch 0050, iter [00130, 01251], lr: 0.001198, loss: 0.4147
2022-09-22 10:47:20 - train: epoch 0050, iter [00140, 01251], lr: 0.001198, loss: 0.4363
2022-09-22 10:47:41 - train: epoch 0050, iter [00150, 01251], lr: 0.001198, loss: 0.4370
2022-09-22 10:48:02 - train: epoch 0050, iter [00160, 01251], lr: 0.001198, loss: 0.4208
2022-09-22 10:48:22 - train: epoch 0050, iter [00170, 01251], lr: 0.001198, loss: 0.4361
2022-09-22 10:48:43 - train: epoch 0050, iter [00180, 01251], lr: 0.001198, loss: 0.3987
2022-09-22 10:49:04 - train: epoch 0050, iter [00190, 01251], lr: 0.001198, loss: 0.4206
2022-09-22 10:49:24 - train: epoch 0050, iter [00200, 01251], lr: 0.001198, loss: 0.4308
2022-09-22 10:49:45 - train: epoch 0050, iter [00210, 01251], lr: 0.001198, loss: 0.3989
2022-09-22 10:50:05 - train: epoch 0050, iter [00220, 01251], lr: 0.001198, loss: 0.4137
2022-09-22 10:50:25 - train: epoch 0050, iter [00230, 01251], lr: 0.001198, loss: 0.4294
2022-09-22 10:50:46 - train: epoch 0050, iter [00240, 01251], lr: 0.001198, loss: 0.4107
2022-09-22 10:51:06 - train: epoch 0050, iter [00250, 01251], lr: 0.001198, loss: 0.4133
2022-09-22 10:51:26 - train: epoch 0050, iter [00260, 01251], lr: 0.001198, loss: 0.4147
2022-09-22 10:51:46 - train: epoch 0050, iter [00270, 01251], lr: 0.001198, loss: 0.4244
2022-09-22 10:52:07 - train: epoch 0050, iter [00280, 01251], lr: 0.001198, loss: 0.4166
2022-09-22 10:52:27 - train: epoch 0050, iter [00290, 01251], lr: 0.001198, loss: 0.4334
2022-09-22 10:52:48 - train: epoch 0050, iter [00300, 01251], lr: 0.001198, loss: 0.3966
2022-09-22 10:53:08 - train: epoch 0050, iter [00310, 01251], lr: 0.001198, loss: 0.4123
2022-09-22 10:53:28 - train: epoch 0050, iter [00320, 01251], lr: 0.001198, loss: 0.4063
2022-09-22 10:53:49 - train: epoch 0050, iter [00330, 01251], lr: 0.001198, loss: 0.4397
2022-09-22 10:54:09 - train: epoch 0050, iter [00340, 01251], lr: 0.001198, loss: 0.4126
2022-09-22 10:54:29 - train: epoch 0050, iter [00350, 01251], lr: 0.001198, loss: 0.4224
2022-09-22 10:54:50 - train: epoch 0050, iter [00360, 01251], lr: 0.001198, loss: 0.4393
2022-09-22 10:55:10 - train: epoch 0050, iter [00370, 01251], lr: 0.001198, loss: 0.4279
2022-09-22 10:55:31 - train: epoch 0050, iter [00380, 01251], lr: 0.001198, loss: 0.4210
2022-09-22 10:55:51 - train: epoch 0050, iter [00390, 01251], lr: 0.001198, loss: 0.4086
2022-09-22 10:56:12 - train: epoch 0050, iter [00400, 01251], lr: 0.001198, loss: 0.4203
2022-09-22 10:56:32 - train: epoch 0050, iter [00410, 01251], lr: 0.001198, loss: 0.4119
2022-09-22 10:56:53 - train: epoch 0050, iter [00420, 01251], lr: 0.001198, loss: 0.4312
2022-09-22 10:57:13 - train: epoch 0050, iter [00430, 01251], lr: 0.001198, loss: 0.4092
2022-09-22 10:57:33 - train: epoch 0050, iter [00440, 01251], lr: 0.001198, loss: 0.4342
2022-09-22 10:57:53 - train: epoch 0050, iter [00450, 01251], lr: 0.001198, loss: 0.4164
2022-09-22 10:58:14 - train: epoch 0050, iter [00460, 01251], lr: 0.001198, loss: 0.4101
2022-09-22 10:58:34 - train: epoch 0050, iter [00470, 01251], lr: 0.001198, loss: 0.4236
2022-09-22 10:58:55 - train: epoch 0050, iter [00480, 01251], lr: 0.001198, loss: 0.4152
2022-09-22 10:59:15 - train: epoch 0050, iter [00490, 01251], lr: 0.001198, loss: 0.4223
2022-09-22 10:59:35 - train: epoch 0050, iter [00500, 01251], lr: 0.001198, loss: 0.4205
2022-09-22 10:59:56 - train: epoch 0050, iter [00510, 01251], lr: 0.001198, loss: 0.4108
2022-09-22 11:00:16 - train: epoch 0050, iter [00520, 01251], lr: 0.001198, loss: 0.4309
2022-09-22 11:00:37 - train: epoch 0050, iter [00530, 01251], lr: 0.001198, loss: 0.4114
2022-09-22 11:00:57 - train: epoch 0050, iter [00540, 01251], lr: 0.001198, loss: 0.4111
2022-09-22 11:01:17 - train: epoch 0050, iter [00550, 01251], lr: 0.001198, loss: 0.4135
2022-09-22 11:01:38 - train: epoch 0050, iter [00560, 01251], lr: 0.001198, loss: 0.4179
2022-09-22 11:01:58 - train: epoch 0050, iter [00570, 01251], lr: 0.001198, loss: 0.4272
2022-09-22 11:02:19 - train: epoch 0050, iter [00580, 01251], lr: 0.001198, loss: 0.4372
2022-09-22 11:02:39 - train: epoch 0050, iter [00590, 01251], lr: 0.001198, loss: 0.4245
2022-09-22 11:02:59 - train: epoch 0050, iter [00600, 01251], lr: 0.001198, loss: 0.4318
2022-09-22 11:03:20 - train: epoch 0050, iter [00610, 01251], lr: 0.001198, loss: 0.4347
2022-09-22 11:03:40 - train: epoch 0050, iter [00620, 01251], lr: 0.001198, loss: 0.4147
2022-09-22 11:04:01 - train: epoch 0050, iter [00630, 01251], lr: 0.001198, loss: 0.4386
2022-09-22 11:04:21 - train: epoch 0050, iter [00640, 01251], lr: 0.001198, loss: 0.4191
2022-09-22 11:04:41 - train: epoch 0050, iter [00650, 01251], lr: 0.001198, loss: 0.4075
2022-09-22 11:05:02 - train: epoch 0050, iter [00660, 01251], lr: 0.001198, loss: 0.4044
2022-09-22 11:05:22 - train: epoch 0050, iter [00670, 01251], lr: 0.001198, loss: 0.4098
2022-09-22 11:05:42 - train: epoch 0050, iter [00680, 01251], lr: 0.001198, loss: 0.4078
2022-09-22 11:06:03 - train: epoch 0050, iter [00690, 01251], lr: 0.001198, loss: 0.4189
2022-09-22 11:06:23 - train: epoch 0050, iter [00700, 01251], lr: 0.001198, loss: 0.4050
2022-09-22 11:06:44 - train: epoch 0050, iter [00710, 01251], lr: 0.001198, loss: 0.4372
2022-09-22 11:07:04 - train: epoch 0050, iter [00720, 01251], lr: 0.001198, loss: 0.4160
2022-09-22 11:07:25 - train: epoch 0050, iter [00730, 01251], lr: 0.001198, loss: 0.4211
2022-09-22 11:07:46 - train: epoch 0050, iter [00740, 01251], lr: 0.001198, loss: 0.4036
2022-09-22 11:08:06 - train: epoch 0050, iter [00750, 01251], lr: 0.001198, loss: 0.4258
2022-09-22 11:08:27 - train: epoch 0050, iter [00760, 01251], lr: 0.001198, loss: 0.4118
2022-09-22 11:08:48 - train: epoch 0050, iter [00770, 01251], lr: 0.001198, loss: 0.4139
2022-09-22 11:09:09 - train: epoch 0050, iter [00780, 01251], lr: 0.001198, loss: 0.4342
2022-09-22 11:09:30 - train: epoch 0050, iter [00790, 01251], lr: 0.001198, loss: 0.4261
2022-09-22 11:09:51 - train: epoch 0050, iter [00800, 01251], lr: 0.001198, loss: 0.4183
2022-09-22 11:10:12 - train: epoch 0050, iter [00810, 01251], lr: 0.001198, loss: 0.4137
2022-09-22 11:10:33 - train: epoch 0050, iter [00820, 01251], lr: 0.001198, loss: 0.3996
2022-09-22 11:10:54 - train: epoch 0050, iter [00830, 01251], lr: 0.001198, loss: 0.4175
2022-09-22 11:11:14 - train: epoch 0050, iter [00840, 01251], lr: 0.001198, loss: 0.3920
2022-09-22 11:11:35 - train: epoch 0050, iter [00850, 01251], lr: 0.001198, loss: 0.4273
2022-09-22 11:11:56 - train: epoch 0050, iter [00860, 01251], lr: 0.001198, loss: 0.4026
2022-09-22 11:12:17 - train: epoch 0050, iter [00870, 01251], lr: 0.001198, loss: 0.4330
2022-09-22 11:12:38 - train: epoch 0050, iter [00880, 01251], lr: 0.001198, loss: 0.4190
2022-09-22 11:12:58 - train: epoch 0050, iter [00890, 01251], lr: 0.001198, loss: 0.4291
2022-09-22 11:13:19 - train: epoch 0050, iter [00900, 01251], lr: 0.001198, loss: 0.4037
2022-09-22 11:13:40 - train: epoch 0050, iter [00910, 01251], lr: 0.001198, loss: 0.4085
2022-09-22 11:14:00 - train: epoch 0050, iter [00920, 01251], lr: 0.001198, loss: 0.4156
2022-09-22 11:14:21 - train: epoch 0050, iter [00930, 01251], lr: 0.001198, loss: 0.4149
2022-09-22 11:14:42 - train: epoch 0050, iter [00940, 01251], lr: 0.001198, loss: 0.4171
2022-09-22 11:15:03 - train: epoch 0050, iter [00950, 01251], lr: 0.001198, loss: 0.4180
2022-09-22 11:15:23 - train: epoch 0050, iter [00960, 01251], lr: 0.001198, loss: 0.4025
2022-09-22 11:15:44 - train: epoch 0050, iter [00970, 01251], lr: 0.001198, loss: 0.4226
2022-09-22 11:16:05 - train: epoch 0050, iter [00980, 01251], lr: 0.001198, loss: 0.3990
2022-09-22 11:16:26 - train: epoch 0050, iter [00990, 01251], lr: 0.001198, loss: 0.4065
2022-09-22 11:16:46 - train: epoch 0050, iter [01000, 01251], lr: 0.001198, loss: 0.4166
2022-09-22 11:17:07 - train: epoch 0050, iter [01010, 01251], lr: 0.001198, loss: 0.4371
2022-09-22 11:17:28 - train: epoch 0050, iter [01020, 01251], lr: 0.001198, loss: 0.4394
2022-09-22 11:17:48 - train: epoch 0050, iter [01030, 01251], lr: 0.001198, loss: 0.4127
2022-09-22 11:18:09 - train: epoch 0050, iter [01040, 01251], lr: 0.001198, loss: 0.4177
2022-09-22 11:18:30 - train: epoch 0050, iter [01050, 01251], lr: 0.001198, loss: 0.4224
2022-09-22 11:18:51 - train: epoch 0050, iter [01060, 01251], lr: 0.001198, loss: 0.4159
2022-09-22 11:19:11 - train: epoch 0050, iter [01070, 01251], lr: 0.001198, loss: 0.4096
2022-09-22 11:19:32 - train: epoch 0050, iter [01080, 01251], lr: 0.001198, loss: 0.4268
2022-09-22 11:19:53 - train: epoch 0050, iter [01090, 01251], lr: 0.001198, loss: 0.4316
2022-09-22 11:20:14 - train: epoch 0050, iter [01100, 01251], lr: 0.001198, loss: 0.4074
2022-09-22 11:20:34 - train: epoch 0050, iter [01110, 01251], lr: 0.001198, loss: 0.4370
2022-09-22 11:20:55 - train: epoch 0050, iter [01120, 01251], lr: 0.001198, loss: 0.4253
2022-09-22 11:21:16 - train: epoch 0050, iter [01130, 01251], lr: 0.001198, loss: 0.4087
2022-09-22 11:21:36 - train: epoch 0050, iter [01140, 01251], lr: 0.001198, loss: 0.4152
2022-09-22 11:21:57 - train: epoch 0050, iter [01150, 01251], lr: 0.001198, loss: 0.4183
2022-09-22 11:22:18 - train: epoch 0050, iter [01160, 01251], lr: 0.001198, loss: 0.4080
2022-09-22 11:22:38 - train: epoch 0050, iter [01170, 01251], lr: 0.001198, loss: 0.4176
2022-09-22 11:22:59 - train: epoch 0050, iter [01180, 01251], lr: 0.001198, loss: 0.4355
2022-09-22 11:23:19 - train: epoch 0050, iter [01190, 01251], lr: 0.001198, loss: 0.4108
2022-09-22 11:23:39 - train: epoch 0050, iter [01200, 01251], lr: 0.001198, loss: 0.4213
2022-09-22 11:23:59 - train: epoch 0050, iter [01210, 01251], lr: 0.001198, loss: 0.4193
2022-09-22 11:24:20 - train: epoch 0050, iter [01220, 01251], lr: 0.001198, loss: 0.4159
2022-09-22 11:24:40 - train: epoch 0050, iter [01230, 01251], lr: 0.001198, loss: 0.4049
2022-09-22 11:25:00 - train: epoch 0050, iter [01240, 01251], lr: 0.001198, loss: 0.4165
2022-09-22 11:25:20 - train: epoch 0050, iter [01250, 01251], lr: 0.001198, loss: 0.4091
2022-09-22 11:25:24 - train: epoch 050, train_loss: 0.4183
2022-09-22 11:25:28 - until epoch: 050, best_loss: 0.4183
2022-09-22 11:25:28 - epoch 051 lr: 0.001198
2022-09-22 11:26:05 - train: epoch 0051, iter [00010, 01251], lr: 0.001198, loss: 0.4030
2022-09-22 11:26:25 - train: epoch 0051, iter [00020, 01251], lr: 0.001198, loss: 0.4089
2022-09-22 11:26:45 - train: epoch 0051, iter [00030, 01251], lr: 0.001198, loss: 0.4221
2022-09-22 11:27:06 - train: epoch 0051, iter [00040, 01251], lr: 0.001198, loss: 0.4284
2022-09-22 11:27:26 - train: epoch 0051, iter [00050, 01251], lr: 0.001198, loss: 0.4391
2022-09-22 11:27:46 - train: epoch 0051, iter [00060, 01251], lr: 0.001198, loss: 0.4144
2022-09-22 11:28:06 - train: epoch 0051, iter [00070, 01251], lr: 0.001198, loss: 0.4199
2022-09-22 11:28:27 - train: epoch 0051, iter [00080, 01251], lr: 0.001198, loss: 0.4284
2022-09-22 11:28:47 - train: epoch 0051, iter [00090, 01251], lr: 0.001198, loss: 0.4128
2022-09-22 11:29:08 - train: epoch 0051, iter [00100, 01251], lr: 0.001198, loss: 0.4398
2022-09-22 11:29:28 - train: epoch 0051, iter [00110, 01251], lr: 0.001198, loss: 0.4084
2022-09-22 11:29:49 - train: epoch 0051, iter [00120, 01251], lr: 0.001198, loss: 0.4079
2022-09-22 11:30:09 - train: epoch 0051, iter [00130, 01251], lr: 0.001198, loss: 0.4142
2022-09-22 11:30:29 - train: epoch 0051, iter [00140, 01251], lr: 0.001198, loss: 0.4204
2022-09-22 11:30:49 - train: epoch 0051, iter [00150, 01251], lr: 0.001198, loss: 0.4249
2022-09-22 11:31:09 - train: epoch 0051, iter [00160, 01251], lr: 0.001198, loss: 0.4389
2022-09-22 11:31:30 - train: epoch 0051, iter [00170, 01251], lr: 0.001198, loss: 0.4341
2022-09-22 11:31:50 - train: epoch 0051, iter [00180, 01251], lr: 0.001198, loss: 0.4261
2022-09-22 11:32:11 - train: epoch 0051, iter [00190, 01251], lr: 0.001198, loss: 0.4078
2022-09-22 11:32:31 - train: epoch 0051, iter [00200, 01251], lr: 0.001198, loss: 0.4141
2022-09-22 11:32:51 - train: epoch 0051, iter [00210, 01251], lr: 0.001198, loss: 0.3923
2022-09-22 11:33:12 - train: epoch 0051, iter [00220, 01251], lr: 0.001198, loss: 0.4161
2022-09-22 11:33:32 - train: epoch 0051, iter [00230, 01251], lr: 0.001198, loss: 0.4173
2022-09-22 11:33:52 - train: epoch 0051, iter [00240, 01251], lr: 0.001198, loss: 0.4167
2022-09-22 11:34:13 - train: epoch 0051, iter [00250, 01251], lr: 0.001198, loss: 0.4134
2022-09-22 11:34:33 - train: epoch 0051, iter [00260, 01251], lr: 0.001198, loss: 0.4120
2022-09-22 11:34:53 - train: epoch 0051, iter [00270, 01251], lr: 0.001198, loss: 0.4332
2022-09-22 11:35:14 - train: epoch 0051, iter [00280, 01251], lr: 0.001198, loss: 0.4243
2022-09-22 11:35:34 - train: epoch 0051, iter [00290, 01251], lr: 0.001198, loss: 0.4350
2022-09-22 11:35:54 - train: epoch 0051, iter [00300, 01251], lr: 0.001198, loss: 0.4208
2022-09-22 11:36:15 - train: epoch 0051, iter [00310, 01251], lr: 0.001198, loss: 0.4152
2022-09-22 11:36:35 - train: epoch 0051, iter [00320, 01251], lr: 0.001198, loss: 0.4042
2022-09-22 11:36:55 - train: epoch 0051, iter [00330, 01251], lr: 0.001198, loss: 0.4129
2022-09-22 11:37:16 - train: epoch 0051, iter [00340, 01251], lr: 0.001198, loss: 0.4133
2022-09-22 11:37:36 - train: epoch 0051, iter [00350, 01251], lr: 0.001198, loss: 0.4155
2022-09-22 11:37:56 - train: epoch 0051, iter [00360, 01251], lr: 0.001198, loss: 0.4174
2022-09-22 11:38:16 - train: epoch 0051, iter [00370, 01251], lr: 0.001198, loss: 0.4277
2022-09-22 11:38:37 - train: epoch 0051, iter [00380, 01251], lr: 0.001198, loss: 0.4127
2022-09-22 11:38:57 - train: epoch 0051, iter [00390, 01251], lr: 0.001198, loss: 0.4214
2022-09-22 11:39:17 - train: epoch 0051, iter [00400, 01251], lr: 0.001198, loss: 0.4283
2022-09-22 11:39:38 - train: epoch 0051, iter [00410, 01251], lr: 0.001198, loss: 0.4362
2022-09-22 11:39:58 - train: epoch 0051, iter [00420, 01251], lr: 0.001198, loss: 0.4081
2022-09-22 11:40:19 - train: epoch 0051, iter [00430, 01251], lr: 0.001198, loss: 0.4080
2022-09-22 11:40:39 - train: epoch 0051, iter [00440, 01251], lr: 0.001198, loss: 0.4357
2022-09-22 11:41:00 - train: epoch 0051, iter [00450, 01251], lr: 0.001198, loss: 0.4250
2022-09-22 11:41:20 - train: epoch 0051, iter [00460, 01251], lr: 0.001198, loss: 0.4100
2022-09-22 11:41:41 - train: epoch 0051, iter [00470, 01251], lr: 0.001198, loss: 0.4160
2022-09-22 11:42:01 - train: epoch 0051, iter [00480, 01251], lr: 0.001198, loss: 0.4165
2022-09-22 11:42:22 - train: epoch 0051, iter [00490, 01251], lr: 0.001198, loss: 0.4111
2022-09-22 11:42:42 - train: epoch 0051, iter [00500, 01251], lr: 0.001198, loss: 0.4010
2022-09-22 11:43:03 - train: epoch 0051, iter [00510, 01251], lr: 0.001198, loss: 0.4061
2022-09-22 11:43:23 - train: epoch 0051, iter [00520, 01251], lr: 0.001198, loss: 0.4210
2022-09-22 11:43:44 - train: epoch 0051, iter [00530, 01251], lr: 0.001198, loss: 0.4207
2022-09-22 11:44:04 - train: epoch 0051, iter [00540, 01251], lr: 0.001198, loss: 0.4246
2022-09-22 11:44:25 - train: epoch 0051, iter [00550, 01251], lr: 0.001198, loss: 0.4264
2022-09-22 11:44:45 - train: epoch 0051, iter [00560, 01251], lr: 0.001198, loss: 0.4296
2022-09-22 11:45:05 - train: epoch 0051, iter [00570, 01251], lr: 0.001198, loss: 0.4179
2022-09-22 11:45:26 - train: epoch 0051, iter [00580, 01251], lr: 0.001198, loss: 0.4334
2022-09-22 11:45:46 - train: epoch 0051, iter [00590, 01251], lr: 0.001197, loss: 0.4146
2022-09-22 11:46:07 - train: epoch 0051, iter [00600, 01251], lr: 0.001197, loss: 0.4157
2022-09-22 11:46:27 - train: epoch 0051, iter [00610, 01251], lr: 0.001197, loss: 0.4181
2022-09-22 11:46:48 - train: epoch 0051, iter [00620, 01251], lr: 0.001197, loss: 0.4145
2022-09-22 11:47:08 - train: epoch 0051, iter [00630, 01251], lr: 0.001197, loss: 0.4349
2022-09-22 11:47:29 - train: epoch 0051, iter [00640, 01251], lr: 0.001197, loss: 0.4106
2022-09-22 11:47:49 - train: epoch 0051, iter [00650, 01251], lr: 0.001197, loss: 0.4165
2022-09-22 11:48:10 - train: epoch 0051, iter [00660, 01251], lr: 0.001197, loss: 0.4085
2022-09-22 11:48:30 - train: epoch 0051, iter [00670, 01251], lr: 0.001197, loss: 0.4113
2022-09-22 11:48:51 - train: epoch 0051, iter [00680, 01251], lr: 0.001197, loss: 0.4100
2022-09-22 11:49:11 - train: epoch 0051, iter [00690, 01251], lr: 0.001197, loss: 0.4166
2022-09-22 11:49:32 - train: epoch 0051, iter [00700, 01251], lr: 0.001197, loss: 0.4230
2022-09-22 11:49:52 - train: epoch 0051, iter [00710, 01251], lr: 0.001197, loss: 0.4214
2022-09-22 11:50:12 - train: epoch 0051, iter [00720, 01251], lr: 0.001197, loss: 0.4108
2022-09-22 11:50:33 - train: epoch 0051, iter [00730, 01251], lr: 0.001197, loss: 0.4241
2022-09-22 11:50:53 - train: epoch 0051, iter [00740, 01251], lr: 0.001197, loss: 0.4018
2022-09-22 11:51:14 - train: epoch 0051, iter [00750, 01251], lr: 0.001197, loss: 0.4293
2022-09-22 11:51:34 - train: epoch 0051, iter [00760, 01251], lr: 0.001197, loss: 0.4116
2022-09-22 11:51:55 - train: epoch 0051, iter [00770, 01251], lr: 0.001197, loss: 0.4109
2022-09-22 11:52:15 - train: epoch 0051, iter [00780, 01251], lr: 0.001197, loss: 0.4041
2022-09-22 11:52:36 - train: epoch 0051, iter [00790, 01251], lr: 0.001197, loss: 0.4209
2022-09-22 11:52:56 - train: epoch 0051, iter [00800, 01251], lr: 0.001197, loss: 0.4207
2022-09-22 11:53:17 - train: epoch 0051, iter [00810, 01251], lr: 0.001197, loss: 0.4162
2022-09-22 11:53:37 - train: epoch 0051, iter [00820, 01251], lr: 0.001197, loss: 0.4258
2022-09-22 11:53:58 - train: epoch 0051, iter [00830, 01251], lr: 0.001197, loss: 0.4060
2022-09-22 11:54:18 - train: epoch 0051, iter [00840, 01251], lr: 0.001197, loss: 0.4333
2022-09-22 11:54:39 - train: epoch 0051, iter [00850, 01251], lr: 0.001197, loss: 0.4047
2022-09-22 11:54:59 - train: epoch 0051, iter [00860, 01251], lr: 0.001197, loss: 0.4300
2022-09-22 11:55:20 - train: epoch 0051, iter [00870, 01251], lr: 0.001197, loss: 0.4210
2022-09-22 11:55:40 - train: epoch 0051, iter [00880, 01251], lr: 0.001197, loss: 0.4020
2022-09-22 11:56:01 - train: epoch 0051, iter [00890, 01251], lr: 0.001197, loss: 0.4217
2022-09-22 11:56:21 - train: epoch 0051, iter [00900, 01251], lr: 0.001197, loss: 0.4407
2022-09-22 11:56:42 - train: epoch 0051, iter [00910, 01251], lr: 0.001197, loss: 0.4184
2022-09-22 11:57:02 - train: epoch 0051, iter [00920, 01251], lr: 0.001197, loss: 0.4074
2022-09-22 11:57:23 - train: epoch 0051, iter [00930, 01251], lr: 0.001197, loss: 0.4184
2022-09-22 11:57:44 - train: epoch 0051, iter [00940, 01251], lr: 0.001197, loss: 0.4194
2022-09-22 11:58:05 - train: epoch 0051, iter [00950, 01251], lr: 0.001197, loss: 0.4105
2022-09-22 11:58:25 - train: epoch 0051, iter [00960, 01251], lr: 0.001197, loss: 0.4236
2022-09-22 11:58:46 - train: epoch 0051, iter [00970, 01251], lr: 0.001197, loss: 0.4417
2022-09-22 11:59:06 - train: epoch 0051, iter [00980, 01251], lr: 0.001197, loss: 0.4137
2022-09-22 11:59:27 - train: epoch 0051, iter [00990, 01251], lr: 0.001197, loss: 0.3902
2022-09-22 11:59:47 - train: epoch 0051, iter [01000, 01251], lr: 0.001197, loss: 0.4187
2022-09-22 12:00:08 - train: epoch 0051, iter [01010, 01251], lr: 0.001197, loss: 0.4178
2022-09-22 12:00:29 - train: epoch 0051, iter [01020, 01251], lr: 0.001197, loss: 0.4105
2022-09-22 12:00:49 - train: epoch 0051, iter [01030, 01251], lr: 0.001197, loss: 0.4200
2022-09-22 12:01:10 - train: epoch 0051, iter [01040, 01251], lr: 0.001197, loss: 0.4037
2022-09-22 12:01:31 - train: epoch 0051, iter [01050, 01251], lr: 0.001197, loss: 0.4156
2022-09-22 12:01:51 - train: epoch 0051, iter [01060, 01251], lr: 0.001197, loss: 0.4310
2022-09-22 12:02:12 - train: epoch 0051, iter [01070, 01251], lr: 0.001197, loss: 0.4309
2022-09-22 12:02:33 - train: epoch 0051, iter [01080, 01251], lr: 0.001197, loss: 0.4341
2022-09-22 12:02:53 - train: epoch 0051, iter [01090, 01251], lr: 0.001197, loss: 0.4287
2022-09-22 12:03:14 - train: epoch 0051, iter [01100, 01251], lr: 0.001197, loss: 0.4193
2022-09-22 12:03:34 - train: epoch 0051, iter [01110, 01251], lr: 0.001197, loss: 0.4195
2022-09-22 12:03:55 - train: epoch 0051, iter [01120, 01251], lr: 0.001197, loss: 0.4001
2022-09-22 12:04:15 - train: epoch 0051, iter [01130, 01251], lr: 0.001197, loss: 0.4079
2022-09-22 12:04:36 - train: epoch 0051, iter [01140, 01251], lr: 0.001197, loss: 0.4099
2022-09-22 12:04:57 - train: epoch 0051, iter [01150, 01251], lr: 0.001197, loss: 0.4180
2022-09-22 12:05:18 - train: epoch 0051, iter [01160, 01251], lr: 0.001197, loss: 0.4117
2022-09-22 12:05:38 - train: epoch 0051, iter [01170, 01251], lr: 0.001197, loss: 0.4187
2022-09-22 12:05:59 - train: epoch 0051, iter [01180, 01251], lr: 0.001197, loss: 0.4000
2022-09-22 12:06:19 - train: epoch 0051, iter [01190, 01251], lr: 0.001197, loss: 0.4370
2022-09-22 12:06:40 - train: epoch 0051, iter [01200, 01251], lr: 0.001197, loss: 0.4071
2022-09-22 12:07:01 - train: epoch 0051, iter [01210, 01251], lr: 0.001197, loss: 0.4364
2022-09-22 12:07:21 - train: epoch 0051, iter [01220, 01251], lr: 0.001197, loss: 0.4102
2022-09-22 12:07:42 - train: epoch 0051, iter [01230, 01251], lr: 0.001197, loss: 0.4068
2022-09-22 12:08:03 - train: epoch 0051, iter [01240, 01251], lr: 0.001197, loss: 0.4015
2022-09-22 12:08:22 - train: epoch 0051, iter [01250, 01251], lr: 0.001197, loss: 0.4167
2022-09-22 12:08:27 - train: epoch 051, train_loss: 0.4182
2022-09-22 12:08:32 - until epoch: 051, best_loss: 0.4182
2022-09-22 12:08:32 - epoch 052 lr: 0.001197
2022-09-22 12:09:09 - train: epoch 0052, iter [00010, 01251], lr: 0.001197, loss: 0.4443
2022-09-22 12:09:30 - train: epoch 0052, iter [00020, 01251], lr: 0.001197, loss: 0.4228
2022-09-22 12:09:51 - train: epoch 0052, iter [00030, 01251], lr: 0.001197, loss: 0.4241
2022-09-22 12:10:11 - train: epoch 0052, iter [00040, 01251], lr: 0.001197, loss: 0.4100
2022-09-22 12:10:32 - train: epoch 0052, iter [00050, 01251], lr: 0.001197, loss: 0.4317
2022-09-22 12:10:52 - train: epoch 0052, iter [00060, 01251], lr: 0.001197, loss: 0.4183
2022-09-22 12:11:13 - train: epoch 0052, iter [00070, 01251], lr: 0.001197, loss: 0.4340
2022-09-22 12:11:33 - train: epoch 0052, iter [00080, 01251], lr: 0.001197, loss: 0.4403
2022-09-22 12:11:53 - train: epoch 0052, iter [00090, 01251], lr: 0.001197, loss: 0.4127
2022-09-22 12:12:13 - train: epoch 0052, iter [00100, 01251], lr: 0.001197, loss: 0.4057
2022-09-22 12:12:34 - train: epoch 0052, iter [00110, 01251], lr: 0.001197, loss: 0.4071
2022-09-22 12:12:54 - train: epoch 0052, iter [00120, 01251], lr: 0.001197, loss: 0.4388
2022-09-22 12:13:14 - train: epoch 0052, iter [00130, 01251], lr: 0.001197, loss: 0.4427
2022-09-22 12:13:35 - train: epoch 0052, iter [00140, 01251], lr: 0.001197, loss: 0.3977
2022-09-22 12:13:55 - train: epoch 0052, iter [00150, 01251], lr: 0.001197, loss: 0.4274
2022-09-22 12:14:15 - train: epoch 0052, iter [00160, 01251], lr: 0.001197, loss: 0.3892
2022-09-22 12:14:36 - train: epoch 0052, iter [00170, 01251], lr: 0.001197, loss: 0.4115
2022-09-22 12:14:56 - train: epoch 0052, iter [00180, 01251], lr: 0.001197, loss: 0.4234
2022-09-22 12:15:16 - train: epoch 0052, iter [00190, 01251], lr: 0.001197, loss: 0.3984
2022-09-22 12:15:37 - train: epoch 0052, iter [00200, 01251], lr: 0.001197, loss: 0.4065
2022-09-22 12:15:57 - train: epoch 0052, iter [00210, 01251], lr: 0.001197, loss: 0.4192
2022-09-22 12:16:18 - train: epoch 0052, iter [00220, 01251], lr: 0.001197, loss: 0.4098
2022-09-22 12:16:38 - train: epoch 0052, iter [00230, 01251], lr: 0.001197, loss: 0.4126
2022-09-22 12:16:58 - train: epoch 0052, iter [00240, 01251], lr: 0.001197, loss: 0.4322
2022-09-22 12:17:19 - train: epoch 0052, iter [00250, 01251], lr: 0.001197, loss: 0.4007
2022-09-22 12:17:40 - train: epoch 0052, iter [00260, 01251], lr: 0.001197, loss: 0.4042
2022-09-22 12:18:01 - train: epoch 0052, iter [00270, 01251], lr: 0.001197, loss: 0.4261
2022-09-22 12:18:21 - train: epoch 0052, iter [00280, 01251], lr: 0.001197, loss: 0.4008
2022-09-22 12:18:42 - train: epoch 0052, iter [00290, 01251], lr: 0.001197, loss: 0.4256
2022-09-22 12:19:03 - train: epoch 0052, iter [00300, 01251], lr: 0.001197, loss: 0.4233
2022-09-22 12:19:23 - train: epoch 0052, iter [00310, 01251], lr: 0.001197, loss: 0.4198
2022-09-22 12:19:44 - train: epoch 0052, iter [00320, 01251], lr: 0.001197, loss: 0.4239
2022-09-22 12:20:05 - train: epoch 0052, iter [00330, 01251], lr: 0.001197, loss: 0.4470
2022-09-22 12:20:25 - train: epoch 0052, iter [00340, 01251], lr: 0.001197, loss: 0.4179
2022-09-22 12:20:46 - train: epoch 0052, iter [00350, 01251], lr: 0.001197, loss: 0.4014
2022-09-22 12:21:07 - train: epoch 0052, iter [00360, 01251], lr: 0.001197, loss: 0.4114
2022-09-22 12:21:28 - train: epoch 0052, iter [00370, 01251], lr: 0.001197, loss: 0.4044
2022-09-22 12:21:48 - train: epoch 0052, iter [00380, 01251], lr: 0.001197, loss: 0.4352
2022-09-22 12:22:09 - train: epoch 0052, iter [00390, 01251], lr: 0.001197, loss: 0.4174
2022-09-22 12:22:30 - train: epoch 0052, iter [00400, 01251], lr: 0.001197, loss: 0.4096
2022-09-22 12:22:51 - train: epoch 0052, iter [00410, 01251], lr: 0.001197, loss: 0.4207
2022-09-22 12:23:11 - train: epoch 0052, iter [00420, 01251], lr: 0.001197, loss: 0.4283
2022-09-22 12:23:32 - train: epoch 0052, iter [00430, 01251], lr: 0.001197, loss: 0.4139
2022-09-22 12:23:53 - train: epoch 0052, iter [00440, 01251], lr: 0.001197, loss: 0.4033
2022-09-22 12:24:14 - train: epoch 0052, iter [00450, 01251], lr: 0.001197, loss: 0.4404
2022-09-22 12:24:34 - train: epoch 0052, iter [00460, 01251], lr: 0.001197, loss: 0.4024
2022-09-22 12:24:55 - train: epoch 0052, iter [00470, 01251], lr: 0.001197, loss: 0.4120
2022-09-22 12:25:16 - train: epoch 0052, iter [00480, 01251], lr: 0.001197, loss: 0.4043
2022-09-22 12:25:37 - train: epoch 0052, iter [00490, 01251], lr: 0.001197, loss: 0.4268
2022-09-22 12:25:57 - train: epoch 0052, iter [00500, 01251], lr: 0.001197, loss: 0.4300
2022-09-22 12:26:18 - train: epoch 0052, iter [00510, 01251], lr: 0.001197, loss: 0.4032
2022-09-22 12:26:39 - train: epoch 0052, iter [00520, 01251], lr: 0.001197, loss: 0.4331
2022-09-22 12:27:00 - train: epoch 0052, iter [00530, 01251], lr: 0.001197, loss: 0.4212
2022-09-22 12:27:20 - train: epoch 0052, iter [00540, 01251], lr: 0.001197, loss: 0.4135
2022-09-22 12:27:41 - train: epoch 0052, iter [00550, 01251], lr: 0.001197, loss: 0.4326
2022-09-22 12:28:02 - train: epoch 0052, iter [00560, 01251], lr: 0.001197, loss: 0.4410
2022-09-22 12:28:22 - train: epoch 0052, iter [00570, 01251], lr: 0.001197, loss: 0.4191
2022-09-22 12:28:43 - train: epoch 0052, iter [00580, 01251], lr: 0.001197, loss: 0.4170
2022-09-22 12:29:04 - train: epoch 0052, iter [00590, 01251], lr: 0.001197, loss: 0.4091
2022-09-22 12:29:24 - train: epoch 0052, iter [00600, 01251], lr: 0.001197, loss: 0.4155
2022-09-22 12:29:45 - train: epoch 0052, iter [00610, 01251], lr: 0.001197, loss: 0.4152
2022-09-22 12:30:06 - train: epoch 0052, iter [00620, 01251], lr: 0.001197, loss: 0.4105
2022-09-22 12:30:26 - train: epoch 0052, iter [00630, 01251], lr: 0.001197, loss: 0.4006
2022-09-22 12:30:47 - train: epoch 0052, iter [00640, 01251], lr: 0.001197, loss: 0.4032
2022-09-22 12:31:08 - train: epoch 0052, iter [00650, 01251], lr: 0.001197, loss: 0.3946
2022-09-22 12:31:28 - train: epoch 0052, iter [00660, 01251], lr: 0.001197, loss: 0.4100
2022-09-22 12:31:48 - train: epoch 0052, iter [00670, 01251], lr: 0.001197, loss: 0.4232
2022-09-22 12:32:09 - train: epoch 0052, iter [00680, 01251], lr: 0.001197, loss: 0.4415
2022-09-22 12:32:29 - train: epoch 0052, iter [00690, 01251], lr: 0.001197, loss: 0.4185
2022-09-22 12:32:49 - train: epoch 0052, iter [00700, 01251], lr: 0.001197, loss: 0.4282
2022-09-22 12:33:10 - train: epoch 0052, iter [00710, 01251], lr: 0.001197, loss: 0.4230
2022-09-22 12:33:30 - train: epoch 0052, iter [00720, 01251], lr: 0.001197, loss: 0.4017
2022-09-22 12:33:50 - train: epoch 0052, iter [00730, 01251], lr: 0.001197, loss: 0.4100
2022-09-22 12:34:11 - train: epoch 0052, iter [00740, 01251], lr: 0.001197, loss: 0.4040
2022-09-22 12:34:31 - train: epoch 0052, iter [00750, 01251], lr: 0.001197, loss: 0.4162
2022-09-22 12:34:51 - train: epoch 0052, iter [00760, 01251], lr: 0.001197, loss: 0.4236
2022-09-22 12:35:12 - train: epoch 0052, iter [00770, 01251], lr: 0.001197, loss: 0.4278
2022-09-22 12:35:32 - train: epoch 0052, iter [00780, 01251], lr: 0.001197, loss: 0.4179
2022-09-22 12:35:53 - train: epoch 0052, iter [00790, 01251], lr: 0.001197, loss: 0.4310
2022-09-22 12:36:13 - train: epoch 0052, iter [00800, 01251], lr: 0.001197, loss: 0.4226
2022-09-22 12:36:33 - train: epoch 0052, iter [00810, 01251], lr: 0.001197, loss: 0.4197
2022-09-22 12:36:54 - train: epoch 0052, iter [00820, 01251], lr: 0.001197, loss: 0.4072
2022-09-22 12:37:14 - train: epoch 0052, iter [00830, 01251], lr: 0.001197, loss: 0.4154
2022-09-22 12:37:35 - train: epoch 0052, iter [00840, 01251], lr: 0.001197, loss: 0.4266
2022-09-22 12:37:55 - train: epoch 0052, iter [00850, 01251], lr: 0.001197, loss: 0.4279
2022-09-22 12:38:15 - train: epoch 0052, iter [00860, 01251], lr: 0.001197, loss: 0.4089
2022-09-22 12:38:36 - train: epoch 0052, iter [00870, 01251], lr: 0.001197, loss: 0.4164
2022-09-22 12:38:56 - train: epoch 0052, iter [00880, 01251], lr: 0.001197, loss: 0.4236
2022-09-22 12:39:16 - train: epoch 0052, iter [00890, 01251], lr: 0.001197, loss: 0.4099
2022-09-22 12:39:37 - train: epoch 0052, iter [00900, 01251], lr: 0.001197, loss: 0.4034
2022-09-22 12:39:57 - train: epoch 0052, iter [00910, 01251], lr: 0.001197, loss: 0.4047
2022-09-22 12:40:17 - train: epoch 0052, iter [00920, 01251], lr: 0.001197, loss: 0.4008
2022-09-22 12:40:38 - train: epoch 0052, iter [00930, 01251], lr: 0.001197, loss: 0.4260
2022-09-22 12:40:58 - train: epoch 0052, iter [00940, 01251], lr: 0.001197, loss: 0.4253
2022-09-22 12:41:18 - train: epoch 0052, iter [00950, 01251], lr: 0.001197, loss: 0.4308
2022-09-22 12:41:39 - train: epoch 0052, iter [00960, 01251], lr: 0.001197, loss: 0.4105
2022-09-22 12:41:59 - train: epoch 0052, iter [00970, 01251], lr: 0.001197, loss: 0.4143
2022-09-22 12:42:19 - train: epoch 0052, iter [00980, 01251], lr: 0.001197, loss: 0.4099
2022-09-22 12:42:40 - train: epoch 0052, iter [00990, 01251], lr: 0.001197, loss: 0.4187
2022-09-22 12:43:00 - train: epoch 0052, iter [01000, 01251], lr: 0.001197, loss: 0.4172
2022-09-22 12:43:21 - train: epoch 0052, iter [01010, 01251], lr: 0.001197, loss: 0.4113
2022-09-22 12:43:41 - train: epoch 0052, iter [01020, 01251], lr: 0.001197, loss: 0.4354
2022-09-22 12:44:02 - train: epoch 0052, iter [01030, 01251], lr: 0.001197, loss: 0.3956
2022-09-22 12:44:22 - train: epoch 0052, iter [01040, 01251], lr: 0.001197, loss: 0.4380
2022-09-22 12:44:42 - train: epoch 0052, iter [01050, 01251], lr: 0.001197, loss: 0.3901
2022-09-22 12:45:03 - train: epoch 0052, iter [01060, 01251], lr: 0.001197, loss: 0.4232
2022-09-22 12:45:23 - train: epoch 0052, iter [01070, 01251], lr: 0.001197, loss: 0.4435
2022-09-22 12:45:43 - train: epoch 0052, iter [01080, 01251], lr: 0.001197, loss: 0.4292
2022-09-22 12:46:04 - train: epoch 0052, iter [01090, 01251], lr: 0.001197, loss: 0.4155
2022-09-22 12:46:24 - train: epoch 0052, iter [01100, 01251], lr: 0.001197, loss: 0.4016
2022-09-22 12:46:45 - train: epoch 0052, iter [01110, 01251], lr: 0.001197, loss: 0.4210
2022-09-22 12:47:05 - train: epoch 0052, iter [01120, 01251], lr: 0.001197, loss: 0.4212
2022-09-22 12:47:25 - train: epoch 0052, iter [01130, 01251], lr: 0.001197, loss: 0.4055
2022-09-22 12:47:46 - train: epoch 0052, iter [01140, 01251], lr: 0.001197, loss: 0.4392
2022-09-22 12:48:06 - train: epoch 0052, iter [01150, 01251], lr: 0.001197, loss: 0.4109
2022-09-22 12:48:27 - train: epoch 0052, iter [01160, 01251], lr: 0.001197, loss: 0.4067
2022-09-22 12:48:47 - train: epoch 0052, iter [01170, 01251], lr: 0.001197, loss: 0.4199
2022-09-22 12:49:08 - train: epoch 0052, iter [01180, 01251], lr: 0.001197, loss: 0.4281
2022-09-22 12:49:28 - train: epoch 0052, iter [01190, 01251], lr: 0.001197, loss: 0.4087
2022-09-22 12:49:49 - train: epoch 0052, iter [01200, 01251], lr: 0.001197, loss: 0.4166
2022-09-22 12:50:10 - train: epoch 0052, iter [01210, 01251], lr: 0.001197, loss: 0.4091
2022-09-22 12:50:30 - train: epoch 0052, iter [01220, 01251], lr: 0.001197, loss: 0.4156
2022-09-22 12:50:51 - train: epoch 0052, iter [01230, 01251], lr: 0.001197, loss: 0.3988
2022-09-22 12:51:11 - train: epoch 0052, iter [01240, 01251], lr: 0.001197, loss: 0.4106
2022-09-22 12:51:31 - train: epoch 0052, iter [01250, 01251], lr: 0.001197, loss: 0.4162
2022-09-22 12:51:35 - train: epoch 052, train_loss: 0.4179
2022-09-22 12:51:40 - until epoch: 052, best_loss: 0.4179
2022-09-22 12:51:40 - epoch 053 lr: 0.001197
2022-09-22 12:52:17 - train: epoch 0053, iter [00010, 01251], lr: 0.001197, loss: 0.4123
2022-09-22 12:52:37 - train: epoch 0053, iter [00020, 01251], lr: 0.001197, loss: 0.4290
2022-09-22 12:52:58 - train: epoch 0053, iter [00030, 01251], lr: 0.001197, loss: 0.4074
2022-09-22 12:53:18 - train: epoch 0053, iter [00040, 01251], lr: 0.001197, loss: 0.4472
2022-09-22 12:53:38 - train: epoch 0053, iter [00050, 01251], lr: 0.001197, loss: 0.4112
2022-09-22 12:53:59 - train: epoch 0053, iter [00060, 01251], lr: 0.001197, loss: 0.4228
2022-09-22 12:54:19 - train: epoch 0053, iter [00070, 01251], lr: 0.001197, loss: 0.4180
2022-09-22 12:54:39 - train: epoch 0053, iter [00080, 01251], lr: 0.001197, loss: 0.4191
2022-09-22 12:55:00 - train: epoch 0053, iter [00090, 01251], lr: 0.001197, loss: 0.4118
2022-09-22 12:55:20 - train: epoch 0053, iter [00100, 01251], lr: 0.001197, loss: 0.4248
2022-09-22 12:55:41 - train: epoch 0053, iter [00110, 01251], lr: 0.001197, loss: 0.4188
2022-09-22 12:56:01 - train: epoch 0053, iter [00120, 01251], lr: 0.001197, loss: 0.4246
2022-09-22 12:56:21 - train: epoch 0053, iter [00130, 01251], lr: 0.001197, loss: 0.4173
2022-09-22 12:56:42 - train: epoch 0053, iter [00140, 01251], lr: 0.001197, loss: 0.4111
2022-09-22 12:57:02 - train: epoch 0053, iter [00150, 01251], lr: 0.001197, loss: 0.4196
2022-09-22 12:57:23 - train: epoch 0053, iter [00160, 01251], lr: 0.001197, loss: 0.4228
2022-09-22 12:57:43 - train: epoch 0053, iter [00170, 01251], lr: 0.001197, loss: 0.4119
2022-09-22 12:58:03 - train: epoch 0053, iter [00180, 01251], lr: 0.001197, loss: 0.3916
2022-09-22 12:58:23 - train: epoch 0053, iter [00190, 01251], lr: 0.001197, loss: 0.4152
2022-09-22 12:58:44 - train: epoch 0053, iter [00200, 01251], lr: 0.001197, loss: 0.4356
2022-09-22 12:59:04 - train: epoch 0053, iter [00210, 01251], lr: 0.001197, loss: 0.4439
2022-09-22 12:59:24 - train: epoch 0053, iter [00220, 01251], lr: 0.001197, loss: 0.4214
2022-09-22 12:59:45 - train: epoch 0053, iter [00230, 01251], lr: 0.001197, loss: 0.4196
2022-09-22 13:00:05 - train: epoch 0053, iter [00240, 01251], lr: 0.001197, loss: 0.4201
2022-09-22 13:00:25 - train: epoch 0053, iter [00250, 01251], lr: 0.001197, loss: 0.4217
2022-09-22 13:00:46 - train: epoch 0053, iter [00260, 01251], lr: 0.001197, loss: 0.4300
2022-09-22 13:01:06 - train: epoch 0053, iter [00270, 01251], lr: 0.001197, loss: 0.4333
2022-09-22 13:01:26 - train: epoch 0053, iter [00280, 01251], lr: 0.001197, loss: 0.4314
2022-09-22 13:01:47 - train: epoch 0053, iter [00290, 01251], lr: 0.001197, loss: 0.4105
2022-09-22 13:02:07 - train: epoch 0053, iter [00300, 01251], lr: 0.001197, loss: 0.4221
2022-09-22 13:02:27 - train: epoch 0053, iter [00310, 01251], lr: 0.001197, loss: 0.4218
2022-09-22 13:02:48 - train: epoch 0053, iter [00320, 01251], lr: 0.001197, loss: 0.4201
2022-09-22 13:03:08 - train: epoch 0053, iter [00330, 01251], lr: 0.001197, loss: 0.4272
2022-09-22 13:03:28 - train: epoch 0053, iter [00340, 01251], lr: 0.001197, loss: 0.4172
2022-09-22 13:03:49 - train: epoch 0053, iter [00350, 01251], lr: 0.001197, loss: 0.4054
2022-09-22 13:04:09 - train: epoch 0053, iter [00360, 01251], lr: 0.001197, loss: 0.4253
2022-09-22 13:04:29 - train: epoch 0053, iter [00370, 01251], lr: 0.001197, loss: 0.4253
2022-09-22 13:04:50 - train: epoch 0053, iter [00380, 01251], lr: 0.001197, loss: 0.4207
2022-09-22 13:05:10 - train: epoch 0053, iter [00390, 01251], lr: 0.001197, loss: 0.4044
2022-09-22 13:05:30 - train: epoch 0053, iter [00400, 01251], lr: 0.001197, loss: 0.4108
2022-09-22 13:05:51 - train: epoch 0053, iter [00410, 01251], lr: 0.001197, loss: 0.4159
2022-09-22 13:06:11 - train: epoch 0053, iter [00420, 01251], lr: 0.001197, loss: 0.4299
2022-09-22 13:06:31 - train: epoch 0053, iter [00430, 01251], lr: 0.001197, loss: 0.4311
2022-09-22 13:06:52 - train: epoch 0053, iter [00440, 01251], lr: 0.001197, loss: 0.4225
2022-09-22 13:07:12 - train: epoch 0053, iter [00450, 01251], lr: 0.001197, loss: 0.4187
2022-09-22 13:07:32 - train: epoch 0053, iter [00460, 01251], lr: 0.001197, loss: 0.4326
2022-09-22 13:07:53 - train: epoch 0053, iter [00470, 01251], lr: 0.001197, loss: 0.4155
2022-09-22 13:08:13 - train: epoch 0053, iter [00480, 01251], lr: 0.001196, loss: 0.4258
2022-09-22 13:08:34 - train: epoch 0053, iter [00490, 01251], lr: 0.001196, loss: 0.4285
2022-09-22 13:08:54 - train: epoch 0053, iter [00500, 01251], lr: 0.001196, loss: 0.4242
2022-09-22 13:09:14 - train: epoch 0053, iter [00510, 01251], lr: 0.001196, loss: 0.4409
2022-09-22 13:09:35 - train: epoch 0053, iter [00520, 01251], lr: 0.001196, loss: 0.4148
2022-09-22 13:09:55 - train: epoch 0053, iter [00530, 01251], lr: 0.001196, loss: 0.4340
2022-09-22 13:10:15 - train: epoch 0053, iter [00540, 01251], lr: 0.001196, loss: 0.4040
2022-09-22 13:10:36 - train: epoch 0053, iter [00550, 01251], lr: 0.001196, loss: 0.4375
2022-09-22 13:10:56 - train: epoch 0053, iter [00560, 01251], lr: 0.001196, loss: 0.4258
2022-09-22 13:11:16 - train: epoch 0053, iter [00570, 01251], lr: 0.001196, loss: 0.4228
2022-09-22 13:11:37 - train: epoch 0053, iter [00580, 01251], lr: 0.001196, loss: 0.4247
2022-09-22 13:11:57 - train: epoch 0053, iter [00590, 01251], lr: 0.001196, loss: 0.4064
2022-09-22 13:12:17 - train: epoch 0053, iter [00600, 01251], lr: 0.001196, loss: 0.3885
2022-09-22 13:12:38 - train: epoch 0053, iter [00610, 01251], lr: 0.001196, loss: 0.4107
2022-09-22 13:12:58 - train: epoch 0053, iter [00620, 01251], lr: 0.001196, loss: 0.4144
2022-09-22 13:13:18 - train: epoch 0053, iter [00630, 01251], lr: 0.001196, loss: 0.4150
2022-09-22 13:13:39 - train: epoch 0053, iter [00640, 01251], lr: 0.001196, loss: 0.4242
2022-09-22 13:13:59 - train: epoch 0053, iter [00650, 01251], lr: 0.001196, loss: 0.4117
2022-09-22 13:14:19 - train: epoch 0053, iter [00660, 01251], lr: 0.001196, loss: 0.4197
2022-09-22 13:14:40 - train: epoch 0053, iter [00670, 01251], lr: 0.001196, loss: 0.4202
2022-09-22 13:15:00 - train: epoch 0053, iter [00680, 01251], lr: 0.001196, loss: 0.4168
2022-09-22 13:15:21 - train: epoch 0053, iter [00690, 01251], lr: 0.001196, loss: 0.4196
2022-09-22 13:15:41 - train: epoch 0053, iter [00700, 01251], lr: 0.001196, loss: 0.4319
2022-09-22 13:16:01 - train: epoch 0053, iter [00710, 01251], lr: 0.001196, loss: 0.4186
2022-09-22 13:16:21 - train: epoch 0053, iter [00720, 01251], lr: 0.001196, loss: 0.4332
2022-09-22 13:16:42 - train: epoch 0053, iter [00730, 01251], lr: 0.001196, loss: 0.4154
2022-09-22 13:17:02 - train: epoch 0053, iter [00740, 01251], lr: 0.001196, loss: 0.4060
2022-09-22 13:17:23 - train: epoch 0053, iter [00750, 01251], lr: 0.001196, loss: 0.4188
2022-09-22 13:17:43 - train: epoch 0053, iter [00760, 01251], lr: 0.001196, loss: 0.4026
2022-09-22 13:18:03 - train: epoch 0053, iter [00770, 01251], lr: 0.001196, loss: 0.4056
2022-09-22 13:18:24 - train: epoch 0053, iter [00780, 01251], lr: 0.001196, loss: 0.4187
2022-09-22 13:18:44 - train: epoch 0053, iter [00790, 01251], lr: 0.001196, loss: 0.4027
2022-09-22 13:19:05 - train: epoch 0053, iter [00800, 01251], lr: 0.001196, loss: 0.4016
2022-09-22 13:19:25 - train: epoch 0053, iter [00810, 01251], lr: 0.001196, loss: 0.4137
2022-09-22 13:19:45 - train: epoch 0053, iter [00820, 01251], lr: 0.001196, loss: 0.4326
2022-09-22 13:20:06 - train: epoch 0053, iter [00830, 01251], lr: 0.001196, loss: 0.4308
2022-09-22 13:20:26 - train: epoch 0053, iter [00840, 01251], lr: 0.001196, loss: 0.4162
2022-09-22 13:20:46 - train: epoch 0053, iter [00850, 01251], lr: 0.001196, loss: 0.4446
2022-09-22 13:21:07 - train: epoch 0053, iter [00860, 01251], lr: 0.001196, loss: 0.4233
2022-09-22 13:21:27 - train: epoch 0053, iter [00870, 01251], lr: 0.001196, loss: 0.4258
2022-09-22 13:21:48 - train: epoch 0053, iter [00880, 01251], lr: 0.001196, loss: 0.4085
2022-09-22 13:22:08 - train: epoch 0053, iter [00890, 01251], lr: 0.001196, loss: 0.4091
2022-09-22 13:22:28 - train: epoch 0053, iter [00900, 01251], lr: 0.001196, loss: 0.4227
2022-09-22 13:22:49 - train: epoch 0053, iter [00910, 01251], lr: 0.001196, loss: 0.3927
2022-09-22 13:23:09 - train: epoch 0053, iter [00920, 01251], lr: 0.001196, loss: 0.4039
2022-09-22 13:23:30 - train: epoch 0053, iter [00930, 01251], lr: 0.001196, loss: 0.4201
2022-09-22 13:23:50 - train: epoch 0053, iter [00940, 01251], lr: 0.001196, loss: 0.4016
2022-09-22 13:24:10 - train: epoch 0053, iter [00950, 01251], lr: 0.001196, loss: 0.4077
2022-09-22 13:24:31 - train: epoch 0053, iter [00960, 01251], lr: 0.001196, loss: 0.4215
2022-09-22 13:24:51 - train: epoch 0053, iter [00970, 01251], lr: 0.001196, loss: 0.4051
2022-09-22 13:25:11 - train: epoch 0053, iter [00980, 01251], lr: 0.001196, loss: 0.4048
2022-09-22 13:25:32 - train: epoch 0053, iter [00990, 01251], lr: 0.001196, loss: 0.3908
2022-09-22 13:25:52 - train: epoch 0053, iter [01000, 01251], lr: 0.001196, loss: 0.4241
2022-09-22 13:26:13 - train: epoch 0053, iter [01010, 01251], lr: 0.001196, loss: 0.4009
2022-09-22 13:26:33 - train: epoch 0053, iter [01020, 01251], lr: 0.001196, loss: 0.4273
2022-09-22 13:26:53 - train: epoch 0053, iter [01030, 01251], lr: 0.001196, loss: 0.3930
2022-09-22 13:27:14 - train: epoch 0053, iter [01040, 01251], lr: 0.001196, loss: 0.4163
2022-09-22 13:27:34 - train: epoch 0053, iter [01050, 01251], lr: 0.001196, loss: 0.4288
2022-09-22 13:27:54 - train: epoch 0053, iter [01060, 01251], lr: 0.001196, loss: 0.4182
2022-09-22 13:28:15 - train: epoch 0053, iter [01070, 01251], lr: 0.001196, loss: 0.4186
2022-09-22 13:28:35 - train: epoch 0053, iter [01080, 01251], lr: 0.001196, loss: 0.4163
2022-09-22 13:28:56 - train: epoch 0053, iter [01090, 01251], lr: 0.001196, loss: 0.4352
2022-09-22 13:29:16 - train: epoch 0053, iter [01100, 01251], lr: 0.001196, loss: 0.4339
2022-09-22 13:29:36 - train: epoch 0053, iter [01110, 01251], lr: 0.001196, loss: 0.4265
2022-09-22 13:29:57 - train: epoch 0053, iter [01120, 01251], lr: 0.001196, loss: 0.4132
2022-09-22 13:30:17 - train: epoch 0053, iter [01130, 01251], lr: 0.001196, loss: 0.4080
2022-09-22 13:30:38 - train: epoch 0053, iter [01140, 01251], lr: 0.001196, loss: 0.4143
2022-09-22 13:30:58 - train: epoch 0053, iter [01150, 01251], lr: 0.001196, loss: 0.4010
2022-09-22 13:31:19 - train: epoch 0053, iter [01160, 01251], lr: 0.001196, loss: 0.4239
2022-09-22 13:31:39 - train: epoch 0053, iter [01170, 01251], lr: 0.001196, loss: 0.4195
2022-09-22 13:31:59 - train: epoch 0053, iter [01180, 01251], lr: 0.001196, loss: 0.4112
2022-09-22 13:32:20 - train: epoch 0053, iter [01190, 01251], lr: 0.001196, loss: 0.4034
2022-09-22 13:32:40 - train: epoch 0053, iter [01200, 01251], lr: 0.001196, loss: 0.3961
2022-09-22 13:33:00 - train: epoch 0053, iter [01210, 01251], lr: 0.001196, loss: 0.4284
2022-09-22 13:33:21 - train: epoch 0053, iter [01220, 01251], lr: 0.001196, loss: 0.4184
2022-09-22 13:33:41 - train: epoch 0053, iter [01230, 01251], lr: 0.001196, loss: 0.4122
2022-09-22 13:34:02 - train: epoch 0053, iter [01240, 01251], lr: 0.001196, loss: 0.3973
2022-09-22 13:34:21 - train: epoch 0053, iter [01250, 01251], lr: 0.001196, loss: 0.4116
2022-09-22 13:34:26 - train: epoch 053, train_loss: 0.4178
2022-09-22 13:34:31 - until epoch: 053, best_loss: 0.4178
2022-09-22 13:34:31 - epoch 054 lr: 0.001196
2022-09-22 13:35:07 - train: epoch 0054, iter [00010, 01251], lr: 0.001196, loss: 0.4057
2022-09-22 13:35:28 - train: epoch 0054, iter [00020, 01251], lr: 0.001196, loss: 0.4258
2022-09-22 13:35:48 - train: epoch 0054, iter [00030, 01251], lr: 0.001196, loss: 0.4297
2022-09-22 13:36:08 - train: epoch 0054, iter [00040, 01251], lr: 0.001196, loss: 0.4133
2022-09-22 13:36:29 - train: epoch 0054, iter [00050, 01251], lr: 0.001196, loss: 0.4134
2022-09-22 13:36:49 - train: epoch 0054, iter [00060, 01251], lr: 0.001196, loss: 0.4018
2022-09-22 13:37:10 - train: epoch 0054, iter [00070, 01251], lr: 0.001196, loss: 0.4083
2022-09-22 13:37:30 - train: epoch 0054, iter [00080, 01251], lr: 0.001196, loss: 0.4189
2022-09-22 13:37:50 - train: epoch 0054, iter [00090, 01251], lr: 0.001196, loss: 0.4115
2022-09-22 13:38:11 - train: epoch 0054, iter [00100, 01251], lr: 0.001196, loss: 0.4210
2022-09-22 13:38:31 - train: epoch 0054, iter [00110, 01251], lr: 0.001196, loss: 0.4082
2022-09-22 13:38:51 - train: epoch 0054, iter [00120, 01251], lr: 0.001196, loss: 0.4133
2022-09-22 13:39:12 - train: epoch 0054, iter [00130, 01251], lr: 0.001196, loss: 0.3995
2022-09-22 13:39:32 - train: epoch 0054, iter [00140, 01251], lr: 0.001196, loss: 0.4278
2022-09-22 13:39:53 - train: epoch 0054, iter [00150, 01251], lr: 0.001196, loss: 0.4104
2022-09-22 13:40:13 - train: epoch 0054, iter [00160, 01251], lr: 0.001196, loss: 0.4093
2022-09-22 13:40:33 - train: epoch 0054, iter [00170, 01251], lr: 0.001196, loss: 0.4146
2022-09-22 13:40:54 - train: epoch 0054, iter [00180, 01251], lr: 0.001196, loss: 0.4148
2022-09-22 13:41:14 - train: epoch 0054, iter [00190, 01251], lr: 0.001196, loss: 0.4052
2022-09-22 13:41:35 - train: epoch 0054, iter [00200, 01251], lr: 0.001196, loss: 0.4122
2022-09-22 13:41:55 - train: epoch 0054, iter [00210, 01251], lr: 0.001196, loss: 0.3963
2022-09-22 13:42:15 - train: epoch 0054, iter [00220, 01251], lr: 0.001196, loss: 0.4114
2022-09-22 13:42:36 - train: epoch 0054, iter [00230, 01251], lr: 0.001196, loss: 0.3829
2022-09-22 13:42:56 - train: epoch 0054, iter [00240, 01251], lr: 0.001196, loss: 0.4240
2022-09-22 13:43:17 - train: epoch 0054, iter [00250, 01251], lr: 0.001196, loss: 0.3953
2022-09-22 13:43:37 - train: epoch 0054, iter [00260, 01251], lr: 0.001196, loss: 0.4130
2022-09-22 13:43:57 - train: epoch 0054, iter [00270, 01251], lr: 0.001196, loss: 0.4048
2022-09-22 13:44:18 - train: epoch 0054, iter [00280, 01251], lr: 0.001196, loss: 0.4301
2022-09-22 13:44:38 - train: epoch 0054, iter [00290, 01251], lr: 0.001196, loss: 0.4097
2022-09-22 13:44:58 - train: epoch 0054, iter [00300, 01251], lr: 0.001196, loss: 0.3974
2022-09-22 13:45:19 - train: epoch 0054, iter [00310, 01251], lr: 0.001196, loss: 0.4316
2022-09-22 13:45:39 - train: epoch 0054, iter [00320, 01251], lr: 0.001196, loss: 0.4352
2022-09-22 13:45:59 - train: epoch 0054, iter [00330, 01251], lr: 0.001196, loss: 0.4047
2022-09-22 13:46:20 - train: epoch 0054, iter [00340, 01251], lr: 0.001196, loss: 0.3969
2022-09-22 13:46:40 - train: epoch 0054, iter [00350, 01251], lr: 0.001196, loss: 0.4086
2022-09-22 13:47:00 - train: epoch 0054, iter [00360, 01251], lr: 0.001196, loss: 0.3978
2022-09-22 13:47:21 - train: epoch 0054, iter [00370, 01251], lr: 0.001196, loss: 0.4218
2022-09-22 13:47:41 - train: epoch 0054, iter [00380, 01251], lr: 0.001196, loss: 0.4143
2022-09-22 13:48:01 - train: epoch 0054, iter [00390, 01251], lr: 0.001196, loss: 0.4110
2022-09-22 13:48:22 - train: epoch 0054, iter [00400, 01251], lr: 0.001196, loss: 0.4173
2022-09-22 13:48:42 - train: epoch 0054, iter [00410, 01251], lr: 0.001196, loss: 0.4153
2022-09-22 13:49:03 - train: epoch 0054, iter [00420, 01251], lr: 0.001196, loss: 0.4019
2022-09-22 13:49:23 - train: epoch 0054, iter [00430, 01251], lr: 0.001196, loss: 0.4042
2022-09-22 13:49:43 - train: epoch 0054, iter [00440, 01251], lr: 0.001196, loss: 0.4372
2022-09-22 13:50:04 - train: epoch 0054, iter [00450, 01251], lr: 0.001196, loss: 0.4038
2022-09-22 13:50:24 - train: epoch 0054, iter [00460, 01251], lr: 0.001196, loss: 0.4135
2022-09-22 13:50:44 - train: epoch 0054, iter [00470, 01251], lr: 0.001196, loss: 0.4275
2022-09-22 13:51:05 - train: epoch 0054, iter [00480, 01251], lr: 0.001196, loss: 0.4108
2022-09-22 13:51:25 - train: epoch 0054, iter [00490, 01251], lr: 0.001196, loss: 0.4194
2022-09-22 13:51:46 - train: epoch 0054, iter [00500, 01251], lr: 0.001196, loss: 0.4073
2022-09-22 13:52:06 - train: epoch 0054, iter [00510, 01251], lr: 0.001196, loss: 0.4276
2022-09-22 13:52:27 - train: epoch 0054, iter [00520, 01251], lr: 0.001196, loss: 0.4085
2022-09-22 13:52:47 - train: epoch 0054, iter [00530, 01251], lr: 0.001196, loss: 0.4103
2022-09-22 13:53:07 - train: epoch 0054, iter [00540, 01251], lr: 0.001196, loss: 0.4280
2022-09-22 13:53:28 - train: epoch 0054, iter [00550, 01251], lr: 0.001196, loss: 0.4073
2022-09-22 13:53:48 - train: epoch 0054, iter [00560, 01251], lr: 0.001196, loss: 0.4416
2022-09-22 13:54:09 - train: epoch 0054, iter [00570, 01251], lr: 0.001196, loss: 0.4295
2022-09-22 13:54:29 - train: epoch 0054, iter [00580, 01251], lr: 0.001196, loss: 0.4275
2022-09-22 13:54:49 - train: epoch 0054, iter [00590, 01251], lr: 0.001196, loss: 0.3933
2022-09-22 13:55:10 - train: epoch 0054, iter [00600, 01251], lr: 0.001196, loss: 0.4234
2022-09-22 13:55:30 - train: epoch 0054, iter [00610, 01251], lr: 0.001196, loss: 0.4380
2022-09-22 13:55:51 - train: epoch 0054, iter [00620, 01251], lr: 0.001196, loss: 0.4191
2022-09-22 13:56:11 - train: epoch 0054, iter [00630, 01251], lr: 0.001196, loss: 0.4246
2022-09-22 13:56:32 - train: epoch 0054, iter [00640, 01251], lr: 0.001196, loss: 0.4383
2022-09-22 13:56:52 - train: epoch 0054, iter [00650, 01251], lr: 0.001196, loss: 0.4138
2022-09-22 13:57:12 - train: epoch 0054, iter [00660, 01251], lr: 0.001196, loss: 0.4170
2022-09-22 13:57:33 - train: epoch 0054, iter [00670, 01251], lr: 0.001196, loss: 0.4093
2022-09-22 13:57:53 - train: epoch 0054, iter [00680, 01251], lr: 0.001196, loss: 0.4297
2022-09-22 13:58:14 - train: epoch 0054, iter [00690, 01251], lr: 0.001196, loss: 0.4027
2022-09-22 13:58:34 - train: epoch 0054, iter [00700, 01251], lr: 0.001196, loss: 0.4393
2022-09-22 13:58:55 - train: epoch 0054, iter [00710, 01251], lr: 0.001196, loss: 0.4248
2022-09-22 13:59:15 - train: epoch 0054, iter [00720, 01251], lr: 0.001196, loss: 0.4076
2022-09-22 13:59:36 - train: epoch 0054, iter [00730, 01251], lr: 0.001196, loss: 0.4128
2022-09-22 13:59:56 - train: epoch 0054, iter [00740, 01251], lr: 0.001196, loss: 0.4033
2022-09-22 14:00:16 - train: epoch 0054, iter [00750, 01251], lr: 0.001196, loss: 0.4203
2022-09-22 14:00:37 - train: epoch 0054, iter [00760, 01251], lr: 0.001196, loss: 0.4100
2022-09-22 14:00:57 - train: epoch 0054, iter [00770, 01251], lr: 0.001196, loss: 0.4059
2022-09-22 14:01:18 - train: epoch 0054, iter [00780, 01251], lr: 0.001196, loss: 0.4145
2022-09-22 14:01:38 - train: epoch 0054, iter [00790, 01251], lr: 0.001196, loss: 0.3861
2022-09-22 14:01:58 - train: epoch 0054, iter [00800, 01251], lr: 0.001196, loss: 0.4186
2022-09-22 14:02:19 - train: epoch 0054, iter [00810, 01251], lr: 0.001196, loss: 0.4111
2022-09-22 14:02:39 - train: epoch 0054, iter [00820, 01251], lr: 0.001196, loss: 0.4000
2022-09-22 14:02:59 - train: epoch 0054, iter [00830, 01251], lr: 0.001196, loss: 0.4170
2022-09-22 14:03:20 - train: epoch 0054, iter [00840, 01251], lr: 0.001196, loss: 0.4270
2022-09-22 14:03:40 - train: epoch 0054, iter [00850, 01251], lr: 0.001196, loss: 0.4199
2022-09-22 14:04:01 - train: epoch 0054, iter [00860, 01251], lr: 0.001196, loss: 0.4182
2022-09-22 14:04:21 - train: epoch 0054, iter [00870, 01251], lr: 0.001196, loss: 0.4458
2022-09-22 14:04:41 - train: epoch 0054, iter [00880, 01251], lr: 0.001196, loss: 0.4235
2022-09-22 14:05:02 - train: epoch 0054, iter [00890, 01251], lr: 0.001196, loss: 0.4479
2022-09-22 14:05:22 - train: epoch 0054, iter [00900, 01251], lr: 0.001196, loss: 0.4143
2022-09-22 14:05:43 - train: epoch 0054, iter [00910, 01251], lr: 0.001196, loss: 0.4244
2022-09-22 14:06:03 - train: epoch 0054, iter [00920, 01251], lr: 0.001196, loss: 0.4105
2022-09-22 14:06:24 - train: epoch 0054, iter [00930, 01251], lr: 0.001196, loss: 0.4259
2022-09-22 14:06:44 - train: epoch 0054, iter [00940, 01251], lr: 0.001196, loss: 0.4000
2022-09-22 14:07:05 - train: epoch 0054, iter [00950, 01251], lr: 0.001196, loss: 0.4100
2022-09-22 14:07:25 - train: epoch 0054, iter [00960, 01251], lr: 0.001196, loss: 0.4290
2022-09-22 14:07:46 - train: epoch 0054, iter [00970, 01251], lr: 0.001196, loss: 0.4244
2022-09-22 14:08:06 - train: epoch 0054, iter [00980, 01251], lr: 0.001196, loss: 0.4164
2022-09-22 14:08:27 - train: epoch 0054, iter [00990, 01251], lr: 0.001196, loss: 0.3951
2022-09-22 14:08:47 - train: epoch 0054, iter [01000, 01251], lr: 0.001196, loss: 0.4302
2022-09-22 14:09:08 - train: epoch 0054, iter [01010, 01251], lr: 0.001196, loss: 0.4063
2022-09-22 14:09:28 - train: epoch 0054, iter [01020, 01251], lr: 0.001196, loss: 0.4187
2022-09-22 14:09:49 - train: epoch 0054, iter [01030, 01251], lr: 0.001196, loss: 0.4289
2022-09-22 14:10:09 - train: epoch 0054, iter [01040, 01251], lr: 0.001196, loss: 0.4316
2022-09-22 14:10:30 - train: epoch 0054, iter [01050, 01251], lr: 0.001196, loss: 0.4067
2022-09-22 14:10:50 - train: epoch 0054, iter [01060, 01251], lr: 0.001196, loss: 0.4099
2022-09-22 14:11:11 - train: epoch 0054, iter [01070, 01251], lr: 0.001196, loss: 0.4219
2022-09-22 14:11:31 - train: epoch 0054, iter [01080, 01251], lr: 0.001196, loss: 0.4078
2022-09-22 14:11:52 - train: epoch 0054, iter [01090, 01251], lr: 0.001196, loss: 0.4207
2022-09-22 14:12:12 - train: epoch 0054, iter [01100, 01251], lr: 0.001196, loss: 0.4125
2022-09-22 14:12:33 - train: epoch 0054, iter [01110, 01251], lr: 0.001196, loss: 0.4169
2022-09-22 14:12:53 - train: epoch 0054, iter [01120, 01251], lr: 0.001196, loss: 0.4053
2022-09-22 14:13:13 - train: epoch 0054, iter [01130, 01251], lr: 0.001196, loss: 0.4247
2022-09-22 14:13:34 - train: epoch 0054, iter [01140, 01251], lr: 0.001196, loss: 0.4154
2022-09-22 14:13:54 - train: epoch 0054, iter [01150, 01251], lr: 0.001196, loss: 0.4170
2022-09-22 14:14:15 - train: epoch 0054, iter [01160, 01251], lr: 0.001196, loss: 0.3987
2022-09-22 14:14:35 - train: epoch 0054, iter [01170, 01251], lr: 0.001196, loss: 0.4230
2022-09-22 14:14:56 - train: epoch 0054, iter [01180, 01251], lr: 0.001196, loss: 0.4141
2022-09-22 14:15:16 - train: epoch 0054, iter [01190, 01251], lr: 0.001196, loss: 0.4101
2022-09-22 14:15:36 - train: epoch 0054, iter [01200, 01251], lr: 0.001196, loss: 0.4262
2022-09-22 14:15:57 - train: epoch 0054, iter [01210, 01251], lr: 0.001196, loss: 0.4066
2022-09-22 14:16:18 - train: epoch 0054, iter [01220, 01251], lr: 0.001196, loss: 0.4348
2022-09-22 14:16:38 - train: epoch 0054, iter [01230, 01251], lr: 0.001196, loss: 0.4164
2022-09-22 14:16:58 - train: epoch 0054, iter [01240, 01251], lr: 0.001196, loss: 0.4093
2022-09-22 14:17:18 - train: epoch 0054, iter [01250, 01251], lr: 0.001196, loss: 0.4218
2022-09-22 14:17:23 - train: epoch 054, train_loss: 0.4174
2022-09-22 14:17:28 - until epoch: 054, best_loss: 0.4174
2022-09-22 14:17:28 - epoch 055 lr: 0.001196
2022-09-22 14:18:06 - train: epoch 0055, iter [00010, 01251], lr: 0.001196, loss: 0.4170
2022-09-22 14:18:26 - train: epoch 0055, iter [00020, 01251], lr: 0.001196, loss: 0.4170
2022-09-22 14:18:47 - train: epoch 0055, iter [00030, 01251], lr: 0.001196, loss: 0.4372
2022-09-22 14:19:07 - train: epoch 0055, iter [00040, 01251], lr: 0.001196, loss: 0.4107
2022-09-22 14:19:28 - train: epoch 0055, iter [00050, 01251], lr: 0.001196, loss: 0.4292
2022-09-22 14:19:49 - train: epoch 0055, iter [00060, 01251], lr: 0.001195, loss: 0.4156
2022-09-22 14:20:10 - train: epoch 0055, iter [00070, 01251], lr: 0.001195, loss: 0.4111
2022-09-22 14:20:31 - train: epoch 0055, iter [00080, 01251], lr: 0.001195, loss: 0.4062
2022-09-22 14:20:51 - train: epoch 0055, iter [00090, 01251], lr: 0.001195, loss: 0.4215
2022-09-22 14:21:12 - train: epoch 0055, iter [00100, 01251], lr: 0.001195, loss: 0.4191
2022-09-22 14:21:33 - train: epoch 0055, iter [00110, 01251], lr: 0.001195, loss: 0.4206
2022-09-22 14:21:54 - train: epoch 0055, iter [00120, 01251], lr: 0.001195, loss: 0.4168
2022-09-22 14:22:14 - train: epoch 0055, iter [00130, 01251], lr: 0.001195, loss: 0.4075
2022-09-22 14:22:35 - train: epoch 0055, iter [00140, 01251], lr: 0.001195, loss: 0.4071
2022-09-22 14:22:56 - train: epoch 0055, iter [00150, 01251], lr: 0.001195, loss: 0.4243
2022-09-22 14:23:17 - train: epoch 0055, iter [00160, 01251], lr: 0.001195, loss: 0.4162
2022-09-22 14:23:38 - train: epoch 0055, iter [00170, 01251], lr: 0.001195, loss: 0.4152
2022-09-22 14:23:58 - train: epoch 0055, iter [00180, 01251], lr: 0.001195, loss: 0.4216
2022-09-22 14:24:19 - train: epoch 0055, iter [00190, 01251], lr: 0.001195, loss: 0.4228
2022-09-22 14:24:40 - train: epoch 0055, iter [00200, 01251], lr: 0.001195, loss: 0.3980
2022-09-22 14:25:01 - train: epoch 0055, iter [00210, 01251], lr: 0.001195, loss: 0.4053
2022-09-22 14:25:22 - train: epoch 0055, iter [00220, 01251], lr: 0.001195, loss: 0.4225
2022-09-22 14:25:42 - train: epoch 0055, iter [00230, 01251], lr: 0.001195, loss: 0.4031
2022-09-22 14:26:03 - train: epoch 0055, iter [00240, 01251], lr: 0.001195, loss: 0.4185
2022-09-22 14:26:24 - train: epoch 0055, iter [00250, 01251], lr: 0.001195, loss: 0.4236
2022-09-22 14:26:45 - train: epoch 0055, iter [00260, 01251], lr: 0.001195, loss: 0.4168
2022-09-22 14:27:05 - train: epoch 0055, iter [00270, 01251], lr: 0.001195, loss: 0.4301
2022-09-22 14:27:26 - train: epoch 0055, iter [00280, 01251], lr: 0.001195, loss: 0.4408
2022-09-22 14:27:47 - train: epoch 0055, iter [00290, 01251], lr: 0.001195, loss: 0.4469
2022-09-22 14:28:08 - train: epoch 0055, iter [00300, 01251], lr: 0.001195, loss: 0.4328
2022-09-22 14:28:29 - train: epoch 0055, iter [00310, 01251], lr: 0.001195, loss: 0.4152
2022-09-22 14:28:50 - train: epoch 0055, iter [00320, 01251], lr: 0.001195, loss: 0.4273
2022-09-22 14:29:10 - train: epoch 0055, iter [00330, 01251], lr: 0.001195, loss: 0.4128
2022-09-22 14:29:31 - train: epoch 0055, iter [00340, 01251], lr: 0.001195, loss: 0.4109
2022-09-22 14:29:52 - train: epoch 0055, iter [00350, 01251], lr: 0.001195, loss: 0.4195
2022-09-22 14:30:13 - train: epoch 0055, iter [00360, 01251], lr: 0.001195, loss: 0.4362
2022-09-22 14:30:34 - train: epoch 0055, iter [00370, 01251], lr: 0.001195, loss: 0.4263
2022-09-22 14:30:54 - train: epoch 0055, iter [00380, 01251], lr: 0.001195, loss: 0.4170
2022-09-22 14:31:15 - train: epoch 0055, iter [00390, 01251], lr: 0.001195, loss: 0.3950
2022-09-22 14:31:36 - train: epoch 0055, iter [00400, 01251], lr: 0.001195, loss: 0.4126
2022-09-22 14:31:57 - train: epoch 0055, iter [00410, 01251], lr: 0.001195, loss: 0.4078
2022-09-22 14:32:18 - train: epoch 0055, iter [00420, 01251], lr: 0.001195, loss: 0.4152
2022-09-22 14:32:39 - train: epoch 0055, iter [00430, 01251], lr: 0.001195, loss: 0.4272
2022-09-22 14:32:59 - train: epoch 0055, iter [00440, 01251], lr: 0.001195, loss: 0.4044
2022-09-22 14:33:20 - train: epoch 0055, iter [00450, 01251], lr: 0.001195, loss: 0.4139
2022-09-22 14:33:41 - train: epoch 0055, iter [00460, 01251], lr: 0.001195, loss: 0.4175
2022-09-22 14:34:02 - train: epoch 0055, iter [00470, 01251], lr: 0.001195, loss: 0.3963
2022-09-22 14:34:23 - train: epoch 0055, iter [00480, 01251], lr: 0.001195, loss: 0.4087
2022-09-22 14:34:44 - train: epoch 0055, iter [00490, 01251], lr: 0.001195, loss: 0.4100
2022-09-22 14:35:04 - train: epoch 0055, iter [00500, 01251], lr: 0.001195, loss: 0.4034
2022-09-22 14:35:25 - train: epoch 0055, iter [00510, 01251], lr: 0.001195, loss: 0.4293
2022-09-22 14:35:46 - train: epoch 0055, iter [00520, 01251], lr: 0.001195, loss: 0.4152
2022-09-22 14:36:07 - train: epoch 0055, iter [00530, 01251], lr: 0.001195, loss: 0.4038
2022-09-22 14:36:28 - train: epoch 0055, iter [00540, 01251], lr: 0.001195, loss: 0.4079
2022-09-22 14:36:48 - train: epoch 0055, iter [00550, 01251], lr: 0.001195, loss: 0.4029
2022-09-22 14:37:09 - train: epoch 0055, iter [00560, 01251], lr: 0.001195, loss: 0.4229
2022-09-22 14:37:30 - train: epoch 0055, iter [00570, 01251], lr: 0.001195, loss: 0.4310
2022-09-22 14:37:51 - train: epoch 0055, iter [00580, 01251], lr: 0.001195, loss: 0.4431
2022-09-22 14:38:12 - train: epoch 0055, iter [00590, 01251], lr: 0.001195, loss: 0.4276
2022-09-22 14:38:32 - train: epoch 0055, iter [00600, 01251], lr: 0.001195, loss: 0.4040
2022-09-22 14:38:53 - train: epoch 0055, iter [00610, 01251], lr: 0.001195, loss: 0.4110
2022-09-22 14:39:14 - train: epoch 0055, iter [00620, 01251], lr: 0.001195, loss: 0.4377
2022-09-22 14:39:35 - train: epoch 0055, iter [00630, 01251], lr: 0.001195, loss: 0.4272
2022-09-22 14:39:55 - train: epoch 0055, iter [00640, 01251], lr: 0.001195, loss: 0.4144
2022-09-22 14:40:16 - train: epoch 0055, iter [00650, 01251], lr: 0.001195, loss: 0.4169
2022-09-22 14:40:37 - train: epoch 0055, iter [00660, 01251], lr: 0.001195, loss: 0.4235
2022-09-22 14:40:58 - train: epoch 0055, iter [00670, 01251], lr: 0.001195, loss: 0.4271
2022-09-22 14:41:19 - train: epoch 0055, iter [00680, 01251], lr: 0.001195, loss: 0.4150
2022-09-22 14:41:39 - train: epoch 0055, iter [00690, 01251], lr: 0.001195, loss: 0.4108
2022-09-22 14:42:00 - train: epoch 0055, iter [00700, 01251], lr: 0.001195, loss: 0.4179
2022-09-22 14:42:21 - train: epoch 0055, iter [00710, 01251], lr: 0.001195, loss: 0.4130
2022-09-22 14:42:41 - train: epoch 0055, iter [00720, 01251], lr: 0.001195, loss: 0.4121
2022-09-22 14:43:02 - train: epoch 0055, iter [00730, 01251], lr: 0.001195, loss: 0.4200
2022-09-22 14:43:23 - train: epoch 0055, iter [00740, 01251], lr: 0.001195, loss: 0.4302
2022-09-22 14:43:43 - train: epoch 0055, iter [00750, 01251], lr: 0.001195, loss: 0.4147
2022-09-22 14:44:04 - train: epoch 0055, iter [00760, 01251], lr: 0.001195, loss: 0.4017
2022-09-22 14:44:25 - train: epoch 0055, iter [00770, 01251], lr: 0.001195, loss: 0.4217
2022-09-22 14:44:46 - train: epoch 0055, iter [00780, 01251], lr: 0.001195, loss: 0.4184
2022-09-22 14:45:06 - train: epoch 0055, iter [00790, 01251], lr: 0.001195, loss: 0.4130
2022-09-22 14:45:27 - train: epoch 0055, iter [00800, 01251], lr: 0.001195, loss: 0.4094
2022-09-22 14:45:48 - train: epoch 0055, iter [00810, 01251], lr: 0.001195, loss: 0.4162
2022-09-22 14:46:09 - train: epoch 0055, iter [00820, 01251], lr: 0.001195, loss: 0.4140
2022-09-22 14:46:30 - train: epoch 0055, iter [00830, 01251], lr: 0.001195, loss: 0.4223
2022-09-22 14:46:51 - train: epoch 0055, iter [00840, 01251], lr: 0.001195, loss: 0.4228
2022-09-22 14:47:11 - train: epoch 0055, iter [00850, 01251], lr: 0.001195, loss: 0.4102
2022-09-22 14:47:32 - train: epoch 0055, iter [00860, 01251], lr: 0.001195, loss: 0.4193
2022-09-22 14:47:52 - train: epoch 0055, iter [00870, 01251], lr: 0.001195, loss: 0.4220
2022-09-22 14:48:13 - train: epoch 0055, iter [00880, 01251], lr: 0.001195, loss: 0.4143
2022-09-22 14:48:34 - train: epoch 0055, iter [00890, 01251], lr: 0.001195, loss: 0.4044
2022-09-22 14:48:54 - train: epoch 0055, iter [00900, 01251], lr: 0.001195, loss: 0.4041
2022-09-22 14:49:15 - train: epoch 0055, iter [00910, 01251], lr: 0.001195, loss: 0.4008
2022-09-22 14:49:35 - train: epoch 0055, iter [00920, 01251], lr: 0.001195, loss: 0.4158
2022-09-22 14:49:56 - train: epoch 0055, iter [00930, 01251], lr: 0.001195, loss: 0.4282
2022-09-22 14:50:17 - train: epoch 0055, iter [00940, 01251], lr: 0.001195, loss: 0.4189
2022-09-22 14:50:37 - train: epoch 0055, iter [00950, 01251], lr: 0.001195, loss: 0.4276
2022-09-22 14:50:58 - train: epoch 0055, iter [00960, 01251], lr: 0.001195, loss: 0.4029
2022-09-22 14:51:19 - train: epoch 0055, iter [00970, 01251], lr: 0.001195, loss: 0.4251
2022-09-22 14:51:39 - train: epoch 0055, iter [00980, 01251], lr: 0.001195, loss: 0.4267
2022-09-22 14:52:00 - train: epoch 0055, iter [00990, 01251], lr: 0.001195, loss: 0.4198
2022-09-22 14:52:20 - train: epoch 0055, iter [01000, 01251], lr: 0.001195, loss: 0.4152
2022-09-22 14:52:41 - train: epoch 0055, iter [01010, 01251], lr: 0.001195, loss: 0.4177
2022-09-22 14:53:02 - train: epoch 0055, iter [01020, 01251], lr: 0.001195, loss: 0.4008
2022-09-22 14:53:22 - train: epoch 0055, iter [01030, 01251], lr: 0.001195, loss: 0.4282
2022-09-22 14:53:43 - train: epoch 0055, iter [01040, 01251], lr: 0.001195, loss: 0.4361
2022-09-22 14:54:04 - train: epoch 0055, iter [01050, 01251], lr: 0.001195, loss: 0.4030
2022-09-22 14:54:25 - train: epoch 0055, iter [01060, 01251], lr: 0.001195, loss: 0.4183
2022-09-22 14:54:45 - train: epoch 0055, iter [01070, 01251], lr: 0.001195, loss: 0.4425
2022-09-22 14:55:06 - train: epoch 0055, iter [01080, 01251], lr: 0.001195, loss: 0.4104
2022-09-22 14:55:27 - train: epoch 0055, iter [01090, 01251], lr: 0.001195, loss: 0.3998
2022-09-22 14:55:47 - train: epoch 0055, iter [01100, 01251], lr: 0.001195, loss: 0.4259
2022-09-22 14:56:08 - train: epoch 0055, iter [01110, 01251], lr: 0.001195, loss: 0.4149
2022-09-22 14:56:28 - train: epoch 0055, iter [01120, 01251], lr: 0.001195, loss: 0.4227
2022-09-22 14:56:49 - train: epoch 0055, iter [01130, 01251], lr: 0.001195, loss: 0.4268
2022-09-22 14:57:09 - train: epoch 0055, iter [01140, 01251], lr: 0.001195, loss: 0.4236
2022-09-22 14:57:30 - train: epoch 0055, iter [01150, 01251], lr: 0.001195, loss: 0.4400
2022-09-22 14:57:51 - train: epoch 0055, iter [01160, 01251], lr: 0.001195, loss: 0.4101
2022-09-22 14:58:11 - train: epoch 0055, iter [01170, 01251], lr: 0.001195, loss: 0.3985
2022-09-22 14:58:32 - train: epoch 0055, iter [01180, 01251], lr: 0.001195, loss: 0.4273
2022-09-22 14:58:52 - train: epoch 0055, iter [01190, 01251], lr: 0.001195, loss: 0.4128
2022-09-22 14:59:13 - train: epoch 0055, iter [01200, 01251], lr: 0.001195, loss: 0.4063
2022-09-22 14:59:34 - train: epoch 0055, iter [01210, 01251], lr: 0.001195, loss: 0.4292
2022-09-22 14:59:55 - train: epoch 0055, iter [01220, 01251], lr: 0.001195, loss: 0.4183
2022-09-22 15:00:16 - train: epoch 0055, iter [01230, 01251], lr: 0.001195, loss: 0.4256
2022-09-22 15:00:37 - train: epoch 0055, iter [01240, 01251], lr: 0.001195, loss: 0.4195
2022-09-22 15:00:57 - train: epoch 0055, iter [01250, 01251], lr: 0.001195, loss: 0.4302
2022-09-22 15:01:01 - train: epoch 055, train_loss: 0.4174
2022-09-22 15:01:06 - until epoch: 055, best_loss: 0.4174
2022-09-22 15:01:06 - epoch 056 lr: 0.001195
2022-09-22 15:01:43 - train: epoch 0056, iter [00010, 01251], lr: 0.001195, loss: 0.4149
2022-09-22 15:02:04 - train: epoch 0056, iter [00020, 01251], lr: 0.001195, loss: 0.4171
2022-09-22 15:02:24 - train: epoch 0056, iter [00030, 01251], lr: 0.001195, loss: 0.4119
2022-09-22 15:02:45 - train: epoch 0056, iter [00040, 01251], lr: 0.001195, loss: 0.4317
2022-09-22 15:03:06 - train: epoch 0056, iter [00050, 01251], lr: 0.001195, loss: 0.4098
2022-09-22 15:03:27 - train: epoch 0056, iter [00060, 01251], lr: 0.001195, loss: 0.4152
2022-09-22 15:03:47 - train: epoch 0056, iter [00070, 01251], lr: 0.001195, loss: 0.4357
2022-09-22 15:04:08 - train: epoch 0056, iter [00080, 01251], lr: 0.001195, loss: 0.4015
2022-09-22 15:04:29 - train: epoch 0056, iter [00090, 01251], lr: 0.001195, loss: 0.4149
2022-09-22 15:04:50 - train: epoch 0056, iter [00100, 01251], lr: 0.001195, loss: 0.4025
2022-09-22 15:05:10 - train: epoch 0056, iter [00110, 01251], lr: 0.001195, loss: 0.4082
2022-09-22 15:05:31 - train: epoch 0056, iter [00120, 01251], lr: 0.001195, loss: 0.3948
2022-09-22 15:05:52 - train: epoch 0056, iter [00130, 01251], lr: 0.001195, loss: 0.4002
2022-09-22 15:06:12 - train: epoch 0056, iter [00140, 01251], lr: 0.001195, loss: 0.4120
2022-09-22 15:06:33 - train: epoch 0056, iter [00150, 01251], lr: 0.001195, loss: 0.4364
2022-09-22 15:06:54 - train: epoch 0056, iter [00160, 01251], lr: 0.001195, loss: 0.4267
2022-09-22 15:07:15 - train: epoch 0056, iter [00170, 01251], lr: 0.001195, loss: 0.4277
2022-09-22 15:07:35 - train: epoch 0056, iter [00180, 01251], lr: 0.001195, loss: 0.4340
2022-09-22 15:07:56 - train: epoch 0056, iter [00190, 01251], lr: 0.001195, loss: 0.4011
2022-09-22 15:08:17 - train: epoch 0056, iter [00200, 01251], lr: 0.001195, loss: 0.4149
2022-09-22 15:08:38 - train: epoch 0056, iter [00210, 01251], lr: 0.001195, loss: 0.4291
2022-09-22 15:08:59 - train: epoch 0056, iter [00220, 01251], lr: 0.001195, loss: 0.4113
2022-09-22 15:09:19 - train: epoch 0056, iter [00230, 01251], lr: 0.001195, loss: 0.3968
2022-09-22 15:09:40 - train: epoch 0056, iter [00240, 01251], lr: 0.001195, loss: 0.4044
2022-09-22 15:10:01 - train: epoch 0056, iter [00250, 01251], lr: 0.001195, loss: 0.4092
2022-09-22 15:10:21 - train: epoch 0056, iter [00260, 01251], lr: 0.001195, loss: 0.4177
2022-09-22 15:10:42 - train: epoch 0056, iter [00270, 01251], lr: 0.001195, loss: 0.4052
2022-09-22 15:11:02 - train: epoch 0056, iter [00280, 01251], lr: 0.001195, loss: 0.4055
2022-09-22 15:11:23 - train: epoch 0056, iter [00290, 01251], lr: 0.001195, loss: 0.4173
2022-09-22 15:11:43 - train: epoch 0056, iter [00300, 01251], lr: 0.001195, loss: 0.4117
2022-09-22 15:12:04 - train: epoch 0056, iter [00310, 01251], lr: 0.001195, loss: 0.4345
2022-09-22 15:12:25 - train: epoch 0056, iter [00320, 01251], lr: 0.001195, loss: 0.4314
2022-09-22 15:12:46 - train: epoch 0056, iter [00330, 01251], lr: 0.001195, loss: 0.4181
2022-09-22 15:13:07 - train: epoch 0056, iter [00340, 01251], lr: 0.001195, loss: 0.4101
2022-09-22 15:13:28 - train: epoch 0056, iter [00350, 01251], lr: 0.001195, loss: 0.4161
2022-09-22 15:13:49 - train: epoch 0056, iter [00360, 01251], lr: 0.001195, loss: 0.4378
2022-09-22 15:14:09 - train: epoch 0056, iter [00370, 01251], lr: 0.001195, loss: 0.4232
2022-09-22 15:14:30 - train: epoch 0056, iter [00380, 01251], lr: 0.001195, loss: 0.4290
2022-09-22 15:14:51 - train: epoch 0056, iter [00390, 01251], lr: 0.001195, loss: 0.4146
2022-09-22 15:15:12 - train: epoch 0056, iter [00400, 01251], lr: 0.001195, loss: 0.4174
2022-09-22 15:15:33 - train: epoch 0056, iter [00410, 01251], lr: 0.001195, loss: 0.4230
2022-09-22 15:15:53 - train: epoch 0056, iter [00420, 01251], lr: 0.001195, loss: 0.4198
2022-09-22 15:16:14 - train: epoch 0056, iter [00430, 01251], lr: 0.001195, loss: 0.4196
2022-09-22 15:16:35 - train: epoch 0056, iter [00440, 01251], lr: 0.001195, loss: 0.4208
2022-09-22 15:16:56 - train: epoch 0056, iter [00450, 01251], lr: 0.001195, loss: 0.4240
2022-09-22 15:17:17 - train: epoch 0056, iter [00460, 01251], lr: 0.001195, loss: 0.4034
2022-09-22 15:17:38 - train: epoch 0056, iter [00470, 01251], lr: 0.001195, loss: 0.4295
2022-09-22 15:17:58 - train: epoch 0056, iter [00480, 01251], lr: 0.001195, loss: 0.4292
2022-09-22 15:18:18 - train: epoch 0056, iter [00490, 01251], lr: 0.001195, loss: 0.4029
2022-09-22 15:18:39 - train: epoch 0056, iter [00500, 01251], lr: 0.001195, loss: 0.4100
2022-09-22 15:18:59 - train: epoch 0056, iter [00510, 01251], lr: 0.001195, loss: 0.4085
2022-09-22 15:19:20 - train: epoch 0056, iter [00520, 01251], lr: 0.001195, loss: 0.4209
2022-09-22 15:19:40 - train: epoch 0056, iter [00530, 01251], lr: 0.001195, loss: 0.4243
2022-09-22 15:20:00 - train: epoch 0056, iter [00540, 01251], lr: 0.001195, loss: 0.4381
2022-09-22 15:20:20 - train: epoch 0056, iter [00550, 01251], lr: 0.001195, loss: 0.4216
2022-09-22 15:20:41 - train: epoch 0056, iter [00560, 01251], lr: 0.001195, loss: 0.4018
2022-09-22 15:21:01 - train: epoch 0056, iter [00570, 01251], lr: 0.001195, loss: 0.4321
2022-09-22 15:21:21 - train: epoch 0056, iter [00580, 01251], lr: 0.001195, loss: 0.4212
2022-09-22 15:21:41 - train: epoch 0056, iter [00590, 01251], lr: 0.001195, loss: 0.4139
2022-09-22 15:22:02 - train: epoch 0056, iter [00600, 01251], lr: 0.001195, loss: 0.4194
2022-09-22 15:22:22 - train: epoch 0056, iter [00610, 01251], lr: 0.001195, loss: 0.4329
2022-09-22 15:22:42 - train: epoch 0056, iter [00620, 01251], lr: 0.001195, loss: 0.4138
2022-09-22 15:23:03 - train: epoch 0056, iter [00630, 01251], lr: 0.001195, loss: 0.4233
2022-09-22 15:23:23 - train: epoch 0056, iter [00640, 01251], lr: 0.001195, loss: 0.4299
2022-09-22 15:23:43 - train: epoch 0056, iter [00650, 01251], lr: 0.001195, loss: 0.4029
2022-09-22 15:24:04 - train: epoch 0056, iter [00660, 01251], lr: 0.001195, loss: 0.3927
2022-09-22 15:24:24 - train: epoch 0056, iter [00670, 01251], lr: 0.001194, loss: 0.4397
2022-09-22 15:24:44 - train: epoch 0056, iter [00680, 01251], lr: 0.001194, loss: 0.4147
2022-09-22 15:25:04 - train: epoch 0056, iter [00690, 01251], lr: 0.001194, loss: 0.4295
2022-09-22 15:25:25 - train: epoch 0056, iter [00700, 01251], lr: 0.001194, loss: 0.4152
2022-09-22 15:25:45 - train: epoch 0056, iter [00710, 01251], lr: 0.001194, loss: 0.4044
2022-09-22 15:26:06 - train: epoch 0056, iter [00720, 01251], lr: 0.001194, loss: 0.3967
2022-09-22 15:26:26 - train: epoch 0056, iter [00730, 01251], lr: 0.001194, loss: 0.4213
2022-09-22 15:26:46 - train: epoch 0056, iter [00740, 01251], lr: 0.001194, loss: 0.4183
2022-09-22 15:27:07 - train: epoch 0056, iter [00750, 01251], lr: 0.001194, loss: 0.4119
2022-09-22 15:27:27 - train: epoch 0056, iter [00760, 01251], lr: 0.001194, loss: 0.4138
2022-09-22 15:27:47 - train: epoch 0056, iter [00770, 01251], lr: 0.001194, loss: 0.4067
2022-09-22 15:28:07 - train: epoch 0056, iter [00780, 01251], lr: 0.001194, loss: 0.4091
2022-09-22 15:28:28 - train: epoch 0056, iter [00790, 01251], lr: 0.001194, loss: 0.4211
2022-09-22 15:28:48 - train: epoch 0056, iter [00800, 01251], lr: 0.001194, loss: 0.4077
2022-09-22 15:29:09 - train: epoch 0056, iter [00810, 01251], lr: 0.001194, loss: 0.4141
2022-09-22 15:29:29 - train: epoch 0056, iter [00820, 01251], lr: 0.001194, loss: 0.4245
2022-09-22 15:29:49 - train: epoch 0056, iter [00830, 01251], lr: 0.001194, loss: 0.4193
2022-09-22 15:30:09 - train: epoch 0056, iter [00840, 01251], lr: 0.001194, loss: 0.4013
2022-09-22 15:30:30 - train: epoch 0056, iter [00850, 01251], lr: 0.001194, loss: 0.3797
2022-09-22 15:30:50 - train: epoch 0056, iter [00860, 01251], lr: 0.001194, loss: 0.4191
2022-09-22 15:31:10 - train: epoch 0056, iter [00870, 01251], lr: 0.001194, loss: 0.4247
2022-09-22 15:31:30 - train: epoch 0056, iter [00880, 01251], lr: 0.001194, loss: 0.4156
2022-09-22 15:31:51 - train: epoch 0056, iter [00890, 01251], lr: 0.001194, loss: 0.3973
2022-09-22 15:32:11 - train: epoch 0056, iter [00900, 01251], lr: 0.001194, loss: 0.4156
2022-09-22 15:32:31 - train: epoch 0056, iter [00910, 01251], lr: 0.001194, loss: 0.4149
2022-09-22 15:32:52 - train: epoch 0056, iter [00920, 01251], lr: 0.001194, loss: 0.4312
2022-09-22 15:33:12 - train: epoch 0056, iter [00930, 01251], lr: 0.001194, loss: 0.4332
2022-09-22 15:33:32 - train: epoch 0056, iter [00940, 01251], lr: 0.001194, loss: 0.4293
2022-09-22 15:33:52 - train: epoch 0056, iter [00950, 01251], lr: 0.001194, loss: 0.4086
2022-09-22 15:34:13 - train: epoch 0056, iter [00960, 01251], lr: 0.001194, loss: 0.4042
2022-09-22 15:34:33 - train: epoch 0056, iter [00970, 01251], lr: 0.001194, loss: 0.4300
2022-09-22 15:34:53 - train: epoch 0056, iter [00980, 01251], lr: 0.001194, loss: 0.4147
2022-09-22 15:35:14 - train: epoch 0056, iter [00990, 01251], lr: 0.001194, loss: 0.4295
2022-09-22 15:35:34 - train: epoch 0056, iter [01000, 01251], lr: 0.001194, loss: 0.4208
2022-09-22 15:35:54 - train: epoch 0056, iter [01010, 01251], lr: 0.001194, loss: 0.4392
2022-09-22 15:36:15 - train: epoch 0056, iter [01020, 01251], lr: 0.001194, loss: 0.4066
2022-09-22 15:36:35 - train: epoch 0056, iter [01030, 01251], lr: 0.001194, loss: 0.4154
2022-09-22 15:36:55 - train: epoch 0056, iter [01040, 01251], lr: 0.001194, loss: 0.4267
2022-09-22 15:37:16 - train: epoch 0056, iter [01050, 01251], lr: 0.001194, loss: 0.3936
2022-09-22 15:37:36 - train: epoch 0056, iter [01060, 01251], lr: 0.001194, loss: 0.4119
2022-09-22 15:37:57 - train: epoch 0056, iter [01070, 01251], lr: 0.001194, loss: 0.4279
2022-09-22 15:38:17 - train: epoch 0056, iter [01080, 01251], lr: 0.001194, loss: 0.4164
2022-09-22 15:38:38 - train: epoch 0056, iter [01090, 01251], lr: 0.001194, loss: 0.4030
2022-09-22 15:38:58 - train: epoch 0056, iter [01100, 01251], lr: 0.001194, loss: 0.4407
2022-09-22 15:39:19 - train: epoch 0056, iter [01110, 01251], lr: 0.001194, loss: 0.4167
2022-09-22 15:39:40 - train: epoch 0056, iter [01120, 01251], lr: 0.001194, loss: 0.4292
2022-09-22 15:40:00 - train: epoch 0056, iter [01130, 01251], lr: 0.001194, loss: 0.4130
2022-09-22 15:40:21 - train: epoch 0056, iter [01140, 01251], lr: 0.001194, loss: 0.3848
2022-09-22 15:40:41 - train: epoch 0056, iter [01150, 01251], lr: 0.001194, loss: 0.4167
2022-09-22 15:41:02 - train: epoch 0056, iter [01160, 01251], lr: 0.001194, loss: 0.4012
2022-09-22 15:41:22 - train: epoch 0056, iter [01170, 01251], lr: 0.001194, loss: 0.4097
2022-09-22 15:41:43 - train: epoch 0056, iter [01180, 01251], lr: 0.001194, loss: 0.4133
2022-09-22 15:42:04 - train: epoch 0056, iter [01190, 01251], lr: 0.001194, loss: 0.4209
2022-09-22 15:42:24 - train: epoch 0056, iter [01200, 01251], lr: 0.001194, loss: 0.3887
2022-09-22 15:42:45 - train: epoch 0056, iter [01210, 01251], lr: 0.001194, loss: 0.4255
2022-09-22 15:43:05 - train: epoch 0056, iter [01220, 01251], lr: 0.001194, loss: 0.4299
2022-09-22 15:43:26 - train: epoch 0056, iter [01230, 01251], lr: 0.001194, loss: 0.4125
2022-09-22 15:43:46 - train: epoch 0056, iter [01240, 01251], lr: 0.001194, loss: 0.4162
2022-09-22 15:44:06 - train: epoch 0056, iter [01250, 01251], lr: 0.001194, loss: 0.4026
2022-09-22 15:44:11 - train: epoch 056, train_loss: 0.4173
2022-09-22 15:44:15 - until epoch: 056, best_loss: 0.4173
2022-09-22 15:44:15 - epoch 057 lr: 0.001194
2022-09-22 15:44:52 - train: epoch 0057, iter [00010, 01251], lr: 0.001194, loss: 0.3965
2022-09-22 15:45:13 - train: epoch 0057, iter [00020, 01251], lr: 0.001194, loss: 0.4169
2022-09-22 15:45:34 - train: epoch 0057, iter [00030, 01251], lr: 0.001194, loss: 0.4299
2022-09-22 15:45:54 - train: epoch 0057, iter [00040, 01251], lr: 0.001194, loss: 0.4327
2022-09-22 15:46:15 - train: epoch 0057, iter [00050, 01251], lr: 0.001194, loss: 0.4256
2022-09-22 15:46:36 - train: epoch 0057, iter [00060, 01251], lr: 0.001194, loss: 0.4118
2022-09-22 15:46:56 - train: epoch 0057, iter [00070, 01251], lr: 0.001194, loss: 0.4056
2022-09-22 15:47:17 - train: epoch 0057, iter [00080, 01251], lr: 0.001194, loss: 0.4454
2022-09-22 15:47:37 - train: epoch 0057, iter [00090, 01251], lr: 0.001194, loss: 0.4074
2022-09-22 15:47:58 - train: epoch 0057, iter [00100, 01251], lr: 0.001194, loss: 0.4406
2022-09-22 15:48:18 - train: epoch 0057, iter [00110, 01251], lr: 0.001194, loss: 0.4113
2022-09-22 15:48:39 - train: epoch 0057, iter [00120, 01251], lr: 0.001194, loss: 0.4090
2022-09-22 15:48:59 - train: epoch 0057, iter [00130, 01251], lr: 0.001194, loss: 0.4208
2022-09-22 15:49:20 - train: epoch 0057, iter [00140, 01251], lr: 0.001194, loss: 0.4486
2022-09-22 15:49:40 - train: epoch 0057, iter [00150, 01251], lr: 0.001194, loss: 0.4152
2022-09-22 15:50:01 - train: epoch 0057, iter [00160, 01251], lr: 0.001194, loss: 0.4322
2022-09-22 15:50:21 - train: epoch 0057, iter [00170, 01251], lr: 0.001194, loss: 0.4272
2022-09-22 15:50:42 - train: epoch 0057, iter [00180, 01251], lr: 0.001194, loss: 0.4322
2022-09-22 15:51:02 - train: epoch 0057, iter [00190, 01251], lr: 0.001194, loss: 0.4094
2022-09-22 15:51:23 - train: epoch 0057, iter [00200, 01251], lr: 0.001194, loss: 0.4087
2022-09-22 15:51:43 - train: epoch 0057, iter [00210, 01251], lr: 0.001194, loss: 0.4313
2022-09-22 15:52:04 - train: epoch 0057, iter [00220, 01251], lr: 0.001194, loss: 0.4162
2022-09-22 15:52:24 - train: epoch 0057, iter [00230, 01251], lr: 0.001194, loss: 0.4112
2022-09-22 15:52:45 - train: epoch 0057, iter [00240, 01251], lr: 0.001194, loss: 0.4228
2022-09-22 15:53:05 - train: epoch 0057, iter [00250, 01251], lr: 0.001194, loss: 0.4080
2022-09-22 15:53:26 - train: epoch 0057, iter [00260, 01251], lr: 0.001194, loss: 0.4102
2022-09-22 15:53:46 - train: epoch 0057, iter [00270, 01251], lr: 0.001194, loss: 0.4186
2022-09-22 15:54:07 - train: epoch 0057, iter [00280, 01251], lr: 0.001194, loss: 0.4204
2022-09-22 15:54:27 - train: epoch 0057, iter [00290, 01251], lr: 0.001194, loss: 0.4208
2022-09-22 15:54:48 - train: epoch 0057, iter [00300, 01251], lr: 0.001194, loss: 0.4185
2022-09-22 15:55:08 - train: epoch 0057, iter [00310, 01251], lr: 0.001194, loss: 0.4153
2022-09-22 15:55:29 - train: epoch 0057, iter [00320, 01251], lr: 0.001194, loss: 0.4183
2022-09-22 15:55:49 - train: epoch 0057, iter [00330, 01251], lr: 0.001194, loss: 0.4205
2022-09-22 15:56:09 - train: epoch 0057, iter [00340, 01251], lr: 0.001194, loss: 0.4229
2022-09-22 15:56:30 - train: epoch 0057, iter [00350, 01251], lr: 0.001194, loss: 0.4140
2022-09-22 15:56:50 - train: epoch 0057, iter [00360, 01251], lr: 0.001194, loss: 0.4194
2022-09-22 15:57:11 - train: epoch 0057, iter [00370, 01251], lr: 0.001194, loss: 0.4273
2022-09-22 15:57:31 - train: epoch 0057, iter [00380, 01251], lr: 0.001194, loss: 0.4070
2022-09-22 15:57:52 - train: epoch 0057, iter [00390, 01251], lr: 0.001194, loss: 0.4147
2022-09-22 15:58:12 - train: epoch 0057, iter [00400, 01251], lr: 0.001194, loss: 0.4037
2022-09-22 15:58:33 - train: epoch 0057, iter [00410, 01251], lr: 0.001194, loss: 0.4170
2022-09-22 15:58:53 - train: epoch 0057, iter [00420, 01251], lr: 0.001194, loss: 0.4064
2022-09-22 15:59:14 - train: epoch 0057, iter [00430, 01251], lr: 0.001194, loss: 0.4257
2022-09-22 15:59:34 - train: epoch 0057, iter [00440, 01251], lr: 0.001194, loss: 0.4040
2022-09-22 15:59:55 - train: epoch 0057, iter [00450, 01251], lr: 0.001194, loss: 0.3907
2022-09-22 16:00:15 - train: epoch 0057, iter [00460, 01251], lr: 0.001194, loss: 0.4098
2022-09-22 16:00:36 - train: epoch 0057, iter [00470, 01251], lr: 0.001194, loss: 0.4108
2022-09-22 16:00:56 - train: epoch 0057, iter [00480, 01251], lr: 0.001194, loss: 0.4236
2022-09-22 16:01:17 - train: epoch 0057, iter [00490, 01251], lr: 0.001194, loss: 0.4104
2022-09-22 16:01:37 - train: epoch 0057, iter [00500, 01251], lr: 0.001194, loss: 0.4268
2022-09-22 16:01:58 - train: epoch 0057, iter [00510, 01251], lr: 0.001194, loss: 0.4042
2022-09-22 16:02:18 - train: epoch 0057, iter [00520, 01251], lr: 0.001194, loss: 0.4207
2022-09-22 16:02:39 - train: epoch 0057, iter [00530, 01251], lr: 0.001194, loss: 0.4314
2022-09-22 16:02:59 - train: epoch 0057, iter [00540, 01251], lr: 0.001194, loss: 0.4186
2022-09-22 16:03:20 - train: epoch 0057, iter [00550, 01251], lr: 0.001194, loss: 0.4241
2022-09-22 16:03:40 - train: epoch 0057, iter [00560, 01251], lr: 0.001194, loss: 0.4250
2022-09-22 16:04:01 - train: epoch 0057, iter [00570, 01251], lr: 0.001194, loss: 0.4315
2022-09-22 16:04:21 - train: epoch 0057, iter [00580, 01251], lr: 0.001194, loss: 0.4225
2022-09-22 16:04:42 - train: epoch 0057, iter [00590, 01251], lr: 0.001194, loss: 0.4148
2022-09-22 16:05:03 - train: epoch 0057, iter [00600, 01251], lr: 0.001194, loss: 0.4182
2022-09-22 16:05:23 - train: epoch 0057, iter [00610, 01251], lr: 0.001194, loss: 0.4162
2022-09-22 16:05:43 - train: epoch 0057, iter [00620, 01251], lr: 0.001194, loss: 0.4278
2022-09-22 16:06:04 - train: epoch 0057, iter [00630, 01251], lr: 0.001194, loss: 0.4249
2022-09-22 16:06:24 - train: epoch 0057, iter [00640, 01251], lr: 0.001194, loss: 0.4243
2022-09-22 16:06:45 - train: epoch 0057, iter [00650, 01251], lr: 0.001194, loss: 0.4327
2022-09-22 16:07:05 - train: epoch 0057, iter [00660, 01251], lr: 0.001194, loss: 0.4014
2022-09-22 16:07:26 - train: epoch 0057, iter [00670, 01251], lr: 0.001194, loss: 0.4057
2022-09-22 16:07:46 - train: epoch 0057, iter [00680, 01251], lr: 0.001194, loss: 0.4065
2022-09-22 16:08:07 - train: epoch 0057, iter [00690, 01251], lr: 0.001194, loss: 0.4175
2022-09-22 16:08:27 - train: epoch 0057, iter [00700, 01251], lr: 0.001194, loss: 0.4188
2022-09-22 16:08:48 - train: epoch 0057, iter [00710, 01251], lr: 0.001194, loss: 0.4189
2022-09-22 16:09:08 - train: epoch 0057, iter [00720, 01251], lr: 0.001194, loss: 0.4110
2022-09-22 16:09:29 - train: epoch 0057, iter [00730, 01251], lr: 0.001194, loss: 0.4140
2022-09-22 16:09:49 - train: epoch 0057, iter [00740, 01251], lr: 0.001194, loss: 0.4003
2022-09-22 16:10:10 - train: epoch 0057, iter [00750, 01251], lr: 0.001194, loss: 0.4005
2022-09-22 16:10:31 - train: epoch 0057, iter [00760, 01251], lr: 0.001194, loss: 0.4300
2022-09-22 16:10:51 - train: epoch 0057, iter [00770, 01251], lr: 0.001194, loss: 0.4379
2022-09-22 16:11:12 - train: epoch 0057, iter [00780, 01251], lr: 0.001194, loss: 0.4273
2022-09-22 16:11:32 - train: epoch 0057, iter [00790, 01251], lr: 0.001194, loss: 0.4058
2022-09-22 16:11:53 - train: epoch 0057, iter [00800, 01251], lr: 0.001194, loss: 0.4127
2022-09-22 16:12:13 - train: epoch 0057, iter [00810, 01251], lr: 0.001194, loss: 0.4094
2022-09-22 16:12:34 - train: epoch 0057, iter [00820, 01251], lr: 0.001194, loss: 0.4070
2022-09-22 16:12:54 - train: epoch 0057, iter [00830, 01251], lr: 0.001194, loss: 0.4072
2022-09-22 16:13:15 - train: epoch 0057, iter [00840, 01251], lr: 0.001194, loss: 0.3922
2022-09-22 16:13:35 - train: epoch 0057, iter [00850, 01251], lr: 0.001194, loss: 0.4285
2022-09-22 16:13:56 - train: epoch 0057, iter [00860, 01251], lr: 0.001194, loss: 0.4119
2022-09-22 16:14:16 - train: epoch 0057, iter [00870, 01251], lr: 0.001194, loss: 0.4164
2022-09-22 16:14:37 - train: epoch 0057, iter [00880, 01251], lr: 0.001194, loss: 0.4225
2022-09-22 16:14:57 - train: epoch 0057, iter [00890, 01251], lr: 0.001194, loss: 0.4419
2022-09-22 16:15:18 - train: epoch 0057, iter [00900, 01251], lr: 0.001194, loss: 0.4202
2022-09-22 16:15:38 - train: epoch 0057, iter [00910, 01251], lr: 0.001194, loss: 0.4235
2022-09-22 16:15:59 - train: epoch 0057, iter [00920, 01251], lr: 0.001194, loss: 0.4178
2022-09-22 16:16:19 - train: epoch 0057, iter [00930, 01251], lr: 0.001194, loss: 0.4463
2022-09-22 16:16:40 - train: epoch 0057, iter [00940, 01251], lr: 0.001194, loss: 0.4126
2022-09-22 16:17:01 - train: epoch 0057, iter [00950, 01251], lr: 0.001194, loss: 0.4195
2022-09-22 16:17:21 - train: epoch 0057, iter [00960, 01251], lr: 0.001194, loss: 0.4250
2022-09-22 16:17:42 - train: epoch 0057, iter [00970, 01251], lr: 0.001194, loss: 0.4386
2022-09-22 16:18:02 - train: epoch 0057, iter [00980, 01251], lr: 0.001194, loss: 0.4119
2022-09-22 16:18:23 - train: epoch 0057, iter [00990, 01251], lr: 0.001194, loss: 0.4108
2022-09-22 16:18:43 - train: epoch 0057, iter [01000, 01251], lr: 0.001194, loss: 0.4077
2022-09-22 16:19:04 - train: epoch 0057, iter [01010, 01251], lr: 0.001194, loss: 0.4219
2022-09-22 16:19:24 - train: epoch 0057, iter [01020, 01251], lr: 0.001194, loss: 0.4149
2022-09-22 16:19:45 - train: epoch 0057, iter [01030, 01251], lr: 0.001194, loss: 0.4217
2022-09-22 16:20:05 - train: epoch 0057, iter [01040, 01251], lr: 0.001194, loss: 0.4238
2022-09-22 16:20:26 - train: epoch 0057, iter [01050, 01251], lr: 0.001194, loss: 0.4007
2022-09-22 16:20:46 - train: epoch 0057, iter [01060, 01251], lr: 0.001194, loss: 0.4340
2022-09-22 16:21:07 - train: epoch 0057, iter [01070, 01251], lr: 0.001194, loss: 0.4103
2022-09-22 16:21:27 - train: epoch 0057, iter [01080, 01251], lr: 0.001194, loss: 0.4219
2022-09-22 16:21:48 - train: epoch 0057, iter [01090, 01251], lr: 0.001194, loss: 0.4214
2022-09-22 16:22:09 - train: epoch 0057, iter [01100, 01251], lr: 0.001194, loss: 0.4078
2022-09-22 16:22:29 - train: epoch 0057, iter [01110, 01251], lr: 0.001193, loss: 0.4300
2022-09-22 16:22:49 - train: epoch 0057, iter [01120, 01251], lr: 0.001193, loss: 0.4205
2022-09-22 16:23:10 - train: epoch 0057, iter [01130, 01251], lr: 0.001193, loss: 0.3987
2022-09-22 16:23:31 - train: epoch 0057, iter [01140, 01251], lr: 0.001193, loss: 0.4007
2022-09-22 16:23:51 - train: epoch 0057, iter [01150, 01251], lr: 0.001193, loss: 0.4118
2022-09-22 16:24:12 - train: epoch 0057, iter [01160, 01251], lr: 0.001193, loss: 0.4040
2022-09-22 16:24:32 - train: epoch 0057, iter [01170, 01251], lr: 0.001193, loss: 0.4050
2022-09-22 16:24:53 - train: epoch 0057, iter [01180, 01251], lr: 0.001193, loss: 0.4212
2022-09-22 16:25:13 - train: epoch 0057, iter [01190, 01251], lr: 0.001193, loss: 0.4216
2022-09-22 16:25:34 - train: epoch 0057, iter [01200, 01251], lr: 0.001193, loss: 0.4247
2022-09-22 16:25:54 - train: epoch 0057, iter [01210, 01251], lr: 0.001193, loss: 0.4300
2022-09-22 16:26:15 - train: epoch 0057, iter [01220, 01251], lr: 0.001193, loss: 0.4324
2022-09-22 16:26:36 - train: epoch 0057, iter [01230, 01251], lr: 0.001193, loss: 0.4088
2022-09-22 16:26:56 - train: epoch 0057, iter [01240, 01251], lr: 0.001193, loss: 0.4184
2022-09-22 16:27:16 - train: epoch 0057, iter [01250, 01251], lr: 0.001193, loss: 0.4109
2022-09-22 16:27:21 - train: epoch 057, train_loss: 0.4171
2022-09-22 16:27:26 - until epoch: 057, best_loss: 0.4171
2022-09-22 16:27:26 - epoch 058 lr: 0.001193
2022-09-22 16:28:03 - train: epoch 0058, iter [00010, 01251], lr: 0.001193, loss: 0.3980
2022-09-22 16:28:24 - train: epoch 0058, iter [00020, 01251], lr: 0.001193, loss: 0.4267
2022-09-22 16:28:44 - train: epoch 0058, iter [00030, 01251], lr: 0.001193, loss: 0.4115
2022-09-22 16:29:05 - train: epoch 0058, iter [00040, 01251], lr: 0.001193, loss: 0.4401
2022-09-22 16:29:26 - train: epoch 0058, iter [00050, 01251], lr: 0.001193, loss: 0.4167
2022-09-22 16:29:47 - train: epoch 0058, iter [00060, 01251], lr: 0.001193, loss: 0.4361
2022-09-22 16:30:07 - train: epoch 0058, iter [00070, 01251], lr: 0.001193, loss: 0.4110
2022-09-22 16:30:28 - train: epoch 0058, iter [00080, 01251], lr: 0.001193, loss: 0.4198
2022-09-22 16:30:49 - train: epoch 0058, iter [00090, 01251], lr: 0.001193, loss: 0.4214
2022-09-22 16:31:10 - train: epoch 0058, iter [00100, 01251], lr: 0.001193, loss: 0.4072
2022-09-22 16:31:31 - train: epoch 0058, iter [00110, 01251], lr: 0.001193, loss: 0.4269
2022-09-22 16:31:51 - train: epoch 0058, iter [00120, 01251], lr: 0.001193, loss: 0.4151
2022-09-22 16:32:12 - train: epoch 0058, iter [00130, 01251], lr: 0.001193, loss: 0.4053
2022-09-22 16:32:33 - train: epoch 0058, iter [00140, 01251], lr: 0.001193, loss: 0.4221
2022-09-22 16:32:53 - train: epoch 0058, iter [00150, 01251], lr: 0.001193, loss: 0.4183
2022-09-22 16:33:14 - train: epoch 0058, iter [00160, 01251], lr: 0.001193, loss: 0.4319
2022-09-22 16:33:35 - train: epoch 0058, iter [00170, 01251], lr: 0.001193, loss: 0.4323
2022-09-22 16:33:56 - train: epoch 0058, iter [00180, 01251], lr: 0.001193, loss: 0.4051
2022-09-22 16:34:16 - train: epoch 0058, iter [00190, 01251], lr: 0.001193, loss: 0.4054
2022-09-22 16:34:37 - train: epoch 0058, iter [00200, 01251], lr: 0.001193, loss: 0.4107
2022-09-22 16:34:58 - train: epoch 0058, iter [00210, 01251], lr: 0.001193, loss: 0.4332
2022-09-22 16:35:19 - train: epoch 0058, iter [00220, 01251], lr: 0.001193, loss: 0.4198
2022-09-22 16:35:39 - train: epoch 0058, iter [00230, 01251], lr: 0.001193, loss: 0.4084
2022-09-22 16:36:00 - train: epoch 0058, iter [00240, 01251], lr: 0.001193, loss: 0.4410
2022-09-22 16:36:21 - train: epoch 0058, iter [00250, 01251], lr: 0.001193, loss: 0.4143
2022-09-22 16:36:42 - train: epoch 0058, iter [00260, 01251], lr: 0.001193, loss: 0.4307
2022-09-22 16:37:03 - train: epoch 0058, iter [00270, 01251], lr: 0.001193, loss: 0.4282
2022-09-22 16:37:24 - train: epoch 0058, iter [00280, 01251], lr: 0.001193, loss: 0.4295
2022-09-22 16:37:44 - train: epoch 0058, iter [00290, 01251], lr: 0.001193, loss: 0.4056
2022-09-22 16:38:05 - train: epoch 0058, iter [00300, 01251], lr: 0.001193, loss: 0.4121
2022-09-22 16:38:26 - train: epoch 0058, iter [00310, 01251], lr: 0.001193, loss: 0.4216
2022-09-22 16:38:46 - train: epoch 0058, iter [00320, 01251], lr: 0.001193, loss: 0.4221
2022-09-22 16:39:07 - train: epoch 0058, iter [00330, 01251], lr: 0.001193, loss: 0.4083
2022-09-22 16:39:28 - train: epoch 0058, iter [00340, 01251], lr: 0.001193, loss: 0.4193
2022-09-22 16:39:48 - train: epoch 0058, iter [00350, 01251], lr: 0.001193, loss: 0.4336
2022-09-22 16:40:09 - train: epoch 0058, iter [00360, 01251], lr: 0.001193, loss: 0.4096
2022-09-22 16:40:30 - train: epoch 0058, iter [00370, 01251], lr: 0.001193, loss: 0.4057
2022-09-22 16:40:51 - train: epoch 0058, iter [00380, 01251], lr: 0.001193, loss: 0.4187
2022-09-22 16:41:11 - train: epoch 0058, iter [00390, 01251], lr: 0.001193, loss: 0.4054
2022-09-22 16:41:32 - train: epoch 0058, iter [00400, 01251], lr: 0.001193, loss: 0.4179
2022-09-22 16:41:53 - train: epoch 0058, iter [00410, 01251], lr: 0.001193, loss: 0.4142
2022-09-22 16:42:14 - train: epoch 0058, iter [00420, 01251], lr: 0.001193, loss: 0.4022
2022-09-22 16:42:34 - train: epoch 0058, iter [00430, 01251], lr: 0.001193, loss: 0.4136
2022-09-22 16:42:55 - train: epoch 0058, iter [00440, 01251], lr: 0.001193, loss: 0.4386
2022-09-22 16:43:16 - train: epoch 0058, iter [00450, 01251], lr: 0.001193, loss: 0.4096
2022-09-22 16:43:37 - train: epoch 0058, iter [00460, 01251], lr: 0.001193, loss: 0.4086
2022-09-22 16:43:57 - train: epoch 0058, iter [00470, 01251], lr: 0.001193, loss: 0.4144
2022-09-22 16:44:18 - train: epoch 0058, iter [00480, 01251], lr: 0.001193, loss: 0.4048
2022-09-22 16:44:39 - train: epoch 0058, iter [00490, 01251], lr: 0.001193, loss: 0.4152
2022-09-22 16:44:59 - train: epoch 0058, iter [00500, 01251], lr: 0.001193, loss: 0.4182
2022-09-22 16:45:20 - train: epoch 0058, iter [00510, 01251], lr: 0.001193, loss: 0.4086
2022-09-22 16:45:41 - train: epoch 0058, iter [00520, 01251], lr: 0.001193, loss: 0.4260
2022-09-22 16:46:02 - train: epoch 0058, iter [00530, 01251], lr: 0.001193, loss: 0.4099
2022-09-22 16:46:23 - train: epoch 0058, iter [00540, 01251], lr: 0.001193, loss: 0.4055
2022-09-22 16:46:43 - train: epoch 0058, iter [00550, 01251], lr: 0.001193, loss: 0.4174
2022-09-22 16:47:04 - train: epoch 0058, iter [00560, 01251], lr: 0.001193, loss: 0.4073
2022-09-22 16:47:25 - train: epoch 0058, iter [00570, 01251], lr: 0.001193, loss: 0.4422
2022-09-22 16:47:46 - train: epoch 0058, iter [00580, 01251], lr: 0.001193, loss: 0.4094
2022-09-22 16:48:07 - train: epoch 0058, iter [00590, 01251], lr: 0.001193, loss: 0.4145
2022-09-22 16:48:28 - train: epoch 0058, iter [00600, 01251], lr: 0.001193, loss: 0.4185
2022-09-22 16:48:48 - train: epoch 0058, iter [00610, 01251], lr: 0.001193, loss: 0.4068
2022-09-22 16:49:09 - train: epoch 0058, iter [00620, 01251], lr: 0.001193, loss: 0.3733
2022-09-22 16:49:30 - train: epoch 0058, iter [00630, 01251], lr: 0.001193, loss: 0.4266
2022-09-22 16:49:51 - train: epoch 0058, iter [00640, 01251], lr: 0.001193, loss: 0.4135
2022-09-22 16:50:12 - train: epoch 0058, iter [00650, 01251], lr: 0.001193, loss: 0.4245
2022-09-22 16:50:33 - train: epoch 0058, iter [00660, 01251], lr: 0.001193, loss: 0.4136
2022-09-22 16:50:53 - train: epoch 0058, iter [00670, 01251], lr: 0.001193, loss: 0.4184
2022-09-22 16:51:14 - train: epoch 0058, iter [00680, 01251], lr: 0.001193, loss: 0.4355
2022-09-22 16:51:35 - train: epoch 0058, iter [00690, 01251], lr: 0.001193, loss: 0.4100
2022-09-22 16:51:56 - train: epoch 0058, iter [00700, 01251], lr: 0.001193, loss: 0.4203
2022-09-22 16:52:16 - train: epoch 0058, iter [00710, 01251], lr: 0.001193, loss: 0.4343
2022-09-22 16:52:37 - train: epoch 0058, iter [00720, 01251], lr: 0.001193, loss: 0.4051
2022-09-22 16:52:58 - train: epoch 0058, iter [00730, 01251], lr: 0.001193, loss: 0.4209
2022-09-22 16:53:19 - train: epoch 0058, iter [00740, 01251], lr: 0.001193, loss: 0.4142
2022-09-22 16:53:40 - train: epoch 0058, iter [00750, 01251], lr: 0.001193, loss: 0.4259
2022-09-22 16:54:01 - train: epoch 0058, iter [00760, 01251], lr: 0.001193, loss: 0.4130
2022-09-22 16:54:21 - train: epoch 0058, iter [00770, 01251], lr: 0.001193, loss: 0.4044
2022-09-22 16:54:42 - train: epoch 0058, iter [00780, 01251], lr: 0.001193, loss: 0.4117
2022-09-22 16:55:03 - train: epoch 0058, iter [00790, 01251], lr: 0.001193, loss: 0.4229
2022-09-22 16:55:24 - train: epoch 0058, iter [00800, 01251], lr: 0.001193, loss: 0.4162
2022-09-22 16:55:45 - train: epoch 0058, iter [00810, 01251], lr: 0.001193, loss: 0.4045
2022-09-22 16:56:06 - train: epoch 0058, iter [00820, 01251], lr: 0.001193, loss: 0.4052
2022-09-22 16:56:26 - train: epoch 0058, iter [00830, 01251], lr: 0.001193, loss: 0.4127
2022-09-22 16:56:47 - train: epoch 0058, iter [00840, 01251], lr: 0.001193, loss: 0.4052
2022-09-22 16:57:08 - train: epoch 0058, iter [00850, 01251], lr: 0.001193, loss: 0.4188
2022-09-22 16:57:29 - train: epoch 0058, iter [00860, 01251], lr: 0.001193, loss: 0.4204
2022-09-22 16:57:50 - train: epoch 0058, iter [00870, 01251], lr: 0.001193, loss: 0.4263
2022-09-22 16:58:11 - train: epoch 0058, iter [00880, 01251], lr: 0.001193, loss: 0.4125
2022-09-22 16:58:31 - train: epoch 0058, iter [00890, 01251], lr: 0.001193, loss: 0.4206
2022-09-22 16:58:52 - train: epoch 0058, iter [00900, 01251], lr: 0.001193, loss: 0.4099
2022-09-22 16:59:13 - train: epoch 0058, iter [00910, 01251], lr: 0.001193, loss: 0.4082
2022-09-22 16:59:34 - train: epoch 0058, iter [00920, 01251], lr: 0.001193, loss: 0.4195
2022-09-22 16:59:55 - train: epoch 0058, iter [00930, 01251], lr: 0.001193, loss: 0.4263
2022-09-22 17:00:16 - train: epoch 0058, iter [00940, 01251], lr: 0.001193, loss: 0.3977
2022-09-22 17:00:37 - train: epoch 0058, iter [00950, 01251], lr: 0.001193, loss: 0.4039
2022-09-22 17:00:57 - train: epoch 0058, iter [00960, 01251], lr: 0.001193, loss: 0.4145
2022-09-22 17:01:18 - train: epoch 0058, iter [00970, 01251], lr: 0.001193, loss: 0.4496
2022-09-22 17:01:39 - train: epoch 0058, iter [00980, 01251], lr: 0.001193, loss: 0.4164
2022-09-22 17:02:00 - train: epoch 0058, iter [00990, 01251], lr: 0.001193, loss: 0.4122
2022-09-22 17:02:21 - train: epoch 0058, iter [01000, 01251], lr: 0.001193, loss: 0.4258
2022-09-22 17:02:42 - train: epoch 0058, iter [01010, 01251], lr: 0.001193, loss: 0.4316
2022-09-22 17:03:03 - train: epoch 0058, iter [01020, 01251], lr: 0.001193, loss: 0.4143
2022-09-22 17:03:23 - train: epoch 0058, iter [01030, 01251], lr: 0.001193, loss: 0.4117
2022-09-22 17:03:44 - train: epoch 0058, iter [01040, 01251], lr: 0.001193, loss: 0.4121
2022-09-22 17:04:05 - train: epoch 0058, iter [01050, 01251], lr: 0.001193, loss: 0.4086
2022-09-22 17:04:26 - train: epoch 0058, iter [01060, 01251], lr: 0.001193, loss: 0.4186
2022-09-22 17:04:47 - train: epoch 0058, iter [01070, 01251], lr: 0.001193, loss: 0.3983
2022-09-22 17:05:08 - train: epoch 0058, iter [01080, 01251], lr: 0.001193, loss: 0.4184
2022-09-22 17:05:29 - train: epoch 0058, iter [01090, 01251], lr: 0.001193, loss: 0.4085
2022-09-22 17:05:50 - train: epoch 0058, iter [01100, 01251], lr: 0.001193, loss: 0.4054
2022-09-22 17:06:11 - train: epoch 0058, iter [01110, 01251], lr: 0.001193, loss: 0.4089
2022-09-22 17:06:31 - train: epoch 0058, iter [01120, 01251], lr: 0.001193, loss: 0.4107
2022-09-22 17:06:52 - train: epoch 0058, iter [01130, 01251], lr: 0.001193, loss: 0.4119
2022-09-22 17:07:13 - train: epoch 0058, iter [01140, 01251], lr: 0.001193, loss: 0.4128
2022-09-22 17:07:34 - train: epoch 0058, iter [01150, 01251], lr: 0.001193, loss: 0.4110
2022-09-22 17:07:55 - train: epoch 0058, iter [01160, 01251], lr: 0.001193, loss: 0.4207
2022-09-22 17:08:15 - train: epoch 0058, iter [01170, 01251], lr: 0.001193, loss: 0.4084
2022-09-22 17:08:36 - train: epoch 0058, iter [01180, 01251], lr: 0.001193, loss: 0.4044
2022-09-22 17:08:57 - train: epoch 0058, iter [01190, 01251], lr: 0.001193, loss: 0.4256
2022-09-22 17:09:17 - train: epoch 0058, iter [01200, 01251], lr: 0.001193, loss: 0.4105
2022-09-22 17:09:38 - train: epoch 0058, iter [01210, 01251], lr: 0.001193, loss: 0.4208
2022-09-22 17:09:59 - train: epoch 0058, iter [01220, 01251], lr: 0.001193, loss: 0.4116
2022-09-22 17:10:20 - train: epoch 0058, iter [01230, 01251], lr: 0.001193, loss: 0.4121
2022-09-22 17:10:41 - train: epoch 0058, iter [01240, 01251], lr: 0.001193, loss: 0.4214
2022-09-22 17:11:01 - train: epoch 0058, iter [01250, 01251], lr: 0.001193, loss: 0.4032
2022-09-22 17:11:06 - train: epoch 058, train_loss: 0.4169
2022-09-22 17:11:11 - until epoch: 058, best_loss: 0.4169
2022-09-22 17:11:11 - epoch 059 lr: 0.001193
2022-09-22 17:11:48 - train: epoch 0059, iter [00010, 01251], lr: 0.001193, loss: 0.4127
2022-09-22 17:12:09 - train: epoch 0059, iter [00020, 01251], lr: 0.001193, loss: 0.4216
2022-09-22 17:12:30 - train: epoch 0059, iter [00030, 01251], lr: 0.001193, loss: 0.3805
2022-09-22 17:12:51 - train: epoch 0059, iter [00040, 01251], lr: 0.001193, loss: 0.4090
2022-09-22 17:13:12 - train: epoch 0059, iter [00050, 01251], lr: 0.001193, loss: 0.4240
2022-09-22 17:13:33 - train: epoch 0059, iter [00060, 01251], lr: 0.001193, loss: 0.4398
2022-09-22 17:13:54 - train: epoch 0059, iter [00070, 01251], lr: 0.001193, loss: 0.4132
2022-09-22 17:14:15 - train: epoch 0059, iter [00080, 01251], lr: 0.001193, loss: 0.4153
2022-09-22 17:14:36 - train: epoch 0059, iter [00090, 01251], lr: 0.001193, loss: 0.4073
2022-09-22 17:14:57 - train: epoch 0059, iter [00100, 01251], lr: 0.001193, loss: 0.4027
2022-09-22 17:15:18 - train: epoch 0059, iter [00110, 01251], lr: 0.001193, loss: 0.4152
2022-09-22 17:15:39 - train: epoch 0059, iter [00120, 01251], lr: 0.001193, loss: 0.4000
2022-09-22 17:16:00 - train: epoch 0059, iter [00130, 01251], lr: 0.001193, loss: 0.4247
2022-09-22 17:16:21 - train: epoch 0059, iter [00140, 01251], lr: 0.001193, loss: 0.4441
2022-09-22 17:16:42 - train: epoch 0059, iter [00150, 01251], lr: 0.001193, loss: 0.4065
2022-09-22 17:17:03 - train: epoch 0059, iter [00160, 01251], lr: 0.001193, loss: 0.4220
2022-09-22 17:17:24 - train: epoch 0059, iter [00170, 01251], lr: 0.001193, loss: 0.4358
2022-09-22 17:17:45 - train: epoch 0059, iter [00180, 01251], lr: 0.001192, loss: 0.4065
2022-09-22 17:18:05 - train: epoch 0059, iter [00190, 01251], lr: 0.001192, loss: 0.4159
2022-09-22 17:18:26 - train: epoch 0059, iter [00200, 01251], lr: 0.001192, loss: 0.4228
2022-09-22 17:18:47 - train: epoch 0059, iter [00210, 01251], lr: 0.001192, loss: 0.4190
2022-09-22 17:19:08 - train: epoch 0059, iter [00220, 01251], lr: 0.001192, loss: 0.4156
2022-09-22 17:19:29 - train: epoch 0059, iter [00230, 01251], lr: 0.001192, loss: 0.4245
2022-09-22 17:19:50 - train: epoch 0059, iter [00240, 01251], lr: 0.001192, loss: 0.4136
2022-09-22 17:20:10 - train: epoch 0059, iter [00250, 01251], lr: 0.001192, loss: 0.4197
2022-09-22 17:20:31 - train: epoch 0059, iter [00260, 01251], lr: 0.001192, loss: 0.4170
2022-09-22 17:20:52 - train: epoch 0059, iter [00270, 01251], lr: 0.001192, loss: 0.3974
2022-09-22 17:21:13 - train: epoch 0059, iter [00280, 01251], lr: 0.001192, loss: 0.4294
2022-09-22 17:21:34 - train: epoch 0059, iter [00290, 01251], lr: 0.001192, loss: 0.4060
2022-09-22 17:21:55 - train: epoch 0059, iter [00300, 01251], lr: 0.001192, loss: 0.4182
2022-09-22 17:22:15 - train: epoch 0059, iter [00310, 01251], lr: 0.001192, loss: 0.4249
2022-09-22 17:22:36 - train: epoch 0059, iter [00320, 01251], lr: 0.001192, loss: 0.3966
2022-09-22 17:22:57 - train: epoch 0059, iter [00330, 01251], lr: 0.001192, loss: 0.4014
2022-09-22 17:23:18 - train: epoch 0059, iter [00340, 01251], lr: 0.001192, loss: 0.4131
2022-09-22 17:23:39 - train: epoch 0059, iter [00350, 01251], lr: 0.001192, loss: 0.4073
2022-09-22 17:23:59 - train: epoch 0059, iter [00360, 01251], lr: 0.001192, loss: 0.4350
2022-09-22 17:24:20 - train: epoch 0059, iter [00370, 01251], lr: 0.001192, loss: 0.4236
2022-09-22 17:24:41 - train: epoch 0059, iter [00380, 01251], lr: 0.001192, loss: 0.4270
2022-09-22 17:25:02 - train: epoch 0059, iter [00390, 01251], lr: 0.001192, loss: 0.4331
2022-09-22 17:25:22 - train: epoch 0059, iter [00400, 01251], lr: 0.001192, loss: 0.4090
2022-09-22 17:25:43 - train: epoch 0059, iter [00410, 01251], lr: 0.001192, loss: 0.4252
2022-09-22 17:26:04 - train: epoch 0059, iter [00420, 01251], lr: 0.001192, loss: 0.4115
2022-09-22 17:26:24 - train: epoch 0059, iter [00430, 01251], lr: 0.001192, loss: 0.4189
2022-09-22 17:26:45 - train: epoch 0059, iter [00440, 01251], lr: 0.001192, loss: 0.4234
2022-09-22 17:27:06 - train: epoch 0059, iter [00450, 01251], lr: 0.001192, loss: 0.4272
2022-09-22 17:27:27 - train: epoch 0059, iter [00460, 01251], lr: 0.001192, loss: 0.4166
2022-09-22 17:27:48 - train: epoch 0059, iter [00470, 01251], lr: 0.001192, loss: 0.4068
2022-09-22 17:28:09 - train: epoch 0059, iter [00480, 01251], lr: 0.001192, loss: 0.4312
2022-09-22 17:28:29 - train: epoch 0059, iter [00490, 01251], lr: 0.001192, loss: 0.4150
2022-09-22 17:28:50 - train: epoch 0059, iter [00500, 01251], lr: 0.001192, loss: 0.4167
2022-09-22 17:29:11 - train: epoch 0059, iter [00510, 01251], lr: 0.001192, loss: 0.4158
2022-09-22 17:29:32 - train: epoch 0059, iter [00520, 01251], lr: 0.001192, loss: 0.4239
2022-09-22 17:29:52 - train: epoch 0059, iter [00530, 01251], lr: 0.001192, loss: 0.4119
2022-09-22 17:30:13 - train: epoch 0059, iter [00540, 01251], lr: 0.001192, loss: 0.4253
2022-09-22 17:30:34 - train: epoch 0059, iter [00550, 01251], lr: 0.001192, loss: 0.4339
2022-09-22 17:30:55 - train: epoch 0059, iter [00560, 01251], lr: 0.001192, loss: 0.4335
2022-09-22 17:31:15 - train: epoch 0059, iter [00570, 01251], lr: 0.001192, loss: 0.4032
2022-09-22 17:31:36 - train: epoch 0059, iter [00580, 01251], lr: 0.001192, loss: 0.4159
2022-09-22 17:31:57 - train: epoch 0059, iter [00590, 01251], lr: 0.001192, loss: 0.4180
2022-09-22 17:32:18 - train: epoch 0059, iter [00600, 01251], lr: 0.001192, loss: 0.4261
2022-09-22 17:32:38 - train: epoch 0059, iter [00610, 01251], lr: 0.001192, loss: 0.3998
2022-09-22 17:32:59 - train: epoch 0059, iter [00620, 01251], lr: 0.001192, loss: 0.4089
2022-09-22 17:33:20 - train: epoch 0059, iter [00630, 01251], lr: 0.001192, loss: 0.4130
2022-09-22 17:33:41 - train: epoch 0059, iter [00640, 01251], lr: 0.001192, loss: 0.4208
2022-09-22 17:34:01 - train: epoch 0059, iter [00650, 01251], lr: 0.001192, loss: 0.4155
2022-09-22 17:34:22 - train: epoch 0059, iter [00660, 01251], lr: 0.001192, loss: 0.4187
2022-09-22 17:34:43 - train: epoch 0059, iter [00670, 01251], lr: 0.001192, loss: 0.4012
2022-09-22 17:35:04 - train: epoch 0059, iter [00680, 01251], lr: 0.001192, loss: 0.4111
2022-09-22 17:35:25 - train: epoch 0059, iter [00690, 01251], lr: 0.001192, loss: 0.4237
2022-09-22 17:35:46 - train: epoch 0059, iter [00700, 01251], lr: 0.001192, loss: 0.4002
2022-09-22 17:36:07 - train: epoch 0059, iter [00710, 01251], lr: 0.001192, loss: 0.4165
2022-09-22 17:36:28 - train: epoch 0059, iter [00720, 01251], lr: 0.001192, loss: 0.4326
2022-09-22 17:36:49 - train: epoch 0059, iter [00730, 01251], lr: 0.001192, loss: 0.4213
2022-09-22 17:37:10 - train: epoch 0059, iter [00740, 01251], lr: 0.001192, loss: 0.4220
2022-09-22 17:37:31 - train: epoch 0059, iter [00750, 01251], lr: 0.001192, loss: 0.4283
2022-09-22 17:37:51 - train: epoch 0059, iter [00760, 01251], lr: 0.001192, loss: 0.4342
2022-09-22 17:38:12 - train: epoch 0059, iter [00770, 01251], lr: 0.001192, loss: 0.4246
2022-09-22 17:38:33 - train: epoch 0059, iter [00780, 01251], lr: 0.001192, loss: 0.4181
2022-09-22 17:38:54 - train: epoch 0059, iter [00790, 01251], lr: 0.001192, loss: 0.4145
2022-09-22 17:39:15 - train: epoch 0059, iter [00800, 01251], lr: 0.001192, loss: 0.4176
2022-09-22 17:39:36 - train: epoch 0059, iter [00810, 01251], lr: 0.001192, loss: 0.3995
2022-09-22 17:39:57 - train: epoch 0059, iter [00820, 01251], lr: 0.001192, loss: 0.3960
2022-09-22 17:40:19 - train: epoch 0059, iter [00830, 01251], lr: 0.001192, loss: 0.4208
2022-09-22 17:40:40 - train: epoch 0059, iter [00840, 01251], lr: 0.001192, loss: 0.4246
2022-09-22 17:41:01 - train: epoch 0059, iter [00850, 01251], lr: 0.001192, loss: 0.4287
2022-09-22 17:41:22 - train: epoch 0059, iter [00860, 01251], lr: 0.001192, loss: 0.4287
2022-09-22 17:41:44 - train: epoch 0059, iter [00870, 01251], lr: 0.001192, loss: 0.4323
2022-09-22 17:42:05 - train: epoch 0059, iter [00880, 01251], lr: 0.001192, loss: 0.4131
2022-09-22 17:42:26 - train: epoch 0059, iter [00890, 01251], lr: 0.001192, loss: 0.4138
2022-09-22 17:42:47 - train: epoch 0059, iter [00900, 01251], lr: 0.001192, loss: 0.4039
2022-09-22 17:43:08 - train: epoch 0059, iter [00910, 01251], lr: 0.001192, loss: 0.4326
2022-09-22 17:43:30 - train: epoch 0059, iter [00920, 01251], lr: 0.001192, loss: 0.4333
2022-09-22 17:43:51 - train: epoch 0059, iter [00930, 01251], lr: 0.001192, loss: 0.4121
2022-09-22 17:44:12 - train: epoch 0059, iter [00940, 01251], lr: 0.001192, loss: 0.4354
2022-09-22 17:44:33 - train: epoch 0059, iter [00950, 01251], lr: 0.001192, loss: 0.4023
2022-09-22 17:44:55 - train: epoch 0059, iter [00960, 01251], lr: 0.001192, loss: 0.4064
2022-09-22 17:45:16 - train: epoch 0059, iter [00970, 01251], lr: 0.001192, loss: 0.4089
2022-09-22 17:45:37 - train: epoch 0059, iter [00980, 01251], lr: 0.001192, loss: 0.4098
2022-09-22 17:45:59 - train: epoch 0059, iter [00990, 01251], lr: 0.001192, loss: 0.4064
2022-09-22 17:46:20 - train: epoch 0059, iter [01000, 01251], lr: 0.001192, loss: 0.4269
2022-09-22 17:46:41 - train: epoch 0059, iter [01010, 01251], lr: 0.001192, loss: 0.4226
2022-09-22 17:47:02 - train: epoch 0059, iter [01020, 01251], lr: 0.001192, loss: 0.4238
2022-09-22 17:47:23 - train: epoch 0059, iter [01030, 01251], lr: 0.001192, loss: 0.4017
2022-09-22 17:47:45 - train: epoch 0059, iter [01040, 01251], lr: 0.001192, loss: 0.4374
2022-09-22 17:48:06 - train: epoch 0059, iter [01050, 01251], lr: 0.001192, loss: 0.4208
2022-09-22 17:48:27 - train: epoch 0059, iter [01060, 01251], lr: 0.001192, loss: 0.4259
2022-09-22 17:48:48 - train: epoch 0059, iter [01070, 01251], lr: 0.001192, loss: 0.4090
2022-09-22 17:49:09 - train: epoch 0059, iter [01080, 01251], lr: 0.001192, loss: 0.4055
2022-09-22 17:49:30 - train: epoch 0059, iter [01090, 01251], lr: 0.001192, loss: 0.4256
2022-09-22 17:49:51 - train: epoch 0059, iter [01100, 01251], lr: 0.001192, loss: 0.4261
2022-09-22 17:50:12 - train: epoch 0059, iter [01110, 01251], lr: 0.001192, loss: 0.4220
2022-09-22 17:50:33 - train: epoch 0059, iter [01120, 01251], lr: 0.001192, loss: 0.4245
2022-09-22 17:50:55 - train: epoch 0059, iter [01130, 01251], lr: 0.001192, loss: 0.4253
2022-09-22 17:51:15 - train: epoch 0059, iter [01140, 01251], lr: 0.001192, loss: 0.4003
2022-09-22 17:51:37 - train: epoch 0059, iter [01150, 01251], lr: 0.001192, loss: 0.4350
2022-09-22 17:51:58 - train: epoch 0059, iter [01160, 01251], lr: 0.001192, loss: 0.4233
2022-09-22 17:52:19 - train: epoch 0059, iter [01170, 01251], lr: 0.001192, loss: 0.4178
2022-09-22 17:52:40 - train: epoch 0059, iter [01180, 01251], lr: 0.001192, loss: 0.4208
2022-09-22 17:53:01 - train: epoch 0059, iter [01190, 01251], lr: 0.001192, loss: 0.3977
2022-09-22 17:53:22 - train: epoch 0059, iter [01200, 01251], lr: 0.001192, loss: 0.4212
2022-09-22 17:53:43 - train: epoch 0059, iter [01210, 01251], lr: 0.001192, loss: 0.4203
2022-09-22 17:54:04 - train: epoch 0059, iter [01220, 01251], lr: 0.001192, loss: 0.4140
2022-09-22 17:54:25 - train: epoch 0059, iter [01230, 01251], lr: 0.001192, loss: 0.4250
2022-09-22 17:54:46 - train: epoch 0059, iter [01240, 01251], lr: 0.001192, loss: 0.4265
2022-09-22 17:55:06 - train: epoch 0059, iter [01250, 01251], lr: 0.001192, loss: 0.3957
2022-09-22 17:55:11 - train: epoch 059, train_loss: 0.4167
2022-09-22 17:55:16 - until epoch: 059, best_loss: 0.4167
2022-09-22 17:55:16 - epoch 060 lr: 0.001192
2022-09-22 17:55:54 - train: epoch 0060, iter [00010, 01251], lr: 0.001192, loss: 0.4307
2022-09-22 17:56:14 - train: epoch 0060, iter [00020, 01251], lr: 0.001192, loss: 0.4138
2022-09-22 17:56:35 - train: epoch 0060, iter [00030, 01251], lr: 0.001192, loss: 0.4164
2022-09-22 17:56:55 - train: epoch 0060, iter [00040, 01251], lr: 0.001192, loss: 0.4196
2022-09-22 17:57:16 - train: epoch 0060, iter [00050, 01251], lr: 0.001192, loss: 0.4206
2022-09-22 17:57:37 - train: epoch 0060, iter [00060, 01251], lr: 0.001192, loss: 0.4337
2022-09-22 17:57:57 - train: epoch 0060, iter [00070, 01251], lr: 0.001192, loss: 0.4274
2022-09-22 17:58:18 - train: epoch 0060, iter [00080, 01251], lr: 0.001192, loss: 0.4239
2022-09-22 17:58:38 - train: epoch 0060, iter [00090, 01251], lr: 0.001192, loss: 0.4138
2022-09-22 17:58:59 - train: epoch 0060, iter [00100, 01251], lr: 0.001192, loss: 0.4398
2022-09-22 17:59:19 - train: epoch 0060, iter [00110, 01251], lr: 0.001192, loss: 0.4018
2022-09-22 17:59:39 - train: epoch 0060, iter [00120, 01251], lr: 0.001192, loss: 0.3993
2022-09-22 17:59:59 - train: epoch 0060, iter [00130, 01251], lr: 0.001192, loss: 0.4418
2022-09-22 18:00:20 - train: epoch 0060, iter [00140, 01251], lr: 0.001192, loss: 0.4034
2022-09-22 18:00:40 - train: epoch 0060, iter [00150, 01251], lr: 0.001192, loss: 0.4178
2022-09-22 18:01:01 - train: epoch 0060, iter [00160, 01251], lr: 0.001192, loss: 0.4127
2022-09-22 18:01:21 - train: epoch 0060, iter [00170, 01251], lr: 0.001192, loss: 0.4073
2022-09-22 18:01:42 - train: epoch 0060, iter [00180, 01251], lr: 0.001192, loss: 0.4117
2022-09-22 18:02:02 - train: epoch 0060, iter [00190, 01251], lr: 0.001192, loss: 0.3988
2022-09-22 18:02:22 - train: epoch 0060, iter [00200, 01251], lr: 0.001192, loss: 0.4041
2022-09-22 18:02:43 - train: epoch 0060, iter [00210, 01251], lr: 0.001192, loss: 0.4013
2022-09-22 18:03:04 - train: epoch 0060, iter [00220, 01251], lr: 0.001192, loss: 0.4162
2022-09-22 18:03:24 - train: epoch 0060, iter [00230, 01251], lr: 0.001192, loss: 0.4025
2022-09-22 18:03:45 - train: epoch 0060, iter [00240, 01251], lr: 0.001192, loss: 0.4128
2022-09-22 18:04:05 - train: epoch 0060, iter [00250, 01251], lr: 0.001192, loss: 0.4242
2022-09-22 18:04:25 - train: epoch 0060, iter [00260, 01251], lr: 0.001192, loss: 0.4358
2022-09-22 18:04:45 - train: epoch 0060, iter [00270, 01251], lr: 0.001192, loss: 0.4203
2022-09-22 18:05:05 - train: epoch 0060, iter [00280, 01251], lr: 0.001192, loss: 0.3872
2022-09-22 18:05:25 - train: epoch 0060, iter [00290, 01251], lr: 0.001192, loss: 0.4318
2022-09-22 18:05:46 - train: epoch 0060, iter [00300, 01251], lr: 0.001192, loss: 0.4143
2022-09-22 18:06:06 - train: epoch 0060, iter [00310, 01251], lr: 0.001192, loss: 0.4372
2022-09-22 18:06:26 - train: epoch 0060, iter [00320, 01251], lr: 0.001192, loss: 0.4237
2022-09-22 18:06:46 - train: epoch 0060, iter [00330, 01251], lr: 0.001192, loss: 0.3920
2022-09-22 18:07:07 - train: epoch 0060, iter [00340, 01251], lr: 0.001192, loss: 0.4251
2022-09-22 18:07:27 - train: epoch 0060, iter [00350, 01251], lr: 0.001192, loss: 0.4172
2022-09-22 18:07:48 - train: epoch 0060, iter [00360, 01251], lr: 0.001192, loss: 0.4307
2022-09-22 18:08:08 - train: epoch 0060, iter [00370, 01251], lr: 0.001192, loss: 0.3963
2022-09-22 18:08:28 - train: epoch 0060, iter [00380, 01251], lr: 0.001192, loss: 0.4101
2022-09-22 18:08:48 - train: epoch 0060, iter [00390, 01251], lr: 0.001191, loss: 0.4286
2022-09-22 18:09:09 - train: epoch 0060, iter [00400, 01251], lr: 0.001191, loss: 0.4138
2022-09-22 18:09:29 - train: epoch 0060, iter [00410, 01251], lr: 0.001191, loss: 0.4311
2022-09-22 18:09:50 - train: epoch 0060, iter [00420, 01251], lr: 0.001191, loss: 0.4203
2022-09-22 18:10:10 - train: epoch 0060, iter [00430, 01251], lr: 0.001191, loss: 0.4201
2022-09-22 18:10:31 - train: epoch 0060, iter [00440, 01251], lr: 0.001191, loss: 0.4173
2022-09-22 18:10:51 - train: epoch 0060, iter [00450, 01251], lr: 0.001191, loss: 0.4117
2022-09-22 18:11:12 - train: epoch 0060, iter [00460, 01251], lr: 0.001191, loss: 0.4181
2022-09-22 18:11:32 - train: epoch 0060, iter [00470, 01251], lr: 0.001191, loss: 0.4028
2022-09-22 18:11:52 - train: epoch 0060, iter [00480, 01251], lr: 0.001191, loss: 0.4394
2022-09-22 18:12:12 - train: epoch 0060, iter [00490, 01251], lr: 0.001191, loss: 0.4217
2022-09-22 18:12:32 - train: epoch 0060, iter [00500, 01251], lr: 0.001191, loss: 0.4132
2022-09-22 18:12:52 - train: epoch 0060, iter [00510, 01251], lr: 0.001191, loss: 0.4426
2022-09-22 18:13:13 - train: epoch 0060, iter [00520, 01251], lr: 0.001191, loss: 0.4122
2022-09-22 18:13:33 - train: epoch 0060, iter [00530, 01251], lr: 0.001191, loss: 0.4228
2022-09-22 18:13:54 - train: epoch 0060, iter [00540, 01251], lr: 0.001191, loss: 0.4242
2022-09-22 18:14:14 - train: epoch 0060, iter [00550, 01251], lr: 0.001191, loss: 0.4284
2022-09-22 18:14:35 - train: epoch 0060, iter [00560, 01251], lr: 0.001191, loss: 0.4045
2022-09-22 18:14:55 - train: epoch 0060, iter [00570, 01251], lr: 0.001191, loss: 0.4304
2022-09-22 18:15:15 - train: epoch 0060, iter [00580, 01251], lr: 0.001191, loss: 0.4168
2022-09-22 18:15:36 - train: epoch 0060, iter [00590, 01251], lr: 0.001191, loss: 0.4191
2022-09-22 18:15:56 - train: epoch 0060, iter [00600, 01251], lr: 0.001191, loss: 0.4138
2022-09-22 18:16:16 - train: epoch 0060, iter [00610, 01251], lr: 0.001191, loss: 0.4263
2022-09-22 18:16:36 - train: epoch 0060, iter [00620, 01251], lr: 0.001191, loss: 0.4150
2022-09-22 18:16:57 - train: epoch 0060, iter [00630, 01251], lr: 0.001191, loss: 0.4113
2022-09-22 18:17:18 - train: epoch 0060, iter [00640, 01251], lr: 0.001191, loss: 0.4253
2022-09-22 18:17:38 - train: epoch 0060, iter [00650, 01251], lr: 0.001191, loss: 0.4075
2022-09-22 18:17:59 - train: epoch 0060, iter [00660, 01251], lr: 0.001191, loss: 0.4244
2022-09-22 18:18:20 - train: epoch 0060, iter [00670, 01251], lr: 0.001191, loss: 0.4323
2022-09-22 18:18:40 - train: epoch 0060, iter [00680, 01251], lr: 0.001191, loss: 0.4282
2022-09-22 18:19:01 - train: epoch 0060, iter [00690, 01251], lr: 0.001191, loss: 0.4263
2022-09-22 18:19:22 - train: epoch 0060, iter [00700, 01251], lr: 0.001191, loss: 0.3987
2022-09-22 18:19:42 - train: epoch 0060, iter [00710, 01251], lr: 0.001191, loss: 0.4294
2022-09-22 18:20:03 - train: epoch 0060, iter [00720, 01251], lr: 0.001191, loss: 0.4232
2022-09-22 18:20:24 - train: epoch 0060, iter [00730, 01251], lr: 0.001191, loss: 0.4072
2022-09-22 18:20:44 - train: epoch 0060, iter [00740, 01251], lr: 0.001191, loss: 0.4074
2022-09-22 18:21:05 - train: epoch 0060, iter [00750, 01251], lr: 0.001191, loss: 0.4183
2022-09-22 18:21:26 - train: epoch 0060, iter [00760, 01251], lr: 0.001191, loss: 0.4222
2022-09-22 18:21:46 - train: epoch 0060, iter [00770, 01251], lr: 0.001191, loss: 0.4375
2022-09-22 18:22:07 - train: epoch 0060, iter [00780, 01251], lr: 0.001191, loss: 0.4036
2022-09-22 18:22:28 - train: epoch 0060, iter [00790, 01251], lr: 0.001191, loss: 0.4120
2022-09-22 18:22:48 - train: epoch 0060, iter [00800, 01251], lr: 0.001191, loss: 0.4166
2022-09-22 18:23:09 - train: epoch 0060, iter [00810, 01251], lr: 0.001191, loss: 0.4438
2022-09-22 18:23:30 - train: epoch 0060, iter [00820, 01251], lr: 0.001191, loss: 0.4045
2022-09-22 18:23:50 - train: epoch 0060, iter [00830, 01251], lr: 0.001191, loss: 0.4252
2022-09-22 18:24:11 - train: epoch 0060, iter [00840, 01251], lr: 0.001191, loss: 0.4078
2022-09-22 18:24:32 - train: epoch 0060, iter [00850, 01251], lr: 0.001191, loss: 0.4045
2022-09-22 18:24:52 - train: epoch 0060, iter [00860, 01251], lr: 0.001191, loss: 0.4159
2022-09-22 18:25:13 - train: epoch 0060, iter [00870, 01251], lr: 0.001191, loss: 0.4175
2022-09-22 18:25:33 - train: epoch 0060, iter [00880, 01251], lr: 0.001191, loss: 0.4189
2022-09-22 18:25:54 - train: epoch 0060, iter [00890, 01251], lr: 0.001191, loss: 0.4134
2022-09-22 18:26:15 - train: epoch 0060, iter [00900, 01251], lr: 0.001191, loss: 0.4176
2022-09-22 18:26:35 - train: epoch 0060, iter [00910, 01251], lr: 0.001191, loss: 0.4405
2022-09-22 18:26:56 - train: epoch 0060, iter [00920, 01251], lr: 0.001191, loss: 0.4053
2022-09-22 18:27:16 - train: epoch 0060, iter [00930, 01251], lr: 0.001191, loss: 0.4104
2022-09-22 18:27:37 - train: epoch 0060, iter [00940, 01251], lr: 0.001191, loss: 0.4254
2022-09-22 18:27:58 - train: epoch 0060, iter [00950, 01251], lr: 0.001191, loss: 0.4264
2022-09-22 18:28:19 - train: epoch 0060, iter [00960, 01251], lr: 0.001191, loss: 0.3927
2022-09-22 18:28:39 - train: epoch 0060, iter [00970, 01251], lr: 0.001191, loss: 0.4047
2022-09-22 18:29:00 - train: epoch 0060, iter [00980, 01251], lr: 0.001191, loss: 0.4152
2022-09-22 18:29:20 - train: epoch 0060, iter [00990, 01251], lr: 0.001191, loss: 0.4171
2022-09-22 18:29:41 - train: epoch 0060, iter [01000, 01251], lr: 0.001191, loss: 0.4260
2022-09-22 18:30:01 - train: epoch 0060, iter [01010, 01251], lr: 0.001191, loss: 0.4082
2022-09-22 18:30:22 - train: epoch 0060, iter [01020, 01251], lr: 0.001191, loss: 0.4271
2022-09-22 18:30:42 - train: epoch 0060, iter [01030, 01251], lr: 0.001191, loss: 0.4154
2022-09-22 18:31:03 - train: epoch 0060, iter [01040, 01251], lr: 0.001191, loss: 0.4003
2022-09-22 18:31:24 - train: epoch 0060, iter [01050, 01251], lr: 0.001191, loss: 0.4154
2022-09-22 18:31:44 - train: epoch 0060, iter [01060, 01251], lr: 0.001191, loss: 0.4106
2022-09-22 18:32:05 - train: epoch 0060, iter [01070, 01251], lr: 0.001191, loss: 0.4264
2022-09-22 18:32:25 - train: epoch 0060, iter [01080, 01251], lr: 0.001191, loss: 0.4090
2022-09-22 18:32:46 - train: epoch 0060, iter [01090, 01251], lr: 0.001191, loss: 0.3960
2022-09-22 18:33:06 - train: epoch 0060, iter [01100, 01251], lr: 0.001191, loss: 0.4213
2022-09-22 18:33:27 - train: epoch 0060, iter [01110, 01251], lr: 0.001191, loss: 0.4009
2022-09-22 18:33:48 - train: epoch 0060, iter [01120, 01251], lr: 0.001191, loss: 0.4047
2022-09-22 18:34:08 - train: epoch 0060, iter [01130, 01251], lr: 0.001191, loss: 0.4184
2022-09-22 18:34:29 - train: epoch 0060, iter [01140, 01251], lr: 0.001191, loss: 0.4388
2022-09-22 18:34:50 - train: epoch 0060, iter [01150, 01251], lr: 0.001191, loss: 0.4273
2022-09-22 18:35:11 - train: epoch 0060, iter [01160, 01251], lr: 0.001191, loss: 0.4488
2022-09-22 18:35:31 - train: epoch 0060, iter [01170, 01251], lr: 0.001191, loss: 0.4263
2022-09-22 18:35:52 - train: epoch 0060, iter [01180, 01251], lr: 0.001191, loss: 0.4191
2022-09-22 18:36:13 - train: epoch 0060, iter [01190, 01251], lr: 0.001191, loss: 0.4101
2022-09-22 18:36:33 - train: epoch 0060, iter [01200, 01251], lr: 0.001191, loss: 0.4123
2022-09-22 18:36:54 - train: epoch 0060, iter [01210, 01251], lr: 0.001191, loss: 0.4080
2022-09-22 18:37:14 - train: epoch 0060, iter [01220, 01251], lr: 0.001191, loss: 0.4156
2022-09-22 18:37:35 - train: epoch 0060, iter [01230, 01251], lr: 0.001191, loss: 0.4078
2022-09-22 18:37:56 - train: epoch 0060, iter [01240, 01251], lr: 0.001191, loss: 0.4168
2022-09-22 18:38:16 - train: epoch 0060, iter [01250, 01251], lr: 0.001191, loss: 0.3984
2022-09-22 18:38:20 - train: epoch 060, train_loss: 0.4166
2022-09-22 18:38:24 - until epoch: 060, best_loss: 0.4166
2022-09-22 18:38:24 - epoch 061 lr: 0.001191
2022-09-22 18:39:01 - train: epoch 0061, iter [00010, 01251], lr: 0.001191, loss: 0.4040
2022-09-22 18:39:22 - train: epoch 0061, iter [00020, 01251], lr: 0.001191, loss: 0.4094
2022-09-22 18:39:42 - train: epoch 0061, iter [00030, 01251], lr: 0.001191, loss: 0.4059
2022-09-22 18:40:03 - train: epoch 0061, iter [00040, 01251], lr: 0.001191, loss: 0.4128
2022-09-22 18:40:24 - train: epoch 0061, iter [00050, 01251], lr: 0.001191, loss: 0.4199
2022-09-22 18:40:44 - train: epoch 0061, iter [00060, 01251], lr: 0.001191, loss: 0.4193
2022-09-22 18:41:05 - train: epoch 0061, iter [00070, 01251], lr: 0.001191, loss: 0.4292
2022-09-22 18:41:25 - train: epoch 0061, iter [00080, 01251], lr: 0.001191, loss: 0.4073
2022-09-22 18:41:46 - train: epoch 0061, iter [00090, 01251], lr: 0.001191, loss: 0.4431
2022-09-22 18:42:07 - train: epoch 0061, iter [00100, 01251], lr: 0.001191, loss: 0.4214
2022-09-22 18:42:27 - train: epoch 0061, iter [00110, 01251], lr: 0.001191, loss: 0.4389
2022-09-22 18:42:48 - train: epoch 0061, iter [00120, 01251], lr: 0.001191, loss: 0.4000
2022-09-22 18:43:09 - train: epoch 0061, iter [00130, 01251], lr: 0.001191, loss: 0.4059
2022-09-22 18:43:30 - train: epoch 0061, iter [00140, 01251], lr: 0.001191, loss: 0.4272
2022-09-22 18:43:50 - train: epoch 0061, iter [00150, 01251], lr: 0.001191, loss: 0.4121
2022-09-22 18:44:11 - train: epoch 0061, iter [00160, 01251], lr: 0.001191, loss: 0.4146
2022-09-22 18:44:32 - train: epoch 0061, iter [00170, 01251], lr: 0.001191, loss: 0.4160
2022-09-22 18:44:53 - train: epoch 0061, iter [00180, 01251], lr: 0.001191, loss: 0.4204
2022-09-22 18:45:14 - train: epoch 0061, iter [00190, 01251], lr: 0.001191, loss: 0.4001
2022-09-22 18:45:34 - train: epoch 0061, iter [00200, 01251], lr: 0.001191, loss: 0.3995
2022-09-22 18:45:55 - train: epoch 0061, iter [00210, 01251], lr: 0.001191, loss: 0.4290
2022-09-22 18:46:16 - train: epoch 0061, iter [00220, 01251], lr: 0.001191, loss: 0.4089
2022-09-22 18:46:37 - train: epoch 0061, iter [00230, 01251], lr: 0.001191, loss: 0.4320
2022-09-22 18:46:57 - train: epoch 0061, iter [00240, 01251], lr: 0.001191, loss: 0.4045
2022-09-22 18:47:18 - train: epoch 0061, iter [00250, 01251], lr: 0.001191, loss: 0.4200
2022-09-22 18:47:38 - train: epoch 0061, iter [00260, 01251], lr: 0.001191, loss: 0.4166
2022-09-22 18:47:59 - train: epoch 0061, iter [00270, 01251], lr: 0.001191, loss: 0.4229
2022-09-22 18:48:19 - train: epoch 0061, iter [00280, 01251], lr: 0.001191, loss: 0.4243
2022-09-22 18:48:40 - train: epoch 0061, iter [00290, 01251], lr: 0.001191, loss: 0.4124
2022-09-22 18:49:01 - train: epoch 0061, iter [00300, 01251], lr: 0.001191, loss: 0.4166
2022-09-22 18:49:21 - train: epoch 0061, iter [00310, 01251], lr: 0.001191, loss: 0.4014
2022-09-22 18:49:42 - train: epoch 0061, iter [00320, 01251], lr: 0.001191, loss: 0.4412
2022-09-22 18:50:03 - train: epoch 0061, iter [00330, 01251], lr: 0.001191, loss: 0.4047
2022-09-22 18:50:23 - train: epoch 0061, iter [00340, 01251], lr: 0.001191, loss: 0.4253
2022-09-22 18:50:44 - train: epoch 0061, iter [00350, 01251], lr: 0.001191, loss: 0.4182
2022-09-22 18:51:05 - train: epoch 0061, iter [00360, 01251], lr: 0.001191, loss: 0.4237
2022-09-22 18:51:25 - train: epoch 0061, iter [00370, 01251], lr: 0.001191, loss: 0.3979
2022-09-22 18:51:46 - train: epoch 0061, iter [00380, 01251], lr: 0.001191, loss: 0.4021
2022-09-22 18:52:07 - train: epoch 0061, iter [00390, 01251], lr: 0.001191, loss: 0.4438
2022-09-22 18:52:27 - train: epoch 0061, iter [00400, 01251], lr: 0.001191, loss: 0.4004
2022-09-22 18:52:48 - train: epoch 0061, iter [00410, 01251], lr: 0.001191, loss: 0.4168
2022-09-22 18:53:09 - train: epoch 0061, iter [00420, 01251], lr: 0.001191, loss: 0.4053
2022-09-22 18:53:30 - train: epoch 0061, iter [00430, 01251], lr: 0.001191, loss: 0.4069
2022-09-22 18:53:51 - train: epoch 0061, iter [00440, 01251], lr: 0.001191, loss: 0.4032
2022-09-22 18:54:11 - train: epoch 0061, iter [00450, 01251], lr: 0.001191, loss: 0.4115
2022-09-22 18:54:32 - train: epoch 0061, iter [00460, 01251], lr: 0.001191, loss: 0.4103
2022-09-22 18:54:53 - train: epoch 0061, iter [00470, 01251], lr: 0.001191, loss: 0.4065
2022-09-22 18:55:14 - train: epoch 0061, iter [00480, 01251], lr: 0.001191, loss: 0.3987
2022-09-22 18:55:35 - train: epoch 0061, iter [00490, 01251], lr: 0.001191, loss: 0.4045
2022-09-22 18:55:56 - train: epoch 0061, iter [00500, 01251], lr: 0.001191, loss: 0.4224
2022-09-22 18:56:16 - train: epoch 0061, iter [00510, 01251], lr: 0.001191, loss: 0.4147
2022-09-22 18:56:37 - train: epoch 0061, iter [00520, 01251], lr: 0.001191, loss: 0.4237
2022-09-22 18:56:58 - train: epoch 0061, iter [00530, 01251], lr: 0.001190, loss: 0.4313
2022-09-22 18:57:18 - train: epoch 0061, iter [00540, 01251], lr: 0.001190, loss: 0.4223
2022-09-22 18:57:39 - train: epoch 0061, iter [00550, 01251], lr: 0.001190, loss: 0.4222
2022-09-22 18:58:00 - train: epoch 0061, iter [00560, 01251], lr: 0.001190, loss: 0.4352
2022-09-22 18:58:21 - train: epoch 0061, iter [00570, 01251], lr: 0.001190, loss: 0.4222
2022-09-22 18:58:42 - train: epoch 0061, iter [00580, 01251], lr: 0.001190, loss: 0.4131
2022-09-22 18:59:02 - train: epoch 0061, iter [00590, 01251], lr: 0.001190, loss: 0.4124
2022-09-22 18:59:23 - train: epoch 0061, iter [00600, 01251], lr: 0.001190, loss: 0.4313
2022-09-22 18:59:44 - train: epoch 0061, iter [00610, 01251], lr: 0.001190, loss: 0.4290
2022-09-22 19:00:04 - train: epoch 0061, iter [00620, 01251], lr: 0.001190, loss: 0.3998
2022-09-22 19:00:25 - train: epoch 0061, iter [00630, 01251], lr: 0.001190, loss: 0.3946
2022-09-22 19:00:46 - train: epoch 0061, iter [00640, 01251], lr: 0.001190, loss: 0.4237
2022-09-22 19:01:07 - train: epoch 0061, iter [00650, 01251], lr: 0.001190, loss: 0.4232
2022-09-22 19:01:27 - train: epoch 0061, iter [00660, 01251], lr: 0.001190, loss: 0.4101
2022-09-22 19:01:48 - train: epoch 0061, iter [00670, 01251], lr: 0.001190, loss: 0.4141
2022-09-22 19:02:09 - train: epoch 0061, iter [00680, 01251], lr: 0.001190, loss: 0.4158
2022-09-22 19:02:29 - train: epoch 0061, iter [00690, 01251], lr: 0.001190, loss: 0.4039
2022-09-22 19:02:50 - train: epoch 0061, iter [00700, 01251], lr: 0.001190, loss: 0.4050
2022-09-22 19:03:11 - train: epoch 0061, iter [00710, 01251], lr: 0.001190, loss: 0.4405
2022-09-22 19:03:32 - train: epoch 0061, iter [00720, 01251], lr: 0.001190, loss: 0.4118
2022-09-22 19:03:52 - train: epoch 0061, iter [00730, 01251], lr: 0.001190, loss: 0.4301
2022-09-22 19:04:13 - train: epoch 0061, iter [00740, 01251], lr: 0.001190, loss: 0.4067
2022-09-22 19:04:34 - train: epoch 0061, iter [00750, 01251], lr: 0.001190, loss: 0.4178
2022-09-22 19:04:55 - train: epoch 0061, iter [00760, 01251], lr: 0.001190, loss: 0.3985
2022-09-22 19:05:15 - train: epoch 0061, iter [00770, 01251], lr: 0.001190, loss: 0.4049
2022-09-22 19:05:36 - train: epoch 0061, iter [00780, 01251], lr: 0.001190, loss: 0.4471
2022-09-22 19:05:57 - train: epoch 0061, iter [00790, 01251], lr: 0.001190, loss: 0.4004
2022-09-22 19:06:17 - train: epoch 0061, iter [00800, 01251], lr: 0.001190, loss: 0.4096
2022-09-22 19:06:38 - train: epoch 0061, iter [00810, 01251], lr: 0.001190, loss: 0.4260
2022-09-22 19:06:59 - train: epoch 0061, iter [00820, 01251], lr: 0.001190, loss: 0.4106
2022-09-22 19:07:20 - train: epoch 0061, iter [00830, 01251], lr: 0.001190, loss: 0.3939
2022-09-22 19:07:40 - train: epoch 0061, iter [00840, 01251], lr: 0.001190, loss: 0.4212
2022-09-22 19:08:01 - train: epoch 0061, iter [00850, 01251], lr: 0.001190, loss: 0.4172
2022-09-22 19:08:22 - train: epoch 0061, iter [00860, 01251], lr: 0.001190, loss: 0.4289
2022-09-22 19:08:43 - train: epoch 0061, iter [00870, 01251], lr: 0.001190, loss: 0.3992
2022-09-22 19:09:03 - train: epoch 0061, iter [00880, 01251], lr: 0.001190, loss: 0.4116
2022-09-22 19:09:24 - train: epoch 0061, iter [00890, 01251], lr: 0.001190, loss: 0.4377
2022-09-22 19:09:45 - train: epoch 0061, iter [00900, 01251], lr: 0.001190, loss: 0.4192
2022-09-22 19:10:05 - train: epoch 0061, iter [00910, 01251], lr: 0.001190, loss: 0.4280
2022-09-22 19:10:26 - train: epoch 0061, iter [00920, 01251], lr: 0.001190, loss: 0.4280
2022-09-22 19:10:47 - train: epoch 0061, iter [00930, 01251], lr: 0.001190, loss: 0.4093
2022-09-22 19:11:07 - train: epoch 0061, iter [00940, 01251], lr: 0.001190, loss: 0.4132
2022-09-22 19:11:28 - train: epoch 0061, iter [00950, 01251], lr: 0.001190, loss: 0.4141
2022-09-22 19:11:49 - train: epoch 0061, iter [00960, 01251], lr: 0.001190, loss: 0.4105
2022-09-22 19:12:10 - train: epoch 0061, iter [00970, 01251], lr: 0.001190, loss: 0.3951
2022-09-22 19:12:30 - train: epoch 0061, iter [00980, 01251], lr: 0.001190, loss: 0.4171
2022-09-22 19:12:51 - train: epoch 0061, iter [00990, 01251], lr: 0.001190, loss: 0.4164
2022-09-22 19:13:12 - train: epoch 0061, iter [01000, 01251], lr: 0.001190, loss: 0.4093
2022-09-22 19:13:33 - train: epoch 0061, iter [01010, 01251], lr: 0.001190, loss: 0.4247
2022-09-22 19:13:54 - train: epoch 0061, iter [01020, 01251], lr: 0.001190, loss: 0.4166
2022-09-22 19:14:14 - train: epoch 0061, iter [01030, 01251], lr: 0.001190, loss: 0.4284
2022-09-22 19:14:35 - train: epoch 0061, iter [01040, 01251], lr: 0.001190, loss: 0.4153
2022-09-22 19:14:56 - train: epoch 0061, iter [01050, 01251], lr: 0.001190, loss: 0.4379
2022-09-22 19:15:16 - train: epoch 0061, iter [01060, 01251], lr: 0.001190, loss: 0.4195
2022-09-22 19:15:37 - train: epoch 0061, iter [01070, 01251], lr: 0.001190, loss: 0.4115
2022-09-22 19:15:57 - train: epoch 0061, iter [01080, 01251], lr: 0.001190, loss: 0.4238
2022-09-22 19:16:18 - train: epoch 0061, iter [01090, 01251], lr: 0.001190, loss: 0.4215
2022-09-22 19:16:39 - train: epoch 0061, iter [01100, 01251], lr: 0.001190, loss: 0.4067
2022-09-22 19:17:00 - train: epoch 0061, iter [01110, 01251], lr: 0.001190, loss: 0.4057
2022-09-22 19:17:20 - train: epoch 0061, iter [01120, 01251], lr: 0.001190, loss: 0.4218
2022-09-22 19:17:41 - train: epoch 0061, iter [01130, 01251], lr: 0.001190, loss: 0.4083
2022-09-22 19:18:02 - train: epoch 0061, iter [01140, 01251], lr: 0.001190, loss: 0.4320
2022-09-22 19:18:23 - train: epoch 0061, iter [01150, 01251], lr: 0.001190, loss: 0.4262
2022-09-22 19:18:43 - train: epoch 0061, iter [01160, 01251], lr: 0.001190, loss: 0.4041
2022-09-22 19:19:04 - train: epoch 0061, iter [01170, 01251], lr: 0.001190, loss: 0.4216
2022-09-22 19:19:25 - train: epoch 0061, iter [01180, 01251], lr: 0.001190, loss: 0.4176
2022-09-22 19:19:45 - train: epoch 0061, iter [01190, 01251], lr: 0.001190, loss: 0.3965
2022-09-22 19:20:06 - train: epoch 0061, iter [01200, 01251], lr: 0.001190, loss: 0.4077
2022-09-22 19:20:27 - train: epoch 0061, iter [01210, 01251], lr: 0.001190, loss: 0.4074
2022-09-22 19:20:47 - train: epoch 0061, iter [01220, 01251], lr: 0.001190, loss: 0.4424
2022-09-22 19:21:08 - train: epoch 0061, iter [01230, 01251], lr: 0.001190, loss: 0.4178
2022-09-22 19:21:29 - train: epoch 0061, iter [01240, 01251], lr: 0.001190, loss: 0.4118
2022-09-22 19:21:48 - train: epoch 0061, iter [01250, 01251], lr: 0.001190, loss: 0.4211
2022-09-22 19:21:53 - train: epoch 061, train_loss: 0.4165
2022-09-22 19:21:58 - until epoch: 061, best_loss: 0.4165
2022-09-22 19:21:58 - epoch 062 lr: 0.001190
2022-09-22 19:22:34 - train: epoch 0062, iter [00010, 01251], lr: 0.001190, loss: 0.4015
2022-09-22 19:22:55 - train: epoch 0062, iter [00020, 01251], lr: 0.001190, loss: 0.4228
2022-09-22 19:23:16 - train: epoch 0062, iter [00030, 01251], lr: 0.001190, loss: 0.4046
2022-09-22 19:23:36 - train: epoch 0062, iter [00040, 01251], lr: 0.001190, loss: 0.4101
2022-09-22 19:23:57 - train: epoch 0062, iter [00050, 01251], lr: 0.001190, loss: 0.4136
2022-09-22 19:24:18 - train: epoch 0062, iter [00060, 01251], lr: 0.001190, loss: 0.4269
2022-09-22 19:24:39 - train: epoch 0062, iter [00070, 01251], lr: 0.001190, loss: 0.4164
2022-09-22 19:25:00 - train: epoch 0062, iter [00080, 01251], lr: 0.001190, loss: 0.4268
2022-09-22 19:25:21 - train: epoch 0062, iter [00090, 01251], lr: 0.001190, loss: 0.4021
2022-09-22 19:25:42 - train: epoch 0062, iter [00100, 01251], lr: 0.001190, loss: 0.4262
2022-09-22 19:26:02 - train: epoch 0062, iter [00110, 01251], lr: 0.001190, loss: 0.4153
2022-09-22 19:26:23 - train: epoch 0062, iter [00120, 01251], lr: 0.001190, loss: 0.4115
2022-09-22 19:26:44 - train: epoch 0062, iter [00130, 01251], lr: 0.001190, loss: 0.3985
2022-09-22 19:27:05 - train: epoch 0062, iter [00140, 01251], lr: 0.001190, loss: 0.4023
2022-09-22 19:27:26 - train: epoch 0062, iter [00150, 01251], lr: 0.001190, loss: 0.3948
2022-09-22 19:27:47 - train: epoch 0062, iter [00160, 01251], lr: 0.001190, loss: 0.4097
2022-09-22 19:28:08 - train: epoch 0062, iter [00170, 01251], lr: 0.001190, loss: 0.4096
2022-09-22 19:28:29 - train: epoch 0062, iter [00180, 01251], lr: 0.001190, loss: 0.4129
2022-09-22 19:28:50 - train: epoch 0062, iter [00190, 01251], lr: 0.001190, loss: 0.4276
2022-09-22 19:29:11 - train: epoch 0062, iter [00200, 01251], lr: 0.001190, loss: 0.4301
2022-09-22 19:29:31 - train: epoch 0062, iter [00210, 01251], lr: 0.001190, loss: 0.4127
2022-09-22 19:29:52 - train: epoch 0062, iter [00220, 01251], lr: 0.001190, loss: 0.4356
2022-09-22 19:30:13 - train: epoch 0062, iter [00230, 01251], lr: 0.001190, loss: 0.4330
2022-09-22 19:30:34 - train: epoch 0062, iter [00240, 01251], lr: 0.001190, loss: 0.4129
2022-09-22 19:30:55 - train: epoch 0062, iter [00250, 01251], lr: 0.001190, loss: 0.4118
2022-09-22 19:31:16 - train: epoch 0062, iter [00260, 01251], lr: 0.001190, loss: 0.4257
2022-09-22 19:31:37 - train: epoch 0062, iter [00270, 01251], lr: 0.001190, loss: 0.4290
2022-09-22 19:31:58 - train: epoch 0062, iter [00280, 01251], lr: 0.001190, loss: 0.4202
2022-09-22 19:32:19 - train: epoch 0062, iter [00290, 01251], lr: 0.001190, loss: 0.4123
2022-09-22 19:32:40 - train: epoch 0062, iter [00300, 01251], lr: 0.001190, loss: 0.4121
2022-09-22 19:33:01 - train: epoch 0062, iter [00310, 01251], lr: 0.001190, loss: 0.4142
2022-09-22 19:33:21 - train: epoch 0062, iter [00320, 01251], lr: 0.001190, loss: 0.3981
2022-09-22 19:33:42 - train: epoch 0062, iter [00330, 01251], lr: 0.001190, loss: 0.4199
2022-09-22 19:34:03 - train: epoch 0062, iter [00340, 01251], lr: 0.001190, loss: 0.4299
2022-09-22 19:34:24 - train: epoch 0062, iter [00350, 01251], lr: 0.001190, loss: 0.4111
2022-09-22 19:34:45 - train: epoch 0062, iter [00360, 01251], lr: 0.001190, loss: 0.4245
2022-09-22 19:35:06 - train: epoch 0062, iter [00370, 01251], lr: 0.001190, loss: 0.4206
2022-09-22 19:35:27 - train: epoch 0062, iter [00380, 01251], lr: 0.001190, loss: 0.4324
2022-09-22 19:35:48 - train: epoch 0062, iter [00390, 01251], lr: 0.001190, loss: 0.4217
2022-09-22 19:36:09 - train: epoch 0062, iter [00400, 01251], lr: 0.001190, loss: 0.4089
2022-09-22 19:36:29 - train: epoch 0062, iter [00410, 01251], lr: 0.001190, loss: 0.4254
2022-09-22 19:36:50 - train: epoch 0062, iter [00420, 01251], lr: 0.001190, loss: 0.4164
2022-09-22 19:37:11 - train: epoch 0062, iter [00430, 01251], lr: 0.001190, loss: 0.4109
2022-09-22 19:37:32 - train: epoch 0062, iter [00440, 01251], lr: 0.001190, loss: 0.4148
2022-09-22 19:37:53 - train: epoch 0062, iter [00450, 01251], lr: 0.001190, loss: 0.4065
2022-09-22 19:38:14 - train: epoch 0062, iter [00460, 01251], lr: 0.001190, loss: 0.4220
2022-09-22 19:38:35 - train: epoch 0062, iter [00470, 01251], lr: 0.001190, loss: 0.4250
2022-09-22 19:38:56 - train: epoch 0062, iter [00480, 01251], lr: 0.001190, loss: 0.4278
2022-09-22 19:39:17 - train: epoch 0062, iter [00490, 01251], lr: 0.001190, loss: 0.4208
2022-09-22 19:39:37 - train: epoch 0062, iter [00500, 01251], lr: 0.001190, loss: 0.4086
2022-09-22 19:39:58 - train: epoch 0062, iter [00510, 01251], lr: 0.001190, loss: 0.4153
2022-09-22 19:40:19 - train: epoch 0062, iter [00520, 01251], lr: 0.001190, loss: 0.4114
2022-09-22 19:40:40 - train: epoch 0062, iter [00530, 01251], lr: 0.001190, loss: 0.4072
2022-09-22 19:41:01 - train: epoch 0062, iter [00540, 01251], lr: 0.001190, loss: 0.4205
2022-09-22 19:41:22 - train: epoch 0062, iter [00550, 01251], lr: 0.001190, loss: 0.4009
2022-09-22 19:41:43 - train: epoch 0062, iter [00560, 01251], lr: 0.001190, loss: 0.4054
2022-09-22 19:42:04 - train: epoch 0062, iter [00570, 01251], lr: 0.001190, loss: 0.4180
2022-09-22 19:42:25 - train: epoch 0062, iter [00580, 01251], lr: 0.001190, loss: 0.4136
2022-09-22 19:42:46 - train: epoch 0062, iter [00590, 01251], lr: 0.001189, loss: 0.4152
2022-09-22 19:43:07 - train: epoch 0062, iter [00600, 01251], lr: 0.001189, loss: 0.4112
2022-09-22 19:43:28 - train: epoch 0062, iter [00610, 01251], lr: 0.001189, loss: 0.4136
2022-09-22 19:43:49 - train: epoch 0062, iter [00620, 01251], lr: 0.001189, loss: 0.4213
2022-09-22 19:44:10 - train: epoch 0062, iter [00630, 01251], lr: 0.001189, loss: 0.4304
2022-09-22 19:44:31 - train: epoch 0062, iter [00640, 01251], lr: 0.001189, loss: 0.4304
2022-09-22 19:44:52 - train: epoch 0062, iter [00650, 01251], lr: 0.001189, loss: 0.4211
2022-09-22 19:45:13 - train: epoch 0062, iter [00660, 01251], lr: 0.001189, loss: 0.3908
2022-09-22 19:45:34 - train: epoch 0062, iter [00670, 01251], lr: 0.001189, loss: 0.4181
2022-09-22 19:45:55 - train: epoch 0062, iter [00680, 01251], lr: 0.001189, loss: 0.3975
2022-09-22 19:46:16 - train: epoch 0062, iter [00690, 01251], lr: 0.001189, loss: 0.4064
2022-09-22 19:46:37 - train: epoch 0062, iter [00700, 01251], lr: 0.001189, loss: 0.4156
2022-09-22 19:46:58 - train: epoch 0062, iter [00710, 01251], lr: 0.001189, loss: 0.4248
2022-09-22 19:47:19 - train: epoch 0062, iter [00720, 01251], lr: 0.001189, loss: 0.4173
2022-09-22 19:47:40 - train: epoch 0062, iter [00730, 01251], lr: 0.001189, loss: 0.4119
2022-09-22 19:48:01 - train: epoch 0062, iter [00740, 01251], lr: 0.001189, loss: 0.4107
2022-09-22 19:48:22 - train: epoch 0062, iter [00750, 01251], lr: 0.001189, loss: 0.4009
2022-09-22 19:48:43 - train: epoch 0062, iter [00760, 01251], lr: 0.001189, loss: 0.4074
2022-09-22 19:49:04 - train: epoch 0062, iter [00770, 01251], lr: 0.001189, loss: 0.4191
2022-09-22 19:49:24 - train: epoch 0062, iter [00780, 01251], lr: 0.001189, loss: 0.4249
2022-09-22 19:49:45 - train: epoch 0062, iter [00790, 01251], lr: 0.001189, loss: 0.4189
2022-09-22 19:50:06 - train: epoch 0062, iter [00800, 01251], lr: 0.001189, loss: 0.4177
2022-09-22 19:50:27 - train: epoch 0062, iter [00810, 01251], lr: 0.001189, loss: 0.4244
2022-09-22 19:50:48 - train: epoch 0062, iter [00820, 01251], lr: 0.001189, loss: 0.4277
2022-09-22 19:51:09 - train: epoch 0062, iter [00830, 01251], lr: 0.001189, loss: 0.4288
2022-09-22 19:51:30 - train: epoch 0062, iter [00840, 01251], lr: 0.001189, loss: 0.4093
2022-09-22 19:51:51 - train: epoch 0062, iter [00850, 01251], lr: 0.001189, loss: 0.4199
2022-09-22 19:52:12 - train: epoch 0062, iter [00860, 01251], lr: 0.001189, loss: 0.4274
2022-09-22 19:52:33 - train: epoch 0062, iter [00870, 01251], lr: 0.001189, loss: 0.3952
2022-09-22 19:52:54 - train: epoch 0062, iter [00880, 01251], lr: 0.001189, loss: 0.4238
2022-09-22 19:53:15 - train: epoch 0062, iter [00890, 01251], lr: 0.001189, loss: 0.4289
2022-09-22 19:53:35 - train: epoch 0062, iter [00900, 01251], lr: 0.001189, loss: 0.4335
2022-09-22 19:53:56 - train: epoch 0062, iter [00910, 01251], lr: 0.001189, loss: 0.4030
2022-09-22 19:54:17 - train: epoch 0062, iter [00920, 01251], lr: 0.001189, loss: 0.4173
2022-09-22 19:54:38 - train: epoch 0062, iter [00930, 01251], lr: 0.001189, loss: 0.4128
2022-09-22 19:54:59 - train: epoch 0062, iter [00940, 01251], lr: 0.001189, loss: 0.3998
2022-09-22 19:55:20 - train: epoch 0062, iter [00950, 01251], lr: 0.001189, loss: 0.4192
2022-09-22 19:55:41 - train: epoch 0062, iter [00960, 01251], lr: 0.001189, loss: 0.4197
2022-09-22 19:56:01 - train: epoch 0062, iter [00970, 01251], lr: 0.001189, loss: 0.4054
2022-09-22 19:56:22 - train: epoch 0062, iter [00980, 01251], lr: 0.001189, loss: 0.4107
2022-09-22 19:56:43 - train: epoch 0062, iter [00990, 01251], lr: 0.001189, loss: 0.4089
2022-09-22 19:57:04 - train: epoch 0062, iter [01000, 01251], lr: 0.001189, loss: 0.4059
2022-09-22 19:57:25 - train: epoch 0062, iter [01010, 01251], lr: 0.001189, loss: 0.4007
2022-09-22 19:57:45 - train: epoch 0062, iter [01020, 01251], lr: 0.001189, loss: 0.4249
2022-09-22 19:58:06 - train: epoch 0062, iter [01030, 01251], lr: 0.001189, loss: 0.3950
2022-09-22 19:58:27 - train: epoch 0062, iter [01040, 01251], lr: 0.001189, loss: 0.4002
2022-09-22 19:58:48 - train: epoch 0062, iter [01050, 01251], lr: 0.001189, loss: 0.4030
2022-09-22 19:59:08 - train: epoch 0062, iter [01060, 01251], lr: 0.001189, loss: 0.4213
2022-09-22 19:59:29 - train: epoch 0062, iter [01070, 01251], lr: 0.001189, loss: 0.4084
2022-09-22 19:59:50 - train: epoch 0062, iter [01080, 01251], lr: 0.001189, loss: 0.4139
2022-09-22 20:00:11 - train: epoch 0062, iter [01090, 01251], lr: 0.001189, loss: 0.4218
2022-09-22 20:00:31 - train: epoch 0062, iter [01100, 01251], lr: 0.001189, loss: 0.4140
2022-09-22 20:00:52 - train: epoch 0062, iter [01110, 01251], lr: 0.001189, loss: 0.4231
2022-09-22 20:01:13 - train: epoch 0062, iter [01120, 01251], lr: 0.001189, loss: 0.4289
2022-09-22 20:01:34 - train: epoch 0062, iter [01130, 01251], lr: 0.001189, loss: 0.3892
2022-09-22 20:01:55 - train: epoch 0062, iter [01140, 01251], lr: 0.001189, loss: 0.4135
2022-09-22 20:02:16 - train: epoch 0062, iter [01150, 01251], lr: 0.001189, loss: 0.4090
2022-09-22 20:02:37 - train: epoch 0062, iter [01160, 01251], lr: 0.001189, loss: 0.4148
2022-09-22 20:02:58 - train: epoch 0062, iter [01170, 01251], lr: 0.001189, loss: 0.4156
2022-09-22 20:03:18 - train: epoch 0062, iter [01180, 01251], lr: 0.001189, loss: 0.4078
2022-09-22 20:03:39 - train: epoch 0062, iter [01190, 01251], lr: 0.001189, loss: 0.4053
2022-09-22 20:04:00 - train: epoch 0062, iter [01200, 01251], lr: 0.001189, loss: 0.4262
2022-09-22 20:04:21 - train: epoch 0062, iter [01210, 01251], lr: 0.001189, loss: 0.4386
2022-09-22 20:04:42 - train: epoch 0062, iter [01220, 01251], lr: 0.001189, loss: 0.4048
2022-09-22 20:05:03 - train: epoch 0062, iter [01230, 01251], lr: 0.001189, loss: 0.4037
2022-09-22 20:05:23 - train: epoch 0062, iter [01240, 01251], lr: 0.001189, loss: 0.4475
2022-09-22 20:05:43 - train: epoch 0062, iter [01250, 01251], lr: 0.001189, loss: 0.4040
2022-09-22 20:05:48 - train: epoch 062, train_loss: 0.4164
2022-09-22 20:05:53 - until epoch: 062, best_loss: 0.4164
2022-09-22 20:05:53 - epoch 063 lr: 0.001189
2022-09-22 20:06:30 - train: epoch 0063, iter [00010, 01251], lr: 0.001189, loss: 0.4053
2022-09-22 20:06:51 - train: epoch 0063, iter [00020, 01251], lr: 0.001189, loss: 0.3987
2022-09-22 20:07:11 - train: epoch 0063, iter [00030, 01251], lr: 0.001189, loss: 0.4014
2022-09-22 20:07:32 - train: epoch 0063, iter [00040, 01251], lr: 0.001189, loss: 0.4195
2022-09-22 20:07:53 - train: epoch 0063, iter [00050, 01251], lr: 0.001189, loss: 0.4322
2022-09-22 20:08:14 - train: epoch 0063, iter [00060, 01251], lr: 0.001189, loss: 0.4140
2022-09-22 20:08:34 - train: epoch 0063, iter [00070, 01251], lr: 0.001189, loss: 0.4004
2022-09-22 20:08:55 - train: epoch 0063, iter [00080, 01251], lr: 0.001189, loss: 0.4091
2022-09-22 20:09:16 - train: epoch 0063, iter [00090, 01251], lr: 0.001189, loss: 0.4035
2022-09-22 20:09:36 - train: epoch 0063, iter [00100, 01251], lr: 0.001189, loss: 0.4287
2022-09-22 20:09:57 - train: epoch 0063, iter [00110, 01251], lr: 0.001189, loss: 0.4226
2022-09-22 20:10:18 - train: epoch 0063, iter [00120, 01251], lr: 0.001189, loss: 0.4146
2022-09-22 20:10:39 - train: epoch 0063, iter [00130, 01251], lr: 0.001189, loss: 0.4311
2022-09-22 20:11:00 - train: epoch 0063, iter [00140, 01251], lr: 0.001189, loss: 0.4032
2022-09-22 20:11:20 - train: epoch 0063, iter [00150, 01251], lr: 0.001189, loss: 0.3889
2022-09-22 20:11:41 - train: epoch 0063, iter [00160, 01251], lr: 0.001189, loss: 0.4205
2022-09-22 20:12:01 - train: epoch 0063, iter [00170, 01251], lr: 0.001189, loss: 0.4082
2022-09-22 20:12:22 - train: epoch 0063, iter [00180, 01251], lr: 0.001189, loss: 0.4226
2022-09-22 20:12:43 - train: epoch 0063, iter [00190, 01251], lr: 0.001189, loss: 0.4223
2022-09-22 20:13:03 - train: epoch 0063, iter [00200, 01251], lr: 0.001189, loss: 0.4357
2022-09-22 20:13:24 - train: epoch 0063, iter [00210, 01251], lr: 0.001189, loss: 0.4214
2022-09-22 20:13:45 - train: epoch 0063, iter [00220, 01251], lr: 0.001189, loss: 0.4102
2022-09-22 20:14:05 - train: epoch 0063, iter [00230, 01251], lr: 0.001189, loss: 0.4158
2022-09-22 20:14:26 - train: epoch 0063, iter [00240, 01251], lr: 0.001189, loss: 0.4067
2022-09-22 20:14:47 - train: epoch 0063, iter [00250, 01251], lr: 0.001189, loss: 0.4158
2022-09-22 20:15:07 - train: epoch 0063, iter [00260, 01251], lr: 0.001189, loss: 0.4043
2022-09-22 20:15:28 - train: epoch 0063, iter [00270, 01251], lr: 0.001189, loss: 0.4321
2022-09-22 20:15:49 - train: epoch 0063, iter [00280, 01251], lr: 0.001189, loss: 0.4115
2022-09-22 20:16:09 - train: epoch 0063, iter [00290, 01251], lr: 0.001189, loss: 0.4417
2022-09-22 20:16:30 - train: epoch 0063, iter [00300, 01251], lr: 0.001189, loss: 0.4348
2022-09-22 20:16:50 - train: epoch 0063, iter [00310, 01251], lr: 0.001189, loss: 0.4021
2022-09-22 20:17:11 - train: epoch 0063, iter [00320, 01251], lr: 0.001189, loss: 0.4200
2022-09-22 20:17:32 - train: epoch 0063, iter [00330, 01251], lr: 0.001189, loss: 0.4219
2022-09-22 20:17:53 - train: epoch 0063, iter [00340, 01251], lr: 0.001189, loss: 0.4118
2022-09-22 20:18:13 - train: epoch 0063, iter [00350, 01251], lr: 0.001189, loss: 0.4262
2022-09-22 20:18:34 - train: epoch 0063, iter [00360, 01251], lr: 0.001189, loss: 0.4291
2022-09-22 20:18:55 - train: epoch 0063, iter [00370, 01251], lr: 0.001189, loss: 0.4219
2022-09-22 20:19:15 - train: epoch 0063, iter [00380, 01251], lr: 0.001189, loss: 0.3952
2022-09-22 20:19:36 - train: epoch 0063, iter [00390, 01251], lr: 0.001189, loss: 0.4107
2022-09-22 20:19:57 - train: epoch 0063, iter [00400, 01251], lr: 0.001189, loss: 0.4336
2022-09-22 20:20:17 - train: epoch 0063, iter [00410, 01251], lr: 0.001189, loss: 0.4284
2022-09-22 20:20:38 - train: epoch 0063, iter [00420, 01251], lr: 0.001189, loss: 0.4099
2022-09-22 20:20:59 - train: epoch 0063, iter [00430, 01251], lr: 0.001189, loss: 0.4163
2022-09-22 20:21:20 - train: epoch 0063, iter [00440, 01251], lr: 0.001189, loss: 0.4039
2022-09-22 20:21:40 - train: epoch 0063, iter [00450, 01251], lr: 0.001189, loss: 0.4189
2022-09-22 20:22:01 - train: epoch 0063, iter [00460, 01251], lr: 0.001189, loss: 0.4196
2022-09-22 20:22:22 - train: epoch 0063, iter [00470, 01251], lr: 0.001189, loss: 0.4122
2022-09-22 20:22:42 - train: epoch 0063, iter [00480, 01251], lr: 0.001189, loss: 0.4115
2022-09-22 20:23:03 - train: epoch 0063, iter [00490, 01251], lr: 0.001189, loss: 0.4254
2022-09-22 20:23:24 - train: epoch 0063, iter [00500, 01251], lr: 0.001189, loss: 0.4317
2022-09-22 20:23:44 - train: epoch 0063, iter [00510, 01251], lr: 0.001189, loss: 0.4104
2022-09-22 20:24:05 - train: epoch 0063, iter [00520, 01251], lr: 0.001189, loss: 0.4217
2022-09-22 20:24:26 - train: epoch 0063, iter [00530, 01251], lr: 0.001189, loss: 0.4172
2022-09-22 20:24:47 - train: epoch 0063, iter [00540, 01251], lr: 0.001189, loss: 0.4158
2022-09-22 20:25:07 - train: epoch 0063, iter [00550, 01251], lr: 0.001189, loss: 0.4217
2022-09-22 20:25:28 - train: epoch 0063, iter [00560, 01251], lr: 0.001189, loss: 0.4078
2022-09-22 20:25:48 - train: epoch 0063, iter [00570, 01251], lr: 0.001189, loss: 0.4236
2022-09-22 20:26:09 - train: epoch 0063, iter [00580, 01251], lr: 0.001189, loss: 0.4248
2022-09-22 20:26:30 - train: epoch 0063, iter [00590, 01251], lr: 0.001189, loss: 0.4139
2022-09-22 20:26:50 - train: epoch 0063, iter [00600, 01251], lr: 0.001188, loss: 0.4080
2022-09-22 20:27:11 - train: epoch 0063, iter [00610, 01251], lr: 0.001188, loss: 0.4268
2022-09-22 20:27:32 - train: epoch 0063, iter [00620, 01251], lr: 0.001188, loss: 0.3976
2022-09-22 20:27:53 - train: epoch 0063, iter [00630, 01251], lr: 0.001188, loss: 0.3881
2022-09-22 20:28:14 - train: epoch 0063, iter [00640, 01251], lr: 0.001188, loss: 0.4348
2022-09-22 20:28:34 - train: epoch 0063, iter [00650, 01251], lr: 0.001188, loss: 0.4213
2022-09-22 20:28:55 - train: epoch 0063, iter [00660, 01251], lr: 0.001188, loss: 0.4235
2022-09-22 20:29:16 - train: epoch 0063, iter [00670, 01251], lr: 0.001188, loss: 0.4296
2022-09-22 20:29:37 - train: epoch 0063, iter [00680, 01251], lr: 0.001188, loss: 0.3973
2022-09-22 20:29:58 - train: epoch 0063, iter [00690, 01251], lr: 0.001188, loss: 0.4250
2022-09-22 20:30:19 - train: epoch 0063, iter [00700, 01251], lr: 0.001188, loss: 0.3954
2022-09-22 20:30:40 - train: epoch 0063, iter [00710, 01251], lr: 0.001188, loss: 0.4149
2022-09-22 20:31:01 - train: epoch 0063, iter [00720, 01251], lr: 0.001188, loss: 0.4444
2022-09-22 20:31:22 - train: epoch 0063, iter [00730, 01251], lr: 0.001188, loss: 0.4386
2022-09-22 20:31:43 - train: epoch 0063, iter [00740, 01251], lr: 0.001188, loss: 0.4087
2022-09-22 20:32:04 - train: epoch 0063, iter [00750, 01251], lr: 0.001188, loss: 0.4301
2022-09-22 20:32:25 - train: epoch 0063, iter [00760, 01251], lr: 0.001188, loss: 0.4113
2022-09-22 20:32:46 - train: epoch 0063, iter [00770, 01251], lr: 0.001188, loss: 0.4034
2022-09-22 20:33:07 - train: epoch 0063, iter [00780, 01251], lr: 0.001188, loss: 0.4108
2022-09-22 20:33:28 - train: epoch 0063, iter [00790, 01251], lr: 0.001188, loss: 0.4190
2022-09-22 20:33:49 - train: epoch 0063, iter [00800, 01251], lr: 0.001188, loss: 0.4244
2022-09-22 20:34:10 - train: epoch 0063, iter [00810, 01251], lr: 0.001188, loss: 0.4250
2022-09-22 20:34:31 - train: epoch 0063, iter [00820, 01251], lr: 0.001188, loss: 0.4128
2022-09-22 20:34:52 - train: epoch 0063, iter [00830, 01251], lr: 0.001188, loss: 0.4243
2022-09-22 20:35:13 - train: epoch 0063, iter [00840, 01251], lr: 0.001188, loss: 0.3987
2022-09-22 20:35:34 - train: epoch 0063, iter [00850, 01251], lr: 0.001188, loss: 0.4133
2022-09-22 20:35:55 - train: epoch 0063, iter [00860, 01251], lr: 0.001188, loss: 0.4024
2022-09-22 20:36:16 - train: epoch 0063, iter [00870, 01251], lr: 0.001188, loss: 0.4282
2022-09-22 20:36:37 - train: epoch 0063, iter [00880, 01251], lr: 0.001188, loss: 0.4047
2022-09-22 20:36:58 - train: epoch 0063, iter [00890, 01251], lr: 0.001188, loss: 0.4316
2022-09-22 20:37:19 - train: epoch 0063, iter [00900, 01251], lr: 0.001188, loss: 0.4187
2022-09-22 20:37:40 - train: epoch 0063, iter [00910, 01251], lr: 0.001188, loss: 0.4222
2022-09-22 20:38:01 - train: epoch 0063, iter [00920, 01251], lr: 0.001188, loss: 0.4020
2022-09-22 20:38:22 - train: epoch 0063, iter [00930, 01251], lr: 0.001188, loss: 0.4184
2022-09-22 20:38:43 - train: epoch 0063, iter [00940, 01251], lr: 0.001188, loss: 0.4110
2022-09-22 20:39:03 - train: epoch 0063, iter [00950, 01251], lr: 0.001188, loss: 0.4137
2022-09-22 20:39:23 - train: epoch 0063, iter [00960, 01251], lr: 0.001188, loss: 0.4278
2022-09-22 20:39:44 - train: epoch 0063, iter [00970, 01251], lr: 0.001188, loss: 0.4229
2022-09-22 20:40:04 - train: epoch 0063, iter [00980, 01251], lr: 0.001188, loss: 0.4156
2022-09-22 20:40:24 - train: epoch 0063, iter [00990, 01251], lr: 0.001188, loss: 0.4144
2022-09-22 20:40:45 - train: epoch 0063, iter [01000, 01251], lr: 0.001188, loss: 0.4156
2022-09-22 20:41:05 - train: epoch 0063, iter [01010, 01251], lr: 0.001188, loss: 0.4114
2022-09-22 20:41:26 - train: epoch 0063, iter [01020, 01251], lr: 0.001188, loss: 0.4045
2022-09-22 20:41:46 - train: epoch 0063, iter [01030, 01251], lr: 0.001188, loss: 0.4170
2022-09-22 20:42:06 - train: epoch 0063, iter [01040, 01251], lr: 0.001188, loss: 0.3920
2022-09-22 20:42:26 - train: epoch 0063, iter [01050, 01251], lr: 0.001188, loss: 0.4258
2022-09-22 20:42:47 - train: epoch 0063, iter [01060, 01251], lr: 0.001188, loss: 0.4242
2022-09-22 20:43:07 - train: epoch 0063, iter [01070, 01251], lr: 0.001188, loss: 0.4147
2022-09-22 20:43:27 - train: epoch 0063, iter [01080, 01251], lr: 0.001188, loss: 0.4283
2022-09-22 20:43:48 - train: epoch 0063, iter [01090, 01251], lr: 0.001188, loss: 0.4193
2022-09-22 20:44:08 - train: epoch 0063, iter [01100, 01251], lr: 0.001188, loss: 0.4238
2022-09-22 20:44:28 - train: epoch 0063, iter [01110, 01251], lr: 0.001188, loss: 0.4274
2022-09-22 20:44:49 - train: epoch 0063, iter [01120, 01251], lr: 0.001188, loss: 0.4243
2022-09-22 20:45:09 - train: epoch 0063, iter [01130, 01251], lr: 0.001188, loss: 0.4191
2022-09-22 20:45:29 - train: epoch 0063, iter [01140, 01251], lr: 0.001188, loss: 0.3932
2022-09-22 20:45:49 - train: epoch 0063, iter [01150, 01251], lr: 0.001188, loss: 0.4222
2022-09-22 20:46:10 - train: epoch 0063, iter [01160, 01251], lr: 0.001188, loss: 0.4058
2022-09-22 20:46:30 - train: epoch 0063, iter [01170, 01251], lr: 0.001188, loss: 0.4114
2022-09-22 20:46:50 - train: epoch 0063, iter [01180, 01251], lr: 0.001188, loss: 0.4002
2022-09-22 20:47:11 - train: epoch 0063, iter [01190, 01251], lr: 0.001188, loss: 0.3891
2022-09-22 20:47:31 - train: epoch 0063, iter [01200, 01251], lr: 0.001188, loss: 0.4301
2022-09-22 20:47:51 - train: epoch 0063, iter [01210, 01251], lr: 0.001188, loss: 0.4113
2022-09-22 20:48:11 - train: epoch 0063, iter [01220, 01251], lr: 0.001188, loss: 0.4018
2022-09-22 20:48:31 - train: epoch 0063, iter [01230, 01251], lr: 0.001188, loss: 0.4139
2022-09-22 20:48:51 - train: epoch 0063, iter [01240, 01251], lr: 0.001188, loss: 0.4088
2022-09-22 20:49:11 - train: epoch 0063, iter [01250, 01251], lr: 0.001188, loss: 0.4216
2022-09-22 20:49:15 - train: epoch 063, train_loss: 0.4163
2022-09-22 20:49:20 - until epoch: 063, best_loss: 0.4163
2022-09-22 20:49:20 - epoch 064 lr: 0.001188
2022-09-22 20:49:55 - train: epoch 0064, iter [00010, 01251], lr: 0.001188, loss: 0.4056
2022-09-22 20:50:15 - train: epoch 0064, iter [00020, 01251], lr: 0.001188, loss: 0.4114
2022-09-22 20:50:35 - train: epoch 0064, iter [00030, 01251], lr: 0.001188, loss: 0.4192
2022-09-22 20:50:55 - train: epoch 0064, iter [00040, 01251], lr: 0.001188, loss: 0.4146
2022-09-22 20:51:15 - train: epoch 0064, iter [00050, 01251], lr: 0.001188, loss: 0.3980
2022-09-22 20:51:36 - train: epoch 0064, iter [00060, 01251], lr: 0.001188, loss: 0.4195
2022-09-22 20:51:56 - train: epoch 0064, iter [00070, 01251], lr: 0.001188, loss: 0.4129
2022-09-22 20:52:17 - train: epoch 0064, iter [00080, 01251], lr: 0.001188, loss: 0.4302
2022-09-22 20:52:38 - train: epoch 0064, iter [00090, 01251], lr: 0.001188, loss: 0.4095
2022-09-22 20:52:59 - train: epoch 0064, iter [00100, 01251], lr: 0.001188, loss: 0.4284
2022-09-22 20:53:19 - train: epoch 0064, iter [00110, 01251], lr: 0.001188, loss: 0.4168
2022-09-22 20:53:40 - train: epoch 0064, iter [00120, 01251], lr: 0.001188, loss: 0.4131
2022-09-22 20:54:01 - train: epoch 0064, iter [00130, 01251], lr: 0.001188, loss: 0.4092
2022-09-22 20:54:21 - train: epoch 0064, iter [00140, 01251], lr: 0.001188, loss: 0.4328
2022-09-22 20:54:42 - train: epoch 0064, iter [00150, 01251], lr: 0.001188, loss: 0.4172
2022-09-22 20:55:02 - train: epoch 0064, iter [00160, 01251], lr: 0.001188, loss: 0.4217
2022-09-22 20:55:23 - train: epoch 0064, iter [00170, 01251], lr: 0.001188, loss: 0.4085
2022-09-22 20:55:44 - train: epoch 0064, iter [00180, 01251], lr: 0.001188, loss: 0.4168
2022-09-22 20:56:05 - train: epoch 0064, iter [00190, 01251], lr: 0.001188, loss: 0.4249
2022-09-22 20:56:25 - train: epoch 0064, iter [00200, 01251], lr: 0.001188, loss: 0.4371
2022-09-22 20:56:46 - train: epoch 0064, iter [00210, 01251], lr: 0.001188, loss: 0.4292
2022-09-22 20:57:07 - train: epoch 0064, iter [00220, 01251], lr: 0.001188, loss: 0.4037
2022-09-22 20:57:27 - train: epoch 0064, iter [00230, 01251], lr: 0.001188, loss: 0.4096
2022-09-22 20:57:47 - train: epoch 0064, iter [00240, 01251], lr: 0.001188, loss: 0.4353
2022-09-22 20:58:08 - train: epoch 0064, iter [00250, 01251], lr: 0.001188, loss: 0.4114
2022-09-22 20:58:28 - train: epoch 0064, iter [00260, 01251], lr: 0.001188, loss: 0.3972
2022-09-22 20:58:49 - train: epoch 0064, iter [00270, 01251], lr: 0.001188, loss: 0.4099
2022-09-22 20:59:09 - train: epoch 0064, iter [00280, 01251], lr: 0.001188, loss: 0.4159
2022-09-22 20:59:30 - train: epoch 0064, iter [00290, 01251], lr: 0.001188, loss: 0.3968
2022-09-22 20:59:51 - train: epoch 0064, iter [00300, 01251], lr: 0.001188, loss: 0.4180
2022-09-22 21:00:12 - train: epoch 0064, iter [00310, 01251], lr: 0.001188, loss: 0.4254
2022-09-22 21:00:33 - train: epoch 0064, iter [00320, 01251], lr: 0.001188, loss: 0.4007
2022-09-22 21:00:53 - train: epoch 0064, iter [00330, 01251], lr: 0.001188, loss: 0.4029
2022-09-22 21:01:14 - train: epoch 0064, iter [00340, 01251], lr: 0.001188, loss: 0.4202
2022-09-22 21:01:35 - train: epoch 0064, iter [00350, 01251], lr: 0.001188, loss: 0.4040
2022-09-22 21:01:55 - train: epoch 0064, iter [00360, 01251], lr: 0.001188, loss: 0.4096
2022-09-22 21:02:16 - train: epoch 0064, iter [00370, 01251], lr: 0.001188, loss: 0.4016
2022-09-22 21:02:37 - train: epoch 0064, iter [00380, 01251], lr: 0.001188, loss: 0.4067
2022-09-22 21:02:57 - train: epoch 0064, iter [00390, 01251], lr: 0.001188, loss: 0.4137
2022-09-22 21:03:18 - train: epoch 0064, iter [00400, 01251], lr: 0.001188, loss: 0.4135
2022-09-22 21:03:39 - train: epoch 0064, iter [00410, 01251], lr: 0.001188, loss: 0.4281
2022-09-22 21:04:00 - train: epoch 0064, iter [00420, 01251], lr: 0.001188, loss: 0.4342
2022-09-22 21:04:20 - train: epoch 0064, iter [00430, 01251], lr: 0.001188, loss: 0.4089
2022-09-22 21:04:41 - train: epoch 0064, iter [00440, 01251], lr: 0.001188, loss: 0.4172
2022-09-22 21:05:02 - train: epoch 0064, iter [00450, 01251], lr: 0.001188, loss: 0.4157
2022-09-22 21:05:23 - train: epoch 0064, iter [00460, 01251], lr: 0.001188, loss: 0.4315
2022-09-22 21:05:44 - train: epoch 0064, iter [00470, 01251], lr: 0.001188, loss: 0.4238
2022-09-22 21:06:04 - train: epoch 0064, iter [00480, 01251], lr: 0.001188, loss: 0.4266
2022-09-22 21:06:25 - train: epoch 0064, iter [00490, 01251], lr: 0.001188, loss: 0.4347
2022-09-22 21:06:46 - train: epoch 0064, iter [00500, 01251], lr: 0.001188, loss: 0.4276
2022-09-22 21:07:06 - train: epoch 0064, iter [00510, 01251], lr: 0.001188, loss: 0.4323
2022-09-22 21:07:27 - train: epoch 0064, iter [00520, 01251], lr: 0.001188, loss: 0.4157
2022-09-22 21:07:48 - train: epoch 0064, iter [00530, 01251], lr: 0.001188, loss: 0.4017
2022-09-22 21:08:09 - train: epoch 0064, iter [00540, 01251], lr: 0.001188, loss: 0.4167
2022-09-22 21:08:29 - train: epoch 0064, iter [00550, 01251], lr: 0.001187, loss: 0.4343
2022-09-22 21:08:50 - train: epoch 0064, iter [00560, 01251], lr: 0.001187, loss: 0.4119
2022-09-22 21:09:11 - train: epoch 0064, iter [00570, 01251], lr: 0.001187, loss: 0.4283
2022-09-22 21:09:31 - train: epoch 0064, iter [00580, 01251], lr: 0.001187, loss: 0.4142
2022-09-22 21:09:52 - train: epoch 0064, iter [00590, 01251], lr: 0.001187, loss: 0.4101
2022-09-22 21:10:13 - train: epoch 0064, iter [00600, 01251], lr: 0.001187, loss: 0.4084
2022-09-22 21:10:33 - train: epoch 0064, iter [00610, 01251], lr: 0.001187, loss: 0.3963
2022-09-22 21:10:54 - train: epoch 0064, iter [00620, 01251], lr: 0.001187, loss: 0.4086
2022-09-22 21:11:14 - train: epoch 0064, iter [00630, 01251], lr: 0.001187, loss: 0.4007
2022-09-22 21:11:35 - train: epoch 0064, iter [00640, 01251], lr: 0.001187, loss: 0.4084
2022-09-22 21:11:56 - train: epoch 0064, iter [00650, 01251], lr: 0.001187, loss: 0.4316
2022-09-22 21:12:17 - train: epoch 0064, iter [00660, 01251], lr: 0.001187, loss: 0.4254
2022-09-22 21:12:38 - train: epoch 0064, iter [00670, 01251], lr: 0.001187, loss: 0.4270
2022-09-22 21:12:58 - train: epoch 0064, iter [00680, 01251], lr: 0.001187, loss: 0.4242
2022-09-22 21:13:19 - train: epoch 0064, iter [00690, 01251], lr: 0.001187, loss: 0.4185
2022-09-22 21:13:40 - train: epoch 0064, iter [00700, 01251], lr: 0.001187, loss: 0.3990
2022-09-22 21:14:00 - train: epoch 0064, iter [00710, 01251], lr: 0.001187, loss: 0.4214
2022-09-22 21:14:21 - train: epoch 0064, iter [00720, 01251], lr: 0.001187, loss: 0.4250
2022-09-22 21:14:42 - train: epoch 0064, iter [00730, 01251], lr: 0.001187, loss: 0.4302
2022-09-22 21:15:02 - train: epoch 0064, iter [00740, 01251], lr: 0.001187, loss: 0.4160
2022-09-22 21:15:23 - train: epoch 0064, iter [00750, 01251], lr: 0.001187, loss: 0.4163
2022-09-22 21:15:43 - train: epoch 0064, iter [00760, 01251], lr: 0.001187, loss: 0.4059
2022-09-22 21:16:04 - train: epoch 0064, iter [00770, 01251], lr: 0.001187, loss: 0.4160
2022-09-22 21:16:24 - train: epoch 0064, iter [00780, 01251], lr: 0.001187, loss: 0.4128
2022-09-22 21:16:45 - train: epoch 0064, iter [00790, 01251], lr: 0.001187, loss: 0.4257
2022-09-22 21:17:06 - train: epoch 0064, iter [00800, 01251], lr: 0.001187, loss: 0.4300
2022-09-22 21:17:26 - train: epoch 0064, iter [00810, 01251], lr: 0.001187, loss: 0.4240
2022-09-22 21:17:47 - train: epoch 0064, iter [00820, 01251], lr: 0.001187, loss: 0.4178
2022-09-22 21:18:08 - train: epoch 0064, iter [00830, 01251], lr: 0.001187, loss: 0.4104
2022-09-22 21:18:29 - train: epoch 0064, iter [00840, 01251], lr: 0.001187, loss: 0.4271
2022-09-22 21:18:49 - train: epoch 0064, iter [00850, 01251], lr: 0.001187, loss: 0.4232
2022-09-22 21:19:10 - train: epoch 0064, iter [00860, 01251], lr: 0.001187, loss: 0.4270
2022-09-22 21:19:31 - train: epoch 0064, iter [00870, 01251], lr: 0.001187, loss: 0.4240
2022-09-22 21:19:51 - train: epoch 0064, iter [00880, 01251], lr: 0.001187, loss: 0.3873
2022-09-22 21:20:12 - train: epoch 0064, iter [00890, 01251], lr: 0.001187, loss: 0.4052
2022-09-22 21:20:33 - train: epoch 0064, iter [00900, 01251], lr: 0.001187, loss: 0.4216
2022-09-22 21:20:53 - train: epoch 0064, iter [00910, 01251], lr: 0.001187, loss: 0.4167
2022-09-22 21:21:14 - train: epoch 0064, iter [00920, 01251], lr: 0.001187, loss: 0.4376
2022-09-22 21:21:35 - train: epoch 0064, iter [00930, 01251], lr: 0.001187, loss: 0.4067
2022-09-22 21:21:56 - train: epoch 0064, iter [00940, 01251], lr: 0.001187, loss: 0.4010
2022-09-22 21:22:16 - train: epoch 0064, iter [00950, 01251], lr: 0.001187, loss: 0.4002
2022-09-22 21:22:37 - train: epoch 0064, iter [00960, 01251], lr: 0.001187, loss: 0.4116
2022-09-22 21:22:58 - train: epoch 0064, iter [00970, 01251], lr: 0.001187, loss: 0.3980
2022-09-22 21:23:18 - train: epoch 0064, iter [00980, 01251], lr: 0.001187, loss: 0.3977
2022-09-22 21:23:39 - train: epoch 0064, iter [00990, 01251], lr: 0.001187, loss: 0.4256
2022-09-22 21:24:00 - train: epoch 0064, iter [01000, 01251], lr: 0.001187, loss: 0.3933
2022-09-22 21:24:21 - train: epoch 0064, iter [01010, 01251], lr: 0.001187, loss: 0.4103
2022-09-22 21:24:41 - train: epoch 0064, iter [01020, 01251], lr: 0.001187, loss: 0.4251
2022-09-22 21:25:02 - train: epoch 0064, iter [01030, 01251], lr: 0.001187, loss: 0.4174
2022-09-22 21:25:23 - train: epoch 0064, iter [01040, 01251], lr: 0.001187, loss: 0.4299
2022-09-22 21:25:43 - train: epoch 0064, iter [01050, 01251], lr: 0.001187, loss: 0.4178
2022-09-22 21:26:04 - train: epoch 0064, iter [01060, 01251], lr: 0.001187, loss: 0.4272
2022-09-22 21:26:25 - train: epoch 0064, iter [01070, 01251], lr: 0.001187, loss: 0.4249
2022-09-22 21:26:46 - train: epoch 0064, iter [01080, 01251], lr: 0.001187, loss: 0.4261
2022-09-22 21:27:06 - train: epoch 0064, iter [01090, 01251], lr: 0.001187, loss: 0.4102
2022-09-22 21:27:27 - train: epoch 0064, iter [01100, 01251], lr: 0.001187, loss: 0.4035
2022-09-22 21:27:48 - train: epoch 0064, iter [01110, 01251], lr: 0.001187, loss: 0.3981
2022-09-22 21:28:09 - train: epoch 0064, iter [01120, 01251], lr: 0.001187, loss: 0.4210
2022-09-22 21:28:30 - train: epoch 0064, iter [01130, 01251], lr: 0.001187, loss: 0.4207
2022-09-22 21:28:50 - train: epoch 0064, iter [01140, 01251], lr: 0.001187, loss: 0.4201
2022-09-22 21:29:11 - train: epoch 0064, iter [01150, 01251], lr: 0.001187, loss: 0.4115
2022-09-22 21:29:32 - train: epoch 0064, iter [01160, 01251], lr: 0.001187, loss: 0.4240
2022-09-22 21:29:52 - train: epoch 0064, iter [01170, 01251], lr: 0.001187, loss: 0.4303
2022-09-22 21:30:13 - train: epoch 0064, iter [01180, 01251], lr: 0.001187, loss: 0.4175
2022-09-22 21:30:34 - train: epoch 0064, iter [01190, 01251], lr: 0.001187, loss: 0.4188
2022-09-22 21:30:55 - train: epoch 0064, iter [01200, 01251], lr: 0.001187, loss: 0.4132
2022-09-22 21:31:15 - train: epoch 0064, iter [01210, 01251], lr: 0.001187, loss: 0.4215
2022-09-22 21:31:36 - train: epoch 0064, iter [01220, 01251], lr: 0.001187, loss: 0.3948
2022-09-22 21:31:57 - train: epoch 0064, iter [01230, 01251], lr: 0.001187, loss: 0.4251
2022-09-22 21:32:18 - train: epoch 0064, iter [01240, 01251], lr: 0.001187, loss: 0.4251
2022-09-22 21:32:38 - train: epoch 0064, iter [01250, 01251], lr: 0.001187, loss: 0.3990
2022-09-22 21:32:42 - train: epoch 064, train_loss: 0.4161
2022-09-22 21:32:46 - until epoch: 064, best_loss: 0.4161
2022-09-22 21:32:46 - epoch 065 lr: 0.001187
2022-09-22 21:33:23 - train: epoch 0065, iter [00010, 01251], lr: 0.001187, loss: 0.4018
2022-09-22 21:33:44 - train: epoch 0065, iter [00020, 01251], lr: 0.001187, loss: 0.4335
2022-09-22 21:34:05 - train: epoch 0065, iter [00030, 01251], lr: 0.001187, loss: 0.3934
2022-09-22 21:34:26 - train: epoch 0065, iter [00040, 01251], lr: 0.001187, loss: 0.4033
2022-09-22 21:34:46 - train: epoch 0065, iter [00050, 01251], lr: 0.001187, loss: 0.3997
2022-09-22 21:35:07 - train: epoch 0065, iter [00060, 01251], lr: 0.001187, loss: 0.4076
2022-09-22 21:35:28 - train: epoch 0065, iter [00070, 01251], lr: 0.001187, loss: 0.4263
2022-09-22 21:35:48 - train: epoch 0065, iter [00080, 01251], lr: 0.001187, loss: 0.4267
2022-09-22 21:36:09 - train: epoch 0065, iter [00090, 01251], lr: 0.001187, loss: 0.4214
2022-09-22 21:36:30 - train: epoch 0065, iter [00100, 01251], lr: 0.001187, loss: 0.4268
2022-09-22 21:36:50 - train: epoch 0065, iter [00110, 01251], lr: 0.001187, loss: 0.4165
2022-09-22 21:37:11 - train: epoch 0065, iter [00120, 01251], lr: 0.001187, loss: 0.4179
2022-09-22 21:37:31 - train: epoch 0065, iter [00130, 01251], lr: 0.001187, loss: 0.4181
2022-09-22 21:37:52 - train: epoch 0065, iter [00140, 01251], lr: 0.001187, loss: 0.4121
2022-09-22 21:38:13 - train: epoch 0065, iter [00150, 01251], lr: 0.001187, loss: 0.4215
2022-09-22 21:38:34 - train: epoch 0065, iter [00160, 01251], lr: 0.001187, loss: 0.4250
2022-09-22 21:38:54 - train: epoch 0065, iter [00170, 01251], lr: 0.001187, loss: 0.4095
2022-09-22 21:39:15 - train: epoch 0065, iter [00180, 01251], lr: 0.001187, loss: 0.3928
2022-09-22 21:39:36 - train: epoch 0065, iter [00190, 01251], lr: 0.001187, loss: 0.3914
2022-09-22 21:39:57 - train: epoch 0065, iter [00200, 01251], lr: 0.001187, loss: 0.4252
2022-09-22 21:40:18 - train: epoch 0065, iter [00210, 01251], lr: 0.001187, loss: 0.4000
2022-09-22 21:40:38 - train: epoch 0065, iter [00220, 01251], lr: 0.001187, loss: 0.4191
2022-09-22 21:40:59 - train: epoch 0065, iter [00230, 01251], lr: 0.001187, loss: 0.4084
2022-09-22 21:41:20 - train: epoch 0065, iter [00240, 01251], lr: 0.001187, loss: 0.4168
2022-09-22 21:41:40 - train: epoch 0065, iter [00250, 01251], lr: 0.001187, loss: 0.4209
2022-09-22 21:42:01 - train: epoch 0065, iter [00260, 01251], lr: 0.001187, loss: 0.3993
2022-09-22 21:42:22 - train: epoch 0065, iter [00270, 01251], lr: 0.001187, loss: 0.4096
2022-09-22 21:42:43 - train: epoch 0065, iter [00280, 01251], lr: 0.001187, loss: 0.4337
2022-09-22 21:43:03 - train: epoch 0065, iter [00290, 01251], lr: 0.001187, loss: 0.4069
2022-09-22 21:43:24 - train: epoch 0065, iter [00300, 01251], lr: 0.001187, loss: 0.4074
2022-09-22 21:43:45 - train: epoch 0065, iter [00310, 01251], lr: 0.001187, loss: 0.4148
2022-09-22 21:44:05 - train: epoch 0065, iter [00320, 01251], lr: 0.001187, loss: 0.4033
2022-09-22 21:44:26 - train: epoch 0065, iter [00330, 01251], lr: 0.001187, loss: 0.4155
2022-09-22 21:44:47 - train: epoch 0065, iter [00340, 01251], lr: 0.001187, loss: 0.4034
2022-09-22 21:45:08 - train: epoch 0065, iter [00350, 01251], lr: 0.001187, loss: 0.4150
2022-09-22 21:45:28 - train: epoch 0065, iter [00360, 01251], lr: 0.001187, loss: 0.4109
2022-09-22 21:45:49 - train: epoch 0065, iter [00370, 01251], lr: 0.001187, loss: 0.4192
2022-09-22 21:46:10 - train: epoch 0065, iter [00380, 01251], lr: 0.001187, loss: 0.4184
2022-09-22 21:46:30 - train: epoch 0065, iter [00390, 01251], lr: 0.001187, loss: 0.4151
2022-09-22 21:46:51 - train: epoch 0065, iter [00400, 01251], lr: 0.001187, loss: 0.4055
2022-09-22 21:47:12 - train: epoch 0065, iter [00410, 01251], lr: 0.001187, loss: 0.4200
2022-09-22 21:47:32 - train: epoch 0065, iter [00420, 01251], lr: 0.001187, loss: 0.3986
2022-09-22 21:47:52 - train: epoch 0065, iter [00430, 01251], lr: 0.001187, loss: 0.4218
2022-09-22 21:48:13 - train: epoch 0065, iter [00440, 01251], lr: 0.001187, loss: 0.4157
2022-09-22 21:48:33 - train: epoch 0065, iter [00450, 01251], lr: 0.001186, loss: 0.4318
2022-09-22 21:48:54 - train: epoch 0065, iter [00460, 01251], lr: 0.001186, loss: 0.4126
2022-09-22 21:49:15 - train: epoch 0065, iter [00470, 01251], lr: 0.001186, loss: 0.4194
2022-09-22 21:49:35 - train: epoch 0065, iter [00480, 01251], lr: 0.001186, loss: 0.4476
2022-09-22 21:49:56 - train: epoch 0065, iter [00490, 01251], lr: 0.001186, loss: 0.4141
2022-09-22 21:50:16 - train: epoch 0065, iter [00500, 01251], lr: 0.001186, loss: 0.4403
2022-09-22 21:50:37 - train: epoch 0065, iter [00510, 01251], lr: 0.001186, loss: 0.4029
2022-09-22 21:50:57 - train: epoch 0065, iter [00520, 01251], lr: 0.001186, loss: 0.4103
2022-09-22 21:51:18 - train: epoch 0065, iter [00530, 01251], lr: 0.001186, loss: 0.4119
2022-09-22 21:51:38 - train: epoch 0065, iter [00540, 01251], lr: 0.001186, loss: 0.4243
2022-09-22 21:51:58 - train: epoch 0065, iter [00550, 01251], lr: 0.001186, loss: 0.4152
2022-09-22 21:52:19 - train: epoch 0065, iter [00560, 01251], lr: 0.001186, loss: 0.4205
2022-09-22 21:52:39 - train: epoch 0065, iter [00570, 01251], lr: 0.001186, loss: 0.4339
2022-09-22 21:53:00 - train: epoch 0065, iter [00580, 01251], lr: 0.001186, loss: 0.4073
2022-09-22 21:53:20 - train: epoch 0065, iter [00590, 01251], lr: 0.001186, loss: 0.4120
2022-09-22 21:53:41 - train: epoch 0065, iter [00600, 01251], lr: 0.001186, loss: 0.4027
2022-09-22 21:54:01 - train: epoch 0065, iter [00610, 01251], lr: 0.001186, loss: 0.4309
2022-09-22 21:54:22 - train: epoch 0065, iter [00620, 01251], lr: 0.001186, loss: 0.4251
2022-09-22 21:54:43 - train: epoch 0065, iter [00630, 01251], lr: 0.001186, loss: 0.4185
2022-09-22 21:55:03 - train: epoch 0065, iter [00640, 01251], lr: 0.001186, loss: 0.4326
2022-09-22 21:55:24 - train: epoch 0065, iter [00650, 01251], lr: 0.001186, loss: 0.3986
2022-09-22 21:55:44 - train: epoch 0065, iter [00660, 01251], lr: 0.001186, loss: 0.4151
2022-09-22 21:56:05 - train: epoch 0065, iter [00670, 01251], lr: 0.001186, loss: 0.4307
2022-09-22 21:56:26 - train: epoch 0065, iter [00680, 01251], lr: 0.001186, loss: 0.4013
2022-09-22 21:56:46 - train: epoch 0065, iter [00690, 01251], lr: 0.001186, loss: 0.3998
2022-09-22 21:57:07 - train: epoch 0065, iter [00700, 01251], lr: 0.001186, loss: 0.4240
2022-09-22 21:57:28 - train: epoch 0065, iter [00710, 01251], lr: 0.001186, loss: 0.4199
2022-09-22 21:57:48 - train: epoch 0065, iter [00720, 01251], lr: 0.001186, loss: 0.4094
2022-09-22 21:58:09 - train: epoch 0065, iter [00730, 01251], lr: 0.001186, loss: 0.4076
2022-09-22 21:58:30 - train: epoch 0065, iter [00740, 01251], lr: 0.001186, loss: 0.4013
2022-09-22 21:58:50 - train: epoch 0065, iter [00750, 01251], lr: 0.001186, loss: 0.3957
2022-09-22 21:59:11 - train: epoch 0065, iter [00760, 01251], lr: 0.001186, loss: 0.4125
2022-09-22 21:59:32 - train: epoch 0065, iter [00770, 01251], lr: 0.001186, loss: 0.4029
2022-09-22 21:59:52 - train: epoch 0065, iter [00780, 01251], lr: 0.001186, loss: 0.4312
2022-09-22 22:00:13 - train: epoch 0065, iter [00790, 01251], lr: 0.001186, loss: 0.4144
2022-09-22 22:00:34 - train: epoch 0065, iter [00800, 01251], lr: 0.001186, loss: 0.4242
2022-09-22 22:00:54 - train: epoch 0065, iter [00810, 01251], lr: 0.001186, loss: 0.4247
2022-09-22 22:01:15 - train: epoch 0065, iter [00820, 01251], lr: 0.001186, loss: 0.4045
2022-09-22 22:01:35 - train: epoch 0065, iter [00830, 01251], lr: 0.001186, loss: 0.4057
2022-09-22 22:01:56 - train: epoch 0065, iter [00840, 01251], lr: 0.001186, loss: 0.3996
2022-09-22 22:02:17 - train: epoch 0065, iter [00850, 01251], lr: 0.001186, loss: 0.3977
2022-09-22 22:02:37 - train: epoch 0065, iter [00860, 01251], lr: 0.001186, loss: 0.4253
2022-09-22 22:02:58 - train: epoch 0065, iter [00870, 01251], lr: 0.001186, loss: 0.4141
2022-09-22 22:03:19 - train: epoch 0065, iter [00880, 01251], lr: 0.001186, loss: 0.4276
2022-09-22 22:03:39 - train: epoch 0065, iter [00890, 01251], lr: 0.001186, loss: 0.4093
2022-09-22 22:04:00 - train: epoch 0065, iter [00900, 01251], lr: 0.001186, loss: 0.4194
2022-09-22 22:04:21 - train: epoch 0065, iter [00910, 01251], lr: 0.001186, loss: 0.4098
2022-09-22 22:04:42 - train: epoch 0065, iter [00920, 01251], lr: 0.001186, loss: 0.4007
2022-09-22 22:05:02 - train: epoch 0065, iter [00930, 01251], lr: 0.001186, loss: 0.4315
2022-09-22 22:05:23 - train: epoch 0065, iter [00940, 01251], lr: 0.001186, loss: 0.4241
2022-09-22 22:05:44 - train: epoch 0065, iter [00950, 01251], lr: 0.001186, loss: 0.4123
2022-09-22 22:06:05 - train: epoch 0065, iter [00960, 01251], lr: 0.001186, loss: 0.4206
2022-09-22 22:06:25 - train: epoch 0065, iter [00970, 01251], lr: 0.001186, loss: 0.4179
2022-09-22 22:06:46 - train: epoch 0065, iter [00980, 01251], lr: 0.001186, loss: 0.4275
2022-09-22 22:07:06 - train: epoch 0065, iter [00990, 01251], lr: 0.001186, loss: 0.4129
2022-09-22 22:07:27 - train: epoch 0065, iter [01000, 01251], lr: 0.001186, loss: 0.4346
2022-09-22 22:07:48 - train: epoch 0065, iter [01010, 01251], lr: 0.001186, loss: 0.4235
2022-09-22 22:08:09 - train: epoch 0065, iter [01020, 01251], lr: 0.001186, loss: 0.4152
2022-09-22 22:08:29 - train: epoch 0065, iter [01030, 01251], lr: 0.001186, loss: 0.4152
2022-09-22 22:08:50 - train: epoch 0065, iter [01040, 01251], lr: 0.001186, loss: 0.4105
2022-09-22 22:09:11 - train: epoch 0065, iter [01050, 01251], lr: 0.001186, loss: 0.4210
2022-09-22 22:09:31 - train: epoch 0065, iter [01060, 01251], lr: 0.001186, loss: 0.4107
2022-09-22 22:09:52 - train: epoch 0065, iter [01070, 01251], lr: 0.001186, loss: 0.4035
2022-09-22 22:10:13 - train: epoch 0065, iter [01080, 01251], lr: 0.001186, loss: 0.4150
2022-09-22 22:10:34 - train: epoch 0065, iter [01090, 01251], lr: 0.001186, loss: 0.3994
2022-09-22 22:10:55 - train: epoch 0065, iter [01100, 01251], lr: 0.001186, loss: 0.4058
2022-09-22 22:11:15 - train: epoch 0065, iter [01110, 01251], lr: 0.001186, loss: 0.4084
2022-09-22 22:11:36 - train: epoch 0065, iter [01120, 01251], lr: 0.001186, loss: 0.4294
2022-09-22 22:11:57 - train: epoch 0065, iter [01130, 01251], lr: 0.001186, loss: 0.4017
2022-09-22 22:12:18 - train: epoch 0065, iter [01140, 01251], lr: 0.001186, loss: 0.4056
2022-09-22 22:12:38 - train: epoch 0065, iter [01150, 01251], lr: 0.001186, loss: 0.4140
2022-09-22 22:12:59 - train: epoch 0065, iter [01160, 01251], lr: 0.001186, loss: 0.4175
2022-09-22 22:13:20 - train: epoch 0065, iter [01170, 01251], lr: 0.001186, loss: 0.4007
2022-09-22 22:13:41 - train: epoch 0065, iter [01180, 01251], lr: 0.001186, loss: 0.4093
2022-09-22 22:14:02 - train: epoch 0065, iter [01190, 01251], lr: 0.001186, loss: 0.4214
2022-09-22 22:14:22 - train: epoch 0065, iter [01200, 01251], lr: 0.001186, loss: 0.4289
2022-09-22 22:14:43 - train: epoch 0065, iter [01210, 01251], lr: 0.001186, loss: 0.4133
2022-09-22 22:15:04 - train: epoch 0065, iter [01220, 01251], lr: 0.001186, loss: 0.4078
2022-09-22 22:15:25 - train: epoch 0065, iter [01230, 01251], lr: 0.001186, loss: 0.4209
2022-09-22 22:15:45 - train: epoch 0065, iter [01240, 01251], lr: 0.001186, loss: 0.4351
2022-09-22 22:16:05 - train: epoch 0065, iter [01250, 01251], lr: 0.001186, loss: 0.4175
2022-09-22 22:16:10 - train: epoch 065, train_loss: 0.4161
2022-09-22 22:16:13 - until epoch: 065, best_loss: 0.4161
2022-09-22 22:16:13 - epoch 066 lr: 0.001186
2022-09-22 22:16:51 - train: epoch 0066, iter [00010, 01251], lr: 0.001186, loss: 0.4028
2022-09-22 22:17:11 - train: epoch 0066, iter [00020, 01251], lr: 0.001186, loss: 0.4012
2022-09-22 22:17:32 - train: epoch 0066, iter [00030, 01251], lr: 0.001186, loss: 0.4175
2022-09-22 22:17:53 - train: epoch 0066, iter [00040, 01251], lr: 0.001186, loss: 0.4214
2022-09-22 22:18:13 - train: epoch 0066, iter [00050, 01251], lr: 0.001186, loss: 0.4142
2022-09-22 22:18:34 - train: epoch 0066, iter [00060, 01251], lr: 0.001186, loss: 0.4051
2022-09-22 22:18:54 - train: epoch 0066, iter [00070, 01251], lr: 0.001186, loss: 0.4154
2022-09-22 22:19:15 - train: epoch 0066, iter [00080, 01251], lr: 0.001186, loss: 0.3955
2022-09-22 22:19:36 - train: epoch 0066, iter [00090, 01251], lr: 0.001186, loss: 0.4190
2022-09-22 22:19:57 - train: epoch 0066, iter [00100, 01251], lr: 0.001186, loss: 0.3997
2022-09-22 22:20:17 - train: epoch 0066, iter [00110, 01251], lr: 0.001186, loss: 0.4355
2022-09-22 22:20:38 - train: epoch 0066, iter [00120, 01251], lr: 0.001186, loss: 0.4292
2022-09-22 22:20:59 - train: epoch 0066, iter [00130, 01251], lr: 0.001186, loss: 0.4118
2022-09-22 22:21:20 - train: epoch 0066, iter [00140, 01251], lr: 0.001186, loss: 0.3946
2022-09-22 22:21:40 - train: epoch 0066, iter [00150, 01251], lr: 0.001186, loss: 0.4122
2022-09-22 22:22:01 - train: epoch 0066, iter [00160, 01251], lr: 0.001186, loss: 0.4067
2022-09-22 22:22:22 - train: epoch 0066, iter [00170, 01251], lr: 0.001186, loss: 0.4194
2022-09-22 22:22:42 - train: epoch 0066, iter [00180, 01251], lr: 0.001186, loss: 0.4246
2022-09-22 22:23:03 - train: epoch 0066, iter [00190, 01251], lr: 0.001186, loss: 0.4209
2022-09-22 22:23:24 - train: epoch 0066, iter [00200, 01251], lr: 0.001186, loss: 0.4105
2022-09-22 22:23:44 - train: epoch 0066, iter [00210, 01251], lr: 0.001186, loss: 0.4185
2022-09-22 22:24:05 - train: epoch 0066, iter [00220, 01251], lr: 0.001186, loss: 0.4181
2022-09-22 22:24:26 - train: epoch 0066, iter [00230, 01251], lr: 0.001186, loss: 0.4003
2022-09-22 22:24:47 - train: epoch 0066, iter [00240, 01251], lr: 0.001186, loss: 0.4260
2022-09-22 22:25:07 - train: epoch 0066, iter [00250, 01251], lr: 0.001186, loss: 0.4202
2022-09-22 22:25:28 - train: epoch 0066, iter [00260, 01251], lr: 0.001186, loss: 0.4113
2022-09-22 22:25:49 - train: epoch 0066, iter [00270, 01251], lr: 0.001186, loss: 0.4026
2022-09-22 22:26:09 - train: epoch 0066, iter [00280, 01251], lr: 0.001186, loss: 0.4079
2022-09-22 22:26:30 - train: epoch 0066, iter [00290, 01251], lr: 0.001186, loss: 0.4044
2022-09-22 22:26:51 - train: epoch 0066, iter [00300, 01251], lr: 0.001186, loss: 0.4248
2022-09-22 22:27:12 - train: epoch 0066, iter [00310, 01251], lr: 0.001185, loss: 0.4136
2022-09-22 22:27:32 - train: epoch 0066, iter [00320, 01251], lr: 0.001185, loss: 0.4271
2022-09-22 22:27:53 - train: epoch 0066, iter [00330, 01251], lr: 0.001185, loss: 0.4130
2022-09-22 22:28:14 - train: epoch 0066, iter [00340, 01251], lr: 0.001185, loss: 0.4096
2022-09-22 22:28:34 - train: epoch 0066, iter [00350, 01251], lr: 0.001185, loss: 0.4164
2022-09-22 22:28:55 - train: epoch 0066, iter [00360, 01251], lr: 0.001185, loss: 0.4157
2022-09-22 22:29:16 - train: epoch 0066, iter [00370, 01251], lr: 0.001185, loss: 0.3969
2022-09-22 22:29:37 - train: epoch 0066, iter [00380, 01251], lr: 0.001185, loss: 0.4226
2022-09-22 22:29:57 - train: epoch 0066, iter [00390, 01251], lr: 0.001185, loss: 0.4185
2022-09-22 22:30:18 - train: epoch 0066, iter [00400, 01251], lr: 0.001185, loss: 0.4168
2022-09-22 22:30:39 - train: epoch 0066, iter [00410, 01251], lr: 0.001185, loss: 0.4241
2022-09-22 22:30:59 - train: epoch 0066, iter [00420, 01251], lr: 0.001185, loss: 0.4077
2022-09-22 22:31:20 - train: epoch 0066, iter [00430, 01251], lr: 0.001185, loss: 0.3911
2022-09-22 22:31:41 - train: epoch 0066, iter [00440, 01251], lr: 0.001185, loss: 0.4192
2022-09-22 22:32:02 - train: epoch 0066, iter [00450, 01251], lr: 0.001185, loss: 0.4289
2022-09-22 22:32:22 - train: epoch 0066, iter [00460, 01251], lr: 0.001185, loss: 0.4407
2022-09-22 22:32:43 - train: epoch 0066, iter [00470, 01251], lr: 0.001185, loss: 0.4277
2022-09-22 22:33:04 - train: epoch 0066, iter [00480, 01251], lr: 0.001185, loss: 0.4076
2022-09-22 22:33:25 - train: epoch 0066, iter [00490, 01251], lr: 0.001185, loss: 0.3985
2022-09-22 22:33:45 - train: epoch 0066, iter [00500, 01251], lr: 0.001185, loss: 0.4133
2022-09-22 22:34:06 - train: epoch 0066, iter [00510, 01251], lr: 0.001185, loss: 0.4084
2022-09-22 22:34:26 - train: epoch 0066, iter [00520, 01251], lr: 0.001185, loss: 0.4338
2022-09-22 22:34:47 - train: epoch 0066, iter [00530, 01251], lr: 0.001185, loss: 0.4211
2022-09-22 22:35:08 - train: epoch 0066, iter [00540, 01251], lr: 0.001185, loss: 0.4271
2022-09-22 22:35:29 - train: epoch 0066, iter [00550, 01251], lr: 0.001185, loss: 0.4275
2022-09-22 22:35:50 - train: epoch 0066, iter [00560, 01251], lr: 0.001185, loss: 0.3985
2022-09-22 22:36:11 - train: epoch 0066, iter [00570, 01251], lr: 0.001185, loss: 0.4163
2022-09-22 22:36:32 - train: epoch 0066, iter [00580, 01251], lr: 0.001185, loss: 0.3995
2022-09-22 22:36:53 - train: epoch 0066, iter [00590, 01251], lr: 0.001185, loss: 0.4224
2022-09-22 22:37:14 - train: epoch 0066, iter [00600, 01251], lr: 0.001185, loss: 0.4046
2022-09-22 22:37:35 - train: epoch 0066, iter [00610, 01251], lr: 0.001185, loss: 0.4085
2022-09-22 22:37:56 - train: epoch 0066, iter [00620, 01251], lr: 0.001185, loss: 0.4180
2022-09-22 22:38:17 - train: epoch 0066, iter [00630, 01251], lr: 0.001185, loss: 0.4172
2022-09-22 22:38:38 - train: epoch 0066, iter [00640, 01251], lr: 0.001185, loss: 0.4110
2022-09-22 22:38:59 - train: epoch 0066, iter [00650, 01251], lr: 0.001185, loss: 0.4018
2022-09-22 22:39:20 - train: epoch 0066, iter [00660, 01251], lr: 0.001185, loss: 0.3961
2022-09-22 22:39:40 - train: epoch 0066, iter [00670, 01251], lr: 0.001185, loss: 0.4272
2022-09-22 22:40:01 - train: epoch 0066, iter [00680, 01251], lr: 0.001185, loss: 0.4031
2022-09-22 22:40:22 - train: epoch 0066, iter [00690, 01251], lr: 0.001185, loss: 0.4228
2022-09-22 22:40:43 - train: epoch 0066, iter [00700, 01251], lr: 0.001185, loss: 0.4293
2022-09-22 22:41:04 - train: epoch 0066, iter [00710, 01251], lr: 0.001185, loss: 0.3969
2022-09-22 22:41:25 - train: epoch 0066, iter [00720, 01251], lr: 0.001185, loss: 0.4116
2022-09-22 22:41:46 - train: epoch 0066, iter [00730, 01251], lr: 0.001185, loss: 0.4267
2022-09-22 22:42:07 - train: epoch 0066, iter [00740, 01251], lr: 0.001185, loss: 0.4150
2022-09-22 22:42:27 - train: epoch 0066, iter [00750, 01251], lr: 0.001185, loss: 0.4265
2022-09-22 22:42:49 - train: epoch 0066, iter [00760, 01251], lr: 0.001185, loss: 0.3924
2022-09-22 22:43:10 - train: epoch 0066, iter [00770, 01251], lr: 0.001185, loss: 0.4061
2022-09-22 22:43:31 - train: epoch 0066, iter [00780, 01251], lr: 0.001185, loss: 0.4313
2022-09-22 22:43:52 - train: epoch 0066, iter [00790, 01251], lr: 0.001185, loss: 0.4201
2022-09-22 22:44:12 - train: epoch 0066, iter [00800, 01251], lr: 0.001185, loss: 0.4014
2022-09-22 22:44:34 - train: epoch 0066, iter [00810, 01251], lr: 0.001185, loss: 0.4221
2022-09-22 22:44:55 - train: epoch 0066, iter [00820, 01251], lr: 0.001185, loss: 0.4381
2022-09-22 22:45:16 - train: epoch 0066, iter [00830, 01251], lr: 0.001185, loss: 0.4089
2022-09-22 22:45:37 - train: epoch 0066, iter [00840, 01251], lr: 0.001185, loss: 0.4147
2022-09-22 22:45:58 - train: epoch 0066, iter [00850, 01251], lr: 0.001185, loss: 0.4190
2022-09-22 22:46:19 - train: epoch 0066, iter [00860, 01251], lr: 0.001185, loss: 0.4022
2022-09-22 22:46:40 - train: epoch 0066, iter [00870, 01251], lr: 0.001185, loss: 0.4244
2022-09-22 22:47:01 - train: epoch 0066, iter [00880, 01251], lr: 0.001185, loss: 0.4160
2022-09-22 22:47:22 - train: epoch 0066, iter [00890, 01251], lr: 0.001185, loss: 0.4170
2022-09-22 22:47:43 - train: epoch 0066, iter [00900, 01251], lr: 0.001185, loss: 0.4172
2022-09-22 22:48:04 - train: epoch 0066, iter [00910, 01251], lr: 0.001185, loss: 0.4044
2022-09-22 22:48:25 - train: epoch 0066, iter [00920, 01251], lr: 0.001185, loss: 0.4063
2022-09-22 22:48:47 - train: epoch 0066, iter [00930, 01251], lr: 0.001185, loss: 0.4327
2022-09-22 22:49:08 - train: epoch 0066, iter [00940, 01251], lr: 0.001185, loss: 0.4236
2022-09-22 22:49:29 - train: epoch 0066, iter [00950, 01251], lr: 0.001185, loss: 0.4235
2022-09-22 22:49:50 - train: epoch 0066, iter [00960, 01251], lr: 0.001185, loss: 0.4000
2022-09-22 22:50:11 - train: epoch 0066, iter [00970, 01251], lr: 0.001185, loss: 0.4080
2022-09-22 22:50:32 - train: epoch 0066, iter [00980, 01251], lr: 0.001185, loss: 0.4078
2022-09-22 22:50:52 - train: epoch 0066, iter [00990, 01251], lr: 0.001185, loss: 0.4273
2022-09-22 22:51:14 - train: epoch 0066, iter [01000, 01251], lr: 0.001185, loss: 0.4024
2022-09-22 22:51:34 - train: epoch 0066, iter [01010, 01251], lr: 0.001185, loss: 0.4262
2022-09-22 22:51:55 - train: epoch 0066, iter [01020, 01251], lr: 0.001185, loss: 0.4225
2022-09-22 22:52:16 - train: epoch 0066, iter [01030, 01251], lr: 0.001185, loss: 0.4023
2022-09-22 22:52:37 - train: epoch 0066, iter [01040, 01251], lr: 0.001185, loss: 0.4185
2022-09-22 22:52:58 - train: epoch 0066, iter [01050, 01251], lr: 0.001185, loss: 0.4102
2022-09-22 22:53:19 - train: epoch 0066, iter [01060, 01251], lr: 0.001185, loss: 0.3988
2022-09-22 22:53:40 - train: epoch 0066, iter [01070, 01251], lr: 0.001185, loss: 0.4125
2022-09-22 22:54:01 - train: epoch 0066, iter [01080, 01251], lr: 0.001185, loss: 0.4219
2022-09-22 22:54:22 - train: epoch 0066, iter [01090, 01251], lr: 0.001185, loss: 0.4325
2022-09-22 22:54:43 - train: epoch 0066, iter [01100, 01251], lr: 0.001185, loss: 0.4189
2022-09-22 22:55:04 - train: epoch 0066, iter [01110, 01251], lr: 0.001185, loss: 0.4293
2022-09-22 22:55:26 - train: epoch 0066, iter [01120, 01251], lr: 0.001185, loss: 0.3927
2022-09-22 22:55:47 - train: epoch 0066, iter [01130, 01251], lr: 0.001185, loss: 0.4262
2022-09-22 22:56:08 - train: epoch 0066, iter [01140, 01251], lr: 0.001185, loss: 0.4268
2022-09-22 22:56:29 - train: epoch 0066, iter [01150, 01251], lr: 0.001185, loss: 0.4267
2022-09-22 22:56:50 - train: epoch 0066, iter [01160, 01251], lr: 0.001185, loss: 0.3946
2022-09-22 22:57:11 - train: epoch 0066, iter [01170, 01251], lr: 0.001185, loss: 0.4303
2022-09-22 22:57:32 - train: epoch 0066, iter [01180, 01251], lr: 0.001185, loss: 0.4231
2022-09-22 22:57:54 - train: epoch 0066, iter [01190, 01251], lr: 0.001185, loss: 0.4128
2022-09-22 22:58:15 - train: epoch 0066, iter [01200, 01251], lr: 0.001185, loss: 0.4035
2022-09-22 22:58:36 - train: epoch 0066, iter [01210, 01251], lr: 0.001185, loss: 0.4204
2022-09-22 22:58:57 - train: epoch 0066, iter [01220, 01251], lr: 0.001185, loss: 0.3953
2022-09-22 22:59:18 - train: epoch 0066, iter [01230, 01251], lr: 0.001185, loss: 0.4177
2022-09-22 22:59:38 - train: epoch 0066, iter [01240, 01251], lr: 0.001185, loss: 0.4364
2022-09-22 22:59:59 - train: epoch 0066, iter [01250, 01251], lr: 0.001185, loss: 0.4221
2022-09-22 23:00:03 - train: epoch 066, train_loss: 0.4160
2022-09-22 23:00:07 - until epoch: 066, best_loss: 0.4160
2022-09-25 13:41:07 - epoch 067 lr: 0.001185
2022-09-25 13:41:41 - train: epoch 0067, iter [00010, 01251], lr: 0.001185, loss: 0.4011
2022-09-25 13:41:59 - train: epoch 0067, iter [00020, 01251], lr: 0.001185, loss: 0.4162
2022-09-25 13:42:17 - train: epoch 0067, iter [00030, 01251], lr: 0.001185, loss: 0.3999
2022-09-25 13:42:35 - train: epoch 0067, iter [00040, 01251], lr: 0.001185, loss: 0.4020
2022-09-25 13:42:52 - train: epoch 0067, iter [00050, 01251], lr: 0.001185, loss: 0.4226
2022-09-25 13:43:10 - train: epoch 0067, iter [00060, 01251], lr: 0.001185, loss: 0.4210
2022-09-25 13:43:27 - train: epoch 0067, iter [00070, 01251], lr: 0.001185, loss: 0.4185
2022-09-25 13:43:45 - train: epoch 0067, iter [00080, 01251], lr: 0.001185, loss: 0.4153
2022-09-25 13:44:03 - train: epoch 0067, iter [00090, 01251], lr: 0.001185, loss: 0.4073
2022-09-25 13:44:21 - train: epoch 0067, iter [00100, 01251], lr: 0.001185, loss: 0.4067
2022-09-25 13:44:38 - train: epoch 0067, iter [00110, 01251], lr: 0.001185, loss: 0.4140
2022-09-25 13:44:56 - train: epoch 0067, iter [00120, 01251], lr: 0.001185, loss: 0.3930
2022-09-25 13:45:13 - train: epoch 0067, iter [00130, 01251], lr: 0.001184, loss: 0.4234
2022-09-25 13:45:31 - train: epoch 0067, iter [00140, 01251], lr: 0.001184, loss: 0.4356
2022-09-25 13:45:49 - train: epoch 0067, iter [00150, 01251], lr: 0.001184, loss: 0.4208
2022-09-25 13:46:06 - train: epoch 0067, iter [00160, 01251], lr: 0.001184, loss: 0.4174
2022-09-25 13:46:24 - train: epoch 0067, iter [00170, 01251], lr: 0.001184, loss: 0.3957
2022-09-25 13:46:42 - train: epoch 0067, iter [00180, 01251], lr: 0.001184, loss: 0.4079
2022-09-25 13:46:59 - train: epoch 0067, iter [00190, 01251], lr: 0.001184, loss: 0.4120
2022-09-25 13:47:17 - train: epoch 0067, iter [00200, 01251], lr: 0.001184, loss: 0.4158
2022-09-25 13:47:35 - train: epoch 0067, iter [00210, 01251], lr: 0.001184, loss: 0.4171
2022-09-25 13:47:52 - train: epoch 0067, iter [00220, 01251], lr: 0.001184, loss: 0.4021
2022-09-25 13:48:10 - train: epoch 0067, iter [00230, 01251], lr: 0.001184, loss: 0.4229
2022-09-25 13:48:28 - train: epoch 0067, iter [00240, 01251], lr: 0.001184, loss: 0.4010
2022-09-25 13:48:45 - train: epoch 0067, iter [00250, 01251], lr: 0.001184, loss: 0.4002
2022-09-25 13:49:03 - train: epoch 0067, iter [00260, 01251], lr: 0.001184, loss: 0.4131
2022-09-25 13:49:21 - train: epoch 0067, iter [00270, 01251], lr: 0.001184, loss: 0.4128
2022-09-25 13:49:39 - train: epoch 0067, iter [00280, 01251], lr: 0.001184, loss: 0.4224
2022-09-25 13:49:57 - train: epoch 0067, iter [00290, 01251], lr: 0.001184, loss: 0.4236
2022-09-25 13:50:15 - train: epoch 0067, iter [00300, 01251], lr: 0.001184, loss: 0.4343
2022-09-25 13:50:32 - train: epoch 0067, iter [00310, 01251], lr: 0.001184, loss: 0.4150
2022-09-25 13:50:50 - train: epoch 0067, iter [00320, 01251], lr: 0.001184, loss: 0.4115
2022-09-25 13:51:08 - train: epoch 0067, iter [00330, 01251], lr: 0.001184, loss: 0.4341
2022-09-25 13:51:26 - train: epoch 0067, iter [00340, 01251], lr: 0.001184, loss: 0.4172
2022-09-25 13:51:44 - train: epoch 0067, iter [00350, 01251], lr: 0.001184, loss: 0.4131
2022-09-25 13:52:02 - train: epoch 0067, iter [00360, 01251], lr: 0.001184, loss: 0.4205
2022-09-25 13:52:19 - train: epoch 0067, iter [00370, 01251], lr: 0.001184, loss: 0.4121
2022-09-25 13:52:37 - train: epoch 0067, iter [00380, 01251], lr: 0.001184, loss: 0.4118
2022-09-25 13:52:55 - train: epoch 0067, iter [00390, 01251], lr: 0.001184, loss: 0.4057
2022-09-25 13:53:12 - train: epoch 0067, iter [00400, 01251], lr: 0.001184, loss: 0.4291
2022-09-25 13:53:29 - train: epoch 0067, iter [00410, 01251], lr: 0.001184, loss: 0.4162
2022-09-25 13:53:47 - train: epoch 0067, iter [00420, 01251], lr: 0.001184, loss: 0.4316
2022-09-25 13:54:04 - train: epoch 0067, iter [00430, 01251], lr: 0.001184, loss: 0.4236
2022-09-25 13:54:22 - train: epoch 0067, iter [00440, 01251], lr: 0.001184, loss: 0.4306
2022-09-25 13:54:39 - train: epoch 0067, iter [00450, 01251], lr: 0.001184, loss: 0.4281
2022-09-25 13:54:56 - train: epoch 0067, iter [00460, 01251], lr: 0.001184, loss: 0.4198
2022-09-25 13:55:13 - train: epoch 0067, iter [00470, 01251], lr: 0.001184, loss: 0.3967
2022-09-25 13:55:31 - train: epoch 0067, iter [00480, 01251], lr: 0.001184, loss: 0.4127
2022-09-25 13:55:48 - train: epoch 0067, iter [00490, 01251], lr: 0.001184, loss: 0.4183
2022-09-25 13:56:06 - train: epoch 0067, iter [00500, 01251], lr: 0.001184, loss: 0.4218
2022-09-25 13:56:23 - train: epoch 0067, iter [00510, 01251], lr: 0.001184, loss: 0.4125
2022-09-25 13:56:41 - train: epoch 0067, iter [00520, 01251], lr: 0.001184, loss: 0.4273
2022-09-25 13:56:59 - train: epoch 0067, iter [00530, 01251], lr: 0.001184, loss: 0.4120
2022-09-25 13:57:16 - train: epoch 0067, iter [00540, 01251], lr: 0.001184, loss: 0.3984
2022-09-25 13:57:34 - train: epoch 0067, iter [00550, 01251], lr: 0.001184, loss: 0.4317
2022-09-25 13:57:52 - train: epoch 0067, iter [00560, 01251], lr: 0.001184, loss: 0.4002
2022-09-25 13:58:09 - train: epoch 0067, iter [00570, 01251], lr: 0.001184, loss: 0.4011
2022-09-25 13:58:27 - train: epoch 0067, iter [00580, 01251], lr: 0.001184, loss: 0.4206
2022-09-25 13:58:45 - train: epoch 0067, iter [00590, 01251], lr: 0.001184, loss: 0.4208
2022-09-25 13:59:02 - train: epoch 0067, iter [00600, 01251], lr: 0.001184, loss: 0.4249
2022-09-25 13:59:20 - train: epoch 0067, iter [00610, 01251], lr: 0.001184, loss: 0.4141
2022-09-25 13:59:37 - train: epoch 0067, iter [00620, 01251], lr: 0.001184, loss: 0.4201
2022-09-25 13:59:55 - train: epoch 0067, iter [00630, 01251], lr: 0.001184, loss: 0.4201
2022-09-25 14:00:12 - train: epoch 0067, iter [00640, 01251], lr: 0.001184, loss: 0.4124
2022-09-25 14:00:30 - train: epoch 0067, iter [00650, 01251], lr: 0.001184, loss: 0.3919
2022-09-25 14:00:47 - train: epoch 0067, iter [00660, 01251], lr: 0.001184, loss: 0.4278
2022-09-25 14:01:05 - train: epoch 0067, iter [00670, 01251], lr: 0.001184, loss: 0.4434
2022-09-25 14:01:22 - train: epoch 0067, iter [00680, 01251], lr: 0.001184, loss: 0.4146
2022-09-25 14:01:40 - train: epoch 0067, iter [00690, 01251], lr: 0.001184, loss: 0.4178
2022-09-25 14:01:57 - train: epoch 0067, iter [00700, 01251], lr: 0.001184, loss: 0.4213
2022-09-25 14:02:15 - train: epoch 0067, iter [00710, 01251], lr: 0.001184, loss: 0.4103
2022-09-25 14:02:33 - train: epoch 0067, iter [00720, 01251], lr: 0.001184, loss: 0.4191
2022-09-25 14:02:50 - train: epoch 0067, iter [00730, 01251], lr: 0.001184, loss: 0.4195
2022-09-25 14:03:08 - train: epoch 0067, iter [00740, 01251], lr: 0.001184, loss: 0.4226
2022-09-25 14:03:26 - train: epoch 0067, iter [00750, 01251], lr: 0.001184, loss: 0.4309
2022-09-25 14:03:44 - train: epoch 0067, iter [00760, 01251], lr: 0.001184, loss: 0.4211
2022-09-25 14:04:01 - train: epoch 0067, iter [00770, 01251], lr: 0.001184, loss: 0.4026
2022-09-25 14:04:19 - train: epoch 0067, iter [00780, 01251], lr: 0.001184, loss: 0.4220
2022-09-25 14:04:36 - train: epoch 0067, iter [00790, 01251], lr: 0.001184, loss: 0.4028
2022-09-25 14:04:54 - train: epoch 0067, iter [00800, 01251], lr: 0.001184, loss: 0.4320
2022-09-25 14:05:11 - train: epoch 0067, iter [00810, 01251], lr: 0.001184, loss: 0.4007
2022-09-25 14:05:29 - train: epoch 0067, iter [00820, 01251], lr: 0.001184, loss: 0.3952
2022-09-25 14:05:46 - train: epoch 0067, iter [00830, 01251], lr: 0.001184, loss: 0.4406
2022-09-25 14:06:04 - train: epoch 0067, iter [00840, 01251], lr: 0.001184, loss: 0.4194
2022-09-25 14:06:21 - train: epoch 0067, iter [00850, 01251], lr: 0.001184, loss: 0.4234
2022-09-25 14:06:39 - train: epoch 0067, iter [00860, 01251], lr: 0.001184, loss: 0.4132
2022-09-25 14:06:56 - train: epoch 0067, iter [00870, 01251], lr: 0.001184, loss: 0.4045
2022-09-25 14:07:14 - train: epoch 0067, iter [00880, 01251], lr: 0.001184, loss: 0.4137
2022-09-25 14:07:31 - train: epoch 0067, iter [00890, 01251], lr: 0.001184, loss: 0.4086
2022-09-25 14:07:49 - train: epoch 0067, iter [00900, 01251], lr: 0.001184, loss: 0.4186
2022-09-25 14:08:06 - train: epoch 0067, iter [00910, 01251], lr: 0.001184, loss: 0.4228
2022-09-25 14:08:24 - train: epoch 0067, iter [00920, 01251], lr: 0.001184, loss: 0.4050
2022-09-25 14:08:41 - train: epoch 0067, iter [00930, 01251], lr: 0.001184, loss: 0.4285
2022-09-25 14:08:59 - train: epoch 0067, iter [00940, 01251], lr: 0.001184, loss: 0.4306
2022-09-25 14:09:16 - train: epoch 0067, iter [00950, 01251], lr: 0.001184, loss: 0.4020
2022-09-25 14:09:34 - train: epoch 0067, iter [00960, 01251], lr: 0.001184, loss: 0.3984
2022-09-25 14:09:51 - train: epoch 0067, iter [00970, 01251], lr: 0.001184, loss: 0.4387
2022-09-25 14:10:08 - train: epoch 0067, iter [00980, 01251], lr: 0.001184, loss: 0.4299
2022-09-25 14:10:26 - train: epoch 0067, iter [00990, 01251], lr: 0.001184, loss: 0.4119
2022-09-25 14:10:43 - train: epoch 0067, iter [01000, 01251], lr: 0.001184, loss: 0.4118
2022-09-25 14:11:01 - train: epoch 0067, iter [01010, 01251], lr: 0.001184, loss: 0.4252
2022-09-25 14:11:18 - train: epoch 0067, iter [01020, 01251], lr: 0.001184, loss: 0.4008
2022-09-25 14:11:36 - train: epoch 0067, iter [01030, 01251], lr: 0.001184, loss: 0.4136
2022-09-25 14:11:53 - train: epoch 0067, iter [01040, 01251], lr: 0.001184, loss: 0.4154
2022-09-25 14:12:10 - train: epoch 0067, iter [01050, 01251], lr: 0.001184, loss: 0.4371
2022-09-25 14:12:28 - train: epoch 0067, iter [01060, 01251], lr: 0.001184, loss: 0.4365
2022-09-25 14:12:45 - train: epoch 0067, iter [01070, 01251], lr: 0.001184, loss: 0.4031
2022-09-25 14:13:02 - train: epoch 0067, iter [01080, 01251], lr: 0.001184, loss: 0.4360
2022-09-25 14:13:20 - train: epoch 0067, iter [01090, 01251], lr: 0.001184, loss: 0.4168
2022-09-25 14:13:37 - train: epoch 0067, iter [01100, 01251], lr: 0.001184, loss: 0.3951
2022-09-25 14:13:54 - train: epoch 0067, iter [01110, 01251], lr: 0.001184, loss: 0.4085
2022-09-25 14:14:12 - train: epoch 0067, iter [01120, 01251], lr: 0.001184, loss: 0.4147
2022-09-25 14:14:29 - train: epoch 0067, iter [01130, 01251], lr: 0.001184, loss: 0.3985
2022-09-25 14:14:47 - train: epoch 0067, iter [01140, 01251], lr: 0.001184, loss: 0.4114
2022-09-25 14:15:04 - train: epoch 0067, iter [01150, 01251], lr: 0.001184, loss: 0.4210
2022-09-25 14:15:21 - train: epoch 0067, iter [01160, 01251], lr: 0.001184, loss: 0.4313
2022-09-25 14:15:39 - train: epoch 0067, iter [01170, 01251], lr: 0.001184, loss: 0.3994
2022-09-25 14:15:56 - train: epoch 0067, iter [01180, 01251], lr: 0.001183, loss: 0.4108
2022-09-25 14:16:13 - train: epoch 0067, iter [01190, 01251], lr: 0.001183, loss: 0.4199
2022-09-25 14:16:31 - train: epoch 0067, iter [01200, 01251], lr: 0.001183, loss: 0.4073
2022-09-25 14:16:48 - train: epoch 0067, iter [01210, 01251], lr: 0.001183, loss: 0.4271
2022-09-25 14:17:05 - train: epoch 0067, iter [01220, 01251], lr: 0.001183, loss: 0.4222
2022-09-25 14:17:22 - train: epoch 0067, iter [01230, 01251], lr: 0.001183, loss: 0.4271
2022-09-25 14:17:40 - train: epoch 0067, iter [01240, 01251], lr: 0.001183, loss: 0.4238
2022-09-25 14:17:56 - train: epoch 0067, iter [01250, 01251], lr: 0.001183, loss: 0.4324
2022-09-25 14:18:02 - train: epoch 067, train_loss: 0.4159
2022-09-25 14:18:07 - until epoch: 067, best_loss: 0.4159
2022-09-25 14:18:07 - epoch 068 lr: 0.001183
2022-09-25 14:18:38 - train: epoch 0068, iter [00010, 01251], lr: 0.001183, loss: 0.4229
2022-09-25 14:18:55 - train: epoch 0068, iter [00020, 01251], lr: 0.001183, loss: 0.4294
2022-09-25 14:19:13 - train: epoch 0068, iter [00030, 01251], lr: 0.001183, loss: 0.4326
2022-09-25 14:19:30 - train: epoch 0068, iter [00040, 01251], lr: 0.001183, loss: 0.4008
2022-09-25 14:19:47 - train: epoch 0068, iter [00050, 01251], lr: 0.001183, loss: 0.4178
2022-09-25 14:20:04 - train: epoch 0068, iter [00060, 01251], lr: 0.001183, loss: 0.4146
2022-09-25 14:20:21 - train: epoch 0068, iter [00070, 01251], lr: 0.001183, loss: 0.4128
2022-09-25 14:20:39 - train: epoch 0068, iter [00080, 01251], lr: 0.001183, loss: 0.4197
2022-09-25 14:20:56 - train: epoch 0068, iter [00090, 01251], lr: 0.001183, loss: 0.4048
2022-09-25 14:21:13 - train: epoch 0068, iter [00100, 01251], lr: 0.001183, loss: 0.4231
2022-09-25 14:21:31 - train: epoch 0068, iter [00110, 01251], lr: 0.001183, loss: 0.4068
2022-09-25 14:21:48 - train: epoch 0068, iter [00120, 01251], lr: 0.001183, loss: 0.4027
2022-09-25 14:22:06 - train: epoch 0068, iter [00130, 01251], lr: 0.001183, loss: 0.4093
2022-09-25 14:22:23 - train: epoch 0068, iter [00140, 01251], lr: 0.001183, loss: 0.4307
2022-09-25 14:22:41 - train: epoch 0068, iter [00150, 01251], lr: 0.001183, loss: 0.4093
2022-09-25 14:22:58 - train: epoch 0068, iter [00160, 01251], lr: 0.001183, loss: 0.4357
2022-09-25 14:23:16 - train: epoch 0068, iter [00170, 01251], lr: 0.001183, loss: 0.4239
2022-09-25 14:23:34 - train: epoch 0068, iter [00180, 01251], lr: 0.001183, loss: 0.4216
2022-09-25 14:23:51 - train: epoch 0068, iter [00190, 01251], lr: 0.001183, loss: 0.4082
2022-09-25 14:24:09 - train: epoch 0068, iter [00200, 01251], lr: 0.001183, loss: 0.4216
2022-09-25 14:24:27 - train: epoch 0068, iter [00210, 01251], lr: 0.001183, loss: 0.4278
2022-09-25 14:24:44 - train: epoch 0068, iter [00220, 01251], lr: 0.001183, loss: 0.4297
2022-09-25 14:25:02 - train: epoch 0068, iter [00230, 01251], lr: 0.001183, loss: 0.4222
2022-09-25 14:25:19 - train: epoch 0068, iter [00240, 01251], lr: 0.001183, loss: 0.4162
2022-09-25 14:25:37 - train: epoch 0068, iter [00250, 01251], lr: 0.001183, loss: 0.4091
2022-09-25 14:25:54 - train: epoch 0068, iter [00260, 01251], lr: 0.001183, loss: 0.4003
2022-09-25 14:26:12 - train: epoch 0068, iter [00270, 01251], lr: 0.001183, loss: 0.4074
2022-09-25 14:26:30 - train: epoch 0068, iter [00280, 01251], lr: 0.001183, loss: 0.4290
2022-09-25 14:26:47 - train: epoch 0068, iter [00290, 01251], lr: 0.001183, loss: 0.4092
2022-09-25 14:27:05 - train: epoch 0068, iter [00300, 01251], lr: 0.001183, loss: 0.4101
2022-09-25 14:27:23 - train: epoch 0068, iter [00310, 01251], lr: 0.001183, loss: 0.4267
2022-09-25 14:27:40 - train: epoch 0068, iter [00320, 01251], lr: 0.001183, loss: 0.4273
2022-09-25 14:27:58 - train: epoch 0068, iter [00330, 01251], lr: 0.001183, loss: 0.4023
2022-09-25 14:28:16 - train: epoch 0068, iter [00340, 01251], lr: 0.001183, loss: 0.4143
2022-09-25 14:28:33 - train: epoch 0068, iter [00350, 01251], lr: 0.001183, loss: 0.4009
2022-09-25 14:28:51 - train: epoch 0068, iter [00360, 01251], lr: 0.001183, loss: 0.4106
2022-09-25 14:29:09 - train: epoch 0068, iter [00370, 01251], lr: 0.001183, loss: 0.4168
2022-09-25 14:29:27 - train: epoch 0068, iter [00380, 01251], lr: 0.001183, loss: 0.4021
2022-09-25 14:29:44 - train: epoch 0068, iter [00390, 01251], lr: 0.001183, loss: 0.4143
2022-09-25 14:30:02 - train: epoch 0068, iter [00400, 01251], lr: 0.001183, loss: 0.4105
2022-09-25 14:30:20 - train: epoch 0068, iter [00410, 01251], lr: 0.001183, loss: 0.4218
2022-09-25 14:30:38 - train: epoch 0068, iter [00420, 01251], lr: 0.001183, loss: 0.4172
2022-09-25 14:30:56 - train: epoch 0068, iter [00430, 01251], lr: 0.001183, loss: 0.4138
2022-09-25 14:31:14 - train: epoch 0068, iter [00440, 01251], lr: 0.001183, loss: 0.4150
2022-09-25 14:31:32 - train: epoch 0068, iter [00450, 01251], lr: 0.001183, loss: 0.4203
2022-09-25 14:31:50 - train: epoch 0068, iter [00460, 01251], lr: 0.001183, loss: 0.3955
2022-09-25 14:32:08 - train: epoch 0068, iter [00470, 01251], lr: 0.001183, loss: 0.4072
2022-09-25 14:32:26 - train: epoch 0068, iter [00480, 01251], lr: 0.001183, loss: 0.3978
2022-09-25 14:32:44 - train: epoch 0068, iter [00490, 01251], lr: 0.001183, loss: 0.4206
2022-09-25 14:33:02 - train: epoch 0068, iter [00500, 01251], lr: 0.001183, loss: 0.3991
2022-09-25 14:33:20 - train: epoch 0068, iter [00510, 01251], lr: 0.001183, loss: 0.4405
2022-09-25 14:33:38 - train: epoch 0068, iter [00520, 01251], lr: 0.001183, loss: 0.4328
2022-09-25 14:33:56 - train: epoch 0068, iter [00530, 01251], lr: 0.001183, loss: 0.4383
2022-09-25 14:34:14 - train: epoch 0068, iter [00540, 01251], lr: 0.001183, loss: 0.4122
2022-09-25 14:34:32 - train: epoch 0068, iter [00550, 01251], lr: 0.001183, loss: 0.4183
2022-09-25 14:34:50 - train: epoch 0068, iter [00560, 01251], lr: 0.001183, loss: 0.4335
2022-09-25 14:35:08 - train: epoch 0068, iter [00570, 01251], lr: 0.001183, loss: 0.3989
2022-09-25 14:35:27 - train: epoch 0068, iter [00580, 01251], lr: 0.001183, loss: 0.4287
2022-09-25 14:35:45 - train: epoch 0068, iter [00590, 01251], lr: 0.001183, loss: 0.4254
2022-09-25 14:36:03 - train: epoch 0068, iter [00600, 01251], lr: 0.001183, loss: 0.3927
2022-09-25 14:36:20 - train: epoch 0068, iter [00610, 01251], lr: 0.001183, loss: 0.4050
2022-09-25 14:36:38 - train: epoch 0068, iter [00620, 01251], lr: 0.001183, loss: 0.4137
2022-09-25 14:36:56 - train: epoch 0068, iter [00630, 01251], lr: 0.001183, loss: 0.4354
2022-09-25 14:37:14 - train: epoch 0068, iter [00640, 01251], lr: 0.001183, loss: 0.4445
2022-09-25 14:37:32 - train: epoch 0068, iter [00650, 01251], lr: 0.001183, loss: 0.4167
2022-09-25 14:37:50 - train: epoch 0068, iter [00660, 01251], lr: 0.001183, loss: 0.4074
2022-09-25 14:38:08 - train: epoch 0068, iter [00670, 01251], lr: 0.001183, loss: 0.4095
2022-09-25 14:38:26 - train: epoch 0068, iter [00680, 01251], lr: 0.001183, loss: 0.4189
2022-09-25 14:38:44 - train: epoch 0068, iter [00690, 01251], lr: 0.001183, loss: 0.4093
2022-09-25 14:39:01 - train: epoch 0068, iter [00700, 01251], lr: 0.001183, loss: 0.4242
2022-09-25 14:39:19 - train: epoch 0068, iter [00710, 01251], lr: 0.001183, loss: 0.4129
2022-09-25 14:39:37 - train: epoch 0068, iter [00720, 01251], lr: 0.001183, loss: 0.3894
2022-09-25 14:39:55 - train: epoch 0068, iter [00730, 01251], lr: 0.001183, loss: 0.4146
2022-09-25 14:40:13 - train: epoch 0068, iter [00740, 01251], lr: 0.001183, loss: 0.4186
2022-09-25 14:40:30 - train: epoch 0068, iter [00750, 01251], lr: 0.001183, loss: 0.3999
2022-09-25 14:40:48 - train: epoch 0068, iter [00760, 01251], lr: 0.001183, loss: 0.4205
2022-09-25 14:41:06 - train: epoch 0068, iter [00770, 01251], lr: 0.001183, loss: 0.4155
2022-09-25 14:41:23 - train: epoch 0068, iter [00780, 01251], lr: 0.001183, loss: 0.4235
2022-09-25 14:41:41 - train: epoch 0068, iter [00790, 01251], lr: 0.001183, loss: 0.4184
2022-09-25 14:41:59 - train: epoch 0068, iter [00800, 01251], lr: 0.001183, loss: 0.4092
2022-09-25 14:42:17 - train: epoch 0068, iter [00810, 01251], lr: 0.001183, loss: 0.4131
2022-09-25 14:42:34 - train: epoch 0068, iter [00820, 01251], lr: 0.001183, loss: 0.4124
2022-09-25 14:42:52 - train: epoch 0068, iter [00830, 01251], lr: 0.001183, loss: 0.4302
2022-09-25 14:43:10 - train: epoch 0068, iter [00840, 01251], lr: 0.001183, loss: 0.4220
2022-09-25 14:43:28 - train: epoch 0068, iter [00850, 01251], lr: 0.001183, loss: 0.4241
2022-09-25 14:43:45 - train: epoch 0068, iter [00860, 01251], lr: 0.001183, loss: 0.3984
2022-09-25 14:44:03 - train: epoch 0068, iter [00870, 01251], lr: 0.001183, loss: 0.3915
2022-09-25 14:44:21 - train: epoch 0068, iter [00880, 01251], lr: 0.001183, loss: 0.4189
2022-09-25 14:44:38 - train: epoch 0068, iter [00890, 01251], lr: 0.001183, loss: 0.4259
2022-09-25 14:44:56 - train: epoch 0068, iter [00900, 01251], lr: 0.001183, loss: 0.4046
2022-09-25 14:45:13 - train: epoch 0068, iter [00910, 01251], lr: 0.001183, loss: 0.4320
2022-09-25 14:45:31 - train: epoch 0068, iter [00920, 01251], lr: 0.001183, loss: 0.4165
2022-09-25 14:45:48 - train: epoch 0068, iter [00930, 01251], lr: 0.001183, loss: 0.4331
2022-09-25 14:46:06 - train: epoch 0068, iter [00940, 01251], lr: 0.001182, loss: 0.4264
2022-09-25 14:46:24 - train: epoch 0068, iter [00950, 01251], lr: 0.001182, loss: 0.4179
2022-09-25 14:46:41 - train: epoch 0068, iter [00960, 01251], lr: 0.001182, loss: 0.4226
2022-09-25 14:46:58 - train: epoch 0068, iter [00970, 01251], lr: 0.001182, loss: 0.4147
2022-09-25 14:47:16 - train: epoch 0068, iter [00980, 01251], lr: 0.001182, loss: 0.4014
2022-09-25 14:47:33 - train: epoch 0068, iter [00990, 01251], lr: 0.001182, loss: 0.4210
2022-09-25 14:47:51 - train: epoch 0068, iter [01000, 01251], lr: 0.001182, loss: 0.4172
2022-09-25 14:48:08 - train: epoch 0068, iter [01010, 01251], lr: 0.001182, loss: 0.4193
2022-09-25 14:48:26 - train: epoch 0068, iter [01020, 01251], lr: 0.001182, loss: 0.4138
2022-09-25 14:48:43 - train: epoch 0068, iter [01030, 01251], lr: 0.001182, loss: 0.4307
2022-09-25 14:49:00 - train: epoch 0068, iter [01040, 01251], lr: 0.001182, loss: 0.4008
2022-09-25 14:49:17 - train: epoch 0068, iter [01050, 01251], lr: 0.001182, loss: 0.4132
2022-09-25 14:49:35 - train: epoch 0068, iter [01060, 01251], lr: 0.001182, loss: 0.4012
2022-09-25 14:49:52 - train: epoch 0068, iter [01070, 01251], lr: 0.001182, loss: 0.4173
2022-09-25 14:50:09 - train: epoch 0068, iter [01080, 01251], lr: 0.001182, loss: 0.4184
2022-09-25 14:50:27 - train: epoch 0068, iter [01090, 01251], lr: 0.001182, loss: 0.4065
2022-09-25 14:50:44 - train: epoch 0068, iter [01100, 01251], lr: 0.001182, loss: 0.4062
2022-09-25 14:51:01 - train: epoch 0068, iter [01110, 01251], lr: 0.001182, loss: 0.4242
2022-09-25 14:51:19 - train: epoch 0068, iter [01120, 01251], lr: 0.001182, loss: 0.4085
2022-09-25 14:51:36 - train: epoch 0068, iter [01130, 01251], lr: 0.001182, loss: 0.4247
2022-09-25 14:51:54 - train: epoch 0068, iter [01140, 01251], lr: 0.001182, loss: 0.4042
2022-09-25 14:52:11 - train: epoch 0068, iter [01150, 01251], lr: 0.001182, loss: 0.4248
2022-09-25 14:52:29 - train: epoch 0068, iter [01160, 01251], lr: 0.001182, loss: 0.4230
2022-09-25 14:52:46 - train: epoch 0068, iter [01170, 01251], lr: 0.001182, loss: 0.4266
2022-09-25 14:53:04 - train: epoch 0068, iter [01180, 01251], lr: 0.001182, loss: 0.4021
2022-09-25 14:53:21 - train: epoch 0068, iter [01190, 01251], lr: 0.001182, loss: 0.4400
2022-09-25 14:53:39 - train: epoch 0068, iter [01200, 01251], lr: 0.001182, loss: 0.4025
2022-09-25 14:53:56 - train: epoch 0068, iter [01210, 01251], lr: 0.001182, loss: 0.4030
2022-09-25 14:54:13 - train: epoch 0068, iter [01220, 01251], lr: 0.001182, loss: 0.4041
2022-09-25 14:54:31 - train: epoch 0068, iter [01230, 01251], lr: 0.001182, loss: 0.4261
2022-09-25 14:54:49 - train: epoch 0068, iter [01240, 01251], lr: 0.001182, loss: 0.4250
2022-09-25 14:55:05 - train: epoch 0068, iter [01250, 01251], lr: 0.001182, loss: 0.4173
2022-09-25 14:55:10 - train: epoch 068, train_loss: 0.4157
2022-09-25 14:55:15 - until epoch: 068, best_loss: 0.4157
2022-09-25 14:55:15 - epoch 069 lr: 0.001182
2022-09-25 14:55:47 - train: epoch 0069, iter [00010, 01251], lr: 0.001182, loss: 0.4085
2022-09-25 14:56:04 - train: epoch 0069, iter [00020, 01251], lr: 0.001182, loss: 0.4171
2022-09-25 14:56:21 - train: epoch 0069, iter [00030, 01251], lr: 0.001182, loss: 0.4111
2022-09-25 14:56:38 - train: epoch 0069, iter [00040, 01251], lr: 0.001182, loss: 0.4190
2022-09-25 14:56:55 - train: epoch 0069, iter [00050, 01251], lr: 0.001182, loss: 0.4058
2022-09-25 14:57:12 - train: epoch 0069, iter [00060, 01251], lr: 0.001182, loss: 0.4181
2022-09-25 14:57:29 - train: epoch 0069, iter [00070, 01251], lr: 0.001182, loss: 0.4156
2022-09-25 14:57:47 - train: epoch 0069, iter [00080, 01251], lr: 0.001182, loss: 0.4082
2022-09-25 14:58:04 - train: epoch 0069, iter [00090, 01251], lr: 0.001182, loss: 0.3956
2022-09-25 14:58:21 - train: epoch 0069, iter [00100, 01251], lr: 0.001182, loss: 0.3993
2022-09-25 14:58:38 - train: epoch 0069, iter [00110, 01251], lr: 0.001182, loss: 0.4279
2022-09-25 14:58:55 - train: epoch 0069, iter [00120, 01251], lr: 0.001182, loss: 0.4275
2022-09-25 14:59:12 - train: epoch 0069, iter [00130, 01251], lr: 0.001182, loss: 0.4088
2022-09-25 14:59:29 - train: epoch 0069, iter [00140, 01251], lr: 0.001182, loss: 0.4220
2022-09-25 14:59:46 - train: epoch 0069, iter [00150, 01251], lr: 0.001182, loss: 0.4228
2022-09-25 15:00:03 - train: epoch 0069, iter [00160, 01251], lr: 0.001182, loss: 0.3963
2022-09-25 15:00:20 - train: epoch 0069, iter [00170, 01251], lr: 0.001182, loss: 0.4250
2022-09-25 15:00:38 - train: epoch 0069, iter [00180, 01251], lr: 0.001182, loss: 0.4248
2022-09-25 15:00:55 - train: epoch 0069, iter [00190, 01251], lr: 0.001182, loss: 0.4124
2022-09-25 15:01:12 - train: epoch 0069, iter [00200, 01251], lr: 0.001182, loss: 0.4091
2022-09-25 15:01:29 - train: epoch 0069, iter [00210, 01251], lr: 0.001182, loss: 0.4097
2022-09-25 15:01:46 - train: epoch 0069, iter [00220, 01251], lr: 0.001182, loss: 0.4013
2022-09-25 15:02:03 - train: epoch 0069, iter [00230, 01251], lr: 0.001182, loss: 0.4014
2022-09-25 15:02:20 - train: epoch 0069, iter [00240, 01251], lr: 0.001182, loss: 0.4280
2022-09-25 15:02:37 - train: epoch 0069, iter [00250, 01251], lr: 0.001182, loss: 0.4289
2022-09-25 15:02:55 - train: epoch 0069, iter [00260, 01251], lr: 0.001182, loss: 0.4288
2022-09-25 15:03:12 - train: epoch 0069, iter [00270, 01251], lr: 0.001182, loss: 0.4126
2022-09-25 15:03:29 - train: epoch 0069, iter [00280, 01251], lr: 0.001182, loss: 0.4259
2022-09-25 15:03:46 - train: epoch 0069, iter [00290, 01251], lr: 0.001182, loss: 0.4167
2022-09-25 15:04:03 - train: epoch 0069, iter [00300, 01251], lr: 0.001182, loss: 0.4223
2022-09-25 15:04:20 - train: epoch 0069, iter [00310, 01251], lr: 0.001182, loss: 0.4289
2022-09-25 15:04:37 - train: epoch 0069, iter [00320, 01251], lr: 0.001182, loss: 0.4437
2022-09-25 15:04:54 - train: epoch 0069, iter [00330, 01251], lr: 0.001182, loss: 0.4158
2022-09-25 15:05:12 - train: epoch 0069, iter [00340, 01251], lr: 0.001182, loss: 0.4219
2022-09-25 15:05:29 - train: epoch 0069, iter [00350, 01251], lr: 0.001182, loss: 0.4132
2022-09-25 15:05:46 - train: epoch 0069, iter [00360, 01251], lr: 0.001182, loss: 0.4209
2022-09-25 15:06:03 - train: epoch 0069, iter [00370, 01251], lr: 0.001182, loss: 0.3970
2022-09-25 15:06:20 - train: epoch 0069, iter [00380, 01251], lr: 0.001182, loss: 0.4128
2022-09-25 15:06:38 - train: epoch 0069, iter [00390, 01251], lr: 0.001182, loss: 0.4086
2022-09-25 15:06:55 - train: epoch 0069, iter [00400, 01251], lr: 0.001182, loss: 0.4131
2022-09-25 15:07:12 - train: epoch 0069, iter [00410, 01251], lr: 0.001182, loss: 0.4144
2022-09-25 15:07:29 - train: epoch 0069, iter [00420, 01251], lr: 0.001182, loss: 0.4223
2022-09-25 15:07:46 - train: epoch 0069, iter [00430, 01251], lr: 0.001182, loss: 0.4076
2022-09-25 15:08:03 - train: epoch 0069, iter [00440, 01251], lr: 0.001182, loss: 0.4059
2022-09-25 15:08:21 - train: epoch 0069, iter [00450, 01251], lr: 0.001182, loss: 0.4093
2022-09-25 15:08:38 - train: epoch 0069, iter [00460, 01251], lr: 0.001182, loss: 0.4306
2022-09-25 15:08:55 - train: epoch 0069, iter [00470, 01251], lr: 0.001182, loss: 0.4086
2022-09-25 15:09:12 - train: epoch 0069, iter [00480, 01251], lr: 0.001182, loss: 0.4326
2022-09-25 15:09:29 - train: epoch 0069, iter [00490, 01251], lr: 0.001182, loss: 0.4310
2022-09-25 15:09:46 - train: epoch 0069, iter [00500, 01251], lr: 0.001182, loss: 0.4138
2022-09-25 15:10:03 - train: epoch 0069, iter [00510, 01251], lr: 0.001182, loss: 0.4236
2022-09-25 15:10:20 - train: epoch 0069, iter [00520, 01251], lr: 0.001182, loss: 0.4058
2022-09-25 15:10:38 - train: epoch 0069, iter [00530, 01251], lr: 0.001182, loss: 0.4450
2022-09-25 15:10:55 - train: epoch 0069, iter [00540, 01251], lr: 0.001182, loss: 0.4209
2022-09-25 15:11:12 - train: epoch 0069, iter [00550, 01251], lr: 0.001182, loss: 0.4373
2022-09-25 15:11:29 - train: epoch 0069, iter [00560, 01251], lr: 0.001182, loss: 0.4110
2022-09-25 15:11:46 - train: epoch 0069, iter [00570, 01251], lr: 0.001182, loss: 0.4209
2022-09-25 15:12:04 - train: epoch 0069, iter [00580, 01251], lr: 0.001182, loss: 0.4252
2022-09-25 15:12:21 - train: epoch 0069, iter [00590, 01251], lr: 0.001182, loss: 0.4224
2022-09-25 15:12:38 - train: epoch 0069, iter [00600, 01251], lr: 0.001182, loss: 0.4001
2022-09-25 15:12:55 - train: epoch 0069, iter [00610, 01251], lr: 0.001182, loss: 0.4262
2022-09-25 15:13:12 - train: epoch 0069, iter [00620, 01251], lr: 0.001182, loss: 0.4273
2022-09-25 15:13:29 - train: epoch 0069, iter [00630, 01251], lr: 0.001182, loss: 0.4186
2022-09-25 15:13:47 - train: epoch 0069, iter [00640, 01251], lr: 0.001182, loss: 0.3982
2022-09-25 15:14:04 - train: epoch 0069, iter [00650, 01251], lr: 0.001182, loss: 0.4254
2022-09-25 15:14:21 - train: epoch 0069, iter [00660, 01251], lr: 0.001182, loss: 0.4186
2022-09-25 15:14:38 - train: epoch 0069, iter [00670, 01251], lr: 0.001181, loss: 0.4163
2022-09-25 15:14:55 - train: epoch 0069, iter [00680, 01251], lr: 0.001181, loss: 0.4225
2022-09-25 15:15:13 - train: epoch 0069, iter [00690, 01251], lr: 0.001181, loss: 0.4161
2022-09-25 15:15:30 - train: epoch 0069, iter [00700, 01251], lr: 0.001181, loss: 0.4246
2022-09-25 15:15:47 - train: epoch 0069, iter [00710, 01251], lr: 0.001181, loss: 0.4317
2022-09-25 15:16:04 - train: epoch 0069, iter [00720, 01251], lr: 0.001181, loss: 0.4310
2022-09-25 15:16:22 - train: epoch 0069, iter [00730, 01251], lr: 0.001181, loss: 0.4349
2022-09-25 15:16:39 - train: epoch 0069, iter [00740, 01251], lr: 0.001181, loss: 0.4039
2022-09-25 15:16:56 - train: epoch 0069, iter [00750, 01251], lr: 0.001181, loss: 0.4298
2022-09-25 15:17:13 - train: epoch 0069, iter [00760, 01251], lr: 0.001181, loss: 0.3890
2022-09-25 15:17:31 - train: epoch 0069, iter [00770, 01251], lr: 0.001181, loss: 0.4180
2022-09-25 15:17:48 - train: epoch 0069, iter [00780, 01251], lr: 0.001181, loss: 0.4162
2022-09-25 15:18:05 - train: epoch 0069, iter [00790, 01251], lr: 0.001181, loss: 0.4232
2022-09-25 15:18:22 - train: epoch 0069, iter [00800, 01251], lr: 0.001181, loss: 0.4413
2022-09-25 15:18:39 - train: epoch 0069, iter [00810, 01251], lr: 0.001181, loss: 0.4260
2022-09-25 15:18:56 - train: epoch 0069, iter [00820, 01251], lr: 0.001181, loss: 0.4146
2022-09-25 15:19:14 - train: epoch 0069, iter [00830, 01251], lr: 0.001181, loss: 0.4173
2022-09-25 15:19:31 - train: epoch 0069, iter [00840, 01251], lr: 0.001181, loss: 0.4079
2022-09-25 15:19:48 - train: epoch 0069, iter [00850, 01251], lr: 0.001181, loss: 0.4076
2022-09-25 15:20:05 - train: epoch 0069, iter [00860, 01251], lr: 0.001181, loss: 0.4148
2022-09-25 15:20:23 - train: epoch 0069, iter [00870, 01251], lr: 0.001181, loss: 0.3956
2022-09-25 15:20:40 - train: epoch 0069, iter [00880, 01251], lr: 0.001181, loss: 0.4173
2022-09-25 15:20:57 - train: epoch 0069, iter [00890, 01251], lr: 0.001181, loss: 0.4161
2022-09-25 15:21:14 - train: epoch 0069, iter [00900, 01251], lr: 0.001181, loss: 0.4223
2022-09-25 15:21:31 - train: epoch 0069, iter [00910, 01251], lr: 0.001181, loss: 0.4290
2022-09-25 15:21:48 - train: epoch 0069, iter [00920, 01251], lr: 0.001181, loss: 0.4189
2022-09-25 15:22:06 - train: epoch 0069, iter [00930, 01251], lr: 0.001181, loss: 0.4305
2022-09-25 15:22:23 - train: epoch 0069, iter [00940, 01251], lr: 0.001181, loss: 0.4184
2022-09-25 15:22:40 - train: epoch 0069, iter [00950, 01251], lr: 0.001181, loss: 0.4214
2022-09-25 15:22:58 - train: epoch 0069, iter [00960, 01251], lr: 0.001181, loss: 0.4232
2022-09-25 15:23:15 - train: epoch 0069, iter [00970, 01251], lr: 0.001181, loss: 0.4182
2022-09-25 15:23:32 - train: epoch 0069, iter [00980, 01251], lr: 0.001181, loss: 0.4054
2022-09-25 15:23:49 - train: epoch 0069, iter [00990, 01251], lr: 0.001181, loss: 0.4168
2022-09-25 15:24:07 - train: epoch 0069, iter [01000, 01251], lr: 0.001181, loss: 0.4064
2022-09-25 15:24:24 - train: epoch 0069, iter [01010, 01251], lr: 0.001181, loss: 0.4121
2022-09-25 15:24:41 - train: epoch 0069, iter [01020, 01251], lr: 0.001181, loss: 0.4265
2022-09-25 15:24:59 - train: epoch 0069, iter [01030, 01251], lr: 0.001181, loss: 0.4187
2022-09-25 15:25:16 - train: epoch 0069, iter [01040, 01251], lr: 0.001181, loss: 0.4163
2022-09-25 15:25:33 - train: epoch 0069, iter [01050, 01251], lr: 0.001181, loss: 0.4263
2022-09-25 15:25:50 - train: epoch 0069, iter [01060, 01251], lr: 0.001181, loss: 0.4273
2022-09-25 15:26:07 - train: epoch 0069, iter [01070, 01251], lr: 0.001181, loss: 0.4175
2022-09-25 15:26:24 - train: epoch 0069, iter [01080, 01251], lr: 0.001181, loss: 0.4328
2022-09-25 15:26:42 - train: epoch 0069, iter [01090, 01251], lr: 0.001181, loss: 0.4150
2022-09-25 15:26:59 - train: epoch 0069, iter [01100, 01251], lr: 0.001181, loss: 0.4375
2022-09-25 15:27:16 - train: epoch 0069, iter [01110, 01251], lr: 0.001181, loss: 0.4163
2022-09-25 15:27:34 - train: epoch 0069, iter [01120, 01251], lr: 0.001181, loss: 0.4129
2022-09-25 15:27:51 - train: epoch 0069, iter [01130, 01251], lr: 0.001181, loss: 0.4239
2022-09-25 15:28:08 - train: epoch 0069, iter [01140, 01251], lr: 0.001181, loss: 0.3937
2022-09-25 15:28:25 - train: epoch 0069, iter [01150, 01251], lr: 0.001181, loss: 0.3940
2022-09-25 15:28:42 - train: epoch 0069, iter [01160, 01251], lr: 0.001181, loss: 0.4206
2022-09-25 15:28:59 - train: epoch 0069, iter [01170, 01251], lr: 0.001181, loss: 0.4245
2022-09-25 15:29:17 - train: epoch 0069, iter [01180, 01251], lr: 0.001181, loss: 0.4115
2022-09-25 15:29:34 - train: epoch 0069, iter [01190, 01251], lr: 0.001181, loss: 0.4262
2022-09-25 15:29:51 - train: epoch 0069, iter [01200, 01251], lr: 0.001181, loss: 0.4012
2022-09-25 15:30:09 - train: epoch 0069, iter [01210, 01251], lr: 0.001181, loss: 0.4306
2022-09-25 15:30:26 - train: epoch 0069, iter [01220, 01251], lr: 0.001181, loss: 0.4126
2022-09-25 15:30:43 - train: epoch 0069, iter [01230, 01251], lr: 0.001181, loss: 0.4061
2022-09-25 15:31:00 - train: epoch 0069, iter [01240, 01251], lr: 0.001181, loss: 0.4104
2022-09-25 15:31:16 - train: epoch 0069, iter [01250, 01251], lr: 0.001181, loss: 0.4166
2022-09-25 15:31:21 - train: epoch 069, train_loss: 0.4156
2022-09-25 15:31:27 - until epoch: 069, best_loss: 0.4156
2022-09-25 15:31:27 - epoch 070 lr: 0.001181
2022-09-25 15:31:56 - train: epoch 0070, iter [00010, 01251], lr: 0.001181, loss: 0.4107
2022-09-25 15:32:13 - train: epoch 0070, iter [00020, 01251], lr: 0.001181, loss: 0.4228
2022-09-25 15:32:30 - train: epoch 0070, iter [00030, 01251], lr: 0.001181, loss: 0.4038
2022-09-25 15:32:47 - train: epoch 0070, iter [00040, 01251], lr: 0.001181, loss: 0.4331
2022-09-25 15:33:04 - train: epoch 0070, iter [00050, 01251], lr: 0.001181, loss: 0.4005
2022-09-25 15:33:21 - train: epoch 0070, iter [00060, 01251], lr: 0.001181, loss: 0.4021
2022-09-25 15:33:39 - train: epoch 0070, iter [00070, 01251], lr: 0.001181, loss: 0.4033
2022-09-25 15:33:56 - train: epoch 0070, iter [00080, 01251], lr: 0.001181, loss: 0.4032
2022-09-25 15:34:13 - train: epoch 0070, iter [00090, 01251], lr: 0.001181, loss: 0.4245
2022-09-25 15:34:30 - train: epoch 0070, iter [00100, 01251], lr: 0.001181, loss: 0.4167
2022-09-25 15:34:47 - train: epoch 0070, iter [00110, 01251], lr: 0.001181, loss: 0.4235
2022-09-25 15:35:04 - train: epoch 0070, iter [00120, 01251], lr: 0.001181, loss: 0.4126
2022-09-25 15:35:22 - train: epoch 0070, iter [00130, 01251], lr: 0.001181, loss: 0.4088
2022-09-25 15:35:39 - train: epoch 0070, iter [00140, 01251], lr: 0.001181, loss: 0.4112
2022-09-25 15:35:56 - train: epoch 0070, iter [00150, 01251], lr: 0.001181, loss: 0.3986
2022-09-25 15:36:13 - train: epoch 0070, iter [00160, 01251], lr: 0.001181, loss: 0.4226
2022-09-25 15:36:30 - train: epoch 0070, iter [00170, 01251], lr: 0.001181, loss: 0.4186
2022-09-25 15:36:47 - train: epoch 0070, iter [00180, 01251], lr: 0.001181, loss: 0.4417
2022-09-25 15:37:04 - train: epoch 0070, iter [00190, 01251], lr: 0.001181, loss: 0.4056
2022-09-25 15:37:22 - train: epoch 0070, iter [00200, 01251], lr: 0.001181, loss: 0.4042
2022-09-25 15:37:39 - train: epoch 0070, iter [00210, 01251], lr: 0.001181, loss: 0.4195
2022-09-25 15:37:56 - train: epoch 0070, iter [00220, 01251], lr: 0.001181, loss: 0.4029
2022-09-25 15:38:13 - train: epoch 0070, iter [00230, 01251], lr: 0.001181, loss: 0.4172
2022-09-25 15:38:31 - train: epoch 0070, iter [00240, 01251], lr: 0.001181, loss: 0.4126
2022-09-25 15:38:48 - train: epoch 0070, iter [00250, 01251], lr: 0.001181, loss: 0.4201
2022-09-25 15:39:05 - train: epoch 0070, iter [00260, 01251], lr: 0.001181, loss: 0.4211
2022-09-25 15:39:22 - train: epoch 0070, iter [00270, 01251], lr: 0.001181, loss: 0.4046
2022-09-25 15:39:39 - train: epoch 0070, iter [00280, 01251], lr: 0.001181, loss: 0.4102
2022-09-25 15:39:56 - train: epoch 0070, iter [00290, 01251], lr: 0.001181, loss: 0.4172
2022-09-25 15:40:14 - train: epoch 0070, iter [00300, 01251], lr: 0.001181, loss: 0.4278
2022-09-25 15:40:31 - train: epoch 0070, iter [00310, 01251], lr: 0.001181, loss: 0.3950
2022-09-25 15:40:48 - train: epoch 0070, iter [00320, 01251], lr: 0.001181, loss: 0.4161
2022-09-25 15:41:05 - train: epoch 0070, iter [00330, 01251], lr: 0.001181, loss: 0.4142
2022-09-25 15:41:22 - train: epoch 0070, iter [00340, 01251], lr: 0.001181, loss: 0.4113
2022-09-25 15:41:39 - train: epoch 0070, iter [00350, 01251], lr: 0.001181, loss: 0.4264
2022-09-25 15:41:57 - train: epoch 0070, iter [00360, 01251], lr: 0.001181, loss: 0.4264
2022-09-25 15:42:14 - train: epoch 0070, iter [00370, 01251], lr: 0.001180, loss: 0.4387
2022-09-25 15:42:31 - train: epoch 0070, iter [00380, 01251], lr: 0.001180, loss: 0.4332
2022-09-25 15:42:48 - train: epoch 0070, iter [00390, 01251], lr: 0.001180, loss: 0.4221
2022-09-25 15:43:05 - train: epoch 0070, iter [00400, 01251], lr: 0.001180, loss: 0.4204
2022-09-25 15:43:23 - train: epoch 0070, iter [00410, 01251], lr: 0.001180, loss: 0.4059
2022-09-25 15:43:40 - train: epoch 0070, iter [00420, 01251], lr: 0.001180, loss: 0.4134
2022-09-25 15:43:57 - train: epoch 0070, iter [00430, 01251], lr: 0.001180, loss: 0.4179
2022-09-25 15:44:15 - train: epoch 0070, iter [00440, 01251], lr: 0.001180, loss: 0.4079
2022-09-25 15:44:32 - train: epoch 0070, iter [00450, 01251], lr: 0.001180, loss: 0.3997
2022-09-25 15:44:49 - train: epoch 0070, iter [00460, 01251], lr: 0.001180, loss: 0.4136
2022-09-25 15:45:06 - train: epoch 0070, iter [00470, 01251], lr: 0.001180, loss: 0.3949
2022-09-25 15:45:24 - train: epoch 0070, iter [00480, 01251], lr: 0.001180, loss: 0.4100
2022-09-25 15:45:41 - train: epoch 0070, iter [00490, 01251], lr: 0.001180, loss: 0.4223
2022-09-25 15:45:58 - train: epoch 0070, iter [00500, 01251], lr: 0.001180, loss: 0.4147
2022-09-25 15:46:16 - train: epoch 0070, iter [00510, 01251], lr: 0.001180, loss: 0.3969
2022-09-25 15:46:33 - train: epoch 0070, iter [00520, 01251], lr: 0.001180, loss: 0.4143
2022-09-25 15:46:51 - train: epoch 0070, iter [00530, 01251], lr: 0.001180, loss: 0.4288
2022-09-25 15:47:08 - train: epoch 0070, iter [00540, 01251], lr: 0.001180, loss: 0.4317
2022-09-25 15:47:26 - train: epoch 0070, iter [00550, 01251], lr: 0.001180, loss: 0.4250
2022-09-25 15:47:43 - train: epoch 0070, iter [00560, 01251], lr: 0.001180, loss: 0.4035
2022-09-25 15:48:00 - train: epoch 0070, iter [00570, 01251], lr: 0.001180, loss: 0.4023
2022-09-25 15:48:17 - train: epoch 0070, iter [00580, 01251], lr: 0.001180, loss: 0.4057
2022-09-25 15:48:35 - train: epoch 0070, iter [00590, 01251], lr: 0.001180, loss: 0.4249
2022-09-25 15:48:52 - train: epoch 0070, iter [00600, 01251], lr: 0.001180, loss: 0.4087
2022-09-25 15:49:09 - train: epoch 0070, iter [00610, 01251], lr: 0.001180, loss: 0.4135
2022-09-25 15:49:26 - train: epoch 0070, iter [00620, 01251], lr: 0.001180, loss: 0.4117
2022-09-25 15:49:44 - train: epoch 0070, iter [00630, 01251], lr: 0.001180, loss: 0.4111
2022-09-25 15:50:01 - train: epoch 0070, iter [00640, 01251], lr: 0.001180, loss: 0.4185
2022-09-25 15:50:19 - train: epoch 0070, iter [00650, 01251], lr: 0.001180, loss: 0.4352
2022-09-25 15:50:36 - train: epoch 0070, iter [00660, 01251], lr: 0.001180, loss: 0.4092
2022-09-25 15:50:54 - train: epoch 0070, iter [00670, 01251], lr: 0.001180, loss: 0.4279
2022-09-25 15:51:11 - train: epoch 0070, iter [00680, 01251], lr: 0.001180, loss: 0.4036
2022-09-25 15:51:29 - train: epoch 0070, iter [00690, 01251], lr: 0.001180, loss: 0.4308
2022-09-25 15:51:46 - train: epoch 0070, iter [00700, 01251], lr: 0.001180, loss: 0.4185
2022-09-25 15:52:04 - train: epoch 0070, iter [00710, 01251], lr: 0.001180, loss: 0.4137
2022-09-25 15:52:21 - train: epoch 0070, iter [00720, 01251], lr: 0.001180, loss: 0.4164
2022-09-25 15:52:39 - train: epoch 0070, iter [00730, 01251], lr: 0.001180, loss: 0.4169
2022-09-25 15:52:56 - train: epoch 0070, iter [00740, 01251], lr: 0.001180, loss: 0.4128
2022-09-25 15:53:14 - train: epoch 0070, iter [00750, 01251], lr: 0.001180, loss: 0.4226
2022-09-25 15:53:31 - train: epoch 0070, iter [00760, 01251], lr: 0.001180, loss: 0.4040
2022-09-25 15:53:49 - train: epoch 0070, iter [00770, 01251], lr: 0.001180, loss: 0.4222
2022-09-25 15:54:06 - train: epoch 0070, iter [00780, 01251], lr: 0.001180, loss: 0.4081
2022-09-25 15:54:24 - train: epoch 0070, iter [00790, 01251], lr: 0.001180, loss: 0.4223
2022-09-25 15:54:41 - train: epoch 0070, iter [00800, 01251], lr: 0.001180, loss: 0.4106
2022-09-25 15:54:59 - train: epoch 0070, iter [00810, 01251], lr: 0.001180, loss: 0.4305
2022-09-25 15:55:16 - train: epoch 0070, iter [00820, 01251], lr: 0.001180, loss: 0.4176
2022-09-25 15:55:34 - train: epoch 0070, iter [00830, 01251], lr: 0.001180, loss: 0.4063
2022-09-25 15:55:52 - train: epoch 0070, iter [00840, 01251], lr: 0.001180, loss: 0.4283
2022-09-25 15:56:09 - train: epoch 0070, iter [00850, 01251], lr: 0.001180, loss: 0.4118
2022-09-25 15:56:27 - train: epoch 0070, iter [00860, 01251], lr: 0.001180, loss: 0.4396
2022-09-25 15:56:44 - train: epoch 0070, iter [00870, 01251], lr: 0.001180, loss: 0.3862
2022-09-25 15:57:02 - train: epoch 0070, iter [00880, 01251], lr: 0.001180, loss: 0.4075
2022-09-25 15:57:19 - train: epoch 0070, iter [00890, 01251], lr: 0.001180, loss: 0.4156
2022-09-25 15:57:37 - train: epoch 0070, iter [00900, 01251], lr: 0.001180, loss: 0.4317
2022-09-25 15:57:55 - train: epoch 0070, iter [00910, 01251], lr: 0.001180, loss: 0.4157
2022-09-25 15:58:12 - train: epoch 0070, iter [00920, 01251], lr: 0.001180, loss: 0.4172
2022-09-25 15:58:30 - train: epoch 0070, iter [00930, 01251], lr: 0.001180, loss: 0.3998
2022-09-25 15:58:48 - train: epoch 0070, iter [00940, 01251], lr: 0.001180, loss: 0.4179
2022-09-25 15:59:05 - train: epoch 0070, iter [00950, 01251], lr: 0.001180, loss: 0.4156
2022-09-25 15:59:23 - train: epoch 0070, iter [00960, 01251], lr: 0.001180, loss: 0.4289
2022-09-25 15:59:41 - train: epoch 0070, iter [00970, 01251], lr: 0.001180, loss: 0.4310
2022-09-25 15:59:58 - train: epoch 0070, iter [00980, 01251], lr: 0.001180, loss: 0.4183
2022-09-25 16:00:16 - train: epoch 0070, iter [00990, 01251], lr: 0.001180, loss: 0.4189
2022-09-25 16:00:33 - train: epoch 0070, iter [01000, 01251], lr: 0.001180, loss: 0.4074
2022-09-25 16:00:51 - train: epoch 0070, iter [01010, 01251], lr: 0.001180, loss: 0.3974
2022-09-25 16:01:08 - train: epoch 0070, iter [01020, 01251], lr: 0.001180, loss: 0.4030
2022-09-25 16:01:26 - train: epoch 0070, iter [01030, 01251], lr: 0.001180, loss: 0.4100
2022-09-25 16:01:44 - train: epoch 0070, iter [01040, 01251], lr: 0.001180, loss: 0.4153
2022-09-25 16:02:01 - train: epoch 0070, iter [01050, 01251], lr: 0.001180, loss: 0.4288
2022-09-25 16:02:19 - train: epoch 0070, iter [01060, 01251], lr: 0.001180, loss: 0.4324
2022-09-25 16:02:36 - train: epoch 0070, iter [01070, 01251], lr: 0.001180, loss: 0.4148
2022-09-25 16:02:54 - train: epoch 0070, iter [01080, 01251], lr: 0.001180, loss: 0.4142
2022-09-25 16:03:11 - train: epoch 0070, iter [01090, 01251], lr: 0.001180, loss: 0.4190
2022-09-25 16:03:29 - train: epoch 0070, iter [01100, 01251], lr: 0.001180, loss: 0.4189
2022-09-25 16:03:46 - train: epoch 0070, iter [01110, 01251], lr: 0.001180, loss: 0.4223
2022-09-25 16:04:04 - train: epoch 0070, iter [01120, 01251], lr: 0.001180, loss: 0.4008
2022-09-25 16:04:22 - train: epoch 0070, iter [01130, 01251], lr: 0.001180, loss: 0.4123
2022-09-25 16:04:39 - train: epoch 0070, iter [01140, 01251], lr: 0.001180, loss: 0.4131
2022-09-25 16:04:57 - train: epoch 0070, iter [01150, 01251], lr: 0.001180, loss: 0.4058
2022-09-25 16:05:15 - train: epoch 0070, iter [01160, 01251], lr: 0.001180, loss: 0.3972
2022-09-25 16:05:32 - train: epoch 0070, iter [01170, 01251], lr: 0.001180, loss: 0.4305
2022-09-25 16:05:50 - train: epoch 0070, iter [01180, 01251], lr: 0.001180, loss: 0.3994
2022-09-25 16:06:08 - train: epoch 0070, iter [01190, 01251], lr: 0.001180, loss: 0.4064
2022-09-25 16:06:25 - train: epoch 0070, iter [01200, 01251], lr: 0.001180, loss: 0.4051
2022-09-25 16:06:43 - train: epoch 0070, iter [01210, 01251], lr: 0.001180, loss: 0.4206
2022-09-25 16:07:00 - train: epoch 0070, iter [01220, 01251], lr: 0.001180, loss: 0.4476
2022-09-25 16:07:18 - train: epoch 0070, iter [01230, 01251], lr: 0.001180, loss: 0.4172
2022-09-25 16:07:35 - train: epoch 0070, iter [01240, 01251], lr: 0.001180, loss: 0.4097
2022-09-25 16:07:52 - train: epoch 0070, iter [01250, 01251], lr: 0.001180, loss: 0.4224
2022-09-25 16:07:58 - train: epoch 070, train_loss: 0.4156
2022-09-25 16:08:03 - until epoch: 070, best_loss: 0.4156
2022-09-25 16:08:03 - epoch 071 lr: 0.001180
2022-09-25 16:08:34 - train: epoch 0071, iter [00010, 01251], lr: 0.001180, loss: 0.4062
2022-09-25 16:08:52 - train: epoch 0071, iter [00020, 01251], lr: 0.001180, loss: 0.4189
2022-09-25 16:09:09 - train: epoch 0071, iter [00030, 01251], lr: 0.001180, loss: 0.4146
2022-09-25 16:09:26 - train: epoch 0071, iter [00040, 01251], lr: 0.001180, loss: 0.4124
2022-09-25 16:09:44 - train: epoch 0071, iter [00050, 01251], lr: 0.001180, loss: 0.4087
2022-09-25 16:10:01 - train: epoch 0071, iter [00060, 01251], lr: 0.001179, loss: 0.4183
2022-09-25 16:10:19 - train: epoch 0071, iter [00070, 01251], lr: 0.001179, loss: 0.4184
2022-09-25 16:10:36 - train: epoch 0071, iter [00080, 01251], lr: 0.001179, loss: 0.4131
2022-09-25 16:10:54 - train: epoch 0071, iter [00090, 01251], lr: 0.001179, loss: 0.4211
2022-09-25 16:11:11 - train: epoch 0071, iter [00100, 01251], lr: 0.001179, loss: 0.4183
2022-09-25 16:11:29 - train: epoch 0071, iter [00110, 01251], lr: 0.001179, loss: 0.4030
2022-09-25 16:11:46 - train: epoch 0071, iter [00120, 01251], lr: 0.001179, loss: 0.4057
2022-09-25 16:12:04 - train: epoch 0071, iter [00130, 01251], lr: 0.001179, loss: 0.4264
2022-09-25 16:12:21 - train: epoch 0071, iter [00140, 01251], lr: 0.001179, loss: 0.4142
2022-09-25 16:12:39 - train: epoch 0071, iter [00150, 01251], lr: 0.001179, loss: 0.4278
2022-09-25 16:12:56 - train: epoch 0071, iter [00160, 01251], lr: 0.001179, loss: 0.4377
2022-09-25 16:13:14 - train: epoch 0071, iter [00170, 01251], lr: 0.001179, loss: 0.4140
2022-09-25 16:13:31 - train: epoch 0071, iter [00180, 01251], lr: 0.001179, loss: 0.4072
2022-09-25 16:13:49 - train: epoch 0071, iter [00190, 01251], lr: 0.001179, loss: 0.4056
2022-09-25 16:14:06 - train: epoch 0071, iter [00200, 01251], lr: 0.001179, loss: 0.4038
2022-09-25 16:14:24 - train: epoch 0071, iter [00210, 01251], lr: 0.001179, loss: 0.4045
2022-09-25 16:14:41 - train: epoch 0071, iter [00220, 01251], lr: 0.001179, loss: 0.4214
2022-09-25 16:14:59 - train: epoch 0071, iter [00230, 01251], lr: 0.001179, loss: 0.4220
2022-09-25 16:15:17 - train: epoch 0071, iter [00240, 01251], lr: 0.001179, loss: 0.4025
2022-09-25 16:15:34 - train: epoch 0071, iter [00250, 01251], lr: 0.001179, loss: 0.4171
2022-09-25 16:15:52 - train: epoch 0071, iter [00260, 01251], lr: 0.001179, loss: 0.4223
2022-09-25 16:16:09 - train: epoch 0071, iter [00270, 01251], lr: 0.001179, loss: 0.4266
2022-09-25 16:16:27 - train: epoch 0071, iter [00280, 01251], lr: 0.001179, loss: 0.4304
2022-09-25 16:16:44 - train: epoch 0071, iter [00290, 01251], lr: 0.001179, loss: 0.4260
2022-09-25 16:17:02 - train: epoch 0071, iter [00300, 01251], lr: 0.001179, loss: 0.4176
2022-09-25 16:17:19 - train: epoch 0071, iter [00310, 01251], lr: 0.001179, loss: 0.4128
2022-09-25 16:17:37 - train: epoch 0071, iter [00320, 01251], lr: 0.001179, loss: 0.4172
2022-09-25 16:17:55 - train: epoch 0071, iter [00330, 01251], lr: 0.001179, loss: 0.4248
2022-09-25 16:18:13 - train: epoch 0071, iter [00340, 01251], lr: 0.001179, loss: 0.4182
2022-09-25 16:18:30 - train: epoch 0071, iter [00350, 01251], lr: 0.001179, loss: 0.4137
2022-09-25 16:18:48 - train: epoch 0071, iter [00360, 01251], lr: 0.001179, loss: 0.4240
2022-09-25 16:19:05 - train: epoch 0071, iter [00370, 01251], lr: 0.001179, loss: 0.4110
2022-09-25 16:19:23 - train: epoch 0071, iter [00380, 01251], lr: 0.001179, loss: 0.4335
2022-09-25 16:19:40 - train: epoch 0071, iter [00390, 01251], lr: 0.001179, loss: 0.4400
2022-09-25 16:19:57 - train: epoch 0071, iter [00400, 01251], lr: 0.001179, loss: 0.4095
2022-09-25 16:20:15 - train: epoch 0071, iter [00410, 01251], lr: 0.001179, loss: 0.4027
2022-09-25 16:20:32 - train: epoch 0071, iter [00420, 01251], lr: 0.001179, loss: 0.3904
2022-09-25 16:20:49 - train: epoch 0071, iter [00430, 01251], lr: 0.001179, loss: 0.4286
2022-09-25 16:21:06 - train: epoch 0071, iter [00440, 01251], lr: 0.001179, loss: 0.4203
2022-09-25 16:21:24 - train: epoch 0071, iter [00450, 01251], lr: 0.001179, loss: 0.3959
2022-09-25 16:21:41 - train: epoch 0071, iter [00460, 01251], lr: 0.001179, loss: 0.4382
2022-09-25 16:21:59 - train: epoch 0071, iter [00470, 01251], lr: 0.001179, loss: 0.3972
2022-09-25 16:22:16 - train: epoch 0071, iter [00480, 01251], lr: 0.001179, loss: 0.4299
2022-09-25 16:22:33 - train: epoch 0071, iter [00490, 01251], lr: 0.001179, loss: 0.3982
2022-09-25 16:22:50 - train: epoch 0071, iter [00500, 01251], lr: 0.001179, loss: 0.4015
2022-09-25 16:23:08 - train: epoch 0071, iter [00510, 01251], lr: 0.001179, loss: 0.4107
2022-09-25 16:23:25 - train: epoch 0071, iter [00520, 01251], lr: 0.001179, loss: 0.4142
2022-09-25 16:23:42 - train: epoch 0071, iter [00530, 01251], lr: 0.001179, loss: 0.4127
2022-09-25 16:23:59 - train: epoch 0071, iter [00540, 01251], lr: 0.001179, loss: 0.4010
2022-09-25 16:24:17 - train: epoch 0071, iter [00550, 01251], lr: 0.001179, loss: 0.3961
2022-09-25 16:24:34 - train: epoch 0071, iter [00560, 01251], lr: 0.001179, loss: 0.4151
2022-09-25 16:24:51 - train: epoch 0071, iter [00570, 01251], lr: 0.001179, loss: 0.4156
2022-09-25 16:25:09 - train: epoch 0071, iter [00580, 01251], lr: 0.001179, loss: 0.4209
2022-09-25 16:25:26 - train: epoch 0071, iter [00590, 01251], lr: 0.001179, loss: 0.4142
2022-09-25 16:25:44 - train: epoch 0071, iter [00600, 01251], lr: 0.001179, loss: 0.4267
2022-09-25 16:26:01 - train: epoch 0071, iter [00610, 01251], lr: 0.001179, loss: 0.4242
2022-09-25 16:26:18 - train: epoch 0071, iter [00620, 01251], lr: 0.001179, loss: 0.4269
2022-09-25 16:26:36 - train: epoch 0071, iter [00630, 01251], lr: 0.001179, loss: 0.4329
2022-09-25 16:26:53 - train: epoch 0071, iter [00640, 01251], lr: 0.001179, loss: 0.4240
2022-09-25 16:27:11 - train: epoch 0071, iter [00650, 01251], lr: 0.001179, loss: 0.4137
2022-09-25 16:27:28 - train: epoch 0071, iter [00660, 01251], lr: 0.001179, loss: 0.4114
2022-09-25 16:27:45 - train: epoch 0071, iter [00670, 01251], lr: 0.001179, loss: 0.4170
2022-09-25 16:28:03 - train: epoch 0071, iter [00680, 01251], lr: 0.001179, loss: 0.4091
2022-09-25 16:28:21 - train: epoch 0071, iter [00690, 01251], lr: 0.001179, loss: 0.4008
2022-09-25 16:28:38 - train: epoch 0071, iter [00700, 01251], lr: 0.001179, loss: 0.4007
2022-09-25 16:28:56 - train: epoch 0071, iter [00710, 01251], lr: 0.001179, loss: 0.4022
2022-09-25 16:29:13 - train: epoch 0071, iter [00720, 01251], lr: 0.001179, loss: 0.4253
2022-09-25 16:29:31 - train: epoch 0071, iter [00730, 01251], lr: 0.001179, loss: 0.4303
2022-09-25 16:29:49 - train: epoch 0071, iter [00740, 01251], lr: 0.001179, loss: 0.3940
2022-09-25 16:30:06 - train: epoch 0071, iter [00750, 01251], lr: 0.001179, loss: 0.3939
2022-09-25 16:30:24 - train: epoch 0071, iter [00760, 01251], lr: 0.001179, loss: 0.4086
2022-09-25 16:30:42 - train: epoch 0071, iter [00770, 01251], lr: 0.001179, loss: 0.4381
2022-09-25 16:30:59 - train: epoch 0071, iter [00780, 01251], lr: 0.001179, loss: 0.4189
2022-09-25 16:31:17 - train: epoch 0071, iter [00790, 01251], lr: 0.001179, loss: 0.4196
2022-09-25 16:31:34 - train: epoch 0071, iter [00800, 01251], lr: 0.001179, loss: 0.4205
2022-09-25 16:31:52 - train: epoch 0071, iter [00810, 01251], lr: 0.001179, loss: 0.4045
2022-09-25 16:32:10 - train: epoch 0071, iter [00820, 01251], lr: 0.001179, loss: 0.4226
2022-09-25 16:32:27 - train: epoch 0071, iter [00830, 01251], lr: 0.001179, loss: 0.4125
2022-09-25 16:32:45 - train: epoch 0071, iter [00840, 01251], lr: 0.001179, loss: 0.4146
2022-09-25 16:33:03 - train: epoch 0071, iter [00850, 01251], lr: 0.001179, loss: 0.4202
2022-09-25 16:33:21 - train: epoch 0071, iter [00860, 01251], lr: 0.001179, loss: 0.4105
2022-09-25 16:33:38 - train: epoch 0071, iter [00870, 01251], lr: 0.001179, loss: 0.4165
2022-09-25 16:33:56 - train: epoch 0071, iter [00880, 01251], lr: 0.001179, loss: 0.4323
2022-09-25 16:34:14 - train: epoch 0071, iter [00890, 01251], lr: 0.001179, loss: 0.4197
2022-09-25 16:34:31 - train: epoch 0071, iter [00900, 01251], lr: 0.001179, loss: 0.4237
2022-09-25 16:34:49 - train: epoch 0071, iter [00910, 01251], lr: 0.001179, loss: 0.4193
2022-09-25 16:35:07 - train: epoch 0071, iter [00920, 01251], lr: 0.001179, loss: 0.4105
2022-09-25 16:35:24 - train: epoch 0071, iter [00930, 01251], lr: 0.001179, loss: 0.4303
2022-09-25 16:35:42 - train: epoch 0071, iter [00940, 01251], lr: 0.001179, loss: 0.4076
2022-09-25 16:36:00 - train: epoch 0071, iter [00950, 01251], lr: 0.001179, loss: 0.4307
2022-09-25 16:36:18 - train: epoch 0071, iter [00960, 01251], lr: 0.001179, loss: 0.4241
2022-09-25 16:36:35 - train: epoch 0071, iter [00970, 01251], lr: 0.001178, loss: 0.4078
2022-09-25 16:36:53 - train: epoch 0071, iter [00980, 01251], lr: 0.001178, loss: 0.4162
2022-09-25 16:37:11 - train: epoch 0071, iter [00990, 01251], lr: 0.001178, loss: 0.4381
2022-09-25 16:37:29 - train: epoch 0071, iter [01000, 01251], lr: 0.001178, loss: 0.4143
2022-09-25 16:37:46 - train: epoch 0071, iter [01010, 01251], lr: 0.001178, loss: 0.4054
2022-09-25 16:38:04 - train: epoch 0071, iter [01020, 01251], lr: 0.001178, loss: 0.4121
2022-09-25 16:38:22 - train: epoch 0071, iter [01030, 01251], lr: 0.001178, loss: 0.4187
2022-09-25 16:38:40 - train: epoch 0071, iter [01040, 01251], lr: 0.001178, loss: 0.4161
2022-09-25 16:38:57 - train: epoch 0071, iter [01050, 01251], lr: 0.001178, loss: 0.4057
2022-09-25 16:39:15 - train: epoch 0071, iter [01060, 01251], lr: 0.001178, loss: 0.4012
2022-09-25 16:39:33 - train: epoch 0071, iter [01070, 01251], lr: 0.001178, loss: 0.3943
2022-09-25 16:39:50 - train: epoch 0071, iter [01080, 01251], lr: 0.001178, loss: 0.4021
2022-09-25 16:40:08 - train: epoch 0071, iter [01090, 01251], lr: 0.001178, loss: 0.4161
2022-09-25 16:40:26 - train: epoch 0071, iter [01100, 01251], lr: 0.001178, loss: 0.4028
2022-09-25 16:40:44 - train: epoch 0071, iter [01110, 01251], lr: 0.001178, loss: 0.4103
2022-09-25 16:41:02 - train: epoch 0071, iter [01120, 01251], lr: 0.001178, loss: 0.4147
2022-09-25 16:41:19 - train: epoch 0071, iter [01130, 01251], lr: 0.001178, loss: 0.4115
2022-09-25 16:41:37 - train: epoch 0071, iter [01140, 01251], lr: 0.001178, loss: 0.4249
2022-09-25 16:41:55 - train: epoch 0071, iter [01150, 01251], lr: 0.001178, loss: 0.4117
2022-09-25 16:42:12 - train: epoch 0071, iter [01160, 01251], lr: 0.001178, loss: 0.4069
2022-09-25 16:42:30 - train: epoch 0071, iter [01170, 01251], lr: 0.001178, loss: 0.4244
2022-09-25 16:42:48 - train: epoch 0071, iter [01180, 01251], lr: 0.001178, loss: 0.4301
2022-09-25 16:43:06 - train: epoch 0071, iter [01190, 01251], lr: 0.001178, loss: 0.4057
2022-09-25 16:43:23 - train: epoch 0071, iter [01200, 01251], lr: 0.001178, loss: 0.4092
2022-09-25 16:43:41 - train: epoch 0071, iter [01210, 01251], lr: 0.001178, loss: 0.4095
2022-09-25 16:43:59 - train: epoch 0071, iter [01220, 01251], lr: 0.001178, loss: 0.4240
2022-09-25 16:44:17 - train: epoch 0071, iter [01230, 01251], lr: 0.001178, loss: 0.4272
2022-09-25 16:44:35 - train: epoch 0071, iter [01240, 01251], lr: 0.001178, loss: 0.3900
2022-09-25 16:44:51 - train: epoch 0071, iter [01250, 01251], lr: 0.001178, loss: 0.4148
2022-09-25 16:44:56 - train: epoch 071, train_loss: 0.4154
2022-09-25 16:45:02 - until epoch: 071, best_loss: 0.4154
2022-09-25 17:24:34 - epoch 072 lr: 0.001178
2022-09-25 17:25:17 - train: epoch 0072, iter [00010, 01251], lr: 0.001178, loss: 0.4037
2022-09-25 17:25:38 - train: epoch 0072, iter [00020, 01251], lr: 0.001178, loss: 0.4308
2022-09-25 17:25:59 - train: epoch 0072, iter [00030, 01251], lr: 0.001178, loss: 0.4096
2022-09-25 17:26:20 - train: epoch 0072, iter [00040, 01251], lr: 0.001178, loss: 0.4309
2022-09-25 17:26:41 - train: epoch 0072, iter [00050, 01251], lr: 0.001178, loss: 0.4207
2022-09-25 17:27:01 - train: epoch 0072, iter [00060, 01251], lr: 0.001178, loss: 0.4284
2022-09-25 17:27:22 - train: epoch 0072, iter [00070, 01251], lr: 0.001178, loss: 0.4134
2022-09-25 17:27:43 - train: epoch 0072, iter [00080, 01251], lr: 0.001178, loss: 0.3929
2022-09-25 17:28:04 - train: epoch 0072, iter [00090, 01251], lr: 0.001178, loss: 0.4193
2022-09-25 17:28:25 - train: epoch 0072, iter [00100, 01251], lr: 0.001178, loss: 0.4111
2022-09-25 17:28:46 - train: epoch 0072, iter [00110, 01251], lr: 0.001178, loss: 0.4294
2022-09-25 17:29:07 - train: epoch 0072, iter [00120, 01251], lr: 0.001178, loss: 0.4061
2022-09-25 17:29:28 - train: epoch 0072, iter [00130, 01251], lr: 0.001178, loss: 0.4061
2022-09-25 17:29:49 - train: epoch 0072, iter [00140, 01251], lr: 0.001178, loss: 0.4249
2022-09-25 17:30:09 - train: epoch 0072, iter [00150, 01251], lr: 0.001178, loss: 0.3986
2022-09-25 17:30:30 - train: epoch 0072, iter [00160, 01251], lr: 0.001178, loss: 0.4186
2022-09-25 17:30:51 - train: epoch 0072, iter [00170, 01251], lr: 0.001178, loss: 0.4461
2022-09-25 17:31:12 - train: epoch 0072, iter [00180, 01251], lr: 0.001178, loss: 0.4275
2022-09-25 17:31:33 - train: epoch 0072, iter [00190, 01251], lr: 0.001178, loss: 0.4441
2022-09-25 17:31:54 - train: epoch 0072, iter [00200, 01251], lr: 0.001178, loss: 0.4188
2022-09-25 17:32:15 - train: epoch 0072, iter [00210, 01251], lr: 0.001178, loss: 0.4115
2022-09-25 17:32:36 - train: epoch 0072, iter [00220, 01251], lr: 0.001178, loss: 0.3939
2022-09-25 17:32:57 - train: epoch 0072, iter [00230, 01251], lr: 0.001178, loss: 0.4269
2022-09-25 17:33:18 - train: epoch 0072, iter [00240, 01251], lr: 0.001178, loss: 0.4162
2022-09-25 17:33:39 - train: epoch 0072, iter [00250, 01251], lr: 0.001178, loss: 0.4008
2022-09-25 17:34:00 - train: epoch 0072, iter [00260, 01251], lr: 0.001178, loss: 0.4229
2022-09-25 17:34:21 - train: epoch 0072, iter [00270, 01251], lr: 0.001178, loss: 0.4088
2022-09-25 17:34:42 - train: epoch 0072, iter [00280, 01251], lr: 0.001178, loss: 0.4040
2022-09-25 17:35:03 - train: epoch 0072, iter [00290, 01251], lr: 0.001178, loss: 0.4075
2022-09-25 17:35:24 - train: epoch 0072, iter [00300, 01251], lr: 0.001178, loss: 0.4221
2022-09-25 17:35:45 - train: epoch 0072, iter [00310, 01251], lr: 0.001178, loss: 0.4141
2022-09-25 17:36:06 - train: epoch 0072, iter [00320, 01251], lr: 0.001178, loss: 0.4066
2022-09-25 17:36:27 - train: epoch 0072, iter [00330, 01251], lr: 0.001178, loss: 0.4135
2022-09-25 17:36:48 - train: epoch 0072, iter [00340, 01251], lr: 0.001178, loss: 0.4152
2022-09-25 17:37:09 - train: epoch 0072, iter [00350, 01251], lr: 0.001178, loss: 0.4138
2022-09-25 17:37:30 - train: epoch 0072, iter [00360, 01251], lr: 0.001178, loss: 0.4194
2022-09-25 17:37:51 - train: epoch 0072, iter [00370, 01251], lr: 0.001178, loss: 0.4257
2022-09-25 17:38:12 - train: epoch 0072, iter [00380, 01251], lr: 0.001178, loss: 0.4263
2022-09-25 17:38:33 - train: epoch 0072, iter [00390, 01251], lr: 0.001178, loss: 0.4314
2022-09-25 17:38:54 - train: epoch 0072, iter [00400, 01251], lr: 0.001178, loss: 0.4126
2022-09-25 17:39:14 - train: epoch 0072, iter [00410, 01251], lr: 0.001178, loss: 0.4337
2022-09-25 17:39:35 - train: epoch 0072, iter [00420, 01251], lr: 0.001178, loss: 0.4229
2022-09-25 17:39:56 - train: epoch 0072, iter [00430, 01251], lr: 0.001178, loss: 0.4152
2022-09-25 17:40:17 - train: epoch 0072, iter [00440, 01251], lr: 0.001178, loss: 0.4015
2022-09-25 17:40:38 - train: epoch 0072, iter [00450, 01251], lr: 0.001178, loss: 0.4301
2022-09-25 17:40:59 - train: epoch 0072, iter [00460, 01251], lr: 0.001178, loss: 0.4122
2022-09-25 17:41:20 - train: epoch 0072, iter [00470, 01251], lr: 0.001178, loss: 0.4055
2022-09-25 17:41:41 - train: epoch 0072, iter [00480, 01251], lr: 0.001178, loss: 0.4104
2022-09-25 17:42:02 - train: epoch 0072, iter [00490, 01251], lr: 0.001178, loss: 0.3973
2022-09-25 17:42:23 - train: epoch 0072, iter [00500, 01251], lr: 0.001178, loss: 0.3912
2022-09-25 17:42:43 - train: epoch 0072, iter [00510, 01251], lr: 0.001178, loss: 0.3984
2022-09-25 17:43:04 - train: epoch 0072, iter [00520, 01251], lr: 0.001178, loss: 0.4430
2022-09-25 17:43:25 - train: epoch 0072, iter [00530, 01251], lr: 0.001178, loss: 0.4149
2022-09-25 17:43:46 - train: epoch 0072, iter [00540, 01251], lr: 0.001178, loss: 0.4186
2022-09-25 17:44:07 - train: epoch 0072, iter [00550, 01251], lr: 0.001178, loss: 0.4187
2022-09-25 17:44:28 - train: epoch 0072, iter [00560, 01251], lr: 0.001178, loss: 0.4141
2022-09-25 17:44:49 - train: epoch 0072, iter [00570, 01251], lr: 0.001178, loss: 0.4135
2022-09-25 17:45:10 - train: epoch 0072, iter [00580, 01251], lr: 0.001178, loss: 0.4122
2022-09-25 17:45:31 - train: epoch 0072, iter [00590, 01251], lr: 0.001178, loss: 0.4112
2022-09-25 17:45:52 - train: epoch 0072, iter [00600, 01251], lr: 0.001178, loss: 0.3986
2022-09-25 17:46:13 - train: epoch 0072, iter [00610, 01251], lr: 0.001177, loss: 0.4274
2022-09-25 17:46:33 - train: epoch 0072, iter [00620, 01251], lr: 0.001177, loss: 0.4239
2022-09-25 17:46:54 - train: epoch 0072, iter [00630, 01251], lr: 0.001177, loss: 0.4340
2022-09-25 17:47:15 - train: epoch 0072, iter [00640, 01251], lr: 0.001177, loss: 0.3894
2022-09-25 17:47:36 - train: epoch 0072, iter [00650, 01251], lr: 0.001177, loss: 0.3987
2022-09-25 17:47:57 - train: epoch 0072, iter [00660, 01251], lr: 0.001177, loss: 0.4322
2022-09-25 17:48:18 - train: epoch 0072, iter [00670, 01251], lr: 0.001177, loss: 0.4197
2022-09-25 17:48:39 - train: epoch 0072, iter [00680, 01251], lr: 0.001177, loss: 0.4224
2022-09-25 17:49:00 - train: epoch 0072, iter [00690, 01251], lr: 0.001177, loss: 0.4084
2022-09-25 17:49:21 - train: epoch 0072, iter [00700, 01251], lr: 0.001177, loss: 0.4227
2022-09-25 17:49:42 - train: epoch 0072, iter [00710, 01251], lr: 0.001177, loss: 0.4312
2022-09-25 17:50:03 - train: epoch 0072, iter [00720, 01251], lr: 0.001177, loss: 0.4162
2022-09-25 17:50:23 - train: epoch 0072, iter [00730, 01251], lr: 0.001177, loss: 0.4234
2022-09-25 17:50:44 - train: epoch 0072, iter [00740, 01251], lr: 0.001177, loss: 0.4012
2022-09-25 17:51:05 - train: epoch 0072, iter [00750, 01251], lr: 0.001177, loss: 0.4097
2022-09-25 17:51:26 - train: epoch 0072, iter [00760, 01251], lr: 0.001177, loss: 0.4242
2022-09-25 17:51:47 - train: epoch 0072, iter [00770, 01251], lr: 0.001177, loss: 0.4165
2022-09-25 17:52:08 - train: epoch 0072, iter [00780, 01251], lr: 0.001177, loss: 0.4026
2022-09-25 17:52:29 - train: epoch 0072, iter [00790, 01251], lr: 0.001177, loss: 0.4175
2022-09-25 17:52:50 - train: epoch 0072, iter [00800, 01251], lr: 0.001177, loss: 0.4207
2022-09-25 17:53:10 - train: epoch 0072, iter [00810, 01251], lr: 0.001177, loss: 0.3980
2022-09-25 17:53:31 - train: epoch 0072, iter [00820, 01251], lr: 0.001177, loss: 0.3774
2022-09-25 17:53:52 - train: epoch 0072, iter [00830, 01251], lr: 0.001177, loss: 0.4067
2022-09-25 17:54:13 - train: epoch 0072, iter [00840, 01251], lr: 0.001177, loss: 0.4260
2022-09-25 17:54:33 - train: epoch 0072, iter [00850, 01251], lr: 0.001177, loss: 0.4274
2022-09-25 17:54:54 - train: epoch 0072, iter [00860, 01251], lr: 0.001177, loss: 0.4052
2022-09-25 17:55:15 - train: epoch 0072, iter [00870, 01251], lr: 0.001177, loss: 0.4059
2022-09-25 17:55:36 - train: epoch 0072, iter [00880, 01251], lr: 0.001177, loss: 0.4236
2022-09-25 17:55:57 - train: epoch 0072, iter [00890, 01251], lr: 0.001177, loss: 0.4171
2022-09-25 17:56:18 - train: epoch 0072, iter [00900, 01251], lr: 0.001177, loss: 0.4098
2022-09-25 17:56:39 - train: epoch 0072, iter [00910, 01251], lr: 0.001177, loss: 0.4159
2022-09-25 17:56:59 - train: epoch 0072, iter [00920, 01251], lr: 0.001177, loss: 0.4283
2022-09-25 17:57:20 - train: epoch 0072, iter [00930, 01251], lr: 0.001177, loss: 0.4051
2022-09-25 17:57:41 - train: epoch 0072, iter [00940, 01251], lr: 0.001177, loss: 0.4016
2022-09-25 17:58:02 - train: epoch 0072, iter [00950, 01251], lr: 0.001177, loss: 0.4243
2022-09-25 17:58:23 - train: epoch 0072, iter [00960, 01251], lr: 0.001177, loss: 0.4023
2022-09-25 17:58:43 - train: epoch 0072, iter [00970, 01251], lr: 0.001177, loss: 0.4169
2022-09-25 17:59:04 - train: epoch 0072, iter [00980, 01251], lr: 0.001177, loss: 0.4210
2022-09-25 17:59:25 - train: epoch 0072, iter [00990, 01251], lr: 0.001177, loss: 0.4167
2022-09-25 17:59:45 - train: epoch 0072, iter [01000, 01251], lr: 0.001177, loss: 0.4289
2022-09-25 18:00:06 - train: epoch 0072, iter [01010, 01251], lr: 0.001177, loss: 0.4081
2022-09-25 18:00:27 - train: epoch 0072, iter [01020, 01251], lr: 0.001177, loss: 0.4121
2022-09-25 18:00:48 - train: epoch 0072, iter [01030, 01251], lr: 0.001177, loss: 0.4037
2022-09-25 18:01:08 - train: epoch 0072, iter [01040, 01251], lr: 0.001177, loss: 0.4209
2022-09-25 18:01:29 - train: epoch 0072, iter [01050, 01251], lr: 0.001177, loss: 0.4072
2022-09-25 18:01:50 - train: epoch 0072, iter [01060, 01251], lr: 0.001177, loss: 0.4306
2022-09-25 18:02:11 - train: epoch 0072, iter [01070, 01251], lr: 0.001177, loss: 0.3980
2022-09-25 18:02:31 - train: epoch 0072, iter [01080, 01251], lr: 0.001177, loss: 0.4157
2022-09-25 18:02:52 - train: epoch 0072, iter [01090, 01251], lr: 0.001177, loss: 0.4394
2022-09-25 18:03:13 - train: epoch 0072, iter [01100, 01251], lr: 0.001177, loss: 0.4211
2022-09-25 18:03:34 - train: epoch 0072, iter [01110, 01251], lr: 0.001177, loss: 0.4171
2022-09-25 18:03:54 - train: epoch 0072, iter [01120, 01251], lr: 0.001177, loss: 0.4104
2022-09-25 18:04:15 - train: epoch 0072, iter [01130, 01251], lr: 0.001177, loss: 0.4099
2022-09-25 18:04:36 - train: epoch 0072, iter [01140, 01251], lr: 0.001177, loss: 0.4155
2022-09-25 18:04:57 - train: epoch 0072, iter [01150, 01251], lr: 0.001177, loss: 0.4170
2022-09-25 18:05:17 - train: epoch 0072, iter [01160, 01251], lr: 0.001177, loss: 0.4455
2022-09-25 18:05:38 - train: epoch 0072, iter [01170, 01251], lr: 0.001177, loss: 0.4067
2022-09-25 18:05:59 - train: epoch 0072, iter [01180, 01251], lr: 0.001177, loss: 0.4198
2022-09-25 18:06:20 - train: epoch 0072, iter [01190, 01251], lr: 0.001177, loss: 0.4052
2022-09-25 18:06:40 - train: epoch 0072, iter [01200, 01251], lr: 0.001177, loss: 0.4202
2022-09-25 18:07:01 - train: epoch 0072, iter [01210, 01251], lr: 0.001177, loss: 0.4266
2022-09-25 18:07:22 - train: epoch 0072, iter [01220, 01251], lr: 0.001177, loss: 0.4038
2022-09-25 18:07:42 - train: epoch 0072, iter [01230, 01251], lr: 0.001177, loss: 0.4029
2022-09-25 18:08:03 - train: epoch 0072, iter [01240, 01251], lr: 0.001177, loss: 0.4227
2022-09-25 18:08:23 - train: epoch 0072, iter [01250, 01251], lr: 0.001177, loss: 0.4099
2022-09-25 18:08:27 - train: epoch 072, train_loss: 0.4153
2022-09-25 18:08:31 - until epoch: 072, best_loss: 0.4153
2022-09-25 18:08:31 - epoch 073 lr: 0.001177
2022-09-25 18:09:08 - train: epoch 0073, iter [00010, 01251], lr: 0.001177, loss: 0.4065
2022-09-25 18:09:29 - train: epoch 0073, iter [00020, 01251], lr: 0.001177, loss: 0.4233
2022-09-25 18:09:49 - train: epoch 0073, iter [00030, 01251], lr: 0.001177, loss: 0.4145
2022-09-25 18:10:10 - train: epoch 0073, iter [00040, 01251], lr: 0.001177, loss: 0.4226
2022-09-25 18:10:31 - train: epoch 0073, iter [00050, 01251], lr: 0.001177, loss: 0.4080
2022-09-25 18:10:52 - train: epoch 0073, iter [00060, 01251], lr: 0.001177, loss: 0.4361
2022-09-25 18:11:13 - train: epoch 0073, iter [00070, 01251], lr: 0.001177, loss: 0.4134
2022-09-25 18:11:34 - train: epoch 0073, iter [00080, 01251], lr: 0.001177, loss: 0.4145
2022-09-25 18:11:55 - train: epoch 0073, iter [00090, 01251], lr: 0.001177, loss: 0.3987
2022-09-25 18:12:16 - train: epoch 0073, iter [00100, 01251], lr: 0.001177, loss: 0.4074
2022-09-25 18:12:36 - train: epoch 0073, iter [00110, 01251], lr: 0.001177, loss: 0.4100
2022-09-25 18:12:57 - train: epoch 0073, iter [00120, 01251], lr: 0.001177, loss: 0.4284
2022-09-25 18:13:18 - train: epoch 0073, iter [00130, 01251], lr: 0.001177, loss: 0.4177
2022-09-25 18:13:39 - train: epoch 0073, iter [00140, 01251], lr: 0.001177, loss: 0.4262
2022-09-25 18:14:00 - train: epoch 0073, iter [00150, 01251], lr: 0.001177, loss: 0.4111
2022-09-25 18:14:21 - train: epoch 0073, iter [00160, 01251], lr: 0.001177, loss: 0.4163
2022-09-25 18:14:42 - train: epoch 0073, iter [00170, 01251], lr: 0.001177, loss: 0.4022
2022-09-25 18:15:03 - train: epoch 0073, iter [00180, 01251], lr: 0.001177, loss: 0.4129
2022-09-25 18:15:24 - train: epoch 0073, iter [00190, 01251], lr: 0.001177, loss: 0.4092
2022-09-25 18:15:44 - train: epoch 0073, iter [00200, 01251], lr: 0.001177, loss: 0.4257
2022-09-25 18:16:05 - train: epoch 0073, iter [00210, 01251], lr: 0.001177, loss: 0.4013
2022-09-25 18:16:26 - train: epoch 0073, iter [00220, 01251], lr: 0.001177, loss: 0.4315
2022-09-25 18:16:47 - train: epoch 0073, iter [00230, 01251], lr: 0.001176, loss: 0.4089
2022-09-25 18:17:08 - train: epoch 0073, iter [00240, 01251], lr: 0.001176, loss: 0.4101
2022-09-25 18:17:29 - train: epoch 0073, iter [00250, 01251], lr: 0.001176, loss: 0.4005
2022-09-25 18:17:49 - train: epoch 0073, iter [00260, 01251], lr: 0.001176, loss: 0.4121
2022-09-25 18:18:10 - train: epoch 0073, iter [00270, 01251], lr: 0.001176, loss: 0.4282
2022-09-25 18:18:31 - train: epoch 0073, iter [00280, 01251], lr: 0.001176, loss: 0.4177
2022-09-25 18:18:52 - train: epoch 0073, iter [00290, 01251], lr: 0.001176, loss: 0.4187
2022-09-25 18:19:13 - train: epoch 0073, iter [00300, 01251], lr: 0.001176, loss: 0.4126
2022-09-25 18:19:34 - train: epoch 0073, iter [00310, 01251], lr: 0.001176, loss: 0.4230
2022-09-25 18:19:55 - train: epoch 0073, iter [00320, 01251], lr: 0.001176, loss: 0.4147
2022-09-25 18:20:16 - train: epoch 0073, iter [00330, 01251], lr: 0.001176, loss: 0.4330
2022-09-25 18:20:37 - train: epoch 0073, iter [00340, 01251], lr: 0.001176, loss: 0.4297
2022-09-25 18:20:57 - train: epoch 0073, iter [00350, 01251], lr: 0.001176, loss: 0.4131
2022-09-25 18:21:18 - train: epoch 0073, iter [00360, 01251], lr: 0.001176, loss: 0.4107
2022-09-25 18:21:39 - train: epoch 0073, iter [00370, 01251], lr: 0.001176, loss: 0.4224
2022-09-25 18:22:00 - train: epoch 0073, iter [00380, 01251], lr: 0.001176, loss: 0.3902
2022-09-25 18:22:21 - train: epoch 0073, iter [00390, 01251], lr: 0.001176, loss: 0.4207
2022-09-25 18:22:41 - train: epoch 0073, iter [00400, 01251], lr: 0.001176, loss: 0.4170
2022-09-25 18:23:02 - train: epoch 0073, iter [00410, 01251], lr: 0.001176, loss: 0.4170
2022-09-25 18:23:23 - train: epoch 0073, iter [00420, 01251], lr: 0.001176, loss: 0.4232
2022-09-25 18:23:44 - train: epoch 0073, iter [00430, 01251], lr: 0.001176, loss: 0.4046
2022-09-25 18:24:05 - train: epoch 0073, iter [00440, 01251], lr: 0.001176, loss: 0.4085
2022-09-25 18:24:26 - train: epoch 0073, iter [00450, 01251], lr: 0.001176, loss: 0.4228
2022-09-25 18:24:46 - train: epoch 0073, iter [00460, 01251], lr: 0.001176, loss: 0.4101
2022-09-25 18:25:07 - train: epoch 0073, iter [00470, 01251], lr: 0.001176, loss: 0.4158
2022-09-25 18:25:28 - train: epoch 0073, iter [00480, 01251], lr: 0.001176, loss: 0.4228
2022-09-25 18:25:49 - train: epoch 0073, iter [00490, 01251], lr: 0.001176, loss: 0.4252
2022-09-25 18:26:09 - train: epoch 0073, iter [00500, 01251], lr: 0.001176, loss: 0.4166
2022-09-25 18:26:30 - train: epoch 0073, iter [00510, 01251], lr: 0.001176, loss: 0.4006
2022-09-25 18:26:51 - train: epoch 0073, iter [00520, 01251], lr: 0.001176, loss: 0.4147
2022-09-25 18:27:12 - train: epoch 0073, iter [00530, 01251], lr: 0.001176, loss: 0.4005
2022-09-25 18:27:33 - train: epoch 0073, iter [00540, 01251], lr: 0.001176, loss: 0.4136
2022-09-25 18:27:53 - train: epoch 0073, iter [00550, 01251], lr: 0.001176, loss: 0.4061
2022-09-25 18:28:14 - train: epoch 0073, iter [00560, 01251], lr: 0.001176, loss: 0.4310
2022-09-25 18:28:35 - train: epoch 0073, iter [00570, 01251], lr: 0.001176, loss: 0.4054
2022-09-25 18:28:55 - train: epoch 0073, iter [00580, 01251], lr: 0.001176, loss: 0.4269
2022-09-25 18:29:16 - train: epoch 0073, iter [00590, 01251], lr: 0.001176, loss: 0.4215
2022-09-25 18:29:37 - train: epoch 0073, iter [00600, 01251], lr: 0.001176, loss: 0.4237
2022-09-25 18:29:57 - train: epoch 0073, iter [00610, 01251], lr: 0.001176, loss: 0.4197
2022-09-25 18:30:18 - train: epoch 0073, iter [00620, 01251], lr: 0.001176, loss: 0.4239
2022-09-25 18:30:39 - train: epoch 0073, iter [00630, 01251], lr: 0.001176, loss: 0.4149
2022-09-25 18:31:00 - train: epoch 0073, iter [00640, 01251], lr: 0.001176, loss: 0.4236
2022-09-25 18:31:20 - train: epoch 0073, iter [00650, 01251], lr: 0.001176, loss: 0.3928
2022-09-25 18:31:41 - train: epoch 0073, iter [00660, 01251], lr: 0.001176, loss: 0.4159
2022-09-25 18:32:02 - train: epoch 0073, iter [00670, 01251], lr: 0.001176, loss: 0.4082
2022-09-25 18:32:22 - train: epoch 0073, iter [00680, 01251], lr: 0.001176, loss: 0.4152
2022-09-25 18:32:43 - train: epoch 0073, iter [00690, 01251], lr: 0.001176, loss: 0.4294
2022-09-25 18:33:04 - train: epoch 0073, iter [00700, 01251], lr: 0.001176, loss: 0.4134
2022-09-25 18:33:24 - train: epoch 0073, iter [00710, 01251], lr: 0.001176, loss: 0.4097
2022-09-25 18:33:45 - train: epoch 0073, iter [00720, 01251], lr: 0.001176, loss: 0.4314
2022-09-25 18:34:06 - train: epoch 0073, iter [00730, 01251], lr: 0.001176, loss: 0.3987
2022-09-25 18:34:26 - train: epoch 0073, iter [00740, 01251], lr: 0.001176, loss: 0.4034
2022-09-25 18:34:47 - train: epoch 0073, iter [00750, 01251], lr: 0.001176, loss: 0.4131
2022-09-25 18:35:07 - train: epoch 0073, iter [00760, 01251], lr: 0.001176, loss: 0.4207
2022-09-25 18:35:28 - train: epoch 0073, iter [00770, 01251], lr: 0.001176, loss: 0.4040
2022-09-25 18:35:49 - train: epoch 0073, iter [00780, 01251], lr: 0.001176, loss: 0.4093
2022-09-25 18:36:09 - train: epoch 0073, iter [00790, 01251], lr: 0.001176, loss: 0.4093
2022-09-25 18:36:29 - train: epoch 0073, iter [00800, 01251], lr: 0.001176, loss: 0.3928
2022-09-25 18:36:50 - train: epoch 0073, iter [00810, 01251], lr: 0.001176, loss: 0.3977
2022-09-25 18:37:10 - train: epoch 0073, iter [00820, 01251], lr: 0.001176, loss: 0.4261
2022-09-25 18:37:31 - train: epoch 0073, iter [00830, 01251], lr: 0.001176, loss: 0.4155
2022-09-25 18:37:51 - train: epoch 0073, iter [00840, 01251], lr: 0.001176, loss: 0.4236
2022-09-25 18:38:11 - train: epoch 0073, iter [00850, 01251], lr: 0.001176, loss: 0.4127
2022-09-25 18:38:32 - train: epoch 0073, iter [00860, 01251], lr: 0.001176, loss: 0.3842
2022-09-25 18:38:52 - train: epoch 0073, iter [00870, 01251], lr: 0.001176, loss: 0.4029
2022-09-25 18:39:12 - train: epoch 0073, iter [00880, 01251], lr: 0.001176, loss: 0.4181
2022-09-25 18:39:33 - train: epoch 0073, iter [00890, 01251], lr: 0.001176, loss: 0.4332
2022-09-25 18:39:53 - train: epoch 0073, iter [00900, 01251], lr: 0.001176, loss: 0.4149
2022-09-25 18:40:13 - train: epoch 0073, iter [00910, 01251], lr: 0.001176, loss: 0.4056
2022-09-25 18:40:33 - train: epoch 0073, iter [00920, 01251], lr: 0.001176, loss: 0.4185
2022-09-25 18:40:53 - train: epoch 0073, iter [00930, 01251], lr: 0.001176, loss: 0.4063
2022-09-25 18:41:14 - train: epoch 0073, iter [00940, 01251], lr: 0.001176, loss: 0.4148
2022-09-25 18:41:34 - train: epoch 0073, iter [00950, 01251], lr: 0.001176, loss: 0.4013
2022-09-25 18:41:55 - train: epoch 0073, iter [00960, 01251], lr: 0.001176, loss: 0.4050
2022-09-25 18:42:15 - train: epoch 0073, iter [00970, 01251], lr: 0.001176, loss: 0.4206
2022-09-25 18:42:35 - train: epoch 0073, iter [00980, 01251], lr: 0.001176, loss: 0.3946
2022-09-25 18:42:56 - train: epoch 0073, iter [00990, 01251], lr: 0.001176, loss: 0.4373
2022-09-25 18:43:16 - train: epoch 0073, iter [01000, 01251], lr: 0.001176, loss: 0.4161
2022-09-25 18:43:36 - train: epoch 0073, iter [01010, 01251], lr: 0.001176, loss: 0.4110
2022-09-25 18:43:56 - train: epoch 0073, iter [01020, 01251], lr: 0.001176, loss: 0.4139
2022-09-25 18:44:17 - train: epoch 0073, iter [01030, 01251], lr: 0.001176, loss: 0.4326
2022-09-25 18:44:37 - train: epoch 0073, iter [01040, 01251], lr: 0.001176, loss: 0.4226
2022-09-25 18:44:57 - train: epoch 0073, iter [01050, 01251], lr: 0.001176, loss: 0.4186
2022-09-25 18:45:17 - train: epoch 0073, iter [01060, 01251], lr: 0.001176, loss: 0.4090
2022-09-25 18:45:37 - train: epoch 0073, iter [01070, 01251], lr: 0.001176, loss: 0.4340
2022-09-25 18:45:58 - train: epoch 0073, iter [01080, 01251], lr: 0.001175, loss: 0.4085
2022-09-25 18:46:18 - train: epoch 0073, iter [01090, 01251], lr: 0.001175, loss: 0.4067
2022-09-25 18:46:38 - train: epoch 0073, iter [01100, 01251], lr: 0.001175, loss: 0.4217
2022-09-25 18:46:58 - train: epoch 0073, iter [01110, 01251], lr: 0.001175, loss: 0.4135
2022-09-25 18:47:18 - train: epoch 0073, iter [01120, 01251], lr: 0.001175, loss: 0.4198
2022-09-25 18:47:38 - train: epoch 0073, iter [01130, 01251], lr: 0.001175, loss: 0.4238
2022-09-25 18:47:58 - train: epoch 0073, iter [01140, 01251], lr: 0.001175, loss: 0.4138
2022-09-25 18:48:18 - train: epoch 0073, iter [01150, 01251], lr: 0.001175, loss: 0.4096
2022-09-25 18:48:38 - train: epoch 0073, iter [01160, 01251], lr: 0.001175, loss: 0.4183
2022-09-25 18:48:58 - train: epoch 0073, iter [01170, 01251], lr: 0.001175, loss: 0.4305
2022-09-25 18:49:18 - train: epoch 0073, iter [01180, 01251], lr: 0.001175, loss: 0.4127
2022-09-25 18:49:38 - train: epoch 0073, iter [01190, 01251], lr: 0.001175, loss: 0.4199
2022-09-25 18:49:59 - train: epoch 0073, iter [01200, 01251], lr: 0.001175, loss: 0.4088
2022-09-25 18:50:19 - train: epoch 0073, iter [01210, 01251], lr: 0.001175, loss: 0.4415
2022-09-25 18:50:39 - train: epoch 0073, iter [01220, 01251], lr: 0.001175, loss: 0.4135
2022-09-25 18:50:59 - train: epoch 0073, iter [01230, 01251], lr: 0.001175, loss: 0.4116
2022-09-25 18:51:19 - train: epoch 0073, iter [01240, 01251], lr: 0.001175, loss: 0.4323
2022-09-25 18:51:38 - train: epoch 0073, iter [01250, 01251], lr: 0.001175, loss: 0.4253
2022-09-25 18:51:43 - train: epoch 073, train_loss: 0.4153
2022-09-25 18:51:47 - until epoch: 073, best_loss: 0.4153
2022-09-25 18:51:47 - epoch 074 lr: 0.001175
2022-09-25 18:52:24 - train: epoch 0074, iter [00010, 01251], lr: 0.001175, loss: 0.4139
2022-09-25 18:52:44 - train: epoch 0074, iter [00020, 01251], lr: 0.001175, loss: 0.4003
2022-09-25 18:53:05 - train: epoch 0074, iter [00030, 01251], lr: 0.001175, loss: 0.4152
2022-09-25 18:53:26 - train: epoch 0074, iter [00040, 01251], lr: 0.001175, loss: 0.4112
2022-09-25 18:53:46 - train: epoch 0074, iter [00050, 01251], lr: 0.001175, loss: 0.4175
2022-09-25 18:54:07 - train: epoch 0074, iter [00060, 01251], lr: 0.001175, loss: 0.3910
2022-09-25 18:54:28 - train: epoch 0074, iter [00070, 01251], lr: 0.001175, loss: 0.4271
2022-09-25 18:54:48 - train: epoch 0074, iter [00080, 01251], lr: 0.001175, loss: 0.4133
2022-09-25 18:55:09 - train: epoch 0074, iter [00090, 01251], lr: 0.001175, loss: 0.4170
2022-09-25 18:55:30 - train: epoch 0074, iter [00100, 01251], lr: 0.001175, loss: 0.4058
2022-09-25 18:55:50 - train: epoch 0074, iter [00110, 01251], lr: 0.001175, loss: 0.4054
2022-09-25 18:56:11 - train: epoch 0074, iter [00120, 01251], lr: 0.001175, loss: 0.4079
2022-09-25 18:56:32 - train: epoch 0074, iter [00130, 01251], lr: 0.001175, loss: 0.4207
2022-09-25 18:56:53 - train: epoch 0074, iter [00140, 01251], lr: 0.001175, loss: 0.4031
2022-09-25 18:57:13 - train: epoch 0074, iter [00150, 01251], lr: 0.001175, loss: 0.4181
2022-09-25 18:57:34 - train: epoch 0074, iter [00160, 01251], lr: 0.001175, loss: 0.4267
2022-09-25 18:57:55 - train: epoch 0074, iter [00170, 01251], lr: 0.001175, loss: 0.4192
2022-09-25 18:58:15 - train: epoch 0074, iter [00180, 01251], lr: 0.001175, loss: 0.4124
2022-09-25 18:58:36 - train: epoch 0074, iter [00190, 01251], lr: 0.001175, loss: 0.4042
2022-09-25 18:58:57 - train: epoch 0074, iter [00200, 01251], lr: 0.001175, loss: 0.4317
2022-09-25 18:59:17 - train: epoch 0074, iter [00210, 01251], lr: 0.001175, loss: 0.4209
2022-09-25 18:59:38 - train: epoch 0074, iter [00220, 01251], lr: 0.001175, loss: 0.3904
2022-09-25 18:59:59 - train: epoch 0074, iter [00230, 01251], lr: 0.001175, loss: 0.4341
2022-09-25 19:00:20 - train: epoch 0074, iter [00240, 01251], lr: 0.001175, loss: 0.4210
2022-09-25 19:00:40 - train: epoch 0074, iter [00250, 01251], lr: 0.001175, loss: 0.4432
2022-09-25 19:01:01 - train: epoch 0074, iter [00260, 01251], lr: 0.001175, loss: 0.4233
2022-09-25 19:01:21 - train: epoch 0074, iter [00270, 01251], lr: 0.001175, loss: 0.4401
2022-09-25 19:01:42 - train: epoch 0074, iter [00280, 01251], lr: 0.001175, loss: 0.4116
2022-09-25 19:02:02 - train: epoch 0074, iter [00290, 01251], lr: 0.001175, loss: 0.4097
2022-09-25 19:02:23 - train: epoch 0074, iter [00300, 01251], lr: 0.001175, loss: 0.4095
2022-09-25 19:02:43 - train: epoch 0074, iter [00310, 01251], lr: 0.001175, loss: 0.4266
2022-09-25 19:03:04 - train: epoch 0074, iter [00320, 01251], lr: 0.001175, loss: 0.4190
2022-09-25 19:03:25 - train: epoch 0074, iter [00330, 01251], lr: 0.001175, loss: 0.4102
2022-09-25 19:03:45 - train: epoch 0074, iter [00340, 01251], lr: 0.001175, loss: 0.4086
2022-09-25 19:04:06 - train: epoch 0074, iter [00350, 01251], lr: 0.001175, loss: 0.4235
2022-09-25 19:04:27 - train: epoch 0074, iter [00360, 01251], lr: 0.001175, loss: 0.4009
2022-09-25 19:04:47 - train: epoch 0074, iter [00370, 01251], lr: 0.001175, loss: 0.4278
2022-09-25 19:05:08 - train: epoch 0074, iter [00380, 01251], lr: 0.001175, loss: 0.4240
2022-09-25 19:05:28 - train: epoch 0074, iter [00390, 01251], lr: 0.001175, loss: 0.4031
2022-09-25 19:05:49 - train: epoch 0074, iter [00400, 01251], lr: 0.001175, loss: 0.4290
2022-09-25 19:06:09 - train: epoch 0074, iter [00410, 01251], lr: 0.001175, loss: 0.4138
2022-09-25 19:06:30 - train: epoch 0074, iter [00420, 01251], lr: 0.001175, loss: 0.4008
2022-09-25 19:06:51 - train: epoch 0074, iter [00430, 01251], lr: 0.001175, loss: 0.4107
2022-09-25 19:07:11 - train: epoch 0074, iter [00440, 01251], lr: 0.001175, loss: 0.4017
2022-09-25 19:07:32 - train: epoch 0074, iter [00450, 01251], lr: 0.001175, loss: 0.4218
2022-09-25 19:07:52 - train: epoch 0074, iter [00460, 01251], lr: 0.001175, loss: 0.4249
2022-09-25 19:08:13 - train: epoch 0074, iter [00470, 01251], lr: 0.001175, loss: 0.4083
2022-09-25 19:08:34 - train: epoch 0074, iter [00480, 01251], lr: 0.001175, loss: 0.4164
2022-09-25 19:08:54 - train: epoch 0074, iter [00490, 01251], lr: 0.001175, loss: 0.3984
2022-09-25 19:09:15 - train: epoch 0074, iter [00500, 01251], lr: 0.001175, loss: 0.4316
2022-09-25 19:09:35 - train: epoch 0074, iter [00510, 01251], lr: 0.001175, loss: 0.4095
2022-09-25 19:09:56 - train: epoch 0074, iter [00520, 01251], lr: 0.001175, loss: 0.4085
2022-09-25 19:10:16 - train: epoch 0074, iter [00530, 01251], lr: 0.001175, loss: 0.4288
2022-09-25 19:10:37 - train: epoch 0074, iter [00540, 01251], lr: 0.001175, loss: 0.4084
2022-09-25 19:10:57 - train: epoch 0074, iter [00550, 01251], lr: 0.001175, loss: 0.4259
2022-09-25 19:11:18 - train: epoch 0074, iter [00560, 01251], lr: 0.001175, loss: 0.4158
2022-09-25 19:11:38 - train: epoch 0074, iter [00570, 01251], lr: 0.001175, loss: 0.4157
2022-09-25 19:11:59 - train: epoch 0074, iter [00580, 01251], lr: 0.001175, loss: 0.4178
2022-09-25 19:12:20 - train: epoch 0074, iter [00590, 01251], lr: 0.001175, loss: 0.4219
2022-09-25 19:12:40 - train: epoch 0074, iter [00600, 01251], lr: 0.001175, loss: 0.4358
2022-09-25 19:13:01 - train: epoch 0074, iter [00610, 01251], lr: 0.001175, loss: 0.4312
2022-09-25 19:13:22 - train: epoch 0074, iter [00620, 01251], lr: 0.001175, loss: 0.4090
2022-09-25 19:13:42 - train: epoch 0074, iter [00630, 01251], lr: 0.001175, loss: 0.4133
2022-09-25 19:14:03 - train: epoch 0074, iter [00640, 01251], lr: 0.001175, loss: 0.4051
2022-09-25 19:14:23 - train: epoch 0074, iter [00650, 01251], lr: 0.001175, loss: 0.4143
2022-09-25 19:14:44 - train: epoch 0074, iter [00660, 01251], lr: 0.001175, loss: 0.4186
2022-09-25 19:15:05 - train: epoch 0074, iter [00670, 01251], lr: 0.001174, loss: 0.4058
2022-09-25 19:15:25 - train: epoch 0074, iter [00680, 01251], lr: 0.001174, loss: 0.4245
2022-09-25 19:15:46 - train: epoch 0074, iter [00690, 01251], lr: 0.001174, loss: 0.4250
2022-09-25 19:16:06 - train: epoch 0074, iter [00700, 01251], lr: 0.001174, loss: 0.4221
2022-09-25 19:16:26 - train: epoch 0074, iter [00710, 01251], lr: 0.001174, loss: 0.3842
2022-09-25 19:16:47 - train: epoch 0074, iter [00720, 01251], lr: 0.001174, loss: 0.4167
2022-09-25 19:17:07 - train: epoch 0074, iter [00730, 01251], lr: 0.001174, loss: 0.4210
2022-09-25 19:17:28 - train: epoch 0074, iter [00740, 01251], lr: 0.001174, loss: 0.4240
2022-09-25 19:17:49 - train: epoch 0074, iter [00750, 01251], lr: 0.001174, loss: 0.4295
2022-09-25 19:18:09 - train: epoch 0074, iter [00760, 01251], lr: 0.001174, loss: 0.4033
2022-09-25 19:18:30 - train: epoch 0074, iter [00770, 01251], lr: 0.001174, loss: 0.4202
2022-09-25 19:18:50 - train: epoch 0074, iter [00780, 01251], lr: 0.001174, loss: 0.4296
2022-09-25 19:19:11 - train: epoch 0074, iter [00790, 01251], lr: 0.001174, loss: 0.4060
2022-09-25 19:19:31 - train: epoch 0074, iter [00800, 01251], lr: 0.001174, loss: 0.4065
2022-09-25 19:19:52 - train: epoch 0074, iter [00810, 01251], lr: 0.001174, loss: 0.4127
2022-09-25 19:20:12 - train: epoch 0074, iter [00820, 01251], lr: 0.001174, loss: 0.4194
2022-09-25 19:20:33 - train: epoch 0074, iter [00830, 01251], lr: 0.001174, loss: 0.4173
2022-09-25 19:20:54 - train: epoch 0074, iter [00840, 01251], lr: 0.001174, loss: 0.4028
2022-09-25 19:21:14 - train: epoch 0074, iter [00850, 01251], lr: 0.001174, loss: 0.4055
2022-09-25 19:21:35 - train: epoch 0074, iter [00860, 01251], lr: 0.001174, loss: 0.4103
2022-09-25 19:21:55 - train: epoch 0074, iter [00870, 01251], lr: 0.001174, loss: 0.4059
2022-09-25 19:22:16 - train: epoch 0074, iter [00880, 01251], lr: 0.001174, loss: 0.4317
2022-09-25 19:22:36 - train: epoch 0074, iter [00890, 01251], lr: 0.001174, loss: 0.4431
2022-09-25 19:22:57 - train: epoch 0074, iter [00900, 01251], lr: 0.001174, loss: 0.4324
2022-09-25 19:23:17 - train: epoch 0074, iter [00910, 01251], lr: 0.001174, loss: 0.4229
2022-09-25 19:23:38 - train: epoch 0074, iter [00920, 01251], lr: 0.001174, loss: 0.4283
2022-09-25 19:23:58 - train: epoch 0074, iter [00930, 01251], lr: 0.001174, loss: 0.4249
2022-09-25 19:24:19 - train: epoch 0074, iter [00940, 01251], lr: 0.001174, loss: 0.4035
2022-09-25 19:24:39 - train: epoch 0074, iter [00950, 01251], lr: 0.001174, loss: 0.3878
2022-09-25 19:25:00 - train: epoch 0074, iter [00960, 01251], lr: 0.001174, loss: 0.4227
2022-09-25 19:25:21 - train: epoch 0074, iter [00970, 01251], lr: 0.001174, loss: 0.4260
2022-09-25 19:25:41 - train: epoch 0074, iter [00980, 01251], lr: 0.001174, loss: 0.4064
2022-09-25 19:26:02 - train: epoch 0074, iter [00990, 01251], lr: 0.001174, loss: 0.4022
2022-09-25 19:26:22 - train: epoch 0074, iter [01000, 01251], lr: 0.001174, loss: 0.4233
2022-09-25 19:26:43 - train: epoch 0074, iter [01010, 01251], lr: 0.001174, loss: 0.4341
2022-09-25 19:27:03 - train: epoch 0074, iter [01020, 01251], lr: 0.001174, loss: 0.4245
2022-09-25 19:27:24 - train: epoch 0074, iter [01030, 01251], lr: 0.001174, loss: 0.3978
2022-09-25 19:27:44 - train: epoch 0074, iter [01040, 01251], lr: 0.001174, loss: 0.4200
2022-09-25 19:28:05 - train: epoch 0074, iter [01050, 01251], lr: 0.001174, loss: 0.4122
2022-09-25 19:28:26 - train: epoch 0074, iter [01060, 01251], lr: 0.001174, loss: 0.4208
2022-09-25 19:28:46 - train: epoch 0074, iter [01070, 01251], lr: 0.001174, loss: 0.4241
2022-09-25 19:29:06 - train: epoch 0074, iter [01080, 01251], lr: 0.001174, loss: 0.4252
2022-09-25 19:29:27 - train: epoch 0074, iter [01090, 01251], lr: 0.001174, loss: 0.3998
2022-09-25 19:29:47 - train: epoch 0074, iter [01100, 01251], lr: 0.001174, loss: 0.4213
2022-09-25 19:30:08 - train: epoch 0074, iter [01110, 01251], lr: 0.001174, loss: 0.4233
2022-09-25 19:30:29 - train: epoch 0074, iter [01120, 01251], lr: 0.001174, loss: 0.3918
2022-09-25 19:30:49 - train: epoch 0074, iter [01130, 01251], lr: 0.001174, loss: 0.3983
2022-09-25 19:31:10 - train: epoch 0074, iter [01140, 01251], lr: 0.001174, loss: 0.4178
2022-09-25 19:31:30 - train: epoch 0074, iter [01150, 01251], lr: 0.001174, loss: 0.4084
2022-09-25 19:31:51 - train: epoch 0074, iter [01160, 01251], lr: 0.001174, loss: 0.4332
2022-09-25 19:32:11 - train: epoch 0074, iter [01170, 01251], lr: 0.001174, loss: 0.4055
2022-09-25 19:32:32 - train: epoch 0074, iter [01180, 01251], lr: 0.001174, loss: 0.4153
2022-09-25 19:32:52 - train: epoch 0074, iter [01190, 01251], lr: 0.001174, loss: 0.4263
2022-09-25 19:33:13 - train: epoch 0074, iter [01200, 01251], lr: 0.001174, loss: 0.4097
2022-09-25 19:33:33 - train: epoch 0074, iter [01210, 01251], lr: 0.001174, loss: 0.4258
2022-09-25 19:33:54 - train: epoch 0074, iter [01220, 01251], lr: 0.001174, loss: 0.4119
2022-09-25 19:34:14 - train: epoch 0074, iter [01230, 01251], lr: 0.001174, loss: 0.4029
2022-09-25 19:34:35 - train: epoch 0074, iter [01240, 01251], lr: 0.001174, loss: 0.3972
2022-09-25 19:34:55 - train: epoch 0074, iter [01250, 01251], lr: 0.001174, loss: 0.4180
2022-09-25 19:34:59 - train: epoch 074, train_loss: 0.4152
2022-09-25 19:35:03 - until epoch: 074, best_loss: 0.4152
2022-09-25 19:35:03 - epoch 075 lr: 0.001174
2022-09-25 19:35:40 - train: epoch 0075, iter [00010, 01251], lr: 0.001174, loss: 0.4191
2022-09-25 19:36:00 - train: epoch 0075, iter [00020, 01251], lr: 0.001174, loss: 0.4141
2022-09-25 19:36:20 - train: epoch 0075, iter [00030, 01251], lr: 0.001174, loss: 0.3916
2022-09-25 19:36:41 - train: epoch 0075, iter [00040, 01251], lr: 0.001174, loss: 0.4022
2022-09-25 19:37:01 - train: epoch 0075, iter [00050, 01251], lr: 0.001174, loss: 0.3963
2022-09-25 19:37:22 - train: epoch 0075, iter [00060, 01251], lr: 0.001174, loss: 0.4014
2022-09-25 19:37:42 - train: epoch 0075, iter [00070, 01251], lr: 0.001174, loss: 0.4125
2022-09-25 19:38:03 - train: epoch 0075, iter [00080, 01251], lr: 0.001174, loss: 0.4100
2022-09-25 19:38:23 - train: epoch 0075, iter [00090, 01251], lr: 0.001174, loss: 0.4295
2022-09-25 19:38:44 - train: epoch 0075, iter [00100, 01251], lr: 0.001174, loss: 0.4158
2022-09-25 19:39:04 - train: epoch 0075, iter [00110, 01251], lr: 0.001174, loss: 0.4383
2022-09-25 19:39:25 - train: epoch 0075, iter [00120, 01251], lr: 0.001174, loss: 0.4083
2022-09-25 19:39:45 - train: epoch 0075, iter [00130, 01251], lr: 0.001174, loss: 0.3988
2022-09-25 19:40:06 - train: epoch 0075, iter [00140, 01251], lr: 0.001174, loss: 0.4161
2022-09-25 19:40:26 - train: epoch 0075, iter [00150, 01251], lr: 0.001174, loss: 0.4221
2022-09-25 19:40:47 - train: epoch 0075, iter [00160, 01251], lr: 0.001174, loss: 0.4099
2022-09-25 19:41:07 - train: epoch 0075, iter [00170, 01251], lr: 0.001174, loss: 0.4268
2022-09-25 19:41:28 - train: epoch 0075, iter [00180, 01251], lr: 0.001174, loss: 0.4134
2022-09-25 19:41:48 - train: epoch 0075, iter [00190, 01251], lr: 0.001174, loss: 0.4088
2022-09-25 19:42:09 - train: epoch 0075, iter [00200, 01251], lr: 0.001174, loss: 0.4105
2022-09-25 19:42:29 - train: epoch 0075, iter [00210, 01251], lr: 0.001174, loss: 0.4106
2022-09-25 19:42:50 - train: epoch 0075, iter [00220, 01251], lr: 0.001174, loss: 0.4045
2022-09-25 19:43:10 - train: epoch 0075, iter [00230, 01251], lr: 0.001174, loss: 0.4194
2022-09-25 19:43:31 - train: epoch 0075, iter [00240, 01251], lr: 0.001173, loss: 0.4138
2022-09-25 19:43:51 - train: epoch 0075, iter [00250, 01251], lr: 0.001173, loss: 0.4210
2022-09-25 19:44:12 - train: epoch 0075, iter [00260, 01251], lr: 0.001173, loss: 0.4061
2022-09-25 19:44:32 - train: epoch 0075, iter [00270, 01251], lr: 0.001173, loss: 0.4298
2022-09-25 19:44:53 - train: epoch 0075, iter [00280, 01251], lr: 0.001173, loss: 0.4250
2022-09-25 19:45:13 - train: epoch 0075, iter [00290, 01251], lr: 0.001173, loss: 0.3997
2022-09-25 19:45:34 - train: epoch 0075, iter [00300, 01251], lr: 0.001173, loss: 0.4036
2022-09-25 19:45:55 - train: epoch 0075, iter [00310, 01251], lr: 0.001173, loss: 0.4403
2022-09-25 19:46:15 - train: epoch 0075, iter [00320, 01251], lr: 0.001173, loss: 0.4100
2022-09-25 19:46:36 - train: epoch 0075, iter [00330, 01251], lr: 0.001173, loss: 0.4172
2022-09-25 19:46:56 - train: epoch 0075, iter [00340, 01251], lr: 0.001173, loss: 0.4251
2022-09-25 19:47:16 - train: epoch 0075, iter [00350, 01251], lr: 0.001173, loss: 0.4266
2022-09-25 19:47:36 - train: epoch 0075, iter [00360, 01251], lr: 0.001173, loss: 0.4266
2022-09-25 19:47:57 - train: epoch 0075, iter [00370, 01251], lr: 0.001173, loss: 0.4106
2022-09-25 19:48:17 - train: epoch 0075, iter [00380, 01251], lr: 0.001173, loss: 0.4164
2022-09-25 19:48:38 - train: epoch 0075, iter [00390, 01251], lr: 0.001173, loss: 0.4176
2022-09-25 19:48:58 - train: epoch 0075, iter [00400, 01251], lr: 0.001173, loss: 0.4134
2022-09-25 19:49:19 - train: epoch 0075, iter [00410, 01251], lr: 0.001173, loss: 0.4207
2022-09-25 19:49:39 - train: epoch 0075, iter [00420, 01251], lr: 0.001173, loss: 0.4248
2022-09-25 19:50:00 - train: epoch 0075, iter [00430, 01251], lr: 0.001173, loss: 0.4077
2022-09-25 19:50:20 - train: epoch 0075, iter [00440, 01251], lr: 0.001173, loss: 0.4171
2022-09-25 19:50:41 - train: epoch 0075, iter [00450, 01251], lr: 0.001173, loss: 0.4121
2022-09-25 19:51:01 - train: epoch 0075, iter [00460, 01251], lr: 0.001173, loss: 0.4092
2022-09-25 19:51:22 - train: epoch 0075, iter [00470, 01251], lr: 0.001173, loss: 0.4193
2022-09-25 19:51:42 - train: epoch 0075, iter [00480, 01251], lr: 0.001173, loss: 0.4477
2022-09-25 19:52:02 - train: epoch 0075, iter [00490, 01251], lr: 0.001173, loss: 0.4202
2022-09-25 19:52:23 - train: epoch 0075, iter [00500, 01251], lr: 0.001173, loss: 0.4290
2022-09-25 19:52:44 - train: epoch 0075, iter [00510, 01251], lr: 0.001173, loss: 0.4261
2022-09-25 19:53:04 - train: epoch 0075, iter [00520, 01251], lr: 0.001173, loss: 0.3974
2022-09-25 19:53:25 - train: epoch 0075, iter [00530, 01251], lr: 0.001173, loss: 0.4018
2022-09-25 19:53:45 - train: epoch 0075, iter [00540, 01251], lr: 0.001173, loss: 0.4194
2022-09-25 19:54:05 - train: epoch 0075, iter [00550, 01251], lr: 0.001173, loss: 0.4290
2022-09-25 19:54:26 - train: epoch 0075, iter [00560, 01251], lr: 0.001173, loss: 0.4314
2022-09-25 19:54:46 - train: epoch 0075, iter [00570, 01251], lr: 0.001173, loss: 0.3937
2022-09-25 19:55:07 - train: epoch 0075, iter [00580, 01251], lr: 0.001173, loss: 0.4146
2022-09-25 19:55:27 - train: epoch 0075, iter [00590, 01251], lr: 0.001173, loss: 0.4033
2022-09-25 19:55:48 - train: epoch 0075, iter [00600, 01251], lr: 0.001173, loss: 0.4173
2022-09-25 19:56:08 - train: epoch 0075, iter [00610, 01251], lr: 0.001173, loss: 0.4234
2022-09-25 19:56:29 - train: epoch 0075, iter [00620, 01251], lr: 0.001173, loss: 0.3965
2022-09-25 19:56:49 - train: epoch 0075, iter [00630, 01251], lr: 0.001173, loss: 0.4091
2022-09-25 19:57:10 - train: epoch 0075, iter [00640, 01251], lr: 0.001173, loss: 0.4255
2022-09-25 19:57:30 - train: epoch 0075, iter [00650, 01251], lr: 0.001173, loss: 0.4114
2022-09-25 19:57:51 - train: epoch 0075, iter [00660, 01251], lr: 0.001173, loss: 0.4327
2022-09-25 19:58:11 - train: epoch 0075, iter [00670, 01251], lr: 0.001173, loss: 0.4185
2022-09-25 19:58:31 - train: epoch 0075, iter [00680, 01251], lr: 0.001173, loss: 0.4083
2022-09-25 19:58:52 - train: epoch 0075, iter [00690, 01251], lr: 0.001173, loss: 0.4274
2022-09-25 19:59:12 - train: epoch 0075, iter [00700, 01251], lr: 0.001173, loss: 0.4180
2022-09-25 19:59:33 - train: epoch 0075, iter [00710, 01251], lr: 0.001173, loss: 0.4113
2022-09-25 19:59:53 - train: epoch 0075, iter [00720, 01251], lr: 0.001173, loss: 0.4254
2022-09-25 20:00:13 - train: epoch 0075, iter [00730, 01251], lr: 0.001173, loss: 0.4025
2022-09-25 20:00:34 - train: epoch 0075, iter [00740, 01251], lr: 0.001173, loss: 0.4112
2022-09-25 20:00:54 - train: epoch 0075, iter [00750, 01251], lr: 0.001173, loss: 0.4118
2022-09-25 20:01:15 - train: epoch 0075, iter [00760, 01251], lr: 0.001173, loss: 0.4197
2022-09-25 20:01:35 - train: epoch 0075, iter [00770, 01251], lr: 0.001173, loss: 0.4225
2022-09-25 20:01:56 - train: epoch 0075, iter [00780, 01251], lr: 0.001173, loss: 0.4162
2022-09-25 20:02:16 - train: epoch 0075, iter [00790, 01251], lr: 0.001173, loss: 0.4311
2022-09-25 20:02:37 - train: epoch 0075, iter [00800, 01251], lr: 0.001173, loss: 0.4133
2022-09-25 20:02:58 - train: epoch 0075, iter [00810, 01251], lr: 0.001173, loss: 0.4144
2022-09-25 20:03:18 - train: epoch 0075, iter [00820, 01251], lr: 0.001173, loss: 0.4223
2022-09-25 20:03:38 - train: epoch 0075, iter [00830, 01251], lr: 0.001173, loss: 0.4110
2022-09-25 20:03:59 - train: epoch 0075, iter [00840, 01251], lr: 0.001173, loss: 0.4016
2022-09-25 20:04:20 - train: epoch 0075, iter [00850, 01251], lr: 0.001173, loss: 0.4238
2022-09-25 20:04:40 - train: epoch 0075, iter [00860, 01251], lr: 0.001173, loss: 0.4170
2022-09-25 20:05:01 - train: epoch 0075, iter [00870, 01251], lr: 0.001173, loss: 0.4166
2022-09-25 20:05:21 - train: epoch 0075, iter [00880, 01251], lr: 0.001173, loss: 0.4176
2022-09-25 20:05:42 - train: epoch 0075, iter [00890, 01251], lr: 0.001173, loss: 0.4236
2022-09-25 20:06:02 - train: epoch 0075, iter [00900, 01251], lr: 0.001173, loss: 0.4145
2022-09-25 20:06:23 - train: epoch 0075, iter [00910, 01251], lr: 0.001173, loss: 0.4102
2022-09-25 20:06:43 - train: epoch 0075, iter [00920, 01251], lr: 0.001173, loss: 0.3890
2022-09-25 20:07:04 - train: epoch 0075, iter [00930, 01251], lr: 0.001173, loss: 0.3946
2022-09-25 20:07:24 - train: epoch 0075, iter [00940, 01251], lr: 0.001173, loss: 0.4214
2022-09-25 20:07:45 - train: epoch 0075, iter [00950, 01251], lr: 0.001173, loss: 0.4019
2022-09-25 20:08:05 - train: epoch 0075, iter [00960, 01251], lr: 0.001173, loss: 0.4007
2022-09-25 20:08:26 - train: epoch 0075, iter [00970, 01251], lr: 0.001173, loss: 0.4089
2022-09-25 20:08:46 - train: epoch 0075, iter [00980, 01251], lr: 0.001173, loss: 0.4152
2022-09-25 20:09:07 - train: epoch 0075, iter [00990, 01251], lr: 0.001173, loss: 0.4325
2022-09-25 20:09:27 - train: epoch 0075, iter [01000, 01251], lr: 0.001173, loss: 0.4171
2022-09-25 20:09:48 - train: epoch 0075, iter [01010, 01251], lr: 0.001173, loss: 0.4020
2022-09-25 20:10:08 - train: epoch 0075, iter [01020, 01251], lr: 0.001173, loss: 0.4157
2022-09-25 20:10:29 - train: epoch 0075, iter [01030, 01251], lr: 0.001173, loss: 0.4112
2022-09-25 20:10:49 - train: epoch 0075, iter [01040, 01251], lr: 0.001172, loss: 0.4322
2022-09-25 20:11:10 - train: epoch 0075, iter [01050, 01251], lr: 0.001172, loss: 0.4042
2022-09-25 20:11:30 - train: epoch 0075, iter [01060, 01251], lr: 0.001172, loss: 0.4140
2022-09-25 20:11:51 - train: epoch 0075, iter [01070, 01251], lr: 0.001172, loss: 0.3994
2022-09-25 20:12:11 - train: epoch 0075, iter [01080, 01251], lr: 0.001172, loss: 0.4040
2022-09-25 20:12:32 - train: epoch 0075, iter [01090, 01251], lr: 0.001172, loss: 0.4018
2022-09-25 20:12:52 - train: epoch 0075, iter [01100, 01251], lr: 0.001172, loss: 0.3922
2022-09-25 20:13:13 - train: epoch 0075, iter [01110, 01251], lr: 0.001172, loss: 0.4034
2022-09-25 20:13:33 - train: epoch 0075, iter [01120, 01251], lr: 0.001172, loss: 0.4170
2022-09-25 20:13:54 - train: epoch 0075, iter [01130, 01251], lr: 0.001172, loss: 0.4105
2022-09-25 20:14:15 - train: epoch 0075, iter [01140, 01251], lr: 0.001172, loss: 0.4174
2022-09-25 20:14:35 - train: epoch 0075, iter [01150, 01251], lr: 0.001172, loss: 0.4063
2022-09-25 20:14:56 - train: epoch 0075, iter [01160, 01251], lr: 0.001172, loss: 0.4265
2022-09-25 20:15:16 - train: epoch 0075, iter [01170, 01251], lr: 0.001172, loss: 0.4237
2022-09-25 20:15:37 - train: epoch 0075, iter [01180, 01251], lr: 0.001172, loss: 0.4087
2022-09-25 20:15:57 - train: epoch 0075, iter [01190, 01251], lr: 0.001172, loss: 0.4169
2022-09-25 20:16:17 - train: epoch 0075, iter [01200, 01251], lr: 0.001172, loss: 0.3876
2022-09-25 20:16:38 - train: epoch 0075, iter [01210, 01251], lr: 0.001172, loss: 0.4284
2022-09-25 20:16:58 - train: epoch 0075, iter [01220, 01251], lr: 0.001172, loss: 0.4087
2022-09-25 20:17:19 - train: epoch 0075, iter [01230, 01251], lr: 0.001172, loss: 0.4042
2022-09-25 20:17:39 - train: epoch 0075, iter [01240, 01251], lr: 0.001172, loss: 0.3981
2022-09-25 20:17:59 - train: epoch 0075, iter [01250, 01251], lr: 0.001172, loss: 0.4002
2022-09-25 20:18:04 - train: epoch 075, train_loss: 0.4151
2022-09-25 20:18:09 - until epoch: 075, best_loss: 0.4151
2022-09-25 20:18:09 - epoch 076 lr: 0.001172
2022-09-25 20:18:45 - train: epoch 0076, iter [00010, 01251], lr: 0.001172, loss: 0.4222
2022-09-25 20:19:06 - train: epoch 0076, iter [00020, 01251], lr: 0.001172, loss: 0.4035
2022-09-25 20:19:26 - train: epoch 0076, iter [00030, 01251], lr: 0.001172, loss: 0.4066
2022-09-25 20:19:47 - train: epoch 0076, iter [00040, 01251], lr: 0.001172, loss: 0.4174
2022-09-25 20:20:07 - train: epoch 0076, iter [00050, 01251], lr: 0.001172, loss: 0.4342
2022-09-25 20:20:28 - train: epoch 0076, iter [00060, 01251], lr: 0.001172, loss: 0.4051
2022-09-25 20:20:49 - train: epoch 0076, iter [00070, 01251], lr: 0.001172, loss: 0.4132
2022-09-25 20:21:09 - train: epoch 0076, iter [00080, 01251], lr: 0.001172, loss: 0.4040
2022-09-25 20:21:30 - train: epoch 0076, iter [00090, 01251], lr: 0.001172, loss: 0.4201
2022-09-25 20:21:51 - train: epoch 0076, iter [00100, 01251], lr: 0.001172, loss: 0.4151
2022-09-25 20:22:11 - train: epoch 0076, iter [00110, 01251], lr: 0.001172, loss: 0.4361
2022-09-25 20:22:32 - train: epoch 0076, iter [00120, 01251], lr: 0.001172, loss: 0.4062
2022-09-25 20:22:52 - train: epoch 0076, iter [00130, 01251], lr: 0.001172, loss: 0.3957
2022-09-25 20:23:13 - train: epoch 0076, iter [00140, 01251], lr: 0.001172, loss: 0.4000
2022-09-25 20:23:33 - train: epoch 0076, iter [00150, 01251], lr: 0.001172, loss: 0.4143
2022-09-25 20:23:54 - train: epoch 0076, iter [00160, 01251], lr: 0.001172, loss: 0.4205
2022-09-25 20:24:15 - train: epoch 0076, iter [00170, 01251], lr: 0.001172, loss: 0.4068
2022-09-25 20:24:35 - train: epoch 0076, iter [00180, 01251], lr: 0.001172, loss: 0.4162
2022-09-25 20:24:56 - train: epoch 0076, iter [00190, 01251], lr: 0.001172, loss: 0.4169
2022-09-25 20:25:16 - train: epoch 0076, iter [00200, 01251], lr: 0.001172, loss: 0.4160
2022-09-25 20:25:37 - train: epoch 0076, iter [00210, 01251], lr: 0.001172, loss: 0.4203
2022-09-25 20:25:57 - train: epoch 0076, iter [00220, 01251], lr: 0.001172, loss: 0.4082
2022-09-25 20:26:18 - train: epoch 0076, iter [00230, 01251], lr: 0.001172, loss: 0.4236
2022-09-25 20:26:39 - train: epoch 0076, iter [00240, 01251], lr: 0.001172, loss: 0.4398
2022-09-25 20:26:59 - train: epoch 0076, iter [00250, 01251], lr: 0.001172, loss: 0.4245
2022-09-25 20:27:20 - train: epoch 0076, iter [00260, 01251], lr: 0.001172, loss: 0.4095
2022-09-25 20:27:40 - train: epoch 0076, iter [00270, 01251], lr: 0.001172, loss: 0.4304
2022-09-25 20:28:01 - train: epoch 0076, iter [00280, 01251], lr: 0.001172, loss: 0.4159
2022-09-25 20:28:22 - train: epoch 0076, iter [00290, 01251], lr: 0.001172, loss: 0.3997
2022-09-25 20:28:42 - train: epoch 0076, iter [00300, 01251], lr: 0.001172, loss: 0.4332
2022-09-25 20:29:03 - train: epoch 0076, iter [00310, 01251], lr: 0.001172, loss: 0.4146
2022-09-25 20:29:23 - train: epoch 0076, iter [00320, 01251], lr: 0.001172, loss: 0.4069
2022-09-25 20:29:44 - train: epoch 0076, iter [00330, 01251], lr: 0.001172, loss: 0.4030
2022-09-25 20:30:05 - train: epoch 0076, iter [00340, 01251], lr: 0.001172, loss: 0.4317
2022-09-25 20:30:25 - train: epoch 0076, iter [00350, 01251], lr: 0.001172, loss: 0.4301
2022-09-25 20:30:46 - train: epoch 0076, iter [00360, 01251], lr: 0.001172, loss: 0.4183
2022-09-25 20:31:07 - train: epoch 0076, iter [00370, 01251], lr: 0.001172, loss: 0.4093
2022-09-25 20:31:27 - train: epoch 0076, iter [00380, 01251], lr: 0.001172, loss: 0.4093
2022-09-25 20:31:48 - train: epoch 0076, iter [00390, 01251], lr: 0.001172, loss: 0.4217
2022-09-25 20:32:08 - train: epoch 0076, iter [00400, 01251], lr: 0.001172, loss: 0.4151
2022-09-25 20:32:29 - train: epoch 0076, iter [00410, 01251], lr: 0.001172, loss: 0.4104
2022-09-25 20:32:50 - train: epoch 0076, iter [00420, 01251], lr: 0.001172, loss: 0.4147
2022-09-25 20:33:10 - train: epoch 0076, iter [00430, 01251], lr: 0.001172, loss: 0.4090
2022-09-25 20:33:31 - train: epoch 0076, iter [00440, 01251], lr: 0.001172, loss: 0.4169
2022-09-25 20:33:51 - train: epoch 0076, iter [00450, 01251], lr: 0.001172, loss: 0.4100
2022-09-25 20:34:12 - train: epoch 0076, iter [00460, 01251], lr: 0.001172, loss: 0.4181
2022-09-25 20:34:32 - train: epoch 0076, iter [00470, 01251], lr: 0.001172, loss: 0.4307
2022-09-25 20:34:53 - train: epoch 0076, iter [00480, 01251], lr: 0.001172, loss: 0.4297
2022-09-25 20:35:14 - train: epoch 0076, iter [00490, 01251], lr: 0.001172, loss: 0.4208
2022-09-25 20:35:34 - train: epoch 0076, iter [00500, 01251], lr: 0.001172, loss: 0.4087
2022-09-25 20:35:54 - train: epoch 0076, iter [00510, 01251], lr: 0.001172, loss: 0.4165
2022-09-25 20:36:15 - train: epoch 0076, iter [00520, 01251], lr: 0.001172, loss: 0.4198
2022-09-25 20:36:35 - train: epoch 0076, iter [00530, 01251], lr: 0.001172, loss: 0.4226
2022-09-25 20:36:56 - train: epoch 0076, iter [00540, 01251], lr: 0.001172, loss: 0.4197
2022-09-25 20:37:17 - train: epoch 0076, iter [00550, 01251], lr: 0.001172, loss: 0.4175
2022-09-25 20:37:37 - train: epoch 0076, iter [00560, 01251], lr: 0.001172, loss: 0.4220
2022-09-25 20:37:57 - train: epoch 0076, iter [00570, 01251], lr: 0.001172, loss: 0.4119
2022-09-25 20:38:18 - train: epoch 0076, iter [00580, 01251], lr: 0.001171, loss: 0.4327
2022-09-25 20:38:38 - train: epoch 0076, iter [00590, 01251], lr: 0.001171, loss: 0.4156
2022-09-25 20:38:59 - train: epoch 0076, iter [00600, 01251], lr: 0.001171, loss: 0.4154
2022-09-25 20:39:20 - train: epoch 0076, iter [00610, 01251], lr: 0.001171, loss: 0.4155
2022-09-25 20:39:40 - train: epoch 0076, iter [00620, 01251], lr: 0.001171, loss: 0.4327
2022-09-25 20:40:01 - train: epoch 0076, iter [00630, 01251], lr: 0.001171, loss: 0.4097
2022-09-25 20:40:21 - train: epoch 0076, iter [00640, 01251], lr: 0.001171, loss: 0.4306
2022-09-25 20:40:42 - train: epoch 0076, iter [00650, 01251], lr: 0.001171, loss: 0.3967
2022-09-25 20:41:02 - train: epoch 0076, iter [00660, 01251], lr: 0.001171, loss: 0.4195
2022-09-25 20:41:23 - train: epoch 0076, iter [00670, 01251], lr: 0.001171, loss: 0.4276
2022-09-25 20:41:43 - train: epoch 0076, iter [00680, 01251], lr: 0.001171, loss: 0.4278
2022-09-25 20:42:04 - train: epoch 0076, iter [00690, 01251], lr: 0.001171, loss: 0.3986
2022-09-25 20:42:25 - train: epoch 0076, iter [00700, 01251], lr: 0.001171, loss: 0.4164
2022-09-25 20:42:45 - train: epoch 0076, iter [00710, 01251], lr: 0.001171, loss: 0.4025
2022-09-25 20:43:06 - train: epoch 0076, iter [00720, 01251], lr: 0.001171, loss: 0.4110
2022-09-25 20:43:26 - train: epoch 0076, iter [00730, 01251], lr: 0.001171, loss: 0.4059
2022-09-25 20:43:47 - train: epoch 0076, iter [00740, 01251], lr: 0.001171, loss: 0.4023
2022-09-25 20:44:07 - train: epoch 0076, iter [00750, 01251], lr: 0.001171, loss: 0.4073
2022-09-25 20:44:28 - train: epoch 0076, iter [00760, 01251], lr: 0.001171, loss: 0.4125
2022-09-25 20:44:49 - train: epoch 0076, iter [00770, 01251], lr: 0.001171, loss: 0.4225
2022-09-25 20:45:09 - train: epoch 0076, iter [00780, 01251], lr: 0.001171, loss: 0.4305
2022-09-25 20:45:29 - train: epoch 0076, iter [00790, 01251], lr: 0.001171, loss: 0.4114
2022-09-25 20:45:50 - train: epoch 0076, iter [00800, 01251], lr: 0.001171, loss: 0.4187
2022-09-25 20:46:10 - train: epoch 0076, iter [00810, 01251], lr: 0.001171, loss: 0.4273
2022-09-25 20:46:31 - train: epoch 0076, iter [00820, 01251], lr: 0.001171, loss: 0.4074
2022-09-25 20:46:51 - train: epoch 0076, iter [00830, 01251], lr: 0.001171, loss: 0.4171
2022-09-25 20:47:12 - train: epoch 0076, iter [00840, 01251], lr: 0.001171, loss: 0.4146
2022-09-25 20:47:32 - train: epoch 0076, iter [00850, 01251], lr: 0.001171, loss: 0.4066
2022-09-25 20:47:53 - train: epoch 0076, iter [00860, 01251], lr: 0.001171, loss: 0.4187
2022-09-25 20:48:13 - train: epoch 0076, iter [00870, 01251], lr: 0.001171, loss: 0.4129
2022-09-25 20:48:34 - train: epoch 0076, iter [00880, 01251], lr: 0.001171, loss: 0.4122
2022-09-25 20:48:54 - train: epoch 0076, iter [00890, 01251], lr: 0.001171, loss: 0.4269
2022-09-25 20:49:15 - train: epoch 0076, iter [00900, 01251], lr: 0.001171, loss: 0.4154
2022-09-25 20:49:35 - train: epoch 0076, iter [00910, 01251], lr: 0.001171, loss: 0.4158
2022-09-25 20:49:56 - train: epoch 0076, iter [00920, 01251], lr: 0.001171, loss: 0.4027
2022-09-25 20:50:16 - train: epoch 0076, iter [00930, 01251], lr: 0.001171, loss: 0.4047
2022-09-25 20:50:37 - train: epoch 0076, iter [00940, 01251], lr: 0.001171, loss: 0.4185
2022-09-25 20:50:57 - train: epoch 0076, iter [00950, 01251], lr: 0.001171, loss: 0.4254
2022-09-25 20:51:17 - train: epoch 0076, iter [00960, 01251], lr: 0.001171, loss: 0.4286
2022-09-25 20:51:38 - train: epoch 0076, iter [00970, 01251], lr: 0.001171, loss: 0.4327
2022-09-25 20:51:59 - train: epoch 0076, iter [00980, 01251], lr: 0.001171, loss: 0.4152
2022-09-25 20:52:19 - train: epoch 0076, iter [00990, 01251], lr: 0.001171, loss: 0.3948
2022-09-25 20:52:40 - train: epoch 0076, iter [01000, 01251], lr: 0.001171, loss: 0.4284
2022-09-25 20:53:00 - train: epoch 0076, iter [01010, 01251], lr: 0.001171, loss: 0.3891
2022-09-25 20:53:21 - train: epoch 0076, iter [01020, 01251], lr: 0.001171, loss: 0.4304
2022-09-25 20:53:41 - train: epoch 0076, iter [01030, 01251], lr: 0.001171, loss: 0.4150
2022-09-25 20:54:01 - train: epoch 0076, iter [01040, 01251], lr: 0.001171, loss: 0.3989
2022-09-25 20:54:22 - train: epoch 0076, iter [01050, 01251], lr: 0.001171, loss: 0.4170
2022-09-25 20:54:42 - train: epoch 0076, iter [01060, 01251], lr: 0.001171, loss: 0.4106
2022-09-25 20:55:03 - train: epoch 0076, iter [01070, 01251], lr: 0.001171, loss: 0.4158
2022-09-25 20:55:23 - train: epoch 0076, iter [01080, 01251], lr: 0.001171, loss: 0.4225
2022-09-25 20:55:44 - train: epoch 0076, iter [01090, 01251], lr: 0.001171, loss: 0.4084
2022-09-25 20:56:04 - train: epoch 0076, iter [01100, 01251], lr: 0.001171, loss: 0.4122
2022-09-25 20:56:25 - train: epoch 0076, iter [01110, 01251], lr: 0.001171, loss: 0.4309
2022-09-25 20:56:45 - train: epoch 0076, iter [01120, 01251], lr: 0.001171, loss: 0.4094
2022-09-25 20:57:06 - train: epoch 0076, iter [01130, 01251], lr: 0.001171, loss: 0.4005
2022-09-25 20:57:26 - train: epoch 0076, iter [01140, 01251], lr: 0.001171, loss: 0.4178
2022-09-25 20:57:47 - train: epoch 0076, iter [01150, 01251], lr: 0.001171, loss: 0.4166
2022-09-25 20:58:07 - train: epoch 0076, iter [01160, 01251], lr: 0.001171, loss: 0.4310
2022-09-25 20:58:28 - train: epoch 0076, iter [01170, 01251], lr: 0.001171, loss: 0.4057
2022-09-25 20:58:48 - train: epoch 0076, iter [01180, 01251], lr: 0.001171, loss: 0.4322
2022-09-25 20:59:09 - train: epoch 0076, iter [01190, 01251], lr: 0.001171, loss: 0.4219
2022-09-25 20:59:29 - train: epoch 0076, iter [01200, 01251], lr: 0.001171, loss: 0.4192
2022-09-25 20:59:50 - train: epoch 0076, iter [01210, 01251], lr: 0.001171, loss: 0.4290
2022-09-25 21:00:10 - train: epoch 0076, iter [01220, 01251], lr: 0.001171, loss: 0.4246
2022-09-25 21:00:31 - train: epoch 0076, iter [01230, 01251], lr: 0.001171, loss: 0.4246
2022-09-25 21:00:51 - train: epoch 0076, iter [01240, 01251], lr: 0.001171, loss: 0.4233
2022-09-25 21:01:11 - train: epoch 0076, iter [01250, 01251], lr: 0.001171, loss: 0.4047
2022-09-25 21:01:15 - train: epoch 076, train_loss: 0.4151
2022-09-25 21:01:20 - until epoch: 076, best_loss: 0.4151
2022-09-27 22:02:52 - epoch 077 lr: 0.001171
2022-09-27 22:03:34 - train: epoch 0077, iter [00010, 01251], lr: 0.001171, loss: 0.4223
2022-09-27 22:03:52 - train: epoch 0077, iter [00020, 01251], lr: 0.001171, loss: 0.4259
2022-09-27 22:04:10 - train: epoch 0077, iter [00030, 01251], lr: 0.001171, loss: 0.4224
2022-09-27 22:04:28 - train: epoch 0077, iter [00040, 01251], lr: 0.001171, loss: 0.4174
2022-09-27 22:04:45 - train: epoch 0077, iter [00050, 01251], lr: 0.001171, loss: 0.4150
2022-09-27 22:05:03 - train: epoch 0077, iter [00060, 01251], lr: 0.001171, loss: 0.4073
2022-09-27 22:05:21 - train: epoch 0077, iter [00070, 01251], lr: 0.001171, loss: 0.4048
2022-09-27 22:05:39 - train: epoch 0077, iter [00080, 01251], lr: 0.001171, loss: 0.4025
2022-09-27 22:05:56 - train: epoch 0077, iter [00090, 01251], lr: 0.001171, loss: 0.3939
2022-09-27 22:06:14 - train: epoch 0077, iter [00100, 01251], lr: 0.001171, loss: 0.4234
2022-09-27 22:06:32 - train: epoch 0077, iter [00110, 01251], lr: 0.001170, loss: 0.4180
2022-09-27 22:06:50 - train: epoch 0077, iter [00120, 01251], lr: 0.001170, loss: 0.4110
2022-09-27 22:07:08 - train: epoch 0077, iter [00130, 01251], lr: 0.001170, loss: 0.4037
2022-09-27 22:07:26 - train: epoch 0077, iter [00140, 01251], lr: 0.001170, loss: 0.3893
2022-09-27 22:07:44 - train: epoch 0077, iter [00150, 01251], lr: 0.001170, loss: 0.4187
2022-09-27 22:08:02 - train: epoch 0077, iter [00160, 01251], lr: 0.001170, loss: 0.4009
2022-09-27 22:08:20 - train: epoch 0077, iter [00170, 01251], lr: 0.001170, loss: 0.4130
2022-09-27 22:08:38 - train: epoch 0077, iter [00180, 01251], lr: 0.001170, loss: 0.3937
2022-09-27 22:08:56 - train: epoch 0077, iter [00190, 01251], lr: 0.001170, loss: 0.3973
2022-09-27 22:09:14 - train: epoch 0077, iter [00200, 01251], lr: 0.001170, loss: 0.4331
2022-09-27 22:09:32 - train: epoch 0077, iter [00210, 01251], lr: 0.001170, loss: 0.4100
2022-09-27 22:09:50 - train: epoch 0077, iter [00220, 01251], lr: 0.001170, loss: 0.4140
2022-09-27 22:10:08 - train: epoch 0077, iter [00230, 01251], lr: 0.001170, loss: 0.3986
2022-09-27 22:10:25 - train: epoch 0077, iter [00240, 01251], lr: 0.001170, loss: 0.4028
2022-09-27 22:10:43 - train: epoch 0077, iter [00250, 01251], lr: 0.001170, loss: 0.4306
2022-09-27 22:11:01 - train: epoch 0077, iter [00260, 01251], lr: 0.001170, loss: 0.4222
2022-09-27 22:11:19 - train: epoch 0077, iter [00270, 01251], lr: 0.001170, loss: 0.4017
2022-09-27 22:11:37 - train: epoch 0077, iter [00280, 01251], lr: 0.001170, loss: 0.4329
2022-09-27 22:11:55 - train: epoch 0077, iter [00290, 01251], lr: 0.001170, loss: 0.4142
2022-09-27 22:12:13 - train: epoch 0077, iter [00300, 01251], lr: 0.001170, loss: 0.3980
2022-09-27 22:12:31 - train: epoch 0077, iter [00310, 01251], lr: 0.001170, loss: 0.4171
2022-09-27 22:12:49 - train: epoch 0077, iter [00320, 01251], lr: 0.001170, loss: 0.4116
2022-09-27 22:13:07 - train: epoch 0077, iter [00330, 01251], lr: 0.001170, loss: 0.4226
2022-09-27 22:13:24 - train: epoch 0077, iter [00340, 01251], lr: 0.001170, loss: 0.4153
2022-09-27 22:13:42 - train: epoch 0077, iter [00350, 01251], lr: 0.001170, loss: 0.4311
2022-09-27 22:14:00 - train: epoch 0077, iter [00360, 01251], lr: 0.001170, loss: 0.4494
2022-09-27 22:14:17 - train: epoch 0077, iter [00370, 01251], lr: 0.001170, loss: 0.4210
2022-09-27 22:14:35 - train: epoch 0077, iter [00380, 01251], lr: 0.001170, loss: 0.4034
2022-09-27 22:14:53 - train: epoch 0077, iter [00390, 01251], lr: 0.001170, loss: 0.4216
2022-09-27 22:15:11 - train: epoch 0077, iter [00400, 01251], lr: 0.001170, loss: 0.4028
2022-09-27 22:15:29 - train: epoch 0077, iter [00410, 01251], lr: 0.001170, loss: 0.4159
2022-09-27 22:15:47 - train: epoch 0077, iter [00420, 01251], lr: 0.001170, loss: 0.4203
2022-09-27 22:16:05 - train: epoch 0077, iter [00430, 01251], lr: 0.001170, loss: 0.4312
2022-09-27 22:16:23 - train: epoch 0077, iter [00440, 01251], lr: 0.001170, loss: 0.3924
2022-09-27 22:16:41 - train: epoch 0077, iter [00450, 01251], lr: 0.001170, loss: 0.4146
2022-09-27 22:16:58 - train: epoch 0077, iter [00460, 01251], lr: 0.001170, loss: 0.4077
2022-09-27 22:17:16 - train: epoch 0077, iter [00470, 01251], lr: 0.001170, loss: 0.4274
2022-09-27 22:17:34 - train: epoch 0077, iter [00480, 01251], lr: 0.001170, loss: 0.4252
2022-09-27 22:17:52 - train: epoch 0077, iter [00490, 01251], lr: 0.001170, loss: 0.4271
2022-09-27 22:18:09 - train: epoch 0077, iter [00500, 01251], lr: 0.001170, loss: 0.4132
2022-09-27 22:18:27 - train: epoch 0077, iter [00510, 01251], lr: 0.001170, loss: 0.4266
2022-09-27 22:18:45 - train: epoch 0077, iter [00520, 01251], lr: 0.001170, loss: 0.4101
2022-09-27 22:19:03 - train: epoch 0077, iter [00530, 01251], lr: 0.001170, loss: 0.4015
2022-09-27 22:19:21 - train: epoch 0077, iter [00540, 01251], lr: 0.001170, loss: 0.4183
2022-09-27 22:19:38 - train: epoch 0077, iter [00550, 01251], lr: 0.001170, loss: 0.4212
2022-09-27 22:19:56 - train: epoch 0077, iter [00560, 01251], lr: 0.001170, loss: 0.4049
2022-09-27 22:20:14 - train: epoch 0077, iter [00570, 01251], lr: 0.001170, loss: 0.3956
2022-09-27 22:20:31 - train: epoch 0077, iter [00580, 01251], lr: 0.001170, loss: 0.4267
2022-09-27 22:20:49 - train: epoch 0077, iter [00590, 01251], lr: 0.001170, loss: 0.4272
2022-09-27 22:21:07 - train: epoch 0077, iter [00600, 01251], lr: 0.001170, loss: 0.4290
2022-09-27 22:21:25 - train: epoch 0077, iter [00610, 01251], lr: 0.001170, loss: 0.3964
2022-09-27 22:21:43 - train: epoch 0077, iter [00620, 01251], lr: 0.001170, loss: 0.4269
2022-09-27 22:22:00 - train: epoch 0077, iter [00630, 01251], lr: 0.001170, loss: 0.4128
2022-09-27 22:22:18 - train: epoch 0077, iter [00640, 01251], lr: 0.001170, loss: 0.3975
2022-09-27 22:22:36 - train: epoch 0077, iter [00650, 01251], lr: 0.001170, loss: 0.4259
2022-09-27 22:22:54 - train: epoch 0077, iter [00660, 01251], lr: 0.001170, loss: 0.4159
2022-09-27 22:23:12 - train: epoch 0077, iter [00670, 01251], lr: 0.001170, loss: 0.4157
2022-09-27 22:23:29 - train: epoch 0077, iter [00680, 01251], lr: 0.001170, loss: 0.3951
2022-09-27 22:23:47 - train: epoch 0077, iter [00690, 01251], lr: 0.001170, loss: 0.3970
2022-09-27 22:24:05 - train: epoch 0077, iter [00700, 01251], lr: 0.001170, loss: 0.3895
2022-09-27 22:24:23 - train: epoch 0077, iter [00710, 01251], lr: 0.001170, loss: 0.4204
2022-09-27 22:24:41 - train: epoch 0077, iter [00720, 01251], lr: 0.001170, loss: 0.4137
2022-09-27 22:24:59 - train: epoch 0077, iter [00730, 01251], lr: 0.001170, loss: 0.4210
2022-09-27 22:25:17 - train: epoch 0077, iter [00740, 01251], lr: 0.001170, loss: 0.4086
2022-09-27 22:25:34 - train: epoch 0077, iter [00750, 01251], lr: 0.001170, loss: 0.4129
2022-09-27 22:25:52 - train: epoch 0077, iter [00760, 01251], lr: 0.001170, loss: 0.4073
2022-09-27 22:26:10 - train: epoch 0077, iter [00770, 01251], lr: 0.001170, loss: 0.3925
2022-09-27 22:26:28 - train: epoch 0077, iter [00780, 01251], lr: 0.001170, loss: 0.4230
2022-09-27 22:26:46 - train: epoch 0077, iter [00790, 01251], lr: 0.001170, loss: 0.4307
2022-09-27 22:27:04 - train: epoch 0077, iter [00800, 01251], lr: 0.001170, loss: 0.3998
2022-09-27 22:27:22 - train: epoch 0077, iter [00810, 01251], lr: 0.001170, loss: 0.4138
2022-09-27 22:27:39 - train: epoch 0077, iter [00820, 01251], lr: 0.001170, loss: 0.4332
2022-09-27 22:27:57 - train: epoch 0077, iter [00830, 01251], lr: 0.001170, loss: 0.4147
2022-09-27 22:28:15 - train: epoch 0077, iter [00840, 01251], lr: 0.001170, loss: 0.4089
2022-09-27 22:28:33 - train: epoch 0077, iter [00850, 01251], lr: 0.001170, loss: 0.3911
2022-09-27 22:28:51 - train: epoch 0077, iter [00860, 01251], lr: 0.001170, loss: 0.4023
2022-09-27 22:29:08 - train: epoch 0077, iter [00870, 01251], lr: 0.001169, loss: 0.4136
2022-09-27 22:29:26 - train: epoch 0077, iter [00880, 01251], lr: 0.001169, loss: 0.4227
2022-09-27 22:29:44 - train: epoch 0077, iter [00890, 01251], lr: 0.001169, loss: 0.4378
2022-09-27 22:30:01 - train: epoch 0077, iter [00900, 01251], lr: 0.001169, loss: 0.4202
2022-09-27 22:30:19 - train: epoch 0077, iter [00910, 01251], lr: 0.001169, loss: 0.4375
2022-09-27 22:30:37 - train: epoch 0077, iter [00920, 01251], lr: 0.001169, loss: 0.4076
2022-09-27 22:30:55 - train: epoch 0077, iter [00930, 01251], lr: 0.001169, loss: 0.4124
2022-09-27 22:31:13 - train: epoch 0077, iter [00940, 01251], lr: 0.001169, loss: 0.4265
2022-09-27 22:31:31 - train: epoch 0077, iter [00950, 01251], lr: 0.001169, loss: 0.4118
2022-09-27 22:31:48 - train: epoch 0077, iter [00960, 01251], lr: 0.001169, loss: 0.4287
2022-09-27 22:32:06 - train: epoch 0077, iter [00970, 01251], lr: 0.001169, loss: 0.4141
2022-09-27 22:32:24 - train: epoch 0077, iter [00980, 01251], lr: 0.001169, loss: 0.4170
2022-09-27 22:32:41 - train: epoch 0077, iter [00990, 01251], lr: 0.001169, loss: 0.3982
2022-09-27 22:32:59 - train: epoch 0077, iter [01000, 01251], lr: 0.001169, loss: 0.4129
2022-09-27 22:33:17 - train: epoch 0077, iter [01010, 01251], lr: 0.001169, loss: 0.4053
2022-09-27 22:33:35 - train: epoch 0077, iter [01020, 01251], lr: 0.001169, loss: 0.4209
2022-09-27 22:33:53 - train: epoch 0077, iter [01030, 01251], lr: 0.001169, loss: 0.4043
2022-09-27 22:34:11 - train: epoch 0077, iter [01040, 01251], lr: 0.001169, loss: 0.4123
2022-09-27 22:34:28 - train: epoch 0077, iter [01050, 01251], lr: 0.001169, loss: 0.4013
2022-09-27 22:34:46 - train: epoch 0077, iter [01060, 01251], lr: 0.001169, loss: 0.4072
2022-09-27 22:35:04 - train: epoch 0077, iter [01070, 01251], lr: 0.001169, loss: 0.4216
2022-09-27 22:35:22 - train: epoch 0077, iter [01080, 01251], lr: 0.001169, loss: 0.4086
2022-09-27 22:35:39 - train: epoch 0077, iter [01090, 01251], lr: 0.001169, loss: 0.4056
2022-09-27 22:35:57 - train: epoch 0077, iter [01100, 01251], lr: 0.001169, loss: 0.4330
2022-09-27 22:36:15 - train: epoch 0077, iter [01110, 01251], lr: 0.001169, loss: 0.4064
2022-09-27 22:36:33 - train: epoch 0077, iter [01120, 01251], lr: 0.001169, loss: 0.4473
2022-09-27 22:36:51 - train: epoch 0077, iter [01130, 01251], lr: 0.001169, loss: 0.4149
2022-09-27 22:37:09 - train: epoch 0077, iter [01140, 01251], lr: 0.001169, loss: 0.3967
2022-09-27 22:37:26 - train: epoch 0077, iter [01150, 01251], lr: 0.001169, loss: 0.3938
2022-09-27 22:37:44 - train: epoch 0077, iter [01160, 01251], lr: 0.001169, loss: 0.4047
2022-09-27 22:38:02 - train: epoch 0077, iter [01170, 01251], lr: 0.001169, loss: 0.4141
2022-09-27 22:38:19 - train: epoch 0077, iter [01180, 01251], lr: 0.001169, loss: 0.3935
2022-09-27 22:38:37 - train: epoch 0077, iter [01190, 01251], lr: 0.001169, loss: 0.4337
2022-09-27 22:38:55 - train: epoch 0077, iter [01200, 01251], lr: 0.001169, loss: 0.4186
2022-09-27 22:39:13 - train: epoch 0077, iter [01210, 01251], lr: 0.001169, loss: 0.4154
2022-09-27 22:39:31 - train: epoch 0077, iter [01220, 01251], lr: 0.001169, loss: 0.4123
2022-09-27 22:39:48 - train: epoch 0077, iter [01230, 01251], lr: 0.001169, loss: 0.4275
2022-09-27 22:40:06 - train: epoch 0077, iter [01240, 01251], lr: 0.001169, loss: 0.3910
2022-09-27 22:40:23 - train: epoch 0077, iter [01250, 01251], lr: 0.001169, loss: 0.3999
2022-09-27 22:40:27 - train: epoch 077, train_loss: 0.4150
2022-09-27 22:40:30 - until epoch: 077, best_loss: 0.4150
2022-09-27 22:40:30 - epoch 078 lr: 0.001169
2022-09-27 22:41:03 - train: epoch 0078, iter [00010, 01251], lr: 0.001169, loss: 0.4345
2022-09-27 22:41:21 - train: epoch 0078, iter [00020, 01251], lr: 0.001169, loss: 0.4026
2022-09-27 22:41:39 - train: epoch 0078, iter [00030, 01251], lr: 0.001169, loss: 0.4169
2022-09-27 22:41:56 - train: epoch 0078, iter [00040, 01251], lr: 0.001169, loss: 0.4205
2022-09-27 22:42:14 - train: epoch 0078, iter [00050, 01251], lr: 0.001169, loss: 0.4090
2022-09-27 22:42:32 - train: epoch 0078, iter [00060, 01251], lr: 0.001169, loss: 0.4322
2022-09-27 22:42:50 - train: epoch 0078, iter [00070, 01251], lr: 0.001169, loss: 0.4361
2022-09-27 22:43:08 - train: epoch 0078, iter [00080, 01251], lr: 0.001169, loss: 0.4399
2022-09-27 22:43:26 - train: epoch 0078, iter [00090, 01251], lr: 0.001169, loss: 0.4270
2022-09-27 22:43:43 - train: epoch 0078, iter [00100, 01251], lr: 0.001169, loss: 0.4290
2022-09-27 22:44:01 - train: epoch 0078, iter [00110, 01251], lr: 0.001169, loss: 0.4179
2022-09-27 22:44:19 - train: epoch 0078, iter [00120, 01251], lr: 0.001169, loss: 0.4280
2022-09-27 22:44:37 - train: epoch 0078, iter [00130, 01251], lr: 0.001169, loss: 0.4258
2022-09-27 22:44:55 - train: epoch 0078, iter [00140, 01251], lr: 0.001169, loss: 0.4109
2022-09-27 22:45:13 - train: epoch 0078, iter [00150, 01251], lr: 0.001169, loss: 0.4091
2022-09-27 22:45:30 - train: epoch 0078, iter [00160, 01251], lr: 0.001169, loss: 0.4175
2022-09-27 22:45:48 - train: epoch 0078, iter [00170, 01251], lr: 0.001169, loss: 0.4108
2022-09-27 22:46:06 - train: epoch 0078, iter [00180, 01251], lr: 0.001169, loss: 0.4105
2022-09-27 22:46:24 - train: epoch 0078, iter [00190, 01251], lr: 0.001169, loss: 0.4104
2022-09-27 22:46:42 - train: epoch 0078, iter [00200, 01251], lr: 0.001169, loss: 0.4141
2022-09-27 22:47:00 - train: epoch 0078, iter [00210, 01251], lr: 0.001169, loss: 0.4021
2022-09-27 22:47:18 - train: epoch 0078, iter [00220, 01251], lr: 0.001169, loss: 0.4140
2022-09-27 22:47:36 - train: epoch 0078, iter [00230, 01251], lr: 0.001169, loss: 0.4325
2022-09-27 22:47:53 - train: epoch 0078, iter [00240, 01251], lr: 0.001169, loss: 0.4204
2022-09-27 22:48:11 - train: epoch 0078, iter [00250, 01251], lr: 0.001169, loss: 0.4221
2022-09-27 22:48:29 - train: epoch 0078, iter [00260, 01251], lr: 0.001169, loss: 0.4182
2022-09-27 22:48:47 - train: epoch 0078, iter [00270, 01251], lr: 0.001169, loss: 0.4231
2022-09-27 22:49:05 - train: epoch 0078, iter [00280, 01251], lr: 0.001169, loss: 0.4083
2022-09-27 22:49:23 - train: epoch 0078, iter [00290, 01251], lr: 0.001169, loss: 0.4149
2022-09-27 22:49:41 - train: epoch 0078, iter [00300, 01251], lr: 0.001169, loss: 0.4232
2022-09-27 22:49:58 - train: epoch 0078, iter [00310, 01251], lr: 0.001169, loss: 0.4124
2022-09-27 22:50:16 - train: epoch 0078, iter [00320, 01251], lr: 0.001169, loss: 0.4211
2022-09-27 22:50:34 - train: epoch 0078, iter [00330, 01251], lr: 0.001169, loss: 0.4063
2022-09-27 22:50:52 - train: epoch 0078, iter [00340, 01251], lr: 0.001169, loss: 0.4148
2022-09-27 22:51:10 - train: epoch 0078, iter [00350, 01251], lr: 0.001169, loss: 0.4034
2022-09-27 22:51:27 - train: epoch 0078, iter [00360, 01251], lr: 0.001169, loss: 0.4068
2022-09-27 22:51:45 - train: epoch 0078, iter [00370, 01251], lr: 0.001169, loss: 0.4148
2022-09-27 22:52:03 - train: epoch 0078, iter [00380, 01251], lr: 0.001168, loss: 0.4079
2022-09-27 22:52:21 - train: epoch 0078, iter [00390, 01251], lr: 0.001168, loss: 0.4175
2022-09-27 22:52:39 - train: epoch 0078, iter [00400, 01251], lr: 0.001168, loss: 0.4313
2022-09-27 22:52:56 - train: epoch 0078, iter [00410, 01251], lr: 0.001168, loss: 0.4060
2022-09-27 22:53:14 - train: epoch 0078, iter [00420, 01251], lr: 0.001168, loss: 0.4098
2022-09-27 22:53:32 - train: epoch 0078, iter [00430, 01251], lr: 0.001168, loss: 0.4098
2022-09-27 22:53:50 - train: epoch 0078, iter [00440, 01251], lr: 0.001168, loss: 0.4174
2022-09-27 22:54:08 - train: epoch 0078, iter [00450, 01251], lr: 0.001168, loss: 0.4343
2022-09-27 22:54:26 - train: epoch 0078, iter [00460, 01251], lr: 0.001168, loss: 0.4038
2022-09-27 22:54:44 - train: epoch 0078, iter [00470, 01251], lr: 0.001168, loss: 0.4019
2022-09-27 22:55:02 - train: epoch 0078, iter [00480, 01251], lr: 0.001168, loss: 0.4169
2022-09-27 22:55:19 - train: epoch 0078, iter [00490, 01251], lr: 0.001168, loss: 0.4213
2022-09-27 22:55:37 - train: epoch 0078, iter [00500, 01251], lr: 0.001168, loss: 0.4082
2022-09-27 22:55:55 - train: epoch 0078, iter [00510, 01251], lr: 0.001168, loss: 0.4161
2022-09-27 22:56:13 - train: epoch 0078, iter [00520, 01251], lr: 0.001168, loss: 0.4131
2022-09-27 22:56:31 - train: epoch 0078, iter [00530, 01251], lr: 0.001168, loss: 0.4178
2022-09-27 22:56:49 - train: epoch 0078, iter [00540, 01251], lr: 0.001168, loss: 0.4177
2022-09-27 22:57:06 - train: epoch 0078, iter [00550, 01251], lr: 0.001168, loss: 0.3783
2022-09-27 22:57:24 - train: epoch 0078, iter [00560, 01251], lr: 0.001168, loss: 0.4068
2022-09-27 22:57:42 - train: epoch 0078, iter [00570, 01251], lr: 0.001168, loss: 0.4194
2022-09-27 22:58:00 - train: epoch 0078, iter [00580, 01251], lr: 0.001168, loss: 0.4247
2022-09-27 22:58:18 - train: epoch 0078, iter [00590, 01251], lr: 0.001168, loss: 0.4150
2022-09-27 22:58:36 - train: epoch 0078, iter [00600, 01251], lr: 0.001168, loss: 0.4213
2022-09-27 22:58:54 - train: epoch 0078, iter [00610, 01251], lr: 0.001168, loss: 0.4183
2022-09-27 22:59:12 - train: epoch 0078, iter [00620, 01251], lr: 0.001168, loss: 0.3946
2022-09-27 22:59:30 - train: epoch 0078, iter [00630, 01251], lr: 0.001168, loss: 0.4312
2022-09-27 22:59:48 - train: epoch 0078, iter [00640, 01251], lr: 0.001168, loss: 0.4117
2022-09-27 23:00:06 - train: epoch 0078, iter [00650, 01251], lr: 0.001168, loss: 0.4324
2022-09-27 23:00:23 - train: epoch 0078, iter [00660, 01251], lr: 0.001168, loss: 0.4201
2022-09-27 23:00:41 - train: epoch 0078, iter [00670, 01251], lr: 0.001168, loss: 0.3939
2022-09-27 23:00:59 - train: epoch 0078, iter [00680, 01251], lr: 0.001168, loss: 0.4077
2022-09-27 23:01:17 - train: epoch 0078, iter [00690, 01251], lr: 0.001168, loss: 0.4014
2022-09-27 23:01:35 - train: epoch 0078, iter [00700, 01251], lr: 0.001168, loss: 0.4040
2022-09-27 23:01:53 - train: epoch 0078, iter [00710, 01251], lr: 0.001168, loss: 0.4175
2022-09-27 23:02:11 - train: epoch 0078, iter [00720, 01251], lr: 0.001168, loss: 0.3989
2022-09-27 23:02:29 - train: epoch 0078, iter [00730, 01251], lr: 0.001168, loss: 0.4285
2022-09-27 23:02:47 - train: epoch 0078, iter [00740, 01251], lr: 0.001168, loss: 0.4109
2022-09-27 23:03:05 - train: epoch 0078, iter [00750, 01251], lr: 0.001168, loss: 0.4234
2022-09-27 23:03:23 - train: epoch 0078, iter [00760, 01251], lr: 0.001168, loss: 0.4118
2022-09-27 23:03:40 - train: epoch 0078, iter [00770, 01251], lr: 0.001168, loss: 0.4191
2022-09-27 23:03:58 - train: epoch 0078, iter [00780, 01251], lr: 0.001168, loss: 0.4070
2022-09-27 23:04:16 - train: epoch 0078, iter [00790, 01251], lr: 0.001168, loss: 0.4091
2022-09-27 23:04:34 - train: epoch 0078, iter [00800, 01251], lr: 0.001168, loss: 0.4023
2022-09-27 23:04:51 - train: epoch 0078, iter [00810, 01251], lr: 0.001168, loss: 0.4323
2022-09-27 23:05:09 - train: epoch 0078, iter [00820, 01251], lr: 0.001168, loss: 0.3912
2022-09-27 23:05:27 - train: epoch 0078, iter [00830, 01251], lr: 0.001168, loss: 0.3973
2022-09-27 23:05:45 - train: epoch 0078, iter [00840, 01251], lr: 0.001168, loss: 0.3973
2022-09-27 23:06:03 - train: epoch 0078, iter [00850, 01251], lr: 0.001168, loss: 0.4278
2022-09-27 23:06:21 - train: epoch 0078, iter [00860, 01251], lr: 0.001168, loss: 0.4276
2022-09-27 23:06:39 - train: epoch 0078, iter [00870, 01251], lr: 0.001168, loss: 0.4118
2022-09-27 23:06:56 - train: epoch 0078, iter [00880, 01251], lr: 0.001168, loss: 0.3970
2022-09-27 23:07:14 - train: epoch 0078, iter [00890, 01251], lr: 0.001168, loss: 0.4189
2022-09-27 23:07:32 - train: epoch 0078, iter [00900, 01251], lr: 0.001168, loss: 0.4357
2022-09-27 23:07:50 - train: epoch 0078, iter [00910, 01251], lr: 0.001168, loss: 0.4086
2022-09-27 23:08:08 - train: epoch 0078, iter [00920, 01251], lr: 0.001168, loss: 0.4250
2022-09-27 23:08:26 - train: epoch 0078, iter [00930, 01251], lr: 0.001168, loss: 0.4201
2022-09-27 23:08:43 - train: epoch 0078, iter [00940, 01251], lr: 0.001168, loss: 0.4235
2022-09-27 23:09:01 - train: epoch 0078, iter [00950, 01251], lr: 0.001168, loss: 0.4297
2022-09-27 23:09:19 - train: epoch 0078, iter [00960, 01251], lr: 0.001168, loss: 0.4138
2022-09-27 23:09:37 - train: epoch 0078, iter [00970, 01251], lr: 0.001168, loss: 0.4074
2022-09-27 23:09:54 - train: epoch 0078, iter [00980, 01251], lr: 0.001168, loss: 0.4106
2022-09-27 23:10:12 - train: epoch 0078, iter [00990, 01251], lr: 0.001168, loss: 0.4237
2022-09-27 23:10:30 - train: epoch 0078, iter [01000, 01251], lr: 0.001168, loss: 0.4061
2022-09-27 23:10:48 - train: epoch 0078, iter [01010, 01251], lr: 0.001168, loss: 0.3945
2022-09-27 23:11:06 - train: epoch 0078, iter [01020, 01251], lr: 0.001168, loss: 0.4260
2022-09-27 23:11:23 - train: epoch 0078, iter [01030, 01251], lr: 0.001168, loss: 0.4181
2022-09-27 23:11:41 - train: epoch 0078, iter [01040, 01251], lr: 0.001168, loss: 0.4295
2022-09-27 23:11:59 - train: epoch 0078, iter [01050, 01251], lr: 0.001168, loss: 0.4189
2022-09-27 23:12:17 - train: epoch 0078, iter [01060, 01251], lr: 0.001168, loss: 0.4020
2022-09-27 23:12:35 - train: epoch 0078, iter [01070, 01251], lr: 0.001168, loss: 0.4081
2022-09-27 23:12:53 - train: epoch 0078, iter [01080, 01251], lr: 0.001168, loss: 0.4068
2022-09-27 23:13:10 - train: epoch 0078, iter [01090, 01251], lr: 0.001168, loss: 0.4181
2022-09-27 23:13:28 - train: epoch 0078, iter [01100, 01251], lr: 0.001168, loss: 0.4305
2022-09-27 23:13:46 - train: epoch 0078, iter [01110, 01251], lr: 0.001168, loss: 0.4193
2022-09-27 23:14:04 - train: epoch 0078, iter [01120, 01251], lr: 0.001167, loss: 0.4006
2022-09-27 23:14:21 - train: epoch 0078, iter [01130, 01251], lr: 0.001167, loss: 0.4311
2022-09-27 23:14:39 - train: epoch 0078, iter [01140, 01251], lr: 0.001167, loss: 0.4227
2022-09-27 23:14:57 - train: epoch 0078, iter [01150, 01251], lr: 0.001167, loss: 0.4063
2022-09-27 23:15:15 - train: epoch 0078, iter [01160, 01251], lr: 0.001167, loss: 0.4085
2022-09-27 23:15:33 - train: epoch 0078, iter [01170, 01251], lr: 0.001167, loss: 0.3982
2022-09-27 23:15:51 - train: epoch 0078, iter [01180, 01251], lr: 0.001167, loss: 0.4217
2022-09-27 23:16:08 - train: epoch 0078, iter [01190, 01251], lr: 0.001167, loss: 0.4135
2022-09-27 23:16:26 - train: epoch 0078, iter [01200, 01251], lr: 0.001167, loss: 0.4200
2022-09-27 23:16:44 - train: epoch 0078, iter [01210, 01251], lr: 0.001167, loss: 0.4116
2022-09-27 23:17:02 - train: epoch 0078, iter [01220, 01251], lr: 0.001167, loss: 0.4215
2022-09-27 23:17:20 - train: epoch 0078, iter [01230, 01251], lr: 0.001167, loss: 0.4298
2022-09-27 23:17:38 - train: epoch 0078, iter [01240, 01251], lr: 0.001167, loss: 0.4180
2022-09-27 23:17:55 - train: epoch 0078, iter [01250, 01251], lr: 0.001167, loss: 0.4085
2022-09-27 23:17:59 - train: epoch 078, train_loss: 0.4148
2022-09-27 23:18:01 - until epoch: 078, best_loss: 0.4148
2022-09-27 23:18:01 - epoch 079 lr: 0.001167
2022-09-27 23:18:35 - train: epoch 0079, iter [00010, 01251], lr: 0.001167, loss: 0.4273
2022-09-27 23:18:52 - train: epoch 0079, iter [00020, 01251], lr: 0.001167, loss: 0.3983
2022-09-27 23:19:10 - train: epoch 0079, iter [00030, 01251], lr: 0.001167, loss: 0.4195
2022-09-27 23:19:28 - train: epoch 0079, iter [00040, 01251], lr: 0.001167, loss: 0.3904
2022-09-27 23:19:46 - train: epoch 0079, iter [00050, 01251], lr: 0.001167, loss: 0.4208
2022-09-27 23:20:04 - train: epoch 0079, iter [00060, 01251], lr: 0.001167, loss: 0.4157
2022-09-27 23:20:22 - train: epoch 0079, iter [00070, 01251], lr: 0.001167, loss: 0.4126
2022-09-27 23:20:39 - train: epoch 0079, iter [00080, 01251], lr: 0.001167, loss: 0.4191
2022-09-27 23:20:57 - train: epoch 0079, iter [00090, 01251], lr: 0.001167, loss: 0.4112
2022-09-27 23:21:15 - train: epoch 0079, iter [00100, 01251], lr: 0.001167, loss: 0.4041
2022-09-27 23:21:33 - train: epoch 0079, iter [00110, 01251], lr: 0.001167, loss: 0.4253
2022-09-27 23:21:51 - train: epoch 0079, iter [00120, 01251], lr: 0.001167, loss: 0.3924
2022-09-27 23:22:08 - train: epoch 0079, iter [00130, 01251], lr: 0.001167, loss: 0.4140
2022-09-27 23:22:26 - train: epoch 0079, iter [00140, 01251], lr: 0.001167, loss: 0.4243
2022-09-27 23:22:44 - train: epoch 0079, iter [00150, 01251], lr: 0.001167, loss: 0.4172
2022-09-27 23:23:01 - train: epoch 0079, iter [00160, 01251], lr: 0.001167, loss: 0.4263
2022-09-27 23:23:19 - train: epoch 0079, iter [00170, 01251], lr: 0.001167, loss: 0.4252
2022-09-27 23:23:37 - train: epoch 0079, iter [00180, 01251], lr: 0.001167, loss: 0.4197
2022-09-27 23:23:55 - train: epoch 0079, iter [00190, 01251], lr: 0.001167, loss: 0.4310
2022-09-27 23:24:13 - train: epoch 0079, iter [00200, 01251], lr: 0.001167, loss: 0.4209
2022-09-27 23:24:31 - train: epoch 0079, iter [00210, 01251], lr: 0.001167, loss: 0.4169
2022-09-27 23:24:48 - train: epoch 0079, iter [00220, 01251], lr: 0.001167, loss: 0.4132
2022-09-27 23:25:06 - train: epoch 0079, iter [00230, 01251], lr: 0.001167, loss: 0.4214
2022-09-27 23:25:24 - train: epoch 0079, iter [00240, 01251], lr: 0.001167, loss: 0.4217
2022-09-27 23:25:42 - train: epoch 0079, iter [00250, 01251], lr: 0.001167, loss: 0.4287
2022-09-27 23:26:00 - train: epoch 0079, iter [00260, 01251], lr: 0.001167, loss: 0.4037
2022-09-27 23:26:17 - train: epoch 0079, iter [00270, 01251], lr: 0.001167, loss: 0.4111
2022-09-27 23:26:35 - train: epoch 0079, iter [00280, 01251], lr: 0.001167, loss: 0.4128
2022-09-27 23:26:53 - train: epoch 0079, iter [00290, 01251], lr: 0.001167, loss: 0.4083
2022-09-27 23:27:11 - train: epoch 0079, iter [00300, 01251], lr: 0.001167, loss: 0.4147
2022-09-27 23:27:29 - train: epoch 0079, iter [00310, 01251], lr: 0.001167, loss: 0.4288
2022-09-27 23:27:47 - train: epoch 0079, iter [00320, 01251], lr: 0.001167, loss: 0.4415
2022-09-27 23:28:05 - train: epoch 0079, iter [00330, 01251], lr: 0.001167, loss: 0.4338
2022-09-27 23:28:23 - train: epoch 0079, iter [00340, 01251], lr: 0.001167, loss: 0.4142
2022-09-27 23:28:40 - train: epoch 0079, iter [00350, 01251], lr: 0.001167, loss: 0.4254
2022-09-27 23:28:58 - train: epoch 0079, iter [00360, 01251], lr: 0.001167, loss: 0.4204
2022-09-27 23:29:16 - train: epoch 0079, iter [00370, 01251], lr: 0.001167, loss: 0.4211
2022-09-27 23:29:34 - train: epoch 0079, iter [00380, 01251], lr: 0.001167, loss: 0.4075
2022-09-27 23:29:51 - train: epoch 0079, iter [00390, 01251], lr: 0.001167, loss: 0.4146
2022-09-27 23:30:09 - train: epoch 0079, iter [00400, 01251], lr: 0.001167, loss: 0.4206
2022-09-27 23:30:27 - train: epoch 0079, iter [00410, 01251], lr: 0.001167, loss: 0.3923
2022-09-27 23:30:45 - train: epoch 0079, iter [00420, 01251], lr: 0.001167, loss: 0.4218
2022-09-27 23:31:03 - train: epoch 0079, iter [00430, 01251], lr: 0.001167, loss: 0.4144
2022-09-27 23:31:21 - train: epoch 0079, iter [00440, 01251], lr: 0.001167, loss: 0.4049
2022-09-27 23:31:39 - train: epoch 0079, iter [00450, 01251], lr: 0.001167, loss: 0.4097
2022-09-27 23:31:56 - train: epoch 0079, iter [00460, 01251], lr: 0.001167, loss: 0.4133
2022-09-27 23:32:14 - train: epoch 0079, iter [00470, 01251], lr: 0.001167, loss: 0.4019
2022-09-27 23:32:32 - train: epoch 0079, iter [00480, 01251], lr: 0.001167, loss: 0.3966
2022-09-27 23:32:50 - train: epoch 0079, iter [00490, 01251], lr: 0.001167, loss: 0.3973
2022-09-27 23:33:08 - train: epoch 0079, iter [00500, 01251], lr: 0.001167, loss: 0.4457
2022-09-27 23:33:26 - train: epoch 0079, iter [00510, 01251], lr: 0.001167, loss: 0.4119
2022-09-27 23:33:43 - train: epoch 0079, iter [00520, 01251], lr: 0.001167, loss: 0.4262
2022-09-27 23:34:01 - train: epoch 0079, iter [00530, 01251], lr: 0.001167, loss: 0.4319
2022-09-27 23:34:19 - train: epoch 0079, iter [00540, 01251], lr: 0.001167, loss: 0.4188
2022-09-27 23:34:37 - train: epoch 0079, iter [00550, 01251], lr: 0.001167, loss: 0.4201
2022-09-27 23:34:55 - train: epoch 0079, iter [00560, 01251], lr: 0.001167, loss: 0.4234
2022-09-27 23:35:12 - train: epoch 0079, iter [00570, 01251], lr: 0.001167, loss: 0.4033
2022-09-27 23:35:30 - train: epoch 0079, iter [00580, 01251], lr: 0.001167, loss: 0.4123
2022-09-27 23:35:48 - train: epoch 0079, iter [00590, 01251], lr: 0.001167, loss: 0.4235
2022-09-27 23:36:06 - train: epoch 0079, iter [00600, 01251], lr: 0.001166, loss: 0.4239
2022-09-27 23:36:24 - train: epoch 0079, iter [00610, 01251], lr: 0.001166, loss: 0.4166
2022-09-27 23:36:42 - train: epoch 0079, iter [00620, 01251], lr: 0.001166, loss: 0.4029
2022-09-27 23:37:00 - train: epoch 0079, iter [00630, 01251], lr: 0.001166, loss: 0.4140
2022-09-27 23:37:18 - train: epoch 0079, iter [00640, 01251], lr: 0.001166, loss: 0.4337
2022-09-27 23:37:36 - train: epoch 0079, iter [00650, 01251], lr: 0.001166, loss: 0.4081
2022-09-27 23:37:54 - train: epoch 0079, iter [00660, 01251], lr: 0.001166, loss: 0.4063
2022-09-27 23:38:12 - train: epoch 0079, iter [00670, 01251], lr: 0.001166, loss: 0.4194
2022-09-27 23:38:30 - train: epoch 0079, iter [00680, 01251], lr: 0.001166, loss: 0.3986
2022-09-27 23:38:48 - train: epoch 0079, iter [00690, 01251], lr: 0.001166, loss: 0.4110
2022-09-27 23:39:06 - train: epoch 0079, iter [00700, 01251], lr: 0.001166, loss: 0.3974
2022-09-27 23:39:24 - train: epoch 0079, iter [00710, 01251], lr: 0.001166, loss: 0.4125
2022-09-27 23:39:41 - train: epoch 0079, iter [00720, 01251], lr: 0.001166, loss: 0.4076
2022-09-27 23:39:59 - train: epoch 0079, iter [00730, 01251], lr: 0.001166, loss: 0.4250
2022-09-27 23:40:17 - train: epoch 0079, iter [00740, 01251], lr: 0.001166, loss: 0.4063
2022-09-27 23:40:35 - train: epoch 0079, iter [00750, 01251], lr: 0.001166, loss: 0.4016
2022-09-27 23:40:53 - train: epoch 0079, iter [00760, 01251], lr: 0.001166, loss: 0.4191
2022-09-27 23:41:11 - train: epoch 0079, iter [00770, 01251], lr: 0.001166, loss: 0.4230
2022-09-27 23:41:29 - train: epoch 0079, iter [00780, 01251], lr: 0.001166, loss: 0.4027
2022-09-27 23:41:46 - train: epoch 0079, iter [00790, 01251], lr: 0.001166, loss: 0.4034
2022-09-27 23:42:04 - train: epoch 0079, iter [00800, 01251], lr: 0.001166, loss: 0.3939
2022-09-27 23:42:22 - train: epoch 0079, iter [00810, 01251], lr: 0.001166, loss: 0.4147
2022-09-27 23:42:40 - train: epoch 0079, iter [00820, 01251], lr: 0.001166, loss: 0.4053
2022-09-27 23:42:58 - train: epoch 0079, iter [00830, 01251], lr: 0.001166, loss: 0.4209
2022-09-27 23:43:16 - train: epoch 0079, iter [00840, 01251], lr: 0.001166, loss: 0.4040
2022-09-27 23:43:34 - train: epoch 0079, iter [00850, 01251], lr: 0.001166, loss: 0.3888
2022-09-27 23:43:52 - train: epoch 0079, iter [00860, 01251], lr: 0.001166, loss: 0.4220
2022-09-27 23:44:10 - train: epoch 0079, iter [00870, 01251], lr: 0.001166, loss: 0.4013
2022-09-27 23:44:28 - train: epoch 0079, iter [00880, 01251], lr: 0.001166, loss: 0.4283
2022-09-27 23:44:46 - train: epoch 0079, iter [00890, 01251], lr: 0.001166, loss: 0.4104
2022-09-27 23:45:03 - train: epoch 0079, iter [00900, 01251], lr: 0.001166, loss: 0.4115
2022-09-27 23:45:21 - train: epoch 0079, iter [00910, 01251], lr: 0.001166, loss: 0.4125
2022-09-27 23:45:39 - train: epoch 0079, iter [00920, 01251], lr: 0.001166, loss: 0.4117
2022-09-27 23:45:57 - train: epoch 0079, iter [00930, 01251], lr: 0.001166, loss: 0.4058
2022-09-27 23:46:15 - train: epoch 0079, iter [00940, 01251], lr: 0.001166, loss: 0.4035
2022-09-27 23:46:33 - train: epoch 0079, iter [00950, 01251], lr: 0.001166, loss: 0.4003
2022-09-27 23:46:51 - train: epoch 0079, iter [00960, 01251], lr: 0.001166, loss: 0.3973
2022-09-27 23:47:09 - train: epoch 0079, iter [00970, 01251], lr: 0.001166, loss: 0.4191
2022-09-27 23:47:27 - train: epoch 0079, iter [00980, 01251], lr: 0.001166, loss: 0.4200
2022-09-27 23:47:45 - train: epoch 0079, iter [00990, 01251], lr: 0.001166, loss: 0.4122
2022-09-27 23:48:03 - train: epoch 0079, iter [01000, 01251], lr: 0.001166, loss: 0.4148
2022-09-27 23:48:21 - train: epoch 0079, iter [01010, 01251], lr: 0.001166, loss: 0.4157
2022-09-27 23:48:39 - train: epoch 0079, iter [01020, 01251], lr: 0.001166, loss: 0.4267
2022-09-27 23:48:56 - train: epoch 0079, iter [01030, 01251], lr: 0.001166, loss: 0.4232
2022-09-27 23:49:14 - train: epoch 0079, iter [01040, 01251], lr: 0.001166, loss: 0.4250
2022-09-27 23:49:32 - train: epoch 0079, iter [01050, 01251], lr: 0.001166, loss: 0.4340
2022-09-27 23:49:50 - train: epoch 0079, iter [01060, 01251], lr: 0.001166, loss: 0.3933
2022-09-27 23:50:08 - train: epoch 0079, iter [01070, 01251], lr: 0.001166, loss: 0.4375
2022-09-27 23:50:26 - train: epoch 0079, iter [01080, 01251], lr: 0.001166, loss: 0.4322
2022-09-27 23:50:44 - train: epoch 0079, iter [01090, 01251], lr: 0.001166, loss: 0.4023
2022-09-27 23:51:02 - train: epoch 0079, iter [01100, 01251], lr: 0.001166, loss: 0.4114
2022-09-27 23:51:19 - train: epoch 0079, iter [01110, 01251], lr: 0.001166, loss: 0.4052
2022-09-27 23:51:37 - train: epoch 0079, iter [01120, 01251], lr: 0.001166, loss: 0.4070
2022-09-27 23:51:55 - train: epoch 0079, iter [01130, 01251], lr: 0.001166, loss: 0.4110
2022-09-27 23:52:13 - train: epoch 0079, iter [01140, 01251], lr: 0.001166, loss: 0.3971
2022-09-27 23:52:31 - train: epoch 0079, iter [01150, 01251], lr: 0.001166, loss: 0.4086
2022-09-27 23:52:49 - train: epoch 0079, iter [01160, 01251], lr: 0.001166, loss: 0.4053
2022-09-27 23:53:07 - train: epoch 0079, iter [01170, 01251], lr: 0.001166, loss: 0.4114
2022-09-27 23:53:25 - train: epoch 0079, iter [01180, 01251], lr: 0.001166, loss: 0.4333
2022-09-27 23:53:43 - train: epoch 0079, iter [01190, 01251], lr: 0.001166, loss: 0.4098
2022-09-27 23:54:01 - train: epoch 0079, iter [01200, 01251], lr: 0.001166, loss: 0.4021
2022-09-27 23:54:19 - train: epoch 0079, iter [01210, 01251], lr: 0.001166, loss: 0.4270
2022-09-27 23:54:36 - train: epoch 0079, iter [01220, 01251], lr: 0.001166, loss: 0.4296
2022-09-27 23:54:54 - train: epoch 0079, iter [01230, 01251], lr: 0.001166, loss: 0.4202
2022-09-27 23:55:12 - train: epoch 0079, iter [01240, 01251], lr: 0.001166, loss: 0.4263
2022-09-27 23:55:29 - train: epoch 0079, iter [01250, 01251], lr: 0.001166, loss: 0.4228
2022-09-27 23:55:33 - train: epoch 079, train_loss: 0.4147
2022-09-27 23:55:35 - until epoch: 079, best_loss: 0.4147
2022-09-27 23:55:35 - epoch 080 lr: 0.001166
2022-09-27 23:56:09 - train: epoch 0080, iter [00010, 01251], lr: 0.001166, loss: 0.4367
2022-09-27 23:56:27 - train: epoch 0080, iter [00020, 01251], lr: 0.001166, loss: 0.4018
2022-09-27 23:56:45 - train: epoch 0080, iter [00030, 01251], lr: 0.001166, loss: 0.4262
2022-09-27 23:57:03 - train: epoch 0080, iter [00040, 01251], lr: 0.001166, loss: 0.4229
2022-09-27 23:57:20 - train: epoch 0080, iter [00050, 01251], lr: 0.001166, loss: 0.4083
2022-09-27 23:57:38 - train: epoch 0080, iter [00060, 01251], lr: 0.001166, loss: 0.4008
2022-09-27 23:57:56 - train: epoch 0080, iter [00070, 01251], lr: 0.001165, loss: 0.4067
2022-09-27 23:58:14 - train: epoch 0080, iter [00080, 01251], lr: 0.001165, loss: 0.4045
2022-09-27 23:58:32 - train: epoch 0080, iter [00090, 01251], lr: 0.001165, loss: 0.4044
2022-09-27 23:58:49 - train: epoch 0080, iter [00100, 01251], lr: 0.001165, loss: 0.4109
2022-09-27 23:59:07 - train: epoch 0080, iter [00110, 01251], lr: 0.001165, loss: 0.4070
2022-09-27 23:59:25 - train: epoch 0080, iter [00120, 01251], lr: 0.001165, loss: 0.4077
2022-09-27 23:59:43 - train: epoch 0080, iter [00130, 01251], lr: 0.001165, loss: 0.4170
2022-09-28 00:00:01 - train: epoch 0080, iter [00140, 01251], lr: 0.001165, loss: 0.4112
2022-09-28 00:00:19 - train: epoch 0080, iter [00150, 01251], lr: 0.001165, loss: 0.4175
2022-09-28 00:00:37 - train: epoch 0080, iter [00160, 01251], lr: 0.001165, loss: 0.4140
2022-09-28 00:00:54 - train: epoch 0080, iter [00170, 01251], lr: 0.001165, loss: 0.4061
2022-09-28 00:01:12 - train: epoch 0080, iter [00180, 01251], lr: 0.001165, loss: 0.4210
2022-09-28 00:01:30 - train: epoch 0080, iter [00190, 01251], lr: 0.001165, loss: 0.4261
2022-09-28 00:01:48 - train: epoch 0080, iter [00200, 01251], lr: 0.001165, loss: 0.4107
2022-09-28 00:02:06 - train: epoch 0080, iter [00210, 01251], lr: 0.001165, loss: 0.4076
2022-09-28 00:02:24 - train: epoch 0080, iter [00220, 01251], lr: 0.001165, loss: 0.4135
2022-09-28 00:02:42 - train: epoch 0080, iter [00230, 01251], lr: 0.001165, loss: 0.4045
2022-09-28 00:02:59 - train: epoch 0080, iter [00240, 01251], lr: 0.001165, loss: 0.4001
2022-09-28 00:03:17 - train: epoch 0080, iter [00250, 01251], lr: 0.001165, loss: 0.4201
2022-09-28 00:03:35 - train: epoch 0080, iter [00260, 01251], lr: 0.001165, loss: 0.4206
2022-09-28 00:03:53 - train: epoch 0080, iter [00270, 01251], lr: 0.001165, loss: 0.4007
2022-09-28 00:04:11 - train: epoch 0080, iter [00280, 01251], lr: 0.001165, loss: 0.4183
2022-09-28 00:04:28 - train: epoch 0080, iter [00290, 01251], lr: 0.001165, loss: 0.4214
2022-09-28 00:04:46 - train: epoch 0080, iter [00300, 01251], lr: 0.001165, loss: 0.4389
2022-09-28 00:05:04 - train: epoch 0080, iter [00310, 01251], lr: 0.001165, loss: 0.3984
2022-09-28 00:05:22 - train: epoch 0080, iter [00320, 01251], lr: 0.001165, loss: 0.3930
2022-09-28 00:05:40 - train: epoch 0080, iter [00330, 01251], lr: 0.001165, loss: 0.3981
2022-09-28 00:05:57 - train: epoch 0080, iter [00340, 01251], lr: 0.001165, loss: 0.4231
2022-09-28 00:06:15 - train: epoch 0080, iter [00350, 01251], lr: 0.001165, loss: 0.3995
2022-09-28 00:06:33 - train: epoch 0080, iter [00360, 01251], lr: 0.001165, loss: 0.4057
2022-09-28 00:06:51 - train: epoch 0080, iter [00370, 01251], lr: 0.001165, loss: 0.4143
2022-09-28 00:07:09 - train: epoch 0080, iter [00380, 01251], lr: 0.001165, loss: 0.3931
2022-09-28 00:07:27 - train: epoch 0080, iter [00390, 01251], lr: 0.001165, loss: 0.4264
2022-09-28 00:07:45 - train: epoch 0080, iter [00400, 01251], lr: 0.001165, loss: 0.4131
2022-09-28 00:08:03 - train: epoch 0080, iter [00410, 01251], lr: 0.001165, loss: 0.4138
2022-09-28 00:08:21 - train: epoch 0080, iter [00420, 01251], lr: 0.001165, loss: 0.4142
2022-09-28 00:08:39 - train: epoch 0080, iter [00430, 01251], lr: 0.001165, loss: 0.4015
2022-09-28 00:08:57 - train: epoch 0080, iter [00440, 01251], lr: 0.001165, loss: 0.4053
2022-09-28 00:09:15 - train: epoch 0080, iter [00450, 01251], lr: 0.001165, loss: 0.3946
2022-09-28 00:09:32 - train: epoch 0080, iter [00460, 01251], lr: 0.001165, loss: 0.4208
2022-09-28 00:09:50 - train: epoch 0080, iter [00470, 01251], lr: 0.001165, loss: 0.3943
2022-09-28 00:10:08 - train: epoch 0080, iter [00480, 01251], lr: 0.001165, loss: 0.4039
2022-09-28 00:10:26 - train: epoch 0080, iter [00490, 01251], lr: 0.001165, loss: 0.4354
2022-09-28 00:10:44 - train: epoch 0080, iter [00500, 01251], lr: 0.001165, loss: 0.4051
2022-09-28 00:11:02 - train: epoch 0080, iter [00510, 01251], lr: 0.001165, loss: 0.4204
2022-09-28 00:11:20 - train: epoch 0080, iter [00520, 01251], lr: 0.001165, loss: 0.4022
2022-09-28 00:11:38 - train: epoch 0080, iter [00530, 01251], lr: 0.001165, loss: 0.4003
2022-09-28 00:11:56 - train: epoch 0080, iter [00540, 01251], lr: 0.001165, loss: 0.4112
2022-09-28 00:12:14 - train: epoch 0080, iter [00550, 01251], lr: 0.001165, loss: 0.4190
2022-09-28 00:12:31 - train: epoch 0080, iter [00560, 01251], lr: 0.001165, loss: 0.4156
2022-09-28 00:12:49 - train: epoch 0080, iter [00570, 01251], lr: 0.001165, loss: 0.4081
2022-09-28 00:13:07 - train: epoch 0080, iter [00580, 01251], lr: 0.001165, loss: 0.4190
2022-09-28 00:13:25 - train: epoch 0080, iter [00590, 01251], lr: 0.001165, loss: 0.4201
2022-09-28 00:13:43 - train: epoch 0080, iter [00600, 01251], lr: 0.001165, loss: 0.4424
2022-09-28 00:14:01 - train: epoch 0080, iter [00610, 01251], lr: 0.001165, loss: 0.4204
2022-09-28 00:14:18 - train: epoch 0080, iter [00620, 01251], lr: 0.001165, loss: 0.4143
2022-09-28 00:14:36 - train: epoch 0080, iter [00630, 01251], lr: 0.001165, loss: 0.4063
2022-09-28 00:14:54 - train: epoch 0080, iter [00640, 01251], lr: 0.001165, loss: 0.3944
2022-09-28 00:15:12 - train: epoch 0080, iter [00650, 01251], lr: 0.001165, loss: 0.4209
2022-09-28 00:15:30 - train: epoch 0080, iter [00660, 01251], lr: 0.001165, loss: 0.4173
2022-09-28 00:15:48 - train: epoch 0080, iter [00670, 01251], lr: 0.001165, loss: 0.4100
2022-09-28 00:16:05 - train: epoch 0080, iter [00680, 01251], lr: 0.001165, loss: 0.4030
2022-09-28 00:16:23 - train: epoch 0080, iter [00690, 01251], lr: 0.001165, loss: 0.4052
2022-09-28 00:16:41 - train: epoch 0080, iter [00700, 01251], lr: 0.001165, loss: 0.4045
2022-09-28 00:16:59 - train: epoch 0080, iter [00710, 01251], lr: 0.001165, loss: 0.4171
2022-09-28 00:17:17 - train: epoch 0080, iter [00720, 01251], lr: 0.001165, loss: 0.4244
2022-09-28 00:17:35 - train: epoch 0080, iter [00730, 01251], lr: 0.001165, loss: 0.4290
2022-09-28 00:17:52 - train: epoch 0080, iter [00740, 01251], lr: 0.001165, loss: 0.4088
2022-09-28 00:18:10 - train: epoch 0080, iter [00750, 01251], lr: 0.001165, loss: 0.4117
2022-09-28 00:18:28 - train: epoch 0080, iter [00760, 01251], lr: 0.001165, loss: 0.3920
2022-09-28 00:18:46 - train: epoch 0080, iter [00770, 01251], lr: 0.001165, loss: 0.4153
2022-09-28 00:19:04 - train: epoch 0080, iter [00780, 01251], lr: 0.001164, loss: 0.4065
2022-09-28 00:19:22 - train: epoch 0080, iter [00790, 01251], lr: 0.001164, loss: 0.4267
2022-09-28 00:19:40 - train: epoch 0080, iter [00800, 01251], lr: 0.001164, loss: 0.4141
2022-09-28 00:19:57 - train: epoch 0080, iter [00810, 01251], lr: 0.001164, loss: 0.4283
2022-09-28 00:20:15 - train: epoch 0080, iter [00820, 01251], lr: 0.001164, loss: 0.4020
2022-09-28 00:20:33 - train: epoch 0080, iter [00830, 01251], lr: 0.001164, loss: 0.4174
2022-09-28 00:20:51 - train: epoch 0080, iter [00840, 01251], lr: 0.001164, loss: 0.4099
2022-09-28 00:21:08 - train: epoch 0080, iter [00850, 01251], lr: 0.001164, loss: 0.4338
2022-09-28 00:21:26 - train: epoch 0080, iter [00860, 01251], lr: 0.001164, loss: 0.4127
2022-09-28 00:21:44 - train: epoch 0080, iter [00870, 01251], lr: 0.001164, loss: 0.4056
2022-09-28 00:22:02 - train: epoch 0080, iter [00880, 01251], lr: 0.001164, loss: 0.4205
2022-09-28 00:22:19 - train: epoch 0080, iter [00890, 01251], lr: 0.001164, loss: 0.3960
2022-09-28 00:22:37 - train: epoch 0080, iter [00900, 01251], lr: 0.001164, loss: 0.4324
2022-09-28 00:22:55 - train: epoch 0080, iter [00910, 01251], lr: 0.001164, loss: 0.4216
2022-09-28 00:23:13 - train: epoch 0080, iter [00920, 01251], lr: 0.001164, loss: 0.4027
2022-09-28 00:23:31 - train: epoch 0080, iter [00930, 01251], lr: 0.001164, loss: 0.4282
2022-09-28 00:23:49 - train: epoch 0080, iter [00940, 01251], lr: 0.001164, loss: 0.4270
2022-09-28 00:24:07 - train: epoch 0080, iter [00950, 01251], lr: 0.001164, loss: 0.4138
2022-09-28 00:24:24 - train: epoch 0080, iter [00960, 01251], lr: 0.001164, loss: 0.4053
2022-09-28 00:24:42 - train: epoch 0080, iter [00970, 01251], lr: 0.001164, loss: 0.3958
2022-09-28 00:25:00 - train: epoch 0080, iter [00980, 01251], lr: 0.001164, loss: 0.4183
2022-09-28 00:25:18 - train: epoch 0080, iter [00990, 01251], lr: 0.001164, loss: 0.4166
2022-09-28 00:25:36 - train: epoch 0080, iter [01000, 01251], lr: 0.001164, loss: 0.4430
2022-09-28 00:25:54 - train: epoch 0080, iter [01010, 01251], lr: 0.001164, loss: 0.4301
2022-09-28 00:26:12 - train: epoch 0080, iter [01020, 01251], lr: 0.001164, loss: 0.4168
2022-09-28 00:26:29 - train: epoch 0080, iter [01030, 01251], lr: 0.001164, loss: 0.4295
2022-09-28 00:26:47 - train: epoch 0080, iter [01040, 01251], lr: 0.001164, loss: 0.4121
2022-09-28 00:27:05 - train: epoch 0080, iter [01050, 01251], lr: 0.001164, loss: 0.4089
2022-09-28 00:27:23 - train: epoch 0080, iter [01060, 01251], lr: 0.001164, loss: 0.4190
2022-09-28 00:27:41 - train: epoch 0080, iter [01070, 01251], lr: 0.001164, loss: 0.4350
2022-09-28 00:27:59 - train: epoch 0080, iter [01080, 01251], lr: 0.001164, loss: 0.4027
2022-09-28 00:28:17 - train: epoch 0080, iter [01090, 01251], lr: 0.001164, loss: 0.4093
2022-09-28 00:28:35 - train: epoch 0080, iter [01100, 01251], lr: 0.001164, loss: 0.4048
2022-09-28 00:28:53 - train: epoch 0080, iter [01110, 01251], lr: 0.001164, loss: 0.4106
2022-09-28 00:29:11 - train: epoch 0080, iter [01120, 01251], lr: 0.001164, loss: 0.3978
2022-09-28 00:29:29 - train: epoch 0080, iter [01130, 01251], lr: 0.001164, loss: 0.4294
2022-09-28 00:29:47 - train: epoch 0080, iter [01140, 01251], lr: 0.001164, loss: 0.4247
2022-09-28 00:30:05 - train: epoch 0080, iter [01150, 01251], lr: 0.001164, loss: 0.4339
2022-09-28 00:30:22 - train: epoch 0080, iter [01160, 01251], lr: 0.001164, loss: 0.4181
2022-09-28 00:30:40 - train: epoch 0080, iter [01170, 01251], lr: 0.001164, loss: 0.4100
2022-09-28 00:30:58 - train: epoch 0080, iter [01180, 01251], lr: 0.001164, loss: 0.4412
2022-09-28 00:31:16 - train: epoch 0080, iter [01190, 01251], lr: 0.001164, loss: 0.3942
2022-09-28 00:31:34 - train: epoch 0080, iter [01200, 01251], lr: 0.001164, loss: 0.3962
2022-09-28 00:31:52 - train: epoch 0080, iter [01210, 01251], lr: 0.001164, loss: 0.4227
2022-09-28 00:32:10 - train: epoch 0080, iter [01220, 01251], lr: 0.001164, loss: 0.4193
2022-09-28 00:32:27 - train: epoch 0080, iter [01230, 01251], lr: 0.001164, loss: 0.4243
2022-09-28 00:32:45 - train: epoch 0080, iter [01240, 01251], lr: 0.001164, loss: 0.4348
2022-09-28 00:33:02 - train: epoch 0080, iter [01250, 01251], lr: 0.001164, loss: 0.4019
2022-09-28 00:33:06 - train: epoch 080, train_loss: 0.4147
2022-09-28 00:33:07 - until epoch: 080, best_loss: 0.4147
2022-09-28 00:33:07 - epoch 081 lr: 0.001164
2022-09-28 00:33:41 - train: epoch 0081, iter [00010, 01251], lr: 0.001164, loss: 0.4161
2022-09-28 00:33:58 - train: epoch 0081, iter [00020, 01251], lr: 0.001164, loss: 0.4150
2022-09-28 00:34:16 - train: epoch 0081, iter [00030, 01251], lr: 0.001164, loss: 0.4121
2022-09-28 00:34:34 - train: epoch 0081, iter [00040, 01251], lr: 0.001164, loss: 0.4407
2022-09-28 00:34:52 - train: epoch 0081, iter [00050, 01251], lr: 0.001164, loss: 0.4062
2022-09-28 00:35:09 - train: epoch 0081, iter [00060, 01251], lr: 0.001164, loss: 0.4062
2022-09-28 00:35:27 - train: epoch 0081, iter [00070, 01251], lr: 0.001164, loss: 0.4106
2022-09-28 00:35:45 - train: epoch 0081, iter [00080, 01251], lr: 0.001164, loss: 0.4386
2022-09-28 00:36:03 - train: epoch 0081, iter [00090, 01251], lr: 0.001164, loss: 0.4155
2022-09-28 00:36:21 - train: epoch 0081, iter [00100, 01251], lr: 0.001164, loss: 0.4137
2022-09-28 00:36:39 - train: epoch 0081, iter [00110, 01251], lr: 0.001164, loss: 0.4137
2022-09-28 00:36:56 - train: epoch 0081, iter [00120, 01251], lr: 0.001164, loss: 0.3971
2022-09-28 00:37:14 - train: epoch 0081, iter [00130, 01251], lr: 0.001164, loss: 0.4340
2022-09-28 00:37:32 - train: epoch 0081, iter [00140, 01251], lr: 0.001164, loss: 0.4368
2022-09-28 00:37:50 - train: epoch 0081, iter [00150, 01251], lr: 0.001164, loss: 0.4074
2022-09-28 00:38:08 - train: epoch 0081, iter [00160, 01251], lr: 0.001164, loss: 0.4305
2022-09-28 00:38:26 - train: epoch 0081, iter [00170, 01251], lr: 0.001164, loss: 0.4186
2022-09-28 00:38:43 - train: epoch 0081, iter [00180, 01251], lr: 0.001164, loss: 0.4142
2022-09-28 00:39:01 - train: epoch 0081, iter [00190, 01251], lr: 0.001164, loss: 0.4135
2022-09-28 00:39:19 - train: epoch 0081, iter [00200, 01251], lr: 0.001164, loss: 0.4282
2022-09-28 00:39:37 - train: epoch 0081, iter [00210, 01251], lr: 0.001164, loss: 0.4134
2022-09-28 00:39:55 - train: epoch 0081, iter [00220, 01251], lr: 0.001163, loss: 0.4149
2022-09-28 00:40:13 - train: epoch 0081, iter [00230, 01251], lr: 0.001163, loss: 0.4042
2022-09-28 00:40:31 - train: epoch 0081, iter [00240, 01251], lr: 0.001163, loss: 0.4191
2022-09-28 00:40:48 - train: epoch 0081, iter [00250, 01251], lr: 0.001163, loss: 0.4117
2022-09-28 00:41:06 - train: epoch 0081, iter [00260, 01251], lr: 0.001163, loss: 0.4168
2022-09-28 00:41:25 - train: epoch 0081, iter [00270, 01251], lr: 0.001163, loss: 0.4113
2022-09-28 00:41:43 - train: epoch 0081, iter [00280, 01251], lr: 0.001163, loss: 0.4122
2022-09-28 00:42:01 - train: epoch 0081, iter [00290, 01251], lr: 0.001163, loss: 0.4326
2022-09-28 00:42:19 - train: epoch 0081, iter [00300, 01251], lr: 0.001163, loss: 0.4185
2022-09-28 00:42:37 - train: epoch 0081, iter [00310, 01251], lr: 0.001163, loss: 0.4178
2022-09-28 00:42:54 - train: epoch 0081, iter [00320, 01251], lr: 0.001163, loss: 0.4066
2022-09-28 00:43:12 - train: epoch 0081, iter [00330, 01251], lr: 0.001163, loss: 0.4111
2022-09-28 00:43:30 - train: epoch 0081, iter [00340, 01251], lr: 0.001163, loss: 0.4039
2022-09-28 00:43:48 - train: epoch 0081, iter [00350, 01251], lr: 0.001163, loss: 0.4153
2022-09-28 00:44:06 - train: epoch 0081, iter [00360, 01251], lr: 0.001163, loss: 0.4150
2022-09-28 00:44:24 - train: epoch 0081, iter [00370, 01251], lr: 0.001163, loss: 0.4109
2022-09-28 00:44:42 - train: epoch 0081, iter [00380, 01251], lr: 0.001163, loss: 0.4099
2022-09-28 00:45:00 - train: epoch 0081, iter [00390, 01251], lr: 0.001163, loss: 0.4351
2022-09-28 00:45:17 - train: epoch 0081, iter [00400, 01251], lr: 0.001163, loss: 0.4104
2022-09-28 00:45:35 - train: epoch 0081, iter [00410, 01251], lr: 0.001163, loss: 0.4161
2022-09-28 00:45:53 - train: epoch 0081, iter [00420, 01251], lr: 0.001163, loss: 0.4387
2022-09-28 00:46:11 - train: epoch 0081, iter [00430, 01251], lr: 0.001163, loss: 0.3829
2022-09-28 00:46:29 - train: epoch 0081, iter [00440, 01251], lr: 0.001163, loss: 0.4291
2022-09-28 00:46:47 - train: epoch 0081, iter [00450, 01251], lr: 0.001163, loss: 0.4293
2022-09-28 00:47:05 - train: epoch 0081, iter [00460, 01251], lr: 0.001163, loss: 0.4089
2022-09-28 00:47:23 - train: epoch 0081, iter [00470, 01251], lr: 0.001163, loss: 0.4219
2022-09-28 00:47:41 - train: epoch 0081, iter [00480, 01251], lr: 0.001163, loss: 0.4071
2022-09-28 00:47:59 - train: epoch 0081, iter [00490, 01251], lr: 0.001163, loss: 0.4235
2022-09-28 00:48:17 - train: epoch 0081, iter [00500, 01251], lr: 0.001163, loss: 0.4114
2022-09-28 00:48:34 - train: epoch 0081, iter [00510, 01251], lr: 0.001163, loss: 0.4158
2022-09-28 00:48:52 - train: epoch 0081, iter [00520, 01251], lr: 0.001163, loss: 0.4274
2022-09-28 00:49:10 - train: epoch 0081, iter [00530, 01251], lr: 0.001163, loss: 0.4024
2022-09-28 00:49:28 - train: epoch 0081, iter [00540, 01251], lr: 0.001163, loss: 0.4065
2022-09-28 00:49:46 - train: epoch 0081, iter [00550, 01251], lr: 0.001163, loss: 0.4285
2022-09-28 00:50:04 - train: epoch 0081, iter [00560, 01251], lr: 0.001163, loss: 0.4157
2022-09-28 00:50:21 - train: epoch 0081, iter [00570, 01251], lr: 0.001163, loss: 0.3989
2022-09-28 00:50:39 - train: epoch 0081, iter [00580, 01251], lr: 0.001163, loss: 0.4202
2022-09-28 00:50:57 - train: epoch 0081, iter [00590, 01251], lr: 0.001163, loss: 0.4174
2022-09-28 00:51:15 - train: epoch 0081, iter [00600, 01251], lr: 0.001163, loss: 0.4157
2022-09-28 00:51:33 - train: epoch 0081, iter [00610, 01251], lr: 0.001163, loss: 0.3972
2022-09-28 00:51:51 - train: epoch 0081, iter [00620, 01251], lr: 0.001163, loss: 0.4053
2022-09-28 00:52:08 - train: epoch 0081, iter [00630, 01251], lr: 0.001163, loss: 0.4185
2022-09-28 00:52:26 - train: epoch 0081, iter [00640, 01251], lr: 0.001163, loss: 0.4141
2022-09-28 00:52:44 - train: epoch 0081, iter [00650, 01251], lr: 0.001163, loss: 0.4088
2022-09-28 00:53:02 - train: epoch 0081, iter [00660, 01251], lr: 0.001163, loss: 0.4116
2022-09-28 00:53:20 - train: epoch 0081, iter [00670, 01251], lr: 0.001163, loss: 0.4073
2022-09-28 00:53:38 - train: epoch 0081, iter [00680, 01251], lr: 0.001163, loss: 0.4204
2022-09-28 00:53:55 - train: epoch 0081, iter [00690, 01251], lr: 0.001163, loss: 0.4107
2022-09-28 00:54:13 - train: epoch 0081, iter [00700, 01251], lr: 0.001163, loss: 0.4293
2022-09-28 00:54:31 - train: epoch 0081, iter [00710, 01251], lr: 0.001163, loss: 0.4121
2022-09-28 00:54:49 - train: epoch 0081, iter [00720, 01251], lr: 0.001163, loss: 0.4016
2022-09-28 00:55:07 - train: epoch 0081, iter [00730, 01251], lr: 0.001163, loss: 0.4260
2022-09-28 00:55:25 - train: epoch 0081, iter [00740, 01251], lr: 0.001163, loss: 0.4141
2022-09-28 00:55:43 - train: epoch 0081, iter [00750, 01251], lr: 0.001163, loss: 0.3944
2022-09-28 00:56:01 - train: epoch 0081, iter [00760, 01251], lr: 0.001163, loss: 0.4037
2022-09-28 00:56:18 - train: epoch 0081, iter [00770, 01251], lr: 0.001163, loss: 0.4058
2022-09-28 00:56:36 - train: epoch 0081, iter [00780, 01251], lr: 0.001163, loss: 0.4173
2022-09-28 00:56:54 - train: epoch 0081, iter [00790, 01251], lr: 0.001163, loss: 0.4331
2022-09-28 00:57:12 - train: epoch 0081, iter [00800, 01251], lr: 0.001163, loss: 0.4238
2022-09-28 00:57:30 - train: epoch 0081, iter [00810, 01251], lr: 0.001163, loss: 0.4172
2022-09-28 00:57:48 - train: epoch 0081, iter [00820, 01251], lr: 0.001163, loss: 0.3997
2022-09-28 00:58:06 - train: epoch 0081, iter [00830, 01251], lr: 0.001163, loss: 0.3820
2022-09-28 00:58:24 - train: epoch 0081, iter [00840, 01251], lr: 0.001163, loss: 0.4055
2022-09-28 00:58:41 - train: epoch 0081, iter [00850, 01251], lr: 0.001163, loss: 0.4200
2022-09-28 00:58:59 - train: epoch 0081, iter [00860, 01251], lr: 0.001163, loss: 0.3882
2022-09-28 00:59:17 - train: epoch 0081, iter [00870, 01251], lr: 0.001163, loss: 0.4204
2022-09-28 00:59:35 - train: epoch 0081, iter [00880, 01251], lr: 0.001163, loss: 0.4091
2022-09-28 00:59:53 - train: epoch 0081, iter [00890, 01251], lr: 0.001163, loss: 0.4167
2022-09-28 01:00:11 - train: epoch 0081, iter [00900, 01251], lr: 0.001163, loss: 0.4059
2022-09-28 01:00:29 - train: epoch 0081, iter [00910, 01251], lr: 0.001163, loss: 0.4024
2022-09-28 01:00:47 - train: epoch 0081, iter [00920, 01251], lr: 0.001162, loss: 0.4207
2022-09-28 01:01:05 - train: epoch 0081, iter [00930, 01251], lr: 0.001162, loss: 0.4119
2022-09-28 01:01:23 - train: epoch 0081, iter [00940, 01251], lr: 0.001162, loss: 0.3973
2022-09-28 01:01:40 - train: epoch 0081, iter [00950, 01251], lr: 0.001162, loss: 0.4185
2022-09-28 01:01:59 - train: epoch 0081, iter [00960, 01251], lr: 0.001162, loss: 0.4275
2022-09-28 01:02:16 - train: epoch 0081, iter [00970, 01251], lr: 0.001162, loss: 0.4106
2022-09-28 01:02:34 - train: epoch 0081, iter [00980, 01251], lr: 0.001162, loss: 0.4196
2022-09-28 01:02:52 - train: epoch 0081, iter [00990, 01251], lr: 0.001162, loss: 0.4229
2022-09-28 01:03:10 - train: epoch 0081, iter [01000, 01251], lr: 0.001162, loss: 0.4339
2022-09-28 01:03:28 - train: epoch 0081, iter [01010, 01251], lr: 0.001162, loss: 0.4092
2022-09-28 01:03:46 - train: epoch 0081, iter [01020, 01251], lr: 0.001162, loss: 0.4084
2022-09-28 01:04:04 - train: epoch 0081, iter [01030, 01251], lr: 0.001162, loss: 0.4144
2022-09-28 01:04:22 - train: epoch 0081, iter [01040, 01251], lr: 0.001162, loss: 0.4155
2022-09-28 01:04:39 - train: epoch 0081, iter [01050, 01251], lr: 0.001162, loss: 0.4136
2022-09-28 01:04:57 - train: epoch 0081, iter [01060, 01251], lr: 0.001162, loss: 0.4250
2022-09-28 01:05:15 - train: epoch 0081, iter [01070, 01251], lr: 0.001162, loss: 0.4297
2022-09-28 01:05:33 - train: epoch 0081, iter [01080, 01251], lr: 0.001162, loss: 0.4241
2022-09-28 01:05:51 - train: epoch 0081, iter [01090, 01251], lr: 0.001162, loss: 0.4148
2022-09-28 01:06:09 - train: epoch 0081, iter [01100, 01251], lr: 0.001162, loss: 0.4114
2022-09-28 01:06:26 - train: epoch 0081, iter [01110, 01251], lr: 0.001162, loss: 0.4362
2022-09-28 01:06:44 - train: epoch 0081, iter [01120, 01251], lr: 0.001162, loss: 0.4036
2022-09-28 01:07:02 - train: epoch 0081, iter [01130, 01251], lr: 0.001162, loss: 0.4177
2022-09-28 01:07:20 - train: epoch 0081, iter [01140, 01251], lr: 0.001162, loss: 0.4293
2022-09-28 01:07:38 - train: epoch 0081, iter [01150, 01251], lr: 0.001162, loss: 0.4245
2022-09-28 01:07:56 - train: epoch 0081, iter [01160, 01251], lr: 0.001162, loss: 0.4047
2022-09-28 01:08:14 - train: epoch 0081, iter [01170, 01251], lr: 0.001162, loss: 0.4244
2022-09-28 01:08:31 - train: epoch 0081, iter [01180, 01251], lr: 0.001162, loss: 0.4214
2022-09-28 01:08:49 - train: epoch 0081, iter [01190, 01251], lr: 0.001162, loss: 0.3949
2022-09-28 01:09:07 - train: epoch 0081, iter [01200, 01251], lr: 0.001162, loss: 0.4105
2022-09-28 01:09:25 - train: epoch 0081, iter [01210, 01251], lr: 0.001162, loss: 0.3930
2022-09-28 01:09:42 - train: epoch 0081, iter [01220, 01251], lr: 0.001162, loss: 0.4098
2022-09-28 01:10:00 - train: epoch 0081, iter [01230, 01251], lr: 0.001162, loss: 0.4151
2022-09-28 01:10:18 - train: epoch 0081, iter [01240, 01251], lr: 0.001162, loss: 0.4115
2022-09-28 01:10:35 - train: epoch 0081, iter [01250, 01251], lr: 0.001162, loss: 0.4201
2022-09-28 01:10:39 - train: epoch 081, train_loss: 0.4147
2022-09-28 01:10:41 - until epoch: 081, best_loss: 0.4147
2022-09-28 01:10:41 - epoch 082 lr: 0.001162
2022-09-28 01:11:14 - train: epoch 0082, iter [00010, 01251], lr: 0.001162, loss: 0.4374
2022-09-28 01:11:32 - train: epoch 0082, iter [00020, 01251], lr: 0.001162, loss: 0.4330
2022-09-28 01:11:50 - train: epoch 0082, iter [00030, 01251], lr: 0.001162, loss: 0.4130
2022-09-28 01:12:08 - train: epoch 0082, iter [00040, 01251], lr: 0.001162, loss: 0.3969
2022-09-28 01:12:25 - train: epoch 0082, iter [00050, 01251], lr: 0.001162, loss: 0.4237
2022-09-28 01:12:43 - train: epoch 0082, iter [00060, 01251], lr: 0.001162, loss: 0.4282
2022-09-28 01:13:01 - train: epoch 0082, iter [00070, 01251], lr: 0.001162, loss: 0.4303
2022-09-28 01:13:19 - train: epoch 0082, iter [00080, 01251], lr: 0.001162, loss: 0.4270
2022-09-28 01:13:37 - train: epoch 0082, iter [00090, 01251], lr: 0.001162, loss: 0.4105
2022-09-28 01:13:55 - train: epoch 0082, iter [00100, 01251], lr: 0.001162, loss: 0.4335
2022-09-28 01:14:12 - train: epoch 0082, iter [00110, 01251], lr: 0.001162, loss: 0.4111
2022-09-28 01:14:30 - train: epoch 0082, iter [00120, 01251], lr: 0.001162, loss: 0.4210
2022-09-28 01:14:48 - train: epoch 0082, iter [00130, 01251], lr: 0.001162, loss: 0.4092
2022-09-28 01:15:06 - train: epoch 0082, iter [00140, 01251], lr: 0.001162, loss: 0.3985
2022-09-28 01:15:24 - train: epoch 0082, iter [00150, 01251], lr: 0.001162, loss: 0.4165
2022-09-28 01:15:41 - train: epoch 0082, iter [00160, 01251], lr: 0.001162, loss: 0.4157
2022-09-28 01:15:59 - train: epoch 0082, iter [00170, 01251], lr: 0.001162, loss: 0.4273
2022-09-28 01:16:17 - train: epoch 0082, iter [00180, 01251], lr: 0.001162, loss: 0.4226
2022-09-28 01:16:35 - train: epoch 0082, iter [00190, 01251], lr: 0.001162, loss: 0.4158
2022-09-28 01:16:53 - train: epoch 0082, iter [00200, 01251], lr: 0.001162, loss: 0.4176
2022-09-28 01:17:11 - train: epoch 0082, iter [00210, 01251], lr: 0.001162, loss: 0.4336
2022-09-28 01:17:29 - train: epoch 0082, iter [00220, 01251], lr: 0.001162, loss: 0.4225
2022-09-28 01:17:47 - train: epoch 0082, iter [00230, 01251], lr: 0.001162, loss: 0.3992
2022-09-28 01:18:05 - train: epoch 0082, iter [00240, 01251], lr: 0.001162, loss: 0.4006
2022-09-28 01:18:23 - train: epoch 0082, iter [00250, 01251], lr: 0.001162, loss: 0.4215
2022-09-28 01:18:40 - train: epoch 0082, iter [00260, 01251], lr: 0.001162, loss: 0.4164
2022-09-28 01:18:58 - train: epoch 0082, iter [00270, 01251], lr: 0.001162, loss: 0.4115
2022-09-28 01:19:16 - train: epoch 0082, iter [00280, 01251], lr: 0.001162, loss: 0.4095
2022-09-28 01:19:33 - train: epoch 0082, iter [00290, 01251], lr: 0.001162, loss: 0.4173
2022-09-28 01:19:51 - train: epoch 0082, iter [00300, 01251], lr: 0.001162, loss: 0.4270
2022-09-28 01:20:09 - train: epoch 0082, iter [00310, 01251], lr: 0.001162, loss: 0.4208
2022-09-28 01:20:27 - train: epoch 0082, iter [00320, 01251], lr: 0.001162, loss: 0.4194
2022-09-28 01:20:44 - train: epoch 0082, iter [00330, 01251], lr: 0.001162, loss: 0.4399
2022-09-28 01:21:02 - train: epoch 0082, iter [00340, 01251], lr: 0.001162, loss: 0.4114
2022-09-28 01:21:20 - train: epoch 0082, iter [00350, 01251], lr: 0.001161, loss: 0.4101
2022-09-28 01:21:38 - train: epoch 0082, iter [00360, 01251], lr: 0.001161, loss: 0.4286
2022-09-28 01:21:56 - train: epoch 0082, iter [00370, 01251], lr: 0.001161, loss: 0.4139
2022-09-28 01:22:14 - train: epoch 0082, iter [00380, 01251], lr: 0.001161, loss: 0.4045
2022-09-28 01:22:31 - train: epoch 0082, iter [00390, 01251], lr: 0.001161, loss: 0.4326
2022-09-28 01:22:49 - train: epoch 0082, iter [00400, 01251], lr: 0.001161, loss: 0.4046
2022-09-28 01:23:07 - train: epoch 0082, iter [00410, 01251], lr: 0.001161, loss: 0.4194
2022-09-28 01:23:25 - train: epoch 0082, iter [00420, 01251], lr: 0.001161, loss: 0.4139
2022-09-28 01:23:42 - train: epoch 0082, iter [00430, 01251], lr: 0.001161, loss: 0.3976
2022-09-28 01:24:00 - train: epoch 0082, iter [00440, 01251], lr: 0.001161, loss: 0.4026
2022-09-28 01:24:18 - train: epoch 0082, iter [00450, 01251], lr: 0.001161, loss: 0.4040
2022-09-28 01:24:36 - train: epoch 0082, iter [00460, 01251], lr: 0.001161, loss: 0.4108
2022-09-28 01:24:53 - train: epoch 0082, iter [00470, 01251], lr: 0.001161, loss: 0.3972
2022-09-28 01:25:11 - train: epoch 0082, iter [00480, 01251], lr: 0.001161, loss: 0.4159
2022-09-28 01:25:29 - train: epoch 0082, iter [00490, 01251], lr: 0.001161, loss: 0.4059
2022-09-28 01:25:47 - train: epoch 0082, iter [00500, 01251], lr: 0.001161, loss: 0.4110
2022-09-28 01:26:04 - train: epoch 0082, iter [00510, 01251], lr: 0.001161, loss: 0.3882
2022-09-28 01:26:22 - train: epoch 0082, iter [00520, 01251], lr: 0.001161, loss: 0.4216
2022-09-28 01:26:40 - train: epoch 0082, iter [00530, 01251], lr: 0.001161, loss: 0.4239
2022-09-28 01:26:58 - train: epoch 0082, iter [00540, 01251], lr: 0.001161, loss: 0.4032
2022-09-28 01:27:15 - train: epoch 0082, iter [00550, 01251], lr: 0.001161, loss: 0.4087
2022-09-28 01:27:33 - train: epoch 0082, iter [00560, 01251], lr: 0.001161, loss: 0.4008
2022-09-28 01:27:51 - train: epoch 0082, iter [00570, 01251], lr: 0.001161, loss: 0.4075
2022-09-28 01:28:09 - train: epoch 0082, iter [00580, 01251], lr: 0.001161, loss: 0.4183
2022-09-28 01:28:27 - train: epoch 0082, iter [00590, 01251], lr: 0.001161, loss: 0.4120
2022-09-28 01:28:44 - train: epoch 0082, iter [00600, 01251], lr: 0.001161, loss: 0.4145
2022-09-28 01:29:02 - train: epoch 0082, iter [00610, 01251], lr: 0.001161, loss: 0.4163
2022-09-28 01:29:20 - train: epoch 0082, iter [00620, 01251], lr: 0.001161, loss: 0.3930
2022-09-28 01:29:38 - train: epoch 0082, iter [00630, 01251], lr: 0.001161, loss: 0.3990
2022-09-28 01:29:56 - train: epoch 0082, iter [00640, 01251], lr: 0.001161, loss: 0.4158
2022-09-28 01:30:14 - train: epoch 0082, iter [00650, 01251], lr: 0.001161, loss: 0.4263
2022-09-28 01:30:31 - train: epoch 0082, iter [00660, 01251], lr: 0.001161, loss: 0.4281
2022-09-28 01:30:49 - train: epoch 0082, iter [00670, 01251], lr: 0.001161, loss: 0.4116
2022-09-28 01:31:07 - train: epoch 0082, iter [00680, 01251], lr: 0.001161, loss: 0.4260
2022-09-28 01:31:25 - train: epoch 0082, iter [00690, 01251], lr: 0.001161, loss: 0.4075
2022-09-28 01:31:43 - train: epoch 0082, iter [00700, 01251], lr: 0.001161, loss: 0.4240
2022-09-28 01:32:01 - train: epoch 0082, iter [00710, 01251], lr: 0.001161, loss: 0.4323
2022-09-28 01:32:19 - train: epoch 0082, iter [00720, 01251], lr: 0.001161, loss: 0.4320
2022-09-28 01:32:37 - train: epoch 0082, iter [00730, 01251], lr: 0.001161, loss: 0.4453
2022-09-28 01:32:54 - train: epoch 0082, iter [00740, 01251], lr: 0.001161, loss: 0.4515
2022-09-28 01:33:12 - train: epoch 0082, iter [00750, 01251], lr: 0.001161, loss: 0.4149
2022-09-28 01:33:30 - train: epoch 0082, iter [00760, 01251], lr: 0.001161, loss: 0.4083
2022-09-28 01:33:47 - train: epoch 0082, iter [00770, 01251], lr: 0.001161, loss: 0.4245
2022-09-28 01:34:05 - train: epoch 0082, iter [00780, 01251], lr: 0.001161, loss: 0.4038
2022-09-28 01:34:23 - train: epoch 0082, iter [00790, 01251], lr: 0.001161, loss: 0.4094
2022-09-28 01:34:41 - train: epoch 0082, iter [00800, 01251], lr: 0.001161, loss: 0.4050
2022-09-28 01:34:59 - train: epoch 0082, iter [00810, 01251], lr: 0.001161, loss: 0.4110
2022-09-28 01:35:17 - train: epoch 0082, iter [00820, 01251], lr: 0.001161, loss: 0.4138
2022-09-28 01:35:35 - train: epoch 0082, iter [00830, 01251], lr: 0.001161, loss: 0.4100
2022-09-28 01:35:53 - train: epoch 0082, iter [00840, 01251], lr: 0.001161, loss: 0.4136
2022-09-28 01:36:11 - train: epoch 0082, iter [00850, 01251], lr: 0.001161, loss: 0.4013
2022-09-28 01:36:29 - train: epoch 0082, iter [00860, 01251], lr: 0.001161, loss: 0.4082
2022-09-28 01:36:46 - train: epoch 0082, iter [00870, 01251], lr: 0.001161, loss: 0.4000
2022-09-28 01:37:04 - train: epoch 0082, iter [00880, 01251], lr: 0.001161, loss: 0.4220
2022-09-28 01:37:22 - train: epoch 0082, iter [00890, 01251], lr: 0.001161, loss: 0.4185
2022-09-28 01:37:40 - train: epoch 0082, iter [00900, 01251], lr: 0.001161, loss: 0.4201
2022-09-28 01:37:58 - train: epoch 0082, iter [00910, 01251], lr: 0.001161, loss: 0.4195
2022-09-28 01:38:15 - train: epoch 0082, iter [00920, 01251], lr: 0.001161, loss: 0.4106
2022-09-28 01:38:33 - train: epoch 0082, iter [00930, 01251], lr: 0.001161, loss: 0.4017
2022-09-28 01:38:51 - train: epoch 0082, iter [00940, 01251], lr: 0.001161, loss: 0.4138
2022-09-28 01:39:09 - train: epoch 0082, iter [00950, 01251], lr: 0.001161, loss: 0.4322
2022-09-28 01:39:26 - train: epoch 0082, iter [00960, 01251], lr: 0.001161, loss: 0.4072
2022-09-28 01:39:44 - train: epoch 0082, iter [00970, 01251], lr: 0.001161, loss: 0.4192
2022-09-28 01:40:02 - train: epoch 0082, iter [00980, 01251], lr: 0.001161, loss: 0.4109
2022-09-28 01:40:20 - train: epoch 0082, iter [00990, 01251], lr: 0.001161, loss: 0.4034
2022-09-28 01:40:38 - train: epoch 0082, iter [01000, 01251], lr: 0.001161, loss: 0.4228
2022-09-28 01:40:55 - train: epoch 0082, iter [01010, 01251], lr: 0.001161, loss: 0.4212
2022-09-28 01:41:13 - train: epoch 0082, iter [01020, 01251], lr: 0.001160, loss: 0.3999
2022-09-28 01:41:31 - train: epoch 0082, iter [01030, 01251], lr: 0.001160, loss: 0.4070
2022-09-28 01:41:49 - train: epoch 0082, iter [01040, 01251], lr: 0.001160, loss: 0.4279
2022-09-28 01:42:06 - train: epoch 0082, iter [01050, 01251], lr: 0.001160, loss: 0.4087
2022-09-28 01:42:24 - train: epoch 0082, iter [01060, 01251], lr: 0.001160, loss: 0.4049
2022-09-28 01:42:42 - train: epoch 0082, iter [01070, 01251], lr: 0.001160, loss: 0.4025
2022-09-28 01:43:00 - train: epoch 0082, iter [01080, 01251], lr: 0.001160, loss: 0.4118
2022-09-28 01:43:17 - train: epoch 0082, iter [01090, 01251], lr: 0.001160, loss: 0.3990
2022-09-28 01:43:35 - train: epoch 0082, iter [01100, 01251], lr: 0.001160, loss: 0.4143
2022-09-28 01:43:53 - train: epoch 0082, iter [01110, 01251], lr: 0.001160, loss: 0.4342
2022-09-28 01:44:11 - train: epoch 0082, iter [01120, 01251], lr: 0.001160, loss: 0.4124
2022-09-28 01:44:29 - train: epoch 0082, iter [01130, 01251], lr: 0.001160, loss: 0.4199
2022-09-28 01:44:47 - train: epoch 0082, iter [01140, 01251], lr: 0.001160, loss: 0.4064
2022-09-28 01:45:05 - train: epoch 0082, iter [01150, 01251], lr: 0.001160, loss: 0.4047
2022-09-28 01:45:23 - train: epoch 0082, iter [01160, 01251], lr: 0.001160, loss: 0.4097
2022-09-28 01:45:41 - train: epoch 0082, iter [01170, 01251], lr: 0.001160, loss: 0.4039
2022-09-28 01:45:58 - train: epoch 0082, iter [01180, 01251], lr: 0.001160, loss: 0.3993
2022-09-28 01:46:16 - train: epoch 0082, iter [01190, 01251], lr: 0.001160, loss: 0.4272
2022-09-28 01:46:34 - train: epoch 0082, iter [01200, 01251], lr: 0.001160, loss: 0.4158
2022-09-28 01:46:52 - train: epoch 0082, iter [01210, 01251], lr: 0.001160, loss: 0.3895
2022-09-28 01:47:10 - train: epoch 0082, iter [01220, 01251], lr: 0.001160, loss: 0.4103
2022-09-28 01:47:28 - train: epoch 0082, iter [01230, 01251], lr: 0.001160, loss: 0.4223
2022-09-28 01:47:46 - train: epoch 0082, iter [01240, 01251], lr: 0.001160, loss: 0.3902
2022-09-28 01:48:03 - train: epoch 0082, iter [01250, 01251], lr: 0.001160, loss: 0.4114
2022-09-28 01:48:07 - train: epoch 082, train_loss: 0.4146
2022-09-28 01:48:09 - until epoch: 082, best_loss: 0.4146
2022-09-28 01:48:09 - epoch 083 lr: 0.001160
2022-09-28 01:48:43 - train: epoch 0083, iter [00010, 01251], lr: 0.001160, loss: 0.4143
2022-09-28 01:49:00 - train: epoch 0083, iter [00020, 01251], lr: 0.001160, loss: 0.4323
2022-09-28 01:49:18 - train: epoch 0083, iter [00030, 01251], lr: 0.001160, loss: 0.4157
2022-09-28 01:49:36 - train: epoch 0083, iter [00040, 01251], lr: 0.001160, loss: 0.4197
2022-09-28 01:49:54 - train: epoch 0083, iter [00050, 01251], lr: 0.001160, loss: 0.4110
2022-09-28 01:50:12 - train: epoch 0083, iter [00060, 01251], lr: 0.001160, loss: 0.3933
2022-09-28 01:50:30 - train: epoch 0083, iter [00070, 01251], lr: 0.001160, loss: 0.4319
2022-09-28 01:50:48 - train: epoch 0083, iter [00080, 01251], lr: 0.001160, loss: 0.4063
2022-09-28 01:51:06 - train: epoch 0083, iter [00090, 01251], lr: 0.001160, loss: 0.4125
2022-09-28 01:51:24 - train: epoch 0083, iter [00100, 01251], lr: 0.001160, loss: 0.4194
2022-09-28 01:51:42 - train: epoch 0083, iter [00110, 01251], lr: 0.001160, loss: 0.4000
2022-09-28 01:51:59 - train: epoch 0083, iter [00120, 01251], lr: 0.001160, loss: 0.4188
2022-09-28 01:52:17 - train: epoch 0083, iter [00130, 01251], lr: 0.001160, loss: 0.4224
2022-09-28 01:52:35 - train: epoch 0083, iter [00140, 01251], lr: 0.001160, loss: 0.4159
2022-09-28 01:52:53 - train: epoch 0083, iter [00150, 01251], lr: 0.001160, loss: 0.4130
2022-09-28 01:53:11 - train: epoch 0083, iter [00160, 01251], lr: 0.001160, loss: 0.4249
2022-09-28 01:53:29 - train: epoch 0083, iter [00170, 01251], lr: 0.001160, loss: 0.4150
2022-09-28 01:53:47 - train: epoch 0083, iter [00180, 01251], lr: 0.001160, loss: 0.4372
2022-09-28 01:54:05 - train: epoch 0083, iter [00190, 01251], lr: 0.001160, loss: 0.4064
2022-09-28 01:54:23 - train: epoch 0083, iter [00200, 01251], lr: 0.001160, loss: 0.3809
2022-09-28 01:54:40 - train: epoch 0083, iter [00210, 01251], lr: 0.001160, loss: 0.4253
2022-09-28 01:54:59 - train: epoch 0083, iter [00220, 01251], lr: 0.001160, loss: 0.4082
2022-09-28 01:55:17 - train: epoch 0083, iter [00230, 01251], lr: 0.001160, loss: 0.4217
2022-09-28 01:55:35 - train: epoch 0083, iter [00240, 01251], lr: 0.001160, loss: 0.4101
2022-09-28 01:55:52 - train: epoch 0083, iter [00250, 01251], lr: 0.001160, loss: 0.4122
2022-09-28 01:56:11 - train: epoch 0083, iter [00260, 01251], lr: 0.001160, loss: 0.4237
2022-09-28 01:56:28 - train: epoch 0083, iter [00270, 01251], lr: 0.001160, loss: 0.4250
2022-09-28 01:56:47 - train: epoch 0083, iter [00280, 01251], lr: 0.001160, loss: 0.4163
2022-09-28 01:57:04 - train: epoch 0083, iter [00290, 01251], lr: 0.001160, loss: 0.4221
2022-09-28 01:57:22 - train: epoch 0083, iter [00300, 01251], lr: 0.001160, loss: 0.3946
2022-09-28 01:57:40 - train: epoch 0083, iter [00310, 01251], lr: 0.001160, loss: 0.4025
2022-09-28 01:57:58 - train: epoch 0083, iter [00320, 01251], lr: 0.001160, loss: 0.4045
2022-09-28 01:58:16 - train: epoch 0083, iter [00330, 01251], lr: 0.001160, loss: 0.4161
2022-09-28 01:58:34 - train: epoch 0083, iter [00340, 01251], lr: 0.001160, loss: 0.4219
2022-09-28 01:58:52 - train: epoch 0083, iter [00350, 01251], lr: 0.001160, loss: 0.4154
2022-09-28 01:59:10 - train: epoch 0083, iter [00360, 01251], lr: 0.001160, loss: 0.4186
2022-09-28 01:59:28 - train: epoch 0083, iter [00370, 01251], lr: 0.001160, loss: 0.4268
2022-09-28 01:59:46 - train: epoch 0083, iter [00380, 01251], lr: 0.001160, loss: 0.4110
2022-09-28 02:00:03 - train: epoch 0083, iter [00390, 01251], lr: 0.001160, loss: 0.4061
2022-09-28 02:00:21 - train: epoch 0083, iter [00400, 01251], lr: 0.001160, loss: 0.4226
2022-09-28 02:00:39 - train: epoch 0083, iter [00410, 01251], lr: 0.001160, loss: 0.4159
2022-09-28 02:00:57 - train: epoch 0083, iter [00420, 01251], lr: 0.001160, loss: 0.4006
2022-09-28 02:01:15 - train: epoch 0083, iter [00430, 01251], lr: 0.001160, loss: 0.4333
2022-09-28 02:01:33 - train: epoch 0083, iter [00440, 01251], lr: 0.001159, loss: 0.4097
2022-09-28 02:01:51 - train: epoch 0083, iter [00450, 01251], lr: 0.001159, loss: 0.4141
2022-09-28 02:02:09 - train: epoch 0083, iter [00460, 01251], lr: 0.001159, loss: 0.4014
2022-09-28 02:02:27 - train: epoch 0083, iter [00470, 01251], lr: 0.001159, loss: 0.4318
2022-09-28 02:02:45 - train: epoch 0083, iter [00480, 01251], lr: 0.001159, loss: 0.4196
2022-09-28 02:03:02 - train: epoch 0083, iter [00490, 01251], lr: 0.001159, loss: 0.4126
2022-09-28 02:03:20 - train: epoch 0083, iter [00500, 01251], lr: 0.001159, loss: 0.4157
2022-09-28 02:03:38 - train: epoch 0083, iter [00510, 01251], lr: 0.001159, loss: 0.4017
2022-09-28 02:03:56 - train: epoch 0083, iter [00520, 01251], lr: 0.001159, loss: 0.3939
2022-09-28 02:04:14 - train: epoch 0083, iter [00530, 01251], lr: 0.001159, loss: 0.4224
2022-09-28 02:04:32 - train: epoch 0083, iter [00540, 01251], lr: 0.001159, loss: 0.4267
2022-09-28 02:04:50 - train: epoch 0083, iter [00550, 01251], lr: 0.001159, loss: 0.4071
2022-09-28 02:05:08 - train: epoch 0083, iter [00560, 01251], lr: 0.001159, loss: 0.4265
2022-09-28 02:05:25 - train: epoch 0083, iter [00570, 01251], lr: 0.001159, loss: 0.4049
2022-09-28 02:05:43 - train: epoch 0083, iter [00580, 01251], lr: 0.001159, loss: 0.4266
2022-09-28 02:06:01 - train: epoch 0083, iter [00590, 01251], lr: 0.001159, loss: 0.4105
2022-09-28 02:06:19 - train: epoch 0083, iter [00600, 01251], lr: 0.001159, loss: 0.4196
2022-09-28 02:06:37 - train: epoch 0083, iter [00610, 01251], lr: 0.001159, loss: 0.4071
2022-09-28 02:06:55 - train: epoch 0083, iter [00620, 01251], lr: 0.001159, loss: 0.4228
2022-09-28 02:07:12 - train: epoch 0083, iter [00630, 01251], lr: 0.001159, loss: 0.3996
2022-09-28 02:07:30 - train: epoch 0083, iter [00640, 01251], lr: 0.001159, loss: 0.4433
2022-09-28 02:07:48 - train: epoch 0083, iter [00650, 01251], lr: 0.001159, loss: 0.4063
2022-09-28 02:08:06 - train: epoch 0083, iter [00660, 01251], lr: 0.001159, loss: 0.4061
2022-09-28 02:08:24 - train: epoch 0083, iter [00670, 01251], lr: 0.001159, loss: 0.4393
2022-09-28 02:08:42 - train: epoch 0083, iter [00680, 01251], lr: 0.001159, loss: 0.4200
2022-09-28 02:09:00 - train: epoch 0083, iter [00690, 01251], lr: 0.001159, loss: 0.4308
2022-09-28 02:09:18 - train: epoch 0083, iter [00700, 01251], lr: 0.001159, loss: 0.4071
2022-09-28 02:09:36 - train: epoch 0083, iter [00710, 01251], lr: 0.001159, loss: 0.4234
2022-09-28 02:09:53 - train: epoch 0083, iter [00720, 01251], lr: 0.001159, loss: 0.4279
2022-09-28 02:10:11 - train: epoch 0083, iter [00730, 01251], lr: 0.001159, loss: 0.4174
2022-09-28 02:10:29 - train: epoch 0083, iter [00740, 01251], lr: 0.001159, loss: 0.4073
2022-09-28 02:10:47 - train: epoch 0083, iter [00750, 01251], lr: 0.001159, loss: 0.3918
2022-09-28 02:11:05 - train: epoch 0083, iter [00760, 01251], lr: 0.001159, loss: 0.4254
2022-09-28 02:11:23 - train: epoch 0083, iter [00770, 01251], lr: 0.001159, loss: 0.4099
2022-09-28 02:11:41 - train: epoch 0083, iter [00780, 01251], lr: 0.001159, loss: 0.4305
2022-09-28 02:11:59 - train: epoch 0083, iter [00790, 01251], lr: 0.001159, loss: 0.4179
2022-09-28 02:12:17 - train: epoch 0083, iter [00800, 01251], lr: 0.001159, loss: 0.4213
2022-09-28 02:12:35 - train: epoch 0083, iter [00810, 01251], lr: 0.001159, loss: 0.4023
2022-09-28 02:12:53 - train: epoch 0083, iter [00820, 01251], lr: 0.001159, loss: 0.4205
2022-09-28 02:13:10 - train: epoch 0083, iter [00830, 01251], lr: 0.001159, loss: 0.4117
2022-09-28 02:13:29 - train: epoch 0083, iter [00840, 01251], lr: 0.001159, loss: 0.4321
2022-09-28 02:13:46 - train: epoch 0083, iter [00850, 01251], lr: 0.001159, loss: 0.4299
2022-09-28 02:14:04 - train: epoch 0083, iter [00860, 01251], lr: 0.001159, loss: 0.4202
2022-09-28 02:14:22 - train: epoch 0083, iter [00870, 01251], lr: 0.001159, loss: 0.4035
2022-09-28 02:14:40 - train: epoch 0083, iter [00880, 01251], lr: 0.001159, loss: 0.4113
2022-09-28 02:14:58 - train: epoch 0083, iter [00890, 01251], lr: 0.001159, loss: 0.4196
2022-09-28 02:15:16 - train: epoch 0083, iter [00900, 01251], lr: 0.001159, loss: 0.3959
2022-09-28 02:15:34 - train: epoch 0083, iter [00910, 01251], lr: 0.001159, loss: 0.4040
2022-09-28 02:15:52 - train: epoch 0083, iter [00920, 01251], lr: 0.001159, loss: 0.4265
2022-09-28 02:16:11 - train: epoch 0083, iter [00930, 01251], lr: 0.001159, loss: 0.4333
2022-09-28 02:16:28 - train: epoch 0083, iter [00940, 01251], lr: 0.001159, loss: 0.4137
2022-09-28 02:16:46 - train: epoch 0083, iter [00950, 01251], lr: 0.001159, loss: 0.4255
2022-09-28 02:17:04 - train: epoch 0083, iter [00960, 01251], lr: 0.001159, loss: 0.4116
2022-09-28 02:17:22 - train: epoch 0083, iter [00970, 01251], lr: 0.001159, loss: 0.3943
2022-09-28 02:17:40 - train: epoch 0083, iter [00980, 01251], lr: 0.001159, loss: 0.4118
2022-09-28 02:17:58 - train: epoch 0083, iter [00990, 01251], lr: 0.001159, loss: 0.4135
2022-09-28 02:18:16 - train: epoch 0083, iter [01000, 01251], lr: 0.001159, loss: 0.4229
2022-09-28 02:18:35 - train: epoch 0083, iter [01010, 01251], lr: 0.001159, loss: 0.4205
2022-09-28 02:18:53 - train: epoch 0083, iter [01020, 01251], lr: 0.001159, loss: 0.4100
2022-09-28 02:19:11 - train: epoch 0083, iter [01030, 01251], lr: 0.001159, loss: 0.4257
2022-09-28 02:19:29 - train: epoch 0083, iter [01040, 01251], lr: 0.001159, loss: 0.4077
2022-09-28 02:19:47 - train: epoch 0083, iter [01050, 01251], lr: 0.001159, loss: 0.4207
2022-09-28 02:20:05 - train: epoch 0083, iter [01060, 01251], lr: 0.001159, loss: 0.4004
2022-09-28 02:20:23 - train: epoch 0083, iter [01070, 01251], lr: 0.001159, loss: 0.4033
2022-09-28 02:20:41 - train: epoch 0083, iter [01080, 01251], lr: 0.001159, loss: 0.3937
2022-09-28 02:20:59 - train: epoch 0083, iter [01090, 01251], lr: 0.001158, loss: 0.3889
2022-09-28 02:21:18 - train: epoch 0083, iter [01100, 01251], lr: 0.001158, loss: 0.4130
2022-09-28 02:21:36 - train: epoch 0083, iter [01110, 01251], lr: 0.001158, loss: 0.4145
2022-09-28 02:21:54 - train: epoch 0083, iter [01120, 01251], lr: 0.001158, loss: 0.4168
2022-09-28 02:22:12 - train: epoch 0083, iter [01130, 01251], lr: 0.001158, loss: 0.4076
2022-09-28 02:22:30 - train: epoch 0083, iter [01140, 01251], lr: 0.001158, loss: 0.4293
2022-09-28 02:22:48 - train: epoch 0083, iter [01150, 01251], lr: 0.001158, loss: 0.4115
2022-09-28 02:23:06 - train: epoch 0083, iter [01160, 01251], lr: 0.001158, loss: 0.4184
2022-09-28 02:23:24 - train: epoch 0083, iter [01170, 01251], lr: 0.001158, loss: 0.4049
2022-09-28 02:23:42 - train: epoch 0083, iter [01180, 01251], lr: 0.001158, loss: 0.4045
2022-09-28 02:24:00 - train: epoch 0083, iter [01190, 01251], lr: 0.001158, loss: 0.4054
2022-09-28 02:24:18 - train: epoch 0083, iter [01200, 01251], lr: 0.001158, loss: 0.4059
2022-09-28 02:24:36 - train: epoch 0083, iter [01210, 01251], lr: 0.001158, loss: 0.4123
2022-09-28 02:24:54 - train: epoch 0083, iter [01220, 01251], lr: 0.001158, loss: 0.4106
2022-09-28 02:25:12 - train: epoch 0083, iter [01230, 01251], lr: 0.001158, loss: 0.4203
2022-09-28 02:25:30 - train: epoch 0083, iter [01240, 01251], lr: 0.001158, loss: 0.4075
2022-09-28 02:25:47 - train: epoch 0083, iter [01250, 01251], lr: 0.001158, loss: 0.4199
2022-09-28 02:25:51 - train: epoch 083, train_loss: 0.4146
2022-09-28 02:25:52 - until epoch: 083, best_loss: 0.4146
2022-09-28 02:25:52 - epoch 084 lr: 0.001158
2022-09-28 02:26:26 - train: epoch 0084, iter [00010, 01251], lr: 0.001158, loss: 0.3939
2022-09-28 02:26:44 - train: epoch 0084, iter [00020, 01251], lr: 0.001158, loss: 0.4391
2022-09-28 02:27:02 - train: epoch 0084, iter [00030, 01251], lr: 0.001158, loss: 0.4281
2022-09-28 02:27:20 - train: epoch 0084, iter [00040, 01251], lr: 0.001158, loss: 0.4097
2022-09-28 02:27:38 - train: epoch 0084, iter [00050, 01251], lr: 0.001158, loss: 0.4250
2022-09-28 02:27:56 - train: epoch 0084, iter [00060, 01251], lr: 0.001158, loss: 0.4017
2022-09-28 02:28:14 - train: epoch 0084, iter [00070, 01251], lr: 0.001158, loss: 0.4360
2022-09-28 02:28:32 - train: epoch 0084, iter [00080, 01251], lr: 0.001158, loss: 0.4177
2022-09-28 02:28:51 - train: epoch 0084, iter [00090, 01251], lr: 0.001158, loss: 0.4090
2022-09-28 02:29:09 - train: epoch 0084, iter [00100, 01251], lr: 0.001158, loss: 0.4258
2022-09-28 02:29:27 - train: epoch 0084, iter [00110, 01251], lr: 0.001158, loss: 0.4212
2022-09-28 02:29:45 - train: epoch 0084, iter [00120, 01251], lr: 0.001158, loss: 0.4198
2022-09-28 02:30:03 - train: epoch 0084, iter [00130, 01251], lr: 0.001158, loss: 0.4105
2022-09-28 02:30:21 - train: epoch 0084, iter [00140, 01251], lr: 0.001158, loss: 0.4070
2022-09-28 02:30:39 - train: epoch 0084, iter [00150, 01251], lr: 0.001158, loss: 0.4076
2022-09-28 02:30:57 - train: epoch 0084, iter [00160, 01251], lr: 0.001158, loss: 0.4325
2022-09-28 02:31:15 - train: epoch 0084, iter [00170, 01251], lr: 0.001158, loss: 0.4168
2022-09-28 02:31:33 - train: epoch 0084, iter [00180, 01251], lr: 0.001158, loss: 0.4214
2022-09-28 02:31:51 - train: epoch 0084, iter [00190, 01251], lr: 0.001158, loss: 0.4218
2022-09-28 02:32:09 - train: epoch 0084, iter [00200, 01251], lr: 0.001158, loss: 0.4107
2022-09-28 02:32:27 - train: epoch 0084, iter [00210, 01251], lr: 0.001158, loss: 0.4336
2022-09-28 02:32:46 - train: epoch 0084, iter [00220, 01251], lr: 0.001158, loss: 0.4263
2022-09-28 02:33:04 - train: epoch 0084, iter [00230, 01251], lr: 0.001158, loss: 0.4085
2022-09-28 02:33:22 - train: epoch 0084, iter [00240, 01251], lr: 0.001158, loss: 0.4154
2022-09-28 02:33:40 - train: epoch 0084, iter [00250, 01251], lr: 0.001158, loss: 0.4240
2022-09-28 02:33:58 - train: epoch 0084, iter [00260, 01251], lr: 0.001158, loss: 0.4039
2022-09-28 02:34:16 - train: epoch 0084, iter [00270, 01251], lr: 0.001158, loss: 0.4221
2022-09-28 02:34:34 - train: epoch 0084, iter [00280, 01251], lr: 0.001158, loss: 0.4271
2022-09-28 02:34:52 - train: epoch 0084, iter [00290, 01251], lr: 0.001158, loss: 0.4217
2022-09-28 02:35:10 - train: epoch 0084, iter [00300, 01251], lr: 0.001158, loss: 0.4181
2022-09-28 02:35:28 - train: epoch 0084, iter [00310, 01251], lr: 0.001158, loss: 0.4181
2022-09-28 02:35:46 - train: epoch 0084, iter [00320, 01251], lr: 0.001158, loss: 0.4202
2022-09-28 02:36:04 - train: epoch 0084, iter [00330, 01251], lr: 0.001158, loss: 0.4095
2022-09-28 02:36:21 - train: epoch 0084, iter [00340, 01251], lr: 0.001158, loss: 0.4325
2022-09-28 02:36:40 - train: epoch 0084, iter [00350, 01251], lr: 0.001158, loss: 0.4182
2022-09-28 02:36:57 - train: epoch 0084, iter [00360, 01251], lr: 0.001158, loss: 0.4040
2022-09-28 02:37:16 - train: epoch 0084, iter [00370, 01251], lr: 0.001158, loss: 0.4100
2022-09-28 02:37:33 - train: epoch 0084, iter [00380, 01251], lr: 0.001158, loss: 0.4302
2022-09-28 02:37:52 - train: epoch 0084, iter [00390, 01251], lr: 0.001158, loss: 0.4254
2022-09-28 02:38:09 - train: epoch 0084, iter [00400, 01251], lr: 0.001158, loss: 0.4091
2022-09-28 02:38:27 - train: epoch 0084, iter [00410, 01251], lr: 0.001158, loss: 0.4264
2022-09-28 02:38:45 - train: epoch 0084, iter [00420, 01251], lr: 0.001158, loss: 0.4056
2022-09-28 02:39:03 - train: epoch 0084, iter [00430, 01251], lr: 0.001158, loss: 0.4077
2022-09-28 02:39:21 - train: epoch 0084, iter [00440, 01251], lr: 0.001158, loss: 0.4002
2022-09-28 02:39:39 - train: epoch 0084, iter [00450, 01251], lr: 0.001158, loss: 0.4081
2022-09-28 02:39:57 - train: epoch 0084, iter [00460, 01251], lr: 0.001158, loss: 0.4264
2022-09-28 02:40:15 - train: epoch 0084, iter [00470, 01251], lr: 0.001158, loss: 0.4212
2022-09-28 02:40:33 - train: epoch 0084, iter [00480, 01251], lr: 0.001158, loss: 0.4206
2022-09-28 02:40:50 - train: epoch 0084, iter [00490, 01251], lr: 0.001157, loss: 0.4116
2022-09-28 02:41:08 - train: epoch 0084, iter [00500, 01251], lr: 0.001157, loss: 0.4090
2022-09-28 02:41:26 - train: epoch 0084, iter [00510, 01251], lr: 0.001157, loss: 0.3991
2022-09-28 02:41:44 - train: epoch 0084, iter [00520, 01251], lr: 0.001157, loss: 0.4101
2022-09-28 02:42:02 - train: epoch 0084, iter [00530, 01251], lr: 0.001157, loss: 0.4304
2022-09-28 02:42:20 - train: epoch 0084, iter [00540, 01251], lr: 0.001157, loss: 0.4201
2022-09-28 02:42:38 - train: epoch 0084, iter [00550, 01251], lr: 0.001157, loss: 0.3944
2022-09-28 02:42:56 - train: epoch 0084, iter [00560, 01251], lr: 0.001157, loss: 0.4106
2022-09-28 02:43:14 - train: epoch 0084, iter [00570, 01251], lr: 0.001157, loss: 0.4236
2022-09-28 02:43:32 - train: epoch 0084, iter [00580, 01251], lr: 0.001157, loss: 0.4245
2022-09-28 02:43:50 - train: epoch 0084, iter [00590, 01251], lr: 0.001157, loss: 0.4191
2022-09-28 02:44:08 - train: epoch 0084, iter [00600, 01251], lr: 0.001157, loss: 0.3964
2022-09-28 02:44:26 - train: epoch 0084, iter [00610, 01251], lr: 0.001157, loss: 0.4175
2022-09-28 02:44:44 - train: epoch 0084, iter [00620, 01251], lr: 0.001157, loss: 0.4317
2022-09-28 02:45:02 - train: epoch 0084, iter [00630, 01251], lr: 0.001157, loss: 0.4138
2022-09-28 02:45:19 - train: epoch 0084, iter [00640, 01251], lr: 0.001157, loss: 0.4124
2022-09-28 02:45:37 - train: epoch 0084, iter [00650, 01251], lr: 0.001157, loss: 0.3865
2022-09-28 02:45:55 - train: epoch 0084, iter [00660, 01251], lr: 0.001157, loss: 0.4174
2022-09-28 02:46:13 - train: epoch 0084, iter [00670, 01251], lr: 0.001157, loss: 0.4202
2022-09-28 02:46:31 - train: epoch 0084, iter [00680, 01251], lr: 0.001157, loss: 0.4307
2022-09-28 02:46:49 - train: epoch 0084, iter [00690, 01251], lr: 0.001157, loss: 0.4143
2022-09-28 02:47:07 - train: epoch 0084, iter [00700, 01251], lr: 0.001157, loss: 0.4173
2022-09-28 02:47:25 - train: epoch 0084, iter [00710, 01251], lr: 0.001157, loss: 0.4208
2022-09-28 02:47:44 - train: epoch 0084, iter [00720, 01251], lr: 0.001157, loss: 0.4035
2022-09-28 02:48:02 - train: epoch 0084, iter [00730, 01251], lr: 0.001157, loss: 0.4326
2022-09-28 02:48:20 - train: epoch 0084, iter [00740, 01251], lr: 0.001157, loss: 0.3984
2022-09-28 02:48:38 - train: epoch 0084, iter [00750, 01251], lr: 0.001157, loss: 0.4060
2022-09-28 02:48:56 - train: epoch 0084, iter [00760, 01251], lr: 0.001157, loss: 0.4133
2022-09-28 02:49:14 - train: epoch 0084, iter [00770, 01251], lr: 0.001157, loss: 0.4136
2022-09-28 02:49:32 - train: epoch 0084, iter [00780, 01251], lr: 0.001157, loss: 0.4223
2022-09-28 02:49:50 - train: epoch 0084, iter [00790, 01251], lr: 0.001157, loss: 0.4031
2022-09-28 02:50:07 - train: epoch 0084, iter [00800, 01251], lr: 0.001157, loss: 0.4076
2022-09-28 02:50:25 - train: epoch 0084, iter [00810, 01251], lr: 0.001157, loss: 0.4161
2022-09-28 02:50:43 - train: epoch 0084, iter [00820, 01251], lr: 0.001157, loss: 0.4295
2022-09-28 02:51:01 - train: epoch 0084, iter [00830, 01251], lr: 0.001157, loss: 0.3994
2022-09-28 02:51:19 - train: epoch 0084, iter [00840, 01251], lr: 0.001157, loss: 0.3912
2022-09-28 02:51:37 - train: epoch 0084, iter [00850, 01251], lr: 0.001157, loss: 0.4088
2022-09-28 02:51:56 - train: epoch 0084, iter [00860, 01251], lr: 0.001157, loss: 0.3973
2022-09-28 02:52:14 - train: epoch 0084, iter [00870, 01251], lr: 0.001157, loss: 0.3995
2022-09-28 02:52:31 - train: epoch 0084, iter [00880, 01251], lr: 0.001157, loss: 0.4158
2022-09-28 02:52:49 - train: epoch 0084, iter [00890, 01251], lr: 0.001157, loss: 0.4025
2022-09-28 02:53:08 - train: epoch 0084, iter [00900, 01251], lr: 0.001157, loss: 0.3974
2022-09-28 02:53:25 - train: epoch 0084, iter [00910, 01251], lr: 0.001157, loss: 0.4354
2022-09-28 02:53:43 - train: epoch 0084, iter [00920, 01251], lr: 0.001157, loss: 0.4236
2022-09-28 02:54:01 - train: epoch 0084, iter [00930, 01251], lr: 0.001157, loss: 0.4237
2022-09-28 02:54:20 - train: epoch 0084, iter [00940, 01251], lr: 0.001157, loss: 0.4052
2022-09-28 02:54:37 - train: epoch 0084, iter [00950, 01251], lr: 0.001157, loss: 0.4140
2022-09-28 02:54:55 - train: epoch 0084, iter [00960, 01251], lr: 0.001157, loss: 0.4325
2022-09-28 02:55:13 - train: epoch 0084, iter [00970, 01251], lr: 0.001157, loss: 0.4279
2022-09-28 02:55:31 - train: epoch 0084, iter [00980, 01251], lr: 0.001157, loss: 0.4142
2022-09-28 02:55:49 - train: epoch 0084, iter [00990, 01251], lr: 0.001157, loss: 0.4105
2022-09-28 02:56:07 - train: epoch 0084, iter [01000, 01251], lr: 0.001157, loss: 0.4023
2022-09-28 02:56:25 - train: epoch 0084, iter [01010, 01251], lr: 0.001157, loss: 0.4255
2022-09-28 02:56:43 - train: epoch 0084, iter [01020, 01251], lr: 0.001157, loss: 0.4126
2022-09-28 02:57:01 - train: epoch 0084, iter [01030, 01251], lr: 0.001157, loss: 0.3864
2022-09-28 02:57:19 - train: epoch 0084, iter [01040, 01251], lr: 0.001157, loss: 0.4128
2022-09-28 02:57:37 - train: epoch 0084, iter [01050, 01251], lr: 0.001157, loss: 0.4069
2022-09-28 02:57:55 - train: epoch 0084, iter [01060, 01251], lr: 0.001157, loss: 0.4307
2022-09-28 02:58:13 - train: epoch 0084, iter [01070, 01251], lr: 0.001157, loss: 0.4093
2022-09-28 02:58:31 - train: epoch 0084, iter [01080, 01251], lr: 0.001157, loss: 0.4257
2022-09-28 02:58:49 - train: epoch 0084, iter [01090, 01251], lr: 0.001157, loss: 0.4029
2022-09-28 02:59:06 - train: epoch 0084, iter [01100, 01251], lr: 0.001157, loss: 0.4164
2022-09-28 02:59:25 - train: epoch 0084, iter [01110, 01251], lr: 0.001157, loss: 0.3959
2022-09-28 02:59:43 - train: epoch 0084, iter [01120, 01251], lr: 0.001157, loss: 0.4310
2022-09-28 03:00:01 - train: epoch 0084, iter [01130, 01251], lr: 0.001156, loss: 0.3990
2022-09-28 03:00:19 - train: epoch 0084, iter [01140, 01251], lr: 0.001156, loss: 0.3978
2022-09-28 03:00:37 - train: epoch 0084, iter [01150, 01251], lr: 0.001156, loss: 0.4251
2022-09-28 03:00:55 - train: epoch 0084, iter [01160, 01251], lr: 0.001156, loss: 0.4052
2022-09-28 03:01:13 - train: epoch 0084, iter [01170, 01251], lr: 0.001156, loss: 0.3989
2022-09-28 03:01:32 - train: epoch 0084, iter [01180, 01251], lr: 0.001156, loss: 0.4040
2022-09-28 03:01:49 - train: epoch 0084, iter [01190, 01251], lr: 0.001156, loss: 0.4275
2022-09-28 03:02:07 - train: epoch 0084, iter [01200, 01251], lr: 0.001156, loss: 0.4320
2022-09-28 03:02:25 - train: epoch 0084, iter [01210, 01251], lr: 0.001156, loss: 0.4124
2022-09-28 03:02:43 - train: epoch 0084, iter [01220, 01251], lr: 0.001156, loss: 0.4277
2022-09-28 03:03:01 - train: epoch 0084, iter [01230, 01251], lr: 0.001156, loss: 0.3996
2022-09-28 03:03:19 - train: epoch 0084, iter [01240, 01251], lr: 0.001156, loss: 0.4192
2022-09-28 03:03:36 - train: epoch 0084, iter [01250, 01251], lr: 0.001156, loss: 0.3968
2022-09-28 03:03:40 - train: epoch 084, train_loss: 0.4145
2022-09-28 03:03:42 - until epoch: 084, best_loss: 0.4145
2022-09-28 03:03:42 - epoch 085 lr: 0.001156
2022-09-28 03:04:15 - train: epoch 0085, iter [00010, 01251], lr: 0.001156, loss: 0.4023
2022-09-28 03:04:33 - train: epoch 0085, iter [00020, 01251], lr: 0.001156, loss: 0.4228
2022-09-28 03:04:51 - train: epoch 0085, iter [00030, 01251], lr: 0.001156, loss: 0.4249
2022-09-28 03:05:09 - train: epoch 0085, iter [00040, 01251], lr: 0.001156, loss: 0.4090
2022-09-28 03:05:26 - train: epoch 0085, iter [00050, 01251], lr: 0.001156, loss: 0.4200
2022-09-28 03:05:44 - train: epoch 0085, iter [00060, 01251], lr: 0.001156, loss: 0.4175
2022-09-28 03:06:02 - train: epoch 0085, iter [00070, 01251], lr: 0.001156, loss: 0.4085
2022-09-28 03:06:20 - train: epoch 0085, iter [00080, 01251], lr: 0.001156, loss: 0.4037
2022-09-28 03:06:38 - train: epoch 0085, iter [00090, 01251], lr: 0.001156, loss: 0.4131
2022-09-28 03:06:56 - train: epoch 0085, iter [00100, 01251], lr: 0.001156, loss: 0.4160
2022-09-28 03:07:13 - train: epoch 0085, iter [00110, 01251], lr: 0.001156, loss: 0.4235
2022-09-28 03:07:32 - train: epoch 0085, iter [00120, 01251], lr: 0.001156, loss: 0.4177
2022-09-28 03:07:50 - train: epoch 0085, iter [00130, 01251], lr: 0.001156, loss: 0.4056
2022-09-28 03:08:08 - train: epoch 0085, iter [00140, 01251], lr: 0.001156, loss: 0.4153
2022-09-28 03:08:26 - train: epoch 0085, iter [00150, 01251], lr: 0.001156, loss: 0.4100
2022-09-28 03:08:44 - train: epoch 0085, iter [00160, 01251], lr: 0.001156, loss: 0.4378
2022-09-28 03:09:02 - train: epoch 0085, iter [00170, 01251], lr: 0.001156, loss: 0.4143
2022-09-28 03:09:20 - train: epoch 0085, iter [00180, 01251], lr: 0.001156, loss: 0.4142
2022-09-28 03:09:38 - train: epoch 0085, iter [00190, 01251], lr: 0.001156, loss: 0.4199
2022-09-28 03:09:56 - train: epoch 0085, iter [00200, 01251], lr: 0.001156, loss: 0.4331
2022-09-28 03:10:14 - train: epoch 0085, iter [00210, 01251], lr: 0.001156, loss: 0.4304
2022-09-28 03:10:32 - train: epoch 0085, iter [00220, 01251], lr: 0.001156, loss: 0.4121
2022-09-28 03:10:50 - train: epoch 0085, iter [00230, 01251], lr: 0.001156, loss: 0.4203
2022-09-28 03:11:08 - train: epoch 0085, iter [00240, 01251], lr: 0.001156, loss: 0.4117
2022-09-28 03:11:26 - train: epoch 0085, iter [00250, 01251], lr: 0.001156, loss: 0.4212
2022-09-28 03:11:44 - train: epoch 0085, iter [00260, 01251], lr: 0.001156, loss: 0.4256
2022-09-28 03:12:02 - train: epoch 0085, iter [00270, 01251], lr: 0.001156, loss: 0.4335
2022-09-28 03:12:20 - train: epoch 0085, iter [00280, 01251], lr: 0.001156, loss: 0.4145
2022-09-28 03:12:38 - train: epoch 0085, iter [00290, 01251], lr: 0.001156, loss: 0.4029
2022-09-28 03:12:56 - train: epoch 0085, iter [00300, 01251], lr: 0.001156, loss: 0.4162
2022-09-28 03:13:14 - train: epoch 0085, iter [00310, 01251], lr: 0.001156, loss: 0.4012
2022-09-28 03:13:32 - train: epoch 0085, iter [00320, 01251], lr: 0.001156, loss: 0.4161
2022-09-28 03:13:50 - train: epoch 0085, iter [00330, 01251], lr: 0.001156, loss: 0.4124
2022-09-28 03:14:08 - train: epoch 0085, iter [00340, 01251], lr: 0.001156, loss: 0.4193
2022-09-28 03:14:26 - train: epoch 0085, iter [00350, 01251], lr: 0.001156, loss: 0.4231
2022-09-28 03:14:44 - train: epoch 0085, iter [00360, 01251], lr: 0.001156, loss: 0.3958
2022-09-28 03:15:02 - train: epoch 0085, iter [00370, 01251], lr: 0.001156, loss: 0.4095
2022-09-28 03:15:20 - train: epoch 0085, iter [00380, 01251], lr: 0.001156, loss: 0.4027
2022-09-28 03:15:38 - train: epoch 0085, iter [00390, 01251], lr: 0.001156, loss: 0.4318
2022-09-28 03:15:55 - train: epoch 0085, iter [00400, 01251], lr: 0.001156, loss: 0.4092
2022-09-28 03:16:13 - train: epoch 0085, iter [00410, 01251], lr: 0.001156, loss: 0.4216
2022-09-28 03:16:32 - train: epoch 0085, iter [00420, 01251], lr: 0.001156, loss: 0.4201
2022-09-28 03:16:49 - train: epoch 0085, iter [00430, 01251], lr: 0.001156, loss: 0.4104
2022-09-28 03:17:07 - train: epoch 0085, iter [00440, 01251], lr: 0.001156, loss: 0.4131
2022-09-28 03:17:25 - train: epoch 0085, iter [00450, 01251], lr: 0.001156, loss: 0.4056
2022-09-28 03:17:43 - train: epoch 0085, iter [00460, 01251], lr: 0.001156, loss: 0.4237
2022-09-28 03:18:01 - train: epoch 0085, iter [00470, 01251], lr: 0.001156, loss: 0.4212
2022-09-28 03:18:19 - train: epoch 0085, iter [00480, 01251], lr: 0.001156, loss: 0.4056
2022-09-28 03:18:37 - train: epoch 0085, iter [00490, 01251], lr: 0.001156, loss: 0.3955
2022-09-28 03:18:55 - train: epoch 0085, iter [00500, 01251], lr: 0.001156, loss: 0.3932
2022-09-28 03:19:13 - train: epoch 0085, iter [00510, 01251], lr: 0.001156, loss: 0.4289
2022-09-28 03:19:31 - train: epoch 0085, iter [00520, 01251], lr: 0.001155, loss: 0.4197
2022-09-28 03:19:49 - train: epoch 0085, iter [00530, 01251], lr: 0.001155, loss: 0.4377
2022-09-28 03:20:07 - train: epoch 0085, iter [00540, 01251], lr: 0.001155, loss: 0.4079
2022-09-28 03:20:25 - train: epoch 0085, iter [00550, 01251], lr: 0.001155, loss: 0.4224
2022-09-28 03:20:43 - train: epoch 0085, iter [00560, 01251], lr: 0.001155, loss: 0.4116
2022-09-28 03:21:02 - train: epoch 0085, iter [00570, 01251], lr: 0.001155, loss: 0.4254
2022-09-28 03:21:20 - train: epoch 0085, iter [00580, 01251], lr: 0.001155, loss: 0.4271
2022-09-28 03:21:38 - train: epoch 0085, iter [00590, 01251], lr: 0.001155, loss: 0.4420
2022-09-28 03:21:56 - train: epoch 0085, iter [00600, 01251], lr: 0.001155, loss: 0.3972
2022-09-28 03:22:14 - train: epoch 0085, iter [00610, 01251], lr: 0.001155, loss: 0.4288
2022-09-28 03:22:32 - train: epoch 0085, iter [00620, 01251], lr: 0.001155, loss: 0.4105
2022-09-28 03:22:50 - train: epoch 0085, iter [00630, 01251], lr: 0.001155, loss: 0.4130
2022-09-28 03:23:08 - train: epoch 0085, iter [00640, 01251], lr: 0.001155, loss: 0.4300
2022-09-28 03:23:26 - train: epoch 0085, iter [00650, 01251], lr: 0.001155, loss: 0.4243
2022-09-28 03:23:44 - train: epoch 0085, iter [00660, 01251], lr: 0.001155, loss: 0.4422
2022-09-28 03:24:02 - train: epoch 0085, iter [00670, 01251], lr: 0.001155, loss: 0.4133
2022-09-28 03:24:21 - train: epoch 0085, iter [00680, 01251], lr: 0.001155, loss: 0.4129
2022-09-28 03:24:39 - train: epoch 0085, iter [00690, 01251], lr: 0.001155, loss: 0.3953
2022-09-28 03:24:57 - train: epoch 0085, iter [00700, 01251], lr: 0.001155, loss: 0.4185
2022-09-28 03:25:15 - train: epoch 0085, iter [00710, 01251], lr: 0.001155, loss: 0.4149
2022-09-28 03:25:33 - train: epoch 0085, iter [00720, 01251], lr: 0.001155, loss: 0.4140
2022-09-28 03:25:51 - train: epoch 0085, iter [00730, 01251], lr: 0.001155, loss: 0.4141
2022-09-28 03:26:09 - train: epoch 0085, iter [00740, 01251], lr: 0.001155, loss: 0.4285
2022-09-28 03:26:27 - train: epoch 0085, iter [00750, 01251], lr: 0.001155, loss: 0.4378
2022-09-28 03:26:45 - train: epoch 0085, iter [00760, 01251], lr: 0.001155, loss: 0.4295
2022-09-28 03:27:03 - train: epoch 0085, iter [00770, 01251], lr: 0.001155, loss: 0.4180
2022-09-28 03:27:21 - train: epoch 0085, iter [00780, 01251], lr: 0.001155, loss: 0.4192
2022-09-28 03:27:39 - train: epoch 0085, iter [00790, 01251], lr: 0.001155, loss: 0.4155
2022-09-28 03:27:57 - train: epoch 0085, iter [00800, 01251], lr: 0.001155, loss: 0.4118
2022-09-28 03:28:15 - train: epoch 0085, iter [00810, 01251], lr: 0.001155, loss: 0.4172
2022-09-28 03:28:33 - train: epoch 0085, iter [00820, 01251], lr: 0.001155, loss: 0.4174
2022-09-28 03:28:51 - train: epoch 0085, iter [00830, 01251], lr: 0.001155, loss: 0.4239
2022-09-28 03:29:09 - train: epoch 0085, iter [00840, 01251], lr: 0.001155, loss: 0.3935
2022-09-28 03:29:27 - train: epoch 0085, iter [00850, 01251], lr: 0.001155, loss: 0.3969
2022-09-28 03:29:45 - train: epoch 0085, iter [00860, 01251], lr: 0.001155, loss: 0.4015
2022-09-28 03:30:03 - train: epoch 0085, iter [00870, 01251], lr: 0.001155, loss: 0.4265
2022-09-28 03:30:21 - train: epoch 0085, iter [00880, 01251], lr: 0.001155, loss: 0.4030
2022-09-28 03:30:39 - train: epoch 0085, iter [00890, 01251], lr: 0.001155, loss: 0.4166
2022-09-28 03:30:57 - train: epoch 0085, iter [00900, 01251], lr: 0.001155, loss: 0.4068
2022-09-28 03:31:15 - train: epoch 0085, iter [00910, 01251], lr: 0.001155, loss: 0.4070
2022-09-28 03:31:33 - train: epoch 0085, iter [00920, 01251], lr: 0.001155, loss: 0.4127
2022-09-28 03:31:51 - train: epoch 0085, iter [00930, 01251], lr: 0.001155, loss: 0.4291
2022-09-28 03:32:09 - train: epoch 0085, iter [00940, 01251], lr: 0.001155, loss: 0.4053
2022-09-28 03:32:27 - train: epoch 0085, iter [00950, 01251], lr: 0.001155, loss: 0.4145
2022-09-28 03:32:45 - train: epoch 0085, iter [00960, 01251], lr: 0.001155, loss: 0.4077
2022-09-28 03:33:03 - train: epoch 0085, iter [00970, 01251], lr: 0.001155, loss: 0.3849
2022-09-28 03:33:22 - train: epoch 0085, iter [00980, 01251], lr: 0.001155, loss: 0.4157
2022-09-28 03:33:39 - train: epoch 0085, iter [00990, 01251], lr: 0.001155, loss: 0.4094
2022-09-28 03:33:57 - train: epoch 0085, iter [01000, 01251], lr: 0.001155, loss: 0.4217
2022-09-28 03:34:15 - train: epoch 0085, iter [01010, 01251], lr: 0.001155, loss: 0.4321
2022-09-28 03:34:33 - train: epoch 0085, iter [01020, 01251], lr: 0.001155, loss: 0.4277
2022-09-28 03:34:51 - train: epoch 0085, iter [01030, 01251], lr: 0.001155, loss: 0.3966
2022-09-28 03:35:09 - train: epoch 0085, iter [01040, 01251], lr: 0.001155, loss: 0.4259
2022-09-28 03:35:27 - train: epoch 0085, iter [01050, 01251], lr: 0.001155, loss: 0.4263
2022-09-28 03:35:45 - train: epoch 0085, iter [01060, 01251], lr: 0.001155, loss: 0.4165
2022-09-28 03:36:03 - train: epoch 0085, iter [01070, 01251], lr: 0.001155, loss: 0.4207
2022-09-28 03:36:21 - train: epoch 0085, iter [01080, 01251], lr: 0.001155, loss: 0.3960
2022-09-28 03:36:40 - train: epoch 0085, iter [01090, 01251], lr: 0.001155, loss: 0.4188
2022-09-28 03:36:58 - train: epoch 0085, iter [01100, 01251], lr: 0.001155, loss: 0.4090
2022-09-28 03:37:16 - train: epoch 0085, iter [01110, 01251], lr: 0.001155, loss: 0.4020
2022-09-28 03:37:34 - train: epoch 0085, iter [01120, 01251], lr: 0.001155, loss: 0.4201
2022-09-28 03:37:52 - train: epoch 0085, iter [01130, 01251], lr: 0.001155, loss: 0.4268
2022-09-28 03:38:10 - train: epoch 0085, iter [01140, 01251], lr: 0.001155, loss: 0.4134
2022-09-28 03:38:28 - train: epoch 0085, iter [01150, 01251], lr: 0.001154, loss: 0.4218
2022-09-28 03:38:46 - train: epoch 0085, iter [01160, 01251], lr: 0.001154, loss: 0.4262
2022-09-28 03:39:04 - train: epoch 0085, iter [01170, 01251], lr: 0.001154, loss: 0.4045
2022-09-28 03:39:22 - train: epoch 0085, iter [01180, 01251], lr: 0.001154, loss: 0.4148
2022-09-28 03:39:40 - train: epoch 0085, iter [01190, 01251], lr: 0.001154, loss: 0.4407
2022-09-28 03:39:58 - train: epoch 0085, iter [01200, 01251], lr: 0.001154, loss: 0.4218
2022-09-28 03:40:16 - train: epoch 0085, iter [01210, 01251], lr: 0.001154, loss: 0.4208
2022-09-28 03:40:34 - train: epoch 0085, iter [01220, 01251], lr: 0.001154, loss: 0.4263
2022-09-28 03:40:52 - train: epoch 0085, iter [01230, 01251], lr: 0.001154, loss: 0.4130
2022-09-28 03:41:10 - train: epoch 0085, iter [01240, 01251], lr: 0.001154, loss: 0.4317
2022-09-28 03:41:27 - train: epoch 0085, iter [01250, 01251], lr: 0.001154, loss: 0.3941
2022-09-28 03:41:31 - train: epoch 085, train_loss: 0.4143
2022-09-28 03:41:33 - until epoch: 085, best_loss: 0.4143
2022-09-28 03:41:33 - epoch 086 lr: 0.001154
2022-09-28 03:42:06 - train: epoch 0086, iter [00010, 01251], lr: 0.001154, loss: 0.4013
2022-09-28 03:42:24 - train: epoch 0086, iter [00020, 01251], lr: 0.001154, loss: 0.4056
2022-09-28 03:42:42 - train: epoch 0086, iter [00030, 01251], lr: 0.001154, loss: 0.4052
2022-09-28 03:42:59 - train: epoch 0086, iter [00040, 01251], lr: 0.001154, loss: 0.4084
2022-09-28 03:43:17 - train: epoch 0086, iter [00050, 01251], lr: 0.001154, loss: 0.4146
2022-09-28 03:43:35 - train: epoch 0086, iter [00060, 01251], lr: 0.001154, loss: 0.4125
2022-09-28 03:43:53 - train: epoch 0086, iter [00070, 01251], lr: 0.001154, loss: 0.4112
2022-09-28 03:44:11 - train: epoch 0086, iter [00080, 01251], lr: 0.001154, loss: 0.4083
2022-09-28 03:44:29 - train: epoch 0086, iter [00090, 01251], lr: 0.001154, loss: 0.3833
2022-09-28 03:44:47 - train: epoch 0086, iter [00100, 01251], lr: 0.001154, loss: 0.4196
2022-09-28 03:45:05 - train: epoch 0086, iter [00110, 01251], lr: 0.001154, loss: 0.4079
2022-09-28 03:45:23 - train: epoch 0086, iter [00120, 01251], lr: 0.001154, loss: 0.4256
2022-09-28 03:45:42 - train: epoch 0086, iter [00130, 01251], lr: 0.001154, loss: 0.4134
2022-09-28 03:46:00 - train: epoch 0086, iter [00140, 01251], lr: 0.001154, loss: 0.4042
2022-09-28 03:46:18 - train: epoch 0086, iter [00150, 01251], lr: 0.001154, loss: 0.4031
2022-09-28 03:46:36 - train: epoch 0086, iter [00160, 01251], lr: 0.001154, loss: 0.4138
2022-09-28 03:46:54 - train: epoch 0086, iter [00170, 01251], lr: 0.001154, loss: 0.4143
2022-09-28 03:47:12 - train: epoch 0086, iter [00180, 01251], lr: 0.001154, loss: 0.4254
2022-09-28 03:47:30 - train: epoch 0086, iter [00190, 01251], lr: 0.001154, loss: 0.4015
2022-09-28 03:47:48 - train: epoch 0086, iter [00200, 01251], lr: 0.001154, loss: 0.4235
2022-09-28 03:48:06 - train: epoch 0086, iter [00210, 01251], lr: 0.001154, loss: 0.4100
2022-09-28 03:48:24 - train: epoch 0086, iter [00220, 01251], lr: 0.001154, loss: 0.4313
2022-09-28 03:48:42 - train: epoch 0086, iter [00230, 01251], lr: 0.001154, loss: 0.4241
2022-09-28 03:49:00 - train: epoch 0086, iter [00240, 01251], lr: 0.001154, loss: 0.4052
2022-09-28 03:49:18 - train: epoch 0086, iter [00250, 01251], lr: 0.001154, loss: 0.4273
2022-09-28 03:49:36 - train: epoch 0086, iter [00260, 01251], lr: 0.001154, loss: 0.4044
2022-09-28 03:49:54 - train: epoch 0086, iter [00270, 01251], lr: 0.001154, loss: 0.3952
2022-09-28 03:50:12 - train: epoch 0086, iter [00280, 01251], lr: 0.001154, loss: 0.4228
2022-09-28 03:50:30 - train: epoch 0086, iter [00290, 01251], lr: 0.001154, loss: 0.4319
2022-09-28 03:50:49 - train: epoch 0086, iter [00300, 01251], lr: 0.001154, loss: 0.4240
2022-09-28 03:51:07 - train: epoch 0086, iter [00310, 01251], lr: 0.001154, loss: 0.4273
2022-09-28 03:51:25 - train: epoch 0086, iter [00320, 01251], lr: 0.001154, loss: 0.4131
2022-09-28 03:51:43 - train: epoch 0086, iter [00330, 01251], lr: 0.001154, loss: 0.4175
2022-09-28 03:52:01 - train: epoch 0086, iter [00340, 01251], lr: 0.001154, loss: 0.4172
2022-09-28 03:52:19 - train: epoch 0086, iter [00350, 01251], lr: 0.001154, loss: 0.3896
2022-09-28 03:52:37 - train: epoch 0086, iter [00360, 01251], lr: 0.001154, loss: 0.4093
2022-09-28 03:52:55 - train: epoch 0086, iter [00370, 01251], lr: 0.001154, loss: 0.4388
2022-09-28 03:53:13 - train: epoch 0086, iter [00380, 01251], lr: 0.001154, loss: 0.4128
2022-09-28 03:53:31 - train: epoch 0086, iter [00390, 01251], lr: 0.001154, loss: 0.4264
2022-09-28 03:53:49 - train: epoch 0086, iter [00400, 01251], lr: 0.001154, loss: 0.4099
2022-09-28 03:54:07 - train: epoch 0086, iter [00410, 01251], lr: 0.001154, loss: 0.4029
2022-09-28 03:54:25 - train: epoch 0086, iter [00420, 01251], lr: 0.001154, loss: 0.4057
2022-09-28 03:54:43 - train: epoch 0086, iter [00430, 01251], lr: 0.001154, loss: 0.4112
2022-09-28 03:55:01 - train: epoch 0086, iter [00440, 01251], lr: 0.001154, loss: 0.4111
2022-09-28 03:55:19 - train: epoch 0086, iter [00450, 01251], lr: 0.001154, loss: 0.4249
2022-09-28 03:55:37 - train: epoch 0086, iter [00460, 01251], lr: 0.001154, loss: 0.4101
2022-09-28 03:55:55 - train: epoch 0086, iter [00470, 01251], lr: 0.001154, loss: 0.4109
2022-09-28 03:56:13 - train: epoch 0086, iter [00480, 01251], lr: 0.001154, loss: 0.4127
2022-09-28 03:56:31 - train: epoch 0086, iter [00490, 01251], lr: 0.001154, loss: 0.3875
2022-09-28 03:56:49 - train: epoch 0086, iter [00500, 01251], lr: 0.001154, loss: 0.3841
2022-09-28 03:57:07 - train: epoch 0086, iter [00510, 01251], lr: 0.001154, loss: 0.4229
2022-09-28 03:57:25 - train: epoch 0086, iter [00520, 01251], lr: 0.001153, loss: 0.4252
2022-09-28 03:57:43 - train: epoch 0086, iter [00530, 01251], lr: 0.001153, loss: 0.4213
2022-09-28 03:58:01 - train: epoch 0086, iter [00540, 01251], lr: 0.001153, loss: 0.4335
2022-09-28 03:58:19 - train: epoch 0086, iter [00550, 01251], lr: 0.001153, loss: 0.4155
2022-09-28 03:58:37 - train: epoch 0086, iter [00560, 01251], lr: 0.001153, loss: 0.4426
2022-09-28 03:58:55 - train: epoch 0086, iter [00570, 01251], lr: 0.001153, loss: 0.3975
2022-09-28 03:59:13 - train: epoch 0086, iter [00580, 01251], lr: 0.001153, loss: 0.4123
2022-09-28 03:59:31 - train: epoch 0086, iter [00590, 01251], lr: 0.001153, loss: 0.4080
2022-09-28 03:59:49 - train: epoch 0086, iter [00600, 01251], lr: 0.001153, loss: 0.4154
2022-09-28 04:00:07 - train: epoch 0086, iter [00610, 01251], lr: 0.001153, loss: 0.4070
2022-09-28 04:00:25 - train: epoch 0086, iter [00620, 01251], lr: 0.001153, loss: 0.4241
2022-09-28 04:00:43 - train: epoch 0086, iter [00630, 01251], lr: 0.001153, loss: 0.4122
2022-09-28 04:01:01 - train: epoch 0086, iter [00640, 01251], lr: 0.001153, loss: 0.4341
2022-09-28 04:01:19 - train: epoch 0086, iter [00650, 01251], lr: 0.001153, loss: 0.4284
2022-09-28 04:01:37 - train: epoch 0086, iter [00660, 01251], lr: 0.001153, loss: 0.4299
2022-09-28 04:01:55 - train: epoch 0086, iter [00670, 01251], lr: 0.001153, loss: 0.4251
2022-09-28 04:02:13 - train: epoch 0086, iter [00680, 01251], lr: 0.001153, loss: 0.4147
2022-09-28 04:02:31 - train: epoch 0086, iter [00690, 01251], lr: 0.001153, loss: 0.4127
2022-09-28 04:02:49 - train: epoch 0086, iter [00700, 01251], lr: 0.001153, loss: 0.4220
2022-09-28 04:03:07 - train: epoch 0086, iter [00710, 01251], lr: 0.001153, loss: 0.4255
2022-09-28 04:03:25 - train: epoch 0086, iter [00720, 01251], lr: 0.001153, loss: 0.4207
2022-09-28 04:03:43 - train: epoch 0086, iter [00730, 01251], lr: 0.001153, loss: 0.4088
2022-09-28 04:04:01 - train: epoch 0086, iter [00740, 01251], lr: 0.001153, loss: 0.4078
2022-09-28 04:04:19 - train: epoch 0086, iter [00750, 01251], lr: 0.001153, loss: 0.4158
2022-09-28 04:04:37 - train: epoch 0086, iter [00760, 01251], lr: 0.001153, loss: 0.4152
2022-09-28 04:04:55 - train: epoch 0086, iter [00770, 01251], lr: 0.001153, loss: 0.4147
2022-09-28 04:05:13 - train: epoch 0086, iter [00780, 01251], lr: 0.001153, loss: 0.4116
2022-09-28 04:05:30 - train: epoch 0086, iter [00790, 01251], lr: 0.001153, loss: 0.4022
2022-09-28 04:05:49 - train: epoch 0086, iter [00800, 01251], lr: 0.001153, loss: 0.4087
2022-09-28 04:06:07 - train: epoch 0086, iter [00810, 01251], lr: 0.001153, loss: 0.4231
2022-09-28 04:06:25 - train: epoch 0086, iter [00820, 01251], lr: 0.001153, loss: 0.4269
2022-09-28 04:06:43 - train: epoch 0086, iter [00830, 01251], lr: 0.001153, loss: 0.4162
2022-09-28 04:07:01 - train: epoch 0086, iter [00840, 01251], lr: 0.001153, loss: 0.4288
2022-09-28 04:07:19 - train: epoch 0086, iter [00850, 01251], lr: 0.001153, loss: 0.4263
2022-09-28 04:07:37 - train: epoch 0086, iter [00860, 01251], lr: 0.001153, loss: 0.4234
2022-09-28 04:07:55 - train: epoch 0086, iter [00870, 01251], lr: 0.001153, loss: 0.4218
2022-09-28 04:08:13 - train: epoch 0086, iter [00880, 01251], lr: 0.001153, loss: 0.4190
2022-09-28 04:08:31 - train: epoch 0086, iter [00890, 01251], lr: 0.001153, loss: 0.4191
2022-09-28 04:08:49 - train: epoch 0086, iter [00900, 01251], lr: 0.001153, loss: 0.4239
2022-09-28 04:09:07 - train: epoch 0086, iter [00910, 01251], lr: 0.001153, loss: 0.4025
2022-09-28 04:09:25 - train: epoch 0086, iter [00920, 01251], lr: 0.001153, loss: 0.3976
2022-09-28 04:09:43 - train: epoch 0086, iter [00930, 01251], lr: 0.001153, loss: 0.4131
2022-09-28 04:10:00 - train: epoch 0086, iter [00940, 01251], lr: 0.001153, loss: 0.4407
2022-09-28 04:10:18 - train: epoch 0086, iter [00950, 01251], lr: 0.001153, loss: 0.4055
2022-09-28 04:10:36 - train: epoch 0086, iter [00960, 01251], lr: 0.001153, loss: 0.4229
2022-09-28 04:10:54 - train: epoch 0086, iter [00970, 01251], lr: 0.001153, loss: 0.3994
2022-09-28 04:11:12 - train: epoch 0086, iter [00980, 01251], lr: 0.001153, loss: 0.4212
2022-09-28 04:11:30 - train: epoch 0086, iter [00990, 01251], lr: 0.001153, loss: 0.4152
2022-09-28 04:11:48 - train: epoch 0086, iter [01000, 01251], lr: 0.001153, loss: 0.4413
2022-09-28 04:12:06 - train: epoch 0086, iter [01010, 01251], lr: 0.001153, loss: 0.4236
2022-09-28 04:12:24 - train: epoch 0086, iter [01020, 01251], lr: 0.001153, loss: 0.4217
2022-09-28 04:12:42 - train: epoch 0086, iter [01030, 01251], lr: 0.001153, loss: 0.4266
2022-09-28 04:13:00 - train: epoch 0086, iter [01040, 01251], lr: 0.001153, loss: 0.4207
2022-09-28 04:13:18 - train: epoch 0086, iter [01050, 01251], lr: 0.001153, loss: 0.4125
2022-09-28 04:13:36 - train: epoch 0086, iter [01060, 01251], lr: 0.001153, loss: 0.4076
2022-09-28 04:13:54 - train: epoch 0086, iter [01070, 01251], lr: 0.001153, loss: 0.4241
2022-09-28 04:14:12 - train: epoch 0086, iter [01080, 01251], lr: 0.001153, loss: 0.4057
2022-09-28 04:14:30 - train: epoch 0086, iter [01090, 01251], lr: 0.001153, loss: 0.4297
2022-09-28 04:14:48 - train: epoch 0086, iter [01100, 01251], lr: 0.001153, loss: 0.4138
2022-09-28 04:15:06 - train: epoch 0086, iter [01110, 01251], lr: 0.001153, loss: 0.4109
2022-09-28 04:15:24 - train: epoch 0086, iter [01120, 01251], lr: 0.001153, loss: 0.4324
2022-09-28 04:15:43 - train: epoch 0086, iter [01130, 01251], lr: 0.001153, loss: 0.4284
2022-09-28 04:16:00 - train: epoch 0086, iter [01140, 01251], lr: 0.001152, loss: 0.4009
2022-09-28 04:16:18 - train: epoch 0086, iter [01150, 01251], lr: 0.001152, loss: 0.4167
2022-09-28 04:16:37 - train: epoch 0086, iter [01160, 01251], lr: 0.001152, loss: 0.4362
2022-09-28 04:16:55 - train: epoch 0086, iter [01170, 01251], lr: 0.001152, loss: 0.4056
2022-09-28 04:17:13 - train: epoch 0086, iter [01180, 01251], lr: 0.001152, loss: 0.4158
2022-09-28 04:17:31 - train: epoch 0086, iter [01190, 01251], lr: 0.001152, loss: 0.4087
2022-09-28 04:17:49 - train: epoch 0086, iter [01200, 01251], lr: 0.001152, loss: 0.4236
2022-09-28 04:18:07 - train: epoch 0086, iter [01210, 01251], lr: 0.001152, loss: 0.4335
2022-09-28 04:18:25 - train: epoch 0086, iter [01220, 01251], lr: 0.001152, loss: 0.3971
2022-09-28 04:18:43 - train: epoch 0086, iter [01230, 01251], lr: 0.001152, loss: 0.4165
2022-09-28 04:19:01 - train: epoch 0086, iter [01240, 01251], lr: 0.001152, loss: 0.4200
2022-09-28 04:19:18 - train: epoch 0086, iter [01250, 01251], lr: 0.001152, loss: 0.3986
2022-09-28 04:19:22 - train: epoch 086, train_loss: 0.4144
2022-09-28 04:19:23 - until epoch: 086, best_loss: 0.4143
2022-09-28 04:19:23 - epoch 087 lr: 0.001152
2022-09-28 04:19:56 - train: epoch 0087, iter [00010, 01251], lr: 0.001152, loss: 0.4088
2022-09-28 04:20:14 - train: epoch 0087, iter [00020, 01251], lr: 0.001152, loss: 0.4190
2022-09-28 04:20:32 - train: epoch 0087, iter [00030, 01251], lr: 0.001152, loss: 0.4464
2022-09-28 04:20:50 - train: epoch 0087, iter [00040, 01251], lr: 0.001152, loss: 0.4055
2022-09-28 04:21:08 - train: epoch 0087, iter [00050, 01251], lr: 0.001152, loss: 0.4417
2022-09-28 04:21:26 - train: epoch 0087, iter [00060, 01251], lr: 0.001152, loss: 0.3971
2022-09-28 04:21:44 - train: epoch 0087, iter [00070, 01251], lr: 0.001152, loss: 0.4057
2022-09-28 04:22:02 - train: epoch 0087, iter [00080, 01251], lr: 0.001152, loss: 0.4322
2022-09-28 04:22:20 - train: epoch 0087, iter [00090, 01251], lr: 0.001152, loss: 0.3948
2022-09-28 04:22:38 - train: epoch 0087, iter [00100, 01251], lr: 0.001152, loss: 0.4088
2022-09-28 04:22:56 - train: epoch 0087, iter [00110, 01251], lr: 0.001152, loss: 0.4127
2022-09-28 04:23:14 - train: epoch 0087, iter [00120, 01251], lr: 0.001152, loss: 0.4214
2022-09-28 04:23:32 - train: epoch 0087, iter [00130, 01251], lr: 0.001152, loss: 0.4110
2022-09-28 04:23:50 - train: epoch 0087, iter [00140, 01251], lr: 0.001152, loss: 0.4264
2022-09-28 04:24:08 - train: epoch 0087, iter [00150, 01251], lr: 0.001152, loss: 0.4176
2022-09-28 04:24:26 - train: epoch 0087, iter [00160, 01251], lr: 0.001152, loss: 0.4049
2022-09-28 04:24:44 - train: epoch 0087, iter [00170, 01251], lr: 0.001152, loss: 0.4273
2022-09-28 04:25:02 - train: epoch 0087, iter [00180, 01251], lr: 0.001152, loss: 0.4096
2022-09-28 04:25:20 - train: epoch 0087, iter [00190, 01251], lr: 0.001152, loss: 0.4203
2022-09-28 04:25:38 - train: epoch 0087, iter [00200, 01251], lr: 0.001152, loss: 0.4072
2022-09-28 04:25:56 - train: epoch 0087, iter [00210, 01251], lr: 0.001152, loss: 0.4146
2022-09-28 04:26:14 - train: epoch 0087, iter [00220, 01251], lr: 0.001152, loss: 0.4265
2022-09-28 04:26:32 - train: epoch 0087, iter [00230, 01251], lr: 0.001152, loss: 0.4209
2022-09-28 04:26:50 - train: epoch 0087, iter [00240, 01251], lr: 0.001152, loss: 0.4177
2022-09-28 04:27:08 - train: epoch 0087, iter [00250, 01251], lr: 0.001152, loss: 0.4248
2022-09-28 04:27:26 - train: epoch 0087, iter [00260, 01251], lr: 0.001152, loss: 0.3973
2022-09-28 04:27:44 - train: epoch 0087, iter [00270, 01251], lr: 0.001152, loss: 0.4011
2022-09-28 04:28:02 - train: epoch 0087, iter [00280, 01251], lr: 0.001152, loss: 0.4149
2022-09-28 04:28:20 - train: epoch 0087, iter [00290, 01251], lr: 0.001152, loss: 0.3945
2022-09-28 04:28:38 - train: epoch 0087, iter [00300, 01251], lr: 0.001152, loss: 0.4024
2022-09-28 04:28:56 - train: epoch 0087, iter [00310, 01251], lr: 0.001152, loss: 0.4114
2022-09-28 04:29:14 - train: epoch 0087, iter [00320, 01251], lr: 0.001152, loss: 0.4064
2022-09-28 04:29:32 - train: epoch 0087, iter [00330, 01251], lr: 0.001152, loss: 0.4380
2022-09-28 04:29:50 - train: epoch 0087, iter [00340, 01251], lr: 0.001152, loss: 0.4190
2022-09-28 04:30:08 - train: epoch 0087, iter [00350, 01251], lr: 0.001152, loss: 0.4443
2022-09-28 04:30:26 - train: epoch 0087, iter [00360, 01251], lr: 0.001152, loss: 0.4178
2022-09-28 04:30:44 - train: epoch 0087, iter [00370, 01251], lr: 0.001152, loss: 0.3926
2022-09-28 04:31:02 - train: epoch 0087, iter [00380, 01251], lr: 0.001152, loss: 0.4037
2022-09-28 04:31:20 - train: epoch 0087, iter [00390, 01251], lr: 0.001152, loss: 0.4151
2022-09-28 04:31:38 - train: epoch 0087, iter [00400, 01251], lr: 0.001152, loss: 0.4176
2022-09-28 04:31:56 - train: epoch 0087, iter [00410, 01251], lr: 0.001152, loss: 0.3932
2022-09-28 04:32:14 - train: epoch 0087, iter [00420, 01251], lr: 0.001152, loss: 0.3961
2022-09-28 04:32:32 - train: epoch 0087, iter [00430, 01251], lr: 0.001152, loss: 0.4208
2022-09-28 04:32:50 - train: epoch 0087, iter [00440, 01251], lr: 0.001152, loss: 0.4197
2022-09-28 04:33:08 - train: epoch 0087, iter [00450, 01251], lr: 0.001152, loss: 0.4097
2022-09-28 04:33:26 - train: epoch 0087, iter [00460, 01251], lr: 0.001152, loss: 0.4222
2022-09-28 04:33:44 - train: epoch 0087, iter [00470, 01251], lr: 0.001152, loss: 0.4229
2022-09-28 04:34:02 - train: epoch 0087, iter [00480, 01251], lr: 0.001152, loss: 0.4117
2022-09-28 04:34:20 - train: epoch 0087, iter [00490, 01251], lr: 0.001151, loss: 0.4143
2022-09-28 04:34:38 - train: epoch 0087, iter [00500, 01251], lr: 0.001151, loss: 0.4244
2022-09-28 04:34:56 - train: epoch 0087, iter [00510, 01251], lr: 0.001151, loss: 0.4002
2022-09-28 04:35:14 - train: epoch 0087, iter [00520, 01251], lr: 0.001151, loss: 0.3923
2022-09-28 04:35:32 - train: epoch 0087, iter [00530, 01251], lr: 0.001151, loss: 0.4211
2022-09-28 04:35:50 - train: epoch 0087, iter [00540, 01251], lr: 0.001151, loss: 0.3930
2022-09-28 04:36:08 - train: epoch 0087, iter [00550, 01251], lr: 0.001151, loss: 0.3923
2022-09-28 04:36:26 - train: epoch 0087, iter [00560, 01251], lr: 0.001151, loss: 0.4103
2022-09-28 04:36:43 - train: epoch 0087, iter [00570, 01251], lr: 0.001151, loss: 0.4227
2022-09-28 04:37:01 - train: epoch 0087, iter [00580, 01251], lr: 0.001151, loss: 0.4333
2022-09-28 04:37:19 - train: epoch 0087, iter [00590, 01251], lr: 0.001151, loss: 0.4111
2022-09-28 04:37:37 - train: epoch 0087, iter [00600, 01251], lr: 0.001151, loss: 0.4159
2022-09-28 04:37:55 - train: epoch 0087, iter [00610, 01251], lr: 0.001151, loss: 0.4243
2022-09-28 04:38:13 - train: epoch 0087, iter [00620, 01251], lr: 0.001151, loss: 0.4344
2022-09-28 04:38:31 - train: epoch 0087, iter [00630, 01251], lr: 0.001151, loss: 0.4197
2022-09-28 04:38:49 - train: epoch 0087, iter [00640, 01251], lr: 0.001151, loss: 0.4239
2022-09-28 04:39:07 - train: epoch 0087, iter [00650, 01251], lr: 0.001151, loss: 0.4104
2022-09-28 04:39:25 - train: epoch 0087, iter [00660, 01251], lr: 0.001151, loss: 0.4108
2022-09-28 04:39:43 - train: epoch 0087, iter [00670, 01251], lr: 0.001151, loss: 0.4020
2022-09-28 04:40:00 - train: epoch 0087, iter [00680, 01251], lr: 0.001151, loss: 0.4217
2022-09-28 04:40:18 - train: epoch 0087, iter [00690, 01251], lr: 0.001151, loss: 0.3914
2022-09-28 04:40:36 - train: epoch 0087, iter [00700, 01251], lr: 0.001151, loss: 0.4072
2022-09-28 04:40:54 - train: epoch 0087, iter [00710, 01251], lr: 0.001151, loss: 0.4148
2022-09-28 04:41:12 - train: epoch 0087, iter [00720, 01251], lr: 0.001151, loss: 0.3989
2022-09-28 04:41:30 - train: epoch 0087, iter [00730, 01251], lr: 0.001151, loss: 0.4096
2022-09-28 04:41:48 - train: epoch 0087, iter [00740, 01251], lr: 0.001151, loss: 0.4060
2022-09-28 04:42:06 - train: epoch 0087, iter [00750, 01251], lr: 0.001151, loss: 0.4074
2022-09-28 04:42:24 - train: epoch 0087, iter [00760, 01251], lr: 0.001151, loss: 0.4379
2022-09-28 04:42:42 - train: epoch 0087, iter [00770, 01251], lr: 0.001151, loss: 0.4167
2022-09-28 04:42:59 - train: epoch 0087, iter [00780, 01251], lr: 0.001151, loss: 0.3884
2022-09-28 04:43:18 - train: epoch 0087, iter [00790, 01251], lr: 0.001151, loss: 0.3847
2022-09-28 04:43:36 - train: epoch 0087, iter [00800, 01251], lr: 0.001151, loss: 0.4028
2022-09-28 04:43:53 - train: epoch 0087, iter [00810, 01251], lr: 0.001151, loss: 0.4219
2022-09-28 04:44:11 - train: epoch 0087, iter [00820, 01251], lr: 0.001151, loss: 0.4163
2022-09-28 04:44:29 - train: epoch 0087, iter [00830, 01251], lr: 0.001151, loss: 0.4212
2022-09-28 04:44:47 - train: epoch 0087, iter [00840, 01251], lr: 0.001151, loss: 0.3859
2022-09-28 04:45:05 - train: epoch 0087, iter [00850, 01251], lr: 0.001151, loss: 0.4277
2022-09-28 04:45:23 - train: epoch 0087, iter [00860, 01251], lr: 0.001151, loss: 0.4200
2022-09-28 04:45:41 - train: epoch 0087, iter [00870, 01251], lr: 0.001151, loss: 0.4254
2022-09-28 04:45:59 - train: epoch 0087, iter [00880, 01251], lr: 0.001151, loss: 0.4119
2022-09-28 04:46:17 - train: epoch 0087, iter [00890, 01251], lr: 0.001151, loss: 0.4171
2022-09-28 04:46:35 - train: epoch 0087, iter [00900, 01251], lr: 0.001151, loss: 0.4385
2022-09-28 04:46:52 - train: epoch 0087, iter [00910, 01251], lr: 0.001151, loss: 0.4087
2022-09-28 04:47:10 - train: epoch 0087, iter [00920, 01251], lr: 0.001151, loss: 0.4151
2022-09-28 04:47:28 - train: epoch 0087, iter [00930, 01251], lr: 0.001151, loss: 0.4152
2022-09-28 04:47:46 - train: epoch 0087, iter [00940, 01251], lr: 0.001151, loss: 0.4047
2022-09-28 04:48:04 - train: epoch 0087, iter [00950, 01251], lr: 0.001151, loss: 0.4137
2022-09-28 04:48:22 - train: epoch 0087, iter [00960, 01251], lr: 0.001151, loss: 0.4152
2022-09-28 04:48:40 - train: epoch 0087, iter [00970, 01251], lr: 0.001151, loss: 0.3961
2022-09-28 04:48:58 - train: epoch 0087, iter [00980, 01251], lr: 0.001151, loss: 0.4231
2022-09-28 04:49:16 - train: epoch 0087, iter [00990, 01251], lr: 0.001151, loss: 0.4254
2022-09-28 04:49:34 - train: epoch 0087, iter [01000, 01251], lr: 0.001151, loss: 0.4329
2022-09-28 04:49:51 - train: epoch 0087, iter [01010, 01251], lr: 0.001151, loss: 0.4164
2022-09-28 04:50:09 - train: epoch 0087, iter [01020, 01251], lr: 0.001151, loss: 0.3890
2022-09-28 04:50:27 - train: epoch 0087, iter [01030, 01251], lr: 0.001151, loss: 0.4410
2022-09-28 04:50:45 - train: epoch 0087, iter [01040, 01251], lr: 0.001151, loss: 0.4192
2022-09-28 04:51:03 - train: epoch 0087, iter [01050, 01251], lr: 0.001151, loss: 0.4353
2022-09-28 04:51:21 - train: epoch 0087, iter [01060, 01251], lr: 0.001151, loss: 0.4127
2022-09-28 04:51:39 - train: epoch 0087, iter [01070, 01251], lr: 0.001151, loss: 0.4032
2022-09-28 04:51:57 - train: epoch 0087, iter [01080, 01251], lr: 0.001151, loss: 0.4125
2022-09-28 04:52:15 - train: epoch 0087, iter [01090, 01251], lr: 0.001151, loss: 0.4032
2022-09-28 04:52:33 - train: epoch 0087, iter [01100, 01251], lr: 0.001150, loss: 0.4062
2022-09-28 04:52:51 - train: epoch 0087, iter [01110, 01251], lr: 0.001150, loss: 0.4360
2022-09-28 04:53:09 - train: epoch 0087, iter [01120, 01251], lr: 0.001150, loss: 0.4170
2022-09-28 04:53:27 - train: epoch 0087, iter [01130, 01251], lr: 0.001150, loss: 0.4147
2022-09-28 04:53:45 - train: epoch 0087, iter [01140, 01251], lr: 0.001150, loss: 0.4221
2022-09-28 04:54:03 - train: epoch 0087, iter [01150, 01251], lr: 0.001150, loss: 0.4192
2022-09-28 04:54:20 - train: epoch 0087, iter [01160, 01251], lr: 0.001150, loss: 0.4056
2022-09-28 04:54:38 - train: epoch 0087, iter [01170, 01251], lr: 0.001150, loss: 0.3987
2022-09-28 04:54:56 - train: epoch 0087, iter [01180, 01251], lr: 0.001150, loss: 0.4189
2022-09-28 04:55:14 - train: epoch 0087, iter [01190, 01251], lr: 0.001150, loss: 0.4407
2022-09-28 04:55:32 - train: epoch 0087, iter [01200, 01251], lr: 0.001150, loss: 0.4182
2022-09-28 04:55:51 - train: epoch 0087, iter [01210, 01251], lr: 0.001150, loss: 0.4057
2022-09-28 04:56:08 - train: epoch 0087, iter [01220, 01251], lr: 0.001150, loss: 0.3820
2022-09-28 04:56:27 - train: epoch 0087, iter [01230, 01251], lr: 0.001150, loss: 0.4161
2022-09-28 04:56:44 - train: epoch 0087, iter [01240, 01251], lr: 0.001150, loss: 0.4051
2022-09-28 04:57:02 - train: epoch 0087, iter [01250, 01251], lr: 0.001150, loss: 0.4025
2022-09-28 04:57:05 - train: epoch 087, train_loss: 0.4142
2022-09-28 04:57:08 - until epoch: 087, best_loss: 0.4142
2022-09-28 04:57:08 - epoch 088 lr: 0.001150
2022-09-28 04:57:41 - train: epoch 0088, iter [00010, 01251], lr: 0.001150, loss: 0.4321
2022-09-28 04:57:59 - train: epoch 0088, iter [00020, 01251], lr: 0.001150, loss: 0.4179
2022-09-28 04:58:17 - train: epoch 0088, iter [00030, 01251], lr: 0.001150, loss: 0.4320
2022-09-28 04:58:35 - train: epoch 0088, iter [00040, 01251], lr: 0.001150, loss: 0.4307
2022-09-28 04:58:53 - train: epoch 0088, iter [00050, 01251], lr: 0.001150, loss: 0.4068
2022-09-28 04:59:11 - train: epoch 0088, iter [00060, 01251], lr: 0.001150, loss: 0.4206
2022-09-28 04:59:29 - train: epoch 0088, iter [00070, 01251], lr: 0.001150, loss: 0.4098
2022-09-28 04:59:47 - train: epoch 0088, iter [00080, 01251], lr: 0.001150, loss: 0.4039
2022-09-28 05:00:05 - train: epoch 0088, iter [00090, 01251], lr: 0.001150, loss: 0.4136
2022-09-28 05:00:23 - train: epoch 0088, iter [00100, 01251], lr: 0.001150, loss: 0.4082
2022-09-28 05:00:41 - train: epoch 0088, iter [00110, 01251], lr: 0.001150, loss: 0.4239
2022-09-28 05:00:59 - train: epoch 0088, iter [00120, 01251], lr: 0.001150, loss: 0.4257
2022-09-28 05:01:17 - train: epoch 0088, iter [00130, 01251], lr: 0.001150, loss: 0.4123
2022-09-28 05:01:35 - train: epoch 0088, iter [00140, 01251], lr: 0.001150, loss: 0.4213
2022-09-28 05:01:53 - train: epoch 0088, iter [00150, 01251], lr: 0.001150, loss: 0.4093
2022-09-28 05:02:11 - train: epoch 0088, iter [00160, 01251], lr: 0.001150, loss: 0.4136
2022-09-28 05:02:29 - train: epoch 0088, iter [00170, 01251], lr: 0.001150, loss: 0.3989
2022-09-28 05:02:47 - train: epoch 0088, iter [00180, 01251], lr: 0.001150, loss: 0.4015
2022-09-28 05:03:05 - train: epoch 0088, iter [00190, 01251], lr: 0.001150, loss: 0.3993
2022-09-28 05:03:23 - train: epoch 0088, iter [00200, 01251], lr: 0.001150, loss: 0.4136
2022-09-28 05:03:41 - train: epoch 0088, iter [00210, 01251], lr: 0.001150, loss: 0.4087
2022-09-28 05:03:59 - train: epoch 0088, iter [00220, 01251], lr: 0.001150, loss: 0.4230
2022-09-28 05:04:17 - train: epoch 0088, iter [00230, 01251], lr: 0.001150, loss: 0.4087
2022-09-28 05:04:35 - train: epoch 0088, iter [00240, 01251], lr: 0.001150, loss: 0.4249
2022-09-28 05:04:53 - train: epoch 0088, iter [00250, 01251], lr: 0.001150, loss: 0.4137
2022-09-28 05:05:11 - train: epoch 0088, iter [00260, 01251], lr: 0.001150, loss: 0.4180
2022-09-28 05:05:29 - train: epoch 0088, iter [00270, 01251], lr: 0.001150, loss: 0.3877
2022-09-28 05:05:46 - train: epoch 0088, iter [00280, 01251], lr: 0.001150, loss: 0.4207
2022-09-28 05:06:04 - train: epoch 0088, iter [00290, 01251], lr: 0.001150, loss: 0.4206
2022-09-28 05:06:22 - train: epoch 0088, iter [00300, 01251], lr: 0.001150, loss: 0.4038
2022-09-28 05:06:40 - train: epoch 0088, iter [00310, 01251], lr: 0.001150, loss: 0.4058
2022-09-28 05:06:58 - train: epoch 0088, iter [00320, 01251], lr: 0.001150, loss: 0.4207
2022-09-28 05:07:16 - train: epoch 0088, iter [00330, 01251], lr: 0.001150, loss: 0.4083
2022-09-28 05:07:33 - train: epoch 0088, iter [00340, 01251], lr: 0.001150, loss: 0.3867
2022-09-28 05:07:51 - train: epoch 0088, iter [00350, 01251], lr: 0.001150, loss: 0.3996
2022-09-28 05:08:09 - train: epoch 0088, iter [00360, 01251], lr: 0.001150, loss: 0.4184
2022-09-28 05:08:27 - train: epoch 0088, iter [00370, 01251], lr: 0.001150, loss: 0.4298
2022-09-28 05:08:45 - train: epoch 0088, iter [00380, 01251], lr: 0.001150, loss: 0.4299
2022-09-28 05:09:03 - train: epoch 0088, iter [00390, 01251], lr: 0.001150, loss: 0.4154
2022-09-28 05:09:21 - train: epoch 0088, iter [00400, 01251], lr: 0.001150, loss: 0.4206
2022-09-28 05:09:38 - train: epoch 0088, iter [00410, 01251], lr: 0.001150, loss: 0.4098
2022-09-28 05:09:56 - train: epoch 0088, iter [00420, 01251], lr: 0.001150, loss: 0.4227
2022-09-28 05:10:14 - train: epoch 0088, iter [00430, 01251], lr: 0.001150, loss: 0.4047
2022-09-28 05:10:32 - train: epoch 0088, iter [00440, 01251], lr: 0.001149, loss: 0.4113
2022-09-28 05:10:50 - train: epoch 0088, iter [00450, 01251], lr: 0.001149, loss: 0.4089
2022-09-28 05:11:07 - train: epoch 0088, iter [00460, 01251], lr: 0.001149, loss: 0.4227
2022-09-28 05:11:25 - train: epoch 0088, iter [00470, 01251], lr: 0.001149, loss: 0.4036
2022-09-28 05:11:43 - train: epoch 0088, iter [00480, 01251], lr: 0.001149, loss: 0.4448
2022-09-28 05:12:01 - train: epoch 0088, iter [00490, 01251], lr: 0.001149, loss: 0.4024
2022-09-28 05:12:19 - train: epoch 0088, iter [00500, 01251], lr: 0.001149, loss: 0.3940
2022-09-28 05:12:37 - train: epoch 0088, iter [00510, 01251], lr: 0.001149, loss: 0.4172
2022-09-28 05:12:55 - train: epoch 0088, iter [00520, 01251], lr: 0.001149, loss: 0.4185
2022-09-28 05:13:13 - train: epoch 0088, iter [00530, 01251], lr: 0.001149, loss: 0.4140
2022-09-28 05:13:30 - train: epoch 0088, iter [00540, 01251], lr: 0.001149, loss: 0.4086
2022-09-28 05:13:48 - train: epoch 0088, iter [00550, 01251], lr: 0.001149, loss: 0.4405
2022-09-28 05:14:06 - train: epoch 0088, iter [00560, 01251], lr: 0.001149, loss: 0.4221
2022-09-28 05:14:24 - train: epoch 0088, iter [00570, 01251], lr: 0.001149, loss: 0.4184
2022-09-28 05:14:42 - train: epoch 0088, iter [00580, 01251], lr: 0.001149, loss: 0.4052
2022-09-28 05:14:59 - train: epoch 0088, iter [00590, 01251], lr: 0.001149, loss: 0.4229
2022-09-28 05:15:17 - train: epoch 0088, iter [00600, 01251], lr: 0.001149, loss: 0.4177
2022-09-28 05:15:35 - train: epoch 0088, iter [00610, 01251], lr: 0.001149, loss: 0.4151
2022-09-28 05:15:53 - train: epoch 0088, iter [00620, 01251], lr: 0.001149, loss: 0.4131
2022-09-28 05:16:11 - train: epoch 0088, iter [00630, 01251], lr: 0.001149, loss: 0.4378
2022-09-28 05:16:29 - train: epoch 0088, iter [00640, 01251], lr: 0.001149, loss: 0.4135
2022-09-28 05:16:47 - train: epoch 0088, iter [00650, 01251], lr: 0.001149, loss: 0.4032
2022-09-28 05:17:04 - train: epoch 0088, iter [00660, 01251], lr: 0.001149, loss: 0.4104
2022-09-28 05:17:22 - train: epoch 0088, iter [00670, 01251], lr: 0.001149, loss: 0.4257
2022-09-28 05:17:40 - train: epoch 0088, iter [00680, 01251], lr: 0.001149, loss: 0.4128
2022-09-28 05:17:58 - train: epoch 0088, iter [00690, 01251], lr: 0.001149, loss: 0.4155
2022-09-28 05:18:16 - train: epoch 0088, iter [00700, 01251], lr: 0.001149, loss: 0.3953
2022-09-28 05:18:34 - train: epoch 0088, iter [00710, 01251], lr: 0.001149, loss: 0.4300
2022-09-28 05:18:52 - train: epoch 0088, iter [00720, 01251], lr: 0.001149, loss: 0.4158
2022-09-28 05:19:10 - train: epoch 0088, iter [00730, 01251], lr: 0.001149, loss: 0.4471
2022-09-28 05:19:28 - train: epoch 0088, iter [00740, 01251], lr: 0.001149, loss: 0.3924
2022-09-28 05:19:46 - train: epoch 0088, iter [00750, 01251], lr: 0.001149, loss: 0.4302
2022-09-28 05:20:04 - train: epoch 0088, iter [00760, 01251], lr: 0.001149, loss: 0.4057
2022-09-28 05:20:22 - train: epoch 0088, iter [00770, 01251], lr: 0.001149, loss: 0.4091
2022-09-28 05:20:39 - train: epoch 0088, iter [00780, 01251], lr: 0.001149, loss: 0.4075
2022-09-28 05:20:57 - train: epoch 0088, iter [00790, 01251], lr: 0.001149, loss: 0.4064
2022-09-28 05:21:15 - train: epoch 0088, iter [00800, 01251], lr: 0.001149, loss: 0.3968
2022-09-28 05:21:33 - train: epoch 0088, iter [00810, 01251], lr: 0.001149, loss: 0.4059
2022-09-28 05:21:51 - train: epoch 0088, iter [00820, 01251], lr: 0.001149, loss: 0.4062
2022-09-28 05:22:09 - train: epoch 0088, iter [00830, 01251], lr: 0.001149, loss: 0.4122
2022-09-28 05:22:27 - train: epoch 0088, iter [00840, 01251], lr: 0.001149, loss: 0.4059
2022-09-28 05:22:45 - train: epoch 0088, iter [00850, 01251], lr: 0.001149, loss: 0.4021
2022-09-28 05:23:03 - train: epoch 0088, iter [00860, 01251], lr: 0.001149, loss: 0.4175
2022-09-28 05:23:20 - train: epoch 0088, iter [00870, 01251], lr: 0.001149, loss: 0.4303
2022-09-28 05:23:38 - train: epoch 0088, iter [00880, 01251], lr: 0.001149, loss: 0.4161
2022-09-28 05:23:56 - train: epoch 0088, iter [00890, 01251], lr: 0.001149, loss: 0.4074
2022-09-28 05:24:14 - train: epoch 0088, iter [00900, 01251], lr: 0.001149, loss: 0.4159
2022-09-28 05:24:32 - train: epoch 0088, iter [00910, 01251], lr: 0.001149, loss: 0.4263
2022-09-28 05:24:50 - train: epoch 0088, iter [00920, 01251], lr: 0.001149, loss: 0.4206
2022-09-28 05:25:07 - train: epoch 0088, iter [00930, 01251], lr: 0.001149, loss: 0.4219
2022-09-28 05:25:25 - train: epoch 0088, iter [00940, 01251], lr: 0.001149, loss: 0.4012
2022-09-28 05:25:43 - train: epoch 0088, iter [00950, 01251], lr: 0.001149, loss: 0.3994
2022-09-28 05:26:01 - train: epoch 0088, iter [00960, 01251], lr: 0.001149, loss: 0.4156
2022-09-28 05:26:19 - train: epoch 0088, iter [00970, 01251], lr: 0.001149, loss: 0.4028
2022-09-28 05:26:37 - train: epoch 0088, iter [00980, 01251], lr: 0.001149, loss: 0.3998
2022-09-28 05:26:55 - train: epoch 0088, iter [00990, 01251], lr: 0.001149, loss: 0.4238
2022-09-28 05:27:12 - train: epoch 0088, iter [01000, 01251], lr: 0.001149, loss: 0.4267
2022-09-28 05:27:31 - train: epoch 0088, iter [01010, 01251], lr: 0.001149, loss: 0.3916
2022-09-28 05:27:49 - train: epoch 0088, iter [01020, 01251], lr: 0.001149, loss: 0.4219
2022-09-28 05:28:07 - train: epoch 0088, iter [01030, 01251], lr: 0.001149, loss: 0.4157
2022-09-28 05:28:25 - train: epoch 0088, iter [01040, 01251], lr: 0.001148, loss: 0.4192
2022-09-28 05:28:43 - train: epoch 0088, iter [01050, 01251], lr: 0.001148, loss: 0.3952
2022-09-28 05:29:01 - train: epoch 0088, iter [01060, 01251], lr: 0.001148, loss: 0.4051
2022-09-28 05:29:18 - train: epoch 0088, iter [01070, 01251], lr: 0.001148, loss: 0.4172
2022-09-28 05:29:37 - train: epoch 0088, iter [01080, 01251], lr: 0.001148, loss: 0.3951
2022-09-28 05:29:54 - train: epoch 0088, iter [01090, 01251], lr: 0.001148, loss: 0.3972
2022-09-28 05:30:12 - train: epoch 0088, iter [01100, 01251], lr: 0.001148, loss: 0.4266
2022-09-28 05:30:31 - train: epoch 0088, iter [01110, 01251], lr: 0.001148, loss: 0.4045
2022-09-28 05:30:49 - train: epoch 0088, iter [01120, 01251], lr: 0.001148, loss: 0.4072
2022-09-28 05:31:06 - train: epoch 0088, iter [01130, 01251], lr: 0.001148, loss: 0.4066
2022-09-28 05:31:24 - train: epoch 0088, iter [01140, 01251], lr: 0.001148, loss: 0.4332
2022-09-28 05:31:42 - train: epoch 0088, iter [01150, 01251], lr: 0.001148, loss: 0.4225
2022-09-28 05:32:00 - train: epoch 0088, iter [01160, 01251], lr: 0.001148, loss: 0.4077
2022-09-28 05:32:18 - train: epoch 0088, iter [01170, 01251], lr: 0.001148, loss: 0.4139
2022-09-28 05:32:36 - train: epoch 0088, iter [01180, 01251], lr: 0.001148, loss: 0.4229
2022-09-28 05:32:54 - train: epoch 0088, iter [01190, 01251], lr: 0.001148, loss: 0.3988
2022-09-28 05:33:12 - train: epoch 0088, iter [01200, 01251], lr: 0.001148, loss: 0.4072
2022-09-28 05:33:30 - train: epoch 0088, iter [01210, 01251], lr: 0.001148, loss: 0.4224
2022-09-28 05:33:48 - train: epoch 0088, iter [01220, 01251], lr: 0.001148, loss: 0.4221
2022-09-28 05:34:06 - train: epoch 0088, iter [01230, 01251], lr: 0.001148, loss: 0.4293
2022-09-28 05:34:24 - train: epoch 0088, iter [01240, 01251], lr: 0.001148, loss: 0.4116
2022-09-28 05:34:41 - train: epoch 0088, iter [01250, 01251], lr: 0.001148, loss: 0.4168
2022-09-28 05:34:45 - train: epoch 088, train_loss: 0.4141
2022-09-28 05:34:47 - until epoch: 088, best_loss: 0.4141
2022-09-28 05:34:47 - epoch 089 lr: 0.001148
2022-09-28 05:35:20 - train: epoch 0089, iter [00010, 01251], lr: 0.001148, loss: 0.4131
2022-09-28 05:35:38 - train: epoch 0089, iter [00020, 01251], lr: 0.001148, loss: 0.4246
2022-09-28 05:35:56 - train: epoch 0089, iter [00030, 01251], lr: 0.001148, loss: 0.4061
2022-09-28 05:36:14 - train: epoch 0089, iter [00040, 01251], lr: 0.001148, loss: 0.4338
2022-09-28 05:36:32 - train: epoch 0089, iter [00050, 01251], lr: 0.001148, loss: 0.4099
2022-09-28 05:36:50 - train: epoch 0089, iter [00060, 01251], lr: 0.001148, loss: 0.4115
2022-09-28 05:37:08 - train: epoch 0089, iter [00070, 01251], lr: 0.001148, loss: 0.4374
2022-09-28 05:37:26 - train: epoch 0089, iter [00080, 01251], lr: 0.001148, loss: 0.4118
2022-09-28 05:37:44 - train: epoch 0089, iter [00090, 01251], lr: 0.001148, loss: 0.4115
2022-09-28 05:38:02 - train: epoch 0089, iter [00100, 01251], lr: 0.001148, loss: 0.4208
2022-09-28 05:38:21 - train: epoch 0089, iter [00110, 01251], lr: 0.001148, loss: 0.4322
2022-09-28 05:38:39 - train: epoch 0089, iter [00120, 01251], lr: 0.001148, loss: 0.4232
2022-09-28 05:38:57 - train: epoch 0089, iter [00130, 01251], lr: 0.001148, loss: 0.4152
2022-09-28 05:39:15 - train: epoch 0089, iter [00140, 01251], lr: 0.001148, loss: 0.4216
2022-09-28 05:39:33 - train: epoch 0089, iter [00150, 01251], lr: 0.001148, loss: 0.4050
2022-09-28 05:39:51 - train: epoch 0089, iter [00160, 01251], lr: 0.001148, loss: 0.4013
2022-09-28 05:40:09 - train: epoch 0089, iter [00170, 01251], lr: 0.001148, loss: 0.4167
2022-09-28 05:40:27 - train: epoch 0089, iter [00180, 01251], lr: 0.001148, loss: 0.4169
2022-09-28 05:40:45 - train: epoch 0089, iter [00190, 01251], lr: 0.001148, loss: 0.4182
2022-09-28 05:41:04 - train: epoch 0089, iter [00200, 01251], lr: 0.001148, loss: 0.4227
2022-09-28 05:41:22 - train: epoch 0089, iter [00210, 01251], lr: 0.001148, loss: 0.4033
2022-09-28 05:41:40 - train: epoch 0089, iter [00220, 01251], lr: 0.001148, loss: 0.4049
2022-09-28 05:41:58 - train: epoch 0089, iter [00230, 01251], lr: 0.001148, loss: 0.4133
2022-09-28 05:42:16 - train: epoch 0089, iter [00240, 01251], lr: 0.001148, loss: 0.4138
2022-09-28 05:42:34 - train: epoch 0089, iter [00250, 01251], lr: 0.001148, loss: 0.4199
2022-09-28 05:42:53 - train: epoch 0089, iter [00260, 01251], lr: 0.001148, loss: 0.4238
2022-09-28 05:43:11 - train: epoch 0089, iter [00270, 01251], lr: 0.001148, loss: 0.4221
2022-09-28 05:43:29 - train: epoch 0089, iter [00280, 01251], lr: 0.001148, loss: 0.4085
2022-09-28 05:43:47 - train: epoch 0089, iter [00290, 01251], lr: 0.001148, loss: 0.3975
2022-09-28 05:44:06 - train: epoch 0089, iter [00300, 01251], lr: 0.001148, loss: 0.4217
2022-09-28 05:44:23 - train: epoch 0089, iter [00310, 01251], lr: 0.001148, loss: 0.4176
2022-09-28 05:44:42 - train: epoch 0089, iter [00320, 01251], lr: 0.001148, loss: 0.4055
2022-09-28 05:45:00 - train: epoch 0089, iter [00330, 01251], lr: 0.001148, loss: 0.4320
2022-09-28 05:45:18 - train: epoch 0089, iter [00340, 01251], lr: 0.001148, loss: 0.4194
2022-09-28 05:45:36 - train: epoch 0089, iter [00350, 01251], lr: 0.001148, loss: 0.4136
2022-09-28 05:45:55 - train: epoch 0089, iter [00360, 01251], lr: 0.001148, loss: 0.4104
2022-09-28 05:46:13 - train: epoch 0089, iter [00370, 01251], lr: 0.001147, loss: 0.4050
2022-09-28 05:46:31 - train: epoch 0089, iter [00380, 01251], lr: 0.001147, loss: 0.4109
2022-09-28 05:46:49 - train: epoch 0089, iter [00390, 01251], lr: 0.001147, loss: 0.4189
2022-09-28 05:47:07 - train: epoch 0089, iter [00400, 01251], lr: 0.001147, loss: 0.4220
2022-09-28 05:47:25 - train: epoch 0089, iter [00410, 01251], lr: 0.001147, loss: 0.3991
2022-09-28 05:47:43 - train: epoch 0089, iter [00420, 01251], lr: 0.001147, loss: 0.4036
2022-09-28 05:48:02 - train: epoch 0089, iter [00430, 01251], lr: 0.001147, loss: 0.4056
2022-09-28 05:48:20 - train: epoch 0089, iter [00440, 01251], lr: 0.001147, loss: 0.4108
2022-09-28 05:48:38 - train: epoch 0089, iter [00450, 01251], lr: 0.001147, loss: 0.4221
2022-09-28 05:48:56 - train: epoch 0089, iter [00460, 01251], lr: 0.001147, loss: 0.4092
2022-09-28 05:49:14 - train: epoch 0089, iter [00470, 01251], lr: 0.001147, loss: 0.4209
2022-09-28 05:49:32 - train: epoch 0089, iter [00480, 01251], lr: 0.001147, loss: 0.4076
2022-09-28 05:49:51 - train: epoch 0089, iter [00490, 01251], lr: 0.001147, loss: 0.4149
2022-09-28 05:50:08 - train: epoch 0089, iter [00500, 01251], lr: 0.001147, loss: 0.4219
2022-09-28 05:50:26 - train: epoch 0089, iter [00510, 01251], lr: 0.001147, loss: 0.4110
2022-09-28 05:50:45 - train: epoch 0089, iter [00520, 01251], lr: 0.001147, loss: 0.4192
2022-09-28 05:51:03 - train: epoch 0089, iter [00530, 01251], lr: 0.001147, loss: 0.4049
2022-09-28 05:51:21 - train: epoch 0089, iter [00540, 01251], lr: 0.001147, loss: 0.4186
2022-09-28 05:51:39 - train: epoch 0089, iter [00550, 01251], lr: 0.001147, loss: 0.4020
2022-09-28 05:51:57 - train: epoch 0089, iter [00560, 01251], lr: 0.001147, loss: 0.4101
2022-09-28 05:52:15 - train: epoch 0089, iter [00570, 01251], lr: 0.001147, loss: 0.4212
2022-09-28 05:52:33 - train: epoch 0089, iter [00580, 01251], lr: 0.001147, loss: 0.4160
2022-09-28 05:52:51 - train: epoch 0089, iter [00590, 01251], lr: 0.001147, loss: 0.4131
2022-09-28 05:53:09 - train: epoch 0089, iter [00600, 01251], lr: 0.001147, loss: 0.4486
2022-09-28 05:53:28 - train: epoch 0089, iter [00610, 01251], lr: 0.001147, loss: 0.4298
2022-09-28 05:53:45 - train: epoch 0089, iter [00620, 01251], lr: 0.001147, loss: 0.4074
2022-09-28 05:54:03 - train: epoch 0089, iter [00630, 01251], lr: 0.001147, loss: 0.4153
2022-09-28 05:54:22 - train: epoch 0089, iter [00640, 01251], lr: 0.001147, loss: 0.4089
2022-09-28 05:54:40 - train: epoch 0089, iter [00650, 01251], lr: 0.001147, loss: 0.4319
2022-09-28 05:54:58 - train: epoch 0089, iter [00660, 01251], lr: 0.001147, loss: 0.4125
2022-09-28 05:55:16 - train: epoch 0089, iter [00670, 01251], lr: 0.001147, loss: 0.3889
2022-09-28 05:55:34 - train: epoch 0089, iter [00680, 01251], lr: 0.001147, loss: 0.4018
2022-09-28 05:55:52 - train: epoch 0089, iter [00690, 01251], lr: 0.001147, loss: 0.4270
2022-09-28 05:56:10 - train: epoch 0089, iter [00700, 01251], lr: 0.001147, loss: 0.4249
2022-09-28 05:56:28 - train: epoch 0089, iter [00710, 01251], lr: 0.001147, loss: 0.4016
2022-09-28 05:56:46 - train: epoch 0089, iter [00720, 01251], lr: 0.001147, loss: 0.4209
2022-09-28 05:57:04 - train: epoch 0089, iter [00730, 01251], lr: 0.001147, loss: 0.4019
2022-09-28 05:57:22 - train: epoch 0089, iter [00740, 01251], lr: 0.001147, loss: 0.4118
2022-09-28 05:57:41 - train: epoch 0089, iter [00750, 01251], lr: 0.001147, loss: 0.3942
2022-09-28 05:57:59 - train: epoch 0089, iter [00760, 01251], lr: 0.001147, loss: 0.4176
2022-09-28 05:58:17 - train: epoch 0089, iter [00770, 01251], lr: 0.001147, loss: 0.4177
2022-09-28 05:58:35 - train: epoch 0089, iter [00780, 01251], lr: 0.001147, loss: 0.4173
2022-09-28 05:58:53 - train: epoch 0089, iter [00790, 01251], lr: 0.001147, loss: 0.4138
2022-09-28 05:59:10 - train: epoch 0089, iter [00800, 01251], lr: 0.001147, loss: 0.4075
2022-09-28 05:59:29 - train: epoch 0089, iter [00810, 01251], lr: 0.001147, loss: 0.4155
2022-09-28 05:59:47 - train: epoch 0089, iter [00820, 01251], lr: 0.001147, loss: 0.4375
2022-09-28 06:00:04 - train: epoch 0089, iter [00830, 01251], lr: 0.001147, loss: 0.4004
2022-09-28 06:00:22 - train: epoch 0089, iter [00840, 01251], lr: 0.001147, loss: 0.4355
2022-09-28 06:00:40 - train: epoch 0089, iter [00850, 01251], lr: 0.001147, loss: 0.4259
2022-09-28 06:00:58 - train: epoch 0089, iter [00860, 01251], lr: 0.001147, loss: 0.4210
2022-09-28 06:01:16 - train: epoch 0089, iter [00870, 01251], lr: 0.001147, loss: 0.4061
2022-09-28 06:01:34 - train: epoch 0089, iter [00880, 01251], lr: 0.001147, loss: 0.4035
2022-09-28 06:01:52 - train: epoch 0089, iter [00890, 01251], lr: 0.001147, loss: 0.4150
2022-09-28 06:02:10 - train: epoch 0089, iter [00900, 01251], lr: 0.001147, loss: 0.4147
2022-09-28 06:02:28 - train: epoch 0089, iter [00910, 01251], lr: 0.001147, loss: 0.4074
2022-09-28 06:02:45 - train: epoch 0089, iter [00920, 01251], lr: 0.001147, loss: 0.3983
2022-09-28 06:03:04 - train: epoch 0089, iter [00930, 01251], lr: 0.001147, loss: 0.4103
2022-09-28 06:03:21 - train: epoch 0089, iter [00940, 01251], lr: 0.001147, loss: 0.3975
2022-09-28 06:03:39 - train: epoch 0089, iter [00950, 01251], lr: 0.001146, loss: 0.4090
2022-09-28 06:03:58 - train: epoch 0089, iter [00960, 01251], lr: 0.001146, loss: 0.4074
2022-09-28 06:04:15 - train: epoch 0089, iter [00970, 01251], lr: 0.001146, loss: 0.3895
2022-09-28 06:04:33 - train: epoch 0089, iter [00980, 01251], lr: 0.001146, loss: 0.4172
2022-09-28 06:04:51 - train: epoch 0089, iter [00990, 01251], lr: 0.001146, loss: 0.4057
2022-09-28 06:05:09 - train: epoch 0089, iter [01000, 01251], lr: 0.001146, loss: 0.4318
2022-09-28 06:05:27 - train: epoch 0089, iter [01010, 01251], lr: 0.001146, loss: 0.4233
2022-09-28 06:05:45 - train: epoch 0089, iter [01020, 01251], lr: 0.001146, loss: 0.4399
2022-09-28 06:06:03 - train: epoch 0089, iter [01030, 01251], lr: 0.001146, loss: 0.4358
2022-09-28 06:06:21 - train: epoch 0089, iter [01040, 01251], lr: 0.001146, loss: 0.4174
2022-09-28 06:06:39 - train: epoch 0089, iter [01050, 01251], lr: 0.001146, loss: 0.4089
2022-09-28 06:06:57 - train: epoch 0089, iter [01060, 01251], lr: 0.001146, loss: 0.4148
2022-09-28 06:07:14 - train: epoch 0089, iter [01070, 01251], lr: 0.001146, loss: 0.4367
2022-09-28 06:07:32 - train: epoch 0089, iter [01080, 01251], lr: 0.001146, loss: 0.4178
2022-09-28 06:07:50 - train: epoch 0089, iter [01090, 01251], lr: 0.001146, loss: 0.4113
2022-09-28 06:08:08 - train: epoch 0089, iter [01100, 01251], lr: 0.001146, loss: 0.4029
2022-09-28 06:08:26 - train: epoch 0089, iter [01110, 01251], lr: 0.001146, loss: 0.3988
2022-09-28 06:08:45 - train: epoch 0089, iter [01120, 01251], lr: 0.001146, loss: 0.4162
2022-09-28 06:09:03 - train: epoch 0089, iter [01130, 01251], lr: 0.001146, loss: 0.4287
2022-09-28 06:09:21 - train: epoch 0089, iter [01140, 01251], lr: 0.001146, loss: 0.4079
2022-09-28 06:09:38 - train: epoch 0089, iter [01150, 01251], lr: 0.001146, loss: 0.4101
2022-09-28 06:09:57 - train: epoch 0089, iter [01160, 01251], lr: 0.001146, loss: 0.4099
2022-09-28 06:10:15 - train: epoch 0089, iter [01170, 01251], lr: 0.001146, loss: 0.4191
2022-09-28 06:10:33 - train: epoch 0089, iter [01180, 01251], lr: 0.001146, loss: 0.4060
2022-09-28 06:10:51 - train: epoch 0089, iter [01190, 01251], lr: 0.001146, loss: 0.4085
2022-09-28 06:11:09 - train: epoch 0089, iter [01200, 01251], lr: 0.001146, loss: 0.4434
2022-09-28 06:11:27 - train: epoch 0089, iter [01210, 01251], lr: 0.001146, loss: 0.3895
2022-09-28 06:11:44 - train: epoch 0089, iter [01220, 01251], lr: 0.001146, loss: 0.3970
2022-09-28 06:12:02 - train: epoch 0089, iter [01230, 01251], lr: 0.001146, loss: 0.4053
2022-09-28 06:12:21 - train: epoch 0089, iter [01240, 01251], lr: 0.001146, loss: 0.4199
2022-09-28 06:12:38 - train: epoch 0089, iter [01250, 01251], lr: 0.001146, loss: 0.4158
2022-09-28 06:12:42 - train: epoch 089, train_loss: 0.4140
2022-09-28 06:12:44 - until epoch: 089, best_loss: 0.4140
2022-09-28 06:12:44 - epoch 090 lr: 0.001146
2022-09-28 06:13:17 - train: epoch 0090, iter [00010, 01251], lr: 0.001146, loss: 0.4096
2022-09-28 06:13:35 - train: epoch 0090, iter [00020, 01251], lr: 0.001146, loss: 0.4105
2022-09-28 06:13:53 - train: epoch 0090, iter [00030, 01251], lr: 0.001146, loss: 0.4210
2022-09-28 06:14:11 - train: epoch 0090, iter [00040, 01251], lr: 0.001146, loss: 0.4243
2022-09-28 06:14:29 - train: epoch 0090, iter [00050, 01251], lr: 0.001146, loss: 0.4130
2022-09-28 06:14:47 - train: epoch 0090, iter [00060, 01251], lr: 0.001146, loss: 0.4213
2022-09-28 06:15:05 - train: epoch 0090, iter [00070, 01251], lr: 0.001146, loss: 0.4342
2022-09-28 06:15:22 - train: epoch 0090, iter [00080, 01251], lr: 0.001146, loss: 0.4267
2022-09-28 06:15:41 - train: epoch 0090, iter [00090, 01251], lr: 0.001146, loss: 0.3961
2022-09-28 06:15:58 - train: epoch 0090, iter [00100, 01251], lr: 0.001146, loss: 0.4170
2022-09-28 06:16:17 - train: epoch 0090, iter [00110, 01251], lr: 0.001146, loss: 0.4170
2022-09-28 06:16:35 - train: epoch 0090, iter [00120, 01251], lr: 0.001146, loss: 0.4206
2022-09-28 06:16:53 - train: epoch 0090, iter [00130, 01251], lr: 0.001146, loss: 0.4218
2022-09-28 06:17:11 - train: epoch 0090, iter [00140, 01251], lr: 0.001146, loss: 0.4169
2022-09-28 06:17:29 - train: epoch 0090, iter [00150, 01251], lr: 0.001146, loss: 0.4390
2022-09-28 06:17:47 - train: epoch 0090, iter [00160, 01251], lr: 0.001146, loss: 0.4219
2022-09-28 06:18:05 - train: epoch 0090, iter [00170, 01251], lr: 0.001146, loss: 0.4316
2022-09-28 06:18:23 - train: epoch 0090, iter [00180, 01251], lr: 0.001146, loss: 0.4330
2022-09-28 06:18:41 - train: epoch 0090, iter [00190, 01251], lr: 0.001146, loss: 0.4469
2022-09-28 06:18:58 - train: epoch 0090, iter [00200, 01251], lr: 0.001146, loss: 0.4094
2022-09-28 06:19:17 - train: epoch 0090, iter [00210, 01251], lr: 0.001146, loss: 0.4261
2022-09-28 06:19:34 - train: epoch 0090, iter [00220, 01251], lr: 0.001146, loss: 0.3945
2022-09-28 06:19:52 - train: epoch 0090, iter [00230, 01251], lr: 0.001146, loss: 0.4060
2022-09-28 06:20:10 - train: epoch 0090, iter [00240, 01251], lr: 0.001146, loss: 0.4135
2022-09-28 06:20:28 - train: epoch 0090, iter [00250, 01251], lr: 0.001146, loss: 0.4281
2022-09-28 06:20:46 - train: epoch 0090, iter [00260, 01251], lr: 0.001146, loss: 0.4102
2022-09-28 06:21:04 - train: epoch 0090, iter [00270, 01251], lr: 0.001146, loss: 0.4043
2022-09-28 06:21:22 - train: epoch 0090, iter [00280, 01251], lr: 0.001145, loss: 0.3924
2022-09-28 06:21:40 - train: epoch 0090, iter [00290, 01251], lr: 0.001145, loss: 0.4090
2022-09-28 06:21:58 - train: epoch 0090, iter [00300, 01251], lr: 0.001145, loss: 0.4113
2022-09-28 06:22:16 - train: epoch 0090, iter [00310, 01251], lr: 0.001145, loss: 0.4349
2022-09-28 06:22:34 - train: epoch 0090, iter [00320, 01251], lr: 0.001145, loss: 0.4095
2022-09-28 06:22:52 - train: epoch 0090, iter [00330, 01251], lr: 0.001145, loss: 0.4056
2022-09-28 06:23:10 - train: epoch 0090, iter [00340, 01251], lr: 0.001145, loss: 0.4072
2022-09-28 06:23:28 - train: epoch 0090, iter [00350, 01251], lr: 0.001145, loss: 0.4251
2022-09-28 06:23:46 - train: epoch 0090, iter [00360, 01251], lr: 0.001145, loss: 0.4134
2022-09-28 06:24:04 - train: epoch 0090, iter [00370, 01251], lr: 0.001145, loss: 0.4287
2022-09-28 06:24:22 - train: epoch 0090, iter [00380, 01251], lr: 0.001145, loss: 0.4069
2022-09-28 06:24:40 - train: epoch 0090, iter [00390, 01251], lr: 0.001145, loss: 0.4198
2022-09-28 06:24:58 - train: epoch 0090, iter [00400, 01251], lr: 0.001145, loss: 0.3923
2022-09-28 06:25:16 - train: epoch 0090, iter [00410, 01251], lr: 0.001145, loss: 0.4032
2022-09-28 06:25:34 - train: epoch 0090, iter [00420, 01251], lr: 0.001145, loss: 0.4115
2022-09-28 06:25:52 - train: epoch 0090, iter [00430, 01251], lr: 0.001145, loss: 0.4271
2022-09-28 06:26:10 - train: epoch 0090, iter [00440, 01251], lr: 0.001145, loss: 0.4125
2022-09-28 06:26:28 - train: epoch 0090, iter [00450, 01251], lr: 0.001145, loss: 0.4212
2022-09-28 06:26:46 - train: epoch 0090, iter [00460, 01251], lr: 0.001145, loss: 0.4197
2022-09-28 06:27:04 - train: epoch 0090, iter [00470, 01251], lr: 0.001145, loss: 0.4095
2022-09-28 06:27:22 - train: epoch 0090, iter [00480, 01251], lr: 0.001145, loss: 0.4110
2022-09-28 06:27:40 - train: epoch 0090, iter [00490, 01251], lr: 0.001145, loss: 0.4276
2022-09-28 06:27:58 - train: epoch 0090, iter [00500, 01251], lr: 0.001145, loss: 0.4211
2022-09-28 06:28:16 - train: epoch 0090, iter [00510, 01251], lr: 0.001145, loss: 0.4184
2022-09-28 06:28:35 - train: epoch 0090, iter [00520, 01251], lr: 0.001145, loss: 0.4080
2022-09-28 06:28:52 - train: epoch 0090, iter [00530, 01251], lr: 0.001145, loss: 0.4151
2022-09-28 06:29:10 - train: epoch 0090, iter [00540, 01251], lr: 0.001145, loss: 0.4084
2022-09-28 06:29:28 - train: epoch 0090, iter [00550, 01251], lr: 0.001145, loss: 0.4272
2022-09-28 06:29:46 - train: epoch 0090, iter [00560, 01251], lr: 0.001145, loss: 0.4051
2022-09-28 06:30:04 - train: epoch 0090, iter [00570, 01251], lr: 0.001145, loss: 0.4112
2022-09-28 06:30:22 - train: epoch 0090, iter [00580, 01251], lr: 0.001145, loss: 0.4074
2022-09-28 06:30:40 - train: epoch 0090, iter [00590, 01251], lr: 0.001145, loss: 0.4314
2022-09-28 06:30:58 - train: epoch 0090, iter [00600, 01251], lr: 0.001145, loss: 0.4113
2022-09-28 06:31:16 - train: epoch 0090, iter [00610, 01251], lr: 0.001145, loss: 0.4096
2022-09-28 06:31:34 - train: epoch 0090, iter [00620, 01251], lr: 0.001145, loss: 0.4047
2022-09-28 06:31:52 - train: epoch 0090, iter [00630, 01251], lr: 0.001145, loss: 0.4050
2022-09-28 06:32:10 - train: epoch 0090, iter [00640, 01251], lr: 0.001145, loss: 0.4259
2022-09-28 06:32:27 - train: epoch 0090, iter [00650, 01251], lr: 0.001145, loss: 0.3951
2022-09-28 06:32:45 - train: epoch 0090, iter [00660, 01251], lr: 0.001145, loss: 0.4163
2022-09-28 06:33:03 - train: epoch 0090, iter [00670, 01251], lr: 0.001145, loss: 0.4142
2022-09-28 06:33:21 - train: epoch 0090, iter [00680, 01251], lr: 0.001145, loss: 0.4114
2022-09-28 06:33:39 - train: epoch 0090, iter [00690, 01251], lr: 0.001145, loss: 0.4382
2022-09-28 06:33:57 - train: epoch 0090, iter [00700, 01251], lr: 0.001145, loss: 0.4130
2022-09-28 06:34:15 - train: epoch 0090, iter [00710, 01251], lr: 0.001145, loss: 0.4144
2022-09-28 06:34:33 - train: epoch 0090, iter [00720, 01251], lr: 0.001145, loss: 0.4043
2022-09-28 06:34:51 - train: epoch 0090, iter [00730, 01251], lr: 0.001145, loss: 0.4186
2022-09-28 06:35:09 - train: epoch 0090, iter [00740, 01251], lr: 0.001145, loss: 0.4092
2022-09-28 06:35:27 - train: epoch 0090, iter [00750, 01251], lr: 0.001145, loss: 0.4293
2022-09-28 06:35:45 - train: epoch 0090, iter [00760, 01251], lr: 0.001145, loss: 0.3956
2022-09-28 06:36:03 - train: epoch 0090, iter [00770, 01251], lr: 0.001145, loss: 0.4089
2022-09-28 06:36:21 - train: epoch 0090, iter [00780, 01251], lr: 0.001145, loss: 0.4259
2022-09-28 06:36:39 - train: epoch 0090, iter [00790, 01251], lr: 0.001145, loss: 0.4123
2022-09-28 06:36:57 - train: epoch 0090, iter [00800, 01251], lr: 0.001145, loss: 0.4161
2022-09-28 06:37:15 - train: epoch 0090, iter [00810, 01251], lr: 0.001145, loss: 0.4250
2022-09-28 06:37:33 - train: epoch 0090, iter [00820, 01251], lr: 0.001145, loss: 0.4319
2022-09-28 06:37:51 - train: epoch 0090, iter [00830, 01251], lr: 0.001145, loss: 0.4123
2022-09-28 06:38:09 - train: epoch 0090, iter [00840, 01251], lr: 0.001145, loss: 0.4143
2022-09-28 06:38:27 - train: epoch 0090, iter [00850, 01251], lr: 0.001144, loss: 0.4213
2022-09-28 06:38:44 - train: epoch 0090, iter [00860, 01251], lr: 0.001144, loss: 0.3932
2022-09-28 06:39:02 - train: epoch 0090, iter [00870, 01251], lr: 0.001144, loss: 0.4201
2022-09-28 06:39:20 - train: epoch 0090, iter [00880, 01251], lr: 0.001144, loss: 0.4179
2022-09-28 06:39:38 - train: epoch 0090, iter [00890, 01251], lr: 0.001144, loss: 0.4017
2022-09-28 06:39:56 - train: epoch 0090, iter [00900, 01251], lr: 0.001144, loss: 0.4336
2022-09-28 06:40:14 - train: epoch 0090, iter [00910, 01251], lr: 0.001144, loss: 0.4033
2022-09-28 06:40:32 - train: epoch 0090, iter [00920, 01251], lr: 0.001144, loss: 0.4109
2022-09-28 06:40:50 - train: epoch 0090, iter [00930, 01251], lr: 0.001144, loss: 0.4145
2022-09-28 06:41:08 - train: epoch 0090, iter [00940, 01251], lr: 0.001144, loss: 0.3957
2022-09-28 06:41:25 - train: epoch 0090, iter [00950, 01251], lr: 0.001144, loss: 0.4193
2022-09-28 06:41:44 - train: epoch 0090, iter [00960, 01251], lr: 0.001144, loss: 0.4260
2022-09-28 06:42:02 - train: epoch 0090, iter [00970, 01251], lr: 0.001144, loss: 0.4257
2022-09-28 06:42:19 - train: epoch 0090, iter [00980, 01251], lr: 0.001144, loss: 0.4276
2022-09-28 06:42:37 - train: epoch 0090, iter [00990, 01251], lr: 0.001144, loss: 0.4281
2022-09-28 06:42:55 - train: epoch 0090, iter [01000, 01251], lr: 0.001144, loss: 0.4026
2022-09-28 06:43:13 - train: epoch 0090, iter [01010, 01251], lr: 0.001144, loss: 0.4221
2022-09-28 06:43:31 - train: epoch 0090, iter [01020, 01251], lr: 0.001144, loss: 0.4090
2022-09-28 06:43:49 - train: epoch 0090, iter [01030, 01251], lr: 0.001144, loss: 0.4464
2022-09-28 06:44:07 - train: epoch 0090, iter [01040, 01251], lr: 0.001144, loss: 0.4378
2022-09-28 06:44:24 - train: epoch 0090, iter [01050, 01251], lr: 0.001144, loss: 0.4108
2022-09-28 06:44:42 - train: epoch 0090, iter [01060, 01251], lr: 0.001144, loss: 0.3894
2022-09-28 06:45:00 - train: epoch 0090, iter [01070, 01251], lr: 0.001144, loss: 0.4012
2022-09-28 06:45:18 - train: epoch 0090, iter [01080, 01251], lr: 0.001144, loss: 0.4212
2022-09-28 06:45:36 - train: epoch 0090, iter [01090, 01251], lr: 0.001144, loss: 0.4001
2022-09-28 06:45:54 - train: epoch 0090, iter [01100, 01251], lr: 0.001144, loss: 0.4307
2022-09-28 06:46:12 - train: epoch 0090, iter [01110, 01251], lr: 0.001144, loss: 0.3987
2022-09-28 06:46:30 - train: epoch 0090, iter [01120, 01251], lr: 0.001144, loss: 0.3999
2022-09-28 06:46:48 - train: epoch 0090, iter [01130, 01251], lr: 0.001144, loss: 0.3963
2022-09-28 06:47:05 - train: epoch 0090, iter [01140, 01251], lr: 0.001144, loss: 0.4103
2022-09-28 06:47:23 - train: epoch 0090, iter [01150, 01251], lr: 0.001144, loss: 0.4098
2022-09-28 06:47:41 - train: epoch 0090, iter [01160, 01251], lr: 0.001144, loss: 0.4080
2022-09-28 06:47:59 - train: epoch 0090, iter [01170, 01251], lr: 0.001144, loss: 0.4121
2022-09-28 06:48:18 - train: epoch 0090, iter [01180, 01251], lr: 0.001144, loss: 0.4155
2022-09-28 06:48:36 - train: epoch 0090, iter [01190, 01251], lr: 0.001144, loss: 0.4157
2022-09-28 06:48:54 - train: epoch 0090, iter [01200, 01251], lr: 0.001144, loss: 0.4022
2022-09-28 06:49:12 - train: epoch 0090, iter [01210, 01251], lr: 0.001144, loss: 0.4028
2022-09-28 06:49:30 - train: epoch 0090, iter [01220, 01251], lr: 0.001144, loss: 0.4105
2022-09-28 06:49:48 - train: epoch 0090, iter [01230, 01251], lr: 0.001144, loss: 0.3926
2022-09-28 06:50:06 - train: epoch 0090, iter [01240, 01251], lr: 0.001144, loss: 0.4217
2022-09-28 06:50:23 - train: epoch 0090, iter [01250, 01251], lr: 0.001144, loss: 0.4114
2022-09-28 06:50:27 - train: epoch 090, train_loss: 0.4139
2022-09-28 06:50:29 - until epoch: 090, best_loss: 0.4139
2022-09-28 06:50:29 - epoch 091 lr: 0.001144
2022-09-28 06:51:02 - train: epoch 0091, iter [00010, 01251], lr: 0.001144, loss: 0.4105
2022-09-28 06:51:20 - train: epoch 0091, iter [00020, 01251], lr: 0.001144, loss: 0.4154
2022-09-28 06:51:38 - train: epoch 0091, iter [00030, 01251], lr: 0.001144, loss: 0.4041
2022-09-28 06:51:56 - train: epoch 0091, iter [00040, 01251], lr: 0.001144, loss: 0.4332
2022-09-28 06:52:14 - train: epoch 0091, iter [00050, 01251], lr: 0.001144, loss: 0.4096
2022-09-28 06:52:32 - train: epoch 0091, iter [00060, 01251], lr: 0.001144, loss: 0.4067
2022-09-28 06:52:50 - train: epoch 0091, iter [00070, 01251], lr: 0.001144, loss: 0.4296
2022-09-28 06:53:07 - train: epoch 0091, iter [00080, 01251], lr: 0.001144, loss: 0.4185
2022-09-28 06:53:26 - train: epoch 0091, iter [00090, 01251], lr: 0.001144, loss: 0.4272
2022-09-28 06:53:43 - train: epoch 0091, iter [00100, 01251], lr: 0.001144, loss: 0.4217
2022-09-28 06:54:01 - train: epoch 0091, iter [00110, 01251], lr: 0.001144, loss: 0.4209
2022-09-28 06:54:19 - train: epoch 0091, iter [00120, 01251], lr: 0.001144, loss: 0.4298
2022-09-28 06:54:37 - train: epoch 0091, iter [00130, 01251], lr: 0.001144, loss: 0.3989
2022-09-28 06:54:55 - train: epoch 0091, iter [00140, 01251], lr: 0.001144, loss: 0.4185
2022-09-28 06:55:13 - train: epoch 0091, iter [00150, 01251], lr: 0.001144, loss: 0.4041
2022-09-28 06:55:31 - train: epoch 0091, iter [00160, 01251], lr: 0.001144, loss: 0.4288
2022-09-28 06:55:49 - train: epoch 0091, iter [00170, 01251], lr: 0.001143, loss: 0.4182
2022-09-28 06:56:07 - train: epoch 0091, iter [00180, 01251], lr: 0.001143, loss: 0.4085
2022-09-28 06:56:25 - train: epoch 0091, iter [00190, 01251], lr: 0.001143, loss: 0.4076
2022-09-28 06:56:43 - train: epoch 0091, iter [00200, 01251], lr: 0.001143, loss: 0.4098
2022-09-28 06:57:01 - train: epoch 0091, iter [00210, 01251], lr: 0.001143, loss: 0.4156
2022-09-28 06:57:18 - train: epoch 0091, iter [00220, 01251], lr: 0.001143, loss: 0.4081
2022-09-28 06:57:36 - train: epoch 0091, iter [00230, 01251], lr: 0.001143, loss: 0.4151
2022-09-28 06:57:54 - train: epoch 0091, iter [00240, 01251], lr: 0.001143, loss: 0.4400
2022-09-28 06:58:12 - train: epoch 0091, iter [00250, 01251], lr: 0.001143, loss: 0.3966
2022-09-28 06:58:30 - train: epoch 0091, iter [00260, 01251], lr: 0.001143, loss: 0.4143
2022-09-28 06:58:48 - train: epoch 0091, iter [00270, 01251], lr: 0.001143, loss: 0.3971
2022-09-28 06:59:05 - train: epoch 0091, iter [00280, 01251], lr: 0.001143, loss: 0.4187
2022-09-28 06:59:23 - train: epoch 0091, iter [00290, 01251], lr: 0.001143, loss: 0.4178
2022-09-28 06:59:41 - train: epoch 0091, iter [00300, 01251], lr: 0.001143, loss: 0.4119
2022-09-28 06:59:59 - train: epoch 0091, iter [00310, 01251], lr: 0.001143, loss: 0.4107
2022-09-28 07:00:17 - train: epoch 0091, iter [00320, 01251], lr: 0.001143, loss: 0.4322
2022-09-28 07:00:35 - train: epoch 0091, iter [00330, 01251], lr: 0.001143, loss: 0.4258
2022-09-28 07:00:53 - train: epoch 0091, iter [00340, 01251], lr: 0.001143, loss: 0.4084
2022-09-28 07:01:11 - train: epoch 0091, iter [00350, 01251], lr: 0.001143, loss: 0.4036
2022-09-28 07:01:29 - train: epoch 0091, iter [00360, 01251], lr: 0.001143, loss: 0.3944
2022-09-28 07:01:47 - train: epoch 0091, iter [00370, 01251], lr: 0.001143, loss: 0.4066
2022-09-28 07:02:04 - train: epoch 0091, iter [00380, 01251], lr: 0.001143, loss: 0.4160
2022-09-28 07:02:22 - train: epoch 0091, iter [00390, 01251], lr: 0.001143, loss: 0.4045
2022-09-28 07:02:40 - train: epoch 0091, iter [00400, 01251], lr: 0.001143, loss: 0.4144
2022-09-28 07:02:58 - train: epoch 0091, iter [00410, 01251], lr: 0.001143, loss: 0.4056
2022-09-28 07:03:16 - train: epoch 0091, iter [00420, 01251], lr: 0.001143, loss: 0.3996
2022-09-28 07:03:34 - train: epoch 0091, iter [00430, 01251], lr: 0.001143, loss: 0.4379
2022-09-28 07:03:51 - train: epoch 0091, iter [00440, 01251], lr: 0.001143, loss: 0.4122
2022-09-28 07:04:09 - train: epoch 0091, iter [00450, 01251], lr: 0.001143, loss: 0.4018
2022-09-28 07:04:27 - train: epoch 0091, iter [00460, 01251], lr: 0.001143, loss: 0.4201
2022-09-28 07:04:45 - train: epoch 0091, iter [00470, 01251], lr: 0.001143, loss: 0.3971
2022-09-28 07:05:03 - train: epoch 0091, iter [00480, 01251], lr: 0.001143, loss: 0.4221
2022-09-28 07:05:21 - train: epoch 0091, iter [00490, 01251], lr: 0.001143, loss: 0.4062
2022-09-28 07:05:39 - train: epoch 0091, iter [00500, 01251], lr: 0.001143, loss: 0.3977
2022-09-28 07:05:57 - train: epoch 0091, iter [00510, 01251], lr: 0.001143, loss: 0.4298
2022-09-28 07:06:15 - train: epoch 0091, iter [00520, 01251], lr: 0.001143, loss: 0.4098
2022-09-28 07:06:32 - train: epoch 0091, iter [00530, 01251], lr: 0.001143, loss: 0.4091
2022-09-28 07:06:50 - train: epoch 0091, iter [00540, 01251], lr: 0.001143, loss: 0.4174
2022-09-28 07:07:08 - train: epoch 0091, iter [00550, 01251], lr: 0.001143, loss: 0.3971
2022-09-28 07:07:26 - train: epoch 0091, iter [00560, 01251], lr: 0.001143, loss: 0.4385
2022-09-28 07:07:44 - train: epoch 0091, iter [00570, 01251], lr: 0.001143, loss: 0.3947
2022-09-28 07:08:02 - train: epoch 0091, iter [00580, 01251], lr: 0.001143, loss: 0.4151
2022-09-28 07:08:20 - train: epoch 0091, iter [00590, 01251], lr: 0.001143, loss: 0.4096
2022-09-28 07:08:38 - train: epoch 0091, iter [00600, 01251], lr: 0.001143, loss: 0.4035
2022-09-28 07:08:56 - train: epoch 0091, iter [00610, 01251], lr: 0.001143, loss: 0.4037
2022-09-28 07:09:13 - train: epoch 0091, iter [00620, 01251], lr: 0.001143, loss: 0.4085
2022-09-28 07:09:31 - train: epoch 0091, iter [00630, 01251], lr: 0.001143, loss: 0.4150
2022-09-28 07:09:49 - train: epoch 0091, iter [00640, 01251], lr: 0.001143, loss: 0.4094
2022-09-28 07:10:07 - train: epoch 0091, iter [00650, 01251], lr: 0.001143, loss: 0.4185
2022-09-28 07:10:25 - train: epoch 0091, iter [00660, 01251], lr: 0.001143, loss: 0.4105
2022-09-28 07:10:43 - train: epoch 0091, iter [00670, 01251], lr: 0.001143, loss: 0.3995
2022-09-28 07:11:00 - train: epoch 0091, iter [00680, 01251], lr: 0.001143, loss: 0.4086
2022-09-28 07:11:18 - train: epoch 0091, iter [00690, 01251], lr: 0.001143, loss: 0.4207
2022-09-28 07:11:37 - train: epoch 0091, iter [00700, 01251], lr: 0.001143, loss: 0.4172
2022-09-28 07:11:54 - train: epoch 0091, iter [00710, 01251], lr: 0.001143, loss: 0.4229
2022-09-28 07:12:12 - train: epoch 0091, iter [00720, 01251], lr: 0.001143, loss: 0.4172
2022-09-28 07:12:30 - train: epoch 0091, iter [00730, 01251], lr: 0.001142, loss: 0.4109
2022-09-28 07:12:48 - train: epoch 0091, iter [00740, 01251], lr: 0.001142, loss: 0.4188
2022-09-28 07:13:06 - train: epoch 0091, iter [00750, 01251], lr: 0.001142, loss: 0.4016
2022-09-28 07:13:24 - train: epoch 0091, iter [00760, 01251], lr: 0.001142, loss: 0.4173
2022-09-28 07:13:42 - train: epoch 0091, iter [00770, 01251], lr: 0.001142, loss: 0.3962
2022-09-28 07:14:00 - train: epoch 0091, iter [00780, 01251], lr: 0.001142, loss: 0.4015
2022-09-28 07:14:18 - train: epoch 0091, iter [00790, 01251], lr: 0.001142, loss: 0.4137
2022-09-28 07:14:36 - train: epoch 0091, iter [00800, 01251], lr: 0.001142, loss: 0.4150
2022-09-28 07:14:54 - train: epoch 0091, iter [00810, 01251], lr: 0.001142, loss: 0.4337
2022-09-28 07:15:11 - train: epoch 0091, iter [00820, 01251], lr: 0.001142, loss: 0.4121
2022-09-28 07:15:29 - train: epoch 0091, iter [00830, 01251], lr: 0.001142, loss: 0.4100
2022-09-28 07:15:47 - train: epoch 0091, iter [00840, 01251], lr: 0.001142, loss: 0.3944
2022-09-28 07:16:05 - train: epoch 0091, iter [00850, 01251], lr: 0.001142, loss: 0.4119
2022-09-28 07:16:23 - train: epoch 0091, iter [00860, 01251], lr: 0.001142, loss: 0.3800
2022-09-28 07:16:40 - train: epoch 0091, iter [00870, 01251], lr: 0.001142, loss: 0.4060
2022-09-28 07:16:58 - train: epoch 0091, iter [00880, 01251], lr: 0.001142, loss: 0.4199
2022-09-28 07:17:16 - train: epoch 0091, iter [00890, 01251], lr: 0.001142, loss: 0.4182
2022-09-28 07:17:34 - train: epoch 0091, iter [00900, 01251], lr: 0.001142, loss: 0.4385
2022-09-28 07:17:52 - train: epoch 0091, iter [00910, 01251], lr: 0.001142, loss: 0.4248
2022-09-28 07:18:10 - train: epoch 0091, iter [00920, 01251], lr: 0.001142, loss: 0.4215
2022-09-28 07:18:28 - train: epoch 0091, iter [00930, 01251], lr: 0.001142, loss: 0.4118
2022-09-28 07:18:46 - train: epoch 0091, iter [00940, 01251], lr: 0.001142, loss: 0.4305
2022-09-28 07:19:04 - train: epoch 0091, iter [00950, 01251], lr: 0.001142, loss: 0.4143
2022-09-28 07:19:22 - train: epoch 0091, iter [00960, 01251], lr: 0.001142, loss: 0.4112
2022-09-28 07:19:40 - train: epoch 0091, iter [00970, 01251], lr: 0.001142, loss: 0.3990
2022-09-28 07:19:58 - train: epoch 0091, iter [00980, 01251], lr: 0.001142, loss: 0.4092
2022-09-28 07:20:15 - train: epoch 0091, iter [00990, 01251], lr: 0.001142, loss: 0.4199
2022-09-28 07:20:33 - train: epoch 0091, iter [01000, 01251], lr: 0.001142, loss: 0.4230
2022-09-28 07:20:51 - train: epoch 0091, iter [01010, 01251], lr: 0.001142, loss: 0.4332
2022-09-28 07:21:09 - train: epoch 0091, iter [01020, 01251], lr: 0.001142, loss: 0.4075
2022-09-28 07:21:27 - train: epoch 0091, iter [01030, 01251], lr: 0.001142, loss: 0.4174
2022-09-28 07:21:45 - train: epoch 0091, iter [01040, 01251], lr: 0.001142, loss: 0.4084
2022-09-28 07:22:02 - train: epoch 0091, iter [01050, 01251], lr: 0.001142, loss: 0.4289
2022-09-28 07:22:20 - train: epoch 0091, iter [01060, 01251], lr: 0.001142, loss: 0.4108
2022-09-28 07:22:38 - train: epoch 0091, iter [01070, 01251], lr: 0.001142, loss: 0.4204
2022-09-28 07:22:56 - train: epoch 0091, iter [01080, 01251], lr: 0.001142, loss: 0.4230
2022-09-28 07:23:14 - train: epoch 0091, iter [01090, 01251], lr: 0.001142, loss: 0.4048
2022-09-28 07:23:32 - train: epoch 0091, iter [01100, 01251], lr: 0.001142, loss: 0.4087
2022-09-28 07:23:50 - train: epoch 0091, iter [01110, 01251], lr: 0.001142, loss: 0.4149
2022-09-28 07:24:07 - train: epoch 0091, iter [01120, 01251], lr: 0.001142, loss: 0.4238
2022-09-28 07:24:25 - train: epoch 0091, iter [01130, 01251], lr: 0.001142, loss: 0.4092
2022-09-28 07:24:43 - train: epoch 0091, iter [01140, 01251], lr: 0.001142, loss: 0.4163
2022-09-28 07:25:01 - train: epoch 0091, iter [01150, 01251], lr: 0.001142, loss: 0.4126
2022-09-28 07:25:19 - train: epoch 0091, iter [01160, 01251], lr: 0.001142, loss: 0.4206
2022-09-28 07:25:37 - train: epoch 0091, iter [01170, 01251], lr: 0.001142, loss: 0.4137
2022-09-28 07:25:55 - train: epoch 0091, iter [01180, 01251], lr: 0.001142, loss: 0.4150
2022-09-28 07:26:13 - train: epoch 0091, iter [01190, 01251], lr: 0.001142, loss: 0.4101
2022-09-28 07:26:31 - train: epoch 0091, iter [01200, 01251], lr: 0.001142, loss: 0.4073
2022-09-28 07:26:49 - train: epoch 0091, iter [01210, 01251], lr: 0.001142, loss: 0.4023
2022-09-28 07:27:07 - train: epoch 0091, iter [01220, 01251], lr: 0.001142, loss: 0.4069
2022-09-28 07:27:25 - train: epoch 0091, iter [01230, 01251], lr: 0.001142, loss: 0.4159
2022-09-28 07:27:43 - train: epoch 0091, iter [01240, 01251], lr: 0.001142, loss: 0.3941
2022-09-28 07:28:00 - train: epoch 0091, iter [01250, 01251], lr: 0.001142, loss: 0.4108
2022-09-28 07:28:03 - train: epoch 091, train_loss: 0.4140
2022-09-28 07:28:05 - until epoch: 091, best_loss: 0.4139
2022-09-28 07:28:05 - epoch 092 lr: 0.001142
2022-09-28 07:28:38 - train: epoch 0092, iter [00010, 01251], lr: 0.001142, loss: 0.4065
2022-09-28 07:28:56 - train: epoch 0092, iter [00020, 01251], lr: 0.001142, loss: 0.4001
2022-09-28 07:29:14 - train: epoch 0092, iter [00030, 01251], lr: 0.001141, loss: 0.4040
2022-09-28 07:29:32 - train: epoch 0092, iter [00040, 01251], lr: 0.001141, loss: 0.4076
2022-09-28 07:29:50 - train: epoch 0092, iter [00050, 01251], lr: 0.001141, loss: 0.4096
2022-09-28 07:30:08 - train: epoch 0092, iter [00060, 01251], lr: 0.001141, loss: 0.4133
2022-09-28 07:30:26 - train: epoch 0092, iter [00070, 01251], lr: 0.001141, loss: 0.4038
2022-09-28 07:30:44 - train: epoch 0092, iter [00080, 01251], lr: 0.001141, loss: 0.4079
2022-09-28 07:31:02 - train: epoch 0092, iter [00090, 01251], lr: 0.001141, loss: 0.4246
2022-09-28 07:31:20 - train: epoch 0092, iter [00100, 01251], lr: 0.001141, loss: 0.4102
2022-09-28 07:31:38 - train: epoch 0092, iter [00110, 01251], lr: 0.001141, loss: 0.4067
2022-09-28 07:31:56 - train: epoch 0092, iter [00120, 01251], lr: 0.001141, loss: 0.4168
2022-09-28 07:32:14 - train: epoch 0092, iter [00130, 01251], lr: 0.001141, loss: 0.4147
2022-09-28 07:32:32 - train: epoch 0092, iter [00140, 01251], lr: 0.001141, loss: 0.3974
2022-09-28 07:32:50 - train: epoch 0092, iter [00150, 01251], lr: 0.001141, loss: 0.4015
2022-09-28 07:33:08 - train: epoch 0092, iter [00160, 01251], lr: 0.001141, loss: 0.4102
2022-09-28 07:33:25 - train: epoch 0092, iter [00170, 01251], lr: 0.001141, loss: 0.4289
2022-09-28 07:33:43 - train: epoch 0092, iter [00180, 01251], lr: 0.001141, loss: 0.4178
2022-09-28 07:34:01 - train: epoch 0092, iter [00190, 01251], lr: 0.001141, loss: 0.4081
2022-09-28 07:34:19 - train: epoch 0092, iter [00200, 01251], lr: 0.001141, loss: 0.4164
2022-09-28 07:34:37 - train: epoch 0092, iter [00210, 01251], lr: 0.001141, loss: 0.4258
2022-09-28 07:34:54 - train: epoch 0092, iter [00220, 01251], lr: 0.001141, loss: 0.4142
2022-09-28 07:35:12 - train: epoch 0092, iter [00230, 01251], lr: 0.001141, loss: 0.4128
2022-09-28 07:35:30 - train: epoch 0092, iter [00240, 01251], lr: 0.001141, loss: 0.4051
2022-09-28 07:35:48 - train: epoch 0092, iter [00250, 01251], lr: 0.001141, loss: 0.4091
2022-09-28 07:36:06 - train: epoch 0092, iter [00260, 01251], lr: 0.001141, loss: 0.4062
2022-09-28 07:36:24 - train: epoch 0092, iter [00270, 01251], lr: 0.001141, loss: 0.4093
2022-09-28 07:36:41 - train: epoch 0092, iter [00280, 01251], lr: 0.001141, loss: 0.4268
2022-09-28 07:36:59 - train: epoch 0092, iter [00290, 01251], lr: 0.001141, loss: 0.4273
2022-09-28 07:37:17 - train: epoch 0092, iter [00300, 01251], lr: 0.001141, loss: 0.4171
2022-09-28 07:37:35 - train: epoch 0092, iter [00310, 01251], lr: 0.001141, loss: 0.4063
2022-09-28 07:37:53 - train: epoch 0092, iter [00320, 01251], lr: 0.001141, loss: 0.4110
2022-09-28 07:38:11 - train: epoch 0092, iter [00330, 01251], lr: 0.001141, loss: 0.4064
2022-09-28 07:38:29 - train: epoch 0092, iter [00340, 01251], lr: 0.001141, loss: 0.4223
2022-09-28 07:38:47 - train: epoch 0092, iter [00350, 01251], lr: 0.001141, loss: 0.4231
2022-09-28 07:39:05 - train: epoch 0092, iter [00360, 01251], lr: 0.001141, loss: 0.4141
2022-09-28 07:39:22 - train: epoch 0092, iter [00370, 01251], lr: 0.001141, loss: 0.4237
2022-09-28 07:39:40 - train: epoch 0092, iter [00380, 01251], lr: 0.001141, loss: 0.4182
2022-09-28 07:39:58 - train: epoch 0092, iter [00390, 01251], lr: 0.001141, loss: 0.4265
2022-09-28 07:40:16 - train: epoch 0092, iter [00400, 01251], lr: 0.001141, loss: 0.4159
2022-09-28 07:40:34 - train: epoch 0092, iter [00410, 01251], lr: 0.001141, loss: 0.4102
2022-09-28 07:40:52 - train: epoch 0092, iter [00420, 01251], lr: 0.001141, loss: 0.4079
2022-09-28 07:41:10 - train: epoch 0092, iter [00430, 01251], lr: 0.001141, loss: 0.4130
2022-09-28 07:41:28 - train: epoch 0092, iter [00440, 01251], lr: 0.001141, loss: 0.4073
2022-09-28 07:41:46 - train: epoch 0092, iter [00450, 01251], lr: 0.001141, loss: 0.4116
2022-09-28 07:42:04 - train: epoch 0092, iter [00460, 01251], lr: 0.001141, loss: 0.4241
2022-09-28 07:42:22 - train: epoch 0092, iter [00470, 01251], lr: 0.001141, loss: 0.4254
2022-09-28 07:42:40 - train: epoch 0092, iter [00480, 01251], lr: 0.001141, loss: 0.4003
2022-09-28 07:42:58 - train: epoch 0092, iter [00490, 01251], lr: 0.001141, loss: 0.4080
2022-09-28 07:43:15 - train: epoch 0092, iter [00500, 01251], lr: 0.001141, loss: 0.4200
2022-09-28 07:43:33 - train: epoch 0092, iter [00510, 01251], lr: 0.001141, loss: 0.4201
2022-09-28 07:43:51 - train: epoch 0092, iter [00520, 01251], lr: 0.001141, loss: 0.3996
2022-09-28 07:44:09 - train: epoch 0092, iter [00530, 01251], lr: 0.001141, loss: 0.4311
2022-09-28 07:44:27 - train: epoch 0092, iter [00540, 01251], lr: 0.001141, loss: 0.4177
2022-09-28 07:44:45 - train: epoch 0092, iter [00550, 01251], lr: 0.001141, loss: 0.3936
2022-09-28 07:45:03 - train: epoch 0092, iter [00560, 01251], lr: 0.001141, loss: 0.4384
2022-09-28 07:45:20 - train: epoch 0092, iter [00570, 01251], lr: 0.001141, loss: 0.4220
2022-09-28 07:45:38 - train: epoch 0092, iter [00580, 01251], lr: 0.001141, loss: 0.4049
2022-09-28 07:45:56 - train: epoch 0092, iter [00590, 01251], lr: 0.001140, loss: 0.3980
2022-09-28 07:46:14 - train: epoch 0092, iter [00600, 01251], lr: 0.001140, loss: 0.3963
2022-09-28 07:46:32 - train: epoch 0092, iter [00610, 01251], lr: 0.001140, loss: 0.4242
2022-09-28 07:46:50 - train: epoch 0092, iter [00620, 01251], lr: 0.001140, loss: 0.4099
2022-09-28 07:47:08 - train: epoch 0092, iter [00630, 01251], lr: 0.001140, loss: 0.4183
2022-09-28 07:47:26 - train: epoch 0092, iter [00640, 01251], lr: 0.001140, loss: 0.4104
2022-09-28 07:47:44 - train: epoch 0092, iter [00650, 01251], lr: 0.001140, loss: 0.4105
2022-09-28 07:48:02 - train: epoch 0092, iter [00660, 01251], lr: 0.001140, loss: 0.4062
2022-09-28 07:48:19 - train: epoch 0092, iter [00670, 01251], lr: 0.001140, loss: 0.4026
2022-09-28 07:48:37 - train: epoch 0092, iter [00680, 01251], lr: 0.001140, loss: 0.4456
2022-09-28 07:48:55 - train: epoch 0092, iter [00690, 01251], lr: 0.001140, loss: 0.4147
2022-09-28 07:49:13 - train: epoch 0092, iter [00700, 01251], lr: 0.001140, loss: 0.4028
2022-09-28 07:49:31 - train: epoch 0092, iter [00710, 01251], lr: 0.001140, loss: 0.4149
2022-09-28 07:49:49 - train: epoch 0092, iter [00720, 01251], lr: 0.001140, loss: 0.4221
2022-09-28 07:50:07 - train: epoch 0092, iter [00730, 01251], lr: 0.001140, loss: 0.4321
2022-09-28 07:50:25 - train: epoch 0092, iter [00740, 01251], lr: 0.001140, loss: 0.3959
2022-09-28 07:50:43 - train: epoch 0092, iter [00750, 01251], lr: 0.001140, loss: 0.4105
2022-09-28 07:51:01 - train: epoch 0092, iter [00760, 01251], lr: 0.001140, loss: 0.4006
2022-09-28 07:51:19 - train: epoch 0092, iter [00770, 01251], lr: 0.001140, loss: 0.4001
2022-09-28 07:51:37 - train: epoch 0092, iter [00780, 01251], lr: 0.001140, loss: 0.3974
2022-09-28 07:51:55 - train: epoch 0092, iter [00790, 01251], lr: 0.001140, loss: 0.4143
2022-09-28 07:52:13 - train: epoch 0092, iter [00800, 01251], lr: 0.001140, loss: 0.4188
2022-09-28 07:52:31 - train: epoch 0092, iter [00810, 01251], lr: 0.001140, loss: 0.4088
2022-09-28 07:52:48 - train: epoch 0092, iter [00820, 01251], lr: 0.001140, loss: 0.4212
2022-09-28 07:53:06 - train: epoch 0092, iter [00830, 01251], lr: 0.001140, loss: 0.4051
2022-09-28 07:53:24 - train: epoch 0092, iter [00840, 01251], lr: 0.001140, loss: 0.4167
2022-09-28 07:53:42 - train: epoch 0092, iter [00850, 01251], lr: 0.001140, loss: 0.4207
2022-09-28 07:54:00 - train: epoch 0092, iter [00860, 01251], lr: 0.001140, loss: 0.4084
2022-09-28 07:54:18 - train: epoch 0092, iter [00870, 01251], lr: 0.001140, loss: 0.4016
2022-09-28 07:54:36 - train: epoch 0092, iter [00880, 01251], lr: 0.001140, loss: 0.4134
2022-09-28 07:54:54 - train: epoch 0092, iter [00890, 01251], lr: 0.001140, loss: 0.4148
2022-09-28 07:55:12 - train: epoch 0092, iter [00900, 01251], lr: 0.001140, loss: 0.4144
2022-09-28 07:55:30 - train: epoch 0092, iter [00910, 01251], lr: 0.001140, loss: 0.3978
2022-09-28 07:55:48 - train: epoch 0092, iter [00920, 01251], lr: 0.001140, loss: 0.4133
2022-09-28 07:56:06 - train: epoch 0092, iter [00930, 01251], lr: 0.001140, loss: 0.4246
2022-09-28 07:56:24 - train: epoch 0092, iter [00940, 01251], lr: 0.001140, loss: 0.4147
2022-09-28 07:56:41 - train: epoch 0092, iter [00950, 01251], lr: 0.001140, loss: 0.4103
2022-09-28 07:56:59 - train: epoch 0092, iter [00960, 01251], lr: 0.001140, loss: 0.4265
2022-09-28 07:57:17 - train: epoch 0092, iter [00970, 01251], lr: 0.001140, loss: 0.4140
2022-09-28 07:57:35 - train: epoch 0092, iter [00980, 01251], lr: 0.001140, loss: 0.3832
2022-09-28 07:57:53 - train: epoch 0092, iter [00990, 01251], lr: 0.001140, loss: 0.4103
2022-09-28 07:58:11 - train: epoch 0092, iter [01000, 01251], lr: 0.001140, loss: 0.4122
2022-09-28 07:58:29 - train: epoch 0092, iter [01010, 01251], lr: 0.001140, loss: 0.4439
2022-09-28 07:58:47 - train: epoch 0092, iter [01020, 01251], lr: 0.001140, loss: 0.4233
2022-09-28 07:59:05 - train: epoch 0092, iter [01030, 01251], lr: 0.001140, loss: 0.4184
2022-09-28 07:59:23 - train: epoch 0092, iter [01040, 01251], lr: 0.001140, loss: 0.3966
2022-09-28 07:59:41 - train: epoch 0092, iter [01050, 01251], lr: 0.001140, loss: 0.4252
2022-09-28 07:59:59 - train: epoch 0092, iter [01060, 01251], lr: 0.001140, loss: 0.4287
2022-09-28 08:00:17 - train: epoch 0092, iter [01070, 01251], lr: 0.001140, loss: 0.4235
2022-09-28 08:00:35 - train: epoch 0092, iter [01080, 01251], lr: 0.001140, loss: 0.4185
2022-09-28 08:00:52 - train: epoch 0092, iter [01090, 01251], lr: 0.001140, loss: 0.3899
2022-09-28 08:01:10 - train: epoch 0092, iter [01100, 01251], lr: 0.001140, loss: 0.3951
2022-09-28 08:01:28 - train: epoch 0092, iter [01110, 01251], lr: 0.001140, loss: 0.4246
2022-09-28 08:01:46 - train: epoch 0092, iter [01120, 01251], lr: 0.001140, loss: 0.4072
2022-09-28 08:02:04 - train: epoch 0092, iter [01130, 01251], lr: 0.001139, loss: 0.4316
2022-09-28 08:02:22 - train: epoch 0092, iter [01140, 01251], lr: 0.001139, loss: 0.4132
2022-09-28 08:02:40 - train: epoch 0092, iter [01150, 01251], lr: 0.001139, loss: 0.4174
2022-09-28 08:02:58 - train: epoch 0092, iter [01160, 01251], lr: 0.001139, loss: 0.3956
2022-09-28 08:03:16 - train: epoch 0092, iter [01170, 01251], lr: 0.001139, loss: 0.4068
2022-09-28 08:03:34 - train: epoch 0092, iter [01180, 01251], lr: 0.001139, loss: 0.4042
2022-09-28 08:03:52 - train: epoch 0092, iter [01190, 01251], lr: 0.001139, loss: 0.4367
2022-09-28 08:04:11 - train: epoch 0092, iter [01200, 01251], lr: 0.001139, loss: 0.4150
2022-09-28 08:04:29 - train: epoch 0092, iter [01210, 01251], lr: 0.001139, loss: 0.4204
2022-09-28 08:04:47 - train: epoch 0092, iter [01220, 01251], lr: 0.001139, loss: 0.4177
2022-09-28 08:05:05 - train: epoch 0092, iter [01230, 01251], lr: 0.001139, loss: 0.4136
2022-09-28 08:05:23 - train: epoch 0092, iter [01240, 01251], lr: 0.001139, loss: 0.3843
2022-09-28 08:05:40 - train: epoch 0092, iter [01250, 01251], lr: 0.001139, loss: 0.4060
2022-09-28 08:05:44 - train: epoch 092, train_loss: 0.4139
2022-09-28 08:05:46 - until epoch: 092, best_loss: 0.4139
2022-09-28 08:05:46 - epoch 093 lr: 0.001139
2022-09-28 08:06:20 - train: epoch 0093, iter [00010, 01251], lr: 0.001139, loss: 0.4140
2022-09-28 08:06:37 - train: epoch 0093, iter [00020, 01251], lr: 0.001139, loss: 0.4094
2022-09-28 08:06:55 - train: epoch 0093, iter [00030, 01251], lr: 0.001139, loss: 0.4209
2022-09-28 08:07:13 - train: epoch 0093, iter [00040, 01251], lr: 0.001139, loss: 0.4208
2022-09-28 08:07:31 - train: epoch 0093, iter [00050, 01251], lr: 0.001139, loss: 0.3964
2022-09-28 08:07:49 - train: epoch 0093, iter [00060, 01251], lr: 0.001139, loss: 0.4441
2022-09-28 08:08:07 - train: epoch 0093, iter [00070, 01251], lr: 0.001139, loss: 0.4204
2022-09-28 08:08:25 - train: epoch 0093, iter [00080, 01251], lr: 0.001139, loss: 0.4231
2022-09-28 08:08:43 - train: epoch 0093, iter [00090, 01251], lr: 0.001139, loss: 0.4231
2022-09-28 08:09:02 - train: epoch 0093, iter [00100, 01251], lr: 0.001139, loss: 0.4261
2022-09-28 08:09:20 - train: epoch 0093, iter [00110, 01251], lr: 0.001139, loss: 0.4028
2022-09-28 08:09:38 - train: epoch 0093, iter [00120, 01251], lr: 0.001139, loss: 0.4135
2022-09-28 08:09:56 - train: epoch 0093, iter [00130, 01251], lr: 0.001139, loss: 0.3847
2022-09-28 08:10:14 - train: epoch 0093, iter [00140, 01251], lr: 0.001139, loss: 0.4041
2022-09-28 08:10:33 - train: epoch 0093, iter [00150, 01251], lr: 0.001139, loss: 0.4051
2022-09-28 08:10:51 - train: epoch 0093, iter [00160, 01251], lr: 0.001139, loss: 0.4156
2022-09-28 08:11:09 - train: epoch 0093, iter [00170, 01251], lr: 0.001139, loss: 0.4165
2022-09-28 08:11:27 - train: epoch 0093, iter [00180, 01251], lr: 0.001139, loss: 0.4215
2022-09-28 08:11:46 - train: epoch 0093, iter [00190, 01251], lr: 0.001139, loss: 0.4069
2022-09-28 08:12:04 - train: epoch 0093, iter [00200, 01251], lr: 0.001139, loss: 0.4223
2022-09-28 08:12:22 - train: epoch 0093, iter [00210, 01251], lr: 0.001139, loss: 0.3960
2022-09-28 08:12:40 - train: epoch 0093, iter [00220, 01251], lr: 0.001139, loss: 0.4105
2022-09-28 08:12:59 - train: epoch 0093, iter [00230, 01251], lr: 0.001139, loss: 0.3980
2022-09-28 08:13:17 - train: epoch 0093, iter [00240, 01251], lr: 0.001139, loss: 0.4301
2022-09-28 08:13:35 - train: epoch 0093, iter [00250, 01251], lr: 0.001139, loss: 0.4238
2022-09-28 08:13:53 - train: epoch 0093, iter [00260, 01251], lr: 0.001139, loss: 0.4004
2022-09-28 08:14:11 - train: epoch 0093, iter [00270, 01251], lr: 0.001139, loss: 0.4240
2022-09-28 08:14:29 - train: epoch 0093, iter [00280, 01251], lr: 0.001139, loss: 0.4251
2022-09-28 08:14:48 - train: epoch 0093, iter [00290, 01251], lr: 0.001139, loss: 0.4160
2022-09-28 08:15:06 - train: epoch 0093, iter [00300, 01251], lr: 0.001139, loss: 0.4325
2022-09-28 08:15:24 - train: epoch 0093, iter [00310, 01251], lr: 0.001139, loss: 0.4203
2022-09-28 08:15:42 - train: epoch 0093, iter [00320, 01251], lr: 0.001139, loss: 0.4075
2022-09-28 08:16:01 - train: epoch 0093, iter [00330, 01251], lr: 0.001139, loss: 0.4024
2022-09-28 08:16:19 - train: epoch 0093, iter [00340, 01251], lr: 0.001139, loss: 0.4156
2022-09-28 08:16:37 - train: epoch 0093, iter [00350, 01251], lr: 0.001139, loss: 0.4188
2022-09-28 08:16:55 - train: epoch 0093, iter [00360, 01251], lr: 0.001139, loss: 0.4089
2022-09-28 08:17:13 - train: epoch 0093, iter [00370, 01251], lr: 0.001139, loss: 0.4138
2022-09-28 08:17:31 - train: epoch 0093, iter [00380, 01251], lr: 0.001139, loss: 0.4033
2022-09-28 08:17:49 - train: epoch 0093, iter [00390, 01251], lr: 0.001139, loss: 0.3947
2022-09-28 08:18:08 - train: epoch 0093, iter [00400, 01251], lr: 0.001139, loss: 0.4241
2022-09-28 08:18:26 - train: epoch 0093, iter [00410, 01251], lr: 0.001139, loss: 0.4212
2022-09-28 08:18:44 - train: epoch 0093, iter [00420, 01251], lr: 0.001139, loss: 0.4224
2022-09-28 08:19:02 - train: epoch 0093, iter [00430, 01251], lr: 0.001138, loss: 0.4099
2022-09-28 08:19:20 - train: epoch 0093, iter [00440, 01251], lr: 0.001138, loss: 0.4135
2022-09-28 08:19:38 - train: epoch 0093, iter [00450, 01251], lr: 0.001138, loss: 0.4230
2022-09-28 08:19:56 - train: epoch 0093, iter [00460, 01251], lr: 0.001138, loss: 0.4025
2022-09-28 08:20:14 - train: epoch 0093, iter [00470, 01251], lr: 0.001138, loss: 0.3988
2022-09-28 08:20:32 - train: epoch 0093, iter [00480, 01251], lr: 0.001138, loss: 0.4179
2022-09-28 08:20:51 - train: epoch 0093, iter [00490, 01251], lr: 0.001138, loss: 0.4152
2022-09-28 08:21:09 - train: epoch 0093, iter [00500, 01251], lr: 0.001138, loss: 0.3945
2022-09-28 08:21:27 - train: epoch 0093, iter [00510, 01251], lr: 0.001138, loss: 0.4095
2022-09-28 08:21:45 - train: epoch 0093, iter [00520, 01251], lr: 0.001138, loss: 0.4263
2022-09-28 08:22:03 - train: epoch 0093, iter [00530, 01251], lr: 0.001138, loss: 0.3998
2022-09-28 08:22:22 - train: epoch 0093, iter [00540, 01251], lr: 0.001138, loss: 0.3898
2022-09-28 08:22:40 - train: epoch 0093, iter [00550, 01251], lr: 0.001138, loss: 0.4175
2022-09-28 08:22:58 - train: epoch 0093, iter [00560, 01251], lr: 0.001138, loss: 0.4091
2022-09-28 08:23:16 - train: epoch 0093, iter [00570, 01251], lr: 0.001138, loss: 0.4197
2022-09-28 08:23:34 - train: epoch 0093, iter [00580, 01251], lr: 0.001138, loss: 0.4152
2022-09-28 08:23:52 - train: epoch 0093, iter [00590, 01251], lr: 0.001138, loss: 0.4181
2022-09-28 08:24:10 - train: epoch 0093, iter [00600, 01251], lr: 0.001138, loss: 0.4314
2022-09-28 08:24:28 - train: epoch 0093, iter [00610, 01251], lr: 0.001138, loss: 0.4240
2022-09-28 08:24:46 - train: epoch 0093, iter [00620, 01251], lr: 0.001138, loss: 0.3907
2022-09-28 08:25:04 - train: epoch 0093, iter [00630, 01251], lr: 0.001138, loss: 0.4144
2022-09-28 08:25:22 - train: epoch 0093, iter [00640, 01251], lr: 0.001138, loss: 0.4122
2022-09-28 08:25:40 - train: epoch 0093, iter [00650, 01251], lr: 0.001138, loss: 0.4070
2022-09-28 08:25:58 - train: epoch 0093, iter [00660, 01251], lr: 0.001138, loss: 0.4217
2022-09-28 08:26:16 - train: epoch 0093, iter [00670, 01251], lr: 0.001138, loss: 0.4230
2022-09-28 08:26:34 - train: epoch 0093, iter [00680, 01251], lr: 0.001138, loss: 0.4188
2022-09-28 08:26:52 - train: epoch 0093, iter [00690, 01251], lr: 0.001138, loss: 0.4345
2022-09-28 08:27:10 - train: epoch 0093, iter [00700, 01251], lr: 0.001138, loss: 0.4125
2022-09-28 08:27:29 - train: epoch 0093, iter [00710, 01251], lr: 0.001138, loss: 0.4142
2022-09-28 08:27:47 - train: epoch 0093, iter [00720, 01251], lr: 0.001138, loss: 0.4247
2022-09-28 08:28:05 - train: epoch 0093, iter [00730, 01251], lr: 0.001138, loss: 0.4192
2022-09-28 08:28:23 - train: epoch 0093, iter [00740, 01251], lr: 0.001138, loss: 0.4208
2022-09-28 08:28:41 - train: epoch 0093, iter [00750, 01251], lr: 0.001138, loss: 0.4089
2022-09-28 08:28:59 - train: epoch 0093, iter [00760, 01251], lr: 0.001138, loss: 0.4110
2022-09-28 08:29:18 - train: epoch 0093, iter [00770, 01251], lr: 0.001138, loss: 0.4061
2022-09-28 08:29:35 - train: epoch 0093, iter [00780, 01251], lr: 0.001138, loss: 0.4140
2022-09-28 08:29:53 - train: epoch 0093, iter [00790, 01251], lr: 0.001138, loss: 0.4132
2022-09-28 08:30:12 - train: epoch 0093, iter [00800, 01251], lr: 0.001138, loss: 0.4146
2022-09-28 08:30:30 - train: epoch 0093, iter [00810, 01251], lr: 0.001138, loss: 0.4032
2022-09-28 08:30:48 - train: epoch 0093, iter [00820, 01251], lr: 0.001138, loss: 0.4064
2022-09-28 08:31:07 - train: epoch 0093, iter [00830, 01251], lr: 0.001138, loss: 0.4255
2022-09-28 08:31:25 - train: epoch 0093, iter [00840, 01251], lr: 0.001138, loss: 0.4147
2022-09-28 08:31:43 - train: epoch 0093, iter [00850, 01251], lr: 0.001138, loss: 0.4153
2022-09-28 08:32:01 - train: epoch 0093, iter [00860, 01251], lr: 0.001138, loss: 0.4174
2022-09-28 08:32:19 - train: epoch 0093, iter [00870, 01251], lr: 0.001138, loss: 0.4076
2022-09-28 08:32:37 - train: epoch 0093, iter [00880, 01251], lr: 0.001138, loss: 0.4119
2022-09-28 08:32:55 - train: epoch 0093, iter [00890, 01251], lr: 0.001138, loss: 0.4192
2022-09-28 08:33:13 - train: epoch 0093, iter [00900, 01251], lr: 0.001138, loss: 0.4258
2022-09-28 08:33:32 - train: epoch 0093, iter [00910, 01251], lr: 0.001138, loss: 0.3980
2022-09-28 08:33:50 - train: epoch 0093, iter [00920, 01251], lr: 0.001138, loss: 0.4028
2022-09-28 08:34:08 - train: epoch 0093, iter [00930, 01251], lr: 0.001138, loss: 0.4192
2022-09-28 08:34:26 - train: epoch 0093, iter [00940, 01251], lr: 0.001138, loss: 0.4075
2022-09-28 08:34:44 - train: epoch 0093, iter [00950, 01251], lr: 0.001138, loss: 0.4156
2022-09-28 08:35:02 - train: epoch 0093, iter [00960, 01251], lr: 0.001138, loss: 0.4170
2022-09-28 08:35:21 - train: epoch 0093, iter [00970, 01251], lr: 0.001137, loss: 0.4171
2022-09-28 08:35:38 - train: epoch 0093, iter [00980, 01251], lr: 0.001137, loss: 0.4151
2022-09-28 08:35:57 - train: epoch 0093, iter [00990, 01251], lr: 0.001137, loss: 0.4046
2022-09-28 08:36:15 - train: epoch 0093, iter [01000, 01251], lr: 0.001137, loss: 0.4049
2022-09-28 08:36:33 - train: epoch 0093, iter [01010, 01251], lr: 0.001137, loss: 0.4294
2022-09-28 08:36:52 - train: epoch 0093, iter [01020, 01251], lr: 0.001137, loss: 0.4239
2022-09-28 08:37:10 - train: epoch 0093, iter [01030, 01251], lr: 0.001137, loss: 0.4234
2022-09-28 08:37:28 - train: epoch 0093, iter [01040, 01251], lr: 0.001137, loss: 0.4149
2022-09-28 08:37:46 - train: epoch 0093, iter [01050, 01251], lr: 0.001137, loss: 0.4169
2022-09-28 08:38:05 - train: epoch 0093, iter [01060, 01251], lr: 0.001137, loss: 0.4272
2022-09-28 08:38:23 - train: epoch 0093, iter [01070, 01251], lr: 0.001137, loss: 0.4073
2022-09-28 08:38:41 - train: epoch 0093, iter [01080, 01251], lr: 0.001137, loss: 0.4027
2022-09-28 08:38:59 - train: epoch 0093, iter [01090, 01251], lr: 0.001137, loss: 0.4233
2022-09-28 08:39:18 - train: epoch 0093, iter [01100, 01251], lr: 0.001137, loss: 0.4329
2022-09-28 08:39:35 - train: epoch 0093, iter [01110, 01251], lr: 0.001137, loss: 0.4236
2022-09-28 08:39:54 - train: epoch 0093, iter [01120, 01251], lr: 0.001137, loss: 0.4125
2022-09-28 08:40:11 - train: epoch 0093, iter [01130, 01251], lr: 0.001137, loss: 0.4017
2022-09-28 08:40:30 - train: epoch 0093, iter [01140, 01251], lr: 0.001137, loss: 0.4077
2022-09-28 08:40:48 - train: epoch 0093, iter [01150, 01251], lr: 0.001137, loss: 0.4404
2022-09-28 08:41:06 - train: epoch 0093, iter [01160, 01251], lr: 0.001137, loss: 0.4139
2022-09-28 08:41:24 - train: epoch 0093, iter [01170, 01251], lr: 0.001137, loss: 0.4166
2022-09-28 08:41:43 - train: epoch 0093, iter [01180, 01251], lr: 0.001137, loss: 0.4174
2022-09-28 08:42:01 - train: epoch 0093, iter [01190, 01251], lr: 0.001137, loss: 0.4363
2022-09-28 08:42:19 - train: epoch 0093, iter [01200, 01251], lr: 0.001137, loss: 0.4020
2022-09-28 08:42:37 - train: epoch 0093, iter [01210, 01251], lr: 0.001137, loss: 0.3961
2022-09-28 08:42:55 - train: epoch 0093, iter [01220, 01251], lr: 0.001137, loss: 0.3935
2022-09-28 08:43:14 - train: epoch 0093, iter [01230, 01251], lr: 0.001137, loss: 0.4119
2022-09-28 08:43:32 - train: epoch 0093, iter [01240, 01251], lr: 0.001137, loss: 0.3953
2022-09-28 08:43:49 - train: epoch 0093, iter [01250, 01251], lr: 0.001137, loss: 0.3976
2022-09-28 08:43:53 - train: epoch 093, train_loss: 0.4139
2022-09-28 08:43:54 - until epoch: 093, best_loss: 0.4139
2022-09-28 08:43:54 - epoch 094 lr: 0.001137
2022-09-28 08:44:28 - train: epoch 0094, iter [00010, 01251], lr: 0.001137, loss: 0.4179
2022-09-28 08:44:45 - train: epoch 0094, iter [00020, 01251], lr: 0.001137, loss: 0.4373
2022-09-28 08:45:04 - train: epoch 0094, iter [00030, 01251], lr: 0.001137, loss: 0.4082
2022-09-28 08:45:22 - train: epoch 0094, iter [00040, 01251], lr: 0.001137, loss: 0.4108
2022-09-28 08:45:40 - train: epoch 0094, iter [00050, 01251], lr: 0.001137, loss: 0.4048
2022-09-28 08:45:58 - train: epoch 0094, iter [00060, 01251], lr: 0.001137, loss: 0.4301
2022-09-28 08:46:16 - train: epoch 0094, iter [00070, 01251], lr: 0.001137, loss: 0.4099
2022-09-28 08:46:34 - train: epoch 0094, iter [00080, 01251], lr: 0.001137, loss: 0.4251
2022-09-28 08:46:52 - train: epoch 0094, iter [00090, 01251], lr: 0.001137, loss: 0.4050
2022-09-28 08:47:11 - train: epoch 0094, iter [00100, 01251], lr: 0.001137, loss: 0.4242
2022-09-28 08:47:29 - train: epoch 0094, iter [00110, 01251], lr: 0.001137, loss: 0.4093
2022-09-28 08:47:47 - train: epoch 0094, iter [00120, 01251], lr: 0.001137, loss: 0.4314
2022-09-28 08:48:05 - train: epoch 0094, iter [00130, 01251], lr: 0.001137, loss: 0.4292
2022-09-28 08:48:23 - train: epoch 0094, iter [00140, 01251], lr: 0.001137, loss: 0.4229
2022-09-28 08:48:42 - train: epoch 0094, iter [00150, 01251], lr: 0.001137, loss: 0.3986
2022-09-28 08:49:00 - train: epoch 0094, iter [00160, 01251], lr: 0.001137, loss: 0.4008
2022-09-28 08:49:18 - train: epoch 0094, iter [00170, 01251], lr: 0.001137, loss: 0.4267
2022-09-28 08:49:36 - train: epoch 0094, iter [00180, 01251], lr: 0.001137, loss: 0.4145
2022-09-28 08:49:54 - train: epoch 0094, iter [00190, 01251], lr: 0.001137, loss: 0.4141
2022-09-28 08:50:13 - train: epoch 0094, iter [00200, 01251], lr: 0.001137, loss: 0.4163
2022-09-28 08:50:31 - train: epoch 0094, iter [00210, 01251], lr: 0.001137, loss: 0.4203
2022-09-28 08:50:49 - train: epoch 0094, iter [00220, 01251], lr: 0.001137, loss: 0.3959
2022-09-28 08:51:07 - train: epoch 0094, iter [00230, 01251], lr: 0.001137, loss: 0.4064
2022-09-28 08:51:26 - train: epoch 0094, iter [00240, 01251], lr: 0.001137, loss: 0.4420
2022-09-28 08:51:44 - train: epoch 0094, iter [00250, 01251], lr: 0.001136, loss: 0.4099
2022-09-28 08:52:02 - train: epoch 0094, iter [00260, 01251], lr: 0.001136, loss: 0.4105
2022-09-28 08:52:20 - train: epoch 0094, iter [00270, 01251], lr: 0.001136, loss: 0.3978
2022-09-28 08:52:39 - train: epoch 0094, iter [00280, 01251], lr: 0.001136, loss: 0.3996
2022-09-28 08:52:57 - train: epoch 0094, iter [00290, 01251], lr: 0.001136, loss: 0.4120
2022-09-28 08:53:15 - train: epoch 0094, iter [00300, 01251], lr: 0.001136, loss: 0.4035
2022-09-28 08:53:33 - train: epoch 0094, iter [00310, 01251], lr: 0.001136, loss: 0.4211
2022-09-28 08:53:51 - train: epoch 0094, iter [00320, 01251], lr: 0.001136, loss: 0.4067
2022-09-28 08:54:10 - train: epoch 0094, iter [00330, 01251], lr: 0.001136, loss: 0.4095
2022-09-28 08:54:28 - train: epoch 0094, iter [00340, 01251], lr: 0.001136, loss: 0.3949
2022-09-28 08:54:46 - train: epoch 0094, iter [00350, 01251], lr: 0.001136, loss: 0.4086
2022-09-28 08:55:04 - train: epoch 0094, iter [00360, 01251], lr: 0.001136, loss: 0.4065
2022-09-28 08:55:22 - train: epoch 0094, iter [00370, 01251], lr: 0.001136, loss: 0.4291
2022-09-28 08:55:40 - train: epoch 0094, iter [00380, 01251], lr: 0.001136, loss: 0.4144
2022-09-28 08:55:58 - train: epoch 0094, iter [00390, 01251], lr: 0.001136, loss: 0.4299
2022-09-28 08:56:16 - train: epoch 0094, iter [00400, 01251], lr: 0.001136, loss: 0.4218
2022-09-28 08:56:34 - train: epoch 0094, iter [00410, 01251], lr: 0.001136, loss: 0.4276
2022-09-28 08:56:52 - train: epoch 0094, iter [00420, 01251], lr: 0.001136, loss: 0.4085
2022-09-28 08:57:10 - train: epoch 0094, iter [00430, 01251], lr: 0.001136, loss: 0.3899
2022-09-28 08:57:28 - train: epoch 0094, iter [00440, 01251], lr: 0.001136, loss: 0.4083
2022-09-28 08:57:45 - train: epoch 0094, iter [00450, 01251], lr: 0.001136, loss: 0.4170
2022-09-28 08:58:03 - train: epoch 0094, iter [00460, 01251], lr: 0.001136, loss: 0.4189
2022-09-28 08:58:21 - train: epoch 0094, iter [00470, 01251], lr: 0.001136, loss: 0.4177
2022-09-28 08:58:39 - train: epoch 0094, iter [00480, 01251], lr: 0.001136, loss: 0.4213
2022-09-28 08:58:57 - train: epoch 0094, iter [00490, 01251], lr: 0.001136, loss: 0.4027
2022-09-28 08:59:15 - train: epoch 0094, iter [00500, 01251], lr: 0.001136, loss: 0.4321
2022-09-28 08:59:33 - train: epoch 0094, iter [00510, 01251], lr: 0.001136, loss: 0.4009
2022-09-28 08:59:51 - train: epoch 0094, iter [00520, 01251], lr: 0.001136, loss: 0.4320
2022-09-28 09:00:08 - train: epoch 0094, iter [00530, 01251], lr: 0.001136, loss: 0.4022
2022-09-28 09:00:26 - train: epoch 0094, iter [00540, 01251], lr: 0.001136, loss: 0.4251
2022-09-28 09:00:44 - train: epoch 0094, iter [00550, 01251], lr: 0.001136, loss: 0.4176
2022-09-28 09:01:02 - train: epoch 0094, iter [00560, 01251], lr: 0.001136, loss: 0.4062
2022-09-28 09:01:20 - train: epoch 0094, iter [00570, 01251], lr: 0.001136, loss: 0.4211
2022-09-28 09:01:38 - train: epoch 0094, iter [00580, 01251], lr: 0.001136, loss: 0.4141
2022-09-28 09:01:56 - train: epoch 0094, iter [00590, 01251], lr: 0.001136, loss: 0.3933
2022-09-28 09:02:14 - train: epoch 0094, iter [00600, 01251], lr: 0.001136, loss: 0.4181
2022-09-28 09:02:32 - train: epoch 0094, iter [00610, 01251], lr: 0.001136, loss: 0.4012
2022-09-28 09:02:50 - train: epoch 0094, iter [00620, 01251], lr: 0.001136, loss: 0.4152
2022-09-28 09:03:08 - train: epoch 0094, iter [00630, 01251], lr: 0.001136, loss: 0.4091
2022-09-28 09:03:26 - train: epoch 0094, iter [00640, 01251], lr: 0.001136, loss: 0.4194
2022-09-28 09:03:44 - train: epoch 0094, iter [00650, 01251], lr: 0.001136, loss: 0.4208
2022-09-28 09:04:02 - train: epoch 0094, iter [00660, 01251], lr: 0.001136, loss: 0.4112
2022-09-28 09:04:20 - train: epoch 0094, iter [00670, 01251], lr: 0.001136, loss: 0.4169
2022-09-28 09:04:38 - train: epoch 0094, iter [00680, 01251], lr: 0.001136, loss: 0.4054
2022-09-28 09:04:56 - train: epoch 0094, iter [00690, 01251], lr: 0.001136, loss: 0.4257
2022-09-28 09:05:14 - train: epoch 0094, iter [00700, 01251], lr: 0.001136, loss: 0.3991
2022-09-28 09:05:32 - train: epoch 0094, iter [00710, 01251], lr: 0.001136, loss: 0.4250
2022-09-28 09:05:50 - train: epoch 0094, iter [00720, 01251], lr: 0.001136, loss: 0.4121
2022-09-28 09:06:07 - train: epoch 0094, iter [00730, 01251], lr: 0.001136, loss: 0.4093
2022-09-28 09:06:25 - train: epoch 0094, iter [00740, 01251], lr: 0.001136, loss: 0.4324
2022-09-28 09:06:43 - train: epoch 0094, iter [00750, 01251], lr: 0.001136, loss: 0.4079
2022-09-28 09:07:01 - train: epoch 0094, iter [00760, 01251], lr: 0.001136, loss: 0.4457
2022-09-28 09:07:19 - train: epoch 0094, iter [00770, 01251], lr: 0.001136, loss: 0.4146
2022-09-28 09:07:37 - train: epoch 0094, iter [00780, 01251], lr: 0.001135, loss: 0.3863
2022-09-28 09:07:55 - train: epoch 0094, iter [00790, 01251], lr: 0.001135, loss: 0.4212
2022-09-28 09:08:13 - train: epoch 0094, iter [00800, 01251], lr: 0.001135, loss: 0.4089
2022-09-28 09:08:31 - train: epoch 0094, iter [00810, 01251], lr: 0.001135, loss: 0.4141
2022-09-28 09:08:49 - train: epoch 0094, iter [00820, 01251], lr: 0.001135, loss: 0.4168
2022-09-28 09:09:07 - train: epoch 0094, iter [00830, 01251], lr: 0.001135, loss: 0.4233
2022-09-28 09:09:25 - train: epoch 0094, iter [00840, 01251], lr: 0.001135, loss: 0.3902
2022-09-28 09:09:43 - train: epoch 0094, iter [00850, 01251], lr: 0.001135, loss: 0.4217
2022-09-28 09:10:01 - train: epoch 0094, iter [00860, 01251], lr: 0.001135, loss: 0.4085
2022-09-28 09:10:19 - train: epoch 0094, iter [00870, 01251], lr: 0.001135, loss: 0.4324
2022-09-28 09:10:37 - train: epoch 0094, iter [00880, 01251], lr: 0.001135, loss: 0.4208
2022-09-28 09:10:55 - train: epoch 0094, iter [00890, 01251], lr: 0.001135, loss: 0.4280
2022-09-28 09:11:13 - train: epoch 0094, iter [00900, 01251], lr: 0.001135, loss: 0.4007
2022-09-28 09:11:31 - train: epoch 0094, iter [00910, 01251], lr: 0.001135, loss: 0.4099
2022-09-28 09:11:49 - train: epoch 0094, iter [00920, 01251], lr: 0.001135, loss: 0.4327
2022-09-28 09:12:07 - train: epoch 0094, iter [00930, 01251], lr: 0.001135, loss: 0.4059
2022-09-28 09:12:25 - train: epoch 0094, iter [00940, 01251], lr: 0.001135, loss: 0.4106
2022-09-28 09:12:42 - train: epoch 0094, iter [00950, 01251], lr: 0.001135, loss: 0.4236
2022-09-28 09:13:01 - train: epoch 0094, iter [00960, 01251], lr: 0.001135, loss: 0.4291
2022-09-28 09:13:18 - train: epoch 0094, iter [00970, 01251], lr: 0.001135, loss: 0.4191
2022-09-28 09:13:36 - train: epoch 0094, iter [00980, 01251], lr: 0.001135, loss: 0.4001
2022-09-28 09:13:54 - train: epoch 0094, iter [00990, 01251], lr: 0.001135, loss: 0.4108
2022-09-28 09:14:12 - train: epoch 0094, iter [01000, 01251], lr: 0.001135, loss: 0.3937
2022-09-28 09:14:30 - train: epoch 0094, iter [01010, 01251], lr: 0.001135, loss: 0.4161
2022-09-28 09:14:48 - train: epoch 0094, iter [01020, 01251], lr: 0.001135, loss: 0.4179
2022-09-28 09:15:06 - train: epoch 0094, iter [01030, 01251], lr: 0.001135, loss: 0.4283
2022-09-28 09:15:24 - train: epoch 0094, iter [01040, 01251], lr: 0.001135, loss: 0.4249
2022-09-28 09:15:42 - train: epoch 0094, iter [01050, 01251], lr: 0.001135, loss: 0.4136
2022-09-28 09:16:00 - train: epoch 0094, iter [01060, 01251], lr: 0.001135, loss: 0.4159
2022-09-28 09:16:18 - train: epoch 0094, iter [01070, 01251], lr: 0.001135, loss: 0.4125
2022-09-28 09:16:36 - train: epoch 0094, iter [01080, 01251], lr: 0.001135, loss: 0.4063
2022-09-28 09:16:54 - train: epoch 0094, iter [01090, 01251], lr: 0.001135, loss: 0.4118
2022-09-28 09:17:12 - train: epoch 0094, iter [01100, 01251], lr: 0.001135, loss: 0.4089
2022-09-28 09:17:29 - train: epoch 0094, iter [01110, 01251], lr: 0.001135, loss: 0.4267
2022-09-28 09:17:47 - train: epoch 0094, iter [01120, 01251], lr: 0.001135, loss: 0.4174
2022-09-28 09:18:05 - train: epoch 0094, iter [01130, 01251], lr: 0.001135, loss: 0.4181
2022-09-28 09:18:24 - train: epoch 0094, iter [01140, 01251], lr: 0.001135, loss: 0.4029
2022-09-28 09:18:41 - train: epoch 0094, iter [01150, 01251], lr: 0.001135, loss: 0.4127
2022-09-28 09:18:59 - train: epoch 0094, iter [01160, 01251], lr: 0.001135, loss: 0.4137
2022-09-28 09:19:17 - train: epoch 0094, iter [01170, 01251], lr: 0.001135, loss: 0.4195
2022-09-28 09:19:35 - train: epoch 0094, iter [01180, 01251], lr: 0.001135, loss: 0.4095
2022-09-28 09:19:53 - train: epoch 0094, iter [01190, 01251], lr: 0.001135, loss: 0.4143
2022-09-28 09:20:11 - train: epoch 0094, iter [01200, 01251], lr: 0.001135, loss: 0.4038
2022-09-28 09:20:29 - train: epoch 0094, iter [01210, 01251], lr: 0.001135, loss: 0.4060
2022-09-28 09:20:47 - train: epoch 0094, iter [01220, 01251], lr: 0.001135, loss: 0.4046
2022-09-28 09:21:05 - train: epoch 0094, iter [01230, 01251], lr: 0.001135, loss: 0.4085
2022-09-28 09:21:23 - train: epoch 0094, iter [01240, 01251], lr: 0.001135, loss: 0.4093
2022-09-28 09:21:40 - train: epoch 0094, iter [01250, 01251], lr: 0.001135, loss: 0.4260
2022-09-28 09:21:43 - train: epoch 094, train_loss: 0.4138
2022-09-28 09:21:46 - until epoch: 094, best_loss: 0.4138
2022-09-28 09:21:46 - epoch 095 lr: 0.001135
2022-09-28 09:22:19 - train: epoch 0095, iter [00010, 01251], lr: 0.001135, loss: 0.4153
2022-09-28 09:22:37 - train: epoch 0095, iter [00020, 01251], lr: 0.001135, loss: 0.4027
2022-09-28 09:22:55 - train: epoch 0095, iter [00030, 01251], lr: 0.001135, loss: 0.3964
2022-09-28 09:23:12 - train: epoch 0095, iter [00040, 01251], lr: 0.001135, loss: 0.3952
2022-09-28 09:23:30 - train: epoch 0095, iter [00050, 01251], lr: 0.001135, loss: 0.4106
2022-09-28 09:23:48 - train: epoch 0095, iter [00060, 01251], lr: 0.001134, loss: 0.4244
2022-09-28 09:24:06 - train: epoch 0095, iter [00070, 01251], lr: 0.001134, loss: 0.4152
2022-09-28 09:24:24 - train: epoch 0095, iter [00080, 01251], lr: 0.001134, loss: 0.3995
2022-09-28 09:24:42 - train: epoch 0095, iter [00090, 01251], lr: 0.001134, loss: 0.3865
2022-09-28 09:24:59 - train: epoch 0095, iter [00100, 01251], lr: 0.001134, loss: 0.4101
2022-09-28 09:25:17 - train: epoch 0095, iter [00110, 01251], lr: 0.001134, loss: 0.4329
2022-09-28 09:25:35 - train: epoch 0095, iter [00120, 01251], lr: 0.001134, loss: 0.4024
2022-09-28 09:25:53 - train: epoch 0095, iter [00130, 01251], lr: 0.001134, loss: 0.4169
2022-09-28 09:26:11 - train: epoch 0095, iter [00140, 01251], lr: 0.001134, loss: 0.3974
2022-09-28 09:26:28 - train: epoch 0095, iter [00150, 01251], lr: 0.001134, loss: 0.4360
2022-09-28 09:26:47 - train: epoch 0095, iter [00160, 01251], lr: 0.001134, loss: 0.4185
2022-09-28 09:27:04 - train: epoch 0095, iter [00170, 01251], lr: 0.001134, loss: 0.4363
2022-09-28 09:27:22 - train: epoch 0095, iter [00180, 01251], lr: 0.001134, loss: 0.4003
2022-09-28 09:27:40 - train: epoch 0095, iter [00190, 01251], lr: 0.001134, loss: 0.4142
2022-09-28 09:27:58 - train: epoch 0095, iter [00200, 01251], lr: 0.001134, loss: 0.4306
2022-09-28 09:28:16 - train: epoch 0095, iter [00210, 01251], lr: 0.001134, loss: 0.4067
2022-09-28 09:28:34 - train: epoch 0095, iter [00220, 01251], lr: 0.001134, loss: 0.3928
2022-09-28 09:28:52 - train: epoch 0095, iter [00230, 01251], lr: 0.001134, loss: 0.4165
2022-09-28 09:29:10 - train: epoch 0095, iter [00240, 01251], lr: 0.001134, loss: 0.4156
2022-09-28 09:29:28 - train: epoch 0095, iter [00250, 01251], lr: 0.001134, loss: 0.4077
2022-09-28 09:29:46 - train: epoch 0095, iter [00260, 01251], lr: 0.001134, loss: 0.4123
2022-09-28 09:30:03 - train: epoch 0095, iter [00270, 01251], lr: 0.001134, loss: 0.4035
2022-09-28 09:30:21 - train: epoch 0095, iter [00280, 01251], lr: 0.001134, loss: 0.4358
2022-09-28 09:30:39 - train: epoch 0095, iter [00290, 01251], lr: 0.001134, loss: 0.4089
2022-09-28 09:30:57 - train: epoch 0095, iter [00300, 01251], lr: 0.001134, loss: 0.4167
2022-09-28 09:31:15 - train: epoch 0095, iter [00310, 01251], lr: 0.001134, loss: 0.4062
2022-09-28 09:31:32 - train: epoch 0095, iter [00320, 01251], lr: 0.001134, loss: 0.4117
2022-09-28 09:31:50 - train: epoch 0095, iter [00330, 01251], lr: 0.001134, loss: 0.4144
2022-09-28 09:32:08 - train: epoch 0095, iter [00340, 01251], lr: 0.001134, loss: 0.4121
2022-09-28 09:32:26 - train: epoch 0095, iter [00350, 01251], lr: 0.001134, loss: 0.4071
2022-09-28 09:32:44 - train: epoch 0095, iter [00360, 01251], lr: 0.001134, loss: 0.4142
2022-09-28 09:33:01 - train: epoch 0095, iter [00370, 01251], lr: 0.001134, loss: 0.4297
2022-09-28 09:33:19 - train: epoch 0095, iter [00380, 01251], lr: 0.001134, loss: 0.4296
2022-09-28 09:33:37 - train: epoch 0095, iter [00390, 01251], lr: 0.001134, loss: 0.4123
2022-09-28 09:33:55 - train: epoch 0095, iter [00400, 01251], lr: 0.001134, loss: 0.4271
2022-09-28 09:34:13 - train: epoch 0095, iter [00410, 01251], lr: 0.001134, loss: 0.3838
2022-09-28 09:34:31 - train: epoch 0095, iter [00420, 01251], lr: 0.001134, loss: 0.4126
2022-09-28 09:34:49 - train: epoch 0095, iter [00430, 01251], lr: 0.001134, loss: 0.4106
2022-09-28 09:35:07 - train: epoch 0095, iter [00440, 01251], lr: 0.001134, loss: 0.3913
2022-09-28 09:35:25 - train: epoch 0095, iter [00450, 01251], lr: 0.001134, loss: 0.4134
2022-09-28 09:35:43 - train: epoch 0095, iter [00460, 01251], lr: 0.001134, loss: 0.4364
2022-09-28 09:36:01 - train: epoch 0095, iter [00470, 01251], lr: 0.001134, loss: 0.4077
2022-09-28 09:36:18 - train: epoch 0095, iter [00480, 01251], lr: 0.001134, loss: 0.4103
2022-09-28 09:36:36 - train: epoch 0095, iter [00490, 01251], lr: 0.001134, loss: 0.3886
2022-09-28 09:36:54 - train: epoch 0095, iter [00500, 01251], lr: 0.001134, loss: 0.4004
2022-09-28 09:37:12 - train: epoch 0095, iter [00510, 01251], lr: 0.001134, loss: 0.4122
2022-09-28 09:37:30 - train: epoch 0095, iter [00520, 01251], lr: 0.001134, loss: 0.4102
2022-09-28 09:37:47 - train: epoch 0095, iter [00530, 01251], lr: 0.001134, loss: 0.4068
2022-09-28 09:38:05 - train: epoch 0095, iter [00540, 01251], lr: 0.001134, loss: 0.4075
2022-09-28 09:38:23 - train: epoch 0095, iter [00550, 01251], lr: 0.001134, loss: 0.4236
2022-09-28 09:38:41 - train: epoch 0095, iter [00560, 01251], lr: 0.001134, loss: 0.4008
2022-09-28 09:38:59 - train: epoch 0095, iter [00570, 01251], lr: 0.001134, loss: 0.4243
2022-09-28 09:39:17 - train: epoch 0095, iter [00580, 01251], lr: 0.001133, loss: 0.4142
2022-09-28 09:39:35 - train: epoch 0095, iter [00590, 01251], lr: 0.001133, loss: 0.4150
2022-09-28 09:39:53 - train: epoch 0095, iter [00600, 01251], lr: 0.001133, loss: 0.4347
2022-09-28 09:40:11 - train: epoch 0095, iter [00610, 01251], lr: 0.001133, loss: 0.3928
2022-09-28 09:40:28 - train: epoch 0095, iter [00620, 01251], lr: 0.001133, loss: 0.4281
2022-09-28 09:40:46 - train: epoch 0095, iter [00630, 01251], lr: 0.001133, loss: 0.4283
2022-09-28 09:41:04 - train: epoch 0095, iter [00640, 01251], lr: 0.001133, loss: 0.4196
2022-09-28 09:41:22 - train: epoch 0095, iter [00650, 01251], lr: 0.001133, loss: 0.4178
2022-09-28 09:41:40 - train: epoch 0095, iter [00660, 01251], lr: 0.001133, loss: 0.4211
2022-09-28 09:41:58 - train: epoch 0095, iter [00670, 01251], lr: 0.001133, loss: 0.4313
2022-09-28 09:42:16 - train: epoch 0095, iter [00680, 01251], lr: 0.001133, loss: 0.4265
2022-09-28 09:42:34 - train: epoch 0095, iter [00690, 01251], lr: 0.001133, loss: 0.3947
2022-09-28 09:42:52 - train: epoch 0095, iter [00700, 01251], lr: 0.001133, loss: 0.4092
2022-09-28 09:43:10 - train: epoch 0095, iter [00710, 01251], lr: 0.001133, loss: 0.4216
2022-09-28 09:43:28 - train: epoch 0095, iter [00720, 01251], lr: 0.001133, loss: 0.4155
2022-09-28 09:43:46 - train: epoch 0095, iter [00730, 01251], lr: 0.001133, loss: 0.4207
2022-09-28 09:44:04 - train: epoch 0095, iter [00740, 01251], lr: 0.001133, loss: 0.3986
2022-09-28 09:44:21 - train: epoch 0095, iter [00750, 01251], lr: 0.001133, loss: 0.4072
2022-09-28 09:44:39 - train: epoch 0095, iter [00760, 01251], lr: 0.001133, loss: 0.4042
2022-09-28 09:44:57 - train: epoch 0095, iter [00770, 01251], lr: 0.001133, loss: 0.4061
2022-09-28 09:45:15 - train: epoch 0095, iter [00780, 01251], lr: 0.001133, loss: 0.4032
2022-09-28 09:45:33 - train: epoch 0095, iter [00790, 01251], lr: 0.001133, loss: 0.3974
2022-09-28 09:45:51 - train: epoch 0095, iter [00800, 01251], lr: 0.001133, loss: 0.4291
2022-09-28 09:46:09 - train: epoch 0095, iter [00810, 01251], lr: 0.001133, loss: 0.3953
2022-09-28 09:46:26 - train: epoch 0095, iter [00820, 01251], lr: 0.001133, loss: 0.4309
2022-09-28 09:46:44 - train: epoch 0095, iter [00830, 01251], lr: 0.001133, loss: 0.4111
2022-09-28 09:47:02 - train: epoch 0095, iter [00840, 01251], lr: 0.001133, loss: 0.4190
2022-09-28 09:47:20 - train: epoch 0095, iter [00850, 01251], lr: 0.001133, loss: 0.4131
2022-09-28 09:47:37 - train: epoch 0095, iter [00860, 01251], lr: 0.001133, loss: 0.4232
2022-09-28 09:47:55 - train: epoch 0095, iter [00870, 01251], lr: 0.001133, loss: 0.3891
2022-09-28 09:48:13 - train: epoch 0095, iter [00880, 01251], lr: 0.001133, loss: 0.4067
2022-09-28 09:48:31 - train: epoch 0095, iter [00890, 01251], lr: 0.001133, loss: 0.4059
2022-09-28 09:48:49 - train: epoch 0095, iter [00900, 01251], lr: 0.001133, loss: 0.4239
2022-09-28 09:49:07 - train: epoch 0095, iter [00910, 01251], lr: 0.001133, loss: 0.4040
2022-09-28 09:49:25 - train: epoch 0095, iter [00920, 01251], lr: 0.001133, loss: 0.4303
2022-09-28 09:49:43 - train: epoch 0095, iter [00930, 01251], lr: 0.001133, loss: 0.4141
2022-09-28 09:50:01 - train: epoch 0095, iter [00940, 01251], lr: 0.001133, loss: 0.4052
2022-09-28 09:50:18 - train: epoch 0095, iter [00950, 01251], lr: 0.001133, loss: 0.4208
2022-09-28 09:50:36 - train: epoch 0095, iter [00960, 01251], lr: 0.001133, loss: 0.4109
2022-09-28 09:50:54 - train: epoch 0095, iter [00970, 01251], lr: 0.001133, loss: 0.4249
2022-09-28 09:51:12 - train: epoch 0095, iter [00980, 01251], lr: 0.001133, loss: 0.4205
2022-09-28 09:51:30 - train: epoch 0095, iter [00990, 01251], lr: 0.001133, loss: 0.4011
2022-09-28 09:51:47 - train: epoch 0095, iter [01000, 01251], lr: 0.001133, loss: 0.4003
2022-09-28 09:52:05 - train: epoch 0095, iter [01010, 01251], lr: 0.001133, loss: 0.4281
2022-09-28 09:52:23 - train: epoch 0095, iter [01020, 01251], lr: 0.001133, loss: 0.4293
2022-09-28 09:52:41 - train: epoch 0095, iter [01030, 01251], lr: 0.001133, loss: 0.4003
2022-09-28 09:52:59 - train: epoch 0095, iter [01040, 01251], lr: 0.001133, loss: 0.4108
2022-09-28 09:53:17 - train: epoch 0095, iter [01050, 01251], lr: 0.001133, loss: 0.4224
2022-09-28 09:53:35 - train: epoch 0095, iter [01060, 01251], lr: 0.001133, loss: 0.4094
2022-09-28 09:53:53 - train: epoch 0095, iter [01070, 01251], lr: 0.001133, loss: 0.4113
2022-09-28 09:54:11 - train: epoch 0095, iter [01080, 01251], lr: 0.001133, loss: 0.4117
2022-09-28 09:54:29 - train: epoch 0095, iter [01090, 01251], lr: 0.001133, loss: 0.4168
2022-09-28 09:54:47 - train: epoch 0095, iter [01100, 01251], lr: 0.001132, loss: 0.4119
2022-09-28 09:55:04 - train: epoch 0095, iter [01110, 01251], lr: 0.001132, loss: 0.4066
2022-09-28 09:55:22 - train: epoch 0095, iter [01120, 01251], lr: 0.001132, loss: 0.4291
2022-09-28 09:55:40 - train: epoch 0095, iter [01130, 01251], lr: 0.001132, loss: 0.4230
2022-09-28 09:55:58 - train: epoch 0095, iter [01140, 01251], lr: 0.001132, loss: 0.4122
2022-09-28 09:56:16 - train: epoch 0095, iter [01150, 01251], lr: 0.001132, loss: 0.4249
2022-09-28 09:56:34 - train: epoch 0095, iter [01160, 01251], lr: 0.001132, loss: 0.4027
2022-09-28 09:56:52 - train: epoch 0095, iter [01170, 01251], lr: 0.001132, loss: 0.4387
2022-09-28 09:57:10 - train: epoch 0095, iter [01180, 01251], lr: 0.001132, loss: 0.4250
2022-09-28 09:57:28 - train: epoch 0095, iter [01190, 01251], lr: 0.001132, loss: 0.4267
2022-09-28 09:57:46 - train: epoch 0095, iter [01200, 01251], lr: 0.001132, loss: 0.4057
2022-09-28 09:58:04 - train: epoch 0095, iter [01210, 01251], lr: 0.001132, loss: 0.4206
2022-09-28 09:58:22 - train: epoch 0095, iter [01220, 01251], lr: 0.001132, loss: 0.3988
2022-09-28 09:58:39 - train: epoch 0095, iter [01230, 01251], lr: 0.001132, loss: 0.3943
2022-09-28 09:58:57 - train: epoch 0095, iter [01240, 01251], lr: 0.001132, loss: 0.4252
2022-09-28 09:59:14 - train: epoch 0095, iter [01250, 01251], lr: 0.001132, loss: 0.3761
2022-09-28 09:59:18 - train: epoch 095, train_loss: 0.4137
2022-09-28 09:59:20 - until epoch: 095, best_loss: 0.4137
2022-09-28 09:59:20 - epoch 096 lr: 0.001132
2022-09-28 09:59:53 - train: epoch 0096, iter [00010, 01251], lr: 0.001132, loss: 0.4131
2022-09-28 10:00:11 - train: epoch 0096, iter [00020, 01251], lr: 0.001132, loss: 0.4160
2022-09-28 10:00:29 - train: epoch 0096, iter [00030, 01251], lr: 0.001132, loss: 0.4081
2022-09-28 10:00:47 - train: epoch 0096, iter [00040, 01251], lr: 0.001132, loss: 0.4365
2022-09-28 10:01:05 - train: epoch 0096, iter [00050, 01251], lr: 0.001132, loss: 0.4144
2022-09-28 10:01:23 - train: epoch 0096, iter [00060, 01251], lr: 0.001132, loss: 0.4130
2022-09-28 10:01:41 - train: epoch 0096, iter [00070, 01251], lr: 0.001132, loss: 0.3986
2022-09-28 10:01:59 - train: epoch 0096, iter [00080, 01251], lr: 0.001132, loss: 0.4081
2022-09-28 10:02:17 - train: epoch 0096, iter [00090, 01251], lr: 0.001132, loss: 0.4201
2022-09-28 10:02:35 - train: epoch 0096, iter [00100, 01251], lr: 0.001132, loss: 0.4041
2022-09-28 10:02:53 - train: epoch 0096, iter [00110, 01251], lr: 0.001132, loss: 0.4261
2022-09-28 10:03:11 - train: epoch 0096, iter [00120, 01251], lr: 0.001132, loss: 0.4024
2022-09-28 10:03:29 - train: epoch 0096, iter [00130, 01251], lr: 0.001132, loss: 0.3941
2022-09-28 10:03:47 - train: epoch 0096, iter [00140, 01251], lr: 0.001132, loss: 0.3922
2022-09-28 10:04:05 - train: epoch 0096, iter [00150, 01251], lr: 0.001132, loss: 0.4058
2022-09-28 10:04:23 - train: epoch 0096, iter [00160, 01251], lr: 0.001132, loss: 0.4127
2022-09-28 10:04:41 - train: epoch 0096, iter [00170, 01251], lr: 0.001132, loss: 0.3873
2022-09-28 10:04:59 - train: epoch 0096, iter [00180, 01251], lr: 0.001132, loss: 0.4188
2022-09-28 10:05:17 - train: epoch 0096, iter [00190, 01251], lr: 0.001132, loss: 0.4265
2022-09-28 10:05:35 - train: epoch 0096, iter [00200, 01251], lr: 0.001132, loss: 0.4146
2022-09-28 10:05:53 - train: epoch 0096, iter [00210, 01251], lr: 0.001132, loss: 0.4045
2022-09-28 10:06:11 - train: epoch 0096, iter [00220, 01251], lr: 0.001132, loss: 0.4277
2022-09-28 10:06:29 - train: epoch 0096, iter [00230, 01251], lr: 0.001132, loss: 0.4456
2022-09-28 10:06:47 - train: epoch 0096, iter [00240, 01251], lr: 0.001132, loss: 0.3994
2022-09-28 10:07:05 - train: epoch 0096, iter [00250, 01251], lr: 0.001132, loss: 0.4085
2022-09-28 10:07:23 - train: epoch 0096, iter [00260, 01251], lr: 0.001132, loss: 0.4056
2022-09-28 10:07:41 - train: epoch 0096, iter [00270, 01251], lr: 0.001132, loss: 0.4095
2022-09-28 10:07:59 - train: epoch 0096, iter [00280, 01251], lr: 0.001132, loss: 0.4071
2022-09-28 10:08:17 - train: epoch 0096, iter [00290, 01251], lr: 0.001132, loss: 0.4035
2022-09-28 10:08:36 - train: epoch 0096, iter [00300, 01251], lr: 0.001132, loss: 0.4165
2022-09-28 10:08:54 - train: epoch 0096, iter [00310, 01251], lr: 0.001132, loss: 0.4025
2022-09-28 10:09:12 - train: epoch 0096, iter [00320, 01251], lr: 0.001132, loss: 0.4225
2022-09-28 10:09:30 - train: epoch 0096, iter [00330, 01251], lr: 0.001132, loss: 0.4122
2022-09-28 10:09:49 - train: epoch 0096, iter [00340, 01251], lr: 0.001132, loss: 0.4110
2022-09-28 10:10:07 - train: epoch 0096, iter [00350, 01251], lr: 0.001132, loss: 0.4167
2022-09-28 10:10:25 - train: epoch 0096, iter [00360, 01251], lr: 0.001132, loss: 0.3934
2022-09-28 10:10:43 - train: epoch 0096, iter [00370, 01251], lr: 0.001131, loss: 0.4104
2022-09-28 10:11:01 - train: epoch 0096, iter [00380, 01251], lr: 0.001131, loss: 0.4402
2022-09-28 10:11:19 - train: epoch 0096, iter [00390, 01251], lr: 0.001131, loss: 0.4163
2022-09-28 10:11:37 - train: epoch 0096, iter [00400, 01251], lr: 0.001131, loss: 0.4265
2022-09-28 10:11:55 - train: epoch 0096, iter [00410, 01251], lr: 0.001131, loss: 0.4132
2022-09-28 10:12:13 - train: epoch 0096, iter [00420, 01251], lr: 0.001131, loss: 0.4257
2022-09-28 10:12:31 - train: epoch 0096, iter [00430, 01251], lr: 0.001131, loss: 0.4140
2022-09-28 10:12:50 - train: epoch 0096, iter [00440, 01251], lr: 0.001131, loss: 0.4147
2022-09-28 10:13:08 - train: epoch 0096, iter [00450, 01251], lr: 0.001131, loss: 0.4015
2022-09-28 10:13:26 - train: epoch 0096, iter [00460, 01251], lr: 0.001131, loss: 0.4091
2022-09-28 10:13:44 - train: epoch 0096, iter [00470, 01251], lr: 0.001131, loss: 0.4212
2022-09-28 10:14:03 - train: epoch 0096, iter [00480, 01251], lr: 0.001131, loss: 0.3997
2022-09-28 10:14:21 - train: epoch 0096, iter [00490, 01251], lr: 0.001131, loss: 0.4105
2022-09-28 10:14:39 - train: epoch 0096, iter [00500, 01251], lr: 0.001131, loss: 0.4040
2022-09-28 10:14:58 - train: epoch 0096, iter [00510, 01251], lr: 0.001131, loss: 0.4167
2022-09-28 10:15:16 - train: epoch 0096, iter [00520, 01251], lr: 0.001131, loss: 0.4113
2022-09-28 10:15:34 - train: epoch 0096, iter [00530, 01251], lr: 0.001131, loss: 0.4182
2022-09-28 10:15:52 - train: epoch 0096, iter [00540, 01251], lr: 0.001131, loss: 0.4347
2022-09-28 10:16:10 - train: epoch 0096, iter [00550, 01251], lr: 0.001131, loss: 0.4022
2022-09-28 10:16:28 - train: epoch 0096, iter [00560, 01251], lr: 0.001131, loss: 0.4338
2022-09-28 10:16:46 - train: epoch 0096, iter [00570, 01251], lr: 0.001131, loss: 0.4066
2022-09-28 10:17:04 - train: epoch 0096, iter [00580, 01251], lr: 0.001131, loss: 0.4350
2022-09-28 10:17:22 - train: epoch 0096, iter [00590, 01251], lr: 0.001131, loss: 0.4147
2022-09-28 10:17:40 - train: epoch 0096, iter [00600, 01251], lr: 0.001131, loss: 0.4390
2022-09-28 10:17:59 - train: epoch 0096, iter [00610, 01251], lr: 0.001131, loss: 0.4133
2022-09-28 10:18:16 - train: epoch 0096, iter [00620, 01251], lr: 0.001131, loss: 0.3951
2022-09-28 10:18:35 - train: epoch 0096, iter [00630, 01251], lr: 0.001131, loss: 0.4125
2022-09-28 10:18:53 - train: epoch 0096, iter [00640, 01251], lr: 0.001131, loss: 0.4175
2022-09-28 10:19:11 - train: epoch 0096, iter [00650, 01251], lr: 0.001131, loss: 0.4088
2022-09-28 10:19:29 - train: epoch 0096, iter [00660, 01251], lr: 0.001131, loss: 0.4022
2022-09-28 10:19:48 - train: epoch 0096, iter [00670, 01251], lr: 0.001131, loss: 0.4079
2022-09-28 10:20:06 - train: epoch 0096, iter [00680, 01251], lr: 0.001131, loss: 0.4310
2022-09-28 10:20:24 - train: epoch 0096, iter [00690, 01251], lr: 0.001131, loss: 0.4205
2022-09-28 10:20:43 - train: epoch 0096, iter [00700, 01251], lr: 0.001131, loss: 0.4044
2022-09-28 10:21:01 - train: epoch 0096, iter [00710, 01251], lr: 0.001131, loss: 0.4098
2022-09-28 10:21:20 - train: epoch 0096, iter [00720, 01251], lr: 0.001131, loss: 0.4115
2022-09-28 10:21:38 - train: epoch 0096, iter [00730, 01251], lr: 0.001131, loss: 0.3856
2022-09-28 10:21:56 - train: epoch 0096, iter [00740, 01251], lr: 0.001131, loss: 0.4128
2022-09-28 10:22:14 - train: epoch 0096, iter [00750, 01251], lr: 0.001131, loss: 0.4179
2022-09-28 10:22:32 - train: epoch 0096, iter [00760, 01251], lr: 0.001131, loss: 0.4176
2022-09-28 10:22:51 - train: epoch 0096, iter [00770, 01251], lr: 0.001131, loss: 0.4270
2022-09-28 10:23:09 - train: epoch 0096, iter [00780, 01251], lr: 0.001131, loss: 0.4142
2022-09-28 10:23:27 - train: epoch 0096, iter [00790, 01251], lr: 0.001131, loss: 0.4105
2022-09-28 10:23:45 - train: epoch 0096, iter [00800, 01251], lr: 0.001131, loss: 0.4177
2022-09-28 10:24:04 - train: epoch 0096, iter [00810, 01251], lr: 0.001131, loss: 0.4108
2022-09-28 10:24:22 - train: epoch 0096, iter [00820, 01251], lr: 0.001131, loss: 0.4055
2022-09-28 10:24:41 - train: epoch 0096, iter [00830, 01251], lr: 0.001131, loss: 0.4101
2022-09-28 10:24:59 - train: epoch 0096, iter [00840, 01251], lr: 0.001131, loss: 0.4114
2022-09-28 10:25:17 - train: epoch 0096, iter [00850, 01251], lr: 0.001131, loss: 0.4192
2022-09-28 10:25:36 - train: epoch 0096, iter [00860, 01251], lr: 0.001131, loss: 0.4140
2022-09-28 10:25:54 - train: epoch 0096, iter [00870, 01251], lr: 0.001131, loss: 0.3992
2022-09-28 10:26:12 - train: epoch 0096, iter [00880, 01251], lr: 0.001130, loss: 0.4062
2022-09-28 10:26:31 - train: epoch 0096, iter [00890, 01251], lr: 0.001130, loss: 0.4307
2022-09-28 10:26:49 - train: epoch 0096, iter [00900, 01251], lr: 0.001130, loss: 0.4024
2022-09-28 10:27:07 - train: epoch 0096, iter [00910, 01251], lr: 0.001130, loss: 0.4311
2022-09-28 10:27:26 - train: epoch 0096, iter [00920, 01251], lr: 0.001130, loss: 0.3995
2022-09-28 10:27:44 - train: epoch 0096, iter [00930, 01251], lr: 0.001130, loss: 0.4193
2022-09-28 10:28:03 - train: epoch 0096, iter [00940, 01251], lr: 0.001130, loss: 0.4404
2022-09-28 10:28:21 - train: epoch 0096, iter [00950, 01251], lr: 0.001130, loss: 0.4190
2022-09-28 10:28:39 - train: epoch 0096, iter [00960, 01251], lr: 0.001130, loss: 0.4390
2022-09-28 10:28:57 - train: epoch 0096, iter [00970, 01251], lr: 0.001130, loss: 0.3993
2022-09-28 10:29:15 - train: epoch 0096, iter [00980, 01251], lr: 0.001130, loss: 0.4165
2022-09-28 10:29:33 - train: epoch 0096, iter [00990, 01251], lr: 0.001130, loss: 0.4116
2022-09-28 10:29:51 - train: epoch 0096, iter [01000, 01251], lr: 0.001130, loss: 0.4183
2022-09-28 10:30:10 - train: epoch 0096, iter [01010, 01251], lr: 0.001130, loss: 0.4187
2022-09-28 10:30:28 - train: epoch 0096, iter [01020, 01251], lr: 0.001130, loss: 0.4185
2022-09-28 10:30:47 - train: epoch 0096, iter [01030, 01251], lr: 0.001130, loss: 0.4197
2022-09-28 10:31:05 - train: epoch 0096, iter [01040, 01251], lr: 0.001130, loss: 0.4135
2022-09-28 10:31:23 - train: epoch 0096, iter [01050, 01251], lr: 0.001130, loss: 0.4242
2022-09-28 10:31:42 - train: epoch 0096, iter [01060, 01251], lr: 0.001130, loss: 0.4190
2022-09-28 10:32:00 - train: epoch 0096, iter [01070, 01251], lr: 0.001130, loss: 0.4269
2022-09-28 10:32:18 - train: epoch 0096, iter [01080, 01251], lr: 0.001130, loss: 0.4074
2022-09-28 10:32:36 - train: epoch 0096, iter [01090, 01251], lr: 0.001130, loss: 0.4157
2022-09-28 10:32:54 - train: epoch 0096, iter [01100, 01251], lr: 0.001130, loss: 0.3990
2022-09-28 10:33:13 - train: epoch 0096, iter [01110, 01251], lr: 0.001130, loss: 0.4125
2022-09-28 10:33:31 - train: epoch 0096, iter [01120, 01251], lr: 0.001130, loss: 0.3933
2022-09-28 10:33:50 - train: epoch 0096, iter [01130, 01251], lr: 0.001130, loss: 0.4091
2022-09-28 10:34:08 - train: epoch 0096, iter [01140, 01251], lr: 0.001130, loss: 0.4200
2022-09-28 10:34:26 - train: epoch 0096, iter [01150, 01251], lr: 0.001130, loss: 0.4277
2022-09-28 10:34:44 - train: epoch 0096, iter [01160, 01251], lr: 0.001130, loss: 0.4265
2022-09-28 10:35:02 - train: epoch 0096, iter [01170, 01251], lr: 0.001130, loss: 0.4130
2022-09-28 10:35:21 - train: epoch 0096, iter [01180, 01251], lr: 0.001130, loss: 0.4167
2022-09-28 10:35:39 - train: epoch 0096, iter [01190, 01251], lr: 0.001130, loss: 0.4280
2022-09-28 10:35:58 - train: epoch 0096, iter [01200, 01251], lr: 0.001130, loss: 0.4084
2022-09-28 10:36:16 - train: epoch 0096, iter [01210, 01251], lr: 0.001130, loss: 0.3999
2022-09-28 10:36:35 - train: epoch 0096, iter [01220, 01251], lr: 0.001130, loss: 0.3982
2022-09-28 10:36:53 - train: epoch 0096, iter [01230, 01251], lr: 0.001130, loss: 0.4209
2022-09-28 10:37:12 - train: epoch 0096, iter [01240, 01251], lr: 0.001130, loss: 0.4179
2022-09-28 10:37:29 - train: epoch 0096, iter [01250, 01251], lr: 0.001130, loss: 0.4127
2022-09-28 10:37:32 - train: epoch 096, train_loss: 0.4136
2022-09-28 10:37:34 - until epoch: 096, best_loss: 0.4136
2022-09-28 10:37:34 - epoch 097 lr: 0.001130
2022-09-28 10:38:07 - train: epoch 0097, iter [00010, 01251], lr: 0.001130, loss: 0.4223
2022-09-28 10:38:25 - train: epoch 0097, iter [00020, 01251], lr: 0.001130, loss: 0.4273
2022-09-28 10:38:43 - train: epoch 0097, iter [00030, 01251], lr: 0.001130, loss: 0.4252
2022-09-28 10:39:02 - train: epoch 0097, iter [00040, 01251], lr: 0.001130, loss: 0.3916
2022-09-28 10:39:20 - train: epoch 0097, iter [00050, 01251], lr: 0.001130, loss: 0.4182
2022-09-28 10:39:38 - train: epoch 0097, iter [00060, 01251], lr: 0.001130, loss: 0.4194
2022-09-28 10:39:57 - train: epoch 0097, iter [00070, 01251], lr: 0.001130, loss: 0.4189
2022-09-28 10:40:15 - train: epoch 0097, iter [00080, 01251], lr: 0.001130, loss: 0.4055
2022-09-28 10:40:33 - train: epoch 0097, iter [00090, 01251], lr: 0.001130, loss: 0.4103
2022-09-28 10:40:51 - train: epoch 0097, iter [00100, 01251], lr: 0.001130, loss: 0.4032
2022-09-28 10:41:10 - train: epoch 0097, iter [00110, 01251], lr: 0.001130, loss: 0.4123
2022-09-28 10:41:28 - train: epoch 0097, iter [00120, 01251], lr: 0.001130, loss: 0.4025
2022-09-28 10:41:46 - train: epoch 0097, iter [00130, 01251], lr: 0.001130, loss: 0.4077
2022-09-28 10:42:05 - train: epoch 0097, iter [00140, 01251], lr: 0.001129, loss: 0.4194
2022-09-28 10:42:23 - train: epoch 0097, iter [00150, 01251], lr: 0.001129, loss: 0.4197
2022-09-28 10:42:42 - train: epoch 0097, iter [00160, 01251], lr: 0.001129, loss: 0.4118
2022-09-28 10:43:00 - train: epoch 0097, iter [00170, 01251], lr: 0.001129, loss: 0.4204
2022-09-28 10:43:19 - train: epoch 0097, iter [00180, 01251], lr: 0.001129, loss: 0.4137
2022-09-28 10:43:37 - train: epoch 0097, iter [00190, 01251], lr: 0.001129, loss: 0.4032
2022-09-28 10:43:55 - train: epoch 0097, iter [00200, 01251], lr: 0.001129, loss: 0.4083
2022-09-28 10:44:13 - train: epoch 0097, iter [00210, 01251], lr: 0.001129, loss: 0.3875
2022-09-28 10:44:32 - train: epoch 0097, iter [00220, 01251], lr: 0.001129, loss: 0.4286
2022-09-28 10:44:50 - train: epoch 0097, iter [00230, 01251], lr: 0.001129, loss: 0.4101
2022-09-28 10:45:09 - train: epoch 0097, iter [00240, 01251], lr: 0.001129, loss: 0.4013
2022-09-28 10:45:27 - train: epoch 0097, iter [00250, 01251], lr: 0.001129, loss: 0.4309
2022-09-28 10:45:45 - train: epoch 0097, iter [00260, 01251], lr: 0.001129, loss: 0.4242
2022-09-28 10:46:04 - train: epoch 0097, iter [00270, 01251], lr: 0.001129, loss: 0.4400
2022-09-28 10:46:22 - train: epoch 0097, iter [00280, 01251], lr: 0.001129, loss: 0.4277
2022-09-28 10:46:41 - train: epoch 0097, iter [00290, 01251], lr: 0.001129, loss: 0.4072
2022-09-28 10:46:59 - train: epoch 0097, iter [00300, 01251], lr: 0.001129, loss: 0.4215
2022-09-28 10:47:17 - train: epoch 0097, iter [00310, 01251], lr: 0.001129, loss: 0.4091
2022-09-28 10:47:36 - train: epoch 0097, iter [00320, 01251], lr: 0.001129, loss: 0.4190
2022-09-28 10:47:54 - train: epoch 0097, iter [00330, 01251], lr: 0.001129, loss: 0.4241
2022-09-28 10:48:12 - train: epoch 0097, iter [00340, 01251], lr: 0.001129, loss: 0.4285
2022-09-28 10:48:31 - train: epoch 0097, iter [00350, 01251], lr: 0.001129, loss: 0.4041
2022-09-28 10:48:49 - train: epoch 0097, iter [00360, 01251], lr: 0.001129, loss: 0.4412
2022-09-28 10:49:08 - train: epoch 0097, iter [00370, 01251], lr: 0.001129, loss: 0.4312
2022-09-28 10:49:26 - train: epoch 0097, iter [00380, 01251], lr: 0.001129, loss: 0.4161
2022-09-28 10:49:44 - train: epoch 0097, iter [00390, 01251], lr: 0.001129, loss: 0.4072
2022-09-28 10:50:02 - train: epoch 0097, iter [00400, 01251], lr: 0.001129, loss: 0.4215
2022-09-28 10:50:20 - train: epoch 0097, iter [00410, 01251], lr: 0.001129, loss: 0.4037
2022-09-28 10:50:39 - train: epoch 0097, iter [00420, 01251], lr: 0.001129, loss: 0.4174
2022-09-28 10:50:57 - train: epoch 0097, iter [00430, 01251], lr: 0.001129, loss: 0.3982
2022-09-28 10:51:15 - train: epoch 0097, iter [00440, 01251], lr: 0.001129, loss: 0.4365
2022-09-28 10:51:34 - train: epoch 0097, iter [00450, 01251], lr: 0.001129, loss: 0.4226
2022-09-28 10:51:52 - train: epoch 0097, iter [00460, 01251], lr: 0.001129, loss: 0.4088
2022-09-28 10:52:10 - train: epoch 0097, iter [00470, 01251], lr: 0.001129, loss: 0.4087
2022-09-28 10:52:29 - train: epoch 0097, iter [00480, 01251], lr: 0.001129, loss: 0.4192
2022-09-28 10:52:47 - train: epoch 0097, iter [00490, 01251], lr: 0.001129, loss: 0.4275
2022-09-28 10:53:05 - train: epoch 0097, iter [00500, 01251], lr: 0.001129, loss: 0.4277
2022-09-28 10:53:23 - train: epoch 0097, iter [00510, 01251], lr: 0.001129, loss: 0.4023
2022-09-28 10:53:42 - train: epoch 0097, iter [00520, 01251], lr: 0.001129, loss: 0.4104
2022-09-28 10:54:00 - train: epoch 0097, iter [00530, 01251], lr: 0.001129, loss: 0.4000
2022-09-28 10:54:18 - train: epoch 0097, iter [00540, 01251], lr: 0.001129, loss: 0.4023
2022-09-28 10:54:36 - train: epoch 0097, iter [00550, 01251], lr: 0.001129, loss: 0.4282
2022-09-28 10:54:54 - train: epoch 0097, iter [00560, 01251], lr: 0.001129, loss: 0.4057
2022-09-28 10:55:12 - train: epoch 0097, iter [00570, 01251], lr: 0.001129, loss: 0.4039
2022-09-28 10:55:30 - train: epoch 0097, iter [00580, 01251], lr: 0.001129, loss: 0.4232
2022-09-28 10:55:48 - train: epoch 0097, iter [00590, 01251], lr: 0.001129, loss: 0.3963
2022-09-28 10:56:06 - train: epoch 0097, iter [00600, 01251], lr: 0.001129, loss: 0.4099
2022-09-28 10:56:25 - train: epoch 0097, iter [00610, 01251], lr: 0.001129, loss: 0.4115
2022-09-28 10:56:43 - train: epoch 0097, iter [00620, 01251], lr: 0.001129, loss: 0.4050
2022-09-28 10:57:01 - train: epoch 0097, iter [00630, 01251], lr: 0.001129, loss: 0.4290
2022-09-28 10:57:19 - train: epoch 0097, iter [00640, 01251], lr: 0.001129, loss: 0.4043
2022-09-28 10:57:37 - train: epoch 0097, iter [00650, 01251], lr: 0.001128, loss: 0.4112
2022-09-28 10:57:55 - train: epoch 0097, iter [00660, 01251], lr: 0.001128, loss: 0.3866
2022-09-28 10:58:13 - train: epoch 0097, iter [00670, 01251], lr: 0.001128, loss: 0.4115
2022-09-28 10:58:32 - train: epoch 0097, iter [00680, 01251], lr: 0.001128, loss: 0.4410
2022-09-28 10:58:49 - train: epoch 0097, iter [00690, 01251], lr: 0.001128, loss: 0.4217
2022-09-28 10:59:08 - train: epoch 0097, iter [00700, 01251], lr: 0.001128, loss: 0.4014
2022-09-28 10:59:26 - train: epoch 0097, iter [00710, 01251], lr: 0.001128, loss: 0.4271
2022-09-28 10:59:44 - train: epoch 0097, iter [00720, 01251], lr: 0.001128, loss: 0.4231
2022-09-28 11:00:02 - train: epoch 0097, iter [00730, 01251], lr: 0.001128, loss: 0.4196
2022-09-28 11:00:20 - train: epoch 0097, iter [00740, 01251], lr: 0.001128, loss: 0.4008
2022-09-28 11:00:38 - train: epoch 0097, iter [00750, 01251], lr: 0.001128, loss: 0.4081
2022-09-28 11:00:56 - train: epoch 0097, iter [00760, 01251], lr: 0.001128, loss: 0.4176
2022-09-28 11:01:14 - train: epoch 0097, iter [00770, 01251], lr: 0.001128, loss: 0.3988
2022-09-28 11:01:33 - train: epoch 0097, iter [00780, 01251], lr: 0.001128, loss: 0.4022
2022-09-28 11:01:51 - train: epoch 0097, iter [00790, 01251], lr: 0.001128, loss: 0.4257
2022-09-28 11:02:09 - train: epoch 0097, iter [00800, 01251], lr: 0.001128, loss: 0.4048
2022-09-28 11:02:27 - train: epoch 0097, iter [00810, 01251], lr: 0.001128, loss: 0.4043
2022-09-28 11:02:46 - train: epoch 0097, iter [00820, 01251], lr: 0.001128, loss: 0.4259
2022-09-28 11:03:04 - train: epoch 0097, iter [00830, 01251], lr: 0.001128, loss: 0.4089
2022-09-28 11:03:22 - train: epoch 0097, iter [00840, 01251], lr: 0.001128, loss: 0.4000
2022-09-28 11:03:40 - train: epoch 0097, iter [00850, 01251], lr: 0.001128, loss: 0.4168
2022-09-28 11:03:58 - train: epoch 0097, iter [00860, 01251], lr: 0.001128, loss: 0.4130
2022-09-28 11:04:16 - train: epoch 0097, iter [00870, 01251], lr: 0.001128, loss: 0.4150
2022-09-28 11:04:34 - train: epoch 0097, iter [00880, 01251], lr: 0.001128, loss: 0.4065
2022-09-28 11:04:52 - train: epoch 0097, iter [00890, 01251], lr: 0.001128, loss: 0.3846
2022-09-28 11:05:11 - train: epoch 0097, iter [00900, 01251], lr: 0.001128, loss: 0.4083
2022-09-28 11:05:29 - train: epoch 0097, iter [00910, 01251], lr: 0.001128, loss: 0.4206
2022-09-28 11:05:47 - train: epoch 0097, iter [00920, 01251], lr: 0.001128, loss: 0.4201
2022-09-28 11:06:06 - train: epoch 0097, iter [00930, 01251], lr: 0.001128, loss: 0.4294
2022-09-28 11:06:24 - train: epoch 0097, iter [00940, 01251], lr: 0.001128, loss: 0.4008
2022-09-28 11:06:42 - train: epoch 0097, iter [00950, 01251], lr: 0.001128, loss: 0.4050
2022-09-28 11:07:00 - train: epoch 0097, iter [00960, 01251], lr: 0.001128, loss: 0.4219
2022-09-28 11:07:18 - train: epoch 0097, iter [00970, 01251], lr: 0.001128, loss: 0.4208
2022-09-28 11:07:36 - train: epoch 0097, iter [00980, 01251], lr: 0.001128, loss: 0.4254
2022-09-28 11:07:54 - train: epoch 0097, iter [00990, 01251], lr: 0.001128, loss: 0.4189
2022-09-28 11:08:13 - train: epoch 0097, iter [01000, 01251], lr: 0.001128, loss: 0.4258
2022-09-28 11:08:31 - train: epoch 0097, iter [01010, 01251], lr: 0.001128, loss: 0.4011
2022-09-28 11:08:49 - train: epoch 0097, iter [01020, 01251], lr: 0.001128, loss: 0.4243
2022-09-28 11:09:07 - train: epoch 0097, iter [01030, 01251], lr: 0.001128, loss: 0.4092
2022-09-28 11:09:26 - train: epoch 0097, iter [01040, 01251], lr: 0.001128, loss: 0.4115
2022-09-28 11:09:44 - train: epoch 0097, iter [01050, 01251], lr: 0.001128, loss: 0.4161
2022-09-28 11:10:02 - train: epoch 0097, iter [01060, 01251], lr: 0.001128, loss: 0.4046
2022-09-28 11:10:20 - train: epoch 0097, iter [01070, 01251], lr: 0.001128, loss: 0.4007
2022-09-28 11:10:38 - train: epoch 0097, iter [01080, 01251], lr: 0.001128, loss: 0.4044
2022-09-28 11:10:56 - train: epoch 0097, iter [01090, 01251], lr: 0.001128, loss: 0.4057
2022-09-28 11:11:14 - train: epoch 0097, iter [01100, 01251], lr: 0.001128, loss: 0.4234
2022-09-28 11:11:32 - train: epoch 0097, iter [01110, 01251], lr: 0.001128, loss: 0.4047
2022-09-28 11:11:51 - train: epoch 0097, iter [01120, 01251], lr: 0.001128, loss: 0.3905
2022-09-28 11:12:09 - train: epoch 0097, iter [01130, 01251], lr: 0.001128, loss: 0.4121
2022-09-28 11:12:27 - train: epoch 0097, iter [01140, 01251], lr: 0.001128, loss: 0.4019
2022-09-28 11:12:45 - train: epoch 0097, iter [01150, 01251], lr: 0.001127, loss: 0.4143
2022-09-28 11:13:03 - train: epoch 0097, iter [01160, 01251], lr: 0.001127, loss: 0.4125
2022-09-28 11:13:21 - train: epoch 0097, iter [01170, 01251], lr: 0.001127, loss: 0.4054
2022-09-28 11:13:40 - train: epoch 0097, iter [01180, 01251], lr: 0.001127, loss: 0.4257
2022-09-28 11:13:58 - train: epoch 0097, iter [01190, 01251], lr: 0.001127, loss: 0.4176
2022-09-28 11:14:16 - train: epoch 0097, iter [01200, 01251], lr: 0.001127, loss: 0.4122
2022-09-28 11:14:34 - train: epoch 0097, iter [01210, 01251], lr: 0.001127, loss: 0.4306
2022-09-28 11:14:52 - train: epoch 0097, iter [01220, 01251], lr: 0.001127, loss: 0.4132
2022-09-28 11:15:10 - train: epoch 0097, iter [01230, 01251], lr: 0.001127, loss: 0.3952
2022-09-28 11:15:29 - train: epoch 0097, iter [01240, 01251], lr: 0.001127, loss: 0.4144
2022-09-28 11:15:46 - train: epoch 0097, iter [01250, 01251], lr: 0.001127, loss: 0.4131
2022-09-28 11:15:50 - train: epoch 097, train_loss: 0.4136
2022-09-28 11:15:52 - until epoch: 097, best_loss: 0.4136
2022-09-28 11:15:52 - epoch 098 lr: 0.001127
2022-09-28 11:16:25 - train: epoch 0098, iter [00010, 01251], lr: 0.001127, loss: 0.4343
2022-09-28 11:16:43 - train: epoch 0098, iter [00020, 01251], lr: 0.001127, loss: 0.4099
2022-09-28 11:17:01 - train: epoch 0098, iter [00030, 01251], lr: 0.001127, loss: 0.4110
2022-09-28 11:17:20 - train: epoch 0098, iter [00040, 01251], lr: 0.001127, loss: 0.4107
2022-09-28 11:17:38 - train: epoch 0098, iter [00050, 01251], lr: 0.001127, loss: 0.4180
2022-09-28 11:17:56 - train: epoch 0098, iter [00060, 01251], lr: 0.001127, loss: 0.4256
2022-09-28 11:18:14 - train: epoch 0098, iter [00070, 01251], lr: 0.001127, loss: 0.3933
2022-09-28 11:18:32 - train: epoch 0098, iter [00080, 01251], lr: 0.001127, loss: 0.4117
2022-09-28 11:18:50 - train: epoch 0098, iter [00090, 01251], lr: 0.001127, loss: 0.3992
2022-09-28 11:19:08 - train: epoch 0098, iter [00100, 01251], lr: 0.001127, loss: 0.4084
2022-09-28 11:19:27 - train: epoch 0098, iter [00110, 01251], lr: 0.001127, loss: 0.4064
2022-09-28 11:19:45 - train: epoch 0098, iter [00120, 01251], lr: 0.001127, loss: 0.4161
2022-09-28 11:20:03 - train: epoch 0098, iter [00130, 01251], lr: 0.001127, loss: 0.4139
2022-09-28 11:20:21 - train: epoch 0098, iter [00140, 01251], lr: 0.001127, loss: 0.4334
2022-09-28 11:20:39 - train: epoch 0098, iter [00150, 01251], lr: 0.001127, loss: 0.4309
2022-09-28 11:20:57 - train: epoch 0098, iter [00160, 01251], lr: 0.001127, loss: 0.4146
2022-09-28 11:21:15 - train: epoch 0098, iter [00170, 01251], lr: 0.001127, loss: 0.4056
2022-09-28 11:21:33 - train: epoch 0098, iter [00180, 01251], lr: 0.001127, loss: 0.4252
2022-09-28 11:21:52 - train: epoch 0098, iter [00190, 01251], lr: 0.001127, loss: 0.4355
2022-09-28 11:22:10 - train: epoch 0098, iter [00200, 01251], lr: 0.001127, loss: 0.4233
2022-09-28 11:22:28 - train: epoch 0098, iter [00210, 01251], lr: 0.001127, loss: 0.4110
2022-09-28 11:22:46 - train: epoch 0098, iter [00220, 01251], lr: 0.001127, loss: 0.4111
2022-09-28 11:23:04 - train: epoch 0098, iter [00230, 01251], lr: 0.001127, loss: 0.4287
2022-09-28 11:23:22 - train: epoch 0098, iter [00240, 01251], lr: 0.001127, loss: 0.4124
2022-09-28 11:23:40 - train: epoch 0098, iter [00250, 01251], lr: 0.001127, loss: 0.4155
2022-09-28 11:23:58 - train: epoch 0098, iter [00260, 01251], lr: 0.001127, loss: 0.4354
2022-09-28 11:24:16 - train: epoch 0098, iter [00270, 01251], lr: 0.001127, loss: 0.4243
2022-09-28 11:24:34 - train: epoch 0098, iter [00280, 01251], lr: 0.001127, loss: 0.4390
2022-09-28 11:24:52 - train: epoch 0098, iter [00290, 01251], lr: 0.001127, loss: 0.4091
2022-09-28 11:25:10 - train: epoch 0098, iter [00300, 01251], lr: 0.001127, loss: 0.4151
2022-09-28 11:25:28 - train: epoch 0098, iter [00310, 01251], lr: 0.001127, loss: 0.4335
2022-09-28 11:25:46 - train: epoch 0098, iter [00320, 01251], lr: 0.001127, loss: 0.4136
2022-09-28 11:26:04 - train: epoch 0098, iter [00330, 01251], lr: 0.001127, loss: 0.4092
2022-09-28 11:26:22 - train: epoch 0098, iter [00340, 01251], lr: 0.001127, loss: 0.4085
2022-09-28 11:26:40 - train: epoch 0098, iter [00350, 01251], lr: 0.001127, loss: 0.4309
2022-09-28 11:26:58 - train: epoch 0098, iter [00360, 01251], lr: 0.001127, loss: 0.4097
2022-09-28 11:27:16 - train: epoch 0098, iter [00370, 01251], lr: 0.001127, loss: 0.4251
2022-09-28 11:27:34 - train: epoch 0098, iter [00380, 01251], lr: 0.001127, loss: 0.4063
2022-09-28 11:27:53 - train: epoch 0098, iter [00390, 01251], lr: 0.001127, loss: 0.4197
2022-09-28 11:28:10 - train: epoch 0098, iter [00400, 01251], lr: 0.001126, loss: 0.4047
2022-09-28 11:28:28 - train: epoch 0098, iter [00410, 01251], lr: 0.001126, loss: 0.4284
2022-09-28 11:28:46 - train: epoch 0098, iter [00420, 01251], lr: 0.001126, loss: 0.4065
2022-09-28 11:29:04 - train: epoch 0098, iter [00430, 01251], lr: 0.001126, loss: 0.4458
2022-09-28 11:29:22 - train: epoch 0098, iter [00440, 01251], lr: 0.001126, loss: 0.4233
2022-09-28 11:29:40 - train: epoch 0098, iter [00450, 01251], lr: 0.001126, loss: 0.3967
2022-09-28 11:29:58 - train: epoch 0098, iter [00460, 01251], lr: 0.001126, loss: 0.4049
2022-09-28 11:30:16 - train: epoch 0098, iter [00470, 01251], lr: 0.001126, loss: 0.4057
2022-09-28 11:30:35 - train: epoch 0098, iter [00480, 01251], lr: 0.001126, loss: 0.4066
2022-09-28 11:30:53 - train: epoch 0098, iter [00490, 01251], lr: 0.001126, loss: 0.4178
2022-09-28 11:31:11 - train: epoch 0098, iter [00500, 01251], lr: 0.001126, loss: 0.4140
2022-09-28 11:31:29 - train: epoch 0098, iter [00510, 01251], lr: 0.001126, loss: 0.4093
2022-09-28 11:31:47 - train: epoch 0098, iter [00520, 01251], lr: 0.001126, loss: 0.4174
2022-09-28 11:32:05 - train: epoch 0098, iter [00530, 01251], lr: 0.001126, loss: 0.4169
2022-09-28 11:32:23 - train: epoch 0098, iter [00540, 01251], lr: 0.001126, loss: 0.4343
2022-09-28 11:32:41 - train: epoch 0098, iter [00550, 01251], lr: 0.001126, loss: 0.4010
2022-09-28 11:32:59 - train: epoch 0098, iter [00560, 01251], lr: 0.001126, loss: 0.4013
2022-09-28 11:33:17 - train: epoch 0098, iter [00570, 01251], lr: 0.001126, loss: 0.4063
2022-09-28 11:33:35 - train: epoch 0098, iter [00580, 01251], lr: 0.001126, loss: 0.4131
2022-09-28 11:33:53 - train: epoch 0098, iter [00590, 01251], lr: 0.001126, loss: 0.4025
2022-09-28 11:34:12 - train: epoch 0098, iter [00600, 01251], lr: 0.001126, loss: 0.4296
2022-09-28 11:34:30 - train: epoch 0098, iter [00610, 01251], lr: 0.001126, loss: 0.4214
2022-09-28 11:34:48 - train: epoch 0098, iter [00620, 01251], lr: 0.001126, loss: 0.3953
2022-09-28 11:35:06 - train: epoch 0098, iter [00630, 01251], lr: 0.001126, loss: 0.4123
2022-09-28 11:35:24 - train: epoch 0098, iter [00640, 01251], lr: 0.001126, loss: 0.4293
2022-09-28 11:35:42 - train: epoch 0098, iter [00650, 01251], lr: 0.001126, loss: 0.4286
2022-09-28 11:36:00 - train: epoch 0098, iter [00660, 01251], lr: 0.001126, loss: 0.4111
2022-09-28 11:36:18 - train: epoch 0098, iter [00670, 01251], lr: 0.001126, loss: 0.3971
2022-09-28 11:36:36 - train: epoch 0098, iter [00680, 01251], lr: 0.001126, loss: 0.4068
2022-09-28 11:36:54 - train: epoch 0098, iter [00690, 01251], lr: 0.001126, loss: 0.4143
2022-09-28 11:37:12 - train: epoch 0098, iter [00700, 01251], lr: 0.001126, loss: 0.4148
2022-09-28 11:37:30 - train: epoch 0098, iter [00710, 01251], lr: 0.001126, loss: 0.4031
2022-09-28 11:37:48 - train: epoch 0098, iter [00720, 01251], lr: 0.001126, loss: 0.3945
2022-09-28 11:38:06 - train: epoch 0098, iter [00730, 01251], lr: 0.001126, loss: 0.4110
2022-09-28 11:38:24 - train: epoch 0098, iter [00740, 01251], lr: 0.001126, loss: 0.4183
2022-09-28 11:38:42 - train: epoch 0098, iter [00750, 01251], lr: 0.001126, loss: 0.4088
2022-09-28 11:39:00 - train: epoch 0098, iter [00760, 01251], lr: 0.001126, loss: 0.4166
2022-09-28 11:39:18 - train: epoch 0098, iter [00770, 01251], lr: 0.001126, loss: 0.4238
2022-09-28 11:39:36 - train: epoch 0098, iter [00780, 01251], lr: 0.001126, loss: 0.4049
2022-09-28 11:39:54 - train: epoch 0098, iter [00790, 01251], lr: 0.001126, loss: 0.4178
2022-09-28 11:40:12 - train: epoch 0098, iter [00800, 01251], lr: 0.001126, loss: 0.4087
2022-09-28 11:40:30 - train: epoch 0098, iter [00810, 01251], lr: 0.001126, loss: 0.4112
2022-09-28 11:40:48 - train: epoch 0098, iter [00820, 01251], lr: 0.001126, loss: 0.4213
2022-09-28 11:41:06 - train: epoch 0098, iter [00830, 01251], lr: 0.001126, loss: 0.4128
2022-09-28 11:41:24 - train: epoch 0098, iter [00840, 01251], lr: 0.001126, loss: 0.3937
2022-09-28 11:41:42 - train: epoch 0098, iter [00850, 01251], lr: 0.001126, loss: 0.3851
2022-09-28 11:42:00 - train: epoch 0098, iter [00860, 01251], lr: 0.001126, loss: 0.4229
2022-09-28 11:42:18 - train: epoch 0098, iter [00870, 01251], lr: 0.001126, loss: 0.4206
2022-09-28 11:42:36 - train: epoch 0098, iter [00880, 01251], lr: 0.001126, loss: 0.4045
2022-09-28 11:42:54 - train: epoch 0098, iter [00890, 01251], lr: 0.001126, loss: 0.4303
2022-09-28 11:43:12 - train: epoch 0098, iter [00900, 01251], lr: 0.001125, loss: 0.4071
2022-09-28 11:43:30 - train: epoch 0098, iter [00910, 01251], lr: 0.001125, loss: 0.4124
2022-09-28 11:43:48 - train: epoch 0098, iter [00920, 01251], lr: 0.001125, loss: 0.4177
2022-09-28 11:44:06 - train: epoch 0098, iter [00930, 01251], lr: 0.001125, loss: 0.4084
2022-09-28 11:44:24 - train: epoch 0098, iter [00940, 01251], lr: 0.001125, loss: 0.4014
2022-09-28 11:44:42 - train: epoch 0098, iter [00950, 01251], lr: 0.001125, loss: 0.4120
2022-09-28 11:45:00 - train: epoch 0098, iter [00960, 01251], lr: 0.001125, loss: 0.4100
2022-09-28 11:45:18 - train: epoch 0098, iter [00970, 01251], lr: 0.001125, loss: 0.4074
2022-09-28 11:45:36 - train: epoch 0098, iter [00980, 01251], lr: 0.001125, loss: 0.4211
2022-09-28 11:45:54 - train: epoch 0098, iter [00990, 01251], lr: 0.001125, loss: 0.3996
2022-09-28 11:46:12 - train: epoch 0098, iter [01000, 01251], lr: 0.001125, loss: 0.4167
2022-09-28 11:46:30 - train: epoch 0098, iter [01010, 01251], lr: 0.001125, loss: 0.4148
2022-09-28 11:46:49 - train: epoch 0098, iter [01020, 01251], lr: 0.001125, loss: 0.4132
2022-09-28 11:47:07 - train: epoch 0098, iter [01030, 01251], lr: 0.001125, loss: 0.4247
2022-09-28 11:47:24 - train: epoch 0098, iter [01040, 01251], lr: 0.001125, loss: 0.4093
2022-09-28 11:47:42 - train: epoch 0098, iter [01050, 01251], lr: 0.001125, loss: 0.4115
2022-09-28 11:48:00 - train: epoch 0098, iter [01060, 01251], lr: 0.001125, loss: 0.3887
2022-09-28 11:48:18 - train: epoch 0098, iter [01070, 01251], lr: 0.001125, loss: 0.4291
2022-09-28 11:48:36 - train: epoch 0098, iter [01080, 01251], lr: 0.001125, loss: 0.4132
2022-09-28 11:48:54 - train: epoch 0098, iter [01090, 01251], lr: 0.001125, loss: 0.3973
2022-09-28 11:49:12 - train: epoch 0098, iter [01100, 01251], lr: 0.001125, loss: 0.4131
2022-09-28 11:49:30 - train: epoch 0098, iter [01110, 01251], lr: 0.001125, loss: 0.3898
2022-09-28 11:49:48 - train: epoch 0098, iter [01120, 01251], lr: 0.001125, loss: 0.4258
2022-09-28 11:50:06 - train: epoch 0098, iter [01130, 01251], lr: 0.001125, loss: 0.4034
2022-09-28 11:50:24 - train: epoch 0098, iter [01140, 01251], lr: 0.001125, loss: 0.4050
2022-09-28 11:50:42 - train: epoch 0098, iter [01150, 01251], lr: 0.001125, loss: 0.4207
2022-09-28 11:51:00 - train: epoch 0098, iter [01160, 01251], lr: 0.001125, loss: 0.4219
2022-09-28 11:51:18 - train: epoch 0098, iter [01170, 01251], lr: 0.001125, loss: 0.4078
2022-09-28 11:51:37 - train: epoch 0098, iter [01180, 01251], lr: 0.001125, loss: 0.4149
2022-09-28 11:51:54 - train: epoch 0098, iter [01190, 01251], lr: 0.001125, loss: 0.4094
2022-09-28 11:52:12 - train: epoch 0098, iter [01200, 01251], lr: 0.001125, loss: 0.4110
2022-09-28 11:52:31 - train: epoch 0098, iter [01210, 01251], lr: 0.001125, loss: 0.4117
2022-09-28 11:52:49 - train: epoch 0098, iter [01220, 01251], lr: 0.001125, loss: 0.4259
2022-09-28 11:53:07 - train: epoch 0098, iter [01230, 01251], lr: 0.001125, loss: 0.4145
2022-09-28 11:53:25 - train: epoch 0098, iter [01240, 01251], lr: 0.001125, loss: 0.4165
2022-09-28 11:53:41 - train: epoch 0098, iter [01250, 01251], lr: 0.001125, loss: 0.4094
2022-09-28 11:53:45 - train: epoch 098, train_loss: 0.4135
2022-09-28 11:53:48 - until epoch: 098, best_loss: 0.4135
2022-09-28 11:53:48 - epoch 099 lr: 0.001125
2022-09-28 11:54:21 - train: epoch 0099, iter [00010, 01251], lr: 0.001125, loss: 0.4032
2022-09-28 11:54:39 - train: epoch 0099, iter [00020, 01251], lr: 0.001125, loss: 0.4146
2022-09-28 11:54:57 - train: epoch 0099, iter [00030, 01251], lr: 0.001125, loss: 0.4012
2022-09-28 11:55:15 - train: epoch 0099, iter [00040, 01251], lr: 0.001125, loss: 0.4305
2022-09-28 11:55:33 - train: epoch 0099, iter [00050, 01251], lr: 0.001125, loss: 0.4155
2022-09-28 11:55:50 - train: epoch 0099, iter [00060, 01251], lr: 0.001125, loss: 0.4086
2022-09-28 11:56:08 - train: epoch 0099, iter [00070, 01251], lr: 0.001125, loss: 0.4223
2022-09-28 11:56:26 - train: epoch 0099, iter [00080, 01251], lr: 0.001125, loss: 0.3937
2022-09-28 11:56:44 - train: epoch 0099, iter [00090, 01251], lr: 0.001125, loss: 0.4088
2022-09-28 11:57:02 - train: epoch 0099, iter [00100, 01251], lr: 0.001125, loss: 0.4059
2022-09-28 11:57:20 - train: epoch 0099, iter [00110, 01251], lr: 0.001125, loss: 0.4019
2022-09-28 11:57:38 - train: epoch 0099, iter [00120, 01251], lr: 0.001125, loss: 0.4061
2022-09-28 11:57:56 - train: epoch 0099, iter [00130, 01251], lr: 0.001125, loss: 0.4185
2022-09-28 11:58:14 - train: epoch 0099, iter [00140, 01251], lr: 0.001124, loss: 0.4079
2022-09-28 11:58:32 - train: epoch 0099, iter [00150, 01251], lr: 0.001124, loss: 0.4075
2022-09-28 11:58:50 - train: epoch 0099, iter [00160, 01251], lr: 0.001124, loss: 0.4408
2022-09-28 11:59:08 - train: epoch 0099, iter [00170, 01251], lr: 0.001124, loss: 0.4250
2022-09-28 11:59:26 - train: epoch 0099, iter [00180, 01251], lr: 0.001124, loss: 0.4158
2022-09-28 11:59:44 - train: epoch 0099, iter [00190, 01251], lr: 0.001124, loss: 0.4085
2022-09-28 12:00:02 - train: epoch 0099, iter [00200, 01251], lr: 0.001124, loss: 0.3859
2022-09-28 12:00:20 - train: epoch 0099, iter [00210, 01251], lr: 0.001124, loss: 0.4125
2022-09-28 12:00:38 - train: epoch 0099, iter [00220, 01251], lr: 0.001124, loss: 0.4169
2022-09-28 12:00:56 - train: epoch 0099, iter [00230, 01251], lr: 0.001124, loss: 0.4392
2022-09-28 12:01:14 - train: epoch 0099, iter [00240, 01251], lr: 0.001124, loss: 0.4048
2022-09-28 12:01:32 - train: epoch 0099, iter [00250, 01251], lr: 0.001124, loss: 0.4146
2022-09-28 12:01:50 - train: epoch 0099, iter [00260, 01251], lr: 0.001124, loss: 0.4059
2022-09-28 12:02:07 - train: epoch 0099, iter [00270, 01251], lr: 0.001124, loss: 0.4071
2022-09-28 12:02:25 - train: epoch 0099, iter [00280, 01251], lr: 0.001124, loss: 0.4132
2022-09-28 12:02:43 - train: epoch 0099, iter [00290, 01251], lr: 0.001124, loss: 0.4128
2022-09-28 12:03:01 - train: epoch 0099, iter [00300, 01251], lr: 0.001124, loss: 0.4177
2022-09-28 12:03:19 - train: epoch 0099, iter [00310, 01251], lr: 0.001124, loss: 0.4076
2022-09-28 12:03:37 - train: epoch 0099, iter [00320, 01251], lr: 0.001124, loss: 0.4328
2022-09-28 12:03:55 - train: epoch 0099, iter [00330, 01251], lr: 0.001124, loss: 0.4341
2022-09-28 12:04:13 - train: epoch 0099, iter [00340, 01251], lr: 0.001124, loss: 0.3864
2022-09-28 12:04:31 - train: epoch 0099, iter [00350, 01251], lr: 0.001124, loss: 0.3988
2022-09-28 12:04:49 - train: epoch 0099, iter [00360, 01251], lr: 0.001124, loss: 0.4194
2022-09-28 12:05:07 - train: epoch 0099, iter [00370, 01251], lr: 0.001124, loss: 0.4331
2022-09-28 12:05:25 - train: epoch 0099, iter [00380, 01251], lr: 0.001124, loss: 0.4236
2022-09-28 12:05:43 - train: epoch 0099, iter [00390, 01251], lr: 0.001124, loss: 0.4164
2022-09-28 12:06:01 - train: epoch 0099, iter [00400, 01251], lr: 0.001124, loss: 0.4079
2022-09-28 12:06:18 - train: epoch 0099, iter [00410, 01251], lr: 0.001124, loss: 0.3900
2022-09-28 12:06:36 - train: epoch 0099, iter [00420, 01251], lr: 0.001124, loss: 0.3993
2022-09-28 12:06:54 - train: epoch 0099, iter [00430, 01251], lr: 0.001124, loss: 0.4149
2022-09-28 12:07:12 - train: epoch 0099, iter [00440, 01251], lr: 0.001124, loss: 0.4160
2022-09-28 12:07:30 - train: epoch 0099, iter [00450, 01251], lr: 0.001124, loss: 0.4207
2022-09-28 12:07:48 - train: epoch 0099, iter [00460, 01251], lr: 0.001124, loss: 0.4026
2022-09-28 12:08:06 - train: epoch 0099, iter [00470, 01251], lr: 0.001124, loss: 0.3986
2022-09-28 12:08:24 - train: epoch 0099, iter [00480, 01251], lr: 0.001124, loss: 0.4074
2022-09-28 12:08:42 - train: epoch 0099, iter [00490, 01251], lr: 0.001124, loss: 0.4163
2022-09-28 12:09:00 - train: epoch 0099, iter [00500, 01251], lr: 0.001124, loss: 0.4146
2022-09-28 12:09:18 - train: epoch 0099, iter [00510, 01251], lr: 0.001124, loss: 0.4297
2022-09-28 12:09:36 - train: epoch 0099, iter [00520, 01251], lr: 0.001124, loss: 0.4149
2022-09-28 12:09:54 - train: epoch 0099, iter [00530, 01251], lr: 0.001124, loss: 0.3868
2022-09-28 12:10:12 - train: epoch 0099, iter [00540, 01251], lr: 0.001124, loss: 0.4036
2022-09-28 12:10:30 - train: epoch 0099, iter [00550, 01251], lr: 0.001124, loss: 0.3982
2022-09-28 12:10:48 - train: epoch 0099, iter [00560, 01251], lr: 0.001124, loss: 0.4070
2022-09-28 12:11:05 - train: epoch 0099, iter [00570, 01251], lr: 0.001124, loss: 0.4220
2022-09-28 12:11:23 - train: epoch 0099, iter [00580, 01251], lr: 0.001124, loss: 0.4286
2022-09-28 12:11:41 - train: epoch 0099, iter [00590, 01251], lr: 0.001124, loss: 0.4245
2022-09-28 12:11:59 - train: epoch 0099, iter [00600, 01251], lr: 0.001124, loss: 0.4165
2022-09-28 12:12:17 - train: epoch 0099, iter [00610, 01251], lr: 0.001124, loss: 0.4053
2022-09-28 12:12:35 - train: epoch 0099, iter [00620, 01251], lr: 0.001124, loss: 0.4208
2022-09-28 12:12:53 - train: epoch 0099, iter [00630, 01251], lr: 0.001123, loss: 0.4113
2022-09-28 12:13:10 - train: epoch 0099, iter [00640, 01251], lr: 0.001123, loss: 0.4001
2022-09-28 12:13:28 - train: epoch 0099, iter [00650, 01251], lr: 0.001123, loss: 0.4122
2022-09-28 12:13:46 - train: epoch 0099, iter [00660, 01251], lr: 0.001123, loss: 0.4278
2022-09-28 12:14:04 - train: epoch 0099, iter [00670, 01251], lr: 0.001123, loss: 0.4030
2022-09-28 12:14:22 - train: epoch 0099, iter [00680, 01251], lr: 0.001123, loss: 0.4122
2022-09-28 12:14:40 - train: epoch 0099, iter [00690, 01251], lr: 0.001123, loss: 0.4009
2022-09-28 12:14:57 - train: epoch 0099, iter [00700, 01251], lr: 0.001123, loss: 0.3991
2022-09-28 12:15:15 - train: epoch 0099, iter [00710, 01251], lr: 0.001123, loss: 0.3940
2022-09-28 12:15:33 - train: epoch 0099, iter [00720, 01251], lr: 0.001123, loss: 0.4131
2022-09-28 12:15:51 - train: epoch 0099, iter [00730, 01251], lr: 0.001123, loss: 0.4286
2022-09-28 12:16:08 - train: epoch 0099, iter [00740, 01251], lr: 0.001123, loss: 0.4287
2022-09-28 12:16:26 - train: epoch 0099, iter [00750, 01251], lr: 0.001123, loss: 0.3946
2022-09-28 12:16:44 - train: epoch 0099, iter [00760, 01251], lr: 0.001123, loss: 0.4198
2022-09-28 12:17:02 - train: epoch 0099, iter [00770, 01251], lr: 0.001123, loss: 0.4287
2022-09-28 12:17:20 - train: epoch 0099, iter [00780, 01251], lr: 0.001123, loss: 0.4107
2022-09-28 12:17:38 - train: epoch 0099, iter [00790, 01251], lr: 0.001123, loss: 0.4337
2022-09-28 12:17:56 - train: epoch 0099, iter [00800, 01251], lr: 0.001123, loss: 0.3925
2022-09-28 12:18:14 - train: epoch 0099, iter [00810, 01251], lr: 0.001123, loss: 0.3956
2022-09-28 12:18:31 - train: epoch 0099, iter [00820, 01251], lr: 0.001123, loss: 0.4189
2022-09-28 12:18:49 - train: epoch 0099, iter [00830, 01251], lr: 0.001123, loss: 0.4150
2022-09-28 12:19:07 - train: epoch 0099, iter [00840, 01251], lr: 0.001123, loss: 0.4230
2022-09-28 12:19:25 - train: epoch 0099, iter [00850, 01251], lr: 0.001123, loss: 0.4309
2022-09-28 12:19:43 - train: epoch 0099, iter [00860, 01251], lr: 0.001123, loss: 0.4301
2022-09-28 12:20:01 - train: epoch 0099, iter [00870, 01251], lr: 0.001123, loss: 0.4135
2022-09-28 12:20:19 - train: epoch 0099, iter [00880, 01251], lr: 0.001123, loss: 0.4077
2022-09-28 12:20:37 - train: epoch 0099, iter [00890, 01251], lr: 0.001123, loss: 0.4152
2022-09-28 12:20:55 - train: epoch 0099, iter [00900, 01251], lr: 0.001123, loss: 0.4280
2022-09-28 12:21:12 - train: epoch 0099, iter [00910, 01251], lr: 0.001123, loss: 0.4180
2022-09-28 12:21:30 - train: epoch 0099, iter [00920, 01251], lr: 0.001123, loss: 0.4135
2022-09-28 12:21:48 - train: epoch 0099, iter [00930, 01251], lr: 0.001123, loss: 0.4070
2022-09-28 12:22:06 - train: epoch 0099, iter [00940, 01251], lr: 0.001123, loss: 0.4084
2022-09-28 12:22:24 - train: epoch 0099, iter [00950, 01251], lr: 0.001123, loss: 0.4112
2022-09-28 12:22:42 - train: epoch 0099, iter [00960, 01251], lr: 0.001123, loss: 0.4003
2022-09-28 12:23:00 - train: epoch 0099, iter [00970, 01251], lr: 0.001123, loss: 0.4069
2022-09-28 12:23:18 - train: epoch 0099, iter [00980, 01251], lr: 0.001123, loss: 0.4223
2022-09-28 12:23:36 - train: epoch 0099, iter [00990, 01251], lr: 0.001123, loss: 0.4042
2022-09-28 12:23:53 - train: epoch 0099, iter [01000, 01251], lr: 0.001123, loss: 0.3793
2022-09-28 12:24:11 - train: epoch 0099, iter [01010, 01251], lr: 0.001123, loss: 0.4206
2022-09-28 12:24:29 - train: epoch 0099, iter [01020, 01251], lr: 0.001123, loss: 0.4047
2022-09-28 12:24:47 - train: epoch 0099, iter [01030, 01251], lr: 0.001123, loss: 0.4303
2022-09-28 12:25:05 - train: epoch 0099, iter [01040, 01251], lr: 0.001123, loss: 0.4146
2022-09-28 12:25:23 - train: epoch 0099, iter [01050, 01251], lr: 0.001123, loss: 0.4143
2022-09-28 12:25:41 - train: epoch 0099, iter [01060, 01251], lr: 0.001123, loss: 0.4253
2022-09-28 12:25:59 - train: epoch 0099, iter [01070, 01251], lr: 0.001123, loss: 0.4323
2022-09-28 12:26:17 - train: epoch 0099, iter [01080, 01251], lr: 0.001123, loss: 0.4098
2022-09-28 12:26:34 - train: epoch 0099, iter [01090, 01251], lr: 0.001123, loss: 0.4031
2022-09-28 12:26:52 - train: epoch 0099, iter [01100, 01251], lr: 0.001123, loss: 0.4356
2022-09-28 12:27:10 - train: epoch 0099, iter [01110, 01251], lr: 0.001123, loss: 0.4227
2022-09-28 12:27:28 - train: epoch 0099, iter [01120, 01251], lr: 0.001122, loss: 0.4055
2022-09-28 12:27:46 - train: epoch 0099, iter [01130, 01251], lr: 0.001122, loss: 0.4067
2022-09-28 12:28:04 - train: epoch 0099, iter [01140, 01251], lr: 0.001122, loss: 0.4066
2022-09-28 12:28:22 - train: epoch 0099, iter [01150, 01251], lr: 0.001122, loss: 0.4257
2022-09-28 12:28:40 - train: epoch 0099, iter [01160, 01251], lr: 0.001122, loss: 0.4143
2022-09-28 12:28:58 - train: epoch 0099, iter [01170, 01251], lr: 0.001122, loss: 0.4060
2022-09-28 12:29:16 - train: epoch 0099, iter [01180, 01251], lr: 0.001122, loss: 0.4134
2022-09-28 12:29:33 - train: epoch 0099, iter [01190, 01251], lr: 0.001122, loss: 0.4050
2022-09-28 12:29:51 - train: epoch 0099, iter [01200, 01251], lr: 0.001122, loss: 0.4056
2022-09-28 12:30:09 - train: epoch 0099, iter [01210, 01251], lr: 0.001122, loss: 0.4111
2022-09-28 12:30:27 - train: epoch 0099, iter [01220, 01251], lr: 0.001122, loss: 0.4054
2022-09-28 12:30:45 - train: epoch 0099, iter [01230, 01251], lr: 0.001122, loss: 0.4169
2022-09-28 12:31:03 - train: epoch 0099, iter [01240, 01251], lr: 0.001122, loss: 0.4135
2022-09-28 12:31:20 - train: epoch 0099, iter [01250, 01251], lr: 0.001122, loss: 0.4237
2022-09-28 12:31:24 - train: epoch 099, train_loss: 0.4134
2022-09-28 12:31:26 - until epoch: 099, best_loss: 0.4134
2022-09-28 12:31:26 - epoch 100 lr: 0.001122
2022-09-28 12:31:59 - train: epoch 0100, iter [00010, 01251], lr: 0.001122, loss: 0.4282
2022-09-28 12:32:17 - train: epoch 0100, iter [00020, 01251], lr: 0.001122, loss: 0.4101
2022-09-28 12:32:35 - train: epoch 0100, iter [00030, 01251], lr: 0.001122, loss: 0.4293
2022-09-28 12:32:53 - train: epoch 0100, iter [00040, 01251], lr: 0.001122, loss: 0.4445
2022-09-28 12:33:11 - train: epoch 0100, iter [00050, 01251], lr: 0.001122, loss: 0.3878
2022-09-28 12:33:29 - train: epoch 0100, iter [00060, 01251], lr: 0.001122, loss: 0.4290
2022-09-28 12:33:46 - train: epoch 0100, iter [00070, 01251], lr: 0.001122, loss: 0.3827
2022-09-28 12:34:04 - train: epoch 0100, iter [00080, 01251], lr: 0.001122, loss: 0.4070
2022-09-28 12:34:22 - train: epoch 0100, iter [00090, 01251], lr: 0.001122, loss: 0.4175
2022-09-28 12:34:40 - train: epoch 0100, iter [00100, 01251], lr: 0.001122, loss: 0.4119
2022-09-28 12:34:57 - train: epoch 0100, iter [00110, 01251], lr: 0.001122, loss: 0.4069
2022-09-28 12:35:15 - train: epoch 0100, iter [00120, 01251], lr: 0.001122, loss: 0.4130
2022-09-28 12:35:33 - train: epoch 0100, iter [00130, 01251], lr: 0.001122, loss: 0.4222
2022-09-28 12:35:51 - train: epoch 0100, iter [00140, 01251], lr: 0.001122, loss: 0.4092
2022-09-28 12:36:09 - train: epoch 0100, iter [00150, 01251], lr: 0.001122, loss: 0.4196
2022-09-28 12:36:27 - train: epoch 0100, iter [00160, 01251], lr: 0.001122, loss: 0.3985
2022-09-28 12:36:45 - train: epoch 0100, iter [00170, 01251], lr: 0.001122, loss: 0.3930
2022-09-28 12:37:03 - train: epoch 0100, iter [00180, 01251], lr: 0.001122, loss: 0.4053
2022-09-28 12:37:20 - train: epoch 0100, iter [00190, 01251], lr: 0.001122, loss: 0.4308
2022-09-28 12:37:38 - train: epoch 0100, iter [00200, 01251], lr: 0.001122, loss: 0.4180
2022-09-28 12:37:56 - train: epoch 0100, iter [00210, 01251], lr: 0.001122, loss: 0.4248
2022-09-28 12:38:14 - train: epoch 0100, iter [00220, 01251], lr: 0.001122, loss: 0.4153
2022-09-28 12:38:31 - train: epoch 0100, iter [00230, 01251], lr: 0.001122, loss: 0.4126
2022-09-28 12:38:49 - train: epoch 0100, iter [00240, 01251], lr: 0.001122, loss: 0.4077
2022-09-28 12:39:07 - train: epoch 0100, iter [00250, 01251], lr: 0.001122, loss: 0.4191
2022-09-28 12:39:25 - train: epoch 0100, iter [00260, 01251], lr: 0.001122, loss: 0.4015
2022-09-28 12:39:43 - train: epoch 0100, iter [00270, 01251], lr: 0.001122, loss: 0.4117
2022-09-28 12:40:01 - train: epoch 0100, iter [00280, 01251], lr: 0.001122, loss: 0.4041
2022-09-28 12:40:18 - train: epoch 0100, iter [00290, 01251], lr: 0.001122, loss: 0.4048
2022-09-28 12:40:36 - train: epoch 0100, iter [00300, 01251], lr: 0.001122, loss: 0.4046
2022-09-28 12:40:54 - train: epoch 0100, iter [00310, 01251], lr: 0.001122, loss: 0.4178
2022-09-28 12:41:12 - train: epoch 0100, iter [00320, 01251], lr: 0.001122, loss: 0.4150
2022-09-28 12:41:30 - train: epoch 0100, iter [00330, 01251], lr: 0.001122, loss: 0.4346
2022-09-28 12:41:48 - train: epoch 0100, iter [00340, 01251], lr: 0.001122, loss: 0.4200
2022-09-28 12:42:05 - train: epoch 0100, iter [00350, 01251], lr: 0.001121, loss: 0.4007
2022-09-28 12:42:23 - train: epoch 0100, iter [00360, 01251], lr: 0.001121, loss: 0.4117
2022-09-28 12:42:41 - train: epoch 0100, iter [00370, 01251], lr: 0.001121, loss: 0.4261
2022-09-28 12:42:59 - train: epoch 0100, iter [00380, 01251], lr: 0.001121, loss: 0.4091
2022-09-28 12:43:17 - train: epoch 0100, iter [00390, 01251], lr: 0.001121, loss: 0.4060
2022-09-28 12:43:35 - train: epoch 0100, iter [00400, 01251], lr: 0.001121, loss: 0.4030
2022-09-28 12:43:53 - train: epoch 0100, iter [00410, 01251], lr: 0.001121, loss: 0.4146
2022-09-28 12:44:10 - train: epoch 0100, iter [00420, 01251], lr: 0.001121, loss: 0.4094
2022-09-28 12:44:28 - train: epoch 0100, iter [00430, 01251], lr: 0.001121, loss: 0.4179
2022-09-28 12:44:46 - train: epoch 0100, iter [00440, 01251], lr: 0.001121, loss: 0.4081
2022-09-28 12:45:04 - train: epoch 0100, iter [00450, 01251], lr: 0.001121, loss: 0.4108
2022-09-28 12:45:22 - train: epoch 0100, iter [00460, 01251], lr: 0.001121, loss: 0.4172
2022-09-28 12:45:40 - train: epoch 0100, iter [00470, 01251], lr: 0.001121, loss: 0.4078
2022-09-28 12:45:58 - train: epoch 0100, iter [00480, 01251], lr: 0.001121, loss: 0.4085
2022-09-28 12:46:16 - train: epoch 0100, iter [00490, 01251], lr: 0.001121, loss: 0.4143
2022-09-28 12:46:34 - train: epoch 0100, iter [00500, 01251], lr: 0.001121, loss: 0.4305
2022-09-28 12:46:51 - train: epoch 0100, iter [00510, 01251], lr: 0.001121, loss: 0.3972
2022-09-28 12:47:09 - train: epoch 0100, iter [00520, 01251], lr: 0.001121, loss: 0.4101
2022-09-28 12:47:27 - train: epoch 0100, iter [00530, 01251], lr: 0.001121, loss: 0.3903
2022-09-28 12:47:45 - train: epoch 0100, iter [00540, 01251], lr: 0.001121, loss: 0.3909
2022-09-28 12:48:03 - train: epoch 0100, iter [00550, 01251], lr: 0.001121, loss: 0.4286
2022-09-28 12:48:21 - train: epoch 0100, iter [00560, 01251], lr: 0.001121, loss: 0.4228
2022-09-28 12:48:38 - train: epoch 0100, iter [00570, 01251], lr: 0.001121, loss: 0.3965
2022-09-28 12:48:56 - train: epoch 0100, iter [00580, 01251], lr: 0.001121, loss: 0.4052
2022-09-28 12:49:14 - train: epoch 0100, iter [00590, 01251], lr: 0.001121, loss: 0.4079
2022-09-28 12:49:32 - train: epoch 0100, iter [00600, 01251], lr: 0.001121, loss: 0.4133
2022-09-28 12:49:50 - train: epoch 0100, iter [00610, 01251], lr: 0.001121, loss: 0.4204
2022-09-28 12:50:08 - train: epoch 0100, iter [00620, 01251], lr: 0.001121, loss: 0.4012
2022-09-28 12:50:25 - train: epoch 0100, iter [00630, 01251], lr: 0.001121, loss: 0.4269
2022-09-28 12:50:43 - train: epoch 0100, iter [00640, 01251], lr: 0.001121, loss: 0.4063
2022-09-28 12:51:01 - train: epoch 0100, iter [00650, 01251], lr: 0.001121, loss: 0.4059
2022-09-28 12:51:19 - train: epoch 0100, iter [00660, 01251], lr: 0.001121, loss: 0.4090
2022-09-28 12:51:37 - train: epoch 0100, iter [00670, 01251], lr: 0.001121, loss: 0.3877
2022-09-28 12:51:55 - train: epoch 0100, iter [00680, 01251], lr: 0.001121, loss: 0.4128
2022-09-28 12:52:12 - train: epoch 0100, iter [00690, 01251], lr: 0.001121, loss: 0.4199
2022-09-28 12:52:30 - train: epoch 0100, iter [00700, 01251], lr: 0.001121, loss: 0.4052
2022-09-28 12:52:48 - train: epoch 0100, iter [00710, 01251], lr: 0.001121, loss: 0.4095
2022-09-28 12:53:06 - train: epoch 0100, iter [00720, 01251], lr: 0.001121, loss: 0.4029
2022-09-28 12:53:24 - train: epoch 0100, iter [00730, 01251], lr: 0.001121, loss: 0.4254
2022-09-28 12:53:42 - train: epoch 0100, iter [00740, 01251], lr: 0.001121, loss: 0.4138
2022-09-28 12:53:59 - train: epoch 0100, iter [00750, 01251], lr: 0.001121, loss: 0.4264
2022-09-28 12:54:17 - train: epoch 0100, iter [00760, 01251], lr: 0.001121, loss: 0.4144
2022-09-28 12:54:35 - train: epoch 0100, iter [00770, 01251], lr: 0.001121, loss: 0.4096
2022-09-28 12:54:53 - train: epoch 0100, iter [00780, 01251], lr: 0.001121, loss: 0.3946
2022-09-28 12:55:11 - train: epoch 0100, iter [00790, 01251], lr: 0.001121, loss: 0.4097
2022-09-28 12:55:29 - train: epoch 0100, iter [00800, 01251], lr: 0.001121, loss: 0.3979
2022-09-28 12:55:47 - train: epoch 0100, iter [00810, 01251], lr: 0.001121, loss: 0.4077
2022-09-28 12:56:05 - train: epoch 0100, iter [00820, 01251], lr: 0.001121, loss: 0.4163
2022-09-28 12:56:23 - train: epoch 0100, iter [00830, 01251], lr: 0.001120, loss: 0.3965
2022-09-28 12:56:41 - train: epoch 0100, iter [00840, 01251], lr: 0.001120, loss: 0.4093
2022-09-28 12:56:59 - train: epoch 0100, iter [00850, 01251], lr: 0.001120, loss: 0.4023
2022-09-28 12:57:16 - train: epoch 0100, iter [00860, 01251], lr: 0.001120, loss: 0.4053
2022-09-28 12:57:34 - train: epoch 0100, iter [00870, 01251], lr: 0.001120, loss: 0.4072
2022-09-28 12:57:52 - train: epoch 0100, iter [00880, 01251], lr: 0.001120, loss: 0.4071
2022-09-28 12:58:10 - train: epoch 0100, iter [00890, 01251], lr: 0.001120, loss: 0.4111
2022-09-28 12:58:28 - train: epoch 0100, iter [00900, 01251], lr: 0.001120, loss: 0.4199
2022-09-28 12:58:45 - train: epoch 0100, iter [00910, 01251], lr: 0.001120, loss: 0.4193
2022-09-28 12:59:03 - train: epoch 0100, iter [00920, 01251], lr: 0.001120, loss: 0.3978
2022-09-28 12:59:21 - train: epoch 0100, iter [00930, 01251], lr: 0.001120, loss: 0.4343
2022-09-28 12:59:39 - train: epoch 0100, iter [00940, 01251], lr: 0.001120, loss: 0.3982
2022-09-28 12:59:57 - train: epoch 0100, iter [00950, 01251], lr: 0.001120, loss: 0.4216
2022-09-28 13:00:15 - train: epoch 0100, iter [00960, 01251], lr: 0.001120, loss: 0.4037
2022-09-28 13:00:32 - train: epoch 0100, iter [00970, 01251], lr: 0.001120, loss: 0.4221
2022-09-28 13:00:50 - train: epoch 0100, iter [00980, 01251], lr: 0.001120, loss: 0.4313
2022-09-28 13:01:08 - train: epoch 0100, iter [00990, 01251], lr: 0.001120, loss: 0.3968
2022-09-28 13:01:26 - train: epoch 0100, iter [01000, 01251], lr: 0.001120, loss: 0.4071
2022-09-28 13:01:44 - train: epoch 0100, iter [01010, 01251], lr: 0.001120, loss: 0.4036
2022-09-28 13:02:02 - train: epoch 0100, iter [01020, 01251], lr: 0.001120, loss: 0.4286
2022-09-28 13:02:19 - train: epoch 0100, iter [01030, 01251], lr: 0.001120, loss: 0.4197
2022-09-28 13:02:37 - train: epoch 0100, iter [01040, 01251], lr: 0.001120, loss: 0.4234
2022-09-28 13:02:55 - train: epoch 0100, iter [01050, 01251], lr: 0.001120, loss: 0.4074
2022-09-28 13:03:12 - train: epoch 0100, iter [01060, 01251], lr: 0.001120, loss: 0.4173
2022-09-28 13:03:30 - train: epoch 0100, iter [01070, 01251], lr: 0.001120, loss: 0.4245
2022-09-28 13:03:48 - train: epoch 0100, iter [01080, 01251], lr: 0.001120, loss: 0.4192
2022-09-28 13:04:06 - train: epoch 0100, iter [01090, 01251], lr: 0.001120, loss: 0.4003
2022-09-28 13:04:24 - train: epoch 0100, iter [01100, 01251], lr: 0.001120, loss: 0.3998
2022-09-28 13:04:42 - train: epoch 0100, iter [01110, 01251], lr: 0.001120, loss: 0.4069
2022-09-28 13:05:00 - train: epoch 0100, iter [01120, 01251], lr: 0.001120, loss: 0.3981
2022-09-28 13:05:17 - train: epoch 0100, iter [01130, 01251], lr: 0.001120, loss: 0.4072
2022-09-28 13:05:35 - train: epoch 0100, iter [01140, 01251], lr: 0.001120, loss: 0.4212
2022-09-28 13:05:53 - train: epoch 0100, iter [01150, 01251], lr: 0.001120, loss: 0.4308
2022-09-28 13:06:11 - train: epoch 0100, iter [01160, 01251], lr: 0.001120, loss: 0.4122
2022-09-28 13:06:28 - train: epoch 0100, iter [01170, 01251], lr: 0.001120, loss: 0.3960
2022-09-28 13:06:47 - train: epoch 0100, iter [01180, 01251], lr: 0.001120, loss: 0.4177
2022-09-28 13:07:04 - train: epoch 0100, iter [01190, 01251], lr: 0.001120, loss: 0.4194
2022-09-28 13:07:22 - train: epoch 0100, iter [01200, 01251], lr: 0.001120, loss: 0.4149
2022-09-28 13:07:40 - train: epoch 0100, iter [01210, 01251], lr: 0.001120, loss: 0.4064
2022-09-28 13:07:58 - train: epoch 0100, iter [01220, 01251], lr: 0.001120, loss: 0.4137
2022-09-28 13:08:16 - train: epoch 0100, iter [01230, 01251], lr: 0.001120, loss: 0.4021
2022-09-28 13:08:33 - train: epoch 0100, iter [01240, 01251], lr: 0.001120, loss: 0.4181
2022-09-28 13:08:50 - train: epoch 0100, iter [01250, 01251], lr: 0.001120, loss: 0.4071
2022-09-28 13:08:54 - train: epoch 100, train_loss: 0.4133
2022-09-28 13:08:57 - until epoch: 100, best_loss: 0.4133
2022-09-28 13:08:57 - epoch 101 lr: 0.001120
2022-09-28 13:09:31 - train: epoch 0101, iter [00010, 01251], lr: 0.001120, loss: 0.4272
2022-09-28 13:09:49 - train: epoch 0101, iter [00020, 01251], lr: 0.001120, loss: 0.4004
2022-09-28 13:10:06 - train: epoch 0101, iter [00030, 01251], lr: 0.001120, loss: 0.4114
2022-09-28 13:10:24 - train: epoch 0101, iter [00040, 01251], lr: 0.001120, loss: 0.4116
2022-09-28 13:10:42 - train: epoch 0101, iter [00050, 01251], lr: 0.001120, loss: 0.4222
2022-09-28 13:11:00 - train: epoch 0101, iter [00060, 01251], lr: 0.001119, loss: 0.3933
2022-09-28 13:11:17 - train: epoch 0101, iter [00070, 01251], lr: 0.001119, loss: 0.3966
2022-09-28 13:11:35 - train: epoch 0101, iter [00080, 01251], lr: 0.001119, loss: 0.4022
2022-09-28 13:11:53 - train: epoch 0101, iter [00090, 01251], lr: 0.001119, loss: 0.4312
2022-09-28 13:12:10 - train: epoch 0101, iter [00100, 01251], lr: 0.001119, loss: 0.4056
2022-09-28 13:12:28 - train: epoch 0101, iter [00110, 01251], lr: 0.001119, loss: 0.4273
2022-09-28 13:12:46 - train: epoch 0101, iter [00120, 01251], lr: 0.001119, loss: 0.4101
2022-09-28 13:13:04 - train: epoch 0101, iter [00130, 01251], lr: 0.001119, loss: 0.4183
2022-09-28 13:13:21 - train: epoch 0101, iter [00140, 01251], lr: 0.001119, loss: 0.4186
2022-09-28 13:13:39 - train: epoch 0101, iter [00150, 01251], lr: 0.001119, loss: 0.4077
2022-09-28 13:13:57 - train: epoch 0101, iter [00160, 01251], lr: 0.001119, loss: 0.4098
2022-09-28 13:14:15 - train: epoch 0101, iter [00170, 01251], lr: 0.001119, loss: 0.3916
2022-09-28 13:14:32 - train: epoch 0101, iter [00180, 01251], lr: 0.001119, loss: 0.4145
2022-09-28 13:14:50 - train: epoch 0101, iter [00190, 01251], lr: 0.001119, loss: 0.4096
2022-09-28 13:15:08 - train: epoch 0101, iter [00200, 01251], lr: 0.001119, loss: 0.4001
2022-09-28 13:15:26 - train: epoch 0101, iter [00210, 01251], lr: 0.001119, loss: 0.4214
2022-09-28 13:15:43 - train: epoch 0101, iter [00220, 01251], lr: 0.001119, loss: 0.4028
2022-09-28 13:16:01 - train: epoch 0101, iter [00230, 01251], lr: 0.001119, loss: 0.4220
2022-09-28 13:16:19 - train: epoch 0101, iter [00240, 01251], lr: 0.001119, loss: 0.4101
2022-09-28 13:16:37 - train: epoch 0101, iter [00250, 01251], lr: 0.001119, loss: 0.4330
2022-09-28 13:16:54 - train: epoch 0101, iter [00260, 01251], lr: 0.001119, loss: 0.3989
2022-09-28 13:17:12 - train: epoch 0101, iter [00270, 01251], lr: 0.001119, loss: 0.4421
2022-09-28 13:17:30 - train: epoch 0101, iter [00280, 01251], lr: 0.001119, loss: 0.4116
2022-09-28 13:17:48 - train: epoch 0101, iter [00290, 01251], lr: 0.001119, loss: 0.3861
2022-09-28 13:18:06 - train: epoch 0101, iter [00300, 01251], lr: 0.001119, loss: 0.4195
2022-09-28 13:18:24 - train: epoch 0101, iter [00310, 01251], lr: 0.001119, loss: 0.4065
2022-09-28 13:18:42 - train: epoch 0101, iter [00320, 01251], lr: 0.001119, loss: 0.4097
2022-09-28 13:18:59 - train: epoch 0101, iter [00330, 01251], lr: 0.001119, loss: 0.4081
2022-09-28 13:19:17 - train: epoch 0101, iter [00340, 01251], lr: 0.001119, loss: 0.4072
2022-09-28 13:19:35 - train: epoch 0101, iter [00350, 01251], lr: 0.001119, loss: 0.4190
2022-09-28 13:19:53 - train: epoch 0101, iter [00360, 01251], lr: 0.001119, loss: 0.3982
2022-09-28 13:20:10 - train: epoch 0101, iter [00370, 01251], lr: 0.001119, loss: 0.4056
2022-09-28 13:20:28 - train: epoch 0101, iter [00380, 01251], lr: 0.001119, loss: 0.4079
2022-09-28 13:20:46 - train: epoch 0101, iter [00390, 01251], lr: 0.001119, loss: 0.4180
2022-09-28 13:21:03 - train: epoch 0101, iter [00400, 01251], lr: 0.001119, loss: 0.4308
2022-09-28 13:21:21 - train: epoch 0101, iter [00410, 01251], lr: 0.001119, loss: 0.4052
2022-09-28 13:21:39 - train: epoch 0101, iter [00420, 01251], lr: 0.001119, loss: 0.4024
2022-09-28 13:21:57 - train: epoch 0101, iter [00430, 01251], lr: 0.001119, loss: 0.4139
2022-09-28 13:22:14 - train: epoch 0101, iter [00440, 01251], lr: 0.001119, loss: 0.4144
2022-09-28 13:22:32 - train: epoch 0101, iter [00450, 01251], lr: 0.001119, loss: 0.4070
2022-09-28 13:22:50 - train: epoch 0101, iter [00460, 01251], lr: 0.001119, loss: 0.4034
2022-09-28 13:23:07 - train: epoch 0101, iter [00470, 01251], lr: 0.001119, loss: 0.4103
2022-09-28 13:23:25 - train: epoch 0101, iter [00480, 01251], lr: 0.001119, loss: 0.4251
2022-09-28 13:23:43 - train: epoch 0101, iter [00490, 01251], lr: 0.001119, loss: 0.4067
2022-09-28 13:24:01 - train: epoch 0101, iter [00500, 01251], lr: 0.001119, loss: 0.4068
2022-09-28 13:24:19 - train: epoch 0101, iter [00510, 01251], lr: 0.001119, loss: 0.4265
2022-09-28 13:24:37 - train: epoch 0101, iter [00520, 01251], lr: 0.001119, loss: 0.4004
2022-09-28 13:24:54 - train: epoch 0101, iter [00530, 01251], lr: 0.001119, loss: 0.3936
2022-09-28 13:25:12 - train: epoch 0101, iter [00540, 01251], lr: 0.001118, loss: 0.4097
2022-09-28 13:25:30 - train: epoch 0101, iter [00550, 01251], lr: 0.001118, loss: 0.4175
2022-09-28 13:25:48 - train: epoch 0101, iter [00560, 01251], lr: 0.001118, loss: 0.4045
2022-09-28 13:26:05 - train: epoch 0101, iter [00570, 01251], lr: 0.001118, loss: 0.4200
2022-09-28 13:26:23 - train: epoch 0101, iter [00580, 01251], lr: 0.001118, loss: 0.4042
2022-09-28 13:26:41 - train: epoch 0101, iter [00590, 01251], lr: 0.001118, loss: 0.4041
2022-09-28 13:26:59 - train: epoch 0101, iter [00600, 01251], lr: 0.001118, loss: 0.4151
2022-09-28 13:27:16 - train: epoch 0101, iter [00610, 01251], lr: 0.001118, loss: 0.4243
2022-09-28 13:27:34 - train: epoch 0101, iter [00620, 01251], lr: 0.001118, loss: 0.4222
2022-09-28 13:27:52 - train: epoch 0101, iter [00630, 01251], lr: 0.001118, loss: 0.4283
2022-09-28 13:28:10 - train: epoch 0101, iter [00640, 01251], lr: 0.001118, loss: 0.4128
2022-09-28 13:28:28 - train: epoch 0101, iter [00650, 01251], lr: 0.001118, loss: 0.4203
2022-09-28 13:28:45 - train: epoch 0101, iter [00660, 01251], lr: 0.001118, loss: 0.3992
2022-09-28 13:29:03 - train: epoch 0101, iter [00670, 01251], lr: 0.001118, loss: 0.4033
2022-09-28 13:29:21 - train: epoch 0101, iter [00680, 01251], lr: 0.001118, loss: 0.4152
2022-09-28 13:29:39 - train: epoch 0101, iter [00690, 01251], lr: 0.001118, loss: 0.4221
2022-09-28 13:29:57 - train: epoch 0101, iter [00700, 01251], lr: 0.001118, loss: 0.4278
2022-09-28 13:30:15 - train: epoch 0101, iter [00710, 01251], lr: 0.001118, loss: 0.4366
2022-09-28 13:30:32 - train: epoch 0101, iter [00720, 01251], lr: 0.001118, loss: 0.4126
2022-09-28 13:30:50 - train: epoch 0101, iter [00730, 01251], lr: 0.001118, loss: 0.4189
2022-09-28 13:31:08 - train: epoch 0101, iter [00740, 01251], lr: 0.001118, loss: 0.3880
2022-09-28 13:31:26 - train: epoch 0101, iter [00750, 01251], lr: 0.001118, loss: 0.4093
2022-09-28 13:31:43 - train: epoch 0101, iter [00760, 01251], lr: 0.001118, loss: 0.4024
2022-09-28 13:32:01 - train: epoch 0101, iter [00770, 01251], lr: 0.001118, loss: 0.3946
2022-09-28 13:32:19 - train: epoch 0101, iter [00780, 01251], lr: 0.001118, loss: 0.4186
2022-09-28 13:32:36 - train: epoch 0101, iter [00790, 01251], lr: 0.001118, loss: 0.4353
2022-09-28 13:32:55 - train: epoch 0101, iter [00800, 01251], lr: 0.001118, loss: 0.4022
2022-09-28 13:33:12 - train: epoch 0101, iter [00810, 01251], lr: 0.001118, loss: 0.4202
2022-09-28 13:33:30 - train: epoch 0101, iter [00820, 01251], lr: 0.001118, loss: 0.4053
2022-09-28 13:33:48 - train: epoch 0101, iter [00830, 01251], lr: 0.001118, loss: 0.4169
2022-09-28 13:34:06 - train: epoch 0101, iter [00840, 01251], lr: 0.001118, loss: 0.4093
2022-09-28 13:34:24 - train: epoch 0101, iter [00850, 01251], lr: 0.001118, loss: 0.4075
2022-09-28 13:34:41 - train: epoch 0101, iter [00860, 01251], lr: 0.001118, loss: 0.4253
2022-09-28 13:34:59 - train: epoch 0101, iter [00870, 01251], lr: 0.001118, loss: 0.4206
2022-09-28 13:35:17 - train: epoch 0101, iter [00880, 01251], lr: 0.001118, loss: 0.4188
2022-09-28 13:35:35 - train: epoch 0101, iter [00890, 01251], lr: 0.001118, loss: 0.4088
2022-09-28 13:35:52 - train: epoch 0101, iter [00900, 01251], lr: 0.001118, loss: 0.4075
2022-09-28 13:36:10 - train: epoch 0101, iter [00910, 01251], lr: 0.001118, loss: 0.4271
2022-09-28 13:36:28 - train: epoch 0101, iter [00920, 01251], lr: 0.001118, loss: 0.4200
2022-09-28 13:36:46 - train: epoch 0101, iter [00930, 01251], lr: 0.001118, loss: 0.4170
2022-09-28 13:37:03 - train: epoch 0101, iter [00940, 01251], lr: 0.001118, loss: 0.4214
2022-09-28 13:37:21 - train: epoch 0101, iter [00950, 01251], lr: 0.001118, loss: 0.4377
2022-09-28 13:37:39 - train: epoch 0101, iter [00960, 01251], lr: 0.001118, loss: 0.4247
2022-09-28 13:37:57 - train: epoch 0101, iter [00970, 01251], lr: 0.001118, loss: 0.4058
2022-09-28 13:38:15 - train: epoch 0101, iter [00980, 01251], lr: 0.001118, loss: 0.4163
2022-09-28 13:38:32 - train: epoch 0101, iter [00990, 01251], lr: 0.001118, loss: 0.4119
2022-09-28 13:38:50 - train: epoch 0101, iter [01000, 01251], lr: 0.001118, loss: 0.4146
2022-09-28 13:39:08 - train: epoch 0101, iter [01010, 01251], lr: 0.001117, loss: 0.4312
2022-09-28 13:39:26 - train: epoch 0101, iter [01020, 01251], lr: 0.001117, loss: 0.4069
2022-09-28 13:39:43 - train: epoch 0101, iter [01030, 01251], lr: 0.001117, loss: 0.4102
2022-09-28 13:40:01 - train: epoch 0101, iter [01040, 01251], lr: 0.001117, loss: 0.4140
2022-09-28 13:40:19 - train: epoch 0101, iter [01050, 01251], lr: 0.001117, loss: 0.4115
2022-09-28 13:40:37 - train: epoch 0101, iter [01060, 01251], lr: 0.001117, loss: 0.4072
2022-09-28 13:40:54 - train: epoch 0101, iter [01070, 01251], lr: 0.001117, loss: 0.4053
2022-09-28 13:41:12 - train: epoch 0101, iter [01080, 01251], lr: 0.001117, loss: 0.4158
2022-09-28 13:41:30 - train: epoch 0101, iter [01090, 01251], lr: 0.001117, loss: 0.4111
2022-09-28 13:41:48 - train: epoch 0101, iter [01100, 01251], lr: 0.001117, loss: 0.4280
2022-09-28 13:42:06 - train: epoch 0101, iter [01110, 01251], lr: 0.001117, loss: 0.4252
2022-09-28 13:42:24 - train: epoch 0101, iter [01120, 01251], lr: 0.001117, loss: 0.4151
2022-09-28 13:42:41 - train: epoch 0101, iter [01130, 01251], lr: 0.001117, loss: 0.4196
2022-09-28 13:42:59 - train: epoch 0101, iter [01140, 01251], lr: 0.001117, loss: 0.4227
2022-09-28 13:43:17 - train: epoch 0101, iter [01150, 01251], lr: 0.001117, loss: 0.4130
2022-09-28 13:43:35 - train: epoch 0101, iter [01160, 01251], lr: 0.001117, loss: 0.4206
2022-09-28 13:43:53 - train: epoch 0101, iter [01170, 01251], lr: 0.001117, loss: 0.4184
2022-09-28 13:44:10 - train: epoch 0101, iter [01180, 01251], lr: 0.001117, loss: 0.4320
2022-09-28 13:44:28 - train: epoch 0101, iter [01190, 01251], lr: 0.001117, loss: 0.4162
2022-09-28 13:44:46 - train: epoch 0101, iter [01200, 01251], lr: 0.001117, loss: 0.4151
2022-09-28 13:45:04 - train: epoch 0101, iter [01210, 01251], lr: 0.001117, loss: 0.4144
2022-09-28 13:45:21 - train: epoch 0101, iter [01220, 01251], lr: 0.001117, loss: 0.4231
2022-09-28 13:45:39 - train: epoch 0101, iter [01230, 01251], lr: 0.001117, loss: 0.4090
2022-09-28 13:45:57 - train: epoch 0101, iter [01240, 01251], lr: 0.001117, loss: 0.4241
2022-09-28 13:46:14 - train: epoch 0101, iter [01250, 01251], lr: 0.001117, loss: 0.4133
2022-09-28 13:46:18 - train: epoch 101, train_loss: 0.4133
2022-09-28 13:46:20 - until epoch: 101, best_loss: 0.4133
2022-09-28 13:46:20 - epoch 102 lr: 0.001117
2022-09-28 13:46:53 - train: epoch 0102, iter [00010, 01251], lr: 0.001117, loss: 0.4012
2022-09-28 13:47:11 - train: epoch 0102, iter [00020, 01251], lr: 0.001117, loss: 0.4302
2022-09-28 13:47:28 - train: epoch 0102, iter [00030, 01251], lr: 0.001117, loss: 0.4151
2022-09-28 13:47:46 - train: epoch 0102, iter [00040, 01251], lr: 0.001117, loss: 0.4100
2022-09-28 13:48:04 - train: epoch 0102, iter [00050, 01251], lr: 0.001117, loss: 0.4298
2022-09-28 13:48:22 - train: epoch 0102, iter [00060, 01251], lr: 0.001117, loss: 0.4317
2022-09-28 13:48:39 - train: epoch 0102, iter [00070, 01251], lr: 0.001117, loss: 0.4021
2022-09-28 13:48:57 - train: epoch 0102, iter [00080, 01251], lr: 0.001117, loss: 0.4146
2022-09-28 13:49:15 - train: epoch 0102, iter [00090, 01251], lr: 0.001117, loss: 0.4158
2022-09-28 13:49:33 - train: epoch 0102, iter [00100, 01251], lr: 0.001117, loss: 0.3933
2022-09-28 13:49:51 - train: epoch 0102, iter [00110, 01251], lr: 0.001117, loss: 0.4153
2022-09-28 13:50:08 - train: epoch 0102, iter [00120, 01251], lr: 0.001117, loss: 0.4017
2022-09-28 13:50:26 - train: epoch 0102, iter [00130, 01251], lr: 0.001117, loss: 0.4328
2022-09-28 13:50:44 - train: epoch 0102, iter [00140, 01251], lr: 0.001117, loss: 0.4226
2022-09-28 13:51:02 - train: epoch 0102, iter [00150, 01251], lr: 0.001117, loss: 0.4167
2022-09-28 13:51:19 - train: epoch 0102, iter [00160, 01251], lr: 0.001117, loss: 0.4118
2022-09-28 13:51:37 - train: epoch 0102, iter [00170, 01251], lr: 0.001117, loss: 0.4333
2022-09-28 13:51:55 - train: epoch 0102, iter [00180, 01251], lr: 0.001117, loss: 0.4162
2022-09-28 13:52:13 - train: epoch 0102, iter [00190, 01251], lr: 0.001117, loss: 0.4145
2022-09-28 13:52:31 - train: epoch 0102, iter [00200, 01251], lr: 0.001117, loss: 0.4017
2022-09-28 13:52:49 - train: epoch 0102, iter [00210, 01251], lr: 0.001117, loss: 0.4201
2022-09-28 13:53:06 - train: epoch 0102, iter [00220, 01251], lr: 0.001117, loss: 0.3956
2022-09-28 13:53:24 - train: epoch 0102, iter [00230, 01251], lr: 0.001116, loss: 0.3861
2022-09-28 13:53:42 - train: epoch 0102, iter [00240, 01251], lr: 0.001116, loss: 0.4037
2022-09-28 13:54:00 - train: epoch 0102, iter [00250, 01251], lr: 0.001116, loss: 0.4121
2022-09-28 13:54:17 - train: epoch 0102, iter [00260, 01251], lr: 0.001116, loss: 0.3886
2022-09-28 13:54:35 - train: epoch 0102, iter [00270, 01251], lr: 0.001116, loss: 0.4285
2022-09-28 13:54:53 - train: epoch 0102, iter [00280, 01251], lr: 0.001116, loss: 0.4232
2022-09-28 13:55:11 - train: epoch 0102, iter [00290, 01251], lr: 0.001116, loss: 0.4049
2022-09-28 13:55:28 - train: epoch 0102, iter [00300, 01251], lr: 0.001116, loss: 0.4096
2022-09-28 13:55:46 - train: epoch 0102, iter [00310, 01251], lr: 0.001116, loss: 0.4338
2022-09-28 13:56:04 - train: epoch 0102, iter [00320, 01251], lr: 0.001116, loss: 0.4085
2022-09-28 13:56:22 - train: epoch 0102, iter [00330, 01251], lr: 0.001116, loss: 0.4310
2022-09-28 13:56:40 - train: epoch 0102, iter [00340, 01251], lr: 0.001116, loss: 0.4061
2022-09-28 13:56:57 - train: epoch 0102, iter [00350, 01251], lr: 0.001116, loss: 0.4028
2022-09-28 13:57:15 - train: epoch 0102, iter [00360, 01251], lr: 0.001116, loss: 0.4071
2022-09-28 13:57:33 - train: epoch 0102, iter [00370, 01251], lr: 0.001116, loss: 0.4107
2022-09-28 13:57:51 - train: epoch 0102, iter [00380, 01251], lr: 0.001116, loss: 0.4119
2022-09-28 13:58:09 - train: epoch 0102, iter [00390, 01251], lr: 0.001116, loss: 0.4136
2022-09-28 13:58:27 - train: epoch 0102, iter [00400, 01251], lr: 0.001116, loss: 0.3962
2022-09-28 13:58:44 - train: epoch 0102, iter [00410, 01251], lr: 0.001116, loss: 0.4117
2022-09-28 13:59:02 - train: epoch 0102, iter [00420, 01251], lr: 0.001116, loss: 0.3920
2022-09-28 13:59:20 - train: epoch 0102, iter [00430, 01251], lr: 0.001116, loss: 0.4088
2022-09-28 13:59:38 - train: epoch 0102, iter [00440, 01251], lr: 0.001116, loss: 0.4147
2022-09-28 13:59:56 - train: epoch 0102, iter [00450, 01251], lr: 0.001116, loss: 0.4226
2022-09-28 14:00:13 - train: epoch 0102, iter [00460, 01251], lr: 0.001116, loss: 0.4270
2022-09-28 14:00:31 - train: epoch 0102, iter [00470, 01251], lr: 0.001116, loss: 0.4170
2022-09-28 14:00:49 - train: epoch 0102, iter [00480, 01251], lr: 0.001116, loss: 0.4366
2022-09-28 14:01:07 - train: epoch 0102, iter [00490, 01251], lr: 0.001116, loss: 0.4285
2022-09-28 14:01:24 - train: epoch 0102, iter [00500, 01251], lr: 0.001116, loss: 0.4050
2022-09-28 14:01:42 - train: epoch 0102, iter [00510, 01251], lr: 0.001116, loss: 0.4178
2022-09-28 14:02:00 - train: epoch 0102, iter [00520, 01251], lr: 0.001116, loss: 0.4235
2022-09-28 14:02:18 - train: epoch 0102, iter [00530, 01251], lr: 0.001116, loss: 0.4270
2022-09-28 14:02:36 - train: epoch 0102, iter [00540, 01251], lr: 0.001116, loss: 0.3849
2022-09-28 14:02:53 - train: epoch 0102, iter [00550, 01251], lr: 0.001116, loss: 0.4043
2022-09-28 14:03:11 - train: epoch 0102, iter [00560, 01251], lr: 0.001116, loss: 0.4232
2022-09-28 14:03:29 - train: epoch 0102, iter [00570, 01251], lr: 0.001116, loss: 0.4060
2022-09-28 14:03:46 - train: epoch 0102, iter [00580, 01251], lr: 0.001116, loss: 0.4114
2022-09-28 14:04:04 - train: epoch 0102, iter [00590, 01251], lr: 0.001116, loss: 0.4246
2022-09-28 14:04:22 - train: epoch 0102, iter [00600, 01251], lr: 0.001116, loss: 0.4094
2022-09-28 14:04:40 - train: epoch 0102, iter [00610, 01251], lr: 0.001116, loss: 0.4109
2022-09-28 14:04:58 - train: epoch 0102, iter [00620, 01251], lr: 0.001116, loss: 0.4181
2022-09-28 14:05:15 - train: epoch 0102, iter [00630, 01251], lr: 0.001116, loss: 0.4115
2022-09-28 14:05:33 - train: epoch 0102, iter [00640, 01251], lr: 0.001116, loss: 0.4011
2022-09-28 14:05:51 - train: epoch 0102, iter [00650, 01251], lr: 0.001116, loss: 0.4065
2022-09-28 14:06:09 - train: epoch 0102, iter [00660, 01251], lr: 0.001116, loss: 0.4243
2022-09-28 14:06:27 - train: epoch 0102, iter [00670, 01251], lr: 0.001116, loss: 0.4173
2022-09-28 14:06:44 - train: epoch 0102, iter [00680, 01251], lr: 0.001116, loss: 0.4126
2022-09-28 14:07:02 - train: epoch 0102, iter [00690, 01251], lr: 0.001116, loss: 0.4146
2022-09-28 14:07:20 - train: epoch 0102, iter [00700, 01251], lr: 0.001115, loss: 0.4069
2022-09-28 14:07:37 - train: epoch 0102, iter [00710, 01251], lr: 0.001115, loss: 0.4169
2022-09-28 14:07:55 - train: epoch 0102, iter [00720, 01251], lr: 0.001115, loss: 0.4310
2022-09-28 14:08:13 - train: epoch 0102, iter [00730, 01251], lr: 0.001115, loss: 0.4110
2022-09-28 14:08:31 - train: epoch 0102, iter [00740, 01251], lr: 0.001115, loss: 0.4233
2022-09-28 14:08:48 - train: epoch 0102, iter [00750, 01251], lr: 0.001115, loss: 0.4227
2022-09-28 14:09:06 - train: epoch 0102, iter [00760, 01251], lr: 0.001115, loss: 0.4247
2022-09-28 14:09:24 - train: epoch 0102, iter [00770, 01251], lr: 0.001115, loss: 0.4158
2022-09-28 14:09:42 - train: epoch 0102, iter [00780, 01251], lr: 0.001115, loss: 0.4155
2022-09-28 14:09:59 - train: epoch 0102, iter [00790, 01251], lr: 0.001115, loss: 0.4231
2022-09-28 14:10:17 - train: epoch 0102, iter [00800, 01251], lr: 0.001115, loss: 0.4019
2022-09-28 14:10:35 - train: epoch 0102, iter [00810, 01251], lr: 0.001115, loss: 0.4096
2022-09-28 14:10:53 - train: epoch 0102, iter [00820, 01251], lr: 0.001115, loss: 0.4059
2022-09-28 14:11:11 - train: epoch 0102, iter [00830, 01251], lr: 0.001115, loss: 0.4093
2022-09-28 14:11:29 - train: epoch 0102, iter [00840, 01251], lr: 0.001115, loss: 0.4370
2022-09-28 14:11:46 - train: epoch 0102, iter [00850, 01251], lr: 0.001115, loss: 0.4221
2022-09-28 14:12:04 - train: epoch 0102, iter [00860, 01251], lr: 0.001115, loss: 0.4125
2022-09-28 14:12:22 - train: epoch 0102, iter [00870, 01251], lr: 0.001115, loss: 0.3963
2022-09-28 14:12:40 - train: epoch 0102, iter [00880, 01251], lr: 0.001115, loss: 0.4242
2022-09-28 14:12:58 - train: epoch 0102, iter [00890, 01251], lr: 0.001115, loss: 0.4178
2022-09-28 14:13:16 - train: epoch 0102, iter [00900, 01251], lr: 0.001115, loss: 0.4095
2022-09-28 14:13:33 - train: epoch 0102, iter [00910, 01251], lr: 0.001115, loss: 0.4511
2022-09-28 14:13:51 - train: epoch 0102, iter [00920, 01251], lr: 0.001115, loss: 0.4143
2022-09-28 14:14:09 - train: epoch 0102, iter [00930, 01251], lr: 0.001115, loss: 0.4032
2022-09-28 14:14:27 - train: epoch 0102, iter [00940, 01251], lr: 0.001115, loss: 0.3987
2022-09-28 14:14:45 - train: epoch 0102, iter [00950, 01251], lr: 0.001115, loss: 0.4114
2022-09-28 14:15:03 - train: epoch 0102, iter [00960, 01251], lr: 0.001115, loss: 0.4235
2022-09-28 14:15:20 - train: epoch 0102, iter [00970, 01251], lr: 0.001115, loss: 0.4152
2022-09-28 14:15:38 - train: epoch 0102, iter [00980, 01251], lr: 0.001115, loss: 0.4049
2022-09-28 14:15:56 - train: epoch 0102, iter [00990, 01251], lr: 0.001115, loss: 0.4154
2022-09-28 14:16:14 - train: epoch 0102, iter [01000, 01251], lr: 0.001115, loss: 0.4259
2022-09-28 14:16:32 - train: epoch 0102, iter [01010, 01251], lr: 0.001115, loss: 0.4170
2022-09-28 14:16:49 - train: epoch 0102, iter [01020, 01251], lr: 0.001115, loss: 0.4095
2022-09-28 14:17:07 - train: epoch 0102, iter [01030, 01251], lr: 0.001115, loss: 0.4001
2022-09-28 14:17:25 - train: epoch 0102, iter [01040, 01251], lr: 0.001115, loss: 0.4121
2022-09-28 14:17:43 - train: epoch 0102, iter [01050, 01251], lr: 0.001115, loss: 0.4195
2022-09-28 14:18:01 - train: epoch 0102, iter [01060, 01251], lr: 0.001115, loss: 0.4243
2022-09-28 14:18:18 - train: epoch 0102, iter [01070, 01251], lr: 0.001115, loss: 0.3967
2022-09-28 14:18:36 - train: epoch 0102, iter [01080, 01251], lr: 0.001115, loss: 0.3962
2022-09-28 14:18:54 - train: epoch 0102, iter [01090, 01251], lr: 0.001115, loss: 0.4297
2022-09-28 14:19:12 - train: epoch 0102, iter [01100, 01251], lr: 0.001115, loss: 0.4255
2022-09-28 14:19:29 - train: epoch 0102, iter [01110, 01251], lr: 0.001115, loss: 0.4262
2022-09-28 14:19:47 - train: epoch 0102, iter [01120, 01251], lr: 0.001115, loss: 0.4017
2022-09-28 14:20:05 - train: epoch 0102, iter [01130, 01251], lr: 0.001115, loss: 0.4149
2022-09-28 14:20:23 - train: epoch 0102, iter [01140, 01251], lr: 0.001115, loss: 0.4084
2022-09-28 14:20:40 - train: epoch 0102, iter [01150, 01251], lr: 0.001115, loss: 0.4062
2022-09-28 14:20:58 - train: epoch 0102, iter [01160, 01251], lr: 0.001114, loss: 0.4167
2022-09-28 14:21:16 - train: epoch 0102, iter [01170, 01251], lr: 0.001114, loss: 0.4185
2022-09-28 14:21:34 - train: epoch 0102, iter [01180, 01251], lr: 0.001114, loss: 0.4398
2022-09-28 14:21:51 - train: epoch 0102, iter [01190, 01251], lr: 0.001114, loss: 0.4266
2022-09-28 14:22:09 - train: epoch 0102, iter [01200, 01251], lr: 0.001114, loss: 0.4179
2022-09-28 14:22:27 - train: epoch 0102, iter [01210, 01251], lr: 0.001114, loss: 0.4126
2022-09-28 14:22:45 - train: epoch 0102, iter [01220, 01251], lr: 0.001114, loss: 0.4300
2022-09-28 14:23:03 - train: epoch 0102, iter [01230, 01251], lr: 0.001114, loss: 0.4171
2022-09-28 14:23:21 - train: epoch 0102, iter [01240, 01251], lr: 0.001114, loss: 0.4184
2022-09-28 14:23:38 - train: epoch 0102, iter [01250, 01251], lr: 0.001114, loss: 0.4145
2022-09-28 14:23:42 - train: epoch 102, train_loss: 0.4132
2022-09-28 14:23:44 - until epoch: 102, best_loss: 0.4132
2022-09-28 14:23:44 - epoch 103 lr: 0.001114
2022-09-28 14:24:18 - train: epoch 0103, iter [00010, 01251], lr: 0.001114, loss: 0.4116
2022-09-28 14:24:35 - train: epoch 0103, iter [00020, 01251], lr: 0.001114, loss: 0.4253
2022-09-28 14:24:53 - train: epoch 0103, iter [00030, 01251], lr: 0.001114, loss: 0.4180
2022-09-28 14:25:11 - train: epoch 0103, iter [00040, 01251], lr: 0.001114, loss: 0.4041
2022-09-28 14:25:29 - train: epoch 0103, iter [00050, 01251], lr: 0.001114, loss: 0.3936
2022-09-28 14:25:46 - train: epoch 0103, iter [00060, 01251], lr: 0.001114, loss: 0.4145
2022-09-28 14:26:04 - train: epoch 0103, iter [00070, 01251], lr: 0.001114, loss: 0.4247
2022-09-28 14:26:22 - train: epoch 0103, iter [00080, 01251], lr: 0.001114, loss: 0.3982
2022-09-28 14:26:40 - train: epoch 0103, iter [00090, 01251], lr: 0.001114, loss: 0.4001
2022-09-28 14:26:58 - train: epoch 0103, iter [00100, 01251], lr: 0.001114, loss: 0.3980
2022-09-28 14:27:15 - train: epoch 0103, iter [00110, 01251], lr: 0.001114, loss: 0.4216
2022-09-28 14:27:33 - train: epoch 0103, iter [00120, 01251], lr: 0.001114, loss: 0.4084
2022-09-28 14:27:51 - train: epoch 0103, iter [00130, 01251], lr: 0.001114, loss: 0.4242
2022-09-28 14:28:09 - train: epoch 0103, iter [00140, 01251], lr: 0.001114, loss: 0.4203
2022-09-28 14:28:26 - train: epoch 0103, iter [00150, 01251], lr: 0.001114, loss: 0.4171
2022-09-28 14:28:44 - train: epoch 0103, iter [00160, 01251], lr: 0.001114, loss: 0.4321
2022-09-28 14:29:02 - train: epoch 0103, iter [00170, 01251], lr: 0.001114, loss: 0.4254
2022-09-28 14:29:20 - train: epoch 0103, iter [00180, 01251], lr: 0.001114, loss: 0.4218
2022-09-28 14:29:37 - train: epoch 0103, iter [00190, 01251], lr: 0.001114, loss: 0.4181
2022-09-28 14:29:55 - train: epoch 0103, iter [00200, 01251], lr: 0.001114, loss: 0.4279
2022-09-28 14:30:13 - train: epoch 0103, iter [00210, 01251], lr: 0.001114, loss: 0.4042
2022-09-28 14:30:31 - train: epoch 0103, iter [00220, 01251], lr: 0.001114, loss: 0.4166
2022-09-28 14:30:49 - train: epoch 0103, iter [00230, 01251], lr: 0.001114, loss: 0.3887
2022-09-28 14:31:06 - train: epoch 0103, iter [00240, 01251], lr: 0.001114, loss: 0.4102
2022-09-28 14:31:24 - train: epoch 0103, iter [00250, 01251], lr: 0.001114, loss: 0.4188
2022-09-28 14:31:42 - train: epoch 0103, iter [00260, 01251], lr: 0.001114, loss: 0.4172
2022-09-28 14:32:00 - train: epoch 0103, iter [00270, 01251], lr: 0.001114, loss: 0.4199
2022-09-28 14:32:18 - train: epoch 0103, iter [00280, 01251], lr: 0.001114, loss: 0.4390
2022-09-28 14:32:35 - train: epoch 0103, iter [00290, 01251], lr: 0.001114, loss: 0.4072
2022-09-28 14:32:53 - train: epoch 0103, iter [00300, 01251], lr: 0.001114, loss: 0.3919
2022-09-28 14:33:11 - train: epoch 0103, iter [00310, 01251], lr: 0.001114, loss: 0.4212
2022-09-28 14:33:28 - train: epoch 0103, iter [00320, 01251], lr: 0.001114, loss: 0.3980
2022-09-28 14:33:46 - train: epoch 0103, iter [00330, 01251], lr: 0.001114, loss: 0.4282
2022-09-28 14:34:04 - train: epoch 0103, iter [00340, 01251], lr: 0.001114, loss: 0.4250
2022-09-28 14:34:21 - train: epoch 0103, iter [00350, 01251], lr: 0.001114, loss: 0.4280
2022-09-28 14:34:39 - train: epoch 0103, iter [00360, 01251], lr: 0.001114, loss: 0.4237
2022-09-28 14:34:57 - train: epoch 0103, iter [00370, 01251], lr: 0.001114, loss: 0.4409
2022-09-28 14:35:15 - train: epoch 0103, iter [00380, 01251], lr: 0.001113, loss: 0.3807
2022-09-28 14:35:33 - train: epoch 0103, iter [00390, 01251], lr: 0.001113, loss: 0.4095
2022-09-28 14:35:50 - train: epoch 0103, iter [00400, 01251], lr: 0.001113, loss: 0.4292
2022-09-28 14:36:08 - train: epoch 0103, iter [00410, 01251], lr: 0.001113, loss: 0.4312
2022-09-28 14:36:26 - train: epoch 0103, iter [00420, 01251], lr: 0.001113, loss: 0.4147
2022-09-28 14:36:44 - train: epoch 0103, iter [00430, 01251], lr: 0.001113, loss: 0.4268
2022-09-28 14:37:02 - train: epoch 0103, iter [00440, 01251], lr: 0.001113, loss: 0.4138
2022-09-28 14:37:19 - train: epoch 0103, iter [00450, 01251], lr: 0.001113, loss: 0.4109
2022-09-28 14:37:37 - train: epoch 0103, iter [00460, 01251], lr: 0.001113, loss: 0.4138
2022-09-28 14:37:55 - train: epoch 0103, iter [00470, 01251], lr: 0.001113, loss: 0.4151
2022-09-28 14:38:13 - train: epoch 0103, iter [00480, 01251], lr: 0.001113, loss: 0.4040
2022-09-28 14:38:31 - train: epoch 0103, iter [00490, 01251], lr: 0.001113, loss: 0.4270
2022-09-28 14:38:49 - train: epoch 0103, iter [00500, 01251], lr: 0.001113, loss: 0.4172
2022-09-28 14:39:06 - train: epoch 0103, iter [00510, 01251], lr: 0.001113, loss: 0.4201
2022-09-28 14:39:24 - train: epoch 0103, iter [00520, 01251], lr: 0.001113, loss: 0.4189
2022-09-28 14:39:42 - train: epoch 0103, iter [00530, 01251], lr: 0.001113, loss: 0.4326
2022-09-28 14:40:00 - train: epoch 0103, iter [00540, 01251], lr: 0.001113, loss: 0.4133
2022-09-28 14:40:17 - train: epoch 0103, iter [00550, 01251], lr: 0.001113, loss: 0.4053
2022-09-28 14:40:35 - train: epoch 0103, iter [00560, 01251], lr: 0.001113, loss: 0.4167
2022-09-28 14:40:53 - train: epoch 0103, iter [00570, 01251], lr: 0.001113, loss: 0.4173
2022-09-28 14:41:11 - train: epoch 0103, iter [00580, 01251], lr: 0.001113, loss: 0.4235
2022-09-28 14:41:28 - train: epoch 0103, iter [00590, 01251], lr: 0.001113, loss: 0.4161
2022-09-28 14:41:46 - train: epoch 0103, iter [00600, 01251], lr: 0.001113, loss: 0.4054
2022-09-28 14:42:04 - train: epoch 0103, iter [00610, 01251], lr: 0.001113, loss: 0.4052
2022-09-28 14:42:22 - train: epoch 0103, iter [00620, 01251], lr: 0.001113, loss: 0.4215
2022-09-28 14:42:39 - train: epoch 0103, iter [00630, 01251], lr: 0.001113, loss: 0.4141
2022-09-28 14:42:57 - train: epoch 0103, iter [00640, 01251], lr: 0.001113, loss: 0.4178
2022-09-28 14:43:15 - train: epoch 0103, iter [00650, 01251], lr: 0.001113, loss: 0.4024
2022-09-28 14:43:33 - train: epoch 0103, iter [00660, 01251], lr: 0.001113, loss: 0.4104
2022-09-28 14:43:50 - train: epoch 0103, iter [00670, 01251], lr: 0.001113, loss: 0.4060
2022-09-28 14:44:08 - train: epoch 0103, iter [00680, 01251], lr: 0.001113, loss: 0.4286
2022-09-28 14:44:26 - train: epoch 0103, iter [00690, 01251], lr: 0.001113, loss: 0.4137
2022-09-28 14:44:44 - train: epoch 0103, iter [00700, 01251], lr: 0.001113, loss: 0.4143
2022-09-28 14:45:01 - train: epoch 0103, iter [00710, 01251], lr: 0.001113, loss: 0.3949
2022-09-28 14:45:19 - train: epoch 0103, iter [00720, 01251], lr: 0.001113, loss: 0.4047
2022-09-28 14:45:37 - train: epoch 0103, iter [00730, 01251], lr: 0.001113, loss: 0.4201
2022-09-28 14:45:55 - train: epoch 0103, iter [00740, 01251], lr: 0.001113, loss: 0.4193
2022-09-28 14:46:13 - train: epoch 0103, iter [00750, 01251], lr: 0.001113, loss: 0.4227
2022-09-28 14:46:30 - train: epoch 0103, iter [00760, 01251], lr: 0.001113, loss: 0.4003
2022-09-28 14:46:48 - train: epoch 0103, iter [00770, 01251], lr: 0.001113, loss: 0.4062
2022-09-28 14:47:06 - train: epoch 0103, iter [00780, 01251], lr: 0.001113, loss: 0.4087
2022-09-28 14:47:23 - train: epoch 0103, iter [00790, 01251], lr: 0.001113, loss: 0.4108
2022-09-28 14:47:41 - train: epoch 0103, iter [00800, 01251], lr: 0.001113, loss: 0.3917
2022-09-28 14:47:59 - train: epoch 0103, iter [00810, 01251], lr: 0.001113, loss: 0.4240
2022-09-28 14:48:17 - train: epoch 0103, iter [00820, 01251], lr: 0.001113, loss: 0.4020
2022-09-28 14:48:35 - train: epoch 0103, iter [00830, 01251], lr: 0.001113, loss: 0.4129
2022-09-28 14:48:52 - train: epoch 0103, iter [00840, 01251], lr: 0.001112, loss: 0.4034
2022-09-28 14:49:10 - train: epoch 0103, iter [00850, 01251], lr: 0.001112, loss: 0.4096
2022-09-28 14:49:28 - train: epoch 0103, iter [00860, 01251], lr: 0.001112, loss: 0.3969
2022-09-28 14:49:46 - train: epoch 0103, iter [00870, 01251], lr: 0.001112, loss: 0.4297
2022-09-28 14:50:04 - train: epoch 0103, iter [00880, 01251], lr: 0.001112, loss: 0.4108
2022-09-28 14:50:21 - train: epoch 0103, iter [00890, 01251], lr: 0.001112, loss: 0.4476
2022-09-28 14:50:39 - train: epoch 0103, iter [00900, 01251], lr: 0.001112, loss: 0.4126
2022-09-28 14:50:57 - train: epoch 0103, iter [00910, 01251], lr: 0.001112, loss: 0.4095
2022-09-28 14:51:15 - train: epoch 0103, iter [00920, 01251], lr: 0.001112, loss: 0.4029
2022-09-28 14:51:33 - train: epoch 0103, iter [00930, 01251], lr: 0.001112, loss: 0.4207
2022-09-28 14:51:50 - train: epoch 0103, iter [00940, 01251], lr: 0.001112, loss: 0.4139
2022-09-28 14:52:08 - train: epoch 0103, iter [00950, 01251], lr: 0.001112, loss: 0.4076
2022-09-28 14:52:26 - train: epoch 0103, iter [00960, 01251], lr: 0.001112, loss: 0.4214
2022-09-28 14:52:44 - train: epoch 0103, iter [00970, 01251], lr: 0.001112, loss: 0.4008
2022-09-28 14:53:01 - train: epoch 0103, iter [00980, 01251], lr: 0.001112, loss: 0.4092
2022-09-28 14:53:19 - train: epoch 0103, iter [00990, 01251], lr: 0.001112, loss: 0.4033
2022-09-28 14:53:37 - train: epoch 0103, iter [01000, 01251], lr: 0.001112, loss: 0.3991
2022-09-28 14:53:55 - train: epoch 0103, iter [01010, 01251], lr: 0.001112, loss: 0.4110
2022-09-28 14:54:12 - train: epoch 0103, iter [01020, 01251], lr: 0.001112, loss: 0.4322
2022-09-28 14:54:30 - train: epoch 0103, iter [01030, 01251], lr: 0.001112, loss: 0.4047
2022-09-28 14:54:48 - train: epoch 0103, iter [01040, 01251], lr: 0.001112, loss: 0.4160
2022-09-28 14:55:06 - train: epoch 0103, iter [01050, 01251], lr: 0.001112, loss: 0.4120
2022-09-28 14:55:24 - train: epoch 0103, iter [01060, 01251], lr: 0.001112, loss: 0.4187
2022-09-28 14:55:41 - train: epoch 0103, iter [01070, 01251], lr: 0.001112, loss: 0.4156
2022-09-28 14:55:59 - train: epoch 0103, iter [01080, 01251], lr: 0.001112, loss: 0.4104
2022-09-28 14:56:17 - train: epoch 0103, iter [01090, 01251], lr: 0.001112, loss: 0.4066
2022-09-28 14:56:35 - train: epoch 0103, iter [01100, 01251], lr: 0.001112, loss: 0.4181
2022-09-28 14:56:53 - train: epoch 0103, iter [01110, 01251], lr: 0.001112, loss: 0.4182
2022-09-28 14:57:10 - train: epoch 0103, iter [01120, 01251], lr: 0.001112, loss: 0.4392
2022-09-28 14:57:28 - train: epoch 0103, iter [01130, 01251], lr: 0.001112, loss: 0.4192
2022-09-28 14:57:46 - train: epoch 0103, iter [01140, 01251], lr: 0.001112, loss: 0.4216
2022-09-28 14:58:04 - train: epoch 0103, iter [01150, 01251], lr: 0.001112, loss: 0.4115
2022-09-28 14:58:21 - train: epoch 0103, iter [01160, 01251], lr: 0.001112, loss: 0.4140
2022-09-28 14:58:39 - train: epoch 0103, iter [01170, 01251], lr: 0.001112, loss: 0.4122
2022-09-28 14:58:57 - train: epoch 0103, iter [01180, 01251], lr: 0.001112, loss: 0.4228
2022-09-28 14:59:15 - train: epoch 0103, iter [01190, 01251], lr: 0.001112, loss: 0.4147
2022-09-28 14:59:33 - train: epoch 0103, iter [01200, 01251], lr: 0.001112, loss: 0.3894
2022-09-28 14:59:50 - train: epoch 0103, iter [01210, 01251], lr: 0.001112, loss: 0.4251
2022-09-28 15:00:08 - train: epoch 0103, iter [01220, 01251], lr: 0.001112, loss: 0.4015
2022-09-28 15:00:26 - train: epoch 0103, iter [01230, 01251], lr: 0.001112, loss: 0.4226
2022-09-28 15:00:44 - train: epoch 0103, iter [01240, 01251], lr: 0.001112, loss: 0.4048
2022-09-28 15:01:00 - train: epoch 0103, iter [01250, 01251], lr: 0.001112, loss: 0.3849
2022-09-28 15:01:04 - train: epoch 103, train_loss: 0.4132
2022-09-28 15:01:07 - until epoch: 103, best_loss: 0.4132
2022-09-28 15:01:07 - epoch 104 lr: 0.001112
2022-09-28 15:01:40 - train: epoch 0104, iter [00010, 01251], lr: 0.001112, loss: 0.3956
2022-09-28 15:01:58 - train: epoch 0104, iter [00020, 01251], lr: 0.001112, loss: 0.4136
2022-09-28 15:02:16 - train: epoch 0104, iter [00030, 01251], lr: 0.001112, loss: 0.4196
2022-09-28 15:02:34 - train: epoch 0104, iter [00040, 01251], lr: 0.001111, loss: 0.4285
2022-09-28 15:02:52 - train: epoch 0104, iter [00050, 01251], lr: 0.001111, loss: 0.4192
2022-09-28 15:03:09 - train: epoch 0104, iter [00060, 01251], lr: 0.001111, loss: 0.4006
2022-09-28 15:03:27 - train: epoch 0104, iter [00070, 01251], lr: 0.001111, loss: 0.4235
2022-09-28 15:03:45 - train: epoch 0104, iter [00080, 01251], lr: 0.001111, loss: 0.4123
2022-09-28 15:04:03 - train: epoch 0104, iter [00090, 01251], lr: 0.001111, loss: 0.4241
2022-09-28 15:04:20 - train: epoch 0104, iter [00100, 01251], lr: 0.001111, loss: 0.4085
2022-09-28 15:04:38 - train: epoch 0104, iter [00110, 01251], lr: 0.001111, loss: 0.3986
2022-09-28 15:04:56 - train: epoch 0104, iter [00120, 01251], lr: 0.001111, loss: 0.4062
2022-09-28 15:05:14 - train: epoch 0104, iter [00130, 01251], lr: 0.001111, loss: 0.4288
2022-09-28 15:05:32 - train: epoch 0104, iter [00140, 01251], lr: 0.001111, loss: 0.4104
2022-09-28 15:05:49 - train: epoch 0104, iter [00150, 01251], lr: 0.001111, loss: 0.4050
2022-09-28 15:06:07 - train: epoch 0104, iter [00160, 01251], lr: 0.001111, loss: 0.4130
2022-09-28 15:06:25 - train: epoch 0104, iter [00170, 01251], lr: 0.001111, loss: 0.4174
2022-09-28 15:06:43 - train: epoch 0104, iter [00180, 01251], lr: 0.001111, loss: 0.4159
2022-09-28 15:07:01 - train: epoch 0104, iter [00190, 01251], lr: 0.001111, loss: 0.4025
2022-09-28 15:07:19 - train: epoch 0104, iter [00200, 01251], lr: 0.001111, loss: 0.3927
2022-09-28 15:07:36 - train: epoch 0104, iter [00210, 01251], lr: 0.001111, loss: 0.4321
2022-09-28 15:07:54 - train: epoch 0104, iter [00220, 01251], lr: 0.001111, loss: 0.4200
2022-09-28 15:08:12 - train: epoch 0104, iter [00230, 01251], lr: 0.001111, loss: 0.4160
2022-09-28 15:08:30 - train: epoch 0104, iter [00240, 01251], lr: 0.001111, loss: 0.4247
2022-09-28 15:08:47 - train: epoch 0104, iter [00250, 01251], lr: 0.001111, loss: 0.4187
2022-09-28 15:09:05 - train: epoch 0104, iter [00260, 01251], lr: 0.001111, loss: 0.4035
2022-09-28 15:09:23 - train: epoch 0104, iter [00270, 01251], lr: 0.001111, loss: 0.4192
2022-09-28 15:09:41 - train: epoch 0104, iter [00280, 01251], lr: 0.001111, loss: 0.4097
2022-09-28 15:09:59 - train: epoch 0104, iter [00290, 01251], lr: 0.001111, loss: 0.4164
2022-09-28 15:10:17 - train: epoch 0104, iter [00300, 01251], lr: 0.001111, loss: 0.4317
2022-09-28 15:10:35 - train: epoch 0104, iter [00310, 01251], lr: 0.001111, loss: 0.3992
2022-09-28 15:10:52 - train: epoch 0104, iter [00320, 01251], lr: 0.001111, loss: 0.4284
2022-09-28 15:11:10 - train: epoch 0104, iter [00330, 01251], lr: 0.001111, loss: 0.4230
2022-09-28 15:11:28 - train: epoch 0104, iter [00340, 01251], lr: 0.001111, loss: 0.4028
2022-09-28 15:11:45 - train: epoch 0104, iter [00350, 01251], lr: 0.001111, loss: 0.4135
2022-09-28 15:12:03 - train: epoch 0104, iter [00360, 01251], lr: 0.001111, loss: 0.4156
2022-09-28 15:12:21 - train: epoch 0104, iter [00370, 01251], lr: 0.001111, loss: 0.4207
2022-09-28 15:12:39 - train: epoch 0104, iter [00380, 01251], lr: 0.001111, loss: 0.4114
2022-09-28 15:12:57 - train: epoch 0104, iter [00390, 01251], lr: 0.001111, loss: 0.4145
2022-09-28 15:13:15 - train: epoch 0104, iter [00400, 01251], lr: 0.001111, loss: 0.4148
2022-09-28 15:13:32 - train: epoch 0104, iter [00410, 01251], lr: 0.001111, loss: 0.4263
2022-09-28 15:13:50 - train: epoch 0104, iter [00420, 01251], lr: 0.001111, loss: 0.4261
2022-09-28 15:14:08 - train: epoch 0104, iter [00430, 01251], lr: 0.001111, loss: 0.4380
2022-09-28 15:14:26 - train: epoch 0104, iter [00440, 01251], lr: 0.001111, loss: 0.4092
2022-09-28 15:14:44 - train: epoch 0104, iter [00450, 01251], lr: 0.001111, loss: 0.4073
2022-09-28 15:15:01 - train: epoch 0104, iter [00460, 01251], lr: 0.001111, loss: 0.4191
2022-09-28 15:15:19 - train: epoch 0104, iter [00470, 01251], lr: 0.001111, loss: 0.4269
2022-09-28 15:15:37 - train: epoch 0104, iter [00480, 01251], lr: 0.001111, loss: 0.4215
2022-09-28 15:15:55 - train: epoch 0104, iter [00490, 01251], lr: 0.001111, loss: 0.4205
2022-09-28 15:16:13 - train: epoch 0104, iter [00500, 01251], lr: 0.001110, loss: 0.4182
2022-09-28 15:16:30 - train: epoch 0104, iter [00510, 01251], lr: 0.001110, loss: 0.4035
2022-09-28 15:16:48 - train: epoch 0104, iter [00520, 01251], lr: 0.001110, loss: 0.4128
2022-09-28 15:17:06 - train: epoch 0104, iter [00530, 01251], lr: 0.001110, loss: 0.4096
2022-09-28 15:17:24 - train: epoch 0104, iter [00540, 01251], lr: 0.001110, loss: 0.4186
2022-09-28 15:17:42 - train: epoch 0104, iter [00550, 01251], lr: 0.001110, loss: 0.4211
2022-09-28 15:18:00 - train: epoch 0104, iter [00560, 01251], lr: 0.001110, loss: 0.3996
2022-09-28 15:18:17 - train: epoch 0104, iter [00570, 01251], lr: 0.001110, loss: 0.4003
2022-09-28 15:18:35 - train: epoch 0104, iter [00580, 01251], lr: 0.001110, loss: 0.4056
2022-09-28 15:18:53 - train: epoch 0104, iter [00590, 01251], lr: 0.001110, loss: 0.4058
2022-09-28 15:19:11 - train: epoch 0104, iter [00600, 01251], lr: 0.001110, loss: 0.4052
2022-09-28 15:19:29 - train: epoch 0104, iter [00610, 01251], lr: 0.001110, loss: 0.4026
2022-09-28 15:19:46 - train: epoch 0104, iter [00620, 01251], lr: 0.001110, loss: 0.4183
2022-09-28 15:20:04 - train: epoch 0104, iter [00630, 01251], lr: 0.001110, loss: 0.4189
2022-09-28 15:20:22 - train: epoch 0104, iter [00640, 01251], lr: 0.001110, loss: 0.4148
2022-09-28 15:20:40 - train: epoch 0104, iter [00650, 01251], lr: 0.001110, loss: 0.4201
2022-09-28 15:20:58 - train: epoch 0104, iter [00660, 01251], lr: 0.001110, loss: 0.3940
2022-09-28 15:21:16 - train: epoch 0104, iter [00670, 01251], lr: 0.001110, loss: 0.4067
2022-09-28 15:21:34 - train: epoch 0104, iter [00680, 01251], lr: 0.001110, loss: 0.4131
2022-09-28 15:21:52 - train: epoch 0104, iter [00690, 01251], lr: 0.001110, loss: 0.4230
2022-09-28 15:22:10 - train: epoch 0104, iter [00700, 01251], lr: 0.001110, loss: 0.4248
2022-09-28 15:22:27 - train: epoch 0104, iter [00710, 01251], lr: 0.001110, loss: 0.4245
2022-09-28 15:22:45 - train: epoch 0104, iter [00720, 01251], lr: 0.001110, loss: 0.4165
2022-09-28 15:23:03 - train: epoch 0104, iter [00730, 01251], lr: 0.001110, loss: 0.4108
2022-09-28 15:23:21 - train: epoch 0104, iter [00740, 01251], lr: 0.001110, loss: 0.4133
2022-09-28 15:23:38 - train: epoch 0104, iter [00750, 01251], lr: 0.001110, loss: 0.4390
2022-09-28 15:23:56 - train: epoch 0104, iter [00760, 01251], lr: 0.001110, loss: 0.4202
2022-09-28 15:24:14 - train: epoch 0104, iter [00770, 01251], lr: 0.001110, loss: 0.4143
2022-09-28 15:24:32 - train: epoch 0104, iter [00780, 01251], lr: 0.001110, loss: 0.4275
2022-09-28 15:24:50 - train: epoch 0104, iter [00790, 01251], lr: 0.001110, loss: 0.4170
2022-09-28 15:25:07 - train: epoch 0104, iter [00800, 01251], lr: 0.001110, loss: 0.4270
2022-09-28 15:25:26 - train: epoch 0104, iter [00810, 01251], lr: 0.001110, loss: 0.4326
2022-09-28 15:25:43 - train: epoch 0104, iter [00820, 01251], lr: 0.001110, loss: 0.4120
2022-09-28 15:26:01 - train: epoch 0104, iter [00830, 01251], lr: 0.001110, loss: 0.4130
2022-09-28 15:26:19 - train: epoch 0104, iter [00840, 01251], lr: 0.001110, loss: 0.4140
2022-09-28 15:26:37 - train: epoch 0104, iter [00850, 01251], lr: 0.001110, loss: 0.4339
2022-09-28 15:26:55 - train: epoch 0104, iter [00860, 01251], lr: 0.001110, loss: 0.4142
2022-09-28 15:27:13 - train: epoch 0104, iter [00870, 01251], lr: 0.001110, loss: 0.4212
2022-09-28 15:27:31 - train: epoch 0104, iter [00880, 01251], lr: 0.001110, loss: 0.4127
2022-09-28 15:27:48 - train: epoch 0104, iter [00890, 01251], lr: 0.001110, loss: 0.4230
2022-09-28 15:28:06 - train: epoch 0104, iter [00900, 01251], lr: 0.001110, loss: 0.4158
2022-09-28 15:28:24 - train: epoch 0104, iter [00910, 01251], lr: 0.001110, loss: 0.3993
2022-09-28 15:28:42 - train: epoch 0104, iter [00920, 01251], lr: 0.001110, loss: 0.4422
2022-09-28 15:29:00 - train: epoch 0104, iter [00930, 01251], lr: 0.001110, loss: 0.4373
2022-09-28 15:29:18 - train: epoch 0104, iter [00940, 01251], lr: 0.001110, loss: 0.4097
2022-09-28 15:29:35 - train: epoch 0104, iter [00950, 01251], lr: 0.001109, loss: 0.4350
2022-09-28 15:29:53 - train: epoch 0104, iter [00960, 01251], lr: 0.001109, loss: 0.4226
2022-09-28 15:30:11 - train: epoch 0104, iter [00970, 01251], lr: 0.001109, loss: 0.4084
2022-09-28 15:30:29 - train: epoch 0104, iter [00980, 01251], lr: 0.001109, loss: 0.4206
2022-09-28 15:30:47 - train: epoch 0104, iter [00990, 01251], lr: 0.001109, loss: 0.4116
2022-09-28 15:31:05 - train: epoch 0104, iter [01000, 01251], lr: 0.001109, loss: 0.4227
2022-09-28 15:31:23 - train: epoch 0104, iter [01010, 01251], lr: 0.001109, loss: 0.4235
2022-09-28 15:31:40 - train: epoch 0104, iter [01020, 01251], lr: 0.001109, loss: 0.3944
2022-09-28 15:31:58 - train: epoch 0104, iter [01030, 01251], lr: 0.001109, loss: 0.4279
2022-09-28 15:32:16 - train: epoch 0104, iter [01040, 01251], lr: 0.001109, loss: 0.4090
2022-09-28 15:32:34 - train: epoch 0104, iter [01050, 01251], lr: 0.001109, loss: 0.4254
2022-09-28 15:32:52 - train: epoch 0104, iter [01060, 01251], lr: 0.001109, loss: 0.4171
2022-09-28 15:33:10 - train: epoch 0104, iter [01070, 01251], lr: 0.001109, loss: 0.4021
2022-09-28 15:33:27 - train: epoch 0104, iter [01080, 01251], lr: 0.001109, loss: 0.4103
2022-09-28 15:33:45 - train: epoch 0104, iter [01090, 01251], lr: 0.001109, loss: 0.4022
2022-09-28 15:34:03 - train: epoch 0104, iter [01100, 01251], lr: 0.001109, loss: 0.4198
2022-09-28 15:34:21 - train: epoch 0104, iter [01110, 01251], lr: 0.001109, loss: 0.4125
2022-09-28 15:34:39 - train: epoch 0104, iter [01120, 01251], lr: 0.001109, loss: 0.4053
2022-09-28 15:34:57 - train: epoch 0104, iter [01130, 01251], lr: 0.001109, loss: 0.4171
2022-09-28 15:35:14 - train: epoch 0104, iter [01140, 01251], lr: 0.001109, loss: 0.4068
2022-09-28 15:35:32 - train: epoch 0104, iter [01150, 01251], lr: 0.001109, loss: 0.4077
2022-09-28 15:35:50 - train: epoch 0104, iter [01160, 01251], lr: 0.001109, loss: 0.3989
2022-09-28 15:36:08 - train: epoch 0104, iter [01170, 01251], lr: 0.001109, loss: 0.4266
2022-09-28 15:36:25 - train: epoch 0104, iter [01180, 01251], lr: 0.001109, loss: 0.4117
2022-09-28 15:36:43 - train: epoch 0104, iter [01190, 01251], lr: 0.001109, loss: 0.4045
2022-09-28 15:37:01 - train: epoch 0104, iter [01200, 01251], lr: 0.001109, loss: 0.3974
2022-09-28 15:37:19 - train: epoch 0104, iter [01210, 01251], lr: 0.001109, loss: 0.4427
2022-09-28 15:37:37 - train: epoch 0104, iter [01220, 01251], lr: 0.001109, loss: 0.4206
2022-09-28 15:37:54 - train: epoch 0104, iter [01230, 01251], lr: 0.001109, loss: 0.4102
2022-09-28 15:38:12 - train: epoch 0104, iter [01240, 01251], lr: 0.001109, loss: 0.4351
2022-09-28 15:38:29 - train: epoch 0104, iter [01250, 01251], lr: 0.001109, loss: 0.4158
2022-09-28 15:38:33 - train: epoch 104, train_loss: 0.4131
2022-09-28 15:38:35 - until epoch: 104, best_loss: 0.4131
2022-09-28 15:38:35 - epoch 105 lr: 0.001109
2022-09-28 15:39:08 - train: epoch 0105, iter [00010, 01251], lr: 0.001109, loss: 0.4111
2022-09-28 15:39:26 - train: epoch 0105, iter [00020, 01251], lr: 0.001109, loss: 0.3984
2022-09-28 15:39:44 - train: epoch 0105, iter [00030, 01251], lr: 0.001109, loss: 0.4223
2022-09-28 15:40:02 - train: epoch 0105, iter [00040, 01251], lr: 0.001109, loss: 0.4188
2022-09-28 15:40:20 - train: epoch 0105, iter [00050, 01251], lr: 0.001109, loss: 0.3903
2022-09-28 15:40:38 - train: epoch 0105, iter [00060, 01251], lr: 0.001109, loss: 0.4258
2022-09-28 15:40:56 - train: epoch 0105, iter [00070, 01251], lr: 0.001109, loss: 0.4120
2022-09-28 15:41:13 - train: epoch 0105, iter [00080, 01251], lr: 0.001109, loss: 0.4057
2022-09-28 15:41:31 - train: epoch 0105, iter [00090, 01251], lr: 0.001109, loss: 0.4278
2022-09-28 15:41:49 - train: epoch 0105, iter [00100, 01251], lr: 0.001109, loss: 0.4134
2022-09-28 15:42:07 - train: epoch 0105, iter [00110, 01251], lr: 0.001109, loss: 0.4079
2022-09-28 15:42:25 - train: epoch 0105, iter [00120, 01251], lr: 0.001109, loss: 0.3926
2022-09-28 15:42:42 - train: epoch 0105, iter [00130, 01251], lr: 0.001109, loss: 0.4226
2022-09-28 15:43:00 - train: epoch 0105, iter [00140, 01251], lr: 0.001109, loss: 0.4286
2022-09-28 15:43:18 - train: epoch 0105, iter [00150, 01251], lr: 0.001108, loss: 0.3922
2022-09-28 15:43:36 - train: epoch 0105, iter [00160, 01251], lr: 0.001108, loss: 0.4313
2022-09-28 15:43:54 - train: epoch 0105, iter [00170, 01251], lr: 0.001108, loss: 0.3953
2022-09-28 15:44:11 - train: epoch 0105, iter [00180, 01251], lr: 0.001108, loss: 0.3898
2022-09-28 15:44:29 - train: epoch 0105, iter [00190, 01251], lr: 0.001108, loss: 0.4107
2022-09-28 15:44:47 - train: epoch 0105, iter [00200, 01251], lr: 0.001108, loss: 0.4204
2022-09-28 15:45:05 - train: epoch 0105, iter [00210, 01251], lr: 0.001108, loss: 0.4110
2022-09-28 15:45:23 - train: epoch 0105, iter [00220, 01251], lr: 0.001108, loss: 0.4064
2022-09-28 15:45:40 - train: epoch 0105, iter [00230, 01251], lr: 0.001108, loss: 0.4035
2022-09-28 15:45:58 - train: epoch 0105, iter [00240, 01251], lr: 0.001108, loss: 0.3778
2022-09-28 15:46:16 - train: epoch 0105, iter [00250, 01251], lr: 0.001108, loss: 0.4109
2022-09-28 15:46:34 - train: epoch 0105, iter [00260, 01251], lr: 0.001108, loss: 0.4378
2022-09-28 15:46:51 - train: epoch 0105, iter [00270, 01251], lr: 0.001108, loss: 0.3808
2022-09-28 15:47:09 - train: epoch 0105, iter [00280, 01251], lr: 0.001108, loss: 0.4141
2022-09-28 15:47:27 - train: epoch 0105, iter [00290, 01251], lr: 0.001108, loss: 0.4160
2022-09-28 15:47:45 - train: epoch 0105, iter [00300, 01251], lr: 0.001108, loss: 0.4072
2022-09-28 15:48:03 - train: epoch 0105, iter [00310, 01251], lr: 0.001108, loss: 0.4102
2022-09-28 15:48:20 - train: epoch 0105, iter [00320, 01251], lr: 0.001108, loss: 0.4111
2022-09-28 15:48:38 - train: epoch 0105, iter [00330, 01251], lr: 0.001108, loss: 0.4244
2022-09-28 15:48:56 - train: epoch 0105, iter [00340, 01251], lr: 0.001108, loss: 0.3983
2022-09-28 15:49:14 - train: epoch 0105, iter [00350, 01251], lr: 0.001108, loss: 0.4155
2022-09-28 15:49:32 - train: epoch 0105, iter [00360, 01251], lr: 0.001108, loss: 0.4164
2022-09-28 15:49:50 - train: epoch 0105, iter [00370, 01251], lr: 0.001108, loss: 0.3988
2022-09-28 15:50:07 - train: epoch 0105, iter [00380, 01251], lr: 0.001108, loss: 0.4094
2022-09-28 15:50:25 - train: epoch 0105, iter [00390, 01251], lr: 0.001108, loss: 0.4108
2022-09-28 15:50:43 - train: epoch 0105, iter [00400, 01251], lr: 0.001108, loss: 0.3932
2022-09-28 15:51:01 - train: epoch 0105, iter [00410, 01251], lr: 0.001108, loss: 0.3958
2022-09-28 15:51:18 - train: epoch 0105, iter [00420, 01251], lr: 0.001108, loss: 0.4154
2022-09-28 15:51:36 - train: epoch 0105, iter [00430, 01251], lr: 0.001108, loss: 0.4056
2022-09-28 15:51:54 - train: epoch 0105, iter [00440, 01251], lr: 0.001108, loss: 0.3966
2022-09-28 15:52:12 - train: epoch 0105, iter [00450, 01251], lr: 0.001108, loss: 0.4015
2022-09-28 15:52:30 - train: epoch 0105, iter [00460, 01251], lr: 0.001108, loss: 0.4145
2022-09-28 15:52:48 - train: epoch 0105, iter [00470, 01251], lr: 0.001108, loss: 0.3983
2022-09-28 15:53:06 - train: epoch 0105, iter [00480, 01251], lr: 0.001108, loss: 0.3875
2022-09-28 15:53:24 - train: epoch 0105, iter [00490, 01251], lr: 0.001108, loss: 0.4132
2022-09-28 15:53:41 - train: epoch 0105, iter [00500, 01251], lr: 0.001108, loss: 0.4029
2022-09-28 15:53:59 - train: epoch 0105, iter [00510, 01251], lr: 0.001108, loss: 0.3992
2022-09-28 15:54:17 - train: epoch 0105, iter [00520, 01251], lr: 0.001108, loss: 0.4130
2022-09-28 15:54:35 - train: epoch 0105, iter [00530, 01251], lr: 0.001108, loss: 0.4052
2022-09-28 15:54:52 - train: epoch 0105, iter [00540, 01251], lr: 0.001108, loss: 0.4431
2022-09-28 15:55:10 - train: epoch 0105, iter [00550, 01251], lr: 0.001108, loss: 0.4256
2022-09-28 15:55:28 - train: epoch 0105, iter [00560, 01251], lr: 0.001108, loss: 0.4097
2022-09-28 15:55:46 - train: epoch 0105, iter [00570, 01251], lr: 0.001108, loss: 0.4353
2022-09-28 15:56:04 - train: epoch 0105, iter [00580, 01251], lr: 0.001108, loss: 0.4159
2022-09-28 15:56:21 - train: epoch 0105, iter [00590, 01251], lr: 0.001108, loss: 0.4021
2022-09-28 15:56:39 - train: epoch 0105, iter [00600, 01251], lr: 0.001107, loss: 0.4228
2022-09-28 15:56:57 - train: epoch 0105, iter [00610, 01251], lr: 0.001107, loss: 0.3934
2022-09-28 15:57:15 - train: epoch 0105, iter [00620, 01251], lr: 0.001107, loss: 0.4084
2022-09-28 15:57:33 - train: epoch 0105, iter [00630, 01251], lr: 0.001107, loss: 0.4007
2022-09-28 15:57:51 - train: epoch 0105, iter [00640, 01251], lr: 0.001107, loss: 0.4247
2022-09-28 15:58:08 - train: epoch 0105, iter [00650, 01251], lr: 0.001107, loss: 0.4020
2022-09-28 15:58:26 - train: epoch 0105, iter [00660, 01251], lr: 0.001107, loss: 0.4151
2022-09-28 15:58:43 - train: epoch 0105, iter [00670, 01251], lr: 0.001107, loss: 0.4138
2022-09-28 15:59:01 - train: epoch 0105, iter [00680, 01251], lr: 0.001107, loss: 0.4000
2022-09-28 15:59:19 - train: epoch 0105, iter [00690, 01251], lr: 0.001107, loss: 0.4230
2022-09-28 15:59:37 - train: epoch 0105, iter [00700, 01251], lr: 0.001107, loss: 0.4238
2022-09-28 15:59:55 - train: epoch 0105, iter [00710, 01251], lr: 0.001107, loss: 0.4173
2022-09-28 16:00:12 - train: epoch 0105, iter [00720, 01251], lr: 0.001107, loss: 0.4342
2022-09-28 16:00:30 - train: epoch 0105, iter [00730, 01251], lr: 0.001107, loss: 0.4064
2022-09-28 16:00:48 - train: epoch 0105, iter [00740, 01251], lr: 0.001107, loss: 0.4131
2022-09-28 16:01:06 - train: epoch 0105, iter [00750, 01251], lr: 0.001107, loss: 0.4041
2022-09-28 16:01:24 - train: epoch 0105, iter [00760, 01251], lr: 0.001107, loss: 0.4228
2022-09-28 16:01:41 - train: epoch 0105, iter [00770, 01251], lr: 0.001107, loss: 0.4157
2022-09-28 16:02:00 - train: epoch 0105, iter [00780, 01251], lr: 0.001107, loss: 0.4204
2022-09-28 16:02:18 - train: epoch 0105, iter [00790, 01251], lr: 0.001107, loss: 0.4031
2022-09-28 16:02:35 - train: epoch 0105, iter [00800, 01251], lr: 0.001107, loss: 0.3820
2022-09-28 16:02:53 - train: epoch 0105, iter [00810, 01251], lr: 0.001107, loss: 0.4310
2022-09-28 16:03:11 - train: epoch 0105, iter [00820, 01251], lr: 0.001107, loss: 0.4064
2022-09-28 16:03:29 - train: epoch 0105, iter [00830, 01251], lr: 0.001107, loss: 0.4293
2022-09-28 16:03:46 - train: epoch 0105, iter [00840, 01251], lr: 0.001107, loss: 0.4083
2022-09-28 16:04:04 - train: epoch 0105, iter [00850, 01251], lr: 0.001107, loss: 0.4167
2022-09-28 16:04:22 - train: epoch 0105, iter [00860, 01251], lr: 0.001107, loss: 0.4120
2022-09-28 16:04:40 - train: epoch 0105, iter [00870, 01251], lr: 0.001107, loss: 0.3977
2022-09-28 16:04:57 - train: epoch 0105, iter [00880, 01251], lr: 0.001107, loss: 0.3937
2022-09-28 16:05:15 - train: epoch 0105, iter [00890, 01251], lr: 0.001107, loss: 0.4064
2022-09-28 16:05:33 - train: epoch 0105, iter [00900, 01251], lr: 0.001107, loss: 0.4209
2022-09-28 16:05:51 - train: epoch 0105, iter [00910, 01251], lr: 0.001107, loss: 0.4236
2022-09-28 16:06:08 - train: epoch 0105, iter [00920, 01251], lr: 0.001107, loss: 0.4099
2022-09-28 16:06:26 - train: epoch 0105, iter [00930, 01251], lr: 0.001107, loss: 0.4029
2022-09-28 16:06:44 - train: epoch 0105, iter [00940, 01251], lr: 0.001107, loss: 0.4065
2022-09-28 16:07:02 - train: epoch 0105, iter [00950, 01251], lr: 0.001107, loss: 0.3844
2022-09-28 16:07:20 - train: epoch 0105, iter [00960, 01251], lr: 0.001107, loss: 0.4140
2022-09-28 16:07:38 - train: epoch 0105, iter [00970, 01251], lr: 0.001107, loss: 0.3911
2022-09-28 16:07:56 - train: epoch 0105, iter [00980, 01251], lr: 0.001107, loss: 0.4288
2022-09-28 16:08:13 - train: epoch 0105, iter [00990, 01251], lr: 0.001107, loss: 0.4124
2022-09-28 16:08:31 - train: epoch 0105, iter [01000, 01251], lr: 0.001107, loss: 0.4141
2022-09-28 16:08:49 - train: epoch 0105, iter [01010, 01251], lr: 0.001107, loss: 0.4087
2022-09-28 16:09:07 - train: epoch 0105, iter [01020, 01251], lr: 0.001107, loss: 0.4218
2022-09-28 16:09:25 - train: epoch 0105, iter [01030, 01251], lr: 0.001107, loss: 0.4192
2022-09-28 16:09:43 - train: epoch 0105, iter [01040, 01251], lr: 0.001107, loss: 0.4047
2022-09-28 16:10:00 - train: epoch 0105, iter [01050, 01251], lr: 0.001106, loss: 0.4076
2022-09-28 16:10:18 - train: epoch 0105, iter [01060, 01251], lr: 0.001106, loss: 0.4011
2022-09-28 16:10:36 - train: epoch 0105, iter [01070, 01251], lr: 0.001106, loss: 0.4076
2022-09-28 16:10:54 - train: epoch 0105, iter [01080, 01251], lr: 0.001106, loss: 0.4194
2022-09-28 16:11:12 - train: epoch 0105, iter [01090, 01251], lr: 0.001106, loss: 0.3991
2022-09-28 16:11:29 - train: epoch 0105, iter [01100, 01251], lr: 0.001106, loss: 0.4345
2022-09-28 16:11:47 - train: epoch 0105, iter [01110, 01251], lr: 0.001106, loss: 0.4056
2022-09-28 16:12:05 - train: epoch 0105, iter [01120, 01251], lr: 0.001106, loss: 0.4142
2022-09-28 16:12:22 - train: epoch 0105, iter [01130, 01251], lr: 0.001106, loss: 0.4283
2022-09-28 16:12:40 - train: epoch 0105, iter [01140, 01251], lr: 0.001106, loss: 0.4291
2022-09-28 16:12:58 - train: epoch 0105, iter [01150, 01251], lr: 0.001106, loss: 0.4084
2022-09-28 16:13:16 - train: epoch 0105, iter [01160, 01251], lr: 0.001106, loss: 0.4098
2022-09-28 16:13:34 - train: epoch 0105, iter [01170, 01251], lr: 0.001106, loss: 0.4340
2022-09-28 16:13:52 - train: epoch 0105, iter [01180, 01251], lr: 0.001106, loss: 0.3976
2022-09-28 16:14:10 - train: epoch 0105, iter [01190, 01251], lr: 0.001106, loss: 0.4183
2022-09-28 16:14:27 - train: epoch 0105, iter [01200, 01251], lr: 0.001106, loss: 0.4198
2022-09-28 16:14:45 - train: epoch 0105, iter [01210, 01251], lr: 0.001106, loss: 0.4092
2022-09-28 16:15:03 - train: epoch 0105, iter [01220, 01251], lr: 0.001106, loss: 0.4235
2022-09-28 16:15:21 - train: epoch 0105, iter [01230, 01251], lr: 0.001106, loss: 0.4255
2022-09-28 16:15:39 - train: epoch 0105, iter [01240, 01251], lr: 0.001106, loss: 0.4131
2022-09-28 16:15:56 - train: epoch 0105, iter [01250, 01251], lr: 0.001106, loss: 0.4474
2022-09-28 16:15:59 - train: epoch 105, train_loss: 0.4130
2022-09-28 16:16:02 - until epoch: 105, best_loss: 0.4130
2022-09-28 16:16:02 - epoch 106 lr: 0.001106
2022-09-28 16:16:35 - train: epoch 0106, iter [00010, 01251], lr: 0.001106, loss: 0.3892
2022-09-28 16:16:53 - train: epoch 0106, iter [00020, 01251], lr: 0.001106, loss: 0.4004
2022-09-28 16:17:10 - train: epoch 0106, iter [00030, 01251], lr: 0.001106, loss: 0.4118
2022-09-28 16:17:28 - train: epoch 0106, iter [00040, 01251], lr: 0.001106, loss: 0.4113
2022-09-28 16:17:46 - train: epoch 0106, iter [00050, 01251], lr: 0.001106, loss: 0.4203
2022-09-28 16:18:04 - train: epoch 0106, iter [00060, 01251], lr: 0.001106, loss: 0.4027
2022-09-28 16:18:22 - train: epoch 0106, iter [00070, 01251], lr: 0.001106, loss: 0.3986
2022-09-28 16:18:39 - train: epoch 0106, iter [00080, 01251], lr: 0.001106, loss: 0.4148
2022-09-28 16:18:57 - train: epoch 0106, iter [00090, 01251], lr: 0.001106, loss: 0.4202
2022-09-28 16:19:15 - train: epoch 0106, iter [00100, 01251], lr: 0.001106, loss: 0.3937
2022-09-28 16:19:33 - train: epoch 0106, iter [00110, 01251], lr: 0.001106, loss: 0.4301
2022-09-28 16:19:50 - train: epoch 0106, iter [00120, 01251], lr: 0.001106, loss: 0.3923
2022-09-28 16:20:08 - train: epoch 0106, iter [00130, 01251], lr: 0.001106, loss: 0.4097
2022-09-28 16:20:26 - train: epoch 0106, iter [00140, 01251], lr: 0.001106, loss: 0.4374
2022-09-28 16:20:44 - train: epoch 0106, iter [00150, 01251], lr: 0.001106, loss: 0.3980
2022-09-28 16:21:02 - train: epoch 0106, iter [00160, 01251], lr: 0.001106, loss: 0.4031
2022-09-28 16:21:20 - train: epoch 0106, iter [00170, 01251], lr: 0.001106, loss: 0.4092
2022-09-28 16:21:37 - train: epoch 0106, iter [00180, 01251], lr: 0.001106, loss: 0.4081
2022-09-28 16:21:55 - train: epoch 0106, iter [00190, 01251], lr: 0.001106, loss: 0.4196
2022-09-28 16:22:13 - train: epoch 0106, iter [00200, 01251], lr: 0.001106, loss: 0.4433
2022-09-28 16:22:31 - train: epoch 0106, iter [00210, 01251], lr: 0.001106, loss: 0.4313
2022-09-28 16:22:49 - train: epoch 0106, iter [00220, 01251], lr: 0.001106, loss: 0.4044
2022-09-28 16:23:07 - train: epoch 0106, iter [00230, 01251], lr: 0.001106, loss: 0.4059
2022-09-28 16:23:24 - train: epoch 0106, iter [00240, 01251], lr: 0.001105, loss: 0.4025
2022-09-28 16:23:42 - train: epoch 0106, iter [00250, 01251], lr: 0.001105, loss: 0.4019
2022-09-28 16:24:00 - train: epoch 0106, iter [00260, 01251], lr: 0.001105, loss: 0.4263
2022-09-28 16:24:17 - train: epoch 0106, iter [00270, 01251], lr: 0.001105, loss: 0.3970
2022-09-28 16:24:35 - train: epoch 0106, iter [00280, 01251], lr: 0.001105, loss: 0.4015
2022-09-28 16:24:53 - train: epoch 0106, iter [00290, 01251], lr: 0.001105, loss: 0.3905
2022-09-28 16:25:11 - train: epoch 0106, iter [00300, 01251], lr: 0.001105, loss: 0.4031
2022-09-28 16:25:29 - train: epoch 0106, iter [00310, 01251], lr: 0.001105, loss: 0.4075
2022-09-28 16:25:47 - train: epoch 0106, iter [00320, 01251], lr: 0.001105, loss: 0.4224
2022-09-28 16:26:05 - train: epoch 0106, iter [00330, 01251], lr: 0.001105, loss: 0.4083
2022-09-28 16:26:23 - train: epoch 0106, iter [00340, 01251], lr: 0.001105, loss: 0.4288
2022-09-28 16:26:40 - train: epoch 0106, iter [00350, 01251], lr: 0.001105, loss: 0.4263
2022-09-28 16:26:58 - train: epoch 0106, iter [00360, 01251], lr: 0.001105, loss: 0.4156
2022-09-28 16:27:16 - train: epoch 0106, iter [00370, 01251], lr: 0.001105, loss: 0.4052
2022-09-28 16:27:34 - train: epoch 0106, iter [00380, 01251], lr: 0.001105, loss: 0.4020
2022-09-28 16:27:52 - train: epoch 0106, iter [00390, 01251], lr: 0.001105, loss: 0.4189
2022-09-28 16:28:10 - train: epoch 0106, iter [00400, 01251], lr: 0.001105, loss: 0.4130
2022-09-28 16:28:27 - train: epoch 0106, iter [00410, 01251], lr: 0.001105, loss: 0.4035
2022-09-28 16:28:45 - train: epoch 0106, iter [00420, 01251], lr: 0.001105, loss: 0.4098
2022-09-28 16:29:03 - train: epoch 0106, iter [00430, 01251], lr: 0.001105, loss: 0.4163
2022-09-28 16:29:21 - train: epoch 0106, iter [00440, 01251], lr: 0.001105, loss: 0.4174
2022-09-28 16:29:38 - train: epoch 0106, iter [00450, 01251], lr: 0.001105, loss: 0.4293
2022-09-28 16:29:56 - train: epoch 0106, iter [00460, 01251], lr: 0.001105, loss: 0.4126
2022-09-28 16:30:14 - train: epoch 0106, iter [00470, 01251], lr: 0.001105, loss: 0.4069
2022-09-28 16:30:32 - train: epoch 0106, iter [00480, 01251], lr: 0.001105, loss: 0.3971
2022-09-28 16:30:49 - train: epoch 0106, iter [00490, 01251], lr: 0.001105, loss: 0.4106
2022-09-28 16:31:07 - train: epoch 0106, iter [00500, 01251], lr: 0.001105, loss: 0.3988
2022-09-28 16:31:25 - train: epoch 0106, iter [00510, 01251], lr: 0.001105, loss: 0.4168
2022-09-28 16:31:43 - train: epoch 0106, iter [00520, 01251], lr: 0.001105, loss: 0.4168
2022-09-28 16:32:01 - train: epoch 0106, iter [00530, 01251], lr: 0.001105, loss: 0.4258
2022-09-28 16:32:18 - train: epoch 0106, iter [00540, 01251], lr: 0.001105, loss: 0.4011
2022-09-28 16:32:36 - train: epoch 0106, iter [00550, 01251], lr: 0.001105, loss: 0.4132
2022-09-28 16:32:54 - train: epoch 0106, iter [00560, 01251], lr: 0.001105, loss: 0.4166
2022-09-28 16:33:12 - train: epoch 0106, iter [00570, 01251], lr: 0.001105, loss: 0.3995
2022-09-28 16:33:30 - train: epoch 0106, iter [00580, 01251], lr: 0.001105, loss: 0.4184
2022-09-28 16:33:48 - train: epoch 0106, iter [00590, 01251], lr: 0.001105, loss: 0.4126
2022-09-28 16:34:05 - train: epoch 0106, iter [00600, 01251], lr: 0.001105, loss: 0.4067
2022-09-28 16:34:23 - train: epoch 0106, iter [00610, 01251], lr: 0.001105, loss: 0.4080
2022-09-28 16:34:41 - train: epoch 0106, iter [00620, 01251], lr: 0.001105, loss: 0.4291
2022-09-28 16:34:59 - train: epoch 0106, iter [00630, 01251], lr: 0.001105, loss: 0.4180
2022-09-28 16:35:16 - train: epoch 0106, iter [00640, 01251], lr: 0.001105, loss: 0.4239
2022-09-28 16:35:34 - train: epoch 0106, iter [00650, 01251], lr: 0.001105, loss: 0.4116
2022-09-28 16:35:52 - train: epoch 0106, iter [00660, 01251], lr: 0.001105, loss: 0.4046
2022-09-28 16:36:09 - train: epoch 0106, iter [00670, 01251], lr: 0.001105, loss: 0.4236
2022-09-28 16:36:27 - train: epoch 0106, iter [00680, 01251], lr: 0.001104, loss: 0.4013
2022-09-28 16:36:45 - train: epoch 0106, iter [00690, 01251], lr: 0.001104, loss: 0.3958
2022-09-28 16:37:03 - train: epoch 0106, iter [00700, 01251], lr: 0.001104, loss: 0.4022
2022-09-28 16:37:21 - train: epoch 0106, iter [00710, 01251], lr: 0.001104, loss: 0.4238
2022-09-28 16:37:39 - train: epoch 0106, iter [00720, 01251], lr: 0.001104, loss: 0.4213
2022-09-28 16:37:56 - train: epoch 0106, iter [00730, 01251], lr: 0.001104, loss: 0.4094
2022-09-28 16:38:14 - train: epoch 0106, iter [00740, 01251], lr: 0.001104, loss: 0.4134
2022-09-28 16:38:32 - train: epoch 0106, iter [00750, 01251], lr: 0.001104, loss: 0.4109
2022-09-28 16:38:50 - train: epoch 0106, iter [00760, 01251], lr: 0.001104, loss: 0.4377
2022-09-28 16:39:08 - train: epoch 0106, iter [00770, 01251], lr: 0.001104, loss: 0.3936
2022-09-28 16:39:26 - train: epoch 0106, iter [00780, 01251], lr: 0.001104, loss: 0.4136
2022-09-28 16:39:44 - train: epoch 0106, iter [00790, 01251], lr: 0.001104, loss: 0.4230
2022-09-28 16:40:01 - train: epoch 0106, iter [00800, 01251], lr: 0.001104, loss: 0.4048
2022-09-28 16:40:19 - train: epoch 0106, iter [00810, 01251], lr: 0.001104, loss: 0.4168
2022-09-28 16:40:37 - train: epoch 0106, iter [00820, 01251], lr: 0.001104, loss: 0.4257
2022-09-28 16:40:55 - train: epoch 0106, iter [00830, 01251], lr: 0.001104, loss: 0.4230
2022-09-28 16:41:13 - train: epoch 0106, iter [00840, 01251], lr: 0.001104, loss: 0.4081
2022-09-28 16:41:30 - train: epoch 0106, iter [00850, 01251], lr: 0.001104, loss: 0.4050
2022-09-28 16:41:48 - train: epoch 0106, iter [00860, 01251], lr: 0.001104, loss: 0.4210
2022-09-28 16:42:06 - train: epoch 0106, iter [00870, 01251], lr: 0.001104, loss: 0.4382
2022-09-28 16:42:24 - train: epoch 0106, iter [00880, 01251], lr: 0.001104, loss: 0.4099
2022-09-28 16:42:42 - train: epoch 0106, iter [00890, 01251], lr: 0.001104, loss: 0.4028
2022-09-28 16:43:00 - train: epoch 0106, iter [00900, 01251], lr: 0.001104, loss: 0.4157
2022-09-28 16:43:17 - train: epoch 0106, iter [00910, 01251], lr: 0.001104, loss: 0.4351
2022-09-28 16:43:35 - train: epoch 0106, iter [00920, 01251], lr: 0.001104, loss: 0.4129
2022-09-28 16:43:53 - train: epoch 0106, iter [00930, 01251], lr: 0.001104, loss: 0.4052
2022-09-28 16:44:11 - train: epoch 0106, iter [00940, 01251], lr: 0.001104, loss: 0.3980
2022-09-28 16:44:28 - train: epoch 0106, iter [00950, 01251], lr: 0.001104, loss: 0.3988
2022-09-28 16:44:46 - train: epoch 0106, iter [00960, 01251], lr: 0.001104, loss: 0.4045
2022-09-28 16:45:04 - train: epoch 0106, iter [00970, 01251], lr: 0.001104, loss: 0.4095
2022-09-28 16:45:22 - train: epoch 0106, iter [00980, 01251], lr: 0.001104, loss: 0.4133
2022-09-28 16:45:40 - train: epoch 0106, iter [00990, 01251], lr: 0.001104, loss: 0.4083
2022-09-28 16:45:57 - train: epoch 0106, iter [01000, 01251], lr: 0.001104, loss: 0.4156
2022-09-28 16:46:15 - train: epoch 0106, iter [01010, 01251], lr: 0.001104, loss: 0.3904
2022-09-28 16:46:33 - train: epoch 0106, iter [01020, 01251], lr: 0.001104, loss: 0.4161
2022-09-28 16:46:51 - train: epoch 0106, iter [01030, 01251], lr: 0.001104, loss: 0.4081
2022-09-28 16:47:09 - train: epoch 0106, iter [01040, 01251], lr: 0.001104, loss: 0.4300
2022-09-28 16:47:27 - train: epoch 0106, iter [01050, 01251], lr: 0.001104, loss: 0.4088
2022-09-28 16:47:45 - train: epoch 0106, iter [01060, 01251], lr: 0.001104, loss: 0.4049
2022-09-28 16:48:02 - train: epoch 0106, iter [01070, 01251], lr: 0.001104, loss: 0.4114
2022-09-28 16:48:20 - train: epoch 0106, iter [01080, 01251], lr: 0.001104, loss: 0.4185
2022-09-28 16:48:38 - train: epoch 0106, iter [01090, 01251], lr: 0.001104, loss: 0.4092
2022-09-28 16:48:56 - train: epoch 0106, iter [01100, 01251], lr: 0.001104, loss: 0.4248
2022-09-28 16:49:14 - train: epoch 0106, iter [01110, 01251], lr: 0.001104, loss: 0.4003
2022-09-28 16:49:32 - train: epoch 0106, iter [01120, 01251], lr: 0.001104, loss: 0.4180
2022-09-28 16:49:50 - train: epoch 0106, iter [01130, 01251], lr: 0.001103, loss: 0.4144
2022-09-28 16:50:07 - train: epoch 0106, iter [01140, 01251], lr: 0.001103, loss: 0.4183
2022-09-28 16:50:25 - train: epoch 0106, iter [01150, 01251], lr: 0.001103, loss: 0.4155
2022-09-28 16:50:43 - train: epoch 0106, iter [01160, 01251], lr: 0.001103, loss: 0.4150
2022-09-28 16:51:01 - train: epoch 0106, iter [01170, 01251], lr: 0.001103, loss: 0.3846
2022-09-28 16:51:19 - train: epoch 0106, iter [01180, 01251], lr: 0.001103, loss: 0.4147
2022-09-28 16:51:37 - train: epoch 0106, iter [01190, 01251], lr: 0.001103, loss: 0.4342
2022-09-28 16:51:55 - train: epoch 0106, iter [01200, 01251], lr: 0.001103, loss: 0.4102
2022-09-28 16:52:12 - train: epoch 0106, iter [01210, 01251], lr: 0.001103, loss: 0.4143
2022-09-28 16:52:30 - train: epoch 0106, iter [01220, 01251], lr: 0.001103, loss: 0.4007
2022-09-28 16:52:48 - train: epoch 0106, iter [01230, 01251], lr: 0.001103, loss: 0.4444
2022-09-28 16:53:06 - train: epoch 0106, iter [01240, 01251], lr: 0.001103, loss: 0.4114
2022-09-28 16:53:23 - train: epoch 0106, iter [01250, 01251], lr: 0.001103, loss: 0.4013
2022-09-28 16:53:26 - train: epoch 106, train_loss: 0.4130
2022-09-28 16:53:29 - until epoch: 106, best_loss: 0.4130
2022-09-28 16:53:29 - epoch 107 lr: 0.001103
2022-09-28 16:54:02 - train: epoch 0107, iter [00010, 01251], lr: 0.001103, loss: 0.4235
2022-09-28 16:54:20 - train: epoch 0107, iter [00020, 01251], lr: 0.001103, loss: 0.4119
2022-09-28 16:54:38 - train: epoch 0107, iter [00030, 01251], lr: 0.001103, loss: 0.3894
2022-09-28 16:54:56 - train: epoch 0107, iter [00040, 01251], lr: 0.001103, loss: 0.4228
2022-09-28 16:55:13 - train: epoch 0107, iter [00050, 01251], lr: 0.001103, loss: 0.3930
2022-09-28 16:55:31 - train: epoch 0107, iter [00060, 01251], lr: 0.001103, loss: 0.3772
2022-09-28 16:55:49 - train: epoch 0107, iter [00070, 01251], lr: 0.001103, loss: 0.4053
2022-09-28 16:56:07 - train: epoch 0107, iter [00080, 01251], lr: 0.001103, loss: 0.4269
2022-09-28 16:56:25 - train: epoch 0107, iter [00090, 01251], lr: 0.001103, loss: 0.4125
2022-09-28 16:56:42 - train: epoch 0107, iter [00100, 01251], lr: 0.001103, loss: 0.4173
2022-09-28 16:57:00 - train: epoch 0107, iter [00110, 01251], lr: 0.001103, loss: 0.4351
2022-09-28 16:57:18 - train: epoch 0107, iter [00120, 01251], lr: 0.001103, loss: 0.4137
2022-09-28 16:57:36 - train: epoch 0107, iter [00130, 01251], lr: 0.001103, loss: 0.4266
2022-09-28 16:57:54 - train: epoch 0107, iter [00140, 01251], lr: 0.001103, loss: 0.4352
2022-09-28 16:58:12 - train: epoch 0107, iter [00150, 01251], lr: 0.001103, loss: 0.4137
2022-09-28 16:58:30 - train: epoch 0107, iter [00160, 01251], lr: 0.001103, loss: 0.4005
2022-09-28 16:58:48 - train: epoch 0107, iter [00170, 01251], lr: 0.001103, loss: 0.3972
2022-09-28 16:59:06 - train: epoch 0107, iter [00180, 01251], lr: 0.001103, loss: 0.4115
2022-09-28 16:59:23 - train: epoch 0107, iter [00190, 01251], lr: 0.001103, loss: 0.4295
2022-09-28 16:59:41 - train: epoch 0107, iter [00200, 01251], lr: 0.001103, loss: 0.4093
2022-09-28 16:59:59 - train: epoch 0107, iter [00210, 01251], lr: 0.001103, loss: 0.4164
2022-09-28 17:00:17 - train: epoch 0107, iter [00220, 01251], lr: 0.001103, loss: 0.4255
2022-09-28 17:00:35 - train: epoch 0107, iter [00230, 01251], lr: 0.001103, loss: 0.4202
2022-09-28 17:00:53 - train: epoch 0107, iter [00240, 01251], lr: 0.001103, loss: 0.4234
2022-09-28 17:01:10 - train: epoch 0107, iter [00250, 01251], lr: 0.001103, loss: 0.4169
2022-09-28 17:01:28 - train: epoch 0107, iter [00260, 01251], lr: 0.001103, loss: 0.4062
2022-09-28 17:01:46 - train: epoch 0107, iter [00270, 01251], lr: 0.001103, loss: 0.4126
2022-09-28 17:02:04 - train: epoch 0107, iter [00280, 01251], lr: 0.001103, loss: 0.3941
2022-09-28 17:02:22 - train: epoch 0107, iter [00290, 01251], lr: 0.001103, loss: 0.3994
2022-09-28 17:02:39 - train: epoch 0107, iter [00300, 01251], lr: 0.001103, loss: 0.3935
2022-09-28 17:02:57 - train: epoch 0107, iter [00310, 01251], lr: 0.001102, loss: 0.4078
2022-09-28 17:03:15 - train: epoch 0107, iter [00320, 01251], lr: 0.001102, loss: 0.4025
2022-09-28 17:03:33 - train: epoch 0107, iter [00330, 01251], lr: 0.001102, loss: 0.4078
2022-09-28 17:03:51 - train: epoch 0107, iter [00340, 01251], lr: 0.001102, loss: 0.4185
2022-09-28 17:04:08 - train: epoch 0107, iter [00350, 01251], lr: 0.001102, loss: 0.4071
2022-09-28 17:04:26 - train: epoch 0107, iter [00360, 01251], lr: 0.001102, loss: 0.4124
2022-09-28 17:04:44 - train: epoch 0107, iter [00370, 01251], lr: 0.001102, loss: 0.4204
2022-09-28 17:05:02 - train: epoch 0107, iter [00380, 01251], lr: 0.001102, loss: 0.4136
2022-09-28 17:05:19 - train: epoch 0107, iter [00390, 01251], lr: 0.001102, loss: 0.3982
2022-09-28 17:05:37 - train: epoch 0107, iter [00400, 01251], lr: 0.001102, loss: 0.4141
2022-09-28 17:05:55 - train: epoch 0107, iter [00410, 01251], lr: 0.001102, loss: 0.4226
2022-09-28 17:06:13 - train: epoch 0107, iter [00420, 01251], lr: 0.001102, loss: 0.3998
2022-09-28 17:06:31 - train: epoch 0107, iter [00430, 01251], lr: 0.001102, loss: 0.4158
2022-09-28 17:06:48 - train: epoch 0107, iter [00440, 01251], lr: 0.001102, loss: 0.4069
2022-09-28 17:07:06 - train: epoch 0107, iter [00450, 01251], lr: 0.001102, loss: 0.4265
2022-09-28 17:07:24 - train: epoch 0107, iter [00460, 01251], lr: 0.001102, loss: 0.4026
2022-09-28 17:07:42 - train: epoch 0107, iter [00470, 01251], lr: 0.001102, loss: 0.4166
2022-09-28 17:08:00 - train: epoch 0107, iter [00480, 01251], lr: 0.001102, loss: 0.4009
2022-09-28 17:08:17 - train: epoch 0107, iter [00490, 01251], lr: 0.001102, loss: 0.4277
2022-09-28 17:08:35 - train: epoch 0107, iter [00500, 01251], lr: 0.001102, loss: 0.4332
2022-09-28 17:08:53 - train: epoch 0107, iter [00510, 01251], lr: 0.001102, loss: 0.4147
2022-09-28 17:09:11 - train: epoch 0107, iter [00520, 01251], lr: 0.001102, loss: 0.4036
2022-09-28 17:09:29 - train: epoch 0107, iter [00530, 01251], lr: 0.001102, loss: 0.4115
2022-09-28 17:09:47 - train: epoch 0107, iter [00540, 01251], lr: 0.001102, loss: 0.4059
2022-09-28 17:10:04 - train: epoch 0107, iter [00550, 01251], lr: 0.001102, loss: 0.3871
2022-09-28 17:10:23 - train: epoch 0107, iter [00560, 01251], lr: 0.001102, loss: 0.4142
2022-09-28 17:10:40 - train: epoch 0107, iter [00570, 01251], lr: 0.001102, loss: 0.4174
2022-09-28 17:10:58 - train: epoch 0107, iter [00580, 01251], lr: 0.001102, loss: 0.4039
2022-09-28 17:11:16 - train: epoch 0107, iter [00590, 01251], lr: 0.001102, loss: 0.4125
2022-09-28 17:11:34 - train: epoch 0107, iter [00600, 01251], lr: 0.001102, loss: 0.3994
2022-09-28 17:11:52 - train: epoch 0107, iter [00610, 01251], lr: 0.001102, loss: 0.4205
2022-09-28 17:12:10 - train: epoch 0107, iter [00620, 01251], lr: 0.001102, loss: 0.4094
2022-09-28 17:12:28 - train: epoch 0107, iter [00630, 01251], lr: 0.001102, loss: 0.4179
2022-09-28 17:12:45 - train: epoch 0107, iter [00640, 01251], lr: 0.001102, loss: 0.4135
2022-09-28 17:13:03 - train: epoch 0107, iter [00650, 01251], lr: 0.001102, loss: 0.3982
2022-09-28 17:13:21 - train: epoch 0107, iter [00660, 01251], lr: 0.001102, loss: 0.3949
2022-09-28 17:13:39 - train: epoch 0107, iter [00670, 01251], lr: 0.001102, loss: 0.4243
2022-09-28 17:13:57 - train: epoch 0107, iter [00680, 01251], lr: 0.001102, loss: 0.4147
2022-09-28 17:14:15 - train: epoch 0107, iter [00690, 01251], lr: 0.001102, loss: 0.4205
2022-09-28 17:14:33 - train: epoch 0107, iter [00700, 01251], lr: 0.001102, loss: 0.4129
2022-09-28 17:14:50 - train: epoch 0107, iter [00710, 01251], lr: 0.001102, loss: 0.4189
2022-09-28 17:15:08 - train: epoch 0107, iter [00720, 01251], lr: 0.001102, loss: 0.4179
2022-09-28 17:15:26 - train: epoch 0107, iter [00730, 01251], lr: 0.001102, loss: 0.4098
2022-09-28 17:15:44 - train: epoch 0107, iter [00740, 01251], lr: 0.001102, loss: 0.4084
2022-09-28 17:16:02 - train: epoch 0107, iter [00750, 01251], lr: 0.001101, loss: 0.4186
2022-09-28 17:16:19 - train: epoch 0107, iter [00760, 01251], lr: 0.001101, loss: 0.3931
2022-09-28 17:16:37 - train: epoch 0107, iter [00770, 01251], lr: 0.001101, loss: 0.4078
2022-09-28 17:16:55 - train: epoch 0107, iter [00780, 01251], lr: 0.001101, loss: 0.4152
2022-09-28 17:17:13 - train: epoch 0107, iter [00790, 01251], lr: 0.001101, loss: 0.4027
2022-09-28 17:17:31 - train: epoch 0107, iter [00800, 01251], lr: 0.001101, loss: 0.4208
2022-09-28 17:17:49 - train: epoch 0107, iter [00810, 01251], lr: 0.001101, loss: 0.4070
2022-09-28 17:18:06 - train: epoch 0107, iter [00820, 01251], lr: 0.001101, loss: 0.4281
2022-09-28 17:18:24 - train: epoch 0107, iter [00830, 01251], lr: 0.001101, loss: 0.4078
2022-09-28 17:18:42 - train: epoch 0107, iter [00840, 01251], lr: 0.001101, loss: 0.4116
2022-09-28 17:19:00 - train: epoch 0107, iter [00850, 01251], lr: 0.001101, loss: 0.4085
2022-09-28 17:19:18 - train: epoch 0107, iter [00860, 01251], lr: 0.001101, loss: 0.4111
2022-09-28 17:19:36 - train: epoch 0107, iter [00870, 01251], lr: 0.001101, loss: 0.3872
2022-09-28 17:19:53 - train: epoch 0107, iter [00880, 01251], lr: 0.001101, loss: 0.4451
2022-09-28 17:20:11 - train: epoch 0107, iter [00890, 01251], lr: 0.001101, loss: 0.4127
2022-09-28 17:20:29 - train: epoch 0107, iter [00900, 01251], lr: 0.001101, loss: 0.4119
2022-09-28 17:20:47 - train: epoch 0107, iter [00910, 01251], lr: 0.001101, loss: 0.4262
2022-09-28 17:21:05 - train: epoch 0107, iter [00920, 01251], lr: 0.001101, loss: 0.4147
2022-09-28 17:21:23 - train: epoch 0107, iter [00930, 01251], lr: 0.001101, loss: 0.4184
2022-09-28 17:21:41 - train: epoch 0107, iter [00940, 01251], lr: 0.001101, loss: 0.4008
2022-09-28 17:21:59 - train: epoch 0107, iter [00950, 01251], lr: 0.001101, loss: 0.3903
2022-09-28 17:22:16 - train: epoch 0107, iter [00960, 01251], lr: 0.001101, loss: 0.4243
2022-09-28 17:22:34 - train: epoch 0107, iter [00970, 01251], lr: 0.001101, loss: 0.4008
2022-09-28 17:22:52 - train: epoch 0107, iter [00980, 01251], lr: 0.001101, loss: 0.4284
2022-09-28 17:23:10 - train: epoch 0107, iter [00990, 01251], lr: 0.001101, loss: 0.4059
2022-09-28 17:23:28 - train: epoch 0107, iter [01000, 01251], lr: 0.001101, loss: 0.4058
2022-09-28 17:23:46 - train: epoch 0107, iter [01010, 01251], lr: 0.001101, loss: 0.4161
2022-09-28 17:24:03 - train: epoch 0107, iter [01020, 01251], lr: 0.001101, loss: 0.4236
2022-09-28 17:24:21 - train: epoch 0107, iter [01030, 01251], lr: 0.001101, loss: 0.3972
2022-09-28 17:24:39 - train: epoch 0107, iter [01040, 01251], lr: 0.001101, loss: 0.4207
2022-09-28 17:24:56 - train: epoch 0107, iter [01050, 01251], lr: 0.001101, loss: 0.4201
2022-09-28 17:25:14 - train: epoch 0107, iter [01060, 01251], lr: 0.001101, loss: 0.4330
2022-09-28 17:25:32 - train: epoch 0107, iter [01070, 01251], lr: 0.001101, loss: 0.4106
2022-09-28 17:25:49 - train: epoch 0107, iter [01080, 01251], lr: 0.001101, loss: 0.4127
2022-09-28 17:26:07 - train: epoch 0107, iter [01090, 01251], lr: 0.001101, loss: 0.4046
2022-09-28 17:26:25 - train: epoch 0107, iter [01100, 01251], lr: 0.001101, loss: 0.4153
2022-09-28 17:26:42 - train: epoch 0107, iter [01110, 01251], lr: 0.001101, loss: 0.3968
2022-09-28 17:27:00 - train: epoch 0107, iter [01120, 01251], lr: 0.001101, loss: 0.4092
2022-09-28 17:27:18 - train: epoch 0107, iter [01130, 01251], lr: 0.001101, loss: 0.4117
2022-09-28 17:27:35 - train: epoch 0107, iter [01140, 01251], lr: 0.001101, loss: 0.4057
2022-09-28 17:27:53 - train: epoch 0107, iter [01150, 01251], lr: 0.001101, loss: 0.4230
2022-09-28 17:28:11 - train: epoch 0107, iter [01160, 01251], lr: 0.001101, loss: 0.4253
2022-09-28 17:28:28 - train: epoch 0107, iter [01170, 01251], lr: 0.001101, loss: 0.4213
2022-09-28 17:28:46 - train: epoch 0107, iter [01180, 01251], lr: 0.001100, loss: 0.4128
2022-09-28 17:29:03 - train: epoch 0107, iter [01190, 01251], lr: 0.001100, loss: 0.3973
2022-09-28 17:29:21 - train: epoch 0107, iter [01200, 01251], lr: 0.001100, loss: 0.4089
2022-09-28 17:29:38 - train: epoch 0107, iter [01210, 01251], lr: 0.001100, loss: 0.4116
2022-09-28 17:29:56 - train: epoch 0107, iter [01220, 01251], lr: 0.001100, loss: 0.4018
2022-09-28 17:30:13 - train: epoch 0107, iter [01230, 01251], lr: 0.001100, loss: 0.4207
2022-09-28 17:30:31 - train: epoch 0107, iter [01240, 01251], lr: 0.001100, loss: 0.4103
2022-09-28 17:30:48 - train: epoch 0107, iter [01250, 01251], lr: 0.001100, loss: 0.4125
2022-09-28 17:30:52 - train: epoch 107, train_loss: 0.4128
2022-09-28 17:30:54 - until epoch: 107, best_loss: 0.4128
2022-09-28 17:30:54 - epoch 108 lr: 0.001100
2022-09-28 17:31:27 - train: epoch 0108, iter [00010, 01251], lr: 0.001100, loss: 0.4375
2022-09-28 17:31:45 - train: epoch 0108, iter [00020, 01251], lr: 0.001100, loss: 0.4036
2022-09-28 17:32:03 - train: epoch 0108, iter [00030, 01251], lr: 0.001100, loss: 0.4021
2022-09-28 17:32:20 - train: epoch 0108, iter [00040, 01251], lr: 0.001100, loss: 0.4221
2022-09-28 17:32:37 - train: epoch 0108, iter [00050, 01251], lr: 0.001100, loss: 0.4028
2022-09-28 17:32:55 - train: epoch 0108, iter [00060, 01251], lr: 0.001100, loss: 0.3982
2022-09-28 17:33:13 - train: epoch 0108, iter [00070, 01251], lr: 0.001100, loss: 0.4261
2022-09-28 17:33:30 - train: epoch 0108, iter [00080, 01251], lr: 0.001100, loss: 0.4242
2022-09-28 17:33:48 - train: epoch 0108, iter [00090, 01251], lr: 0.001100, loss: 0.4198
2022-09-28 17:34:05 - train: epoch 0108, iter [00100, 01251], lr: 0.001100, loss: 0.4208
2022-09-28 17:34:23 - train: epoch 0108, iter [00110, 01251], lr: 0.001100, loss: 0.4249
2022-09-28 17:34:41 - train: epoch 0108, iter [00120, 01251], lr: 0.001100, loss: 0.3935
2022-09-28 17:34:58 - train: epoch 0108, iter [00130, 01251], lr: 0.001100, loss: 0.4064
2022-09-28 17:35:16 - train: epoch 0108, iter [00140, 01251], lr: 0.001100, loss: 0.4343
2022-09-28 17:35:33 - train: epoch 0108, iter [00150, 01251], lr: 0.001100, loss: 0.4080
2022-09-28 17:35:51 - train: epoch 0108, iter [00160, 01251], lr: 0.001100, loss: 0.4210
2022-09-28 17:36:08 - train: epoch 0108, iter [00170, 01251], lr: 0.001100, loss: 0.4169
2022-09-28 17:36:26 - train: epoch 0108, iter [00180, 01251], lr: 0.001100, loss: 0.4204
2022-09-28 17:36:43 - train: epoch 0108, iter [00190, 01251], lr: 0.001100, loss: 0.4137
2022-09-28 17:37:01 - train: epoch 0108, iter [00200, 01251], lr: 0.001100, loss: 0.4168
2022-09-28 17:37:18 - train: epoch 0108, iter [00210, 01251], lr: 0.001100, loss: 0.4152
2022-09-28 17:37:36 - train: epoch 0108, iter [00220, 01251], lr: 0.001100, loss: 0.4256
2022-09-28 17:37:53 - train: epoch 0108, iter [00230, 01251], lr: 0.001100, loss: 0.4160
2022-09-28 17:38:11 - train: epoch 0108, iter [00240, 01251], lr: 0.001100, loss: 0.4230
2022-09-28 17:38:29 - train: epoch 0108, iter [00250, 01251], lr: 0.001100, loss: 0.4295
2022-09-28 17:38:46 - train: epoch 0108, iter [00260, 01251], lr: 0.001100, loss: 0.4079
2022-09-28 17:39:04 - train: epoch 0108, iter [00270, 01251], lr: 0.001100, loss: 0.4270
2022-09-28 17:39:21 - train: epoch 0108, iter [00280, 01251], lr: 0.001100, loss: 0.4068
2022-09-28 17:39:39 - train: epoch 0108, iter [00290, 01251], lr: 0.001100, loss: 0.4018
2022-09-28 17:39:56 - train: epoch 0108, iter [00300, 01251], lr: 0.001100, loss: 0.4037
2022-09-28 17:40:14 - train: epoch 0108, iter [00310, 01251], lr: 0.001100, loss: 0.4202
2022-09-28 17:40:32 - train: epoch 0108, iter [00320, 01251], lr: 0.001100, loss: 0.4121
2022-09-28 17:40:49 - train: epoch 0108, iter [00330, 01251], lr: 0.001100, loss: 0.4015
2022-09-28 17:41:07 - train: epoch 0108, iter [00340, 01251], lr: 0.001100, loss: 0.4015
2022-09-28 17:41:24 - train: epoch 0108, iter [00350, 01251], lr: 0.001100, loss: 0.4199
2022-09-28 17:41:42 - train: epoch 0108, iter [00360, 01251], lr: 0.001099, loss: 0.4078
2022-09-28 17:41:59 - train: epoch 0108, iter [00370, 01251], lr: 0.001099, loss: 0.4010
2022-09-28 17:42:17 - train: epoch 0108, iter [00380, 01251], lr: 0.001099, loss: 0.4241
2022-09-28 17:42:34 - train: epoch 0108, iter [00390, 01251], lr: 0.001099, loss: 0.4339
2022-09-28 17:42:51 - train: epoch 0108, iter [00400, 01251], lr: 0.001099, loss: 0.4091
2022-09-28 17:43:09 - train: epoch 0108, iter [00410, 01251], lr: 0.001099, loss: 0.4285
2022-09-28 17:43:26 - train: epoch 0108, iter [00420, 01251], lr: 0.001099, loss: 0.4142
2022-09-28 17:43:44 - train: epoch 0108, iter [00430, 01251], lr: 0.001099, loss: 0.4199
2022-09-28 17:44:02 - train: epoch 0108, iter [00440, 01251], lr: 0.001099, loss: 0.4135
2022-09-28 17:44:19 - train: epoch 0108, iter [00450, 01251], lr: 0.001099, loss: 0.4207
2022-09-28 17:44:36 - train: epoch 0108, iter [00460, 01251], lr: 0.001099, loss: 0.4002
2022-09-28 17:44:54 - train: epoch 0108, iter [00470, 01251], lr: 0.001099, loss: 0.4198
2022-09-28 17:45:11 - train: epoch 0108, iter [00480, 01251], lr: 0.001099, loss: 0.4319
2022-09-28 17:45:29 - train: epoch 0108, iter [00490, 01251], lr: 0.001099, loss: 0.4133
2022-09-28 17:45:46 - train: epoch 0108, iter [00500, 01251], lr: 0.001099, loss: 0.4053
2022-09-28 17:46:04 - train: epoch 0108, iter [00510, 01251], lr: 0.001099, loss: 0.4117
2022-09-28 17:46:21 - train: epoch 0108, iter [00520, 01251], lr: 0.001099, loss: 0.4246
2022-09-28 17:46:39 - train: epoch 0108, iter [00530, 01251], lr: 0.001099, loss: 0.3964
2022-09-28 17:46:56 - train: epoch 0108, iter [00540, 01251], lr: 0.001099, loss: 0.4105
2022-09-28 17:47:14 - train: epoch 0108, iter [00550, 01251], lr: 0.001099, loss: 0.4121
2022-09-28 17:47:31 - train: epoch 0108, iter [00560, 01251], lr: 0.001099, loss: 0.4192
2022-09-28 17:47:49 - train: epoch 0108, iter [00570, 01251], lr: 0.001099, loss: 0.4193
2022-09-28 17:48:06 - train: epoch 0108, iter [00580, 01251], lr: 0.001099, loss: 0.4074
2022-09-28 17:48:23 - train: epoch 0108, iter [00590, 01251], lr: 0.001099, loss: 0.4150
2022-09-28 17:48:41 - train: epoch 0108, iter [00600, 01251], lr: 0.001099, loss: 0.3969
2022-09-28 17:48:58 - train: epoch 0108, iter [00610, 01251], lr: 0.001099, loss: 0.4119
2022-09-28 17:49:16 - train: epoch 0108, iter [00620, 01251], lr: 0.001099, loss: 0.4045
2022-09-28 17:49:33 - train: epoch 0108, iter [00630, 01251], lr: 0.001099, loss: 0.4255
2022-09-28 17:49:51 - train: epoch 0108, iter [00640, 01251], lr: 0.001099, loss: 0.4091
2022-09-28 17:50:08 - train: epoch 0108, iter [00650, 01251], lr: 0.001099, loss: 0.4186
2022-09-28 17:50:26 - train: epoch 0108, iter [00660, 01251], lr: 0.001099, loss: 0.4030
2022-09-28 17:50:44 - train: epoch 0108, iter [00670, 01251], lr: 0.001099, loss: 0.4194
2022-09-28 17:51:01 - train: epoch 0108, iter [00680, 01251], lr: 0.001099, loss: 0.4091
2022-09-28 17:51:19 - train: epoch 0108, iter [00690, 01251], lr: 0.001099, loss: 0.4073
2022-09-28 17:51:36 - train: epoch 0108, iter [00700, 01251], lr: 0.001099, loss: 0.4278
2022-09-28 17:51:53 - train: epoch 0108, iter [00710, 01251], lr: 0.001099, loss: 0.3959
2022-09-28 17:52:11 - train: epoch 0108, iter [00720, 01251], lr: 0.001099, loss: 0.4030
2022-09-28 17:52:28 - train: epoch 0108, iter [00730, 01251], lr: 0.001099, loss: 0.4081
2022-09-28 17:52:46 - train: epoch 0108, iter [00740, 01251], lr: 0.001099, loss: 0.4237
2022-09-28 17:53:03 - train: epoch 0108, iter [00750, 01251], lr: 0.001099, loss: 0.4286
2022-09-28 17:53:21 - train: epoch 0108, iter [00760, 01251], lr: 0.001099, loss: 0.4131
2022-09-28 17:53:38 - train: epoch 0108, iter [00770, 01251], lr: 0.001099, loss: 0.4080
2022-09-28 17:53:55 - train: epoch 0108, iter [00780, 01251], lr: 0.001099, loss: 0.3992
2022-09-28 17:54:13 - train: epoch 0108, iter [00790, 01251], lr: 0.001098, loss: 0.4247
2022-09-28 17:54:30 - train: epoch 0108, iter [00800, 01251], lr: 0.001098, loss: 0.4255
2022-09-28 17:54:48 - train: epoch 0108, iter [00810, 01251], lr: 0.001098, loss: 0.3881
2022-09-28 17:55:06 - train: epoch 0108, iter [00820, 01251], lr: 0.001098, loss: 0.4314
2022-09-28 17:55:23 - train: epoch 0108, iter [00830, 01251], lr: 0.001098, loss: 0.3961
2022-09-28 17:55:41 - train: epoch 0108, iter [00840, 01251], lr: 0.001098, loss: 0.4242
2022-09-28 17:55:58 - train: epoch 0108, iter [00850, 01251], lr: 0.001098, loss: 0.4243
2022-09-28 17:56:15 - train: epoch 0108, iter [00860, 01251], lr: 0.001098, loss: 0.4213
2022-09-28 17:56:33 - train: epoch 0108, iter [00870, 01251], lr: 0.001098, loss: 0.4182
2022-09-28 17:56:50 - train: epoch 0108, iter [00880, 01251], lr: 0.001098, loss: 0.3990
2022-09-28 17:57:07 - train: epoch 0108, iter [00890, 01251], lr: 0.001098, loss: 0.4180
2022-09-28 17:57:25 - train: epoch 0108, iter [00900, 01251], lr: 0.001098, loss: 0.4277
2022-09-28 17:57:43 - train: epoch 0108, iter [00910, 01251], lr: 0.001098, loss: 0.4259
2022-09-28 17:58:00 - train: epoch 0108, iter [00920, 01251], lr: 0.001098, loss: 0.4202
2022-09-28 17:58:18 - train: epoch 0108, iter [00930, 01251], lr: 0.001098, loss: 0.4142
2022-09-28 17:58:35 - train: epoch 0108, iter [00940, 01251], lr: 0.001098, loss: 0.4270
2022-09-28 17:58:53 - train: epoch 0108, iter [00950, 01251], lr: 0.001098, loss: 0.4092
2022-09-28 17:59:10 - train: epoch 0108, iter [00960, 01251], lr: 0.001098, loss: 0.4127
2022-09-28 17:59:28 - train: epoch 0108, iter [00970, 01251], lr: 0.001098, loss: 0.4117
2022-09-28 17:59:45 - train: epoch 0108, iter [00980, 01251], lr: 0.001098, loss: 0.4053
2022-09-28 18:00:03 - train: epoch 0108, iter [00990, 01251], lr: 0.001098, loss: 0.4074
2022-09-28 18:00:20 - train: epoch 0108, iter [01000, 01251], lr: 0.001098, loss: 0.4316
2022-09-28 18:00:38 - train: epoch 0108, iter [01010, 01251], lr: 0.001098, loss: 0.4276
2022-09-28 18:00:56 - train: epoch 0108, iter [01020, 01251], lr: 0.001098, loss: 0.4047
2022-09-28 18:01:13 - train: epoch 0108, iter [01030, 01251], lr: 0.001098, loss: 0.4120
2022-09-28 18:01:31 - train: epoch 0108, iter [01040, 01251], lr: 0.001098, loss: 0.4206
2022-09-28 18:01:48 - train: epoch 0108, iter [01050, 01251], lr: 0.001098, loss: 0.4329
2022-09-28 18:02:05 - train: epoch 0108, iter [01060, 01251], lr: 0.001098, loss: 0.4122
2022-09-28 18:02:23 - train: epoch 0108, iter [01070, 01251], lr: 0.001098, loss: 0.4133
2022-09-28 18:02:40 - train: epoch 0108, iter [01080, 01251], lr: 0.001098, loss: 0.4286
2022-09-28 18:02:58 - train: epoch 0108, iter [01090, 01251], lr: 0.001098, loss: 0.4170
2022-09-28 18:03:15 - train: epoch 0108, iter [01100, 01251], lr: 0.001098, loss: 0.3979
2022-09-28 18:03:33 - train: epoch 0108, iter [01110, 01251], lr: 0.001098, loss: 0.4199
2022-09-28 18:03:50 - train: epoch 0108, iter [01120, 01251], lr: 0.001098, loss: 0.4117
2022-09-28 18:04:08 - train: epoch 0108, iter [01130, 01251], lr: 0.001098, loss: 0.4099
2022-09-28 18:04:25 - train: epoch 0108, iter [01140, 01251], lr: 0.001098, loss: 0.3922
2022-09-28 18:04:42 - train: epoch 0108, iter [01150, 01251], lr: 0.001098, loss: 0.4102
2022-09-28 18:05:00 - train: epoch 0108, iter [01160, 01251], lr: 0.001098, loss: 0.4090
2022-09-28 18:05:18 - train: epoch 0108, iter [01170, 01251], lr: 0.001098, loss: 0.4165
2022-09-28 18:05:35 - train: epoch 0108, iter [01180, 01251], lr: 0.001098, loss: 0.4269
2022-09-28 18:05:53 - train: epoch 0108, iter [01190, 01251], lr: 0.001098, loss: 0.4024
2022-09-28 18:06:11 - train: epoch 0108, iter [01200, 01251], lr: 0.001098, loss: 0.4228
2022-09-28 18:06:28 - train: epoch 0108, iter [01210, 01251], lr: 0.001098, loss: 0.4316
2022-09-28 18:06:45 - train: epoch 0108, iter [01220, 01251], lr: 0.001097, loss: 0.4143
2022-09-28 18:07:03 - train: epoch 0108, iter [01230, 01251], lr: 0.001097, loss: 0.4072
2022-09-28 18:07:20 - train: epoch 0108, iter [01240, 01251], lr: 0.001097, loss: 0.4215
2022-09-28 18:07:37 - train: epoch 0108, iter [01250, 01251], lr: 0.001097, loss: 0.4184
2022-09-28 18:07:40 - train: epoch 108, train_loss: 0.4129
2022-09-28 18:07:42 - until epoch: 108, best_loss: 0.4128
2022-09-28 18:07:42 - epoch 109 lr: 0.001097
2022-09-28 18:08:15 - train: epoch 0109, iter [00010, 01251], lr: 0.001097, loss: 0.4227
2022-09-28 18:08:33 - train: epoch 0109, iter [00020, 01251], lr: 0.001097, loss: 0.4152
2022-09-28 18:08:51 - train: epoch 0109, iter [00030, 01251], lr: 0.001097, loss: 0.4150
2022-09-28 18:09:09 - train: epoch 0109, iter [00040, 01251], lr: 0.001097, loss: 0.4104
2022-09-28 18:09:27 - train: epoch 0109, iter [00050, 01251], lr: 0.001097, loss: 0.4043
2022-09-28 18:09:44 - train: epoch 0109, iter [00060, 01251], lr: 0.001097, loss: 0.3916
2022-09-28 18:10:02 - train: epoch 0109, iter [00070, 01251], lr: 0.001097, loss: 0.4111
2022-09-28 18:10:20 - train: epoch 0109, iter [00080, 01251], lr: 0.001097, loss: 0.4309
2022-09-28 18:10:37 - train: epoch 0109, iter [00090, 01251], lr: 0.001097, loss: 0.4023
2022-09-28 18:10:55 - train: epoch 0109, iter [00100, 01251], lr: 0.001097, loss: 0.4040
2022-09-28 18:11:12 - train: epoch 0109, iter [00110, 01251], lr: 0.001097, loss: 0.3961
2022-09-28 18:11:30 - train: epoch 0109, iter [00120, 01251], lr: 0.001097, loss: 0.4035
2022-09-28 18:11:48 - train: epoch 0109, iter [00130, 01251], lr: 0.001097, loss: 0.4179
2022-09-28 18:12:05 - train: epoch 0109, iter [00140, 01251], lr: 0.001097, loss: 0.4286
2022-09-28 18:12:23 - train: epoch 0109, iter [00150, 01251], lr: 0.001097, loss: 0.4306
2022-09-28 18:12:41 - train: epoch 0109, iter [00160, 01251], lr: 0.001097, loss: 0.4214
2022-09-28 18:12:58 - train: epoch 0109, iter [00170, 01251], lr: 0.001097, loss: 0.4108
2022-09-28 18:13:16 - train: epoch 0109, iter [00180, 01251], lr: 0.001097, loss: 0.4114
2022-09-28 18:13:33 - train: epoch 0109, iter [00190, 01251], lr: 0.001097, loss: 0.4028
2022-09-28 18:13:51 - train: epoch 0109, iter [00200, 01251], lr: 0.001097, loss: 0.3974
2022-09-28 18:14:08 - train: epoch 0109, iter [00210, 01251], lr: 0.001097, loss: 0.4156
2022-09-28 18:14:26 - train: epoch 0109, iter [00220, 01251], lr: 0.001097, loss: 0.4076
2022-09-28 18:14:44 - train: epoch 0109, iter [00230, 01251], lr: 0.001097, loss: 0.4164
2022-09-28 18:15:01 - train: epoch 0109, iter [00240, 01251], lr: 0.001097, loss: 0.3967
2022-09-28 18:15:19 - train: epoch 0109, iter [00250, 01251], lr: 0.001097, loss: 0.4098
2022-09-28 18:15:37 - train: epoch 0109, iter [00260, 01251], lr: 0.001097, loss: 0.4046
2022-09-28 18:15:54 - train: epoch 0109, iter [00270, 01251], lr: 0.001097, loss: 0.4224
2022-09-28 18:16:12 - train: epoch 0109, iter [00280, 01251], lr: 0.001097, loss: 0.4310
2022-09-28 18:16:30 - train: epoch 0109, iter [00290, 01251], lr: 0.001097, loss: 0.4148
2022-09-28 18:16:48 - train: epoch 0109, iter [00300, 01251], lr: 0.001097, loss: 0.4152
2022-09-28 18:17:05 - train: epoch 0109, iter [00310, 01251], lr: 0.001097, loss: 0.4077
2022-09-28 18:17:23 - train: epoch 0109, iter [00320, 01251], lr: 0.001097, loss: 0.3854
2022-09-28 18:17:41 - train: epoch 0109, iter [00330, 01251], lr: 0.001097, loss: 0.4032
2022-09-28 18:17:58 - train: epoch 0109, iter [00340, 01251], lr: 0.001097, loss: 0.4009
2022-09-28 18:18:16 - train: epoch 0109, iter [00350, 01251], lr: 0.001097, loss: 0.4153
2022-09-28 18:18:34 - train: epoch 0109, iter [00360, 01251], lr: 0.001097, loss: 0.4251
2022-09-28 18:18:51 - train: epoch 0109, iter [00370, 01251], lr: 0.001097, loss: 0.4210
2022-09-28 18:19:09 - train: epoch 0109, iter [00380, 01251], lr: 0.001097, loss: 0.4071
2022-09-28 18:19:27 - train: epoch 0109, iter [00390, 01251], lr: 0.001097, loss: 0.3987
2022-09-28 18:19:44 - train: epoch 0109, iter [00400, 01251], lr: 0.001096, loss: 0.4103
2022-09-28 18:20:02 - train: epoch 0109, iter [00410, 01251], lr: 0.001096, loss: 0.4093
2022-09-28 18:20:20 - train: epoch 0109, iter [00420, 01251], lr: 0.001096, loss: 0.4177
2022-09-28 18:20:38 - train: epoch 0109, iter [00430, 01251], lr: 0.001096, loss: 0.4100
2022-09-28 18:20:55 - train: epoch 0109, iter [00440, 01251], lr: 0.001096, loss: 0.4024
2022-09-28 18:21:13 - train: epoch 0109, iter [00450, 01251], lr: 0.001096, loss: 0.4259
2022-09-28 18:21:31 - train: epoch 0109, iter [00460, 01251], lr: 0.001096, loss: 0.4125
2022-09-28 18:21:49 - train: epoch 0109, iter [00470, 01251], lr: 0.001096, loss: 0.4172
2022-09-28 18:22:06 - train: epoch 0109, iter [00480, 01251], lr: 0.001096, loss: 0.4276
2022-09-28 18:22:24 - train: epoch 0109, iter [00490, 01251], lr: 0.001096, loss: 0.3981
2022-09-28 18:22:42 - train: epoch 0109, iter [00500, 01251], lr: 0.001096, loss: 0.4249
2022-09-28 18:23:00 - train: epoch 0109, iter [00510, 01251], lr: 0.001096, loss: 0.4096
2022-09-28 18:23:17 - train: epoch 0109, iter [00520, 01251], lr: 0.001096, loss: 0.4264
2022-09-28 18:23:35 - train: epoch 0109, iter [00530, 01251], lr: 0.001096, loss: 0.4141
2022-09-28 18:23:53 - train: epoch 0109, iter [00540, 01251], lr: 0.001096, loss: 0.4126
2022-09-28 18:24:10 - train: epoch 0109, iter [00550, 01251], lr: 0.001096, loss: 0.4230
2022-09-28 18:24:28 - train: epoch 0109, iter [00560, 01251], lr: 0.001096, loss: 0.4077
2022-09-28 18:24:46 - train: epoch 0109, iter [00570, 01251], lr: 0.001096, loss: 0.4141
2022-09-28 18:25:03 - train: epoch 0109, iter [00580, 01251], lr: 0.001096, loss: 0.4329
2022-09-28 18:25:21 - train: epoch 0109, iter [00590, 01251], lr: 0.001096, loss: 0.4292
2022-09-28 18:25:38 - train: epoch 0109, iter [00600, 01251], lr: 0.001096, loss: 0.4159
2022-09-28 18:25:56 - train: epoch 0109, iter [00610, 01251], lr: 0.001096, loss: 0.4075
2022-09-28 18:26:14 - train: epoch 0109, iter [00620, 01251], lr: 0.001096, loss: 0.4222
2022-09-28 18:26:31 - train: epoch 0109, iter [00630, 01251], lr: 0.001096, loss: 0.4222
2022-09-28 18:26:49 - train: epoch 0109, iter [00640, 01251], lr: 0.001096, loss: 0.4328
2022-09-28 18:27:07 - train: epoch 0109, iter [00650, 01251], lr: 0.001096, loss: 0.4234
2022-09-28 18:27:24 - train: epoch 0109, iter [00660, 01251], lr: 0.001096, loss: 0.4271
2022-09-28 18:27:42 - train: epoch 0109, iter [00670, 01251], lr: 0.001096, loss: 0.4123
2022-09-28 18:27:59 - train: epoch 0109, iter [00680, 01251], lr: 0.001096, loss: 0.4024
2022-09-28 18:28:17 - train: epoch 0109, iter [00690, 01251], lr: 0.001096, loss: 0.4079
2022-09-28 18:28:34 - train: epoch 0109, iter [00700, 01251], lr: 0.001096, loss: 0.3896
2022-09-28 18:28:52 - train: epoch 0109, iter [00710, 01251], lr: 0.001096, loss: 0.4258
2022-09-28 18:29:09 - train: epoch 0109, iter [00720, 01251], lr: 0.001096, loss: 0.4397
2022-09-28 18:29:27 - train: epoch 0109, iter [00730, 01251], lr: 0.001096, loss: 0.4288
2022-09-28 18:29:45 - train: epoch 0109, iter [00740, 01251], lr: 0.001096, loss: 0.4199
2022-09-28 18:30:03 - train: epoch 0109, iter [00750, 01251], lr: 0.001096, loss: 0.4201
2022-09-28 18:30:20 - train: epoch 0109, iter [00760, 01251], lr: 0.001096, loss: 0.4132
2022-09-28 18:30:38 - train: epoch 0109, iter [00770, 01251], lr: 0.001096, loss: 0.4067
2022-09-28 18:30:56 - train: epoch 0109, iter [00780, 01251], lr: 0.001096, loss: 0.4081
2022-09-28 18:31:13 - train: epoch 0109, iter [00790, 01251], lr: 0.001096, loss: 0.4002
2022-09-28 18:31:31 - train: epoch 0109, iter [00800, 01251], lr: 0.001096, loss: 0.4191
2022-09-28 18:31:48 - train: epoch 0109, iter [00810, 01251], lr: 0.001096, loss: 0.4064
2022-09-28 18:32:06 - train: epoch 0109, iter [00820, 01251], lr: 0.001095, loss: 0.4109
2022-09-28 18:32:24 - train: epoch 0109, iter [00830, 01251], lr: 0.001095, loss: 0.4184
2022-09-28 18:32:41 - train: epoch 0109, iter [00840, 01251], lr: 0.001095, loss: 0.4108
2022-09-28 18:32:59 - train: epoch 0109, iter [00850, 01251], lr: 0.001095, loss: 0.4166
2022-09-28 18:33:17 - train: epoch 0109, iter [00860, 01251], lr: 0.001095, loss: 0.3989
2022-09-28 18:33:35 - train: epoch 0109, iter [00870, 01251], lr: 0.001095, loss: 0.4256
2022-09-28 18:33:52 - train: epoch 0109, iter [00880, 01251], lr: 0.001095, loss: 0.4199
2022-09-28 18:34:10 - train: epoch 0109, iter [00890, 01251], lr: 0.001095, loss: 0.4100
2022-09-28 18:34:27 - train: epoch 0109, iter [00900, 01251], lr: 0.001095, loss: 0.4190
2022-09-28 18:34:45 - train: epoch 0109, iter [00910, 01251], lr: 0.001095, loss: 0.4031
2022-09-28 18:35:03 - train: epoch 0109, iter [00920, 01251], lr: 0.001095, loss: 0.4165
2022-09-28 18:35:21 - train: epoch 0109, iter [00930, 01251], lr: 0.001095, loss: 0.4016
2022-09-28 18:35:38 - train: epoch 0109, iter [00940, 01251], lr: 0.001095, loss: 0.4160
2022-09-28 18:35:56 - train: epoch 0109, iter [00950, 01251], lr: 0.001095, loss: 0.4307
2022-09-28 18:36:13 - train: epoch 0109, iter [00960, 01251], lr: 0.001095, loss: 0.4358
2022-09-28 18:36:31 - train: epoch 0109, iter [00970, 01251], lr: 0.001095, loss: 0.4182
2022-09-28 18:36:49 - train: epoch 0109, iter [00980, 01251], lr: 0.001095, loss: 0.4035
2022-09-28 18:37:06 - train: epoch 0109, iter [00990, 01251], lr: 0.001095, loss: 0.4144
2022-09-28 18:37:24 - train: epoch 0109, iter [01000, 01251], lr: 0.001095, loss: 0.4165
2022-09-28 18:37:41 - train: epoch 0109, iter [01010, 01251], lr: 0.001095, loss: 0.4002
2022-09-28 18:37:59 - train: epoch 0109, iter [01020, 01251], lr: 0.001095, loss: 0.4173
2022-09-28 18:38:17 - train: epoch 0109, iter [01030, 01251], lr: 0.001095, loss: 0.3930
2022-09-28 18:38:35 - train: epoch 0109, iter [01040, 01251], lr: 0.001095, loss: 0.3923
2022-09-28 18:38:52 - train: epoch 0109, iter [01050, 01251], lr: 0.001095, loss: 0.4291
2022-09-28 18:39:10 - train: epoch 0109, iter [01060, 01251], lr: 0.001095, loss: 0.4423
2022-09-28 18:39:27 - train: epoch 0109, iter [01070, 01251], lr: 0.001095, loss: 0.3977
2022-09-28 18:39:45 - train: epoch 0109, iter [01080, 01251], lr: 0.001095, loss: 0.4145
2022-09-28 18:40:02 - train: epoch 0109, iter [01090, 01251], lr: 0.001095, loss: 0.4089
2022-09-28 18:40:20 - train: epoch 0109, iter [01100, 01251], lr: 0.001095, loss: 0.4334
2022-09-28 18:40:38 - train: epoch 0109, iter [01110, 01251], lr: 0.001095, loss: 0.4089
2022-09-28 18:40:55 - train: epoch 0109, iter [01120, 01251], lr: 0.001095, loss: 0.4202
2022-09-28 18:41:13 - train: epoch 0109, iter [01130, 01251], lr: 0.001095, loss: 0.4057
2022-09-28 18:41:31 - train: epoch 0109, iter [01140, 01251], lr: 0.001095, loss: 0.4104
2022-09-28 18:41:48 - train: epoch 0109, iter [01150, 01251], lr: 0.001095, loss: 0.4065
2022-09-28 18:42:06 - train: epoch 0109, iter [01160, 01251], lr: 0.001095, loss: 0.4103
2022-09-28 18:42:23 - train: epoch 0109, iter [01170, 01251], lr: 0.001095, loss: 0.4041
2022-09-28 18:42:41 - train: epoch 0109, iter [01180, 01251], lr: 0.001095, loss: 0.3995
2022-09-28 18:42:59 - train: epoch 0109, iter [01190, 01251], lr: 0.001095, loss: 0.4120
2022-09-28 18:43:16 - train: epoch 0109, iter [01200, 01251], lr: 0.001095, loss: 0.4075
2022-09-28 18:43:34 - train: epoch 0109, iter [01210, 01251], lr: 0.001095, loss: 0.3984
2022-09-28 18:43:52 - train: epoch 0109, iter [01220, 01251], lr: 0.001095, loss: 0.3959
2022-09-28 18:44:09 - train: epoch 0109, iter [01230, 01251], lr: 0.001095, loss: 0.4334
2022-09-28 18:44:27 - train: epoch 0109, iter [01240, 01251], lr: 0.001095, loss: 0.3915
2022-09-28 18:44:44 - train: epoch 0109, iter [01250, 01251], lr: 0.001094, loss: 0.3978
2022-09-28 18:44:48 - train: epoch 109, train_loss: 0.4128
2022-09-28 18:44:50 - until epoch: 109, best_loss: 0.4128
2022-09-28 18:44:50 - epoch 110 lr: 0.001094
2022-09-28 18:45:23 - train: epoch 0110, iter [00010, 01251], lr: 0.001094, loss: 0.3953
2022-09-28 18:45:41 - train: epoch 0110, iter [00020, 01251], lr: 0.001094, loss: 0.4405
2022-09-28 18:45:59 - train: epoch 0110, iter [00030, 01251], lr: 0.001094, loss: 0.4182
2022-09-28 18:46:17 - train: epoch 0110, iter [00040, 01251], lr: 0.001094, loss: 0.4375
2022-09-28 18:46:34 - train: epoch 0110, iter [00050, 01251], lr: 0.001094, loss: 0.4211
2022-09-28 18:46:52 - train: epoch 0110, iter [00060, 01251], lr: 0.001094, loss: 0.4252
2022-09-28 18:47:10 - train: epoch 0110, iter [00070, 01251], lr: 0.001094, loss: 0.4166
2022-09-28 18:47:27 - train: epoch 0110, iter [00080, 01251], lr: 0.001094, loss: 0.4238
2022-09-28 18:47:45 - train: epoch 0110, iter [00090, 01251], lr: 0.001094, loss: 0.3871
2022-09-28 18:48:03 - train: epoch 0110, iter [00100, 01251], lr: 0.001094, loss: 0.4222
2022-09-28 18:48:20 - train: epoch 0110, iter [00110, 01251], lr: 0.001094, loss: 0.4187
2022-09-28 18:48:38 - train: epoch 0110, iter [00120, 01251], lr: 0.001094, loss: 0.4151
2022-09-28 18:48:55 - train: epoch 0110, iter [00130, 01251], lr: 0.001094, loss: 0.4082
2022-09-28 18:49:13 - train: epoch 0110, iter [00140, 01251], lr: 0.001094, loss: 0.4051
2022-09-28 18:49:31 - train: epoch 0110, iter [00150, 01251], lr: 0.001094, loss: 0.3913
2022-09-28 18:49:48 - train: epoch 0110, iter [00160, 01251], lr: 0.001094, loss: 0.4287
2022-09-28 18:50:06 - train: epoch 0110, iter [00170, 01251], lr: 0.001094, loss: 0.4260
2022-09-28 18:50:24 - train: epoch 0110, iter [00180, 01251], lr: 0.001094, loss: 0.4062
2022-09-28 18:50:41 - train: epoch 0110, iter [00190, 01251], lr: 0.001094, loss: 0.3972
2022-09-28 18:50:59 - train: epoch 0110, iter [00200, 01251], lr: 0.001094, loss: 0.4085
2022-09-28 18:51:16 - train: epoch 0110, iter [00210, 01251], lr: 0.001094, loss: 0.3920
2022-09-28 18:51:34 - train: epoch 0110, iter [00220, 01251], lr: 0.001094, loss: 0.4230
2022-09-28 18:51:52 - train: epoch 0110, iter [00230, 01251], lr: 0.001094, loss: 0.4045
2022-09-28 18:52:10 - train: epoch 0110, iter [00240, 01251], lr: 0.001094, loss: 0.4201
2022-09-28 18:52:27 - train: epoch 0110, iter [00250, 01251], lr: 0.001094, loss: 0.4200
2022-09-28 18:52:45 - train: epoch 0110, iter [00260, 01251], lr: 0.001094, loss: 0.4144
2022-09-28 18:53:03 - train: epoch 0110, iter [00270, 01251], lr: 0.001094, loss: 0.4290
2022-09-28 18:53:20 - train: epoch 0110, iter [00280, 01251], lr: 0.001094, loss: 0.4133
2022-09-28 18:53:39 - train: epoch 0110, iter [00290, 01251], lr: 0.001094, loss: 0.4036
2022-09-28 18:53:56 - train: epoch 0110, iter [00300, 01251], lr: 0.001094, loss: 0.4033
2022-09-28 18:54:14 - train: epoch 0110, iter [00310, 01251], lr: 0.001094, loss: 0.4299
2022-09-28 18:54:32 - train: epoch 0110, iter [00320, 01251], lr: 0.001094, loss: 0.4108
2022-09-28 18:54:49 - train: epoch 0110, iter [00330, 01251], lr: 0.001094, loss: 0.4079
2022-09-28 18:55:07 - train: epoch 0110, iter [00340, 01251], lr: 0.001094, loss: 0.4204
2022-09-28 18:55:25 - train: epoch 0110, iter [00350, 01251], lr: 0.001094, loss: 0.4113
2022-09-28 18:55:43 - train: epoch 0110, iter [00360, 01251], lr: 0.001094, loss: 0.4094
2022-09-28 18:56:00 - train: epoch 0110, iter [00370, 01251], lr: 0.001094, loss: 0.4046
2022-09-28 18:56:18 - train: epoch 0110, iter [00380, 01251], lr: 0.001094, loss: 0.4239
2022-09-28 18:56:35 - train: epoch 0110, iter [00390, 01251], lr: 0.001094, loss: 0.4331
2022-09-28 18:56:53 - train: epoch 0110, iter [00400, 01251], lr: 0.001094, loss: 0.4257
2022-09-28 18:57:11 - train: epoch 0110, iter [00410, 01251], lr: 0.001094, loss: 0.4228
2022-09-28 18:57:29 - train: epoch 0110, iter [00420, 01251], lr: 0.001093, loss: 0.4045
2022-09-28 18:57:46 - train: epoch 0110, iter [00430, 01251], lr: 0.001093, loss: 0.4036
2022-09-28 18:58:04 - train: epoch 0110, iter [00440, 01251], lr: 0.001093, loss: 0.4244
2022-09-28 18:58:21 - train: epoch 0110, iter [00450, 01251], lr: 0.001093, loss: 0.4124
2022-09-28 18:58:39 - train: epoch 0110, iter [00460, 01251], lr: 0.001093, loss: 0.4175
2022-09-28 18:58:57 - train: epoch 0110, iter [00470, 01251], lr: 0.001093, loss: 0.4204
2022-09-28 18:59:14 - train: epoch 0110, iter [00480, 01251], lr: 0.001093, loss: 0.4154
2022-09-28 18:59:32 - train: epoch 0110, iter [00490, 01251], lr: 0.001093, loss: 0.4197
2022-09-28 18:59:49 - train: epoch 0110, iter [00500, 01251], lr: 0.001093, loss: 0.4049
2022-09-28 19:00:07 - train: epoch 0110, iter [00510, 01251], lr: 0.001093, loss: 0.3979
2022-09-28 19:00:25 - train: epoch 0110, iter [00520, 01251], lr: 0.001093, loss: 0.4241
2022-09-28 19:00:42 - train: epoch 0110, iter [00530, 01251], lr: 0.001093, loss: 0.4189
2022-09-28 19:01:00 - train: epoch 0110, iter [00540, 01251], lr: 0.001093, loss: 0.4106
2022-09-28 19:01:17 - train: epoch 0110, iter [00550, 01251], lr: 0.001093, loss: 0.4299
2022-09-28 19:01:35 - train: epoch 0110, iter [00560, 01251], lr: 0.001093, loss: 0.4102
2022-09-28 19:01:53 - train: epoch 0110, iter [00570, 01251], lr: 0.001093, loss: 0.4187
2022-09-28 19:02:10 - train: epoch 0110, iter [00580, 01251], lr: 0.001093, loss: 0.4144
2022-09-28 19:02:28 - train: epoch 0110, iter [00590, 01251], lr: 0.001093, loss: 0.3982
2022-09-28 19:02:45 - train: epoch 0110, iter [00600, 01251], lr: 0.001093, loss: 0.4140
2022-09-28 19:03:03 - train: epoch 0110, iter [00610, 01251], lr: 0.001093, loss: 0.3990
2022-09-28 19:03:20 - train: epoch 0110, iter [00620, 01251], lr: 0.001093, loss: 0.4157
2022-09-28 19:03:38 - train: epoch 0110, iter [00630, 01251], lr: 0.001093, loss: 0.4001
2022-09-28 19:03:56 - train: epoch 0110, iter [00640, 01251], lr: 0.001093, loss: 0.3924
2022-09-28 19:04:13 - train: epoch 0110, iter [00650, 01251], lr: 0.001093, loss: 0.4175
2022-09-28 19:04:31 - train: epoch 0110, iter [00660, 01251], lr: 0.001093, loss: 0.4051
2022-09-28 19:04:49 - train: epoch 0110, iter [00670, 01251], lr: 0.001093, loss: 0.4117
2022-09-28 19:05:06 - train: epoch 0110, iter [00680, 01251], lr: 0.001093, loss: 0.3945
2022-09-28 19:05:24 - train: epoch 0110, iter [00690, 01251], lr: 0.001093, loss: 0.4087
2022-09-28 19:05:42 - train: epoch 0110, iter [00700, 01251], lr: 0.001093, loss: 0.4206
2022-09-28 19:05:59 - train: epoch 0110, iter [00710, 01251], lr: 0.001093, loss: 0.3979
2022-09-28 19:06:17 - train: epoch 0110, iter [00720, 01251], lr: 0.001093, loss: 0.4162
2022-09-28 19:06:35 - train: epoch 0110, iter [00730, 01251], lr: 0.001093, loss: 0.4097
2022-09-28 19:06:52 - train: epoch 0110, iter [00740, 01251], lr: 0.001093, loss: 0.4218
2022-09-28 19:07:10 - train: epoch 0110, iter [00750, 01251], lr: 0.001093, loss: 0.4221
2022-09-28 19:07:27 - train: epoch 0110, iter [00760, 01251], lr: 0.001093, loss: 0.3971
2022-09-28 19:07:45 - train: epoch 0110, iter [00770, 01251], lr: 0.001093, loss: 0.4337
2022-09-28 19:08:03 - train: epoch 0110, iter [00780, 01251], lr: 0.001093, loss: 0.4086
2022-09-28 19:08:20 - train: epoch 0110, iter [00790, 01251], lr: 0.001093, loss: 0.3947
2022-09-28 19:08:38 - train: epoch 0110, iter [00800, 01251], lr: 0.001093, loss: 0.4065
2022-09-28 19:08:56 - train: epoch 0110, iter [00810, 01251], lr: 0.001093, loss: 0.4161
2022-09-28 19:09:13 - train: epoch 0110, iter [00820, 01251], lr: 0.001093, loss: 0.4089
2022-09-28 19:09:31 - train: epoch 0110, iter [00830, 01251], lr: 0.001092, loss: 0.4098
2022-09-28 19:09:49 - train: epoch 0110, iter [00840, 01251], lr: 0.001092, loss: 0.4100
2022-09-28 19:10:07 - train: epoch 0110, iter [00850, 01251], lr: 0.001092, loss: 0.4071
2022-09-28 19:10:24 - train: epoch 0110, iter [00860, 01251], lr: 0.001092, loss: 0.4151
2022-09-28 19:10:42 - train: epoch 0110, iter [00870, 01251], lr: 0.001092, loss: 0.4025
2022-09-28 19:11:00 - train: epoch 0110, iter [00880, 01251], lr: 0.001092, loss: 0.4252
2022-09-28 19:11:18 - train: epoch 0110, iter [00890, 01251], lr: 0.001092, loss: 0.4167
2022-09-28 19:11:36 - train: epoch 0110, iter [00900, 01251], lr: 0.001092, loss: 0.3968
2022-09-28 19:11:53 - train: epoch 0110, iter [00910, 01251], lr: 0.001092, loss: 0.4122
2022-09-28 19:12:11 - train: epoch 0110, iter [00920, 01251], lr: 0.001092, loss: 0.4198
2022-09-28 19:12:29 - train: epoch 0110, iter [00930, 01251], lr: 0.001092, loss: 0.4151
2022-09-28 19:12:47 - train: epoch 0110, iter [00940, 01251], lr: 0.001092, loss: 0.3937
2022-09-28 19:13:05 - train: epoch 0110, iter [00950, 01251], lr: 0.001092, loss: 0.4209
2022-09-28 19:13:22 - train: epoch 0110, iter [00960, 01251], lr: 0.001092, loss: 0.4203
2022-09-28 19:13:40 - train: epoch 0110, iter [00970, 01251], lr: 0.001092, loss: 0.3969
2022-09-28 19:13:58 - train: epoch 0110, iter [00980, 01251], lr: 0.001092, loss: 0.4155
2022-09-28 19:14:15 - train: epoch 0110, iter [00990, 01251], lr: 0.001092, loss: 0.4115
2022-09-28 19:14:33 - train: epoch 0110, iter [01000, 01251], lr: 0.001092, loss: 0.4139
2022-09-28 19:14:51 - train: epoch 0110, iter [01010, 01251], lr: 0.001092, loss: 0.4238
2022-09-28 19:15:08 - train: epoch 0110, iter [01020, 01251], lr: 0.001092, loss: 0.4140
2022-09-28 19:15:26 - train: epoch 0110, iter [01030, 01251], lr: 0.001092, loss: 0.4174
2022-09-28 19:15:44 - train: epoch 0110, iter [01040, 01251], lr: 0.001092, loss: 0.4023
2022-09-28 19:16:01 - train: epoch 0110, iter [01050, 01251], lr: 0.001092, loss: 0.4232
2022-09-28 19:16:19 - train: epoch 0110, iter [01060, 01251], lr: 0.001092, loss: 0.4271
2022-09-28 19:16:37 - train: epoch 0110, iter [01070, 01251], lr: 0.001092, loss: 0.4172
2022-09-28 19:16:54 - train: epoch 0110, iter [01080, 01251], lr: 0.001092, loss: 0.4156
2022-09-28 19:17:12 - train: epoch 0110, iter [01090, 01251], lr: 0.001092, loss: 0.4010
2022-09-28 19:17:29 - train: epoch 0110, iter [01100, 01251], lr: 0.001092, loss: 0.4001
2022-09-28 19:17:47 - train: epoch 0110, iter [01110, 01251], lr: 0.001092, loss: 0.4123
2022-09-28 19:18:05 - train: epoch 0110, iter [01120, 01251], lr: 0.001092, loss: 0.4340
2022-09-28 19:18:22 - train: epoch 0110, iter [01130, 01251], lr: 0.001092, loss: 0.4128
2022-09-28 19:18:40 - train: epoch 0110, iter [01140, 01251], lr: 0.001092, loss: 0.4068
2022-09-28 19:18:58 - train: epoch 0110, iter [01150, 01251], lr: 0.001092, loss: 0.4013
2022-09-28 19:19:15 - train: epoch 0110, iter [01160, 01251], lr: 0.001092, loss: 0.3949
2022-09-28 19:19:33 - train: epoch 0110, iter [01170, 01251], lr: 0.001092, loss: 0.4308
2022-09-28 19:19:51 - train: epoch 0110, iter [01180, 01251], lr: 0.001092, loss: 0.4201
2022-09-28 19:20:09 - train: epoch 0110, iter [01190, 01251], lr: 0.001092, loss: 0.4134
2022-09-28 19:20:26 - train: epoch 0110, iter [01200, 01251], lr: 0.001092, loss: 0.3979
2022-09-28 19:20:44 - train: epoch 0110, iter [01210, 01251], lr: 0.001092, loss: 0.4222
2022-09-28 19:21:02 - train: epoch 0110, iter [01220, 01251], lr: 0.001092, loss: 0.4163
2022-09-28 19:21:19 - train: epoch 0110, iter [01230, 01251], lr: 0.001092, loss: 0.4235
2022-09-28 19:21:37 - train: epoch 0110, iter [01240, 01251], lr: 0.001092, loss: 0.4005
2022-09-28 19:21:54 - train: epoch 0110, iter [01250, 01251], lr: 0.001091, loss: 0.4079
2022-09-28 19:21:57 - train: epoch 110, train_loss: 0.4127
2022-09-28 19:22:00 - until epoch: 110, best_loss: 0.4127
2022-09-28 19:22:00 - epoch 111 lr: 0.001091
2022-09-28 19:22:33 - train: epoch 0111, iter [00010, 01251], lr: 0.001091, loss: 0.4132
2022-09-28 19:22:51 - train: epoch 0111, iter [00020, 01251], lr: 0.001091, loss: 0.4174
2022-09-28 19:23:08 - train: epoch 0111, iter [00030, 01251], lr: 0.001091, loss: 0.4208
2022-09-28 19:23:26 - train: epoch 0111, iter [00040, 01251], lr: 0.001091, loss: 0.4069
2022-09-28 19:23:44 - train: epoch 0111, iter [00050, 01251], lr: 0.001091, loss: 0.4165
2022-09-28 19:24:01 - train: epoch 0111, iter [00060, 01251], lr: 0.001091, loss: 0.4067
2022-09-28 19:24:19 - train: epoch 0111, iter [00070, 01251], lr: 0.001091, loss: 0.4235
2022-09-28 19:24:36 - train: epoch 0111, iter [00080, 01251], lr: 0.001091, loss: 0.4111
2022-09-28 19:24:54 - train: epoch 0111, iter [00090, 01251], lr: 0.001091, loss: 0.4001
2022-09-28 19:25:11 - train: epoch 0111, iter [00100, 01251], lr: 0.001091, loss: 0.4288
2022-09-28 19:25:29 - train: epoch 0111, iter [00110, 01251], lr: 0.001091, loss: 0.4222
2022-09-28 19:25:46 - train: epoch 0111, iter [00120, 01251], lr: 0.001091, loss: 0.4294
2022-09-28 19:26:04 - train: epoch 0111, iter [00130, 01251], lr: 0.001091, loss: 0.4070
2022-09-28 19:26:21 - train: epoch 0111, iter [00140, 01251], lr: 0.001091, loss: 0.4231
2022-09-28 19:26:39 - train: epoch 0111, iter [00150, 01251], lr: 0.001091, loss: 0.3980
2022-09-28 19:26:57 - train: epoch 0111, iter [00160, 01251], lr: 0.001091, loss: 0.4101
2022-09-28 19:27:14 - train: epoch 0111, iter [00170, 01251], lr: 0.001091, loss: 0.3981
2022-09-28 19:27:32 - train: epoch 0111, iter [00180, 01251], lr: 0.001091, loss: 0.4262
2022-09-28 19:27:49 - train: epoch 0111, iter [00190, 01251], lr: 0.001091, loss: 0.4293
2022-09-28 19:28:07 - train: epoch 0111, iter [00200, 01251], lr: 0.001091, loss: 0.3962
2022-09-28 19:28:24 - train: epoch 0111, iter [00210, 01251], lr: 0.001091, loss: 0.4098
2022-09-28 19:28:42 - train: epoch 0111, iter [00220, 01251], lr: 0.001091, loss: 0.3977
2022-09-28 19:28:59 - train: epoch 0111, iter [00230, 01251], lr: 0.001091, loss: 0.4182
2022-09-28 19:29:17 - train: epoch 0111, iter [00240, 01251], lr: 0.001091, loss: 0.4109
2022-09-28 19:29:34 - train: epoch 0111, iter [00250, 01251], lr: 0.001091, loss: 0.4073
2022-09-28 19:29:52 - train: epoch 0111, iter [00260, 01251], lr: 0.001091, loss: 0.4254
2022-09-28 19:30:10 - train: epoch 0111, iter [00270, 01251], lr: 0.001091, loss: 0.4128
2022-09-28 19:30:27 - train: epoch 0111, iter [00280, 01251], lr: 0.001091, loss: 0.4103
2022-09-28 19:30:44 - train: epoch 0111, iter [00290, 01251], lr: 0.001091, loss: 0.4087
2022-09-28 19:31:02 - train: epoch 0111, iter [00300, 01251], lr: 0.001091, loss: 0.4090
2022-09-28 19:31:19 - train: epoch 0111, iter [00310, 01251], lr: 0.001091, loss: 0.4180
2022-09-28 19:31:37 - train: epoch 0111, iter [00320, 01251], lr: 0.001091, loss: 0.4285
2022-09-28 19:31:54 - train: epoch 0111, iter [00330, 01251], lr: 0.001091, loss: 0.4162
2022-09-28 19:32:12 - train: epoch 0111, iter [00340, 01251], lr: 0.001091, loss: 0.4279
2022-09-28 19:32:29 - train: epoch 0111, iter [00350, 01251], lr: 0.001091, loss: 0.4149
2022-09-28 19:32:47 - train: epoch 0111, iter [00360, 01251], lr: 0.001091, loss: 0.4078
2022-09-28 19:33:05 - train: epoch 0111, iter [00370, 01251], lr: 0.001091, loss: 0.3932
2022-09-28 19:33:22 - train: epoch 0111, iter [00380, 01251], lr: 0.001091, loss: 0.4059
2022-09-28 19:33:40 - train: epoch 0111, iter [00390, 01251], lr: 0.001091, loss: 0.4063
2022-09-28 19:33:57 - train: epoch 0111, iter [00400, 01251], lr: 0.001091, loss: 0.4150
2022-09-28 19:34:15 - train: epoch 0111, iter [00410, 01251], lr: 0.001091, loss: 0.4073
2022-09-28 19:34:32 - train: epoch 0111, iter [00420, 01251], lr: 0.001090, loss: 0.4020
2022-09-28 19:34:50 - train: epoch 0111, iter [00430, 01251], lr: 0.001090, loss: 0.4296
2022-09-28 19:35:07 - train: epoch 0111, iter [00440, 01251], lr: 0.001090, loss: 0.4023
2022-09-28 19:35:24 - train: epoch 0111, iter [00450, 01251], lr: 0.001090, loss: 0.4283
2022-09-28 19:35:42 - train: epoch 0111, iter [00460, 01251], lr: 0.001090, loss: 0.3894
2022-09-28 19:35:59 - train: epoch 0111, iter [00470, 01251], lr: 0.001090, loss: 0.3983
2022-09-28 19:36:17 - train: epoch 0111, iter [00480, 01251], lr: 0.001090, loss: 0.3962
2022-09-28 19:36:34 - train: epoch 0111, iter [00490, 01251], lr: 0.001090, loss: 0.4073
2022-09-28 19:36:51 - train: epoch 0111, iter [00500, 01251], lr: 0.001090, loss: 0.4132
2022-09-28 19:37:09 - train: epoch 0111, iter [00510, 01251], lr: 0.001090, loss: 0.3950
2022-09-28 19:37:27 - train: epoch 0111, iter [00520, 01251], lr: 0.001090, loss: 0.4249
2022-09-28 19:37:44 - train: epoch 0111, iter [00530, 01251], lr: 0.001090, loss: 0.3919
2022-09-28 19:38:02 - train: epoch 0111, iter [00540, 01251], lr: 0.001090, loss: 0.4243
2022-09-28 19:38:20 - train: epoch 0111, iter [00550, 01251], lr: 0.001090, loss: 0.4088
2022-09-28 19:38:37 - train: epoch 0111, iter [00560, 01251], lr: 0.001090, loss: 0.4232
2022-09-28 19:38:55 - train: epoch 0111, iter [00570, 01251], lr: 0.001090, loss: 0.4299
2022-09-28 19:39:12 - train: epoch 0111, iter [00580, 01251], lr: 0.001090, loss: 0.4082
2022-09-28 19:39:30 - train: epoch 0111, iter [00590, 01251], lr: 0.001090, loss: 0.3899
2022-09-28 19:39:47 - train: epoch 0111, iter [00600, 01251], lr: 0.001090, loss: 0.4065
2022-09-28 19:40:05 - train: epoch 0111, iter [00610, 01251], lr: 0.001090, loss: 0.4083
2022-09-28 19:40:23 - train: epoch 0111, iter [00620, 01251], lr: 0.001090, loss: 0.4347
2022-09-28 19:40:40 - train: epoch 0111, iter [00630, 01251], lr: 0.001090, loss: 0.4324
2022-09-28 19:40:58 - train: epoch 0111, iter [00640, 01251], lr: 0.001090, loss: 0.3898
2022-09-28 19:41:16 - train: epoch 0111, iter [00650, 01251], lr: 0.001090, loss: 0.4086
2022-09-28 19:41:33 - train: epoch 0111, iter [00660, 01251], lr: 0.001090, loss: 0.4234
2022-09-28 19:41:51 - train: epoch 0111, iter [00670, 01251], lr: 0.001090, loss: 0.4096
2022-09-28 19:42:09 - train: epoch 0111, iter [00680, 01251], lr: 0.001090, loss: 0.4194
2022-09-28 19:42:27 - train: epoch 0111, iter [00690, 01251], lr: 0.001090, loss: 0.4021
2022-09-28 19:42:44 - train: epoch 0111, iter [00700, 01251], lr: 0.001090, loss: 0.3970
2022-09-28 19:43:02 - train: epoch 0111, iter [00710, 01251], lr: 0.001090, loss: 0.3982
2022-09-28 19:43:20 - train: epoch 0111, iter [00720, 01251], lr: 0.001090, loss: 0.4068
2022-09-28 19:43:37 - train: epoch 0111, iter [00730, 01251], lr: 0.001090, loss: 0.4114
2022-09-28 19:43:55 - train: epoch 0111, iter [00740, 01251], lr: 0.001090, loss: 0.4138
2022-09-28 19:44:13 - train: epoch 0111, iter [00750, 01251], lr: 0.001090, loss: 0.4165
2022-09-28 19:44:31 - train: epoch 0111, iter [00760, 01251], lr: 0.001090, loss: 0.4185
2022-09-28 19:44:49 - train: epoch 0111, iter [00770, 01251], lr: 0.001090, loss: 0.4246
2022-09-28 19:45:06 - train: epoch 0111, iter [00780, 01251], lr: 0.001090, loss: 0.4104
2022-09-28 19:45:24 - train: epoch 0111, iter [00790, 01251], lr: 0.001090, loss: 0.4110
2022-09-28 19:45:42 - train: epoch 0111, iter [00800, 01251], lr: 0.001090, loss: 0.4054
2022-09-28 19:45:59 - train: epoch 0111, iter [00810, 01251], lr: 0.001090, loss: 0.4223
2022-09-28 19:46:17 - train: epoch 0111, iter [00820, 01251], lr: 0.001090, loss: 0.4104
2022-09-28 19:46:35 - train: epoch 0111, iter [00830, 01251], lr: 0.001089, loss: 0.4188
2022-09-28 19:46:52 - train: epoch 0111, iter [00840, 01251], lr: 0.001089, loss: 0.3979
2022-09-28 19:47:10 - train: epoch 0111, iter [00850, 01251], lr: 0.001089, loss: 0.4516
2022-09-28 19:47:28 - train: epoch 0111, iter [00860, 01251], lr: 0.001089, loss: 0.4308
2022-09-28 19:47:46 - train: epoch 0111, iter [00870, 01251], lr: 0.001089, loss: 0.4043
2022-09-28 19:48:03 - train: epoch 0111, iter [00880, 01251], lr: 0.001089, loss: 0.4051
2022-09-28 19:48:21 - train: epoch 0111, iter [00890, 01251], lr: 0.001089, loss: 0.4028
2022-09-28 19:48:39 - train: epoch 0111, iter [00900, 01251], lr: 0.001089, loss: 0.4040
2022-09-28 19:48:56 - train: epoch 0111, iter [00910, 01251], lr: 0.001089, loss: 0.4130
2022-09-28 19:49:14 - train: epoch 0111, iter [00920, 01251], lr: 0.001089, loss: 0.4216
2022-09-28 19:49:31 - train: epoch 0111, iter [00930, 01251], lr: 0.001089, loss: 0.4295
2022-09-28 19:49:49 - train: epoch 0111, iter [00940, 01251], lr: 0.001089, loss: 0.4083
2022-09-28 19:50:07 - train: epoch 0111, iter [00950, 01251], lr: 0.001089, loss: 0.4071
2022-09-28 19:50:24 - train: epoch 0111, iter [00960, 01251], lr: 0.001089, loss: 0.4231
2022-09-28 19:50:42 - train: epoch 0111, iter [00970, 01251], lr: 0.001089, loss: 0.4049
2022-09-28 19:50:59 - train: epoch 0111, iter [00980, 01251], lr: 0.001089, loss: 0.4055
2022-09-28 19:51:17 - train: epoch 0111, iter [00990, 01251], lr: 0.001089, loss: 0.4289
2022-09-28 19:51:34 - train: epoch 0111, iter [01000, 01251], lr: 0.001089, loss: 0.4018
2022-09-28 19:51:52 - train: epoch 0111, iter [01010, 01251], lr: 0.001089, loss: 0.4159
2022-09-28 19:52:09 - train: epoch 0111, iter [01020, 01251], lr: 0.001089, loss: 0.4127
2022-09-28 19:52:27 - train: epoch 0111, iter [01030, 01251], lr: 0.001089, loss: 0.4182
2022-09-28 19:52:45 - train: epoch 0111, iter [01040, 01251], lr: 0.001089, loss: 0.4149
2022-09-28 19:53:03 - train: epoch 0111, iter [01050, 01251], lr: 0.001089, loss: 0.4075
2022-09-28 19:53:21 - train: epoch 0111, iter [01060, 01251], lr: 0.001089, loss: 0.4065
2022-09-28 19:53:39 - train: epoch 0111, iter [01070, 01251], lr: 0.001089, loss: 0.4063
2022-09-28 19:53:57 - train: epoch 0111, iter [01080, 01251], lr: 0.001089, loss: 0.4215
2022-09-28 19:54:14 - train: epoch 0111, iter [01090, 01251], lr: 0.001089, loss: 0.4266
2022-09-28 19:54:32 - train: epoch 0111, iter [01100, 01251], lr: 0.001089, loss: 0.4135
2022-09-28 19:54:51 - train: epoch 0111, iter [01110, 01251], lr: 0.001089, loss: 0.4127
2022-09-28 19:55:09 - train: epoch 0111, iter [01120, 01251], lr: 0.001089, loss: 0.4112
2022-09-28 19:55:26 - train: epoch 0111, iter [01130, 01251], lr: 0.001089, loss: 0.4050
2022-09-28 19:55:44 - train: epoch 0111, iter [01140, 01251], lr: 0.001089, loss: 0.4108
2022-09-28 19:56:02 - train: epoch 0111, iter [01150, 01251], lr: 0.001089, loss: 0.4116
2022-09-28 19:56:20 - train: epoch 0111, iter [01160, 01251], lr: 0.001089, loss: 0.4223
2022-09-28 19:56:38 - train: epoch 0111, iter [01170, 01251], lr: 0.001089, loss: 0.4040
2022-09-28 19:56:56 - train: epoch 0111, iter [01180, 01251], lr: 0.001089, loss: 0.4282
2022-09-28 19:57:14 - train: epoch 0111, iter [01190, 01251], lr: 0.001089, loss: 0.4211
2022-09-28 19:57:32 - train: epoch 0111, iter [01200, 01251], lr: 0.001089, loss: 0.4089
2022-09-28 19:57:50 - train: epoch 0111, iter [01210, 01251], lr: 0.001089, loss: 0.4133
2022-09-28 19:58:07 - train: epoch 0111, iter [01220, 01251], lr: 0.001089, loss: 0.4305
2022-09-28 19:58:25 - train: epoch 0111, iter [01230, 01251], lr: 0.001089, loss: 0.4138
2022-09-28 19:58:43 - train: epoch 0111, iter [01240, 01251], lr: 0.001088, loss: 0.4043
2022-09-28 19:59:00 - train: epoch 0111, iter [01250, 01251], lr: 0.001088, loss: 0.4079
2022-09-28 19:59:04 - train: epoch 111, train_loss: 0.4126
2022-09-28 19:59:07 - until epoch: 111, best_loss: 0.4126
2022-09-28 19:59:07 - epoch 112 lr: 0.001088
2022-09-28 19:59:41 - train: epoch 0112, iter [00010, 01251], lr: 0.001088, loss: 0.3914
2022-09-28 19:59:59 - train: epoch 0112, iter [00020, 01251], lr: 0.001088, loss: 0.4289
2022-09-28 20:00:17 - train: epoch 0112, iter [00030, 01251], lr: 0.001088, loss: 0.4120
2022-09-28 20:00:34 - train: epoch 0112, iter [00040, 01251], lr: 0.001088, loss: 0.3959
2022-09-28 20:00:52 - train: epoch 0112, iter [00050, 01251], lr: 0.001088, loss: 0.3936
2022-09-28 20:01:10 - train: epoch 0112, iter [00060, 01251], lr: 0.001088, loss: 0.4213
2022-09-28 20:01:28 - train: epoch 0112, iter [00070, 01251], lr: 0.001088, loss: 0.4201
2022-09-28 20:01:46 - train: epoch 0112, iter [00080, 01251], lr: 0.001088, loss: 0.4131
2022-09-28 20:02:03 - train: epoch 0112, iter [00090, 01251], lr: 0.001088, loss: 0.4230
2022-09-28 20:02:21 - train: epoch 0112, iter [00100, 01251], lr: 0.001088, loss: 0.4238
2022-09-28 20:02:39 - train: epoch 0112, iter [00110, 01251], lr: 0.001088, loss: 0.4293
2022-09-28 20:02:57 - train: epoch 0112, iter [00120, 01251], lr: 0.001088, loss: 0.4131
2022-09-28 20:03:15 - train: epoch 0112, iter [00130, 01251], lr: 0.001088, loss: 0.4110
2022-09-28 20:03:33 - train: epoch 0112, iter [00140, 01251], lr: 0.001088, loss: 0.4030
2022-09-28 20:03:51 - train: epoch 0112, iter [00150, 01251], lr: 0.001088, loss: 0.3977
2022-09-28 20:04:09 - train: epoch 0112, iter [00160, 01251], lr: 0.001088, loss: 0.4133
2022-09-28 20:04:26 - train: epoch 0112, iter [00170, 01251], lr: 0.001088, loss: 0.4063
2022-09-28 20:04:44 - train: epoch 0112, iter [00180, 01251], lr: 0.001088, loss: 0.4406
2022-09-28 20:05:02 - train: epoch 0112, iter [00190, 01251], lr: 0.001088, loss: 0.4001
2022-09-28 20:05:20 - train: epoch 0112, iter [00200, 01251], lr: 0.001088, loss: 0.4292
2022-09-28 20:05:38 - train: epoch 0112, iter [00210, 01251], lr: 0.001088, loss: 0.4197
2022-09-28 20:05:56 - train: epoch 0112, iter [00220, 01251], lr: 0.001088, loss: 0.4109
2022-09-28 20:06:13 - train: epoch 0112, iter [00230, 01251], lr: 0.001088, loss: 0.4183
2022-09-28 20:06:31 - train: epoch 0112, iter [00240, 01251], lr: 0.001088, loss: 0.4019
2022-09-28 20:06:49 - train: epoch 0112, iter [00250, 01251], lr: 0.001088, loss: 0.4226
2022-09-28 20:07:07 - train: epoch 0112, iter [00260, 01251], lr: 0.001088, loss: 0.4138
2022-09-28 20:07:25 - train: epoch 0112, iter [00270, 01251], lr: 0.001088, loss: 0.3986
2022-09-28 20:07:42 - train: epoch 0112, iter [00280, 01251], lr: 0.001088, loss: 0.4186
2022-09-28 20:08:00 - train: epoch 0112, iter [00290, 01251], lr: 0.001088, loss: 0.4122
2022-09-28 20:08:18 - train: epoch 0112, iter [00300, 01251], lr: 0.001088, loss: 0.4229
2022-09-28 20:08:36 - train: epoch 0112, iter [00310, 01251], lr: 0.001088, loss: 0.4113
2022-09-28 20:08:54 - train: epoch 0112, iter [00320, 01251], lr: 0.001088, loss: 0.3900
2022-09-28 20:09:11 - train: epoch 0112, iter [00330, 01251], lr: 0.001088, loss: 0.4285
2022-09-28 20:09:29 - train: epoch 0112, iter [00340, 01251], lr: 0.001088, loss: 0.4298
2022-09-28 20:09:47 - train: epoch 0112, iter [00350, 01251], lr: 0.001088, loss: 0.4229
2022-09-28 20:10:05 - train: epoch 0112, iter [00360, 01251], lr: 0.001088, loss: 0.4124
2022-09-28 20:10:22 - train: epoch 0112, iter [00370, 01251], lr: 0.001088, loss: 0.4199
2022-09-28 20:10:40 - train: epoch 0112, iter [00380, 01251], lr: 0.001088, loss: 0.4171
2022-09-28 20:10:58 - train: epoch 0112, iter [00390, 01251], lr: 0.001088, loss: 0.4285
2022-09-28 20:11:16 - train: epoch 0112, iter [00400, 01251], lr: 0.001087, loss: 0.4145
2022-09-28 20:11:33 - train: epoch 0112, iter [00410, 01251], lr: 0.001087, loss: 0.4048
2022-09-28 20:11:51 - train: epoch 0112, iter [00420, 01251], lr: 0.001087, loss: 0.4210
2022-09-28 20:12:09 - train: epoch 0112, iter [00430, 01251], lr: 0.001087, loss: 0.4164
2022-09-28 20:12:27 - train: epoch 0112, iter [00440, 01251], lr: 0.001087, loss: 0.4238
2022-09-28 20:12:44 - train: epoch 0112, iter [00450, 01251], lr: 0.001087, loss: 0.4244
2022-09-28 20:13:02 - train: epoch 0112, iter [00460, 01251], lr: 0.001087, loss: 0.4146
2022-09-28 20:13:20 - train: epoch 0112, iter [00470, 01251], lr: 0.001087, loss: 0.4185
2022-09-28 20:13:38 - train: epoch 0112, iter [00480, 01251], lr: 0.001087, loss: 0.4176
2022-09-28 20:13:56 - train: epoch 0112, iter [00490, 01251], lr: 0.001087, loss: 0.3824
2022-09-28 20:14:14 - train: epoch 0112, iter [00500, 01251], lr: 0.001087, loss: 0.4082
2022-09-28 20:14:31 - train: epoch 0112, iter [00510, 01251], lr: 0.001087, loss: 0.3994
2022-09-28 20:14:49 - train: epoch 0112, iter [00520, 01251], lr: 0.001087, loss: 0.4253
2022-09-28 20:15:07 - train: epoch 0112, iter [00530, 01251], lr: 0.001087, loss: 0.4159
2022-09-28 20:15:25 - train: epoch 0112, iter [00540, 01251], lr: 0.001087, loss: 0.3954
2022-09-28 20:15:43 - train: epoch 0112, iter [00550, 01251], lr: 0.001087, loss: 0.4280
2022-09-28 20:16:01 - train: epoch 0112, iter [00560, 01251], lr: 0.001087, loss: 0.4017
2022-09-28 20:16:18 - train: epoch 0112, iter [00570, 01251], lr: 0.001087, loss: 0.4067
2022-09-28 20:16:36 - train: epoch 0112, iter [00580, 01251], lr: 0.001087, loss: 0.4242
2022-09-28 20:16:54 - train: epoch 0112, iter [00590, 01251], lr: 0.001087, loss: 0.4135
2022-09-28 20:17:12 - train: epoch 0112, iter [00600, 01251], lr: 0.001087, loss: 0.3981
2022-09-28 20:17:29 - train: epoch 0112, iter [00610, 01251], lr: 0.001087, loss: 0.4195
2022-09-28 20:17:47 - train: epoch 0112, iter [00620, 01251], lr: 0.001087, loss: 0.4120
2022-09-28 20:18:05 - train: epoch 0112, iter [00630, 01251], lr: 0.001087, loss: 0.4236
2022-09-28 20:18:23 - train: epoch 0112, iter [00640, 01251], lr: 0.001087, loss: 0.4133
2022-09-28 20:18:41 - train: epoch 0112, iter [00650, 01251], lr: 0.001087, loss: 0.4151
2022-09-28 20:18:59 - train: epoch 0112, iter [00660, 01251], lr: 0.001087, loss: 0.4235
2022-09-28 20:19:17 - train: epoch 0112, iter [00670, 01251], lr: 0.001087, loss: 0.4227
2022-09-28 20:19:35 - train: epoch 0112, iter [00680, 01251], lr: 0.001087, loss: 0.4068
2022-09-28 20:19:53 - train: epoch 0112, iter [00690, 01251], lr: 0.001087, loss: 0.3976
2022-09-28 20:20:11 - train: epoch 0112, iter [00700, 01251], lr: 0.001087, loss: 0.3992
2022-09-28 20:20:29 - train: epoch 0112, iter [00710, 01251], lr: 0.001087, loss: 0.3862
2022-09-28 20:20:46 - train: epoch 0112, iter [00720, 01251], lr: 0.001087, loss: 0.4079
2022-09-28 20:21:04 - train: epoch 0112, iter [00730, 01251], lr: 0.001087, loss: 0.4162
2022-09-28 20:21:22 - train: epoch 0112, iter [00740, 01251], lr: 0.001087, loss: 0.4170
2022-09-28 20:21:40 - train: epoch 0112, iter [00750, 01251], lr: 0.001087, loss: 0.4319
2022-09-28 20:21:58 - train: epoch 0112, iter [00760, 01251], lr: 0.001087, loss: 0.4098
2022-09-28 20:22:16 - train: epoch 0112, iter [00770, 01251], lr: 0.001087, loss: 0.4089
2022-09-28 20:22:33 - train: epoch 0112, iter [00780, 01251], lr: 0.001087, loss: 0.4189
2022-09-28 20:22:51 - train: epoch 0112, iter [00790, 01251], lr: 0.001087, loss: 0.4008
2022-09-28 20:23:09 - train: epoch 0112, iter [00800, 01251], lr: 0.001087, loss: 0.4211
2022-09-28 20:23:27 - train: epoch 0112, iter [00810, 01251], lr: 0.001086, loss: 0.4325
2022-09-28 20:23:44 - train: epoch 0112, iter [00820, 01251], lr: 0.001086, loss: 0.3957
2022-09-28 20:24:02 - train: epoch 0112, iter [00830, 01251], lr: 0.001086, loss: 0.4223
2022-09-28 20:24:20 - train: epoch 0112, iter [00840, 01251], lr: 0.001086, loss: 0.3875
2022-09-28 20:24:38 - train: epoch 0112, iter [00850, 01251], lr: 0.001086, loss: 0.4087
2022-09-28 20:24:56 - train: epoch 0112, iter [00860, 01251], lr: 0.001086, loss: 0.4032
2022-09-28 20:25:14 - train: epoch 0112, iter [00870, 01251], lr: 0.001086, loss: 0.4341
2022-09-28 20:25:32 - train: epoch 0112, iter [00880, 01251], lr: 0.001086, loss: 0.4227
2022-09-28 20:25:50 - train: epoch 0112, iter [00890, 01251], lr: 0.001086, loss: 0.4132
2022-09-28 20:26:07 - train: epoch 0112, iter [00900, 01251], lr: 0.001086, loss: 0.3939
2022-09-28 20:26:25 - train: epoch 0112, iter [00910, 01251], lr: 0.001086, loss: 0.4253
2022-09-28 20:26:43 - train: epoch 0112, iter [00920, 01251], lr: 0.001086, loss: 0.4233
2022-09-28 20:27:01 - train: epoch 0112, iter [00930, 01251], lr: 0.001086, loss: 0.4195
2022-09-28 20:27:19 - train: epoch 0112, iter [00940, 01251], lr: 0.001086, loss: 0.4106
2022-09-28 20:27:37 - train: epoch 0112, iter [00950, 01251], lr: 0.001086, loss: 0.4155
2022-09-28 20:27:55 - train: epoch 0112, iter [00960, 01251], lr: 0.001086, loss: 0.4039
2022-09-28 20:28:12 - train: epoch 0112, iter [00970, 01251], lr: 0.001086, loss: 0.4358
2022-09-28 20:28:30 - train: epoch 0112, iter [00980, 01251], lr: 0.001086, loss: 0.4177
2022-09-28 20:28:48 - train: epoch 0112, iter [00990, 01251], lr: 0.001086, loss: 0.4247
2022-09-28 20:29:06 - train: epoch 0112, iter [01000, 01251], lr: 0.001086, loss: 0.4184
2022-09-28 20:29:24 - train: epoch 0112, iter [01010, 01251], lr: 0.001086, loss: 0.3994
2022-09-28 20:29:41 - train: epoch 0112, iter [01020, 01251], lr: 0.001086, loss: 0.4117
2022-09-28 20:29:59 - train: epoch 0112, iter [01030, 01251], lr: 0.001086, loss: 0.4115
2022-09-28 20:30:17 - train: epoch 0112, iter [01040, 01251], lr: 0.001086, loss: 0.3804
2022-09-28 20:30:35 - train: epoch 0112, iter [01050, 01251], lr: 0.001086, loss: 0.4109
2022-09-28 20:30:53 - train: epoch 0112, iter [01060, 01251], lr: 0.001086, loss: 0.4124
2022-09-28 20:31:11 - train: epoch 0112, iter [01070, 01251], lr: 0.001086, loss: 0.4125
2022-09-28 20:31:28 - train: epoch 0112, iter [01080, 01251], lr: 0.001086, loss: 0.3992
2022-09-28 20:31:46 - train: epoch 0112, iter [01090, 01251], lr: 0.001086, loss: 0.4057
2022-09-28 20:32:04 - train: epoch 0112, iter [01100, 01251], lr: 0.001086, loss: 0.4297
2022-09-28 20:32:22 - train: epoch 0112, iter [01110, 01251], lr: 0.001086, loss: 0.4034
2022-09-28 20:32:40 - train: epoch 0112, iter [01120, 01251], lr: 0.001086, loss: 0.4159
2022-09-28 20:32:58 - train: epoch 0112, iter [01130, 01251], lr: 0.001086, loss: 0.4036
2022-09-28 20:33:15 - train: epoch 0112, iter [01140, 01251], lr: 0.001086, loss: 0.3947
2022-09-28 20:33:33 - train: epoch 0112, iter [01150, 01251], lr: 0.001086, loss: 0.3925
2022-09-28 20:33:51 - train: epoch 0112, iter [01160, 01251], lr: 0.001086, loss: 0.4166
2022-09-28 20:34:09 - train: epoch 0112, iter [01170, 01251], lr: 0.001086, loss: 0.4117
2022-09-28 20:34:27 - train: epoch 0112, iter [01180, 01251], lr: 0.001086, loss: 0.4034
2022-09-28 20:34:45 - train: epoch 0112, iter [01190, 01251], lr: 0.001086, loss: 0.3953
2022-09-28 20:35:03 - train: epoch 0112, iter [01200, 01251], lr: 0.001086, loss: 0.4160
2022-09-28 20:35:20 - train: epoch 0112, iter [01210, 01251], lr: 0.001086, loss: 0.4091
2022-09-28 20:35:38 - train: epoch 0112, iter [01220, 01251], lr: 0.001085, loss: 0.3880
2022-09-28 20:35:56 - train: epoch 0112, iter [01230, 01251], lr: 0.001085, loss: 0.3974
2022-09-28 20:36:14 - train: epoch 0112, iter [01240, 01251], lr: 0.001085, loss: 0.4179
2022-09-28 20:36:31 - train: epoch 0112, iter [01250, 01251], lr: 0.001085, loss: 0.4173
2022-09-28 20:36:35 - train: epoch 112, train_loss: 0.4127
2022-09-28 20:36:37 - until epoch: 112, best_loss: 0.4126
2022-09-28 20:36:37 - epoch 113 lr: 0.001085
2022-09-28 20:37:09 - train: epoch 0113, iter [00010, 01251], lr: 0.001085, loss: 0.4204
2022-09-28 20:37:27 - train: epoch 0113, iter [00020, 01251], lr: 0.001085, loss: 0.4267
2022-09-28 20:37:45 - train: epoch 0113, iter [00030, 01251], lr: 0.001085, loss: 0.3996
2022-09-28 20:38:03 - train: epoch 0113, iter [00040, 01251], lr: 0.001085, loss: 0.4189
2022-09-28 20:38:20 - train: epoch 0113, iter [00050, 01251], lr: 0.001085, loss: 0.4175
2022-09-28 20:38:38 - train: epoch 0113, iter [00060, 01251], lr: 0.001085, loss: 0.3872
2022-09-28 20:38:56 - train: epoch 0113, iter [00070, 01251], lr: 0.001085, loss: 0.4146
2022-09-28 20:39:14 - train: epoch 0113, iter [00080, 01251], lr: 0.001085, loss: 0.4040
2022-09-28 20:39:32 - train: epoch 0113, iter [00090, 01251], lr: 0.001085, loss: 0.3948
2022-09-28 20:39:50 - train: epoch 0113, iter [00100, 01251], lr: 0.001085, loss: 0.4213
2022-09-28 20:40:07 - train: epoch 0113, iter [00110, 01251], lr: 0.001085, loss: 0.4230
2022-09-28 20:40:25 - train: epoch 0113, iter [00120, 01251], lr: 0.001085, loss: 0.3985
2022-09-28 20:40:43 - train: epoch 0113, iter [00130, 01251], lr: 0.001085, loss: 0.4236
2022-09-28 20:41:01 - train: epoch 0113, iter [00140, 01251], lr: 0.001085, loss: 0.4057
2022-09-28 20:41:18 - train: epoch 0113, iter [00150, 01251], lr: 0.001085, loss: 0.4052
2022-09-28 20:41:36 - train: epoch 0113, iter [00160, 01251], lr: 0.001085, loss: 0.4291
2022-09-28 20:41:54 - train: epoch 0113, iter [00170, 01251], lr: 0.001085, loss: 0.4194
2022-09-28 20:42:11 - train: epoch 0113, iter [00180, 01251], lr: 0.001085, loss: 0.4156
2022-09-28 20:42:29 - train: epoch 0113, iter [00190, 01251], lr: 0.001085, loss: 0.4119
2022-09-28 20:42:47 - train: epoch 0113, iter [00200, 01251], lr: 0.001085, loss: 0.4313
2022-09-28 20:43:05 - train: epoch 0113, iter [00210, 01251], lr: 0.001085, loss: 0.4062
2022-09-28 20:43:22 - train: epoch 0113, iter [00220, 01251], lr: 0.001085, loss: 0.4205
2022-09-28 20:43:40 - train: epoch 0113, iter [00230, 01251], lr: 0.001085, loss: 0.4217
2022-09-28 20:43:58 - train: epoch 0113, iter [00240, 01251], lr: 0.001085, loss: 0.4227
2022-09-28 20:44:16 - train: epoch 0113, iter [00250, 01251], lr: 0.001085, loss: 0.4290
2022-09-28 20:44:33 - train: epoch 0113, iter [00260, 01251], lr: 0.001085, loss: 0.3834
2022-09-28 20:44:51 - train: epoch 0113, iter [00270, 01251], lr: 0.001085, loss: 0.3975
2022-09-28 20:45:09 - train: epoch 0113, iter [00280, 01251], lr: 0.001085, loss: 0.4102
2022-09-28 20:45:27 - train: epoch 0113, iter [00290, 01251], lr: 0.001085, loss: 0.4010
2022-09-28 20:45:44 - train: epoch 0113, iter [00300, 01251], lr: 0.001085, loss: 0.4284
2022-09-28 20:46:02 - train: epoch 0113, iter [00310, 01251], lr: 0.001085, loss: 0.4198
2022-09-28 20:46:20 - train: epoch 0113, iter [00320, 01251], lr: 0.001085, loss: 0.4158
2022-09-28 20:46:38 - train: epoch 0113, iter [00330, 01251], lr: 0.001085, loss: 0.4055
2022-09-28 20:46:55 - train: epoch 0113, iter [00340, 01251], lr: 0.001085, loss: 0.4369
2022-09-28 20:47:13 - train: epoch 0113, iter [00350, 01251], lr: 0.001085, loss: 0.4085
2022-09-28 20:47:31 - train: epoch 0113, iter [00360, 01251], lr: 0.001085, loss: 0.4205
2022-09-28 20:47:48 - train: epoch 0113, iter [00370, 01251], lr: 0.001084, loss: 0.4098
2022-09-28 20:48:06 - train: epoch 0113, iter [00380, 01251], lr: 0.001084, loss: 0.3941
2022-09-28 20:48:24 - train: epoch 0113, iter [00390, 01251], lr: 0.001084, loss: 0.4169
2022-09-28 20:48:42 - train: epoch 0113, iter [00400, 01251], lr: 0.001084, loss: 0.4161
2022-09-28 20:48:59 - train: epoch 0113, iter [00410, 01251], lr: 0.001084, loss: 0.4031
2022-09-28 20:49:17 - train: epoch 0113, iter [00420, 01251], lr: 0.001084, loss: 0.4173
2022-09-28 20:49:35 - train: epoch 0113, iter [00430, 01251], lr: 0.001084, loss: 0.4380
2022-09-28 20:49:53 - train: epoch 0113, iter [00440, 01251], lr: 0.001084, loss: 0.4049
2022-09-28 20:50:11 - train: epoch 0113, iter [00450, 01251], lr: 0.001084, loss: 0.3968
2022-09-28 20:50:28 - train: epoch 0113, iter [00460, 01251], lr: 0.001084, loss: 0.4037
2022-09-28 20:50:46 - train: epoch 0113, iter [00470, 01251], lr: 0.001084, loss: 0.4288
2022-09-28 20:51:04 - train: epoch 0113, iter [00480, 01251], lr: 0.001084, loss: 0.3961
2022-09-28 20:51:21 - train: epoch 0113, iter [00490, 01251], lr: 0.001084, loss: 0.4081
2022-09-28 20:51:39 - train: epoch 0113, iter [00500, 01251], lr: 0.001084, loss: 0.4080
2022-09-28 20:51:57 - train: epoch 0113, iter [00510, 01251], lr: 0.001084, loss: 0.4205
2022-09-28 20:52:15 - train: epoch 0113, iter [00520, 01251], lr: 0.001084, loss: 0.4124
2022-09-28 20:52:32 - train: epoch 0113, iter [00530, 01251], lr: 0.001084, loss: 0.3976
2022-09-28 20:52:50 - train: epoch 0113, iter [00540, 01251], lr: 0.001084, loss: 0.3924
2022-09-28 20:53:08 - train: epoch 0113, iter [00550, 01251], lr: 0.001084, loss: 0.4271
2022-09-28 20:53:26 - train: epoch 0113, iter [00560, 01251], lr: 0.001084, loss: 0.4078
2022-09-28 20:53:43 - train: epoch 0113, iter [00570, 01251], lr: 0.001084, loss: 0.4167
2022-09-28 20:54:01 - train: epoch 0113, iter [00580, 01251], lr: 0.001084, loss: 0.3960
2022-09-28 20:54:19 - train: epoch 0113, iter [00590, 01251], lr: 0.001084, loss: 0.4155
2022-09-28 20:54:37 - train: epoch 0113, iter [00600, 01251], lr: 0.001084, loss: 0.4205
2022-09-28 20:54:55 - train: epoch 0113, iter [00610, 01251], lr: 0.001084, loss: 0.4096
2022-09-28 20:55:12 - train: epoch 0113, iter [00620, 01251], lr: 0.001084, loss: 0.3980
2022-09-28 20:55:30 - train: epoch 0113, iter [00630, 01251], lr: 0.001084, loss: 0.4117
2022-09-28 20:55:48 - train: epoch 0113, iter [00640, 01251], lr: 0.001084, loss: 0.4153
2022-09-28 20:56:05 - train: epoch 0113, iter [00650, 01251], lr: 0.001084, loss: 0.4049
2022-09-28 20:56:23 - train: epoch 0113, iter [00660, 01251], lr: 0.001084, loss: 0.4167
2022-09-28 20:56:41 - train: epoch 0113, iter [00670, 01251], lr: 0.001084, loss: 0.4177
2022-09-28 20:56:59 - train: epoch 0113, iter [00680, 01251], lr: 0.001084, loss: 0.4299
2022-09-28 20:57:17 - train: epoch 0113, iter [00690, 01251], lr: 0.001084, loss: 0.4098
2022-09-28 20:57:34 - train: epoch 0113, iter [00700, 01251], lr: 0.001084, loss: 0.4010
2022-09-28 20:57:52 - train: epoch 0113, iter [00710, 01251], lr: 0.001084, loss: 0.4146
2022-09-28 20:58:10 - train: epoch 0113, iter [00720, 01251], lr: 0.001084, loss: 0.4071
2022-09-28 20:58:28 - train: epoch 0113, iter [00730, 01251], lr: 0.001084, loss: 0.4175
2022-09-28 20:58:45 - train: epoch 0113, iter [00740, 01251], lr: 0.001084, loss: 0.4188
2022-09-28 20:59:03 - train: epoch 0113, iter [00750, 01251], lr: 0.001084, loss: 0.4287
2022-09-28 20:59:21 - train: epoch 0113, iter [00760, 01251], lr: 0.001084, loss: 0.4081
2022-09-28 20:59:39 - train: epoch 0113, iter [00770, 01251], lr: 0.001084, loss: 0.4143
2022-09-28 20:59:57 - train: epoch 0113, iter [00780, 01251], lr: 0.001083, loss: 0.4165
2022-09-28 21:00:14 - train: epoch 0113, iter [00790, 01251], lr: 0.001083, loss: 0.4038
2022-09-28 21:00:32 - train: epoch 0113, iter [00800, 01251], lr: 0.001083, loss: 0.4252
2022-09-28 21:00:50 - train: epoch 0113, iter [00810, 01251], lr: 0.001083, loss: 0.4201
2022-09-28 21:01:08 - train: epoch 0113, iter [00820, 01251], lr: 0.001083, loss: 0.4074
2022-09-28 21:01:25 - train: epoch 0113, iter [00830, 01251], lr: 0.001083, loss: 0.4305
2022-09-28 21:01:43 - train: epoch 0113, iter [00840, 01251], lr: 0.001083, loss: 0.4109
2022-09-28 21:02:01 - train: epoch 0113, iter [00850, 01251], lr: 0.001083, loss: 0.3918
2022-09-28 21:02:18 - train: epoch 0113, iter [00860, 01251], lr: 0.001083, loss: 0.4149
2022-09-28 21:02:36 - train: epoch 0113, iter [00870, 01251], lr: 0.001083, loss: 0.4228
2022-09-28 21:02:54 - train: epoch 0113, iter [00880, 01251], lr: 0.001083, loss: 0.4044
2022-09-28 21:03:12 - train: epoch 0113, iter [00890, 01251], lr: 0.001083, loss: 0.4117
2022-09-28 21:03:30 - train: epoch 0113, iter [00900, 01251], lr: 0.001083, loss: 0.4015
2022-09-28 21:03:47 - train: epoch 0113, iter [00910, 01251], lr: 0.001083, loss: 0.4163
2022-09-28 21:04:05 - train: epoch 0113, iter [00920, 01251], lr: 0.001083, loss: 0.4359
2022-09-28 21:04:23 - train: epoch 0113, iter [00930, 01251], lr: 0.001083, loss: 0.4081
2022-09-28 21:04:41 - train: epoch 0113, iter [00940, 01251], lr: 0.001083, loss: 0.4099
2022-09-28 21:04:58 - train: epoch 0113, iter [00950, 01251], lr: 0.001083, loss: 0.4097
2022-09-28 21:05:16 - train: epoch 0113, iter [00960, 01251], lr: 0.001083, loss: 0.4030
2022-09-28 21:05:34 - train: epoch 0113, iter [00970, 01251], lr: 0.001083, loss: 0.3983
2022-09-28 21:05:52 - train: epoch 0113, iter [00980, 01251], lr: 0.001083, loss: 0.4013
2022-09-28 21:06:09 - train: epoch 0113, iter [00990, 01251], lr: 0.001083, loss: 0.4023
2022-09-28 21:06:27 - train: epoch 0113, iter [01000, 01251], lr: 0.001083, loss: 0.4173
2022-09-28 21:06:45 - train: epoch 0113, iter [01010, 01251], lr: 0.001083, loss: 0.4213
2022-09-28 21:07:02 - train: epoch 0113, iter [01020, 01251], lr: 0.001083, loss: 0.4028
2022-09-28 21:07:20 - train: epoch 0113, iter [01030, 01251], lr: 0.001083, loss: 0.4343
2022-09-28 21:07:38 - train: epoch 0113, iter [01040, 01251], lr: 0.001083, loss: 0.4140
2022-09-28 21:07:55 - train: epoch 0113, iter [01050, 01251], lr: 0.001083, loss: 0.4142
2022-09-28 21:08:13 - train: epoch 0113, iter [01060, 01251], lr: 0.001083, loss: 0.4009
2022-09-28 21:08:31 - train: epoch 0113, iter [01070, 01251], lr: 0.001083, loss: 0.4047
2022-09-28 21:08:49 - train: epoch 0113, iter [01080, 01251], lr: 0.001083, loss: 0.4095
2022-09-28 21:09:06 - train: epoch 0113, iter [01090, 01251], lr: 0.001083, loss: 0.4037
2022-09-28 21:09:24 - train: epoch 0113, iter [01100, 01251], lr: 0.001083, loss: 0.3903
2022-09-28 21:09:42 - train: epoch 0113, iter [01110, 01251], lr: 0.001083, loss: 0.4059
2022-09-28 21:10:00 - train: epoch 0113, iter [01120, 01251], lr: 0.001083, loss: 0.4102
2022-09-28 21:10:17 - train: epoch 0113, iter [01130, 01251], lr: 0.001083, loss: 0.3997
2022-09-28 21:10:35 - train: epoch 0113, iter [01140, 01251], lr: 0.001083, loss: 0.4217
2022-09-28 21:10:53 - train: epoch 0113, iter [01150, 01251], lr: 0.001083, loss: 0.4310
2022-09-28 21:11:10 - train: epoch 0113, iter [01160, 01251], lr: 0.001083, loss: 0.4155
2022-09-28 21:11:28 - train: epoch 0113, iter [01170, 01251], lr: 0.001083, loss: 0.4112
2022-09-28 21:11:46 - train: epoch 0113, iter [01180, 01251], lr: 0.001082, loss: 0.4010
2022-09-28 21:12:03 - train: epoch 0113, iter [01190, 01251], lr: 0.001082, loss: 0.4112
2022-09-28 21:12:21 - train: epoch 0113, iter [01200, 01251], lr: 0.001082, loss: 0.4137
2022-09-28 21:12:39 - train: epoch 0113, iter [01210, 01251], lr: 0.001082, loss: 0.4412
2022-09-28 21:12:57 - train: epoch 0113, iter [01220, 01251], lr: 0.001082, loss: 0.4136
2022-09-28 21:13:14 - train: epoch 0113, iter [01230, 01251], lr: 0.001082, loss: 0.4056
2022-09-28 21:13:32 - train: epoch 0113, iter [01240, 01251], lr: 0.001082, loss: 0.4325
2022-09-28 21:13:49 - train: epoch 0113, iter [01250, 01251], lr: 0.001082, loss: 0.4092
2022-09-28 21:13:52 - train: epoch 113, train_loss: 0.4126
2022-09-28 21:13:55 - until epoch: 113, best_loss: 0.4126
2022-09-28 21:13:55 - epoch 114 lr: 0.001082
2022-09-28 21:14:28 - train: epoch 0114, iter [00010, 01251], lr: 0.001082, loss: 0.4114
2022-09-28 21:14:45 - train: epoch 0114, iter [00020, 01251], lr: 0.001082, loss: 0.4124
2022-09-28 21:15:03 - train: epoch 0114, iter [00030, 01251], lr: 0.001082, loss: 0.4194
2022-09-28 21:15:21 - train: epoch 0114, iter [00040, 01251], lr: 0.001082, loss: 0.4157
2022-09-28 21:15:39 - train: epoch 0114, iter [00050, 01251], lr: 0.001082, loss: 0.4028
2022-09-28 21:15:57 - train: epoch 0114, iter [00060, 01251], lr: 0.001082, loss: 0.4120
2022-09-28 21:16:14 - train: epoch 0114, iter [00070, 01251], lr: 0.001082, loss: 0.4253
2022-09-28 21:16:32 - train: epoch 0114, iter [00080, 01251], lr: 0.001082, loss: 0.4202
2022-09-28 21:16:50 - train: epoch 0114, iter [00090, 01251], lr: 0.001082, loss: 0.4150
2022-09-28 21:17:08 - train: epoch 0114, iter [00100, 01251], lr: 0.001082, loss: 0.4050
2022-09-28 21:17:26 - train: epoch 0114, iter [00110, 01251], lr: 0.001082, loss: 0.4281
2022-09-28 21:17:43 - train: epoch 0114, iter [00120, 01251], lr: 0.001082, loss: 0.4066
2022-09-28 21:18:01 - train: epoch 0114, iter [00130, 01251], lr: 0.001082, loss: 0.4081
2022-09-28 21:18:19 - train: epoch 0114, iter [00140, 01251], lr: 0.001082, loss: 0.4163
2022-09-28 21:18:37 - train: epoch 0114, iter [00150, 01251], lr: 0.001082, loss: 0.4088
2022-09-28 21:18:55 - train: epoch 0114, iter [00160, 01251], lr: 0.001082, loss: 0.4055
2022-09-28 21:19:12 - train: epoch 0114, iter [00170, 01251], lr: 0.001082, loss: 0.4029
2022-09-28 21:19:30 - train: epoch 0114, iter [00180, 01251], lr: 0.001082, loss: 0.4227
2022-09-28 21:19:48 - train: epoch 0114, iter [00190, 01251], lr: 0.001082, loss: 0.4012
2022-09-28 21:20:06 - train: epoch 0114, iter [00200, 01251], lr: 0.001082, loss: 0.4255
2022-09-28 21:20:23 - train: epoch 0114, iter [00210, 01251], lr: 0.001082, loss: 0.3964
2022-09-28 21:20:41 - train: epoch 0114, iter [00220, 01251], lr: 0.001082, loss: 0.4306
2022-09-28 21:20:59 - train: epoch 0114, iter [00230, 01251], lr: 0.001082, loss: 0.4013
2022-09-28 21:21:17 - train: epoch 0114, iter [00240, 01251], lr: 0.001082, loss: 0.4225
2022-09-28 21:21:35 - train: epoch 0114, iter [00250, 01251], lr: 0.001082, loss: 0.4025
2022-09-28 21:21:53 - train: epoch 0114, iter [00260, 01251], lr: 0.001082, loss: 0.4057
2022-09-28 21:22:10 - train: epoch 0114, iter [00270, 01251], lr: 0.001082, loss: 0.4266
2022-09-28 21:22:28 - train: epoch 0114, iter [00280, 01251], lr: 0.001082, loss: 0.4207
2022-09-28 21:22:46 - train: epoch 0114, iter [00290, 01251], lr: 0.001082, loss: 0.4090
2022-09-28 21:23:04 - train: epoch 0114, iter [00300, 01251], lr: 0.001082, loss: 0.4018
2022-09-28 21:23:22 - train: epoch 0114, iter [00310, 01251], lr: 0.001082, loss: 0.4078
2022-09-28 21:23:40 - train: epoch 0114, iter [00320, 01251], lr: 0.001082, loss: 0.4364
2022-09-28 21:23:57 - train: epoch 0114, iter [00330, 01251], lr: 0.001081, loss: 0.4137
2022-09-28 21:24:15 - train: epoch 0114, iter [00340, 01251], lr: 0.001081, loss: 0.4181
2022-09-28 21:24:33 - train: epoch 0114, iter [00350, 01251], lr: 0.001081, loss: 0.4135
2022-09-28 21:24:51 - train: epoch 0114, iter [00360, 01251], lr: 0.001081, loss: 0.4196
2022-09-28 21:25:09 - train: epoch 0114, iter [00370, 01251], lr: 0.001081, loss: 0.4075
2022-09-28 21:25:27 - train: epoch 0114, iter [00380, 01251], lr: 0.001081, loss: 0.4165
2022-09-28 21:25:44 - train: epoch 0114, iter [00390, 01251], lr: 0.001081, loss: 0.4003
2022-09-28 21:26:02 - train: epoch 0114, iter [00400, 01251], lr: 0.001081, loss: 0.4216
2022-09-28 21:26:20 - train: epoch 0114, iter [00410, 01251], lr: 0.001081, loss: 0.4241
2022-09-28 21:26:37 - train: epoch 0114, iter [00420, 01251], lr: 0.001081, loss: 0.4204
2022-09-28 21:26:55 - train: epoch 0114, iter [00430, 01251], lr: 0.001081, loss: 0.4198
2022-09-28 21:27:13 - train: epoch 0114, iter [00440, 01251], lr: 0.001081, loss: 0.4278
2022-09-28 21:27:31 - train: epoch 0114, iter [00450, 01251], lr: 0.001081, loss: 0.4134
2022-09-28 21:27:49 - train: epoch 0114, iter [00460, 01251], lr: 0.001081, loss: 0.4322
2022-09-28 21:28:06 - train: epoch 0114, iter [00470, 01251], lr: 0.001081, loss: 0.4138
2022-09-28 21:28:24 - train: epoch 0114, iter [00480, 01251], lr: 0.001081, loss: 0.3877
2022-09-28 21:28:42 - train: epoch 0114, iter [00490, 01251], lr: 0.001081, loss: 0.4319
2022-09-28 21:28:59 - train: epoch 0114, iter [00500, 01251], lr: 0.001081, loss: 0.4118
2022-09-28 21:29:17 - train: epoch 0114, iter [00510, 01251], lr: 0.001081, loss: 0.4308
2022-09-28 21:29:35 - train: epoch 0114, iter [00520, 01251], lr: 0.001081, loss: 0.4156
2022-09-28 21:29:53 - train: epoch 0114, iter [00530, 01251], lr: 0.001081, loss: 0.4009
2022-09-28 21:30:10 - train: epoch 0114, iter [00540, 01251], lr: 0.001081, loss: 0.4221
2022-09-28 21:30:28 - train: epoch 0114, iter [00550, 01251], lr: 0.001081, loss: 0.4157
2022-09-28 21:30:46 - train: epoch 0114, iter [00560, 01251], lr: 0.001081, loss: 0.4179
2022-09-28 21:31:04 - train: epoch 0114, iter [00570, 01251], lr: 0.001081, loss: 0.4091
2022-09-28 21:31:21 - train: epoch 0114, iter [00580, 01251], lr: 0.001081, loss: 0.4126
2022-09-28 21:31:39 - train: epoch 0114, iter [00590, 01251], lr: 0.001081, loss: 0.4105
2022-09-28 21:31:57 - train: epoch 0114, iter [00600, 01251], lr: 0.001081, loss: 0.4131
2022-09-28 21:32:15 - train: epoch 0114, iter [00610, 01251], lr: 0.001081, loss: 0.4188
2022-09-28 21:32:33 - train: epoch 0114, iter [00620, 01251], lr: 0.001081, loss: 0.4127
2022-09-28 21:32:51 - train: epoch 0114, iter [00630, 01251], lr: 0.001081, loss: 0.4167
2022-09-28 21:33:08 - train: epoch 0114, iter [00640, 01251], lr: 0.001081, loss: 0.4154
2022-09-28 21:33:26 - train: epoch 0114, iter [00650, 01251], lr: 0.001081, loss: 0.4077
2022-09-28 21:33:44 - train: epoch 0114, iter [00660, 01251], lr: 0.001081, loss: 0.4159
2022-09-28 21:34:02 - train: epoch 0114, iter [00670, 01251], lr: 0.001081, loss: 0.4125
2022-09-28 21:34:20 - train: epoch 0114, iter [00680, 01251], lr: 0.001081, loss: 0.4101
2022-09-28 21:34:37 - train: epoch 0114, iter [00690, 01251], lr: 0.001081, loss: 0.4120
2022-09-28 21:34:55 - train: epoch 0114, iter [00700, 01251], lr: 0.001081, loss: 0.4136
2022-09-28 21:35:13 - train: epoch 0114, iter [00710, 01251], lr: 0.001081, loss: 0.4100
2022-09-28 21:35:31 - train: epoch 0114, iter [00720, 01251], lr: 0.001081, loss: 0.4004
2022-09-28 21:35:49 - train: epoch 0114, iter [00730, 01251], lr: 0.001080, loss: 0.4235
2022-09-28 21:36:06 - train: epoch 0114, iter [00740, 01251], lr: 0.001080, loss: 0.4208
2022-09-28 21:36:24 - train: epoch 0114, iter [00750, 01251], lr: 0.001080, loss: 0.4292
2022-09-28 21:36:42 - train: epoch 0114, iter [00760, 01251], lr: 0.001080, loss: 0.4068
2022-09-28 21:37:00 - train: epoch 0114, iter [00770, 01251], lr: 0.001080, loss: 0.3786
2022-09-28 21:37:17 - train: epoch 0114, iter [00780, 01251], lr: 0.001080, loss: 0.4065
2022-09-28 21:37:35 - train: epoch 0114, iter [00790, 01251], lr: 0.001080, loss: 0.4187
2022-09-28 21:37:53 - train: epoch 0114, iter [00800, 01251], lr: 0.001080, loss: 0.3933
2022-09-28 21:38:10 - train: epoch 0114, iter [00810, 01251], lr: 0.001080, loss: 0.3964
2022-09-28 21:38:28 - train: epoch 0114, iter [00820, 01251], lr: 0.001080, loss: 0.4051
2022-09-28 21:38:46 - train: epoch 0114, iter [00830, 01251], lr: 0.001080, loss: 0.4102
2022-09-28 21:39:04 - train: epoch 0114, iter [00840, 01251], lr: 0.001080, loss: 0.3825
2022-09-28 21:39:22 - train: epoch 0114, iter [00850, 01251], lr: 0.001080, loss: 0.3943
2022-09-28 21:39:39 - train: epoch 0114, iter [00860, 01251], lr: 0.001080, loss: 0.4173
2022-09-28 21:39:57 - train: epoch 0114, iter [00870, 01251], lr: 0.001080, loss: 0.4250
2022-09-28 21:40:15 - train: epoch 0114, iter [00880, 01251], lr: 0.001080, loss: 0.4110
2022-09-28 21:40:33 - train: epoch 0114, iter [00890, 01251], lr: 0.001080, loss: 0.3976
2022-09-28 21:40:51 - train: epoch 0114, iter [00900, 01251], lr: 0.001080, loss: 0.4105
2022-09-28 21:41:09 - train: epoch 0114, iter [00910, 01251], lr: 0.001080, loss: 0.4165
2022-09-28 21:41:26 - train: epoch 0114, iter [00920, 01251], lr: 0.001080, loss: 0.4209
2022-09-28 21:41:44 - train: epoch 0114, iter [00930, 01251], lr: 0.001080, loss: 0.4246
2022-09-28 21:42:02 - train: epoch 0114, iter [00940, 01251], lr: 0.001080, loss: 0.4086
2022-09-28 21:42:20 - train: epoch 0114, iter [00950, 01251], lr: 0.001080, loss: 0.4171
2022-09-28 21:42:37 - train: epoch 0114, iter [00960, 01251], lr: 0.001080, loss: 0.4004
2022-09-28 21:42:55 - train: epoch 0114, iter [00970, 01251], lr: 0.001080, loss: 0.3989
2022-09-28 21:43:13 - train: epoch 0114, iter [00980, 01251], lr: 0.001080, loss: 0.4030
2022-09-28 21:43:30 - train: epoch 0114, iter [00990, 01251], lr: 0.001080, loss: 0.4311
2022-09-28 21:43:48 - train: epoch 0114, iter [01000, 01251], lr: 0.001080, loss: 0.4087
2022-09-28 21:44:06 - train: epoch 0114, iter [01010, 01251], lr: 0.001080, loss: 0.4418
2022-09-28 21:44:24 - train: epoch 0114, iter [01020, 01251], lr: 0.001080, loss: 0.4107
2022-09-28 21:44:42 - train: epoch 0114, iter [01030, 01251], lr: 0.001080, loss: 0.4040
2022-09-28 21:44:59 - train: epoch 0114, iter [01040, 01251], lr: 0.001080, loss: 0.4033
2022-09-28 21:45:17 - train: epoch 0114, iter [01050, 01251], lr: 0.001080, loss: 0.4105
2022-09-28 21:45:35 - train: epoch 0114, iter [01060, 01251], lr: 0.001080, loss: 0.4349
2022-09-28 21:45:53 - train: epoch 0114, iter [01070, 01251], lr: 0.001080, loss: 0.4178
2022-09-28 21:46:11 - train: epoch 0114, iter [01080, 01251], lr: 0.001080, loss: 0.4040
2022-09-28 21:46:29 - train: epoch 0114, iter [01090, 01251], lr: 0.001080, loss: 0.4100
2022-09-28 21:46:46 - train: epoch 0114, iter [01100, 01251], lr: 0.001080, loss: 0.4132
2022-09-28 21:47:04 - train: epoch 0114, iter [01110, 01251], lr: 0.001080, loss: 0.4036
2022-09-28 21:47:22 - train: epoch 0114, iter [01120, 01251], lr: 0.001080, loss: 0.4028
2022-09-28 21:47:40 - train: epoch 0114, iter [01130, 01251], lr: 0.001079, loss: 0.4157
2022-09-28 21:47:58 - train: epoch 0114, iter [01140, 01251], lr: 0.001079, loss: 0.4116
2022-09-28 21:48:15 - train: epoch 0114, iter [01150, 01251], lr: 0.001079, loss: 0.4295
2022-09-28 21:48:33 - train: epoch 0114, iter [01160, 01251], lr: 0.001079, loss: 0.3918
2022-09-28 21:48:51 - train: epoch 0114, iter [01170, 01251], lr: 0.001079, loss: 0.4190
2022-09-28 21:49:09 - train: epoch 0114, iter [01180, 01251], lr: 0.001079, loss: 0.4024
2022-09-28 21:49:26 - train: epoch 0114, iter [01190, 01251], lr: 0.001079, loss: 0.4112
2022-09-28 21:49:44 - train: epoch 0114, iter [01200, 01251], lr: 0.001079, loss: 0.4205
2022-09-28 21:50:02 - train: epoch 0114, iter [01210, 01251], lr: 0.001079, loss: 0.4309
2022-09-28 21:50:20 - train: epoch 0114, iter [01220, 01251], lr: 0.001079, loss: 0.4324
2022-09-28 21:50:37 - train: epoch 0114, iter [01230, 01251], lr: 0.001079, loss: 0.4126
2022-09-28 21:50:55 - train: epoch 0114, iter [01240, 01251], lr: 0.001079, loss: 0.3916
2022-09-28 21:51:12 - train: epoch 0114, iter [01250, 01251], lr: 0.001079, loss: 0.4210
2022-09-28 21:51:16 - train: epoch 114, train_loss: 0.4126
2022-09-28 21:51:18 - until epoch: 114, best_loss: 0.4126
2022-09-28 22:49:21 - epoch 115 lr: 0.001079
2022-09-28 22:50:00 - train: epoch 0115, iter [00010, 01251], lr: 0.001079, loss: 0.3879
2022-09-28 22:50:17 - train: epoch 0115, iter [00020, 01251], lr: 0.001079, loss: 0.4084
2022-09-28 22:50:35 - train: epoch 0115, iter [00030, 01251], lr: 0.001079, loss: 0.4228
2022-09-28 22:50:53 - train: epoch 0115, iter [00040, 01251], lr: 0.001079, loss: 0.3929
2022-09-28 22:51:11 - train: epoch 0115, iter [00050, 01251], lr: 0.001079, loss: 0.4071
2022-09-28 22:51:29 - train: epoch 0115, iter [00060, 01251], lr: 0.001079, loss: 0.4196
2022-09-28 22:51:46 - train: epoch 0115, iter [00070, 01251], lr: 0.001079, loss: 0.4104
2022-09-28 22:52:04 - train: epoch 0115, iter [00080, 01251], lr: 0.001079, loss: 0.4128
2022-09-28 22:52:22 - train: epoch 0115, iter [00090, 01251], lr: 0.001079, loss: 0.4167
2022-09-28 22:52:40 - train: epoch 0115, iter [00100, 01251], lr: 0.001079, loss: 0.4136
2022-09-28 22:52:57 - train: epoch 0115, iter [00110, 01251], lr: 0.001079, loss: 0.4091
2022-09-28 22:53:15 - train: epoch 0115, iter [00120, 01251], lr: 0.001079, loss: 0.4242
2022-09-28 22:53:32 - train: epoch 0115, iter [00130, 01251], lr: 0.001079, loss: 0.4180
2022-09-28 22:53:50 - train: epoch 0115, iter [00140, 01251], lr: 0.001079, loss: 0.4214
2022-09-28 22:54:08 - train: epoch 0115, iter [00150, 01251], lr: 0.001079, loss: 0.4055
2022-09-28 22:54:26 - train: epoch 0115, iter [00160, 01251], lr: 0.001079, loss: 0.4282
2022-09-28 22:54:43 - train: epoch 0115, iter [00170, 01251], lr: 0.001079, loss: 0.3891
2022-09-28 22:55:01 - train: epoch 0115, iter [00180, 01251], lr: 0.001079, loss: 0.4276
2022-09-28 22:55:19 - train: epoch 0115, iter [00190, 01251], lr: 0.001079, loss: 0.4185
2022-09-28 22:55:37 - train: epoch 0115, iter [00200, 01251], lr: 0.001079, loss: 0.4281
2022-09-28 22:55:54 - train: epoch 0115, iter [00210, 01251], lr: 0.001079, loss: 0.4182
2022-09-28 22:56:12 - train: epoch 0115, iter [00220, 01251], lr: 0.001079, loss: 0.4282
2022-09-28 22:56:30 - train: epoch 0115, iter [00230, 01251], lr: 0.001079, loss: 0.4082
2022-09-28 22:56:47 - train: epoch 0115, iter [00240, 01251], lr: 0.001079, loss: 0.3863
2022-09-28 22:57:05 - train: epoch 0115, iter [00250, 01251], lr: 0.001079, loss: 0.4151
2022-09-28 22:57:23 - train: epoch 0115, iter [00260, 01251], lr: 0.001079, loss: 0.4167
2022-09-28 22:57:41 - train: epoch 0115, iter [00270, 01251], lr: 0.001079, loss: 0.4281
2022-09-28 22:57:58 - train: epoch 0115, iter [00280, 01251], lr: 0.001078, loss: 0.4089
2022-09-28 22:58:16 - train: epoch 0115, iter [00290, 01251], lr: 0.001078, loss: 0.4113
2022-09-28 22:58:34 - train: epoch 0115, iter [00300, 01251], lr: 0.001078, loss: 0.3792
2022-09-28 22:58:52 - train: epoch 0115, iter [00310, 01251], lr: 0.001078, loss: 0.4044
2022-09-28 22:59:09 - train: epoch 0115, iter [00320, 01251], lr: 0.001078, loss: 0.3949
2022-09-28 22:59:27 - train: epoch 0115, iter [00330, 01251], lr: 0.001078, loss: 0.4157
2022-09-28 22:59:45 - train: epoch 0115, iter [00340, 01251], lr: 0.001078, loss: 0.4215
2022-09-28 23:00:03 - train: epoch 0115, iter [00350, 01251], lr: 0.001078, loss: 0.4189
2022-09-28 23:00:20 - train: epoch 0115, iter [00360, 01251], lr: 0.001078, loss: 0.4082
2022-09-28 23:00:38 - train: epoch 0115, iter [00370, 01251], lr: 0.001078, loss: 0.4078
2022-09-28 23:00:56 - train: epoch 0115, iter [00380, 01251], lr: 0.001078, loss: 0.3826
2022-09-28 23:01:13 - train: epoch 0115, iter [00390, 01251], lr: 0.001078, loss: 0.4261
2022-09-28 23:01:31 - train: epoch 0115, iter [00400, 01251], lr: 0.001078, loss: 0.3983
2022-09-28 23:01:49 - train: epoch 0115, iter [00410, 01251], lr: 0.001078, loss: 0.4063
2022-09-28 23:02:07 - train: epoch 0115, iter [00420, 01251], lr: 0.001078, loss: 0.3979
2022-09-28 23:02:24 - train: epoch 0115, iter [00430, 01251], lr: 0.001078, loss: 0.4020
2022-09-28 23:02:42 - train: epoch 0115, iter [00440, 01251], lr: 0.001078, loss: 0.4217
2022-09-28 23:03:00 - train: epoch 0115, iter [00450, 01251], lr: 0.001078, loss: 0.4244
2022-09-28 23:03:18 - train: epoch 0115, iter [00460, 01251], lr: 0.001078, loss: 0.4289
2022-09-28 23:03:35 - train: epoch 0115, iter [00470, 01251], lr: 0.001078, loss: 0.4008
2022-09-28 23:03:53 - train: epoch 0115, iter [00480, 01251], lr: 0.001078, loss: 0.4083
2022-09-28 23:04:11 - train: epoch 0115, iter [00490, 01251], lr: 0.001078, loss: 0.4192
2022-09-28 23:04:29 - train: epoch 0115, iter [00500, 01251], lr: 0.001078, loss: 0.4312
2022-09-28 23:04:47 - train: epoch 0115, iter [00510, 01251], lr: 0.001078, loss: 0.4288
2022-09-28 23:05:04 - train: epoch 0115, iter [00520, 01251], lr: 0.001078, loss: 0.4134
2022-09-28 23:05:22 - train: epoch 0115, iter [00530, 01251], lr: 0.001078, loss: 0.4223
2022-09-28 23:05:40 - train: epoch 0115, iter [00540, 01251], lr: 0.001078, loss: 0.4212
2022-09-28 23:05:57 - train: epoch 0115, iter [00550, 01251], lr: 0.001078, loss: 0.4303
2022-09-28 23:06:15 - train: epoch 0115, iter [00560, 01251], lr: 0.001078, loss: 0.4273
2022-09-28 23:06:33 - train: epoch 0115, iter [00570, 01251], lr: 0.001078, loss: 0.4064
2022-09-28 23:06:50 - train: epoch 0115, iter [00580, 01251], lr: 0.001078, loss: 0.4306
2022-09-28 23:07:08 - train: epoch 0115, iter [00590, 01251], lr: 0.001078, loss: 0.4116
2022-09-28 23:07:26 - train: epoch 0115, iter [00600, 01251], lr: 0.001078, loss: 0.4177
2022-09-28 23:07:44 - train: epoch 0115, iter [00610, 01251], lr: 0.001078, loss: 0.4099
2022-09-28 23:08:01 - train: epoch 0115, iter [00620, 01251], lr: 0.001078, loss: 0.4165
2022-09-28 23:08:19 - train: epoch 0115, iter [00630, 01251], lr: 0.001078, loss: 0.4127
2022-09-28 23:08:37 - train: epoch 0115, iter [00640, 01251], lr: 0.001078, loss: 0.4189
2022-09-28 23:08:55 - train: epoch 0115, iter [00650, 01251], lr: 0.001078, loss: 0.4231
2022-09-28 23:09:13 - train: epoch 0115, iter [00660, 01251], lr: 0.001078, loss: 0.4184
2022-09-28 23:09:31 - train: epoch 0115, iter [00670, 01251], lr: 0.001077, loss: 0.4278
2022-09-28 23:09:49 - train: epoch 0115, iter [00680, 01251], lr: 0.001077, loss: 0.4354
2022-09-28 23:10:06 - train: epoch 0115, iter [00690, 01251], lr: 0.001077, loss: 0.4035
2022-09-28 23:10:24 - train: epoch 0115, iter [00700, 01251], lr: 0.001077, loss: 0.4041
2022-09-28 23:10:42 - train: epoch 0115, iter [00710, 01251], lr: 0.001077, loss: 0.4158
2022-09-28 23:11:00 - train: epoch 0115, iter [00720, 01251], lr: 0.001077, loss: 0.4099
2022-09-28 23:11:17 - train: epoch 0115, iter [00730, 01251], lr: 0.001077, loss: 0.3981
2022-09-28 23:11:35 - train: epoch 0115, iter [00740, 01251], lr: 0.001077, loss: 0.4186
2022-09-28 23:11:53 - train: epoch 0115, iter [00750, 01251], lr: 0.001077, loss: 0.4125
2022-09-28 23:12:10 - train: epoch 0115, iter [00760, 01251], lr: 0.001077, loss: 0.3961
2022-09-28 23:12:28 - train: epoch 0115, iter [00770, 01251], lr: 0.001077, loss: 0.4009
2022-09-28 23:12:46 - train: epoch 0115, iter [00780, 01251], lr: 0.001077, loss: 0.4006
2022-09-28 23:13:04 - train: epoch 0115, iter [00790, 01251], lr: 0.001077, loss: 0.4048
2022-09-28 23:13:21 - train: epoch 0115, iter [00800, 01251], lr: 0.001077, loss: 0.4155
2022-09-28 23:13:39 - train: epoch 0115, iter [00810, 01251], lr: 0.001077, loss: 0.3976
2022-09-28 23:13:57 - train: epoch 0115, iter [00820, 01251], lr: 0.001077, loss: 0.4203
2022-09-28 23:14:15 - train: epoch 0115, iter [00830, 01251], lr: 0.001077, loss: 0.4150
2022-09-28 23:14:32 - train: epoch 0115, iter [00840, 01251], lr: 0.001077, loss: 0.4242
2022-09-28 23:14:50 - train: epoch 0115, iter [00850, 01251], lr: 0.001077, loss: 0.4001
2022-09-28 23:15:08 - train: epoch 0115, iter [00860, 01251], lr: 0.001077, loss: 0.4104
2022-09-28 23:15:25 - train: epoch 0115, iter [00870, 01251], lr: 0.001077, loss: 0.4135
2022-09-28 23:15:43 - train: epoch 0115, iter [00880, 01251], lr: 0.001077, loss: 0.4099
2022-09-28 23:16:01 - train: epoch 0115, iter [00890, 01251], lr: 0.001077, loss: 0.4261
2022-09-28 23:16:19 - train: epoch 0115, iter [00900, 01251], lr: 0.001077, loss: 0.4023
2022-09-28 23:16:36 - train: epoch 0115, iter [00910, 01251], lr: 0.001077, loss: 0.4130
2022-09-28 23:16:54 - train: epoch 0115, iter [00920, 01251], lr: 0.001077, loss: 0.3926
2022-09-28 23:17:12 - train: epoch 0115, iter [00930, 01251], lr: 0.001077, loss: 0.4282
2022-09-28 23:17:30 - train: epoch 0115, iter [00940, 01251], lr: 0.001077, loss: 0.4026
2022-09-28 23:17:48 - train: epoch 0115, iter [00950, 01251], lr: 0.001077, loss: 0.4221
2022-09-28 23:18:05 - train: epoch 0115, iter [00960, 01251], lr: 0.001077, loss: 0.4023
2022-09-28 23:18:23 - train: epoch 0115, iter [00970, 01251], lr: 0.001077, loss: 0.4184
2022-09-28 23:18:41 - train: epoch 0115, iter [00980, 01251], lr: 0.001077, loss: 0.4012
2022-09-28 23:18:59 - train: epoch 0115, iter [00990, 01251], lr: 0.001077, loss: 0.4280
2022-09-28 23:19:16 - train: epoch 0115, iter [01000, 01251], lr: 0.001077, loss: 0.4104
2022-09-28 23:19:34 - train: epoch 0115, iter [01010, 01251], lr: 0.001077, loss: 0.4236
2022-09-28 23:19:52 - train: epoch 0115, iter [01020, 01251], lr: 0.001077, loss: 0.4053
2022-09-28 23:20:09 - train: epoch 0115, iter [01030, 01251], lr: 0.001077, loss: 0.3981
2022-09-28 23:20:27 - train: epoch 0115, iter [01040, 01251], lr: 0.001077, loss: 0.4157
2022-09-28 23:20:45 - train: epoch 0115, iter [01050, 01251], lr: 0.001077, loss: 0.4209
2022-09-28 23:21:02 - train: epoch 0115, iter [01060, 01251], lr: 0.001076, loss: 0.4098
2022-09-28 23:21:20 - train: epoch 0115, iter [01070, 01251], lr: 0.001076, loss: 0.3875
2022-09-28 23:21:38 - train: epoch 0115, iter [01080, 01251], lr: 0.001076, loss: 0.4078
2022-09-28 23:21:56 - train: epoch 0115, iter [01090, 01251], lr: 0.001076, loss: 0.4329
2022-09-28 23:22:14 - train: epoch 0115, iter [01100, 01251], lr: 0.001076, loss: 0.4084
2022-09-28 23:22:32 - train: epoch 0115, iter [01110, 01251], lr: 0.001076, loss: 0.3966
2022-09-28 23:22:49 - train: epoch 0115, iter [01120, 01251], lr: 0.001076, loss: 0.4058
2022-09-28 23:23:07 - train: epoch 0115, iter [01130, 01251], lr: 0.001076, loss: 0.4128
2022-09-28 23:23:25 - train: epoch 0115, iter [01140, 01251], lr: 0.001076, loss: 0.4201
2022-09-28 23:23:43 - train: epoch 0115, iter [01150, 01251], lr: 0.001076, loss: 0.3998
2022-09-28 23:24:00 - train: epoch 0115, iter [01160, 01251], lr: 0.001076, loss: 0.4268
2022-09-28 23:24:18 - train: epoch 0115, iter [01170, 01251], lr: 0.001076, loss: 0.4098
2022-09-28 23:24:36 - train: epoch 0115, iter [01180, 01251], lr: 0.001076, loss: 0.4274
2022-09-28 23:24:54 - train: epoch 0115, iter [01190, 01251], lr: 0.001076, loss: 0.4274
2022-09-28 23:25:12 - train: epoch 0115, iter [01200, 01251], lr: 0.001076, loss: 0.4190
2022-09-28 23:25:29 - train: epoch 0115, iter [01210, 01251], lr: 0.001076, loss: 0.4097
2022-09-28 23:25:47 - train: epoch 0115, iter [01220, 01251], lr: 0.001076, loss: 0.4114
2022-09-28 23:26:05 - train: epoch 0115, iter [01230, 01251], lr: 0.001076, loss: 0.4090
2022-09-28 23:26:22 - train: epoch 0115, iter [01240, 01251], lr: 0.001076, loss: 0.4199
2022-09-28 23:26:40 - train: epoch 0115, iter [01250, 01251], lr: 0.001076, loss: 0.4260
2022-09-28 23:26:44 - train: epoch 115, train_loss: 0.4124
2022-09-28 23:26:46 - until epoch: 115, best_loss: 0.4124
2022-09-28 23:26:46 - epoch 116 lr: 0.001076
2022-09-28 23:27:17 - train: epoch 0116, iter [00010, 01251], lr: 0.001076, loss: 0.4255
2022-09-28 23:27:35 - train: epoch 0116, iter [00020, 01251], lr: 0.001076, loss: 0.4062
2022-09-28 23:27:52 - train: epoch 0116, iter [00030, 01251], lr: 0.001076, loss: 0.3901
2022-09-28 23:28:10 - train: epoch 0116, iter [00040, 01251], lr: 0.001076, loss: 0.4215
2022-09-28 23:28:28 - train: epoch 0116, iter [00050, 01251], lr: 0.001076, loss: 0.4167
2022-09-28 23:28:45 - train: epoch 0116, iter [00060, 01251], lr: 0.001076, loss: 0.4139
2022-09-28 23:29:03 - train: epoch 0116, iter [00070, 01251], lr: 0.001076, loss: 0.4144
2022-09-28 23:29:21 - train: epoch 0116, iter [00080, 01251], lr: 0.001076, loss: 0.4231
2022-09-28 23:29:39 - train: epoch 0116, iter [00090, 01251], lr: 0.001076, loss: 0.4110
2022-09-28 23:29:56 - train: epoch 0116, iter [00100, 01251], lr: 0.001076, loss: 0.4145
2022-09-28 23:30:14 - train: epoch 0116, iter [00110, 01251], lr: 0.001076, loss: 0.4171
2022-09-28 23:30:32 - train: epoch 0116, iter [00120, 01251], lr: 0.001076, loss: 0.4156
2022-09-28 23:30:50 - train: epoch 0116, iter [00130, 01251], lr: 0.001076, loss: 0.4343
2022-09-28 23:31:08 - train: epoch 0116, iter [00140, 01251], lr: 0.001076, loss: 0.4343
2022-09-28 23:31:25 - train: epoch 0116, iter [00150, 01251], lr: 0.001076, loss: 0.4125
2022-09-28 23:31:43 - train: epoch 0116, iter [00160, 01251], lr: 0.001076, loss: 0.3899
2022-09-28 23:32:01 - train: epoch 0116, iter [00170, 01251], lr: 0.001076, loss: 0.4070
2022-09-28 23:32:18 - train: epoch 0116, iter [00180, 01251], lr: 0.001076, loss: 0.4295
2022-09-28 23:32:36 - train: epoch 0116, iter [00190, 01251], lr: 0.001076, loss: 0.4117
2022-09-28 23:32:54 - train: epoch 0116, iter [00200, 01251], lr: 0.001076, loss: 0.4065
2022-09-28 23:33:12 - train: epoch 0116, iter [00210, 01251], lr: 0.001075, loss: 0.4180
2022-09-28 23:33:30 - train: epoch 0116, iter [00220, 01251], lr: 0.001075, loss: 0.4055
2022-09-28 23:33:47 - train: epoch 0116, iter [00230, 01251], lr: 0.001075, loss: 0.4250
2022-09-28 23:34:05 - train: epoch 0116, iter [00240, 01251], lr: 0.001075, loss: 0.3999
2022-09-28 23:34:23 - train: epoch 0116, iter [00250, 01251], lr: 0.001075, loss: 0.4182
2022-09-28 23:34:41 - train: epoch 0116, iter [00260, 01251], lr: 0.001075, loss: 0.4079
2022-09-28 23:34:58 - train: epoch 0116, iter [00270, 01251], lr: 0.001075, loss: 0.4158
2022-09-28 23:35:16 - train: epoch 0116, iter [00280, 01251], lr: 0.001075, loss: 0.4082
2022-09-28 23:35:34 - train: epoch 0116, iter [00290, 01251], lr: 0.001075, loss: 0.4172
2022-09-28 23:35:51 - train: epoch 0116, iter [00300, 01251], lr: 0.001075, loss: 0.4287
2022-09-28 23:36:09 - train: epoch 0116, iter [00310, 01251], lr: 0.001075, loss: 0.4009
2022-09-28 23:36:27 - train: epoch 0116, iter [00320, 01251], lr: 0.001075, loss: 0.4042
2022-09-28 23:36:44 - train: epoch 0116, iter [00330, 01251], lr: 0.001075, loss: 0.4267
2022-09-28 23:37:02 - train: epoch 0116, iter [00340, 01251], lr: 0.001075, loss: 0.4164
2022-09-28 23:37:20 - train: epoch 0116, iter [00350, 01251], lr: 0.001075, loss: 0.3985
2022-09-28 23:37:38 - train: epoch 0116, iter [00360, 01251], lr: 0.001075, loss: 0.4009
2022-09-28 23:37:55 - train: epoch 0116, iter [00370, 01251], lr: 0.001075, loss: 0.4104
2022-09-28 23:38:13 - train: epoch 0116, iter [00380, 01251], lr: 0.001075, loss: 0.4199
2022-09-28 23:38:31 - train: epoch 0116, iter [00390, 01251], lr: 0.001075, loss: 0.4039
2022-09-28 23:38:48 - train: epoch 0116, iter [00400, 01251], lr: 0.001075, loss: 0.4303
2022-09-28 23:39:06 - train: epoch 0116, iter [00410, 01251], lr: 0.001075, loss: 0.4053
2022-09-28 23:39:24 - train: epoch 0116, iter [00420, 01251], lr: 0.001075, loss: 0.4179
2022-09-28 23:39:42 - train: epoch 0116, iter [00430, 01251], lr: 0.001075, loss: 0.4087
2022-09-28 23:39:59 - train: epoch 0116, iter [00440, 01251], lr: 0.001075, loss: 0.4234
2022-09-28 23:40:17 - train: epoch 0116, iter [00450, 01251], lr: 0.001075, loss: 0.4119
2022-09-28 23:40:35 - train: epoch 0116, iter [00460, 01251], lr: 0.001075, loss: 0.3980
2022-09-28 23:40:52 - train: epoch 0116, iter [00470, 01251], lr: 0.001075, loss: 0.3890
2022-09-28 23:41:10 - train: epoch 0116, iter [00480, 01251], lr: 0.001075, loss: 0.4105
2022-09-28 23:41:28 - train: epoch 0116, iter [00490, 01251], lr: 0.001075, loss: 0.3929
2022-09-28 23:41:45 - train: epoch 0116, iter [00500, 01251], lr: 0.001075, loss: 0.4366
2022-09-28 23:42:04 - train: epoch 0116, iter [00510, 01251], lr: 0.001075, loss: 0.4183
2022-09-28 23:42:21 - train: epoch 0116, iter [00520, 01251], lr: 0.001075, loss: 0.4114
2022-09-28 23:42:39 - train: epoch 0116, iter [00530, 01251], lr: 0.001075, loss: 0.3964
2022-09-28 23:42:57 - train: epoch 0116, iter [00540, 01251], lr: 0.001075, loss: 0.4232
2022-09-28 23:43:15 - train: epoch 0116, iter [00550, 01251], lr: 0.001075, loss: 0.3959
2022-09-28 23:43:32 - train: epoch 0116, iter [00560, 01251], lr: 0.001075, loss: 0.4167
2022-09-28 23:43:50 - train: epoch 0116, iter [00570, 01251], lr: 0.001075, loss: 0.4051
2022-09-28 23:44:08 - train: epoch 0116, iter [00580, 01251], lr: 0.001075, loss: 0.4266
2022-09-28 23:44:25 - train: epoch 0116, iter [00590, 01251], lr: 0.001075, loss: 0.4089
2022-09-28 23:44:43 - train: epoch 0116, iter [00600, 01251], lr: 0.001074, loss: 0.4102
2022-09-28 23:45:01 - train: epoch 0116, iter [00610, 01251], lr: 0.001074, loss: 0.4109
2022-09-28 23:45:18 - train: epoch 0116, iter [00620, 01251], lr: 0.001074, loss: 0.3705
2022-09-28 23:45:36 - train: epoch 0116, iter [00630, 01251], lr: 0.001074, loss: 0.3937
2022-09-28 23:45:54 - train: epoch 0116, iter [00640, 01251], lr: 0.001074, loss: 0.4143
2022-09-28 23:46:11 - train: epoch 0116, iter [00650, 01251], lr: 0.001074, loss: 0.4178
2022-09-28 23:46:29 - train: epoch 0116, iter [00660, 01251], lr: 0.001074, loss: 0.4169
2022-09-28 23:46:47 - train: epoch 0116, iter [00670, 01251], lr: 0.001074, loss: 0.4345
2022-09-28 23:47:05 - train: epoch 0116, iter [00680, 01251], lr: 0.001074, loss: 0.4067
2022-09-28 23:47:22 - train: epoch 0116, iter [00690, 01251], lr: 0.001074, loss: 0.4022
2022-09-28 23:47:40 - train: epoch 0116, iter [00700, 01251], lr: 0.001074, loss: 0.4314
2022-09-28 23:47:58 - train: epoch 0116, iter [00710, 01251], lr: 0.001074, loss: 0.4172
2022-09-28 23:48:16 - train: epoch 0116, iter [00720, 01251], lr: 0.001074, loss: 0.4151
2022-09-28 23:48:33 - train: epoch 0116, iter [00730, 01251], lr: 0.001074, loss: 0.4053
2022-09-28 23:48:51 - train: epoch 0116, iter [00740, 01251], lr: 0.001074, loss: 0.4300
2022-09-28 23:49:09 - train: epoch 0116, iter [00750, 01251], lr: 0.001074, loss: 0.4237
2022-09-28 23:49:27 - train: epoch 0116, iter [00760, 01251], lr: 0.001074, loss: 0.4067
2022-09-28 23:49:45 - train: epoch 0116, iter [00770, 01251], lr: 0.001074, loss: 0.4112
2022-09-28 23:50:02 - train: epoch 0116, iter [00780, 01251], lr: 0.001074, loss: 0.4011
2022-09-28 23:50:20 - train: epoch 0116, iter [00790, 01251], lr: 0.001074, loss: 0.4183
2022-09-28 23:50:38 - train: epoch 0116, iter [00800, 01251], lr: 0.001074, loss: 0.4234
2022-09-28 23:50:56 - train: epoch 0116, iter [00810, 01251], lr: 0.001074, loss: 0.4067
2022-09-28 23:51:13 - train: epoch 0116, iter [00820, 01251], lr: 0.001074, loss: 0.4075
2022-09-28 23:51:31 - train: epoch 0116, iter [00830, 01251], lr: 0.001074, loss: 0.4071
2022-09-28 23:51:49 - train: epoch 0116, iter [00840, 01251], lr: 0.001074, loss: 0.4126
2022-09-28 23:52:07 - train: epoch 0116, iter [00850, 01251], lr: 0.001074, loss: 0.4013
2022-09-28 23:52:24 - train: epoch 0116, iter [00860, 01251], lr: 0.001074, loss: 0.4369
2022-09-28 23:52:42 - train: epoch 0116, iter [00870, 01251], lr: 0.001074, loss: 0.4259
2022-09-28 23:53:00 - train: epoch 0116, iter [00880, 01251], lr: 0.001074, loss: 0.4096
2022-09-28 23:53:18 - train: epoch 0116, iter [00890, 01251], lr: 0.001074, loss: 0.4218
2022-09-28 23:53:36 - train: epoch 0116, iter [00900, 01251], lr: 0.001074, loss: 0.3957
2022-09-28 23:53:53 - train: epoch 0116, iter [00910, 01251], lr: 0.001074, loss: 0.4269
2022-09-28 23:54:11 - train: epoch 0116, iter [00920, 01251], lr: 0.001074, loss: 0.3950
2022-09-28 23:54:29 - train: epoch 0116, iter [00930, 01251], lr: 0.001074, loss: 0.4105
2022-09-28 23:54:47 - train: epoch 0116, iter [00940, 01251], lr: 0.001074, loss: 0.4217
2022-09-28 23:55:04 - train: epoch 0116, iter [00950, 01251], lr: 0.001074, loss: 0.4000
2022-09-28 23:55:22 - train: epoch 0116, iter [00960, 01251], lr: 0.001074, loss: 0.4074
2022-09-28 23:55:40 - train: epoch 0116, iter [00970, 01251], lr: 0.001074, loss: 0.4314
2022-09-28 23:55:58 - train: epoch 0116, iter [00980, 01251], lr: 0.001074, loss: 0.4159
2022-09-28 23:56:16 - train: epoch 0116, iter [00990, 01251], lr: 0.001073, loss: 0.3861
2022-09-28 23:56:33 - train: epoch 0116, iter [01000, 01251], lr: 0.001073, loss: 0.4193
2022-09-28 23:56:51 - train: epoch 0116, iter [01010, 01251], lr: 0.001073, loss: 0.4214
2022-09-28 23:57:09 - train: epoch 0116, iter [01020, 01251], lr: 0.001073, loss: 0.4181
2022-09-28 23:57:27 - train: epoch 0116, iter [01030, 01251], lr: 0.001073, loss: 0.4345
2022-09-28 23:57:44 - train: epoch 0116, iter [01040, 01251], lr: 0.001073, loss: 0.4332
2022-09-28 23:58:02 - train: epoch 0116, iter [01050, 01251], lr: 0.001073, loss: 0.4035
2022-09-28 23:58:20 - train: epoch 0116, iter [01060, 01251], lr: 0.001073, loss: 0.4195
2022-09-28 23:58:38 - train: epoch 0116, iter [01070, 01251], lr: 0.001073, loss: 0.4062
2022-09-28 23:58:55 - train: epoch 0116, iter [01080, 01251], lr: 0.001073, loss: 0.4046
2022-09-28 23:59:13 - train: epoch 0116, iter [01090, 01251], lr: 0.001073, loss: 0.4169
2022-09-28 23:59:31 - train: epoch 0116, iter [01100, 01251], lr: 0.001073, loss: 0.3963
2022-09-28 23:59:49 - train: epoch 0116, iter [01110, 01251], lr: 0.001073, loss: 0.3898
2022-09-29 00:00:07 - train: epoch 0116, iter [01120, 01251], lr: 0.001073, loss: 0.4097
2022-09-29 00:00:24 - train: epoch 0116, iter [01130, 01251], lr: 0.001073, loss: 0.4187
2022-09-29 00:00:42 - train: epoch 0116, iter [01140, 01251], lr: 0.001073, loss: 0.3907
2022-09-29 00:01:00 - train: epoch 0116, iter [01150, 01251], lr: 0.001073, loss: 0.4205
2022-09-29 00:01:18 - train: epoch 0116, iter [01160, 01251], lr: 0.001073, loss: 0.3802
2022-09-29 00:01:35 - train: epoch 0116, iter [01170, 01251], lr: 0.001073, loss: 0.4084
2022-09-29 00:01:53 - train: epoch 0116, iter [01180, 01251], lr: 0.001073, loss: 0.4050
2022-09-29 00:02:11 - train: epoch 0116, iter [01190, 01251], lr: 0.001073, loss: 0.4149
2022-09-29 00:02:29 - train: epoch 0116, iter [01200, 01251], lr: 0.001073, loss: 0.4096
2022-09-29 00:02:47 - train: epoch 0116, iter [01210, 01251], lr: 0.001073, loss: 0.4064
2022-09-29 00:03:04 - train: epoch 0116, iter [01220, 01251], lr: 0.001073, loss: 0.4171
2022-09-29 00:03:22 - train: epoch 0116, iter [01230, 01251], lr: 0.001073, loss: 0.4061
2022-09-29 00:03:40 - train: epoch 0116, iter [01240, 01251], lr: 0.001073, loss: 0.4240
2022-09-29 00:03:57 - train: epoch 0116, iter [01250, 01251], lr: 0.001073, loss: 0.4161
2022-09-29 00:04:01 - train: epoch 116, train_loss: 0.4123
2022-09-29 00:04:03 - until epoch: 116, best_loss: 0.4123
2022-09-29 00:04:03 - epoch 117 lr: 0.001073
2022-09-29 00:04:35 - train: epoch 0117, iter [00010, 01251], lr: 0.001073, loss: 0.4113
2022-09-29 00:04:53 - train: epoch 0117, iter [00020, 01251], lr: 0.001073, loss: 0.4181
2022-09-29 00:05:10 - train: epoch 0117, iter [00030, 01251], lr: 0.001073, loss: 0.4143
2022-09-29 00:05:28 - train: epoch 0117, iter [00040, 01251], lr: 0.001073, loss: 0.3964
2022-09-29 00:05:46 - train: epoch 0117, iter [00050, 01251], lr: 0.001073, loss: 0.4071
2022-09-29 00:06:04 - train: epoch 0117, iter [00060, 01251], lr: 0.001073, loss: 0.4195
2022-09-29 00:06:21 - train: epoch 0117, iter [00070, 01251], lr: 0.001073, loss: 0.3948
2022-09-29 00:06:39 - train: epoch 0117, iter [00080, 01251], lr: 0.001073, loss: 0.4067
2022-09-29 00:06:57 - train: epoch 0117, iter [00090, 01251], lr: 0.001073, loss: 0.4068
2022-09-29 00:07:15 - train: epoch 0117, iter [00100, 01251], lr: 0.001073, loss: 0.4154
2022-09-29 00:07:32 - train: epoch 0117, iter [00110, 01251], lr: 0.001073, loss: 0.3915
2022-09-29 00:07:50 - train: epoch 0117, iter [00120, 01251], lr: 0.001072, loss: 0.4032
2022-09-29 00:08:08 - train: epoch 0117, iter [00130, 01251], lr: 0.001072, loss: 0.3917
2022-09-29 00:08:26 - train: epoch 0117, iter [00140, 01251], lr: 0.001072, loss: 0.4162
2022-09-29 00:08:43 - train: epoch 0117, iter [00150, 01251], lr: 0.001072, loss: 0.4133
2022-09-29 00:09:01 - train: epoch 0117, iter [00160, 01251], lr: 0.001072, loss: 0.4102
2022-09-29 00:09:19 - train: epoch 0117, iter [00170, 01251], lr: 0.001072, loss: 0.4104
2022-09-29 00:09:37 - train: epoch 0117, iter [00180, 01251], lr: 0.001072, loss: 0.4001
2022-09-29 00:09:55 - train: epoch 0117, iter [00190, 01251], lr: 0.001072, loss: 0.4046
2022-09-29 00:10:13 - train: epoch 0117, iter [00200, 01251], lr: 0.001072, loss: 0.4236
2022-09-29 00:10:30 - train: epoch 0117, iter [00210, 01251], lr: 0.001072, loss: 0.4429
2022-09-29 00:10:48 - train: epoch 0117, iter [00220, 01251], lr: 0.001072, loss: 0.4104
2022-09-29 00:11:05 - train: epoch 0117, iter [00230, 01251], lr: 0.001072, loss: 0.4167
2022-09-29 00:11:23 - train: epoch 0117, iter [00240, 01251], lr: 0.001072, loss: 0.4088
2022-09-29 00:11:41 - train: epoch 0117, iter [00250, 01251], lr: 0.001072, loss: 0.3946
2022-09-29 00:11:58 - train: epoch 0117, iter [00260, 01251], lr: 0.001072, loss: 0.4249
2022-09-29 00:12:16 - train: epoch 0117, iter [00270, 01251], lr: 0.001072, loss: 0.4209
2022-09-29 00:12:34 - train: epoch 0117, iter [00280, 01251], lr: 0.001072, loss: 0.4327
2022-09-29 00:12:51 - train: epoch 0117, iter [00290, 01251], lr: 0.001072, loss: 0.4077
2022-09-29 00:13:09 - train: epoch 0117, iter [00300, 01251], lr: 0.001072, loss: 0.4248
2022-09-29 00:13:27 - train: epoch 0117, iter [00310, 01251], lr: 0.001072, loss: 0.4003
2022-09-29 00:13:44 - train: epoch 0117, iter [00320, 01251], lr: 0.001072, loss: 0.4189
2022-09-29 00:14:02 - train: epoch 0117, iter [00330, 01251], lr: 0.001072, loss: 0.4208
2022-09-29 00:14:19 - train: epoch 0117, iter [00340, 01251], lr: 0.001072, loss: 0.4061
2022-09-29 00:14:37 - train: epoch 0117, iter [00350, 01251], lr: 0.001072, loss: 0.4183
2022-09-29 00:14:55 - train: epoch 0117, iter [00360, 01251], lr: 0.001072, loss: 0.3966
2022-09-29 00:15:12 - train: epoch 0117, iter [00370, 01251], lr: 0.001072, loss: 0.4163
2022-09-29 00:15:30 - train: epoch 0117, iter [00380, 01251], lr: 0.001072, loss: 0.4035
2022-09-29 00:15:48 - train: epoch 0117, iter [00390, 01251], lr: 0.001072, loss: 0.4115
2022-09-29 00:16:05 - train: epoch 0117, iter [00400, 01251], lr: 0.001072, loss: 0.4097
2022-09-29 00:16:23 - train: epoch 0117, iter [00410, 01251], lr: 0.001072, loss: 0.4088
2022-09-29 00:16:41 - train: epoch 0117, iter [00420, 01251], lr: 0.001072, loss: 0.4106
2022-09-29 00:16:59 - train: epoch 0117, iter [00430, 01251], lr: 0.001072, loss: 0.3961
2022-09-29 00:17:16 - train: epoch 0117, iter [00440, 01251], lr: 0.001072, loss: 0.4244
2022-09-29 00:17:34 - train: epoch 0117, iter [00450, 01251], lr: 0.001072, loss: 0.4263
2022-09-29 00:17:52 - train: epoch 0117, iter [00460, 01251], lr: 0.001072, loss: 0.4072
2022-09-29 00:18:10 - train: epoch 0117, iter [00470, 01251], lr: 0.001072, loss: 0.3989
2022-09-29 00:18:28 - train: epoch 0117, iter [00480, 01251], lr: 0.001072, loss: 0.4232
2022-09-29 00:18:45 - train: epoch 0117, iter [00490, 01251], lr: 0.001072, loss: 0.3971
2022-09-29 00:19:03 - train: epoch 0117, iter [00500, 01251], lr: 0.001072, loss: 0.4067
2022-09-29 00:19:21 - train: epoch 0117, iter [00510, 01251], lr: 0.001071, loss: 0.4039
2022-09-29 00:19:38 - train: epoch 0117, iter [00520, 01251], lr: 0.001071, loss: 0.4259
2022-09-29 00:19:56 - train: epoch 0117, iter [00530, 01251], lr: 0.001071, loss: 0.3979
2022-09-29 00:20:14 - train: epoch 0117, iter [00540, 01251], lr: 0.001071, loss: 0.4210
2022-09-29 00:20:32 - train: epoch 0117, iter [00550, 01251], lr: 0.001071, loss: 0.4197
2022-09-29 00:20:49 - train: epoch 0117, iter [00560, 01251], lr: 0.001071, loss: 0.4179
2022-09-29 00:21:07 - train: epoch 0117, iter [00570, 01251], lr: 0.001071, loss: 0.4143
2022-09-29 00:21:25 - train: epoch 0117, iter [00580, 01251], lr: 0.001071, loss: 0.3936
2022-09-29 00:21:42 - train: epoch 0117, iter [00590, 01251], lr: 0.001071, loss: 0.4054
2022-09-29 00:22:00 - train: epoch 0117, iter [00600, 01251], lr: 0.001071, loss: 0.4277
2022-09-29 00:22:18 - train: epoch 0117, iter [00610, 01251], lr: 0.001071, loss: 0.4245
2022-09-29 00:22:35 - train: epoch 0117, iter [00620, 01251], lr: 0.001071, loss: 0.4116
2022-09-29 00:22:53 - train: epoch 0117, iter [00630, 01251], lr: 0.001071, loss: 0.4366
2022-09-29 00:23:11 - train: epoch 0117, iter [00640, 01251], lr: 0.001071, loss: 0.3894
2022-09-29 00:23:29 - train: epoch 0117, iter [00650, 01251], lr: 0.001071, loss: 0.4070
2022-09-29 00:23:47 - train: epoch 0117, iter [00660, 01251], lr: 0.001071, loss: 0.4237
2022-09-29 00:24:04 - train: epoch 0117, iter [00670, 01251], lr: 0.001071, loss: 0.4216
2022-09-29 00:24:22 - train: epoch 0117, iter [00680, 01251], lr: 0.001071, loss: 0.4036
2022-09-29 00:24:40 - train: epoch 0117, iter [00690, 01251], lr: 0.001071, loss: 0.4174
2022-09-29 00:24:58 - train: epoch 0117, iter [00700, 01251], lr: 0.001071, loss: 0.4196
2022-09-29 00:25:16 - train: epoch 0117, iter [00710, 01251], lr: 0.001071, loss: 0.4042
2022-09-29 00:25:33 - train: epoch 0117, iter [00720, 01251], lr: 0.001071, loss: 0.4127
2022-09-29 00:25:51 - train: epoch 0117, iter [00730, 01251], lr: 0.001071, loss: 0.4090
2022-09-29 00:26:09 - train: epoch 0117, iter [00740, 01251], lr: 0.001071, loss: 0.4297
2022-09-29 00:26:26 - train: epoch 0117, iter [00750, 01251], lr: 0.001071, loss: 0.4131
2022-09-29 00:26:44 - train: epoch 0117, iter [00760, 01251], lr: 0.001071, loss: 0.4306
2022-09-29 00:27:02 - train: epoch 0117, iter [00770, 01251], lr: 0.001071, loss: 0.3917
2022-09-29 00:27:20 - train: epoch 0117, iter [00780, 01251], lr: 0.001071, loss: 0.4299
2022-09-29 00:27:38 - train: epoch 0117, iter [00790, 01251], lr: 0.001071, loss: 0.4176
2022-09-29 00:27:55 - train: epoch 0117, iter [00800, 01251], lr: 0.001071, loss: 0.4074
2022-09-29 00:28:13 - train: epoch 0117, iter [00810, 01251], lr: 0.001071, loss: 0.4301
2022-09-29 00:28:31 - train: epoch 0117, iter [00820, 01251], lr: 0.001071, loss: 0.4279
2022-09-29 00:28:49 - train: epoch 0117, iter [00830, 01251], lr: 0.001071, loss: 0.4131
2022-09-29 00:29:07 - train: epoch 0117, iter [00840, 01251], lr: 0.001071, loss: 0.4215
2022-09-29 00:29:24 - train: epoch 0117, iter [00850, 01251], lr: 0.001071, loss: 0.3954
2022-09-29 00:29:42 - train: epoch 0117, iter [00860, 01251], lr: 0.001071, loss: 0.4112
2022-09-29 00:30:00 - train: epoch 0117, iter [00870, 01251], lr: 0.001071, loss: 0.4038
2022-09-29 00:30:17 - train: epoch 0117, iter [00880, 01251], lr: 0.001071, loss: 0.4222
2022-09-29 00:30:35 - train: epoch 0117, iter [00890, 01251], lr: 0.001071, loss: 0.4104
2022-09-29 00:30:53 - train: epoch 0117, iter [00900, 01251], lr: 0.001070, loss: 0.4183
2022-09-29 00:31:11 - train: epoch 0117, iter [00910, 01251], lr: 0.001070, loss: 0.3983
2022-09-29 00:31:28 - train: epoch 0117, iter [00920, 01251], lr: 0.001070, loss: 0.4035
2022-09-29 00:31:46 - train: epoch 0117, iter [00930, 01251], lr: 0.001070, loss: 0.4259
2022-09-29 00:32:04 - train: epoch 0117, iter [00940, 01251], lr: 0.001070, loss: 0.4000
2022-09-29 00:32:22 - train: epoch 0117, iter [00950, 01251], lr: 0.001070, loss: 0.4211
2022-09-29 00:32:39 - train: epoch 0117, iter [00960, 01251], lr: 0.001070, loss: 0.3979
2022-09-29 00:32:57 - train: epoch 0117, iter [00970, 01251], lr: 0.001070, loss: 0.4037
2022-09-29 00:33:15 - train: epoch 0117, iter [00980, 01251], lr: 0.001070, loss: 0.4202
2022-09-29 00:33:32 - train: epoch 0117, iter [00990, 01251], lr: 0.001070, loss: 0.4221
2022-09-29 00:33:50 - train: epoch 0117, iter [01000, 01251], lr: 0.001070, loss: 0.4165
2022-09-29 00:34:08 - train: epoch 0117, iter [01010, 01251], lr: 0.001070, loss: 0.4128
2022-09-29 00:34:26 - train: epoch 0117, iter [01020, 01251], lr: 0.001070, loss: 0.4301
2022-09-29 00:34:43 - train: epoch 0117, iter [01030, 01251], lr: 0.001070, loss: 0.4010
2022-09-29 00:35:01 - train: epoch 0117, iter [01040, 01251], lr: 0.001070, loss: 0.4195
2022-09-29 00:35:19 - train: epoch 0117, iter [01050, 01251], lr: 0.001070, loss: 0.4294
2022-09-29 00:35:37 - train: epoch 0117, iter [01060, 01251], lr: 0.001070, loss: 0.4175
2022-09-29 00:35:55 - train: epoch 0117, iter [01070, 01251], lr: 0.001070, loss: 0.4176
2022-09-29 00:36:12 - train: epoch 0117, iter [01080, 01251], lr: 0.001070, loss: 0.4201
2022-09-29 00:36:30 - train: epoch 0117, iter [01090, 01251], lr: 0.001070, loss: 0.4060
2022-09-29 00:36:48 - train: epoch 0117, iter [01100, 01251], lr: 0.001070, loss: 0.4094
2022-09-29 00:37:06 - train: epoch 0117, iter [01110, 01251], lr: 0.001070, loss: 0.4073
2022-09-29 00:37:24 - train: epoch 0117, iter [01120, 01251], lr: 0.001070, loss: 0.3887
2022-09-29 00:37:42 - train: epoch 0117, iter [01130, 01251], lr: 0.001070, loss: 0.4095
2022-09-29 00:37:59 - train: epoch 0117, iter [01140, 01251], lr: 0.001070, loss: 0.4314
2022-09-29 00:38:17 - train: epoch 0117, iter [01150, 01251], lr: 0.001070, loss: 0.4266
2022-09-29 00:38:35 - train: epoch 0117, iter [01160, 01251], lr: 0.001070, loss: 0.4148
2022-09-29 00:38:53 - train: epoch 0117, iter [01170, 01251], lr: 0.001070, loss: 0.4150
2022-09-29 00:39:10 - train: epoch 0117, iter [01180, 01251], lr: 0.001070, loss: 0.4104
2022-09-29 00:39:28 - train: epoch 0117, iter [01190, 01251], lr: 0.001070, loss: 0.4026
2022-09-29 00:39:46 - train: epoch 0117, iter [01200, 01251], lr: 0.001070, loss: 0.3993
2022-09-29 00:40:04 - train: epoch 0117, iter [01210, 01251], lr: 0.001070, loss: 0.4233
2022-09-29 00:40:21 - train: epoch 0117, iter [01220, 01251], lr: 0.001070, loss: 0.4245
2022-09-29 00:40:39 - train: epoch 0117, iter [01230, 01251], lr: 0.001070, loss: 0.3973
2022-09-29 00:40:57 - train: epoch 0117, iter [01240, 01251], lr: 0.001070, loss: 0.4081
2022-09-29 00:41:14 - train: epoch 0117, iter [01250, 01251], lr: 0.001070, loss: 0.4192
2022-09-29 00:41:18 - train: epoch 117, train_loss: 0.4123
2022-09-29 00:41:19 - until epoch: 117, best_loss: 0.4123
2022-09-29 00:41:19 - epoch 118 lr: 0.001070
2022-09-29 00:41:52 - train: epoch 0118, iter [00010, 01251], lr: 0.001070, loss: 0.4052
2022-09-29 00:42:10 - train: epoch 0118, iter [00020, 01251], lr: 0.001070, loss: 0.4296
2022-09-29 00:42:28 - train: epoch 0118, iter [00030, 01251], lr: 0.001069, loss: 0.4015
2022-09-29 00:42:46 - train: epoch 0118, iter [00040, 01251], lr: 0.001069, loss: 0.4017
2022-09-29 00:43:04 - train: epoch 0118, iter [00050, 01251], lr: 0.001069, loss: 0.4157
2022-09-29 00:43:21 - train: epoch 0118, iter [00060, 01251], lr: 0.001069, loss: 0.4175
2022-09-29 00:43:39 - train: epoch 0118, iter [00070, 01251], lr: 0.001069, loss: 0.4239
2022-09-29 00:43:57 - train: epoch 0118, iter [00080, 01251], lr: 0.001069, loss: 0.4166
2022-09-29 00:44:14 - train: epoch 0118, iter [00090, 01251], lr: 0.001069, loss: 0.4050
2022-09-29 00:44:32 - train: epoch 0118, iter [00100, 01251], lr: 0.001069, loss: 0.4352
2022-09-29 00:44:50 - train: epoch 0118, iter [00110, 01251], lr: 0.001069, loss: 0.4043
2022-09-29 00:45:08 - train: epoch 0118, iter [00120, 01251], lr: 0.001069, loss: 0.4305
2022-09-29 00:45:25 - train: epoch 0118, iter [00130, 01251], lr: 0.001069, loss: 0.4018
2022-09-29 00:45:43 - train: epoch 0118, iter [00140, 01251], lr: 0.001069, loss: 0.3837
2022-09-29 00:46:01 - train: epoch 0118, iter [00150, 01251], lr: 0.001069, loss: 0.4019
2022-09-29 00:46:19 - train: epoch 0118, iter [00160, 01251], lr: 0.001069, loss: 0.4007
2022-09-29 00:46:37 - train: epoch 0118, iter [00170, 01251], lr: 0.001069, loss: 0.4179
2022-09-29 00:46:54 - train: epoch 0118, iter [00180, 01251], lr: 0.001069, loss: 0.4165
2022-09-29 00:47:12 - train: epoch 0118, iter [00190, 01251], lr: 0.001069, loss: 0.4187
2022-09-29 00:47:30 - train: epoch 0118, iter [00200, 01251], lr: 0.001069, loss: 0.3924
2022-09-29 00:47:48 - train: epoch 0118, iter [00210, 01251], lr: 0.001069, loss: 0.4097
2022-09-29 00:48:06 - train: epoch 0118, iter [00220, 01251], lr: 0.001069, loss: 0.3952
2022-09-29 00:48:24 - train: epoch 0118, iter [00230, 01251], lr: 0.001069, loss: 0.4124
2022-09-29 00:48:41 - train: epoch 0118, iter [00240, 01251], lr: 0.001069, loss: 0.4016
2022-09-29 00:48:59 - train: epoch 0118, iter [00250, 01251], lr: 0.001069, loss: 0.4328
2022-09-29 00:49:17 - train: epoch 0118, iter [00260, 01251], lr: 0.001069, loss: 0.4136
2022-09-29 00:49:35 - train: epoch 0118, iter [00270, 01251], lr: 0.001069, loss: 0.3982
2022-09-29 00:49:52 - train: epoch 0118, iter [00280, 01251], lr: 0.001069, loss: 0.3926
2022-09-29 00:50:10 - train: epoch 0118, iter [00290, 01251], lr: 0.001069, loss: 0.4186
2022-09-29 00:50:28 - train: epoch 0118, iter [00300, 01251], lr: 0.001069, loss: 0.3821
2022-09-29 00:50:46 - train: epoch 0118, iter [00310, 01251], lr: 0.001069, loss: 0.3925
2022-09-29 00:51:04 - train: epoch 0118, iter [00320, 01251], lr: 0.001069, loss: 0.4067
2022-09-29 00:51:21 - train: epoch 0118, iter [00330, 01251], lr: 0.001069, loss: 0.4274
2022-09-29 00:51:39 - train: epoch 0118, iter [00340, 01251], lr: 0.001069, loss: 0.4143
2022-09-29 00:51:57 - train: epoch 0118, iter [00350, 01251], lr: 0.001069, loss: 0.4179
2022-09-29 00:52:14 - train: epoch 0118, iter [00360, 01251], lr: 0.001069, loss: 0.4199
2022-09-29 00:52:32 - train: epoch 0118, iter [00370, 01251], lr: 0.001069, loss: 0.4043
2022-09-29 00:52:50 - train: epoch 0118, iter [00380, 01251], lr: 0.001069, loss: 0.4119
2022-09-29 00:53:08 - train: epoch 0118, iter [00390, 01251], lr: 0.001069, loss: 0.4019
2022-09-29 00:53:25 - train: epoch 0118, iter [00400, 01251], lr: 0.001069, loss: 0.4062
2022-09-29 00:53:43 - train: epoch 0118, iter [00410, 01251], lr: 0.001068, loss: 0.4059
2022-09-29 00:54:01 - train: epoch 0118, iter [00420, 01251], lr: 0.001068, loss: 0.3938
2022-09-29 00:54:19 - train: epoch 0118, iter [00430, 01251], lr: 0.001068, loss: 0.4068
2022-09-29 00:54:37 - train: epoch 0118, iter [00440, 01251], lr: 0.001068, loss: 0.4271
2022-09-29 00:54:54 - train: epoch 0118, iter [00450, 01251], lr: 0.001068, loss: 0.4245
2022-09-29 00:55:12 - train: epoch 0118, iter [00460, 01251], lr: 0.001068, loss: 0.3937
2022-09-29 00:55:30 - train: epoch 0118, iter [00470, 01251], lr: 0.001068, loss: 0.4125
2022-09-29 00:55:48 - train: epoch 0118, iter [00480, 01251], lr: 0.001068, loss: 0.4163
2022-09-29 00:56:06 - train: epoch 0118, iter [00490, 01251], lr: 0.001068, loss: 0.3940
2022-09-29 00:56:24 - train: epoch 0118, iter [00500, 01251], lr: 0.001068, loss: 0.4120
2022-09-29 00:56:41 - train: epoch 0118, iter [00510, 01251], lr: 0.001068, loss: 0.4335
2022-09-29 00:56:59 - train: epoch 0118, iter [00520, 01251], lr: 0.001068, loss: 0.4027
2022-09-29 00:57:17 - train: epoch 0118, iter [00530, 01251], lr: 0.001068, loss: 0.3798
2022-09-29 00:57:35 - train: epoch 0118, iter [00540, 01251], lr: 0.001068, loss: 0.4193
2022-09-29 00:57:53 - train: epoch 0118, iter [00550, 01251], lr: 0.001068, loss: 0.4183
2022-09-29 00:58:10 - train: epoch 0118, iter [00560, 01251], lr: 0.001068, loss: 0.3851
2022-09-29 00:58:28 - train: epoch 0118, iter [00570, 01251], lr: 0.001068, loss: 0.4219
2022-09-29 00:58:46 - train: epoch 0118, iter [00580, 01251], lr: 0.001068, loss: 0.4161
2022-09-29 00:59:04 - train: epoch 0118, iter [00590, 01251], lr: 0.001068, loss: 0.4107
2022-09-29 00:59:21 - train: epoch 0118, iter [00600, 01251], lr: 0.001068, loss: 0.3972
2022-09-29 00:59:39 - train: epoch 0118, iter [00610, 01251], lr: 0.001068, loss: 0.3997
2022-09-29 00:59:57 - train: epoch 0118, iter [00620, 01251], lr: 0.001068, loss: 0.4111
2022-09-29 01:00:15 - train: epoch 0118, iter [00630, 01251], lr: 0.001068, loss: 0.4081
2022-09-29 01:00:32 - train: epoch 0118, iter [00640, 01251], lr: 0.001068, loss: 0.3957
2022-09-29 01:00:50 - train: epoch 0118, iter [00650, 01251], lr: 0.001068, loss: 0.3969
2022-09-29 01:01:08 - train: epoch 0118, iter [00660, 01251], lr: 0.001068, loss: 0.3978
2022-09-29 01:01:26 - train: epoch 0118, iter [00670, 01251], lr: 0.001068, loss: 0.4044
2022-09-29 01:01:44 - train: epoch 0118, iter [00680, 01251], lr: 0.001068, loss: 0.4128
2022-09-29 01:02:01 - train: epoch 0118, iter [00690, 01251], lr: 0.001068, loss: 0.4115
2022-09-29 01:02:19 - train: epoch 0118, iter [00700, 01251], lr: 0.001068, loss: 0.3850
2022-09-29 01:02:37 - train: epoch 0118, iter [00710, 01251], lr: 0.001068, loss: 0.3979
2022-09-29 01:02:55 - train: epoch 0118, iter [00720, 01251], lr: 0.001068, loss: 0.4183
2022-09-29 01:03:12 - train: epoch 0118, iter [00730, 01251], lr: 0.001068, loss: 0.3940
2022-09-29 01:03:30 - train: epoch 0118, iter [00740, 01251], lr: 0.001068, loss: 0.3966
2022-09-29 01:03:48 - train: epoch 0118, iter [00750, 01251], lr: 0.001068, loss: 0.4011
2022-09-29 01:04:05 - train: epoch 0118, iter [00760, 01251], lr: 0.001068, loss: 0.4235
2022-09-29 01:04:23 - train: epoch 0118, iter [00770, 01251], lr: 0.001068, loss: 0.4044
2022-09-29 01:04:41 - train: epoch 0118, iter [00780, 01251], lr: 0.001068, loss: 0.4084
2022-09-29 01:04:59 - train: epoch 0118, iter [00790, 01251], lr: 0.001067, loss: 0.4123
2022-09-29 01:05:16 - train: epoch 0118, iter [00800, 01251], lr: 0.001067, loss: 0.4151
2022-09-29 01:05:34 - train: epoch 0118, iter [00810, 01251], lr: 0.001067, loss: 0.4235
2022-09-29 01:05:52 - train: epoch 0118, iter [00820, 01251], lr: 0.001067, loss: 0.4007
2022-09-29 01:06:10 - train: epoch 0118, iter [00830, 01251], lr: 0.001067, loss: 0.4359
2022-09-29 01:06:28 - train: epoch 0118, iter [00840, 01251], lr: 0.001067, loss: 0.4031
2022-09-29 01:06:45 - train: epoch 0118, iter [00850, 01251], lr: 0.001067, loss: 0.4063
2022-09-29 01:07:03 - train: epoch 0118, iter [00860, 01251], lr: 0.001067, loss: 0.4120
2022-09-29 01:07:21 - train: epoch 0118, iter [00870, 01251], lr: 0.001067, loss: 0.4154
2022-09-29 01:07:39 - train: epoch 0118, iter [00880, 01251], lr: 0.001067, loss: 0.4127
2022-09-29 01:07:56 - train: epoch 0118, iter [00890, 01251], lr: 0.001067, loss: 0.4206
2022-09-29 01:08:14 - train: epoch 0118, iter [00900, 01251], lr: 0.001067, loss: 0.3973
2022-09-29 01:08:32 - train: epoch 0118, iter [00910, 01251], lr: 0.001067, loss: 0.4125
2022-09-29 01:08:49 - train: epoch 0118, iter [00920, 01251], lr: 0.001067, loss: 0.3907
2022-09-29 01:09:07 - train: epoch 0118, iter [00930, 01251], lr: 0.001067, loss: 0.4106
2022-09-29 01:09:25 - train: epoch 0118, iter [00940, 01251], lr: 0.001067, loss: 0.3882
2022-09-29 01:09:43 - train: epoch 0118, iter [00950, 01251], lr: 0.001067, loss: 0.4154
2022-09-29 01:10:01 - train: epoch 0118, iter [00960, 01251], lr: 0.001067, loss: 0.4409
2022-09-29 01:10:18 - train: epoch 0118, iter [00970, 01251], lr: 0.001067, loss: 0.4032
2022-09-29 01:10:36 - train: epoch 0118, iter [00980, 01251], lr: 0.001067, loss: 0.4379
2022-09-29 01:10:54 - train: epoch 0118, iter [00990, 01251], lr: 0.001067, loss: 0.4196
2022-09-29 01:11:12 - train: epoch 0118, iter [01000, 01251], lr: 0.001067, loss: 0.4090
2022-09-29 01:11:30 - train: epoch 0118, iter [01010, 01251], lr: 0.001067, loss: 0.4181
2022-09-29 01:11:47 - train: epoch 0118, iter [01020, 01251], lr: 0.001067, loss: 0.4209
2022-09-29 01:12:05 - train: epoch 0118, iter [01030, 01251], lr: 0.001067, loss: 0.4116
2022-09-29 01:12:23 - train: epoch 0118, iter [01040, 01251], lr: 0.001067, loss: 0.4048
2022-09-29 01:12:41 - train: epoch 0118, iter [01050, 01251], lr: 0.001067, loss: 0.4299
2022-09-29 01:12:59 - train: epoch 0118, iter [01060, 01251], lr: 0.001067, loss: 0.4305
2022-09-29 01:13:17 - train: epoch 0118, iter [01070, 01251], lr: 0.001067, loss: 0.3928
2022-09-29 01:13:34 - train: epoch 0118, iter [01080, 01251], lr: 0.001067, loss: 0.4121
2022-09-29 01:13:52 - train: epoch 0118, iter [01090, 01251], lr: 0.001067, loss: 0.4276
2022-09-29 01:14:10 - train: epoch 0118, iter [01100, 01251], lr: 0.001067, loss: 0.4039
2022-09-29 01:14:28 - train: epoch 0118, iter [01110, 01251], lr: 0.001067, loss: 0.4062
2022-09-29 01:14:46 - train: epoch 0118, iter [01120, 01251], lr: 0.001067, loss: 0.4015
2022-09-29 01:15:04 - train: epoch 0118, iter [01130, 01251], lr: 0.001067, loss: 0.4199
2022-09-29 01:15:21 - train: epoch 0118, iter [01140, 01251], lr: 0.001067, loss: 0.4105
2022-09-29 01:15:39 - train: epoch 0118, iter [01150, 01251], lr: 0.001067, loss: 0.4088
2022-09-29 01:15:57 - train: epoch 0118, iter [01160, 01251], lr: 0.001067, loss: 0.4134
2022-09-29 01:16:15 - train: epoch 0118, iter [01170, 01251], lr: 0.001067, loss: 0.4315
2022-09-29 01:16:32 - train: epoch 0118, iter [01180, 01251], lr: 0.001066, loss: 0.4027
2022-09-29 01:16:50 - train: epoch 0118, iter [01190, 01251], lr: 0.001066, loss: 0.4070
2022-09-29 01:17:08 - train: epoch 0118, iter [01200, 01251], lr: 0.001066, loss: 0.3919
2022-09-29 01:17:26 - train: epoch 0118, iter [01210, 01251], lr: 0.001066, loss: 0.4140
2022-09-29 01:17:44 - train: epoch 0118, iter [01220, 01251], lr: 0.001066, loss: 0.4213
2022-09-29 01:18:01 - train: epoch 0118, iter [01230, 01251], lr: 0.001066, loss: 0.4099
2022-09-29 01:18:19 - train: epoch 0118, iter [01240, 01251], lr: 0.001066, loss: 0.4013
2022-09-29 01:18:36 - train: epoch 0118, iter [01250, 01251], lr: 0.001066, loss: 0.4105
2022-09-29 01:18:40 - train: epoch 118, train_loss: 0.4123
2022-09-29 01:18:43 - until epoch: 118, best_loss: 0.4123
2022-09-29 01:18:43 - epoch 119 lr: 0.001066
2022-09-29 01:19:13 - train: epoch 0119, iter [00010, 01251], lr: 0.001066, loss: 0.4258
2022-09-29 01:19:31 - train: epoch 0119, iter [00020, 01251], lr: 0.001066, loss: 0.4227
2022-09-29 01:19:49 - train: epoch 0119, iter [00030, 01251], lr: 0.001066, loss: 0.4055
2022-09-29 01:20:06 - train: epoch 0119, iter [00040, 01251], lr: 0.001066, loss: 0.4053
2022-09-29 01:20:24 - train: epoch 0119, iter [00050, 01251], lr: 0.001066, loss: 0.4207
2022-09-29 01:20:42 - train: epoch 0119, iter [00060, 01251], lr: 0.001066, loss: 0.3972
2022-09-29 01:21:00 - train: epoch 0119, iter [00070, 01251], lr: 0.001066, loss: 0.4175
2022-09-29 01:21:18 - train: epoch 0119, iter [00080, 01251], lr: 0.001066, loss: 0.4374
2022-09-29 01:21:36 - train: epoch 0119, iter [00090, 01251], lr: 0.001066, loss: 0.3898
2022-09-29 01:21:54 - train: epoch 0119, iter [00100, 01251], lr: 0.001066, loss: 0.3984
2022-09-29 01:22:11 - train: epoch 0119, iter [00110, 01251], lr: 0.001066, loss: 0.4083
2022-09-29 01:22:29 - train: epoch 0119, iter [00120, 01251], lr: 0.001066, loss: 0.3954
2022-09-29 01:22:47 - train: epoch 0119, iter [00130, 01251], lr: 0.001066, loss: 0.4115
2022-09-29 01:23:05 - train: epoch 0119, iter [00140, 01251], lr: 0.001066, loss: 0.4243
2022-09-29 01:23:22 - train: epoch 0119, iter [00150, 01251], lr: 0.001066, loss: 0.4059
2022-09-29 01:23:40 - train: epoch 0119, iter [00160, 01251], lr: 0.001066, loss: 0.4005
2022-09-29 01:23:58 - train: epoch 0119, iter [00170, 01251], lr: 0.001066, loss: 0.4247
2022-09-29 01:24:16 - train: epoch 0119, iter [00180, 01251], lr: 0.001066, loss: 0.4114
2022-09-29 01:24:33 - train: epoch 0119, iter [00190, 01251], lr: 0.001066, loss: 0.4054
2022-09-29 01:24:51 - train: epoch 0119, iter [00200, 01251], lr: 0.001066, loss: 0.4149
2022-09-29 01:25:09 - train: epoch 0119, iter [00210, 01251], lr: 0.001066, loss: 0.4049
2022-09-29 01:25:27 - train: epoch 0119, iter [00220, 01251], lr: 0.001066, loss: 0.4085
2022-09-29 01:25:45 - train: epoch 0119, iter [00230, 01251], lr: 0.001066, loss: 0.4014
2022-09-29 01:26:02 - train: epoch 0119, iter [00240, 01251], lr: 0.001066, loss: 0.4058
2022-09-29 01:26:20 - train: epoch 0119, iter [00250, 01251], lr: 0.001066, loss: 0.3915
2022-09-29 01:26:38 - train: epoch 0119, iter [00260, 01251], lr: 0.001066, loss: 0.4243
2022-09-29 01:26:56 - train: epoch 0119, iter [00270, 01251], lr: 0.001066, loss: 0.4330
2022-09-29 01:27:13 - train: epoch 0119, iter [00280, 01251], lr: 0.001066, loss: 0.4202
2022-09-29 01:27:31 - train: epoch 0119, iter [00290, 01251], lr: 0.001066, loss: 0.4175
2022-09-29 01:27:49 - train: epoch 0119, iter [00300, 01251], lr: 0.001065, loss: 0.4134
2022-09-29 01:28:06 - train: epoch 0119, iter [00310, 01251], lr: 0.001065, loss: 0.4085
2022-09-29 01:28:24 - train: epoch 0119, iter [00320, 01251], lr: 0.001065, loss: 0.4131
2022-09-29 01:28:42 - train: epoch 0119, iter [00330, 01251], lr: 0.001065, loss: 0.4176
2022-09-29 01:29:00 - train: epoch 0119, iter [00340, 01251], lr: 0.001065, loss: 0.3829
2022-09-29 01:29:18 - train: epoch 0119, iter [00350, 01251], lr: 0.001065, loss: 0.4023
2022-09-29 01:29:35 - train: epoch 0119, iter [00360, 01251], lr: 0.001065, loss: 0.4003
2022-09-29 01:29:53 - train: epoch 0119, iter [00370, 01251], lr: 0.001065, loss: 0.4223
2022-09-29 01:30:11 - train: epoch 0119, iter [00380, 01251], lr: 0.001065, loss: 0.4098
2022-09-29 01:30:29 - train: epoch 0119, iter [00390, 01251], lr: 0.001065, loss: 0.4433
2022-09-29 01:30:46 - train: epoch 0119, iter [00400, 01251], lr: 0.001065, loss: 0.4104
2022-09-29 01:31:04 - train: epoch 0119, iter [00410, 01251], lr: 0.001065, loss: 0.4046
2022-09-29 01:31:21 - train: epoch 0119, iter [00420, 01251], lr: 0.001065, loss: 0.4074
2022-09-29 01:31:39 - train: epoch 0119, iter [00430, 01251], lr: 0.001065, loss: 0.4284
2022-09-29 01:31:57 - train: epoch 0119, iter [00440, 01251], lr: 0.001065, loss: 0.4148
2022-09-29 01:32:15 - train: epoch 0119, iter [00450, 01251], lr: 0.001065, loss: 0.4206
2022-09-29 01:32:33 - train: epoch 0119, iter [00460, 01251], lr: 0.001065, loss: 0.4016
2022-09-29 01:32:50 - train: epoch 0119, iter [00470, 01251], lr: 0.001065, loss: 0.4225
2022-09-29 01:33:08 - train: epoch 0119, iter [00480, 01251], lr: 0.001065, loss: 0.4164
2022-09-29 01:33:26 - train: epoch 0119, iter [00490, 01251], lr: 0.001065, loss: 0.4158
2022-09-29 01:33:43 - train: epoch 0119, iter [00500, 01251], lr: 0.001065, loss: 0.4166
2022-09-29 01:34:01 - train: epoch 0119, iter [00510, 01251], lr: 0.001065, loss: 0.4237
2022-09-29 01:34:19 - train: epoch 0119, iter [00520, 01251], lr: 0.001065, loss: 0.4027
2022-09-29 01:34:37 - train: epoch 0119, iter [00530, 01251], lr: 0.001065, loss: 0.4238
2022-09-29 01:34:54 - train: epoch 0119, iter [00540, 01251], lr: 0.001065, loss: 0.4114
2022-09-29 01:35:12 - train: epoch 0119, iter [00550, 01251], lr: 0.001065, loss: 0.4051
2022-09-29 01:35:30 - train: epoch 0119, iter [00560, 01251], lr: 0.001065, loss: 0.4276
2022-09-29 01:35:48 - train: epoch 0119, iter [00570, 01251], lr: 0.001065, loss: 0.4347
2022-09-29 01:36:05 - train: epoch 0119, iter [00580, 01251], lr: 0.001065, loss: 0.4225
2022-09-29 01:36:23 - train: epoch 0119, iter [00590, 01251], lr: 0.001065, loss: 0.4204
2022-09-29 01:36:41 - train: epoch 0119, iter [00600, 01251], lr: 0.001065, loss: 0.4295
2022-09-29 01:36:59 - train: epoch 0119, iter [00610, 01251], lr: 0.001065, loss: 0.4348
2022-09-29 01:37:17 - train: epoch 0119, iter [00620, 01251], lr: 0.001065, loss: 0.4194
2022-09-29 01:37:34 - train: epoch 0119, iter [00630, 01251], lr: 0.001065, loss: 0.3928
2022-09-29 01:37:52 - train: epoch 0119, iter [00640, 01251], lr: 0.001065, loss: 0.4137
2022-09-29 01:38:10 - train: epoch 0119, iter [00650, 01251], lr: 0.001065, loss: 0.3995
2022-09-29 01:38:28 - train: epoch 0119, iter [00660, 01251], lr: 0.001065, loss: 0.4144
2022-09-29 01:38:45 - train: epoch 0119, iter [00670, 01251], lr: 0.001065, loss: 0.4122
2022-09-29 01:39:03 - train: epoch 0119, iter [00680, 01251], lr: 0.001064, loss: 0.4212
2022-09-29 01:39:21 - train: epoch 0119, iter [00690, 01251], lr: 0.001064, loss: 0.4107
2022-09-29 01:39:39 - train: epoch 0119, iter [00700, 01251], lr: 0.001064, loss: 0.4168
2022-09-29 01:39:56 - train: epoch 0119, iter [00710, 01251], lr: 0.001064, loss: 0.3965
2022-09-29 01:40:14 - train: epoch 0119, iter [00720, 01251], lr: 0.001064, loss: 0.4199
2022-09-29 01:40:32 - train: epoch 0119, iter [00730, 01251], lr: 0.001064, loss: 0.4302
2022-09-29 01:40:49 - train: epoch 0119, iter [00740, 01251], lr: 0.001064, loss: 0.4192
2022-09-29 01:41:07 - train: epoch 0119, iter [00750, 01251], lr: 0.001064, loss: 0.4237
2022-09-29 01:41:25 - train: epoch 0119, iter [00760, 01251], lr: 0.001064, loss: 0.4138
2022-09-29 01:41:43 - train: epoch 0119, iter [00770, 01251], lr: 0.001064, loss: 0.4088
2022-09-29 01:42:00 - train: epoch 0119, iter [00780, 01251], lr: 0.001064, loss: 0.4134
2022-09-29 01:42:18 - train: epoch 0119, iter [00790, 01251], lr: 0.001064, loss: 0.4159
2022-09-29 01:42:36 - train: epoch 0119, iter [00800, 01251], lr: 0.001064, loss: 0.4096
2022-09-29 01:42:54 - train: epoch 0119, iter [00810, 01251], lr: 0.001064, loss: 0.4250
2022-09-29 01:43:12 - train: epoch 0119, iter [00820, 01251], lr: 0.001064, loss: 0.4105
2022-09-29 01:43:29 - train: epoch 0119, iter [00830, 01251], lr: 0.001064, loss: 0.3945
2022-09-29 01:43:47 - train: epoch 0119, iter [00840, 01251], lr: 0.001064, loss: 0.4202
2022-09-29 01:44:05 - train: epoch 0119, iter [00850, 01251], lr: 0.001064, loss: 0.4172
2022-09-29 01:44:23 - train: epoch 0119, iter [00860, 01251], lr: 0.001064, loss: 0.4110
2022-09-29 01:44:41 - train: epoch 0119, iter [00870, 01251], lr: 0.001064, loss: 0.4044
2022-09-29 01:44:58 - train: epoch 0119, iter [00880, 01251], lr: 0.001064, loss: 0.4055
2022-09-29 01:45:16 - train: epoch 0119, iter [00890, 01251], lr: 0.001064, loss: 0.3930
2022-09-29 01:45:34 - train: epoch 0119, iter [00900, 01251], lr: 0.001064, loss: 0.4170
2022-09-29 01:45:52 - train: epoch 0119, iter [00910, 01251], lr: 0.001064, loss: 0.4195
2022-09-29 01:46:10 - train: epoch 0119, iter [00920, 01251], lr: 0.001064, loss: 0.4233
2022-09-29 01:46:28 - train: epoch 0119, iter [00930, 01251], lr: 0.001064, loss: 0.4089
2022-09-29 01:46:45 - train: epoch 0119, iter [00940, 01251], lr: 0.001064, loss: 0.4278
2022-09-29 01:47:03 - train: epoch 0119, iter [00950, 01251], lr: 0.001064, loss: 0.4080
2022-09-29 01:47:21 - train: epoch 0119, iter [00960, 01251], lr: 0.001064, loss: 0.3937
2022-09-29 01:47:38 - train: epoch 0119, iter [00970, 01251], lr: 0.001064, loss: 0.4032
2022-09-29 01:47:56 - train: epoch 0119, iter [00980, 01251], lr: 0.001064, loss: 0.4156
2022-09-29 01:48:14 - train: epoch 0119, iter [00990, 01251], lr: 0.001064, loss: 0.4089
2022-09-29 01:48:32 - train: epoch 0119, iter [01000, 01251], lr: 0.001064, loss: 0.4080
2022-09-29 01:48:49 - train: epoch 0119, iter [01010, 01251], lr: 0.001064, loss: 0.4302
2022-09-29 01:49:07 - train: epoch 0119, iter [01020, 01251], lr: 0.001064, loss: 0.4113
2022-09-29 01:49:25 - train: epoch 0119, iter [01030, 01251], lr: 0.001064, loss: 0.4004
2022-09-29 01:49:43 - train: epoch 0119, iter [01040, 01251], lr: 0.001064, loss: 0.4192
2022-09-29 01:50:00 - train: epoch 0119, iter [01050, 01251], lr: 0.001064, loss: 0.4253
2022-09-29 01:50:18 - train: epoch 0119, iter [01060, 01251], lr: 0.001063, loss: 0.3998
2022-09-29 01:50:36 - train: epoch 0119, iter [01070, 01251], lr: 0.001063, loss: 0.4302
2022-09-29 01:50:54 - train: epoch 0119, iter [01080, 01251], lr: 0.001063, loss: 0.4104
2022-09-29 01:51:11 - train: epoch 0119, iter [01090, 01251], lr: 0.001063, loss: 0.3909
2022-09-29 01:51:29 - train: epoch 0119, iter [01100, 01251], lr: 0.001063, loss: 0.4270
2022-09-29 01:51:47 - train: epoch 0119, iter [01110, 01251], lr: 0.001063, loss: 0.4207
2022-09-29 01:52:05 - train: epoch 0119, iter [01120, 01251], lr: 0.001063, loss: 0.3971
2022-09-29 01:52:22 - train: epoch 0119, iter [01130, 01251], lr: 0.001063, loss: 0.3998
2022-09-29 01:52:40 - train: epoch 0119, iter [01140, 01251], lr: 0.001063, loss: 0.4051
2022-09-29 01:52:58 - train: epoch 0119, iter [01150, 01251], lr: 0.001063, loss: 0.4201
2022-09-29 01:53:16 - train: epoch 0119, iter [01160, 01251], lr: 0.001063, loss: 0.4194
2022-09-29 01:53:34 - train: epoch 0119, iter [01170, 01251], lr: 0.001063, loss: 0.4098
2022-09-29 01:53:51 - train: epoch 0119, iter [01180, 01251], lr: 0.001063, loss: 0.3980
2022-09-29 01:54:09 - train: epoch 0119, iter [01190, 01251], lr: 0.001063, loss: 0.4142
2022-09-29 01:54:27 - train: epoch 0119, iter [01200, 01251], lr: 0.001063, loss: 0.4120
2022-09-29 01:54:45 - train: epoch 0119, iter [01210, 01251], lr: 0.001063, loss: 0.4266
2022-09-29 01:55:02 - train: epoch 0119, iter [01220, 01251], lr: 0.001063, loss: 0.3975
2022-09-29 01:55:20 - train: epoch 0119, iter [01230, 01251], lr: 0.001063, loss: 0.3965
2022-09-29 01:55:38 - train: epoch 0119, iter [01240, 01251], lr: 0.001063, loss: 0.4124
2022-09-29 01:55:55 - train: epoch 0119, iter [01250, 01251], lr: 0.001063, loss: 0.4039
2022-09-29 01:55:59 - train: epoch 119, train_loss: 0.4122
2022-09-29 01:56:01 - until epoch: 119, best_loss: 0.4122
2022-09-29 01:56:01 - epoch 120 lr: 0.001063
2022-09-29 01:56:34 - train: epoch 0120, iter [00010, 01251], lr: 0.001063, loss: 0.4063
2022-09-29 01:56:52 - train: epoch 0120, iter [00020, 01251], lr: 0.001063, loss: 0.3997
2022-09-29 01:57:10 - train: epoch 0120, iter [00030, 01251], lr: 0.001063, loss: 0.4109
2022-09-29 01:57:27 - train: epoch 0120, iter [00040, 01251], lr: 0.001063, loss: 0.4235
2022-09-29 01:57:45 - train: epoch 0120, iter [00050, 01251], lr: 0.001063, loss: 0.4192
2022-09-29 01:58:03 - train: epoch 0120, iter [00060, 01251], lr: 0.001063, loss: 0.4002
2022-09-29 01:58:20 - train: epoch 0120, iter [00070, 01251], lr: 0.001063, loss: 0.4069
2022-09-29 01:58:38 - train: epoch 0120, iter [00080, 01251], lr: 0.001063, loss: 0.4062
2022-09-29 01:58:56 - train: epoch 0120, iter [00090, 01251], lr: 0.001063, loss: 0.4277
2022-09-29 01:59:14 - train: epoch 0120, iter [00100, 01251], lr: 0.001063, loss: 0.4059
2022-09-29 01:59:31 - train: epoch 0120, iter [00110, 01251], lr: 0.001063, loss: 0.4027
2022-09-29 01:59:49 - train: epoch 0120, iter [00120, 01251], lr: 0.001063, loss: 0.4176
2022-09-29 02:00:07 - train: epoch 0120, iter [00130, 01251], lr: 0.001063, loss: 0.4181
2022-09-29 02:00:25 - train: epoch 0120, iter [00140, 01251], lr: 0.001063, loss: 0.3992
2022-09-29 02:00:42 - train: epoch 0120, iter [00150, 01251], lr: 0.001063, loss: 0.4175
2022-09-29 02:01:00 - train: epoch 0120, iter [00160, 01251], lr: 0.001063, loss: 0.4115
2022-09-29 02:01:17 - train: epoch 0120, iter [00170, 01251], lr: 0.001063, loss: 0.4158
2022-09-29 02:01:35 - train: epoch 0120, iter [00180, 01251], lr: 0.001062, loss: 0.4120
2022-09-29 02:01:53 - train: epoch 0120, iter [00190, 01251], lr: 0.001062, loss: 0.4073
2022-09-29 02:02:11 - train: epoch 0120, iter [00200, 01251], lr: 0.001062, loss: 0.3971
2022-09-29 02:02:28 - train: epoch 0120, iter [00210, 01251], lr: 0.001062, loss: 0.3900
2022-09-29 02:02:46 - train: epoch 0120, iter [00220, 01251], lr: 0.001062, loss: 0.4293
2022-09-29 02:03:04 - train: epoch 0120, iter [00230, 01251], lr: 0.001062, loss: 0.4246
2022-09-29 02:03:22 - train: epoch 0120, iter [00240, 01251], lr: 0.001062, loss: 0.4246
2022-09-29 02:03:39 - train: epoch 0120, iter [00250, 01251], lr: 0.001062, loss: 0.4001
2022-09-29 02:03:57 - train: epoch 0120, iter [00260, 01251], lr: 0.001062, loss: 0.4101
2022-09-29 02:04:15 - train: epoch 0120, iter [00270, 01251], lr: 0.001062, loss: 0.3965
2022-09-29 02:04:32 - train: epoch 0120, iter [00280, 01251], lr: 0.001062, loss: 0.4224
2022-09-29 02:04:50 - train: epoch 0120, iter [00290, 01251], lr: 0.001062, loss: 0.4229
2022-09-29 02:05:08 - train: epoch 0120, iter [00300, 01251], lr: 0.001062, loss: 0.4098
2022-09-29 02:05:25 - train: epoch 0120, iter [00310, 01251], lr: 0.001062, loss: 0.4229
2022-09-29 02:05:43 - train: epoch 0120, iter [00320, 01251], lr: 0.001062, loss: 0.4126
2022-09-29 02:06:01 - train: epoch 0120, iter [00330, 01251], lr: 0.001062, loss: 0.4292
2022-09-29 02:06:19 - train: epoch 0120, iter [00340, 01251], lr: 0.001062, loss: 0.4085
2022-09-29 02:06:36 - train: epoch 0120, iter [00350, 01251], lr: 0.001062, loss: 0.4021
2022-09-29 02:06:54 - train: epoch 0120, iter [00360, 01251], lr: 0.001062, loss: 0.4173
2022-09-29 02:07:11 - train: epoch 0120, iter [00370, 01251], lr: 0.001062, loss: 0.4016
2022-09-29 02:07:29 - train: epoch 0120, iter [00380, 01251], lr: 0.001062, loss: 0.4319
2022-09-29 02:07:47 - train: epoch 0120, iter [00390, 01251], lr: 0.001062, loss: 0.4270
2022-09-29 02:08:05 - train: epoch 0120, iter [00400, 01251], lr: 0.001062, loss: 0.4144
2022-09-29 02:08:22 - train: epoch 0120, iter [00410, 01251], lr: 0.001062, loss: 0.4190
2022-09-29 02:08:40 - train: epoch 0120, iter [00420, 01251], lr: 0.001062, loss: 0.4434
2022-09-29 02:08:57 - train: epoch 0120, iter [00430, 01251], lr: 0.001062, loss: 0.4102
2022-09-29 02:09:15 - train: epoch 0120, iter [00440, 01251], lr: 0.001062, loss: 0.4065
2022-09-29 02:09:33 - train: epoch 0120, iter [00450, 01251], lr: 0.001062, loss: 0.4047
2022-09-29 02:09:50 - train: epoch 0120, iter [00460, 01251], lr: 0.001062, loss: 0.4018
2022-09-29 02:10:08 - train: epoch 0120, iter [00470, 01251], lr: 0.001062, loss: 0.4036
2022-09-29 02:10:26 - train: epoch 0120, iter [00480, 01251], lr: 0.001062, loss: 0.4059
2022-09-29 02:10:44 - train: epoch 0120, iter [00490, 01251], lr: 0.001062, loss: 0.4344
2022-09-29 02:11:01 - train: epoch 0120, iter [00500, 01251], lr: 0.001062, loss: 0.4179
2022-09-29 02:11:19 - train: epoch 0120, iter [00510, 01251], lr: 0.001062, loss: 0.4013
2022-09-29 02:11:37 - train: epoch 0120, iter [00520, 01251], lr: 0.001062, loss: 0.4159
2022-09-29 02:11:55 - train: epoch 0120, iter [00530, 01251], lr: 0.001062, loss: 0.4361
2022-09-29 02:12:12 - train: epoch 0120, iter [00540, 01251], lr: 0.001062, loss: 0.4157
2022-09-29 02:12:30 - train: epoch 0120, iter [00550, 01251], lr: 0.001062, loss: 0.4305
2022-09-29 02:12:48 - train: epoch 0120, iter [00560, 01251], lr: 0.001061, loss: 0.4269
2022-09-29 02:13:06 - train: epoch 0120, iter [00570, 01251], lr: 0.001061, loss: 0.4144
2022-09-29 02:13:23 - train: epoch 0120, iter [00580, 01251], lr: 0.001061, loss: 0.4066
2022-09-29 02:13:41 - train: epoch 0120, iter [00590, 01251], lr: 0.001061, loss: 0.4248
2022-09-29 02:13:58 - train: epoch 0120, iter [00600, 01251], lr: 0.001061, loss: 0.3999
2022-09-29 02:14:16 - train: epoch 0120, iter [00610, 01251], lr: 0.001061, loss: 0.3978
2022-09-29 02:14:34 - train: epoch 0120, iter [00620, 01251], lr: 0.001061, loss: 0.4251
2022-09-29 02:14:51 - train: epoch 0120, iter [00630, 01251], lr: 0.001061, loss: 0.4204
2022-09-29 02:15:09 - train: epoch 0120, iter [00640, 01251], lr: 0.001061, loss: 0.4022
2022-09-29 02:15:27 - train: epoch 0120, iter [00650, 01251], lr: 0.001061, loss: 0.4049
2022-09-29 02:15:44 - train: epoch 0120, iter [00660, 01251], lr: 0.001061, loss: 0.4096
2022-09-29 02:16:02 - train: epoch 0120, iter [00670, 01251], lr: 0.001061, loss: 0.4122
2022-09-29 02:16:20 - train: epoch 0120, iter [00680, 01251], lr: 0.001061, loss: 0.4060
2022-09-29 02:16:37 - train: epoch 0120, iter [00690, 01251], lr: 0.001061, loss: 0.4132
2022-09-29 02:16:55 - train: epoch 0120, iter [00700, 01251], lr: 0.001061, loss: 0.4110
2022-09-29 02:17:13 - train: epoch 0120, iter [00710, 01251], lr: 0.001061, loss: 0.4157
2022-09-29 02:17:30 - train: epoch 0120, iter [00720, 01251], lr: 0.001061, loss: 0.4095
2022-09-29 02:17:48 - train: epoch 0120, iter [00730, 01251], lr: 0.001061, loss: 0.4090
2022-09-29 02:18:06 - train: epoch 0120, iter [00740, 01251], lr: 0.001061, loss: 0.3952
2022-09-29 02:18:24 - train: epoch 0120, iter [00750, 01251], lr: 0.001061, loss: 0.4208
2022-09-29 02:18:41 - train: epoch 0120, iter [00760, 01251], lr: 0.001061, loss: 0.4035
2022-09-29 02:18:59 - train: epoch 0120, iter [00770, 01251], lr: 0.001061, loss: 0.4231
2022-09-29 02:19:17 - train: epoch 0120, iter [00780, 01251], lr: 0.001061, loss: 0.4143
2022-09-29 02:19:34 - train: epoch 0120, iter [00790, 01251], lr: 0.001061, loss: 0.4128
2022-09-29 02:19:52 - train: epoch 0120, iter [00800, 01251], lr: 0.001061, loss: 0.4104
2022-09-29 02:20:10 - train: epoch 0120, iter [00810, 01251], lr: 0.001061, loss: 0.4235
2022-09-29 02:20:28 - train: epoch 0120, iter [00820, 01251], lr: 0.001061, loss: 0.4122
2022-09-29 02:20:45 - train: epoch 0120, iter [00830, 01251], lr: 0.001061, loss: 0.4062
2022-09-29 02:21:03 - train: epoch 0120, iter [00840, 01251], lr: 0.001061, loss: 0.4026
2022-09-29 02:21:21 - train: epoch 0120, iter [00850, 01251], lr: 0.001061, loss: 0.4087
2022-09-29 02:21:38 - train: epoch 0120, iter [00860, 01251], lr: 0.001061, loss: 0.3914
2022-09-29 02:21:56 - train: epoch 0120, iter [00870, 01251], lr: 0.001061, loss: 0.4161
2022-09-29 02:22:14 - train: epoch 0120, iter [00880, 01251], lr: 0.001061, loss: 0.4129
2022-09-29 02:22:31 - train: epoch 0120, iter [00890, 01251], lr: 0.001061, loss: 0.3975
2022-09-29 02:22:49 - train: epoch 0120, iter [00900, 01251], lr: 0.001061, loss: 0.4196
2022-09-29 02:23:07 - train: epoch 0120, iter [00910, 01251], lr: 0.001061, loss: 0.4131
2022-09-29 02:23:24 - train: epoch 0120, iter [00920, 01251], lr: 0.001061, loss: 0.4186
2022-09-29 02:23:42 - train: epoch 0120, iter [00930, 01251], lr: 0.001060, loss: 0.4013
2022-09-29 02:24:00 - train: epoch 0120, iter [00940, 01251], lr: 0.001060, loss: 0.4285
2022-09-29 02:24:18 - train: epoch 0120, iter [00950, 01251], lr: 0.001060, loss: 0.4102
2022-09-29 02:24:35 - train: epoch 0120, iter [00960, 01251], lr: 0.001060, loss: 0.4185
2022-09-29 02:24:53 - train: epoch 0120, iter [00970, 01251], lr: 0.001060, loss: 0.4095
2022-09-29 02:25:11 - train: epoch 0120, iter [00980, 01251], lr: 0.001060, loss: 0.4080
2022-09-29 02:25:29 - train: epoch 0120, iter [00990, 01251], lr: 0.001060, loss: 0.4050
2022-09-29 02:25:47 - train: epoch 0120, iter [01000, 01251], lr: 0.001060, loss: 0.4033
2022-09-29 02:26:04 - train: epoch 0120, iter [01010, 01251], lr: 0.001060, loss: 0.3903
2022-09-29 02:26:22 - train: epoch 0120, iter [01020, 01251], lr: 0.001060, loss: 0.4337
2022-09-29 02:26:40 - train: epoch 0120, iter [01030, 01251], lr: 0.001060, loss: 0.4223
2022-09-29 02:26:57 - train: epoch 0120, iter [01040, 01251], lr: 0.001060, loss: 0.4132
2022-09-29 02:27:15 - train: epoch 0120, iter [01050, 01251], lr: 0.001060, loss: 0.4063
2022-09-29 02:27:33 - train: epoch 0120, iter [01060, 01251], lr: 0.001060, loss: 0.4190
2022-09-29 02:27:51 - train: epoch 0120, iter [01070, 01251], lr: 0.001060, loss: 0.3999
2022-09-29 02:28:08 - train: epoch 0120, iter [01080, 01251], lr: 0.001060, loss: 0.4013
2022-09-29 02:28:26 - train: epoch 0120, iter [01090, 01251], lr: 0.001060, loss: 0.4198
2022-09-29 02:28:44 - train: epoch 0120, iter [01100, 01251], lr: 0.001060, loss: 0.4080
2022-09-29 02:29:02 - train: epoch 0120, iter [01110, 01251], lr: 0.001060, loss: 0.4082
2022-09-29 02:29:19 - train: epoch 0120, iter [01120, 01251], lr: 0.001060, loss: 0.4140
2022-09-29 02:29:37 - train: epoch 0120, iter [01130, 01251], lr: 0.001060, loss: 0.3910
2022-09-29 02:29:55 - train: epoch 0120, iter [01140, 01251], lr: 0.001060, loss: 0.4231
2022-09-29 02:30:12 - train: epoch 0120, iter [01150, 01251], lr: 0.001060, loss: 0.4153
2022-09-29 02:30:30 - train: epoch 0120, iter [01160, 01251], lr: 0.001060, loss: 0.4152
2022-09-29 02:30:48 - train: epoch 0120, iter [01170, 01251], lr: 0.001060, loss: 0.3945
2022-09-29 02:31:06 - train: epoch 0120, iter [01180, 01251], lr: 0.001060, loss: 0.4080
2022-09-29 02:31:23 - train: epoch 0120, iter [01190, 01251], lr: 0.001060, loss: 0.4049
2022-09-29 02:31:41 - train: epoch 0120, iter [01200, 01251], lr: 0.001060, loss: 0.4211
2022-09-29 02:31:59 - train: epoch 0120, iter [01210, 01251], lr: 0.001060, loss: 0.4133
2022-09-29 02:32:17 - train: epoch 0120, iter [01220, 01251], lr: 0.001060, loss: 0.4018
2022-09-29 02:32:34 - train: epoch 0120, iter [01230, 01251], lr: 0.001060, loss: 0.4059
2022-09-29 02:32:52 - train: epoch 0120, iter [01240, 01251], lr: 0.001060, loss: 0.4297
2022-09-29 02:33:09 - train: epoch 0120, iter [01250, 01251], lr: 0.001060, loss: 0.4250
2022-09-29 02:33:13 - train: epoch 120, train_loss: 0.4120
2022-09-29 02:33:15 - until epoch: 120, best_loss: 0.4120
2022-09-29 02:33:15 - epoch 121 lr: 0.001060
2022-09-29 02:33:48 - train: epoch 0121, iter [00010, 01251], lr: 0.001060, loss: 0.4309
2022-09-29 02:34:06 - train: epoch 0121, iter [00020, 01251], lr: 0.001060, loss: 0.4068
2022-09-29 02:34:23 - train: epoch 0121, iter [00030, 01251], lr: 0.001060, loss: 0.4068
2022-09-29 02:34:41 - train: epoch 0121, iter [00040, 01251], lr: 0.001060, loss: 0.4237
2022-09-29 02:34:59 - train: epoch 0121, iter [00050, 01251], lr: 0.001059, loss: 0.4312
2022-09-29 02:35:16 - train: epoch 0121, iter [00060, 01251], lr: 0.001059, loss: 0.4008
2022-09-29 02:35:34 - train: epoch 0121, iter [00070, 01251], lr: 0.001059, loss: 0.4025
2022-09-29 02:35:52 - train: epoch 0121, iter [00080, 01251], lr: 0.001059, loss: 0.3837
2022-09-29 02:36:09 - train: epoch 0121, iter [00090, 01251], lr: 0.001059, loss: 0.4109
2022-09-29 02:36:27 - train: epoch 0121, iter [00100, 01251], lr: 0.001059, loss: 0.4168
2022-09-29 02:36:45 - train: epoch 0121, iter [00110, 01251], lr: 0.001059, loss: 0.4295
2022-09-29 02:37:03 - train: epoch 0121, iter [00120, 01251], lr: 0.001059, loss: 0.4187
2022-09-29 02:37:20 - train: epoch 0121, iter [00130, 01251], lr: 0.001059, loss: 0.4071
2022-09-29 02:37:38 - train: epoch 0121, iter [00140, 01251], lr: 0.001059, loss: 0.4142
2022-09-29 02:37:56 - train: epoch 0121, iter [00150, 01251], lr: 0.001059, loss: 0.4132
2022-09-29 02:38:13 - train: epoch 0121, iter [00160, 01251], lr: 0.001059, loss: 0.3819
2022-09-29 02:38:31 - train: epoch 0121, iter [00170, 01251], lr: 0.001059, loss: 0.4161
2022-09-29 02:38:49 - train: epoch 0121, iter [00180, 01251], lr: 0.001059, loss: 0.4034
2022-09-29 02:39:06 - train: epoch 0121, iter [00190, 01251], lr: 0.001059, loss: 0.4226
2022-09-29 02:39:24 - train: epoch 0121, iter [00200, 01251], lr: 0.001059, loss: 0.4173
2022-09-29 02:39:42 - train: epoch 0121, iter [00210, 01251], lr: 0.001059, loss: 0.4111
2022-09-29 02:40:00 - train: epoch 0121, iter [00220, 01251], lr: 0.001059, loss: 0.4223
2022-09-29 02:40:18 - train: epoch 0121, iter [00230, 01251], lr: 0.001059, loss: 0.4015
2022-09-29 02:40:35 - train: epoch 0121, iter [00240, 01251], lr: 0.001059, loss: 0.4121
2022-09-29 02:40:53 - train: epoch 0121, iter [00250, 01251], lr: 0.001059, loss: 0.4187
2022-09-29 02:41:11 - train: epoch 0121, iter [00260, 01251], lr: 0.001059, loss: 0.4027
2022-09-29 02:41:29 - train: epoch 0121, iter [00270, 01251], lr: 0.001059, loss: 0.4140
2022-09-29 02:41:46 - train: epoch 0121, iter [00280, 01251], lr: 0.001059, loss: 0.4199
2022-09-29 02:42:04 - train: epoch 0121, iter [00290, 01251], lr: 0.001059, loss: 0.4105
2022-09-29 02:42:22 - train: epoch 0121, iter [00300, 01251], lr: 0.001059, loss: 0.4230
2022-09-29 02:42:40 - train: epoch 0121, iter [00310, 01251], lr: 0.001059, loss: 0.4230
2022-09-29 02:42:58 - train: epoch 0121, iter [00320, 01251], lr: 0.001059, loss: 0.4154
2022-09-29 02:43:15 - train: epoch 0121, iter [00330, 01251], lr: 0.001059, loss: 0.4171
2022-09-29 02:43:33 - train: epoch 0121, iter [00340, 01251], lr: 0.001059, loss: 0.4091
2022-09-29 02:43:51 - train: epoch 0121, iter [00350, 01251], lr: 0.001059, loss: 0.4360
2022-09-29 02:44:08 - train: epoch 0121, iter [00360, 01251], lr: 0.001059, loss: 0.4175
2022-09-29 02:44:26 - train: epoch 0121, iter [00370, 01251], lr: 0.001059, loss: 0.4168
2022-09-29 02:44:44 - train: epoch 0121, iter [00380, 01251], lr: 0.001059, loss: 0.4346
2022-09-29 02:45:01 - train: epoch 0121, iter [00390, 01251], lr: 0.001059, loss: 0.4063
2022-09-29 02:45:19 - train: epoch 0121, iter [00400, 01251], lr: 0.001059, loss: 0.4251
2022-09-29 02:45:37 - train: epoch 0121, iter [00410, 01251], lr: 0.001059, loss: 0.4231
2022-09-29 02:45:55 - train: epoch 0121, iter [00420, 01251], lr: 0.001058, loss: 0.4139
2022-09-29 02:46:12 - train: epoch 0121, iter [00430, 01251], lr: 0.001058, loss: 0.4065
2022-09-29 02:46:30 - train: epoch 0121, iter [00440, 01251], lr: 0.001058, loss: 0.4147
2022-09-29 02:46:48 - train: epoch 0121, iter [00450, 01251], lr: 0.001058, loss: 0.4108
2022-09-29 02:47:05 - train: epoch 0121, iter [00460, 01251], lr: 0.001058, loss: 0.4113
2022-09-29 02:47:23 - train: epoch 0121, iter [00470, 01251], lr: 0.001058, loss: 0.4274
2022-09-29 02:47:41 - train: epoch 0121, iter [00480, 01251], lr: 0.001058, loss: 0.4074
2022-09-29 02:47:58 - train: epoch 0121, iter [00490, 01251], lr: 0.001058, loss: 0.4165
2022-09-29 02:48:16 - train: epoch 0121, iter [00500, 01251], lr: 0.001058, loss: 0.4098
2022-09-29 02:48:34 - train: epoch 0121, iter [00510, 01251], lr: 0.001058, loss: 0.4195
2022-09-29 02:48:52 - train: epoch 0121, iter [00520, 01251], lr: 0.001058, loss: 0.4160
2022-09-29 02:49:09 - train: epoch 0121, iter [00530, 01251], lr: 0.001058, loss: 0.4259
2022-09-29 02:49:27 - train: epoch 0121, iter [00540, 01251], lr: 0.001058, loss: 0.4065
2022-09-29 02:49:45 - train: epoch 0121, iter [00550, 01251], lr: 0.001058, loss: 0.3912
2022-09-29 02:50:02 - train: epoch 0121, iter [00560, 01251], lr: 0.001058, loss: 0.4284
2022-09-29 02:50:20 - train: epoch 0121, iter [00570, 01251], lr: 0.001058, loss: 0.4187
2022-09-29 02:50:38 - train: epoch 0121, iter [00580, 01251], lr: 0.001058, loss: 0.4063
2022-09-29 02:50:56 - train: epoch 0121, iter [00590, 01251], lr: 0.001058, loss: 0.4279
2022-09-29 02:51:14 - train: epoch 0121, iter [00600, 01251], lr: 0.001058, loss: 0.4108
2022-09-29 02:51:31 - train: epoch 0121, iter [00610, 01251], lr: 0.001058, loss: 0.4235
2022-09-29 02:51:49 - train: epoch 0121, iter [00620, 01251], lr: 0.001058, loss: 0.4211
2022-09-29 02:52:07 - train: epoch 0121, iter [00630, 01251], lr: 0.001058, loss: 0.4055
2022-09-29 02:52:24 - train: epoch 0121, iter [00640, 01251], lr: 0.001058, loss: 0.4225
2022-09-29 02:52:42 - train: epoch 0121, iter [00650, 01251], lr: 0.001058, loss: 0.3962
2022-09-29 02:53:00 - train: epoch 0121, iter [00660, 01251], lr: 0.001058, loss: 0.4033
2022-09-29 02:53:17 - train: epoch 0121, iter [00670, 01251], lr: 0.001058, loss: 0.3989
2022-09-29 02:53:35 - train: epoch 0121, iter [00680, 01251], lr: 0.001058, loss: 0.4213
2022-09-29 02:53:53 - train: epoch 0121, iter [00690, 01251], lr: 0.001058, loss: 0.3973
2022-09-29 02:54:11 - train: epoch 0121, iter [00700, 01251], lr: 0.001058, loss: 0.4015
2022-09-29 02:54:28 - train: epoch 0121, iter [00710, 01251], lr: 0.001058, loss: 0.4048
2022-09-29 02:54:46 - train: epoch 0121, iter [00720, 01251], lr: 0.001058, loss: 0.3988
2022-09-29 02:55:04 - train: epoch 0121, iter [00730, 01251], lr: 0.001058, loss: 0.4073
2022-09-29 02:55:22 - train: epoch 0121, iter [00740, 01251], lr: 0.001058, loss: 0.3842
2022-09-29 02:55:40 - train: epoch 0121, iter [00750, 01251], lr: 0.001058, loss: 0.4090
2022-09-29 02:55:57 - train: epoch 0121, iter [00760, 01251], lr: 0.001058, loss: 0.4185
2022-09-29 02:56:15 - train: epoch 0121, iter [00770, 01251], lr: 0.001058, loss: 0.4141
2022-09-29 02:56:33 - train: epoch 0121, iter [00780, 01251], lr: 0.001058, loss: 0.4100
2022-09-29 02:56:50 - train: epoch 0121, iter [00790, 01251], lr: 0.001057, loss: 0.3908
2022-09-29 02:57:08 - train: epoch 0121, iter [00800, 01251], lr: 0.001057, loss: 0.4308
2022-09-29 02:57:26 - train: epoch 0121, iter [00810, 01251], lr: 0.001057, loss: 0.3969
2022-09-29 02:57:43 - train: epoch 0121, iter [00820, 01251], lr: 0.001057, loss: 0.4158
2022-09-29 02:58:01 - train: epoch 0121, iter [00830, 01251], lr: 0.001057, loss: 0.4106
2022-09-29 02:58:19 - train: epoch 0121, iter [00840, 01251], lr: 0.001057, loss: 0.4242
2022-09-29 02:58:36 - train: epoch 0121, iter [00850, 01251], lr: 0.001057, loss: 0.4143
2022-09-29 02:58:54 - train: epoch 0121, iter [00860, 01251], lr: 0.001057, loss: 0.4279
2022-09-29 02:59:11 - train: epoch 0121, iter [00870, 01251], lr: 0.001057, loss: 0.4067
2022-09-29 02:59:29 - train: epoch 0121, iter [00880, 01251], lr: 0.001057, loss: 0.3972
2022-09-29 02:59:47 - train: epoch 0121, iter [00890, 01251], lr: 0.001057, loss: 0.4140
2022-09-29 03:00:05 - train: epoch 0121, iter [00900, 01251], lr: 0.001057, loss: 0.4250
2022-09-29 03:00:23 - train: epoch 0121, iter [00910, 01251], lr: 0.001057, loss: 0.4135
2022-09-29 03:00:40 - train: epoch 0121, iter [00920, 01251], lr: 0.001057, loss: 0.3976
2022-09-29 03:00:58 - train: epoch 0121, iter [00930, 01251], lr: 0.001057, loss: 0.4120
2022-09-29 03:01:16 - train: epoch 0121, iter [00940, 01251], lr: 0.001057, loss: 0.4117
2022-09-29 03:01:33 - train: epoch 0121, iter [00950, 01251], lr: 0.001057, loss: 0.3958
2022-09-29 03:01:51 - train: epoch 0121, iter [00960, 01251], lr: 0.001057, loss: 0.4053
2022-09-29 03:02:09 - train: epoch 0121, iter [00970, 01251], lr: 0.001057, loss: 0.4173
2022-09-29 03:02:27 - train: epoch 0121, iter [00980, 01251], lr: 0.001057, loss: 0.4040
2022-09-29 03:02:44 - train: epoch 0121, iter [00990, 01251], lr: 0.001057, loss: 0.4194
2022-09-29 03:03:02 - train: epoch 0121, iter [01000, 01251], lr: 0.001057, loss: 0.4062
2022-09-29 03:03:20 - train: epoch 0121, iter [01010, 01251], lr: 0.001057, loss: 0.4129
2022-09-29 03:03:38 - train: epoch 0121, iter [01020, 01251], lr: 0.001057, loss: 0.4195
2022-09-29 03:03:55 - train: epoch 0121, iter [01030, 01251], lr: 0.001057, loss: 0.4224
2022-09-29 03:04:13 - train: epoch 0121, iter [01040, 01251], lr: 0.001057, loss: 0.3902
2022-09-29 03:04:31 - train: epoch 0121, iter [01050, 01251], lr: 0.001057, loss: 0.4067
2022-09-29 03:04:49 - train: epoch 0121, iter [01060, 01251], lr: 0.001057, loss: 0.4054
2022-09-29 03:05:06 - train: epoch 0121, iter [01070, 01251], lr: 0.001057, loss: 0.4021
2022-09-29 03:05:24 - train: epoch 0121, iter [01080, 01251], lr: 0.001057, loss: 0.4198
2022-09-29 03:05:42 - train: epoch 0121, iter [01090, 01251], lr: 0.001057, loss: 0.4093
2022-09-29 03:06:00 - train: epoch 0121, iter [01100, 01251], lr: 0.001057, loss: 0.4104
2022-09-29 03:06:17 - train: epoch 0121, iter [01110, 01251], lr: 0.001057, loss: 0.4211
2022-09-29 03:06:35 - train: epoch 0121, iter [01120, 01251], lr: 0.001057, loss: 0.4030
2022-09-29 03:06:52 - train: epoch 0121, iter [01130, 01251], lr: 0.001057, loss: 0.4219
2022-09-29 03:07:10 - train: epoch 0121, iter [01140, 01251], lr: 0.001057, loss: 0.4074
2022-09-29 03:07:28 - train: epoch 0121, iter [01150, 01251], lr: 0.001057, loss: 0.4105
2022-09-29 03:07:46 - train: epoch 0121, iter [01160, 01251], lr: 0.001056, loss: 0.3955
2022-09-29 03:08:04 - train: epoch 0121, iter [01170, 01251], lr: 0.001056, loss: 0.4154
2022-09-29 03:08:21 - train: epoch 0121, iter [01180, 01251], lr: 0.001056, loss: 0.4151
2022-09-29 03:08:39 - train: epoch 0121, iter [01190, 01251], lr: 0.001056, loss: 0.4375
2022-09-29 03:08:57 - train: epoch 0121, iter [01200, 01251], lr: 0.001056, loss: 0.4115
2022-09-29 03:09:14 - train: epoch 0121, iter [01210, 01251], lr: 0.001056, loss: 0.4126
2022-09-29 03:09:32 - train: epoch 0121, iter [01220, 01251], lr: 0.001056, loss: 0.4196
2022-09-29 03:09:50 - train: epoch 0121, iter [01230, 01251], lr: 0.001056, loss: 0.4134
2022-09-29 03:10:07 - train: epoch 0121, iter [01240, 01251], lr: 0.001056, loss: 0.4108
2022-09-29 03:10:25 - train: epoch 0121, iter [01250, 01251], lr: 0.001056, loss: 0.4251
2022-09-29 03:10:29 - train: epoch 121, train_loss: 0.4122
2022-09-29 03:10:30 - until epoch: 121, best_loss: 0.4120
2022-09-29 03:10:30 - epoch 122 lr: 0.001056
2022-09-29 03:11:02 - train: epoch 0122, iter [00010, 01251], lr: 0.001056, loss: 0.4111
2022-09-29 03:11:20 - train: epoch 0122, iter [00020, 01251], lr: 0.001056, loss: 0.4127
2022-09-29 03:11:38 - train: epoch 0122, iter [00030, 01251], lr: 0.001056, loss: 0.4022
2022-09-29 03:11:55 - train: epoch 0122, iter [00040, 01251], lr: 0.001056, loss: 0.4291
2022-09-29 03:12:13 - train: epoch 0122, iter [00050, 01251], lr: 0.001056, loss: 0.4041
2022-09-29 03:12:31 - train: epoch 0122, iter [00060, 01251], lr: 0.001056, loss: 0.4310
2022-09-29 03:12:49 - train: epoch 0122, iter [00070, 01251], lr: 0.001056, loss: 0.3971
2022-09-29 03:13:06 - train: epoch 0122, iter [00080, 01251], lr: 0.001056, loss: 0.4242
2022-09-29 03:13:24 - train: epoch 0122, iter [00090, 01251], lr: 0.001056, loss: 0.4224
2022-09-29 03:13:42 - train: epoch 0122, iter [00100, 01251], lr: 0.001056, loss: 0.3967
2022-09-29 03:14:00 - train: epoch 0122, iter [00110, 01251], lr: 0.001056, loss: 0.4203
2022-09-29 03:14:17 - train: epoch 0122, iter [00120, 01251], lr: 0.001056, loss: 0.4063
2022-09-29 03:14:35 - train: epoch 0122, iter [00130, 01251], lr: 0.001056, loss: 0.4237
2022-09-29 03:14:53 - train: epoch 0122, iter [00140, 01251], lr: 0.001056, loss: 0.4252
2022-09-29 03:15:11 - train: epoch 0122, iter [00150, 01251], lr: 0.001056, loss: 0.4099
2022-09-29 03:15:28 - train: epoch 0122, iter [00160, 01251], lr: 0.001056, loss: 0.3859
2022-09-29 03:15:46 - train: epoch 0122, iter [00170, 01251], lr: 0.001056, loss: 0.4137
2022-09-29 03:16:04 - train: epoch 0122, iter [00180, 01251], lr: 0.001056, loss: 0.4012
2022-09-29 03:16:22 - train: epoch 0122, iter [00190, 01251], lr: 0.001056, loss: 0.3916
2022-09-29 03:16:39 - train: epoch 0122, iter [00200, 01251], lr: 0.001056, loss: 0.4229
2022-09-29 03:16:57 - train: epoch 0122, iter [00210, 01251], lr: 0.001056, loss: 0.4064
2022-09-29 03:17:15 - train: epoch 0122, iter [00220, 01251], lr: 0.001056, loss: 0.4093
2022-09-29 03:17:32 - train: epoch 0122, iter [00230, 01251], lr: 0.001056, loss: 0.3985
2022-09-29 03:17:50 - train: epoch 0122, iter [00240, 01251], lr: 0.001056, loss: 0.4146
2022-09-29 03:18:08 - train: epoch 0122, iter [00250, 01251], lr: 0.001056, loss: 0.4117
2022-09-29 03:18:25 - train: epoch 0122, iter [00260, 01251], lr: 0.001056, loss: 0.4154
2022-09-29 03:18:43 - train: epoch 0122, iter [00270, 01251], lr: 0.001056, loss: 0.4206
2022-09-29 03:19:01 - train: epoch 0122, iter [00280, 01251], lr: 0.001055, loss: 0.4305
2022-09-29 03:19:19 - train: epoch 0122, iter [00290, 01251], lr: 0.001055, loss: 0.4041
2022-09-29 03:19:36 - train: epoch 0122, iter [00300, 01251], lr: 0.001055, loss: 0.4111
2022-09-29 03:19:54 - train: epoch 0122, iter [00310, 01251], lr: 0.001055, loss: 0.4129
2022-09-29 03:20:11 - train: epoch 0122, iter [00320, 01251], lr: 0.001055, loss: 0.4127
2022-09-29 03:20:29 - train: epoch 0122, iter [00330, 01251], lr: 0.001055, loss: 0.4262
2022-09-29 03:20:47 - train: epoch 0122, iter [00340, 01251], lr: 0.001055, loss: 0.4265
2022-09-29 03:21:05 - train: epoch 0122, iter [00350, 01251], lr: 0.001055, loss: 0.4230
2022-09-29 03:21:23 - train: epoch 0122, iter [00360, 01251], lr: 0.001055, loss: 0.4183
2022-09-29 03:21:40 - train: epoch 0122, iter [00370, 01251], lr: 0.001055, loss: 0.4127
2022-09-29 03:21:58 - train: epoch 0122, iter [00380, 01251], lr: 0.001055, loss: 0.3999
2022-09-29 03:22:16 - train: epoch 0122, iter [00390, 01251], lr: 0.001055, loss: 0.4305
2022-09-29 03:22:34 - train: epoch 0122, iter [00400, 01251], lr: 0.001055, loss: 0.4258
2022-09-29 03:22:51 - train: epoch 0122, iter [00410, 01251], lr: 0.001055, loss: 0.4276
2022-09-29 03:23:09 - train: epoch 0122, iter [00420, 01251], lr: 0.001055, loss: 0.4165
2022-09-29 03:23:26 - train: epoch 0122, iter [00430, 01251], lr: 0.001055, loss: 0.4058
2022-09-29 03:23:44 - train: epoch 0122, iter [00440, 01251], lr: 0.001055, loss: 0.4169
2022-09-29 03:24:02 - train: epoch 0122, iter [00450, 01251], lr: 0.001055, loss: 0.4247
2022-09-29 03:24:20 - train: epoch 0122, iter [00460, 01251], lr: 0.001055, loss: 0.3995
2022-09-29 03:24:37 - train: epoch 0122, iter [00470, 01251], lr: 0.001055, loss: 0.4299
2022-09-29 03:24:55 - train: epoch 0122, iter [00480, 01251], lr: 0.001055, loss: 0.4086
2022-09-29 03:25:13 - train: epoch 0122, iter [00490, 01251], lr: 0.001055, loss: 0.4208
2022-09-29 03:25:30 - train: epoch 0122, iter [00500, 01251], lr: 0.001055, loss: 0.3967
2022-09-29 03:25:48 - train: epoch 0122, iter [00510, 01251], lr: 0.001055, loss: 0.4189
2022-09-29 03:26:06 - train: epoch 0122, iter [00520, 01251], lr: 0.001055, loss: 0.3982
2022-09-29 03:26:24 - train: epoch 0122, iter [00530, 01251], lr: 0.001055, loss: 0.4153
2022-09-29 03:26:41 - train: epoch 0122, iter [00540, 01251], lr: 0.001055, loss: 0.4221
2022-09-29 03:26:59 - train: epoch 0122, iter [00550, 01251], lr: 0.001055, loss: 0.4275
2022-09-29 03:27:17 - train: epoch 0122, iter [00560, 01251], lr: 0.001055, loss: 0.4087
2022-09-29 03:27:35 - train: epoch 0122, iter [00570, 01251], lr: 0.001055, loss: 0.4080
2022-09-29 03:27:52 - train: epoch 0122, iter [00580, 01251], lr: 0.001055, loss: 0.4061
2022-09-29 03:28:10 - train: epoch 0122, iter [00590, 01251], lr: 0.001055, loss: 0.4153
2022-09-29 03:28:27 - train: epoch 0122, iter [00600, 01251], lr: 0.001055, loss: 0.4254
2022-09-29 03:28:45 - train: epoch 0122, iter [00610, 01251], lr: 0.001055, loss: 0.4038
2022-09-29 03:29:03 - train: epoch 0122, iter [00620, 01251], lr: 0.001055, loss: 0.4100
2022-09-29 03:29:21 - train: epoch 0122, iter [00630, 01251], lr: 0.001055, loss: 0.3997
2022-09-29 03:29:38 - train: epoch 0122, iter [00640, 01251], lr: 0.001054, loss: 0.4145
2022-09-29 03:29:56 - train: epoch 0122, iter [00650, 01251], lr: 0.001054, loss: 0.4164
2022-09-29 03:30:14 - train: epoch 0122, iter [00660, 01251], lr: 0.001054, loss: 0.3979
2022-09-29 03:30:32 - train: epoch 0122, iter [00670, 01251], lr: 0.001054, loss: 0.4085
2022-09-29 03:30:49 - train: epoch 0122, iter [00680, 01251], lr: 0.001054, loss: 0.4171
2022-09-29 03:31:07 - train: epoch 0122, iter [00690, 01251], lr: 0.001054, loss: 0.4115
2022-09-29 03:31:25 - train: epoch 0122, iter [00700, 01251], lr: 0.001054, loss: 0.3971
2022-09-29 03:31:42 - train: epoch 0122, iter [00710, 01251], lr: 0.001054, loss: 0.4314
2022-09-29 03:32:00 - train: epoch 0122, iter [00720, 01251], lr: 0.001054, loss: 0.4149
2022-09-29 03:32:18 - train: epoch 0122, iter [00730, 01251], lr: 0.001054, loss: 0.4079
2022-09-29 03:32:36 - train: epoch 0122, iter [00740, 01251], lr: 0.001054, loss: 0.4008
2022-09-29 03:32:53 - train: epoch 0122, iter [00750, 01251], lr: 0.001054, loss: 0.4098
2022-09-29 03:33:11 - train: epoch 0122, iter [00760, 01251], lr: 0.001054, loss: 0.4103
2022-09-29 03:33:29 - train: epoch 0122, iter [00770, 01251], lr: 0.001054, loss: 0.4184
2022-09-29 03:33:47 - train: epoch 0122, iter [00780, 01251], lr: 0.001054, loss: 0.4060
2022-09-29 03:34:04 - train: epoch 0122, iter [00790, 01251], lr: 0.001054, loss: 0.4382
2022-09-29 03:34:22 - train: epoch 0122, iter [00800, 01251], lr: 0.001054, loss: 0.4177
2022-09-29 03:34:40 - train: epoch 0122, iter [00810, 01251], lr: 0.001054, loss: 0.3970
2022-09-29 03:34:58 - train: epoch 0122, iter [00820, 01251], lr: 0.001054, loss: 0.4091
2022-09-29 03:35:15 - train: epoch 0122, iter [00830, 01251], lr: 0.001054, loss: 0.4123
2022-09-29 03:35:33 - train: epoch 0122, iter [00840, 01251], lr: 0.001054, loss: 0.4221
2022-09-29 03:35:51 - train: epoch 0122, iter [00850, 01251], lr: 0.001054, loss: 0.4158
2022-09-29 03:36:09 - train: epoch 0122, iter [00860, 01251], lr: 0.001054, loss: 0.4099
2022-09-29 03:36:26 - train: epoch 0122, iter [00870, 01251], lr: 0.001054, loss: 0.4141
2022-09-29 03:36:44 - train: epoch 0122, iter [00880, 01251], lr: 0.001054, loss: 0.4177
2022-09-29 03:37:02 - train: epoch 0122, iter [00890, 01251], lr: 0.001054, loss: 0.4383
2022-09-29 03:37:19 - train: epoch 0122, iter [00900, 01251], lr: 0.001054, loss: 0.3889
2022-09-29 03:37:37 - train: epoch 0122, iter [00910, 01251], lr: 0.001054, loss: 0.3937
2022-09-29 03:37:55 - train: epoch 0122, iter [00920, 01251], lr: 0.001054, loss: 0.4146
2022-09-29 03:38:13 - train: epoch 0122, iter [00930, 01251], lr: 0.001054, loss: 0.4246
2022-09-29 03:38:30 - train: epoch 0122, iter [00940, 01251], lr: 0.001054, loss: 0.4132
2022-09-29 03:38:48 - train: epoch 0122, iter [00950, 01251], lr: 0.001054, loss: 0.4079
2022-09-29 03:39:06 - train: epoch 0122, iter [00960, 01251], lr: 0.001054, loss: 0.4282
2022-09-29 03:39:24 - train: epoch 0122, iter [00970, 01251], lr: 0.001054, loss: 0.4164
2022-09-29 03:39:42 - train: epoch 0122, iter [00980, 01251], lr: 0.001054, loss: 0.3974
2022-09-29 03:39:59 - train: epoch 0122, iter [00990, 01251], lr: 0.001054, loss: 0.3985
2022-09-29 03:40:17 - train: epoch 0122, iter [01000, 01251], lr: 0.001054, loss: 0.4208
2022-09-29 03:40:35 - train: epoch 0122, iter [01010, 01251], lr: 0.001053, loss: 0.4105
2022-09-29 03:40:53 - train: epoch 0122, iter [01020, 01251], lr: 0.001053, loss: 0.4151
2022-09-29 03:41:10 - train: epoch 0122, iter [01030, 01251], lr: 0.001053, loss: 0.4293
2022-09-29 03:41:28 - train: epoch 0122, iter [01040, 01251], lr: 0.001053, loss: 0.3989
2022-09-29 03:41:46 - train: epoch 0122, iter [01050, 01251], lr: 0.001053, loss: 0.4089
2022-09-29 03:42:04 - train: epoch 0122, iter [01060, 01251], lr: 0.001053, loss: 0.4346
2022-09-29 03:42:21 - train: epoch 0122, iter [01070, 01251], lr: 0.001053, loss: 0.4014
2022-09-29 03:42:39 - train: epoch 0122, iter [01080, 01251], lr: 0.001053, loss: 0.4062
2022-09-29 03:42:56 - train: epoch 0122, iter [01090, 01251], lr: 0.001053, loss: 0.4213
2022-09-29 03:43:14 - train: epoch 0122, iter [01100, 01251], lr: 0.001053, loss: 0.3931
2022-09-29 03:43:32 - train: epoch 0122, iter [01110, 01251], lr: 0.001053, loss: 0.4116
2022-09-29 03:43:50 - train: epoch 0122, iter [01120, 01251], lr: 0.001053, loss: 0.3926
2022-09-29 03:44:08 - train: epoch 0122, iter [01130, 01251], lr: 0.001053, loss: 0.4176
2022-09-29 03:44:25 - train: epoch 0122, iter [01140, 01251], lr: 0.001053, loss: 0.4024
2022-09-29 03:44:43 - train: epoch 0122, iter [01150, 01251], lr: 0.001053, loss: 0.3965
2022-09-29 03:45:01 - train: epoch 0122, iter [01160, 01251], lr: 0.001053, loss: 0.4278
2022-09-29 03:45:18 - train: epoch 0122, iter [01170, 01251], lr: 0.001053, loss: 0.4093
2022-09-29 03:45:36 - train: epoch 0122, iter [01180, 01251], lr: 0.001053, loss: 0.4030
2022-09-29 03:45:54 - train: epoch 0122, iter [01190, 01251], lr: 0.001053, loss: 0.3989
2022-09-29 03:46:12 - train: epoch 0122, iter [01200, 01251], lr: 0.001053, loss: 0.4140
2022-09-29 03:46:30 - train: epoch 0122, iter [01210, 01251], lr: 0.001053, loss: 0.4284
2022-09-29 03:46:47 - train: epoch 0122, iter [01220, 01251], lr: 0.001053, loss: 0.3933
2022-09-29 03:47:05 - train: epoch 0122, iter [01230, 01251], lr: 0.001053, loss: 0.4073
2022-09-29 03:47:23 - train: epoch 0122, iter [01240, 01251], lr: 0.001053, loss: 0.4110
2022-09-29 03:47:40 - train: epoch 0122, iter [01250, 01251], lr: 0.001053, loss: 0.4209
2022-09-29 03:47:43 - train: epoch 122, train_loss: 0.4121
2022-09-29 03:47:45 - until epoch: 122, best_loss: 0.4120
2022-09-29 03:47:45 - epoch 123 lr: 0.001053
2022-09-29 03:48:18 - train: epoch 0123, iter [00010, 01251], lr: 0.001053, loss: 0.4278
2022-09-29 03:48:36 - train: epoch 0123, iter [00020, 01251], lr: 0.001053, loss: 0.4288
2022-09-29 03:48:53 - train: epoch 0123, iter [00030, 01251], lr: 0.001053, loss: 0.4084
2022-09-29 03:49:11 - train: epoch 0123, iter [00040, 01251], lr: 0.001053, loss: 0.3951
2022-09-29 03:49:29 - train: epoch 0123, iter [00050, 01251], lr: 0.001053, loss: 0.4215
2022-09-29 03:49:47 - train: epoch 0123, iter [00060, 01251], lr: 0.001053, loss: 0.4168
2022-09-29 03:50:04 - train: epoch 0123, iter [00070, 01251], lr: 0.001053, loss: 0.4085
2022-09-29 03:50:22 - train: epoch 0123, iter [00080, 01251], lr: 0.001053, loss: 0.4233
2022-09-29 03:50:40 - train: epoch 0123, iter [00090, 01251], lr: 0.001053, loss: 0.4029
2022-09-29 03:50:57 - train: epoch 0123, iter [00100, 01251], lr: 0.001053, loss: 0.4118
2022-09-29 03:51:15 - train: epoch 0123, iter [00110, 01251], lr: 0.001053, loss: 0.4056
2022-09-29 03:51:33 - train: epoch 0123, iter [00120, 01251], lr: 0.001052, loss: 0.4294
2022-09-29 03:51:50 - train: epoch 0123, iter [00130, 01251], lr: 0.001052, loss: 0.4308
2022-09-29 03:52:08 - train: epoch 0123, iter [00140, 01251], lr: 0.001052, loss: 0.4292
2022-09-29 03:52:26 - train: epoch 0123, iter [00150, 01251], lr: 0.001052, loss: 0.4152
2022-09-29 03:52:43 - train: epoch 0123, iter [00160, 01251], lr: 0.001052, loss: 0.4163
2022-09-29 03:53:01 - train: epoch 0123, iter [00170, 01251], lr: 0.001052, loss: 0.4113
2022-09-29 03:53:19 - train: epoch 0123, iter [00180, 01251], lr: 0.001052, loss: 0.4380
2022-09-29 03:53:37 - train: epoch 0123, iter [00190, 01251], lr: 0.001052, loss: 0.4122
2022-09-29 03:53:54 - train: epoch 0123, iter [00200, 01251], lr: 0.001052, loss: 0.4211
2022-09-29 03:54:12 - train: epoch 0123, iter [00210, 01251], lr: 0.001052, loss: 0.4252
2022-09-29 03:54:29 - train: epoch 0123, iter [00220, 01251], lr: 0.001052, loss: 0.4412
2022-09-29 03:54:47 - train: epoch 0123, iter [00230, 01251], lr: 0.001052, loss: 0.4292
2022-09-29 03:55:05 - train: epoch 0123, iter [00240, 01251], lr: 0.001052, loss: 0.4030
2022-09-29 03:55:23 - train: epoch 0123, iter [00250, 01251], lr: 0.001052, loss: 0.4046
2022-09-29 03:55:40 - train: epoch 0123, iter [00260, 01251], lr: 0.001052, loss: 0.4213
2022-09-29 03:55:58 - train: epoch 0123, iter [00270, 01251], lr: 0.001052, loss: 0.4080
2022-09-29 03:56:16 - train: epoch 0123, iter [00280, 01251], lr: 0.001052, loss: 0.4093
2022-09-29 03:56:33 - train: epoch 0123, iter [00290, 01251], lr: 0.001052, loss: 0.3892
2022-09-29 03:56:51 - train: epoch 0123, iter [00300, 01251], lr: 0.001052, loss: 0.4098
2022-09-29 03:57:09 - train: epoch 0123, iter [00310, 01251], lr: 0.001052, loss: 0.4144
2022-09-29 03:57:27 - train: epoch 0123, iter [00320, 01251], lr: 0.001052, loss: 0.3989
2022-09-29 03:57:44 - train: epoch 0123, iter [00330, 01251], lr: 0.001052, loss: 0.3977
2022-09-29 03:58:02 - train: epoch 0123, iter [00340, 01251], lr: 0.001052, loss: 0.4267
2022-09-29 03:58:20 - train: epoch 0123, iter [00350, 01251], lr: 0.001052, loss: 0.4238
2022-09-29 03:58:37 - train: epoch 0123, iter [00360, 01251], lr: 0.001052, loss: 0.4296
2022-09-29 03:58:55 - train: epoch 0123, iter [00370, 01251], lr: 0.001052, loss: 0.4159
2022-09-29 03:59:13 - train: epoch 0123, iter [00380, 01251], lr: 0.001052, loss: 0.3983
2022-09-29 03:59:31 - train: epoch 0123, iter [00390, 01251], lr: 0.001052, loss: 0.4190
2022-09-29 03:59:48 - train: epoch 0123, iter [00400, 01251], lr: 0.001052, loss: 0.4135
2022-09-29 04:00:06 - train: epoch 0123, iter [00410, 01251], lr: 0.001052, loss: 0.4001
2022-09-29 04:00:24 - train: epoch 0123, iter [00420, 01251], lr: 0.001052, loss: 0.4176
2022-09-29 04:00:42 - train: epoch 0123, iter [00430, 01251], lr: 0.001052, loss: 0.4146
2022-09-29 04:00:59 - train: epoch 0123, iter [00440, 01251], lr: 0.001052, loss: 0.4156
2022-09-29 04:01:17 - train: epoch 0123, iter [00450, 01251], lr: 0.001052, loss: 0.4290
2022-09-29 04:01:34 - train: epoch 0123, iter [00460, 01251], lr: 0.001052, loss: 0.4190
2022-09-29 04:01:52 - train: epoch 0123, iter [00470, 01251], lr: 0.001052, loss: 0.4080
2022-09-29 04:02:10 - train: epoch 0123, iter [00480, 01251], lr: 0.001052, loss: 0.4072
2022-09-29 04:02:28 - train: epoch 0123, iter [00490, 01251], lr: 0.001051, loss: 0.4154
2022-09-29 04:02:45 - train: epoch 0123, iter [00500, 01251], lr: 0.001051, loss: 0.4011
2022-09-29 04:03:03 - train: epoch 0123, iter [00510, 01251], lr: 0.001051, loss: 0.4089
2022-09-29 04:03:21 - train: epoch 0123, iter [00520, 01251], lr: 0.001051, loss: 0.4031
2022-09-29 04:03:38 - train: epoch 0123, iter [00530, 01251], lr: 0.001051, loss: 0.4048
2022-09-29 04:03:56 - train: epoch 0123, iter [00540, 01251], lr: 0.001051, loss: 0.4050
2022-09-29 04:04:14 - train: epoch 0123, iter [00550, 01251], lr: 0.001051, loss: 0.3942
2022-09-29 04:04:31 - train: epoch 0123, iter [00560, 01251], lr: 0.001051, loss: 0.4187
2022-09-29 04:04:49 - train: epoch 0123, iter [00570, 01251], lr: 0.001051, loss: 0.4126
2022-09-29 04:05:07 - train: epoch 0123, iter [00580, 01251], lr: 0.001051, loss: 0.4300
2022-09-29 04:05:25 - train: epoch 0123, iter [00590, 01251], lr: 0.001051, loss: 0.4239
2022-09-29 04:05:42 - train: epoch 0123, iter [00600, 01251], lr: 0.001051, loss: 0.4035
2022-09-29 04:06:00 - train: epoch 0123, iter [00610, 01251], lr: 0.001051, loss: 0.4183
2022-09-29 04:06:18 - train: epoch 0123, iter [00620, 01251], lr: 0.001051, loss: 0.4081
2022-09-29 04:06:35 - train: epoch 0123, iter [00630, 01251], lr: 0.001051, loss: 0.4172
2022-09-29 04:06:53 - train: epoch 0123, iter [00640, 01251], lr: 0.001051, loss: 0.4043
2022-09-29 04:07:11 - train: epoch 0123, iter [00650, 01251], lr: 0.001051, loss: 0.4152
2022-09-29 04:07:28 - train: epoch 0123, iter [00660, 01251], lr: 0.001051, loss: 0.4279
2022-09-29 04:07:46 - train: epoch 0123, iter [00670, 01251], lr: 0.001051, loss: 0.3923
2022-09-29 04:08:04 - train: epoch 0123, iter [00680, 01251], lr: 0.001051, loss: 0.4197
2022-09-29 04:08:21 - train: epoch 0123, iter [00690, 01251], lr: 0.001051, loss: 0.4210
2022-09-29 04:08:39 - train: epoch 0123, iter [00700, 01251], lr: 0.001051, loss: 0.4221
2022-09-29 04:08:57 - train: epoch 0123, iter [00710, 01251], lr: 0.001051, loss: 0.4141
2022-09-29 04:09:14 - train: epoch 0123, iter [00720, 01251], lr: 0.001051, loss: 0.4285
2022-09-29 04:09:32 - train: epoch 0123, iter [00730, 01251], lr: 0.001051, loss: 0.4093
2022-09-29 04:09:50 - train: epoch 0123, iter [00740, 01251], lr: 0.001051, loss: 0.4181
2022-09-29 04:10:08 - train: epoch 0123, iter [00750, 01251], lr: 0.001051, loss: 0.4038
2022-09-29 04:10:25 - train: epoch 0123, iter [00760, 01251], lr: 0.001051, loss: 0.4288
2022-09-29 04:10:43 - train: epoch 0123, iter [00770, 01251], lr: 0.001051, loss: 0.4053
2022-09-29 04:11:01 - train: epoch 0123, iter [00780, 01251], lr: 0.001051, loss: 0.4107
2022-09-29 04:11:19 - train: epoch 0123, iter [00790, 01251], lr: 0.001051, loss: 0.4048
2022-09-29 04:11:36 - train: epoch 0123, iter [00800, 01251], lr: 0.001051, loss: 0.4133
2022-09-29 04:11:54 - train: epoch 0123, iter [00810, 01251], lr: 0.001051, loss: 0.4068
2022-09-29 04:12:12 - train: epoch 0123, iter [00820, 01251], lr: 0.001051, loss: 0.4127
2022-09-29 04:12:29 - train: epoch 0123, iter [00830, 01251], lr: 0.001051, loss: 0.4265
2022-09-29 04:12:47 - train: epoch 0123, iter [00840, 01251], lr: 0.001051, loss: 0.4138
2022-09-29 04:13:05 - train: epoch 0123, iter [00850, 01251], lr: 0.001050, loss: 0.3965
2022-09-29 04:13:22 - train: epoch 0123, iter [00860, 01251], lr: 0.001050, loss: 0.3923
2022-09-29 04:13:40 - train: epoch 0123, iter [00870, 01251], lr: 0.001050, loss: 0.4179
2022-09-29 04:13:58 - train: epoch 0123, iter [00880, 01251], lr: 0.001050, loss: 0.3917
2022-09-29 04:14:16 - train: epoch 0123, iter [00890, 01251], lr: 0.001050, loss: 0.4136
2022-09-29 04:14:33 - train: epoch 0123, iter [00900, 01251], lr: 0.001050, loss: 0.3936
2022-09-29 04:14:51 - train: epoch 0123, iter [00910, 01251], lr: 0.001050, loss: 0.4080
2022-09-29 04:15:09 - train: epoch 0123, iter [00920, 01251], lr: 0.001050, loss: 0.4187
2022-09-29 04:15:27 - train: epoch 0123, iter [00930, 01251], lr: 0.001050, loss: 0.4320
2022-09-29 04:15:44 - train: epoch 0123, iter [00940, 01251], lr: 0.001050, loss: 0.4131
2022-09-29 04:16:02 - train: epoch 0123, iter [00950, 01251], lr: 0.001050, loss: 0.4113
2022-09-29 04:16:20 - train: epoch 0123, iter [00960, 01251], lr: 0.001050, loss: 0.4182
2022-09-29 04:16:38 - train: epoch 0123, iter [00970, 01251], lr: 0.001050, loss: 0.3929
2022-09-29 04:16:55 - train: epoch 0123, iter [00980, 01251], lr: 0.001050, loss: 0.4131
2022-09-29 04:17:13 - train: epoch 0123, iter [00990, 01251], lr: 0.001050, loss: 0.4020
2022-09-29 04:17:31 - train: epoch 0123, iter [01000, 01251], lr: 0.001050, loss: 0.4028
2022-09-29 04:17:49 - train: epoch 0123, iter [01010, 01251], lr: 0.001050, loss: 0.3998
2022-09-29 04:18:06 - train: epoch 0123, iter [01020, 01251], lr: 0.001050, loss: 0.4027
2022-09-29 04:18:24 - train: epoch 0123, iter [01030, 01251], lr: 0.001050, loss: 0.4244
2022-09-29 04:18:42 - train: epoch 0123, iter [01040, 01251], lr: 0.001050, loss: 0.4310
2022-09-29 04:19:00 - train: epoch 0123, iter [01050, 01251], lr: 0.001050, loss: 0.4125
2022-09-29 04:19:18 - train: epoch 0123, iter [01060, 01251], lr: 0.001050, loss: 0.3986
2022-09-29 04:19:35 - train: epoch 0123, iter [01070, 01251], lr: 0.001050, loss: 0.3988
2022-09-29 04:19:53 - train: epoch 0123, iter [01080, 01251], lr: 0.001050, loss: 0.4242
2022-09-29 04:20:11 - train: epoch 0123, iter [01090, 01251], lr: 0.001050, loss: 0.4255
2022-09-29 04:20:28 - train: epoch 0123, iter [01100, 01251], lr: 0.001050, loss: 0.4046
2022-09-29 04:20:46 - train: epoch 0123, iter [01110, 01251], lr: 0.001050, loss: 0.4250
2022-09-29 04:21:04 - train: epoch 0123, iter [01120, 01251], lr: 0.001050, loss: 0.4091
2022-09-29 04:21:22 - train: epoch 0123, iter [01130, 01251], lr: 0.001050, loss: 0.4280
2022-09-29 04:21:39 - train: epoch 0123, iter [01140, 01251], lr: 0.001050, loss: 0.4206
2022-09-29 04:21:57 - train: epoch 0123, iter [01150, 01251], lr: 0.001050, loss: 0.4307
2022-09-29 04:22:15 - train: epoch 0123, iter [01160, 01251], lr: 0.001050, loss: 0.4184
2022-09-29 04:22:33 - train: epoch 0123, iter [01170, 01251], lr: 0.001050, loss: 0.4114
2022-09-29 04:22:50 - train: epoch 0123, iter [01180, 01251], lr: 0.001050, loss: 0.4071
2022-09-29 04:23:08 - train: epoch 0123, iter [01190, 01251], lr: 0.001050, loss: 0.4206
2022-09-29 04:23:26 - train: epoch 0123, iter [01200, 01251], lr: 0.001050, loss: 0.4102
2022-09-29 04:23:44 - train: epoch 0123, iter [01210, 01251], lr: 0.001049, loss: 0.3821
2022-09-29 04:24:01 - train: epoch 0123, iter [01220, 01251], lr: 0.001049, loss: 0.4386
2022-09-29 04:24:19 - train: epoch 0123, iter [01230, 01251], lr: 0.001049, loss: 0.4154
2022-09-29 04:24:37 - train: epoch 0123, iter [01240, 01251], lr: 0.001049, loss: 0.4055
2022-09-29 04:24:54 - train: epoch 0123, iter [01250, 01251], lr: 0.001049, loss: 0.4258
2022-09-29 04:24:58 - train: epoch 123, train_loss: 0.4121
2022-09-29 04:24:59 - until epoch: 123, best_loss: 0.4120
2022-09-29 04:24:59 - epoch 124 lr: 0.001049
2022-09-29 04:25:32 - train: epoch 0124, iter [00010, 01251], lr: 0.001049, loss: 0.4098
2022-09-29 04:25:50 - train: epoch 0124, iter [00020, 01251], lr: 0.001049, loss: 0.4030
2022-09-29 04:26:07 - train: epoch 0124, iter [00030, 01251], lr: 0.001049, loss: 0.4483
2022-09-29 04:26:25 - train: epoch 0124, iter [00040, 01251], lr: 0.001049, loss: 0.4140
2022-09-29 04:26:43 - train: epoch 0124, iter [00050, 01251], lr: 0.001049, loss: 0.4111
2022-09-29 04:27:01 - train: epoch 0124, iter [00060, 01251], lr: 0.001049, loss: 0.3976
2022-09-29 04:27:18 - train: epoch 0124, iter [00070, 01251], lr: 0.001049, loss: 0.4030
2022-09-29 04:27:36 - train: epoch 0124, iter [00080, 01251], lr: 0.001049, loss: 0.4134
2022-09-29 04:27:54 - train: epoch 0124, iter [00090, 01251], lr: 0.001049, loss: 0.4363
2022-09-29 04:28:12 - train: epoch 0124, iter [00100, 01251], lr: 0.001049, loss: 0.4059
2022-09-29 04:28:29 - train: epoch 0124, iter [00110, 01251], lr: 0.001049, loss: 0.4145
2022-09-29 04:28:47 - train: epoch 0124, iter [00120, 01251], lr: 0.001049, loss: 0.4029
2022-09-29 04:29:05 - train: epoch 0124, iter [00130, 01251], lr: 0.001049, loss: 0.3990
2022-09-29 04:29:23 - train: epoch 0124, iter [00140, 01251], lr: 0.001049, loss: 0.4189
2022-09-29 04:29:41 - train: epoch 0124, iter [00150, 01251], lr: 0.001049, loss: 0.4102
2022-09-29 04:29:59 - train: epoch 0124, iter [00160, 01251], lr: 0.001049, loss: 0.4101
2022-09-29 04:30:16 - train: epoch 0124, iter [00170, 01251], lr: 0.001049, loss: 0.4267
2022-09-29 04:30:34 - train: epoch 0124, iter [00180, 01251], lr: 0.001049, loss: 0.4109
2022-09-29 04:30:52 - train: epoch 0124, iter [00190, 01251], lr: 0.001049, loss: 0.4050
2022-09-29 04:31:09 - train: epoch 0124, iter [00200, 01251], lr: 0.001049, loss: 0.4124
2022-09-29 04:31:27 - train: epoch 0124, iter [00210, 01251], lr: 0.001049, loss: 0.4151
2022-09-29 04:31:45 - train: epoch 0124, iter [00220, 01251], lr: 0.001049, loss: 0.4149
2022-09-29 04:32:03 - train: epoch 0124, iter [00230, 01251], lr: 0.001049, loss: 0.4332
2022-09-29 04:32:20 - train: epoch 0124, iter [00240, 01251], lr: 0.001049, loss: 0.4285
2022-09-29 04:32:38 - train: epoch 0124, iter [00250, 01251], lr: 0.001049, loss: 0.4157
2022-09-29 04:32:56 - train: epoch 0124, iter [00260, 01251], lr: 0.001049, loss: 0.4184
2022-09-29 04:33:14 - train: epoch 0124, iter [00270, 01251], lr: 0.001049, loss: 0.4107
2022-09-29 04:33:32 - train: epoch 0124, iter [00280, 01251], lr: 0.001049, loss: 0.4177
2022-09-29 04:33:49 - train: epoch 0124, iter [00290, 01251], lr: 0.001049, loss: 0.4219
2022-09-29 04:34:07 - train: epoch 0124, iter [00300, 01251], lr: 0.001049, loss: 0.4198
2022-09-29 04:34:25 - train: epoch 0124, iter [00310, 01251], lr: 0.001049, loss: 0.4152
2022-09-29 04:34:43 - train: epoch 0124, iter [00320, 01251], lr: 0.001048, loss: 0.4194
2022-09-29 04:35:01 - train: epoch 0124, iter [00330, 01251], lr: 0.001048, loss: 0.4027
2022-09-29 04:35:18 - train: epoch 0124, iter [00340, 01251], lr: 0.001048, loss: 0.4076
2022-09-29 04:35:36 - train: epoch 0124, iter [00350, 01251], lr: 0.001048, loss: 0.4214
2022-09-29 04:35:54 - train: epoch 0124, iter [00360, 01251], lr: 0.001048, loss: 0.4275
2022-09-29 04:36:12 - train: epoch 0124, iter [00370, 01251], lr: 0.001048, loss: 0.4171
2022-09-29 04:36:29 - train: epoch 0124, iter [00380, 01251], lr: 0.001048, loss: 0.4223
2022-09-29 04:36:47 - train: epoch 0124, iter [00390, 01251], lr: 0.001048, loss: 0.4078
2022-09-29 04:37:05 - train: epoch 0124, iter [00400, 01251], lr: 0.001048, loss: 0.4410
2022-09-29 04:37:22 - train: epoch 0124, iter [00410, 01251], lr: 0.001048, loss: 0.4290
2022-09-29 04:37:40 - train: epoch 0124, iter [00420, 01251], lr: 0.001048, loss: 0.4123
2022-09-29 04:37:58 - train: epoch 0124, iter [00430, 01251], lr: 0.001048, loss: 0.4088
2022-09-29 04:38:16 - train: epoch 0124, iter [00440, 01251], lr: 0.001048, loss: 0.4140
2022-09-29 04:38:33 - train: epoch 0124, iter [00450, 01251], lr: 0.001048, loss: 0.3953
2022-09-29 04:38:51 - train: epoch 0124, iter [00460, 01251], lr: 0.001048, loss: 0.3958
2022-09-29 04:39:09 - train: epoch 0124, iter [00470, 01251], lr: 0.001048, loss: 0.4261
2022-09-29 04:39:27 - train: epoch 0124, iter [00480, 01251], lr: 0.001048, loss: 0.4106
2022-09-29 04:39:44 - train: epoch 0124, iter [00490, 01251], lr: 0.001048, loss: 0.4137
2022-09-29 04:40:02 - train: epoch 0124, iter [00500, 01251], lr: 0.001048, loss: 0.4225
2022-09-29 04:40:19 - train: epoch 0124, iter [00510, 01251], lr: 0.001048, loss: 0.4103
2022-09-29 04:40:37 - train: epoch 0124, iter [00520, 01251], lr: 0.001048, loss: 0.4083
2022-09-29 04:40:55 - train: epoch 0124, iter [00530, 01251], lr: 0.001048, loss: 0.4185
2022-09-29 04:41:13 - train: epoch 0124, iter [00540, 01251], lr: 0.001048, loss: 0.3977
2022-09-29 04:41:30 - train: epoch 0124, iter [00550, 01251], lr: 0.001048, loss: 0.4162
2022-09-29 04:41:48 - train: epoch 0124, iter [00560, 01251], lr: 0.001048, loss: 0.4069
2022-09-29 04:42:06 - train: epoch 0124, iter [00570, 01251], lr: 0.001048, loss: 0.4099
2022-09-29 04:42:23 - train: epoch 0124, iter [00580, 01251], lr: 0.001048, loss: 0.4074
2022-09-29 04:42:41 - train: epoch 0124, iter [00590, 01251], lr: 0.001048, loss: 0.4016
2022-09-29 04:42:59 - train: epoch 0124, iter [00600, 01251], lr: 0.001048, loss: 0.4139
2022-09-29 04:43:17 - train: epoch 0124, iter [00610, 01251], lr: 0.001048, loss: 0.3972
2022-09-29 04:43:34 - train: epoch 0124, iter [00620, 01251], lr: 0.001048, loss: 0.4063
2022-09-29 04:43:52 - train: epoch 0124, iter [00630, 01251], lr: 0.001048, loss: 0.4134
2022-09-29 04:44:10 - train: epoch 0124, iter [00640, 01251], lr: 0.001048, loss: 0.4045
2022-09-29 04:44:28 - train: epoch 0124, iter [00650, 01251], lr: 0.001048, loss: 0.4324
2022-09-29 04:44:45 - train: epoch 0124, iter [00660, 01251], lr: 0.001048, loss: 0.4210
2022-09-29 04:45:03 - train: epoch 0124, iter [00670, 01251], lr: 0.001048, loss: 0.4140
2022-09-29 04:45:21 - train: epoch 0124, iter [00680, 01251], lr: 0.001047, loss: 0.4025
2022-09-29 04:45:38 - train: epoch 0124, iter [00690, 01251], lr: 0.001047, loss: 0.4257
2022-09-29 04:45:56 - train: epoch 0124, iter [00700, 01251], lr: 0.001047, loss: 0.4258
2022-09-29 04:46:14 - train: epoch 0124, iter [00710, 01251], lr: 0.001047, loss: 0.3927
2022-09-29 04:46:32 - train: epoch 0124, iter [00720, 01251], lr: 0.001047, loss: 0.4220
2022-09-29 04:46:49 - train: epoch 0124, iter [00730, 01251], lr: 0.001047, loss: 0.4129
2022-09-29 04:47:07 - train: epoch 0124, iter [00740, 01251], lr: 0.001047, loss: 0.3953
2022-09-29 04:47:25 - train: epoch 0124, iter [00750, 01251], lr: 0.001047, loss: 0.4245
2022-09-29 04:47:42 - train: epoch 0124, iter [00760, 01251], lr: 0.001047, loss: 0.4014
2022-09-29 04:48:00 - train: epoch 0124, iter [00770, 01251], lr: 0.001047, loss: 0.4129
2022-09-29 04:48:18 - train: epoch 0124, iter [00780, 01251], lr: 0.001047, loss: 0.4220
2022-09-29 04:48:36 - train: epoch 0124, iter [00790, 01251], lr: 0.001047, loss: 0.4047
2022-09-29 04:48:54 - train: epoch 0124, iter [00800, 01251], lr: 0.001047, loss: 0.4138
2022-09-29 04:49:11 - train: epoch 0124, iter [00810, 01251], lr: 0.001047, loss: 0.3992
2022-09-29 04:49:29 - train: epoch 0124, iter [00820, 01251], lr: 0.001047, loss: 0.4190
2022-09-29 04:49:47 - train: epoch 0124, iter [00830, 01251], lr: 0.001047, loss: 0.4041
2022-09-29 04:50:05 - train: epoch 0124, iter [00840, 01251], lr: 0.001047, loss: 0.3888
2022-09-29 04:50:22 - train: epoch 0124, iter [00850, 01251], lr: 0.001047, loss: 0.4148
2022-09-29 04:50:40 - train: epoch 0124, iter [00860, 01251], lr: 0.001047, loss: 0.4243
2022-09-29 04:50:58 - train: epoch 0124, iter [00870, 01251], lr: 0.001047, loss: 0.4027
2022-09-29 04:51:16 - train: epoch 0124, iter [00880, 01251], lr: 0.001047, loss: 0.4034
2022-09-29 04:51:33 - train: epoch 0124, iter [00890, 01251], lr: 0.001047, loss: 0.3996
2022-09-29 04:51:51 - train: epoch 0124, iter [00900, 01251], lr: 0.001047, loss: 0.4022
2022-09-29 04:52:09 - train: epoch 0124, iter [00910, 01251], lr: 0.001047, loss: 0.4129
2022-09-29 04:52:27 - train: epoch 0124, iter [00920, 01251], lr: 0.001047, loss: 0.3859
2022-09-29 04:52:44 - train: epoch 0124, iter [00930, 01251], lr: 0.001047, loss: 0.4083
2022-09-29 04:53:02 - train: epoch 0124, iter [00940, 01251], lr: 0.001047, loss: 0.4153
2022-09-29 04:53:20 - train: epoch 0124, iter [00950, 01251], lr: 0.001047, loss: 0.4073
2022-09-29 04:53:37 - train: epoch 0124, iter [00960, 01251], lr: 0.001047, loss: 0.4081
2022-09-29 04:53:55 - train: epoch 0124, iter [00970, 01251], lr: 0.001047, loss: 0.4133
2022-09-29 04:54:13 - train: epoch 0124, iter [00980, 01251], lr: 0.001047, loss: 0.3802
2022-09-29 04:54:31 - train: epoch 0124, iter [00990, 01251], lr: 0.001047, loss: 0.4017
2022-09-29 04:54:48 - train: epoch 0124, iter [01000, 01251], lr: 0.001047, loss: 0.4136
2022-09-29 04:55:06 - train: epoch 0124, iter [01010, 01251], lr: 0.001047, loss: 0.3980
2022-09-29 04:55:24 - train: epoch 0124, iter [01020, 01251], lr: 0.001047, loss: 0.4218
2022-09-29 04:55:41 - train: epoch 0124, iter [01030, 01251], lr: 0.001047, loss: 0.4176
2022-09-29 04:55:59 - train: epoch 0124, iter [01040, 01251], lr: 0.001046, loss: 0.4135
2022-09-29 04:56:17 - train: epoch 0124, iter [01050, 01251], lr: 0.001046, loss: 0.4121
2022-09-29 04:56:34 - train: epoch 0124, iter [01060, 01251], lr: 0.001046, loss: 0.4060
2022-09-29 04:56:52 - train: epoch 0124, iter [01070, 01251], lr: 0.001046, loss: 0.4162
2022-09-29 04:57:10 - train: epoch 0124, iter [01080, 01251], lr: 0.001046, loss: 0.4267
2022-09-29 04:57:27 - train: epoch 0124, iter [01090, 01251], lr: 0.001046, loss: 0.4219
2022-09-29 04:57:45 - train: epoch 0124, iter [01100, 01251], lr: 0.001046, loss: 0.4147
2022-09-29 04:58:03 - train: epoch 0124, iter [01110, 01251], lr: 0.001046, loss: 0.4279
2022-09-29 04:58:21 - train: epoch 0124, iter [01120, 01251], lr: 0.001046, loss: 0.4101
2022-09-29 04:58:39 - train: epoch 0124, iter [01130, 01251], lr: 0.001046, loss: 0.4075
2022-09-29 04:58:56 - train: epoch 0124, iter [01140, 01251], lr: 0.001046, loss: 0.4156
2022-09-29 04:59:14 - train: epoch 0124, iter [01150, 01251], lr: 0.001046, loss: 0.4258
2022-09-29 04:59:31 - train: epoch 0124, iter [01160, 01251], lr: 0.001046, loss: 0.4249
2022-09-29 04:59:49 - train: epoch 0124, iter [01170, 01251], lr: 0.001046, loss: 0.4280
2022-09-29 05:00:07 - train: epoch 0124, iter [01180, 01251], lr: 0.001046, loss: 0.4240
2022-09-29 05:00:25 - train: epoch 0124, iter [01190, 01251], lr: 0.001046, loss: 0.4026
2022-09-29 05:00:42 - train: epoch 0124, iter [01200, 01251], lr: 0.001046, loss: 0.4224
2022-09-29 05:01:00 - train: epoch 0124, iter [01210, 01251], lr: 0.001046, loss: 0.4084
2022-09-29 05:01:18 - train: epoch 0124, iter [01220, 01251], lr: 0.001046, loss: 0.4040
2022-09-29 05:01:36 - train: epoch 0124, iter [01230, 01251], lr: 0.001046, loss: 0.4139
2022-09-29 05:01:53 - train: epoch 0124, iter [01240, 01251], lr: 0.001046, loss: 0.4098
2022-09-29 05:02:11 - train: epoch 0124, iter [01250, 01251], lr: 0.001046, loss: 0.4051
2022-09-29 05:02:15 - train: epoch 124, train_loss: 0.4118
2022-09-29 05:02:17 - until epoch: 124, best_loss: 0.4118
2022-09-29 05:02:17 - epoch 125 lr: 0.001046
2022-09-29 05:02:49 - train: epoch 0125, iter [00010, 01251], lr: 0.001046, loss: 0.4211
2022-09-29 05:03:07 - train: epoch 0125, iter [00020, 01251], lr: 0.001046, loss: 0.4213
2022-09-29 05:03:25 - train: epoch 0125, iter [00030, 01251], lr: 0.001046, loss: 0.4126
2022-09-29 05:03:43 - train: epoch 0125, iter [00040, 01251], lr: 0.001046, loss: 0.4064
2022-09-29 05:04:00 - train: epoch 0125, iter [00050, 01251], lr: 0.001046, loss: 0.4037
2022-09-29 05:04:18 - train: epoch 0125, iter [00060, 01251], lr: 0.001046, loss: 0.3973
2022-09-29 05:04:35 - train: epoch 0125, iter [00070, 01251], lr: 0.001046, loss: 0.4076
2022-09-29 05:04:53 - train: epoch 0125, iter [00080, 01251], lr: 0.001046, loss: 0.4059
2022-09-29 05:05:11 - train: epoch 0125, iter [00090, 01251], lr: 0.001046, loss: 0.4196
2022-09-29 05:05:29 - train: epoch 0125, iter [00100, 01251], lr: 0.001046, loss: 0.4033
2022-09-29 05:05:47 - train: epoch 0125, iter [00110, 01251], lr: 0.001046, loss: 0.4046
2022-09-29 05:06:04 - train: epoch 0125, iter [00120, 01251], lr: 0.001046, loss: 0.4078
2022-09-29 05:06:22 - train: epoch 0125, iter [00130, 01251], lr: 0.001046, loss: 0.3975
2022-09-29 05:06:40 - train: epoch 0125, iter [00140, 01251], lr: 0.001045, loss: 0.4207
2022-09-29 05:06:57 - train: epoch 0125, iter [00150, 01251], lr: 0.001045, loss: 0.4165
2022-09-29 05:07:15 - train: epoch 0125, iter [00160, 01251], lr: 0.001045, loss: 0.4169
2022-09-29 05:07:33 - train: epoch 0125, iter [00170, 01251], lr: 0.001045, loss: 0.4180
2022-09-29 05:07:50 - train: epoch 0125, iter [00180, 01251], lr: 0.001045, loss: 0.4302
2022-09-29 05:08:08 - train: epoch 0125, iter [00190, 01251], lr: 0.001045, loss: 0.3994
2022-09-29 05:08:26 - train: epoch 0125, iter [00200, 01251], lr: 0.001045, loss: 0.4218
2022-09-29 05:08:43 - train: epoch 0125, iter [00210, 01251], lr: 0.001045, loss: 0.3991
2022-09-29 05:09:01 - train: epoch 0125, iter [00220, 01251], lr: 0.001045, loss: 0.4033
2022-09-29 05:09:19 - train: epoch 0125, iter [00230, 01251], lr: 0.001045, loss: 0.3977
2022-09-29 05:09:37 - train: epoch 0125, iter [00240, 01251], lr: 0.001045, loss: 0.4254
2022-09-29 05:09:55 - train: epoch 0125, iter [00250, 01251], lr: 0.001045, loss: 0.3941
2022-09-29 05:10:12 - train: epoch 0125, iter [00260, 01251], lr: 0.001045, loss: 0.4036
2022-09-29 05:10:30 - train: epoch 0125, iter [00270, 01251], lr: 0.001045, loss: 0.4137
2022-09-29 05:10:48 - train: epoch 0125, iter [00280, 01251], lr: 0.001045, loss: 0.4165
2022-09-29 05:11:05 - train: epoch 0125, iter [00290, 01251], lr: 0.001045, loss: 0.3878
2022-09-29 05:11:23 - train: epoch 0125, iter [00300, 01251], lr: 0.001045, loss: 0.4156
2022-09-29 05:11:41 - train: epoch 0125, iter [00310, 01251], lr: 0.001045, loss: 0.4031
2022-09-29 05:11:59 - train: epoch 0125, iter [00320, 01251], lr: 0.001045, loss: 0.3793
2022-09-29 05:12:16 - train: epoch 0125, iter [00330, 01251], lr: 0.001045, loss: 0.4126
2022-09-29 05:12:34 - train: epoch 0125, iter [00340, 01251], lr: 0.001045, loss: 0.4114
2022-09-29 05:12:52 - train: epoch 0125, iter [00350, 01251], lr: 0.001045, loss: 0.4161
2022-09-29 05:13:10 - train: epoch 0125, iter [00360, 01251], lr: 0.001045, loss: 0.4179
2022-09-29 05:13:27 - train: epoch 0125, iter [00370, 01251], lr: 0.001045, loss: 0.4103
2022-09-29 05:13:45 - train: epoch 0125, iter [00380, 01251], lr: 0.001045, loss: 0.4083
2022-09-29 05:14:03 - train: epoch 0125, iter [00390, 01251], lr: 0.001045, loss: 0.4012
2022-09-29 05:14:21 - train: epoch 0125, iter [00400, 01251], lr: 0.001045, loss: 0.4017
2022-09-29 05:14:38 - train: epoch 0125, iter [00410, 01251], lr: 0.001045, loss: 0.4020
2022-09-29 05:14:56 - train: epoch 0125, iter [00420, 01251], lr: 0.001045, loss: 0.4194
2022-09-29 05:15:13 - train: epoch 0125, iter [00430, 01251], lr: 0.001045, loss: 0.4217
2022-09-29 05:15:31 - train: epoch 0125, iter [00440, 01251], lr: 0.001045, loss: 0.4192
2022-09-29 05:15:49 - train: epoch 0125, iter [00450, 01251], lr: 0.001045, loss: 0.4061
2022-09-29 05:16:06 - train: epoch 0125, iter [00460, 01251], lr: 0.001045, loss: 0.4164
2022-09-29 05:16:24 - train: epoch 0125, iter [00470, 01251], lr: 0.001045, loss: 0.4013
2022-09-29 05:16:42 - train: epoch 0125, iter [00480, 01251], lr: 0.001045, loss: 0.3922
2022-09-29 05:17:00 - train: epoch 0125, iter [00490, 01251], lr: 0.001045, loss: 0.4016
2022-09-29 05:17:17 - train: epoch 0125, iter [00500, 01251], lr: 0.001044, loss: 0.4195
2022-09-29 05:17:35 - train: epoch 0125, iter [00510, 01251], lr: 0.001044, loss: 0.4197
2022-09-29 05:17:53 - train: epoch 0125, iter [00520, 01251], lr: 0.001044, loss: 0.4060
2022-09-29 05:18:10 - train: epoch 0125, iter [00530, 01251], lr: 0.001044, loss: 0.4105
2022-09-29 05:18:28 - train: epoch 0125, iter [00540, 01251], lr: 0.001044, loss: 0.4245
2022-09-29 05:18:46 - train: epoch 0125, iter [00550, 01251], lr: 0.001044, loss: 0.4093
2022-09-29 05:19:03 - train: epoch 0125, iter [00560, 01251], lr: 0.001044, loss: 0.3888
2022-09-29 05:19:21 - train: epoch 0125, iter [00570, 01251], lr: 0.001044, loss: 0.4051
2022-09-29 05:19:39 - train: epoch 0125, iter [00580, 01251], lr: 0.001044, loss: 0.4218
2022-09-29 05:19:57 - train: epoch 0125, iter [00590, 01251], lr: 0.001044, loss: 0.4130
2022-09-29 05:20:14 - train: epoch 0125, iter [00600, 01251], lr: 0.001044, loss: 0.4183
2022-09-29 05:20:32 - train: epoch 0125, iter [00610, 01251], lr: 0.001044, loss: 0.4170
2022-09-29 05:20:50 - train: epoch 0125, iter [00620, 01251], lr: 0.001044, loss: 0.4221
2022-09-29 05:21:08 - train: epoch 0125, iter [00630, 01251], lr: 0.001044, loss: 0.4044
2022-09-29 05:21:25 - train: epoch 0125, iter [00640, 01251], lr: 0.001044, loss: 0.4344
2022-09-29 05:21:43 - train: epoch 0125, iter [00650, 01251], lr: 0.001044, loss: 0.4217
2022-09-29 05:22:01 - train: epoch 0125, iter [00660, 01251], lr: 0.001044, loss: 0.4062
2022-09-29 05:22:18 - train: epoch 0125, iter [00670, 01251], lr: 0.001044, loss: 0.3935
2022-09-29 05:22:36 - train: epoch 0125, iter [00680, 01251], lr: 0.001044, loss: 0.3986
2022-09-29 05:22:54 - train: epoch 0125, iter [00690, 01251], lr: 0.001044, loss: 0.3986
2022-09-29 05:23:12 - train: epoch 0125, iter [00700, 01251], lr: 0.001044, loss: 0.4260
2022-09-29 05:23:29 - train: epoch 0125, iter [00710, 01251], lr: 0.001044, loss: 0.4285
2022-09-29 05:23:47 - train: epoch 0125, iter [00720, 01251], lr: 0.001044, loss: 0.4142
2022-09-29 05:24:05 - train: epoch 0125, iter [00730, 01251], lr: 0.001044, loss: 0.4209
2022-09-29 05:24:22 - train: epoch 0125, iter [00740, 01251], lr: 0.001044, loss: 0.4090
2022-09-29 05:24:40 - train: epoch 0125, iter [00750, 01251], lr: 0.001044, loss: 0.4145
2022-09-29 05:24:58 - train: epoch 0125, iter [00760, 01251], lr: 0.001044, loss: 0.3991
2022-09-29 05:25:16 - train: epoch 0125, iter [00770, 01251], lr: 0.001044, loss: 0.4314
2022-09-29 05:25:33 - train: epoch 0125, iter [00780, 01251], lr: 0.001044, loss: 0.4042
2022-09-29 05:25:51 - train: epoch 0125, iter [00790, 01251], lr: 0.001044, loss: 0.4123
2022-09-29 05:26:09 - train: epoch 0125, iter [00800, 01251], lr: 0.001044, loss: 0.4106
2022-09-29 05:26:26 - train: epoch 0125, iter [00810, 01251], lr: 0.001044, loss: 0.4335
2022-09-29 05:26:44 - train: epoch 0125, iter [00820, 01251], lr: 0.001044, loss: 0.3872
2022-09-29 05:27:02 - train: epoch 0125, iter [00830, 01251], lr: 0.001044, loss: 0.4043
2022-09-29 05:27:20 - train: epoch 0125, iter [00840, 01251], lr: 0.001044, loss: 0.4114
2022-09-29 05:27:37 - train: epoch 0125, iter [00850, 01251], lr: 0.001043, loss: 0.4079
2022-09-29 05:27:55 - train: epoch 0125, iter [00860, 01251], lr: 0.001043, loss: 0.3920
2022-09-29 05:28:13 - train: epoch 0125, iter [00870, 01251], lr: 0.001043, loss: 0.4128
2022-09-29 05:28:30 - train: epoch 0125, iter [00880, 01251], lr: 0.001043, loss: 0.4150
2022-09-29 05:28:48 - train: epoch 0125, iter [00890, 01251], lr: 0.001043, loss: 0.4001
2022-09-29 05:29:06 - train: epoch 0125, iter [00900, 01251], lr: 0.001043, loss: 0.4034
2022-09-29 05:29:23 - train: epoch 0125, iter [00910, 01251], lr: 0.001043, loss: 0.4227
2022-09-29 05:29:41 - train: epoch 0125, iter [00920, 01251], lr: 0.001043, loss: 0.4311
2022-09-29 05:29:59 - train: epoch 0125, iter [00930, 01251], lr: 0.001043, loss: 0.4262
2022-09-29 05:30:16 - train: epoch 0125, iter [00940, 01251], lr: 0.001043, loss: 0.3974
2022-09-29 05:30:34 - train: epoch 0125, iter [00950, 01251], lr: 0.001043, loss: 0.4033
2022-09-29 05:30:52 - train: epoch 0125, iter [00960, 01251], lr: 0.001043, loss: 0.4269
2022-09-29 05:31:09 - train: epoch 0125, iter [00970, 01251], lr: 0.001043, loss: 0.4046
2022-09-29 05:31:27 - train: epoch 0125, iter [00980, 01251], lr: 0.001043, loss: 0.4256
2022-09-29 05:31:45 - train: epoch 0125, iter [00990, 01251], lr: 0.001043, loss: 0.4277
2022-09-29 05:32:03 - train: epoch 0125, iter [01000, 01251], lr: 0.001043, loss: 0.4014
2022-09-29 05:32:20 - train: epoch 0125, iter [01010, 01251], lr: 0.001043, loss: 0.4248
2022-09-29 05:32:38 - train: epoch 0125, iter [01020, 01251], lr: 0.001043, loss: 0.4267
2022-09-29 05:32:56 - train: epoch 0125, iter [01030, 01251], lr: 0.001043, loss: 0.4354
2022-09-29 05:33:14 - train: epoch 0125, iter [01040, 01251], lr: 0.001043, loss: 0.4175
2022-09-29 05:33:32 - train: epoch 0125, iter [01050, 01251], lr: 0.001043, loss: 0.4156
2022-09-29 05:33:49 - train: epoch 0125, iter [01060, 01251], lr: 0.001043, loss: 0.4004
2022-09-29 05:34:07 - train: epoch 0125, iter [01070, 01251], lr: 0.001043, loss: 0.4236
2022-09-29 05:34:25 - train: epoch 0125, iter [01080, 01251], lr: 0.001043, loss: 0.4004
2022-09-29 05:34:42 - train: epoch 0125, iter [01090, 01251], lr: 0.001043, loss: 0.4073
2022-09-29 05:35:00 - train: epoch 0125, iter [01100, 01251], lr: 0.001043, loss: 0.4165
2022-09-29 05:35:18 - train: epoch 0125, iter [01110, 01251], lr: 0.001043, loss: 0.4144
2022-09-29 05:35:35 - train: epoch 0125, iter [01120, 01251], lr: 0.001043, loss: 0.4206
2022-09-29 05:35:53 - train: epoch 0125, iter [01130, 01251], lr: 0.001043, loss: 0.3939
2022-09-29 05:36:11 - train: epoch 0125, iter [01140, 01251], lr: 0.001043, loss: 0.4299
2022-09-29 05:36:29 - train: epoch 0125, iter [01150, 01251], lr: 0.001043, loss: 0.4198
2022-09-29 05:36:46 - train: epoch 0125, iter [01160, 01251], lr: 0.001043, loss: 0.4271
2022-09-29 05:37:04 - train: epoch 0125, iter [01170, 01251], lr: 0.001043, loss: 0.4163
2022-09-29 05:37:22 - train: epoch 0125, iter [01180, 01251], lr: 0.001043, loss: 0.4124
2022-09-29 05:37:40 - train: epoch 0125, iter [01190, 01251], lr: 0.001043, loss: 0.4119
2022-09-29 05:37:57 - train: epoch 0125, iter [01200, 01251], lr: 0.001043, loss: 0.4281
2022-09-29 05:38:15 - train: epoch 0125, iter [01210, 01251], lr: 0.001042, loss: 0.3972
2022-09-29 05:38:33 - train: epoch 0125, iter [01220, 01251], lr: 0.001042, loss: 0.4061
2022-09-29 05:38:50 - train: epoch 0125, iter [01230, 01251], lr: 0.001042, loss: 0.3969
2022-09-29 05:39:08 - train: epoch 0125, iter [01240, 01251], lr: 0.001042, loss: 0.4085
2022-09-29 05:39:25 - train: epoch 0125, iter [01250, 01251], lr: 0.001042, loss: 0.3934
2022-09-29 05:39:29 - train: epoch 125, train_loss: 0.4118
2022-09-29 05:39:31 - until epoch: 125, best_loss: 0.4118
2022-09-29 05:39:31 - epoch 126 lr: 0.001042
2022-09-29 05:40:04 - train: epoch 0126, iter [00010, 01251], lr: 0.001042, loss: 0.4134
2022-09-29 05:40:22 - train: epoch 0126, iter [00020, 01251], lr: 0.001042, loss: 0.4139
2022-09-29 05:40:40 - train: epoch 0126, iter [00030, 01251], lr: 0.001042, loss: 0.4048
2022-09-29 05:40:58 - train: epoch 0126, iter [00040, 01251], lr: 0.001042, loss: 0.4107
2022-09-29 05:41:15 - train: epoch 0126, iter [00050, 01251], lr: 0.001042, loss: 0.4259
2022-09-29 05:41:33 - train: epoch 0126, iter [00060, 01251], lr: 0.001042, loss: 0.4071
2022-09-29 05:41:51 - train: epoch 0126, iter [00070, 01251], lr: 0.001042, loss: 0.3920
2022-09-29 05:42:09 - train: epoch 0126, iter [00080, 01251], lr: 0.001042, loss: 0.4179
2022-09-29 05:42:26 - train: epoch 0126, iter [00090, 01251], lr: 0.001042, loss: 0.4018
2022-09-29 05:42:44 - train: epoch 0126, iter [00100, 01251], lr: 0.001042, loss: 0.4062
2022-09-29 05:43:02 - train: epoch 0126, iter [00110, 01251], lr: 0.001042, loss: 0.4083
2022-09-29 05:43:20 - train: epoch 0126, iter [00120, 01251], lr: 0.001042, loss: 0.4182
2022-09-29 05:43:37 - train: epoch 0126, iter [00130, 01251], lr: 0.001042, loss: 0.4269
2022-09-29 05:43:55 - train: epoch 0126, iter [00140, 01251], lr: 0.001042, loss: 0.4269
2022-09-29 05:44:13 - train: epoch 0126, iter [00150, 01251], lr: 0.001042, loss: 0.4060
2022-09-29 05:44:31 - train: epoch 0126, iter [00160, 01251], lr: 0.001042, loss: 0.4249
2022-09-29 05:44:49 - train: epoch 0126, iter [00170, 01251], lr: 0.001042, loss: 0.3981
2022-09-29 05:45:06 - train: epoch 0126, iter [00180, 01251], lr: 0.001042, loss: 0.4358
2022-09-29 05:45:24 - train: epoch 0126, iter [00190, 01251], lr: 0.001042, loss: 0.4173
2022-09-29 05:45:42 - train: epoch 0126, iter [00200, 01251], lr: 0.001042, loss: 0.4307
2022-09-29 05:45:59 - train: epoch 0126, iter [00210, 01251], lr: 0.001042, loss: 0.4299
2022-09-29 05:46:17 - train: epoch 0126, iter [00220, 01251], lr: 0.001042, loss: 0.4037
2022-09-29 05:46:35 - train: epoch 0126, iter [00230, 01251], lr: 0.001042, loss: 0.4036
2022-09-29 05:46:53 - train: epoch 0126, iter [00240, 01251], lr: 0.001042, loss: 0.4123
2022-09-29 05:47:11 - train: epoch 0126, iter [00250, 01251], lr: 0.001042, loss: 0.4116
2022-09-29 05:47:28 - train: epoch 0126, iter [00260, 01251], lr: 0.001042, loss: 0.4137
2022-09-29 05:47:46 - train: epoch 0126, iter [00270, 01251], lr: 0.001042, loss: 0.4114
2022-09-29 05:48:04 - train: epoch 0126, iter [00280, 01251], lr: 0.001042, loss: 0.3893
2022-09-29 05:48:22 - train: epoch 0126, iter [00290, 01251], lr: 0.001042, loss: 0.4130
2022-09-29 05:48:39 - train: epoch 0126, iter [00300, 01251], lr: 0.001042, loss: 0.4276
2022-09-29 05:48:57 - train: epoch 0126, iter [00310, 01251], lr: 0.001041, loss: 0.3970
2022-09-29 05:49:15 - train: epoch 0126, iter [00320, 01251], lr: 0.001041, loss: 0.4343
2022-09-29 05:49:33 - train: epoch 0126, iter [00330, 01251], lr: 0.001041, loss: 0.4012
2022-09-29 05:49:51 - train: epoch 0126, iter [00340, 01251], lr: 0.001041, loss: 0.3967
2022-09-29 05:50:08 - train: epoch 0126, iter [00350, 01251], lr: 0.001041, loss: 0.4086
2022-09-29 05:50:26 - train: epoch 0126, iter [00360, 01251], lr: 0.001041, loss: 0.4000
2022-09-29 05:50:44 - train: epoch 0126, iter [00370, 01251], lr: 0.001041, loss: 0.4245
2022-09-29 05:51:02 - train: epoch 0126, iter [00380, 01251], lr: 0.001041, loss: 0.4055
2022-09-29 05:51:19 - train: epoch 0126, iter [00390, 01251], lr: 0.001041, loss: 0.4104
2022-09-29 05:51:37 - train: epoch 0126, iter [00400, 01251], lr: 0.001041, loss: 0.4245
2022-09-29 05:51:55 - train: epoch 0126, iter [00410, 01251], lr: 0.001041, loss: 0.3995
2022-09-29 05:52:13 - train: epoch 0126, iter [00420, 01251], lr: 0.001041, loss: 0.4057
2022-09-29 05:52:30 - train: epoch 0126, iter [00430, 01251], lr: 0.001041, loss: 0.4064
2022-09-29 05:52:48 - train: epoch 0126, iter [00440, 01251], lr: 0.001041, loss: 0.4144
2022-09-29 05:53:06 - train: epoch 0126, iter [00450, 01251], lr: 0.001041, loss: 0.4094
2022-09-29 05:53:23 - train: epoch 0126, iter [00460, 01251], lr: 0.001041, loss: 0.4117
2022-09-29 05:53:41 - train: epoch 0126, iter [00470, 01251], lr: 0.001041, loss: 0.4061
2022-09-29 05:53:59 - train: epoch 0126, iter [00480, 01251], lr: 0.001041, loss: 0.4333
2022-09-29 05:54:17 - train: epoch 0126, iter [00490, 01251], lr: 0.001041, loss: 0.4051
2022-09-29 05:54:34 - train: epoch 0126, iter [00500, 01251], lr: 0.001041, loss: 0.4267
2022-09-29 05:54:52 - train: epoch 0126, iter [00510, 01251], lr: 0.001041, loss: 0.4225
2022-09-29 05:55:10 - train: epoch 0126, iter [00520, 01251], lr: 0.001041, loss: 0.4314
2022-09-29 05:55:27 - train: epoch 0126, iter [00530, 01251], lr: 0.001041, loss: 0.4281
2022-09-29 05:55:45 - train: epoch 0126, iter [00540, 01251], lr: 0.001041, loss: 0.4025
2022-09-29 05:56:03 - train: epoch 0126, iter [00550, 01251], lr: 0.001041, loss: 0.4223
2022-09-29 05:56:21 - train: epoch 0126, iter [00560, 01251], lr: 0.001041, loss: 0.3967
2022-09-29 05:56:39 - train: epoch 0126, iter [00570, 01251], lr: 0.001041, loss: 0.4170
2022-09-29 05:56:56 - train: epoch 0126, iter [00580, 01251], lr: 0.001041, loss: 0.4307
2022-09-29 05:57:14 - train: epoch 0126, iter [00590, 01251], lr: 0.001041, loss: 0.3957
2022-09-29 05:57:32 - train: epoch 0126, iter [00600, 01251], lr: 0.001041, loss: 0.4129
2022-09-29 05:57:49 - train: epoch 0126, iter [00610, 01251], lr: 0.001041, loss: 0.4125
2022-09-29 05:58:07 - train: epoch 0126, iter [00620, 01251], lr: 0.001041, loss: 0.4132
2022-09-29 05:58:25 - train: epoch 0126, iter [00630, 01251], lr: 0.001041, loss: 0.4137
2022-09-29 05:58:43 - train: epoch 0126, iter [00640, 01251], lr: 0.001041, loss: 0.4206
2022-09-29 05:59:01 - train: epoch 0126, iter [00650, 01251], lr: 0.001041, loss: 0.4140
2022-09-29 05:59:18 - train: epoch 0126, iter [00660, 01251], lr: 0.001040, loss: 0.4043
2022-09-29 05:59:36 - train: epoch 0126, iter [00670, 01251], lr: 0.001040, loss: 0.4094
2022-09-29 05:59:54 - train: epoch 0126, iter [00680, 01251], lr: 0.001040, loss: 0.4115
2022-09-29 06:00:12 - train: epoch 0126, iter [00690, 01251], lr: 0.001040, loss: 0.4012
2022-09-29 06:00:29 - train: epoch 0126, iter [00700, 01251], lr: 0.001040, loss: 0.4088
2022-09-29 06:00:47 - train: epoch 0126, iter [00710, 01251], lr: 0.001040, loss: 0.4007
2022-09-29 06:01:05 - train: epoch 0126, iter [00720, 01251], lr: 0.001040, loss: 0.3878
2022-09-29 06:01:23 - train: epoch 0126, iter [00730, 01251], lr: 0.001040, loss: 0.4032
2022-09-29 06:01:41 - train: epoch 0126, iter [00740, 01251], lr: 0.001040, loss: 0.4298
2022-09-29 06:01:58 - train: epoch 0126, iter [00750, 01251], lr: 0.001040, loss: 0.4079
2022-09-29 06:02:16 - train: epoch 0126, iter [00760, 01251], lr: 0.001040, loss: 0.3959
2022-09-29 06:02:34 - train: epoch 0126, iter [00770, 01251], lr: 0.001040, loss: 0.4024
2022-09-29 06:02:51 - train: epoch 0126, iter [00780, 01251], lr: 0.001040, loss: 0.3944
2022-09-29 06:03:09 - train: epoch 0126, iter [00790, 01251], lr: 0.001040, loss: 0.4117
2022-09-29 06:03:27 - train: epoch 0126, iter [00800, 01251], lr: 0.001040, loss: 0.4250
2022-09-29 06:03:44 - train: epoch 0126, iter [00810, 01251], lr: 0.001040, loss: 0.4306
2022-09-29 06:04:02 - train: epoch 0126, iter [00820, 01251], lr: 0.001040, loss: 0.4171
2022-09-29 06:04:20 - train: epoch 0126, iter [00830, 01251], lr: 0.001040, loss: 0.4109
2022-09-29 06:04:38 - train: epoch 0126, iter [00840, 01251], lr: 0.001040, loss: 0.4075
2022-09-29 06:04:55 - train: epoch 0126, iter [00850, 01251], lr: 0.001040, loss: 0.3970
2022-09-29 06:05:13 - train: epoch 0126, iter [00860, 01251], lr: 0.001040, loss: 0.3958
2022-09-29 06:05:31 - train: epoch 0126, iter [00870, 01251], lr: 0.001040, loss: 0.4041
2022-09-29 06:05:49 - train: epoch 0126, iter [00880, 01251], lr: 0.001040, loss: 0.4128
2022-09-29 06:06:07 - train: epoch 0126, iter [00890, 01251], lr: 0.001040, loss: 0.4072
2022-09-29 06:06:25 - train: epoch 0126, iter [00900, 01251], lr: 0.001040, loss: 0.4387
2022-09-29 06:06:43 - train: epoch 0126, iter [00910, 01251], lr: 0.001040, loss: 0.4278
2022-09-29 06:07:00 - train: epoch 0126, iter [00920, 01251], lr: 0.001040, loss: 0.3967
2022-09-29 06:07:18 - train: epoch 0126, iter [00930, 01251], lr: 0.001040, loss: 0.3995
2022-09-29 06:07:36 - train: epoch 0126, iter [00940, 01251], lr: 0.001040, loss: 0.3984
2022-09-29 06:07:53 - train: epoch 0126, iter [00950, 01251], lr: 0.001040, loss: 0.4218
2022-09-29 06:08:11 - train: epoch 0126, iter [00960, 01251], lr: 0.001040, loss: 0.4133
2022-09-29 06:08:29 - train: epoch 0126, iter [00970, 01251], lr: 0.001040, loss: 0.4204
2022-09-29 06:08:46 - train: epoch 0126, iter [00980, 01251], lr: 0.001040, loss: 0.4216
2022-09-29 06:09:04 - train: epoch 0126, iter [00990, 01251], lr: 0.001040, loss: 0.4166
2022-09-29 06:09:22 - train: epoch 0126, iter [01000, 01251], lr: 0.001040, loss: 0.4063
2022-09-29 06:09:39 - train: epoch 0126, iter [01010, 01251], lr: 0.001039, loss: 0.4178
2022-09-29 06:09:57 - train: epoch 0126, iter [01020, 01251], lr: 0.001039, loss: 0.4137
2022-09-29 06:10:15 - train: epoch 0126, iter [01030, 01251], lr: 0.001039, loss: 0.4115
2022-09-29 06:10:32 - train: epoch 0126, iter [01040, 01251], lr: 0.001039, loss: 0.4139
2022-09-29 06:10:50 - train: epoch 0126, iter [01050, 01251], lr: 0.001039, loss: 0.4122
2022-09-29 06:11:08 - train: epoch 0126, iter [01060, 01251], lr: 0.001039, loss: 0.4161
2022-09-29 06:11:26 - train: epoch 0126, iter [01070, 01251], lr: 0.001039, loss: 0.4001
2022-09-29 06:11:43 - train: epoch 0126, iter [01080, 01251], lr: 0.001039, loss: 0.4167
2022-09-29 06:12:01 - train: epoch 0126, iter [01090, 01251], lr: 0.001039, loss: 0.4136
2022-09-29 06:12:19 - train: epoch 0126, iter [01100, 01251], lr: 0.001039, loss: 0.4143
2022-09-29 06:12:37 - train: epoch 0126, iter [01110, 01251], lr: 0.001039, loss: 0.4084
2022-09-29 06:12:54 - train: epoch 0126, iter [01120, 01251], lr: 0.001039, loss: 0.4003
2022-09-29 06:13:12 - train: epoch 0126, iter [01130, 01251], lr: 0.001039, loss: 0.4234
2022-09-29 06:13:30 - train: epoch 0126, iter [01140, 01251], lr: 0.001039, loss: 0.4092
2022-09-29 06:13:48 - train: epoch 0126, iter [01150, 01251], lr: 0.001039, loss: 0.4125
2022-09-29 06:14:05 - train: epoch 0126, iter [01160, 01251], lr: 0.001039, loss: 0.4112
2022-09-29 06:14:23 - train: epoch 0126, iter [01170, 01251], lr: 0.001039, loss: 0.4154
2022-09-29 06:14:41 - train: epoch 0126, iter [01180, 01251], lr: 0.001039, loss: 0.4079
2022-09-29 06:14:59 - train: epoch 0126, iter [01190, 01251], lr: 0.001039, loss: 0.4276
2022-09-29 06:15:16 - train: epoch 0126, iter [01200, 01251], lr: 0.001039, loss: 0.4075
2022-09-29 06:15:34 - train: epoch 0126, iter [01210, 01251], lr: 0.001039, loss: 0.4214
2022-09-29 06:15:52 - train: epoch 0126, iter [01220, 01251], lr: 0.001039, loss: 0.4145
2022-09-29 06:16:10 - train: epoch 0126, iter [01230, 01251], lr: 0.001039, loss: 0.4204
2022-09-29 06:16:27 - train: epoch 0126, iter [01240, 01251], lr: 0.001039, loss: 0.4023
2022-09-29 06:16:44 - train: epoch 0126, iter [01250, 01251], lr: 0.001039, loss: 0.4096
2022-09-29 06:16:49 - train: epoch 126, train_loss: 0.4117
2022-09-29 06:16:51 - until epoch: 126, best_loss: 0.4117
2022-09-29 06:16:51 - epoch 127 lr: 0.001039
2022-09-29 06:17:24 - train: epoch 0127, iter [00010, 01251], lr: 0.001039, loss: 0.3971
2022-09-29 06:17:41 - train: epoch 0127, iter [00020, 01251], lr: 0.001039, loss: 0.4081
2022-09-29 06:17:59 - train: epoch 0127, iter [00030, 01251], lr: 0.001039, loss: 0.4376
2022-09-29 06:18:17 - train: epoch 0127, iter [00040, 01251], lr: 0.001039, loss: 0.4159
2022-09-29 06:18:35 - train: epoch 0127, iter [00050, 01251], lr: 0.001039, loss: 0.4182
2022-09-29 06:18:52 - train: epoch 0127, iter [00060, 01251], lr: 0.001039, loss: 0.4066
2022-09-29 06:19:10 - train: epoch 0127, iter [00070, 01251], lr: 0.001039, loss: 0.4256
2022-09-29 06:19:28 - train: epoch 0127, iter [00080, 01251], lr: 0.001039, loss: 0.4205
2022-09-29 06:19:46 - train: epoch 0127, iter [00090, 01251], lr: 0.001039, loss: 0.4080
2022-09-29 06:20:04 - train: epoch 0127, iter [00100, 01251], lr: 0.001039, loss: 0.4031
2022-09-29 06:20:21 - train: epoch 0127, iter [00110, 01251], lr: 0.001038, loss: 0.4075
2022-09-29 06:20:39 - train: epoch 0127, iter [00120, 01251], lr: 0.001038, loss: 0.4069
2022-09-29 06:20:57 - train: epoch 0127, iter [00130, 01251], lr: 0.001038, loss: 0.4117
2022-09-29 06:21:15 - train: epoch 0127, iter [00140, 01251], lr: 0.001038, loss: 0.4247
2022-09-29 06:21:32 - train: epoch 0127, iter [00150, 01251], lr: 0.001038, loss: 0.4078
2022-09-29 06:21:50 - train: epoch 0127, iter [00160, 01251], lr: 0.001038, loss: 0.4301
2022-09-29 06:22:08 - train: epoch 0127, iter [00170, 01251], lr: 0.001038, loss: 0.4180
2022-09-29 06:22:25 - train: epoch 0127, iter [00180, 01251], lr: 0.001038, loss: 0.4078
2022-09-29 06:22:43 - train: epoch 0127, iter [00190, 01251], lr: 0.001038, loss: 0.4285
2022-09-29 06:23:01 - train: epoch 0127, iter [00200, 01251], lr: 0.001038, loss: 0.3894
2022-09-29 06:23:18 - train: epoch 0127, iter [00210, 01251], lr: 0.001038, loss: 0.4172
2022-09-29 06:23:36 - train: epoch 0127, iter [00220, 01251], lr: 0.001038, loss: 0.3921
2022-09-29 06:23:54 - train: epoch 0127, iter [00230, 01251], lr: 0.001038, loss: 0.4164
2022-09-29 06:24:11 - train: epoch 0127, iter [00240, 01251], lr: 0.001038, loss: 0.3980
2022-09-29 06:24:29 - train: epoch 0127, iter [00250, 01251], lr: 0.001038, loss: 0.4155
2022-09-29 06:24:47 - train: epoch 0127, iter [00260, 01251], lr: 0.001038, loss: 0.4066
2022-09-29 06:25:05 - train: epoch 0127, iter [00270, 01251], lr: 0.001038, loss: 0.4284
2022-09-29 06:25:22 - train: epoch 0127, iter [00280, 01251], lr: 0.001038, loss: 0.4306
2022-09-29 06:25:40 - train: epoch 0127, iter [00290, 01251], lr: 0.001038, loss: 0.4145
2022-09-29 06:25:58 - train: epoch 0127, iter [00300, 01251], lr: 0.001038, loss: 0.4268
2022-09-29 06:26:16 - train: epoch 0127, iter [00310, 01251], lr: 0.001038, loss: 0.3797
2022-09-29 06:26:33 - train: epoch 0127, iter [00320, 01251], lr: 0.001038, loss: 0.4104
2022-09-29 06:26:51 - train: epoch 0127, iter [00330, 01251], lr: 0.001038, loss: 0.4180
2022-09-29 06:27:09 - train: epoch 0127, iter [00340, 01251], lr: 0.001038, loss: 0.4106
2022-09-29 06:27:27 - train: epoch 0127, iter [00350, 01251], lr: 0.001038, loss: 0.4212
2022-09-29 06:27:45 - train: epoch 0127, iter [00360, 01251], lr: 0.001038, loss: 0.4129
2022-09-29 06:28:02 - train: epoch 0127, iter [00370, 01251], lr: 0.001038, loss: 0.4276
2022-09-29 06:28:20 - train: epoch 0127, iter [00380, 01251], lr: 0.001038, loss: 0.4185
2022-09-29 06:28:38 - train: epoch 0127, iter [00390, 01251], lr: 0.001038, loss: 0.4002
2022-09-29 06:28:56 - train: epoch 0127, iter [00400, 01251], lr: 0.001038, loss: 0.4038
2022-09-29 06:29:13 - train: epoch 0127, iter [00410, 01251], lr: 0.001038, loss: 0.3947
2022-09-29 06:29:31 - train: epoch 0127, iter [00420, 01251], lr: 0.001038, loss: 0.4042
2022-09-29 06:29:49 - train: epoch 0127, iter [00430, 01251], lr: 0.001038, loss: 0.4026
2022-09-29 06:30:07 - train: epoch 0127, iter [00440, 01251], lr: 0.001038, loss: 0.4210
2022-09-29 06:30:24 - train: epoch 0127, iter [00450, 01251], lr: 0.001038, loss: 0.4146
2022-09-29 06:30:42 - train: epoch 0127, iter [00460, 01251], lr: 0.001037, loss: 0.4158
2022-09-29 06:31:00 - train: epoch 0127, iter [00470, 01251], lr: 0.001037, loss: 0.4202
2022-09-29 06:31:18 - train: epoch 0127, iter [00480, 01251], lr: 0.001037, loss: 0.4156
2022-09-29 06:31:35 - train: epoch 0127, iter [00490, 01251], lr: 0.001037, loss: 0.4265
2022-09-29 06:31:53 - train: epoch 0127, iter [00500, 01251], lr: 0.001037, loss: 0.4113
2022-09-29 06:32:11 - train: epoch 0127, iter [00510, 01251], lr: 0.001037, loss: 0.4007
2022-09-29 06:32:29 - train: epoch 0127, iter [00520, 01251], lr: 0.001037, loss: 0.4307
2022-09-29 06:32:46 - train: epoch 0127, iter [00530, 01251], lr: 0.001037, loss: 0.4188
2022-09-29 06:33:04 - train: epoch 0127, iter [00540, 01251], lr: 0.001037, loss: 0.4117
2022-09-29 06:33:22 - train: epoch 0127, iter [00550, 01251], lr: 0.001037, loss: 0.4365
2022-09-29 06:33:40 - train: epoch 0127, iter [00560, 01251], lr: 0.001037, loss: 0.4015
2022-09-29 06:33:58 - train: epoch 0127, iter [00570, 01251], lr: 0.001037, loss: 0.4083
2022-09-29 06:34:15 - train: epoch 0127, iter [00580, 01251], lr: 0.001037, loss: 0.4037
2022-09-29 06:34:33 - train: epoch 0127, iter [00590, 01251], lr: 0.001037, loss: 0.4127
2022-09-29 06:34:51 - train: epoch 0127, iter [00600, 01251], lr: 0.001037, loss: 0.4222
2022-09-29 06:35:09 - train: epoch 0127, iter [00610, 01251], lr: 0.001037, loss: 0.4027
2022-09-29 06:35:26 - train: epoch 0127, iter [00620, 01251], lr: 0.001037, loss: 0.4021
2022-09-29 06:35:44 - train: epoch 0127, iter [00630, 01251], lr: 0.001037, loss: 0.4197
2022-09-29 06:36:02 - train: epoch 0127, iter [00640, 01251], lr: 0.001037, loss: 0.3926
2022-09-29 06:36:20 - train: epoch 0127, iter [00650, 01251], lr: 0.001037, loss: 0.4045
2022-09-29 06:36:37 - train: epoch 0127, iter [00660, 01251], lr: 0.001037, loss: 0.4043
2022-09-29 06:36:55 - train: epoch 0127, iter [00670, 01251], lr: 0.001037, loss: 0.4055
2022-09-29 06:37:12 - train: epoch 0127, iter [00680, 01251], lr: 0.001037, loss: 0.4267
2022-09-29 06:37:30 - train: epoch 0127, iter [00690, 01251], lr: 0.001037, loss: 0.4234
2022-09-29 06:37:48 - train: epoch 0127, iter [00700, 01251], lr: 0.001037, loss: 0.4164
2022-09-29 06:38:06 - train: epoch 0127, iter [00710, 01251], lr: 0.001037, loss: 0.4061
2022-09-29 06:38:24 - train: epoch 0127, iter [00720, 01251], lr: 0.001037, loss: 0.4038
2022-09-29 06:38:41 - train: epoch 0127, iter [00730, 01251], lr: 0.001037, loss: 0.4148
2022-09-29 06:38:59 - train: epoch 0127, iter [00740, 01251], lr: 0.001037, loss: 0.3889
2022-09-29 06:39:17 - train: epoch 0127, iter [00750, 01251], lr: 0.001037, loss: 0.4080
2022-09-29 06:39:35 - train: epoch 0127, iter [00760, 01251], lr: 0.001037, loss: 0.4057
2022-09-29 06:39:52 - train: epoch 0127, iter [00770, 01251], lr: 0.001037, loss: 0.4144
2022-09-29 06:40:10 - train: epoch 0127, iter [00780, 01251], lr: 0.001037, loss: 0.4141
2022-09-29 06:40:28 - train: epoch 0127, iter [00790, 01251], lr: 0.001037, loss: 0.4155
2022-09-29 06:40:46 - train: epoch 0127, iter [00800, 01251], lr: 0.001037, loss: 0.3917
2022-09-29 06:41:03 - train: epoch 0127, iter [00810, 01251], lr: 0.001036, loss: 0.3897
2022-09-29 06:41:21 - train: epoch 0127, iter [00820, 01251], lr: 0.001036, loss: 0.4011
2022-09-29 06:41:39 - train: epoch 0127, iter [00830, 01251], lr: 0.001036, loss: 0.4280
2022-09-29 06:41:56 - train: epoch 0127, iter [00840, 01251], lr: 0.001036, loss: 0.4216
2022-09-29 06:42:14 - train: epoch 0127, iter [00850, 01251], lr: 0.001036, loss: 0.4094
2022-09-29 06:42:32 - train: epoch 0127, iter [00860, 01251], lr: 0.001036, loss: 0.4169
2022-09-29 06:42:50 - train: epoch 0127, iter [00870, 01251], lr: 0.001036, loss: 0.4203
2022-09-29 06:43:07 - train: epoch 0127, iter [00880, 01251], lr: 0.001036, loss: 0.4275
2022-09-29 06:43:25 - train: epoch 0127, iter [00890, 01251], lr: 0.001036, loss: 0.4165
2022-09-29 06:43:43 - train: epoch 0127, iter [00900, 01251], lr: 0.001036, loss: 0.4171
2022-09-29 06:44:01 - train: epoch 0127, iter [00910, 01251], lr: 0.001036, loss: 0.4107
2022-09-29 06:44:18 - train: epoch 0127, iter [00920, 01251], lr: 0.001036, loss: 0.3958
2022-09-29 06:44:36 - train: epoch 0127, iter [00930, 01251], lr: 0.001036, loss: 0.4053
2022-09-29 06:44:54 - train: epoch 0127, iter [00940, 01251], lr: 0.001036, loss: 0.4055
2022-09-29 06:45:12 - train: epoch 0127, iter [00950, 01251], lr: 0.001036, loss: 0.3979
2022-09-29 06:45:29 - train: epoch 0127, iter [00960, 01251], lr: 0.001036, loss: 0.4057
2022-09-29 06:45:47 - train: epoch 0127, iter [00970, 01251], lr: 0.001036, loss: 0.4055
2022-09-29 06:46:05 - train: epoch 0127, iter [00980, 01251], lr: 0.001036, loss: 0.3908
2022-09-29 06:46:22 - train: epoch 0127, iter [00990, 01251], lr: 0.001036, loss: 0.4103
2022-09-29 06:46:40 - train: epoch 0127, iter [01000, 01251], lr: 0.001036, loss: 0.4267
2022-09-29 06:46:58 - train: epoch 0127, iter [01010, 01251], lr: 0.001036, loss: 0.4211
2022-09-29 06:47:16 - train: epoch 0127, iter [01020, 01251], lr: 0.001036, loss: 0.4168
2022-09-29 06:47:33 - train: epoch 0127, iter [01030, 01251], lr: 0.001036, loss: 0.4125
2022-09-29 06:47:51 - train: epoch 0127, iter [01040, 01251], lr: 0.001036, loss: 0.4187
2022-09-29 06:48:09 - train: epoch 0127, iter [01050, 01251], lr: 0.001036, loss: 0.4038
2022-09-29 06:48:27 - train: epoch 0127, iter [01060, 01251], lr: 0.001036, loss: 0.4219
2022-09-29 06:48:45 - train: epoch 0127, iter [01070, 01251], lr: 0.001036, loss: 0.3912
2022-09-29 06:49:02 - train: epoch 0127, iter [01080, 01251], lr: 0.001036, loss: 0.4262
2022-09-29 06:49:20 - train: epoch 0127, iter [01090, 01251], lr: 0.001036, loss: 0.4046
2022-09-29 06:49:38 - train: epoch 0127, iter [01100, 01251], lr: 0.001036, loss: 0.4153
2022-09-29 06:49:56 - train: epoch 0127, iter [01110, 01251], lr: 0.001036, loss: 0.4163
2022-09-29 06:50:13 - train: epoch 0127, iter [01120, 01251], lr: 0.001036, loss: 0.4028
2022-09-29 06:50:31 - train: epoch 0127, iter [01130, 01251], lr: 0.001036, loss: 0.3960
2022-09-29 06:50:49 - train: epoch 0127, iter [01140, 01251], lr: 0.001036, loss: 0.4152
2022-09-29 06:51:07 - train: epoch 0127, iter [01150, 01251], lr: 0.001036, loss: 0.4100
2022-09-29 06:51:25 - train: epoch 0127, iter [01160, 01251], lr: 0.001035, loss: 0.4284
2022-09-29 06:51:42 - train: epoch 0127, iter [01170, 01251], lr: 0.001035, loss: 0.3925
2022-09-29 06:52:00 - train: epoch 0127, iter [01180, 01251], lr: 0.001035, loss: 0.3918
2022-09-29 06:52:18 - train: epoch 0127, iter [01190, 01251], lr: 0.001035, loss: 0.3940
2022-09-29 06:52:36 - train: epoch 0127, iter [01200, 01251], lr: 0.001035, loss: 0.4141
2022-09-29 06:52:53 - train: epoch 0127, iter [01210, 01251], lr: 0.001035, loss: 0.4207
2022-09-29 06:53:11 - train: epoch 0127, iter [01220, 01251], lr: 0.001035, loss: 0.4119
2022-09-29 06:53:29 - train: epoch 0127, iter [01230, 01251], lr: 0.001035, loss: 0.4081
2022-09-29 06:53:47 - train: epoch 0127, iter [01240, 01251], lr: 0.001035, loss: 0.4055
2022-09-29 06:54:04 - train: epoch 0127, iter [01250, 01251], lr: 0.001035, loss: 0.4239
2022-09-29 06:54:08 - train: epoch 127, train_loss: 0.4117
2022-09-29 06:54:10 - until epoch: 127, best_loss: 0.4117
2022-09-29 06:54:10 - epoch 128 lr: 0.001035
2022-09-29 06:54:43 - train: epoch 0128, iter [00010, 01251], lr: 0.001035, loss: 0.3958
2022-09-29 06:55:01 - train: epoch 0128, iter [00020, 01251], lr: 0.001035, loss: 0.4202
2022-09-29 06:55:18 - train: epoch 0128, iter [00030, 01251], lr: 0.001035, loss: 0.4450
2022-09-29 06:55:36 - train: epoch 0128, iter [00040, 01251], lr: 0.001035, loss: 0.4073
2022-09-29 06:55:54 - train: epoch 0128, iter [00050, 01251], lr: 0.001035, loss: 0.3994
2022-09-29 06:56:11 - train: epoch 0128, iter [00060, 01251], lr: 0.001035, loss: 0.4219
2022-09-29 06:56:29 - train: epoch 0128, iter [00070, 01251], lr: 0.001035, loss: 0.4104
2022-09-29 06:56:47 - train: epoch 0128, iter [00080, 01251], lr: 0.001035, loss: 0.3932
2022-09-29 06:57:04 - train: epoch 0128, iter [00090, 01251], lr: 0.001035, loss: 0.4113
2022-09-29 06:57:22 - train: epoch 0128, iter [00100, 01251], lr: 0.001035, loss: 0.4455
2022-09-29 06:57:40 - train: epoch 0128, iter [00110, 01251], lr: 0.001035, loss: 0.4117
2022-09-29 06:57:58 - train: epoch 0128, iter [00120, 01251], lr: 0.001035, loss: 0.4169
2022-09-29 06:58:16 - train: epoch 0128, iter [00130, 01251], lr: 0.001035, loss: 0.4060
2022-09-29 06:58:33 - train: epoch 0128, iter [00140, 01251], lr: 0.001035, loss: 0.4050
2022-09-29 06:58:50 - train: epoch 0128, iter [00150, 01251], lr: 0.001035, loss: 0.4272
2022-09-29 06:59:08 - train: epoch 0128, iter [00160, 01251], lr: 0.001035, loss: 0.4013
2022-09-29 06:59:26 - train: epoch 0128, iter [00170, 01251], lr: 0.001035, loss: 0.3924
2022-09-29 06:59:44 - train: epoch 0128, iter [00180, 01251], lr: 0.001035, loss: 0.3940
2022-09-29 07:00:02 - train: epoch 0128, iter [00190, 01251], lr: 0.001035, loss: 0.4071
2022-09-29 07:00:19 - train: epoch 0128, iter [00200, 01251], lr: 0.001035, loss: 0.4082
2022-09-29 07:00:37 - train: epoch 0128, iter [00210, 01251], lr: 0.001035, loss: 0.3948
2022-09-29 07:00:55 - train: epoch 0128, iter [00220, 01251], lr: 0.001035, loss: 0.3996
2022-09-29 07:01:12 - train: epoch 0128, iter [00230, 01251], lr: 0.001035, loss: 0.4139
2022-09-29 07:01:30 - train: epoch 0128, iter [00240, 01251], lr: 0.001035, loss: 0.4134
2022-09-29 07:01:48 - train: epoch 0128, iter [00250, 01251], lr: 0.001035, loss: 0.4149
2022-09-29 07:02:05 - train: epoch 0128, iter [00260, 01251], lr: 0.001034, loss: 0.4197
2022-09-29 07:02:23 - train: epoch 0128, iter [00270, 01251], lr: 0.001034, loss: 0.4137
2022-09-29 07:02:41 - train: epoch 0128, iter [00280, 01251], lr: 0.001034, loss: 0.4138
2022-09-29 07:02:59 - train: epoch 0128, iter [00290, 01251], lr: 0.001034, loss: 0.4053
2022-09-29 07:03:16 - train: epoch 0128, iter [00300, 01251], lr: 0.001034, loss: 0.3922
2022-09-29 07:03:34 - train: epoch 0128, iter [00310, 01251], lr: 0.001034, loss: 0.4206
2022-09-29 07:03:52 - train: epoch 0128, iter [00320, 01251], lr: 0.001034, loss: 0.4242
2022-09-29 07:04:10 - train: epoch 0128, iter [00330, 01251], lr: 0.001034, loss: 0.4094
2022-09-29 07:04:27 - train: epoch 0128, iter [00340, 01251], lr: 0.001034, loss: 0.3929
2022-09-29 07:04:45 - train: epoch 0128, iter [00350, 01251], lr: 0.001034, loss: 0.4105
2022-09-29 07:05:03 - train: epoch 0128, iter [00360, 01251], lr: 0.001034, loss: 0.4292
2022-09-29 07:05:20 - train: epoch 0128, iter [00370, 01251], lr: 0.001034, loss: 0.3923
2022-09-29 07:05:38 - train: epoch 0128, iter [00380, 01251], lr: 0.001034, loss: 0.4042
2022-09-29 07:05:56 - train: epoch 0128, iter [00390, 01251], lr: 0.001034, loss: 0.4083
2022-09-29 07:06:14 - train: epoch 0128, iter [00400, 01251], lr: 0.001034, loss: 0.4013
2022-09-29 07:06:31 - train: epoch 0128, iter [00410, 01251], lr: 0.001034, loss: 0.4013
2022-09-29 07:06:49 - train: epoch 0128, iter [00420, 01251], lr: 0.001034, loss: 0.4214
2022-09-29 07:07:07 - train: epoch 0128, iter [00430, 01251], lr: 0.001034, loss: 0.3996
2022-09-29 07:07:25 - train: epoch 0128, iter [00440, 01251], lr: 0.001034, loss: 0.4005
2022-09-29 07:07:42 - train: epoch 0128, iter [00450, 01251], lr: 0.001034, loss: 0.4134
2022-09-29 07:08:00 - train: epoch 0128, iter [00460, 01251], lr: 0.001034, loss: 0.4034
2022-09-29 07:08:18 - train: epoch 0128, iter [00470, 01251], lr: 0.001034, loss: 0.4100
2022-09-29 07:08:36 - train: epoch 0128, iter [00480, 01251], lr: 0.001034, loss: 0.4031
2022-09-29 07:08:53 - train: epoch 0128, iter [00490, 01251], lr: 0.001034, loss: 0.4258
2022-09-29 07:09:11 - train: epoch 0128, iter [00500, 01251], lr: 0.001034, loss: 0.3929
2022-09-29 07:09:29 - train: epoch 0128, iter [00510, 01251], lr: 0.001034, loss: 0.4135
2022-09-29 07:09:46 - train: epoch 0128, iter [00520, 01251], lr: 0.001034, loss: 0.4108
2022-09-29 07:10:04 - train: epoch 0128, iter [00530, 01251], lr: 0.001034, loss: 0.4272
2022-09-29 07:10:22 - train: epoch 0128, iter [00540, 01251], lr: 0.001034, loss: 0.4110
2022-09-29 07:10:40 - train: epoch 0128, iter [00550, 01251], lr: 0.001034, loss: 0.4140
2022-09-29 07:10:57 - train: epoch 0128, iter [00560, 01251], lr: 0.001034, loss: 0.4274
2022-09-29 07:11:15 - train: epoch 0128, iter [00570, 01251], lr: 0.001034, loss: 0.4248
2022-09-29 07:11:33 - train: epoch 0128, iter [00580, 01251], lr: 0.001034, loss: 0.4133
2022-09-29 07:11:51 - train: epoch 0128, iter [00590, 01251], lr: 0.001034, loss: 0.3983
2022-09-29 07:12:09 - train: epoch 0128, iter [00600, 01251], lr: 0.001033, loss: 0.4059
2022-09-29 07:12:27 - train: epoch 0128, iter [00610, 01251], lr: 0.001033, loss: 0.4058
2022-09-29 07:12:44 - train: epoch 0128, iter [00620, 01251], lr: 0.001033, loss: 0.4109
2022-09-29 07:13:02 - train: epoch 0128, iter [00630, 01251], lr: 0.001033, loss: 0.4026
2022-09-29 07:13:20 - train: epoch 0128, iter [00640, 01251], lr: 0.001033, loss: 0.4173
2022-09-29 07:13:37 - train: epoch 0128, iter [00650, 01251], lr: 0.001033, loss: 0.4162
2022-09-29 07:13:55 - train: epoch 0128, iter [00660, 01251], lr: 0.001033, loss: 0.4115
2022-09-29 07:14:13 - train: epoch 0128, iter [00670, 01251], lr: 0.001033, loss: 0.4088
2022-09-29 07:14:30 - train: epoch 0128, iter [00680, 01251], lr: 0.001033, loss: 0.4126
2022-09-29 07:14:48 - train: epoch 0128, iter [00690, 01251], lr: 0.001033, loss: 0.4103
2022-09-29 07:15:06 - train: epoch 0128, iter [00700, 01251], lr: 0.001033, loss: 0.4225
2022-09-29 07:15:24 - train: epoch 0128, iter [00710, 01251], lr: 0.001033, loss: 0.4244
2022-09-29 07:15:41 - train: epoch 0128, iter [00720, 01251], lr: 0.001033, loss: 0.4201
2022-09-29 07:15:59 - train: epoch 0128, iter [00730, 01251], lr: 0.001033, loss: 0.3956
2022-09-29 07:16:17 - train: epoch 0128, iter [00740, 01251], lr: 0.001033, loss: 0.4164
2022-09-29 07:16:35 - train: epoch 0128, iter [00750, 01251], lr: 0.001033, loss: 0.4099
2022-09-29 07:16:52 - train: epoch 0128, iter [00760, 01251], lr: 0.001033, loss: 0.4034
2022-09-29 07:17:10 - train: epoch 0128, iter [00770, 01251], lr: 0.001033, loss: 0.4003
2022-09-29 07:17:28 - train: epoch 0128, iter [00780, 01251], lr: 0.001033, loss: 0.4206
2022-09-29 07:17:46 - train: epoch 0128, iter [00790, 01251], lr: 0.001033, loss: 0.4141
2022-09-29 07:18:04 - train: epoch 0128, iter [00800, 01251], lr: 0.001033, loss: 0.4101
2022-09-29 07:18:21 - train: epoch 0128, iter [00810, 01251], lr: 0.001033, loss: 0.4070
2022-09-29 07:18:39 - train: epoch 0128, iter [00820, 01251], lr: 0.001033, loss: 0.4097
2022-09-29 07:18:57 - train: epoch 0128, iter [00830, 01251], lr: 0.001033, loss: 0.4188
2022-09-29 07:19:14 - train: epoch 0128, iter [00840, 01251], lr: 0.001033, loss: 0.4139
2022-09-29 07:19:32 - train: epoch 0128, iter [00850, 01251], lr: 0.001033, loss: 0.4277
2022-09-29 07:19:50 - train: epoch 0128, iter [00860, 01251], lr: 0.001033, loss: 0.4038
2022-09-29 07:20:08 - train: epoch 0128, iter [00870, 01251], lr: 0.001033, loss: 0.3970
2022-09-29 07:20:25 - train: epoch 0128, iter [00880, 01251], lr: 0.001033, loss: 0.3899
2022-09-29 07:20:43 - train: epoch 0128, iter [00890, 01251], lr: 0.001033, loss: 0.4390
2022-09-29 07:21:01 - train: epoch 0128, iter [00900, 01251], lr: 0.001033, loss: 0.3993
2022-09-29 07:21:19 - train: epoch 0128, iter [00910, 01251], lr: 0.001033, loss: 0.3957
2022-09-29 07:21:36 - train: epoch 0128, iter [00920, 01251], lr: 0.001033, loss: 0.4021
2022-09-29 07:21:54 - train: epoch 0128, iter [00930, 01251], lr: 0.001033, loss: 0.4009
2022-09-29 07:22:12 - train: epoch 0128, iter [00940, 01251], lr: 0.001033, loss: 0.4150
2022-09-29 07:22:30 - train: epoch 0128, iter [00950, 01251], lr: 0.001032, loss: 0.4062
2022-09-29 07:22:48 - train: epoch 0128, iter [00960, 01251], lr: 0.001032, loss: 0.4047
2022-09-29 07:23:05 - train: epoch 0128, iter [00970, 01251], lr: 0.001032, loss: 0.4172
2022-09-29 07:23:23 - train: epoch 0128, iter [00980, 01251], lr: 0.001032, loss: 0.3966
2022-09-29 07:23:41 - train: epoch 0128, iter [00990, 01251], lr: 0.001032, loss: 0.4292
2022-09-29 07:23:59 - train: epoch 0128, iter [01000, 01251], lr: 0.001032, loss: 0.4020
2022-09-29 07:24:16 - train: epoch 0128, iter [01010, 01251], lr: 0.001032, loss: 0.4075
2022-09-29 07:24:34 - train: epoch 0128, iter [01020, 01251], lr: 0.001032, loss: 0.4082
2022-09-29 07:24:52 - train: epoch 0128, iter [01030, 01251], lr: 0.001032, loss: 0.4192
2022-09-29 07:25:09 - train: epoch 0128, iter [01040, 01251], lr: 0.001032, loss: 0.4155
2022-09-29 07:25:27 - train: epoch 0128, iter [01050, 01251], lr: 0.001032, loss: 0.3853
2022-09-29 07:25:45 - train: epoch 0128, iter [01060, 01251], lr: 0.001032, loss: 0.4292
2022-09-29 07:26:03 - train: epoch 0128, iter [01070, 01251], lr: 0.001032, loss: 0.4240
2022-09-29 07:26:21 - train: epoch 0128, iter [01080, 01251], lr: 0.001032, loss: 0.4014
2022-09-29 07:26:38 - train: epoch 0128, iter [01090, 01251], lr: 0.001032, loss: 0.4156
2022-09-29 07:26:56 - train: epoch 0128, iter [01100, 01251], lr: 0.001032, loss: 0.4210
2022-09-29 07:27:14 - train: epoch 0128, iter [01110, 01251], lr: 0.001032, loss: 0.4316
2022-09-29 07:27:31 - train: epoch 0128, iter [01120, 01251], lr: 0.001032, loss: 0.4187
2022-09-29 07:27:49 - train: epoch 0128, iter [01130, 01251], lr: 0.001032, loss: 0.4256
2022-09-29 07:28:07 - train: epoch 0128, iter [01140, 01251], lr: 0.001032, loss: 0.4249
2022-09-29 07:28:25 - train: epoch 0128, iter [01150, 01251], lr: 0.001032, loss: 0.4063
2022-09-29 07:28:42 - train: epoch 0128, iter [01160, 01251], lr: 0.001032, loss: 0.4404
2022-09-29 07:29:00 - train: epoch 0128, iter [01170, 01251], lr: 0.001032, loss: 0.4084
2022-09-29 07:29:18 - train: epoch 0128, iter [01180, 01251], lr: 0.001032, loss: 0.4150
2022-09-29 07:29:35 - train: epoch 0128, iter [01190, 01251], lr: 0.001032, loss: 0.4318
2022-09-29 07:29:53 - train: epoch 0128, iter [01200, 01251], lr: 0.001032, loss: 0.4133
2022-09-29 07:30:11 - train: epoch 0128, iter [01210, 01251], lr: 0.001032, loss: 0.4167
2022-09-29 07:30:28 - train: epoch 0128, iter [01220, 01251], lr: 0.001032, loss: 0.4072
2022-09-29 07:30:47 - train: epoch 0128, iter [01230, 01251], lr: 0.001032, loss: 0.4150
2022-09-29 07:31:04 - train: epoch 0128, iter [01240, 01251], lr: 0.001032, loss: 0.4133
2022-09-29 07:31:21 - train: epoch 0128, iter [01250, 01251], lr: 0.001032, loss: 0.4268
2022-09-29 07:31:25 - train: epoch 128, train_loss: 0.4117
2022-09-29 07:31:28 - until epoch: 128, best_loss: 0.4117
2022-09-29 07:31:28 - epoch 129 lr: 0.001032
2022-09-29 07:31:59 - train: epoch 0129, iter [00010, 01251], lr: 0.001032, loss: 0.4346
2022-09-29 07:32:17 - train: epoch 0129, iter [00020, 01251], lr: 0.001032, loss: 0.4198
2022-09-29 07:32:35 - train: epoch 0129, iter [00030, 01251], lr: 0.001032, loss: 0.4170
2022-09-29 07:32:53 - train: epoch 0129, iter [00040, 01251], lr: 0.001031, loss: 0.4206
2022-09-29 07:33:10 - train: epoch 0129, iter [00050, 01251], lr: 0.001031, loss: 0.3987
2022-09-29 07:33:28 - train: epoch 0129, iter [00060, 01251], lr: 0.001031, loss: 0.3833
2022-09-29 07:33:46 - train: epoch 0129, iter [00070, 01251], lr: 0.001031, loss: 0.3985
2022-09-29 07:34:04 - train: epoch 0129, iter [00080, 01251], lr: 0.001031, loss: 0.4074
2022-09-29 07:34:22 - train: epoch 0129, iter [00090, 01251], lr: 0.001031, loss: 0.4122
2022-09-29 07:34:40 - train: epoch 0129, iter [00100, 01251], lr: 0.001031, loss: 0.4148
2022-09-29 07:34:57 - train: epoch 0129, iter [00110, 01251], lr: 0.001031, loss: 0.4089
2022-09-29 07:35:15 - train: epoch 0129, iter [00120, 01251], lr: 0.001031, loss: 0.4068
2022-09-29 07:35:33 - train: epoch 0129, iter [00130, 01251], lr: 0.001031, loss: 0.3949
2022-09-29 07:35:51 - train: epoch 0129, iter [00140, 01251], lr: 0.001031, loss: 0.4153
2022-09-29 07:36:08 - train: epoch 0129, iter [00150, 01251], lr: 0.001031, loss: 0.4175
2022-09-29 07:36:26 - train: epoch 0129, iter [00160, 01251], lr: 0.001031, loss: 0.4130
2022-09-29 07:36:44 - train: epoch 0129, iter [00170, 01251], lr: 0.001031, loss: 0.3997
2022-09-29 07:37:01 - train: epoch 0129, iter [00180, 01251], lr: 0.001031, loss: 0.4151
2022-09-29 07:37:19 - train: epoch 0129, iter [00190, 01251], lr: 0.001031, loss: 0.4323
2022-09-29 07:37:37 - train: epoch 0129, iter [00200, 01251], lr: 0.001031, loss: 0.4050
2022-09-29 07:37:54 - train: epoch 0129, iter [00210, 01251], lr: 0.001031, loss: 0.4118
2022-09-29 07:38:12 - train: epoch 0129, iter [00220, 01251], lr: 0.001031, loss: 0.4082
2022-09-29 07:38:30 - train: epoch 0129, iter [00230, 01251], lr: 0.001031, loss: 0.4230
2022-09-29 07:38:47 - train: epoch 0129, iter [00240, 01251], lr: 0.001031, loss: 0.4311
2022-09-29 07:39:05 - train: epoch 0129, iter [00250, 01251], lr: 0.001031, loss: 0.3976
2022-09-29 07:39:23 - train: epoch 0129, iter [00260, 01251], lr: 0.001031, loss: 0.4061
2022-09-29 07:39:41 - train: epoch 0129, iter [00270, 01251], lr: 0.001031, loss: 0.3959
2022-09-29 07:39:58 - train: epoch 0129, iter [00280, 01251], lr: 0.001031, loss: 0.4206
2022-09-29 07:40:16 - train: epoch 0129, iter [00290, 01251], lr: 0.001031, loss: 0.4230
2022-09-29 07:40:34 - train: epoch 0129, iter [00300, 01251], lr: 0.001031, loss: 0.4044
2022-09-29 07:40:51 - train: epoch 0129, iter [00310, 01251], lr: 0.001031, loss: 0.4039
2022-09-29 07:41:09 - train: epoch 0129, iter [00320, 01251], lr: 0.001031, loss: 0.4009
2022-09-29 07:41:27 - train: epoch 0129, iter [00330, 01251], lr: 0.001031, loss: 0.3981
2022-09-29 07:41:44 - train: epoch 0129, iter [00340, 01251], lr: 0.001031, loss: 0.4021
2022-09-29 07:42:02 - train: epoch 0129, iter [00350, 01251], lr: 0.001031, loss: 0.4148
2022-09-29 07:42:20 - train: epoch 0129, iter [00360, 01251], lr: 0.001031, loss: 0.4247
2022-09-29 07:42:38 - train: epoch 0129, iter [00370, 01251], lr: 0.001031, loss: 0.4144
2022-09-29 07:42:55 - train: epoch 0129, iter [00380, 01251], lr: 0.001030, loss: 0.4290
2022-09-29 07:43:13 - train: epoch 0129, iter [00390, 01251], lr: 0.001030, loss: 0.4040
2022-09-29 07:43:31 - train: epoch 0129, iter [00400, 01251], lr: 0.001030, loss: 0.3974
2022-09-29 07:43:49 - train: epoch 0129, iter [00410, 01251], lr: 0.001030, loss: 0.4112
2022-09-29 07:44:06 - train: epoch 0129, iter [00420, 01251], lr: 0.001030, loss: 0.4102
2022-09-29 07:44:24 - train: epoch 0129, iter [00430, 01251], lr: 0.001030, loss: 0.4129
2022-09-29 07:44:42 - train: epoch 0129, iter [00440, 01251], lr: 0.001030, loss: 0.4013
2022-09-29 07:44:59 - train: epoch 0129, iter [00450, 01251], lr: 0.001030, loss: 0.4139
2022-09-29 07:45:17 - train: epoch 0129, iter [00460, 01251], lr: 0.001030, loss: 0.4093
2022-09-29 07:45:35 - train: epoch 0129, iter [00470, 01251], lr: 0.001030, loss: 0.4127
2022-09-29 07:45:53 - train: epoch 0129, iter [00480, 01251], lr: 0.001030, loss: 0.4139
2022-09-29 07:46:10 - train: epoch 0129, iter [00490, 01251], lr: 0.001030, loss: 0.4180
2022-09-29 07:46:28 - train: epoch 0129, iter [00500, 01251], lr: 0.001030, loss: 0.4309
2022-09-29 07:46:46 - train: epoch 0129, iter [00510, 01251], lr: 0.001030, loss: 0.4101
2022-09-29 07:47:04 - train: epoch 0129, iter [00520, 01251], lr: 0.001030, loss: 0.4082
2022-09-29 07:47:22 - train: epoch 0129, iter [00530, 01251], lr: 0.001030, loss: 0.4295
2022-09-29 07:47:40 - train: epoch 0129, iter [00540, 01251], lr: 0.001030, loss: 0.4171
2022-09-29 07:47:57 - train: epoch 0129, iter [00550, 01251], lr: 0.001030, loss: 0.4107
2022-09-29 07:48:15 - train: epoch 0129, iter [00560, 01251], lr: 0.001030, loss: 0.4233
2022-09-29 07:48:32 - train: epoch 0129, iter [00570, 01251], lr: 0.001030, loss: 0.4087
2022-09-29 07:48:50 - train: epoch 0129, iter [00580, 01251], lr: 0.001030, loss: 0.4151
2022-09-29 07:49:08 - train: epoch 0129, iter [00590, 01251], lr: 0.001030, loss: 0.4041
2022-09-29 07:49:26 - train: epoch 0129, iter [00600, 01251], lr: 0.001030, loss: 0.4089
2022-09-29 07:49:44 - train: epoch 0129, iter [00610, 01251], lr: 0.001030, loss: 0.4142
2022-09-29 07:50:01 - train: epoch 0129, iter [00620, 01251], lr: 0.001030, loss: 0.4176
2022-09-29 07:50:19 - train: epoch 0129, iter [00630, 01251], lr: 0.001030, loss: 0.3998
2022-09-29 07:50:37 - train: epoch 0129, iter [00640, 01251], lr: 0.001030, loss: 0.4121
2022-09-29 07:50:55 - train: epoch 0129, iter [00650, 01251], lr: 0.001030, loss: 0.4136
2022-09-29 07:51:12 - train: epoch 0129, iter [00660, 01251], lr: 0.001030, loss: 0.4030
2022-09-29 07:51:30 - train: epoch 0129, iter [00670, 01251], lr: 0.001030, loss: 0.4309
2022-09-29 07:51:48 - train: epoch 0129, iter [00680, 01251], lr: 0.001030, loss: 0.4414
2022-09-29 07:52:06 - train: epoch 0129, iter [00690, 01251], lr: 0.001030, loss: 0.4010
2022-09-29 07:52:23 - train: epoch 0129, iter [00700, 01251], lr: 0.001030, loss: 0.4187
2022-09-29 07:52:41 - train: epoch 0129, iter [00710, 01251], lr: 0.001030, loss: 0.3984
2022-09-29 07:52:59 - train: epoch 0129, iter [00720, 01251], lr: 0.001030, loss: 0.4046
2022-09-29 07:53:16 - train: epoch 0129, iter [00730, 01251], lr: 0.001029, loss: 0.4061
2022-09-29 07:53:34 - train: epoch 0129, iter [00740, 01251], lr: 0.001029, loss: 0.4267
2022-09-29 07:53:52 - train: epoch 0129, iter [00750, 01251], lr: 0.001029, loss: 0.3985
2022-09-29 07:54:09 - train: epoch 0129, iter [00760, 01251], lr: 0.001029, loss: 0.4225
2022-09-29 07:54:27 - train: epoch 0129, iter [00770, 01251], lr: 0.001029, loss: 0.3946
2022-09-29 07:54:45 - train: epoch 0129, iter [00780, 01251], lr: 0.001029, loss: 0.4087
2022-09-29 07:55:03 - train: epoch 0129, iter [00790, 01251], lr: 0.001029, loss: 0.4179
2022-09-29 07:55:20 - train: epoch 0129, iter [00800, 01251], lr: 0.001029, loss: 0.4122
2022-09-29 07:55:38 - train: epoch 0129, iter [00810, 01251], lr: 0.001029, loss: 0.3961
2022-09-29 07:55:56 - train: epoch 0129, iter [00820, 01251], lr: 0.001029, loss: 0.4016
2022-09-29 07:56:14 - train: epoch 0129, iter [00830, 01251], lr: 0.001029, loss: 0.4303
2022-09-29 07:56:31 - train: epoch 0129, iter [00840, 01251], lr: 0.001029, loss: 0.4048
2022-09-29 07:56:49 - train: epoch 0129, iter [00850, 01251], lr: 0.001029, loss: 0.3962
2022-09-29 07:57:07 - train: epoch 0129, iter [00860, 01251], lr: 0.001029, loss: 0.4097
2022-09-29 07:57:24 - train: epoch 0129, iter [00870, 01251], lr: 0.001029, loss: 0.4278
2022-09-29 07:57:42 - train: epoch 0129, iter [00880, 01251], lr: 0.001029, loss: 0.4072
2022-09-29 07:58:00 - train: epoch 0129, iter [00890, 01251], lr: 0.001029, loss: 0.4177
2022-09-29 07:58:18 - train: epoch 0129, iter [00900, 01251], lr: 0.001029, loss: 0.3970
2022-09-29 07:58:35 - train: epoch 0129, iter [00910, 01251], lr: 0.001029, loss: 0.4152
2022-09-29 07:58:53 - train: epoch 0129, iter [00920, 01251], lr: 0.001029, loss: 0.4057
2022-09-29 07:59:11 - train: epoch 0129, iter [00930, 01251], lr: 0.001029, loss: 0.4183
2022-09-29 07:59:28 - train: epoch 0129, iter [00940, 01251], lr: 0.001029, loss: 0.3891
2022-09-29 07:59:46 - train: epoch 0129, iter [00950, 01251], lr: 0.001029, loss: 0.4231
2022-09-29 08:00:04 - train: epoch 0129, iter [00960, 01251], lr: 0.001029, loss: 0.4082
2022-09-29 08:00:22 - train: epoch 0129, iter [00970, 01251], lr: 0.001029, loss: 0.4298
2022-09-29 08:00:39 - train: epoch 0129, iter [00980, 01251], lr: 0.001029, loss: 0.4062
2022-09-29 08:00:57 - train: epoch 0129, iter [00990, 01251], lr: 0.001029, loss: 0.4152
2022-09-29 08:01:15 - train: epoch 0129, iter [01000, 01251], lr: 0.001029, loss: 0.4181
2022-09-29 08:01:32 - train: epoch 0129, iter [01010, 01251], lr: 0.001029, loss: 0.4061
2022-09-29 08:01:50 - train: epoch 0129, iter [01020, 01251], lr: 0.001029, loss: 0.4038
2022-09-29 08:02:08 - train: epoch 0129, iter [01030, 01251], lr: 0.001029, loss: 0.3952
2022-09-29 08:02:26 - train: epoch 0129, iter [01040, 01251], lr: 0.001029, loss: 0.4060
2022-09-29 08:02:43 - train: epoch 0129, iter [01050, 01251], lr: 0.001029, loss: 0.4115
2022-09-29 08:03:01 - train: epoch 0129, iter [01060, 01251], lr: 0.001029, loss: 0.3962
2022-09-29 08:03:19 - train: epoch 0129, iter [01070, 01251], lr: 0.001028, loss: 0.4226
2022-09-29 08:03:36 - train: epoch 0129, iter [01080, 01251], lr: 0.001028, loss: 0.4121
2022-09-29 08:03:54 - train: epoch 0129, iter [01090, 01251], lr: 0.001028, loss: 0.3936
2022-09-29 08:04:12 - train: epoch 0129, iter [01100, 01251], lr: 0.001028, loss: 0.4066
2022-09-29 08:04:30 - train: epoch 0129, iter [01110, 01251], lr: 0.001028, loss: 0.4118
2022-09-29 08:04:48 - train: epoch 0129, iter [01120, 01251], lr: 0.001028, loss: 0.4066
2022-09-29 08:05:05 - train: epoch 0129, iter [01130, 01251], lr: 0.001028, loss: 0.4093
2022-09-29 08:05:23 - train: epoch 0129, iter [01140, 01251], lr: 0.001028, loss: 0.4192
2022-09-29 08:05:41 - train: epoch 0129, iter [01150, 01251], lr: 0.001028, loss: 0.4071
2022-09-29 08:05:58 - train: epoch 0129, iter [01160, 01251], lr: 0.001028, loss: 0.4087
2022-09-29 08:06:16 - train: epoch 0129, iter [01170, 01251], lr: 0.001028, loss: 0.3894
2022-09-29 08:06:34 - train: epoch 0129, iter [01180, 01251], lr: 0.001028, loss: 0.4163
2022-09-29 08:06:51 - train: epoch 0129, iter [01190, 01251], lr: 0.001028, loss: 0.3990
2022-09-29 08:07:09 - train: epoch 0129, iter [01200, 01251], lr: 0.001028, loss: 0.4074
2022-09-29 08:07:27 - train: epoch 0129, iter [01210, 01251], lr: 0.001028, loss: 0.4158
2022-09-29 08:07:45 - train: epoch 0129, iter [01220, 01251], lr: 0.001028, loss: 0.4148
2022-09-29 08:08:02 - train: epoch 0129, iter [01230, 01251], lr: 0.001028, loss: 0.4162
2022-09-29 08:08:20 - train: epoch 0129, iter [01240, 01251], lr: 0.001028, loss: 0.3921
2022-09-29 08:08:37 - train: epoch 0129, iter [01250, 01251], lr: 0.001028, loss: 0.4212
2022-09-29 08:08:41 - train: epoch 129, train_loss: 0.4117
2022-09-29 08:08:44 - until epoch: 129, best_loss: 0.4117
2022-09-29 08:08:44 - epoch 130 lr: 0.001028
2022-09-29 08:09:16 - train: epoch 0130, iter [00010, 01251], lr: 0.001028, loss: 0.4163
2022-09-29 08:09:34 - train: epoch 0130, iter [00020, 01251], lr: 0.001028, loss: 0.3856
2022-09-29 08:09:52 - train: epoch 0130, iter [00030, 01251], lr: 0.001028, loss: 0.4049
2022-09-29 08:10:10 - train: epoch 0130, iter [00040, 01251], lr: 0.001028, loss: 0.4044
2022-09-29 08:10:27 - train: epoch 0130, iter [00050, 01251], lr: 0.001028, loss: 0.4213
2022-09-29 08:10:46 - train: epoch 0130, iter [00060, 01251], lr: 0.001028, loss: 0.4229
2022-09-29 08:11:03 - train: epoch 0130, iter [00070, 01251], lr: 0.001028, loss: 0.4145
2022-09-29 08:11:21 - train: epoch 0130, iter [00080, 01251], lr: 0.001028, loss: 0.4316
2022-09-29 08:11:39 - train: epoch 0130, iter [00090, 01251], lr: 0.001028, loss: 0.4087
2022-09-29 08:11:57 - train: epoch 0130, iter [00100, 01251], lr: 0.001028, loss: 0.4027
2022-09-29 08:12:15 - train: epoch 0130, iter [00110, 01251], lr: 0.001028, loss: 0.3942
2022-09-29 08:12:32 - train: epoch 0130, iter [00120, 01251], lr: 0.001028, loss: 0.4248
2022-09-29 08:12:50 - train: epoch 0130, iter [00130, 01251], lr: 0.001028, loss: 0.4091
2022-09-29 08:13:08 - train: epoch 0130, iter [00140, 01251], lr: 0.001028, loss: 0.4038
2022-09-29 08:13:26 - train: epoch 0130, iter [00150, 01251], lr: 0.001028, loss: 0.4153
2022-09-29 08:13:44 - train: epoch 0130, iter [00160, 01251], lr: 0.001027, loss: 0.4054
2022-09-29 08:14:01 - train: epoch 0130, iter [00170, 01251], lr: 0.001027, loss: 0.4064
2022-09-29 08:14:19 - train: epoch 0130, iter [00180, 01251], lr: 0.001027, loss: 0.4073
2022-09-29 08:14:37 - train: epoch 0130, iter [00190, 01251], lr: 0.001027, loss: 0.4226
2022-09-29 08:14:55 - train: epoch 0130, iter [00200, 01251], lr: 0.001027, loss: 0.4250
2022-09-29 08:15:13 - train: epoch 0130, iter [00210, 01251], lr: 0.001027, loss: 0.4010
2022-09-29 08:15:31 - train: epoch 0130, iter [00220, 01251], lr: 0.001027, loss: 0.4271
2022-09-29 08:15:48 - train: epoch 0130, iter [00230, 01251], lr: 0.001027, loss: 0.4231
2022-09-29 08:16:06 - train: epoch 0130, iter [00240, 01251], lr: 0.001027, loss: 0.4019
2022-09-29 08:16:24 - train: epoch 0130, iter [00250, 01251], lr: 0.001027, loss: 0.4278
2022-09-29 08:16:42 - train: epoch 0130, iter [00260, 01251], lr: 0.001027, loss: 0.4098
2022-09-29 08:17:00 - train: epoch 0130, iter [00270, 01251], lr: 0.001027, loss: 0.4166
2022-09-29 08:17:18 - train: epoch 0130, iter [00280, 01251], lr: 0.001027, loss: 0.4007
2022-09-29 08:17:36 - train: epoch 0130, iter [00290, 01251], lr: 0.001027, loss: 0.4031
2022-09-29 08:17:53 - train: epoch 0130, iter [00300, 01251], lr: 0.001027, loss: 0.4339
2022-09-29 08:18:11 - train: epoch 0130, iter [00310, 01251], lr: 0.001027, loss: 0.4323
2022-09-29 08:18:29 - train: epoch 0130, iter [00320, 01251], lr: 0.001027, loss: 0.4180
2022-09-29 08:18:47 - train: epoch 0130, iter [00330, 01251], lr: 0.001027, loss: 0.4103
2022-09-29 08:19:05 - train: epoch 0130, iter [00340, 01251], lr: 0.001027, loss: 0.4160
2022-09-29 08:19:22 - train: epoch 0130, iter [00350, 01251], lr: 0.001027, loss: 0.4224
2022-09-29 08:19:40 - train: epoch 0130, iter [00360, 01251], lr: 0.001027, loss: 0.4210
2022-09-29 08:19:58 - train: epoch 0130, iter [00370, 01251], lr: 0.001027, loss: 0.3750
2022-09-29 08:20:16 - train: epoch 0130, iter [00380, 01251], lr: 0.001027, loss: 0.4097
2022-09-29 08:20:33 - train: epoch 0130, iter [00390, 01251], lr: 0.001027, loss: 0.3855
2022-09-29 08:20:51 - train: epoch 0130, iter [00400, 01251], lr: 0.001027, loss: 0.4089
2022-09-29 08:21:09 - train: epoch 0130, iter [00410, 01251], lr: 0.001027, loss: 0.3868
2022-09-29 08:21:27 - train: epoch 0130, iter [00420, 01251], lr: 0.001027, loss: 0.4069
2022-09-29 08:21:44 - train: epoch 0130, iter [00430, 01251], lr: 0.001027, loss: 0.4409
2022-09-29 08:22:02 - train: epoch 0130, iter [00440, 01251], lr: 0.001027, loss: 0.4012
2022-09-29 08:22:20 - train: epoch 0130, iter [00450, 01251], lr: 0.001027, loss: 0.4165
2022-09-29 08:22:38 - train: epoch 0130, iter [00460, 01251], lr: 0.001027, loss: 0.3997
2022-09-29 08:22:55 - train: epoch 0130, iter [00470, 01251], lr: 0.001027, loss: 0.4330
2022-09-29 08:23:13 - train: epoch 0130, iter [00480, 01251], lr: 0.001027, loss: 0.3950
2022-09-29 08:23:31 - train: epoch 0130, iter [00490, 01251], lr: 0.001027, loss: 0.4172
2022-09-29 08:23:48 - train: epoch 0130, iter [00500, 01251], lr: 0.001026, loss: 0.4287
2022-09-29 08:24:06 - train: epoch 0130, iter [00510, 01251], lr: 0.001026, loss: 0.4070
2022-09-29 08:24:24 - train: epoch 0130, iter [00520, 01251], lr: 0.001026, loss: 0.4076
2022-09-29 08:24:41 - train: epoch 0130, iter [00530, 01251], lr: 0.001026, loss: 0.3977
2022-09-29 08:24:59 - train: epoch 0130, iter [00540, 01251], lr: 0.001026, loss: 0.4201
2022-09-29 08:25:17 - train: epoch 0130, iter [00550, 01251], lr: 0.001026, loss: 0.4065
2022-09-29 08:25:35 - train: epoch 0130, iter [00560, 01251], lr: 0.001026, loss: 0.4186
2022-09-29 08:25:53 - train: epoch 0130, iter [00570, 01251], lr: 0.001026, loss: 0.3897
2022-09-29 08:26:10 - train: epoch 0130, iter [00580, 01251], lr: 0.001026, loss: 0.4027
2022-09-29 08:26:28 - train: epoch 0130, iter [00590, 01251], lr: 0.001026, loss: 0.4206
2022-09-29 08:26:45 - train: epoch 0130, iter [00600, 01251], lr: 0.001026, loss: 0.4361
2022-09-29 08:27:03 - train: epoch 0130, iter [00610, 01251], lr: 0.001026, loss: 0.4359
2022-09-29 08:27:21 - train: epoch 0130, iter [00620, 01251], lr: 0.001026, loss: 0.3880
2022-09-29 08:27:39 - train: epoch 0130, iter [00630, 01251], lr: 0.001026, loss: 0.4435
2022-09-29 08:27:57 - train: epoch 0130, iter [00640, 01251], lr: 0.001026, loss: 0.4137
2022-09-29 08:28:14 - train: epoch 0130, iter [00650, 01251], lr: 0.001026, loss: 0.4120
2022-09-29 08:28:32 - train: epoch 0130, iter [00660, 01251], lr: 0.001026, loss: 0.4132
2022-09-29 08:28:50 - train: epoch 0130, iter [00670, 01251], lr: 0.001026, loss: 0.4301
2022-09-29 08:29:08 - train: epoch 0130, iter [00680, 01251], lr: 0.001026, loss: 0.4004
2022-09-29 08:29:25 - train: epoch 0130, iter [00690, 01251], lr: 0.001026, loss: 0.4157
2022-09-29 08:29:43 - train: epoch 0130, iter [00700, 01251], lr: 0.001026, loss: 0.4041
2022-09-29 08:30:01 - train: epoch 0130, iter [00710, 01251], lr: 0.001026, loss: 0.4126
2022-09-29 08:30:19 - train: epoch 0130, iter [00720, 01251], lr: 0.001026, loss: 0.4141
2022-09-29 08:30:36 - train: epoch 0130, iter [00730, 01251], lr: 0.001026, loss: 0.4213
2022-09-29 08:30:54 - train: epoch 0130, iter [00740, 01251], lr: 0.001026, loss: 0.3938
2022-09-29 08:31:12 - train: epoch 0130, iter [00750, 01251], lr: 0.001026, loss: 0.4027
2022-09-29 08:31:30 - train: epoch 0130, iter [00760, 01251], lr: 0.001026, loss: 0.4106
2022-09-29 08:31:47 - train: epoch 0130, iter [00770, 01251], lr: 0.001026, loss: 0.4145
2022-09-29 08:32:05 - train: epoch 0130, iter [00780, 01251], lr: 0.001026, loss: 0.4080
2022-09-29 08:32:23 - train: epoch 0130, iter [00790, 01251], lr: 0.001026, loss: 0.4242
2022-09-29 08:32:41 - train: epoch 0130, iter [00800, 01251], lr: 0.001026, loss: 0.4035
2022-09-29 08:32:58 - train: epoch 0130, iter [00810, 01251], lr: 0.001026, loss: 0.4129
2022-09-29 08:33:16 - train: epoch 0130, iter [00820, 01251], lr: 0.001026, loss: 0.4213
2022-09-29 08:33:34 - train: epoch 0130, iter [00830, 01251], lr: 0.001026, loss: 0.4188
2022-09-29 08:33:51 - train: epoch 0130, iter [00840, 01251], lr: 0.001025, loss: 0.3912
2022-09-29 08:34:09 - train: epoch 0130, iter [00850, 01251], lr: 0.001025, loss: 0.4163
2022-09-29 08:34:27 - train: epoch 0130, iter [00860, 01251], lr: 0.001025, loss: 0.4061
2022-09-29 08:34:45 - train: epoch 0130, iter [00870, 01251], lr: 0.001025, loss: 0.4066
2022-09-29 08:35:03 - train: epoch 0130, iter [00880, 01251], lr: 0.001025, loss: 0.3920
2022-09-29 08:35:20 - train: epoch 0130, iter [00890, 01251], lr: 0.001025, loss: 0.4217
2022-09-29 08:35:38 - train: epoch 0130, iter [00900, 01251], lr: 0.001025, loss: 0.4174
2022-09-29 08:35:56 - train: epoch 0130, iter [00910, 01251], lr: 0.001025, loss: 0.4054
2022-09-29 08:36:14 - train: epoch 0130, iter [00920, 01251], lr: 0.001025, loss: 0.4104
2022-09-29 08:36:31 - train: epoch 0130, iter [00930, 01251], lr: 0.001025, loss: 0.4051
2022-09-29 08:36:49 - train: epoch 0130, iter [00940, 01251], lr: 0.001025, loss: 0.4125
2022-09-29 08:37:07 - train: epoch 0130, iter [00950, 01251], lr: 0.001025, loss: 0.4034
2022-09-29 08:37:25 - train: epoch 0130, iter [00960, 01251], lr: 0.001025, loss: 0.4086
2022-09-29 08:37:43 - train: epoch 0130, iter [00970, 01251], lr: 0.001025, loss: 0.4137
2022-09-29 08:38:00 - train: epoch 0130, iter [00980, 01251], lr: 0.001025, loss: 0.4087
2022-09-29 08:38:18 - train: epoch 0130, iter [00990, 01251], lr: 0.001025, loss: 0.4038
2022-09-29 08:38:36 - train: epoch 0130, iter [01000, 01251], lr: 0.001025, loss: 0.4156
2022-09-29 08:38:53 - train: epoch 0130, iter [01010, 01251], lr: 0.001025, loss: 0.4037
2022-09-29 08:39:11 - train: epoch 0130, iter [01020, 01251], lr: 0.001025, loss: 0.4088
2022-09-29 08:39:29 - train: epoch 0130, iter [01030, 01251], lr: 0.001025, loss: 0.4218
2022-09-29 08:39:47 - train: epoch 0130, iter [01040, 01251], lr: 0.001025, loss: 0.4177
2022-09-29 08:40:05 - train: epoch 0130, iter [01050, 01251], lr: 0.001025, loss: 0.3962
2022-09-29 08:40:22 - train: epoch 0130, iter [01060, 01251], lr: 0.001025, loss: 0.3780
2022-09-29 08:40:40 - train: epoch 0130, iter [01070, 01251], lr: 0.001025, loss: 0.4068
2022-09-29 08:40:58 - train: epoch 0130, iter [01080, 01251], lr: 0.001025, loss: 0.4100
2022-09-29 08:41:15 - train: epoch 0130, iter [01090, 01251], lr: 0.001025, loss: 0.4176
2022-09-29 08:41:33 - train: epoch 0130, iter [01100, 01251], lr: 0.001025, loss: 0.3959
2022-09-29 08:41:51 - train: epoch 0130, iter [01110, 01251], lr: 0.001025, loss: 0.4106
2022-09-29 08:42:09 - train: epoch 0130, iter [01120, 01251], lr: 0.001025, loss: 0.4169
2022-09-29 08:42:26 - train: epoch 0130, iter [01130, 01251], lr: 0.001025, loss: 0.4002
2022-09-29 08:42:44 - train: epoch 0130, iter [01140, 01251], lr: 0.001025, loss: 0.4279
2022-09-29 08:43:02 - train: epoch 0130, iter [01150, 01251], lr: 0.001025, loss: 0.4202
2022-09-29 08:43:20 - train: epoch 0130, iter [01160, 01251], lr: 0.001025, loss: 0.4154
2022-09-29 08:43:37 - train: epoch 0130, iter [01170, 01251], lr: 0.001025, loss: 0.4063
2022-09-29 08:43:55 - train: epoch 0130, iter [01180, 01251], lr: 0.001024, loss: 0.3943
2022-09-29 08:44:13 - train: epoch 0130, iter [01190, 01251], lr: 0.001024, loss: 0.4098
2022-09-29 08:44:31 - train: epoch 0130, iter [01200, 01251], lr: 0.001024, loss: 0.4251
2022-09-29 08:44:48 - train: epoch 0130, iter [01210, 01251], lr: 0.001024, loss: 0.3884
2022-09-29 08:45:06 - train: epoch 0130, iter [01220, 01251], lr: 0.001024, loss: 0.4203
2022-09-29 08:45:24 - train: epoch 0130, iter [01230, 01251], lr: 0.001024, loss: 0.4132
2022-09-29 08:45:42 - train: epoch 0130, iter [01240, 01251], lr: 0.001024, loss: 0.4128
2022-09-29 08:45:59 - train: epoch 0130, iter [01250, 01251], lr: 0.001024, loss: 0.3962
2022-09-29 08:46:03 - train: epoch 130, train_loss: 0.4116
2022-09-29 08:46:05 - until epoch: 130, best_loss: 0.4116
2022-09-29 08:46:05 - epoch 131 lr: 0.001024
2022-09-29 08:46:38 - train: epoch 0131, iter [00010, 01251], lr: 0.001024, loss: 0.4210
2022-09-29 08:46:56 - train: epoch 0131, iter [00020, 01251], lr: 0.001024, loss: 0.3840
2022-09-29 08:47:13 - train: epoch 0131, iter [00030, 01251], lr: 0.001024, loss: 0.4071
2022-09-29 08:47:31 - train: epoch 0131, iter [00040, 01251], lr: 0.001024, loss: 0.3924
2022-09-29 08:47:49 - train: epoch 0131, iter [00050, 01251], lr: 0.001024, loss: 0.4155
2022-09-29 08:48:07 - train: epoch 0131, iter [00060, 01251], lr: 0.001024, loss: 0.4167
2022-09-29 08:48:24 - train: epoch 0131, iter [00070, 01251], lr: 0.001024, loss: 0.4081
2022-09-29 08:48:42 - train: epoch 0131, iter [00080, 01251], lr: 0.001024, loss: 0.3939
2022-09-29 08:49:00 - train: epoch 0131, iter [00090, 01251], lr: 0.001024, loss: 0.4258
2022-09-29 08:49:17 - train: epoch 0131, iter [00100, 01251], lr: 0.001024, loss: 0.4127
2022-09-29 08:49:35 - train: epoch 0131, iter [00110, 01251], lr: 0.001024, loss: 0.3962
2022-09-29 08:49:53 - train: epoch 0131, iter [00120, 01251], lr: 0.001024, loss: 0.4153
2022-09-29 08:50:10 - train: epoch 0131, iter [00130, 01251], lr: 0.001024, loss: 0.4183
2022-09-29 08:50:28 - train: epoch 0131, iter [00140, 01251], lr: 0.001024, loss: 0.4146
2022-09-29 08:50:46 - train: epoch 0131, iter [00150, 01251], lr: 0.001024, loss: 0.4003
2022-09-29 08:51:03 - train: epoch 0131, iter [00160, 01251], lr: 0.001024, loss: 0.4199
2022-09-29 08:51:21 - train: epoch 0131, iter [00170, 01251], lr: 0.001024, loss: 0.3919
2022-09-29 08:51:39 - train: epoch 0131, iter [00180, 01251], lr: 0.001024, loss: 0.4140
2022-09-29 08:51:56 - train: epoch 0131, iter [00190, 01251], lr: 0.001024, loss: 0.4203
2022-09-29 08:52:14 - train: epoch 0131, iter [00200, 01251], lr: 0.001024, loss: 0.4117
2022-09-29 08:52:32 - train: epoch 0131, iter [00210, 01251], lr: 0.001024, loss: 0.4018
2022-09-29 08:52:50 - train: epoch 0131, iter [00220, 01251], lr: 0.001024, loss: 0.4103
2022-09-29 08:53:07 - train: epoch 0131, iter [00230, 01251], lr: 0.001024, loss: 0.4009
2022-09-29 08:53:25 - train: epoch 0131, iter [00240, 01251], lr: 0.001024, loss: 0.4017
2022-09-29 08:53:43 - train: epoch 0131, iter [00250, 01251], lr: 0.001024, loss: 0.3977
2022-09-29 08:54:01 - train: epoch 0131, iter [00260, 01251], lr: 0.001023, loss: 0.4269
2022-09-29 08:54:18 - train: epoch 0131, iter [00270, 01251], lr: 0.001023, loss: 0.4157
2022-09-29 08:54:36 - train: epoch 0131, iter [00280, 01251], lr: 0.001023, loss: 0.3952
2022-09-29 08:54:54 - train: epoch 0131, iter [00290, 01251], lr: 0.001023, loss: 0.4242
2022-09-29 08:55:11 - train: epoch 0131, iter [00300, 01251], lr: 0.001023, loss: 0.3888
2022-09-29 08:55:29 - train: epoch 0131, iter [00310, 01251], lr: 0.001023, loss: 0.4208
2022-09-29 08:55:47 - train: epoch 0131, iter [00320, 01251], lr: 0.001023, loss: 0.4262
2022-09-29 08:56:04 - train: epoch 0131, iter [00330, 01251], lr: 0.001023, loss: 0.4043
2022-09-29 08:56:22 - train: epoch 0131, iter [00340, 01251], lr: 0.001023, loss: 0.4177
2022-09-29 08:56:40 - train: epoch 0131, iter [00350, 01251], lr: 0.001023, loss: 0.4029
2022-09-29 08:56:57 - train: epoch 0131, iter [00360, 01251], lr: 0.001023, loss: 0.4010
2022-09-29 08:57:15 - train: epoch 0131, iter [00370, 01251], lr: 0.001023, loss: 0.4267
2022-09-29 08:57:32 - train: epoch 0131, iter [00380, 01251], lr: 0.001023, loss: 0.4028
2022-09-29 08:57:50 - train: epoch 0131, iter [00390, 01251], lr: 0.001023, loss: 0.4083
2022-09-29 08:58:08 - train: epoch 0131, iter [00400, 01251], lr: 0.001023, loss: 0.3979
2022-09-29 08:58:25 - train: epoch 0131, iter [00410, 01251], lr: 0.001023, loss: 0.4109
2022-09-29 08:58:43 - train: epoch 0131, iter [00420, 01251], lr: 0.001023, loss: 0.4199
2022-09-29 08:59:01 - train: epoch 0131, iter [00430, 01251], lr: 0.001023, loss: 0.3924
2022-09-29 08:59:18 - train: epoch 0131, iter [00440, 01251], lr: 0.001023, loss: 0.4194
2022-09-29 08:59:36 - train: epoch 0131, iter [00450, 01251], lr: 0.001023, loss: 0.4082
2022-09-29 08:59:54 - train: epoch 0131, iter [00460, 01251], lr: 0.001023, loss: 0.4079
2022-09-29 09:00:11 - train: epoch 0131, iter [00470, 01251], lr: 0.001023, loss: 0.4125
2022-09-29 09:00:29 - train: epoch 0131, iter [00480, 01251], lr: 0.001023, loss: 0.3941
2022-09-29 09:00:47 - train: epoch 0131, iter [00490, 01251], lr: 0.001023, loss: 0.4163
2022-09-29 09:01:04 - train: epoch 0131, iter [00500, 01251], lr: 0.001023, loss: 0.4368
2022-09-29 09:01:22 - train: epoch 0131, iter [00510, 01251], lr: 0.001023, loss: 0.4153
2022-09-29 09:01:40 - train: epoch 0131, iter [00520, 01251], lr: 0.001023, loss: 0.4043
2022-09-29 09:01:58 - train: epoch 0131, iter [00530, 01251], lr: 0.001023, loss: 0.4028
2022-09-29 09:02:15 - train: epoch 0131, iter [00540, 01251], lr: 0.001023, loss: 0.4016
2022-09-29 09:02:33 - train: epoch 0131, iter [00550, 01251], lr: 0.001023, loss: 0.4126
2022-09-29 09:02:50 - train: epoch 0131, iter [00560, 01251], lr: 0.001023, loss: 0.4263
2022-09-29 09:03:08 - train: epoch 0131, iter [00570, 01251], lr: 0.001023, loss: 0.4148
2022-09-29 09:03:26 - train: epoch 0131, iter [00580, 01251], lr: 0.001023, loss: 0.4188
2022-09-29 09:03:44 - train: epoch 0131, iter [00590, 01251], lr: 0.001023, loss: 0.4058
2022-09-29 09:04:02 - train: epoch 0131, iter [00600, 01251], lr: 0.001022, loss: 0.4267
2022-09-29 09:04:19 - train: epoch 0131, iter [00610, 01251], lr: 0.001022, loss: 0.4208
2022-09-29 09:04:37 - train: epoch 0131, iter [00620, 01251], lr: 0.001022, loss: 0.4162
2022-09-29 09:04:54 - train: epoch 0131, iter [00630, 01251], lr: 0.001022, loss: 0.4102
2022-09-29 09:05:12 - train: epoch 0131, iter [00640, 01251], lr: 0.001022, loss: 0.4175
2022-09-29 09:05:30 - train: epoch 0131, iter [00650, 01251], lr: 0.001022, loss: 0.4275
2022-09-29 09:05:47 - train: epoch 0131, iter [00660, 01251], lr: 0.001022, loss: 0.3853
2022-09-29 09:06:05 - train: epoch 0131, iter [00670, 01251], lr: 0.001022, loss: 0.4152
2022-09-29 09:06:23 - train: epoch 0131, iter [00680, 01251], lr: 0.001022, loss: 0.3962
2022-09-29 09:06:40 - train: epoch 0131, iter [00690, 01251], lr: 0.001022, loss: 0.4001
2022-09-29 09:06:58 - train: epoch 0131, iter [00700, 01251], lr: 0.001022, loss: 0.4083
2022-09-29 09:07:16 - train: epoch 0131, iter [00710, 01251], lr: 0.001022, loss: 0.4065
2022-09-29 09:07:34 - train: epoch 0131, iter [00720, 01251], lr: 0.001022, loss: 0.4198
2022-09-29 09:07:51 - train: epoch 0131, iter [00730, 01251], lr: 0.001022, loss: 0.4264
2022-09-29 09:08:09 - train: epoch 0131, iter [00740, 01251], lr: 0.001022, loss: 0.4280
2022-09-29 09:08:27 - train: epoch 0131, iter [00750, 01251], lr: 0.001022, loss: 0.4104
2022-09-29 09:08:44 - train: epoch 0131, iter [00760, 01251], lr: 0.001022, loss: 0.4036
2022-09-29 09:09:02 - train: epoch 0131, iter [00770, 01251], lr: 0.001022, loss: 0.4315
2022-09-29 09:09:20 - train: epoch 0131, iter [00780, 01251], lr: 0.001022, loss: 0.4225
2022-09-29 09:09:37 - train: epoch 0131, iter [00790, 01251], lr: 0.001022, loss: 0.4014
2022-09-29 09:09:55 - train: epoch 0131, iter [00800, 01251], lr: 0.001022, loss: 0.4056
2022-09-29 09:10:13 - train: epoch 0131, iter [00810, 01251], lr: 0.001022, loss: 0.4093
2022-09-29 09:10:30 - train: epoch 0131, iter [00820, 01251], lr: 0.001022, loss: 0.3944
2022-09-29 09:10:48 - train: epoch 0131, iter [00830, 01251], lr: 0.001022, loss: 0.3996
2022-09-29 09:11:06 - train: epoch 0131, iter [00840, 01251], lr: 0.001022, loss: 0.3929
2022-09-29 09:11:23 - train: epoch 0131, iter [00850, 01251], lr: 0.001022, loss: 0.4181
2022-09-29 09:11:41 - train: epoch 0131, iter [00860, 01251], lr: 0.001022, loss: 0.4078
2022-09-29 09:11:59 - train: epoch 0131, iter [00870, 01251], lr: 0.001022, loss: 0.4161
2022-09-29 09:12:16 - train: epoch 0131, iter [00880, 01251], lr: 0.001022, loss: 0.4215
2022-09-29 09:12:34 - train: epoch 0131, iter [00890, 01251], lr: 0.001022, loss: 0.4160
2022-09-29 09:12:52 - train: epoch 0131, iter [00900, 01251], lr: 0.001022, loss: 0.4181
2022-09-29 09:13:09 - train: epoch 0131, iter [00910, 01251], lr: 0.001022, loss: 0.4087
2022-09-29 09:13:27 - train: epoch 0131, iter [00920, 01251], lr: 0.001022, loss: 0.4111
2022-09-29 09:13:45 - train: epoch 0131, iter [00930, 01251], lr: 0.001022, loss: 0.3908
2022-09-29 09:14:03 - train: epoch 0131, iter [00940, 01251], lr: 0.001021, loss: 0.4133
2022-09-29 09:14:20 - train: epoch 0131, iter [00950, 01251], lr: 0.001021, loss: 0.4069
2022-09-29 09:14:38 - train: epoch 0131, iter [00960, 01251], lr: 0.001021, loss: 0.4129
2022-09-29 09:14:56 - train: epoch 0131, iter [00970, 01251], lr: 0.001021, loss: 0.4218
2022-09-29 09:15:14 - train: epoch 0131, iter [00980, 01251], lr: 0.001021, loss: 0.4111
2022-09-29 09:15:31 - train: epoch 0131, iter [00990, 01251], lr: 0.001021, loss: 0.4080
2022-09-29 09:15:49 - train: epoch 0131, iter [01000, 01251], lr: 0.001021, loss: 0.4117
2022-09-29 09:16:07 - train: epoch 0131, iter [01010, 01251], lr: 0.001021, loss: 0.4090
2022-09-29 09:16:24 - train: epoch 0131, iter [01020, 01251], lr: 0.001021, loss: 0.4238
2022-09-29 09:16:42 - train: epoch 0131, iter [01030, 01251], lr: 0.001021, loss: 0.4226
2022-09-29 09:17:00 - train: epoch 0131, iter [01040, 01251], lr: 0.001021, loss: 0.4114
2022-09-29 09:17:17 - train: epoch 0131, iter [01050, 01251], lr: 0.001021, loss: 0.3923
2022-09-29 09:17:35 - train: epoch 0131, iter [01060, 01251], lr: 0.001021, loss: 0.4036
2022-09-29 09:17:53 - train: epoch 0131, iter [01070, 01251], lr: 0.001021, loss: 0.4182
2022-09-29 09:18:10 - train: epoch 0131, iter [01080, 01251], lr: 0.001021, loss: 0.4400
2022-09-29 09:18:28 - train: epoch 0131, iter [01090, 01251], lr: 0.001021, loss: 0.4001
2022-09-29 09:18:46 - train: epoch 0131, iter [01100, 01251], lr: 0.001021, loss: 0.4122
2022-09-29 09:19:03 - train: epoch 0131, iter [01110, 01251], lr: 0.001021, loss: 0.4201
2022-09-29 09:19:21 - train: epoch 0131, iter [01120, 01251], lr: 0.001021, loss: 0.4324
2022-09-29 09:19:39 - train: epoch 0131, iter [01130, 01251], lr: 0.001021, loss: 0.4210
2022-09-29 09:19:56 - train: epoch 0131, iter [01140, 01251], lr: 0.001021, loss: 0.4171
2022-09-29 09:20:14 - train: epoch 0131, iter [01150, 01251], lr: 0.001021, loss: 0.4065
2022-09-29 09:20:32 - train: epoch 0131, iter [01160, 01251], lr: 0.001021, loss: 0.3935
2022-09-29 09:20:50 - train: epoch 0131, iter [01170, 01251], lr: 0.001021, loss: 0.4193
2022-09-29 09:21:07 - train: epoch 0131, iter [01180, 01251], lr: 0.001021, loss: 0.3907
2022-09-29 09:21:25 - train: epoch 0131, iter [01190, 01251], lr: 0.001021, loss: 0.4183
2022-09-29 09:21:42 - train: epoch 0131, iter [01200, 01251], lr: 0.001021, loss: 0.4022
2022-09-29 09:22:00 - train: epoch 0131, iter [01210, 01251], lr: 0.001021, loss: 0.4367
2022-09-29 09:22:18 - train: epoch 0131, iter [01220, 01251], lr: 0.001021, loss: 0.4059
2022-09-29 09:22:35 - train: epoch 0131, iter [01230, 01251], lr: 0.001021, loss: 0.4222
2022-09-29 09:22:53 - train: epoch 0131, iter [01240, 01251], lr: 0.001021, loss: 0.4133
2022-09-29 09:23:10 - train: epoch 0131, iter [01250, 01251], lr: 0.001021, loss: 0.4125
2022-09-29 09:23:14 - train: epoch 131, train_loss: 0.4115
2022-09-29 09:23:16 - until epoch: 131, best_loss: 0.4115
2022-09-29 09:23:16 - epoch 132 lr: 0.001021
2022-09-29 09:23:49 - train: epoch 0132, iter [00010, 01251], lr: 0.001021, loss: 0.3982
2022-09-29 09:24:07 - train: epoch 0132, iter [00020, 01251], lr: 0.001020, loss: 0.4064
2022-09-29 09:24:24 - train: epoch 0132, iter [00030, 01251], lr: 0.001020, loss: 0.4203
2022-09-29 09:24:42 - train: epoch 0132, iter [00040, 01251], lr: 0.001020, loss: 0.4063
2022-09-29 09:25:00 - train: epoch 0132, iter [00050, 01251], lr: 0.001020, loss: 0.4281
2022-09-29 09:25:18 - train: epoch 0132, iter [00060, 01251], lr: 0.001020, loss: 0.4405
2022-09-29 09:25:36 - train: epoch 0132, iter [00070, 01251], lr: 0.001020, loss: 0.3893
2022-09-29 09:25:53 - train: epoch 0132, iter [00080, 01251], lr: 0.001020, loss: 0.4085
2022-09-29 09:26:11 - train: epoch 0132, iter [00090, 01251], lr: 0.001020, loss: 0.3957
2022-09-29 09:26:28 - train: epoch 0132, iter [00100, 01251], lr: 0.001020, loss: 0.3987
2022-09-29 09:26:46 - train: epoch 0132, iter [00110, 01251], lr: 0.001020, loss: 0.4078
2022-09-29 09:27:04 - train: epoch 0132, iter [00120, 01251], lr: 0.001020, loss: 0.4295
2022-09-29 09:27:22 - train: epoch 0132, iter [00130, 01251], lr: 0.001020, loss: 0.4091
2022-09-29 09:27:39 - train: epoch 0132, iter [00140, 01251], lr: 0.001020, loss: 0.3953
2022-09-29 09:27:57 - train: epoch 0132, iter [00150, 01251], lr: 0.001020, loss: 0.4277
2022-09-29 09:28:15 - train: epoch 0132, iter [00160, 01251], lr: 0.001020, loss: 0.4241
2022-09-29 09:28:32 - train: epoch 0132, iter [00170, 01251], lr: 0.001020, loss: 0.4200
2022-09-29 09:28:50 - train: epoch 0132, iter [00180, 01251], lr: 0.001020, loss: 0.4221
2022-09-29 09:29:08 - train: epoch 0132, iter [00190, 01251], lr: 0.001020, loss: 0.4206
2022-09-29 09:29:25 - train: epoch 0132, iter [00200, 01251], lr: 0.001020, loss: 0.4071
2022-09-29 09:29:43 - train: epoch 0132, iter [00210, 01251], lr: 0.001020, loss: 0.4012
2022-09-29 09:30:01 - train: epoch 0132, iter [00220, 01251], lr: 0.001020, loss: 0.4262
2022-09-29 09:30:18 - train: epoch 0132, iter [00230, 01251], lr: 0.001020, loss: 0.4177
2022-09-29 09:30:36 - train: epoch 0132, iter [00240, 01251], lr: 0.001020, loss: 0.3968
2022-09-29 09:30:54 - train: epoch 0132, iter [00250, 01251], lr: 0.001020, loss: 0.4098
2022-09-29 09:31:12 - train: epoch 0132, iter [00260, 01251], lr: 0.001020, loss: 0.4191
2022-09-29 09:31:29 - train: epoch 0132, iter [00270, 01251], lr: 0.001020, loss: 0.4143
2022-09-29 09:31:47 - train: epoch 0132, iter [00280, 01251], lr: 0.001020, loss: 0.4160
2022-09-29 09:32:05 - train: epoch 0132, iter [00290, 01251], lr: 0.001020, loss: 0.4086
2022-09-29 09:32:23 - train: epoch 0132, iter [00300, 01251], lr: 0.001020, loss: 0.4164
2022-09-29 09:32:40 - train: epoch 0132, iter [00310, 01251], lr: 0.001020, loss: 0.4128
2022-09-29 09:32:58 - train: epoch 0132, iter [00320, 01251], lr: 0.001020, loss: 0.4093
2022-09-29 09:33:16 - train: epoch 0132, iter [00330, 01251], lr: 0.001020, loss: 0.4277
2022-09-29 09:33:33 - train: epoch 0132, iter [00340, 01251], lr: 0.001020, loss: 0.4168
2022-09-29 09:33:51 - train: epoch 0132, iter [00350, 01251], lr: 0.001019, loss: 0.4045
2022-09-29 09:34:09 - train: epoch 0132, iter [00360, 01251], lr: 0.001019, loss: 0.4198
2022-09-29 09:34:26 - train: epoch 0132, iter [00370, 01251], lr: 0.001019, loss: 0.4246
2022-09-29 09:34:44 - train: epoch 0132, iter [00380, 01251], lr: 0.001019, loss: 0.4156
2022-09-29 09:35:02 - train: epoch 0132, iter [00390, 01251], lr: 0.001019, loss: 0.4201
2022-09-29 09:35:20 - train: epoch 0132, iter [00400, 01251], lr: 0.001019, loss: 0.4124
2022-09-29 09:35:37 - train: epoch 0132, iter [00410, 01251], lr: 0.001019, loss: 0.4088
2022-09-29 09:35:55 - train: epoch 0132, iter [00420, 01251], lr: 0.001019, loss: 0.4141
2022-09-29 09:36:13 - train: epoch 0132, iter [00430, 01251], lr: 0.001019, loss: 0.4068
2022-09-29 09:36:30 - train: epoch 0132, iter [00440, 01251], lr: 0.001019, loss: 0.4166
2022-09-29 09:36:48 - train: epoch 0132, iter [00450, 01251], lr: 0.001019, loss: 0.3854
2022-09-29 09:37:06 - train: epoch 0132, iter [00460, 01251], lr: 0.001019, loss: 0.3897
2022-09-29 09:37:24 - train: epoch 0132, iter [00470, 01251], lr: 0.001019, loss: 0.4170
2022-09-29 09:37:41 - train: epoch 0132, iter [00480, 01251], lr: 0.001019, loss: 0.4160
2022-09-29 09:37:59 - train: epoch 0132, iter [00490, 01251], lr: 0.001019, loss: 0.4158
2022-09-29 09:38:17 - train: epoch 0132, iter [00500, 01251], lr: 0.001019, loss: 0.4049
2022-09-29 09:38:35 - train: epoch 0132, iter [00510, 01251], lr: 0.001019, loss: 0.4262
2022-09-29 09:38:52 - train: epoch 0132, iter [00520, 01251], lr: 0.001019, loss: 0.4284
2022-09-29 09:39:10 - train: epoch 0132, iter [00530, 01251], lr: 0.001019, loss: 0.4429
2022-09-29 09:39:28 - train: epoch 0132, iter [00540, 01251], lr: 0.001019, loss: 0.4150
2022-09-29 09:39:46 - train: epoch 0132, iter [00550, 01251], lr: 0.001019, loss: 0.4141
2022-09-29 09:40:04 - train: epoch 0132, iter [00560, 01251], lr: 0.001019, loss: 0.4115
2022-09-29 09:40:21 - train: epoch 0132, iter [00570, 01251], lr: 0.001019, loss: 0.4168
2022-09-29 09:40:39 - train: epoch 0132, iter [00580, 01251], lr: 0.001019, loss: 0.4016
2022-09-29 09:40:57 - train: epoch 0132, iter [00590, 01251], lr: 0.001019, loss: 0.4271
2022-09-29 09:41:14 - train: epoch 0132, iter [00600, 01251], lr: 0.001019, loss: 0.4192
2022-09-29 09:41:32 - train: epoch 0132, iter [00610, 01251], lr: 0.001019, loss: 0.4146
2022-09-29 09:41:50 - train: epoch 0132, iter [00620, 01251], lr: 0.001019, loss: 0.4215
2022-09-29 09:42:08 - train: epoch 0132, iter [00630, 01251], lr: 0.001019, loss: 0.4085
2022-09-29 09:42:25 - train: epoch 0132, iter [00640, 01251], lr: 0.001019, loss: 0.4079
2022-09-29 09:42:43 - train: epoch 0132, iter [00650, 01251], lr: 0.001019, loss: 0.4146
2022-09-29 09:43:01 - train: epoch 0132, iter [00660, 01251], lr: 0.001019, loss: 0.4137
2022-09-29 09:43:19 - train: epoch 0132, iter [00670, 01251], lr: 0.001019, loss: 0.4163
2022-09-29 09:43:37 - train: epoch 0132, iter [00680, 01251], lr: 0.001019, loss: 0.4109
2022-09-29 09:43:54 - train: epoch 0132, iter [00690, 01251], lr: 0.001018, loss: 0.4005
2022-09-29 09:44:12 - train: epoch 0132, iter [00700, 01251], lr: 0.001018, loss: 0.4221
2022-09-29 09:44:30 - train: epoch 0132, iter [00710, 01251], lr: 0.001018, loss: 0.4257
2022-09-29 09:44:48 - train: epoch 0132, iter [00720, 01251], lr: 0.001018, loss: 0.3867
2022-09-29 09:45:06 - train: epoch 0132, iter [00730, 01251], lr: 0.001018, loss: 0.4120
2022-09-29 09:45:23 - train: epoch 0132, iter [00740, 01251], lr: 0.001018, loss: 0.4138
2022-09-29 09:45:41 - train: epoch 0132, iter [00750, 01251], lr: 0.001018, loss: 0.3850
2022-09-29 09:45:59 - train: epoch 0132, iter [00760, 01251], lr: 0.001018, loss: 0.4097
2022-09-29 09:46:17 - train: epoch 0132, iter [00770, 01251], lr: 0.001018, loss: 0.4041
2022-09-29 09:46:34 - train: epoch 0132, iter [00780, 01251], lr: 0.001018, loss: 0.4128
2022-09-29 09:46:52 - train: epoch 0132, iter [00790, 01251], lr: 0.001018, loss: 0.4264
2022-09-29 09:47:10 - train: epoch 0132, iter [00800, 01251], lr: 0.001018, loss: 0.4202
2022-09-29 09:47:28 - train: epoch 0132, iter [00810, 01251], lr: 0.001018, loss: 0.4190
2022-09-29 09:47:45 - train: epoch 0132, iter [00820, 01251], lr: 0.001018, loss: 0.4101
2022-09-29 09:48:03 - train: epoch 0132, iter [00830, 01251], lr: 0.001018, loss: 0.4178
2022-09-29 09:48:21 - train: epoch 0132, iter [00840, 01251], lr: 0.001018, loss: 0.3999
2022-09-29 09:48:39 - train: epoch 0132, iter [00850, 01251], lr: 0.001018, loss: 0.3957
2022-09-29 09:48:56 - train: epoch 0132, iter [00860, 01251], lr: 0.001018, loss: 0.4215
2022-09-29 09:49:14 - train: epoch 0132, iter [00870, 01251], lr: 0.001018, loss: 0.4172
2022-09-29 09:49:32 - train: epoch 0132, iter [00880, 01251], lr: 0.001018, loss: 0.4144
2022-09-29 09:49:49 - train: epoch 0132, iter [00890, 01251], lr: 0.001018, loss: 0.4328
2022-09-29 09:50:07 - train: epoch 0132, iter [00900, 01251], lr: 0.001018, loss: 0.3930
2022-09-29 09:50:25 - train: epoch 0132, iter [00910, 01251], lr: 0.001018, loss: 0.4301
2022-09-29 09:50:42 - train: epoch 0132, iter [00920, 01251], lr: 0.001018, loss: 0.3919
2022-09-29 09:51:00 - train: epoch 0132, iter [00930, 01251], lr: 0.001018, loss: 0.4196
2022-09-29 09:51:18 - train: epoch 0132, iter [00940, 01251], lr: 0.001018, loss: 0.4034
2022-09-29 09:51:35 - train: epoch 0132, iter [00950, 01251], lr: 0.001018, loss: 0.4204
2022-09-29 09:51:53 - train: epoch 0132, iter [00960, 01251], lr: 0.001018, loss: 0.4230
2022-09-29 09:52:11 - train: epoch 0132, iter [00970, 01251], lr: 0.001018, loss: 0.4079
2022-09-29 09:52:29 - train: epoch 0132, iter [00980, 01251], lr: 0.001018, loss: 0.4183
2022-09-29 09:52:46 - train: epoch 0132, iter [00990, 01251], lr: 0.001018, loss: 0.3887
2022-09-29 09:53:04 - train: epoch 0132, iter [01000, 01251], lr: 0.001018, loss: 0.4225
2022-09-29 09:53:22 - train: epoch 0132, iter [01010, 01251], lr: 0.001018, loss: 0.4245
2022-09-29 09:53:40 - train: epoch 0132, iter [01020, 01251], lr: 0.001017, loss: 0.4002
2022-09-29 09:53:58 - train: epoch 0132, iter [01030, 01251], lr: 0.001017, loss: 0.3881
2022-09-29 09:54:15 - train: epoch 0132, iter [01040, 01251], lr: 0.001017, loss: 0.4215
2022-09-29 09:54:33 - train: epoch 0132, iter [01050, 01251], lr: 0.001017, loss: 0.3954
2022-09-29 09:54:51 - train: epoch 0132, iter [01060, 01251], lr: 0.001017, loss: 0.4249
2022-09-29 09:55:09 - train: epoch 0132, iter [01070, 01251], lr: 0.001017, loss: 0.4042
2022-09-29 09:55:26 - train: epoch 0132, iter [01080, 01251], lr: 0.001017, loss: 0.3986
2022-09-29 09:55:44 - train: epoch 0132, iter [01090, 01251], lr: 0.001017, loss: 0.3968
2022-09-29 09:56:02 - train: epoch 0132, iter [01100, 01251], lr: 0.001017, loss: 0.4144
2022-09-29 09:56:20 - train: epoch 0132, iter [01110, 01251], lr: 0.001017, loss: 0.4089
2022-09-29 09:56:37 - train: epoch 0132, iter [01120, 01251], lr: 0.001017, loss: 0.4366
2022-09-29 09:56:55 - train: epoch 0132, iter [01130, 01251], lr: 0.001017, loss: 0.4139
2022-09-29 09:57:13 - train: epoch 0132, iter [01140, 01251], lr: 0.001017, loss: 0.4338
2022-09-29 09:57:31 - train: epoch 0132, iter [01150, 01251], lr: 0.001017, loss: 0.4121
2022-09-29 09:57:48 - train: epoch 0132, iter [01160, 01251], lr: 0.001017, loss: 0.3935
2022-09-29 09:58:06 - train: epoch 0132, iter [01170, 01251], lr: 0.001017, loss: 0.4311
2022-09-29 09:58:24 - train: epoch 0132, iter [01180, 01251], lr: 0.001017, loss: 0.4073
2022-09-29 09:58:42 - train: epoch 0132, iter [01190, 01251], lr: 0.001017, loss: 0.4189
2022-09-29 09:58:59 - train: epoch 0132, iter [01200, 01251], lr: 0.001017, loss: 0.4023
2022-09-29 09:59:17 - train: epoch 0132, iter [01210, 01251], lr: 0.001017, loss: 0.4223
2022-09-29 09:59:35 - train: epoch 0132, iter [01220, 01251], lr: 0.001017, loss: 0.4214
2022-09-29 09:59:53 - train: epoch 0132, iter [01230, 01251], lr: 0.001017, loss: 0.4122
2022-09-29 10:00:11 - train: epoch 0132, iter [01240, 01251], lr: 0.001017, loss: 0.4166
2022-09-29 10:00:28 - train: epoch 0132, iter [01250, 01251], lr: 0.001017, loss: 0.4250
2022-09-29 10:00:32 - train: epoch 132, train_loss: 0.4115
2022-09-29 10:00:34 - until epoch: 132, best_loss: 0.4115
2022-09-29 10:00:34 - epoch 133 lr: 0.001017
2022-09-29 10:01:07 - train: epoch 0133, iter [00010, 01251], lr: 0.001017, loss: 0.4150
2022-09-29 10:01:25 - train: epoch 0133, iter [00020, 01251], lr: 0.001017, loss: 0.4238
2022-09-29 10:01:42 - train: epoch 0133, iter [00030, 01251], lr: 0.001017, loss: 0.3952
2022-09-29 10:02:00 - train: epoch 0133, iter [00040, 01251], lr: 0.001017, loss: 0.4204
2022-09-29 10:02:18 - train: epoch 0133, iter [00050, 01251], lr: 0.001017, loss: 0.4019
2022-09-29 10:02:36 - train: epoch 0133, iter [00060, 01251], lr: 0.001017, loss: 0.4187
2022-09-29 10:02:53 - train: epoch 0133, iter [00070, 01251], lr: 0.001017, loss: 0.4219
2022-09-29 10:03:11 - train: epoch 0133, iter [00080, 01251], lr: 0.001017, loss: 0.4158
2022-09-29 10:03:28 - train: epoch 0133, iter [00090, 01251], lr: 0.001017, loss: 0.4046
2022-09-29 10:03:46 - train: epoch 0133, iter [00100, 01251], lr: 0.001016, loss: 0.4089
2022-09-29 10:04:04 - train: epoch 0133, iter [00110, 01251], lr: 0.001016, loss: 0.4115
2022-09-29 10:04:21 - train: epoch 0133, iter [00120, 01251], lr: 0.001016, loss: 0.3822
2022-09-29 10:04:39 - train: epoch 0133, iter [00130, 01251], lr: 0.001016, loss: 0.4141
2022-09-29 10:04:57 - train: epoch 0133, iter [00140, 01251], lr: 0.001016, loss: 0.4198
2022-09-29 10:05:15 - train: epoch 0133, iter [00150, 01251], lr: 0.001016, loss: 0.4189
2022-09-29 10:05:32 - train: epoch 0133, iter [00160, 01251], lr: 0.001016, loss: 0.4210
2022-09-29 10:05:50 - train: epoch 0133, iter [00170, 01251], lr: 0.001016, loss: 0.3967
2022-09-29 10:06:08 - train: epoch 0133, iter [00180, 01251], lr: 0.001016, loss: 0.4061
2022-09-29 10:06:25 - train: epoch 0133, iter [00190, 01251], lr: 0.001016, loss: 0.4104
2022-09-29 10:06:43 - train: epoch 0133, iter [00200, 01251], lr: 0.001016, loss: 0.4098
2022-09-29 10:07:01 - train: epoch 0133, iter [00210, 01251], lr: 0.001016, loss: 0.4068
2022-09-29 10:07:18 - train: epoch 0133, iter [00220, 01251], lr: 0.001016, loss: 0.4054
2022-09-29 10:07:36 - train: epoch 0133, iter [00230, 01251], lr: 0.001016, loss: 0.3842
2022-09-29 10:07:54 - train: epoch 0133, iter [00240, 01251], lr: 0.001016, loss: 0.4034
2022-09-29 10:08:12 - train: epoch 0133, iter [00250, 01251], lr: 0.001016, loss: 0.3771
2022-09-29 10:08:29 - train: epoch 0133, iter [00260, 01251], lr: 0.001016, loss: 0.4185
2022-09-29 10:08:47 - train: epoch 0133, iter [00270, 01251], lr: 0.001016, loss: 0.4070
2022-09-29 10:09:05 - train: epoch 0133, iter [00280, 01251], lr: 0.001016, loss: 0.3990
2022-09-29 10:09:22 - train: epoch 0133, iter [00290, 01251], lr: 0.001016, loss: 0.4069
2022-09-29 10:09:40 - train: epoch 0133, iter [00300, 01251], lr: 0.001016, loss: 0.4023
2022-09-29 10:09:58 - train: epoch 0133, iter [00310, 01251], lr: 0.001016, loss: 0.4189
2022-09-29 10:10:16 - train: epoch 0133, iter [00320, 01251], lr: 0.001016, loss: 0.4242
2022-09-29 10:10:33 - train: epoch 0133, iter [00330, 01251], lr: 0.001016, loss: 0.4158
2022-09-29 10:10:51 - train: epoch 0133, iter [00340, 01251], lr: 0.001016, loss: 0.4200
2022-09-29 10:11:09 - train: epoch 0133, iter [00350, 01251], lr: 0.001016, loss: 0.4213
2022-09-29 10:11:26 - train: epoch 0133, iter [00360, 01251], lr: 0.001016, loss: 0.4143
2022-09-29 10:11:44 - train: epoch 0133, iter [00370, 01251], lr: 0.001016, loss: 0.4139
2022-09-29 10:12:02 - train: epoch 0133, iter [00380, 01251], lr: 0.001016, loss: 0.4134
2022-09-29 10:12:20 - train: epoch 0133, iter [00390, 01251], lr: 0.001016, loss: 0.4091
2022-09-29 10:12:37 - train: epoch 0133, iter [00400, 01251], lr: 0.001016, loss: 0.4100
2022-09-29 10:12:55 - train: epoch 0133, iter [00410, 01251], lr: 0.001016, loss: 0.4225
2022-09-29 10:13:13 - train: epoch 0133, iter [00420, 01251], lr: 0.001016, loss: 0.4211
2022-09-29 10:13:31 - train: epoch 0133, iter [00430, 01251], lr: 0.001015, loss: 0.3866
2022-09-29 10:13:48 - train: epoch 0133, iter [00440, 01251], lr: 0.001015, loss: 0.4061
2022-09-29 10:14:06 - train: epoch 0133, iter [00450, 01251], lr: 0.001015, loss: 0.4157
2022-09-29 10:14:24 - train: epoch 0133, iter [00460, 01251], lr: 0.001015, loss: 0.4008
2022-09-29 10:14:41 - train: epoch 0133, iter [00470, 01251], lr: 0.001015, loss: 0.4102
2022-09-29 10:14:59 - train: epoch 0133, iter [00480, 01251], lr: 0.001015, loss: 0.4042
2022-09-29 10:15:17 - train: epoch 0133, iter [00490, 01251], lr: 0.001015, loss: 0.3924
2022-09-29 10:15:35 - train: epoch 0133, iter [00500, 01251], lr: 0.001015, loss: 0.3955
2022-09-29 10:15:53 - train: epoch 0133, iter [00510, 01251], lr: 0.001015, loss: 0.4187
2022-09-29 10:16:10 - train: epoch 0133, iter [00520, 01251], lr: 0.001015, loss: 0.4075
2022-09-29 10:16:28 - train: epoch 0133, iter [00530, 01251], lr: 0.001015, loss: 0.4332
2022-09-29 10:16:46 - train: epoch 0133, iter [00540, 01251], lr: 0.001015, loss: 0.4144
2022-09-29 10:17:03 - train: epoch 0133, iter [00550, 01251], lr: 0.001015, loss: 0.4021
2022-09-29 10:17:21 - train: epoch 0133, iter [00560, 01251], lr: 0.001015, loss: 0.4170
2022-09-29 10:17:39 - train: epoch 0133, iter [00570, 01251], lr: 0.001015, loss: 0.3958
2022-09-29 10:17:57 - train: epoch 0133, iter [00580, 01251], lr: 0.001015, loss: 0.4183
2022-09-29 10:18:14 - train: epoch 0133, iter [00590, 01251], lr: 0.001015, loss: 0.4090
2022-09-29 10:18:32 - train: epoch 0133, iter [00600, 01251], lr: 0.001015, loss: 0.4151
2022-09-29 10:18:50 - train: epoch 0133, iter [00610, 01251], lr: 0.001015, loss: 0.4163
2022-09-29 10:19:07 - train: epoch 0133, iter [00620, 01251], lr: 0.001015, loss: 0.4166
2022-09-29 10:19:25 - train: epoch 0133, iter [00630, 01251], lr: 0.001015, loss: 0.4129
2022-09-29 10:19:43 - train: epoch 0133, iter [00640, 01251], lr: 0.001015, loss: 0.4091
2022-09-29 10:20:01 - train: epoch 0133, iter [00650, 01251], lr: 0.001015, loss: 0.3974
2022-09-29 10:20:18 - train: epoch 0133, iter [00660, 01251], lr: 0.001015, loss: 0.3991
2022-09-29 10:20:36 - train: epoch 0133, iter [00670, 01251], lr: 0.001015, loss: 0.3982
2022-09-29 10:20:54 - train: epoch 0133, iter [00680, 01251], lr: 0.001015, loss: 0.4216
2022-09-29 10:21:11 - train: epoch 0133, iter [00690, 01251], lr: 0.001015, loss: 0.4039
2022-09-29 10:21:29 - train: epoch 0133, iter [00700, 01251], lr: 0.001015, loss: 0.4075
2022-09-29 10:21:47 - train: epoch 0133, iter [00710, 01251], lr: 0.001015, loss: 0.4087
2022-09-29 10:22:04 - train: epoch 0133, iter [00720, 01251], lr: 0.001015, loss: 0.4094
2022-09-29 10:22:22 - train: epoch 0133, iter [00730, 01251], lr: 0.001015, loss: 0.4243
2022-09-29 10:22:40 - train: epoch 0133, iter [00740, 01251], lr: 0.001015, loss: 0.4160
2022-09-29 10:22:58 - train: epoch 0133, iter [00750, 01251], lr: 0.001015, loss: 0.4111
2022-09-29 10:23:16 - train: epoch 0133, iter [00760, 01251], lr: 0.001015, loss: 0.4274
2022-09-29 10:23:33 - train: epoch 0133, iter [00770, 01251], lr: 0.001014, loss: 0.4218
2022-09-29 10:23:51 - train: epoch 0133, iter [00780, 01251], lr: 0.001014, loss: 0.4430
2022-09-29 10:24:09 - train: epoch 0133, iter [00790, 01251], lr: 0.001014, loss: 0.4019
2022-09-29 10:24:27 - train: epoch 0133, iter [00800, 01251], lr: 0.001014, loss: 0.4179
2022-09-29 10:24:44 - train: epoch 0133, iter [00810, 01251], lr: 0.001014, loss: 0.4146
2022-09-29 10:25:02 - train: epoch 0133, iter [00820, 01251], lr: 0.001014, loss: 0.4095
2022-09-29 10:25:20 - train: epoch 0133, iter [00830, 01251], lr: 0.001014, loss: 0.4126
2022-09-29 10:25:37 - train: epoch 0133, iter [00840, 01251], lr: 0.001014, loss: 0.4035
2022-09-29 10:25:55 - train: epoch 0133, iter [00850, 01251], lr: 0.001014, loss: 0.4158
2022-09-29 10:26:13 - train: epoch 0133, iter [00860, 01251], lr: 0.001014, loss: 0.4166
2022-09-29 10:26:30 - train: epoch 0133, iter [00870, 01251], lr: 0.001014, loss: 0.4279
2022-09-29 10:26:48 - train: epoch 0133, iter [00880, 01251], lr: 0.001014, loss: 0.4012
2022-09-29 10:27:06 - train: epoch 0133, iter [00890, 01251], lr: 0.001014, loss: 0.4012
2022-09-29 10:27:24 - train: epoch 0133, iter [00900, 01251], lr: 0.001014, loss: 0.4125
2022-09-29 10:27:42 - train: epoch 0133, iter [00910, 01251], lr: 0.001014, loss: 0.4013
2022-09-29 10:27:59 - train: epoch 0133, iter [00920, 01251], lr: 0.001014, loss: 0.4195
2022-09-29 10:28:17 - train: epoch 0133, iter [00930, 01251], lr: 0.001014, loss: 0.4007
2022-09-29 10:28:35 - train: epoch 0133, iter [00940, 01251], lr: 0.001014, loss: 0.4024
2022-09-29 10:28:52 - train: epoch 0133, iter [00950, 01251], lr: 0.001014, loss: 0.4111
2022-09-29 10:29:10 - train: epoch 0133, iter [00960, 01251], lr: 0.001014, loss: 0.4198
2022-09-29 10:29:28 - train: epoch 0133, iter [00970, 01251], lr: 0.001014, loss: 0.4181
2022-09-29 10:29:46 - train: epoch 0133, iter [00980, 01251], lr: 0.001014, loss: 0.4162
2022-09-29 10:30:03 - train: epoch 0133, iter [00990, 01251], lr: 0.001014, loss: 0.4083
2022-09-29 10:30:21 - train: epoch 0133, iter [01000, 01251], lr: 0.001014, loss: 0.4249
2022-09-29 10:30:39 - train: epoch 0133, iter [01010, 01251], lr: 0.001014, loss: 0.3945
2022-09-29 10:30:56 - train: epoch 0133, iter [01020, 01251], lr: 0.001014, loss: 0.4079
2022-09-29 10:31:14 - train: epoch 0133, iter [01030, 01251], lr: 0.001014, loss: 0.4056
2022-09-29 10:31:32 - train: epoch 0133, iter [01040, 01251], lr: 0.001014, loss: 0.4056
2022-09-29 10:31:50 - train: epoch 0133, iter [01050, 01251], lr: 0.001014, loss: 0.4005
2022-09-29 10:32:07 - train: epoch 0133, iter [01060, 01251], lr: 0.001014, loss: 0.4062
2022-09-29 10:32:25 - train: epoch 0133, iter [01070, 01251], lr: 0.001014, loss: 0.3978
2022-09-29 10:32:43 - train: epoch 0133, iter [01080, 01251], lr: 0.001014, loss: 0.4194
2022-09-29 10:33:01 - train: epoch 0133, iter [01090, 01251], lr: 0.001014, loss: 0.4217
2022-09-29 10:33:19 - train: epoch 0133, iter [01100, 01251], lr: 0.001013, loss: 0.4042
2022-09-29 10:33:36 - train: epoch 0133, iter [01110, 01251], lr: 0.001013, loss: 0.3984
2022-09-29 10:33:54 - train: epoch 0133, iter [01120, 01251], lr: 0.001013, loss: 0.4222
2022-09-29 10:34:12 - train: epoch 0133, iter [01130, 01251], lr: 0.001013, loss: 0.4161
2022-09-29 10:34:30 - train: epoch 0133, iter [01140, 01251], lr: 0.001013, loss: 0.3961
2022-09-29 10:34:47 - train: epoch 0133, iter [01150, 01251], lr: 0.001013, loss: 0.4233
2022-09-29 10:35:05 - train: epoch 0133, iter [01160, 01251], lr: 0.001013, loss: 0.3958
2022-09-29 10:35:23 - train: epoch 0133, iter [01170, 01251], lr: 0.001013, loss: 0.4157
2022-09-29 10:35:41 - train: epoch 0133, iter [01180, 01251], lr: 0.001013, loss: 0.4171
2022-09-29 10:35:58 - train: epoch 0133, iter [01190, 01251], lr: 0.001013, loss: 0.4143
2022-09-29 10:36:16 - train: epoch 0133, iter [01200, 01251], lr: 0.001013, loss: 0.4147
2022-09-29 10:36:34 - train: epoch 0133, iter [01210, 01251], lr: 0.001013, loss: 0.4219
2022-09-29 10:36:51 - train: epoch 0133, iter [01220, 01251], lr: 0.001013, loss: 0.4217
2022-09-29 10:37:09 - train: epoch 0133, iter [01230, 01251], lr: 0.001013, loss: 0.4130
2022-09-29 10:37:27 - train: epoch 0133, iter [01240, 01251], lr: 0.001013, loss: 0.4092
2022-09-29 10:37:44 - train: epoch 0133, iter [01250, 01251], lr: 0.001013, loss: 0.4014
2022-09-29 10:37:48 - train: epoch 133, train_loss: 0.4113
2022-09-29 10:37:50 - until epoch: 133, best_loss: 0.4113
2022-09-29 10:37:50 - epoch 134 lr: 0.001013
2022-09-29 10:38:24 - train: epoch 0134, iter [00010, 01251], lr: 0.001013, loss: 0.4318
2022-09-29 10:38:42 - train: epoch 0134, iter [00020, 01251], lr: 0.001013, loss: 0.4018
2022-09-29 10:38:59 - train: epoch 0134, iter [00030, 01251], lr: 0.001013, loss: 0.4240
2022-09-29 10:39:17 - train: epoch 0134, iter [00040, 01251], lr: 0.001013, loss: 0.4144
2022-09-29 10:39:35 - train: epoch 0134, iter [00050, 01251], lr: 0.001013, loss: 0.4203
2022-09-29 10:39:53 - train: epoch 0134, iter [00060, 01251], lr: 0.001013, loss: 0.4119
2022-09-29 10:40:10 - train: epoch 0134, iter [00070, 01251], lr: 0.001013, loss: 0.4103
2022-09-29 10:40:28 - train: epoch 0134, iter [00080, 01251], lr: 0.001013, loss: 0.4271
2022-09-29 10:40:46 - train: epoch 0134, iter [00090, 01251], lr: 0.001013, loss: 0.4150
2022-09-29 10:41:04 - train: epoch 0134, iter [00100, 01251], lr: 0.001013, loss: 0.3909
2022-09-29 10:41:21 - train: epoch 0134, iter [00110, 01251], lr: 0.001013, loss: 0.4114
2022-09-29 10:41:39 - train: epoch 0134, iter [00120, 01251], lr: 0.001013, loss: 0.4246
2022-09-29 10:41:57 - train: epoch 0134, iter [00130, 01251], lr: 0.001013, loss: 0.4014
2022-09-29 10:42:15 - train: epoch 0134, iter [00140, 01251], lr: 0.001013, loss: 0.4147
2022-09-29 10:42:32 - train: epoch 0134, iter [00150, 01251], lr: 0.001013, loss: 0.4386
2022-09-29 10:42:50 - train: epoch 0134, iter [00160, 01251], lr: 0.001013, loss: 0.4228
2022-09-29 10:43:08 - train: epoch 0134, iter [00170, 01251], lr: 0.001012, loss: 0.4038
2022-09-29 10:43:26 - train: epoch 0134, iter [00180, 01251], lr: 0.001012, loss: 0.4293
2022-09-29 10:43:43 - train: epoch 0134, iter [00190, 01251], lr: 0.001012, loss: 0.4131
2022-09-29 10:44:01 - train: epoch 0134, iter [00200, 01251], lr: 0.001012, loss: 0.3941
2022-09-29 10:44:19 - train: epoch 0134, iter [00210, 01251], lr: 0.001012, loss: 0.3938
2022-09-29 10:44:37 - train: epoch 0134, iter [00220, 01251], lr: 0.001012, loss: 0.4246
2022-09-29 10:44:54 - train: epoch 0134, iter [00230, 01251], lr: 0.001012, loss: 0.4136
2022-09-29 10:45:12 - train: epoch 0134, iter [00240, 01251], lr: 0.001012, loss: 0.4097
2022-09-29 10:45:30 - train: epoch 0134, iter [00250, 01251], lr: 0.001012, loss: 0.4186
2022-09-29 10:45:47 - train: epoch 0134, iter [00260, 01251], lr: 0.001012, loss: 0.4252
2022-09-29 10:46:05 - train: epoch 0134, iter [00270, 01251], lr: 0.001012, loss: 0.3955
2022-09-29 10:46:23 - train: epoch 0134, iter [00280, 01251], lr: 0.001012, loss: 0.4056
2022-09-29 10:46:40 - train: epoch 0134, iter [00290, 01251], lr: 0.001012, loss: 0.4276
2022-09-29 10:46:58 - train: epoch 0134, iter [00300, 01251], lr: 0.001012, loss: 0.4048
2022-09-29 10:47:16 - train: epoch 0134, iter [00310, 01251], lr: 0.001012, loss: 0.4035
2022-09-29 10:47:34 - train: epoch 0134, iter [00320, 01251], lr: 0.001012, loss: 0.4119
2022-09-29 10:47:51 - train: epoch 0134, iter [00330, 01251], lr: 0.001012, loss: 0.4128
2022-09-29 10:48:09 - train: epoch 0134, iter [00340, 01251], lr: 0.001012, loss: 0.4061
2022-09-29 10:48:27 - train: epoch 0134, iter [00350, 01251], lr: 0.001012, loss: 0.4299
2022-09-29 10:48:44 - train: epoch 0134, iter [00360, 01251], lr: 0.001012, loss: 0.4024
2022-09-29 10:49:02 - train: epoch 0134, iter [00370, 01251], lr: 0.001012, loss: 0.4020
2022-09-29 10:49:20 - train: epoch 0134, iter [00380, 01251], lr: 0.001012, loss: 0.3999
2022-09-29 10:49:38 - train: epoch 0134, iter [00390, 01251], lr: 0.001012, loss: 0.4101
2022-09-29 10:49:55 - train: epoch 0134, iter [00400, 01251], lr: 0.001012, loss: 0.3851
2022-09-29 10:50:13 - train: epoch 0134, iter [00410, 01251], lr: 0.001012, loss: 0.4089
2022-09-29 10:50:31 - train: epoch 0134, iter [00420, 01251], lr: 0.001012, loss: 0.4271
2022-09-29 10:50:49 - train: epoch 0134, iter [00430, 01251], lr: 0.001012, loss: 0.4040
2022-09-29 10:51:06 - train: epoch 0134, iter [00440, 01251], lr: 0.001012, loss: 0.4158
2022-09-29 10:51:24 - train: epoch 0134, iter [00450, 01251], lr: 0.001012, loss: 0.4306
2022-09-29 10:51:42 - train: epoch 0134, iter [00460, 01251], lr: 0.001012, loss: 0.4052
2022-09-29 10:52:00 - train: epoch 0134, iter [00470, 01251], lr: 0.001012, loss: 0.4056
2022-09-29 10:52:17 - train: epoch 0134, iter [00480, 01251], lr: 0.001012, loss: 0.4187
2022-09-29 10:52:35 - train: epoch 0134, iter [00490, 01251], lr: 0.001012, loss: 0.4126
2022-09-29 10:52:53 - train: epoch 0134, iter [00500, 01251], lr: 0.001011, loss: 0.4212
2022-09-29 10:53:10 - train: epoch 0134, iter [00510, 01251], lr: 0.001011, loss: 0.4130
2022-09-29 10:53:28 - train: epoch 0134, iter [00520, 01251], lr: 0.001011, loss: 0.4171
2022-09-29 10:53:46 - train: epoch 0134, iter [00530, 01251], lr: 0.001011, loss: 0.4040
2022-09-29 10:54:03 - train: epoch 0134, iter [00540, 01251], lr: 0.001011, loss: 0.4060
2022-09-29 10:54:21 - train: epoch 0134, iter [00550, 01251], lr: 0.001011, loss: 0.4204
2022-09-29 10:54:39 - train: epoch 0134, iter [00560, 01251], lr: 0.001011, loss: 0.4021
2022-09-29 10:54:57 - train: epoch 0134, iter [00570, 01251], lr: 0.001011, loss: 0.4219
2022-09-29 10:55:14 - train: epoch 0134, iter [00580, 01251], lr: 0.001011, loss: 0.4364
2022-09-29 10:55:32 - train: epoch 0134, iter [00590, 01251], lr: 0.001011, loss: 0.3939
2022-09-29 10:55:50 - train: epoch 0134, iter [00600, 01251], lr: 0.001011, loss: 0.4097
2022-09-29 10:56:08 - train: epoch 0134, iter [00610, 01251], lr: 0.001011, loss: 0.3959
2022-09-29 10:56:26 - train: epoch 0134, iter [00620, 01251], lr: 0.001011, loss: 0.4132
2022-09-29 10:56:43 - train: epoch 0134, iter [00630, 01251], lr: 0.001011, loss: 0.3996
2022-09-29 10:57:01 - train: epoch 0134, iter [00640, 01251], lr: 0.001011, loss: 0.3913
2022-09-29 10:57:19 - train: epoch 0134, iter [00650, 01251], lr: 0.001011, loss: 0.4195
2022-09-29 10:57:36 - train: epoch 0134, iter [00660, 01251], lr: 0.001011, loss: 0.4052
2022-09-29 10:57:54 - train: epoch 0134, iter [00670, 01251], lr: 0.001011, loss: 0.4191
2022-09-29 10:58:12 - train: epoch 0134, iter [00680, 01251], lr: 0.001011, loss: 0.4234
2022-09-29 10:58:29 - train: epoch 0134, iter [00690, 01251], lr: 0.001011, loss: 0.4096
2022-09-29 10:58:47 - train: epoch 0134, iter [00700, 01251], lr: 0.001011, loss: 0.4104
2022-09-29 10:59:05 - train: epoch 0134, iter [00710, 01251], lr: 0.001011, loss: 0.4065
2022-09-29 10:59:22 - train: epoch 0134, iter [00720, 01251], lr: 0.001011, loss: 0.3949
2022-09-29 10:59:40 - train: epoch 0134, iter [00730, 01251], lr: 0.001011, loss: 0.4115
2022-09-29 10:59:58 - train: epoch 0134, iter [00740, 01251], lr: 0.001011, loss: 0.4022
2022-09-29 11:00:16 - train: epoch 0134, iter [00750, 01251], lr: 0.001011, loss: 0.4007
2022-09-29 11:00:33 - train: epoch 0134, iter [00760, 01251], lr: 0.001011, loss: 0.4020
2022-09-29 11:00:51 - train: epoch 0134, iter [00770, 01251], lr: 0.001011, loss: 0.4165
2022-09-29 11:01:09 - train: epoch 0134, iter [00780, 01251], lr: 0.001011, loss: 0.3977
2022-09-29 11:01:26 - train: epoch 0134, iter [00790, 01251], lr: 0.001011, loss: 0.4120
2022-09-29 11:01:44 - train: epoch 0134, iter [00800, 01251], lr: 0.001011, loss: 0.4255
2022-09-29 11:02:02 - train: epoch 0134, iter [00810, 01251], lr: 0.001011, loss: 0.3965
2022-09-29 11:02:19 - train: epoch 0134, iter [00820, 01251], lr: 0.001011, loss: 0.4072
2022-09-29 11:02:37 - train: epoch 0134, iter [00830, 01251], lr: 0.001010, loss: 0.4063
2022-09-29 11:02:55 - train: epoch 0134, iter [00840, 01251], lr: 0.001010, loss: 0.4223
2022-09-29 11:03:13 - train: epoch 0134, iter [00850, 01251], lr: 0.001010, loss: 0.4128
2022-09-29 11:03:30 - train: epoch 0134, iter [00860, 01251], lr: 0.001010, loss: 0.4195
2022-09-29 11:03:48 - train: epoch 0134, iter [00870, 01251], lr: 0.001010, loss: 0.4323
2022-09-29 11:04:06 - train: epoch 0134, iter [00880, 01251], lr: 0.001010, loss: 0.4022
2022-09-29 11:04:23 - train: epoch 0134, iter [00890, 01251], lr: 0.001010, loss: 0.4152
2022-09-29 11:04:41 - train: epoch 0134, iter [00900, 01251], lr: 0.001010, loss: 0.4185
2022-09-29 11:04:59 - train: epoch 0134, iter [00910, 01251], lr: 0.001010, loss: 0.4067
2022-09-29 11:05:16 - train: epoch 0134, iter [00920, 01251], lr: 0.001010, loss: 0.4022
2022-09-29 11:05:34 - train: epoch 0134, iter [00930, 01251], lr: 0.001010, loss: 0.3974
2022-09-29 11:05:52 - train: epoch 0134, iter [00940, 01251], lr: 0.001010, loss: 0.4177
2022-09-29 11:06:10 - train: epoch 0134, iter [00950, 01251], lr: 0.001010, loss: 0.4180
2022-09-29 11:06:27 - train: epoch 0134, iter [00960, 01251], lr: 0.001010, loss: 0.4069
2022-09-29 11:06:45 - train: epoch 0134, iter [00970, 01251], lr: 0.001010, loss: 0.4083
2022-09-29 11:07:03 - train: epoch 0134, iter [00980, 01251], lr: 0.001010, loss: 0.3916
2022-09-29 11:07:21 - train: epoch 0134, iter [00990, 01251], lr: 0.001010, loss: 0.4120
2022-09-29 11:07:38 - train: epoch 0134, iter [01000, 01251], lr: 0.001010, loss: 0.4090
2022-09-29 11:07:56 - train: epoch 0134, iter [01010, 01251], lr: 0.001010, loss: 0.4150
2022-09-29 11:08:14 - train: epoch 0134, iter [01020, 01251], lr: 0.001010, loss: 0.4056
2022-09-29 11:08:32 - train: epoch 0134, iter [01030, 01251], lr: 0.001010, loss: 0.3969
2022-09-29 11:08:49 - train: epoch 0134, iter [01040, 01251], lr: 0.001010, loss: 0.4137
2022-09-29 11:09:07 - train: epoch 0134, iter [01050, 01251], lr: 0.001010, loss: 0.4155
2022-09-29 11:09:25 - train: epoch 0134, iter [01060, 01251], lr: 0.001010, loss: 0.4091
2022-09-29 11:09:43 - train: epoch 0134, iter [01070, 01251], lr: 0.001010, loss: 0.4092
2022-09-29 11:10:00 - train: epoch 0134, iter [01080, 01251], lr: 0.001010, loss: 0.4083
2022-09-29 11:10:18 - train: epoch 0134, iter [01090, 01251], lr: 0.001010, loss: 0.3972
2022-09-29 11:10:36 - train: epoch 0134, iter [01100, 01251], lr: 0.001010, loss: 0.4156
2022-09-29 11:10:54 - train: epoch 0134, iter [01110, 01251], lr: 0.001010, loss: 0.3990
2022-09-29 11:11:12 - train: epoch 0134, iter [01120, 01251], lr: 0.001010, loss: 0.4199
2022-09-29 11:11:29 - train: epoch 0134, iter [01130, 01251], lr: 0.001010, loss: 0.3951
2022-09-29 11:11:47 - train: epoch 0134, iter [01140, 01251], lr: 0.001010, loss: 0.4284
2022-09-29 11:12:05 - train: epoch 0134, iter [01150, 01251], lr: 0.001010, loss: 0.4104
2022-09-29 11:12:23 - train: epoch 0134, iter [01160, 01251], lr: 0.001009, loss: 0.4112
2022-09-29 11:12:40 - train: epoch 0134, iter [01170, 01251], lr: 0.001009, loss: 0.3971
2022-09-29 11:12:58 - train: epoch 0134, iter [01180, 01251], lr: 0.001009, loss: 0.4015
2022-09-29 11:13:16 - train: epoch 0134, iter [01190, 01251], lr: 0.001009, loss: 0.4328
2022-09-29 11:13:34 - train: epoch 0134, iter [01200, 01251], lr: 0.001009, loss: 0.4318
2022-09-29 11:13:52 - train: epoch 0134, iter [01210, 01251], lr: 0.001009, loss: 0.4191
2022-09-29 11:14:09 - train: epoch 0134, iter [01220, 01251], lr: 0.001009, loss: 0.3971
2022-09-29 11:14:27 - train: epoch 0134, iter [01230, 01251], lr: 0.001009, loss: 0.4080
2022-09-29 11:14:45 - train: epoch 0134, iter [01240, 01251], lr: 0.001009, loss: 0.4019
2022-09-29 11:15:02 - train: epoch 0134, iter [01250, 01251], lr: 0.001009, loss: 0.4215
2022-09-29 11:15:06 - train: epoch 134, train_loss: 0.4113
2022-09-29 11:15:08 - until epoch: 134, best_loss: 0.4113
2022-09-29 11:15:08 - epoch 135 lr: 0.001009
2022-09-29 11:15:41 - train: epoch 0135, iter [00010, 01251], lr: 0.001009, loss: 0.4070
2022-09-29 11:15:59 - train: epoch 0135, iter [00020, 01251], lr: 0.001009, loss: 0.3971
2022-09-29 11:16:16 - train: epoch 0135, iter [00030, 01251], lr: 0.001009, loss: 0.4121
2022-09-29 11:16:34 - train: epoch 0135, iter [00040, 01251], lr: 0.001009, loss: 0.4171
2022-09-29 11:16:52 - train: epoch 0135, iter [00050, 01251], lr: 0.001009, loss: 0.4045
2022-09-29 11:17:10 - train: epoch 0135, iter [00060, 01251], lr: 0.001009, loss: 0.3974
2022-09-29 11:17:27 - train: epoch 0135, iter [00070, 01251], lr: 0.001009, loss: 0.3814
2022-09-29 11:17:45 - train: epoch 0135, iter [00080, 01251], lr: 0.001009, loss: 0.3992
2022-09-29 11:18:03 - train: epoch 0135, iter [00090, 01251], lr: 0.001009, loss: 0.4034
2022-09-29 11:18:20 - train: epoch 0135, iter [00100, 01251], lr: 0.001009, loss: 0.4069
2022-09-29 11:18:38 - train: epoch 0135, iter [00110, 01251], lr: 0.001009, loss: 0.4099
2022-09-29 11:18:56 - train: epoch 0135, iter [00120, 01251], lr: 0.001009, loss: 0.4020
2022-09-29 11:19:14 - train: epoch 0135, iter [00130, 01251], lr: 0.001009, loss: 0.3997
2022-09-29 11:19:31 - train: epoch 0135, iter [00140, 01251], lr: 0.001009, loss: 0.3935
2022-09-29 11:19:49 - train: epoch 0135, iter [00150, 01251], lr: 0.001009, loss: 0.3806
2022-09-29 11:20:07 - train: epoch 0135, iter [00160, 01251], lr: 0.001009, loss: 0.4030
2022-09-29 11:20:25 - train: epoch 0135, iter [00170, 01251], lr: 0.001009, loss: 0.4056
2022-09-29 11:20:43 - train: epoch 0135, iter [00180, 01251], lr: 0.001009, loss: 0.4314
2022-09-29 11:21:00 - train: epoch 0135, iter [00190, 01251], lr: 0.001009, loss: 0.4126
2022-09-29 11:21:18 - train: epoch 0135, iter [00200, 01251], lr: 0.001009, loss: 0.4200
2022-09-29 11:21:36 - train: epoch 0135, iter [00210, 01251], lr: 0.001009, loss: 0.4083
2022-09-29 11:21:54 - train: epoch 0135, iter [00220, 01251], lr: 0.001009, loss: 0.3950
2022-09-29 11:22:11 - train: epoch 0135, iter [00230, 01251], lr: 0.001008, loss: 0.3948
2022-09-29 11:22:29 - train: epoch 0135, iter [00240, 01251], lr: 0.001008, loss: 0.4232
2022-09-29 11:22:47 - train: epoch 0135, iter [00250, 01251], lr: 0.001008, loss: 0.4149
2022-09-29 11:23:05 - train: epoch 0135, iter [00260, 01251], lr: 0.001008, loss: 0.4130
2022-09-29 11:23:22 - train: epoch 0135, iter [00270, 01251], lr: 0.001008, loss: 0.4225
2022-09-29 11:23:40 - train: epoch 0135, iter [00280, 01251], lr: 0.001008, loss: 0.4331
2022-09-29 11:23:58 - train: epoch 0135, iter [00290, 01251], lr: 0.001008, loss: 0.4028
2022-09-29 11:24:16 - train: epoch 0135, iter [00300, 01251], lr: 0.001008, loss: 0.4223
2022-09-29 11:24:34 - train: epoch 0135, iter [00310, 01251], lr: 0.001008, loss: 0.4143
2022-09-29 11:24:51 - train: epoch 0135, iter [00320, 01251], lr: 0.001008, loss: 0.4098
2022-09-29 11:25:09 - train: epoch 0135, iter [00330, 01251], lr: 0.001008, loss: 0.4108
2022-09-29 11:25:27 - train: epoch 0135, iter [00340, 01251], lr: 0.001008, loss: 0.3923
2022-09-29 11:25:45 - train: epoch 0135, iter [00350, 01251], lr: 0.001008, loss: 0.3984
2022-09-29 11:26:02 - train: epoch 0135, iter [00360, 01251], lr: 0.001008, loss: 0.4008
2022-09-29 11:26:20 - train: epoch 0135, iter [00370, 01251], lr: 0.001008, loss: 0.4122
2022-09-29 11:26:38 - train: epoch 0135, iter [00380, 01251], lr: 0.001008, loss: 0.4241
2022-09-29 11:26:56 - train: epoch 0135, iter [00390, 01251], lr: 0.001008, loss: 0.4372
2022-09-29 11:27:14 - train: epoch 0135, iter [00400, 01251], lr: 0.001008, loss: 0.4041
2022-09-29 11:27:31 - train: epoch 0135, iter [00410, 01251], lr: 0.001008, loss: 0.4035
2022-09-29 11:27:49 - train: epoch 0135, iter [00420, 01251], lr: 0.001008, loss: 0.4146
2022-09-29 11:28:07 - train: epoch 0135, iter [00430, 01251], lr: 0.001008, loss: 0.4175
2022-09-29 11:28:25 - train: epoch 0135, iter [00440, 01251], lr: 0.001008, loss: 0.4176
2022-09-29 11:28:42 - train: epoch 0135, iter [00450, 01251], lr: 0.001008, loss: 0.4186
2022-09-29 11:29:00 - train: epoch 0135, iter [00460, 01251], lr: 0.001008, loss: 0.4072
2022-09-29 11:29:18 - train: epoch 0135, iter [00470, 01251], lr: 0.001008, loss: 0.4145
2022-09-29 11:29:36 - train: epoch 0135, iter [00480, 01251], lr: 0.001008, loss: 0.3836
2022-09-29 11:29:53 - train: epoch 0135, iter [00490, 01251], lr: 0.001008, loss: 0.4011
2022-09-29 11:30:11 - train: epoch 0135, iter [00500, 01251], lr: 0.001008, loss: 0.4045
2022-09-29 11:30:29 - train: epoch 0135, iter [00510, 01251], lr: 0.001008, loss: 0.4272
2022-09-29 11:30:46 - train: epoch 0135, iter [00520, 01251], lr: 0.001008, loss: 0.4041
2022-09-29 11:31:04 - train: epoch 0135, iter [00530, 01251], lr: 0.001008, loss: 0.4203
2022-09-29 11:31:22 - train: epoch 0135, iter [00540, 01251], lr: 0.001008, loss: 0.4115
2022-09-29 11:31:40 - train: epoch 0135, iter [00550, 01251], lr: 0.001008, loss: 0.3980
2022-09-29 11:31:58 - train: epoch 0135, iter [00560, 01251], lr: 0.001007, loss: 0.3991
2022-09-29 11:32:16 - train: epoch 0135, iter [00570, 01251], lr: 0.001007, loss: 0.4025
2022-09-29 11:32:33 - train: epoch 0135, iter [00580, 01251], lr: 0.001007, loss: 0.4014
2022-09-29 11:32:51 - train: epoch 0135, iter [00590, 01251], lr: 0.001007, loss: 0.3883
2022-09-29 11:33:09 - train: epoch 0135, iter [00600, 01251], lr: 0.001007, loss: 0.4099
2022-09-29 11:33:27 - train: epoch 0135, iter [00610, 01251], lr: 0.001007, loss: 0.4248
2022-09-29 11:33:45 - train: epoch 0135, iter [00620, 01251], lr: 0.001007, loss: 0.4247
2022-09-29 11:34:03 - train: epoch 0135, iter [00630, 01251], lr: 0.001007, loss: 0.3969
2022-09-29 11:34:21 - train: epoch 0135, iter [00640, 01251], lr: 0.001007, loss: 0.4265
2022-09-29 11:34:39 - train: epoch 0135, iter [00650, 01251], lr: 0.001007, loss: 0.4105
2022-09-29 11:34:57 - train: epoch 0135, iter [00660, 01251], lr: 0.001007, loss: 0.4064
2022-09-29 11:35:15 - train: epoch 0135, iter [00670, 01251], lr: 0.001007, loss: 0.4120
2022-09-29 11:35:33 - train: epoch 0135, iter [00680, 01251], lr: 0.001007, loss: 0.4165
2022-09-29 11:35:51 - train: epoch 0135, iter [00690, 01251], lr: 0.001007, loss: 0.3921
2022-09-29 11:36:08 - train: epoch 0135, iter [00700, 01251], lr: 0.001007, loss: 0.4216
2022-09-29 11:36:26 - train: epoch 0135, iter [00710, 01251], lr: 0.001007, loss: 0.4208
2022-09-29 11:36:44 - train: epoch 0135, iter [00720, 01251], lr: 0.001007, loss: 0.4059
2022-09-29 11:37:02 - train: epoch 0135, iter [00730, 01251], lr: 0.001007, loss: 0.4139
2022-09-29 11:37:20 - train: epoch 0135, iter [00740, 01251], lr: 0.001007, loss: 0.4118
2022-09-29 11:37:38 - train: epoch 0135, iter [00750, 01251], lr: 0.001007, loss: 0.4096
2022-09-29 11:37:56 - train: epoch 0135, iter [00760, 01251], lr: 0.001007, loss: 0.4104
2022-09-29 11:38:14 - train: epoch 0135, iter [00770, 01251], lr: 0.001007, loss: 0.4227
2022-09-29 11:38:31 - train: epoch 0135, iter [00780, 01251], lr: 0.001007, loss: 0.4007
2022-09-29 11:38:49 - train: epoch 0135, iter [00790, 01251], lr: 0.001007, loss: 0.4182
2022-09-29 11:39:07 - train: epoch 0135, iter [00800, 01251], lr: 0.001007, loss: 0.4164
2022-09-29 11:39:25 - train: epoch 0135, iter [00810, 01251], lr: 0.001007, loss: 0.4063
2022-09-29 11:39:43 - train: epoch 0135, iter [00820, 01251], lr: 0.001007, loss: 0.4179
2022-09-29 11:40:01 - train: epoch 0135, iter [00830, 01251], lr: 0.001007, loss: 0.4204
2022-09-29 11:40:19 - train: epoch 0135, iter [00840, 01251], lr: 0.001007, loss: 0.4195
2022-09-29 11:40:37 - train: epoch 0135, iter [00850, 01251], lr: 0.001007, loss: 0.4085
2022-09-29 11:40:54 - train: epoch 0135, iter [00860, 01251], lr: 0.001007, loss: 0.3954
2022-09-29 11:41:12 - train: epoch 0135, iter [00870, 01251], lr: 0.001007, loss: 0.4198
2022-09-29 11:41:30 - train: epoch 0135, iter [00880, 01251], lr: 0.001006, loss: 0.4222
2022-09-29 11:41:48 - train: epoch 0135, iter [00890, 01251], lr: 0.001006, loss: 0.4066
2022-09-29 11:42:06 - train: epoch 0135, iter [00900, 01251], lr: 0.001006, loss: 0.4156
2022-09-29 11:42:24 - train: epoch 0135, iter [00910, 01251], lr: 0.001006, loss: 0.3845
2022-09-29 11:42:41 - train: epoch 0135, iter [00920, 01251], lr: 0.001006, loss: 0.4060
2022-09-29 11:42:59 - train: epoch 0135, iter [00930, 01251], lr: 0.001006, loss: 0.4142
2022-09-29 11:43:17 - train: epoch 0135, iter [00940, 01251], lr: 0.001006, loss: 0.4239
2022-09-29 11:43:35 - train: epoch 0135, iter [00950, 01251], lr: 0.001006, loss: 0.4233
2022-09-29 11:43:52 - train: epoch 0135, iter [00960, 01251], lr: 0.001006, loss: 0.4000
2022-09-29 11:44:10 - train: epoch 0135, iter [00970, 01251], lr: 0.001006, loss: 0.4169
2022-09-29 11:44:28 - train: epoch 0135, iter [00980, 01251], lr: 0.001006, loss: 0.3998
2022-09-29 11:44:45 - train: epoch 0135, iter [00990, 01251], lr: 0.001006, loss: 0.4215
2022-09-29 11:45:03 - train: epoch 0135, iter [01000, 01251], lr: 0.001006, loss: 0.4150
2022-09-29 11:45:20 - train: epoch 0135, iter [01010, 01251], lr: 0.001006, loss: 0.4018
2022-09-29 11:45:38 - train: epoch 0135, iter [01020, 01251], lr: 0.001006, loss: 0.4111
2022-09-29 11:45:56 - train: epoch 0135, iter [01030, 01251], lr: 0.001006, loss: 0.4012
2022-09-29 11:46:13 - train: epoch 0135, iter [01040, 01251], lr: 0.001006, loss: 0.4018
2022-09-29 11:46:31 - train: epoch 0135, iter [01050, 01251], lr: 0.001006, loss: 0.4175
2022-09-29 11:46:49 - train: epoch 0135, iter [01060, 01251], lr: 0.001006, loss: 0.4241
2022-09-29 11:47:07 - train: epoch 0135, iter [01070, 01251], lr: 0.001006, loss: 0.3899
2022-09-29 11:47:24 - train: epoch 0135, iter [01080, 01251], lr: 0.001006, loss: 0.4151
2022-09-29 11:47:42 - train: epoch 0135, iter [01090, 01251], lr: 0.001006, loss: 0.4041
2022-09-29 11:48:00 - train: epoch 0135, iter [01100, 01251], lr: 0.001006, loss: 0.4174
2022-09-29 11:48:17 - train: epoch 0135, iter [01110, 01251], lr: 0.001006, loss: 0.4152
2022-09-29 11:48:35 - train: epoch 0135, iter [01120, 01251], lr: 0.001006, loss: 0.3992
2022-09-29 11:48:53 - train: epoch 0135, iter [01130, 01251], lr: 0.001006, loss: 0.3961
2022-09-29 11:49:10 - train: epoch 0135, iter [01140, 01251], lr: 0.001006, loss: 0.4035
2022-09-29 11:49:28 - train: epoch 0135, iter [01150, 01251], lr: 0.001006, loss: 0.3908
2022-09-29 11:49:46 - train: epoch 0135, iter [01160, 01251], lr: 0.001006, loss: 0.4217
2022-09-29 11:50:03 - train: epoch 0135, iter [01170, 01251], lr: 0.001006, loss: 0.4116
2022-09-29 11:50:21 - train: epoch 0135, iter [01180, 01251], lr: 0.001006, loss: 0.4116
2022-09-29 11:50:39 - train: epoch 0135, iter [01190, 01251], lr: 0.001006, loss: 0.4144
2022-09-29 11:50:57 - train: epoch 0135, iter [01200, 01251], lr: 0.001006, loss: 0.4012
2022-09-29 11:51:14 - train: epoch 0135, iter [01210, 01251], lr: 0.001005, loss: 0.4049
2022-09-29 11:51:32 - train: epoch 0135, iter [01220, 01251], lr: 0.001005, loss: 0.4241
2022-09-29 11:51:50 - train: epoch 0135, iter [01230, 01251], lr: 0.001005, loss: 0.4112
2022-09-29 11:52:07 - train: epoch 0135, iter [01240, 01251], lr: 0.001005, loss: 0.4174
2022-09-29 11:52:25 - train: epoch 0135, iter [01250, 01251], lr: 0.001005, loss: 0.4091
2022-09-29 11:52:28 - train: epoch 135, train_loss: 0.4112
2022-09-29 11:52:31 - until epoch: 135, best_loss: 0.4112
2022-09-29 11:52:31 - epoch 136 lr: 0.001005
2022-09-29 11:53:04 - train: epoch 0136, iter [00010, 01251], lr: 0.001005, loss: 0.4042
2022-09-29 11:53:21 - train: epoch 0136, iter [00020, 01251], lr: 0.001005, loss: 0.4245
2022-09-29 11:53:39 - train: epoch 0136, iter [00030, 01251], lr: 0.001005, loss: 0.4125
2022-09-29 11:53:57 - train: epoch 0136, iter [00040, 01251], lr: 0.001005, loss: 0.4219
2022-09-29 11:54:14 - train: epoch 0136, iter [00050, 01251], lr: 0.001005, loss: 0.4091
2022-09-29 11:54:32 - train: epoch 0136, iter [00060, 01251], lr: 0.001005, loss: 0.3954
2022-09-29 11:54:50 - train: epoch 0136, iter [00070, 01251], lr: 0.001005, loss: 0.3885
2022-09-29 11:55:07 - train: epoch 0136, iter [00080, 01251], lr: 0.001005, loss: 0.4144
2022-09-29 11:55:25 - train: epoch 0136, iter [00090, 01251], lr: 0.001005, loss: 0.4008
2022-09-29 11:55:43 - train: epoch 0136, iter [00100, 01251], lr: 0.001005, loss: 0.4130
2022-09-29 11:56:01 - train: epoch 0136, iter [00110, 01251], lr: 0.001005, loss: 0.4210
2022-09-29 11:56:18 - train: epoch 0136, iter [00120, 01251], lr: 0.001005, loss: 0.4257
2022-09-29 11:56:36 - train: epoch 0136, iter [00130, 01251], lr: 0.001005, loss: 0.4258
2022-09-29 11:56:54 - train: epoch 0136, iter [00140, 01251], lr: 0.001005, loss: 0.4021
2022-09-29 11:57:11 - train: epoch 0136, iter [00150, 01251], lr: 0.001005, loss: 0.4104
2022-09-29 11:57:29 - train: epoch 0136, iter [00160, 01251], lr: 0.001005, loss: 0.3942
2022-09-29 11:57:47 - train: epoch 0136, iter [00170, 01251], lr: 0.001005, loss: 0.4042
2022-09-29 11:58:04 - train: epoch 0136, iter [00180, 01251], lr: 0.001005, loss: 0.4197
2022-09-29 11:58:22 - train: epoch 0136, iter [00190, 01251], lr: 0.001005, loss: 0.4302
2022-09-29 11:58:40 - train: epoch 0136, iter [00200, 01251], lr: 0.001005, loss: 0.4119
2022-09-29 11:58:57 - train: epoch 0136, iter [00210, 01251], lr: 0.001005, loss: 0.4149
2022-09-29 11:59:15 - train: epoch 0136, iter [00220, 01251], lr: 0.001005, loss: 0.4086
2022-09-29 11:59:33 - train: epoch 0136, iter [00230, 01251], lr: 0.001005, loss: 0.4167
2022-09-29 11:59:51 - train: epoch 0136, iter [00240, 01251], lr: 0.001005, loss: 0.3981
2022-09-29 12:00:08 - train: epoch 0136, iter [00250, 01251], lr: 0.001005, loss: 0.4236
2022-09-29 12:00:26 - train: epoch 0136, iter [00260, 01251], lr: 0.001005, loss: 0.4108
2022-09-29 12:00:44 - train: epoch 0136, iter [00270, 01251], lr: 0.001005, loss: 0.4034
2022-09-29 12:01:01 - train: epoch 0136, iter [00280, 01251], lr: 0.001004, loss: 0.4197
2022-09-29 12:01:19 - train: epoch 0136, iter [00290, 01251], lr: 0.001004, loss: 0.4015
2022-09-29 12:01:37 - train: epoch 0136, iter [00300, 01251], lr: 0.001004, loss: 0.4186
2022-09-29 12:01:54 - train: epoch 0136, iter [00310, 01251], lr: 0.001004, loss: 0.4065
2022-09-29 12:02:12 - train: epoch 0136, iter [00320, 01251], lr: 0.001004, loss: 0.4043
2022-09-29 12:02:30 - train: epoch 0136, iter [00330, 01251], lr: 0.001004, loss: 0.4250
2022-09-29 12:02:48 - train: epoch 0136, iter [00340, 01251], lr: 0.001004, loss: 0.4171
2022-09-29 12:03:05 - train: epoch 0136, iter [00350, 01251], lr: 0.001004, loss: 0.4126
2022-09-29 12:03:23 - train: epoch 0136, iter [00360, 01251], lr: 0.001004, loss: 0.4201
2022-09-29 12:03:41 - train: epoch 0136, iter [00370, 01251], lr: 0.001004, loss: 0.3873
2022-09-29 12:03:59 - train: epoch 0136, iter [00380, 01251], lr: 0.001004, loss: 0.4003
2022-09-29 12:04:16 - train: epoch 0136, iter [00390, 01251], lr: 0.001004, loss: 0.3818
2022-09-29 12:04:34 - train: epoch 0136, iter [00400, 01251], lr: 0.001004, loss: 0.3993
2022-09-29 12:04:51 - train: epoch 0136, iter [00410, 01251], lr: 0.001004, loss: 0.4031
2022-09-29 12:05:09 - train: epoch 0136, iter [00420, 01251], lr: 0.001004, loss: 0.4118
2022-09-29 12:05:27 - train: epoch 0136, iter [00430, 01251], lr: 0.001004, loss: 0.4177
2022-09-29 12:05:45 - train: epoch 0136, iter [00440, 01251], lr: 0.001004, loss: 0.4016
2022-09-29 12:06:03 - train: epoch 0136, iter [00450, 01251], lr: 0.001004, loss: 0.4258
2022-09-29 12:06:20 - train: epoch 0136, iter [00460, 01251], lr: 0.001004, loss: 0.4230
2022-09-29 12:06:38 - train: epoch 0136, iter [00470, 01251], lr: 0.001004, loss: 0.4433
2022-09-29 12:06:56 - train: epoch 0136, iter [00480, 01251], lr: 0.001004, loss: 0.4051
2022-09-29 12:07:13 - train: epoch 0136, iter [00490, 01251], lr: 0.001004, loss: 0.4198
2022-09-29 12:07:31 - train: epoch 0136, iter [00500, 01251], lr: 0.001004, loss: 0.4348
2022-09-29 12:07:49 - train: epoch 0136, iter [00510, 01251], lr: 0.001004, loss: 0.4012
2022-09-29 12:08:07 - train: epoch 0136, iter [00520, 01251], lr: 0.001004, loss: 0.4115
2022-09-29 12:08:25 - train: epoch 0136, iter [00530, 01251], lr: 0.001004, loss: 0.4127
2022-09-29 12:08:42 - train: epoch 0136, iter [00540, 01251], lr: 0.001004, loss: 0.4154
2022-09-29 12:09:00 - train: epoch 0136, iter [00550, 01251], lr: 0.001004, loss: 0.4111
2022-09-29 12:09:18 - train: epoch 0136, iter [00560, 01251], lr: 0.001004, loss: 0.4028
2022-09-29 12:09:36 - train: epoch 0136, iter [00570, 01251], lr: 0.001004, loss: 0.4051
2022-09-29 12:09:53 - train: epoch 0136, iter [00580, 01251], lr: 0.001004, loss: 0.4175
2022-09-29 12:10:11 - train: epoch 0136, iter [00590, 01251], lr: 0.001004, loss: 0.4169
2022-09-29 12:10:29 - train: epoch 0136, iter [00600, 01251], lr: 0.001003, loss: 0.4196
2022-09-29 12:10:47 - train: epoch 0136, iter [00610, 01251], lr: 0.001003, loss: 0.4053
2022-09-29 12:11:04 - train: epoch 0136, iter [00620, 01251], lr: 0.001003, loss: 0.4058
2022-09-29 12:11:22 - train: epoch 0136, iter [00630, 01251], lr: 0.001003, loss: 0.4128
2022-09-29 12:11:40 - train: epoch 0136, iter [00640, 01251], lr: 0.001003, loss: 0.4136
2022-09-29 12:11:57 - train: epoch 0136, iter [00650, 01251], lr: 0.001003, loss: 0.4144
2022-09-29 12:12:15 - train: epoch 0136, iter [00660, 01251], lr: 0.001003, loss: 0.4132
2022-09-29 12:12:33 - train: epoch 0136, iter [00670, 01251], lr: 0.001003, loss: 0.4081
2022-09-29 12:12:50 - train: epoch 0136, iter [00680, 01251], lr: 0.001003, loss: 0.4161
2022-09-29 12:13:08 - train: epoch 0136, iter [00690, 01251], lr: 0.001003, loss: 0.4037
2022-09-29 12:13:26 - train: epoch 0136, iter [00700, 01251], lr: 0.001003, loss: 0.4077
2022-09-29 12:13:44 - train: epoch 0136, iter [00710, 01251], lr: 0.001003, loss: 0.4257
2022-09-29 12:14:01 - train: epoch 0136, iter [00720, 01251], lr: 0.001003, loss: 0.4226
2022-09-29 12:14:19 - train: epoch 0136, iter [00730, 01251], lr: 0.001003, loss: 0.4151
2022-09-29 12:14:37 - train: epoch 0136, iter [00740, 01251], lr: 0.001003, loss: 0.3931
2022-09-29 12:14:54 - train: epoch 0136, iter [00750, 01251], lr: 0.001003, loss: 0.4193
2022-09-29 12:15:12 - train: epoch 0136, iter [00760, 01251], lr: 0.001003, loss: 0.4284
2022-09-29 12:15:30 - train: epoch 0136, iter [00770, 01251], lr: 0.001003, loss: 0.4338
2022-09-29 12:15:47 - train: epoch 0136, iter [00780, 01251], lr: 0.001003, loss: 0.4076
2022-09-29 12:16:05 - train: epoch 0136, iter [00790, 01251], lr: 0.001003, loss: 0.4050
2022-09-29 12:16:23 - train: epoch 0136, iter [00800, 01251], lr: 0.001003, loss: 0.4064
2022-09-29 12:16:41 - train: epoch 0136, iter [00810, 01251], lr: 0.001003, loss: 0.4241
2022-09-29 12:16:58 - train: epoch 0136, iter [00820, 01251], lr: 0.001003, loss: 0.4178
2022-09-29 12:17:16 - train: epoch 0136, iter [00830, 01251], lr: 0.001003, loss: 0.4223
2022-09-29 12:17:33 - train: epoch 0136, iter [00840, 01251], lr: 0.001003, loss: 0.3943
2022-09-29 12:17:51 - train: epoch 0136, iter [00850, 01251], lr: 0.001003, loss: 0.4240
2022-09-29 12:18:09 - train: epoch 0136, iter [00860, 01251], lr: 0.001003, loss: 0.4255
2022-09-29 12:18:26 - train: epoch 0136, iter [00870, 01251], lr: 0.001003, loss: 0.4244
2022-09-29 12:18:44 - train: epoch 0136, iter [00880, 01251], lr: 0.001003, loss: 0.4132
2022-09-29 12:19:02 - train: epoch 0136, iter [00890, 01251], lr: 0.001003, loss: 0.4062
2022-09-29 12:19:19 - train: epoch 0136, iter [00900, 01251], lr: 0.001003, loss: 0.4153
2022-09-29 12:19:37 - train: epoch 0136, iter [00910, 01251], lr: 0.001003, loss: 0.4112
2022-09-29 12:19:55 - train: epoch 0136, iter [00920, 01251], lr: 0.001003, loss: 0.4165
2022-09-29 12:20:12 - train: epoch 0136, iter [00930, 01251], lr: 0.001002, loss: 0.4199
2022-09-29 12:20:30 - train: epoch 0136, iter [00940, 01251], lr: 0.001002, loss: 0.4213
2022-09-29 12:20:48 - train: epoch 0136, iter [00950, 01251], lr: 0.001002, loss: 0.4054
2022-09-29 12:21:05 - train: epoch 0136, iter [00960, 01251], lr: 0.001002, loss: 0.4305
2022-09-29 12:21:23 - train: epoch 0136, iter [00970, 01251], lr: 0.001002, loss: 0.4063
2022-09-29 12:21:41 - train: epoch 0136, iter [00980, 01251], lr: 0.001002, loss: 0.4149
2022-09-29 12:21:58 - train: epoch 0136, iter [00990, 01251], lr: 0.001002, loss: 0.4163
2022-09-29 12:22:16 - train: epoch 0136, iter [01000, 01251], lr: 0.001002, loss: 0.4058
2022-09-29 12:22:34 - train: epoch 0136, iter [01010, 01251], lr: 0.001002, loss: 0.4408
2022-09-29 12:22:51 - train: epoch 0136, iter [01020, 01251], lr: 0.001002, loss: 0.4111
2022-09-29 12:23:09 - train: epoch 0136, iter [01030, 01251], lr: 0.001002, loss: 0.4089
2022-09-29 12:23:27 - train: epoch 0136, iter [01040, 01251], lr: 0.001002, loss: 0.4342
2022-09-29 12:23:45 - train: epoch 0136, iter [01050, 01251], lr: 0.001002, loss: 0.4324
2022-09-29 12:24:02 - train: epoch 0136, iter [01060, 01251], lr: 0.001002, loss: 0.4051
2022-09-29 12:24:20 - train: epoch 0136, iter [01070, 01251], lr: 0.001002, loss: 0.4112
2022-09-29 12:24:38 - train: epoch 0136, iter [01080, 01251], lr: 0.001002, loss: 0.3845
2022-09-29 12:24:55 - train: epoch 0136, iter [01090, 01251], lr: 0.001002, loss: 0.4118
2022-09-29 12:25:13 - train: epoch 0136, iter [01100, 01251], lr: 0.001002, loss: 0.4092
2022-09-29 12:25:31 - train: epoch 0136, iter [01110, 01251], lr: 0.001002, loss: 0.4111
2022-09-29 12:25:48 - train: epoch 0136, iter [01120, 01251], lr: 0.001002, loss: 0.4044
2022-09-29 12:26:06 - train: epoch 0136, iter [01130, 01251], lr: 0.001002, loss: 0.4058
2022-09-29 12:26:24 - train: epoch 0136, iter [01140, 01251], lr: 0.001002, loss: 0.4149
2022-09-29 12:26:41 - train: epoch 0136, iter [01150, 01251], lr: 0.001002, loss: 0.3992
2022-09-29 12:26:59 - train: epoch 0136, iter [01160, 01251], lr: 0.001002, loss: 0.4370
2022-09-29 12:27:17 - train: epoch 0136, iter [01170, 01251], lr: 0.001002, loss: 0.4097
2022-09-29 12:27:35 - train: epoch 0136, iter [01180, 01251], lr: 0.001002, loss: 0.4104
2022-09-29 12:27:52 - train: epoch 0136, iter [01190, 01251], lr: 0.001002, loss: 0.4060
2022-09-29 12:28:10 - train: epoch 0136, iter [01200, 01251], lr: 0.001002, loss: 0.4329
2022-09-29 12:28:28 - train: epoch 0136, iter [01210, 01251], lr: 0.001002, loss: 0.4146
2022-09-29 12:28:45 - train: epoch 0136, iter [01220, 01251], lr: 0.001002, loss: 0.4085
2022-09-29 12:29:03 - train: epoch 0136, iter [01230, 01251], lr: 0.001002, loss: 0.3997
2022-09-29 12:29:21 - train: epoch 0136, iter [01240, 01251], lr: 0.001002, loss: 0.3850
2022-09-29 12:29:38 - train: epoch 0136, iter [01250, 01251], lr: 0.001001, loss: 0.3990
2022-09-29 12:29:42 - train: epoch 136, train_loss: 0.4113
2022-09-29 12:29:43 - until epoch: 136, best_loss: 0.4112
2022-09-29 12:29:43 - epoch 137 lr: 0.001001
2022-09-29 12:30:16 - train: epoch 0137, iter [00010, 01251], lr: 0.001001, loss: 0.4070
2022-09-29 12:30:33 - train: epoch 0137, iter [00020, 01251], lr: 0.001001, loss: 0.4092
2022-09-29 12:30:51 - train: epoch 0137, iter [00030, 01251], lr: 0.001001, loss: 0.4153
2022-09-29 12:31:09 - train: epoch 0137, iter [00040, 01251], lr: 0.001001, loss: 0.4079
2022-09-29 12:31:26 - train: epoch 0137, iter [00050, 01251], lr: 0.001001, loss: 0.3799
2022-09-29 12:31:44 - train: epoch 0137, iter [00060, 01251], lr: 0.001001, loss: 0.3951
2022-09-29 12:32:02 - train: epoch 0137, iter [00070, 01251], lr: 0.001001, loss: 0.4080
2022-09-29 12:32:19 - train: epoch 0137, iter [00080, 01251], lr: 0.001001, loss: 0.4045
2022-09-29 12:32:37 - train: epoch 0137, iter [00090, 01251], lr: 0.001001, loss: 0.3958
2022-09-29 12:32:55 - train: epoch 0137, iter [00100, 01251], lr: 0.001001, loss: 0.4284
2022-09-29 12:33:13 - train: epoch 0137, iter [00110, 01251], lr: 0.001001, loss: 0.4117
2022-09-29 12:33:30 - train: epoch 0137, iter [00120, 01251], lr: 0.001001, loss: 0.3976
2022-09-29 12:33:48 - train: epoch 0137, iter [00130, 01251], lr: 0.001001, loss: 0.4018
2022-09-29 12:34:06 - train: epoch 0137, iter [00140, 01251], lr: 0.001001, loss: 0.4009
2022-09-29 12:34:23 - train: epoch 0137, iter [00150, 01251], lr: 0.001001, loss: 0.4308
2022-09-29 12:34:41 - train: epoch 0137, iter [00160, 01251], lr: 0.001001, loss: 0.3990
2022-09-29 12:34:59 - train: epoch 0137, iter [00170, 01251], lr: 0.001001, loss: 0.4138
2022-09-29 12:35:16 - train: epoch 0137, iter [00180, 01251], lr: 0.001001, loss: 0.4213
2022-09-29 12:35:34 - train: epoch 0137, iter [00190, 01251], lr: 0.001001, loss: 0.4110
2022-09-29 12:35:52 - train: epoch 0137, iter [00200, 01251], lr: 0.001001, loss: 0.3999
2022-09-29 12:36:10 - train: epoch 0137, iter [00210, 01251], lr: 0.001001, loss: 0.4042
2022-09-29 12:36:28 - train: epoch 0137, iter [00220, 01251], lr: 0.001001, loss: 0.4078
2022-09-29 12:36:46 - train: epoch 0137, iter [00230, 01251], lr: 0.001001, loss: 0.4204
2022-09-29 12:37:03 - train: epoch 0137, iter [00240, 01251], lr: 0.001001, loss: 0.4217
2022-09-29 12:37:21 - train: epoch 0137, iter [00250, 01251], lr: 0.001001, loss: 0.4087
2022-09-29 12:37:39 - train: epoch 0137, iter [00260, 01251], lr: 0.001001, loss: 0.4081
2022-09-29 12:37:57 - train: epoch 0137, iter [00270, 01251], lr: 0.001001, loss: 0.4317
2022-09-29 12:38:14 - train: epoch 0137, iter [00280, 01251], lr: 0.001001, loss: 0.4206
2022-09-29 12:38:32 - train: epoch 0137, iter [00290, 01251], lr: 0.001001, loss: 0.4214
2022-09-29 12:38:50 - train: epoch 0137, iter [00300, 01251], lr: 0.001001, loss: 0.4105
2022-09-29 12:39:08 - train: epoch 0137, iter [00310, 01251], lr: 0.001001, loss: 0.4103
2022-09-29 12:39:25 - train: epoch 0137, iter [00320, 01251], lr: 0.001000, loss: 0.4244
2022-09-29 12:39:43 - train: epoch 0137, iter [00330, 01251], lr: 0.001000, loss: 0.3977
2022-09-29 12:40:01 - train: epoch 0137, iter [00340, 01251], lr: 0.001000, loss: 0.4060
2022-09-29 12:40:19 - train: epoch 0137, iter [00350, 01251], lr: 0.001000, loss: 0.4215
2022-09-29 12:40:37 - train: epoch 0137, iter [00360, 01251], lr: 0.001000, loss: 0.4081
2022-09-29 12:40:54 - train: epoch 0137, iter [00370, 01251], lr: 0.001000, loss: 0.4220
2022-09-29 12:41:12 - train: epoch 0137, iter [00380, 01251], lr: 0.001000, loss: 0.3895
2022-09-29 12:41:30 - train: epoch 0137, iter [00390, 01251], lr: 0.001000, loss: 0.4062
2022-09-29 12:41:47 - train: epoch 0137, iter [00400, 01251], lr: 0.001000, loss: 0.4180
2022-09-29 12:42:05 - train: epoch 0137, iter [00410, 01251], lr: 0.001000, loss: 0.4113
2022-09-29 12:42:23 - train: epoch 0137, iter [00420, 01251], lr: 0.001000, loss: 0.4035
2022-09-29 12:42:40 - train: epoch 0137, iter [00430, 01251], lr: 0.001000, loss: 0.4009
2022-09-29 12:42:58 - train: epoch 0137, iter [00440, 01251], lr: 0.001000, loss: 0.4220
2022-09-29 12:43:16 - train: epoch 0137, iter [00450, 01251], lr: 0.001000, loss: 0.4157
2022-09-29 12:43:33 - train: epoch 0137, iter [00460, 01251], lr: 0.001000, loss: 0.3982
2022-09-29 12:43:51 - train: epoch 0137, iter [00470, 01251], lr: 0.001000, loss: 0.4143
2022-09-29 12:44:09 - train: epoch 0137, iter [00480, 01251], lr: 0.001000, loss: 0.4218
2022-09-29 12:44:27 - train: epoch 0137, iter [00490, 01251], lr: 0.001000, loss: 0.4134
2022-09-29 12:44:44 - train: epoch 0137, iter [00500, 01251], lr: 0.001000, loss: 0.4262
2022-09-29 12:45:02 - train: epoch 0137, iter [00510, 01251], lr: 0.001000, loss: 0.4141
2022-09-29 12:45:20 - train: epoch 0137, iter [00520, 01251], lr: 0.001000, loss: 0.4191
2022-09-29 12:45:38 - train: epoch 0137, iter [00530, 01251], lr: 0.001000, loss: 0.4096
2022-09-29 12:45:55 - train: epoch 0137, iter [00540, 01251], lr: 0.001000, loss: 0.4177
2022-09-29 12:46:13 - train: epoch 0137, iter [00550, 01251], lr: 0.001000, loss: 0.4106
2022-09-29 12:46:31 - train: epoch 0137, iter [00560, 01251], lr: 0.001000, loss: 0.4203
2022-09-29 12:46:49 - train: epoch 0137, iter [00570, 01251], lr: 0.001000, loss: 0.4151
2022-09-29 12:47:06 - train: epoch 0137, iter [00580, 01251], lr: 0.001000, loss: 0.4214
2022-09-29 12:47:24 - train: epoch 0137, iter [00590, 01251], lr: 0.001000, loss: 0.4043
2022-09-29 12:47:42 - train: epoch 0137, iter [00600, 01251], lr: 0.001000, loss: 0.4139
2022-09-29 12:48:00 - train: epoch 0137, iter [00610, 01251], lr: 0.001000, loss: 0.4061
2022-09-29 12:48:17 - train: epoch 0137, iter [00620, 01251], lr: 0.001000, loss: 0.4166
2022-09-29 12:48:35 - train: epoch 0137, iter [00630, 01251], lr: 0.001000, loss: 0.4258
2022-09-29 12:48:53 - train: epoch 0137, iter [00640, 01251], lr: 0.000999, loss: 0.4198
2022-09-29 12:49:10 - train: epoch 0137, iter [00650, 01251], lr: 0.000999, loss: 0.4044
2022-09-29 12:49:28 - train: epoch 0137, iter [00660, 01251], lr: 0.000999, loss: 0.4117
2022-09-29 12:49:46 - train: epoch 0137, iter [00670, 01251], lr: 0.000999, loss: 0.4304
2022-09-29 12:50:04 - train: epoch 0137, iter [00680, 01251], lr: 0.000999, loss: 0.4071
2022-09-29 12:50:21 - train: epoch 0137, iter [00690, 01251], lr: 0.000999, loss: 0.4034
2022-09-29 12:50:39 - train: epoch 0137, iter [00700, 01251], lr: 0.000999, loss: 0.4161
2022-09-29 12:50:57 - train: epoch 0137, iter [00710, 01251], lr: 0.000999, loss: 0.4108
2022-09-29 12:51:15 - train: epoch 0137, iter [00720, 01251], lr: 0.000999, loss: 0.4251
2022-09-29 12:51:32 - train: epoch 0137, iter [00730, 01251], lr: 0.000999, loss: 0.4232
2022-09-29 12:51:50 - train: epoch 0137, iter [00740, 01251], lr: 0.000999, loss: 0.4313
2022-09-29 12:52:08 - train: epoch 0137, iter [00750, 01251], lr: 0.000999, loss: 0.4108
2022-09-29 12:52:26 - train: epoch 0137, iter [00760, 01251], lr: 0.000999, loss: 0.3970
2022-09-29 12:52:43 - train: epoch 0137, iter [00770, 01251], lr: 0.000999, loss: 0.3893
2022-09-29 12:53:01 - train: epoch 0137, iter [00780, 01251], lr: 0.000999, loss: 0.4060
2022-09-29 12:53:19 - train: epoch 0137, iter [00790, 01251], lr: 0.000999, loss: 0.4112
2022-09-29 12:53:37 - train: epoch 0137, iter [00800, 01251], lr: 0.000999, loss: 0.3995
2022-09-29 12:53:54 - train: epoch 0137, iter [00810, 01251], lr: 0.000999, loss: 0.4035
2022-09-29 12:54:12 - train: epoch 0137, iter [00820, 01251], lr: 0.000999, loss: 0.4157
2022-09-29 12:54:30 - train: epoch 0137, iter [00830, 01251], lr: 0.000999, loss: 0.4214
2022-09-29 12:54:48 - train: epoch 0137, iter [00840, 01251], lr: 0.000999, loss: 0.4212
2022-09-29 12:55:06 - train: epoch 0137, iter [00850, 01251], lr: 0.000999, loss: 0.4176
2022-09-29 12:55:23 - train: epoch 0137, iter [00860, 01251], lr: 0.000999, loss: 0.4092
2022-09-29 12:55:41 - train: epoch 0137, iter [00870, 01251], lr: 0.000999, loss: 0.3982
2022-09-29 12:55:59 - train: epoch 0137, iter [00880, 01251], lr: 0.000999, loss: 0.4162
2022-09-29 12:56:17 - train: epoch 0137, iter [00890, 01251], lr: 0.000999, loss: 0.4194
2022-09-29 12:56:34 - train: epoch 0137, iter [00900, 01251], lr: 0.000999, loss: 0.4233
2022-09-29 12:56:52 - train: epoch 0137, iter [00910, 01251], lr: 0.000999, loss: 0.4148
2022-09-29 12:57:10 - train: epoch 0137, iter [00920, 01251], lr: 0.000999, loss: 0.4149
2022-09-29 12:57:28 - train: epoch 0137, iter [00930, 01251], lr: 0.000999, loss: 0.4114
2022-09-29 12:57:45 - train: epoch 0137, iter [00940, 01251], lr: 0.000999, loss: 0.4135
2022-09-29 12:58:03 - train: epoch 0137, iter [00950, 01251], lr: 0.000999, loss: 0.3961
2022-09-29 12:58:21 - train: epoch 0137, iter [00960, 01251], lr: 0.000998, loss: 0.4191
2022-09-29 12:58:38 - train: epoch 0137, iter [00970, 01251], lr: 0.000998, loss: 0.4212
2022-09-29 12:58:56 - train: epoch 0137, iter [00980, 01251], lr: 0.000998, loss: 0.4239
2022-09-29 12:59:14 - train: epoch 0137, iter [00990, 01251], lr: 0.000998, loss: 0.3999
2022-09-29 12:59:32 - train: epoch 0137, iter [01000, 01251], lr: 0.000998, loss: 0.3985
2022-09-29 12:59:49 - train: epoch 0137, iter [01010, 01251], lr: 0.000998, loss: 0.4162
2022-09-29 13:00:07 - train: epoch 0137, iter [01020, 01251], lr: 0.000998, loss: 0.3955
2022-09-29 13:00:24 - train: epoch 0137, iter [01030, 01251], lr: 0.000998, loss: 0.4253
2022-09-29 13:00:42 - train: epoch 0137, iter [01040, 01251], lr: 0.000998, loss: 0.3985
2022-09-29 13:01:00 - train: epoch 0137, iter [01050, 01251], lr: 0.000998, loss: 0.4145
2022-09-29 13:01:18 - train: epoch 0137, iter [01060, 01251], lr: 0.000998, loss: 0.4197
2022-09-29 13:01:36 - train: epoch 0137, iter [01070, 01251], lr: 0.000998, loss: 0.3978
2022-09-29 13:01:53 - train: epoch 0137, iter [01080, 01251], lr: 0.000998, loss: 0.4298
2022-09-29 13:02:11 - train: epoch 0137, iter [01090, 01251], lr: 0.000998, loss: 0.4336
2022-09-29 13:02:29 - train: epoch 0137, iter [01100, 01251], lr: 0.000998, loss: 0.4181
2022-09-29 13:02:47 - train: epoch 0137, iter [01110, 01251], lr: 0.000998, loss: 0.4086
2022-09-29 13:03:05 - train: epoch 0137, iter [01120, 01251], lr: 0.000998, loss: 0.4119
2022-09-29 13:03:22 - train: epoch 0137, iter [01130, 01251], lr: 0.000998, loss: 0.4131
2022-09-29 13:03:40 - train: epoch 0137, iter [01140, 01251], lr: 0.000998, loss: 0.4335
2022-09-29 13:03:58 - train: epoch 0137, iter [01150, 01251], lr: 0.000998, loss: 0.4260
2022-09-29 13:04:15 - train: epoch 0137, iter [01160, 01251], lr: 0.000998, loss: 0.4217
2022-09-29 13:04:33 - train: epoch 0137, iter [01170, 01251], lr: 0.000998, loss: 0.4101
2022-09-29 13:04:51 - train: epoch 0137, iter [01180, 01251], lr: 0.000998, loss: 0.4113
2022-09-29 13:05:09 - train: epoch 0137, iter [01190, 01251], lr: 0.000998, loss: 0.4280
2022-09-29 13:05:27 - train: epoch 0137, iter [01200, 01251], lr: 0.000998, loss: 0.4102
2022-09-29 13:05:44 - train: epoch 0137, iter [01210, 01251], lr: 0.000998, loss: 0.4338
2022-09-29 13:06:02 - train: epoch 0137, iter [01220, 01251], lr: 0.000998, loss: 0.3993
2022-09-29 13:06:20 - train: epoch 0137, iter [01230, 01251], lr: 0.000998, loss: 0.4034
2022-09-29 13:06:37 - train: epoch 0137, iter [01240, 01251], lr: 0.000998, loss: 0.4264
2022-09-29 13:06:55 - train: epoch 0137, iter [01250, 01251], lr: 0.000998, loss: 0.3986
2022-09-29 13:06:58 - train: epoch 137, train_loss: 0.4112
2022-09-29 13:07:00 - until epoch: 137, best_loss: 0.4112
2022-09-29 13:07:00 - epoch 138 lr: 0.000998
2022-09-29 13:07:33 - train: epoch 0138, iter [00010, 01251], lr: 0.000998, loss: 0.4224
2022-09-29 13:07:51 - train: epoch 0138, iter [00020, 01251], lr: 0.000998, loss: 0.4232
2022-09-29 13:08:09 - train: epoch 0138, iter [00030, 01251], lr: 0.000997, loss: 0.4122
2022-09-29 13:08:27 - train: epoch 0138, iter [00040, 01251], lr: 0.000997, loss: 0.4115
2022-09-29 13:08:44 - train: epoch 0138, iter [00050, 01251], lr: 0.000997, loss: 0.4241
2022-09-29 13:09:02 - train: epoch 0138, iter [00060, 01251], lr: 0.000997, loss: 0.4231
2022-09-29 13:09:20 - train: epoch 0138, iter [00070, 01251], lr: 0.000997, loss: 0.4346
2022-09-29 13:09:38 - train: epoch 0138, iter [00080, 01251], lr: 0.000997, loss: 0.4208
2022-09-29 13:09:55 - train: epoch 0138, iter [00090, 01251], lr: 0.000997, loss: 0.4217
2022-09-29 13:10:13 - train: epoch 0138, iter [00100, 01251], lr: 0.000997, loss: 0.4233
2022-09-29 13:10:31 - train: epoch 0138, iter [00110, 01251], lr: 0.000997, loss: 0.4126
2022-09-29 13:10:48 - train: epoch 0138, iter [00120, 01251], lr: 0.000997, loss: 0.4160
2022-09-29 13:11:06 - train: epoch 0138, iter [00130, 01251], lr: 0.000997, loss: 0.4198
2022-09-29 13:11:24 - train: epoch 0138, iter [00140, 01251], lr: 0.000997, loss: 0.4249
2022-09-29 13:11:41 - train: epoch 0138, iter [00150, 01251], lr: 0.000997, loss: 0.4199
2022-09-29 13:11:59 - train: epoch 0138, iter [00160, 01251], lr: 0.000997, loss: 0.4032
2022-09-29 13:12:17 - train: epoch 0138, iter [00170, 01251], lr: 0.000997, loss: 0.4175
2022-09-29 13:12:35 - train: epoch 0138, iter [00180, 01251], lr: 0.000997, loss: 0.4190
2022-09-29 13:12:52 - train: epoch 0138, iter [00190, 01251], lr: 0.000997, loss: 0.4205
2022-09-29 13:13:10 - train: epoch 0138, iter [00200, 01251], lr: 0.000997, loss: 0.4071
2022-09-29 13:13:28 - train: epoch 0138, iter [00210, 01251], lr: 0.000997, loss: 0.4148
2022-09-29 13:13:45 - train: epoch 0138, iter [00220, 01251], lr: 0.000997, loss: 0.3877
2022-09-29 13:14:03 - train: epoch 0138, iter [00230, 01251], lr: 0.000997, loss: 0.3986
2022-09-29 13:14:21 - train: epoch 0138, iter [00240, 01251], lr: 0.000997, loss: 0.4131
2022-09-29 13:14:38 - train: epoch 0138, iter [00250, 01251], lr: 0.000997, loss: 0.4267
2022-09-29 13:14:56 - train: epoch 0138, iter [00260, 01251], lr: 0.000997, loss: 0.4077
2022-09-29 13:15:14 - train: epoch 0138, iter [00270, 01251], lr: 0.000997, loss: 0.4074
2022-09-29 13:15:32 - train: epoch 0138, iter [00280, 01251], lr: 0.000997, loss: 0.4119
2022-09-29 13:15:49 - train: epoch 0138, iter [00290, 01251], lr: 0.000997, loss: 0.3970
2022-09-29 13:16:07 - train: epoch 0138, iter [00300, 01251], lr: 0.000997, loss: 0.4178
2022-09-29 13:16:24 - train: epoch 0138, iter [00310, 01251], lr: 0.000997, loss: 0.4071
2022-09-29 13:16:42 - train: epoch 0138, iter [00320, 01251], lr: 0.000997, loss: 0.4440
2022-09-29 13:17:00 - train: epoch 0138, iter [00330, 01251], lr: 0.000997, loss: 0.4166
2022-09-29 13:17:17 - train: epoch 0138, iter [00340, 01251], lr: 0.000997, loss: 0.4316
2022-09-29 13:17:35 - train: epoch 0138, iter [00350, 01251], lr: 0.000996, loss: 0.4309
2022-09-29 13:17:52 - train: epoch 0138, iter [00360, 01251], lr: 0.000996, loss: 0.4216
2022-09-29 13:18:10 - train: epoch 0138, iter [00370, 01251], lr: 0.000996, loss: 0.3993
2022-09-29 13:18:28 - train: epoch 0138, iter [00380, 01251], lr: 0.000996, loss: 0.4069
2022-09-29 13:18:46 - train: epoch 0138, iter [00390, 01251], lr: 0.000996, loss: 0.4179
2022-09-29 13:19:03 - train: epoch 0138, iter [00400, 01251], lr: 0.000996, loss: 0.3829
2022-09-29 13:19:21 - train: epoch 0138, iter [00410, 01251], lr: 0.000996, loss: 0.4055
2022-09-29 13:19:39 - train: epoch 0138, iter [00420, 01251], lr: 0.000996, loss: 0.4069
2022-09-29 13:19:56 - train: epoch 0138, iter [00430, 01251], lr: 0.000996, loss: 0.4087
2022-09-29 13:20:14 - train: epoch 0138, iter [00440, 01251], lr: 0.000996, loss: 0.4214
2022-09-29 13:20:31 - train: epoch 0138, iter [00450, 01251], lr: 0.000996, loss: 0.4065
2022-09-29 13:20:49 - train: epoch 0138, iter [00460, 01251], lr: 0.000996, loss: 0.4293
2022-09-29 13:21:07 - train: epoch 0138, iter [00470, 01251], lr: 0.000996, loss: 0.4128
2022-09-29 13:21:25 - train: epoch 0138, iter [00480, 01251], lr: 0.000996, loss: 0.4110
2022-09-29 13:21:42 - train: epoch 0138, iter [00490, 01251], lr: 0.000996, loss: 0.4030
2022-09-29 13:22:00 - train: epoch 0138, iter [00500, 01251], lr: 0.000996, loss: 0.3979
2022-09-29 13:22:18 - train: epoch 0138, iter [00510, 01251], lr: 0.000996, loss: 0.4057
2022-09-29 13:22:35 - train: epoch 0138, iter [00520, 01251], lr: 0.000996, loss: 0.4036
2022-09-29 13:22:53 - train: epoch 0138, iter [00530, 01251], lr: 0.000996, loss: 0.4112
2022-09-29 13:23:11 - train: epoch 0138, iter [00540, 01251], lr: 0.000996, loss: 0.4116
2022-09-29 13:23:29 - train: epoch 0138, iter [00550, 01251], lr: 0.000996, loss: 0.4163
2022-09-29 13:23:46 - train: epoch 0138, iter [00560, 01251], lr: 0.000996, loss: 0.3968
2022-09-29 13:24:04 - train: epoch 0138, iter [00570, 01251], lr: 0.000996, loss: 0.4046
2022-09-29 13:24:22 - train: epoch 0138, iter [00580, 01251], lr: 0.000996, loss: 0.4182
2022-09-29 13:24:39 - train: epoch 0138, iter [00590, 01251], lr: 0.000996, loss: 0.4208
2022-09-29 13:24:57 - train: epoch 0138, iter [00600, 01251], lr: 0.000996, loss: 0.4109
2022-09-29 13:25:15 - train: epoch 0138, iter [00610, 01251], lr: 0.000996, loss: 0.4123
2022-09-29 13:25:32 - train: epoch 0138, iter [00620, 01251], lr: 0.000996, loss: 0.3979
2022-09-29 13:25:50 - train: epoch 0138, iter [00630, 01251], lr: 0.000996, loss: 0.4242
2022-09-29 13:26:08 - train: epoch 0138, iter [00640, 01251], lr: 0.000996, loss: 0.4086
2022-09-29 13:26:25 - train: epoch 0138, iter [00650, 01251], lr: 0.000996, loss: 0.3917
2022-09-29 13:26:43 - train: epoch 0138, iter [00660, 01251], lr: 0.000995, loss: 0.4004
2022-09-29 13:27:01 - train: epoch 0138, iter [00670, 01251], lr: 0.000995, loss: 0.4025
2022-09-29 13:27:19 - train: epoch 0138, iter [00680, 01251], lr: 0.000995, loss: 0.4181
2022-09-29 13:27:36 - train: epoch 0138, iter [00690, 01251], lr: 0.000995, loss: 0.4160
2022-09-29 13:27:54 - train: epoch 0138, iter [00700, 01251], lr: 0.000995, loss: 0.4186
2022-09-29 13:28:12 - train: epoch 0138, iter [00710, 01251], lr: 0.000995, loss: 0.4049
2022-09-29 13:28:30 - train: epoch 0138, iter [00720, 01251], lr: 0.000995, loss: 0.4048
2022-09-29 13:28:47 - train: epoch 0138, iter [00730, 01251], lr: 0.000995, loss: 0.3989
2022-09-29 13:29:05 - train: epoch 0138, iter [00740, 01251], lr: 0.000995, loss: 0.4012
2022-09-29 13:29:23 - train: epoch 0138, iter [00750, 01251], lr: 0.000995, loss: 0.4172
2022-09-29 13:29:40 - train: epoch 0138, iter [00760, 01251], lr: 0.000995, loss: 0.4136
2022-09-29 13:29:58 - train: epoch 0138, iter [00770, 01251], lr: 0.000995, loss: 0.4187
2022-09-29 13:30:16 - train: epoch 0138, iter [00780, 01251], lr: 0.000995, loss: 0.4088
2022-09-29 13:30:34 - train: epoch 0138, iter [00790, 01251], lr: 0.000995, loss: 0.4038
2022-09-29 13:30:51 - train: epoch 0138, iter [00800, 01251], lr: 0.000995, loss: 0.3994
2022-09-29 13:31:09 - train: epoch 0138, iter [00810, 01251], lr: 0.000995, loss: 0.4108
2022-09-29 13:31:27 - train: epoch 0138, iter [00820, 01251], lr: 0.000995, loss: 0.3988
2022-09-29 13:31:45 - train: epoch 0138, iter [00830, 01251], lr: 0.000995, loss: 0.3971
2022-09-29 13:32:02 - train: epoch 0138, iter [00840, 01251], lr: 0.000995, loss: 0.4113
2022-09-29 13:32:20 - train: epoch 0138, iter [00850, 01251], lr: 0.000995, loss: 0.4020
2022-09-29 13:32:37 - train: epoch 0138, iter [00860, 01251], lr: 0.000995, loss: 0.4043
2022-09-29 13:32:55 - train: epoch 0138, iter [00870, 01251], lr: 0.000995, loss: 0.4058
2022-09-29 13:33:13 - train: epoch 0138, iter [00880, 01251], lr: 0.000995, loss: 0.3979
2022-09-29 13:33:31 - train: epoch 0138, iter [00890, 01251], lr: 0.000995, loss: 0.4139
2022-09-29 13:33:48 - train: epoch 0138, iter [00900, 01251], lr: 0.000995, loss: 0.4086
2022-09-29 13:34:06 - train: epoch 0138, iter [00910, 01251], lr: 0.000995, loss: 0.4142
2022-09-29 13:34:24 - train: epoch 0138, iter [00920, 01251], lr: 0.000995, loss: 0.4074
2022-09-29 13:34:41 - train: epoch 0138, iter [00930, 01251], lr: 0.000995, loss: 0.4107
2022-09-29 13:34:59 - train: epoch 0138, iter [00940, 01251], lr: 0.000995, loss: 0.4092
2022-09-29 13:35:17 - train: epoch 0138, iter [00950, 01251], lr: 0.000995, loss: 0.4229
2022-09-29 13:35:35 - train: epoch 0138, iter [00960, 01251], lr: 0.000995, loss: 0.4261
2022-09-29 13:35:52 - train: epoch 0138, iter [00970, 01251], lr: 0.000995, loss: 0.4178
2022-09-29 13:36:10 - train: epoch 0138, iter [00980, 01251], lr: 0.000994, loss: 0.4191
2022-09-29 13:36:28 - train: epoch 0138, iter [00990, 01251], lr: 0.000994, loss: 0.4053
2022-09-29 13:36:45 - train: epoch 0138, iter [01000, 01251], lr: 0.000994, loss: 0.4125
2022-09-29 13:37:03 - train: epoch 0138, iter [01010, 01251], lr: 0.000994, loss: 0.4161
2022-09-29 13:37:21 - train: epoch 0138, iter [01020, 01251], lr: 0.000994, loss: 0.3959
2022-09-29 13:37:38 - train: epoch 0138, iter [01030, 01251], lr: 0.000994, loss: 0.4102
2022-09-29 13:37:56 - train: epoch 0138, iter [01040, 01251], lr: 0.000994, loss: 0.4199
2022-09-29 13:38:14 - train: epoch 0138, iter [01050, 01251], lr: 0.000994, loss: 0.4129
2022-09-29 13:38:32 - train: epoch 0138, iter [01060, 01251], lr: 0.000994, loss: 0.4196
2022-09-29 13:38:49 - train: epoch 0138, iter [01070, 01251], lr: 0.000994, loss: 0.4042
2022-09-29 13:39:07 - train: epoch 0138, iter [01080, 01251], lr: 0.000994, loss: 0.4136
2022-09-29 13:39:25 - train: epoch 0138, iter [01090, 01251], lr: 0.000994, loss: 0.4085
2022-09-29 13:39:42 - train: epoch 0138, iter [01100, 01251], lr: 0.000994, loss: 0.4097
2022-09-29 13:40:00 - train: epoch 0138, iter [01110, 01251], lr: 0.000994, loss: 0.4159
2022-09-29 13:40:18 - train: epoch 0138, iter [01120, 01251], lr: 0.000994, loss: 0.4173
2022-09-29 13:40:35 - train: epoch 0138, iter [01130, 01251], lr: 0.000994, loss: 0.4102
2022-09-29 13:40:53 - train: epoch 0138, iter [01140, 01251], lr: 0.000994, loss: 0.4200
2022-09-29 13:41:11 - train: epoch 0138, iter [01150, 01251], lr: 0.000994, loss: 0.4207
2022-09-29 13:41:29 - train: epoch 0138, iter [01160, 01251], lr: 0.000994, loss: 0.4362
2022-09-29 13:41:46 - train: epoch 0138, iter [01170, 01251], lr: 0.000994, loss: 0.4187
2022-09-29 13:42:04 - train: epoch 0138, iter [01180, 01251], lr: 0.000994, loss: 0.4379
2022-09-29 13:42:22 - train: epoch 0138, iter [01190, 01251], lr: 0.000994, loss: 0.4143
2022-09-29 13:42:40 - train: epoch 0138, iter [01200, 01251], lr: 0.000994, loss: 0.4247
2022-09-29 13:42:57 - train: epoch 0138, iter [01210, 01251], lr: 0.000994, loss: 0.4058
2022-09-29 13:43:15 - train: epoch 0138, iter [01220, 01251], lr: 0.000994, loss: 0.4136
2022-09-29 13:43:33 - train: epoch 0138, iter [01230, 01251], lr: 0.000994, loss: 0.4179
2022-09-29 13:43:51 - train: epoch 0138, iter [01240, 01251], lr: 0.000994, loss: 0.4232
2022-09-29 13:44:08 - train: epoch 0138, iter [01250, 01251], lr: 0.000994, loss: 0.3991
2022-09-29 13:44:12 - train: epoch 138, train_loss: 0.4111
2022-09-29 13:44:14 - until epoch: 138, best_loss: 0.4111
2022-09-29 13:44:14 - epoch 139 lr: 0.000994
2022-09-29 13:44:46 - train: epoch 0139, iter [00010, 01251], lr: 0.000994, loss: 0.4120
2022-09-29 13:45:04 - train: epoch 0139, iter [00020, 01251], lr: 0.000994, loss: 0.4070
2022-09-29 13:45:22 - train: epoch 0139, iter [00030, 01251], lr: 0.000994, loss: 0.4281
2022-09-29 13:45:40 - train: epoch 0139, iter [00040, 01251], lr: 0.000994, loss: 0.4078
2022-09-29 13:45:57 - train: epoch 0139, iter [00050, 01251], lr: 0.000993, loss: 0.4160
2022-09-29 13:46:15 - train: epoch 0139, iter [00060, 01251], lr: 0.000993, loss: 0.4011
2022-09-29 13:46:32 - train: epoch 0139, iter [00070, 01251], lr: 0.000993, loss: 0.4155
2022-09-29 13:46:50 - train: epoch 0139, iter [00080, 01251], lr: 0.000993, loss: 0.4065
2022-09-29 13:47:08 - train: epoch 0139, iter [00090, 01251], lr: 0.000993, loss: 0.4018
2022-09-29 13:47:25 - train: epoch 0139, iter [00100, 01251], lr: 0.000993, loss: 0.3933
2022-09-29 13:47:43 - train: epoch 0139, iter [00110, 01251], lr: 0.000993, loss: 0.4116
2022-09-29 13:48:01 - train: epoch 0139, iter [00120, 01251], lr: 0.000993, loss: 0.3995
2022-09-29 13:48:19 - train: epoch 0139, iter [00130, 01251], lr: 0.000993, loss: 0.4164
2022-09-29 13:48:37 - train: epoch 0139, iter [00140, 01251], lr: 0.000993, loss: 0.4035
2022-09-29 13:48:54 - train: epoch 0139, iter [00150, 01251], lr: 0.000993, loss: 0.4321
2022-09-29 13:49:12 - train: epoch 0139, iter [00160, 01251], lr: 0.000993, loss: 0.4293
2022-09-29 13:49:30 - train: epoch 0139, iter [00170, 01251], lr: 0.000993, loss: 0.4275
2022-09-29 13:49:47 - train: epoch 0139, iter [00180, 01251], lr: 0.000993, loss: 0.3980
2022-09-29 13:50:05 - train: epoch 0139, iter [00190, 01251], lr: 0.000993, loss: 0.4102
2022-09-29 13:50:23 - train: epoch 0139, iter [00200, 01251], lr: 0.000993, loss: 0.3878
2022-09-29 13:50:41 - train: epoch 0139, iter [00210, 01251], lr: 0.000993, loss: 0.4174
2022-09-29 13:50:58 - train: epoch 0139, iter [00220, 01251], lr: 0.000993, loss: 0.3963
2022-09-29 13:51:16 - train: epoch 0139, iter [00230, 01251], lr: 0.000993, loss: 0.4226
2022-09-29 13:51:34 - train: epoch 0139, iter [00240, 01251], lr: 0.000993, loss: 0.4058
2022-09-29 13:51:51 - train: epoch 0139, iter [00250, 01251], lr: 0.000993, loss: 0.4240
2022-09-29 13:52:09 - train: epoch 0139, iter [00260, 01251], lr: 0.000993, loss: 0.4032
2022-09-29 13:52:26 - train: epoch 0139, iter [00270, 01251], lr: 0.000993, loss: 0.3955
2022-09-29 13:52:44 - train: epoch 0139, iter [00280, 01251], lr: 0.000993, loss: 0.4043
2022-09-29 13:53:02 - train: epoch 0139, iter [00290, 01251], lr: 0.000993, loss: 0.4370
2022-09-29 13:53:19 - train: epoch 0139, iter [00300, 01251], lr: 0.000993, loss: 0.3917
2022-09-29 13:53:37 - train: epoch 0139, iter [00310, 01251], lr: 0.000993, loss: 0.4147
2022-09-29 13:53:54 - train: epoch 0139, iter [00320, 01251], lr: 0.000993, loss: 0.4145
2022-09-29 13:54:12 - train: epoch 0139, iter [00330, 01251], lr: 0.000993, loss: 0.4004
2022-09-29 13:54:30 - train: epoch 0139, iter [00340, 01251], lr: 0.000993, loss: 0.4252
2022-09-29 13:54:47 - train: epoch 0139, iter [00350, 01251], lr: 0.000993, loss: 0.4061
2022-09-29 13:55:05 - train: epoch 0139, iter [00360, 01251], lr: 0.000992, loss: 0.4140
2022-09-29 13:55:23 - train: epoch 0139, iter [00370, 01251], lr: 0.000992, loss: 0.4198
2022-09-29 13:55:40 - train: epoch 0139, iter [00380, 01251], lr: 0.000992, loss: 0.4078
2022-09-29 13:55:58 - train: epoch 0139, iter [00390, 01251], lr: 0.000992, loss: 0.4135
2022-09-29 13:56:16 - train: epoch 0139, iter [00400, 01251], lr: 0.000992, loss: 0.3953
2022-09-29 13:56:34 - train: epoch 0139, iter [00410, 01251], lr: 0.000992, loss: 0.3836
2022-09-29 13:56:51 - train: epoch 0139, iter [00420, 01251], lr: 0.000992, loss: 0.4171
2022-09-29 13:57:09 - train: epoch 0139, iter [00430, 01251], lr: 0.000992, loss: 0.4296
2022-09-29 13:57:27 - train: epoch 0139, iter [00440, 01251], lr: 0.000992, loss: 0.4049
2022-09-29 13:57:44 - train: epoch 0139, iter [00450, 01251], lr: 0.000992, loss: 0.4256
2022-09-29 13:58:02 - train: epoch 0139, iter [00460, 01251], lr: 0.000992, loss: 0.4292
2022-09-29 13:58:20 - train: epoch 0139, iter [00470, 01251], lr: 0.000992, loss: 0.4262
2022-09-29 13:58:37 - train: epoch 0139, iter [00480, 01251], lr: 0.000992, loss: 0.3997
2022-09-29 13:58:55 - train: epoch 0139, iter [00490, 01251], lr: 0.000992, loss: 0.4158
2022-09-29 13:59:13 - train: epoch 0139, iter [00500, 01251], lr: 0.000992, loss: 0.4127
2022-09-29 13:59:30 - train: epoch 0139, iter [00510, 01251], lr: 0.000992, loss: 0.4140
2022-09-29 13:59:48 - train: epoch 0139, iter [00520, 01251], lr: 0.000992, loss: 0.3916
2022-09-29 14:00:06 - train: epoch 0139, iter [00530, 01251], lr: 0.000992, loss: 0.3971
2022-09-29 14:00:23 - train: epoch 0139, iter [00540, 01251], lr: 0.000992, loss: 0.4148
2022-09-29 14:00:41 - train: epoch 0139, iter [00550, 01251], lr: 0.000992, loss: 0.3973
2022-09-29 14:00:59 - train: epoch 0139, iter [00560, 01251], lr: 0.000992, loss: 0.4073
2022-09-29 14:01:16 - train: epoch 0139, iter [00570, 01251], lr: 0.000992, loss: 0.4188
2022-09-29 14:01:34 - train: epoch 0139, iter [00580, 01251], lr: 0.000992, loss: 0.4009
2022-09-29 14:01:51 - train: epoch 0139, iter [00590, 01251], lr: 0.000992, loss: 0.4195
2022-09-29 14:02:09 - train: epoch 0139, iter [00600, 01251], lr: 0.000992, loss: 0.3870
2022-09-29 14:02:27 - train: epoch 0139, iter [00610, 01251], lr: 0.000992, loss: 0.4118
2022-09-29 14:02:45 - train: epoch 0139, iter [00620, 01251], lr: 0.000992, loss: 0.4081
2022-09-29 14:03:02 - train: epoch 0139, iter [00630, 01251], lr: 0.000992, loss: 0.4104
2022-09-29 14:03:20 - train: epoch 0139, iter [00640, 01251], lr: 0.000992, loss: 0.3925
2022-09-29 14:03:38 - train: epoch 0139, iter [00650, 01251], lr: 0.000992, loss: 0.4108
2022-09-29 14:03:55 - train: epoch 0139, iter [00660, 01251], lr: 0.000992, loss: 0.4240
2022-09-29 14:04:13 - train: epoch 0139, iter [00670, 01251], lr: 0.000992, loss: 0.3861
2022-09-29 14:04:31 - train: epoch 0139, iter [00680, 01251], lr: 0.000991, loss: 0.3985
2022-09-29 14:04:49 - train: epoch 0139, iter [00690, 01251], lr: 0.000991, loss: 0.3979
2022-09-29 14:05:06 - train: epoch 0139, iter [00700, 01251], lr: 0.000991, loss: 0.4311
2022-09-29 14:05:24 - train: epoch 0139, iter [00710, 01251], lr: 0.000991, loss: 0.4202
2022-09-29 14:05:42 - train: epoch 0139, iter [00720, 01251], lr: 0.000991, loss: 0.4079
2022-09-29 14:05:59 - train: epoch 0139, iter [00730, 01251], lr: 0.000991, loss: 0.4086
2022-09-29 14:06:17 - train: epoch 0139, iter [00740, 01251], lr: 0.000991, loss: 0.4019
2022-09-29 14:06:35 - train: epoch 0139, iter [00750, 01251], lr: 0.000991, loss: 0.4210
2022-09-29 14:06:52 - train: epoch 0139, iter [00760, 01251], lr: 0.000991, loss: 0.4128
2022-09-29 14:07:10 - train: epoch 0139, iter [00770, 01251], lr: 0.000991, loss: 0.4067
2022-09-29 14:07:28 - train: epoch 0139, iter [00780, 01251], lr: 0.000991, loss: 0.3838
2022-09-29 14:07:46 - train: epoch 0139, iter [00790, 01251], lr: 0.000991, loss: 0.4103
2022-09-29 14:08:03 - train: epoch 0139, iter [00800, 01251], lr: 0.000991, loss: 0.4157
2022-09-29 14:08:21 - train: epoch 0139, iter [00810, 01251], lr: 0.000991, loss: 0.4054
2022-09-29 14:08:39 - train: epoch 0139, iter [00820, 01251], lr: 0.000991, loss: 0.4065
2022-09-29 14:08:56 - train: epoch 0139, iter [00830, 01251], lr: 0.000991, loss: 0.3944
2022-09-29 14:09:14 - train: epoch 0139, iter [00840, 01251], lr: 0.000991, loss: 0.4229
2022-09-29 14:09:32 - train: epoch 0139, iter [00850, 01251], lr: 0.000991, loss: 0.4043
2022-09-29 14:09:50 - train: epoch 0139, iter [00860, 01251], lr: 0.000991, loss: 0.4127
2022-09-29 14:10:07 - train: epoch 0139, iter [00870, 01251], lr: 0.000991, loss: 0.4275
2022-09-29 14:10:25 - train: epoch 0139, iter [00880, 01251], lr: 0.000991, loss: 0.3969
2022-09-29 14:10:43 - train: epoch 0139, iter [00890, 01251], lr: 0.000991, loss: 0.4087
2022-09-29 14:11:00 - train: epoch 0139, iter [00900, 01251], lr: 0.000991, loss: 0.4023
2022-09-29 14:11:18 - train: epoch 0139, iter [00910, 01251], lr: 0.000991, loss: 0.4194
2022-09-29 14:11:36 - train: epoch 0139, iter [00920, 01251], lr: 0.000991, loss: 0.4039
2022-09-29 14:11:53 - train: epoch 0139, iter [00930, 01251], lr: 0.000991, loss: 0.3890
2022-09-29 14:12:11 - train: epoch 0139, iter [00940, 01251], lr: 0.000991, loss: 0.4266
2022-09-29 14:12:29 - train: epoch 0139, iter [00950, 01251], lr: 0.000991, loss: 0.3964
2022-09-29 14:12:46 - train: epoch 0139, iter [00960, 01251], lr: 0.000991, loss: 0.4000
2022-09-29 14:13:04 - train: epoch 0139, iter [00970, 01251], lr: 0.000991, loss: 0.4085
2022-09-29 14:13:22 - train: epoch 0139, iter [00980, 01251], lr: 0.000991, loss: 0.4285
2022-09-29 14:13:40 - train: epoch 0139, iter [00990, 01251], lr: 0.000990, loss: 0.4121
2022-09-29 14:13:57 - train: epoch 0139, iter [01000, 01251], lr: 0.000990, loss: 0.4164
2022-09-29 14:14:15 - train: epoch 0139, iter [01010, 01251], lr: 0.000990, loss: 0.3996
2022-09-29 14:14:33 - train: epoch 0139, iter [01020, 01251], lr: 0.000990, loss: 0.4135
2022-09-29 14:14:50 - train: epoch 0139, iter [01030, 01251], lr: 0.000990, loss: 0.4182
2022-09-29 14:15:08 - train: epoch 0139, iter [01040, 01251], lr: 0.000990, loss: 0.4048
2022-09-29 14:15:26 - train: epoch 0139, iter [01050, 01251], lr: 0.000990, loss: 0.3873
2022-09-29 14:15:44 - train: epoch 0139, iter [01060, 01251], lr: 0.000990, loss: 0.3980
2022-09-29 14:16:01 - train: epoch 0139, iter [01070, 01251], lr: 0.000990, loss: 0.4062
2022-09-29 14:16:19 - train: epoch 0139, iter [01080, 01251], lr: 0.000990, loss: 0.4079
2022-09-29 14:16:37 - train: epoch 0139, iter [01090, 01251], lr: 0.000990, loss: 0.4100
2022-09-29 14:16:54 - train: epoch 0139, iter [01100, 01251], lr: 0.000990, loss: 0.3996
2022-09-29 14:17:12 - train: epoch 0139, iter [01110, 01251], lr: 0.000990, loss: 0.3957
2022-09-29 14:17:30 - train: epoch 0139, iter [01120, 01251], lr: 0.000990, loss: 0.4219
2022-09-29 14:17:47 - train: epoch 0139, iter [01130, 01251], lr: 0.000990, loss: 0.4013
2022-09-29 14:18:05 - train: epoch 0139, iter [01140, 01251], lr: 0.000990, loss: 0.4089
2022-09-29 14:18:23 - train: epoch 0139, iter [01150, 01251], lr: 0.000990, loss: 0.4323
2022-09-29 14:18:40 - train: epoch 0139, iter [01160, 01251], lr: 0.000990, loss: 0.4282
2022-09-29 14:18:58 - train: epoch 0139, iter [01170, 01251], lr: 0.000990, loss: 0.4117
2022-09-29 14:19:16 - train: epoch 0139, iter [01180, 01251], lr: 0.000990, loss: 0.4127
2022-09-29 14:19:33 - train: epoch 0139, iter [01190, 01251], lr: 0.000990, loss: 0.4039
2022-09-29 14:19:51 - train: epoch 0139, iter [01200, 01251], lr: 0.000990, loss: 0.4121
2022-09-29 14:20:09 - train: epoch 0139, iter [01210, 01251], lr: 0.000990, loss: 0.3912
2022-09-29 14:20:27 - train: epoch 0139, iter [01220, 01251], lr: 0.000990, loss: 0.4002
2022-09-29 14:20:44 - train: epoch 0139, iter [01230, 01251], lr: 0.000990, loss: 0.3988
2022-09-29 14:21:02 - train: epoch 0139, iter [01240, 01251], lr: 0.000990, loss: 0.4190
2022-09-29 14:21:19 - train: epoch 0139, iter [01250, 01251], lr: 0.000990, loss: 0.4208
2022-09-29 14:21:23 - train: epoch 139, train_loss: 0.4111
2022-09-29 14:21:24 - until epoch: 139, best_loss: 0.4111
2022-09-29 14:21:24 - epoch 140 lr: 0.000990
2022-09-29 14:21:57 - train: epoch 0140, iter [00010, 01251], lr: 0.000990, loss: 0.3980
2022-09-29 14:22:15 - train: epoch 0140, iter [00020, 01251], lr: 0.000990, loss: 0.4208
2022-09-29 14:22:32 - train: epoch 0140, iter [00030, 01251], lr: 0.000990, loss: 0.4037
2022-09-29 14:22:50 - train: epoch 0140, iter [00040, 01251], lr: 0.000990, loss: 0.4127
2022-09-29 14:23:08 - train: epoch 0140, iter [00050, 01251], lr: 0.000990, loss: 0.4093
2022-09-29 14:23:25 - train: epoch 0140, iter [00060, 01251], lr: 0.000989, loss: 0.4271
2022-09-29 14:23:43 - train: epoch 0140, iter [00070, 01251], lr: 0.000989, loss: 0.4313
2022-09-29 14:24:01 - train: epoch 0140, iter [00080, 01251], lr: 0.000989, loss: 0.4186
2022-09-29 14:24:19 - train: epoch 0140, iter [00090, 01251], lr: 0.000989, loss: 0.4147
2022-09-29 14:24:37 - train: epoch 0140, iter [00100, 01251], lr: 0.000989, loss: 0.4309
2022-09-29 14:24:54 - train: epoch 0140, iter [00110, 01251], lr: 0.000989, loss: 0.4018
2022-09-29 14:25:12 - train: epoch 0140, iter [00120, 01251], lr: 0.000989, loss: 0.3944
2022-09-29 14:25:30 - train: epoch 0140, iter [00130, 01251], lr: 0.000989, loss: 0.3987
2022-09-29 14:25:47 - train: epoch 0140, iter [00140, 01251], lr: 0.000989, loss: 0.4310
2022-09-29 14:26:05 - train: epoch 0140, iter [00150, 01251], lr: 0.000989, loss: 0.4270
2022-09-29 14:26:22 - train: epoch 0140, iter [00160, 01251], lr: 0.000989, loss: 0.4002
2022-09-29 14:26:40 - train: epoch 0140, iter [00170, 01251], lr: 0.000989, loss: 0.4132
2022-09-29 14:26:58 - train: epoch 0140, iter [00180, 01251], lr: 0.000989, loss: 0.4278
2022-09-29 14:27:15 - train: epoch 0140, iter [00190, 01251], lr: 0.000989, loss: 0.4036
2022-09-29 14:27:33 - train: epoch 0140, iter [00200, 01251], lr: 0.000989, loss: 0.3960
2022-09-29 14:27:51 - train: epoch 0140, iter [00210, 01251], lr: 0.000989, loss: 0.4155
2022-09-29 14:28:08 - train: epoch 0140, iter [00220, 01251], lr: 0.000989, loss: 0.4245
2022-09-29 14:28:26 - train: epoch 0140, iter [00230, 01251], lr: 0.000989, loss: 0.4063
2022-09-29 14:28:44 - train: epoch 0140, iter [00240, 01251], lr: 0.000989, loss: 0.3905
2022-09-29 14:29:01 - train: epoch 0140, iter [00250, 01251], lr: 0.000989, loss: 0.4039
2022-09-29 14:29:19 - train: epoch 0140, iter [00260, 01251], lr: 0.000989, loss: 0.4294
2022-09-29 14:29:37 - train: epoch 0140, iter [00270, 01251], lr: 0.000989, loss: 0.4263
2022-09-29 14:29:55 - train: epoch 0140, iter [00280, 01251], lr: 0.000989, loss: 0.3946
2022-09-29 14:30:12 - train: epoch 0140, iter [00290, 01251], lr: 0.000989, loss: 0.4066
2022-09-29 14:30:30 - train: epoch 0140, iter [00300, 01251], lr: 0.000989, loss: 0.3915
2022-09-29 14:30:48 - train: epoch 0140, iter [00310, 01251], lr: 0.000989, loss: 0.4241
2022-09-29 14:31:06 - train: epoch 0140, iter [00320, 01251], lr: 0.000989, loss: 0.3980
2022-09-29 14:31:24 - train: epoch 0140, iter [00330, 01251], lr: 0.000989, loss: 0.4291
2022-09-29 14:31:41 - train: epoch 0140, iter [00340, 01251], lr: 0.000989, loss: 0.4110
2022-09-29 14:31:59 - train: epoch 0140, iter [00350, 01251], lr: 0.000989, loss: 0.4092
2022-09-29 14:32:17 - train: epoch 0140, iter [00360, 01251], lr: 0.000989, loss: 0.4009
2022-09-29 14:32:35 - train: epoch 0140, iter [00370, 01251], lr: 0.000988, loss: 0.4060
2022-09-29 14:32:53 - train: epoch 0140, iter [00380, 01251], lr: 0.000988, loss: 0.4223
2022-09-29 14:33:11 - train: epoch 0140, iter [00390, 01251], lr: 0.000988, loss: 0.3989
2022-09-29 14:33:28 - train: epoch 0140, iter [00400, 01251], lr: 0.000988, loss: 0.4184
2022-09-29 14:33:46 - train: epoch 0140, iter [00410, 01251], lr: 0.000988, loss: 0.4231
2022-09-29 14:34:04 - train: epoch 0140, iter [00420, 01251], lr: 0.000988, loss: 0.4053
2022-09-29 14:34:21 - train: epoch 0140, iter [00430, 01251], lr: 0.000988, loss: 0.4177
2022-09-29 14:34:39 - train: epoch 0140, iter [00440, 01251], lr: 0.000988, loss: 0.4194
2022-09-29 14:34:57 - train: epoch 0140, iter [00450, 01251], lr: 0.000988, loss: 0.4104
2022-09-29 14:35:15 - train: epoch 0140, iter [00460, 01251], lr: 0.000988, loss: 0.3856
2022-09-29 14:35:32 - train: epoch 0140, iter [00470, 01251], lr: 0.000988, loss: 0.4059
2022-09-29 14:35:50 - train: epoch 0140, iter [00480, 01251], lr: 0.000988, loss: 0.4092
2022-09-29 14:36:08 - train: epoch 0140, iter [00490, 01251], lr: 0.000988, loss: 0.4007
2022-09-29 14:36:26 - train: epoch 0140, iter [00500, 01251], lr: 0.000988, loss: 0.4120
2022-09-29 14:36:43 - train: epoch 0140, iter [00510, 01251], lr: 0.000988, loss: 0.4345
2022-09-29 14:37:01 - train: epoch 0140, iter [00520, 01251], lr: 0.000988, loss: 0.4213
2022-09-29 14:37:19 - train: epoch 0140, iter [00530, 01251], lr: 0.000988, loss: 0.4279
2022-09-29 14:37:37 - train: epoch 0140, iter [00540, 01251], lr: 0.000988, loss: 0.4161
2022-09-29 14:37:54 - train: epoch 0140, iter [00550, 01251], lr: 0.000988, loss: 0.4216
2022-09-29 14:38:12 - train: epoch 0140, iter [00560, 01251], lr: 0.000988, loss: 0.3954
2022-09-29 14:38:30 - train: epoch 0140, iter [00570, 01251], lr: 0.000988, loss: 0.4135
2022-09-29 14:38:48 - train: epoch 0140, iter [00580, 01251], lr: 0.000988, loss: 0.4093
2022-09-29 14:39:05 - train: epoch 0140, iter [00590, 01251], lr: 0.000988, loss: 0.4008
2022-09-29 14:39:23 - train: epoch 0140, iter [00600, 01251], lr: 0.000988, loss: 0.4121
2022-09-29 14:39:41 - train: epoch 0140, iter [00610, 01251], lr: 0.000988, loss: 0.4024
2022-09-29 14:39:59 - train: epoch 0140, iter [00620, 01251], lr: 0.000988, loss: 0.4048
2022-09-29 14:40:16 - train: epoch 0140, iter [00630, 01251], lr: 0.000988, loss: 0.4347
2022-09-29 14:40:34 - train: epoch 0140, iter [00640, 01251], lr: 0.000988, loss: 0.4164
2022-09-29 14:40:52 - train: epoch 0140, iter [00650, 01251], lr: 0.000988, loss: 0.4051
2022-09-29 14:41:10 - train: epoch 0140, iter [00660, 01251], lr: 0.000988, loss: 0.4238
2022-09-29 14:41:27 - train: epoch 0140, iter [00670, 01251], lr: 0.000988, loss: 0.3968
2022-09-29 14:41:45 - train: epoch 0140, iter [00680, 01251], lr: 0.000988, loss: 0.4130
2022-09-29 14:42:03 - train: epoch 0140, iter [00690, 01251], lr: 0.000987, loss: 0.4014
2022-09-29 14:42:20 - train: epoch 0140, iter [00700, 01251], lr: 0.000987, loss: 0.3962
2022-09-29 14:42:38 - train: epoch 0140, iter [00710, 01251], lr: 0.000987, loss: 0.4123
2022-09-29 14:42:56 - train: epoch 0140, iter [00720, 01251], lr: 0.000987, loss: 0.3935
2022-09-29 14:43:14 - train: epoch 0140, iter [00730, 01251], lr: 0.000987, loss: 0.4150
2022-09-29 14:43:31 - train: epoch 0140, iter [00740, 01251], lr: 0.000987, loss: 0.4114
2022-09-29 14:43:49 - train: epoch 0140, iter [00750, 01251], lr: 0.000987, loss: 0.4019
2022-09-29 14:44:07 - train: epoch 0140, iter [00760, 01251], lr: 0.000987, loss: 0.4035
2022-09-29 14:44:25 - train: epoch 0140, iter [00770, 01251], lr: 0.000987, loss: 0.4159
2022-09-29 14:44:42 - train: epoch 0140, iter [00780, 01251], lr: 0.000987, loss: 0.4207
2022-09-29 14:45:00 - train: epoch 0140, iter [00790, 01251], lr: 0.000987, loss: 0.4086
2022-09-29 14:45:18 - train: epoch 0140, iter [00800, 01251], lr: 0.000987, loss: 0.4294
2022-09-29 14:45:35 - train: epoch 0140, iter [00810, 01251], lr: 0.000987, loss: 0.3885
2022-09-29 14:45:53 - train: epoch 0140, iter [00820, 01251], lr: 0.000987, loss: 0.4013
2022-09-29 14:46:11 - train: epoch 0140, iter [00830, 01251], lr: 0.000987, loss: 0.4116
2022-09-29 14:46:29 - train: epoch 0140, iter [00840, 01251], lr: 0.000987, loss: 0.3961
2022-09-29 14:46:47 - train: epoch 0140, iter [00850, 01251], lr: 0.000987, loss: 0.4258
2022-09-29 14:47:04 - train: epoch 0140, iter [00860, 01251], lr: 0.000987, loss: 0.4140
2022-09-29 14:47:22 - train: epoch 0140, iter [00870, 01251], lr: 0.000987, loss: 0.4070
2022-09-29 14:47:40 - train: epoch 0140, iter [00880, 01251], lr: 0.000987, loss: 0.4221
2022-09-29 14:47:57 - train: epoch 0140, iter [00890, 01251], lr: 0.000987, loss: 0.4184
2022-09-29 14:48:15 - train: epoch 0140, iter [00900, 01251], lr: 0.000987, loss: 0.4086
2022-09-29 14:48:33 - train: epoch 0140, iter [00910, 01251], lr: 0.000987, loss: 0.4016
2022-09-29 14:48:51 - train: epoch 0140, iter [00920, 01251], lr: 0.000987, loss: 0.4078
2022-09-29 14:49:08 - train: epoch 0140, iter [00930, 01251], lr: 0.000987, loss: 0.4074
2022-09-29 14:49:26 - train: epoch 0140, iter [00940, 01251], lr: 0.000987, loss: 0.4251
2022-09-29 14:49:44 - train: epoch 0140, iter [00950, 01251], lr: 0.000987, loss: 0.4354
2022-09-29 14:50:01 - train: epoch 0140, iter [00960, 01251], lr: 0.000987, loss: 0.4115
2022-09-29 14:50:19 - train: epoch 0140, iter [00970, 01251], lr: 0.000987, loss: 0.4419
2022-09-29 14:50:37 - train: epoch 0140, iter [00980, 01251], lr: 0.000987, loss: 0.4045
2022-09-29 14:50:54 - train: epoch 0140, iter [00990, 01251], lr: 0.000987, loss: 0.3968
2022-09-29 14:51:12 - train: epoch 0140, iter [01000, 01251], lr: 0.000986, loss: 0.4195
2022-09-29 14:51:30 - train: epoch 0140, iter [01010, 01251], lr: 0.000986, loss: 0.4046
2022-09-29 14:51:48 - train: epoch 0140, iter [01020, 01251], lr: 0.000986, loss: 0.4032
2022-09-29 14:52:05 - train: epoch 0140, iter [01030, 01251], lr: 0.000986, loss: 0.4149
2022-09-29 14:52:23 - train: epoch 0140, iter [01040, 01251], lr: 0.000986, loss: 0.4161
2022-09-29 14:52:41 - train: epoch 0140, iter [01050, 01251], lr: 0.000986, loss: 0.4097
2022-09-29 14:52:59 - train: epoch 0140, iter [01060, 01251], lr: 0.000986, loss: 0.4087
2022-09-29 14:53:16 - train: epoch 0140, iter [01070, 01251], lr: 0.000986, loss: 0.3984
2022-09-29 14:53:34 - train: epoch 0140, iter [01080, 01251], lr: 0.000986, loss: 0.3969
2022-09-29 14:53:52 - train: epoch 0140, iter [01090, 01251], lr: 0.000986, loss: 0.4083
2022-09-29 14:54:09 - train: epoch 0140, iter [01100, 01251], lr: 0.000986, loss: 0.4047
2022-09-29 14:54:27 - train: epoch 0140, iter [01110, 01251], lr: 0.000986, loss: 0.4205
2022-09-29 14:54:45 - train: epoch 0140, iter [01120, 01251], lr: 0.000986, loss: 0.4161
2022-09-29 14:55:03 - train: epoch 0140, iter [01130, 01251], lr: 0.000986, loss: 0.4213
2022-09-29 14:55:20 - train: epoch 0140, iter [01140, 01251], lr: 0.000986, loss: 0.4121
2022-09-29 14:55:38 - train: epoch 0140, iter [01150, 01251], lr: 0.000986, loss: 0.3704
2022-09-29 14:55:56 - train: epoch 0140, iter [01160, 01251], lr: 0.000986, loss: 0.4246
2022-09-29 14:56:13 - train: epoch 0140, iter [01170, 01251], lr: 0.000986, loss: 0.4237
2022-09-29 14:56:31 - train: epoch 0140, iter [01180, 01251], lr: 0.000986, loss: 0.4125
2022-09-29 14:56:49 - train: epoch 0140, iter [01190, 01251], lr: 0.000986, loss: 0.4076
2022-09-29 14:57:07 - train: epoch 0140, iter [01200, 01251], lr: 0.000986, loss: 0.4217
2022-09-29 14:57:24 - train: epoch 0140, iter [01210, 01251], lr: 0.000986, loss: 0.4161
2022-09-29 14:57:42 - train: epoch 0140, iter [01220, 01251], lr: 0.000986, loss: 0.4426
2022-09-29 14:57:59 - train: epoch 0140, iter [01230, 01251], lr: 0.000986, loss: 0.4028
2022-09-29 14:58:17 - train: epoch 0140, iter [01240, 01251], lr: 0.000986, loss: 0.4028
2022-09-29 14:58:34 - train: epoch 0140, iter [01250, 01251], lr: 0.000986, loss: 0.4130
2022-09-29 14:58:38 - train: epoch 140, train_loss: 0.4110
2022-09-29 14:58:41 - until epoch: 140, best_loss: 0.4110
2022-09-29 14:58:41 - epoch 141 lr: 0.000986
2022-09-29 14:59:13 - train: epoch 0141, iter [00010, 01251], lr: 0.000986, loss: 0.4213
2022-09-29 14:59:31 - train: epoch 0141, iter [00020, 01251], lr: 0.000986, loss: 0.3972
2022-09-29 14:59:48 - train: epoch 0141, iter [00030, 01251], lr: 0.000986, loss: 0.3991
2022-09-29 15:00:06 - train: epoch 0141, iter [00040, 01251], lr: 0.000986, loss: 0.4233
2022-09-29 15:00:24 - train: epoch 0141, iter [00050, 01251], lr: 0.000986, loss: 0.4229
2022-09-29 15:00:42 - train: epoch 0141, iter [00060, 01251], lr: 0.000985, loss: 0.4254
2022-09-29 15:00:59 - train: epoch 0141, iter [00070, 01251], lr: 0.000985, loss: 0.4018
2022-09-29 15:01:17 - train: epoch 0141, iter [00080, 01251], lr: 0.000985, loss: 0.4139
2022-09-29 15:01:35 - train: epoch 0141, iter [00090, 01251], lr: 0.000985, loss: 0.4108
2022-09-29 15:01:52 - train: epoch 0141, iter [00100, 01251], lr: 0.000985, loss: 0.4119
2022-09-29 15:02:10 - train: epoch 0141, iter [00110, 01251], lr: 0.000985, loss: 0.4180
2022-09-29 15:02:28 - train: epoch 0141, iter [00120, 01251], lr: 0.000985, loss: 0.4132
2022-09-29 15:02:45 - train: epoch 0141, iter [00130, 01251], lr: 0.000985, loss: 0.4084
2022-09-29 15:03:03 - train: epoch 0141, iter [00140, 01251], lr: 0.000985, loss: 0.4106
2022-09-29 15:03:21 - train: epoch 0141, iter [00150, 01251], lr: 0.000985, loss: 0.4114
2022-09-29 15:03:39 - train: epoch 0141, iter [00160, 01251], lr: 0.000985, loss: 0.4058
2022-09-29 15:03:56 - train: epoch 0141, iter [00170, 01251], lr: 0.000985, loss: 0.4187
2022-09-29 15:04:14 - train: epoch 0141, iter [00180, 01251], lr: 0.000985, loss: 0.4175
2022-09-29 15:04:31 - train: epoch 0141, iter [00190, 01251], lr: 0.000985, loss: 0.4040
2022-09-29 15:04:49 - train: epoch 0141, iter [00200, 01251], lr: 0.000985, loss: 0.4075
2022-09-29 15:05:07 - train: epoch 0141, iter [00210, 01251], lr: 0.000985, loss: 0.4035
2022-09-29 15:05:25 - train: epoch 0141, iter [00220, 01251], lr: 0.000985, loss: 0.4115
2022-09-29 15:05:42 - train: epoch 0141, iter [00230, 01251], lr: 0.000985, loss: 0.4142
2022-09-29 15:06:00 - train: epoch 0141, iter [00240, 01251], lr: 0.000985, loss: 0.3951
2022-09-29 15:06:18 - train: epoch 0141, iter [00250, 01251], lr: 0.000985, loss: 0.4076
2022-09-29 15:06:35 - train: epoch 0141, iter [00260, 01251], lr: 0.000985, loss: 0.3954
2022-09-29 15:06:53 - train: epoch 0141, iter [00270, 01251], lr: 0.000985, loss: 0.4011
2022-09-29 15:07:11 - train: epoch 0141, iter [00280, 01251], lr: 0.000985, loss: 0.4235
2022-09-29 15:07:29 - train: epoch 0141, iter [00290, 01251], lr: 0.000985, loss: 0.4112
2022-09-29 15:07:46 - train: epoch 0141, iter [00300, 01251], lr: 0.000985, loss: 0.4176
2022-09-29 15:08:04 - train: epoch 0141, iter [00310, 01251], lr: 0.000985, loss: 0.4087
2022-09-29 15:08:22 - train: epoch 0141, iter [00320, 01251], lr: 0.000985, loss: 0.4207
2022-09-29 15:08:39 - train: epoch 0141, iter [00330, 01251], lr: 0.000985, loss: 0.4101
2022-09-29 15:08:57 - train: epoch 0141, iter [00340, 01251], lr: 0.000985, loss: 0.3933
2022-09-29 15:09:15 - train: epoch 0141, iter [00350, 01251], lr: 0.000985, loss: 0.4145
2022-09-29 15:09:32 - train: epoch 0141, iter [00360, 01251], lr: 0.000985, loss: 0.4163
2022-09-29 15:09:50 - train: epoch 0141, iter [00370, 01251], lr: 0.000984, loss: 0.4291
2022-09-29 15:10:08 - train: epoch 0141, iter [00380, 01251], lr: 0.000984, loss: 0.4263
2022-09-29 15:10:26 - train: epoch 0141, iter [00390, 01251], lr: 0.000984, loss: 0.4161
2022-09-29 15:10:43 - train: epoch 0141, iter [00400, 01251], lr: 0.000984, loss: 0.4081
2022-09-29 15:11:01 - train: epoch 0141, iter [00410, 01251], lr: 0.000984, loss: 0.4063
2022-09-29 15:11:19 - train: epoch 0141, iter [00420, 01251], lr: 0.000984, loss: 0.4305
2022-09-29 15:11:36 - train: epoch 0141, iter [00430, 01251], lr: 0.000984, loss: 0.4140
2022-09-29 15:11:54 - train: epoch 0141, iter [00440, 01251], lr: 0.000984, loss: 0.4164
2022-09-29 15:12:12 - train: epoch 0141, iter [00450, 01251], lr: 0.000984, loss: 0.4113
2022-09-29 15:12:30 - train: epoch 0141, iter [00460, 01251], lr: 0.000984, loss: 0.4164
2022-09-29 15:12:47 - train: epoch 0141, iter [00470, 01251], lr: 0.000984, loss: 0.4205
2022-09-29 15:13:05 - train: epoch 0141, iter [00480, 01251], lr: 0.000984, loss: 0.4095
2022-09-29 15:13:23 - train: epoch 0141, iter [00490, 01251], lr: 0.000984, loss: 0.3902
2022-09-29 15:13:41 - train: epoch 0141, iter [00500, 01251], lr: 0.000984, loss: 0.4306
2022-09-29 15:13:58 - train: epoch 0141, iter [00510, 01251], lr: 0.000984, loss: 0.4038
2022-09-29 15:14:16 - train: epoch 0141, iter [00520, 01251], lr: 0.000984, loss: 0.4112
2022-09-29 15:14:34 - train: epoch 0141, iter [00530, 01251], lr: 0.000984, loss: 0.4037
2022-09-29 15:14:51 - train: epoch 0141, iter [00540, 01251], lr: 0.000984, loss: 0.4062
2022-09-29 15:15:09 - train: epoch 0141, iter [00550, 01251], lr: 0.000984, loss: 0.3949
2022-09-29 15:15:27 - train: epoch 0141, iter [00560, 01251], lr: 0.000984, loss: 0.4335
2022-09-29 15:15:44 - train: epoch 0141, iter [00570, 01251], lr: 0.000984, loss: 0.4132
2022-09-29 15:16:02 - train: epoch 0141, iter [00580, 01251], lr: 0.000984, loss: 0.4125
2022-09-29 15:16:20 - train: epoch 0141, iter [00590, 01251], lr: 0.000984, loss: 0.4074
2022-09-29 15:16:38 - train: epoch 0141, iter [00600, 01251], lr: 0.000984, loss: 0.4127
2022-09-29 15:16:55 - train: epoch 0141, iter [00610, 01251], lr: 0.000984, loss: 0.3992
2022-09-29 15:17:13 - train: epoch 0141, iter [00620, 01251], lr: 0.000984, loss: 0.4161
2022-09-29 15:17:31 - train: epoch 0141, iter [00630, 01251], lr: 0.000984, loss: 0.4081
2022-09-29 15:17:48 - train: epoch 0141, iter [00640, 01251], lr: 0.000984, loss: 0.4026
2022-09-29 15:18:06 - train: epoch 0141, iter [00650, 01251], lr: 0.000984, loss: 0.3949
2022-09-29 15:18:24 - train: epoch 0141, iter [00660, 01251], lr: 0.000984, loss: 0.4050
2022-09-29 15:18:42 - train: epoch 0141, iter [00670, 01251], lr: 0.000984, loss: 0.4050
2022-09-29 15:19:00 - train: epoch 0141, iter [00680, 01251], lr: 0.000983, loss: 0.4209
2022-09-29 15:19:17 - train: epoch 0141, iter [00690, 01251], lr: 0.000983, loss: 0.4299
2022-09-29 15:19:35 - train: epoch 0141, iter [00700, 01251], lr: 0.000983, loss: 0.4013
2022-09-29 15:19:53 - train: epoch 0141, iter [00710, 01251], lr: 0.000983, loss: 0.3992
2022-09-29 15:20:10 - train: epoch 0141, iter [00720, 01251], lr: 0.000983, loss: 0.4128
2022-09-29 15:20:28 - train: epoch 0141, iter [00730, 01251], lr: 0.000983, loss: 0.4120
2022-09-29 15:20:45 - train: epoch 0141, iter [00740, 01251], lr: 0.000983, loss: 0.4197
2022-09-29 15:21:03 - train: epoch 0141, iter [00750, 01251], lr: 0.000983, loss: 0.4160
2022-09-29 15:21:21 - train: epoch 0141, iter [00760, 01251], lr: 0.000983, loss: 0.4296
2022-09-29 15:21:39 - train: epoch 0141, iter [00770, 01251], lr: 0.000983, loss: 0.3937
2022-09-29 15:21:56 - train: epoch 0141, iter [00780, 01251], lr: 0.000983, loss: 0.4112
2022-09-29 15:22:14 - train: epoch 0141, iter [00790, 01251], lr: 0.000983, loss: 0.4069
2022-09-29 15:22:32 - train: epoch 0141, iter [00800, 01251], lr: 0.000983, loss: 0.3997
2022-09-29 15:22:50 - train: epoch 0141, iter [00810, 01251], lr: 0.000983, loss: 0.4074
2022-09-29 15:23:08 - train: epoch 0141, iter [00820, 01251], lr: 0.000983, loss: 0.4162
2022-09-29 15:23:25 - train: epoch 0141, iter [00830, 01251], lr: 0.000983, loss: 0.4203
2022-09-29 15:23:43 - train: epoch 0141, iter [00840, 01251], lr: 0.000983, loss: 0.3952
2022-09-29 15:24:01 - train: epoch 0141, iter [00850, 01251], lr: 0.000983, loss: 0.4043
2022-09-29 15:24:19 - train: epoch 0141, iter [00860, 01251], lr: 0.000983, loss: 0.4135
2022-09-29 15:24:36 - train: epoch 0141, iter [00870, 01251], lr: 0.000983, loss: 0.4131
2022-09-29 15:24:54 - train: epoch 0141, iter [00880, 01251], lr: 0.000983, loss: 0.4219
2022-09-29 15:25:12 - train: epoch 0141, iter [00890, 01251], lr: 0.000983, loss: 0.4056
2022-09-29 15:25:29 - train: epoch 0141, iter [00900, 01251], lr: 0.000983, loss: 0.4207
2022-09-29 15:25:47 - train: epoch 0141, iter [00910, 01251], lr: 0.000983, loss: 0.3812
2022-09-29 15:26:05 - train: epoch 0141, iter [00920, 01251], lr: 0.000983, loss: 0.3952
2022-09-29 15:26:22 - train: epoch 0141, iter [00930, 01251], lr: 0.000983, loss: 0.4136
2022-09-29 15:26:40 - train: epoch 0141, iter [00940, 01251], lr: 0.000983, loss: 0.4063
2022-09-29 15:26:58 - train: epoch 0141, iter [00950, 01251], lr: 0.000983, loss: 0.4007
2022-09-29 15:27:16 - train: epoch 0141, iter [00960, 01251], lr: 0.000983, loss: 0.4260
2022-09-29 15:27:33 - train: epoch 0141, iter [00970, 01251], lr: 0.000983, loss: 0.4213
2022-09-29 15:27:51 - train: epoch 0141, iter [00980, 01251], lr: 0.000983, loss: 0.3991
2022-09-29 15:28:09 - train: epoch 0141, iter [00990, 01251], lr: 0.000982, loss: 0.3840
2022-09-29 15:28:26 - train: epoch 0141, iter [01000, 01251], lr: 0.000982, loss: 0.4079
2022-09-29 15:28:44 - train: epoch 0141, iter [01010, 01251], lr: 0.000982, loss: 0.4150
2022-09-29 15:29:02 - train: epoch 0141, iter [01020, 01251], lr: 0.000982, loss: 0.4145
2022-09-29 15:29:20 - train: epoch 0141, iter [01030, 01251], lr: 0.000982, loss: 0.4123
2022-09-29 15:29:37 - train: epoch 0141, iter [01040, 01251], lr: 0.000982, loss: 0.4071
2022-09-29 15:29:55 - train: epoch 0141, iter [01050, 01251], lr: 0.000982, loss: 0.3968
2022-09-29 15:30:13 - train: epoch 0141, iter [01060, 01251], lr: 0.000982, loss: 0.4030
2022-09-29 15:30:30 - train: epoch 0141, iter [01070, 01251], lr: 0.000982, loss: 0.4114
2022-09-29 15:30:48 - train: epoch 0141, iter [01080, 01251], lr: 0.000982, loss: 0.4033
2022-09-29 15:31:06 - train: epoch 0141, iter [01090, 01251], lr: 0.000982, loss: 0.4208
2022-09-29 15:31:24 - train: epoch 0141, iter [01100, 01251], lr: 0.000982, loss: 0.4065
2022-09-29 15:31:41 - train: epoch 0141, iter [01110, 01251], lr: 0.000982, loss: 0.4229
2022-09-29 15:31:59 - train: epoch 0141, iter [01120, 01251], lr: 0.000982, loss: 0.4189
2022-09-29 15:32:17 - train: epoch 0141, iter [01130, 01251], lr: 0.000982, loss: 0.4370
2022-09-29 15:32:34 - train: epoch 0141, iter [01140, 01251], lr: 0.000982, loss: 0.4047
2022-09-29 15:32:52 - train: epoch 0141, iter [01150, 01251], lr: 0.000982, loss: 0.4208
2022-09-29 15:33:10 - train: epoch 0141, iter [01160, 01251], lr: 0.000982, loss: 0.4268
2022-09-29 15:33:27 - train: epoch 0141, iter [01170, 01251], lr: 0.000982, loss: 0.4052
2022-09-29 15:33:45 - train: epoch 0141, iter [01180, 01251], lr: 0.000982, loss: 0.3983
2022-09-29 15:34:03 - train: epoch 0141, iter [01190, 01251], lr: 0.000982, loss: 0.4098
2022-09-29 15:34:21 - train: epoch 0141, iter [01200, 01251], lr: 0.000982, loss: 0.4116
2022-09-29 15:34:38 - train: epoch 0141, iter [01210, 01251], lr: 0.000982, loss: 0.4047
2022-09-29 15:34:56 - train: epoch 0141, iter [01220, 01251], lr: 0.000982, loss: 0.4068
2022-09-29 15:35:14 - train: epoch 0141, iter [01230, 01251], lr: 0.000982, loss: 0.4078
2022-09-29 15:35:32 - train: epoch 0141, iter [01240, 01251], lr: 0.000982, loss: 0.4017
2022-09-29 15:35:49 - train: epoch 0141, iter [01250, 01251], lr: 0.000982, loss: 0.4196
2022-09-29 15:35:53 - train: epoch 141, train_loss: 0.4109
2022-09-29 15:35:55 - until epoch: 141, best_loss: 0.4109
2022-09-29 15:35:55 - epoch 142 lr: 0.000982
2022-09-29 15:36:29 - train: epoch 0142, iter [00010, 01251], lr: 0.000982, loss: 0.4073
2022-09-29 15:36:46 - train: epoch 0142, iter [00020, 01251], lr: 0.000982, loss: 0.4251
2022-09-29 15:37:04 - train: epoch 0142, iter [00030, 01251], lr: 0.000982, loss: 0.4244
2022-09-29 15:37:22 - train: epoch 0142, iter [00040, 01251], lr: 0.000982, loss: 0.4130
2022-09-29 15:37:40 - train: epoch 0142, iter [00050, 01251], lr: 0.000981, loss: 0.4052
2022-09-29 15:37:57 - train: epoch 0142, iter [00060, 01251], lr: 0.000981, loss: 0.4204
2022-09-29 15:38:15 - train: epoch 0142, iter [00070, 01251], lr: 0.000981, loss: 0.4225
2022-09-29 15:38:33 - train: epoch 0142, iter [00080, 01251], lr: 0.000981, loss: 0.4131
2022-09-29 15:38:51 - train: epoch 0142, iter [00090, 01251], lr: 0.000981, loss: 0.3906
2022-09-29 15:39:08 - train: epoch 0142, iter [00100, 01251], lr: 0.000981, loss: 0.4075
2022-09-29 15:39:26 - train: epoch 0142, iter [00110, 01251], lr: 0.000981, loss: 0.4068
2022-09-29 15:39:44 - train: epoch 0142, iter [00120, 01251], lr: 0.000981, loss: 0.4010
2022-09-29 15:40:01 - train: epoch 0142, iter [00130, 01251], lr: 0.000981, loss: 0.4143
2022-09-29 15:40:19 - train: epoch 0142, iter [00140, 01251], lr: 0.000981, loss: 0.3888
2022-09-29 15:40:37 - train: epoch 0142, iter [00150, 01251], lr: 0.000981, loss: 0.4219
2022-09-29 15:40:54 - train: epoch 0142, iter [00160, 01251], lr: 0.000981, loss: 0.4022
2022-09-29 15:41:12 - train: epoch 0142, iter [00170, 01251], lr: 0.000981, loss: 0.4188
2022-09-29 15:41:30 - train: epoch 0142, iter [00180, 01251], lr: 0.000981, loss: 0.3981
2022-09-29 15:41:47 - train: epoch 0142, iter [00190, 01251], lr: 0.000981, loss: 0.4295
2022-09-29 15:42:05 - train: epoch 0142, iter [00200, 01251], lr: 0.000981, loss: 0.4018
2022-09-29 15:42:23 - train: epoch 0142, iter [00210, 01251], lr: 0.000981, loss: 0.3977
2022-09-29 15:42:41 - train: epoch 0142, iter [00220, 01251], lr: 0.000981, loss: 0.3825
2022-09-29 15:42:58 - train: epoch 0142, iter [00230, 01251], lr: 0.000981, loss: 0.4440
2022-09-29 15:43:16 - train: epoch 0142, iter [00240, 01251], lr: 0.000981, loss: 0.4063
2022-09-29 15:43:34 - train: epoch 0142, iter [00250, 01251], lr: 0.000981, loss: 0.3973
2022-09-29 15:43:52 - train: epoch 0142, iter [00260, 01251], lr: 0.000981, loss: 0.3897
2022-09-29 15:44:09 - train: epoch 0142, iter [00270, 01251], lr: 0.000981, loss: 0.4210
2022-09-29 15:44:27 - train: epoch 0142, iter [00280, 01251], lr: 0.000981, loss: 0.4122
2022-09-29 15:44:45 - train: epoch 0142, iter [00290, 01251], lr: 0.000981, loss: 0.4076
2022-09-29 15:45:03 - train: epoch 0142, iter [00300, 01251], lr: 0.000981, loss: 0.4063
2022-09-29 15:45:20 - train: epoch 0142, iter [00310, 01251], lr: 0.000981, loss: 0.4080
2022-09-29 15:45:38 - train: epoch 0142, iter [00320, 01251], lr: 0.000981, loss: 0.4050
2022-09-29 15:45:56 - train: epoch 0142, iter [00330, 01251], lr: 0.000981, loss: 0.4174
2022-09-29 15:46:13 - train: epoch 0142, iter [00340, 01251], lr: 0.000981, loss: 0.3835
2022-09-29 15:46:31 - train: epoch 0142, iter [00350, 01251], lr: 0.000981, loss: 0.4345
2022-09-29 15:46:49 - train: epoch 0142, iter [00360, 01251], lr: 0.000980, loss: 0.4217
2022-09-29 15:47:07 - train: epoch 0142, iter [00370, 01251], lr: 0.000980, loss: 0.4307
2022-09-29 15:47:24 - train: epoch 0142, iter [00380, 01251], lr: 0.000980, loss: 0.4047
2022-09-29 15:47:42 - train: epoch 0142, iter [00390, 01251], lr: 0.000980, loss: 0.4008
2022-09-29 15:48:00 - train: epoch 0142, iter [00400, 01251], lr: 0.000980, loss: 0.3986
2022-09-29 15:48:18 - train: epoch 0142, iter [00410, 01251], lr: 0.000980, loss: 0.3912
2022-09-29 15:48:35 - train: epoch 0142, iter [00420, 01251], lr: 0.000980, loss: 0.4173
2022-09-29 15:48:53 - train: epoch 0142, iter [00430, 01251], lr: 0.000980, loss: 0.4119
2022-09-29 15:49:11 - train: epoch 0142, iter [00440, 01251], lr: 0.000980, loss: 0.3999
2022-09-29 15:49:28 - train: epoch 0142, iter [00450, 01251], lr: 0.000980, loss: 0.4166
2022-09-29 15:49:46 - train: epoch 0142, iter [00460, 01251], lr: 0.000980, loss: 0.4196
2022-09-29 15:50:04 - train: epoch 0142, iter [00470, 01251], lr: 0.000980, loss: 0.4377
2022-09-29 15:50:22 - train: epoch 0142, iter [00480, 01251], lr: 0.000980, loss: 0.3904
2022-09-29 15:50:39 - train: epoch 0142, iter [00490, 01251], lr: 0.000980, loss: 0.4155
2022-09-29 15:50:57 - train: epoch 0142, iter [00500, 01251], lr: 0.000980, loss: 0.4265
2022-09-29 15:51:15 - train: epoch 0142, iter [00510, 01251], lr: 0.000980, loss: 0.4066
2022-09-29 15:51:33 - train: epoch 0142, iter [00520, 01251], lr: 0.000980, loss: 0.3988
2022-09-29 15:51:50 - train: epoch 0142, iter [00530, 01251], lr: 0.000980, loss: 0.3903
2022-09-29 15:52:08 - train: epoch 0142, iter [00540, 01251], lr: 0.000980, loss: 0.4042
2022-09-29 15:52:26 - train: epoch 0142, iter [00550, 01251], lr: 0.000980, loss: 0.4150
2022-09-29 15:52:43 - train: epoch 0142, iter [00560, 01251], lr: 0.000980, loss: 0.4170
2022-09-29 15:53:01 - train: epoch 0142, iter [00570, 01251], lr: 0.000980, loss: 0.3934
2022-09-29 15:53:19 - train: epoch 0142, iter [00580, 01251], lr: 0.000980, loss: 0.4014
2022-09-29 15:53:36 - train: epoch 0142, iter [00590, 01251], lr: 0.000980, loss: 0.4187
2022-09-29 15:53:54 - train: epoch 0142, iter [00600, 01251], lr: 0.000980, loss: 0.3998
2022-09-29 15:54:12 - train: epoch 0142, iter [00610, 01251], lr: 0.000980, loss: 0.4150
2022-09-29 15:54:30 - train: epoch 0142, iter [00620, 01251], lr: 0.000980, loss: 0.4135
2022-09-29 15:54:48 - train: epoch 0142, iter [00630, 01251], lr: 0.000980, loss: 0.4113
2022-09-29 15:55:05 - train: epoch 0142, iter [00640, 01251], lr: 0.000980, loss: 0.4140
2022-09-29 15:55:23 - train: epoch 0142, iter [00650, 01251], lr: 0.000980, loss: 0.4333
2022-09-29 15:55:41 - train: epoch 0142, iter [00660, 01251], lr: 0.000980, loss: 0.4219
2022-09-29 15:55:59 - train: epoch 0142, iter [00670, 01251], lr: 0.000979, loss: 0.4176
2022-09-29 15:56:16 - train: epoch 0142, iter [00680, 01251], lr: 0.000979, loss: 0.4072
2022-09-29 15:56:34 - train: epoch 0142, iter [00690, 01251], lr: 0.000979, loss: 0.4089
2022-09-29 15:56:52 - train: epoch 0142, iter [00700, 01251], lr: 0.000979, loss: 0.4182
2022-09-29 15:57:09 - train: epoch 0142, iter [00710, 01251], lr: 0.000979, loss: 0.4102
2022-09-29 15:57:27 - train: epoch 0142, iter [00720, 01251], lr: 0.000979, loss: 0.4025
2022-09-29 15:57:45 - train: epoch 0142, iter [00730, 01251], lr: 0.000979, loss: 0.4043
2022-09-29 15:58:03 - train: epoch 0142, iter [00740, 01251], lr: 0.000979, loss: 0.4056
2022-09-29 15:58:20 - train: epoch 0142, iter [00750, 01251], lr: 0.000979, loss: 0.4180
2022-09-29 15:58:38 - train: epoch 0142, iter [00760, 01251], lr: 0.000979, loss: 0.4103
2022-09-29 15:58:56 - train: epoch 0142, iter [00770, 01251], lr: 0.000979, loss: 0.3913
2022-09-29 15:59:13 - train: epoch 0142, iter [00780, 01251], lr: 0.000979, loss: 0.4202
2022-09-29 15:59:31 - train: epoch 0142, iter [00790, 01251], lr: 0.000979, loss: 0.3983
2022-09-29 15:59:49 - train: epoch 0142, iter [00800, 01251], lr: 0.000979, loss: 0.4000
2022-09-29 16:00:07 - train: epoch 0142, iter [00810, 01251], lr: 0.000979, loss: 0.3976
2022-09-29 16:00:24 - train: epoch 0142, iter [00820, 01251], lr: 0.000979, loss: 0.4101
2022-09-29 16:00:42 - train: epoch 0142, iter [00830, 01251], lr: 0.000979, loss: 0.3971
2022-09-29 16:00:59 - train: epoch 0142, iter [00840, 01251], lr: 0.000979, loss: 0.4109
2022-09-29 16:01:17 - train: epoch 0142, iter [00850, 01251], lr: 0.000979, loss: 0.4263
2022-09-29 16:01:35 - train: epoch 0142, iter [00860, 01251], lr: 0.000979, loss: 0.4245
2022-09-29 16:01:53 - train: epoch 0142, iter [00870, 01251], lr: 0.000979, loss: 0.4154
2022-09-29 16:02:10 - train: epoch 0142, iter [00880, 01251], lr: 0.000979, loss: 0.4210
2022-09-29 16:02:28 - train: epoch 0142, iter [00890, 01251], lr: 0.000979, loss: 0.4194
2022-09-29 16:02:46 - train: epoch 0142, iter [00900, 01251], lr: 0.000979, loss: 0.4102
2022-09-29 16:03:04 - train: epoch 0142, iter [00910, 01251], lr: 0.000979, loss: 0.4145
2022-09-29 16:03:21 - train: epoch 0142, iter [00920, 01251], lr: 0.000979, loss: 0.4221
2022-09-29 16:03:39 - train: epoch 0142, iter [00930, 01251], lr: 0.000979, loss: 0.3939
2022-09-29 16:03:57 - train: epoch 0142, iter [00940, 01251], lr: 0.000979, loss: 0.4044
2022-09-29 16:04:14 - train: epoch 0142, iter [00950, 01251], lr: 0.000979, loss: 0.4242
2022-09-29 16:04:32 - train: epoch 0142, iter [00960, 01251], lr: 0.000979, loss: 0.4075
2022-09-29 16:04:50 - train: epoch 0142, iter [00970, 01251], lr: 0.000979, loss: 0.4076
2022-09-29 16:05:07 - train: epoch 0142, iter [00980, 01251], lr: 0.000978, loss: 0.3974
2022-09-29 16:05:25 - train: epoch 0142, iter [00990, 01251], lr: 0.000978, loss: 0.3986
2022-09-29 16:05:43 - train: epoch 0142, iter [01000, 01251], lr: 0.000978, loss: 0.4135
2022-09-29 16:06:00 - train: epoch 0142, iter [01010, 01251], lr: 0.000978, loss: 0.4215
2022-09-29 16:06:18 - train: epoch 0142, iter [01020, 01251], lr: 0.000978, loss: 0.4107
2022-09-29 16:06:36 - train: epoch 0142, iter [01030, 01251], lr: 0.000978, loss: 0.4114
2022-09-29 16:06:54 - train: epoch 0142, iter [01040, 01251], lr: 0.000978, loss: 0.4368
2022-09-29 16:07:11 - train: epoch 0142, iter [01050, 01251], lr: 0.000978, loss: 0.4129
2022-09-29 16:07:29 - train: epoch 0142, iter [01060, 01251], lr: 0.000978, loss: 0.4233
2022-09-29 16:07:47 - train: epoch 0142, iter [01070, 01251], lr: 0.000978, loss: 0.4098
2022-09-29 16:08:04 - train: epoch 0142, iter [01080, 01251], lr: 0.000978, loss: 0.4057
2022-09-29 16:08:22 - train: epoch 0142, iter [01090, 01251], lr: 0.000978, loss: 0.3992
2022-09-29 16:08:40 - train: epoch 0142, iter [01100, 01251], lr: 0.000978, loss: 0.4263
2022-09-29 16:08:58 - train: epoch 0142, iter [01110, 01251], lr: 0.000978, loss: 0.4145
2022-09-29 16:09:15 - train: epoch 0142, iter [01120, 01251], lr: 0.000978, loss: 0.4152
2022-09-29 16:09:33 - train: epoch 0142, iter [01130, 01251], lr: 0.000978, loss: 0.4075
2022-09-29 16:09:51 - train: epoch 0142, iter [01140, 01251], lr: 0.000978, loss: 0.4166
2022-09-29 16:10:09 - train: epoch 0142, iter [01150, 01251], lr: 0.000978, loss: 0.4182
2022-09-29 16:10:26 - train: epoch 0142, iter [01160, 01251], lr: 0.000978, loss: 0.4098
2022-09-29 16:10:44 - train: epoch 0142, iter [01170, 01251], lr: 0.000978, loss: 0.4246
2022-09-29 16:11:02 - train: epoch 0142, iter [01180, 01251], lr: 0.000978, loss: 0.4100
2022-09-29 16:11:20 - train: epoch 0142, iter [01190, 01251], lr: 0.000978, loss: 0.4147
2022-09-29 16:11:37 - train: epoch 0142, iter [01200, 01251], lr: 0.000978, loss: 0.4013
2022-09-29 16:11:55 - train: epoch 0142, iter [01210, 01251], lr: 0.000978, loss: 0.4221
2022-09-29 16:12:13 - train: epoch 0142, iter [01220, 01251], lr: 0.000978, loss: 0.4071
2022-09-29 16:12:31 - train: epoch 0142, iter [01230, 01251], lr: 0.000978, loss: 0.4209
2022-09-29 16:12:48 - train: epoch 0142, iter [01240, 01251], lr: 0.000978, loss: 0.4170
2022-09-29 16:13:05 - train: epoch 0142, iter [01250, 01251], lr: 0.000978, loss: 0.3965
2022-09-29 16:13:09 - train: epoch 142, train_loss: 0.4108
2022-09-29 16:13:12 - until epoch: 142, best_loss: 0.4108
2022-09-29 16:13:12 - epoch 143 lr: 0.000978
2022-09-29 16:13:44 - train: epoch 0143, iter [00010, 01251], lr: 0.000978, loss: 0.4139
2022-09-29 16:14:02 - train: epoch 0143, iter [00020, 01251], lr: 0.000978, loss: 0.4020
2022-09-29 16:14:20 - train: epoch 0143, iter [00030, 01251], lr: 0.000977, loss: 0.4020
2022-09-29 16:14:38 - train: epoch 0143, iter [00040, 01251], lr: 0.000977, loss: 0.4046
2022-09-29 16:14:55 - train: epoch 0143, iter [00050, 01251], lr: 0.000977, loss: 0.3859
2022-09-29 16:15:13 - train: epoch 0143, iter [00060, 01251], lr: 0.000977, loss: 0.4009
2022-09-29 16:15:31 - train: epoch 0143, iter [00070, 01251], lr: 0.000977, loss: 0.4203
2022-09-29 16:15:48 - train: epoch 0143, iter [00080, 01251], lr: 0.000977, loss: 0.4162
2022-09-29 16:16:06 - train: epoch 0143, iter [00090, 01251], lr: 0.000977, loss: 0.4177
2022-09-29 16:16:24 - train: epoch 0143, iter [00100, 01251], lr: 0.000977, loss: 0.4073
2022-09-29 16:16:42 - train: epoch 0143, iter [00110, 01251], lr: 0.000977, loss: 0.3911
2022-09-29 16:17:00 - train: epoch 0143, iter [00120, 01251], lr: 0.000977, loss: 0.4100
2022-09-29 16:17:17 - train: epoch 0143, iter [00130, 01251], lr: 0.000977, loss: 0.3984
2022-09-29 16:17:35 - train: epoch 0143, iter [00140, 01251], lr: 0.000977, loss: 0.4085
2022-09-29 16:17:53 - train: epoch 0143, iter [00150, 01251], lr: 0.000977, loss: 0.4346
2022-09-29 16:18:10 - train: epoch 0143, iter [00160, 01251], lr: 0.000977, loss: 0.3991
2022-09-29 16:18:28 - train: epoch 0143, iter [00170, 01251], lr: 0.000977, loss: 0.4042
2022-09-29 16:18:46 - train: epoch 0143, iter [00180, 01251], lr: 0.000977, loss: 0.3906
2022-09-29 16:19:03 - train: epoch 0143, iter [00190, 01251], lr: 0.000977, loss: 0.4055
2022-09-29 16:19:21 - train: epoch 0143, iter [00200, 01251], lr: 0.000977, loss: 0.4225
2022-09-29 16:19:39 - train: epoch 0143, iter [00210, 01251], lr: 0.000977, loss: 0.4096
2022-09-29 16:19:56 - train: epoch 0143, iter [00220, 01251], lr: 0.000977, loss: 0.4087
2022-09-29 16:20:14 - train: epoch 0143, iter [00230, 01251], lr: 0.000977, loss: 0.4093
2022-09-29 16:20:32 - train: epoch 0143, iter [00240, 01251], lr: 0.000977, loss: 0.3987
2022-09-29 16:20:49 - train: epoch 0143, iter [00250, 01251], lr: 0.000977, loss: 0.4169
2022-09-29 16:21:07 - train: epoch 0143, iter [00260, 01251], lr: 0.000977, loss: 0.4094
2022-09-29 16:21:25 - train: epoch 0143, iter [00270, 01251], lr: 0.000977, loss: 0.4027
2022-09-29 16:21:43 - train: epoch 0143, iter [00280, 01251], lr: 0.000977, loss: 0.4089
2022-09-29 16:22:01 - train: epoch 0143, iter [00290, 01251], lr: 0.000977, loss: 0.4126
2022-09-29 16:22:18 - train: epoch 0143, iter [00300, 01251], lr: 0.000977, loss: 0.3968
2022-09-29 16:22:36 - train: epoch 0143, iter [00310, 01251], lr: 0.000977, loss: 0.4040
2022-09-29 16:22:54 - train: epoch 0143, iter [00320, 01251], lr: 0.000977, loss: 0.4088
2022-09-29 16:23:12 - train: epoch 0143, iter [00330, 01251], lr: 0.000977, loss: 0.4052
2022-09-29 16:23:29 - train: epoch 0143, iter [00340, 01251], lr: 0.000976, loss: 0.4177
2022-09-29 16:23:47 - train: epoch 0143, iter [00350, 01251], lr: 0.000976, loss: 0.4083
2022-09-29 16:24:05 - train: epoch 0143, iter [00360, 01251], lr: 0.000976, loss: 0.4138
2022-09-29 16:24:22 - train: epoch 0143, iter [00370, 01251], lr: 0.000976, loss: 0.3993
2022-09-29 16:24:40 - train: epoch 0143, iter [00380, 01251], lr: 0.000976, loss: 0.4033
2022-09-29 16:24:58 - train: epoch 0143, iter [00390, 01251], lr: 0.000976, loss: 0.3948
2022-09-29 16:25:15 - train: epoch 0143, iter [00400, 01251], lr: 0.000976, loss: 0.4096
2022-09-29 16:25:33 - train: epoch 0143, iter [00410, 01251], lr: 0.000976, loss: 0.3974
2022-09-29 16:25:51 - train: epoch 0143, iter [00420, 01251], lr: 0.000976, loss: 0.4045
2022-09-29 16:26:08 - train: epoch 0143, iter [00430, 01251], lr: 0.000976, loss: 0.4038
2022-09-29 16:26:26 - train: epoch 0143, iter [00440, 01251], lr: 0.000976, loss: 0.4161
2022-09-29 16:26:44 - train: epoch 0143, iter [00450, 01251], lr: 0.000976, loss: 0.4015
2022-09-29 16:27:01 - train: epoch 0143, iter [00460, 01251], lr: 0.000976, loss: 0.3987
2022-09-29 16:27:19 - train: epoch 0143, iter [00470, 01251], lr: 0.000976, loss: 0.4195
2022-09-29 16:27:37 - train: epoch 0143, iter [00480, 01251], lr: 0.000976, loss: 0.4142
2022-09-29 16:27:55 - train: epoch 0143, iter [00490, 01251], lr: 0.000976, loss: 0.4098
2022-09-29 16:28:12 - train: epoch 0143, iter [00500, 01251], lr: 0.000976, loss: 0.4212
2022-09-29 16:28:30 - train: epoch 0143, iter [00510, 01251], lr: 0.000976, loss: 0.3980
2022-09-29 16:28:48 - train: epoch 0143, iter [00520, 01251], lr: 0.000976, loss: 0.3949
2022-09-29 16:29:05 - train: epoch 0143, iter [00530, 01251], lr: 0.000976, loss: 0.4182
2022-09-29 16:29:23 - train: epoch 0143, iter [00540, 01251], lr: 0.000976, loss: 0.4159
2022-09-29 16:29:41 - train: epoch 0143, iter [00550, 01251], lr: 0.000976, loss: 0.4009
2022-09-29 16:29:59 - train: epoch 0143, iter [00560, 01251], lr: 0.000976, loss: 0.4295
2022-09-29 16:30:16 - train: epoch 0143, iter [00570, 01251], lr: 0.000976, loss: 0.4004
2022-09-29 16:30:34 - train: epoch 0143, iter [00580, 01251], lr: 0.000976, loss: 0.4118
2022-09-29 16:30:52 - train: epoch 0143, iter [00590, 01251], lr: 0.000976, loss: 0.3924
2022-09-29 16:31:09 - train: epoch 0143, iter [00600, 01251], lr: 0.000976, loss: 0.4027
2022-09-29 16:31:27 - train: epoch 0143, iter [00610, 01251], lr: 0.000976, loss: 0.4199
2022-09-29 16:31:44 - train: epoch 0143, iter [00620, 01251], lr: 0.000976, loss: 0.4032
2022-09-29 16:32:02 - train: epoch 0143, iter [00630, 01251], lr: 0.000976, loss: 0.4146
2022-09-29 16:32:20 - train: epoch 0143, iter [00640, 01251], lr: 0.000976, loss: 0.4184
2022-09-29 16:32:37 - train: epoch 0143, iter [00650, 01251], lr: 0.000975, loss: 0.3995
2022-09-29 16:32:55 - train: epoch 0143, iter [00660, 01251], lr: 0.000975, loss: 0.4231
2022-09-29 16:33:13 - train: epoch 0143, iter [00670, 01251], lr: 0.000975, loss: 0.3846
2022-09-29 16:33:30 - train: epoch 0143, iter [00680, 01251], lr: 0.000975, loss: 0.3981
2022-09-29 16:33:48 - train: epoch 0143, iter [00690, 01251], lr: 0.000975, loss: 0.3963
2022-09-29 16:34:06 - train: epoch 0143, iter [00700, 01251], lr: 0.000975, loss: 0.3998
2022-09-29 16:34:23 - train: epoch 0143, iter [00710, 01251], lr: 0.000975, loss: 0.4318
2022-09-29 16:34:41 - train: epoch 0143, iter [00720, 01251], lr: 0.000975, loss: 0.4196
2022-09-29 16:34:59 - train: epoch 0143, iter [00730, 01251], lr: 0.000975, loss: 0.4015
2022-09-29 16:35:16 - train: epoch 0143, iter [00740, 01251], lr: 0.000975, loss: 0.4109
2022-09-29 16:35:34 - train: epoch 0143, iter [00750, 01251], lr: 0.000975, loss: 0.3988
2022-09-29 16:35:52 - train: epoch 0143, iter [00760, 01251], lr: 0.000975, loss: 0.4068
2022-09-29 16:36:09 - train: epoch 0143, iter [00770, 01251], lr: 0.000975, loss: 0.4245
2022-09-29 16:36:27 - train: epoch 0143, iter [00780, 01251], lr: 0.000975, loss: 0.4022
2022-09-29 16:36:45 - train: epoch 0143, iter [00790, 01251], lr: 0.000975, loss: 0.4305
2022-09-29 16:37:02 - train: epoch 0143, iter [00800, 01251], lr: 0.000975, loss: 0.3970
2022-09-29 16:37:20 - train: epoch 0143, iter [00810, 01251], lr: 0.000975, loss: 0.3962
2022-09-29 16:37:38 - train: epoch 0143, iter [00820, 01251], lr: 0.000975, loss: 0.3995
2022-09-29 16:37:55 - train: epoch 0143, iter [00830, 01251], lr: 0.000975, loss: 0.4153
2022-09-29 16:38:13 - train: epoch 0143, iter [00840, 01251], lr: 0.000975, loss: 0.4135
2022-09-29 16:38:31 - train: epoch 0143, iter [00850, 01251], lr: 0.000975, loss: 0.3922
2022-09-29 16:38:48 - train: epoch 0143, iter [00860, 01251], lr: 0.000975, loss: 0.4247
2022-09-29 16:39:06 - train: epoch 0143, iter [00870, 01251], lr: 0.000975, loss: 0.4127
2022-09-29 16:39:24 - train: epoch 0143, iter [00880, 01251], lr: 0.000975, loss: 0.4210
2022-09-29 16:39:42 - train: epoch 0143, iter [00890, 01251], lr: 0.000975, loss: 0.4001
2022-09-29 16:39:59 - train: epoch 0143, iter [00900, 01251], lr: 0.000975, loss: 0.3857
2022-09-29 16:40:17 - train: epoch 0143, iter [00910, 01251], lr: 0.000975, loss: 0.4015
2022-09-29 16:40:35 - train: epoch 0143, iter [00920, 01251], lr: 0.000975, loss: 0.4155
2022-09-29 16:40:52 - train: epoch 0143, iter [00930, 01251], lr: 0.000975, loss: 0.4038
2022-09-29 16:41:10 - train: epoch 0143, iter [00940, 01251], lr: 0.000975, loss: 0.4084
2022-09-29 16:41:28 - train: epoch 0143, iter [00950, 01251], lr: 0.000974, loss: 0.4127
2022-09-29 16:41:45 - train: epoch 0143, iter [00960, 01251], lr: 0.000974, loss: 0.3994
2022-09-29 16:42:03 - train: epoch 0143, iter [00970, 01251], lr: 0.000974, loss: 0.4167
2022-09-29 16:42:21 - train: epoch 0143, iter [00980, 01251], lr: 0.000974, loss: 0.4140
2022-09-29 16:42:38 - train: epoch 0143, iter [00990, 01251], lr: 0.000974, loss: 0.4069
2022-09-29 16:42:56 - train: epoch 0143, iter [01000, 01251], lr: 0.000974, loss: 0.3868
2022-09-29 16:43:14 - train: epoch 0143, iter [01010, 01251], lr: 0.000974, loss: 0.4012
2022-09-29 16:43:31 - train: epoch 0143, iter [01020, 01251], lr: 0.000974, loss: 0.4229
2022-09-29 16:43:49 - train: epoch 0143, iter [01030, 01251], lr: 0.000974, loss: 0.4175
2022-09-29 16:44:07 - train: epoch 0143, iter [01040, 01251], lr: 0.000974, loss: 0.4091
2022-09-29 16:44:25 - train: epoch 0143, iter [01050, 01251], lr: 0.000974, loss: 0.4092
2022-09-29 16:44:42 - train: epoch 0143, iter [01060, 01251], lr: 0.000974, loss: 0.4075
2022-09-29 16:45:00 - train: epoch 0143, iter [01070, 01251], lr: 0.000974, loss: 0.4320
2022-09-29 16:45:18 - train: epoch 0143, iter [01080, 01251], lr: 0.000974, loss: 0.3941
2022-09-29 16:45:35 - train: epoch 0143, iter [01090, 01251], lr: 0.000974, loss: 0.3981
2022-09-29 16:45:53 - train: epoch 0143, iter [01100, 01251], lr: 0.000974, loss: 0.4198
2022-09-29 16:46:11 - train: epoch 0143, iter [01110, 01251], lr: 0.000974, loss: 0.3998
2022-09-29 16:46:28 - train: epoch 0143, iter [01120, 01251], lr: 0.000974, loss: 0.4059
2022-09-29 16:46:46 - train: epoch 0143, iter [01130, 01251], lr: 0.000974, loss: 0.4099
2022-09-29 16:47:04 - train: epoch 0143, iter [01140, 01251], lr: 0.000974, loss: 0.4011
2022-09-29 16:47:21 - train: epoch 0143, iter [01150, 01251], lr: 0.000974, loss: 0.4076
2022-09-29 16:47:39 - train: epoch 0143, iter [01160, 01251], lr: 0.000974, loss: 0.4138
2022-09-29 16:47:57 - train: epoch 0143, iter [01170, 01251], lr: 0.000974, loss: 0.3971
2022-09-29 16:48:15 - train: epoch 0143, iter [01180, 01251], lr: 0.000974, loss: 0.3959
2022-09-29 16:48:32 - train: epoch 0143, iter [01190, 01251], lr: 0.000974, loss: 0.3914
2022-09-29 16:48:50 - train: epoch 0143, iter [01200, 01251], lr: 0.000974, loss: 0.4171
2022-09-29 16:49:08 - train: epoch 0143, iter [01210, 01251], lr: 0.000974, loss: 0.4083
2022-09-29 16:49:26 - train: epoch 0143, iter [01220, 01251], lr: 0.000974, loss: 0.4193
2022-09-29 16:49:43 - train: epoch 0143, iter [01230, 01251], lr: 0.000974, loss: 0.4121
2022-09-29 16:50:01 - train: epoch 0143, iter [01240, 01251], lr: 0.000974, loss: 0.4102
2022-09-29 16:50:18 - train: epoch 0143, iter [01250, 01251], lr: 0.000974, loss: 0.4076
2022-09-29 16:50:22 - train: epoch 143, train_loss: 0.4107
2022-09-29 16:50:24 - until epoch: 143, best_loss: 0.4107
2022-09-29 16:50:24 - epoch 144 lr: 0.000974
2022-09-29 16:50:56 - train: epoch 0144, iter [00010, 01251], lr: 0.000973, loss: 0.3949
2022-09-29 16:51:14 - train: epoch 0144, iter [00020, 01251], lr: 0.000973, loss: 0.4096
2022-09-29 16:51:32 - train: epoch 0144, iter [00030, 01251], lr: 0.000973, loss: 0.3975
2022-09-29 16:51:50 - train: epoch 0144, iter [00040, 01251], lr: 0.000973, loss: 0.4023
2022-09-29 16:52:07 - train: epoch 0144, iter [00050, 01251], lr: 0.000973, loss: 0.4223
2022-09-29 16:52:25 - train: epoch 0144, iter [00060, 01251], lr: 0.000973, loss: 0.4067
2022-09-29 16:52:43 - train: epoch 0144, iter [00070, 01251], lr: 0.000973, loss: 0.4219
2022-09-29 16:53:01 - train: epoch 0144, iter [00080, 01251], lr: 0.000973, loss: 0.4022
2022-09-29 16:53:19 - train: epoch 0144, iter [00090, 01251], lr: 0.000973, loss: 0.3959
2022-09-29 16:53:36 - train: epoch 0144, iter [00100, 01251], lr: 0.000973, loss: 0.4036
2022-09-29 16:53:54 - train: epoch 0144, iter [00110, 01251], lr: 0.000973, loss: 0.3992
2022-09-29 16:54:12 - train: epoch 0144, iter [00120, 01251], lr: 0.000973, loss: 0.4199
2022-09-29 16:54:29 - train: epoch 0144, iter [00130, 01251], lr: 0.000973, loss: 0.4028
2022-09-29 16:54:47 - train: epoch 0144, iter [00140, 01251], lr: 0.000973, loss: 0.4121
2022-09-29 16:55:05 - train: epoch 0144, iter [00150, 01251], lr: 0.000973, loss: 0.4096
2022-09-29 16:55:23 - train: epoch 0144, iter [00160, 01251], lr: 0.000973, loss: 0.4219
2022-09-29 16:55:41 - train: epoch 0144, iter [00170, 01251], lr: 0.000973, loss: 0.4170
2022-09-29 16:55:59 - train: epoch 0144, iter [00180, 01251], lr: 0.000973, loss: 0.3909
2022-09-29 16:56:16 - train: epoch 0144, iter [00190, 01251], lr: 0.000973, loss: 0.4348
2022-09-29 16:56:34 - train: epoch 0144, iter [00200, 01251], lr: 0.000973, loss: 0.4144
2022-09-29 16:56:52 - train: epoch 0144, iter [00210, 01251], lr: 0.000973, loss: 0.4121
2022-09-29 16:57:09 - train: epoch 0144, iter [00220, 01251], lr: 0.000973, loss: 0.4097
2022-09-29 16:57:27 - train: epoch 0144, iter [00230, 01251], lr: 0.000973, loss: 0.4089
2022-09-29 16:57:45 - train: epoch 0144, iter [00240, 01251], lr: 0.000973, loss: 0.4085
2022-09-29 16:58:02 - train: epoch 0144, iter [00250, 01251], lr: 0.000973, loss: 0.3812
2022-09-29 16:58:20 - train: epoch 0144, iter [00260, 01251], lr: 0.000973, loss: 0.4199
2022-09-29 16:58:38 - train: epoch 0144, iter [00270, 01251], lr: 0.000973, loss: 0.3942
2022-09-29 16:58:56 - train: epoch 0144, iter [00280, 01251], lr: 0.000973, loss: 0.4171
2022-09-29 16:59:14 - train: epoch 0144, iter [00290, 01251], lr: 0.000973, loss: 0.4036
2022-09-29 16:59:31 - train: epoch 0144, iter [00300, 01251], lr: 0.000973, loss: 0.3991
2022-09-29 16:59:49 - train: epoch 0144, iter [00310, 01251], lr: 0.000972, loss: 0.4174
2022-09-29 17:00:07 - train: epoch 0144, iter [00320, 01251], lr: 0.000972, loss: 0.4123
2022-09-29 17:00:24 - train: epoch 0144, iter [00330, 01251], lr: 0.000972, loss: 0.4005
2022-09-29 17:00:42 - train: epoch 0144, iter [00340, 01251], lr: 0.000972, loss: 0.4108
2022-09-29 17:01:00 - train: epoch 0144, iter [00350, 01251], lr: 0.000972, loss: 0.4178
2022-09-29 17:01:18 - train: epoch 0144, iter [00360, 01251], lr: 0.000972, loss: 0.4153
2022-09-29 17:01:35 - train: epoch 0144, iter [00370, 01251], lr: 0.000972, loss: 0.4219
2022-09-29 17:01:53 - train: epoch 0144, iter [00380, 01251], lr: 0.000972, loss: 0.4137
2022-09-29 17:02:11 - train: epoch 0144, iter [00390, 01251], lr: 0.000972, loss: 0.3887
2022-09-29 17:02:28 - train: epoch 0144, iter [00400, 01251], lr: 0.000972, loss: 0.3924
2022-09-29 17:02:46 - train: epoch 0144, iter [00410, 01251], lr: 0.000972, loss: 0.4124
2022-09-29 17:03:04 - train: epoch 0144, iter [00420, 01251], lr: 0.000972, loss: 0.4061
2022-09-29 17:03:21 - train: epoch 0144, iter [00430, 01251], lr: 0.000972, loss: 0.4147
2022-09-29 17:03:39 - train: epoch 0144, iter [00440, 01251], lr: 0.000972, loss: 0.4019
2022-09-29 17:03:57 - train: epoch 0144, iter [00450, 01251], lr: 0.000972, loss: 0.3841
2022-09-29 17:04:15 - train: epoch 0144, iter [00460, 01251], lr: 0.000972, loss: 0.4109
2022-09-29 17:04:32 - train: epoch 0144, iter [00470, 01251], lr: 0.000972, loss: 0.4044
2022-09-29 17:04:50 - train: epoch 0144, iter [00480, 01251], lr: 0.000972, loss: 0.4027
2022-09-29 17:05:08 - train: epoch 0144, iter [00490, 01251], lr: 0.000972, loss: 0.4124
2022-09-29 17:05:26 - train: epoch 0144, iter [00500, 01251], lr: 0.000972, loss: 0.3932
2022-09-29 17:05:44 - train: epoch 0144, iter [00510, 01251], lr: 0.000972, loss: 0.4163
2022-09-29 17:06:01 - train: epoch 0144, iter [00520, 01251], lr: 0.000972, loss: 0.4273
2022-09-29 17:06:19 - train: epoch 0144, iter [00530, 01251], lr: 0.000972, loss: 0.4319
2022-09-29 17:06:37 - train: epoch 0144, iter [00540, 01251], lr: 0.000972, loss: 0.4228
2022-09-29 17:06:54 - train: epoch 0144, iter [00550, 01251], lr: 0.000972, loss: 0.4171
2022-09-29 17:07:12 - train: epoch 0144, iter [00560, 01251], lr: 0.000972, loss: 0.4049
2022-09-29 17:07:30 - train: epoch 0144, iter [00570, 01251], lr: 0.000972, loss: 0.4089
2022-09-29 17:07:48 - train: epoch 0144, iter [00580, 01251], lr: 0.000972, loss: 0.3900
2022-09-29 17:08:05 - train: epoch 0144, iter [00590, 01251], lr: 0.000972, loss: 0.4039
2022-09-29 17:08:23 - train: epoch 0144, iter [00600, 01251], lr: 0.000972, loss: 0.3873
2022-09-29 17:08:41 - train: epoch 0144, iter [00610, 01251], lr: 0.000972, loss: 0.3965
2022-09-29 17:08:59 - train: epoch 0144, iter [00620, 01251], lr: 0.000971, loss: 0.4008
2022-09-29 17:09:16 - train: epoch 0144, iter [00630, 01251], lr: 0.000971, loss: 0.4170
2022-09-29 17:09:34 - train: epoch 0144, iter [00640, 01251], lr: 0.000971, loss: 0.4267
2022-09-29 17:09:52 - train: epoch 0144, iter [00650, 01251], lr: 0.000971, loss: 0.4013
2022-09-29 17:10:09 - train: epoch 0144, iter [00660, 01251], lr: 0.000971, loss: 0.4131
2022-09-29 17:10:27 - train: epoch 0144, iter [00670, 01251], lr: 0.000971, loss: 0.4043
2022-09-29 17:10:45 - train: epoch 0144, iter [00680, 01251], lr: 0.000971, loss: 0.4073
2022-09-29 17:11:03 - train: epoch 0144, iter [00690, 01251], lr: 0.000971, loss: 0.4063
2022-09-29 17:11:20 - train: epoch 0144, iter [00700, 01251], lr: 0.000971, loss: 0.3907
2022-09-29 17:11:38 - train: epoch 0144, iter [00710, 01251], lr: 0.000971, loss: 0.3879
2022-09-29 17:11:56 - train: epoch 0144, iter [00720, 01251], lr: 0.000971, loss: 0.4146
2022-09-29 17:12:14 - train: epoch 0144, iter [00730, 01251], lr: 0.000971, loss: 0.4028
2022-09-29 17:12:32 - train: epoch 0144, iter [00740, 01251], lr: 0.000971, loss: 0.4204
2022-09-29 17:12:49 - train: epoch 0144, iter [00750, 01251], lr: 0.000971, loss: 0.4112
2022-09-29 17:13:07 - train: epoch 0144, iter [00760, 01251], lr: 0.000971, loss: 0.3965
2022-09-29 17:13:25 - train: epoch 0144, iter [00770, 01251], lr: 0.000971, loss: 0.4128
2022-09-29 17:13:42 - train: epoch 0144, iter [00780, 01251], lr: 0.000971, loss: 0.4034
2022-09-29 17:14:00 - train: epoch 0144, iter [00790, 01251], lr: 0.000971, loss: 0.4130
2022-09-29 17:14:18 - train: epoch 0144, iter [00800, 01251], lr: 0.000971, loss: 0.4059
2022-09-29 17:14:35 - train: epoch 0144, iter [00810, 01251], lr: 0.000971, loss: 0.4056
2022-09-29 17:14:53 - train: epoch 0144, iter [00820, 01251], lr: 0.000971, loss: 0.4106
2022-09-29 17:15:11 - train: epoch 0144, iter [00830, 01251], lr: 0.000971, loss: 0.4055
2022-09-29 17:15:29 - train: epoch 0144, iter [00840, 01251], lr: 0.000971, loss: 0.3997
2022-09-29 17:15:46 - train: epoch 0144, iter [00850, 01251], lr: 0.000971, loss: 0.4028
2022-09-29 17:16:04 - train: epoch 0144, iter [00860, 01251], lr: 0.000971, loss: 0.3917
2022-09-29 17:16:22 - train: epoch 0144, iter [00870, 01251], lr: 0.000971, loss: 0.3876
2022-09-29 17:16:39 - train: epoch 0144, iter [00880, 01251], lr: 0.000971, loss: 0.4145
2022-09-29 17:16:57 - train: epoch 0144, iter [00890, 01251], lr: 0.000971, loss: 0.3981
2022-09-29 17:17:15 - train: epoch 0144, iter [00900, 01251], lr: 0.000971, loss: 0.4098
2022-09-29 17:17:32 - train: epoch 0144, iter [00910, 01251], lr: 0.000971, loss: 0.4206
2022-09-29 17:17:50 - train: epoch 0144, iter [00920, 01251], lr: 0.000970, loss: 0.4175
2022-09-29 17:18:08 - train: epoch 0144, iter [00930, 01251], lr: 0.000970, loss: 0.4000
2022-09-29 17:18:26 - train: epoch 0144, iter [00940, 01251], lr: 0.000970, loss: 0.4057
2022-09-29 17:18:43 - train: epoch 0144, iter [00950, 01251], lr: 0.000970, loss: 0.4011
2022-09-29 17:19:01 - train: epoch 0144, iter [00960, 01251], lr: 0.000970, loss: 0.4103
2022-09-29 17:19:19 - train: epoch 0144, iter [00970, 01251], lr: 0.000970, loss: 0.3940
2022-09-29 17:19:37 - train: epoch 0144, iter [00980, 01251], lr: 0.000970, loss: 0.4075
2022-09-29 17:19:54 - train: epoch 0144, iter [00990, 01251], lr: 0.000970, loss: 0.4046
2022-09-29 17:20:12 - train: epoch 0144, iter [01000, 01251], lr: 0.000970, loss: 0.4063
2022-09-29 17:20:30 - train: epoch 0144, iter [01010, 01251], lr: 0.000970, loss: 0.4171
2022-09-29 17:20:47 - train: epoch 0144, iter [01020, 01251], lr: 0.000970, loss: 0.4127
2022-09-29 17:21:05 - train: epoch 0144, iter [01030, 01251], lr: 0.000970, loss: 0.4431
2022-09-29 17:21:23 - train: epoch 0144, iter [01040, 01251], lr: 0.000970, loss: 0.4317
2022-09-29 17:21:41 - train: epoch 0144, iter [01050, 01251], lr: 0.000970, loss: 0.4236
2022-09-29 17:21:58 - train: epoch 0144, iter [01060, 01251], lr: 0.000970, loss: 0.4011
2022-09-29 17:22:16 - train: epoch 0144, iter [01070, 01251], lr: 0.000970, loss: 0.3924
2022-09-29 17:22:34 - train: epoch 0144, iter [01080, 01251], lr: 0.000970, loss: 0.4186
2022-09-29 17:22:51 - train: epoch 0144, iter [01090, 01251], lr: 0.000970, loss: 0.4153
2022-09-29 17:23:09 - train: epoch 0144, iter [01100, 01251], lr: 0.000970, loss: 0.4117
2022-09-29 17:23:27 - train: epoch 0144, iter [01110, 01251], lr: 0.000970, loss: 0.4043
2022-09-29 17:23:45 - train: epoch 0144, iter [01120, 01251], lr: 0.000970, loss: 0.4109
2022-09-29 17:24:02 - train: epoch 0144, iter [01130, 01251], lr: 0.000970, loss: 0.4195
2022-09-29 17:24:20 - train: epoch 0144, iter [01140, 01251], lr: 0.000970, loss: 0.4160
2022-09-29 17:24:38 - train: epoch 0144, iter [01150, 01251], lr: 0.000970, loss: 0.4186
2022-09-29 17:24:56 - train: epoch 0144, iter [01160, 01251], lr: 0.000970, loss: 0.4072
2022-09-29 17:25:13 - train: epoch 0144, iter [01170, 01251], lr: 0.000970, loss: 0.4353
2022-09-29 17:25:31 - train: epoch 0144, iter [01180, 01251], lr: 0.000970, loss: 0.4310
2022-09-29 17:25:49 - train: epoch 0144, iter [01190, 01251], lr: 0.000970, loss: 0.4215
2022-09-29 17:26:06 - train: epoch 0144, iter [01200, 01251], lr: 0.000970, loss: 0.3988
2022-09-29 17:26:24 - train: epoch 0144, iter [01210, 01251], lr: 0.000970, loss: 0.4200
2022-09-29 17:26:42 - train: epoch 0144, iter [01220, 01251], lr: 0.000969, loss: 0.4182
2022-09-29 17:26:59 - train: epoch 0144, iter [01230, 01251], lr: 0.000969, loss: 0.4110
2022-09-29 17:27:17 - train: epoch 0144, iter [01240, 01251], lr: 0.000969, loss: 0.3807
2022-09-29 17:27:34 - train: epoch 0144, iter [01250, 01251], lr: 0.000969, loss: 0.4030
2022-09-29 17:27:38 - train: epoch 144, train_loss: 0.4107
2022-09-29 17:27:41 - until epoch: 144, best_loss: 0.4107
2022-09-29 17:27:41 - epoch 145 lr: 0.000969
2022-09-29 17:28:14 - train: epoch 0145, iter [00010, 01251], lr: 0.000969, loss: 0.3959
2022-09-29 17:28:32 - train: epoch 0145, iter [00020, 01251], lr: 0.000969, loss: 0.4050
2022-09-29 17:28:50 - train: epoch 0145, iter [00030, 01251], lr: 0.000969, loss: 0.4008
2022-09-29 17:29:07 - train: epoch 0145, iter [00040, 01251], lr: 0.000969, loss: 0.4235
2022-09-29 17:29:25 - train: epoch 0145, iter [00050, 01251], lr: 0.000969, loss: 0.3864
2022-09-29 17:29:43 - train: epoch 0145, iter [00060, 01251], lr: 0.000969, loss: 0.4163
2022-09-29 17:30:01 - train: epoch 0145, iter [00070, 01251], lr: 0.000969, loss: 0.4176
2022-09-29 17:30:18 - train: epoch 0145, iter [00080, 01251], lr: 0.000969, loss: 0.4114
2022-09-29 17:30:36 - train: epoch 0145, iter [00090, 01251], lr: 0.000969, loss: 0.4144
2022-09-29 17:30:54 - train: epoch 0145, iter [00100, 01251], lr: 0.000969, loss: 0.3963
2022-09-29 17:31:12 - train: epoch 0145, iter [00110, 01251], lr: 0.000969, loss: 0.4028
2022-09-29 17:31:30 - train: epoch 0145, iter [00120, 01251], lr: 0.000969, loss: 0.4086
2022-09-29 17:31:47 - train: epoch 0145, iter [00130, 01251], lr: 0.000969, loss: 0.4011
2022-09-29 17:32:05 - train: epoch 0145, iter [00140, 01251], lr: 0.000969, loss: 0.4192
2022-09-29 17:32:23 - train: epoch 0145, iter [00150, 01251], lr: 0.000969, loss: 0.4225
2022-09-29 17:32:41 - train: epoch 0145, iter [00160, 01251], lr: 0.000969, loss: 0.4101
2022-09-29 17:32:59 - train: epoch 0145, iter [00170, 01251], lr: 0.000969, loss: 0.4150
2022-09-29 17:33:17 - train: epoch 0145, iter [00180, 01251], lr: 0.000969, loss: 0.4145
2022-09-29 17:33:34 - train: epoch 0145, iter [00190, 01251], lr: 0.000969, loss: 0.3966
2022-09-29 17:33:52 - train: epoch 0145, iter [00200, 01251], lr: 0.000969, loss: 0.4313
2022-09-29 17:34:10 - train: epoch 0145, iter [00210, 01251], lr: 0.000969, loss: 0.4163
2022-09-29 17:34:28 - train: epoch 0145, iter [00220, 01251], lr: 0.000969, loss: 0.4133
2022-09-29 17:34:45 - train: epoch 0145, iter [00230, 01251], lr: 0.000969, loss: 0.3986
2022-09-29 17:35:03 - train: epoch 0145, iter [00240, 01251], lr: 0.000969, loss: 0.4093
2022-09-29 17:35:21 - train: epoch 0145, iter [00250, 01251], lr: 0.000969, loss: 0.4214
2022-09-29 17:35:39 - train: epoch 0145, iter [00260, 01251], lr: 0.000969, loss: 0.4090
2022-09-29 17:35:56 - train: epoch 0145, iter [00270, 01251], lr: 0.000969, loss: 0.4105
2022-09-29 17:36:14 - train: epoch 0145, iter [00280, 01251], lr: 0.000968, loss: 0.3930
2022-09-29 17:36:31 - train: epoch 0145, iter [00290, 01251], lr: 0.000968, loss: 0.4206
2022-09-29 17:36:49 - train: epoch 0145, iter [00300, 01251], lr: 0.000968, loss: 0.4211
2022-09-29 17:37:07 - train: epoch 0145, iter [00310, 01251], lr: 0.000968, loss: 0.4059
2022-09-29 17:37:24 - train: epoch 0145, iter [00320, 01251], lr: 0.000968, loss: 0.4212
2022-09-29 17:37:42 - train: epoch 0145, iter [00330, 01251], lr: 0.000968, loss: 0.4016
2022-09-29 17:38:00 - train: epoch 0145, iter [00340, 01251], lr: 0.000968, loss: 0.4095
2022-09-29 17:38:18 - train: epoch 0145, iter [00350, 01251], lr: 0.000968, loss: 0.4239
2022-09-29 17:38:35 - train: epoch 0145, iter [00360, 01251], lr: 0.000968, loss: 0.4092
2022-09-29 17:38:53 - train: epoch 0145, iter [00370, 01251], lr: 0.000968, loss: 0.4042
2022-09-29 17:39:11 - train: epoch 0145, iter [00380, 01251], lr: 0.000968, loss: 0.4268
2022-09-29 17:39:28 - train: epoch 0145, iter [00390, 01251], lr: 0.000968, loss: 0.4008
2022-09-29 17:39:46 - train: epoch 0145, iter [00400, 01251], lr: 0.000968, loss: 0.4017
2022-09-29 17:40:04 - train: epoch 0145, iter [00410, 01251], lr: 0.000968, loss: 0.4108
2022-09-29 17:40:21 - train: epoch 0145, iter [00420, 01251], lr: 0.000968, loss: 0.3957
2022-09-29 17:40:39 - train: epoch 0145, iter [00430, 01251], lr: 0.000968, loss: 0.4222
2022-09-29 17:40:57 - train: epoch 0145, iter [00440, 01251], lr: 0.000968, loss: 0.4074
2022-09-29 17:41:15 - train: epoch 0145, iter [00450, 01251], lr: 0.000968, loss: 0.4165
2022-09-29 17:41:32 - train: epoch 0145, iter [00460, 01251], lr: 0.000968, loss: 0.4097
2022-09-29 17:41:50 - train: epoch 0145, iter [00470, 01251], lr: 0.000968, loss: 0.4046
2022-09-29 17:42:08 - train: epoch 0145, iter [00480, 01251], lr: 0.000968, loss: 0.4037
2022-09-29 17:42:26 - train: epoch 0145, iter [00490, 01251], lr: 0.000968, loss: 0.4154
2022-09-29 17:42:43 - train: epoch 0145, iter [00500, 01251], lr: 0.000968, loss: 0.4098
2022-09-29 17:43:01 - train: epoch 0145, iter [00510, 01251], lr: 0.000968, loss: 0.4172
2022-09-29 17:43:18 - train: epoch 0145, iter [00520, 01251], lr: 0.000968, loss: 0.3818
2022-09-29 17:43:36 - train: epoch 0145, iter [00530, 01251], lr: 0.000968, loss: 0.4051
2022-09-29 17:43:54 - train: epoch 0145, iter [00540, 01251], lr: 0.000968, loss: 0.4434
2022-09-29 17:44:11 - train: epoch 0145, iter [00550, 01251], lr: 0.000968, loss: 0.4039
2022-09-29 17:44:29 - train: epoch 0145, iter [00560, 01251], lr: 0.000968, loss: 0.4005
2022-09-29 17:44:47 - train: epoch 0145, iter [00570, 01251], lr: 0.000968, loss: 0.4056
2022-09-29 17:45:04 - train: epoch 0145, iter [00580, 01251], lr: 0.000967, loss: 0.4034
2022-09-29 17:45:22 - train: epoch 0145, iter [00590, 01251], lr: 0.000967, loss: 0.3998
2022-09-29 17:45:40 - train: epoch 0145, iter [00600, 01251], lr: 0.000967, loss: 0.3937
2022-09-29 17:45:57 - train: epoch 0145, iter [00610, 01251], lr: 0.000967, loss: 0.3988
2022-09-29 17:46:15 - train: epoch 0145, iter [00620, 01251], lr: 0.000967, loss: 0.4049
2022-09-29 17:46:33 - train: epoch 0145, iter [00630, 01251], lr: 0.000967, loss: 0.4280
2022-09-29 17:46:51 - train: epoch 0145, iter [00640, 01251], lr: 0.000967, loss: 0.4191
2022-09-29 17:47:08 - train: epoch 0145, iter [00650, 01251], lr: 0.000967, loss: 0.4190
2022-09-29 17:47:26 - train: epoch 0145, iter [00660, 01251], lr: 0.000967, loss: 0.4223
2022-09-29 17:47:44 - train: epoch 0145, iter [00670, 01251], lr: 0.000967, loss: 0.4252
2022-09-29 17:48:01 - train: epoch 0145, iter [00680, 01251], lr: 0.000967, loss: 0.4069
2022-09-29 17:48:19 - train: epoch 0145, iter [00690, 01251], lr: 0.000967, loss: 0.4156
2022-09-29 17:48:37 - train: epoch 0145, iter [00700, 01251], lr: 0.000967, loss: 0.4109
2022-09-29 17:48:54 - train: epoch 0145, iter [00710, 01251], lr: 0.000967, loss: 0.4136
2022-09-29 17:49:12 - train: epoch 0145, iter [00720, 01251], lr: 0.000967, loss: 0.4220
2022-09-29 17:49:30 - train: epoch 0145, iter [00730, 01251], lr: 0.000967, loss: 0.4059
2022-09-29 17:49:48 - train: epoch 0145, iter [00740, 01251], lr: 0.000967, loss: 0.4063
2022-09-29 17:50:05 - train: epoch 0145, iter [00750, 01251], lr: 0.000967, loss: 0.3985
2022-09-29 17:50:23 - train: epoch 0145, iter [00760, 01251], lr: 0.000967, loss: 0.3974
2022-09-29 17:50:41 - train: epoch 0145, iter [00770, 01251], lr: 0.000967, loss: 0.4104
2022-09-29 17:50:58 - train: epoch 0145, iter [00780, 01251], lr: 0.000967, loss: 0.4157
2022-09-29 17:51:16 - train: epoch 0145, iter [00790, 01251], lr: 0.000967, loss: 0.4094
2022-09-29 17:51:34 - train: epoch 0145, iter [00800, 01251], lr: 0.000967, loss: 0.4238
2022-09-29 17:51:52 - train: epoch 0145, iter [00810, 01251], lr: 0.000967, loss: 0.4127
2022-09-29 17:52:09 - train: epoch 0145, iter [00820, 01251], lr: 0.000967, loss: 0.4087
2022-09-29 17:52:27 - train: epoch 0145, iter [00830, 01251], lr: 0.000967, loss: 0.4236
2022-09-29 17:52:44 - train: epoch 0145, iter [00840, 01251], lr: 0.000967, loss: 0.4085
2022-09-29 17:53:02 - train: epoch 0145, iter [00850, 01251], lr: 0.000967, loss: 0.4207
2022-09-29 17:53:20 - train: epoch 0145, iter [00860, 01251], lr: 0.000967, loss: 0.4151
2022-09-29 17:53:38 - train: epoch 0145, iter [00870, 01251], lr: 0.000967, loss: 0.4304
2022-09-29 17:53:56 - train: epoch 0145, iter [00880, 01251], lr: 0.000966, loss: 0.3953
2022-09-29 17:54:13 - train: epoch 0145, iter [00890, 01251], lr: 0.000966, loss: 0.3939
2022-09-29 17:54:31 - train: epoch 0145, iter [00900, 01251], lr: 0.000966, loss: 0.3996
2022-09-29 17:54:49 - train: epoch 0145, iter [00910, 01251], lr: 0.000966, loss: 0.4169
2022-09-29 17:55:06 - train: epoch 0145, iter [00920, 01251], lr: 0.000966, loss: 0.3971
2022-09-29 17:55:24 - train: epoch 0145, iter [00930, 01251], lr: 0.000966, loss: 0.4106
2022-09-29 17:55:41 - train: epoch 0145, iter [00940, 01251], lr: 0.000966, loss: 0.3958
2022-09-29 17:55:59 - train: epoch 0145, iter [00950, 01251], lr: 0.000966, loss: 0.4067
2022-09-29 17:56:17 - train: epoch 0145, iter [00960, 01251], lr: 0.000966, loss: 0.4298
2022-09-29 17:56:35 - train: epoch 0145, iter [00970, 01251], lr: 0.000966, loss: 0.4375
2022-09-29 17:56:52 - train: epoch 0145, iter [00980, 01251], lr: 0.000966, loss: 0.4011
2022-09-29 17:57:10 - train: epoch 0145, iter [00990, 01251], lr: 0.000966, loss: 0.4023
2022-09-29 17:57:28 - train: epoch 0145, iter [01000, 01251], lr: 0.000966, loss: 0.4356
2022-09-29 17:57:45 - train: epoch 0145, iter [01010, 01251], lr: 0.000966, loss: 0.4264
2022-09-29 17:58:03 - train: epoch 0145, iter [01020, 01251], lr: 0.000966, loss: 0.4219
2022-09-29 17:58:21 - train: epoch 0145, iter [01030, 01251], lr: 0.000966, loss: 0.4036
2022-09-29 17:58:38 - train: epoch 0145, iter [01040, 01251], lr: 0.000966, loss: 0.4149
2022-09-29 17:58:56 - train: epoch 0145, iter [01050, 01251], lr: 0.000966, loss: 0.3968
2022-09-29 17:59:14 - train: epoch 0145, iter [01060, 01251], lr: 0.000966, loss: 0.4163
2022-09-29 17:59:31 - train: epoch 0145, iter [01070, 01251], lr: 0.000966, loss: 0.4118
2022-09-29 17:59:49 - train: epoch 0145, iter [01080, 01251], lr: 0.000966, loss: 0.4062
2022-09-29 18:00:07 - train: epoch 0145, iter [01090, 01251], lr: 0.000966, loss: 0.3920
2022-09-29 18:00:25 - train: epoch 0145, iter [01100, 01251], lr: 0.000966, loss: 0.3873
2022-09-29 18:00:42 - train: epoch 0145, iter [01110, 01251], lr: 0.000966, loss: 0.4113
2022-09-29 18:01:00 - train: epoch 0145, iter [01120, 01251], lr: 0.000966, loss: 0.4098
2022-09-29 18:01:18 - train: epoch 0145, iter [01130, 01251], lr: 0.000966, loss: 0.4068
2022-09-29 18:01:36 - train: epoch 0145, iter [01140, 01251], lr: 0.000966, loss: 0.4130
2022-09-29 18:01:53 - train: epoch 0145, iter [01150, 01251], lr: 0.000966, loss: 0.4237
2022-09-29 18:02:11 - train: epoch 0145, iter [01160, 01251], lr: 0.000966, loss: 0.4102
2022-09-29 18:02:29 - train: epoch 0145, iter [01170, 01251], lr: 0.000966, loss: 0.3967
2022-09-29 18:02:46 - train: epoch 0145, iter [01180, 01251], lr: 0.000965, loss: 0.4226
2022-09-29 18:03:04 - train: epoch 0145, iter [01190, 01251], lr: 0.000965, loss: 0.4265
2022-09-29 18:03:22 - train: epoch 0145, iter [01200, 01251], lr: 0.000965, loss: 0.4257
2022-09-29 18:03:39 - train: epoch 0145, iter [01210, 01251], lr: 0.000965, loss: 0.4033
2022-09-29 18:03:57 - train: epoch 0145, iter [01220, 01251], lr: 0.000965, loss: 0.4085
2022-09-29 18:04:15 - train: epoch 0145, iter [01230, 01251], lr: 0.000965, loss: 0.4064
2022-09-29 18:04:33 - train: epoch 0145, iter [01240, 01251], lr: 0.000965, loss: 0.4051
2022-09-29 18:04:50 - train: epoch 0145, iter [01250, 01251], lr: 0.000965, loss: 0.4135
2022-09-29 18:04:54 - train: epoch 145, train_loss: 0.4107
2022-09-29 18:04:55 - until epoch: 145, best_loss: 0.4107
2022-09-29 18:04:55 - epoch 146 lr: 0.000965
2022-09-29 18:05:28 - train: epoch 0146, iter [00010, 01251], lr: 0.000965, loss: 0.4155
2022-09-29 18:05:46 - train: epoch 0146, iter [00020, 01251], lr: 0.000965, loss: 0.3954
2022-09-29 18:06:03 - train: epoch 0146, iter [00030, 01251], lr: 0.000965, loss: 0.4228
2022-09-29 18:06:21 - train: epoch 0146, iter [00040, 01251], lr: 0.000965, loss: 0.4093
2022-09-29 18:06:39 - train: epoch 0146, iter [00050, 01251], lr: 0.000965, loss: 0.4019
2022-09-29 18:06:57 - train: epoch 0146, iter [00060, 01251], lr: 0.000965, loss: 0.4410
2022-09-29 18:07:14 - train: epoch 0146, iter [00070, 01251], lr: 0.000965, loss: 0.4102
2022-09-29 18:07:32 - train: epoch 0146, iter [00080, 01251], lr: 0.000965, loss: 0.4360
2022-09-29 18:07:50 - train: epoch 0146, iter [00090, 01251], lr: 0.000965, loss: 0.4045
2022-09-29 18:08:07 - train: epoch 0146, iter [00100, 01251], lr: 0.000965, loss: 0.4207
2022-09-29 18:08:25 - train: epoch 0146, iter [00110, 01251], lr: 0.000965, loss: 0.4196
2022-09-29 18:08:43 - train: epoch 0146, iter [00120, 01251], lr: 0.000965, loss: 0.3910
2022-09-29 18:09:00 - train: epoch 0146, iter [00130, 01251], lr: 0.000965, loss: 0.4101
2022-09-29 18:09:18 - train: epoch 0146, iter [00140, 01251], lr: 0.000965, loss: 0.4024
2022-09-29 18:09:36 - train: epoch 0146, iter [00150, 01251], lr: 0.000965, loss: 0.4316
2022-09-29 18:09:53 - train: epoch 0146, iter [00160, 01251], lr: 0.000965, loss: 0.4216
2022-09-29 18:10:11 - train: epoch 0146, iter [00170, 01251], lr: 0.000965, loss: 0.4218
2022-09-29 18:10:29 - train: epoch 0146, iter [00180, 01251], lr: 0.000965, loss: 0.4235
2022-09-29 18:10:46 - train: epoch 0146, iter [00190, 01251], lr: 0.000965, loss: 0.4386
2022-09-29 18:11:04 - train: epoch 0146, iter [00200, 01251], lr: 0.000965, loss: 0.4144
2022-09-29 18:11:22 - train: epoch 0146, iter [00210, 01251], lr: 0.000965, loss: 0.4024
2022-09-29 18:11:39 - train: epoch 0146, iter [00220, 01251], lr: 0.000965, loss: 0.4282
2022-09-29 18:11:57 - train: epoch 0146, iter [00230, 01251], lr: 0.000964, loss: 0.4334
2022-09-29 18:12:15 - train: epoch 0146, iter [00240, 01251], lr: 0.000964, loss: 0.4029
2022-09-29 18:12:33 - train: epoch 0146, iter [00250, 01251], lr: 0.000964, loss: 0.4159
2022-09-29 18:12:50 - train: epoch 0146, iter [00260, 01251], lr: 0.000964, loss: 0.4189
2022-09-29 18:13:08 - train: epoch 0146, iter [00270, 01251], lr: 0.000964, loss: 0.3985
2022-09-29 18:13:25 - train: epoch 0146, iter [00280, 01251], lr: 0.000964, loss: 0.4129
2022-09-29 18:13:43 - train: epoch 0146, iter [00290, 01251], lr: 0.000964, loss: 0.4246
2022-09-29 18:14:01 - train: epoch 0146, iter [00300, 01251], lr: 0.000964, loss: 0.4178
2022-09-29 18:14:19 - train: epoch 0146, iter [00310, 01251], lr: 0.000964, loss: 0.4085
2022-09-29 18:14:36 - train: epoch 0146, iter [00320, 01251], lr: 0.000964, loss: 0.4279
2022-09-29 18:14:54 - train: epoch 0146, iter [00330, 01251], lr: 0.000964, loss: 0.4117
2022-09-29 18:15:12 - train: epoch 0146, iter [00340, 01251], lr: 0.000964, loss: 0.4144
2022-09-29 18:15:29 - train: epoch 0146, iter [00350, 01251], lr: 0.000964, loss: 0.3953
2022-09-29 18:15:47 - train: epoch 0146, iter [00360, 01251], lr: 0.000964, loss: 0.4047
2022-09-29 18:16:04 - train: epoch 0146, iter [00370, 01251], lr: 0.000964, loss: 0.4079
2022-09-29 18:16:22 - train: epoch 0146, iter [00380, 01251], lr: 0.000964, loss: 0.4183
2022-09-29 18:16:40 - train: epoch 0146, iter [00390, 01251], lr: 0.000964, loss: 0.3968
2022-09-29 18:16:57 - train: epoch 0146, iter [00400, 01251], lr: 0.000964, loss: 0.4032
2022-09-29 18:17:15 - train: epoch 0146, iter [00410, 01251], lr: 0.000964, loss: 0.4120
2022-09-29 18:17:33 - train: epoch 0146, iter [00420, 01251], lr: 0.000964, loss: 0.4017
2022-09-29 18:17:51 - train: epoch 0146, iter [00430, 01251], lr: 0.000964, loss: 0.4191
2022-09-29 18:18:08 - train: epoch 0146, iter [00440, 01251], lr: 0.000964, loss: 0.4015
2022-09-29 18:18:26 - train: epoch 0146, iter [00450, 01251], lr: 0.000964, loss: 0.4081
2022-09-29 18:18:44 - train: epoch 0146, iter [00460, 01251], lr: 0.000964, loss: 0.3935
2022-09-29 18:19:01 - train: epoch 0146, iter [00470, 01251], lr: 0.000964, loss: 0.4045
2022-09-29 18:19:19 - train: epoch 0146, iter [00480, 01251], lr: 0.000964, loss: 0.4188
2022-09-29 18:19:37 - train: epoch 0146, iter [00490, 01251], lr: 0.000964, loss: 0.4113
2022-09-29 18:19:55 - train: epoch 0146, iter [00500, 01251], lr: 0.000964, loss: 0.3990
2022-09-29 18:20:12 - train: epoch 0146, iter [00510, 01251], lr: 0.000964, loss: 0.4042
2022-09-29 18:20:30 - train: epoch 0146, iter [00520, 01251], lr: 0.000964, loss: 0.4050
2022-09-29 18:20:48 - train: epoch 0146, iter [00530, 01251], lr: 0.000963, loss: 0.4165
2022-09-29 18:21:05 - train: epoch 0146, iter [00540, 01251], lr: 0.000963, loss: 0.4319
2022-09-29 18:21:23 - train: epoch 0146, iter [00550, 01251], lr: 0.000963, loss: 0.4013
2022-09-29 18:21:41 - train: epoch 0146, iter [00560, 01251], lr: 0.000963, loss: 0.3799
2022-09-29 18:21:59 - train: epoch 0146, iter [00570, 01251], lr: 0.000963, loss: 0.4276
2022-09-29 18:22:16 - train: epoch 0146, iter [00580, 01251], lr: 0.000963, loss: 0.4025
2022-09-29 18:22:34 - train: epoch 0146, iter [00590, 01251], lr: 0.000963, loss: 0.4077
2022-09-29 18:22:51 - train: epoch 0146, iter [00600, 01251], lr: 0.000963, loss: 0.3926
2022-09-29 18:23:09 - train: epoch 0146, iter [00610, 01251], lr: 0.000963, loss: 0.4142
2022-09-29 18:23:27 - train: epoch 0146, iter [00620, 01251], lr: 0.000963, loss: 0.4031
2022-09-29 18:23:44 - train: epoch 0146, iter [00630, 01251], lr: 0.000963, loss: 0.4184
2022-09-29 18:24:02 - train: epoch 0146, iter [00640, 01251], lr: 0.000963, loss: 0.4089
2022-09-29 18:24:20 - train: epoch 0146, iter [00650, 01251], lr: 0.000963, loss: 0.3883
2022-09-29 18:24:37 - train: epoch 0146, iter [00660, 01251], lr: 0.000963, loss: 0.4056
2022-09-29 18:24:55 - train: epoch 0146, iter [00670, 01251], lr: 0.000963, loss: 0.4082
2022-09-29 18:25:13 - train: epoch 0146, iter [00680, 01251], lr: 0.000963, loss: 0.4197
2022-09-29 18:25:30 - train: epoch 0146, iter [00690, 01251], lr: 0.000963, loss: 0.4147
2022-09-29 18:25:48 - train: epoch 0146, iter [00700, 01251], lr: 0.000963, loss: 0.4305
2022-09-29 18:26:06 - train: epoch 0146, iter [00710, 01251], lr: 0.000963, loss: 0.3926
2022-09-29 18:26:23 - train: epoch 0146, iter [00720, 01251], lr: 0.000963, loss: 0.4104
2022-09-29 18:26:41 - train: epoch 0146, iter [00730, 01251], lr: 0.000963, loss: 0.4099
2022-09-29 18:26:58 - train: epoch 0146, iter [00740, 01251], lr: 0.000963, loss: 0.4321
2022-09-29 18:27:16 - train: epoch 0146, iter [00750, 01251], lr: 0.000963, loss: 0.4137
2022-09-29 18:27:34 - train: epoch 0146, iter [00760, 01251], lr: 0.000963, loss: 0.4037
2022-09-29 18:27:51 - train: epoch 0146, iter [00770, 01251], lr: 0.000963, loss: 0.3987
2022-09-29 18:28:09 - train: epoch 0146, iter [00780, 01251], lr: 0.000963, loss: 0.4155
2022-09-29 18:28:27 - train: epoch 0146, iter [00790, 01251], lr: 0.000963, loss: 0.4010
2022-09-29 18:28:45 - train: epoch 0146, iter [00800, 01251], lr: 0.000963, loss: 0.4235
2022-09-29 18:29:02 - train: epoch 0146, iter [00810, 01251], lr: 0.000963, loss: 0.4081
2022-09-29 18:29:20 - train: epoch 0146, iter [00820, 01251], lr: 0.000963, loss: 0.4038
2022-09-29 18:29:38 - train: epoch 0146, iter [00830, 01251], lr: 0.000962, loss: 0.4432
2022-09-29 18:29:55 - train: epoch 0146, iter [00840, 01251], lr: 0.000962, loss: 0.3939
2022-09-29 18:30:13 - train: epoch 0146, iter [00850, 01251], lr: 0.000962, loss: 0.4142
2022-09-29 18:30:31 - train: epoch 0146, iter [00860, 01251], lr: 0.000962, loss: 0.4239
2022-09-29 18:30:49 - train: epoch 0146, iter [00870, 01251], lr: 0.000962, loss: 0.3974
2022-09-29 18:31:06 - train: epoch 0146, iter [00880, 01251], lr: 0.000962, loss: 0.4255
2022-09-29 18:31:24 - train: epoch 0146, iter [00890, 01251], lr: 0.000962, loss: 0.3952
2022-09-29 18:31:41 - train: epoch 0146, iter [00900, 01251], lr: 0.000962, loss: 0.3834
2022-09-29 18:31:59 - train: epoch 0146, iter [00910, 01251], lr: 0.000962, loss: 0.4202
2022-09-29 18:32:17 - train: epoch 0146, iter [00920, 01251], lr: 0.000962, loss: 0.4142
2022-09-29 18:32:34 - train: epoch 0146, iter [00930, 01251], lr: 0.000962, loss: 0.3982
2022-09-29 18:32:52 - train: epoch 0146, iter [00940, 01251], lr: 0.000962, loss: 0.4273
2022-09-29 18:33:10 - train: epoch 0146, iter [00950, 01251], lr: 0.000962, loss: 0.4086
2022-09-29 18:33:28 - train: epoch 0146, iter [00960, 01251], lr: 0.000962, loss: 0.4276
2022-09-29 18:33:45 - train: epoch 0146, iter [00970, 01251], lr: 0.000962, loss: 0.4173
2022-09-29 18:34:03 - train: epoch 0146, iter [00980, 01251], lr: 0.000962, loss: 0.4272
2022-09-29 18:34:21 - train: epoch 0146, iter [00990, 01251], lr: 0.000962, loss: 0.4086
2022-09-29 18:34:38 - train: epoch 0146, iter [01000, 01251], lr: 0.000962, loss: 0.4141
2022-09-29 18:34:56 - train: epoch 0146, iter [01010, 01251], lr: 0.000962, loss: 0.4184
2022-09-29 18:35:14 - train: epoch 0146, iter [01020, 01251], lr: 0.000962, loss: 0.4119
2022-09-29 18:35:31 - train: epoch 0146, iter [01030, 01251], lr: 0.000962, loss: 0.4308
2022-09-29 18:35:49 - train: epoch 0146, iter [01040, 01251], lr: 0.000962, loss: 0.3977
2022-09-29 18:36:06 - train: epoch 0146, iter [01050, 01251], lr: 0.000962, loss: 0.4105
2022-09-29 18:36:24 - train: epoch 0146, iter [01060, 01251], lr: 0.000962, loss: 0.4284
2022-09-29 18:36:42 - train: epoch 0146, iter [01070, 01251], lr: 0.000962, loss: 0.4033
2022-09-29 18:36:59 - train: epoch 0146, iter [01080, 01251], lr: 0.000962, loss: 0.4097
2022-09-29 18:37:17 - train: epoch 0146, iter [01090, 01251], lr: 0.000962, loss: 0.4317
2022-09-29 18:37:35 - train: epoch 0146, iter [01100, 01251], lr: 0.000962, loss: 0.4106
2022-09-29 18:37:52 - train: epoch 0146, iter [01110, 01251], lr: 0.000962, loss: 0.4170
2022-09-29 18:38:10 - train: epoch 0146, iter [01120, 01251], lr: 0.000962, loss: 0.3940
2022-09-29 18:38:28 - train: epoch 0146, iter [01130, 01251], lr: 0.000961, loss: 0.4037
2022-09-29 18:38:45 - train: epoch 0146, iter [01140, 01251], lr: 0.000961, loss: 0.4112
2022-09-29 18:39:03 - train: epoch 0146, iter [01150, 01251], lr: 0.000961, loss: 0.4235
2022-09-29 18:39:20 - train: epoch 0146, iter [01160, 01251], lr: 0.000961, loss: 0.3948
2022-09-29 18:39:38 - train: epoch 0146, iter [01170, 01251], lr: 0.000961, loss: 0.4279
2022-09-29 18:39:56 - train: epoch 0146, iter [01180, 01251], lr: 0.000961, loss: 0.4061
2022-09-29 18:40:14 - train: epoch 0146, iter [01190, 01251], lr: 0.000961, loss: 0.4160
2022-09-29 18:40:31 - train: epoch 0146, iter [01200, 01251], lr: 0.000961, loss: 0.4204
2022-09-29 18:40:49 - train: epoch 0146, iter [01210, 01251], lr: 0.000961, loss: 0.4103
2022-09-29 18:41:07 - train: epoch 0146, iter [01220, 01251], lr: 0.000961, loss: 0.4240
2022-09-29 18:41:24 - train: epoch 0146, iter [01230, 01251], lr: 0.000961, loss: 0.3867
2022-09-29 18:41:42 - train: epoch 0146, iter [01240, 01251], lr: 0.000961, loss: 0.4239
2022-09-29 18:41:59 - train: epoch 0146, iter [01250, 01251], lr: 0.000961, loss: 0.4356
2022-09-29 18:42:03 - train: epoch 146, train_loss: 0.4106
2022-09-29 18:42:05 - until epoch: 146, best_loss: 0.4106
2022-09-29 18:42:05 - epoch 147 lr: 0.000961
2022-09-29 18:42:38 - train: epoch 0147, iter [00010, 01251], lr: 0.000961, loss: 0.4173
2022-09-29 18:42:55 - train: epoch 0147, iter [00020, 01251], lr: 0.000961, loss: 0.4088
2022-09-29 18:43:13 - train: epoch 0147, iter [00030, 01251], lr: 0.000961, loss: 0.3941
2022-09-29 18:43:31 - train: epoch 0147, iter [00040, 01251], lr: 0.000961, loss: 0.4252
2022-09-29 18:43:49 - train: epoch 0147, iter [00050, 01251], lr: 0.000961, loss: 0.4151
2022-09-29 18:44:07 - train: epoch 0147, iter [00060, 01251], lr: 0.000961, loss: 0.4190
2022-09-29 18:44:24 - train: epoch 0147, iter [00070, 01251], lr: 0.000961, loss: 0.4159
2022-09-29 18:44:42 - train: epoch 0147, iter [00080, 01251], lr: 0.000961, loss: 0.4209
2022-09-29 18:45:00 - train: epoch 0147, iter [00090, 01251], lr: 0.000961, loss: 0.3972
2022-09-29 18:45:18 - train: epoch 0147, iter [00100, 01251], lr: 0.000961, loss: 0.4137
2022-09-29 18:45:35 - train: epoch 0147, iter [00110, 01251], lr: 0.000961, loss: 0.4229
2022-09-29 18:45:53 - train: epoch 0147, iter [00120, 01251], lr: 0.000961, loss: 0.4065
2022-09-29 18:46:11 - train: epoch 0147, iter [00130, 01251], lr: 0.000961, loss: 0.4105
2022-09-29 18:46:29 - train: epoch 0147, iter [00140, 01251], lr: 0.000961, loss: 0.4175
2022-09-29 18:46:46 - train: epoch 0147, iter [00150, 01251], lr: 0.000961, loss: 0.4032
2022-09-29 18:47:04 - train: epoch 0147, iter [00160, 01251], lr: 0.000961, loss: 0.3964
2022-09-29 18:47:22 - train: epoch 0147, iter [00170, 01251], lr: 0.000961, loss: 0.4063
2022-09-29 18:47:39 - train: epoch 0147, iter [00180, 01251], lr: 0.000960, loss: 0.4161
2022-09-29 18:47:57 - train: epoch 0147, iter [00190, 01251], lr: 0.000960, loss: 0.4277
2022-09-29 18:48:15 - train: epoch 0147, iter [00200, 01251], lr: 0.000960, loss: 0.4082
2022-09-29 18:48:32 - train: epoch 0147, iter [00210, 01251], lr: 0.000960, loss: 0.4161
2022-09-29 18:48:50 - train: epoch 0147, iter [00220, 01251], lr: 0.000960, loss: 0.4312
2022-09-29 18:49:08 - train: epoch 0147, iter [00230, 01251], lr: 0.000960, loss: 0.4140
2022-09-29 18:49:26 - train: epoch 0147, iter [00240, 01251], lr: 0.000960, loss: 0.4275
2022-09-29 18:49:43 - train: epoch 0147, iter [00250, 01251], lr: 0.000960, loss: 0.3973
2022-09-29 18:50:01 - train: epoch 0147, iter [00260, 01251], lr: 0.000960, loss: 0.4062
2022-09-29 18:50:18 - train: epoch 0147, iter [00270, 01251], lr: 0.000960, loss: 0.4102
2022-09-29 18:50:36 - train: epoch 0147, iter [00280, 01251], lr: 0.000960, loss: 0.4076
2022-09-29 18:50:54 - train: epoch 0147, iter [00290, 01251], lr: 0.000960, loss: 0.4182
2022-09-29 18:51:12 - train: epoch 0147, iter [00300, 01251], lr: 0.000960, loss: 0.4070
2022-09-29 18:51:29 - train: epoch 0147, iter [00310, 01251], lr: 0.000960, loss: 0.4196
2022-09-29 18:51:47 - train: epoch 0147, iter [00320, 01251], lr: 0.000960, loss: 0.4015
2022-09-29 18:52:05 - train: epoch 0147, iter [00330, 01251], lr: 0.000960, loss: 0.4216
2022-09-29 18:52:22 - train: epoch 0147, iter [00340, 01251], lr: 0.000960, loss: 0.4212
2022-09-29 18:52:40 - train: epoch 0147, iter [00350, 01251], lr: 0.000960, loss: 0.4077
2022-09-29 18:52:58 - train: epoch 0147, iter [00360, 01251], lr: 0.000960, loss: 0.4126
2022-09-29 18:53:16 - train: epoch 0147, iter [00370, 01251], lr: 0.000960, loss: 0.4056
2022-09-29 18:53:33 - train: epoch 0147, iter [00380, 01251], lr: 0.000960, loss: 0.4134
2022-09-29 18:53:51 - train: epoch 0147, iter [00390, 01251], lr: 0.000960, loss: 0.4162
2022-09-29 18:54:09 - train: epoch 0147, iter [00400, 01251], lr: 0.000960, loss: 0.4129
2022-09-29 18:54:27 - train: epoch 0147, iter [00410, 01251], lr: 0.000960, loss: 0.4156
2022-09-29 18:54:44 - train: epoch 0147, iter [00420, 01251], lr: 0.000960, loss: 0.4113
2022-09-29 18:55:02 - train: epoch 0147, iter [00430, 01251], lr: 0.000960, loss: 0.3889
2022-09-29 18:55:20 - train: epoch 0147, iter [00440, 01251], lr: 0.000960, loss: 0.4110
2022-09-29 18:55:38 - train: epoch 0147, iter [00450, 01251], lr: 0.000960, loss: 0.4253
2022-09-29 18:55:56 - train: epoch 0147, iter [00460, 01251], lr: 0.000960, loss: 0.4116
2022-09-29 18:56:14 - train: epoch 0147, iter [00470, 01251], lr: 0.000960, loss: 0.4090
2022-09-29 18:56:32 - train: epoch 0147, iter [00480, 01251], lr: 0.000959, loss: 0.3975
2022-09-29 18:56:49 - train: epoch 0147, iter [00490, 01251], lr: 0.000959, loss: 0.4257
2022-09-29 18:57:07 - train: epoch 0147, iter [00500, 01251], lr: 0.000959, loss: 0.4096
2022-09-29 18:57:25 - train: epoch 0147, iter [00510, 01251], lr: 0.000959, loss: 0.4268
2022-09-29 18:57:43 - train: epoch 0147, iter [00520, 01251], lr: 0.000959, loss: 0.4194
2022-09-29 18:58:01 - train: epoch 0147, iter [00530, 01251], lr: 0.000959, loss: 0.4067
2022-09-29 18:58:18 - train: epoch 0147, iter [00540, 01251], lr: 0.000959, loss: 0.4062
2022-09-29 18:58:36 - train: epoch 0147, iter [00550, 01251], lr: 0.000959, loss: 0.4276
2022-09-29 18:58:54 - train: epoch 0147, iter [00560, 01251], lr: 0.000959, loss: 0.4300
2022-09-29 18:59:12 - train: epoch 0147, iter [00570, 01251], lr: 0.000959, loss: 0.4201
2022-09-29 18:59:30 - train: epoch 0147, iter [00580, 01251], lr: 0.000959, loss: 0.4186
2022-09-29 18:59:48 - train: epoch 0147, iter [00590, 01251], lr: 0.000959, loss: 0.4260
2022-09-29 19:00:05 - train: epoch 0147, iter [00600, 01251], lr: 0.000959, loss: 0.4221
2022-09-29 19:00:23 - train: epoch 0147, iter [00610, 01251], lr: 0.000959, loss: 0.4017
2022-09-29 19:00:41 - train: epoch 0147, iter [00620, 01251], lr: 0.000959, loss: 0.4217
2022-09-29 19:00:59 - train: epoch 0147, iter [00630, 01251], lr: 0.000959, loss: 0.4107
2022-09-29 19:01:17 - train: epoch 0147, iter [00640, 01251], lr: 0.000959, loss: 0.4035
2022-09-29 19:01:35 - train: epoch 0147, iter [00650, 01251], lr: 0.000959, loss: 0.4083
2022-09-29 19:01:53 - train: epoch 0147, iter [00660, 01251], lr: 0.000959, loss: 0.4229
2022-09-29 19:02:10 - train: epoch 0147, iter [00670, 01251], lr: 0.000959, loss: 0.4159
2022-09-29 19:02:28 - train: epoch 0147, iter [00680, 01251], lr: 0.000959, loss: 0.3888
2022-09-29 19:02:46 - train: epoch 0147, iter [00690, 01251], lr: 0.000959, loss: 0.4203
2022-09-29 19:03:04 - train: epoch 0147, iter [00700, 01251], lr: 0.000959, loss: 0.4071
2022-09-29 19:03:21 - train: epoch 0147, iter [00710, 01251], lr: 0.000959, loss: 0.4232
2022-09-29 19:03:39 - train: epoch 0147, iter [00720, 01251], lr: 0.000959, loss: 0.4088
2022-09-29 19:03:56 - train: epoch 0147, iter [00730, 01251], lr: 0.000959, loss: 0.4073
2022-09-29 19:04:14 - train: epoch 0147, iter [00740, 01251], lr: 0.000959, loss: 0.4213
2022-09-29 19:04:31 - train: epoch 0147, iter [00750, 01251], lr: 0.000959, loss: 0.4114
2022-09-29 19:04:49 - train: epoch 0147, iter [00760, 01251], lr: 0.000959, loss: 0.4141
2022-09-29 19:05:07 - train: epoch 0147, iter [00770, 01251], lr: 0.000959, loss: 0.3940
2022-09-29 19:05:24 - train: epoch 0147, iter [00780, 01251], lr: 0.000958, loss: 0.4025
2022-09-29 19:05:42 - train: epoch 0147, iter [00790, 01251], lr: 0.000958, loss: 0.4113
2022-09-29 19:06:00 - train: epoch 0147, iter [00800, 01251], lr: 0.000958, loss: 0.4119
2022-09-29 19:06:17 - train: epoch 0147, iter [00810, 01251], lr: 0.000958, loss: 0.4069
2022-09-29 19:06:35 - train: epoch 0147, iter [00820, 01251], lr: 0.000958, loss: 0.4192
2022-09-29 19:06:53 - train: epoch 0147, iter [00830, 01251], lr: 0.000958, loss: 0.4070
2022-09-29 19:07:10 - train: epoch 0147, iter [00840, 01251], lr: 0.000958, loss: 0.3825
2022-09-29 19:07:28 - train: epoch 0147, iter [00850, 01251], lr: 0.000958, loss: 0.3998
2022-09-29 19:07:46 - train: epoch 0147, iter [00860, 01251], lr: 0.000958, loss: 0.4068
2022-09-29 19:08:04 - train: epoch 0147, iter [00870, 01251], lr: 0.000958, loss: 0.4067
2022-09-29 19:08:21 - train: epoch 0147, iter [00880, 01251], lr: 0.000958, loss: 0.3900
2022-09-29 19:08:39 - train: epoch 0147, iter [00890, 01251], lr: 0.000958, loss: 0.4170
2022-09-29 19:08:57 - train: epoch 0147, iter [00900, 01251], lr: 0.000958, loss: 0.4383
2022-09-29 19:09:15 - train: epoch 0147, iter [00910, 01251], lr: 0.000958, loss: 0.4058
2022-09-29 19:09:32 - train: epoch 0147, iter [00920, 01251], lr: 0.000958, loss: 0.3966
2022-09-29 19:09:50 - train: epoch 0147, iter [00930, 01251], lr: 0.000958, loss: 0.4253
2022-09-29 19:10:08 - train: epoch 0147, iter [00940, 01251], lr: 0.000958, loss: 0.4149
2022-09-29 19:10:26 - train: epoch 0147, iter [00950, 01251], lr: 0.000958, loss: 0.4202
2022-09-29 19:10:43 - train: epoch 0147, iter [00960, 01251], lr: 0.000958, loss: 0.4026
2022-09-29 19:11:01 - train: epoch 0147, iter [00970, 01251], lr: 0.000958, loss: 0.4117
2022-09-29 19:11:19 - train: epoch 0147, iter [00980, 01251], lr: 0.000958, loss: 0.4223
2022-09-29 19:11:37 - train: epoch 0147, iter [00990, 01251], lr: 0.000958, loss: 0.4025
2022-09-29 19:11:54 - train: epoch 0147, iter [01000, 01251], lr: 0.000958, loss: 0.4208
2022-09-29 19:12:12 - train: epoch 0147, iter [01010, 01251], lr: 0.000958, loss: 0.4289
2022-09-29 19:12:30 - train: epoch 0147, iter [01020, 01251], lr: 0.000958, loss: 0.4003
2022-09-29 19:12:48 - train: epoch 0147, iter [01030, 01251], lr: 0.000958, loss: 0.4028
2022-09-29 19:13:06 - train: epoch 0147, iter [01040, 01251], lr: 0.000958, loss: 0.4187
2022-09-29 19:13:24 - train: epoch 0147, iter [01050, 01251], lr: 0.000958, loss: 0.4095
2022-09-29 19:13:41 - train: epoch 0147, iter [01060, 01251], lr: 0.000958, loss: 0.4142
2022-09-29 19:13:59 - train: epoch 0147, iter [01070, 01251], lr: 0.000958, loss: 0.4017
2022-09-29 19:14:17 - train: epoch 0147, iter [01080, 01251], lr: 0.000957, loss: 0.4252
2022-09-29 19:14:35 - train: epoch 0147, iter [01090, 01251], lr: 0.000957, loss: 0.3963
2022-09-29 19:14:53 - train: epoch 0147, iter [01100, 01251], lr: 0.000957, loss: 0.4221
2022-09-29 19:15:11 - train: epoch 0147, iter [01110, 01251], lr: 0.000957, loss: 0.4053
2022-09-29 19:15:29 - train: epoch 0147, iter [01120, 01251], lr: 0.000957, loss: 0.4189
2022-09-29 19:15:46 - train: epoch 0147, iter [01130, 01251], lr: 0.000957, loss: 0.4168
2022-09-29 19:16:04 - train: epoch 0147, iter [01140, 01251], lr: 0.000957, loss: 0.4178
2022-09-29 19:16:22 - train: epoch 0147, iter [01150, 01251], lr: 0.000957, loss: 0.3866
2022-09-29 19:16:40 - train: epoch 0147, iter [01160, 01251], lr: 0.000957, loss: 0.4028
2022-09-29 19:16:58 - train: epoch 0147, iter [01170, 01251], lr: 0.000957, loss: 0.3897
2022-09-29 19:17:16 - train: epoch 0147, iter [01180, 01251], lr: 0.000957, loss: 0.4176
2022-09-29 19:17:34 - train: epoch 0147, iter [01190, 01251], lr: 0.000957, loss: 0.3912
2022-09-29 19:17:51 - train: epoch 0147, iter [01200, 01251], lr: 0.000957, loss: 0.4109
2022-09-29 19:18:09 - train: epoch 0147, iter [01210, 01251], lr: 0.000957, loss: 0.4104
2022-09-29 19:18:27 - train: epoch 0147, iter [01220, 01251], lr: 0.000957, loss: 0.3951
2022-09-29 19:18:45 - train: epoch 0147, iter [01230, 01251], lr: 0.000957, loss: 0.4122
2022-09-29 19:19:03 - train: epoch 0147, iter [01240, 01251], lr: 0.000957, loss: 0.4047
2022-09-29 19:19:20 - train: epoch 0147, iter [01250, 01251], lr: 0.000957, loss: 0.4004
2022-09-29 19:19:24 - train: epoch 147, train_loss: 0.4105
2022-09-29 19:19:27 - until epoch: 147, best_loss: 0.4105
2022-09-29 19:19:27 - epoch 148 lr: 0.000957
2022-09-29 19:20:00 - train: epoch 0148, iter [00010, 01251], lr: 0.000957, loss: 0.4056
2022-09-29 19:20:17 - train: epoch 0148, iter [00020, 01251], lr: 0.000957, loss: 0.4039
2022-09-29 19:20:35 - train: epoch 0148, iter [00030, 01251], lr: 0.000957, loss: 0.3960
2022-09-29 19:20:53 - train: epoch 0148, iter [00040, 01251], lr: 0.000957, loss: 0.4079
2022-09-29 19:21:11 - train: epoch 0148, iter [00050, 01251], lr: 0.000957, loss: 0.4156
2022-09-29 19:21:28 - train: epoch 0148, iter [00060, 01251], lr: 0.000957, loss: 0.4131
2022-09-29 19:21:46 - train: epoch 0148, iter [00070, 01251], lr: 0.000957, loss: 0.4011
2022-09-29 19:22:04 - train: epoch 0148, iter [00080, 01251], lr: 0.000957, loss: 0.4187
2022-09-29 19:22:22 - train: epoch 0148, iter [00090, 01251], lr: 0.000957, loss: 0.4213
2022-09-29 19:22:39 - train: epoch 0148, iter [00100, 01251], lr: 0.000957, loss: 0.3927
2022-09-29 19:22:57 - train: epoch 0148, iter [00110, 01251], lr: 0.000957, loss: 0.4392
2022-09-29 19:23:15 - train: epoch 0148, iter [00120, 01251], lr: 0.000956, loss: 0.3888
2022-09-29 19:23:33 - train: epoch 0148, iter [00130, 01251], lr: 0.000956, loss: 0.4218
2022-09-29 19:23:51 - train: epoch 0148, iter [00140, 01251], lr: 0.000956, loss: 0.3962
2022-09-29 19:24:09 - train: epoch 0148, iter [00150, 01251], lr: 0.000956, loss: 0.4127
2022-09-29 19:24:26 - train: epoch 0148, iter [00160, 01251], lr: 0.000956, loss: 0.4031
2022-09-29 19:24:44 - train: epoch 0148, iter [00170, 01251], lr: 0.000956, loss: 0.4159
2022-09-29 19:25:02 - train: epoch 0148, iter [00180, 01251], lr: 0.000956, loss: 0.3995
2022-09-29 19:25:20 - train: epoch 0148, iter [00190, 01251], lr: 0.000956, loss: 0.4176
2022-09-29 19:25:38 - train: epoch 0148, iter [00200, 01251], lr: 0.000956, loss: 0.4118
2022-09-29 19:25:56 - train: epoch 0148, iter [00210, 01251], lr: 0.000956, loss: 0.4342
2022-09-29 19:26:14 - train: epoch 0148, iter [00220, 01251], lr: 0.000956, loss: 0.4070
2022-09-29 19:26:32 - train: epoch 0148, iter [00230, 01251], lr: 0.000956, loss: 0.4140
2022-09-29 19:26:50 - train: epoch 0148, iter [00240, 01251], lr: 0.000956, loss: 0.4088
2022-09-29 19:27:07 - train: epoch 0148, iter [00250, 01251], lr: 0.000956, loss: 0.4109
2022-09-29 19:27:25 - train: epoch 0148, iter [00260, 01251], lr: 0.000956, loss: 0.4232
2022-09-29 19:27:43 - train: epoch 0148, iter [00270, 01251], lr: 0.000956, loss: 0.4070
2022-09-29 19:28:01 - train: epoch 0148, iter [00280, 01251], lr: 0.000956, loss: 0.4273
2022-09-29 19:28:19 - train: epoch 0148, iter [00290, 01251], lr: 0.000956, loss: 0.4031
2022-09-29 19:28:37 - train: epoch 0148, iter [00300, 01251], lr: 0.000956, loss: 0.4253
2022-09-29 19:28:55 - train: epoch 0148, iter [00310, 01251], lr: 0.000956, loss: 0.4224
2022-09-29 19:29:13 - train: epoch 0148, iter [00320, 01251], lr: 0.000956, loss: 0.3931
2022-09-29 19:29:30 - train: epoch 0148, iter [00330, 01251], lr: 0.000956, loss: 0.3989
2022-09-29 19:29:48 - train: epoch 0148, iter [00340, 01251], lr: 0.000956, loss: 0.4008
2022-09-29 19:30:06 - train: epoch 0148, iter [00350, 01251], lr: 0.000956, loss: 0.4113
2022-09-29 19:30:24 - train: epoch 0148, iter [00360, 01251], lr: 0.000956, loss: 0.4265
2022-09-29 19:30:42 - train: epoch 0148, iter [00370, 01251], lr: 0.000956, loss: 0.4096
2022-09-29 19:31:00 - train: epoch 0148, iter [00380, 01251], lr: 0.000956, loss: 0.3948
2022-09-29 19:31:18 - train: epoch 0148, iter [00390, 01251], lr: 0.000956, loss: 0.4241
2022-09-29 19:31:36 - train: epoch 0148, iter [00400, 01251], lr: 0.000956, loss: 0.4010
2022-09-29 19:31:54 - train: epoch 0148, iter [00410, 01251], lr: 0.000956, loss: 0.4256
2022-09-29 19:32:11 - train: epoch 0148, iter [00420, 01251], lr: 0.000955, loss: 0.4119
2022-09-29 19:32:29 - train: epoch 0148, iter [00430, 01251], lr: 0.000955, loss: 0.4097
2022-09-29 19:32:47 - train: epoch 0148, iter [00440, 01251], lr: 0.000955, loss: 0.4254
2022-09-29 19:33:05 - train: epoch 0148, iter [00450, 01251], lr: 0.000955, loss: 0.4198
2022-09-29 19:33:23 - train: epoch 0148, iter [00460, 01251], lr: 0.000955, loss: 0.4025
2022-09-29 19:33:41 - train: epoch 0148, iter [00470, 01251], lr: 0.000955, loss: 0.4268
2022-09-29 19:33:59 - train: epoch 0148, iter [00480, 01251], lr: 0.000955, loss: 0.4210
2022-09-29 19:34:17 - train: epoch 0148, iter [00490, 01251], lr: 0.000955, loss: 0.4159
2022-09-29 19:34:34 - train: epoch 0148, iter [00500, 01251], lr: 0.000955, loss: 0.4295
2022-09-29 19:34:52 - train: epoch 0148, iter [00510, 01251], lr: 0.000955, loss: 0.4267
2022-09-29 19:35:10 - train: epoch 0148, iter [00520, 01251], lr: 0.000955, loss: 0.4136
2022-09-29 19:35:28 - train: epoch 0148, iter [00530, 01251], lr: 0.000955, loss: 0.4201
2022-09-29 19:35:46 - train: epoch 0148, iter [00540, 01251], lr: 0.000955, loss: 0.3878
2022-09-29 19:36:04 - train: epoch 0148, iter [00550, 01251], lr: 0.000955, loss: 0.4057
2022-09-29 19:36:22 - train: epoch 0148, iter [00560, 01251], lr: 0.000955, loss: 0.3980
2022-09-29 19:36:40 - train: epoch 0148, iter [00570, 01251], lr: 0.000955, loss: 0.4370
2022-09-29 19:36:58 - train: epoch 0148, iter [00580, 01251], lr: 0.000955, loss: 0.4116
2022-09-29 19:37:16 - train: epoch 0148, iter [00590, 01251], lr: 0.000955, loss: 0.4088
2022-09-29 19:37:33 - train: epoch 0148, iter [00600, 01251], lr: 0.000955, loss: 0.4208
2022-09-29 19:37:52 - train: epoch 0148, iter [00610, 01251], lr: 0.000955, loss: 0.3971
2022-09-29 19:38:09 - train: epoch 0148, iter [00620, 01251], lr: 0.000955, loss: 0.4102
2022-09-29 19:38:27 - train: epoch 0148, iter [00630, 01251], lr: 0.000955, loss: 0.4133
2022-09-29 19:38:45 - train: epoch 0148, iter [00640, 01251], lr: 0.000955, loss: 0.4200
2022-09-29 19:39:03 - train: epoch 0148, iter [00650, 01251], lr: 0.000955, loss: 0.4012
2022-09-29 19:39:21 - train: epoch 0148, iter [00660, 01251], lr: 0.000955, loss: 0.4176
2022-09-29 19:39:39 - train: epoch 0148, iter [00670, 01251], lr: 0.000955, loss: 0.4096
2022-09-29 19:39:56 - train: epoch 0148, iter [00680, 01251], lr: 0.000955, loss: 0.4004
2022-09-29 19:40:14 - train: epoch 0148, iter [00690, 01251], lr: 0.000955, loss: 0.4053
2022-09-29 19:40:32 - train: epoch 0148, iter [00700, 01251], lr: 0.000955, loss: 0.3968
2022-09-29 19:40:50 - train: epoch 0148, iter [00710, 01251], lr: 0.000955, loss: 0.3851
2022-09-29 19:41:08 - train: epoch 0148, iter [00720, 01251], lr: 0.000954, loss: 0.4033
2022-09-29 19:41:26 - train: epoch 0148, iter [00730, 01251], lr: 0.000954, loss: 0.4243
2022-09-29 19:41:44 - train: epoch 0148, iter [00740, 01251], lr: 0.000954, loss: 0.4142
2022-09-29 19:42:02 - train: epoch 0148, iter [00750, 01251], lr: 0.000954, loss: 0.4242
2022-09-29 19:42:20 - train: epoch 0148, iter [00760, 01251], lr: 0.000954, loss: 0.4230
2022-09-29 19:42:37 - train: epoch 0148, iter [00770, 01251], lr: 0.000954, loss: 0.3990
2022-09-29 19:42:55 - train: epoch 0148, iter [00780, 01251], lr: 0.000954, loss: 0.4050
2022-09-29 19:43:13 - train: epoch 0148, iter [00790, 01251], lr: 0.000954, loss: 0.4165
2022-09-29 19:43:31 - train: epoch 0148, iter [00800, 01251], lr: 0.000954, loss: 0.3921
2022-09-29 19:43:49 - train: epoch 0148, iter [00810, 01251], lr: 0.000954, loss: 0.4185
2022-09-29 19:44:06 - train: epoch 0148, iter [00820, 01251], lr: 0.000954, loss: 0.3975
2022-09-29 19:44:24 - train: epoch 0148, iter [00830, 01251], lr: 0.000954, loss: 0.4061
2022-09-29 19:44:42 - train: epoch 0148, iter [00840, 01251], lr: 0.000954, loss: 0.4070
2022-09-29 19:45:00 - train: epoch 0148, iter [00850, 01251], lr: 0.000954, loss: 0.4162
2022-09-29 19:45:18 - train: epoch 0148, iter [00860, 01251], lr: 0.000954, loss: 0.4053
2022-09-29 19:45:36 - train: epoch 0148, iter [00870, 01251], lr: 0.000954, loss: 0.4193
2022-09-29 19:45:53 - train: epoch 0148, iter [00880, 01251], lr: 0.000954, loss: 0.4078
2022-09-29 19:46:11 - train: epoch 0148, iter [00890, 01251], lr: 0.000954, loss: 0.3983
2022-09-29 19:46:29 - train: epoch 0148, iter [00900, 01251], lr: 0.000954, loss: 0.4087
2022-09-29 19:46:47 - train: epoch 0148, iter [00910, 01251], lr: 0.000954, loss: 0.4231
2022-09-29 19:47:05 - train: epoch 0148, iter [00920, 01251], lr: 0.000954, loss: 0.4110
2022-09-29 19:47:23 - train: epoch 0148, iter [00930, 01251], lr: 0.000954, loss: 0.4121
2022-09-29 19:47:41 - train: epoch 0148, iter [00940, 01251], lr: 0.000954, loss: 0.3931
2022-09-29 19:47:58 - train: epoch 0148, iter [00950, 01251], lr: 0.000954, loss: 0.4119
2022-09-29 19:48:16 - train: epoch 0148, iter [00960, 01251], lr: 0.000954, loss: 0.4028
2022-09-29 19:48:34 - train: epoch 0148, iter [00970, 01251], lr: 0.000954, loss: 0.4191
2022-09-29 19:48:52 - train: epoch 0148, iter [00980, 01251], lr: 0.000954, loss: 0.4280
2022-09-29 19:49:10 - train: epoch 0148, iter [00990, 01251], lr: 0.000954, loss: 0.4112
2022-09-29 19:49:28 - train: epoch 0148, iter [01000, 01251], lr: 0.000954, loss: 0.3885
2022-09-29 19:49:46 - train: epoch 0148, iter [01010, 01251], lr: 0.000953, loss: 0.4049
2022-09-29 19:50:04 - train: epoch 0148, iter [01020, 01251], lr: 0.000953, loss: 0.3944
2022-09-29 19:50:21 - train: epoch 0148, iter [01030, 01251], lr: 0.000953, loss: 0.3970
2022-09-29 19:50:39 - train: epoch 0148, iter [01040, 01251], lr: 0.000953, loss: 0.4055
2022-09-29 19:50:57 - train: epoch 0148, iter [01050, 01251], lr: 0.000953, loss: 0.4148
2022-09-29 19:51:15 - train: epoch 0148, iter [01060, 01251], lr: 0.000953, loss: 0.4185
2022-09-29 19:51:32 - train: epoch 0148, iter [01070, 01251], lr: 0.000953, loss: 0.3914
2022-09-29 19:51:50 - train: epoch 0148, iter [01080, 01251], lr: 0.000953, loss: 0.4468
2022-09-29 19:52:08 - train: epoch 0148, iter [01090, 01251], lr: 0.000953, loss: 0.4267
2022-09-29 19:52:25 - train: epoch 0148, iter [01100, 01251], lr: 0.000953, loss: 0.4106
2022-09-29 19:52:43 - train: epoch 0148, iter [01110, 01251], lr: 0.000953, loss: 0.4105
2022-09-29 19:53:01 - train: epoch 0148, iter [01120, 01251], lr: 0.000953, loss: 0.4205
2022-09-29 19:53:19 - train: epoch 0148, iter [01130, 01251], lr: 0.000953, loss: 0.3967
2022-09-29 19:53:37 - train: epoch 0148, iter [01140, 01251], lr: 0.000953, loss: 0.4029
2022-09-29 19:53:54 - train: epoch 0148, iter [01150, 01251], lr: 0.000953, loss: 0.3936
2022-09-29 19:54:12 - train: epoch 0148, iter [01160, 01251], lr: 0.000953, loss: 0.4116
2022-09-29 19:54:30 - train: epoch 0148, iter [01170, 01251], lr: 0.000953, loss: 0.3886
2022-09-29 19:54:48 - train: epoch 0148, iter [01180, 01251], lr: 0.000953, loss: 0.4149
2022-09-29 19:55:06 - train: epoch 0148, iter [01190, 01251], lr: 0.000953, loss: 0.4335
2022-09-29 19:55:24 - train: epoch 0148, iter [01200, 01251], lr: 0.000953, loss: 0.4182
2022-09-29 19:55:42 - train: epoch 0148, iter [01210, 01251], lr: 0.000953, loss: 0.3964
2022-09-29 19:56:00 - train: epoch 0148, iter [01220, 01251], lr: 0.000953, loss: 0.4110
2022-09-29 19:56:17 - train: epoch 0148, iter [01230, 01251], lr: 0.000953, loss: 0.4152
2022-09-29 19:56:35 - train: epoch 0148, iter [01240, 01251], lr: 0.000953, loss: 0.4223
2022-09-29 19:56:52 - train: epoch 0148, iter [01250, 01251], lr: 0.000953, loss: 0.3983
2022-09-29 19:56:56 - train: epoch 148, train_loss: 0.4105
2022-09-29 19:56:58 - until epoch: 148, best_loss: 0.4105
2022-09-29 19:56:58 - epoch 149 lr: 0.000953
2022-09-29 19:57:32 - train: epoch 0149, iter [00010, 01251], lr: 0.000953, loss: 0.4086
2022-09-29 19:57:50 - train: epoch 0149, iter [00020, 01251], lr: 0.000953, loss: 0.4289
2022-09-29 19:58:08 - train: epoch 0149, iter [00030, 01251], lr: 0.000953, loss: 0.4269
2022-09-29 19:58:26 - train: epoch 0149, iter [00040, 01251], lr: 0.000953, loss: 0.4100
2022-09-29 19:58:44 - train: epoch 0149, iter [00050, 01251], lr: 0.000953, loss: 0.4153
2022-09-29 19:59:02 - train: epoch 0149, iter [00060, 01251], lr: 0.000952, loss: 0.4049
2022-09-29 19:59:20 - train: epoch 0149, iter [00070, 01251], lr: 0.000952, loss: 0.3963
2022-09-29 19:59:38 - train: epoch 0149, iter [00080, 01251], lr: 0.000952, loss: 0.4212
2022-09-29 19:59:56 - train: epoch 0149, iter [00090, 01251], lr: 0.000952, loss: 0.4089
2022-09-29 20:00:14 - train: epoch 0149, iter [00100, 01251], lr: 0.000952, loss: 0.4301
2022-09-29 20:00:32 - train: epoch 0149, iter [00110, 01251], lr: 0.000952, loss: 0.4185
2022-09-29 20:00:50 - train: epoch 0149, iter [00120, 01251], lr: 0.000952, loss: 0.3941
2022-09-29 20:01:08 - train: epoch 0149, iter [00130, 01251], lr: 0.000952, loss: 0.4166
2022-09-29 20:01:26 - train: epoch 0149, iter [00140, 01251], lr: 0.000952, loss: 0.4012
2022-09-29 20:01:44 - train: epoch 0149, iter [00150, 01251], lr: 0.000952, loss: 0.4392
2022-09-29 20:02:02 - train: epoch 0149, iter [00160, 01251], lr: 0.000952, loss: 0.4113
2022-09-29 20:02:19 - train: epoch 0149, iter [00170, 01251], lr: 0.000952, loss: 0.4181
2022-09-29 20:02:37 - train: epoch 0149, iter [00180, 01251], lr: 0.000952, loss: 0.4132
2022-09-29 20:02:55 - train: epoch 0149, iter [00190, 01251], lr: 0.000952, loss: 0.4163
2022-09-29 20:03:13 - train: epoch 0149, iter [00200, 01251], lr: 0.000952, loss: 0.4081
2022-09-29 20:03:31 - train: epoch 0149, iter [00210, 01251], lr: 0.000952, loss: 0.4120
2022-09-29 20:03:49 - train: epoch 0149, iter [00220, 01251], lr: 0.000952, loss: 0.4228
2022-09-29 20:04:07 - train: epoch 0149, iter [00230, 01251], lr: 0.000952, loss: 0.4139
2022-09-29 20:04:25 - train: epoch 0149, iter [00240, 01251], lr: 0.000952, loss: 0.4127
2022-09-29 20:04:43 - train: epoch 0149, iter [00250, 01251], lr: 0.000952, loss: 0.4041
2022-09-29 20:05:00 - train: epoch 0149, iter [00260, 01251], lr: 0.000952, loss: 0.3762
2022-09-29 20:05:18 - train: epoch 0149, iter [00270, 01251], lr: 0.000952, loss: 0.4186
2022-09-29 20:05:36 - train: epoch 0149, iter [00280, 01251], lr: 0.000952, loss: 0.4184
2022-09-29 20:05:54 - train: epoch 0149, iter [00290, 01251], lr: 0.000952, loss: 0.4253
2022-09-29 20:06:12 - train: epoch 0149, iter [00300, 01251], lr: 0.000952, loss: 0.4022
2022-09-29 20:06:30 - train: epoch 0149, iter [00310, 01251], lr: 0.000952, loss: 0.4002
2022-09-29 20:06:48 - train: epoch 0149, iter [00320, 01251], lr: 0.000952, loss: 0.3945
2022-09-29 20:07:06 - train: epoch 0149, iter [00330, 01251], lr: 0.000952, loss: 0.4133
2022-09-29 20:07:23 - train: epoch 0149, iter [00340, 01251], lr: 0.000952, loss: 0.4014
2022-09-29 20:07:41 - train: epoch 0149, iter [00350, 01251], lr: 0.000951, loss: 0.4025
2022-09-29 20:07:59 - train: epoch 0149, iter [00360, 01251], lr: 0.000951, loss: 0.4102
2022-09-29 20:08:17 - train: epoch 0149, iter [00370, 01251], lr: 0.000951, loss: 0.3971
2022-09-29 20:08:35 - train: epoch 0149, iter [00380, 01251], lr: 0.000951, loss: 0.4021
2022-09-29 20:08:53 - train: epoch 0149, iter [00390, 01251], lr: 0.000951, loss: 0.4194
2022-09-29 20:09:11 - train: epoch 0149, iter [00400, 01251], lr: 0.000951, loss: 0.4207
2022-09-29 20:09:29 - train: epoch 0149, iter [00410, 01251], lr: 0.000951, loss: 0.3863
2022-09-29 20:09:47 - train: epoch 0149, iter [00420, 01251], lr: 0.000951, loss: 0.4124
2022-09-29 20:10:05 - train: epoch 0149, iter [00430, 01251], lr: 0.000951, loss: 0.4257
2022-09-29 20:10:22 - train: epoch 0149, iter [00440, 01251], lr: 0.000951, loss: 0.4254
2022-09-29 20:10:40 - train: epoch 0149, iter [00450, 01251], lr: 0.000951, loss: 0.4119
2022-09-29 20:10:58 - train: epoch 0149, iter [00460, 01251], lr: 0.000951, loss: 0.4060
2022-09-29 20:11:16 - train: epoch 0149, iter [00470, 01251], lr: 0.000951, loss: 0.4135
2022-09-29 20:11:34 - train: epoch 0149, iter [00480, 01251], lr: 0.000951, loss: 0.3918
2022-09-29 20:11:52 - train: epoch 0149, iter [00490, 01251], lr: 0.000951, loss: 0.4054
2022-09-29 20:12:10 - train: epoch 0149, iter [00500, 01251], lr: 0.000951, loss: 0.3947
2022-09-29 20:12:28 - train: epoch 0149, iter [00510, 01251], lr: 0.000951, loss: 0.4038
2022-09-29 20:12:46 - train: epoch 0149, iter [00520, 01251], lr: 0.000951, loss: 0.4208
2022-09-29 20:13:04 - train: epoch 0149, iter [00530, 01251], lr: 0.000951, loss: 0.4150
2022-09-29 20:13:23 - train: epoch 0149, iter [00540, 01251], lr: 0.000951, loss: 0.4173
2022-09-29 20:13:40 - train: epoch 0149, iter [00550, 01251], lr: 0.000951, loss: 0.4091
2022-09-29 20:13:58 - train: epoch 0149, iter [00560, 01251], lr: 0.000951, loss: 0.4044
2022-09-29 20:14:16 - train: epoch 0149, iter [00570, 01251], lr: 0.000951, loss: 0.4094
2022-09-29 20:14:34 - train: epoch 0149, iter [00580, 01251], lr: 0.000951, loss: 0.4066
2022-09-29 20:14:52 - train: epoch 0149, iter [00590, 01251], lr: 0.000951, loss: 0.4167
2022-09-29 20:15:10 - train: epoch 0149, iter [00600, 01251], lr: 0.000951, loss: 0.4294
2022-09-29 20:15:28 - train: epoch 0149, iter [00610, 01251], lr: 0.000951, loss: 0.4428
2022-09-29 20:15:46 - train: epoch 0149, iter [00620, 01251], lr: 0.000951, loss: 0.4141
2022-09-29 20:16:04 - train: epoch 0149, iter [00630, 01251], lr: 0.000951, loss: 0.4233
2022-09-29 20:16:22 - train: epoch 0149, iter [00640, 01251], lr: 0.000951, loss: 0.4170
2022-09-29 20:16:40 - train: epoch 0149, iter [00650, 01251], lr: 0.000950, loss: 0.4200
2022-09-29 20:16:58 - train: epoch 0149, iter [00660, 01251], lr: 0.000950, loss: 0.4083
2022-09-29 20:17:16 - train: epoch 0149, iter [00670, 01251], lr: 0.000950, loss: 0.4199
2022-09-29 20:17:34 - train: epoch 0149, iter [00680, 01251], lr: 0.000950, loss: 0.4148
2022-09-29 20:17:52 - train: epoch 0149, iter [00690, 01251], lr: 0.000950, loss: 0.4124
2022-09-29 20:18:10 - train: epoch 0149, iter [00700, 01251], lr: 0.000950, loss: 0.4260
2022-09-29 20:18:29 - train: epoch 0149, iter [00710, 01251], lr: 0.000950, loss: 0.4205
2022-09-29 20:18:47 - train: epoch 0149, iter [00720, 01251], lr: 0.000950, loss: 0.4109
2022-09-29 20:19:05 - train: epoch 0149, iter [00730, 01251], lr: 0.000950, loss: 0.4100
2022-09-29 20:19:23 - train: epoch 0149, iter [00740, 01251], lr: 0.000950, loss: 0.4052
2022-09-29 20:19:40 - train: epoch 0149, iter [00750, 01251], lr: 0.000950, loss: 0.4050
2022-09-29 20:19:59 - train: epoch 0149, iter [00760, 01251], lr: 0.000950, loss: 0.4217
2022-09-29 20:20:17 - train: epoch 0149, iter [00770, 01251], lr: 0.000950, loss: 0.4312
2022-09-29 20:20:35 - train: epoch 0149, iter [00780, 01251], lr: 0.000950, loss: 0.4046
2022-09-29 20:20:53 - train: epoch 0149, iter [00790, 01251], lr: 0.000950, loss: 0.4323
2022-09-29 20:21:11 - train: epoch 0149, iter [00800, 01251], lr: 0.000950, loss: 0.4307
2022-09-29 20:21:29 - train: epoch 0149, iter [00810, 01251], lr: 0.000950, loss: 0.4008
2022-09-29 20:21:47 - train: epoch 0149, iter [00820, 01251], lr: 0.000950, loss: 0.4123
2022-09-29 20:22:05 - train: epoch 0149, iter [00830, 01251], lr: 0.000950, loss: 0.4220
2022-09-29 20:22:23 - train: epoch 0149, iter [00840, 01251], lr: 0.000950, loss: 0.4106
2022-09-29 20:22:41 - train: epoch 0149, iter [00850, 01251], lr: 0.000950, loss: 0.4171
2022-09-29 20:22:59 - train: epoch 0149, iter [00860, 01251], lr: 0.000950, loss: 0.4199
2022-09-29 20:23:17 - train: epoch 0149, iter [00870, 01251], lr: 0.000950, loss: 0.4108
2022-09-29 20:23:35 - train: epoch 0149, iter [00880, 01251], lr: 0.000950, loss: 0.4033
2022-09-29 20:23:52 - train: epoch 0149, iter [00890, 01251], lr: 0.000950, loss: 0.4147
2022-09-29 20:24:10 - train: epoch 0149, iter [00900, 01251], lr: 0.000950, loss: 0.4182
2022-09-29 20:24:28 - train: epoch 0149, iter [00910, 01251], lr: 0.000950, loss: 0.3989
2022-09-29 20:24:47 - train: epoch 0149, iter [00920, 01251], lr: 0.000950, loss: 0.4219
2022-09-29 20:25:05 - train: epoch 0149, iter [00930, 01251], lr: 0.000950, loss: 0.4199
2022-09-29 20:25:22 - train: epoch 0149, iter [00940, 01251], lr: 0.000949, loss: 0.4042
2022-09-29 20:25:41 - train: epoch 0149, iter [00950, 01251], lr: 0.000949, loss: 0.4115
2022-09-29 20:25:59 - train: epoch 0149, iter [00960, 01251], lr: 0.000949, loss: 0.4095
2022-09-29 20:26:17 - train: epoch 0149, iter [00970, 01251], lr: 0.000949, loss: 0.4117
2022-09-29 20:26:35 - train: epoch 0149, iter [00980, 01251], lr: 0.000949, loss: 0.4093
2022-09-29 20:26:53 - train: epoch 0149, iter [00990, 01251], lr: 0.000949, loss: 0.4235
2022-09-29 20:27:11 - train: epoch 0149, iter [01000, 01251], lr: 0.000949, loss: 0.4185
2022-09-29 20:27:29 - train: epoch 0149, iter [01010, 01251], lr: 0.000949, loss: 0.4293
2022-09-29 20:27:47 - train: epoch 0149, iter [01020, 01251], lr: 0.000949, loss: 0.4065
2022-09-29 20:28:05 - train: epoch 0149, iter [01030, 01251], lr: 0.000949, loss: 0.4292
2022-09-29 20:28:23 - train: epoch 0149, iter [01040, 01251], lr: 0.000949, loss: 0.3927
2022-09-29 20:28:41 - train: epoch 0149, iter [01050, 01251], lr: 0.000949, loss: 0.4259
2022-09-29 20:28:59 - train: epoch 0149, iter [01060, 01251], lr: 0.000949, loss: 0.4216
2022-09-29 20:29:17 - train: epoch 0149, iter [01070, 01251], lr: 0.000949, loss: 0.4156
2022-09-29 20:29:36 - train: epoch 0149, iter [01080, 01251], lr: 0.000949, loss: 0.3993
2022-09-29 20:29:54 - train: epoch 0149, iter [01090, 01251], lr: 0.000949, loss: 0.4224
2022-09-29 20:30:12 - train: epoch 0149, iter [01100, 01251], lr: 0.000949, loss: 0.4003
2022-09-29 20:30:30 - train: epoch 0149, iter [01110, 01251], lr: 0.000949, loss: 0.4041
2022-09-29 20:30:48 - train: epoch 0149, iter [01120, 01251], lr: 0.000949, loss: 0.4257
2022-09-29 20:31:06 - train: epoch 0149, iter [01130, 01251], lr: 0.000949, loss: 0.4199
2022-09-29 20:31:24 - train: epoch 0149, iter [01140, 01251], lr: 0.000949, loss: 0.4284
2022-09-29 20:31:42 - train: epoch 0149, iter [01150, 01251], lr: 0.000949, loss: 0.4223
2022-09-29 20:32:01 - train: epoch 0149, iter [01160, 01251], lr: 0.000949, loss: 0.4165
2022-09-29 20:32:19 - train: epoch 0149, iter [01170, 01251], lr: 0.000949, loss: 0.4053
2022-09-29 20:32:37 - train: epoch 0149, iter [01180, 01251], lr: 0.000949, loss: 0.4224
2022-09-29 20:32:55 - train: epoch 0149, iter [01190, 01251], lr: 0.000949, loss: 0.4266
2022-09-29 20:33:13 - train: epoch 0149, iter [01200, 01251], lr: 0.000949, loss: 0.4023
2022-09-29 20:33:31 - train: epoch 0149, iter [01210, 01251], lr: 0.000949, loss: 0.4068
2022-09-29 20:33:49 - train: epoch 0149, iter [01220, 01251], lr: 0.000949, loss: 0.4005
2022-09-29 20:34:07 - train: epoch 0149, iter [01230, 01251], lr: 0.000948, loss: 0.4198
2022-09-29 20:34:25 - train: epoch 0149, iter [01240, 01251], lr: 0.000948, loss: 0.4113
2022-09-29 20:34:42 - train: epoch 0149, iter [01250, 01251], lr: 0.000948, loss: 0.4109
2022-09-29 20:34:46 - train: epoch 149, train_loss: 0.4105
2022-09-29 20:34:47 - until epoch: 149, best_loss: 0.4105
2022-09-29 20:34:47 - epoch 150 lr: 0.000948
2022-09-29 20:35:20 - train: epoch 0150, iter [00010, 01251], lr: 0.000948, loss: 0.4206
2022-09-29 20:35:38 - train: epoch 0150, iter [00020, 01251], lr: 0.000948, loss: 0.4135
2022-09-29 20:35:56 - train: epoch 0150, iter [00030, 01251], lr: 0.000948, loss: 0.3971
2022-09-29 20:36:14 - train: epoch 0150, iter [00040, 01251], lr: 0.000948, loss: 0.4282
2022-09-29 20:36:32 - train: epoch 0150, iter [00050, 01251], lr: 0.000948, loss: 0.4044
2022-09-29 20:36:50 - train: epoch 0150, iter [00060, 01251], lr: 0.000948, loss: 0.4016
2022-09-29 20:37:08 - train: epoch 0150, iter [00070, 01251], lr: 0.000948, loss: 0.4033
2022-09-29 20:37:26 - train: epoch 0150, iter [00080, 01251], lr: 0.000948, loss: 0.4114
2022-09-29 20:37:44 - train: epoch 0150, iter [00090, 01251], lr: 0.000948, loss: 0.4162
2022-09-29 20:38:01 - train: epoch 0150, iter [00100, 01251], lr: 0.000948, loss: 0.3969
2022-09-29 20:38:19 - train: epoch 0150, iter [00110, 01251], lr: 0.000948, loss: 0.4082
2022-09-29 20:38:37 - train: epoch 0150, iter [00120, 01251], lr: 0.000948, loss: 0.3858
2022-09-29 20:38:55 - train: epoch 0150, iter [00130, 01251], lr: 0.000948, loss: 0.3975
2022-09-29 20:39:13 - train: epoch 0150, iter [00140, 01251], lr: 0.000948, loss: 0.4099
2022-09-29 20:39:31 - train: epoch 0150, iter [00150, 01251], lr: 0.000948, loss: 0.4140
2022-09-29 20:39:49 - train: epoch 0150, iter [00160, 01251], lr: 0.000948, loss: 0.4233
2022-09-29 20:40:07 - train: epoch 0150, iter [00170, 01251], lr: 0.000948, loss: 0.4141
2022-09-29 20:40:25 - train: epoch 0150, iter [00180, 01251], lr: 0.000948, loss: 0.3887
2022-09-29 20:40:43 - train: epoch 0150, iter [00190, 01251], lr: 0.000948, loss: 0.3863
2022-09-29 20:41:01 - train: epoch 0150, iter [00200, 01251], lr: 0.000948, loss: 0.4112
2022-09-29 20:41:19 - train: epoch 0150, iter [00210, 01251], lr: 0.000948, loss: 0.4270
2022-09-29 20:41:37 - train: epoch 0150, iter [00220, 01251], lr: 0.000948, loss: 0.3918
2022-09-29 20:41:55 - train: epoch 0150, iter [00230, 01251], lr: 0.000948, loss: 0.4216
2022-09-29 20:42:13 - train: epoch 0150, iter [00240, 01251], lr: 0.000948, loss: 0.3927
2022-09-29 20:42:31 - train: epoch 0150, iter [00250, 01251], lr: 0.000948, loss: 0.4088
2022-09-29 20:42:49 - train: epoch 0150, iter [00260, 01251], lr: 0.000948, loss: 0.4007
2022-09-29 20:43:07 - train: epoch 0150, iter [00270, 01251], lr: 0.000948, loss: 0.4099
2022-09-29 20:43:25 - train: epoch 0150, iter [00280, 01251], lr: 0.000947, loss: 0.4331
2022-09-29 20:43:43 - train: epoch 0150, iter [00290, 01251], lr: 0.000947, loss: 0.4052
2022-09-29 20:44:01 - train: epoch 0150, iter [00300, 01251], lr: 0.000947, loss: 0.4141
2022-09-29 20:44:20 - train: epoch 0150, iter [00310, 01251], lr: 0.000947, loss: 0.4189
2022-09-29 20:44:37 - train: epoch 0150, iter [00320, 01251], lr: 0.000947, loss: 0.4184
2022-09-29 20:44:55 - train: epoch 0150, iter [00330, 01251], lr: 0.000947, loss: 0.4088
2022-09-29 20:45:13 - train: epoch 0150, iter [00340, 01251], lr: 0.000947, loss: 0.4117
2022-09-29 20:45:31 - train: epoch 0150, iter [00350, 01251], lr: 0.000947, loss: 0.4285
2022-09-29 20:45:50 - train: epoch 0150, iter [00360, 01251], lr: 0.000947, loss: 0.4158
2022-09-29 20:46:07 - train: epoch 0150, iter [00370, 01251], lr: 0.000947, loss: 0.4098
2022-09-29 20:46:26 - train: epoch 0150, iter [00380, 01251], lr: 0.000947, loss: 0.4009
2022-09-29 20:46:43 - train: epoch 0150, iter [00390, 01251], lr: 0.000947, loss: 0.4140
2022-09-29 20:47:01 - train: epoch 0150, iter [00400, 01251], lr: 0.000947, loss: 0.3909
2022-09-29 20:47:19 - train: epoch 0150, iter [00410, 01251], lr: 0.000947, loss: 0.4283
2022-09-29 20:47:37 - train: epoch 0150, iter [00420, 01251], lr: 0.000947, loss: 0.4272
2022-09-29 20:47:55 - train: epoch 0150, iter [00430, 01251], lr: 0.000947, loss: 0.4185
2022-09-29 20:48:13 - train: epoch 0150, iter [00440, 01251], lr: 0.000947, loss: 0.4083
2022-09-29 20:48:31 - train: epoch 0150, iter [00450, 01251], lr: 0.000947, loss: 0.4233
2022-09-29 20:48:49 - train: epoch 0150, iter [00460, 01251], lr: 0.000947, loss: 0.4011
2022-09-29 20:49:07 - train: epoch 0150, iter [00470, 01251], lr: 0.000947, loss: 0.3972
2022-09-29 20:49:25 - train: epoch 0150, iter [00480, 01251], lr: 0.000947, loss: 0.4223
2022-09-29 20:49:43 - train: epoch 0150, iter [00490, 01251], lr: 0.000947, loss: 0.3927
2022-09-29 20:50:01 - train: epoch 0150, iter [00500, 01251], lr: 0.000947, loss: 0.4055
2022-09-29 20:50:19 - train: epoch 0150, iter [00510, 01251], lr: 0.000947, loss: 0.4169
2022-09-29 20:50:37 - train: epoch 0150, iter [00520, 01251], lr: 0.000947, loss: 0.4246
2022-09-29 20:50:55 - train: epoch 0150, iter [00530, 01251], lr: 0.000947, loss: 0.4091
2022-09-29 20:51:13 - train: epoch 0150, iter [00540, 01251], lr: 0.000947, loss: 0.4210
2022-09-29 20:51:31 - train: epoch 0150, iter [00550, 01251], lr: 0.000947, loss: 0.4068
2022-09-29 20:51:49 - train: epoch 0150, iter [00560, 01251], lr: 0.000947, loss: 0.3916
2022-09-29 20:52:06 - train: epoch 0150, iter [00570, 01251], lr: 0.000946, loss: 0.4259
2022-09-29 20:52:24 - train: epoch 0150, iter [00580, 01251], lr: 0.000946, loss: 0.4090
2022-09-29 20:52:42 - train: epoch 0150, iter [00590, 01251], lr: 0.000946, loss: 0.4420
2022-09-29 20:53:00 - train: epoch 0150, iter [00600, 01251], lr: 0.000946, loss: 0.3990
2022-09-29 20:53:19 - train: epoch 0150, iter [00610, 01251], lr: 0.000946, loss: 0.4215
2022-09-29 20:53:37 - train: epoch 0150, iter [00620, 01251], lr: 0.000946, loss: 0.4061
2022-09-29 20:53:55 - train: epoch 0150, iter [00630, 01251], lr: 0.000946, loss: 0.3875
2022-09-29 20:54:13 - train: epoch 0150, iter [00640, 01251], lr: 0.000946, loss: 0.4194
2022-09-29 20:54:31 - train: epoch 0150, iter [00650, 01251], lr: 0.000946, loss: 0.4111
2022-09-29 20:54:49 - train: epoch 0150, iter [00660, 01251], lr: 0.000946, loss: 0.4188
2022-09-29 20:55:07 - train: epoch 0150, iter [00670, 01251], lr: 0.000946, loss: 0.3945
2022-09-29 20:55:25 - train: epoch 0150, iter [00680, 01251], lr: 0.000946, loss: 0.4303
2022-09-29 20:55:43 - train: epoch 0150, iter [00690, 01251], lr: 0.000946, loss: 0.4224
2022-09-29 20:56:01 - train: epoch 0150, iter [00700, 01251], lr: 0.000946, loss: 0.3879
2022-09-29 20:56:19 - train: epoch 0150, iter [00710, 01251], lr: 0.000946, loss: 0.4196
2022-09-29 20:56:37 - train: epoch 0150, iter [00720, 01251], lr: 0.000946, loss: 0.4034
2022-09-29 20:56:55 - train: epoch 0150, iter [00730, 01251], lr: 0.000946, loss: 0.4081
2022-09-29 20:57:13 - train: epoch 0150, iter [00740, 01251], lr: 0.000946, loss: 0.4104
2022-09-29 20:57:31 - train: epoch 0150, iter [00750, 01251], lr: 0.000946, loss: 0.3947
2022-09-29 20:57:49 - train: epoch 0150, iter [00760, 01251], lr: 0.000946, loss: 0.4061
2022-09-29 20:58:07 - train: epoch 0150, iter [00770, 01251], lr: 0.000946, loss: 0.4189
2022-09-29 20:58:25 - train: epoch 0150, iter [00780, 01251], lr: 0.000946, loss: 0.4216
2022-09-29 20:58:43 - train: epoch 0150, iter [00790, 01251], lr: 0.000946, loss: 0.4165
2022-09-29 20:59:01 - train: epoch 0150, iter [00800, 01251], lr: 0.000946, loss: 0.4294
2022-09-29 20:59:20 - train: epoch 0150, iter [00810, 01251], lr: 0.000946, loss: 0.4198
2022-09-29 20:59:37 - train: epoch 0150, iter [00820, 01251], lr: 0.000946, loss: 0.4179
2022-09-29 20:59:56 - train: epoch 0150, iter [00830, 01251], lr: 0.000946, loss: 0.4107
2022-09-29 21:00:14 - train: epoch 0150, iter [00840, 01251], lr: 0.000946, loss: 0.4080
2022-09-29 21:00:32 - train: epoch 0150, iter [00850, 01251], lr: 0.000946, loss: 0.4214
2022-09-29 21:00:50 - train: epoch 0150, iter [00860, 01251], lr: 0.000945, loss: 0.3914
2022-09-29 21:01:08 - train: epoch 0150, iter [00870, 01251], lr: 0.000945, loss: 0.4166
2022-09-29 21:01:26 - train: epoch 0150, iter [00880, 01251], lr: 0.000945, loss: 0.3993
2022-09-29 21:01:44 - train: epoch 0150, iter [00890, 01251], lr: 0.000945, loss: 0.4216
2022-09-29 21:02:02 - train: epoch 0150, iter [00900, 01251], lr: 0.000945, loss: 0.4219
2022-09-29 21:02:21 - train: epoch 0150, iter [00910, 01251], lr: 0.000945, loss: 0.4098
2022-09-29 21:02:39 - train: epoch 0150, iter [00920, 01251], lr: 0.000945, loss: 0.4200
2022-09-29 21:02:57 - train: epoch 0150, iter [00930, 01251], lr: 0.000945, loss: 0.3979
2022-09-29 21:03:15 - train: epoch 0150, iter [00940, 01251], lr: 0.000945, loss: 0.3958
2022-09-29 21:03:33 - train: epoch 0150, iter [00950, 01251], lr: 0.000945, loss: 0.4282
2022-09-29 21:03:51 - train: epoch 0150, iter [00960, 01251], lr: 0.000945, loss: 0.4093
2022-09-29 21:04:09 - train: epoch 0150, iter [00970, 01251], lr: 0.000945, loss: 0.4099
2022-09-29 21:04:27 - train: epoch 0150, iter [00980, 01251], lr: 0.000945, loss: 0.4196
2022-09-29 21:04:45 - train: epoch 0150, iter [00990, 01251], lr: 0.000945, loss: 0.4219
2022-09-29 21:05:04 - train: epoch 0150, iter [01000, 01251], lr: 0.000945, loss: 0.4010
2022-09-29 21:05:22 - train: epoch 0150, iter [01010, 01251], lr: 0.000945, loss: 0.4302
2022-09-29 21:05:40 - train: epoch 0150, iter [01020, 01251], lr: 0.000945, loss: 0.4040
2022-09-29 21:05:58 - train: epoch 0150, iter [01030, 01251], lr: 0.000945, loss: 0.4224
2022-09-29 21:06:16 - train: epoch 0150, iter [01040, 01251], lr: 0.000945, loss: 0.4161
2022-09-29 21:06:34 - train: epoch 0150, iter [01050, 01251], lr: 0.000945, loss: 0.3793
2022-09-29 21:06:52 - train: epoch 0150, iter [01060, 01251], lr: 0.000945, loss: 0.4110
2022-09-29 21:07:10 - train: epoch 0150, iter [01070, 01251], lr: 0.000945, loss: 0.3918
2022-09-29 21:07:28 - train: epoch 0150, iter [01080, 01251], lr: 0.000945, loss: 0.4071
2022-09-29 21:07:46 - train: epoch 0150, iter [01090, 01251], lr: 0.000945, loss: 0.3876
2022-09-29 21:08:05 - train: epoch 0150, iter [01100, 01251], lr: 0.000945, loss: 0.4036
2022-09-29 21:08:23 - train: epoch 0150, iter [01110, 01251], lr: 0.000945, loss: 0.4065
2022-09-29 21:08:41 - train: epoch 0150, iter [01120, 01251], lr: 0.000945, loss: 0.4190
2022-09-29 21:08:59 - train: epoch 0150, iter [01130, 01251], lr: 0.000945, loss: 0.4023
2022-09-29 21:09:17 - train: epoch 0150, iter [01140, 01251], lr: 0.000945, loss: 0.4000
2022-09-29 21:09:35 - train: epoch 0150, iter [01150, 01251], lr: 0.000944, loss: 0.4061
2022-09-29 21:09:53 - train: epoch 0150, iter [01160, 01251], lr: 0.000944, loss: 0.4285
2022-09-29 21:10:11 - train: epoch 0150, iter [01170, 01251], lr: 0.000944, loss: 0.4194
2022-09-29 21:10:29 - train: epoch 0150, iter [01180, 01251], lr: 0.000944, loss: 0.4125
2022-09-29 21:10:47 - train: epoch 0150, iter [01190, 01251], lr: 0.000944, loss: 0.4229
2022-09-29 21:11:05 - train: epoch 0150, iter [01200, 01251], lr: 0.000944, loss: 0.4382
2022-09-29 21:11:24 - train: epoch 0150, iter [01210, 01251], lr: 0.000944, loss: 0.4085
2022-09-29 21:11:41 - train: epoch 0150, iter [01220, 01251], lr: 0.000944, loss: 0.4182
2022-09-29 21:11:59 - train: epoch 0150, iter [01230, 01251], lr: 0.000944, loss: 0.4219
2022-09-29 21:12:17 - train: epoch 0150, iter [01240, 01251], lr: 0.000944, loss: 0.4299
2022-09-29 21:12:35 - train: epoch 0150, iter [01250, 01251], lr: 0.000944, loss: 0.4361
2022-09-29 21:12:39 - train: epoch 150, train_loss: 0.4104
2022-09-29 21:12:41 - until epoch: 150, best_loss: 0.4104
2022-09-29 21:12:41 - epoch 151 lr: 0.000944
2022-09-29 21:13:14 - train: epoch 0151, iter [00010, 01251], lr: 0.000944, loss: 0.4228
2022-09-29 21:13:32 - train: epoch 0151, iter [00020, 01251], lr: 0.000944, loss: 0.4125
2022-09-29 21:13:50 - train: epoch 0151, iter [00030, 01251], lr: 0.000944, loss: 0.4040
2022-09-29 21:14:08 - train: epoch 0151, iter [00040, 01251], lr: 0.000944, loss: 0.4064
2022-09-29 21:14:27 - train: epoch 0151, iter [00050, 01251], lr: 0.000944, loss: 0.4148
2022-09-29 21:14:44 - train: epoch 0151, iter [00060, 01251], lr: 0.000944, loss: 0.4015
2022-09-29 21:15:02 - train: epoch 0151, iter [00070, 01251], lr: 0.000944, loss: 0.4143
2022-09-29 21:15:21 - train: epoch 0151, iter [00080, 01251], lr: 0.000944, loss: 0.4213
2022-09-29 21:15:39 - train: epoch 0151, iter [00090, 01251], lr: 0.000944, loss: 0.4153
2022-09-29 21:15:57 - train: epoch 0151, iter [00100, 01251], lr: 0.000944, loss: 0.4056
2022-09-29 21:16:15 - train: epoch 0151, iter [00110, 01251], lr: 0.000944, loss: 0.3929
2022-09-29 21:16:33 - train: epoch 0151, iter [00120, 01251], lr: 0.000944, loss: 0.4097
2022-09-29 21:16:51 - train: epoch 0151, iter [00130, 01251], lr: 0.000944, loss: 0.4172
2022-09-29 21:17:09 - train: epoch 0151, iter [00140, 01251], lr: 0.000944, loss: 0.4111
2022-09-29 21:17:27 - train: epoch 0151, iter [00150, 01251], lr: 0.000944, loss: 0.4139
2022-09-29 21:17:45 - train: epoch 0151, iter [00160, 01251], lr: 0.000944, loss: 0.4247
2022-09-29 21:18:03 - train: epoch 0151, iter [00170, 01251], lr: 0.000944, loss: 0.3838
2022-09-29 21:18:20 - train: epoch 0151, iter [00180, 01251], lr: 0.000944, loss: 0.4079
2022-09-29 21:18:38 - train: epoch 0151, iter [00190, 01251], lr: 0.000943, loss: 0.3924
2022-09-29 21:18:56 - train: epoch 0151, iter [00200, 01251], lr: 0.000943, loss: 0.3873
2022-09-29 21:19:14 - train: epoch 0151, iter [00210, 01251], lr: 0.000943, loss: 0.4211
2022-09-29 21:19:32 - train: epoch 0151, iter [00220, 01251], lr: 0.000943, loss: 0.4026
2022-09-29 21:19:50 - train: epoch 0151, iter [00230, 01251], lr: 0.000943, loss: 0.3908
2022-09-29 21:20:08 - train: epoch 0151, iter [00240, 01251], lr: 0.000943, loss: 0.4203
2022-09-29 21:20:26 - train: epoch 0151, iter [00250, 01251], lr: 0.000943, loss: 0.4135
2022-09-29 21:20:44 - train: epoch 0151, iter [00260, 01251], lr: 0.000943, loss: 0.4048
2022-09-29 21:21:02 - train: epoch 0151, iter [00270, 01251], lr: 0.000943, loss: 0.4025
2022-09-29 21:21:20 - train: epoch 0151, iter [00280, 01251], lr: 0.000943, loss: 0.4120
2022-09-29 21:21:38 - train: epoch 0151, iter [00290, 01251], lr: 0.000943, loss: 0.4134
2022-09-29 21:21:56 - train: epoch 0151, iter [00300, 01251], lr: 0.000943, loss: 0.3924
2022-09-29 21:22:14 - train: epoch 0151, iter [00310, 01251], lr: 0.000943, loss: 0.4220
2022-09-29 21:22:33 - train: epoch 0151, iter [00320, 01251], lr: 0.000943, loss: 0.4212
2022-09-29 21:22:51 - train: epoch 0151, iter [00330, 01251], lr: 0.000943, loss: 0.4028
2022-09-29 21:23:09 - train: epoch 0151, iter [00340, 01251], lr: 0.000943, loss: 0.4015
2022-09-29 21:23:27 - train: epoch 0151, iter [00350, 01251], lr: 0.000943, loss: 0.4207
2022-09-29 21:23:45 - train: epoch 0151, iter [00360, 01251], lr: 0.000943, loss: 0.4282
2022-09-29 21:24:03 - train: epoch 0151, iter [00370, 01251], lr: 0.000943, loss: 0.4050
2022-09-29 21:24:21 - train: epoch 0151, iter [00380, 01251], lr: 0.000943, loss: 0.4182
2022-09-29 21:24:39 - train: epoch 0151, iter [00390, 01251], lr: 0.000943, loss: 0.4103
2022-09-29 21:24:57 - train: epoch 0151, iter [00400, 01251], lr: 0.000943, loss: 0.4135
2022-09-29 21:25:15 - train: epoch 0151, iter [00410, 01251], lr: 0.000943, loss: 0.4056
2022-09-29 21:25:33 - train: epoch 0151, iter [00420, 01251], lr: 0.000943, loss: 0.4233
2022-09-29 21:25:52 - train: epoch 0151, iter [00430, 01251], lr: 0.000943, loss: 0.4049
2022-09-29 21:26:10 - train: epoch 0151, iter [00440, 01251], lr: 0.000943, loss: 0.4028
2022-09-29 21:26:28 - train: epoch 0151, iter [00450, 01251], lr: 0.000943, loss: 0.4336
2022-09-29 21:26:46 - train: epoch 0151, iter [00460, 01251], lr: 0.000943, loss: 0.4051
2022-09-29 21:27:04 - train: epoch 0151, iter [00470, 01251], lr: 0.000943, loss: 0.3830
2022-09-29 21:27:22 - train: epoch 0151, iter [00480, 01251], lr: 0.000942, loss: 0.4139
2022-09-29 21:27:41 - train: epoch 0151, iter [00490, 01251], lr: 0.000942, loss: 0.4323
2022-09-29 21:27:59 - train: epoch 0151, iter [00500, 01251], lr: 0.000942, loss: 0.4106
2022-09-29 21:28:17 - train: epoch 0151, iter [00510, 01251], lr: 0.000942, loss: 0.4046
2022-09-29 21:28:35 - train: epoch 0151, iter [00520, 01251], lr: 0.000942, loss: 0.4020
2022-09-29 21:28:53 - train: epoch 0151, iter [00530, 01251], lr: 0.000942, loss: 0.4210
2022-09-29 21:29:11 - train: epoch 0151, iter [00540, 01251], lr: 0.000942, loss: 0.4075
2022-09-29 21:29:29 - train: epoch 0151, iter [00550, 01251], lr: 0.000942, loss: 0.4213
2022-09-29 21:29:47 - train: epoch 0151, iter [00560, 01251], lr: 0.000942, loss: 0.4024
2022-09-29 21:30:05 - train: epoch 0151, iter [00570, 01251], lr: 0.000942, loss: 0.4045
2022-09-29 21:30:23 - train: epoch 0151, iter [00580, 01251], lr: 0.000942, loss: 0.4094
2022-09-29 21:30:42 - train: epoch 0151, iter [00590, 01251], lr: 0.000942, loss: 0.3943
2022-09-29 21:31:00 - train: epoch 0151, iter [00600, 01251], lr: 0.000942, loss: 0.4226
2022-09-29 21:31:18 - train: epoch 0151, iter [00610, 01251], lr: 0.000942, loss: 0.4186
2022-09-29 21:31:36 - train: epoch 0151, iter [00620, 01251], lr: 0.000942, loss: 0.4110
2022-09-29 21:31:54 - train: epoch 0151, iter [00630, 01251], lr: 0.000942, loss: 0.4064
2022-09-29 21:32:12 - train: epoch 0151, iter [00640, 01251], lr: 0.000942, loss: 0.4034
2022-09-29 21:32:30 - train: epoch 0151, iter [00650, 01251], lr: 0.000942, loss: 0.4245
2022-09-29 21:32:48 - train: epoch 0151, iter [00660, 01251], lr: 0.000942, loss: 0.4162
2022-09-29 21:33:06 - train: epoch 0151, iter [00670, 01251], lr: 0.000942, loss: 0.4055
2022-09-29 21:33:24 - train: epoch 0151, iter [00680, 01251], lr: 0.000942, loss: 0.4117
2022-09-29 21:33:42 - train: epoch 0151, iter [00690, 01251], lr: 0.000942, loss: 0.4136
2022-09-29 21:34:01 - train: epoch 0151, iter [00700, 01251], lr: 0.000942, loss: 0.4035
2022-09-29 21:34:19 - train: epoch 0151, iter [00710, 01251], lr: 0.000942, loss: 0.4250
2022-09-29 21:34:37 - train: epoch 0151, iter [00720, 01251], lr: 0.000942, loss: 0.4171
2022-09-29 21:34:55 - train: epoch 0151, iter [00730, 01251], lr: 0.000942, loss: 0.4326
2022-09-29 21:35:13 - train: epoch 0151, iter [00740, 01251], lr: 0.000942, loss: 0.4088
2022-09-29 21:35:31 - train: epoch 0151, iter [00750, 01251], lr: 0.000942, loss: 0.3944
2022-09-29 21:35:49 - train: epoch 0151, iter [00760, 01251], lr: 0.000942, loss: 0.4051
2022-09-29 21:36:07 - train: epoch 0151, iter [00770, 01251], lr: 0.000942, loss: 0.4103
2022-09-29 21:36:25 - train: epoch 0151, iter [00780, 01251], lr: 0.000941, loss: 0.4245
2022-09-29 21:36:43 - train: epoch 0151, iter [00790, 01251], lr: 0.000941, loss: 0.3985
2022-09-29 21:37:01 - train: epoch 0151, iter [00800, 01251], lr: 0.000941, loss: 0.4249
2022-09-29 21:37:19 - train: epoch 0151, iter [00810, 01251], lr: 0.000941, loss: 0.4197
2022-09-29 21:37:37 - train: epoch 0151, iter [00820, 01251], lr: 0.000941, loss: 0.3994
2022-09-29 21:37:55 - train: epoch 0151, iter [00830, 01251], lr: 0.000941, loss: 0.4041
2022-09-29 21:38:13 - train: epoch 0151, iter [00840, 01251], lr: 0.000941, loss: 0.4024
2022-09-29 21:38:32 - train: epoch 0151, iter [00850, 01251], lr: 0.000941, loss: 0.3934
2022-09-29 21:38:50 - train: epoch 0151, iter [00860, 01251], lr: 0.000941, loss: 0.4202
2022-09-29 21:39:07 - train: epoch 0151, iter [00870, 01251], lr: 0.000941, loss: 0.4058
2022-09-29 21:39:25 - train: epoch 0151, iter [00880, 01251], lr: 0.000941, loss: 0.4122
2022-09-29 21:39:44 - train: epoch 0151, iter [00890, 01251], lr: 0.000941, loss: 0.3910
2022-09-29 21:40:02 - train: epoch 0151, iter [00900, 01251], lr: 0.000941, loss: 0.4283
2022-09-29 21:40:20 - train: epoch 0151, iter [00910, 01251], lr: 0.000941, loss: 0.4007
2022-09-29 21:40:38 - train: epoch 0151, iter [00920, 01251], lr: 0.000941, loss: 0.4323
2022-09-29 21:40:56 - train: epoch 0151, iter [00930, 01251], lr: 0.000941, loss: 0.4106
2022-09-29 21:41:14 - train: epoch 0151, iter [00940, 01251], lr: 0.000941, loss: 0.4151
2022-09-29 21:41:32 - train: epoch 0151, iter [00950, 01251], lr: 0.000941, loss: 0.3971
2022-09-29 21:41:50 - train: epoch 0151, iter [00960, 01251], lr: 0.000941, loss: 0.4165
2022-09-29 21:42:08 - train: epoch 0151, iter [00970, 01251], lr: 0.000941, loss: 0.3876
2022-09-29 21:42:27 - train: epoch 0151, iter [00980, 01251], lr: 0.000941, loss: 0.4221
2022-09-29 21:42:45 - train: epoch 0151, iter [00990, 01251], lr: 0.000941, loss: 0.4046
2022-09-29 21:43:03 - train: epoch 0151, iter [01000, 01251], lr: 0.000941, loss: 0.4405
2022-09-29 21:43:21 - train: epoch 0151, iter [01010, 01251], lr: 0.000941, loss: 0.3945
2022-09-29 21:43:39 - train: epoch 0151, iter [01020, 01251], lr: 0.000941, loss: 0.4125
2022-09-29 21:43:57 - train: epoch 0151, iter [01030, 01251], lr: 0.000941, loss: 0.4154
2022-09-29 21:44:15 - train: epoch 0151, iter [01040, 01251], lr: 0.000941, loss: 0.4271
2022-09-29 21:44:33 - train: epoch 0151, iter [01050, 01251], lr: 0.000941, loss: 0.4179
2022-09-29 21:44:51 - train: epoch 0151, iter [01060, 01251], lr: 0.000941, loss: 0.4023
2022-09-29 21:45:09 - train: epoch 0151, iter [01070, 01251], lr: 0.000940, loss: 0.4182
2022-09-29 21:45:27 - train: epoch 0151, iter [01080, 01251], lr: 0.000940, loss: 0.4228
2022-09-29 21:45:45 - train: epoch 0151, iter [01090, 01251], lr: 0.000940, loss: 0.4179
2022-09-29 21:46:03 - train: epoch 0151, iter [01100, 01251], lr: 0.000940, loss: 0.4114
2022-09-29 21:46:21 - train: epoch 0151, iter [01110, 01251], lr: 0.000940, loss: 0.4239
2022-09-29 21:46:39 - train: epoch 0151, iter [01120, 01251], lr: 0.000940, loss: 0.4296
2022-09-29 21:46:57 - train: epoch 0151, iter [01130, 01251], lr: 0.000940, loss: 0.3959
2022-09-29 21:47:15 - train: epoch 0151, iter [01140, 01251], lr: 0.000940, loss: 0.4276
2022-09-29 21:47:33 - train: epoch 0151, iter [01150, 01251], lr: 0.000940, loss: 0.4269
2022-09-29 21:47:51 - train: epoch 0151, iter [01160, 01251], lr: 0.000940, loss: 0.4224
2022-09-29 21:48:09 - train: epoch 0151, iter [01170, 01251], lr: 0.000940, loss: 0.4177
2022-09-29 21:48:27 - train: epoch 0151, iter [01180, 01251], lr: 0.000940, loss: 0.4020
2022-09-29 21:48:45 - train: epoch 0151, iter [01190, 01251], lr: 0.000940, loss: 0.4302
2022-09-29 21:49:03 - train: epoch 0151, iter [01200, 01251], lr: 0.000940, loss: 0.4285
2022-09-29 21:49:21 - train: epoch 0151, iter [01210, 01251], lr: 0.000940, loss: 0.3893
2022-09-29 21:49:39 - train: epoch 0151, iter [01220, 01251], lr: 0.000940, loss: 0.4073
2022-09-29 21:49:57 - train: epoch 0151, iter [01230, 01251], lr: 0.000940, loss: 0.3900
2022-09-29 21:50:15 - train: epoch 0151, iter [01240, 01251], lr: 0.000940, loss: 0.4162
2022-09-29 21:50:33 - train: epoch 0151, iter [01250, 01251], lr: 0.000940, loss: 0.4095
2022-09-29 21:50:37 - train: epoch 151, train_loss: 0.4104
2022-09-29 21:50:39 - until epoch: 151, best_loss: 0.4104
2022-09-29 22:03:40 - epoch 152 lr: 0.000940
2022-09-29 22:04:11 - train: epoch 0152, iter [00010, 01251], lr: 0.000940, loss: 0.4142
2022-09-29 22:04:28 - train: epoch 0152, iter [00020, 01251], lr: 0.000940, loss: 0.4099
2022-09-29 22:04:46 - train: epoch 0152, iter [00030, 01251], lr: 0.000940, loss: 0.3948
2022-09-29 22:05:04 - train: epoch 0152, iter [00040, 01251], lr: 0.000940, loss: 0.4252
2022-09-29 22:05:22 - train: epoch 0152, iter [00050, 01251], lr: 0.000940, loss: 0.3945
2022-09-29 22:05:40 - train: epoch 0152, iter [00060, 01251], lr: 0.000940, loss: 0.4195
2022-09-29 22:05:58 - train: epoch 0152, iter [00070, 01251], lr: 0.000940, loss: 0.3998
2022-09-29 22:06:15 - train: epoch 0152, iter [00080, 01251], lr: 0.000940, loss: 0.4113
2022-09-29 22:06:33 - train: epoch 0152, iter [00090, 01251], lr: 0.000940, loss: 0.4123
2022-09-29 22:06:51 - train: epoch 0152, iter [00100, 01251], lr: 0.000939, loss: 0.4101
2022-09-29 22:07:09 - train: epoch 0152, iter [00110, 01251], lr: 0.000939, loss: 0.4214
2022-09-29 22:07:27 - train: epoch 0152, iter [00120, 01251], lr: 0.000939, loss: 0.3995
2022-09-29 22:07:45 - train: epoch 0152, iter [00130, 01251], lr: 0.000939, loss: 0.4128
2022-09-29 22:08:03 - train: epoch 0152, iter [00140, 01251], lr: 0.000939, loss: 0.4031
2022-09-29 22:08:20 - train: epoch 0152, iter [00150, 01251], lr: 0.000939, loss: 0.4438
2022-09-29 22:08:38 - train: epoch 0152, iter [00160, 01251], lr: 0.000939, loss: 0.3919
2022-09-29 22:08:56 - train: epoch 0152, iter [00170, 01251], lr: 0.000939, loss: 0.3970
2022-09-29 22:09:14 - train: epoch 0152, iter [00180, 01251], lr: 0.000939, loss: 0.4076
2022-09-29 22:09:32 - train: epoch 0152, iter [00190, 01251], lr: 0.000939, loss: 0.4114
2022-09-29 22:09:50 - train: epoch 0152, iter [00200, 01251], lr: 0.000939, loss: 0.4123
2022-09-29 22:10:08 - train: epoch 0152, iter [00210, 01251], lr: 0.000939, loss: 0.4176
2022-09-29 22:10:25 - train: epoch 0152, iter [00220, 01251], lr: 0.000939, loss: 0.4108
2022-09-29 22:10:43 - train: epoch 0152, iter [00230, 01251], lr: 0.000939, loss: 0.4166
2022-09-29 22:11:01 - train: epoch 0152, iter [00240, 01251], lr: 0.000939, loss: 0.4125
2022-09-29 22:11:19 - train: epoch 0152, iter [00250, 01251], lr: 0.000939, loss: 0.3988
2022-09-29 22:11:37 - train: epoch 0152, iter [00260, 01251], lr: 0.000939, loss: 0.3924
2022-09-29 22:11:55 - train: epoch 0152, iter [00270, 01251], lr: 0.000939, loss: 0.4178
2022-09-29 22:12:13 - train: epoch 0152, iter [00280, 01251], lr: 0.000939, loss: 0.4080
2022-09-29 22:12:31 - train: epoch 0152, iter [00290, 01251], lr: 0.000939, loss: 0.4113
2022-09-29 22:12:49 - train: epoch 0152, iter [00300, 01251], lr: 0.000939, loss: 0.4125
2022-09-29 22:13:07 - train: epoch 0152, iter [00310, 01251], lr: 0.000939, loss: 0.4117
2022-09-29 22:13:25 - train: epoch 0152, iter [00320, 01251], lr: 0.000939, loss: 0.4065
2022-09-29 22:13:43 - train: epoch 0152, iter [00330, 01251], lr: 0.000939, loss: 0.3944
2022-09-29 22:14:01 - train: epoch 0152, iter [00340, 01251], lr: 0.000939, loss: 0.3897
2022-09-29 22:14:19 - train: epoch 0152, iter [00350, 01251], lr: 0.000939, loss: 0.4079
2022-09-29 22:14:37 - train: epoch 0152, iter [00360, 01251], lr: 0.000939, loss: 0.4051
2022-09-29 22:14:55 - train: epoch 0152, iter [00370, 01251], lr: 0.000939, loss: 0.3918
2022-09-29 22:15:13 - train: epoch 0152, iter [00380, 01251], lr: 0.000939, loss: 0.4052
2022-09-29 22:15:31 - train: epoch 0152, iter [00390, 01251], lr: 0.000938, loss: 0.4263
2022-09-29 22:15:49 - train: epoch 0152, iter [00400, 01251], lr: 0.000938, loss: 0.4128
2022-09-29 22:16:07 - train: epoch 0152, iter [00410, 01251], lr: 0.000938, loss: 0.4393
2022-09-29 22:16:25 - train: epoch 0152, iter [00420, 01251], lr: 0.000938, loss: 0.3952
2022-09-29 22:16:43 - train: epoch 0152, iter [00430, 01251], lr: 0.000938, loss: 0.4065
2022-09-29 22:17:01 - train: epoch 0152, iter [00440, 01251], lr: 0.000938, loss: 0.4105
2022-09-29 22:17:19 - train: epoch 0152, iter [00450, 01251], lr: 0.000938, loss: 0.4145
2022-09-29 22:17:37 - train: epoch 0152, iter [00460, 01251], lr: 0.000938, loss: 0.3970
2022-09-29 22:17:55 - train: epoch 0152, iter [00470, 01251], lr: 0.000938, loss: 0.4178
2022-09-29 22:18:13 - train: epoch 0152, iter [00480, 01251], lr: 0.000938, loss: 0.4268
2022-09-29 22:18:31 - train: epoch 0152, iter [00490, 01251], lr: 0.000938, loss: 0.3972
2022-09-29 22:18:49 - train: epoch 0152, iter [00500, 01251], lr: 0.000938, loss: 0.3990
2022-09-29 22:19:07 - train: epoch 0152, iter [00510, 01251], lr: 0.000938, loss: 0.4205
2022-09-29 22:19:25 - train: epoch 0152, iter [00520, 01251], lr: 0.000938, loss: 0.4004
2022-09-29 22:19:43 - train: epoch 0152, iter [00530, 01251], lr: 0.000938, loss: 0.4030
2022-09-29 22:20:01 - train: epoch 0152, iter [00540, 01251], lr: 0.000938, loss: 0.3974
2022-09-29 22:20:19 - train: epoch 0152, iter [00550, 01251], lr: 0.000938, loss: 0.4180
2022-09-29 22:20:37 - train: epoch 0152, iter [00560, 01251], lr: 0.000938, loss: 0.4159
2022-09-29 22:20:55 - train: epoch 0152, iter [00570, 01251], lr: 0.000938, loss: 0.4113
2022-09-29 22:21:13 - train: epoch 0152, iter [00580, 01251], lr: 0.000938, loss: 0.4117
2022-09-29 22:21:31 - train: epoch 0152, iter [00590, 01251], lr: 0.000938, loss: 0.4110
2022-09-29 22:21:49 - train: epoch 0152, iter [00600, 01251], lr: 0.000938, loss: 0.4069
2022-09-29 22:22:07 - train: epoch 0152, iter [00610, 01251], lr: 0.000938, loss: 0.4115
2022-09-29 22:22:25 - train: epoch 0152, iter [00620, 01251], lr: 0.000938, loss: 0.4057
2022-09-29 22:22:43 - train: epoch 0152, iter [00630, 01251], lr: 0.000938, loss: 0.3894
2022-09-29 22:23:01 - train: epoch 0152, iter [00640, 01251], lr: 0.000938, loss: 0.4085
2022-09-29 22:23:19 - train: epoch 0152, iter [00650, 01251], lr: 0.000938, loss: 0.3967
2022-09-29 22:23:37 - train: epoch 0152, iter [00660, 01251], lr: 0.000938, loss: 0.4313
2022-09-29 22:23:55 - train: epoch 0152, iter [00670, 01251], lr: 0.000938, loss: 0.3963
2022-09-29 22:24:13 - train: epoch 0152, iter [00680, 01251], lr: 0.000937, loss: 0.4048
2022-09-29 22:24:31 - train: epoch 0152, iter [00690, 01251], lr: 0.000937, loss: 0.3995
2022-09-29 22:24:49 - train: epoch 0152, iter [00700, 01251], lr: 0.000937, loss: 0.3988
2022-09-29 22:25:07 - train: epoch 0152, iter [00710, 01251], lr: 0.000937, loss: 0.4086
2022-09-29 22:25:25 - train: epoch 0152, iter [00720, 01251], lr: 0.000937, loss: 0.4125
2022-09-29 22:25:43 - train: epoch 0152, iter [00730, 01251], lr: 0.000937, loss: 0.3946
2022-09-29 22:26:00 - train: epoch 0152, iter [00740, 01251], lr: 0.000937, loss: 0.4238
2022-09-29 22:26:18 - train: epoch 0152, iter [00750, 01251], lr: 0.000937, loss: 0.4059
2022-09-29 22:26:36 - train: epoch 0152, iter [00760, 01251], lr: 0.000937, loss: 0.4072
2022-09-29 22:26:54 - train: epoch 0152, iter [00770, 01251], lr: 0.000937, loss: 0.4199
2022-09-29 22:27:12 - train: epoch 0152, iter [00780, 01251], lr: 0.000937, loss: 0.4345
2022-09-29 22:27:30 - train: epoch 0152, iter [00790, 01251], lr: 0.000937, loss: 0.4380
2022-09-29 22:27:48 - train: epoch 0152, iter [00800, 01251], lr: 0.000937, loss: 0.4229
2022-09-29 22:28:06 - train: epoch 0152, iter [00810, 01251], lr: 0.000937, loss: 0.4114
2022-09-29 22:28:24 - train: epoch 0152, iter [00820, 01251], lr: 0.000937, loss: 0.3962
2022-09-29 22:28:42 - train: epoch 0152, iter [00830, 01251], lr: 0.000937, loss: 0.4222
2022-09-29 22:29:00 - train: epoch 0152, iter [00840, 01251], lr: 0.000937, loss: 0.4234
2022-09-29 22:29:18 - train: epoch 0152, iter [00850, 01251], lr: 0.000937, loss: 0.4158
2022-09-29 22:29:36 - train: epoch 0152, iter [00860, 01251], lr: 0.000937, loss: 0.3783
2022-09-29 22:29:54 - train: epoch 0152, iter [00870, 01251], lr: 0.000937, loss: 0.4044
2022-09-29 22:30:12 - train: epoch 0152, iter [00880, 01251], lr: 0.000937, loss: 0.4307
2022-09-29 22:30:30 - train: epoch 0152, iter [00890, 01251], lr: 0.000937, loss: 0.4229
2022-09-29 22:30:47 - train: epoch 0152, iter [00900, 01251], lr: 0.000937, loss: 0.4227
2022-09-29 22:31:05 - train: epoch 0152, iter [00910, 01251], lr: 0.000937, loss: 0.4156
2022-09-29 22:31:23 - train: epoch 0152, iter [00920, 01251], lr: 0.000937, loss: 0.4347
2022-09-29 22:31:41 - train: epoch 0152, iter [00930, 01251], lr: 0.000937, loss: 0.4157
2022-09-29 22:31:59 - train: epoch 0152, iter [00940, 01251], lr: 0.000937, loss: 0.3992
2022-09-29 22:32:17 - train: epoch 0152, iter [00950, 01251], lr: 0.000937, loss: 0.4037
2022-09-29 22:32:35 - train: epoch 0152, iter [00960, 01251], lr: 0.000937, loss: 0.3924
2022-09-29 22:32:53 - train: epoch 0152, iter [00970, 01251], lr: 0.000936, loss: 0.4248
2022-09-29 22:33:11 - train: epoch 0152, iter [00980, 01251], lr: 0.000936, loss: 0.4091
2022-09-29 22:33:29 - train: epoch 0152, iter [00990, 01251], lr: 0.000936, loss: 0.4294
2022-09-29 22:33:46 - train: epoch 0152, iter [01000, 01251], lr: 0.000936, loss: 0.4065
2022-09-29 22:34:05 - train: epoch 0152, iter [01010, 01251], lr: 0.000936, loss: 0.4188
2022-09-29 22:34:23 - train: epoch 0152, iter [01020, 01251], lr: 0.000936, loss: 0.4014
2022-09-29 22:34:41 - train: epoch 0152, iter [01030, 01251], lr: 0.000936, loss: 0.4194
2022-09-29 22:34:59 - train: epoch 0152, iter [01040, 01251], lr: 0.000936, loss: 0.4249
2022-09-29 22:35:16 - train: epoch 0152, iter [01050, 01251], lr: 0.000936, loss: 0.4161
2022-09-29 22:35:34 - train: epoch 0152, iter [01060, 01251], lr: 0.000936, loss: 0.4019
2022-09-29 22:35:52 - train: epoch 0152, iter [01070, 01251], lr: 0.000936, loss: 0.4121
2022-09-29 22:36:10 - train: epoch 0152, iter [01080, 01251], lr: 0.000936, loss: 0.4038
2022-09-29 22:36:28 - train: epoch 0152, iter [01090, 01251], lr: 0.000936, loss: 0.4208
2022-09-29 22:36:46 - train: epoch 0152, iter [01100, 01251], lr: 0.000936, loss: 0.4059
2022-09-29 22:37:03 - train: epoch 0152, iter [01110, 01251], lr: 0.000936, loss: 0.4174
2022-09-29 22:37:21 - train: epoch 0152, iter [01120, 01251], lr: 0.000936, loss: 0.4193
2022-09-29 22:37:40 - train: epoch 0152, iter [01130, 01251], lr: 0.000936, loss: 0.4054
2022-09-29 22:37:58 - train: epoch 0152, iter [01140, 01251], lr: 0.000936, loss: 0.4135
2022-09-29 22:38:16 - train: epoch 0152, iter [01150, 01251], lr: 0.000936, loss: 0.3982
2022-09-29 22:38:34 - train: epoch 0152, iter [01160, 01251], lr: 0.000936, loss: 0.4114
2022-09-29 22:38:52 - train: epoch 0152, iter [01170, 01251], lr: 0.000936, loss: 0.4211
2022-09-29 22:39:10 - train: epoch 0152, iter [01180, 01251], lr: 0.000936, loss: 0.4252
2022-09-29 22:39:28 - train: epoch 0152, iter [01190, 01251], lr: 0.000936, loss: 0.4060
2022-09-29 22:39:46 - train: epoch 0152, iter [01200, 01251], lr: 0.000936, loss: 0.4285
2022-09-29 22:40:04 - train: epoch 0152, iter [01210, 01251], lr: 0.000936, loss: 0.4084
2022-09-29 22:40:22 - train: epoch 0152, iter [01220, 01251], lr: 0.000936, loss: 0.4230
2022-09-29 22:40:40 - train: epoch 0152, iter [01230, 01251], lr: 0.000936, loss: 0.4332
2022-09-29 22:40:58 - train: epoch 0152, iter [01240, 01251], lr: 0.000936, loss: 0.4067
2022-09-29 22:41:16 - train: epoch 0152, iter [01250, 01251], lr: 0.000936, loss: 0.4099
2022-09-29 22:41:19 - train: epoch 152, train_loss: 0.4103
2022-09-29 22:41:21 - until epoch: 152, best_loss: 0.4103
2022-09-29 22:41:21 - epoch 153 lr: 0.000936
2022-09-29 22:41:48 - train: epoch 0153, iter [00010, 01251], lr: 0.000935, loss: 0.4186
2022-09-29 22:42:06 - train: epoch 0153, iter [00020, 01251], lr: 0.000935, loss: 0.4368
2022-09-29 22:42:24 - train: epoch 0153, iter [00030, 01251], lr: 0.000935, loss: 0.4007
2022-09-29 22:42:41 - train: epoch 0153, iter [00040, 01251], lr: 0.000935, loss: 0.4078
2022-09-29 22:42:59 - train: epoch 0153, iter [00050, 01251], lr: 0.000935, loss: 0.4053
2022-09-29 22:43:17 - train: epoch 0153, iter [00060, 01251], lr: 0.000935, loss: 0.4177
2022-09-29 22:43:35 - train: epoch 0153, iter [00070, 01251], lr: 0.000935, loss: 0.4341
2022-09-29 22:43:53 - train: epoch 0153, iter [00080, 01251], lr: 0.000935, loss: 0.4001
2022-09-29 22:44:11 - train: epoch 0153, iter [00090, 01251], lr: 0.000935, loss: 0.4096
2022-09-29 22:44:29 - train: epoch 0153, iter [00100, 01251], lr: 0.000935, loss: 0.3982
2022-09-29 22:44:47 - train: epoch 0153, iter [00110, 01251], lr: 0.000935, loss: 0.4274
2022-09-29 22:45:05 - train: epoch 0153, iter [00120, 01251], lr: 0.000935, loss: 0.3895
2022-09-29 22:45:23 - train: epoch 0153, iter [00130, 01251], lr: 0.000935, loss: 0.4171
2022-09-29 22:45:41 - train: epoch 0153, iter [00140, 01251], lr: 0.000935, loss: 0.4072
2022-09-29 22:45:59 - train: epoch 0153, iter [00150, 01251], lr: 0.000935, loss: 0.4059
2022-09-29 22:46:17 - train: epoch 0153, iter [00160, 01251], lr: 0.000935, loss: 0.4183
2022-09-29 22:46:35 - train: epoch 0153, iter [00170, 01251], lr: 0.000935, loss: 0.4172
2022-09-29 22:46:52 - train: epoch 0153, iter [00180, 01251], lr: 0.000935, loss: 0.4211
2022-09-29 22:47:11 - train: epoch 0153, iter [00190, 01251], lr: 0.000935, loss: 0.4151
2022-09-29 22:47:29 - train: epoch 0153, iter [00200, 01251], lr: 0.000935, loss: 0.4077
2022-09-29 22:47:47 - train: epoch 0153, iter [00210, 01251], lr: 0.000935, loss: 0.3919
2022-09-29 22:48:04 - train: epoch 0153, iter [00220, 01251], lr: 0.000935, loss: 0.4251
2022-09-29 22:48:22 - train: epoch 0153, iter [00230, 01251], lr: 0.000935, loss: 0.3921
2022-09-29 22:48:40 - train: epoch 0153, iter [00240, 01251], lr: 0.000935, loss: 0.4069
2022-09-29 22:48:58 - train: epoch 0153, iter [00250, 01251], lr: 0.000935, loss: 0.4219
2022-09-29 22:49:16 - train: epoch 0153, iter [00260, 01251], lr: 0.000935, loss: 0.4116
2022-09-29 22:49:34 - train: epoch 0153, iter [00270, 01251], lr: 0.000935, loss: 0.4059
2022-09-29 22:49:52 - train: epoch 0153, iter [00280, 01251], lr: 0.000935, loss: 0.4343
2022-09-29 22:50:10 - train: epoch 0153, iter [00290, 01251], lr: 0.000935, loss: 0.4020
2022-09-29 22:50:28 - train: epoch 0153, iter [00300, 01251], lr: 0.000934, loss: 0.4105
2022-09-29 22:50:46 - train: epoch 0153, iter [00310, 01251], lr: 0.000934, loss: 0.4069
2022-09-29 22:51:04 - train: epoch 0153, iter [00320, 01251], lr: 0.000934, loss: 0.4098
2022-09-29 22:51:22 - train: epoch 0153, iter [00330, 01251], lr: 0.000934, loss: 0.3944
2022-09-29 22:51:40 - train: epoch 0153, iter [00340, 01251], lr: 0.000934, loss: 0.4190
2022-09-29 22:51:58 - train: epoch 0153, iter [00350, 01251], lr: 0.000934, loss: 0.4224
2022-09-29 22:52:16 - train: epoch 0153, iter [00360, 01251], lr: 0.000934, loss: 0.4103
2022-09-29 22:52:34 - train: epoch 0153, iter [00370, 01251], lr: 0.000934, loss: 0.4142
2022-09-29 22:52:52 - train: epoch 0153, iter [00380, 01251], lr: 0.000934, loss: 0.4049
2022-09-29 22:53:10 - train: epoch 0153, iter [00390, 01251], lr: 0.000934, loss: 0.4130
2022-09-29 22:53:28 - train: epoch 0153, iter [00400, 01251], lr: 0.000934, loss: 0.4217
2022-09-29 22:53:46 - train: epoch 0153, iter [00410, 01251], lr: 0.000934, loss: 0.4263
2022-09-29 22:54:04 - train: epoch 0153, iter [00420, 01251], lr: 0.000934, loss: 0.4262
2022-09-29 22:54:22 - train: epoch 0153, iter [00430, 01251], lr: 0.000934, loss: 0.4152
2022-09-29 22:54:40 - train: epoch 0153, iter [00440, 01251], lr: 0.000934, loss: 0.3952
2022-09-29 22:54:58 - train: epoch 0153, iter [00450, 01251], lr: 0.000934, loss: 0.4173
2022-09-29 22:55:15 - train: epoch 0153, iter [00460, 01251], lr: 0.000934, loss: 0.4054
2022-09-29 22:55:33 - train: epoch 0153, iter [00470, 01251], lr: 0.000934, loss: 0.4128
2022-09-29 22:55:51 - train: epoch 0153, iter [00480, 01251], lr: 0.000934, loss: 0.4292
2022-09-29 22:56:09 - train: epoch 0153, iter [00490, 01251], lr: 0.000934, loss: 0.4135
2022-09-29 22:56:27 - train: epoch 0153, iter [00500, 01251], lr: 0.000934, loss: 0.4092
2022-09-29 22:56:44 - train: epoch 0153, iter [00510, 01251], lr: 0.000934, loss: 0.4082
2022-09-29 22:57:02 - train: epoch 0153, iter [00520, 01251], lr: 0.000934, loss: 0.4162
2022-09-29 22:57:20 - train: epoch 0153, iter [00530, 01251], lr: 0.000934, loss: 0.3945
2022-09-29 22:57:37 - train: epoch 0153, iter [00540, 01251], lr: 0.000934, loss: 0.3993
2022-09-29 22:57:55 - train: epoch 0153, iter [00550, 01251], lr: 0.000934, loss: 0.4071
2022-09-29 22:58:12 - train: epoch 0153, iter [00560, 01251], lr: 0.000934, loss: 0.4292
2022-09-29 22:58:30 - train: epoch 0153, iter [00570, 01251], lr: 0.000934, loss: 0.4125
2022-09-29 22:58:48 - train: epoch 0153, iter [00580, 01251], lr: 0.000934, loss: 0.4196
2022-09-29 22:59:05 - train: epoch 0153, iter [00590, 01251], lr: 0.000933, loss: 0.4161
2022-09-29 22:59:23 - train: epoch 0153, iter [00600, 01251], lr: 0.000933, loss: 0.4180
2022-09-29 22:59:40 - train: epoch 0153, iter [00610, 01251], lr: 0.000933, loss: 0.4164
2022-09-29 22:59:58 - train: epoch 0153, iter [00620, 01251], lr: 0.000933, loss: 0.3830
2022-09-29 23:00:16 - train: epoch 0153, iter [00630, 01251], lr: 0.000933, loss: 0.4034
2022-09-29 23:00:34 - train: epoch 0153, iter [00640, 01251], lr: 0.000933, loss: 0.4157
2022-09-29 23:00:52 - train: epoch 0153, iter [00650, 01251], lr: 0.000933, loss: 0.3935
2022-09-29 23:01:09 - train: epoch 0153, iter [00660, 01251], lr: 0.000933, loss: 0.4115
2022-09-29 23:01:27 - train: epoch 0153, iter [00670, 01251], lr: 0.000933, loss: 0.3946
2022-09-29 23:01:45 - train: epoch 0153, iter [00680, 01251], lr: 0.000933, loss: 0.4070
2022-09-29 23:02:03 - train: epoch 0153, iter [00690, 01251], lr: 0.000933, loss: 0.4073
2022-09-29 23:02:21 - train: epoch 0153, iter [00700, 01251], lr: 0.000933, loss: 0.4216
2022-09-29 23:02:38 - train: epoch 0153, iter [00710, 01251], lr: 0.000933, loss: 0.4081
2022-09-29 23:02:56 - train: epoch 0153, iter [00720, 01251], lr: 0.000933, loss: 0.4063
2022-09-29 23:03:13 - train: epoch 0153, iter [00730, 01251], lr: 0.000933, loss: 0.4032
2022-09-29 23:03:31 - train: epoch 0153, iter [00740, 01251], lr: 0.000933, loss: 0.4307
2022-09-29 23:03:49 - train: epoch 0153, iter [00750, 01251], lr: 0.000933, loss: 0.4175
2022-09-29 23:04:06 - train: epoch 0153, iter [00760, 01251], lr: 0.000933, loss: 0.4054
2022-09-29 23:04:24 - train: epoch 0153, iter [00770, 01251], lr: 0.000933, loss: 0.4124
2022-09-29 23:04:42 - train: epoch 0153, iter [00780, 01251], lr: 0.000933, loss: 0.4082
2022-09-29 23:04:59 - train: epoch 0153, iter [00790, 01251], lr: 0.000933, loss: 0.3988
2022-09-29 23:05:17 - train: epoch 0153, iter [00800, 01251], lr: 0.000933, loss: 0.4098
2022-09-29 23:05:35 - train: epoch 0153, iter [00810, 01251], lr: 0.000933, loss: 0.4038
2022-09-29 23:05:52 - train: epoch 0153, iter [00820, 01251], lr: 0.000933, loss: 0.4350
2022-09-29 23:06:10 - train: epoch 0153, iter [00830, 01251], lr: 0.000933, loss: 0.4072
2022-09-29 23:06:28 - train: epoch 0153, iter [00840, 01251], lr: 0.000933, loss: 0.4042
2022-09-29 23:06:45 - train: epoch 0153, iter [00850, 01251], lr: 0.000933, loss: 0.4346
2022-09-29 23:07:03 - train: epoch 0153, iter [00860, 01251], lr: 0.000933, loss: 0.3994
2022-09-29 23:07:21 - train: epoch 0153, iter [00870, 01251], lr: 0.000932, loss: 0.4191
2022-09-29 23:07:38 - train: epoch 0153, iter [00880, 01251], lr: 0.000932, loss: 0.4213
2022-09-29 23:07:56 - train: epoch 0153, iter [00890, 01251], lr: 0.000932, loss: 0.4121
2022-09-29 23:08:14 - train: epoch 0153, iter [00900, 01251], lr: 0.000932, loss: 0.4068
2022-09-29 23:08:31 - train: epoch 0153, iter [00910, 01251], lr: 0.000932, loss: 0.4231
2022-09-29 23:08:49 - train: epoch 0153, iter [00920, 01251], lr: 0.000932, loss: 0.3982
2022-09-29 23:09:07 - train: epoch 0153, iter [00930, 01251], lr: 0.000932, loss: 0.4117
2022-09-29 23:09:24 - train: epoch 0153, iter [00940, 01251], lr: 0.000932, loss: 0.4009
2022-09-29 23:09:42 - train: epoch 0153, iter [00950, 01251], lr: 0.000932, loss: 0.3981
2022-09-29 23:10:00 - train: epoch 0153, iter [00960, 01251], lr: 0.000932, loss: 0.4106
2022-09-29 23:10:17 - train: epoch 0153, iter [00970, 01251], lr: 0.000932, loss: 0.3810
2022-09-29 23:10:35 - train: epoch 0153, iter [00980, 01251], lr: 0.000932, loss: 0.3893
2022-09-29 23:10:52 - train: epoch 0153, iter [00990, 01251], lr: 0.000932, loss: 0.4095
2022-09-29 23:11:10 - train: epoch 0153, iter [01000, 01251], lr: 0.000932, loss: 0.4132
2022-09-29 23:11:27 - train: epoch 0153, iter [01010, 01251], lr: 0.000932, loss: 0.3888
2022-09-29 23:11:45 - train: epoch 0153, iter [01020, 01251], lr: 0.000932, loss: 0.4135
2022-09-29 23:12:02 - train: epoch 0153, iter [01030, 01251], lr: 0.000932, loss: 0.4125
2022-09-29 23:12:20 - train: epoch 0153, iter [01040, 01251], lr: 0.000932, loss: 0.3986
2022-09-29 23:12:38 - train: epoch 0153, iter [01050, 01251], lr: 0.000932, loss: 0.4033
2022-09-29 23:12:55 - train: epoch 0153, iter [01060, 01251], lr: 0.000932, loss: 0.3941
2022-09-29 23:13:13 - train: epoch 0153, iter [01070, 01251], lr: 0.000932, loss: 0.4016
2022-09-29 23:13:30 - train: epoch 0153, iter [01080, 01251], lr: 0.000932, loss: 0.4215
2022-09-29 23:13:48 - train: epoch 0153, iter [01090, 01251], lr: 0.000932, loss: 0.4193
2022-09-29 23:14:06 - train: epoch 0153, iter [01100, 01251], lr: 0.000932, loss: 0.4093
2022-09-29 23:14:23 - train: epoch 0153, iter [01110, 01251], lr: 0.000932, loss: 0.4015
2022-09-29 23:14:41 - train: epoch 0153, iter [01120, 01251], lr: 0.000932, loss: 0.4140
2022-09-29 23:14:59 - train: epoch 0153, iter [01130, 01251], lr: 0.000932, loss: 0.4067
2022-09-29 23:15:16 - train: epoch 0153, iter [01140, 01251], lr: 0.000932, loss: 0.4172
2022-09-29 23:15:34 - train: epoch 0153, iter [01150, 01251], lr: 0.000932, loss: 0.4023
2022-09-29 23:15:52 - train: epoch 0153, iter [01160, 01251], lr: 0.000931, loss: 0.4050
2022-09-29 23:16:09 - train: epoch 0153, iter [01170, 01251], lr: 0.000931, loss: 0.3820
2022-09-29 23:16:27 - train: epoch 0153, iter [01180, 01251], lr: 0.000931, loss: 0.4287
2022-09-29 23:16:44 - train: epoch 0153, iter [01190, 01251], lr: 0.000931, loss: 0.4016
2022-09-29 23:17:02 - train: epoch 0153, iter [01200, 01251], lr: 0.000931, loss: 0.4154
2022-09-29 23:17:19 - train: epoch 0153, iter [01210, 01251], lr: 0.000931, loss: 0.3949
2022-09-29 23:17:36 - train: epoch 0153, iter [01220, 01251], lr: 0.000931, loss: 0.4117
2022-09-29 23:17:54 - train: epoch 0153, iter [01230, 01251], lr: 0.000931, loss: 0.4265
2022-09-29 23:18:12 - train: epoch 0153, iter [01240, 01251], lr: 0.000931, loss: 0.3967
2022-09-29 23:18:29 - train: epoch 0153, iter [01250, 01251], lr: 0.000931, loss: 0.4190
2022-09-29 23:18:32 - train: epoch 153, train_loss: 0.4102
2022-09-29 23:18:35 - until epoch: 153, best_loss: 0.4102
2022-09-29 23:18:35 - epoch 154 lr: 0.000931
2022-09-29 23:19:01 - train: epoch 0154, iter [00010, 01251], lr: 0.000931, loss: 0.4121
2022-09-29 23:19:19 - train: epoch 0154, iter [00020, 01251], lr: 0.000931, loss: 0.4133
2022-09-29 23:19:37 - train: epoch 0154, iter [00030, 01251], lr: 0.000931, loss: 0.4229
2022-09-29 23:19:54 - train: epoch 0154, iter [00040, 01251], lr: 0.000931, loss: 0.4086
2022-09-29 23:20:12 - train: epoch 0154, iter [00050, 01251], lr: 0.000931, loss: 0.4251
2022-09-29 23:20:30 - train: epoch 0154, iter [00060, 01251], lr: 0.000931, loss: 0.4078
2022-09-29 23:20:48 - train: epoch 0154, iter [00070, 01251], lr: 0.000931, loss: 0.3965
2022-09-29 23:21:06 - train: epoch 0154, iter [00080, 01251], lr: 0.000931, loss: 0.4072
2022-09-29 23:21:24 - train: epoch 0154, iter [00090, 01251], lr: 0.000931, loss: 0.4178
2022-09-29 23:21:41 - train: epoch 0154, iter [00100, 01251], lr: 0.000931, loss: 0.4042
2022-09-29 23:21:59 - train: epoch 0154, iter [00110, 01251], lr: 0.000931, loss: 0.4188
2022-09-29 23:22:17 - train: epoch 0154, iter [00120, 01251], lr: 0.000931, loss: 0.4191
2022-09-29 23:22:35 - train: epoch 0154, iter [00130, 01251], lr: 0.000931, loss: 0.4069
2022-09-29 23:22:53 - train: epoch 0154, iter [00140, 01251], lr: 0.000931, loss: 0.4229
2022-09-29 23:23:11 - train: epoch 0154, iter [00150, 01251], lr: 0.000931, loss: 0.4213
2022-09-29 23:23:28 - train: epoch 0154, iter [00160, 01251], lr: 0.000931, loss: 0.4163
2022-09-29 23:23:46 - train: epoch 0154, iter [00170, 01251], lr: 0.000931, loss: 0.4223
2022-09-29 23:24:04 - train: epoch 0154, iter [00180, 01251], lr: 0.000931, loss: 0.4072
2022-09-29 23:24:21 - train: epoch 0154, iter [00190, 01251], lr: 0.000930, loss: 0.4024
2022-09-29 23:24:39 - train: epoch 0154, iter [00200, 01251], lr: 0.000930, loss: 0.3953
2022-09-29 23:24:57 - train: epoch 0154, iter [00210, 01251], lr: 0.000930, loss: 0.4230
2022-09-29 23:25:15 - train: epoch 0154, iter [00220, 01251], lr: 0.000930, loss: 0.4111
2022-09-29 23:25:32 - train: epoch 0154, iter [00230, 01251], lr: 0.000930, loss: 0.4121
2022-09-29 23:25:50 - train: epoch 0154, iter [00240, 01251], lr: 0.000930, loss: 0.4247
2022-09-29 23:26:08 - train: epoch 0154, iter [00250, 01251], lr: 0.000930, loss: 0.4008
2022-09-29 23:26:26 - train: epoch 0154, iter [00260, 01251], lr: 0.000930, loss: 0.4035
2022-09-29 23:26:44 - train: epoch 0154, iter [00270, 01251], lr: 0.000930, loss: 0.3899
2022-09-29 23:27:02 - train: epoch 0154, iter [00280, 01251], lr: 0.000930, loss: 0.4085
2022-09-29 23:27:20 - train: epoch 0154, iter [00290, 01251], lr: 0.000930, loss: 0.4054
2022-09-29 23:27:38 - train: epoch 0154, iter [00300, 01251], lr: 0.000930, loss: 0.3947
2022-09-29 23:27:55 - train: epoch 0154, iter [00310, 01251], lr: 0.000930, loss: 0.4088
2022-09-29 23:28:13 - train: epoch 0154, iter [00320, 01251], lr: 0.000930, loss: 0.4097
2022-09-29 23:28:31 - train: epoch 0154, iter [00330, 01251], lr: 0.000930, loss: 0.3956
2022-09-29 23:28:49 - train: epoch 0154, iter [00340, 01251], lr: 0.000930, loss: 0.4128
2022-09-29 23:29:06 - train: epoch 0154, iter [00350, 01251], lr: 0.000930, loss: 0.4183
2022-09-29 23:29:24 - train: epoch 0154, iter [00360, 01251], lr: 0.000930, loss: 0.4098
2022-09-29 23:29:42 - train: epoch 0154, iter [00370, 01251], lr: 0.000930, loss: 0.3995
2022-09-29 23:29:59 - train: epoch 0154, iter [00380, 01251], lr: 0.000930, loss: 0.4038
2022-09-29 23:30:17 - train: epoch 0154, iter [00390, 01251], lr: 0.000930, loss: 0.4255
2022-09-29 23:30:35 - train: epoch 0154, iter [00400, 01251], lr: 0.000930, loss: 0.3992
2022-09-29 23:30:53 - train: epoch 0154, iter [00410, 01251], lr: 0.000930, loss: 0.3828
2022-09-29 23:31:10 - train: epoch 0154, iter [00420, 01251], lr: 0.000930, loss: 0.3985
2022-09-29 23:31:28 - train: epoch 0154, iter [00430, 01251], lr: 0.000930, loss: 0.4221
2022-09-29 23:31:46 - train: epoch 0154, iter [00440, 01251], lr: 0.000930, loss: 0.4163
2022-09-29 23:32:04 - train: epoch 0154, iter [00450, 01251], lr: 0.000930, loss: 0.4142
2022-09-29 23:32:21 - train: epoch 0154, iter [00460, 01251], lr: 0.000930, loss: 0.4119
2022-09-29 23:32:39 - train: epoch 0154, iter [00470, 01251], lr: 0.000930, loss: 0.4195
2022-09-29 23:32:57 - train: epoch 0154, iter [00480, 01251], lr: 0.000929, loss: 0.3865
2022-09-29 23:33:15 - train: epoch 0154, iter [00490, 01251], lr: 0.000929, loss: 0.4143
2022-09-29 23:33:32 - train: epoch 0154, iter [00500, 01251], lr: 0.000929, loss: 0.4226
2022-09-29 23:33:50 - train: epoch 0154, iter [00510, 01251], lr: 0.000929, loss: 0.4180
2022-09-29 23:34:08 - train: epoch 0154, iter [00520, 01251], lr: 0.000929, loss: 0.4033
2022-09-29 23:34:25 - train: epoch 0154, iter [00530, 01251], lr: 0.000929, loss: 0.4059
2022-09-29 23:34:43 - train: epoch 0154, iter [00540, 01251], lr: 0.000929, loss: 0.4121
2022-09-29 23:35:01 - train: epoch 0154, iter [00550, 01251], lr: 0.000929, loss: 0.4127
2022-09-29 23:35:19 - train: epoch 0154, iter [00560, 01251], lr: 0.000929, loss: 0.4040
2022-09-29 23:35:37 - train: epoch 0154, iter [00570, 01251], lr: 0.000929, loss: 0.3823
2022-09-29 23:35:54 - train: epoch 0154, iter [00580, 01251], lr: 0.000929, loss: 0.4229
2022-09-29 23:36:12 - train: epoch 0154, iter [00590, 01251], lr: 0.000929, loss: 0.4109
2022-09-29 23:36:29 - train: epoch 0154, iter [00600, 01251], lr: 0.000929, loss: 0.4236
2022-09-29 23:36:47 - train: epoch 0154, iter [00610, 01251], lr: 0.000929, loss: 0.4109
2022-09-29 23:37:04 - train: epoch 0154, iter [00620, 01251], lr: 0.000929, loss: 0.4201
2022-09-29 23:37:22 - train: epoch 0154, iter [00630, 01251], lr: 0.000929, loss: 0.4249
2022-09-29 23:37:40 - train: epoch 0154, iter [00640, 01251], lr: 0.000929, loss: 0.4166
2022-09-29 23:37:57 - train: epoch 0154, iter [00650, 01251], lr: 0.000929, loss: 0.4036
2022-09-29 23:38:15 - train: epoch 0154, iter [00660, 01251], lr: 0.000929, loss: 0.4245
2022-09-29 23:38:32 - train: epoch 0154, iter [00670, 01251], lr: 0.000929, loss: 0.4092
2022-09-29 23:38:50 - train: epoch 0154, iter [00680, 01251], lr: 0.000929, loss: 0.4125
2022-09-29 23:39:08 - train: epoch 0154, iter [00690, 01251], lr: 0.000929, loss: 0.4141
2022-09-29 23:39:25 - train: epoch 0154, iter [00700, 01251], lr: 0.000929, loss: 0.4127
2022-09-29 23:39:43 - train: epoch 0154, iter [00710, 01251], lr: 0.000929, loss: 0.4157
2022-09-29 23:40:01 - train: epoch 0154, iter [00720, 01251], lr: 0.000929, loss: 0.4019
2022-09-29 23:40:18 - train: epoch 0154, iter [00730, 01251], lr: 0.000929, loss: 0.3984
2022-09-29 23:40:36 - train: epoch 0154, iter [00740, 01251], lr: 0.000929, loss: 0.3984
2022-09-29 23:40:53 - train: epoch 0154, iter [00750, 01251], lr: 0.000929, loss: 0.4018
2022-09-29 23:41:11 - train: epoch 0154, iter [00760, 01251], lr: 0.000929, loss: 0.4072
2022-09-29 23:41:29 - train: epoch 0154, iter [00770, 01251], lr: 0.000928, loss: 0.4169
2022-09-29 23:41:46 - train: epoch 0154, iter [00780, 01251], lr: 0.000928, loss: 0.4179
2022-09-29 23:42:04 - train: epoch 0154, iter [00790, 01251], lr: 0.000928, loss: 0.4161
2022-09-29 23:42:21 - train: epoch 0154, iter [00800, 01251], lr: 0.000928, loss: 0.3956
2022-09-29 23:42:39 - train: epoch 0154, iter [00810, 01251], lr: 0.000928, loss: 0.4168
2022-09-29 23:42:56 - train: epoch 0154, iter [00820, 01251], lr: 0.000928, loss: 0.4111
2022-09-29 23:43:14 - train: epoch 0154, iter [00830, 01251], lr: 0.000928, loss: 0.3820
2022-09-29 23:43:32 - train: epoch 0154, iter [00840, 01251], lr: 0.000928, loss: 0.4124
2022-09-29 23:43:49 - train: epoch 0154, iter [00850, 01251], lr: 0.000928, loss: 0.4047
2022-09-29 23:44:07 - train: epoch 0154, iter [00860, 01251], lr: 0.000928, loss: 0.4249
2022-09-29 23:44:25 - train: epoch 0154, iter [00870, 01251], lr: 0.000928, loss: 0.4018
2022-09-29 23:44:42 - train: epoch 0154, iter [00880, 01251], lr: 0.000928, loss: 0.4186
2022-09-29 23:45:00 - train: epoch 0154, iter [00890, 01251], lr: 0.000928, loss: 0.4280
2022-09-29 23:45:17 - train: epoch 0154, iter [00900, 01251], lr: 0.000928, loss: 0.3999
2022-09-29 23:45:35 - train: epoch 0154, iter [00910, 01251], lr: 0.000928, loss: 0.4184
2022-09-29 23:45:52 - train: epoch 0154, iter [00920, 01251], lr: 0.000928, loss: 0.4048
2022-09-29 23:46:10 - train: epoch 0154, iter [00930, 01251], lr: 0.000928, loss: 0.4184
2022-09-29 23:46:27 - train: epoch 0154, iter [00940, 01251], lr: 0.000928, loss: 0.4130
2022-09-29 23:46:45 - train: epoch 0154, iter [00950, 01251], lr: 0.000928, loss: 0.4104
2022-09-29 23:47:02 - train: epoch 0154, iter [00960, 01251], lr: 0.000928, loss: 0.4033
2022-09-29 23:47:19 - train: epoch 0154, iter [00970, 01251], lr: 0.000928, loss: 0.4336
2022-09-29 23:47:37 - train: epoch 0154, iter [00980, 01251], lr: 0.000928, loss: 0.4210
2022-09-29 23:47:55 - train: epoch 0154, iter [00990, 01251], lr: 0.000928, loss: 0.4033
2022-09-29 23:48:12 - train: epoch 0154, iter [01000, 01251], lr: 0.000928, loss: 0.4085
2022-09-29 23:48:30 - train: epoch 0154, iter [01010, 01251], lr: 0.000928, loss: 0.4290
2022-09-29 23:48:47 - train: epoch 0154, iter [01020, 01251], lr: 0.000928, loss: 0.4286
2022-09-29 23:49:05 - train: epoch 0154, iter [01030, 01251], lr: 0.000928, loss: 0.4122
2022-09-29 23:49:22 - train: epoch 0154, iter [01040, 01251], lr: 0.000928, loss: 0.4119
2022-09-29 23:49:40 - train: epoch 0154, iter [01050, 01251], lr: 0.000927, loss: 0.4131
2022-09-29 23:49:57 - train: epoch 0154, iter [01060, 01251], lr: 0.000927, loss: 0.4090
2022-09-29 23:50:15 - train: epoch 0154, iter [01070, 01251], lr: 0.000927, loss: 0.4238
2022-09-29 23:50:32 - train: epoch 0154, iter [01080, 01251], lr: 0.000927, loss: 0.4150
2022-09-29 23:50:50 - train: epoch 0154, iter [01090, 01251], lr: 0.000927, loss: 0.4059
2022-09-29 23:51:08 - train: epoch 0154, iter [01100, 01251], lr: 0.000927, loss: 0.3992
2022-09-29 23:51:25 - train: epoch 0154, iter [01110, 01251], lr: 0.000927, loss: 0.4097
2022-09-29 23:51:43 - train: epoch 0154, iter [01120, 01251], lr: 0.000927, loss: 0.4005
2022-09-29 23:52:01 - train: epoch 0154, iter [01130, 01251], lr: 0.000927, loss: 0.4087
2022-09-29 23:52:18 - train: epoch 0154, iter [01140, 01251], lr: 0.000927, loss: 0.4273
2022-09-29 23:52:36 - train: epoch 0154, iter [01150, 01251], lr: 0.000927, loss: 0.4004
2022-09-29 23:52:53 - train: epoch 0154, iter [01160, 01251], lr: 0.000927, loss: 0.4137
2022-09-29 23:53:11 - train: epoch 0154, iter [01170, 01251], lr: 0.000927, loss: 0.4360
2022-09-29 23:53:29 - train: epoch 0154, iter [01180, 01251], lr: 0.000927, loss: 0.4253
2022-09-29 23:53:46 - train: epoch 0154, iter [01190, 01251], lr: 0.000927, loss: 0.4220
2022-09-29 23:54:04 - train: epoch 0154, iter [01200, 01251], lr: 0.000927, loss: 0.4303
2022-09-29 23:54:22 - train: epoch 0154, iter [01210, 01251], lr: 0.000927, loss: 0.4043
2022-09-29 23:54:39 - train: epoch 0154, iter [01220, 01251], lr: 0.000927, loss: 0.4164
2022-09-29 23:54:57 - train: epoch 0154, iter [01230, 01251], lr: 0.000927, loss: 0.4155
2022-09-29 23:55:15 - train: epoch 0154, iter [01240, 01251], lr: 0.000927, loss: 0.4123
2022-09-29 23:55:32 - train: epoch 0154, iter [01250, 01251], lr: 0.000927, loss: 0.4151
2022-09-29 23:55:35 - train: epoch 154, train_loss: 0.4101
2022-09-29 23:55:38 - until epoch: 154, best_loss: 0.4101
2022-09-29 23:55:38 - epoch 155 lr: 0.000927
2022-09-29 23:56:03 - train: epoch 0155, iter [00010, 01251], lr: 0.000927, loss: 0.4098
2022-09-29 23:56:21 - train: epoch 0155, iter [00020, 01251], lr: 0.000927, loss: 0.4046
2022-09-29 23:56:38 - train: epoch 0155, iter [00030, 01251], lr: 0.000927, loss: 0.4261
2022-09-29 23:56:56 - train: epoch 0155, iter [00040, 01251], lr: 0.000927, loss: 0.4189
2022-09-29 23:57:13 - train: epoch 0155, iter [00050, 01251], lr: 0.000927, loss: 0.4075
2022-09-29 23:57:31 - train: epoch 0155, iter [00060, 01251], lr: 0.000927, loss: 0.3831
2022-09-29 23:57:48 - train: epoch 0155, iter [00070, 01251], lr: 0.000927, loss: 0.4187
2022-09-29 23:58:06 - train: epoch 0155, iter [00080, 01251], lr: 0.000927, loss: 0.4171
2022-09-29 23:58:24 - train: epoch 0155, iter [00090, 01251], lr: 0.000926, loss: 0.4103
2022-09-29 23:58:41 - train: epoch 0155, iter [00100, 01251], lr: 0.000926, loss: 0.3929
2022-09-29 23:58:59 - train: epoch 0155, iter [00110, 01251], lr: 0.000926, loss: 0.4090
2022-09-29 23:59:17 - train: epoch 0155, iter [00120, 01251], lr: 0.000926, loss: 0.4280
2022-09-29 23:59:34 - train: epoch 0155, iter [00130, 01251], lr: 0.000926, loss: 0.4225
2022-09-29 23:59:52 - train: epoch 0155, iter [00140, 01251], lr: 0.000926, loss: 0.4092
2022-09-30 00:00:09 - train: epoch 0155, iter [00150, 01251], lr: 0.000926, loss: 0.4231
2022-09-30 00:00:27 - train: epoch 0155, iter [00160, 01251], lr: 0.000926, loss: 0.4100
2022-09-30 00:00:45 - train: epoch 0155, iter [00170, 01251], lr: 0.000926, loss: 0.4073
2022-09-30 00:01:03 - train: epoch 0155, iter [00180, 01251], lr: 0.000926, loss: 0.4155
2022-09-30 00:01:21 - train: epoch 0155, iter [00190, 01251], lr: 0.000926, loss: 0.4254
2022-09-30 00:01:38 - train: epoch 0155, iter [00200, 01251], lr: 0.000926, loss: 0.4334
2022-09-30 00:01:56 - train: epoch 0155, iter [00210, 01251], lr: 0.000926, loss: 0.4077
2022-09-30 00:02:14 - train: epoch 0155, iter [00220, 01251], lr: 0.000926, loss: 0.4048
2022-09-30 00:02:31 - train: epoch 0155, iter [00230, 01251], lr: 0.000926, loss: 0.4217
2022-09-30 00:02:49 - train: epoch 0155, iter [00240, 01251], lr: 0.000926, loss: 0.4136
2022-09-30 00:03:07 - train: epoch 0155, iter [00250, 01251], lr: 0.000926, loss: 0.3924
2022-09-30 00:03:24 - train: epoch 0155, iter [00260, 01251], lr: 0.000926, loss: 0.4116
2022-09-30 00:03:42 - train: epoch 0155, iter [00270, 01251], lr: 0.000926, loss: 0.3865
2022-09-30 00:03:59 - train: epoch 0155, iter [00280, 01251], lr: 0.000926, loss: 0.4209
2022-09-30 00:04:17 - train: epoch 0155, iter [00290, 01251], lr: 0.000926, loss: 0.4017
2022-09-30 00:04:34 - train: epoch 0155, iter [00300, 01251], lr: 0.000926, loss: 0.4176
2022-09-30 00:04:52 - train: epoch 0155, iter [00310, 01251], lr: 0.000926, loss: 0.4048
2022-09-30 00:05:10 - train: epoch 0155, iter [00320, 01251], lr: 0.000926, loss: 0.4021
2022-09-30 00:05:27 - train: epoch 0155, iter [00330, 01251], lr: 0.000926, loss: 0.4257
2022-09-30 00:05:45 - train: epoch 0155, iter [00340, 01251], lr: 0.000926, loss: 0.4053
2022-09-30 00:06:02 - train: epoch 0155, iter [00350, 01251], lr: 0.000926, loss: 0.4128
2022-09-30 00:06:20 - train: epoch 0155, iter [00360, 01251], lr: 0.000926, loss: 0.4168
2022-09-30 00:06:38 - train: epoch 0155, iter [00370, 01251], lr: 0.000925, loss: 0.4260
2022-09-30 00:06:56 - train: epoch 0155, iter [00380, 01251], lr: 0.000925, loss: 0.4039
2022-09-30 00:07:14 - train: epoch 0155, iter [00390, 01251], lr: 0.000925, loss: 0.4003
2022-09-30 00:07:32 - train: epoch 0155, iter [00400, 01251], lr: 0.000925, loss: 0.4238
2022-09-30 00:07:50 - train: epoch 0155, iter [00410, 01251], lr: 0.000925, loss: 0.4164
2022-09-30 00:08:08 - train: epoch 0155, iter [00420, 01251], lr: 0.000925, loss: 0.4114
2022-09-30 00:08:25 - train: epoch 0155, iter [00430, 01251], lr: 0.000925, loss: 0.4309
2022-09-30 00:08:43 - train: epoch 0155, iter [00440, 01251], lr: 0.000925, loss: 0.3988
2022-09-30 00:09:01 - train: epoch 0155, iter [00450, 01251], lr: 0.000925, loss: 0.4117
2022-09-30 00:09:18 - train: epoch 0155, iter [00460, 01251], lr: 0.000925, loss: 0.3878
2022-09-30 00:09:36 - train: epoch 0155, iter [00470, 01251], lr: 0.000925, loss: 0.4079
2022-09-30 00:09:53 - train: epoch 0155, iter [00480, 01251], lr: 0.000925, loss: 0.4097
2022-09-30 00:10:11 - train: epoch 0155, iter [00490, 01251], lr: 0.000925, loss: 0.3970
2022-09-30 00:10:29 - train: epoch 0155, iter [00500, 01251], lr: 0.000925, loss: 0.4025
2022-09-30 00:10:46 - train: epoch 0155, iter [00510, 01251], lr: 0.000925, loss: 0.4058
2022-09-30 00:11:04 - train: epoch 0155, iter [00520, 01251], lr: 0.000925, loss: 0.4038
2022-09-30 00:11:21 - train: epoch 0155, iter [00530, 01251], lr: 0.000925, loss: 0.4214
2022-09-30 00:11:39 - train: epoch 0155, iter [00540, 01251], lr: 0.000925, loss: 0.4076
2022-09-30 00:11:56 - train: epoch 0155, iter [00550, 01251], lr: 0.000925, loss: 0.4089
2022-09-30 00:12:14 - train: epoch 0155, iter [00560, 01251], lr: 0.000925, loss: 0.4230
2022-09-30 00:12:32 - train: epoch 0155, iter [00570, 01251], lr: 0.000925, loss: 0.4236
2022-09-30 00:12:49 - train: epoch 0155, iter [00580, 01251], lr: 0.000925, loss: 0.4040
2022-09-30 00:13:07 - train: epoch 0155, iter [00590, 01251], lr: 0.000925, loss: 0.4013
2022-09-30 00:13:24 - train: epoch 0155, iter [00600, 01251], lr: 0.000925, loss: 0.4189
2022-09-30 00:13:42 - train: epoch 0155, iter [00610, 01251], lr: 0.000925, loss: 0.4105
2022-09-30 00:14:00 - train: epoch 0155, iter [00620, 01251], lr: 0.000925, loss: 0.3914
2022-09-30 00:14:17 - train: epoch 0155, iter [00630, 01251], lr: 0.000925, loss: 0.4048
2022-09-30 00:14:35 - train: epoch 0155, iter [00640, 01251], lr: 0.000925, loss: 0.3970
2022-09-30 00:14:52 - train: epoch 0155, iter [00650, 01251], lr: 0.000924, loss: 0.4111
2022-09-30 00:15:10 - train: epoch 0155, iter [00660, 01251], lr: 0.000924, loss: 0.3987
2022-09-30 00:15:27 - train: epoch 0155, iter [00670, 01251], lr: 0.000924, loss: 0.4254
2022-09-30 00:15:45 - train: epoch 0155, iter [00680, 01251], lr: 0.000924, loss: 0.3994
2022-09-30 00:16:03 - train: epoch 0155, iter [00690, 01251], lr: 0.000924, loss: 0.4278
2022-09-30 00:16:20 - train: epoch 0155, iter [00700, 01251], lr: 0.000924, loss: 0.4209
2022-09-30 00:16:38 - train: epoch 0155, iter [00710, 01251], lr: 0.000924, loss: 0.3964
2022-09-30 00:16:55 - train: epoch 0155, iter [00720, 01251], lr: 0.000924, loss: 0.3939
2022-09-30 00:17:13 - train: epoch 0155, iter [00730, 01251], lr: 0.000924, loss: 0.3998
2022-09-30 00:17:30 - train: epoch 0155, iter [00740, 01251], lr: 0.000924, loss: 0.4187
2022-09-30 00:17:48 - train: epoch 0155, iter [00750, 01251], lr: 0.000924, loss: 0.4134
2022-09-30 00:18:05 - train: epoch 0155, iter [00760, 01251], lr: 0.000924, loss: 0.4257
2022-09-30 00:18:23 - train: epoch 0155, iter [00770, 01251], lr: 0.000924, loss: 0.4164
2022-09-30 00:18:41 - train: epoch 0155, iter [00780, 01251], lr: 0.000924, loss: 0.4170
2022-09-30 00:18:59 - train: epoch 0155, iter [00790, 01251], lr: 0.000924, loss: 0.4227
2022-09-30 00:19:16 - train: epoch 0155, iter [00800, 01251], lr: 0.000924, loss: 0.3902
2022-09-30 00:19:34 - train: epoch 0155, iter [00810, 01251], lr: 0.000924, loss: 0.4173
2022-09-30 00:19:52 - train: epoch 0155, iter [00820, 01251], lr: 0.000924, loss: 0.4171
2022-09-30 00:20:09 - train: epoch 0155, iter [00830, 01251], lr: 0.000924, loss: 0.4018
2022-09-30 00:20:27 - train: epoch 0155, iter [00840, 01251], lr: 0.000924, loss: 0.4255
2022-09-30 00:20:45 - train: epoch 0155, iter [00850, 01251], lr: 0.000924, loss: 0.4074
2022-09-30 00:21:02 - train: epoch 0155, iter [00860, 01251], lr: 0.000924, loss: 0.3902
2022-09-30 00:21:20 - train: epoch 0155, iter [00870, 01251], lr: 0.000924, loss: 0.3978
2022-09-30 00:21:38 - train: epoch 0155, iter [00880, 01251], lr: 0.000924, loss: 0.4154
2022-09-30 00:21:55 - train: epoch 0155, iter [00890, 01251], lr: 0.000924, loss: 0.3968
2022-09-30 00:22:13 - train: epoch 0155, iter [00900, 01251], lr: 0.000924, loss: 0.4034
2022-09-30 00:22:30 - train: epoch 0155, iter [00910, 01251], lr: 0.000924, loss: 0.3941
2022-09-30 00:22:48 - train: epoch 0155, iter [00920, 01251], lr: 0.000924, loss: 0.4088
2022-09-30 00:23:05 - train: epoch 0155, iter [00930, 01251], lr: 0.000924, loss: 0.4163
2022-09-30 00:23:23 - train: epoch 0155, iter [00940, 01251], lr: 0.000923, loss: 0.4148
2022-09-30 00:23:41 - train: epoch 0155, iter [00950, 01251], lr: 0.000923, loss: 0.4168
2022-09-30 00:23:59 - train: epoch 0155, iter [00960, 01251], lr: 0.000923, loss: 0.4150
2022-09-30 00:24:17 - train: epoch 0155, iter [00970, 01251], lr: 0.000923, loss: 0.4014
2022-09-30 00:24:35 - train: epoch 0155, iter [00980, 01251], lr: 0.000923, loss: 0.4115
2022-09-30 00:24:52 - train: epoch 0155, iter [00990, 01251], lr: 0.000923, loss: 0.4009
2022-09-30 00:25:10 - train: epoch 0155, iter [01000, 01251], lr: 0.000923, loss: 0.4115
2022-09-30 00:25:27 - train: epoch 0155, iter [01010, 01251], lr: 0.000923, loss: 0.4194
2022-09-30 00:25:45 - train: epoch 0155, iter [01020, 01251], lr: 0.000923, loss: 0.4169
2022-09-30 00:26:03 - train: epoch 0155, iter [01030, 01251], lr: 0.000923, loss: 0.4105
2022-09-30 00:26:20 - train: epoch 0155, iter [01040, 01251], lr: 0.000923, loss: 0.3987
2022-09-30 00:26:38 - train: epoch 0155, iter [01050, 01251], lr: 0.000923, loss: 0.4079
2022-09-30 00:26:55 - train: epoch 0155, iter [01060, 01251], lr: 0.000923, loss: 0.4155
2022-09-30 00:27:13 - train: epoch 0155, iter [01070, 01251], lr: 0.000923, loss: 0.3916
2022-09-30 00:27:30 - train: epoch 0155, iter [01080, 01251], lr: 0.000923, loss: 0.4165
2022-09-30 00:27:48 - train: epoch 0155, iter [01090, 01251], lr: 0.000923, loss: 0.4084
2022-09-30 00:28:06 - train: epoch 0155, iter [01100, 01251], lr: 0.000923, loss: 0.4132
2022-09-30 00:28:23 - train: epoch 0155, iter [01110, 01251], lr: 0.000923, loss: 0.4151
2022-09-30 00:28:41 - train: epoch 0155, iter [01120, 01251], lr: 0.000923, loss: 0.4082
2022-09-30 00:28:58 - train: epoch 0155, iter [01130, 01251], lr: 0.000923, loss: 0.4077
2022-09-30 00:29:16 - train: epoch 0155, iter [01140, 01251], lr: 0.000923, loss: 0.4110
2022-09-30 00:29:33 - train: epoch 0155, iter [01150, 01251], lr: 0.000923, loss: 0.4040
2022-09-30 00:29:51 - train: epoch 0155, iter [01160, 01251], lr: 0.000923, loss: 0.4140
2022-09-30 00:30:09 - train: epoch 0155, iter [01170, 01251], lr: 0.000923, loss: 0.4105
2022-09-30 00:30:26 - train: epoch 0155, iter [01180, 01251], lr: 0.000923, loss: 0.4024
2022-09-30 00:30:44 - train: epoch 0155, iter [01190, 01251], lr: 0.000923, loss: 0.4103
2022-09-30 00:31:01 - train: epoch 0155, iter [01200, 01251], lr: 0.000923, loss: 0.4126
2022-09-30 00:31:19 - train: epoch 0155, iter [01210, 01251], lr: 0.000923, loss: 0.4010
2022-09-30 00:31:37 - train: epoch 0155, iter [01220, 01251], lr: 0.000922, loss: 0.4084
2022-09-30 00:31:54 - train: epoch 0155, iter [01230, 01251], lr: 0.000922, loss: 0.4109
2022-09-30 00:32:12 - train: epoch 0155, iter [01240, 01251], lr: 0.000922, loss: 0.4156
2022-09-30 00:32:29 - train: epoch 0155, iter [01250, 01251], lr: 0.000922, loss: 0.3775
2022-09-30 00:32:32 - train: epoch 155, train_loss: 0.4101
2022-09-30 00:32:35 - until epoch: 155, best_loss: 0.4101
2022-09-30 00:32:35 - epoch 156 lr: 0.000922
2022-09-30 00:33:01 - train: epoch 0156, iter [00010, 01251], lr: 0.000922, loss: 0.4140
2022-09-30 00:33:19 - train: epoch 0156, iter [00020, 01251], lr: 0.000922, loss: 0.3838
2022-09-30 00:33:37 - train: epoch 0156, iter [00030, 01251], lr: 0.000922, loss: 0.4240
2022-09-30 00:33:54 - train: epoch 0156, iter [00040, 01251], lr: 0.000922, loss: 0.4003
2022-09-30 00:34:12 - train: epoch 0156, iter [00050, 01251], lr: 0.000922, loss: 0.4079
2022-09-30 00:34:30 - train: epoch 0156, iter [00060, 01251], lr: 0.000922, loss: 0.4027
2022-09-30 00:34:48 - train: epoch 0156, iter [00070, 01251], lr: 0.000922, loss: 0.4132
2022-09-30 00:35:06 - train: epoch 0156, iter [00080, 01251], lr: 0.000922, loss: 0.3915
2022-09-30 00:35:24 - train: epoch 0156, iter [00090, 01251], lr: 0.000922, loss: 0.4180
2022-09-30 00:35:42 - train: epoch 0156, iter [00100, 01251], lr: 0.000922, loss: 0.3919
2022-09-30 00:36:00 - train: epoch 0156, iter [00110, 01251], lr: 0.000922, loss: 0.4077
2022-09-30 00:36:18 - train: epoch 0156, iter [00120, 01251], lr: 0.000922, loss: 0.4245
2022-09-30 00:36:36 - train: epoch 0156, iter [00130, 01251], lr: 0.000922, loss: 0.4058
2022-09-30 00:36:53 - train: epoch 0156, iter [00140, 01251], lr: 0.000922, loss: 0.3975
2022-09-30 00:37:11 - train: epoch 0156, iter [00150, 01251], lr: 0.000922, loss: 0.4221
2022-09-30 00:37:29 - train: epoch 0156, iter [00160, 01251], lr: 0.000922, loss: 0.4185
2022-09-30 00:37:47 - train: epoch 0156, iter [00170, 01251], lr: 0.000922, loss: 0.3975
2022-09-30 00:38:04 - train: epoch 0156, iter [00180, 01251], lr: 0.000922, loss: 0.4169
2022-09-30 00:38:22 - train: epoch 0156, iter [00190, 01251], lr: 0.000922, loss: 0.4165
2022-09-30 00:38:40 - train: epoch 0156, iter [00200, 01251], lr: 0.000922, loss: 0.4110
2022-09-30 00:38:58 - train: epoch 0156, iter [00210, 01251], lr: 0.000922, loss: 0.4041
2022-09-30 00:39:15 - train: epoch 0156, iter [00220, 01251], lr: 0.000922, loss: 0.3935
2022-09-30 00:39:33 - train: epoch 0156, iter [00230, 01251], lr: 0.000922, loss: 0.4030
2022-09-30 00:39:51 - train: epoch 0156, iter [00240, 01251], lr: 0.000922, loss: 0.4237
2022-09-30 00:40:09 - train: epoch 0156, iter [00250, 01251], lr: 0.000921, loss: 0.4215
2022-09-30 00:40:27 - train: epoch 0156, iter [00260, 01251], lr: 0.000921, loss: 0.4047
2022-09-30 00:40:44 - train: epoch 0156, iter [00270, 01251], lr: 0.000921, loss: 0.4124
2022-09-30 00:41:02 - train: epoch 0156, iter [00280, 01251], lr: 0.000921, loss: 0.4091
2022-09-30 00:41:20 - train: epoch 0156, iter [00290, 01251], lr: 0.000921, loss: 0.4235
2022-09-30 00:41:38 - train: epoch 0156, iter [00300, 01251], lr: 0.000921, loss: 0.4194
2022-09-30 00:41:56 - train: epoch 0156, iter [00310, 01251], lr: 0.000921, loss: 0.4172
2022-09-30 00:42:14 - train: epoch 0156, iter [00320, 01251], lr: 0.000921, loss: 0.4061
2022-09-30 00:42:32 - train: epoch 0156, iter [00330, 01251], lr: 0.000921, loss: 0.4240
2022-09-30 00:42:50 - train: epoch 0156, iter [00340, 01251], lr: 0.000921, loss: 0.4026
2022-09-30 00:43:08 - train: epoch 0156, iter [00350, 01251], lr: 0.000921, loss: 0.3975
2022-09-30 00:43:26 - train: epoch 0156, iter [00360, 01251], lr: 0.000921, loss: 0.4202
2022-09-30 00:43:44 - train: epoch 0156, iter [00370, 01251], lr: 0.000921, loss: 0.3890
2022-09-30 00:44:02 - train: epoch 0156, iter [00380, 01251], lr: 0.000921, loss: 0.3925
2022-09-30 00:44:20 - train: epoch 0156, iter [00390, 01251], lr: 0.000921, loss: 0.4170
2022-09-30 00:44:37 - train: epoch 0156, iter [00400, 01251], lr: 0.000921, loss: 0.4160
2022-09-30 00:44:55 - train: epoch 0156, iter [00410, 01251], lr: 0.000921, loss: 0.4306
2022-09-30 00:45:12 - train: epoch 0156, iter [00420, 01251], lr: 0.000921, loss: 0.4216
2022-09-30 00:45:30 - train: epoch 0156, iter [00430, 01251], lr: 0.000921, loss: 0.4182
2022-09-30 00:45:48 - train: epoch 0156, iter [00440, 01251], lr: 0.000921, loss: 0.4135
2022-09-30 00:46:05 - train: epoch 0156, iter [00450, 01251], lr: 0.000921, loss: 0.4187
2022-09-30 00:46:23 - train: epoch 0156, iter [00460, 01251], lr: 0.000921, loss: 0.3951
2022-09-30 00:46:40 - train: epoch 0156, iter [00470, 01251], lr: 0.000921, loss: 0.3920
2022-09-30 00:46:58 - train: epoch 0156, iter [00480, 01251], lr: 0.000921, loss: 0.4192
2022-09-30 00:47:16 - train: epoch 0156, iter [00490, 01251], lr: 0.000921, loss: 0.4146
2022-09-30 00:47:33 - train: epoch 0156, iter [00500, 01251], lr: 0.000921, loss: 0.4219
2022-09-30 00:47:51 - train: epoch 0156, iter [00510, 01251], lr: 0.000921, loss: 0.3979
2022-09-30 00:48:09 - train: epoch 0156, iter [00520, 01251], lr: 0.000921, loss: 0.4175
2022-09-30 00:48:26 - train: epoch 0156, iter [00530, 01251], lr: 0.000921, loss: 0.3879
2022-09-30 00:48:44 - train: epoch 0156, iter [00540, 01251], lr: 0.000920, loss: 0.4171
2022-09-30 00:49:02 - train: epoch 0156, iter [00550, 01251], lr: 0.000920, loss: 0.3838
2022-09-30 00:49:20 - train: epoch 0156, iter [00560, 01251], lr: 0.000920, loss: 0.4306
2022-09-30 00:49:37 - train: epoch 0156, iter [00570, 01251], lr: 0.000920, loss: 0.4173
2022-09-30 00:49:55 - train: epoch 0156, iter [00580, 01251], lr: 0.000920, loss: 0.4140
2022-09-30 00:50:13 - train: epoch 0156, iter [00590, 01251], lr: 0.000920, loss: 0.3988
2022-09-30 00:50:30 - train: epoch 0156, iter [00600, 01251], lr: 0.000920, loss: 0.4062
2022-09-30 00:50:48 - train: epoch 0156, iter [00610, 01251], lr: 0.000920, loss: 0.4049
2022-09-30 00:51:06 - train: epoch 0156, iter [00620, 01251], lr: 0.000920, loss: 0.4335
2022-09-30 00:51:24 - train: epoch 0156, iter [00630, 01251], lr: 0.000920, loss: 0.4023
2022-09-30 00:51:42 - train: epoch 0156, iter [00640, 01251], lr: 0.000920, loss: 0.4144
2022-09-30 00:51:59 - train: epoch 0156, iter [00650, 01251], lr: 0.000920, loss: 0.4116
2022-09-30 00:52:17 - train: epoch 0156, iter [00660, 01251], lr: 0.000920, loss: 0.4290
2022-09-30 00:52:35 - train: epoch 0156, iter [00670, 01251], lr: 0.000920, loss: 0.3987
2022-09-30 00:52:52 - train: epoch 0156, iter [00680, 01251], lr: 0.000920, loss: 0.3993
2022-09-30 00:53:10 - train: epoch 0156, iter [00690, 01251], lr: 0.000920, loss: 0.4021
2022-09-30 00:53:27 - train: epoch 0156, iter [00700, 01251], lr: 0.000920, loss: 0.3972
2022-09-30 00:53:45 - train: epoch 0156, iter [00710, 01251], lr: 0.000920, loss: 0.4164
2022-09-30 00:54:03 - train: epoch 0156, iter [00720, 01251], lr: 0.000920, loss: 0.4285
2022-09-30 00:54:21 - train: epoch 0156, iter [00730, 01251], lr: 0.000920, loss: 0.4076
2022-09-30 00:54:38 - train: epoch 0156, iter [00740, 01251], lr: 0.000920, loss: 0.4105
2022-09-30 00:54:55 - train: epoch 0156, iter [00750, 01251], lr: 0.000920, loss: 0.4087
2022-09-30 00:55:13 - train: epoch 0156, iter [00760, 01251], lr: 0.000920, loss: 0.4086
2022-09-30 00:55:31 - train: epoch 0156, iter [00770, 01251], lr: 0.000920, loss: 0.4127
2022-09-30 00:55:49 - train: epoch 0156, iter [00780, 01251], lr: 0.000920, loss: 0.4016
2022-09-30 00:56:06 - train: epoch 0156, iter [00790, 01251], lr: 0.000920, loss: 0.4141
2022-09-30 00:56:24 - train: epoch 0156, iter [00800, 01251], lr: 0.000920, loss: 0.3764
2022-09-30 00:56:41 - train: epoch 0156, iter [00810, 01251], lr: 0.000920, loss: 0.4239
2022-09-30 00:56:59 - train: epoch 0156, iter [00820, 01251], lr: 0.000919, loss: 0.4112
2022-09-30 00:57:16 - train: epoch 0156, iter [00830, 01251], lr: 0.000919, loss: 0.4210
2022-09-30 00:57:34 - train: epoch 0156, iter [00840, 01251], lr: 0.000919, loss: 0.4118
2022-09-30 00:57:52 - train: epoch 0156, iter [00850, 01251], lr: 0.000919, loss: 0.4155
2022-09-30 00:58:10 - train: epoch 0156, iter [00860, 01251], lr: 0.000919, loss: 0.4205
2022-09-30 00:58:27 - train: epoch 0156, iter [00870, 01251], lr: 0.000919, loss: 0.4098
2022-09-30 00:58:45 - train: epoch 0156, iter [00880, 01251], lr: 0.000919, loss: 0.4258
2022-09-30 00:59:03 - train: epoch 0156, iter [00890, 01251], lr: 0.000919, loss: 0.4031
2022-09-30 00:59:21 - train: epoch 0156, iter [00900, 01251], lr: 0.000919, loss: 0.4120
2022-09-30 00:59:39 - train: epoch 0156, iter [00910, 01251], lr: 0.000919, loss: 0.4347
2022-09-30 00:59:57 - train: epoch 0156, iter [00920, 01251], lr: 0.000919, loss: 0.4054
2022-09-30 01:00:15 - train: epoch 0156, iter [00930, 01251], lr: 0.000919, loss: 0.4096
2022-09-30 01:00:33 - train: epoch 0156, iter [00940, 01251], lr: 0.000919, loss: 0.4105
2022-09-30 01:00:51 - train: epoch 0156, iter [00950, 01251], lr: 0.000919, loss: 0.4021
2022-09-30 01:01:09 - train: epoch 0156, iter [00960, 01251], lr: 0.000919, loss: 0.3982
2022-09-30 01:01:26 - train: epoch 0156, iter [00970, 01251], lr: 0.000919, loss: 0.4173
2022-09-30 01:01:44 - train: epoch 0156, iter [00980, 01251], lr: 0.000919, loss: 0.4106
2022-09-30 01:02:02 - train: epoch 0156, iter [00990, 01251], lr: 0.000919, loss: 0.3943
2022-09-30 01:02:20 - train: epoch 0156, iter [01000, 01251], lr: 0.000919, loss: 0.4088
2022-09-30 01:02:38 - train: epoch 0156, iter [01010, 01251], lr: 0.000919, loss: 0.4267
2022-09-30 01:02:56 - train: epoch 0156, iter [01020, 01251], lr: 0.000919, loss: 0.4136
2022-09-30 01:03:13 - train: epoch 0156, iter [01030, 01251], lr: 0.000919, loss: 0.4270
2022-09-30 01:03:31 - train: epoch 0156, iter [01040, 01251], lr: 0.000919, loss: 0.4006
2022-09-30 01:03:49 - train: epoch 0156, iter [01050, 01251], lr: 0.000919, loss: 0.3813
2022-09-30 01:04:07 - train: epoch 0156, iter [01060, 01251], lr: 0.000919, loss: 0.3840
2022-09-30 01:04:25 - train: epoch 0156, iter [01070, 01251], lr: 0.000919, loss: 0.3963
2022-09-30 01:04:43 - train: epoch 0156, iter [01080, 01251], lr: 0.000919, loss: 0.3877
2022-09-30 01:05:01 - train: epoch 0156, iter [01090, 01251], lr: 0.000919, loss: 0.3966
2022-09-30 01:05:19 - train: epoch 0156, iter [01100, 01251], lr: 0.000918, loss: 0.4234
2022-09-30 01:05:36 - train: epoch 0156, iter [01110, 01251], lr: 0.000918, loss: 0.4203
2022-09-30 01:05:54 - train: epoch 0156, iter [01120, 01251], lr: 0.000918, loss: 0.4010
2022-09-30 01:06:12 - train: epoch 0156, iter [01130, 01251], lr: 0.000918, loss: 0.4107
2022-09-30 01:06:30 - train: epoch 0156, iter [01140, 01251], lr: 0.000918, loss: 0.4151
2022-09-30 01:06:48 - train: epoch 0156, iter [01150, 01251], lr: 0.000918, loss: 0.4195
2022-09-30 01:07:06 - train: epoch 0156, iter [01160, 01251], lr: 0.000918, loss: 0.4083
2022-09-30 01:07:24 - train: epoch 0156, iter [01170, 01251], lr: 0.000918, loss: 0.4071
2022-09-30 01:07:42 - train: epoch 0156, iter [01180, 01251], lr: 0.000918, loss: 0.4020
2022-09-30 01:08:00 - train: epoch 0156, iter [01190, 01251], lr: 0.000918, loss: 0.4033
2022-09-30 01:08:18 - train: epoch 0156, iter [01200, 01251], lr: 0.000918, loss: 0.4106
2022-09-30 01:08:36 - train: epoch 0156, iter [01210, 01251], lr: 0.000918, loss: 0.3856
2022-09-30 01:08:54 - train: epoch 0156, iter [01220, 01251], lr: 0.000918, loss: 0.4066
2022-09-30 01:09:12 - train: epoch 0156, iter [01230, 01251], lr: 0.000918, loss: 0.4161
2022-09-30 01:09:30 - train: epoch 0156, iter [01240, 01251], lr: 0.000918, loss: 0.4120
2022-09-30 01:09:48 - train: epoch 0156, iter [01250, 01251], lr: 0.000918, loss: 0.4142
2022-09-30 01:09:51 - train: epoch 156, train_loss: 0.4101
2022-09-30 01:09:54 - until epoch: 156, best_loss: 0.4101
2022-09-30 01:09:54 - epoch 157 lr: 0.000918
2022-09-30 01:10:19 - train: epoch 0157, iter [00010, 01251], lr: 0.000918, loss: 0.4011
2022-09-30 01:10:37 - train: epoch 0157, iter [00020, 01251], lr: 0.000918, loss: 0.4222
2022-09-30 01:10:55 - train: epoch 0157, iter [00030, 01251], lr: 0.000918, loss: 0.3936
2022-09-30 01:11:13 - train: epoch 0157, iter [00040, 01251], lr: 0.000918, loss: 0.4289
2022-09-30 01:11:30 - train: epoch 0157, iter [00050, 01251], lr: 0.000918, loss: 0.4019
2022-09-30 01:11:48 - train: epoch 0157, iter [00060, 01251], lr: 0.000918, loss: 0.4286
2022-09-30 01:12:06 - train: epoch 0157, iter [00070, 01251], lr: 0.000918, loss: 0.4143
2022-09-30 01:12:24 - train: epoch 0157, iter [00080, 01251], lr: 0.000918, loss: 0.4123
2022-09-30 01:12:42 - train: epoch 0157, iter [00090, 01251], lr: 0.000918, loss: 0.3870
2022-09-30 01:13:00 - train: epoch 0157, iter [00100, 01251], lr: 0.000918, loss: 0.4217
2022-09-30 01:13:18 - train: epoch 0157, iter [00110, 01251], lr: 0.000918, loss: 0.4130
2022-09-30 01:13:36 - train: epoch 0157, iter [00120, 01251], lr: 0.000918, loss: 0.3952
2022-09-30 01:13:54 - train: epoch 0157, iter [00130, 01251], lr: 0.000917, loss: 0.4208
2022-09-30 01:14:11 - train: epoch 0157, iter [00140, 01251], lr: 0.000917, loss: 0.3967
2022-09-30 01:14:29 - train: epoch 0157, iter [00150, 01251], lr: 0.000917, loss: 0.4165
2022-09-30 01:14:47 - train: epoch 0157, iter [00160, 01251], lr: 0.000917, loss: 0.3831
2022-09-30 01:15:05 - train: epoch 0157, iter [00170, 01251], lr: 0.000917, loss: 0.3932
2022-09-30 01:15:23 - train: epoch 0157, iter [00180, 01251], lr: 0.000917, loss: 0.4052
2022-09-30 01:15:41 - train: epoch 0157, iter [00190, 01251], lr: 0.000917, loss: 0.4101
2022-09-30 01:15:59 - train: epoch 0157, iter [00200, 01251], lr: 0.000917, loss: 0.3999
2022-09-30 01:16:17 - train: epoch 0157, iter [00210, 01251], lr: 0.000917, loss: 0.4078
2022-09-30 01:16:34 - train: epoch 0157, iter [00220, 01251], lr: 0.000917, loss: 0.4130
2022-09-30 01:16:52 - train: epoch 0157, iter [00230, 01251], lr: 0.000917, loss: 0.4097
2022-09-30 01:17:10 - train: epoch 0157, iter [00240, 01251], lr: 0.000917, loss: 0.3908
2022-09-30 01:17:28 - train: epoch 0157, iter [00250, 01251], lr: 0.000917, loss: 0.4157
2022-09-30 01:17:46 - train: epoch 0157, iter [00260, 01251], lr: 0.000917, loss: 0.4156
2022-09-30 01:18:04 - train: epoch 0157, iter [00270, 01251], lr: 0.000917, loss: 0.4023
2022-09-30 01:18:22 - train: epoch 0157, iter [00280, 01251], lr: 0.000917, loss: 0.4051
2022-09-30 01:18:39 - train: epoch 0157, iter [00290, 01251], lr: 0.000917, loss: 0.4077
2022-09-30 01:18:57 - train: epoch 0157, iter [00300, 01251], lr: 0.000917, loss: 0.3872
2022-09-30 01:19:15 - train: epoch 0157, iter [00310, 01251], lr: 0.000917, loss: 0.4260
2022-09-30 01:19:33 - train: epoch 0157, iter [00320, 01251], lr: 0.000917, loss: 0.4034
2022-09-30 01:19:51 - train: epoch 0157, iter [00330, 01251], lr: 0.000917, loss: 0.4317
2022-09-30 01:20:08 - train: epoch 0157, iter [00340, 01251], lr: 0.000917, loss: 0.4131
2022-09-30 01:20:26 - train: epoch 0157, iter [00350, 01251], lr: 0.000917, loss: 0.4156
2022-09-30 01:20:44 - train: epoch 0157, iter [00360, 01251], lr: 0.000917, loss: 0.4045
2022-09-30 01:21:02 - train: epoch 0157, iter [00370, 01251], lr: 0.000917, loss: 0.4126
2022-09-30 01:21:20 - train: epoch 0157, iter [00380, 01251], lr: 0.000917, loss: 0.4108
2022-09-30 01:21:37 - train: epoch 0157, iter [00390, 01251], lr: 0.000917, loss: 0.4320
2022-09-30 01:21:55 - train: epoch 0157, iter [00400, 01251], lr: 0.000917, loss: 0.4134
2022-09-30 01:22:13 - train: epoch 0157, iter [00410, 01251], lr: 0.000916, loss: 0.3971
2022-09-30 01:22:31 - train: epoch 0157, iter [00420, 01251], lr: 0.000916, loss: 0.4090
2022-09-30 01:22:49 - train: epoch 0157, iter [00430, 01251], lr: 0.000916, loss: 0.4129
2022-09-30 01:23:07 - train: epoch 0157, iter [00440, 01251], lr: 0.000916, loss: 0.4142
2022-09-30 01:23:25 - train: epoch 0157, iter [00450, 01251], lr: 0.000916, loss: 0.4088
2022-09-30 01:23:42 - train: epoch 0157, iter [00460, 01251], lr: 0.000916, loss: 0.3977
2022-09-30 01:24:00 - train: epoch 0157, iter [00470, 01251], lr: 0.000916, loss: 0.4030
2022-09-30 01:24:18 - train: epoch 0157, iter [00480, 01251], lr: 0.000916, loss: 0.4045
2022-09-30 01:24:36 - train: epoch 0157, iter [00490, 01251], lr: 0.000916, loss: 0.4020
2022-09-30 01:24:54 - train: epoch 0157, iter [00500, 01251], lr: 0.000916, loss: 0.4128
2022-09-30 01:25:12 - train: epoch 0157, iter [00510, 01251], lr: 0.000916, loss: 0.4138
2022-09-30 01:25:30 - train: epoch 0157, iter [00520, 01251], lr: 0.000916, loss: 0.4046
2022-09-30 01:25:48 - train: epoch 0157, iter [00530, 01251], lr: 0.000916, loss: 0.4099
2022-09-30 01:26:06 - train: epoch 0157, iter [00540, 01251], lr: 0.000916, loss: 0.4373
2022-09-30 01:26:24 - train: epoch 0157, iter [00550, 01251], lr: 0.000916, loss: 0.4135
2022-09-30 01:26:42 - train: epoch 0157, iter [00560, 01251], lr: 0.000916, loss: 0.4235
2022-09-30 01:26:59 - train: epoch 0157, iter [00570, 01251], lr: 0.000916, loss: 0.4204
2022-09-30 01:27:18 - train: epoch 0157, iter [00580, 01251], lr: 0.000916, loss: 0.4033
2022-09-30 01:27:35 - train: epoch 0157, iter [00590, 01251], lr: 0.000916, loss: 0.4265
2022-09-30 01:27:53 - train: epoch 0157, iter [00600, 01251], lr: 0.000916, loss: 0.4008
2022-09-30 01:28:11 - train: epoch 0157, iter [00610, 01251], lr: 0.000916, loss: 0.4276
2022-09-30 01:28:29 - train: epoch 0157, iter [00620, 01251], lr: 0.000916, loss: 0.3790
2022-09-30 01:28:47 - train: epoch 0157, iter [00630, 01251], lr: 0.000916, loss: 0.4091
2022-09-30 01:29:05 - train: epoch 0157, iter [00640, 01251], lr: 0.000916, loss: 0.4034
2022-09-30 01:29:23 - train: epoch 0157, iter [00650, 01251], lr: 0.000916, loss: 0.4198
2022-09-30 01:29:40 - train: epoch 0157, iter [00660, 01251], lr: 0.000916, loss: 0.4297
2022-09-30 01:29:58 - train: epoch 0157, iter [00670, 01251], lr: 0.000916, loss: 0.4055
2022-09-30 01:30:16 - train: epoch 0157, iter [00680, 01251], lr: 0.000916, loss: 0.4141
2022-09-30 01:30:34 - train: epoch 0157, iter [00690, 01251], lr: 0.000915, loss: 0.4253
2022-09-30 01:30:52 - train: epoch 0157, iter [00700, 01251], lr: 0.000915, loss: 0.4046
2022-09-30 01:31:10 - train: epoch 0157, iter [00710, 01251], lr: 0.000915, loss: 0.4351
2022-09-30 01:31:28 - train: epoch 0157, iter [00720, 01251], lr: 0.000915, loss: 0.4016
2022-09-30 01:31:46 - train: epoch 0157, iter [00730, 01251], lr: 0.000915, loss: 0.4013
2022-09-30 01:32:04 - train: epoch 0157, iter [00740, 01251], lr: 0.000915, loss: 0.3982
2022-09-30 01:32:22 - train: epoch 0157, iter [00750, 01251], lr: 0.000915, loss: 0.4083
2022-09-30 01:32:39 - train: epoch 0157, iter [00760, 01251], lr: 0.000915, loss: 0.3889
2022-09-30 01:32:57 - train: epoch 0157, iter [00770, 01251], lr: 0.000915, loss: 0.4231
2022-09-30 01:33:15 - train: epoch 0157, iter [00780, 01251], lr: 0.000915, loss: 0.4086
2022-09-30 01:33:33 - train: epoch 0157, iter [00790, 01251], lr: 0.000915, loss: 0.4257
2022-09-30 01:33:51 - train: epoch 0157, iter [00800, 01251], lr: 0.000915, loss: 0.4124
2022-09-30 01:34:09 - train: epoch 0157, iter [00810, 01251], lr: 0.000915, loss: 0.4185
2022-09-30 01:34:26 - train: epoch 0157, iter [00820, 01251], lr: 0.000915, loss: 0.4323
2022-09-30 01:34:44 - train: epoch 0157, iter [00830, 01251], lr: 0.000915, loss: 0.3900
2022-09-30 01:35:02 - train: epoch 0157, iter [00840, 01251], lr: 0.000915, loss: 0.4037
2022-09-30 01:35:20 - train: epoch 0157, iter [00850, 01251], lr: 0.000915, loss: 0.4097
2022-09-30 01:35:38 - train: epoch 0157, iter [00860, 01251], lr: 0.000915, loss: 0.4176
2022-09-30 01:35:56 - train: epoch 0157, iter [00870, 01251], lr: 0.000915, loss: 0.3987
2022-09-30 01:36:14 - train: epoch 0157, iter [00880, 01251], lr: 0.000915, loss: 0.4163
2022-09-30 01:36:32 - train: epoch 0157, iter [00890, 01251], lr: 0.000915, loss: 0.4205
2022-09-30 01:36:50 - train: epoch 0157, iter [00900, 01251], lr: 0.000915, loss: 0.4047
2022-09-30 01:37:08 - train: epoch 0157, iter [00910, 01251], lr: 0.000915, loss: 0.4070
2022-09-30 01:37:25 - train: epoch 0157, iter [00920, 01251], lr: 0.000915, loss: 0.3988
2022-09-30 01:37:43 - train: epoch 0157, iter [00930, 01251], lr: 0.000915, loss: 0.4095
2022-09-30 01:38:01 - train: epoch 0157, iter [00940, 01251], lr: 0.000915, loss: 0.4005
2022-09-30 01:38:19 - train: epoch 0157, iter [00950, 01251], lr: 0.000915, loss: 0.4293
2022-09-30 01:38:37 - train: epoch 0157, iter [00960, 01251], lr: 0.000915, loss: 0.4127
2022-09-30 01:38:55 - train: epoch 0157, iter [00970, 01251], lr: 0.000915, loss: 0.4180
2022-09-30 01:39:13 - train: epoch 0157, iter [00980, 01251], lr: 0.000914, loss: 0.3995
2022-09-30 01:39:31 - train: epoch 0157, iter [00990, 01251], lr: 0.000914, loss: 0.4066
2022-09-30 01:39:49 - train: epoch 0157, iter [01000, 01251], lr: 0.000914, loss: 0.3969
2022-09-30 01:40:07 - train: epoch 0157, iter [01010, 01251], lr: 0.000914, loss: 0.3909
2022-09-30 01:40:25 - train: epoch 0157, iter [01020, 01251], lr: 0.000914, loss: 0.4308
2022-09-30 01:40:43 - train: epoch 0157, iter [01030, 01251], lr: 0.000914, loss: 0.4046
2022-09-30 01:41:01 - train: epoch 0157, iter [01040, 01251], lr: 0.000914, loss: 0.4135
2022-09-30 01:41:18 - train: epoch 0157, iter [01050, 01251], lr: 0.000914, loss: 0.4284
2022-09-30 01:41:36 - train: epoch 0157, iter [01060, 01251], lr: 0.000914, loss: 0.4230
2022-09-30 01:41:54 - train: epoch 0157, iter [01070, 01251], lr: 0.000914, loss: 0.4202
2022-09-30 01:42:12 - train: epoch 0157, iter [01080, 01251], lr: 0.000914, loss: 0.4113
2022-09-30 01:42:30 - train: epoch 0157, iter [01090, 01251], lr: 0.000914, loss: 0.4197
2022-09-30 01:42:48 - train: epoch 0157, iter [01100, 01251], lr: 0.000914, loss: 0.3975
2022-09-30 01:43:06 - train: epoch 0157, iter [01110, 01251], lr: 0.000914, loss: 0.4075
2022-09-30 01:43:24 - train: epoch 0157, iter [01120, 01251], lr: 0.000914, loss: 0.3943
2022-09-30 01:43:42 - train: epoch 0157, iter [01130, 01251], lr: 0.000914, loss: 0.4060
2022-09-30 01:44:00 - train: epoch 0157, iter [01140, 01251], lr: 0.000914, loss: 0.4119
2022-09-30 01:44:17 - train: epoch 0157, iter [01150, 01251], lr: 0.000914, loss: 0.4072
2022-09-30 01:44:35 - train: epoch 0157, iter [01160, 01251], lr: 0.000914, loss: 0.4265
2022-09-30 01:44:53 - train: epoch 0157, iter [01170, 01251], lr: 0.000914, loss: 0.4257
2022-09-30 01:45:11 - train: epoch 0157, iter [01180, 01251], lr: 0.000914, loss: 0.4113
2022-09-30 01:45:29 - train: epoch 0157, iter [01190, 01251], lr: 0.000914, loss: 0.3898
2022-09-30 01:45:47 - train: epoch 0157, iter [01200, 01251], lr: 0.000914, loss: 0.4045
2022-09-30 01:46:05 - train: epoch 0157, iter [01210, 01251], lr: 0.000914, loss: 0.4062
2022-09-30 01:46:23 - train: epoch 0157, iter [01220, 01251], lr: 0.000914, loss: 0.4318
2022-09-30 01:46:41 - train: epoch 0157, iter [01230, 01251], lr: 0.000914, loss: 0.4083
2022-09-30 01:46:59 - train: epoch 0157, iter [01240, 01251], lr: 0.000914, loss: 0.4057
2022-09-30 01:47:16 - train: epoch 0157, iter [01250, 01251], lr: 0.000914, loss: 0.4195
2022-09-30 01:47:20 - train: epoch 157, train_loss: 0.4100
2022-09-30 01:47:22 - until epoch: 157, best_loss: 0.4100
2022-09-30 01:47:22 - epoch 158 lr: 0.000913
2022-09-30 01:47:48 - train: epoch 0158, iter [00010, 01251], lr: 0.000913, loss: 0.4256
2022-09-30 01:48:06 - train: epoch 0158, iter [00020, 01251], lr: 0.000913, loss: 0.4007
2022-09-30 01:48:24 - train: epoch 0158, iter [00030, 01251], lr: 0.000913, loss: 0.4022
2022-09-30 01:48:42 - train: epoch 0158, iter [00040, 01251], lr: 0.000913, loss: 0.3961
2022-09-30 01:49:00 - train: epoch 0158, iter [00050, 01251], lr: 0.000913, loss: 0.4018
2022-09-30 01:49:18 - train: epoch 0158, iter [00060, 01251], lr: 0.000913, loss: 0.3914
2022-09-30 01:49:36 - train: epoch 0158, iter [00070, 01251], lr: 0.000913, loss: 0.4201
2022-09-30 01:49:53 - train: epoch 0158, iter [00080, 01251], lr: 0.000913, loss: 0.4169
2022-09-30 01:50:11 - train: epoch 0158, iter [00090, 01251], lr: 0.000913, loss: 0.4276
2022-09-30 01:50:29 - train: epoch 0158, iter [00100, 01251], lr: 0.000913, loss: 0.4139
2022-09-30 01:50:47 - train: epoch 0158, iter [00110, 01251], lr: 0.000913, loss: 0.4242
2022-09-30 01:51:05 - train: epoch 0158, iter [00120, 01251], lr: 0.000913, loss: 0.3819
2022-09-30 01:51:23 - train: epoch 0158, iter [00130, 01251], lr: 0.000913, loss: 0.3937
2022-09-30 01:51:41 - train: epoch 0158, iter [00140, 01251], lr: 0.000913, loss: 0.4086
2022-09-30 01:51:59 - train: epoch 0158, iter [00150, 01251], lr: 0.000913, loss: 0.4137
2022-09-30 01:52:16 - train: epoch 0158, iter [00160, 01251], lr: 0.000913, loss: 0.4157
2022-09-30 01:52:34 - train: epoch 0158, iter [00170, 01251], lr: 0.000913, loss: 0.4008
2022-09-30 01:52:52 - train: epoch 0158, iter [00180, 01251], lr: 0.000913, loss: 0.4204
2022-09-30 01:53:10 - train: epoch 0158, iter [00190, 01251], lr: 0.000913, loss: 0.4119
2022-09-30 01:53:28 - train: epoch 0158, iter [00200, 01251], lr: 0.000913, loss: 0.3938
2022-09-30 01:53:46 - train: epoch 0158, iter [00210, 01251], lr: 0.000913, loss: 0.4014
2022-09-30 01:54:04 - train: epoch 0158, iter [00220, 01251], lr: 0.000913, loss: 0.4267
2022-09-30 01:54:21 - train: epoch 0158, iter [00230, 01251], lr: 0.000913, loss: 0.4133
2022-09-30 01:54:39 - train: epoch 0158, iter [00240, 01251], lr: 0.000913, loss: 0.4099
2022-09-30 01:54:57 - train: epoch 0158, iter [00250, 01251], lr: 0.000913, loss: 0.4249
2022-09-30 01:55:15 - train: epoch 0158, iter [00260, 01251], lr: 0.000913, loss: 0.3906
2022-09-30 01:55:33 - train: epoch 0158, iter [00270, 01251], lr: 0.000913, loss: 0.4182
2022-09-30 01:55:51 - train: epoch 0158, iter [00280, 01251], lr: 0.000912, loss: 0.4054
2022-09-30 01:56:09 - train: epoch 0158, iter [00290, 01251], lr: 0.000912, loss: 0.4095
2022-09-30 01:56:26 - train: epoch 0158, iter [00300, 01251], lr: 0.000912, loss: 0.4244
2022-09-30 01:56:44 - train: epoch 0158, iter [00310, 01251], lr: 0.000912, loss: 0.4077
2022-09-30 01:57:02 - train: epoch 0158, iter [00320, 01251], lr: 0.000912, loss: 0.4018
2022-09-30 01:57:20 - train: epoch 0158, iter [00330, 01251], lr: 0.000912, loss: 0.4131
2022-09-30 01:57:38 - train: epoch 0158, iter [00340, 01251], lr: 0.000912, loss: 0.4118
2022-09-30 01:57:56 - train: epoch 0158, iter [00350, 01251], lr: 0.000912, loss: 0.4113
2022-09-30 01:58:14 - train: epoch 0158, iter [00360, 01251], lr: 0.000912, loss: 0.4045
2022-09-30 01:58:32 - train: epoch 0158, iter [00370, 01251], lr: 0.000912, loss: 0.4128
2022-09-30 01:58:49 - train: epoch 0158, iter [00380, 01251], lr: 0.000912, loss: 0.4203
2022-09-30 01:59:07 - train: epoch 0158, iter [00390, 01251], lr: 0.000912, loss: 0.4188
2022-09-30 01:59:25 - train: epoch 0158, iter [00400, 01251], lr: 0.000912, loss: 0.4354
2022-09-30 01:59:43 - train: epoch 0158, iter [00410, 01251], lr: 0.000912, loss: 0.3903
2022-09-30 02:00:01 - train: epoch 0158, iter [00420, 01251], lr: 0.000912, loss: 0.3953
2022-09-30 02:00:19 - train: epoch 0158, iter [00430, 01251], lr: 0.000912, loss: 0.4066
2022-09-30 02:00:37 - train: epoch 0158, iter [00440, 01251], lr: 0.000912, loss: 0.4115
2022-09-30 02:00:54 - train: epoch 0158, iter [00450, 01251], lr: 0.000912, loss: 0.4198
2022-09-30 02:01:12 - train: epoch 0158, iter [00460, 01251], lr: 0.000912, loss: 0.4198
2022-09-30 02:01:30 - train: epoch 0158, iter [00470, 01251], lr: 0.000912, loss: 0.4248
2022-09-30 02:01:48 - train: epoch 0158, iter [00480, 01251], lr: 0.000912, loss: 0.4061
2022-09-30 02:02:06 - train: epoch 0158, iter [00490, 01251], lr: 0.000912, loss: 0.3921
2022-09-30 02:02:24 - train: epoch 0158, iter [00500, 01251], lr: 0.000912, loss: 0.3970
2022-09-30 02:02:41 - train: epoch 0158, iter [00510, 01251], lr: 0.000912, loss: 0.3994
2022-09-30 02:02:59 - train: epoch 0158, iter [00520, 01251], lr: 0.000912, loss: 0.4120
2022-09-30 02:03:17 - train: epoch 0158, iter [00530, 01251], lr: 0.000912, loss: 0.4119
2022-09-30 02:03:35 - train: epoch 0158, iter [00540, 01251], lr: 0.000912, loss: 0.4165
2022-09-30 02:03:52 - train: epoch 0158, iter [00550, 01251], lr: 0.000912, loss: 0.4010
2022-09-30 02:04:10 - train: epoch 0158, iter [00560, 01251], lr: 0.000911, loss: 0.4105
2022-09-30 02:04:28 - train: epoch 0158, iter [00570, 01251], lr: 0.000911, loss: 0.4081
2022-09-30 02:04:46 - train: epoch 0158, iter [00580, 01251], lr: 0.000911, loss: 0.4197
2022-09-30 02:05:04 - train: epoch 0158, iter [00590, 01251], lr: 0.000911, loss: 0.4050
2022-09-30 02:05:22 - train: epoch 0158, iter [00600, 01251], lr: 0.000911, loss: 0.4230
2022-09-30 02:05:39 - train: epoch 0158, iter [00610, 01251], lr: 0.000911, loss: 0.4073
2022-09-30 02:05:57 - train: epoch 0158, iter [00620, 01251], lr: 0.000911, loss: 0.4227
2022-09-30 02:06:15 - train: epoch 0158, iter [00630, 01251], lr: 0.000911, loss: 0.4128
2022-09-30 02:06:33 - train: epoch 0158, iter [00640, 01251], lr: 0.000911, loss: 0.4038
2022-09-30 02:06:51 - train: epoch 0158, iter [00650, 01251], lr: 0.000911, loss: 0.4091
2022-09-30 02:07:09 - train: epoch 0158, iter [00660, 01251], lr: 0.000911, loss: 0.4103
2022-09-30 02:07:27 - train: epoch 0158, iter [00670, 01251], lr: 0.000911, loss: 0.4109
2022-09-30 02:07:45 - train: epoch 0158, iter [00680, 01251], lr: 0.000911, loss: 0.4178
2022-09-30 02:08:02 - train: epoch 0158, iter [00690, 01251], lr: 0.000911, loss: 0.4130
2022-09-30 02:08:20 - train: epoch 0158, iter [00700, 01251], lr: 0.000911, loss: 0.4163
2022-09-30 02:08:38 - train: epoch 0158, iter [00710, 01251], lr: 0.000911, loss: 0.4163
2022-09-30 02:08:56 - train: epoch 0158, iter [00720, 01251], lr: 0.000911, loss: 0.4283
2022-09-30 02:09:14 - train: epoch 0158, iter [00730, 01251], lr: 0.000911, loss: 0.3863
2022-09-30 02:09:32 - train: epoch 0158, iter [00740, 01251], lr: 0.000911, loss: 0.4149
2022-09-30 02:09:49 - train: epoch 0158, iter [00750, 01251], lr: 0.000911, loss: 0.4027
2022-09-30 02:10:07 - train: epoch 0158, iter [00760, 01251], lr: 0.000911, loss: 0.4027
2022-09-30 02:10:25 - train: epoch 0158, iter [00770, 01251], lr: 0.000911, loss: 0.4244
2022-09-30 02:10:43 - train: epoch 0158, iter [00780, 01251], lr: 0.000911, loss: 0.4122
2022-09-30 02:11:00 - train: epoch 0158, iter [00790, 01251], lr: 0.000911, loss: 0.4261
2022-09-30 02:11:18 - train: epoch 0158, iter [00800, 01251], lr: 0.000911, loss: 0.4132
2022-09-30 02:11:36 - train: epoch 0158, iter [00810, 01251], lr: 0.000911, loss: 0.4322
2022-09-30 02:11:54 - train: epoch 0158, iter [00820, 01251], lr: 0.000911, loss: 0.4449
2022-09-30 02:12:12 - train: epoch 0158, iter [00830, 01251], lr: 0.000911, loss: 0.4055
2022-09-30 02:12:29 - train: epoch 0158, iter [00840, 01251], lr: 0.000910, loss: 0.3917
2022-09-30 02:12:47 - train: epoch 0158, iter [00850, 01251], lr: 0.000910, loss: 0.4152
2022-09-30 02:13:05 - train: epoch 0158, iter [00860, 01251], lr: 0.000910, loss: 0.4071
2022-09-30 02:13:23 - train: epoch 0158, iter [00870, 01251], lr: 0.000910, loss: 0.3975
2022-09-30 02:13:41 - train: epoch 0158, iter [00880, 01251], lr: 0.000910, loss: 0.4185
2022-09-30 02:13:59 - train: epoch 0158, iter [00890, 01251], lr: 0.000910, loss: 0.3980
2022-09-30 02:14:16 - train: epoch 0158, iter [00900, 01251], lr: 0.000910, loss: 0.4196
2022-09-30 02:14:34 - train: epoch 0158, iter [00910, 01251], lr: 0.000910, loss: 0.4237
2022-09-30 02:14:52 - train: epoch 0158, iter [00920, 01251], lr: 0.000910, loss: 0.4082
2022-09-30 02:15:10 - train: epoch 0158, iter [00930, 01251], lr: 0.000910, loss: 0.4127
2022-09-30 02:15:27 - train: epoch 0158, iter [00940, 01251], lr: 0.000910, loss: 0.3989
2022-09-30 02:15:45 - train: epoch 0158, iter [00950, 01251], lr: 0.000910, loss: 0.4165
2022-09-30 02:16:03 - train: epoch 0158, iter [00960, 01251], lr: 0.000910, loss: 0.4085
2022-09-30 02:16:21 - train: epoch 0158, iter [00970, 01251], lr: 0.000910, loss: 0.4221
2022-09-30 02:16:38 - train: epoch 0158, iter [00980, 01251], lr: 0.000910, loss: 0.4059
2022-09-30 02:16:56 - train: epoch 0158, iter [00990, 01251], lr: 0.000910, loss: 0.3939
2022-09-30 02:17:14 - train: epoch 0158, iter [01000, 01251], lr: 0.000910, loss: 0.4176
2022-09-30 02:17:31 - train: epoch 0158, iter [01010, 01251], lr: 0.000910, loss: 0.4048
2022-09-30 02:17:49 - train: epoch 0158, iter [01020, 01251], lr: 0.000910, loss: 0.4044
2022-09-30 02:18:06 - train: epoch 0158, iter [01030, 01251], lr: 0.000910, loss: 0.4386
2022-09-30 02:18:24 - train: epoch 0158, iter [01040, 01251], lr: 0.000910, loss: 0.4261
2022-09-30 02:18:42 - train: epoch 0158, iter [01050, 01251], lr: 0.000910, loss: 0.3827
2022-09-30 02:19:00 - train: epoch 0158, iter [01060, 01251], lr: 0.000910, loss: 0.4119
2022-09-30 02:19:18 - train: epoch 0158, iter [01070, 01251], lr: 0.000910, loss: 0.3867
2022-09-30 02:19:35 - train: epoch 0158, iter [01080, 01251], lr: 0.000910, loss: 0.4128
2022-09-30 02:19:53 - train: epoch 0158, iter [01090, 01251], lr: 0.000910, loss: 0.4108
2022-09-30 02:20:11 - train: epoch 0158, iter [01100, 01251], lr: 0.000910, loss: 0.4153
2022-09-30 02:20:28 - train: epoch 0158, iter [01110, 01251], lr: 0.000910, loss: 0.4143
2022-09-30 02:20:46 - train: epoch 0158, iter [01120, 01251], lr: 0.000909, loss: 0.4129
2022-09-30 02:21:03 - train: epoch 0158, iter [01130, 01251], lr: 0.000909, loss: 0.4187
2022-09-30 02:21:21 - train: epoch 0158, iter [01140, 01251], lr: 0.000909, loss: 0.4289
2022-09-30 02:21:39 - train: epoch 0158, iter [01150, 01251], lr: 0.000909, loss: 0.3972
2022-09-30 02:21:57 - train: epoch 0158, iter [01160, 01251], lr: 0.000909, loss: 0.3932
2022-09-30 02:22:15 - train: epoch 0158, iter [01170, 01251], lr: 0.000909, loss: 0.4083
2022-09-30 02:22:32 - train: epoch 0158, iter [01180, 01251], lr: 0.000909, loss: 0.4229
2022-09-30 02:22:50 - train: epoch 0158, iter [01190, 01251], lr: 0.000909, loss: 0.4118
2022-09-30 02:23:08 - train: epoch 0158, iter [01200, 01251], lr: 0.000909, loss: 0.4268
2022-09-30 02:23:25 - train: epoch 0158, iter [01210, 01251], lr: 0.000909, loss: 0.3991
2022-09-30 02:23:43 - train: epoch 0158, iter [01220, 01251], lr: 0.000909, loss: 0.4479
2022-09-30 02:24:01 - train: epoch 0158, iter [01230, 01251], lr: 0.000909, loss: 0.4211
2022-09-30 02:24:18 - train: epoch 0158, iter [01240, 01251], lr: 0.000909, loss: 0.4016
2022-09-30 02:24:36 - train: epoch 0158, iter [01250, 01251], lr: 0.000909, loss: 0.3913
2022-09-30 02:24:39 - train: epoch 158, train_loss: 0.4099
2022-09-30 02:24:42 - until epoch: 158, best_loss: 0.4099
2022-09-30 02:24:42 - epoch 159 lr: 0.000909
2022-09-30 02:25:08 - train: epoch 0159, iter [00010, 01251], lr: 0.000909, loss: 0.4231
2022-09-30 02:25:26 - train: epoch 0159, iter [00020, 01251], lr: 0.000909, loss: 0.4197
2022-09-30 02:25:44 - train: epoch 0159, iter [00030, 01251], lr: 0.000909, loss: 0.4153
2022-09-30 02:26:02 - train: epoch 0159, iter [00040, 01251], lr: 0.000909, loss: 0.3792
2022-09-30 02:26:20 - train: epoch 0159, iter [00050, 01251], lr: 0.000909, loss: 0.4254
2022-09-30 02:26:38 - train: epoch 0159, iter [00060, 01251], lr: 0.000909, loss: 0.3923
2022-09-30 02:26:56 - train: epoch 0159, iter [00070, 01251], lr: 0.000909, loss: 0.4146
2022-09-30 02:27:13 - train: epoch 0159, iter [00080, 01251], lr: 0.000909, loss: 0.4136
2022-09-30 02:27:31 - train: epoch 0159, iter [00090, 01251], lr: 0.000909, loss: 0.4235
2022-09-30 02:27:49 - train: epoch 0159, iter [00100, 01251], lr: 0.000909, loss: 0.4132
2022-09-30 02:28:07 - train: epoch 0159, iter [00110, 01251], lr: 0.000909, loss: 0.4185
2022-09-30 02:28:25 - train: epoch 0159, iter [00120, 01251], lr: 0.000909, loss: 0.4222
2022-09-30 02:28:43 - train: epoch 0159, iter [00130, 01251], lr: 0.000909, loss: 0.4338
2022-09-30 02:29:01 - train: epoch 0159, iter [00140, 01251], lr: 0.000909, loss: 0.3956
2022-09-30 02:29:19 - train: epoch 0159, iter [00150, 01251], lr: 0.000908, loss: 0.4058
2022-09-30 02:29:37 - train: epoch 0159, iter [00160, 01251], lr: 0.000908, loss: 0.4126
2022-09-30 02:29:55 - train: epoch 0159, iter [00170, 01251], lr: 0.000908, loss: 0.4237
2022-09-30 02:30:13 - train: epoch 0159, iter [00180, 01251], lr: 0.000908, loss: 0.3989
2022-09-30 02:30:31 - train: epoch 0159, iter [00190, 01251], lr: 0.000908, loss: 0.4144
2022-09-30 02:30:49 - train: epoch 0159, iter [00200, 01251], lr: 0.000908, loss: 0.4179
2022-09-30 02:31:07 - train: epoch 0159, iter [00210, 01251], lr: 0.000908, loss: 0.4049
2022-09-30 02:31:25 - train: epoch 0159, iter [00220, 01251], lr: 0.000908, loss: 0.4141
2022-09-30 02:31:43 - train: epoch 0159, iter [00230, 01251], lr: 0.000908, loss: 0.4147
2022-09-30 02:32:01 - train: epoch 0159, iter [00240, 01251], lr: 0.000908, loss: 0.3984
2022-09-30 02:32:19 - train: epoch 0159, iter [00250, 01251], lr: 0.000908, loss: 0.4243
2022-09-30 02:32:37 - train: epoch 0159, iter [00260, 01251], lr: 0.000908, loss: 0.3939
2022-09-30 02:32:55 - train: epoch 0159, iter [00270, 01251], lr: 0.000908, loss: 0.4075
2022-09-30 02:33:13 - train: epoch 0159, iter [00280, 01251], lr: 0.000908, loss: 0.3919
2022-09-30 02:33:31 - train: epoch 0159, iter [00290, 01251], lr: 0.000908, loss: 0.4191
2022-09-30 02:33:48 - train: epoch 0159, iter [00300, 01251], lr: 0.000908, loss: 0.4285
2022-09-30 02:34:06 - train: epoch 0159, iter [00310, 01251], lr: 0.000908, loss: 0.4042
2022-09-30 02:34:24 - train: epoch 0159, iter [00320, 01251], lr: 0.000908, loss: 0.4179
2022-09-30 02:34:42 - train: epoch 0159, iter [00330, 01251], lr: 0.000908, loss: 0.4229
2022-09-30 02:35:00 - train: epoch 0159, iter [00340, 01251], lr: 0.000908, loss: 0.4135
2022-09-30 02:35:18 - train: epoch 0159, iter [00350, 01251], lr: 0.000908, loss: 0.3932
2022-09-30 02:35:36 - train: epoch 0159, iter [00360, 01251], lr: 0.000908, loss: 0.4301
2022-09-30 02:35:55 - train: epoch 0159, iter [00370, 01251], lr: 0.000908, loss: 0.4033
2022-09-30 02:36:13 - train: epoch 0159, iter [00380, 01251], lr: 0.000908, loss: 0.4081
2022-09-30 02:36:31 - train: epoch 0159, iter [00390, 01251], lr: 0.000908, loss: 0.4061
2022-09-30 02:36:48 - train: epoch 0159, iter [00400, 01251], lr: 0.000908, loss: 0.4179
2022-09-30 02:37:06 - train: epoch 0159, iter [00410, 01251], lr: 0.000908, loss: 0.4303
2022-09-30 02:37:25 - train: epoch 0159, iter [00420, 01251], lr: 0.000908, loss: 0.4181
2022-09-30 02:37:43 - train: epoch 0159, iter [00430, 01251], lr: 0.000907, loss: 0.4119
2022-09-30 02:38:01 - train: epoch 0159, iter [00440, 01251], lr: 0.000907, loss: 0.4031
2022-09-30 02:38:19 - train: epoch 0159, iter [00450, 01251], lr: 0.000907, loss: 0.4289
2022-09-30 02:38:37 - train: epoch 0159, iter [00460, 01251], lr: 0.000907, loss: 0.4008
2022-09-30 02:38:54 - train: epoch 0159, iter [00470, 01251], lr: 0.000907, loss: 0.4311
2022-09-30 02:39:12 - train: epoch 0159, iter [00480, 01251], lr: 0.000907, loss: 0.4039
2022-09-30 02:39:30 - train: epoch 0159, iter [00490, 01251], lr: 0.000907, loss: 0.4131
2022-09-30 02:39:48 - train: epoch 0159, iter [00500, 01251], lr: 0.000907, loss: 0.4007
2022-09-30 02:40:06 - train: epoch 0159, iter [00510, 01251], lr: 0.000907, loss: 0.4212
2022-09-30 02:40:24 - train: epoch 0159, iter [00520, 01251], lr: 0.000907, loss: 0.3943
2022-09-30 02:40:42 - train: epoch 0159, iter [00530, 01251], lr: 0.000907, loss: 0.4121
2022-09-30 02:41:00 - train: epoch 0159, iter [00540, 01251], lr: 0.000907, loss: 0.4483
2022-09-30 02:41:18 - train: epoch 0159, iter [00550, 01251], lr: 0.000907, loss: 0.4104
2022-09-30 02:41:36 - train: epoch 0159, iter [00560, 01251], lr: 0.000907, loss: 0.4159
2022-09-30 02:41:54 - train: epoch 0159, iter [00570, 01251], lr: 0.000907, loss: 0.4071
2022-09-30 02:42:12 - train: epoch 0159, iter [00580, 01251], lr: 0.000907, loss: 0.4069
2022-09-30 02:42:30 - train: epoch 0159, iter [00590, 01251], lr: 0.000907, loss: 0.4067
2022-09-30 02:42:48 - train: epoch 0159, iter [00600, 01251], lr: 0.000907, loss: 0.4021
2022-09-30 02:43:06 - train: epoch 0159, iter [00610, 01251], lr: 0.000907, loss: 0.4317
2022-09-30 02:43:24 - train: epoch 0159, iter [00620, 01251], lr: 0.000907, loss: 0.4049
2022-09-30 02:43:42 - train: epoch 0159, iter [00630, 01251], lr: 0.000907, loss: 0.4086
2022-09-30 02:43:59 - train: epoch 0159, iter [00640, 01251], lr: 0.000907, loss: 0.4072
2022-09-30 02:44:18 - train: epoch 0159, iter [00650, 01251], lr: 0.000907, loss: 0.4089
2022-09-30 02:44:35 - train: epoch 0159, iter [00660, 01251], lr: 0.000907, loss: 0.4031
2022-09-30 02:44:53 - train: epoch 0159, iter [00670, 01251], lr: 0.000907, loss: 0.4106
2022-09-30 02:45:11 - train: epoch 0159, iter [00680, 01251], lr: 0.000907, loss: 0.4292
2022-09-30 02:45:29 - train: epoch 0159, iter [00690, 01251], lr: 0.000907, loss: 0.4134
2022-09-30 02:45:47 - train: epoch 0159, iter [00700, 01251], lr: 0.000907, loss: 0.4196
2022-09-30 02:46:05 - train: epoch 0159, iter [00710, 01251], lr: 0.000906, loss: 0.3976
2022-09-30 02:46:23 - train: epoch 0159, iter [00720, 01251], lr: 0.000906, loss: 0.3883
2022-09-30 02:46:41 - train: epoch 0159, iter [00730, 01251], lr: 0.000906, loss: 0.4092
2022-09-30 02:46:59 - train: epoch 0159, iter [00740, 01251], lr: 0.000906, loss: 0.4086
2022-09-30 02:47:17 - train: epoch 0159, iter [00750, 01251], lr: 0.000906, loss: 0.4003
2022-09-30 02:47:35 - train: epoch 0159, iter [00760, 01251], lr: 0.000906, loss: 0.4187
2022-09-30 02:47:52 - train: epoch 0159, iter [00770, 01251], lr: 0.000906, loss: 0.3862
2022-09-30 02:48:10 - train: epoch 0159, iter [00780, 01251], lr: 0.000906, loss: 0.4236
2022-09-30 02:48:28 - train: epoch 0159, iter [00790, 01251], lr: 0.000906, loss: 0.4047
2022-09-30 02:48:46 - train: epoch 0159, iter [00800, 01251], lr: 0.000906, loss: 0.4156
2022-09-30 02:49:04 - train: epoch 0159, iter [00810, 01251], lr: 0.000906, loss: 0.4012
2022-09-30 02:49:22 - train: epoch 0159, iter [00820, 01251], lr: 0.000906, loss: 0.3927
2022-09-30 02:49:40 - train: epoch 0159, iter [00830, 01251], lr: 0.000906, loss: 0.4151
2022-09-30 02:49:58 - train: epoch 0159, iter [00840, 01251], lr: 0.000906, loss: 0.4248
2022-09-30 02:50:16 - train: epoch 0159, iter [00850, 01251], lr: 0.000906, loss: 0.4042
2022-09-30 02:50:34 - train: epoch 0159, iter [00860, 01251], lr: 0.000906, loss: 0.4100
2022-09-30 02:50:52 - train: epoch 0159, iter [00870, 01251], lr: 0.000906, loss: 0.4178
2022-09-30 02:51:10 - train: epoch 0159, iter [00880, 01251], lr: 0.000906, loss: 0.4063
2022-09-30 02:51:28 - train: epoch 0159, iter [00890, 01251], lr: 0.000906, loss: 0.4044
2022-09-30 02:51:46 - train: epoch 0159, iter [00900, 01251], lr: 0.000906, loss: 0.4047
2022-09-30 02:52:04 - train: epoch 0159, iter [00910, 01251], lr: 0.000906, loss: 0.4084
2022-09-30 02:52:22 - train: epoch 0159, iter [00920, 01251], lr: 0.000906, loss: 0.4266
2022-09-30 02:52:40 - train: epoch 0159, iter [00930, 01251], lr: 0.000906, loss: 0.4084
2022-09-30 02:52:58 - train: epoch 0159, iter [00940, 01251], lr: 0.000906, loss: 0.3925
2022-09-30 02:53:17 - train: epoch 0159, iter [00950, 01251], lr: 0.000906, loss: 0.4160
2022-09-30 02:53:35 - train: epoch 0159, iter [00960, 01251], lr: 0.000906, loss: 0.4148
2022-09-30 02:53:52 - train: epoch 0159, iter [00970, 01251], lr: 0.000906, loss: 0.4091
2022-09-30 02:54:11 - train: epoch 0159, iter [00980, 01251], lr: 0.000905, loss: 0.4129
2022-09-30 02:54:29 - train: epoch 0159, iter [00990, 01251], lr: 0.000905, loss: 0.4058
2022-09-30 02:54:47 - train: epoch 0159, iter [01000, 01251], lr: 0.000905, loss: 0.4203
2022-09-30 02:55:05 - train: epoch 0159, iter [01010, 01251], lr: 0.000905, loss: 0.4034
2022-09-30 02:55:23 - train: epoch 0159, iter [01020, 01251], lr: 0.000905, loss: 0.4221
2022-09-30 02:55:41 - train: epoch 0159, iter [01030, 01251], lr: 0.000905, loss: 0.4207
2022-09-30 02:55:59 - train: epoch 0159, iter [01040, 01251], lr: 0.000905, loss: 0.4277
2022-09-30 02:56:17 - train: epoch 0159, iter [01050, 01251], lr: 0.000905, loss: 0.4065
2022-09-30 02:56:35 - train: epoch 0159, iter [01060, 01251], lr: 0.000905, loss: 0.4217
2022-09-30 02:56:53 - train: epoch 0159, iter [01070, 01251], lr: 0.000905, loss: 0.4104
2022-09-30 02:57:11 - train: epoch 0159, iter [01080, 01251], lr: 0.000905, loss: 0.4158
2022-09-30 02:57:29 - train: epoch 0159, iter [01090, 01251], lr: 0.000905, loss: 0.4291
2022-09-30 02:57:47 - train: epoch 0159, iter [01100, 01251], lr: 0.000905, loss: 0.4066
2022-09-30 02:58:05 - train: epoch 0159, iter [01110, 01251], lr: 0.000905, loss: 0.4159
2022-09-30 02:58:23 - train: epoch 0159, iter [01120, 01251], lr: 0.000905, loss: 0.4070
2022-09-30 02:58:41 - train: epoch 0159, iter [01130, 01251], lr: 0.000905, loss: 0.4158
2022-09-30 02:58:59 - train: epoch 0159, iter [01140, 01251], lr: 0.000905, loss: 0.4048
2022-09-30 02:59:17 - train: epoch 0159, iter [01150, 01251], lr: 0.000905, loss: 0.4052
2022-09-30 02:59:35 - train: epoch 0159, iter [01160, 01251], lr: 0.000905, loss: 0.3944
2022-09-30 02:59:53 - train: epoch 0159, iter [01170, 01251], lr: 0.000905, loss: 0.4274
2022-09-30 03:00:11 - train: epoch 0159, iter [01180, 01251], lr: 0.000905, loss: 0.4215
2022-09-30 03:00:29 - train: epoch 0159, iter [01190, 01251], lr: 0.000905, loss: 0.4152
2022-09-30 03:00:47 - train: epoch 0159, iter [01200, 01251], lr: 0.000905, loss: 0.4131
2022-09-30 03:01:05 - train: epoch 0159, iter [01210, 01251], lr: 0.000905, loss: 0.4020
2022-09-30 03:01:23 - train: epoch 0159, iter [01220, 01251], lr: 0.000905, loss: 0.4182
2022-09-30 03:01:41 - train: epoch 0159, iter [01230, 01251], lr: 0.000905, loss: 0.4287
2022-09-30 03:01:59 - train: epoch 0159, iter [01240, 01251], lr: 0.000905, loss: 0.3984
2022-09-30 03:02:16 - train: epoch 0159, iter [01250, 01251], lr: 0.000905, loss: 0.3984
2022-09-30 03:02:19 - train: epoch 159, train_loss: 0.4099
2022-09-30 03:02:21 - until epoch: 159, best_loss: 0.4099
2022-09-30 03:02:21 - epoch 160 lr: 0.000905
2022-09-30 03:02:46 - train: epoch 0160, iter [00010, 01251], lr: 0.000904, loss: 0.4023
2022-09-30 03:03:04 - train: epoch 0160, iter [00020, 01251], lr: 0.000904, loss: 0.4156
2022-09-30 03:03:22 - train: epoch 0160, iter [00030, 01251], lr: 0.000904, loss: 0.4195
2022-09-30 03:03:40 - train: epoch 0160, iter [00040, 01251], lr: 0.000904, loss: 0.4137
2022-09-30 03:03:58 - train: epoch 0160, iter [00050, 01251], lr: 0.000904, loss: 0.4115
2022-09-30 03:04:16 - train: epoch 0160, iter [00060, 01251], lr: 0.000904, loss: 0.4296
2022-09-30 03:04:34 - train: epoch 0160, iter [00070, 01251], lr: 0.000904, loss: 0.4169
2022-09-30 03:04:52 - train: epoch 0160, iter [00080, 01251], lr: 0.000904, loss: 0.4154
2022-09-30 03:05:10 - train: epoch 0160, iter [00090, 01251], lr: 0.000904, loss: 0.4177
2022-09-30 03:05:28 - train: epoch 0160, iter [00100, 01251], lr: 0.000904, loss: 0.3995
2022-09-30 03:05:46 - train: epoch 0160, iter [00110, 01251], lr: 0.000904, loss: 0.4206
2022-09-30 03:06:04 - train: epoch 0160, iter [00120, 01251], lr: 0.000904, loss: 0.4243
2022-09-30 03:06:22 - train: epoch 0160, iter [00130, 01251], lr: 0.000904, loss: 0.4006
2022-09-30 03:06:40 - train: epoch 0160, iter [00140, 01251], lr: 0.000904, loss: 0.4020
2022-09-30 03:06:58 - train: epoch 0160, iter [00150, 01251], lr: 0.000904, loss: 0.4154
2022-09-30 03:07:16 - train: epoch 0160, iter [00160, 01251], lr: 0.000904, loss: 0.4082
2022-09-30 03:07:34 - train: epoch 0160, iter [00170, 01251], lr: 0.000904, loss: 0.4192
2022-09-30 03:07:52 - train: epoch 0160, iter [00180, 01251], lr: 0.000904, loss: 0.4120
2022-09-30 03:08:10 - train: epoch 0160, iter [00190, 01251], lr: 0.000904, loss: 0.4097
2022-09-30 03:08:28 - train: epoch 0160, iter [00200, 01251], lr: 0.000904, loss: 0.4082
2022-09-30 03:08:46 - train: epoch 0160, iter [00210, 01251], lr: 0.000904, loss: 0.4171
2022-09-30 03:09:04 - train: epoch 0160, iter [00220, 01251], lr: 0.000904, loss: 0.3914
2022-09-30 03:09:23 - train: epoch 0160, iter [00230, 01251], lr: 0.000904, loss: 0.3951
2022-09-30 03:09:41 - train: epoch 0160, iter [00240, 01251], lr: 0.000904, loss: 0.3851
2022-09-30 03:09:59 - train: epoch 0160, iter [00250, 01251], lr: 0.000904, loss: 0.3999
2022-09-30 03:10:17 - train: epoch 0160, iter [00260, 01251], lr: 0.000904, loss: 0.4183
2022-09-30 03:10:35 - train: epoch 0160, iter [00270, 01251], lr: 0.000904, loss: 0.4062
2022-09-30 03:10:53 - train: epoch 0160, iter [00280, 01251], lr: 0.000904, loss: 0.4143
2022-09-30 03:11:11 - train: epoch 0160, iter [00290, 01251], lr: 0.000903, loss: 0.4092
2022-09-30 03:11:29 - train: epoch 0160, iter [00300, 01251], lr: 0.000903, loss: 0.4124
2022-09-30 03:11:47 - train: epoch 0160, iter [00310, 01251], lr: 0.000903, loss: 0.3918
2022-09-30 03:12:05 - train: epoch 0160, iter [00320, 01251], lr: 0.000903, loss: 0.4259
2022-09-30 03:12:23 - train: epoch 0160, iter [00330, 01251], lr: 0.000903, loss: 0.4138
2022-09-30 03:12:41 - train: epoch 0160, iter [00340, 01251], lr: 0.000903, loss: 0.4072
2022-09-30 03:12:58 - train: epoch 0160, iter [00350, 01251], lr: 0.000903, loss: 0.4094
2022-09-30 03:13:16 - train: epoch 0160, iter [00360, 01251], lr: 0.000903, loss: 0.3867
2022-09-30 03:13:34 - train: epoch 0160, iter [00370, 01251], lr: 0.000903, loss: 0.4112
2022-09-30 03:13:52 - train: epoch 0160, iter [00380, 01251], lr: 0.000903, loss: 0.4070
2022-09-30 03:14:10 - train: epoch 0160, iter [00390, 01251], lr: 0.000903, loss: 0.4087
2022-09-30 03:14:28 - train: epoch 0160, iter [00400, 01251], lr: 0.000903, loss: 0.4136
2022-09-30 03:14:46 - train: epoch 0160, iter [00410, 01251], lr: 0.000903, loss: 0.4004
2022-09-30 03:15:04 - train: epoch 0160, iter [00420, 01251], lr: 0.000903, loss: 0.4162
2022-09-30 03:15:23 - train: epoch 0160, iter [00430, 01251], lr: 0.000903, loss: 0.4070
2022-09-30 03:15:40 - train: epoch 0160, iter [00440, 01251], lr: 0.000903, loss: 0.4046
2022-09-30 03:15:59 - train: epoch 0160, iter [00450, 01251], lr: 0.000903, loss: 0.4037
2022-09-30 03:16:17 - train: epoch 0160, iter [00460, 01251], lr: 0.000903, loss: 0.4272
2022-09-30 03:16:35 - train: epoch 0160, iter [00470, 01251], lr: 0.000903, loss: 0.4047
2022-09-30 03:16:53 - train: epoch 0160, iter [00480, 01251], lr: 0.000903, loss: 0.4153
2022-09-30 03:17:11 - train: epoch 0160, iter [00490, 01251], lr: 0.000903, loss: 0.4020
2022-09-30 03:17:29 - train: epoch 0160, iter [00500, 01251], lr: 0.000903, loss: 0.4121
2022-09-30 03:17:47 - train: epoch 0160, iter [00510, 01251], lr: 0.000903, loss: 0.4281
2022-09-30 03:18:05 - train: epoch 0160, iter [00520, 01251], lr: 0.000903, loss: 0.3994
2022-09-30 03:18:23 - train: epoch 0160, iter [00530, 01251], lr: 0.000903, loss: 0.4036
2022-09-30 03:18:41 - train: epoch 0160, iter [00540, 01251], lr: 0.000903, loss: 0.4038
2022-09-30 03:18:59 - train: epoch 0160, iter [00550, 01251], lr: 0.000903, loss: 0.4050
2022-09-30 03:19:17 - train: epoch 0160, iter [00560, 01251], lr: 0.000903, loss: 0.4049
2022-09-30 03:19:35 - train: epoch 0160, iter [00570, 01251], lr: 0.000902, loss: 0.4125
2022-09-30 03:19:53 - train: epoch 0160, iter [00580, 01251], lr: 0.000902, loss: 0.4047
2022-09-30 03:20:12 - train: epoch 0160, iter [00590, 01251], lr: 0.000902, loss: 0.4043
2022-09-30 03:20:30 - train: epoch 0160, iter [00600, 01251], lr: 0.000902, loss: 0.4212
2022-09-30 03:20:48 - train: epoch 0160, iter [00610, 01251], lr: 0.000902, loss: 0.4109
2022-09-30 03:21:06 - train: epoch 0160, iter [00620, 01251], lr: 0.000902, loss: 0.3869
2022-09-30 03:21:24 - train: epoch 0160, iter [00630, 01251], lr: 0.000902, loss: 0.4135
2022-09-30 03:21:42 - train: epoch 0160, iter [00640, 01251], lr: 0.000902, loss: 0.4316
2022-09-30 03:22:00 - train: epoch 0160, iter [00650, 01251], lr: 0.000902, loss: 0.4071
2022-09-30 03:22:18 - train: epoch 0160, iter [00660, 01251], lr: 0.000902, loss: 0.4119
2022-09-30 03:22:36 - train: epoch 0160, iter [00670, 01251], lr: 0.000902, loss: 0.3711
2022-09-30 03:22:54 - train: epoch 0160, iter [00680, 01251], lr: 0.000902, loss: 0.3865
2022-09-30 03:23:12 - train: epoch 0160, iter [00690, 01251], lr: 0.000902, loss: 0.4060
2022-09-30 03:23:30 - train: epoch 0160, iter [00700, 01251], lr: 0.000902, loss: 0.4107
2022-09-30 03:23:48 - train: epoch 0160, iter [00710, 01251], lr: 0.000902, loss: 0.4109
2022-09-30 03:24:06 - train: epoch 0160, iter [00720, 01251], lr: 0.000902, loss: 0.3977
2022-09-30 03:24:24 - train: epoch 0160, iter [00730, 01251], lr: 0.000902, loss: 0.4064
2022-09-30 03:24:42 - train: epoch 0160, iter [00740, 01251], lr: 0.000902, loss: 0.3915
2022-09-30 03:25:01 - train: epoch 0160, iter [00750, 01251], lr: 0.000902, loss: 0.4270
2022-09-30 03:25:19 - train: epoch 0160, iter [00760, 01251], lr: 0.000902, loss: 0.4136
2022-09-30 03:25:37 - train: epoch 0160, iter [00770, 01251], lr: 0.000902, loss: 0.4002
2022-09-30 03:25:55 - train: epoch 0160, iter [00780, 01251], lr: 0.000902, loss: 0.4044
2022-09-30 03:26:13 - train: epoch 0160, iter [00790, 01251], lr: 0.000902, loss: 0.4006
2022-09-30 03:26:31 - train: epoch 0160, iter [00800, 01251], lr: 0.000902, loss: 0.3993
2022-09-30 03:26:49 - train: epoch 0160, iter [00810, 01251], lr: 0.000902, loss: 0.4118
2022-09-30 03:27:07 - train: epoch 0160, iter [00820, 01251], lr: 0.000902, loss: 0.4208
2022-09-30 03:27:25 - train: epoch 0160, iter [00830, 01251], lr: 0.000902, loss: 0.4031
2022-09-30 03:27:43 - train: epoch 0160, iter [00840, 01251], lr: 0.000901, loss: 0.4148
2022-09-30 03:28:00 - train: epoch 0160, iter [00850, 01251], lr: 0.000901, loss: 0.4047
2022-09-30 03:28:18 - train: epoch 0160, iter [00860, 01251], lr: 0.000901, loss: 0.4170
2022-09-30 03:28:37 - train: epoch 0160, iter [00870, 01251], lr: 0.000901, loss: 0.4041
2022-09-30 03:28:55 - train: epoch 0160, iter [00880, 01251], lr: 0.000901, loss: 0.4244
2022-09-30 03:29:13 - train: epoch 0160, iter [00890, 01251], lr: 0.000901, loss: 0.3959
2022-09-30 03:29:30 - train: epoch 0160, iter [00900, 01251], lr: 0.000901, loss: 0.4138
2022-09-30 03:29:49 - train: epoch 0160, iter [00910, 01251], lr: 0.000901, loss: 0.4012
2022-09-30 03:30:07 - train: epoch 0160, iter [00920, 01251], lr: 0.000901, loss: 0.4018
2022-09-30 03:30:24 - train: epoch 0160, iter [00930, 01251], lr: 0.000901, loss: 0.3987
2022-09-30 03:30:43 - train: epoch 0160, iter [00940, 01251], lr: 0.000901, loss: 0.4005
2022-09-30 03:31:01 - train: epoch 0160, iter [00950, 01251], lr: 0.000901, loss: 0.4148
2022-09-30 03:31:19 - train: epoch 0160, iter [00960, 01251], lr: 0.000901, loss: 0.4153
2022-09-30 03:31:37 - train: epoch 0160, iter [00970, 01251], lr: 0.000901, loss: 0.4411
2022-09-30 03:31:54 - train: epoch 0160, iter [00980, 01251], lr: 0.000901, loss: 0.4217
2022-09-30 03:32:13 - train: epoch 0160, iter [00990, 01251], lr: 0.000901, loss: 0.4191
2022-09-30 03:32:31 - train: epoch 0160, iter [01000, 01251], lr: 0.000901, loss: 0.4028
2022-09-30 03:32:49 - train: epoch 0160, iter [01010, 01251], lr: 0.000901, loss: 0.4112
2022-09-30 03:33:07 - train: epoch 0160, iter [01020, 01251], lr: 0.000901, loss: 0.4105
2022-09-30 03:33:25 - train: epoch 0160, iter [01030, 01251], lr: 0.000901, loss: 0.4367
2022-09-30 03:33:43 - train: epoch 0160, iter [01040, 01251], lr: 0.000901, loss: 0.3976
2022-09-30 03:34:01 - train: epoch 0160, iter [01050, 01251], lr: 0.000901, loss: 0.4138
2022-09-30 03:34:19 - train: epoch 0160, iter [01060, 01251], lr: 0.000901, loss: 0.3867
2022-09-30 03:34:37 - train: epoch 0160, iter [01070, 01251], lr: 0.000901, loss: 0.4038
2022-09-30 03:34:55 - train: epoch 0160, iter [01080, 01251], lr: 0.000901, loss: 0.4267
2022-09-30 03:35:13 - train: epoch 0160, iter [01090, 01251], lr: 0.000901, loss: 0.4071
2022-09-30 03:35:32 - train: epoch 0160, iter [01100, 01251], lr: 0.000901, loss: 0.4021
2022-09-30 03:35:50 - train: epoch 0160, iter [01110, 01251], lr: 0.000901, loss: 0.4190
2022-09-30 03:36:08 - train: epoch 0160, iter [01120, 01251], lr: 0.000900, loss: 0.3850
2022-09-30 03:36:26 - train: epoch 0160, iter [01130, 01251], lr: 0.000900, loss: 0.4096
2022-09-30 03:36:44 - train: epoch 0160, iter [01140, 01251], lr: 0.000900, loss: 0.3921
2022-09-30 03:37:01 - train: epoch 0160, iter [01150, 01251], lr: 0.000900, loss: 0.4239
2022-09-30 03:37:19 - train: epoch 0160, iter [01160, 01251], lr: 0.000900, loss: 0.4225
2022-09-30 03:37:38 - train: epoch 0160, iter [01170, 01251], lr: 0.000900, loss: 0.3917
2022-09-30 03:37:55 - train: epoch 0160, iter [01180, 01251], lr: 0.000900, loss: 0.3994
2022-09-30 03:38:13 - train: epoch 0160, iter [01190, 01251], lr: 0.000900, loss: 0.4108
2022-09-30 03:38:31 - train: epoch 0160, iter [01200, 01251], lr: 0.000900, loss: 0.3862
2022-09-30 03:38:49 - train: epoch 0160, iter [01210, 01251], lr: 0.000900, loss: 0.4005
2022-09-30 03:39:07 - train: epoch 0160, iter [01220, 01251], lr: 0.000900, loss: 0.4057
2022-09-30 03:39:25 - train: epoch 0160, iter [01230, 01251], lr: 0.000900, loss: 0.4176
2022-09-30 03:39:43 - train: epoch 0160, iter [01240, 01251], lr: 0.000900, loss: 0.4142
2022-09-30 03:40:01 - train: epoch 0160, iter [01250, 01251], lr: 0.000900, loss: 0.4161
2022-09-30 03:40:04 - train: epoch 160, train_loss: 0.4097
2022-09-30 03:40:07 - until epoch: 160, best_loss: 0.4097
2022-09-30 03:40:07 - epoch 161 lr: 0.000900
2022-09-30 03:40:32 - train: epoch 0161, iter [00010, 01251], lr: 0.000900, loss: 0.4078
2022-09-30 03:40:49 - train: epoch 0161, iter [00020, 01251], lr: 0.000900, loss: 0.4126
2022-09-30 03:41:07 - train: epoch 0161, iter [00030, 01251], lr: 0.000900, loss: 0.4063
2022-09-30 03:41:26 - train: epoch 0161, iter [00040, 01251], lr: 0.000900, loss: 0.4220
2022-09-30 03:41:44 - train: epoch 0161, iter [00050, 01251], lr: 0.000900, loss: 0.3966
2022-09-30 03:42:02 - train: epoch 0161, iter [00060, 01251], lr: 0.000900, loss: 0.4078
2022-09-30 03:42:20 - train: epoch 0161, iter [00070, 01251], lr: 0.000900, loss: 0.4119
2022-09-30 03:42:38 - train: epoch 0161, iter [00080, 01251], lr: 0.000900, loss: 0.4320
2022-09-30 03:42:56 - train: epoch 0161, iter [00090, 01251], lr: 0.000900, loss: 0.4169
2022-09-30 03:43:15 - train: epoch 0161, iter [00100, 01251], lr: 0.000900, loss: 0.4075
2022-09-30 03:43:33 - train: epoch 0161, iter [00110, 01251], lr: 0.000900, loss: 0.4048
2022-09-30 03:43:51 - train: epoch 0161, iter [00120, 01251], lr: 0.000900, loss: 0.4083
2022-09-30 03:44:09 - train: epoch 0161, iter [00130, 01251], lr: 0.000900, loss: 0.4057
2022-09-30 03:44:27 - train: epoch 0161, iter [00140, 01251], lr: 0.000899, loss: 0.4215
2022-09-30 03:44:45 - train: epoch 0161, iter [00150, 01251], lr: 0.000899, loss: 0.4168
2022-09-30 03:45:04 - train: epoch 0161, iter [00160, 01251], lr: 0.000899, loss: 0.3972
2022-09-30 03:45:22 - train: epoch 0161, iter [00170, 01251], lr: 0.000899, loss: 0.4112
2022-09-30 03:45:40 - train: epoch 0161, iter [00180, 01251], lr: 0.000899, loss: 0.4071
2022-09-30 03:45:58 - train: epoch 0161, iter [00190, 01251], lr: 0.000899, loss: 0.3995
2022-09-30 03:46:16 - train: epoch 0161, iter [00200, 01251], lr: 0.000899, loss: 0.4245
2022-09-30 03:46:35 - train: epoch 0161, iter [00210, 01251], lr: 0.000899, loss: 0.3992
2022-09-30 03:46:53 - train: epoch 0161, iter [00220, 01251], lr: 0.000899, loss: 0.4014
2022-09-30 03:47:11 - train: epoch 0161, iter [00230, 01251], lr: 0.000899, loss: 0.4216
2022-09-30 03:47:29 - train: epoch 0161, iter [00240, 01251], lr: 0.000899, loss: 0.4108
2022-09-30 03:47:47 - train: epoch 0161, iter [00250, 01251], lr: 0.000899, loss: 0.4071
2022-09-30 03:48:05 - train: epoch 0161, iter [00260, 01251], lr: 0.000899, loss: 0.4041
2022-09-30 03:48:23 - train: epoch 0161, iter [00270, 01251], lr: 0.000899, loss: 0.3913
2022-09-30 03:48:41 - train: epoch 0161, iter [00280, 01251], lr: 0.000899, loss: 0.4371
2022-09-30 03:49:00 - train: epoch 0161, iter [00290, 01251], lr: 0.000899, loss: 0.4140
2022-09-30 03:49:18 - train: epoch 0161, iter [00300, 01251], lr: 0.000899, loss: 0.4119
2022-09-30 03:49:36 - train: epoch 0161, iter [00310, 01251], lr: 0.000899, loss: 0.4148
2022-09-30 03:49:54 - train: epoch 0161, iter [00320, 01251], lr: 0.000899, loss: 0.4053
2022-09-30 03:50:12 - train: epoch 0161, iter [00330, 01251], lr: 0.000899, loss: 0.4090
2022-09-30 03:50:30 - train: epoch 0161, iter [00340, 01251], lr: 0.000899, loss: 0.3937
2022-09-30 03:50:48 - train: epoch 0161, iter [00350, 01251], lr: 0.000899, loss: 0.3971
2022-09-30 03:51:06 - train: epoch 0161, iter [00360, 01251], lr: 0.000899, loss: 0.4035
2022-09-30 03:51:25 - train: epoch 0161, iter [00370, 01251], lr: 0.000899, loss: 0.4138
2022-09-30 03:51:43 - train: epoch 0161, iter [00380, 01251], lr: 0.000899, loss: 0.4125
2022-09-30 03:52:02 - train: epoch 0161, iter [00390, 01251], lr: 0.000899, loss: 0.4091
2022-09-30 03:52:19 - train: epoch 0161, iter [00400, 01251], lr: 0.000899, loss: 0.4035
2022-09-30 03:52:38 - train: epoch 0161, iter [00410, 01251], lr: 0.000899, loss: 0.4192
2022-09-30 03:52:56 - train: epoch 0161, iter [00420, 01251], lr: 0.000898, loss: 0.4005
2022-09-30 03:53:14 - train: epoch 0161, iter [00430, 01251], lr: 0.000898, loss: 0.4074
2022-09-30 03:53:33 - train: epoch 0161, iter [00440, 01251], lr: 0.000898, loss: 0.4036
2022-09-30 03:53:51 - train: epoch 0161, iter [00450, 01251], lr: 0.000898, loss: 0.4319
2022-09-30 03:54:09 - train: epoch 0161, iter [00460, 01251], lr: 0.000898, loss: 0.4075
2022-09-30 03:54:27 - train: epoch 0161, iter [00470, 01251], lr: 0.000898, loss: 0.4180
2022-09-30 03:54:45 - train: epoch 0161, iter [00480, 01251], lr: 0.000898, loss: 0.4213
2022-09-30 03:55:03 - train: epoch 0161, iter [00490, 01251], lr: 0.000898, loss: 0.4095
2022-09-30 03:55:21 - train: epoch 0161, iter [00500, 01251], lr: 0.000898, loss: 0.4147
2022-09-30 03:55:39 - train: epoch 0161, iter [00510, 01251], lr: 0.000898, loss: 0.4201
2022-09-30 03:55:57 - train: epoch 0161, iter [00520, 01251], lr: 0.000898, loss: 0.4107
2022-09-30 03:56:15 - train: epoch 0161, iter [00530, 01251], lr: 0.000898, loss: 0.4094
2022-09-30 03:56:33 - train: epoch 0161, iter [00540, 01251], lr: 0.000898, loss: 0.4227
2022-09-30 03:56:51 - train: epoch 0161, iter [00550, 01251], lr: 0.000898, loss: 0.4207
2022-09-30 03:57:10 - train: epoch 0161, iter [00560, 01251], lr: 0.000898, loss: 0.4048
2022-09-30 03:57:28 - train: epoch 0161, iter [00570, 01251], lr: 0.000898, loss: 0.4289
2022-09-30 03:57:46 - train: epoch 0161, iter [00580, 01251], lr: 0.000898, loss: 0.4126
2022-09-30 03:58:04 - train: epoch 0161, iter [00590, 01251], lr: 0.000898, loss: 0.4262
2022-09-30 03:58:22 - train: epoch 0161, iter [00600, 01251], lr: 0.000898, loss: 0.4016
2022-09-30 03:58:40 - train: epoch 0161, iter [00610, 01251], lr: 0.000898, loss: 0.4054
2022-09-30 03:58:59 - train: epoch 0161, iter [00620, 01251], lr: 0.000898, loss: 0.4062
2022-09-30 03:59:17 - train: epoch 0161, iter [00630, 01251], lr: 0.000898, loss: 0.4164
2022-09-30 03:59:35 - train: epoch 0161, iter [00640, 01251], lr: 0.000898, loss: 0.3930
2022-09-30 03:59:53 - train: epoch 0161, iter [00650, 01251], lr: 0.000898, loss: 0.4197
2022-09-30 04:00:12 - train: epoch 0161, iter [00660, 01251], lr: 0.000898, loss: 0.4189
2022-09-30 04:00:30 - train: epoch 0161, iter [00670, 01251], lr: 0.000898, loss: 0.4053
2022-09-30 04:00:48 - train: epoch 0161, iter [00680, 01251], lr: 0.000898, loss: 0.4154
2022-09-30 04:01:07 - train: epoch 0161, iter [00690, 01251], lr: 0.000897, loss: 0.3980
2022-09-30 04:01:25 - train: epoch 0161, iter [00700, 01251], lr: 0.000897, loss: 0.4071
2022-09-30 04:01:43 - train: epoch 0161, iter [00710, 01251], lr: 0.000897, loss: 0.3986
2022-09-30 04:02:01 - train: epoch 0161, iter [00720, 01251], lr: 0.000897, loss: 0.4057
2022-09-30 04:02:19 - train: epoch 0161, iter [00730, 01251], lr: 0.000897, loss: 0.3969
2022-09-30 04:02:38 - train: epoch 0161, iter [00740, 01251], lr: 0.000897, loss: 0.4169
2022-09-30 04:02:56 - train: epoch 0161, iter [00750, 01251], lr: 0.000897, loss: 0.4363
2022-09-30 04:03:14 - train: epoch 0161, iter [00760, 01251], lr: 0.000897, loss: 0.3989
2022-09-30 04:03:32 - train: epoch 0161, iter [00770, 01251], lr: 0.000897, loss: 0.4033
2022-09-30 04:03:50 - train: epoch 0161, iter [00780, 01251], lr: 0.000897, loss: 0.4211
2022-09-30 04:04:08 - train: epoch 0161, iter [00790, 01251], lr: 0.000897, loss: 0.4166
2022-09-30 04:04:27 - train: epoch 0161, iter [00800, 01251], lr: 0.000897, loss: 0.4048
2022-09-30 04:04:45 - train: epoch 0161, iter [00810, 01251], lr: 0.000897, loss: 0.4110
2022-09-30 04:05:03 - train: epoch 0161, iter [00820, 01251], lr: 0.000897, loss: 0.3842
2022-09-30 04:05:21 - train: epoch 0161, iter [00830, 01251], lr: 0.000897, loss: 0.4111
2022-09-30 04:05:39 - train: epoch 0161, iter [00840, 01251], lr: 0.000897, loss: 0.4094
2022-09-30 04:05:57 - train: epoch 0161, iter [00850, 01251], lr: 0.000897, loss: 0.4083
2022-09-30 04:06:15 - train: epoch 0161, iter [00860, 01251], lr: 0.000897, loss: 0.4093
2022-09-30 04:06:33 - train: epoch 0161, iter [00870, 01251], lr: 0.000897, loss: 0.4033
2022-09-30 04:06:52 - train: epoch 0161, iter [00880, 01251], lr: 0.000897, loss: 0.4196
2022-09-30 04:07:10 - train: epoch 0161, iter [00890, 01251], lr: 0.000897, loss: 0.4118
2022-09-30 04:07:28 - train: epoch 0161, iter [00900, 01251], lr: 0.000897, loss: 0.4178
2022-09-30 04:07:46 - train: epoch 0161, iter [00910, 01251], lr: 0.000897, loss: 0.4067
2022-09-30 04:08:04 - train: epoch 0161, iter [00920, 01251], lr: 0.000897, loss: 0.4042
2022-09-30 04:08:22 - train: epoch 0161, iter [00930, 01251], lr: 0.000897, loss: 0.4202
2022-09-30 04:08:40 - train: epoch 0161, iter [00940, 01251], lr: 0.000897, loss: 0.4133
2022-09-30 04:08:58 - train: epoch 0161, iter [00950, 01251], lr: 0.000897, loss: 0.4002
2022-09-30 04:09:16 - train: epoch 0161, iter [00960, 01251], lr: 0.000897, loss: 0.4007
2022-09-30 04:09:35 - train: epoch 0161, iter [00970, 01251], lr: 0.000896, loss: 0.3773
2022-09-30 04:09:53 - train: epoch 0161, iter [00980, 01251], lr: 0.000896, loss: 0.4115
2022-09-30 04:10:11 - train: epoch 0161, iter [00990, 01251], lr: 0.000896, loss: 0.4106
2022-09-30 04:10:29 - train: epoch 0161, iter [01000, 01251], lr: 0.000896, loss: 0.4060
2022-09-30 04:10:47 - train: epoch 0161, iter [01010, 01251], lr: 0.000896, loss: 0.4044
2022-09-30 04:11:05 - train: epoch 0161, iter [01020, 01251], lr: 0.000896, loss: 0.4196
2022-09-30 04:11:23 - train: epoch 0161, iter [01030, 01251], lr: 0.000896, loss: 0.4288
2022-09-30 04:11:41 - train: epoch 0161, iter [01040, 01251], lr: 0.000896, loss: 0.4019
2022-09-30 04:11:59 - train: epoch 0161, iter [01050, 01251], lr: 0.000896, loss: 0.4069
2022-09-30 04:12:17 - train: epoch 0161, iter [01060, 01251], lr: 0.000896, loss: 0.4012
2022-09-30 04:12:35 - train: epoch 0161, iter [01070, 01251], lr: 0.000896, loss: 0.3837
2022-09-30 04:12:53 - train: epoch 0161, iter [01080, 01251], lr: 0.000896, loss: 0.3939
2022-09-30 04:13:11 - train: epoch 0161, iter [01090, 01251], lr: 0.000896, loss: 0.4218
2022-09-30 04:13:29 - train: epoch 0161, iter [01100, 01251], lr: 0.000896, loss: 0.4015
2022-09-30 04:13:48 - train: epoch 0161, iter [01110, 01251], lr: 0.000896, loss: 0.4124
2022-09-30 04:14:05 - train: epoch 0161, iter [01120, 01251], lr: 0.000896, loss: 0.3873
2022-09-30 04:14:24 - train: epoch 0161, iter [01130, 01251], lr: 0.000896, loss: 0.4493
2022-09-30 04:14:42 - train: epoch 0161, iter [01140, 01251], lr: 0.000896, loss: 0.4188
2022-09-30 04:15:00 - train: epoch 0161, iter [01150, 01251], lr: 0.000896, loss: 0.3939
2022-09-30 04:15:18 - train: epoch 0161, iter [01160, 01251], lr: 0.000896, loss: 0.4143
2022-09-30 04:15:36 - train: epoch 0161, iter [01170, 01251], lr: 0.000896, loss: 0.4012
2022-09-30 04:15:54 - train: epoch 0161, iter [01180, 01251], lr: 0.000896, loss: 0.4152
2022-09-30 04:16:12 - train: epoch 0161, iter [01190, 01251], lr: 0.000896, loss: 0.3987
2022-09-30 04:16:31 - train: epoch 0161, iter [01200, 01251], lr: 0.000896, loss: 0.4173
2022-09-30 04:16:49 - train: epoch 0161, iter [01210, 01251], lr: 0.000896, loss: 0.4157
2022-09-30 04:17:07 - train: epoch 0161, iter [01220, 01251], lr: 0.000896, loss: 0.4054
2022-09-30 04:17:25 - train: epoch 0161, iter [01230, 01251], lr: 0.000896, loss: 0.4258
2022-09-30 04:17:43 - train: epoch 0161, iter [01240, 01251], lr: 0.000895, loss: 0.4135
2022-09-30 04:18:01 - train: epoch 0161, iter [01250, 01251], lr: 0.000895, loss: 0.4033
2022-09-30 04:18:04 - train: epoch 161, train_loss: 0.4097
2022-09-30 04:18:07 - until epoch: 161, best_loss: 0.4097
2022-09-30 04:18:07 - epoch 162 lr: 0.000895
2022-09-30 04:18:31 - train: epoch 0162, iter [00010, 01251], lr: 0.000895, loss: 0.4106
2022-09-30 04:18:49 - train: epoch 0162, iter [00020, 01251], lr: 0.000895, loss: 0.4064
2022-09-30 04:19:07 - train: epoch 0162, iter [00030, 01251], lr: 0.000895, loss: 0.4067
2022-09-30 04:19:25 - train: epoch 0162, iter [00040, 01251], lr: 0.000895, loss: 0.4008
2022-09-30 04:19:43 - train: epoch 0162, iter [00050, 01251], lr: 0.000895, loss: 0.3953
2022-09-30 04:20:00 - train: epoch 0162, iter [00060, 01251], lr: 0.000895, loss: 0.3981
2022-09-30 04:20:19 - train: epoch 0162, iter [00070, 01251], lr: 0.000895, loss: 0.3899
2022-09-30 04:20:37 - train: epoch 0162, iter [00080, 01251], lr: 0.000895, loss: 0.4135
2022-09-30 04:20:55 - train: epoch 0162, iter [00090, 01251], lr: 0.000895, loss: 0.3966
2022-09-30 04:21:13 - train: epoch 0162, iter [00100, 01251], lr: 0.000895, loss: 0.4036
2022-09-30 04:21:31 - train: epoch 0162, iter [00110, 01251], lr: 0.000895, loss: 0.4091
2022-09-30 04:21:49 - train: epoch 0162, iter [00120, 01251], lr: 0.000895, loss: 0.4057
2022-09-30 04:22:07 - train: epoch 0162, iter [00130, 01251], lr: 0.000895, loss: 0.4049
2022-09-30 04:22:25 - train: epoch 0162, iter [00140, 01251], lr: 0.000895, loss: 0.4119
2022-09-30 04:22:43 - train: epoch 0162, iter [00150, 01251], lr: 0.000895, loss: 0.4132
2022-09-30 04:23:01 - train: epoch 0162, iter [00160, 01251], lr: 0.000895, loss: 0.4119
2022-09-30 04:23:19 - train: epoch 0162, iter [00170, 01251], lr: 0.000895, loss: 0.4200
2022-09-30 04:23:37 - train: epoch 0162, iter [00180, 01251], lr: 0.000895, loss: 0.4158
2022-09-30 04:23:55 - train: epoch 0162, iter [00190, 01251], lr: 0.000895, loss: 0.4096
2022-09-30 04:24:13 - train: epoch 0162, iter [00200, 01251], lr: 0.000895, loss: 0.3913
2022-09-30 04:24:31 - train: epoch 0162, iter [00210, 01251], lr: 0.000895, loss: 0.4017
2022-09-30 04:24:49 - train: epoch 0162, iter [00220, 01251], lr: 0.000895, loss: 0.4122
2022-09-30 04:25:07 - train: epoch 0162, iter [00230, 01251], lr: 0.000895, loss: 0.3882
2022-09-30 04:25:25 - train: epoch 0162, iter [00240, 01251], lr: 0.000895, loss: 0.4177
2022-09-30 04:25:43 - train: epoch 0162, iter [00250, 01251], lr: 0.000895, loss: 0.3927
2022-09-30 04:26:01 - train: epoch 0162, iter [00260, 01251], lr: 0.000895, loss: 0.3958
2022-09-30 04:26:19 - train: epoch 0162, iter [00270, 01251], lr: 0.000894, loss: 0.4316
2022-09-30 04:26:37 - train: epoch 0162, iter [00280, 01251], lr: 0.000894, loss: 0.4270
2022-09-30 04:26:56 - train: epoch 0162, iter [00290, 01251], lr: 0.000894, loss: 0.3888
2022-09-30 04:27:14 - train: epoch 0162, iter [00300, 01251], lr: 0.000894, loss: 0.3975
2022-09-30 04:27:32 - train: epoch 0162, iter [00310, 01251], lr: 0.000894, loss: 0.4136
2022-09-30 04:27:50 - train: epoch 0162, iter [00320, 01251], lr: 0.000894, loss: 0.4035
2022-09-30 04:28:08 - train: epoch 0162, iter [00330, 01251], lr: 0.000894, loss: 0.4193
2022-09-30 04:28:26 - train: epoch 0162, iter [00340, 01251], lr: 0.000894, loss: 0.3961
2022-09-30 04:28:44 - train: epoch 0162, iter [00350, 01251], lr: 0.000894, loss: 0.4064
2022-09-30 04:29:02 - train: epoch 0162, iter [00360, 01251], lr: 0.000894, loss: 0.4039
2022-09-30 04:29:20 - train: epoch 0162, iter [00370, 01251], lr: 0.000894, loss: 0.4162
2022-09-30 04:29:38 - train: epoch 0162, iter [00380, 01251], lr: 0.000894, loss: 0.4176
2022-09-30 04:29:56 - train: epoch 0162, iter [00390, 01251], lr: 0.000894, loss: 0.4263
2022-09-30 04:30:14 - train: epoch 0162, iter [00400, 01251], lr: 0.000894, loss: 0.4212
2022-09-30 04:30:32 - train: epoch 0162, iter [00410, 01251], lr: 0.000894, loss: 0.4103
2022-09-30 04:30:50 - train: epoch 0162, iter [00420, 01251], lr: 0.000894, loss: 0.4112
2022-09-30 04:31:08 - train: epoch 0162, iter [00430, 01251], lr: 0.000894, loss: 0.4048
2022-09-30 04:31:26 - train: epoch 0162, iter [00440, 01251], lr: 0.000894, loss: 0.4003
2022-09-30 04:31:44 - train: epoch 0162, iter [00450, 01251], lr: 0.000894, loss: 0.4136
2022-09-30 04:32:02 - train: epoch 0162, iter [00460, 01251], lr: 0.000894, loss: 0.4053
2022-09-30 04:32:20 - train: epoch 0162, iter [00470, 01251], lr: 0.000894, loss: 0.4207
2022-09-30 04:32:39 - train: epoch 0162, iter [00480, 01251], lr: 0.000894, loss: 0.4257
2022-09-30 04:32:57 - train: epoch 0162, iter [00490, 01251], lr: 0.000894, loss: 0.4077
2022-09-30 04:33:15 - train: epoch 0162, iter [00500, 01251], lr: 0.000894, loss: 0.4003
2022-09-30 04:33:33 - train: epoch 0162, iter [00510, 01251], lr: 0.000894, loss: 0.4167
2022-09-30 04:33:51 - train: epoch 0162, iter [00520, 01251], lr: 0.000894, loss: 0.3898
2022-09-30 04:34:09 - train: epoch 0162, iter [00530, 01251], lr: 0.000894, loss: 0.3924
2022-09-30 04:34:27 - train: epoch 0162, iter [00540, 01251], lr: 0.000893, loss: 0.4256
2022-09-30 04:34:45 - train: epoch 0162, iter [00550, 01251], lr: 0.000893, loss: 0.4051
2022-09-30 04:35:03 - train: epoch 0162, iter [00560, 01251], lr: 0.000893, loss: 0.4004
2022-09-30 04:35:21 - train: epoch 0162, iter [00570, 01251], lr: 0.000893, loss: 0.4112
2022-09-30 04:35:40 - train: epoch 0162, iter [00580, 01251], lr: 0.000893, loss: 0.4100
2022-09-30 04:35:58 - train: epoch 0162, iter [00590, 01251], lr: 0.000893, loss: 0.3983
2022-09-30 04:36:16 - train: epoch 0162, iter [00600, 01251], lr: 0.000893, loss: 0.4151
2022-09-30 04:36:34 - train: epoch 0162, iter [00610, 01251], lr: 0.000893, loss: 0.4105
2022-09-30 04:36:52 - train: epoch 0162, iter [00620, 01251], lr: 0.000893, loss: 0.4269
2022-09-30 04:37:10 - train: epoch 0162, iter [00630, 01251], lr: 0.000893, loss: 0.4098
2022-09-30 04:37:28 - train: epoch 0162, iter [00640, 01251], lr: 0.000893, loss: 0.4171
2022-09-30 04:37:46 - train: epoch 0162, iter [00650, 01251], lr: 0.000893, loss: 0.4102
2022-09-30 04:38:04 - train: epoch 0162, iter [00660, 01251], lr: 0.000893, loss: 0.4201
2022-09-30 04:38:21 - train: epoch 0162, iter [00670, 01251], lr: 0.000893, loss: 0.4006
2022-09-30 04:38:39 - train: epoch 0162, iter [00680, 01251], lr: 0.000893, loss: 0.4007
2022-09-30 04:38:58 - train: epoch 0162, iter [00690, 01251], lr: 0.000893, loss: 0.3984
2022-09-30 04:39:16 - train: epoch 0162, iter [00700, 01251], lr: 0.000893, loss: 0.3883
2022-09-30 04:39:34 - train: epoch 0162, iter [00710, 01251], lr: 0.000893, loss: 0.4114
2022-09-30 04:39:52 - train: epoch 0162, iter [00720, 01251], lr: 0.000893, loss: 0.4185
2022-09-30 04:40:10 - train: epoch 0162, iter [00730, 01251], lr: 0.000893, loss: 0.4231
2022-09-30 04:40:28 - train: epoch 0162, iter [00740, 01251], lr: 0.000893, loss: 0.4156
2022-09-30 04:40:46 - train: epoch 0162, iter [00750, 01251], lr: 0.000893, loss: 0.4203
2022-09-30 04:41:04 - train: epoch 0162, iter [00760, 01251], lr: 0.000893, loss: 0.4074
2022-09-30 04:41:22 - train: epoch 0162, iter [00770, 01251], lr: 0.000893, loss: 0.4219
2022-09-30 04:41:39 - train: epoch 0162, iter [00780, 01251], lr: 0.000893, loss: 0.4030
2022-09-30 04:41:58 - train: epoch 0162, iter [00790, 01251], lr: 0.000893, loss: 0.4125
2022-09-30 04:42:16 - train: epoch 0162, iter [00800, 01251], lr: 0.000893, loss: 0.4041
2022-09-30 04:42:34 - train: epoch 0162, iter [00810, 01251], lr: 0.000892, loss: 0.4066
2022-09-30 04:42:52 - train: epoch 0162, iter [00820, 01251], lr: 0.000892, loss: 0.4146
2022-09-30 04:43:10 - train: epoch 0162, iter [00830, 01251], lr: 0.000892, loss: 0.3962
2022-09-30 04:43:28 - train: epoch 0162, iter [00840, 01251], lr: 0.000892, loss: 0.4218
2022-09-30 04:43:46 - train: epoch 0162, iter [00850, 01251], lr: 0.000892, loss: 0.4045
2022-09-30 04:44:04 - train: epoch 0162, iter [00860, 01251], lr: 0.000892, loss: 0.4124
2022-09-30 04:44:22 - train: epoch 0162, iter [00870, 01251], lr: 0.000892, loss: 0.4251
2022-09-30 04:44:40 - train: epoch 0162, iter [00880, 01251], lr: 0.000892, loss: 0.4178
2022-09-30 04:44:58 - train: epoch 0162, iter [00890, 01251], lr: 0.000892, loss: 0.3897
2022-09-30 04:45:16 - train: epoch 0162, iter [00900, 01251], lr: 0.000892, loss: 0.3989
2022-09-30 04:45:34 - train: epoch 0162, iter [00910, 01251], lr: 0.000892, loss: 0.3974
2022-09-30 04:45:52 - train: epoch 0162, iter [00920, 01251], lr: 0.000892, loss: 0.4001
2022-09-30 04:46:10 - train: epoch 0162, iter [00930, 01251], lr: 0.000892, loss: 0.4107
2022-09-30 04:46:28 - train: epoch 0162, iter [00940, 01251], lr: 0.000892, loss: 0.4224
2022-09-30 04:46:46 - train: epoch 0162, iter [00950, 01251], lr: 0.000892, loss: 0.4201
2022-09-30 04:47:04 - train: epoch 0162, iter [00960, 01251], lr: 0.000892, loss: 0.4253
2022-09-30 04:47:22 - train: epoch 0162, iter [00970, 01251], lr: 0.000892, loss: 0.3787
2022-09-30 04:47:40 - train: epoch 0162, iter [00980, 01251], lr: 0.000892, loss: 0.4000
2022-09-30 04:47:58 - train: epoch 0162, iter [00990, 01251], lr: 0.000892, loss: 0.4140
2022-09-30 04:48:16 - train: epoch 0162, iter [01000, 01251], lr: 0.000892, loss: 0.4107
2022-09-30 04:48:34 - train: epoch 0162, iter [01010, 01251], lr: 0.000892, loss: 0.3926
2022-09-30 04:48:52 - train: epoch 0162, iter [01020, 01251], lr: 0.000892, loss: 0.4270
2022-09-30 04:49:10 - train: epoch 0162, iter [01030, 01251], lr: 0.000892, loss: 0.4109
2022-09-30 04:49:28 - train: epoch 0162, iter [01040, 01251], lr: 0.000892, loss: 0.4199
2022-09-30 04:49:46 - train: epoch 0162, iter [01050, 01251], lr: 0.000892, loss: 0.4353
2022-09-30 04:50:04 - train: epoch 0162, iter [01060, 01251], lr: 0.000892, loss: 0.4122
2022-09-30 04:50:22 - train: epoch 0162, iter [01070, 01251], lr: 0.000892, loss: 0.3961
2022-09-30 04:50:40 - train: epoch 0162, iter [01080, 01251], lr: 0.000892, loss: 0.4176
2022-09-30 04:50:58 - train: epoch 0162, iter [01090, 01251], lr: 0.000891, loss: 0.3954
2022-09-30 04:51:16 - train: epoch 0162, iter [01100, 01251], lr: 0.000891, loss: 0.4067
2022-09-30 04:51:34 - train: epoch 0162, iter [01110, 01251], lr: 0.000891, loss: 0.4038
2022-09-30 04:51:52 - train: epoch 0162, iter [01120, 01251], lr: 0.000891, loss: 0.4078
2022-09-30 04:52:10 - train: epoch 0162, iter [01130, 01251], lr: 0.000891, loss: 0.4221
2022-09-30 04:52:29 - train: epoch 0162, iter [01140, 01251], lr: 0.000891, loss: 0.4092
2022-09-30 04:52:47 - train: epoch 0162, iter [01150, 01251], lr: 0.000891, loss: 0.3950
2022-09-30 04:53:05 - train: epoch 0162, iter [01160, 01251], lr: 0.000891, loss: 0.3964
2022-09-30 04:53:23 - train: epoch 0162, iter [01170, 01251], lr: 0.000891, loss: 0.3916
2022-09-30 04:53:41 - train: epoch 0162, iter [01180, 01251], lr: 0.000891, loss: 0.3984
2022-09-30 04:54:00 - train: epoch 0162, iter [01190, 01251], lr: 0.000891, loss: 0.4115
2022-09-30 04:54:17 - train: epoch 0162, iter [01200, 01251], lr: 0.000891, loss: 0.4051
2022-09-30 04:54:35 - train: epoch 0162, iter [01210, 01251], lr: 0.000891, loss: 0.4125
2022-09-30 04:54:54 - train: epoch 0162, iter [01220, 01251], lr: 0.000891, loss: 0.4032
2022-09-30 04:55:12 - train: epoch 0162, iter [01230, 01251], lr: 0.000891, loss: 0.4208
2022-09-30 04:55:30 - train: epoch 0162, iter [01240, 01251], lr: 0.000891, loss: 0.4081
2022-09-30 04:55:47 - train: epoch 0162, iter [01250, 01251], lr: 0.000891, loss: 0.4219
2022-09-30 04:55:51 - train: epoch 162, train_loss: 0.4096
2022-09-30 04:55:53 - until epoch: 162, best_loss: 0.4096
2022-09-30 04:55:53 - epoch 163 lr: 0.000891
2022-09-30 04:56:18 - train: epoch 0163, iter [00010, 01251], lr: 0.000891, loss: 0.4091
2022-09-30 04:56:36 - train: epoch 0163, iter [00020, 01251], lr: 0.000891, loss: 0.3970
2022-09-30 04:56:54 - train: epoch 0163, iter [00030, 01251], lr: 0.000891, loss: 0.4003
2022-09-30 04:57:13 - train: epoch 0163, iter [00040, 01251], lr: 0.000891, loss: 0.4367
2022-09-30 04:57:30 - train: epoch 0163, iter [00050, 01251], lr: 0.000891, loss: 0.4143
2022-09-30 04:57:49 - train: epoch 0163, iter [00060, 01251], lr: 0.000891, loss: 0.3848
2022-09-30 04:58:07 - train: epoch 0163, iter [00070, 01251], lr: 0.000891, loss: 0.4190
2022-09-30 04:58:25 - train: epoch 0163, iter [00080, 01251], lr: 0.000891, loss: 0.4002
2022-09-30 04:58:43 - train: epoch 0163, iter [00090, 01251], lr: 0.000891, loss: 0.3971
2022-09-30 04:59:02 - train: epoch 0163, iter [00100, 01251], lr: 0.000891, loss: 0.4009
2022-09-30 04:59:20 - train: epoch 0163, iter [00110, 01251], lr: 0.000890, loss: 0.4114
2022-09-30 04:59:38 - train: epoch 0163, iter [00120, 01251], lr: 0.000890, loss: 0.4133
2022-09-30 04:59:56 - train: epoch 0163, iter [00130, 01251], lr: 0.000890, loss: 0.4155
2022-09-30 05:00:14 - train: epoch 0163, iter [00140, 01251], lr: 0.000890, loss: 0.4138
2022-09-30 05:00:32 - train: epoch 0163, iter [00150, 01251], lr: 0.000890, loss: 0.3997
2022-09-30 05:00:50 - train: epoch 0163, iter [00160, 01251], lr: 0.000890, loss: 0.4163
2022-09-30 05:01:08 - train: epoch 0163, iter [00170, 01251], lr: 0.000890, loss: 0.4002
2022-09-30 05:01:26 - train: epoch 0163, iter [00180, 01251], lr: 0.000890, loss: 0.4405
2022-09-30 05:01:45 - train: epoch 0163, iter [00190, 01251], lr: 0.000890, loss: 0.4122
2022-09-30 05:02:03 - train: epoch 0163, iter [00200, 01251], lr: 0.000890, loss: 0.4102
2022-09-30 05:02:21 - train: epoch 0163, iter [00210, 01251], lr: 0.000890, loss: 0.3996
2022-09-30 05:02:39 - train: epoch 0163, iter [00220, 01251], lr: 0.000890, loss: 0.4048
2022-09-30 05:02:57 - train: epoch 0163, iter [00230, 01251], lr: 0.000890, loss: 0.3933
2022-09-30 05:03:15 - train: epoch 0163, iter [00240, 01251], lr: 0.000890, loss: 0.4143
2022-09-30 05:03:33 - train: epoch 0163, iter [00250, 01251], lr: 0.000890, loss: 0.4263
2022-09-30 05:03:51 - train: epoch 0163, iter [00260, 01251], lr: 0.000890, loss: 0.4119
2022-09-30 05:04:09 - train: epoch 0163, iter [00270, 01251], lr: 0.000890, loss: 0.4047
2022-09-30 05:04:27 - train: epoch 0163, iter [00280, 01251], lr: 0.000890, loss: 0.4043
2022-09-30 05:04:45 - train: epoch 0163, iter [00290, 01251], lr: 0.000890, loss: 0.4214
2022-09-30 05:05:03 - train: epoch 0163, iter [00300, 01251], lr: 0.000890, loss: 0.4030
2022-09-30 05:05:21 - train: epoch 0163, iter [00310, 01251], lr: 0.000890, loss: 0.4341
2022-09-30 05:05:40 - train: epoch 0163, iter [00320, 01251], lr: 0.000890, loss: 0.4288
2022-09-30 05:05:58 - train: epoch 0163, iter [00330, 01251], lr: 0.000890, loss: 0.3897
2022-09-30 05:06:16 - train: epoch 0163, iter [00340, 01251], lr: 0.000890, loss: 0.4108
2022-09-30 05:06:34 - train: epoch 0163, iter [00350, 01251], lr: 0.000890, loss: 0.4114
2022-09-30 05:06:52 - train: epoch 0163, iter [00360, 01251], lr: 0.000890, loss: 0.4302
2022-09-30 05:07:10 - train: epoch 0163, iter [00370, 01251], lr: 0.000890, loss: 0.4331
2022-09-30 05:07:28 - train: epoch 0163, iter [00380, 01251], lr: 0.000889, loss: 0.3852
2022-09-30 05:07:46 - train: epoch 0163, iter [00390, 01251], lr: 0.000889, loss: 0.4189
2022-09-30 05:08:04 - train: epoch 0163, iter [00400, 01251], lr: 0.000889, loss: 0.4151
2022-09-30 05:08:22 - train: epoch 0163, iter [00410, 01251], lr: 0.000889, loss: 0.3985
2022-09-30 05:08:40 - train: epoch 0163, iter [00420, 01251], lr: 0.000889, loss: 0.3971
2022-09-30 05:08:58 - train: epoch 0163, iter [00430, 01251], lr: 0.000889, loss: 0.4267
2022-09-30 05:09:17 - train: epoch 0163, iter [00440, 01251], lr: 0.000889, loss: 0.4165
2022-09-30 05:09:35 - train: epoch 0163, iter [00450, 01251], lr: 0.000889, loss: 0.4025
2022-09-30 05:09:53 - train: epoch 0163, iter [00460, 01251], lr: 0.000889, loss: 0.4286
2022-09-30 05:10:11 - train: epoch 0163, iter [00470, 01251], lr: 0.000889, loss: 0.3978
2022-09-30 05:10:29 - train: epoch 0163, iter [00480, 01251], lr: 0.000889, loss: 0.3984
2022-09-30 05:10:47 - train: epoch 0163, iter [00490, 01251], lr: 0.000889, loss: 0.4220
2022-09-30 05:11:05 - train: epoch 0163, iter [00500, 01251], lr: 0.000889, loss: 0.4213
2022-09-30 05:11:23 - train: epoch 0163, iter [00510, 01251], lr: 0.000889, loss: 0.4095
2022-09-30 05:11:41 - train: epoch 0163, iter [00520, 01251], lr: 0.000889, loss: 0.3981
2022-09-30 05:11:59 - train: epoch 0163, iter [00530, 01251], lr: 0.000889, loss: 0.4020
2022-09-30 05:12:18 - train: epoch 0163, iter [00540, 01251], lr: 0.000889, loss: 0.4255
2022-09-30 05:12:36 - train: epoch 0163, iter [00550, 01251], lr: 0.000889, loss: 0.4192
2022-09-30 05:12:54 - train: epoch 0163, iter [00560, 01251], lr: 0.000889, loss: 0.4270
2022-09-30 05:13:12 - train: epoch 0163, iter [00570, 01251], lr: 0.000889, loss: 0.4101
2022-09-30 05:13:30 - train: epoch 0163, iter [00580, 01251], lr: 0.000889, loss: 0.4203
2022-09-30 05:13:48 - train: epoch 0163, iter [00590, 01251], lr: 0.000889, loss: 0.4216
2022-09-30 05:14:06 - train: epoch 0163, iter [00600, 01251], lr: 0.000889, loss: 0.3919
2022-09-30 05:14:24 - train: epoch 0163, iter [00610, 01251], lr: 0.000889, loss: 0.4008
2022-09-30 05:14:42 - train: epoch 0163, iter [00620, 01251], lr: 0.000889, loss: 0.3964
2022-09-30 05:15:00 - train: epoch 0163, iter [00630, 01251], lr: 0.000889, loss: 0.3971
2022-09-30 05:15:18 - train: epoch 0163, iter [00640, 01251], lr: 0.000889, loss: 0.4131
2022-09-30 05:15:36 - train: epoch 0163, iter [00650, 01251], lr: 0.000889, loss: 0.4101
2022-09-30 05:15:54 - train: epoch 0163, iter [00660, 01251], lr: 0.000888, loss: 0.4067
2022-09-30 05:16:12 - train: epoch 0163, iter [00670, 01251], lr: 0.000888, loss: 0.4038
2022-09-30 05:16:30 - train: epoch 0163, iter [00680, 01251], lr: 0.000888, loss: 0.4137
2022-09-30 05:16:48 - train: epoch 0163, iter [00690, 01251], lr: 0.000888, loss: 0.4252
2022-09-30 05:17:07 - train: epoch 0163, iter [00700, 01251], lr: 0.000888, loss: 0.4011
2022-09-30 05:17:25 - train: epoch 0163, iter [00710, 01251], lr: 0.000888, loss: 0.4076
2022-09-30 05:17:43 - train: epoch 0163, iter [00720, 01251], lr: 0.000888, loss: 0.4099
2022-09-30 05:18:01 - train: epoch 0163, iter [00730, 01251], lr: 0.000888, loss: 0.4133
2022-09-30 05:18:19 - train: epoch 0163, iter [00740, 01251], lr: 0.000888, loss: 0.4031
2022-09-30 05:18:37 - train: epoch 0163, iter [00750, 01251], lr: 0.000888, loss: 0.4286
2022-09-30 05:18:55 - train: epoch 0163, iter [00760, 01251], lr: 0.000888, loss: 0.4119
2022-09-30 05:19:13 - train: epoch 0163, iter [00770, 01251], lr: 0.000888, loss: 0.4015
2022-09-30 05:19:32 - train: epoch 0163, iter [00780, 01251], lr: 0.000888, loss: 0.4147
2022-09-30 05:19:50 - train: epoch 0163, iter [00790, 01251], lr: 0.000888, loss: 0.4167
2022-09-30 05:20:08 - train: epoch 0163, iter [00800, 01251], lr: 0.000888, loss: 0.4229
2022-09-30 05:20:26 - train: epoch 0163, iter [00810, 01251], lr: 0.000888, loss: 0.3975
2022-09-30 05:20:44 - train: epoch 0163, iter [00820, 01251], lr: 0.000888, loss: 0.4008
2022-09-30 05:21:02 - train: epoch 0163, iter [00830, 01251], lr: 0.000888, loss: 0.4043
2022-09-30 05:21:20 - train: epoch 0163, iter [00840, 01251], lr: 0.000888, loss: 0.4261
2022-09-30 05:21:38 - train: epoch 0163, iter [00850, 01251], lr: 0.000888, loss: 0.4047
2022-09-30 05:21:56 - train: epoch 0163, iter [00860, 01251], lr: 0.000888, loss: 0.4002
2022-09-30 05:22:14 - train: epoch 0163, iter [00870, 01251], lr: 0.000888, loss: 0.3994
2022-09-30 05:22:32 - train: epoch 0163, iter [00880, 01251], lr: 0.000888, loss: 0.4105
2022-09-30 05:22:50 - train: epoch 0163, iter [00890, 01251], lr: 0.000888, loss: 0.4184
2022-09-30 05:23:08 - train: epoch 0163, iter [00900, 01251], lr: 0.000888, loss: 0.4279
2022-09-30 05:23:26 - train: epoch 0163, iter [00910, 01251], lr: 0.000888, loss: 0.4186
2022-09-30 05:23:44 - train: epoch 0163, iter [00920, 01251], lr: 0.000888, loss: 0.3964
2022-09-30 05:24:03 - train: epoch 0163, iter [00930, 01251], lr: 0.000887, loss: 0.3940
2022-09-30 05:24:21 - train: epoch 0163, iter [00940, 01251], lr: 0.000887, loss: 0.4002
2022-09-30 05:24:39 - train: epoch 0163, iter [00950, 01251], lr: 0.000887, loss: 0.4164
2022-09-30 05:24:57 - train: epoch 0163, iter [00960, 01251], lr: 0.000887, loss: 0.4057
2022-09-30 05:25:15 - train: epoch 0163, iter [00970, 01251], lr: 0.000887, loss: 0.4129
2022-09-30 05:25:33 - train: epoch 0163, iter [00980, 01251], lr: 0.000887, loss: 0.4002
2022-09-30 05:25:51 - train: epoch 0163, iter [00990, 01251], lr: 0.000887, loss: 0.3996
2022-09-30 05:26:09 - train: epoch 0163, iter [01000, 01251], lr: 0.000887, loss: 0.4115
2022-09-30 05:26:27 - train: epoch 0163, iter [01010, 01251], lr: 0.000887, loss: 0.3994
2022-09-30 05:26:45 - train: epoch 0163, iter [01020, 01251], lr: 0.000887, loss: 0.4014
2022-09-30 05:27:03 - train: epoch 0163, iter [01030, 01251], lr: 0.000887, loss: 0.4096
2022-09-30 05:27:21 - train: epoch 0163, iter [01040, 01251], lr: 0.000887, loss: 0.4156
2022-09-30 05:27:39 - train: epoch 0163, iter [01050, 01251], lr: 0.000887, loss: 0.4119
2022-09-30 05:27:57 - train: epoch 0163, iter [01060, 01251], lr: 0.000887, loss: 0.4127
2022-09-30 05:28:15 - train: epoch 0163, iter [01070, 01251], lr: 0.000887, loss: 0.4347
2022-09-30 05:28:33 - train: epoch 0163, iter [01080, 01251], lr: 0.000887, loss: 0.3840
2022-09-30 05:28:51 - train: epoch 0163, iter [01090, 01251], lr: 0.000887, loss: 0.4120
2022-09-30 05:29:09 - train: epoch 0163, iter [01100, 01251], lr: 0.000887, loss: 0.4147
2022-09-30 05:29:27 - train: epoch 0163, iter [01110, 01251], lr: 0.000887, loss: 0.3990
2022-09-30 05:29:45 - train: epoch 0163, iter [01120, 01251], lr: 0.000887, loss: 0.4138
2022-09-30 05:30:03 - train: epoch 0163, iter [01130, 01251], lr: 0.000887, loss: 0.4287
2022-09-30 05:30:21 - train: epoch 0163, iter [01140, 01251], lr: 0.000887, loss: 0.4055
2022-09-30 05:30:39 - train: epoch 0163, iter [01150, 01251], lr: 0.000887, loss: 0.4300
2022-09-30 05:30:57 - train: epoch 0163, iter [01160, 01251], lr: 0.000887, loss: 0.4172
2022-09-30 05:31:15 - train: epoch 0163, iter [01170, 01251], lr: 0.000887, loss: 0.4082
2022-09-30 05:31:33 - train: epoch 0163, iter [01180, 01251], lr: 0.000887, loss: 0.3941
2022-09-30 05:31:51 - train: epoch 0163, iter [01190, 01251], lr: 0.000887, loss: 0.4075
2022-09-30 05:32:09 - train: epoch 0163, iter [01200, 01251], lr: 0.000886, loss: 0.4063
2022-09-30 05:32:27 - train: epoch 0163, iter [01210, 01251], lr: 0.000886, loss: 0.4113
2022-09-30 05:32:45 - train: epoch 0163, iter [01220, 01251], lr: 0.000886, loss: 0.4278
2022-09-30 05:33:03 - train: epoch 0163, iter [01230, 01251], lr: 0.000886, loss: 0.4343
2022-09-30 05:33:21 - train: epoch 0163, iter [01240, 01251], lr: 0.000886, loss: 0.4165
2022-09-30 05:33:39 - train: epoch 0163, iter [01250, 01251], lr: 0.000886, loss: 0.3938
2022-09-30 05:33:42 - train: epoch 163, train_loss: 0.4095
2022-09-30 05:33:45 - until epoch: 163, best_loss: 0.4095
2022-09-30 05:33:45 - epoch 164 lr: 0.000886
2022-09-30 05:34:09 - train: epoch 0164, iter [00010, 01251], lr: 0.000886, loss: 0.4115
2022-09-30 05:34:27 - train: epoch 0164, iter [00020, 01251], lr: 0.000886, loss: 0.4039
2022-09-30 05:34:45 - train: epoch 0164, iter [00030, 01251], lr: 0.000886, loss: 0.4147
2022-09-30 05:35:03 - train: epoch 0164, iter [00040, 01251], lr: 0.000886, loss: 0.4085
2022-09-30 05:35:21 - train: epoch 0164, iter [00050, 01251], lr: 0.000886, loss: 0.3978
2022-09-30 05:35:40 - train: epoch 0164, iter [00060, 01251], lr: 0.000886, loss: 0.3848
2022-09-30 05:35:58 - train: epoch 0164, iter [00070, 01251], lr: 0.000886, loss: 0.3936
2022-09-30 05:36:16 - train: epoch 0164, iter [00080, 01251], lr: 0.000886, loss: 0.4016
2022-09-30 05:36:34 - train: epoch 0164, iter [00090, 01251], lr: 0.000886, loss: 0.4226
2022-09-30 05:36:52 - train: epoch 0164, iter [00100, 01251], lr: 0.000886, loss: 0.4213
2022-09-30 05:37:10 - train: epoch 0164, iter [00110, 01251], lr: 0.000886, loss: 0.4039
2022-09-30 05:37:28 - train: epoch 0164, iter [00120, 01251], lr: 0.000886, loss: 0.3904
2022-09-30 05:37:46 - train: epoch 0164, iter [00130, 01251], lr: 0.000886, loss: 0.3954
2022-09-30 05:38:05 - train: epoch 0164, iter [00140, 01251], lr: 0.000886, loss: 0.4124
2022-09-30 05:38:23 - train: epoch 0164, iter [00150, 01251], lr: 0.000886, loss: 0.4123
2022-09-30 05:38:41 - train: epoch 0164, iter [00160, 01251], lr: 0.000886, loss: 0.4146
2022-09-30 05:38:59 - train: epoch 0164, iter [00170, 01251], lr: 0.000886, loss: 0.4093
2022-09-30 05:39:17 - train: epoch 0164, iter [00180, 01251], lr: 0.000886, loss: 0.3995
2022-09-30 05:39:35 - train: epoch 0164, iter [00190, 01251], lr: 0.000886, loss: 0.4093
2022-09-30 05:39:53 - train: epoch 0164, iter [00200, 01251], lr: 0.000886, loss: 0.3830
2022-09-30 05:40:12 - train: epoch 0164, iter [00210, 01251], lr: 0.000886, loss: 0.4118
2022-09-30 05:40:30 - train: epoch 0164, iter [00220, 01251], lr: 0.000885, loss: 0.4205
2022-09-30 05:40:48 - train: epoch 0164, iter [00230, 01251], lr: 0.000885, loss: 0.4119
2022-09-30 05:41:06 - train: epoch 0164, iter [00240, 01251], lr: 0.000885, loss: 0.4196
2022-09-30 05:41:25 - train: epoch 0164, iter [00250, 01251], lr: 0.000885, loss: 0.4262
2022-09-30 05:41:43 - train: epoch 0164, iter [00260, 01251], lr: 0.000885, loss: 0.3859
2022-09-30 05:42:01 - train: epoch 0164, iter [00270, 01251], lr: 0.000885, loss: 0.4192
2022-09-30 05:42:19 - train: epoch 0164, iter [00280, 01251], lr: 0.000885, loss: 0.3875
2022-09-30 05:42:37 - train: epoch 0164, iter [00290, 01251], lr: 0.000885, loss: 0.4011
2022-09-30 05:42:55 - train: epoch 0164, iter [00300, 01251], lr: 0.000885, loss: 0.4282
2022-09-30 05:43:13 - train: epoch 0164, iter [00310, 01251], lr: 0.000885, loss: 0.4125
2022-09-30 05:43:31 - train: epoch 0164, iter [00320, 01251], lr: 0.000885, loss: 0.3993
2022-09-30 05:43:49 - train: epoch 0164, iter [00330, 01251], lr: 0.000885, loss: 0.4239
2022-09-30 05:44:07 - train: epoch 0164, iter [00340, 01251], lr: 0.000885, loss: 0.4076
2022-09-30 05:44:25 - train: epoch 0164, iter [00350, 01251], lr: 0.000885, loss: 0.4040
2022-09-30 05:44:43 - train: epoch 0164, iter [00360, 01251], lr: 0.000885, loss: 0.4207
2022-09-30 05:45:01 - train: epoch 0164, iter [00370, 01251], lr: 0.000885, loss: 0.4086
2022-09-30 05:45:19 - train: epoch 0164, iter [00380, 01251], lr: 0.000885, loss: 0.4170
2022-09-30 05:45:37 - train: epoch 0164, iter [00390, 01251], lr: 0.000885, loss: 0.4252
2022-09-30 05:45:55 - train: epoch 0164, iter [00400, 01251], lr: 0.000885, loss: 0.3886
2022-09-30 05:46:13 - train: epoch 0164, iter [00410, 01251], lr: 0.000885, loss: 0.4322
2022-09-30 05:46:31 - train: epoch 0164, iter [00420, 01251], lr: 0.000885, loss: 0.4082
2022-09-30 05:46:49 - train: epoch 0164, iter [00430, 01251], lr: 0.000885, loss: 0.4038
2022-09-30 05:47:07 - train: epoch 0164, iter [00440, 01251], lr: 0.000885, loss: 0.4179
2022-09-30 05:47:25 - train: epoch 0164, iter [00450, 01251], lr: 0.000885, loss: 0.4059
2022-09-30 05:47:43 - train: epoch 0164, iter [00460, 01251], lr: 0.000885, loss: 0.4158
2022-09-30 05:48:01 - train: epoch 0164, iter [00470, 01251], lr: 0.000885, loss: 0.3982
2022-09-30 05:48:19 - train: epoch 0164, iter [00480, 01251], lr: 0.000885, loss: 0.4296
2022-09-30 05:48:38 - train: epoch 0164, iter [00490, 01251], lr: 0.000884, loss: 0.4128
2022-09-30 05:48:56 - train: epoch 0164, iter [00500, 01251], lr: 0.000884, loss: 0.4029
2022-09-30 05:49:14 - train: epoch 0164, iter [00510, 01251], lr: 0.000884, loss: 0.4179
2022-09-30 05:49:32 - train: epoch 0164, iter [00520, 01251], lr: 0.000884, loss: 0.4334
2022-09-30 05:49:50 - train: epoch 0164, iter [00530, 01251], lr: 0.000884, loss: 0.4115
2022-09-30 05:50:08 - train: epoch 0164, iter [00540, 01251], lr: 0.000884, loss: 0.4000
2022-09-30 05:50:26 - train: epoch 0164, iter [00550, 01251], lr: 0.000884, loss: 0.4070
2022-09-30 05:50:45 - train: epoch 0164, iter [00560, 01251], lr: 0.000884, loss: 0.4075
2022-09-30 05:51:03 - train: epoch 0164, iter [00570, 01251], lr: 0.000884, loss: 0.4029
2022-09-30 05:51:21 - train: epoch 0164, iter [00580, 01251], lr: 0.000884, loss: 0.4008
2022-09-30 05:51:39 - train: epoch 0164, iter [00590, 01251], lr: 0.000884, loss: 0.4066
2022-09-30 05:51:57 - train: epoch 0164, iter [00600, 01251], lr: 0.000884, loss: 0.4330
2022-09-30 05:52:15 - train: epoch 0164, iter [00610, 01251], lr: 0.000884, loss: 0.4014
2022-09-30 05:52:34 - train: epoch 0164, iter [00620, 01251], lr: 0.000884, loss: 0.4192
2022-09-30 05:52:52 - train: epoch 0164, iter [00630, 01251], lr: 0.000884, loss: 0.3852
2022-09-30 05:53:10 - train: epoch 0164, iter [00640, 01251], lr: 0.000884, loss: 0.4165
2022-09-30 05:53:28 - train: epoch 0164, iter [00650, 01251], lr: 0.000884, loss: 0.4115
2022-09-30 05:53:46 - train: epoch 0164, iter [00660, 01251], lr: 0.000884, loss: 0.3906
2022-09-30 05:54:04 - train: epoch 0164, iter [00670, 01251], lr: 0.000884, loss: 0.4070
2022-09-30 05:54:22 - train: epoch 0164, iter [00680, 01251], lr: 0.000884, loss: 0.3941
2022-09-30 05:54:41 - train: epoch 0164, iter [00690, 01251], lr: 0.000884, loss: 0.4146
2022-09-30 05:54:59 - train: epoch 0164, iter [00700, 01251], lr: 0.000884, loss: 0.3981
2022-09-30 05:55:17 - train: epoch 0164, iter [00710, 01251], lr: 0.000884, loss: 0.4053
2022-09-30 05:55:35 - train: epoch 0164, iter [00720, 01251], lr: 0.000884, loss: 0.4031
2022-09-30 05:55:53 - train: epoch 0164, iter [00730, 01251], lr: 0.000884, loss: 0.4085
2022-09-30 05:56:11 - train: epoch 0164, iter [00740, 01251], lr: 0.000884, loss: 0.4261
2022-09-30 05:56:30 - train: epoch 0164, iter [00750, 01251], lr: 0.000884, loss: 0.3913
2022-09-30 05:56:48 - train: epoch 0164, iter [00760, 01251], lr: 0.000883, loss: 0.3940
2022-09-30 05:57:06 - train: epoch 0164, iter [00770, 01251], lr: 0.000883, loss: 0.4122
2022-09-30 05:57:24 - train: epoch 0164, iter [00780, 01251], lr: 0.000883, loss: 0.3992
2022-09-30 05:57:42 - train: epoch 0164, iter [00790, 01251], lr: 0.000883, loss: 0.3964
2022-09-30 05:58:00 - train: epoch 0164, iter [00800, 01251], lr: 0.000883, loss: 0.4224
2022-09-30 05:58:18 - train: epoch 0164, iter [00810, 01251], lr: 0.000883, loss: 0.3988
2022-09-30 05:58:36 - train: epoch 0164, iter [00820, 01251], lr: 0.000883, loss: 0.4134
2022-09-30 05:58:55 - train: epoch 0164, iter [00830, 01251], lr: 0.000883, loss: 0.4175
2022-09-30 05:59:13 - train: epoch 0164, iter [00840, 01251], lr: 0.000883, loss: 0.4096
2022-09-30 05:59:31 - train: epoch 0164, iter [00850, 01251], lr: 0.000883, loss: 0.3996
2022-09-30 05:59:49 - train: epoch 0164, iter [00860, 01251], lr: 0.000883, loss: 0.3998
2022-09-30 06:00:07 - train: epoch 0164, iter [00870, 01251], lr: 0.000883, loss: 0.4046
2022-09-30 06:00:25 - train: epoch 0164, iter [00880, 01251], lr: 0.000883, loss: 0.4091
2022-09-30 06:00:43 - train: epoch 0164, iter [00890, 01251], lr: 0.000883, loss: 0.4223
2022-09-30 06:01:01 - train: epoch 0164, iter [00900, 01251], lr: 0.000883, loss: 0.4088
2022-09-30 06:01:19 - train: epoch 0164, iter [00910, 01251], lr: 0.000883, loss: 0.4245
2022-09-30 06:01:37 - train: epoch 0164, iter [00920, 01251], lr: 0.000883, loss: 0.3833
2022-09-30 06:01:56 - train: epoch 0164, iter [00930, 01251], lr: 0.000883, loss: 0.4136
2022-09-30 06:02:14 - train: epoch 0164, iter [00940, 01251], lr: 0.000883, loss: 0.4142
2022-09-30 06:02:32 - train: epoch 0164, iter [00950, 01251], lr: 0.000883, loss: 0.3915
2022-09-30 06:02:50 - train: epoch 0164, iter [00960, 01251], lr: 0.000883, loss: 0.4053
2022-09-30 06:03:08 - train: epoch 0164, iter [00970, 01251], lr: 0.000883, loss: 0.4256
2022-09-30 06:03:26 - train: epoch 0164, iter [00980, 01251], lr: 0.000883, loss: 0.4065
2022-09-30 06:03:44 - train: epoch 0164, iter [00990, 01251], lr: 0.000883, loss: 0.4129
2022-09-30 06:04:02 - train: epoch 0164, iter [01000, 01251], lr: 0.000883, loss: 0.4156
2022-09-30 06:04:20 - train: epoch 0164, iter [01010, 01251], lr: 0.000883, loss: 0.4236
2022-09-30 06:04:38 - train: epoch 0164, iter [01020, 01251], lr: 0.000883, loss: 0.4259
2022-09-30 06:04:56 - train: epoch 0164, iter [01030, 01251], lr: 0.000882, loss: 0.4267
2022-09-30 06:05:15 - train: epoch 0164, iter [01040, 01251], lr: 0.000882, loss: 0.4229
2022-09-30 06:05:33 - train: epoch 0164, iter [01050, 01251], lr: 0.000882, loss: 0.4068
2022-09-30 06:05:51 - train: epoch 0164, iter [01060, 01251], lr: 0.000882, loss: 0.4060
2022-09-30 06:06:09 - train: epoch 0164, iter [01070, 01251], lr: 0.000882, loss: 0.4165
2022-09-30 06:06:27 - train: epoch 0164, iter [01080, 01251], lr: 0.000882, loss: 0.4127
2022-09-30 06:06:45 - train: epoch 0164, iter [01090, 01251], lr: 0.000882, loss: 0.4100
2022-09-30 06:07:03 - train: epoch 0164, iter [01100, 01251], lr: 0.000882, loss: 0.4178
2022-09-30 06:07:21 - train: epoch 0164, iter [01110, 01251], lr: 0.000882, loss: 0.4173
2022-09-30 06:07:39 - train: epoch 0164, iter [01120, 01251], lr: 0.000882, loss: 0.3906
2022-09-30 06:07:57 - train: epoch 0164, iter [01130, 01251], lr: 0.000882, loss: 0.3850
2022-09-30 06:08:15 - train: epoch 0164, iter [01140, 01251], lr: 0.000882, loss: 0.3962
2022-09-30 06:08:33 - train: epoch 0164, iter [01150, 01251], lr: 0.000882, loss: 0.3962
2022-09-30 06:08:51 - train: epoch 0164, iter [01160, 01251], lr: 0.000882, loss: 0.3997
2022-09-30 06:09:09 - train: epoch 0164, iter [01170, 01251], lr: 0.000882, loss: 0.4095
2022-09-30 06:09:27 - train: epoch 0164, iter [01180, 01251], lr: 0.000882, loss: 0.4007
2022-09-30 06:09:46 - train: epoch 0164, iter [01190, 01251], lr: 0.000882, loss: 0.4085
2022-09-30 06:10:04 - train: epoch 0164, iter [01200, 01251], lr: 0.000882, loss: 0.4017
2022-09-30 06:10:22 - train: epoch 0164, iter [01210, 01251], lr: 0.000882, loss: 0.4074
2022-09-30 06:10:40 - train: epoch 0164, iter [01220, 01251], lr: 0.000882, loss: 0.3989
2022-09-30 06:10:58 - train: epoch 0164, iter [01230, 01251], lr: 0.000882, loss: 0.3865
2022-09-30 06:11:16 - train: epoch 0164, iter [01240, 01251], lr: 0.000882, loss: 0.4100
2022-09-30 06:11:33 - train: epoch 0164, iter [01250, 01251], lr: 0.000882, loss: 0.4056
2022-09-30 06:11:37 - train: epoch 164, train_loss: 0.4096
2022-09-30 06:11:38 - until epoch: 164, best_loss: 0.4095
2022-09-30 06:11:38 - epoch 165 lr: 0.000882
2022-09-30 06:12:04 - train: epoch 0165, iter [00010, 01251], lr: 0.000882, loss: 0.4085
2022-09-30 06:12:22 - train: epoch 0165, iter [00020, 01251], lr: 0.000882, loss: 0.3855
2022-09-30 06:12:41 - train: epoch 0165, iter [00030, 01251], lr: 0.000882, loss: 0.4270
2022-09-30 06:12:59 - train: epoch 0165, iter [00040, 01251], lr: 0.000882, loss: 0.4114
2022-09-30 06:13:17 - train: epoch 0165, iter [00050, 01251], lr: 0.000881, loss: 0.4101
2022-09-30 06:13:35 - train: epoch 0165, iter [00060, 01251], lr: 0.000881, loss: 0.4003
2022-09-30 06:13:54 - train: epoch 0165, iter [00070, 01251], lr: 0.000881, loss: 0.4021
2022-09-30 06:14:12 - train: epoch 0165, iter [00080, 01251], lr: 0.000881, loss: 0.4183
2022-09-30 06:14:30 - train: epoch 0165, iter [00090, 01251], lr: 0.000881, loss: 0.3954
2022-09-30 06:14:48 - train: epoch 0165, iter [00100, 01251], lr: 0.000881, loss: 0.3825
2022-09-30 06:15:06 - train: epoch 0165, iter [00110, 01251], lr: 0.000881, loss: 0.4211
2022-09-30 06:15:24 - train: epoch 0165, iter [00120, 01251], lr: 0.000881, loss: 0.3956
2022-09-30 06:15:42 - train: epoch 0165, iter [00130, 01251], lr: 0.000881, loss: 0.4240
2022-09-30 06:16:00 - train: epoch 0165, iter [00140, 01251], lr: 0.000881, loss: 0.4026
2022-09-30 06:16:19 - train: epoch 0165, iter [00150, 01251], lr: 0.000881, loss: 0.4215
2022-09-30 06:16:37 - train: epoch 0165, iter [00160, 01251], lr: 0.000881, loss: 0.4051
2022-09-30 06:16:55 - train: epoch 0165, iter [00170, 01251], lr: 0.000881, loss: 0.4038
2022-09-30 06:17:13 - train: epoch 0165, iter [00180, 01251], lr: 0.000881, loss: 0.4096
2022-09-30 06:17:31 - train: epoch 0165, iter [00190, 01251], lr: 0.000881, loss: 0.4174
2022-09-30 06:17:49 - train: epoch 0165, iter [00200, 01251], lr: 0.000881, loss: 0.4143
2022-09-30 06:18:07 - train: epoch 0165, iter [00210, 01251], lr: 0.000881, loss: 0.4125
2022-09-30 06:18:25 - train: epoch 0165, iter [00220, 01251], lr: 0.000881, loss: 0.4130
2022-09-30 06:18:43 - train: epoch 0165, iter [00230, 01251], lr: 0.000881, loss: 0.4116
2022-09-30 06:19:01 - train: epoch 0165, iter [00240, 01251], lr: 0.000881, loss: 0.3916
2022-09-30 06:19:20 - train: epoch 0165, iter [00250, 01251], lr: 0.000881, loss: 0.4191
2022-09-30 06:19:38 - train: epoch 0165, iter [00260, 01251], lr: 0.000881, loss: 0.4078
2022-09-30 06:19:56 - train: epoch 0165, iter [00270, 01251], lr: 0.000881, loss: 0.3971
2022-09-30 06:20:14 - train: epoch 0165, iter [00280, 01251], lr: 0.000881, loss: 0.4269
2022-09-30 06:20:32 - train: epoch 0165, iter [00290, 01251], lr: 0.000881, loss: 0.4118
2022-09-30 06:20:50 - train: epoch 0165, iter [00300, 01251], lr: 0.000881, loss: 0.4173
2022-09-30 06:21:08 - train: epoch 0165, iter [00310, 01251], lr: 0.000881, loss: 0.3853
2022-09-30 06:21:26 - train: epoch 0165, iter [00320, 01251], lr: 0.000880, loss: 0.4137
2022-09-30 06:21:44 - train: epoch 0165, iter [00330, 01251], lr: 0.000880, loss: 0.3933
2022-09-30 06:22:02 - train: epoch 0165, iter [00340, 01251], lr: 0.000880, loss: 0.4182
2022-09-30 06:22:20 - train: epoch 0165, iter [00350, 01251], lr: 0.000880, loss: 0.4156
2022-09-30 06:22:39 - train: epoch 0165, iter [00360, 01251], lr: 0.000880, loss: 0.3999
2022-09-30 06:22:57 - train: epoch 0165, iter [00370, 01251], lr: 0.000880, loss: 0.3863
2022-09-30 06:23:15 - train: epoch 0165, iter [00380, 01251], lr: 0.000880, loss: 0.4193
2022-09-30 06:23:33 - train: epoch 0165, iter [00390, 01251], lr: 0.000880, loss: 0.4144
2022-09-30 06:23:51 - train: epoch 0165, iter [00400, 01251], lr: 0.000880, loss: 0.4056
2022-09-30 06:24:09 - train: epoch 0165, iter [00410, 01251], lr: 0.000880, loss: 0.4130
2022-09-30 06:24:27 - train: epoch 0165, iter [00420, 01251], lr: 0.000880, loss: 0.4018
2022-09-30 06:24:45 - train: epoch 0165, iter [00430, 01251], lr: 0.000880, loss: 0.4086
2022-09-30 06:25:04 - train: epoch 0165, iter [00440, 01251], lr: 0.000880, loss: 0.4193
2022-09-30 06:25:22 - train: epoch 0165, iter [00450, 01251], lr: 0.000880, loss: 0.4054
2022-09-30 06:25:39 - train: epoch 0165, iter [00460, 01251], lr: 0.000880, loss: 0.4128
2022-09-30 06:25:58 - train: epoch 0165, iter [00470, 01251], lr: 0.000880, loss: 0.3903
2022-09-30 06:26:16 - train: epoch 0165, iter [00480, 01251], lr: 0.000880, loss: 0.4050
2022-09-30 06:26:34 - train: epoch 0165, iter [00490, 01251], lr: 0.000880, loss: 0.4294
2022-09-30 06:26:52 - train: epoch 0165, iter [00500, 01251], lr: 0.000880, loss: 0.3949
2022-09-30 06:27:10 - train: epoch 0165, iter [00510, 01251], lr: 0.000880, loss: 0.3950
2022-09-30 06:27:28 - train: epoch 0165, iter [00520, 01251], lr: 0.000880, loss: 0.4238
2022-09-30 06:27:46 - train: epoch 0165, iter [00530, 01251], lr: 0.000880, loss: 0.3992
2022-09-30 06:28:04 - train: epoch 0165, iter [00540, 01251], lr: 0.000880, loss: 0.3882
2022-09-30 06:28:22 - train: epoch 0165, iter [00550, 01251], lr: 0.000880, loss: 0.4033
2022-09-30 06:28:41 - train: epoch 0165, iter [00560, 01251], lr: 0.000880, loss: 0.4096
2022-09-30 06:28:59 - train: epoch 0165, iter [00570, 01251], lr: 0.000880, loss: 0.4074
2022-09-30 06:29:17 - train: epoch 0165, iter [00580, 01251], lr: 0.000880, loss: 0.4090
2022-09-30 06:29:35 - train: epoch 0165, iter [00590, 01251], lr: 0.000880, loss: 0.4125
2022-09-30 06:29:53 - train: epoch 0165, iter [00600, 01251], lr: 0.000879, loss: 0.4095
2022-09-30 06:30:11 - train: epoch 0165, iter [00610, 01251], lr: 0.000879, loss: 0.4222
2022-09-30 06:30:29 - train: epoch 0165, iter [00620, 01251], lr: 0.000879, loss: 0.4187
2022-09-30 06:30:47 - train: epoch 0165, iter [00630, 01251], lr: 0.000879, loss: 0.4224
2022-09-30 06:31:05 - train: epoch 0165, iter [00640, 01251], lr: 0.000879, loss: 0.3920
2022-09-30 06:31:23 - train: epoch 0165, iter [00650, 01251], lr: 0.000879, loss: 0.4101
2022-09-30 06:31:41 - train: epoch 0165, iter [00660, 01251], lr: 0.000879, loss: 0.4290
2022-09-30 06:31:59 - train: epoch 0165, iter [00670, 01251], lr: 0.000879, loss: 0.4139
2022-09-30 06:32:18 - train: epoch 0165, iter [00680, 01251], lr: 0.000879, loss: 0.4051
2022-09-30 06:32:36 - train: epoch 0165, iter [00690, 01251], lr: 0.000879, loss: 0.3780
2022-09-30 06:32:54 - train: epoch 0165, iter [00700, 01251], lr: 0.000879, loss: 0.3985
2022-09-30 06:33:12 - train: epoch 0165, iter [00710, 01251], lr: 0.000879, loss: 0.4266
2022-09-30 06:33:30 - train: epoch 0165, iter [00720, 01251], lr: 0.000879, loss: 0.4180
2022-09-30 06:33:48 - train: epoch 0165, iter [00730, 01251], lr: 0.000879, loss: 0.3935
2022-09-30 06:34:06 - train: epoch 0165, iter [00740, 01251], lr: 0.000879, loss: 0.4014
2022-09-30 06:34:24 - train: epoch 0165, iter [00750, 01251], lr: 0.000879, loss: 0.4237
2022-09-30 06:34:42 - train: epoch 0165, iter [00760, 01251], lr: 0.000879, loss: 0.4371
2022-09-30 06:35:00 - train: epoch 0165, iter [00770, 01251], lr: 0.000879, loss: 0.4013
2022-09-30 06:35:18 - train: epoch 0165, iter [00780, 01251], lr: 0.000879, loss: 0.4118
2022-09-30 06:35:36 - train: epoch 0165, iter [00790, 01251], lr: 0.000879, loss: 0.4288
2022-09-30 06:35:54 - train: epoch 0165, iter [00800, 01251], lr: 0.000879, loss: 0.4215
2022-09-30 06:36:12 - train: epoch 0165, iter [00810, 01251], lr: 0.000879, loss: 0.4148
2022-09-30 06:36:30 - train: epoch 0165, iter [00820, 01251], lr: 0.000879, loss: 0.4155
2022-09-30 06:36:48 - train: epoch 0165, iter [00830, 01251], lr: 0.000879, loss: 0.4004
2022-09-30 06:37:06 - train: epoch 0165, iter [00840, 01251], lr: 0.000879, loss: 0.4125
2022-09-30 06:37:24 - train: epoch 0165, iter [00850, 01251], lr: 0.000879, loss: 0.4234
2022-09-30 06:37:42 - train: epoch 0165, iter [00860, 01251], lr: 0.000878, loss: 0.4296
2022-09-30 06:38:01 - train: epoch 0165, iter [00870, 01251], lr: 0.000878, loss: 0.3987
2022-09-30 06:38:19 - train: epoch 0165, iter [00880, 01251], lr: 0.000878, loss: 0.4184
2022-09-30 06:38:37 - train: epoch 0165, iter [00890, 01251], lr: 0.000878, loss: 0.3986
2022-09-30 06:38:55 - train: epoch 0165, iter [00900, 01251], lr: 0.000878, loss: 0.4279
2022-09-30 06:39:13 - train: epoch 0165, iter [00910, 01251], lr: 0.000878, loss: 0.4019
2022-09-30 06:39:31 - train: epoch 0165, iter [00920, 01251], lr: 0.000878, loss: 0.4228
2022-09-30 06:39:49 - train: epoch 0165, iter [00930, 01251], lr: 0.000878, loss: 0.3732
2022-09-30 06:40:07 - train: epoch 0165, iter [00940, 01251], lr: 0.000878, loss: 0.4117
2022-09-30 06:40:25 - train: epoch 0165, iter [00950, 01251], lr: 0.000878, loss: 0.4235
2022-09-30 06:40:43 - train: epoch 0165, iter [00960, 01251], lr: 0.000878, loss: 0.4134
2022-09-30 06:41:01 - train: epoch 0165, iter [00970, 01251], lr: 0.000878, loss: 0.4155
2022-09-30 06:41:19 - train: epoch 0165, iter [00980, 01251], lr: 0.000878, loss: 0.4081
2022-09-30 06:41:37 - train: epoch 0165, iter [00990, 01251], lr: 0.000878, loss: 0.4026
2022-09-30 06:41:55 - train: epoch 0165, iter [01000, 01251], lr: 0.000878, loss: 0.3962
2022-09-30 06:42:14 - train: epoch 0165, iter [01010, 01251], lr: 0.000878, loss: 0.4065
2022-09-30 06:42:31 - train: epoch 0165, iter [01020, 01251], lr: 0.000878, loss: 0.4058
2022-09-30 06:42:49 - train: epoch 0165, iter [01030, 01251], lr: 0.000878, loss: 0.4047
2022-09-30 06:43:08 - train: epoch 0165, iter [01040, 01251], lr: 0.000878, loss: 0.4060
2022-09-30 06:43:26 - train: epoch 0165, iter [01050, 01251], lr: 0.000878, loss: 0.4074
2022-09-30 06:43:44 - train: epoch 0165, iter [01060, 01251], lr: 0.000878, loss: 0.4132
2022-09-30 06:44:02 - train: epoch 0165, iter [01070, 01251], lr: 0.000878, loss: 0.4054
2022-09-30 06:44:20 - train: epoch 0165, iter [01080, 01251], lr: 0.000878, loss: 0.4079
2022-09-30 06:44:38 - train: epoch 0165, iter [01090, 01251], lr: 0.000878, loss: 0.4159
2022-09-30 06:44:56 - train: epoch 0165, iter [01100, 01251], lr: 0.000878, loss: 0.4061
2022-09-30 06:45:14 - train: epoch 0165, iter [01110, 01251], lr: 0.000878, loss: 0.4021
2022-09-30 06:45:32 - train: epoch 0165, iter [01120, 01251], lr: 0.000878, loss: 0.4208
2022-09-30 06:45:50 - train: epoch 0165, iter [01130, 01251], lr: 0.000877, loss: 0.4121
2022-09-30 06:46:08 - train: epoch 0165, iter [01140, 01251], lr: 0.000877, loss: 0.3936
2022-09-30 06:46:26 - train: epoch 0165, iter [01150, 01251], lr: 0.000877, loss: 0.4187
2022-09-30 06:46:44 - train: epoch 0165, iter [01160, 01251], lr: 0.000877, loss: 0.4154
2022-09-30 06:47:02 - train: epoch 0165, iter [01170, 01251], lr: 0.000877, loss: 0.4054
2022-09-30 06:47:20 - train: epoch 0165, iter [01180, 01251], lr: 0.000877, loss: 0.3950
2022-09-30 06:47:38 - train: epoch 0165, iter [01190, 01251], lr: 0.000877, loss: 0.4108
2022-09-30 06:47:56 - train: epoch 0165, iter [01200, 01251], lr: 0.000877, loss: 0.4089
2022-09-30 06:48:14 - train: epoch 0165, iter [01210, 01251], lr: 0.000877, loss: 0.3857
2022-09-30 06:48:32 - train: epoch 0165, iter [01220, 01251], lr: 0.000877, loss: 0.4091
2022-09-30 06:48:50 - train: epoch 0165, iter [01230, 01251], lr: 0.000877, loss: 0.4092
2022-09-30 06:49:08 - train: epoch 0165, iter [01240, 01251], lr: 0.000877, loss: 0.4170
2022-09-30 06:49:25 - train: epoch 0165, iter [01250, 01251], lr: 0.000877, loss: 0.4118
2022-09-30 06:49:28 - train: epoch 165, train_loss: 0.4094
2022-09-30 06:49:31 - until epoch: 165, best_loss: 0.4094
2022-09-30 06:49:31 - epoch 166 lr: 0.000877
2022-09-30 06:49:56 - train: epoch 0166, iter [00010, 01251], lr: 0.000877, loss: 0.4116
2022-09-30 06:50:14 - train: epoch 0166, iter [00020, 01251], lr: 0.000877, loss: 0.4162
2022-09-30 06:50:33 - train: epoch 0166, iter [00030, 01251], lr: 0.000877, loss: 0.3830
2022-09-30 06:50:51 - train: epoch 0166, iter [00040, 01251], lr: 0.000877, loss: 0.4032
2022-09-30 06:51:09 - train: epoch 0166, iter [00050, 01251], lr: 0.000877, loss: 0.4165
2022-09-30 06:51:27 - train: epoch 0166, iter [00060, 01251], lr: 0.000877, loss: 0.4202
2022-09-30 06:51:45 - train: epoch 0166, iter [00070, 01251], lr: 0.000877, loss: 0.4140
2022-09-30 06:52:03 - train: epoch 0166, iter [00080, 01251], lr: 0.000877, loss: 0.4021
2022-09-30 06:52:21 - train: epoch 0166, iter [00090, 01251], lr: 0.000877, loss: 0.4017
2022-09-30 06:52:39 - train: epoch 0166, iter [00100, 01251], lr: 0.000877, loss: 0.3962
2022-09-30 06:52:58 - train: epoch 0166, iter [00110, 01251], lr: 0.000877, loss: 0.4109
2022-09-30 06:53:16 - train: epoch 0166, iter [00120, 01251], lr: 0.000877, loss: 0.3990
2022-09-30 06:53:33 - train: epoch 0166, iter [00130, 01251], lr: 0.000877, loss: 0.4091
2022-09-30 06:53:52 - train: epoch 0166, iter [00140, 01251], lr: 0.000877, loss: 0.3894
2022-09-30 06:54:10 - train: epoch 0166, iter [00150, 01251], lr: 0.000876, loss: 0.4059
2022-09-30 06:54:28 - train: epoch 0166, iter [00160, 01251], lr: 0.000876, loss: 0.4230
2022-09-30 06:54:46 - train: epoch 0166, iter [00170, 01251], lr: 0.000876, loss: 0.4278
2022-09-30 06:55:04 - train: epoch 0166, iter [00180, 01251], lr: 0.000876, loss: 0.3946
2022-09-30 06:55:22 - train: epoch 0166, iter [00190, 01251], lr: 0.000876, loss: 0.4055
2022-09-30 06:55:40 - train: epoch 0166, iter [00200, 01251], lr: 0.000876, loss: 0.4199
2022-09-30 06:55:58 - train: epoch 0166, iter [00210, 01251], lr: 0.000876, loss: 0.3958
2022-09-30 06:56:16 - train: epoch 0166, iter [00220, 01251], lr: 0.000876, loss: 0.4134
2022-09-30 06:56:34 - train: epoch 0166, iter [00230, 01251], lr: 0.000876, loss: 0.4010
2022-09-30 06:56:52 - train: epoch 0166, iter [00240, 01251], lr: 0.000876, loss: 0.4039
2022-09-30 06:57:11 - train: epoch 0166, iter [00250, 01251], lr: 0.000876, loss: 0.4174
2022-09-30 06:57:29 - train: epoch 0166, iter [00260, 01251], lr: 0.000876, loss: 0.4126
2022-09-30 06:57:47 - train: epoch 0166, iter [00270, 01251], lr: 0.000876, loss: 0.4112
2022-09-30 06:58:05 - train: epoch 0166, iter [00280, 01251], lr: 0.000876, loss: 0.4047
2022-09-30 06:58:23 - train: epoch 0166, iter [00290, 01251], lr: 0.000876, loss: 0.4045
2022-09-30 06:58:41 - train: epoch 0166, iter [00300, 01251], lr: 0.000876, loss: 0.4021
2022-09-30 06:59:00 - train: epoch 0166, iter [00310, 01251], lr: 0.000876, loss: 0.4053
2022-09-30 06:59:18 - train: epoch 0166, iter [00320, 01251], lr: 0.000876, loss: 0.3911
2022-09-30 06:59:36 - train: epoch 0166, iter [00330, 01251], lr: 0.000876, loss: 0.4189
2022-09-30 06:59:54 - train: epoch 0166, iter [00340, 01251], lr: 0.000876, loss: 0.4073
2022-09-30 07:00:12 - train: epoch 0166, iter [00350, 01251], lr: 0.000876, loss: 0.4296
2022-09-30 07:00:30 - train: epoch 0166, iter [00360, 01251], lr: 0.000876, loss: 0.4088
2022-09-30 07:00:48 - train: epoch 0166, iter [00370, 01251], lr: 0.000876, loss: 0.4279
2022-09-30 07:01:06 - train: epoch 0166, iter [00380, 01251], lr: 0.000876, loss: 0.4225
2022-09-30 07:01:24 - train: epoch 0166, iter [00390, 01251], lr: 0.000876, loss: 0.4213
2022-09-30 07:01:42 - train: epoch 0166, iter [00400, 01251], lr: 0.000876, loss: 0.4071
2022-09-30 07:02:00 - train: epoch 0166, iter [00410, 01251], lr: 0.000876, loss: 0.4245
2022-09-30 07:02:18 - train: epoch 0166, iter [00420, 01251], lr: 0.000875, loss: 0.4022
2022-09-30 07:02:36 - train: epoch 0166, iter [00430, 01251], lr: 0.000875, loss: 0.4030
2022-09-30 07:02:54 - train: epoch 0166, iter [00440, 01251], lr: 0.000875, loss: 0.4153
2022-09-30 07:03:12 - train: epoch 0166, iter [00450, 01251], lr: 0.000875, loss: 0.3902
2022-09-30 07:03:30 - train: epoch 0166, iter [00460, 01251], lr: 0.000875, loss: 0.4289
2022-09-30 07:03:48 - train: epoch 0166, iter [00470, 01251], lr: 0.000875, loss: 0.4172
2022-09-30 07:04:06 - train: epoch 0166, iter [00480, 01251], lr: 0.000875, loss: 0.4199
2022-09-30 07:04:24 - train: epoch 0166, iter [00490, 01251], lr: 0.000875, loss: 0.4160
2022-09-30 07:04:43 - train: epoch 0166, iter [00500, 01251], lr: 0.000875, loss: 0.4202
2022-09-30 07:05:00 - train: epoch 0166, iter [00510, 01251], lr: 0.000875, loss: 0.4108
2022-09-30 07:05:18 - train: epoch 0166, iter [00520, 01251], lr: 0.000875, loss: 0.4023
2022-09-30 07:05:37 - train: epoch 0166, iter [00530, 01251], lr: 0.000875, loss: 0.4162
2022-09-30 07:05:54 - train: epoch 0166, iter [00540, 01251], lr: 0.000875, loss: 0.4157
2022-09-30 07:06:13 - train: epoch 0166, iter [00550, 01251], lr: 0.000875, loss: 0.4121
2022-09-30 07:06:31 - train: epoch 0166, iter [00560, 01251], lr: 0.000875, loss: 0.4158
2022-09-30 07:06:49 - train: epoch 0166, iter [00570, 01251], lr: 0.000875, loss: 0.4096
2022-09-30 07:07:07 - train: epoch 0166, iter [00580, 01251], lr: 0.000875, loss: 0.3975
2022-09-30 07:07:25 - train: epoch 0166, iter [00590, 01251], lr: 0.000875, loss: 0.4166
2022-09-30 07:07:43 - train: epoch 0166, iter [00600, 01251], lr: 0.000875, loss: 0.3833
2022-09-30 07:08:01 - train: epoch 0166, iter [00610, 01251], lr: 0.000875, loss: 0.4148
2022-09-30 07:08:19 - train: epoch 0166, iter [00620, 01251], lr: 0.000875, loss: 0.4152
2022-09-30 07:08:37 - train: epoch 0166, iter [00630, 01251], lr: 0.000875, loss: 0.4137
2022-09-30 07:08:56 - train: epoch 0166, iter [00640, 01251], lr: 0.000875, loss: 0.4120
2022-09-30 07:09:14 - train: epoch 0166, iter [00650, 01251], lr: 0.000875, loss: 0.4119
2022-09-30 07:09:32 - train: epoch 0166, iter [00660, 01251], lr: 0.000875, loss: 0.4036
2022-09-30 07:09:50 - train: epoch 0166, iter [00670, 01251], lr: 0.000875, loss: 0.4170
2022-09-30 07:10:08 - train: epoch 0166, iter [00680, 01251], lr: 0.000875, loss: 0.4199
2022-09-30 07:10:26 - train: epoch 0166, iter [00690, 01251], lr: 0.000874, loss: 0.3965
2022-09-30 07:10:44 - train: epoch 0166, iter [00700, 01251], lr: 0.000874, loss: 0.4028
2022-09-30 07:11:02 - train: epoch 0166, iter [00710, 01251], lr: 0.000874, loss: 0.3921
2022-09-30 07:11:21 - train: epoch 0166, iter [00720, 01251], lr: 0.000874, loss: 0.4085
2022-09-30 07:11:39 - train: epoch 0166, iter [00730, 01251], lr: 0.000874, loss: 0.4128
2022-09-30 07:11:56 - train: epoch 0166, iter [00740, 01251], lr: 0.000874, loss: 0.4135
2022-09-30 07:12:15 - train: epoch 0166, iter [00750, 01251], lr: 0.000874, loss: 0.4336
2022-09-30 07:12:33 - train: epoch 0166, iter [00760, 01251], lr: 0.000874, loss: 0.3976
2022-09-30 07:12:51 - train: epoch 0166, iter [00770, 01251], lr: 0.000874, loss: 0.3979
2022-09-30 07:13:09 - train: epoch 0166, iter [00780, 01251], lr: 0.000874, loss: 0.3894
2022-09-30 07:13:27 - train: epoch 0166, iter [00790, 01251], lr: 0.000874, loss: 0.4055
2022-09-30 07:13:45 - train: epoch 0166, iter [00800, 01251], lr: 0.000874, loss: 0.4224
2022-09-30 07:14:03 - train: epoch 0166, iter [00810, 01251], lr: 0.000874, loss: 0.4059
2022-09-30 07:14:21 - train: epoch 0166, iter [00820, 01251], lr: 0.000874, loss: 0.4127
2022-09-30 07:14:39 - train: epoch 0166, iter [00830, 01251], lr: 0.000874, loss: 0.3920
2022-09-30 07:14:58 - train: epoch 0166, iter [00840, 01251], lr: 0.000874, loss: 0.3905
2022-09-30 07:15:16 - train: epoch 0166, iter [00850, 01251], lr: 0.000874, loss: 0.4045
2022-09-30 07:15:34 - train: epoch 0166, iter [00860, 01251], lr: 0.000874, loss: 0.4089
2022-09-30 07:15:52 - train: epoch 0166, iter [00870, 01251], lr: 0.000874, loss: 0.4015
2022-09-30 07:16:11 - train: epoch 0166, iter [00880, 01251], lr: 0.000874, loss: 0.4076
2022-09-30 07:16:29 - train: epoch 0166, iter [00890, 01251], lr: 0.000874, loss: 0.4093
2022-09-30 07:16:47 - train: epoch 0166, iter [00900, 01251], lr: 0.000874, loss: 0.4167
2022-09-30 07:17:05 - train: epoch 0166, iter [00910, 01251], lr: 0.000874, loss: 0.4085
2022-09-30 07:17:23 - train: epoch 0166, iter [00920, 01251], lr: 0.000874, loss: 0.4184
2022-09-30 07:17:41 - train: epoch 0166, iter [00930, 01251], lr: 0.000874, loss: 0.4043
2022-09-30 07:17:59 - train: epoch 0166, iter [00940, 01251], lr: 0.000874, loss: 0.4239
2022-09-30 07:18:17 - train: epoch 0166, iter [00950, 01251], lr: 0.000874, loss: 0.4028
2022-09-30 07:18:35 - train: epoch 0166, iter [00960, 01251], lr: 0.000873, loss: 0.4043
2022-09-30 07:18:53 - train: epoch 0166, iter [00970, 01251], lr: 0.000873, loss: 0.4124
2022-09-30 07:19:12 - train: epoch 0166, iter [00980, 01251], lr: 0.000873, loss: 0.3934
2022-09-30 07:19:30 - train: epoch 0166, iter [00990, 01251], lr: 0.000873, loss: 0.4035
2022-09-30 07:19:48 - train: epoch 0166, iter [01000, 01251], lr: 0.000873, loss: 0.4057
2022-09-30 07:20:06 - train: epoch 0166, iter [01010, 01251], lr: 0.000873, loss: 0.4123
2022-09-30 07:20:24 - train: epoch 0166, iter [01020, 01251], lr: 0.000873, loss: 0.4058
2022-09-30 07:20:42 - train: epoch 0166, iter [01030, 01251], lr: 0.000873, loss: 0.4054
2022-09-30 07:21:00 - train: epoch 0166, iter [01040, 01251], lr: 0.000873, loss: 0.4255
2022-09-30 07:21:18 - train: epoch 0166, iter [01050, 01251], lr: 0.000873, loss: 0.4099
2022-09-30 07:21:36 - train: epoch 0166, iter [01060, 01251], lr: 0.000873, loss: 0.4096
2022-09-30 07:21:54 - train: epoch 0166, iter [01070, 01251], lr: 0.000873, loss: 0.4197
2022-09-30 07:22:13 - train: epoch 0166, iter [01080, 01251], lr: 0.000873, loss: 0.3944
2022-09-30 07:22:30 - train: epoch 0166, iter [01090, 01251], lr: 0.000873, loss: 0.4204
2022-09-30 07:22:48 - train: epoch 0166, iter [01100, 01251], lr: 0.000873, loss: 0.3929
2022-09-30 07:23:06 - train: epoch 0166, iter [01110, 01251], lr: 0.000873, loss: 0.4002
2022-09-30 07:23:24 - train: epoch 0166, iter [01120, 01251], lr: 0.000873, loss: 0.4052
2022-09-30 07:23:43 - train: epoch 0166, iter [01130, 01251], lr: 0.000873, loss: 0.4230
2022-09-30 07:24:00 - train: epoch 0166, iter [01140, 01251], lr: 0.000873, loss: 0.4242
2022-09-30 07:24:18 - train: epoch 0166, iter [01150, 01251], lr: 0.000873, loss: 0.4199
2022-09-30 07:24:36 - train: epoch 0166, iter [01160, 01251], lr: 0.000873, loss: 0.4005
2022-09-30 07:24:54 - train: epoch 0166, iter [01170, 01251], lr: 0.000873, loss: 0.3945
2022-09-30 07:25:13 - train: epoch 0166, iter [01180, 01251], lr: 0.000873, loss: 0.4167
2022-09-30 07:25:31 - train: epoch 0166, iter [01190, 01251], lr: 0.000873, loss: 0.3948
2022-09-30 07:25:49 - train: epoch 0166, iter [01200, 01251], lr: 0.000873, loss: 0.4178
2022-09-30 07:26:07 - train: epoch 0166, iter [01210, 01251], lr: 0.000873, loss: 0.4292
2022-09-30 07:26:25 - train: epoch 0166, iter [01220, 01251], lr: 0.000873, loss: 0.4075
2022-09-30 07:26:43 - train: epoch 0166, iter [01230, 01251], lr: 0.000872, loss: 0.4033
2022-09-30 07:27:02 - train: epoch 0166, iter [01240, 01251], lr: 0.000872, loss: 0.4455
2022-09-30 07:27:20 - train: epoch 0166, iter [01250, 01251], lr: 0.000872, loss: 0.4048
2022-09-30 07:27:23 - train: epoch 166, train_loss: 0.4095
2022-09-30 07:27:24 - until epoch: 166, best_loss: 0.4094
2022-09-30 07:27:24 - epoch 167 lr: 0.000872
2022-09-30 07:27:50 - train: epoch 0167, iter [00010, 01251], lr: 0.000872, loss: 0.4181
2022-09-30 07:28:08 - train: epoch 0167, iter [00020, 01251], lr: 0.000872, loss: 0.4058
2022-09-30 07:28:26 - train: epoch 0167, iter [00030, 01251], lr: 0.000872, loss: 0.4319
2022-09-30 07:28:45 - train: epoch 0167, iter [00040, 01251], lr: 0.000872, loss: 0.4127
2022-09-30 07:29:03 - train: epoch 0167, iter [00050, 01251], lr: 0.000872, loss: 0.4100
2022-09-30 07:29:21 - train: epoch 0167, iter [00060, 01251], lr: 0.000872, loss: 0.3979
2022-09-30 07:29:39 - train: epoch 0167, iter [00070, 01251], lr: 0.000872, loss: 0.4023
2022-09-30 07:29:56 - train: epoch 0167, iter [00080, 01251], lr: 0.000872, loss: 0.3992
2022-09-30 07:30:14 - train: epoch 0167, iter [00090, 01251], lr: 0.000872, loss: 0.4031
2022-09-30 07:30:33 - train: epoch 0167, iter [00100, 01251], lr: 0.000872, loss: 0.3919
2022-09-30 07:30:51 - train: epoch 0167, iter [00110, 01251], lr: 0.000872, loss: 0.3902
2022-09-30 07:31:09 - train: epoch 0167, iter [00120, 01251], lr: 0.000872, loss: 0.4281
2022-09-30 07:31:27 - train: epoch 0167, iter [00130, 01251], lr: 0.000872, loss: 0.4012
2022-09-30 07:31:45 - train: epoch 0167, iter [00140, 01251], lr: 0.000872, loss: 0.4237
2022-09-30 07:32:03 - train: epoch 0167, iter [00150, 01251], lr: 0.000872, loss: 0.3920
2022-09-30 07:32:21 - train: epoch 0167, iter [00160, 01251], lr: 0.000872, loss: 0.3969
2022-09-30 07:32:40 - train: epoch 0167, iter [00170, 01251], lr: 0.000872, loss: 0.3943
2022-09-30 07:32:58 - train: epoch 0167, iter [00180, 01251], lr: 0.000872, loss: 0.3933
2022-09-30 07:33:16 - train: epoch 0167, iter [00190, 01251], lr: 0.000872, loss: 0.4035
2022-09-30 07:33:34 - train: epoch 0167, iter [00200, 01251], lr: 0.000872, loss: 0.3986
2022-09-30 07:33:52 - train: epoch 0167, iter [00210, 01251], lr: 0.000872, loss: 0.4056
2022-09-30 07:34:10 - train: epoch 0167, iter [00220, 01251], lr: 0.000872, loss: 0.3953
2022-09-30 07:34:28 - train: epoch 0167, iter [00230, 01251], lr: 0.000872, loss: 0.4213
2022-09-30 07:34:46 - train: epoch 0167, iter [00240, 01251], lr: 0.000871, loss: 0.4167
2022-09-30 07:35:04 - train: epoch 0167, iter [00250, 01251], lr: 0.000871, loss: 0.4098
2022-09-30 07:35:22 - train: epoch 0167, iter [00260, 01251], lr: 0.000871, loss: 0.4067
2022-09-30 07:35:40 - train: epoch 0167, iter [00270, 01251], lr: 0.000871, loss: 0.3906
2022-09-30 07:35:58 - train: epoch 0167, iter [00280, 01251], lr: 0.000871, loss: 0.4086
2022-09-30 07:36:16 - train: epoch 0167, iter [00290, 01251], lr: 0.000871, loss: 0.4069
2022-09-30 07:36:34 - train: epoch 0167, iter [00300, 01251], lr: 0.000871, loss: 0.4285
2022-09-30 07:36:52 - train: epoch 0167, iter [00310, 01251], lr: 0.000871, loss: 0.4112
2022-09-30 07:37:10 - train: epoch 0167, iter [00320, 01251], lr: 0.000871, loss: 0.4181
2022-09-30 07:37:28 - train: epoch 0167, iter [00330, 01251], lr: 0.000871, loss: 0.3918
2022-09-30 07:37:46 - train: epoch 0167, iter [00340, 01251], lr: 0.000871, loss: 0.3977
2022-09-30 07:38:04 - train: epoch 0167, iter [00350, 01251], lr: 0.000871, loss: 0.4120
2022-09-30 07:38:22 - train: epoch 0167, iter [00360, 01251], lr: 0.000871, loss: 0.4022
2022-09-30 07:38:41 - train: epoch 0167, iter [00370, 01251], lr: 0.000871, loss: 0.4268
2022-09-30 07:38:58 - train: epoch 0167, iter [00380, 01251], lr: 0.000871, loss: 0.4182
2022-09-30 07:39:17 - train: epoch 0167, iter [00390, 01251], lr: 0.000871, loss: 0.4140
2022-09-30 07:39:35 - train: epoch 0167, iter [00400, 01251], lr: 0.000871, loss: 0.4162
2022-09-30 07:39:53 - train: epoch 0167, iter [00410, 01251], lr: 0.000871, loss: 0.4327
2022-09-30 07:40:11 - train: epoch 0167, iter [00420, 01251], lr: 0.000871, loss: 0.4440
2022-09-30 07:40:29 - train: epoch 0167, iter [00430, 01251], lr: 0.000871, loss: 0.4044
2022-09-30 07:40:47 - train: epoch 0167, iter [00440, 01251], lr: 0.000871, loss: 0.4109
2022-09-30 07:41:05 - train: epoch 0167, iter [00450, 01251], lr: 0.000871, loss: 0.3952
2022-09-30 07:41:23 - train: epoch 0167, iter [00460, 01251], lr: 0.000871, loss: 0.4135
2022-09-30 07:41:42 - train: epoch 0167, iter [00470, 01251], lr: 0.000871, loss: 0.3967
2022-09-30 07:41:59 - train: epoch 0167, iter [00480, 01251], lr: 0.000871, loss: 0.4039
2022-09-30 07:42:17 - train: epoch 0167, iter [00490, 01251], lr: 0.000871, loss: 0.4225
2022-09-30 07:42:35 - train: epoch 0167, iter [00500, 01251], lr: 0.000871, loss: 0.3903
2022-09-30 07:42:53 - train: epoch 0167, iter [00510, 01251], lr: 0.000870, loss: 0.3879
2022-09-30 07:43:11 - train: epoch 0167, iter [00520, 01251], lr: 0.000870, loss: 0.4015
2022-09-30 07:43:29 - train: epoch 0167, iter [00530, 01251], lr: 0.000870, loss: 0.4008
2022-09-30 07:43:48 - train: epoch 0167, iter [00540, 01251], lr: 0.000870, loss: 0.4039
2022-09-30 07:44:06 - train: epoch 0167, iter [00550, 01251], lr: 0.000870, loss: 0.4095
2022-09-30 07:44:24 - train: epoch 0167, iter [00560, 01251], lr: 0.000870, loss: 0.4136
2022-09-30 07:44:42 - train: epoch 0167, iter [00570, 01251], lr: 0.000870, loss: 0.3961
2022-09-30 07:45:00 - train: epoch 0167, iter [00580, 01251], lr: 0.000870, loss: 0.3974
2022-09-30 07:45:18 - train: epoch 0167, iter [00590, 01251], lr: 0.000870, loss: 0.4118
2022-09-30 07:45:36 - train: epoch 0167, iter [00600, 01251], lr: 0.000870, loss: 0.4044
2022-09-30 07:45:53 - train: epoch 0167, iter [00610, 01251], lr: 0.000870, loss: 0.4010
2022-09-30 07:46:11 - train: epoch 0167, iter [00620, 01251], lr: 0.000870, loss: 0.4185
2022-09-30 07:46:29 - train: epoch 0167, iter [00630, 01251], lr: 0.000870, loss: 0.3976
2022-09-30 07:46:47 - train: epoch 0167, iter [00640, 01251], lr: 0.000870, loss: 0.4003
2022-09-30 07:47:05 - train: epoch 0167, iter [00650, 01251], lr: 0.000870, loss: 0.4050
2022-09-30 07:47:23 - train: epoch 0167, iter [00660, 01251], lr: 0.000870, loss: 0.4012
2022-09-30 07:47:41 - train: epoch 0167, iter [00670, 01251], lr: 0.000870, loss: 0.4072
2022-09-30 07:48:00 - train: epoch 0167, iter [00680, 01251], lr: 0.000870, loss: 0.3954
2022-09-30 07:48:18 - train: epoch 0167, iter [00690, 01251], lr: 0.000870, loss: 0.4070
2022-09-30 07:48:36 - train: epoch 0167, iter [00700, 01251], lr: 0.000870, loss: 0.4090
2022-09-30 07:48:54 - train: epoch 0167, iter [00710, 01251], lr: 0.000870, loss: 0.3962
2022-09-30 07:49:12 - train: epoch 0167, iter [00720, 01251], lr: 0.000870, loss: 0.4164
2022-09-30 07:49:30 - train: epoch 0167, iter [00730, 01251], lr: 0.000870, loss: 0.3925
2022-09-30 07:49:48 - train: epoch 0167, iter [00740, 01251], lr: 0.000870, loss: 0.3986
2022-09-30 07:50:06 - train: epoch 0167, iter [00750, 01251], lr: 0.000870, loss: 0.4002
2022-09-30 07:50:24 - train: epoch 0167, iter [00760, 01251], lr: 0.000870, loss: 0.3920
2022-09-30 07:50:42 - train: epoch 0167, iter [00770, 01251], lr: 0.000870, loss: 0.4077
2022-09-30 07:51:00 - train: epoch 0167, iter [00780, 01251], lr: 0.000869, loss: 0.4013
2022-09-30 07:51:18 - train: epoch 0167, iter [00790, 01251], lr: 0.000869, loss: 0.3997
2022-09-30 07:51:36 - train: epoch 0167, iter [00800, 01251], lr: 0.000869, loss: 0.4038
2022-09-30 07:51:54 - train: epoch 0167, iter [00810, 01251], lr: 0.000869, loss: 0.4089
2022-09-30 07:52:12 - train: epoch 0167, iter [00820, 01251], lr: 0.000869, loss: 0.3994
2022-09-30 07:52:30 - train: epoch 0167, iter [00830, 01251], lr: 0.000869, loss: 0.3985
2022-09-30 07:52:48 - train: epoch 0167, iter [00840, 01251], lr: 0.000869, loss: 0.3924
2022-09-30 07:53:06 - train: epoch 0167, iter [00850, 01251], lr: 0.000869, loss: 0.4047
2022-09-30 07:53:25 - train: epoch 0167, iter [00860, 01251], lr: 0.000869, loss: 0.4018
2022-09-30 07:53:43 - train: epoch 0167, iter [00870, 01251], lr: 0.000869, loss: 0.4142
2022-09-30 07:54:01 - train: epoch 0167, iter [00880, 01251], lr: 0.000869, loss: 0.4046
2022-09-30 07:54:19 - train: epoch 0167, iter [00890, 01251], lr: 0.000869, loss: 0.4135
2022-09-30 07:54:37 - train: epoch 0167, iter [00900, 01251], lr: 0.000869, loss: 0.3825
2022-09-30 07:54:55 - train: epoch 0167, iter [00910, 01251], lr: 0.000869, loss: 0.4174
2022-09-30 07:55:13 - train: epoch 0167, iter [00920, 01251], lr: 0.000869, loss: 0.4037
2022-09-30 07:55:31 - train: epoch 0167, iter [00930, 01251], lr: 0.000869, loss: 0.4298
2022-09-30 07:55:49 - train: epoch 0167, iter [00940, 01251], lr: 0.000869, loss: 0.4086
2022-09-30 07:56:08 - train: epoch 0167, iter [00950, 01251], lr: 0.000869, loss: 0.3988
2022-09-30 07:56:26 - train: epoch 0167, iter [00960, 01251], lr: 0.000869, loss: 0.4177
2022-09-30 07:56:44 - train: epoch 0167, iter [00970, 01251], lr: 0.000869, loss: 0.4009
2022-09-30 07:57:02 - train: epoch 0167, iter [00980, 01251], lr: 0.000869, loss: 0.4188
2022-09-30 07:57:20 - train: epoch 0167, iter [00990, 01251], lr: 0.000869, loss: 0.3975
2022-09-30 07:57:38 - train: epoch 0167, iter [01000, 01251], lr: 0.000869, loss: 0.4172
2022-09-30 07:57:56 - train: epoch 0167, iter [01010, 01251], lr: 0.000869, loss: 0.4105
2022-09-30 07:58:14 - train: epoch 0167, iter [01020, 01251], lr: 0.000869, loss: 0.4232
2022-09-30 07:58:32 - train: epoch 0167, iter [01030, 01251], lr: 0.000869, loss: 0.3893
2022-09-30 07:58:50 - train: epoch 0167, iter [01040, 01251], lr: 0.000869, loss: 0.4169
2022-09-30 07:59:08 - train: epoch 0167, iter [01050, 01251], lr: 0.000868, loss: 0.3978
2022-09-30 07:59:26 - train: epoch 0167, iter [01060, 01251], lr: 0.000868, loss: 0.4171
2022-09-30 07:59:44 - train: epoch 0167, iter [01070, 01251], lr: 0.000868, loss: 0.4098
2022-09-30 08:00:02 - train: epoch 0167, iter [01080, 01251], lr: 0.000868, loss: 0.4088
2022-09-30 08:00:20 - train: epoch 0167, iter [01090, 01251], lr: 0.000868, loss: 0.4124
2022-09-30 08:00:38 - train: epoch 0167, iter [01100, 01251], lr: 0.000868, loss: 0.4183
2022-09-30 08:00:56 - train: epoch 0167, iter [01110, 01251], lr: 0.000868, loss: 0.4196
2022-09-30 08:01:14 - train: epoch 0167, iter [01120, 01251], lr: 0.000868, loss: 0.4249
2022-09-30 08:01:32 - train: epoch 0167, iter [01130, 01251], lr: 0.000868, loss: 0.4065
2022-09-30 08:01:50 - train: epoch 0167, iter [01140, 01251], lr: 0.000868, loss: 0.4121
2022-09-30 08:02:08 - train: epoch 0167, iter [01150, 01251], lr: 0.000868, loss: 0.3898
2022-09-30 08:02:26 - train: epoch 0167, iter [01160, 01251], lr: 0.000868, loss: 0.4107
2022-09-30 08:02:44 - train: epoch 0167, iter [01170, 01251], lr: 0.000868, loss: 0.3995
2022-09-30 08:03:02 - train: epoch 0167, iter [01180, 01251], lr: 0.000868, loss: 0.4156
2022-09-30 08:03:20 - train: epoch 0167, iter [01190, 01251], lr: 0.000868, loss: 0.4188
2022-09-30 08:03:38 - train: epoch 0167, iter [01200, 01251], lr: 0.000868, loss: 0.3990
2022-09-30 08:03:56 - train: epoch 0167, iter [01210, 01251], lr: 0.000868, loss: 0.4107
2022-09-30 08:04:14 - train: epoch 0167, iter [01220, 01251], lr: 0.000868, loss: 0.4092
2022-09-30 08:04:32 - train: epoch 0167, iter [01230, 01251], lr: 0.000868, loss: 0.3903
2022-09-30 08:04:50 - train: epoch 0167, iter [01240, 01251], lr: 0.000868, loss: 0.3886
2022-09-30 08:05:08 - train: epoch 0167, iter [01250, 01251], lr: 0.000868, loss: 0.3952
2022-09-30 08:05:11 - train: epoch 167, train_loss: 0.4094
2022-09-30 08:05:13 - until epoch: 167, best_loss: 0.4094
2022-09-30 08:05:13 - epoch 168 lr: 0.000868
2022-09-30 08:05:38 - train: epoch 0168, iter [00010, 01251], lr: 0.000868, loss: 0.3927
2022-09-30 08:05:56 - train: epoch 0168, iter [00020, 01251], lr: 0.000868, loss: 0.3999
2022-09-30 08:06:14 - train: epoch 0168, iter [00030, 01251], lr: 0.000868, loss: 0.4026
2022-09-30 08:06:32 - train: epoch 0168, iter [00040, 01251], lr: 0.000868, loss: 0.3999
2022-09-30 08:06:50 - train: epoch 0168, iter [00050, 01251], lr: 0.000868, loss: 0.4107
2022-09-30 08:07:08 - train: epoch 0168, iter [00060, 01251], lr: 0.000867, loss: 0.4109
2022-09-30 08:07:26 - train: epoch 0168, iter [00070, 01251], lr: 0.000867, loss: 0.4210
2022-09-30 08:07:44 - train: epoch 0168, iter [00080, 01251], lr: 0.000867, loss: 0.4068
2022-09-30 08:08:02 - train: epoch 0168, iter [00090, 01251], lr: 0.000867, loss: 0.3829
2022-09-30 08:08:20 - train: epoch 0168, iter [00100, 01251], lr: 0.000867, loss: 0.4238
2022-09-30 08:08:38 - train: epoch 0168, iter [00110, 01251], lr: 0.000867, loss: 0.4064
2022-09-30 08:08:56 - train: epoch 0168, iter [00120, 01251], lr: 0.000867, loss: 0.3987
2022-09-30 08:09:14 - train: epoch 0168, iter [00130, 01251], lr: 0.000867, loss: 0.4091
2022-09-30 08:09:32 - train: epoch 0168, iter [00140, 01251], lr: 0.000867, loss: 0.4197
2022-09-30 08:09:50 - train: epoch 0168, iter [00150, 01251], lr: 0.000867, loss: 0.3898
2022-09-30 08:10:09 - train: epoch 0168, iter [00160, 01251], lr: 0.000867, loss: 0.4087
2022-09-30 08:10:27 - train: epoch 0168, iter [00170, 01251], lr: 0.000867, loss: 0.4151
2022-09-30 08:10:45 - train: epoch 0168, iter [00180, 01251], lr: 0.000867, loss: 0.3882
2022-09-30 08:11:03 - train: epoch 0168, iter [00190, 01251], lr: 0.000867, loss: 0.4065
2022-09-30 08:11:21 - train: epoch 0168, iter [00200, 01251], lr: 0.000867, loss: 0.4002
2022-09-30 08:11:38 - train: epoch 0168, iter [00210, 01251], lr: 0.000867, loss: 0.4106
2022-09-30 08:11:56 - train: epoch 0168, iter [00220, 01251], lr: 0.000867, loss: 0.4110
2022-09-30 08:12:14 - train: epoch 0168, iter [00230, 01251], lr: 0.000867, loss: 0.4056
2022-09-30 08:12:32 - train: epoch 0168, iter [00240, 01251], lr: 0.000867, loss: 0.4211
2022-09-30 08:12:50 - train: epoch 0168, iter [00250, 01251], lr: 0.000867, loss: 0.3898
2022-09-30 08:13:08 - train: epoch 0168, iter [00260, 01251], lr: 0.000867, loss: 0.4044
2022-09-30 08:13:26 - train: epoch 0168, iter [00270, 01251], lr: 0.000867, loss: 0.4119
2022-09-30 08:13:45 - train: epoch 0168, iter [00280, 01251], lr: 0.000867, loss: 0.4048
2022-09-30 08:14:03 - train: epoch 0168, iter [00290, 01251], lr: 0.000867, loss: 0.4141
2022-09-30 08:14:21 - train: epoch 0168, iter [00300, 01251], lr: 0.000867, loss: 0.4098
2022-09-30 08:14:39 - train: epoch 0168, iter [00310, 01251], lr: 0.000867, loss: 0.4106
2022-09-30 08:14:57 - train: epoch 0168, iter [00320, 01251], lr: 0.000867, loss: 0.3955
2022-09-30 08:15:15 - train: epoch 0168, iter [00330, 01251], lr: 0.000866, loss: 0.4175
2022-09-30 08:15:33 - train: epoch 0168, iter [00340, 01251], lr: 0.000866, loss: 0.4092
2022-09-30 08:15:51 - train: epoch 0168, iter [00350, 01251], lr: 0.000866, loss: 0.4002
2022-09-30 08:16:09 - train: epoch 0168, iter [00360, 01251], lr: 0.000866, loss: 0.4152
2022-09-30 08:16:28 - train: epoch 0168, iter [00370, 01251], lr: 0.000866, loss: 0.4160
2022-09-30 08:16:46 - train: epoch 0168, iter [00380, 01251], lr: 0.000866, loss: 0.4352
2022-09-30 08:17:04 - train: epoch 0168, iter [00390, 01251], lr: 0.000866, loss: 0.4177
2022-09-30 08:17:22 - train: epoch 0168, iter [00400, 01251], lr: 0.000866, loss: 0.4129
2022-09-30 08:17:40 - train: epoch 0168, iter [00410, 01251], lr: 0.000866, loss: 0.4253
2022-09-30 08:17:58 - train: epoch 0168, iter [00420, 01251], lr: 0.000866, loss: 0.3878
2022-09-30 08:18:16 - train: epoch 0168, iter [00430, 01251], lr: 0.000866, loss: 0.4114
2022-09-30 08:18:34 - train: epoch 0168, iter [00440, 01251], lr: 0.000866, loss: 0.4207
2022-09-30 08:18:52 - train: epoch 0168, iter [00450, 01251], lr: 0.000866, loss: 0.4096
2022-09-30 08:19:10 - train: epoch 0168, iter [00460, 01251], lr: 0.000866, loss: 0.4137
2022-09-30 08:19:28 - train: epoch 0168, iter [00470, 01251], lr: 0.000866, loss: 0.4129
2022-09-30 08:19:46 - train: epoch 0168, iter [00480, 01251], lr: 0.000866, loss: 0.4195
2022-09-30 08:20:04 - train: epoch 0168, iter [00490, 01251], lr: 0.000866, loss: 0.4130
2022-09-30 08:20:22 - train: epoch 0168, iter [00500, 01251], lr: 0.000866, loss: 0.4036
2022-09-30 08:20:40 - train: epoch 0168, iter [00510, 01251], lr: 0.000866, loss: 0.4079
2022-09-30 08:20:58 - train: epoch 0168, iter [00520, 01251], lr: 0.000866, loss: 0.4111
2022-09-30 08:21:16 - train: epoch 0168, iter [00530, 01251], lr: 0.000866, loss: 0.3982
2022-09-30 08:21:34 - train: epoch 0168, iter [00540, 01251], lr: 0.000866, loss: 0.3903
2022-09-30 08:21:52 - train: epoch 0168, iter [00550, 01251], lr: 0.000866, loss: 0.3889
2022-09-30 08:22:10 - train: epoch 0168, iter [00560, 01251], lr: 0.000866, loss: 0.4008
2022-09-30 08:22:28 - train: epoch 0168, iter [00570, 01251], lr: 0.000866, loss: 0.3934
2022-09-30 08:22:46 - train: epoch 0168, iter [00580, 01251], lr: 0.000866, loss: 0.3996
2022-09-30 08:23:04 - train: epoch 0168, iter [00590, 01251], lr: 0.000866, loss: 0.4130
2022-09-30 08:23:22 - train: epoch 0168, iter [00600, 01251], lr: 0.000865, loss: 0.4189
2022-09-30 08:23:40 - train: epoch 0168, iter [00610, 01251], lr: 0.000865, loss: 0.4046
2022-09-30 08:23:58 - train: epoch 0168, iter [00620, 01251], lr: 0.000865, loss: 0.4113
2022-09-30 08:24:16 - train: epoch 0168, iter [00630, 01251], lr: 0.000865, loss: 0.4024
2022-09-30 08:24:34 - train: epoch 0168, iter [00640, 01251], lr: 0.000865, loss: 0.4031
2022-09-30 08:24:52 - train: epoch 0168, iter [00650, 01251], lr: 0.000865, loss: 0.4108
2022-09-30 08:25:10 - train: epoch 0168, iter [00660, 01251], lr: 0.000865, loss: 0.4143
2022-09-30 08:25:28 - train: epoch 0168, iter [00670, 01251], lr: 0.000865, loss: 0.4144
2022-09-30 08:25:46 - train: epoch 0168, iter [00680, 01251], lr: 0.000865, loss: 0.3968
2022-09-30 08:26:04 - train: epoch 0168, iter [00690, 01251], lr: 0.000865, loss: 0.4104
2022-09-30 08:26:22 - train: epoch 0168, iter [00700, 01251], lr: 0.000865, loss: 0.4210
2022-09-30 08:26:40 - train: epoch 0168, iter [00710, 01251], lr: 0.000865, loss: 0.3963
2022-09-30 08:26:59 - train: epoch 0168, iter [00720, 01251], lr: 0.000865, loss: 0.4182
2022-09-30 08:27:17 - train: epoch 0168, iter [00730, 01251], lr: 0.000865, loss: 0.3877
2022-09-30 08:27:34 - train: epoch 0168, iter [00740, 01251], lr: 0.000865, loss: 0.4105
2022-09-30 08:27:52 - train: epoch 0168, iter [00750, 01251], lr: 0.000865, loss: 0.4261
2022-09-30 08:28:10 - train: epoch 0168, iter [00760, 01251], lr: 0.000865, loss: 0.4026
2022-09-30 08:28:29 - train: epoch 0168, iter [00770, 01251], lr: 0.000865, loss: 0.4005
2022-09-30 08:28:47 - train: epoch 0168, iter [00780, 01251], lr: 0.000865, loss: 0.4020
2022-09-30 08:29:04 - train: epoch 0168, iter [00790, 01251], lr: 0.000865, loss: 0.3930
2022-09-30 08:29:22 - train: epoch 0168, iter [00800, 01251], lr: 0.000865, loss: 0.4100
2022-09-30 08:29:40 - train: epoch 0168, iter [00810, 01251], lr: 0.000865, loss: 0.3986
2022-09-30 08:29:58 - train: epoch 0168, iter [00820, 01251], lr: 0.000865, loss: 0.4002
2022-09-30 08:30:16 - train: epoch 0168, iter [00830, 01251], lr: 0.000865, loss: 0.4126
2022-09-30 08:30:34 - train: epoch 0168, iter [00840, 01251], lr: 0.000865, loss: 0.4246
2022-09-30 08:30:52 - train: epoch 0168, iter [00850, 01251], lr: 0.000865, loss: 0.4087
2022-09-30 08:31:11 - train: epoch 0168, iter [00860, 01251], lr: 0.000864, loss: 0.4008
2022-09-30 08:31:29 - train: epoch 0168, iter [00870, 01251], lr: 0.000864, loss: 0.4027
2022-09-30 08:31:47 - train: epoch 0168, iter [00880, 01251], lr: 0.000864, loss: 0.4092
2022-09-30 08:32:05 - train: epoch 0168, iter [00890, 01251], lr: 0.000864, loss: 0.4181
2022-09-30 08:32:23 - train: epoch 0168, iter [00900, 01251], lr: 0.000864, loss: 0.4158
2022-09-30 08:32:41 - train: epoch 0168, iter [00910, 01251], lr: 0.000864, loss: 0.4182
2022-09-30 08:32:59 - train: epoch 0168, iter [00920, 01251], lr: 0.000864, loss: 0.4273
2022-09-30 08:33:17 - train: epoch 0168, iter [00930, 01251], lr: 0.000864, loss: 0.4184
2022-09-30 08:33:35 - train: epoch 0168, iter [00940, 01251], lr: 0.000864, loss: 0.4154
2022-09-30 08:33:53 - train: epoch 0168, iter [00950, 01251], lr: 0.000864, loss: 0.4064
2022-09-30 08:34:11 - train: epoch 0168, iter [00960, 01251], lr: 0.000864, loss: 0.3982
2022-09-30 08:34:29 - train: epoch 0168, iter [00970, 01251], lr: 0.000864, loss: 0.3972
2022-09-30 08:34:47 - train: epoch 0168, iter [00980, 01251], lr: 0.000864, loss: 0.4075
2022-09-30 08:35:06 - train: epoch 0168, iter [00990, 01251], lr: 0.000864, loss: 0.4052
2022-09-30 08:35:23 - train: epoch 0168, iter [01000, 01251], lr: 0.000864, loss: 0.4207
2022-09-30 08:35:42 - train: epoch 0168, iter [01010, 01251], lr: 0.000864, loss: 0.3989
2022-09-30 08:36:00 - train: epoch 0168, iter [01020, 01251], lr: 0.000864, loss: 0.4074
2022-09-30 08:36:18 - train: epoch 0168, iter [01030, 01251], lr: 0.000864, loss: 0.4094
2022-09-30 08:36:35 - train: epoch 0168, iter [01040, 01251], lr: 0.000864, loss: 0.4306
2022-09-30 08:36:54 - train: epoch 0168, iter [01050, 01251], lr: 0.000864, loss: 0.4001
2022-09-30 08:37:12 - train: epoch 0168, iter [01060, 01251], lr: 0.000864, loss: 0.4043
2022-09-30 08:37:31 - train: epoch 0168, iter [01070, 01251], lr: 0.000864, loss: 0.3964
2022-09-30 08:37:49 - train: epoch 0168, iter [01080, 01251], lr: 0.000864, loss: 0.4123
2022-09-30 08:38:07 - train: epoch 0168, iter [01090, 01251], lr: 0.000864, loss: 0.3997
2022-09-30 08:38:26 - train: epoch 0168, iter [01100, 01251], lr: 0.000864, loss: 0.4193
2022-09-30 08:38:44 - train: epoch 0168, iter [01110, 01251], lr: 0.000864, loss: 0.3980
2022-09-30 08:39:03 - train: epoch 0168, iter [01120, 01251], lr: 0.000864, loss: 0.4377
2022-09-30 08:39:21 - train: epoch 0168, iter [01130, 01251], lr: 0.000863, loss: 0.4098
2022-09-30 08:39:40 - train: epoch 0168, iter [01140, 01251], lr: 0.000863, loss: 0.4022
2022-09-30 08:39:58 - train: epoch 0168, iter [01150, 01251], lr: 0.000863, loss: 0.4166
2022-09-30 08:40:17 - train: epoch 0168, iter [01160, 01251], lr: 0.000863, loss: 0.4262
2022-09-30 08:40:35 - train: epoch 0168, iter [01170, 01251], lr: 0.000863, loss: 0.4106
2022-09-30 08:40:54 - train: epoch 0168, iter [01180, 01251], lr: 0.000863, loss: 0.4065
2022-09-30 08:41:12 - train: epoch 0168, iter [01190, 01251], lr: 0.000863, loss: 0.3945
2022-09-30 08:41:31 - train: epoch 0168, iter [01200, 01251], lr: 0.000863, loss: 0.4333
2022-09-30 08:41:50 - train: epoch 0168, iter [01210, 01251], lr: 0.000863, loss: 0.4192
2022-09-30 08:42:08 - train: epoch 0168, iter [01220, 01251], lr: 0.000863, loss: 0.4020
2022-09-30 08:42:27 - train: epoch 0168, iter [01230, 01251], lr: 0.000863, loss: 0.4208
2022-09-30 08:42:46 - train: epoch 0168, iter [01240, 01251], lr: 0.000863, loss: 0.4075
2022-09-30 08:43:04 - train: epoch 0168, iter [01250, 01251], lr: 0.000863, loss: 0.4243
2022-09-30 08:43:07 - train: epoch 168, train_loss: 0.4093
2022-09-30 08:43:10 - until epoch: 168, best_loss: 0.4093
2022-09-30 08:43:10 - epoch 169 lr: 0.000863
2022-09-30 08:43:35 - train: epoch 0169, iter [00010, 01251], lr: 0.000863, loss: 0.3990
2022-09-30 08:43:53 - train: epoch 0169, iter [00020, 01251], lr: 0.000863, loss: 0.4078
2022-09-30 08:44:12 - train: epoch 0169, iter [00030, 01251], lr: 0.000863, loss: 0.4140
2022-09-30 08:44:30 - train: epoch 0169, iter [00040, 01251], lr: 0.000863, loss: 0.4051
2022-09-30 08:44:49 - train: epoch 0169, iter [00050, 01251], lr: 0.000863, loss: 0.4060
2022-09-30 08:45:07 - train: epoch 0169, iter [00060, 01251], lr: 0.000863, loss: 0.4142
2022-09-30 08:45:26 - train: epoch 0169, iter [00070, 01251], lr: 0.000863, loss: 0.4022
2022-09-30 08:45:45 - train: epoch 0169, iter [00080, 01251], lr: 0.000863, loss: 0.4056
2022-09-30 08:46:03 - train: epoch 0169, iter [00090, 01251], lr: 0.000863, loss: 0.4101
2022-09-30 08:46:22 - train: epoch 0169, iter [00100, 01251], lr: 0.000863, loss: 0.4099
2022-09-30 08:46:41 - train: epoch 0169, iter [00110, 01251], lr: 0.000863, loss: 0.4372
2022-09-30 08:46:59 - train: epoch 0169, iter [00120, 01251], lr: 0.000863, loss: 0.4000
2022-09-30 08:47:18 - train: epoch 0169, iter [00130, 01251], lr: 0.000863, loss: 0.4078
2022-09-30 08:47:36 - train: epoch 0169, iter [00140, 01251], lr: 0.000862, loss: 0.4230
2022-09-30 08:47:55 - train: epoch 0169, iter [00150, 01251], lr: 0.000862, loss: 0.4218
2022-09-30 08:48:13 - train: epoch 0169, iter [00160, 01251], lr: 0.000862, loss: 0.3945
2022-09-30 08:48:32 - train: epoch 0169, iter [00170, 01251], lr: 0.000862, loss: 0.4132
2022-09-30 08:48:51 - train: epoch 0169, iter [00180, 01251], lr: 0.000862, loss: 0.4291
2022-09-30 08:49:09 - train: epoch 0169, iter [00190, 01251], lr: 0.000862, loss: 0.4195
2022-09-30 08:49:28 - train: epoch 0169, iter [00200, 01251], lr: 0.000862, loss: 0.4235
2022-09-30 08:49:46 - train: epoch 0169, iter [00210, 01251], lr: 0.000862, loss: 0.4128
2022-09-30 08:50:05 - train: epoch 0169, iter [00220, 01251], lr: 0.000862, loss: 0.4065
2022-09-30 08:50:23 - train: epoch 0169, iter [00230, 01251], lr: 0.000862, loss: 0.3899
2022-09-30 08:50:42 - train: epoch 0169, iter [00240, 01251], lr: 0.000862, loss: 0.4339
2022-09-30 08:51:00 - train: epoch 0169, iter [00250, 01251], lr: 0.000862, loss: 0.4082
2022-09-30 08:51:19 - train: epoch 0169, iter [00260, 01251], lr: 0.000862, loss: 0.4164
2022-09-30 08:51:38 - train: epoch 0169, iter [00270, 01251], lr: 0.000862, loss: 0.4115
2022-09-30 08:51:56 - train: epoch 0169, iter [00280, 01251], lr: 0.000862, loss: 0.4185
2022-09-30 08:52:15 - train: epoch 0169, iter [00290, 01251], lr: 0.000862, loss: 0.4318
2022-09-30 08:52:34 - train: epoch 0169, iter [00300, 01251], lr: 0.000862, loss: 0.4062
2022-09-30 08:52:52 - train: epoch 0169, iter [00310, 01251], lr: 0.000862, loss: 0.4028
2022-09-30 08:53:11 - train: epoch 0169, iter [00320, 01251], lr: 0.000862, loss: 0.4278
2022-09-30 08:53:30 - train: epoch 0169, iter [00330, 01251], lr: 0.000862, loss: 0.4041
2022-09-30 08:53:48 - train: epoch 0169, iter [00340, 01251], lr: 0.000862, loss: 0.4061
2022-09-30 08:54:07 - train: epoch 0169, iter [00350, 01251], lr: 0.000862, loss: 0.4115
2022-09-30 08:54:25 - train: epoch 0169, iter [00360, 01251], lr: 0.000862, loss: 0.4208
2022-09-30 08:54:43 - train: epoch 0169, iter [00370, 01251], lr: 0.000862, loss: 0.3909
2022-09-30 08:55:02 - train: epoch 0169, iter [00380, 01251], lr: 0.000862, loss: 0.4042
2022-09-30 08:55:21 - train: epoch 0169, iter [00390, 01251], lr: 0.000862, loss: 0.4137
2022-09-30 08:55:39 - train: epoch 0169, iter [00400, 01251], lr: 0.000862, loss: 0.4102
2022-09-30 08:55:58 - train: epoch 0169, iter [00410, 01251], lr: 0.000861, loss: 0.4041
2022-09-30 08:56:16 - train: epoch 0169, iter [00420, 01251], lr: 0.000861, loss: 0.4223
2022-09-30 08:56:35 - train: epoch 0169, iter [00430, 01251], lr: 0.000861, loss: 0.4137
2022-09-30 08:56:53 - train: epoch 0169, iter [00440, 01251], lr: 0.000861, loss: 0.4161
2022-09-30 08:57:12 - train: epoch 0169, iter [00450, 01251], lr: 0.000861, loss: 0.3871
2022-09-30 08:57:30 - train: epoch 0169, iter [00460, 01251], lr: 0.000861, loss: 0.3968
2022-09-30 08:57:49 - train: epoch 0169, iter [00470, 01251], lr: 0.000861, loss: 0.4017
2022-09-30 08:58:08 - train: epoch 0169, iter [00480, 01251], lr: 0.000861, loss: 0.4175
2022-09-30 08:58:26 - train: epoch 0169, iter [00490, 01251], lr: 0.000861, loss: 0.4186
2022-09-30 08:58:45 - train: epoch 0169, iter [00500, 01251], lr: 0.000861, loss: 0.4122
2022-09-30 08:59:04 - train: epoch 0169, iter [00510, 01251], lr: 0.000861, loss: 0.4175
2022-09-30 08:59:22 - train: epoch 0169, iter [00520, 01251], lr: 0.000861, loss: 0.3932
2022-09-30 08:59:40 - train: epoch 0169, iter [00530, 01251], lr: 0.000861, loss: 0.4053
2022-09-30 08:59:59 - train: epoch 0169, iter [00540, 01251], lr: 0.000861, loss: 0.4001
2022-09-30 09:00:18 - train: epoch 0169, iter [00550, 01251], lr: 0.000861, loss: 0.4060
2022-09-30 09:00:36 - train: epoch 0169, iter [00560, 01251], lr: 0.000861, loss: 0.4139
2022-09-30 09:00:55 - train: epoch 0169, iter [00570, 01251], lr: 0.000861, loss: 0.4060
2022-09-30 09:01:14 - train: epoch 0169, iter [00580, 01251], lr: 0.000861, loss: 0.4237
2022-09-30 09:01:32 - train: epoch 0169, iter [00590, 01251], lr: 0.000861, loss: 0.4017
2022-09-30 09:01:51 - train: epoch 0169, iter [00600, 01251], lr: 0.000861, loss: 0.4173
2022-09-30 09:02:09 - train: epoch 0169, iter [00610, 01251], lr: 0.000861, loss: 0.4033
2022-09-30 09:02:28 - train: epoch 0169, iter [00620, 01251], lr: 0.000861, loss: 0.4055
2022-09-30 09:02:46 - train: epoch 0169, iter [00630, 01251], lr: 0.000861, loss: 0.4072
2022-09-30 09:03:05 - train: epoch 0169, iter [00640, 01251], lr: 0.000861, loss: 0.3933
2022-09-30 09:03:24 - train: epoch 0169, iter [00650, 01251], lr: 0.000861, loss: 0.4402
2022-09-30 09:03:42 - train: epoch 0169, iter [00660, 01251], lr: 0.000861, loss: 0.4017
2022-09-30 09:04:01 - train: epoch 0169, iter [00670, 01251], lr: 0.000860, loss: 0.4043
2022-09-30 09:04:19 - train: epoch 0169, iter [00680, 01251], lr: 0.000860, loss: 0.4061
2022-09-30 09:04:38 - train: epoch 0169, iter [00690, 01251], lr: 0.000860, loss: 0.4104
2022-09-30 09:04:56 - train: epoch 0169, iter [00700, 01251], lr: 0.000860, loss: 0.3995
2022-09-30 09:05:15 - train: epoch 0169, iter [00710, 01251], lr: 0.000860, loss: 0.3940
2022-09-30 09:05:33 - train: epoch 0169, iter [00720, 01251], lr: 0.000860, loss: 0.3965
2022-09-30 09:05:52 - train: epoch 0169, iter [00730, 01251], lr: 0.000860, loss: 0.4060
2022-09-30 09:06:10 - train: epoch 0169, iter [00740, 01251], lr: 0.000860, loss: 0.4260
2022-09-30 09:06:29 - train: epoch 0169, iter [00750, 01251], lr: 0.000860, loss: 0.3983
2022-09-30 09:06:47 - train: epoch 0169, iter [00760, 01251], lr: 0.000860, loss: 0.4182
2022-09-30 09:07:05 - train: epoch 0169, iter [00770, 01251], lr: 0.000860, loss: 0.3979
2022-09-30 09:07:24 - train: epoch 0169, iter [00780, 01251], lr: 0.000860, loss: 0.4056
2022-09-30 09:07:43 - train: epoch 0169, iter [00790, 01251], lr: 0.000860, loss: 0.3812
2022-09-30 09:08:01 - train: epoch 0169, iter [00800, 01251], lr: 0.000860, loss: 0.4016
2022-09-30 09:08:19 - train: epoch 0169, iter [00810, 01251], lr: 0.000860, loss: 0.3941
2022-09-30 09:08:38 - train: epoch 0169, iter [00820, 01251], lr: 0.000860, loss: 0.4193
2022-09-30 09:08:57 - train: epoch 0169, iter [00830, 01251], lr: 0.000860, loss: 0.3985
2022-09-30 09:09:15 - train: epoch 0169, iter [00840, 01251], lr: 0.000860, loss: 0.4349
2022-09-30 09:09:34 - train: epoch 0169, iter [00850, 01251], lr: 0.000860, loss: 0.4047
2022-09-30 09:09:52 - train: epoch 0169, iter [00860, 01251], lr: 0.000860, loss: 0.4123
2022-09-30 09:10:11 - train: epoch 0169, iter [00870, 01251], lr: 0.000860, loss: 0.4146
2022-09-30 09:10:30 - train: epoch 0169, iter [00880, 01251], lr: 0.000860, loss: 0.4023
2022-09-30 09:10:48 - train: epoch 0169, iter [00890, 01251], lr: 0.000860, loss: 0.4032
2022-09-30 09:11:07 - train: epoch 0169, iter [00900, 01251], lr: 0.000860, loss: 0.3950
2022-09-30 09:11:25 - train: epoch 0169, iter [00910, 01251], lr: 0.000860, loss: 0.3827
2022-09-30 09:11:44 - train: epoch 0169, iter [00920, 01251], lr: 0.000860, loss: 0.4159
2022-09-30 09:12:03 - train: epoch 0169, iter [00930, 01251], lr: 0.000860, loss: 0.4045
2022-09-30 09:12:22 - train: epoch 0169, iter [00940, 01251], lr: 0.000859, loss: 0.4056
2022-09-30 09:12:40 - train: epoch 0169, iter [00950, 01251], lr: 0.000859, loss: 0.4129
2022-09-30 09:12:59 - train: epoch 0169, iter [00960, 01251], lr: 0.000859, loss: 0.3848
2022-09-30 09:13:18 - train: epoch 0169, iter [00970, 01251], lr: 0.000859, loss: 0.4225
2022-09-30 09:13:36 - train: epoch 0169, iter [00980, 01251], lr: 0.000859, loss: 0.4169
2022-09-30 09:13:55 - train: epoch 0169, iter [00990, 01251], lr: 0.000859, loss: 0.4096
2022-09-30 09:14:13 - train: epoch 0169, iter [01000, 01251], lr: 0.000859, loss: 0.4048
2022-09-30 09:14:31 - train: epoch 0169, iter [01010, 01251], lr: 0.000859, loss: 0.4167
2022-09-30 09:14:50 - train: epoch 0169, iter [01020, 01251], lr: 0.000859, loss: 0.4074
2022-09-30 09:15:08 - train: epoch 0169, iter [01030, 01251], lr: 0.000859, loss: 0.3898
2022-09-30 09:15:27 - train: epoch 0169, iter [01040, 01251], lr: 0.000859, loss: 0.4264
2022-09-30 09:15:46 - train: epoch 0169, iter [01050, 01251], lr: 0.000859, loss: 0.4226
2022-09-30 09:16:04 - train: epoch 0169, iter [01060, 01251], lr: 0.000859, loss: 0.3909
2022-09-30 09:16:22 - train: epoch 0169, iter [01070, 01251], lr: 0.000859, loss: 0.3830
2022-09-30 09:16:41 - train: epoch 0169, iter [01080, 01251], lr: 0.000859, loss: 0.4003
2022-09-30 09:16:59 - train: epoch 0169, iter [01090, 01251], lr: 0.000859, loss: 0.3980
2022-09-30 09:17:18 - train: epoch 0169, iter [01100, 01251], lr: 0.000859, loss: 0.4124
2022-09-30 09:17:36 - train: epoch 0169, iter [01110, 01251], lr: 0.000859, loss: 0.3958
2022-09-30 09:17:55 - train: epoch 0169, iter [01120, 01251], lr: 0.000859, loss: 0.4017
2022-09-30 09:18:13 - train: epoch 0169, iter [01130, 01251], lr: 0.000859, loss: 0.4032
2022-09-30 09:18:32 - train: epoch 0169, iter [01140, 01251], lr: 0.000859, loss: 0.4170
2022-09-30 09:18:50 - train: epoch 0169, iter [01150, 01251], lr: 0.000859, loss: 0.4139
2022-09-30 09:19:09 - train: epoch 0169, iter [01160, 01251], lr: 0.000859, loss: 0.4033
2022-09-30 09:19:27 - train: epoch 0169, iter [01170, 01251], lr: 0.000859, loss: 0.4077
2022-09-30 09:19:46 - train: epoch 0169, iter [01180, 01251], lr: 0.000859, loss: 0.4072
2022-09-30 09:20:05 - train: epoch 0169, iter [01190, 01251], lr: 0.000859, loss: 0.4050
2022-09-30 09:20:23 - train: epoch 0169, iter [01200, 01251], lr: 0.000858, loss: 0.4200
2022-09-30 09:20:42 - train: epoch 0169, iter [01210, 01251], lr: 0.000858, loss: 0.4169
2022-09-30 09:21:00 - train: epoch 0169, iter [01220, 01251], lr: 0.000858, loss: 0.4125
2022-09-30 09:21:19 - train: epoch 0169, iter [01230, 01251], lr: 0.000858, loss: 0.4068
2022-09-30 09:21:37 - train: epoch 0169, iter [01240, 01251], lr: 0.000858, loss: 0.4064
2022-09-30 09:21:56 - train: epoch 0169, iter [01250, 01251], lr: 0.000858, loss: 0.3987
2022-09-30 09:21:59 - train: epoch 169, train_loss: 0.4091
2022-09-30 09:22:02 - until epoch: 169, best_loss: 0.4091
2022-09-30 09:22:02 - epoch 170 lr: 0.000858
2022-09-30 09:22:27 - train: epoch 0170, iter [00010, 01251], lr: 0.000858, loss: 0.4093
2022-09-30 09:22:45 - train: epoch 0170, iter [00020, 01251], lr: 0.000858, loss: 0.4161
2022-09-30 09:23:04 - train: epoch 0170, iter [00030, 01251], lr: 0.000858, loss: 0.4001
2022-09-30 09:23:22 - train: epoch 0170, iter [00040, 01251], lr: 0.000858, loss: 0.4135
2022-09-30 09:23:41 - train: epoch 0170, iter [00050, 01251], lr: 0.000858, loss: 0.4095
2022-09-30 09:23:59 - train: epoch 0170, iter [00060, 01251], lr: 0.000858, loss: 0.4149
2022-09-30 09:24:18 - train: epoch 0170, iter [00070, 01251], lr: 0.000858, loss: 0.4087
2022-09-30 09:24:37 - train: epoch 0170, iter [00080, 01251], lr: 0.000858, loss: 0.4000
2022-09-30 09:24:55 - train: epoch 0170, iter [00090, 01251], lr: 0.000858, loss: 0.4071
2022-09-30 09:25:14 - train: epoch 0170, iter [00100, 01251], lr: 0.000858, loss: 0.4124
2022-09-30 09:25:32 - train: epoch 0170, iter [00110, 01251], lr: 0.000858, loss: 0.4283
2022-09-30 09:25:51 - train: epoch 0170, iter [00120, 01251], lr: 0.000858, loss: 0.4067
2022-09-30 09:26:09 - train: epoch 0170, iter [00130, 01251], lr: 0.000858, loss: 0.3974
2022-09-30 09:26:28 - train: epoch 0170, iter [00140, 01251], lr: 0.000858, loss: 0.4291
2022-09-30 09:26:46 - train: epoch 0170, iter [00150, 01251], lr: 0.000858, loss: 0.4068
2022-09-30 09:27:04 - train: epoch 0170, iter [00160, 01251], lr: 0.000858, loss: 0.4234
2022-09-30 09:27:23 - train: epoch 0170, iter [00170, 01251], lr: 0.000858, loss: 0.4091
2022-09-30 09:27:41 - train: epoch 0170, iter [00180, 01251], lr: 0.000858, loss: 0.4034
2022-09-30 09:28:00 - train: epoch 0170, iter [00190, 01251], lr: 0.000858, loss: 0.4142
2022-09-30 09:28:18 - train: epoch 0170, iter [00200, 01251], lr: 0.000858, loss: 0.4085
2022-09-30 09:28:37 - train: epoch 0170, iter [00210, 01251], lr: 0.000858, loss: 0.3999
2022-09-30 09:28:56 - train: epoch 0170, iter [00220, 01251], lr: 0.000857, loss: 0.4151
2022-09-30 09:29:14 - train: epoch 0170, iter [00230, 01251], lr: 0.000857, loss: 0.4213
2022-09-30 09:29:33 - train: epoch 0170, iter [00240, 01251], lr: 0.000857, loss: 0.4034
2022-09-30 09:29:51 - train: epoch 0170, iter [00250, 01251], lr: 0.000857, loss: 0.4333
2022-09-30 09:30:10 - train: epoch 0170, iter [00260, 01251], lr: 0.000857, loss: 0.4077
2022-09-30 09:30:28 - train: epoch 0170, iter [00270, 01251], lr: 0.000857, loss: 0.4065
2022-09-30 09:30:47 - train: epoch 0170, iter [00280, 01251], lr: 0.000857, loss: 0.4075
2022-09-30 09:31:05 - train: epoch 0170, iter [00290, 01251], lr: 0.000857, loss: 0.4204
2022-09-30 09:31:24 - train: epoch 0170, iter [00300, 01251], lr: 0.000857, loss: 0.4094
2022-09-30 09:31:43 - train: epoch 0170, iter [00310, 01251], lr: 0.000857, loss: 0.4157
2022-09-30 09:32:01 - train: epoch 0170, iter [00320, 01251], lr: 0.000857, loss: 0.4057
2022-09-30 09:32:20 - train: epoch 0170, iter [00330, 01251], lr: 0.000857, loss: 0.4276
2022-09-30 09:32:39 - train: epoch 0170, iter [00340, 01251], lr: 0.000857, loss: 0.4209
2022-09-30 09:32:57 - train: epoch 0170, iter [00350, 01251], lr: 0.000857, loss: 0.4110
2022-09-30 09:33:15 - train: epoch 0170, iter [00360, 01251], lr: 0.000857, loss: 0.4108
2022-09-30 09:33:33 - train: epoch 0170, iter [00370, 01251], lr: 0.000857, loss: 0.3976
2022-09-30 09:33:51 - train: epoch 0170, iter [00380, 01251], lr: 0.000857, loss: 0.4278
2022-09-30 09:34:09 - train: epoch 0170, iter [00390, 01251], lr: 0.000857, loss: 0.4123
2022-09-30 09:34:27 - train: epoch 0170, iter [00400, 01251], lr: 0.000857, loss: 0.4122
2022-09-30 09:34:45 - train: epoch 0170, iter [00410, 01251], lr: 0.000857, loss: 0.3910
2022-09-30 09:35:03 - train: epoch 0170, iter [00420, 01251], lr: 0.000857, loss: 0.4242
2022-09-30 09:35:21 - train: epoch 0170, iter [00430, 01251], lr: 0.000857, loss: 0.4190
2022-09-30 09:35:39 - train: epoch 0170, iter [00440, 01251], lr: 0.000857, loss: 0.4193
2022-09-30 09:35:57 - train: epoch 0170, iter [00450, 01251], lr: 0.000857, loss: 0.4173
2022-09-30 09:36:15 - train: epoch 0170, iter [00460, 01251], lr: 0.000857, loss: 0.4106
2022-09-30 09:36:33 - train: epoch 0170, iter [00470, 01251], lr: 0.000857, loss: 0.4161
2022-09-30 09:36:50 - train: epoch 0170, iter [00480, 01251], lr: 0.000856, loss: 0.4048
2022-09-30 09:37:08 - train: epoch 0170, iter [00490, 01251], lr: 0.000856, loss: 0.4209
2022-09-30 09:37:26 - train: epoch 0170, iter [00500, 01251], lr: 0.000856, loss: 0.4040
2022-09-30 09:37:44 - train: epoch 0170, iter [00510, 01251], lr: 0.000856, loss: 0.3945
2022-09-30 09:38:02 - train: epoch 0170, iter [00520, 01251], lr: 0.000856, loss: 0.4043
2022-09-30 09:38:19 - train: epoch 0170, iter [00530, 01251], lr: 0.000856, loss: 0.4174
2022-09-30 09:38:37 - train: epoch 0170, iter [00540, 01251], lr: 0.000856, loss: 0.4199
2022-09-30 09:38:55 - train: epoch 0170, iter [00550, 01251], lr: 0.000856, loss: 0.3845
2022-09-30 09:39:13 - train: epoch 0170, iter [00560, 01251], lr: 0.000856, loss: 0.3955
2022-09-30 09:39:31 - train: epoch 0170, iter [00570, 01251], lr: 0.000856, loss: 0.4107
2022-09-30 09:39:49 - train: epoch 0170, iter [00580, 01251], lr: 0.000856, loss: 0.4041
2022-09-30 09:40:07 - train: epoch 0170, iter [00590, 01251], lr: 0.000856, loss: 0.4087
2022-09-30 09:40:25 - train: epoch 0170, iter [00600, 01251], lr: 0.000856, loss: 0.4093
2022-09-30 09:40:43 - train: epoch 0170, iter [00610, 01251], lr: 0.000856, loss: 0.4133
2022-09-30 09:41:00 - train: epoch 0170, iter [00620, 01251], lr: 0.000856, loss: 0.3972
2022-09-30 09:41:18 - train: epoch 0170, iter [00630, 01251], lr: 0.000856, loss: 0.3955
2022-09-30 09:41:36 - train: epoch 0170, iter [00640, 01251], lr: 0.000856, loss: 0.4133
2022-09-30 09:41:54 - train: epoch 0170, iter [00650, 01251], lr: 0.000856, loss: 0.4146
2022-09-30 09:42:12 - train: epoch 0170, iter [00660, 01251], lr: 0.000856, loss: 0.4175
2022-09-30 09:42:29 - train: epoch 0170, iter [00670, 01251], lr: 0.000856, loss: 0.4154
2022-09-30 09:42:48 - train: epoch 0170, iter [00680, 01251], lr: 0.000856, loss: 0.4248
2022-09-30 09:43:06 - train: epoch 0170, iter [00690, 01251], lr: 0.000856, loss: 0.4090
2022-09-30 09:43:24 - train: epoch 0170, iter [00700, 01251], lr: 0.000856, loss: 0.4063
2022-09-30 09:43:42 - train: epoch 0170, iter [00710, 01251], lr: 0.000856, loss: 0.4134
2022-09-30 09:44:00 - train: epoch 0170, iter [00720, 01251], lr: 0.000856, loss: 0.4135
2022-09-30 09:44:18 - train: epoch 0170, iter [00730, 01251], lr: 0.000856, loss: 0.3986
2022-09-30 09:44:36 - train: epoch 0170, iter [00740, 01251], lr: 0.000856, loss: 0.4125
2022-09-30 09:44:53 - train: epoch 0170, iter [00750, 01251], lr: 0.000855, loss: 0.4120
2022-09-30 09:45:11 - train: epoch 0170, iter [00760, 01251], lr: 0.000855, loss: 0.4115
2022-09-30 09:45:29 - train: epoch 0170, iter [00770, 01251], lr: 0.000855, loss: 0.4383
2022-09-30 09:45:47 - train: epoch 0170, iter [00780, 01251], lr: 0.000855, loss: 0.3904
2022-09-30 09:46:05 - train: epoch 0170, iter [00790, 01251], lr: 0.000855, loss: 0.4111
2022-09-30 09:46:23 - train: epoch 0170, iter [00800, 01251], lr: 0.000855, loss: 0.4058
2022-09-30 09:46:41 - train: epoch 0170, iter [00810, 01251], lr: 0.000855, loss: 0.4229
2022-09-30 09:46:58 - train: epoch 0170, iter [00820, 01251], lr: 0.000855, loss: 0.4168
2022-09-30 09:47:16 - train: epoch 0170, iter [00830, 01251], lr: 0.000855, loss: 0.4266
2022-09-30 09:47:34 - train: epoch 0170, iter [00840, 01251], lr: 0.000855, loss: 0.4172
2022-09-30 09:47:52 - train: epoch 0170, iter [00850, 01251], lr: 0.000855, loss: 0.3924
2022-09-30 09:48:09 - train: epoch 0170, iter [00860, 01251], lr: 0.000855, loss: 0.4010
2022-09-30 09:48:27 - train: epoch 0170, iter [00870, 01251], lr: 0.000855, loss: 0.4026
2022-09-30 09:48:45 - train: epoch 0170, iter [00880, 01251], lr: 0.000855, loss: 0.4023
2022-09-30 09:49:03 - train: epoch 0170, iter [00890, 01251], lr: 0.000855, loss: 0.3942
2022-09-30 09:49:21 - train: epoch 0170, iter [00900, 01251], lr: 0.000855, loss: 0.3975
2022-09-30 09:49:39 - train: epoch 0170, iter [00910, 01251], lr: 0.000855, loss: 0.3976
2022-09-30 09:49:57 - train: epoch 0170, iter [00920, 01251], lr: 0.000855, loss: 0.3897
2022-09-30 09:50:15 - train: epoch 0170, iter [00930, 01251], lr: 0.000855, loss: 0.4397
2022-09-30 09:50:32 - train: epoch 0170, iter [00940, 01251], lr: 0.000855, loss: 0.4036
2022-09-30 09:50:50 - train: epoch 0170, iter [00950, 01251], lr: 0.000855, loss: 0.4087
2022-09-30 09:51:08 - train: epoch 0170, iter [00960, 01251], lr: 0.000855, loss: 0.4008
2022-09-30 09:51:26 - train: epoch 0170, iter [00970, 01251], lr: 0.000855, loss: 0.4028
2022-09-30 09:51:44 - train: epoch 0170, iter [00980, 01251], lr: 0.000855, loss: 0.3954
2022-09-30 09:52:02 - train: epoch 0170, iter [00990, 01251], lr: 0.000855, loss: 0.4063
2022-09-30 09:52:20 - train: epoch 0170, iter [01000, 01251], lr: 0.000855, loss: 0.4082
2022-09-30 09:52:38 - train: epoch 0170, iter [01010, 01251], lr: 0.000854, loss: 0.4142
2022-09-30 09:52:56 - train: epoch 0170, iter [01020, 01251], lr: 0.000854, loss: 0.4268
2022-09-30 09:53:14 - train: epoch 0170, iter [01030, 01251], lr: 0.000854, loss: 0.4236
2022-09-30 09:53:31 - train: epoch 0170, iter [01040, 01251], lr: 0.000854, loss: 0.4133
2022-09-30 09:53:49 - train: epoch 0170, iter [01050, 01251], lr: 0.000854, loss: 0.3944
2022-09-30 09:54:07 - train: epoch 0170, iter [01060, 01251], lr: 0.000854, loss: 0.4109
2022-09-30 09:54:25 - train: epoch 0170, iter [01070, 01251], lr: 0.000854, loss: 0.4035
2022-09-30 09:54:43 - train: epoch 0170, iter [01080, 01251], lr: 0.000854, loss: 0.4104
2022-09-30 09:55:00 - train: epoch 0170, iter [01090, 01251], lr: 0.000854, loss: 0.4051
2022-09-30 09:55:18 - train: epoch 0170, iter [01100, 01251], lr: 0.000854, loss: 0.4234
2022-09-30 09:55:36 - train: epoch 0170, iter [01110, 01251], lr: 0.000854, loss: 0.3857
2022-09-30 09:55:54 - train: epoch 0170, iter [01120, 01251], lr: 0.000854, loss: 0.3929
2022-09-30 09:56:12 - train: epoch 0170, iter [01130, 01251], lr: 0.000854, loss: 0.4212
2022-09-30 09:56:30 - train: epoch 0170, iter [01140, 01251], lr: 0.000854, loss: 0.4064
2022-09-30 09:56:48 - train: epoch 0170, iter [01150, 01251], lr: 0.000854, loss: 0.3935
2022-09-30 09:57:05 - train: epoch 0170, iter [01160, 01251], lr: 0.000854, loss: 0.4247
2022-09-30 09:57:23 - train: epoch 0170, iter [01170, 01251], lr: 0.000854, loss: 0.4027
2022-09-30 09:57:41 - train: epoch 0170, iter [01180, 01251], lr: 0.000854, loss: 0.4012
2022-09-30 09:57:59 - train: epoch 0170, iter [01190, 01251], lr: 0.000854, loss: 0.4142
2022-09-30 09:58:17 - train: epoch 0170, iter [01200, 01251], lr: 0.000854, loss: 0.4044
2022-09-30 09:58:34 - train: epoch 0170, iter [01210, 01251], lr: 0.000854, loss: 0.4150
2022-09-30 09:58:52 - train: epoch 0170, iter [01220, 01251], lr: 0.000854, loss: 0.4169
2022-09-30 09:59:10 - train: epoch 0170, iter [01230, 01251], lr: 0.000854, loss: 0.4312
2022-09-30 09:59:28 - train: epoch 0170, iter [01240, 01251], lr: 0.000854, loss: 0.4192
2022-09-30 09:59:45 - train: epoch 0170, iter [01250, 01251], lr: 0.000854, loss: 0.4239
2022-09-30 09:59:49 - train: epoch 170, train_loss: 0.4091
2022-09-30 09:59:52 - until epoch: 170, best_loss: 0.4091
2022-09-30 09:59:52 - epoch 171 lr: 0.000854
2022-09-30 10:00:17 - train: epoch 0171, iter [00010, 01251], lr: 0.000854, loss: 0.4090
2022-09-30 10:00:34 - train: epoch 0171, iter [00020, 01251], lr: 0.000853, loss: 0.4295
2022-09-30 10:00:52 - train: epoch 0171, iter [00030, 01251], lr: 0.000853, loss: 0.4225
2022-09-30 10:01:10 - train: epoch 0171, iter [00040, 01251], lr: 0.000853, loss: 0.4168
2022-09-30 10:01:28 - train: epoch 0171, iter [00050, 01251], lr: 0.000853, loss: 0.3928
2022-09-30 10:01:46 - train: epoch 0171, iter [00060, 01251], lr: 0.000853, loss: 0.4366
2022-09-30 10:02:03 - train: epoch 0171, iter [00070, 01251], lr: 0.000853, loss: 0.3906
2022-09-30 10:02:21 - train: epoch 0171, iter [00080, 01251], lr: 0.000853, loss: 0.4162
2022-09-30 10:02:39 - train: epoch 0171, iter [00090, 01251], lr: 0.000853, loss: 0.4041
2022-09-30 10:02:57 - train: epoch 0171, iter [00100, 01251], lr: 0.000853, loss: 0.4090
2022-09-30 10:03:15 - train: epoch 0171, iter [00110, 01251], lr: 0.000853, loss: 0.4099
2022-09-30 10:03:33 - train: epoch 0171, iter [00120, 01251], lr: 0.000853, loss: 0.4246
2022-09-30 10:03:51 - train: epoch 0171, iter [00130, 01251], lr: 0.000853, loss: 0.4111
2022-09-30 10:04:09 - train: epoch 0171, iter [00140, 01251], lr: 0.000853, loss: 0.4114
2022-09-30 10:04:27 - train: epoch 0171, iter [00150, 01251], lr: 0.000853, loss: 0.3900
2022-09-30 10:04:45 - train: epoch 0171, iter [00160, 01251], lr: 0.000853, loss: 0.3928
2022-09-30 10:05:03 - train: epoch 0171, iter [00170, 01251], lr: 0.000853, loss: 0.4179
2022-09-30 10:05:21 - train: epoch 0171, iter [00180, 01251], lr: 0.000853, loss: 0.4034
2022-09-30 10:05:39 - train: epoch 0171, iter [00190, 01251], lr: 0.000853, loss: 0.4207
2022-09-30 10:05:56 - train: epoch 0171, iter [00200, 01251], lr: 0.000853, loss: 0.4088
2022-09-30 10:06:14 - train: epoch 0171, iter [00210, 01251], lr: 0.000853, loss: 0.4013
2022-09-30 10:06:32 - train: epoch 0171, iter [00220, 01251], lr: 0.000853, loss: 0.3816
2022-09-30 10:06:50 - train: epoch 0171, iter [00230, 01251], lr: 0.000853, loss: 0.4216
2022-09-30 10:07:08 - train: epoch 0171, iter [00240, 01251], lr: 0.000853, loss: 0.4187
2022-09-30 10:07:25 - train: epoch 0171, iter [00250, 01251], lr: 0.000853, loss: 0.4020
2022-09-30 10:07:43 - train: epoch 0171, iter [00260, 01251], lr: 0.000853, loss: 0.4123
2022-09-30 10:08:01 - train: epoch 0171, iter [00270, 01251], lr: 0.000853, loss: 0.4114
2022-09-30 10:08:19 - train: epoch 0171, iter [00280, 01251], lr: 0.000853, loss: 0.4041
2022-09-30 10:08:37 - train: epoch 0171, iter [00290, 01251], lr: 0.000852, loss: 0.3874
2022-09-30 10:08:55 - train: epoch 0171, iter [00300, 01251], lr: 0.000852, loss: 0.4016
2022-09-30 10:09:13 - train: epoch 0171, iter [00310, 01251], lr: 0.000852, loss: 0.4353
2022-09-30 10:09:30 - train: epoch 0171, iter [00320, 01251], lr: 0.000852, loss: 0.4211
2022-09-30 10:09:48 - train: epoch 0171, iter [00330, 01251], lr: 0.000852, loss: 0.4214
2022-09-30 10:10:06 - train: epoch 0171, iter [00340, 01251], lr: 0.000852, loss: 0.4103
2022-09-30 10:10:24 - train: epoch 0171, iter [00350, 01251], lr: 0.000852, loss: 0.4296
2022-09-30 10:10:42 - train: epoch 0171, iter [00360, 01251], lr: 0.000852, loss: 0.4120
2022-09-30 10:11:00 - train: epoch 0171, iter [00370, 01251], lr: 0.000852, loss: 0.4129
2022-09-30 10:11:17 - train: epoch 0171, iter [00380, 01251], lr: 0.000852, loss: 0.4149
2022-09-30 10:11:35 - train: epoch 0171, iter [00390, 01251], lr: 0.000852, loss: 0.3988
2022-09-30 10:11:53 - train: epoch 0171, iter [00400, 01251], lr: 0.000852, loss: 0.4001
2022-09-30 10:12:11 - train: epoch 0171, iter [00410, 01251], lr: 0.000852, loss: 0.3988
2022-09-30 10:12:28 - train: epoch 0171, iter [00420, 01251], lr: 0.000852, loss: 0.4177
2022-09-30 10:12:46 - train: epoch 0171, iter [00430, 01251], lr: 0.000852, loss: 0.4181
2022-09-30 10:13:04 - train: epoch 0171, iter [00440, 01251], lr: 0.000852, loss: 0.4119
2022-09-30 10:13:22 - train: epoch 0171, iter [00450, 01251], lr: 0.000852, loss: 0.4030
2022-09-30 10:13:39 - train: epoch 0171, iter [00460, 01251], lr: 0.000852, loss: 0.4117
2022-09-30 10:13:57 - train: epoch 0171, iter [00470, 01251], lr: 0.000852, loss: 0.3958
2022-09-30 10:14:15 - train: epoch 0171, iter [00480, 01251], lr: 0.000852, loss: 0.3926
2022-09-30 10:14:33 - train: epoch 0171, iter [00490, 01251], lr: 0.000852, loss: 0.3996
2022-09-30 10:14:51 - train: epoch 0171, iter [00500, 01251], lr: 0.000852, loss: 0.4047
2022-09-30 10:15:08 - train: epoch 0171, iter [00510, 01251], lr: 0.000852, loss: 0.4080
2022-09-30 10:15:26 - train: epoch 0171, iter [00520, 01251], lr: 0.000852, loss: 0.3921
2022-09-30 10:15:44 - train: epoch 0171, iter [00530, 01251], lr: 0.000852, loss: 0.4166
2022-09-30 10:16:02 - train: epoch 0171, iter [00540, 01251], lr: 0.000852, loss: 0.4181
2022-09-30 10:16:19 - train: epoch 0171, iter [00550, 01251], lr: 0.000851, loss: 0.3856
2022-09-30 10:16:37 - train: epoch 0171, iter [00560, 01251], lr: 0.000851, loss: 0.4162
2022-09-30 10:16:55 - train: epoch 0171, iter [00570, 01251], lr: 0.000851, loss: 0.3977
2022-09-30 10:17:13 - train: epoch 0171, iter [00580, 01251], lr: 0.000851, loss: 0.4052
2022-09-30 10:17:31 - train: epoch 0171, iter [00590, 01251], lr: 0.000851, loss: 0.4070
2022-09-30 10:17:49 - train: epoch 0171, iter [00600, 01251], lr: 0.000851, loss: 0.4171
2022-09-30 10:18:06 - train: epoch 0171, iter [00610, 01251], lr: 0.000851, loss: 0.4158
2022-09-30 10:18:24 - train: epoch 0171, iter [00620, 01251], lr: 0.000851, loss: 0.4115
2022-09-30 10:18:42 - train: epoch 0171, iter [00630, 01251], lr: 0.000851, loss: 0.4078
2022-09-30 10:18:59 - train: epoch 0171, iter [00640, 01251], lr: 0.000851, loss: 0.4075
2022-09-30 10:19:17 - train: epoch 0171, iter [00650, 01251], lr: 0.000851, loss: 0.4091
2022-09-30 10:19:35 - train: epoch 0171, iter [00660, 01251], lr: 0.000851, loss: 0.4070
2022-09-30 10:19:53 - train: epoch 0171, iter [00670, 01251], lr: 0.000851, loss: 0.4032
2022-09-30 10:20:10 - train: epoch 0171, iter [00680, 01251], lr: 0.000851, loss: 0.4169
2022-09-30 10:20:28 - train: epoch 0171, iter [00690, 01251], lr: 0.000851, loss: 0.4115
2022-09-30 10:20:46 - train: epoch 0171, iter [00700, 01251], lr: 0.000851, loss: 0.3869
2022-09-30 10:21:04 - train: epoch 0171, iter [00710, 01251], lr: 0.000851, loss: 0.4079
2022-09-30 10:21:21 - train: epoch 0171, iter [00720, 01251], lr: 0.000851, loss: 0.4072
2022-09-30 10:21:39 - train: epoch 0171, iter [00730, 01251], lr: 0.000851, loss: 0.3921
2022-09-30 10:21:57 - train: epoch 0171, iter [00740, 01251], lr: 0.000851, loss: 0.4078
2022-09-30 10:22:15 - train: epoch 0171, iter [00750, 01251], lr: 0.000851, loss: 0.4015
2022-09-30 10:22:33 - train: epoch 0171, iter [00760, 01251], lr: 0.000851, loss: 0.4109
2022-09-30 10:22:50 - train: epoch 0171, iter [00770, 01251], lr: 0.000851, loss: 0.4042
2022-09-30 10:23:08 - train: epoch 0171, iter [00780, 01251], lr: 0.000851, loss: 0.4101
2022-09-30 10:23:26 - train: epoch 0171, iter [00790, 01251], lr: 0.000851, loss: 0.4048
2022-09-30 10:23:44 - train: epoch 0171, iter [00800, 01251], lr: 0.000851, loss: 0.4007
2022-09-30 10:24:02 - train: epoch 0171, iter [00810, 01251], lr: 0.000850, loss: 0.3960
2022-09-30 10:24:19 - train: epoch 0171, iter [00820, 01251], lr: 0.000850, loss: 0.3955
2022-09-30 10:24:37 - train: epoch 0171, iter [00830, 01251], lr: 0.000850, loss: 0.4073
2022-09-30 10:24:55 - train: epoch 0171, iter [00840, 01251], lr: 0.000850, loss: 0.4089
2022-09-30 10:25:13 - train: epoch 0171, iter [00850, 01251], lr: 0.000850, loss: 0.4119
2022-09-30 10:25:30 - train: epoch 0171, iter [00860, 01251], lr: 0.000850, loss: 0.4112
2022-09-30 10:25:48 - train: epoch 0171, iter [00870, 01251], lr: 0.000850, loss: 0.4141
2022-09-30 10:26:06 - train: epoch 0171, iter [00880, 01251], lr: 0.000850, loss: 0.4025
2022-09-30 10:26:23 - train: epoch 0171, iter [00890, 01251], lr: 0.000850, loss: 0.4475
2022-09-30 10:26:41 - train: epoch 0171, iter [00900, 01251], lr: 0.000850, loss: 0.4138
2022-09-30 10:26:59 - train: epoch 0171, iter [00910, 01251], lr: 0.000850, loss: 0.4233
2022-09-30 10:27:16 - train: epoch 0171, iter [00920, 01251], lr: 0.000850, loss: 0.4129
2022-09-30 10:27:34 - train: epoch 0171, iter [00930, 01251], lr: 0.000850, loss: 0.3833
2022-09-30 10:27:52 - train: epoch 0171, iter [00940, 01251], lr: 0.000850, loss: 0.4060
2022-09-30 10:28:10 - train: epoch 0171, iter [00950, 01251], lr: 0.000850, loss: 0.4090
2022-09-30 10:28:28 - train: epoch 0171, iter [00960, 01251], lr: 0.000850, loss: 0.4198
2022-09-30 10:28:45 - train: epoch 0171, iter [00970, 01251], lr: 0.000850, loss: 0.4099
2022-09-30 10:29:03 - train: epoch 0171, iter [00980, 01251], lr: 0.000850, loss: 0.4090
2022-09-30 10:29:21 - train: epoch 0171, iter [00990, 01251], lr: 0.000850, loss: 0.3962
2022-09-30 10:29:39 - train: epoch 0171, iter [01000, 01251], lr: 0.000850, loss: 0.4103
2022-09-30 10:29:56 - train: epoch 0171, iter [01010, 01251], lr: 0.000850, loss: 0.4249
2022-09-30 10:30:14 - train: epoch 0171, iter [01020, 01251], lr: 0.000850, loss: 0.4084
2022-09-30 10:30:32 - train: epoch 0171, iter [01030, 01251], lr: 0.000850, loss: 0.4023
2022-09-30 10:30:50 - train: epoch 0171, iter [01040, 01251], lr: 0.000850, loss: 0.4159
2022-09-30 10:31:08 - train: epoch 0171, iter [01050, 01251], lr: 0.000850, loss: 0.4216
2022-09-30 10:31:25 - train: epoch 0171, iter [01060, 01251], lr: 0.000850, loss: 0.4375
2022-09-30 10:31:43 - train: epoch 0171, iter [01070, 01251], lr: 0.000850, loss: 0.4321
2022-09-30 10:32:01 - train: epoch 0171, iter [01080, 01251], lr: 0.000849, loss: 0.4101
2022-09-30 10:32:18 - train: epoch 0171, iter [01090, 01251], lr: 0.000849, loss: 0.3981
2022-09-30 10:32:36 - train: epoch 0171, iter [01100, 01251], lr: 0.000849, loss: 0.4107
2022-09-30 10:32:54 - train: epoch 0171, iter [01110, 01251], lr: 0.000849, loss: 0.4166
2022-09-30 10:33:12 - train: epoch 0171, iter [01120, 01251], lr: 0.000849, loss: 0.4041
2022-09-30 10:33:29 - train: epoch 0171, iter [01130, 01251], lr: 0.000849, loss: 0.4035
2022-09-30 10:33:47 - train: epoch 0171, iter [01140, 01251], lr: 0.000849, loss: 0.3961
2022-09-30 10:34:05 - train: epoch 0171, iter [01150, 01251], lr: 0.000849, loss: 0.3960
2022-09-30 10:34:23 - train: epoch 0171, iter [01160, 01251], lr: 0.000849, loss: 0.4289
2022-09-30 10:34:41 - train: epoch 0171, iter [01170, 01251], lr: 0.000849, loss: 0.4179
2022-09-30 10:34:58 - train: epoch 0171, iter [01180, 01251], lr: 0.000849, loss: 0.4031
2022-09-30 10:35:16 - train: epoch 0171, iter [01190, 01251], lr: 0.000849, loss: 0.4042
2022-09-30 10:35:34 - train: epoch 0171, iter [01200, 01251], lr: 0.000849, loss: 0.3936
2022-09-30 10:35:51 - train: epoch 0171, iter [01210, 01251], lr: 0.000849, loss: 0.4341
2022-09-30 10:36:09 - train: epoch 0171, iter [01220, 01251], lr: 0.000849, loss: 0.4289
2022-09-30 10:36:27 - train: epoch 0171, iter [01230, 01251], lr: 0.000849, loss: 0.4215
2022-09-30 10:36:45 - train: epoch 0171, iter [01240, 01251], lr: 0.000849, loss: 0.4068
2022-09-30 10:37:02 - train: epoch 0171, iter [01250, 01251], lr: 0.000849, loss: 0.3831
2022-09-30 10:37:06 - train: epoch 171, train_loss: 0.4092
2022-09-30 10:37:07 - until epoch: 171, best_loss: 0.4091
2022-09-30 10:37:07 - epoch 172 lr: 0.000849
2022-09-30 10:37:32 - train: epoch 0172, iter [00010, 01251], lr: 0.000849, loss: 0.4142
2022-09-30 10:37:50 - train: epoch 0172, iter [00020, 01251], lr: 0.000849, loss: 0.3916
2022-09-30 10:38:08 - train: epoch 0172, iter [00030, 01251], lr: 0.000849, loss: 0.3984
2022-09-30 10:38:26 - train: epoch 0172, iter [00040, 01251], lr: 0.000849, loss: 0.4256
2022-09-30 10:38:43 - train: epoch 0172, iter [00050, 01251], lr: 0.000849, loss: 0.4136
2022-09-30 10:39:01 - train: epoch 0172, iter [00060, 01251], lr: 0.000849, loss: 0.4037
2022-09-30 10:39:19 - train: epoch 0172, iter [00070, 01251], lr: 0.000849, loss: 0.3872
2022-09-30 10:39:36 - train: epoch 0172, iter [00080, 01251], lr: 0.000849, loss: 0.3826
2022-09-30 10:39:54 - train: epoch 0172, iter [00090, 01251], lr: 0.000848, loss: 0.4143
2022-09-30 10:40:12 - train: epoch 0172, iter [00100, 01251], lr: 0.000848, loss: 0.4090
2022-09-30 10:40:30 - train: epoch 0172, iter [00110, 01251], lr: 0.000848, loss: 0.4040
2022-09-30 10:40:47 - train: epoch 0172, iter [00120, 01251], lr: 0.000848, loss: 0.3948
2022-09-30 10:41:05 - train: epoch 0172, iter [00130, 01251], lr: 0.000848, loss: 0.3961
2022-09-30 10:41:23 - train: epoch 0172, iter [00140, 01251], lr: 0.000848, loss: 0.3989
2022-09-30 10:41:41 - train: epoch 0172, iter [00150, 01251], lr: 0.000848, loss: 0.4003
2022-09-30 10:41:59 - train: epoch 0172, iter [00160, 01251], lr: 0.000848, loss: 0.3798
2022-09-30 10:42:17 - train: epoch 0172, iter [00170, 01251], lr: 0.000848, loss: 0.3864
2022-09-30 10:42:34 - train: epoch 0172, iter [00180, 01251], lr: 0.000848, loss: 0.4105
2022-09-30 10:42:52 - train: epoch 0172, iter [00190, 01251], lr: 0.000848, loss: 0.4057
2022-09-30 10:43:10 - train: epoch 0172, iter [00200, 01251], lr: 0.000848, loss: 0.4054
2022-09-30 10:43:28 - train: epoch 0172, iter [00210, 01251], lr: 0.000848, loss: 0.3965
2022-09-30 10:43:46 - train: epoch 0172, iter [00220, 01251], lr: 0.000848, loss: 0.4114
2022-09-30 10:44:03 - train: epoch 0172, iter [00230, 01251], lr: 0.000848, loss: 0.4129
2022-09-30 10:44:21 - train: epoch 0172, iter [00240, 01251], lr: 0.000848, loss: 0.3963
2022-09-30 10:44:39 - train: epoch 0172, iter [00250, 01251], lr: 0.000848, loss: 0.4044
2022-09-30 10:44:56 - train: epoch 0172, iter [00260, 01251], lr: 0.000848, loss: 0.4032
2022-09-30 10:45:14 - train: epoch 0172, iter [00270, 01251], lr: 0.000848, loss: 0.4078
2022-09-30 10:45:32 - train: epoch 0172, iter [00280, 01251], lr: 0.000848, loss: 0.4074
2022-09-30 10:45:50 - train: epoch 0172, iter [00290, 01251], lr: 0.000848, loss: 0.3958
2022-09-30 10:46:08 - train: epoch 0172, iter [00300, 01251], lr: 0.000848, loss: 0.4388
2022-09-30 10:46:26 - train: epoch 0172, iter [00310, 01251], lr: 0.000848, loss: 0.4217
2022-09-30 10:46:43 - train: epoch 0172, iter [00320, 01251], lr: 0.000848, loss: 0.4122
2022-09-30 10:47:01 - train: epoch 0172, iter [00330, 01251], lr: 0.000848, loss: 0.3994
2022-09-30 10:47:19 - train: epoch 0172, iter [00340, 01251], lr: 0.000848, loss: 0.3963
2022-09-30 10:47:37 - train: epoch 0172, iter [00350, 01251], lr: 0.000847, loss: 0.4210
2022-09-30 10:47:54 - train: epoch 0172, iter [00360, 01251], lr: 0.000847, loss: 0.3940
2022-09-30 10:48:12 - train: epoch 0172, iter [00370, 01251], lr: 0.000847, loss: 0.3902
2022-09-30 10:48:30 - train: epoch 0172, iter [00380, 01251], lr: 0.000847, loss: 0.4051
2022-09-30 10:48:48 - train: epoch 0172, iter [00390, 01251], lr: 0.000847, loss: 0.4063
2022-09-30 10:49:05 - train: epoch 0172, iter [00400, 01251], lr: 0.000847, loss: 0.4137
2022-09-30 10:49:23 - train: epoch 0172, iter [00410, 01251], lr: 0.000847, loss: 0.4276
2022-09-30 10:49:41 - train: epoch 0172, iter [00420, 01251], lr: 0.000847, loss: 0.4051
2022-09-30 10:49:59 - train: epoch 0172, iter [00430, 01251], lr: 0.000847, loss: 0.4071
2022-09-30 10:50:16 - train: epoch 0172, iter [00440, 01251], lr: 0.000847, loss: 0.4126
2022-09-30 10:50:34 - train: epoch 0172, iter [00450, 01251], lr: 0.000847, loss: 0.4190
2022-09-30 10:50:52 - train: epoch 0172, iter [00460, 01251], lr: 0.000847, loss: 0.4048
2022-09-30 10:51:10 - train: epoch 0172, iter [00470, 01251], lr: 0.000847, loss: 0.4123
2022-09-30 10:51:28 - train: epoch 0172, iter [00480, 01251], lr: 0.000847, loss: 0.4040
2022-09-30 10:51:45 - train: epoch 0172, iter [00490, 01251], lr: 0.000847, loss: 0.4335
2022-09-30 10:52:03 - train: epoch 0172, iter [00500, 01251], lr: 0.000847, loss: 0.4127
2022-09-30 10:52:21 - train: epoch 0172, iter [00510, 01251], lr: 0.000847, loss: 0.4348
2022-09-30 10:52:38 - train: epoch 0172, iter [00520, 01251], lr: 0.000847, loss: 0.4247
2022-09-30 10:52:56 - train: epoch 0172, iter [00530, 01251], lr: 0.000847, loss: 0.4324
2022-09-30 10:53:14 - train: epoch 0172, iter [00540, 01251], lr: 0.000847, loss: 0.4079
2022-09-30 10:53:32 - train: epoch 0172, iter [00550, 01251], lr: 0.000847, loss: 0.4257
2022-09-30 10:53:49 - train: epoch 0172, iter [00560, 01251], lr: 0.000847, loss: 0.4095
2022-09-30 10:54:07 - train: epoch 0172, iter [00570, 01251], lr: 0.000847, loss: 0.4231
2022-09-30 10:54:25 - train: epoch 0172, iter [00580, 01251], lr: 0.000847, loss: 0.4214
2022-09-30 10:54:43 - train: epoch 0172, iter [00590, 01251], lr: 0.000847, loss: 0.4136
2022-09-30 10:55:00 - train: epoch 0172, iter [00600, 01251], lr: 0.000847, loss: 0.3919
2022-09-30 10:55:18 - train: epoch 0172, iter [00610, 01251], lr: 0.000846, loss: 0.4115
2022-09-30 10:55:36 - train: epoch 0172, iter [00620, 01251], lr: 0.000846, loss: 0.4155
2022-09-30 10:55:54 - train: epoch 0172, iter [00630, 01251], lr: 0.000846, loss: 0.4159
2022-09-30 10:56:12 - train: epoch 0172, iter [00640, 01251], lr: 0.000846, loss: 0.3979
2022-09-30 10:56:30 - train: epoch 0172, iter [00650, 01251], lr: 0.000846, loss: 0.4173
2022-09-30 10:56:48 - train: epoch 0172, iter [00660, 01251], lr: 0.000846, loss: 0.3922
2022-09-30 10:57:05 - train: epoch 0172, iter [00670, 01251], lr: 0.000846, loss: 0.3986
2022-09-30 10:57:23 - train: epoch 0172, iter [00680, 01251], lr: 0.000846, loss: 0.4010
2022-09-30 10:57:41 - train: epoch 0172, iter [00690, 01251], lr: 0.000846, loss: 0.3934
2022-09-30 10:57:59 - train: epoch 0172, iter [00700, 01251], lr: 0.000846, loss: 0.4021
2022-09-30 10:58:16 - train: epoch 0172, iter [00710, 01251], lr: 0.000846, loss: 0.4150
2022-09-30 10:58:34 - train: epoch 0172, iter [00720, 01251], lr: 0.000846, loss: 0.4338
2022-09-30 10:58:52 - train: epoch 0172, iter [00730, 01251], lr: 0.000846, loss: 0.4009
2022-09-30 10:59:09 - train: epoch 0172, iter [00740, 01251], lr: 0.000846, loss: 0.4023
2022-09-30 10:59:27 - train: epoch 0172, iter [00750, 01251], lr: 0.000846, loss: 0.4122
2022-09-30 10:59:45 - train: epoch 0172, iter [00760, 01251], lr: 0.000846, loss: 0.4191
2022-09-30 11:00:03 - train: epoch 0172, iter [00770, 01251], lr: 0.000846, loss: 0.4072
2022-09-30 11:00:21 - train: epoch 0172, iter [00780, 01251], lr: 0.000846, loss: 0.4138
2022-09-30 11:00:39 - train: epoch 0172, iter [00790, 01251], lr: 0.000846, loss: 0.4015
2022-09-30 11:00:56 - train: epoch 0172, iter [00800, 01251], lr: 0.000846, loss: 0.4104
2022-09-30 11:01:14 - train: epoch 0172, iter [00810, 01251], lr: 0.000846, loss: 0.3944
2022-09-30 11:01:32 - train: epoch 0172, iter [00820, 01251], lr: 0.000846, loss: 0.4019
2022-09-30 11:01:50 - train: epoch 0172, iter [00830, 01251], lr: 0.000846, loss: 0.4236
2022-09-30 11:02:08 - train: epoch 0172, iter [00840, 01251], lr: 0.000846, loss: 0.3931
2022-09-30 11:02:25 - train: epoch 0172, iter [00850, 01251], lr: 0.000846, loss: 0.4106
2022-09-30 11:02:43 - train: epoch 0172, iter [00860, 01251], lr: 0.000846, loss: 0.4114
2022-09-30 11:03:01 - train: epoch 0172, iter [00870, 01251], lr: 0.000845, loss: 0.3970
2022-09-30 11:03:19 - train: epoch 0172, iter [00880, 01251], lr: 0.000845, loss: 0.4164
2022-09-30 11:03:37 - train: epoch 0172, iter [00890, 01251], lr: 0.000845, loss: 0.4080
2022-09-30 11:03:55 - train: epoch 0172, iter [00900, 01251], lr: 0.000845, loss: 0.4096
2022-09-30 11:04:13 - train: epoch 0172, iter [00910, 01251], lr: 0.000845, loss: 0.4132
2022-09-30 11:04:30 - train: epoch 0172, iter [00920, 01251], lr: 0.000845, loss: 0.3926
2022-09-30 11:04:48 - train: epoch 0172, iter [00930, 01251], lr: 0.000845, loss: 0.4283
2022-09-30 11:05:06 - train: epoch 0172, iter [00940, 01251], lr: 0.000845, loss: 0.3964
2022-09-30 11:05:24 - train: epoch 0172, iter [00950, 01251], lr: 0.000845, loss: 0.4130
2022-09-30 11:05:42 - train: epoch 0172, iter [00960, 01251], lr: 0.000845, loss: 0.4040
2022-09-30 11:06:00 - train: epoch 0172, iter [00970, 01251], lr: 0.000845, loss: 0.4000
2022-09-30 11:06:17 - train: epoch 0172, iter [00980, 01251], lr: 0.000845, loss: 0.3992
2022-09-30 11:06:35 - train: epoch 0172, iter [00990, 01251], lr: 0.000845, loss: 0.4093
2022-09-30 11:06:53 - train: epoch 0172, iter [01000, 01251], lr: 0.000845, loss: 0.4227
2022-09-30 11:07:11 - train: epoch 0172, iter [01010, 01251], lr: 0.000845, loss: 0.4258
2022-09-30 11:07:28 - train: epoch 0172, iter [01020, 01251], lr: 0.000845, loss: 0.4247
2022-09-30 11:07:46 - train: epoch 0172, iter [01030, 01251], lr: 0.000845, loss: 0.3861
2022-09-30 11:08:04 - train: epoch 0172, iter [01040, 01251], lr: 0.000845, loss: 0.4057
2022-09-30 11:08:22 - train: epoch 0172, iter [01050, 01251], lr: 0.000845, loss: 0.3991
2022-09-30 11:08:40 - train: epoch 0172, iter [01060, 01251], lr: 0.000845, loss: 0.3975
2022-09-30 11:08:57 - train: epoch 0172, iter [01070, 01251], lr: 0.000845, loss: 0.3941
2022-09-30 11:09:15 - train: epoch 0172, iter [01080, 01251], lr: 0.000845, loss: 0.4050
2022-09-30 11:09:33 - train: epoch 0172, iter [01090, 01251], lr: 0.000845, loss: 0.4056
2022-09-30 11:09:50 - train: epoch 0172, iter [01100, 01251], lr: 0.000845, loss: 0.4095
2022-09-30 11:10:08 - train: epoch 0172, iter [01110, 01251], lr: 0.000845, loss: 0.3883
2022-09-30 11:10:26 - train: epoch 0172, iter [01120, 01251], lr: 0.000845, loss: 0.4232
2022-09-30 11:10:44 - train: epoch 0172, iter [01130, 01251], lr: 0.000845, loss: 0.4132
2022-09-30 11:11:01 - train: epoch 0172, iter [01140, 01251], lr: 0.000844, loss: 0.4051
2022-09-30 11:11:19 - train: epoch 0172, iter [01150, 01251], lr: 0.000844, loss: 0.4095
2022-09-30 11:11:37 - train: epoch 0172, iter [01160, 01251], lr: 0.000844, loss: 0.3959
2022-09-30 11:11:55 - train: epoch 0172, iter [01170, 01251], lr: 0.000844, loss: 0.3967
2022-09-30 11:12:13 - train: epoch 0172, iter [01180, 01251], lr: 0.000844, loss: 0.3960
2022-09-30 11:12:30 - train: epoch 0172, iter [01190, 01251], lr: 0.000844, loss: 0.3759
2022-09-30 11:12:48 - train: epoch 0172, iter [01200, 01251], lr: 0.000844, loss: 0.4139
2022-09-30 11:13:06 - train: epoch 0172, iter [01210, 01251], lr: 0.000844, loss: 0.3995
2022-09-30 11:13:24 - train: epoch 0172, iter [01220, 01251], lr: 0.000844, loss: 0.4285
2022-09-30 11:13:42 - train: epoch 0172, iter [01230, 01251], lr: 0.000844, loss: 0.4026
2022-09-30 11:13:59 - train: epoch 0172, iter [01240, 01251], lr: 0.000844, loss: 0.3884
2022-09-30 11:14:17 - train: epoch 0172, iter [01250, 01251], lr: 0.000844, loss: 0.4044
2022-09-30 11:14:20 - train: epoch 172, train_loss: 0.4090
2022-09-30 11:14:23 - until epoch: 172, best_loss: 0.4090
2022-09-30 11:14:23 - epoch 173 lr: 0.000844
2022-09-30 11:14:47 - train: epoch 0173, iter [00010, 01251], lr: 0.000844, loss: 0.4084
2022-09-30 11:15:05 - train: epoch 0173, iter [00020, 01251], lr: 0.000844, loss: 0.4108
2022-09-30 11:15:23 - train: epoch 0173, iter [00030, 01251], lr: 0.000844, loss: 0.3828
2022-09-30 11:15:41 - train: epoch 0173, iter [00040, 01251], lr: 0.000844, loss: 0.4046
2022-09-30 11:15:58 - train: epoch 0173, iter [00050, 01251], lr: 0.000844, loss: 0.3978
2022-09-30 11:16:16 - train: epoch 0173, iter [00060, 01251], lr: 0.000844, loss: 0.3922
2022-09-30 11:16:34 - train: epoch 0173, iter [00070, 01251], lr: 0.000844, loss: 0.4053
2022-09-30 11:16:52 - train: epoch 0173, iter [00080, 01251], lr: 0.000844, loss: 0.3924
2022-09-30 11:17:10 - train: epoch 0173, iter [00090, 01251], lr: 0.000844, loss: 0.4009
2022-09-30 11:17:27 - train: epoch 0173, iter [00100, 01251], lr: 0.000844, loss: 0.4035
2022-09-30 11:17:45 - train: epoch 0173, iter [00110, 01251], lr: 0.000844, loss: 0.4029
2022-09-30 11:18:03 - train: epoch 0173, iter [00120, 01251], lr: 0.000844, loss: 0.4263
2022-09-30 11:18:21 - train: epoch 0173, iter [00130, 01251], lr: 0.000844, loss: 0.4021
2022-09-30 11:18:39 - train: epoch 0173, iter [00140, 01251], lr: 0.000844, loss: 0.4250
2022-09-30 11:18:57 - train: epoch 0173, iter [00150, 01251], lr: 0.000843, loss: 0.4252
2022-09-30 11:19:14 - train: epoch 0173, iter [00160, 01251], lr: 0.000843, loss: 0.4054
2022-09-30 11:19:32 - train: epoch 0173, iter [00170, 01251], lr: 0.000843, loss: 0.3963
2022-09-30 11:19:50 - train: epoch 0173, iter [00180, 01251], lr: 0.000843, loss: 0.4095
2022-09-30 11:20:08 - train: epoch 0173, iter [00190, 01251], lr: 0.000843, loss: 0.4188
2022-09-30 11:20:26 - train: epoch 0173, iter [00200, 01251], lr: 0.000843, loss: 0.4051
2022-09-30 11:20:43 - train: epoch 0173, iter [00210, 01251], lr: 0.000843, loss: 0.4064
2022-09-30 11:21:01 - train: epoch 0173, iter [00220, 01251], lr: 0.000843, loss: 0.3993
2022-09-30 11:21:19 - train: epoch 0173, iter [00230, 01251], lr: 0.000843, loss: 0.3926
2022-09-30 11:21:37 - train: epoch 0173, iter [00240, 01251], lr: 0.000843, loss: 0.4178
2022-09-30 11:21:54 - train: epoch 0173, iter [00250, 01251], lr: 0.000843, loss: 0.4278
2022-09-30 11:22:12 - train: epoch 0173, iter [00260, 01251], lr: 0.000843, loss: 0.4198
2022-09-30 11:22:30 - train: epoch 0173, iter [00270, 01251], lr: 0.000843, loss: 0.4281
2022-09-30 11:22:48 - train: epoch 0173, iter [00280, 01251], lr: 0.000843, loss: 0.4007
2022-09-30 11:23:05 - train: epoch 0173, iter [00290, 01251], lr: 0.000843, loss: 0.4267
2022-09-30 11:23:23 - train: epoch 0173, iter [00300, 01251], lr: 0.000843, loss: 0.4062
2022-09-30 11:23:41 - train: epoch 0173, iter [00310, 01251], lr: 0.000843, loss: 0.4079
2022-09-30 11:23:58 - train: epoch 0173, iter [00320, 01251], lr: 0.000843, loss: 0.3947
2022-09-30 11:24:16 - train: epoch 0173, iter [00330, 01251], lr: 0.000843, loss: 0.3922
2022-09-30 11:24:34 - train: epoch 0173, iter [00340, 01251], lr: 0.000843, loss: 0.4081
2022-09-30 11:24:52 - train: epoch 0173, iter [00350, 01251], lr: 0.000843, loss: 0.4103
2022-09-30 11:25:09 - train: epoch 0173, iter [00360, 01251], lr: 0.000843, loss: 0.4251
2022-09-30 11:25:27 - train: epoch 0173, iter [00370, 01251], lr: 0.000843, loss: 0.4165
2022-09-30 11:25:45 - train: epoch 0173, iter [00380, 01251], lr: 0.000843, loss: 0.4106
2022-09-30 11:26:02 - train: epoch 0173, iter [00390, 01251], lr: 0.000843, loss: 0.4154
2022-09-30 11:26:20 - train: epoch 0173, iter [00400, 01251], lr: 0.000843, loss: 0.4155
2022-09-30 11:26:38 - train: epoch 0173, iter [00410, 01251], lr: 0.000842, loss: 0.4067
2022-09-30 11:26:56 - train: epoch 0173, iter [00420, 01251], lr: 0.000842, loss: 0.3953
2022-09-30 11:27:13 - train: epoch 0173, iter [00430, 01251], lr: 0.000842, loss: 0.4001
2022-09-30 11:27:31 - train: epoch 0173, iter [00440, 01251], lr: 0.000842, loss: 0.4227
2022-09-30 11:27:49 - train: epoch 0173, iter [00450, 01251], lr: 0.000842, loss: 0.4165
2022-09-30 11:28:07 - train: epoch 0173, iter [00460, 01251], lr: 0.000842, loss: 0.4194
2022-09-30 11:28:25 - train: epoch 0173, iter [00470, 01251], lr: 0.000842, loss: 0.4095
2022-09-30 11:28:43 - train: epoch 0173, iter [00480, 01251], lr: 0.000842, loss: 0.4109
2022-09-30 11:29:01 - train: epoch 0173, iter [00490, 01251], lr: 0.000842, loss: 0.3981
2022-09-30 11:29:19 - train: epoch 0173, iter [00500, 01251], lr: 0.000842, loss: 0.4073
2022-09-30 11:29:37 - train: epoch 0173, iter [00510, 01251], lr: 0.000842, loss: 0.4127
2022-09-30 11:29:54 - train: epoch 0173, iter [00520, 01251], lr: 0.000842, loss: 0.4071
2022-09-30 11:30:12 - train: epoch 0173, iter [00530, 01251], lr: 0.000842, loss: 0.3971
2022-09-30 11:30:30 - train: epoch 0173, iter [00540, 01251], lr: 0.000842, loss: 0.4130
2022-09-30 11:30:48 - train: epoch 0173, iter [00550, 01251], lr: 0.000842, loss: 0.3964
2022-09-30 11:31:05 - train: epoch 0173, iter [00560, 01251], lr: 0.000842, loss: 0.3973
2022-09-30 11:31:23 - train: epoch 0173, iter [00570, 01251], lr: 0.000842, loss: 0.4086
2022-09-30 11:31:41 - train: epoch 0173, iter [00580, 01251], lr: 0.000842, loss: 0.4079
2022-09-30 11:31:59 - train: epoch 0173, iter [00590, 01251], lr: 0.000842, loss: 0.4028
2022-09-30 11:32:17 - train: epoch 0173, iter [00600, 01251], lr: 0.000842, loss: 0.4128
2022-09-30 11:32:35 - train: epoch 0173, iter [00610, 01251], lr: 0.000842, loss: 0.4086
2022-09-30 11:32:52 - train: epoch 0173, iter [00620, 01251], lr: 0.000842, loss: 0.4145
2022-09-30 11:33:10 - train: epoch 0173, iter [00630, 01251], lr: 0.000842, loss: 0.4057
2022-09-30 11:33:28 - train: epoch 0173, iter [00640, 01251], lr: 0.000842, loss: 0.4136
2022-09-30 11:33:46 - train: epoch 0173, iter [00650, 01251], lr: 0.000842, loss: 0.4110
2022-09-30 11:34:04 - train: epoch 0173, iter [00660, 01251], lr: 0.000842, loss: 0.4165
2022-09-30 11:34:22 - train: epoch 0173, iter [00670, 01251], lr: 0.000841, loss: 0.3947
2022-09-30 11:34:39 - train: epoch 0173, iter [00680, 01251], lr: 0.000841, loss: 0.4115
2022-09-30 11:34:58 - train: epoch 0173, iter [00690, 01251], lr: 0.000841, loss: 0.4058
2022-09-30 11:35:16 - train: epoch 0173, iter [00700, 01251], lr: 0.000841, loss: 0.4041
2022-09-30 11:35:33 - train: epoch 0173, iter [00710, 01251], lr: 0.000841, loss: 0.4288
2022-09-30 11:35:51 - train: epoch 0173, iter [00720, 01251], lr: 0.000841, loss: 0.4080
2022-09-30 11:36:09 - train: epoch 0173, iter [00730, 01251], lr: 0.000841, loss: 0.4183
2022-09-30 11:36:27 - train: epoch 0173, iter [00740, 01251], lr: 0.000841, loss: 0.3905
2022-09-30 11:36:45 - train: epoch 0173, iter [00750, 01251], lr: 0.000841, loss: 0.4088
2022-09-30 11:37:02 - train: epoch 0173, iter [00760, 01251], lr: 0.000841, loss: 0.4014
2022-09-30 11:37:20 - train: epoch 0173, iter [00770, 01251], lr: 0.000841, loss: 0.4105
2022-09-30 11:37:38 - train: epoch 0173, iter [00780, 01251], lr: 0.000841, loss: 0.4046
2022-09-30 11:37:56 - train: epoch 0173, iter [00790, 01251], lr: 0.000841, loss: 0.4154
2022-09-30 11:38:13 - train: epoch 0173, iter [00800, 01251], lr: 0.000841, loss: 0.4051
2022-09-30 11:38:31 - train: epoch 0173, iter [00810, 01251], lr: 0.000841, loss: 0.4142
2022-09-30 11:38:49 - train: epoch 0173, iter [00820, 01251], lr: 0.000841, loss: 0.4008
2022-09-30 11:39:06 - train: epoch 0173, iter [00830, 01251], lr: 0.000841, loss: 0.3939
2022-09-30 11:39:24 - train: epoch 0173, iter [00840, 01251], lr: 0.000841, loss: 0.4073
2022-09-30 11:39:42 - train: epoch 0173, iter [00850, 01251], lr: 0.000841, loss: 0.4114
2022-09-30 11:40:00 - train: epoch 0173, iter [00860, 01251], lr: 0.000841, loss: 0.4108
2022-09-30 11:40:18 - train: epoch 0173, iter [00870, 01251], lr: 0.000841, loss: 0.4047
2022-09-30 11:40:36 - train: epoch 0173, iter [00880, 01251], lr: 0.000841, loss: 0.4287
2022-09-30 11:40:53 - train: epoch 0173, iter [00890, 01251], lr: 0.000841, loss: 0.4094
2022-09-30 11:41:11 - train: epoch 0173, iter [00900, 01251], lr: 0.000841, loss: 0.4135
2022-09-30 11:41:29 - train: epoch 0173, iter [00910, 01251], lr: 0.000841, loss: 0.4051
2022-09-30 11:41:46 - train: epoch 0173, iter [00920, 01251], lr: 0.000841, loss: 0.4162
2022-09-30 11:42:04 - train: epoch 0173, iter [00930, 01251], lr: 0.000840, loss: 0.4226
2022-09-30 11:42:22 - train: epoch 0173, iter [00940, 01251], lr: 0.000840, loss: 0.4014
2022-09-30 11:42:40 - train: epoch 0173, iter [00950, 01251], lr: 0.000840, loss: 0.3954
2022-09-30 11:42:58 - train: epoch 0173, iter [00960, 01251], lr: 0.000840, loss: 0.4113
2022-09-30 11:43:15 - train: epoch 0173, iter [00970, 01251], lr: 0.000840, loss: 0.4220
2022-09-30 11:43:33 - train: epoch 0173, iter [00980, 01251], lr: 0.000840, loss: 0.3877
2022-09-30 11:43:51 - train: epoch 0173, iter [00990, 01251], lr: 0.000840, loss: 0.4240
2022-09-30 11:44:09 - train: epoch 0173, iter [01000, 01251], lr: 0.000840, loss: 0.4223
2022-09-30 11:44:27 - train: epoch 0173, iter [01010, 01251], lr: 0.000840, loss: 0.4032
2022-09-30 11:44:44 - train: epoch 0173, iter [01020, 01251], lr: 0.000840, loss: 0.4017
2022-09-30 11:45:02 - train: epoch 0173, iter [01030, 01251], lr: 0.000840, loss: 0.3958
2022-09-30 11:45:20 - train: epoch 0173, iter [01040, 01251], lr: 0.000840, loss: 0.4084
2022-09-30 11:45:37 - train: epoch 0173, iter [01050, 01251], lr: 0.000840, loss: 0.4027
2022-09-30 11:45:55 - train: epoch 0173, iter [01060, 01251], lr: 0.000840, loss: 0.4052
2022-09-30 11:46:13 - train: epoch 0173, iter [01070, 01251], lr: 0.000840, loss: 0.4447
2022-09-30 11:46:31 - train: epoch 0173, iter [01080, 01251], lr: 0.000840, loss: 0.4129
2022-09-30 11:46:48 - train: epoch 0173, iter [01090, 01251], lr: 0.000840, loss: 0.4148
2022-09-30 11:47:06 - train: epoch 0173, iter [01100, 01251], lr: 0.000840, loss: 0.3918
2022-09-30 11:47:24 - train: epoch 0173, iter [01110, 01251], lr: 0.000840, loss: 0.4302
2022-09-30 11:47:42 - train: epoch 0173, iter [01120, 01251], lr: 0.000840, loss: 0.4116
2022-09-30 11:48:00 - train: epoch 0173, iter [01130, 01251], lr: 0.000840, loss: 0.4147
2022-09-30 11:48:17 - train: epoch 0173, iter [01140, 01251], lr: 0.000840, loss: 0.4003
2022-09-30 11:48:35 - train: epoch 0173, iter [01150, 01251], lr: 0.000840, loss: 0.3965
2022-09-30 11:48:53 - train: epoch 0173, iter [01160, 01251], lr: 0.000840, loss: 0.3922
2022-09-30 11:49:11 - train: epoch 0173, iter [01170, 01251], lr: 0.000840, loss: 0.4168
2022-09-30 11:49:29 - train: epoch 0173, iter [01180, 01251], lr: 0.000840, loss: 0.4094
2022-09-30 11:49:47 - train: epoch 0173, iter [01190, 01251], lr: 0.000839, loss: 0.4163
2022-09-30 11:50:04 - train: epoch 0173, iter [01200, 01251], lr: 0.000839, loss: 0.3928
2022-09-30 11:50:22 - train: epoch 0173, iter [01210, 01251], lr: 0.000839, loss: 0.4103
2022-09-30 11:50:40 - train: epoch 0173, iter [01220, 01251], lr: 0.000839, loss: 0.4124
2022-09-30 11:50:58 - train: epoch 0173, iter [01230, 01251], lr: 0.000839, loss: 0.4044
2022-09-30 11:51:16 - train: epoch 0173, iter [01240, 01251], lr: 0.000839, loss: 0.4340
2022-09-30 11:51:33 - train: epoch 0173, iter [01250, 01251], lr: 0.000839, loss: 0.4118
2022-09-30 11:51:36 - train: epoch 173, train_loss: 0.4089
2022-09-30 11:51:39 - until epoch: 173, best_loss: 0.4089
2022-09-30 11:51:39 - epoch 174 lr: 0.000839
2022-09-30 11:52:04 - train: epoch 0174, iter [00010, 01251], lr: 0.000839, loss: 0.4025
2022-09-30 11:52:22 - train: epoch 0174, iter [00020, 01251], lr: 0.000839, loss: 0.4136
2022-09-30 11:52:40 - train: epoch 0174, iter [00030, 01251], lr: 0.000839, loss: 0.4077
2022-09-30 11:52:57 - train: epoch 0174, iter [00040, 01251], lr: 0.000839, loss: 0.4033
2022-09-30 11:53:15 - train: epoch 0174, iter [00050, 01251], lr: 0.000839, loss: 0.4247
2022-09-30 11:53:33 - train: epoch 0174, iter [00060, 01251], lr: 0.000839, loss: 0.4208
2022-09-30 11:53:50 - train: epoch 0174, iter [00070, 01251], lr: 0.000839, loss: 0.4433
2022-09-30 11:54:08 - train: epoch 0174, iter [00080, 01251], lr: 0.000839, loss: 0.4062
2022-09-30 11:54:26 - train: epoch 0174, iter [00090, 01251], lr: 0.000839, loss: 0.4029
2022-09-30 11:54:43 - train: epoch 0174, iter [00100, 01251], lr: 0.000839, loss: 0.3965
2022-09-30 11:55:01 - train: epoch 0174, iter [00110, 01251], lr: 0.000839, loss: 0.4144
2022-09-30 11:55:19 - train: epoch 0174, iter [00120, 01251], lr: 0.000839, loss: 0.4166
2022-09-30 11:55:37 - train: epoch 0174, iter [00130, 01251], lr: 0.000839, loss: 0.4212
2022-09-30 11:55:55 - train: epoch 0174, iter [00140, 01251], lr: 0.000839, loss: 0.4206
2022-09-30 11:56:12 - train: epoch 0174, iter [00150, 01251], lr: 0.000839, loss: 0.4188
2022-09-30 11:56:30 - train: epoch 0174, iter [00160, 01251], lr: 0.000839, loss: 0.4140
2022-09-30 11:56:48 - train: epoch 0174, iter [00170, 01251], lr: 0.000839, loss: 0.4038
2022-09-30 11:57:06 - train: epoch 0174, iter [00180, 01251], lr: 0.000839, loss: 0.4122
2022-09-30 11:57:23 - train: epoch 0174, iter [00190, 01251], lr: 0.000839, loss: 0.3925
2022-09-30 11:57:41 - train: epoch 0174, iter [00200, 01251], lr: 0.000838, loss: 0.4101
2022-09-30 11:57:59 - train: epoch 0174, iter [00210, 01251], lr: 0.000838, loss: 0.4176
2022-09-30 11:58:17 - train: epoch 0174, iter [00220, 01251], lr: 0.000838, loss: 0.4039
2022-09-30 11:58:34 - train: epoch 0174, iter [00230, 01251], lr: 0.000838, loss: 0.4028
2022-09-30 11:58:52 - train: epoch 0174, iter [00240, 01251], lr: 0.000838, loss: 0.4091
2022-09-30 11:59:10 - train: epoch 0174, iter [00250, 01251], lr: 0.000838, loss: 0.3992
2022-09-30 11:59:28 - train: epoch 0174, iter [00260, 01251], lr: 0.000838, loss: 0.4250
2022-09-30 11:59:46 - train: epoch 0174, iter [00270, 01251], lr: 0.000838, loss: 0.4028
2022-09-30 12:00:03 - train: epoch 0174, iter [00280, 01251], lr: 0.000838, loss: 0.4028
2022-09-30 12:00:21 - train: epoch 0174, iter [00290, 01251], lr: 0.000838, loss: 0.4098
2022-09-30 12:00:39 - train: epoch 0174, iter [00300, 01251], lr: 0.000838, loss: 0.4255
2022-09-30 12:00:57 - train: epoch 0174, iter [00310, 01251], lr: 0.000838, loss: 0.3971
2022-09-30 12:01:15 - train: epoch 0174, iter [00320, 01251], lr: 0.000838, loss: 0.4007
2022-09-30 12:01:32 - train: epoch 0174, iter [00330, 01251], lr: 0.000838, loss: 0.4188
2022-09-30 12:01:50 - train: epoch 0174, iter [00340, 01251], lr: 0.000838, loss: 0.4216
2022-09-30 12:02:08 - train: epoch 0174, iter [00350, 01251], lr: 0.000838, loss: 0.3890
2022-09-30 12:02:26 - train: epoch 0174, iter [00360, 01251], lr: 0.000838, loss: 0.4210
2022-09-30 12:02:43 - train: epoch 0174, iter [00370, 01251], lr: 0.000838, loss: 0.4087
2022-09-30 12:03:01 - train: epoch 0174, iter [00380, 01251], lr: 0.000838, loss: 0.3933
2022-09-30 12:03:19 - train: epoch 0174, iter [00390, 01251], lr: 0.000838, loss: 0.3964
2022-09-30 12:03:37 - train: epoch 0174, iter [00400, 01251], lr: 0.000838, loss: 0.3960
2022-09-30 12:03:54 - train: epoch 0174, iter [00410, 01251], lr: 0.000838, loss: 0.4048
2022-09-30 12:04:12 - train: epoch 0174, iter [00420, 01251], lr: 0.000838, loss: 0.4180
2022-09-30 12:04:30 - train: epoch 0174, iter [00430, 01251], lr: 0.000838, loss: 0.3974
2022-09-30 12:04:48 - train: epoch 0174, iter [00440, 01251], lr: 0.000838, loss: 0.4101
2022-09-30 12:05:05 - train: epoch 0174, iter [00450, 01251], lr: 0.000838, loss: 0.4045
2022-09-30 12:05:23 - train: epoch 0174, iter [00460, 01251], lr: 0.000837, loss: 0.4036
2022-09-30 12:05:41 - train: epoch 0174, iter [00470, 01251], lr: 0.000837, loss: 0.3915
2022-09-30 12:05:59 - train: epoch 0174, iter [00480, 01251], lr: 0.000837, loss: 0.3913
2022-09-30 12:06:16 - train: epoch 0174, iter [00490, 01251], lr: 0.000837, loss: 0.4192
2022-09-30 12:06:34 - train: epoch 0174, iter [00500, 01251], lr: 0.000837, loss: 0.4045
2022-09-30 12:06:52 - train: epoch 0174, iter [00510, 01251], lr: 0.000837, loss: 0.3961
2022-09-30 12:07:10 - train: epoch 0174, iter [00520, 01251], lr: 0.000837, loss: 0.4104
2022-09-30 12:07:27 - train: epoch 0174, iter [00530, 01251], lr: 0.000837, loss: 0.4295
2022-09-30 12:07:45 - train: epoch 0174, iter [00540, 01251], lr: 0.000837, loss: 0.4102
2022-09-30 12:08:03 - train: epoch 0174, iter [00550, 01251], lr: 0.000837, loss: 0.4050
2022-09-30 12:08:20 - train: epoch 0174, iter [00560, 01251], lr: 0.000837, loss: 0.4066
2022-09-30 12:08:38 - train: epoch 0174, iter [00570, 01251], lr: 0.000837, loss: 0.4237
2022-09-30 12:08:56 - train: epoch 0174, iter [00580, 01251], lr: 0.000837, loss: 0.3908
2022-09-30 12:09:14 - train: epoch 0174, iter [00590, 01251], lr: 0.000837, loss: 0.4227
2022-09-30 12:09:32 - train: epoch 0174, iter [00600, 01251], lr: 0.000837, loss: 0.3949
2022-09-30 12:09:50 - train: epoch 0174, iter [00610, 01251], lr: 0.000837, loss: 0.3999
2022-09-30 12:10:07 - train: epoch 0174, iter [00620, 01251], lr: 0.000837, loss: 0.4058
2022-09-30 12:10:25 - train: epoch 0174, iter [00630, 01251], lr: 0.000837, loss: 0.3968
2022-09-30 12:10:43 - train: epoch 0174, iter [00640, 01251], lr: 0.000837, loss: 0.4111
2022-09-30 12:11:01 - train: epoch 0174, iter [00650, 01251], lr: 0.000837, loss: 0.4158
2022-09-30 12:11:18 - train: epoch 0174, iter [00660, 01251], lr: 0.000837, loss: 0.4119
2022-09-30 12:11:36 - train: epoch 0174, iter [00670, 01251], lr: 0.000837, loss: 0.4057
2022-09-30 12:11:54 - train: epoch 0174, iter [00680, 01251], lr: 0.000837, loss: 0.3986
2022-09-30 12:12:12 - train: epoch 0174, iter [00690, 01251], lr: 0.000837, loss: 0.4084
2022-09-30 12:12:29 - train: epoch 0174, iter [00700, 01251], lr: 0.000837, loss: 0.4004
2022-09-30 12:12:47 - train: epoch 0174, iter [00710, 01251], lr: 0.000837, loss: 0.4047
2022-09-30 12:13:05 - train: epoch 0174, iter [00720, 01251], lr: 0.000836, loss: 0.4208
2022-09-30 12:13:22 - train: epoch 0174, iter [00730, 01251], lr: 0.000836, loss: 0.3971
2022-09-30 12:13:40 - train: epoch 0174, iter [00740, 01251], lr: 0.000836, loss: 0.4024
2022-09-30 12:13:58 - train: epoch 0174, iter [00750, 01251], lr: 0.000836, loss: 0.3979
2022-09-30 12:14:15 - train: epoch 0174, iter [00760, 01251], lr: 0.000836, loss: 0.4124
2022-09-30 12:14:33 - train: epoch 0174, iter [00770, 01251], lr: 0.000836, loss: 0.4294
2022-09-30 12:14:51 - train: epoch 0174, iter [00780, 01251], lr: 0.000836, loss: 0.4084
2022-09-30 12:15:08 - train: epoch 0174, iter [00790, 01251], lr: 0.000836, loss: 0.4150
2022-09-30 12:15:26 - train: epoch 0174, iter [00800, 01251], lr: 0.000836, loss: 0.4229
2022-09-30 12:15:44 - train: epoch 0174, iter [00810, 01251], lr: 0.000836, loss: 0.4005
2022-09-30 12:16:02 - train: epoch 0174, iter [00820, 01251], lr: 0.000836, loss: 0.3883
2022-09-30 12:16:19 - train: epoch 0174, iter [00830, 01251], lr: 0.000836, loss: 0.4011
2022-09-30 12:16:37 - train: epoch 0174, iter [00840, 01251], lr: 0.000836, loss: 0.4170
2022-09-30 12:16:55 - train: epoch 0174, iter [00850, 01251], lr: 0.000836, loss: 0.4120
2022-09-30 12:17:13 - train: epoch 0174, iter [00860, 01251], lr: 0.000836, loss: 0.4091
2022-09-30 12:17:30 - train: epoch 0174, iter [00870, 01251], lr: 0.000836, loss: 0.3988
2022-09-30 12:17:48 - train: epoch 0174, iter [00880, 01251], lr: 0.000836, loss: 0.4247
2022-09-30 12:18:06 - train: epoch 0174, iter [00890, 01251], lr: 0.000836, loss: 0.3985
2022-09-30 12:18:24 - train: epoch 0174, iter [00900, 01251], lr: 0.000836, loss: 0.4227
2022-09-30 12:18:41 - train: epoch 0174, iter [00910, 01251], lr: 0.000836, loss: 0.4088
2022-09-30 12:18:59 - train: epoch 0174, iter [00920, 01251], lr: 0.000836, loss: 0.4086
2022-09-30 12:19:17 - train: epoch 0174, iter [00930, 01251], lr: 0.000836, loss: 0.4092
2022-09-30 12:19:35 - train: epoch 0174, iter [00940, 01251], lr: 0.000836, loss: 0.4150
2022-09-30 12:19:52 - train: epoch 0174, iter [00950, 01251], lr: 0.000836, loss: 0.4083
2022-09-30 12:20:10 - train: epoch 0174, iter [00960, 01251], lr: 0.000836, loss: 0.4156
2022-09-30 12:20:28 - train: epoch 0174, iter [00970, 01251], lr: 0.000836, loss: 0.3903
2022-09-30 12:20:46 - train: epoch 0174, iter [00980, 01251], lr: 0.000835, loss: 0.4088
2022-09-30 12:21:03 - train: epoch 0174, iter [00990, 01251], lr: 0.000835, loss: 0.3964
2022-09-30 12:21:21 - train: epoch 0174, iter [01000, 01251], lr: 0.000835, loss: 0.4000
2022-09-30 12:21:39 - train: epoch 0174, iter [01010, 01251], lr: 0.000835, loss: 0.4133
2022-09-30 12:21:57 - train: epoch 0174, iter [01020, 01251], lr: 0.000835, loss: 0.4224
2022-09-30 12:22:14 - train: epoch 0174, iter [01030, 01251], lr: 0.000835, loss: 0.4059
2022-09-30 12:22:32 - train: epoch 0174, iter [01040, 01251], lr: 0.000835, loss: 0.4086
2022-09-30 12:22:50 - train: epoch 0174, iter [01050, 01251], lr: 0.000835, loss: 0.4110
2022-09-30 12:23:08 - train: epoch 0174, iter [01060, 01251], lr: 0.000835, loss: 0.4172
2022-09-30 12:23:25 - train: epoch 0174, iter [01070, 01251], lr: 0.000835, loss: 0.4141
2022-09-30 12:23:43 - train: epoch 0174, iter [01080, 01251], lr: 0.000835, loss: 0.4085
2022-09-30 12:24:01 - train: epoch 0174, iter [01090, 01251], lr: 0.000835, loss: 0.4128
2022-09-30 12:24:18 - train: epoch 0174, iter [01100, 01251], lr: 0.000835, loss: 0.4133
2022-09-30 12:24:36 - train: epoch 0174, iter [01110, 01251], lr: 0.000835, loss: 0.3955
2022-09-30 12:24:54 - train: epoch 0174, iter [01120, 01251], lr: 0.000835, loss: 0.4180
2022-09-30 12:25:12 - train: epoch 0174, iter [01130, 01251], lr: 0.000835, loss: 0.3902
2022-09-30 12:25:30 - train: epoch 0174, iter [01140, 01251], lr: 0.000835, loss: 0.4126
2022-09-30 12:25:47 - train: epoch 0174, iter [01150, 01251], lr: 0.000835, loss: 0.4310
2022-09-30 12:26:05 - train: epoch 0174, iter [01160, 01251], lr: 0.000835, loss: 0.4117
2022-09-30 12:26:23 - train: epoch 0174, iter [01170, 01251], lr: 0.000835, loss: 0.4002
2022-09-30 12:26:41 - train: epoch 0174, iter [01180, 01251], lr: 0.000835, loss: 0.4155
2022-09-30 12:26:58 - train: epoch 0174, iter [01190, 01251], lr: 0.000835, loss: 0.4261
2022-09-30 12:27:16 - train: epoch 0174, iter [01200, 01251], lr: 0.000835, loss: 0.3971
2022-09-30 12:27:34 - train: epoch 0174, iter [01210, 01251], lr: 0.000835, loss: 0.4086
2022-09-30 12:27:51 - train: epoch 0174, iter [01220, 01251], lr: 0.000835, loss: 0.4017
2022-09-30 12:28:09 - train: epoch 0174, iter [01230, 01251], lr: 0.000835, loss: 0.4149
2022-09-30 12:28:27 - train: epoch 0174, iter [01240, 01251], lr: 0.000834, loss: 0.4104
2022-09-30 12:28:45 - train: epoch 0174, iter [01250, 01251], lr: 0.000834, loss: 0.4090
2022-09-30 12:28:48 - train: epoch 174, train_loss: 0.4089
2022-09-30 12:28:50 - until epoch: 174, best_loss: 0.4089
2022-09-30 12:28:50 - epoch 175 lr: 0.000834
2022-09-30 12:29:15 - train: epoch 0175, iter [00010, 01251], lr: 0.000834, loss: 0.3985
2022-09-30 12:29:33 - train: epoch 0175, iter [00020, 01251], lr: 0.000834, loss: 0.4181
2022-09-30 12:29:51 - train: epoch 0175, iter [00030, 01251], lr: 0.000834, loss: 0.4120
2022-09-30 12:30:09 - train: epoch 0175, iter [00040, 01251], lr: 0.000834, loss: 0.4072
2022-09-30 12:30:27 - train: epoch 0175, iter [00050, 01251], lr: 0.000834, loss: 0.3958
2022-09-30 12:30:44 - train: epoch 0175, iter [00060, 01251], lr: 0.000834, loss: 0.4124
2022-09-30 12:31:02 - train: epoch 0175, iter [00070, 01251], lr: 0.000834, loss: 0.4070
2022-09-30 12:31:20 - train: epoch 0175, iter [00080, 01251], lr: 0.000834, loss: 0.3940
2022-09-30 12:31:37 - train: epoch 0175, iter [00090, 01251], lr: 0.000834, loss: 0.4081
2022-09-30 12:31:55 - train: epoch 0175, iter [00100, 01251], lr: 0.000834, loss: 0.4170
2022-09-30 12:32:13 - train: epoch 0175, iter [00110, 01251], lr: 0.000834, loss: 0.4257
2022-09-30 12:32:30 - train: epoch 0175, iter [00120, 01251], lr: 0.000834, loss: 0.3940
2022-09-30 12:32:48 - train: epoch 0175, iter [00130, 01251], lr: 0.000834, loss: 0.4003
2022-09-30 12:33:06 - train: epoch 0175, iter [00140, 01251], lr: 0.000834, loss: 0.3923
2022-09-30 12:33:23 - train: epoch 0175, iter [00150, 01251], lr: 0.000834, loss: 0.4313
2022-09-30 12:33:41 - train: epoch 0175, iter [00160, 01251], lr: 0.000834, loss: 0.4190
2022-09-30 12:33:59 - train: epoch 0175, iter [00170, 01251], lr: 0.000834, loss: 0.4049
2022-09-30 12:34:16 - train: epoch 0175, iter [00180, 01251], lr: 0.000834, loss: 0.4089
2022-09-30 12:34:34 - train: epoch 0175, iter [00190, 01251], lr: 0.000834, loss: 0.4087
2022-09-30 12:34:52 - train: epoch 0175, iter [00200, 01251], lr: 0.000834, loss: 0.3952
2022-09-30 12:35:10 - train: epoch 0175, iter [00210, 01251], lr: 0.000834, loss: 0.4035
2022-09-30 12:35:27 - train: epoch 0175, iter [00220, 01251], lr: 0.000834, loss: 0.4238
2022-09-30 12:35:45 - train: epoch 0175, iter [00230, 01251], lr: 0.000834, loss: 0.3906
2022-09-30 12:36:03 - train: epoch 0175, iter [00240, 01251], lr: 0.000834, loss: 0.4055
2022-09-30 12:36:20 - train: epoch 0175, iter [00250, 01251], lr: 0.000833, loss: 0.4150
2022-09-30 12:36:38 - train: epoch 0175, iter [00260, 01251], lr: 0.000833, loss: 0.4128
2022-09-30 12:36:56 - train: epoch 0175, iter [00270, 01251], lr: 0.000833, loss: 0.4048
2022-09-30 12:37:14 - train: epoch 0175, iter [00280, 01251], lr: 0.000833, loss: 0.4170
2022-09-30 12:37:31 - train: epoch 0175, iter [00290, 01251], lr: 0.000833, loss: 0.4012
2022-09-30 12:37:49 - train: epoch 0175, iter [00300, 01251], lr: 0.000833, loss: 0.4068
2022-09-30 12:38:07 - train: epoch 0175, iter [00310, 01251], lr: 0.000833, loss: 0.3957
2022-09-30 12:38:25 - train: epoch 0175, iter [00320, 01251], lr: 0.000833, loss: 0.4131
2022-09-30 12:38:42 - train: epoch 0175, iter [00330, 01251], lr: 0.000833, loss: 0.4081
2022-09-30 12:39:00 - train: epoch 0175, iter [00340, 01251], lr: 0.000833, loss: 0.4079
2022-09-30 12:39:18 - train: epoch 0175, iter [00350, 01251], lr: 0.000833, loss: 0.4104
2022-09-30 12:39:36 - train: epoch 0175, iter [00360, 01251], lr: 0.000833, loss: 0.3944
2022-09-30 12:39:53 - train: epoch 0175, iter [00370, 01251], lr: 0.000833, loss: 0.4030
2022-09-30 12:40:11 - train: epoch 0175, iter [00380, 01251], lr: 0.000833, loss: 0.4022
2022-09-30 12:40:29 - train: epoch 0175, iter [00390, 01251], lr: 0.000833, loss: 0.4001
2022-09-30 12:40:46 - train: epoch 0175, iter [00400, 01251], lr: 0.000833, loss: 0.3938
2022-09-30 12:41:04 - train: epoch 0175, iter [00410, 01251], lr: 0.000833, loss: 0.3849
2022-09-30 12:41:22 - train: epoch 0175, iter [00420, 01251], lr: 0.000833, loss: 0.4265
2022-09-30 12:41:40 - train: epoch 0175, iter [00430, 01251], lr: 0.000833, loss: 0.4070
2022-09-30 12:41:58 - train: epoch 0175, iter [00440, 01251], lr: 0.000833, loss: 0.4048
2022-09-30 12:42:15 - train: epoch 0175, iter [00450, 01251], lr: 0.000833, loss: 0.4096
2022-09-30 12:42:33 - train: epoch 0175, iter [00460, 01251], lr: 0.000833, loss: 0.3891
2022-09-30 12:42:51 - train: epoch 0175, iter [00470, 01251], lr: 0.000833, loss: 0.4029
2022-09-30 12:43:08 - train: epoch 0175, iter [00480, 01251], lr: 0.000833, loss: 0.4090
2022-09-30 12:43:26 - train: epoch 0175, iter [00490, 01251], lr: 0.000833, loss: 0.4070
2022-09-30 12:43:44 - train: epoch 0175, iter [00500, 01251], lr: 0.000833, loss: 0.4158
2022-09-30 12:44:02 - train: epoch 0175, iter [00510, 01251], lr: 0.000832, loss: 0.4056
2022-09-30 12:44:19 - train: epoch 0175, iter [00520, 01251], lr: 0.000832, loss: 0.4173
2022-09-30 12:44:37 - train: epoch 0175, iter [00530, 01251], lr: 0.000832, loss: 0.3920
2022-09-30 12:44:55 - train: epoch 0175, iter [00540, 01251], lr: 0.000832, loss: 0.4268
2022-09-30 12:45:13 - train: epoch 0175, iter [00550, 01251], lr: 0.000832, loss: 0.4091
2022-09-30 12:45:31 - train: epoch 0175, iter [00560, 01251], lr: 0.000832, loss: 0.4218
2022-09-30 12:45:48 - train: epoch 0175, iter [00570, 01251], lr: 0.000832, loss: 0.4094
2022-09-30 12:46:06 - train: epoch 0175, iter [00580, 01251], lr: 0.000832, loss: 0.4172
2022-09-30 12:46:24 - train: epoch 0175, iter [00590, 01251], lr: 0.000832, loss: 0.3982
2022-09-30 12:46:42 - train: epoch 0175, iter [00600, 01251], lr: 0.000832, loss: 0.4072
2022-09-30 12:46:59 - train: epoch 0175, iter [00610, 01251], lr: 0.000832, loss: 0.4135
2022-09-30 12:47:17 - train: epoch 0175, iter [00620, 01251], lr: 0.000832, loss: 0.4360
2022-09-30 12:47:35 - train: epoch 0175, iter [00630, 01251], lr: 0.000832, loss: 0.4188
2022-09-30 12:47:53 - train: epoch 0175, iter [00640, 01251], lr: 0.000832, loss: 0.4098
2022-09-30 12:48:10 - train: epoch 0175, iter [00650, 01251], lr: 0.000832, loss: 0.4091
2022-09-30 12:48:28 - train: epoch 0175, iter [00660, 01251], lr: 0.000832, loss: 0.4022
2022-09-30 12:48:45 - train: epoch 0175, iter [00670, 01251], lr: 0.000832, loss: 0.3903
2022-09-30 12:49:03 - train: epoch 0175, iter [00680, 01251], lr: 0.000832, loss: 0.3963
2022-09-30 12:49:21 - train: epoch 0175, iter [00690, 01251], lr: 0.000832, loss: 0.4144
2022-09-30 12:49:38 - train: epoch 0175, iter [00700, 01251], lr: 0.000832, loss: 0.3979
2022-09-30 12:49:56 - train: epoch 0175, iter [00710, 01251], lr: 0.000832, loss: 0.4029
2022-09-30 12:50:14 - train: epoch 0175, iter [00720, 01251], lr: 0.000832, loss: 0.4130
2022-09-30 12:50:31 - train: epoch 0175, iter [00730, 01251], lr: 0.000832, loss: 0.4058
2022-09-30 12:50:49 - train: epoch 0175, iter [00740, 01251], lr: 0.000832, loss: 0.4172
2022-09-30 12:51:07 - train: epoch 0175, iter [00750, 01251], lr: 0.000832, loss: 0.4027
2022-09-30 12:51:24 - train: epoch 0175, iter [00760, 01251], lr: 0.000832, loss: 0.4044
2022-09-30 12:51:42 - train: epoch 0175, iter [00770, 01251], lr: 0.000831, loss: 0.4212
2022-09-30 12:52:00 - train: epoch 0175, iter [00780, 01251], lr: 0.000831, loss: 0.4029
2022-09-30 12:52:18 - train: epoch 0175, iter [00790, 01251], lr: 0.000831, loss: 0.4161
2022-09-30 12:52:35 - train: epoch 0175, iter [00800, 01251], lr: 0.000831, loss: 0.4117
2022-09-30 12:52:53 - train: epoch 0175, iter [00810, 01251], lr: 0.000831, loss: 0.4305
2022-09-30 12:53:11 - train: epoch 0175, iter [00820, 01251], lr: 0.000831, loss: 0.4109
2022-09-30 12:53:28 - train: epoch 0175, iter [00830, 01251], lr: 0.000831, loss: 0.4245
2022-09-30 12:53:46 - train: epoch 0175, iter [00840, 01251], lr: 0.000831, loss: 0.4007
2022-09-30 12:54:04 - train: epoch 0175, iter [00850, 01251], lr: 0.000831, loss: 0.4027
2022-09-30 12:54:22 - train: epoch 0175, iter [00860, 01251], lr: 0.000831, loss: 0.4140
2022-09-30 12:54:39 - train: epoch 0175, iter [00870, 01251], lr: 0.000831, loss: 0.3953
2022-09-30 12:54:57 - train: epoch 0175, iter [00880, 01251], lr: 0.000831, loss: 0.4129
2022-09-30 12:55:15 - train: epoch 0175, iter [00890, 01251], lr: 0.000831, loss: 0.3927
2022-09-30 12:55:33 - train: epoch 0175, iter [00900, 01251], lr: 0.000831, loss: 0.4202
2022-09-30 12:55:51 - train: epoch 0175, iter [00910, 01251], lr: 0.000831, loss: 0.4025
2022-09-30 12:56:08 - train: epoch 0175, iter [00920, 01251], lr: 0.000831, loss: 0.4024
2022-09-30 12:56:26 - train: epoch 0175, iter [00930, 01251], lr: 0.000831, loss: 0.4122
2022-09-30 12:56:44 - train: epoch 0175, iter [00940, 01251], lr: 0.000831, loss: 0.4272
2022-09-30 12:57:02 - train: epoch 0175, iter [00950, 01251], lr: 0.000831, loss: 0.4162
2022-09-30 12:57:19 - train: epoch 0175, iter [00960, 01251], lr: 0.000831, loss: 0.4027
2022-09-30 12:57:37 - train: epoch 0175, iter [00970, 01251], lr: 0.000831, loss: 0.4229
2022-09-30 12:57:55 - train: epoch 0175, iter [00980, 01251], lr: 0.000831, loss: 0.4263
2022-09-30 12:58:13 - train: epoch 0175, iter [00990, 01251], lr: 0.000831, loss: 0.4137
2022-09-30 12:58:30 - train: epoch 0175, iter [01000, 01251], lr: 0.000831, loss: 0.4061
2022-09-30 12:58:48 - train: epoch 0175, iter [01010, 01251], lr: 0.000831, loss: 0.4312
2022-09-30 12:59:06 - train: epoch 0175, iter [01020, 01251], lr: 0.000831, loss: 0.4135
2022-09-30 12:59:23 - train: epoch 0175, iter [01030, 01251], lr: 0.000830, loss: 0.4225
2022-09-30 12:59:41 - train: epoch 0175, iter [01040, 01251], lr: 0.000830, loss: 0.3993
2022-09-30 12:59:59 - train: epoch 0175, iter [01050, 01251], lr: 0.000830, loss: 0.3990
2022-09-30 13:00:16 - train: epoch 0175, iter [01060, 01251], lr: 0.000830, loss: 0.4042
2022-09-30 13:00:34 - train: epoch 0175, iter [01070, 01251], lr: 0.000830, loss: 0.3937
2022-09-30 13:00:52 - train: epoch 0175, iter [01080, 01251], lr: 0.000830, loss: 0.4101
2022-09-30 13:01:09 - train: epoch 0175, iter [01090, 01251], lr: 0.000830, loss: 0.4320
2022-09-30 13:01:27 - train: epoch 0175, iter [01100, 01251], lr: 0.000830, loss: 0.4026
2022-09-30 13:01:44 - train: epoch 0175, iter [01110, 01251], lr: 0.000830, loss: 0.4155
2022-09-30 13:02:02 - train: epoch 0175, iter [01120, 01251], lr: 0.000830, loss: 0.4182
2022-09-30 13:02:20 - train: epoch 0175, iter [01130, 01251], lr: 0.000830, loss: 0.4053
2022-09-30 13:02:37 - train: epoch 0175, iter [01140, 01251], lr: 0.000830, loss: 0.4034
2022-09-30 13:02:55 - train: epoch 0175, iter [01150, 01251], lr: 0.000830, loss: 0.4233
2022-09-30 13:03:13 - train: epoch 0175, iter [01160, 01251], lr: 0.000830, loss: 0.4199
2022-09-30 13:03:31 - train: epoch 0175, iter [01170, 01251], lr: 0.000830, loss: 0.3966
2022-09-30 13:03:48 - train: epoch 0175, iter [01180, 01251], lr: 0.000830, loss: 0.4125
2022-09-30 13:04:06 - train: epoch 0175, iter [01190, 01251], lr: 0.000830, loss: 0.4148
2022-09-30 13:04:24 - train: epoch 0175, iter [01200, 01251], lr: 0.000830, loss: 0.4307
2022-09-30 13:04:42 - train: epoch 0175, iter [01210, 01251], lr: 0.000830, loss: 0.4054
2022-09-30 13:04:59 - train: epoch 0175, iter [01220, 01251], lr: 0.000830, loss: 0.3969
2022-09-30 13:05:17 - train: epoch 0175, iter [01230, 01251], lr: 0.000830, loss: 0.3928
2022-09-30 13:05:35 - train: epoch 0175, iter [01240, 01251], lr: 0.000830, loss: 0.3972
2022-09-30 13:05:52 - train: epoch 0175, iter [01250, 01251], lr: 0.000830, loss: 0.4276
2022-09-30 13:05:56 - train: epoch 175, train_loss: 0.4089
2022-09-30 13:05:58 - until epoch: 175, best_loss: 0.4089
2022-09-30 13:05:58 - epoch 176 lr: 0.000830
2022-09-30 13:06:24 - train: epoch 0176, iter [00010, 01251], lr: 0.000830, loss: 0.4032
2022-09-30 13:06:42 - train: epoch 0176, iter [00020, 01251], lr: 0.000830, loss: 0.4065
2022-09-30 13:07:00 - train: epoch 0176, iter [00030, 01251], lr: 0.000829, loss: 0.4001
2022-09-30 13:07:17 - train: epoch 0176, iter [00040, 01251], lr: 0.000829, loss: 0.4128
2022-09-30 13:07:35 - train: epoch 0176, iter [00050, 01251], lr: 0.000829, loss: 0.4012
2022-09-30 13:07:52 - train: epoch 0176, iter [00060, 01251], lr: 0.000829, loss: 0.3925
2022-09-30 13:08:10 - train: epoch 0176, iter [00070, 01251], lr: 0.000829, loss: 0.3902
2022-09-30 13:08:28 - train: epoch 0176, iter [00080, 01251], lr: 0.000829, loss: 0.3980
2022-09-30 13:08:45 - train: epoch 0176, iter [00090, 01251], lr: 0.000829, loss: 0.4008
2022-09-30 13:09:03 - train: epoch 0176, iter [00100, 01251], lr: 0.000829, loss: 0.4089
2022-09-30 13:09:21 - train: epoch 0176, iter [00110, 01251], lr: 0.000829, loss: 0.4038
2022-09-30 13:09:39 - train: epoch 0176, iter [00120, 01251], lr: 0.000829, loss: 0.4397
2022-09-30 13:09:56 - train: epoch 0176, iter [00130, 01251], lr: 0.000829, loss: 0.4096
2022-09-30 13:10:14 - train: epoch 0176, iter [00140, 01251], lr: 0.000829, loss: 0.3927
2022-09-30 13:10:32 - train: epoch 0176, iter [00150, 01251], lr: 0.000829, loss: 0.4078
2022-09-30 13:10:49 - train: epoch 0176, iter [00160, 01251], lr: 0.000829, loss: 0.4213
2022-09-30 13:11:07 - train: epoch 0176, iter [00170, 01251], lr: 0.000829, loss: 0.4247
2022-09-30 13:11:25 - train: epoch 0176, iter [00180, 01251], lr: 0.000829, loss: 0.3981
2022-09-30 13:11:43 - train: epoch 0176, iter [00190, 01251], lr: 0.000829, loss: 0.4233
2022-09-30 13:12:00 - train: epoch 0176, iter [00200, 01251], lr: 0.000829, loss: 0.3933
2022-09-30 13:12:18 - train: epoch 0176, iter [00210, 01251], lr: 0.000829, loss: 0.4102
2022-09-30 13:12:35 - train: epoch 0176, iter [00220, 01251], lr: 0.000829, loss: 0.3968
2022-09-30 13:12:53 - train: epoch 0176, iter [00230, 01251], lr: 0.000829, loss: 0.4142
2022-09-30 13:13:11 - train: epoch 0176, iter [00240, 01251], lr: 0.000829, loss: 0.4162
2022-09-30 13:13:28 - train: epoch 0176, iter [00250, 01251], lr: 0.000829, loss: 0.3939
2022-09-30 13:13:46 - train: epoch 0176, iter [00260, 01251], lr: 0.000829, loss: 0.4207
2022-09-30 13:14:04 - train: epoch 0176, iter [00270, 01251], lr: 0.000829, loss: 0.4033
2022-09-30 13:14:21 - train: epoch 0176, iter [00280, 01251], lr: 0.000829, loss: 0.3839
2022-09-30 13:14:39 - train: epoch 0176, iter [00290, 01251], lr: 0.000828, loss: 0.3946
2022-09-30 13:14:57 - train: epoch 0176, iter [00300, 01251], lr: 0.000828, loss: 0.4094
2022-09-30 13:15:14 - train: epoch 0176, iter [00310, 01251], lr: 0.000828, loss: 0.4169
2022-09-30 13:15:32 - train: epoch 0176, iter [00320, 01251], lr: 0.000828, loss: 0.4072
2022-09-30 13:15:50 - train: epoch 0176, iter [00330, 01251], lr: 0.000828, loss: 0.4179
2022-09-30 13:16:07 - train: epoch 0176, iter [00340, 01251], lr: 0.000828, loss: 0.3967
2022-09-30 13:16:25 - train: epoch 0176, iter [00350, 01251], lr: 0.000828, loss: 0.4022
2022-09-30 13:16:43 - train: epoch 0176, iter [00360, 01251], lr: 0.000828, loss: 0.4065
2022-09-30 13:17:00 - train: epoch 0176, iter [00370, 01251], lr: 0.000828, loss: 0.4066
2022-09-30 13:17:18 - train: epoch 0176, iter [00380, 01251], lr: 0.000828, loss: 0.4064
2022-09-30 13:17:36 - train: epoch 0176, iter [00390, 01251], lr: 0.000828, loss: 0.4217
2022-09-30 13:17:53 - train: epoch 0176, iter [00400, 01251], lr: 0.000828, loss: 0.3949
2022-09-30 13:18:11 - train: epoch 0176, iter [00410, 01251], lr: 0.000828, loss: 0.3922
2022-09-30 13:18:29 - train: epoch 0176, iter [00420, 01251], lr: 0.000828, loss: 0.4009
2022-09-30 13:18:47 - train: epoch 0176, iter [00430, 01251], lr: 0.000828, loss: 0.4068
2022-09-30 13:19:04 - train: epoch 0176, iter [00440, 01251], lr: 0.000828, loss: 0.3952
2022-09-30 13:19:22 - train: epoch 0176, iter [00450, 01251], lr: 0.000828, loss: 0.4157
2022-09-30 13:19:40 - train: epoch 0176, iter [00460, 01251], lr: 0.000828, loss: 0.4096
2022-09-30 13:19:57 - train: epoch 0176, iter [00470, 01251], lr: 0.000828, loss: 0.4129
2022-09-30 13:20:15 - train: epoch 0176, iter [00480, 01251], lr: 0.000828, loss: 0.4115
2022-09-30 13:20:33 - train: epoch 0176, iter [00490, 01251], lr: 0.000828, loss: 0.4177
2022-09-30 13:20:50 - train: epoch 0176, iter [00500, 01251], lr: 0.000828, loss: 0.4196
2022-09-30 13:21:08 - train: epoch 0176, iter [00510, 01251], lr: 0.000828, loss: 0.4175
2022-09-30 13:21:26 - train: epoch 0176, iter [00520, 01251], lr: 0.000828, loss: 0.4009
2022-09-30 13:21:43 - train: epoch 0176, iter [00530, 01251], lr: 0.000828, loss: 0.3990
2022-09-30 13:22:01 - train: epoch 0176, iter [00540, 01251], lr: 0.000828, loss: 0.3991
2022-09-30 13:22:19 - train: epoch 0176, iter [00550, 01251], lr: 0.000827, loss: 0.4115
2022-09-30 13:22:37 - train: epoch 0176, iter [00560, 01251], lr: 0.000827, loss: 0.4248
2022-09-30 13:22:54 - train: epoch 0176, iter [00570, 01251], lr: 0.000827, loss: 0.3790
2022-09-30 13:23:12 - train: epoch 0176, iter [00580, 01251], lr: 0.000827, loss: 0.3910
2022-09-30 13:23:30 - train: epoch 0176, iter [00590, 01251], lr: 0.000827, loss: 0.4077
2022-09-30 13:23:47 - train: epoch 0176, iter [00600, 01251], lr: 0.000827, loss: 0.3961
2022-09-30 13:24:05 - train: epoch 0176, iter [00610, 01251], lr: 0.000827, loss: 0.4061
2022-09-30 13:24:23 - train: epoch 0176, iter [00620, 01251], lr: 0.000827, loss: 0.3983
2022-09-30 13:24:40 - train: epoch 0176, iter [00630, 01251], lr: 0.000827, loss: 0.4081
2022-09-30 13:24:58 - train: epoch 0176, iter [00640, 01251], lr: 0.000827, loss: 0.4348
2022-09-30 13:25:16 - train: epoch 0176, iter [00650, 01251], lr: 0.000827, loss: 0.4142
2022-09-30 13:25:34 - train: epoch 0176, iter [00660, 01251], lr: 0.000827, loss: 0.3961
2022-09-30 13:25:52 - train: epoch 0176, iter [00670, 01251], lr: 0.000827, loss: 0.4176
2022-09-30 13:26:09 - train: epoch 0176, iter [00680, 01251], lr: 0.000827, loss: 0.4336
2022-09-30 13:26:27 - train: epoch 0176, iter [00690, 01251], lr: 0.000827, loss: 0.4097
2022-09-30 13:26:45 - train: epoch 0176, iter [00700, 01251], lr: 0.000827, loss: 0.3999
2022-09-30 13:27:03 - train: epoch 0176, iter [00710, 01251], lr: 0.000827, loss: 0.4123
2022-09-30 13:27:21 - train: epoch 0176, iter [00720, 01251], lr: 0.000827, loss: 0.4085
2022-09-30 13:27:38 - train: epoch 0176, iter [00730, 01251], lr: 0.000827, loss: 0.4055
2022-09-30 13:27:56 - train: epoch 0176, iter [00740, 01251], lr: 0.000827, loss: 0.4243
2022-09-30 13:28:14 - train: epoch 0176, iter [00750, 01251], lr: 0.000827, loss: 0.4119
2022-09-30 13:28:32 - train: epoch 0176, iter [00760, 01251], lr: 0.000827, loss: 0.4027
2022-09-30 13:28:49 - train: epoch 0176, iter [00770, 01251], lr: 0.000827, loss: 0.4010
2022-09-30 13:29:07 - train: epoch 0176, iter [00780, 01251], lr: 0.000827, loss: 0.3973
2022-09-30 13:29:24 - train: epoch 0176, iter [00790, 01251], lr: 0.000827, loss: 0.4123
2022-09-30 13:29:42 - train: epoch 0176, iter [00800, 01251], lr: 0.000827, loss: 0.3958
2022-09-30 13:30:00 - train: epoch 0176, iter [00810, 01251], lr: 0.000826, loss: 0.4159
2022-09-30 13:30:18 - train: epoch 0176, iter [00820, 01251], lr: 0.000826, loss: 0.4195
2022-09-30 13:30:35 - train: epoch 0176, iter [00830, 01251], lr: 0.000826, loss: 0.4161
2022-09-30 13:30:53 - train: epoch 0176, iter [00840, 01251], lr: 0.000826, loss: 0.4077
2022-09-30 13:31:11 - train: epoch 0176, iter [00850, 01251], lr: 0.000826, loss: 0.4035
2022-09-30 13:31:28 - train: epoch 0176, iter [00860, 01251], lr: 0.000826, loss: 0.3999
2022-09-30 13:31:46 - train: epoch 0176, iter [00870, 01251], lr: 0.000826, loss: 0.4196
2022-09-30 13:32:04 - train: epoch 0176, iter [00880, 01251], lr: 0.000826, loss: 0.4169
2022-09-30 13:32:21 - train: epoch 0176, iter [00890, 01251], lr: 0.000826, loss: 0.4083
2022-09-30 13:32:39 - train: epoch 0176, iter [00900, 01251], lr: 0.000826, loss: 0.4023
2022-09-30 13:32:57 - train: epoch 0176, iter [00910, 01251], lr: 0.000826, loss: 0.4054
2022-09-30 13:33:15 - train: epoch 0176, iter [00920, 01251], lr: 0.000826, loss: 0.4120
2022-09-30 13:33:33 - train: epoch 0176, iter [00930, 01251], lr: 0.000826, loss: 0.3972
2022-09-30 13:33:50 - train: epoch 0176, iter [00940, 01251], lr: 0.000826, loss: 0.4100
2022-09-30 13:34:08 - train: epoch 0176, iter [00950, 01251], lr: 0.000826, loss: 0.3981
2022-09-30 13:34:26 - train: epoch 0176, iter [00960, 01251], lr: 0.000826, loss: 0.4177
2022-09-30 13:34:43 - train: epoch 0176, iter [00970, 01251], lr: 0.000826, loss: 0.3962
2022-09-30 13:35:01 - train: epoch 0176, iter [00980, 01251], lr: 0.000826, loss: 0.4100
2022-09-30 13:35:19 - train: epoch 0176, iter [00990, 01251], lr: 0.000826, loss: 0.3999
2022-09-30 13:35:37 - train: epoch 0176, iter [01000, 01251], lr: 0.000826, loss: 0.4104
2022-09-30 13:35:54 - train: epoch 0176, iter [01010, 01251], lr: 0.000826, loss: 0.4005
2022-09-30 13:36:12 - train: epoch 0176, iter [01020, 01251], lr: 0.000826, loss: 0.4261
2022-09-30 13:36:30 - train: epoch 0176, iter [01030, 01251], lr: 0.000826, loss: 0.4173
2022-09-30 13:36:48 - train: epoch 0176, iter [01040, 01251], lr: 0.000826, loss: 0.4106
2022-09-30 13:37:05 - train: epoch 0176, iter [01050, 01251], lr: 0.000826, loss: 0.3984
2022-09-30 13:37:23 - train: epoch 0176, iter [01060, 01251], lr: 0.000826, loss: 0.4222
2022-09-30 13:37:41 - train: epoch 0176, iter [01070, 01251], lr: 0.000825, loss: 0.4183
2022-09-30 13:37:59 - train: epoch 0176, iter [01080, 01251], lr: 0.000825, loss: 0.4137
2022-09-30 13:38:17 - train: epoch 0176, iter [01090, 01251], lr: 0.000825, loss: 0.4154
2022-09-30 13:38:34 - train: epoch 0176, iter [01100, 01251], lr: 0.000825, loss: 0.4200
2022-09-30 13:38:52 - train: epoch 0176, iter [01110, 01251], lr: 0.000825, loss: 0.4159
2022-09-30 13:39:10 - train: epoch 0176, iter [01120, 01251], lr: 0.000825, loss: 0.4176
2022-09-30 13:39:27 - train: epoch 0176, iter [01130, 01251], lr: 0.000825, loss: 0.3884
2022-09-30 13:39:45 - train: epoch 0176, iter [01140, 01251], lr: 0.000825, loss: 0.4073
2022-09-30 13:40:03 - train: epoch 0176, iter [01150, 01251], lr: 0.000825, loss: 0.4113
2022-09-30 13:40:21 - train: epoch 0176, iter [01160, 01251], lr: 0.000825, loss: 0.3952
2022-09-30 13:40:38 - train: epoch 0176, iter [01170, 01251], lr: 0.000825, loss: 0.4008
2022-09-30 13:40:56 - train: epoch 0176, iter [01180, 01251], lr: 0.000825, loss: 0.3928
2022-09-30 13:41:14 - train: epoch 0176, iter [01190, 01251], lr: 0.000825, loss: 0.3931
2022-09-30 13:41:31 - train: epoch 0176, iter [01200, 01251], lr: 0.000825, loss: 0.3966
2022-09-30 13:41:49 - train: epoch 0176, iter [01210, 01251], lr: 0.000825, loss: 0.4257
2022-09-30 13:42:07 - train: epoch 0176, iter [01220, 01251], lr: 0.000825, loss: 0.3958
2022-09-30 13:42:24 - train: epoch 0176, iter [01230, 01251], lr: 0.000825, loss: 0.4076
2022-09-30 13:42:42 - train: epoch 0176, iter [01240, 01251], lr: 0.000825, loss: 0.4013
2022-09-30 13:42:59 - train: epoch 0176, iter [01250, 01251], lr: 0.000825, loss: 0.4433
2022-09-30 13:43:03 - train: epoch 176, train_loss: 0.4088
2022-09-30 13:43:06 - until epoch: 176, best_loss: 0.4088
2022-09-30 13:43:06 - epoch 177 lr: 0.000825
2022-09-30 13:43:31 - train: epoch 0177, iter [00010, 01251], lr: 0.000825, loss: 0.4093
2022-09-30 13:43:49 - train: epoch 0177, iter [00020, 01251], lr: 0.000825, loss: 0.4196
2022-09-30 13:44:06 - train: epoch 0177, iter [00030, 01251], lr: 0.000825, loss: 0.4015
2022-09-30 13:44:24 - train: epoch 0177, iter [00040, 01251], lr: 0.000825, loss: 0.3956
2022-09-30 13:44:42 - train: epoch 0177, iter [00050, 01251], lr: 0.000825, loss: 0.3998
2022-09-30 13:44:59 - train: epoch 0177, iter [00060, 01251], lr: 0.000825, loss: 0.3985
2022-09-30 13:45:17 - train: epoch 0177, iter [00070, 01251], lr: 0.000824, loss: 0.4006
2022-09-30 13:45:34 - train: epoch 0177, iter [00080, 01251], lr: 0.000824, loss: 0.4109
2022-09-30 13:45:52 - train: epoch 0177, iter [00090, 01251], lr: 0.000824, loss: 0.4033
2022-09-30 13:46:09 - train: epoch 0177, iter [00100, 01251], lr: 0.000824, loss: 0.3950
2022-09-30 13:46:27 - train: epoch 0177, iter [00110, 01251], lr: 0.000824, loss: 0.4015
2022-09-30 13:46:45 - train: epoch 0177, iter [00120, 01251], lr: 0.000824, loss: 0.4195
2022-09-30 13:47:02 - train: epoch 0177, iter [00130, 01251], lr: 0.000824, loss: 0.4097
2022-09-30 13:47:20 - train: epoch 0177, iter [00140, 01251], lr: 0.000824, loss: 0.4119
2022-09-30 13:47:37 - train: epoch 0177, iter [00150, 01251], lr: 0.000824, loss: 0.4108
2022-09-30 13:47:55 - train: epoch 0177, iter [00160, 01251], lr: 0.000824, loss: 0.4012
2022-09-30 13:48:13 - train: epoch 0177, iter [00170, 01251], lr: 0.000824, loss: 0.4004
2022-09-30 13:48:30 - train: epoch 0177, iter [00180, 01251], lr: 0.000824, loss: 0.4226
2022-09-30 13:48:48 - train: epoch 0177, iter [00190, 01251], lr: 0.000824, loss: 0.4121
2022-09-30 13:49:06 - train: epoch 0177, iter [00200, 01251], lr: 0.000824, loss: 0.4134
2022-09-30 13:49:23 - train: epoch 0177, iter [00210, 01251], lr: 0.000824, loss: 0.4351
2022-09-30 13:49:41 - train: epoch 0177, iter [00220, 01251], lr: 0.000824, loss: 0.4261
2022-09-30 13:49:59 - train: epoch 0177, iter [00230, 01251], lr: 0.000824, loss: 0.4130
2022-09-30 13:50:17 - train: epoch 0177, iter [00240, 01251], lr: 0.000824, loss: 0.4181
2022-09-30 13:50:35 - train: epoch 0177, iter [00250, 01251], lr: 0.000824, loss: 0.4038
2022-09-30 13:50:53 - train: epoch 0177, iter [00260, 01251], lr: 0.000824, loss: 0.4153
2022-09-30 13:51:11 - train: epoch 0177, iter [00270, 01251], lr: 0.000824, loss: 0.4032
2022-09-30 13:51:29 - train: epoch 0177, iter [00280, 01251], lr: 0.000824, loss: 0.4118
2022-09-30 13:51:47 - train: epoch 0177, iter [00290, 01251], lr: 0.000824, loss: 0.4133
2022-09-30 13:52:05 - train: epoch 0177, iter [00300, 01251], lr: 0.000824, loss: 0.4096
2022-09-30 13:52:23 - train: epoch 0177, iter [00310, 01251], lr: 0.000824, loss: 0.4080
2022-09-30 13:52:41 - train: epoch 0177, iter [00320, 01251], lr: 0.000824, loss: 0.4087
2022-09-30 13:52:59 - train: epoch 0177, iter [00330, 01251], lr: 0.000823, loss: 0.4062
2022-09-30 13:53:18 - train: epoch 0177, iter [00340, 01251], lr: 0.000823, loss: 0.4070
2022-09-30 13:53:35 - train: epoch 0177, iter [00350, 01251], lr: 0.000823, loss: 0.4273
2022-09-30 13:53:54 - train: epoch 0177, iter [00360, 01251], lr: 0.000823, loss: 0.3907
2022-09-30 13:54:12 - train: epoch 0177, iter [00370, 01251], lr: 0.000823, loss: 0.3919
2022-09-30 13:54:30 - train: epoch 0177, iter [00380, 01251], lr: 0.000823, loss: 0.4235
2022-09-30 13:54:48 - train: epoch 0177, iter [00390, 01251], lr: 0.000823, loss: 0.4074
2022-09-30 13:55:06 - train: epoch 0177, iter [00400, 01251], lr: 0.000823, loss: 0.4136
2022-09-30 13:55:24 - train: epoch 0177, iter [00410, 01251], lr: 0.000823, loss: 0.4262
2022-09-30 13:55:42 - train: epoch 0177, iter [00420, 01251], lr: 0.000823, loss: 0.4130
2022-09-30 13:56:01 - train: epoch 0177, iter [00430, 01251], lr: 0.000823, loss: 0.4096
2022-09-30 13:56:19 - train: epoch 0177, iter [00440, 01251], lr: 0.000823, loss: 0.4078
2022-09-30 13:56:37 - train: epoch 0177, iter [00450, 01251], lr: 0.000823, loss: 0.3786
2022-09-30 13:56:55 - train: epoch 0177, iter [00460, 01251], lr: 0.000823, loss: 0.4062
2022-09-30 13:57:13 - train: epoch 0177, iter [00470, 01251], lr: 0.000823, loss: 0.4192
2022-09-30 13:57:31 - train: epoch 0177, iter [00480, 01251], lr: 0.000823, loss: 0.3873
2022-09-30 13:57:49 - train: epoch 0177, iter [00490, 01251], lr: 0.000823, loss: 0.3795
2022-09-30 13:58:08 - train: epoch 0177, iter [00500, 01251], lr: 0.000823, loss: 0.4087
2022-09-30 13:58:26 - train: epoch 0177, iter [00510, 01251], lr: 0.000823, loss: 0.4008
2022-09-30 13:58:44 - train: epoch 0177, iter [00520, 01251], lr: 0.000823, loss: 0.4351
2022-09-30 13:59:02 - train: epoch 0177, iter [00530, 01251], lr: 0.000823, loss: 0.4082
2022-09-30 13:59:20 - train: epoch 0177, iter [00540, 01251], lr: 0.000823, loss: 0.4110
2022-09-30 13:59:38 - train: epoch 0177, iter [00550, 01251], lr: 0.000823, loss: 0.4042
2022-09-30 13:59:56 - train: epoch 0177, iter [00560, 01251], lr: 0.000823, loss: 0.4135
2022-09-30 14:00:15 - train: epoch 0177, iter [00570, 01251], lr: 0.000823, loss: 0.3898
2022-09-30 14:00:33 - train: epoch 0177, iter [00580, 01251], lr: 0.000823, loss: 0.4098
2022-09-30 14:00:51 - train: epoch 0177, iter [00590, 01251], lr: 0.000822, loss: 0.3969
2022-09-30 14:01:09 - train: epoch 0177, iter [00600, 01251], lr: 0.000822, loss: 0.3960
2022-09-30 14:01:27 - train: epoch 0177, iter [00610, 01251], lr: 0.000822, loss: 0.4027
2022-09-30 14:01:45 - train: epoch 0177, iter [00620, 01251], lr: 0.000822, loss: 0.4057
2022-09-30 14:02:03 - train: epoch 0177, iter [00630, 01251], lr: 0.000822, loss: 0.4028
2022-09-30 14:02:21 - train: epoch 0177, iter [00640, 01251], lr: 0.000822, loss: 0.4213
2022-09-30 14:02:39 - train: epoch 0177, iter [00650, 01251], lr: 0.000822, loss: 0.4066
2022-09-30 14:02:57 - train: epoch 0177, iter [00660, 01251], lr: 0.000822, loss: 0.4134
2022-09-30 14:03:16 - train: epoch 0177, iter [00670, 01251], lr: 0.000822, loss: 0.4299
2022-09-30 14:03:34 - train: epoch 0177, iter [00680, 01251], lr: 0.000822, loss: 0.3925
2022-09-30 14:03:52 - train: epoch 0177, iter [00690, 01251], lr: 0.000822, loss: 0.3952
2022-09-30 14:04:10 - train: epoch 0177, iter [00700, 01251], lr: 0.000822, loss: 0.4016
2022-09-30 14:04:28 - train: epoch 0177, iter [00710, 01251], lr: 0.000822, loss: 0.4028
2022-09-30 14:04:47 - train: epoch 0177, iter [00720, 01251], lr: 0.000822, loss: 0.3873
2022-09-30 14:05:05 - train: epoch 0177, iter [00730, 01251], lr: 0.000822, loss: 0.4139
2022-09-30 14:05:23 - train: epoch 0177, iter [00740, 01251], lr: 0.000822, loss: 0.3921
2022-09-30 14:05:41 - train: epoch 0177, iter [00750, 01251], lr: 0.000822, loss: 0.4055
2022-09-30 14:05:59 - train: epoch 0177, iter [00760, 01251], lr: 0.000822, loss: 0.4262
2022-09-30 14:06:17 - train: epoch 0177, iter [00770, 01251], lr: 0.000822, loss: 0.4017
2022-09-30 14:06:35 - train: epoch 0177, iter [00780, 01251], lr: 0.000822, loss: 0.4098
2022-09-30 14:06:53 - train: epoch 0177, iter [00790, 01251], lr: 0.000822, loss: 0.4140
2022-09-30 14:07:11 - train: epoch 0177, iter [00800, 01251], lr: 0.000822, loss: 0.3996
2022-09-30 14:07:30 - train: epoch 0177, iter [00810, 01251], lr: 0.000822, loss: 0.3998
2022-09-30 14:07:48 - train: epoch 0177, iter [00820, 01251], lr: 0.000822, loss: 0.3831
2022-09-30 14:08:06 - train: epoch 0177, iter [00830, 01251], lr: 0.000822, loss: 0.4202
2022-09-30 14:08:24 - train: epoch 0177, iter [00840, 01251], lr: 0.000822, loss: 0.4133
2022-09-30 14:08:42 - train: epoch 0177, iter [00850, 01251], lr: 0.000821, loss: 0.3985
2022-09-30 14:09:00 - train: epoch 0177, iter [00860, 01251], lr: 0.000821, loss: 0.3924
2022-09-30 14:09:18 - train: epoch 0177, iter [00870, 01251], lr: 0.000821, loss: 0.4209
2022-09-30 14:09:36 - train: epoch 0177, iter [00880, 01251], lr: 0.000821, loss: 0.4096
2022-09-30 14:09:55 - train: epoch 0177, iter [00890, 01251], lr: 0.000821, loss: 0.4200
2022-09-30 14:10:13 - train: epoch 0177, iter [00900, 01251], lr: 0.000821, loss: 0.3945
2022-09-30 14:10:31 - train: epoch 0177, iter [00910, 01251], lr: 0.000821, loss: 0.4101
2022-09-30 14:10:49 - train: epoch 0177, iter [00920, 01251], lr: 0.000821, loss: 0.3930
2022-09-30 14:11:07 - train: epoch 0177, iter [00930, 01251], lr: 0.000821, loss: 0.3991
2022-09-30 14:11:25 - train: epoch 0177, iter [00940, 01251], lr: 0.000821, loss: 0.4033
2022-09-30 14:11:43 - train: epoch 0177, iter [00950, 01251], lr: 0.000821, loss: 0.3999
2022-09-30 14:12:01 - train: epoch 0177, iter [00960, 01251], lr: 0.000821, loss: 0.4009
2022-09-30 14:12:19 - train: epoch 0177, iter [00970, 01251], lr: 0.000821, loss: 0.4191
2022-09-30 14:12:37 - train: epoch 0177, iter [00980, 01251], lr: 0.000821, loss: 0.3725
2022-09-30 14:12:55 - train: epoch 0177, iter [00990, 01251], lr: 0.000821, loss: 0.4230
2022-09-30 14:13:14 - train: epoch 0177, iter [01000, 01251], lr: 0.000821, loss: 0.3843
2022-09-30 14:13:32 - train: epoch 0177, iter [01010, 01251], lr: 0.000821, loss: 0.4015
2022-09-30 14:13:50 - train: epoch 0177, iter [01020, 01251], lr: 0.000821, loss: 0.4158
2022-09-30 14:14:08 - train: epoch 0177, iter [01030, 01251], lr: 0.000821, loss: 0.4016
2022-09-30 14:14:27 - train: epoch 0177, iter [01040, 01251], lr: 0.000821, loss: 0.3976
2022-09-30 14:14:45 - train: epoch 0177, iter [01050, 01251], lr: 0.000821, loss: 0.3984
2022-09-30 14:15:03 - train: epoch 0177, iter [01060, 01251], lr: 0.000821, loss: 0.4147
2022-09-30 14:15:21 - train: epoch 0177, iter [01070, 01251], lr: 0.000821, loss: 0.4069
2022-09-30 14:15:39 - train: epoch 0177, iter [01080, 01251], lr: 0.000821, loss: 0.4021
2022-09-30 14:15:58 - train: epoch 0177, iter [01090, 01251], lr: 0.000821, loss: 0.3984
2022-09-30 14:16:16 - train: epoch 0177, iter [01100, 01251], lr: 0.000820, loss: 0.4108
2022-09-30 14:16:34 - train: epoch 0177, iter [01110, 01251], lr: 0.000820, loss: 0.3998
2022-09-30 14:16:52 - train: epoch 0177, iter [01120, 01251], lr: 0.000820, loss: 0.4020
2022-09-30 14:17:10 - train: epoch 0177, iter [01130, 01251], lr: 0.000820, loss: 0.3972
2022-09-30 14:17:28 - train: epoch 0177, iter [01140, 01251], lr: 0.000820, loss: 0.4190
2022-09-30 14:17:46 - train: epoch 0177, iter [01150, 01251], lr: 0.000820, loss: 0.4012
2022-09-30 14:18:05 - train: epoch 0177, iter [01160, 01251], lr: 0.000820, loss: 0.3990
2022-09-30 14:18:22 - train: epoch 0177, iter [01170, 01251], lr: 0.000820, loss: 0.4230
2022-09-30 14:18:41 - train: epoch 0177, iter [01180, 01251], lr: 0.000820, loss: 0.3986
2022-09-30 14:18:59 - train: epoch 0177, iter [01190, 01251], lr: 0.000820, loss: 0.4171
2022-09-30 14:19:17 - train: epoch 0177, iter [01200, 01251], lr: 0.000820, loss: 0.3850
2022-09-30 14:19:34 - train: epoch 0177, iter [01210, 01251], lr: 0.000820, loss: 0.4085
2022-09-30 14:19:52 - train: epoch 0177, iter [01220, 01251], lr: 0.000820, loss: 0.4045
2022-09-30 14:20:10 - train: epoch 0177, iter [01230, 01251], lr: 0.000820, loss: 0.3997
2022-09-30 14:20:28 - train: epoch 0177, iter [01240, 01251], lr: 0.000820, loss: 0.4151
2022-09-30 14:20:45 - train: epoch 0177, iter [01250, 01251], lr: 0.000820, loss: 0.4201
2022-09-30 14:20:49 - train: epoch 177, train_loss: 0.4086
2022-09-30 14:20:52 - until epoch: 177, best_loss: 0.4086
2022-09-30 14:20:52 - epoch 178 lr: 0.000820
2022-09-30 14:21:18 - train: epoch 0178, iter [00010, 01251], lr: 0.000820, loss: 0.3959
2022-09-30 14:21:36 - train: epoch 0178, iter [00020, 01251], lr: 0.000820, loss: 0.4132
2022-09-30 14:21:54 - train: epoch 0178, iter [00030, 01251], lr: 0.000820, loss: 0.4240
2022-09-30 14:22:12 - train: epoch 0178, iter [00040, 01251], lr: 0.000820, loss: 0.4002
2022-09-30 14:22:30 - train: epoch 0178, iter [00050, 01251], lr: 0.000820, loss: 0.4059
2022-09-30 14:22:48 - train: epoch 0178, iter [00060, 01251], lr: 0.000820, loss: 0.4092
2022-09-30 14:23:06 - train: epoch 0178, iter [00070, 01251], lr: 0.000820, loss: 0.3958
2022-09-30 14:23:24 - train: epoch 0178, iter [00080, 01251], lr: 0.000820, loss: 0.4128
2022-09-30 14:23:42 - train: epoch 0178, iter [00090, 01251], lr: 0.000820, loss: 0.4008
2022-09-30 14:24:00 - train: epoch 0178, iter [00100, 01251], lr: 0.000820, loss: 0.4097
2022-09-30 14:24:18 - train: epoch 0178, iter [00110, 01251], lr: 0.000819, loss: 0.3851
2022-09-30 14:24:36 - train: epoch 0178, iter [00120, 01251], lr: 0.000819, loss: 0.3941
2022-09-30 14:24:53 - train: epoch 0178, iter [00130, 01251], lr: 0.000819, loss: 0.4189
2022-09-30 14:25:11 - train: epoch 0178, iter [00140, 01251], lr: 0.000819, loss: 0.3899
2022-09-30 14:25:29 - train: epoch 0178, iter [00150, 01251], lr: 0.000819, loss: 0.4079
2022-09-30 14:25:47 - train: epoch 0178, iter [00160, 01251], lr: 0.000819, loss: 0.3991
2022-09-30 14:26:05 - train: epoch 0178, iter [00170, 01251], lr: 0.000819, loss: 0.3884
2022-09-30 14:26:23 - train: epoch 0178, iter [00180, 01251], lr: 0.000819, loss: 0.4176
2022-09-30 14:26:41 - train: epoch 0178, iter [00190, 01251], lr: 0.000819, loss: 0.3828
2022-09-30 14:26:59 - train: epoch 0178, iter [00200, 01251], lr: 0.000819, loss: 0.4060
2022-09-30 14:27:17 - train: epoch 0178, iter [00210, 01251], lr: 0.000819, loss: 0.3970
2022-09-30 14:27:35 - train: epoch 0178, iter [00220, 01251], lr: 0.000819, loss: 0.3943
2022-09-30 14:27:53 - train: epoch 0178, iter [00230, 01251], lr: 0.000819, loss: 0.4008
2022-09-30 14:28:11 - train: epoch 0178, iter [00240, 01251], lr: 0.000819, loss: 0.4080
2022-09-30 14:28:28 - train: epoch 0178, iter [00250, 01251], lr: 0.000819, loss: 0.4175
2022-09-30 14:28:46 - train: epoch 0178, iter [00260, 01251], lr: 0.000819, loss: 0.3966
2022-09-30 14:29:04 - train: epoch 0178, iter [00270, 01251], lr: 0.000819, loss: 0.4120
2022-09-30 14:29:22 - train: epoch 0178, iter [00280, 01251], lr: 0.000819, loss: 0.4173
2022-09-30 14:29:40 - train: epoch 0178, iter [00290, 01251], lr: 0.000819, loss: 0.3969
2022-09-30 14:29:58 - train: epoch 0178, iter [00300, 01251], lr: 0.000819, loss: 0.4079
2022-09-30 14:30:16 - train: epoch 0178, iter [00310, 01251], lr: 0.000819, loss: 0.4082
2022-09-30 14:30:34 - train: epoch 0178, iter [00320, 01251], lr: 0.000819, loss: 0.3999
2022-09-30 14:30:52 - train: epoch 0178, iter [00330, 01251], lr: 0.000819, loss: 0.4050
2022-09-30 14:31:10 - train: epoch 0178, iter [00340, 01251], lr: 0.000819, loss: 0.4245
2022-09-30 14:31:28 - train: epoch 0178, iter [00350, 01251], lr: 0.000819, loss: 0.4260
2022-09-30 14:31:46 - train: epoch 0178, iter [00360, 01251], lr: 0.000818, loss: 0.4089
2022-09-30 14:32:04 - train: epoch 0178, iter [00370, 01251], lr: 0.000818, loss: 0.4174
2022-09-30 14:32:22 - train: epoch 0178, iter [00380, 01251], lr: 0.000818, loss: 0.4182
2022-09-30 14:32:40 - train: epoch 0178, iter [00390, 01251], lr: 0.000818, loss: 0.4085
2022-09-30 14:32:58 - train: epoch 0178, iter [00400, 01251], lr: 0.000818, loss: 0.4040
2022-09-30 14:33:16 - train: epoch 0178, iter [00410, 01251], lr: 0.000818, loss: 0.3825
2022-09-30 14:33:34 - train: epoch 0178, iter [00420, 01251], lr: 0.000818, loss: 0.4163
2022-09-30 14:33:52 - train: epoch 0178, iter [00430, 01251], lr: 0.000818, loss: 0.4334
2022-09-30 14:34:10 - train: epoch 0178, iter [00440, 01251], lr: 0.000818, loss: 0.3940
2022-09-30 14:34:28 - train: epoch 0178, iter [00450, 01251], lr: 0.000818, loss: 0.3934
2022-09-30 14:34:46 - train: epoch 0178, iter [00460, 01251], lr: 0.000818, loss: 0.4169
2022-09-30 14:35:04 - train: epoch 0178, iter [00470, 01251], lr: 0.000818, loss: 0.4033
2022-09-30 14:35:22 - train: epoch 0178, iter [00480, 01251], lr: 0.000818, loss: 0.4112
2022-09-30 14:35:40 - train: epoch 0178, iter [00490, 01251], lr: 0.000818, loss: 0.4237
2022-09-30 14:35:57 - train: epoch 0178, iter [00500, 01251], lr: 0.000818, loss: 0.3955
2022-09-30 14:36:15 - train: epoch 0178, iter [00510, 01251], lr: 0.000818, loss: 0.4133
2022-09-30 14:36:33 - train: epoch 0178, iter [00520, 01251], lr: 0.000818, loss: 0.3981
2022-09-30 14:36:51 - train: epoch 0178, iter [00530, 01251], lr: 0.000818, loss: 0.4068
2022-09-30 14:37:09 - train: epoch 0178, iter [00540, 01251], lr: 0.000818, loss: 0.4049
2022-09-30 14:37:27 - train: epoch 0178, iter [00550, 01251], lr: 0.000818, loss: 0.4164
2022-09-30 14:37:45 - train: epoch 0178, iter [00560, 01251], lr: 0.000818, loss: 0.3937
2022-09-30 14:38:03 - train: epoch 0178, iter [00570, 01251], lr: 0.000818, loss: 0.4247
2022-09-30 14:38:21 - train: epoch 0178, iter [00580, 01251], lr: 0.000818, loss: 0.4119
2022-09-30 14:38:39 - train: epoch 0178, iter [00590, 01251], lr: 0.000818, loss: 0.4265
2022-09-30 14:38:57 - train: epoch 0178, iter [00600, 01251], lr: 0.000818, loss: 0.4180
2022-09-30 14:39:15 - train: epoch 0178, iter [00610, 01251], lr: 0.000818, loss: 0.4135
2022-09-30 14:39:33 - train: epoch 0178, iter [00620, 01251], lr: 0.000817, loss: 0.3987
2022-09-30 14:39:51 - train: epoch 0178, iter [00630, 01251], lr: 0.000817, loss: 0.4115
2022-09-30 14:40:09 - train: epoch 0178, iter [00640, 01251], lr: 0.000817, loss: 0.3956
2022-09-30 14:40:27 - train: epoch 0178, iter [00650, 01251], lr: 0.000817, loss: 0.4056
2022-09-30 14:40:45 - train: epoch 0178, iter [00660, 01251], lr: 0.000817, loss: 0.4293
2022-09-30 14:41:03 - train: epoch 0178, iter [00670, 01251], lr: 0.000817, loss: 0.3994
2022-09-30 14:41:21 - train: epoch 0178, iter [00680, 01251], lr: 0.000817, loss: 0.4131
2022-09-30 14:41:39 - train: epoch 0178, iter [00690, 01251], lr: 0.000817, loss: 0.4102
2022-09-30 14:41:57 - train: epoch 0178, iter [00700, 01251], lr: 0.000817, loss: 0.4022
2022-09-30 14:42:15 - train: epoch 0178, iter [00710, 01251], lr: 0.000817, loss: 0.4004
2022-09-30 14:42:33 - train: epoch 0178, iter [00720, 01251], lr: 0.000817, loss: 0.4043
2022-09-30 14:42:51 - train: epoch 0178, iter [00730, 01251], lr: 0.000817, loss: 0.3955
2022-09-30 14:43:09 - train: epoch 0178, iter [00740, 01251], lr: 0.000817, loss: 0.4049
2022-09-30 14:43:27 - train: epoch 0178, iter [00750, 01251], lr: 0.000817, loss: 0.3966
2022-09-30 14:43:46 - train: epoch 0178, iter [00760, 01251], lr: 0.000817, loss: 0.4052
2022-09-30 14:44:04 - train: epoch 0178, iter [00770, 01251], lr: 0.000817, loss: 0.4069
2022-09-30 14:44:22 - train: epoch 0178, iter [00780, 01251], lr: 0.000817, loss: 0.4058
2022-09-30 14:44:40 - train: epoch 0178, iter [00790, 01251], lr: 0.000817, loss: 0.4192
2022-09-30 14:44:58 - train: epoch 0178, iter [00800, 01251], lr: 0.000817, loss: 0.3940
2022-09-30 14:45:15 - train: epoch 0178, iter [00810, 01251], lr: 0.000817, loss: 0.4151
2022-09-30 14:45:34 - train: epoch 0178, iter [00820, 01251], lr: 0.000817, loss: 0.4170
2022-09-30 14:45:52 - train: epoch 0178, iter [00830, 01251], lr: 0.000817, loss: 0.3958
2022-09-30 14:46:10 - train: epoch 0178, iter [00840, 01251], lr: 0.000817, loss: 0.3941
2022-09-30 14:46:28 - train: epoch 0178, iter [00850, 01251], lr: 0.000817, loss: 0.4146
2022-09-30 14:46:46 - train: epoch 0178, iter [00860, 01251], lr: 0.000817, loss: 0.4148
2022-09-30 14:47:05 - train: epoch 0178, iter [00870, 01251], lr: 0.000817, loss: 0.4047
2022-09-30 14:47:23 - train: epoch 0178, iter [00880, 01251], lr: 0.000816, loss: 0.4102
2022-09-30 14:47:41 - train: epoch 0178, iter [00890, 01251], lr: 0.000816, loss: 0.4102
2022-09-30 14:47:59 - train: epoch 0178, iter [00900, 01251], lr: 0.000816, loss: 0.4034
2022-09-30 14:48:18 - train: epoch 0178, iter [00910, 01251], lr: 0.000816, loss: 0.3994
2022-09-30 14:48:36 - train: epoch 0178, iter [00920, 01251], lr: 0.000816, loss: 0.4076
2022-09-30 14:48:54 - train: epoch 0178, iter [00930, 01251], lr: 0.000816, loss: 0.4156
2022-09-30 14:49:12 - train: epoch 0178, iter [00940, 01251], lr: 0.000816, loss: 0.4024
2022-09-30 14:49:30 - train: epoch 0178, iter [00950, 01251], lr: 0.000816, loss: 0.4191
2022-09-30 14:49:48 - train: epoch 0178, iter [00960, 01251], lr: 0.000816, loss: 0.3885
2022-09-30 14:50:07 - train: epoch 0178, iter [00970, 01251], lr: 0.000816, loss: 0.4160
2022-09-30 14:50:25 - train: epoch 0178, iter [00980, 01251], lr: 0.000816, loss: 0.4223
2022-09-30 14:50:43 - train: epoch 0178, iter [00990, 01251], lr: 0.000816, loss: 0.3971
2022-09-30 14:51:01 - train: epoch 0178, iter [01000, 01251], lr: 0.000816, loss: 0.4053
2022-09-30 14:51:19 - train: epoch 0178, iter [01010, 01251], lr: 0.000816, loss: 0.4002
2022-09-30 14:51:37 - train: epoch 0178, iter [01020, 01251], lr: 0.000816, loss: 0.4068
2022-09-30 14:51:56 - train: epoch 0178, iter [01030, 01251], lr: 0.000816, loss: 0.4051
2022-09-30 14:52:14 - train: epoch 0178, iter [01040, 01251], lr: 0.000816, loss: 0.4128
2022-09-30 14:52:32 - train: epoch 0178, iter [01050, 01251], lr: 0.000816, loss: 0.4205
2022-09-30 14:52:50 - train: epoch 0178, iter [01060, 01251], lr: 0.000816, loss: 0.4124
2022-09-30 14:53:08 - train: epoch 0178, iter [01070, 01251], lr: 0.000816, loss: 0.4193
2022-09-30 14:53:26 - train: epoch 0178, iter [01080, 01251], lr: 0.000816, loss: 0.3940
2022-09-30 14:53:44 - train: epoch 0178, iter [01090, 01251], lr: 0.000816, loss: 0.4018
2022-09-30 14:54:03 - train: epoch 0178, iter [01100, 01251], lr: 0.000816, loss: 0.4116
2022-09-30 14:54:21 - train: epoch 0178, iter [01110, 01251], lr: 0.000816, loss: 0.4010
2022-09-30 14:54:39 - train: epoch 0178, iter [01120, 01251], lr: 0.000816, loss: 0.3992
2022-09-30 14:54:57 - train: epoch 0178, iter [01130, 01251], lr: 0.000815, loss: 0.4209
2022-09-30 14:55:16 - train: epoch 0178, iter [01140, 01251], lr: 0.000815, loss: 0.4012
2022-09-30 14:55:34 - train: epoch 0178, iter [01150, 01251], lr: 0.000815, loss: 0.4287
2022-09-30 14:55:52 - train: epoch 0178, iter [01160, 01251], lr: 0.000815, loss: 0.4135
2022-09-30 14:56:11 - train: epoch 0178, iter [01170, 01251], lr: 0.000815, loss: 0.4308
2022-09-30 14:56:29 - train: epoch 0178, iter [01180, 01251], lr: 0.000815, loss: 0.4175
2022-09-30 14:56:47 - train: epoch 0178, iter [01190, 01251], lr: 0.000815, loss: 0.4098
2022-09-30 14:57:05 - train: epoch 0178, iter [01200, 01251], lr: 0.000815, loss: 0.3960
2022-09-30 14:57:24 - train: epoch 0178, iter [01210, 01251], lr: 0.000815, loss: 0.4047
2022-09-30 14:57:42 - train: epoch 0178, iter [01220, 01251], lr: 0.000815, loss: 0.3974
2022-09-30 14:58:00 - train: epoch 0178, iter [01230, 01251], lr: 0.000815, loss: 0.4206
2022-09-30 14:58:18 - train: epoch 0178, iter [01240, 01251], lr: 0.000815, loss: 0.4085
2022-09-30 14:58:36 - train: epoch 0178, iter [01250, 01251], lr: 0.000815, loss: 0.4072
2022-09-30 14:58:39 - train: epoch 178, train_loss: 0.4086
2022-09-30 14:58:42 - until epoch: 178, best_loss: 0.4086
2022-09-30 14:58:42 - epoch 179 lr: 0.000815
2022-09-30 14:59:08 - train: epoch 0179, iter [00010, 01251], lr: 0.000815, loss: 0.4179
2022-09-30 14:59:26 - train: epoch 0179, iter [00020, 01251], lr: 0.000815, loss: 0.4091
2022-09-30 14:59:44 - train: epoch 0179, iter [00030, 01251], lr: 0.000815, loss: 0.4206
2022-09-30 15:00:02 - train: epoch 0179, iter [00040, 01251], lr: 0.000815, loss: 0.3979
2022-09-30 15:00:20 - train: epoch 0179, iter [00050, 01251], lr: 0.000815, loss: 0.4030
2022-09-30 15:00:38 - train: epoch 0179, iter [00060, 01251], lr: 0.000815, loss: 0.3989
2022-09-30 15:00:56 - train: epoch 0179, iter [00070, 01251], lr: 0.000815, loss: 0.4124
2022-09-30 15:01:14 - train: epoch 0179, iter [00080, 01251], lr: 0.000815, loss: 0.3982
2022-09-30 15:01:31 - train: epoch 0179, iter [00090, 01251], lr: 0.000815, loss: 0.4121
2022-09-30 15:01:50 - train: epoch 0179, iter [00100, 01251], lr: 0.000815, loss: 0.4096
2022-09-30 15:02:08 - train: epoch 0179, iter [00110, 01251], lr: 0.000815, loss: 0.4192
2022-09-30 15:02:26 - train: epoch 0179, iter [00120, 01251], lr: 0.000815, loss: 0.3941
2022-09-30 15:02:44 - train: epoch 0179, iter [00130, 01251], lr: 0.000815, loss: 0.4385
2022-09-30 15:03:02 - train: epoch 0179, iter [00140, 01251], lr: 0.000814, loss: 0.4281
2022-09-30 15:03:19 - train: epoch 0179, iter [00150, 01251], lr: 0.000814, loss: 0.3874
2022-09-30 15:03:37 - train: epoch 0179, iter [00160, 01251], lr: 0.000814, loss: 0.4151
2022-09-30 15:03:55 - train: epoch 0179, iter [00170, 01251], lr: 0.000814, loss: 0.3994
2022-09-30 15:04:13 - train: epoch 0179, iter [00180, 01251], lr: 0.000814, loss: 0.4036
2022-09-30 15:04:31 - train: epoch 0179, iter [00190, 01251], lr: 0.000814, loss: 0.4111
2022-09-30 15:04:49 - train: epoch 0179, iter [00200, 01251], lr: 0.000814, loss: 0.3993
2022-09-30 15:05:07 - train: epoch 0179, iter [00210, 01251], lr: 0.000814, loss: 0.4103
2022-09-30 15:05:25 - train: epoch 0179, iter [00220, 01251], lr: 0.000814, loss: 0.3997
2022-09-30 15:05:42 - train: epoch 0179, iter [00230, 01251], lr: 0.000814, loss: 0.4077
2022-09-30 15:06:01 - train: epoch 0179, iter [00240, 01251], lr: 0.000814, loss: 0.4284
2022-09-30 15:06:19 - train: epoch 0179, iter [00250, 01251], lr: 0.000814, loss: 0.4120
2022-09-30 15:06:37 - train: epoch 0179, iter [00260, 01251], lr: 0.000814, loss: 0.4042
2022-09-30 15:06:55 - train: epoch 0179, iter [00270, 01251], lr: 0.000814, loss: 0.3961
2022-09-30 15:07:13 - train: epoch 0179, iter [00280, 01251], lr: 0.000814, loss: 0.3879
2022-09-30 15:07:31 - train: epoch 0179, iter [00290, 01251], lr: 0.000814, loss: 0.4171
2022-09-30 15:07:49 - train: epoch 0179, iter [00300, 01251], lr: 0.000814, loss: 0.4378
2022-09-30 15:08:07 - train: epoch 0179, iter [00310, 01251], lr: 0.000814, loss: 0.4066
2022-09-30 15:08:25 - train: epoch 0179, iter [00320, 01251], lr: 0.000814, loss: 0.4172
2022-09-30 15:08:43 - train: epoch 0179, iter [00330, 01251], lr: 0.000814, loss: 0.4103
2022-09-30 15:09:01 - train: epoch 0179, iter [00340, 01251], lr: 0.000814, loss: 0.4188
2022-09-30 15:09:19 - train: epoch 0179, iter [00350, 01251], lr: 0.000814, loss: 0.4276
2022-09-30 15:09:37 - train: epoch 0179, iter [00360, 01251], lr: 0.000814, loss: 0.3941
2022-09-30 15:09:55 - train: epoch 0179, iter [00370, 01251], lr: 0.000814, loss: 0.4376
2022-09-30 15:10:13 - train: epoch 0179, iter [00380, 01251], lr: 0.000814, loss: 0.4162
2022-09-30 15:10:31 - train: epoch 0179, iter [00390, 01251], lr: 0.000813, loss: 0.4194
2022-09-30 15:10:50 - train: epoch 0179, iter [00400, 01251], lr: 0.000813, loss: 0.4247
2022-09-30 15:11:07 - train: epoch 0179, iter [00410, 01251], lr: 0.000813, loss: 0.3799
2022-09-30 15:11:26 - train: epoch 0179, iter [00420, 01251], lr: 0.000813, loss: 0.4215
2022-09-30 15:11:44 - train: epoch 0179, iter [00430, 01251], lr: 0.000813, loss: 0.3885
2022-09-30 15:12:02 - train: epoch 0179, iter [00440, 01251], lr: 0.000813, loss: 0.3941
2022-09-30 15:12:20 - train: epoch 0179, iter [00450, 01251], lr: 0.000813, loss: 0.4203
2022-09-30 15:12:38 - train: epoch 0179, iter [00460, 01251], lr: 0.000813, loss: 0.4020
2022-09-30 15:12:56 - train: epoch 0179, iter [00470, 01251], lr: 0.000813, loss: 0.4290
2022-09-30 15:13:14 - train: epoch 0179, iter [00480, 01251], lr: 0.000813, loss: 0.4135
2022-09-30 15:13:32 - train: epoch 0179, iter [00490, 01251], lr: 0.000813, loss: 0.4185
2022-09-30 15:13:51 - train: epoch 0179, iter [00500, 01251], lr: 0.000813, loss: 0.4077
2022-09-30 15:14:09 - train: epoch 0179, iter [00510, 01251], lr: 0.000813, loss: 0.4215
2022-09-30 15:14:27 - train: epoch 0179, iter [00520, 01251], lr: 0.000813, loss: 0.4103
2022-09-30 15:14:45 - train: epoch 0179, iter [00530, 01251], lr: 0.000813, loss: 0.4256
2022-09-30 15:15:03 - train: epoch 0179, iter [00540, 01251], lr: 0.000813, loss: 0.4240
2022-09-30 15:15:22 - train: epoch 0179, iter [00550, 01251], lr: 0.000813, loss: 0.4113
2022-09-30 15:15:40 - train: epoch 0179, iter [00560, 01251], lr: 0.000813, loss: 0.4244
2022-09-30 15:15:58 - train: epoch 0179, iter [00570, 01251], lr: 0.000813, loss: 0.3798
2022-09-30 15:16:17 - train: epoch 0179, iter [00580, 01251], lr: 0.000813, loss: 0.4146
2022-09-30 15:16:35 - train: epoch 0179, iter [00590, 01251], lr: 0.000813, loss: 0.4237
2022-09-30 15:16:53 - train: epoch 0179, iter [00600, 01251], lr: 0.000813, loss: 0.3890
2022-09-30 15:17:11 - train: epoch 0179, iter [00610, 01251], lr: 0.000813, loss: 0.3979
2022-09-30 15:17:29 - train: epoch 0179, iter [00620, 01251], lr: 0.000813, loss: 0.3928
2022-09-30 15:17:48 - train: epoch 0179, iter [00630, 01251], lr: 0.000813, loss: 0.4048
2022-09-30 15:18:06 - train: epoch 0179, iter [00640, 01251], lr: 0.000813, loss: 0.3899
2022-09-30 15:18:24 - train: epoch 0179, iter [00650, 01251], lr: 0.000812, loss: 0.4058
2022-09-30 15:18:43 - train: epoch 0179, iter [00660, 01251], lr: 0.000812, loss: 0.4276
2022-09-30 15:19:01 - train: epoch 0179, iter [00670, 01251], lr: 0.000812, loss: 0.4211
2022-09-30 15:19:19 - train: epoch 0179, iter [00680, 01251], lr: 0.000812, loss: 0.4174
2022-09-30 15:19:38 - train: epoch 0179, iter [00690, 01251], lr: 0.000812, loss: 0.4140
2022-09-30 15:19:56 - train: epoch 0179, iter [00700, 01251], lr: 0.000812, loss: 0.3891
2022-09-30 15:20:14 - train: epoch 0179, iter [00710, 01251], lr: 0.000812, loss: 0.4103
2022-09-30 15:20:32 - train: epoch 0179, iter [00720, 01251], lr: 0.000812, loss: 0.4040
2022-09-30 15:20:50 - train: epoch 0179, iter [00730, 01251], lr: 0.000812, loss: 0.4055
2022-09-30 15:21:09 - train: epoch 0179, iter [00740, 01251], lr: 0.000812, loss: 0.4338
2022-09-30 15:21:27 - train: epoch 0179, iter [00750, 01251], lr: 0.000812, loss: 0.4114
2022-09-30 15:21:45 - train: epoch 0179, iter [00760, 01251], lr: 0.000812, loss: 0.4208
2022-09-30 15:22:03 - train: epoch 0179, iter [00770, 01251], lr: 0.000812, loss: 0.4056
2022-09-30 15:22:21 - train: epoch 0179, iter [00780, 01251], lr: 0.000812, loss: 0.4243
2022-09-30 15:22:39 - train: epoch 0179, iter [00790, 01251], lr: 0.000812, loss: 0.4145
2022-09-30 15:22:57 - train: epoch 0179, iter [00800, 01251], lr: 0.000812, loss: 0.3969
2022-09-30 15:23:16 - train: epoch 0179, iter [00810, 01251], lr: 0.000812, loss: 0.4026
2022-09-30 15:23:34 - train: epoch 0179, iter [00820, 01251], lr: 0.000812, loss: 0.3896
2022-09-30 15:23:52 - train: epoch 0179, iter [00830, 01251], lr: 0.000812, loss: 0.4062
2022-09-30 15:24:11 - train: epoch 0179, iter [00840, 01251], lr: 0.000812, loss: 0.4077
2022-09-30 15:24:29 - train: epoch 0179, iter [00850, 01251], lr: 0.000812, loss: 0.4105
2022-09-30 15:24:47 - train: epoch 0179, iter [00860, 01251], lr: 0.000812, loss: 0.4099
2022-09-30 15:25:05 - train: epoch 0179, iter [00870, 01251], lr: 0.000812, loss: 0.4267
2022-09-30 15:25:24 - train: epoch 0179, iter [00880, 01251], lr: 0.000812, loss: 0.3972
2022-09-30 15:25:42 - train: epoch 0179, iter [00890, 01251], lr: 0.000812, loss: 0.4034
2022-09-30 15:26:00 - train: epoch 0179, iter [00900, 01251], lr: 0.000811, loss: 0.3952
2022-09-30 15:26:19 - train: epoch 0179, iter [00910, 01251], lr: 0.000811, loss: 0.4010
2022-09-30 15:26:37 - train: epoch 0179, iter [00920, 01251], lr: 0.000811, loss: 0.4043
2022-09-30 15:26:55 - train: epoch 0179, iter [00930, 01251], lr: 0.000811, loss: 0.4257
2022-09-30 15:27:13 - train: epoch 0179, iter [00940, 01251], lr: 0.000811, loss: 0.4258
2022-09-30 15:27:31 - train: epoch 0179, iter [00950, 01251], lr: 0.000811, loss: 0.3975
2022-09-30 15:27:49 - train: epoch 0179, iter [00960, 01251], lr: 0.000811, loss: 0.4378
2022-09-30 15:28:08 - train: epoch 0179, iter [00970, 01251], lr: 0.000811, loss: 0.4102
2022-09-30 15:28:26 - train: epoch 0179, iter [00980, 01251], lr: 0.000811, loss: 0.4106
2022-09-30 15:28:44 - train: epoch 0179, iter [00990, 01251], lr: 0.000811, loss: 0.4202
2022-09-30 15:29:02 - train: epoch 0179, iter [01000, 01251], lr: 0.000811, loss: 0.3977
2022-09-30 15:29:20 - train: epoch 0179, iter [01010, 01251], lr: 0.000811, loss: 0.4255
2022-09-30 15:29:39 - train: epoch 0179, iter [01020, 01251], lr: 0.000811, loss: 0.4008
2022-09-30 15:29:56 - train: epoch 0179, iter [01030, 01251], lr: 0.000811, loss: 0.3939
2022-09-30 15:30:15 - train: epoch 0179, iter [01040, 01251], lr: 0.000811, loss: 0.4107
2022-09-30 15:30:33 - train: epoch 0179, iter [01050, 01251], lr: 0.000811, loss: 0.3973
2022-09-30 15:30:51 - train: epoch 0179, iter [01060, 01251], lr: 0.000811, loss: 0.4129
2022-09-30 15:31:09 - train: epoch 0179, iter [01070, 01251], lr: 0.000811, loss: 0.3781
2022-09-30 15:31:27 - train: epoch 0179, iter [01080, 01251], lr: 0.000811, loss: 0.3958
2022-09-30 15:31:45 - train: epoch 0179, iter [01090, 01251], lr: 0.000811, loss: 0.4041
2022-09-30 15:32:03 - train: epoch 0179, iter [01100, 01251], lr: 0.000811, loss: 0.4137
2022-09-30 15:32:21 - train: epoch 0179, iter [01110, 01251], lr: 0.000811, loss: 0.4139
2022-09-30 15:32:39 - train: epoch 0179, iter [01120, 01251], lr: 0.000811, loss: 0.4126
2022-09-30 15:32:58 - train: epoch 0179, iter [01130, 01251], lr: 0.000811, loss: 0.4021
2022-09-30 15:33:16 - train: epoch 0179, iter [01140, 01251], lr: 0.000811, loss: 0.4139
2022-09-30 15:33:35 - train: epoch 0179, iter [01150, 01251], lr: 0.000811, loss: 0.3998
2022-09-30 15:33:53 - train: epoch 0179, iter [01160, 01251], lr: 0.000810, loss: 0.3985
2022-09-30 15:34:12 - train: epoch 0179, iter [01170, 01251], lr: 0.000810, loss: 0.4032
2022-09-30 15:34:30 - train: epoch 0179, iter [01180, 01251], lr: 0.000810, loss: 0.4093
2022-09-30 15:34:48 - train: epoch 0179, iter [01190, 01251], lr: 0.000810, loss: 0.3912
2022-09-30 15:35:06 - train: epoch 0179, iter [01200, 01251], lr: 0.000810, loss: 0.4102
2022-09-30 15:35:25 - train: epoch 0179, iter [01210, 01251], lr: 0.000810, loss: 0.4177
2022-09-30 15:35:43 - train: epoch 0179, iter [01220, 01251], lr: 0.000810, loss: 0.4042
2022-09-30 15:36:01 - train: epoch 0179, iter [01230, 01251], lr: 0.000810, loss: 0.4272
2022-09-30 15:36:19 - train: epoch 0179, iter [01240, 01251], lr: 0.000810, loss: 0.4172
2022-09-30 15:36:37 - train: epoch 0179, iter [01250, 01251], lr: 0.000810, loss: 0.4117
2022-09-30 15:36:40 - train: epoch 179, train_loss: 0.4086
2022-09-30 15:36:42 - until epoch: 179, best_loss: 0.4086
2022-09-30 15:36:42 - epoch 180 lr: 0.000810
2022-09-30 15:37:07 - train: epoch 0180, iter [00010, 01251], lr: 0.000810, loss: 0.3992
2022-09-30 15:37:25 - train: epoch 0180, iter [00020, 01251], lr: 0.000810, loss: 0.3818
2022-09-30 15:37:43 - train: epoch 0180, iter [00030, 01251], lr: 0.000810, loss: 0.4088
2022-09-30 15:38:02 - train: epoch 0180, iter [00040, 01251], lr: 0.000810, loss: 0.3954
2022-09-30 15:38:20 - train: epoch 0180, iter [00050, 01251], lr: 0.000810, loss: 0.4186
2022-09-30 15:38:38 - train: epoch 0180, iter [00060, 01251], lr: 0.000810, loss: 0.4127
2022-09-30 15:38:56 - train: epoch 0180, iter [00070, 01251], lr: 0.000810, loss: 0.3945
2022-09-30 15:39:14 - train: epoch 0180, iter [00080, 01251], lr: 0.000810, loss: 0.3995
2022-09-30 15:39:32 - train: epoch 0180, iter [00090, 01251], lr: 0.000810, loss: 0.4221
2022-09-30 15:39:50 - train: epoch 0180, iter [00100, 01251], lr: 0.000810, loss: 0.4047
2022-09-30 15:40:08 - train: epoch 0180, iter [00110, 01251], lr: 0.000810, loss: 0.3995
2022-09-30 15:40:27 - train: epoch 0180, iter [00120, 01251], lr: 0.000810, loss: 0.3973
2022-09-30 15:40:45 - train: epoch 0180, iter [00130, 01251], lr: 0.000810, loss: 0.4120
2022-09-30 15:41:03 - train: epoch 0180, iter [00140, 01251], lr: 0.000810, loss: 0.3816
2022-09-30 15:41:21 - train: epoch 0180, iter [00150, 01251], lr: 0.000810, loss: 0.4073
2022-09-30 15:41:40 - train: epoch 0180, iter [00160, 01251], lr: 0.000809, loss: 0.3928
2022-09-30 15:41:58 - train: epoch 0180, iter [00170, 01251], lr: 0.000809, loss: 0.4035
2022-09-30 15:42:16 - train: epoch 0180, iter [00180, 01251], lr: 0.000809, loss: 0.4150
2022-09-30 15:42:35 - train: epoch 0180, iter [00190, 01251], lr: 0.000809, loss: 0.4258
2022-09-30 15:42:53 - train: epoch 0180, iter [00200, 01251], lr: 0.000809, loss: 0.3810
2022-09-30 15:43:11 - train: epoch 0180, iter [00210, 01251], lr: 0.000809, loss: 0.4278
2022-09-30 15:43:29 - train: epoch 0180, iter [00220, 01251], lr: 0.000809, loss: 0.4025
2022-09-30 15:43:48 - train: epoch 0180, iter [00230, 01251], lr: 0.000809, loss: 0.4155
2022-09-30 15:44:06 - train: epoch 0180, iter [00240, 01251], lr: 0.000809, loss: 0.4080
2022-09-30 15:44:24 - train: epoch 0180, iter [00250, 01251], lr: 0.000809, loss: 0.4139
2022-09-30 15:44:42 - train: epoch 0180, iter [00260, 01251], lr: 0.000809, loss: 0.4033
2022-09-30 15:45:01 - train: epoch 0180, iter [00270, 01251], lr: 0.000809, loss: 0.3991
2022-09-30 15:45:19 - train: epoch 0180, iter [00280, 01251], lr: 0.000809, loss: 0.4032
2022-09-30 15:45:37 - train: epoch 0180, iter [00290, 01251], lr: 0.000809, loss: 0.3767
2022-09-30 15:45:55 - train: epoch 0180, iter [00300, 01251], lr: 0.000809, loss: 0.4088
2022-09-30 15:46:13 - train: epoch 0180, iter [00310, 01251], lr: 0.000809, loss: 0.3794
2022-09-30 15:46:32 - train: epoch 0180, iter [00320, 01251], lr: 0.000809, loss: 0.3882
2022-09-30 15:46:49 - train: epoch 0180, iter [00330, 01251], lr: 0.000809, loss: 0.4056
2022-09-30 15:47:08 - train: epoch 0180, iter [00340, 01251], lr: 0.000809, loss: 0.4161
2022-09-30 15:47:26 - train: epoch 0180, iter [00350, 01251], lr: 0.000809, loss: 0.3966
2022-09-30 15:47:44 - train: epoch 0180, iter [00360, 01251], lr: 0.000809, loss: 0.4045
2022-09-30 15:48:02 - train: epoch 0180, iter [00370, 01251], lr: 0.000809, loss: 0.4003
2022-09-30 15:48:19 - train: epoch 0180, iter [00380, 01251], lr: 0.000809, loss: 0.3969
2022-09-30 15:48:37 - train: epoch 0180, iter [00390, 01251], lr: 0.000809, loss: 0.4245
2022-09-30 15:48:55 - train: epoch 0180, iter [00400, 01251], lr: 0.000809, loss: 0.4017
2022-09-30 15:49:13 - train: epoch 0180, iter [00410, 01251], lr: 0.000809, loss: 0.4024
2022-09-30 15:49:30 - train: epoch 0180, iter [00420, 01251], lr: 0.000808, loss: 0.3958
2022-09-30 15:49:48 - train: epoch 0180, iter [00430, 01251], lr: 0.000808, loss: 0.4148
2022-09-30 15:50:06 - train: epoch 0180, iter [00440, 01251], lr: 0.000808, loss: 0.4238
2022-09-30 15:50:24 - train: epoch 0180, iter [00450, 01251], lr: 0.000808, loss: 0.3930
2022-09-30 15:50:42 - train: epoch 0180, iter [00460, 01251], lr: 0.000808, loss: 0.4093
2022-09-30 15:51:00 - train: epoch 0180, iter [00470, 01251], lr: 0.000808, loss: 0.4079
2022-09-30 15:51:18 - train: epoch 0180, iter [00480, 01251], lr: 0.000808, loss: 0.4224
2022-09-30 15:51:36 - train: epoch 0180, iter [00490, 01251], lr: 0.000808, loss: 0.4082
2022-09-30 15:51:55 - train: epoch 0180, iter [00500, 01251], lr: 0.000808, loss: 0.4193
2022-09-30 15:52:14 - train: epoch 0180, iter [00510, 01251], lr: 0.000808, loss: 0.4039
2022-09-30 15:52:33 - train: epoch 0180, iter [00520, 01251], lr: 0.000808, loss: 0.4021
2022-09-30 15:52:52 - train: epoch 0180, iter [00530, 01251], lr: 0.000808, loss: 0.4103
2022-09-30 15:53:11 - train: epoch 0180, iter [00540, 01251], lr: 0.000808, loss: 0.3964
2022-09-30 15:53:30 - train: epoch 0180, iter [00550, 01251], lr: 0.000808, loss: 0.4055
2022-09-30 15:53:49 - train: epoch 0180, iter [00560, 01251], lr: 0.000808, loss: 0.4006
2022-09-30 15:54:07 - train: epoch 0180, iter [00570, 01251], lr: 0.000808, loss: 0.4150
2022-09-30 15:54:25 - train: epoch 0180, iter [00580, 01251], lr: 0.000808, loss: 0.4274
2022-09-30 15:54:42 - train: epoch 0180, iter [00590, 01251], lr: 0.000808, loss: 0.4256
2022-09-30 15:55:00 - train: epoch 0180, iter [00600, 01251], lr: 0.000808, loss: 0.4287
2022-09-30 15:55:18 - train: epoch 0180, iter [00610, 01251], lr: 0.000808, loss: 0.4207
2022-09-30 15:55:36 - train: epoch 0180, iter [00620, 01251], lr: 0.000808, loss: 0.4134
2022-09-30 15:55:53 - train: epoch 0180, iter [00630, 01251], lr: 0.000808, loss: 0.3978
2022-09-30 15:56:11 - train: epoch 0180, iter [00640, 01251], lr: 0.000808, loss: 0.4143
2022-09-30 15:56:29 - train: epoch 0180, iter [00650, 01251], lr: 0.000808, loss: 0.4036
2022-09-30 15:56:47 - train: epoch 0180, iter [00660, 01251], lr: 0.000808, loss: 0.4346
2022-09-30 15:57:05 - train: epoch 0180, iter [00670, 01251], lr: 0.000807, loss: 0.4045
2022-09-30 15:57:23 - train: epoch 0180, iter [00680, 01251], lr: 0.000807, loss: 0.3915
2022-09-30 15:57:41 - train: epoch 0180, iter [00690, 01251], lr: 0.000807, loss: 0.4223
2022-09-30 15:57:58 - train: epoch 0180, iter [00700, 01251], lr: 0.000807, loss: 0.4153
2022-09-30 15:58:16 - train: epoch 0180, iter [00710, 01251], lr: 0.000807, loss: 0.4197
2022-09-30 15:58:34 - train: epoch 0180, iter [00720, 01251], lr: 0.000807, loss: 0.4023
2022-09-30 15:58:52 - train: epoch 0180, iter [00730, 01251], lr: 0.000807, loss: 0.4070
2022-09-30 15:59:10 - train: epoch 0180, iter [00740, 01251], lr: 0.000807, loss: 0.3985
2022-09-30 15:59:27 - train: epoch 0180, iter [00750, 01251], lr: 0.000807, loss: 0.4065
2022-09-30 15:59:45 - train: epoch 0180, iter [00760, 01251], lr: 0.000807, loss: 0.4230
2022-09-30 16:00:03 - train: epoch 0180, iter [00770, 01251], lr: 0.000807, loss: 0.4111
2022-09-30 16:00:21 - train: epoch 0180, iter [00780, 01251], lr: 0.000807, loss: 0.3795
2022-09-30 16:00:39 - train: epoch 0180, iter [00790, 01251], lr: 0.000807, loss: 0.4081
2022-09-30 16:00:57 - train: epoch 0180, iter [00800, 01251], lr: 0.000807, loss: 0.4155
2022-09-30 16:01:15 - train: epoch 0180, iter [00810, 01251], lr: 0.000807, loss: 0.4142
2022-09-30 16:01:32 - train: epoch 0180, iter [00820, 01251], lr: 0.000807, loss: 0.4214
2022-09-30 16:01:50 - train: epoch 0180, iter [00830, 01251], lr: 0.000807, loss: 0.4033
2022-09-30 16:02:08 - train: epoch 0180, iter [00840, 01251], lr: 0.000807, loss: 0.3997
2022-09-30 16:02:26 - train: epoch 0180, iter [00850, 01251], lr: 0.000807, loss: 0.4186
2022-09-30 16:02:44 - train: epoch 0180, iter [00860, 01251], lr: 0.000807, loss: 0.4211
2022-09-30 16:03:02 - train: epoch 0180, iter [00870, 01251], lr: 0.000807, loss: 0.4127
2022-09-30 16:03:19 - train: epoch 0180, iter [00880, 01251], lr: 0.000807, loss: 0.4175
2022-09-30 16:03:37 - train: epoch 0180, iter [00890, 01251], lr: 0.000807, loss: 0.4186
2022-09-30 16:03:55 - train: epoch 0180, iter [00900, 01251], lr: 0.000807, loss: 0.4193
2022-09-30 16:04:13 - train: epoch 0180, iter [00910, 01251], lr: 0.000807, loss: 0.4167
2022-09-30 16:04:30 - train: epoch 0180, iter [00920, 01251], lr: 0.000807, loss: 0.4136
2022-09-30 16:04:48 - train: epoch 0180, iter [00930, 01251], lr: 0.000806, loss: 0.4048
2022-09-30 16:05:06 - train: epoch 0180, iter [00940, 01251], lr: 0.000806, loss: 0.4047
2022-09-30 16:05:24 - train: epoch 0180, iter [00950, 01251], lr: 0.000806, loss: 0.4021
2022-09-30 16:05:41 - train: epoch 0180, iter [00960, 01251], lr: 0.000806, loss: 0.4017
2022-09-30 16:05:59 - train: epoch 0180, iter [00970, 01251], lr: 0.000806, loss: 0.4315
2022-09-30 16:06:17 - train: epoch 0180, iter [00980, 01251], lr: 0.000806, loss: 0.4085
2022-09-30 16:06:35 - train: epoch 0180, iter [00990, 01251], lr: 0.000806, loss: 0.4140
2022-09-30 16:06:53 - train: epoch 0180, iter [01000, 01251], lr: 0.000806, loss: 0.4157
2022-09-30 16:07:11 - train: epoch 0180, iter [01010, 01251], lr: 0.000806, loss: 0.4121
2022-09-30 16:07:29 - train: epoch 0180, iter [01020, 01251], lr: 0.000806, loss: 0.4021
2022-09-30 16:07:46 - train: epoch 0180, iter [01030, 01251], lr: 0.000806, loss: 0.3883
2022-09-30 16:08:04 - train: epoch 0180, iter [01040, 01251], lr: 0.000806, loss: 0.3940
2022-09-30 16:08:22 - train: epoch 0180, iter [01050, 01251], lr: 0.000806, loss: 0.4065
2022-09-30 16:08:40 - train: epoch 0180, iter [01060, 01251], lr: 0.000806, loss: 0.4007
2022-09-30 16:08:58 - train: epoch 0180, iter [01070, 01251], lr: 0.000806, loss: 0.4204
2022-09-30 16:09:15 - train: epoch 0180, iter [01080, 01251], lr: 0.000806, loss: 0.4219
2022-09-30 16:09:33 - train: epoch 0180, iter [01090, 01251], lr: 0.000806, loss: 0.4004
2022-09-30 16:09:51 - train: epoch 0180, iter [01100, 01251], lr: 0.000806, loss: 0.4353
2022-09-30 16:10:09 - train: epoch 0180, iter [01110, 01251], lr: 0.000806, loss: 0.3952
2022-09-30 16:10:27 - train: epoch 0180, iter [01120, 01251], lr: 0.000806, loss: 0.3961
2022-09-30 16:10:45 - train: epoch 0180, iter [01130, 01251], lr: 0.000806, loss: 0.4153
2022-09-30 16:11:03 - train: epoch 0180, iter [01140, 01251], lr: 0.000806, loss: 0.4105
2022-09-30 16:11:20 - train: epoch 0180, iter [01150, 01251], lr: 0.000806, loss: 0.3998
2022-09-30 16:11:38 - train: epoch 0180, iter [01160, 01251], lr: 0.000806, loss: 0.4186
2022-09-30 16:11:56 - train: epoch 0180, iter [01170, 01251], lr: 0.000806, loss: 0.4050
2022-09-30 16:12:14 - train: epoch 0180, iter [01180, 01251], lr: 0.000805, loss: 0.4186
2022-09-30 16:12:32 - train: epoch 0180, iter [01190, 01251], lr: 0.000805, loss: 0.4065
2022-09-30 16:12:50 - train: epoch 0180, iter [01200, 01251], lr: 0.000805, loss: 0.4136
2022-09-30 16:13:07 - train: epoch 0180, iter [01210, 01251], lr: 0.000805, loss: 0.4011
2022-09-30 16:13:25 - train: epoch 0180, iter [01220, 01251], lr: 0.000805, loss: 0.4151
2022-09-30 16:13:43 - train: epoch 0180, iter [01230, 01251], lr: 0.000805, loss: 0.4015
2022-09-30 16:14:01 - train: epoch 0180, iter [01240, 01251], lr: 0.000805, loss: 0.4120
2022-09-30 16:14:19 - train: epoch 0180, iter [01250, 01251], lr: 0.000805, loss: 0.4226
2022-09-30 16:14:22 - train: epoch 180, train_loss: 0.4085
2022-09-30 16:14:25 - until epoch: 180, best_loss: 0.4085
2022-09-30 16:14:25 - epoch 181 lr: 0.000805
2022-09-30 16:14:50 - train: epoch 0181, iter [00010, 01251], lr: 0.000805, loss: 0.3992
2022-09-30 16:15:07 - train: epoch 0181, iter [00020, 01251], lr: 0.000805, loss: 0.4071
2022-09-30 16:15:25 - train: epoch 0181, iter [00030, 01251], lr: 0.000805, loss: 0.4027
2022-09-30 16:15:43 - train: epoch 0181, iter [00040, 01251], lr: 0.000805, loss: 0.3996
2022-09-30 16:16:00 - train: epoch 0181, iter [00050, 01251], lr: 0.000805, loss: 0.4043
2022-09-30 16:16:18 - train: epoch 0181, iter [00060, 01251], lr: 0.000805, loss: 0.4215
2022-09-30 16:16:36 - train: epoch 0181, iter [00070, 01251], lr: 0.000805, loss: 0.3974
2022-09-30 16:16:53 - train: epoch 0181, iter [00080, 01251], lr: 0.000805, loss: 0.4075
2022-09-30 16:17:11 - train: epoch 0181, iter [00090, 01251], lr: 0.000805, loss: 0.3994
2022-09-30 16:17:29 - train: epoch 0181, iter [00100, 01251], lr: 0.000805, loss: 0.4177
2022-09-30 16:17:46 - train: epoch 0181, iter [00110, 01251], lr: 0.000805, loss: 0.4125
2022-09-30 16:18:04 - train: epoch 0181, iter [00120, 01251], lr: 0.000805, loss: 0.4011
2022-09-30 16:18:22 - train: epoch 0181, iter [00130, 01251], lr: 0.000805, loss: 0.3988
2022-09-30 16:18:39 - train: epoch 0181, iter [00140, 01251], lr: 0.000805, loss: 0.4265
2022-09-30 16:18:57 - train: epoch 0181, iter [00150, 01251], lr: 0.000805, loss: 0.3998
2022-09-30 16:19:15 - train: epoch 0181, iter [00160, 01251], lr: 0.000805, loss: 0.3936
2022-09-30 16:19:33 - train: epoch 0181, iter [00170, 01251], lr: 0.000805, loss: 0.4191
2022-09-30 16:19:50 - train: epoch 0181, iter [00180, 01251], lr: 0.000805, loss: 0.4145
2022-09-30 16:20:08 - train: epoch 0181, iter [00190, 01251], lr: 0.000804, loss: 0.4099
2022-09-30 16:20:26 - train: epoch 0181, iter [00200, 01251], lr: 0.000804, loss: 0.4117
2022-09-30 16:20:44 - train: epoch 0181, iter [00210, 01251], lr: 0.000804, loss: 0.4103
2022-09-30 16:21:02 - train: epoch 0181, iter [00220, 01251], lr: 0.000804, loss: 0.4010
2022-09-30 16:21:19 - train: epoch 0181, iter [00230, 01251], lr: 0.000804, loss: 0.4111
2022-09-30 16:21:37 - train: epoch 0181, iter [00240, 01251], lr: 0.000804, loss: 0.4105
2022-09-30 16:21:55 - train: epoch 0181, iter [00250, 01251], lr: 0.000804, loss: 0.4143
2022-09-30 16:22:12 - train: epoch 0181, iter [00260, 01251], lr: 0.000804, loss: 0.4070
2022-09-30 16:22:30 - train: epoch 0181, iter [00270, 01251], lr: 0.000804, loss: 0.4310
2022-09-30 16:22:48 - train: epoch 0181, iter [00280, 01251], lr: 0.000804, loss: 0.4001
2022-09-30 16:23:06 - train: epoch 0181, iter [00290, 01251], lr: 0.000804, loss: 0.3988
2022-09-30 16:23:23 - train: epoch 0181, iter [00300, 01251], lr: 0.000804, loss: 0.3997
2022-09-30 16:23:41 - train: epoch 0181, iter [00310, 01251], lr: 0.000804, loss: 0.4151
2022-09-30 16:23:59 - train: epoch 0181, iter [00320, 01251], lr: 0.000804, loss: 0.4087
2022-09-30 16:24:16 - train: epoch 0181, iter [00330, 01251], lr: 0.000804, loss: 0.4171
2022-09-30 16:24:34 - train: epoch 0181, iter [00340, 01251], lr: 0.000804, loss: 0.4226
2022-09-30 16:24:52 - train: epoch 0181, iter [00350, 01251], lr: 0.000804, loss: 0.3922
2022-09-30 16:25:09 - train: epoch 0181, iter [00360, 01251], lr: 0.000804, loss: 0.3957
2022-09-30 16:25:27 - train: epoch 0181, iter [00370, 01251], lr: 0.000804, loss: 0.4085
2022-09-30 16:25:45 - train: epoch 0181, iter [00380, 01251], lr: 0.000804, loss: 0.4061
2022-09-30 16:26:03 - train: epoch 0181, iter [00390, 01251], lr: 0.000804, loss: 0.3967
2022-09-30 16:26:20 - train: epoch 0181, iter [00400, 01251], lr: 0.000804, loss: 0.4009
2022-09-30 16:26:38 - train: epoch 0181, iter [00410, 01251], lr: 0.000804, loss: 0.3901
2022-09-30 16:26:56 - train: epoch 0181, iter [00420, 01251], lr: 0.000804, loss: 0.3899
2022-09-30 16:27:13 - train: epoch 0181, iter [00430, 01251], lr: 0.000804, loss: 0.4039
2022-09-30 16:27:31 - train: epoch 0181, iter [00440, 01251], lr: 0.000803, loss: 0.4000
2022-09-30 16:27:49 - train: epoch 0181, iter [00450, 01251], lr: 0.000803, loss: 0.3986
2022-09-30 16:28:07 - train: epoch 0181, iter [00460, 01251], lr: 0.000803, loss: 0.4114
2022-09-30 16:28:24 - train: epoch 0181, iter [00470, 01251], lr: 0.000803, loss: 0.4133
2022-09-30 16:28:42 - train: epoch 0181, iter [00480, 01251], lr: 0.000803, loss: 0.4203
2022-09-30 16:29:00 - train: epoch 0181, iter [00490, 01251], lr: 0.000803, loss: 0.4000
2022-09-30 16:29:18 - train: epoch 0181, iter [00500, 01251], lr: 0.000803, loss: 0.4147
2022-09-30 16:29:35 - train: epoch 0181, iter [00510, 01251], lr: 0.000803, loss: 0.4066
2022-09-30 16:29:53 - train: epoch 0181, iter [00520, 01251], lr: 0.000803, loss: 0.4061
2022-09-30 16:30:11 - train: epoch 0181, iter [00530, 01251], lr: 0.000803, loss: 0.4206
2022-09-30 16:30:29 - train: epoch 0181, iter [00540, 01251], lr: 0.000803, loss: 0.4165
2022-09-30 16:30:46 - train: epoch 0181, iter [00550, 01251], lr: 0.000803, loss: 0.4172
2022-09-30 16:31:04 - train: epoch 0181, iter [00560, 01251], lr: 0.000803, loss: 0.3948
2022-09-30 16:31:22 - train: epoch 0181, iter [00570, 01251], lr: 0.000803, loss: 0.4098
2022-09-30 16:31:40 - train: epoch 0181, iter [00580, 01251], lr: 0.000803, loss: 0.4168
2022-09-30 16:31:57 - train: epoch 0181, iter [00590, 01251], lr: 0.000803, loss: 0.4147
2022-09-30 16:32:15 - train: epoch 0181, iter [00600, 01251], lr: 0.000803, loss: 0.3928
2022-09-30 16:32:33 - train: epoch 0181, iter [00610, 01251], lr: 0.000803, loss: 0.4103
2022-09-30 16:32:50 - train: epoch 0181, iter [00620, 01251], lr: 0.000803, loss: 0.4225
2022-09-30 16:33:08 - train: epoch 0181, iter [00630, 01251], lr: 0.000803, loss: 0.4257
2022-09-30 16:33:26 - train: epoch 0181, iter [00640, 01251], lr: 0.000803, loss: 0.4173
2022-09-30 16:33:43 - train: epoch 0181, iter [00650, 01251], lr: 0.000803, loss: 0.4142
2022-09-30 16:34:01 - train: epoch 0181, iter [00660, 01251], lr: 0.000803, loss: 0.4065
2022-09-30 16:34:19 - train: epoch 0181, iter [00670, 01251], lr: 0.000803, loss: 0.4101
2022-09-30 16:34:36 - train: epoch 0181, iter [00680, 01251], lr: 0.000803, loss: 0.3947
2022-09-30 16:34:54 - train: epoch 0181, iter [00690, 01251], lr: 0.000802, loss: 0.4025
2022-09-30 16:35:12 - train: epoch 0181, iter [00700, 01251], lr: 0.000802, loss: 0.4025
2022-09-30 16:35:29 - train: epoch 0181, iter [00710, 01251], lr: 0.000802, loss: 0.4023
2022-09-30 16:35:47 - train: epoch 0181, iter [00720, 01251], lr: 0.000802, loss: 0.4040
2022-09-30 16:36:05 - train: epoch 0181, iter [00730, 01251], lr: 0.000802, loss: 0.4106
2022-09-30 16:36:22 - train: epoch 0181, iter [00740, 01251], lr: 0.000802, loss: 0.4103
2022-09-30 16:36:40 - train: epoch 0181, iter [00750, 01251], lr: 0.000802, loss: 0.4179
2022-09-30 16:36:58 - train: epoch 0181, iter [00760, 01251], lr: 0.000802, loss: 0.4293
2022-09-30 16:37:16 - train: epoch 0181, iter [00770, 01251], lr: 0.000802, loss: 0.3940
2022-09-30 16:37:33 - train: epoch 0181, iter [00780, 01251], lr: 0.000802, loss: 0.4153
2022-09-30 16:37:51 - train: epoch 0181, iter [00790, 01251], lr: 0.000802, loss: 0.4027
2022-09-30 16:38:09 - train: epoch 0181, iter [00800, 01251], lr: 0.000802, loss: 0.4078
2022-09-30 16:38:26 - train: epoch 0181, iter [00810, 01251], lr: 0.000802, loss: 0.3982
2022-09-30 16:38:44 - train: epoch 0181, iter [00820, 01251], lr: 0.000802, loss: 0.3931
2022-09-30 16:39:02 - train: epoch 0181, iter [00830, 01251], lr: 0.000802, loss: 0.4113
2022-09-30 16:39:20 - train: epoch 0181, iter [00840, 01251], lr: 0.000802, loss: 0.3790
2022-09-30 16:39:37 - train: epoch 0181, iter [00850, 01251], lr: 0.000802, loss: 0.4155
2022-09-30 16:39:55 - train: epoch 0181, iter [00860, 01251], lr: 0.000802, loss: 0.4088
2022-09-30 16:40:13 - train: epoch 0181, iter [00870, 01251], lr: 0.000802, loss: 0.4116
2022-09-30 16:40:31 - train: epoch 0181, iter [00880, 01251], lr: 0.000802, loss: 0.3980
2022-09-30 16:40:48 - train: epoch 0181, iter [00890, 01251], lr: 0.000802, loss: 0.4283
2022-09-30 16:41:06 - train: epoch 0181, iter [00900, 01251], lr: 0.000802, loss: 0.3781
2022-09-30 16:41:24 - train: epoch 0181, iter [00910, 01251], lr: 0.000802, loss: 0.4145
2022-09-30 16:41:41 - train: epoch 0181, iter [00920, 01251], lr: 0.000802, loss: 0.4094
2022-09-30 16:41:59 - train: epoch 0181, iter [00930, 01251], lr: 0.000802, loss: 0.3933
2022-09-30 16:42:17 - train: epoch 0181, iter [00940, 01251], lr: 0.000802, loss: 0.4113
2022-09-30 16:42:34 - train: epoch 0181, iter [00950, 01251], lr: 0.000801, loss: 0.3968
2022-09-30 16:42:52 - train: epoch 0181, iter [00960, 01251], lr: 0.000801, loss: 0.4101
2022-09-30 16:43:10 - train: epoch 0181, iter [00970, 01251], lr: 0.000801, loss: 0.4129
2022-09-30 16:43:27 - train: epoch 0181, iter [00980, 01251], lr: 0.000801, loss: 0.4023
2022-09-30 16:43:45 - train: epoch 0181, iter [00990, 01251], lr: 0.000801, loss: 0.4049
2022-09-30 16:44:03 - train: epoch 0181, iter [01000, 01251], lr: 0.000801, loss: 0.4033
2022-09-30 16:44:20 - train: epoch 0181, iter [01010, 01251], lr: 0.000801, loss: 0.4138
2022-09-30 16:44:38 - train: epoch 0181, iter [01020, 01251], lr: 0.000801, loss: 0.4339
2022-09-30 16:44:56 - train: epoch 0181, iter [01030, 01251], lr: 0.000801, loss: 0.3931
2022-09-30 16:45:14 - train: epoch 0181, iter [01040, 01251], lr: 0.000801, loss: 0.4083
2022-09-30 16:45:31 - train: epoch 0181, iter [01050, 01251], lr: 0.000801, loss: 0.4064
2022-09-30 16:45:49 - train: epoch 0181, iter [01060, 01251], lr: 0.000801, loss: 0.4122
2022-09-30 16:46:07 - train: epoch 0181, iter [01070, 01251], lr: 0.000801, loss: 0.4076
2022-09-30 16:46:25 - train: epoch 0181, iter [01080, 01251], lr: 0.000801, loss: 0.4231
2022-09-30 16:46:42 - train: epoch 0181, iter [01090, 01251], lr: 0.000801, loss: 0.4075
2022-09-30 16:47:00 - train: epoch 0181, iter [01100, 01251], lr: 0.000801, loss: 0.4126
2022-09-30 16:47:18 - train: epoch 0181, iter [01110, 01251], lr: 0.000801, loss: 0.4115
2022-09-30 16:47:35 - train: epoch 0181, iter [01120, 01251], lr: 0.000801, loss: 0.3868
2022-09-30 16:47:53 - train: epoch 0181, iter [01130, 01251], lr: 0.000801, loss: 0.4150
2022-09-30 16:48:11 - train: epoch 0181, iter [01140, 01251], lr: 0.000801, loss: 0.4189
2022-09-30 16:48:29 - train: epoch 0181, iter [01150, 01251], lr: 0.000801, loss: 0.4112
2022-09-30 16:48:46 - train: epoch 0181, iter [01160, 01251], lr: 0.000801, loss: 0.4188
2022-09-30 16:49:04 - train: epoch 0181, iter [01170, 01251], lr: 0.000801, loss: 0.4124
2022-09-30 16:49:22 - train: epoch 0181, iter [01180, 01251], lr: 0.000801, loss: 0.3961
2022-09-30 16:49:39 - train: epoch 0181, iter [01190, 01251], lr: 0.000801, loss: 0.4063
2022-09-30 16:49:57 - train: epoch 0181, iter [01200, 01251], lr: 0.000800, loss: 0.4103
2022-09-30 16:50:15 - train: epoch 0181, iter [01210, 01251], lr: 0.000800, loss: 0.4127
2022-09-30 16:50:32 - train: epoch 0181, iter [01220, 01251], lr: 0.000800, loss: 0.4063
2022-09-30 16:50:50 - train: epoch 0181, iter [01230, 01251], lr: 0.000800, loss: 0.4277
2022-09-30 16:51:08 - train: epoch 0181, iter [01240, 01251], lr: 0.000800, loss: 0.4087
2022-09-30 16:51:25 - train: epoch 0181, iter [01250, 01251], lr: 0.000800, loss: 0.4075
2022-09-30 16:51:29 - train: epoch 181, train_loss: 0.4084
2022-09-30 16:51:32 - until epoch: 181, best_loss: 0.4084
2022-09-30 16:51:32 - epoch 182 lr: 0.000800
2022-09-30 16:51:57 - train: epoch 0182, iter [00010, 01251], lr: 0.000800, loss: 0.4132
2022-09-30 16:52:14 - train: epoch 0182, iter [00020, 01251], lr: 0.000800, loss: 0.4072
2022-09-30 16:52:32 - train: epoch 0182, iter [00030, 01251], lr: 0.000800, loss: 0.4138
2022-09-30 16:52:50 - train: epoch 0182, iter [00040, 01251], lr: 0.000800, loss: 0.4099
2022-09-30 16:53:07 - train: epoch 0182, iter [00050, 01251], lr: 0.000800, loss: 0.3952
2022-09-30 16:53:25 - train: epoch 0182, iter [00060, 01251], lr: 0.000800, loss: 0.4007
2022-09-30 16:53:43 - train: epoch 0182, iter [00070, 01251], lr: 0.000800, loss: 0.4056
2022-09-30 16:54:01 - train: epoch 0182, iter [00080, 01251], lr: 0.000800, loss: 0.4113
2022-09-30 16:54:18 - train: epoch 0182, iter [00090, 01251], lr: 0.000800, loss: 0.4018
2022-09-30 16:54:36 - train: epoch 0182, iter [00100, 01251], lr: 0.000800, loss: 0.4071
2022-09-30 16:54:54 - train: epoch 0182, iter [00110, 01251], lr: 0.000800, loss: 0.4043
2022-09-30 16:55:11 - train: epoch 0182, iter [00120, 01251], lr: 0.000800, loss: 0.3814
2022-09-30 16:55:29 - train: epoch 0182, iter [00130, 01251], lr: 0.000800, loss: 0.4068
2022-09-30 16:55:47 - train: epoch 0182, iter [00140, 01251], lr: 0.000800, loss: 0.4014
2022-09-30 16:56:04 - train: epoch 0182, iter [00150, 01251], lr: 0.000800, loss: 0.4153
2022-09-30 16:56:22 - train: epoch 0182, iter [00160, 01251], lr: 0.000800, loss: 0.4175
2022-09-30 16:56:40 - train: epoch 0182, iter [00170, 01251], lr: 0.000800, loss: 0.4123
2022-09-30 16:56:58 - train: epoch 0182, iter [00180, 01251], lr: 0.000800, loss: 0.4218
2022-09-30 16:57:15 - train: epoch 0182, iter [00190, 01251], lr: 0.000800, loss: 0.4146
2022-09-30 16:57:33 - train: epoch 0182, iter [00200, 01251], lr: 0.000799, loss: 0.4027
2022-09-30 16:57:51 - train: epoch 0182, iter [00210, 01251], lr: 0.000799, loss: 0.4101
2022-09-30 16:58:08 - train: epoch 0182, iter [00220, 01251], lr: 0.000799, loss: 0.3930
2022-09-30 16:58:26 - train: epoch 0182, iter [00230, 01251], lr: 0.000799, loss: 0.4140
2022-09-30 16:58:44 - train: epoch 0182, iter [00240, 01251], lr: 0.000799, loss: 0.4092
2022-09-30 16:59:02 - train: epoch 0182, iter [00250, 01251], lr: 0.000799, loss: 0.4173
2022-09-30 16:59:19 - train: epoch 0182, iter [00260, 01251], lr: 0.000799, loss: 0.4116
2022-09-30 16:59:37 - train: epoch 0182, iter [00270, 01251], lr: 0.000799, loss: 0.4109
2022-09-30 16:59:55 - train: epoch 0182, iter [00280, 01251], lr: 0.000799, loss: 0.4138
2022-09-30 17:00:12 - train: epoch 0182, iter [00290, 01251], lr: 0.000799, loss: 0.4073
2022-09-30 17:00:30 - train: epoch 0182, iter [00300, 01251], lr: 0.000799, loss: 0.4003
2022-09-30 17:00:48 - train: epoch 0182, iter [00310, 01251], lr: 0.000799, loss: 0.3975
2022-09-30 17:01:06 - train: epoch 0182, iter [00320, 01251], lr: 0.000799, loss: 0.3989
2022-09-30 17:01:23 - train: epoch 0182, iter [00330, 01251], lr: 0.000799, loss: 0.4116
2022-09-30 17:01:41 - train: epoch 0182, iter [00340, 01251], lr: 0.000799, loss: 0.4084
2022-09-30 17:01:59 - train: epoch 0182, iter [00350, 01251], lr: 0.000799, loss: 0.4118
2022-09-30 17:02:17 - train: epoch 0182, iter [00360, 01251], lr: 0.000799, loss: 0.4135
2022-09-30 17:02:35 - train: epoch 0182, iter [00370, 01251], lr: 0.000799, loss: 0.3947
2022-09-30 17:02:52 - train: epoch 0182, iter [00380, 01251], lr: 0.000799, loss: 0.4021
2022-09-30 17:03:10 - train: epoch 0182, iter [00390, 01251], lr: 0.000799, loss: 0.4006
2022-09-30 17:03:28 - train: epoch 0182, iter [00400, 01251], lr: 0.000799, loss: 0.4014
2022-09-30 17:03:45 - train: epoch 0182, iter [00410, 01251], lr: 0.000799, loss: 0.4259
2022-09-30 17:04:03 - train: epoch 0182, iter [00420, 01251], lr: 0.000799, loss: 0.4363
2022-09-30 17:04:21 - train: epoch 0182, iter [00430, 01251], lr: 0.000799, loss: 0.4114
2022-09-30 17:04:39 - train: epoch 0182, iter [00440, 01251], lr: 0.000799, loss: 0.4021
2022-09-30 17:04:56 - train: epoch 0182, iter [00450, 01251], lr: 0.000799, loss: 0.4161
2022-09-30 17:05:14 - train: epoch 0182, iter [00460, 01251], lr: 0.000798, loss: 0.3918
2022-09-30 17:05:32 - train: epoch 0182, iter [00470, 01251], lr: 0.000798, loss: 0.4022
2022-09-30 17:05:50 - train: epoch 0182, iter [00480, 01251], lr: 0.000798, loss: 0.4109
2022-09-30 17:06:07 - train: epoch 0182, iter [00490, 01251], lr: 0.000798, loss: 0.4231
2022-09-30 17:06:25 - train: epoch 0182, iter [00500, 01251], lr: 0.000798, loss: 0.4153
2022-09-30 17:06:43 - train: epoch 0182, iter [00510, 01251], lr: 0.000798, loss: 0.4017
2022-09-30 17:07:00 - train: epoch 0182, iter [00520, 01251], lr: 0.000798, loss: 0.4228
2022-09-30 17:07:18 - train: epoch 0182, iter [00530, 01251], lr: 0.000798, loss: 0.4219
2022-09-30 17:07:36 - train: epoch 0182, iter [00540, 01251], lr: 0.000798, loss: 0.4123
2022-09-30 17:07:54 - train: epoch 0182, iter [00550, 01251], lr: 0.000798, loss: 0.4095
2022-09-30 17:08:11 - train: epoch 0182, iter [00560, 01251], lr: 0.000798, loss: 0.3943
2022-09-30 17:08:29 - train: epoch 0182, iter [00570, 01251], lr: 0.000798, loss: 0.3980
2022-09-30 17:08:47 - train: epoch 0182, iter [00580, 01251], lr: 0.000798, loss: 0.4134
2022-09-30 17:09:05 - train: epoch 0182, iter [00590, 01251], lr: 0.000798, loss: 0.4248
2022-09-30 17:09:22 - train: epoch 0182, iter [00600, 01251], lr: 0.000798, loss: 0.4082
2022-09-30 17:09:40 - train: epoch 0182, iter [00610, 01251], lr: 0.000798, loss: 0.4241
2022-09-30 17:09:57 - train: epoch 0182, iter [00620, 01251], lr: 0.000798, loss: 0.4030
2022-09-30 17:10:15 - train: epoch 0182, iter [00630, 01251], lr: 0.000798, loss: 0.4037
2022-09-30 17:10:33 - train: epoch 0182, iter [00640, 01251], lr: 0.000798, loss: 0.4136
2022-09-30 17:10:51 - train: epoch 0182, iter [00650, 01251], lr: 0.000798, loss: 0.4100
2022-09-30 17:11:08 - train: epoch 0182, iter [00660, 01251], lr: 0.000798, loss: 0.4287
2022-09-30 17:11:26 - train: epoch 0182, iter [00670, 01251], lr: 0.000798, loss: 0.4025
2022-09-30 17:11:44 - train: epoch 0182, iter [00680, 01251], lr: 0.000798, loss: 0.4269
2022-09-30 17:12:01 - train: epoch 0182, iter [00690, 01251], lr: 0.000798, loss: 0.4292
2022-09-30 17:12:19 - train: epoch 0182, iter [00700, 01251], lr: 0.000798, loss: 0.4170
2022-09-30 17:12:37 - train: epoch 0182, iter [00710, 01251], lr: 0.000797, loss: 0.4012
2022-09-30 17:12:54 - train: epoch 0182, iter [00720, 01251], lr: 0.000797, loss: 0.4209
2022-09-30 17:13:12 - train: epoch 0182, iter [00730, 01251], lr: 0.000797, loss: 0.4192
2022-09-30 17:13:30 - train: epoch 0182, iter [00740, 01251], lr: 0.000797, loss: 0.4234
2022-09-30 17:13:47 - train: epoch 0182, iter [00750, 01251], lr: 0.000797, loss: 0.4107
2022-09-30 17:14:05 - train: epoch 0182, iter [00760, 01251], lr: 0.000797, loss: 0.4041
2022-09-30 17:14:23 - train: epoch 0182, iter [00770, 01251], lr: 0.000797, loss: 0.4025
2022-09-30 17:14:41 - train: epoch 0182, iter [00780, 01251], lr: 0.000797, loss: 0.4171
2022-09-30 17:14:58 - train: epoch 0182, iter [00790, 01251], lr: 0.000797, loss: 0.4132
2022-09-30 17:15:16 - train: epoch 0182, iter [00800, 01251], lr: 0.000797, loss: 0.4329
2022-09-30 17:15:34 - train: epoch 0182, iter [00810, 01251], lr: 0.000797, loss: 0.4032
2022-09-30 17:15:51 - train: epoch 0182, iter [00820, 01251], lr: 0.000797, loss: 0.4142
2022-09-30 17:16:09 - train: epoch 0182, iter [00830, 01251], lr: 0.000797, loss: 0.3990
2022-09-30 17:16:27 - train: epoch 0182, iter [00840, 01251], lr: 0.000797, loss: 0.4053
2022-09-30 17:16:44 - train: epoch 0182, iter [00850, 01251], lr: 0.000797, loss: 0.4172
2022-09-30 17:17:02 - train: epoch 0182, iter [00860, 01251], lr: 0.000797, loss: 0.4020
2022-09-30 17:17:20 - train: epoch 0182, iter [00870, 01251], lr: 0.000797, loss: 0.4082
2022-09-30 17:17:38 - train: epoch 0182, iter [00880, 01251], lr: 0.000797, loss: 0.4060
2022-09-30 17:17:55 - train: epoch 0182, iter [00890, 01251], lr: 0.000797, loss: 0.4162
2022-09-30 17:18:13 - train: epoch 0182, iter [00900, 01251], lr: 0.000797, loss: 0.4005
2022-09-30 17:18:31 - train: epoch 0182, iter [00910, 01251], lr: 0.000797, loss: 0.4215
2022-09-30 17:18:48 - train: epoch 0182, iter [00920, 01251], lr: 0.000797, loss: 0.4048
2022-09-30 17:19:06 - train: epoch 0182, iter [00930, 01251], lr: 0.000797, loss: 0.3984
2022-09-30 17:19:24 - train: epoch 0182, iter [00940, 01251], lr: 0.000797, loss: 0.4047
2022-09-30 17:19:41 - train: epoch 0182, iter [00950, 01251], lr: 0.000797, loss: 0.4163
2022-09-30 17:19:59 - train: epoch 0182, iter [00960, 01251], lr: 0.000796, loss: 0.4162
2022-09-30 17:20:17 - train: epoch 0182, iter [00970, 01251], lr: 0.000796, loss: 0.4134
2022-09-30 17:20:35 - train: epoch 0182, iter [00980, 01251], lr: 0.000796, loss: 0.3898
2022-09-30 17:20:52 - train: epoch 0182, iter [00990, 01251], lr: 0.000796, loss: 0.4281
2022-09-30 17:21:10 - train: epoch 0182, iter [01000, 01251], lr: 0.000796, loss: 0.4187
2022-09-30 17:21:28 - train: epoch 0182, iter [01010, 01251], lr: 0.000796, loss: 0.4020
2022-09-30 17:21:45 - train: epoch 0182, iter [01020, 01251], lr: 0.000796, loss: 0.4046
2022-09-30 17:22:03 - train: epoch 0182, iter [01030, 01251], lr: 0.000796, loss: 0.4140
2022-09-30 17:22:21 - train: epoch 0182, iter [01040, 01251], lr: 0.000796, loss: 0.4242
2022-09-30 17:22:38 - train: epoch 0182, iter [01050, 01251], lr: 0.000796, loss: 0.4134
2022-09-30 17:22:56 - train: epoch 0182, iter [01060, 01251], lr: 0.000796, loss: 0.4127
2022-09-30 17:23:14 - train: epoch 0182, iter [01070, 01251], lr: 0.000796, loss: 0.3878
2022-09-30 17:23:31 - train: epoch 0182, iter [01080, 01251], lr: 0.000796, loss: 0.4227
2022-09-30 17:23:49 - train: epoch 0182, iter [01090, 01251], lr: 0.000796, loss: 0.4159
2022-09-30 17:24:06 - train: epoch 0182, iter [01100, 01251], lr: 0.000796, loss: 0.3990
2022-09-30 17:24:24 - train: epoch 0182, iter [01110, 01251], lr: 0.000796, loss: 0.4057
2022-09-30 17:24:42 - train: epoch 0182, iter [01120, 01251], lr: 0.000796, loss: 0.4082
2022-09-30 17:25:00 - train: epoch 0182, iter [01130, 01251], lr: 0.000796, loss: 0.4176
2022-09-30 17:25:17 - train: epoch 0182, iter [01140, 01251], lr: 0.000796, loss: 0.4210
2022-09-30 17:25:35 - train: epoch 0182, iter [01150, 01251], lr: 0.000796, loss: 0.4090
2022-09-30 17:25:53 - train: epoch 0182, iter [01160, 01251], lr: 0.000796, loss: 0.4323
2022-09-30 17:26:11 - train: epoch 0182, iter [01170, 01251], lr: 0.000796, loss: 0.4189
2022-09-30 17:26:28 - train: epoch 0182, iter [01180, 01251], lr: 0.000796, loss: 0.4063
2022-09-30 17:26:46 - train: epoch 0182, iter [01190, 01251], lr: 0.000796, loss: 0.4001
2022-09-30 17:27:04 - train: epoch 0182, iter [01200, 01251], lr: 0.000796, loss: 0.3979
2022-09-30 17:27:21 - train: epoch 0182, iter [01210, 01251], lr: 0.000796, loss: 0.4251
2022-09-30 17:27:39 - train: epoch 0182, iter [01220, 01251], lr: 0.000795, loss: 0.4144
2022-09-30 17:27:57 - train: epoch 0182, iter [01230, 01251], lr: 0.000795, loss: 0.3976
2022-09-30 17:28:15 - train: epoch 0182, iter [01240, 01251], lr: 0.000795, loss: 0.3862
2022-09-30 17:28:32 - train: epoch 0182, iter [01250, 01251], lr: 0.000795, loss: 0.4432
2022-09-30 17:28:35 - train: epoch 182, train_loss: 0.4083
2022-09-30 17:28:38 - until epoch: 182, best_loss: 0.4083
2022-09-30 17:28:38 - epoch 183 lr: 0.000795
2022-09-30 17:29:03 - train: epoch 0183, iter [00010, 01251], lr: 0.000795, loss: 0.4019
2022-09-30 17:29:21 - train: epoch 0183, iter [00020, 01251], lr: 0.000795, loss: 0.3981
2022-09-30 17:29:38 - train: epoch 0183, iter [00030, 01251], lr: 0.000795, loss: 0.3994
2022-09-30 17:29:56 - train: epoch 0183, iter [00040, 01251], lr: 0.000795, loss: 0.4085
2022-09-30 17:30:14 - train: epoch 0183, iter [00050, 01251], lr: 0.000795, loss: 0.3994
2022-09-30 17:30:31 - train: epoch 0183, iter [00060, 01251], lr: 0.000795, loss: 0.3905
2022-09-30 17:30:49 - train: epoch 0183, iter [00070, 01251], lr: 0.000795, loss: 0.4061
2022-09-30 17:31:07 - train: epoch 0183, iter [00080, 01251], lr: 0.000795, loss: 0.4129
2022-09-30 17:31:25 - train: epoch 0183, iter [00090, 01251], lr: 0.000795, loss: 0.4171
2022-09-30 17:31:42 - train: epoch 0183, iter [00100, 01251], lr: 0.000795, loss: 0.4039
2022-09-30 17:32:00 - train: epoch 0183, iter [00110, 01251], lr: 0.000795, loss: 0.4280
2022-09-30 17:32:17 - train: epoch 0183, iter [00120, 01251], lr: 0.000795, loss: 0.3996
2022-09-30 17:32:35 - train: epoch 0183, iter [00130, 01251], lr: 0.000795, loss: 0.3980
2022-09-30 17:32:53 - train: epoch 0183, iter [00140, 01251], lr: 0.000795, loss: 0.4008
2022-09-30 17:33:10 - train: epoch 0183, iter [00150, 01251], lr: 0.000795, loss: 0.4021
2022-09-30 17:33:28 - train: epoch 0183, iter [00160, 01251], lr: 0.000795, loss: 0.4444
2022-09-30 17:33:46 - train: epoch 0183, iter [00170, 01251], lr: 0.000795, loss: 0.4081
2022-09-30 17:34:04 - train: epoch 0183, iter [00180, 01251], lr: 0.000795, loss: 0.4055
2022-09-30 17:34:21 - train: epoch 0183, iter [00190, 01251], lr: 0.000795, loss: 0.4160
2022-09-30 17:34:39 - train: epoch 0183, iter [00200, 01251], lr: 0.000795, loss: 0.4141
2022-09-30 17:34:56 - train: epoch 0183, iter [00210, 01251], lr: 0.000795, loss: 0.3922
2022-09-30 17:35:14 - train: epoch 0183, iter [00220, 01251], lr: 0.000794, loss: 0.4130
2022-09-30 17:35:32 - train: epoch 0183, iter [00230, 01251], lr: 0.000794, loss: 0.4290
2022-09-30 17:35:50 - train: epoch 0183, iter [00240, 01251], lr: 0.000794, loss: 0.3904
2022-09-30 17:36:07 - train: epoch 0183, iter [00250, 01251], lr: 0.000794, loss: 0.4069
2022-09-30 17:36:25 - train: epoch 0183, iter [00260, 01251], lr: 0.000794, loss: 0.3884
2022-09-30 17:36:43 - train: epoch 0183, iter [00270, 01251], lr: 0.000794, loss: 0.4240
2022-09-30 17:37:00 - train: epoch 0183, iter [00280, 01251], lr: 0.000794, loss: 0.4197
2022-09-30 17:37:18 - train: epoch 0183, iter [00290, 01251], lr: 0.000794, loss: 0.4085
2022-09-30 17:37:36 - train: epoch 0183, iter [00300, 01251], lr: 0.000794, loss: 0.4198
2022-09-30 17:37:53 - train: epoch 0183, iter [00310, 01251], lr: 0.000794, loss: 0.3905
2022-09-30 17:38:11 - train: epoch 0183, iter [00320, 01251], lr: 0.000794, loss: 0.4165
2022-09-30 17:38:29 - train: epoch 0183, iter [00330, 01251], lr: 0.000794, loss: 0.4160
2022-09-30 17:38:46 - train: epoch 0183, iter [00340, 01251], lr: 0.000794, loss: 0.3918
2022-09-30 17:39:04 - train: epoch 0183, iter [00350, 01251], lr: 0.000794, loss: 0.4135
2022-09-30 17:39:22 - train: epoch 0183, iter [00360, 01251], lr: 0.000794, loss: 0.3933
2022-09-30 17:39:40 - train: epoch 0183, iter [00370, 01251], lr: 0.000794, loss: 0.4214
2022-09-30 17:39:57 - train: epoch 0183, iter [00380, 01251], lr: 0.000794, loss: 0.4114
2022-09-30 17:40:15 - train: epoch 0183, iter [00390, 01251], lr: 0.000794, loss: 0.4128
2022-09-30 17:40:33 - train: epoch 0183, iter [00400, 01251], lr: 0.000794, loss: 0.4154
2022-09-30 17:40:50 - train: epoch 0183, iter [00410, 01251], lr: 0.000794, loss: 0.3894
2022-09-30 17:41:08 - train: epoch 0183, iter [00420, 01251], lr: 0.000794, loss: 0.4149
2022-09-30 17:41:26 - train: epoch 0183, iter [00430, 01251], lr: 0.000794, loss: 0.3998
2022-09-30 17:41:43 - train: epoch 0183, iter [00440, 01251], lr: 0.000794, loss: 0.4159
2022-09-30 17:42:01 - train: epoch 0183, iter [00450, 01251], lr: 0.000794, loss: 0.3910
2022-09-30 17:42:19 - train: epoch 0183, iter [00460, 01251], lr: 0.000794, loss: 0.4083
2022-09-30 17:42:37 - train: epoch 0183, iter [00470, 01251], lr: 0.000793, loss: 0.3854
2022-09-30 17:42:54 - train: epoch 0183, iter [00480, 01251], lr: 0.000793, loss: 0.3907
2022-09-30 17:43:12 - train: epoch 0183, iter [00490, 01251], lr: 0.000793, loss: 0.3989
2022-09-30 17:43:30 - train: epoch 0183, iter [00500, 01251], lr: 0.000793, loss: 0.4095
2022-09-30 17:43:47 - train: epoch 0183, iter [00510, 01251], lr: 0.000793, loss: 0.4187
2022-09-30 17:44:05 - train: epoch 0183, iter [00520, 01251], lr: 0.000793, loss: 0.4091
2022-09-30 17:44:23 - train: epoch 0183, iter [00530, 01251], lr: 0.000793, loss: 0.4106
2022-09-30 17:44:41 - train: epoch 0183, iter [00540, 01251], lr: 0.000793, loss: 0.4288
2022-09-30 17:44:58 - train: epoch 0183, iter [00550, 01251], lr: 0.000793, loss: 0.4183
2022-09-30 17:45:16 - train: epoch 0183, iter [00560, 01251], lr: 0.000793, loss: 0.4109
2022-09-30 17:45:34 - train: epoch 0183, iter [00570, 01251], lr: 0.000793, loss: 0.4027
2022-09-30 17:45:51 - train: epoch 0183, iter [00580, 01251], lr: 0.000793, loss: 0.3991
2022-09-30 17:46:09 - train: epoch 0183, iter [00590, 01251], lr: 0.000793, loss: 0.4170
2022-09-30 17:46:27 - train: epoch 0183, iter [00600, 01251], lr: 0.000793, loss: 0.4061
2022-09-30 17:46:45 - train: epoch 0183, iter [00610, 01251], lr: 0.000793, loss: 0.4072
2022-09-30 17:47:02 - train: epoch 0183, iter [00620, 01251], lr: 0.000793, loss: 0.4189
2022-09-30 17:47:20 - train: epoch 0183, iter [00630, 01251], lr: 0.000793, loss: 0.4169
2022-09-30 17:47:38 - train: epoch 0183, iter [00640, 01251], lr: 0.000793, loss: 0.4127
2022-09-30 17:47:56 - train: epoch 0183, iter [00650, 01251], lr: 0.000793, loss: 0.4001
2022-09-30 17:48:13 - train: epoch 0183, iter [00660, 01251], lr: 0.000793, loss: 0.4188
2022-09-30 17:48:31 - train: epoch 0183, iter [00670, 01251], lr: 0.000793, loss: 0.4081
2022-09-30 17:48:49 - train: epoch 0183, iter [00680, 01251], lr: 0.000793, loss: 0.4051
2022-09-30 17:49:07 - train: epoch 0183, iter [00690, 01251], lr: 0.000793, loss: 0.4179
2022-09-30 17:49:24 - train: epoch 0183, iter [00700, 01251], lr: 0.000793, loss: 0.4049
2022-09-30 17:49:42 - train: epoch 0183, iter [00710, 01251], lr: 0.000793, loss: 0.4140
2022-09-30 17:50:00 - train: epoch 0183, iter [00720, 01251], lr: 0.000792, loss: 0.4100
2022-09-30 17:50:17 - train: epoch 0183, iter [00730, 01251], lr: 0.000792, loss: 0.4081
2022-09-30 17:50:35 - train: epoch 0183, iter [00740, 01251], lr: 0.000792, loss: 0.4148
2022-09-30 17:50:53 - train: epoch 0183, iter [00750, 01251], lr: 0.000792, loss: 0.3987
2022-09-30 17:51:11 - train: epoch 0183, iter [00760, 01251], lr: 0.000792, loss: 0.4053
2022-09-30 17:51:29 - train: epoch 0183, iter [00770, 01251], lr: 0.000792, loss: 0.4039
2022-09-30 17:51:46 - train: epoch 0183, iter [00780, 01251], lr: 0.000792, loss: 0.4002
2022-09-30 17:52:04 - train: epoch 0183, iter [00790, 01251], lr: 0.000792, loss: 0.4112
2022-09-30 17:52:22 - train: epoch 0183, iter [00800, 01251], lr: 0.000792, loss: 0.4029
2022-09-30 17:52:39 - train: epoch 0183, iter [00810, 01251], lr: 0.000792, loss: 0.4080
2022-09-30 17:52:57 - train: epoch 0183, iter [00820, 01251], lr: 0.000792, loss: 0.4093
2022-09-30 17:53:15 - train: epoch 0183, iter [00830, 01251], lr: 0.000792, loss: 0.3934
2022-09-30 17:53:33 - train: epoch 0183, iter [00840, 01251], lr: 0.000792, loss: 0.4164
2022-09-30 17:53:50 - train: epoch 0183, iter [00850, 01251], lr: 0.000792, loss: 0.4360
2022-09-30 17:54:08 - train: epoch 0183, iter [00860, 01251], lr: 0.000792, loss: 0.3905
2022-09-30 17:54:26 - train: epoch 0183, iter [00870, 01251], lr: 0.000792, loss: 0.4043
2022-09-30 17:54:44 - train: epoch 0183, iter [00880, 01251], lr: 0.000792, loss: 0.4262
2022-09-30 17:55:01 - train: epoch 0183, iter [00890, 01251], lr: 0.000792, loss: 0.4126
2022-09-30 17:55:19 - train: epoch 0183, iter [00900, 01251], lr: 0.000792, loss: 0.4060
2022-09-30 17:55:37 - train: epoch 0183, iter [00910, 01251], lr: 0.000792, loss: 0.4120
2022-09-30 17:55:55 - train: epoch 0183, iter [00920, 01251], lr: 0.000792, loss: 0.4254
2022-09-30 17:56:12 - train: epoch 0183, iter [00930, 01251], lr: 0.000792, loss: 0.3916
2022-09-30 17:56:30 - train: epoch 0183, iter [00940, 01251], lr: 0.000792, loss: 0.4181
2022-09-30 17:56:48 - train: epoch 0183, iter [00950, 01251], lr: 0.000792, loss: 0.4037
2022-09-30 17:57:06 - train: epoch 0183, iter [00960, 01251], lr: 0.000792, loss: 0.4106
2022-09-30 17:57:23 - train: epoch 0183, iter [00970, 01251], lr: 0.000791, loss: 0.4031
2022-09-30 17:57:41 - train: epoch 0183, iter [00980, 01251], lr: 0.000791, loss: 0.4135
2022-09-30 17:57:59 - train: epoch 0183, iter [00990, 01251], lr: 0.000791, loss: 0.3946
2022-09-30 17:58:17 - train: epoch 0183, iter [01000, 01251], lr: 0.000791, loss: 0.3981
2022-09-30 17:58:35 - train: epoch 0183, iter [01010, 01251], lr: 0.000791, loss: 0.4073
2022-09-30 17:58:52 - train: epoch 0183, iter [01020, 01251], lr: 0.000791, loss: 0.4151
2022-09-30 17:59:10 - train: epoch 0183, iter [01030, 01251], lr: 0.000791, loss: 0.3764
2022-09-30 17:59:28 - train: epoch 0183, iter [01040, 01251], lr: 0.000791, loss: 0.4055
2022-09-30 17:59:46 - train: epoch 0183, iter [01050, 01251], lr: 0.000791, loss: 0.3909
2022-09-30 18:00:03 - train: epoch 0183, iter [01060, 01251], lr: 0.000791, loss: 0.3992
2022-09-30 18:00:21 - train: epoch 0183, iter [01070, 01251], lr: 0.000791, loss: 0.4082
2022-09-30 18:00:38 - train: epoch 0183, iter [01080, 01251], lr: 0.000791, loss: 0.3953
2022-09-30 18:00:56 - train: epoch 0183, iter [01090, 01251], lr: 0.000791, loss: 0.4252
2022-09-30 18:01:14 - train: epoch 0183, iter [01100, 01251], lr: 0.000791, loss: 0.4152
2022-09-30 18:01:32 - train: epoch 0183, iter [01110, 01251], lr: 0.000791, loss: 0.3831
2022-09-30 18:01:50 - train: epoch 0183, iter [01120, 01251], lr: 0.000791, loss: 0.4268
2022-09-30 18:02:07 - train: epoch 0183, iter [01130, 01251], lr: 0.000791, loss: 0.4050
2022-09-30 18:02:25 - train: epoch 0183, iter [01140, 01251], lr: 0.000791, loss: 0.3942
2022-09-30 18:02:43 - train: epoch 0183, iter [01150, 01251], lr: 0.000791, loss: 0.4282
2022-09-30 18:03:00 - train: epoch 0183, iter [01160, 01251], lr: 0.000791, loss: 0.3641
2022-09-30 18:03:18 - train: epoch 0183, iter [01170, 01251], lr: 0.000791, loss: 0.4176
2022-09-30 18:03:36 - train: epoch 0183, iter [01180, 01251], lr: 0.000791, loss: 0.4065
2022-09-30 18:03:54 - train: epoch 0183, iter [01190, 01251], lr: 0.000791, loss: 0.3952
2022-09-30 18:04:11 - train: epoch 0183, iter [01200, 01251], lr: 0.000791, loss: 0.4170
2022-09-30 18:04:29 - train: epoch 0183, iter [01210, 01251], lr: 0.000791, loss: 0.3965
2022-09-30 18:04:47 - train: epoch 0183, iter [01220, 01251], lr: 0.000791, loss: 0.4204
2022-09-30 18:05:04 - train: epoch 0183, iter [01230, 01251], lr: 0.000790, loss: 0.4026
2022-09-30 18:05:22 - train: epoch 0183, iter [01240, 01251], lr: 0.000790, loss: 0.4165
2022-09-30 18:05:39 - train: epoch 0183, iter [01250, 01251], lr: 0.000790, loss: 0.4282
2022-09-30 18:05:43 - train: epoch 183, train_loss: 0.4082
2022-09-30 18:05:46 - until epoch: 183, best_loss: 0.4082
2022-09-30 18:05:46 - epoch 184 lr: 0.000790
2022-09-30 18:06:10 - train: epoch 0184, iter [00010, 01251], lr: 0.000790, loss: 0.4170
2022-09-30 18:06:28 - train: epoch 0184, iter [00020, 01251], lr: 0.000790, loss: 0.4125
2022-09-30 18:06:46 - train: epoch 0184, iter [00030, 01251], lr: 0.000790, loss: 0.3999
2022-09-30 18:07:04 - train: epoch 0184, iter [00040, 01251], lr: 0.000790, loss: 0.3882
2022-09-30 18:07:21 - train: epoch 0184, iter [00050, 01251], lr: 0.000790, loss: 0.3982
2022-09-30 18:07:39 - train: epoch 0184, iter [00060, 01251], lr: 0.000790, loss: 0.4092
2022-09-30 18:07:57 - train: epoch 0184, iter [00070, 01251], lr: 0.000790, loss: 0.4122
2022-09-30 18:08:15 - train: epoch 0184, iter [00080, 01251], lr: 0.000790, loss: 0.4068
2022-09-30 18:08:33 - train: epoch 0184, iter [00090, 01251], lr: 0.000790, loss: 0.4182
2022-09-30 18:08:50 - train: epoch 0184, iter [00100, 01251], lr: 0.000790, loss: 0.4217
2022-09-30 18:09:08 - train: epoch 0184, iter [00110, 01251], lr: 0.000790, loss: 0.4002
2022-09-30 18:09:26 - train: epoch 0184, iter [00120, 01251], lr: 0.000790, loss: 0.4242
2022-09-30 18:09:44 - train: epoch 0184, iter [00130, 01251], lr: 0.000790, loss: 0.4045
2022-09-30 18:10:01 - train: epoch 0184, iter [00140, 01251], lr: 0.000790, loss: 0.4123
2022-09-30 18:10:19 - train: epoch 0184, iter [00150, 01251], lr: 0.000790, loss: 0.4188
2022-09-30 18:10:37 - train: epoch 0184, iter [00160, 01251], lr: 0.000790, loss: 0.4100
2022-09-30 18:10:55 - train: epoch 0184, iter [00170, 01251], lr: 0.000790, loss: 0.4062
2022-09-30 18:11:13 - train: epoch 0184, iter [00180, 01251], lr: 0.000790, loss: 0.4160
2022-09-30 18:11:30 - train: epoch 0184, iter [00190, 01251], lr: 0.000790, loss: 0.4150
2022-09-30 18:11:48 - train: epoch 0184, iter [00200, 01251], lr: 0.000790, loss: 0.4209
2022-09-30 18:12:06 - train: epoch 0184, iter [00210, 01251], lr: 0.000790, loss: 0.3946
2022-09-30 18:12:24 - train: epoch 0184, iter [00220, 01251], lr: 0.000790, loss: 0.4069
2022-09-30 18:12:41 - train: epoch 0184, iter [00230, 01251], lr: 0.000789, loss: 0.4215
2022-09-30 18:12:59 - train: epoch 0184, iter [00240, 01251], lr: 0.000789, loss: 0.4232
2022-09-30 18:13:17 - train: epoch 0184, iter [00250, 01251], lr: 0.000789, loss: 0.4020
2022-09-30 18:13:35 - train: epoch 0184, iter [00260, 01251], lr: 0.000789, loss: 0.4049
2022-09-30 18:13:52 - train: epoch 0184, iter [00270, 01251], lr: 0.000789, loss: 0.4015
2022-09-30 18:14:10 - train: epoch 0184, iter [00280, 01251], lr: 0.000789, loss: 0.4101
2022-09-30 18:14:27 - train: epoch 0184, iter [00290, 01251], lr: 0.000789, loss: 0.4010
2022-09-30 18:14:45 - train: epoch 0184, iter [00300, 01251], lr: 0.000789, loss: 0.3927
2022-09-30 18:15:03 - train: epoch 0184, iter [00310, 01251], lr: 0.000789, loss: 0.4031
2022-09-30 18:15:20 - train: epoch 0184, iter [00320, 01251], lr: 0.000789, loss: 0.4312
2022-09-30 18:15:38 - train: epoch 0184, iter [00330, 01251], lr: 0.000789, loss: 0.4181
2022-09-30 18:15:56 - train: epoch 0184, iter [00340, 01251], lr: 0.000789, loss: 0.4135
2022-09-30 18:16:14 - train: epoch 0184, iter [00350, 01251], lr: 0.000789, loss: 0.4160
2022-09-30 18:16:31 - train: epoch 0184, iter [00360, 01251], lr: 0.000789, loss: 0.4219
2022-09-30 18:16:49 - train: epoch 0184, iter [00370, 01251], lr: 0.000789, loss: 0.4045
2022-09-30 18:17:07 - train: epoch 0184, iter [00380, 01251], lr: 0.000789, loss: 0.4084
2022-09-30 18:17:24 - train: epoch 0184, iter [00390, 01251], lr: 0.000789, loss: 0.4124
2022-09-30 18:17:42 - train: epoch 0184, iter [00400, 01251], lr: 0.000789, loss: 0.4063
2022-09-30 18:18:00 - train: epoch 0184, iter [00410, 01251], lr: 0.000789, loss: 0.3909
2022-09-30 18:18:18 - train: epoch 0184, iter [00420, 01251], lr: 0.000789, loss: 0.4057
2022-09-30 18:18:35 - train: epoch 0184, iter [00430, 01251], lr: 0.000789, loss: 0.4107
2022-09-30 18:18:53 - train: epoch 0184, iter [00440, 01251], lr: 0.000789, loss: 0.4181
2022-09-30 18:19:11 - train: epoch 0184, iter [00450, 01251], lr: 0.000789, loss: 0.4145
2022-09-30 18:19:29 - train: epoch 0184, iter [00460, 01251], lr: 0.000789, loss: 0.4037
2022-09-30 18:19:46 - train: epoch 0184, iter [00470, 01251], lr: 0.000789, loss: 0.4153
2022-09-30 18:20:04 - train: epoch 0184, iter [00480, 01251], lr: 0.000788, loss: 0.4043
2022-09-30 18:20:21 - train: epoch 0184, iter [00490, 01251], lr: 0.000788, loss: 0.4252
2022-09-30 18:20:39 - train: epoch 0184, iter [00500, 01251], lr: 0.000788, loss: 0.3897
2022-09-30 18:20:57 - train: epoch 0184, iter [00510, 01251], lr: 0.000788, loss: 0.4346
2022-09-30 18:21:15 - train: epoch 0184, iter [00520, 01251], lr: 0.000788, loss: 0.4030
2022-09-30 18:21:32 - train: epoch 0184, iter [00530, 01251], lr: 0.000788, loss: 0.4045
2022-09-30 18:21:50 - train: epoch 0184, iter [00540, 01251], lr: 0.000788, loss: 0.3981
2022-09-30 18:22:08 - train: epoch 0184, iter [00550, 01251], lr: 0.000788, loss: 0.4136
2022-09-30 18:22:25 - train: epoch 0184, iter [00560, 01251], lr: 0.000788, loss: 0.4216
2022-09-30 18:22:43 - train: epoch 0184, iter [00570, 01251], lr: 0.000788, loss: 0.4359
2022-09-30 18:23:01 - train: epoch 0184, iter [00580, 01251], lr: 0.000788, loss: 0.4101
2022-09-30 18:23:19 - train: epoch 0184, iter [00590, 01251], lr: 0.000788, loss: 0.3939
2022-09-30 18:23:36 - train: epoch 0184, iter [00600, 01251], lr: 0.000788, loss: 0.4101
2022-09-30 18:23:54 - train: epoch 0184, iter [00610, 01251], lr: 0.000788, loss: 0.3957
2022-09-30 18:24:12 - train: epoch 0184, iter [00620, 01251], lr: 0.000788, loss: 0.4075
2022-09-30 18:24:29 - train: epoch 0184, iter [00630, 01251], lr: 0.000788, loss: 0.3865
2022-09-30 18:24:47 - train: epoch 0184, iter [00640, 01251], lr: 0.000788, loss: 0.4171
2022-09-30 18:25:05 - train: epoch 0184, iter [00650, 01251], lr: 0.000788, loss: 0.3994
2022-09-30 18:25:23 - train: epoch 0184, iter [00660, 01251], lr: 0.000788, loss: 0.4150
2022-09-30 18:25:41 - train: epoch 0184, iter [00670, 01251], lr: 0.000788, loss: 0.4172
2022-09-30 18:25:58 - train: epoch 0184, iter [00680, 01251], lr: 0.000788, loss: 0.4049
2022-09-30 18:26:16 - train: epoch 0184, iter [00690, 01251], lr: 0.000788, loss: 0.3836
2022-09-30 18:26:34 - train: epoch 0184, iter [00700, 01251], lr: 0.000788, loss: 0.4255
2022-09-30 18:26:52 - train: epoch 0184, iter [00710, 01251], lr: 0.000788, loss: 0.3964
2022-09-30 18:27:09 - train: epoch 0184, iter [00720, 01251], lr: 0.000788, loss: 0.3888
2022-09-30 18:27:27 - train: epoch 0184, iter [00730, 01251], lr: 0.000787, loss: 0.4087
2022-09-30 18:27:45 - train: epoch 0184, iter [00740, 01251], lr: 0.000787, loss: 0.4009
2022-09-30 18:28:02 - train: epoch 0184, iter [00750, 01251], lr: 0.000787, loss: 0.4294
2022-09-30 18:28:20 - train: epoch 0184, iter [00760, 01251], lr: 0.000787, loss: 0.4065
2022-09-30 18:28:38 - train: epoch 0184, iter [00770, 01251], lr: 0.000787, loss: 0.3829
2022-09-30 18:28:56 - train: epoch 0184, iter [00780, 01251], lr: 0.000787, loss: 0.4068
2022-09-30 18:29:13 - train: epoch 0184, iter [00790, 01251], lr: 0.000787, loss: 0.4078
2022-09-30 18:29:31 - train: epoch 0184, iter [00800, 01251], lr: 0.000787, loss: 0.4258
2022-09-30 18:29:49 - train: epoch 0184, iter [00810, 01251], lr: 0.000787, loss: 0.4138
2022-09-30 18:30:07 - train: epoch 0184, iter [00820, 01251], lr: 0.000787, loss: 0.4033
2022-09-30 18:30:24 - train: epoch 0184, iter [00830, 01251], lr: 0.000787, loss: 0.4101
2022-09-30 18:30:42 - train: epoch 0184, iter [00840, 01251], lr: 0.000787, loss: 0.4067
2022-09-30 18:31:00 - train: epoch 0184, iter [00850, 01251], lr: 0.000787, loss: 0.3986
2022-09-30 18:31:18 - train: epoch 0184, iter [00860, 01251], lr: 0.000787, loss: 0.3956
2022-09-30 18:31:35 - train: epoch 0184, iter [00870, 01251], lr: 0.000787, loss: 0.4071
2022-09-30 18:31:53 - train: epoch 0184, iter [00880, 01251], lr: 0.000787, loss: 0.4161
2022-09-30 18:32:11 - train: epoch 0184, iter [00890, 01251], lr: 0.000787, loss: 0.4027
2022-09-30 18:32:28 - train: epoch 0184, iter [00900, 01251], lr: 0.000787, loss: 0.4094
2022-09-30 18:32:46 - train: epoch 0184, iter [00910, 01251], lr: 0.000787, loss: 0.4211
2022-09-30 18:33:04 - train: epoch 0184, iter [00920, 01251], lr: 0.000787, loss: 0.4073
2022-09-30 18:33:22 - train: epoch 0184, iter [00930, 01251], lr: 0.000787, loss: 0.4216
2022-09-30 18:33:39 - train: epoch 0184, iter [00940, 01251], lr: 0.000787, loss: 0.4138
2022-09-30 18:33:57 - train: epoch 0184, iter [00950, 01251], lr: 0.000787, loss: 0.4052
2022-09-30 18:34:15 - train: epoch 0184, iter [00960, 01251], lr: 0.000787, loss: 0.4095
2022-09-30 18:34:33 - train: epoch 0184, iter [00970, 01251], lr: 0.000787, loss: 0.4072
2022-09-30 18:34:50 - train: epoch 0184, iter [00980, 01251], lr: 0.000786, loss: 0.4038
2022-09-30 18:35:08 - train: epoch 0184, iter [00990, 01251], lr: 0.000786, loss: 0.4236
2022-09-30 18:35:26 - train: epoch 0184, iter [01000, 01251], lr: 0.000786, loss: 0.4050
2022-09-30 18:35:44 - train: epoch 0184, iter [01010, 01251], lr: 0.000786, loss: 0.4084
2022-09-30 18:36:01 - train: epoch 0184, iter [01020, 01251], lr: 0.000786, loss: 0.3987
2022-09-30 18:36:19 - train: epoch 0184, iter [01030, 01251], lr: 0.000786, loss: 0.4154
2022-09-30 18:36:37 - train: epoch 0184, iter [01040, 01251], lr: 0.000786, loss: 0.4220
2022-09-30 18:36:55 - train: epoch 0184, iter [01050, 01251], lr: 0.000786, loss: 0.3899
2022-09-30 18:37:12 - train: epoch 0184, iter [01060, 01251], lr: 0.000786, loss: 0.4027
2022-09-30 18:37:30 - train: epoch 0184, iter [01070, 01251], lr: 0.000786, loss: 0.4032
2022-09-30 18:37:48 - train: epoch 0184, iter [01080, 01251], lr: 0.000786, loss: 0.4110
2022-09-30 18:38:05 - train: epoch 0184, iter [01090, 01251], lr: 0.000786, loss: 0.4112
2022-09-30 18:38:23 - train: epoch 0184, iter [01100, 01251], lr: 0.000786, loss: 0.4120
2022-09-30 18:38:41 - train: epoch 0184, iter [01110, 01251], lr: 0.000786, loss: 0.3929
2022-09-30 18:38:58 - train: epoch 0184, iter [01120, 01251], lr: 0.000786, loss: 0.4212
2022-09-30 18:39:16 - train: epoch 0184, iter [01130, 01251], lr: 0.000786, loss: 0.4076
2022-09-30 18:39:33 - train: epoch 0184, iter [01140, 01251], lr: 0.000786, loss: 0.4196
2022-09-30 18:39:51 - train: epoch 0184, iter [01150, 01251], lr: 0.000786, loss: 0.4092
2022-09-30 18:40:09 - train: epoch 0184, iter [01160, 01251], lr: 0.000786, loss: 0.4335
2022-09-30 18:40:26 - train: epoch 0184, iter [01170, 01251], lr: 0.000786, loss: 0.4182
2022-09-30 18:40:44 - train: epoch 0184, iter [01180, 01251], lr: 0.000786, loss: 0.4213
2022-09-30 18:41:02 - train: epoch 0184, iter [01190, 01251], lr: 0.000786, loss: 0.4030
2022-09-30 18:41:19 - train: epoch 0184, iter [01200, 01251], lr: 0.000786, loss: 0.3968
2022-09-30 18:41:37 - train: epoch 0184, iter [01210, 01251], lr: 0.000786, loss: 0.4086
2022-09-30 18:41:55 - train: epoch 0184, iter [01220, 01251], lr: 0.000786, loss: 0.4124
2022-09-30 18:42:13 - train: epoch 0184, iter [01230, 01251], lr: 0.000785, loss: 0.3969
2022-09-30 18:42:30 - train: epoch 0184, iter [01240, 01251], lr: 0.000785, loss: 0.4176
2022-09-30 18:42:47 - train: epoch 0184, iter [01250, 01251], lr: 0.000785, loss: 0.4007
2022-09-30 18:42:51 - train: epoch 184, train_loss: 0.4082
2022-09-30 18:42:52 - until epoch: 184, best_loss: 0.4082
2022-09-30 18:42:52 - epoch 185 lr: 0.000785
2022-09-30 18:43:18 - train: epoch 0185, iter [00010, 01251], lr: 0.000785, loss: 0.3959
2022-09-30 18:43:36 - train: epoch 0185, iter [00020, 01251], lr: 0.000785, loss: 0.4143
2022-09-30 18:43:53 - train: epoch 0185, iter [00030, 01251], lr: 0.000785, loss: 0.4363
2022-09-30 18:44:11 - train: epoch 0185, iter [00040, 01251], lr: 0.000785, loss: 0.4084
2022-09-30 18:44:29 - train: epoch 0185, iter [00050, 01251], lr: 0.000785, loss: 0.4036
2022-09-30 18:44:46 - train: epoch 0185, iter [00060, 01251], lr: 0.000785, loss: 0.4225
2022-09-30 18:45:04 - train: epoch 0185, iter [00070, 01251], lr: 0.000785, loss: 0.4291
2022-09-30 18:45:22 - train: epoch 0185, iter [00080, 01251], lr: 0.000785, loss: 0.4114
2022-09-30 18:45:39 - train: epoch 0185, iter [00090, 01251], lr: 0.000785, loss: 0.4046
2022-09-30 18:45:57 - train: epoch 0185, iter [00100, 01251], lr: 0.000785, loss: 0.3953
2022-09-30 18:46:15 - train: epoch 0185, iter [00110, 01251], lr: 0.000785, loss: 0.4101
2022-09-30 18:46:33 - train: epoch 0185, iter [00120, 01251], lr: 0.000785, loss: 0.4100
2022-09-30 18:46:51 - train: epoch 0185, iter [00130, 01251], lr: 0.000785, loss: 0.4133
2022-09-30 18:47:08 - train: epoch 0185, iter [00140, 01251], lr: 0.000785, loss: 0.3983
2022-09-30 18:47:26 - train: epoch 0185, iter [00150, 01251], lr: 0.000785, loss: 0.4153
2022-09-30 18:47:44 - train: epoch 0185, iter [00160, 01251], lr: 0.000785, loss: 0.3952
2022-09-30 18:48:01 - train: epoch 0185, iter [00170, 01251], lr: 0.000785, loss: 0.3962
2022-09-30 18:48:20 - train: epoch 0185, iter [00180, 01251], lr: 0.000785, loss: 0.3991
2022-09-30 18:48:38 - train: epoch 0185, iter [00190, 01251], lr: 0.000785, loss: 0.3966
2022-09-30 18:48:55 - train: epoch 0185, iter [00200, 01251], lr: 0.000785, loss: 0.4038
2022-09-30 18:49:13 - train: epoch 0185, iter [00210, 01251], lr: 0.000785, loss: 0.4006
2022-09-30 18:49:31 - train: epoch 0185, iter [00220, 01251], lr: 0.000785, loss: 0.4106
2022-09-30 18:49:48 - train: epoch 0185, iter [00230, 01251], lr: 0.000784, loss: 0.4097
2022-09-30 18:50:06 - train: epoch 0185, iter [00240, 01251], lr: 0.000784, loss: 0.4086
2022-09-30 18:50:24 - train: epoch 0185, iter [00250, 01251], lr: 0.000784, loss: 0.4187
2022-09-30 18:50:42 - train: epoch 0185, iter [00260, 01251], lr: 0.000784, loss: 0.4254
2022-09-30 18:51:00 - train: epoch 0185, iter [00270, 01251], lr: 0.000784, loss: 0.4080
2022-09-30 18:51:17 - train: epoch 0185, iter [00280, 01251], lr: 0.000784, loss: 0.3937
2022-09-30 18:51:35 - train: epoch 0185, iter [00290, 01251], lr: 0.000784, loss: 0.4173
2022-09-30 18:51:53 - train: epoch 0185, iter [00300, 01251], lr: 0.000784, loss: 0.3848
2022-09-30 18:52:11 - train: epoch 0185, iter [00310, 01251], lr: 0.000784, loss: 0.4137
2022-09-30 18:52:29 - train: epoch 0185, iter [00320, 01251], lr: 0.000784, loss: 0.4300
2022-09-30 18:52:46 - train: epoch 0185, iter [00330, 01251], lr: 0.000784, loss: 0.3983
2022-09-30 18:53:04 - train: epoch 0185, iter [00340, 01251], lr: 0.000784, loss: 0.4133
2022-09-30 18:53:22 - train: epoch 0185, iter [00350, 01251], lr: 0.000784, loss: 0.4114
2022-09-30 18:53:40 - train: epoch 0185, iter [00360, 01251], lr: 0.000784, loss: 0.3937
2022-09-30 18:53:58 - train: epoch 0185, iter [00370, 01251], lr: 0.000784, loss: 0.4137
2022-09-30 18:54:15 - train: epoch 0185, iter [00380, 01251], lr: 0.000784, loss: 0.3999
2022-09-30 18:54:33 - train: epoch 0185, iter [00390, 01251], lr: 0.000784, loss: 0.4079
2022-09-30 18:54:51 - train: epoch 0185, iter [00400, 01251], lr: 0.000784, loss: 0.3891
2022-09-30 18:55:09 - train: epoch 0185, iter [00410, 01251], lr: 0.000784, loss: 0.4021
2022-09-30 18:55:27 - train: epoch 0185, iter [00420, 01251], lr: 0.000784, loss: 0.4002
2022-09-30 18:55:45 - train: epoch 0185, iter [00430, 01251], lr: 0.000784, loss: 0.4136
2022-09-30 18:56:03 - train: epoch 0185, iter [00440, 01251], lr: 0.000784, loss: 0.3936
2022-09-30 18:56:21 - train: epoch 0185, iter [00450, 01251], lr: 0.000784, loss: 0.4142
2022-09-30 18:56:38 - train: epoch 0185, iter [00460, 01251], lr: 0.000784, loss: 0.4080
2022-09-30 18:56:56 - train: epoch 0185, iter [00470, 01251], lr: 0.000784, loss: 0.3923
2022-09-30 18:57:14 - train: epoch 0185, iter [00480, 01251], lr: 0.000783, loss: 0.3976
2022-09-30 18:57:32 - train: epoch 0185, iter [00490, 01251], lr: 0.000783, loss: 0.4015
2022-09-30 18:57:50 - train: epoch 0185, iter [00500, 01251], lr: 0.000783, loss: 0.3892
2022-09-30 18:58:07 - train: epoch 0185, iter [00510, 01251], lr: 0.000783, loss: 0.4137
2022-09-30 18:58:25 - train: epoch 0185, iter [00520, 01251], lr: 0.000783, loss: 0.4076
2022-09-30 18:58:43 - train: epoch 0185, iter [00530, 01251], lr: 0.000783, loss: 0.4185
2022-09-30 18:59:01 - train: epoch 0185, iter [00540, 01251], lr: 0.000783, loss: 0.4253
2022-09-30 18:59:19 - train: epoch 0185, iter [00550, 01251], lr: 0.000783, loss: 0.4370
2022-09-30 18:59:37 - train: epoch 0185, iter [00560, 01251], lr: 0.000783, loss: 0.4185
2022-09-30 18:59:55 - train: epoch 0185, iter [00570, 01251], lr: 0.000783, loss: 0.3977
2022-09-30 19:00:13 - train: epoch 0185, iter [00580, 01251], lr: 0.000783, loss: 0.4024
2022-09-30 19:00:31 - train: epoch 0185, iter [00590, 01251], lr: 0.000783, loss: 0.4052
2022-09-30 19:00:48 - train: epoch 0185, iter [00600, 01251], lr: 0.000783, loss: 0.4073
2022-09-30 19:01:06 - train: epoch 0185, iter [00610, 01251], lr: 0.000783, loss: 0.3954
2022-09-30 19:01:24 - train: epoch 0185, iter [00620, 01251], lr: 0.000783, loss: 0.4133
2022-09-30 19:01:42 - train: epoch 0185, iter [00630, 01251], lr: 0.000783, loss: 0.3957
2022-09-30 19:02:00 - train: epoch 0185, iter [00640, 01251], lr: 0.000783, loss: 0.4064
2022-09-30 19:02:18 - train: epoch 0185, iter [00650, 01251], lr: 0.000783, loss: 0.4199
2022-09-30 19:02:36 - train: epoch 0185, iter [00660, 01251], lr: 0.000783, loss: 0.4003
2022-09-30 19:02:54 - train: epoch 0185, iter [00670, 01251], lr: 0.000783, loss: 0.4061
2022-09-30 19:03:12 - train: epoch 0185, iter [00680, 01251], lr: 0.000783, loss: 0.4047
2022-09-30 19:03:30 - train: epoch 0185, iter [00690, 01251], lr: 0.000783, loss: 0.4238
2022-09-30 19:03:48 - train: epoch 0185, iter [00700, 01251], lr: 0.000783, loss: 0.3891
2022-09-30 19:04:06 - train: epoch 0185, iter [00710, 01251], lr: 0.000783, loss: 0.4012
2022-09-30 19:04:24 - train: epoch 0185, iter [00720, 01251], lr: 0.000783, loss: 0.3950
2022-09-30 19:04:41 - train: epoch 0185, iter [00730, 01251], lr: 0.000783, loss: 0.4144
2022-09-30 19:04:59 - train: epoch 0185, iter [00740, 01251], lr: 0.000782, loss: 0.4153
2022-09-30 19:05:17 - train: epoch 0185, iter [00750, 01251], lr: 0.000782, loss: 0.4153
2022-09-30 19:05:35 - train: epoch 0185, iter [00760, 01251], lr: 0.000782, loss: 0.4207
2022-09-30 19:05:53 - train: epoch 0185, iter [00770, 01251], lr: 0.000782, loss: 0.4232
2022-09-30 19:06:11 - train: epoch 0185, iter [00780, 01251], lr: 0.000782, loss: 0.3900
2022-09-30 19:06:29 - train: epoch 0185, iter [00790, 01251], lr: 0.000782, loss: 0.3994
2022-09-30 19:06:47 - train: epoch 0185, iter [00800, 01251], lr: 0.000782, loss: 0.4025
2022-09-30 19:07:05 - train: epoch 0185, iter [00810, 01251], lr: 0.000782, loss: 0.3967
2022-09-30 19:07:23 - train: epoch 0185, iter [00820, 01251], lr: 0.000782, loss: 0.4022
2022-09-30 19:07:41 - train: epoch 0185, iter [00830, 01251], lr: 0.000782, loss: 0.4091
2022-09-30 19:07:59 - train: epoch 0185, iter [00840, 01251], lr: 0.000782, loss: 0.4058
2022-09-30 19:08:17 - train: epoch 0185, iter [00850, 01251], lr: 0.000782, loss: 0.4050
2022-09-30 19:08:35 - train: epoch 0185, iter [00860, 01251], lr: 0.000782, loss: 0.4225
2022-09-30 19:08:53 - train: epoch 0185, iter [00870, 01251], lr: 0.000782, loss: 0.4341
2022-09-30 19:09:11 - train: epoch 0185, iter [00880, 01251], lr: 0.000782, loss: 0.4005
2022-09-30 19:09:29 - train: epoch 0185, iter [00890, 01251], lr: 0.000782, loss: 0.4264
2022-09-30 19:09:47 - train: epoch 0185, iter [00900, 01251], lr: 0.000782, loss: 0.3766
2022-09-30 19:10:05 - train: epoch 0185, iter [00910, 01251], lr: 0.000782, loss: 0.4007
2022-09-30 19:10:23 - train: epoch 0185, iter [00920, 01251], lr: 0.000782, loss: 0.4087
2022-09-30 19:10:41 - train: epoch 0185, iter [00930, 01251], lr: 0.000782, loss: 0.4065
2022-09-30 19:10:59 - train: epoch 0185, iter [00940, 01251], lr: 0.000782, loss: 0.4100
2022-09-30 19:11:17 - train: epoch 0185, iter [00950, 01251], lr: 0.000782, loss: 0.3904
2022-09-30 19:11:35 - train: epoch 0185, iter [00960, 01251], lr: 0.000782, loss: 0.4141
2022-09-30 19:11:53 - train: epoch 0185, iter [00970, 01251], lr: 0.000782, loss: 0.4147
2022-09-30 19:12:11 - train: epoch 0185, iter [00980, 01251], lr: 0.000782, loss: 0.4150
2022-09-30 19:12:29 - train: epoch 0185, iter [00990, 01251], lr: 0.000781, loss: 0.4102
2022-09-30 19:12:47 - train: epoch 0185, iter [01000, 01251], lr: 0.000781, loss: 0.4078
2022-09-30 19:13:05 - train: epoch 0185, iter [01010, 01251], lr: 0.000781, loss: 0.4075
2022-09-30 19:13:23 - train: epoch 0185, iter [01020, 01251], lr: 0.000781, loss: 0.4035
2022-09-30 19:13:41 - train: epoch 0185, iter [01030, 01251], lr: 0.000781, loss: 0.4167
2022-09-30 19:13:59 - train: epoch 0185, iter [01040, 01251], lr: 0.000781, loss: 0.4247
2022-09-30 19:14:17 - train: epoch 0185, iter [01050, 01251], lr: 0.000781, loss: 0.4247
2022-09-30 19:14:35 - train: epoch 0185, iter [01060, 01251], lr: 0.000781, loss: 0.4314
2022-09-30 19:14:53 - train: epoch 0185, iter [01070, 01251], lr: 0.000781, loss: 0.3935
2022-09-30 19:15:11 - train: epoch 0185, iter [01080, 01251], lr: 0.000781, loss: 0.4078
2022-09-30 19:15:29 - train: epoch 0185, iter [01090, 01251], lr: 0.000781, loss: 0.4071
2022-09-30 19:15:47 - train: epoch 0185, iter [01100, 01251], lr: 0.000781, loss: 0.4233
2022-09-30 19:16:04 - train: epoch 0185, iter [01110, 01251], lr: 0.000781, loss: 0.4146
2022-09-30 19:16:22 - train: epoch 0185, iter [01120, 01251], lr: 0.000781, loss: 0.4018
2022-09-30 19:16:40 - train: epoch 0185, iter [01130, 01251], lr: 0.000781, loss: 0.4050
2022-09-30 19:16:58 - train: epoch 0185, iter [01140, 01251], lr: 0.000781, loss: 0.3878
2022-09-30 19:17:16 - train: epoch 0185, iter [01150, 01251], lr: 0.000781, loss: 0.3885
2022-09-30 19:17:34 - train: epoch 0185, iter [01160, 01251], lr: 0.000781, loss: 0.4146
2022-09-30 19:17:52 - train: epoch 0185, iter [01170, 01251], lr: 0.000781, loss: 0.4073
2022-09-30 19:18:10 - train: epoch 0185, iter [01180, 01251], lr: 0.000781, loss: 0.4022
2022-09-30 19:18:28 - train: epoch 0185, iter [01190, 01251], lr: 0.000781, loss: 0.4262
2022-09-30 19:18:46 - train: epoch 0185, iter [01200, 01251], lr: 0.000781, loss: 0.4296
2022-09-30 19:19:04 - train: epoch 0185, iter [01210, 01251], lr: 0.000781, loss: 0.4125
2022-09-30 19:19:22 - train: epoch 0185, iter [01220, 01251], lr: 0.000781, loss: 0.4181
2022-09-30 19:19:40 - train: epoch 0185, iter [01230, 01251], lr: 0.000781, loss: 0.4106
2022-09-30 19:19:58 - train: epoch 0185, iter [01240, 01251], lr: 0.000780, loss: 0.4128
2022-09-30 19:20:16 - train: epoch 0185, iter [01250, 01251], lr: 0.000780, loss: 0.4193
2022-09-30 19:20:19 - train: epoch 185, train_loss: 0.4082
2022-09-30 19:20:22 - until epoch: 185, best_loss: 0.4082
2022-09-30 19:20:22 - epoch 186 lr: 0.000780
2022-09-30 19:20:47 - train: epoch 0186, iter [00010, 01251], lr: 0.000780, loss: 0.3998
2022-09-30 19:21:05 - train: epoch 0186, iter [00020, 01251], lr: 0.000780, loss: 0.3992
2022-09-30 19:21:23 - train: epoch 0186, iter [00030, 01251], lr: 0.000780, loss: 0.3985
2022-09-30 19:21:41 - train: epoch 0186, iter [00040, 01251], lr: 0.000780, loss: 0.3943
2022-09-30 19:21:59 - train: epoch 0186, iter [00050, 01251], lr: 0.000780, loss: 0.4091
2022-09-30 19:22:16 - train: epoch 0186, iter [00060, 01251], lr: 0.000780, loss: 0.4139
2022-09-30 19:22:34 - train: epoch 0186, iter [00070, 01251], lr: 0.000780, loss: 0.4109
2022-09-30 19:22:52 - train: epoch 0186, iter [00080, 01251], lr: 0.000780, loss: 0.4196
2022-09-30 19:23:10 - train: epoch 0186, iter [00090, 01251], lr: 0.000780, loss: 0.3915
2022-09-30 19:23:28 - train: epoch 0186, iter [00100, 01251], lr: 0.000780, loss: 0.4269
2022-09-30 19:23:47 - train: epoch 0186, iter [00110, 01251], lr: 0.000780, loss: 0.3918
2022-09-30 19:24:04 - train: epoch 0186, iter [00120, 01251], lr: 0.000780, loss: 0.4384
2022-09-30 19:24:22 - train: epoch 0186, iter [00130, 01251], lr: 0.000780, loss: 0.4054
2022-09-30 19:24:40 - train: epoch 0186, iter [00140, 01251], lr: 0.000780, loss: 0.4095
2022-09-30 19:24:58 - train: epoch 0186, iter [00150, 01251], lr: 0.000780, loss: 0.3974
2022-09-30 19:25:16 - train: epoch 0186, iter [00160, 01251], lr: 0.000780, loss: 0.3999
2022-09-30 19:25:34 - train: epoch 0186, iter [00170, 01251], lr: 0.000780, loss: 0.4192
2022-09-30 19:25:52 - train: epoch 0186, iter [00180, 01251], lr: 0.000780, loss: 0.4166
2022-09-30 19:26:10 - train: epoch 0186, iter [00190, 01251], lr: 0.000780, loss: 0.4005
2022-09-30 19:26:28 - train: epoch 0186, iter [00200, 01251], lr: 0.000780, loss: 0.4028
2022-09-30 19:26:46 - train: epoch 0186, iter [00210, 01251], lr: 0.000780, loss: 0.4017
2022-09-30 19:27:04 - train: epoch 0186, iter [00220, 01251], lr: 0.000780, loss: 0.3985
2022-09-30 19:27:21 - train: epoch 0186, iter [00230, 01251], lr: 0.000780, loss: 0.4155
2022-09-30 19:27:39 - train: epoch 0186, iter [00240, 01251], lr: 0.000779, loss: 0.3883
2022-09-30 19:27:57 - train: epoch 0186, iter [00250, 01251], lr: 0.000779, loss: 0.4053
2022-09-30 19:28:15 - train: epoch 0186, iter [00260, 01251], lr: 0.000779, loss: 0.4051
2022-09-30 19:28:33 - train: epoch 0186, iter [00270, 01251], lr: 0.000779, loss: 0.3925
2022-09-30 19:28:52 - train: epoch 0186, iter [00280, 01251], lr: 0.000779, loss: 0.4012
2022-09-30 19:29:09 - train: epoch 0186, iter [00290, 01251], lr: 0.000779, loss: 0.4154
2022-09-30 19:29:27 - train: epoch 0186, iter [00300, 01251], lr: 0.000779, loss: 0.4151
2022-09-30 19:29:45 - train: epoch 0186, iter [00310, 01251], lr: 0.000779, loss: 0.4044
2022-09-30 19:30:03 - train: epoch 0186, iter [00320, 01251], lr: 0.000779, loss: 0.4133
2022-09-30 19:30:21 - train: epoch 0186, iter [00330, 01251], lr: 0.000779, loss: 0.4147
2022-09-30 19:30:39 - train: epoch 0186, iter [00340, 01251], lr: 0.000779, loss: 0.3925
2022-09-30 19:30:57 - train: epoch 0186, iter [00350, 01251], lr: 0.000779, loss: 0.4055
2022-09-30 19:31:15 - train: epoch 0186, iter [00360, 01251], lr: 0.000779, loss: 0.3924
2022-09-30 19:31:33 - train: epoch 0186, iter [00370, 01251], lr: 0.000779, loss: 0.4057
2022-09-30 19:31:51 - train: epoch 0186, iter [00380, 01251], lr: 0.000779, loss: 0.4246
2022-09-30 19:32:09 - train: epoch 0186, iter [00390, 01251], lr: 0.000779, loss: 0.3934
2022-09-30 19:32:27 - train: epoch 0186, iter [00400, 01251], lr: 0.000779, loss: 0.4146
2022-09-30 19:32:45 - train: epoch 0186, iter [00410, 01251], lr: 0.000779, loss: 0.4128
2022-09-30 19:33:03 - train: epoch 0186, iter [00420, 01251], lr: 0.000779, loss: 0.4278
2022-09-30 19:33:21 - train: epoch 0186, iter [00430, 01251], lr: 0.000779, loss: 0.4317
2022-09-30 19:33:39 - train: epoch 0186, iter [00440, 01251], lr: 0.000779, loss: 0.3990
2022-09-30 19:33:57 - train: epoch 0186, iter [00450, 01251], lr: 0.000779, loss: 0.4066
2022-09-30 19:34:15 - train: epoch 0186, iter [00460, 01251], lr: 0.000779, loss: 0.3970
2022-09-30 19:34:33 - train: epoch 0186, iter [00470, 01251], lr: 0.000779, loss: 0.4222
2022-09-30 19:34:51 - train: epoch 0186, iter [00480, 01251], lr: 0.000779, loss: 0.4080
2022-09-30 19:35:09 - train: epoch 0186, iter [00490, 01251], lr: 0.000778, loss: 0.3954
2022-09-30 19:35:27 - train: epoch 0186, iter [00500, 01251], lr: 0.000778, loss: 0.4010
2022-09-30 19:35:45 - train: epoch 0186, iter [00510, 01251], lr: 0.000778, loss: 0.3996
2022-09-30 19:36:03 - train: epoch 0186, iter [00520, 01251], lr: 0.000778, loss: 0.4014
2022-09-30 19:36:21 - train: epoch 0186, iter [00530, 01251], lr: 0.000778, loss: 0.4015
2022-09-30 19:36:39 - train: epoch 0186, iter [00540, 01251], lr: 0.000778, loss: 0.4029
2022-09-30 19:36:57 - train: epoch 0186, iter [00550, 01251], lr: 0.000778, loss: 0.3979
2022-09-30 19:37:15 - train: epoch 0186, iter [00560, 01251], lr: 0.000778, loss: 0.4078
2022-09-30 19:37:33 - train: epoch 0186, iter [00570, 01251], lr: 0.000778, loss: 0.4029
2022-09-30 19:37:51 - train: epoch 0186, iter [00580, 01251], lr: 0.000778, loss: 0.3995
2022-09-30 19:38:09 - train: epoch 0186, iter [00590, 01251], lr: 0.000778, loss: 0.3923
2022-09-30 19:38:27 - train: epoch 0186, iter [00600, 01251], lr: 0.000778, loss: 0.4064
2022-09-30 19:38:45 - train: epoch 0186, iter [00610, 01251], lr: 0.000778, loss: 0.3931
2022-09-30 19:39:03 - train: epoch 0186, iter [00620, 01251], lr: 0.000778, loss: 0.3846
2022-09-30 19:39:21 - train: epoch 0186, iter [00630, 01251], lr: 0.000778, loss: 0.4171
2022-09-30 19:39:39 - train: epoch 0186, iter [00640, 01251], lr: 0.000778, loss: 0.4055
2022-09-30 19:39:57 - train: epoch 0186, iter [00650, 01251], lr: 0.000778, loss: 0.4105
2022-09-30 19:40:15 - train: epoch 0186, iter [00660, 01251], lr: 0.000778, loss: 0.4056
2022-09-30 19:40:33 - train: epoch 0186, iter [00670, 01251], lr: 0.000778, loss: 0.4019
2022-09-30 19:40:51 - train: epoch 0186, iter [00680, 01251], lr: 0.000778, loss: 0.3892
2022-09-30 19:41:09 - train: epoch 0186, iter [00690, 01251], lr: 0.000778, loss: 0.4190
2022-09-30 19:41:27 - train: epoch 0186, iter [00700, 01251], lr: 0.000778, loss: 0.4125
2022-09-30 19:41:45 - train: epoch 0186, iter [00710, 01251], lr: 0.000778, loss: 0.4048
2022-09-30 19:42:02 - train: epoch 0186, iter [00720, 01251], lr: 0.000778, loss: 0.4041
2022-09-30 19:42:20 - train: epoch 0186, iter [00730, 01251], lr: 0.000778, loss: 0.4173
2022-09-30 19:42:38 - train: epoch 0186, iter [00740, 01251], lr: 0.000777, loss: 0.4016
2022-09-30 19:42:56 - train: epoch 0186, iter [00750, 01251], lr: 0.000777, loss: 0.4077
2022-09-30 19:43:14 - train: epoch 0186, iter [00760, 01251], lr: 0.000777, loss: 0.3836
2022-09-30 19:43:32 - train: epoch 0186, iter [00770, 01251], lr: 0.000777, loss: 0.3965
2022-09-30 19:43:50 - train: epoch 0186, iter [00780, 01251], lr: 0.000777, loss: 0.4275
2022-09-30 19:44:08 - train: epoch 0186, iter [00790, 01251], lr: 0.000777, loss: 0.4240
2022-09-30 19:44:26 - train: epoch 0186, iter [00800, 01251], lr: 0.000777, loss: 0.3916
2022-09-30 19:44:44 - train: epoch 0186, iter [00810, 01251], lr: 0.000777, loss: 0.3968
2022-09-30 19:45:02 - train: epoch 0186, iter [00820, 01251], lr: 0.000777, loss: 0.4142
2022-09-30 19:45:20 - train: epoch 0186, iter [00830, 01251], lr: 0.000777, loss: 0.4156
2022-09-30 19:45:38 - train: epoch 0186, iter [00840, 01251], lr: 0.000777, loss: 0.4080
2022-09-30 19:45:56 - train: epoch 0186, iter [00850, 01251], lr: 0.000777, loss: 0.4107
2022-09-30 19:46:14 - train: epoch 0186, iter [00860, 01251], lr: 0.000777, loss: 0.4085
2022-09-30 19:46:32 - train: epoch 0186, iter [00870, 01251], lr: 0.000777, loss: 0.4168
2022-09-30 19:46:51 - train: epoch 0186, iter [00880, 01251], lr: 0.000777, loss: 0.4017
2022-09-30 19:47:09 - train: epoch 0186, iter [00890, 01251], lr: 0.000777, loss: 0.4294
2022-09-30 19:47:27 - train: epoch 0186, iter [00900, 01251], lr: 0.000777, loss: 0.4079
2022-09-30 19:47:45 - train: epoch 0186, iter [00910, 01251], lr: 0.000777, loss: 0.4018
2022-09-30 19:48:03 - train: epoch 0186, iter [00920, 01251], lr: 0.000777, loss: 0.4026
2022-09-30 19:48:21 - train: epoch 0186, iter [00930, 01251], lr: 0.000777, loss: 0.3974
2022-09-30 19:48:39 - train: epoch 0186, iter [00940, 01251], lr: 0.000777, loss: 0.3927
2022-09-30 19:48:58 - train: epoch 0186, iter [00950, 01251], lr: 0.000777, loss: 0.3888
2022-09-30 19:49:16 - train: epoch 0186, iter [00960, 01251], lr: 0.000777, loss: 0.4180
2022-09-30 19:49:34 - train: epoch 0186, iter [00970, 01251], lr: 0.000777, loss: 0.4058
2022-09-30 19:49:53 - train: epoch 0186, iter [00980, 01251], lr: 0.000777, loss: 0.4102
2022-09-30 19:50:11 - train: epoch 0186, iter [00990, 01251], lr: 0.000776, loss: 0.3991
2022-09-30 19:50:29 - train: epoch 0186, iter [01000, 01251], lr: 0.000776, loss: 0.4265
2022-09-30 19:50:47 - train: epoch 0186, iter [01010, 01251], lr: 0.000776, loss: 0.4271
2022-09-30 19:51:05 - train: epoch 0186, iter [01020, 01251], lr: 0.000776, loss: 0.4050
2022-09-30 19:51:23 - train: epoch 0186, iter [01030, 01251], lr: 0.000776, loss: 0.3913
2022-09-30 19:51:41 - train: epoch 0186, iter [01040, 01251], lr: 0.000776, loss: 0.3913
2022-09-30 19:52:00 - train: epoch 0186, iter [01050, 01251], lr: 0.000776, loss: 0.4043
2022-09-30 19:52:18 - train: epoch 0186, iter [01060, 01251], lr: 0.000776, loss: 0.3924
2022-09-30 19:52:36 - train: epoch 0186, iter [01070, 01251], lr: 0.000776, loss: 0.4287
2022-09-30 19:52:54 - train: epoch 0186, iter [01080, 01251], lr: 0.000776, loss: 0.4193
2022-09-30 19:53:12 - train: epoch 0186, iter [01090, 01251], lr: 0.000776, loss: 0.4203
2022-09-30 19:53:30 - train: epoch 0186, iter [01100, 01251], lr: 0.000776, loss: 0.3944
2022-09-30 19:53:48 - train: epoch 0186, iter [01110, 01251], lr: 0.000776, loss: 0.4008
2022-09-30 19:54:07 - train: epoch 0186, iter [01120, 01251], lr: 0.000776, loss: 0.4050
2022-09-30 19:54:25 - train: epoch 0186, iter [01130, 01251], lr: 0.000776, loss: 0.4240
2022-09-30 19:54:43 - train: epoch 0186, iter [01140, 01251], lr: 0.000776, loss: 0.3988
2022-09-30 19:55:01 - train: epoch 0186, iter [01150, 01251], lr: 0.000776, loss: 0.4126
2022-09-30 19:55:19 - train: epoch 0186, iter [01160, 01251], lr: 0.000776, loss: 0.4031
2022-09-30 19:55:37 - train: epoch 0186, iter [01170, 01251], lr: 0.000776, loss: 0.4114
2022-09-30 19:55:55 - train: epoch 0186, iter [01180, 01251], lr: 0.000776, loss: 0.4098
2022-09-30 19:56:14 - train: epoch 0186, iter [01190, 01251], lr: 0.000776, loss: 0.4134
2022-09-30 19:56:32 - train: epoch 0186, iter [01200, 01251], lr: 0.000776, loss: 0.4158
2022-09-30 19:56:50 - train: epoch 0186, iter [01210, 01251], lr: 0.000776, loss: 0.4160
2022-09-30 19:57:08 - train: epoch 0186, iter [01220, 01251], lr: 0.000776, loss: 0.4198
2022-09-30 19:57:27 - train: epoch 0186, iter [01230, 01251], lr: 0.000776, loss: 0.3873
2022-09-30 19:57:45 - train: epoch 0186, iter [01240, 01251], lr: 0.000775, loss: 0.4087
2022-09-30 19:58:03 - train: epoch 0186, iter [01250, 01251], lr: 0.000775, loss: 0.4040
2022-09-30 19:58:06 - train: epoch 186, train_loss: 0.4080
2022-09-30 19:58:09 - until epoch: 186, best_loss: 0.4080
2022-09-30 19:58:09 - epoch 187 lr: 0.000775
2022-09-30 19:58:34 - train: epoch 0187, iter [00010, 01251], lr: 0.000775, loss: 0.3985
2022-09-30 19:58:52 - train: epoch 0187, iter [00020, 01251], lr: 0.000775, loss: 0.3915
2022-09-30 19:59:10 - train: epoch 0187, iter [00030, 01251], lr: 0.000775, loss: 0.4114
2022-09-30 19:59:28 - train: epoch 0187, iter [00040, 01251], lr: 0.000775, loss: 0.4230
2022-09-30 19:59:46 - train: epoch 0187, iter [00050, 01251], lr: 0.000775, loss: 0.4118
2022-09-30 20:00:04 - train: epoch 0187, iter [00060, 01251], lr: 0.000775, loss: 0.4085
2022-09-30 20:00:22 - train: epoch 0187, iter [00070, 01251], lr: 0.000775, loss: 0.4050
2022-09-30 20:00:40 - train: epoch 0187, iter [00080, 01251], lr: 0.000775, loss: 0.4169
2022-09-30 20:00:59 - train: epoch 0187, iter [00090, 01251], lr: 0.000775, loss: 0.4297
2022-09-30 20:01:17 - train: epoch 0187, iter [00100, 01251], lr: 0.000775, loss: 0.4234
2022-09-30 20:01:35 - train: epoch 0187, iter [00110, 01251], lr: 0.000775, loss: 0.4061
2022-09-30 20:01:53 - train: epoch 0187, iter [00120, 01251], lr: 0.000775, loss: 0.3932
2022-09-30 20:02:11 - train: epoch 0187, iter [00130, 01251], lr: 0.000775, loss: 0.3926
2022-09-30 20:02:29 - train: epoch 0187, iter [00140, 01251], lr: 0.000775, loss: 0.3942
2022-09-30 20:02:47 - train: epoch 0187, iter [00150, 01251], lr: 0.000775, loss: 0.4050
2022-09-30 20:03:05 - train: epoch 0187, iter [00160, 01251], lr: 0.000775, loss: 0.4292
2022-09-30 20:03:23 - train: epoch 0187, iter [00170, 01251], lr: 0.000775, loss: 0.4251
2022-09-30 20:03:41 - train: epoch 0187, iter [00180, 01251], lr: 0.000775, loss: 0.3911
2022-09-30 20:03:59 - train: epoch 0187, iter [00190, 01251], lr: 0.000775, loss: 0.4098
2022-09-30 20:04:17 - train: epoch 0187, iter [00200, 01251], lr: 0.000775, loss: 0.4060
2022-09-30 20:04:35 - train: epoch 0187, iter [00210, 01251], lr: 0.000775, loss: 0.3965
2022-09-30 20:04:53 - train: epoch 0187, iter [00220, 01251], lr: 0.000775, loss: 0.4104
2022-09-30 20:05:11 - train: epoch 0187, iter [00230, 01251], lr: 0.000775, loss: 0.4132
2022-09-30 20:05:29 - train: epoch 0187, iter [00240, 01251], lr: 0.000774, loss: 0.3962
2022-09-30 20:05:47 - train: epoch 0187, iter [00250, 01251], lr: 0.000774, loss: 0.3985
2022-09-30 20:06:05 - train: epoch 0187, iter [00260, 01251], lr: 0.000774, loss: 0.4263
2022-09-30 20:06:23 - train: epoch 0187, iter [00270, 01251], lr: 0.000774, loss: 0.4114
2022-09-30 20:06:41 - train: epoch 0187, iter [00280, 01251], lr: 0.000774, loss: 0.3990
2022-09-30 20:06:59 - train: epoch 0187, iter [00290, 01251], lr: 0.000774, loss: 0.4056
2022-09-30 20:07:17 - train: epoch 0187, iter [00300, 01251], lr: 0.000774, loss: 0.3903
2022-09-30 20:07:35 - train: epoch 0187, iter [00310, 01251], lr: 0.000774, loss: 0.4237
2022-09-30 20:07:53 - train: epoch 0187, iter [00320, 01251], lr: 0.000774, loss: 0.4037
2022-09-30 20:08:11 - train: epoch 0187, iter [00330, 01251], lr: 0.000774, loss: 0.4051
2022-09-30 20:08:29 - train: epoch 0187, iter [00340, 01251], lr: 0.000774, loss: 0.4007
2022-09-30 20:08:47 - train: epoch 0187, iter [00350, 01251], lr: 0.000774, loss: 0.4242
2022-09-30 20:09:05 - train: epoch 0187, iter [00360, 01251], lr: 0.000774, loss: 0.4121
2022-09-30 20:09:23 - train: epoch 0187, iter [00370, 01251], lr: 0.000774, loss: 0.4122
2022-09-30 20:09:41 - train: epoch 0187, iter [00380, 01251], lr: 0.000774, loss: 0.4334
2022-09-30 20:09:59 - train: epoch 0187, iter [00390, 01251], lr: 0.000774, loss: 0.4158
2022-09-30 20:10:17 - train: epoch 0187, iter [00400, 01251], lr: 0.000774, loss: 0.4107
2022-09-30 20:10:35 - train: epoch 0187, iter [00410, 01251], lr: 0.000774, loss: 0.4143
2022-09-30 20:10:53 - train: epoch 0187, iter [00420, 01251], lr: 0.000774, loss: 0.4293
2022-09-30 20:11:11 - train: epoch 0187, iter [00430, 01251], lr: 0.000774, loss: 0.4080
2022-09-30 20:11:29 - train: epoch 0187, iter [00440, 01251], lr: 0.000774, loss: 0.3965
2022-09-30 20:11:47 - train: epoch 0187, iter [00450, 01251], lr: 0.000774, loss: 0.4021
2022-09-30 20:12:05 - train: epoch 0187, iter [00460, 01251], lr: 0.000774, loss: 0.4140
2022-09-30 20:12:23 - train: epoch 0187, iter [00470, 01251], lr: 0.000774, loss: 0.4316
2022-09-30 20:12:41 - train: epoch 0187, iter [00480, 01251], lr: 0.000774, loss: 0.4053
2022-09-30 20:12:59 - train: epoch 0187, iter [00490, 01251], lr: 0.000773, loss: 0.4045
2022-09-30 20:13:17 - train: epoch 0187, iter [00500, 01251], lr: 0.000773, loss: 0.4003
2022-09-30 20:13:35 - train: epoch 0187, iter [00510, 01251], lr: 0.000773, loss: 0.3874
2022-09-30 20:13:53 - train: epoch 0187, iter [00520, 01251], lr: 0.000773, loss: 0.4101
2022-09-30 20:14:11 - train: epoch 0187, iter [00530, 01251], lr: 0.000773, loss: 0.4056
2022-09-30 20:14:30 - train: epoch 0187, iter [00540, 01251], lr: 0.000773, loss: 0.3952
2022-09-30 20:14:48 - train: epoch 0187, iter [00550, 01251], lr: 0.000773, loss: 0.4073
2022-09-30 20:15:06 - train: epoch 0187, iter [00560, 01251], lr: 0.000773, loss: 0.4087
2022-09-30 20:15:24 - train: epoch 0187, iter [00570, 01251], lr: 0.000773, loss: 0.4034
2022-09-30 20:15:42 - train: epoch 0187, iter [00580, 01251], lr: 0.000773, loss: 0.4070
2022-09-30 20:16:00 - train: epoch 0187, iter [00590, 01251], lr: 0.000773, loss: 0.4222
2022-09-30 20:16:18 - train: epoch 0187, iter [00600, 01251], lr: 0.000773, loss: 0.4002
2022-09-30 20:16:36 - train: epoch 0187, iter [00610, 01251], lr: 0.000773, loss: 0.4107
2022-09-30 20:16:54 - train: epoch 0187, iter [00620, 01251], lr: 0.000773, loss: 0.4129
2022-09-30 20:17:12 - train: epoch 0187, iter [00630, 01251], lr: 0.000773, loss: 0.4044
2022-09-30 20:17:30 - train: epoch 0187, iter [00640, 01251], lr: 0.000773, loss: 0.3927
2022-09-30 20:17:48 - train: epoch 0187, iter [00650, 01251], lr: 0.000773, loss: 0.4013
2022-09-30 20:18:07 - train: epoch 0187, iter [00660, 01251], lr: 0.000773, loss: 0.4118
2022-09-30 20:18:25 - train: epoch 0187, iter [00670, 01251], lr: 0.000773, loss: 0.3910
2022-09-30 20:18:43 - train: epoch 0187, iter [00680, 01251], lr: 0.000773, loss: 0.4034
2022-09-30 20:19:01 - train: epoch 0187, iter [00690, 01251], lr: 0.000773, loss: 0.4101
2022-09-30 20:19:19 - train: epoch 0187, iter [00700, 01251], lr: 0.000773, loss: 0.4138
2022-09-30 20:19:37 - train: epoch 0187, iter [00710, 01251], lr: 0.000773, loss: 0.4020
2022-09-30 20:19:56 - train: epoch 0187, iter [00720, 01251], lr: 0.000773, loss: 0.4167
2022-09-30 20:20:14 - train: epoch 0187, iter [00730, 01251], lr: 0.000772, loss: 0.4167
2022-09-30 20:20:32 - train: epoch 0187, iter [00740, 01251], lr: 0.000772, loss: 0.4015
2022-09-30 20:20:51 - train: epoch 0187, iter [00750, 01251], lr: 0.000772, loss: 0.4232
2022-09-30 20:21:09 - train: epoch 0187, iter [00760, 01251], lr: 0.000772, loss: 0.4034
2022-09-30 20:21:27 - train: epoch 0187, iter [00770, 01251], lr: 0.000772, loss: 0.4137
2022-09-30 20:21:45 - train: epoch 0187, iter [00780, 01251], lr: 0.000772, loss: 0.3862
2022-09-30 20:22:04 - train: epoch 0187, iter [00790, 01251], lr: 0.000772, loss: 0.3911
2022-09-30 20:22:22 - train: epoch 0187, iter [00800, 01251], lr: 0.000772, loss: 0.4269
2022-09-30 20:22:40 - train: epoch 0187, iter [00810, 01251], lr: 0.000772, loss: 0.4115
2022-09-30 20:22:58 - train: epoch 0187, iter [00820, 01251], lr: 0.000772, loss: 0.3974
2022-09-30 20:23:16 - train: epoch 0187, iter [00830, 01251], lr: 0.000772, loss: 0.4214
2022-09-30 20:23:35 - train: epoch 0187, iter [00840, 01251], lr: 0.000772, loss: 0.4279
2022-09-30 20:23:53 - train: epoch 0187, iter [00850, 01251], lr: 0.000772, loss: 0.4100
2022-09-30 20:24:11 - train: epoch 0187, iter [00860, 01251], lr: 0.000772, loss: 0.4078
2022-09-30 20:24:29 - train: epoch 0187, iter [00870, 01251], lr: 0.000772, loss: 0.3971
2022-09-30 20:24:47 - train: epoch 0187, iter [00880, 01251], lr: 0.000772, loss: 0.4147
2022-09-30 20:25:06 - train: epoch 0187, iter [00890, 01251], lr: 0.000772, loss: 0.4174
2022-09-30 20:25:23 - train: epoch 0187, iter [00900, 01251], lr: 0.000772, loss: 0.4041
2022-09-30 20:25:41 - train: epoch 0187, iter [00910, 01251], lr: 0.000772, loss: 0.3962
2022-09-30 20:26:00 - train: epoch 0187, iter [00920, 01251], lr: 0.000772, loss: 0.4124
2022-09-30 20:26:18 - train: epoch 0187, iter [00930, 01251], lr: 0.000772, loss: 0.4088
2022-09-30 20:26:36 - train: epoch 0187, iter [00940, 01251], lr: 0.000772, loss: 0.4290
2022-09-30 20:26:54 - train: epoch 0187, iter [00950, 01251], lr: 0.000772, loss: 0.4275
2022-09-30 20:27:12 - train: epoch 0187, iter [00960, 01251], lr: 0.000772, loss: 0.4153
2022-09-30 20:27:31 - train: epoch 0187, iter [00970, 01251], lr: 0.000772, loss: 0.4194
2022-09-30 20:27:49 - train: epoch 0187, iter [00980, 01251], lr: 0.000771, loss: 0.4019
2022-09-30 20:28:07 - train: epoch 0187, iter [00990, 01251], lr: 0.000771, loss: 0.4033
2022-09-30 20:28:25 - train: epoch 0187, iter [01000, 01251], lr: 0.000771, loss: 0.4206
2022-09-30 20:28:43 - train: epoch 0187, iter [01010, 01251], lr: 0.000771, loss: 0.4138
2022-09-30 20:29:01 - train: epoch 0187, iter [01020, 01251], lr: 0.000771, loss: 0.4281
2022-09-30 20:29:19 - train: epoch 0187, iter [01030, 01251], lr: 0.000771, loss: 0.4180
2022-09-30 20:29:36 - train: epoch 0187, iter [01040, 01251], lr: 0.000771, loss: 0.4123
2022-09-30 20:29:54 - train: epoch 0187, iter [01050, 01251], lr: 0.000771, loss: 0.4031
2022-09-30 20:30:13 - train: epoch 0187, iter [01060, 01251], lr: 0.000771, loss: 0.3752
2022-09-30 20:30:31 - train: epoch 0187, iter [01070, 01251], lr: 0.000771, loss: 0.3993
2022-09-30 20:30:49 - train: epoch 0187, iter [01080, 01251], lr: 0.000771, loss: 0.4059
2022-09-30 20:31:06 - train: epoch 0187, iter [01090, 01251], lr: 0.000771, loss: 0.3983
2022-09-30 20:31:25 - train: epoch 0187, iter [01100, 01251], lr: 0.000771, loss: 0.4184
2022-09-30 20:31:43 - train: epoch 0187, iter [01110, 01251], lr: 0.000771, loss: 0.4261
2022-09-30 20:32:02 - train: epoch 0187, iter [01120, 01251], lr: 0.000771, loss: 0.4040
2022-09-30 20:32:21 - train: epoch 0187, iter [01130, 01251], lr: 0.000771, loss: 0.4016
2022-09-30 20:32:39 - train: epoch 0187, iter [01140, 01251], lr: 0.000771, loss: 0.4117
2022-09-30 20:32:58 - train: epoch 0187, iter [01150, 01251], lr: 0.000771, loss: 0.3882
2022-09-30 20:33:17 - train: epoch 0187, iter [01160, 01251], lr: 0.000771, loss: 0.4090
2022-09-30 20:33:35 - train: epoch 0187, iter [01170, 01251], lr: 0.000771, loss: 0.4048
2022-09-30 20:33:54 - train: epoch 0187, iter [01180, 01251], lr: 0.000771, loss: 0.4056
2022-09-30 20:34:12 - train: epoch 0187, iter [01190, 01251], lr: 0.000771, loss: 0.4115
2022-09-30 20:34:31 - train: epoch 0187, iter [01200, 01251], lr: 0.000771, loss: 0.4144
2022-09-30 20:34:49 - train: epoch 0187, iter [01210, 01251], lr: 0.000771, loss: 0.4089
2022-09-30 20:35:08 - train: epoch 0187, iter [01220, 01251], lr: 0.000771, loss: 0.4045
2022-09-30 20:35:27 - train: epoch 0187, iter [01230, 01251], lr: 0.000770, loss: 0.4115
2022-09-30 20:35:45 - train: epoch 0187, iter [01240, 01251], lr: 0.000770, loss: 0.4067
2022-09-30 20:36:04 - train: epoch 0187, iter [01250, 01251], lr: 0.000770, loss: 0.4294
2022-09-30 20:36:07 - train: epoch 187, train_loss: 0.4080
2022-09-30 20:36:09 - until epoch: 187, best_loss: 0.4080
2022-09-30 20:36:09 - epoch 188 lr: 0.000770
2022-09-30 20:36:35 - train: epoch 0188, iter [00010, 01251], lr: 0.000770, loss: 0.4370
2022-09-30 20:36:53 - train: epoch 0188, iter [00020, 01251], lr: 0.000770, loss: 0.4092
2022-09-30 20:37:11 - train: epoch 0188, iter [00030, 01251], lr: 0.000770, loss: 0.4036
2022-09-30 20:37:30 - train: epoch 0188, iter [00040, 01251], lr: 0.000770, loss: 0.4068
2022-09-30 20:37:48 - train: epoch 0188, iter [00050, 01251], lr: 0.000770, loss: 0.4045
2022-09-30 20:38:06 - train: epoch 0188, iter [00060, 01251], lr: 0.000770, loss: 0.4112
2022-09-30 20:38:25 - train: epoch 0188, iter [00070, 01251], lr: 0.000770, loss: 0.4117
2022-09-30 20:38:43 - train: epoch 0188, iter [00080, 01251], lr: 0.000770, loss: 0.4015
2022-09-30 20:39:02 - train: epoch 0188, iter [00090, 01251], lr: 0.000770, loss: 0.4254
2022-09-30 20:39:20 - train: epoch 0188, iter [00100, 01251], lr: 0.000770, loss: 0.3979
2022-09-30 20:39:39 - train: epoch 0188, iter [00110, 01251], lr: 0.000770, loss: 0.4108
2022-09-30 20:39:57 - train: epoch 0188, iter [00120, 01251], lr: 0.000770, loss: 0.4004
2022-09-30 20:40:15 - train: epoch 0188, iter [00130, 01251], lr: 0.000770, loss: 0.4074
2022-09-30 20:40:34 - train: epoch 0188, iter [00140, 01251], lr: 0.000770, loss: 0.4089
2022-09-30 20:40:53 - train: epoch 0188, iter [00150, 01251], lr: 0.000770, loss: 0.3777
2022-09-30 20:41:11 - train: epoch 0188, iter [00160, 01251], lr: 0.000770, loss: 0.4127
2022-09-30 20:41:29 - train: epoch 0188, iter [00170, 01251], lr: 0.000770, loss: 0.3899
2022-09-30 20:41:47 - train: epoch 0188, iter [00180, 01251], lr: 0.000770, loss: 0.3957
2022-09-30 20:42:06 - train: epoch 0188, iter [00190, 01251], lr: 0.000770, loss: 0.3871
2022-09-30 20:42:24 - train: epoch 0188, iter [00200, 01251], lr: 0.000770, loss: 0.3972
2022-09-30 20:42:42 - train: epoch 0188, iter [00210, 01251], lr: 0.000770, loss: 0.3975
2022-09-30 20:43:00 - train: epoch 0188, iter [00220, 01251], lr: 0.000770, loss: 0.4098
2022-09-30 20:43:18 - train: epoch 0188, iter [00230, 01251], lr: 0.000769, loss: 0.4107
2022-09-30 20:43:36 - train: epoch 0188, iter [00240, 01251], lr: 0.000769, loss: 0.4116
2022-09-30 20:43:55 - train: epoch 0188, iter [00250, 01251], lr: 0.000769, loss: 0.4197
2022-09-30 20:44:13 - train: epoch 0188, iter [00260, 01251], lr: 0.000769, loss: 0.4135
2022-09-30 20:44:31 - train: epoch 0188, iter [00270, 01251], lr: 0.000769, loss: 0.4044
2022-09-30 20:44:49 - train: epoch 0188, iter [00280, 01251], lr: 0.000769, loss: 0.4154
2022-09-30 20:45:08 - train: epoch 0188, iter [00290, 01251], lr: 0.000769, loss: 0.3999
2022-09-30 20:45:26 - train: epoch 0188, iter [00300, 01251], lr: 0.000769, loss: 0.4013
2022-09-30 20:45:44 - train: epoch 0188, iter [00310, 01251], lr: 0.000769, loss: 0.4058
2022-09-30 20:46:02 - train: epoch 0188, iter [00320, 01251], lr: 0.000769, loss: 0.4106
2022-09-30 20:46:20 - train: epoch 0188, iter [00330, 01251], lr: 0.000769, loss: 0.4172
2022-09-30 20:46:38 - train: epoch 0188, iter [00340, 01251], lr: 0.000769, loss: 0.3978
2022-09-30 20:46:56 - train: epoch 0188, iter [00350, 01251], lr: 0.000769, loss: 0.4090
2022-09-30 20:47:14 - train: epoch 0188, iter [00360, 01251], lr: 0.000769, loss: 0.4174
2022-09-30 20:47:33 - train: epoch 0188, iter [00370, 01251], lr: 0.000769, loss: 0.4229
2022-09-30 20:47:51 - train: epoch 0188, iter [00380, 01251], lr: 0.000769, loss: 0.4016
2022-09-30 20:48:09 - train: epoch 0188, iter [00390, 01251], lr: 0.000769, loss: 0.3951
2022-09-30 20:48:27 - train: epoch 0188, iter [00400, 01251], lr: 0.000769, loss: 0.4031
2022-09-30 20:48:45 - train: epoch 0188, iter [00410, 01251], lr: 0.000769, loss: 0.3947
2022-09-30 20:49:03 - train: epoch 0188, iter [00420, 01251], lr: 0.000769, loss: 0.4022
2022-09-30 20:49:21 - train: epoch 0188, iter [00430, 01251], lr: 0.000769, loss: 0.4120
2022-09-30 20:49:40 - train: epoch 0188, iter [00440, 01251], lr: 0.000769, loss: 0.4096
2022-09-30 20:49:58 - train: epoch 0188, iter [00450, 01251], lr: 0.000769, loss: 0.4158
2022-09-30 20:50:16 - train: epoch 0188, iter [00460, 01251], lr: 0.000769, loss: 0.4098
2022-09-30 20:50:34 - train: epoch 0188, iter [00470, 01251], lr: 0.000769, loss: 0.4183
2022-09-30 20:50:52 - train: epoch 0188, iter [00480, 01251], lr: 0.000768, loss: 0.4179
2022-09-30 20:51:10 - train: epoch 0188, iter [00490, 01251], lr: 0.000768, loss: 0.3839
2022-09-30 20:51:29 - train: epoch 0188, iter [00500, 01251], lr: 0.000768, loss: 0.3996
2022-09-30 20:51:47 - train: epoch 0188, iter [00510, 01251], lr: 0.000768, loss: 0.4051
2022-09-30 20:52:05 - train: epoch 0188, iter [00520, 01251], lr: 0.000768, loss: 0.4053
2022-09-30 20:52:23 - train: epoch 0188, iter [00530, 01251], lr: 0.000768, loss: 0.4179
2022-09-30 20:52:41 - train: epoch 0188, iter [00540, 01251], lr: 0.000768, loss: 0.4212
2022-09-30 20:52:59 - train: epoch 0188, iter [00550, 01251], lr: 0.000768, loss: 0.4070
2022-09-30 20:53:17 - train: epoch 0188, iter [00560, 01251], lr: 0.000768, loss: 0.4051
2022-09-30 20:53:35 - train: epoch 0188, iter [00570, 01251], lr: 0.000768, loss: 0.4068
2022-09-30 20:53:54 - train: epoch 0188, iter [00580, 01251], lr: 0.000768, loss: 0.4084
2022-09-30 20:54:12 - train: epoch 0188, iter [00590, 01251], lr: 0.000768, loss: 0.4224
2022-09-30 20:54:30 - train: epoch 0188, iter [00600, 01251], lr: 0.000768, loss: 0.4267
2022-09-30 20:54:48 - train: epoch 0188, iter [00610, 01251], lr: 0.000768, loss: 0.4427
2022-09-30 20:55:06 - train: epoch 0188, iter [00620, 01251], lr: 0.000768, loss: 0.4029
2022-09-30 20:55:24 - train: epoch 0188, iter [00630, 01251], lr: 0.000768, loss: 0.4089
2022-09-30 20:55:43 - train: epoch 0188, iter [00640, 01251], lr: 0.000768, loss: 0.4122
2022-09-30 20:56:01 - train: epoch 0188, iter [00650, 01251], lr: 0.000768, loss: 0.4159
2022-09-30 20:56:19 - train: epoch 0188, iter [00660, 01251], lr: 0.000768, loss: 0.3856
2022-09-30 20:56:37 - train: epoch 0188, iter [00670, 01251], lr: 0.000768, loss: 0.4035
2022-09-30 20:56:55 - train: epoch 0188, iter [00680, 01251], lr: 0.000768, loss: 0.4005
2022-09-30 20:57:13 - train: epoch 0188, iter [00690, 01251], lr: 0.000768, loss: 0.4082
2022-09-30 20:57:31 - train: epoch 0188, iter [00700, 01251], lr: 0.000768, loss: 0.4152
2022-09-30 20:57:50 - train: epoch 0188, iter [00710, 01251], lr: 0.000768, loss: 0.4086
2022-09-30 20:58:08 - train: epoch 0188, iter [00720, 01251], lr: 0.000768, loss: 0.3809
2022-09-30 20:58:26 - train: epoch 0188, iter [00730, 01251], lr: 0.000767, loss: 0.4047
2022-09-30 20:58:44 - train: epoch 0188, iter [00740, 01251], lr: 0.000767, loss: 0.3903
2022-09-30 20:59:02 - train: epoch 0188, iter [00750, 01251], lr: 0.000767, loss: 0.3904
2022-09-30 20:59:20 - train: epoch 0188, iter [00760, 01251], lr: 0.000767, loss: 0.4155
2022-09-30 20:59:38 - train: epoch 0188, iter [00770, 01251], lr: 0.000767, loss: 0.4240
2022-09-30 20:59:56 - train: epoch 0188, iter [00780, 01251], lr: 0.000767, loss: 0.3984
2022-09-30 21:00:14 - train: epoch 0188, iter [00790, 01251], lr: 0.000767, loss: 0.4029
2022-09-30 21:00:33 - train: epoch 0188, iter [00800, 01251], lr: 0.000767, loss: 0.3936
2022-09-30 21:00:50 - train: epoch 0188, iter [00810, 01251], lr: 0.000767, loss: 0.4099
2022-09-30 21:01:09 - train: epoch 0188, iter [00820, 01251], lr: 0.000767, loss: 0.4088
2022-09-30 21:01:27 - train: epoch 0188, iter [00830, 01251], lr: 0.000767, loss: 0.3899
2022-09-30 21:01:45 - train: epoch 0188, iter [00840, 01251], lr: 0.000767, loss: 0.4291
2022-09-30 21:02:03 - train: epoch 0188, iter [00850, 01251], lr: 0.000767, loss: 0.3921
2022-09-30 21:02:21 - train: epoch 0188, iter [00860, 01251], lr: 0.000767, loss: 0.3987
2022-09-30 21:02:39 - train: epoch 0188, iter [00870, 01251], lr: 0.000767, loss: 0.3977
2022-09-30 21:02:57 - train: epoch 0188, iter [00880, 01251], lr: 0.000767, loss: 0.3974
2022-09-30 21:03:15 - train: epoch 0188, iter [00890, 01251], lr: 0.000767, loss: 0.4200
2022-09-30 21:03:33 - train: epoch 0188, iter [00900, 01251], lr: 0.000767, loss: 0.3747
2022-09-30 21:03:51 - train: epoch 0188, iter [00910, 01251], lr: 0.000767, loss: 0.4193
2022-09-30 21:04:09 - train: epoch 0188, iter [00920, 01251], lr: 0.000767, loss: 0.4183
2022-09-30 21:04:27 - train: epoch 0188, iter [00930, 01251], lr: 0.000767, loss: 0.3965
2022-09-30 21:04:45 - train: epoch 0188, iter [00940, 01251], lr: 0.000767, loss: 0.4024
2022-09-30 21:05:03 - train: epoch 0188, iter [00950, 01251], lr: 0.000767, loss: 0.4130
2022-09-30 21:05:21 - train: epoch 0188, iter [00960, 01251], lr: 0.000767, loss: 0.4071
2022-09-30 21:05:39 - train: epoch 0188, iter [00970, 01251], lr: 0.000767, loss: 0.4036
2022-09-30 21:05:57 - train: epoch 0188, iter [00980, 01251], lr: 0.000766, loss: 0.4073
2022-09-30 21:06:16 - train: epoch 0188, iter [00990, 01251], lr: 0.000766, loss: 0.4066
2022-09-30 21:06:34 - train: epoch 0188, iter [01000, 01251], lr: 0.000766, loss: 0.4060
2022-09-30 21:06:52 - train: epoch 0188, iter [01010, 01251], lr: 0.000766, loss: 0.4138
2022-09-30 21:07:10 - train: epoch 0188, iter [01020, 01251], lr: 0.000766, loss: 0.4283
2022-09-30 21:07:28 - train: epoch 0188, iter [01030, 01251], lr: 0.000766, loss: 0.4094
2022-09-30 21:07:46 - train: epoch 0188, iter [01040, 01251], lr: 0.000766, loss: 0.4064
2022-09-30 21:08:04 - train: epoch 0188, iter [01050, 01251], lr: 0.000766, loss: 0.4130
2022-09-30 21:08:22 - train: epoch 0188, iter [01060, 01251], lr: 0.000766, loss: 0.3976
2022-09-30 21:08:40 - train: epoch 0188, iter [01070, 01251], lr: 0.000766, loss: 0.4064
2022-09-30 21:08:58 - train: epoch 0188, iter [01080, 01251], lr: 0.000766, loss: 0.4134
2022-09-30 21:09:16 - train: epoch 0188, iter [01090, 01251], lr: 0.000766, loss: 0.3969
2022-09-30 21:09:35 - train: epoch 0188, iter [01100, 01251], lr: 0.000766, loss: 0.3992
2022-09-30 21:09:53 - train: epoch 0188, iter [01110, 01251], lr: 0.000766, loss: 0.4121
2022-09-30 21:10:11 - train: epoch 0188, iter [01120, 01251], lr: 0.000766, loss: 0.4181
2022-09-30 21:10:29 - train: epoch 0188, iter [01130, 01251], lr: 0.000766, loss: 0.4037
2022-09-30 21:10:47 - train: epoch 0188, iter [01140, 01251], lr: 0.000766, loss: 0.4012
2022-09-30 21:11:05 - train: epoch 0188, iter [01150, 01251], lr: 0.000766, loss: 0.4338
2022-09-30 21:11:23 - train: epoch 0188, iter [01160, 01251], lr: 0.000766, loss: 0.4176
2022-09-30 21:11:41 - train: epoch 0188, iter [01170, 01251], lr: 0.000766, loss: 0.4010
2022-09-30 21:11:59 - train: epoch 0188, iter [01180, 01251], lr: 0.000766, loss: 0.4169
2022-09-30 21:12:18 - train: epoch 0188, iter [01190, 01251], lr: 0.000766, loss: 0.3996
2022-09-30 21:12:36 - train: epoch 0188, iter [01200, 01251], lr: 0.000766, loss: 0.4103
2022-09-30 21:12:54 - train: epoch 0188, iter [01210, 01251], lr: 0.000766, loss: 0.4257
2022-09-30 21:13:12 - train: epoch 0188, iter [01220, 01251], lr: 0.000766, loss: 0.3967
2022-09-30 21:13:30 - train: epoch 0188, iter [01230, 01251], lr: 0.000765, loss: 0.3917
2022-09-30 21:13:48 - train: epoch 0188, iter [01240, 01251], lr: 0.000765, loss: 0.4106
2022-09-30 21:14:05 - train: epoch 0188, iter [01250, 01251], lr: 0.000765, loss: 0.4219
2022-09-30 21:14:09 - train: epoch 188, train_loss: 0.4080
2022-09-30 21:14:10 - until epoch: 188, best_loss: 0.4080
2022-09-30 21:14:10 - epoch 189 lr: 0.000765
2022-09-30 21:14:37 - train: epoch 0189, iter [00010, 01251], lr: 0.000765, loss: 0.4142
2022-09-30 21:14:56 - train: epoch 0189, iter [00020, 01251], lr: 0.000765, loss: 0.4112
2022-09-30 21:15:14 - train: epoch 0189, iter [00030, 01251], lr: 0.000765, loss: 0.4057
2022-09-30 21:15:32 - train: epoch 0189, iter [00040, 01251], lr: 0.000765, loss: 0.4092
2022-09-30 21:15:50 - train: epoch 0189, iter [00050, 01251], lr: 0.000765, loss: 0.4017
2022-09-30 21:16:08 - train: epoch 0189, iter [00060, 01251], lr: 0.000765, loss: 0.4097
2022-09-30 21:16:25 - train: epoch 0189, iter [00070, 01251], lr: 0.000765, loss: 0.4128
2022-09-30 21:16:43 - train: epoch 0189, iter [00080, 01251], lr: 0.000765, loss: 0.4009
2022-09-30 21:17:01 - train: epoch 0189, iter [00090, 01251], lr: 0.000765, loss: 0.4061
2022-09-30 21:17:19 - train: epoch 0189, iter [00100, 01251], lr: 0.000765, loss: 0.4144
2022-09-30 21:17:36 - train: epoch 0189, iter [00110, 01251], lr: 0.000765, loss: 0.4211
2022-09-30 21:17:54 - train: epoch 0189, iter [00120, 01251], lr: 0.000765, loss: 0.3904
2022-09-30 21:18:12 - train: epoch 0189, iter [00130, 01251], lr: 0.000765, loss: 0.4040
2022-09-30 21:18:30 - train: epoch 0189, iter [00140, 01251], lr: 0.000765, loss: 0.4045
2022-09-30 21:18:48 - train: epoch 0189, iter [00150, 01251], lr: 0.000765, loss: 0.4039
2022-09-30 21:19:06 - train: epoch 0189, iter [00160, 01251], lr: 0.000765, loss: 0.4276
2022-09-30 21:19:24 - train: epoch 0189, iter [00170, 01251], lr: 0.000765, loss: 0.4062
2022-09-30 21:19:42 - train: epoch 0189, iter [00180, 01251], lr: 0.000765, loss: 0.4126
2022-09-30 21:19:59 - train: epoch 0189, iter [00190, 01251], lr: 0.000765, loss: 0.4011
2022-09-30 21:20:17 - train: epoch 0189, iter [00200, 01251], lr: 0.000765, loss: 0.4138
2022-09-30 21:20:35 - train: epoch 0189, iter [00210, 01251], lr: 0.000765, loss: 0.3856
2022-09-30 21:20:53 - train: epoch 0189, iter [00220, 01251], lr: 0.000764, loss: 0.4241
2022-09-30 21:21:11 - train: epoch 0189, iter [00230, 01251], lr: 0.000764, loss: 0.4091
2022-09-30 21:21:29 - train: epoch 0189, iter [00240, 01251], lr: 0.000764, loss: 0.4017
2022-09-30 21:21:47 - train: epoch 0189, iter [00250, 01251], lr: 0.000764, loss: 0.3954
2022-09-30 21:22:05 - train: epoch 0189, iter [00260, 01251], lr: 0.000764, loss: 0.3998
2022-09-30 21:22:23 - train: epoch 0189, iter [00270, 01251], lr: 0.000764, loss: 0.4023
2022-09-30 21:22:41 - train: epoch 0189, iter [00280, 01251], lr: 0.000764, loss: 0.4239
2022-09-30 21:22:59 - train: epoch 0189, iter [00290, 01251], lr: 0.000764, loss: 0.4260
2022-09-30 21:23:17 - train: epoch 0189, iter [00300, 01251], lr: 0.000764, loss: 0.4170
2022-09-30 21:23:35 - train: epoch 0189, iter [00310, 01251], lr: 0.000764, loss: 0.3955
2022-09-30 21:23:53 - train: epoch 0189, iter [00320, 01251], lr: 0.000764, loss: 0.3993
2022-09-30 21:24:11 - train: epoch 0189, iter [00330, 01251], lr: 0.000764, loss: 0.4034
2022-09-30 21:24:29 - train: epoch 0189, iter [00340, 01251], lr: 0.000764, loss: 0.3944
2022-09-30 21:24:47 - train: epoch 0189, iter [00350, 01251], lr: 0.000764, loss: 0.3894
2022-09-30 21:25:05 - train: epoch 0189, iter [00360, 01251], lr: 0.000764, loss: 0.4093
2022-09-30 21:25:23 - train: epoch 0189, iter [00370, 01251], lr: 0.000764, loss: 0.4155
2022-09-30 21:25:41 - train: epoch 0189, iter [00380, 01251], lr: 0.000764, loss: 0.3992
2022-09-30 21:25:59 - train: epoch 0189, iter [00390, 01251], lr: 0.000764, loss: 0.4165
2022-09-30 21:26:17 - train: epoch 0189, iter [00400, 01251], lr: 0.000764, loss: 0.4097
2022-09-30 21:26:34 - train: epoch 0189, iter [00410, 01251], lr: 0.000764, loss: 0.3863
2022-09-30 21:26:52 - train: epoch 0189, iter [00420, 01251], lr: 0.000764, loss: 0.4074
2022-09-30 21:27:10 - train: epoch 0189, iter [00430, 01251], lr: 0.000764, loss: 0.4099
2022-09-30 21:27:28 - train: epoch 0189, iter [00440, 01251], lr: 0.000764, loss: 0.4103
2022-09-30 21:27:46 - train: epoch 0189, iter [00450, 01251], lr: 0.000764, loss: 0.3867
2022-09-30 21:28:04 - train: epoch 0189, iter [00460, 01251], lr: 0.000764, loss: 0.4157
2022-09-30 21:28:22 - train: epoch 0189, iter [00470, 01251], lr: 0.000763, loss: 0.4154
2022-09-30 21:28:39 - train: epoch 0189, iter [00480, 01251], lr: 0.000763, loss: 0.4167
2022-09-30 21:28:57 - train: epoch 0189, iter [00490, 01251], lr: 0.000763, loss: 0.4213
2022-09-30 21:29:15 - train: epoch 0189, iter [00500, 01251], lr: 0.000763, loss: 0.4187
2022-09-30 21:29:33 - train: epoch 0189, iter [00510, 01251], lr: 0.000763, loss: 0.3957
2022-09-30 21:29:50 - train: epoch 0189, iter [00520, 01251], lr: 0.000763, loss: 0.4180
2022-09-30 21:30:08 - train: epoch 0189, iter [00530, 01251], lr: 0.000763, loss: 0.3988
2022-09-30 21:30:26 - train: epoch 0189, iter [00540, 01251], lr: 0.000763, loss: 0.4142
2022-09-30 21:30:44 - train: epoch 0189, iter [00550, 01251], lr: 0.000763, loss: 0.4169
2022-09-30 21:31:01 - train: epoch 0189, iter [00560, 01251], lr: 0.000763, loss: 0.4036
2022-09-30 21:31:19 - train: epoch 0189, iter [00570, 01251], lr: 0.000763, loss: 0.3999
2022-09-30 21:31:37 - train: epoch 0189, iter [00580, 01251], lr: 0.000763, loss: 0.3922
2022-09-30 21:31:55 - train: epoch 0189, iter [00590, 01251], lr: 0.000763, loss: 0.4031
2022-09-30 21:32:12 - train: epoch 0189, iter [00600, 01251], lr: 0.000763, loss: 0.4178
2022-09-30 21:32:30 - train: epoch 0189, iter [00610, 01251], lr: 0.000763, loss: 0.3962
2022-09-30 21:32:48 - train: epoch 0189, iter [00620, 01251], lr: 0.000763, loss: 0.4018
2022-09-30 21:33:06 - train: epoch 0189, iter [00630, 01251], lr: 0.000763, loss: 0.3839
2022-09-30 21:33:24 - train: epoch 0189, iter [00640, 01251], lr: 0.000763, loss: 0.3893
2022-09-30 21:33:41 - train: epoch 0189, iter [00650, 01251], lr: 0.000763, loss: 0.4144
2022-09-30 21:33:59 - train: epoch 0189, iter [00660, 01251], lr: 0.000763, loss: 0.4162
2022-09-30 21:34:17 - train: epoch 0189, iter [00670, 01251], lr: 0.000763, loss: 0.4127
2022-09-30 21:34:34 - train: epoch 0189, iter [00680, 01251], lr: 0.000763, loss: 0.3914
2022-09-30 21:34:52 - train: epoch 0189, iter [00690, 01251], lr: 0.000763, loss: 0.4119
2022-09-30 21:35:10 - train: epoch 0189, iter [00700, 01251], lr: 0.000763, loss: 0.3926
2022-09-30 21:35:28 - train: epoch 0189, iter [00710, 01251], lr: 0.000763, loss: 0.4108
2022-09-30 21:35:45 - train: epoch 0189, iter [00720, 01251], lr: 0.000762, loss: 0.4132
2022-09-30 21:36:03 - train: epoch 0189, iter [00730, 01251], lr: 0.000762, loss: 0.4133
2022-09-30 21:36:21 - train: epoch 0189, iter [00740, 01251], lr: 0.000762, loss: 0.3992
2022-09-30 21:36:39 - train: epoch 0189, iter [00750, 01251], lr: 0.000762, loss: 0.4033
2022-09-30 21:36:56 - train: epoch 0189, iter [00760, 01251], lr: 0.000762, loss: 0.3854
2022-09-30 21:37:14 - train: epoch 0189, iter [00770, 01251], lr: 0.000762, loss: 0.4151
2022-09-30 21:37:32 - train: epoch 0189, iter [00780, 01251], lr: 0.000762, loss: 0.4161
2022-09-30 21:37:50 - train: epoch 0189, iter [00790, 01251], lr: 0.000762, loss: 0.4219
2022-09-30 21:38:08 - train: epoch 0189, iter [00800, 01251], lr: 0.000762, loss: 0.3981
2022-09-30 21:38:25 - train: epoch 0189, iter [00810, 01251], lr: 0.000762, loss: 0.4023
2022-09-30 21:38:43 - train: epoch 0189, iter [00820, 01251], lr: 0.000762, loss: 0.4216
2022-09-30 21:39:01 - train: epoch 0189, iter [00830, 01251], lr: 0.000762, loss: 0.4373
2022-09-30 21:39:19 - train: epoch 0189, iter [00840, 01251], lr: 0.000762, loss: 0.3961
2022-09-30 21:39:37 - train: epoch 0189, iter [00850, 01251], lr: 0.000762, loss: 0.4079
2022-09-30 21:39:54 - train: epoch 0189, iter [00860, 01251], lr: 0.000762, loss: 0.4206
2022-09-30 21:40:12 - train: epoch 0189, iter [00870, 01251], lr: 0.000762, loss: 0.4197
2022-09-30 21:40:30 - train: epoch 0189, iter [00880, 01251], lr: 0.000762, loss: 0.3933
2022-09-30 21:40:48 - train: epoch 0189, iter [00890, 01251], lr: 0.000762, loss: 0.4157
2022-09-30 21:41:05 - train: epoch 0189, iter [00900, 01251], lr: 0.000762, loss: 0.3993
2022-09-30 21:41:23 - train: epoch 0189, iter [00910, 01251], lr: 0.000762, loss: 0.3924
2022-09-30 21:41:41 - train: epoch 0189, iter [00920, 01251], lr: 0.000762, loss: 0.4152
2022-09-30 21:41:59 - train: epoch 0189, iter [00930, 01251], lr: 0.000762, loss: 0.4189
2022-09-30 21:42:16 - train: epoch 0189, iter [00940, 01251], lr: 0.000762, loss: 0.3984
2022-09-30 21:42:34 - train: epoch 0189, iter [00950, 01251], lr: 0.000762, loss: 0.4202
2022-09-30 21:42:52 - train: epoch 0189, iter [00960, 01251], lr: 0.000762, loss: 0.4148
2022-09-30 21:43:10 - train: epoch 0189, iter [00970, 01251], lr: 0.000761, loss: 0.4038
2022-09-30 21:43:28 - train: epoch 0189, iter [00980, 01251], lr: 0.000761, loss: 0.4048
2022-09-30 21:43:45 - train: epoch 0189, iter [00990, 01251], lr: 0.000761, loss: 0.3967
2022-09-30 21:44:03 - train: epoch 0189, iter [01000, 01251], lr: 0.000761, loss: 0.4166
2022-09-30 21:44:21 - train: epoch 0189, iter [01010, 01251], lr: 0.000761, loss: 0.3983
2022-09-30 21:44:38 - train: epoch 0189, iter [01020, 01251], lr: 0.000761, loss: 0.3972
2022-09-30 21:44:56 - train: epoch 0189, iter [01030, 01251], lr: 0.000761, loss: 0.4114
2022-09-30 21:45:14 - train: epoch 0189, iter [01040, 01251], lr: 0.000761, loss: 0.4138
2022-09-30 21:45:31 - train: epoch 0189, iter [01050, 01251], lr: 0.000761, loss: 0.4100
2022-09-30 21:45:49 - train: epoch 0189, iter [01060, 01251], lr: 0.000761, loss: 0.3999
2022-09-30 21:46:07 - train: epoch 0189, iter [01070, 01251], lr: 0.000761, loss: 0.4116
2022-09-30 21:46:25 - train: epoch 0189, iter [01080, 01251], lr: 0.000761, loss: 0.3829
2022-09-30 21:46:43 - train: epoch 0189, iter [01090, 01251], lr: 0.000761, loss: 0.4074
2022-09-30 21:47:00 - train: epoch 0189, iter [01100, 01251], lr: 0.000761, loss: 0.4029
2022-09-30 21:47:18 - train: epoch 0189, iter [01110, 01251], lr: 0.000761, loss: 0.4084
2022-09-30 21:47:36 - train: epoch 0189, iter [01120, 01251], lr: 0.000761, loss: 0.3945
2022-09-30 21:47:54 - train: epoch 0189, iter [01130, 01251], lr: 0.000761, loss: 0.3982
2022-09-30 21:48:11 - train: epoch 0189, iter [01140, 01251], lr: 0.000761, loss: 0.3933
2022-09-30 21:48:29 - train: epoch 0189, iter [01150, 01251], lr: 0.000761, loss: 0.4039
2022-09-30 21:48:47 - train: epoch 0189, iter [01160, 01251], lr: 0.000761, loss: 0.3908
2022-09-30 21:49:05 - train: epoch 0189, iter [01170, 01251], lr: 0.000761, loss: 0.4037
2022-09-30 21:49:23 - train: epoch 0189, iter [01180, 01251], lr: 0.000761, loss: 0.4157
2022-09-30 21:49:40 - train: epoch 0189, iter [01190, 01251], lr: 0.000761, loss: 0.4039
2022-09-30 21:49:58 - train: epoch 0189, iter [01200, 01251], lr: 0.000761, loss: 0.4162
2022-09-30 21:50:16 - train: epoch 0189, iter [01210, 01251], lr: 0.000761, loss: 0.4230
2022-09-30 21:50:33 - train: epoch 0189, iter [01220, 01251], lr: 0.000760, loss: 0.4158
2022-09-30 21:50:51 - train: epoch 0189, iter [01230, 01251], lr: 0.000760, loss: 0.4087
2022-09-30 21:51:09 - train: epoch 0189, iter [01240, 01251], lr: 0.000760, loss: 0.4196
2022-09-30 21:51:26 - train: epoch 0189, iter [01250, 01251], lr: 0.000760, loss: 0.3955
2022-09-30 21:51:30 - train: epoch 189, train_loss: 0.4079
2022-09-30 21:51:32 - until epoch: 189, best_loss: 0.4079
2022-09-30 21:51:32 - epoch 190 lr: 0.000760
2022-09-30 21:51:58 - train: epoch 0190, iter [00010, 01251], lr: 0.000760, loss: 0.4167
2022-09-30 21:52:16 - train: epoch 0190, iter [00020, 01251], lr: 0.000760, loss: 0.3908
2022-09-30 21:52:33 - train: epoch 0190, iter [00030, 01251], lr: 0.000760, loss: 0.4002
2022-09-30 21:52:51 - train: epoch 0190, iter [00040, 01251], lr: 0.000760, loss: 0.4162
2022-09-30 21:53:09 - train: epoch 0190, iter [00050, 01251], lr: 0.000760, loss: 0.4185
2022-09-30 21:53:27 - train: epoch 0190, iter [00060, 01251], lr: 0.000760, loss: 0.4003
2022-09-30 21:53:44 - train: epoch 0190, iter [00070, 01251], lr: 0.000760, loss: 0.4099
2022-09-30 21:54:02 - train: epoch 0190, iter [00080, 01251], lr: 0.000760, loss: 0.4222
2022-09-30 21:54:20 - train: epoch 0190, iter [00090, 01251], lr: 0.000760, loss: 0.4063
2022-09-30 21:54:38 - train: epoch 0190, iter [00100, 01251], lr: 0.000760, loss: 0.4137
2022-09-30 21:54:55 - train: epoch 0190, iter [00110, 01251], lr: 0.000760, loss: 0.3945
2022-09-30 21:55:13 - train: epoch 0190, iter [00120, 01251], lr: 0.000760, loss: 0.4001
2022-09-30 21:55:31 - train: epoch 0190, iter [00130, 01251], lr: 0.000760, loss: 0.4116
2022-09-30 21:55:48 - train: epoch 0190, iter [00140, 01251], lr: 0.000760, loss: 0.4199
2022-09-30 21:56:06 - train: epoch 0190, iter [00150, 01251], lr: 0.000760, loss: 0.4311
2022-09-30 21:56:24 - train: epoch 0190, iter [00160, 01251], lr: 0.000760, loss: 0.4045
2022-09-30 21:56:41 - train: epoch 0190, iter [00170, 01251], lr: 0.000760, loss: 0.4152
2022-09-30 21:56:59 - train: epoch 0190, iter [00180, 01251], lr: 0.000760, loss: 0.4004
2022-09-30 21:57:17 - train: epoch 0190, iter [00190, 01251], lr: 0.000760, loss: 0.4163
2022-09-30 21:57:35 - train: epoch 0190, iter [00200, 01251], lr: 0.000760, loss: 0.4171
2022-09-30 21:57:52 - train: epoch 0190, iter [00210, 01251], lr: 0.000759, loss: 0.4166
2022-09-30 21:58:10 - train: epoch 0190, iter [00220, 01251], lr: 0.000759, loss: 0.4162
2022-09-30 21:58:28 - train: epoch 0190, iter [00230, 01251], lr: 0.000759, loss: 0.4008
2022-09-30 21:58:46 - train: epoch 0190, iter [00240, 01251], lr: 0.000759, loss: 0.4067
2022-09-30 21:59:04 - train: epoch 0190, iter [00250, 01251], lr: 0.000759, loss: 0.4113
2022-09-30 21:59:21 - train: epoch 0190, iter [00260, 01251], lr: 0.000759, loss: 0.3888
2022-09-30 21:59:39 - train: epoch 0190, iter [00270, 01251], lr: 0.000759, loss: 0.4038
2022-09-30 21:59:57 - train: epoch 0190, iter [00280, 01251], lr: 0.000759, loss: 0.3913
2022-09-30 22:00:15 - train: epoch 0190, iter [00290, 01251], lr: 0.000759, loss: 0.4168
2022-09-30 22:00:32 - train: epoch 0190, iter [00300, 01251], lr: 0.000759, loss: 0.4067
2022-09-30 22:00:50 - train: epoch 0190, iter [00310, 01251], lr: 0.000759, loss: 0.3970
2022-09-30 22:01:08 - train: epoch 0190, iter [00320, 01251], lr: 0.000759, loss: 0.3966
2022-09-30 22:01:25 - train: epoch 0190, iter [00330, 01251], lr: 0.000759, loss: 0.3792
2022-09-30 22:01:43 - train: epoch 0190, iter [00340, 01251], lr: 0.000759, loss: 0.4183
2022-09-30 22:02:01 - train: epoch 0190, iter [00350, 01251], lr: 0.000759, loss: 0.3957
2022-09-30 22:02:19 - train: epoch 0190, iter [00360, 01251], lr: 0.000759, loss: 0.4133
2022-09-30 22:02:37 - train: epoch 0190, iter [00370, 01251], lr: 0.000759, loss: 0.4140
2022-09-30 22:02:54 - train: epoch 0190, iter [00380, 01251], lr: 0.000759, loss: 0.4203
2022-09-30 22:03:12 - train: epoch 0190, iter [00390, 01251], lr: 0.000759, loss: 0.3990
2022-09-30 22:03:30 - train: epoch 0190, iter [00400, 01251], lr: 0.000759, loss: 0.4024
2022-09-30 22:03:47 - train: epoch 0190, iter [00410, 01251], lr: 0.000759, loss: 0.4077
2022-09-30 22:04:05 - train: epoch 0190, iter [00420, 01251], lr: 0.000759, loss: 0.4078
2022-09-30 22:04:23 - train: epoch 0190, iter [00430, 01251], lr: 0.000759, loss: 0.4149
2022-09-30 22:04:41 - train: epoch 0190, iter [00440, 01251], lr: 0.000759, loss: 0.4104
2022-09-30 22:04:58 - train: epoch 0190, iter [00450, 01251], lr: 0.000759, loss: 0.4089
2022-09-30 22:05:16 - train: epoch 0190, iter [00460, 01251], lr: 0.000758, loss: 0.3952
2022-09-30 22:05:34 - train: epoch 0190, iter [00470, 01251], lr: 0.000758, loss: 0.3989
2022-09-30 22:05:51 - train: epoch 0190, iter [00480, 01251], lr: 0.000758, loss: 0.4022
2022-09-30 22:06:09 - train: epoch 0190, iter [00490, 01251], lr: 0.000758, loss: 0.3986
2022-09-30 22:06:27 - train: epoch 0190, iter [00500, 01251], lr: 0.000758, loss: 0.4222
2022-09-30 22:06:45 - train: epoch 0190, iter [00510, 01251], lr: 0.000758, loss: 0.3826
2022-09-30 22:07:02 - train: epoch 0190, iter [00520, 01251], lr: 0.000758, loss: 0.4085
2022-09-30 22:07:20 - train: epoch 0190, iter [00530, 01251], lr: 0.000758, loss: 0.4046
2022-09-30 22:07:38 - train: epoch 0190, iter [00540, 01251], lr: 0.000758, loss: 0.4130
2022-09-30 22:07:56 - train: epoch 0190, iter [00550, 01251], lr: 0.000758, loss: 0.4116
2022-09-30 22:08:13 - train: epoch 0190, iter [00560, 01251], lr: 0.000758, loss: 0.4086
2022-09-30 22:08:31 - train: epoch 0190, iter [00570, 01251], lr: 0.000758, loss: 0.4009
2022-09-30 22:08:49 - train: epoch 0190, iter [00580, 01251], lr: 0.000758, loss: 0.4278
2022-09-30 22:09:07 - train: epoch 0190, iter [00590, 01251], lr: 0.000758, loss: 0.4153
2022-09-30 22:09:24 - train: epoch 0190, iter [00600, 01251], lr: 0.000758, loss: 0.3950
2022-09-30 22:09:42 - train: epoch 0190, iter [00610, 01251], lr: 0.000758, loss: 0.3957
2022-09-30 22:10:00 - train: epoch 0190, iter [00620, 01251], lr: 0.000758, loss: 0.4130
2022-09-30 22:10:18 - train: epoch 0190, iter [00630, 01251], lr: 0.000758, loss: 0.4235
2022-09-30 22:10:35 - train: epoch 0190, iter [00640, 01251], lr: 0.000758, loss: 0.4073
2022-09-30 22:10:53 - train: epoch 0190, iter [00650, 01251], lr: 0.000758, loss: 0.4017
2022-09-30 22:11:11 - train: epoch 0190, iter [00660, 01251], lr: 0.000758, loss: 0.4216
2022-09-30 22:11:29 - train: epoch 0190, iter [00670, 01251], lr: 0.000758, loss: 0.4278
2022-09-30 22:11:46 - train: epoch 0190, iter [00680, 01251], lr: 0.000758, loss: 0.3837
2022-09-30 22:12:04 - train: epoch 0190, iter [00690, 01251], lr: 0.000758, loss: 0.3901
2022-09-30 22:12:22 - train: epoch 0190, iter [00700, 01251], lr: 0.000758, loss: 0.4108
2022-09-30 22:12:39 - train: epoch 0190, iter [00710, 01251], lr: 0.000757, loss: 0.4137
2022-09-30 22:12:57 - train: epoch 0190, iter [00720, 01251], lr: 0.000757, loss: 0.4042
2022-09-30 22:13:15 - train: epoch 0190, iter [00730, 01251], lr: 0.000757, loss: 0.4037
2022-09-30 22:13:33 - train: epoch 0190, iter [00740, 01251], lr: 0.000757, loss: 0.3950
2022-09-30 22:13:51 - train: epoch 0190, iter [00750, 01251], lr: 0.000757, loss: 0.4109
2022-09-30 22:14:08 - train: epoch 0190, iter [00760, 01251], lr: 0.000757, loss: 0.4031
2022-09-30 22:14:26 - train: epoch 0190, iter [00770, 01251], lr: 0.000757, loss: 0.4158
2022-09-30 22:14:44 - train: epoch 0190, iter [00780, 01251], lr: 0.000757, loss: 0.4121
2022-09-30 22:15:02 - train: epoch 0190, iter [00790, 01251], lr: 0.000757, loss: 0.4199
2022-09-30 22:15:19 - train: epoch 0190, iter [00800, 01251], lr: 0.000757, loss: 0.4071
2022-09-30 22:15:37 - train: epoch 0190, iter [00810, 01251], lr: 0.000757, loss: 0.3861
2022-09-30 22:15:55 - train: epoch 0190, iter [00820, 01251], lr: 0.000757, loss: 0.4207
2022-09-30 22:16:12 - train: epoch 0190, iter [00830, 01251], lr: 0.000757, loss: 0.4014
2022-09-30 22:16:30 - train: epoch 0190, iter [00840, 01251], lr: 0.000757, loss: 0.4176
2022-09-30 22:16:48 - train: epoch 0190, iter [00850, 01251], lr: 0.000757, loss: 0.3975
2022-09-30 22:17:06 - train: epoch 0190, iter [00860, 01251], lr: 0.000757, loss: 0.4320
2022-09-30 22:17:23 - train: epoch 0190, iter [00870, 01251], lr: 0.000757, loss: 0.4285
2022-09-30 22:17:41 - train: epoch 0190, iter [00880, 01251], lr: 0.000757, loss: 0.3940
2022-09-30 22:17:59 - train: epoch 0190, iter [00890, 01251], lr: 0.000757, loss: 0.3989
2022-09-30 22:18:16 - train: epoch 0190, iter [00900, 01251], lr: 0.000757, loss: 0.4130
2022-09-30 22:18:34 - train: epoch 0190, iter [00910, 01251], lr: 0.000757, loss: 0.4078
2022-09-30 22:18:52 - train: epoch 0190, iter [00920, 01251], lr: 0.000757, loss: 0.4167
2022-09-30 22:19:10 - train: epoch 0190, iter [00930, 01251], lr: 0.000757, loss: 0.4139
2022-09-30 22:19:27 - train: epoch 0190, iter [00940, 01251], lr: 0.000757, loss: 0.4078
2022-09-30 22:19:45 - train: epoch 0190, iter [00950, 01251], lr: 0.000757, loss: 0.4158
2022-09-30 22:20:03 - train: epoch 0190, iter [00960, 01251], lr: 0.000756, loss: 0.4037
2022-09-30 22:20:21 - train: epoch 0190, iter [00970, 01251], lr: 0.000756, loss: 0.4095
2022-09-30 22:20:38 - train: epoch 0190, iter [00980, 01251], lr: 0.000756, loss: 0.3925
2022-09-30 22:20:56 - train: epoch 0190, iter [00990, 01251], lr: 0.000756, loss: 0.4112
2022-09-30 22:21:14 - train: epoch 0190, iter [01000, 01251], lr: 0.000756, loss: 0.3977
2022-09-30 22:21:32 - train: epoch 0190, iter [01010, 01251], lr: 0.000756, loss: 0.4088
2022-09-30 22:21:49 - train: epoch 0190, iter [01020, 01251], lr: 0.000756, loss: 0.3952
2022-09-30 22:22:07 - train: epoch 0190, iter [01030, 01251], lr: 0.000756, loss: 0.4165
2022-09-30 22:22:25 - train: epoch 0190, iter [01040, 01251], lr: 0.000756, loss: 0.3930
2022-09-30 22:22:43 - train: epoch 0190, iter [01050, 01251], lr: 0.000756, loss: 0.4060
2022-09-30 22:23:01 - train: epoch 0190, iter [01060, 01251], lr: 0.000756, loss: 0.4103
2022-09-30 22:23:18 - train: epoch 0190, iter [01070, 01251], lr: 0.000756, loss: 0.4090
2022-09-30 22:23:36 - train: epoch 0190, iter [01080, 01251], lr: 0.000756, loss: 0.4070
2022-09-30 22:23:54 - train: epoch 0190, iter [01090, 01251], lr: 0.000756, loss: 0.4035
2022-09-30 22:24:11 - train: epoch 0190, iter [01100, 01251], lr: 0.000756, loss: 0.3963
2022-09-30 22:24:29 - train: epoch 0190, iter [01110, 01251], lr: 0.000756, loss: 0.4005
2022-09-30 22:24:47 - train: epoch 0190, iter [01120, 01251], lr: 0.000756, loss: 0.4041
2022-09-30 22:25:04 - train: epoch 0190, iter [01130, 01251], lr: 0.000756, loss: 0.4202
2022-09-30 22:25:22 - train: epoch 0190, iter [01140, 01251], lr: 0.000756, loss: 0.4103
2022-09-30 22:25:40 - train: epoch 0190, iter [01150, 01251], lr: 0.000756, loss: 0.4294
2022-09-30 22:25:58 - train: epoch 0190, iter [01160, 01251], lr: 0.000756, loss: 0.4030
2022-09-30 22:26:15 - train: epoch 0190, iter [01170, 01251], lr: 0.000756, loss: 0.4161
2022-09-30 22:26:33 - train: epoch 0190, iter [01180, 01251], lr: 0.000756, loss: 0.4070
2022-09-30 22:26:51 - train: epoch 0190, iter [01190, 01251], lr: 0.000756, loss: 0.4198
2022-09-30 22:27:09 - train: epoch 0190, iter [01200, 01251], lr: 0.000755, loss: 0.4175
2022-09-30 22:27:26 - train: epoch 0190, iter [01210, 01251], lr: 0.000755, loss: 0.4210
2022-09-30 22:27:44 - train: epoch 0190, iter [01220, 01251], lr: 0.000755, loss: 0.3953
2022-09-30 22:28:02 - train: epoch 0190, iter [01230, 01251], lr: 0.000755, loss: 0.4066
2022-09-30 22:28:19 - train: epoch 0190, iter [01240, 01251], lr: 0.000755, loss: 0.4002
2022-09-30 22:28:37 - train: epoch 0190, iter [01250, 01251], lr: 0.000755, loss: 0.3885
2022-09-30 22:28:40 - train: epoch 190, train_loss: 0.4078
2022-09-30 22:28:43 - until epoch: 190, best_loss: 0.4078
2022-09-30 22:28:43 - epoch 191 lr: 0.000755
2022-09-30 22:29:07 - train: epoch 0191, iter [00010, 01251], lr: 0.000755, loss: 0.4036
2022-09-30 22:29:25 - train: epoch 0191, iter [00020, 01251], lr: 0.000755, loss: 0.4055
2022-09-30 22:29:43 - train: epoch 0191, iter [00030, 01251], lr: 0.000755, loss: 0.4166
2022-09-30 22:30:01 - train: epoch 0191, iter [00040, 01251], lr: 0.000755, loss: 0.4055
2022-09-30 22:30:18 - train: epoch 0191, iter [00050, 01251], lr: 0.000755, loss: 0.4055
2022-09-30 22:30:36 - train: epoch 0191, iter [00060, 01251], lr: 0.000755, loss: 0.4192
2022-09-30 22:30:54 - train: epoch 0191, iter [00070, 01251], lr: 0.000755, loss: 0.4321
2022-09-30 22:31:12 - train: epoch 0191, iter [00080, 01251], lr: 0.000755, loss: 0.4252
2022-09-30 22:31:30 - train: epoch 0191, iter [00090, 01251], lr: 0.000755, loss: 0.4299
2022-09-30 22:31:47 - train: epoch 0191, iter [00100, 01251], lr: 0.000755, loss: 0.3912
2022-09-30 22:32:05 - train: epoch 0191, iter [00110, 01251], lr: 0.000755, loss: 0.3969
2022-09-30 22:32:23 - train: epoch 0191, iter [00120, 01251], lr: 0.000755, loss: 0.4016
2022-09-30 22:32:41 - train: epoch 0191, iter [00130, 01251], lr: 0.000755, loss: 0.3892
2022-09-30 22:32:58 - train: epoch 0191, iter [00140, 01251], lr: 0.000755, loss: 0.3851
2022-09-30 22:33:16 - train: epoch 0191, iter [00150, 01251], lr: 0.000755, loss: 0.3902
2022-09-30 22:33:34 - train: epoch 0191, iter [00160, 01251], lr: 0.000755, loss: 0.4245
2022-09-30 22:33:52 - train: epoch 0191, iter [00170, 01251], lr: 0.000755, loss: 0.3846
2022-09-30 22:34:10 - train: epoch 0191, iter [00180, 01251], lr: 0.000755, loss: 0.3802
2022-09-30 22:34:28 - train: epoch 0191, iter [00190, 01251], lr: 0.000755, loss: 0.3855
2022-09-30 22:34:45 - train: epoch 0191, iter [00200, 01251], lr: 0.000754, loss: 0.4185
2022-09-30 22:35:03 - train: epoch 0191, iter [00210, 01251], lr: 0.000754, loss: 0.4061
2022-09-30 22:35:21 - train: epoch 0191, iter [00220, 01251], lr: 0.000754, loss: 0.4008
2022-09-30 22:35:39 - train: epoch 0191, iter [00230, 01251], lr: 0.000754, loss: 0.4132
2022-09-30 22:35:56 - train: epoch 0191, iter [00240, 01251], lr: 0.000754, loss: 0.4104
2022-09-30 22:36:14 - train: epoch 0191, iter [00250, 01251], lr: 0.000754, loss: 0.3880
2022-09-30 22:36:31 - train: epoch 0191, iter [00260, 01251], lr: 0.000754, loss: 0.3943
2022-09-30 22:36:49 - train: epoch 0191, iter [00270, 01251], lr: 0.000754, loss: 0.3871
2022-09-30 22:37:07 - train: epoch 0191, iter [00280, 01251], lr: 0.000754, loss: 0.4140
2022-09-30 22:37:24 - train: epoch 0191, iter [00290, 01251], lr: 0.000754, loss: 0.3904
2022-09-30 22:37:42 - train: epoch 0191, iter [00300, 01251], lr: 0.000754, loss: 0.4017
2022-09-30 22:38:00 - train: epoch 0191, iter [00310, 01251], lr: 0.000754, loss: 0.3942
2022-09-30 22:38:17 - train: epoch 0191, iter [00320, 01251], lr: 0.000754, loss: 0.4188
2022-09-30 22:38:35 - train: epoch 0191, iter [00330, 01251], lr: 0.000754, loss: 0.4164
2022-09-30 22:38:53 - train: epoch 0191, iter [00340, 01251], lr: 0.000754, loss: 0.4165
2022-09-30 22:39:11 - train: epoch 0191, iter [00350, 01251], lr: 0.000754, loss: 0.4093
2022-09-30 22:39:29 - train: epoch 0191, iter [00360, 01251], lr: 0.000754, loss: 0.4034
2022-09-30 22:39:46 - train: epoch 0191, iter [00370, 01251], lr: 0.000754, loss: 0.4224
2022-09-30 22:40:04 - train: epoch 0191, iter [00380, 01251], lr: 0.000754, loss: 0.4189
2022-09-30 22:40:22 - train: epoch 0191, iter [00390, 01251], lr: 0.000754, loss: 0.4128
2022-09-30 22:40:39 - train: epoch 0191, iter [00400, 01251], lr: 0.000754, loss: 0.4108
2022-09-30 22:40:57 - train: epoch 0191, iter [00410, 01251], lr: 0.000754, loss: 0.4321
2022-09-30 22:41:15 - train: epoch 0191, iter [00420, 01251], lr: 0.000754, loss: 0.4013
2022-09-30 22:41:32 - train: epoch 0191, iter [00430, 01251], lr: 0.000754, loss: 0.4089
2022-09-30 22:41:50 - train: epoch 0191, iter [00440, 01251], lr: 0.000754, loss: 0.3888
2022-09-30 22:42:08 - train: epoch 0191, iter [00450, 01251], lr: 0.000753, loss: 0.3982
2022-09-30 22:42:26 - train: epoch 0191, iter [00460, 01251], lr: 0.000753, loss: 0.4156
2022-09-30 22:42:43 - train: epoch 0191, iter [00470, 01251], lr: 0.000753, loss: 0.4023
2022-09-30 22:43:01 - train: epoch 0191, iter [00480, 01251], lr: 0.000753, loss: 0.3998
2022-09-30 22:43:19 - train: epoch 0191, iter [00490, 01251], lr: 0.000753, loss: 0.4131
2022-09-30 22:43:36 - train: epoch 0191, iter [00500, 01251], lr: 0.000753, loss: 0.4035
2022-09-30 22:43:54 - train: epoch 0191, iter [00510, 01251], lr: 0.000753, loss: 0.4022
2022-09-30 22:44:12 - train: epoch 0191, iter [00520, 01251], lr: 0.000753, loss: 0.4231
2022-09-30 22:44:29 - train: epoch 0191, iter [00530, 01251], lr: 0.000753, loss: 0.4030
2022-09-30 22:44:47 - train: epoch 0191, iter [00540, 01251], lr: 0.000753, loss: 0.4109
2022-09-30 22:45:05 - train: epoch 0191, iter [00550, 01251], lr: 0.000753, loss: 0.3953
2022-09-30 22:45:23 - train: epoch 0191, iter [00560, 01251], lr: 0.000753, loss: 0.4260
2022-09-30 22:45:40 - train: epoch 0191, iter [00570, 01251], lr: 0.000753, loss: 0.4004
2022-09-30 22:45:58 - train: epoch 0191, iter [00580, 01251], lr: 0.000753, loss: 0.4085
2022-09-30 22:46:16 - train: epoch 0191, iter [00590, 01251], lr: 0.000753, loss: 0.4060
2022-09-30 22:46:34 - train: epoch 0191, iter [00600, 01251], lr: 0.000753, loss: 0.3888
2022-09-30 22:46:51 - train: epoch 0191, iter [00610, 01251], lr: 0.000753, loss: 0.4123
2022-09-30 22:47:09 - train: epoch 0191, iter [00620, 01251], lr: 0.000753, loss: 0.4280
2022-09-30 22:47:27 - train: epoch 0191, iter [00630, 01251], lr: 0.000753, loss: 0.4089
2022-09-30 22:47:45 - train: epoch 0191, iter [00640, 01251], lr: 0.000753, loss: 0.4123
2022-09-30 22:48:03 - train: epoch 0191, iter [00650, 01251], lr: 0.000753, loss: 0.4169
2022-09-30 22:48:20 - train: epoch 0191, iter [00660, 01251], lr: 0.000753, loss: 0.4105
2022-09-30 22:48:38 - train: epoch 0191, iter [00670, 01251], lr: 0.000753, loss: 0.3968
2022-09-30 22:48:56 - train: epoch 0191, iter [00680, 01251], lr: 0.000753, loss: 0.4084
2022-09-30 22:49:13 - train: epoch 0191, iter [00690, 01251], lr: 0.000753, loss: 0.4138
2022-09-30 22:49:31 - train: epoch 0191, iter [00700, 01251], lr: 0.000752, loss: 0.3972
2022-09-30 22:49:48 - train: epoch 0191, iter [00710, 01251], lr: 0.000752, loss: 0.3947
2022-09-30 22:50:06 - train: epoch 0191, iter [00720, 01251], lr: 0.000752, loss: 0.3977
2022-09-30 22:50:24 - train: epoch 0191, iter [00730, 01251], lr: 0.000752, loss: 0.4290
2022-09-30 22:50:42 - train: epoch 0191, iter [00740, 01251], lr: 0.000752, loss: 0.4007
2022-09-30 22:51:00 - train: epoch 0191, iter [00750, 01251], lr: 0.000752, loss: 0.4021
2022-09-30 22:51:17 - train: epoch 0191, iter [00760, 01251], lr: 0.000752, loss: 0.4070
2022-09-30 22:51:35 - train: epoch 0191, iter [00770, 01251], lr: 0.000752, loss: 0.3976
2022-09-30 22:51:53 - train: epoch 0191, iter [00780, 01251], lr: 0.000752, loss: 0.4085
2022-09-30 22:52:10 - train: epoch 0191, iter [00790, 01251], lr: 0.000752, loss: 0.4114
2022-09-30 22:52:28 - train: epoch 0191, iter [00800, 01251], lr: 0.000752, loss: 0.4249
2022-09-30 22:52:46 - train: epoch 0191, iter [00810, 01251], lr: 0.000752, loss: 0.4105
2022-09-30 22:53:03 - train: epoch 0191, iter [00820, 01251], lr: 0.000752, loss: 0.4118
2022-09-30 22:53:21 - train: epoch 0191, iter [00830, 01251], lr: 0.000752, loss: 0.4047
2022-09-30 22:53:39 - train: epoch 0191, iter [00840, 01251], lr: 0.000752, loss: 0.4080
2022-09-30 22:53:57 - train: epoch 0191, iter [00850, 01251], lr: 0.000752, loss: 0.4134
2022-09-30 22:54:14 - train: epoch 0191, iter [00860, 01251], lr: 0.000752, loss: 0.4023
2022-09-30 22:54:32 - train: epoch 0191, iter [00870, 01251], lr: 0.000752, loss: 0.4089
2022-09-30 22:54:50 - train: epoch 0191, iter [00880, 01251], lr: 0.000752, loss: 0.4253
2022-09-30 22:55:07 - train: epoch 0191, iter [00890, 01251], lr: 0.000752, loss: 0.4058
2022-09-30 22:55:25 - train: epoch 0191, iter [00900, 01251], lr: 0.000752, loss: 0.3955
2022-09-30 22:55:43 - train: epoch 0191, iter [00910, 01251], lr: 0.000752, loss: 0.4247
2022-09-30 22:56:01 - train: epoch 0191, iter [00920, 01251], lr: 0.000752, loss: 0.4148
2022-09-30 22:56:18 - train: epoch 0191, iter [00930, 01251], lr: 0.000752, loss: 0.3929
2022-09-30 22:56:36 - train: epoch 0191, iter [00940, 01251], lr: 0.000751, loss: 0.4162
2022-09-30 22:56:54 - train: epoch 0191, iter [00950, 01251], lr: 0.000751, loss: 0.4112
2022-09-30 22:57:12 - train: epoch 0191, iter [00960, 01251], lr: 0.000751, loss: 0.3999
2022-09-30 22:57:29 - train: epoch 0191, iter [00970, 01251], lr: 0.000751, loss: 0.4197
2022-09-30 22:57:47 - train: epoch 0191, iter [00980, 01251], lr: 0.000751, loss: 0.3853
2022-09-30 22:58:04 - train: epoch 0191, iter [00990, 01251], lr: 0.000751, loss: 0.3782
2022-09-30 22:58:22 - train: epoch 0191, iter [01000, 01251], lr: 0.000751, loss: 0.4059
2022-09-30 22:58:40 - train: epoch 0191, iter [01010, 01251], lr: 0.000751, loss: 0.4047
2022-09-30 22:58:57 - train: epoch 0191, iter [01020, 01251], lr: 0.000751, loss: 0.4141
2022-09-30 22:59:15 - train: epoch 0191, iter [01030, 01251], lr: 0.000751, loss: 0.3905
2022-09-30 22:59:33 - train: epoch 0191, iter [01040, 01251], lr: 0.000751, loss: 0.4074
2022-09-30 22:59:51 - train: epoch 0191, iter [01050, 01251], lr: 0.000751, loss: 0.4148
2022-09-30 23:00:08 - train: epoch 0191, iter [01060, 01251], lr: 0.000751, loss: 0.3998
2022-09-30 23:00:26 - train: epoch 0191, iter [01070, 01251], lr: 0.000751, loss: 0.3909
2022-09-30 23:00:44 - train: epoch 0191, iter [01080, 01251], lr: 0.000751, loss: 0.4047
2022-09-30 23:01:01 - train: epoch 0191, iter [01090, 01251], lr: 0.000751, loss: 0.3944
2022-09-30 23:01:19 - train: epoch 0191, iter [01100, 01251], lr: 0.000751, loss: 0.3931
2022-09-30 23:01:37 - train: epoch 0191, iter [01110, 01251], lr: 0.000751, loss: 0.4072
2022-09-30 23:01:54 - train: epoch 0191, iter [01120, 01251], lr: 0.000751, loss: 0.4006
2022-09-30 23:02:12 - train: epoch 0191, iter [01130, 01251], lr: 0.000751, loss: 0.3952
2022-09-30 23:02:30 - train: epoch 0191, iter [01140, 01251], lr: 0.000751, loss: 0.4127
2022-09-30 23:02:47 - train: epoch 0191, iter [01150, 01251], lr: 0.000751, loss: 0.4019
2022-09-30 23:03:05 - train: epoch 0191, iter [01160, 01251], lr: 0.000751, loss: 0.4232
2022-09-30 23:03:23 - train: epoch 0191, iter [01170, 01251], lr: 0.000751, loss: 0.3937
2022-09-30 23:03:40 - train: epoch 0191, iter [01180, 01251], lr: 0.000751, loss: 0.4012
2022-09-30 23:03:58 - train: epoch 0191, iter [01190, 01251], lr: 0.000750, loss: 0.3953
2022-09-30 23:04:16 - train: epoch 0191, iter [01200, 01251], lr: 0.000750, loss: 0.4076
2022-09-30 23:04:34 - train: epoch 0191, iter [01210, 01251], lr: 0.000750, loss: 0.4108
2022-09-30 23:04:51 - train: epoch 0191, iter [01220, 01251], lr: 0.000750, loss: 0.4178
2022-09-30 23:05:09 - train: epoch 0191, iter [01230, 01251], lr: 0.000750, loss: 0.4181
2022-09-30 23:05:27 - train: epoch 0191, iter [01240, 01251], lr: 0.000750, loss: 0.4028
2022-09-30 23:05:44 - train: epoch 0191, iter [01250, 01251], lr: 0.000750, loss: 0.4087
2022-09-30 23:05:47 - train: epoch 191, train_loss: 0.4076
2022-09-30 23:05:50 - until epoch: 191, best_loss: 0.4076
2022-09-30 23:05:50 - epoch 192 lr: 0.000750
2022-09-30 23:06:15 - train: epoch 0192, iter [00010, 01251], lr: 0.000750, loss: 0.4179
2022-09-30 23:06:33 - train: epoch 0192, iter [00020, 01251], lr: 0.000750, loss: 0.4250
2022-09-30 23:06:50 - train: epoch 0192, iter [00030, 01251], lr: 0.000750, loss: 0.4077
2022-09-30 23:07:08 - train: epoch 0192, iter [00040, 01251], lr: 0.000750, loss: 0.4183
2022-09-30 23:07:26 - train: epoch 0192, iter [00050, 01251], lr: 0.000750, loss: 0.4128
2022-09-30 23:07:43 - train: epoch 0192, iter [00060, 01251], lr: 0.000750, loss: 0.3951
2022-09-30 23:08:01 - train: epoch 0192, iter [00070, 01251], lr: 0.000750, loss: 0.4139
2022-09-30 23:08:19 - train: epoch 0192, iter [00080, 01251], lr: 0.000750, loss: 0.3871
2022-09-30 23:08:36 - train: epoch 0192, iter [00090, 01251], lr: 0.000750, loss: 0.3834
2022-09-30 23:08:54 - train: epoch 0192, iter [00100, 01251], lr: 0.000750, loss: 0.4225
2022-09-30 23:09:12 - train: epoch 0192, iter [00110, 01251], lr: 0.000750, loss: 0.3900
2022-09-30 23:09:30 - train: epoch 0192, iter [00120, 01251], lr: 0.000750, loss: 0.4095
2022-09-30 23:09:47 - train: epoch 0192, iter [00130, 01251], lr: 0.000750, loss: 0.4219
2022-09-30 23:10:05 - train: epoch 0192, iter [00140, 01251], lr: 0.000750, loss: 0.4297
2022-09-30 23:10:23 - train: epoch 0192, iter [00150, 01251], lr: 0.000750, loss: 0.4214
2022-09-30 23:10:40 - train: epoch 0192, iter [00160, 01251], lr: 0.000750, loss: 0.4144
2022-09-30 23:10:58 - train: epoch 0192, iter [00170, 01251], lr: 0.000750, loss: 0.4135
2022-09-30 23:11:16 - train: epoch 0192, iter [00180, 01251], lr: 0.000749, loss: 0.3895
2022-09-30 23:11:34 - train: epoch 0192, iter [00190, 01251], lr: 0.000749, loss: 0.3938
2022-09-30 23:11:51 - train: epoch 0192, iter [00200, 01251], lr: 0.000749, loss: 0.4142
2022-09-30 23:12:09 - train: epoch 0192, iter [00210, 01251], lr: 0.000749, loss: 0.4016
2022-09-30 23:12:27 - train: epoch 0192, iter [00220, 01251], lr: 0.000749, loss: 0.3939
2022-09-30 23:12:44 - train: epoch 0192, iter [00230, 01251], lr: 0.000749, loss: 0.4115
2022-09-30 23:13:02 - train: epoch 0192, iter [00240, 01251], lr: 0.000749, loss: 0.4277
2022-09-30 23:13:20 - train: epoch 0192, iter [00250, 01251], lr: 0.000749, loss: 0.3862
2022-09-30 23:13:37 - train: epoch 0192, iter [00260, 01251], lr: 0.000749, loss: 0.4016
2022-09-30 23:13:55 - train: epoch 0192, iter [00270, 01251], lr: 0.000749, loss: 0.4228
2022-09-30 23:14:13 - train: epoch 0192, iter [00280, 01251], lr: 0.000749, loss: 0.4177
2022-09-30 23:14:31 - train: epoch 0192, iter [00290, 01251], lr: 0.000749, loss: 0.4104
2022-09-30 23:14:48 - train: epoch 0192, iter [00300, 01251], lr: 0.000749, loss: 0.3903
2022-09-30 23:15:06 - train: epoch 0192, iter [00310, 01251], lr: 0.000749, loss: 0.4043
2022-09-30 23:15:24 - train: epoch 0192, iter [00320, 01251], lr: 0.000749, loss: 0.3873
2022-09-30 23:15:42 - train: epoch 0192, iter [00330, 01251], lr: 0.000749, loss: 0.4131
2022-09-30 23:15:59 - train: epoch 0192, iter [00340, 01251], lr: 0.000749, loss: 0.4248
2022-09-30 23:16:17 - train: epoch 0192, iter [00350, 01251], lr: 0.000749, loss: 0.4051
2022-09-30 23:16:35 - train: epoch 0192, iter [00360, 01251], lr: 0.000749, loss: 0.4010
2022-09-30 23:16:52 - train: epoch 0192, iter [00370, 01251], lr: 0.000749, loss: 0.3768
2022-09-30 23:17:10 - train: epoch 0192, iter [00380, 01251], lr: 0.000749, loss: 0.3995
2022-09-30 23:17:28 - train: epoch 0192, iter [00390, 01251], lr: 0.000749, loss: 0.4103
2022-09-30 23:17:45 - train: epoch 0192, iter [00400, 01251], lr: 0.000749, loss: 0.3927
2022-09-30 23:18:03 - train: epoch 0192, iter [00410, 01251], lr: 0.000749, loss: 0.4023
2022-09-30 23:18:21 - train: epoch 0192, iter [00420, 01251], lr: 0.000749, loss: 0.4040
2022-09-30 23:18:39 - train: epoch 0192, iter [00430, 01251], lr: 0.000748, loss: 0.3854
2022-09-30 23:18:56 - train: epoch 0192, iter [00440, 01251], lr: 0.000748, loss: 0.4116
2022-09-30 23:19:14 - train: epoch 0192, iter [00450, 01251], lr: 0.000748, loss: 0.4253
2022-09-30 23:19:32 - train: epoch 0192, iter [00460, 01251], lr: 0.000748, loss: 0.4041
2022-09-30 23:19:49 - train: epoch 0192, iter [00470, 01251], lr: 0.000748, loss: 0.3991
2022-09-30 23:20:07 - train: epoch 0192, iter [00480, 01251], lr: 0.000748, loss: 0.4030
2022-09-30 23:20:25 - train: epoch 0192, iter [00490, 01251], lr: 0.000748, loss: 0.3966
2022-09-30 23:20:42 - train: epoch 0192, iter [00500, 01251], lr: 0.000748, loss: 0.4046
2022-09-30 23:21:00 - train: epoch 0192, iter [00510, 01251], lr: 0.000748, loss: 0.4082
2022-09-30 23:21:18 - train: epoch 0192, iter [00520, 01251], lr: 0.000748, loss: 0.4095
2022-09-30 23:21:36 - train: epoch 0192, iter [00530, 01251], lr: 0.000748, loss: 0.4218
2022-09-30 23:21:53 - train: epoch 0192, iter [00540, 01251], lr: 0.000748, loss: 0.4010
2022-09-30 23:22:11 - train: epoch 0192, iter [00550, 01251], lr: 0.000748, loss: 0.4136
2022-09-30 23:22:29 - train: epoch 0192, iter [00560, 01251], lr: 0.000748, loss: 0.4176
2022-09-30 23:22:46 - train: epoch 0192, iter [00570, 01251], lr: 0.000748, loss: 0.4126
2022-09-30 23:23:04 - train: epoch 0192, iter [00580, 01251], lr: 0.000748, loss: 0.4217
2022-09-30 23:23:22 - train: epoch 0192, iter [00590, 01251], lr: 0.000748, loss: 0.4031
2022-09-30 23:23:40 - train: epoch 0192, iter [00600, 01251], lr: 0.000748, loss: 0.4154
2022-09-30 23:23:57 - train: epoch 0192, iter [00610, 01251], lr: 0.000748, loss: 0.4028
2022-09-30 23:24:15 - train: epoch 0192, iter [00620, 01251], lr: 0.000748, loss: 0.4110
2022-09-30 23:24:33 - train: epoch 0192, iter [00630, 01251], lr: 0.000748, loss: 0.3981
2022-09-30 23:24:50 - train: epoch 0192, iter [00640, 01251], lr: 0.000748, loss: 0.4095
2022-09-30 23:25:08 - train: epoch 0192, iter [00650, 01251], lr: 0.000748, loss: 0.4121
2022-09-30 23:25:26 - train: epoch 0192, iter [00660, 01251], lr: 0.000748, loss: 0.3966
2022-09-30 23:25:43 - train: epoch 0192, iter [00670, 01251], lr: 0.000748, loss: 0.3986
2022-09-30 23:26:01 - train: epoch 0192, iter [00680, 01251], lr: 0.000747, loss: 0.4053
2022-09-30 23:26:19 - train: epoch 0192, iter [00690, 01251], lr: 0.000747, loss: 0.3967
2022-09-30 23:26:36 - train: epoch 0192, iter [00700, 01251], lr: 0.000747, loss: 0.3947
2022-09-30 23:26:54 - train: epoch 0192, iter [00710, 01251], lr: 0.000747, loss: 0.3955
2022-09-30 23:27:12 - train: epoch 0192, iter [00720, 01251], lr: 0.000747, loss: 0.4046
2022-09-30 23:27:30 - train: epoch 0192, iter [00730, 01251], lr: 0.000747, loss: 0.3995
2022-09-30 23:27:47 - train: epoch 0192, iter [00740, 01251], lr: 0.000747, loss: 0.4022
2022-09-30 23:28:05 - train: epoch 0192, iter [00750, 01251], lr: 0.000747, loss: 0.4043
2022-09-30 23:28:23 - train: epoch 0192, iter [00760, 01251], lr: 0.000747, loss: 0.3930
2022-09-30 23:28:40 - train: epoch 0192, iter [00770, 01251], lr: 0.000747, loss: 0.4040
2022-09-30 23:28:58 - train: epoch 0192, iter [00780, 01251], lr: 0.000747, loss: 0.4241
2022-09-30 23:29:16 - train: epoch 0192, iter [00790, 01251], lr: 0.000747, loss: 0.4194
2022-09-30 23:29:34 - train: epoch 0192, iter [00800, 01251], lr: 0.000747, loss: 0.4156
2022-09-30 23:29:52 - train: epoch 0192, iter [00810, 01251], lr: 0.000747, loss: 0.4352
2022-09-30 23:30:09 - train: epoch 0192, iter [00820, 01251], lr: 0.000747, loss: 0.3890
2022-09-30 23:30:27 - train: epoch 0192, iter [00830, 01251], lr: 0.000747, loss: 0.4121
2022-09-30 23:30:45 - train: epoch 0192, iter [00840, 01251], lr: 0.000747, loss: 0.4196
2022-09-30 23:31:02 - train: epoch 0192, iter [00850, 01251], lr: 0.000747, loss: 0.4149
2022-09-30 23:31:20 - train: epoch 0192, iter [00860, 01251], lr: 0.000747, loss: 0.4174
2022-09-30 23:31:38 - train: epoch 0192, iter [00870, 01251], lr: 0.000747, loss: 0.4160
2022-09-30 23:31:55 - train: epoch 0192, iter [00880, 01251], lr: 0.000747, loss: 0.4031
2022-09-30 23:32:13 - train: epoch 0192, iter [00890, 01251], lr: 0.000747, loss: 0.4063
2022-09-30 23:32:31 - train: epoch 0192, iter [00900, 01251], lr: 0.000747, loss: 0.4108
2022-09-30 23:32:49 - train: epoch 0192, iter [00910, 01251], lr: 0.000747, loss: 0.3853
2022-09-30 23:33:06 - train: epoch 0192, iter [00920, 01251], lr: 0.000746, loss: 0.3805
2022-09-30 23:33:24 - train: epoch 0192, iter [00930, 01251], lr: 0.000746, loss: 0.3948
2022-09-30 23:33:42 - train: epoch 0192, iter [00940, 01251], lr: 0.000746, loss: 0.3965
2022-09-30 23:33:59 - train: epoch 0192, iter [00950, 01251], lr: 0.000746, loss: 0.4085
2022-09-30 23:34:17 - train: epoch 0192, iter [00960, 01251], lr: 0.000746, loss: 0.4142
2022-09-30 23:34:35 - train: epoch 0192, iter [00970, 01251], lr: 0.000746, loss: 0.4097
2022-09-30 23:34:53 - train: epoch 0192, iter [00980, 01251], lr: 0.000746, loss: 0.3959
2022-09-30 23:35:10 - train: epoch 0192, iter [00990, 01251], lr: 0.000746, loss: 0.4129
2022-09-30 23:35:28 - train: epoch 0192, iter [01000, 01251], lr: 0.000746, loss: 0.4186
2022-09-30 23:35:46 - train: epoch 0192, iter [01010, 01251], lr: 0.000746, loss: 0.3926
2022-09-30 23:36:04 - train: epoch 0192, iter [01020, 01251], lr: 0.000746, loss: 0.4171
2022-09-30 23:36:21 - train: epoch 0192, iter [01030, 01251], lr: 0.000746, loss: 0.3903
2022-09-30 23:36:39 - train: epoch 0192, iter [01040, 01251], lr: 0.000746, loss: 0.4244
2022-09-30 23:36:57 - train: epoch 0192, iter [01050, 01251], lr: 0.000746, loss: 0.4004
2022-09-30 23:37:15 - train: epoch 0192, iter [01060, 01251], lr: 0.000746, loss: 0.4081
2022-09-30 23:37:32 - train: epoch 0192, iter [01070, 01251], lr: 0.000746, loss: 0.4007
2022-09-30 23:37:50 - train: epoch 0192, iter [01080, 01251], lr: 0.000746, loss: 0.4112
2022-09-30 23:38:08 - train: epoch 0192, iter [01090, 01251], lr: 0.000746, loss: 0.3950
2022-09-30 23:38:25 - train: epoch 0192, iter [01100, 01251], lr: 0.000746, loss: 0.3990
2022-09-30 23:38:43 - train: epoch 0192, iter [01110, 01251], lr: 0.000746, loss: 0.4023
2022-09-30 23:39:01 - train: epoch 0192, iter [01120, 01251], lr: 0.000746, loss: 0.3951
2022-09-30 23:39:18 - train: epoch 0192, iter [01130, 01251], lr: 0.000746, loss: 0.4244
2022-09-30 23:39:36 - train: epoch 0192, iter [01140, 01251], lr: 0.000746, loss: 0.4203
2022-09-30 23:39:54 - train: epoch 0192, iter [01150, 01251], lr: 0.000746, loss: 0.4156
2022-09-30 23:40:11 - train: epoch 0192, iter [01160, 01251], lr: 0.000746, loss: 0.3973
2022-09-30 23:40:29 - train: epoch 0192, iter [01170, 01251], lr: 0.000745, loss: 0.4073
2022-09-30 23:40:47 - train: epoch 0192, iter [01180, 01251], lr: 0.000745, loss: 0.3942
2022-09-30 23:41:05 - train: epoch 0192, iter [01190, 01251], lr: 0.000745, loss: 0.4014
2022-09-30 23:41:22 - train: epoch 0192, iter [01200, 01251], lr: 0.000745, loss: 0.4188
2022-09-30 23:41:40 - train: epoch 0192, iter [01210, 01251], lr: 0.000745, loss: 0.4049
2022-09-30 23:41:58 - train: epoch 0192, iter [01220, 01251], lr: 0.000745, loss: 0.4228
2022-09-30 23:42:16 - train: epoch 0192, iter [01230, 01251], lr: 0.000745, loss: 0.4109
2022-09-30 23:42:33 - train: epoch 0192, iter [01240, 01251], lr: 0.000745, loss: 0.3927
2022-09-30 23:42:51 - train: epoch 0192, iter [01250, 01251], lr: 0.000745, loss: 0.4288
2022-09-30 23:42:54 - train: epoch 192, train_loss: 0.4076
2022-09-30 23:42:57 - until epoch: 192, best_loss: 0.4076
2022-09-30 23:42:57 - epoch 193 lr: 0.000745
2022-09-30 23:43:21 - train: epoch 0193, iter [00010, 01251], lr: 0.000745, loss: 0.4079
2022-09-30 23:43:39 - train: epoch 0193, iter [00020, 01251], lr: 0.000745, loss: 0.4128
2022-09-30 23:43:56 - train: epoch 0193, iter [00030, 01251], lr: 0.000745, loss: 0.4131
2022-09-30 23:44:14 - train: epoch 0193, iter [00040, 01251], lr: 0.000745, loss: 0.4039
2022-09-30 23:44:32 - train: epoch 0193, iter [00050, 01251], lr: 0.000745, loss: 0.4063
2022-09-30 23:44:49 - train: epoch 0193, iter [00060, 01251], lr: 0.000745, loss: 0.4100
2022-09-30 23:45:07 - train: epoch 0193, iter [00070, 01251], lr: 0.000745, loss: 0.4093
2022-09-30 23:45:25 - train: epoch 0193, iter [00080, 01251], lr: 0.000745, loss: 0.4128
2022-09-30 23:45:43 - train: epoch 0193, iter [00090, 01251], lr: 0.000745, loss: 0.4227
2022-09-30 23:46:00 - train: epoch 0193, iter [00100, 01251], lr: 0.000745, loss: 0.4296
2022-09-30 23:46:18 - train: epoch 0193, iter [00110, 01251], lr: 0.000745, loss: 0.4004
2022-09-30 23:46:35 - train: epoch 0193, iter [00120, 01251], lr: 0.000745, loss: 0.4144
2022-09-30 23:46:53 - train: epoch 0193, iter [00130, 01251], lr: 0.000745, loss: 0.3993
2022-09-30 23:47:11 - train: epoch 0193, iter [00140, 01251], lr: 0.000745, loss: 0.4022
2022-09-30 23:47:28 - train: epoch 0193, iter [00150, 01251], lr: 0.000745, loss: 0.4038
2022-09-30 23:47:46 - train: epoch 0193, iter [00160, 01251], lr: 0.000745, loss: 0.4017
2022-09-30 23:48:04 - train: epoch 0193, iter [00170, 01251], lr: 0.000744, loss: 0.4007
2022-09-30 23:48:22 - train: epoch 0193, iter [00180, 01251], lr: 0.000744, loss: 0.4206
2022-09-30 23:48:39 - train: epoch 0193, iter [00190, 01251], lr: 0.000744, loss: 0.3999
2022-09-30 23:48:57 - train: epoch 0193, iter [00200, 01251], lr: 0.000744, loss: 0.3972
2022-09-30 23:49:15 - train: epoch 0193, iter [00210, 01251], lr: 0.000744, loss: 0.4111
2022-09-30 23:49:33 - train: epoch 0193, iter [00220, 01251], lr: 0.000744, loss: 0.4168
2022-09-30 23:49:50 - train: epoch 0193, iter [00230, 01251], lr: 0.000744, loss: 0.3964
2022-09-30 23:50:08 - train: epoch 0193, iter [00240, 01251], lr: 0.000744, loss: 0.4154
2022-09-30 23:50:26 - train: epoch 0193, iter [00250, 01251], lr: 0.000744, loss: 0.3962
2022-09-30 23:50:44 - train: epoch 0193, iter [00260, 01251], lr: 0.000744, loss: 0.4038
2022-09-30 23:51:01 - train: epoch 0193, iter [00270, 01251], lr: 0.000744, loss: 0.4175
2022-09-30 23:51:19 - train: epoch 0193, iter [00280, 01251], lr: 0.000744, loss: 0.3954
2022-09-30 23:51:37 - train: epoch 0193, iter [00290, 01251], lr: 0.000744, loss: 0.3995
2022-09-30 23:51:54 - train: epoch 0193, iter [00300, 01251], lr: 0.000744, loss: 0.4320
2022-09-30 23:52:12 - train: epoch 0193, iter [00310, 01251], lr: 0.000744, loss: 0.4206
2022-09-30 23:52:30 - train: epoch 0193, iter [00320, 01251], lr: 0.000744, loss: 0.4112
2022-09-30 23:52:48 - train: epoch 0193, iter [00330, 01251], lr: 0.000744, loss: 0.4145
2022-09-30 23:53:05 - train: epoch 0193, iter [00340, 01251], lr: 0.000744, loss: 0.4159
2022-09-30 23:53:23 - train: epoch 0193, iter [00350, 01251], lr: 0.000744, loss: 0.4177
2022-09-30 23:53:41 - train: epoch 0193, iter [00360, 01251], lr: 0.000744, loss: 0.4215
2022-09-30 23:53:58 - train: epoch 0193, iter [00370, 01251], lr: 0.000744, loss: 0.4173
2022-09-30 23:54:16 - train: epoch 0193, iter [00380, 01251], lr: 0.000744, loss: 0.3994
2022-09-30 23:54:34 - train: epoch 0193, iter [00390, 01251], lr: 0.000744, loss: 0.4114
2022-09-30 23:54:52 - train: epoch 0193, iter [00400, 01251], lr: 0.000744, loss: 0.3958
2022-09-30 23:55:09 - train: epoch 0193, iter [00410, 01251], lr: 0.000743, loss: 0.4159
2022-09-30 23:55:27 - train: epoch 0193, iter [00420, 01251], lr: 0.000743, loss: 0.4248
2022-09-30 23:55:45 - train: epoch 0193, iter [00430, 01251], lr: 0.000743, loss: 0.4141
2022-09-30 23:56:02 - train: epoch 0193, iter [00440, 01251], lr: 0.000743, loss: 0.4335
2022-09-30 23:56:20 - train: epoch 0193, iter [00450, 01251], lr: 0.000743, loss: 0.3914
2022-09-30 23:56:38 - train: epoch 0193, iter [00460, 01251], lr: 0.000743, loss: 0.3985
2022-09-30 23:56:56 - train: epoch 0193, iter [00470, 01251], lr: 0.000743, loss: 0.4080
2022-09-30 23:57:13 - train: epoch 0193, iter [00480, 01251], lr: 0.000743, loss: 0.4186
2022-09-30 23:57:31 - train: epoch 0193, iter [00490, 01251], lr: 0.000743, loss: 0.4287
2022-09-30 23:57:49 - train: epoch 0193, iter [00500, 01251], lr: 0.000743, loss: 0.4034
2022-09-30 23:58:07 - train: epoch 0193, iter [00510, 01251], lr: 0.000743, loss: 0.3793
2022-09-30 23:58:25 - train: epoch 0193, iter [00520, 01251], lr: 0.000743, loss: 0.3992
2022-09-30 23:58:42 - train: epoch 0193, iter [00530, 01251], lr: 0.000743, loss: 0.3895
2022-09-30 23:59:00 - train: epoch 0193, iter [00540, 01251], lr: 0.000743, loss: 0.4083
2022-09-30 23:59:18 - train: epoch 0193, iter [00550, 01251], lr: 0.000743, loss: 0.3912
2022-09-30 23:59:35 - train: epoch 0193, iter [00560, 01251], lr: 0.000743, loss: 0.4052
2022-09-30 23:59:53 - train: epoch 0193, iter [00570, 01251], lr: 0.000743, loss: 0.3840
2022-10-01 00:00:11 - train: epoch 0193, iter [00580, 01251], lr: 0.000743, loss: 0.3955
2022-10-01 00:00:28 - train: epoch 0193, iter [00590, 01251], lr: 0.000743, loss: 0.4106
2022-10-01 00:00:46 - train: epoch 0193, iter [00600, 01251], lr: 0.000743, loss: 0.4019
2022-10-01 00:01:04 - train: epoch 0193, iter [00610, 01251], lr: 0.000743, loss: 0.4114
2022-10-01 00:01:21 - train: epoch 0193, iter [00620, 01251], lr: 0.000743, loss: 0.4275
2022-10-01 00:01:39 - train: epoch 0193, iter [00630, 01251], lr: 0.000743, loss: 0.4006
2022-10-01 00:01:57 - train: epoch 0193, iter [00640, 01251], lr: 0.000743, loss: 0.4227
2022-10-01 00:02:15 - train: epoch 0193, iter [00650, 01251], lr: 0.000743, loss: 0.4023
2022-10-01 00:02:32 - train: epoch 0193, iter [00660, 01251], lr: 0.000742, loss: 0.4038
2022-10-01 00:02:50 - train: epoch 0193, iter [00670, 01251], lr: 0.000742, loss: 0.3964
2022-10-01 00:03:08 - train: epoch 0193, iter [00680, 01251], lr: 0.000742, loss: 0.4196
2022-10-01 00:03:25 - train: epoch 0193, iter [00690, 01251], lr: 0.000742, loss: 0.3951
2022-10-01 00:03:43 - train: epoch 0193, iter [00700, 01251], lr: 0.000742, loss: 0.4247
2022-10-01 00:04:01 - train: epoch 0193, iter [00710, 01251], lr: 0.000742, loss: 0.4029
2022-10-01 00:04:19 - train: epoch 0193, iter [00720, 01251], lr: 0.000742, loss: 0.4053
2022-10-01 00:04:36 - train: epoch 0193, iter [00730, 01251], lr: 0.000742, loss: 0.3998
2022-10-01 00:04:54 - train: epoch 0193, iter [00740, 01251], lr: 0.000742, loss: 0.3964
2022-10-01 00:05:12 - train: epoch 0193, iter [00750, 01251], lr: 0.000742, loss: 0.4032
2022-10-01 00:05:30 - train: epoch 0193, iter [00760, 01251], lr: 0.000742, loss: 0.4120
2022-10-01 00:05:47 - train: epoch 0193, iter [00770, 01251], lr: 0.000742, loss: 0.4125
2022-10-01 00:06:05 - train: epoch 0193, iter [00780, 01251], lr: 0.000742, loss: 0.3933
2022-10-01 00:06:23 - train: epoch 0193, iter [00790, 01251], lr: 0.000742, loss: 0.4096
2022-10-01 00:06:41 - train: epoch 0193, iter [00800, 01251], lr: 0.000742, loss: 0.3969
2022-10-01 00:06:58 - train: epoch 0193, iter [00810, 01251], lr: 0.000742, loss: 0.4294
2022-10-01 00:07:16 - train: epoch 0193, iter [00820, 01251], lr: 0.000742, loss: 0.4065
2022-10-01 00:07:34 - train: epoch 0193, iter [00830, 01251], lr: 0.000742, loss: 0.4108
2022-10-01 00:07:51 - train: epoch 0193, iter [00840, 01251], lr: 0.000742, loss: 0.4102
2022-10-01 00:08:09 - train: epoch 0193, iter [00850, 01251], lr: 0.000742, loss: 0.4188
2022-10-01 00:08:27 - train: epoch 0193, iter [00860, 01251], lr: 0.000742, loss: 0.4243
2022-10-01 00:08:44 - train: epoch 0193, iter [00870, 01251], lr: 0.000742, loss: 0.4079
2022-10-01 00:09:02 - train: epoch 0193, iter [00880, 01251], lr: 0.000742, loss: 0.4087
2022-10-01 00:09:20 - train: epoch 0193, iter [00890, 01251], lr: 0.000742, loss: 0.4109
2022-10-01 00:09:38 - train: epoch 0193, iter [00900, 01251], lr: 0.000741, loss: 0.4230
2022-10-01 00:09:55 - train: epoch 0193, iter [00910, 01251], lr: 0.000741, loss: 0.4033
2022-10-01 00:10:13 - train: epoch 0193, iter [00920, 01251], lr: 0.000741, loss: 0.4052
2022-10-01 00:10:31 - train: epoch 0193, iter [00930, 01251], lr: 0.000741, loss: 0.4106
2022-10-01 00:10:48 - train: epoch 0193, iter [00940, 01251], lr: 0.000741, loss: 0.3963
2022-10-01 00:11:06 - train: epoch 0193, iter [00950, 01251], lr: 0.000741, loss: 0.4035
2022-10-01 00:11:24 - train: epoch 0193, iter [00960, 01251], lr: 0.000741, loss: 0.3954
2022-10-01 00:11:42 - train: epoch 0193, iter [00970, 01251], lr: 0.000741, loss: 0.4059
2022-10-01 00:11:59 - train: epoch 0193, iter [00980, 01251], lr: 0.000741, loss: 0.4032
2022-10-01 00:12:17 - train: epoch 0193, iter [00990, 01251], lr: 0.000741, loss: 0.4091
2022-10-01 00:12:35 - train: epoch 0193, iter [01000, 01251], lr: 0.000741, loss: 0.4116
2022-10-01 00:12:53 - train: epoch 0193, iter [01010, 01251], lr: 0.000741, loss: 0.4151
2022-10-01 00:13:11 - train: epoch 0193, iter [01020, 01251], lr: 0.000741, loss: 0.4112
2022-10-01 00:13:28 - train: epoch 0193, iter [01030, 01251], lr: 0.000741, loss: 0.3957
2022-10-01 00:13:46 - train: epoch 0193, iter [01040, 01251], lr: 0.000741, loss: 0.3930
2022-10-01 00:14:03 - train: epoch 0193, iter [01050, 01251], lr: 0.000741, loss: 0.4130
2022-10-01 00:14:21 - train: epoch 0193, iter [01060, 01251], lr: 0.000741, loss: 0.4347
2022-10-01 00:14:39 - train: epoch 0193, iter [01070, 01251], lr: 0.000741, loss: 0.3996
2022-10-01 00:14:57 - train: epoch 0193, iter [01080, 01251], lr: 0.000741, loss: 0.4043
2022-10-01 00:15:14 - train: epoch 0193, iter [01090, 01251], lr: 0.000741, loss: 0.4048
2022-10-01 00:15:32 - train: epoch 0193, iter [01100, 01251], lr: 0.000741, loss: 0.4214
2022-10-01 00:15:50 - train: epoch 0193, iter [01110, 01251], lr: 0.000741, loss: 0.4316
2022-10-01 00:16:08 - train: epoch 0193, iter [01120, 01251], lr: 0.000741, loss: 0.4143
2022-10-01 00:16:25 - train: epoch 0193, iter [01130, 01251], lr: 0.000741, loss: 0.4091
2022-10-01 00:16:43 - train: epoch 0193, iter [01140, 01251], lr: 0.000741, loss: 0.4213
2022-10-01 00:17:01 - train: epoch 0193, iter [01150, 01251], lr: 0.000740, loss: 0.4105
2022-10-01 00:17:19 - train: epoch 0193, iter [01160, 01251], lr: 0.000740, loss: 0.4124
2022-10-01 00:17:36 - train: epoch 0193, iter [01170, 01251], lr: 0.000740, loss: 0.4255
2022-10-01 00:17:54 - train: epoch 0193, iter [01180, 01251], lr: 0.000740, loss: 0.4130
2022-10-01 00:18:12 - train: epoch 0193, iter [01190, 01251], lr: 0.000740, loss: 0.3971
2022-10-01 00:18:29 - train: epoch 0193, iter [01200, 01251], lr: 0.000740, loss: 0.4079
2022-10-01 00:18:47 - train: epoch 0193, iter [01210, 01251], lr: 0.000740, loss: 0.4083
2022-10-01 00:19:05 - train: epoch 0193, iter [01220, 01251], lr: 0.000740, loss: 0.4251
2022-10-01 00:19:23 - train: epoch 0193, iter [01230, 01251], lr: 0.000740, loss: 0.4065
2022-10-01 00:19:40 - train: epoch 0193, iter [01240, 01251], lr: 0.000740, loss: 0.3968
2022-10-01 00:19:58 - train: epoch 0193, iter [01250, 01251], lr: 0.000740, loss: 0.4000
2022-10-01 00:20:01 - train: epoch 193, train_loss: 0.4076
2022-10-01 00:20:03 - until epoch: 193, best_loss: 0.4076
2022-10-01 00:20:03 - epoch 194 lr: 0.000740
2022-10-01 00:20:28 - train: epoch 0194, iter [00010, 01251], lr: 0.000740, loss: 0.4134
2022-10-01 00:20:46 - train: epoch 0194, iter [00020, 01251], lr: 0.000740, loss: 0.4007
2022-10-01 00:21:03 - train: epoch 0194, iter [00030, 01251], lr: 0.000740, loss: 0.4070
2022-10-01 00:21:21 - train: epoch 0194, iter [00040, 01251], lr: 0.000740, loss: 0.4111
2022-10-01 00:21:39 - train: epoch 0194, iter [00050, 01251], lr: 0.000740, loss: 0.4179
2022-10-01 00:21:56 - train: epoch 0194, iter [00060, 01251], lr: 0.000740, loss: 0.4015
2022-10-01 00:22:14 - train: epoch 0194, iter [00070, 01251], lr: 0.000740, loss: 0.4151
2022-10-01 00:22:32 - train: epoch 0194, iter [00080, 01251], lr: 0.000740, loss: 0.4161
2022-10-01 00:22:49 - train: epoch 0194, iter [00090, 01251], lr: 0.000740, loss: 0.4100
2022-10-01 00:23:07 - train: epoch 0194, iter [00100, 01251], lr: 0.000740, loss: 0.4161
2022-10-01 00:23:25 - train: epoch 0194, iter [00110, 01251], lr: 0.000740, loss: 0.4100
2022-10-01 00:23:42 - train: epoch 0194, iter [00120, 01251], lr: 0.000740, loss: 0.4040
2022-10-01 00:24:00 - train: epoch 0194, iter [00130, 01251], lr: 0.000740, loss: 0.3993
2022-10-01 00:24:18 - train: epoch 0194, iter [00140, 01251], lr: 0.000739, loss: 0.4179
2022-10-01 00:24:35 - train: epoch 0194, iter [00150, 01251], lr: 0.000739, loss: 0.3943
2022-10-01 00:24:53 - train: epoch 0194, iter [00160, 01251], lr: 0.000739, loss: 0.4018
2022-10-01 00:25:11 - train: epoch 0194, iter [00170, 01251], lr: 0.000739, loss: 0.4063
2022-10-01 00:25:28 - train: epoch 0194, iter [00180, 01251], lr: 0.000739, loss: 0.4069
2022-10-01 00:25:46 - train: epoch 0194, iter [00190, 01251], lr: 0.000739, loss: 0.3906
2022-10-01 00:26:04 - train: epoch 0194, iter [00200, 01251], lr: 0.000739, loss: 0.4148
2022-10-01 00:26:21 - train: epoch 0194, iter [00210, 01251], lr: 0.000739, loss: 0.4000
2022-10-01 00:26:39 - train: epoch 0194, iter [00220, 01251], lr: 0.000739, loss: 0.4088
2022-10-01 00:26:57 - train: epoch 0194, iter [00230, 01251], lr: 0.000739, loss: 0.4141
2022-10-01 00:27:15 - train: epoch 0194, iter [00240, 01251], lr: 0.000739, loss: 0.4048
2022-10-01 00:27:32 - train: epoch 0194, iter [00250, 01251], lr: 0.000739, loss: 0.4099
2022-10-01 00:27:50 - train: epoch 0194, iter [00260, 01251], lr: 0.000739, loss: 0.4268
2022-10-01 00:28:08 - train: epoch 0194, iter [00270, 01251], lr: 0.000739, loss: 0.4199
2022-10-01 00:28:25 - train: epoch 0194, iter [00280, 01251], lr: 0.000739, loss: 0.4150
2022-10-01 00:28:43 - train: epoch 0194, iter [00290, 01251], lr: 0.000739, loss: 0.4022
2022-10-01 00:29:01 - train: epoch 0194, iter [00300, 01251], lr: 0.000739, loss: 0.4207
2022-10-01 00:29:18 - train: epoch 0194, iter [00310, 01251], lr: 0.000739, loss: 0.3963
2022-10-01 00:29:36 - train: epoch 0194, iter [00320, 01251], lr: 0.000739, loss: 0.3995
2022-10-01 00:29:54 - train: epoch 0194, iter [00330, 01251], lr: 0.000739, loss: 0.3910
2022-10-01 00:30:11 - train: epoch 0194, iter [00340, 01251], lr: 0.000739, loss: 0.4014
2022-10-01 00:30:29 - train: epoch 0194, iter [00350, 01251], lr: 0.000739, loss: 0.4042
2022-10-01 00:30:47 - train: epoch 0194, iter [00360, 01251], lr: 0.000739, loss: 0.4050
2022-10-01 00:31:05 - train: epoch 0194, iter [00370, 01251], lr: 0.000739, loss: 0.4158
2022-10-01 00:31:22 - train: epoch 0194, iter [00380, 01251], lr: 0.000739, loss: 0.4025
2022-10-01 00:31:40 - train: epoch 0194, iter [00390, 01251], lr: 0.000738, loss: 0.4147
2022-10-01 00:31:58 - train: epoch 0194, iter [00400, 01251], lr: 0.000738, loss: 0.4090
2022-10-01 00:32:15 - train: epoch 0194, iter [00410, 01251], lr: 0.000738, loss: 0.4095
2022-10-01 00:32:33 - train: epoch 0194, iter [00420, 01251], lr: 0.000738, loss: 0.3993
2022-10-01 00:32:50 - train: epoch 0194, iter [00430, 01251], lr: 0.000738, loss: 0.3957
2022-10-01 00:33:08 - train: epoch 0194, iter [00440, 01251], lr: 0.000738, loss: 0.4109
2022-10-01 00:33:26 - train: epoch 0194, iter [00450, 01251], lr: 0.000738, loss: 0.4047
2022-10-01 00:33:44 - train: epoch 0194, iter [00460, 01251], lr: 0.000738, loss: 0.4412
2022-10-01 00:34:01 - train: epoch 0194, iter [00470, 01251], lr: 0.000738, loss: 0.4019
2022-10-01 00:34:19 - train: epoch 0194, iter [00480, 01251], lr: 0.000738, loss: 0.4146
2022-10-01 00:34:36 - train: epoch 0194, iter [00490, 01251], lr: 0.000738, loss: 0.4151
2022-10-01 00:34:54 - train: epoch 0194, iter [00500, 01251], lr: 0.000738, loss: 0.3999
2022-10-01 00:35:12 - train: epoch 0194, iter [00510, 01251], lr: 0.000738, loss: 0.4173
2022-10-01 00:35:30 - train: epoch 0194, iter [00520, 01251], lr: 0.000738, loss: 0.4057
2022-10-01 00:35:47 - train: epoch 0194, iter [00530, 01251], lr: 0.000738, loss: 0.4073
2022-10-01 00:36:05 - train: epoch 0194, iter [00540, 01251], lr: 0.000738, loss: 0.4174
2022-10-01 00:36:23 - train: epoch 0194, iter [00550, 01251], lr: 0.000738, loss: 0.4177
2022-10-01 00:36:41 - train: epoch 0194, iter [00560, 01251], lr: 0.000738, loss: 0.4110
2022-10-01 00:36:58 - train: epoch 0194, iter [00570, 01251], lr: 0.000738, loss: 0.4129
2022-10-01 00:37:16 - train: epoch 0194, iter [00580, 01251], lr: 0.000738, loss: 0.3922
2022-10-01 00:37:34 - train: epoch 0194, iter [00590, 01251], lr: 0.000738, loss: 0.4000
2022-10-01 00:37:52 - train: epoch 0194, iter [00600, 01251], lr: 0.000738, loss: 0.3992
2022-10-01 00:38:09 - train: epoch 0194, iter [00610, 01251], lr: 0.000738, loss: 0.4123
2022-10-01 00:38:27 - train: epoch 0194, iter [00620, 01251], lr: 0.000738, loss: 0.3895
2022-10-01 00:38:45 - train: epoch 0194, iter [00630, 01251], lr: 0.000738, loss: 0.4094
2022-10-01 00:39:03 - train: epoch 0194, iter [00640, 01251], lr: 0.000737, loss: 0.4154
2022-10-01 00:39:20 - train: epoch 0194, iter [00650, 01251], lr: 0.000737, loss: 0.3962
2022-10-01 00:39:38 - train: epoch 0194, iter [00660, 01251], lr: 0.000737, loss: 0.4107
2022-10-01 00:39:56 - train: epoch 0194, iter [00670, 01251], lr: 0.000737, loss: 0.4064
2022-10-01 00:40:13 - train: epoch 0194, iter [00680, 01251], lr: 0.000737, loss: 0.4069
2022-10-01 00:40:31 - train: epoch 0194, iter [00690, 01251], lr: 0.000737, loss: 0.3990
2022-10-01 00:40:49 - train: epoch 0194, iter [00700, 01251], lr: 0.000737, loss: 0.4038
2022-10-01 00:41:07 - train: epoch 0194, iter [00710, 01251], lr: 0.000737, loss: 0.4009
2022-10-01 00:41:24 - train: epoch 0194, iter [00720, 01251], lr: 0.000737, loss: 0.4240
2022-10-01 00:41:42 - train: epoch 0194, iter [00730, 01251], lr: 0.000737, loss: 0.3943
2022-10-01 00:42:00 - train: epoch 0194, iter [00740, 01251], lr: 0.000737, loss: 0.4164
2022-10-01 00:42:17 - train: epoch 0194, iter [00750, 01251], lr: 0.000737, loss: 0.4278
2022-10-01 00:42:35 - train: epoch 0194, iter [00760, 01251], lr: 0.000737, loss: 0.4147
2022-10-01 00:42:53 - train: epoch 0194, iter [00770, 01251], lr: 0.000737, loss: 0.4061
2022-10-01 00:43:10 - train: epoch 0194, iter [00780, 01251], lr: 0.000737, loss: 0.4183
2022-10-01 00:43:28 - train: epoch 0194, iter [00790, 01251], lr: 0.000737, loss: 0.3996
2022-10-01 00:43:46 - train: epoch 0194, iter [00800, 01251], lr: 0.000737, loss: 0.4099
2022-10-01 00:44:03 - train: epoch 0194, iter [00810, 01251], lr: 0.000737, loss: 0.4035
2022-10-01 00:44:21 - train: epoch 0194, iter [00820, 01251], lr: 0.000737, loss: 0.3979
2022-10-01 00:44:39 - train: epoch 0194, iter [00830, 01251], lr: 0.000737, loss: 0.4091
2022-10-01 00:44:56 - train: epoch 0194, iter [00840, 01251], lr: 0.000737, loss: 0.4250
2022-10-01 00:45:14 - train: epoch 0194, iter [00850, 01251], lr: 0.000737, loss: 0.4211
2022-10-01 00:45:31 - train: epoch 0194, iter [00860, 01251], lr: 0.000737, loss: 0.4126
2022-10-01 00:45:49 - train: epoch 0194, iter [00870, 01251], lr: 0.000737, loss: 0.4064
2022-10-01 00:46:07 - train: epoch 0194, iter [00880, 01251], lr: 0.000736, loss: 0.3985
2022-10-01 00:46:24 - train: epoch 0194, iter [00890, 01251], lr: 0.000736, loss: 0.4199
2022-10-01 00:46:42 - train: epoch 0194, iter [00900, 01251], lr: 0.000736, loss: 0.4018
2022-10-01 00:47:00 - train: epoch 0194, iter [00910, 01251], lr: 0.000736, loss: 0.4190
2022-10-01 00:47:18 - train: epoch 0194, iter [00920, 01251], lr: 0.000736, loss: 0.4019
2022-10-01 00:47:35 - train: epoch 0194, iter [00930, 01251], lr: 0.000736, loss: 0.4100
2022-10-01 00:47:53 - train: epoch 0194, iter [00940, 01251], lr: 0.000736, loss: 0.4034
2022-10-01 00:48:11 - train: epoch 0194, iter [00950, 01251], lr: 0.000736, loss: 0.4096
2022-10-01 00:48:28 - train: epoch 0194, iter [00960, 01251], lr: 0.000736, loss: 0.4140
2022-10-01 00:48:46 - train: epoch 0194, iter [00970, 01251], lr: 0.000736, loss: 0.4101
2022-10-01 00:49:04 - train: epoch 0194, iter [00980, 01251], lr: 0.000736, loss: 0.4123
2022-10-01 00:49:21 - train: epoch 0194, iter [00990, 01251], lr: 0.000736, loss: 0.4236
2022-10-01 00:49:39 - train: epoch 0194, iter [01000, 01251], lr: 0.000736, loss: 0.4276
2022-10-01 00:49:57 - train: epoch 0194, iter [01010, 01251], lr: 0.000736, loss: 0.4049
2022-10-01 00:50:14 - train: epoch 0194, iter [01020, 01251], lr: 0.000736, loss: 0.4259
2022-10-01 00:50:32 - train: epoch 0194, iter [01030, 01251], lr: 0.000736, loss: 0.4165
2022-10-01 00:50:50 - train: epoch 0194, iter [01040, 01251], lr: 0.000736, loss: 0.4305
2022-10-01 00:51:07 - train: epoch 0194, iter [01050, 01251], lr: 0.000736, loss: 0.4006
2022-10-01 00:51:25 - train: epoch 0194, iter [01060, 01251], lr: 0.000736, loss: 0.4066
2022-10-01 00:51:43 - train: epoch 0194, iter [01070, 01251], lr: 0.000736, loss: 0.3911
2022-10-01 00:52:00 - train: epoch 0194, iter [01080, 01251], lr: 0.000736, loss: 0.4383
2022-10-01 00:52:18 - train: epoch 0194, iter [01090, 01251], lr: 0.000736, loss: 0.4240
2022-10-01 00:52:36 - train: epoch 0194, iter [01100, 01251], lr: 0.000736, loss: 0.4042
2022-10-01 00:52:53 - train: epoch 0194, iter [01110, 01251], lr: 0.000736, loss: 0.4048
2022-10-01 00:53:11 - train: epoch 0194, iter [01120, 01251], lr: 0.000736, loss: 0.4134
2022-10-01 00:53:29 - train: epoch 0194, iter [01130, 01251], lr: 0.000735, loss: 0.3990
2022-10-01 00:53:47 - train: epoch 0194, iter [01140, 01251], lr: 0.000735, loss: 0.4118
2022-10-01 00:54:04 - train: epoch 0194, iter [01150, 01251], lr: 0.000735, loss: 0.4144
2022-10-01 00:54:22 - train: epoch 0194, iter [01160, 01251], lr: 0.000735, loss: 0.3994
2022-10-01 00:54:40 - train: epoch 0194, iter [01170, 01251], lr: 0.000735, loss: 0.4076
2022-10-01 00:54:58 - train: epoch 0194, iter [01180, 01251], lr: 0.000735, loss: 0.4109
2022-10-01 00:55:15 - train: epoch 0194, iter [01190, 01251], lr: 0.000735, loss: 0.4138
2022-10-01 00:55:33 - train: epoch 0194, iter [01200, 01251], lr: 0.000735, loss: 0.4280
2022-10-01 00:55:51 - train: epoch 0194, iter [01210, 01251], lr: 0.000735, loss: 0.4201
2022-10-01 00:56:09 - train: epoch 0194, iter [01220, 01251], lr: 0.000735, loss: 0.3947
2022-10-01 00:56:26 - train: epoch 0194, iter [01230, 01251], lr: 0.000735, loss: 0.4266
2022-10-01 00:56:44 - train: epoch 0194, iter [01240, 01251], lr: 0.000735, loss: 0.4387
2022-10-01 00:57:01 - train: epoch 0194, iter [01250, 01251], lr: 0.000735, loss: 0.4046
2022-10-01 00:57:04 - train: epoch 194, train_loss: 0.4075
2022-10-01 00:57:07 - until epoch: 194, best_loss: 0.4075
2022-10-01 00:57:07 - epoch 195 lr: 0.000735
2022-10-01 00:57:32 - train: epoch 0195, iter [00010, 01251], lr: 0.000735, loss: 0.4294
2022-10-01 00:57:50 - train: epoch 0195, iter [00020, 01251], lr: 0.000735, loss: 0.4209
2022-10-01 00:58:07 - train: epoch 0195, iter [00030, 01251], lr: 0.000735, loss: 0.4064
2022-10-01 00:58:25 - train: epoch 0195, iter [00040, 01251], lr: 0.000735, loss: 0.4016
2022-10-01 00:58:42 - train: epoch 0195, iter [00050, 01251], lr: 0.000735, loss: 0.3947
2022-10-01 00:59:00 - train: epoch 0195, iter [00060, 01251], lr: 0.000735, loss: 0.4134
2022-10-01 00:59:17 - train: epoch 0195, iter [00070, 01251], lr: 0.000735, loss: 0.4088
2022-10-01 00:59:35 - train: epoch 0195, iter [00080, 01251], lr: 0.000735, loss: 0.4122
2022-10-01 00:59:53 - train: epoch 0195, iter [00090, 01251], lr: 0.000735, loss: 0.4173
2022-10-01 01:00:11 - train: epoch 0195, iter [00100, 01251], lr: 0.000735, loss: 0.3987
2022-10-01 01:00:28 - train: epoch 0195, iter [00110, 01251], lr: 0.000735, loss: 0.4178
2022-10-01 01:00:46 - train: epoch 0195, iter [00120, 01251], lr: 0.000734, loss: 0.3875
2022-10-01 01:01:04 - train: epoch 0195, iter [00130, 01251], lr: 0.000734, loss: 0.4143
2022-10-01 01:01:22 - train: epoch 0195, iter [00140, 01251], lr: 0.000734, loss: 0.3970
2022-10-01 01:01:39 - train: epoch 0195, iter [00150, 01251], lr: 0.000734, loss: 0.3819
2022-10-01 01:01:57 - train: epoch 0195, iter [00160, 01251], lr: 0.000734, loss: 0.3987
2022-10-01 01:02:15 - train: epoch 0195, iter [00170, 01251], lr: 0.000734, loss: 0.3999
2022-10-01 01:02:33 - train: epoch 0195, iter [00180, 01251], lr: 0.000734, loss: 0.4020
2022-10-01 01:02:50 - train: epoch 0195, iter [00190, 01251], lr: 0.000734, loss: 0.4097
2022-10-01 01:03:08 - train: epoch 0195, iter [00200, 01251], lr: 0.000734, loss: 0.4144
2022-10-01 01:03:26 - train: epoch 0195, iter [00210, 01251], lr: 0.000734, loss: 0.4110
2022-10-01 01:03:43 - train: epoch 0195, iter [00220, 01251], lr: 0.000734, loss: 0.4231
2022-10-01 01:04:01 - train: epoch 0195, iter [00230, 01251], lr: 0.000734, loss: 0.4187
2022-10-01 01:04:19 - train: epoch 0195, iter [00240, 01251], lr: 0.000734, loss: 0.4048
2022-10-01 01:04:36 - train: epoch 0195, iter [00250, 01251], lr: 0.000734, loss: 0.4208
2022-10-01 01:04:54 - train: epoch 0195, iter [00260, 01251], lr: 0.000734, loss: 0.3898
2022-10-01 01:05:12 - train: epoch 0195, iter [00270, 01251], lr: 0.000734, loss: 0.3926
2022-10-01 01:05:29 - train: epoch 0195, iter [00280, 01251], lr: 0.000734, loss: 0.4110
2022-10-01 01:05:47 - train: epoch 0195, iter [00290, 01251], lr: 0.000734, loss: 0.4180
2022-10-01 01:06:05 - train: epoch 0195, iter [00300, 01251], lr: 0.000734, loss: 0.4090
2022-10-01 01:06:23 - train: epoch 0195, iter [00310, 01251], lr: 0.000734, loss: 0.4220
2022-10-01 01:06:40 - train: epoch 0195, iter [00320, 01251], lr: 0.000734, loss: 0.4126
2022-10-01 01:06:58 - train: epoch 0195, iter [00330, 01251], lr: 0.000734, loss: 0.4217
2022-10-01 01:07:16 - train: epoch 0195, iter [00340, 01251], lr: 0.000734, loss: 0.4028
2022-10-01 01:07:34 - train: epoch 0195, iter [00350, 01251], lr: 0.000734, loss: 0.4259
2022-10-01 01:07:51 - train: epoch 0195, iter [00360, 01251], lr: 0.000734, loss: 0.4266
2022-10-01 01:08:09 - train: epoch 0195, iter [00370, 01251], lr: 0.000733, loss: 0.4245
2022-10-01 01:08:27 - train: epoch 0195, iter [00380, 01251], lr: 0.000733, loss: 0.4175
2022-10-01 01:08:44 - train: epoch 0195, iter [00390, 01251], lr: 0.000733, loss: 0.3855
2022-10-01 01:09:02 - train: epoch 0195, iter [00400, 01251], lr: 0.000733, loss: 0.4107
2022-10-01 01:09:20 - train: epoch 0195, iter [00410, 01251], lr: 0.000733, loss: 0.4307
2022-10-01 01:09:38 - train: epoch 0195, iter [00420, 01251], lr: 0.000733, loss: 0.4080
2022-10-01 01:09:56 - train: epoch 0195, iter [00430, 01251], lr: 0.000733, loss: 0.4105
2022-10-01 01:10:13 - train: epoch 0195, iter [00440, 01251], lr: 0.000733, loss: 0.4151
2022-10-01 01:10:31 - train: epoch 0195, iter [00450, 01251], lr: 0.000733, loss: 0.4047
2022-10-01 01:10:49 - train: epoch 0195, iter [00460, 01251], lr: 0.000733, loss: 0.4051
2022-10-01 01:11:07 - train: epoch 0195, iter [00470, 01251], lr: 0.000733, loss: 0.4104
2022-10-01 01:11:24 - train: epoch 0195, iter [00480, 01251], lr: 0.000733, loss: 0.3983
2022-10-01 01:11:42 - train: epoch 0195, iter [00490, 01251], lr: 0.000733, loss: 0.3896
2022-10-01 01:12:00 - train: epoch 0195, iter [00500, 01251], lr: 0.000733, loss: 0.3942
2022-10-01 01:12:18 - train: epoch 0195, iter [00510, 01251], lr: 0.000733, loss: 0.4196
2022-10-01 01:12:35 - train: epoch 0195, iter [00520, 01251], lr: 0.000733, loss: 0.3946
2022-10-01 01:12:53 - train: epoch 0195, iter [00530, 01251], lr: 0.000733, loss: 0.3940
2022-10-01 01:13:11 - train: epoch 0195, iter [00540, 01251], lr: 0.000733, loss: 0.4226
2022-10-01 01:13:28 - train: epoch 0195, iter [00550, 01251], lr: 0.000733, loss: 0.4184
2022-10-01 01:13:46 - train: epoch 0195, iter [00560, 01251], lr: 0.000733, loss: 0.3902
2022-10-01 01:14:04 - train: epoch 0195, iter [00570, 01251], lr: 0.000733, loss: 0.4187
2022-10-01 01:14:21 - train: epoch 0195, iter [00580, 01251], lr: 0.000733, loss: 0.4325
2022-10-01 01:14:39 - train: epoch 0195, iter [00590, 01251], lr: 0.000733, loss: 0.4027
2022-10-01 01:14:57 - train: epoch 0195, iter [00600, 01251], lr: 0.000733, loss: 0.4351
2022-10-01 01:15:14 - train: epoch 0195, iter [00610, 01251], lr: 0.000732, loss: 0.3990
2022-10-01 01:15:32 - train: epoch 0195, iter [00620, 01251], lr: 0.000732, loss: 0.4006
2022-10-01 01:15:50 - train: epoch 0195, iter [00630, 01251], lr: 0.000732, loss: 0.4159
2022-10-01 01:16:08 - train: epoch 0195, iter [00640, 01251], lr: 0.000732, loss: 0.4164
2022-10-01 01:16:25 - train: epoch 0195, iter [00650, 01251], lr: 0.000732, loss: 0.3930
2022-10-01 01:16:43 - train: epoch 0195, iter [00660, 01251], lr: 0.000732, loss: 0.4088
2022-10-01 01:17:01 - train: epoch 0195, iter [00670, 01251], lr: 0.000732, loss: 0.4230
2022-10-01 01:17:18 - train: epoch 0195, iter [00680, 01251], lr: 0.000732, loss: 0.4055
2022-10-01 01:17:36 - train: epoch 0195, iter [00690, 01251], lr: 0.000732, loss: 0.4201
2022-10-01 01:17:54 - train: epoch 0195, iter [00700, 01251], lr: 0.000732, loss: 0.4292
2022-10-01 01:18:11 - train: epoch 0195, iter [00710, 01251], lr: 0.000732, loss: 0.3882
2022-10-01 01:18:29 - train: epoch 0195, iter [00720, 01251], lr: 0.000732, loss: 0.4067
2022-10-01 01:18:47 - train: epoch 0195, iter [00730, 01251], lr: 0.000732, loss: 0.4002
2022-10-01 01:19:05 - train: epoch 0195, iter [00740, 01251], lr: 0.000732, loss: 0.4121
2022-10-01 01:19:22 - train: epoch 0195, iter [00750, 01251], lr: 0.000732, loss: 0.3820
2022-10-01 01:19:40 - train: epoch 0195, iter [00760, 01251], lr: 0.000732, loss: 0.4081
2022-10-01 01:19:58 - train: epoch 0195, iter [00770, 01251], lr: 0.000732, loss: 0.4174
2022-10-01 01:20:15 - train: epoch 0195, iter [00780, 01251], lr: 0.000732, loss: 0.4220
2022-10-01 01:20:33 - train: epoch 0195, iter [00790, 01251], lr: 0.000732, loss: 0.4039
2022-10-01 01:20:51 - train: epoch 0195, iter [00800, 01251], lr: 0.000732, loss: 0.4079
2022-10-01 01:21:08 - train: epoch 0195, iter [00810, 01251], lr: 0.000732, loss: 0.4201
2022-10-01 01:21:26 - train: epoch 0195, iter [00820, 01251], lr: 0.000732, loss: 0.3970
2022-10-01 01:21:44 - train: epoch 0195, iter [00830, 01251], lr: 0.000732, loss: 0.4021
2022-10-01 01:22:01 - train: epoch 0195, iter [00840, 01251], lr: 0.000732, loss: 0.4036
2022-10-01 01:22:19 - train: epoch 0195, iter [00850, 01251], lr: 0.000732, loss: 0.3784
2022-10-01 01:22:37 - train: epoch 0195, iter [00860, 01251], lr: 0.000731, loss: 0.4207
2022-10-01 01:22:55 - train: epoch 0195, iter [00870, 01251], lr: 0.000731, loss: 0.4098
2022-10-01 01:23:12 - train: epoch 0195, iter [00880, 01251], lr: 0.000731, loss: 0.4026
2022-10-01 01:23:30 - train: epoch 0195, iter [00890, 01251], lr: 0.000731, loss: 0.3990
2022-10-01 01:23:48 - train: epoch 0195, iter [00900, 01251], lr: 0.000731, loss: 0.4002
2022-10-01 01:24:06 - train: epoch 0195, iter [00910, 01251], lr: 0.000731, loss: 0.4193
2022-10-01 01:24:23 - train: epoch 0195, iter [00920, 01251], lr: 0.000731, loss: 0.4080
2022-10-01 01:24:41 - train: epoch 0195, iter [00930, 01251], lr: 0.000731, loss: 0.3980
2022-10-01 01:24:59 - train: epoch 0195, iter [00940, 01251], lr: 0.000731, loss: 0.4244
2022-10-01 01:25:16 - train: epoch 0195, iter [00950, 01251], lr: 0.000731, loss: 0.4140
2022-10-01 01:25:34 - train: epoch 0195, iter [00960, 01251], lr: 0.000731, loss: 0.3968
2022-10-01 01:25:52 - train: epoch 0195, iter [00970, 01251], lr: 0.000731, loss: 0.4143
2022-10-01 01:26:10 - train: epoch 0195, iter [00980, 01251], lr: 0.000731, loss: 0.4125
2022-10-01 01:26:27 - train: epoch 0195, iter [00990, 01251], lr: 0.000731, loss: 0.3779
2022-10-01 01:26:45 - train: epoch 0195, iter [01000, 01251], lr: 0.000731, loss: 0.4062
2022-10-01 01:27:03 - train: epoch 0195, iter [01010, 01251], lr: 0.000731, loss: 0.3930
2022-10-01 01:27:21 - train: epoch 0195, iter [01020, 01251], lr: 0.000731, loss: 0.4135
2022-10-01 01:27:38 - train: epoch 0195, iter [01030, 01251], lr: 0.000731, loss: 0.4015
2022-10-01 01:27:56 - train: epoch 0195, iter [01040, 01251], lr: 0.000731, loss: 0.4165
2022-10-01 01:28:14 - train: epoch 0195, iter [01050, 01251], lr: 0.000731, loss: 0.4017
2022-10-01 01:28:31 - train: epoch 0195, iter [01060, 01251], lr: 0.000731, loss: 0.4020
2022-10-01 01:28:49 - train: epoch 0195, iter [01070, 01251], lr: 0.000731, loss: 0.4387
2022-10-01 01:29:07 - train: epoch 0195, iter [01080, 01251], lr: 0.000731, loss: 0.4201
2022-10-01 01:29:24 - train: epoch 0195, iter [01090, 01251], lr: 0.000731, loss: 0.4084
2022-10-01 01:29:42 - train: epoch 0195, iter [01100, 01251], lr: 0.000730, loss: 0.4313
2022-10-01 01:30:00 - train: epoch 0195, iter [01110, 01251], lr: 0.000730, loss: 0.4196
2022-10-01 01:30:18 - train: epoch 0195, iter [01120, 01251], lr: 0.000730, loss: 0.4067
2022-10-01 01:30:35 - train: epoch 0195, iter [01130, 01251], lr: 0.000730, loss: 0.4128
2022-10-01 01:30:53 - train: epoch 0195, iter [01140, 01251], lr: 0.000730, loss: 0.4194
2022-10-01 01:31:10 - train: epoch 0195, iter [01150, 01251], lr: 0.000730, loss: 0.3968
2022-10-01 01:31:28 - train: epoch 0195, iter [01160, 01251], lr: 0.000730, loss: 0.4021
2022-10-01 01:31:46 - train: epoch 0195, iter [01170, 01251], lr: 0.000730, loss: 0.3906
2022-10-01 01:32:03 - train: epoch 0195, iter [01180, 01251], lr: 0.000730, loss: 0.4001
2022-10-01 01:32:21 - train: epoch 0195, iter [01190, 01251], lr: 0.000730, loss: 0.4007
2022-10-01 01:32:39 - train: epoch 0195, iter [01200, 01251], lr: 0.000730, loss: 0.4151
2022-10-01 01:32:56 - train: epoch 0195, iter [01210, 01251], lr: 0.000730, loss: 0.3999
2022-10-01 01:33:14 - train: epoch 0195, iter [01220, 01251], lr: 0.000730, loss: 0.4134
2022-10-01 01:33:32 - train: epoch 0195, iter [01230, 01251], lr: 0.000730, loss: 0.4269
2022-10-01 01:33:49 - train: epoch 0195, iter [01240, 01251], lr: 0.000730, loss: 0.4141
2022-10-01 01:34:07 - train: epoch 0195, iter [01250, 01251], lr: 0.000730, loss: 0.3924
2022-10-01 01:34:10 - train: epoch 195, train_loss: 0.4074
2022-10-01 01:34:13 - until epoch: 195, best_loss: 0.4074
2022-10-01 01:34:13 - epoch 196 lr: 0.000730
2022-10-01 01:34:37 - train: epoch 0196, iter [00010, 01251], lr: 0.000730, loss: 0.3885
2022-10-01 01:34:54 - train: epoch 0196, iter [00020, 01251], lr: 0.000730, loss: 0.3928
2022-10-01 01:35:12 - train: epoch 0196, iter [00030, 01251], lr: 0.000730, loss: 0.4119
2022-10-01 01:35:30 - train: epoch 0196, iter [00040, 01251], lr: 0.000730, loss: 0.4196
2022-10-01 01:35:48 - train: epoch 0196, iter [00050, 01251], lr: 0.000730, loss: 0.3895
2022-10-01 01:36:05 - train: epoch 0196, iter [00060, 01251], lr: 0.000730, loss: 0.4113
2022-10-01 01:36:23 - train: epoch 0196, iter [00070, 01251], lr: 0.000730, loss: 0.4063
2022-10-01 01:36:41 - train: epoch 0196, iter [00080, 01251], lr: 0.000730, loss: 0.4217
2022-10-01 01:36:58 - train: epoch 0196, iter [00090, 01251], lr: 0.000729, loss: 0.4106
2022-10-01 01:37:16 - train: epoch 0196, iter [00100, 01251], lr: 0.000729, loss: 0.4099
2022-10-01 01:37:33 - train: epoch 0196, iter [00110, 01251], lr: 0.000729, loss: 0.4123
2022-10-01 01:37:51 - train: epoch 0196, iter [00120, 01251], lr: 0.000729, loss: 0.4001
2022-10-01 01:38:08 - train: epoch 0196, iter [00130, 01251], lr: 0.000729, loss: 0.4119
2022-10-01 01:38:26 - train: epoch 0196, iter [00140, 01251], lr: 0.000729, loss: 0.4055
2022-10-01 01:38:43 - train: epoch 0196, iter [00150, 01251], lr: 0.000729, loss: 0.4207
2022-10-01 01:39:01 - train: epoch 0196, iter [00160, 01251], lr: 0.000729, loss: 0.4003
2022-10-01 01:39:18 - train: epoch 0196, iter [00170, 01251], lr: 0.000729, loss: 0.4193
2022-10-01 01:39:36 - train: epoch 0196, iter [00180, 01251], lr: 0.000729, loss: 0.4090
2022-10-01 01:39:54 - train: epoch 0196, iter [00190, 01251], lr: 0.000729, loss: 0.4096
2022-10-01 01:40:11 - train: epoch 0196, iter [00200, 01251], lr: 0.000729, loss: 0.3944
2022-10-01 01:40:29 - train: epoch 0196, iter [00210, 01251], lr: 0.000729, loss: 0.4097
2022-10-01 01:40:47 - train: epoch 0196, iter [00220, 01251], lr: 0.000729, loss: 0.3971
2022-10-01 01:41:04 - train: epoch 0196, iter [00230, 01251], lr: 0.000729, loss: 0.3922
2022-10-01 01:41:22 - train: epoch 0196, iter [00240, 01251], lr: 0.000729, loss: 0.4157
2022-10-01 01:41:40 - train: epoch 0196, iter [00250, 01251], lr: 0.000729, loss: 0.4180
2022-10-01 01:41:57 - train: epoch 0196, iter [00260, 01251], lr: 0.000729, loss: 0.3854
2022-10-01 01:42:15 - train: epoch 0196, iter [00270, 01251], lr: 0.000729, loss: 0.4094
2022-10-01 01:42:33 - train: epoch 0196, iter [00280, 01251], lr: 0.000729, loss: 0.4113
2022-10-01 01:42:50 - train: epoch 0196, iter [00290, 01251], lr: 0.000729, loss: 0.3971
2022-10-01 01:43:08 - train: epoch 0196, iter [00300, 01251], lr: 0.000729, loss: 0.3962
2022-10-01 01:43:26 - train: epoch 0196, iter [00310, 01251], lr: 0.000729, loss: 0.4025
2022-10-01 01:43:43 - train: epoch 0196, iter [00320, 01251], lr: 0.000729, loss: 0.4109
2022-10-01 01:44:01 - train: epoch 0196, iter [00330, 01251], lr: 0.000729, loss: 0.3998
2022-10-01 01:44:19 - train: epoch 0196, iter [00340, 01251], lr: 0.000728, loss: 0.4135
2022-10-01 01:44:36 - train: epoch 0196, iter [00350, 01251], lr: 0.000728, loss: 0.4125
2022-10-01 01:44:54 - train: epoch 0196, iter [00360, 01251], lr: 0.000728, loss: 0.4022
2022-10-01 01:45:12 - train: epoch 0196, iter [00370, 01251], lr: 0.000728, loss: 0.4205
2022-10-01 01:45:30 - train: epoch 0196, iter [00380, 01251], lr: 0.000728, loss: 0.3934
2022-10-01 01:45:47 - train: epoch 0196, iter [00390, 01251], lr: 0.000728, loss: 0.4066
2022-10-01 01:46:05 - train: epoch 0196, iter [00400, 01251], lr: 0.000728, loss: 0.3983
2022-10-01 01:46:23 - train: epoch 0196, iter [00410, 01251], lr: 0.000728, loss: 0.4148
2022-10-01 01:46:41 - train: epoch 0196, iter [00420, 01251], lr: 0.000728, loss: 0.4079
2022-10-01 01:46:59 - train: epoch 0196, iter [00430, 01251], lr: 0.000728, loss: 0.4230
2022-10-01 01:47:16 - train: epoch 0196, iter [00440, 01251], lr: 0.000728, loss: 0.4145
2022-10-01 01:47:34 - train: epoch 0196, iter [00450, 01251], lr: 0.000728, loss: 0.4187
2022-10-01 01:47:52 - train: epoch 0196, iter [00460, 01251], lr: 0.000728, loss: 0.4159
2022-10-01 01:48:10 - train: epoch 0196, iter [00470, 01251], lr: 0.000728, loss: 0.4024
2022-10-01 01:48:27 - train: epoch 0196, iter [00480, 01251], lr: 0.000728, loss: 0.4059
2022-10-01 01:48:45 - train: epoch 0196, iter [00490, 01251], lr: 0.000728, loss: 0.3987
2022-10-01 01:49:03 - train: epoch 0196, iter [00500, 01251], lr: 0.000728, loss: 0.4386
2022-10-01 01:49:21 - train: epoch 0196, iter [00510, 01251], lr: 0.000728, loss: 0.3947
2022-10-01 01:49:38 - train: epoch 0196, iter [00520, 01251], lr: 0.000728, loss: 0.3921
2022-10-01 01:49:56 - train: epoch 0196, iter [00530, 01251], lr: 0.000728, loss: 0.3952
2022-10-01 01:50:14 - train: epoch 0196, iter [00540, 01251], lr: 0.000728, loss: 0.3993
2022-10-01 01:50:32 - train: epoch 0196, iter [00550, 01251], lr: 0.000728, loss: 0.3981
2022-10-01 01:50:49 - train: epoch 0196, iter [00560, 01251], lr: 0.000728, loss: 0.4153
2022-10-01 01:51:07 - train: epoch 0196, iter [00570, 01251], lr: 0.000728, loss: 0.4107
2022-10-01 01:51:25 - train: epoch 0196, iter [00580, 01251], lr: 0.000727, loss: 0.3930
2022-10-01 01:51:42 - train: epoch 0196, iter [00590, 01251], lr: 0.000727, loss: 0.4081
2022-10-01 01:52:00 - train: epoch 0196, iter [00600, 01251], lr: 0.000727, loss: 0.4012
2022-10-01 01:52:18 - train: epoch 0196, iter [00610, 01251], lr: 0.000727, loss: 0.4026
2022-10-01 01:52:35 - train: epoch 0196, iter [00620, 01251], lr: 0.000727, loss: 0.4031
2022-10-01 01:52:53 - train: epoch 0196, iter [00630, 01251], lr: 0.000727, loss: 0.4154
2022-10-01 01:53:11 - train: epoch 0196, iter [00640, 01251], lr: 0.000727, loss: 0.4030
2022-10-01 01:53:29 - train: epoch 0196, iter [00650, 01251], lr: 0.000727, loss: 0.4252
2022-10-01 01:53:46 - train: epoch 0196, iter [00660, 01251], lr: 0.000727, loss: 0.3876
2022-10-01 01:54:04 - train: epoch 0196, iter [00670, 01251], lr: 0.000727, loss: 0.4168
2022-10-01 01:54:22 - train: epoch 0196, iter [00680, 01251], lr: 0.000727, loss: 0.3943
2022-10-01 01:54:40 - train: epoch 0196, iter [00690, 01251], lr: 0.000727, loss: 0.4096
2022-10-01 01:54:57 - train: epoch 0196, iter [00700, 01251], lr: 0.000727, loss: 0.3963
2022-10-01 01:55:15 - train: epoch 0196, iter [00710, 01251], lr: 0.000727, loss: 0.3957
2022-10-01 01:55:33 - train: epoch 0196, iter [00720, 01251], lr: 0.000727, loss: 0.4179
2022-10-01 01:55:51 - train: epoch 0196, iter [00730, 01251], lr: 0.000727, loss: 0.4011
2022-10-01 01:56:08 - train: epoch 0196, iter [00740, 01251], lr: 0.000727, loss: 0.4115
2022-10-01 01:56:26 - train: epoch 0196, iter [00750, 01251], lr: 0.000727, loss: 0.4177
2022-10-01 01:56:44 - train: epoch 0196, iter [00760, 01251], lr: 0.000727, loss: 0.4227
2022-10-01 01:57:02 - train: epoch 0196, iter [00770, 01251], lr: 0.000727, loss: 0.4169
2022-10-01 01:57:19 - train: epoch 0196, iter [00780, 01251], lr: 0.000727, loss: 0.3986
2022-10-01 01:57:37 - train: epoch 0196, iter [00790, 01251], lr: 0.000727, loss: 0.3942
2022-10-01 01:57:55 - train: epoch 0196, iter [00800, 01251], lr: 0.000727, loss: 0.4192
2022-10-01 01:58:12 - train: epoch 0196, iter [00810, 01251], lr: 0.000727, loss: 0.4203
2022-10-01 01:58:30 - train: epoch 0196, iter [00820, 01251], lr: 0.000727, loss: 0.4103
2022-10-01 01:58:48 - train: epoch 0196, iter [00830, 01251], lr: 0.000726, loss: 0.3930
2022-10-01 01:59:06 - train: epoch 0196, iter [00840, 01251], lr: 0.000726, loss: 0.4233
2022-10-01 01:59:23 - train: epoch 0196, iter [00850, 01251], lr: 0.000726, loss: 0.4108
2022-10-01 01:59:41 - train: epoch 0196, iter [00860, 01251], lr: 0.000726, loss: 0.4161
2022-10-01 01:59:59 - train: epoch 0196, iter [00870, 01251], lr: 0.000726, loss: 0.4052
2022-10-01 02:00:16 - train: epoch 0196, iter [00880, 01251], lr: 0.000726, loss: 0.4232
2022-10-01 02:00:34 - train: epoch 0196, iter [00890, 01251], lr: 0.000726, loss: 0.4173
2022-10-01 02:00:52 - train: epoch 0196, iter [00900, 01251], lr: 0.000726, loss: 0.4199
2022-10-01 02:01:10 - train: epoch 0196, iter [00910, 01251], lr: 0.000726, loss: 0.3962
2022-10-01 02:01:27 - train: epoch 0196, iter [00920, 01251], lr: 0.000726, loss: 0.4094
2022-10-01 02:01:45 - train: epoch 0196, iter [00930, 01251], lr: 0.000726, loss: 0.4175
2022-10-01 02:02:03 - train: epoch 0196, iter [00940, 01251], lr: 0.000726, loss: 0.4190
2022-10-01 02:02:20 - train: epoch 0196, iter [00950, 01251], lr: 0.000726, loss: 0.4104
2022-10-01 02:02:38 - train: epoch 0196, iter [00960, 01251], lr: 0.000726, loss: 0.4062
2022-10-01 02:02:56 - train: epoch 0196, iter [00970, 01251], lr: 0.000726, loss: 0.4050
2022-10-01 02:03:13 - train: epoch 0196, iter [00980, 01251], lr: 0.000726, loss: 0.3979
2022-10-01 02:03:31 - train: epoch 0196, iter [00990, 01251], lr: 0.000726, loss: 0.3974
2022-10-01 02:03:49 - train: epoch 0196, iter [01000, 01251], lr: 0.000726, loss: 0.4161
2022-10-01 02:04:06 - train: epoch 0196, iter [01010, 01251], lr: 0.000726, loss: 0.4139
2022-10-01 02:04:24 - train: epoch 0196, iter [01020, 01251], lr: 0.000726, loss: 0.4060
2022-10-01 02:04:42 - train: epoch 0196, iter [01030, 01251], lr: 0.000726, loss: 0.4080
2022-10-01 02:04:59 - train: epoch 0196, iter [01040, 01251], lr: 0.000726, loss: 0.3946
2022-10-01 02:05:17 - train: epoch 0196, iter [01050, 01251], lr: 0.000726, loss: 0.3932
2022-10-01 02:05:35 - train: epoch 0196, iter [01060, 01251], lr: 0.000726, loss: 0.4093
2022-10-01 02:05:53 - train: epoch 0196, iter [01070, 01251], lr: 0.000725, loss: 0.4162
2022-10-01 02:06:10 - train: epoch 0196, iter [01080, 01251], lr: 0.000725, loss: 0.4137
2022-10-01 02:06:28 - train: epoch 0196, iter [01090, 01251], lr: 0.000725, loss: 0.4051
2022-10-01 02:06:46 - train: epoch 0196, iter [01100, 01251], lr: 0.000725, loss: 0.3959
2022-10-01 02:07:03 - train: epoch 0196, iter [01110, 01251], lr: 0.000725, loss: 0.4315
2022-10-01 02:07:21 - train: epoch 0196, iter [01120, 01251], lr: 0.000725, loss: 0.4167
2022-10-01 02:07:39 - train: epoch 0196, iter [01130, 01251], lr: 0.000725, loss: 0.3961
2022-10-01 02:07:57 - train: epoch 0196, iter [01140, 01251], lr: 0.000725, loss: 0.4012
2022-10-01 02:08:14 - train: epoch 0196, iter [01150, 01251], lr: 0.000725, loss: 0.4018
2022-10-01 02:08:32 - train: epoch 0196, iter [01160, 01251], lr: 0.000725, loss: 0.4244
2022-10-01 02:08:50 - train: epoch 0196, iter [01170, 01251], lr: 0.000725, loss: 0.4192
2022-10-01 02:09:07 - train: epoch 0196, iter [01180, 01251], lr: 0.000725, loss: 0.4142
2022-10-01 02:09:25 - train: epoch 0196, iter [01190, 01251], lr: 0.000725, loss: 0.4150
2022-10-01 02:09:43 - train: epoch 0196, iter [01200, 01251], lr: 0.000725, loss: 0.4093
2022-10-01 02:10:01 - train: epoch 0196, iter [01210, 01251], lr: 0.000725, loss: 0.4048
2022-10-01 02:10:19 - train: epoch 0196, iter [01220, 01251], lr: 0.000725, loss: 0.4094
2022-10-01 02:10:36 - train: epoch 0196, iter [01230, 01251], lr: 0.000725, loss: 0.4394
2022-10-01 02:10:54 - train: epoch 0196, iter [01240, 01251], lr: 0.000725, loss: 0.4090
2022-10-01 02:11:11 - train: epoch 0196, iter [01250, 01251], lr: 0.000725, loss: 0.4121
2022-10-01 02:11:15 - train: epoch 196, train_loss: 0.4074
2022-10-01 02:11:17 - until epoch: 196, best_loss: 0.4074
2022-10-01 02:11:17 - epoch 197 lr: 0.000725
2022-10-01 02:11:42 - train: epoch 0197, iter [00010, 01251], lr: 0.000725, loss: 0.3990
2022-10-01 02:12:00 - train: epoch 0197, iter [00020, 01251], lr: 0.000725, loss: 0.4001
2022-10-01 02:12:17 - train: epoch 0197, iter [00030, 01251], lr: 0.000725, loss: 0.3882
2022-10-01 02:12:34 - train: epoch 0197, iter [00040, 01251], lr: 0.000725, loss: 0.4051
2022-10-01 02:12:52 - train: epoch 0197, iter [00050, 01251], lr: 0.000725, loss: 0.3979
2022-10-01 02:13:10 - train: epoch 0197, iter [00060, 01251], lr: 0.000725, loss: 0.4076
2022-10-01 02:13:27 - train: epoch 0197, iter [00070, 01251], lr: 0.000724, loss: 0.4031
2022-10-01 02:13:45 - train: epoch 0197, iter [00080, 01251], lr: 0.000724, loss: 0.3963
2022-10-01 02:14:03 - train: epoch 0197, iter [00090, 01251], lr: 0.000724, loss: 0.4000
2022-10-01 02:14:20 - train: epoch 0197, iter [00100, 01251], lr: 0.000724, loss: 0.4093
2022-10-01 02:14:38 - train: epoch 0197, iter [00110, 01251], lr: 0.000724, loss: 0.3978
2022-10-01 02:14:56 - train: epoch 0197, iter [00120, 01251], lr: 0.000724, loss: 0.4156
2022-10-01 02:15:13 - train: epoch 0197, iter [00130, 01251], lr: 0.000724, loss: 0.4101
2022-10-01 02:15:31 - train: epoch 0197, iter [00140, 01251], lr: 0.000724, loss: 0.4147
2022-10-01 02:15:49 - train: epoch 0197, iter [00150, 01251], lr: 0.000724, loss: 0.4367
2022-10-01 02:16:07 - train: epoch 0197, iter [00160, 01251], lr: 0.000724, loss: 0.4094
2022-10-01 02:16:24 - train: epoch 0197, iter [00170, 01251], lr: 0.000724, loss: 0.4246
2022-10-01 02:16:42 - train: epoch 0197, iter [00180, 01251], lr: 0.000724, loss: 0.4076
2022-10-01 02:17:00 - train: epoch 0197, iter [00190, 01251], lr: 0.000724, loss: 0.4183
2022-10-01 02:17:18 - train: epoch 0197, iter [00200, 01251], lr: 0.000724, loss: 0.3963
2022-10-01 02:17:35 - train: epoch 0197, iter [00210, 01251], lr: 0.000724, loss: 0.4003
2022-10-01 02:17:53 - train: epoch 0197, iter [00220, 01251], lr: 0.000724, loss: 0.4087
2022-10-01 02:18:11 - train: epoch 0197, iter [00230, 01251], lr: 0.000724, loss: 0.4116
2022-10-01 02:18:29 - train: epoch 0197, iter [00240, 01251], lr: 0.000724, loss: 0.4070
2022-10-01 02:18:46 - train: epoch 0197, iter [00250, 01251], lr: 0.000724, loss: 0.3952
2022-10-01 02:19:04 - train: epoch 0197, iter [00260, 01251], lr: 0.000724, loss: 0.4096
2022-10-01 02:19:22 - train: epoch 0197, iter [00270, 01251], lr: 0.000724, loss: 0.3823
2022-10-01 02:19:39 - train: epoch 0197, iter [00280, 01251], lr: 0.000724, loss: 0.3936
2022-10-01 02:19:57 - train: epoch 0197, iter [00290, 01251], lr: 0.000724, loss: 0.4204
2022-10-01 02:20:15 - train: epoch 0197, iter [00300, 01251], lr: 0.000724, loss: 0.4005
2022-10-01 02:20:33 - train: epoch 0197, iter [00310, 01251], lr: 0.000723, loss: 0.3970
2022-10-01 02:20:50 - train: epoch 0197, iter [00320, 01251], lr: 0.000723, loss: 0.4238
2022-10-01 02:21:08 - train: epoch 0197, iter [00330, 01251], lr: 0.000723, loss: 0.4225
2022-10-01 02:21:26 - train: epoch 0197, iter [00340, 01251], lr: 0.000723, loss: 0.4072
2022-10-01 02:21:43 - train: epoch 0197, iter [00350, 01251], lr: 0.000723, loss: 0.4190
2022-10-01 02:22:01 - train: epoch 0197, iter [00360, 01251], lr: 0.000723, loss: 0.4258
2022-10-01 02:22:19 - train: epoch 0197, iter [00370, 01251], lr: 0.000723, loss: 0.3886
2022-10-01 02:22:37 - train: epoch 0197, iter [00380, 01251], lr: 0.000723, loss: 0.4090
2022-10-01 02:22:54 - train: epoch 0197, iter [00390, 01251], lr: 0.000723, loss: 0.4101
2022-10-01 02:23:12 - train: epoch 0197, iter [00400, 01251], lr: 0.000723, loss: 0.4080
2022-10-01 02:23:30 - train: epoch 0197, iter [00410, 01251], lr: 0.000723, loss: 0.4217
2022-10-01 02:23:48 - train: epoch 0197, iter [00420, 01251], lr: 0.000723, loss: 0.3866
2022-10-01 02:24:06 - train: epoch 0197, iter [00430, 01251], lr: 0.000723, loss: 0.4132
2022-10-01 02:24:23 - train: epoch 0197, iter [00440, 01251], lr: 0.000723, loss: 0.3978
2022-10-01 02:24:41 - train: epoch 0197, iter [00450, 01251], lr: 0.000723, loss: 0.3982
2022-10-01 02:24:59 - train: epoch 0197, iter [00460, 01251], lr: 0.000723, loss: 0.4111
2022-10-01 02:25:17 - train: epoch 0197, iter [00470, 01251], lr: 0.000723, loss: 0.4174
2022-10-01 02:25:34 - train: epoch 0197, iter [00480, 01251], lr: 0.000723, loss: 0.3960
2022-10-01 02:25:52 - train: epoch 0197, iter [00490, 01251], lr: 0.000723, loss: 0.4026
2022-10-01 02:26:10 - train: epoch 0197, iter [00500, 01251], lr: 0.000723, loss: 0.4097
2022-10-01 02:26:28 - train: epoch 0197, iter [00510, 01251], lr: 0.000723, loss: 0.4173
2022-10-01 02:26:46 - train: epoch 0197, iter [00520, 01251], lr: 0.000723, loss: 0.3997
2022-10-01 02:27:04 - train: epoch 0197, iter [00530, 01251], lr: 0.000723, loss: 0.4094
2022-10-01 02:27:21 - train: epoch 0197, iter [00540, 01251], lr: 0.000723, loss: 0.4080
2022-10-01 02:27:39 - train: epoch 0197, iter [00550, 01251], lr: 0.000722, loss: 0.4016
2022-10-01 02:27:57 - train: epoch 0197, iter [00560, 01251], lr: 0.000722, loss: 0.4097
2022-10-01 02:28:15 - train: epoch 0197, iter [00570, 01251], lr: 0.000722, loss: 0.4112
2022-10-01 02:28:32 - train: epoch 0197, iter [00580, 01251], lr: 0.000722, loss: 0.4085
2022-10-01 02:28:50 - train: epoch 0197, iter [00590, 01251], lr: 0.000722, loss: 0.3933
2022-10-01 02:29:08 - train: epoch 0197, iter [00600, 01251], lr: 0.000722, loss: 0.3825
2022-10-01 02:29:25 - train: epoch 0197, iter [00610, 01251], lr: 0.000722, loss: 0.4033
2022-10-01 02:29:43 - train: epoch 0197, iter [00620, 01251], lr: 0.000722, loss: 0.4082
2022-10-01 02:30:01 - train: epoch 0197, iter [00630, 01251], lr: 0.000722, loss: 0.4053
2022-10-01 02:30:19 - train: epoch 0197, iter [00640, 01251], lr: 0.000722, loss: 0.4002
2022-10-01 02:30:36 - train: epoch 0197, iter [00650, 01251], lr: 0.000722, loss: 0.3840
2022-10-01 02:30:54 - train: epoch 0197, iter [00660, 01251], lr: 0.000722, loss: 0.4016
2022-10-01 02:31:12 - train: epoch 0197, iter [00670, 01251], lr: 0.000722, loss: 0.4013
2022-10-01 02:31:29 - train: epoch 0197, iter [00680, 01251], lr: 0.000722, loss: 0.3862
2022-10-01 02:31:47 - train: epoch 0197, iter [00690, 01251], lr: 0.000722, loss: 0.4070
2022-10-01 02:32:05 - train: epoch 0197, iter [00700, 01251], lr: 0.000722, loss: 0.4051
2022-10-01 02:32:23 - train: epoch 0197, iter [00710, 01251], lr: 0.000722, loss: 0.4195
2022-10-01 02:32:40 - train: epoch 0197, iter [00720, 01251], lr: 0.000722, loss: 0.3949
2022-10-01 02:32:58 - train: epoch 0197, iter [00730, 01251], lr: 0.000722, loss: 0.4083
2022-10-01 02:33:15 - train: epoch 0197, iter [00740, 01251], lr: 0.000722, loss: 0.4057
2022-10-01 02:33:33 - train: epoch 0197, iter [00750, 01251], lr: 0.000722, loss: 0.4020
2022-10-01 02:33:51 - train: epoch 0197, iter [00760, 01251], lr: 0.000722, loss: 0.3926
2022-10-01 02:34:08 - train: epoch 0197, iter [00770, 01251], lr: 0.000722, loss: 0.3948
2022-10-01 02:34:26 - train: epoch 0197, iter [00780, 01251], lr: 0.000722, loss: 0.4047
2022-10-01 02:34:44 - train: epoch 0197, iter [00790, 01251], lr: 0.000722, loss: 0.4192
2022-10-01 02:35:01 - train: epoch 0197, iter [00800, 01251], lr: 0.000721, loss: 0.3986
2022-10-01 02:35:19 - train: epoch 0197, iter [00810, 01251], lr: 0.000721, loss: 0.3877
2022-10-01 02:35:37 - train: epoch 0197, iter [00820, 01251], lr: 0.000721, loss: 0.4142
2022-10-01 02:35:54 - train: epoch 0197, iter [00830, 01251], lr: 0.000721, loss: 0.3929
2022-10-01 02:36:12 - train: epoch 0197, iter [00840, 01251], lr: 0.000721, loss: 0.4099
2022-10-01 02:36:30 - train: epoch 0197, iter [00850, 01251], lr: 0.000721, loss: 0.4015
2022-10-01 02:36:47 - train: epoch 0197, iter [00860, 01251], lr: 0.000721, loss: 0.3915
2022-10-01 02:37:05 - train: epoch 0197, iter [00870, 01251], lr: 0.000721, loss: 0.4190
2022-10-01 02:37:23 - train: epoch 0197, iter [00880, 01251], lr: 0.000721, loss: 0.3912
2022-10-01 02:37:40 - train: epoch 0197, iter [00890, 01251], lr: 0.000721, loss: 0.4133
2022-10-01 02:37:58 - train: epoch 0197, iter [00900, 01251], lr: 0.000721, loss: 0.4280
2022-10-01 02:38:16 - train: epoch 0197, iter [00910, 01251], lr: 0.000721, loss: 0.3908
2022-10-01 02:38:34 - train: epoch 0197, iter [00920, 01251], lr: 0.000721, loss: 0.3925
2022-10-01 02:38:51 - train: epoch 0197, iter [00930, 01251], lr: 0.000721, loss: 0.3987
2022-10-01 02:39:09 - train: epoch 0197, iter [00940, 01251], lr: 0.000721, loss: 0.4097
2022-10-01 02:39:27 - train: epoch 0197, iter [00950, 01251], lr: 0.000721, loss: 0.4117
2022-10-01 02:39:45 - train: epoch 0197, iter [00960, 01251], lr: 0.000721, loss: 0.4050
2022-10-01 02:40:02 - train: epoch 0197, iter [00970, 01251], lr: 0.000721, loss: 0.3941
2022-10-01 02:40:20 - train: epoch 0197, iter [00980, 01251], lr: 0.000721, loss: 0.4104
2022-10-01 02:40:38 - train: epoch 0197, iter [00990, 01251], lr: 0.000721, loss: 0.4095
2022-10-01 02:40:56 - train: epoch 0197, iter [01000, 01251], lr: 0.000721, loss: 0.4130
2022-10-01 02:41:13 - train: epoch 0197, iter [01010, 01251], lr: 0.000721, loss: 0.3909
2022-10-01 02:41:31 - train: epoch 0197, iter [01020, 01251], lr: 0.000721, loss: 0.4202
2022-10-01 02:41:49 - train: epoch 0197, iter [01030, 01251], lr: 0.000721, loss: 0.3811
2022-10-01 02:42:07 - train: epoch 0197, iter [01040, 01251], lr: 0.000720, loss: 0.3928
2022-10-01 02:42:24 - train: epoch 0197, iter [01050, 01251], lr: 0.000720, loss: 0.4142
2022-10-01 02:42:42 - train: epoch 0197, iter [01060, 01251], lr: 0.000720, loss: 0.4004
2022-10-01 02:43:00 - train: epoch 0197, iter [01070, 01251], lr: 0.000720, loss: 0.3965
2022-10-01 02:43:17 - train: epoch 0197, iter [01080, 01251], lr: 0.000720, loss: 0.4129
2022-10-01 02:43:35 - train: epoch 0197, iter [01090, 01251], lr: 0.000720, loss: 0.4102
2022-10-01 02:43:53 - train: epoch 0197, iter [01100, 01251], lr: 0.000720, loss: 0.3979
2022-10-01 02:44:10 - train: epoch 0197, iter [01110, 01251], lr: 0.000720, loss: 0.4022
2022-10-01 02:44:28 - train: epoch 0197, iter [01120, 01251], lr: 0.000720, loss: 0.4089
2022-10-01 02:44:46 - train: epoch 0197, iter [01130, 01251], lr: 0.000720, loss: 0.4237
2022-10-01 02:45:04 - train: epoch 0197, iter [01140, 01251], lr: 0.000720, loss: 0.3992
2022-10-01 02:45:21 - train: epoch 0197, iter [01150, 01251], lr: 0.000720, loss: 0.3978
2022-10-01 02:45:39 - train: epoch 0197, iter [01160, 01251], lr: 0.000720, loss: 0.3788
2022-10-01 02:45:57 - train: epoch 0197, iter [01170, 01251], lr: 0.000720, loss: 0.3998
2022-10-01 02:46:15 - train: epoch 0197, iter [01180, 01251], lr: 0.000720, loss: 0.4074
2022-10-01 02:46:32 - train: epoch 0197, iter [01190, 01251], lr: 0.000720, loss: 0.3948
2022-10-01 02:46:50 - train: epoch 0197, iter [01200, 01251], lr: 0.000720, loss: 0.3994
2022-10-01 02:47:08 - train: epoch 0197, iter [01210, 01251], lr: 0.000720, loss: 0.3892
2022-10-01 02:47:26 - train: epoch 0197, iter [01220, 01251], lr: 0.000720, loss: 0.4250
2022-10-01 02:47:43 - train: epoch 0197, iter [01230, 01251], lr: 0.000720, loss: 0.4066
2022-10-01 02:48:01 - train: epoch 0197, iter [01240, 01251], lr: 0.000720, loss: 0.4195
2022-10-01 02:48:18 - train: epoch 0197, iter [01250, 01251], lr: 0.000720, loss: 0.4167
2022-10-01 02:48:21 - train: epoch 197, train_loss: 0.4072
2022-10-01 02:48:24 - until epoch: 197, best_loss: 0.4072
2022-10-01 02:48:24 - epoch 198 lr: 0.000720
2022-10-01 02:48:49 - train: epoch 0198, iter [00010, 01251], lr: 0.000720, loss: 0.4149
2022-10-01 02:49:06 - train: epoch 0198, iter [00020, 01251], lr: 0.000720, loss: 0.4172
2022-10-01 02:49:24 - train: epoch 0198, iter [00030, 01251], lr: 0.000719, loss: 0.4229
2022-10-01 02:49:41 - train: epoch 0198, iter [00040, 01251], lr: 0.000719, loss: 0.4066
2022-10-01 02:49:59 - train: epoch 0198, iter [00050, 01251], lr: 0.000719, loss: 0.4031
2022-10-01 02:50:17 - train: epoch 0198, iter [00060, 01251], lr: 0.000719, loss: 0.4101
2022-10-01 02:50:34 - train: epoch 0198, iter [00070, 01251], lr: 0.000719, loss: 0.3913
2022-10-01 02:50:52 - train: epoch 0198, iter [00080, 01251], lr: 0.000719, loss: 0.4233
2022-10-01 02:51:10 - train: epoch 0198, iter [00090, 01251], lr: 0.000719, loss: 0.4284
2022-10-01 02:51:27 - train: epoch 0198, iter [00100, 01251], lr: 0.000719, loss: 0.4136
2022-10-01 02:51:45 - train: epoch 0198, iter [00110, 01251], lr: 0.000719, loss: 0.3871
2022-10-01 02:52:03 - train: epoch 0198, iter [00120, 01251], lr: 0.000719, loss: 0.4144
2022-10-01 02:52:20 - train: epoch 0198, iter [00130, 01251], lr: 0.000719, loss: 0.4255
2022-10-01 02:52:38 - train: epoch 0198, iter [00140, 01251], lr: 0.000719, loss: 0.4058
2022-10-01 02:52:56 - train: epoch 0198, iter [00150, 01251], lr: 0.000719, loss: 0.4325
2022-10-01 02:53:13 - train: epoch 0198, iter [00160, 01251], lr: 0.000719, loss: 0.4070
2022-10-01 02:53:31 - train: epoch 0198, iter [00170, 01251], lr: 0.000719, loss: 0.4149
2022-10-01 02:53:49 - train: epoch 0198, iter [00180, 01251], lr: 0.000719, loss: 0.4139
2022-10-01 02:54:06 - train: epoch 0198, iter [00190, 01251], lr: 0.000719, loss: 0.3945
2022-10-01 02:54:24 - train: epoch 0198, iter [00200, 01251], lr: 0.000719, loss: 0.4045
2022-10-01 02:54:42 - train: epoch 0198, iter [00210, 01251], lr: 0.000719, loss: 0.3978
2022-10-01 02:55:00 - train: epoch 0198, iter [00220, 01251], lr: 0.000719, loss: 0.4191
2022-10-01 02:55:17 - train: epoch 0198, iter [00230, 01251], lr: 0.000719, loss: 0.4315
2022-10-01 02:55:35 - train: epoch 0198, iter [00240, 01251], lr: 0.000719, loss: 0.4085
2022-10-01 02:55:53 - train: epoch 0198, iter [00250, 01251], lr: 0.000719, loss: 0.4101
2022-10-01 02:56:11 - train: epoch 0198, iter [00260, 01251], lr: 0.000719, loss: 0.3897
2022-10-01 02:56:28 - train: epoch 0198, iter [00270, 01251], lr: 0.000719, loss: 0.4098
2022-10-01 02:56:46 - train: epoch 0198, iter [00280, 01251], lr: 0.000718, loss: 0.4115
2022-10-01 02:57:04 - train: epoch 0198, iter [00290, 01251], lr: 0.000718, loss: 0.4116
2022-10-01 02:57:21 - train: epoch 0198, iter [00300, 01251], lr: 0.000718, loss: 0.3977
2022-10-01 02:57:39 - train: epoch 0198, iter [00310, 01251], lr: 0.000718, loss: 0.4077
2022-10-01 02:57:57 - train: epoch 0198, iter [00320, 01251], lr: 0.000718, loss: 0.4044
2022-10-01 02:58:15 - train: epoch 0198, iter [00330, 01251], lr: 0.000718, loss: 0.4200
2022-10-01 02:58:32 - train: epoch 0198, iter [00340, 01251], lr: 0.000718, loss: 0.4124
2022-10-01 02:58:50 - train: epoch 0198, iter [00350, 01251], lr: 0.000718, loss: 0.3988
2022-10-01 02:59:08 - train: epoch 0198, iter [00360, 01251], lr: 0.000718, loss: 0.4105
2022-10-01 02:59:25 - train: epoch 0198, iter [00370, 01251], lr: 0.000718, loss: 0.3975
2022-10-01 02:59:43 - train: epoch 0198, iter [00380, 01251], lr: 0.000718, loss: 0.3978
2022-10-01 03:00:01 - train: epoch 0198, iter [00390, 01251], lr: 0.000718, loss: 0.3921
2022-10-01 03:00:18 - train: epoch 0198, iter [00400, 01251], lr: 0.000718, loss: 0.4309
2022-10-01 03:00:36 - train: epoch 0198, iter [00410, 01251], lr: 0.000718, loss: 0.4172
2022-10-01 03:00:54 - train: epoch 0198, iter [00420, 01251], lr: 0.000718, loss: 0.3943
2022-10-01 03:01:11 - train: epoch 0198, iter [00430, 01251], lr: 0.000718, loss: 0.4046
2022-10-01 03:01:29 - train: epoch 0198, iter [00440, 01251], lr: 0.000718, loss: 0.4166
2022-10-01 03:01:47 - train: epoch 0198, iter [00450, 01251], lr: 0.000718, loss: 0.4122
2022-10-01 03:02:04 - train: epoch 0198, iter [00460, 01251], lr: 0.000718, loss: 0.4015
2022-10-01 03:02:22 - train: epoch 0198, iter [00470, 01251], lr: 0.000718, loss: 0.4098
2022-10-01 03:02:40 - train: epoch 0198, iter [00480, 01251], lr: 0.000718, loss: 0.3981
2022-10-01 03:02:57 - train: epoch 0198, iter [00490, 01251], lr: 0.000718, loss: 0.4246
2022-10-01 03:03:15 - train: epoch 0198, iter [00500, 01251], lr: 0.000718, loss: 0.4014
2022-10-01 03:03:32 - train: epoch 0198, iter [00510, 01251], lr: 0.000718, loss: 0.3895
2022-10-01 03:03:50 - train: epoch 0198, iter [00520, 01251], lr: 0.000717, loss: 0.4097
2022-10-01 03:04:08 - train: epoch 0198, iter [00530, 01251], lr: 0.000717, loss: 0.4090
2022-10-01 03:04:26 - train: epoch 0198, iter [00540, 01251], lr: 0.000717, loss: 0.4094
2022-10-01 03:04:43 - train: epoch 0198, iter [00550, 01251], lr: 0.000717, loss: 0.4126
2022-10-01 03:05:01 - train: epoch 0198, iter [00560, 01251], lr: 0.000717, loss: 0.4058
2022-10-01 03:05:19 - train: epoch 0198, iter [00570, 01251], lr: 0.000717, loss: 0.4168
2022-10-01 03:05:36 - train: epoch 0198, iter [00580, 01251], lr: 0.000717, loss: 0.4197
2022-10-01 03:05:54 - train: epoch 0198, iter [00590, 01251], lr: 0.000717, loss: 0.3824
2022-10-01 03:06:12 - train: epoch 0198, iter [00600, 01251], lr: 0.000717, loss: 0.4154
2022-10-01 03:06:29 - train: epoch 0198, iter [00610, 01251], lr: 0.000717, loss: 0.4140
2022-10-01 03:06:47 - train: epoch 0198, iter [00620, 01251], lr: 0.000717, loss: 0.4182
2022-10-01 03:07:04 - train: epoch 0198, iter [00630, 01251], lr: 0.000717, loss: 0.4067
2022-10-01 03:07:22 - train: epoch 0198, iter [00640, 01251], lr: 0.000717, loss: 0.4214
2022-10-01 03:07:40 - train: epoch 0198, iter [00650, 01251], lr: 0.000717, loss: 0.3984
2022-10-01 03:07:58 - train: epoch 0198, iter [00660, 01251], lr: 0.000717, loss: 0.4025
2022-10-01 03:08:15 - train: epoch 0198, iter [00670, 01251], lr: 0.000717, loss: 0.4261
2022-10-01 03:08:33 - train: epoch 0198, iter [00680, 01251], lr: 0.000717, loss: 0.3918
2022-10-01 03:08:50 - train: epoch 0198, iter [00690, 01251], lr: 0.000717, loss: 0.4156
2022-10-01 03:09:08 - train: epoch 0198, iter [00700, 01251], lr: 0.000717, loss: 0.3939
2022-10-01 03:09:26 - train: epoch 0198, iter [00710, 01251], lr: 0.000717, loss: 0.4020
2022-10-01 03:09:43 - train: epoch 0198, iter [00720, 01251], lr: 0.000717, loss: 0.3882
2022-10-01 03:10:01 - train: epoch 0198, iter [00730, 01251], lr: 0.000717, loss: 0.3730
2022-10-01 03:10:19 - train: epoch 0198, iter [00740, 01251], lr: 0.000717, loss: 0.3929
2022-10-01 03:10:36 - train: epoch 0198, iter [00750, 01251], lr: 0.000717, loss: 0.3965
2022-10-01 03:10:54 - train: epoch 0198, iter [00760, 01251], lr: 0.000717, loss: 0.4153
2022-10-01 03:11:12 - train: epoch 0198, iter [00770, 01251], lr: 0.000716, loss: 0.4082
2022-10-01 03:11:29 - train: epoch 0198, iter [00780, 01251], lr: 0.000716, loss: 0.4172
2022-10-01 03:11:47 - train: epoch 0198, iter [00790, 01251], lr: 0.000716, loss: 0.4369
2022-10-01 03:12:04 - train: epoch 0198, iter [00800, 01251], lr: 0.000716, loss: 0.4118
2022-10-01 03:12:22 - train: epoch 0198, iter [00810, 01251], lr: 0.000716, loss: 0.4029
2022-10-01 03:12:40 - train: epoch 0198, iter [00820, 01251], lr: 0.000716, loss: 0.3924
2022-10-01 03:12:58 - train: epoch 0198, iter [00830, 01251], lr: 0.000716, loss: 0.4206
2022-10-01 03:13:15 - train: epoch 0198, iter [00840, 01251], lr: 0.000716, loss: 0.4163
2022-10-01 03:13:33 - train: epoch 0198, iter [00850, 01251], lr: 0.000716, loss: 0.3912
2022-10-01 03:13:51 - train: epoch 0198, iter [00860, 01251], lr: 0.000716, loss: 0.4225
2022-10-01 03:14:08 - train: epoch 0198, iter [00870, 01251], lr: 0.000716, loss: 0.3887
2022-10-01 03:14:26 - train: epoch 0198, iter [00880, 01251], lr: 0.000716, loss: 0.4199
2022-10-01 03:14:44 - train: epoch 0198, iter [00890, 01251], lr: 0.000716, loss: 0.4101
2022-10-01 03:15:02 - train: epoch 0198, iter [00900, 01251], lr: 0.000716, loss: 0.3781
2022-10-01 03:15:19 - train: epoch 0198, iter [00910, 01251], lr: 0.000716, loss: 0.4001
2022-10-01 03:15:37 - train: epoch 0198, iter [00920, 01251], lr: 0.000716, loss: 0.4029
2022-10-01 03:15:55 - train: epoch 0198, iter [00930, 01251], lr: 0.000716, loss: 0.4069
2022-10-01 03:16:12 - train: epoch 0198, iter [00940, 01251], lr: 0.000716, loss: 0.4116
2022-10-01 03:16:30 - train: epoch 0198, iter [00950, 01251], lr: 0.000716, loss: 0.4164
2022-10-01 03:16:48 - train: epoch 0198, iter [00960, 01251], lr: 0.000716, loss: 0.4208
2022-10-01 03:17:06 - train: epoch 0198, iter [00970, 01251], lr: 0.000716, loss: 0.4007
2022-10-01 03:17:23 - train: epoch 0198, iter [00980, 01251], lr: 0.000716, loss: 0.3992
2022-10-01 03:17:41 - train: epoch 0198, iter [00990, 01251], lr: 0.000716, loss: 0.4150
2022-10-01 03:17:59 - train: epoch 0198, iter [01000, 01251], lr: 0.000716, loss: 0.4212
2022-10-01 03:18:16 - train: epoch 0198, iter [01010, 01251], lr: 0.000715, loss: 0.3880
2022-10-01 03:18:34 - train: epoch 0198, iter [01020, 01251], lr: 0.000715, loss: 0.3979
2022-10-01 03:18:52 - train: epoch 0198, iter [01030, 01251], lr: 0.000715, loss: 0.4069
2022-10-01 03:19:09 - train: epoch 0198, iter [01040, 01251], lr: 0.000715, loss: 0.4013
2022-10-01 03:19:27 - train: epoch 0198, iter [01050, 01251], lr: 0.000715, loss: 0.4119
2022-10-01 03:19:45 - train: epoch 0198, iter [01060, 01251], lr: 0.000715, loss: 0.3782
2022-10-01 03:20:02 - train: epoch 0198, iter [01070, 01251], lr: 0.000715, loss: 0.4168
2022-10-01 03:20:20 - train: epoch 0198, iter [01080, 01251], lr: 0.000715, loss: 0.4132
2022-10-01 03:20:38 - train: epoch 0198, iter [01090, 01251], lr: 0.000715, loss: 0.4025
2022-10-01 03:20:56 - train: epoch 0198, iter [01100, 01251], lr: 0.000715, loss: 0.4174
2022-10-01 03:21:13 - train: epoch 0198, iter [01110, 01251], lr: 0.000715, loss: 0.4273
2022-10-01 03:21:31 - train: epoch 0198, iter [01120, 01251], lr: 0.000715, loss: 0.4122
2022-10-01 03:21:49 - train: epoch 0198, iter [01130, 01251], lr: 0.000715, loss: 0.3913
2022-10-01 03:22:06 - train: epoch 0198, iter [01140, 01251], lr: 0.000715, loss: 0.4116
2022-10-01 03:22:24 - train: epoch 0198, iter [01150, 01251], lr: 0.000715, loss: 0.3980
2022-10-01 03:22:42 - train: epoch 0198, iter [01160, 01251], lr: 0.000715, loss: 0.4117
2022-10-01 03:22:59 - train: epoch 0198, iter [01170, 01251], lr: 0.000715, loss: 0.3995
2022-10-01 03:23:17 - train: epoch 0198, iter [01180, 01251], lr: 0.000715, loss: 0.3870
2022-10-01 03:23:35 - train: epoch 0198, iter [01190, 01251], lr: 0.000715, loss: 0.3985
2022-10-01 03:23:53 - train: epoch 0198, iter [01200, 01251], lr: 0.000715, loss: 0.3959
2022-10-01 03:24:10 - train: epoch 0198, iter [01210, 01251], lr: 0.000715, loss: 0.3881
2022-10-01 03:24:28 - train: epoch 0198, iter [01220, 01251], lr: 0.000715, loss: 0.4126
2022-10-01 03:24:45 - train: epoch 0198, iter [01230, 01251], lr: 0.000715, loss: 0.3912
2022-10-01 03:25:03 - train: epoch 0198, iter [01240, 01251], lr: 0.000715, loss: 0.4069
2022-10-01 03:25:21 - train: epoch 0198, iter [01250, 01251], lr: 0.000714, loss: 0.4239
2022-10-01 03:25:24 - train: epoch 198, train_loss: 0.4072
2022-10-01 03:25:27 - until epoch: 198, best_loss: 0.4072
2022-10-01 03:25:27 - epoch 199 lr: 0.000714
2022-10-01 03:25:52 - train: epoch 0199, iter [00010, 01251], lr: 0.000714, loss: 0.4146
2022-10-01 03:26:10 - train: epoch 0199, iter [00020, 01251], lr: 0.000714, loss: 0.4074
2022-10-01 03:26:27 - train: epoch 0199, iter [00030, 01251], lr: 0.000714, loss: 0.4157
2022-10-01 03:26:45 - train: epoch 0199, iter [00040, 01251], lr: 0.000714, loss: 0.4086
2022-10-01 03:27:02 - train: epoch 0199, iter [00050, 01251], lr: 0.000714, loss: 0.4120
2022-10-01 03:27:20 - train: epoch 0199, iter [00060, 01251], lr: 0.000714, loss: 0.4006
2022-10-01 03:27:37 - train: epoch 0199, iter [00070, 01251], lr: 0.000714, loss: 0.4156
2022-10-01 03:27:55 - train: epoch 0199, iter [00080, 01251], lr: 0.000714, loss: 0.4001
2022-10-01 03:28:13 - train: epoch 0199, iter [00090, 01251], lr: 0.000714, loss: 0.4153
2022-10-01 03:28:30 - train: epoch 0199, iter [00100, 01251], lr: 0.000714, loss: 0.4215
2022-10-01 03:28:48 - train: epoch 0199, iter [00110, 01251], lr: 0.000714, loss: 0.4090
2022-10-01 03:29:06 - train: epoch 0199, iter [00120, 01251], lr: 0.000714, loss: 0.4094
2022-10-01 03:29:23 - train: epoch 0199, iter [00130, 01251], lr: 0.000714, loss: 0.4114
2022-10-01 03:29:41 - train: epoch 0199, iter [00140, 01251], lr: 0.000714, loss: 0.3932
2022-10-01 03:29:59 - train: epoch 0199, iter [00150, 01251], lr: 0.000714, loss: 0.4116
2022-10-01 03:30:16 - train: epoch 0199, iter [00160, 01251], lr: 0.000714, loss: 0.4046
2022-10-01 03:30:34 - train: epoch 0199, iter [00170, 01251], lr: 0.000714, loss: 0.4064
2022-10-01 03:30:52 - train: epoch 0199, iter [00180, 01251], lr: 0.000714, loss: 0.4071
2022-10-01 03:31:09 - train: epoch 0199, iter [00190, 01251], lr: 0.000714, loss: 0.4050
2022-10-01 03:31:27 - train: epoch 0199, iter [00200, 01251], lr: 0.000714, loss: 0.4345
2022-10-01 03:31:45 - train: epoch 0199, iter [00210, 01251], lr: 0.000714, loss: 0.3966
2022-10-01 03:32:02 - train: epoch 0199, iter [00220, 01251], lr: 0.000714, loss: 0.3894
2022-10-01 03:32:20 - train: epoch 0199, iter [00230, 01251], lr: 0.000714, loss: 0.4193
2022-10-01 03:32:38 - train: epoch 0199, iter [00240, 01251], lr: 0.000713, loss: 0.4058
2022-10-01 03:32:55 - train: epoch 0199, iter [00250, 01251], lr: 0.000713, loss: 0.4070
2022-10-01 03:33:13 - train: epoch 0199, iter [00260, 01251], lr: 0.000713, loss: 0.4108
2022-10-01 03:33:31 - train: epoch 0199, iter [00270, 01251], lr: 0.000713, loss: 0.4073
2022-10-01 03:33:48 - train: epoch 0199, iter [00280, 01251], lr: 0.000713, loss: 0.4227
2022-10-01 03:34:06 - train: epoch 0199, iter [00290, 01251], lr: 0.000713, loss: 0.4333
2022-10-01 03:34:24 - train: epoch 0199, iter [00300, 01251], lr: 0.000713, loss: 0.4044
2022-10-01 03:34:41 - train: epoch 0199, iter [00310, 01251], lr: 0.000713, loss: 0.4109
2022-10-01 03:34:59 - train: epoch 0199, iter [00320, 01251], lr: 0.000713, loss: 0.4211
2022-10-01 03:35:16 - train: epoch 0199, iter [00330, 01251], lr: 0.000713, loss: 0.4109
2022-10-01 03:35:34 - train: epoch 0199, iter [00340, 01251], lr: 0.000713, loss: 0.4170
2022-10-01 03:35:52 - train: epoch 0199, iter [00350, 01251], lr: 0.000713, loss: 0.3988
2022-10-01 03:36:10 - train: epoch 0199, iter [00360, 01251], lr: 0.000713, loss: 0.3912
2022-10-01 03:36:27 - train: epoch 0199, iter [00370, 01251], lr: 0.000713, loss: 0.3926
2022-10-01 03:36:45 - train: epoch 0199, iter [00380, 01251], lr: 0.000713, loss: 0.4411
2022-10-01 03:37:03 - train: epoch 0199, iter [00390, 01251], lr: 0.000713, loss: 0.3943
2022-10-01 03:37:20 - train: epoch 0199, iter [00400, 01251], lr: 0.000713, loss: 0.3940
2022-10-01 03:37:38 - train: epoch 0199, iter [00410, 01251], lr: 0.000713, loss: 0.4069
2022-10-01 03:37:56 - train: epoch 0199, iter [00420, 01251], lr: 0.000713, loss: 0.3932
2022-10-01 03:38:14 - train: epoch 0199, iter [00430, 01251], lr: 0.000713, loss: 0.4058
2022-10-01 03:38:31 - train: epoch 0199, iter [00440, 01251], lr: 0.000713, loss: 0.3964
2022-10-01 03:38:49 - train: epoch 0199, iter [00450, 01251], lr: 0.000713, loss: 0.4113
2022-10-01 03:39:06 - train: epoch 0199, iter [00460, 01251], lr: 0.000713, loss: 0.4149
2022-10-01 03:39:24 - train: epoch 0199, iter [00470, 01251], lr: 0.000713, loss: 0.4178
2022-10-01 03:39:42 - train: epoch 0199, iter [00480, 01251], lr: 0.000713, loss: 0.4187
2022-10-01 03:39:59 - train: epoch 0199, iter [00490, 01251], lr: 0.000712, loss: 0.3955
2022-10-01 03:40:17 - train: epoch 0199, iter [00500, 01251], lr: 0.000712, loss: 0.3994
2022-10-01 03:40:35 - train: epoch 0199, iter [00510, 01251], lr: 0.000712, loss: 0.4238
2022-10-01 03:40:53 - train: epoch 0199, iter [00520, 01251], lr: 0.000712, loss: 0.3848
2022-10-01 03:41:10 - train: epoch 0199, iter [00530, 01251], lr: 0.000712, loss: 0.3943
2022-10-01 03:41:28 - train: epoch 0199, iter [00540, 01251], lr: 0.000712, loss: 0.4216
2022-10-01 03:41:46 - train: epoch 0199, iter [00550, 01251], lr: 0.000712, loss: 0.4094
2022-10-01 03:42:03 - train: epoch 0199, iter [00560, 01251], lr: 0.000712, loss: 0.4029
2022-10-01 03:42:21 - train: epoch 0199, iter [00570, 01251], lr: 0.000712, loss: 0.4055
2022-10-01 03:42:39 - train: epoch 0199, iter [00580, 01251], lr: 0.000712, loss: 0.4135
2022-10-01 03:42:56 - train: epoch 0199, iter [00590, 01251], lr: 0.000712, loss: 0.4077
2022-10-01 03:43:14 - train: epoch 0199, iter [00600, 01251], lr: 0.000712, loss: 0.4026
2022-10-01 03:43:32 - train: epoch 0199, iter [00610, 01251], lr: 0.000712, loss: 0.4021
2022-10-01 03:43:49 - train: epoch 0199, iter [00620, 01251], lr: 0.000712, loss: 0.4066
2022-10-01 03:44:07 - train: epoch 0199, iter [00630, 01251], lr: 0.000712, loss: 0.4039
2022-10-01 03:44:25 - train: epoch 0199, iter [00640, 01251], lr: 0.000712, loss: 0.3922
2022-10-01 03:44:42 - train: epoch 0199, iter [00650, 01251], lr: 0.000712, loss: 0.4192
2022-10-01 03:45:00 - train: epoch 0199, iter [00660, 01251], lr: 0.000712, loss: 0.4086
2022-10-01 03:45:18 - train: epoch 0199, iter [00670, 01251], lr: 0.000712, loss: 0.4037
2022-10-01 03:45:35 - train: epoch 0199, iter [00680, 01251], lr: 0.000712, loss: 0.4249
2022-10-01 03:45:53 - train: epoch 0199, iter [00690, 01251], lr: 0.000712, loss: 0.4166
2022-10-01 03:46:11 - train: epoch 0199, iter [00700, 01251], lr: 0.000712, loss: 0.3868
2022-10-01 03:46:29 - train: epoch 0199, iter [00710, 01251], lr: 0.000712, loss: 0.4012
2022-10-01 03:46:47 - train: epoch 0199, iter [00720, 01251], lr: 0.000712, loss: 0.4020
2022-10-01 03:47:04 - train: epoch 0199, iter [00730, 01251], lr: 0.000711, loss: 0.4038
2022-10-01 03:47:22 - train: epoch 0199, iter [00740, 01251], lr: 0.000711, loss: 0.3916
2022-10-01 03:47:40 - train: epoch 0199, iter [00750, 01251], lr: 0.000711, loss: 0.4001
2022-10-01 03:47:57 - train: epoch 0199, iter [00760, 01251], lr: 0.000711, loss: 0.4095
2022-10-01 03:48:15 - train: epoch 0199, iter [00770, 01251], lr: 0.000711, loss: 0.3884
2022-10-01 03:48:33 - train: epoch 0199, iter [00780, 01251], lr: 0.000711, loss: 0.4095
2022-10-01 03:48:50 - train: epoch 0199, iter [00790, 01251], lr: 0.000711, loss: 0.3959
2022-10-01 03:49:08 - train: epoch 0199, iter [00800, 01251], lr: 0.000711, loss: 0.4178
2022-10-01 03:49:26 - train: epoch 0199, iter [00810, 01251], lr: 0.000711, loss: 0.4130
2022-10-01 03:49:44 - train: epoch 0199, iter [00820, 01251], lr: 0.000711, loss: 0.4221
2022-10-01 03:50:01 - train: epoch 0199, iter [00830, 01251], lr: 0.000711, loss: 0.3940
2022-10-01 03:50:19 - train: epoch 0199, iter [00840, 01251], lr: 0.000711, loss: 0.4039
2022-10-01 03:50:37 - train: epoch 0199, iter [00850, 01251], lr: 0.000711, loss: 0.4074
2022-10-01 03:50:54 - train: epoch 0199, iter [00860, 01251], lr: 0.000711, loss: 0.3794
2022-10-01 03:51:12 - train: epoch 0199, iter [00870, 01251], lr: 0.000711, loss: 0.4043
2022-10-01 03:51:30 - train: epoch 0199, iter [00880, 01251], lr: 0.000711, loss: 0.4047
2022-10-01 03:51:47 - train: epoch 0199, iter [00890, 01251], lr: 0.000711, loss: 0.4175
2022-10-01 03:52:05 - train: epoch 0199, iter [00900, 01251], lr: 0.000711, loss: 0.4149
2022-10-01 03:52:23 - train: epoch 0199, iter [00910, 01251], lr: 0.000711, loss: 0.4156
2022-10-01 03:52:40 - train: epoch 0199, iter [00920, 01251], lr: 0.000711, loss: 0.3914
2022-10-01 03:52:58 - train: epoch 0199, iter [00930, 01251], lr: 0.000711, loss: 0.4180
2022-10-01 03:53:16 - train: epoch 0199, iter [00940, 01251], lr: 0.000711, loss: 0.4219
2022-10-01 03:53:33 - train: epoch 0199, iter [00950, 01251], lr: 0.000711, loss: 0.3953
2022-10-01 03:53:51 - train: epoch 0199, iter [00960, 01251], lr: 0.000711, loss: 0.3893
2022-10-01 03:54:09 - train: epoch 0199, iter [00970, 01251], lr: 0.000710, loss: 0.4119
2022-10-01 03:54:27 - train: epoch 0199, iter [00980, 01251], lr: 0.000710, loss: 0.4043
2022-10-01 03:54:45 - train: epoch 0199, iter [00990, 01251], lr: 0.000710, loss: 0.4119
2022-10-01 03:55:02 - train: epoch 0199, iter [01000, 01251], lr: 0.000710, loss: 0.3919
2022-10-01 03:55:20 - train: epoch 0199, iter [01010, 01251], lr: 0.000710, loss: 0.4119
2022-10-01 03:55:38 - train: epoch 0199, iter [01020, 01251], lr: 0.000710, loss: 0.4037
2022-10-01 03:55:55 - train: epoch 0199, iter [01030, 01251], lr: 0.000710, loss: 0.4152
2022-10-01 03:56:13 - train: epoch 0199, iter [01040, 01251], lr: 0.000710, loss: 0.4117
2022-10-01 03:56:31 - train: epoch 0199, iter [01050, 01251], lr: 0.000710, loss: 0.4116
2022-10-01 03:56:48 - train: epoch 0199, iter [01060, 01251], lr: 0.000710, loss: 0.4216
2022-10-01 03:57:06 - train: epoch 0199, iter [01070, 01251], lr: 0.000710, loss: 0.4017
2022-10-01 03:57:24 - train: epoch 0199, iter [01080, 01251], lr: 0.000710, loss: 0.3785
2022-10-01 03:57:42 - train: epoch 0199, iter [01090, 01251], lr: 0.000710, loss: 0.4011
2022-10-01 03:57:59 - train: epoch 0199, iter [01100, 01251], lr: 0.000710, loss: 0.4326
2022-10-01 03:58:17 - train: epoch 0199, iter [01110, 01251], lr: 0.000710, loss: 0.4159
2022-10-01 03:58:35 - train: epoch 0199, iter [01120, 01251], lr: 0.000710, loss: 0.3974
2022-10-01 03:58:52 - train: epoch 0199, iter [01130, 01251], lr: 0.000710, loss: 0.4447
2022-10-01 03:59:10 - train: epoch 0199, iter [01140, 01251], lr: 0.000710, loss: 0.4019
2022-10-01 03:59:28 - train: epoch 0199, iter [01150, 01251], lr: 0.000710, loss: 0.4137
2022-10-01 03:59:45 - train: epoch 0199, iter [01160, 01251], lr: 0.000710, loss: 0.3917
2022-10-01 04:00:03 - train: epoch 0199, iter [01170, 01251], lr: 0.000710, loss: 0.4060
2022-10-01 04:00:21 - train: epoch 0199, iter [01180, 01251], lr: 0.000710, loss: 0.4072
2022-10-01 04:00:39 - train: epoch 0199, iter [01190, 01251], lr: 0.000710, loss: 0.3935
2022-10-01 04:00:56 - train: epoch 0199, iter [01200, 01251], lr: 0.000710, loss: 0.4035
2022-10-01 04:01:14 - train: epoch 0199, iter [01210, 01251], lr: 0.000710, loss: 0.4208
2022-10-01 04:01:32 - train: epoch 0199, iter [01220, 01251], lr: 0.000709, loss: 0.4055
2022-10-01 04:01:49 - train: epoch 0199, iter [01230, 01251], lr: 0.000709, loss: 0.4004
2022-10-01 04:02:07 - train: epoch 0199, iter [01240, 01251], lr: 0.000709, loss: 0.3957
2022-10-01 04:02:24 - train: epoch 0199, iter [01250, 01251], lr: 0.000709, loss: 0.4158
2022-10-01 04:02:28 - train: epoch 199, train_loss: 0.4071
2022-10-01 04:02:30 - until epoch: 199, best_loss: 0.4071
2022-10-01 04:02:30 - epoch 200 lr: 0.000709
2022-10-01 04:02:55 - train: epoch 0200, iter [00010, 01251], lr: 0.000709, loss: 0.4256
2022-10-01 04:03:12 - train: epoch 0200, iter [00020, 01251], lr: 0.000709, loss: 0.4141
2022-10-01 04:03:30 - train: epoch 0200, iter [00030, 01251], lr: 0.000709, loss: 0.4244
2022-10-01 04:03:48 - train: epoch 0200, iter [00040, 01251], lr: 0.000709, loss: 0.4027
2022-10-01 04:04:05 - train: epoch 0200, iter [00050, 01251], lr: 0.000709, loss: 0.3869
2022-10-01 04:04:23 - train: epoch 0200, iter [00060, 01251], lr: 0.000709, loss: 0.4187
2022-10-01 04:04:41 - train: epoch 0200, iter [00070, 01251], lr: 0.000709, loss: 0.3947
2022-10-01 04:04:58 - train: epoch 0200, iter [00080, 01251], lr: 0.000709, loss: 0.4047
2022-10-01 04:05:16 - train: epoch 0200, iter [00090, 01251], lr: 0.000709, loss: 0.3945
2022-10-01 04:05:34 - train: epoch 0200, iter [00100, 01251], lr: 0.000709, loss: 0.4246
2022-10-01 04:05:52 - train: epoch 0200, iter [00110, 01251], lr: 0.000709, loss: 0.4019
2022-10-01 04:06:09 - train: epoch 0200, iter [00120, 01251], lr: 0.000709, loss: 0.4196
2022-10-01 04:06:27 - train: epoch 0200, iter [00130, 01251], lr: 0.000709, loss: 0.4197
2022-10-01 04:06:44 - train: epoch 0200, iter [00140, 01251], lr: 0.000709, loss: 0.4041
2022-10-01 04:07:02 - train: epoch 0200, iter [00150, 01251], lr: 0.000709, loss: 0.4237
2022-10-01 04:07:20 - train: epoch 0200, iter [00160, 01251], lr: 0.000709, loss: 0.3977
2022-10-01 04:07:37 - train: epoch 0200, iter [00170, 01251], lr: 0.000709, loss: 0.4051
2022-10-01 04:07:55 - train: epoch 0200, iter [00180, 01251], lr: 0.000709, loss: 0.4111
2022-10-01 04:08:13 - train: epoch 0200, iter [00190, 01251], lr: 0.000709, loss: 0.4330
2022-10-01 04:08:30 - train: epoch 0200, iter [00200, 01251], lr: 0.000709, loss: 0.3983
2022-10-01 04:08:48 - train: epoch 0200, iter [00210, 01251], lr: 0.000708, loss: 0.3983
2022-10-01 04:09:06 - train: epoch 0200, iter [00220, 01251], lr: 0.000708, loss: 0.4000
2022-10-01 04:09:24 - train: epoch 0200, iter [00230, 01251], lr: 0.000708, loss: 0.4153
2022-10-01 04:09:41 - train: epoch 0200, iter [00240, 01251], lr: 0.000708, loss: 0.4114
2022-10-01 04:09:59 - train: epoch 0200, iter [00250, 01251], lr: 0.000708, loss: 0.4169
2022-10-01 04:10:17 - train: epoch 0200, iter [00260, 01251], lr: 0.000708, loss: 0.4235
2022-10-01 04:10:34 - train: epoch 0200, iter [00270, 01251], lr: 0.000708, loss: 0.4131
2022-10-01 04:10:52 - train: epoch 0200, iter [00280, 01251], lr: 0.000708, loss: 0.3954
2022-10-01 04:11:09 - train: epoch 0200, iter [00290, 01251], lr: 0.000708, loss: 0.4202
2022-10-01 04:11:27 - train: epoch 0200, iter [00300, 01251], lr: 0.000708, loss: 0.4000
2022-10-01 04:11:45 - train: epoch 0200, iter [00310, 01251], lr: 0.000708, loss: 0.4160
2022-10-01 04:12:03 - train: epoch 0200, iter [00320, 01251], lr: 0.000708, loss: 0.4079
2022-10-01 04:12:20 - train: epoch 0200, iter [00330, 01251], lr: 0.000708, loss: 0.4120
2022-10-01 04:12:38 - train: epoch 0200, iter [00340, 01251], lr: 0.000708, loss: 0.4035
2022-10-01 04:12:56 - train: epoch 0200, iter [00350, 01251], lr: 0.000708, loss: 0.3958
2022-10-01 04:13:13 - train: epoch 0200, iter [00360, 01251], lr: 0.000708, loss: 0.4213
2022-10-01 04:13:31 - train: epoch 0200, iter [00370, 01251], lr: 0.000708, loss: 0.3788
2022-10-01 04:13:49 - train: epoch 0200, iter [00380, 01251], lr: 0.000708, loss: 0.4041
2022-10-01 04:14:06 - train: epoch 0200, iter [00390, 01251], lr: 0.000708, loss: 0.3991
2022-10-01 04:14:24 - train: epoch 0200, iter [00400, 01251], lr: 0.000708, loss: 0.3961
2022-10-01 04:14:42 - train: epoch 0200, iter [00410, 01251], lr: 0.000708, loss: 0.4094
2022-10-01 04:14:59 - train: epoch 0200, iter [00420, 01251], lr: 0.000708, loss: 0.3968
2022-10-01 04:15:17 - train: epoch 0200, iter [00430, 01251], lr: 0.000708, loss: 0.4247
2022-10-01 04:15:35 - train: epoch 0200, iter [00440, 01251], lr: 0.000708, loss: 0.4132
2022-10-01 04:15:53 - train: epoch 0200, iter [00450, 01251], lr: 0.000707, loss: 0.4001
2022-10-01 04:16:11 - train: epoch 0200, iter [00460, 01251], lr: 0.000707, loss: 0.4167
2022-10-01 04:16:28 - train: epoch 0200, iter [00470, 01251], lr: 0.000707, loss: 0.4260
2022-10-01 04:16:46 - train: epoch 0200, iter [00480, 01251], lr: 0.000707, loss: 0.4107
2022-10-01 04:17:04 - train: epoch 0200, iter [00490, 01251], lr: 0.000707, loss: 0.4028
2022-10-01 04:17:22 - train: epoch 0200, iter [00500, 01251], lr: 0.000707, loss: 0.4034
2022-10-01 04:17:40 - train: epoch 0200, iter [00510, 01251], lr: 0.000707, loss: 0.3914
2022-10-01 04:17:58 - train: epoch 0200, iter [00520, 01251], lr: 0.000707, loss: 0.4011
2022-10-01 04:18:15 - train: epoch 0200, iter [00530, 01251], lr: 0.000707, loss: 0.3991
2022-10-01 04:18:33 - train: epoch 0200, iter [00540, 01251], lr: 0.000707, loss: 0.4102
2022-10-01 04:18:51 - train: epoch 0200, iter [00550, 01251], lr: 0.000707, loss: 0.4167
2022-10-01 04:19:09 - train: epoch 0200, iter [00560, 01251], lr: 0.000707, loss: 0.4237
2022-10-01 04:19:27 - train: epoch 0200, iter [00570, 01251], lr: 0.000707, loss: 0.4114
2022-10-01 04:19:45 - train: epoch 0200, iter [00580, 01251], lr: 0.000707, loss: 0.4053
2022-10-01 04:20:03 - train: epoch 0200, iter [00590, 01251], lr: 0.000707, loss: 0.3950
2022-10-01 04:20:20 - train: epoch 0200, iter [00600, 01251], lr: 0.000707, loss: 0.4067
2022-10-01 04:20:38 - train: epoch 0200, iter [00610, 01251], lr: 0.000707, loss: 0.4111
2022-10-01 04:20:56 - train: epoch 0200, iter [00620, 01251], lr: 0.000707, loss: 0.4127
2022-10-01 04:21:14 - train: epoch 0200, iter [00630, 01251], lr: 0.000707, loss: 0.3942
2022-10-01 04:21:32 - train: epoch 0200, iter [00640, 01251], lr: 0.000707, loss: 0.4210
2022-10-01 04:21:50 - train: epoch 0200, iter [00650, 01251], lr: 0.000707, loss: 0.4238
2022-10-01 04:22:08 - train: epoch 0200, iter [00660, 01251], lr: 0.000707, loss: 0.4131
2022-10-01 04:22:26 - train: epoch 0200, iter [00670, 01251], lr: 0.000707, loss: 0.4083
2022-10-01 04:22:43 - train: epoch 0200, iter [00680, 01251], lr: 0.000707, loss: 0.3921
2022-10-01 04:23:01 - train: epoch 0200, iter [00690, 01251], lr: 0.000707, loss: 0.4049
2022-10-01 04:23:19 - train: epoch 0200, iter [00700, 01251], lr: 0.000706, loss: 0.4091
2022-10-01 04:23:37 - train: epoch 0200, iter [00710, 01251], lr: 0.000706, loss: 0.3960
2022-10-01 04:23:55 - train: epoch 0200, iter [00720, 01251], lr: 0.000706, loss: 0.4086
2022-10-01 04:24:12 - train: epoch 0200, iter [00730, 01251], lr: 0.000706, loss: 0.4301
2022-10-01 04:24:30 - train: epoch 0200, iter [00740, 01251], lr: 0.000706, loss: 0.4015
2022-10-01 04:24:48 - train: epoch 0200, iter [00750, 01251], lr: 0.000706, loss: 0.4265
2022-10-01 04:25:06 - train: epoch 0200, iter [00760, 01251], lr: 0.000706, loss: 0.3931
2022-10-01 04:25:23 - train: epoch 0200, iter [00770, 01251], lr: 0.000706, loss: 0.4113
2022-10-01 04:25:41 - train: epoch 0200, iter [00780, 01251], lr: 0.000706, loss: 0.4040
2022-10-01 04:25:59 - train: epoch 0200, iter [00790, 01251], lr: 0.000706, loss: 0.4228
2022-10-01 04:26:17 - train: epoch 0200, iter [00800, 01251], lr: 0.000706, loss: 0.4088
2022-10-01 04:26:34 - train: epoch 0200, iter [00810, 01251], lr: 0.000706, loss: 0.4096
2022-10-01 04:26:52 - train: epoch 0200, iter [00820, 01251], lr: 0.000706, loss: 0.4082
2022-10-01 04:27:10 - train: epoch 0200, iter [00830, 01251], lr: 0.000706, loss: 0.4204
2022-10-01 04:27:27 - train: epoch 0200, iter [00840, 01251], lr: 0.000706, loss: 0.4142
2022-10-01 04:27:45 - train: epoch 0200, iter [00850, 01251], lr: 0.000706, loss: 0.4116
2022-10-01 04:28:03 - train: epoch 0200, iter [00860, 01251], lr: 0.000706, loss: 0.3985
2022-10-01 04:28:21 - train: epoch 0200, iter [00870, 01251], lr: 0.000706, loss: 0.3904
2022-10-01 04:28:39 - train: epoch 0200, iter [00880, 01251], lr: 0.000706, loss: 0.4160
2022-10-01 04:28:57 - train: epoch 0200, iter [00890, 01251], lr: 0.000706, loss: 0.4087
2022-10-01 04:29:14 - train: epoch 0200, iter [00900, 01251], lr: 0.000706, loss: 0.4327
2022-10-01 04:29:32 - train: epoch 0200, iter [00910, 01251], lr: 0.000706, loss: 0.4131
2022-10-01 04:29:50 - train: epoch 0200, iter [00920, 01251], lr: 0.000706, loss: 0.4260
2022-10-01 04:30:08 - train: epoch 0200, iter [00930, 01251], lr: 0.000706, loss: 0.4005
2022-10-01 04:30:25 - train: epoch 0200, iter [00940, 01251], lr: 0.000705, loss: 0.4082
2022-10-01 04:30:43 - train: epoch 0200, iter [00950, 01251], lr: 0.000705, loss: 0.4034
2022-10-01 04:31:01 - train: epoch 0200, iter [00960, 01251], lr: 0.000705, loss: 0.4066
2022-10-01 04:31:18 - train: epoch 0200, iter [00970, 01251], lr: 0.000705, loss: 0.3973
2022-10-01 04:31:36 - train: epoch 0200, iter [00980, 01251], lr: 0.000705, loss: 0.4092
2022-10-01 04:31:54 - train: epoch 0200, iter [00990, 01251], lr: 0.000705, loss: 0.4281
2022-10-01 04:32:12 - train: epoch 0200, iter [01000, 01251], lr: 0.000705, loss: 0.3925
2022-10-01 04:32:29 - train: epoch 0200, iter [01010, 01251], lr: 0.000705, loss: 0.3893
2022-10-01 04:32:47 - train: epoch 0200, iter [01020, 01251], lr: 0.000705, loss: 0.3985
2022-10-01 04:33:05 - train: epoch 0200, iter [01030, 01251], lr: 0.000705, loss: 0.4165
2022-10-01 04:33:23 - train: epoch 0200, iter [01040, 01251], lr: 0.000705, loss: 0.3938
2022-10-01 04:33:40 - train: epoch 0200, iter [01050, 01251], lr: 0.000705, loss: 0.4072
2022-10-01 04:33:58 - train: epoch 0200, iter [01060, 01251], lr: 0.000705, loss: 0.4094
2022-10-01 04:34:16 - train: epoch 0200, iter [01070, 01251], lr: 0.000705, loss: 0.4119
2022-10-01 04:34:34 - train: epoch 0200, iter [01080, 01251], lr: 0.000705, loss: 0.4149
2022-10-01 04:34:52 - train: epoch 0200, iter [01090, 01251], lr: 0.000705, loss: 0.4284
2022-10-01 04:35:09 - train: epoch 0200, iter [01100, 01251], lr: 0.000705, loss: 0.4005
2022-10-01 04:35:27 - train: epoch 0200, iter [01110, 01251], lr: 0.000705, loss: 0.3953
2022-10-01 04:35:45 - train: epoch 0200, iter [01120, 01251], lr: 0.000705, loss: 0.4136
2022-10-01 04:36:03 - train: epoch 0200, iter [01130, 01251], lr: 0.000705, loss: 0.4287
2022-10-01 04:36:20 - train: epoch 0200, iter [01140, 01251], lr: 0.000705, loss: 0.4004
2022-10-01 04:36:38 - train: epoch 0200, iter [01150, 01251], lr: 0.000705, loss: 0.4100
2022-10-01 04:36:56 - train: epoch 0200, iter [01160, 01251], lr: 0.000705, loss: 0.4079
2022-10-01 04:37:14 - train: epoch 0200, iter [01170, 01251], lr: 0.000705, loss: 0.3992
2022-10-01 04:37:31 - train: epoch 0200, iter [01180, 01251], lr: 0.000704, loss: 0.4101
2022-10-01 04:37:49 - train: epoch 0200, iter [01190, 01251], lr: 0.000704, loss: 0.4105
2022-10-01 04:38:07 - train: epoch 0200, iter [01200, 01251], lr: 0.000704, loss: 0.4054
2022-10-01 04:38:25 - train: epoch 0200, iter [01210, 01251], lr: 0.000704, loss: 0.3898
2022-10-01 04:38:42 - train: epoch 0200, iter [01220, 01251], lr: 0.000704, loss: 0.4169
2022-10-01 04:39:00 - train: epoch 0200, iter [01230, 01251], lr: 0.000704, loss: 0.4060
2022-10-01 04:39:18 - train: epoch 0200, iter [01240, 01251], lr: 0.000704, loss: 0.4073
2022-10-01 04:39:36 - train: epoch 0200, iter [01250, 01251], lr: 0.000704, loss: 0.4124
2022-10-01 04:39:39 - train: epoch 200, train_loss: 0.4071
2022-10-01 04:39:42 - until epoch: 200, best_loss: 0.4071
2022-10-01 04:39:42 - epoch 201 lr: 0.000704
2022-10-01 04:40:05 - train: epoch 0201, iter [00010, 01251], lr: 0.000704, loss: 0.3802
2022-10-01 04:40:23 - train: epoch 0201, iter [00020, 01251], lr: 0.000704, loss: 0.3934
2022-10-01 04:40:41 - train: epoch 0201, iter [00030, 01251], lr: 0.000704, loss: 0.4059
2022-10-01 04:40:58 - train: epoch 0201, iter [00040, 01251], lr: 0.000704, loss: 0.3942
2022-10-01 04:41:16 - train: epoch 0201, iter [00050, 01251], lr: 0.000704, loss: 0.4201
2022-10-01 04:41:34 - train: epoch 0201, iter [00060, 01251], lr: 0.000704, loss: 0.4214
2022-10-01 04:41:51 - train: epoch 0201, iter [00070, 01251], lr: 0.000704, loss: 0.4280
2022-10-01 04:42:09 - train: epoch 0201, iter [00080, 01251], lr: 0.000704, loss: 0.3916
2022-10-01 04:42:27 - train: epoch 0201, iter [00090, 01251], lr: 0.000704, loss: 0.4000
2022-10-01 04:42:45 - train: epoch 0201, iter [00100, 01251], lr: 0.000704, loss: 0.4057
2022-10-01 04:43:02 - train: epoch 0201, iter [00110, 01251], lr: 0.000704, loss: 0.3943
2022-10-01 04:43:20 - train: epoch 0201, iter [00120, 01251], lr: 0.000704, loss: 0.4182
2022-10-01 04:43:38 - train: epoch 0201, iter [00130, 01251], lr: 0.000704, loss: 0.4102
2022-10-01 04:43:56 - train: epoch 0201, iter [00140, 01251], lr: 0.000704, loss: 0.4108
2022-10-01 04:44:13 - train: epoch 0201, iter [00150, 01251], lr: 0.000704, loss: 0.4135
2022-10-01 04:44:31 - train: epoch 0201, iter [00160, 01251], lr: 0.000704, loss: 0.4168
2022-10-01 04:44:49 - train: epoch 0201, iter [00170, 01251], lr: 0.000703, loss: 0.4249
2022-10-01 04:45:07 - train: epoch 0201, iter [00180, 01251], lr: 0.000703, loss: 0.3964
2022-10-01 04:45:25 - train: epoch 0201, iter [00190, 01251], lr: 0.000703, loss: 0.3858
2022-10-01 04:45:43 - train: epoch 0201, iter [00200, 01251], lr: 0.000703, loss: 0.4119
2022-10-01 04:46:00 - train: epoch 0201, iter [00210, 01251], lr: 0.000703, loss: 0.4141
2022-10-01 04:46:18 - train: epoch 0201, iter [00220, 01251], lr: 0.000703, loss: 0.4081
2022-10-01 04:46:36 - train: epoch 0201, iter [00230, 01251], lr: 0.000703, loss: 0.3977
2022-10-01 04:46:54 - train: epoch 0201, iter [00240, 01251], lr: 0.000703, loss: 0.4003
2022-10-01 04:47:11 - train: epoch 0201, iter [00250, 01251], lr: 0.000703, loss: 0.4237
2022-10-01 04:47:29 - train: epoch 0201, iter [00260, 01251], lr: 0.000703, loss: 0.3983
2022-10-01 04:47:47 - train: epoch 0201, iter [00270, 01251], lr: 0.000703, loss: 0.4168
2022-10-01 04:48:05 - train: epoch 0201, iter [00280, 01251], lr: 0.000703, loss: 0.4094
2022-10-01 04:48:22 - train: epoch 0201, iter [00290, 01251], lr: 0.000703, loss: 0.3958
2022-10-01 04:48:40 - train: epoch 0201, iter [00300, 01251], lr: 0.000703, loss: 0.3897
2022-10-01 04:48:58 - train: epoch 0201, iter [00310, 01251], lr: 0.000703, loss: 0.4215
2022-10-01 04:49:16 - train: epoch 0201, iter [00320, 01251], lr: 0.000703, loss: 0.4023
2022-10-01 04:49:33 - train: epoch 0201, iter [00330, 01251], lr: 0.000703, loss: 0.4166
2022-10-01 04:49:51 - train: epoch 0201, iter [00340, 01251], lr: 0.000703, loss: 0.4208
2022-10-01 04:50:09 - train: epoch 0201, iter [00350, 01251], lr: 0.000703, loss: 0.4062
2022-10-01 04:50:27 - train: epoch 0201, iter [00360, 01251], lr: 0.000703, loss: 0.4187
2022-10-01 04:50:45 - train: epoch 0201, iter [00370, 01251], lr: 0.000703, loss: 0.4192
2022-10-01 04:51:02 - train: epoch 0201, iter [00380, 01251], lr: 0.000703, loss: 0.4039
2022-10-01 04:51:20 - train: epoch 0201, iter [00390, 01251], lr: 0.000703, loss: 0.4087
2022-10-01 04:51:38 - train: epoch 0201, iter [00400, 01251], lr: 0.000703, loss: 0.4242
2022-10-01 04:51:56 - train: epoch 0201, iter [00410, 01251], lr: 0.000702, loss: 0.4073
2022-10-01 04:52:13 - train: epoch 0201, iter [00420, 01251], lr: 0.000702, loss: 0.3980
2022-10-01 04:52:31 - train: epoch 0201, iter [00430, 01251], lr: 0.000702, loss: 0.4058
2022-10-01 04:52:49 - train: epoch 0201, iter [00440, 01251], lr: 0.000702, loss: 0.4159
2022-10-01 04:53:06 - train: epoch 0201, iter [00450, 01251], lr: 0.000702, loss: 0.3992
2022-10-01 04:53:24 - train: epoch 0201, iter [00460, 01251], lr: 0.000702, loss: 0.4043
2022-10-01 04:53:42 - train: epoch 0201, iter [00470, 01251], lr: 0.000702, loss: 0.4117
2022-10-01 04:53:59 - train: epoch 0201, iter [00480, 01251], lr: 0.000702, loss: 0.4101
2022-10-01 04:54:17 - train: epoch 0201, iter [00490, 01251], lr: 0.000702, loss: 0.4130
2022-10-01 04:54:35 - train: epoch 0201, iter [00500, 01251], lr: 0.000702, loss: 0.4276
2022-10-01 04:54:53 - train: epoch 0201, iter [00510, 01251], lr: 0.000702, loss: 0.4116
2022-10-01 04:55:11 - train: epoch 0201, iter [00520, 01251], lr: 0.000702, loss: 0.4082
2022-10-01 04:55:28 - train: epoch 0201, iter [00530, 01251], lr: 0.000702, loss: 0.4005
2022-10-01 04:55:46 - train: epoch 0201, iter [00540, 01251], lr: 0.000702, loss: 0.4293
2022-10-01 04:56:04 - train: epoch 0201, iter [00550, 01251], lr: 0.000702, loss: 0.4036
2022-10-01 04:56:21 - train: epoch 0201, iter [00560, 01251], lr: 0.000702, loss: 0.4044
2022-10-01 04:56:39 - train: epoch 0201, iter [00570, 01251], lr: 0.000702, loss: 0.4149
2022-10-01 04:56:57 - train: epoch 0201, iter [00580, 01251], lr: 0.000702, loss: 0.4009
2022-10-01 04:57:15 - train: epoch 0201, iter [00590, 01251], lr: 0.000702, loss: 0.3949
2022-10-01 04:57:33 - train: epoch 0201, iter [00600, 01251], lr: 0.000702, loss: 0.4077
2022-10-01 04:57:50 - train: epoch 0201, iter [00610, 01251], lr: 0.000702, loss: 0.3931
2022-10-01 04:58:08 - train: epoch 0201, iter [00620, 01251], lr: 0.000702, loss: 0.4085
2022-10-01 04:58:26 - train: epoch 0201, iter [00630, 01251], lr: 0.000702, loss: 0.3977
2022-10-01 04:58:43 - train: epoch 0201, iter [00640, 01251], lr: 0.000702, loss: 0.4069
2022-10-01 04:59:01 - train: epoch 0201, iter [00650, 01251], lr: 0.000702, loss: 0.4287
2022-10-01 04:59:19 - train: epoch 0201, iter [00660, 01251], lr: 0.000701, loss: 0.3970
2022-10-01 04:59:37 - train: epoch 0201, iter [00670, 01251], lr: 0.000701, loss: 0.3992
2022-10-01 04:59:54 - train: epoch 0201, iter [00680, 01251], lr: 0.000701, loss: 0.4162
2022-10-01 05:00:12 - train: epoch 0201, iter [00690, 01251], lr: 0.000701, loss: 0.4265
2022-10-01 05:00:30 - train: epoch 0201, iter [00700, 01251], lr: 0.000701, loss: 0.4252
2022-10-01 05:00:47 - train: epoch 0201, iter [00710, 01251], lr: 0.000701, loss: 0.4182
2022-10-01 05:01:05 - train: epoch 0201, iter [00720, 01251], lr: 0.000701, loss: 0.4329
2022-10-01 05:01:23 - train: epoch 0201, iter [00730, 01251], lr: 0.000701, loss: 0.3997
2022-10-01 05:01:40 - train: epoch 0201, iter [00740, 01251], lr: 0.000701, loss: 0.4009
2022-10-01 05:01:58 - train: epoch 0201, iter [00750, 01251], lr: 0.000701, loss: 0.4235
2022-10-01 05:02:16 - train: epoch 0201, iter [00760, 01251], lr: 0.000701, loss: 0.4193
2022-10-01 05:02:34 - train: epoch 0201, iter [00770, 01251], lr: 0.000701, loss: 0.4170
2022-10-01 05:02:51 - train: epoch 0201, iter [00780, 01251], lr: 0.000701, loss: 0.4210
2022-10-01 05:03:09 - train: epoch 0201, iter [00790, 01251], lr: 0.000701, loss: 0.4103
2022-10-01 05:03:27 - train: epoch 0201, iter [00800, 01251], lr: 0.000701, loss: 0.4038
2022-10-01 05:03:44 - train: epoch 0201, iter [00810, 01251], lr: 0.000701, loss: 0.4224
2022-10-01 05:04:02 - train: epoch 0201, iter [00820, 01251], lr: 0.000701, loss: 0.4122
2022-10-01 05:04:20 - train: epoch 0201, iter [00830, 01251], lr: 0.000701, loss: 0.4067
2022-10-01 05:04:38 - train: epoch 0201, iter [00840, 01251], lr: 0.000701, loss: 0.4037
2022-10-01 05:04:56 - train: epoch 0201, iter [00850, 01251], lr: 0.000701, loss: 0.4131
2022-10-01 05:05:13 - train: epoch 0201, iter [00860, 01251], lr: 0.000701, loss: 0.3931
2022-10-01 05:05:31 - train: epoch 0201, iter [00870, 01251], lr: 0.000701, loss: 0.3916
2022-10-01 05:05:49 - train: epoch 0201, iter [00880, 01251], lr: 0.000701, loss: 0.4037
2022-10-01 05:06:07 - train: epoch 0201, iter [00890, 01251], lr: 0.000701, loss: 0.4112
2022-10-01 05:06:24 - train: epoch 0201, iter [00900, 01251], lr: 0.000700, loss: 0.4100
2022-10-01 05:06:42 - train: epoch 0201, iter [00910, 01251], lr: 0.000700, loss: 0.4019
2022-10-01 05:07:00 - train: epoch 0201, iter [00920, 01251], lr: 0.000700, loss: 0.4122
2022-10-01 05:07:18 - train: epoch 0201, iter [00930, 01251], lr: 0.000700, loss: 0.4153
2022-10-01 05:07:36 - train: epoch 0201, iter [00940, 01251], lr: 0.000700, loss: 0.3982
2022-10-01 05:07:53 - train: epoch 0201, iter [00950, 01251], lr: 0.000700, loss: 0.4004
2022-10-01 05:08:11 - train: epoch 0201, iter [00960, 01251], lr: 0.000700, loss: 0.4143
2022-10-01 05:08:29 - train: epoch 0201, iter [00970, 01251], lr: 0.000700, loss: 0.4181
2022-10-01 05:08:46 - train: epoch 0201, iter [00980, 01251], lr: 0.000700, loss: 0.4082
2022-10-01 05:09:04 - train: epoch 0201, iter [00990, 01251], lr: 0.000700, loss: 0.4037
2022-10-01 05:09:22 - train: epoch 0201, iter [01000, 01251], lr: 0.000700, loss: 0.3825
2022-10-01 05:09:40 - train: epoch 0201, iter [01010, 01251], lr: 0.000700, loss: 0.3993
2022-10-01 05:09:57 - train: epoch 0201, iter [01020, 01251], lr: 0.000700, loss: 0.4297
2022-10-01 05:10:15 - train: epoch 0201, iter [01030, 01251], lr: 0.000700, loss: 0.4065
2022-10-01 05:10:33 - train: epoch 0201, iter [01040, 01251], lr: 0.000700, loss: 0.3994
2022-10-01 05:10:51 - train: epoch 0201, iter [01050, 01251], lr: 0.000700, loss: 0.4058
2022-10-01 05:11:08 - train: epoch 0201, iter [01060, 01251], lr: 0.000700, loss: 0.4037
2022-10-01 05:11:26 - train: epoch 0201, iter [01070, 01251], lr: 0.000700, loss: 0.4124
2022-10-01 05:11:44 - train: epoch 0201, iter [01080, 01251], lr: 0.000700, loss: 0.4022
2022-10-01 05:12:02 - train: epoch 0201, iter [01090, 01251], lr: 0.000700, loss: 0.4015
2022-10-01 05:12:19 - train: epoch 0201, iter [01100, 01251], lr: 0.000700, loss: 0.4091
2022-10-01 05:12:37 - train: epoch 0201, iter [01110, 01251], lr: 0.000700, loss: 0.4164
2022-10-01 05:12:55 - train: epoch 0201, iter [01120, 01251], lr: 0.000700, loss: 0.4098
2022-10-01 05:13:13 - train: epoch 0201, iter [01130, 01251], lr: 0.000700, loss: 0.3929
2022-10-01 05:13:30 - train: epoch 0201, iter [01140, 01251], lr: 0.000699, loss: 0.4019
2022-10-01 05:13:48 - train: epoch 0201, iter [01150, 01251], lr: 0.000699, loss: 0.4060
2022-10-01 05:14:06 - train: epoch 0201, iter [01160, 01251], lr: 0.000699, loss: 0.3787
2022-10-01 05:14:24 - train: epoch 0201, iter [01170, 01251], lr: 0.000699, loss: 0.3998
2022-10-01 05:14:41 - train: epoch 0201, iter [01180, 01251], lr: 0.000699, loss: 0.3963
2022-10-01 05:14:59 - train: epoch 0201, iter [01190, 01251], lr: 0.000699, loss: 0.4050
2022-10-01 05:15:17 - train: epoch 0201, iter [01200, 01251], lr: 0.000699, loss: 0.4138
2022-10-01 05:15:34 - train: epoch 0201, iter [01210, 01251], lr: 0.000699, loss: 0.4090
2022-10-01 05:15:52 - train: epoch 0201, iter [01220, 01251], lr: 0.000699, loss: 0.4041
2022-10-01 05:16:10 - train: epoch 0201, iter [01230, 01251], lr: 0.000699, loss: 0.4141
2022-10-01 05:16:28 - train: epoch 0201, iter [01240, 01251], lr: 0.000699, loss: 0.4233
2022-10-01 05:16:45 - train: epoch 0201, iter [01250, 01251], lr: 0.000699, loss: 0.4252
2022-10-01 05:16:49 - train: epoch 201, train_loss: 0.4070
2022-10-01 05:16:51 - until epoch: 201, best_loss: 0.4070
2022-10-01 05:16:51 - epoch 202 lr: 0.000699
2022-10-01 05:17:16 - train: epoch 0202, iter [00010, 01251], lr: 0.000699, loss: 0.4034
2022-10-01 05:17:34 - train: epoch 0202, iter [00020, 01251], lr: 0.000699, loss: 0.4107
2022-10-01 05:17:51 - train: epoch 0202, iter [00030, 01251], lr: 0.000699, loss: 0.4092
2022-10-01 05:18:09 - train: epoch 0202, iter [00040, 01251], lr: 0.000699, loss: 0.3932
2022-10-01 05:18:26 - train: epoch 0202, iter [00050, 01251], lr: 0.000699, loss: 0.4066
2022-10-01 05:18:44 - train: epoch 0202, iter [00060, 01251], lr: 0.000699, loss: 0.4123
2022-10-01 05:19:02 - train: epoch 0202, iter [00070, 01251], lr: 0.000699, loss: 0.4196
2022-10-01 05:19:20 - train: epoch 0202, iter [00080, 01251], lr: 0.000699, loss: 0.4145
2022-10-01 05:19:37 - train: epoch 0202, iter [00090, 01251], lr: 0.000699, loss: 0.3966
2022-10-01 05:19:55 - train: epoch 0202, iter [00100, 01251], lr: 0.000699, loss: 0.4109
2022-10-01 05:20:13 - train: epoch 0202, iter [00110, 01251], lr: 0.000699, loss: 0.4094
2022-10-01 05:20:31 - train: epoch 0202, iter [00120, 01251], lr: 0.000699, loss: 0.4109
2022-10-01 05:20:48 - train: epoch 0202, iter [00130, 01251], lr: 0.000698, loss: 0.4091
2022-10-01 05:21:06 - train: epoch 0202, iter [00140, 01251], lr: 0.000698, loss: 0.4048
2022-10-01 05:21:24 - train: epoch 0202, iter [00150, 01251], lr: 0.000698, loss: 0.3891
2022-10-01 05:21:42 - train: epoch 0202, iter [00160, 01251], lr: 0.000698, loss: 0.4161
2022-10-01 05:21:59 - train: epoch 0202, iter [00170, 01251], lr: 0.000698, loss: 0.4098
2022-10-01 05:22:17 - train: epoch 0202, iter [00180, 01251], lr: 0.000698, loss: 0.4055
2022-10-01 05:22:34 - train: epoch 0202, iter [00190, 01251], lr: 0.000698, loss: 0.4021
2022-10-01 05:22:52 - train: epoch 0202, iter [00200, 01251], lr: 0.000698, loss: 0.3938
2022-10-01 05:23:10 - train: epoch 0202, iter [00210, 01251], lr: 0.000698, loss: 0.4046
2022-10-01 05:23:28 - train: epoch 0202, iter [00220, 01251], lr: 0.000698, loss: 0.3884
2022-10-01 05:23:45 - train: epoch 0202, iter [00230, 01251], lr: 0.000698, loss: 0.3934
2022-10-01 05:24:03 - train: epoch 0202, iter [00240, 01251], lr: 0.000698, loss: 0.4021
2022-10-01 05:24:21 - train: epoch 0202, iter [00250, 01251], lr: 0.000698, loss: 0.4061
2022-10-01 05:24:39 - train: epoch 0202, iter [00260, 01251], lr: 0.000698, loss: 0.4220
2022-10-01 05:24:57 - train: epoch 0202, iter [00270, 01251], lr: 0.000698, loss: 0.3991
2022-10-01 05:25:14 - train: epoch 0202, iter [00280, 01251], lr: 0.000698, loss: 0.4103
2022-10-01 05:25:32 - train: epoch 0202, iter [00290, 01251], lr: 0.000698, loss: 0.4124
2022-10-01 05:25:50 - train: epoch 0202, iter [00300, 01251], lr: 0.000698, loss: 0.4018
2022-10-01 05:26:07 - train: epoch 0202, iter [00310, 01251], lr: 0.000698, loss: 0.4145
2022-10-01 05:26:25 - train: epoch 0202, iter [00320, 01251], lr: 0.000698, loss: 0.4205
2022-10-01 05:26:43 - train: epoch 0202, iter [00330, 01251], lr: 0.000698, loss: 0.3931
2022-10-01 05:27:01 - train: epoch 0202, iter [00340, 01251], lr: 0.000698, loss: 0.4121
2022-10-01 05:27:18 - train: epoch 0202, iter [00350, 01251], lr: 0.000698, loss: 0.4144
2022-10-01 05:27:36 - train: epoch 0202, iter [00360, 01251], lr: 0.000698, loss: 0.4238
2022-10-01 05:27:54 - train: epoch 0202, iter [00370, 01251], lr: 0.000698, loss: 0.4272
2022-10-01 05:28:12 - train: epoch 0202, iter [00380, 01251], lr: 0.000697, loss: 0.4006
2022-10-01 05:28:30 - train: epoch 0202, iter [00390, 01251], lr: 0.000697, loss: 0.4490
2022-10-01 05:28:48 - train: epoch 0202, iter [00400, 01251], lr: 0.000697, loss: 0.4066
2022-10-01 05:29:05 - train: epoch 0202, iter [00410, 01251], lr: 0.000697, loss: 0.3874
2022-10-01 05:29:23 - train: epoch 0202, iter [00420, 01251], lr: 0.000697, loss: 0.4173
2022-10-01 05:29:41 - train: epoch 0202, iter [00430, 01251], lr: 0.000697, loss: 0.3946
2022-10-01 05:29:59 - train: epoch 0202, iter [00440, 01251], lr: 0.000697, loss: 0.4093
2022-10-01 05:30:16 - train: epoch 0202, iter [00450, 01251], lr: 0.000697, loss: 0.4203
2022-10-01 05:30:34 - train: epoch 0202, iter [00460, 01251], lr: 0.000697, loss: 0.3975
2022-10-01 05:30:52 - train: epoch 0202, iter [00470, 01251], lr: 0.000697, loss: 0.4143
2022-10-01 05:31:10 - train: epoch 0202, iter [00480, 01251], lr: 0.000697, loss: 0.4087
2022-10-01 05:31:28 - train: epoch 0202, iter [00490, 01251], lr: 0.000697, loss: 0.4030
2022-10-01 05:31:45 - train: epoch 0202, iter [00500, 01251], lr: 0.000697, loss: 0.4165
2022-10-01 05:32:03 - train: epoch 0202, iter [00510, 01251], lr: 0.000697, loss: 0.3935
2022-10-01 05:32:21 - train: epoch 0202, iter [00520, 01251], lr: 0.000697, loss: 0.4060
2022-10-01 05:32:38 - train: epoch 0202, iter [00530, 01251], lr: 0.000697, loss: 0.4012
2022-10-01 05:32:56 - train: epoch 0202, iter [00540, 01251], lr: 0.000697, loss: 0.4001
2022-10-01 05:33:14 - train: epoch 0202, iter [00550, 01251], lr: 0.000697, loss: 0.4185
2022-10-01 05:33:32 - train: epoch 0202, iter [00560, 01251], lr: 0.000697, loss: 0.4343
2022-10-01 05:33:49 - train: epoch 0202, iter [00570, 01251], lr: 0.000697, loss: 0.4062
2022-10-01 05:34:07 - train: epoch 0202, iter [00580, 01251], lr: 0.000697, loss: 0.4097
2022-10-01 05:34:25 - train: epoch 0202, iter [00590, 01251], lr: 0.000697, loss: 0.4020
2022-10-01 05:34:43 - train: epoch 0202, iter [00600, 01251], lr: 0.000697, loss: 0.3923
2022-10-01 05:35:00 - train: epoch 0202, iter [00610, 01251], lr: 0.000697, loss: 0.3977
2022-10-01 05:35:18 - train: epoch 0202, iter [00620, 01251], lr: 0.000696, loss: 0.4140
2022-10-01 05:35:36 - train: epoch 0202, iter [00630, 01251], lr: 0.000696, loss: 0.3849
2022-10-01 05:35:54 - train: epoch 0202, iter [00640, 01251], lr: 0.000696, loss: 0.4241
2022-10-01 05:36:11 - train: epoch 0202, iter [00650, 01251], lr: 0.000696, loss: 0.3985
2022-10-01 05:36:29 - train: epoch 0202, iter [00660, 01251], lr: 0.000696, loss: 0.4096
2022-10-01 05:36:47 - train: epoch 0202, iter [00670, 01251], lr: 0.000696, loss: 0.4035
2022-10-01 05:37:05 - train: epoch 0202, iter [00680, 01251], lr: 0.000696, loss: 0.3888
2022-10-01 05:37:22 - train: epoch 0202, iter [00690, 01251], lr: 0.000696, loss: 0.4118
2022-10-01 05:37:40 - train: epoch 0202, iter [00700, 01251], lr: 0.000696, loss: 0.4082
2022-10-01 05:37:58 - train: epoch 0202, iter [00710, 01251], lr: 0.000696, loss: 0.4019
2022-10-01 05:38:15 - train: epoch 0202, iter [00720, 01251], lr: 0.000696, loss: 0.4252
2022-10-01 05:38:33 - train: epoch 0202, iter [00730, 01251], lr: 0.000696, loss: 0.4006
2022-10-01 05:38:51 - train: epoch 0202, iter [00740, 01251], lr: 0.000696, loss: 0.4089
2022-10-01 05:39:09 - train: epoch 0202, iter [00750, 01251], lr: 0.000696, loss: 0.4093
2022-10-01 05:39:27 - train: epoch 0202, iter [00760, 01251], lr: 0.000696, loss: 0.3910
2022-10-01 05:39:44 - train: epoch 0202, iter [00770, 01251], lr: 0.000696, loss: 0.4160
2022-10-01 05:40:02 - train: epoch 0202, iter [00780, 01251], lr: 0.000696, loss: 0.4012
2022-10-01 05:40:20 - train: epoch 0202, iter [00790, 01251], lr: 0.000696, loss: 0.4123
2022-10-01 05:40:38 - train: epoch 0202, iter [00800, 01251], lr: 0.000696, loss: 0.4163
2022-10-01 05:40:56 - train: epoch 0202, iter [00810, 01251], lr: 0.000696, loss: 0.3940
2022-10-01 05:41:13 - train: epoch 0202, iter [00820, 01251], lr: 0.000696, loss: 0.4061
2022-10-01 05:41:31 - train: epoch 0202, iter [00830, 01251], lr: 0.000696, loss: 0.4060
2022-10-01 05:41:49 - train: epoch 0202, iter [00840, 01251], lr: 0.000696, loss: 0.4104
2022-10-01 05:42:07 - train: epoch 0202, iter [00850, 01251], lr: 0.000696, loss: 0.4089
2022-10-01 05:42:24 - train: epoch 0202, iter [00860, 01251], lr: 0.000695, loss: 0.4167
2022-10-01 05:42:42 - train: epoch 0202, iter [00870, 01251], lr: 0.000695, loss: 0.4103
2022-10-01 05:43:00 - train: epoch 0202, iter [00880, 01251], lr: 0.000695, loss: 0.4084
2022-10-01 05:43:17 - train: epoch 0202, iter [00890, 01251], lr: 0.000695, loss: 0.3835
2022-10-01 05:43:35 - train: epoch 0202, iter [00900, 01251], lr: 0.000695, loss: 0.4064
2022-10-01 05:43:53 - train: epoch 0202, iter [00910, 01251], lr: 0.000695, loss: 0.4117
2022-10-01 05:44:10 - train: epoch 0202, iter [00920, 01251], lr: 0.000695, loss: 0.4072
2022-10-01 05:44:28 - train: epoch 0202, iter [00930, 01251], lr: 0.000695, loss: 0.4170
2022-10-01 05:44:46 - train: epoch 0202, iter [00940, 01251], lr: 0.000695, loss: 0.4006
2022-10-01 05:45:03 - train: epoch 0202, iter [00950, 01251], lr: 0.000695, loss: 0.3896
2022-10-01 05:45:21 - train: epoch 0202, iter [00960, 01251], lr: 0.000695, loss: 0.4248
2022-10-01 05:45:39 - train: epoch 0202, iter [00970, 01251], lr: 0.000695, loss: 0.3778
2022-10-01 05:45:56 - train: epoch 0202, iter [00980, 01251], lr: 0.000695, loss: 0.4329
2022-10-01 05:46:14 - train: epoch 0202, iter [00990, 01251], lr: 0.000695, loss: 0.4078
2022-10-01 05:46:32 - train: epoch 0202, iter [01000, 01251], lr: 0.000695, loss: 0.4026
2022-10-01 05:46:50 - train: epoch 0202, iter [01010, 01251], lr: 0.000695, loss: 0.4094
2022-10-01 05:47:07 - train: epoch 0202, iter [01020, 01251], lr: 0.000695, loss: 0.4084
2022-10-01 05:47:25 - train: epoch 0202, iter [01030, 01251], lr: 0.000695, loss: 0.4075
2022-10-01 05:47:43 - train: epoch 0202, iter [01040, 01251], lr: 0.000695, loss: 0.4098
2022-10-01 05:48:01 - train: epoch 0202, iter [01050, 01251], lr: 0.000695, loss: 0.4107
2022-10-01 05:48:19 - train: epoch 0202, iter [01060, 01251], lr: 0.000695, loss: 0.4159
2022-10-01 05:48:36 - train: epoch 0202, iter [01070, 01251], lr: 0.000695, loss: 0.4212
2022-10-01 05:48:54 - train: epoch 0202, iter [01080, 01251], lr: 0.000695, loss: 0.3927
2022-10-01 05:49:12 - train: epoch 0202, iter [01090, 01251], lr: 0.000695, loss: 0.4181
2022-10-01 05:49:30 - train: epoch 0202, iter [01100, 01251], lr: 0.000694, loss: 0.4000
2022-10-01 05:49:48 - train: epoch 0202, iter [01110, 01251], lr: 0.000694, loss: 0.3915
2022-10-01 05:50:05 - train: epoch 0202, iter [01120, 01251], lr: 0.000694, loss: 0.4080
2022-10-01 05:50:23 - train: epoch 0202, iter [01130, 01251], lr: 0.000694, loss: 0.3891
2022-10-01 05:50:41 - train: epoch 0202, iter [01140, 01251], lr: 0.000694, loss: 0.4200
2022-10-01 05:50:59 - train: epoch 0202, iter [01150, 01251], lr: 0.000694, loss: 0.4163
2022-10-01 05:51:16 - train: epoch 0202, iter [01160, 01251], lr: 0.000694, loss: 0.4240
2022-10-01 05:51:34 - train: epoch 0202, iter [01170, 01251], lr: 0.000694, loss: 0.4070
2022-10-01 05:51:52 - train: epoch 0202, iter [01180, 01251], lr: 0.000694, loss: 0.4141
2022-10-01 05:52:10 - train: epoch 0202, iter [01190, 01251], lr: 0.000694, loss: 0.4107
2022-10-01 05:52:27 - train: epoch 0202, iter [01200, 01251], lr: 0.000694, loss: 0.4157
2022-10-01 05:52:45 - train: epoch 0202, iter [01210, 01251], lr: 0.000694, loss: 0.4126
2022-10-01 05:53:03 - train: epoch 0202, iter [01220, 01251], lr: 0.000694, loss: 0.4110
2022-10-01 05:53:21 - train: epoch 0202, iter [01230, 01251], lr: 0.000694, loss: 0.4029
2022-10-01 05:53:39 - train: epoch 0202, iter [01240, 01251], lr: 0.000694, loss: 0.4196
2022-10-01 05:53:56 - train: epoch 0202, iter [01250, 01251], lr: 0.000694, loss: 0.3991
2022-10-01 05:53:59 - train: epoch 202, train_loss: 0.4069
2022-10-01 05:54:02 - until epoch: 202, best_loss: 0.4069
2022-10-01 05:54:02 - epoch 203 lr: 0.000694
2022-10-01 05:54:27 - train: epoch 0203, iter [00010, 01251], lr: 0.000694, loss: 0.4197
2022-10-01 05:54:44 - train: epoch 0203, iter [00020, 01251], lr: 0.000694, loss: 0.4109
2022-10-01 05:55:01 - train: epoch 0203, iter [00030, 01251], lr: 0.000694, loss: 0.3793
2022-10-01 05:55:19 - train: epoch 0203, iter [00040, 01251], lr: 0.000694, loss: 0.4163
2022-10-01 05:55:36 - train: epoch 0203, iter [00050, 01251], lr: 0.000694, loss: 0.3997
2022-10-01 05:55:54 - train: epoch 0203, iter [00060, 01251], lr: 0.000694, loss: 0.3970
2022-10-01 05:56:12 - train: epoch 0203, iter [00070, 01251], lr: 0.000694, loss: 0.3914
2022-10-01 05:56:29 - train: epoch 0203, iter [00080, 01251], lr: 0.000694, loss: 0.4256
2022-10-01 05:56:47 - train: epoch 0203, iter [00090, 01251], lr: 0.000693, loss: 0.3995
2022-10-01 05:57:04 - train: epoch 0203, iter [00100, 01251], lr: 0.000693, loss: 0.4011
2022-10-01 05:57:22 - train: epoch 0203, iter [00110, 01251], lr: 0.000693, loss: 0.4182
2022-10-01 05:57:40 - train: epoch 0203, iter [00120, 01251], lr: 0.000693, loss: 0.4134
2022-10-01 05:57:57 - train: epoch 0203, iter [00130, 01251], lr: 0.000693, loss: 0.4150
2022-10-01 05:58:15 - train: epoch 0203, iter [00140, 01251], lr: 0.000693, loss: 0.4186
2022-10-01 05:58:32 - train: epoch 0203, iter [00150, 01251], lr: 0.000693, loss: 0.4075
2022-10-01 05:58:50 - train: epoch 0203, iter [00160, 01251], lr: 0.000693, loss: 0.3901
2022-10-01 05:59:08 - train: epoch 0203, iter [00170, 01251], lr: 0.000693, loss: 0.4065
2022-10-01 05:59:26 - train: epoch 0203, iter [00180, 01251], lr: 0.000693, loss: 0.4132
2022-10-01 05:59:43 - train: epoch 0203, iter [00190, 01251], lr: 0.000693, loss: 0.3847
2022-10-01 06:00:01 - train: epoch 0203, iter [00200, 01251], lr: 0.000693, loss: 0.4237
2022-10-01 06:00:19 - train: epoch 0203, iter [00210, 01251], lr: 0.000693, loss: 0.4131
2022-10-01 06:00:37 - train: epoch 0203, iter [00220, 01251], lr: 0.000693, loss: 0.4014
2022-10-01 06:00:54 - train: epoch 0203, iter [00230, 01251], lr: 0.000693, loss: 0.3969
2022-10-01 06:01:12 - train: epoch 0203, iter [00240, 01251], lr: 0.000693, loss: 0.3999
2022-10-01 06:01:30 - train: epoch 0203, iter [00250, 01251], lr: 0.000693, loss: 0.3944
2022-10-01 06:01:47 - train: epoch 0203, iter [00260, 01251], lr: 0.000693, loss: 0.4030
2022-10-01 06:02:05 - train: epoch 0203, iter [00270, 01251], lr: 0.000693, loss: 0.4126
2022-10-01 06:02:23 - train: epoch 0203, iter [00280, 01251], lr: 0.000693, loss: 0.3978
2022-10-01 06:02:40 - train: epoch 0203, iter [00290, 01251], lr: 0.000693, loss: 0.4048
2022-10-01 06:02:58 - train: epoch 0203, iter [00300, 01251], lr: 0.000693, loss: 0.4166
2022-10-01 06:03:16 - train: epoch 0203, iter [00310, 01251], lr: 0.000693, loss: 0.4240
2022-10-01 06:03:33 - train: epoch 0203, iter [00320, 01251], lr: 0.000693, loss: 0.4248
2022-10-01 06:03:51 - train: epoch 0203, iter [00330, 01251], lr: 0.000692, loss: 0.3882
2022-10-01 06:04:09 - train: epoch 0203, iter [00340, 01251], lr: 0.000692, loss: 0.4041
2022-10-01 06:04:26 - train: epoch 0203, iter [00350, 01251], lr: 0.000692, loss: 0.3885
2022-10-01 06:04:44 - train: epoch 0203, iter [00360, 01251], lr: 0.000692, loss: 0.3901
2022-10-01 06:05:02 - train: epoch 0203, iter [00370, 01251], lr: 0.000692, loss: 0.4141
2022-10-01 06:05:19 - train: epoch 0203, iter [00380, 01251], lr: 0.000692, loss: 0.4203
2022-10-01 06:05:37 - train: epoch 0203, iter [00390, 01251], lr: 0.000692, loss: 0.4233
2022-10-01 06:05:55 - train: epoch 0203, iter [00400, 01251], lr: 0.000692, loss: 0.3969
2022-10-01 06:06:13 - train: epoch 0203, iter [00410, 01251], lr: 0.000692, loss: 0.4158
2022-10-01 06:06:30 - train: epoch 0203, iter [00420, 01251], lr: 0.000692, loss: 0.4013
2022-10-01 06:06:48 - train: epoch 0203, iter [00430, 01251], lr: 0.000692, loss: 0.4095
2022-10-01 06:07:06 - train: epoch 0203, iter [00440, 01251], lr: 0.000692, loss: 0.4014
2022-10-01 06:07:24 - train: epoch 0203, iter [00450, 01251], lr: 0.000692, loss: 0.4048
2022-10-01 06:07:41 - train: epoch 0203, iter [00460, 01251], lr: 0.000692, loss: 0.4079
2022-10-01 06:07:59 - train: epoch 0203, iter [00470, 01251], lr: 0.000692, loss: 0.4178
2022-10-01 06:08:17 - train: epoch 0203, iter [00480, 01251], lr: 0.000692, loss: 0.4180
2022-10-01 06:08:35 - train: epoch 0203, iter [00490, 01251], lr: 0.000692, loss: 0.4106
2022-10-01 06:08:52 - train: epoch 0203, iter [00500, 01251], lr: 0.000692, loss: 0.3933
2022-10-01 06:09:10 - train: epoch 0203, iter [00510, 01251], lr: 0.000692, loss: 0.4104
2022-10-01 06:09:28 - train: epoch 0203, iter [00520, 01251], lr: 0.000692, loss: 0.4097
2022-10-01 06:09:45 - train: epoch 0203, iter [00530, 01251], lr: 0.000692, loss: 0.3977
2022-10-01 06:10:03 - train: epoch 0203, iter [00540, 01251], lr: 0.000692, loss: 0.3897
2022-10-01 06:10:21 - train: epoch 0203, iter [00550, 01251], lr: 0.000692, loss: 0.3912
2022-10-01 06:10:38 - train: epoch 0203, iter [00560, 01251], lr: 0.000692, loss: 0.4271
2022-10-01 06:10:56 - train: epoch 0203, iter [00570, 01251], lr: 0.000692, loss: 0.4228
2022-10-01 06:11:14 - train: epoch 0203, iter [00580, 01251], lr: 0.000691, loss: 0.4179
2022-10-01 06:11:31 - train: epoch 0203, iter [00590, 01251], lr: 0.000691, loss: 0.4002
2022-10-01 06:11:49 - train: epoch 0203, iter [00600, 01251], lr: 0.000691, loss: 0.3872
2022-10-01 06:12:07 - train: epoch 0203, iter [00610, 01251], lr: 0.000691, loss: 0.4179
2022-10-01 06:12:25 - train: epoch 0203, iter [00620, 01251], lr: 0.000691, loss: 0.4057
2022-10-01 06:12:42 - train: epoch 0203, iter [00630, 01251], lr: 0.000691, loss: 0.4187
2022-10-01 06:13:00 - train: epoch 0203, iter [00640, 01251], lr: 0.000691, loss: 0.4177
2022-10-01 06:13:18 - train: epoch 0203, iter [00650, 01251], lr: 0.000691, loss: 0.3883
2022-10-01 06:13:35 - train: epoch 0203, iter [00660, 01251], lr: 0.000691, loss: 0.4060
2022-10-01 06:13:53 - train: epoch 0203, iter [00670, 01251], lr: 0.000691, loss: 0.4136
2022-10-01 06:14:11 - train: epoch 0203, iter [00680, 01251], lr: 0.000691, loss: 0.4009
2022-10-01 06:14:28 - train: epoch 0203, iter [00690, 01251], lr: 0.000691, loss: 0.3818
2022-10-01 06:14:46 - train: epoch 0203, iter [00700, 01251], lr: 0.000691, loss: 0.4049
2022-10-01 06:15:04 - train: epoch 0203, iter [00710, 01251], lr: 0.000691, loss: 0.4013
2022-10-01 06:15:21 - train: epoch 0203, iter [00720, 01251], lr: 0.000691, loss: 0.4106
2022-10-01 06:15:39 - train: epoch 0203, iter [00730, 01251], lr: 0.000691, loss: 0.4187
2022-10-01 06:15:57 - train: epoch 0203, iter [00740, 01251], lr: 0.000691, loss: 0.3895
2022-10-01 06:16:14 - train: epoch 0203, iter [00750, 01251], lr: 0.000691, loss: 0.4110
2022-10-01 06:16:32 - train: epoch 0203, iter [00760, 01251], lr: 0.000691, loss: 0.4171
2022-10-01 06:16:50 - train: epoch 0203, iter [00770, 01251], lr: 0.000691, loss: 0.3897
2022-10-01 06:17:07 - train: epoch 0203, iter [00780, 01251], lr: 0.000691, loss: 0.4014
2022-10-01 06:17:25 - train: epoch 0203, iter [00790, 01251], lr: 0.000691, loss: 0.4154
2022-10-01 06:17:43 - train: epoch 0203, iter [00800, 01251], lr: 0.000691, loss: 0.4175
2022-10-01 06:18:00 - train: epoch 0203, iter [00810, 01251], lr: 0.000691, loss: 0.4196
2022-10-01 06:18:18 - train: epoch 0203, iter [00820, 01251], lr: 0.000690, loss: 0.3945
2022-10-01 06:18:36 - train: epoch 0203, iter [00830, 01251], lr: 0.000690, loss: 0.4235
2022-10-01 06:18:53 - train: epoch 0203, iter [00840, 01251], lr: 0.000690, loss: 0.3837
2022-10-01 06:19:11 - train: epoch 0203, iter [00850, 01251], lr: 0.000690, loss: 0.4303
2022-10-01 06:19:29 - train: epoch 0203, iter [00860, 01251], lr: 0.000690, loss: 0.4028
2022-10-01 06:19:47 - train: epoch 0203, iter [00870, 01251], lr: 0.000690, loss: 0.4080
2022-10-01 06:20:04 - train: epoch 0203, iter [00880, 01251], lr: 0.000690, loss: 0.4072
2022-10-01 06:20:22 - train: epoch 0203, iter [00890, 01251], lr: 0.000690, loss: 0.4105
2022-10-01 06:20:40 - train: epoch 0203, iter [00900, 01251], lr: 0.000690, loss: 0.3618
2022-10-01 06:20:57 - train: epoch 0203, iter [00910, 01251], lr: 0.000690, loss: 0.4085
2022-10-01 06:21:15 - train: epoch 0203, iter [00920, 01251], lr: 0.000690, loss: 0.4100
2022-10-01 06:21:33 - train: epoch 0203, iter [00930, 01251], lr: 0.000690, loss: 0.4059
2022-10-01 06:21:50 - train: epoch 0203, iter [00940, 01251], lr: 0.000690, loss: 0.4315
2022-10-01 06:22:08 - train: epoch 0203, iter [00950, 01251], lr: 0.000690, loss: 0.4104
2022-10-01 06:22:26 - train: epoch 0203, iter [00960, 01251], lr: 0.000690, loss: 0.4205
2022-10-01 06:22:43 - train: epoch 0203, iter [00970, 01251], lr: 0.000690, loss: 0.3995
2022-10-01 06:23:01 - train: epoch 0203, iter [00980, 01251], lr: 0.000690, loss: 0.4184
2022-10-01 06:23:19 - train: epoch 0203, iter [00990, 01251], lr: 0.000690, loss: 0.4101
2022-10-01 06:23:37 - train: epoch 0203, iter [01000, 01251], lr: 0.000690, loss: 0.4075
2022-10-01 06:23:54 - train: epoch 0203, iter [01010, 01251], lr: 0.000690, loss: 0.3862
2022-10-01 06:24:12 - train: epoch 0203, iter [01020, 01251], lr: 0.000690, loss: 0.3957
2022-10-01 06:24:30 - train: epoch 0203, iter [01030, 01251], lr: 0.000690, loss: 0.4155
2022-10-01 06:24:48 - train: epoch 0203, iter [01040, 01251], lr: 0.000690, loss: 0.3986
2022-10-01 06:25:05 - train: epoch 0203, iter [01050, 01251], lr: 0.000690, loss: 0.3959
2022-10-01 06:25:23 - train: epoch 0203, iter [01060, 01251], lr: 0.000689, loss: 0.4268
2022-10-01 06:25:41 - train: epoch 0203, iter [01070, 01251], lr: 0.000689, loss: 0.3879
2022-10-01 06:25:58 - train: epoch 0203, iter [01080, 01251], lr: 0.000689, loss: 0.3840
2022-10-01 06:26:16 - train: epoch 0203, iter [01090, 01251], lr: 0.000689, loss: 0.4212
2022-10-01 06:26:34 - train: epoch 0203, iter [01100, 01251], lr: 0.000689, loss: 0.4095
2022-10-01 06:26:51 - train: epoch 0203, iter [01110, 01251], lr: 0.000689, loss: 0.3998
2022-10-01 06:27:09 - train: epoch 0203, iter [01120, 01251], lr: 0.000689, loss: 0.3968
2022-10-01 06:27:27 - train: epoch 0203, iter [01130, 01251], lr: 0.000689, loss: 0.3964
2022-10-01 06:27:44 - train: epoch 0203, iter [01140, 01251], lr: 0.000689, loss: 0.3972
2022-10-01 06:28:02 - train: epoch 0203, iter [01150, 01251], lr: 0.000689, loss: 0.4226
2022-10-01 06:28:20 - train: epoch 0203, iter [01160, 01251], lr: 0.000689, loss: 0.3954
2022-10-01 06:28:37 - train: epoch 0203, iter [01170, 01251], lr: 0.000689, loss: 0.4140
2022-10-01 06:28:55 - train: epoch 0203, iter [01180, 01251], lr: 0.000689, loss: 0.4248
2022-10-01 06:29:13 - train: epoch 0203, iter [01190, 01251], lr: 0.000689, loss: 0.4013
2022-10-01 06:29:30 - train: epoch 0203, iter [01200, 01251], lr: 0.000689, loss: 0.3979
2022-10-01 06:29:48 - train: epoch 0203, iter [01210, 01251], lr: 0.000689, loss: 0.4200
2022-10-01 06:30:06 - train: epoch 0203, iter [01220, 01251], lr: 0.000689, loss: 0.3940
2022-10-01 06:30:23 - train: epoch 0203, iter [01230, 01251], lr: 0.000689, loss: 0.4043
2022-10-01 06:30:41 - train: epoch 0203, iter [01240, 01251], lr: 0.000689, loss: 0.4225
2022-10-01 06:30:58 - train: epoch 0203, iter [01250, 01251], lr: 0.000689, loss: 0.4130
2022-10-01 06:31:02 - train: epoch 203, train_loss: 0.4068
2022-10-01 06:31:05 - until epoch: 203, best_loss: 0.4068
2022-10-01 06:31:05 - epoch 204 lr: 0.000689
2022-10-01 06:31:29 - train: epoch 0204, iter [00010, 01251], lr: 0.000689, loss: 0.4065
2022-10-01 06:31:47 - train: epoch 0204, iter [00020, 01251], lr: 0.000689, loss: 0.4048
2022-10-01 06:32:04 - train: epoch 0204, iter [00030, 01251], lr: 0.000689, loss: 0.4234
2022-10-01 06:32:22 - train: epoch 0204, iter [00040, 01251], lr: 0.000689, loss: 0.4150
2022-10-01 06:32:39 - train: epoch 0204, iter [00050, 01251], lr: 0.000688, loss: 0.4229
2022-10-01 06:32:57 - train: epoch 0204, iter [00060, 01251], lr: 0.000688, loss: 0.3783
2022-10-01 06:33:15 - train: epoch 0204, iter [00070, 01251], lr: 0.000688, loss: 0.4093
2022-10-01 06:33:32 - train: epoch 0204, iter [00080, 01251], lr: 0.000688, loss: 0.3996
2022-10-01 06:33:50 - train: epoch 0204, iter [00090, 01251], lr: 0.000688, loss: 0.3865
2022-10-01 06:34:08 - train: epoch 0204, iter [00100, 01251], lr: 0.000688, loss: 0.4117
2022-10-01 06:34:25 - train: epoch 0204, iter [00110, 01251], lr: 0.000688, loss: 0.4290
2022-10-01 06:34:43 - train: epoch 0204, iter [00120, 01251], lr: 0.000688, loss: 0.4229
2022-10-01 06:35:00 - train: epoch 0204, iter [00130, 01251], lr: 0.000688, loss: 0.4078
2022-10-01 06:35:18 - train: epoch 0204, iter [00140, 01251], lr: 0.000688, loss: 0.4097
2022-10-01 06:35:36 - train: epoch 0204, iter [00150, 01251], lr: 0.000688, loss: 0.4036
2022-10-01 06:35:54 - train: epoch 0204, iter [00160, 01251], lr: 0.000688, loss: 0.4014
2022-10-01 06:36:11 - train: epoch 0204, iter [00170, 01251], lr: 0.000688, loss: 0.4043
2022-10-01 06:36:29 - train: epoch 0204, iter [00180, 01251], lr: 0.000688, loss: 0.4034
2022-10-01 06:36:47 - train: epoch 0204, iter [00190, 01251], lr: 0.000688, loss: 0.3879
2022-10-01 06:37:04 - train: epoch 0204, iter [00200, 01251], lr: 0.000688, loss: 0.4130
2022-10-01 06:37:22 - train: epoch 0204, iter [00210, 01251], lr: 0.000688, loss: 0.4206
2022-10-01 06:37:40 - train: epoch 0204, iter [00220, 01251], lr: 0.000688, loss: 0.4043
2022-10-01 06:37:57 - train: epoch 0204, iter [00230, 01251], lr: 0.000688, loss: 0.3867
2022-10-01 06:38:15 - train: epoch 0204, iter [00240, 01251], lr: 0.000688, loss: 0.4238
2022-10-01 06:38:33 - train: epoch 0204, iter [00250, 01251], lr: 0.000688, loss: 0.4141
2022-10-01 06:38:50 - train: epoch 0204, iter [00260, 01251], lr: 0.000688, loss: 0.4085
2022-10-01 06:39:08 - train: epoch 0204, iter [00270, 01251], lr: 0.000688, loss: 0.4037
2022-10-01 06:39:26 - train: epoch 0204, iter [00280, 01251], lr: 0.000688, loss: 0.4033
2022-10-01 06:39:44 - train: epoch 0204, iter [00290, 01251], lr: 0.000687, loss: 0.4106
2022-10-01 06:40:01 - train: epoch 0204, iter [00300, 01251], lr: 0.000687, loss: 0.4246
2022-10-01 06:40:19 - train: epoch 0204, iter [00310, 01251], lr: 0.000687, loss: 0.3987
2022-10-01 06:40:37 - train: epoch 0204, iter [00320, 01251], lr: 0.000687, loss: 0.4060
2022-10-01 06:40:54 - train: epoch 0204, iter [00330, 01251], lr: 0.000687, loss: 0.4109
2022-10-01 06:41:12 - train: epoch 0204, iter [00340, 01251], lr: 0.000687, loss: 0.4078
2022-10-01 06:41:29 - train: epoch 0204, iter [00350, 01251], lr: 0.000687, loss: 0.4056
2022-10-01 06:41:47 - train: epoch 0204, iter [00360, 01251], lr: 0.000687, loss: 0.4066
2022-10-01 06:42:05 - train: epoch 0204, iter [00370, 01251], lr: 0.000687, loss: 0.4028
2022-10-01 06:42:23 - train: epoch 0204, iter [00380, 01251], lr: 0.000687, loss: 0.4012
2022-10-01 06:42:40 - train: epoch 0204, iter [00390, 01251], lr: 0.000687, loss: 0.4061
2022-10-01 06:42:58 - train: epoch 0204, iter [00400, 01251], lr: 0.000687, loss: 0.4062
2022-10-01 06:43:15 - train: epoch 0204, iter [00410, 01251], lr: 0.000687, loss: 0.4026
2022-10-01 06:43:33 - train: epoch 0204, iter [00420, 01251], lr: 0.000687, loss: 0.4303
2022-10-01 06:43:51 - train: epoch 0204, iter [00430, 01251], lr: 0.000687, loss: 0.4040
2022-10-01 06:44:09 - train: epoch 0204, iter [00440, 01251], lr: 0.000687, loss: 0.4058
2022-10-01 06:44:26 - train: epoch 0204, iter [00450, 01251], lr: 0.000687, loss: 0.4060
2022-10-01 06:44:44 - train: epoch 0204, iter [00460, 01251], lr: 0.000687, loss: 0.3990
2022-10-01 06:45:02 - train: epoch 0204, iter [00470, 01251], lr: 0.000687, loss: 0.4111
2022-10-01 06:45:19 - train: epoch 0204, iter [00480, 01251], lr: 0.000687, loss: 0.4183
2022-10-01 06:45:37 - train: epoch 0204, iter [00490, 01251], lr: 0.000687, loss: 0.4340
2022-10-01 06:45:55 - train: epoch 0204, iter [00500, 01251], lr: 0.000687, loss: 0.4113
2022-10-01 06:46:12 - train: epoch 0204, iter [00510, 01251], lr: 0.000687, loss: 0.4042
2022-10-01 06:46:30 - train: epoch 0204, iter [00520, 01251], lr: 0.000687, loss: 0.3905
2022-10-01 06:46:48 - train: epoch 0204, iter [00530, 01251], lr: 0.000686, loss: 0.3941
2022-10-01 06:47:05 - train: epoch 0204, iter [00540, 01251], lr: 0.000686, loss: 0.4013
2022-10-01 06:47:23 - train: epoch 0204, iter [00550, 01251], lr: 0.000686, loss: 0.4074
2022-10-01 06:47:41 - train: epoch 0204, iter [00560, 01251], lr: 0.000686, loss: 0.4028
2022-10-01 06:47:59 - train: epoch 0204, iter [00570, 01251], lr: 0.000686, loss: 0.4089
2022-10-01 06:48:16 - train: epoch 0204, iter [00580, 01251], lr: 0.000686, loss: 0.3938
2022-10-01 06:48:34 - train: epoch 0204, iter [00590, 01251], lr: 0.000686, loss: 0.4315
2022-10-01 06:48:51 - train: epoch 0204, iter [00600, 01251], lr: 0.000686, loss: 0.4179
2022-10-01 06:49:09 - train: epoch 0204, iter [00610, 01251], lr: 0.000686, loss: 0.3964
2022-10-01 06:49:27 - train: epoch 0204, iter [00620, 01251], lr: 0.000686, loss: 0.4105
2022-10-01 06:49:45 - train: epoch 0204, iter [00630, 01251], lr: 0.000686, loss: 0.4039
2022-10-01 06:50:02 - train: epoch 0204, iter [00640, 01251], lr: 0.000686, loss: 0.3841
2022-10-01 06:50:20 - train: epoch 0204, iter [00650, 01251], lr: 0.000686, loss: 0.4067
2022-10-01 06:50:38 - train: epoch 0204, iter [00660, 01251], lr: 0.000686, loss: 0.4029
2022-10-01 06:50:55 - train: epoch 0204, iter [00670, 01251], lr: 0.000686, loss: 0.4316
2022-10-01 06:51:13 - train: epoch 0204, iter [00680, 01251], lr: 0.000686, loss: 0.4390
2022-10-01 06:51:31 - train: epoch 0204, iter [00690, 01251], lr: 0.000686, loss: 0.4145
2022-10-01 06:51:48 - train: epoch 0204, iter [00700, 01251], lr: 0.000686, loss: 0.3802
2022-10-01 06:52:06 - train: epoch 0204, iter [00710, 01251], lr: 0.000686, loss: 0.4027
2022-10-01 06:52:24 - train: epoch 0204, iter [00720, 01251], lr: 0.000686, loss: 0.3970
2022-10-01 06:52:41 - train: epoch 0204, iter [00730, 01251], lr: 0.000686, loss: 0.4145
2022-10-01 06:52:59 - train: epoch 0204, iter [00740, 01251], lr: 0.000686, loss: 0.4065
2022-10-01 06:53:17 - train: epoch 0204, iter [00750, 01251], lr: 0.000686, loss: 0.3960
2022-10-01 06:53:35 - train: epoch 0204, iter [00760, 01251], lr: 0.000686, loss: 0.4006
2022-10-01 06:53:52 - train: epoch 0204, iter [00770, 01251], lr: 0.000685, loss: 0.4093
2022-10-01 06:54:10 - train: epoch 0204, iter [00780, 01251], lr: 0.000685, loss: 0.4038
2022-10-01 06:54:28 - train: epoch 0204, iter [00790, 01251], lr: 0.000685, loss: 0.4079
2022-10-01 06:54:45 - train: epoch 0204, iter [00800, 01251], lr: 0.000685, loss: 0.3984
2022-10-01 06:55:03 - train: epoch 0204, iter [00810, 01251], lr: 0.000685, loss: 0.4146
2022-10-01 06:55:21 - train: epoch 0204, iter [00820, 01251], lr: 0.000685, loss: 0.4200
2022-10-01 06:55:39 - train: epoch 0204, iter [00830, 01251], lr: 0.000685, loss: 0.4052
2022-10-01 06:55:56 - train: epoch 0204, iter [00840, 01251], lr: 0.000685, loss: 0.3912
2022-10-01 06:56:14 - train: epoch 0204, iter [00850, 01251], lr: 0.000685, loss: 0.4031
2022-10-01 06:56:32 - train: epoch 0204, iter [00860, 01251], lr: 0.000685, loss: 0.4136
2022-10-01 06:56:49 - train: epoch 0204, iter [00870, 01251], lr: 0.000685, loss: 0.3919
2022-10-01 06:57:07 - train: epoch 0204, iter [00880, 01251], lr: 0.000685, loss: 0.3871
2022-10-01 06:57:25 - train: epoch 0204, iter [00890, 01251], lr: 0.000685, loss: 0.4097
2022-10-01 06:57:43 - train: epoch 0204, iter [00900, 01251], lr: 0.000685, loss: 0.3948
2022-10-01 06:58:00 - train: epoch 0204, iter [00910, 01251], lr: 0.000685, loss: 0.3973
2022-10-01 06:58:18 - train: epoch 0204, iter [00920, 01251], lr: 0.000685, loss: 0.4320
2022-10-01 06:58:36 - train: epoch 0204, iter [00930, 01251], lr: 0.000685, loss: 0.4027
2022-10-01 06:58:53 - train: epoch 0204, iter [00940, 01251], lr: 0.000685, loss: 0.4232
2022-10-01 06:59:11 - train: epoch 0204, iter [00950, 01251], lr: 0.000685, loss: 0.3996
2022-10-01 06:59:29 - train: epoch 0204, iter [00960, 01251], lr: 0.000685, loss: 0.4186
2022-10-01 06:59:47 - train: epoch 0204, iter [00970, 01251], lr: 0.000685, loss: 0.4150
2022-10-01 07:00:04 - train: epoch 0204, iter [00980, 01251], lr: 0.000685, loss: 0.4125
2022-10-01 07:00:22 - train: epoch 0204, iter [00990, 01251], lr: 0.000685, loss: 0.3980
2022-10-01 07:00:40 - train: epoch 0204, iter [01000, 01251], lr: 0.000685, loss: 0.4154
2022-10-01 07:00:57 - train: epoch 0204, iter [01010, 01251], lr: 0.000685, loss: 0.4147
2022-10-01 07:01:15 - train: epoch 0204, iter [01020, 01251], lr: 0.000684, loss: 0.4160
2022-10-01 07:01:33 - train: epoch 0204, iter [01030, 01251], lr: 0.000684, loss: 0.4181
2022-10-01 07:01:50 - train: epoch 0204, iter [01040, 01251], lr: 0.000684, loss: 0.3984
2022-10-01 07:02:08 - train: epoch 0204, iter [01050, 01251], lr: 0.000684, loss: 0.4159
2022-10-01 07:02:26 - train: epoch 0204, iter [01060, 01251], lr: 0.000684, loss: 0.4162
2022-10-01 07:02:43 - train: epoch 0204, iter [01070, 01251], lr: 0.000684, loss: 0.4105
2022-10-01 07:03:01 - train: epoch 0204, iter [01080, 01251], lr: 0.000684, loss: 0.4008
2022-10-01 07:03:19 - train: epoch 0204, iter [01090, 01251], lr: 0.000684, loss: 0.4055
2022-10-01 07:03:37 - train: epoch 0204, iter [01100, 01251], lr: 0.000684, loss: 0.4051
2022-10-01 07:03:54 - train: epoch 0204, iter [01110, 01251], lr: 0.000684, loss: 0.4048
2022-10-01 07:04:12 - train: epoch 0204, iter [01120, 01251], lr: 0.000684, loss: 0.4143
2022-10-01 07:04:30 - train: epoch 0204, iter [01130, 01251], lr: 0.000684, loss: 0.3940
2022-10-01 07:04:47 - train: epoch 0204, iter [01140, 01251], lr: 0.000684, loss: 0.4039
2022-10-01 07:05:05 - train: epoch 0204, iter [01150, 01251], lr: 0.000684, loss: 0.4041
2022-10-01 07:05:23 - train: epoch 0204, iter [01160, 01251], lr: 0.000684, loss: 0.4026
2022-10-01 07:05:41 - train: epoch 0204, iter [01170, 01251], lr: 0.000684, loss: 0.4031
2022-10-01 07:05:58 - train: epoch 0204, iter [01180, 01251], lr: 0.000684, loss: 0.4069
2022-10-01 07:06:16 - train: epoch 0204, iter [01190, 01251], lr: 0.000684, loss: 0.4075
2022-10-01 07:06:34 - train: epoch 0204, iter [01200, 01251], lr: 0.000684, loss: 0.4275
2022-10-01 07:06:51 - train: epoch 0204, iter [01210, 01251], lr: 0.000684, loss: 0.4017
2022-10-01 07:07:09 - train: epoch 0204, iter [01220, 01251], lr: 0.000684, loss: 0.4130
2022-10-01 07:07:27 - train: epoch 0204, iter [01230, 01251], lr: 0.000684, loss: 0.3902
2022-10-01 07:07:44 - train: epoch 0204, iter [01240, 01251], lr: 0.000684, loss: 0.4135
2022-10-01 07:08:02 - train: epoch 0204, iter [01250, 01251], lr: 0.000684, loss: 0.4134
2022-10-01 07:08:05 - train: epoch 204, train_loss: 0.4068
2022-10-01 07:08:08 - until epoch: 204, best_loss: 0.4068
2022-10-01 07:08:08 - epoch 205 lr: 0.000684
2022-10-01 07:08:33 - train: epoch 0205, iter [00010, 01251], lr: 0.000683, loss: 0.4213
2022-10-01 07:08:50 - train: epoch 0205, iter [00020, 01251], lr: 0.000683, loss: 0.4114
2022-10-01 07:09:07 - train: epoch 0205, iter [00030, 01251], lr: 0.000683, loss: 0.3925
2022-10-01 07:09:25 - train: epoch 0205, iter [00040, 01251], lr: 0.000683, loss: 0.4037
2022-10-01 07:09:43 - train: epoch 0205, iter [00050, 01251], lr: 0.000683, loss: 0.4160
2022-10-01 07:10:00 - train: epoch 0205, iter [00060, 01251], lr: 0.000683, loss: 0.4076
2022-10-01 07:10:18 - train: epoch 0205, iter [00070, 01251], lr: 0.000683, loss: 0.4038
2022-10-01 07:10:36 - train: epoch 0205, iter [00080, 01251], lr: 0.000683, loss: 0.4118
2022-10-01 07:10:53 - train: epoch 0205, iter [00090, 01251], lr: 0.000683, loss: 0.4255
2022-10-01 07:11:11 - train: epoch 0205, iter [00100, 01251], lr: 0.000683, loss: 0.4293
2022-10-01 07:11:29 - train: epoch 0205, iter [00110, 01251], lr: 0.000683, loss: 0.4097
2022-10-01 07:11:46 - train: epoch 0205, iter [00120, 01251], lr: 0.000683, loss: 0.3971
2022-10-01 07:12:04 - train: epoch 0205, iter [00130, 01251], lr: 0.000683, loss: 0.4036
2022-10-01 07:12:22 - train: epoch 0205, iter [00140, 01251], lr: 0.000683, loss: 0.4134
2022-10-01 07:12:39 - train: epoch 0205, iter [00150, 01251], lr: 0.000683, loss: 0.4096
2022-10-01 07:12:57 - train: epoch 0205, iter [00160, 01251], lr: 0.000683, loss: 0.4024
2022-10-01 07:13:15 - train: epoch 0205, iter [00170, 01251], lr: 0.000683, loss: 0.3912
2022-10-01 07:13:32 - train: epoch 0205, iter [00180, 01251], lr: 0.000683, loss: 0.3927
2022-10-01 07:13:50 - train: epoch 0205, iter [00190, 01251], lr: 0.000683, loss: 0.4072
2022-10-01 07:14:08 - train: epoch 0205, iter [00200, 01251], lr: 0.000683, loss: 0.3920
2022-10-01 07:14:26 - train: epoch 0205, iter [00210, 01251], lr: 0.000683, loss: 0.4198
2022-10-01 07:14:43 - train: epoch 0205, iter [00220, 01251], lr: 0.000683, loss: 0.4005
2022-10-01 07:15:01 - train: epoch 0205, iter [00230, 01251], lr: 0.000683, loss: 0.3997
2022-10-01 07:15:19 - train: epoch 0205, iter [00240, 01251], lr: 0.000683, loss: 0.3983
2022-10-01 07:15:37 - train: epoch 0205, iter [00250, 01251], lr: 0.000682, loss: 0.4132
2022-10-01 07:15:54 - train: epoch 0205, iter [00260, 01251], lr: 0.000682, loss: 0.4109
2022-10-01 07:16:12 - train: epoch 0205, iter [00270, 01251], lr: 0.000682, loss: 0.4186
2022-10-01 07:16:29 - train: epoch 0205, iter [00280, 01251], lr: 0.000682, loss: 0.4067
2022-10-01 07:16:47 - train: epoch 0205, iter [00290, 01251], lr: 0.000682, loss: 0.4301
2022-10-01 07:17:05 - train: epoch 0205, iter [00300, 01251], lr: 0.000682, loss: 0.4217
2022-10-01 07:17:22 - train: epoch 0205, iter [00310, 01251], lr: 0.000682, loss: 0.4059
2022-10-01 07:17:40 - train: epoch 0205, iter [00320, 01251], lr: 0.000682, loss: 0.4316
2022-10-01 07:17:58 - train: epoch 0205, iter [00330, 01251], lr: 0.000682, loss: 0.3995
2022-10-01 07:18:16 - train: epoch 0205, iter [00340, 01251], lr: 0.000682, loss: 0.3951
2022-10-01 07:18:33 - train: epoch 0205, iter [00350, 01251], lr: 0.000682, loss: 0.4158
2022-10-01 07:18:51 - train: epoch 0205, iter [00360, 01251], lr: 0.000682, loss: 0.4013
2022-10-01 07:19:09 - train: epoch 0205, iter [00370, 01251], lr: 0.000682, loss: 0.4100
2022-10-01 07:19:26 - train: epoch 0205, iter [00380, 01251], lr: 0.000682, loss: 0.4243
2022-10-01 07:19:44 - train: epoch 0205, iter [00390, 01251], lr: 0.000682, loss: 0.4211
2022-10-01 07:20:02 - train: epoch 0205, iter [00400, 01251], lr: 0.000682, loss: 0.4034
2022-10-01 07:20:19 - train: epoch 0205, iter [00410, 01251], lr: 0.000682, loss: 0.4160
2022-10-01 07:20:37 - train: epoch 0205, iter [00420, 01251], lr: 0.000682, loss: 0.3847
2022-10-01 07:20:55 - train: epoch 0205, iter [00430, 01251], lr: 0.000682, loss: 0.4071
2022-10-01 07:21:13 - train: epoch 0205, iter [00440, 01251], lr: 0.000682, loss: 0.4114
2022-10-01 07:21:30 - train: epoch 0205, iter [00450, 01251], lr: 0.000682, loss: 0.4066
2022-10-01 07:21:48 - train: epoch 0205, iter [00460, 01251], lr: 0.000682, loss: 0.4106
2022-10-01 07:22:06 - train: epoch 0205, iter [00470, 01251], lr: 0.000682, loss: 0.3958
2022-10-01 07:22:24 - train: epoch 0205, iter [00480, 01251], lr: 0.000682, loss: 0.3985
2022-10-01 07:22:41 - train: epoch 0205, iter [00490, 01251], lr: 0.000681, loss: 0.4149
2022-10-01 07:22:59 - train: epoch 0205, iter [00500, 01251], lr: 0.000681, loss: 0.4186
2022-10-01 07:23:17 - train: epoch 0205, iter [00510, 01251], lr: 0.000681, loss: 0.4138
2022-10-01 07:23:34 - train: epoch 0205, iter [00520, 01251], lr: 0.000681, loss: 0.4088
2022-10-01 07:23:52 - train: epoch 0205, iter [00530, 01251], lr: 0.000681, loss: 0.3919
2022-10-01 07:24:10 - train: epoch 0205, iter [00540, 01251], lr: 0.000681, loss: 0.4291
2022-10-01 07:24:28 - train: epoch 0205, iter [00550, 01251], lr: 0.000681, loss: 0.4191
2022-10-01 07:24:45 - train: epoch 0205, iter [00560, 01251], lr: 0.000681, loss: 0.3978
2022-10-01 07:25:03 - train: epoch 0205, iter [00570, 01251], lr: 0.000681, loss: 0.4140
2022-10-01 07:25:21 - train: epoch 0205, iter [00580, 01251], lr: 0.000681, loss: 0.3838
2022-10-01 07:25:39 - train: epoch 0205, iter [00590, 01251], lr: 0.000681, loss: 0.4060
2022-10-01 07:25:56 - train: epoch 0205, iter [00600, 01251], lr: 0.000681, loss: 0.3945
2022-10-01 07:26:14 - train: epoch 0205, iter [00610, 01251], lr: 0.000681, loss: 0.3953
2022-10-01 07:26:32 - train: epoch 0205, iter [00620, 01251], lr: 0.000681, loss: 0.3908
2022-10-01 07:26:49 - train: epoch 0205, iter [00630, 01251], lr: 0.000681, loss: 0.4085
2022-10-01 07:27:07 - train: epoch 0205, iter [00640, 01251], lr: 0.000681, loss: 0.3944
2022-10-01 07:27:25 - train: epoch 0205, iter [00650, 01251], lr: 0.000681, loss: 0.4058
2022-10-01 07:27:43 - train: epoch 0205, iter [00660, 01251], lr: 0.000681, loss: 0.4133
2022-10-01 07:28:01 - train: epoch 0205, iter [00670, 01251], lr: 0.000681, loss: 0.3815
2022-10-01 07:28:18 - train: epoch 0205, iter [00680, 01251], lr: 0.000681, loss: 0.3999
2022-10-01 07:28:36 - train: epoch 0205, iter [00690, 01251], lr: 0.000681, loss: 0.3998
2022-10-01 07:28:54 - train: epoch 0205, iter [00700, 01251], lr: 0.000681, loss: 0.3692
2022-10-01 07:29:11 - train: epoch 0205, iter [00710, 01251], lr: 0.000681, loss: 0.4145
2022-10-01 07:29:29 - train: epoch 0205, iter [00720, 01251], lr: 0.000681, loss: 0.4230
2022-10-01 07:29:47 - train: epoch 0205, iter [00730, 01251], lr: 0.000680, loss: 0.4152
2022-10-01 07:30:05 - train: epoch 0205, iter [00740, 01251], lr: 0.000680, loss: 0.4074
2022-10-01 07:30:22 - train: epoch 0205, iter [00750, 01251], lr: 0.000680, loss: 0.4277
2022-10-01 07:30:40 - train: epoch 0205, iter [00760, 01251], lr: 0.000680, loss: 0.4129
2022-10-01 07:30:58 - train: epoch 0205, iter [00770, 01251], lr: 0.000680, loss: 0.4228
2022-10-01 07:31:15 - train: epoch 0205, iter [00780, 01251], lr: 0.000680, loss: 0.4031
2022-10-01 07:31:33 - train: epoch 0205, iter [00790, 01251], lr: 0.000680, loss: 0.3947
2022-10-01 07:31:51 - train: epoch 0205, iter [00800, 01251], lr: 0.000680, loss: 0.4034
2022-10-01 07:32:09 - train: epoch 0205, iter [00810, 01251], lr: 0.000680, loss: 0.3955
2022-10-01 07:32:27 - train: epoch 0205, iter [00820, 01251], lr: 0.000680, loss: 0.4226
2022-10-01 07:32:45 - train: epoch 0205, iter [00830, 01251], lr: 0.000680, loss: 0.4063
2022-10-01 07:33:02 - train: epoch 0205, iter [00840, 01251], lr: 0.000680, loss: 0.3977
2022-10-01 07:33:20 - train: epoch 0205, iter [00850, 01251], lr: 0.000680, loss: 0.4050
2022-10-01 07:33:38 - train: epoch 0205, iter [00860, 01251], lr: 0.000680, loss: 0.3781
2022-10-01 07:33:56 - train: epoch 0205, iter [00870, 01251], lr: 0.000680, loss: 0.4105
2022-10-01 07:34:13 - train: epoch 0205, iter [00880, 01251], lr: 0.000680, loss: 0.4093
2022-10-01 07:34:31 - train: epoch 0205, iter [00890, 01251], lr: 0.000680, loss: 0.3950
2022-10-01 07:34:49 - train: epoch 0205, iter [00900, 01251], lr: 0.000680, loss: 0.4145
2022-10-01 07:35:06 - train: epoch 0205, iter [00910, 01251], lr: 0.000680, loss: 0.4173
2022-10-01 07:35:24 - train: epoch 0205, iter [00920, 01251], lr: 0.000680, loss: 0.4128
2022-10-01 07:35:42 - train: epoch 0205, iter [00930, 01251], lr: 0.000680, loss: 0.4019
2022-10-01 07:36:00 - train: epoch 0205, iter [00940, 01251], lr: 0.000680, loss: 0.4103
2022-10-01 07:36:17 - train: epoch 0205, iter [00950, 01251], lr: 0.000680, loss: 0.3987
2022-10-01 07:36:35 - train: epoch 0205, iter [00960, 01251], lr: 0.000680, loss: 0.4129
2022-10-01 07:36:53 - train: epoch 0205, iter [00970, 01251], lr: 0.000679, loss: 0.4191
2022-10-01 07:37:10 - train: epoch 0205, iter [00980, 01251], lr: 0.000679, loss: 0.4166
2022-10-01 07:37:28 - train: epoch 0205, iter [00990, 01251], lr: 0.000679, loss: 0.3968
2022-10-01 07:37:46 - train: epoch 0205, iter [01000, 01251], lr: 0.000679, loss: 0.3987
2022-10-01 07:38:03 - train: epoch 0205, iter [01010, 01251], lr: 0.000679, loss: 0.4340
2022-10-01 07:38:21 - train: epoch 0205, iter [01020, 01251], lr: 0.000679, loss: 0.3899
2022-10-01 07:38:39 - train: epoch 0205, iter [01030, 01251], lr: 0.000679, loss: 0.3981
2022-10-01 07:38:57 - train: epoch 0205, iter [01040, 01251], lr: 0.000679, loss: 0.4054
2022-10-01 07:39:14 - train: epoch 0205, iter [01050, 01251], lr: 0.000679, loss: 0.3964
2022-10-01 07:39:32 - train: epoch 0205, iter [01060, 01251], lr: 0.000679, loss: 0.4127
2022-10-01 07:39:50 - train: epoch 0205, iter [01070, 01251], lr: 0.000679, loss: 0.3843
2022-10-01 07:40:07 - train: epoch 0205, iter [01080, 01251], lr: 0.000679, loss: 0.4078
2022-10-01 07:40:25 - train: epoch 0205, iter [01090, 01251], lr: 0.000679, loss: 0.4051
2022-10-01 07:40:43 - train: epoch 0205, iter [01100, 01251], lr: 0.000679, loss: 0.4092
2022-10-01 07:41:01 - train: epoch 0205, iter [01110, 01251], lr: 0.000679, loss: 0.4056
2022-10-01 07:41:18 - train: epoch 0205, iter [01120, 01251], lr: 0.000679, loss: 0.4272
2022-10-01 07:41:36 - train: epoch 0205, iter [01130, 01251], lr: 0.000679, loss: 0.3995
2022-10-01 07:41:54 - train: epoch 0205, iter [01140, 01251], lr: 0.000679, loss: 0.4295
2022-10-01 07:42:11 - train: epoch 0205, iter [01150, 01251], lr: 0.000679, loss: 0.4044
2022-10-01 07:42:29 - train: epoch 0205, iter [01160, 01251], lr: 0.000679, loss: 0.3952
2022-10-01 07:42:47 - train: epoch 0205, iter [01170, 01251], lr: 0.000679, loss: 0.4133
2022-10-01 07:43:05 - train: epoch 0205, iter [01180, 01251], lr: 0.000679, loss: 0.4277
2022-10-01 07:43:22 - train: epoch 0205, iter [01190, 01251], lr: 0.000679, loss: 0.4225
2022-10-01 07:43:40 - train: epoch 0205, iter [01200, 01251], lr: 0.000679, loss: 0.3818
2022-10-01 07:43:58 - train: epoch 0205, iter [01210, 01251], lr: 0.000678, loss: 0.3972
2022-10-01 07:44:16 - train: epoch 0205, iter [01220, 01251], lr: 0.000678, loss: 0.4137
2022-10-01 07:44:33 - train: epoch 0205, iter [01230, 01251], lr: 0.000678, loss: 0.4004
2022-10-01 07:44:51 - train: epoch 0205, iter [01240, 01251], lr: 0.000678, loss: 0.4188
2022-10-01 07:45:09 - train: epoch 0205, iter [01250, 01251], lr: 0.000678, loss: 0.4215
2022-10-01 07:45:12 - train: epoch 205, train_loss: 0.4066
2022-10-01 07:45:15 - until epoch: 205, best_loss: 0.4066
2022-10-01 07:45:15 - epoch 206 lr: 0.000678
2022-10-01 07:45:39 - train: epoch 0206, iter [00010, 01251], lr: 0.000678, loss: 0.4038
2022-10-01 07:45:57 - train: epoch 0206, iter [00020, 01251], lr: 0.000678, loss: 0.4201
2022-10-01 07:46:14 - train: epoch 0206, iter [00030, 01251], lr: 0.000678, loss: 0.4211
2022-10-01 07:46:31 - train: epoch 0206, iter [00040, 01251], lr: 0.000678, loss: 0.4057
2022-10-01 07:46:49 - train: epoch 0206, iter [00050, 01251], lr: 0.000678, loss: 0.4113
2022-10-01 07:47:07 - train: epoch 0206, iter [00060, 01251], lr: 0.000678, loss: 0.4021
2022-10-01 07:47:24 - train: epoch 0206, iter [00070, 01251], lr: 0.000678, loss: 0.4049
2022-10-01 07:47:42 - train: epoch 0206, iter [00080, 01251], lr: 0.000678, loss: 0.3929
2022-10-01 07:47:59 - train: epoch 0206, iter [00090, 01251], lr: 0.000678, loss: 0.4044
2022-10-01 07:48:17 - train: epoch 0206, iter [00100, 01251], lr: 0.000678, loss: 0.3960
2022-10-01 07:48:35 - train: epoch 0206, iter [00110, 01251], lr: 0.000678, loss: 0.4140
2022-10-01 07:48:52 - train: epoch 0206, iter [00120, 01251], lr: 0.000678, loss: 0.4122
2022-10-01 07:49:10 - train: epoch 0206, iter [00130, 01251], lr: 0.000678, loss: 0.4250
2022-10-01 07:49:27 - train: epoch 0206, iter [00140, 01251], lr: 0.000678, loss: 0.3921
2022-10-01 07:49:45 - train: epoch 0206, iter [00150, 01251], lr: 0.000678, loss: 0.3984
2022-10-01 07:50:03 - train: epoch 0206, iter [00160, 01251], lr: 0.000678, loss: 0.4071
2022-10-01 07:50:21 - train: epoch 0206, iter [00170, 01251], lr: 0.000678, loss: 0.3977
2022-10-01 07:50:38 - train: epoch 0206, iter [00180, 01251], lr: 0.000678, loss: 0.3850
2022-10-01 07:50:56 - train: epoch 0206, iter [00190, 01251], lr: 0.000678, loss: 0.4098
2022-10-01 07:51:14 - train: epoch 0206, iter [00200, 01251], lr: 0.000677, loss: 0.4068
2022-10-01 07:51:32 - train: epoch 0206, iter [00210, 01251], lr: 0.000677, loss: 0.4121
2022-10-01 07:51:49 - train: epoch 0206, iter [00220, 01251], lr: 0.000677, loss: 0.4075
2022-10-01 07:52:07 - train: epoch 0206, iter [00230, 01251], lr: 0.000677, loss: 0.3914
2022-10-01 07:52:25 - train: epoch 0206, iter [00240, 01251], lr: 0.000677, loss: 0.4106
2022-10-01 07:52:42 - train: epoch 0206, iter [00250, 01251], lr: 0.000677, loss: 0.4194
2022-10-01 07:53:00 - train: epoch 0206, iter [00260, 01251], lr: 0.000677, loss: 0.3963
2022-10-01 07:53:18 - train: epoch 0206, iter [00270, 01251], lr: 0.000677, loss: 0.4157
2022-10-01 07:53:36 - train: epoch 0206, iter [00280, 01251], lr: 0.000677, loss: 0.4139
2022-10-01 07:53:53 - train: epoch 0206, iter [00290, 01251], lr: 0.000677, loss: 0.3769
2022-10-01 07:54:11 - train: epoch 0206, iter [00300, 01251], lr: 0.000677, loss: 0.4179
2022-10-01 07:54:29 - train: epoch 0206, iter [00310, 01251], lr: 0.000677, loss: 0.4317
2022-10-01 07:54:47 - train: epoch 0206, iter [00320, 01251], lr: 0.000677, loss: 0.3867
2022-10-01 07:55:04 - train: epoch 0206, iter [00330, 01251], lr: 0.000677, loss: 0.4190
2022-10-01 07:55:22 - train: epoch 0206, iter [00340, 01251], lr: 0.000677, loss: 0.3865
2022-10-01 07:55:40 - train: epoch 0206, iter [00350, 01251], lr: 0.000677, loss: 0.3981
2022-10-01 07:55:57 - train: epoch 0206, iter [00360, 01251], lr: 0.000677, loss: 0.3910
2022-10-01 07:56:15 - train: epoch 0206, iter [00370, 01251], lr: 0.000677, loss: 0.4038
2022-10-01 07:56:33 - train: epoch 0206, iter [00380, 01251], lr: 0.000677, loss: 0.4177
2022-10-01 07:56:51 - train: epoch 0206, iter [00390, 01251], lr: 0.000677, loss: 0.3968
2022-10-01 07:57:08 - train: epoch 0206, iter [00400, 01251], lr: 0.000677, loss: 0.4113
2022-10-01 07:57:26 - train: epoch 0206, iter [00410, 01251], lr: 0.000677, loss: 0.4100
2022-10-01 07:57:43 - train: epoch 0206, iter [00420, 01251], lr: 0.000677, loss: 0.4179
2022-10-01 07:58:01 - train: epoch 0206, iter [00430, 01251], lr: 0.000677, loss: 0.4117
2022-10-01 07:58:19 - train: epoch 0206, iter [00440, 01251], lr: 0.000676, loss: 0.4007
2022-10-01 07:58:36 - train: epoch 0206, iter [00450, 01251], lr: 0.000676, loss: 0.3827
2022-10-01 07:58:54 - train: epoch 0206, iter [00460, 01251], lr: 0.000676, loss: 0.4214
2022-10-01 07:59:12 - train: epoch 0206, iter [00470, 01251], lr: 0.000676, loss: 0.4070
2022-10-01 07:59:29 - train: epoch 0206, iter [00480, 01251], lr: 0.000676, loss: 0.4198
2022-10-01 07:59:47 - train: epoch 0206, iter [00490, 01251], lr: 0.000676, loss: 0.3937
2022-10-01 08:00:05 - train: epoch 0206, iter [00500, 01251], lr: 0.000676, loss: 0.4189
2022-10-01 08:00:23 - train: epoch 0206, iter [00510, 01251], lr: 0.000676, loss: 0.4131
2022-10-01 08:00:40 - train: epoch 0206, iter [00520, 01251], lr: 0.000676, loss: 0.4047
2022-10-01 08:00:58 - train: epoch 0206, iter [00530, 01251], lr: 0.000676, loss: 0.4266
2022-10-01 08:01:16 - train: epoch 0206, iter [00540, 01251], lr: 0.000676, loss: 0.4211
2022-10-01 08:01:33 - train: epoch 0206, iter [00550, 01251], lr: 0.000676, loss: 0.4106
2022-10-01 08:01:51 - train: epoch 0206, iter [00560, 01251], lr: 0.000676, loss: 0.3966
2022-10-01 08:02:09 - train: epoch 0206, iter [00570, 01251], lr: 0.000676, loss: 0.4167
2022-10-01 08:02:26 - train: epoch 0206, iter [00580, 01251], lr: 0.000676, loss: 0.4147
2022-10-01 08:02:44 - train: epoch 0206, iter [00590, 01251], lr: 0.000676, loss: 0.3953
2022-10-01 08:03:02 - train: epoch 0206, iter [00600, 01251], lr: 0.000676, loss: 0.4144
2022-10-01 08:03:20 - train: epoch 0206, iter [00610, 01251], lr: 0.000676, loss: 0.4146
2022-10-01 08:03:37 - train: epoch 0206, iter [00620, 01251], lr: 0.000676, loss: 0.4149
2022-10-01 08:03:55 - train: epoch 0206, iter [00630, 01251], lr: 0.000676, loss: 0.3900
2022-10-01 08:04:12 - train: epoch 0206, iter [00640, 01251], lr: 0.000676, loss: 0.4134
2022-10-01 08:04:30 - train: epoch 0206, iter [00650, 01251], lr: 0.000676, loss: 0.4161
2022-10-01 08:04:48 - train: epoch 0206, iter [00660, 01251], lr: 0.000676, loss: 0.3820
2022-10-01 08:05:05 - train: epoch 0206, iter [00670, 01251], lr: 0.000676, loss: 0.3852
2022-10-01 08:05:23 - train: epoch 0206, iter [00680, 01251], lr: 0.000675, loss: 0.3849
2022-10-01 08:05:41 - train: epoch 0206, iter [00690, 01251], lr: 0.000675, loss: 0.3897
2022-10-01 08:05:59 - train: epoch 0206, iter [00700, 01251], lr: 0.000675, loss: 0.4047
2022-10-01 08:06:16 - train: epoch 0206, iter [00710, 01251], lr: 0.000675, loss: 0.4153
2022-10-01 08:06:34 - train: epoch 0206, iter [00720, 01251], lr: 0.000675, loss: 0.4283
2022-10-01 08:06:52 - train: epoch 0206, iter [00730, 01251], lr: 0.000675, loss: 0.3956
2022-10-01 08:07:09 - train: epoch 0206, iter [00740, 01251], lr: 0.000675, loss: 0.4070
2022-10-01 08:07:27 - train: epoch 0206, iter [00750, 01251], lr: 0.000675, loss: 0.3956
2022-10-01 08:07:45 - train: epoch 0206, iter [00760, 01251], lr: 0.000675, loss: 0.3860
2022-10-01 08:08:02 - train: epoch 0206, iter [00770, 01251], lr: 0.000675, loss: 0.4119
2022-10-01 08:08:20 - train: epoch 0206, iter [00780, 01251], lr: 0.000675, loss: 0.4109
2022-10-01 08:08:38 - train: epoch 0206, iter [00790, 01251], lr: 0.000675, loss: 0.3883
2022-10-01 08:08:55 - train: epoch 0206, iter [00800, 01251], lr: 0.000675, loss: 0.3930
2022-10-01 08:09:13 - train: epoch 0206, iter [00810, 01251], lr: 0.000675, loss: 0.3999
2022-10-01 08:09:31 - train: epoch 0206, iter [00820, 01251], lr: 0.000675, loss: 0.4090
2022-10-01 08:09:49 - train: epoch 0206, iter [00830, 01251], lr: 0.000675, loss: 0.3913
2022-10-01 08:10:06 - train: epoch 0206, iter [00840, 01251], lr: 0.000675, loss: 0.4033
2022-10-01 08:10:24 - train: epoch 0206, iter [00850, 01251], lr: 0.000675, loss: 0.4300
2022-10-01 08:10:42 - train: epoch 0206, iter [00860, 01251], lr: 0.000675, loss: 0.3915
2022-10-01 08:10:59 - train: epoch 0206, iter [00870, 01251], lr: 0.000675, loss: 0.3960
2022-10-01 08:11:17 - train: epoch 0206, iter [00880, 01251], lr: 0.000675, loss: 0.4291
2022-10-01 08:11:35 - train: epoch 0206, iter [00890, 01251], lr: 0.000675, loss: 0.3934
2022-10-01 08:11:53 - train: epoch 0206, iter [00900, 01251], lr: 0.000675, loss: 0.4113
2022-10-01 08:12:10 - train: epoch 0206, iter [00910, 01251], lr: 0.000675, loss: 0.4041
2022-10-01 08:12:28 - train: epoch 0206, iter [00920, 01251], lr: 0.000674, loss: 0.4059
2022-10-01 08:12:46 - train: epoch 0206, iter [00930, 01251], lr: 0.000674, loss: 0.4017
2022-10-01 08:13:04 - train: epoch 0206, iter [00940, 01251], lr: 0.000674, loss: 0.4085
2022-10-01 08:13:21 - train: epoch 0206, iter [00950, 01251], lr: 0.000674, loss: 0.3963
2022-10-01 08:13:39 - train: epoch 0206, iter [00960, 01251], lr: 0.000674, loss: 0.4037
2022-10-01 08:13:57 - train: epoch 0206, iter [00970, 01251], lr: 0.000674, loss: 0.4168
2022-10-01 08:14:14 - train: epoch 0206, iter [00980, 01251], lr: 0.000674, loss: 0.4113
2022-10-01 08:14:32 - train: epoch 0206, iter [00990, 01251], lr: 0.000674, loss: 0.3873
2022-10-01 08:14:50 - train: epoch 0206, iter [01000, 01251], lr: 0.000674, loss: 0.3963
2022-10-01 08:15:08 - train: epoch 0206, iter [01010, 01251], lr: 0.000674, loss: 0.4016
2022-10-01 08:15:25 - train: epoch 0206, iter [01020, 01251], lr: 0.000674, loss: 0.4127
2022-10-01 08:15:43 - train: epoch 0206, iter [01030, 01251], lr: 0.000674, loss: 0.4048
2022-10-01 08:16:01 - train: epoch 0206, iter [01040, 01251], lr: 0.000674, loss: 0.4024
2022-10-01 08:16:18 - train: epoch 0206, iter [01050, 01251], lr: 0.000674, loss: 0.4120
2022-10-01 08:16:36 - train: epoch 0206, iter [01060, 01251], lr: 0.000674, loss: 0.3912
2022-10-01 08:16:54 - train: epoch 0206, iter [01070, 01251], lr: 0.000674, loss: 0.4152
2022-10-01 08:17:11 - train: epoch 0206, iter [01080, 01251], lr: 0.000674, loss: 0.4019
2022-10-01 08:17:29 - train: epoch 0206, iter [01090, 01251], lr: 0.000674, loss: 0.4264
2022-10-01 08:17:47 - train: epoch 0206, iter [01100, 01251], lr: 0.000674, loss: 0.4204
2022-10-01 08:18:04 - train: epoch 0206, iter [01110, 01251], lr: 0.000674, loss: 0.4066
2022-10-01 08:18:22 - train: epoch 0206, iter [01120, 01251], lr: 0.000674, loss: 0.4213
2022-10-01 08:18:40 - train: epoch 0206, iter [01130, 01251], lr: 0.000674, loss: 0.4211
2022-10-01 08:18:58 - train: epoch 0206, iter [01140, 01251], lr: 0.000674, loss: 0.4061
2022-10-01 08:19:15 - train: epoch 0206, iter [01150, 01251], lr: 0.000674, loss: 0.4223
2022-10-01 08:19:33 - train: epoch 0206, iter [01160, 01251], lr: 0.000673, loss: 0.3996
2022-10-01 08:19:51 - train: epoch 0206, iter [01170, 01251], lr: 0.000673, loss: 0.3828
2022-10-01 08:20:08 - train: epoch 0206, iter [01180, 01251], lr: 0.000673, loss: 0.4069
2022-10-01 08:20:26 - train: epoch 0206, iter [01190, 01251], lr: 0.000673, loss: 0.4073
2022-10-01 08:20:44 - train: epoch 0206, iter [01200, 01251], lr: 0.000673, loss: 0.3973
2022-10-01 08:21:01 - train: epoch 0206, iter [01210, 01251], lr: 0.000673, loss: 0.4086
2022-10-01 08:21:19 - train: epoch 0206, iter [01220, 01251], lr: 0.000673, loss: 0.3928
2022-10-01 08:21:37 - train: epoch 0206, iter [01230, 01251], lr: 0.000673, loss: 0.4136
2022-10-01 08:21:55 - train: epoch 0206, iter [01240, 01251], lr: 0.000673, loss: 0.4085
2022-10-01 08:22:12 - train: epoch 0206, iter [01250, 01251], lr: 0.000673, loss: 0.3778
2022-10-01 08:22:15 - train: epoch 206, train_loss: 0.4066
2022-10-01 08:22:18 - until epoch: 206, best_loss: 0.4066
2022-10-01 08:22:18 - epoch 207 lr: 0.000673
2022-10-01 08:22:43 - train: epoch 0207, iter [00010, 01251], lr: 0.000673, loss: 0.4296
2022-10-01 08:23:00 - train: epoch 0207, iter [00020, 01251], lr: 0.000673, loss: 0.3938
2022-10-01 08:23:18 - train: epoch 0207, iter [00030, 01251], lr: 0.000673, loss: 0.4078
2022-10-01 08:23:35 - train: epoch 0207, iter [00040, 01251], lr: 0.000673, loss: 0.4080
2022-10-01 08:23:53 - train: epoch 0207, iter [00050, 01251], lr: 0.000673, loss: 0.4146
2022-10-01 08:24:10 - train: epoch 0207, iter [00060, 01251], lr: 0.000673, loss: 0.3829
2022-10-01 08:24:28 - train: epoch 0207, iter [00070, 01251], lr: 0.000673, loss: 0.4199
2022-10-01 08:24:45 - train: epoch 0207, iter [00080, 01251], lr: 0.000673, loss: 0.3883
2022-10-01 08:25:03 - train: epoch 0207, iter [00090, 01251], lr: 0.000673, loss: 0.3914
2022-10-01 08:25:21 - train: epoch 0207, iter [00100, 01251], lr: 0.000673, loss: 0.3942
2022-10-01 08:25:38 - train: epoch 0207, iter [00110, 01251], lr: 0.000673, loss: 0.4113
2022-10-01 08:25:56 - train: epoch 0207, iter [00120, 01251], lr: 0.000673, loss: 0.4002
2022-10-01 08:26:14 - train: epoch 0207, iter [00130, 01251], lr: 0.000673, loss: 0.3909
2022-10-01 08:26:31 - train: epoch 0207, iter [00140, 01251], lr: 0.000673, loss: 0.4082
2022-10-01 08:26:49 - train: epoch 0207, iter [00150, 01251], lr: 0.000672, loss: 0.4033
2022-10-01 08:27:07 - train: epoch 0207, iter [00160, 01251], lr: 0.000672, loss: 0.4022
2022-10-01 08:27:24 - train: epoch 0207, iter [00170, 01251], lr: 0.000672, loss: 0.4184
2022-10-01 08:27:42 - train: epoch 0207, iter [00180, 01251], lr: 0.000672, loss: 0.4128
2022-10-01 08:28:00 - train: epoch 0207, iter [00190, 01251], lr: 0.000672, loss: 0.4105
2022-10-01 08:28:17 - train: epoch 0207, iter [00200, 01251], lr: 0.000672, loss: 0.3969
2022-10-01 08:28:35 - train: epoch 0207, iter [00210, 01251], lr: 0.000672, loss: 0.4067
2022-10-01 08:28:53 - train: epoch 0207, iter [00220, 01251], lr: 0.000672, loss: 0.3935
2022-10-01 08:29:10 - train: epoch 0207, iter [00230, 01251], lr: 0.000672, loss: 0.4033
2022-10-01 08:29:28 - train: epoch 0207, iter [00240, 01251], lr: 0.000672, loss: 0.4026
2022-10-01 08:29:46 - train: epoch 0207, iter [00250, 01251], lr: 0.000672, loss: 0.4072
2022-10-01 08:30:03 - train: epoch 0207, iter [00260, 01251], lr: 0.000672, loss: 0.4051
2022-10-01 08:30:21 - train: epoch 0207, iter [00270, 01251], lr: 0.000672, loss: 0.4023
2022-10-01 08:30:39 - train: epoch 0207, iter [00280, 01251], lr: 0.000672, loss: 0.3991
2022-10-01 08:30:56 - train: epoch 0207, iter [00290, 01251], lr: 0.000672, loss: 0.4124
2022-10-01 08:31:14 - train: epoch 0207, iter [00300, 01251], lr: 0.000672, loss: 0.4119
2022-10-01 08:31:32 - train: epoch 0207, iter [00310, 01251], lr: 0.000672, loss: 0.4152
2022-10-01 08:31:50 - train: epoch 0207, iter [00320, 01251], lr: 0.000672, loss: 0.4010
2022-10-01 08:32:07 - train: epoch 0207, iter [00330, 01251], lr: 0.000672, loss: 0.4128
2022-10-01 08:32:25 - train: epoch 0207, iter [00340, 01251], lr: 0.000672, loss: 0.4201
2022-10-01 08:32:43 - train: epoch 0207, iter [00350, 01251], lr: 0.000672, loss: 0.3988
2022-10-01 08:33:00 - train: epoch 0207, iter [00360, 01251], lr: 0.000672, loss: 0.4118
2022-10-01 08:33:18 - train: epoch 0207, iter [00370, 01251], lr: 0.000672, loss: 0.4003
2022-10-01 08:33:35 - train: epoch 0207, iter [00380, 01251], lr: 0.000672, loss: 0.4144
2022-10-01 08:33:53 - train: epoch 0207, iter [00390, 01251], lr: 0.000672, loss: 0.4112
2022-10-01 08:34:11 - train: epoch 0207, iter [00400, 01251], lr: 0.000671, loss: 0.4070
2022-10-01 08:34:28 - train: epoch 0207, iter [00410, 01251], lr: 0.000671, loss: 0.4438
2022-10-01 08:34:46 - train: epoch 0207, iter [00420, 01251], lr: 0.000671, loss: 0.4109
2022-10-01 08:35:04 - train: epoch 0207, iter [00430, 01251], lr: 0.000671, loss: 0.3934
2022-10-01 08:35:22 - train: epoch 0207, iter [00440, 01251], lr: 0.000671, loss: 0.4178
2022-10-01 08:35:39 - train: epoch 0207, iter [00450, 01251], lr: 0.000671, loss: 0.4135
2022-10-01 08:35:57 - train: epoch 0207, iter [00460, 01251], lr: 0.000671, loss: 0.4182
2022-10-01 08:36:15 - train: epoch 0207, iter [00470, 01251], lr: 0.000671, loss: 0.4077
2022-10-01 08:36:33 - train: epoch 0207, iter [00480, 01251], lr: 0.000671, loss: 0.4210
2022-10-01 08:36:50 - train: epoch 0207, iter [00490, 01251], lr: 0.000671, loss: 0.3869
2022-10-01 08:37:08 - train: epoch 0207, iter [00500, 01251], lr: 0.000671, loss: 0.4196
2022-10-01 08:37:26 - train: epoch 0207, iter [00510, 01251], lr: 0.000671, loss: 0.4145
2022-10-01 08:37:43 - train: epoch 0207, iter [00520, 01251], lr: 0.000671, loss: 0.4154
2022-10-01 08:38:01 - train: epoch 0207, iter [00530, 01251], lr: 0.000671, loss: 0.4095
2022-10-01 08:38:19 - train: epoch 0207, iter [00540, 01251], lr: 0.000671, loss: 0.4176
2022-10-01 08:38:37 - train: epoch 0207, iter [00550, 01251], lr: 0.000671, loss: 0.3924
2022-10-01 08:38:54 - train: epoch 0207, iter [00560, 01251], lr: 0.000671, loss: 0.4177
2022-10-01 08:39:12 - train: epoch 0207, iter [00570, 01251], lr: 0.000671, loss: 0.3950
2022-10-01 08:39:30 - train: epoch 0207, iter [00580, 01251], lr: 0.000671, loss: 0.3916
2022-10-01 08:39:47 - train: epoch 0207, iter [00590, 01251], lr: 0.000671, loss: 0.4040
2022-10-01 08:40:05 - train: epoch 0207, iter [00600, 01251], lr: 0.000671, loss: 0.4019
2022-10-01 08:40:23 - train: epoch 0207, iter [00610, 01251], lr: 0.000671, loss: 0.4033
2022-10-01 08:40:40 - train: epoch 0207, iter [00620, 01251], lr: 0.000671, loss: 0.4194
2022-10-01 08:40:58 - train: epoch 0207, iter [00630, 01251], lr: 0.000671, loss: 0.4224
2022-10-01 08:41:16 - train: epoch 0207, iter [00640, 01251], lr: 0.000670, loss: 0.3891
2022-10-01 08:41:34 - train: epoch 0207, iter [00650, 01251], lr: 0.000670, loss: 0.4003
2022-10-01 08:41:51 - train: epoch 0207, iter [00660, 01251], lr: 0.000670, loss: 0.4109
2022-10-01 08:42:09 - train: epoch 0207, iter [00670, 01251], lr: 0.000670, loss: 0.4224
2022-10-01 08:42:27 - train: epoch 0207, iter [00680, 01251], lr: 0.000670, loss: 0.3976
2022-10-01 08:42:44 - train: epoch 0207, iter [00690, 01251], lr: 0.000670, loss: 0.3905
2022-10-01 08:43:02 - train: epoch 0207, iter [00700, 01251], lr: 0.000670, loss: 0.4213
2022-10-01 08:43:20 - train: epoch 0207, iter [00710, 01251], lr: 0.000670, loss: 0.4223
2022-10-01 08:43:37 - train: epoch 0207, iter [00720, 01251], lr: 0.000670, loss: 0.4125
2022-10-01 08:43:55 - train: epoch 0207, iter [00730, 01251], lr: 0.000670, loss: 0.4194
2022-10-01 08:44:13 - train: epoch 0207, iter [00740, 01251], lr: 0.000670, loss: 0.3920
2022-10-01 08:44:31 - train: epoch 0207, iter [00750, 01251], lr: 0.000670, loss: 0.4092
2022-10-01 08:44:48 - train: epoch 0207, iter [00760, 01251], lr: 0.000670, loss: 0.4100
2022-10-01 08:45:06 - train: epoch 0207, iter [00770, 01251], lr: 0.000670, loss: 0.4074
2022-10-01 08:45:24 - train: epoch 0207, iter [00780, 01251], lr: 0.000670, loss: 0.3979
2022-10-01 08:45:41 - train: epoch 0207, iter [00790, 01251], lr: 0.000670, loss: 0.4014
2022-10-01 08:45:59 - train: epoch 0207, iter [00800, 01251], lr: 0.000670, loss: 0.4259
2022-10-01 08:46:17 - train: epoch 0207, iter [00810, 01251], lr: 0.000670, loss: 0.4272
2022-10-01 08:46:35 - train: epoch 0207, iter [00820, 01251], lr: 0.000670, loss: 0.3958
2022-10-01 08:46:52 - train: epoch 0207, iter [00830, 01251], lr: 0.000670, loss: 0.3959
2022-10-01 08:47:10 - train: epoch 0207, iter [00840, 01251], lr: 0.000670, loss: 0.4017
2022-10-01 08:47:28 - train: epoch 0207, iter [00850, 01251], lr: 0.000670, loss: 0.3956
2022-10-01 08:47:46 - train: epoch 0207, iter [00860, 01251], lr: 0.000670, loss: 0.4081
2022-10-01 08:48:03 - train: epoch 0207, iter [00870, 01251], lr: 0.000670, loss: 0.4010
2022-10-01 08:48:21 - train: epoch 0207, iter [00880, 01251], lr: 0.000669, loss: 0.4037
2022-10-01 08:48:39 - train: epoch 0207, iter [00890, 01251], lr: 0.000669, loss: 0.4127
2022-10-01 08:48:57 - train: epoch 0207, iter [00900, 01251], lr: 0.000669, loss: 0.4013
2022-10-01 08:49:14 - train: epoch 0207, iter [00910, 01251], lr: 0.000669, loss: 0.3932
2022-10-01 08:49:32 - train: epoch 0207, iter [00920, 01251], lr: 0.000669, loss: 0.4187
2022-10-01 08:49:49 - train: epoch 0207, iter [00930, 01251], lr: 0.000669, loss: 0.4120
2022-10-01 08:50:07 - train: epoch 0207, iter [00940, 01251], lr: 0.000669, loss: 0.4001
2022-10-01 08:50:25 - train: epoch 0207, iter [00950, 01251], lr: 0.000669, loss: 0.4024
2022-10-01 08:50:43 - train: epoch 0207, iter [00960, 01251], lr: 0.000669, loss: 0.3989
2022-10-01 08:51:00 - train: epoch 0207, iter [00970, 01251], lr: 0.000669, loss: 0.4085
2022-10-01 08:51:18 - train: epoch 0207, iter [00980, 01251], lr: 0.000669, loss: 0.4059
2022-10-01 08:51:36 - train: epoch 0207, iter [00990, 01251], lr: 0.000669, loss: 0.4089
2022-10-01 08:51:53 - train: epoch 0207, iter [01000, 01251], lr: 0.000669, loss: 0.4145
2022-10-01 08:52:11 - train: epoch 0207, iter [01010, 01251], lr: 0.000669, loss: 0.3986
2022-10-01 08:52:29 - train: epoch 0207, iter [01020, 01251], lr: 0.000669, loss: 0.4205
2022-10-01 08:52:47 - train: epoch 0207, iter [01030, 01251], lr: 0.000669, loss: 0.4118
2022-10-01 08:53:04 - train: epoch 0207, iter [01040, 01251], lr: 0.000669, loss: 0.4103
2022-10-01 08:53:22 - train: epoch 0207, iter [01050, 01251], lr: 0.000669, loss: 0.3993
2022-10-01 08:53:40 - train: epoch 0207, iter [01060, 01251], lr: 0.000669, loss: 0.4203
2022-10-01 08:53:57 - train: epoch 0207, iter [01070, 01251], lr: 0.000669, loss: 0.4126
2022-10-01 08:54:15 - train: epoch 0207, iter [01080, 01251], lr: 0.000669, loss: 0.4113
2022-10-01 08:54:33 - train: epoch 0207, iter [01090, 01251], lr: 0.000669, loss: 0.4063
2022-10-01 08:54:51 - train: epoch 0207, iter [01100, 01251], lr: 0.000669, loss: 0.3730
2022-10-01 08:55:08 - train: epoch 0207, iter [01110, 01251], lr: 0.000669, loss: 0.3926
2022-10-01 08:55:26 - train: epoch 0207, iter [01120, 01251], lr: 0.000668, loss: 0.4129
2022-10-01 08:55:44 - train: epoch 0207, iter [01130, 01251], lr: 0.000668, loss: 0.4004
2022-10-01 08:56:02 - train: epoch 0207, iter [01140, 01251], lr: 0.000668, loss: 0.4117
2022-10-01 08:56:19 - train: epoch 0207, iter [01150, 01251], lr: 0.000668, loss: 0.4131
2022-10-01 08:56:37 - train: epoch 0207, iter [01160, 01251], lr: 0.000668, loss: 0.4091
2022-10-01 08:56:55 - train: epoch 0207, iter [01170, 01251], lr: 0.000668, loss: 0.4274
2022-10-01 08:57:12 - train: epoch 0207, iter [01180, 01251], lr: 0.000668, loss: 0.4069
2022-10-01 08:57:30 - train: epoch 0207, iter [01190, 01251], lr: 0.000668, loss: 0.4061
2022-10-01 08:57:48 - train: epoch 0207, iter [01200, 01251], lr: 0.000668, loss: 0.3889
2022-10-01 08:58:05 - train: epoch 0207, iter [01210, 01251], lr: 0.000668, loss: 0.3843
2022-10-01 08:58:23 - train: epoch 0207, iter [01220, 01251], lr: 0.000668, loss: 0.4040
2022-10-01 08:58:41 - train: epoch 0207, iter [01230, 01251], lr: 0.000668, loss: 0.4140
2022-10-01 08:58:59 - train: epoch 0207, iter [01240, 01251], lr: 0.000668, loss: 0.3967
2022-10-01 08:59:16 - train: epoch 0207, iter [01250, 01251], lr: 0.000668, loss: 0.4080
2022-10-01 08:59:19 - train: epoch 207, train_loss: 0.4065
2022-10-01 08:59:22 - until epoch: 207, best_loss: 0.4065
2022-10-01 08:59:22 - epoch 208 lr: 0.000668
2022-10-01 08:59:47 - train: epoch 0208, iter [00010, 01251], lr: 0.000668, loss: 0.4194
2022-10-01 09:00:04 - train: epoch 0208, iter [00020, 01251], lr: 0.000668, loss: 0.4165
2022-10-01 09:00:22 - train: epoch 0208, iter [00030, 01251], lr: 0.000668, loss: 0.4034
2022-10-01 09:00:39 - train: epoch 0208, iter [00040, 01251], lr: 0.000668, loss: 0.4052
2022-10-01 09:00:57 - train: epoch 0208, iter [00050, 01251], lr: 0.000668, loss: 0.4131
2022-10-01 09:01:15 - train: epoch 0208, iter [00060, 01251], lr: 0.000668, loss: 0.4137
2022-10-01 09:01:33 - train: epoch 0208, iter [00070, 01251], lr: 0.000668, loss: 0.3892
2022-10-01 09:01:51 - train: epoch 0208, iter [00080, 01251], lr: 0.000668, loss: 0.4158
2022-10-01 09:02:08 - train: epoch 0208, iter [00090, 01251], lr: 0.000668, loss: 0.3718
2022-10-01 09:02:26 - train: epoch 0208, iter [00100, 01251], lr: 0.000668, loss: 0.4001
2022-10-01 09:02:44 - train: epoch 0208, iter [00110, 01251], lr: 0.000667, loss: 0.4241
2022-10-01 09:03:01 - train: epoch 0208, iter [00120, 01251], lr: 0.000667, loss: 0.3989
2022-10-01 09:03:19 - train: epoch 0208, iter [00130, 01251], lr: 0.000667, loss: 0.4096
2022-10-01 09:03:37 - train: epoch 0208, iter [00140, 01251], lr: 0.000667, loss: 0.4271
2022-10-01 09:03:54 - train: epoch 0208, iter [00150, 01251], lr: 0.000667, loss: 0.3894
2022-10-01 09:04:12 - train: epoch 0208, iter [00160, 01251], lr: 0.000667, loss: 0.3994
2022-10-01 09:04:30 - train: epoch 0208, iter [00170, 01251], lr: 0.000667, loss: 0.4329
2022-10-01 09:04:48 - train: epoch 0208, iter [00180, 01251], lr: 0.000667, loss: 0.3889
2022-10-01 09:05:05 - train: epoch 0208, iter [00190, 01251], lr: 0.000667, loss: 0.4090
2022-10-01 09:05:23 - train: epoch 0208, iter [00200, 01251], lr: 0.000667, loss: 0.3927
2022-10-01 09:05:41 - train: epoch 0208, iter [00210, 01251], lr: 0.000667, loss: 0.4139
2022-10-01 09:05:58 - train: epoch 0208, iter [00220, 01251], lr: 0.000667, loss: 0.4170
2022-10-01 09:06:16 - train: epoch 0208, iter [00230, 01251], lr: 0.000667, loss: 0.3900
2022-10-01 09:06:34 - train: epoch 0208, iter [00240, 01251], lr: 0.000667, loss: 0.4216
2022-10-01 09:06:52 - train: epoch 0208, iter [00250, 01251], lr: 0.000667, loss: 0.4210
2022-10-01 09:07:09 - train: epoch 0208, iter [00260, 01251], lr: 0.000667, loss: 0.4285
2022-10-01 09:07:27 - train: epoch 0208, iter [00270, 01251], lr: 0.000667, loss: 0.4156
2022-10-01 09:07:45 - train: epoch 0208, iter [00280, 01251], lr: 0.000667, loss: 0.4118
2022-10-01 09:08:03 - train: epoch 0208, iter [00290, 01251], lr: 0.000667, loss: 0.4155
2022-10-01 09:08:20 - train: epoch 0208, iter [00300, 01251], lr: 0.000667, loss: 0.4135
2022-10-01 09:08:38 - train: epoch 0208, iter [00310, 01251], lr: 0.000667, loss: 0.4042
2022-10-01 09:08:56 - train: epoch 0208, iter [00320, 01251], lr: 0.000667, loss: 0.4250
2022-10-01 09:09:13 - train: epoch 0208, iter [00330, 01251], lr: 0.000667, loss: 0.3948
2022-10-01 09:09:31 - train: epoch 0208, iter [00340, 01251], lr: 0.000667, loss: 0.4125
2022-10-01 09:09:49 - train: epoch 0208, iter [00350, 01251], lr: 0.000666, loss: 0.4166
2022-10-01 09:10:07 - train: epoch 0208, iter [00360, 01251], lr: 0.000666, loss: 0.4213
2022-10-01 09:10:24 - train: epoch 0208, iter [00370, 01251], lr: 0.000666, loss: 0.4211
2022-10-01 09:10:42 - train: epoch 0208, iter [00380, 01251], lr: 0.000666, loss: 0.3983
2022-10-01 09:11:00 - train: epoch 0208, iter [00390, 01251], lr: 0.000666, loss: 0.3941
2022-10-01 09:11:18 - train: epoch 0208, iter [00400, 01251], lr: 0.000666, loss: 0.3870
2022-10-01 09:11:35 - train: epoch 0208, iter [00410, 01251], lr: 0.000666, loss: 0.4152
2022-10-01 09:11:53 - train: epoch 0208, iter [00420, 01251], lr: 0.000666, loss: 0.4262
2022-10-01 09:12:11 - train: epoch 0208, iter [00430, 01251], lr: 0.000666, loss: 0.4105
2022-10-01 09:12:29 - train: epoch 0208, iter [00440, 01251], lr: 0.000666, loss: 0.4036
2022-10-01 09:12:47 - train: epoch 0208, iter [00450, 01251], lr: 0.000666, loss: 0.4175
2022-10-01 09:13:04 - train: epoch 0208, iter [00460, 01251], lr: 0.000666, loss: 0.4188
2022-10-01 09:13:22 - train: epoch 0208, iter [00470, 01251], lr: 0.000666, loss: 0.4175
2022-10-01 09:13:40 - train: epoch 0208, iter [00480, 01251], lr: 0.000666, loss: 0.4084
2022-10-01 09:13:58 - train: epoch 0208, iter [00490, 01251], lr: 0.000666, loss: 0.4299
2022-10-01 09:14:15 - train: epoch 0208, iter [00500, 01251], lr: 0.000666, loss: 0.4342
2022-10-01 09:14:33 - train: epoch 0208, iter [00510, 01251], lr: 0.000666, loss: 0.4084
2022-10-01 09:14:51 - train: epoch 0208, iter [00520, 01251], lr: 0.000666, loss: 0.4012
2022-10-01 09:15:09 - train: epoch 0208, iter [00530, 01251], lr: 0.000666, loss: 0.4049
2022-10-01 09:15:26 - train: epoch 0208, iter [00540, 01251], lr: 0.000666, loss: 0.3958
2022-10-01 09:15:44 - train: epoch 0208, iter [00550, 01251], lr: 0.000666, loss: 0.4095
2022-10-01 09:16:02 - train: epoch 0208, iter [00560, 01251], lr: 0.000666, loss: 0.4200
2022-10-01 09:16:20 - train: epoch 0208, iter [00570, 01251], lr: 0.000666, loss: 0.4007
2022-10-01 09:16:37 - train: epoch 0208, iter [00580, 01251], lr: 0.000666, loss: 0.4017
2022-10-01 09:16:55 - train: epoch 0208, iter [00590, 01251], lr: 0.000665, loss: 0.4000
2022-10-01 09:17:13 - train: epoch 0208, iter [00600, 01251], lr: 0.000665, loss: 0.4153
2022-10-01 09:17:30 - train: epoch 0208, iter [00610, 01251], lr: 0.000665, loss: 0.4064
2022-10-01 09:17:48 - train: epoch 0208, iter [00620, 01251], lr: 0.000665, loss: 0.4178
2022-10-01 09:18:05 - train: epoch 0208, iter [00630, 01251], lr: 0.000665, loss: 0.4038
2022-10-01 09:18:23 - train: epoch 0208, iter [00640, 01251], lr: 0.000665, loss: 0.4187
2022-10-01 09:18:41 - train: epoch 0208, iter [00650, 01251], lr: 0.000665, loss: 0.3929
2022-10-01 09:18:59 - train: epoch 0208, iter [00660, 01251], lr: 0.000665, loss: 0.3860
2022-10-01 09:19:16 - train: epoch 0208, iter [00670, 01251], lr: 0.000665, loss: 0.4017
2022-10-01 09:19:34 - train: epoch 0208, iter [00680, 01251], lr: 0.000665, loss: 0.4233
2022-10-01 09:19:52 - train: epoch 0208, iter [00690, 01251], lr: 0.000665, loss: 0.4028
2022-10-01 09:20:09 - train: epoch 0208, iter [00700, 01251], lr: 0.000665, loss: 0.4096
2022-10-01 09:20:27 - train: epoch 0208, iter [00710, 01251], lr: 0.000665, loss: 0.3842
2022-10-01 09:20:45 - train: epoch 0208, iter [00720, 01251], lr: 0.000665, loss: 0.4127
2022-10-01 09:21:03 - train: epoch 0208, iter [00730, 01251], lr: 0.000665, loss: 0.4056
2022-10-01 09:21:21 - train: epoch 0208, iter [00740, 01251], lr: 0.000665, loss: 0.4350
2022-10-01 09:21:39 - train: epoch 0208, iter [00750, 01251], lr: 0.000665, loss: 0.4121
2022-10-01 09:21:56 - train: epoch 0208, iter [00760, 01251], lr: 0.000665, loss: 0.4103
2022-10-01 09:22:14 - train: epoch 0208, iter [00770, 01251], lr: 0.000665, loss: 0.4470
2022-10-01 09:22:32 - train: epoch 0208, iter [00780, 01251], lr: 0.000665, loss: 0.4038
2022-10-01 09:22:49 - train: epoch 0208, iter [00790, 01251], lr: 0.000665, loss: 0.4275
2022-10-01 09:23:07 - train: epoch 0208, iter [00800, 01251], lr: 0.000665, loss: 0.4014
2022-10-01 09:23:25 - train: epoch 0208, iter [00810, 01251], lr: 0.000665, loss: 0.4051
2022-10-01 09:23:43 - train: epoch 0208, iter [00820, 01251], lr: 0.000665, loss: 0.4060
2022-10-01 09:24:01 - train: epoch 0208, iter [00830, 01251], lr: 0.000664, loss: 0.4067
2022-10-01 09:24:19 - train: epoch 0208, iter [00840, 01251], lr: 0.000664, loss: 0.3863
2022-10-01 09:24:36 - train: epoch 0208, iter [00850, 01251], lr: 0.000664, loss: 0.4133
2022-10-01 09:24:54 - train: epoch 0208, iter [00860, 01251], lr: 0.000664, loss: 0.4243
2022-10-01 09:25:12 - train: epoch 0208, iter [00870, 01251], lr: 0.000664, loss: 0.3832
2022-10-01 09:25:30 - train: epoch 0208, iter [00880, 01251], lr: 0.000664, loss: 0.4320
2022-10-01 09:25:47 - train: epoch 0208, iter [00890, 01251], lr: 0.000664, loss: 0.3983
2022-10-01 09:26:05 - train: epoch 0208, iter [00900, 01251], lr: 0.000664, loss: 0.4006
2022-10-01 09:26:23 - train: epoch 0208, iter [00910, 01251], lr: 0.000664, loss: 0.4115
2022-10-01 09:26:41 - train: epoch 0208, iter [00920, 01251], lr: 0.000664, loss: 0.4057
2022-10-01 09:26:59 - train: epoch 0208, iter [00930, 01251], lr: 0.000664, loss: 0.4092
2022-10-01 09:27:17 - train: epoch 0208, iter [00940, 01251], lr: 0.000664, loss: 0.3979
2022-10-01 09:27:35 - train: epoch 0208, iter [00950, 01251], lr: 0.000664, loss: 0.4030
2022-10-01 09:27:53 - train: epoch 0208, iter [00960, 01251], lr: 0.000664, loss: 0.4155
2022-10-01 09:28:11 - train: epoch 0208, iter [00970, 01251], lr: 0.000664, loss: 0.4155
2022-10-01 09:28:29 - train: epoch 0208, iter [00980, 01251], lr: 0.000664, loss: 0.4148
2022-10-01 09:28:47 - train: epoch 0208, iter [00990, 01251], lr: 0.000664, loss: 0.3917
2022-10-01 09:29:05 - train: epoch 0208, iter [01000, 01251], lr: 0.000664, loss: 0.3980
2022-10-01 09:29:22 - train: epoch 0208, iter [01010, 01251], lr: 0.000664, loss: 0.3826
2022-10-01 09:29:40 - train: epoch 0208, iter [01020, 01251], lr: 0.000664, loss: 0.4119
2022-10-01 09:29:58 - train: epoch 0208, iter [01030, 01251], lr: 0.000664, loss: 0.4184
2022-10-01 09:30:16 - train: epoch 0208, iter [01040, 01251], lr: 0.000664, loss: 0.4084
2022-10-01 09:30:34 - train: epoch 0208, iter [01050, 01251], lr: 0.000664, loss: 0.3909
2022-10-01 09:30:52 - train: epoch 0208, iter [01060, 01251], lr: 0.000664, loss: 0.4016
2022-10-01 09:31:10 - train: epoch 0208, iter [01070, 01251], lr: 0.000663, loss: 0.4025
2022-10-01 09:31:28 - train: epoch 0208, iter [01080, 01251], lr: 0.000663, loss: 0.3872
2022-10-01 09:31:46 - train: epoch 0208, iter [01090, 01251], lr: 0.000663, loss: 0.4224
2022-10-01 09:32:03 - train: epoch 0208, iter [01100, 01251], lr: 0.000663, loss: 0.4173
2022-10-01 09:32:21 - train: epoch 0208, iter [01110, 01251], lr: 0.000663, loss: 0.4233
2022-10-01 09:32:39 - train: epoch 0208, iter [01120, 01251], lr: 0.000663, loss: 0.4171
2022-10-01 09:32:57 - train: epoch 0208, iter [01130, 01251], lr: 0.000663, loss: 0.3913
2022-10-01 09:33:15 - train: epoch 0208, iter [01140, 01251], lr: 0.000663, loss: 0.4267
2022-10-01 09:33:33 - train: epoch 0208, iter [01150, 01251], lr: 0.000663, loss: 0.4059
2022-10-01 09:33:50 - train: epoch 0208, iter [01160, 01251], lr: 0.000663, loss: 0.3919
2022-10-01 09:34:08 - train: epoch 0208, iter [01170, 01251], lr: 0.000663, loss: 0.4167
2022-10-01 09:34:26 - train: epoch 0208, iter [01180, 01251], lr: 0.000663, loss: 0.4090
2022-10-01 09:34:44 - train: epoch 0208, iter [01190, 01251], lr: 0.000663, loss: 0.3975
2022-10-01 09:35:02 - train: epoch 0208, iter [01200, 01251], lr: 0.000663, loss: 0.3980
2022-10-01 09:35:20 - train: epoch 0208, iter [01210, 01251], lr: 0.000663, loss: 0.4136
2022-10-01 09:35:38 - train: epoch 0208, iter [01220, 01251], lr: 0.000663, loss: 0.4084
2022-10-01 09:35:56 - train: epoch 0208, iter [01230, 01251], lr: 0.000663, loss: 0.4199
2022-10-01 09:36:13 - train: epoch 0208, iter [01240, 01251], lr: 0.000663, loss: 0.4024
2022-10-01 09:36:31 - train: epoch 0208, iter [01250, 01251], lr: 0.000663, loss: 0.3938
2022-10-01 09:36:34 - train: epoch 208, train_loss: 0.4064
2022-10-01 09:36:37 - until epoch: 208, best_loss: 0.4064
2022-10-01 09:36:37 - epoch 209 lr: 0.000663
2022-10-01 09:37:02 - train: epoch 0209, iter [00010, 01251], lr: 0.000663, loss: 0.4204
2022-10-01 09:37:20 - train: epoch 0209, iter [00020, 01251], lr: 0.000663, loss: 0.4062
2022-10-01 09:37:38 - train: epoch 0209, iter [00030, 01251], lr: 0.000663, loss: 0.4094
2022-10-01 09:37:56 - train: epoch 0209, iter [00040, 01251], lr: 0.000663, loss: 0.4210
2022-10-01 09:38:13 - train: epoch 0209, iter [00050, 01251], lr: 0.000663, loss: 0.4117
2022-10-01 09:38:31 - train: epoch 0209, iter [00060, 01251], lr: 0.000662, loss: 0.3808
2022-10-01 09:38:49 - train: epoch 0209, iter [00070, 01251], lr: 0.000662, loss: 0.4119
2022-10-01 09:39:07 - train: epoch 0209, iter [00080, 01251], lr: 0.000662, loss: 0.4171
2022-10-01 09:39:25 - train: epoch 0209, iter [00090, 01251], lr: 0.000662, loss: 0.4050
2022-10-01 09:39:43 - train: epoch 0209, iter [00100, 01251], lr: 0.000662, loss: 0.3956
2022-10-01 09:40:01 - train: epoch 0209, iter [00110, 01251], lr: 0.000662, loss: 0.4074
2022-10-01 09:40:19 - train: epoch 0209, iter [00120, 01251], lr: 0.000662, loss: 0.4405
2022-10-01 09:40:37 - train: epoch 0209, iter [00130, 01251], lr: 0.000662, loss: 0.4074
2022-10-01 09:40:55 - train: epoch 0209, iter [00140, 01251], lr: 0.000662, loss: 0.3878
2022-10-01 09:41:13 - train: epoch 0209, iter [00150, 01251], lr: 0.000662, loss: 0.3920
2022-10-01 09:41:30 - train: epoch 0209, iter [00160, 01251], lr: 0.000662, loss: 0.3907
2022-10-01 09:41:48 - train: epoch 0209, iter [00170, 01251], lr: 0.000662, loss: 0.4009
2022-10-01 09:42:06 - train: epoch 0209, iter [00180, 01251], lr: 0.000662, loss: 0.4151
2022-10-01 09:42:24 - train: epoch 0209, iter [00190, 01251], lr: 0.000662, loss: 0.4103
2022-10-01 09:42:42 - train: epoch 0209, iter [00200, 01251], lr: 0.000662, loss: 0.3898
2022-10-01 09:43:00 - train: epoch 0209, iter [00210, 01251], lr: 0.000662, loss: 0.4066
2022-10-01 09:43:17 - train: epoch 0209, iter [00220, 01251], lr: 0.000662, loss: 0.4074
2022-10-01 09:43:35 - train: epoch 0209, iter [00230, 01251], lr: 0.000662, loss: 0.4143
2022-10-01 09:43:53 - train: epoch 0209, iter [00240, 01251], lr: 0.000662, loss: 0.4078
2022-10-01 09:44:11 - train: epoch 0209, iter [00250, 01251], lr: 0.000662, loss: 0.4241
2022-10-01 09:44:29 - train: epoch 0209, iter [00260, 01251], lr: 0.000662, loss: 0.3831
2022-10-01 09:44:47 - train: epoch 0209, iter [00270, 01251], lr: 0.000662, loss: 0.4042
2022-10-01 09:45:04 - train: epoch 0209, iter [00280, 01251], lr: 0.000662, loss: 0.4008
2022-10-01 09:45:22 - train: epoch 0209, iter [00290, 01251], lr: 0.000662, loss: 0.4140
2022-10-01 09:45:40 - train: epoch 0209, iter [00300, 01251], lr: 0.000661, loss: 0.4114
2022-10-01 09:45:58 - train: epoch 0209, iter [00310, 01251], lr: 0.000661, loss: 0.4045
2022-10-01 09:46:16 - train: epoch 0209, iter [00320, 01251], lr: 0.000661, loss: 0.3967
2022-10-01 09:46:34 - train: epoch 0209, iter [00330, 01251], lr: 0.000661, loss: 0.3836
2022-10-01 09:46:51 - train: epoch 0209, iter [00340, 01251], lr: 0.000661, loss: 0.4139
2022-10-01 09:47:09 - train: epoch 0209, iter [00350, 01251], lr: 0.000661, loss: 0.4213
2022-10-01 09:47:27 - train: epoch 0209, iter [00360, 01251], lr: 0.000661, loss: 0.3892
2022-10-01 09:47:45 - train: epoch 0209, iter [00370, 01251], lr: 0.000661, loss: 0.3940
2022-10-01 09:48:03 - train: epoch 0209, iter [00380, 01251], lr: 0.000661, loss: 0.4179
2022-10-01 09:48:21 - train: epoch 0209, iter [00390, 01251], lr: 0.000661, loss: 0.4003
2022-10-01 09:48:38 - train: epoch 0209, iter [00400, 01251], lr: 0.000661, loss: 0.4008
2022-10-01 09:48:57 - train: epoch 0209, iter [00410, 01251], lr: 0.000661, loss: 0.4112
2022-10-01 09:49:14 - train: epoch 0209, iter [00420, 01251], lr: 0.000661, loss: 0.3999
2022-10-01 09:49:32 - train: epoch 0209, iter [00430, 01251], lr: 0.000661, loss: 0.3993
2022-10-01 09:49:50 - train: epoch 0209, iter [00440, 01251], lr: 0.000661, loss: 0.3945
2022-10-01 09:50:08 - train: epoch 0209, iter [00450, 01251], lr: 0.000661, loss: 0.4201
2022-10-01 09:50:26 - train: epoch 0209, iter [00460, 01251], lr: 0.000661, loss: 0.4107
2022-10-01 09:50:43 - train: epoch 0209, iter [00470, 01251], lr: 0.000661, loss: 0.4114
2022-10-01 09:51:01 - train: epoch 0209, iter [00480, 01251], lr: 0.000661, loss: 0.4197
2022-10-01 09:51:19 - train: epoch 0209, iter [00490, 01251], lr: 0.000661, loss: 0.4245
2022-10-01 09:51:37 - train: epoch 0209, iter [00500, 01251], lr: 0.000661, loss: 0.4217
2022-10-01 09:51:54 - train: epoch 0209, iter [00510, 01251], lr: 0.000661, loss: 0.3990
2022-10-01 09:52:12 - train: epoch 0209, iter [00520, 01251], lr: 0.000661, loss: 0.4098
2022-10-01 09:52:30 - train: epoch 0209, iter [00530, 01251], lr: 0.000661, loss: 0.3954
2022-10-01 09:52:48 - train: epoch 0209, iter [00540, 01251], lr: 0.000660, loss: 0.4058
2022-10-01 09:53:06 - train: epoch 0209, iter [00550, 01251], lr: 0.000660, loss: 0.4354
2022-10-01 09:53:23 - train: epoch 0209, iter [00560, 01251], lr: 0.000660, loss: 0.4178
2022-10-01 09:53:41 - train: epoch 0209, iter [00570, 01251], lr: 0.000660, loss: 0.4091
2022-10-01 09:53:59 - train: epoch 0209, iter [00580, 01251], lr: 0.000660, loss: 0.4104
2022-10-01 09:54:17 - train: epoch 0209, iter [00590, 01251], lr: 0.000660, loss: 0.3953
2022-10-01 09:54:35 - train: epoch 0209, iter [00600, 01251], lr: 0.000660, loss: 0.4191
2022-10-01 09:54:52 - train: epoch 0209, iter [00610, 01251], lr: 0.000660, loss: 0.4185
2022-10-01 09:55:10 - train: epoch 0209, iter [00620, 01251], lr: 0.000660, loss: 0.4172
2022-10-01 09:55:28 - train: epoch 0209, iter [00630, 01251], lr: 0.000660, loss: 0.4105
2022-10-01 09:55:46 - train: epoch 0209, iter [00640, 01251], lr: 0.000660, loss: 0.4193
2022-10-01 09:56:04 - train: epoch 0209, iter [00650, 01251], lr: 0.000660, loss: 0.4287
2022-10-01 09:56:22 - train: epoch 0209, iter [00660, 01251], lr: 0.000660, loss: 0.4016
2022-10-01 09:56:39 - train: epoch 0209, iter [00670, 01251], lr: 0.000660, loss: 0.4333
2022-10-01 09:56:57 - train: epoch 0209, iter [00680, 01251], lr: 0.000660, loss: 0.4274
2022-10-01 09:57:15 - train: epoch 0209, iter [00690, 01251], lr: 0.000660, loss: 0.4227
2022-10-01 09:57:33 - train: epoch 0209, iter [00700, 01251], lr: 0.000660, loss: 0.4037
2022-10-01 09:57:51 - train: epoch 0209, iter [00710, 01251], lr: 0.000660, loss: 0.4040
2022-10-01 09:58:09 - train: epoch 0209, iter [00720, 01251], lr: 0.000660, loss: 0.4077
2022-10-01 09:58:26 - train: epoch 0209, iter [00730, 01251], lr: 0.000660, loss: 0.3925
2022-10-01 09:58:44 - train: epoch 0209, iter [00740, 01251], lr: 0.000660, loss: 0.3968
2022-10-01 09:59:02 - train: epoch 0209, iter [00750, 01251], lr: 0.000660, loss: 0.4147
2022-10-01 09:59:20 - train: epoch 0209, iter [00760, 01251], lr: 0.000660, loss: 0.4005
2022-10-01 09:59:38 - train: epoch 0209, iter [00770, 01251], lr: 0.000660, loss: 0.4086
2022-10-01 09:59:55 - train: epoch 0209, iter [00780, 01251], lr: 0.000659, loss: 0.4095
2022-10-01 10:00:13 - train: epoch 0209, iter [00790, 01251], lr: 0.000659, loss: 0.4097
2022-10-01 10:00:31 - train: epoch 0209, iter [00800, 01251], lr: 0.000659, loss: 0.4062
2022-10-01 10:00:49 - train: epoch 0209, iter [00810, 01251], lr: 0.000659, loss: 0.3964
2022-10-01 10:01:07 - train: epoch 0209, iter [00820, 01251], lr: 0.000659, loss: 0.3908
2022-10-01 10:01:24 - train: epoch 0209, iter [00830, 01251], lr: 0.000659, loss: 0.4157
2022-10-01 10:01:42 - train: epoch 0209, iter [00840, 01251], lr: 0.000659, loss: 0.4203
2022-10-01 10:02:00 - train: epoch 0209, iter [00850, 01251], lr: 0.000659, loss: 0.4138
2022-10-01 10:02:18 - train: epoch 0209, iter [00860, 01251], lr: 0.000659, loss: 0.3927
2022-10-01 10:02:36 - train: epoch 0209, iter [00870, 01251], lr: 0.000659, loss: 0.4078
2022-10-01 10:02:53 - train: epoch 0209, iter [00880, 01251], lr: 0.000659, loss: 0.4079
2022-10-01 10:03:11 - train: epoch 0209, iter [00890, 01251], lr: 0.000659, loss: 0.4160
2022-10-01 10:03:29 - train: epoch 0209, iter [00900, 01251], lr: 0.000659, loss: 0.3944
2022-10-01 10:03:47 - train: epoch 0209, iter [00910, 01251], lr: 0.000659, loss: 0.3941
2022-10-01 10:04:05 - train: epoch 0209, iter [00920, 01251], lr: 0.000659, loss: 0.3943
2022-10-01 10:04:23 - train: epoch 0209, iter [00930, 01251], lr: 0.000659, loss: 0.4059
2022-10-01 10:04:41 - train: epoch 0209, iter [00940, 01251], lr: 0.000659, loss: 0.3873
2022-10-01 10:04:58 - train: epoch 0209, iter [00950, 01251], lr: 0.000659, loss: 0.3925
2022-10-01 10:05:16 - train: epoch 0209, iter [00960, 01251], lr: 0.000659, loss: 0.4138
2022-10-01 10:05:34 - train: epoch 0209, iter [00970, 01251], lr: 0.000659, loss: 0.3787
2022-10-01 10:05:52 - train: epoch 0209, iter [00980, 01251], lr: 0.000659, loss: 0.4104
2022-10-01 10:06:10 - train: epoch 0209, iter [00990, 01251], lr: 0.000659, loss: 0.4184
2022-10-01 10:06:28 - train: epoch 0209, iter [01000, 01251], lr: 0.000659, loss: 0.4273
2022-10-01 10:06:45 - train: epoch 0209, iter [01010, 01251], lr: 0.000659, loss: 0.4209
2022-10-01 10:07:03 - train: epoch 0209, iter [01020, 01251], lr: 0.000658, loss: 0.4141
2022-10-01 10:07:21 - train: epoch 0209, iter [01030, 01251], lr: 0.000658, loss: 0.4038
2022-10-01 10:07:39 - train: epoch 0209, iter [01040, 01251], lr: 0.000658, loss: 0.4165
2022-10-01 10:07:56 - train: epoch 0209, iter [01050, 01251], lr: 0.000658, loss: 0.3972
2022-10-01 10:08:14 - train: epoch 0209, iter [01060, 01251], lr: 0.000658, loss: 0.4045
2022-10-01 10:08:32 - train: epoch 0209, iter [01070, 01251], lr: 0.000658, loss: 0.3944
2022-10-01 10:08:50 - train: epoch 0209, iter [01080, 01251], lr: 0.000658, loss: 0.4026
2022-10-01 10:09:08 - train: epoch 0209, iter [01090, 01251], lr: 0.000658, loss: 0.4033
2022-10-01 10:09:26 - train: epoch 0209, iter [01100, 01251], lr: 0.000658, loss: 0.3938
2022-10-01 10:09:43 - train: epoch 0209, iter [01110, 01251], lr: 0.000658, loss: 0.4169
2022-10-01 10:10:01 - train: epoch 0209, iter [01120, 01251], lr: 0.000658, loss: 0.3968
2022-10-01 10:10:19 - train: epoch 0209, iter [01130, 01251], lr: 0.000658, loss: 0.4070
2022-10-01 10:10:37 - train: epoch 0209, iter [01140, 01251], lr: 0.000658, loss: 0.4128
2022-10-01 10:10:55 - train: epoch 0209, iter [01150, 01251], lr: 0.000658, loss: 0.4145
2022-10-01 10:11:13 - train: epoch 0209, iter [01160, 01251], lr: 0.000658, loss: 0.4244
2022-10-01 10:11:31 - train: epoch 0209, iter [01170, 01251], lr: 0.000658, loss: 0.4083
2022-10-01 10:11:48 - train: epoch 0209, iter [01180, 01251], lr: 0.000658, loss: 0.4046
2022-10-01 10:12:06 - train: epoch 0209, iter [01190, 01251], lr: 0.000658, loss: 0.4141
2022-10-01 10:12:24 - train: epoch 0209, iter [01200, 01251], lr: 0.000658, loss: 0.3885
2022-10-01 10:12:42 - train: epoch 0209, iter [01210, 01251], lr: 0.000658, loss: 0.4222
2022-10-01 10:13:00 - train: epoch 0209, iter [01220, 01251], lr: 0.000658, loss: 0.4230
2022-10-01 10:13:17 - train: epoch 0209, iter [01230, 01251], lr: 0.000658, loss: 0.4194
2022-10-01 10:13:35 - train: epoch 0209, iter [01240, 01251], lr: 0.000658, loss: 0.4214
2022-10-01 10:13:53 - train: epoch 0209, iter [01250, 01251], lr: 0.000658, loss: 0.3876
2022-10-01 10:13:56 - train: epoch 209, train_loss: 0.4064
2022-10-01 10:13:59 - until epoch: 209, best_loss: 0.4064
2022-10-01 10:13:59 - epoch 210 lr: 0.000658
2022-10-01 10:14:23 - train: epoch 0210, iter [00010, 01251], lr: 0.000657, loss: 0.4230
2022-10-01 10:14:42 - train: epoch 0210, iter [00020, 01251], lr: 0.000657, loss: 0.4089
2022-10-01 10:14:59 - train: epoch 0210, iter [00030, 01251], lr: 0.000657, loss: 0.4242
2022-10-01 10:15:17 - train: epoch 0210, iter [00040, 01251], lr: 0.000657, loss: 0.3915
2022-10-01 10:15:35 - train: epoch 0210, iter [00050, 01251], lr: 0.000657, loss: 0.4042
2022-10-01 10:15:53 - train: epoch 0210, iter [00060, 01251], lr: 0.000657, loss: 0.4097
2022-10-01 10:16:11 - train: epoch 0210, iter [00070, 01251], lr: 0.000657, loss: 0.4114
2022-10-01 10:16:29 - train: epoch 0210, iter [00080, 01251], lr: 0.000657, loss: 0.3914
2022-10-01 10:16:47 - train: epoch 0210, iter [00090, 01251], lr: 0.000657, loss: 0.3932
2022-10-01 10:17:04 - train: epoch 0210, iter [00100, 01251], lr: 0.000657, loss: 0.3882
2022-10-01 10:17:23 - train: epoch 0210, iter [00110, 01251], lr: 0.000657, loss: 0.3866
2022-10-01 10:17:41 - train: epoch 0210, iter [00120, 01251], lr: 0.000657, loss: 0.3915
2022-10-01 10:17:58 - train: epoch 0210, iter [00130, 01251], lr: 0.000657, loss: 0.4128
2022-10-01 10:18:16 - train: epoch 0210, iter [00140, 01251], lr: 0.000657, loss: 0.4099
2022-10-01 10:18:34 - train: epoch 0210, iter [00150, 01251], lr: 0.000657, loss: 0.4079
2022-10-01 10:18:52 - train: epoch 0210, iter [00160, 01251], lr: 0.000657, loss: 0.4060
2022-10-01 10:19:10 - train: epoch 0210, iter [00170, 01251], lr: 0.000657, loss: 0.4109
2022-10-01 10:19:28 - train: epoch 0210, iter [00180, 01251], lr: 0.000657, loss: 0.4080
2022-10-01 10:19:45 - train: epoch 0210, iter [00190, 01251], lr: 0.000657, loss: 0.4113
2022-10-01 10:20:03 - train: epoch 0210, iter [00200, 01251], lr: 0.000657, loss: 0.4114
2022-10-01 10:20:21 - train: epoch 0210, iter [00210, 01251], lr: 0.000657, loss: 0.4139
2022-10-01 10:20:39 - train: epoch 0210, iter [00220, 01251], lr: 0.000657, loss: 0.4248
2022-10-01 10:20:57 - train: epoch 0210, iter [00230, 01251], lr: 0.000657, loss: 0.4192
2022-10-01 10:21:15 - train: epoch 0210, iter [00240, 01251], lr: 0.000657, loss: 0.4268
2022-10-01 10:21:33 - train: epoch 0210, iter [00250, 01251], lr: 0.000656, loss: 0.4129
2022-10-01 10:21:51 - train: epoch 0210, iter [00260, 01251], lr: 0.000656, loss: 0.3985
2022-10-01 10:22:09 - train: epoch 0210, iter [00270, 01251], lr: 0.000656, loss: 0.4090
2022-10-01 10:22:27 - train: epoch 0210, iter [00280, 01251], lr: 0.000656, loss: 0.4110
2022-10-01 10:22:44 - train: epoch 0210, iter [00290, 01251], lr: 0.000656, loss: 0.3939
2022-10-01 10:23:02 - train: epoch 0210, iter [00300, 01251], lr: 0.000656, loss: 0.4106
2022-10-01 10:23:20 - train: epoch 0210, iter [00310, 01251], lr: 0.000656, loss: 0.4096
2022-10-01 10:23:38 - train: epoch 0210, iter [00320, 01251], lr: 0.000656, loss: 0.3906
2022-10-01 10:23:56 - train: epoch 0210, iter [00330, 01251], lr: 0.000656, loss: 0.4099
2022-10-01 10:24:13 - train: epoch 0210, iter [00340, 01251], lr: 0.000656, loss: 0.4015
2022-10-01 10:24:31 - train: epoch 0210, iter [00350, 01251], lr: 0.000656, loss: 0.4059
2022-10-01 10:24:49 - train: epoch 0210, iter [00360, 01251], lr: 0.000656, loss: 0.4127
2022-10-01 10:25:07 - train: epoch 0210, iter [00370, 01251], lr: 0.000656, loss: 0.4052
2022-10-01 10:25:25 - train: epoch 0210, iter [00380, 01251], lr: 0.000656, loss: 0.4192
2022-10-01 10:25:43 - train: epoch 0210, iter [00390, 01251], lr: 0.000656, loss: 0.4097
2022-10-01 10:26:01 - train: epoch 0210, iter [00400, 01251], lr: 0.000656, loss: 0.4455
2022-10-01 10:26:19 - train: epoch 0210, iter [00410, 01251], lr: 0.000656, loss: 0.4039
2022-10-01 10:26:37 - train: epoch 0210, iter [00420, 01251], lr: 0.000656, loss: 0.4101
2022-10-01 10:26:54 - train: epoch 0210, iter [00430, 01251], lr: 0.000656, loss: 0.4183
2022-10-01 10:27:12 - train: epoch 0210, iter [00440, 01251], lr: 0.000656, loss: 0.4074
2022-10-01 10:27:30 - train: epoch 0210, iter [00450, 01251], lr: 0.000656, loss: 0.4111
2022-10-01 10:27:48 - train: epoch 0210, iter [00460, 01251], lr: 0.000656, loss: 0.4177
2022-10-01 10:28:06 - train: epoch 0210, iter [00470, 01251], lr: 0.000656, loss: 0.3804
2022-10-01 10:28:24 - train: epoch 0210, iter [00480, 01251], lr: 0.000656, loss: 0.3840
2022-10-01 10:28:41 - train: epoch 0210, iter [00490, 01251], lr: 0.000655, loss: 0.4126
2022-10-01 10:28:59 - train: epoch 0210, iter [00500, 01251], lr: 0.000655, loss: 0.3920
2022-10-01 10:29:17 - train: epoch 0210, iter [00510, 01251], lr: 0.000655, loss: 0.3840
2022-10-01 10:29:35 - train: epoch 0210, iter [00520, 01251], lr: 0.000655, loss: 0.4137
2022-10-01 10:29:53 - train: epoch 0210, iter [00530, 01251], lr: 0.000655, loss: 0.4133
2022-10-01 10:30:11 - train: epoch 0210, iter [00540, 01251], lr: 0.000655, loss: 0.3987
2022-10-01 10:30:29 - train: epoch 0210, iter [00550, 01251], lr: 0.000655, loss: 0.3997
2022-10-01 10:30:46 - train: epoch 0210, iter [00560, 01251], lr: 0.000655, loss: 0.3916
2022-10-01 10:31:04 - train: epoch 0210, iter [00570, 01251], lr: 0.000655, loss: 0.4025
2022-10-01 10:31:22 - train: epoch 0210, iter [00580, 01251], lr: 0.000655, loss: 0.4156
2022-10-01 10:31:40 - train: epoch 0210, iter [00590, 01251], lr: 0.000655, loss: 0.4134
2022-10-01 10:31:58 - train: epoch 0210, iter [00600, 01251], lr: 0.000655, loss: 0.4065
2022-10-01 10:32:16 - train: epoch 0210, iter [00610, 01251], lr: 0.000655, loss: 0.3922
2022-10-01 10:32:34 - train: epoch 0210, iter [00620, 01251], lr: 0.000655, loss: 0.4019
2022-10-01 10:32:51 - train: epoch 0210, iter [00630, 01251], lr: 0.000655, loss: 0.4004
2022-10-01 10:33:09 - train: epoch 0210, iter [00640, 01251], lr: 0.000655, loss: 0.4204
2022-10-01 10:33:27 - train: epoch 0210, iter [00650, 01251], lr: 0.000655, loss: 0.4018
2022-10-01 10:33:45 - train: epoch 0210, iter [00660, 01251], lr: 0.000655, loss: 0.4025
2022-10-01 10:34:03 - train: epoch 0210, iter [00670, 01251], lr: 0.000655, loss: 0.3897
2022-10-01 10:34:21 - train: epoch 0210, iter [00680, 01251], lr: 0.000655, loss: 0.4138
2022-10-01 10:34:39 - train: epoch 0210, iter [00690, 01251], lr: 0.000655, loss: 0.4058
2022-10-01 10:34:57 - train: epoch 0210, iter [00700, 01251], lr: 0.000655, loss: 0.3972
2022-10-01 10:35:15 - train: epoch 0210, iter [00710, 01251], lr: 0.000655, loss: 0.4268
2022-10-01 10:35:33 - train: epoch 0210, iter [00720, 01251], lr: 0.000655, loss: 0.4101
2022-10-01 10:35:51 - train: epoch 0210, iter [00730, 01251], lr: 0.000654, loss: 0.3998
2022-10-01 10:36:09 - train: epoch 0210, iter [00740, 01251], lr: 0.000654, loss: 0.4112
2022-10-01 10:36:27 - train: epoch 0210, iter [00750, 01251], lr: 0.000654, loss: 0.3943
2022-10-01 10:36:45 - train: epoch 0210, iter [00760, 01251], lr: 0.000654, loss: 0.4246
2022-10-01 10:37:03 - train: epoch 0210, iter [00770, 01251], lr: 0.000654, loss: 0.4048
2022-10-01 10:37:21 - train: epoch 0210, iter [00780, 01251], lr: 0.000654, loss: 0.4198
2022-10-01 10:37:39 - train: epoch 0210, iter [00790, 01251], lr: 0.000654, loss: 0.4150
2022-10-01 10:37:57 - train: epoch 0210, iter [00800, 01251], lr: 0.000654, loss: 0.4143
2022-10-01 10:38:15 - train: epoch 0210, iter [00810, 01251], lr: 0.000654, loss: 0.3984
2022-10-01 10:38:33 - train: epoch 0210, iter [00820, 01251], lr: 0.000654, loss: 0.4006
2022-10-01 10:38:51 - train: epoch 0210, iter [00830, 01251], lr: 0.000654, loss: 0.4076
2022-10-01 10:39:09 - train: epoch 0210, iter [00840, 01251], lr: 0.000654, loss: 0.4044
2022-10-01 10:39:27 - train: epoch 0210, iter [00850, 01251], lr: 0.000654, loss: 0.4264
2022-10-01 10:39:45 - train: epoch 0210, iter [00860, 01251], lr: 0.000654, loss: 0.4106
2022-10-01 10:40:03 - train: epoch 0210, iter [00870, 01251], lr: 0.000654, loss: 0.3892
2022-10-01 10:40:21 - train: epoch 0210, iter [00880, 01251], lr: 0.000654, loss: 0.4080
2022-10-01 10:40:39 - train: epoch 0210, iter [00890, 01251], lr: 0.000654, loss: 0.4225
2022-10-01 10:40:57 - train: epoch 0210, iter [00900, 01251], lr: 0.000654, loss: 0.4086
2022-10-01 10:41:15 - train: epoch 0210, iter [00910, 01251], lr: 0.000654, loss: 0.4268
2022-10-01 10:41:33 - train: epoch 0210, iter [00920, 01251], lr: 0.000654, loss: 0.4086
2022-10-01 10:41:52 - train: epoch 0210, iter [00930, 01251], lr: 0.000654, loss: 0.4088
2022-10-01 10:42:10 - train: epoch 0210, iter [00940, 01251], lr: 0.000654, loss: 0.3843
2022-10-01 10:42:27 - train: epoch 0210, iter [00950, 01251], lr: 0.000654, loss: 0.4075
2022-10-01 10:42:46 - train: epoch 0210, iter [00960, 01251], lr: 0.000654, loss: 0.3962
2022-10-01 10:43:04 - train: epoch 0210, iter [00970, 01251], lr: 0.000653, loss: 0.3925
2022-10-01 10:43:22 - train: epoch 0210, iter [00980, 01251], lr: 0.000653, loss: 0.4008
2022-10-01 10:43:40 - train: epoch 0210, iter [00990, 01251], lr: 0.000653, loss: 0.3879
2022-10-01 10:43:58 - train: epoch 0210, iter [01000, 01251], lr: 0.000653, loss: 0.4120
2022-10-01 10:44:16 - train: epoch 0210, iter [01010, 01251], lr: 0.000653, loss: 0.3920
2022-10-01 10:44:34 - train: epoch 0210, iter [01020, 01251], lr: 0.000653, loss: 0.3941
2022-10-01 10:44:52 - train: epoch 0210, iter [01030, 01251], lr: 0.000653, loss: 0.3999
2022-10-01 10:45:10 - train: epoch 0210, iter [01040, 01251], lr: 0.000653, loss: 0.4012
2022-10-01 10:45:28 - train: epoch 0210, iter [01050, 01251], lr: 0.000653, loss: 0.4188
2022-10-01 10:45:46 - train: epoch 0210, iter [01060, 01251], lr: 0.000653, loss: 0.4100
2022-10-01 10:46:04 - train: epoch 0210, iter [01070, 01251], lr: 0.000653, loss: 0.4098
2022-10-01 10:46:22 - train: epoch 0210, iter [01080, 01251], lr: 0.000653, loss: 0.4048
2022-10-01 10:46:41 - train: epoch 0210, iter [01090, 01251], lr: 0.000653, loss: 0.4025
2022-10-01 10:46:58 - train: epoch 0210, iter [01100, 01251], lr: 0.000653, loss: 0.4072
2022-10-01 10:47:17 - train: epoch 0210, iter [01110, 01251], lr: 0.000653, loss: 0.3950
2022-10-01 10:47:35 - train: epoch 0210, iter [01120, 01251], lr: 0.000653, loss: 0.4013
2022-10-01 10:47:53 - train: epoch 0210, iter [01130, 01251], lr: 0.000653, loss: 0.3930
2022-10-01 10:48:11 - train: epoch 0210, iter [01140, 01251], lr: 0.000653, loss: 0.4281
2022-10-01 10:48:29 - train: epoch 0210, iter [01150, 01251], lr: 0.000653, loss: 0.4149
2022-10-01 10:48:47 - train: epoch 0210, iter [01160, 01251], lr: 0.000653, loss: 0.4093
2022-10-01 10:49:05 - train: epoch 0210, iter [01170, 01251], lr: 0.000653, loss: 0.3931
2022-10-01 10:49:23 - train: epoch 0210, iter [01180, 01251], lr: 0.000653, loss: 0.4133
2022-10-01 10:49:41 - train: epoch 0210, iter [01190, 01251], lr: 0.000653, loss: 0.4044
2022-10-01 10:49:59 - train: epoch 0210, iter [01200, 01251], lr: 0.000653, loss: 0.4124
2022-10-01 10:50:18 - train: epoch 0210, iter [01210, 01251], lr: 0.000652, loss: 0.3963
2022-10-01 10:50:36 - train: epoch 0210, iter [01220, 01251], lr: 0.000652, loss: 0.4005
2022-10-01 10:50:54 - train: epoch 0210, iter [01230, 01251], lr: 0.000652, loss: 0.4176
2022-10-01 10:51:12 - train: epoch 0210, iter [01240, 01251], lr: 0.000652, loss: 0.4009
2022-10-01 10:51:29 - train: epoch 0210, iter [01250, 01251], lr: 0.000652, loss: 0.4075
2022-10-01 10:51:33 - train: epoch 210, train_loss: 0.4063
2022-10-01 10:51:36 - until epoch: 210, best_loss: 0.4063
2022-10-01 10:51:36 - epoch 211 lr: 0.000652
2022-10-01 10:52:00 - train: epoch 0211, iter [00010, 01251], lr: 0.000652, loss: 0.4246
2022-10-01 10:52:18 - train: epoch 0211, iter [00020, 01251], lr: 0.000652, loss: 0.4204
2022-10-01 10:52:36 - train: epoch 0211, iter [00030, 01251], lr: 0.000652, loss: 0.4096
2022-10-01 10:52:53 - train: epoch 0211, iter [00040, 01251], lr: 0.000652, loss: 0.4002
2022-10-01 10:53:11 - train: epoch 0211, iter [00050, 01251], lr: 0.000652, loss: 0.3869
2022-10-01 10:53:29 - train: epoch 0211, iter [00060, 01251], lr: 0.000652, loss: 0.3863
2022-10-01 10:53:47 - train: epoch 0211, iter [00070, 01251], lr: 0.000652, loss: 0.4402
2022-10-01 10:54:05 - train: epoch 0211, iter [00080, 01251], lr: 0.000652, loss: 0.3945
2022-10-01 10:54:24 - train: epoch 0211, iter [00090, 01251], lr: 0.000652, loss: 0.4004
2022-10-01 10:54:42 - train: epoch 0211, iter [00100, 01251], lr: 0.000652, loss: 0.4063
2022-10-01 10:55:00 - train: epoch 0211, iter [00110, 01251], lr: 0.000652, loss: 0.4106
2022-10-01 10:55:18 - train: epoch 0211, iter [00120, 01251], lr: 0.000652, loss: 0.4089
2022-10-01 10:55:35 - train: epoch 0211, iter [00130, 01251], lr: 0.000652, loss: 0.4017
2022-10-01 10:55:53 - train: epoch 0211, iter [00140, 01251], lr: 0.000652, loss: 0.4117
2022-10-01 10:56:11 - train: epoch 0211, iter [00150, 01251], lr: 0.000652, loss: 0.4220
2022-10-01 10:56:29 - train: epoch 0211, iter [00160, 01251], lr: 0.000652, loss: 0.4290
2022-10-01 10:56:47 - train: epoch 0211, iter [00170, 01251], lr: 0.000652, loss: 0.3968
2022-10-01 10:57:05 - train: epoch 0211, iter [00180, 01251], lr: 0.000652, loss: 0.4180
2022-10-01 10:57:23 - train: epoch 0211, iter [00190, 01251], lr: 0.000652, loss: 0.3943
2022-10-01 10:57:41 - train: epoch 0211, iter [00200, 01251], lr: 0.000651, loss: 0.4129
2022-10-01 10:57:59 - train: epoch 0211, iter [00210, 01251], lr: 0.000651, loss: 0.4058
2022-10-01 10:58:18 - train: epoch 0211, iter [00220, 01251], lr: 0.000651, loss: 0.4097
2022-10-01 10:58:35 - train: epoch 0211, iter [00230, 01251], lr: 0.000651, loss: 0.3832
2022-10-01 10:58:54 - train: epoch 0211, iter [00240, 01251], lr: 0.000651, loss: 0.3941
2022-10-01 10:59:12 - train: epoch 0211, iter [00250, 01251], lr: 0.000651, loss: 0.4052
2022-10-01 10:59:29 - train: epoch 0211, iter [00260, 01251], lr: 0.000651, loss: 0.3994
2022-10-01 10:59:48 - train: epoch 0211, iter [00270, 01251], lr: 0.000651, loss: 0.3932
2022-10-01 11:00:06 - train: epoch 0211, iter [00280, 01251], lr: 0.000651, loss: 0.4019
2022-10-01 11:00:23 - train: epoch 0211, iter [00290, 01251], lr: 0.000651, loss: 0.3882
2022-10-01 11:00:41 - train: epoch 0211, iter [00300, 01251], lr: 0.000651, loss: 0.4055
2022-10-01 11:00:59 - train: epoch 0211, iter [00310, 01251], lr: 0.000651, loss: 0.4025
2022-10-01 11:01:17 - train: epoch 0211, iter [00320, 01251], lr: 0.000651, loss: 0.4026
2022-10-01 11:01:35 - train: epoch 0211, iter [00330, 01251], lr: 0.000651, loss: 0.4276
2022-10-01 11:01:53 - train: epoch 0211, iter [00340, 01251], lr: 0.000651, loss: 0.4001
2022-10-01 11:02:11 - train: epoch 0211, iter [00350, 01251], lr: 0.000651, loss: 0.3856
2022-10-01 11:02:29 - train: epoch 0211, iter [00360, 01251], lr: 0.000651, loss: 0.4173
2022-10-01 11:02:47 - train: epoch 0211, iter [00370, 01251], lr: 0.000651, loss: 0.4052
2022-10-01 11:03:05 - train: epoch 0211, iter [00380, 01251], lr: 0.000651, loss: 0.4150
2022-10-01 11:03:23 - train: epoch 0211, iter [00390, 01251], lr: 0.000651, loss: 0.4194
2022-10-01 11:03:41 - train: epoch 0211, iter [00400, 01251], lr: 0.000651, loss: 0.3977
2022-10-01 11:03:59 - train: epoch 0211, iter [00410, 01251], lr: 0.000651, loss: 0.4077
2022-10-01 11:04:17 - train: epoch 0211, iter [00420, 01251], lr: 0.000651, loss: 0.4166
2022-10-01 11:04:34 - train: epoch 0211, iter [00430, 01251], lr: 0.000651, loss: 0.4170
2022-10-01 11:04:52 - train: epoch 0211, iter [00440, 01251], lr: 0.000650, loss: 0.3976
2022-10-01 11:05:10 - train: epoch 0211, iter [00450, 01251], lr: 0.000650, loss: 0.3960
2022-10-01 11:05:28 - train: epoch 0211, iter [00460, 01251], lr: 0.000650, loss: 0.3976
2022-10-01 11:05:46 - train: epoch 0211, iter [00470, 01251], lr: 0.000650, loss: 0.4176
2022-10-01 11:06:04 - train: epoch 0211, iter [00480, 01251], lr: 0.000650, loss: 0.4029
2022-10-01 11:06:22 - train: epoch 0211, iter [00490, 01251], lr: 0.000650, loss: 0.4023
2022-10-01 11:06:40 - train: epoch 0211, iter [00500, 01251], lr: 0.000650, loss: 0.4099
2022-10-01 11:06:58 - train: epoch 0211, iter [00510, 01251], lr: 0.000650, loss: 0.4261
2022-10-01 11:07:16 - train: epoch 0211, iter [00520, 01251], lr: 0.000650, loss: 0.4165
2022-10-01 11:07:35 - train: epoch 0211, iter [00530, 01251], lr: 0.000650, loss: 0.4086
2022-10-01 11:07:53 - train: epoch 0211, iter [00540, 01251], lr: 0.000650, loss: 0.3958
2022-10-01 11:08:11 - train: epoch 0211, iter [00550, 01251], lr: 0.000650, loss: 0.3985
2022-10-01 11:08:29 - train: epoch 0211, iter [00560, 01251], lr: 0.000650, loss: 0.4111
2022-10-01 11:08:47 - train: epoch 0211, iter [00570, 01251], lr: 0.000650, loss: 0.4094
2022-10-01 11:09:04 - train: epoch 0211, iter [00580, 01251], lr: 0.000650, loss: 0.4020
2022-10-01 11:09:22 - train: epoch 0211, iter [00590, 01251], lr: 0.000650, loss: 0.4198
2022-10-01 11:09:40 - train: epoch 0211, iter [00600, 01251], lr: 0.000650, loss: 0.4184
2022-10-01 11:09:58 - train: epoch 0211, iter [00610, 01251], lr: 0.000650, loss: 0.4058
2022-10-01 11:10:16 - train: epoch 0211, iter [00620, 01251], lr: 0.000650, loss: 0.3875
2022-10-01 11:10:34 - train: epoch 0211, iter [00630, 01251], lr: 0.000650, loss: 0.4043
2022-10-01 11:10:52 - train: epoch 0211, iter [00640, 01251], lr: 0.000650, loss: 0.3889
2022-10-01 11:11:10 - train: epoch 0211, iter [00650, 01251], lr: 0.000650, loss: 0.4184
2022-10-01 11:11:28 - train: epoch 0211, iter [00660, 01251], lr: 0.000650, loss: 0.4073
2022-10-01 11:11:46 - train: epoch 0211, iter [00670, 01251], lr: 0.000649, loss: 0.4103
2022-10-01 11:12:04 - train: epoch 0211, iter [00680, 01251], lr: 0.000649, loss: 0.4030
2022-10-01 11:12:22 - train: epoch 0211, iter [00690, 01251], lr: 0.000649, loss: 0.4010
2022-10-01 11:12:40 - train: epoch 0211, iter [00700, 01251], lr: 0.000649, loss: 0.4043
2022-10-01 11:12:58 - train: epoch 0211, iter [00710, 01251], lr: 0.000649, loss: 0.4210
2022-10-01 11:13:16 - train: epoch 0211, iter [00720, 01251], lr: 0.000649, loss: 0.4310
2022-10-01 11:13:34 - train: epoch 0211, iter [00730, 01251], lr: 0.000649, loss: 0.4013
2022-10-01 11:13:52 - train: epoch 0211, iter [00740, 01251], lr: 0.000649, loss: 0.4161
2022-10-01 11:14:10 - train: epoch 0211, iter [00750, 01251], lr: 0.000649, loss: 0.4032
2022-10-01 11:14:28 - train: epoch 0211, iter [00760, 01251], lr: 0.000649, loss: 0.4121
2022-10-01 11:14:46 - train: epoch 0211, iter [00770, 01251], lr: 0.000649, loss: 0.4098
2022-10-01 11:15:04 - train: epoch 0211, iter [00780, 01251], lr: 0.000649, loss: 0.3914
2022-10-01 11:15:22 - train: epoch 0211, iter [00790, 01251], lr: 0.000649, loss: 0.4158
2022-10-01 11:15:40 - train: epoch 0211, iter [00800, 01251], lr: 0.000649, loss: 0.4117
2022-10-01 11:15:58 - train: epoch 0211, iter [00810, 01251], lr: 0.000649, loss: 0.3938
2022-10-01 11:16:16 - train: epoch 0211, iter [00820, 01251], lr: 0.000649, loss: 0.3918
2022-10-01 11:16:35 - train: epoch 0211, iter [00830, 01251], lr: 0.000649, loss: 0.4133
2022-10-01 11:16:53 - train: epoch 0211, iter [00840, 01251], lr: 0.000649, loss: 0.3921
2022-10-01 11:17:11 - train: epoch 0211, iter [00850, 01251], lr: 0.000649, loss: 0.4135
2022-10-01 11:17:29 - train: epoch 0211, iter [00860, 01251], lr: 0.000649, loss: 0.4156
2022-10-01 11:17:47 - train: epoch 0211, iter [00870, 01251], lr: 0.000649, loss: 0.3926
2022-10-01 11:18:04 - train: epoch 0211, iter [00880, 01251], lr: 0.000649, loss: 0.3862
2022-10-01 11:18:23 - train: epoch 0211, iter [00890, 01251], lr: 0.000649, loss: 0.3963
2022-10-01 11:18:40 - train: epoch 0211, iter [00900, 01251], lr: 0.000649, loss: 0.4044
2022-10-01 11:18:58 - train: epoch 0211, iter [00910, 01251], lr: 0.000648, loss: 0.3875
2022-10-01 11:19:17 - train: epoch 0211, iter [00920, 01251], lr: 0.000648, loss: 0.4165
2022-10-01 11:19:35 - train: epoch 0211, iter [00930, 01251], lr: 0.000648, loss: 0.3786
2022-10-01 11:19:53 - train: epoch 0211, iter [00940, 01251], lr: 0.000648, loss: 0.3800
2022-10-01 11:20:11 - train: epoch 0211, iter [00950, 01251], lr: 0.000648, loss: 0.4120
2022-10-01 11:20:29 - train: epoch 0211, iter [00960, 01251], lr: 0.000648, loss: 0.4116
2022-10-01 11:20:47 - train: epoch 0211, iter [00970, 01251], lr: 0.000648, loss: 0.4157
2022-10-01 11:21:05 - train: epoch 0211, iter [00980, 01251], lr: 0.000648, loss: 0.4203
2022-10-01 11:21:23 - train: epoch 0211, iter [00990, 01251], lr: 0.000648, loss: 0.4139
2022-10-01 11:21:41 - train: epoch 0211, iter [01000, 01251], lr: 0.000648, loss: 0.4157
2022-10-01 11:21:58 - train: epoch 0211, iter [01010, 01251], lr: 0.000648, loss: 0.4089
2022-10-01 11:22:16 - train: epoch 0211, iter [01020, 01251], lr: 0.000648, loss: 0.4251
2022-10-01 11:22:35 - train: epoch 0211, iter [01030, 01251], lr: 0.000648, loss: 0.3836
2022-10-01 11:22:53 - train: epoch 0211, iter [01040, 01251], lr: 0.000648, loss: 0.4261
2022-10-01 11:23:11 - train: epoch 0211, iter [01050, 01251], lr: 0.000648, loss: 0.4095
2022-10-01 11:23:29 - train: epoch 0211, iter [01060, 01251], lr: 0.000648, loss: 0.4155
2022-10-01 11:23:47 - train: epoch 0211, iter [01070, 01251], lr: 0.000648, loss: 0.4093
2022-10-01 11:24:05 - train: epoch 0211, iter [01080, 01251], lr: 0.000648, loss: 0.4064
2022-10-01 11:24:23 - train: epoch 0211, iter [01090, 01251], lr: 0.000648, loss: 0.3969
2022-10-01 11:24:41 - train: epoch 0211, iter [01100, 01251], lr: 0.000648, loss: 0.4131
2022-10-01 11:24:59 - train: epoch 0211, iter [01110, 01251], lr: 0.000648, loss: 0.3955
2022-10-01 11:25:17 - train: epoch 0211, iter [01120, 01251], lr: 0.000648, loss: 0.3960
2022-10-01 11:25:35 - train: epoch 0211, iter [01130, 01251], lr: 0.000648, loss: 0.4062
2022-10-01 11:25:53 - train: epoch 0211, iter [01140, 01251], lr: 0.000648, loss: 0.3953
2022-10-01 11:26:11 - train: epoch 0211, iter [01150, 01251], lr: 0.000647, loss: 0.4092
2022-10-01 11:26:29 - train: epoch 0211, iter [01160, 01251], lr: 0.000647, loss: 0.3926
2022-10-01 11:26:47 - train: epoch 0211, iter [01170, 01251], lr: 0.000647, loss: 0.4187
2022-10-01 11:27:05 - train: epoch 0211, iter [01180, 01251], lr: 0.000647, loss: 0.3887
2022-10-01 11:27:24 - train: epoch 0211, iter [01190, 01251], lr: 0.000647, loss: 0.3835
2022-10-01 11:27:42 - train: epoch 0211, iter [01200, 01251], lr: 0.000647, loss: 0.4306
2022-10-01 11:28:00 - train: epoch 0211, iter [01210, 01251], lr: 0.000647, loss: 0.4020
2022-10-01 11:28:18 - train: epoch 0211, iter [01220, 01251], lr: 0.000647, loss: 0.4004
2022-10-01 11:28:36 - train: epoch 0211, iter [01230, 01251], lr: 0.000647, loss: 0.4222
2022-10-01 11:28:54 - train: epoch 0211, iter [01240, 01251], lr: 0.000647, loss: 0.4157
2022-10-01 11:29:11 - train: epoch 0211, iter [01250, 01251], lr: 0.000647, loss: 0.4012
2022-10-01 11:29:14 - train: epoch 211, train_loss: 0.4062
2022-10-01 11:29:17 - until epoch: 211, best_loss: 0.4062
2022-10-01 11:29:17 - epoch 212 lr: 0.000647
2022-10-01 11:29:42 - train: epoch 0212, iter [00010, 01251], lr: 0.000647, loss: 0.3954
2022-10-01 11:30:00 - train: epoch 0212, iter [00020, 01251], lr: 0.000647, loss: 0.3964
2022-10-01 11:30:18 - train: epoch 0212, iter [00030, 01251], lr: 0.000647, loss: 0.3899
2022-10-01 11:30:35 - train: epoch 0212, iter [00040, 01251], lr: 0.000647, loss: 0.4153
2022-10-01 11:30:53 - train: epoch 0212, iter [00050, 01251], lr: 0.000647, loss: 0.4053
2022-10-01 11:31:11 - train: epoch 0212, iter [00060, 01251], lr: 0.000647, loss: 0.4014
2022-10-01 11:31:29 - train: epoch 0212, iter [00070, 01251], lr: 0.000647, loss: 0.4080
2022-10-01 11:31:47 - train: epoch 0212, iter [00080, 01251], lr: 0.000647, loss: 0.4009
2022-10-01 11:32:05 - train: epoch 0212, iter [00090, 01251], lr: 0.000647, loss: 0.3882
2022-10-01 11:32:23 - train: epoch 0212, iter [00100, 01251], lr: 0.000647, loss: 0.3873
2022-10-01 11:32:42 - train: epoch 0212, iter [00110, 01251], lr: 0.000647, loss: 0.3989
2022-10-01 11:33:00 - train: epoch 0212, iter [00120, 01251], lr: 0.000647, loss: 0.4110
2022-10-01 11:33:17 - train: epoch 0212, iter [00130, 01251], lr: 0.000647, loss: 0.4219
2022-10-01 11:33:35 - train: epoch 0212, iter [00140, 01251], lr: 0.000646, loss: 0.3961
2022-10-01 11:33:53 - train: epoch 0212, iter [00150, 01251], lr: 0.000646, loss: 0.3981
2022-10-01 11:34:11 - train: epoch 0212, iter [00160, 01251], lr: 0.000646, loss: 0.4204
2022-10-01 11:34:29 - train: epoch 0212, iter [00170, 01251], lr: 0.000646, loss: 0.4160
2022-10-01 11:34:47 - train: epoch 0212, iter [00180, 01251], lr: 0.000646, loss: 0.4107
2022-10-01 11:35:05 - train: epoch 0212, iter [00190, 01251], lr: 0.000646, loss: 0.4173
2022-10-01 11:35:24 - train: epoch 0212, iter [00200, 01251], lr: 0.000646, loss: 0.4021
2022-10-01 11:35:42 - train: epoch 0212, iter [00210, 01251], lr: 0.000646, loss: 0.3916
2022-10-01 11:36:00 - train: epoch 0212, iter [00220, 01251], lr: 0.000646, loss: 0.4031
2022-10-01 11:36:18 - train: epoch 0212, iter [00230, 01251], lr: 0.000646, loss: 0.4040
2022-10-01 11:36:36 - train: epoch 0212, iter [00240, 01251], lr: 0.000646, loss: 0.3973
2022-10-01 11:36:54 - train: epoch 0212, iter [00250, 01251], lr: 0.000646, loss: 0.4048
2022-10-01 11:37:12 - train: epoch 0212, iter [00260, 01251], lr: 0.000646, loss: 0.4173
2022-10-01 11:37:30 - train: epoch 0212, iter [00270, 01251], lr: 0.000646, loss: 0.4084
2022-10-01 11:37:48 - train: epoch 0212, iter [00280, 01251], lr: 0.000646, loss: 0.4082
2022-10-01 11:38:06 - train: epoch 0212, iter [00290, 01251], lr: 0.000646, loss: 0.3979
2022-10-01 11:38:24 - train: epoch 0212, iter [00300, 01251], lr: 0.000646, loss: 0.4049
2022-10-01 11:38:41 - train: epoch 0212, iter [00310, 01251], lr: 0.000646, loss: 0.4022
2022-10-01 11:39:00 - train: epoch 0212, iter [00320, 01251], lr: 0.000646, loss: 0.4008
2022-10-01 11:39:18 - train: epoch 0212, iter [00330, 01251], lr: 0.000646, loss: 0.4018
2022-10-01 11:39:36 - train: epoch 0212, iter [00340, 01251], lr: 0.000646, loss: 0.4156
2022-10-01 11:39:54 - train: epoch 0212, iter [00350, 01251], lr: 0.000646, loss: 0.4070
2022-10-01 11:40:12 - train: epoch 0212, iter [00360, 01251], lr: 0.000646, loss: 0.4269
2022-10-01 11:40:30 - train: epoch 0212, iter [00370, 01251], lr: 0.000646, loss: 0.3757
2022-10-01 11:40:48 - train: epoch 0212, iter [00380, 01251], lr: 0.000645, loss: 0.3898
2022-10-01 11:41:06 - train: epoch 0212, iter [00390, 01251], lr: 0.000645, loss: 0.4099
2022-10-01 11:41:24 - train: epoch 0212, iter [00400, 01251], lr: 0.000645, loss: 0.4163
2022-10-01 11:41:42 - train: epoch 0212, iter [00410, 01251], lr: 0.000645, loss: 0.4098
2022-10-01 11:42:00 - train: epoch 0212, iter [00420, 01251], lr: 0.000645, loss: 0.4284
2022-10-01 11:42:18 - train: epoch 0212, iter [00430, 01251], lr: 0.000645, loss: 0.4166
2022-10-01 11:42:36 - train: epoch 0212, iter [00440, 01251], lr: 0.000645, loss: 0.4142
2022-10-01 11:42:54 - train: epoch 0212, iter [00450, 01251], lr: 0.000645, loss: 0.4112
2022-10-01 11:43:12 - train: epoch 0212, iter [00460, 01251], lr: 0.000645, loss: 0.4162
2022-10-01 11:43:30 - train: epoch 0212, iter [00470, 01251], lr: 0.000645, loss: 0.3970
2022-10-01 11:43:48 - train: epoch 0212, iter [00480, 01251], lr: 0.000645, loss: 0.4176
2022-10-01 11:44:05 - train: epoch 0212, iter [00490, 01251], lr: 0.000645, loss: 0.4112
2022-10-01 11:44:23 - train: epoch 0212, iter [00500, 01251], lr: 0.000645, loss: 0.4051
2022-10-01 11:44:41 - train: epoch 0212, iter [00510, 01251], lr: 0.000645, loss: 0.3985
2022-10-01 11:44:59 - train: epoch 0212, iter [00520, 01251], lr: 0.000645, loss: 0.4049
2022-10-01 11:45:17 - train: epoch 0212, iter [00530, 01251], lr: 0.000645, loss: 0.3920
2022-10-01 11:45:35 - train: epoch 0212, iter [00540, 01251], lr: 0.000645, loss: 0.4070
2022-10-01 11:45:53 - train: epoch 0212, iter [00550, 01251], lr: 0.000645, loss: 0.4051
2022-10-01 11:46:11 - train: epoch 0212, iter [00560, 01251], lr: 0.000645, loss: 0.4002
2022-10-01 11:46:29 - train: epoch 0212, iter [00570, 01251], lr: 0.000645, loss: 0.3986
2022-10-01 11:46:47 - train: epoch 0212, iter [00580, 01251], lr: 0.000645, loss: 0.4079
2022-10-01 11:47:05 - train: epoch 0212, iter [00590, 01251], lr: 0.000645, loss: 0.4008
2022-10-01 11:47:23 - train: epoch 0212, iter [00600, 01251], lr: 0.000645, loss: 0.4073
2022-10-01 11:47:41 - train: epoch 0212, iter [00610, 01251], lr: 0.000645, loss: 0.3984
2022-10-01 11:47:59 - train: epoch 0212, iter [00620, 01251], lr: 0.000644, loss: 0.4008
2022-10-01 11:48:17 - train: epoch 0212, iter [00630, 01251], lr: 0.000644, loss: 0.4022
2022-10-01 11:48:35 - train: epoch 0212, iter [00640, 01251], lr: 0.000644, loss: 0.4064
2022-10-01 11:48:53 - train: epoch 0212, iter [00650, 01251], lr: 0.000644, loss: 0.4152
2022-10-01 11:49:11 - train: epoch 0212, iter [00660, 01251], lr: 0.000644, loss: 0.3955
2022-10-01 11:49:29 - train: epoch 0212, iter [00670, 01251], lr: 0.000644, loss: 0.4114
2022-10-01 11:49:47 - train: epoch 0212, iter [00680, 01251], lr: 0.000644, loss: 0.4108
2022-10-01 11:50:05 - train: epoch 0212, iter [00690, 01251], lr: 0.000644, loss: 0.3883
2022-10-01 11:50:23 - train: epoch 0212, iter [00700, 01251], lr: 0.000644, loss: 0.4134
2022-10-01 11:50:41 - train: epoch 0212, iter [00710, 01251], lr: 0.000644, loss: 0.4152
2022-10-01 11:50:59 - train: epoch 0212, iter [00720, 01251], lr: 0.000644, loss: 0.4159
2022-10-01 11:51:17 - train: epoch 0212, iter [00730, 01251], lr: 0.000644, loss: 0.3954
2022-10-01 11:51:35 - train: epoch 0212, iter [00740, 01251], lr: 0.000644, loss: 0.4061
2022-10-01 11:51:53 - train: epoch 0212, iter [00750, 01251], lr: 0.000644, loss: 0.4192
2022-10-01 11:52:11 - train: epoch 0212, iter [00760, 01251], lr: 0.000644, loss: 0.4010
2022-10-01 11:52:29 - train: epoch 0212, iter [00770, 01251], lr: 0.000644, loss: 0.4103
2022-10-01 11:52:47 - train: epoch 0212, iter [00780, 01251], lr: 0.000644, loss: 0.4080
2022-10-01 11:53:05 - train: epoch 0212, iter [00790, 01251], lr: 0.000644, loss: 0.4046
2022-10-01 11:53:23 - train: epoch 0212, iter [00800, 01251], lr: 0.000644, loss: 0.4147
2022-10-01 11:53:41 - train: epoch 0212, iter [00810, 01251], lr: 0.000644, loss: 0.4061
2022-10-01 11:53:59 - train: epoch 0212, iter [00820, 01251], lr: 0.000644, loss: 0.4039
2022-10-01 11:54:17 - train: epoch 0212, iter [00830, 01251], lr: 0.000644, loss: 0.4006
2022-10-01 11:54:35 - train: epoch 0212, iter [00840, 01251], lr: 0.000644, loss: 0.4239
2022-10-01 11:54:53 - train: epoch 0212, iter [00850, 01251], lr: 0.000644, loss: 0.4191
2022-10-01 11:55:11 - train: epoch 0212, iter [00860, 01251], lr: 0.000643, loss: 0.3991
2022-10-01 11:55:29 - train: epoch 0212, iter [00870, 01251], lr: 0.000643, loss: 0.4210
2022-10-01 11:55:47 - train: epoch 0212, iter [00880, 01251], lr: 0.000643, loss: 0.4036
2022-10-01 11:56:05 - train: epoch 0212, iter [00890, 01251], lr: 0.000643, loss: 0.4306
2022-10-01 11:56:23 - train: epoch 0212, iter [00900, 01251], lr: 0.000643, loss: 0.4151
2022-10-01 11:56:41 - train: epoch 0212, iter [00910, 01251], lr: 0.000643, loss: 0.4104
2022-10-01 11:56:59 - train: epoch 0212, iter [00920, 01251], lr: 0.000643, loss: 0.4000
2022-10-01 11:57:17 - train: epoch 0212, iter [00930, 01251], lr: 0.000643, loss: 0.4123
2022-10-01 11:57:35 - train: epoch 0212, iter [00940, 01251], lr: 0.000643, loss: 0.4036
2022-10-01 11:57:53 - train: epoch 0212, iter [00950, 01251], lr: 0.000643, loss: 0.4101
2022-10-01 11:58:11 - train: epoch 0212, iter [00960, 01251], lr: 0.000643, loss: 0.3946
2022-10-01 11:58:29 - train: epoch 0212, iter [00970, 01251], lr: 0.000643, loss: 0.3958
2022-10-01 11:58:47 - train: epoch 0212, iter [00980, 01251], lr: 0.000643, loss: 0.4320
2022-10-01 11:59:05 - train: epoch 0212, iter [00990, 01251], lr: 0.000643, loss: 0.4249
2022-10-01 11:59:23 - train: epoch 0212, iter [01000, 01251], lr: 0.000643, loss: 0.4119
2022-10-01 11:59:41 - train: epoch 0212, iter [01010, 01251], lr: 0.000643, loss: 0.4235
2022-10-01 11:59:59 - train: epoch 0212, iter [01020, 01251], lr: 0.000643, loss: 0.4068
2022-10-01 12:00:17 - train: epoch 0212, iter [01030, 01251], lr: 0.000643, loss: 0.3989
2022-10-01 12:00:35 - train: epoch 0212, iter [01040, 01251], lr: 0.000643, loss: 0.4010
2022-10-01 12:00:53 - train: epoch 0212, iter [01050, 01251], lr: 0.000643, loss: 0.4166
2022-10-01 12:01:11 - train: epoch 0212, iter [01060, 01251], lr: 0.000643, loss: 0.3946
2022-10-01 12:01:28 - train: epoch 0212, iter [01070, 01251], lr: 0.000643, loss: 0.4057
2022-10-01 12:01:46 - train: epoch 0212, iter [01080, 01251], lr: 0.000643, loss: 0.3824
2022-10-01 12:02:04 - train: epoch 0212, iter [01090, 01251], lr: 0.000643, loss: 0.3858
2022-10-01 12:02:22 - train: epoch 0212, iter [01100, 01251], lr: 0.000642, loss: 0.4215
2022-10-01 12:02:40 - train: epoch 0212, iter [01110, 01251], lr: 0.000642, loss: 0.4055
2022-10-01 12:02:58 - train: epoch 0212, iter [01120, 01251], lr: 0.000642, loss: 0.4052
2022-10-01 12:03:16 - train: epoch 0212, iter [01130, 01251], lr: 0.000642, loss: 0.4171
2022-10-01 12:03:34 - train: epoch 0212, iter [01140, 01251], lr: 0.000642, loss: 0.4213
2022-10-01 12:03:52 - train: epoch 0212, iter [01150, 01251], lr: 0.000642, loss: 0.3976
2022-10-01 12:04:10 - train: epoch 0212, iter [01160, 01251], lr: 0.000642, loss: 0.4149
2022-10-01 12:04:29 - train: epoch 0212, iter [01170, 01251], lr: 0.000642, loss: 0.3929
2022-10-01 12:04:47 - train: epoch 0212, iter [01180, 01251], lr: 0.000642, loss: 0.4205
2022-10-01 12:05:05 - train: epoch 0212, iter [01190, 01251], lr: 0.000642, loss: 0.3987
2022-10-01 12:05:22 - train: epoch 0212, iter [01200, 01251], lr: 0.000642, loss: 0.4126
2022-10-01 12:05:41 - train: epoch 0212, iter [01210, 01251], lr: 0.000642, loss: 0.4011
2022-10-01 12:05:59 - train: epoch 0212, iter [01220, 01251], lr: 0.000642, loss: 0.3861
2022-10-01 12:06:17 - train: epoch 0212, iter [01230, 01251], lr: 0.000642, loss: 0.4203
2022-10-01 12:06:35 - train: epoch 0212, iter [01240, 01251], lr: 0.000642, loss: 0.4068
2022-10-01 12:06:53 - train: epoch 0212, iter [01250, 01251], lr: 0.000642, loss: 0.4017
2022-10-01 12:06:56 - train: epoch 212, train_loss: 0.4061
2022-10-01 12:06:59 - until epoch: 212, best_loss: 0.4061
2022-10-01 12:06:59 - epoch 213 lr: 0.000642
2022-10-01 12:07:24 - train: epoch 0213, iter [00010, 01251], lr: 0.000642, loss: 0.4377
2022-10-01 12:07:42 - train: epoch 0213, iter [00020, 01251], lr: 0.000642, loss: 0.4233
2022-10-01 12:08:00 - train: epoch 0213, iter [00030, 01251], lr: 0.000642, loss: 0.4169
2022-10-01 12:08:18 - train: epoch 0213, iter [00040, 01251], lr: 0.000642, loss: 0.4321
2022-10-01 12:08:36 - train: epoch 0213, iter [00050, 01251], lr: 0.000642, loss: 0.4116
2022-10-01 12:08:53 - train: epoch 0213, iter [00060, 01251], lr: 0.000642, loss: 0.4259
2022-10-01 12:09:12 - train: epoch 0213, iter [00070, 01251], lr: 0.000642, loss: 0.4193
2022-10-01 12:09:30 - train: epoch 0213, iter [00080, 01251], lr: 0.000642, loss: 0.4167
2022-10-01 12:09:48 - train: epoch 0213, iter [00090, 01251], lr: 0.000641, loss: 0.4005
2022-10-01 12:10:07 - train: epoch 0213, iter [00100, 01251], lr: 0.000641, loss: 0.3886
2022-10-01 12:10:25 - train: epoch 0213, iter [00110, 01251], lr: 0.000641, loss: 0.4106
2022-10-01 12:10:43 - train: epoch 0213, iter [00120, 01251], lr: 0.000641, loss: 0.4020
2022-10-01 12:11:01 - train: epoch 0213, iter [00130, 01251], lr: 0.000641, loss: 0.4154
2022-10-01 12:11:19 - train: epoch 0213, iter [00140, 01251], lr: 0.000641, loss: 0.4115
2022-10-01 12:11:38 - train: epoch 0213, iter [00150, 01251], lr: 0.000641, loss: 0.4114
2022-10-01 12:11:56 - train: epoch 0213, iter [00160, 01251], lr: 0.000641, loss: 0.4092
2022-10-01 12:12:14 - train: epoch 0213, iter [00170, 01251], lr: 0.000641, loss: 0.4186
2022-10-01 12:12:32 - train: epoch 0213, iter [00180, 01251], lr: 0.000641, loss: 0.3941
2022-10-01 12:12:50 - train: epoch 0213, iter [00190, 01251], lr: 0.000641, loss: 0.4074
2022-10-01 12:13:08 - train: epoch 0213, iter [00200, 01251], lr: 0.000641, loss: 0.4109
2022-10-01 12:13:27 - train: epoch 0213, iter [00210, 01251], lr: 0.000641, loss: 0.4007
2022-10-01 12:13:45 - train: epoch 0213, iter [00220, 01251], lr: 0.000641, loss: 0.4124
2022-10-01 12:14:03 - train: epoch 0213, iter [00230, 01251], lr: 0.000641, loss: 0.4069
2022-10-01 12:14:22 - train: epoch 0213, iter [00240, 01251], lr: 0.000641, loss: 0.4150
2022-10-01 12:14:40 - train: epoch 0213, iter [00250, 01251], lr: 0.000641, loss: 0.4068
2022-10-01 12:14:58 - train: epoch 0213, iter [00260, 01251], lr: 0.000641, loss: 0.4086
2022-10-01 12:15:16 - train: epoch 0213, iter [00270, 01251], lr: 0.000641, loss: 0.3979
2022-10-01 12:15:35 - train: epoch 0213, iter [00280, 01251], lr: 0.000641, loss: 0.4015
2022-10-01 12:15:53 - train: epoch 0213, iter [00290, 01251], lr: 0.000641, loss: 0.4008
2022-10-01 12:16:11 - train: epoch 0213, iter [00300, 01251], lr: 0.000641, loss: 0.4211
2022-10-01 12:16:30 - train: epoch 0213, iter [00310, 01251], lr: 0.000641, loss: 0.4270
2022-10-01 12:16:48 - train: epoch 0213, iter [00320, 01251], lr: 0.000641, loss: 0.3956
2022-10-01 12:17:06 - train: epoch 0213, iter [00330, 01251], lr: 0.000640, loss: 0.4231
2022-10-01 12:17:24 - train: epoch 0213, iter [00340, 01251], lr: 0.000640, loss: 0.3891
2022-10-01 12:17:42 - train: epoch 0213, iter [00350, 01251], lr: 0.000640, loss: 0.3886
2022-10-01 12:18:01 - train: epoch 0213, iter [00360, 01251], lr: 0.000640, loss: 0.4138
2022-10-01 12:18:19 - train: epoch 0213, iter [00370, 01251], lr: 0.000640, loss: 0.4157
2022-10-01 12:18:38 - train: epoch 0213, iter [00380, 01251], lr: 0.000640, loss: 0.4017
2022-10-01 12:18:56 - train: epoch 0213, iter [00390, 01251], lr: 0.000640, loss: 0.4211
2022-10-01 12:19:15 - train: epoch 0213, iter [00400, 01251], lr: 0.000640, loss: 0.4075
2022-10-01 12:19:33 - train: epoch 0213, iter [00410, 01251], lr: 0.000640, loss: 0.4189
2022-10-01 12:19:51 - train: epoch 0213, iter [00420, 01251], lr: 0.000640, loss: 0.4185
2022-10-01 12:20:09 - train: epoch 0213, iter [00430, 01251], lr: 0.000640, loss: 0.4275
2022-10-01 12:20:27 - train: epoch 0213, iter [00440, 01251], lr: 0.000640, loss: 0.4019
2022-10-01 12:20:45 - train: epoch 0213, iter [00450, 01251], lr: 0.000640, loss: 0.4031
2022-10-01 12:21:03 - train: epoch 0213, iter [00460, 01251], lr: 0.000640, loss: 0.4198
2022-10-01 12:21:21 - train: epoch 0213, iter [00470, 01251], lr: 0.000640, loss: 0.4090
2022-10-01 12:21:40 - train: epoch 0213, iter [00480, 01251], lr: 0.000640, loss: 0.4034
2022-10-01 12:21:58 - train: epoch 0213, iter [00490, 01251], lr: 0.000640, loss: 0.4222
2022-10-01 12:22:16 - train: epoch 0213, iter [00500, 01251], lr: 0.000640, loss: 0.4164
2022-10-01 12:22:34 - train: epoch 0213, iter [00510, 01251], lr: 0.000640, loss: 0.4085
2022-10-01 12:22:52 - train: epoch 0213, iter [00520, 01251], lr: 0.000640, loss: 0.3945
2022-10-01 12:23:11 - train: epoch 0213, iter [00530, 01251], lr: 0.000640, loss: 0.4169
2022-10-01 12:23:29 - train: epoch 0213, iter [00540, 01251], lr: 0.000640, loss: 0.4157
2022-10-01 12:23:47 - train: epoch 0213, iter [00550, 01251], lr: 0.000640, loss: 0.4085
2022-10-01 12:24:05 - train: epoch 0213, iter [00560, 01251], lr: 0.000640, loss: 0.4173
2022-10-01 12:24:23 - train: epoch 0213, iter [00570, 01251], lr: 0.000639, loss: 0.4037
2022-10-01 12:24:41 - train: epoch 0213, iter [00580, 01251], lr: 0.000639, loss: 0.4069
2022-10-01 12:24:59 - train: epoch 0213, iter [00590, 01251], lr: 0.000639, loss: 0.4104
2022-10-01 12:25:18 - train: epoch 0213, iter [00600, 01251], lr: 0.000639, loss: 0.3864
2022-10-01 12:25:35 - train: epoch 0213, iter [00610, 01251], lr: 0.000639, loss: 0.4033
2022-10-01 12:25:53 - train: epoch 0213, iter [00620, 01251], lr: 0.000639, loss: 0.4133
2022-10-01 12:26:12 - train: epoch 0213, iter [00630, 01251], lr: 0.000639, loss: 0.4112
2022-10-01 12:26:30 - train: epoch 0213, iter [00640, 01251], lr: 0.000639, loss: 0.4124
2022-10-01 12:26:48 - train: epoch 0213, iter [00650, 01251], lr: 0.000639, loss: 0.3964
2022-10-01 12:27:06 - train: epoch 0213, iter [00660, 01251], lr: 0.000639, loss: 0.3979
2022-10-01 12:27:24 - train: epoch 0213, iter [00670, 01251], lr: 0.000639, loss: 0.4178
2022-10-01 12:27:43 - train: epoch 0213, iter [00680, 01251], lr: 0.000639, loss: 0.4009
2022-10-01 12:28:01 - train: epoch 0213, iter [00690, 01251], lr: 0.000639, loss: 0.4032
2022-10-01 12:28:18 - train: epoch 0213, iter [00700, 01251], lr: 0.000639, loss: 0.3950
2022-10-01 12:28:36 - train: epoch 0213, iter [00710, 01251], lr: 0.000639, loss: 0.4202
2022-10-01 12:28:55 - train: epoch 0213, iter [00720, 01251], lr: 0.000639, loss: 0.4151
2022-10-01 12:29:13 - train: epoch 0213, iter [00730, 01251], lr: 0.000639, loss: 0.4285
2022-10-01 12:29:31 - train: epoch 0213, iter [00740, 01251], lr: 0.000639, loss: 0.3862
2022-10-01 12:29:49 - train: epoch 0213, iter [00750, 01251], lr: 0.000639, loss: 0.4070
2022-10-01 12:30:07 - train: epoch 0213, iter [00760, 01251], lr: 0.000639, loss: 0.4081
2022-10-01 12:30:25 - train: epoch 0213, iter [00770, 01251], lr: 0.000639, loss: 0.3881
2022-10-01 12:30:43 - train: epoch 0213, iter [00780, 01251], lr: 0.000639, loss: 0.4224
2022-10-01 12:31:01 - train: epoch 0213, iter [00790, 01251], lr: 0.000639, loss: 0.4037
2022-10-01 12:31:19 - train: epoch 0213, iter [00800, 01251], lr: 0.000639, loss: 0.3897
2022-10-01 12:31:38 - train: epoch 0213, iter [00810, 01251], lr: 0.000638, loss: 0.3978
2022-10-01 12:31:56 - train: epoch 0213, iter [00820, 01251], lr: 0.000638, loss: 0.3937
2022-10-01 12:32:14 - train: epoch 0213, iter [00830, 01251], lr: 0.000638, loss: 0.3953
2022-10-01 12:32:32 - train: epoch 0213, iter [00840, 01251], lr: 0.000638, loss: 0.4122
2022-10-01 12:32:50 - train: epoch 0213, iter [00850, 01251], lr: 0.000638, loss: 0.4110
2022-10-01 12:33:08 - train: epoch 0213, iter [00860, 01251], lr: 0.000638, loss: 0.4310
2022-10-01 12:33:26 - train: epoch 0213, iter [00870, 01251], lr: 0.000638, loss: 0.4046
2022-10-01 12:33:44 - train: epoch 0213, iter [00880, 01251], lr: 0.000638, loss: 0.3834
2022-10-01 12:34:02 - train: epoch 0213, iter [00890, 01251], lr: 0.000638, loss: 0.4083
2022-10-01 12:34:20 - train: epoch 0213, iter [00900, 01251], lr: 0.000638, loss: 0.3894
2022-10-01 12:34:38 - train: epoch 0213, iter [00910, 01251], lr: 0.000638, loss: 0.4096
2022-10-01 12:34:56 - train: epoch 0213, iter [00920, 01251], lr: 0.000638, loss: 0.4158
2022-10-01 12:35:14 - train: epoch 0213, iter [00930, 01251], lr: 0.000638, loss: 0.4078
2022-10-01 12:35:32 - train: epoch 0213, iter [00940, 01251], lr: 0.000638, loss: 0.4158
2022-10-01 12:35:50 - train: epoch 0213, iter [00950, 01251], lr: 0.000638, loss: 0.3846
2022-10-01 12:36:08 - train: epoch 0213, iter [00960, 01251], lr: 0.000638, loss: 0.4083
2022-10-01 12:36:26 - train: epoch 0213, iter [00970, 01251], lr: 0.000638, loss: 0.3941
2022-10-01 12:36:44 - train: epoch 0213, iter [00980, 01251], lr: 0.000638, loss: 0.4193
2022-10-01 12:37:02 - train: epoch 0213, iter [00990, 01251], lr: 0.000638, loss: 0.3952
2022-10-01 12:37:20 - train: epoch 0213, iter [01000, 01251], lr: 0.000638, loss: 0.4008
2022-10-01 12:37:38 - train: epoch 0213, iter [01010, 01251], lr: 0.000638, loss: 0.4286
2022-10-01 12:37:56 - train: epoch 0213, iter [01020, 01251], lr: 0.000638, loss: 0.4178
2022-10-01 12:38:14 - train: epoch 0213, iter [01030, 01251], lr: 0.000638, loss: 0.4133
2022-10-01 12:38:32 - train: epoch 0213, iter [01040, 01251], lr: 0.000638, loss: 0.4174
2022-10-01 12:38:50 - train: epoch 0213, iter [01050, 01251], lr: 0.000637, loss: 0.4102
2022-10-01 12:39:08 - train: epoch 0213, iter [01060, 01251], lr: 0.000637, loss: 0.4061
2022-10-01 12:39:25 - train: epoch 0213, iter [01070, 01251], lr: 0.000637, loss: 0.4150
2022-10-01 12:39:43 - train: epoch 0213, iter [01080, 01251], lr: 0.000637, loss: 0.4132
2022-10-01 12:40:01 - train: epoch 0213, iter [01090, 01251], lr: 0.000637, loss: 0.3944
2022-10-01 12:40:19 - train: epoch 0213, iter [01100, 01251], lr: 0.000637, loss: 0.4077
2022-10-01 12:40:37 - train: epoch 0213, iter [01110, 01251], lr: 0.000637, loss: 0.4216
2022-10-01 12:40:56 - train: epoch 0213, iter [01120, 01251], lr: 0.000637, loss: 0.4022
2022-10-01 12:41:13 - train: epoch 0213, iter [01130, 01251], lr: 0.000637, loss: 0.4130
2022-10-01 12:41:32 - train: epoch 0213, iter [01140, 01251], lr: 0.000637, loss: 0.4054
2022-10-01 12:41:49 - train: epoch 0213, iter [01150, 01251], lr: 0.000637, loss: 0.4162
2022-10-01 12:42:08 - train: epoch 0213, iter [01160, 01251], lr: 0.000637, loss: 0.3946
2022-10-01 12:42:26 - train: epoch 0213, iter [01170, 01251], lr: 0.000637, loss: 0.4176
2022-10-01 12:42:44 - train: epoch 0213, iter [01180, 01251], lr: 0.000637, loss: 0.3829
2022-10-01 12:43:02 - train: epoch 0213, iter [01190, 01251], lr: 0.000637, loss: 0.4260
2022-10-01 12:43:20 - train: epoch 0213, iter [01200, 01251], lr: 0.000637, loss: 0.4197
2022-10-01 12:43:38 - train: epoch 0213, iter [01210, 01251], lr: 0.000637, loss: 0.4291
2022-10-01 12:43:55 - train: epoch 0213, iter [01220, 01251], lr: 0.000637, loss: 0.3997
2022-10-01 12:44:13 - train: epoch 0213, iter [01230, 01251], lr: 0.000637, loss: 0.4107
2022-10-01 12:44:31 - train: epoch 0213, iter [01240, 01251], lr: 0.000637, loss: 0.4045
2022-10-01 12:44:49 - train: epoch 0213, iter [01250, 01251], lr: 0.000637, loss: 0.4062
2022-10-01 12:44:52 - train: epoch 213, train_loss: 0.4060
2022-10-01 12:44:55 - until epoch: 213, best_loss: 0.4060
2022-10-01 12:44:55 - epoch 214 lr: 0.000637
2022-10-01 12:45:19 - train: epoch 0214, iter [00010, 01251], lr: 0.000637, loss: 0.4015
2022-10-01 12:45:37 - train: epoch 0214, iter [00020, 01251], lr: 0.000637, loss: 0.4007
2022-10-01 12:45:55 - train: epoch 0214, iter [00030, 01251], lr: 0.000637, loss: 0.3973
2022-10-01 12:46:13 - train: epoch 0214, iter [00040, 01251], lr: 0.000636, loss: 0.4102
2022-10-01 12:46:31 - train: epoch 0214, iter [00050, 01251], lr: 0.000636, loss: 0.4213
2022-10-01 12:46:49 - train: epoch 0214, iter [00060, 01251], lr: 0.000636, loss: 0.3841
2022-10-01 12:47:07 - train: epoch 0214, iter [00070, 01251], lr: 0.000636, loss: 0.4011
2022-10-01 12:47:25 - train: epoch 0214, iter [00080, 01251], lr: 0.000636, loss: 0.4016
2022-10-01 12:47:43 - train: epoch 0214, iter [00090, 01251], lr: 0.000636, loss: 0.4010
2022-10-01 12:48:01 - train: epoch 0214, iter [00100, 01251], lr: 0.000636, loss: 0.3942
2022-10-01 12:48:19 - train: epoch 0214, iter [00110, 01251], lr: 0.000636, loss: 0.3982
2022-10-01 12:48:37 - train: epoch 0214, iter [00120, 01251], lr: 0.000636, loss: 0.4012
2022-10-01 12:48:55 - train: epoch 0214, iter [00130, 01251], lr: 0.000636, loss: 0.3995
2022-10-01 12:49:13 - train: epoch 0214, iter [00140, 01251], lr: 0.000636, loss: 0.3859
2022-10-01 12:49:31 - train: epoch 0214, iter [00150, 01251], lr: 0.000636, loss: 0.4266
2022-10-01 12:49:49 - train: epoch 0214, iter [00160, 01251], lr: 0.000636, loss: 0.4033
2022-10-01 12:50:07 - train: epoch 0214, iter [00170, 01251], lr: 0.000636, loss: 0.3995
2022-10-01 12:50:25 - train: epoch 0214, iter [00180, 01251], lr: 0.000636, loss: 0.3998
2022-10-01 12:50:43 - train: epoch 0214, iter [00190, 01251], lr: 0.000636, loss: 0.4059
2022-10-01 12:51:00 - train: epoch 0214, iter [00200, 01251], lr: 0.000636, loss: 0.3988
2022-10-01 12:51:18 - train: epoch 0214, iter [00210, 01251], lr: 0.000636, loss: 0.4227
2022-10-01 12:51:36 - train: epoch 0214, iter [00220, 01251], lr: 0.000636, loss: 0.4275
2022-10-01 12:51:54 - train: epoch 0214, iter [00230, 01251], lr: 0.000636, loss: 0.4108
2022-10-01 12:52:12 - train: epoch 0214, iter [00240, 01251], lr: 0.000636, loss: 0.4024
2022-10-01 12:52:30 - train: epoch 0214, iter [00250, 01251], lr: 0.000636, loss: 0.4184
2022-10-01 12:52:48 - train: epoch 0214, iter [00260, 01251], lr: 0.000636, loss: 0.3955
2022-10-01 12:53:06 - train: epoch 0214, iter [00270, 01251], lr: 0.000636, loss: 0.4105
2022-10-01 12:53:24 - train: epoch 0214, iter [00280, 01251], lr: 0.000635, loss: 0.4065
2022-10-01 12:53:42 - train: epoch 0214, iter [00290, 01251], lr: 0.000635, loss: 0.4141
2022-10-01 12:54:00 - train: epoch 0214, iter [00300, 01251], lr: 0.000635, loss: 0.4164
2022-10-01 12:54:18 - train: epoch 0214, iter [00310, 01251], lr: 0.000635, loss: 0.4298
2022-10-01 12:54:36 - train: epoch 0214, iter [00320, 01251], lr: 0.000635, loss: 0.4098
2022-10-01 12:54:54 - train: epoch 0214, iter [00330, 01251], lr: 0.000635, loss: 0.4051
2022-10-01 12:55:12 - train: epoch 0214, iter [00340, 01251], lr: 0.000635, loss: 0.4137
2022-10-01 12:55:30 - train: epoch 0214, iter [00350, 01251], lr: 0.000635, loss: 0.3967
2022-10-01 12:55:48 - train: epoch 0214, iter [00360, 01251], lr: 0.000635, loss: 0.4055
2022-10-01 12:56:06 - train: epoch 0214, iter [00370, 01251], lr: 0.000635, loss: 0.4295
2022-10-01 12:56:24 - train: epoch 0214, iter [00380, 01251], lr: 0.000635, loss: 0.4357
2022-10-01 12:56:42 - train: epoch 0214, iter [00390, 01251], lr: 0.000635, loss: 0.3951
2022-10-01 12:57:00 - train: epoch 0214, iter [00400, 01251], lr: 0.000635, loss: 0.4108
2022-10-01 12:57:18 - train: epoch 0214, iter [00410, 01251], lr: 0.000635, loss: 0.4292
2022-10-01 12:57:36 - train: epoch 0214, iter [00420, 01251], lr: 0.000635, loss: 0.3926
2022-10-01 12:57:54 - train: epoch 0214, iter [00430, 01251], lr: 0.000635, loss: 0.4015
2022-10-01 12:58:11 - train: epoch 0214, iter [00440, 01251], lr: 0.000635, loss: 0.4055
2022-10-01 12:58:30 - train: epoch 0214, iter [00450, 01251], lr: 0.000635, loss: 0.4062
2022-10-01 12:58:48 - train: epoch 0214, iter [00460, 01251], lr: 0.000635, loss: 0.4143
2022-10-01 12:59:06 - train: epoch 0214, iter [00470, 01251], lr: 0.000635, loss: 0.4097
2022-10-01 12:59:24 - train: epoch 0214, iter [00480, 01251], lr: 0.000635, loss: 0.4186
2022-10-01 12:59:42 - train: epoch 0214, iter [00490, 01251], lr: 0.000635, loss: 0.3989
2022-10-01 13:00:00 - train: epoch 0214, iter [00500, 01251], lr: 0.000635, loss: 0.3804
2022-10-01 13:00:18 - train: epoch 0214, iter [00510, 01251], lr: 0.000634, loss: 0.4109
2022-10-01 13:00:36 - train: epoch 0214, iter [00520, 01251], lr: 0.000634, loss: 0.4005
2022-10-01 13:00:54 - train: epoch 0214, iter [00530, 01251], lr: 0.000634, loss: 0.4031
2022-10-01 13:01:12 - train: epoch 0214, iter [00540, 01251], lr: 0.000634, loss: 0.4105
2022-10-01 13:01:30 - train: epoch 0214, iter [00550, 01251], lr: 0.000634, loss: 0.3989
2022-10-01 13:01:48 - train: epoch 0214, iter [00560, 01251], lr: 0.000634, loss: 0.4235
2022-10-01 13:02:06 - train: epoch 0214, iter [00570, 01251], lr: 0.000634, loss: 0.4033
2022-10-01 13:02:24 - train: epoch 0214, iter [00580, 01251], lr: 0.000634, loss: 0.3996
2022-10-01 13:02:42 - train: epoch 0214, iter [00590, 01251], lr: 0.000634, loss: 0.4012
2022-10-01 13:03:00 - train: epoch 0214, iter [00600, 01251], lr: 0.000634, loss: 0.4316
2022-10-01 13:03:18 - train: epoch 0214, iter [00610, 01251], lr: 0.000634, loss: 0.3944
2022-10-01 13:03:36 - train: epoch 0214, iter [00620, 01251], lr: 0.000634, loss: 0.4222
2022-10-01 13:03:54 - train: epoch 0214, iter [00630, 01251], lr: 0.000634, loss: 0.4055
2022-10-01 13:04:12 - train: epoch 0214, iter [00640, 01251], lr: 0.000634, loss: 0.4178
2022-10-01 13:04:30 - train: epoch 0214, iter [00650, 01251], lr: 0.000634, loss: 0.4121
2022-10-01 13:04:48 - train: epoch 0214, iter [00660, 01251], lr: 0.000634, loss: 0.4132
2022-10-01 13:05:06 - train: epoch 0214, iter [00670, 01251], lr: 0.000634, loss: 0.3975
2022-10-01 13:05:24 - train: epoch 0214, iter [00680, 01251], lr: 0.000634, loss: 0.4197
2022-10-01 13:05:43 - train: epoch 0214, iter [00690, 01251], lr: 0.000634, loss: 0.3889
2022-10-01 13:06:00 - train: epoch 0214, iter [00700, 01251], lr: 0.000634, loss: 0.4178
2022-10-01 13:06:19 - train: epoch 0214, iter [00710, 01251], lr: 0.000634, loss: 0.4057
2022-10-01 13:06:36 - train: epoch 0214, iter [00720, 01251], lr: 0.000634, loss: 0.4068
2022-10-01 13:06:54 - train: epoch 0214, iter [00730, 01251], lr: 0.000634, loss: 0.3953
2022-10-01 13:07:12 - train: epoch 0214, iter [00740, 01251], lr: 0.000634, loss: 0.3926
2022-10-01 13:07:30 - train: epoch 0214, iter [00750, 01251], lr: 0.000633, loss: 0.3979
2022-10-01 13:07:48 - train: epoch 0214, iter [00760, 01251], lr: 0.000633, loss: 0.4140
2022-10-01 13:08:07 - train: epoch 0214, iter [00770, 01251], lr: 0.000633, loss: 0.3852
2022-10-01 13:08:25 - train: epoch 0214, iter [00780, 01251], lr: 0.000633, loss: 0.4060
2022-10-01 13:08:43 - train: epoch 0214, iter [00790, 01251], lr: 0.000633, loss: 0.3915
2022-10-01 13:09:00 - train: epoch 0214, iter [00800, 01251], lr: 0.000633, loss: 0.4139
2022-10-01 13:09:18 - train: epoch 0214, iter [00810, 01251], lr: 0.000633, loss: 0.4172
2022-10-01 13:09:36 - train: epoch 0214, iter [00820, 01251], lr: 0.000633, loss: 0.4251
2022-10-01 13:09:54 - train: epoch 0214, iter [00830, 01251], lr: 0.000633, loss: 0.3903
2022-10-01 13:10:12 - train: epoch 0214, iter [00840, 01251], lr: 0.000633, loss: 0.3867
2022-10-01 13:10:30 - train: epoch 0214, iter [00850, 01251], lr: 0.000633, loss: 0.4258
2022-10-01 13:10:48 - train: epoch 0214, iter [00860, 01251], lr: 0.000633, loss: 0.4243
2022-10-01 13:11:07 - train: epoch 0214, iter [00870, 01251], lr: 0.000633, loss: 0.4098
2022-10-01 13:11:25 - train: epoch 0214, iter [00880, 01251], lr: 0.000633, loss: 0.3866
2022-10-01 13:11:43 - train: epoch 0214, iter [00890, 01251], lr: 0.000633, loss: 0.4222
2022-10-01 13:12:01 - train: epoch 0214, iter [00900, 01251], lr: 0.000633, loss: 0.4195
2022-10-01 13:12:19 - train: epoch 0214, iter [00910, 01251], lr: 0.000633, loss: 0.3942
2022-10-01 13:12:37 - train: epoch 0214, iter [00920, 01251], lr: 0.000633, loss: 0.4113
2022-10-01 13:12:55 - train: epoch 0214, iter [00930, 01251], lr: 0.000633, loss: 0.4038
2022-10-01 13:13:13 - train: epoch 0214, iter [00940, 01251], lr: 0.000633, loss: 0.4042
2022-10-01 13:13:31 - train: epoch 0214, iter [00950, 01251], lr: 0.000633, loss: 0.4168
2022-10-01 13:13:49 - train: epoch 0214, iter [00960, 01251], lr: 0.000633, loss: 0.4136
2022-10-01 13:14:07 - train: epoch 0214, iter [00970, 01251], lr: 0.000633, loss: 0.4060
2022-10-01 13:14:25 - train: epoch 0214, iter [00980, 01251], lr: 0.000633, loss: 0.4111
2022-10-01 13:14:43 - train: epoch 0214, iter [00990, 01251], lr: 0.000632, loss: 0.4116
2022-10-01 13:15:01 - train: epoch 0214, iter [01000, 01251], lr: 0.000632, loss: 0.4111
2022-10-01 13:15:19 - train: epoch 0214, iter [01010, 01251], lr: 0.000632, loss: 0.4090
2022-10-01 13:15:37 - train: epoch 0214, iter [01020, 01251], lr: 0.000632, loss: 0.4164
2022-10-01 13:15:56 - train: epoch 0214, iter [01030, 01251], lr: 0.000632, loss: 0.4175
2022-10-01 13:16:13 - train: epoch 0214, iter [01040, 01251], lr: 0.000632, loss: 0.4210
2022-10-01 13:16:32 - train: epoch 0214, iter [01050, 01251], lr: 0.000632, loss: 0.4039
2022-10-01 13:16:50 - train: epoch 0214, iter [01060, 01251], lr: 0.000632, loss: 0.4047
2022-10-01 13:17:08 - train: epoch 0214, iter [01070, 01251], lr: 0.000632, loss: 0.4045
2022-10-01 13:17:26 - train: epoch 0214, iter [01080, 01251], lr: 0.000632, loss: 0.4066
2022-10-01 13:17:44 - train: epoch 0214, iter [01090, 01251], lr: 0.000632, loss: 0.4070
2022-10-01 13:18:02 - train: epoch 0214, iter [01100, 01251], lr: 0.000632, loss: 0.4056
2022-10-01 13:18:20 - train: epoch 0214, iter [01110, 01251], lr: 0.000632, loss: 0.3990
2022-10-01 13:18:38 - train: epoch 0214, iter [01120, 01251], lr: 0.000632, loss: 0.3829
2022-10-01 13:18:56 - train: epoch 0214, iter [01130, 01251], lr: 0.000632, loss: 0.4205
2022-10-01 13:19:14 - train: epoch 0214, iter [01140, 01251], lr: 0.000632, loss: 0.4151
2022-10-01 13:19:32 - train: epoch 0214, iter [01150, 01251], lr: 0.000632, loss: 0.3977
2022-10-01 13:19:50 - train: epoch 0214, iter [01160, 01251], lr: 0.000632, loss: 0.4046
2022-10-01 13:20:08 - train: epoch 0214, iter [01170, 01251], lr: 0.000632, loss: 0.4129
2022-10-01 13:20:26 - train: epoch 0214, iter [01180, 01251], lr: 0.000632, loss: 0.4063
2022-10-01 13:20:44 - train: epoch 0214, iter [01190, 01251], lr: 0.000632, loss: 0.4160
2022-10-01 13:21:02 - train: epoch 0214, iter [01200, 01251], lr: 0.000632, loss: 0.3958
2022-10-01 13:21:20 - train: epoch 0214, iter [01210, 01251], lr: 0.000632, loss: 0.4141
2022-10-01 13:21:39 - train: epoch 0214, iter [01220, 01251], lr: 0.000632, loss: 0.3894
2022-10-01 13:21:57 - train: epoch 0214, iter [01230, 01251], lr: 0.000631, loss: 0.3923
2022-10-01 13:22:15 - train: epoch 0214, iter [01240, 01251], lr: 0.000631, loss: 0.4028
2022-10-01 13:22:32 - train: epoch 0214, iter [01250, 01251], lr: 0.000631, loss: 0.4111
2022-10-01 13:22:36 - train: epoch 214, train_loss: 0.4059
2022-10-01 13:22:39 - until epoch: 214, best_loss: 0.4059
2022-10-01 13:22:39 - epoch 215 lr: 0.000631
2022-10-01 13:23:02 - train: epoch 0215, iter [00010, 01251], lr: 0.000631, loss: 0.3991
2022-10-01 13:23:20 - train: epoch 0215, iter [00020, 01251], lr: 0.000631, loss: 0.3967
2022-10-01 13:23:38 - train: epoch 0215, iter [00030, 01251], lr: 0.000631, loss: 0.3914
2022-10-01 13:23:57 - train: epoch 0215, iter [00040, 01251], lr: 0.000631, loss: 0.4179
2022-10-01 13:24:15 - train: epoch 0215, iter [00050, 01251], lr: 0.000631, loss: 0.4143
2022-10-01 13:24:33 - train: epoch 0215, iter [00060, 01251], lr: 0.000631, loss: 0.4027
2022-10-01 13:24:51 - train: epoch 0215, iter [00070, 01251], lr: 0.000631, loss: 0.3938
2022-10-01 13:25:10 - train: epoch 0215, iter [00080, 01251], lr: 0.000631, loss: 0.4142
2022-10-01 13:25:28 - train: epoch 0215, iter [00090, 01251], lr: 0.000631, loss: 0.4121
2022-10-01 13:25:46 - train: epoch 0215, iter [00100, 01251], lr: 0.000631, loss: 0.3987
2022-10-01 13:26:04 - train: epoch 0215, iter [00110, 01251], lr: 0.000631, loss: 0.4076
2022-10-01 13:26:22 - train: epoch 0215, iter [00120, 01251], lr: 0.000631, loss: 0.4225
2022-10-01 13:26:41 - train: epoch 0215, iter [00130, 01251], lr: 0.000631, loss: 0.3971
2022-10-01 13:26:59 - train: epoch 0215, iter [00140, 01251], lr: 0.000631, loss: 0.3942
2022-10-01 13:27:17 - train: epoch 0215, iter [00150, 01251], lr: 0.000631, loss: 0.4056
2022-10-01 13:27:35 - train: epoch 0215, iter [00160, 01251], lr: 0.000631, loss: 0.4108
2022-10-01 13:27:53 - train: epoch 0215, iter [00170, 01251], lr: 0.000631, loss: 0.4135
2022-10-01 13:28:11 - train: epoch 0215, iter [00180, 01251], lr: 0.000631, loss: 0.4030
2022-10-01 13:28:29 - train: epoch 0215, iter [00190, 01251], lr: 0.000631, loss: 0.4140
2022-10-01 13:28:48 - train: epoch 0215, iter [00200, 01251], lr: 0.000631, loss: 0.4200
2022-10-01 13:29:05 - train: epoch 0215, iter [00210, 01251], lr: 0.000631, loss: 0.4095
2022-10-01 13:29:24 - train: epoch 0215, iter [00220, 01251], lr: 0.000630, loss: 0.4199
2022-10-01 13:29:42 - train: epoch 0215, iter [00230, 01251], lr: 0.000630, loss: 0.3950
2022-10-01 13:30:00 - train: epoch 0215, iter [00240, 01251], lr: 0.000630, loss: 0.4182
2022-10-01 13:30:18 - train: epoch 0215, iter [00250, 01251], lr: 0.000630, loss: 0.4177
2022-10-01 13:30:37 - train: epoch 0215, iter [00260, 01251], lr: 0.000630, loss: 0.4152
2022-10-01 13:30:55 - train: epoch 0215, iter [00270, 01251], lr: 0.000630, loss: 0.4189
2022-10-01 13:31:13 - train: epoch 0215, iter [00280, 01251], lr: 0.000630, loss: 0.4284
2022-10-01 13:31:31 - train: epoch 0215, iter [00290, 01251], lr: 0.000630, loss: 0.4106
2022-10-01 13:31:49 - train: epoch 0215, iter [00300, 01251], lr: 0.000630, loss: 0.3915
2022-10-01 13:32:07 - train: epoch 0215, iter [00310, 01251], lr: 0.000630, loss: 0.4058
2022-10-01 13:32:25 - train: epoch 0215, iter [00320, 01251], lr: 0.000630, loss: 0.4091
2022-10-01 13:32:44 - train: epoch 0215, iter [00330, 01251], lr: 0.000630, loss: 0.4091
2022-10-01 13:33:02 - train: epoch 0215, iter [00340, 01251], lr: 0.000630, loss: 0.4088
2022-10-01 13:33:20 - train: epoch 0215, iter [00350, 01251], lr: 0.000630, loss: 0.3812
2022-10-01 13:33:38 - train: epoch 0215, iter [00360, 01251], lr: 0.000630, loss: 0.3800
2022-10-01 13:33:56 - train: epoch 0215, iter [00370, 01251], lr: 0.000630, loss: 0.4343
2022-10-01 13:34:14 - train: epoch 0215, iter [00380, 01251], lr: 0.000630, loss: 0.4029
2022-10-01 13:34:32 - train: epoch 0215, iter [00390, 01251], lr: 0.000630, loss: 0.3939
2022-10-01 13:34:51 - train: epoch 0215, iter [00400, 01251], lr: 0.000630, loss: 0.4005
2022-10-01 13:35:09 - train: epoch 0215, iter [00410, 01251], lr: 0.000630, loss: 0.4013
2022-10-01 13:35:27 - train: epoch 0215, iter [00420, 01251], lr: 0.000630, loss: 0.4290
2022-10-01 13:35:45 - train: epoch 0215, iter [00430, 01251], lr: 0.000630, loss: 0.4009
2022-10-01 13:36:03 - train: epoch 0215, iter [00440, 01251], lr: 0.000630, loss: 0.4072
2022-10-01 13:36:21 - train: epoch 0215, iter [00450, 01251], lr: 0.000630, loss: 0.4083
2022-10-01 13:36:39 - train: epoch 0215, iter [00460, 01251], lr: 0.000629, loss: 0.4227
2022-10-01 13:36:58 - train: epoch 0215, iter [00470, 01251], lr: 0.000629, loss: 0.4218
2022-10-01 13:37:16 - train: epoch 0215, iter [00480, 01251], lr: 0.000629, loss: 0.3953
2022-10-01 13:37:34 - train: epoch 0215, iter [00490, 01251], lr: 0.000629, loss: 0.4096
2022-10-01 13:37:52 - train: epoch 0215, iter [00500, 01251], lr: 0.000629, loss: 0.4155
2022-10-01 13:38:10 - train: epoch 0215, iter [00510, 01251], lr: 0.000629, loss: 0.3937
2022-10-01 13:38:28 - train: epoch 0215, iter [00520, 01251], lr: 0.000629, loss: 0.4159
2022-10-01 13:38:46 - train: epoch 0215, iter [00530, 01251], lr: 0.000629, loss: 0.4123
2022-10-01 13:39:04 - train: epoch 0215, iter [00540, 01251], lr: 0.000629, loss: 0.4180
2022-10-01 13:39:22 - train: epoch 0215, iter [00550, 01251], lr: 0.000629, loss: 0.4134
2022-10-01 13:39:40 - train: epoch 0215, iter [00560, 01251], lr: 0.000629, loss: 0.4060
2022-10-01 13:39:59 - train: epoch 0215, iter [00570, 01251], lr: 0.000629, loss: 0.3794
2022-10-01 13:40:17 - train: epoch 0215, iter [00580, 01251], lr: 0.000629, loss: 0.4236
2022-10-01 13:40:35 - train: epoch 0215, iter [00590, 01251], lr: 0.000629, loss: 0.3757
2022-10-01 13:40:53 - train: epoch 0215, iter [00600, 01251], lr: 0.000629, loss: 0.4064
2022-10-01 13:41:11 - train: epoch 0215, iter [00610, 01251], lr: 0.000629, loss: 0.3963
2022-10-01 13:41:29 - train: epoch 0215, iter [00620, 01251], lr: 0.000629, loss: 0.3948
2022-10-01 13:41:47 - train: epoch 0215, iter [00630, 01251], lr: 0.000629, loss: 0.3807
2022-10-01 13:42:06 - train: epoch 0215, iter [00640, 01251], lr: 0.000629, loss: 0.4113
2022-10-01 13:42:24 - train: epoch 0215, iter [00650, 01251], lr: 0.000629, loss: 0.4110
2022-10-01 13:42:42 - train: epoch 0215, iter [00660, 01251], lr: 0.000629, loss: 0.4069
2022-10-01 13:43:00 - train: epoch 0215, iter [00670, 01251], lr: 0.000629, loss: 0.4243
2022-10-01 13:43:18 - train: epoch 0215, iter [00680, 01251], lr: 0.000629, loss: 0.3966
2022-10-01 13:43:36 - train: epoch 0215, iter [00690, 01251], lr: 0.000629, loss: 0.4110
2022-10-01 13:43:54 - train: epoch 0215, iter [00700, 01251], lr: 0.000628, loss: 0.4088
2022-10-01 13:44:13 - train: epoch 0215, iter [00710, 01251], lr: 0.000628, loss: 0.4151
2022-10-01 13:44:31 - train: epoch 0215, iter [00720, 01251], lr: 0.000628, loss: 0.4394
2022-10-01 13:44:49 - train: epoch 0215, iter [00730, 01251], lr: 0.000628, loss: 0.3986
2022-10-01 13:45:07 - train: epoch 0215, iter [00740, 01251], lr: 0.000628, loss: 0.4174
2022-10-01 13:45:25 - train: epoch 0215, iter [00750, 01251], lr: 0.000628, loss: 0.4276
2022-10-01 13:45:43 - train: epoch 0215, iter [00760, 01251], lr: 0.000628, loss: 0.4038
2022-10-01 13:46:02 - train: epoch 0215, iter [00770, 01251], lr: 0.000628, loss: 0.3916
2022-10-01 13:46:20 - train: epoch 0215, iter [00780, 01251], lr: 0.000628, loss: 0.4043
2022-10-01 13:46:38 - train: epoch 0215, iter [00790, 01251], lr: 0.000628, loss: 0.4147
2022-10-01 13:46:56 - train: epoch 0215, iter [00800, 01251], lr: 0.000628, loss: 0.4233
2022-10-01 13:47:14 - train: epoch 0215, iter [00810, 01251], lr: 0.000628, loss: 0.4019
2022-10-01 13:47:32 - train: epoch 0215, iter [00820, 01251], lr: 0.000628, loss: 0.4183
2022-10-01 13:47:50 - train: epoch 0215, iter [00830, 01251], lr: 0.000628, loss: 0.4020
2022-10-01 13:48:08 - train: epoch 0215, iter [00840, 01251], lr: 0.000628, loss: 0.4205
2022-10-01 13:48:26 - train: epoch 0215, iter [00850, 01251], lr: 0.000628, loss: 0.4028
2022-10-01 13:48:44 - train: epoch 0215, iter [00860, 01251], lr: 0.000628, loss: 0.4137
2022-10-01 13:49:02 - train: epoch 0215, iter [00870, 01251], lr: 0.000628, loss: 0.4158
2022-10-01 13:49:20 - train: epoch 0215, iter [00880, 01251], lr: 0.000628, loss: 0.4023
2022-10-01 13:49:39 - train: epoch 0215, iter [00890, 01251], lr: 0.000628, loss: 0.4058
2022-10-01 13:49:56 - train: epoch 0215, iter [00900, 01251], lr: 0.000628, loss: 0.4076
2022-10-01 13:50:14 - train: epoch 0215, iter [00910, 01251], lr: 0.000628, loss: 0.3782
2022-10-01 13:50:33 - train: epoch 0215, iter [00920, 01251], lr: 0.000628, loss: 0.4042
2022-10-01 13:50:51 - train: epoch 0215, iter [00930, 01251], lr: 0.000628, loss: 0.4126
2022-10-01 13:51:09 - train: epoch 0215, iter [00940, 01251], lr: 0.000627, loss: 0.4182
2022-10-01 13:51:27 - train: epoch 0215, iter [00950, 01251], lr: 0.000627, loss: 0.4087
2022-10-01 13:51:45 - train: epoch 0215, iter [00960, 01251], lr: 0.000627, loss: 0.4162
2022-10-01 13:52:03 - train: epoch 0215, iter [00970, 01251], lr: 0.000627, loss: 0.4087
2022-10-01 13:52:21 - train: epoch 0215, iter [00980, 01251], lr: 0.000627, loss: 0.4057
2022-10-01 13:52:40 - train: epoch 0215, iter [00990, 01251], lr: 0.000627, loss: 0.3968
2022-10-01 13:52:58 - train: epoch 0215, iter [01000, 01251], lr: 0.000627, loss: 0.4060
2022-10-01 13:53:16 - train: epoch 0215, iter [01010, 01251], lr: 0.000627, loss: 0.4015
2022-10-01 13:53:34 - train: epoch 0215, iter [01020, 01251], lr: 0.000627, loss: 0.4183
2022-10-01 13:53:52 - train: epoch 0215, iter [01030, 01251], lr: 0.000627, loss: 0.4041
2022-10-01 13:54:10 - train: epoch 0215, iter [01040, 01251], lr: 0.000627, loss: 0.4000
2022-10-01 13:54:29 - train: epoch 0215, iter [01050, 01251], lr: 0.000627, loss: 0.4043
2022-10-01 13:54:47 - train: epoch 0215, iter [01060, 01251], lr: 0.000627, loss: 0.4055
2022-10-01 13:55:05 - train: epoch 0215, iter [01070, 01251], lr: 0.000627, loss: 0.3882
2022-10-01 13:55:23 - train: epoch 0215, iter [01080, 01251], lr: 0.000627, loss: 0.3917
2022-10-01 13:55:41 - train: epoch 0215, iter [01090, 01251], lr: 0.000627, loss: 0.4037
2022-10-01 13:55:59 - train: epoch 0215, iter [01100, 01251], lr: 0.000627, loss: 0.4065
2022-10-01 13:56:17 - train: epoch 0215, iter [01110, 01251], lr: 0.000627, loss: 0.4039
2022-10-01 13:56:36 - train: epoch 0215, iter [01120, 01251], lr: 0.000627, loss: 0.4140
2022-10-01 13:56:54 - train: epoch 0215, iter [01130, 01251], lr: 0.000627, loss: 0.3988
2022-10-01 13:57:12 - train: epoch 0215, iter [01140, 01251], lr: 0.000627, loss: 0.4021
2022-10-01 13:57:30 - train: epoch 0215, iter [01150, 01251], lr: 0.000627, loss: 0.4205
2022-10-01 13:57:48 - train: epoch 0215, iter [01160, 01251], lr: 0.000627, loss: 0.3920
2022-10-01 13:58:06 - train: epoch 0215, iter [01170, 01251], lr: 0.000627, loss: 0.3775
2022-10-01 13:58:24 - train: epoch 0215, iter [01180, 01251], lr: 0.000626, loss: 0.3959
2022-10-01 13:58:42 - train: epoch 0215, iter [01190, 01251], lr: 0.000626, loss: 0.3962
2022-10-01 13:59:00 - train: epoch 0215, iter [01200, 01251], lr: 0.000626, loss: 0.4145
2022-10-01 13:59:18 - train: epoch 0215, iter [01210, 01251], lr: 0.000626, loss: 0.4190
2022-10-01 13:59:36 - train: epoch 0215, iter [01220, 01251], lr: 0.000626, loss: 0.4153
2022-10-01 13:59:55 - train: epoch 0215, iter [01230, 01251], lr: 0.000626, loss: 0.4231
2022-10-01 14:00:13 - train: epoch 0215, iter [01240, 01251], lr: 0.000626, loss: 0.3974
2022-10-01 14:00:30 - train: epoch 0215, iter [01250, 01251], lr: 0.000626, loss: 0.4133
2022-10-01 14:00:34 - train: epoch 215, train_loss: 0.4059
2022-10-01 14:00:36 - until epoch: 215, best_loss: 0.4059
2022-10-01 14:00:36 - epoch 216 lr: 0.000626
2022-10-01 14:01:01 - train: epoch 0216, iter [00010, 01251], lr: 0.000626, loss: 0.4028
2022-10-01 14:01:19 - train: epoch 0216, iter [00020, 01251], lr: 0.000626, loss: 0.4010
2022-10-01 14:01:37 - train: epoch 0216, iter [00030, 01251], lr: 0.000626, loss: 0.4054
2022-10-01 14:01:55 - train: epoch 0216, iter [00040, 01251], lr: 0.000626, loss: 0.3852
2022-10-01 14:02:14 - train: epoch 0216, iter [00050, 01251], lr: 0.000626, loss: 0.3976
2022-10-01 14:02:32 - train: epoch 0216, iter [00060, 01251], lr: 0.000626, loss: 0.4125
2022-10-01 14:02:50 - train: epoch 0216, iter [00070, 01251], lr: 0.000626, loss: 0.4041
2022-10-01 14:03:08 - train: epoch 0216, iter [00080, 01251], lr: 0.000626, loss: 0.4101
2022-10-01 14:03:26 - train: epoch 0216, iter [00090, 01251], lr: 0.000626, loss: 0.4027
2022-10-01 14:03:44 - train: epoch 0216, iter [00100, 01251], lr: 0.000626, loss: 0.4322
2022-10-01 14:04:03 - train: epoch 0216, iter [00110, 01251], lr: 0.000626, loss: 0.4249
2022-10-01 14:04:21 - train: epoch 0216, iter [00120, 01251], lr: 0.000626, loss: 0.4185
2022-10-01 14:04:39 - train: epoch 0216, iter [00130, 01251], lr: 0.000626, loss: 0.3900
2022-10-01 14:04:57 - train: epoch 0216, iter [00140, 01251], lr: 0.000626, loss: 0.3962
2022-10-01 14:05:15 - train: epoch 0216, iter [00150, 01251], lr: 0.000626, loss: 0.3948
2022-10-01 14:05:34 - train: epoch 0216, iter [00160, 01251], lr: 0.000626, loss: 0.4141
2022-10-01 14:05:52 - train: epoch 0216, iter [00170, 01251], lr: 0.000625, loss: 0.4254
2022-10-01 14:06:10 - train: epoch 0216, iter [00180, 01251], lr: 0.000625, loss: 0.3914
2022-10-01 14:06:28 - train: epoch 0216, iter [00190, 01251], lr: 0.000625, loss: 0.4111
2022-10-01 14:06:46 - train: epoch 0216, iter [00200, 01251], lr: 0.000625, loss: 0.3947
2022-10-01 14:07:04 - train: epoch 0216, iter [00210, 01251], lr: 0.000625, loss: 0.4120
2022-10-01 14:07:22 - train: epoch 0216, iter [00220, 01251], lr: 0.000625, loss: 0.3983
2022-10-01 14:07:40 - train: epoch 0216, iter [00230, 01251], lr: 0.000625, loss: 0.4118
2022-10-01 14:07:59 - train: epoch 0216, iter [00240, 01251], lr: 0.000625, loss: 0.4201
2022-10-01 14:08:17 - train: epoch 0216, iter [00250, 01251], lr: 0.000625, loss: 0.3979
2022-10-01 14:08:35 - train: epoch 0216, iter [00260, 01251], lr: 0.000625, loss: 0.4130
2022-10-01 14:08:54 - train: epoch 0216, iter [00270, 01251], lr: 0.000625, loss: 0.4125
2022-10-01 14:09:12 - train: epoch 0216, iter [00280, 01251], lr: 0.000625, loss: 0.4030
2022-10-01 14:09:30 - train: epoch 0216, iter [00290, 01251], lr: 0.000625, loss: 0.3971
2022-10-01 14:09:48 - train: epoch 0216, iter [00300, 01251], lr: 0.000625, loss: 0.4069
2022-10-01 14:10:06 - train: epoch 0216, iter [00310, 01251], lr: 0.000625, loss: 0.4145
2022-10-01 14:10:24 - train: epoch 0216, iter [00320, 01251], lr: 0.000625, loss: 0.3956
2022-10-01 14:10:42 - train: epoch 0216, iter [00330, 01251], lr: 0.000625, loss: 0.3813
2022-10-01 14:11:01 - train: epoch 0216, iter [00340, 01251], lr: 0.000625, loss: 0.4049
2022-10-01 14:11:19 - train: epoch 0216, iter [00350, 01251], lr: 0.000625, loss: 0.3889
2022-10-01 14:11:37 - train: epoch 0216, iter [00360, 01251], lr: 0.000625, loss: 0.4043
2022-10-01 14:11:56 - train: epoch 0216, iter [00370, 01251], lr: 0.000625, loss: 0.4170
2022-10-01 14:12:14 - train: epoch 0216, iter [00380, 01251], lr: 0.000625, loss: 0.4238
2022-10-01 14:12:32 - train: epoch 0216, iter [00390, 01251], lr: 0.000625, loss: 0.4088
2022-10-01 14:12:50 - train: epoch 0216, iter [00400, 01251], lr: 0.000624, loss: 0.4258
2022-10-01 14:13:09 - train: epoch 0216, iter [00410, 01251], lr: 0.000624, loss: 0.3996
2022-10-01 14:13:27 - train: epoch 0216, iter [00420, 01251], lr: 0.000624, loss: 0.4156
2022-10-01 14:13:45 - train: epoch 0216, iter [00430, 01251], lr: 0.000624, loss: 0.4067
2022-10-01 14:14:04 - train: epoch 0216, iter [00440, 01251], lr: 0.000624, loss: 0.4130
2022-10-01 14:14:22 - train: epoch 0216, iter [00450, 01251], lr: 0.000624, loss: 0.3807
2022-10-01 14:14:40 - train: epoch 0216, iter [00460, 01251], lr: 0.000624, loss: 0.3914
2022-10-01 14:14:58 - train: epoch 0216, iter [00470, 01251], lr: 0.000624, loss: 0.4136
2022-10-01 14:15:16 - train: epoch 0216, iter [00480, 01251], lr: 0.000624, loss: 0.4011
2022-10-01 14:15:35 - train: epoch 0216, iter [00490, 01251], lr: 0.000624, loss: 0.3974
2022-10-01 14:15:53 - train: epoch 0216, iter [00500, 01251], lr: 0.000624, loss: 0.4160
2022-10-01 14:16:11 - train: epoch 0216, iter [00510, 01251], lr: 0.000624, loss: 0.3961
2022-10-01 14:16:29 - train: epoch 0216, iter [00520, 01251], lr: 0.000624, loss: 0.3984
2022-10-01 14:16:47 - train: epoch 0216, iter [00530, 01251], lr: 0.000624, loss: 0.3937
2022-10-01 14:17:05 - train: epoch 0216, iter [00540, 01251], lr: 0.000624, loss: 0.3993
2022-10-01 14:17:24 - train: epoch 0216, iter [00550, 01251], lr: 0.000624, loss: 0.3973
2022-10-01 14:17:42 - train: epoch 0216, iter [00560, 01251], lr: 0.000624, loss: 0.4140
2022-10-01 14:18:00 - train: epoch 0216, iter [00570, 01251], lr: 0.000624, loss: 0.3927
2022-10-01 14:18:18 - train: epoch 0216, iter [00580, 01251], lr: 0.000624, loss: 0.3998
2022-10-01 14:18:37 - train: epoch 0216, iter [00590, 01251], lr: 0.000624, loss: 0.4128
2022-10-01 14:18:55 - train: epoch 0216, iter [00600, 01251], lr: 0.000624, loss: 0.4098
2022-10-01 14:19:13 - train: epoch 0216, iter [00610, 01251], lr: 0.000624, loss: 0.4090
2022-10-01 14:19:32 - train: epoch 0216, iter [00620, 01251], lr: 0.000624, loss: 0.3947
2022-10-01 14:19:50 - train: epoch 0216, iter [00630, 01251], lr: 0.000624, loss: 0.4198
2022-10-01 14:20:08 - train: epoch 0216, iter [00640, 01251], lr: 0.000623, loss: 0.3960
2022-10-01 14:20:26 - train: epoch 0216, iter [00650, 01251], lr: 0.000623, loss: 0.3974
2022-10-01 14:20:44 - train: epoch 0216, iter [00660, 01251], lr: 0.000623, loss: 0.4023
2022-10-01 14:21:02 - train: epoch 0216, iter [00670, 01251], lr: 0.000623, loss: 0.3773
2022-10-01 14:21:20 - train: epoch 0216, iter [00680, 01251], lr: 0.000623, loss: 0.4162
2022-10-01 14:21:39 - train: epoch 0216, iter [00690, 01251], lr: 0.000623, loss: 0.4241
2022-10-01 14:21:57 - train: epoch 0216, iter [00700, 01251], lr: 0.000623, loss: 0.4020
2022-10-01 14:22:15 - train: epoch 0216, iter [00710, 01251], lr: 0.000623, loss: 0.4058
2022-10-01 14:22:34 - train: epoch 0216, iter [00720, 01251], lr: 0.000623, loss: 0.4288
2022-10-01 14:22:52 - train: epoch 0216, iter [00730, 01251], lr: 0.000623, loss: 0.4161
2022-10-01 14:23:10 - train: epoch 0216, iter [00740, 01251], lr: 0.000623, loss: 0.3871
2022-10-01 14:23:28 - train: epoch 0216, iter [00750, 01251], lr: 0.000623, loss: 0.4047
2022-10-01 14:23:46 - train: epoch 0216, iter [00760, 01251], lr: 0.000623, loss: 0.4134
2022-10-01 14:24:04 - train: epoch 0216, iter [00770, 01251], lr: 0.000623, loss: 0.3965
2022-10-01 14:24:22 - train: epoch 0216, iter [00780, 01251], lr: 0.000623, loss: 0.4191
2022-10-01 14:24:40 - train: epoch 0216, iter [00790, 01251], lr: 0.000623, loss: 0.4201
2022-10-01 14:24:58 - train: epoch 0216, iter [00800, 01251], lr: 0.000623, loss: 0.4144
2022-10-01 14:25:17 - train: epoch 0216, iter [00810, 01251], lr: 0.000623, loss: 0.3867
2022-10-01 14:25:35 - train: epoch 0216, iter [00820, 01251], lr: 0.000623, loss: 0.4025
2022-10-01 14:25:53 - train: epoch 0216, iter [00830, 01251], lr: 0.000623, loss: 0.3898
2022-10-01 14:26:11 - train: epoch 0216, iter [00840, 01251], lr: 0.000623, loss: 0.3803
2022-10-01 14:26:29 - train: epoch 0216, iter [00850, 01251], lr: 0.000623, loss: 0.4043
2022-10-01 14:26:47 - train: epoch 0216, iter [00860, 01251], lr: 0.000623, loss: 0.4140
2022-10-01 14:27:06 - train: epoch 0216, iter [00870, 01251], lr: 0.000623, loss: 0.3957
2022-10-01 14:27:24 - train: epoch 0216, iter [00880, 01251], lr: 0.000622, loss: 0.3980
2022-10-01 14:27:42 - train: epoch 0216, iter [00890, 01251], lr: 0.000622, loss: 0.4006
2022-10-01 14:28:00 - train: epoch 0216, iter [00900, 01251], lr: 0.000622, loss: 0.4179
2022-10-01 14:28:18 - train: epoch 0216, iter [00910, 01251], lr: 0.000622, loss: 0.4176
2022-10-01 14:28:37 - train: epoch 0216, iter [00920, 01251], lr: 0.000622, loss: 0.4002
2022-10-01 14:28:55 - train: epoch 0216, iter [00930, 01251], lr: 0.000622, loss: 0.4083
2022-10-01 14:29:13 - train: epoch 0216, iter [00940, 01251], lr: 0.000622, loss: 0.3976
2022-10-01 14:29:31 - train: epoch 0216, iter [00950, 01251], lr: 0.000622, loss: 0.4133
2022-10-01 14:29:49 - train: epoch 0216, iter [00960, 01251], lr: 0.000622, loss: 0.4174
2022-10-01 14:30:08 - train: epoch 0216, iter [00970, 01251], lr: 0.000622, loss: 0.3899
2022-10-01 14:30:26 - train: epoch 0216, iter [00980, 01251], lr: 0.000622, loss: 0.4067
2022-10-01 14:30:45 - train: epoch 0216, iter [00990, 01251], lr: 0.000622, loss: 0.4030
2022-10-01 14:31:03 - train: epoch 0216, iter [01000, 01251], lr: 0.000622, loss: 0.4070
2022-10-01 14:31:21 - train: epoch 0216, iter [01010, 01251], lr: 0.000622, loss: 0.3836
2022-10-01 14:31:39 - train: epoch 0216, iter [01020, 01251], lr: 0.000622, loss: 0.3892
2022-10-01 14:31:57 - train: epoch 0216, iter [01030, 01251], lr: 0.000622, loss: 0.4175
2022-10-01 14:32:16 - train: epoch 0216, iter [01040, 01251], lr: 0.000622, loss: 0.4156
2022-10-01 14:32:34 - train: epoch 0216, iter [01050, 01251], lr: 0.000622, loss: 0.4093
2022-10-01 14:32:52 - train: epoch 0216, iter [01060, 01251], lr: 0.000622, loss: 0.4006
2022-10-01 14:33:11 - train: epoch 0216, iter [01070, 01251], lr: 0.000622, loss: 0.3880
2022-10-01 14:33:29 - train: epoch 0216, iter [01080, 01251], lr: 0.000622, loss: 0.4134
2022-10-01 14:33:47 - train: epoch 0216, iter [01090, 01251], lr: 0.000622, loss: 0.4002
2022-10-01 14:34:05 - train: epoch 0216, iter [01100, 01251], lr: 0.000622, loss: 0.4276
2022-10-01 14:34:23 - train: epoch 0216, iter [01110, 01251], lr: 0.000622, loss: 0.3898
2022-10-01 14:34:41 - train: epoch 0216, iter [01120, 01251], lr: 0.000621, loss: 0.4105
2022-10-01 14:34:59 - train: epoch 0216, iter [01130, 01251], lr: 0.000621, loss: 0.3990
2022-10-01 14:35:18 - train: epoch 0216, iter [01140, 01251], lr: 0.000621, loss: 0.4079
2022-10-01 14:35:36 - train: epoch 0216, iter [01150, 01251], lr: 0.000621, loss: 0.4157
2022-10-01 14:35:54 - train: epoch 0216, iter [01160, 01251], lr: 0.000621, loss: 0.4076
2022-10-01 14:36:12 - train: epoch 0216, iter [01170, 01251], lr: 0.000621, loss: 0.4014
2022-10-01 14:36:30 - train: epoch 0216, iter [01180, 01251], lr: 0.000621, loss: 0.3865
2022-10-01 14:36:48 - train: epoch 0216, iter [01190, 01251], lr: 0.000621, loss: 0.4129
2022-10-01 14:37:07 - train: epoch 0216, iter [01200, 01251], lr: 0.000621, loss: 0.4015
2022-10-01 14:37:25 - train: epoch 0216, iter [01210, 01251], lr: 0.000621, loss: 0.3900
2022-10-01 14:37:43 - train: epoch 0216, iter [01220, 01251], lr: 0.000621, loss: 0.4032
2022-10-01 14:38:01 - train: epoch 0216, iter [01230, 01251], lr: 0.000621, loss: 0.4076
2022-10-01 14:38:19 - train: epoch 0216, iter [01240, 01251], lr: 0.000621, loss: 0.4125
2022-10-01 14:38:37 - train: epoch 0216, iter [01250, 01251], lr: 0.000621, loss: 0.4111
2022-10-01 14:38:40 - train: epoch 216, train_loss: 0.4058
2022-10-01 14:38:43 - until epoch: 216, best_loss: 0.4058
2022-10-01 14:38:43 - epoch 217 lr: 0.000621
2022-10-01 14:39:07 - train: epoch 0217, iter [00010, 01251], lr: 0.000621, loss: 0.3911
2022-10-01 14:39:25 - train: epoch 0217, iter [00020, 01251], lr: 0.000621, loss: 0.4113
2022-10-01 14:39:43 - train: epoch 0217, iter [00030, 01251], lr: 0.000621, loss: 0.4103
2022-10-01 14:40:01 - train: epoch 0217, iter [00040, 01251], lr: 0.000621, loss: 0.4298
2022-10-01 14:40:20 - train: epoch 0217, iter [00050, 01251], lr: 0.000621, loss: 0.4135
2022-10-01 14:40:38 - train: epoch 0217, iter [00060, 01251], lr: 0.000621, loss: 0.3931
2022-10-01 14:40:56 - train: epoch 0217, iter [00070, 01251], lr: 0.000621, loss: 0.4320
2022-10-01 14:41:15 - train: epoch 0217, iter [00080, 01251], lr: 0.000621, loss: 0.4144
2022-10-01 14:41:33 - train: epoch 0217, iter [00090, 01251], lr: 0.000621, loss: 0.4021
2022-10-01 14:41:51 - train: epoch 0217, iter [00100, 01251], lr: 0.000621, loss: 0.3878
2022-10-01 14:42:09 - train: epoch 0217, iter [00110, 01251], lr: 0.000620, loss: 0.4016
2022-10-01 14:42:28 - train: epoch 0217, iter [00120, 01251], lr: 0.000620, loss: 0.4109
2022-10-01 14:42:46 - train: epoch 0217, iter [00130, 01251], lr: 0.000620, loss: 0.4180
2022-10-01 14:43:04 - train: epoch 0217, iter [00140, 01251], lr: 0.000620, loss: 0.4162
2022-10-01 14:43:22 - train: epoch 0217, iter [00150, 01251], lr: 0.000620, loss: 0.3965
2022-10-01 14:43:40 - train: epoch 0217, iter [00160, 01251], lr: 0.000620, loss: 0.4046
2022-10-01 14:43:58 - train: epoch 0217, iter [00170, 01251], lr: 0.000620, loss: 0.4058
2022-10-01 14:44:17 - train: epoch 0217, iter [00180, 01251], lr: 0.000620, loss: 0.3930
2022-10-01 14:44:35 - train: epoch 0217, iter [00190, 01251], lr: 0.000620, loss: 0.3977
2022-10-01 14:44:53 - train: epoch 0217, iter [00200, 01251], lr: 0.000620, loss: 0.4046
2022-10-01 14:45:12 - train: epoch 0217, iter [00210, 01251], lr: 0.000620, loss: 0.3926
2022-10-01 14:45:31 - train: epoch 0217, iter [00220, 01251], lr: 0.000620, loss: 0.4082
2022-10-01 14:45:49 - train: epoch 0217, iter [00230, 01251], lr: 0.000620, loss: 0.4162
2022-10-01 14:46:07 - train: epoch 0217, iter [00240, 01251], lr: 0.000620, loss: 0.3928
2022-10-01 14:46:25 - train: epoch 0217, iter [00250, 01251], lr: 0.000620, loss: 0.4320
2022-10-01 14:46:44 - train: epoch 0217, iter [00260, 01251], lr: 0.000620, loss: 0.3998
2022-10-01 14:47:02 - train: epoch 0217, iter [00270, 01251], lr: 0.000620, loss: 0.4080
2022-10-01 14:47:20 - train: epoch 0217, iter [00280, 01251], lr: 0.000620, loss: 0.3920
2022-10-01 14:47:38 - train: epoch 0217, iter [00290, 01251], lr: 0.000620, loss: 0.4052
2022-10-01 14:47:56 - train: epoch 0217, iter [00300, 01251], lr: 0.000620, loss: 0.4075
2022-10-01 14:48:15 - train: epoch 0217, iter [00310, 01251], lr: 0.000620, loss: 0.4043
2022-10-01 14:48:33 - train: epoch 0217, iter [00320, 01251], lr: 0.000620, loss: 0.4004
2022-10-01 14:48:51 - train: epoch 0217, iter [00330, 01251], lr: 0.000620, loss: 0.3921
2022-10-01 14:49:09 - train: epoch 0217, iter [00340, 01251], lr: 0.000620, loss: 0.4115
2022-10-01 14:49:27 - train: epoch 0217, iter [00350, 01251], lr: 0.000619, loss: 0.4147
2022-10-01 14:49:45 - train: epoch 0217, iter [00360, 01251], lr: 0.000619, loss: 0.4092
2022-10-01 14:50:03 - train: epoch 0217, iter [00370, 01251], lr: 0.000619, loss: 0.4047
2022-10-01 14:50:22 - train: epoch 0217, iter [00380, 01251], lr: 0.000619, loss: 0.4177
2022-10-01 14:50:40 - train: epoch 0217, iter [00390, 01251], lr: 0.000619, loss: 0.4045
2022-10-01 14:50:58 - train: epoch 0217, iter [00400, 01251], lr: 0.000619, loss: 0.4056
2022-10-01 14:51:16 - train: epoch 0217, iter [00410, 01251], lr: 0.000619, loss: 0.4071
2022-10-01 14:51:34 - train: epoch 0217, iter [00420, 01251], lr: 0.000619, loss: 0.4040
2022-10-01 14:51:52 - train: epoch 0217, iter [00430, 01251], lr: 0.000619, loss: 0.3966
2022-10-01 14:52:10 - train: epoch 0217, iter [00440, 01251], lr: 0.000619, loss: 0.4080
2022-10-01 14:52:29 - train: epoch 0217, iter [00450, 01251], lr: 0.000619, loss: 0.4167
2022-10-01 14:52:47 - train: epoch 0217, iter [00460, 01251], lr: 0.000619, loss: 0.3950
2022-10-01 14:53:05 - train: epoch 0217, iter [00470, 01251], lr: 0.000619, loss: 0.3982
2022-10-01 14:53:24 - train: epoch 0217, iter [00480, 01251], lr: 0.000619, loss: 0.3989
2022-10-01 14:53:42 - train: epoch 0217, iter [00490, 01251], lr: 0.000619, loss: 0.4054
2022-10-01 14:54:00 - train: epoch 0217, iter [00500, 01251], lr: 0.000619, loss: 0.3903
2022-10-01 14:54:18 - train: epoch 0217, iter [00510, 01251], lr: 0.000619, loss: 0.3856
2022-10-01 14:54:36 - train: epoch 0217, iter [00520, 01251], lr: 0.000619, loss: 0.4050
2022-10-01 14:54:54 - train: epoch 0217, iter [00530, 01251], lr: 0.000619, loss: 0.4209
2022-10-01 14:55:12 - train: epoch 0217, iter [00540, 01251], lr: 0.000619, loss: 0.3945
2022-10-01 14:55:31 - train: epoch 0217, iter [00550, 01251], lr: 0.000619, loss: 0.4065
2022-10-01 14:55:49 - train: epoch 0217, iter [00560, 01251], lr: 0.000619, loss: 0.3924
2022-10-01 14:56:07 - train: epoch 0217, iter [00570, 01251], lr: 0.000619, loss: 0.3952
2022-10-01 14:56:25 - train: epoch 0217, iter [00580, 01251], lr: 0.000619, loss: 0.4220
2022-10-01 14:56:44 - train: epoch 0217, iter [00590, 01251], lr: 0.000618, loss: 0.4057
2022-10-01 14:57:02 - train: epoch 0217, iter [00600, 01251], lr: 0.000618, loss: 0.3987
2022-10-01 14:57:20 - train: epoch 0217, iter [00610, 01251], lr: 0.000618, loss: 0.4130
2022-10-01 14:57:39 - train: epoch 0217, iter [00620, 01251], lr: 0.000618, loss: 0.4013
2022-10-01 14:57:57 - train: epoch 0217, iter [00630, 01251], lr: 0.000618, loss: 0.4153
2022-10-01 14:58:15 - train: epoch 0217, iter [00640, 01251], lr: 0.000618, loss: 0.3894
2022-10-01 14:58:33 - train: epoch 0217, iter [00650, 01251], lr: 0.000618, loss: 0.4088
2022-10-01 14:58:51 - train: epoch 0217, iter [00660, 01251], lr: 0.000618, loss: 0.3955
2022-10-01 14:59:09 - train: epoch 0217, iter [00670, 01251], lr: 0.000618, loss: 0.3869
2022-10-01 14:59:27 - train: epoch 0217, iter [00680, 01251], lr: 0.000618, loss: 0.4126
2022-10-01 14:59:46 - train: epoch 0217, iter [00690, 01251], lr: 0.000618, loss: 0.4275
2022-10-01 15:00:04 - train: epoch 0217, iter [00700, 01251], lr: 0.000618, loss: 0.4071
2022-10-01 15:00:22 - train: epoch 0217, iter [00710, 01251], lr: 0.000618, loss: 0.4131
2022-10-01 15:00:40 - train: epoch 0217, iter [00720, 01251], lr: 0.000618, loss: 0.4173
2022-10-01 15:00:58 - train: epoch 0217, iter [00730, 01251], lr: 0.000618, loss: 0.4098
2022-10-01 15:01:17 - train: epoch 0217, iter [00740, 01251], lr: 0.000618, loss: 0.4076
2022-10-01 15:01:35 - train: epoch 0217, iter [00750, 01251], lr: 0.000618, loss: 0.3907
2022-10-01 15:01:53 - train: epoch 0217, iter [00760, 01251], lr: 0.000618, loss: 0.4141
2022-10-01 15:02:11 - train: epoch 0217, iter [00770, 01251], lr: 0.000618, loss: 0.4121
2022-10-01 15:02:29 - train: epoch 0217, iter [00780, 01251], lr: 0.000618, loss: 0.3989
2022-10-01 15:02:47 - train: epoch 0217, iter [00790, 01251], lr: 0.000618, loss: 0.4132
2022-10-01 15:03:05 - train: epoch 0217, iter [00800, 01251], lr: 0.000618, loss: 0.4010
2022-10-01 15:03:24 - train: epoch 0217, iter [00810, 01251], lr: 0.000618, loss: 0.4113
2022-10-01 15:03:42 - train: epoch 0217, iter [00820, 01251], lr: 0.000618, loss: 0.4094
2022-10-01 15:04:00 - train: epoch 0217, iter [00830, 01251], lr: 0.000617, loss: 0.4020
2022-10-01 15:04:18 - train: epoch 0217, iter [00840, 01251], lr: 0.000617, loss: 0.4207
2022-10-01 15:04:36 - train: epoch 0217, iter [00850, 01251], lr: 0.000617, loss: 0.3834
2022-10-01 15:04:54 - train: epoch 0217, iter [00860, 01251], lr: 0.000617, loss: 0.4019
2022-10-01 15:05:12 - train: epoch 0217, iter [00870, 01251], lr: 0.000617, loss: 0.4008
2022-10-01 15:05:30 - train: epoch 0217, iter [00880, 01251], lr: 0.000617, loss: 0.3756
2022-10-01 15:05:49 - train: epoch 0217, iter [00890, 01251], lr: 0.000617, loss: 0.3972
2022-10-01 15:06:07 - train: epoch 0217, iter [00900, 01251], lr: 0.000617, loss: 0.4098
2022-10-01 15:06:25 - train: epoch 0217, iter [00910, 01251], lr: 0.000617, loss: 0.4019
2022-10-01 15:06:43 - train: epoch 0217, iter [00920, 01251], lr: 0.000617, loss: 0.3970
2022-10-01 15:07:01 - train: epoch 0217, iter [00930, 01251], lr: 0.000617, loss: 0.4194
2022-10-01 15:07:19 - train: epoch 0217, iter [00940, 01251], lr: 0.000617, loss: 0.3817
2022-10-01 15:07:37 - train: epoch 0217, iter [00950, 01251], lr: 0.000617, loss: 0.4225
2022-10-01 15:07:55 - train: epoch 0217, iter [00960, 01251], lr: 0.000617, loss: 0.4034
2022-10-01 15:08:13 - train: epoch 0217, iter [00970, 01251], lr: 0.000617, loss: 0.4056
2022-10-01 15:08:31 - train: epoch 0217, iter [00980, 01251], lr: 0.000617, loss: 0.4071
2022-10-01 15:08:50 - train: epoch 0217, iter [00990, 01251], lr: 0.000617, loss: 0.3925
2022-10-01 15:09:08 - train: epoch 0217, iter [01000, 01251], lr: 0.000617, loss: 0.4037
2022-10-01 15:09:26 - train: epoch 0217, iter [01010, 01251], lr: 0.000617, loss: 0.3974
2022-10-01 15:09:44 - train: epoch 0217, iter [01020, 01251], lr: 0.000617, loss: 0.4189
2022-10-01 15:10:02 - train: epoch 0217, iter [01030, 01251], lr: 0.000617, loss: 0.4053
2022-10-01 15:10:20 - train: epoch 0217, iter [01040, 01251], lr: 0.000617, loss: 0.4294
2022-10-01 15:10:38 - train: epoch 0217, iter [01050, 01251], lr: 0.000617, loss: 0.4045
2022-10-01 15:10:56 - train: epoch 0217, iter [01060, 01251], lr: 0.000617, loss: 0.4070
2022-10-01 15:11:14 - train: epoch 0217, iter [01070, 01251], lr: 0.000616, loss: 0.4105
2022-10-01 15:11:32 - train: epoch 0217, iter [01080, 01251], lr: 0.000616, loss: 0.3820
2022-10-01 15:11:51 - train: epoch 0217, iter [01090, 01251], lr: 0.000616, loss: 0.4088
2022-10-01 15:12:09 - train: epoch 0217, iter [01100, 01251], lr: 0.000616, loss: 0.3967
2022-10-01 15:12:27 - train: epoch 0217, iter [01110, 01251], lr: 0.000616, loss: 0.4048
2022-10-01 15:12:45 - train: epoch 0217, iter [01120, 01251], lr: 0.000616, loss: 0.4052
2022-10-01 15:13:03 - train: epoch 0217, iter [01130, 01251], lr: 0.000616, loss: 0.4092
2022-10-01 15:13:21 - train: epoch 0217, iter [01140, 01251], lr: 0.000616, loss: 0.4000
2022-10-01 15:13:39 - train: epoch 0217, iter [01150, 01251], lr: 0.000616, loss: 0.3945
2022-10-01 15:13:57 - train: epoch 0217, iter [01160, 01251], lr: 0.000616, loss: 0.3979
2022-10-01 15:14:15 - train: epoch 0217, iter [01170, 01251], lr: 0.000616, loss: 0.3934
2022-10-01 15:14:33 - train: epoch 0217, iter [01180, 01251], lr: 0.000616, loss: 0.3996
2022-10-01 15:14:51 - train: epoch 0217, iter [01190, 01251], lr: 0.000616, loss: 0.3987
2022-10-01 15:15:09 - train: epoch 0217, iter [01200, 01251], lr: 0.000616, loss: 0.4166
2022-10-01 15:15:28 - train: epoch 0217, iter [01210, 01251], lr: 0.000616, loss: 0.4273
2022-10-01 15:15:46 - train: epoch 0217, iter [01220, 01251], lr: 0.000616, loss: 0.4004
2022-10-01 15:16:04 - train: epoch 0217, iter [01230, 01251], lr: 0.000616, loss: 0.3926
2022-10-01 15:16:22 - train: epoch 0217, iter [01240, 01251], lr: 0.000616, loss: 0.4061
2022-10-01 15:16:39 - train: epoch 0217, iter [01250, 01251], lr: 0.000616, loss: 0.3988
2022-10-01 15:16:43 - train: epoch 217, train_loss: 0.4058
2022-10-01 15:16:46 - until epoch: 217, best_loss: 0.4058
2022-10-01 15:16:46 - epoch 218 lr: 0.000616
2022-10-01 15:17:09 - train: epoch 0218, iter [00010, 01251], lr: 0.000616, loss: 0.3983
2022-10-01 15:17:27 - train: epoch 0218, iter [00020, 01251], lr: 0.000616, loss: 0.3988
2022-10-01 15:17:45 - train: epoch 0218, iter [00030, 01251], lr: 0.000616, loss: 0.3847
2022-10-01 15:18:04 - train: epoch 0218, iter [00040, 01251], lr: 0.000616, loss: 0.4095
2022-10-01 15:18:22 - train: epoch 0218, iter [00050, 01251], lr: 0.000615, loss: 0.4008
2022-10-01 15:18:40 - train: epoch 0218, iter [00060, 01251], lr: 0.000615, loss: 0.3924
2022-10-01 15:18:58 - train: epoch 0218, iter [00070, 01251], lr: 0.000615, loss: 0.4010
2022-10-01 15:19:16 - train: epoch 0218, iter [00080, 01251], lr: 0.000615, loss: 0.4005
2022-10-01 15:19:35 - train: epoch 0218, iter [00090, 01251], lr: 0.000615, loss: 0.4011
2022-10-01 15:19:53 - train: epoch 0218, iter [00100, 01251], lr: 0.000615, loss: 0.4259
2022-10-01 15:20:11 - train: epoch 0218, iter [00110, 01251], lr: 0.000615, loss: 0.3941
2022-10-01 15:20:29 - train: epoch 0218, iter [00120, 01251], lr: 0.000615, loss: 0.3922
2022-10-01 15:20:47 - train: epoch 0218, iter [00130, 01251], lr: 0.000615, loss: 0.3936
2022-10-01 15:21:06 - train: epoch 0218, iter [00140, 01251], lr: 0.000615, loss: 0.4172
2022-10-01 15:21:24 - train: epoch 0218, iter [00150, 01251], lr: 0.000615, loss: 0.4088
2022-10-01 15:21:42 - train: epoch 0218, iter [00160, 01251], lr: 0.000615, loss: 0.4033
2022-10-01 15:22:00 - train: epoch 0218, iter [00170, 01251], lr: 0.000615, loss: 0.3985
2022-10-01 15:22:18 - train: epoch 0218, iter [00180, 01251], lr: 0.000615, loss: 0.4076
2022-10-01 15:22:36 - train: epoch 0218, iter [00190, 01251], lr: 0.000615, loss: 0.4107
2022-10-01 15:22:54 - train: epoch 0218, iter [00200, 01251], lr: 0.000615, loss: 0.4188
2022-10-01 15:23:12 - train: epoch 0218, iter [00210, 01251], lr: 0.000615, loss: 0.4199
2022-10-01 15:23:31 - train: epoch 0218, iter [00220, 01251], lr: 0.000615, loss: 0.4021
2022-10-01 15:23:49 - train: epoch 0218, iter [00230, 01251], lr: 0.000615, loss: 0.4003
2022-10-01 15:24:07 - train: epoch 0218, iter [00240, 01251], lr: 0.000615, loss: 0.3951
2022-10-01 15:24:25 - train: epoch 0218, iter [00250, 01251], lr: 0.000615, loss: 0.4177
2022-10-01 15:24:43 - train: epoch 0218, iter [00260, 01251], lr: 0.000615, loss: 0.4329
2022-10-01 15:25:01 - train: epoch 0218, iter [00270, 01251], lr: 0.000615, loss: 0.4118
2022-10-01 15:25:20 - train: epoch 0218, iter [00280, 01251], lr: 0.000615, loss: 0.3714
2022-10-01 15:25:38 - train: epoch 0218, iter [00290, 01251], lr: 0.000614, loss: 0.3947
2022-10-01 15:25:56 - train: epoch 0218, iter [00300, 01251], lr: 0.000614, loss: 0.4029
2022-10-01 15:26:15 - train: epoch 0218, iter [00310, 01251], lr: 0.000614, loss: 0.3931
2022-10-01 15:26:33 - train: epoch 0218, iter [00320, 01251], lr: 0.000614, loss: 0.4191
2022-10-01 15:26:51 - train: epoch 0218, iter [00330, 01251], lr: 0.000614, loss: 0.3987
2022-10-01 15:27:09 - train: epoch 0218, iter [00340, 01251], lr: 0.000614, loss: 0.4186
2022-10-01 15:27:28 - train: epoch 0218, iter [00350, 01251], lr: 0.000614, loss: 0.4071
2022-10-01 15:27:46 - train: epoch 0218, iter [00360, 01251], lr: 0.000614, loss: 0.3992
2022-10-01 15:28:04 - train: epoch 0218, iter [00370, 01251], lr: 0.000614, loss: 0.4093
2022-10-01 15:28:22 - train: epoch 0218, iter [00380, 01251], lr: 0.000614, loss: 0.4008
2022-10-01 15:28:40 - train: epoch 0218, iter [00390, 01251], lr: 0.000614, loss: 0.4187
2022-10-01 15:28:58 - train: epoch 0218, iter [00400, 01251], lr: 0.000614, loss: 0.4323
2022-10-01 15:29:16 - train: epoch 0218, iter [00410, 01251], lr: 0.000614, loss: 0.3948
2022-10-01 15:29:34 - train: epoch 0218, iter [00420, 01251], lr: 0.000614, loss: 0.4067
2022-10-01 15:29:53 - train: epoch 0218, iter [00430, 01251], lr: 0.000614, loss: 0.3980
2022-10-01 15:30:10 - train: epoch 0218, iter [00440, 01251], lr: 0.000614, loss: 0.4155
2022-10-01 15:30:29 - train: epoch 0218, iter [00450, 01251], lr: 0.000614, loss: 0.4182
2022-10-01 15:30:47 - train: epoch 0218, iter [00460, 01251], lr: 0.000614, loss: 0.3803
2022-10-01 15:31:05 - train: epoch 0218, iter [00470, 01251], lr: 0.000614, loss: 0.4008
2022-10-01 15:31:23 - train: epoch 0218, iter [00480, 01251], lr: 0.000614, loss: 0.4147
2022-10-01 15:31:42 - train: epoch 0218, iter [00490, 01251], lr: 0.000614, loss: 0.4061
2022-10-01 15:32:00 - train: epoch 0218, iter [00500, 01251], lr: 0.000614, loss: 0.4273
2022-10-01 15:32:18 - train: epoch 0218, iter [00510, 01251], lr: 0.000614, loss: 0.4014
2022-10-01 15:32:36 - train: epoch 0218, iter [00520, 01251], lr: 0.000614, loss: 0.4232
2022-10-01 15:32:55 - train: epoch 0218, iter [00530, 01251], lr: 0.000613, loss: 0.4203
2022-10-01 15:33:13 - train: epoch 0218, iter [00540, 01251], lr: 0.000613, loss: 0.4137
2022-10-01 15:33:31 - train: epoch 0218, iter [00550, 01251], lr: 0.000613, loss: 0.4126
2022-10-01 15:33:49 - train: epoch 0218, iter [00560, 01251], lr: 0.000613, loss: 0.4152
2022-10-01 15:34:08 - train: epoch 0218, iter [00570, 01251], lr: 0.000613, loss: 0.4187
2022-10-01 15:34:26 - train: epoch 0218, iter [00580, 01251], lr: 0.000613, loss: 0.4105
2022-10-01 15:34:44 - train: epoch 0218, iter [00590, 01251], lr: 0.000613, loss: 0.4073
2022-10-01 15:35:02 - train: epoch 0218, iter [00600, 01251], lr: 0.000613, loss: 0.4050
2022-10-01 15:35:21 - train: epoch 0218, iter [00610, 01251], lr: 0.000613, loss: 0.4255
2022-10-01 15:35:39 - train: epoch 0218, iter [00620, 01251], lr: 0.000613, loss: 0.4159
2022-10-01 15:35:57 - train: epoch 0218, iter [00630, 01251], lr: 0.000613, loss: 0.4014
2022-10-01 15:36:16 - train: epoch 0218, iter [00640, 01251], lr: 0.000613, loss: 0.4129
2022-10-01 15:36:34 - train: epoch 0218, iter [00650, 01251], lr: 0.000613, loss: 0.4088
2022-10-01 15:36:52 - train: epoch 0218, iter [00660, 01251], lr: 0.000613, loss: 0.3941
2022-10-01 15:37:10 - train: epoch 0218, iter [00670, 01251], lr: 0.000613, loss: 0.4119
2022-10-01 15:37:28 - train: epoch 0218, iter [00680, 01251], lr: 0.000613, loss: 0.4099
2022-10-01 15:37:46 - train: epoch 0218, iter [00690, 01251], lr: 0.000613, loss: 0.4085
2022-10-01 15:38:05 - train: epoch 0218, iter [00700, 01251], lr: 0.000613, loss: 0.3995
2022-10-01 15:38:23 - train: epoch 0218, iter [00710, 01251], lr: 0.000613, loss: 0.4191
2022-10-01 15:38:41 - train: epoch 0218, iter [00720, 01251], lr: 0.000613, loss: 0.4047
2022-10-01 15:38:59 - train: epoch 0218, iter [00730, 01251], lr: 0.000613, loss: 0.4139
2022-10-01 15:39:17 - train: epoch 0218, iter [00740, 01251], lr: 0.000613, loss: 0.4128
2022-10-01 15:39:36 - train: epoch 0218, iter [00750, 01251], lr: 0.000613, loss: 0.3969
2022-10-01 15:39:54 - train: epoch 0218, iter [00760, 01251], lr: 0.000613, loss: 0.4028
2022-10-01 15:40:12 - train: epoch 0218, iter [00770, 01251], lr: 0.000612, loss: 0.4153
2022-10-01 15:40:30 - train: epoch 0218, iter [00780, 01251], lr: 0.000612, loss: 0.3946
2022-10-01 15:40:49 - train: epoch 0218, iter [00790, 01251], lr: 0.000612, loss: 0.4057
2022-10-01 15:41:07 - train: epoch 0218, iter [00800, 01251], lr: 0.000612, loss: 0.4077
2022-10-01 15:41:25 - train: epoch 0218, iter [00810, 01251], lr: 0.000612, loss: 0.4176
2022-10-01 15:41:43 - train: epoch 0218, iter [00820, 01251], lr: 0.000612, loss: 0.3874
2022-10-01 15:42:01 - train: epoch 0218, iter [00830, 01251], lr: 0.000612, loss: 0.4077
2022-10-01 15:42:20 - train: epoch 0218, iter [00840, 01251], lr: 0.000612, loss: 0.4096
2022-10-01 15:42:38 - train: epoch 0218, iter [00850, 01251], lr: 0.000612, loss: 0.4035
2022-10-01 15:42:56 - train: epoch 0218, iter [00860, 01251], lr: 0.000612, loss: 0.4060
2022-10-01 15:43:14 - train: epoch 0218, iter [00870, 01251], lr: 0.000612, loss: 0.4044
2022-10-01 15:43:32 - train: epoch 0218, iter [00880, 01251], lr: 0.000612, loss: 0.3853
2022-10-01 15:43:50 - train: epoch 0218, iter [00890, 01251], lr: 0.000612, loss: 0.4243
2022-10-01 15:44:08 - train: epoch 0218, iter [00900, 01251], lr: 0.000612, loss: 0.3970
2022-10-01 15:44:26 - train: epoch 0218, iter [00910, 01251], lr: 0.000612, loss: 0.4260
2022-10-01 15:44:44 - train: epoch 0218, iter [00920, 01251], lr: 0.000612, loss: 0.4000
2022-10-01 15:45:03 - train: epoch 0218, iter [00930, 01251], lr: 0.000612, loss: 0.4234
2022-10-01 15:45:21 - train: epoch 0218, iter [00940, 01251], lr: 0.000612, loss: 0.4046
2022-10-01 15:45:39 - train: epoch 0218, iter [00950, 01251], lr: 0.000612, loss: 0.4143
2022-10-01 15:45:57 - train: epoch 0218, iter [00960, 01251], lr: 0.000612, loss: 0.4110
2022-10-01 15:46:15 - train: epoch 0218, iter [00970, 01251], lr: 0.000612, loss: 0.4000
2022-10-01 15:46:33 - train: epoch 0218, iter [00980, 01251], lr: 0.000612, loss: 0.4078
2022-10-01 15:46:51 - train: epoch 0218, iter [00990, 01251], lr: 0.000612, loss: 0.3857
2022-10-01 15:47:09 - train: epoch 0218, iter [01000, 01251], lr: 0.000612, loss: 0.3875
2022-10-01 15:47:28 - train: epoch 0218, iter [01010, 01251], lr: 0.000611, loss: 0.4037
2022-10-01 15:47:46 - train: epoch 0218, iter [01020, 01251], lr: 0.000611, loss: 0.4184
2022-10-01 15:48:04 - train: epoch 0218, iter [01030, 01251], lr: 0.000611, loss: 0.4001
2022-10-01 15:48:22 - train: epoch 0218, iter [01040, 01251], lr: 0.000611, loss: 0.4157
2022-10-01 15:48:40 - train: epoch 0218, iter [01050, 01251], lr: 0.000611, loss: 0.4136
2022-10-01 15:48:58 - train: epoch 0218, iter [01060, 01251], lr: 0.000611, loss: 0.4167
2022-10-01 15:49:16 - train: epoch 0218, iter [01070, 01251], lr: 0.000611, loss: 0.3955
2022-10-01 15:49:34 - train: epoch 0218, iter [01080, 01251], lr: 0.000611, loss: 0.4204
2022-10-01 15:49:53 - train: epoch 0218, iter [01090, 01251], lr: 0.000611, loss: 0.4257
2022-10-01 15:50:11 - train: epoch 0218, iter [01100, 01251], lr: 0.000611, loss: 0.3861
2022-10-01 15:50:29 - train: epoch 0218, iter [01110, 01251], lr: 0.000611, loss: 0.3931
2022-10-01 15:50:47 - train: epoch 0218, iter [01120, 01251], lr: 0.000611, loss: 0.4152
2022-10-01 15:51:05 - train: epoch 0218, iter [01130, 01251], lr: 0.000611, loss: 0.4204
2022-10-01 15:51:23 - train: epoch 0218, iter [01140, 01251], lr: 0.000611, loss: 0.3973
2022-10-01 15:51:41 - train: epoch 0218, iter [01150, 01251], lr: 0.000611, loss: 0.4079
2022-10-01 15:51:59 - train: epoch 0218, iter [01160, 01251], lr: 0.000611, loss: 0.3868
2022-10-01 15:52:18 - train: epoch 0218, iter [01170, 01251], lr: 0.000611, loss: 0.4133
2022-10-01 15:52:36 - train: epoch 0218, iter [01180, 01251], lr: 0.000611, loss: 0.4057
2022-10-01 15:52:54 - train: epoch 0218, iter [01190, 01251], lr: 0.000611, loss: 0.4223
2022-10-01 15:53:12 - train: epoch 0218, iter [01200, 01251], lr: 0.000611, loss: 0.4003
2022-10-01 15:53:31 - train: epoch 0218, iter [01210, 01251], lr: 0.000611, loss: 0.4144
2022-10-01 15:53:49 - train: epoch 0218, iter [01220, 01251], lr: 0.000611, loss: 0.3967
2022-10-01 15:54:07 - train: epoch 0218, iter [01230, 01251], lr: 0.000611, loss: 0.4090
2022-10-01 15:54:25 - train: epoch 0218, iter [01240, 01251], lr: 0.000611, loss: 0.4050
2022-10-01 15:54:43 - train: epoch 0218, iter [01250, 01251], lr: 0.000610, loss: 0.4245
2022-10-01 15:54:46 - train: epoch 218, train_loss: 0.4056
2022-10-01 15:54:50 - until epoch: 218, best_loss: 0.4056
2022-10-01 15:54:50 - epoch 219 lr: 0.000610
2022-10-01 15:55:14 - train: epoch 0219, iter [00010, 01251], lr: 0.000610, loss: 0.3965
2022-10-01 15:55:32 - train: epoch 0219, iter [00020, 01251], lr: 0.000610, loss: 0.4246
2022-10-01 15:55:50 - train: epoch 0219, iter [00030, 01251], lr: 0.000610, loss: 0.3874
2022-10-01 15:56:08 - train: epoch 0219, iter [00040, 01251], lr: 0.000610, loss: 0.4077
2022-10-01 15:56:26 - train: epoch 0219, iter [00050, 01251], lr: 0.000610, loss: 0.4164
2022-10-01 15:56:43 - train: epoch 0219, iter [00060, 01251], lr: 0.000610, loss: 0.3979
2022-10-01 15:57:01 - train: epoch 0219, iter [00070, 01251], lr: 0.000610, loss: 0.4049
2022-10-01 15:57:19 - train: epoch 0219, iter [00080, 01251], lr: 0.000610, loss: 0.4218
2022-10-01 15:57:37 - train: epoch 0219, iter [00090, 01251], lr: 0.000610, loss: 0.3901
2022-10-01 15:57:55 - train: epoch 0219, iter [00100, 01251], lr: 0.000610, loss: 0.4104
2022-10-01 15:58:13 - train: epoch 0219, iter [00110, 01251], lr: 0.000610, loss: 0.3879
2022-10-01 15:58:31 - train: epoch 0219, iter [00120, 01251], lr: 0.000610, loss: 0.4138
2022-10-01 15:58:49 - train: epoch 0219, iter [00130, 01251], lr: 0.000610, loss: 0.3955
2022-10-01 15:59:06 - train: epoch 0219, iter [00140, 01251], lr: 0.000610, loss: 0.3908
2022-10-01 15:59:24 - train: epoch 0219, iter [00150, 01251], lr: 0.000610, loss: 0.3864
2022-10-01 15:59:42 - train: epoch 0219, iter [00160, 01251], lr: 0.000610, loss: 0.4115
2022-10-01 16:00:00 - train: epoch 0219, iter [00170, 01251], lr: 0.000610, loss: 0.4104
2022-10-01 16:00:18 - train: epoch 0219, iter [00180, 01251], lr: 0.000610, loss: 0.4015
2022-10-01 16:00:36 - train: epoch 0219, iter [00190, 01251], lr: 0.000610, loss: 0.4179
2022-10-01 16:00:54 - train: epoch 0219, iter [00200, 01251], lr: 0.000610, loss: 0.4063
2022-10-01 16:01:12 - train: epoch 0219, iter [00210, 01251], lr: 0.000610, loss: 0.4181
2022-10-01 16:01:30 - train: epoch 0219, iter [00220, 01251], lr: 0.000610, loss: 0.4081
2022-10-01 16:01:48 - train: epoch 0219, iter [00230, 01251], lr: 0.000610, loss: 0.4118
2022-10-01 16:02:06 - train: epoch 0219, iter [00240, 01251], lr: 0.000609, loss: 0.4061
2022-10-01 16:02:24 - train: epoch 0219, iter [00250, 01251], lr: 0.000609, loss: 0.4295
2022-10-01 16:02:42 - train: epoch 0219, iter [00260, 01251], lr: 0.000609, loss: 0.4151
2022-10-01 16:03:00 - train: epoch 0219, iter [00270, 01251], lr: 0.000609, loss: 0.4015
2022-10-01 16:03:18 - train: epoch 0219, iter [00280, 01251], lr: 0.000609, loss: 0.4004
2022-10-01 16:03:36 - train: epoch 0219, iter [00290, 01251], lr: 0.000609, loss: 0.3998
2022-10-01 16:03:53 - train: epoch 0219, iter [00300, 01251], lr: 0.000609, loss: 0.4064
2022-10-01 16:04:12 - train: epoch 0219, iter [00310, 01251], lr: 0.000609, loss: 0.4187
2022-10-01 16:04:30 - train: epoch 0219, iter [00320, 01251], lr: 0.000609, loss: 0.4265
2022-10-01 16:04:48 - train: epoch 0219, iter [00330, 01251], lr: 0.000609, loss: 0.3995
2022-10-01 16:05:06 - train: epoch 0219, iter [00340, 01251], lr: 0.000609, loss: 0.4103
2022-10-01 16:05:24 - train: epoch 0219, iter [00350, 01251], lr: 0.000609, loss: 0.3948
2022-10-01 16:05:42 - train: epoch 0219, iter [00360, 01251], lr: 0.000609, loss: 0.4075
2022-10-01 16:06:00 - train: epoch 0219, iter [00370, 01251], lr: 0.000609, loss: 0.3970
2022-10-01 16:06:18 - train: epoch 0219, iter [00380, 01251], lr: 0.000609, loss: 0.4125
2022-10-01 16:06:36 - train: epoch 0219, iter [00390, 01251], lr: 0.000609, loss: 0.4101
2022-10-01 16:06:54 - train: epoch 0219, iter [00400, 01251], lr: 0.000609, loss: 0.3959
2022-10-01 16:07:12 - train: epoch 0219, iter [00410, 01251], lr: 0.000609, loss: 0.4004
2022-10-01 16:07:30 - train: epoch 0219, iter [00420, 01251], lr: 0.000609, loss: 0.4014
2022-10-01 16:07:48 - train: epoch 0219, iter [00430, 01251], lr: 0.000609, loss: 0.4155
2022-10-01 16:08:06 - train: epoch 0219, iter [00440, 01251], lr: 0.000609, loss: 0.3982
2022-10-01 16:08:24 - train: epoch 0219, iter [00450, 01251], lr: 0.000609, loss: 0.4072
2022-10-01 16:08:42 - train: epoch 0219, iter [00460, 01251], lr: 0.000609, loss: 0.4028
2022-10-01 16:09:00 - train: epoch 0219, iter [00470, 01251], lr: 0.000609, loss: 0.4145
2022-10-01 16:09:18 - train: epoch 0219, iter [00480, 01251], lr: 0.000608, loss: 0.3905
2022-10-01 16:09:36 - train: epoch 0219, iter [00490, 01251], lr: 0.000608, loss: 0.4032
2022-10-01 16:09:54 - train: epoch 0219, iter [00500, 01251], lr: 0.000608, loss: 0.4019
2022-10-01 16:10:12 - train: epoch 0219, iter [00510, 01251], lr: 0.000608, loss: 0.4144
2022-10-01 16:10:30 - train: epoch 0219, iter [00520, 01251], lr: 0.000608, loss: 0.4068
2022-10-01 16:10:48 - train: epoch 0219, iter [00530, 01251], lr: 0.000608, loss: 0.4153
2022-10-01 16:11:06 - train: epoch 0219, iter [00540, 01251], lr: 0.000608, loss: 0.4206
2022-10-01 16:11:24 - train: epoch 0219, iter [00550, 01251], lr: 0.000608, loss: 0.4131
2022-10-01 16:11:42 - train: epoch 0219, iter [00560, 01251], lr: 0.000608, loss: 0.3791
2022-10-01 16:12:00 - train: epoch 0219, iter [00570, 01251], lr: 0.000608, loss: 0.4033
2022-10-01 16:12:18 - train: epoch 0219, iter [00580, 01251], lr: 0.000608, loss: 0.4156
2022-10-01 16:12:36 - train: epoch 0219, iter [00590, 01251], lr: 0.000608, loss: 0.3925
2022-10-01 16:12:54 - train: epoch 0219, iter [00600, 01251], lr: 0.000608, loss: 0.4196
2022-10-01 16:13:12 - train: epoch 0219, iter [00610, 01251], lr: 0.000608, loss: 0.3954
2022-10-01 16:13:30 - train: epoch 0219, iter [00620, 01251], lr: 0.000608, loss: 0.3975
2022-10-01 16:13:48 - train: epoch 0219, iter [00630, 01251], lr: 0.000608, loss: 0.4303
2022-10-01 16:14:06 - train: epoch 0219, iter [00640, 01251], lr: 0.000608, loss: 0.4027
2022-10-01 16:14:24 - train: epoch 0219, iter [00650, 01251], lr: 0.000608, loss: 0.4171
2022-10-01 16:14:42 - train: epoch 0219, iter [00660, 01251], lr: 0.000608, loss: 0.4208
2022-10-01 16:15:00 - train: epoch 0219, iter [00670, 01251], lr: 0.000608, loss: 0.3931
2022-10-01 16:15:18 - train: epoch 0219, iter [00680, 01251], lr: 0.000608, loss: 0.3943
2022-10-01 16:15:36 - train: epoch 0219, iter [00690, 01251], lr: 0.000608, loss: 0.4184
2022-10-01 16:15:54 - train: epoch 0219, iter [00700, 01251], lr: 0.000608, loss: 0.4202
2022-10-01 16:16:12 - train: epoch 0219, iter [00710, 01251], lr: 0.000608, loss: 0.4014
2022-10-01 16:16:30 - train: epoch 0219, iter [00720, 01251], lr: 0.000607, loss: 0.4145
2022-10-01 16:16:48 - train: epoch 0219, iter [00730, 01251], lr: 0.000607, loss: 0.4075
2022-10-01 16:17:06 - train: epoch 0219, iter [00740, 01251], lr: 0.000607, loss: 0.4077
2022-10-01 16:17:24 - train: epoch 0219, iter [00750, 01251], lr: 0.000607, loss: 0.4135
2022-10-01 16:17:42 - train: epoch 0219, iter [00760, 01251], lr: 0.000607, loss: 0.3945
2022-10-01 16:18:00 - train: epoch 0219, iter [00770, 01251], lr: 0.000607, loss: 0.4080
2022-10-01 16:18:18 - train: epoch 0219, iter [00780, 01251], lr: 0.000607, loss: 0.3878
2022-10-01 16:18:36 - train: epoch 0219, iter [00790, 01251], lr: 0.000607, loss: 0.4082
2022-10-01 16:18:54 - train: epoch 0219, iter [00800, 01251], lr: 0.000607, loss: 0.4151
2022-10-01 16:19:12 - train: epoch 0219, iter [00810, 01251], lr: 0.000607, loss: 0.4043
2022-10-01 16:19:30 - train: epoch 0219, iter [00820, 01251], lr: 0.000607, loss: 0.3896
2022-10-01 16:19:48 - train: epoch 0219, iter [00830, 01251], lr: 0.000607, loss: 0.4141
2022-10-01 16:20:06 - train: epoch 0219, iter [00840, 01251], lr: 0.000607, loss: 0.4119
2022-10-01 16:20:25 - train: epoch 0219, iter [00850, 01251], lr: 0.000607, loss: 0.4065
2022-10-01 16:20:43 - train: epoch 0219, iter [00860, 01251], lr: 0.000607, loss: 0.4425
2022-10-01 16:21:01 - train: epoch 0219, iter [00870, 01251], lr: 0.000607, loss: 0.3961
2022-10-01 16:21:19 - train: epoch 0219, iter [00880, 01251], lr: 0.000607, loss: 0.4206
2022-10-01 16:21:37 - train: epoch 0219, iter [00890, 01251], lr: 0.000607, loss: 0.3847
2022-10-01 16:21:55 - train: epoch 0219, iter [00900, 01251], lr: 0.000607, loss: 0.4061
2022-10-01 16:22:13 - train: epoch 0219, iter [00910, 01251], lr: 0.000607, loss: 0.3715
2022-10-01 16:22:31 - train: epoch 0219, iter [00920, 01251], lr: 0.000607, loss: 0.4064
2022-10-01 16:22:49 - train: epoch 0219, iter [00930, 01251], lr: 0.000607, loss: 0.4120
2022-10-01 16:23:07 - train: epoch 0219, iter [00940, 01251], lr: 0.000607, loss: 0.3895
2022-10-01 16:23:25 - train: epoch 0219, iter [00950, 01251], lr: 0.000606, loss: 0.4196
2022-10-01 16:23:43 - train: epoch 0219, iter [00960, 01251], lr: 0.000606, loss: 0.3954
2022-10-01 16:24:01 - train: epoch 0219, iter [00970, 01251], lr: 0.000606, loss: 0.4289
2022-10-01 16:24:19 - train: epoch 0219, iter [00980, 01251], lr: 0.000606, loss: 0.4145
2022-10-01 16:24:37 - train: epoch 0219, iter [00990, 01251], lr: 0.000606, loss: 0.4112
2022-10-01 16:24:55 - train: epoch 0219, iter [01000, 01251], lr: 0.000606, loss: 0.3662
2022-10-01 16:25:13 - train: epoch 0219, iter [01010, 01251], lr: 0.000606, loss: 0.3967
2022-10-01 16:25:31 - train: epoch 0219, iter [01020, 01251], lr: 0.000606, loss: 0.3972
2022-10-01 16:25:49 - train: epoch 0219, iter [01030, 01251], lr: 0.000606, loss: 0.3947
2022-10-01 16:26:07 - train: epoch 0219, iter [01040, 01251], lr: 0.000606, loss: 0.4084
2022-10-01 16:26:25 - train: epoch 0219, iter [01050, 01251], lr: 0.000606, loss: 0.4233
2022-10-01 16:26:43 - train: epoch 0219, iter [01060, 01251], lr: 0.000606, loss: 0.3957
2022-10-01 16:27:01 - train: epoch 0219, iter [01070, 01251], lr: 0.000606, loss: 0.4111
2022-10-01 16:27:20 - train: epoch 0219, iter [01080, 01251], lr: 0.000606, loss: 0.3891
2022-10-01 16:27:38 - train: epoch 0219, iter [01090, 01251], lr: 0.000606, loss: 0.4124
2022-10-01 16:27:56 - train: epoch 0219, iter [01100, 01251], lr: 0.000606, loss: 0.3985
2022-10-01 16:28:14 - train: epoch 0219, iter [01110, 01251], lr: 0.000606, loss: 0.4005
2022-10-01 16:28:32 - train: epoch 0219, iter [01120, 01251], lr: 0.000606, loss: 0.3958
2022-10-01 16:28:50 - train: epoch 0219, iter [01130, 01251], lr: 0.000606, loss: 0.4040
2022-10-01 16:29:08 - train: epoch 0219, iter [01140, 01251], lr: 0.000606, loss: 0.4027
2022-10-01 16:29:26 - train: epoch 0219, iter [01150, 01251], lr: 0.000606, loss: 0.4133
2022-10-01 16:29:44 - train: epoch 0219, iter [01160, 01251], lr: 0.000606, loss: 0.4194
2022-10-01 16:30:02 - train: epoch 0219, iter [01170, 01251], lr: 0.000606, loss: 0.4025
2022-10-01 16:30:20 - train: epoch 0219, iter [01180, 01251], lr: 0.000606, loss: 0.4068
2022-10-01 16:30:38 - train: epoch 0219, iter [01190, 01251], lr: 0.000605, loss: 0.3984
2022-10-01 16:30:56 - train: epoch 0219, iter [01200, 01251], lr: 0.000605, loss: 0.4156
2022-10-01 16:31:14 - train: epoch 0219, iter [01210, 01251], lr: 0.000605, loss: 0.4008
2022-10-01 16:31:32 - train: epoch 0219, iter [01220, 01251], lr: 0.000605, loss: 0.3800
2022-10-01 16:31:50 - train: epoch 0219, iter [01230, 01251], lr: 0.000605, loss: 0.3952
2022-10-01 16:32:08 - train: epoch 0219, iter [01240, 01251], lr: 0.000605, loss: 0.4229
2022-10-01 16:32:26 - train: epoch 0219, iter [01250, 01251], lr: 0.000605, loss: 0.4070
2022-10-01 16:32:29 - train: epoch 219, train_loss: 0.4055
2022-10-01 16:32:32 - until epoch: 219, best_loss: 0.4055
2022-10-01 16:32:32 - epoch 220 lr: 0.000605
2022-10-01 16:32:57 - train: epoch 0220, iter [00010, 01251], lr: 0.000605, loss: 0.4032
2022-10-01 16:33:15 - train: epoch 0220, iter [00020, 01251], lr: 0.000605, loss: 0.4025
2022-10-01 16:33:33 - train: epoch 0220, iter [00030, 01251], lr: 0.000605, loss: 0.4171
2022-10-01 16:33:51 - train: epoch 0220, iter [00040, 01251], lr: 0.000605, loss: 0.4209
2022-10-01 16:34:10 - train: epoch 0220, iter [00050, 01251], lr: 0.000605, loss: 0.3995
2022-10-01 16:34:28 - train: epoch 0220, iter [00060, 01251], lr: 0.000605, loss: 0.4127
2022-10-01 16:34:46 - train: epoch 0220, iter [00070, 01251], lr: 0.000605, loss: 0.4125
2022-10-01 16:35:04 - train: epoch 0220, iter [00080, 01251], lr: 0.000605, loss: 0.3966
2022-10-01 16:35:22 - train: epoch 0220, iter [00090, 01251], lr: 0.000605, loss: 0.3882
2022-10-01 16:35:41 - train: epoch 0220, iter [00100, 01251], lr: 0.000605, loss: 0.4070
2022-10-01 16:35:59 - train: epoch 0220, iter [00110, 01251], lr: 0.000605, loss: 0.3991
2022-10-01 16:36:17 - train: epoch 0220, iter [00120, 01251], lr: 0.000605, loss: 0.4077
2022-10-01 16:36:35 - train: epoch 0220, iter [00130, 01251], lr: 0.000605, loss: 0.4158
2022-10-01 16:36:53 - train: epoch 0220, iter [00140, 01251], lr: 0.000605, loss: 0.4213
2022-10-01 16:37:11 - train: epoch 0220, iter [00150, 01251], lr: 0.000605, loss: 0.4137
2022-10-01 16:37:29 - train: epoch 0220, iter [00160, 01251], lr: 0.000605, loss: 0.4235
2022-10-01 16:37:48 - train: epoch 0220, iter [00170, 01251], lr: 0.000605, loss: 0.3996
2022-10-01 16:38:06 - train: epoch 0220, iter [00180, 01251], lr: 0.000604, loss: 0.3885
2022-10-01 16:38:24 - train: epoch 0220, iter [00190, 01251], lr: 0.000604, loss: 0.4236
2022-10-01 16:38:42 - train: epoch 0220, iter [00200, 01251], lr: 0.000604, loss: 0.4090
2022-10-01 16:39:00 - train: epoch 0220, iter [00210, 01251], lr: 0.000604, loss: 0.4040
2022-10-01 16:39:18 - train: epoch 0220, iter [00220, 01251], lr: 0.000604, loss: 0.3949
2022-10-01 16:39:36 - train: epoch 0220, iter [00230, 01251], lr: 0.000604, loss: 0.3991
2022-10-01 16:39:54 - train: epoch 0220, iter [00240, 01251], lr: 0.000604, loss: 0.4118
2022-10-01 16:40:13 - train: epoch 0220, iter [00250, 01251], lr: 0.000604, loss: 0.3926
2022-10-01 16:40:31 - train: epoch 0220, iter [00260, 01251], lr: 0.000604, loss: 0.4135
2022-10-01 16:40:49 - train: epoch 0220, iter [00270, 01251], lr: 0.000604, loss: 0.4183
2022-10-01 16:41:07 - train: epoch 0220, iter [00280, 01251], lr: 0.000604, loss: 0.3972
2022-10-01 16:41:25 - train: epoch 0220, iter [00290, 01251], lr: 0.000604, loss: 0.4100
2022-10-01 16:41:44 - train: epoch 0220, iter [00300, 01251], lr: 0.000604, loss: 0.4038
2022-10-01 16:42:02 - train: epoch 0220, iter [00310, 01251], lr: 0.000604, loss: 0.4042
2022-10-01 16:42:20 - train: epoch 0220, iter [00320, 01251], lr: 0.000604, loss: 0.4199
2022-10-01 16:42:38 - train: epoch 0220, iter [00330, 01251], lr: 0.000604, loss: 0.4206
2022-10-01 16:42:56 - train: epoch 0220, iter [00340, 01251], lr: 0.000604, loss: 0.4016
2022-10-01 16:43:14 - train: epoch 0220, iter [00350, 01251], lr: 0.000604, loss: 0.4015
2022-10-01 16:43:32 - train: epoch 0220, iter [00360, 01251], lr: 0.000604, loss: 0.3856
2022-10-01 16:43:50 - train: epoch 0220, iter [00370, 01251], lr: 0.000604, loss: 0.4043
2022-10-01 16:44:08 - train: epoch 0220, iter [00380, 01251], lr: 0.000604, loss: 0.3939
2022-10-01 16:44:26 - train: epoch 0220, iter [00390, 01251], lr: 0.000604, loss: 0.4034
2022-10-01 16:44:44 - train: epoch 0220, iter [00400, 01251], lr: 0.000604, loss: 0.4222
2022-10-01 16:45:02 - train: epoch 0220, iter [00410, 01251], lr: 0.000604, loss: 0.4193
2022-10-01 16:45:21 - train: epoch 0220, iter [00420, 01251], lr: 0.000603, loss: 0.4113
2022-10-01 16:45:39 - train: epoch 0220, iter [00430, 01251], lr: 0.000603, loss: 0.3991
2022-10-01 16:45:57 - train: epoch 0220, iter [00440, 01251], lr: 0.000603, loss: 0.4081
2022-10-01 16:46:16 - train: epoch 0220, iter [00450, 01251], lr: 0.000603, loss: 0.4025
2022-10-01 16:46:34 - train: epoch 0220, iter [00460, 01251], lr: 0.000603, loss: 0.4173
2022-10-01 16:46:52 - train: epoch 0220, iter [00470, 01251], lr: 0.000603, loss: 0.4013
2022-10-01 16:47:10 - train: epoch 0220, iter [00480, 01251], lr: 0.000603, loss: 0.3994
2022-10-01 16:47:28 - train: epoch 0220, iter [00490, 01251], lr: 0.000603, loss: 0.3836
2022-10-01 16:47:46 - train: epoch 0220, iter [00500, 01251], lr: 0.000603, loss: 0.4283
2022-10-01 16:48:04 - train: epoch 0220, iter [00510, 01251], lr: 0.000603, loss: 0.3970
2022-10-01 16:48:22 - train: epoch 0220, iter [00520, 01251], lr: 0.000603, loss: 0.4221
2022-10-01 16:48:40 - train: epoch 0220, iter [00530, 01251], lr: 0.000603, loss: 0.3985
2022-10-01 16:48:58 - train: epoch 0220, iter [00540, 01251], lr: 0.000603, loss: 0.4091
2022-10-01 16:49:16 - train: epoch 0220, iter [00550, 01251], lr: 0.000603, loss: 0.4142
2022-10-01 16:49:34 - train: epoch 0220, iter [00560, 01251], lr: 0.000603, loss: 0.4134
2022-10-01 16:49:52 - train: epoch 0220, iter [00570, 01251], lr: 0.000603, loss: 0.4010
2022-10-01 16:50:10 - train: epoch 0220, iter [00580, 01251], lr: 0.000603, loss: 0.4141
2022-10-01 16:50:28 - train: epoch 0220, iter [00590, 01251], lr: 0.000603, loss: 0.3969
2022-10-01 16:50:47 - train: epoch 0220, iter [00600, 01251], lr: 0.000603, loss: 0.3965
2022-10-01 16:51:05 - train: epoch 0220, iter [00610, 01251], lr: 0.000603, loss: 0.3955
2022-10-01 16:51:23 - train: epoch 0220, iter [00620, 01251], lr: 0.000603, loss: 0.4101
2022-10-01 16:51:41 - train: epoch 0220, iter [00630, 01251], lr: 0.000603, loss: 0.4194
2022-10-01 16:51:59 - train: epoch 0220, iter [00640, 01251], lr: 0.000603, loss: 0.4041
2022-10-01 16:52:17 - train: epoch 0220, iter [00650, 01251], lr: 0.000603, loss: 0.3949
2022-10-01 16:52:35 - train: epoch 0220, iter [00660, 01251], lr: 0.000602, loss: 0.3846
2022-10-01 16:52:53 - train: epoch 0220, iter [00670, 01251], lr: 0.000602, loss: 0.4071
2022-10-01 16:53:12 - train: epoch 0220, iter [00680, 01251], lr: 0.000602, loss: 0.4056
2022-10-01 16:53:30 - train: epoch 0220, iter [00690, 01251], lr: 0.000602, loss: 0.4195
2022-10-01 16:53:48 - train: epoch 0220, iter [00700, 01251], lr: 0.000602, loss: 0.3993
2022-10-01 16:54:06 - train: epoch 0220, iter [00710, 01251], lr: 0.000602, loss: 0.4330
2022-10-01 16:54:24 - train: epoch 0220, iter [00720, 01251], lr: 0.000602, loss: 0.3997
2022-10-01 16:54:42 - train: epoch 0220, iter [00730, 01251], lr: 0.000602, loss: 0.4014
2022-10-01 16:55:00 - train: epoch 0220, iter [00740, 01251], lr: 0.000602, loss: 0.4181
2022-10-01 16:55:18 - train: epoch 0220, iter [00750, 01251], lr: 0.000602, loss: 0.4225
2022-10-01 16:55:37 - train: epoch 0220, iter [00760, 01251], lr: 0.000602, loss: 0.4197
2022-10-01 16:55:55 - train: epoch 0220, iter [00770, 01251], lr: 0.000602, loss: 0.3885
2022-10-01 16:56:13 - train: epoch 0220, iter [00780, 01251], lr: 0.000602, loss: 0.3903
2022-10-01 16:56:31 - train: epoch 0220, iter [00790, 01251], lr: 0.000602, loss: 0.4090
2022-10-01 16:56:49 - train: epoch 0220, iter [00800, 01251], lr: 0.000602, loss: 0.4086
2022-10-01 16:57:07 - train: epoch 0220, iter [00810, 01251], lr: 0.000602, loss: 0.4117
2022-10-01 16:57:26 - train: epoch 0220, iter [00820, 01251], lr: 0.000602, loss: 0.3999
2022-10-01 16:57:44 - train: epoch 0220, iter [00830, 01251], lr: 0.000602, loss: 0.3923
2022-10-01 16:58:02 - train: epoch 0220, iter [00840, 01251], lr: 0.000602, loss: 0.4200
2022-10-01 16:58:20 - train: epoch 0220, iter [00850, 01251], lr: 0.000602, loss: 0.4114
2022-10-01 16:58:39 - train: epoch 0220, iter [00860, 01251], lr: 0.000602, loss: 0.4192
2022-10-01 16:58:57 - train: epoch 0220, iter [00870, 01251], lr: 0.000602, loss: 0.3959
2022-10-01 16:59:15 - train: epoch 0220, iter [00880, 01251], lr: 0.000602, loss: 0.4057
2022-10-01 16:59:33 - train: epoch 0220, iter [00890, 01251], lr: 0.000602, loss: 0.4029
2022-10-01 16:59:51 - train: epoch 0220, iter [00900, 01251], lr: 0.000601, loss: 0.4078
2022-10-01 17:00:09 - train: epoch 0220, iter [00910, 01251], lr: 0.000601, loss: 0.4086
2022-10-01 17:00:27 - train: epoch 0220, iter [00920, 01251], lr: 0.000601, loss: 0.4052
2022-10-01 17:00:45 - train: epoch 0220, iter [00930, 01251], lr: 0.000601, loss: 0.4008
2022-10-01 17:01:03 - train: epoch 0220, iter [00940, 01251], lr: 0.000601, loss: 0.4162
2022-10-01 17:01:21 - train: epoch 0220, iter [00950, 01251], lr: 0.000601, loss: 0.4343
2022-10-01 17:01:39 - train: epoch 0220, iter [00960, 01251], lr: 0.000601, loss: 0.3947
2022-10-01 17:01:57 - train: epoch 0220, iter [00970, 01251], lr: 0.000601, loss: 0.4059
2022-10-01 17:02:15 - train: epoch 0220, iter [00980, 01251], lr: 0.000601, loss: 0.4146
2022-10-01 17:02:33 - train: epoch 0220, iter [00990, 01251], lr: 0.000601, loss: 0.4044
2022-10-01 17:02:51 - train: epoch 0220, iter [01000, 01251], lr: 0.000601, loss: 0.4198
2022-10-01 17:03:09 - train: epoch 0220, iter [01010, 01251], lr: 0.000601, loss: 0.4016
2022-10-01 17:03:27 - train: epoch 0220, iter [01020, 01251], lr: 0.000601, loss: 0.4377
2022-10-01 17:03:45 - train: epoch 0220, iter [01030, 01251], lr: 0.000601, loss: 0.4205
2022-10-01 17:04:03 - train: epoch 0220, iter [01040, 01251], lr: 0.000601, loss: 0.4165
2022-10-01 17:04:21 - train: epoch 0220, iter [01050, 01251], lr: 0.000601, loss: 0.4209
2022-10-01 17:04:39 - train: epoch 0220, iter [01060, 01251], lr: 0.000601, loss: 0.4143
2022-10-01 17:04:57 - train: epoch 0220, iter [01070, 01251], lr: 0.000601, loss: 0.3952
2022-10-01 17:05:15 - train: epoch 0220, iter [01080, 01251], lr: 0.000601, loss: 0.3865
2022-10-01 17:05:33 - train: epoch 0220, iter [01090, 01251], lr: 0.000601, loss: 0.4002
2022-10-01 17:05:51 - train: epoch 0220, iter [01100, 01251], lr: 0.000601, loss: 0.3959
2022-10-01 17:06:10 - train: epoch 0220, iter [01110, 01251], lr: 0.000601, loss: 0.4336
2022-10-01 17:06:28 - train: epoch 0220, iter [01120, 01251], lr: 0.000601, loss: 0.4212
2022-10-01 17:06:46 - train: epoch 0220, iter [01130, 01251], lr: 0.000601, loss: 0.3837
2022-10-01 17:07:04 - train: epoch 0220, iter [01140, 01251], lr: 0.000600, loss: 0.4008
2022-10-01 17:07:22 - train: epoch 0220, iter [01150, 01251], lr: 0.000600, loss: 0.4090
2022-10-01 17:07:40 - train: epoch 0220, iter [01160, 01251], lr: 0.000600, loss: 0.4016
2022-10-01 17:07:58 - train: epoch 0220, iter [01170, 01251], lr: 0.000600, loss: 0.4085
2022-10-01 17:08:16 - train: epoch 0220, iter [01180, 01251], lr: 0.000600, loss: 0.3973
2022-10-01 17:08:34 - train: epoch 0220, iter [01190, 01251], lr: 0.000600, loss: 0.4143
2022-10-01 17:08:53 - train: epoch 0220, iter [01200, 01251], lr: 0.000600, loss: 0.4175
2022-10-01 17:09:11 - train: epoch 0220, iter [01210, 01251], lr: 0.000600, loss: 0.4105
2022-10-01 17:09:29 - train: epoch 0220, iter [01220, 01251], lr: 0.000600, loss: 0.3907
2022-10-01 17:09:47 - train: epoch 0220, iter [01230, 01251], lr: 0.000600, loss: 0.3974
2022-10-01 17:10:04 - train: epoch 0220, iter [01240, 01251], lr: 0.000600, loss: 0.4016
2022-10-01 17:10:22 - train: epoch 0220, iter [01250, 01251], lr: 0.000600, loss: 0.4196
2022-10-01 17:10:25 - train: epoch 220, train_loss: 0.4055
2022-10-01 17:10:28 - until epoch: 220, best_loss: 0.4055
2022-10-01 17:10:28 - epoch 221 lr: 0.000600
2022-10-01 17:10:52 - train: epoch 0221, iter [00010, 01251], lr: 0.000600, loss: 0.3983
2022-10-01 17:11:11 - train: epoch 0221, iter [00020, 01251], lr: 0.000600, loss: 0.4039
2022-10-01 17:11:29 - train: epoch 0221, iter [00030, 01251], lr: 0.000600, loss: 0.3772
2022-10-01 17:11:48 - train: epoch 0221, iter [00040, 01251], lr: 0.000600, loss: 0.3979
2022-10-01 17:12:06 - train: epoch 0221, iter [00050, 01251], lr: 0.000600, loss: 0.3845
2022-10-01 17:12:24 - train: epoch 0221, iter [00060, 01251], lr: 0.000600, loss: 0.4067
2022-10-01 17:12:43 - train: epoch 0221, iter [00070, 01251], lr: 0.000600, loss: 0.4034
2022-10-01 17:13:01 - train: epoch 0221, iter [00080, 01251], lr: 0.000600, loss: 0.4112
2022-10-01 17:13:19 - train: epoch 0221, iter [00090, 01251], lr: 0.000600, loss: 0.4079
2022-10-01 17:13:38 - train: epoch 0221, iter [00100, 01251], lr: 0.000600, loss: 0.4194
2022-10-01 17:13:56 - train: epoch 0221, iter [00110, 01251], lr: 0.000600, loss: 0.3980
2022-10-01 17:14:14 - train: epoch 0221, iter [00120, 01251], lr: 0.000599, loss: 0.4049
2022-10-01 17:14:32 - train: epoch 0221, iter [00130, 01251], lr: 0.000599, loss: 0.4107
2022-10-01 17:14:51 - train: epoch 0221, iter [00140, 01251], lr: 0.000599, loss: 0.4219
2022-10-01 17:15:09 - train: epoch 0221, iter [00150, 01251], lr: 0.000599, loss: 0.4063
2022-10-01 17:15:27 - train: epoch 0221, iter [00160, 01251], lr: 0.000599, loss: 0.4111
2022-10-01 17:15:46 - train: epoch 0221, iter [00170, 01251], lr: 0.000599, loss: 0.4089
2022-10-01 17:16:04 - train: epoch 0221, iter [00180, 01251], lr: 0.000599, loss: 0.4145
2022-10-01 17:16:22 - train: epoch 0221, iter [00190, 01251], lr: 0.000599, loss: 0.4118
2022-10-01 17:16:40 - train: epoch 0221, iter [00200, 01251], lr: 0.000599, loss: 0.4003
2022-10-01 17:16:58 - train: epoch 0221, iter [00210, 01251], lr: 0.000599, loss: 0.4047
2022-10-01 17:17:17 - train: epoch 0221, iter [00220, 01251], lr: 0.000599, loss: 0.4061
2022-10-01 17:17:35 - train: epoch 0221, iter [00230, 01251], lr: 0.000599, loss: 0.4065
2022-10-01 17:17:53 - train: epoch 0221, iter [00240, 01251], lr: 0.000599, loss: 0.4000
2022-10-01 17:18:11 - train: epoch 0221, iter [00250, 01251], lr: 0.000599, loss: 0.3946
2022-10-01 17:18:30 - train: epoch 0221, iter [00260, 01251], lr: 0.000599, loss: 0.4129
2022-10-01 17:18:48 - train: epoch 0221, iter [00270, 01251], lr: 0.000599, loss: 0.3965
2022-10-01 17:19:06 - train: epoch 0221, iter [00280, 01251], lr: 0.000599, loss: 0.3928
2022-10-01 17:19:24 - train: epoch 0221, iter [00290, 01251], lr: 0.000599, loss: 0.4016
2022-10-01 17:19:43 - train: epoch 0221, iter [00300, 01251], lr: 0.000599, loss: 0.3954
2022-10-01 17:20:01 - train: epoch 0221, iter [00310, 01251], lr: 0.000599, loss: 0.4096
2022-10-01 17:20:19 - train: epoch 0221, iter [00320, 01251], lr: 0.000599, loss: 0.3872
2022-10-01 17:20:37 - train: epoch 0221, iter [00330, 01251], lr: 0.000599, loss: 0.4129
2022-10-01 17:20:56 - train: epoch 0221, iter [00340, 01251], lr: 0.000599, loss: 0.3947
2022-10-01 17:21:14 - train: epoch 0221, iter [00350, 01251], lr: 0.000599, loss: 0.3999
2022-10-01 17:21:32 - train: epoch 0221, iter [00360, 01251], lr: 0.000598, loss: 0.4024
2022-10-01 17:21:50 - train: epoch 0221, iter [00370, 01251], lr: 0.000598, loss: 0.4049
2022-10-01 17:22:09 - train: epoch 0221, iter [00380, 01251], lr: 0.000598, loss: 0.3959
2022-10-01 17:22:27 - train: epoch 0221, iter [00390, 01251], lr: 0.000598, loss: 0.4011
2022-10-01 17:22:45 - train: epoch 0221, iter [00400, 01251], lr: 0.000598, loss: 0.3922
2022-10-01 17:23:03 - train: epoch 0221, iter [00410, 01251], lr: 0.000598, loss: 0.4279
2022-10-01 17:23:21 - train: epoch 0221, iter [00420, 01251], lr: 0.000598, loss: 0.3972
2022-10-01 17:23:40 - train: epoch 0221, iter [00430, 01251], lr: 0.000598, loss: 0.4172
2022-10-01 17:23:58 - train: epoch 0221, iter [00440, 01251], lr: 0.000598, loss: 0.3978
2022-10-01 17:24:16 - train: epoch 0221, iter [00450, 01251], lr: 0.000598, loss: 0.3995
2022-10-01 17:24:34 - train: epoch 0221, iter [00460, 01251], lr: 0.000598, loss: 0.3913
2022-10-01 17:24:52 - train: epoch 0221, iter [00470, 01251], lr: 0.000598, loss: 0.4041
2022-10-01 17:25:10 - train: epoch 0221, iter [00480, 01251], lr: 0.000598, loss: 0.4191
2022-10-01 17:25:28 - train: epoch 0221, iter [00490, 01251], lr: 0.000598, loss: 0.3925
2022-10-01 17:25:46 - train: epoch 0221, iter [00500, 01251], lr: 0.000598, loss: 0.4101
2022-10-01 17:26:04 - train: epoch 0221, iter [00510, 01251], lr: 0.000598, loss: 0.4026
2022-10-01 17:26:22 - train: epoch 0221, iter [00520, 01251], lr: 0.000598, loss: 0.4113
2022-10-01 17:26:40 - train: epoch 0221, iter [00530, 01251], lr: 0.000598, loss: 0.4091
2022-10-01 17:26:58 - train: epoch 0221, iter [00540, 01251], lr: 0.000598, loss: 0.4158
2022-10-01 17:27:17 - train: epoch 0221, iter [00550, 01251], lr: 0.000598, loss: 0.4217
2022-10-01 17:27:35 - train: epoch 0221, iter [00560, 01251], lr: 0.000598, loss: 0.4252
2022-10-01 17:27:53 - train: epoch 0221, iter [00570, 01251], lr: 0.000598, loss: 0.4043
2022-10-01 17:28:11 - train: epoch 0221, iter [00580, 01251], lr: 0.000598, loss: 0.3995
2022-10-01 17:28:29 - train: epoch 0221, iter [00590, 01251], lr: 0.000598, loss: 0.4124
2022-10-01 17:28:47 - train: epoch 0221, iter [00600, 01251], lr: 0.000597, loss: 0.4043
2022-10-01 17:29:05 - train: epoch 0221, iter [00610, 01251], lr: 0.000597, loss: 0.4194
2022-10-01 17:29:23 - train: epoch 0221, iter [00620, 01251], lr: 0.000597, loss: 0.4008
2022-10-01 17:29:41 - train: epoch 0221, iter [00630, 01251], lr: 0.000597, loss: 0.3995
2022-10-01 17:30:00 - train: epoch 0221, iter [00640, 01251], lr: 0.000597, loss: 0.3949
2022-10-01 17:30:18 - train: epoch 0221, iter [00650, 01251], lr: 0.000597, loss: 0.4155
2022-10-01 17:30:36 - train: epoch 0221, iter [00660, 01251], lr: 0.000597, loss: 0.4077
2022-10-01 17:30:54 - train: epoch 0221, iter [00670, 01251], lr: 0.000597, loss: 0.3951
2022-10-01 17:31:12 - train: epoch 0221, iter [00680, 01251], lr: 0.000597, loss: 0.4134
2022-10-01 17:31:30 - train: epoch 0221, iter [00690, 01251], lr: 0.000597, loss: 0.4078
2022-10-01 17:31:49 - train: epoch 0221, iter [00700, 01251], lr: 0.000597, loss: 0.4076
2022-10-01 17:32:07 - train: epoch 0221, iter [00710, 01251], lr: 0.000597, loss: 0.4121
2022-10-01 17:32:25 - train: epoch 0221, iter [00720, 01251], lr: 0.000597, loss: 0.4152
2022-10-01 17:32:43 - train: epoch 0221, iter [00730, 01251], lr: 0.000597, loss: 0.3986
2022-10-01 17:33:02 - train: epoch 0221, iter [00740, 01251], lr: 0.000597, loss: 0.4101
2022-10-01 17:33:20 - train: epoch 0221, iter [00750, 01251], lr: 0.000597, loss: 0.3941
2022-10-01 17:33:38 - train: epoch 0221, iter [00760, 01251], lr: 0.000597, loss: 0.3894
2022-10-01 17:33:56 - train: epoch 0221, iter [00770, 01251], lr: 0.000597, loss: 0.4025
2022-10-01 17:34:14 - train: epoch 0221, iter [00780, 01251], lr: 0.000597, loss: 0.4085
2022-10-01 17:34:33 - train: epoch 0221, iter [00790, 01251], lr: 0.000597, loss: 0.4017
2022-10-01 17:34:51 - train: epoch 0221, iter [00800, 01251], lr: 0.000597, loss: 0.4162
2022-10-01 17:35:09 - train: epoch 0221, iter [00810, 01251], lr: 0.000597, loss: 0.3974
2022-10-01 17:35:28 - train: epoch 0221, iter [00820, 01251], lr: 0.000597, loss: 0.3916
2022-10-01 17:35:46 - train: epoch 0221, iter [00830, 01251], lr: 0.000597, loss: 0.4105
2022-10-01 17:36:04 - train: epoch 0221, iter [00840, 01251], lr: 0.000596, loss: 0.4075
2022-10-01 17:36:22 - train: epoch 0221, iter [00850, 01251], lr: 0.000596, loss: 0.3904
2022-10-01 17:36:40 - train: epoch 0221, iter [00860, 01251], lr: 0.000596, loss: 0.4065
2022-10-01 17:36:58 - train: epoch 0221, iter [00870, 01251], lr: 0.000596, loss: 0.4114
2022-10-01 17:37:17 - train: epoch 0221, iter [00880, 01251], lr: 0.000596, loss: 0.4133
2022-10-01 17:37:35 - train: epoch 0221, iter [00890, 01251], lr: 0.000596, loss: 0.4075
2022-10-01 17:37:53 - train: epoch 0221, iter [00900, 01251], lr: 0.000596, loss: 0.4236
2022-10-01 17:38:11 - train: epoch 0221, iter [00910, 01251], lr: 0.000596, loss: 0.4103
2022-10-01 17:38:29 - train: epoch 0221, iter [00920, 01251], lr: 0.000596, loss: 0.4162
2022-10-01 17:38:47 - train: epoch 0221, iter [00930, 01251], lr: 0.000596, loss: 0.3969
2022-10-01 17:39:05 - train: epoch 0221, iter [00940, 01251], lr: 0.000596, loss: 0.4157
2022-10-01 17:39:23 - train: epoch 0221, iter [00950, 01251], lr: 0.000596, loss: 0.4038
2022-10-01 17:39:41 - train: epoch 0221, iter [00960, 01251], lr: 0.000596, loss: 0.4056
2022-10-01 17:39:59 - train: epoch 0221, iter [00970, 01251], lr: 0.000596, loss: 0.3987
2022-10-01 17:40:17 - train: epoch 0221, iter [00980, 01251], lr: 0.000596, loss: 0.3995
2022-10-01 17:40:35 - train: epoch 0221, iter [00990, 01251], lr: 0.000596, loss: 0.4164
2022-10-01 17:40:53 - train: epoch 0221, iter [01000, 01251], lr: 0.000596, loss: 0.4154
2022-10-01 17:41:11 - train: epoch 0221, iter [01010, 01251], lr: 0.000596, loss: 0.4128
2022-10-01 17:41:29 - train: epoch 0221, iter [01020, 01251], lr: 0.000596, loss: 0.4122
2022-10-01 17:41:47 - train: epoch 0221, iter [01030, 01251], lr: 0.000596, loss: 0.4066
2022-10-01 17:42:05 - train: epoch 0221, iter [01040, 01251], lr: 0.000596, loss: 0.4170
2022-10-01 17:42:24 - train: epoch 0221, iter [01050, 01251], lr: 0.000596, loss: 0.3959
2022-10-01 17:42:42 - train: epoch 0221, iter [01060, 01251], lr: 0.000596, loss: 0.4030
2022-10-01 17:43:00 - train: epoch 0221, iter [01070, 01251], lr: 0.000596, loss: 0.4144
2022-10-01 17:43:18 - train: epoch 0221, iter [01080, 01251], lr: 0.000595, loss: 0.4337
2022-10-01 17:43:36 - train: epoch 0221, iter [01090, 01251], lr: 0.000595, loss: 0.4211
2022-10-01 17:43:54 - train: epoch 0221, iter [01100, 01251], lr: 0.000595, loss: 0.4126
2022-10-01 17:44:12 - train: epoch 0221, iter [01110, 01251], lr: 0.000595, loss: 0.3841
2022-10-01 17:44:30 - train: epoch 0221, iter [01120, 01251], lr: 0.000595, loss: 0.4251
2022-10-01 17:44:48 - train: epoch 0221, iter [01130, 01251], lr: 0.000595, loss: 0.4185
2022-10-01 17:45:06 - train: epoch 0221, iter [01140, 01251], lr: 0.000595, loss: 0.4123
2022-10-01 17:45:24 - train: epoch 0221, iter [01150, 01251], lr: 0.000595, loss: 0.4098
2022-10-01 17:45:42 - train: epoch 0221, iter [01160, 01251], lr: 0.000595, loss: 0.3848
2022-10-01 17:46:00 - train: epoch 0221, iter [01170, 01251], lr: 0.000595, loss: 0.3936
2022-10-01 17:46:18 - train: epoch 0221, iter [01180, 01251], lr: 0.000595, loss: 0.3874
2022-10-01 17:46:36 - train: epoch 0221, iter [01190, 01251], lr: 0.000595, loss: 0.4060
2022-10-01 17:46:54 - train: epoch 0221, iter [01200, 01251], lr: 0.000595, loss: 0.4114
2022-10-01 17:47:12 - train: epoch 0221, iter [01210, 01251], lr: 0.000595, loss: 0.4077
2022-10-01 17:47:30 - train: epoch 0221, iter [01220, 01251], lr: 0.000595, loss: 0.4176
2022-10-01 17:47:48 - train: epoch 0221, iter [01230, 01251], lr: 0.000595, loss: 0.4066
2022-10-01 17:48:06 - train: epoch 0221, iter [01240, 01251], lr: 0.000595, loss: 0.4114
2022-10-01 17:48:24 - train: epoch 0221, iter [01250, 01251], lr: 0.000595, loss: 0.3842
2022-10-01 17:48:27 - train: epoch 221, train_loss: 0.4054
2022-10-01 17:48:30 - until epoch: 221, best_loss: 0.4054
2022-10-01 17:48:30 - epoch 222 lr: 0.000595
2022-10-01 17:48:54 - train: epoch 0222, iter [00010, 01251], lr: 0.000595, loss: 0.4105
2022-10-01 17:49:12 - train: epoch 0222, iter [00020, 01251], lr: 0.000595, loss: 0.4130
2022-10-01 17:49:30 - train: epoch 0222, iter [00030, 01251], lr: 0.000595, loss: 0.4005
2022-10-01 17:49:49 - train: epoch 0222, iter [00040, 01251], lr: 0.000595, loss: 0.4258
2022-10-01 17:50:08 - train: epoch 0222, iter [00050, 01251], lr: 0.000595, loss: 0.3869
2022-10-01 17:50:26 - train: epoch 0222, iter [00060, 01251], lr: 0.000595, loss: 0.4138
2022-10-01 17:50:44 - train: epoch 0222, iter [00070, 01251], lr: 0.000594, loss: 0.4163
2022-10-01 17:51:02 - train: epoch 0222, iter [00080, 01251], lr: 0.000594, loss: 0.4067
2022-10-01 17:51:20 - train: epoch 0222, iter [00090, 01251], lr: 0.000594, loss: 0.3936
2022-10-01 17:51:38 - train: epoch 0222, iter [00100, 01251], lr: 0.000594, loss: 0.3885
2022-10-01 17:51:57 - train: epoch 0222, iter [00110, 01251], lr: 0.000594, loss: 0.4070
2022-10-01 17:52:15 - train: epoch 0222, iter [00120, 01251], lr: 0.000594, loss: 0.4032
2022-10-01 17:52:33 - train: epoch 0222, iter [00130, 01251], lr: 0.000594, loss: 0.3961
2022-10-01 17:52:51 - train: epoch 0222, iter [00140, 01251], lr: 0.000594, loss: 0.4037
2022-10-01 17:53:10 - train: epoch 0222, iter [00150, 01251], lr: 0.000594, loss: 0.4090
2022-10-01 17:53:28 - train: epoch 0222, iter [00160, 01251], lr: 0.000594, loss: 0.3936
2022-10-01 17:53:46 - train: epoch 0222, iter [00170, 01251], lr: 0.000594, loss: 0.3975
2022-10-01 17:54:04 - train: epoch 0222, iter [00180, 01251], lr: 0.000594, loss: 0.4129
2022-10-01 17:54:22 - train: epoch 0222, iter [00190, 01251], lr: 0.000594, loss: 0.4149
2022-10-01 17:54:41 - train: epoch 0222, iter [00200, 01251], lr: 0.000594, loss: 0.4021
2022-10-01 17:54:59 - train: epoch 0222, iter [00210, 01251], lr: 0.000594, loss: 0.4152
2022-10-01 17:55:17 - train: epoch 0222, iter [00220, 01251], lr: 0.000594, loss: 0.3960
2022-10-01 17:55:35 - train: epoch 0222, iter [00230, 01251], lr: 0.000594, loss: 0.3913
2022-10-01 17:55:54 - train: epoch 0222, iter [00240, 01251], lr: 0.000594, loss: 0.4035
2022-10-01 17:56:12 - train: epoch 0222, iter [00250, 01251], lr: 0.000594, loss: 0.4134
2022-10-01 17:56:30 - train: epoch 0222, iter [00260, 01251], lr: 0.000594, loss: 0.4226
2022-10-01 17:56:49 - train: epoch 0222, iter [00270, 01251], lr: 0.000594, loss: 0.4283
2022-10-01 17:57:07 - train: epoch 0222, iter [00280, 01251], lr: 0.000594, loss: 0.4306
2022-10-01 17:57:25 - train: epoch 0222, iter [00290, 01251], lr: 0.000594, loss: 0.3982
2022-10-01 17:57:43 - train: epoch 0222, iter [00300, 01251], lr: 0.000594, loss: 0.4144
2022-10-01 17:58:01 - train: epoch 0222, iter [00310, 01251], lr: 0.000593, loss: 0.3825
2022-10-01 17:58:19 - train: epoch 0222, iter [00320, 01251], lr: 0.000593, loss: 0.4225
2022-10-01 17:58:38 - train: epoch 0222, iter [00330, 01251], lr: 0.000593, loss: 0.4072
2022-10-01 17:58:56 - train: epoch 0222, iter [00340, 01251], lr: 0.000593, loss: 0.4092
2022-10-01 17:59:14 - train: epoch 0222, iter [00350, 01251], lr: 0.000593, loss: 0.3981
2022-10-01 17:59:32 - train: epoch 0222, iter [00360, 01251], lr: 0.000593, loss: 0.4181
2022-10-01 17:59:50 - train: epoch 0222, iter [00370, 01251], lr: 0.000593, loss: 0.4170
2022-10-01 18:00:08 - train: epoch 0222, iter [00380, 01251], lr: 0.000593, loss: 0.4216
2022-10-01 18:00:27 - train: epoch 0222, iter [00390, 01251], lr: 0.000593, loss: 0.4149
2022-10-01 18:00:45 - train: epoch 0222, iter [00400, 01251], lr: 0.000593, loss: 0.4306
2022-10-01 18:01:03 - train: epoch 0222, iter [00410, 01251], lr: 0.000593, loss: 0.3974
2022-10-01 18:01:21 - train: epoch 0222, iter [00420, 01251], lr: 0.000593, loss: 0.4108
2022-10-01 18:01:40 - train: epoch 0222, iter [00430, 01251], lr: 0.000593, loss: 0.4000
2022-10-01 18:01:58 - train: epoch 0222, iter [00440, 01251], lr: 0.000593, loss: 0.3984
2022-10-01 18:02:16 - train: epoch 0222, iter [00450, 01251], lr: 0.000593, loss: 0.4004
2022-10-01 18:02:35 - train: epoch 0222, iter [00460, 01251], lr: 0.000593, loss: 0.4109
2022-10-01 18:02:53 - train: epoch 0222, iter [00470, 01251], lr: 0.000593, loss: 0.3891
2022-10-01 18:03:11 - train: epoch 0222, iter [00480, 01251], lr: 0.000593, loss: 0.4102
2022-10-01 18:03:29 - train: epoch 0222, iter [00490, 01251], lr: 0.000593, loss: 0.4004
2022-10-01 18:03:47 - train: epoch 0222, iter [00500, 01251], lr: 0.000593, loss: 0.3770
2022-10-01 18:04:05 - train: epoch 0222, iter [00510, 01251], lr: 0.000593, loss: 0.4051
2022-10-01 18:04:24 - train: epoch 0222, iter [00520, 01251], lr: 0.000593, loss: 0.3845
2022-10-01 18:04:42 - train: epoch 0222, iter [00530, 01251], lr: 0.000593, loss: 0.4087
2022-10-01 18:05:00 - train: epoch 0222, iter [00540, 01251], lr: 0.000593, loss: 0.4126
2022-10-01 18:05:18 - train: epoch 0222, iter [00550, 01251], lr: 0.000592, loss: 0.4062
2022-10-01 18:05:36 - train: epoch 0222, iter [00560, 01251], lr: 0.000592, loss: 0.3918
2022-10-01 18:05:55 - train: epoch 0222, iter [00570, 01251], lr: 0.000592, loss: 0.3977
2022-10-01 18:06:13 - train: epoch 0222, iter [00580, 01251], lr: 0.000592, loss: 0.4078
2022-10-01 18:06:31 - train: epoch 0222, iter [00590, 01251], lr: 0.000592, loss: 0.4168
2022-10-01 18:06:49 - train: epoch 0222, iter [00600, 01251], lr: 0.000592, loss: 0.4184
2022-10-01 18:07:07 - train: epoch 0222, iter [00610, 01251], lr: 0.000592, loss: 0.4019
2022-10-01 18:07:26 - train: epoch 0222, iter [00620, 01251], lr: 0.000592, loss: 0.4173
2022-10-01 18:07:44 - train: epoch 0222, iter [00630, 01251], lr: 0.000592, loss: 0.3958
2022-10-01 18:08:02 - train: epoch 0222, iter [00640, 01251], lr: 0.000592, loss: 0.4027
2022-10-01 18:08:20 - train: epoch 0222, iter [00650, 01251], lr: 0.000592, loss: 0.4104
2022-10-01 18:08:38 - train: epoch 0222, iter [00660, 01251], lr: 0.000592, loss: 0.3828
2022-10-01 18:08:56 - train: epoch 0222, iter [00670, 01251], lr: 0.000592, loss: 0.4117
2022-10-01 18:09:14 - train: epoch 0222, iter [00680, 01251], lr: 0.000592, loss: 0.3986
2022-10-01 18:09:32 - train: epoch 0222, iter [00690, 01251], lr: 0.000592, loss: 0.4101
2022-10-01 18:09:50 - train: epoch 0222, iter [00700, 01251], lr: 0.000592, loss: 0.4114
2022-10-01 18:10:08 - train: epoch 0222, iter [00710, 01251], lr: 0.000592, loss: 0.4086
2022-10-01 18:10:26 - train: epoch 0222, iter [00720, 01251], lr: 0.000592, loss: 0.3956
2022-10-01 18:10:45 - train: epoch 0222, iter [00730, 01251], lr: 0.000592, loss: 0.4012
2022-10-01 18:11:03 - train: epoch 0222, iter [00740, 01251], lr: 0.000592, loss: 0.4036
2022-10-01 18:11:21 - train: epoch 0222, iter [00750, 01251], lr: 0.000592, loss: 0.4003
2022-10-01 18:11:39 - train: epoch 0222, iter [00760, 01251], lr: 0.000592, loss: 0.4045
2022-10-01 18:11:57 - train: epoch 0222, iter [00770, 01251], lr: 0.000592, loss: 0.4150
2022-10-01 18:12:15 - train: epoch 0222, iter [00780, 01251], lr: 0.000591, loss: 0.4040
2022-10-01 18:12:33 - train: epoch 0222, iter [00790, 01251], lr: 0.000591, loss: 0.3971
2022-10-01 18:12:51 - train: epoch 0222, iter [00800, 01251], lr: 0.000591, loss: 0.3916
2022-10-01 18:13:10 - train: epoch 0222, iter [00810, 01251], lr: 0.000591, loss: 0.4201
2022-10-01 18:13:27 - train: epoch 0222, iter [00820, 01251], lr: 0.000591, loss: 0.4162
2022-10-01 18:13:46 - train: epoch 0222, iter [00830, 01251], lr: 0.000591, loss: 0.3857
2022-10-01 18:14:04 - train: epoch 0222, iter [00840, 01251], lr: 0.000591, loss: 0.4001
2022-10-01 18:14:22 - train: epoch 0222, iter [00850, 01251], lr: 0.000591, loss: 0.3910
2022-10-01 18:14:40 - train: epoch 0222, iter [00860, 01251], lr: 0.000591, loss: 0.3863
2022-10-01 18:14:58 - train: epoch 0222, iter [00870, 01251], lr: 0.000591, loss: 0.3993
2022-10-01 18:15:16 - train: epoch 0222, iter [00880, 01251], lr: 0.000591, loss: 0.4111
2022-10-01 18:15:34 - train: epoch 0222, iter [00890, 01251], lr: 0.000591, loss: 0.4019
2022-10-01 18:15:52 - train: epoch 0222, iter [00900, 01251], lr: 0.000591, loss: 0.4101
2022-10-01 18:16:10 - train: epoch 0222, iter [00910, 01251], lr: 0.000591, loss: 0.4129
2022-10-01 18:16:29 - train: epoch 0222, iter [00920, 01251], lr: 0.000591, loss: 0.4143
2022-10-01 18:16:47 - train: epoch 0222, iter [00930, 01251], lr: 0.000591, loss: 0.4115
2022-10-01 18:17:05 - train: epoch 0222, iter [00940, 01251], lr: 0.000591, loss: 0.4174
2022-10-01 18:17:24 - train: epoch 0222, iter [00950, 01251], lr: 0.000591, loss: 0.4080
2022-10-01 18:17:42 - train: epoch 0222, iter [00960, 01251], lr: 0.000591, loss: 0.4214
2022-10-01 18:18:00 - train: epoch 0222, iter [00970, 01251], lr: 0.000591, loss: 0.4208
2022-10-01 18:18:18 - train: epoch 0222, iter [00980, 01251], lr: 0.000591, loss: 0.3942
2022-10-01 18:18:36 - train: epoch 0222, iter [00990, 01251], lr: 0.000591, loss: 0.4048
2022-10-01 18:18:54 - train: epoch 0222, iter [01000, 01251], lr: 0.000591, loss: 0.3996
2022-10-01 18:19:12 - train: epoch 0222, iter [01010, 01251], lr: 0.000591, loss: 0.4087
2022-10-01 18:19:30 - train: epoch 0222, iter [01020, 01251], lr: 0.000590, loss: 0.3920
2022-10-01 18:19:48 - train: epoch 0222, iter [01030, 01251], lr: 0.000590, loss: 0.3993
2022-10-01 18:20:07 - train: epoch 0222, iter [01040, 01251], lr: 0.000590, loss: 0.4071
2022-10-01 18:20:25 - train: epoch 0222, iter [01050, 01251], lr: 0.000590, loss: 0.4078
2022-10-01 18:20:43 - train: epoch 0222, iter [01060, 01251], lr: 0.000590, loss: 0.4054
2022-10-01 18:21:01 - train: epoch 0222, iter [01070, 01251], lr: 0.000590, loss: 0.4048
2022-10-01 18:21:19 - train: epoch 0222, iter [01080, 01251], lr: 0.000590, loss: 0.4204
2022-10-01 18:21:37 - train: epoch 0222, iter [01090, 01251], lr: 0.000590, loss: 0.4225
2022-10-01 18:21:55 - train: epoch 0222, iter [01100, 01251], lr: 0.000590, loss: 0.3904
2022-10-01 18:22:13 - train: epoch 0222, iter [01110, 01251], lr: 0.000590, loss: 0.3982
2022-10-01 18:22:31 - train: epoch 0222, iter [01120, 01251], lr: 0.000590, loss: 0.3879
2022-10-01 18:22:49 - train: epoch 0222, iter [01130, 01251], lr: 0.000590, loss: 0.4212
2022-10-01 18:23:07 - train: epoch 0222, iter [01140, 01251], lr: 0.000590, loss: 0.4024
2022-10-01 18:23:25 - train: epoch 0222, iter [01150, 01251], lr: 0.000590, loss: 0.4241
2022-10-01 18:23:43 - train: epoch 0222, iter [01160, 01251], lr: 0.000590, loss: 0.4116
2022-10-01 18:24:01 - train: epoch 0222, iter [01170, 01251], lr: 0.000590, loss: 0.3991
2022-10-01 18:24:19 - train: epoch 0222, iter [01180, 01251], lr: 0.000590, loss: 0.3929
2022-10-01 18:24:37 - train: epoch 0222, iter [01190, 01251], lr: 0.000590, loss: 0.4076
2022-10-01 18:24:55 - train: epoch 0222, iter [01200, 01251], lr: 0.000590, loss: 0.4011
2022-10-01 18:25:13 - train: epoch 0222, iter [01210, 01251], lr: 0.000590, loss: 0.4089
2022-10-01 18:25:31 - train: epoch 0222, iter [01220, 01251], lr: 0.000590, loss: 0.3961
2022-10-01 18:25:49 - train: epoch 0222, iter [01230, 01251], lr: 0.000590, loss: 0.4232
2022-10-01 18:26:07 - train: epoch 0222, iter [01240, 01251], lr: 0.000590, loss: 0.3828
2022-10-01 18:26:24 - train: epoch 0222, iter [01250, 01251], lr: 0.000590, loss: 0.4004
2022-10-01 18:26:28 - train: epoch 222, train_loss: 0.4053
2022-10-01 18:26:31 - until epoch: 222, best_loss: 0.4053
2022-10-01 18:26:31 - epoch 223 lr: 0.000590
2022-10-01 18:26:56 - train: epoch 0223, iter [00010, 01251], lr: 0.000589, loss: 0.4311
2022-10-01 18:27:14 - train: epoch 0223, iter [00020, 01251], lr: 0.000589, loss: 0.4059
2022-10-01 18:27:32 - train: epoch 0223, iter [00030, 01251], lr: 0.000589, loss: 0.4026
2022-10-01 18:27:50 - train: epoch 0223, iter [00040, 01251], lr: 0.000589, loss: 0.4154
2022-10-01 18:28:08 - train: epoch 0223, iter [00050, 01251], lr: 0.000589, loss: 0.3838
2022-10-01 18:28:26 - train: epoch 0223, iter [00060, 01251], lr: 0.000589, loss: 0.4062
2022-10-01 18:28:44 - train: epoch 0223, iter [00070, 01251], lr: 0.000589, loss: 0.3891
2022-10-01 18:29:02 - train: epoch 0223, iter [00080, 01251], lr: 0.000589, loss: 0.4057
2022-10-01 18:29:20 - train: epoch 0223, iter [00090, 01251], lr: 0.000589, loss: 0.4142
2022-10-01 18:29:38 - train: epoch 0223, iter [00100, 01251], lr: 0.000589, loss: 0.4131
2022-10-01 18:29:56 - train: epoch 0223, iter [00110, 01251], lr: 0.000589, loss: 0.3969
2022-10-01 18:30:14 - train: epoch 0223, iter [00120, 01251], lr: 0.000589, loss: 0.4065
2022-10-01 18:30:32 - train: epoch 0223, iter [00130, 01251], lr: 0.000589, loss: 0.4152
2022-10-01 18:30:50 - train: epoch 0223, iter [00140, 01251], lr: 0.000589, loss: 0.3982
2022-10-01 18:31:08 - train: epoch 0223, iter [00150, 01251], lr: 0.000589, loss: 0.4096
2022-10-01 18:31:26 - train: epoch 0223, iter [00160, 01251], lr: 0.000589, loss: 0.4183
2022-10-01 18:31:44 - train: epoch 0223, iter [00170, 01251], lr: 0.000589, loss: 0.3978
2022-10-01 18:32:02 - train: epoch 0223, iter [00180, 01251], lr: 0.000589, loss: 0.4063
2022-10-01 18:32:20 - train: epoch 0223, iter [00190, 01251], lr: 0.000589, loss: 0.3822
2022-10-01 18:32:38 - train: epoch 0223, iter [00200, 01251], lr: 0.000589, loss: 0.4069
2022-10-01 18:32:56 - train: epoch 0223, iter [00210, 01251], lr: 0.000589, loss: 0.4141
2022-10-01 18:33:14 - train: epoch 0223, iter [00220, 01251], lr: 0.000589, loss: 0.3843
2022-10-01 18:33:32 - train: epoch 0223, iter [00230, 01251], lr: 0.000589, loss: 0.4049
2022-10-01 18:33:50 - train: epoch 0223, iter [00240, 01251], lr: 0.000589, loss: 0.4060
2022-10-01 18:34:08 - train: epoch 0223, iter [00250, 01251], lr: 0.000588, loss: 0.4008
2022-10-01 18:34:26 - train: epoch 0223, iter [00260, 01251], lr: 0.000588, loss: 0.3956
2022-10-01 18:34:44 - train: epoch 0223, iter [00270, 01251], lr: 0.000588, loss: 0.3801
2022-10-01 18:35:02 - train: epoch 0223, iter [00280, 01251], lr: 0.000588, loss: 0.4270
2022-10-01 18:35:20 - train: epoch 0223, iter [00290, 01251], lr: 0.000588, loss: 0.4092
2022-10-01 18:35:38 - train: epoch 0223, iter [00300, 01251], lr: 0.000588, loss: 0.4178
2022-10-01 18:35:56 - train: epoch 0223, iter [00310, 01251], lr: 0.000588, loss: 0.4131
2022-10-01 18:36:14 - train: epoch 0223, iter [00320, 01251], lr: 0.000588, loss: 0.3908
2022-10-01 18:36:32 - train: epoch 0223, iter [00330, 01251], lr: 0.000588, loss: 0.4116
2022-10-01 18:36:50 - train: epoch 0223, iter [00340, 01251], lr: 0.000588, loss: 0.3928
2022-10-01 18:37:08 - train: epoch 0223, iter [00350, 01251], lr: 0.000588, loss: 0.4100
2022-10-01 18:37:26 - train: epoch 0223, iter [00360, 01251], lr: 0.000588, loss: 0.4103
2022-10-01 18:37:44 - train: epoch 0223, iter [00370, 01251], lr: 0.000588, loss: 0.3841
2022-10-01 18:38:02 - train: epoch 0223, iter [00380, 01251], lr: 0.000588, loss: 0.3963
2022-10-01 18:38:20 - train: epoch 0223, iter [00390, 01251], lr: 0.000588, loss: 0.4116
2022-10-01 18:38:38 - train: epoch 0223, iter [00400, 01251], lr: 0.000588, loss: 0.4081
2022-10-01 18:38:55 - train: epoch 0223, iter [00410, 01251], lr: 0.000588, loss: 0.4033
2022-10-01 18:39:14 - train: epoch 0223, iter [00420, 01251], lr: 0.000588, loss: 0.4001
2022-10-01 18:39:32 - train: epoch 0223, iter [00430, 01251], lr: 0.000588, loss: 0.4061
2022-10-01 18:39:50 - train: epoch 0223, iter [00440, 01251], lr: 0.000588, loss: 0.3939
2022-10-01 18:40:08 - train: epoch 0223, iter [00450, 01251], lr: 0.000588, loss: 0.4011
2022-10-01 18:40:26 - train: epoch 0223, iter [00460, 01251], lr: 0.000588, loss: 0.4075
2022-10-01 18:40:44 - train: epoch 0223, iter [00470, 01251], lr: 0.000588, loss: 0.4112
2022-10-01 18:41:02 - train: epoch 0223, iter [00480, 01251], lr: 0.000588, loss: 0.3972
2022-10-01 18:41:20 - train: epoch 0223, iter [00490, 01251], lr: 0.000587, loss: 0.4050
2022-10-01 18:41:37 - train: epoch 0223, iter [00500, 01251], lr: 0.000587, loss: 0.3990
2022-10-01 18:41:56 - train: epoch 0223, iter [00510, 01251], lr: 0.000587, loss: 0.3946
2022-10-01 18:42:14 - train: epoch 0223, iter [00520, 01251], lr: 0.000587, loss: 0.4098
2022-10-01 18:42:32 - train: epoch 0223, iter [00530, 01251], lr: 0.000587, loss: 0.3864
2022-10-01 18:42:50 - train: epoch 0223, iter [00540, 01251], lr: 0.000587, loss: 0.4128
2022-10-01 18:43:08 - train: epoch 0223, iter [00550, 01251], lr: 0.000587, loss: 0.4207
2022-10-01 18:43:26 - train: epoch 0223, iter [00560, 01251], lr: 0.000587, loss: 0.3860
2022-10-01 18:43:44 - train: epoch 0223, iter [00570, 01251], lr: 0.000587, loss: 0.4166
2022-10-01 18:44:02 - train: epoch 0223, iter [00580, 01251], lr: 0.000587, loss: 0.4110
2022-10-01 18:44:20 - train: epoch 0223, iter [00590, 01251], lr: 0.000587, loss: 0.4002
2022-10-01 18:44:38 - train: epoch 0223, iter [00600, 01251], lr: 0.000587, loss: 0.4072
2022-10-01 18:44:56 - train: epoch 0223, iter [00610, 01251], lr: 0.000587, loss: 0.4103
2022-10-01 18:45:14 - train: epoch 0223, iter [00620, 01251], lr: 0.000587, loss: 0.4080
2022-10-01 18:45:32 - train: epoch 0223, iter [00630, 01251], lr: 0.000587, loss: 0.4016
2022-10-01 18:45:50 - train: epoch 0223, iter [00640, 01251], lr: 0.000587, loss: 0.3794
2022-10-01 18:46:08 - train: epoch 0223, iter [00650, 01251], lr: 0.000587, loss: 0.4226
2022-10-01 18:46:26 - train: epoch 0223, iter [00660, 01251], lr: 0.000587, loss: 0.4050
2022-10-01 18:46:44 - train: epoch 0223, iter [00670, 01251], lr: 0.000587, loss: 0.4309
2022-10-01 18:47:02 - train: epoch 0223, iter [00680, 01251], lr: 0.000587, loss: 0.4131
2022-10-01 18:47:20 - train: epoch 0223, iter [00690, 01251], lr: 0.000587, loss: 0.3894
2022-10-01 18:47:38 - train: epoch 0223, iter [00700, 01251], lr: 0.000587, loss: 0.4166
2022-10-01 18:47:56 - train: epoch 0223, iter [00710, 01251], lr: 0.000587, loss: 0.4115
2022-10-01 18:48:14 - train: epoch 0223, iter [00720, 01251], lr: 0.000587, loss: 0.4205
2022-10-01 18:48:31 - train: epoch 0223, iter [00730, 01251], lr: 0.000586, loss: 0.4030
2022-10-01 18:48:49 - train: epoch 0223, iter [00740, 01251], lr: 0.000586, loss: 0.3761
2022-10-01 18:49:07 - train: epoch 0223, iter [00750, 01251], lr: 0.000586, loss: 0.4122
2022-10-01 18:49:25 - train: epoch 0223, iter [00760, 01251], lr: 0.000586, loss: 0.4021
2022-10-01 18:49:43 - train: epoch 0223, iter [00770, 01251], lr: 0.000586, loss: 0.3985
2022-10-01 18:50:01 - train: epoch 0223, iter [00780, 01251], lr: 0.000586, loss: 0.4015
2022-10-01 18:50:19 - train: epoch 0223, iter [00790, 01251], lr: 0.000586, loss: 0.3967
2022-10-01 18:50:37 - train: epoch 0223, iter [00800, 01251], lr: 0.000586, loss: 0.3700
2022-10-01 18:50:56 - train: epoch 0223, iter [00810, 01251], lr: 0.000586, loss: 0.4000
2022-10-01 18:51:14 - train: epoch 0223, iter [00820, 01251], lr: 0.000586, loss: 0.3817
2022-10-01 18:51:31 - train: epoch 0223, iter [00830, 01251], lr: 0.000586, loss: 0.4144
2022-10-01 18:51:50 - train: epoch 0223, iter [00840, 01251], lr: 0.000586, loss: 0.4058
2022-10-01 18:52:07 - train: epoch 0223, iter [00850, 01251], lr: 0.000586, loss: 0.3976
2022-10-01 18:52:25 - train: epoch 0223, iter [00860, 01251], lr: 0.000586, loss: 0.3990
2022-10-01 18:52:43 - train: epoch 0223, iter [00870, 01251], lr: 0.000586, loss: 0.4015
2022-10-01 18:53:01 - train: epoch 0223, iter [00880, 01251], lr: 0.000586, loss: 0.4164
2022-10-01 18:53:19 - train: epoch 0223, iter [00890, 01251], lr: 0.000586, loss: 0.4097
2022-10-01 18:53:37 - train: epoch 0223, iter [00900, 01251], lr: 0.000586, loss: 0.4314
2022-10-01 18:53:55 - train: epoch 0223, iter [00910, 01251], lr: 0.000586, loss: 0.3752
2022-10-01 18:54:13 - train: epoch 0223, iter [00920, 01251], lr: 0.000586, loss: 0.4254
2022-10-01 18:54:31 - train: epoch 0223, iter [00930, 01251], lr: 0.000586, loss: 0.3921
2022-10-01 18:54:49 - train: epoch 0223, iter [00940, 01251], lr: 0.000586, loss: 0.4038
2022-10-01 18:55:07 - train: epoch 0223, iter [00950, 01251], lr: 0.000586, loss: 0.4194
2022-10-01 18:55:25 - train: epoch 0223, iter [00960, 01251], lr: 0.000586, loss: 0.4309
2022-10-01 18:55:43 - train: epoch 0223, iter [00970, 01251], lr: 0.000585, loss: 0.4056
2022-10-01 18:56:00 - train: epoch 0223, iter [00980, 01251], lr: 0.000585, loss: 0.3974
2022-10-01 18:56:18 - train: epoch 0223, iter [00990, 01251], lr: 0.000585, loss: 0.4249
2022-10-01 18:56:36 - train: epoch 0223, iter [01000, 01251], lr: 0.000585, loss: 0.4124
2022-10-01 18:56:54 - train: epoch 0223, iter [01010, 01251], lr: 0.000585, loss: 0.4040
2022-10-01 18:57:12 - train: epoch 0223, iter [01020, 01251], lr: 0.000585, loss: 0.4012
2022-10-01 18:57:30 - train: epoch 0223, iter [01030, 01251], lr: 0.000585, loss: 0.4151
2022-10-01 18:57:48 - train: epoch 0223, iter [01040, 01251], lr: 0.000585, loss: 0.3976
2022-10-01 18:58:06 - train: epoch 0223, iter [01050, 01251], lr: 0.000585, loss: 0.3945
2022-10-01 18:58:24 - train: epoch 0223, iter [01060, 01251], lr: 0.000585, loss: 0.3941
2022-10-01 18:58:43 - train: epoch 0223, iter [01070, 01251], lr: 0.000585, loss: 0.4110
2022-10-01 18:59:01 - train: epoch 0223, iter [01080, 01251], lr: 0.000585, loss: 0.3995
2022-10-01 18:59:19 - train: epoch 0223, iter [01090, 01251], lr: 0.000585, loss: 0.4241
2022-10-01 18:59:37 - train: epoch 0223, iter [01100, 01251], lr: 0.000585, loss: 0.4258
2022-10-01 18:59:54 - train: epoch 0223, iter [01110, 01251], lr: 0.000585, loss: 0.3904
2022-10-01 19:00:12 - train: epoch 0223, iter [01120, 01251], lr: 0.000585, loss: 0.4023
2022-10-01 19:00:30 - train: epoch 0223, iter [01130, 01251], lr: 0.000585, loss: 0.3995
2022-10-01 19:00:49 - train: epoch 0223, iter [01140, 01251], lr: 0.000585, loss: 0.4039
2022-10-01 19:01:07 - train: epoch 0223, iter [01150, 01251], lr: 0.000585, loss: 0.4049
2022-10-01 19:01:25 - train: epoch 0223, iter [01160, 01251], lr: 0.000585, loss: 0.4000
2022-10-01 19:01:43 - train: epoch 0223, iter [01170, 01251], lr: 0.000585, loss: 0.3923
2022-10-01 19:02:01 - train: epoch 0223, iter [01180, 01251], lr: 0.000585, loss: 0.3866
2022-10-01 19:02:19 - train: epoch 0223, iter [01190, 01251], lr: 0.000585, loss: 0.4022
2022-10-01 19:02:37 - train: epoch 0223, iter [01200, 01251], lr: 0.000585, loss: 0.4083
2022-10-01 19:02:55 - train: epoch 0223, iter [01210, 01251], lr: 0.000584, loss: 0.4007
2022-10-01 19:03:13 - train: epoch 0223, iter [01220, 01251], lr: 0.000584, loss: 0.4064
2022-10-01 19:03:31 - train: epoch 0223, iter [01230, 01251], lr: 0.000584, loss: 0.4001
2022-10-01 19:03:49 - train: epoch 0223, iter [01240, 01251], lr: 0.000584, loss: 0.4029
2022-10-01 19:04:06 - train: epoch 0223, iter [01250, 01251], lr: 0.000584, loss: 0.4020
2022-10-01 19:04:09 - train: epoch 223, train_loss: 0.4052
2022-10-01 19:04:12 - until epoch: 223, best_loss: 0.4052
2022-10-01 19:04:12 - epoch 224 lr: 0.000584
2022-10-01 19:04:37 - train: epoch 0224, iter [00010, 01251], lr: 0.000584, loss: 0.3844
2022-10-01 19:04:55 - train: epoch 0224, iter [00020, 01251], lr: 0.000584, loss: 0.3961
2022-10-01 19:05:12 - train: epoch 0224, iter [00030, 01251], lr: 0.000584, loss: 0.4079
2022-10-01 19:05:30 - train: epoch 0224, iter [00040, 01251], lr: 0.000584, loss: 0.4109
2022-10-01 19:05:48 - train: epoch 0224, iter [00050, 01251], lr: 0.000584, loss: 0.4129
2022-10-01 19:06:06 - train: epoch 0224, iter [00060, 01251], lr: 0.000584, loss: 0.3981
2022-10-01 19:06:24 - train: epoch 0224, iter [00070, 01251], lr: 0.000584, loss: 0.4297
2022-10-01 19:06:42 - train: epoch 0224, iter [00080, 01251], lr: 0.000584, loss: 0.4036
2022-10-01 19:07:00 - train: epoch 0224, iter [00090, 01251], lr: 0.000584, loss: 0.4003
2022-10-01 19:07:18 - train: epoch 0224, iter [00100, 01251], lr: 0.000584, loss: 0.3983
2022-10-01 19:07:36 - train: epoch 0224, iter [00110, 01251], lr: 0.000584, loss: 0.3875
2022-10-01 19:07:54 - train: epoch 0224, iter [00120, 01251], lr: 0.000584, loss: 0.4337
2022-10-01 19:08:12 - train: epoch 0224, iter [00130, 01251], lr: 0.000584, loss: 0.4105
2022-10-01 19:08:30 - train: epoch 0224, iter [00140, 01251], lr: 0.000584, loss: 0.3986
2022-10-01 19:08:48 - train: epoch 0224, iter [00150, 01251], lr: 0.000584, loss: 0.4040
2022-10-01 19:09:06 - train: epoch 0224, iter [00160, 01251], lr: 0.000584, loss: 0.4051
2022-10-01 19:09:24 - train: epoch 0224, iter [00170, 01251], lr: 0.000584, loss: 0.4115
2022-10-01 19:09:42 - train: epoch 0224, iter [00180, 01251], lr: 0.000584, loss: 0.4116
2022-10-01 19:10:00 - train: epoch 0224, iter [00190, 01251], lr: 0.000583, loss: 0.4266
2022-10-01 19:10:18 - train: epoch 0224, iter [00200, 01251], lr: 0.000583, loss: 0.4048
2022-10-01 19:10:36 - train: epoch 0224, iter [00210, 01251], lr: 0.000583, loss: 0.4043
2022-10-01 19:10:54 - train: epoch 0224, iter [00220, 01251], lr: 0.000583, loss: 0.3888
2022-10-01 19:11:12 - train: epoch 0224, iter [00230, 01251], lr: 0.000583, loss: 0.4129
2022-10-01 19:11:29 - train: epoch 0224, iter [00240, 01251], lr: 0.000583, loss: 0.4170
2022-10-01 19:11:47 - train: epoch 0224, iter [00250, 01251], lr: 0.000583, loss: 0.3954
2022-10-01 19:12:05 - train: epoch 0224, iter [00260, 01251], lr: 0.000583, loss: 0.3945
2022-10-01 19:12:23 - train: epoch 0224, iter [00270, 01251], lr: 0.000583, loss: 0.3975
2022-10-01 19:12:41 - train: epoch 0224, iter [00280, 01251], lr: 0.000583, loss: 0.3957
2022-10-01 19:12:59 - train: epoch 0224, iter [00290, 01251], lr: 0.000583, loss: 0.4149
2022-10-01 19:13:17 - train: epoch 0224, iter [00300, 01251], lr: 0.000583, loss: 0.3818
2022-10-01 19:13:35 - train: epoch 0224, iter [00310, 01251], lr: 0.000583, loss: 0.3997
2022-10-01 19:13:53 - train: epoch 0224, iter [00320, 01251], lr: 0.000583, loss: 0.4029
2022-10-01 19:14:11 - train: epoch 0224, iter [00330, 01251], lr: 0.000583, loss: 0.4014
2022-10-01 19:14:29 - train: epoch 0224, iter [00340, 01251], lr: 0.000583, loss: 0.3732
2022-10-01 19:14:47 - train: epoch 0224, iter [00350, 01251], lr: 0.000583, loss: 0.3937
2022-10-01 19:15:05 - train: epoch 0224, iter [00360, 01251], lr: 0.000583, loss: 0.4254
2022-10-01 19:15:23 - train: epoch 0224, iter [00370, 01251], lr: 0.000583, loss: 0.4091
2022-10-01 19:15:41 - train: epoch 0224, iter [00380, 01251], lr: 0.000583, loss: 0.4020
2022-10-01 19:15:58 - train: epoch 0224, iter [00390, 01251], lr: 0.000583, loss: 0.3887
2022-10-01 19:16:16 - train: epoch 0224, iter [00400, 01251], lr: 0.000583, loss: 0.4319
2022-10-01 19:16:34 - train: epoch 0224, iter [00410, 01251], lr: 0.000583, loss: 0.3984
2022-10-01 19:16:52 - train: epoch 0224, iter [00420, 01251], lr: 0.000583, loss: 0.4002
2022-10-01 19:17:10 - train: epoch 0224, iter [00430, 01251], lr: 0.000582, loss: 0.3983
2022-10-01 19:17:28 - train: epoch 0224, iter [00440, 01251], lr: 0.000582, loss: 0.3918
2022-10-01 19:17:46 - train: epoch 0224, iter [00450, 01251], lr: 0.000582, loss: 0.4313
2022-10-01 19:18:04 - train: epoch 0224, iter [00460, 01251], lr: 0.000582, loss: 0.4065
2022-10-01 19:18:22 - train: epoch 0224, iter [00470, 01251], lr: 0.000582, loss: 0.3971
2022-10-01 19:18:40 - train: epoch 0224, iter [00480, 01251], lr: 0.000582, loss: 0.3936
2022-10-01 19:18:57 - train: epoch 0224, iter [00490, 01251], lr: 0.000582, loss: 0.3932
2022-10-01 19:19:15 - train: epoch 0224, iter [00500, 01251], lr: 0.000582, loss: 0.4042
2022-10-01 19:19:33 - train: epoch 0224, iter [00510, 01251], lr: 0.000582, loss: 0.4120
2022-10-01 19:19:51 - train: epoch 0224, iter [00520, 01251], lr: 0.000582, loss: 0.4128
2022-10-01 19:20:09 - train: epoch 0224, iter [00530, 01251], lr: 0.000582, loss: 0.4168
2022-10-01 19:20:27 - train: epoch 0224, iter [00540, 01251], lr: 0.000582, loss: 0.3889
2022-10-01 19:20:45 - train: epoch 0224, iter [00550, 01251], lr: 0.000582, loss: 0.4149
2022-10-01 19:21:03 - train: epoch 0224, iter [00560, 01251], lr: 0.000582, loss: 0.3961
2022-10-01 19:21:21 - train: epoch 0224, iter [00570, 01251], lr: 0.000582, loss: 0.4094
2022-10-01 19:21:39 - train: epoch 0224, iter [00580, 01251], lr: 0.000582, loss: 0.4134
2022-10-01 19:21:57 - train: epoch 0224, iter [00590, 01251], lr: 0.000582, loss: 0.4216
2022-10-01 19:22:15 - train: epoch 0224, iter [00600, 01251], lr: 0.000582, loss: 0.4017
2022-10-01 19:22:33 - train: epoch 0224, iter [00610, 01251], lr: 0.000582, loss: 0.4171
2022-10-01 19:22:50 - train: epoch 0224, iter [00620, 01251], lr: 0.000582, loss: 0.4189
2022-10-01 19:23:08 - train: epoch 0224, iter [00630, 01251], lr: 0.000582, loss: 0.4098
2022-10-01 19:23:26 - train: epoch 0224, iter [00640, 01251], lr: 0.000582, loss: 0.4005
2022-10-01 19:23:44 - train: epoch 0224, iter [00650, 01251], lr: 0.000582, loss: 0.4269
2022-10-01 19:24:02 - train: epoch 0224, iter [00660, 01251], lr: 0.000582, loss: 0.4006
2022-10-01 19:24:20 - train: epoch 0224, iter [00670, 01251], lr: 0.000581, loss: 0.4086
2022-10-01 19:24:38 - train: epoch 0224, iter [00680, 01251], lr: 0.000581, loss: 0.3937
2022-10-01 19:24:56 - train: epoch 0224, iter [00690, 01251], lr: 0.000581, loss: 0.4184
2022-10-01 19:25:14 - train: epoch 0224, iter [00700, 01251], lr: 0.000581, loss: 0.4059
2022-10-01 19:25:31 - train: epoch 0224, iter [00710, 01251], lr: 0.000581, loss: 0.4237
2022-10-01 19:25:49 - train: epoch 0224, iter [00720, 01251], lr: 0.000581, loss: 0.3999
2022-10-01 19:26:07 - train: epoch 0224, iter [00730, 01251], lr: 0.000581, loss: 0.4081
2022-10-01 19:26:25 - train: epoch 0224, iter [00740, 01251], lr: 0.000581, loss: 0.4045
2022-10-01 19:26:43 - train: epoch 0224, iter [00750, 01251], lr: 0.000581, loss: 0.3984
2022-10-01 19:27:00 - train: epoch 0224, iter [00760, 01251], lr: 0.000581, loss: 0.3757
2022-10-01 19:27:18 - train: epoch 0224, iter [00770, 01251], lr: 0.000581, loss: 0.4000
2022-10-01 19:27:36 - train: epoch 0224, iter [00780, 01251], lr: 0.000581, loss: 0.4071
2022-10-01 19:27:53 - train: epoch 0224, iter [00790, 01251], lr: 0.000581, loss: 0.4238
2022-10-01 19:28:11 - train: epoch 0224, iter [00800, 01251], lr: 0.000581, loss: 0.4094
2022-10-01 19:28:29 - train: epoch 0224, iter [00810, 01251], lr: 0.000581, loss: 0.3917
2022-10-01 19:28:46 - train: epoch 0224, iter [00820, 01251], lr: 0.000581, loss: 0.4045
2022-10-01 19:29:04 - train: epoch 0224, iter [00830, 01251], lr: 0.000581, loss: 0.4143
2022-10-01 19:29:22 - train: epoch 0224, iter [00840, 01251], lr: 0.000581, loss: 0.4091
2022-10-01 19:29:40 - train: epoch 0224, iter [00850, 01251], lr: 0.000581, loss: 0.3968
2022-10-01 19:29:57 - train: epoch 0224, iter [00860, 01251], lr: 0.000581, loss: 0.3935
2022-10-01 19:30:15 - train: epoch 0224, iter [00870, 01251], lr: 0.000581, loss: 0.4033
2022-10-01 19:30:33 - train: epoch 0224, iter [00880, 01251], lr: 0.000581, loss: 0.4110
2022-10-01 19:30:51 - train: epoch 0224, iter [00890, 01251], lr: 0.000581, loss: 0.4181
2022-10-01 19:31:09 - train: epoch 0224, iter [00900, 01251], lr: 0.000581, loss: 0.4012
2022-10-01 19:31:27 - train: epoch 0224, iter [00910, 01251], lr: 0.000580, loss: 0.4256
2022-10-01 19:31:45 - train: epoch 0224, iter [00920, 01251], lr: 0.000580, loss: 0.4170
2022-10-01 19:32:02 - train: epoch 0224, iter [00930, 01251], lr: 0.000580, loss: 0.3990
2022-10-01 19:32:20 - train: epoch 0224, iter [00940, 01251], lr: 0.000580, loss: 0.4185
2022-10-01 19:32:38 - train: epoch 0224, iter [00950, 01251], lr: 0.000580, loss: 0.3895
2022-10-01 19:32:55 - train: epoch 0224, iter [00960, 01251], lr: 0.000580, loss: 0.3938
2022-10-01 19:33:13 - train: epoch 0224, iter [00970, 01251], lr: 0.000580, loss: 0.3928
2022-10-01 19:33:31 - train: epoch 0224, iter [00980, 01251], lr: 0.000580, loss: 0.3953
2022-10-01 19:33:48 - train: epoch 0224, iter [00990, 01251], lr: 0.000580, loss: 0.4319
2022-10-01 19:34:06 - train: epoch 0224, iter [01000, 01251], lr: 0.000580, loss: 0.4098
2022-10-01 19:34:23 - train: epoch 0224, iter [01010, 01251], lr: 0.000580, loss: 0.4162
2022-10-01 19:34:41 - train: epoch 0224, iter [01020, 01251], lr: 0.000580, loss: 0.4229
2022-10-01 19:34:59 - train: epoch 0224, iter [01030, 01251], lr: 0.000580, loss: 0.4135
2022-10-01 19:35:17 - train: epoch 0224, iter [01040, 01251], lr: 0.000580, loss: 0.4188
2022-10-01 19:35:34 - train: epoch 0224, iter [01050, 01251], lr: 0.000580, loss: 0.4082
2022-10-01 19:35:52 - train: epoch 0224, iter [01060, 01251], lr: 0.000580, loss: 0.4000
2022-10-01 19:36:10 - train: epoch 0224, iter [01070, 01251], lr: 0.000580, loss: 0.4042
2022-10-01 19:36:28 - train: epoch 0224, iter [01080, 01251], lr: 0.000580, loss: 0.4074
2022-10-01 19:36:46 - train: epoch 0224, iter [01090, 01251], lr: 0.000580, loss: 0.3880
2022-10-01 19:37:03 - train: epoch 0224, iter [01100, 01251], lr: 0.000580, loss: 0.4259
2022-10-01 19:37:21 - train: epoch 0224, iter [01110, 01251], lr: 0.000580, loss: 0.4043
2022-10-01 19:37:39 - train: epoch 0224, iter [01120, 01251], lr: 0.000580, loss: 0.4190
2022-10-01 19:37:56 - train: epoch 0224, iter [01130, 01251], lr: 0.000580, loss: 0.4069
2022-10-01 19:38:14 - train: epoch 0224, iter [01140, 01251], lr: 0.000580, loss: 0.4291
2022-10-01 19:38:32 - train: epoch 0224, iter [01150, 01251], lr: 0.000579, loss: 0.3946
2022-10-01 19:38:50 - train: epoch 0224, iter [01160, 01251], lr: 0.000579, loss: 0.4087
2022-10-01 19:39:07 - train: epoch 0224, iter [01170, 01251], lr: 0.000579, loss: 0.4079
2022-10-01 19:39:25 - train: epoch 0224, iter [01180, 01251], lr: 0.000579, loss: 0.4211
2022-10-01 19:39:43 - train: epoch 0224, iter [01190, 01251], lr: 0.000579, loss: 0.4292
2022-10-01 19:40:00 - train: epoch 0224, iter [01200, 01251], lr: 0.000579, loss: 0.4029
2022-10-01 19:40:18 - train: epoch 0224, iter [01210, 01251], lr: 0.000579, loss: 0.4041
2022-10-01 19:40:36 - train: epoch 0224, iter [01220, 01251], lr: 0.000579, loss: 0.4123
2022-10-01 19:40:53 - train: epoch 0224, iter [01230, 01251], lr: 0.000579, loss: 0.4026
2022-10-01 19:41:11 - train: epoch 0224, iter [01240, 01251], lr: 0.000579, loss: 0.4076
2022-10-01 19:41:28 - train: epoch 0224, iter [01250, 01251], lr: 0.000579, loss: 0.4185
2022-10-01 19:41:31 - train: epoch 224, train_loss: 0.4052
2022-10-01 19:41:33 - until epoch: 224, best_loss: 0.4052
2022-10-01 19:41:33 - epoch 225 lr: 0.000579
2022-10-01 19:41:58 - train: epoch 0225, iter [00010, 01251], lr: 0.000579, loss: 0.4058
2022-10-01 19:42:16 - train: epoch 0225, iter [00020, 01251], lr: 0.000579, loss: 0.4005
2022-10-01 19:42:34 - train: epoch 0225, iter [00030, 01251], lr: 0.000579, loss: 0.4089
2022-10-01 19:42:52 - train: epoch 0225, iter [00040, 01251], lr: 0.000579, loss: 0.3879
2022-10-01 19:43:10 - train: epoch 0225, iter [00050, 01251], lr: 0.000579, loss: 0.3786
2022-10-01 19:43:28 - train: epoch 0225, iter [00060, 01251], lr: 0.000579, loss: 0.3992
2022-10-01 19:43:46 - train: epoch 0225, iter [00070, 01251], lr: 0.000579, loss: 0.4191
2022-10-01 19:44:03 - train: epoch 0225, iter [00080, 01251], lr: 0.000579, loss: 0.4132
2022-10-01 19:44:21 - train: epoch 0225, iter [00090, 01251], lr: 0.000579, loss: 0.4025
2022-10-01 19:44:39 - train: epoch 0225, iter [00100, 01251], lr: 0.000579, loss: 0.3959
2022-10-01 19:44:57 - train: epoch 0225, iter [00110, 01251], lr: 0.000579, loss: 0.4216
2022-10-01 19:45:14 - train: epoch 0225, iter [00120, 01251], lr: 0.000579, loss: 0.4108
2022-10-01 19:45:32 - train: epoch 0225, iter [00130, 01251], lr: 0.000579, loss: 0.3832
2022-10-01 19:45:50 - train: epoch 0225, iter [00140, 01251], lr: 0.000578, loss: 0.3869
2022-10-01 19:46:08 - train: epoch 0225, iter [00150, 01251], lr: 0.000578, loss: 0.4034
2022-10-01 19:46:26 - train: epoch 0225, iter [00160, 01251], lr: 0.000578, loss: 0.4033
2022-10-01 19:46:43 - train: epoch 0225, iter [00170, 01251], lr: 0.000578, loss: 0.4094
2022-10-01 19:47:01 - train: epoch 0225, iter [00180, 01251], lr: 0.000578, loss: 0.4022
2022-10-01 19:47:19 - train: epoch 0225, iter [00190, 01251], lr: 0.000578, loss: 0.4233
2022-10-01 19:47:37 - train: epoch 0225, iter [00200, 01251], lr: 0.000578, loss: 0.4048
2022-10-01 19:47:54 - train: epoch 0225, iter [00210, 01251], lr: 0.000578, loss: 0.3948
2022-10-01 19:48:12 - train: epoch 0225, iter [00220, 01251], lr: 0.000578, loss: 0.3962
2022-10-01 19:48:30 - train: epoch 0225, iter [00230, 01251], lr: 0.000578, loss: 0.4147
2022-10-01 19:48:47 - train: epoch 0225, iter [00240, 01251], lr: 0.000578, loss: 0.3811
2022-10-01 19:49:05 - train: epoch 0225, iter [00250, 01251], lr: 0.000578, loss: 0.4151
2022-10-01 19:49:23 - train: epoch 0225, iter [00260, 01251], lr: 0.000578, loss: 0.4027
2022-10-01 19:49:41 - train: epoch 0225, iter [00270, 01251], lr: 0.000578, loss: 0.4001
2022-10-01 19:49:59 - train: epoch 0225, iter [00280, 01251], lr: 0.000578, loss: 0.3907
2022-10-01 19:50:16 - train: epoch 0225, iter [00290, 01251], lr: 0.000578, loss: 0.4136
2022-10-01 19:50:35 - train: epoch 0225, iter [00300, 01251], lr: 0.000578, loss: 0.4196
2022-10-01 19:50:52 - train: epoch 0225, iter [00310, 01251], lr: 0.000578, loss: 0.4043
2022-10-01 19:51:10 - train: epoch 0225, iter [00320, 01251], lr: 0.000578, loss: 0.4076
2022-10-01 19:51:28 - train: epoch 0225, iter [00330, 01251], lr: 0.000578, loss: 0.4164
2022-10-01 19:51:46 - train: epoch 0225, iter [00340, 01251], lr: 0.000578, loss: 0.3948
2022-10-01 19:52:04 - train: epoch 0225, iter [00350, 01251], lr: 0.000578, loss: 0.4041
2022-10-01 19:52:22 - train: epoch 0225, iter [00360, 01251], lr: 0.000578, loss: 0.4091
2022-10-01 19:52:40 - train: epoch 0225, iter [00370, 01251], lr: 0.000578, loss: 0.4296
2022-10-01 19:52:58 - train: epoch 0225, iter [00380, 01251], lr: 0.000577, loss: 0.3996
2022-10-01 19:53:15 - train: epoch 0225, iter [00390, 01251], lr: 0.000577, loss: 0.4024
2022-10-01 19:53:33 - train: epoch 0225, iter [00400, 01251], lr: 0.000577, loss: 0.3832
2022-10-01 19:53:51 - train: epoch 0225, iter [00410, 01251], lr: 0.000577, loss: 0.3898
2022-10-01 19:54:09 - train: epoch 0225, iter [00420, 01251], lr: 0.000577, loss: 0.3962
2022-10-01 19:54:27 - train: epoch 0225, iter [00430, 01251], lr: 0.000577, loss: 0.4011
2022-10-01 19:54:45 - train: epoch 0225, iter [00440, 01251], lr: 0.000577, loss: 0.4080
2022-10-01 19:55:02 - train: epoch 0225, iter [00450, 01251], lr: 0.000577, loss: 0.4094
2022-10-01 19:55:20 - train: epoch 0225, iter [00460, 01251], lr: 0.000577, loss: 0.3842
2022-10-01 19:55:38 - train: epoch 0225, iter [00470, 01251], lr: 0.000577, loss: 0.4140
2022-10-01 19:55:56 - train: epoch 0225, iter [00480, 01251], lr: 0.000577, loss: 0.4204
2022-10-01 19:56:13 - train: epoch 0225, iter [00490, 01251], lr: 0.000577, loss: 0.4019
2022-10-01 19:56:31 - train: epoch 0225, iter [00500, 01251], lr: 0.000577, loss: 0.4026
2022-10-01 19:56:49 - train: epoch 0225, iter [00510, 01251], lr: 0.000577, loss: 0.3890
2022-10-01 19:57:07 - train: epoch 0225, iter [00520, 01251], lr: 0.000577, loss: 0.3884
2022-10-01 19:57:25 - train: epoch 0225, iter [00530, 01251], lr: 0.000577, loss: 0.4170
2022-10-01 19:57:42 - train: epoch 0225, iter [00540, 01251], lr: 0.000577, loss: 0.3960
2022-10-01 19:58:00 - train: epoch 0225, iter [00550, 01251], lr: 0.000577, loss: 0.4216
2022-10-01 19:58:17 - train: epoch 0225, iter [00560, 01251], lr: 0.000577, loss: 0.4239
2022-10-01 19:58:35 - train: epoch 0225, iter [00570, 01251], lr: 0.000577, loss: 0.4046
2022-10-01 19:58:53 - train: epoch 0225, iter [00580, 01251], lr: 0.000577, loss: 0.4101
2022-10-01 19:59:10 - train: epoch 0225, iter [00590, 01251], lr: 0.000577, loss: 0.4150
2022-10-01 19:59:28 - train: epoch 0225, iter [00600, 01251], lr: 0.000577, loss: 0.3878
2022-10-01 19:59:46 - train: epoch 0225, iter [00610, 01251], lr: 0.000577, loss: 0.4072
2022-10-01 20:00:03 - train: epoch 0225, iter [00620, 01251], lr: 0.000576, loss: 0.4052
2022-10-01 20:00:21 - train: epoch 0225, iter [00630, 01251], lr: 0.000576, loss: 0.4070
2022-10-01 20:00:39 - train: epoch 0225, iter [00640, 01251], lr: 0.000576, loss: 0.4050
2022-10-01 20:00:57 - train: epoch 0225, iter [00650, 01251], lr: 0.000576, loss: 0.4019
2022-10-01 20:01:15 - train: epoch 0225, iter [00660, 01251], lr: 0.000576, loss: 0.4122
2022-10-01 20:01:32 - train: epoch 0225, iter [00670, 01251], lr: 0.000576, loss: 0.4007
2022-10-01 20:01:50 - train: epoch 0225, iter [00680, 01251], lr: 0.000576, loss: 0.4144
2022-10-01 20:02:08 - train: epoch 0225, iter [00690, 01251], lr: 0.000576, loss: 0.4294
2022-10-01 20:02:26 - train: epoch 0225, iter [00700, 01251], lr: 0.000576, loss: 0.4090
2022-10-01 20:02:43 - train: epoch 0225, iter [00710, 01251], lr: 0.000576, loss: 0.4082
2022-10-01 20:03:01 - train: epoch 0225, iter [00720, 01251], lr: 0.000576, loss: 0.4054
2022-10-01 20:03:19 - train: epoch 0225, iter [00730, 01251], lr: 0.000576, loss: 0.4144
2022-10-01 20:03:37 - train: epoch 0225, iter [00740, 01251], lr: 0.000576, loss: 0.3972
2022-10-01 20:03:54 - train: epoch 0225, iter [00750, 01251], lr: 0.000576, loss: 0.4002
2022-10-01 20:04:12 - train: epoch 0225, iter [00760, 01251], lr: 0.000576, loss: 0.4047
2022-10-01 20:04:29 - train: epoch 0225, iter [00770, 01251], lr: 0.000576, loss: 0.4053
2022-10-01 20:04:47 - train: epoch 0225, iter [00780, 01251], lr: 0.000576, loss: 0.3919
2022-10-01 20:05:05 - train: epoch 0225, iter [00790, 01251], lr: 0.000576, loss: 0.4278
2022-10-01 20:05:22 - train: epoch 0225, iter [00800, 01251], lr: 0.000576, loss: 0.3972
2022-10-01 20:05:40 - train: epoch 0225, iter [00810, 01251], lr: 0.000576, loss: 0.4209
2022-10-01 20:05:58 - train: epoch 0225, iter [00820, 01251], lr: 0.000576, loss: 0.4052
2022-10-01 20:06:15 - train: epoch 0225, iter [00830, 01251], lr: 0.000576, loss: 0.3966
2022-10-01 20:06:33 - train: epoch 0225, iter [00840, 01251], lr: 0.000576, loss: 0.3919
2022-10-01 20:06:51 - train: epoch 0225, iter [00850, 01251], lr: 0.000576, loss: 0.4260
2022-10-01 20:07:08 - train: epoch 0225, iter [00860, 01251], lr: 0.000575, loss: 0.3854
2022-10-01 20:07:26 - train: epoch 0225, iter [00870, 01251], lr: 0.000575, loss: 0.3982
2022-10-01 20:07:44 - train: epoch 0225, iter [00880, 01251], lr: 0.000575, loss: 0.3932
2022-10-01 20:08:01 - train: epoch 0225, iter [00890, 01251], lr: 0.000575, loss: 0.4182
2022-10-01 20:08:19 - train: epoch 0225, iter [00900, 01251], lr: 0.000575, loss: 0.3998
2022-10-01 20:08:37 - train: epoch 0225, iter [00910, 01251], lr: 0.000575, loss: 0.4161
2022-10-01 20:08:54 - train: epoch 0225, iter [00920, 01251], lr: 0.000575, loss: 0.3928
2022-10-01 20:09:12 - train: epoch 0225, iter [00930, 01251], lr: 0.000575, loss: 0.4035
2022-10-01 20:09:30 - train: epoch 0225, iter [00940, 01251], lr: 0.000575, loss: 0.4057
2022-10-01 20:09:47 - train: epoch 0225, iter [00950, 01251], lr: 0.000575, loss: 0.4320
2022-10-01 20:10:05 - train: epoch 0225, iter [00960, 01251], lr: 0.000575, loss: 0.4221
2022-10-01 20:10:23 - train: epoch 0225, iter [00970, 01251], lr: 0.000575, loss: 0.4246
2022-10-01 20:10:40 - train: epoch 0225, iter [00980, 01251], lr: 0.000575, loss: 0.4043
2022-10-01 20:10:58 - train: epoch 0225, iter [00990, 01251], lr: 0.000575, loss: 0.4110
2022-10-01 20:11:16 - train: epoch 0225, iter [01000, 01251], lr: 0.000575, loss: 0.3995
2022-10-01 20:11:34 - train: epoch 0225, iter [01010, 01251], lr: 0.000575, loss: 0.3957
2022-10-01 20:11:51 - train: epoch 0225, iter [01020, 01251], lr: 0.000575, loss: 0.3811
2022-10-01 20:12:09 - train: epoch 0225, iter [01030, 01251], lr: 0.000575, loss: 0.4175
2022-10-01 20:12:27 - train: epoch 0225, iter [01040, 01251], lr: 0.000575, loss: 0.3778
2022-10-01 20:12:44 - train: epoch 0225, iter [01050, 01251], lr: 0.000575, loss: 0.3938
2022-10-01 20:13:02 - train: epoch 0225, iter [01060, 01251], lr: 0.000575, loss: 0.4197
2022-10-01 20:13:20 - train: epoch 0225, iter [01070, 01251], lr: 0.000575, loss: 0.3950
2022-10-01 20:13:37 - train: epoch 0225, iter [01080, 01251], lr: 0.000575, loss: 0.4012
2022-10-01 20:13:55 - train: epoch 0225, iter [01090, 01251], lr: 0.000575, loss: 0.3904
2022-10-01 20:14:12 - train: epoch 0225, iter [01100, 01251], lr: 0.000574, loss: 0.4048
2022-10-01 20:14:30 - train: epoch 0225, iter [01110, 01251], lr: 0.000574, loss: 0.3969
2022-10-01 20:14:48 - train: epoch 0225, iter [01120, 01251], lr: 0.000574, loss: 0.3875
2022-10-01 20:15:05 - train: epoch 0225, iter [01130, 01251], lr: 0.000574, loss: 0.4131
2022-10-01 20:15:23 - train: epoch 0225, iter [01140, 01251], lr: 0.000574, loss: 0.4005
2022-10-01 20:15:41 - train: epoch 0225, iter [01150, 01251], lr: 0.000574, loss: 0.4282
2022-10-01 20:15:58 - train: epoch 0225, iter [01160, 01251], lr: 0.000574, loss: 0.4055
2022-10-01 20:16:16 - train: epoch 0225, iter [01170, 01251], lr: 0.000574, loss: 0.4127
2022-10-01 20:16:33 - train: epoch 0225, iter [01180, 01251], lr: 0.000574, loss: 0.4281
2022-10-01 20:16:51 - train: epoch 0225, iter [01190, 01251], lr: 0.000574, loss: 0.4050
2022-10-01 20:17:09 - train: epoch 0225, iter [01200, 01251], lr: 0.000574, loss: 0.4100
2022-10-01 20:17:26 - train: epoch 0225, iter [01210, 01251], lr: 0.000574, loss: 0.4039
2022-10-01 20:17:44 - train: epoch 0225, iter [01220, 01251], lr: 0.000574, loss: 0.4092
2022-10-01 20:18:02 - train: epoch 0225, iter [01230, 01251], lr: 0.000574, loss: 0.4104
2022-10-01 20:18:20 - train: epoch 0225, iter [01240, 01251], lr: 0.000574, loss: 0.4056
2022-10-01 20:18:37 - train: epoch 0225, iter [01250, 01251], lr: 0.000574, loss: 0.3934
2022-10-01 20:18:40 - train: epoch 225, train_loss: 0.4050
2022-10-01 20:18:43 - until epoch: 225, best_loss: 0.4050
2022-10-01 20:18:43 - epoch 226 lr: 0.000574
2022-10-01 20:19:07 - train: epoch 0226, iter [00010, 01251], lr: 0.000574, loss: 0.3962
2022-10-01 20:19:25 - train: epoch 0226, iter [00020, 01251], lr: 0.000574, loss: 0.3951
2022-10-01 20:19:42 - train: epoch 0226, iter [00030, 01251], lr: 0.000574, loss: 0.4179
2022-10-01 20:20:00 - train: epoch 0226, iter [00040, 01251], lr: 0.000574, loss: 0.4126
2022-10-01 20:20:17 - train: epoch 0226, iter [00050, 01251], lr: 0.000574, loss: 0.4164
2022-10-01 20:20:35 - train: epoch 0226, iter [00060, 01251], lr: 0.000574, loss: 0.4146
2022-10-01 20:20:52 - train: epoch 0226, iter [00070, 01251], lr: 0.000574, loss: 0.4066
2022-10-01 20:21:10 - train: epoch 0226, iter [00080, 01251], lr: 0.000573, loss: 0.3913
2022-10-01 20:21:28 - train: epoch 0226, iter [00090, 01251], lr: 0.000573, loss: 0.3871
2022-10-01 20:21:45 - train: epoch 0226, iter [00100, 01251], lr: 0.000573, loss: 0.4076
2022-10-01 20:22:03 - train: epoch 0226, iter [00110, 01251], lr: 0.000573, loss: 0.4050
2022-10-01 20:22:21 - train: epoch 0226, iter [00120, 01251], lr: 0.000573, loss: 0.4121
2022-10-01 20:22:39 - train: epoch 0226, iter [00130, 01251], lr: 0.000573, loss: 0.4010
2022-10-01 20:22:56 - train: epoch 0226, iter [00140, 01251], lr: 0.000573, loss: 0.4079
2022-10-01 20:23:14 - train: epoch 0226, iter [00150, 01251], lr: 0.000573, loss: 0.4292
2022-10-01 20:23:32 - train: epoch 0226, iter [00160, 01251], lr: 0.000573, loss: 0.4050
2022-10-01 20:23:50 - train: epoch 0226, iter [00170, 01251], lr: 0.000573, loss: 0.3940
2022-10-01 20:24:08 - train: epoch 0226, iter [00180, 01251], lr: 0.000573, loss: 0.3957
2022-10-01 20:24:26 - train: epoch 0226, iter [00190, 01251], lr: 0.000573, loss: 0.4088
2022-10-01 20:24:44 - train: epoch 0226, iter [00200, 01251], lr: 0.000573, loss: 0.4051
2022-10-01 20:25:02 - train: epoch 0226, iter [00210, 01251], lr: 0.000573, loss: 0.4150
2022-10-01 20:25:20 - train: epoch 0226, iter [00220, 01251], lr: 0.000573, loss: 0.4055
2022-10-01 20:25:37 - train: epoch 0226, iter [00230, 01251], lr: 0.000573, loss: 0.4157
2022-10-01 20:25:55 - train: epoch 0226, iter [00240, 01251], lr: 0.000573, loss: 0.3978
2022-10-01 20:26:13 - train: epoch 0226, iter [00250, 01251], lr: 0.000573, loss: 0.3789
2022-10-01 20:26:31 - train: epoch 0226, iter [00260, 01251], lr: 0.000573, loss: 0.3949
2022-10-01 20:26:48 - train: epoch 0226, iter [00270, 01251], lr: 0.000573, loss: 0.4089
2022-10-01 20:27:06 - train: epoch 0226, iter [00280, 01251], lr: 0.000573, loss: 0.3969
2022-10-01 20:27:24 - train: epoch 0226, iter [00290, 01251], lr: 0.000573, loss: 0.4069
2022-10-01 20:27:42 - train: epoch 0226, iter [00300, 01251], lr: 0.000573, loss: 0.3972
2022-10-01 20:28:00 - train: epoch 0226, iter [00310, 01251], lr: 0.000573, loss: 0.3964
2022-10-01 20:28:18 - train: epoch 0226, iter [00320, 01251], lr: 0.000572, loss: 0.4281
2022-10-01 20:28:35 - train: epoch 0226, iter [00330, 01251], lr: 0.000572, loss: 0.4020
2022-10-01 20:28:53 - train: epoch 0226, iter [00340, 01251], lr: 0.000572, loss: 0.4044
2022-10-01 20:29:11 - train: epoch 0226, iter [00350, 01251], lr: 0.000572, loss: 0.3980
2022-10-01 20:29:29 - train: epoch 0226, iter [00360, 01251], lr: 0.000572, loss: 0.4172
2022-10-01 20:29:46 - train: epoch 0226, iter [00370, 01251], lr: 0.000572, loss: 0.4056
2022-10-01 20:30:04 - train: epoch 0226, iter [00380, 01251], lr: 0.000572, loss: 0.4088
2022-10-01 20:30:22 - train: epoch 0226, iter [00390, 01251], lr: 0.000572, loss: 0.4059
2022-10-01 20:30:40 - train: epoch 0226, iter [00400, 01251], lr: 0.000572, loss: 0.4117
2022-10-01 20:30:58 - train: epoch 0226, iter [00410, 01251], lr: 0.000572, loss: 0.4189
2022-10-01 20:31:15 - train: epoch 0226, iter [00420, 01251], lr: 0.000572, loss: 0.3841
2022-10-01 20:31:33 - train: epoch 0226, iter [00430, 01251], lr: 0.000572, loss: 0.3876
2022-10-01 20:31:50 - train: epoch 0226, iter [00440, 01251], lr: 0.000572, loss: 0.3934
2022-10-01 20:32:08 - train: epoch 0226, iter [00450, 01251], lr: 0.000572, loss: 0.3861
2022-10-01 20:32:26 - train: epoch 0226, iter [00460, 01251], lr: 0.000572, loss: 0.4145
2022-10-01 20:32:43 - train: epoch 0226, iter [00470, 01251], lr: 0.000572, loss: 0.3918
2022-10-01 20:33:01 - train: epoch 0226, iter [00480, 01251], lr: 0.000572, loss: 0.4227
2022-10-01 20:33:19 - train: epoch 0226, iter [00490, 01251], lr: 0.000572, loss: 0.4079
2022-10-01 20:33:36 - train: epoch 0226, iter [00500, 01251], lr: 0.000572, loss: 0.3837
2022-10-01 20:33:54 - train: epoch 0226, iter [00510, 01251], lr: 0.000572, loss: 0.4015
2022-10-01 20:34:11 - train: epoch 0226, iter [00520, 01251], lr: 0.000572, loss: 0.3986
2022-10-01 20:34:29 - train: epoch 0226, iter [00530, 01251], lr: 0.000572, loss: 0.4076
2022-10-01 20:34:47 - train: epoch 0226, iter [00540, 01251], lr: 0.000572, loss: 0.4148
2022-10-01 20:35:04 - train: epoch 0226, iter [00550, 01251], lr: 0.000572, loss: 0.3945
2022-10-01 20:35:22 - train: epoch 0226, iter [00560, 01251], lr: 0.000571, loss: 0.4004
2022-10-01 20:35:39 - train: epoch 0226, iter [00570, 01251], lr: 0.000571, loss: 0.3880
2022-10-01 20:35:57 - train: epoch 0226, iter [00580, 01251], lr: 0.000571, loss: 0.3952
2022-10-01 20:36:14 - train: epoch 0226, iter [00590, 01251], lr: 0.000571, loss: 0.3982
2022-10-01 20:36:32 - train: epoch 0226, iter [00600, 01251], lr: 0.000571, loss: 0.4133
2022-10-01 20:36:49 - train: epoch 0226, iter [00610, 01251], lr: 0.000571, loss: 0.3916
2022-10-01 20:37:07 - train: epoch 0226, iter [00620, 01251], lr: 0.000571, loss: 0.3946
2022-10-01 20:37:25 - train: epoch 0226, iter [00630, 01251], lr: 0.000571, loss: 0.4169
2022-10-01 20:37:43 - train: epoch 0226, iter [00640, 01251], lr: 0.000571, loss: 0.4092
2022-10-01 20:38:00 - train: epoch 0226, iter [00650, 01251], lr: 0.000571, loss: 0.4186
2022-10-01 20:38:18 - train: epoch 0226, iter [00660, 01251], lr: 0.000571, loss: 0.4004
2022-10-01 20:38:35 - train: epoch 0226, iter [00670, 01251], lr: 0.000571, loss: 0.4162
2022-10-01 20:38:53 - train: epoch 0226, iter [00680, 01251], lr: 0.000571, loss: 0.4208
2022-10-01 20:39:11 - train: epoch 0226, iter [00690, 01251], lr: 0.000571, loss: 0.4132
2022-10-01 20:39:29 - train: epoch 0226, iter [00700, 01251], lr: 0.000571, loss: 0.3905
2022-10-01 20:39:46 - train: epoch 0226, iter [00710, 01251], lr: 0.000571, loss: 0.3874
2022-10-01 20:40:04 - train: epoch 0226, iter [00720, 01251], lr: 0.000571, loss: 0.3965
2022-10-01 20:40:21 - train: epoch 0226, iter [00730, 01251], lr: 0.000571, loss: 0.3973
2022-10-01 20:40:39 - train: epoch 0226, iter [00740, 01251], lr: 0.000571, loss: 0.4100
2022-10-01 20:40:57 - train: epoch 0226, iter [00750, 01251], lr: 0.000571, loss: 0.4051
2022-10-01 20:41:15 - train: epoch 0226, iter [00760, 01251], lr: 0.000571, loss: 0.4143
2022-10-01 20:41:32 - train: epoch 0226, iter [00770, 01251], lr: 0.000571, loss: 0.4075
2022-10-01 20:41:50 - train: epoch 0226, iter [00780, 01251], lr: 0.000571, loss: 0.4114
2022-10-01 20:42:07 - train: epoch 0226, iter [00790, 01251], lr: 0.000571, loss: 0.4084
2022-10-01 20:42:25 - train: epoch 0226, iter [00800, 01251], lr: 0.000570, loss: 0.3806
2022-10-01 20:42:43 - train: epoch 0226, iter [00810, 01251], lr: 0.000570, loss: 0.3988
2022-10-01 20:43:00 - train: epoch 0226, iter [00820, 01251], lr: 0.000570, loss: 0.3951
2022-10-01 20:43:18 - train: epoch 0226, iter [00830, 01251], lr: 0.000570, loss: 0.3984
2022-10-01 20:43:35 - train: epoch 0226, iter [00840, 01251], lr: 0.000570, loss: 0.4105
2022-10-01 20:43:53 - train: epoch 0226, iter [00850, 01251], lr: 0.000570, loss: 0.4062
2022-10-01 20:44:11 - train: epoch 0226, iter [00860, 01251], lr: 0.000570, loss: 0.4143
2022-10-01 20:44:28 - train: epoch 0226, iter [00870, 01251], lr: 0.000570, loss: 0.3985
2022-10-01 20:44:46 - train: epoch 0226, iter [00880, 01251], lr: 0.000570, loss: 0.4034
2022-10-01 20:45:03 - train: epoch 0226, iter [00890, 01251], lr: 0.000570, loss: 0.3980
2022-10-01 20:45:21 - train: epoch 0226, iter [00900, 01251], lr: 0.000570, loss: 0.4077
2022-10-01 20:45:39 - train: epoch 0226, iter [00910, 01251], lr: 0.000570, loss: 0.3845
2022-10-01 20:45:56 - train: epoch 0226, iter [00920, 01251], lr: 0.000570, loss: 0.3919
2022-10-01 20:46:14 - train: epoch 0226, iter [00930, 01251], lr: 0.000570, loss: 0.4007
2022-10-01 20:46:32 - train: epoch 0226, iter [00940, 01251], lr: 0.000570, loss: 0.3980
2022-10-01 20:46:50 - train: epoch 0226, iter [00950, 01251], lr: 0.000570, loss: 0.4125
2022-10-01 20:47:07 - train: epoch 0226, iter [00960, 01251], lr: 0.000570, loss: 0.4105
2022-10-01 20:47:25 - train: epoch 0226, iter [00970, 01251], lr: 0.000570, loss: 0.4089
2022-10-01 20:47:43 - train: epoch 0226, iter [00980, 01251], lr: 0.000570, loss: 0.4095
2022-10-01 20:48:00 - train: epoch 0226, iter [00990, 01251], lr: 0.000570, loss: 0.4020
2022-10-01 20:48:18 - train: epoch 0226, iter [01000, 01251], lr: 0.000570, loss: 0.4017
2022-10-01 20:48:36 - train: epoch 0226, iter [01010, 01251], lr: 0.000570, loss: 0.4097
2022-10-01 20:48:54 - train: epoch 0226, iter [01020, 01251], lr: 0.000570, loss: 0.4019
2022-10-01 20:49:11 - train: epoch 0226, iter [01030, 01251], lr: 0.000570, loss: 0.4044
2022-10-01 20:49:29 - train: epoch 0226, iter [01040, 01251], lr: 0.000569, loss: 0.4151
2022-10-01 20:49:47 - train: epoch 0226, iter [01050, 01251], lr: 0.000569, loss: 0.4126
2022-10-01 20:50:04 - train: epoch 0226, iter [01060, 01251], lr: 0.000569, loss: 0.4068
2022-10-01 20:50:22 - train: epoch 0226, iter [01070, 01251], lr: 0.000569, loss: 0.4135
2022-10-01 20:50:40 - train: epoch 0226, iter [01080, 01251], lr: 0.000569, loss: 0.4155
2022-10-01 20:50:57 - train: epoch 0226, iter [01090, 01251], lr: 0.000569, loss: 0.3916
2022-10-01 20:51:15 - train: epoch 0226, iter [01100, 01251], lr: 0.000569, loss: 0.3971
2022-10-01 20:51:33 - train: epoch 0226, iter [01110, 01251], lr: 0.000569, loss: 0.4255
2022-10-01 20:51:50 - train: epoch 0226, iter [01120, 01251], lr: 0.000569, loss: 0.4112
2022-10-01 20:52:08 - train: epoch 0226, iter [01130, 01251], lr: 0.000569, loss: 0.4029
2022-10-01 20:52:25 - train: epoch 0226, iter [01140, 01251], lr: 0.000569, loss: 0.3998
2022-10-01 20:52:43 - train: epoch 0226, iter [01150, 01251], lr: 0.000569, loss: 0.4128
2022-10-01 20:53:01 - train: epoch 0226, iter [01160, 01251], lr: 0.000569, loss: 0.4029
2022-10-01 20:53:18 - train: epoch 0226, iter [01170, 01251], lr: 0.000569, loss: 0.4135
2022-10-01 20:53:36 - train: epoch 0226, iter [01180, 01251], lr: 0.000569, loss: 0.3905
2022-10-01 20:53:53 - train: epoch 0226, iter [01190, 01251], lr: 0.000569, loss: 0.4016
2022-10-01 20:54:11 - train: epoch 0226, iter [01200, 01251], lr: 0.000569, loss: 0.4194
2022-10-01 20:54:29 - train: epoch 0226, iter [01210, 01251], lr: 0.000569, loss: 0.3841
2022-10-01 20:54:46 - train: epoch 0226, iter [01220, 01251], lr: 0.000569, loss: 0.4069
2022-10-01 20:55:04 - train: epoch 0226, iter [01230, 01251], lr: 0.000569, loss: 0.4180
2022-10-01 20:55:22 - train: epoch 0226, iter [01240, 01251], lr: 0.000569, loss: 0.3981
2022-10-01 20:55:39 - train: epoch 0226, iter [01250, 01251], lr: 0.000569, loss: 0.3930
2022-10-01 20:55:42 - train: epoch 226, train_loss: 0.4051
2022-10-01 20:55:44 - until epoch: 226, best_loss: 0.4050
2022-10-01 20:55:44 - epoch 227 lr: 0.000569
2022-10-01 20:56:10 - train: epoch 0227, iter [00010, 01251], lr: 0.000569, loss: 0.3973
2022-10-01 20:56:27 - train: epoch 0227, iter [00020, 01251], lr: 0.000569, loss: 0.3783
2022-10-01 20:56:45 - train: epoch 0227, iter [00030, 01251], lr: 0.000568, loss: 0.3937
2022-10-01 20:57:03 - train: epoch 0227, iter [00040, 01251], lr: 0.000568, loss: 0.4169
2022-10-01 20:57:21 - train: epoch 0227, iter [00050, 01251], lr: 0.000568, loss: 0.3956
2022-10-01 20:57:39 - train: epoch 0227, iter [00060, 01251], lr: 0.000568, loss: 0.4121
2022-10-01 20:57:57 - train: epoch 0227, iter [00070, 01251], lr: 0.000568, loss: 0.4035
2022-10-01 20:58:15 - train: epoch 0227, iter [00080, 01251], lr: 0.000568, loss: 0.4228
2022-10-01 20:58:32 - train: epoch 0227, iter [00090, 01251], lr: 0.000568, loss: 0.4220
2022-10-01 20:58:50 - train: epoch 0227, iter [00100, 01251], lr: 0.000568, loss: 0.4200
2022-10-01 20:59:08 - train: epoch 0227, iter [00110, 01251], lr: 0.000568, loss: 0.3966
2022-10-01 20:59:26 - train: epoch 0227, iter [00120, 01251], lr: 0.000568, loss: 0.4050
2022-10-01 20:59:44 - train: epoch 0227, iter [00130, 01251], lr: 0.000568, loss: 0.3914
2022-10-01 21:00:01 - train: epoch 0227, iter [00140, 01251], lr: 0.000568, loss: 0.4127
2022-10-01 21:00:19 - train: epoch 0227, iter [00150, 01251], lr: 0.000568, loss: 0.4131
2022-10-01 21:00:37 - train: epoch 0227, iter [00160, 01251], lr: 0.000568, loss: 0.4030
2022-10-01 21:00:55 - train: epoch 0227, iter [00170, 01251], lr: 0.000568, loss: 0.3939
2022-10-01 21:01:13 - train: epoch 0227, iter [00180, 01251], lr: 0.000568, loss: 0.4002
2022-10-01 21:01:31 - train: epoch 0227, iter [00190, 01251], lr: 0.000568, loss: 0.3956
2022-10-01 21:01:49 - train: epoch 0227, iter [00200, 01251], lr: 0.000568, loss: 0.3866
2022-10-01 21:02:07 - train: epoch 0227, iter [00210, 01251], lr: 0.000568, loss: 0.3961
2022-10-01 21:02:24 - train: epoch 0227, iter [00220, 01251], lr: 0.000568, loss: 0.4134
2022-10-01 21:02:42 - train: epoch 0227, iter [00230, 01251], lr: 0.000568, loss: 0.4031
2022-10-01 21:03:00 - train: epoch 0227, iter [00240, 01251], lr: 0.000568, loss: 0.3989
2022-10-01 21:03:18 - train: epoch 0227, iter [00250, 01251], lr: 0.000568, loss: 0.4113
2022-10-01 21:03:36 - train: epoch 0227, iter [00260, 01251], lr: 0.000568, loss: 0.4092
2022-10-01 21:03:53 - train: epoch 0227, iter [00270, 01251], lr: 0.000567, loss: 0.4058
2022-10-01 21:04:11 - train: epoch 0227, iter [00280, 01251], lr: 0.000567, loss: 0.3968
2022-10-01 21:04:29 - train: epoch 0227, iter [00290, 01251], lr: 0.000567, loss: 0.4115
2022-10-01 21:04:47 - train: epoch 0227, iter [00300, 01251], lr: 0.000567, loss: 0.4133
2022-10-01 21:05:05 - train: epoch 0227, iter [00310, 01251], lr: 0.000567, loss: 0.4156
2022-10-01 21:05:23 - train: epoch 0227, iter [00320, 01251], lr: 0.000567, loss: 0.4206
2022-10-01 21:05:41 - train: epoch 0227, iter [00330, 01251], lr: 0.000567, loss: 0.3947
2022-10-01 21:05:58 - train: epoch 0227, iter [00340, 01251], lr: 0.000567, loss: 0.4035
2022-10-01 21:06:16 - train: epoch 0227, iter [00350, 01251], lr: 0.000567, loss: 0.4030
2022-10-01 21:06:34 - train: epoch 0227, iter [00360, 01251], lr: 0.000567, loss: 0.3937
2022-10-01 21:06:52 - train: epoch 0227, iter [00370, 01251], lr: 0.000567, loss: 0.4184
2022-10-01 21:07:10 - train: epoch 0227, iter [00380, 01251], lr: 0.000567, loss: 0.4095
2022-10-01 21:07:28 - train: epoch 0227, iter [00390, 01251], lr: 0.000567, loss: 0.4186
2022-10-01 21:07:45 - train: epoch 0227, iter [00400, 01251], lr: 0.000567, loss: 0.4051
2022-10-01 21:08:03 - train: epoch 0227, iter [00410, 01251], lr: 0.000567, loss: 0.4163
2022-10-01 21:08:21 - train: epoch 0227, iter [00420, 01251], lr: 0.000567, loss: 0.4023
2022-10-01 21:08:39 - train: epoch 0227, iter [00430, 01251], lr: 0.000567, loss: 0.4043
2022-10-01 21:08:57 - train: epoch 0227, iter [00440, 01251], lr: 0.000567, loss: 0.4130
2022-10-01 21:09:14 - train: epoch 0227, iter [00450, 01251], lr: 0.000567, loss: 0.3903
2022-10-01 21:09:32 - train: epoch 0227, iter [00460, 01251], lr: 0.000567, loss: 0.4074
2022-10-01 21:09:50 - train: epoch 0227, iter [00470, 01251], lr: 0.000567, loss: 0.3840
2022-10-01 21:10:08 - train: epoch 0227, iter [00480, 01251], lr: 0.000567, loss: 0.4014
2022-10-01 21:10:26 - train: epoch 0227, iter [00490, 01251], lr: 0.000567, loss: 0.4152
2022-10-01 21:10:43 - train: epoch 0227, iter [00500, 01251], lr: 0.000567, loss: 0.3879
2022-10-01 21:11:01 - train: epoch 0227, iter [00510, 01251], lr: 0.000566, loss: 0.3909
2022-10-01 21:11:19 - train: epoch 0227, iter [00520, 01251], lr: 0.000566, loss: 0.4026
2022-10-01 21:11:37 - train: epoch 0227, iter [00530, 01251], lr: 0.000566, loss: 0.4014
2022-10-01 21:11:54 - train: epoch 0227, iter [00540, 01251], lr: 0.000566, loss: 0.4070
2022-10-01 21:12:12 - train: epoch 0227, iter [00550, 01251], lr: 0.000566, loss: 0.3819
2022-10-01 21:12:30 - train: epoch 0227, iter [00560, 01251], lr: 0.000566, loss: 0.3982
2022-10-01 21:12:48 - train: epoch 0227, iter [00570, 01251], lr: 0.000566, loss: 0.4064
2022-10-01 21:13:05 - train: epoch 0227, iter [00580, 01251], lr: 0.000566, loss: 0.4174
2022-10-01 21:13:23 - train: epoch 0227, iter [00590, 01251], lr: 0.000566, loss: 0.4067
2022-10-01 21:13:41 - train: epoch 0227, iter [00600, 01251], lr: 0.000566, loss: 0.4120
2022-10-01 21:13:59 - train: epoch 0227, iter [00610, 01251], lr: 0.000566, loss: 0.4129
2022-10-01 21:14:16 - train: epoch 0227, iter [00620, 01251], lr: 0.000566, loss: 0.4122
2022-10-01 21:14:34 - train: epoch 0227, iter [00630, 01251], lr: 0.000566, loss: 0.4065
2022-10-01 21:14:52 - train: epoch 0227, iter [00640, 01251], lr: 0.000566, loss: 0.4098
2022-10-01 21:15:09 - train: epoch 0227, iter [00650, 01251], lr: 0.000566, loss: 0.4152
2022-10-01 21:15:27 - train: epoch 0227, iter [00660, 01251], lr: 0.000566, loss: 0.4030
2022-10-01 21:15:45 - train: epoch 0227, iter [00670, 01251], lr: 0.000566, loss: 0.4005
2022-10-01 21:16:02 - train: epoch 0227, iter [00680, 01251], lr: 0.000566, loss: 0.4033
2022-10-01 21:16:20 - train: epoch 0227, iter [00690, 01251], lr: 0.000566, loss: 0.3962
2022-10-01 21:16:38 - train: epoch 0227, iter [00700, 01251], lr: 0.000566, loss: 0.3941
2022-10-01 21:16:55 - train: epoch 0227, iter [00710, 01251], lr: 0.000566, loss: 0.3977
2022-10-01 21:17:13 - train: epoch 0227, iter [00720, 01251], lr: 0.000566, loss: 0.4011
2022-10-01 21:17:31 - train: epoch 0227, iter [00730, 01251], lr: 0.000566, loss: 0.3986
2022-10-01 21:17:49 - train: epoch 0227, iter [00740, 01251], lr: 0.000566, loss: 0.4171
2022-10-01 21:18:06 - train: epoch 0227, iter [00750, 01251], lr: 0.000565, loss: 0.3936
2022-10-01 21:18:24 - train: epoch 0227, iter [00760, 01251], lr: 0.000565, loss: 0.4112
2022-10-01 21:18:41 - train: epoch 0227, iter [00770, 01251], lr: 0.000565, loss: 0.4067
2022-10-01 21:18:59 - train: epoch 0227, iter [00780, 01251], lr: 0.000565, loss: 0.3841
2022-10-01 21:19:17 - train: epoch 0227, iter [00790, 01251], lr: 0.000565, loss: 0.4188
2022-10-01 21:19:35 - train: epoch 0227, iter [00800, 01251], lr: 0.000565, loss: 0.4013
2022-10-01 21:19:52 - train: epoch 0227, iter [00810, 01251], lr: 0.000565, loss: 0.3914
2022-10-01 21:20:10 - train: epoch 0227, iter [00820, 01251], lr: 0.000565, loss: 0.3962
2022-10-01 21:20:28 - train: epoch 0227, iter [00830, 01251], lr: 0.000565, loss: 0.4065
2022-10-01 21:20:46 - train: epoch 0227, iter [00840, 01251], lr: 0.000565, loss: 0.3913
2022-10-01 21:21:04 - train: epoch 0227, iter [00850, 01251], lr: 0.000565, loss: 0.3933
2022-10-01 21:21:21 - train: epoch 0227, iter [00860, 01251], lr: 0.000565, loss: 0.4154
2022-10-01 21:21:39 - train: epoch 0227, iter [00870, 01251], lr: 0.000565, loss: 0.4094
2022-10-01 21:21:57 - train: epoch 0227, iter [00880, 01251], lr: 0.000565, loss: 0.3872
2022-10-01 21:22:14 - train: epoch 0227, iter [00890, 01251], lr: 0.000565, loss: 0.4081
2022-10-01 21:22:32 - train: epoch 0227, iter [00900, 01251], lr: 0.000565, loss: 0.4055
2022-10-01 21:22:50 - train: epoch 0227, iter [00910, 01251], lr: 0.000565, loss: 0.4040
2022-10-01 21:23:08 - train: epoch 0227, iter [00920, 01251], lr: 0.000565, loss: 0.4032
2022-10-01 21:23:25 - train: epoch 0227, iter [00930, 01251], lr: 0.000565, loss: 0.3991
2022-10-01 21:23:43 - train: epoch 0227, iter [00940, 01251], lr: 0.000565, loss: 0.3969
2022-10-01 21:24:01 - train: epoch 0227, iter [00950, 01251], lr: 0.000565, loss: 0.4132
2022-10-01 21:24:18 - train: epoch 0227, iter [00960, 01251], lr: 0.000565, loss: 0.4092
2022-10-01 21:24:36 - train: epoch 0227, iter [00970, 01251], lr: 0.000565, loss: 0.4041
2022-10-01 21:24:53 - train: epoch 0227, iter [00980, 01251], lr: 0.000565, loss: 0.4066
2022-10-01 21:25:11 - train: epoch 0227, iter [00990, 01251], lr: 0.000564, loss: 0.4163
2022-10-01 21:25:29 - train: epoch 0227, iter [01000, 01251], lr: 0.000564, loss: 0.4139
2022-10-01 21:25:47 - train: epoch 0227, iter [01010, 01251], lr: 0.000564, loss: 0.4086
2022-10-01 21:26:05 - train: epoch 0227, iter [01020, 01251], lr: 0.000564, loss: 0.4177
2022-10-01 21:26:22 - train: epoch 0227, iter [01030, 01251], lr: 0.000564, loss: 0.3949
2022-10-01 21:26:40 - train: epoch 0227, iter [01040, 01251], lr: 0.000564, loss: 0.4122
2022-10-01 21:26:58 - train: epoch 0227, iter [01050, 01251], lr: 0.000564, loss: 0.3992
2022-10-01 21:27:15 - train: epoch 0227, iter [01060, 01251], lr: 0.000564, loss: 0.4052
2022-10-01 21:27:33 - train: epoch 0227, iter [01070, 01251], lr: 0.000564, loss: 0.4153
2022-10-01 21:27:51 - train: epoch 0227, iter [01080, 01251], lr: 0.000564, loss: 0.3977
2022-10-01 21:28:08 - train: epoch 0227, iter [01090, 01251], lr: 0.000564, loss: 0.3974
2022-10-01 21:28:26 - train: epoch 0227, iter [01100, 01251], lr: 0.000564, loss: 0.4119
2022-10-01 21:28:43 - train: epoch 0227, iter [01110, 01251], lr: 0.000564, loss: 0.4155
2022-10-01 21:29:01 - train: epoch 0227, iter [01120, 01251], lr: 0.000564, loss: 0.3935
2022-10-01 21:29:18 - train: epoch 0227, iter [01130, 01251], lr: 0.000564, loss: 0.3973
2022-10-01 21:29:36 - train: epoch 0227, iter [01140, 01251], lr: 0.000564, loss: 0.3986
2022-10-01 21:29:54 - train: epoch 0227, iter [01150, 01251], lr: 0.000564, loss: 0.4251
2022-10-01 21:30:11 - train: epoch 0227, iter [01160, 01251], lr: 0.000564, loss: 0.4177
2022-10-01 21:30:29 - train: epoch 0227, iter [01170, 01251], lr: 0.000564, loss: 0.4061
2022-10-01 21:30:47 - train: epoch 0227, iter [01180, 01251], lr: 0.000564, loss: 0.4200
2022-10-01 21:31:05 - train: epoch 0227, iter [01190, 01251], lr: 0.000564, loss: 0.4033
2022-10-01 21:31:23 - train: epoch 0227, iter [01200, 01251], lr: 0.000564, loss: 0.4131
2022-10-01 21:31:40 - train: epoch 0227, iter [01210, 01251], lr: 0.000564, loss: 0.3943
2022-10-01 21:31:58 - train: epoch 0227, iter [01220, 01251], lr: 0.000564, loss: 0.3912
2022-10-01 21:32:15 - train: epoch 0227, iter [01230, 01251], lr: 0.000563, loss: 0.3942
2022-10-01 21:32:33 - train: epoch 0227, iter [01240, 01251], lr: 0.000563, loss: 0.4176
2022-10-01 21:32:50 - train: epoch 0227, iter [01250, 01251], lr: 0.000563, loss: 0.4022
2022-10-01 21:32:54 - train: epoch 227, train_loss: 0.4049
2022-10-01 21:32:56 - until epoch: 227, best_loss: 0.4049
2022-10-01 22:57:27 - epoch 228 lr: 0.000563
2022-10-01 22:58:14 - train: epoch 0228, iter [00020, 01251], lr: 0.000563, loss: 0.4343
2022-10-01 22:58:32 - train: epoch 0228, iter [00030, 01251], lr: 0.000563, loss: 0.4113
2022-10-01 22:58:50 - train: epoch 0228, iter [00040, 01251], lr: 0.000563, loss: 0.4182
2022-10-01 22:59:08 - train: epoch 0228, iter [00050, 01251], lr: 0.000563, loss: 0.4105
2022-10-01 22:59:26 - train: epoch 0228, iter [00060, 01251], lr: 0.000563, loss: 0.4071
2022-10-01 22:59:44 - train: epoch 0228, iter [00070, 01251], lr: 0.000563, loss: 0.3935
2022-10-01 23:00:02 - train: epoch 0228, iter [00080, 01251], lr: 0.000563, loss: 0.4116
2022-10-01 23:00:20 - train: epoch 0228, iter [00090, 01251], lr: 0.000563, loss: 0.3938
2022-10-01 23:00:38 - train: epoch 0228, iter [00100, 01251], lr: 0.000563, loss: 0.4170
2022-10-01 23:00:56 - train: epoch 0228, iter [00110, 01251], lr: 0.000563, loss: 0.3944
2022-10-01 23:01:13 - train: epoch 0228, iter [00120, 01251], lr: 0.000563, loss: 0.4302
2022-10-01 23:01:31 - train: epoch 0228, iter [00130, 01251], lr: 0.000563, loss: 0.4156
2022-10-01 23:01:49 - train: epoch 0228, iter [00140, 01251], lr: 0.000563, loss: 0.4223
2022-10-01 23:02:07 - train: epoch 0228, iter [00150, 01251], lr: 0.000563, loss: 0.3939
2022-10-01 23:02:25 - train: epoch 0228, iter [00160, 01251], lr: 0.000563, loss: 0.4033
2022-10-01 23:02:43 - train: epoch 0228, iter [00170, 01251], lr: 0.000563, loss: 0.3965
2022-10-01 23:03:01 - train: epoch 0228, iter [00180, 01251], lr: 0.000563, loss: 0.3919
2022-10-01 23:03:19 - train: epoch 0228, iter [00190, 01251], lr: 0.000563, loss: 0.4319
2022-10-01 23:03:37 - train: epoch 0228, iter [00200, 01251], lr: 0.000563, loss: 0.4036
2022-10-01 23:03:55 - train: epoch 0228, iter [00210, 01251], lr: 0.000562, loss: 0.4029
2022-10-01 23:04:12 - train: epoch 0228, iter [00220, 01251], lr: 0.000562, loss: 0.3964
2022-10-01 23:04:31 - train: epoch 0228, iter [00230, 01251], lr: 0.000562, loss: 0.4037
2022-10-01 23:04:49 - train: epoch 0228, iter [00240, 01251], lr: 0.000562, loss: 0.3871
2022-10-01 23:05:06 - train: epoch 0228, iter [00250, 01251], lr: 0.000562, loss: 0.4157
2022-10-01 23:05:24 - train: epoch 0228, iter [00260, 01251], lr: 0.000562, loss: 0.4115
2022-10-01 23:05:42 - train: epoch 0228, iter [00270, 01251], lr: 0.000562, loss: 0.4187
2022-10-01 23:05:59 - train: epoch 0228, iter [00280, 01251], lr: 0.000562, loss: 0.4219
2022-10-01 23:06:17 - train: epoch 0228, iter [00290, 01251], lr: 0.000562, loss: 0.4217
2022-10-01 23:06:35 - train: epoch 0228, iter [00300, 01251], lr: 0.000562, loss: 0.3979
2022-10-01 23:06:53 - train: epoch 0228, iter [00310, 01251], lr: 0.000562, loss: 0.4146
2022-10-01 23:07:11 - train: epoch 0228, iter [00320, 01251], lr: 0.000562, loss: 0.4121
2022-10-01 23:07:29 - train: epoch 0228, iter [00330, 01251], lr: 0.000562, loss: 0.3760
2022-10-01 23:07:46 - train: epoch 0228, iter [00340, 01251], lr: 0.000562, loss: 0.4216
2022-10-01 23:08:04 - train: epoch 0228, iter [00350, 01251], lr: 0.000562, loss: 0.4018
2022-10-01 23:08:22 - train: epoch 0228, iter [00360, 01251], lr: 0.000562, loss: 0.3929
2022-10-01 23:08:40 - train: epoch 0228, iter [00370, 01251], lr: 0.000562, loss: 0.4155
2022-10-01 23:08:58 - train: epoch 0228, iter [00380, 01251], lr: 0.000562, loss: 0.4163
2022-10-01 23:09:16 - train: epoch 0228, iter [00390, 01251], lr: 0.000562, loss: 0.4061
2022-10-01 23:09:34 - train: epoch 0228, iter [00400, 01251], lr: 0.000562, loss: 0.3913
2022-10-01 23:09:51 - train: epoch 0228, iter [00410, 01251], lr: 0.000562, loss: 0.4125
2022-10-01 23:10:09 - train: epoch 0228, iter [00420, 01251], lr: 0.000562, loss: 0.4089
2022-10-01 23:10:27 - train: epoch 0228, iter [00430, 01251], lr: 0.000562, loss: 0.3998
2022-10-01 23:10:45 - train: epoch 0228, iter [00440, 01251], lr: 0.000562, loss: 0.3966
2022-10-01 23:11:03 - train: epoch 0228, iter [00450, 01251], lr: 0.000561, loss: 0.3982
2022-10-01 23:11:21 - train: epoch 0228, iter [00460, 01251], lr: 0.000561, loss: 0.4052
2022-10-01 23:11:39 - train: epoch 0228, iter [00470, 01251], lr: 0.000561, loss: 0.4231
2022-10-01 23:11:57 - train: epoch 0228, iter [00480, 01251], lr: 0.000561, loss: 0.3967
2022-10-01 23:12:15 - train: epoch 0228, iter [00490, 01251], lr: 0.000561, loss: 0.3871
2022-10-01 23:12:32 - train: epoch 0228, iter [00500, 01251], lr: 0.000561, loss: 0.4013
2022-10-01 23:12:50 - train: epoch 0228, iter [00510, 01251], lr: 0.000561, loss: 0.4056
2022-10-01 23:13:08 - train: epoch 0228, iter [00520, 01251], lr: 0.000561, loss: 0.4067
2022-10-01 23:13:26 - train: epoch 0228, iter [00530, 01251], lr: 0.000561, loss: 0.3883
2022-10-01 23:13:44 - train: epoch 0228, iter [00540, 01251], lr: 0.000561, loss: 0.4070
2022-10-01 23:14:02 - train: epoch 0228, iter [00550, 01251], lr: 0.000561, loss: 0.3942
2022-10-01 23:14:19 - train: epoch 0228, iter [00560, 01251], lr: 0.000561, loss: 0.4028
2022-10-01 23:14:37 - train: epoch 0228, iter [00570, 01251], lr: 0.000561, loss: 0.4239
2022-10-01 23:14:55 - train: epoch 0228, iter [00580, 01251], lr: 0.000561, loss: 0.3912
2022-10-01 23:15:13 - train: epoch 0228, iter [00590, 01251], lr: 0.000561, loss: 0.3897
2022-10-01 23:15:31 - train: epoch 0228, iter [00600, 01251], lr: 0.000561, loss: 0.3847
2022-10-01 23:15:49 - train: epoch 0228, iter [00610, 01251], lr: 0.000561, loss: 0.4001
2022-10-01 23:16:06 - train: epoch 0228, iter [00620, 01251], lr: 0.000561, loss: 0.4389
2022-10-01 23:16:24 - train: epoch 0228, iter [00630, 01251], lr: 0.000561, loss: 0.4069
2022-10-01 23:16:42 - train: epoch 0228, iter [00640, 01251], lr: 0.000561, loss: 0.4050
2022-10-01 23:17:00 - train: epoch 0228, iter [00650, 01251], lr: 0.000561, loss: 0.4086
2022-10-01 23:17:18 - train: epoch 0228, iter [00660, 01251], lr: 0.000561, loss: 0.4129
2022-10-01 23:17:35 - train: epoch 0228, iter [00670, 01251], lr: 0.000561, loss: 0.3937
2022-10-01 23:17:54 - train: epoch 0228, iter [00680, 01251], lr: 0.000561, loss: 0.4137
2022-10-01 23:18:11 - train: epoch 0228, iter [00690, 01251], lr: 0.000560, loss: 0.3863
2022-10-01 23:18:29 - train: epoch 0228, iter [00700, 01251], lr: 0.000560, loss: 0.3892
2022-10-01 23:18:47 - train: epoch 0228, iter [00710, 01251], lr: 0.000560, loss: 0.4167
2022-10-01 23:19:05 - train: epoch 0228, iter [00720, 01251], lr: 0.000560, loss: 0.4035
2022-10-01 23:19:23 - train: epoch 0228, iter [00730, 01251], lr: 0.000560, loss: 0.4233
2022-10-01 23:19:41 - train: epoch 0228, iter [00740, 01251], lr: 0.000560, loss: 0.3860
2022-10-01 23:19:58 - train: epoch 0228, iter [00750, 01251], lr: 0.000560, loss: 0.3994
2022-10-01 23:20:17 - train: epoch 0228, iter [00760, 01251], lr: 0.000560, loss: 0.4233
2022-10-01 23:20:34 - train: epoch 0228, iter [00770, 01251], lr: 0.000560, loss: 0.3880
2022-10-01 23:20:52 - train: epoch 0228, iter [00780, 01251], lr: 0.000560, loss: 0.4063
2022-10-01 23:21:10 - train: epoch 0228, iter [00790, 01251], lr: 0.000560, loss: 0.4017
2022-10-01 23:21:28 - train: epoch 0228, iter [00800, 01251], lr: 0.000560, loss: 0.4219
2022-10-01 23:21:46 - train: epoch 0228, iter [00810, 01251], lr: 0.000560, loss: 0.4100
2022-10-01 23:22:04 - train: epoch 0228, iter [00820, 01251], lr: 0.000560, loss: 0.3854
2022-10-01 23:22:22 - train: epoch 0228, iter [00830, 01251], lr: 0.000560, loss: 0.4077
2022-10-01 23:22:40 - train: epoch 0228, iter [00840, 01251], lr: 0.000560, loss: 0.3979
2022-10-01 23:22:58 - train: epoch 0228, iter [00850, 01251], lr: 0.000560, loss: 0.4040
2022-10-01 23:23:16 - train: epoch 0228, iter [00860, 01251], lr: 0.000560, loss: 0.3993
2022-10-01 23:23:33 - train: epoch 0228, iter [00870, 01251], lr: 0.000560, loss: 0.4118
2022-10-01 23:23:51 - train: epoch 0228, iter [00880, 01251], lr: 0.000560, loss: 0.4066
2022-10-01 23:24:09 - train: epoch 0228, iter [00890, 01251], lr: 0.000560, loss: 0.4039
2022-10-01 23:24:27 - train: epoch 0228, iter [00900, 01251], lr: 0.000560, loss: 0.3982
2022-10-01 23:24:45 - train: epoch 0228, iter [00910, 01251], lr: 0.000560, loss: 0.4023
2022-10-01 23:25:03 - train: epoch 0228, iter [00920, 01251], lr: 0.000560, loss: 0.4099
2022-10-01 23:25:21 - train: epoch 0228, iter [00930, 01251], lr: 0.000559, loss: 0.4192
2022-10-01 23:25:38 - train: epoch 0228, iter [00940, 01251], lr: 0.000559, loss: 0.4102
2022-10-01 23:25:56 - train: epoch 0228, iter [00950, 01251], lr: 0.000559, loss: 0.4141
2022-10-01 23:26:14 - train: epoch 0228, iter [00960, 01251], lr: 0.000559, loss: 0.4083
2022-10-01 23:26:32 - train: epoch 0228, iter [00970, 01251], lr: 0.000559, loss: 0.4060
2022-10-01 23:26:50 - train: epoch 0228, iter [00980, 01251], lr: 0.000559, loss: 0.4281
2022-10-01 23:27:08 - train: epoch 0228, iter [00990, 01251], lr: 0.000559, loss: 0.4037
2022-10-01 23:27:26 - train: epoch 0228, iter [01000, 01251], lr: 0.000559, loss: 0.4016
2022-10-01 23:27:44 - train: epoch 0228, iter [01010, 01251], lr: 0.000559, loss: 0.4260
2022-10-01 23:28:02 - train: epoch 0228, iter [01020, 01251], lr: 0.000559, loss: 0.4127
2022-10-01 23:28:20 - train: epoch 0228, iter [01030, 01251], lr: 0.000559, loss: 0.4121
2022-10-01 23:28:38 - train: epoch 0228, iter [01040, 01251], lr: 0.000559, loss: 0.4018
2022-10-01 23:28:56 - train: epoch 0228, iter [01050, 01251], lr: 0.000559, loss: 0.3991
2022-10-01 23:29:13 - train: epoch 0228, iter [01060, 01251], lr: 0.000559, loss: 0.4122
2022-10-01 23:29:31 - train: epoch 0228, iter [01070, 01251], lr: 0.000559, loss: 0.4104
2022-10-01 23:29:49 - train: epoch 0228, iter [01080, 01251], lr: 0.000559, loss: 0.3888
2022-10-01 23:30:07 - train: epoch 0228, iter [01090, 01251], lr: 0.000559, loss: 0.4048
2022-10-01 23:30:25 - train: epoch 0228, iter [01100, 01251], lr: 0.000559, loss: 0.3993
2022-10-01 23:30:43 - train: epoch 0228, iter [01110, 01251], lr: 0.000559, loss: 0.3937
2022-10-01 23:31:00 - train: epoch 0228, iter [01120, 01251], lr: 0.000559, loss: 0.4321
2022-10-01 23:31:18 - train: epoch 0228, iter [01130, 01251], lr: 0.000559, loss: 0.4130
2022-10-01 23:31:36 - train: epoch 0228, iter [01140, 01251], lr: 0.000559, loss: 0.4003
2022-10-01 23:31:53 - train: epoch 0228, iter [01150, 01251], lr: 0.000559, loss: 0.3877
2022-10-01 23:32:11 - train: epoch 0228, iter [01160, 01251], lr: 0.000559, loss: 0.3923
2022-10-01 23:32:29 - train: epoch 0228, iter [01170, 01251], lr: 0.000558, loss: 0.3973
2022-10-01 23:32:47 - train: epoch 0228, iter [01180, 01251], lr: 0.000558, loss: 0.4152
2022-10-01 23:33:05 - train: epoch 0228, iter [01190, 01251], lr: 0.000558, loss: 0.3962
2022-10-01 23:33:23 - train: epoch 0228, iter [01200, 01251], lr: 0.000558, loss: 0.4131
2022-10-01 23:33:41 - train: epoch 0228, iter [01210, 01251], lr: 0.000558, loss: 0.3981
2022-10-01 23:33:59 - train: epoch 0228, iter [01220, 01251], lr: 0.000558, loss: 0.4085
2022-10-01 23:34:17 - train: epoch 0228, iter [01230, 01251], lr: 0.000558, loss: 0.3907
2022-10-01 23:34:35 - train: epoch 0228, iter [01240, 01251], lr: 0.000558, loss: 0.4106
2022-10-01 23:34:52 - train: epoch 0228, iter [01250, 01251], lr: 0.000558, loss: 0.4201
2022-10-01 23:34:56 - train: epoch 228, train_loss: 0.4047
2022-10-01 23:34:58 - until epoch: 228, best_loss: 0.4047
2022-10-01 23:34:58 - epoch 229 lr: 0.000558
2022-10-01 23:35:22 - train: epoch 0229, iter [00010, 01251], lr: 0.000558, loss: 0.4022
2022-10-01 23:35:40 - train: epoch 0229, iter [00020, 01251], lr: 0.000558, loss: 0.4273
2022-10-01 23:35:58 - train: epoch 0229, iter [00030, 01251], lr: 0.000558, loss: 0.3885
2022-10-01 23:36:16 - train: epoch 0229, iter [00040, 01251], lr: 0.000558, loss: 0.4043
2022-10-01 23:36:33 - train: epoch 0229, iter [00050, 01251], lr: 0.000558, loss: 0.3976
2022-10-01 23:36:51 - train: epoch 0229, iter [00060, 01251], lr: 0.000558, loss: 0.4031
2022-10-01 23:37:08 - train: epoch 0229, iter [00070, 01251], lr: 0.000558, loss: 0.4312
2022-10-01 23:37:26 - train: epoch 0229, iter [00080, 01251], lr: 0.000558, loss: 0.4216
2022-10-01 23:37:44 - train: epoch 0229, iter [00090, 01251], lr: 0.000558, loss: 0.4260
2022-10-01 23:38:02 - train: epoch 0229, iter [00100, 01251], lr: 0.000558, loss: 0.4046
2022-10-01 23:38:20 - train: epoch 0229, iter [00110, 01251], lr: 0.000558, loss: 0.3982
2022-10-01 23:38:37 - train: epoch 0229, iter [00120, 01251], lr: 0.000558, loss: 0.4179
2022-10-01 23:38:55 - train: epoch 0229, iter [00130, 01251], lr: 0.000558, loss: 0.4068
2022-10-01 23:39:13 - train: epoch 0229, iter [00140, 01251], lr: 0.000558, loss: 0.4153
2022-10-01 23:39:30 - train: epoch 0229, iter [00150, 01251], lr: 0.000558, loss: 0.4143
2022-10-01 23:39:48 - train: epoch 0229, iter [00160, 01251], lr: 0.000557, loss: 0.3977
2022-10-01 23:40:06 - train: epoch 0229, iter [00170, 01251], lr: 0.000557, loss: 0.4000
2022-10-01 23:40:24 - train: epoch 0229, iter [00180, 01251], lr: 0.000557, loss: 0.4071
2022-10-01 23:40:42 - train: epoch 0229, iter [00190, 01251], lr: 0.000557, loss: 0.4121
2022-10-01 23:40:59 - train: epoch 0229, iter [00200, 01251], lr: 0.000557, loss: 0.3976
2022-10-01 23:41:17 - train: epoch 0229, iter [00210, 01251], lr: 0.000557, loss: 0.3994
2022-10-01 23:41:35 - train: epoch 0229, iter [00220, 01251], lr: 0.000557, loss: 0.3918
2022-10-01 23:41:53 - train: epoch 0229, iter [00230, 01251], lr: 0.000557, loss: 0.4093
2022-10-01 23:42:11 - train: epoch 0229, iter [00240, 01251], lr: 0.000557, loss: 0.4114
2022-10-01 23:42:28 - train: epoch 0229, iter [00250, 01251], lr: 0.000557, loss: 0.4241
2022-10-01 23:42:46 - train: epoch 0229, iter [00260, 01251], lr: 0.000557, loss: 0.4092
2022-10-01 23:43:04 - train: epoch 0229, iter [00270, 01251], lr: 0.000557, loss: 0.4001
2022-10-01 23:43:22 - train: epoch 0229, iter [00280, 01251], lr: 0.000557, loss: 0.4052
2022-10-01 23:43:39 - train: epoch 0229, iter [00290, 01251], lr: 0.000557, loss: 0.3990
2022-10-01 23:43:57 - train: epoch 0229, iter [00300, 01251], lr: 0.000557, loss: 0.3940
2022-10-01 23:44:15 - train: epoch 0229, iter [00310, 01251], lr: 0.000557, loss: 0.4170
2022-10-01 23:44:33 - train: epoch 0229, iter [00320, 01251], lr: 0.000557, loss: 0.3763
2022-10-01 23:44:51 - train: epoch 0229, iter [00330, 01251], lr: 0.000557, loss: 0.4087
2022-10-01 23:45:09 - train: epoch 0229, iter [00340, 01251], lr: 0.000557, loss: 0.4055
2022-10-01 23:45:27 - train: epoch 0229, iter [00350, 01251], lr: 0.000557, loss: 0.4090
2022-10-01 23:45:45 - train: epoch 0229, iter [00360, 01251], lr: 0.000557, loss: 0.4281
2022-10-01 23:46:03 - train: epoch 0229, iter [00370, 01251], lr: 0.000557, loss: 0.4253
2022-10-01 23:46:21 - train: epoch 0229, iter [00380, 01251], lr: 0.000557, loss: 0.4111
2022-10-01 23:46:38 - train: epoch 0229, iter [00390, 01251], lr: 0.000557, loss: 0.3987
2022-10-01 23:46:56 - train: epoch 0229, iter [00400, 01251], lr: 0.000556, loss: 0.4155
2022-10-01 23:47:14 - train: epoch 0229, iter [00410, 01251], lr: 0.000556, loss: 0.3935
2022-10-01 23:47:32 - train: epoch 0229, iter [00420, 01251], lr: 0.000556, loss: 0.4078
2022-10-01 23:47:50 - train: epoch 0229, iter [00430, 01251], lr: 0.000556, loss: 0.4214
2022-10-01 23:48:08 - train: epoch 0229, iter [00440, 01251], lr: 0.000556, loss: 0.3985
2022-10-01 23:48:26 - train: epoch 0229, iter [00450, 01251], lr: 0.000556, loss: 0.4083
2022-10-01 23:48:43 - train: epoch 0229, iter [00460, 01251], lr: 0.000556, loss: 0.4156
2022-10-01 23:49:01 - train: epoch 0229, iter [00470, 01251], lr: 0.000556, loss: 0.3974
2022-10-01 23:49:19 - train: epoch 0229, iter [00480, 01251], lr: 0.000556, loss: 0.4088
2022-10-01 23:49:37 - train: epoch 0229, iter [00490, 01251], lr: 0.000556, loss: 0.4003
2022-10-01 23:49:55 - train: epoch 0229, iter [00500, 01251], lr: 0.000556, loss: 0.4137
2022-10-01 23:50:12 - train: epoch 0229, iter [00510, 01251], lr: 0.000556, loss: 0.4182
2022-10-01 23:50:30 - train: epoch 0229, iter [00520, 01251], lr: 0.000556, loss: 0.4039
2022-10-01 23:50:48 - train: epoch 0229, iter [00530, 01251], lr: 0.000556, loss: 0.4373
2022-10-01 23:51:06 - train: epoch 0229, iter [00540, 01251], lr: 0.000556, loss: 0.3714
2022-10-01 23:51:24 - train: epoch 0229, iter [00550, 01251], lr: 0.000556, loss: 0.3784
2022-10-01 23:51:42 - train: epoch 0229, iter [00560, 01251], lr: 0.000556, loss: 0.3906
2022-10-01 23:52:00 - train: epoch 0229, iter [00570, 01251], lr: 0.000556, loss: 0.4240
2022-10-01 23:52:18 - train: epoch 0229, iter [00580, 01251], lr: 0.000556, loss: 0.4068
2022-10-01 23:52:35 - train: epoch 0229, iter [00590, 01251], lr: 0.000556, loss: 0.4117
2022-10-01 23:52:53 - train: epoch 0229, iter [00600, 01251], lr: 0.000556, loss: 0.4101
2022-10-01 23:53:11 - train: epoch 0229, iter [00610, 01251], lr: 0.000556, loss: 0.4125
2022-10-01 23:53:29 - train: epoch 0229, iter [00620, 01251], lr: 0.000556, loss: 0.4196
2022-10-01 23:53:47 - train: epoch 0229, iter [00630, 01251], lr: 0.000556, loss: 0.3979
2022-10-01 23:54:05 - train: epoch 0229, iter [00640, 01251], lr: 0.000555, loss: 0.3903
2022-10-01 23:54:22 - train: epoch 0229, iter [00650, 01251], lr: 0.000555, loss: 0.3970
2022-10-01 23:54:40 - train: epoch 0229, iter [00660, 01251], lr: 0.000555, loss: 0.3905
2022-10-01 23:54:58 - train: epoch 0229, iter [00670, 01251], lr: 0.000555, loss: 0.4136
2022-10-01 23:55:16 - train: epoch 0229, iter [00680, 01251], lr: 0.000555, loss: 0.4142
2022-10-01 23:55:34 - train: epoch 0229, iter [00690, 01251], lr: 0.000555, loss: 0.3955
2022-10-01 23:55:52 - train: epoch 0229, iter [00700, 01251], lr: 0.000555, loss: 0.3999
2022-10-01 23:56:10 - train: epoch 0229, iter [00710, 01251], lr: 0.000555, loss: 0.4015
2022-10-01 23:56:27 - train: epoch 0229, iter [00720, 01251], lr: 0.000555, loss: 0.4074
2022-10-01 23:56:45 - train: epoch 0229, iter [00730, 01251], lr: 0.000555, loss: 0.4267
2022-10-01 23:57:03 - train: epoch 0229, iter [00740, 01251], lr: 0.000555, loss: 0.4097
2022-10-01 23:57:21 - train: epoch 0229, iter [00750, 01251], lr: 0.000555, loss: 0.3784
2022-10-01 23:57:39 - train: epoch 0229, iter [00760, 01251], lr: 0.000555, loss: 0.3940
2022-10-01 23:57:57 - train: epoch 0229, iter [00770, 01251], lr: 0.000555, loss: 0.4060
2022-10-01 23:58:14 - train: epoch 0229, iter [00780, 01251], lr: 0.000555, loss: 0.4048
2022-10-01 23:58:33 - train: epoch 0229, iter [00790, 01251], lr: 0.000555, loss: 0.4243
2022-10-01 23:58:50 - train: epoch 0229, iter [00800, 01251], lr: 0.000555, loss: 0.3952
2022-10-01 23:59:08 - train: epoch 0229, iter [00810, 01251], lr: 0.000555, loss: 0.4077
2022-10-01 23:59:26 - train: epoch 0229, iter [00820, 01251], lr: 0.000555, loss: 0.4179
2022-10-01 23:59:44 - train: epoch 0229, iter [00830, 01251], lr: 0.000555, loss: 0.4207
2022-10-02 00:00:01 - train: epoch 0229, iter [00840, 01251], lr: 0.000555, loss: 0.4239
2022-10-02 00:00:19 - train: epoch 0229, iter [00850, 01251], lr: 0.000555, loss: 0.4244
2022-10-02 00:00:37 - train: epoch 0229, iter [00860, 01251], lr: 0.000555, loss: 0.3999
2022-10-02 00:00:55 - train: epoch 0229, iter [00870, 01251], lr: 0.000555, loss: 0.3963
2022-10-02 00:01:13 - train: epoch 0229, iter [00880, 01251], lr: 0.000554, loss: 0.4083
2022-10-02 00:01:30 - train: epoch 0229, iter [00890, 01251], lr: 0.000554, loss: 0.4064
2022-10-02 00:01:48 - train: epoch 0229, iter [00900, 01251], lr: 0.000554, loss: 0.4066
2022-10-02 00:02:06 - train: epoch 0229, iter [00910, 01251], lr: 0.000554, loss: 0.4020
2022-10-02 00:02:24 - train: epoch 0229, iter [00920, 01251], lr: 0.000554, loss: 0.3971
2022-10-02 00:02:41 - train: epoch 0229, iter [00930, 01251], lr: 0.000554, loss: 0.4033
2022-10-02 00:02:59 - train: epoch 0229, iter [00940, 01251], lr: 0.000554, loss: 0.4085
2022-10-02 00:03:17 - train: epoch 0229, iter [00950, 01251], lr: 0.000554, loss: 0.3887
2022-10-02 00:03:35 - train: epoch 0229, iter [00960, 01251], lr: 0.000554, loss: 0.3822
2022-10-02 00:03:53 - train: epoch 0229, iter [00970, 01251], lr: 0.000554, loss: 0.4125
2022-10-02 00:04:11 - train: epoch 0229, iter [00980, 01251], lr: 0.000554, loss: 0.4177
2022-10-02 00:04:29 - train: epoch 0229, iter [00990, 01251], lr: 0.000554, loss: 0.3906
2022-10-02 00:04:46 - train: epoch 0229, iter [01000, 01251], lr: 0.000554, loss: 0.4226
2022-10-02 00:05:04 - train: epoch 0229, iter [01010, 01251], lr: 0.000554, loss: 0.4091
2022-10-02 00:05:22 - train: epoch 0229, iter [01020, 01251], lr: 0.000554, loss: 0.4044
2022-10-02 00:05:40 - train: epoch 0229, iter [01030, 01251], lr: 0.000554, loss: 0.4142
2022-10-02 00:05:57 - train: epoch 0229, iter [01040, 01251], lr: 0.000554, loss: 0.3911
2022-10-02 00:06:15 - train: epoch 0229, iter [01050, 01251], lr: 0.000554, loss: 0.4130
2022-10-02 00:06:33 - train: epoch 0229, iter [01060, 01251], lr: 0.000554, loss: 0.4157
2022-10-02 00:06:51 - train: epoch 0229, iter [01070, 01251], lr: 0.000554, loss: 0.4152
2022-10-02 00:07:09 - train: epoch 0229, iter [01080, 01251], lr: 0.000554, loss: 0.4153
2022-10-02 00:07:26 - train: epoch 0229, iter [01090, 01251], lr: 0.000554, loss: 0.4118
2022-10-02 00:07:44 - train: epoch 0229, iter [01100, 01251], lr: 0.000554, loss: 0.3934
2022-10-02 00:08:02 - train: epoch 0229, iter [01110, 01251], lr: 0.000554, loss: 0.4140
2022-10-02 00:08:20 - train: epoch 0229, iter [01120, 01251], lr: 0.000553, loss: 0.3997
2022-10-02 00:08:38 - train: epoch 0229, iter [01130, 01251], lr: 0.000553, loss: 0.3854
2022-10-02 00:08:55 - train: epoch 0229, iter [01140, 01251], lr: 0.000553, loss: 0.4045
2022-10-02 00:09:13 - train: epoch 0229, iter [01150, 01251], lr: 0.000553, loss: 0.4113
2022-10-02 00:09:31 - train: epoch 0229, iter [01160, 01251], lr: 0.000553, loss: 0.3897
2022-10-02 00:09:48 - train: epoch 0229, iter [01170, 01251], lr: 0.000553, loss: 0.4260
2022-10-02 00:10:06 - train: epoch 0229, iter [01180, 01251], lr: 0.000553, loss: 0.4092
2022-10-02 00:10:24 - train: epoch 0229, iter [01190, 01251], lr: 0.000553, loss: 0.4049
2022-10-02 00:10:42 - train: epoch 0229, iter [01200, 01251], lr: 0.000553, loss: 0.3963
2022-10-02 00:11:00 - train: epoch 0229, iter [01210, 01251], lr: 0.000553, loss: 0.4315
2022-10-02 00:11:18 - train: epoch 0229, iter [01220, 01251], lr: 0.000553, loss: 0.4103
2022-10-02 00:11:35 - train: epoch 0229, iter [01230, 01251], lr: 0.000553, loss: 0.3917
2022-10-02 00:11:53 - train: epoch 0229, iter [01240, 01251], lr: 0.000553, loss: 0.4181
2022-10-02 00:12:10 - train: epoch 0229, iter [01250, 01251], lr: 0.000553, loss: 0.4029
2022-10-02 00:12:14 - train: epoch 229, train_loss: 0.4047
2022-10-02 00:12:15 - until epoch: 229, best_loss: 0.4047
2022-10-02 00:12:15 - epoch 230 lr: 0.000553
2022-10-02 00:12:41 - train: epoch 0230, iter [00010, 01251], lr: 0.000553, loss: 0.4042
2022-10-02 00:12:59 - train: epoch 0230, iter [00020, 01251], lr: 0.000553, loss: 0.3908
2022-10-02 00:13:17 - train: epoch 0230, iter [00030, 01251], lr: 0.000553, loss: 0.4165
2022-10-02 00:13:35 - train: epoch 0230, iter [00040, 01251], lr: 0.000553, loss: 0.4214
2022-10-02 00:13:53 - train: epoch 0230, iter [00050, 01251], lr: 0.000553, loss: 0.4008
2022-10-02 00:14:11 - train: epoch 0230, iter [00060, 01251], lr: 0.000553, loss: 0.3961
2022-10-02 00:14:28 - train: epoch 0230, iter [00070, 01251], lr: 0.000553, loss: 0.4120
2022-10-02 00:14:46 - train: epoch 0230, iter [00080, 01251], lr: 0.000553, loss: 0.4120
2022-10-02 00:15:04 - train: epoch 0230, iter [00090, 01251], lr: 0.000553, loss: 0.3872
2022-10-02 00:15:22 - train: epoch 0230, iter [00100, 01251], lr: 0.000553, loss: 0.4010
2022-10-02 00:15:39 - train: epoch 0230, iter [00110, 01251], lr: 0.000552, loss: 0.4206
2022-10-02 00:15:57 - train: epoch 0230, iter [00120, 01251], lr: 0.000552, loss: 0.3876
2022-10-02 00:16:15 - train: epoch 0230, iter [00130, 01251], lr: 0.000552, loss: 0.3999
2022-10-02 00:16:32 - train: epoch 0230, iter [00140, 01251], lr: 0.000552, loss: 0.4152
2022-10-02 00:16:50 - train: epoch 0230, iter [00150, 01251], lr: 0.000552, loss: 0.4041
2022-10-02 00:17:08 - train: epoch 0230, iter [00160, 01251], lr: 0.000552, loss: 0.4076
2022-10-02 00:17:25 - train: epoch 0230, iter [00170, 01251], lr: 0.000552, loss: 0.4026
2022-10-02 00:17:43 - train: epoch 0230, iter [00180, 01251], lr: 0.000552, loss: 0.3974
2022-10-02 00:18:01 - train: epoch 0230, iter [00190, 01251], lr: 0.000552, loss: 0.4146
2022-10-02 00:18:19 - train: epoch 0230, iter [00200, 01251], lr: 0.000552, loss: 0.4149
2022-10-02 00:18:36 - train: epoch 0230, iter [00210, 01251], lr: 0.000552, loss: 0.3999
2022-10-02 00:18:54 - train: epoch 0230, iter [00220, 01251], lr: 0.000552, loss: 0.4077
2022-10-02 00:19:12 - train: epoch 0230, iter [00230, 01251], lr: 0.000552, loss: 0.4250
2022-10-02 00:19:29 - train: epoch 0230, iter [00240, 01251], lr: 0.000552, loss: 0.4246
2022-10-02 00:19:47 - train: epoch 0230, iter [00250, 01251], lr: 0.000552, loss: 0.3906
2022-10-02 00:20:05 - train: epoch 0230, iter [00260, 01251], lr: 0.000552, loss: 0.4018
2022-10-02 00:20:23 - train: epoch 0230, iter [00270, 01251], lr: 0.000552, loss: 0.4044
2022-10-02 00:20:41 - train: epoch 0230, iter [00280, 01251], lr: 0.000552, loss: 0.4045
2022-10-02 00:20:58 - train: epoch 0230, iter [00290, 01251], lr: 0.000552, loss: 0.3996
2022-10-02 00:21:16 - train: epoch 0230, iter [00300, 01251], lr: 0.000552, loss: 0.3973
2022-10-02 00:21:34 - train: epoch 0230, iter [00310, 01251], lr: 0.000552, loss: 0.4052
2022-10-02 00:21:52 - train: epoch 0230, iter [00320, 01251], lr: 0.000552, loss: 0.3965
2022-10-02 00:22:10 - train: epoch 0230, iter [00330, 01251], lr: 0.000552, loss: 0.4184
2022-10-02 00:22:27 - train: epoch 0230, iter [00340, 01251], lr: 0.000552, loss: 0.4033
2022-10-02 00:22:45 - train: epoch 0230, iter [00350, 01251], lr: 0.000551, loss: 0.4335
2022-10-02 00:23:03 - train: epoch 0230, iter [00360, 01251], lr: 0.000551, loss: 0.4037
2022-10-02 00:23:20 - train: epoch 0230, iter [00370, 01251], lr: 0.000551, loss: 0.3865
2022-10-02 00:23:38 - train: epoch 0230, iter [00380, 01251], lr: 0.000551, loss: 0.4109
2022-10-02 00:23:56 - train: epoch 0230, iter [00390, 01251], lr: 0.000551, loss: 0.4037
2022-10-02 00:24:13 - train: epoch 0230, iter [00400, 01251], lr: 0.000551, loss: 0.4000
2022-10-02 00:24:31 - train: epoch 0230, iter [00410, 01251], lr: 0.000551, loss: 0.4051
2022-10-02 00:24:49 - train: epoch 0230, iter [00420, 01251], lr: 0.000551, loss: 0.4122
2022-10-02 00:25:07 - train: epoch 0230, iter [00430, 01251], lr: 0.000551, loss: 0.4015
2022-10-02 00:25:24 - train: epoch 0230, iter [00440, 01251], lr: 0.000551, loss: 0.4116
2022-10-02 00:25:42 - train: epoch 0230, iter [00450, 01251], lr: 0.000551, loss: 0.4173
2022-10-02 00:26:00 - train: epoch 0230, iter [00460, 01251], lr: 0.000551, loss: 0.3838
2022-10-02 00:26:18 - train: epoch 0230, iter [00470, 01251], lr: 0.000551, loss: 0.4063
2022-10-02 00:26:35 - train: epoch 0230, iter [00480, 01251], lr: 0.000551, loss: 0.3965
2022-10-02 00:26:53 - train: epoch 0230, iter [00490, 01251], lr: 0.000551, loss: 0.3875
2022-10-02 00:27:11 - train: epoch 0230, iter [00500, 01251], lr: 0.000551, loss: 0.3985
2022-10-02 00:27:28 - train: epoch 0230, iter [00510, 01251], lr: 0.000551, loss: 0.4071
2022-10-02 00:27:46 - train: epoch 0230, iter [00520, 01251], lr: 0.000551, loss: 0.4015
2022-10-02 00:28:04 - train: epoch 0230, iter [00530, 01251], lr: 0.000551, loss: 0.4184
2022-10-02 00:28:22 - train: epoch 0230, iter [00540, 01251], lr: 0.000551, loss: 0.4099
2022-10-02 00:28:39 - train: epoch 0230, iter [00550, 01251], lr: 0.000551, loss: 0.3866
2022-10-02 00:28:57 - train: epoch 0230, iter [00560, 01251], lr: 0.000551, loss: 0.4163
2022-10-02 00:29:15 - train: epoch 0230, iter [00570, 01251], lr: 0.000551, loss: 0.4197
2022-10-02 00:29:33 - train: epoch 0230, iter [00580, 01251], lr: 0.000551, loss: 0.3936
2022-10-02 00:29:51 - train: epoch 0230, iter [00590, 01251], lr: 0.000550, loss: 0.4065
2022-10-02 00:30:08 - train: epoch 0230, iter [00600, 01251], lr: 0.000550, loss: 0.3859
2022-10-02 00:30:26 - train: epoch 0230, iter [00610, 01251], lr: 0.000550, loss: 0.4063
2022-10-02 00:30:44 - train: epoch 0230, iter [00620, 01251], lr: 0.000550, loss: 0.3973
2022-10-02 00:31:02 - train: epoch 0230, iter [00630, 01251], lr: 0.000550, loss: 0.3943
2022-10-02 00:31:19 - train: epoch 0230, iter [00640, 01251], lr: 0.000550, loss: 0.3887
2022-10-02 00:31:37 - train: epoch 0230, iter [00650, 01251], lr: 0.000550, loss: 0.3987
2022-10-02 00:31:55 - train: epoch 0230, iter [00660, 01251], lr: 0.000550, loss: 0.3989
2022-10-02 00:32:13 - train: epoch 0230, iter [00670, 01251], lr: 0.000550, loss: 0.4175
2022-10-02 00:32:31 - train: epoch 0230, iter [00680, 01251], lr: 0.000550, loss: 0.4008
2022-10-02 00:32:49 - train: epoch 0230, iter [00690, 01251], lr: 0.000550, loss: 0.3936
2022-10-02 00:33:06 - train: epoch 0230, iter [00700, 01251], lr: 0.000550, loss: 0.4064
2022-10-02 00:33:24 - train: epoch 0230, iter [00710, 01251], lr: 0.000550, loss: 0.3991
2022-10-02 00:33:42 - train: epoch 0230, iter [00720, 01251], lr: 0.000550, loss: 0.3894
2022-10-02 00:34:00 - train: epoch 0230, iter [00730, 01251], lr: 0.000550, loss: 0.4179
2022-10-02 00:34:17 - train: epoch 0230, iter [00740, 01251], lr: 0.000550, loss: 0.3943
2022-10-02 00:34:35 - train: epoch 0230, iter [00750, 01251], lr: 0.000550, loss: 0.4080
2022-10-02 00:34:53 - train: epoch 0230, iter [00760, 01251], lr: 0.000550, loss: 0.4076
2022-10-02 00:35:11 - train: epoch 0230, iter [00770, 01251], lr: 0.000550, loss: 0.4000
2022-10-02 00:35:28 - train: epoch 0230, iter [00780, 01251], lr: 0.000550, loss: 0.4185
2022-10-02 00:35:46 - train: epoch 0230, iter [00790, 01251], lr: 0.000550, loss: 0.4331
2022-10-02 00:36:04 - train: epoch 0230, iter [00800, 01251], lr: 0.000550, loss: 0.4145
2022-10-02 00:36:22 - train: epoch 0230, iter [00810, 01251], lr: 0.000550, loss: 0.4077
2022-10-02 00:36:39 - train: epoch 0230, iter [00820, 01251], lr: 0.000550, loss: 0.4083
2022-10-02 00:36:57 - train: epoch 0230, iter [00830, 01251], lr: 0.000549, loss: 0.4109
2022-10-02 00:37:15 - train: epoch 0230, iter [00840, 01251], lr: 0.000549, loss: 0.4177
2022-10-02 00:37:33 - train: epoch 0230, iter [00850, 01251], lr: 0.000549, loss: 0.4004
2022-10-02 00:37:50 - train: epoch 0230, iter [00860, 01251], lr: 0.000549, loss: 0.3956
2022-10-02 00:38:08 - train: epoch 0230, iter [00870, 01251], lr: 0.000549, loss: 0.3991
2022-10-02 00:38:26 - train: epoch 0230, iter [00880, 01251], lr: 0.000549, loss: 0.4077
2022-10-02 00:38:43 - train: epoch 0230, iter [00890, 01251], lr: 0.000549, loss: 0.4036
2022-10-02 00:39:01 - train: epoch 0230, iter [00900, 01251], lr: 0.000549, loss: 0.4013
2022-10-02 00:39:19 - train: epoch 0230, iter [00910, 01251], lr: 0.000549, loss: 0.4121
2022-10-02 00:39:37 - train: epoch 0230, iter [00920, 01251], lr: 0.000549, loss: 0.4036
2022-10-02 00:39:54 - train: epoch 0230, iter [00930, 01251], lr: 0.000549, loss: 0.3899
2022-10-02 00:40:12 - train: epoch 0230, iter [00940, 01251], lr: 0.000549, loss: 0.4069
2022-10-02 00:40:30 - train: epoch 0230, iter [00950, 01251], lr: 0.000549, loss: 0.4092
2022-10-02 00:40:48 - train: epoch 0230, iter [00960, 01251], lr: 0.000549, loss: 0.4225
2022-10-02 00:41:06 - train: epoch 0230, iter [00970, 01251], lr: 0.000549, loss: 0.3876
2022-10-02 00:41:23 - train: epoch 0230, iter [00980, 01251], lr: 0.000549, loss: 0.4204
2022-10-02 00:41:41 - train: epoch 0230, iter [00990, 01251], lr: 0.000549, loss: 0.4152
2022-10-02 00:41:59 - train: epoch 0230, iter [01000, 01251], lr: 0.000549, loss: 0.4122
2022-10-02 00:42:17 - train: epoch 0230, iter [01010, 01251], lr: 0.000549, loss: 0.3961
2022-10-02 00:42:35 - train: epoch 0230, iter [01020, 01251], lr: 0.000549, loss: 0.4204
2022-10-02 00:42:52 - train: epoch 0230, iter [01030, 01251], lr: 0.000549, loss: 0.4102
2022-10-02 00:43:10 - train: epoch 0230, iter [01040, 01251], lr: 0.000549, loss: 0.4013
2022-10-02 00:43:28 - train: epoch 0230, iter [01050, 01251], lr: 0.000549, loss: 0.4016
2022-10-02 00:43:46 - train: epoch 0230, iter [01060, 01251], lr: 0.000549, loss: 0.4069
2022-10-02 00:44:03 - train: epoch 0230, iter [01070, 01251], lr: 0.000548, loss: 0.4053
2022-10-02 00:44:21 - train: epoch 0230, iter [01080, 01251], lr: 0.000548, loss: 0.4367
2022-10-02 00:44:39 - train: epoch 0230, iter [01090, 01251], lr: 0.000548, loss: 0.3960
2022-10-02 00:44:57 - train: epoch 0230, iter [01100, 01251], lr: 0.000548, loss: 0.4003
2022-10-02 00:45:14 - train: epoch 0230, iter [01110, 01251], lr: 0.000548, loss: 0.4088
2022-10-02 00:45:32 - train: epoch 0230, iter [01120, 01251], lr: 0.000548, loss: 0.4083
2022-10-02 00:45:50 - train: epoch 0230, iter [01130, 01251], lr: 0.000548, loss: 0.3918
2022-10-02 00:46:07 - train: epoch 0230, iter [01140, 01251], lr: 0.000548, loss: 0.4062
2022-10-02 00:46:25 - train: epoch 0230, iter [01150, 01251], lr: 0.000548, loss: 0.3939
2022-10-02 00:46:43 - train: epoch 0230, iter [01160, 01251], lr: 0.000548, loss: 0.4079
2022-10-02 00:47:01 - train: epoch 0230, iter [01170, 01251], lr: 0.000548, loss: 0.4196
2022-10-02 00:47:18 - train: epoch 0230, iter [01180, 01251], lr: 0.000548, loss: 0.4280
2022-10-02 00:47:36 - train: epoch 0230, iter [01190, 01251], lr: 0.000548, loss: 0.3862
2022-10-02 00:47:54 - train: epoch 0230, iter [01200, 01251], lr: 0.000548, loss: 0.4020
2022-10-02 00:48:11 - train: epoch 0230, iter [01210, 01251], lr: 0.000548, loss: 0.4240
2022-10-02 00:48:29 - train: epoch 0230, iter [01220, 01251], lr: 0.000548, loss: 0.4071
2022-10-02 00:48:47 - train: epoch 0230, iter [01230, 01251], lr: 0.000548, loss: 0.4024
2022-10-02 00:49:05 - train: epoch 0230, iter [01240, 01251], lr: 0.000548, loss: 0.4046
2022-10-02 00:49:22 - train: epoch 0230, iter [01250, 01251], lr: 0.000548, loss: 0.4071
2022-10-02 00:49:25 - train: epoch 230, train_loss: 0.4046
2022-10-02 00:49:28 - until epoch: 230, best_loss: 0.4046
2022-10-02 00:49:28 - epoch 231 lr: 0.000548
2022-10-02 00:49:53 - train: epoch 0231, iter [00010, 01251], lr: 0.000548, loss: 0.4021
2022-10-02 00:50:11 - train: epoch 0231, iter [00020, 01251], lr: 0.000548, loss: 0.4189
2022-10-02 00:50:29 - train: epoch 0231, iter [00030, 01251], lr: 0.000548, loss: 0.4091
2022-10-02 00:50:47 - train: epoch 0231, iter [00040, 01251], lr: 0.000548, loss: 0.4153
2022-10-02 00:51:05 - train: epoch 0231, iter [00050, 01251], lr: 0.000547, loss: 0.3936
2022-10-02 00:51:22 - train: epoch 0231, iter [00060, 01251], lr: 0.000547, loss: 0.4098
2022-10-02 00:51:40 - train: epoch 0231, iter [00070, 01251], lr: 0.000547, loss: 0.4038
2022-10-02 00:51:58 - train: epoch 0231, iter [00080, 01251], lr: 0.000547, loss: 0.4186
2022-10-02 00:52:16 - train: epoch 0231, iter [00090, 01251], lr: 0.000547, loss: 0.4243
2022-10-02 00:52:33 - train: epoch 0231, iter [00100, 01251], lr: 0.000547, loss: 0.3978
2022-10-02 00:52:51 - train: epoch 0231, iter [00110, 01251], lr: 0.000547, loss: 0.4127
2022-10-02 00:53:09 - train: epoch 0231, iter [00120, 01251], lr: 0.000547, loss: 0.3864
2022-10-02 00:53:27 - train: epoch 0231, iter [00130, 01251], lr: 0.000547, loss: 0.4149
2022-10-02 00:53:45 - train: epoch 0231, iter [00140, 01251], lr: 0.000547, loss: 0.3967
2022-10-02 00:54:03 - train: epoch 0231, iter [00150, 01251], lr: 0.000547, loss: 0.4139
2022-10-02 00:54:20 - train: epoch 0231, iter [00160, 01251], lr: 0.000547, loss: 0.3939
2022-10-02 00:54:38 - train: epoch 0231, iter [00170, 01251], lr: 0.000547, loss: 0.3880
2022-10-02 00:54:56 - train: epoch 0231, iter [00180, 01251], lr: 0.000547, loss: 0.4026
2022-10-02 00:55:14 - train: epoch 0231, iter [00190, 01251], lr: 0.000547, loss: 0.4058
2022-10-02 00:55:31 - train: epoch 0231, iter [00200, 01251], lr: 0.000547, loss: 0.4004
2022-10-02 00:55:49 - train: epoch 0231, iter [00210, 01251], lr: 0.000547, loss: 0.4081
2022-10-02 00:56:07 - train: epoch 0231, iter [00220, 01251], lr: 0.000547, loss: 0.3937
2022-10-02 00:56:25 - train: epoch 0231, iter [00230, 01251], lr: 0.000547, loss: 0.3993
2022-10-02 00:56:42 - train: epoch 0231, iter [00240, 01251], lr: 0.000547, loss: 0.4103
2022-10-02 00:57:00 - train: epoch 0231, iter [00250, 01251], lr: 0.000547, loss: 0.3995
2022-10-02 00:57:18 - train: epoch 0231, iter [00260, 01251], lr: 0.000547, loss: 0.4186
2022-10-02 00:57:36 - train: epoch 0231, iter [00270, 01251], lr: 0.000547, loss: 0.4187
2022-10-02 00:57:53 - train: epoch 0231, iter [00280, 01251], lr: 0.000547, loss: 0.4035
2022-10-02 00:58:11 - train: epoch 0231, iter [00290, 01251], lr: 0.000546, loss: 0.3904
2022-10-02 00:58:29 - train: epoch 0231, iter [00300, 01251], lr: 0.000546, loss: 0.4094
2022-10-02 00:58:47 - train: epoch 0231, iter [00310, 01251], lr: 0.000546, loss: 0.4226
2022-10-02 00:59:04 - train: epoch 0231, iter [00320, 01251], lr: 0.000546, loss: 0.4029
2022-10-02 00:59:22 - train: epoch 0231, iter [00330, 01251], lr: 0.000546, loss: 0.4016
2022-10-02 00:59:40 - train: epoch 0231, iter [00340, 01251], lr: 0.000546, loss: 0.4084
2022-10-02 00:59:58 - train: epoch 0231, iter [00350, 01251], lr: 0.000546, loss: 0.4028
2022-10-02 01:00:16 - train: epoch 0231, iter [00360, 01251], lr: 0.000546, loss: 0.4203
2022-10-02 01:00:33 - train: epoch 0231, iter [00370, 01251], lr: 0.000546, loss: 0.4060
2022-10-02 01:00:51 - train: epoch 0231, iter [00380, 01251], lr: 0.000546, loss: 0.3972
2022-10-02 01:01:09 - train: epoch 0231, iter [00390, 01251], lr: 0.000546, loss: 0.4111
2022-10-02 01:01:27 - train: epoch 0231, iter [00400, 01251], lr: 0.000546, loss: 0.4037
2022-10-02 01:01:45 - train: epoch 0231, iter [00410, 01251], lr: 0.000546, loss: 0.4097
2022-10-02 01:02:02 - train: epoch 0231, iter [00420, 01251], lr: 0.000546, loss: 0.4130
2022-10-02 01:02:20 - train: epoch 0231, iter [00430, 01251], lr: 0.000546, loss: 0.4119
2022-10-02 01:02:38 - train: epoch 0231, iter [00440, 01251], lr: 0.000546, loss: 0.4155
2022-10-02 01:02:56 - train: epoch 0231, iter [00450, 01251], lr: 0.000546, loss: 0.3983
2022-10-02 01:03:13 - train: epoch 0231, iter [00460, 01251], lr: 0.000546, loss: 0.4064
2022-10-02 01:03:31 - train: epoch 0231, iter [00470, 01251], lr: 0.000546, loss: 0.3940
2022-10-02 01:03:49 - train: epoch 0231, iter [00480, 01251], lr: 0.000546, loss: 0.3987
2022-10-02 01:04:07 - train: epoch 0231, iter [00490, 01251], lr: 0.000546, loss: 0.3967
2022-10-02 01:04:25 - train: epoch 0231, iter [00500, 01251], lr: 0.000546, loss: 0.4161
2022-10-02 01:04:42 - train: epoch 0231, iter [00510, 01251], lr: 0.000546, loss: 0.3806
2022-10-02 01:05:00 - train: epoch 0231, iter [00520, 01251], lr: 0.000546, loss: 0.4033
2022-10-02 01:05:18 - train: epoch 0231, iter [00530, 01251], lr: 0.000545, loss: 0.4001
2022-10-02 01:05:36 - train: epoch 0231, iter [00540, 01251], lr: 0.000545, loss: 0.3970
2022-10-02 01:05:54 - train: epoch 0231, iter [00550, 01251], lr: 0.000545, loss: 0.3990
2022-10-02 01:06:11 - train: epoch 0231, iter [00560, 01251], lr: 0.000545, loss: 0.3957
2022-10-02 01:06:29 - train: epoch 0231, iter [00570, 01251], lr: 0.000545, loss: 0.4138
2022-10-02 01:06:47 - train: epoch 0231, iter [00580, 01251], lr: 0.000545, loss: 0.4197
2022-10-02 01:07:05 - train: epoch 0231, iter [00590, 01251], lr: 0.000545, loss: 0.4042
2022-10-02 01:07:23 - train: epoch 0231, iter [00600, 01251], lr: 0.000545, loss: 0.4059
2022-10-02 01:07:40 - train: epoch 0231, iter [00610, 01251], lr: 0.000545, loss: 0.4013
2022-10-02 01:07:58 - train: epoch 0231, iter [00620, 01251], lr: 0.000545, loss: 0.4089
2022-10-02 01:08:16 - train: epoch 0231, iter [00630, 01251], lr: 0.000545, loss: 0.4126
2022-10-02 01:08:34 - train: epoch 0231, iter [00640, 01251], lr: 0.000545, loss: 0.4057
2022-10-02 01:08:52 - train: epoch 0231, iter [00650, 01251], lr: 0.000545, loss: 0.4012
2022-10-02 01:09:10 - train: epoch 0231, iter [00660, 01251], lr: 0.000545, loss: 0.3962
2022-10-02 01:09:27 - train: epoch 0231, iter [00670, 01251], lr: 0.000545, loss: 0.4041
2022-10-02 01:09:45 - train: epoch 0231, iter [00680, 01251], lr: 0.000545, loss: 0.3817
2022-10-02 01:10:03 - train: epoch 0231, iter [00690, 01251], lr: 0.000545, loss: 0.4121
2022-10-02 01:10:21 - train: epoch 0231, iter [00700, 01251], lr: 0.000545, loss: 0.4241
2022-10-02 01:10:39 - train: epoch 0231, iter [00710, 01251], lr: 0.000545, loss: 0.4230
2022-10-02 01:10:57 - train: epoch 0231, iter [00720, 01251], lr: 0.000545, loss: 0.4266
2022-10-02 01:11:14 - train: epoch 0231, iter [00730, 01251], lr: 0.000545, loss: 0.4003
2022-10-02 01:11:32 - train: epoch 0231, iter [00740, 01251], lr: 0.000545, loss: 0.3964
2022-10-02 01:11:50 - train: epoch 0231, iter [00750, 01251], lr: 0.000545, loss: 0.3982
2022-10-02 01:12:08 - train: epoch 0231, iter [00760, 01251], lr: 0.000545, loss: 0.4071
2022-10-02 01:12:26 - train: epoch 0231, iter [00770, 01251], lr: 0.000544, loss: 0.4050
2022-10-02 01:12:43 - train: epoch 0231, iter [00780, 01251], lr: 0.000544, loss: 0.3935
2022-10-02 01:13:01 - train: epoch 0231, iter [00790, 01251], lr: 0.000544, loss: 0.4020
2022-10-02 01:13:19 - train: epoch 0231, iter [00800, 01251], lr: 0.000544, loss: 0.4155
2022-10-02 01:13:37 - train: epoch 0231, iter [00810, 01251], lr: 0.000544, loss: 0.3908
2022-10-02 01:13:54 - train: epoch 0231, iter [00820, 01251], lr: 0.000544, loss: 0.4151
2022-10-02 01:14:12 - train: epoch 0231, iter [00830, 01251], lr: 0.000544, loss: 0.3865
2022-10-02 01:14:30 - train: epoch 0231, iter [00840, 01251], lr: 0.000544, loss: 0.3979
2022-10-02 01:14:48 - train: epoch 0231, iter [00850, 01251], lr: 0.000544, loss: 0.4019
2022-10-02 01:15:05 - train: epoch 0231, iter [00860, 01251], lr: 0.000544, loss: 0.4270
2022-10-02 01:15:23 - train: epoch 0231, iter [00870, 01251], lr: 0.000544, loss: 0.4102
2022-10-02 01:15:41 - train: epoch 0231, iter [00880, 01251], lr: 0.000544, loss: 0.4343
2022-10-02 01:15:59 - train: epoch 0231, iter [00890, 01251], lr: 0.000544, loss: 0.4043
2022-10-02 01:16:17 - train: epoch 0231, iter [00900, 01251], lr: 0.000544, loss: 0.4034
2022-10-02 01:16:34 - train: epoch 0231, iter [00910, 01251], lr: 0.000544, loss: 0.4096
2022-10-02 01:16:52 - train: epoch 0231, iter [00920, 01251], lr: 0.000544, loss: 0.3878
2022-10-02 01:17:10 - train: epoch 0231, iter [00930, 01251], lr: 0.000544, loss: 0.4128
2022-10-02 01:17:28 - train: epoch 0231, iter [00940, 01251], lr: 0.000544, loss: 0.4169
2022-10-02 01:17:45 - train: epoch 0231, iter [00950, 01251], lr: 0.000544, loss: 0.4084
2022-10-02 01:18:03 - train: epoch 0231, iter [00960, 01251], lr: 0.000544, loss: 0.4119
2022-10-02 01:18:21 - train: epoch 0231, iter [00970, 01251], lr: 0.000544, loss: 0.3896
2022-10-02 01:18:39 - train: epoch 0231, iter [00980, 01251], lr: 0.000544, loss: 0.4087
2022-10-02 01:18:57 - train: epoch 0231, iter [00990, 01251], lr: 0.000544, loss: 0.4019
2022-10-02 01:19:15 - train: epoch 0231, iter [01000, 01251], lr: 0.000544, loss: 0.3909
2022-10-02 01:19:33 - train: epoch 0231, iter [01010, 01251], lr: 0.000543, loss: 0.3925
2022-10-02 01:19:50 - train: epoch 0231, iter [01020, 01251], lr: 0.000543, loss: 0.4297
2022-10-02 01:20:08 - train: epoch 0231, iter [01030, 01251], lr: 0.000543, loss: 0.4088
2022-10-02 01:20:26 - train: epoch 0231, iter [01040, 01251], lr: 0.000543, loss: 0.3975
2022-10-02 01:20:44 - train: epoch 0231, iter [01050, 01251], lr: 0.000543, loss: 0.3744
2022-10-02 01:21:02 - train: epoch 0231, iter [01060, 01251], lr: 0.000543, loss: 0.4103
2022-10-02 01:21:19 - train: epoch 0231, iter [01070, 01251], lr: 0.000543, loss: 0.4002
2022-10-02 01:21:37 - train: epoch 0231, iter [01080, 01251], lr: 0.000543, loss: 0.4022
2022-10-02 01:21:55 - train: epoch 0231, iter [01090, 01251], lr: 0.000543, loss: 0.4027
2022-10-02 01:22:13 - train: epoch 0231, iter [01100, 01251], lr: 0.000543, loss: 0.4120
2022-10-02 01:22:30 - train: epoch 0231, iter [01110, 01251], lr: 0.000543, loss: 0.4223
2022-10-02 01:22:48 - train: epoch 0231, iter [01120, 01251], lr: 0.000543, loss: 0.3825
2022-10-02 01:23:06 - train: epoch 0231, iter [01130, 01251], lr: 0.000543, loss: 0.3971
2022-10-02 01:23:24 - train: epoch 0231, iter [01140, 01251], lr: 0.000543, loss: 0.4035
2022-10-02 01:23:42 - train: epoch 0231, iter [01150, 01251], lr: 0.000543, loss: 0.4127
2022-10-02 01:24:00 - train: epoch 0231, iter [01160, 01251], lr: 0.000543, loss: 0.4001
2022-10-02 01:24:17 - train: epoch 0231, iter [01170, 01251], lr: 0.000543, loss: 0.3985
2022-10-02 01:24:35 - train: epoch 0231, iter [01180, 01251], lr: 0.000543, loss: 0.3747
2022-10-02 01:24:52 - train: epoch 0231, iter [01190, 01251], lr: 0.000543, loss: 0.4053
2022-10-02 01:25:10 - train: epoch 0231, iter [01200, 01251], lr: 0.000543, loss: 0.4153
2022-10-02 01:25:28 - train: epoch 0231, iter [01210, 01251], lr: 0.000543, loss: 0.4124
2022-10-02 01:25:46 - train: epoch 0231, iter [01220, 01251], lr: 0.000543, loss: 0.4083
2022-10-02 01:26:03 - train: epoch 0231, iter [01230, 01251], lr: 0.000543, loss: 0.4129
2022-10-02 01:26:21 - train: epoch 0231, iter [01240, 01251], lr: 0.000543, loss: 0.3988
2022-10-02 01:26:39 - train: epoch 0231, iter [01250, 01251], lr: 0.000542, loss: 0.4255
2022-10-02 01:26:42 - train: epoch 231, train_loss: 0.4046
2022-10-02 01:26:43 - until epoch: 231, best_loss: 0.4046
2022-10-02 01:26:43 - epoch 232 lr: 0.000542
2022-10-02 01:27:11 - train: epoch 0232, iter [00010, 01251], lr: 0.000542, loss: 0.4215
2022-10-02 01:27:29 - train: epoch 0232, iter [00020, 01251], lr: 0.000542, loss: 0.4157
2022-10-02 01:27:47 - train: epoch 0232, iter [00030, 01251], lr: 0.000542, loss: 0.3971
2022-10-02 01:28:05 - train: epoch 0232, iter [00040, 01251], lr: 0.000542, loss: 0.3991
2022-10-02 01:28:23 - train: epoch 0232, iter [00050, 01251], lr: 0.000542, loss: 0.4038
2022-10-02 01:28:41 - train: epoch 0232, iter [00060, 01251], lr: 0.000542, loss: 0.4010
2022-10-02 01:28:59 - train: epoch 0232, iter [00070, 01251], lr: 0.000542, loss: 0.3899
2022-10-02 01:29:17 - train: epoch 0232, iter [00080, 01251], lr: 0.000542, loss: 0.4215
2022-10-02 01:29:35 - train: epoch 0232, iter [00090, 01251], lr: 0.000542, loss: 0.4184
2022-10-02 01:29:53 - train: epoch 0232, iter [00100, 01251], lr: 0.000542, loss: 0.4049
2022-10-02 01:30:11 - train: epoch 0232, iter [00110, 01251], lr: 0.000542, loss: 0.3886
2022-10-02 01:30:28 - train: epoch 0232, iter [00120, 01251], lr: 0.000542, loss: 0.4075
2022-10-02 01:30:46 - train: epoch 0232, iter [00130, 01251], lr: 0.000542, loss: 0.3993
2022-10-02 01:31:04 - train: epoch 0232, iter [00140, 01251], lr: 0.000542, loss: 0.4056
2022-10-02 01:31:22 - train: epoch 0232, iter [00150, 01251], lr: 0.000542, loss: 0.4308
2022-10-02 01:31:40 - train: epoch 0232, iter [00160, 01251], lr: 0.000542, loss: 0.3853
2022-10-02 01:31:57 - train: epoch 0232, iter [00170, 01251], lr: 0.000542, loss: 0.4046
2022-10-02 01:32:15 - train: epoch 0232, iter [00180, 01251], lr: 0.000542, loss: 0.3947
2022-10-02 01:32:33 - train: epoch 0232, iter [00190, 01251], lr: 0.000542, loss: 0.4052
2022-10-02 01:32:51 - train: epoch 0232, iter [00200, 01251], lr: 0.000542, loss: 0.4104
2022-10-02 01:33:09 - train: epoch 0232, iter [00210, 01251], lr: 0.000542, loss: 0.3983
2022-10-02 01:33:27 - train: epoch 0232, iter [00220, 01251], lr: 0.000542, loss: 0.4113
2022-10-02 01:33:45 - train: epoch 0232, iter [00230, 01251], lr: 0.000542, loss: 0.4143
2022-10-02 01:34:03 - train: epoch 0232, iter [00240, 01251], lr: 0.000541, loss: 0.4319
2022-10-02 01:34:20 - train: epoch 0232, iter [00250, 01251], lr: 0.000541, loss: 0.4016
2022-10-02 01:34:38 - train: epoch 0232, iter [00260, 01251], lr: 0.000541, loss: 0.4105
2022-10-02 01:34:56 - train: epoch 0232, iter [00270, 01251], lr: 0.000541, loss: 0.4259
2022-10-02 01:35:14 - train: epoch 0232, iter [00280, 01251], lr: 0.000541, loss: 0.4058
2022-10-02 01:35:32 - train: epoch 0232, iter [00290, 01251], lr: 0.000541, loss: 0.4045
2022-10-02 01:35:50 - train: epoch 0232, iter [00300, 01251], lr: 0.000541, loss: 0.4205
2022-10-02 01:36:08 - train: epoch 0232, iter [00310, 01251], lr: 0.000541, loss: 0.3922
2022-10-02 01:36:25 - train: epoch 0232, iter [00320, 01251], lr: 0.000541, loss: 0.4189
2022-10-02 01:36:43 - train: epoch 0232, iter [00330, 01251], lr: 0.000541, loss: 0.4275
2022-10-02 01:37:01 - train: epoch 0232, iter [00340, 01251], lr: 0.000541, loss: 0.4082
2022-10-02 01:37:19 - train: epoch 0232, iter [00350, 01251], lr: 0.000541, loss: 0.4177
2022-10-02 01:37:37 - train: epoch 0232, iter [00360, 01251], lr: 0.000541, loss: 0.4263
2022-10-02 01:37:54 - train: epoch 0232, iter [00370, 01251], lr: 0.000541, loss: 0.4254
2022-10-02 01:38:12 - train: epoch 0232, iter [00380, 01251], lr: 0.000541, loss: 0.3938
2022-10-02 01:38:30 - train: epoch 0232, iter [00390, 01251], lr: 0.000541, loss: 0.4079
2022-10-02 01:38:48 - train: epoch 0232, iter [00400, 01251], lr: 0.000541, loss: 0.4129
2022-10-02 01:39:06 - train: epoch 0232, iter [00410, 01251], lr: 0.000541, loss: 0.3890
2022-10-02 01:39:23 - train: epoch 0232, iter [00420, 01251], lr: 0.000541, loss: 0.3847
2022-10-02 01:39:41 - train: epoch 0232, iter [00430, 01251], lr: 0.000541, loss: 0.4061
2022-10-02 01:39:59 - train: epoch 0232, iter [00440, 01251], lr: 0.000541, loss: 0.3980
2022-10-02 01:40:17 - train: epoch 0232, iter [00450, 01251], lr: 0.000541, loss: 0.3937
2022-10-02 01:40:35 - train: epoch 0232, iter [00460, 01251], lr: 0.000541, loss: 0.3956
2022-10-02 01:40:53 - train: epoch 0232, iter [00470, 01251], lr: 0.000541, loss: 0.4010
2022-10-02 01:41:10 - train: epoch 0232, iter [00480, 01251], lr: 0.000540, loss: 0.3891
2022-10-02 01:41:28 - train: epoch 0232, iter [00490, 01251], lr: 0.000540, loss: 0.4049
2022-10-02 01:41:46 - train: epoch 0232, iter [00500, 01251], lr: 0.000540, loss: 0.3936
2022-10-02 01:42:04 - train: epoch 0232, iter [00510, 01251], lr: 0.000540, loss: 0.3920
2022-10-02 01:42:21 - train: epoch 0232, iter [00520, 01251], lr: 0.000540, loss: 0.3959
2022-10-02 01:42:39 - train: epoch 0232, iter [00530, 01251], lr: 0.000540, loss: 0.4039
2022-10-02 01:42:57 - train: epoch 0232, iter [00540, 01251], lr: 0.000540, loss: 0.4058
2022-10-02 01:43:15 - train: epoch 0232, iter [00550, 01251], lr: 0.000540, loss: 0.3966
2022-10-02 01:43:33 - train: epoch 0232, iter [00560, 01251], lr: 0.000540, loss: 0.4037
2022-10-02 01:43:50 - train: epoch 0232, iter [00570, 01251], lr: 0.000540, loss: 0.4007
2022-10-02 01:44:08 - train: epoch 0232, iter [00580, 01251], lr: 0.000540, loss: 0.3969
2022-10-02 01:44:26 - train: epoch 0232, iter [00590, 01251], lr: 0.000540, loss: 0.4084
2022-10-02 01:44:44 - train: epoch 0232, iter [00600, 01251], lr: 0.000540, loss: 0.3927
2022-10-02 01:45:02 - train: epoch 0232, iter [00610, 01251], lr: 0.000540, loss: 0.4059
2022-10-02 01:45:20 - train: epoch 0232, iter [00620, 01251], lr: 0.000540, loss: 0.4129
2022-10-02 01:45:38 - train: epoch 0232, iter [00630, 01251], lr: 0.000540, loss: 0.4152
2022-10-02 01:45:56 - train: epoch 0232, iter [00640, 01251], lr: 0.000540, loss: 0.4163
2022-10-02 01:46:13 - train: epoch 0232, iter [00650, 01251], lr: 0.000540, loss: 0.4046
2022-10-02 01:46:31 - train: epoch 0232, iter [00660, 01251], lr: 0.000540, loss: 0.4103
2022-10-02 01:46:49 - train: epoch 0232, iter [00670, 01251], lr: 0.000540, loss: 0.4181
2022-10-02 01:47:07 - train: epoch 0232, iter [00680, 01251], lr: 0.000540, loss: 0.3845
2022-10-02 01:47:25 - train: epoch 0232, iter [00690, 01251], lr: 0.000540, loss: 0.4230
2022-10-02 01:47:42 - train: epoch 0232, iter [00700, 01251], lr: 0.000540, loss: 0.4032
2022-10-02 01:48:00 - train: epoch 0232, iter [00710, 01251], lr: 0.000540, loss: 0.4040
2022-10-02 01:48:18 - train: epoch 0232, iter [00720, 01251], lr: 0.000539, loss: 0.4059
2022-10-02 01:48:35 - train: epoch 0232, iter [00730, 01251], lr: 0.000539, loss: 0.4025
2022-10-02 01:48:53 - train: epoch 0232, iter [00740, 01251], lr: 0.000539, loss: 0.3975
2022-10-02 01:49:11 - train: epoch 0232, iter [00750, 01251], lr: 0.000539, loss: 0.4122
2022-10-02 01:49:29 - train: epoch 0232, iter [00760, 01251], lr: 0.000539, loss: 0.3903
2022-10-02 01:49:46 - train: epoch 0232, iter [00770, 01251], lr: 0.000539, loss: 0.4102
2022-10-02 01:50:04 - train: epoch 0232, iter [00780, 01251], lr: 0.000539, loss: 0.4061
2022-10-02 01:50:22 - train: epoch 0232, iter [00790, 01251], lr: 0.000539, loss: 0.4238
2022-10-02 01:50:40 - train: epoch 0232, iter [00800, 01251], lr: 0.000539, loss: 0.4219
2022-10-02 01:50:57 - train: epoch 0232, iter [00810, 01251], lr: 0.000539, loss: 0.4049
2022-10-02 01:51:15 - train: epoch 0232, iter [00820, 01251], lr: 0.000539, loss: 0.4054
2022-10-02 01:51:33 - train: epoch 0232, iter [00830, 01251], lr: 0.000539, loss: 0.3946
2022-10-02 01:51:51 - train: epoch 0232, iter [00840, 01251], lr: 0.000539, loss: 0.4041
2022-10-02 01:52:08 - train: epoch 0232, iter [00850, 01251], lr: 0.000539, loss: 0.3936
2022-10-02 01:52:26 - train: epoch 0232, iter [00860, 01251], lr: 0.000539, loss: 0.4089
2022-10-02 01:52:44 - train: epoch 0232, iter [00870, 01251], lr: 0.000539, loss: 0.3927
2022-10-02 01:53:02 - train: epoch 0232, iter [00880, 01251], lr: 0.000539, loss: 0.4017
2022-10-02 01:53:19 - train: epoch 0232, iter [00890, 01251], lr: 0.000539, loss: 0.3958
2022-10-02 01:53:37 - train: epoch 0232, iter [00900, 01251], lr: 0.000539, loss: 0.3954
2022-10-02 01:53:55 - train: epoch 0232, iter [00910, 01251], lr: 0.000539, loss: 0.4315
2022-10-02 01:54:13 - train: epoch 0232, iter [00920, 01251], lr: 0.000539, loss: 0.4029
2022-10-02 01:54:30 - train: epoch 0232, iter [00930, 01251], lr: 0.000539, loss: 0.4213
2022-10-02 01:54:48 - train: epoch 0232, iter [00940, 01251], lr: 0.000539, loss: 0.4010
2022-10-02 01:55:06 - train: epoch 0232, iter [00950, 01251], lr: 0.000539, loss: 0.4259
2022-10-02 01:55:24 - train: epoch 0232, iter [00960, 01251], lr: 0.000538, loss: 0.3817
2022-10-02 01:55:41 - train: epoch 0232, iter [00970, 01251], lr: 0.000538, loss: 0.4062
2022-10-02 01:55:59 - train: epoch 0232, iter [00980, 01251], lr: 0.000538, loss: 0.4171
2022-10-02 01:56:17 - train: epoch 0232, iter [00990, 01251], lr: 0.000538, loss: 0.3940
2022-10-02 01:56:35 - train: epoch 0232, iter [01000, 01251], lr: 0.000538, loss: 0.4030
2022-10-02 01:56:52 - train: epoch 0232, iter [01010, 01251], lr: 0.000538, loss: 0.4019
2022-10-02 01:57:10 - train: epoch 0232, iter [01020, 01251], lr: 0.000538, loss: 0.4144
2022-10-02 01:57:28 - train: epoch 0232, iter [01030, 01251], lr: 0.000538, loss: 0.4198
2022-10-02 01:57:46 - train: epoch 0232, iter [01040, 01251], lr: 0.000538, loss: 0.4140
2022-10-02 01:58:03 - train: epoch 0232, iter [01050, 01251], lr: 0.000538, loss: 0.4150
2022-10-02 01:58:21 - train: epoch 0232, iter [01060, 01251], lr: 0.000538, loss: 0.3775
2022-10-02 01:58:39 - train: epoch 0232, iter [01070, 01251], lr: 0.000538, loss: 0.4162
2022-10-02 01:58:56 - train: epoch 0232, iter [01080, 01251], lr: 0.000538, loss: 0.4134
2022-10-02 01:59:14 - train: epoch 0232, iter [01090, 01251], lr: 0.000538, loss: 0.4189
2022-10-02 01:59:32 - train: epoch 0232, iter [01100, 01251], lr: 0.000538, loss: 0.4102
2022-10-02 01:59:50 - train: epoch 0232, iter [01110, 01251], lr: 0.000538, loss: 0.4087
2022-10-02 02:00:07 - train: epoch 0232, iter [01120, 01251], lr: 0.000538, loss: 0.4199
2022-10-02 02:00:25 - train: epoch 0232, iter [01130, 01251], lr: 0.000538, loss: 0.3869
2022-10-02 02:00:43 - train: epoch 0232, iter [01140, 01251], lr: 0.000538, loss: 0.4121
2022-10-02 02:01:01 - train: epoch 0232, iter [01150, 01251], lr: 0.000538, loss: 0.4025
2022-10-02 02:01:19 - train: epoch 0232, iter [01160, 01251], lr: 0.000538, loss: 0.4118
2022-10-02 02:01:36 - train: epoch 0232, iter [01170, 01251], lr: 0.000538, loss: 0.4123
2022-10-02 02:01:54 - train: epoch 0232, iter [01180, 01251], lr: 0.000538, loss: 0.3924
2022-10-02 02:02:12 - train: epoch 0232, iter [01190, 01251], lr: 0.000538, loss: 0.3845
2022-10-02 02:02:30 - train: epoch 0232, iter [01200, 01251], lr: 0.000537, loss: 0.3997
2022-10-02 02:02:47 - train: epoch 0232, iter [01210, 01251], lr: 0.000537, loss: 0.3928
2022-10-02 02:03:05 - train: epoch 0232, iter [01220, 01251], lr: 0.000537, loss: 0.4087
2022-10-02 02:03:23 - train: epoch 0232, iter [01230, 01251], lr: 0.000537, loss: 0.4173
2022-10-02 02:03:41 - train: epoch 0232, iter [01240, 01251], lr: 0.000537, loss: 0.4013
2022-10-02 02:03:58 - train: epoch 0232, iter [01250, 01251], lr: 0.000537, loss: 0.3812
2022-10-02 02:04:01 - train: epoch 232, train_loss: 0.4044
2022-10-02 02:04:04 - until epoch: 232, best_loss: 0.4044
2022-10-02 02:04:04 - epoch 233 lr: 0.000537
2022-10-02 02:04:29 - train: epoch 0233, iter [00010, 01251], lr: 0.000537, loss: 0.4106
2022-10-02 02:04:47 - train: epoch 0233, iter [00020, 01251], lr: 0.000537, loss: 0.4036
2022-10-02 02:05:05 - train: epoch 0233, iter [00030, 01251], lr: 0.000537, loss: 0.4041
2022-10-02 02:05:23 - train: epoch 0233, iter [00040, 01251], lr: 0.000537, loss: 0.4141
2022-10-02 02:05:41 - train: epoch 0233, iter [00050, 01251], lr: 0.000537, loss: 0.3907
2022-10-02 02:05:58 - train: epoch 0233, iter [00060, 01251], lr: 0.000537, loss: 0.4232
2022-10-02 02:06:16 - train: epoch 0233, iter [00070, 01251], lr: 0.000537, loss: 0.4015
2022-10-02 02:06:34 - train: epoch 0233, iter [00080, 01251], lr: 0.000537, loss: 0.4101
2022-10-02 02:06:52 - train: epoch 0233, iter [00090, 01251], lr: 0.000537, loss: 0.3920
2022-10-02 02:07:10 - train: epoch 0233, iter [00100, 01251], lr: 0.000537, loss: 0.3965
2022-10-02 02:07:27 - train: epoch 0233, iter [00110, 01251], lr: 0.000537, loss: 0.4105
2022-10-02 02:07:45 - train: epoch 0233, iter [00120, 01251], lr: 0.000537, loss: 0.4038
2022-10-02 02:08:03 - train: epoch 0233, iter [00130, 01251], lr: 0.000537, loss: 0.4032
2022-10-02 02:08:20 - train: epoch 0233, iter [00140, 01251], lr: 0.000537, loss: 0.4136
2022-10-02 02:08:38 - train: epoch 0233, iter [00150, 01251], lr: 0.000537, loss: 0.4336
2022-10-02 02:08:56 - train: epoch 0233, iter [00160, 01251], lr: 0.000537, loss: 0.3952
2022-10-02 02:09:14 - train: epoch 0233, iter [00170, 01251], lr: 0.000537, loss: 0.4116
2022-10-02 02:09:31 - train: epoch 0233, iter [00180, 01251], lr: 0.000537, loss: 0.4055
2022-10-02 02:09:49 - train: epoch 0233, iter [00190, 01251], lr: 0.000536, loss: 0.3910
2022-10-02 02:10:07 - train: epoch 0233, iter [00200, 01251], lr: 0.000536, loss: 0.4143
2022-10-02 02:10:24 - train: epoch 0233, iter [00210, 01251], lr: 0.000536, loss: 0.3942
2022-10-02 02:10:42 - train: epoch 0233, iter [00220, 01251], lr: 0.000536, loss: 0.3944
2022-10-02 02:11:00 - train: epoch 0233, iter [00230, 01251], lr: 0.000536, loss: 0.4223
2022-10-02 02:11:18 - train: epoch 0233, iter [00240, 01251], lr: 0.000536, loss: 0.3903
2022-10-02 02:11:35 - train: epoch 0233, iter [00250, 01251], lr: 0.000536, loss: 0.4130
2022-10-02 02:11:53 - train: epoch 0233, iter [00260, 01251], lr: 0.000536, loss: 0.3988
2022-10-02 02:12:10 - train: epoch 0233, iter [00270, 01251], lr: 0.000536, loss: 0.4069
2022-10-02 02:12:28 - train: epoch 0233, iter [00280, 01251], lr: 0.000536, loss: 0.4066
2022-10-02 02:12:46 - train: epoch 0233, iter [00290, 01251], lr: 0.000536, loss: 0.3827
2022-10-02 02:13:03 - train: epoch 0233, iter [00300, 01251], lr: 0.000536, loss: 0.4208
2022-10-02 02:13:21 - train: epoch 0233, iter [00310, 01251], lr: 0.000536, loss: 0.3977
2022-10-02 02:13:38 - train: epoch 0233, iter [00320, 01251], lr: 0.000536, loss: 0.4106
2022-10-02 02:13:56 - train: epoch 0233, iter [00330, 01251], lr: 0.000536, loss: 0.4142
2022-10-02 02:14:14 - train: epoch 0233, iter [00340, 01251], lr: 0.000536, loss: 0.4085
2022-10-02 02:14:32 - train: epoch 0233, iter [00350, 01251], lr: 0.000536, loss: 0.4012
2022-10-02 02:14:49 - train: epoch 0233, iter [00360, 01251], lr: 0.000536, loss: 0.3924
2022-10-02 02:15:07 - train: epoch 0233, iter [00370, 01251], lr: 0.000536, loss: 0.3943
2022-10-02 02:15:25 - train: epoch 0233, iter [00380, 01251], lr: 0.000536, loss: 0.4165
2022-10-02 02:15:43 - train: epoch 0233, iter [00390, 01251], lr: 0.000536, loss: 0.4109
2022-10-02 02:16:01 - train: epoch 0233, iter [00400, 01251], lr: 0.000536, loss: 0.4224
2022-10-02 02:16:18 - train: epoch 0233, iter [00410, 01251], lr: 0.000536, loss: 0.4161
2022-10-02 02:16:36 - train: epoch 0233, iter [00420, 01251], lr: 0.000536, loss: 0.4009
2022-10-02 02:16:54 - train: epoch 0233, iter [00430, 01251], lr: 0.000535, loss: 0.3939
2022-10-02 02:17:12 - train: epoch 0233, iter [00440, 01251], lr: 0.000535, loss: 0.3987
2022-10-02 02:17:30 - train: epoch 0233, iter [00450, 01251], lr: 0.000535, loss: 0.4157
2022-10-02 02:17:47 - train: epoch 0233, iter [00460, 01251], lr: 0.000535, loss: 0.3849
2022-10-02 02:18:05 - train: epoch 0233, iter [00470, 01251], lr: 0.000535, loss: 0.4147
2022-10-02 02:18:23 - train: epoch 0233, iter [00480, 01251], lr: 0.000535, loss: 0.4168
2022-10-02 02:18:41 - train: epoch 0233, iter [00490, 01251], lr: 0.000535, loss: 0.3873
2022-10-02 02:18:59 - train: epoch 0233, iter [00500, 01251], lr: 0.000535, loss: 0.4048
2022-10-02 02:19:16 - train: epoch 0233, iter [00510, 01251], lr: 0.000535, loss: 0.3955
2022-10-02 02:19:34 - train: epoch 0233, iter [00520, 01251], lr: 0.000535, loss: 0.4135
2022-10-02 02:19:51 - train: epoch 0233, iter [00530, 01251], lr: 0.000535, loss: 0.4021
2022-10-02 02:20:09 - train: epoch 0233, iter [00540, 01251], lr: 0.000535, loss: 0.3853
2022-10-02 02:20:27 - train: epoch 0233, iter [00550, 01251], lr: 0.000535, loss: 0.4054
2022-10-02 02:20:44 - train: epoch 0233, iter [00560, 01251], lr: 0.000535, loss: 0.4175
2022-10-02 02:21:02 - train: epoch 0233, iter [00570, 01251], lr: 0.000535, loss: 0.3994
2022-10-02 02:21:20 - train: epoch 0233, iter [00580, 01251], lr: 0.000535, loss: 0.4045
2022-10-02 02:21:38 - train: epoch 0233, iter [00590, 01251], lr: 0.000535, loss: 0.4009
2022-10-02 02:21:56 - train: epoch 0233, iter [00600, 01251], lr: 0.000535, loss: 0.4087
2022-10-02 02:22:14 - train: epoch 0233, iter [00610, 01251], lr: 0.000535, loss: 0.3938
2022-10-02 02:22:31 - train: epoch 0233, iter [00620, 01251], lr: 0.000535, loss: 0.4098
2022-10-02 02:22:49 - train: epoch 0233, iter [00630, 01251], lr: 0.000535, loss: 0.3812
2022-10-02 02:23:07 - train: epoch 0233, iter [00640, 01251], lr: 0.000535, loss: 0.3945
2022-10-02 02:23:25 - train: epoch 0233, iter [00650, 01251], lr: 0.000535, loss: 0.3881
2022-10-02 02:23:42 - train: epoch 0233, iter [00660, 01251], lr: 0.000535, loss: 0.4077
2022-10-02 02:24:00 - train: epoch 0233, iter [00670, 01251], lr: 0.000534, loss: 0.3882
2022-10-02 02:24:18 - train: epoch 0233, iter [00680, 01251], lr: 0.000534, loss: 0.4024
2022-10-02 02:24:36 - train: epoch 0233, iter [00690, 01251], lr: 0.000534, loss: 0.4157
2022-10-02 02:24:53 - train: epoch 0233, iter [00700, 01251], lr: 0.000534, loss: 0.4077
2022-10-02 02:25:11 - train: epoch 0233, iter [00710, 01251], lr: 0.000534, loss: 0.3954
2022-10-02 02:25:29 - train: epoch 0233, iter [00720, 01251], lr: 0.000534, loss: 0.4081
2022-10-02 02:25:47 - train: epoch 0233, iter [00730, 01251], lr: 0.000534, loss: 0.4053
2022-10-02 02:26:04 - train: epoch 0233, iter [00740, 01251], lr: 0.000534, loss: 0.4044
2022-10-02 02:26:22 - train: epoch 0233, iter [00750, 01251], lr: 0.000534, loss: 0.4276
2022-10-02 02:26:40 - train: epoch 0233, iter [00760, 01251], lr: 0.000534, loss: 0.4208
2022-10-02 02:26:58 - train: epoch 0233, iter [00770, 01251], lr: 0.000534, loss: 0.3960
2022-10-02 02:27:15 - train: epoch 0233, iter [00780, 01251], lr: 0.000534, loss: 0.4003
2022-10-02 02:27:33 - train: epoch 0233, iter [00790, 01251], lr: 0.000534, loss: 0.4051
2022-10-02 02:27:51 - train: epoch 0233, iter [00800, 01251], lr: 0.000534, loss: 0.4097
2022-10-02 02:28:08 - train: epoch 0233, iter [00810, 01251], lr: 0.000534, loss: 0.3834
2022-10-02 02:28:26 - train: epoch 0233, iter [00820, 01251], lr: 0.000534, loss: 0.4065
2022-10-02 02:28:44 - train: epoch 0233, iter [00830, 01251], lr: 0.000534, loss: 0.4085
2022-10-02 02:29:02 - train: epoch 0233, iter [00840, 01251], lr: 0.000534, loss: 0.4096
2022-10-02 02:29:19 - train: epoch 0233, iter [00850, 01251], lr: 0.000534, loss: 0.4008
2022-10-02 02:29:37 - train: epoch 0233, iter [00860, 01251], lr: 0.000534, loss: 0.4243
2022-10-02 02:29:55 - train: epoch 0233, iter [00870, 01251], lr: 0.000534, loss: 0.4134
2022-10-02 02:30:13 - train: epoch 0233, iter [00880, 01251], lr: 0.000534, loss: 0.4083
2022-10-02 02:30:30 - train: epoch 0233, iter [00890, 01251], lr: 0.000534, loss: 0.4070
2022-10-02 02:30:48 - train: epoch 0233, iter [00900, 01251], lr: 0.000534, loss: 0.4008
2022-10-02 02:31:06 - train: epoch 0233, iter [00910, 01251], lr: 0.000533, loss: 0.3930
2022-10-02 02:31:23 - train: epoch 0233, iter [00920, 01251], lr: 0.000533, loss: 0.3945
2022-10-02 02:31:41 - train: epoch 0233, iter [00930, 01251], lr: 0.000533, loss: 0.4032
2022-10-02 02:31:59 - train: epoch 0233, iter [00940, 01251], lr: 0.000533, loss: 0.4038
2022-10-02 02:32:17 - train: epoch 0233, iter [00950, 01251], lr: 0.000533, loss: 0.3999
2022-10-02 02:32:35 - train: epoch 0233, iter [00960, 01251], lr: 0.000533, loss: 0.3951
2022-10-02 02:32:52 - train: epoch 0233, iter [00970, 01251], lr: 0.000533, loss: 0.4046
2022-10-02 02:33:10 - train: epoch 0233, iter [00980, 01251], lr: 0.000533, loss: 0.3953
2022-10-02 02:33:28 - train: epoch 0233, iter [00990, 01251], lr: 0.000533, loss: 0.4028
2022-10-02 02:33:45 - train: epoch 0233, iter [01000, 01251], lr: 0.000533, loss: 0.4104
2022-10-02 02:34:03 - train: epoch 0233, iter [01010, 01251], lr: 0.000533, loss: 0.4221
2022-10-02 02:34:21 - train: epoch 0233, iter [01020, 01251], lr: 0.000533, loss: 0.4051
2022-10-02 02:34:39 - train: epoch 0233, iter [01030, 01251], lr: 0.000533, loss: 0.4141
2022-10-02 02:34:56 - train: epoch 0233, iter [01040, 01251], lr: 0.000533, loss: 0.4048
2022-10-02 02:35:14 - train: epoch 0233, iter [01050, 01251], lr: 0.000533, loss: 0.4251
2022-10-02 02:35:32 - train: epoch 0233, iter [01060, 01251], lr: 0.000533, loss: 0.4028
2022-10-02 02:35:49 - train: epoch 0233, iter [01070, 01251], lr: 0.000533, loss: 0.4086
2022-10-02 02:36:07 - train: epoch 0233, iter [01080, 01251], lr: 0.000533, loss: 0.3975
2022-10-02 02:36:25 - train: epoch 0233, iter [01090, 01251], lr: 0.000533, loss: 0.4223
2022-10-02 02:36:43 - train: epoch 0233, iter [01100, 01251], lr: 0.000533, loss: 0.4183
2022-10-02 02:37:00 - train: epoch 0233, iter [01110, 01251], lr: 0.000533, loss: 0.3929
2022-10-02 02:37:18 - train: epoch 0233, iter [01120, 01251], lr: 0.000533, loss: 0.3891
2022-10-02 02:37:36 - train: epoch 0233, iter [01130, 01251], lr: 0.000533, loss: 0.4207
2022-10-02 02:37:53 - train: epoch 0233, iter [01140, 01251], lr: 0.000533, loss: 0.3994
2022-10-02 02:38:11 - train: epoch 0233, iter [01150, 01251], lr: 0.000532, loss: 0.4106
2022-10-02 02:38:29 - train: epoch 0233, iter [01160, 01251], lr: 0.000532, loss: 0.3911
2022-10-02 02:38:47 - train: epoch 0233, iter [01170, 01251], lr: 0.000532, loss: 0.4248
2022-10-02 02:39:05 - train: epoch 0233, iter [01180, 01251], lr: 0.000532, loss: 0.4249
2022-10-02 02:39:22 - train: epoch 0233, iter [01190, 01251], lr: 0.000532, loss: 0.4059
2022-10-02 02:39:40 - train: epoch 0233, iter [01200, 01251], lr: 0.000532, loss: 0.4105
2022-10-02 02:39:58 - train: epoch 0233, iter [01210, 01251], lr: 0.000532, loss: 0.4133
2022-10-02 02:40:16 - train: epoch 0233, iter [01220, 01251], lr: 0.000532, loss: 0.3992
2022-10-02 02:40:33 - train: epoch 0233, iter [01230, 01251], lr: 0.000532, loss: 0.4006
2022-10-02 02:40:51 - train: epoch 0233, iter [01240, 01251], lr: 0.000532, loss: 0.4106
2022-10-02 02:41:09 - train: epoch 0233, iter [01250, 01251], lr: 0.000532, loss: 0.3987
2022-10-02 02:41:12 - train: epoch 233, train_loss: 0.4044
2022-10-02 02:41:14 - until epoch: 233, best_loss: 0.4044
2022-10-02 02:41:14 - epoch 234 lr: 0.000532
2022-10-02 02:41:40 - train: epoch 0234, iter [00010, 01251], lr: 0.000532, loss: 0.3904
2022-10-02 02:41:58 - train: epoch 0234, iter [00020, 01251], lr: 0.000532, loss: 0.4074
2022-10-02 02:42:16 - train: epoch 0234, iter [00030, 01251], lr: 0.000532, loss: 0.3953
2022-10-02 02:42:33 - train: epoch 0234, iter [00040, 01251], lr: 0.000532, loss: 0.4041
2022-10-02 02:42:51 - train: epoch 0234, iter [00050, 01251], lr: 0.000532, loss: 0.4123
2022-10-02 02:43:09 - train: epoch 0234, iter [00060, 01251], lr: 0.000532, loss: 0.4223
2022-10-02 02:43:26 - train: epoch 0234, iter [00070, 01251], lr: 0.000532, loss: 0.4290
2022-10-02 02:43:44 - train: epoch 0234, iter [00080, 01251], lr: 0.000532, loss: 0.4086
2022-10-02 02:44:02 - train: epoch 0234, iter [00090, 01251], lr: 0.000532, loss: 0.3969
2022-10-02 02:44:20 - train: epoch 0234, iter [00100, 01251], lr: 0.000532, loss: 0.3812
2022-10-02 02:44:37 - train: epoch 0234, iter [00110, 01251], lr: 0.000532, loss: 0.4029
2022-10-02 02:44:55 - train: epoch 0234, iter [00120, 01251], lr: 0.000532, loss: 0.4056
2022-10-02 02:45:13 - train: epoch 0234, iter [00130, 01251], lr: 0.000532, loss: 0.4110
2022-10-02 02:45:30 - train: epoch 0234, iter [00140, 01251], lr: 0.000531, loss: 0.3784
2022-10-02 02:45:48 - train: epoch 0234, iter [00150, 01251], lr: 0.000531, loss: 0.4012
2022-10-02 02:46:06 - train: epoch 0234, iter [00160, 01251], lr: 0.000531, loss: 0.3689
2022-10-02 02:46:24 - train: epoch 0234, iter [00170, 01251], lr: 0.000531, loss: 0.4087
2022-10-02 02:46:42 - train: epoch 0234, iter [00180, 01251], lr: 0.000531, loss: 0.4017
2022-10-02 02:46:59 - train: epoch 0234, iter [00190, 01251], lr: 0.000531, loss: 0.3881
2022-10-02 02:47:17 - train: epoch 0234, iter [00200, 01251], lr: 0.000531, loss: 0.4088
2022-10-02 02:47:35 - train: epoch 0234, iter [00210, 01251], lr: 0.000531, loss: 0.4128
2022-10-02 02:47:53 - train: epoch 0234, iter [00220, 01251], lr: 0.000531, loss: 0.4074
2022-10-02 02:48:10 - train: epoch 0234, iter [00230, 01251], lr: 0.000531, loss: 0.3898
2022-10-02 02:48:28 - train: epoch 0234, iter [00240, 01251], lr: 0.000531, loss: 0.3865
2022-10-02 02:48:46 - train: epoch 0234, iter [00250, 01251], lr: 0.000531, loss: 0.4227
2022-10-02 02:49:04 - train: epoch 0234, iter [00260, 01251], lr: 0.000531, loss: 0.3880
2022-10-02 02:49:21 - train: epoch 0234, iter [00270, 01251], lr: 0.000531, loss: 0.3897
2022-10-02 02:49:39 - train: epoch 0234, iter [00280, 01251], lr: 0.000531, loss: 0.4010
2022-10-02 02:49:57 - train: epoch 0234, iter [00290, 01251], lr: 0.000531, loss: 0.4080
2022-10-02 02:50:14 - train: epoch 0234, iter [00300, 01251], lr: 0.000531, loss: 0.4039
2022-10-02 02:50:32 - train: epoch 0234, iter [00310, 01251], lr: 0.000531, loss: 0.4083
2022-10-02 02:50:50 - train: epoch 0234, iter [00320, 01251], lr: 0.000531, loss: 0.3995
2022-10-02 02:51:08 - train: epoch 0234, iter [00330, 01251], lr: 0.000531, loss: 0.4023
2022-10-02 02:51:25 - train: epoch 0234, iter [00340, 01251], lr: 0.000531, loss: 0.4052
2022-10-02 02:51:43 - train: epoch 0234, iter [00350, 01251], lr: 0.000531, loss: 0.3966
2022-10-02 02:52:01 - train: epoch 0234, iter [00360, 01251], lr: 0.000531, loss: 0.3891
2022-10-02 02:52:19 - train: epoch 0234, iter [00370, 01251], lr: 0.000531, loss: 0.4107
2022-10-02 02:52:37 - train: epoch 0234, iter [00380, 01251], lr: 0.000530, loss: 0.4081
2022-10-02 02:52:54 - train: epoch 0234, iter [00390, 01251], lr: 0.000530, loss: 0.3982
2022-10-02 02:53:12 - train: epoch 0234, iter [00400, 01251], lr: 0.000530, loss: 0.3888
2022-10-02 02:53:30 - train: epoch 0234, iter [00410, 01251], lr: 0.000530, loss: 0.4152
2022-10-02 02:53:48 - train: epoch 0234, iter [00420, 01251], lr: 0.000530, loss: 0.4217
2022-10-02 02:54:05 - train: epoch 0234, iter [00430, 01251], lr: 0.000530, loss: 0.3939
2022-10-02 02:54:23 - train: epoch 0234, iter [00440, 01251], lr: 0.000530, loss: 0.4004
2022-10-02 02:54:41 - train: epoch 0234, iter [00450, 01251], lr: 0.000530, loss: 0.4025
2022-10-02 02:54:59 - train: epoch 0234, iter [00460, 01251], lr: 0.000530, loss: 0.3982
2022-10-02 02:55:16 - train: epoch 0234, iter [00470, 01251], lr: 0.000530, loss: 0.4063
2022-10-02 02:55:34 - train: epoch 0234, iter [00480, 01251], lr: 0.000530, loss: 0.3949
2022-10-02 02:55:52 - train: epoch 0234, iter [00490, 01251], lr: 0.000530, loss: 0.4211
2022-10-02 02:56:09 - train: epoch 0234, iter [00500, 01251], lr: 0.000530, loss: 0.4043
2022-10-02 02:56:27 - train: epoch 0234, iter [00510, 01251], lr: 0.000530, loss: 0.4001
2022-10-02 02:56:45 - train: epoch 0234, iter [00520, 01251], lr: 0.000530, loss: 0.4162
2022-10-02 02:57:02 - train: epoch 0234, iter [00530, 01251], lr: 0.000530, loss: 0.4015
2022-10-02 02:57:20 - train: epoch 0234, iter [00540, 01251], lr: 0.000530, loss: 0.4108
2022-10-02 02:57:38 - train: epoch 0234, iter [00550, 01251], lr: 0.000530, loss: 0.4193
2022-10-02 02:57:56 - train: epoch 0234, iter [00560, 01251], lr: 0.000530, loss: 0.3936
2022-10-02 02:58:14 - train: epoch 0234, iter [00570, 01251], lr: 0.000530, loss: 0.4132
2022-10-02 02:58:31 - train: epoch 0234, iter [00580, 01251], lr: 0.000530, loss: 0.3914
2022-10-02 02:58:49 - train: epoch 0234, iter [00590, 01251], lr: 0.000530, loss: 0.4158
2022-10-02 02:59:07 - train: epoch 0234, iter [00600, 01251], lr: 0.000530, loss: 0.4035
2022-10-02 02:59:24 - train: epoch 0234, iter [00610, 01251], lr: 0.000530, loss: 0.4037
2022-10-02 02:59:42 - train: epoch 0234, iter [00620, 01251], lr: 0.000530, loss: 0.3855
2022-10-02 03:00:00 - train: epoch 0234, iter [00630, 01251], lr: 0.000529, loss: 0.3793
2022-10-02 03:00:18 - train: epoch 0234, iter [00640, 01251], lr: 0.000529, loss: 0.3998
2022-10-02 03:00:35 - train: epoch 0234, iter [00650, 01251], lr: 0.000529, loss: 0.3967
2022-10-02 03:00:53 - train: epoch 0234, iter [00660, 01251], lr: 0.000529, loss: 0.4029
2022-10-02 03:01:11 - train: epoch 0234, iter [00670, 01251], lr: 0.000529, loss: 0.4077
2022-10-02 03:01:29 - train: epoch 0234, iter [00680, 01251], lr: 0.000529, loss: 0.4187
2022-10-02 03:01:46 - train: epoch 0234, iter [00690, 01251], lr: 0.000529, loss: 0.4182
2022-10-02 03:02:04 - train: epoch 0234, iter [00700, 01251], lr: 0.000529, loss: 0.4054
2022-10-02 03:02:22 - train: epoch 0234, iter [00710, 01251], lr: 0.000529, loss: 0.4116
2022-10-02 03:02:39 - train: epoch 0234, iter [00720, 01251], lr: 0.000529, loss: 0.3873
2022-10-02 03:02:57 - train: epoch 0234, iter [00730, 01251], lr: 0.000529, loss: 0.4109
2022-10-02 03:03:15 - train: epoch 0234, iter [00740, 01251], lr: 0.000529, loss: 0.4146
2022-10-02 03:03:32 - train: epoch 0234, iter [00750, 01251], lr: 0.000529, loss: 0.3997
2022-10-02 03:03:50 - train: epoch 0234, iter [00760, 01251], lr: 0.000529, loss: 0.4060
2022-10-02 03:04:08 - train: epoch 0234, iter [00770, 01251], lr: 0.000529, loss: 0.3876
2022-10-02 03:04:26 - train: epoch 0234, iter [00780, 01251], lr: 0.000529, loss: 0.4171
2022-10-02 03:04:44 - train: epoch 0234, iter [00790, 01251], lr: 0.000529, loss: 0.3751
2022-10-02 03:05:01 - train: epoch 0234, iter [00800, 01251], lr: 0.000529, loss: 0.4054
2022-10-02 03:05:19 - train: epoch 0234, iter [00810, 01251], lr: 0.000529, loss: 0.3866
2022-10-02 03:05:37 - train: epoch 0234, iter [00820, 01251], lr: 0.000529, loss: 0.4015
2022-10-02 03:05:55 - train: epoch 0234, iter [00830, 01251], lr: 0.000529, loss: 0.3976
2022-10-02 03:06:12 - train: epoch 0234, iter [00840, 01251], lr: 0.000529, loss: 0.4062
2022-10-02 03:06:30 - train: epoch 0234, iter [00850, 01251], lr: 0.000529, loss: 0.4129
2022-10-02 03:06:48 - train: epoch 0234, iter [00860, 01251], lr: 0.000529, loss: 0.4157
2022-10-02 03:07:06 - train: epoch 0234, iter [00870, 01251], lr: 0.000528, loss: 0.3967
2022-10-02 03:07:23 - train: epoch 0234, iter [00880, 01251], lr: 0.000528, loss: 0.3988
2022-10-02 03:07:41 - train: epoch 0234, iter [00890, 01251], lr: 0.000528, loss: 0.3849
2022-10-02 03:07:59 - train: epoch 0234, iter [00900, 01251], lr: 0.000528, loss: 0.3970
2022-10-02 03:08:16 - train: epoch 0234, iter [00910, 01251], lr: 0.000528, loss: 0.4024
2022-10-02 03:08:34 - train: epoch 0234, iter [00920, 01251], lr: 0.000528, loss: 0.3949
2022-10-02 03:08:52 - train: epoch 0234, iter [00930, 01251], lr: 0.000528, loss: 0.3991
2022-10-02 03:09:10 - train: epoch 0234, iter [00940, 01251], lr: 0.000528, loss: 0.3954
2022-10-02 03:09:27 - train: epoch 0234, iter [00950, 01251], lr: 0.000528, loss: 0.3884
2022-10-02 03:09:45 - train: epoch 0234, iter [00960, 01251], lr: 0.000528, loss: 0.4217
2022-10-02 03:10:03 - train: epoch 0234, iter [00970, 01251], lr: 0.000528, loss: 0.3985
2022-10-02 03:10:21 - train: epoch 0234, iter [00980, 01251], lr: 0.000528, loss: 0.4166
2022-10-02 03:10:38 - train: epoch 0234, iter [00990, 01251], lr: 0.000528, loss: 0.4120
2022-10-02 03:10:56 - train: epoch 0234, iter [01000, 01251], lr: 0.000528, loss: 0.3981
2022-10-02 03:11:14 - train: epoch 0234, iter [01010, 01251], lr: 0.000528, loss: 0.4188
2022-10-02 03:11:32 - train: epoch 0234, iter [01020, 01251], lr: 0.000528, loss: 0.3869
2022-10-02 03:11:49 - train: epoch 0234, iter [01030, 01251], lr: 0.000528, loss: 0.3942
2022-10-02 03:12:07 - train: epoch 0234, iter [01040, 01251], lr: 0.000528, loss: 0.3982
2022-10-02 03:12:25 - train: epoch 0234, iter [01050, 01251], lr: 0.000528, loss: 0.4021
2022-10-02 03:12:43 - train: epoch 0234, iter [01060, 01251], lr: 0.000528, loss: 0.4235
2022-10-02 03:13:00 - train: epoch 0234, iter [01070, 01251], lr: 0.000528, loss: 0.4021
2022-10-02 03:13:18 - train: epoch 0234, iter [01080, 01251], lr: 0.000528, loss: 0.3890
2022-10-02 03:13:36 - train: epoch 0234, iter [01090, 01251], lr: 0.000528, loss: 0.4049
2022-10-02 03:13:54 - train: epoch 0234, iter [01100, 01251], lr: 0.000528, loss: 0.3996
2022-10-02 03:14:11 - train: epoch 0234, iter [01110, 01251], lr: 0.000527, loss: 0.3932
2022-10-02 03:14:29 - train: epoch 0234, iter [01120, 01251], lr: 0.000527, loss: 0.4127
2022-10-02 03:14:47 - train: epoch 0234, iter [01130, 01251], lr: 0.000527, loss: 0.3918
2022-10-02 03:15:05 - train: epoch 0234, iter [01140, 01251], lr: 0.000527, loss: 0.3816
2022-10-02 03:15:22 - train: epoch 0234, iter [01150, 01251], lr: 0.000527, loss: 0.4024
2022-10-02 03:15:40 - train: epoch 0234, iter [01160, 01251], lr: 0.000527, loss: 0.4130
2022-10-02 03:15:58 - train: epoch 0234, iter [01170, 01251], lr: 0.000527, loss: 0.4103
2022-10-02 03:16:15 - train: epoch 0234, iter [01180, 01251], lr: 0.000527, loss: 0.3998
2022-10-02 03:16:33 - train: epoch 0234, iter [01190, 01251], lr: 0.000527, loss: 0.4078
2022-10-02 03:16:51 - train: epoch 0234, iter [01200, 01251], lr: 0.000527, loss: 0.4059
2022-10-02 03:17:08 - train: epoch 0234, iter [01210, 01251], lr: 0.000527, loss: 0.4022
2022-10-02 03:17:26 - train: epoch 0234, iter [01220, 01251], lr: 0.000527, loss: 0.4194
2022-10-02 03:17:44 - train: epoch 0234, iter [01230, 01251], lr: 0.000527, loss: 0.4179
2022-10-02 03:18:01 - train: epoch 0234, iter [01240, 01251], lr: 0.000527, loss: 0.4282
2022-10-02 03:18:19 - train: epoch 0234, iter [01250, 01251], lr: 0.000527, loss: 0.3885
2022-10-02 03:18:22 - train: epoch 234, train_loss: 0.4043
2022-10-02 03:18:25 - until epoch: 234, best_loss: 0.4043
2022-10-02 03:18:25 - epoch 235 lr: 0.000527
2022-10-02 03:18:50 - train: epoch 0235, iter [00010, 01251], lr: 0.000527, loss: 0.4090
2022-10-02 03:19:08 - train: epoch 0235, iter [00020, 01251], lr: 0.000527, loss: 0.4098
2022-10-02 03:19:26 - train: epoch 0235, iter [00030, 01251], lr: 0.000527, loss: 0.4196
2022-10-02 03:19:43 - train: epoch 0235, iter [00040, 01251], lr: 0.000527, loss: 0.4163
2022-10-02 03:20:01 - train: epoch 0235, iter [00050, 01251], lr: 0.000527, loss: 0.4118
2022-10-02 03:20:19 - train: epoch 0235, iter [00060, 01251], lr: 0.000527, loss: 0.4116
2022-10-02 03:20:36 - train: epoch 0235, iter [00070, 01251], lr: 0.000527, loss: 0.3974
2022-10-02 03:20:54 - train: epoch 0235, iter [00080, 01251], lr: 0.000527, loss: 0.3962
2022-10-02 03:21:12 - train: epoch 0235, iter [00090, 01251], lr: 0.000527, loss: 0.4224
2022-10-02 03:21:29 - train: epoch 0235, iter [00100, 01251], lr: 0.000526, loss: 0.3971
2022-10-02 03:21:47 - train: epoch 0235, iter [00110, 01251], lr: 0.000526, loss: 0.3894
2022-10-02 03:22:05 - train: epoch 0235, iter [00120, 01251], lr: 0.000526, loss: 0.4205
2022-10-02 03:22:23 - train: epoch 0235, iter [00130, 01251], lr: 0.000526, loss: 0.4025
2022-10-02 03:22:40 - train: epoch 0235, iter [00140, 01251], lr: 0.000526, loss: 0.4199
2022-10-02 03:22:58 - train: epoch 0235, iter [00150, 01251], lr: 0.000526, loss: 0.4286
2022-10-02 03:23:16 - train: epoch 0235, iter [00160, 01251], lr: 0.000526, loss: 0.3892
2022-10-02 03:23:34 - train: epoch 0235, iter [00170, 01251], lr: 0.000526, loss: 0.3786
2022-10-02 03:23:51 - train: epoch 0235, iter [00180, 01251], lr: 0.000526, loss: 0.3990
2022-10-02 03:24:09 - train: epoch 0235, iter [00190, 01251], lr: 0.000526, loss: 0.4080
2022-10-02 03:24:27 - train: epoch 0235, iter [00200, 01251], lr: 0.000526, loss: 0.4233
2022-10-02 03:24:44 - train: epoch 0235, iter [00210, 01251], lr: 0.000526, loss: 0.3959
2022-10-02 03:25:02 - train: epoch 0235, iter [00220, 01251], lr: 0.000526, loss: 0.4064
2022-10-02 03:25:20 - train: epoch 0235, iter [00230, 01251], lr: 0.000526, loss: 0.3938
2022-10-02 03:25:37 - train: epoch 0235, iter [00240, 01251], lr: 0.000526, loss: 0.3962
2022-10-02 03:25:55 - train: epoch 0235, iter [00250, 01251], lr: 0.000526, loss: 0.4018
2022-10-02 03:26:13 - train: epoch 0235, iter [00260, 01251], lr: 0.000526, loss: 0.4100
2022-10-02 03:26:31 - train: epoch 0235, iter [00270, 01251], lr: 0.000526, loss: 0.4192
2022-10-02 03:26:48 - train: epoch 0235, iter [00280, 01251], lr: 0.000526, loss: 0.3845
2022-10-02 03:27:06 - train: epoch 0235, iter [00290, 01251], lr: 0.000526, loss: 0.4265
2022-10-02 03:27:24 - train: epoch 0235, iter [00300, 01251], lr: 0.000526, loss: 0.4001
2022-10-02 03:27:41 - train: epoch 0235, iter [00310, 01251], lr: 0.000526, loss: 0.4103
2022-10-02 03:27:59 - train: epoch 0235, iter [00320, 01251], lr: 0.000526, loss: 0.3941
2022-10-02 03:28:17 - train: epoch 0235, iter [00330, 01251], lr: 0.000526, loss: 0.4076
2022-10-02 03:28:34 - train: epoch 0235, iter [00340, 01251], lr: 0.000525, loss: 0.4014
2022-10-02 03:28:52 - train: epoch 0235, iter [00350, 01251], lr: 0.000525, loss: 0.4040
2022-10-02 03:29:10 - train: epoch 0235, iter [00360, 01251], lr: 0.000525, loss: 0.3920
2022-10-02 03:29:28 - train: epoch 0235, iter [00370, 01251], lr: 0.000525, loss: 0.4117
2022-10-02 03:29:45 - train: epoch 0235, iter [00380, 01251], lr: 0.000525, loss: 0.4064
2022-10-02 03:30:03 - train: epoch 0235, iter [00390, 01251], lr: 0.000525, loss: 0.3892
2022-10-02 03:30:21 - train: epoch 0235, iter [00400, 01251], lr: 0.000525, loss: 0.4229
2022-10-02 03:30:38 - train: epoch 0235, iter [00410, 01251], lr: 0.000525, loss: 0.4062
2022-10-02 03:30:56 - train: epoch 0235, iter [00420, 01251], lr: 0.000525, loss: 0.3998
2022-10-02 03:31:14 - train: epoch 0235, iter [00430, 01251], lr: 0.000525, loss: 0.4194
2022-10-02 03:31:32 - train: epoch 0235, iter [00440, 01251], lr: 0.000525, loss: 0.4097
2022-10-02 03:31:49 - train: epoch 0235, iter [00450, 01251], lr: 0.000525, loss: 0.4108
2022-10-02 03:32:07 - train: epoch 0235, iter [00460, 01251], lr: 0.000525, loss: 0.3971
2022-10-02 03:32:25 - train: epoch 0235, iter [00470, 01251], lr: 0.000525, loss: 0.3977
2022-10-02 03:32:43 - train: epoch 0235, iter [00480, 01251], lr: 0.000525, loss: 0.4084
2022-10-02 03:33:00 - train: epoch 0235, iter [00490, 01251], lr: 0.000525, loss: 0.3964
2022-10-02 03:33:18 - train: epoch 0235, iter [00500, 01251], lr: 0.000525, loss: 0.4089
2022-10-02 03:33:36 - train: epoch 0235, iter [00510, 01251], lr: 0.000525, loss: 0.3955
2022-10-02 03:33:54 - train: epoch 0235, iter [00520, 01251], lr: 0.000525, loss: 0.4127
2022-10-02 03:34:11 - train: epoch 0235, iter [00530, 01251], lr: 0.000525, loss: 0.3879
2022-10-02 03:34:29 - train: epoch 0235, iter [00540, 01251], lr: 0.000525, loss: 0.4118
2022-10-02 03:34:47 - train: epoch 0235, iter [00550, 01251], lr: 0.000525, loss: 0.4119
2022-10-02 03:35:05 - train: epoch 0235, iter [00560, 01251], lr: 0.000525, loss: 0.4024
2022-10-02 03:35:22 - train: epoch 0235, iter [00570, 01251], lr: 0.000525, loss: 0.4013
2022-10-02 03:35:40 - train: epoch 0235, iter [00580, 01251], lr: 0.000524, loss: 0.4182
2022-10-02 03:35:58 - train: epoch 0235, iter [00590, 01251], lr: 0.000524, loss: 0.3917
2022-10-02 03:36:16 - train: epoch 0235, iter [00600, 01251], lr: 0.000524, loss: 0.4056
2022-10-02 03:36:33 - train: epoch 0235, iter [00610, 01251], lr: 0.000524, loss: 0.4070
2022-10-02 03:36:51 - train: epoch 0235, iter [00620, 01251], lr: 0.000524, loss: 0.3905
2022-10-02 03:37:09 - train: epoch 0235, iter [00630, 01251], lr: 0.000524, loss: 0.4061
2022-10-02 03:37:27 - train: epoch 0235, iter [00640, 01251], lr: 0.000524, loss: 0.3977
2022-10-02 03:37:44 - train: epoch 0235, iter [00650, 01251], lr: 0.000524, loss: 0.3835
2022-10-02 03:38:02 - train: epoch 0235, iter [00660, 01251], lr: 0.000524, loss: 0.4099
2022-10-02 03:38:20 - train: epoch 0235, iter [00670, 01251], lr: 0.000524, loss: 0.4014
2022-10-02 03:38:37 - train: epoch 0235, iter [00680, 01251], lr: 0.000524, loss: 0.4087
2022-10-02 03:38:55 - train: epoch 0235, iter [00690, 01251], lr: 0.000524, loss: 0.3902
2022-10-02 03:39:13 - train: epoch 0235, iter [00700, 01251], lr: 0.000524, loss: 0.3991
2022-10-02 03:39:30 - train: epoch 0235, iter [00710, 01251], lr: 0.000524, loss: 0.3986
2022-10-02 03:39:48 - train: epoch 0235, iter [00720, 01251], lr: 0.000524, loss: 0.3799
2022-10-02 03:40:06 - train: epoch 0235, iter [00730, 01251], lr: 0.000524, loss: 0.4150
2022-10-02 03:40:23 - train: epoch 0235, iter [00740, 01251], lr: 0.000524, loss: 0.4011
2022-10-02 03:40:41 - train: epoch 0235, iter [00750, 01251], lr: 0.000524, loss: 0.4070
2022-10-02 03:40:59 - train: epoch 0235, iter [00760, 01251], lr: 0.000524, loss: 0.4028
2022-10-02 03:41:17 - train: epoch 0235, iter [00770, 01251], lr: 0.000524, loss: 0.3908
2022-10-02 03:41:34 - train: epoch 0235, iter [00780, 01251], lr: 0.000524, loss: 0.4145
2022-10-02 03:41:52 - train: epoch 0235, iter [00790, 01251], lr: 0.000524, loss: 0.4055
2022-10-02 03:42:10 - train: epoch 0235, iter [00800, 01251], lr: 0.000524, loss: 0.4140
2022-10-02 03:42:28 - train: epoch 0235, iter [00810, 01251], lr: 0.000524, loss: 0.4165
2022-10-02 03:42:45 - train: epoch 0235, iter [00820, 01251], lr: 0.000523, loss: 0.3943
2022-10-02 03:43:03 - train: epoch 0235, iter [00830, 01251], lr: 0.000523, loss: 0.3996
2022-10-02 03:43:21 - train: epoch 0235, iter [00840, 01251], lr: 0.000523, loss: 0.4167
2022-10-02 03:43:39 - train: epoch 0235, iter [00850, 01251], lr: 0.000523, loss: 0.4087
2022-10-02 03:43:57 - train: epoch 0235, iter [00860, 01251], lr: 0.000523, loss: 0.4058
2022-10-02 03:44:14 - train: epoch 0235, iter [00870, 01251], lr: 0.000523, loss: 0.4075
2022-10-02 03:44:32 - train: epoch 0235, iter [00880, 01251], lr: 0.000523, loss: 0.4009
2022-10-02 03:44:50 - train: epoch 0235, iter [00890, 01251], lr: 0.000523, loss: 0.4028
2022-10-02 03:45:07 - train: epoch 0235, iter [00900, 01251], lr: 0.000523, loss: 0.4126
2022-10-02 03:45:25 - train: epoch 0235, iter [00910, 01251], lr: 0.000523, loss: 0.3986
2022-10-02 03:45:43 - train: epoch 0235, iter [00920, 01251], lr: 0.000523, loss: 0.4125
2022-10-02 03:46:00 - train: epoch 0235, iter [00930, 01251], lr: 0.000523, loss: 0.4180
2022-10-02 03:46:18 - train: epoch 0235, iter [00940, 01251], lr: 0.000523, loss: 0.4003
2022-10-02 03:46:36 - train: epoch 0235, iter [00950, 01251], lr: 0.000523, loss: 0.4241
2022-10-02 03:46:54 - train: epoch 0235, iter [00960, 01251], lr: 0.000523, loss: 0.3905
2022-10-02 03:47:12 - train: epoch 0235, iter [00970, 01251], lr: 0.000523, loss: 0.3949
2022-10-02 03:47:29 - train: epoch 0235, iter [00980, 01251], lr: 0.000523, loss: 0.4143
2022-10-02 03:47:47 - train: epoch 0235, iter [00990, 01251], lr: 0.000523, loss: 0.4022
2022-10-02 03:48:05 - train: epoch 0235, iter [01000, 01251], lr: 0.000523, loss: 0.3830
2022-10-02 03:48:23 - train: epoch 0235, iter [01010, 01251], lr: 0.000523, loss: 0.4095
2022-10-02 03:48:40 - train: epoch 0235, iter [01020, 01251], lr: 0.000523, loss: 0.4123
2022-10-02 03:48:58 - train: epoch 0235, iter [01030, 01251], lr: 0.000523, loss: 0.4071
2022-10-02 03:49:16 - train: epoch 0235, iter [01040, 01251], lr: 0.000523, loss: 0.3885
2022-10-02 03:49:34 - train: epoch 0235, iter [01050, 01251], lr: 0.000523, loss: 0.3872
2022-10-02 03:49:51 - train: epoch 0235, iter [01060, 01251], lr: 0.000522, loss: 0.3996
2022-10-02 03:50:09 - train: epoch 0235, iter [01070, 01251], lr: 0.000522, loss: 0.4070
2022-10-02 03:50:27 - train: epoch 0235, iter [01080, 01251], lr: 0.000522, loss: 0.3960
2022-10-02 03:50:45 - train: epoch 0235, iter [01090, 01251], lr: 0.000522, loss: 0.4096
2022-10-02 03:51:02 - train: epoch 0235, iter [01100, 01251], lr: 0.000522, loss: 0.4128
2022-10-02 03:51:20 - train: epoch 0235, iter [01110, 01251], lr: 0.000522, loss: 0.3660
2022-10-02 03:51:38 - train: epoch 0235, iter [01120, 01251], lr: 0.000522, loss: 0.3852
2022-10-02 03:51:55 - train: epoch 0235, iter [01130, 01251], lr: 0.000522, loss: 0.3869
2022-10-02 03:52:13 - train: epoch 0235, iter [01140, 01251], lr: 0.000522, loss: 0.3971
2022-10-02 03:52:31 - train: epoch 0235, iter [01150, 01251], lr: 0.000522, loss: 0.4017
2022-10-02 03:52:49 - train: epoch 0235, iter [01160, 01251], lr: 0.000522, loss: 0.3915
2022-10-02 03:53:07 - train: epoch 0235, iter [01170, 01251], lr: 0.000522, loss: 0.3947
2022-10-02 03:53:24 - train: epoch 0235, iter [01180, 01251], lr: 0.000522, loss: 0.3968
2022-10-02 03:53:42 - train: epoch 0235, iter [01190, 01251], lr: 0.000522, loss: 0.4013
2022-10-02 03:54:00 - train: epoch 0235, iter [01200, 01251], lr: 0.000522, loss: 0.4098
2022-10-02 03:54:17 - train: epoch 0235, iter [01210, 01251], lr: 0.000522, loss: 0.4099
2022-10-02 03:54:35 - train: epoch 0235, iter [01220, 01251], lr: 0.000522, loss: 0.3904
2022-10-02 03:54:53 - train: epoch 0235, iter [01230, 01251], lr: 0.000522, loss: 0.3893
2022-10-02 03:55:10 - train: epoch 0235, iter [01240, 01251], lr: 0.000522, loss: 0.3920
2022-10-02 03:55:28 - train: epoch 0235, iter [01250, 01251], lr: 0.000522, loss: 0.4229
2022-10-02 03:55:31 - train: epoch 235, train_loss: 0.4042
2022-10-02 03:55:34 - until epoch: 235, best_loss: 0.4042
2022-10-02 03:55:34 - epoch 236 lr: 0.000522
2022-10-02 03:55:59 - train: epoch 0236, iter [00010, 01251], lr: 0.000522, loss: 0.3718
2022-10-02 03:56:17 - train: epoch 0236, iter [00020, 01251], lr: 0.000522, loss: 0.4090
2022-10-02 03:56:35 - train: epoch 0236, iter [00030, 01251], lr: 0.000522, loss: 0.4032
2022-10-02 03:56:52 - train: epoch 0236, iter [00040, 01251], lr: 0.000522, loss: 0.4045
2022-10-02 03:57:10 - train: epoch 0236, iter [00050, 01251], lr: 0.000521, loss: 0.4024
2022-10-02 03:57:28 - train: epoch 0236, iter [00060, 01251], lr: 0.000521, loss: 0.3872
2022-10-02 03:57:46 - train: epoch 0236, iter [00070, 01251], lr: 0.000521, loss: 0.3900
2022-10-02 03:58:03 - train: epoch 0236, iter [00080, 01251], lr: 0.000521, loss: 0.3853
2022-10-02 03:58:21 - train: epoch 0236, iter [00090, 01251], lr: 0.000521, loss: 0.3975
2022-10-02 03:58:39 - train: epoch 0236, iter [00100, 01251], lr: 0.000521, loss: 0.3751
2022-10-02 03:58:57 - train: epoch 0236, iter [00110, 01251], lr: 0.000521, loss: 0.3962
2022-10-02 03:59:15 - train: epoch 0236, iter [00120, 01251], lr: 0.000521, loss: 0.3890
2022-10-02 03:59:32 - train: epoch 0236, iter [00130, 01251], lr: 0.000521, loss: 0.4098
2022-10-02 03:59:50 - train: epoch 0236, iter [00140, 01251], lr: 0.000521, loss: 0.4033
2022-10-02 04:00:08 - train: epoch 0236, iter [00150, 01251], lr: 0.000521, loss: 0.4087
2022-10-02 04:00:26 - train: epoch 0236, iter [00160, 01251], lr: 0.000521, loss: 0.4073
2022-10-02 04:00:43 - train: epoch 0236, iter [00170, 01251], lr: 0.000521, loss: 0.3937
2022-10-02 04:01:01 - train: epoch 0236, iter [00180, 01251], lr: 0.000521, loss: 0.4186
2022-10-02 04:01:19 - train: epoch 0236, iter [00190, 01251], lr: 0.000521, loss: 0.4000
2022-10-02 04:01:36 - train: epoch 0236, iter [00200, 01251], lr: 0.000521, loss: 0.3955
2022-10-02 04:01:54 - train: epoch 0236, iter [00210, 01251], lr: 0.000521, loss: 0.4068
2022-10-02 04:02:12 - train: epoch 0236, iter [00220, 01251], lr: 0.000521, loss: 0.4096
2022-10-02 04:02:30 - train: epoch 0236, iter [00230, 01251], lr: 0.000521, loss: 0.4133
2022-10-02 04:02:47 - train: epoch 0236, iter [00240, 01251], lr: 0.000521, loss: 0.3884
2022-10-02 04:03:05 - train: epoch 0236, iter [00250, 01251], lr: 0.000521, loss: 0.3927
2022-10-02 04:03:23 - train: epoch 0236, iter [00260, 01251], lr: 0.000521, loss: 0.4048
2022-10-02 04:03:41 - train: epoch 0236, iter [00270, 01251], lr: 0.000521, loss: 0.4212
2022-10-02 04:03:58 - train: epoch 0236, iter [00280, 01251], lr: 0.000521, loss: 0.4015
2022-10-02 04:04:16 - train: epoch 0236, iter [00290, 01251], lr: 0.000520, loss: 0.4115
2022-10-02 04:04:34 - train: epoch 0236, iter [00300, 01251], lr: 0.000520, loss: 0.3970
2022-10-02 04:04:51 - train: epoch 0236, iter [00310, 01251], lr: 0.000520, loss: 0.4174
2022-10-02 04:05:09 - train: epoch 0236, iter [00320, 01251], lr: 0.000520, loss: 0.3988
2022-10-02 04:05:27 - train: epoch 0236, iter [00330, 01251], lr: 0.000520, loss: 0.4186
2022-10-02 04:05:44 - train: epoch 0236, iter [00340, 01251], lr: 0.000520, loss: 0.4165
2022-10-02 04:06:02 - train: epoch 0236, iter [00350, 01251], lr: 0.000520, loss: 0.4108
2022-10-02 04:06:20 - train: epoch 0236, iter [00360, 01251], lr: 0.000520, loss: 0.3960
2022-10-02 04:06:38 - train: epoch 0236, iter [00370, 01251], lr: 0.000520, loss: 0.3988
2022-10-02 04:06:55 - train: epoch 0236, iter [00380, 01251], lr: 0.000520, loss: 0.4123
2022-10-02 04:07:13 - train: epoch 0236, iter [00390, 01251], lr: 0.000520, loss: 0.3892
2022-10-02 04:07:31 - train: epoch 0236, iter [00400, 01251], lr: 0.000520, loss: 0.4088
2022-10-02 04:07:48 - train: epoch 0236, iter [00410, 01251], lr: 0.000520, loss: 0.4088
2022-10-02 04:08:06 - train: epoch 0236, iter [00420, 01251], lr: 0.000520, loss: 0.4008
2022-10-02 04:08:24 - train: epoch 0236, iter [00430, 01251], lr: 0.000520, loss: 0.4051
2022-10-02 04:08:42 - train: epoch 0236, iter [00440, 01251], lr: 0.000520, loss: 0.4209
2022-10-02 04:08:59 - train: epoch 0236, iter [00450, 01251], lr: 0.000520, loss: 0.4145
2022-10-02 04:09:17 - train: epoch 0236, iter [00460, 01251], lr: 0.000520, loss: 0.4099
2022-10-02 04:09:35 - train: epoch 0236, iter [00470, 01251], lr: 0.000520, loss: 0.3974
2022-10-02 04:09:53 - train: epoch 0236, iter [00480, 01251], lr: 0.000520, loss: 0.4123
2022-10-02 04:10:10 - train: epoch 0236, iter [00490, 01251], lr: 0.000520, loss: 0.4207
2022-10-02 04:10:28 - train: epoch 0236, iter [00500, 01251], lr: 0.000520, loss: 0.3999
2022-10-02 04:10:46 - train: epoch 0236, iter [00510, 01251], lr: 0.000520, loss: 0.4081
2022-10-02 04:11:04 - train: epoch 0236, iter [00520, 01251], lr: 0.000520, loss: 0.4015
2022-10-02 04:11:21 - train: epoch 0236, iter [00530, 01251], lr: 0.000519, loss: 0.4027
2022-10-02 04:11:39 - train: epoch 0236, iter [00540, 01251], lr: 0.000519, loss: 0.3921
2022-10-02 04:11:57 - train: epoch 0236, iter [00550, 01251], lr: 0.000519, loss: 0.4411
2022-10-02 04:12:14 - train: epoch 0236, iter [00560, 01251], lr: 0.000519, loss: 0.4160
2022-10-02 04:12:32 - train: epoch 0236, iter [00570, 01251], lr: 0.000519, loss: 0.4094
2022-10-02 04:12:50 - train: epoch 0236, iter [00580, 01251], lr: 0.000519, loss: 0.3871
2022-10-02 04:13:08 - train: epoch 0236, iter [00590, 01251], lr: 0.000519, loss: 0.3998
2022-10-02 04:13:25 - train: epoch 0236, iter [00600, 01251], lr: 0.000519, loss: 0.4199
2022-10-02 04:13:43 - train: epoch 0236, iter [00610, 01251], lr: 0.000519, loss: 0.3895
2022-10-02 04:14:01 - train: epoch 0236, iter [00620, 01251], lr: 0.000519, loss: 0.4010
2022-10-02 04:14:18 - train: epoch 0236, iter [00630, 01251], lr: 0.000519, loss: 0.3975
2022-10-02 04:14:36 - train: epoch 0236, iter [00640, 01251], lr: 0.000519, loss: 0.4015
2022-10-02 04:14:54 - train: epoch 0236, iter [00650, 01251], lr: 0.000519, loss: 0.4101
2022-10-02 04:15:11 - train: epoch 0236, iter [00660, 01251], lr: 0.000519, loss: 0.3843
2022-10-02 04:15:29 - train: epoch 0236, iter [00670, 01251], lr: 0.000519, loss: 0.4051
2022-10-02 04:15:47 - train: epoch 0236, iter [00680, 01251], lr: 0.000519, loss: 0.3896
2022-10-02 04:16:05 - train: epoch 0236, iter [00690, 01251], lr: 0.000519, loss: 0.4148
2022-10-02 04:16:22 - train: epoch 0236, iter [00700, 01251], lr: 0.000519, loss: 0.4126
2022-10-02 04:16:40 - train: epoch 0236, iter [00710, 01251], lr: 0.000519, loss: 0.4116
2022-10-02 04:16:58 - train: epoch 0236, iter [00720, 01251], lr: 0.000519, loss: 0.4123
2022-10-02 04:17:16 - train: epoch 0236, iter [00730, 01251], lr: 0.000519, loss: 0.4028
2022-10-02 04:17:33 - train: epoch 0236, iter [00740, 01251], lr: 0.000519, loss: 0.3797
2022-10-02 04:17:51 - train: epoch 0236, iter [00750, 01251], lr: 0.000519, loss: 0.4136
2022-10-02 04:18:08 - train: epoch 0236, iter [00760, 01251], lr: 0.000519, loss: 0.3939
2022-10-02 04:18:26 - train: epoch 0236, iter [00770, 01251], lr: 0.000518, loss: 0.4069
2022-10-02 04:18:44 - train: epoch 0236, iter [00780, 01251], lr: 0.000518, loss: 0.4270
2022-10-02 04:19:02 - train: epoch 0236, iter [00790, 01251], lr: 0.000518, loss: 0.3933
2022-10-02 04:19:19 - train: epoch 0236, iter [00800, 01251], lr: 0.000518, loss: 0.4026
2022-10-02 04:19:37 - train: epoch 0236, iter [00810, 01251], lr: 0.000518, loss: 0.4076
2022-10-02 04:19:54 - train: epoch 0236, iter [00820, 01251], lr: 0.000518, loss: 0.4135
2022-10-02 04:20:12 - train: epoch 0236, iter [00830, 01251], lr: 0.000518, loss: 0.4129
2022-10-02 04:20:30 - train: epoch 0236, iter [00840, 01251], lr: 0.000518, loss: 0.3920
2022-10-02 04:20:48 - train: epoch 0236, iter [00850, 01251], lr: 0.000518, loss: 0.4149
2022-10-02 04:21:05 - train: epoch 0236, iter [00860, 01251], lr: 0.000518, loss: 0.4081
2022-10-02 04:21:23 - train: epoch 0236, iter [00870, 01251], lr: 0.000518, loss: 0.4190
2022-10-02 04:21:41 - train: epoch 0236, iter [00880, 01251], lr: 0.000518, loss: 0.4162
2022-10-02 04:21:58 - train: epoch 0236, iter [00890, 01251], lr: 0.000518, loss: 0.4211
2022-10-02 04:22:16 - train: epoch 0236, iter [00900, 01251], lr: 0.000518, loss: 0.4262
2022-10-02 04:22:34 - train: epoch 0236, iter [00910, 01251], lr: 0.000518, loss: 0.4176
2022-10-02 04:22:52 - train: epoch 0236, iter [00920, 01251], lr: 0.000518, loss: 0.3922
2022-10-02 04:23:09 - train: epoch 0236, iter [00930, 01251], lr: 0.000518, loss: 0.3848
2022-10-02 04:23:27 - train: epoch 0236, iter [00940, 01251], lr: 0.000518, loss: 0.4002
2022-10-02 04:23:45 - train: epoch 0236, iter [00950, 01251], lr: 0.000518, loss: 0.3988
2022-10-02 04:24:02 - train: epoch 0236, iter [00960, 01251], lr: 0.000518, loss: 0.3985
2022-10-02 04:24:20 - train: epoch 0236, iter [00970, 01251], lr: 0.000518, loss: 0.4141
2022-10-02 04:24:38 - train: epoch 0236, iter [00980, 01251], lr: 0.000518, loss: 0.4211
2022-10-02 04:24:55 - train: epoch 0236, iter [00990, 01251], lr: 0.000518, loss: 0.3926
2022-10-02 04:25:13 - train: epoch 0236, iter [01000, 01251], lr: 0.000518, loss: 0.4046
2022-10-02 04:25:31 - train: epoch 0236, iter [01010, 01251], lr: 0.000517, loss: 0.4168
2022-10-02 04:25:49 - train: epoch 0236, iter [01020, 01251], lr: 0.000517, loss: 0.4074
2022-10-02 04:26:06 - train: epoch 0236, iter [01030, 01251], lr: 0.000517, loss: 0.4047
2022-10-02 04:26:24 - train: epoch 0236, iter [01040, 01251], lr: 0.000517, loss: 0.3822
2022-10-02 04:26:42 - train: epoch 0236, iter [01050, 01251], lr: 0.000517, loss: 0.4221
2022-10-02 04:27:00 - train: epoch 0236, iter [01060, 01251], lr: 0.000517, loss: 0.4153
2022-10-02 04:27:17 - train: epoch 0236, iter [01070, 01251], lr: 0.000517, loss: 0.4217
2022-10-02 04:27:35 - train: epoch 0236, iter [01080, 01251], lr: 0.000517, loss: 0.4011
2022-10-02 04:27:53 - train: epoch 0236, iter [01090, 01251], lr: 0.000517, loss: 0.4049
2022-10-02 04:28:10 - train: epoch 0236, iter [01100, 01251], lr: 0.000517, loss: 0.3904
2022-10-02 04:28:28 - train: epoch 0236, iter [01110, 01251], lr: 0.000517, loss: 0.4072
2022-10-02 04:28:46 - train: epoch 0236, iter [01120, 01251], lr: 0.000517, loss: 0.4072
2022-10-02 04:29:04 - train: epoch 0236, iter [01130, 01251], lr: 0.000517, loss: 0.4071
2022-10-02 04:29:21 - train: epoch 0236, iter [01140, 01251], lr: 0.000517, loss: 0.4006
2022-10-02 04:29:39 - train: epoch 0236, iter [01150, 01251], lr: 0.000517, loss: 0.4168
2022-10-02 04:29:57 - train: epoch 0236, iter [01160, 01251], lr: 0.000517, loss: 0.3746
2022-10-02 04:30:14 - train: epoch 0236, iter [01170, 01251], lr: 0.000517, loss: 0.4156
2022-10-02 04:30:32 - train: epoch 0236, iter [01180, 01251], lr: 0.000517, loss: 0.4279
2022-10-02 04:30:50 - train: epoch 0236, iter [01190, 01251], lr: 0.000517, loss: 0.3943
2022-10-02 04:31:07 - train: epoch 0236, iter [01200, 01251], lr: 0.000517, loss: 0.3943
2022-10-02 04:31:25 - train: epoch 0236, iter [01210, 01251], lr: 0.000517, loss: 0.4311
2022-10-02 04:31:43 - train: epoch 0236, iter [01220, 01251], lr: 0.000517, loss: 0.4115
2022-10-02 04:32:01 - train: epoch 0236, iter [01230, 01251], lr: 0.000517, loss: 0.4155
2022-10-02 04:32:19 - train: epoch 0236, iter [01240, 01251], lr: 0.000517, loss: 0.3994
2022-10-02 04:32:36 - train: epoch 0236, iter [01250, 01251], lr: 0.000517, loss: 0.4140
2022-10-02 04:32:39 - train: epoch 236, train_loss: 0.4041
2022-10-02 04:32:42 - until epoch: 236, best_loss: 0.4041
2022-10-02 04:32:42 - epoch 237 lr: 0.000516
2022-10-02 04:33:07 - train: epoch 0237, iter [00010, 01251], lr: 0.000516, loss: 0.4064
2022-10-02 04:33:25 - train: epoch 0237, iter [00020, 01251], lr: 0.000516, loss: 0.4079
2022-10-02 04:33:43 - train: epoch 0237, iter [00030, 01251], lr: 0.000516, loss: 0.4027
2022-10-02 04:34:00 - train: epoch 0237, iter [00040, 01251], lr: 0.000516, loss: 0.3833
2022-10-02 04:34:18 - train: epoch 0237, iter [00050, 01251], lr: 0.000516, loss: 0.4197
2022-10-02 04:34:36 - train: epoch 0237, iter [00060, 01251], lr: 0.000516, loss: 0.4057
2022-10-02 04:34:54 - train: epoch 0237, iter [00070, 01251], lr: 0.000516, loss: 0.3989
2022-10-02 04:35:11 - train: epoch 0237, iter [00080, 01251], lr: 0.000516, loss: 0.4176
2022-10-02 04:35:29 - train: epoch 0237, iter [00090, 01251], lr: 0.000516, loss: 0.4186
2022-10-02 04:35:47 - train: epoch 0237, iter [00100, 01251], lr: 0.000516, loss: 0.3953
2022-10-02 04:36:04 - train: epoch 0237, iter [00110, 01251], lr: 0.000516, loss: 0.4088
2022-10-02 04:36:22 - train: epoch 0237, iter [00120, 01251], lr: 0.000516, loss: 0.4017
2022-10-02 04:36:40 - train: epoch 0237, iter [00130, 01251], lr: 0.000516, loss: 0.4069
2022-10-02 04:36:57 - train: epoch 0237, iter [00140, 01251], lr: 0.000516, loss: 0.4166
2022-10-02 04:37:15 - train: epoch 0237, iter [00150, 01251], lr: 0.000516, loss: 0.4215
2022-10-02 04:37:33 - train: epoch 0237, iter [00160, 01251], lr: 0.000516, loss: 0.4114
2022-10-02 04:37:51 - train: epoch 0237, iter [00170, 01251], lr: 0.000516, loss: 0.4041
2022-10-02 04:38:08 - train: epoch 0237, iter [00180, 01251], lr: 0.000516, loss: 0.3956
2022-10-02 04:38:26 - train: epoch 0237, iter [00190, 01251], lr: 0.000516, loss: 0.4160
2022-10-02 04:38:44 - train: epoch 0237, iter [00200, 01251], lr: 0.000516, loss: 0.4151
2022-10-02 04:39:02 - train: epoch 0237, iter [00210, 01251], lr: 0.000516, loss: 0.4102
2022-10-02 04:39:19 - train: epoch 0237, iter [00220, 01251], lr: 0.000516, loss: 0.4013
2022-10-02 04:39:37 - train: epoch 0237, iter [00230, 01251], lr: 0.000516, loss: 0.4034
2022-10-02 04:39:55 - train: epoch 0237, iter [00240, 01251], lr: 0.000516, loss: 0.4091
2022-10-02 04:40:12 - train: epoch 0237, iter [00250, 01251], lr: 0.000515, loss: 0.3794
2022-10-02 04:40:30 - train: epoch 0237, iter [00260, 01251], lr: 0.000515, loss: 0.4178
2022-10-02 04:40:48 - train: epoch 0237, iter [00270, 01251], lr: 0.000515, loss: 0.3963
2022-10-02 04:41:06 - train: epoch 0237, iter [00280, 01251], lr: 0.000515, loss: 0.3622
2022-10-02 04:41:23 - train: epoch 0237, iter [00290, 01251], lr: 0.000515, loss: 0.4124
2022-10-02 04:41:41 - train: epoch 0237, iter [00300, 01251], lr: 0.000515, loss: 0.3929
2022-10-02 04:41:59 - train: epoch 0237, iter [00310, 01251], lr: 0.000515, loss: 0.4089
2022-10-02 04:42:17 - train: epoch 0237, iter [00320, 01251], lr: 0.000515, loss: 0.3988
2022-10-02 04:42:34 - train: epoch 0237, iter [00330, 01251], lr: 0.000515, loss: 0.4157
2022-10-02 04:42:52 - train: epoch 0237, iter [00340, 01251], lr: 0.000515, loss: 0.3715
2022-10-02 04:43:10 - train: epoch 0237, iter [00350, 01251], lr: 0.000515, loss: 0.4264
2022-10-02 04:43:28 - train: epoch 0237, iter [00360, 01251], lr: 0.000515, loss: 0.3929
2022-10-02 04:43:45 - train: epoch 0237, iter [00370, 01251], lr: 0.000515, loss: 0.4070
2022-10-02 04:44:03 - train: epoch 0237, iter [00380, 01251], lr: 0.000515, loss: 0.4169
2022-10-02 04:44:21 - train: epoch 0237, iter [00390, 01251], lr: 0.000515, loss: 0.4020
2022-10-02 04:44:38 - train: epoch 0237, iter [00400, 01251], lr: 0.000515, loss: 0.4390
2022-10-02 04:44:56 - train: epoch 0237, iter [00410, 01251], lr: 0.000515, loss: 0.4053
2022-10-02 04:45:14 - train: epoch 0237, iter [00420, 01251], lr: 0.000515, loss: 0.4092
2022-10-02 04:45:31 - train: epoch 0237, iter [00430, 01251], lr: 0.000515, loss: 0.4053
2022-10-02 04:45:49 - train: epoch 0237, iter [00440, 01251], lr: 0.000515, loss: 0.4160
2022-10-02 04:46:07 - train: epoch 0237, iter [00450, 01251], lr: 0.000515, loss: 0.4045
2022-10-02 04:46:25 - train: epoch 0237, iter [00460, 01251], lr: 0.000515, loss: 0.4173
2022-10-02 04:46:42 - train: epoch 0237, iter [00470, 01251], lr: 0.000515, loss: 0.3960
2022-10-02 04:47:00 - train: epoch 0237, iter [00480, 01251], lr: 0.000515, loss: 0.4077
2022-10-02 04:47:18 - train: epoch 0237, iter [00490, 01251], lr: 0.000514, loss: 0.4269
2022-10-02 04:47:36 - train: epoch 0237, iter [00500, 01251], lr: 0.000514, loss: 0.4088
2022-10-02 04:47:53 - train: epoch 0237, iter [00510, 01251], lr: 0.000514, loss: 0.4144
2022-10-02 04:48:11 - train: epoch 0237, iter [00520, 01251], lr: 0.000514, loss: 0.4002
2022-10-02 04:48:29 - train: epoch 0237, iter [00530, 01251], lr: 0.000514, loss: 0.3955
2022-10-02 04:48:46 - train: epoch 0237, iter [00540, 01251], lr: 0.000514, loss: 0.4053
2022-10-02 04:49:04 - train: epoch 0237, iter [00550, 01251], lr: 0.000514, loss: 0.4024
2022-10-02 04:49:22 - train: epoch 0237, iter [00560, 01251], lr: 0.000514, loss: 0.3947
2022-10-02 04:49:40 - train: epoch 0237, iter [00570, 01251], lr: 0.000514, loss: 0.4041
2022-10-02 04:49:57 - train: epoch 0237, iter [00580, 01251], lr: 0.000514, loss: 0.4093
2022-10-02 04:50:15 - train: epoch 0237, iter [00590, 01251], lr: 0.000514, loss: 0.3749
2022-10-02 04:50:33 - train: epoch 0237, iter [00600, 01251], lr: 0.000514, loss: 0.4172
2022-10-02 04:50:50 - train: epoch 0237, iter [00610, 01251], lr: 0.000514, loss: 0.4198
2022-10-02 04:51:08 - train: epoch 0237, iter [00620, 01251], lr: 0.000514, loss: 0.4008
2022-10-02 04:51:26 - train: epoch 0237, iter [00630, 01251], lr: 0.000514, loss: 0.4150
2022-10-02 04:51:44 - train: epoch 0237, iter [00640, 01251], lr: 0.000514, loss: 0.3836
2022-10-02 04:52:01 - train: epoch 0237, iter [00650, 01251], lr: 0.000514, loss: 0.3960
2022-10-02 04:52:19 - train: epoch 0237, iter [00660, 01251], lr: 0.000514, loss: 0.3850
2022-10-02 04:52:37 - train: epoch 0237, iter [00670, 01251], lr: 0.000514, loss: 0.3964
2022-10-02 04:52:55 - train: epoch 0237, iter [00680, 01251], lr: 0.000514, loss: 0.3699
2022-10-02 04:53:12 - train: epoch 0237, iter [00690, 01251], lr: 0.000514, loss: 0.4027
2022-10-02 04:53:30 - train: epoch 0237, iter [00700, 01251], lr: 0.000514, loss: 0.4048
2022-10-02 04:53:48 - train: epoch 0237, iter [00710, 01251], lr: 0.000514, loss: 0.4163
2022-10-02 04:54:05 - train: epoch 0237, iter [00720, 01251], lr: 0.000514, loss: 0.4191
2022-10-02 04:54:23 - train: epoch 0237, iter [00730, 01251], lr: 0.000513, loss: 0.4163
2022-10-02 04:54:41 - train: epoch 0237, iter [00740, 01251], lr: 0.000513, loss: 0.3951
2022-10-02 04:54:58 - train: epoch 0237, iter [00750, 01251], lr: 0.000513, loss: 0.4043
2022-10-02 04:55:16 - train: epoch 0237, iter [00760, 01251], lr: 0.000513, loss: 0.3886
2022-10-02 04:55:34 - train: epoch 0237, iter [00770, 01251], lr: 0.000513, loss: 0.4062
2022-10-02 04:55:52 - train: epoch 0237, iter [00780, 01251], lr: 0.000513, loss: 0.4071
2022-10-02 04:56:09 - train: epoch 0237, iter [00790, 01251], lr: 0.000513, loss: 0.4152
2022-10-02 04:56:27 - train: epoch 0237, iter [00800, 01251], lr: 0.000513, loss: 0.4044
2022-10-02 04:56:45 - train: epoch 0237, iter [00810, 01251], lr: 0.000513, loss: 0.3963
2022-10-02 04:57:03 - train: epoch 0237, iter [00820, 01251], lr: 0.000513, loss: 0.4089
2022-10-02 04:57:20 - train: epoch 0237, iter [00830, 01251], lr: 0.000513, loss: 0.4017
2022-10-02 04:57:38 - train: epoch 0237, iter [00840, 01251], lr: 0.000513, loss: 0.4087
2022-10-02 04:57:56 - train: epoch 0237, iter [00850, 01251], lr: 0.000513, loss: 0.4097
2022-10-02 04:58:14 - train: epoch 0237, iter [00860, 01251], lr: 0.000513, loss: 0.3908
2022-10-02 04:58:32 - train: epoch 0237, iter [00870, 01251], lr: 0.000513, loss: 0.4006
2022-10-02 04:58:49 - train: epoch 0237, iter [00880, 01251], lr: 0.000513, loss: 0.4021
2022-10-02 04:59:07 - train: epoch 0237, iter [00890, 01251], lr: 0.000513, loss: 0.4057
2022-10-02 04:59:25 - train: epoch 0237, iter [00900, 01251], lr: 0.000513, loss: 0.3745
2022-10-02 04:59:42 - train: epoch 0237, iter [00910, 01251], lr: 0.000513, loss: 0.4002
2022-10-02 05:00:00 - train: epoch 0237, iter [00920, 01251], lr: 0.000513, loss: 0.4193
2022-10-02 05:00:18 - train: epoch 0237, iter [00930, 01251], lr: 0.000513, loss: 0.4021
2022-10-02 05:00:36 - train: epoch 0237, iter [00940, 01251], lr: 0.000513, loss: 0.3923
2022-10-02 05:00:53 - train: epoch 0237, iter [00950, 01251], lr: 0.000513, loss: 0.3974
2022-10-02 05:01:11 - train: epoch 0237, iter [00960, 01251], lr: 0.000513, loss: 0.3982
2022-10-02 05:01:29 - train: epoch 0237, iter [00970, 01251], lr: 0.000512, loss: 0.3926
2022-10-02 05:01:46 - train: epoch 0237, iter [00980, 01251], lr: 0.000512, loss: 0.4039
2022-10-02 05:02:04 - train: epoch 0237, iter [00990, 01251], lr: 0.000512, loss: 0.3878
2022-10-02 05:02:22 - train: epoch 0237, iter [01000, 01251], lr: 0.000512, loss: 0.4314
2022-10-02 05:02:39 - train: epoch 0237, iter [01010, 01251], lr: 0.000512, loss: 0.4087
2022-10-02 05:02:57 - train: epoch 0237, iter [01020, 01251], lr: 0.000512, loss: 0.4011
2022-10-02 05:03:15 - train: epoch 0237, iter [01030, 01251], lr: 0.000512, loss: 0.4194
2022-10-02 05:03:32 - train: epoch 0237, iter [01040, 01251], lr: 0.000512, loss: 0.4266
2022-10-02 05:03:50 - train: epoch 0237, iter [01050, 01251], lr: 0.000512, loss: 0.4058
2022-10-02 05:04:08 - train: epoch 0237, iter [01060, 01251], lr: 0.000512, loss: 0.3917
2022-10-02 05:04:25 - train: epoch 0237, iter [01070, 01251], lr: 0.000512, loss: 0.3966
2022-10-02 05:04:43 - train: epoch 0237, iter [01080, 01251], lr: 0.000512, loss: 0.3975
2022-10-02 05:05:01 - train: epoch 0237, iter [01090, 01251], lr: 0.000512, loss: 0.4206
2022-10-02 05:05:19 - train: epoch 0237, iter [01100, 01251], lr: 0.000512, loss: 0.4022
2022-10-02 05:05:36 - train: epoch 0237, iter [01110, 01251], lr: 0.000512, loss: 0.4080
2022-10-02 05:05:54 - train: epoch 0237, iter [01120, 01251], lr: 0.000512, loss: 0.4021
2022-10-02 05:06:12 - train: epoch 0237, iter [01130, 01251], lr: 0.000512, loss: 0.4071
2022-10-02 05:06:29 - train: epoch 0237, iter [01140, 01251], lr: 0.000512, loss: 0.3918
2022-10-02 05:06:47 - train: epoch 0237, iter [01150, 01251], lr: 0.000512, loss: 0.4148
2022-10-02 05:07:05 - train: epoch 0237, iter [01160, 01251], lr: 0.000512, loss: 0.3991
2022-10-02 05:07:23 - train: epoch 0237, iter [01170, 01251], lr: 0.000512, loss: 0.4036
2022-10-02 05:07:40 - train: epoch 0237, iter [01180, 01251], lr: 0.000512, loss: 0.3935
2022-10-02 05:07:58 - train: epoch 0237, iter [01190, 01251], lr: 0.000512, loss: 0.4011
2022-10-02 05:08:16 - train: epoch 0237, iter [01200, 01251], lr: 0.000512, loss: 0.4231
2022-10-02 05:08:33 - train: epoch 0237, iter [01210, 01251], lr: 0.000511, loss: 0.3871
2022-10-02 05:08:51 - train: epoch 0237, iter [01220, 01251], lr: 0.000511, loss: 0.4147
2022-10-02 05:09:09 - train: epoch 0237, iter [01230, 01251], lr: 0.000511, loss: 0.4073
2022-10-02 05:09:27 - train: epoch 0237, iter [01240, 01251], lr: 0.000511, loss: 0.4084
2022-10-02 05:09:44 - train: epoch 0237, iter [01250, 01251], lr: 0.000511, loss: 0.4070
2022-10-02 05:09:47 - train: epoch 237, train_loss: 0.4041
2022-10-02 05:09:50 - until epoch: 237, best_loss: 0.4041
2022-10-02 05:09:50 - epoch 238 lr: 0.000511
2022-10-02 05:10:15 - train: epoch 0238, iter [00010, 01251], lr: 0.000511, loss: 0.3947
2022-10-02 05:10:33 - train: epoch 0238, iter [00020, 01251], lr: 0.000511, loss: 0.4095
2022-10-02 05:10:51 - train: epoch 0238, iter [00030, 01251], lr: 0.000511, loss: 0.4083
2022-10-02 05:11:09 - train: epoch 0238, iter [00040, 01251], lr: 0.000511, loss: 0.3956
2022-10-02 05:11:26 - train: epoch 0238, iter [00050, 01251], lr: 0.000511, loss: 0.4228
2022-10-02 05:11:44 - train: epoch 0238, iter [00060, 01251], lr: 0.000511, loss: 0.3997
2022-10-02 05:12:01 - train: epoch 0238, iter [00070, 01251], lr: 0.000511, loss: 0.4048
2022-10-02 05:12:19 - train: epoch 0238, iter [00080, 01251], lr: 0.000511, loss: 0.4137
2022-10-02 05:12:37 - train: epoch 0238, iter [00090, 01251], lr: 0.000511, loss: 0.4191
2022-10-02 05:12:54 - train: epoch 0238, iter [00100, 01251], lr: 0.000511, loss: 0.3980
2022-10-02 05:13:12 - train: epoch 0238, iter [00110, 01251], lr: 0.000511, loss: 0.3925
2022-10-02 05:13:30 - train: epoch 0238, iter [00120, 01251], lr: 0.000511, loss: 0.4211
2022-10-02 05:13:48 - train: epoch 0238, iter [00130, 01251], lr: 0.000511, loss: 0.3913
2022-10-02 05:14:05 - train: epoch 0238, iter [00140, 01251], lr: 0.000511, loss: 0.4199
2022-10-02 05:14:23 - train: epoch 0238, iter [00150, 01251], lr: 0.000511, loss: 0.4043
2022-10-02 05:14:41 - train: epoch 0238, iter [00160, 01251], lr: 0.000511, loss: 0.4056
2022-10-02 05:14:59 - train: epoch 0238, iter [00170, 01251], lr: 0.000511, loss: 0.4082
2022-10-02 05:15:17 - train: epoch 0238, iter [00180, 01251], lr: 0.000511, loss: 0.3995
2022-10-02 05:15:34 - train: epoch 0238, iter [00190, 01251], lr: 0.000511, loss: 0.4153
2022-10-02 05:15:52 - train: epoch 0238, iter [00200, 01251], lr: 0.000510, loss: 0.3992
2022-10-02 05:16:10 - train: epoch 0238, iter [00210, 01251], lr: 0.000510, loss: 0.4142
2022-10-02 05:16:28 - train: epoch 0238, iter [00220, 01251], lr: 0.000510, loss: 0.4062
2022-10-02 05:16:45 - train: epoch 0238, iter [00230, 01251], lr: 0.000510, loss: 0.4120
2022-10-02 05:17:03 - train: epoch 0238, iter [00240, 01251], lr: 0.000510, loss: 0.4130
2022-10-02 05:17:21 - train: epoch 0238, iter [00250, 01251], lr: 0.000510, loss: 0.4095
2022-10-02 05:17:38 - train: epoch 0238, iter [00260, 01251], lr: 0.000510, loss: 0.4149
2022-10-02 05:17:56 - train: epoch 0238, iter [00270, 01251], lr: 0.000510, loss: 0.4150
2022-10-02 05:18:14 - train: epoch 0238, iter [00280, 01251], lr: 0.000510, loss: 0.4065
2022-10-02 05:18:31 - train: epoch 0238, iter [00290, 01251], lr: 0.000510, loss: 0.4065
2022-10-02 05:18:49 - train: epoch 0238, iter [00300, 01251], lr: 0.000510, loss: 0.4141
2022-10-02 05:19:07 - train: epoch 0238, iter [00310, 01251], lr: 0.000510, loss: 0.4051
2022-10-02 05:19:25 - train: epoch 0238, iter [00320, 01251], lr: 0.000510, loss: 0.3949
2022-10-02 05:19:42 - train: epoch 0238, iter [00330, 01251], lr: 0.000510, loss: 0.4206
2022-10-02 05:20:00 - train: epoch 0238, iter [00340, 01251], lr: 0.000510, loss: 0.4062
2022-10-02 05:20:18 - train: epoch 0238, iter [00350, 01251], lr: 0.000510, loss: 0.4065
2022-10-02 05:20:35 - train: epoch 0238, iter [00360, 01251], lr: 0.000510, loss: 0.3904
2022-10-02 05:20:53 - train: epoch 0238, iter [00370, 01251], lr: 0.000510, loss: 0.4082
2022-10-02 05:21:11 - train: epoch 0238, iter [00380, 01251], lr: 0.000510, loss: 0.4114
2022-10-02 05:21:28 - train: epoch 0238, iter [00390, 01251], lr: 0.000510, loss: 0.3937
2022-10-02 05:21:46 - train: epoch 0238, iter [00400, 01251], lr: 0.000510, loss: 0.4140
2022-10-02 05:22:04 - train: epoch 0238, iter [00410, 01251], lr: 0.000510, loss: 0.4230
2022-10-02 05:22:21 - train: epoch 0238, iter [00420, 01251], lr: 0.000510, loss: 0.4044
2022-10-02 05:22:39 - train: epoch 0238, iter [00430, 01251], lr: 0.000510, loss: 0.4179
2022-10-02 05:22:57 - train: epoch 0238, iter [00440, 01251], lr: 0.000509, loss: 0.4026
2022-10-02 05:23:15 - train: epoch 0238, iter [00450, 01251], lr: 0.000509, loss: 0.3991
2022-10-02 05:23:32 - train: epoch 0238, iter [00460, 01251], lr: 0.000509, loss: 0.4202
2022-10-02 05:23:50 - train: epoch 0238, iter [00470, 01251], lr: 0.000509, loss: 0.4086
2022-10-02 05:24:08 - train: epoch 0238, iter [00480, 01251], lr: 0.000509, loss: 0.4204
2022-10-02 05:24:25 - train: epoch 0238, iter [00490, 01251], lr: 0.000509, loss: 0.3966
2022-10-02 05:24:43 - train: epoch 0238, iter [00500, 01251], lr: 0.000509, loss: 0.3968
2022-10-02 05:25:01 - train: epoch 0238, iter [00510, 01251], lr: 0.000509, loss: 0.4161
2022-10-02 05:25:18 - train: epoch 0238, iter [00520, 01251], lr: 0.000509, loss: 0.4063
2022-10-02 05:25:36 - train: epoch 0238, iter [00530, 01251], lr: 0.000509, loss: 0.4035
2022-10-02 05:25:54 - train: epoch 0238, iter [00540, 01251], lr: 0.000509, loss: 0.4085
2022-10-02 05:26:12 - train: epoch 0238, iter [00550, 01251], lr: 0.000509, loss: 0.4014
2022-10-02 05:26:29 - train: epoch 0238, iter [00560, 01251], lr: 0.000509, loss: 0.3991
2022-10-02 05:26:47 - train: epoch 0238, iter [00570, 01251], lr: 0.000509, loss: 0.4208
2022-10-02 05:27:04 - train: epoch 0238, iter [00580, 01251], lr: 0.000509, loss: 0.3925
2022-10-02 05:27:22 - train: epoch 0238, iter [00590, 01251], lr: 0.000509, loss: 0.3969
2022-10-02 05:27:40 - train: epoch 0238, iter [00600, 01251], lr: 0.000509, loss: 0.4119
2022-10-02 05:27:57 - train: epoch 0238, iter [00610, 01251], lr: 0.000509, loss: 0.3778
2022-10-02 05:28:15 - train: epoch 0238, iter [00620, 01251], lr: 0.000509, loss: 0.3851
2022-10-02 05:28:33 - train: epoch 0238, iter [00630, 01251], lr: 0.000509, loss: 0.4134
2022-10-02 05:28:51 - train: epoch 0238, iter [00640, 01251], lr: 0.000509, loss: 0.3894
2022-10-02 05:29:08 - train: epoch 0238, iter [00650, 01251], lr: 0.000509, loss: 0.4019
2022-10-02 05:29:26 - train: epoch 0238, iter [00660, 01251], lr: 0.000509, loss: 0.4062
2022-10-02 05:29:44 - train: epoch 0238, iter [00670, 01251], lr: 0.000509, loss: 0.4078
2022-10-02 05:30:01 - train: epoch 0238, iter [00680, 01251], lr: 0.000509, loss: 0.4085
2022-10-02 05:30:19 - train: epoch 0238, iter [00690, 01251], lr: 0.000508, loss: 0.4023
2022-10-02 05:30:37 - train: epoch 0238, iter [00700, 01251], lr: 0.000508, loss: 0.4135
2022-10-02 05:30:54 - train: epoch 0238, iter [00710, 01251], lr: 0.000508, loss: 0.3962
2022-10-02 05:31:12 - train: epoch 0238, iter [00720, 01251], lr: 0.000508, loss: 0.3932
2022-10-02 05:31:30 - train: epoch 0238, iter [00730, 01251], lr: 0.000508, loss: 0.4107
2022-10-02 05:31:48 - train: epoch 0238, iter [00740, 01251], lr: 0.000508, loss: 0.4082
2022-10-02 05:32:05 - train: epoch 0238, iter [00750, 01251], lr: 0.000508, loss: 0.3961
2022-10-02 05:32:23 - train: epoch 0238, iter [00760, 01251], lr: 0.000508, loss: 0.3786
2022-10-02 05:32:40 - train: epoch 0238, iter [00770, 01251], lr: 0.000508, loss: 0.4109
2022-10-02 05:32:58 - train: epoch 0238, iter [00780, 01251], lr: 0.000508, loss: 0.4049
2022-10-02 05:33:16 - train: epoch 0238, iter [00790, 01251], lr: 0.000508, loss: 0.4199
2022-10-02 05:33:33 - train: epoch 0238, iter [00800, 01251], lr: 0.000508, loss: 0.4039
2022-10-02 05:33:51 - train: epoch 0238, iter [00810, 01251], lr: 0.000508, loss: 0.4119
2022-10-02 05:34:09 - train: epoch 0238, iter [00820, 01251], lr: 0.000508, loss: 0.4089
2022-10-02 05:34:26 - train: epoch 0238, iter [00830, 01251], lr: 0.000508, loss: 0.4098
2022-10-02 05:34:44 - train: epoch 0238, iter [00840, 01251], lr: 0.000508, loss: 0.4035
2022-10-02 05:35:02 - train: epoch 0238, iter [00850, 01251], lr: 0.000508, loss: 0.4051
2022-10-02 05:35:19 - train: epoch 0238, iter [00860, 01251], lr: 0.000508, loss: 0.3829
2022-10-02 05:35:37 - train: epoch 0238, iter [00870, 01251], lr: 0.000508, loss: 0.3919
2022-10-02 05:35:55 - train: epoch 0238, iter [00880, 01251], lr: 0.000508, loss: 0.3917
2022-10-02 05:36:13 - train: epoch 0238, iter [00890, 01251], lr: 0.000508, loss: 0.3897
2022-10-02 05:36:30 - train: epoch 0238, iter [00900, 01251], lr: 0.000508, loss: 0.4032
2022-10-02 05:36:48 - train: epoch 0238, iter [00910, 01251], lr: 0.000508, loss: 0.4031
2022-10-02 05:37:06 - train: epoch 0238, iter [00920, 01251], lr: 0.000508, loss: 0.3922
2022-10-02 05:37:23 - train: epoch 0238, iter [00930, 01251], lr: 0.000507, loss: 0.3861
2022-10-02 05:37:41 - train: epoch 0238, iter [00940, 01251], lr: 0.000507, loss: 0.3828
2022-10-02 05:37:59 - train: epoch 0238, iter [00950, 01251], lr: 0.000507, loss: 0.3926
2022-10-02 05:38:16 - train: epoch 0238, iter [00960, 01251], lr: 0.000507, loss: 0.3970
2022-10-02 05:38:34 - train: epoch 0238, iter [00970, 01251], lr: 0.000507, loss: 0.4068
2022-10-02 05:38:52 - train: epoch 0238, iter [00980, 01251], lr: 0.000507, loss: 0.3812
2022-10-02 05:39:09 - train: epoch 0238, iter [00990, 01251], lr: 0.000507, loss: 0.4144
2022-10-02 05:39:27 - train: epoch 0238, iter [01000, 01251], lr: 0.000507, loss: 0.4113
2022-10-02 05:39:45 - train: epoch 0238, iter [01010, 01251], lr: 0.000507, loss: 0.4426
2022-10-02 05:40:03 - train: epoch 0238, iter [01020, 01251], lr: 0.000507, loss: 0.4084
2022-10-02 05:40:20 - train: epoch 0238, iter [01030, 01251], lr: 0.000507, loss: 0.3956
2022-10-02 05:40:38 - train: epoch 0238, iter [01040, 01251], lr: 0.000507, loss: 0.4006
2022-10-02 05:40:56 - train: epoch 0238, iter [01050, 01251], lr: 0.000507, loss: 0.4025
2022-10-02 05:41:13 - train: epoch 0238, iter [01060, 01251], lr: 0.000507, loss: 0.4021
2022-10-02 05:41:31 - train: epoch 0238, iter [01070, 01251], lr: 0.000507, loss: 0.3881
2022-10-02 05:41:49 - train: epoch 0238, iter [01080, 01251], lr: 0.000507, loss: 0.4091
2022-10-02 05:42:06 - train: epoch 0238, iter [01090, 01251], lr: 0.000507, loss: 0.4087
2022-10-02 05:42:24 - train: epoch 0238, iter [01100, 01251], lr: 0.000507, loss: 0.4054
2022-10-02 05:42:42 - train: epoch 0238, iter [01110, 01251], lr: 0.000507, loss: 0.3991
2022-10-02 05:42:59 - train: epoch 0238, iter [01120, 01251], lr: 0.000507, loss: 0.4129
2022-10-02 05:43:17 - train: epoch 0238, iter [01130, 01251], lr: 0.000507, loss: 0.4126
2022-10-02 05:43:35 - train: epoch 0238, iter [01140, 01251], lr: 0.000507, loss: 0.4019
2022-10-02 05:43:52 - train: epoch 0238, iter [01150, 01251], lr: 0.000507, loss: 0.3983
2022-10-02 05:44:10 - train: epoch 0238, iter [01160, 01251], lr: 0.000507, loss: 0.4138
2022-10-02 05:44:28 - train: epoch 0238, iter [01170, 01251], lr: 0.000506, loss: 0.4015
2022-10-02 05:44:46 - train: epoch 0238, iter [01180, 01251], lr: 0.000506, loss: 0.3995
2022-10-02 05:45:03 - train: epoch 0238, iter [01190, 01251], lr: 0.000506, loss: 0.4180
2022-10-02 05:45:21 - train: epoch 0238, iter [01200, 01251], lr: 0.000506, loss: 0.4122
2022-10-02 05:45:39 - train: epoch 0238, iter [01210, 01251], lr: 0.000506, loss: 0.4122
2022-10-02 05:45:56 - train: epoch 0238, iter [01220, 01251], lr: 0.000506, loss: 0.3922
2022-10-02 05:46:14 - train: epoch 0238, iter [01230, 01251], lr: 0.000506, loss: 0.3923
2022-10-02 05:46:32 - train: epoch 0238, iter [01240, 01251], lr: 0.000506, loss: 0.3975
2022-10-02 05:46:49 - train: epoch 0238, iter [01250, 01251], lr: 0.000506, loss: 0.4159
2022-10-02 05:46:52 - train: epoch 238, train_loss: 0.4039
2022-10-02 05:46:55 - until epoch: 238, best_loss: 0.4039
2022-10-02 05:46:55 - epoch 239 lr: 0.000506
2022-10-02 05:47:21 - train: epoch 0239, iter [00010, 01251], lr: 0.000506, loss: 0.3960
2022-10-02 05:47:38 - train: epoch 0239, iter [00020, 01251], lr: 0.000506, loss: 0.3853
2022-10-02 05:47:56 - train: epoch 0239, iter [00030, 01251], lr: 0.000506, loss: 0.3979
2022-10-02 05:48:14 - train: epoch 0239, iter [00040, 01251], lr: 0.000506, loss: 0.4018
2022-10-02 05:48:31 - train: epoch 0239, iter [00050, 01251], lr: 0.000506, loss: 0.3885
2022-10-02 05:48:49 - train: epoch 0239, iter [00060, 01251], lr: 0.000506, loss: 0.3849
2022-10-02 05:49:06 - train: epoch 0239, iter [00070, 01251], lr: 0.000506, loss: 0.4067
2022-10-02 05:49:24 - train: epoch 0239, iter [00080, 01251], lr: 0.000506, loss: 0.4158
2022-10-02 05:49:42 - train: epoch 0239, iter [00090, 01251], lr: 0.000506, loss: 0.4022
2022-10-02 05:49:59 - train: epoch 0239, iter [00100, 01251], lr: 0.000506, loss: 0.3806
2022-10-02 05:50:17 - train: epoch 0239, iter [00110, 01251], lr: 0.000506, loss: 0.3945
2022-10-02 05:50:35 - train: epoch 0239, iter [00120, 01251], lr: 0.000506, loss: 0.4175
2022-10-02 05:50:52 - train: epoch 0239, iter [00130, 01251], lr: 0.000506, loss: 0.4008
2022-10-02 05:51:10 - train: epoch 0239, iter [00140, 01251], lr: 0.000506, loss: 0.4028
2022-10-02 05:51:28 - train: epoch 0239, iter [00150, 01251], lr: 0.000506, loss: 0.3960
2022-10-02 05:51:45 - train: epoch 0239, iter [00160, 01251], lr: 0.000505, loss: 0.4094
2022-10-02 05:52:03 - train: epoch 0239, iter [00170, 01251], lr: 0.000505, loss: 0.4091
2022-10-02 05:52:21 - train: epoch 0239, iter [00180, 01251], lr: 0.000505, loss: 0.3892
2022-10-02 05:52:38 - train: epoch 0239, iter [00190, 01251], lr: 0.000505, loss: 0.3965
2022-10-02 05:52:56 - train: epoch 0239, iter [00200, 01251], lr: 0.000505, loss: 0.4054
2022-10-02 05:53:14 - train: epoch 0239, iter [00210, 01251], lr: 0.000505, loss: 0.3954
2022-10-02 05:53:31 - train: epoch 0239, iter [00220, 01251], lr: 0.000505, loss: 0.3872
2022-10-02 05:53:49 - train: epoch 0239, iter [00230, 01251], lr: 0.000505, loss: 0.3860
2022-10-02 05:54:07 - train: epoch 0239, iter [00240, 01251], lr: 0.000505, loss: 0.3974
2022-10-02 05:54:24 - train: epoch 0239, iter [00250, 01251], lr: 0.000505, loss: 0.4175
2022-10-02 05:54:42 - train: epoch 0239, iter [00260, 01251], lr: 0.000505, loss: 0.3793
2022-10-02 05:55:00 - train: epoch 0239, iter [00270, 01251], lr: 0.000505, loss: 0.4089
2022-10-02 05:55:18 - train: epoch 0239, iter [00280, 01251], lr: 0.000505, loss: 0.3892
2022-10-02 05:55:35 - train: epoch 0239, iter [00290, 01251], lr: 0.000505, loss: 0.3948
2022-10-02 05:55:53 - train: epoch 0239, iter [00300, 01251], lr: 0.000505, loss: 0.4057
2022-10-02 05:56:11 - train: epoch 0239, iter [00310, 01251], lr: 0.000505, loss: 0.4004
2022-10-02 05:56:28 - train: epoch 0239, iter [00320, 01251], lr: 0.000505, loss: 0.4022
2022-10-02 05:56:46 - train: epoch 0239, iter [00330, 01251], lr: 0.000505, loss: 0.3981
2022-10-02 05:57:04 - train: epoch 0239, iter [00340, 01251], lr: 0.000505, loss: 0.4358
2022-10-02 05:57:21 - train: epoch 0239, iter [00350, 01251], lr: 0.000505, loss: 0.3789
2022-10-02 05:57:39 - train: epoch 0239, iter [00360, 01251], lr: 0.000505, loss: 0.3889
2022-10-02 05:57:57 - train: epoch 0239, iter [00370, 01251], lr: 0.000505, loss: 0.3958
2022-10-02 05:58:15 - train: epoch 0239, iter [00380, 01251], lr: 0.000505, loss: 0.4279
2022-10-02 05:58:32 - train: epoch 0239, iter [00390, 01251], lr: 0.000505, loss: 0.4025
2022-10-02 05:58:50 - train: epoch 0239, iter [00400, 01251], lr: 0.000504, loss: 0.4067
2022-10-02 05:59:08 - train: epoch 0239, iter [00410, 01251], lr: 0.000504, loss: 0.4202
2022-10-02 05:59:26 - train: epoch 0239, iter [00420, 01251], lr: 0.000504, loss: 0.3964
2022-10-02 05:59:43 - train: epoch 0239, iter [00430, 01251], lr: 0.000504, loss: 0.4140
2022-10-02 06:00:01 - train: epoch 0239, iter [00440, 01251], lr: 0.000504, loss: 0.4106
2022-10-02 06:00:19 - train: epoch 0239, iter [00450, 01251], lr: 0.000504, loss: 0.4174
2022-10-02 06:00:37 - train: epoch 0239, iter [00460, 01251], lr: 0.000504, loss: 0.4185
2022-10-02 06:00:54 - train: epoch 0239, iter [00470, 01251], lr: 0.000504, loss: 0.4094
2022-10-02 06:01:12 - train: epoch 0239, iter [00480, 01251], lr: 0.000504, loss: 0.4263
2022-10-02 06:01:29 - train: epoch 0239, iter [00490, 01251], lr: 0.000504, loss: 0.4210
2022-10-02 06:01:47 - train: epoch 0239, iter [00500, 01251], lr: 0.000504, loss: 0.4168
2022-10-02 06:02:05 - train: epoch 0239, iter [00510, 01251], lr: 0.000504, loss: 0.4171
2022-10-02 06:02:23 - train: epoch 0239, iter [00520, 01251], lr: 0.000504, loss: 0.4065
2022-10-02 06:02:40 - train: epoch 0239, iter [00530, 01251], lr: 0.000504, loss: 0.4193
2022-10-02 06:02:58 - train: epoch 0239, iter [00540, 01251], lr: 0.000504, loss: 0.4103
2022-10-02 06:03:16 - train: epoch 0239, iter [00550, 01251], lr: 0.000504, loss: 0.3990
2022-10-02 06:03:34 - train: epoch 0239, iter [00560, 01251], lr: 0.000504, loss: 0.3958
2022-10-02 06:03:52 - train: epoch 0239, iter [00570, 01251], lr: 0.000504, loss: 0.4047
2022-10-02 06:04:09 - train: epoch 0239, iter [00580, 01251], lr: 0.000504, loss: 0.4193
2022-10-02 06:04:27 - train: epoch 0239, iter [00590, 01251], lr: 0.000504, loss: 0.4015
2022-10-02 06:04:45 - train: epoch 0239, iter [00600, 01251], lr: 0.000504, loss: 0.4022
2022-10-02 06:05:02 - train: epoch 0239, iter [00610, 01251], lr: 0.000504, loss: 0.3939
2022-10-02 06:05:20 - train: epoch 0239, iter [00620, 01251], lr: 0.000504, loss: 0.3944
2022-10-02 06:05:38 - train: epoch 0239, iter [00630, 01251], lr: 0.000504, loss: 0.4160
2022-10-02 06:05:56 - train: epoch 0239, iter [00640, 01251], lr: 0.000503, loss: 0.3995
2022-10-02 06:06:13 - train: epoch 0239, iter [00650, 01251], lr: 0.000503, loss: 0.4084
2022-10-02 06:06:31 - train: epoch 0239, iter [00660, 01251], lr: 0.000503, loss: 0.4139
2022-10-02 06:06:49 - train: epoch 0239, iter [00670, 01251], lr: 0.000503, loss: 0.3973
2022-10-02 06:07:07 - train: epoch 0239, iter [00680, 01251], lr: 0.000503, loss: 0.4011
2022-10-02 06:07:24 - train: epoch 0239, iter [00690, 01251], lr: 0.000503, loss: 0.4296
2022-10-02 06:07:42 - train: epoch 0239, iter [00700, 01251], lr: 0.000503, loss: 0.3966
2022-10-02 06:08:00 - train: epoch 0239, iter [00710, 01251], lr: 0.000503, loss: 0.4163
2022-10-02 06:08:17 - train: epoch 0239, iter [00720, 01251], lr: 0.000503, loss: 0.4040
2022-10-02 06:08:35 - train: epoch 0239, iter [00730, 01251], lr: 0.000503, loss: 0.3961
2022-10-02 06:08:53 - train: epoch 0239, iter [00740, 01251], lr: 0.000503, loss: 0.4227
2022-10-02 06:09:10 - train: epoch 0239, iter [00750, 01251], lr: 0.000503, loss: 0.3971
2022-10-02 06:09:28 - train: epoch 0239, iter [00760, 01251], lr: 0.000503, loss: 0.3787
2022-10-02 06:09:46 - train: epoch 0239, iter [00770, 01251], lr: 0.000503, loss: 0.4013
2022-10-02 06:10:03 - train: epoch 0239, iter [00780, 01251], lr: 0.000503, loss: 0.4001
2022-10-02 06:10:21 - train: epoch 0239, iter [00790, 01251], lr: 0.000503, loss: 0.4169
2022-10-02 06:10:39 - train: epoch 0239, iter [00800, 01251], lr: 0.000503, loss: 0.4023
2022-10-02 06:10:56 - train: epoch 0239, iter [00810, 01251], lr: 0.000503, loss: 0.3949
2022-10-02 06:11:14 - train: epoch 0239, iter [00820, 01251], lr: 0.000503, loss: 0.3982
2022-10-02 06:11:32 - train: epoch 0239, iter [00830, 01251], lr: 0.000503, loss: 0.4065
2022-10-02 06:11:49 - train: epoch 0239, iter [00840, 01251], lr: 0.000503, loss: 0.4184
2022-10-02 06:12:07 - train: epoch 0239, iter [00850, 01251], lr: 0.000503, loss: 0.3931
2022-10-02 06:12:25 - train: epoch 0239, iter [00860, 01251], lr: 0.000503, loss: 0.4006
2022-10-02 06:12:42 - train: epoch 0239, iter [00870, 01251], lr: 0.000503, loss: 0.3893
2022-10-02 06:13:00 - train: epoch 0239, iter [00880, 01251], lr: 0.000503, loss: 0.4160
2022-10-02 06:13:18 - train: epoch 0239, iter [00890, 01251], lr: 0.000502, loss: 0.4020
2022-10-02 06:13:35 - train: epoch 0239, iter [00900, 01251], lr: 0.000502, loss: 0.3962
2022-10-02 06:13:53 - train: epoch 0239, iter [00910, 01251], lr: 0.000502, loss: 0.4131
2022-10-02 06:14:11 - train: epoch 0239, iter [00920, 01251], lr: 0.000502, loss: 0.3999
2022-10-02 06:14:28 - train: epoch 0239, iter [00930, 01251], lr: 0.000502, loss: 0.4100
2022-10-02 06:14:46 - train: epoch 0239, iter [00940, 01251], lr: 0.000502, loss: 0.4018
2022-10-02 06:15:04 - train: epoch 0239, iter [00950, 01251], lr: 0.000502, loss: 0.3989
2022-10-02 06:15:21 - train: epoch 0239, iter [00960, 01251], lr: 0.000502, loss: 0.4226
2022-10-02 06:15:39 - train: epoch 0239, iter [00970, 01251], lr: 0.000502, loss: 0.4003
2022-10-02 06:15:57 - train: epoch 0239, iter [00980, 01251], lr: 0.000502, loss: 0.4016
2022-10-02 06:16:15 - train: epoch 0239, iter [00990, 01251], lr: 0.000502, loss: 0.4140
2022-10-02 06:16:32 - train: epoch 0239, iter [01000, 01251], lr: 0.000502, loss: 0.4000
2022-10-02 06:16:50 - train: epoch 0239, iter [01010, 01251], lr: 0.000502, loss: 0.4040
2022-10-02 06:17:08 - train: epoch 0239, iter [01020, 01251], lr: 0.000502, loss: 0.3795
2022-10-02 06:17:25 - train: epoch 0239, iter [01030, 01251], lr: 0.000502, loss: 0.3969
2022-10-02 06:17:43 - train: epoch 0239, iter [01040, 01251], lr: 0.000502, loss: 0.4188
2022-10-02 06:18:01 - train: epoch 0239, iter [01050, 01251], lr: 0.000502, loss: 0.4054
2022-10-02 06:18:18 - train: epoch 0239, iter [01060, 01251], lr: 0.000502, loss: 0.4209
2022-10-02 06:18:36 - train: epoch 0239, iter [01070, 01251], lr: 0.000502, loss: 0.4225
2022-10-02 06:18:54 - train: epoch 0239, iter [01080, 01251], lr: 0.000502, loss: 0.4015
2022-10-02 06:19:12 - train: epoch 0239, iter [01090, 01251], lr: 0.000502, loss: 0.4192
2022-10-02 06:19:29 - train: epoch 0239, iter [01100, 01251], lr: 0.000502, loss: 0.3938
2022-10-02 06:19:47 - train: epoch 0239, iter [01110, 01251], lr: 0.000502, loss: 0.4085
2022-10-02 06:20:05 - train: epoch 0239, iter [01120, 01251], lr: 0.000502, loss: 0.3931
2022-10-02 06:20:22 - train: epoch 0239, iter [01130, 01251], lr: 0.000501, loss: 0.4078
2022-10-02 06:20:40 - train: epoch 0239, iter [01140, 01251], lr: 0.000501, loss: 0.4073
2022-10-02 06:20:58 - train: epoch 0239, iter [01150, 01251], lr: 0.000501, loss: 0.4044
2022-10-02 06:21:16 - train: epoch 0239, iter [01160, 01251], lr: 0.000501, loss: 0.3949
2022-10-02 06:21:33 - train: epoch 0239, iter [01170, 01251], lr: 0.000501, loss: 0.4234
2022-10-02 06:21:51 - train: epoch 0239, iter [01180, 01251], lr: 0.000501, loss: 0.4019
2022-10-02 06:22:09 - train: epoch 0239, iter [01190, 01251], lr: 0.000501, loss: 0.4194
2022-10-02 06:22:26 - train: epoch 0239, iter [01200, 01251], lr: 0.000501, loss: 0.3895
2022-10-02 06:22:44 - train: epoch 0239, iter [01210, 01251], lr: 0.000501, loss: 0.4006
2022-10-02 06:23:01 - train: epoch 0239, iter [01220, 01251], lr: 0.000501, loss: 0.4076
2022-10-02 06:23:19 - train: epoch 0239, iter [01230, 01251], lr: 0.000501, loss: 0.4115
2022-10-02 06:23:37 - train: epoch 0239, iter [01240, 01251], lr: 0.000501, loss: 0.4178
2022-10-02 06:23:54 - train: epoch 0239, iter [01250, 01251], lr: 0.000501, loss: 0.4021
2022-10-02 06:23:57 - train: epoch 239, train_loss: 0.4039
2022-10-02 06:24:00 - until epoch: 239, best_loss: 0.4039
2022-10-02 06:24:00 - epoch 240 lr: 0.000501
2022-10-02 06:24:26 - train: epoch 0240, iter [00010, 01251], lr: 0.000501, loss: 0.4148
2022-10-02 06:24:43 - train: epoch 0240, iter [00020, 01251], lr: 0.000501, loss: 0.3794
2022-10-02 06:25:01 - train: epoch 0240, iter [00030, 01251], lr: 0.000501, loss: 0.4270
2022-10-02 06:25:18 - train: epoch 0240, iter [00040, 01251], lr: 0.000501, loss: 0.3897
2022-10-02 06:25:36 - train: epoch 0240, iter [00050, 01251], lr: 0.000501, loss: 0.3980
2022-10-02 06:25:54 - train: epoch 0240, iter [00060, 01251], lr: 0.000501, loss: 0.4174
2022-10-02 06:26:11 - train: epoch 0240, iter [00070, 01251], lr: 0.000501, loss: 0.4010
2022-10-02 06:26:29 - train: epoch 0240, iter [00080, 01251], lr: 0.000501, loss: 0.4221
2022-10-02 06:26:47 - train: epoch 0240, iter [00090, 01251], lr: 0.000501, loss: 0.3977
2022-10-02 06:27:05 - train: epoch 0240, iter [00100, 01251], lr: 0.000501, loss: 0.4034
2022-10-02 06:27:22 - train: epoch 0240, iter [00110, 01251], lr: 0.000501, loss: 0.3930
2022-10-02 06:27:40 - train: epoch 0240, iter [00120, 01251], lr: 0.000500, loss: 0.3828
2022-10-02 06:27:58 - train: epoch 0240, iter [00130, 01251], lr: 0.000500, loss: 0.3978
2022-10-02 06:28:15 - train: epoch 0240, iter [00140, 01251], lr: 0.000500, loss: 0.4112
2022-10-02 06:28:33 - train: epoch 0240, iter [00150, 01251], lr: 0.000500, loss: 0.4029
2022-10-02 06:28:51 - train: epoch 0240, iter [00160, 01251], lr: 0.000500, loss: 0.4000
2022-10-02 06:29:09 - train: epoch 0240, iter [00170, 01251], lr: 0.000500, loss: 0.4024
2022-10-02 06:29:26 - train: epoch 0240, iter [00180, 01251], lr: 0.000500, loss: 0.4264
2022-10-02 06:29:44 - train: epoch 0240, iter [00190, 01251], lr: 0.000500, loss: 0.4174
2022-10-02 06:30:02 - train: epoch 0240, iter [00200, 01251], lr: 0.000500, loss: 0.3768
2022-10-02 06:30:20 - train: epoch 0240, iter [00210, 01251], lr: 0.000500, loss: 0.3914
2022-10-02 06:30:37 - train: epoch 0240, iter [00220, 01251], lr: 0.000500, loss: 0.3852
2022-10-02 06:30:55 - train: epoch 0240, iter [00230, 01251], lr: 0.000500, loss: 0.3853
2022-10-02 06:31:13 - train: epoch 0240, iter [00240, 01251], lr: 0.000500, loss: 0.3901
2022-10-02 06:31:30 - train: epoch 0240, iter [00250, 01251], lr: 0.000500, loss: 0.4140
2022-10-02 06:31:48 - train: epoch 0240, iter [00260, 01251], lr: 0.000500, loss: 0.4049
2022-10-02 06:32:06 - train: epoch 0240, iter [00270, 01251], lr: 0.000500, loss: 0.4185
2022-10-02 06:32:23 - train: epoch 0240, iter [00280, 01251], lr: 0.000500, loss: 0.4005
2022-10-02 06:32:41 - train: epoch 0240, iter [00290, 01251], lr: 0.000500, loss: 0.4032
2022-10-02 06:32:59 - train: epoch 0240, iter [00300, 01251], lr: 0.000500, loss: 0.3905
2022-10-02 06:33:16 - train: epoch 0240, iter [00310, 01251], lr: 0.000500, loss: 0.4077
2022-10-02 06:33:34 - train: epoch 0240, iter [00320, 01251], lr: 0.000500, loss: 0.4136
2022-10-02 06:33:52 - train: epoch 0240, iter [00330, 01251], lr: 0.000500, loss: 0.4021
2022-10-02 06:34:09 - train: epoch 0240, iter [00340, 01251], lr: 0.000500, loss: 0.4203
2022-10-02 06:34:27 - train: epoch 0240, iter [00350, 01251], lr: 0.000500, loss: 0.3943
2022-10-02 06:34:45 - train: epoch 0240, iter [00360, 01251], lr: 0.000499, loss: 0.3934
2022-10-02 06:35:03 - train: epoch 0240, iter [00370, 01251], lr: 0.000499, loss: 0.3987
2022-10-02 06:35:20 - train: epoch 0240, iter [00380, 01251], lr: 0.000499, loss: 0.4248
2022-10-02 06:35:38 - train: epoch 0240, iter [00390, 01251], lr: 0.000499, loss: 0.3822
2022-10-02 06:35:55 - train: epoch 0240, iter [00400, 01251], lr: 0.000499, loss: 0.4169
2022-10-02 06:36:13 - train: epoch 0240, iter [00410, 01251], lr: 0.000499, loss: 0.4029
2022-10-02 06:36:31 - train: epoch 0240, iter [00420, 01251], lr: 0.000499, loss: 0.4033
2022-10-02 06:36:49 - train: epoch 0240, iter [00430, 01251], lr: 0.000499, loss: 0.3986
2022-10-02 06:37:06 - train: epoch 0240, iter [00440, 01251], lr: 0.000499, loss: 0.4148
2022-10-02 06:37:24 - train: epoch 0240, iter [00450, 01251], lr: 0.000499, loss: 0.4117
2022-10-02 06:37:42 - train: epoch 0240, iter [00460, 01251], lr: 0.000499, loss: 0.4057
2022-10-02 06:37:59 - train: epoch 0240, iter [00470, 01251], lr: 0.000499, loss: 0.3913
2022-10-02 06:38:17 - train: epoch 0240, iter [00480, 01251], lr: 0.000499, loss: 0.3946
2022-10-02 06:38:35 - train: epoch 0240, iter [00490, 01251], lr: 0.000499, loss: 0.3855
2022-10-02 06:38:53 - train: epoch 0240, iter [00500, 01251], lr: 0.000499, loss: 0.4099
2022-10-02 06:39:10 - train: epoch 0240, iter [00510, 01251], lr: 0.000499, loss: 0.4024
2022-10-02 06:39:28 - train: epoch 0240, iter [00520, 01251], lr: 0.000499, loss: 0.4237
2022-10-02 06:39:46 - train: epoch 0240, iter [00530, 01251], lr: 0.000499, loss: 0.4039
2022-10-02 06:40:03 - train: epoch 0240, iter [00540, 01251], lr: 0.000499, loss: 0.3985
2022-10-02 06:40:21 - train: epoch 0240, iter [00550, 01251], lr: 0.000499, loss: 0.3969
2022-10-02 06:40:38 - train: epoch 0240, iter [00560, 01251], lr: 0.000499, loss: 0.4012
2022-10-02 06:40:56 - train: epoch 0240, iter [00570, 01251], lr: 0.000499, loss: 0.4228
2022-10-02 06:41:14 - train: epoch 0240, iter [00580, 01251], lr: 0.000499, loss: 0.4128
2022-10-02 06:41:32 - train: epoch 0240, iter [00590, 01251], lr: 0.000499, loss: 0.3867
2022-10-02 06:41:49 - train: epoch 0240, iter [00600, 01251], lr: 0.000498, loss: 0.4191
2022-10-02 06:42:07 - train: epoch 0240, iter [00610, 01251], lr: 0.000498, loss: 0.4073
2022-10-02 06:42:25 - train: epoch 0240, iter [00620, 01251], lr: 0.000498, loss: 0.3920
2022-10-02 06:42:43 - train: epoch 0240, iter [00630, 01251], lr: 0.000498, loss: 0.4010
2022-10-02 06:43:00 - train: epoch 0240, iter [00640, 01251], lr: 0.000498, loss: 0.4097
2022-10-02 06:43:18 - train: epoch 0240, iter [00650, 01251], lr: 0.000498, loss: 0.4102
2022-10-02 06:43:36 - train: epoch 0240, iter [00660, 01251], lr: 0.000498, loss: 0.3972
2022-10-02 06:43:53 - train: epoch 0240, iter [00670, 01251], lr: 0.000498, loss: 0.3999
2022-10-02 06:44:11 - train: epoch 0240, iter [00680, 01251], lr: 0.000498, loss: 0.4037
2022-10-02 06:44:29 - train: epoch 0240, iter [00690, 01251], lr: 0.000498, loss: 0.4014
2022-10-02 06:44:47 - train: epoch 0240, iter [00700, 01251], lr: 0.000498, loss: 0.4050
2022-10-02 06:45:04 - train: epoch 0240, iter [00710, 01251], lr: 0.000498, loss: 0.3972
2022-10-02 06:45:22 - train: epoch 0240, iter [00720, 01251], lr: 0.000498, loss: 0.4108
2022-10-02 06:45:40 - train: epoch 0240, iter [00730, 01251], lr: 0.000498, loss: 0.4050
2022-10-02 06:45:57 - train: epoch 0240, iter [00740, 01251], lr: 0.000498, loss: 0.4060
2022-10-02 06:46:15 - train: epoch 0240, iter [00750, 01251], lr: 0.000498, loss: 0.3962
2022-10-02 06:46:33 - train: epoch 0240, iter [00760, 01251], lr: 0.000498, loss: 0.4027
2022-10-02 06:46:50 - train: epoch 0240, iter [00770, 01251], lr: 0.000498, loss: 0.3907
2022-10-02 06:47:08 - train: epoch 0240, iter [00780, 01251], lr: 0.000498, loss: 0.4108
2022-10-02 06:47:26 - train: epoch 0240, iter [00790, 01251], lr: 0.000498, loss: 0.4163
2022-10-02 06:47:44 - train: epoch 0240, iter [00800, 01251], lr: 0.000498, loss: 0.3991
2022-10-02 06:48:01 - train: epoch 0240, iter [00810, 01251], lr: 0.000498, loss: 0.4125
2022-10-02 06:48:19 - train: epoch 0240, iter [00820, 01251], lr: 0.000498, loss: 0.4231
2022-10-02 06:48:37 - train: epoch 0240, iter [00830, 01251], lr: 0.000498, loss: 0.3804
2022-10-02 06:48:54 - train: epoch 0240, iter [00840, 01251], lr: 0.000498, loss: 0.4065
2022-10-02 06:49:12 - train: epoch 0240, iter [00850, 01251], lr: 0.000497, loss: 0.3794
2022-10-02 06:49:30 - train: epoch 0240, iter [00860, 01251], lr: 0.000497, loss: 0.3950
2022-10-02 06:49:47 - train: epoch 0240, iter [00870, 01251], lr: 0.000497, loss: 0.3983
2022-10-02 06:50:05 - train: epoch 0240, iter [00880, 01251], lr: 0.000497, loss: 0.4115
2022-10-02 06:50:23 - train: epoch 0240, iter [00890, 01251], lr: 0.000497, loss: 0.3981
2022-10-02 06:50:41 - train: epoch 0240, iter [00900, 01251], lr: 0.000497, loss: 0.3796
2022-10-02 06:50:58 - train: epoch 0240, iter [00910, 01251], lr: 0.000497, loss: 0.4108
2022-10-02 06:51:16 - train: epoch 0240, iter [00920, 01251], lr: 0.000497, loss: 0.4035
2022-10-02 06:51:34 - train: epoch 0240, iter [00930, 01251], lr: 0.000497, loss: 0.4129
2022-10-02 06:51:51 - train: epoch 0240, iter [00940, 01251], lr: 0.000497, loss: 0.4072
2022-10-02 06:52:09 - train: epoch 0240, iter [00950, 01251], lr: 0.000497, loss: 0.4163
2022-10-02 06:52:27 - train: epoch 0240, iter [00960, 01251], lr: 0.000497, loss: 0.3841
2022-10-02 06:52:44 - train: epoch 0240, iter [00970, 01251], lr: 0.000497, loss: 0.4028
2022-10-02 06:53:02 - train: epoch 0240, iter [00980, 01251], lr: 0.000497, loss: 0.3965
2022-10-02 06:53:20 - train: epoch 0240, iter [00990, 01251], lr: 0.000497, loss: 0.3856
2022-10-02 06:53:38 - train: epoch 0240, iter [01000, 01251], lr: 0.000497, loss: 0.4032
2022-10-02 06:53:55 - train: epoch 0240, iter [01010, 01251], lr: 0.000497, loss: 0.4046
2022-10-02 06:54:13 - train: epoch 0240, iter [01020, 01251], lr: 0.000497, loss: 0.4224
2022-10-02 06:54:31 - train: epoch 0240, iter [01030, 01251], lr: 0.000497, loss: 0.4001
2022-10-02 06:54:48 - train: epoch 0240, iter [01040, 01251], lr: 0.000497, loss: 0.4109
2022-10-02 06:55:06 - train: epoch 0240, iter [01050, 01251], lr: 0.000497, loss: 0.3989
2022-10-02 06:55:24 - train: epoch 0240, iter [01060, 01251], lr: 0.000497, loss: 0.3916
2022-10-02 06:55:41 - train: epoch 0240, iter [01070, 01251], lr: 0.000497, loss: 0.4121
2022-10-02 06:55:59 - train: epoch 0240, iter [01080, 01251], lr: 0.000497, loss: 0.3902
2022-10-02 06:56:17 - train: epoch 0240, iter [01090, 01251], lr: 0.000496, loss: 0.4100
2022-10-02 06:56:35 - train: epoch 0240, iter [01100, 01251], lr: 0.000496, loss: 0.3938
2022-10-02 06:56:52 - train: epoch 0240, iter [01110, 01251], lr: 0.000496, loss: 0.3985
2022-10-02 06:57:10 - train: epoch 0240, iter [01120, 01251], lr: 0.000496, loss: 0.3975
2022-10-02 06:57:28 - train: epoch 0240, iter [01130, 01251], lr: 0.000496, loss: 0.4085
2022-10-02 06:57:46 - train: epoch 0240, iter [01140, 01251], lr: 0.000496, loss: 0.4065
2022-10-02 06:58:03 - train: epoch 0240, iter [01150, 01251], lr: 0.000496, loss: 0.3994
2022-10-02 06:58:21 - train: epoch 0240, iter [01160, 01251], lr: 0.000496, loss: 0.4146
2022-10-02 06:58:39 - train: epoch 0240, iter [01170, 01251], lr: 0.000496, loss: 0.4001
2022-10-02 06:58:57 - train: epoch 0240, iter [01180, 01251], lr: 0.000496, loss: 0.4054
2022-10-02 06:59:14 - train: epoch 0240, iter [01190, 01251], lr: 0.000496, loss: 0.3761
2022-10-02 06:59:32 - train: epoch 0240, iter [01200, 01251], lr: 0.000496, loss: 0.4097
2022-10-02 06:59:50 - train: epoch 0240, iter [01210, 01251], lr: 0.000496, loss: 0.4048
2022-10-02 07:00:07 - train: epoch 0240, iter [01220, 01251], lr: 0.000496, loss: 0.3836
2022-10-02 07:00:25 - train: epoch 0240, iter [01230, 01251], lr: 0.000496, loss: 0.3973
2022-10-02 07:00:43 - train: epoch 0240, iter [01240, 01251], lr: 0.000496, loss: 0.4054
2022-10-02 07:01:00 - train: epoch 0240, iter [01250, 01251], lr: 0.000496, loss: 0.3991
2022-10-02 07:01:03 - train: epoch 240, train_loss: 0.4038
2022-10-02 07:01:06 - until epoch: 240, best_loss: 0.4038
2022-10-02 07:01:06 - epoch 241 lr: 0.000496
2022-10-02 07:01:32 - train: epoch 0241, iter [00010, 01251], lr: 0.000496, loss: 0.4095
2022-10-02 07:01:50 - train: epoch 0241, iter [00020, 01251], lr: 0.000496, loss: 0.4041
2022-10-02 07:02:07 - train: epoch 0241, iter [00030, 01251], lr: 0.000496, loss: 0.3922
2022-10-02 07:02:25 - train: epoch 0241, iter [00040, 01251], lr: 0.000496, loss: 0.4030
2022-10-02 07:02:43 - train: epoch 0241, iter [00050, 01251], lr: 0.000496, loss: 0.4192
2022-10-02 07:03:00 - train: epoch 0241, iter [00060, 01251], lr: 0.000496, loss: 0.4033
2022-10-02 07:03:18 - train: epoch 0241, iter [00070, 01251], lr: 0.000496, loss: 0.4110
2022-10-02 07:03:36 - train: epoch 0241, iter [00080, 01251], lr: 0.000495, loss: 0.4010
2022-10-02 07:03:54 - train: epoch 0241, iter [00090, 01251], lr: 0.000495, loss: 0.4193
2022-10-02 07:04:11 - train: epoch 0241, iter [00100, 01251], lr: 0.000495, loss: 0.4121
2022-10-02 07:04:29 - train: epoch 0241, iter [00110, 01251], lr: 0.000495, loss: 0.3880
2022-10-02 07:04:47 - train: epoch 0241, iter [00120, 01251], lr: 0.000495, loss: 0.4027
2022-10-02 07:05:05 - train: epoch 0241, iter [00130, 01251], lr: 0.000495, loss: 0.4002
2022-10-02 07:05:22 - train: epoch 0241, iter [00140, 01251], lr: 0.000495, loss: 0.4022
2022-10-02 07:05:40 - train: epoch 0241, iter [00150, 01251], lr: 0.000495, loss: 0.4078
2022-10-02 07:05:57 - train: epoch 0241, iter [00160, 01251], lr: 0.000495, loss: 0.4043
2022-10-02 07:06:15 - train: epoch 0241, iter [00170, 01251], lr: 0.000495, loss: 0.4103
2022-10-02 07:06:33 - train: epoch 0241, iter [00180, 01251], lr: 0.000495, loss: 0.4121
2022-10-02 07:06:50 - train: epoch 0241, iter [00190, 01251], lr: 0.000495, loss: 0.3998
2022-10-02 07:07:08 - train: epoch 0241, iter [00200, 01251], lr: 0.000495, loss: 0.4061
2022-10-02 07:07:25 - train: epoch 0241, iter [00210, 01251], lr: 0.000495, loss: 0.4072
2022-10-02 07:07:43 - train: epoch 0241, iter [00220, 01251], lr: 0.000495, loss: 0.4119
2022-10-02 07:08:01 - train: epoch 0241, iter [00230, 01251], lr: 0.000495, loss: 0.3873
2022-10-02 07:08:19 - train: epoch 0241, iter [00240, 01251], lr: 0.000495, loss: 0.3847
2022-10-02 07:08:36 - train: epoch 0241, iter [00250, 01251], lr: 0.000495, loss: 0.4000
2022-10-02 07:08:54 - train: epoch 0241, iter [00260, 01251], lr: 0.000495, loss: 0.3854
2022-10-02 07:09:12 - train: epoch 0241, iter [00270, 01251], lr: 0.000495, loss: 0.3815
2022-10-02 07:09:29 - train: epoch 0241, iter [00280, 01251], lr: 0.000495, loss: 0.3856
2022-10-02 07:09:47 - train: epoch 0241, iter [00290, 01251], lr: 0.000495, loss: 0.3928
2022-10-02 07:10:05 - train: epoch 0241, iter [00300, 01251], lr: 0.000495, loss: 0.4170
2022-10-02 07:10:22 - train: epoch 0241, iter [00310, 01251], lr: 0.000495, loss: 0.4111
2022-10-02 07:10:40 - train: epoch 0241, iter [00320, 01251], lr: 0.000494, loss: 0.4202
2022-10-02 07:10:58 - train: epoch 0241, iter [00330, 01251], lr: 0.000494, loss: 0.4209
2022-10-02 07:11:15 - train: epoch 0241, iter [00340, 01251], lr: 0.000494, loss: 0.3893
2022-10-02 07:11:33 - train: epoch 0241, iter [00350, 01251], lr: 0.000494, loss: 0.3868
2022-10-02 07:11:51 - train: epoch 0241, iter [00360, 01251], lr: 0.000494, loss: 0.3852
2022-10-02 07:12:08 - train: epoch 0241, iter [00370, 01251], lr: 0.000494, loss: 0.3923
2022-10-02 07:12:26 - train: epoch 0241, iter [00380, 01251], lr: 0.000494, loss: 0.3946
2022-10-02 07:12:44 - train: epoch 0241, iter [00390, 01251], lr: 0.000494, loss: 0.3695
2022-10-02 07:13:01 - train: epoch 0241, iter [00400, 01251], lr: 0.000494, loss: 0.4015
2022-10-02 07:13:19 - train: epoch 0241, iter [00410, 01251], lr: 0.000494, loss: 0.4026
2022-10-02 07:13:37 - train: epoch 0241, iter [00420, 01251], lr: 0.000494, loss: 0.4207
2022-10-02 07:13:54 - train: epoch 0241, iter [00430, 01251], lr: 0.000494, loss: 0.4090
2022-10-02 07:14:12 - train: epoch 0241, iter [00440, 01251], lr: 0.000494, loss: 0.4012
2022-10-02 07:14:30 - train: epoch 0241, iter [00450, 01251], lr: 0.000494, loss: 0.3928
2022-10-02 07:14:47 - train: epoch 0241, iter [00460, 01251], lr: 0.000494, loss: 0.4033
2022-10-02 07:15:05 - train: epoch 0241, iter [00470, 01251], lr: 0.000494, loss: 0.4277
2022-10-02 07:15:23 - train: epoch 0241, iter [00480, 01251], lr: 0.000494, loss: 0.4034
2022-10-02 07:15:40 - train: epoch 0241, iter [00490, 01251], lr: 0.000494, loss: 0.4045
2022-10-02 07:15:58 - train: epoch 0241, iter [00500, 01251], lr: 0.000494, loss: 0.4049
2022-10-02 07:16:16 - train: epoch 0241, iter [00510, 01251], lr: 0.000494, loss: 0.4166
2022-10-02 07:16:34 - train: epoch 0241, iter [00520, 01251], lr: 0.000494, loss: 0.4112
2022-10-02 07:16:52 - train: epoch 0241, iter [00530, 01251], lr: 0.000494, loss: 0.4072
2022-10-02 07:17:09 - train: epoch 0241, iter [00540, 01251], lr: 0.000494, loss: 0.3924
2022-10-02 07:17:27 - train: epoch 0241, iter [00550, 01251], lr: 0.000494, loss: 0.3820
2022-10-02 07:17:45 - train: epoch 0241, iter [00560, 01251], lr: 0.000494, loss: 0.4018
2022-10-02 07:18:03 - train: epoch 0241, iter [00570, 01251], lr: 0.000493, loss: 0.4084
2022-10-02 07:18:20 - train: epoch 0241, iter [00580, 01251], lr: 0.000493, loss: 0.3829
2022-10-02 07:18:38 - train: epoch 0241, iter [00590, 01251], lr: 0.000493, loss: 0.4203
2022-10-02 07:18:56 - train: epoch 0241, iter [00600, 01251], lr: 0.000493, loss: 0.3928
2022-10-02 07:19:14 - train: epoch 0241, iter [00610, 01251], lr: 0.000493, loss: 0.4108
2022-10-02 07:19:31 - train: epoch 0241, iter [00620, 01251], lr: 0.000493, loss: 0.4068
2022-10-02 07:19:49 - train: epoch 0241, iter [00630, 01251], lr: 0.000493, loss: 0.3825
2022-10-02 07:20:07 - train: epoch 0241, iter [00640, 01251], lr: 0.000493, loss: 0.4092
2022-10-02 07:20:24 - train: epoch 0241, iter [00650, 01251], lr: 0.000493, loss: 0.3944
2022-10-02 07:20:42 - train: epoch 0241, iter [00660, 01251], lr: 0.000493, loss: 0.4093
2022-10-02 07:21:00 - train: epoch 0241, iter [00670, 01251], lr: 0.000493, loss: 0.3983
2022-10-02 07:21:18 - train: epoch 0241, iter [00680, 01251], lr: 0.000493, loss: 0.4025
2022-10-02 07:21:35 - train: epoch 0241, iter [00690, 01251], lr: 0.000493, loss: 0.3905
2022-10-02 07:21:53 - train: epoch 0241, iter [00700, 01251], lr: 0.000493, loss: 0.3996
2022-10-02 07:22:11 - train: epoch 0241, iter [00710, 01251], lr: 0.000493, loss: 0.4151
2022-10-02 07:22:28 - train: epoch 0241, iter [00720, 01251], lr: 0.000493, loss: 0.4110
2022-10-02 07:22:46 - train: epoch 0241, iter [00730, 01251], lr: 0.000493, loss: 0.4024
2022-10-02 07:23:04 - train: epoch 0241, iter [00740, 01251], lr: 0.000493, loss: 0.4016
2022-10-02 07:23:22 - train: epoch 0241, iter [00750, 01251], lr: 0.000493, loss: 0.3911
2022-10-02 07:23:39 - train: epoch 0241, iter [00760, 01251], lr: 0.000493, loss: 0.4215
2022-10-02 07:23:57 - train: epoch 0241, iter [00770, 01251], lr: 0.000493, loss: 0.4079
2022-10-02 07:24:15 - train: epoch 0241, iter [00780, 01251], lr: 0.000493, loss: 0.4079
2022-10-02 07:24:32 - train: epoch 0241, iter [00790, 01251], lr: 0.000493, loss: 0.4123
2022-10-02 07:24:50 - train: epoch 0241, iter [00800, 01251], lr: 0.000493, loss: 0.4164
2022-10-02 07:25:08 - train: epoch 0241, iter [00810, 01251], lr: 0.000492, loss: 0.4100
2022-10-02 07:25:26 - train: epoch 0241, iter [00820, 01251], lr: 0.000492, loss: 0.3980
2022-10-02 07:25:43 - train: epoch 0241, iter [00830, 01251], lr: 0.000492, loss: 0.4010
2022-10-02 07:26:01 - train: epoch 0241, iter [00840, 01251], lr: 0.000492, loss: 0.3983
2022-10-02 07:26:19 - train: epoch 0241, iter [00850, 01251], lr: 0.000492, loss: 0.4041
2022-10-02 07:26:36 - train: epoch 0241, iter [00860, 01251], lr: 0.000492, loss: 0.4137
2022-10-02 07:26:54 - train: epoch 0241, iter [00870, 01251], lr: 0.000492, loss: 0.4083
2022-10-02 07:27:12 - train: epoch 0241, iter [00880, 01251], lr: 0.000492, loss: 0.4054
2022-10-02 07:27:30 - train: epoch 0241, iter [00890, 01251], lr: 0.000492, loss: 0.4072
2022-10-02 07:27:47 - train: epoch 0241, iter [00900, 01251], lr: 0.000492, loss: 0.3963
2022-10-02 07:28:05 - train: epoch 0241, iter [00910, 01251], lr: 0.000492, loss: 0.4164
2022-10-02 07:28:23 - train: epoch 0241, iter [00920, 01251], lr: 0.000492, loss: 0.3971
2022-10-02 07:28:40 - train: epoch 0241, iter [00930, 01251], lr: 0.000492, loss: 0.3834
2022-10-02 07:28:58 - train: epoch 0241, iter [00940, 01251], lr: 0.000492, loss: 0.4132
2022-10-02 07:29:16 - train: epoch 0241, iter [00950, 01251], lr: 0.000492, loss: 0.3915
2022-10-02 07:29:34 - train: epoch 0241, iter [00960, 01251], lr: 0.000492, loss: 0.3891
2022-10-02 07:29:51 - train: epoch 0241, iter [00970, 01251], lr: 0.000492, loss: 0.3914
2022-10-02 07:30:09 - train: epoch 0241, iter [00980, 01251], lr: 0.000492, loss: 0.4098
2022-10-02 07:30:27 - train: epoch 0241, iter [00990, 01251], lr: 0.000492, loss: 0.3969
2022-10-02 07:30:44 - train: epoch 0241, iter [01000, 01251], lr: 0.000492, loss: 0.4092
2022-10-02 07:31:02 - train: epoch 0241, iter [01010, 01251], lr: 0.000492, loss: 0.3991
2022-10-02 07:31:20 - train: epoch 0241, iter [01020, 01251], lr: 0.000492, loss: 0.4119
2022-10-02 07:31:37 - train: epoch 0241, iter [01030, 01251], lr: 0.000492, loss: 0.3985
2022-10-02 07:31:55 - train: epoch 0241, iter [01040, 01251], lr: 0.000492, loss: 0.4154
2022-10-02 07:32:13 - train: epoch 0241, iter [01050, 01251], lr: 0.000491, loss: 0.3817
2022-10-02 07:32:31 - train: epoch 0241, iter [01060, 01251], lr: 0.000491, loss: 0.3875
2022-10-02 07:32:48 - train: epoch 0241, iter [01070, 01251], lr: 0.000491, loss: 0.4055
2022-10-02 07:33:06 - train: epoch 0241, iter [01080, 01251], lr: 0.000491, loss: 0.3928
2022-10-02 07:33:24 - train: epoch 0241, iter [01090, 01251], lr: 0.000491, loss: 0.4144
2022-10-02 07:33:41 - train: epoch 0241, iter [01100, 01251], lr: 0.000491, loss: 0.4138
2022-10-02 07:33:59 - train: epoch 0241, iter [01110, 01251], lr: 0.000491, loss: 0.3964
2022-10-02 07:34:17 - train: epoch 0241, iter [01120, 01251], lr: 0.000491, loss: 0.4199
2022-10-02 07:34:34 - train: epoch 0241, iter [01130, 01251], lr: 0.000491, loss: 0.4038
2022-10-02 07:34:52 - train: epoch 0241, iter [01140, 01251], lr: 0.000491, loss: 0.4221
2022-10-02 07:35:10 - train: epoch 0241, iter [01150, 01251], lr: 0.000491, loss: 0.4049
2022-10-02 07:35:28 - train: epoch 0241, iter [01160, 01251], lr: 0.000491, loss: 0.4000
2022-10-02 07:35:46 - train: epoch 0241, iter [01170, 01251], lr: 0.000491, loss: 0.3866
2022-10-02 07:36:03 - train: epoch 0241, iter [01180, 01251], lr: 0.000491, loss: 0.3999
2022-10-02 07:36:21 - train: epoch 0241, iter [01190, 01251], lr: 0.000491, loss: 0.3882
2022-10-02 07:36:39 - train: epoch 0241, iter [01200, 01251], lr: 0.000491, loss: 0.4039
2022-10-02 07:36:56 - train: epoch 0241, iter [01210, 01251], lr: 0.000491, loss: 0.4022
2022-10-02 07:37:14 - train: epoch 0241, iter [01220, 01251], lr: 0.000491, loss: 0.3855
2022-10-02 07:37:32 - train: epoch 0241, iter [01230, 01251], lr: 0.000491, loss: 0.3910
2022-10-02 07:37:50 - train: epoch 0241, iter [01240, 01251], lr: 0.000491, loss: 0.3752
2022-10-02 07:38:07 - train: epoch 0241, iter [01250, 01251], lr: 0.000491, loss: 0.3967
2022-10-02 07:38:10 - train: epoch 241, train_loss: 0.4037
2022-10-02 07:38:13 - until epoch: 241, best_loss: 0.4037
2022-10-02 07:38:13 - epoch 242 lr: 0.000491
2022-10-02 07:38:38 - train: epoch 0242, iter [00010, 01251], lr: 0.000491, loss: 0.4154
2022-10-02 07:38:56 - train: epoch 0242, iter [00020, 01251], lr: 0.000491, loss: 0.3921
2022-10-02 07:39:13 - train: epoch 0242, iter [00030, 01251], lr: 0.000491, loss: 0.4093
2022-10-02 07:39:31 - train: epoch 0242, iter [00040, 01251], lr: 0.000490, loss: 0.4136
2022-10-02 07:39:49 - train: epoch 0242, iter [00050, 01251], lr: 0.000490, loss: 0.4186
2022-10-02 07:40:07 - train: epoch 0242, iter [00060, 01251], lr: 0.000490, loss: 0.4037
2022-10-02 07:40:24 - train: epoch 0242, iter [00070, 01251], lr: 0.000490, loss: 0.4195
2022-10-02 07:40:42 - train: epoch 0242, iter [00080, 01251], lr: 0.000490, loss: 0.4080
2022-10-02 07:40:59 - train: epoch 0242, iter [00090, 01251], lr: 0.000490, loss: 0.3902
2022-10-02 07:41:17 - train: epoch 0242, iter [00100, 01251], lr: 0.000490, loss: 0.4026
2022-10-02 07:41:35 - train: epoch 0242, iter [00110, 01251], lr: 0.000490, loss: 0.3923
2022-10-02 07:41:52 - train: epoch 0242, iter [00120, 01251], lr: 0.000490, loss: 0.3936
2022-10-02 07:42:10 - train: epoch 0242, iter [00130, 01251], lr: 0.000490, loss: 0.4197
2022-10-02 07:42:28 - train: epoch 0242, iter [00140, 01251], lr: 0.000490, loss: 0.4033
2022-10-02 07:42:45 - train: epoch 0242, iter [00150, 01251], lr: 0.000490, loss: 0.3931
2022-10-02 07:43:03 - train: epoch 0242, iter [00160, 01251], lr: 0.000490, loss: 0.3810
2022-10-02 07:43:21 - train: epoch 0242, iter [00170, 01251], lr: 0.000490, loss: 0.3994
2022-10-02 07:43:39 - train: epoch 0242, iter [00180, 01251], lr: 0.000490, loss: 0.4055
2022-10-02 07:43:56 - train: epoch 0242, iter [00190, 01251], lr: 0.000490, loss: 0.4007
2022-10-02 07:44:14 - train: epoch 0242, iter [00200, 01251], lr: 0.000490, loss: 0.4167
2022-10-02 07:44:32 - train: epoch 0242, iter [00210, 01251], lr: 0.000490, loss: 0.3979
2022-10-02 07:44:50 - train: epoch 0242, iter [00220, 01251], lr: 0.000490, loss: 0.4017
2022-10-02 07:45:07 - train: epoch 0242, iter [00230, 01251], lr: 0.000490, loss: 0.4165
2022-10-02 07:45:25 - train: epoch 0242, iter [00240, 01251], lr: 0.000490, loss: 0.4190
2022-10-02 07:45:43 - train: epoch 0242, iter [00250, 01251], lr: 0.000490, loss: 0.3993
2022-10-02 07:46:00 - train: epoch 0242, iter [00260, 01251], lr: 0.000490, loss: 0.4087
2022-10-02 07:46:18 - train: epoch 0242, iter [00270, 01251], lr: 0.000490, loss: 0.4078
2022-10-02 07:46:36 - train: epoch 0242, iter [00280, 01251], lr: 0.000490, loss: 0.3969
2022-10-02 07:46:54 - train: epoch 0242, iter [00290, 01251], lr: 0.000489, loss: 0.4133
2022-10-02 07:47:11 - train: epoch 0242, iter [00300, 01251], lr: 0.000489, loss: 0.4039
2022-10-02 07:47:29 - train: epoch 0242, iter [00310, 01251], lr: 0.000489, loss: 0.4124
2022-10-02 07:47:47 - train: epoch 0242, iter [00320, 01251], lr: 0.000489, loss: 0.4102
2022-10-02 07:48:04 - train: epoch 0242, iter [00330, 01251], lr: 0.000489, loss: 0.4096
2022-10-02 07:48:22 - train: epoch 0242, iter [00340, 01251], lr: 0.000489, loss: 0.3905
2022-10-02 07:48:40 - train: epoch 0242, iter [00350, 01251], lr: 0.000489, loss: 0.4274
2022-10-02 07:48:58 - train: epoch 0242, iter [00360, 01251], lr: 0.000489, loss: 0.4050
2022-10-02 07:49:15 - train: epoch 0242, iter [00370, 01251], lr: 0.000489, loss: 0.4231
2022-10-02 07:49:33 - train: epoch 0242, iter [00380, 01251], lr: 0.000489, loss: 0.4023
2022-10-02 07:49:51 - train: epoch 0242, iter [00390, 01251], lr: 0.000489, loss: 0.4185
2022-10-02 07:50:09 - train: epoch 0242, iter [00400, 01251], lr: 0.000489, loss: 0.4072
2022-10-02 07:50:26 - train: epoch 0242, iter [00410, 01251], lr: 0.000489, loss: 0.3918
2022-10-02 07:50:44 - train: epoch 0242, iter [00420, 01251], lr: 0.000489, loss: 0.4100
2022-10-02 07:51:02 - train: epoch 0242, iter [00430, 01251], lr: 0.000489, loss: 0.4068
2022-10-02 07:51:19 - train: epoch 0242, iter [00440, 01251], lr: 0.000489, loss: 0.4113
2022-10-02 07:51:37 - train: epoch 0242, iter [00450, 01251], lr: 0.000489, loss: 0.4073
2022-10-02 07:51:55 - train: epoch 0242, iter [00460, 01251], lr: 0.000489, loss: 0.4194
2022-10-02 07:52:13 - train: epoch 0242, iter [00470, 01251], lr: 0.000489, loss: 0.4162
2022-10-02 07:52:30 - train: epoch 0242, iter [00480, 01251], lr: 0.000489, loss: 0.4058
2022-10-02 07:52:48 - train: epoch 0242, iter [00490, 01251], lr: 0.000489, loss: 0.4079
2022-10-02 07:53:06 - train: epoch 0242, iter [00500, 01251], lr: 0.000489, loss: 0.4121
2022-10-02 07:53:24 - train: epoch 0242, iter [00510, 01251], lr: 0.000489, loss: 0.3926
2022-10-02 07:53:41 - train: epoch 0242, iter [00520, 01251], lr: 0.000489, loss: 0.3875
2022-10-02 07:53:59 - train: epoch 0242, iter [00530, 01251], lr: 0.000488, loss: 0.4066
2022-10-02 07:54:17 - train: epoch 0242, iter [00540, 01251], lr: 0.000488, loss: 0.4156
2022-10-02 07:54:34 - train: epoch 0242, iter [00550, 01251], lr: 0.000488, loss: 0.4216
2022-10-02 07:54:52 - train: epoch 0242, iter [00560, 01251], lr: 0.000488, loss: 0.3970
2022-10-02 07:55:10 - train: epoch 0242, iter [00570, 01251], lr: 0.000488, loss: 0.4266
2022-10-02 07:55:27 - train: epoch 0242, iter [00580, 01251], lr: 0.000488, loss: 0.3995
2022-10-02 07:55:45 - train: epoch 0242, iter [00590, 01251], lr: 0.000488, loss: 0.4056
2022-10-02 07:56:03 - train: epoch 0242, iter [00600, 01251], lr: 0.000488, loss: 0.4056
2022-10-02 07:56:20 - train: epoch 0242, iter [00610, 01251], lr: 0.000488, loss: 0.4001
2022-10-02 07:56:38 - train: epoch 0242, iter [00620, 01251], lr: 0.000488, loss: 0.3932
2022-10-02 07:56:56 - train: epoch 0242, iter [00630, 01251], lr: 0.000488, loss: 0.4134
2022-10-02 07:57:13 - train: epoch 0242, iter [00640, 01251], lr: 0.000488, loss: 0.4126
2022-10-02 07:57:31 - train: epoch 0242, iter [00650, 01251], lr: 0.000488, loss: 0.4114
2022-10-02 07:57:49 - train: epoch 0242, iter [00660, 01251], lr: 0.000488, loss: 0.4131
2022-10-02 07:58:06 - train: epoch 0242, iter [00670, 01251], lr: 0.000488, loss: 0.4098
2022-10-02 07:58:24 - train: epoch 0242, iter [00680, 01251], lr: 0.000488, loss: 0.4087
2022-10-02 07:58:42 - train: epoch 0242, iter [00690, 01251], lr: 0.000488, loss: 0.4046
2022-10-02 07:59:00 - train: epoch 0242, iter [00700, 01251], lr: 0.000488, loss: 0.4171
2022-10-02 07:59:17 - train: epoch 0242, iter [00710, 01251], lr: 0.000488, loss: 0.4110
2022-10-02 07:59:35 - train: epoch 0242, iter [00720, 01251], lr: 0.000488, loss: 0.3947
2022-10-02 07:59:53 - train: epoch 0242, iter [00730, 01251], lr: 0.000488, loss: 0.3945
2022-10-02 08:00:11 - train: epoch 0242, iter [00740, 01251], lr: 0.000488, loss: 0.4128
2022-10-02 08:00:28 - train: epoch 0242, iter [00750, 01251], lr: 0.000488, loss: 0.4146
2022-10-02 08:00:46 - train: epoch 0242, iter [00760, 01251], lr: 0.000488, loss: 0.4028
2022-10-02 08:01:04 - train: epoch 0242, iter [00770, 01251], lr: 0.000487, loss: 0.3865
2022-10-02 08:01:21 - train: epoch 0242, iter [00780, 01251], lr: 0.000487, loss: 0.4008
2022-10-02 08:01:39 - train: epoch 0242, iter [00790, 01251], lr: 0.000487, loss: 0.4019
2022-10-02 08:01:57 - train: epoch 0242, iter [00800, 01251], lr: 0.000487, loss: 0.4017
2022-10-02 08:02:15 - train: epoch 0242, iter [00810, 01251], lr: 0.000487, loss: 0.3942
2022-10-02 08:02:32 - train: epoch 0242, iter [00820, 01251], lr: 0.000487, loss: 0.4167
2022-10-02 08:02:50 - train: epoch 0242, iter [00830, 01251], lr: 0.000487, loss: 0.3883
2022-10-02 08:03:08 - train: epoch 0242, iter [00840, 01251], lr: 0.000487, loss: 0.4014
2022-10-02 08:03:25 - train: epoch 0242, iter [00850, 01251], lr: 0.000487, loss: 0.4303
2022-10-02 08:03:43 - train: epoch 0242, iter [00860, 01251], lr: 0.000487, loss: 0.4071
2022-10-02 08:04:01 - train: epoch 0242, iter [00870, 01251], lr: 0.000487, loss: 0.3929
2022-10-02 08:04:18 - train: epoch 0242, iter [00880, 01251], lr: 0.000487, loss: 0.4024
2022-10-02 08:04:36 - train: epoch 0242, iter [00890, 01251], lr: 0.000487, loss: 0.4006
2022-10-02 08:04:54 - train: epoch 0242, iter [00900, 01251], lr: 0.000487, loss: 0.4287
2022-10-02 08:05:11 - train: epoch 0242, iter [00910, 01251], lr: 0.000487, loss: 0.3982
2022-10-02 08:05:29 - train: epoch 0242, iter [00920, 01251], lr: 0.000487, loss: 0.4086
2022-10-02 08:05:47 - train: epoch 0242, iter [00930, 01251], lr: 0.000487, loss: 0.4017
2022-10-02 08:06:04 - train: epoch 0242, iter [00940, 01251], lr: 0.000487, loss: 0.4047
2022-10-02 08:06:22 - train: epoch 0242, iter [00950, 01251], lr: 0.000487, loss: 0.3975
2022-10-02 08:06:40 - train: epoch 0242, iter [00960, 01251], lr: 0.000487, loss: 0.4067
2022-10-02 08:06:58 - train: epoch 0242, iter [00970, 01251], lr: 0.000487, loss: 0.4068
2022-10-02 08:07:15 - train: epoch 0242, iter [00980, 01251], lr: 0.000487, loss: 0.4006
2022-10-02 08:07:33 - train: epoch 0242, iter [00990, 01251], lr: 0.000487, loss: 0.3839
2022-10-02 08:07:51 - train: epoch 0242, iter [01000, 01251], lr: 0.000487, loss: 0.4235
2022-10-02 08:08:08 - train: epoch 0242, iter [01010, 01251], lr: 0.000487, loss: 0.3971
2022-10-02 08:08:26 - train: epoch 0242, iter [01020, 01251], lr: 0.000486, loss: 0.4115
2022-10-02 08:08:44 - train: epoch 0242, iter [01030, 01251], lr: 0.000486, loss: 0.4060
2022-10-02 08:09:02 - train: epoch 0242, iter [01040, 01251], lr: 0.000486, loss: 0.3992
2022-10-02 08:09:20 - train: epoch 0242, iter [01050, 01251], lr: 0.000486, loss: 0.4077
2022-10-02 08:09:37 - train: epoch 0242, iter [01060, 01251], lr: 0.000486, loss: 0.3804
2022-10-02 08:09:55 - train: epoch 0242, iter [01070, 01251], lr: 0.000486, loss: 0.4103
2022-10-02 08:10:13 - train: epoch 0242, iter [01080, 01251], lr: 0.000486, loss: 0.3924
2022-10-02 08:10:31 - train: epoch 0242, iter [01090, 01251], lr: 0.000486, loss: 0.3977
2022-10-02 08:10:49 - train: epoch 0242, iter [01100, 01251], lr: 0.000486, loss: 0.4155
2022-10-02 08:11:07 - train: epoch 0242, iter [01110, 01251], lr: 0.000486, loss: 0.3993
2022-10-02 08:11:24 - train: epoch 0242, iter [01120, 01251], lr: 0.000486, loss: 0.4015
2022-10-02 08:11:42 - train: epoch 0242, iter [01130, 01251], lr: 0.000486, loss: 0.4046
2022-10-02 08:12:00 - train: epoch 0242, iter [01140, 01251], lr: 0.000486, loss: 0.4033
2022-10-02 08:12:17 - train: epoch 0242, iter [01150, 01251], lr: 0.000486, loss: 0.4010
2022-10-02 08:12:35 - train: epoch 0242, iter [01160, 01251], lr: 0.000486, loss: 0.4164
2022-10-02 08:12:53 - train: epoch 0242, iter [01170, 01251], lr: 0.000486, loss: 0.4033
2022-10-02 08:13:11 - train: epoch 0242, iter [01180, 01251], lr: 0.000486, loss: 0.3916
2022-10-02 08:13:29 - train: epoch 0242, iter [01190, 01251], lr: 0.000486, loss: 0.3977
2022-10-02 08:13:47 - train: epoch 0242, iter [01200, 01251], lr: 0.000486, loss: 0.3900
2022-10-02 08:14:04 - train: epoch 0242, iter [01210, 01251], lr: 0.000486, loss: 0.4039
2022-10-02 08:14:22 - train: epoch 0242, iter [01220, 01251], lr: 0.000486, loss: 0.3960
2022-10-02 08:14:40 - train: epoch 0242, iter [01230, 01251], lr: 0.000486, loss: 0.3903
2022-10-02 08:14:58 - train: epoch 0242, iter [01240, 01251], lr: 0.000486, loss: 0.3851
2022-10-02 08:15:16 - train: epoch 0242, iter [01250, 01251], lr: 0.000486, loss: 0.4040
2022-10-02 08:15:18 - train: epoch 242, train_loss: 0.4036
2022-10-02 08:15:21 - until epoch: 242, best_loss: 0.4036
2022-10-02 08:15:21 - epoch 243 lr: 0.000486
2022-10-02 08:15:47 - train: epoch 0243, iter [00010, 01251], lr: 0.000485, loss: 0.4054
2022-10-02 08:16:05 - train: epoch 0243, iter [00020, 01251], lr: 0.000485, loss: 0.4188
2022-10-02 08:16:22 - train: epoch 0243, iter [00030, 01251], lr: 0.000485, loss: 0.4060
2022-10-02 08:16:40 - train: epoch 0243, iter [00040, 01251], lr: 0.000485, loss: 0.4078
2022-10-02 08:16:58 - train: epoch 0243, iter [00050, 01251], lr: 0.000485, loss: 0.4042
2022-10-02 08:17:16 - train: epoch 0243, iter [00060, 01251], lr: 0.000485, loss: 0.3935
2022-10-02 08:17:34 - train: epoch 0243, iter [00070, 01251], lr: 0.000485, loss: 0.4074
2022-10-02 08:17:52 - train: epoch 0243, iter [00080, 01251], lr: 0.000485, loss: 0.3952
2022-10-02 08:18:10 - train: epoch 0243, iter [00090, 01251], lr: 0.000485, loss: 0.4095
2022-10-02 08:18:28 - train: epoch 0243, iter [00100, 01251], lr: 0.000485, loss: 0.3972
2022-10-02 08:18:46 - train: epoch 0243, iter [00110, 01251], lr: 0.000485, loss: 0.4163
2022-10-02 08:19:04 - train: epoch 0243, iter [00120, 01251], lr: 0.000485, loss: 0.4133
2022-10-02 08:19:22 - train: epoch 0243, iter [00130, 01251], lr: 0.000485, loss: 0.3830
2022-10-02 08:19:39 - train: epoch 0243, iter [00140, 01251], lr: 0.000485, loss: 0.3978
2022-10-02 08:19:57 - train: epoch 0243, iter [00150, 01251], lr: 0.000485, loss: 0.3955
2022-10-02 08:20:15 - train: epoch 0243, iter [00160, 01251], lr: 0.000485, loss: 0.4190
2022-10-02 08:20:33 - train: epoch 0243, iter [00170, 01251], lr: 0.000485, loss: 0.4005
2022-10-02 08:20:51 - train: epoch 0243, iter [00180, 01251], lr: 0.000485, loss: 0.4134
2022-10-02 08:21:09 - train: epoch 0243, iter [00190, 01251], lr: 0.000485, loss: 0.4161
2022-10-02 08:21:26 - train: epoch 0243, iter [00200, 01251], lr: 0.000485, loss: 0.4003
2022-10-02 08:21:44 - train: epoch 0243, iter [00210, 01251], lr: 0.000485, loss: 0.3801
2022-10-02 08:22:02 - train: epoch 0243, iter [00220, 01251], lr: 0.000485, loss: 0.4065
2022-10-02 08:22:20 - train: epoch 0243, iter [00230, 01251], lr: 0.000485, loss: 0.3980
2022-10-02 08:22:38 - train: epoch 0243, iter [00240, 01251], lr: 0.000485, loss: 0.4118
2022-10-02 08:22:56 - train: epoch 0243, iter [00250, 01251], lr: 0.000484, loss: 0.4038
2022-10-02 08:23:13 - train: epoch 0243, iter [00260, 01251], lr: 0.000484, loss: 0.4260
2022-10-02 08:23:31 - train: epoch 0243, iter [00270, 01251], lr: 0.000484, loss: 0.4006
2022-10-02 08:23:49 - train: epoch 0243, iter [00280, 01251], lr: 0.000484, loss: 0.4107
2022-10-02 08:24:07 - train: epoch 0243, iter [00290, 01251], lr: 0.000484, loss: 0.3993
2022-10-02 08:24:25 - train: epoch 0243, iter [00300, 01251], lr: 0.000484, loss: 0.4031
2022-10-02 08:24:43 - train: epoch 0243, iter [00310, 01251], lr: 0.000484, loss: 0.3895
2022-10-02 08:25:01 - train: epoch 0243, iter [00320, 01251], lr: 0.000484, loss: 0.3866
2022-10-02 08:25:19 - train: epoch 0243, iter [00330, 01251], lr: 0.000484, loss: 0.3815
2022-10-02 08:25:37 - train: epoch 0243, iter [00340, 01251], lr: 0.000484, loss: 0.4078
2022-10-02 08:25:55 - train: epoch 0243, iter [00350, 01251], lr: 0.000484, loss: 0.4019
2022-10-02 08:26:13 - train: epoch 0243, iter [00360, 01251], lr: 0.000484, loss: 0.4119
2022-10-02 08:26:31 - train: epoch 0243, iter [00370, 01251], lr: 0.000484, loss: 0.4010
2022-10-02 08:26:48 - train: epoch 0243, iter [00380, 01251], lr: 0.000484, loss: 0.4171
2022-10-02 08:27:06 - train: epoch 0243, iter [00390, 01251], lr: 0.000484, loss: 0.4124
2022-10-02 08:27:24 - train: epoch 0243, iter [00400, 01251], lr: 0.000484, loss: 0.4042
2022-10-02 08:27:42 - train: epoch 0243, iter [00410, 01251], lr: 0.000484, loss: 0.3831
2022-10-02 08:28:00 - train: epoch 0243, iter [00420, 01251], lr: 0.000484, loss: 0.4008
2022-10-02 08:28:18 - train: epoch 0243, iter [00430, 01251], lr: 0.000484, loss: 0.4109
2022-10-02 08:28:36 - train: epoch 0243, iter [00440, 01251], lr: 0.000484, loss: 0.3982
2022-10-02 08:28:54 - train: epoch 0243, iter [00450, 01251], lr: 0.000484, loss: 0.3905
2022-10-02 08:29:12 - train: epoch 0243, iter [00460, 01251], lr: 0.000484, loss: 0.3955
2022-10-02 08:29:30 - train: epoch 0243, iter [00470, 01251], lr: 0.000484, loss: 0.3831
2022-10-02 08:29:47 - train: epoch 0243, iter [00480, 01251], lr: 0.000484, loss: 0.3970
2022-10-02 08:30:05 - train: epoch 0243, iter [00490, 01251], lr: 0.000484, loss: 0.4037
2022-10-02 08:30:23 - train: epoch 0243, iter [00500, 01251], lr: 0.000483, loss: 0.4113
2022-10-02 08:30:41 - train: epoch 0243, iter [00510, 01251], lr: 0.000483, loss: 0.4029
2022-10-02 08:30:59 - train: epoch 0243, iter [00520, 01251], lr: 0.000483, loss: 0.4269
2022-10-02 08:31:17 - train: epoch 0243, iter [00530, 01251], lr: 0.000483, loss: 0.4209
2022-10-02 08:31:35 - train: epoch 0243, iter [00540, 01251], lr: 0.000483, loss: 0.4087
2022-10-02 08:31:53 - train: epoch 0243, iter [00550, 01251], lr: 0.000483, loss: 0.4095
2022-10-02 08:32:10 - train: epoch 0243, iter [00560, 01251], lr: 0.000483, loss: 0.3880
2022-10-02 08:32:28 - train: epoch 0243, iter [00570, 01251], lr: 0.000483, loss: 0.4063
2022-10-02 08:32:46 - train: epoch 0243, iter [00580, 01251], lr: 0.000483, loss: 0.4036
2022-10-02 08:33:04 - train: epoch 0243, iter [00590, 01251], lr: 0.000483, loss: 0.4222
2022-10-02 08:33:22 - train: epoch 0243, iter [00600, 01251], lr: 0.000483, loss: 0.4109
2022-10-02 08:33:40 - train: epoch 0243, iter [00610, 01251], lr: 0.000483, loss: 0.3915
2022-10-02 08:33:58 - train: epoch 0243, iter [00620, 01251], lr: 0.000483, loss: 0.3917
2022-10-02 08:34:15 - train: epoch 0243, iter [00630, 01251], lr: 0.000483, loss: 0.3963
2022-10-02 08:34:33 - train: epoch 0243, iter [00640, 01251], lr: 0.000483, loss: 0.3977
2022-10-02 08:34:51 - train: epoch 0243, iter [00650, 01251], lr: 0.000483, loss: 0.4343
2022-10-02 08:35:09 - train: epoch 0243, iter [00660, 01251], lr: 0.000483, loss: 0.3999
2022-10-02 08:35:27 - train: epoch 0243, iter [00670, 01251], lr: 0.000483, loss: 0.4050
2022-10-02 08:35:45 - train: epoch 0243, iter [00680, 01251], lr: 0.000483, loss: 0.3967
2022-10-02 08:36:03 - train: epoch 0243, iter [00690, 01251], lr: 0.000483, loss: 0.3882
2022-10-02 08:36:20 - train: epoch 0243, iter [00700, 01251], lr: 0.000483, loss: 0.3926
2022-10-02 08:36:38 - train: epoch 0243, iter [00710, 01251], lr: 0.000483, loss: 0.3808
2022-10-02 08:36:56 - train: epoch 0243, iter [00720, 01251], lr: 0.000483, loss: 0.4084
2022-10-02 08:37:14 - train: epoch 0243, iter [00730, 01251], lr: 0.000483, loss: 0.3970
2022-10-02 08:37:32 - train: epoch 0243, iter [00740, 01251], lr: 0.000482, loss: 0.4201
2022-10-02 08:37:50 - train: epoch 0243, iter [00750, 01251], lr: 0.000482, loss: 0.3940
2022-10-02 08:38:08 - train: epoch 0243, iter [00760, 01251], lr: 0.000482, loss: 0.3992
2022-10-02 08:38:26 - train: epoch 0243, iter [00770, 01251], lr: 0.000482, loss: 0.4172
2022-10-02 08:38:44 - train: epoch 0243, iter [00780, 01251], lr: 0.000482, loss: 0.4053
2022-10-02 08:39:01 - train: epoch 0243, iter [00790, 01251], lr: 0.000482, loss: 0.4147
2022-10-02 08:39:19 - train: epoch 0243, iter [00800, 01251], lr: 0.000482, loss: 0.3968
2022-10-02 08:39:37 - train: epoch 0243, iter [00810, 01251], lr: 0.000482, loss: 0.3959
2022-10-02 08:39:55 - train: epoch 0243, iter [00820, 01251], lr: 0.000482, loss: 0.3998
2022-10-02 08:40:13 - train: epoch 0243, iter [00830, 01251], lr: 0.000482, loss: 0.4041
2022-10-02 08:40:31 - train: epoch 0243, iter [00840, 01251], lr: 0.000482, loss: 0.4262
2022-10-02 08:40:49 - train: epoch 0243, iter [00850, 01251], lr: 0.000482, loss: 0.3983
2022-10-02 08:41:07 - train: epoch 0243, iter [00860, 01251], lr: 0.000482, loss: 0.4008
2022-10-02 08:41:25 - train: epoch 0243, iter [00870, 01251], lr: 0.000482, loss: 0.3978
2022-10-02 08:41:42 - train: epoch 0243, iter [00880, 01251], lr: 0.000482, loss: 0.3993
2022-10-02 08:42:00 - train: epoch 0243, iter [00890, 01251], lr: 0.000482, loss: 0.4183
2022-10-02 08:42:18 - train: epoch 0243, iter [00900, 01251], lr: 0.000482, loss: 0.4242
2022-10-02 08:42:36 - train: epoch 0243, iter [00910, 01251], lr: 0.000482, loss: 0.4033
2022-10-02 08:42:54 - train: epoch 0243, iter [00920, 01251], lr: 0.000482, loss: 0.3941
2022-10-02 08:43:12 - train: epoch 0243, iter [00930, 01251], lr: 0.000482, loss: 0.4364
2022-10-02 08:43:29 - train: epoch 0243, iter [00940, 01251], lr: 0.000482, loss: 0.4003
2022-10-02 08:43:47 - train: epoch 0243, iter [00950, 01251], lr: 0.000482, loss: 0.3988
2022-10-02 08:44:05 - train: epoch 0243, iter [00960, 01251], lr: 0.000482, loss: 0.4200
2022-10-02 08:44:23 - train: epoch 0243, iter [00970, 01251], lr: 0.000482, loss: 0.3913
2022-10-02 08:44:41 - train: epoch 0243, iter [00980, 01251], lr: 0.000481, loss: 0.3891
2022-10-02 08:44:58 - train: epoch 0243, iter [00990, 01251], lr: 0.000481, loss: 0.4039
2022-10-02 08:45:16 - train: epoch 0243, iter [01000, 01251], lr: 0.000481, loss: 0.4089
2022-10-02 08:45:34 - train: epoch 0243, iter [01010, 01251], lr: 0.000481, loss: 0.4065
2022-10-02 08:45:52 - train: epoch 0243, iter [01020, 01251], lr: 0.000481, loss: 0.3986
2022-10-02 08:46:10 - train: epoch 0243, iter [01030, 01251], lr: 0.000481, loss: 0.4069
2022-10-02 08:46:27 - train: epoch 0243, iter [01040, 01251], lr: 0.000481, loss: 0.4051
2022-10-02 08:46:45 - train: epoch 0243, iter [01050, 01251], lr: 0.000481, loss: 0.3899
2022-10-02 08:47:03 - train: epoch 0243, iter [01060, 01251], lr: 0.000481, loss: 0.4190
2022-10-02 08:47:21 - train: epoch 0243, iter [01070, 01251], lr: 0.000481, loss: 0.4089
2022-10-02 08:47:39 - train: epoch 0243, iter [01080, 01251], lr: 0.000481, loss: 0.4121
2022-10-02 08:47:57 - train: epoch 0243, iter [01090, 01251], lr: 0.000481, loss: 0.4003
2022-10-02 08:48:14 - train: epoch 0243, iter [01100, 01251], lr: 0.000481, loss: 0.4062
2022-10-02 08:48:32 - train: epoch 0243, iter [01110, 01251], lr: 0.000481, loss: 0.3752
2022-10-02 08:48:50 - train: epoch 0243, iter [01120, 01251], lr: 0.000481, loss: 0.4055
2022-10-02 08:49:08 - train: epoch 0243, iter [01130, 01251], lr: 0.000481, loss: 0.4077
2022-10-02 08:49:26 - train: epoch 0243, iter [01140, 01251], lr: 0.000481, loss: 0.4021
2022-10-02 08:49:44 - train: epoch 0243, iter [01150, 01251], lr: 0.000481, loss: 0.4064
2022-10-02 08:50:01 - train: epoch 0243, iter [01160, 01251], lr: 0.000481, loss: 0.4054
2022-10-02 08:50:19 - train: epoch 0243, iter [01170, 01251], lr: 0.000481, loss: 0.3694
2022-10-02 08:50:37 - train: epoch 0243, iter [01180, 01251], lr: 0.000481, loss: 0.4065
2022-10-02 08:50:55 - train: epoch 0243, iter [01190, 01251], lr: 0.000481, loss: 0.3985
2022-10-02 08:51:13 - train: epoch 0243, iter [01200, 01251], lr: 0.000481, loss: 0.4065
2022-10-02 08:51:30 - train: epoch 0243, iter [01210, 01251], lr: 0.000481, loss: 0.4068
2022-10-02 08:51:48 - train: epoch 0243, iter [01220, 01251], lr: 0.000481, loss: 0.4006
2022-10-02 08:52:06 - train: epoch 0243, iter [01230, 01251], lr: 0.000480, loss: 0.3972
2022-10-02 08:52:24 - train: epoch 0243, iter [01240, 01251], lr: 0.000480, loss: 0.3929
2022-10-02 08:52:42 - train: epoch 0243, iter [01250, 01251], lr: 0.000480, loss: 0.3888
2022-10-02 08:52:45 - train: epoch 243, train_loss: 0.4035
2022-10-02 08:52:47 - until epoch: 243, best_loss: 0.4035
2022-10-02 08:52:47 - epoch 244 lr: 0.000480
2022-10-02 08:53:12 - train: epoch 0244, iter [00010, 01251], lr: 0.000480, loss: 0.3831
2022-10-02 08:53:30 - train: epoch 0244, iter [00020, 01251], lr: 0.000480, loss: 0.4002
2022-10-02 08:53:48 - train: epoch 0244, iter [00030, 01251], lr: 0.000480, loss: 0.4058
2022-10-02 08:54:06 - train: epoch 0244, iter [00040, 01251], lr: 0.000480, loss: 0.4194
2022-10-02 08:54:24 - train: epoch 0244, iter [00050, 01251], lr: 0.000480, loss: 0.4245
2022-10-02 08:54:42 - train: epoch 0244, iter [00060, 01251], lr: 0.000480, loss: 0.4223
2022-10-02 08:55:00 - train: epoch 0244, iter [00070, 01251], lr: 0.000480, loss: 0.4036
2022-10-02 08:55:18 - train: epoch 0244, iter [00080, 01251], lr: 0.000480, loss: 0.4048
2022-10-02 08:55:35 - train: epoch 0244, iter [00090, 01251], lr: 0.000480, loss: 0.4032
2022-10-02 08:55:53 - train: epoch 0244, iter [00100, 01251], lr: 0.000480, loss: 0.3982
2022-10-02 08:56:11 - train: epoch 0244, iter [00110, 01251], lr: 0.000480, loss: 0.4169
2022-10-02 08:56:28 - train: epoch 0244, iter [00120, 01251], lr: 0.000480, loss: 0.3982
2022-10-02 08:56:46 - train: epoch 0244, iter [00130, 01251], lr: 0.000480, loss: 0.3939
2022-10-02 08:57:04 - train: epoch 0244, iter [00140, 01251], lr: 0.000480, loss: 0.3924
2022-10-02 08:57:22 - train: epoch 0244, iter [00150, 01251], lr: 0.000480, loss: 0.3877
2022-10-02 08:57:40 - train: epoch 0244, iter [00160, 01251], lr: 0.000480, loss: 0.3895
2022-10-02 08:57:58 - train: epoch 0244, iter [00170, 01251], lr: 0.000480, loss: 0.3953
2022-10-02 08:58:16 - train: epoch 0244, iter [00180, 01251], lr: 0.000480, loss: 0.4075
2022-10-02 08:58:34 - train: epoch 0244, iter [00190, 01251], lr: 0.000480, loss: 0.4113
2022-10-02 08:58:52 - train: epoch 0244, iter [00200, 01251], lr: 0.000480, loss: 0.4163
2022-10-02 08:59:09 - train: epoch 0244, iter [00210, 01251], lr: 0.000480, loss: 0.3926
2022-10-02 08:59:27 - train: epoch 0244, iter [00220, 01251], lr: 0.000479, loss: 0.4217
2022-10-02 08:59:45 - train: epoch 0244, iter [00230, 01251], lr: 0.000479, loss: 0.4138
2022-10-02 09:00:03 - train: epoch 0244, iter [00240, 01251], lr: 0.000479, loss: 0.3977
2022-10-02 09:00:21 - train: epoch 0244, iter [00250, 01251], lr: 0.000479, loss: 0.3984
2022-10-02 09:00:39 - train: epoch 0244, iter [00260, 01251], lr: 0.000479, loss: 0.3943
2022-10-02 09:00:57 - train: epoch 0244, iter [00270, 01251], lr: 0.000479, loss: 0.4086
2022-10-02 09:01:15 - train: epoch 0244, iter [00280, 01251], lr: 0.000479, loss: 0.3967
2022-10-02 09:01:33 - train: epoch 0244, iter [00290, 01251], lr: 0.000479, loss: 0.4200
2022-10-02 09:01:51 - train: epoch 0244, iter [00300, 01251], lr: 0.000479, loss: 0.3927
2022-10-02 09:02:09 - train: epoch 0244, iter [00310, 01251], lr: 0.000479, loss: 0.3864
2022-10-02 09:02:27 - train: epoch 0244, iter [00320, 01251], lr: 0.000479, loss: 0.3933
2022-10-02 09:02:45 - train: epoch 0244, iter [00330, 01251], lr: 0.000479, loss: 0.3926
2022-10-02 09:03:03 - train: epoch 0244, iter [00340, 01251], lr: 0.000479, loss: 0.3972
2022-10-02 09:03:21 - train: epoch 0244, iter [00350, 01251], lr: 0.000479, loss: 0.4148
2022-10-02 09:03:39 - train: epoch 0244, iter [00360, 01251], lr: 0.000479, loss: 0.3794
2022-10-02 09:03:56 - train: epoch 0244, iter [00370, 01251], lr: 0.000479, loss: 0.4074
2022-10-02 09:04:14 - train: epoch 0244, iter [00380, 01251], lr: 0.000479, loss: 0.4052
2022-10-02 09:04:33 - train: epoch 0244, iter [00390, 01251], lr: 0.000479, loss: 0.4030
2022-10-02 09:04:51 - train: epoch 0244, iter [00400, 01251], lr: 0.000479, loss: 0.4150
2022-10-02 09:05:09 - train: epoch 0244, iter [00410, 01251], lr: 0.000479, loss: 0.4119
2022-10-02 09:05:27 - train: epoch 0244, iter [00420, 01251], lr: 0.000479, loss: 0.4067
2022-10-02 09:05:45 - train: epoch 0244, iter [00430, 01251], lr: 0.000479, loss: 0.3960
2022-10-02 09:06:03 - train: epoch 0244, iter [00440, 01251], lr: 0.000479, loss: 0.4220
2022-10-02 09:06:21 - train: epoch 0244, iter [00450, 01251], lr: 0.000479, loss: 0.3979
2022-10-02 09:06:39 - train: epoch 0244, iter [00460, 01251], lr: 0.000478, loss: 0.3984
2022-10-02 09:06:57 - train: epoch 0244, iter [00470, 01251], lr: 0.000478, loss: 0.4045
2022-10-02 09:07:16 - train: epoch 0244, iter [00480, 01251], lr: 0.000478, loss: 0.3867
2022-10-02 09:07:34 - train: epoch 0244, iter [00490, 01251], lr: 0.000478, loss: 0.4155
2022-10-02 09:07:52 - train: epoch 0244, iter [00500, 01251], lr: 0.000478, loss: 0.3901
2022-10-02 09:08:10 - train: epoch 0244, iter [00510, 01251], lr: 0.000478, loss: 0.4060
2022-10-02 09:08:28 - train: epoch 0244, iter [00520, 01251], lr: 0.000478, loss: 0.4162
2022-10-02 09:08:47 - train: epoch 0244, iter [00530, 01251], lr: 0.000478, loss: 0.4043
2022-10-02 09:09:05 - train: epoch 0244, iter [00540, 01251], lr: 0.000478, loss: 0.4208
2022-10-02 09:09:23 - train: epoch 0244, iter [00550, 01251], lr: 0.000478, loss: 0.4015
2022-10-02 09:09:41 - train: epoch 0244, iter [00560, 01251], lr: 0.000478, loss: 0.3968
2022-10-02 09:09:59 - train: epoch 0244, iter [00570, 01251], lr: 0.000478, loss: 0.4106
2022-10-02 09:10:17 - train: epoch 0244, iter [00580, 01251], lr: 0.000478, loss: 0.4089
2022-10-02 09:10:35 - train: epoch 0244, iter [00590, 01251], lr: 0.000478, loss: 0.4025
2022-10-02 09:10:54 - train: epoch 0244, iter [00600, 01251], lr: 0.000478, loss: 0.3922
2022-10-02 09:11:12 - train: epoch 0244, iter [00610, 01251], lr: 0.000478, loss: 0.3949
2022-10-02 09:11:30 - train: epoch 0244, iter [00620, 01251], lr: 0.000478, loss: 0.4060
2022-10-02 09:11:48 - train: epoch 0244, iter [00630, 01251], lr: 0.000478, loss: 0.3981
2022-10-02 09:12:06 - train: epoch 0244, iter [00640, 01251], lr: 0.000478, loss: 0.4004
2022-10-02 09:12:24 - train: epoch 0244, iter [00650, 01251], lr: 0.000478, loss: 0.4101
2022-10-02 09:12:42 - train: epoch 0244, iter [00660, 01251], lr: 0.000478, loss: 0.3996
2022-10-02 09:13:00 - train: epoch 0244, iter [00670, 01251], lr: 0.000478, loss: 0.3928
2022-10-02 09:13:18 - train: epoch 0244, iter [00680, 01251], lr: 0.000478, loss: 0.4051
2022-10-02 09:13:36 - train: epoch 0244, iter [00690, 01251], lr: 0.000478, loss: 0.3934
2022-10-02 09:13:54 - train: epoch 0244, iter [00700, 01251], lr: 0.000478, loss: 0.4039
2022-10-02 09:14:13 - train: epoch 0244, iter [00710, 01251], lr: 0.000477, loss: 0.3921
2022-10-02 09:14:31 - train: epoch 0244, iter [00720, 01251], lr: 0.000477, loss: 0.3964
2022-10-02 09:14:49 - train: epoch 0244, iter [00730, 01251], lr: 0.000477, loss: 0.4119
2022-10-02 09:15:07 - train: epoch 0244, iter [00740, 01251], lr: 0.000477, loss: 0.4025
2022-10-02 09:15:25 - train: epoch 0244, iter [00750, 01251], lr: 0.000477, loss: 0.4106
2022-10-02 09:15:44 - train: epoch 0244, iter [00760, 01251], lr: 0.000477, loss: 0.3924
2022-10-02 09:16:02 - train: epoch 0244, iter [00770, 01251], lr: 0.000477, loss: 0.3960
2022-10-02 09:16:20 - train: epoch 0244, iter [00780, 01251], lr: 0.000477, loss: 0.4087
2022-10-02 09:16:38 - train: epoch 0244, iter [00790, 01251], lr: 0.000477, loss: 0.4055
2022-10-02 09:16:56 - train: epoch 0244, iter [00800, 01251], lr: 0.000477, loss: 0.4163
2022-10-02 09:17:14 - train: epoch 0244, iter [00810, 01251], lr: 0.000477, loss: 0.4176
2022-10-02 09:17:32 - train: epoch 0244, iter [00820, 01251], lr: 0.000477, loss: 0.3997
2022-10-02 09:17:50 - train: epoch 0244, iter [00830, 01251], lr: 0.000477, loss: 0.4029
2022-10-02 09:18:08 - train: epoch 0244, iter [00840, 01251], lr: 0.000477, loss: 0.4407
2022-10-02 09:18:27 - train: epoch 0244, iter [00850, 01251], lr: 0.000477, loss: 0.4114
2022-10-02 09:18:45 - train: epoch 0244, iter [00860, 01251], lr: 0.000477, loss: 0.4289
2022-10-02 09:19:03 - train: epoch 0244, iter [00870, 01251], lr: 0.000477, loss: 0.4169
2022-10-02 09:19:21 - train: epoch 0244, iter [00880, 01251], lr: 0.000477, loss: 0.4025
2022-10-02 09:19:39 - train: epoch 0244, iter [00890, 01251], lr: 0.000477, loss: 0.3896
2022-10-02 09:19:57 - train: epoch 0244, iter [00900, 01251], lr: 0.000477, loss: 0.3889
2022-10-02 09:20:15 - train: epoch 0244, iter [00910, 01251], lr: 0.000477, loss: 0.4148
2022-10-02 09:20:34 - train: epoch 0244, iter [00920, 01251], lr: 0.000477, loss: 0.4130
2022-10-02 09:20:52 - train: epoch 0244, iter [00930, 01251], lr: 0.000477, loss: 0.3910
2022-10-02 09:21:10 - train: epoch 0244, iter [00940, 01251], lr: 0.000477, loss: 0.4234
2022-10-02 09:21:28 - train: epoch 0244, iter [00950, 01251], lr: 0.000476, loss: 0.4180
2022-10-02 09:21:46 - train: epoch 0244, iter [00960, 01251], lr: 0.000476, loss: 0.3984
2022-10-02 09:22:04 - train: epoch 0244, iter [00970, 01251], lr: 0.000476, loss: 0.3940
2022-10-02 09:22:22 - train: epoch 0244, iter [00980, 01251], lr: 0.000476, loss: 0.3932
2022-10-02 09:22:41 - train: epoch 0244, iter [00990, 01251], lr: 0.000476, loss: 0.4158
2022-10-02 09:22:59 - train: epoch 0244, iter [01000, 01251], lr: 0.000476, loss: 0.3918
2022-10-02 09:23:17 - train: epoch 0244, iter [01010, 01251], lr: 0.000476, loss: 0.4011
2022-10-02 09:23:35 - train: epoch 0244, iter [01020, 01251], lr: 0.000476, loss: 0.4030
2022-10-02 09:23:53 - train: epoch 0244, iter [01030, 01251], lr: 0.000476, loss: 0.3989
2022-10-02 09:24:11 - train: epoch 0244, iter [01040, 01251], lr: 0.000476, loss: 0.3863
2022-10-02 09:24:29 - train: epoch 0244, iter [01050, 01251], lr: 0.000476, loss: 0.4080
2022-10-02 09:24:48 - train: epoch 0244, iter [01060, 01251], lr: 0.000476, loss: 0.4015
2022-10-02 09:25:06 - train: epoch 0244, iter [01070, 01251], lr: 0.000476, loss: 0.4000
2022-10-02 09:25:24 - train: epoch 0244, iter [01080, 01251], lr: 0.000476, loss: 0.4056
2022-10-02 09:25:42 - train: epoch 0244, iter [01090, 01251], lr: 0.000476, loss: 0.4072
2022-10-02 09:26:01 - train: epoch 0244, iter [01100, 01251], lr: 0.000476, loss: 0.4063
2022-10-02 09:26:19 - train: epoch 0244, iter [01110, 01251], lr: 0.000476, loss: 0.4028
2022-10-02 09:26:37 - train: epoch 0244, iter [01120, 01251], lr: 0.000476, loss: 0.4001
2022-10-02 09:26:55 - train: epoch 0244, iter [01130, 01251], lr: 0.000476, loss: 0.3821
2022-10-02 09:27:12 - train: epoch 0244, iter [01140, 01251], lr: 0.000476, loss: 0.3839
2022-10-02 09:27:31 - train: epoch 0244, iter [01150, 01251], lr: 0.000476, loss: 0.3948
2022-10-02 09:27:49 - train: epoch 0244, iter [01160, 01251], lr: 0.000476, loss: 0.4130
2022-10-02 09:28:07 - train: epoch 0244, iter [01170, 01251], lr: 0.000476, loss: 0.4124
2022-10-02 09:28:25 - train: epoch 0244, iter [01180, 01251], lr: 0.000476, loss: 0.3860
2022-10-02 09:28:43 - train: epoch 0244, iter [01190, 01251], lr: 0.000476, loss: 0.4026
2022-10-02 09:29:02 - train: epoch 0244, iter [01200, 01251], lr: 0.000475, loss: 0.4137
2022-10-02 09:29:20 - train: epoch 0244, iter [01210, 01251], lr: 0.000475, loss: 0.3882
2022-10-02 09:29:38 - train: epoch 0244, iter [01220, 01251], lr: 0.000475, loss: 0.4075
2022-10-02 09:29:56 - train: epoch 0244, iter [01230, 01251], lr: 0.000475, loss: 0.3757
2022-10-02 09:30:14 - train: epoch 0244, iter [01240, 01251], lr: 0.000475, loss: 0.4099
2022-10-02 09:30:32 - train: epoch 0244, iter [01250, 01251], lr: 0.000475, loss: 0.4087
2022-10-02 09:30:36 - train: epoch 244, train_loss: 0.4034
2022-10-02 09:30:38 - until epoch: 244, best_loss: 0.4034
2022-10-02 09:30:38 - epoch 245 lr: 0.000475
2022-10-02 09:31:04 - train: epoch 0245, iter [00010, 01251], lr: 0.000475, loss: 0.3995
2022-10-02 09:31:22 - train: epoch 0245, iter [00020, 01251], lr: 0.000475, loss: 0.4106
2022-10-02 09:31:40 - train: epoch 0245, iter [00030, 01251], lr: 0.000475, loss: 0.3897
2022-10-02 09:31:58 - train: epoch 0245, iter [00040, 01251], lr: 0.000475, loss: 0.3989
2022-10-02 09:32:17 - train: epoch 0245, iter [00050, 01251], lr: 0.000475, loss: 0.4058
2022-10-02 09:32:35 - train: epoch 0245, iter [00060, 01251], lr: 0.000475, loss: 0.3968
2022-10-02 09:32:53 - train: epoch 0245, iter [00070, 01251], lr: 0.000475, loss: 0.3944
2022-10-02 09:33:11 - train: epoch 0245, iter [00080, 01251], lr: 0.000475, loss: 0.4059
2022-10-02 09:33:29 - train: epoch 0245, iter [00090, 01251], lr: 0.000475, loss: 0.3993
2022-10-02 09:33:47 - train: epoch 0245, iter [00100, 01251], lr: 0.000475, loss: 0.3972
2022-10-02 09:34:05 - train: epoch 0245, iter [00110, 01251], lr: 0.000475, loss: 0.4025
2022-10-02 09:34:23 - train: epoch 0245, iter [00120, 01251], lr: 0.000475, loss: 0.4057
2022-10-02 09:34:42 - train: epoch 0245, iter [00130, 01251], lr: 0.000475, loss: 0.3878
2022-10-02 09:35:00 - train: epoch 0245, iter [00140, 01251], lr: 0.000475, loss: 0.4204
2022-10-02 09:35:18 - train: epoch 0245, iter [00150, 01251], lr: 0.000475, loss: 0.4096
2022-10-02 09:35:36 - train: epoch 0245, iter [00160, 01251], lr: 0.000475, loss: 0.4127
2022-10-02 09:35:54 - train: epoch 0245, iter [00170, 01251], lr: 0.000475, loss: 0.3961
2022-10-02 09:36:12 - train: epoch 0245, iter [00180, 01251], lr: 0.000475, loss: 0.3896
2022-10-02 09:36:30 - train: epoch 0245, iter [00190, 01251], lr: 0.000474, loss: 0.3836
2022-10-02 09:36:48 - train: epoch 0245, iter [00200, 01251], lr: 0.000474, loss: 0.4020
2022-10-02 09:37:06 - train: epoch 0245, iter [00210, 01251], lr: 0.000474, loss: 0.3911
2022-10-02 09:37:23 - train: epoch 0245, iter [00220, 01251], lr: 0.000474, loss: 0.4260
2022-10-02 09:37:41 - train: epoch 0245, iter [00230, 01251], lr: 0.000474, loss: 0.3968
2022-10-02 09:37:59 - train: epoch 0245, iter [00240, 01251], lr: 0.000474, loss: 0.3979
2022-10-02 09:38:17 - train: epoch 0245, iter [00250, 01251], lr: 0.000474, loss: 0.3994
2022-10-02 09:38:35 - train: epoch 0245, iter [00260, 01251], lr: 0.000474, loss: 0.4037
2022-10-02 09:38:53 - train: epoch 0245, iter [00270, 01251], lr: 0.000474, loss: 0.4043
2022-10-02 09:39:11 - train: epoch 0245, iter [00280, 01251], lr: 0.000474, loss: 0.4019
2022-10-02 09:39:29 - train: epoch 0245, iter [00290, 01251], lr: 0.000474, loss: 0.3673
2022-10-02 09:39:47 - train: epoch 0245, iter [00300, 01251], lr: 0.000474, loss: 0.4061
2022-10-02 09:40:05 - train: epoch 0245, iter [00310, 01251], lr: 0.000474, loss: 0.3806
2022-10-02 09:40:23 - train: epoch 0245, iter [00320, 01251], lr: 0.000474, loss: 0.4073
2022-10-02 09:40:41 - train: epoch 0245, iter [00330, 01251], lr: 0.000474, loss: 0.3895
2022-10-02 09:40:59 - train: epoch 0245, iter [00340, 01251], lr: 0.000474, loss: 0.4048
2022-10-02 09:41:16 - train: epoch 0245, iter [00350, 01251], lr: 0.000474, loss: 0.3988
2022-10-02 09:41:34 - train: epoch 0245, iter [00360, 01251], lr: 0.000474, loss: 0.3973
2022-10-02 09:41:52 - train: epoch 0245, iter [00370, 01251], lr: 0.000474, loss: 0.4187
2022-10-02 09:42:10 - train: epoch 0245, iter [00380, 01251], lr: 0.000474, loss: 0.3925
2022-10-02 09:42:28 - train: epoch 0245, iter [00390, 01251], lr: 0.000474, loss: 0.4141
2022-10-02 09:42:46 - train: epoch 0245, iter [00400, 01251], lr: 0.000474, loss: 0.4033
2022-10-02 09:43:04 - train: epoch 0245, iter [00410, 01251], lr: 0.000474, loss: 0.4033
2022-10-02 09:43:22 - train: epoch 0245, iter [00420, 01251], lr: 0.000474, loss: 0.4029
2022-10-02 09:43:40 - train: epoch 0245, iter [00430, 01251], lr: 0.000473, loss: 0.4158
2022-10-02 09:43:58 - train: epoch 0245, iter [00440, 01251], lr: 0.000473, loss: 0.4036
2022-10-02 09:44:15 - train: epoch 0245, iter [00450, 01251], lr: 0.000473, loss: 0.3977
2022-10-02 09:44:33 - train: epoch 0245, iter [00460, 01251], lr: 0.000473, loss: 0.4055
2022-10-02 09:44:51 - train: epoch 0245, iter [00470, 01251], lr: 0.000473, loss: 0.3934
2022-10-02 09:45:09 - train: epoch 0245, iter [00480, 01251], lr: 0.000473, loss: 0.3951
2022-10-02 09:45:27 - train: epoch 0245, iter [00490, 01251], lr: 0.000473, loss: 0.4091
2022-10-02 09:45:45 - train: epoch 0245, iter [00500, 01251], lr: 0.000473, loss: 0.3928
2022-10-02 09:46:03 - train: epoch 0245, iter [00510, 01251], lr: 0.000473, loss: 0.3980
2022-10-02 09:46:21 - train: epoch 0245, iter [00520, 01251], lr: 0.000473, loss: 0.3961
2022-10-02 09:46:39 - train: epoch 0245, iter [00530, 01251], lr: 0.000473, loss: 0.4170
2022-10-02 09:46:56 - train: epoch 0245, iter [00540, 01251], lr: 0.000473, loss: 0.3813
2022-10-02 09:47:14 - train: epoch 0245, iter [00550, 01251], lr: 0.000473, loss: 0.4044
2022-10-02 09:47:32 - train: epoch 0245, iter [00560, 01251], lr: 0.000473, loss: 0.4152
2022-10-02 09:47:50 - train: epoch 0245, iter [00570, 01251], lr: 0.000473, loss: 0.3823
2022-10-02 09:48:08 - train: epoch 0245, iter [00580, 01251], lr: 0.000473, loss: 0.4263
2022-10-02 09:48:26 - train: epoch 0245, iter [00590, 01251], lr: 0.000473, loss: 0.3907
2022-10-02 09:48:44 - train: epoch 0245, iter [00600, 01251], lr: 0.000473, loss: 0.4045
2022-10-02 09:49:02 - train: epoch 0245, iter [00610, 01251], lr: 0.000473, loss: 0.4124
2022-10-02 09:49:20 - train: epoch 0245, iter [00620, 01251], lr: 0.000473, loss: 0.3992
2022-10-02 09:49:38 - train: epoch 0245, iter [00630, 01251], lr: 0.000473, loss: 0.3862
2022-10-02 09:49:56 - train: epoch 0245, iter [00640, 01251], lr: 0.000473, loss: 0.4068
2022-10-02 09:50:14 - train: epoch 0245, iter [00650, 01251], lr: 0.000473, loss: 0.4032
2022-10-02 09:50:32 - train: epoch 0245, iter [00660, 01251], lr: 0.000473, loss: 0.3941
2022-10-02 09:50:50 - train: epoch 0245, iter [00670, 01251], lr: 0.000473, loss: 0.4194
2022-10-02 09:51:08 - train: epoch 0245, iter [00680, 01251], lr: 0.000472, loss: 0.4163
2022-10-02 09:51:26 - train: epoch 0245, iter [00690, 01251], lr: 0.000472, loss: 0.4043
2022-10-02 09:51:43 - train: epoch 0245, iter [00700, 01251], lr: 0.000472, loss: 0.4182
2022-10-02 09:52:01 - train: epoch 0245, iter [00710, 01251], lr: 0.000472, loss: 0.4112
2022-10-02 09:52:19 - train: epoch 0245, iter [00720, 01251], lr: 0.000472, loss: 0.4123
2022-10-02 09:52:37 - train: epoch 0245, iter [00730, 01251], lr: 0.000472, loss: 0.3919
2022-10-02 09:52:55 - train: epoch 0245, iter [00740, 01251], lr: 0.000472, loss: 0.4005
2022-10-02 09:53:13 - train: epoch 0245, iter [00750, 01251], lr: 0.000472, loss: 0.3958
2022-10-02 09:53:31 - train: epoch 0245, iter [00760, 01251], lr: 0.000472, loss: 0.3861
2022-10-02 09:53:49 - train: epoch 0245, iter [00770, 01251], lr: 0.000472, loss: 0.4185
2022-10-02 09:54:07 - train: epoch 0245, iter [00780, 01251], lr: 0.000472, loss: 0.4030
2022-10-02 09:54:25 - train: epoch 0245, iter [00790, 01251], lr: 0.000472, loss: 0.3920
2022-10-02 09:54:43 - train: epoch 0245, iter [00800, 01251], lr: 0.000472, loss: 0.4023
2022-10-02 09:55:01 - train: epoch 0245, iter [00810, 01251], lr: 0.000472, loss: 0.4091
2022-10-02 09:55:19 - train: epoch 0245, iter [00820, 01251], lr: 0.000472, loss: 0.3984
2022-10-02 09:55:37 - train: epoch 0245, iter [00830, 01251], lr: 0.000472, loss: 0.3998
2022-10-02 09:55:55 - train: epoch 0245, iter [00840, 01251], lr: 0.000472, loss: 0.4167
2022-10-02 09:56:13 - train: epoch 0245, iter [00850, 01251], lr: 0.000472, loss: 0.3884
2022-10-02 09:56:31 - train: epoch 0245, iter [00860, 01251], lr: 0.000472, loss: 0.3924
2022-10-02 09:56:49 - train: epoch 0245, iter [00870, 01251], lr: 0.000472, loss: 0.4196
2022-10-02 09:57:07 - train: epoch 0245, iter [00880, 01251], lr: 0.000472, loss: 0.4037
2022-10-02 09:57:25 - train: epoch 0245, iter [00890, 01251], lr: 0.000472, loss: 0.3815
2022-10-02 09:57:43 - train: epoch 0245, iter [00900, 01251], lr: 0.000472, loss: 0.4267
2022-10-02 09:58:01 - train: epoch 0245, iter [00910, 01251], lr: 0.000472, loss: 0.3890
2022-10-02 09:58:19 - train: epoch 0245, iter [00920, 01251], lr: 0.000471, loss: 0.4006
2022-10-02 09:58:37 - train: epoch 0245, iter [00930, 01251], lr: 0.000471, loss: 0.3988
2022-10-02 09:58:55 - train: epoch 0245, iter [00940, 01251], lr: 0.000471, loss: 0.3912
2022-10-02 09:59:13 - train: epoch 0245, iter [00950, 01251], lr: 0.000471, loss: 0.4124
2022-10-02 09:59:31 - train: epoch 0245, iter [00960, 01251], lr: 0.000471, loss: 0.4319
2022-10-02 09:59:49 - train: epoch 0245, iter [00970, 01251], lr: 0.000471, loss: 0.4233
2022-10-02 10:00:07 - train: epoch 0245, iter [00980, 01251], lr: 0.000471, loss: 0.3985
2022-10-02 10:00:25 - train: epoch 0245, iter [00990, 01251], lr: 0.000471, loss: 0.3941
2022-10-02 10:00:43 - train: epoch 0245, iter [01000, 01251], lr: 0.000471, loss: 0.3936
2022-10-02 10:01:01 - train: epoch 0245, iter [01010, 01251], lr: 0.000471, loss: 0.4191
2022-10-02 10:01:19 - train: epoch 0245, iter [01020, 01251], lr: 0.000471, loss: 0.4193
2022-10-02 10:01:36 - train: epoch 0245, iter [01030, 01251], lr: 0.000471, loss: 0.4004
2022-10-02 10:01:54 - train: epoch 0245, iter [01040, 01251], lr: 0.000471, loss: 0.3945
2022-10-02 10:02:12 - train: epoch 0245, iter [01050, 01251], lr: 0.000471, loss: 0.3875
2022-10-02 10:02:30 - train: epoch 0245, iter [01060, 01251], lr: 0.000471, loss: 0.4100
2022-10-02 10:02:48 - train: epoch 0245, iter [01070, 01251], lr: 0.000471, loss: 0.4074
2022-10-02 10:03:06 - train: epoch 0245, iter [01080, 01251], lr: 0.000471, loss: 0.4146
2022-10-02 10:03:24 - train: epoch 0245, iter [01090, 01251], lr: 0.000471, loss: 0.3927
2022-10-02 10:03:43 - train: epoch 0245, iter [01100, 01251], lr: 0.000471, loss: 0.3922
2022-10-02 10:04:00 - train: epoch 0245, iter [01110, 01251], lr: 0.000471, loss: 0.3998
2022-10-02 10:04:18 - train: epoch 0245, iter [01120, 01251], lr: 0.000471, loss: 0.4113
2022-10-02 10:04:36 - train: epoch 0245, iter [01130, 01251], lr: 0.000471, loss: 0.4124
2022-10-02 10:04:54 - train: epoch 0245, iter [01140, 01251], lr: 0.000471, loss: 0.3864
2022-10-02 10:05:12 - train: epoch 0245, iter [01150, 01251], lr: 0.000471, loss: 0.4069
2022-10-02 10:05:30 - train: epoch 0245, iter [01160, 01251], lr: 0.000471, loss: 0.4022
2022-10-02 10:05:48 - train: epoch 0245, iter [01170, 01251], lr: 0.000470, loss: 0.4269
2022-10-02 10:06:06 - train: epoch 0245, iter [01180, 01251], lr: 0.000470, loss: 0.4103
2022-10-02 10:06:24 - train: epoch 0245, iter [01190, 01251], lr: 0.000470, loss: 0.4179
2022-10-02 10:06:42 - train: epoch 0245, iter [01200, 01251], lr: 0.000470, loss: 0.4109
2022-10-02 10:07:00 - train: epoch 0245, iter [01210, 01251], lr: 0.000470, loss: 0.3942
2022-10-02 10:07:18 - train: epoch 0245, iter [01220, 01251], lr: 0.000470, loss: 0.4051
2022-10-02 10:07:36 - train: epoch 0245, iter [01230, 01251], lr: 0.000470, loss: 0.4169
2022-10-02 10:07:54 - train: epoch 0245, iter [01240, 01251], lr: 0.000470, loss: 0.4132
2022-10-02 10:08:12 - train: epoch 0245, iter [01250, 01251], lr: 0.000470, loss: 0.3948
2022-10-02 10:08:15 - train: epoch 245, train_loss: 0.4032
2022-10-02 10:08:17 - until epoch: 245, best_loss: 0.4032
2022-10-02 10:08:17 - epoch 246 lr: 0.000470
2022-10-02 10:08:42 - train: epoch 0246, iter [00010, 01251], lr: 0.000470, loss: 0.4108
2022-10-02 10:09:00 - train: epoch 0246, iter [00020, 01251], lr: 0.000470, loss: 0.4116
2022-10-02 10:09:18 - train: epoch 0246, iter [00030, 01251], lr: 0.000470, loss: 0.3761
2022-10-02 10:09:36 - train: epoch 0246, iter [00040, 01251], lr: 0.000470, loss: 0.4025
2022-10-02 10:09:54 - train: epoch 0246, iter [00050, 01251], lr: 0.000470, loss: 0.4104
2022-10-02 10:10:12 - train: epoch 0246, iter [00060, 01251], lr: 0.000470, loss: 0.3924
2022-10-02 10:10:29 - train: epoch 0246, iter [00070, 01251], lr: 0.000470, loss: 0.3967
2022-10-02 10:10:47 - train: epoch 0246, iter [00080, 01251], lr: 0.000470, loss: 0.3933
2022-10-02 10:11:05 - train: epoch 0246, iter [00090, 01251], lr: 0.000470, loss: 0.3939
2022-10-02 10:11:23 - train: epoch 0246, iter [00100, 01251], lr: 0.000470, loss: 0.4144
2022-10-02 10:11:41 - train: epoch 0246, iter [00110, 01251], lr: 0.000470, loss: 0.4183
2022-10-02 10:11:59 - train: epoch 0246, iter [00120, 01251], lr: 0.000470, loss: 0.3984
2022-10-02 10:12:17 - train: epoch 0246, iter [00130, 01251], lr: 0.000470, loss: 0.4105
2022-10-02 10:12:35 - train: epoch 0246, iter [00140, 01251], lr: 0.000470, loss: 0.4010
2022-10-02 10:12:53 - train: epoch 0246, iter [00150, 01251], lr: 0.000470, loss: 0.3734
2022-10-02 10:13:11 - train: epoch 0246, iter [00160, 01251], lr: 0.000469, loss: 0.3989
2022-10-02 10:13:29 - train: epoch 0246, iter [00170, 01251], lr: 0.000469, loss: 0.4095
2022-10-02 10:13:47 - train: epoch 0246, iter [00180, 01251], lr: 0.000469, loss: 0.3937
2022-10-02 10:14:05 - train: epoch 0246, iter [00190, 01251], lr: 0.000469, loss: 0.4105
2022-10-02 10:14:23 - train: epoch 0246, iter [00200, 01251], lr: 0.000469, loss: 0.4134
2022-10-02 10:14:40 - train: epoch 0246, iter [00210, 01251], lr: 0.000469, loss: 0.3994
2022-10-02 10:14:58 - train: epoch 0246, iter [00220, 01251], lr: 0.000469, loss: 0.4162
2022-10-02 10:15:15 - train: epoch 0246, iter [00230, 01251], lr: 0.000469, loss: 0.4016
2022-10-02 10:15:33 - train: epoch 0246, iter [00240, 01251], lr: 0.000469, loss: 0.3953
2022-10-02 10:15:51 - train: epoch 0246, iter [00250, 01251], lr: 0.000469, loss: 0.4096
2022-10-02 10:16:09 - train: epoch 0246, iter [00260, 01251], lr: 0.000469, loss: 0.3935
2022-10-02 10:16:26 - train: epoch 0246, iter [00270, 01251], lr: 0.000469, loss: 0.3953
2022-10-02 10:16:43 - train: epoch 0246, iter [00280, 01251], lr: 0.000469, loss: 0.4021
2022-10-02 10:17:01 - train: epoch 0246, iter [00290, 01251], lr: 0.000469, loss: 0.3939
2022-10-02 10:17:19 - train: epoch 0246, iter [00300, 01251], lr: 0.000469, loss: 0.3984
2022-10-02 10:17:36 - train: epoch 0246, iter [00310, 01251], lr: 0.000469, loss: 0.4118
2022-10-02 10:17:54 - train: epoch 0246, iter [00320, 01251], lr: 0.000469, loss: 0.4018
2022-10-02 10:18:12 - train: epoch 0246, iter [00330, 01251], lr: 0.000469, loss: 0.4084
2022-10-02 10:18:30 - train: epoch 0246, iter [00340, 01251], lr: 0.000469, loss: 0.3935
2022-10-02 10:18:47 - train: epoch 0246, iter [00350, 01251], lr: 0.000469, loss: 0.4117
2022-10-02 10:19:05 - train: epoch 0246, iter [00360, 01251], lr: 0.000469, loss: 0.4013
2022-10-02 10:19:22 - train: epoch 0246, iter [00370, 01251], lr: 0.000469, loss: 0.4117
2022-10-02 10:19:40 - train: epoch 0246, iter [00380, 01251], lr: 0.000469, loss: 0.3733
2022-10-02 10:19:58 - train: epoch 0246, iter [00390, 01251], lr: 0.000469, loss: 0.4174
2022-10-02 10:20:15 - train: epoch 0246, iter [00400, 01251], lr: 0.000469, loss: 0.4137
2022-10-02 10:20:33 - train: epoch 0246, iter [00410, 01251], lr: 0.000468, loss: 0.3882
2022-10-02 10:20:50 - train: epoch 0246, iter [00420, 01251], lr: 0.000468, loss: 0.4149
2022-10-02 10:21:08 - train: epoch 0246, iter [00430, 01251], lr: 0.000468, loss: 0.4037
2022-10-02 10:21:25 - train: epoch 0246, iter [00440, 01251], lr: 0.000468, loss: 0.3957
2022-10-02 10:21:43 - train: epoch 0246, iter [00450, 01251], lr: 0.000468, loss: 0.3958
2022-10-02 10:22:00 - train: epoch 0246, iter [00460, 01251], lr: 0.000468, loss: 0.4005
2022-10-02 10:22:18 - train: epoch 0246, iter [00470, 01251], lr: 0.000468, loss: 0.3831
2022-10-02 10:22:36 - train: epoch 0246, iter [00480, 01251], lr: 0.000468, loss: 0.3998
2022-10-02 10:22:53 - train: epoch 0246, iter [00490, 01251], lr: 0.000468, loss: 0.3964
2022-10-02 10:23:11 - train: epoch 0246, iter [00500, 01251], lr: 0.000468, loss: 0.4026
2022-10-02 10:23:28 - train: epoch 0246, iter [00510, 01251], lr: 0.000468, loss: 0.3975
2022-10-02 10:23:46 - train: epoch 0246, iter [00520, 01251], lr: 0.000468, loss: 0.4011
2022-10-02 10:24:04 - train: epoch 0246, iter [00530, 01251], lr: 0.000468, loss: 0.4135
2022-10-02 10:24:21 - train: epoch 0246, iter [00540, 01251], lr: 0.000468, loss: 0.3792
2022-10-02 10:24:39 - train: epoch 0246, iter [00550, 01251], lr: 0.000468, loss: 0.4001
2022-10-02 10:24:56 - train: epoch 0246, iter [00560, 01251], lr: 0.000468, loss: 0.3986
2022-10-02 10:25:14 - train: epoch 0246, iter [00570, 01251], lr: 0.000468, loss: 0.4051
2022-10-02 10:25:31 - train: epoch 0246, iter [00580, 01251], lr: 0.000468, loss: 0.4092
2022-10-02 10:25:49 - train: epoch 0246, iter [00590, 01251], lr: 0.000468, loss: 0.4205
2022-10-02 10:26:07 - train: epoch 0246, iter [00600, 01251], lr: 0.000468, loss: 0.3931
2022-10-02 10:26:24 - train: epoch 0246, iter [00610, 01251], lr: 0.000468, loss: 0.3845
2022-10-02 10:26:42 - train: epoch 0246, iter [00620, 01251], lr: 0.000468, loss: 0.3960
2022-10-02 10:26:59 - train: epoch 0246, iter [00630, 01251], lr: 0.000468, loss: 0.3916
2022-10-02 10:27:17 - train: epoch 0246, iter [00640, 01251], lr: 0.000468, loss: 0.4147
2022-10-02 10:27:35 - train: epoch 0246, iter [00650, 01251], lr: 0.000467, loss: 0.4098
2022-10-02 10:27:52 - train: epoch 0246, iter [00660, 01251], lr: 0.000467, loss: 0.3911
2022-10-02 10:28:10 - train: epoch 0246, iter [00670, 01251], lr: 0.000467, loss: 0.3847
2022-10-02 10:28:28 - train: epoch 0246, iter [00680, 01251], lr: 0.000467, loss: 0.3930
2022-10-02 10:28:45 - train: epoch 0246, iter [00690, 01251], lr: 0.000467, loss: 0.4089
2022-10-02 10:29:03 - train: epoch 0246, iter [00700, 01251], lr: 0.000467, loss: 0.3973
2022-10-02 10:29:20 - train: epoch 0246, iter [00710, 01251], lr: 0.000467, loss: 0.4100
2022-10-02 10:29:38 - train: epoch 0246, iter [00720, 01251], lr: 0.000467, loss: 0.3942
2022-10-02 10:29:55 - train: epoch 0246, iter [00730, 01251], lr: 0.000467, loss: 0.4198
2022-10-02 10:30:13 - train: epoch 0246, iter [00740, 01251], lr: 0.000467, loss: 0.4141
2022-10-02 10:30:30 - train: epoch 0246, iter [00750, 01251], lr: 0.000467, loss: 0.4051
2022-10-02 10:30:48 - train: epoch 0246, iter [00760, 01251], lr: 0.000467, loss: 0.4002
2022-10-02 10:31:05 - train: epoch 0246, iter [00770, 01251], lr: 0.000467, loss: 0.3957
2022-10-02 10:31:23 - train: epoch 0246, iter [00780, 01251], lr: 0.000467, loss: 0.3983
2022-10-02 10:31:40 - train: epoch 0246, iter [00790, 01251], lr: 0.000467, loss: 0.4025
2022-10-02 10:31:58 - train: epoch 0246, iter [00800, 01251], lr: 0.000467, loss: 0.4011
2022-10-02 10:32:15 - train: epoch 0246, iter [00810, 01251], lr: 0.000467, loss: 0.3987
2022-10-02 10:32:33 - train: epoch 0246, iter [00820, 01251], lr: 0.000467, loss: 0.4057
2022-10-02 10:32:50 - train: epoch 0246, iter [00830, 01251], lr: 0.000467, loss: 0.3946
2022-10-02 10:33:08 - train: epoch 0246, iter [00840, 01251], lr: 0.000467, loss: 0.4175
2022-10-02 10:33:26 - train: epoch 0246, iter [00850, 01251], lr: 0.000467, loss: 0.3928
2022-10-02 10:33:43 - train: epoch 0246, iter [00860, 01251], lr: 0.000467, loss: 0.4143
2022-10-02 10:34:01 - train: epoch 0246, iter [00870, 01251], lr: 0.000467, loss: 0.4068
2022-10-02 10:34:18 - train: epoch 0246, iter [00880, 01251], lr: 0.000467, loss: 0.3960
2022-10-02 10:34:36 - train: epoch 0246, iter [00890, 01251], lr: 0.000467, loss: 0.4069
2022-10-02 10:34:53 - train: epoch 0246, iter [00900, 01251], lr: 0.000466, loss: 0.4087
2022-10-02 10:35:11 - train: epoch 0246, iter [00910, 01251], lr: 0.000466, loss: 0.4192
2022-10-02 10:35:29 - train: epoch 0246, iter [00920, 01251], lr: 0.000466, loss: 0.3990
2022-10-02 10:35:47 - train: epoch 0246, iter [00930, 01251], lr: 0.000466, loss: 0.3974
2022-10-02 10:36:04 - train: epoch 0246, iter [00940, 01251], lr: 0.000466, loss: 0.4161
2022-10-02 10:36:22 - train: epoch 0246, iter [00950, 01251], lr: 0.000466, loss: 0.4064
2022-10-02 10:36:39 - train: epoch 0246, iter [00960, 01251], lr: 0.000466, loss: 0.4063
2022-10-02 10:36:57 - train: epoch 0246, iter [00970, 01251], lr: 0.000466, loss: 0.4035
2022-10-02 10:37:15 - train: epoch 0246, iter [00980, 01251], lr: 0.000466, loss: 0.3982
2022-10-02 10:37:32 - train: epoch 0246, iter [00990, 01251], lr: 0.000466, loss: 0.3888
2022-10-02 10:37:50 - train: epoch 0246, iter [01000, 01251], lr: 0.000466, loss: 0.4026
2022-10-02 10:38:08 - train: epoch 0246, iter [01010, 01251], lr: 0.000466, loss: 0.3955
2022-10-02 10:38:25 - train: epoch 0246, iter [01020, 01251], lr: 0.000466, loss: 0.4283
2022-10-02 10:38:43 - train: epoch 0246, iter [01030, 01251], lr: 0.000466, loss: 0.3999
2022-10-02 10:39:00 - train: epoch 0246, iter [01040, 01251], lr: 0.000466, loss: 0.3948
2022-10-02 10:39:18 - train: epoch 0246, iter [01050, 01251], lr: 0.000466, loss: 0.4089
2022-10-02 10:39:35 - train: epoch 0246, iter [01060, 01251], lr: 0.000466, loss: 0.3901
2022-10-02 10:39:53 - train: epoch 0246, iter [01070, 01251], lr: 0.000466, loss: 0.3910
2022-10-02 10:40:11 - train: epoch 0246, iter [01080, 01251], lr: 0.000466, loss: 0.4004
2022-10-02 10:40:28 - train: epoch 0246, iter [01090, 01251], lr: 0.000466, loss: 0.4093
2022-10-02 10:40:46 - train: epoch 0246, iter [01100, 01251], lr: 0.000466, loss: 0.3957
2022-10-02 10:41:03 - train: epoch 0246, iter [01110, 01251], lr: 0.000466, loss: 0.3903
2022-10-02 10:41:21 - train: epoch 0246, iter [01120, 01251], lr: 0.000466, loss: 0.4186
2022-10-02 10:41:38 - train: epoch 0246, iter [01130, 01251], lr: 0.000466, loss: 0.3965
2022-10-02 10:41:56 - train: epoch 0246, iter [01140, 01251], lr: 0.000465, loss: 0.3984
2022-10-02 10:42:13 - train: epoch 0246, iter [01150, 01251], lr: 0.000465, loss: 0.3842
2022-10-02 10:42:31 - train: epoch 0246, iter [01160, 01251], lr: 0.000465, loss: 0.4017
2022-10-02 10:42:48 - train: epoch 0246, iter [01170, 01251], lr: 0.000465, loss: 0.4029
2022-10-02 10:43:06 - train: epoch 0246, iter [01180, 01251], lr: 0.000465, loss: 0.4068
2022-10-02 10:43:24 - train: epoch 0246, iter [01190, 01251], lr: 0.000465, loss: 0.4239
2022-10-02 10:43:41 - train: epoch 0246, iter [01200, 01251], lr: 0.000465, loss: 0.3886
2022-10-02 10:43:59 - train: epoch 0246, iter [01210, 01251], lr: 0.000465, loss: 0.4071
2022-10-02 10:44:17 - train: epoch 0246, iter [01220, 01251], lr: 0.000465, loss: 0.4014
2022-10-02 10:44:34 - train: epoch 0246, iter [01230, 01251], lr: 0.000465, loss: 0.4191
2022-10-02 10:44:52 - train: epoch 0246, iter [01240, 01251], lr: 0.000465, loss: 0.4025
2022-10-02 10:45:09 - train: epoch 0246, iter [01250, 01251], lr: 0.000465, loss: 0.4151
2022-10-02 10:45:12 - train: epoch 246, train_loss: 0.4031
2022-10-02 10:45:15 - until epoch: 246, best_loss: 0.4031
2022-10-02 10:45:15 - epoch 247 lr: 0.000465
2022-10-02 10:45:41 - train: epoch 0247, iter [00010, 01251], lr: 0.000465, loss: 0.4077
2022-10-02 10:45:58 - train: epoch 0247, iter [00020, 01251], lr: 0.000465, loss: 0.4164
2022-10-02 10:46:16 - train: epoch 0247, iter [00030, 01251], lr: 0.000465, loss: 0.3961
2022-10-02 10:46:34 - train: epoch 0247, iter [00040, 01251], lr: 0.000465, loss: 0.3937
2022-10-02 10:46:52 - train: epoch 0247, iter [00050, 01251], lr: 0.000465, loss: 0.4020
2022-10-02 10:47:09 - train: epoch 0247, iter [00060, 01251], lr: 0.000465, loss: 0.3928
2022-10-02 10:47:27 - train: epoch 0247, iter [00070, 01251], lr: 0.000465, loss: 0.4241
2022-10-02 10:47:45 - train: epoch 0247, iter [00080, 01251], lr: 0.000465, loss: 0.3991
2022-10-02 10:48:03 - train: epoch 0247, iter [00090, 01251], lr: 0.000465, loss: 0.4113
2022-10-02 10:48:20 - train: epoch 0247, iter [00100, 01251], lr: 0.000465, loss: 0.3882
2022-10-02 10:48:38 - train: epoch 0247, iter [00110, 01251], lr: 0.000465, loss: 0.4041
2022-10-02 10:48:56 - train: epoch 0247, iter [00120, 01251], lr: 0.000465, loss: 0.3902
2022-10-02 10:49:14 - train: epoch 0247, iter [00130, 01251], lr: 0.000464, loss: 0.4133
2022-10-02 10:49:32 - train: epoch 0247, iter [00140, 01251], lr: 0.000464, loss: 0.3994
2022-10-02 10:49:50 - train: epoch 0247, iter [00150, 01251], lr: 0.000464, loss: 0.4237
2022-10-02 10:50:08 - train: epoch 0247, iter [00160, 01251], lr: 0.000464, loss: 0.3975
2022-10-02 10:50:26 - train: epoch 0247, iter [00170, 01251], lr: 0.000464, loss: 0.4028
2022-10-02 10:50:44 - train: epoch 0247, iter [00180, 01251], lr: 0.000464, loss: 0.4106
2022-10-02 10:51:01 - train: epoch 0247, iter [00190, 01251], lr: 0.000464, loss: 0.4205
2022-10-02 10:51:20 - train: epoch 0247, iter [00200, 01251], lr: 0.000464, loss: 0.3929
2022-10-02 10:51:37 - train: epoch 0247, iter [00210, 01251], lr: 0.000464, loss: 0.4065
2022-10-02 10:51:55 - train: epoch 0247, iter [00220, 01251], lr: 0.000464, loss: 0.3936
2022-10-02 10:52:13 - train: epoch 0247, iter [00230, 01251], lr: 0.000464, loss: 0.3967
2022-10-02 10:52:31 - train: epoch 0247, iter [00240, 01251], lr: 0.000464, loss: 0.3923
2022-10-02 10:52:49 - train: epoch 0247, iter [00250, 01251], lr: 0.000464, loss: 0.4080
2022-10-02 10:53:06 - train: epoch 0247, iter [00260, 01251], lr: 0.000464, loss: 0.4220
2022-10-02 10:53:24 - train: epoch 0247, iter [00270, 01251], lr: 0.000464, loss: 0.4147
2022-10-02 10:53:42 - train: epoch 0247, iter [00280, 01251], lr: 0.000464, loss: 0.4276
2022-10-02 10:54:00 - train: epoch 0247, iter [00290, 01251], lr: 0.000464, loss: 0.4084
2022-10-02 10:54:17 - train: epoch 0247, iter [00300, 01251], lr: 0.000464, loss: 0.4063
2022-10-02 10:54:35 - train: epoch 0247, iter [00310, 01251], lr: 0.000464, loss: 0.4187
2022-10-02 10:54:53 - train: epoch 0247, iter [00320, 01251], lr: 0.000464, loss: 0.3998
2022-10-02 10:55:11 - train: epoch 0247, iter [00330, 01251], lr: 0.000464, loss: 0.4068
2022-10-02 10:55:29 - train: epoch 0247, iter [00340, 01251], lr: 0.000464, loss: 0.3942
2022-10-02 10:55:47 - train: epoch 0247, iter [00350, 01251], lr: 0.000464, loss: 0.4075
2022-10-02 10:56:05 - train: epoch 0247, iter [00360, 01251], lr: 0.000464, loss: 0.4015
2022-10-02 10:56:22 - train: epoch 0247, iter [00370, 01251], lr: 0.000464, loss: 0.4027
2022-10-02 10:56:40 - train: epoch 0247, iter [00380, 01251], lr: 0.000463, loss: 0.4016
2022-10-02 10:56:57 - train: epoch 0247, iter [00390, 01251], lr: 0.000463, loss: 0.4050
2022-10-02 10:57:15 - train: epoch 0247, iter [00400, 01251], lr: 0.000463, loss: 0.3813
2022-10-02 10:57:33 - train: epoch 0247, iter [00410, 01251], lr: 0.000463, loss: 0.3992
2022-10-02 10:57:51 - train: epoch 0247, iter [00420, 01251], lr: 0.000463, loss: 0.4104
2022-10-02 10:58:09 - train: epoch 0247, iter [00430, 01251], lr: 0.000463, loss: 0.3905
2022-10-02 10:58:26 - train: epoch 0247, iter [00440, 01251], lr: 0.000463, loss: 0.3877
2022-10-02 10:58:44 - train: epoch 0247, iter [00450, 01251], lr: 0.000463, loss: 0.3903
2022-10-02 10:59:01 - train: epoch 0247, iter [00460, 01251], lr: 0.000463, loss: 0.3949
2022-10-02 10:59:19 - train: epoch 0247, iter [00470, 01251], lr: 0.000463, loss: 0.4088
2022-10-02 10:59:37 - train: epoch 0247, iter [00480, 01251], lr: 0.000463, loss: 0.4122
2022-10-02 10:59:55 - train: epoch 0247, iter [00490, 01251], lr: 0.000463, loss: 0.4003
2022-10-02 11:00:13 - train: epoch 0247, iter [00500, 01251], lr: 0.000463, loss: 0.3940
2022-10-02 11:00:30 - train: epoch 0247, iter [00510, 01251], lr: 0.000463, loss: 0.4000
2022-10-02 11:00:48 - train: epoch 0247, iter [00520, 01251], lr: 0.000463, loss: 0.4058
2022-10-02 11:01:06 - train: epoch 0247, iter [00530, 01251], lr: 0.000463, loss: 0.4200
2022-10-02 11:01:24 - train: epoch 0247, iter [00540, 01251], lr: 0.000463, loss: 0.4031
2022-10-02 11:01:41 - train: epoch 0247, iter [00550, 01251], lr: 0.000463, loss: 0.4067
2022-10-02 11:01:59 - train: epoch 0247, iter [00560, 01251], lr: 0.000463, loss: 0.4025
2022-10-02 11:02:17 - train: epoch 0247, iter [00570, 01251], lr: 0.000463, loss: 0.3916
2022-10-02 11:02:35 - train: epoch 0247, iter [00580, 01251], lr: 0.000463, loss: 0.4141
2022-10-02 11:02:52 - train: epoch 0247, iter [00590, 01251], lr: 0.000463, loss: 0.4157
2022-10-02 11:03:10 - train: epoch 0247, iter [00600, 01251], lr: 0.000463, loss: 0.3988
2022-10-02 11:03:28 - train: epoch 0247, iter [00610, 01251], lr: 0.000463, loss: 0.4003
2022-10-02 11:03:45 - train: epoch 0247, iter [00620, 01251], lr: 0.000463, loss: 0.4013
2022-10-02 11:04:03 - train: epoch 0247, iter [00630, 01251], lr: 0.000462, loss: 0.3951
2022-10-02 11:04:21 - train: epoch 0247, iter [00640, 01251], lr: 0.000462, loss: 0.4044
2022-10-02 11:04:39 - train: epoch 0247, iter [00650, 01251], lr: 0.000462, loss: 0.4152
2022-10-02 11:04:56 - train: epoch 0247, iter [00660, 01251], lr: 0.000462, loss: 0.4168
2022-10-02 11:05:14 - train: epoch 0247, iter [00670, 01251], lr: 0.000462, loss: 0.4144
2022-10-02 11:05:32 - train: epoch 0247, iter [00680, 01251], lr: 0.000462, loss: 0.3971
2022-10-02 11:05:50 - train: epoch 0247, iter [00690, 01251], lr: 0.000462, loss: 0.4202
2022-10-02 11:06:08 - train: epoch 0247, iter [00700, 01251], lr: 0.000462, loss: 0.4072
2022-10-02 11:06:25 - train: epoch 0247, iter [00710, 01251], lr: 0.000462, loss: 0.3945
2022-10-02 11:06:43 - train: epoch 0247, iter [00720, 01251], lr: 0.000462, loss: 0.3933
2022-10-02 11:07:01 - train: epoch 0247, iter [00730, 01251], lr: 0.000462, loss: 0.3963
2022-10-02 11:07:19 - train: epoch 0247, iter [00740, 01251], lr: 0.000462, loss: 0.4194
2022-10-02 11:07:36 - train: epoch 0247, iter [00750, 01251], lr: 0.000462, loss: 0.3833
2022-10-02 11:07:54 - train: epoch 0247, iter [00760, 01251], lr: 0.000462, loss: 0.3778
2022-10-02 11:08:12 - train: epoch 0247, iter [00770, 01251], lr: 0.000462, loss: 0.4096
2022-10-02 11:08:30 - train: epoch 0247, iter [00780, 01251], lr: 0.000462, loss: 0.4165
2022-10-02 11:08:48 - train: epoch 0247, iter [00790, 01251], lr: 0.000462, loss: 0.3997
2022-10-02 11:09:05 - train: epoch 0247, iter [00800, 01251], lr: 0.000462, loss: 0.3956
2022-10-02 11:09:23 - train: epoch 0247, iter [00810, 01251], lr: 0.000462, loss: 0.3979
2022-10-02 11:09:41 - train: epoch 0247, iter [00820, 01251], lr: 0.000462, loss: 0.4078
2022-10-02 11:09:59 - train: epoch 0247, iter [00830, 01251], lr: 0.000462, loss: 0.4020
2022-10-02 11:10:16 - train: epoch 0247, iter [00840, 01251], lr: 0.000462, loss: 0.4115
2022-10-02 11:10:34 - train: epoch 0247, iter [00850, 01251], lr: 0.000462, loss: 0.4101
2022-10-02 11:10:52 - train: epoch 0247, iter [00860, 01251], lr: 0.000462, loss: 0.3957
2022-10-02 11:11:10 - train: epoch 0247, iter [00870, 01251], lr: 0.000461, loss: 0.3957
2022-10-02 11:11:27 - train: epoch 0247, iter [00880, 01251], lr: 0.000461, loss: 0.3931
2022-10-02 11:11:45 - train: epoch 0247, iter [00890, 01251], lr: 0.000461, loss: 0.3990
2022-10-02 11:12:03 - train: epoch 0247, iter [00900, 01251], lr: 0.000461, loss: 0.4052
2022-10-02 11:12:20 - train: epoch 0247, iter [00910, 01251], lr: 0.000461, loss: 0.4028
2022-10-02 11:12:38 - train: epoch 0247, iter [00920, 01251], lr: 0.000461, loss: 0.4069
2022-10-02 11:12:56 - train: epoch 0247, iter [00930, 01251], lr: 0.000461, loss: 0.4249
2022-10-02 11:13:14 - train: epoch 0247, iter [00940, 01251], lr: 0.000461, loss: 0.3954
2022-10-02 11:13:32 - train: epoch 0247, iter [00950, 01251], lr: 0.000461, loss: 0.3848
2022-10-02 11:13:49 - train: epoch 0247, iter [00960, 01251], lr: 0.000461, loss: 0.4057
2022-10-02 11:14:07 - train: epoch 0247, iter [00970, 01251], lr: 0.000461, loss: 0.3812
2022-10-02 11:14:25 - train: epoch 0247, iter [00980, 01251], lr: 0.000461, loss: 0.4091
2022-10-02 11:14:43 - train: epoch 0247, iter [00990, 01251], lr: 0.000461, loss: 0.4070
2022-10-02 11:15:00 - train: epoch 0247, iter [01000, 01251], lr: 0.000461, loss: 0.3855
2022-10-02 11:15:18 - train: epoch 0247, iter [01010, 01251], lr: 0.000461, loss: 0.4390
2022-10-02 11:15:36 - train: epoch 0247, iter [01020, 01251], lr: 0.000461, loss: 0.3979
2022-10-02 11:15:54 - train: epoch 0247, iter [01030, 01251], lr: 0.000461, loss: 0.4080
2022-10-02 11:16:12 - train: epoch 0247, iter [01040, 01251], lr: 0.000461, loss: 0.4189
2022-10-02 11:16:29 - train: epoch 0247, iter [01050, 01251], lr: 0.000461, loss: 0.4207
2022-10-02 11:16:47 - train: epoch 0247, iter [01060, 01251], lr: 0.000461, loss: 0.4108
2022-10-02 11:17:05 - train: epoch 0247, iter [01070, 01251], lr: 0.000461, loss: 0.4015
2022-10-02 11:17:23 - train: epoch 0247, iter [01080, 01251], lr: 0.000461, loss: 0.4091
2022-10-02 11:17:41 - train: epoch 0247, iter [01090, 01251], lr: 0.000461, loss: 0.4310
2022-10-02 11:17:58 - train: epoch 0247, iter [01100, 01251], lr: 0.000461, loss: 0.3895
2022-10-02 11:18:16 - train: epoch 0247, iter [01110, 01251], lr: 0.000461, loss: 0.4103
2022-10-02 11:18:34 - train: epoch 0247, iter [01120, 01251], lr: 0.000460, loss: 0.3796
2022-10-02 11:18:52 - train: epoch 0247, iter [01130, 01251], lr: 0.000460, loss: 0.4298
2022-10-02 11:19:09 - train: epoch 0247, iter [01140, 01251], lr: 0.000460, loss: 0.4097
2022-10-02 11:19:27 - train: epoch 0247, iter [01150, 01251], lr: 0.000460, loss: 0.4062
2022-10-02 11:19:45 - train: epoch 0247, iter [01160, 01251], lr: 0.000460, loss: 0.4075
2022-10-02 11:20:03 - train: epoch 0247, iter [01170, 01251], lr: 0.000460, loss: 0.4262
2022-10-02 11:20:21 - train: epoch 0247, iter [01180, 01251], lr: 0.000460, loss: 0.3864
2022-10-02 11:20:38 - train: epoch 0247, iter [01190, 01251], lr: 0.000460, loss: 0.4034
2022-10-02 11:20:56 - train: epoch 0247, iter [01200, 01251], lr: 0.000460, loss: 0.4004
2022-10-02 11:21:14 - train: epoch 0247, iter [01210, 01251], lr: 0.000460, loss: 0.4008
2022-10-02 11:21:32 - train: epoch 0247, iter [01220, 01251], lr: 0.000460, loss: 0.4091
2022-10-02 11:21:50 - train: epoch 0247, iter [01230, 01251], lr: 0.000460, loss: 0.4030
2022-10-02 11:22:07 - train: epoch 0247, iter [01240, 01251], lr: 0.000460, loss: 0.4217
2022-10-02 11:22:25 - train: epoch 0247, iter [01250, 01251], lr: 0.000460, loss: 0.3953
2022-10-02 11:22:28 - train: epoch 247, train_loss: 0.4031
2022-10-02 11:22:31 - until epoch: 247, best_loss: 0.4031
2022-10-02 11:22:31 - epoch 248 lr: 0.000460
2022-10-02 11:22:56 - train: epoch 0248, iter [00010, 01251], lr: 0.000460, loss: 0.3970
2022-10-02 11:23:14 - train: epoch 0248, iter [00020, 01251], lr: 0.000460, loss: 0.4073
2022-10-02 11:23:32 - train: epoch 0248, iter [00030, 01251], lr: 0.000460, loss: 0.4095
2022-10-02 11:23:49 - train: epoch 0248, iter [00040, 01251], lr: 0.000460, loss: 0.4068
2022-10-02 11:24:07 - train: epoch 0248, iter [00050, 01251], lr: 0.000460, loss: 0.3828
2022-10-02 11:24:25 - train: epoch 0248, iter [00060, 01251], lr: 0.000460, loss: 0.4047
2022-10-02 11:24:42 - train: epoch 0248, iter [00070, 01251], lr: 0.000460, loss: 0.4035
2022-10-02 11:25:00 - train: epoch 0248, iter [00080, 01251], lr: 0.000460, loss: 0.3918
2022-10-02 11:25:18 - train: epoch 0248, iter [00090, 01251], lr: 0.000460, loss: 0.4047
2022-10-02 11:25:35 - train: epoch 0248, iter [00100, 01251], lr: 0.000460, loss: 0.3895
2022-10-02 11:25:53 - train: epoch 0248, iter [00110, 01251], lr: 0.000459, loss: 0.4210
2022-10-02 11:26:11 - train: epoch 0248, iter [00120, 01251], lr: 0.000459, loss: 0.3906
2022-10-02 11:26:29 - train: epoch 0248, iter [00130, 01251], lr: 0.000459, loss: 0.4138
2022-10-02 11:26:46 - train: epoch 0248, iter [00140, 01251], lr: 0.000459, loss: 0.3834
2022-10-02 11:27:04 - train: epoch 0248, iter [00150, 01251], lr: 0.000459, loss: 0.4144
2022-10-02 11:27:22 - train: epoch 0248, iter [00160, 01251], lr: 0.000459, loss: 0.3782
2022-10-02 11:27:39 - train: epoch 0248, iter [00170, 01251], lr: 0.000459, loss: 0.4047
2022-10-02 11:27:57 - train: epoch 0248, iter [00180, 01251], lr: 0.000459, loss: 0.3980
2022-10-02 11:28:15 - train: epoch 0248, iter [00190, 01251], lr: 0.000459, loss: 0.3992
2022-10-02 11:28:33 - train: epoch 0248, iter [00200, 01251], lr: 0.000459, loss: 0.4024
2022-10-02 11:28:51 - train: epoch 0248, iter [00210, 01251], lr: 0.000459, loss: 0.3960
2022-10-02 11:29:08 - train: epoch 0248, iter [00220, 01251], lr: 0.000459, loss: 0.3906
2022-10-02 11:29:26 - train: epoch 0248, iter [00230, 01251], lr: 0.000459, loss: 0.4098
2022-10-02 11:29:44 - train: epoch 0248, iter [00240, 01251], lr: 0.000459, loss: 0.3886
2022-10-02 11:30:01 - train: epoch 0248, iter [00250, 01251], lr: 0.000459, loss: 0.4009
2022-10-02 11:30:19 - train: epoch 0248, iter [00260, 01251], lr: 0.000459, loss: 0.4237
2022-10-02 11:30:37 - train: epoch 0248, iter [00270, 01251], lr: 0.000459, loss: 0.4164
2022-10-02 11:30:55 - train: epoch 0248, iter [00280, 01251], lr: 0.000459, loss: 0.4074
2022-10-02 11:31:13 - train: epoch 0248, iter [00290, 01251], lr: 0.000459, loss: 0.4052
2022-10-02 11:31:31 - train: epoch 0248, iter [00300, 01251], lr: 0.000459, loss: 0.3914
2022-10-02 11:31:49 - train: epoch 0248, iter [00310, 01251], lr: 0.000459, loss: 0.4121
2022-10-02 11:32:07 - train: epoch 0248, iter [00320, 01251], lr: 0.000459, loss: 0.3813
2022-10-02 11:32:25 - train: epoch 0248, iter [00330, 01251], lr: 0.000459, loss: 0.3952
2022-10-02 11:32:43 - train: epoch 0248, iter [00340, 01251], lr: 0.000459, loss: 0.3993
2022-10-02 11:33:01 - train: epoch 0248, iter [00350, 01251], lr: 0.000459, loss: 0.4035
2022-10-02 11:33:18 - train: epoch 0248, iter [00360, 01251], lr: 0.000458, loss: 0.4021
2022-10-02 11:33:36 - train: epoch 0248, iter [00370, 01251], lr: 0.000458, loss: 0.3973
2022-10-02 11:33:54 - train: epoch 0248, iter [00380, 01251], lr: 0.000458, loss: 0.4020
2022-10-02 11:34:12 - train: epoch 0248, iter [00390, 01251], lr: 0.000458, loss: 0.4155
2022-10-02 11:34:30 - train: epoch 0248, iter [00400, 01251], lr: 0.000458, loss: 0.3965
2022-10-02 11:34:48 - train: epoch 0248, iter [00410, 01251], lr: 0.000458, loss: 0.4006
2022-10-02 11:35:06 - train: epoch 0248, iter [00420, 01251], lr: 0.000458, loss: 0.4074
2022-10-02 11:35:24 - train: epoch 0248, iter [00430, 01251], lr: 0.000458, loss: 0.4135
2022-10-02 11:35:41 - train: epoch 0248, iter [00440, 01251], lr: 0.000458, loss: 0.4260
2022-10-02 11:35:59 - train: epoch 0248, iter [00450, 01251], lr: 0.000458, loss: 0.3914
2022-10-02 11:36:17 - train: epoch 0248, iter [00460, 01251], lr: 0.000458, loss: 0.3851
2022-10-02 11:36:35 - train: epoch 0248, iter [00470, 01251], lr: 0.000458, loss: 0.4157
2022-10-02 11:36:53 - train: epoch 0248, iter [00480, 01251], lr: 0.000458, loss: 0.4085
2022-10-02 11:37:11 - train: epoch 0248, iter [00490, 01251], lr: 0.000458, loss: 0.3986
2022-10-02 11:37:28 - train: epoch 0248, iter [00500, 01251], lr: 0.000458, loss: 0.4117
2022-10-02 11:37:46 - train: epoch 0248, iter [00510, 01251], lr: 0.000458, loss: 0.3928
2022-10-02 11:38:04 - train: epoch 0248, iter [00520, 01251], lr: 0.000458, loss: 0.3867
2022-10-02 11:38:22 - train: epoch 0248, iter [00530, 01251], lr: 0.000458, loss: 0.3837
2022-10-02 11:38:39 - train: epoch 0248, iter [00540, 01251], lr: 0.000458, loss: 0.3964
2022-10-02 11:38:57 - train: epoch 0248, iter [00550, 01251], lr: 0.000458, loss: 0.4021
2022-10-02 11:39:15 - train: epoch 0248, iter [00560, 01251], lr: 0.000458, loss: 0.4105
2022-10-02 11:39:33 - train: epoch 0248, iter [00570, 01251], lr: 0.000458, loss: 0.4160
2022-10-02 11:39:51 - train: epoch 0248, iter [00580, 01251], lr: 0.000458, loss: 0.4022
2022-10-02 11:40:09 - train: epoch 0248, iter [00590, 01251], lr: 0.000458, loss: 0.4101
2022-10-02 11:40:27 - train: epoch 0248, iter [00600, 01251], lr: 0.000457, loss: 0.3971
2022-10-02 11:40:45 - train: epoch 0248, iter [00610, 01251], lr: 0.000457, loss: 0.4161
2022-10-02 11:41:03 - train: epoch 0248, iter [00620, 01251], lr: 0.000457, loss: 0.3992
2022-10-02 11:41:21 - train: epoch 0248, iter [00630, 01251], lr: 0.000457, loss: 0.4195
2022-10-02 11:41:38 - train: epoch 0248, iter [00640, 01251], lr: 0.000457, loss: 0.3753
2022-10-02 11:41:56 - train: epoch 0248, iter [00650, 01251], lr: 0.000457, loss: 0.4122
2022-10-02 11:42:14 - train: epoch 0248, iter [00660, 01251], lr: 0.000457, loss: 0.3917
2022-10-02 11:42:32 - train: epoch 0248, iter [00670, 01251], lr: 0.000457, loss: 0.4056
2022-10-02 11:42:50 - train: epoch 0248, iter [00680, 01251], lr: 0.000457, loss: 0.3957
2022-10-02 11:43:08 - train: epoch 0248, iter [00690, 01251], lr: 0.000457, loss: 0.3939
2022-10-02 11:43:26 - train: epoch 0248, iter [00700, 01251], lr: 0.000457, loss: 0.4043
2022-10-02 11:43:44 - train: epoch 0248, iter [00710, 01251], lr: 0.000457, loss: 0.3940
2022-10-02 11:44:02 - train: epoch 0248, iter [00720, 01251], lr: 0.000457, loss: 0.3976
2022-10-02 11:44:20 - train: epoch 0248, iter [00730, 01251], lr: 0.000457, loss: 0.4200
2022-10-02 11:44:37 - train: epoch 0248, iter [00740, 01251], lr: 0.000457, loss: 0.4009
2022-10-02 11:44:55 - train: epoch 0248, iter [00750, 01251], lr: 0.000457, loss: 0.4409
2022-10-02 11:45:13 - train: epoch 0248, iter [00760, 01251], lr: 0.000457, loss: 0.3967
2022-10-02 11:45:31 - train: epoch 0248, iter [00770, 01251], lr: 0.000457, loss: 0.3994
2022-10-02 11:45:49 - train: epoch 0248, iter [00780, 01251], lr: 0.000457, loss: 0.4115
2022-10-02 11:46:07 - train: epoch 0248, iter [00790, 01251], lr: 0.000457, loss: 0.3891
2022-10-02 11:46:25 - train: epoch 0248, iter [00800, 01251], lr: 0.000457, loss: 0.4231
2022-10-02 11:46:43 - train: epoch 0248, iter [00810, 01251], lr: 0.000457, loss: 0.4098
2022-10-02 11:47:01 - train: epoch 0248, iter [00820, 01251], lr: 0.000457, loss: 0.4097
2022-10-02 11:47:19 - train: epoch 0248, iter [00830, 01251], lr: 0.000457, loss: 0.4105
2022-10-02 11:47:36 - train: epoch 0248, iter [00840, 01251], lr: 0.000457, loss: 0.4049
2022-10-02 11:47:54 - train: epoch 0248, iter [00850, 01251], lr: 0.000456, loss: 0.4125
2022-10-02 11:48:12 - train: epoch 0248, iter [00860, 01251], lr: 0.000456, loss: 0.3924
2022-10-02 11:48:30 - train: epoch 0248, iter [00870, 01251], lr: 0.000456, loss: 0.3799
2022-10-02 11:48:48 - train: epoch 0248, iter [00880, 01251], lr: 0.000456, loss: 0.4114
2022-10-02 11:49:06 - train: epoch 0248, iter [00890, 01251], lr: 0.000456, loss: 0.4138
2022-10-02 11:49:24 - train: epoch 0248, iter [00900, 01251], lr: 0.000456, loss: 0.4073
2022-10-02 11:49:42 - train: epoch 0248, iter [00910, 01251], lr: 0.000456, loss: 0.4124
2022-10-02 11:50:00 - train: epoch 0248, iter [00920, 01251], lr: 0.000456, loss: 0.3903
2022-10-02 11:50:17 - train: epoch 0248, iter [00930, 01251], lr: 0.000456, loss: 0.3783
2022-10-02 11:50:35 - train: epoch 0248, iter [00940, 01251], lr: 0.000456, loss: 0.4004
2022-10-02 11:50:54 - train: epoch 0248, iter [00950, 01251], lr: 0.000456, loss: 0.3971
2022-10-02 11:51:12 - train: epoch 0248, iter [00960, 01251], lr: 0.000456, loss: 0.3906
2022-10-02 11:51:30 - train: epoch 0248, iter [00970, 01251], lr: 0.000456, loss: 0.4114
2022-10-02 11:51:48 - train: epoch 0248, iter [00980, 01251], lr: 0.000456, loss: 0.3920
2022-10-02 11:52:05 - train: epoch 0248, iter [00990, 01251], lr: 0.000456, loss: 0.4030
2022-10-02 11:52:23 - train: epoch 0248, iter [01000, 01251], lr: 0.000456, loss: 0.3949
2022-10-02 11:52:41 - train: epoch 0248, iter [01010, 01251], lr: 0.000456, loss: 0.3990
2022-10-02 11:52:59 - train: epoch 0248, iter [01020, 01251], lr: 0.000456, loss: 0.3932
2022-10-02 11:53:17 - train: epoch 0248, iter [01030, 01251], lr: 0.000456, loss: 0.4023
2022-10-02 11:53:35 - train: epoch 0248, iter [01040, 01251], lr: 0.000456, loss: 0.3973
2022-10-02 11:53:53 - train: epoch 0248, iter [01050, 01251], lr: 0.000456, loss: 0.4062
2022-10-02 11:54:11 - train: epoch 0248, iter [01060, 01251], lr: 0.000456, loss: 0.3958
2022-10-02 11:54:29 - train: epoch 0248, iter [01070, 01251], lr: 0.000456, loss: 0.3868
2022-10-02 11:54:47 - train: epoch 0248, iter [01080, 01251], lr: 0.000456, loss: 0.4098
2022-10-02 11:55:05 - train: epoch 0248, iter [01090, 01251], lr: 0.000456, loss: 0.4034
2022-10-02 11:55:23 - train: epoch 0248, iter [01100, 01251], lr: 0.000455, loss: 0.4028
2022-10-02 11:55:41 - train: epoch 0248, iter [01110, 01251], lr: 0.000455, loss: 0.4102
2022-10-02 11:55:59 - train: epoch 0248, iter [01120, 01251], lr: 0.000455, loss: 0.3880
2022-10-02 11:56:18 - train: epoch 0248, iter [01130, 01251], lr: 0.000455, loss: 0.3881
2022-10-02 11:56:36 - train: epoch 0248, iter [01140, 01251], lr: 0.000455, loss: 0.4170
2022-10-02 11:56:53 - train: epoch 0248, iter [01150, 01251], lr: 0.000455, loss: 0.4142
2022-10-02 11:57:12 - train: epoch 0248, iter [01160, 01251], lr: 0.000455, loss: 0.4051
2022-10-02 11:57:30 - train: epoch 0248, iter [01170, 01251], lr: 0.000455, loss: 0.4223
2022-10-02 11:57:49 - train: epoch 0248, iter [01180, 01251], lr: 0.000455, loss: 0.4126
2022-10-02 11:58:07 - train: epoch 0248, iter [01190, 01251], lr: 0.000455, loss: 0.3989
2022-10-02 11:58:26 - train: epoch 0248, iter [01200, 01251], lr: 0.000455, loss: 0.4233
2022-10-02 11:58:44 - train: epoch 0248, iter [01210, 01251], lr: 0.000455, loss: 0.3879
2022-10-02 11:59:02 - train: epoch 0248, iter [01220, 01251], lr: 0.000455, loss: 0.4048
2022-10-02 11:59:20 - train: epoch 0248, iter [01230, 01251], lr: 0.000455, loss: 0.4116
2022-10-02 11:59:39 - train: epoch 0248, iter [01240, 01251], lr: 0.000455, loss: 0.3891
2022-10-02 11:59:57 - train: epoch 0248, iter [01250, 01251], lr: 0.000455, loss: 0.4194
2022-10-02 12:00:00 - train: epoch 248, train_loss: 0.4030
2022-10-02 12:00:03 - until epoch: 248, best_loss: 0.4030
2022-10-02 12:00:03 - epoch 249 lr: 0.000455
2022-10-02 12:00:28 - train: epoch 0249, iter [00010, 01251], lr: 0.000455, loss: 0.4093
2022-10-02 12:00:46 - train: epoch 0249, iter [00020, 01251], lr: 0.000455, loss: 0.4190
2022-10-02 12:01:04 - train: epoch 0249, iter [00030, 01251], lr: 0.000455, loss: 0.3936
2022-10-02 12:01:22 - train: epoch 0249, iter [00040, 01251], lr: 0.000455, loss: 0.4219
2022-10-02 12:01:40 - train: epoch 0249, iter [00050, 01251], lr: 0.000455, loss: 0.4097
2022-10-02 12:01:58 - train: epoch 0249, iter [00060, 01251], lr: 0.000455, loss: 0.4093
2022-10-02 12:02:16 - train: epoch 0249, iter [00070, 01251], lr: 0.000455, loss: 0.4063
2022-10-02 12:02:34 - train: epoch 0249, iter [00080, 01251], lr: 0.000455, loss: 0.3857
2022-10-02 12:02:52 - train: epoch 0249, iter [00090, 01251], lr: 0.000454, loss: 0.4025
2022-10-02 12:03:11 - train: epoch 0249, iter [00100, 01251], lr: 0.000454, loss: 0.4156
2022-10-02 12:03:28 - train: epoch 0249, iter [00110, 01251], lr: 0.000454, loss: 0.3995
2022-10-02 12:03:47 - train: epoch 0249, iter [00120, 01251], lr: 0.000454, loss: 0.4110
2022-10-02 12:04:05 - train: epoch 0249, iter [00130, 01251], lr: 0.000454, loss: 0.3849
2022-10-02 12:04:23 - train: epoch 0249, iter [00140, 01251], lr: 0.000454, loss: 0.4224
2022-10-02 12:04:42 - train: epoch 0249, iter [00150, 01251], lr: 0.000454, loss: 0.3912
2022-10-02 12:05:00 - train: epoch 0249, iter [00160, 01251], lr: 0.000454, loss: 0.4006
2022-10-02 12:05:18 - train: epoch 0249, iter [00170, 01251], lr: 0.000454, loss: 0.4214
2022-10-02 12:05:37 - train: epoch 0249, iter [00180, 01251], lr: 0.000454, loss: 0.4146
2022-10-02 12:05:55 - train: epoch 0249, iter [00190, 01251], lr: 0.000454, loss: 0.3968
2022-10-02 12:06:13 - train: epoch 0249, iter [00200, 01251], lr: 0.000454, loss: 0.4247
2022-10-02 12:06:32 - train: epoch 0249, iter [00210, 01251], lr: 0.000454, loss: 0.4132
2022-10-02 12:06:50 - train: epoch 0249, iter [00220, 01251], lr: 0.000454, loss: 0.4191
2022-10-02 12:07:08 - train: epoch 0249, iter [00230, 01251], lr: 0.000454, loss: 0.4195
2022-10-02 12:07:26 - train: epoch 0249, iter [00240, 01251], lr: 0.000454, loss: 0.3771
2022-10-02 12:07:44 - train: epoch 0249, iter [00250, 01251], lr: 0.000454, loss: 0.3895
2022-10-02 12:08:03 - train: epoch 0249, iter [00260, 01251], lr: 0.000454, loss: 0.4010
2022-10-02 12:08:21 - train: epoch 0249, iter [00270, 01251], lr: 0.000454, loss: 0.3967
2022-10-02 12:08:39 - train: epoch 0249, iter [00280, 01251], lr: 0.000454, loss: 0.4031
2022-10-02 12:08:57 - train: epoch 0249, iter [00290, 01251], lr: 0.000454, loss: 0.3989
2022-10-02 12:09:15 - train: epoch 0249, iter [00300, 01251], lr: 0.000454, loss: 0.4046
2022-10-02 12:09:33 - train: epoch 0249, iter [00310, 01251], lr: 0.000454, loss: 0.3974
2022-10-02 12:09:51 - train: epoch 0249, iter [00320, 01251], lr: 0.000454, loss: 0.4011
2022-10-02 12:10:10 - train: epoch 0249, iter [00330, 01251], lr: 0.000454, loss: 0.4067
2022-10-02 12:10:28 - train: epoch 0249, iter [00340, 01251], lr: 0.000453, loss: 0.4001
2022-10-02 12:10:46 - train: epoch 0249, iter [00350, 01251], lr: 0.000453, loss: 0.3982
2022-10-02 12:11:04 - train: epoch 0249, iter [00360, 01251], lr: 0.000453, loss: 0.4031
2022-10-02 12:11:22 - train: epoch 0249, iter [00370, 01251], lr: 0.000453, loss: 0.3914
2022-10-02 12:11:40 - train: epoch 0249, iter [00380, 01251], lr: 0.000453, loss: 0.3910
2022-10-02 12:11:58 - train: epoch 0249, iter [00390, 01251], lr: 0.000453, loss: 0.4135
2022-10-02 12:12:16 - train: epoch 0249, iter [00400, 01251], lr: 0.000453, loss: 0.3993
2022-10-02 12:12:34 - train: epoch 0249, iter [00410, 01251], lr: 0.000453, loss: 0.4064
2022-10-02 12:12:52 - train: epoch 0249, iter [00420, 01251], lr: 0.000453, loss: 0.3966
2022-10-02 12:13:10 - train: epoch 0249, iter [00430, 01251], lr: 0.000453, loss: 0.4070
2022-10-02 12:13:29 - train: epoch 0249, iter [00440, 01251], lr: 0.000453, loss: 0.4043
2022-10-02 12:13:47 - train: epoch 0249, iter [00450, 01251], lr: 0.000453, loss: 0.4064
2022-10-02 12:14:05 - train: epoch 0249, iter [00460, 01251], lr: 0.000453, loss: 0.4175
2022-10-02 12:14:24 - train: epoch 0249, iter [00470, 01251], lr: 0.000453, loss: 0.4081
2022-10-02 12:14:42 - train: epoch 0249, iter [00480, 01251], lr: 0.000453, loss: 0.3837
2022-10-02 12:15:01 - train: epoch 0249, iter [00490, 01251], lr: 0.000453, loss: 0.4079
2022-10-02 12:15:19 - train: epoch 0249, iter [00500, 01251], lr: 0.000453, loss: 0.4117
2022-10-02 12:15:37 - train: epoch 0249, iter [00510, 01251], lr: 0.000453, loss: 0.4192
2022-10-02 12:15:55 - train: epoch 0249, iter [00520, 01251], lr: 0.000453, loss: 0.4142
2022-10-02 12:16:14 - train: epoch 0249, iter [00530, 01251], lr: 0.000453, loss: 0.3948
2022-10-02 12:16:32 - train: epoch 0249, iter [00540, 01251], lr: 0.000453, loss: 0.4062
2022-10-02 12:16:51 - train: epoch 0249, iter [00550, 01251], lr: 0.000453, loss: 0.4136
2022-10-02 12:17:09 - train: epoch 0249, iter [00560, 01251], lr: 0.000453, loss: 0.4009
2022-10-02 12:17:28 - train: epoch 0249, iter [00570, 01251], lr: 0.000453, loss: 0.3874
2022-10-02 12:17:46 - train: epoch 0249, iter [00580, 01251], lr: 0.000452, loss: 0.3926
2022-10-02 12:18:04 - train: epoch 0249, iter [00590, 01251], lr: 0.000452, loss: 0.4119
2022-10-02 12:18:23 - train: epoch 0249, iter [00600, 01251], lr: 0.000452, loss: 0.4151
2022-10-02 12:18:41 - train: epoch 0249, iter [00610, 01251], lr: 0.000452, loss: 0.4097
2022-10-02 12:18:59 - train: epoch 0249, iter [00620, 01251], lr: 0.000452, loss: 0.4062
2022-10-02 12:19:18 - train: epoch 0249, iter [00630, 01251], lr: 0.000452, loss: 0.4005
2022-10-02 12:19:36 - train: epoch 0249, iter [00640, 01251], lr: 0.000452, loss: 0.4225
2022-10-02 12:19:54 - train: epoch 0249, iter [00650, 01251], lr: 0.000452, loss: 0.4166
2022-10-02 12:20:13 - train: epoch 0249, iter [00660, 01251], lr: 0.000452, loss: 0.4038
2022-10-02 12:20:31 - train: epoch 0249, iter [00670, 01251], lr: 0.000452, loss: 0.4152
2022-10-02 12:20:50 - train: epoch 0249, iter [00680, 01251], lr: 0.000452, loss: 0.4206
2022-10-02 12:21:08 - train: epoch 0249, iter [00690, 01251], lr: 0.000452, loss: 0.3963
2022-10-02 12:21:27 - train: epoch 0249, iter [00700, 01251], lr: 0.000452, loss: 0.4155
2022-10-02 12:21:45 - train: epoch 0249, iter [00710, 01251], lr: 0.000452, loss: 0.4302
2022-10-02 12:22:04 - train: epoch 0249, iter [00720, 01251], lr: 0.000452, loss: 0.3898
2022-10-02 12:22:22 - train: epoch 0249, iter [00730, 01251], lr: 0.000452, loss: 0.3948
2022-10-02 12:22:41 - train: epoch 0249, iter [00740, 01251], lr: 0.000452, loss: 0.3991
2022-10-02 12:22:59 - train: epoch 0249, iter [00750, 01251], lr: 0.000452, loss: 0.4054
2022-10-02 12:23:18 - train: epoch 0249, iter [00760, 01251], lr: 0.000452, loss: 0.4060
2022-10-02 12:23:36 - train: epoch 0249, iter [00770, 01251], lr: 0.000452, loss: 0.4182
2022-10-02 12:23:53 - train: epoch 0249, iter [00780, 01251], lr: 0.000452, loss: 0.4099
2022-10-02 12:24:12 - train: epoch 0249, iter [00790, 01251], lr: 0.000452, loss: 0.4122
2022-10-02 12:24:30 - train: epoch 0249, iter [00800, 01251], lr: 0.000452, loss: 0.3819
2022-10-02 12:24:48 - train: epoch 0249, iter [00810, 01251], lr: 0.000452, loss: 0.4083
2022-10-02 12:25:07 - train: epoch 0249, iter [00820, 01251], lr: 0.000452, loss: 0.4119
2022-10-02 12:25:26 - train: epoch 0249, iter [00830, 01251], lr: 0.000451, loss: 0.3969
2022-10-02 12:25:44 - train: epoch 0249, iter [00840, 01251], lr: 0.000451, loss: 0.4381
2022-10-02 12:26:03 - train: epoch 0249, iter [00850, 01251], lr: 0.000451, loss: 0.3948
2022-10-02 12:26:22 - train: epoch 0249, iter [00860, 01251], lr: 0.000451, loss: 0.3935
2022-10-02 12:26:40 - train: epoch 0249, iter [00870, 01251], lr: 0.000451, loss: 0.4149
2022-10-02 12:26:58 - train: epoch 0249, iter [00880, 01251], lr: 0.000451, loss: 0.4077
2022-10-02 12:27:17 - train: epoch 0249, iter [00890, 01251], lr: 0.000451, loss: 0.3959
2022-10-02 12:27:35 - train: epoch 0249, iter [00900, 01251], lr: 0.000451, loss: 0.4250
2022-10-02 12:27:54 - train: epoch 0249, iter [00910, 01251], lr: 0.000451, loss: 0.3957
2022-10-02 12:28:12 - train: epoch 0249, iter [00920, 01251], lr: 0.000451, loss: 0.4011
2022-10-02 12:28:30 - train: epoch 0249, iter [00930, 01251], lr: 0.000451, loss: 0.4101
2022-10-02 12:28:49 - train: epoch 0249, iter [00940, 01251], lr: 0.000451, loss: 0.4031
2022-10-02 12:29:07 - train: epoch 0249, iter [00950, 01251], lr: 0.000451, loss: 0.3872
2022-10-02 12:29:25 - train: epoch 0249, iter [00960, 01251], lr: 0.000451, loss: 0.3978
2022-10-02 12:29:44 - train: epoch 0249, iter [00970, 01251], lr: 0.000451, loss: 0.4177
2022-10-02 12:30:03 - train: epoch 0249, iter [00980, 01251], lr: 0.000451, loss: 0.4045
2022-10-02 12:30:21 - train: epoch 0249, iter [00990, 01251], lr: 0.000451, loss: 0.3943
2022-10-02 12:30:40 - train: epoch 0249, iter [01000, 01251], lr: 0.000451, loss: 0.3986
2022-10-02 12:30:58 - train: epoch 0249, iter [01010, 01251], lr: 0.000451, loss: 0.3979
2022-10-02 12:31:17 - train: epoch 0249, iter [01020, 01251], lr: 0.000451, loss: 0.4065
2022-10-02 12:31:35 - train: epoch 0249, iter [01030, 01251], lr: 0.000451, loss: 0.3931
2022-10-02 12:31:54 - train: epoch 0249, iter [01040, 01251], lr: 0.000451, loss: 0.4122
2022-10-02 12:32:12 - train: epoch 0249, iter [01050, 01251], lr: 0.000451, loss: 0.4054
2022-10-02 12:32:31 - train: epoch 0249, iter [01060, 01251], lr: 0.000451, loss: 0.3882
2022-10-02 12:32:49 - train: epoch 0249, iter [01070, 01251], lr: 0.000451, loss: 0.3805
2022-10-02 12:33:08 - train: epoch 0249, iter [01080, 01251], lr: 0.000450, loss: 0.4089
2022-10-02 12:33:26 - train: epoch 0249, iter [01090, 01251], lr: 0.000450, loss: 0.4137
2022-10-02 12:33:45 - train: epoch 0249, iter [01100, 01251], lr: 0.000450, loss: 0.4035
2022-10-02 12:34:03 - train: epoch 0249, iter [01110, 01251], lr: 0.000450, loss: 0.4175
2022-10-02 12:34:21 - train: epoch 0249, iter [01120, 01251], lr: 0.000450, loss: 0.3947
2022-10-02 12:34:40 - train: epoch 0249, iter [01130, 01251], lr: 0.000450, loss: 0.3932
2022-10-02 12:34:59 - train: epoch 0249, iter [01140, 01251], lr: 0.000450, loss: 0.4088
2022-10-02 12:35:17 - train: epoch 0249, iter [01150, 01251], lr: 0.000450, loss: 0.4182
2022-10-02 12:35:35 - train: epoch 0249, iter [01160, 01251], lr: 0.000450, loss: 0.4076
2022-10-02 12:35:54 - train: epoch 0249, iter [01170, 01251], lr: 0.000450, loss: 0.4067
2022-10-02 12:36:13 - train: epoch 0249, iter [01180, 01251], lr: 0.000450, loss: 0.3973
2022-10-02 12:36:31 - train: epoch 0249, iter [01190, 01251], lr: 0.000450, loss: 0.3962
2022-10-02 12:36:50 - train: epoch 0249, iter [01200, 01251], lr: 0.000450, loss: 0.4063
2022-10-02 12:37:08 - train: epoch 0249, iter [01210, 01251], lr: 0.000450, loss: 0.3853
2022-10-02 12:37:26 - train: epoch 0249, iter [01220, 01251], lr: 0.000450, loss: 0.3957
2022-10-02 12:37:45 - train: epoch 0249, iter [01230, 01251], lr: 0.000450, loss: 0.3963
2022-10-02 12:38:03 - train: epoch 0249, iter [01240, 01251], lr: 0.000450, loss: 0.4185
2022-10-02 12:38:21 - train: epoch 0249, iter [01250, 01251], lr: 0.000450, loss: 0.4027
2022-10-02 12:38:25 - train: epoch 249, train_loss: 0.4029
2022-10-02 12:38:28 - until epoch: 249, best_loss: 0.4029
2022-10-02 12:38:28 - epoch 250 lr: 0.000450
2022-10-02 12:38:53 - train: epoch 0250, iter [00010, 01251], lr: 0.000450, loss: 0.4041
2022-10-02 12:39:12 - train: epoch 0250, iter [00020, 01251], lr: 0.000450, loss: 0.4178
2022-10-02 12:39:30 - train: epoch 0250, iter [00030, 01251], lr: 0.000450, loss: 0.4037
2022-10-02 12:39:49 - train: epoch 0250, iter [00040, 01251], lr: 0.000450, loss: 0.4030
2022-10-02 12:40:07 - train: epoch 0250, iter [00050, 01251], lr: 0.000450, loss: 0.3863
2022-10-02 12:40:25 - train: epoch 0250, iter [00060, 01251], lr: 0.000450, loss: 0.3958
2022-10-02 12:40:44 - train: epoch 0250, iter [00070, 01251], lr: 0.000449, loss: 0.3724
2022-10-02 12:41:03 - train: epoch 0250, iter [00080, 01251], lr: 0.000449, loss: 0.4053
2022-10-02 12:41:21 - train: epoch 0250, iter [00090, 01251], lr: 0.000449, loss: 0.4053
2022-10-02 12:41:39 - train: epoch 0250, iter [00100, 01251], lr: 0.000449, loss: 0.3949
2022-10-02 12:41:58 - train: epoch 0250, iter [00110, 01251], lr: 0.000449, loss: 0.3992
2022-10-02 12:42:16 - train: epoch 0250, iter [00120, 01251], lr: 0.000449, loss: 0.4056
2022-10-02 12:42:35 - train: epoch 0250, iter [00130, 01251], lr: 0.000449, loss: 0.4158
2022-10-02 12:42:54 - train: epoch 0250, iter [00140, 01251], lr: 0.000449, loss: 0.3924
2022-10-02 12:43:12 - train: epoch 0250, iter [00150, 01251], lr: 0.000449, loss: 0.3894
2022-10-02 12:43:30 - train: epoch 0250, iter [00160, 01251], lr: 0.000449, loss: 0.4065
2022-10-02 12:43:49 - train: epoch 0250, iter [00170, 01251], lr: 0.000449, loss: 0.4209
2022-10-02 12:44:07 - train: epoch 0250, iter [00180, 01251], lr: 0.000449, loss: 0.4414
2022-10-02 12:44:26 - train: epoch 0250, iter [00190, 01251], lr: 0.000449, loss: 0.4053
2022-10-02 12:44:44 - train: epoch 0250, iter [00200, 01251], lr: 0.000449, loss: 0.3936
2022-10-02 12:45:02 - train: epoch 0250, iter [00210, 01251], lr: 0.000449, loss: 0.4011
2022-10-02 12:45:21 - train: epoch 0250, iter [00220, 01251], lr: 0.000449, loss: 0.4007
2022-10-02 12:45:39 - train: epoch 0250, iter [00230, 01251], lr: 0.000449, loss: 0.3843
2022-10-02 12:45:57 - train: epoch 0250, iter [00240, 01251], lr: 0.000449, loss: 0.4126
2022-10-02 12:46:16 - train: epoch 0250, iter [00250, 01251], lr: 0.000449, loss: 0.4084
2022-10-02 12:46:34 - train: epoch 0250, iter [00260, 01251], lr: 0.000449, loss: 0.3835
2022-10-02 12:46:52 - train: epoch 0250, iter [00270, 01251], lr: 0.000449, loss: 0.4052
2022-10-02 12:47:11 - train: epoch 0250, iter [00280, 01251], lr: 0.000449, loss: 0.3971
2022-10-02 12:47:30 - train: epoch 0250, iter [00290, 01251], lr: 0.000449, loss: 0.4225
2022-10-02 12:47:48 - train: epoch 0250, iter [00300, 01251], lr: 0.000449, loss: 0.4105
2022-10-02 12:48:06 - train: epoch 0250, iter [00310, 01251], lr: 0.000449, loss: 0.3874
2022-10-02 12:48:25 - train: epoch 0250, iter [00320, 01251], lr: 0.000448, loss: 0.4259
2022-10-02 12:48:43 - train: epoch 0250, iter [00330, 01251], lr: 0.000448, loss: 0.4081
2022-10-02 12:49:02 - train: epoch 0250, iter [00340, 01251], lr: 0.000448, loss: 0.4137
2022-10-02 12:49:20 - train: epoch 0250, iter [00350, 01251], lr: 0.000448, loss: 0.3982
2022-10-02 12:49:38 - train: epoch 0250, iter [00360, 01251], lr: 0.000448, loss: 0.4227
2022-10-02 12:49:57 - train: epoch 0250, iter [00370, 01251], lr: 0.000448, loss: 0.3978
2022-10-02 12:50:15 - train: epoch 0250, iter [00380, 01251], lr: 0.000448, loss: 0.3886
2022-10-02 12:50:34 - train: epoch 0250, iter [00390, 01251], lr: 0.000448, loss: 0.4006
2022-10-02 12:50:52 - train: epoch 0250, iter [00400, 01251], lr: 0.000448, loss: 0.3982
2022-10-02 12:51:11 - train: epoch 0250, iter [00410, 01251], lr: 0.000448, loss: 0.4035
2022-10-02 12:51:30 - train: epoch 0250, iter [00420, 01251], lr: 0.000448, loss: 0.4112
2022-10-02 12:51:48 - train: epoch 0250, iter [00430, 01251], lr: 0.000448, loss: 0.4038
2022-10-02 12:52:07 - train: epoch 0250, iter [00440, 01251], lr: 0.000448, loss: 0.3839
2022-10-02 12:52:25 - train: epoch 0250, iter [00450, 01251], lr: 0.000448, loss: 0.4032
2022-10-02 12:52:44 - train: epoch 0250, iter [00460, 01251], lr: 0.000448, loss: 0.4253
2022-10-02 12:53:02 - train: epoch 0250, iter [00470, 01251], lr: 0.000448, loss: 0.3994
2022-10-02 12:53:21 - train: epoch 0250, iter [00480, 01251], lr: 0.000448, loss: 0.4081
2022-10-02 12:53:39 - train: epoch 0250, iter [00490, 01251], lr: 0.000448, loss: 0.4040
2022-10-02 12:53:58 - train: epoch 0250, iter [00500, 01251], lr: 0.000448, loss: 0.4070
2022-10-02 12:54:16 - train: epoch 0250, iter [00510, 01251], lr: 0.000448, loss: 0.3863
2022-10-02 12:54:35 - train: epoch 0250, iter [00520, 01251], lr: 0.000448, loss: 0.4033
2022-10-02 12:54:54 - train: epoch 0250, iter [00530, 01251], lr: 0.000448, loss: 0.3938
2022-10-02 12:55:12 - train: epoch 0250, iter [00540, 01251], lr: 0.000448, loss: 0.4225
2022-10-02 12:55:30 - train: epoch 0250, iter [00550, 01251], lr: 0.000448, loss: 0.4244
2022-10-02 12:55:49 - train: epoch 0250, iter [00560, 01251], lr: 0.000448, loss: 0.3790
2022-10-02 12:56:07 - train: epoch 0250, iter [00570, 01251], lr: 0.000447, loss: 0.3881
2022-10-02 12:56:26 - train: epoch 0250, iter [00580, 01251], lr: 0.000447, loss: 0.3917
2022-10-02 12:56:45 - train: epoch 0250, iter [00590, 01251], lr: 0.000447, loss: 0.3997
2022-10-02 12:57:03 - train: epoch 0250, iter [00600, 01251], lr: 0.000447, loss: 0.4185
2022-10-02 12:57:22 - train: epoch 0250, iter [00610, 01251], lr: 0.000447, loss: 0.4025
2022-10-02 12:57:40 - train: epoch 0250, iter [00620, 01251], lr: 0.000447, loss: 0.4202
2022-10-02 12:57:59 - train: epoch 0250, iter [00630, 01251], lr: 0.000447, loss: 0.3964
2022-10-02 12:58:17 - train: epoch 0250, iter [00640, 01251], lr: 0.000447, loss: 0.3900
2022-10-02 12:58:35 - train: epoch 0250, iter [00650, 01251], lr: 0.000447, loss: 0.3852
2022-10-02 12:58:54 - train: epoch 0250, iter [00660, 01251], lr: 0.000447, loss: 0.4076
2022-10-02 12:59:12 - train: epoch 0250, iter [00670, 01251], lr: 0.000447, loss: 0.4130
2022-10-02 12:59:31 - train: epoch 0250, iter [00680, 01251], lr: 0.000447, loss: 0.4054
2022-10-02 12:59:49 - train: epoch 0250, iter [00690, 01251], lr: 0.000447, loss: 0.4107
2022-10-02 13:00:08 - train: epoch 0250, iter [00700, 01251], lr: 0.000447, loss: 0.4107
2022-10-02 13:00:26 - train: epoch 0250, iter [00710, 01251], lr: 0.000447, loss: 0.4182
2022-10-02 13:00:45 - train: epoch 0250, iter [00720, 01251], lr: 0.000447, loss: 0.4097
2022-10-02 13:01:03 - train: epoch 0250, iter [00730, 01251], lr: 0.000447, loss: 0.3805
2022-10-02 13:01:21 - train: epoch 0250, iter [00740, 01251], lr: 0.000447, loss: 0.4170
2022-10-02 13:01:40 - train: epoch 0250, iter [00750, 01251], lr: 0.000447, loss: 0.4134
2022-10-02 13:01:59 - train: epoch 0250, iter [00760, 01251], lr: 0.000447, loss: 0.3818
2022-10-02 13:02:17 - train: epoch 0250, iter [00770, 01251], lr: 0.000447, loss: 0.3964
2022-10-02 13:02:36 - train: epoch 0250, iter [00780, 01251], lr: 0.000447, loss: 0.3819
2022-10-02 13:02:54 - train: epoch 0250, iter [00790, 01251], lr: 0.000447, loss: 0.4089
2022-10-02 13:03:13 - train: epoch 0250, iter [00800, 01251], lr: 0.000447, loss: 0.3772
2022-10-02 13:03:31 - train: epoch 0250, iter [00810, 01251], lr: 0.000446, loss: 0.3818
2022-10-02 13:03:49 - train: epoch 0250, iter [00820, 01251], lr: 0.000446, loss: 0.4143
2022-10-02 13:04:08 - train: epoch 0250, iter [00830, 01251], lr: 0.000446, loss: 0.3961
2022-10-02 13:04:26 - train: epoch 0250, iter [00840, 01251], lr: 0.000446, loss: 0.3832
2022-10-02 13:04:44 - train: epoch 0250, iter [00850, 01251], lr: 0.000446, loss: 0.4143
2022-10-02 13:05:03 - train: epoch 0250, iter [00860, 01251], lr: 0.000446, loss: 0.4014
2022-10-02 13:05:22 - train: epoch 0250, iter [00870, 01251], lr: 0.000446, loss: 0.4006
2022-10-02 13:05:40 - train: epoch 0250, iter [00880, 01251], lr: 0.000446, loss: 0.3874
2022-10-02 13:05:59 - train: epoch 0250, iter [00890, 01251], lr: 0.000446, loss: 0.3968
2022-10-02 13:06:17 - train: epoch 0250, iter [00900, 01251], lr: 0.000446, loss: 0.4215
2022-10-02 13:06:36 - train: epoch 0250, iter [00910, 01251], lr: 0.000446, loss: 0.3859
2022-10-02 13:06:55 - train: epoch 0250, iter [00920, 01251], lr: 0.000446, loss: 0.3991
2022-10-02 13:07:13 - train: epoch 0250, iter [00930, 01251], lr: 0.000446, loss: 0.3826
2022-10-02 13:07:31 - train: epoch 0250, iter [00940, 01251], lr: 0.000446, loss: 0.4095
2022-10-02 13:07:50 - train: epoch 0250, iter [00950, 01251], lr: 0.000446, loss: 0.4145
2022-10-02 13:08:08 - train: epoch 0250, iter [00960, 01251], lr: 0.000446, loss: 0.3867
2022-10-02 13:08:26 - train: epoch 0250, iter [00970, 01251], lr: 0.000446, loss: 0.4022
2022-10-02 13:08:45 - train: epoch 0250, iter [00980, 01251], lr: 0.000446, loss: 0.4069
2022-10-02 13:09:03 - train: epoch 0250, iter [00990, 01251], lr: 0.000446, loss: 0.4072
2022-10-02 13:09:22 - train: epoch 0250, iter [01000, 01251], lr: 0.000446, loss: 0.4025
2022-10-02 13:09:40 - train: epoch 0250, iter [01010, 01251], lr: 0.000446, loss: 0.4041
2022-10-02 13:09:59 - train: epoch 0250, iter [01020, 01251], lr: 0.000446, loss: 0.4110
2022-10-02 13:10:17 - train: epoch 0250, iter [01030, 01251], lr: 0.000446, loss: 0.4032
2022-10-02 13:10:36 - train: epoch 0250, iter [01040, 01251], lr: 0.000446, loss: 0.3956
2022-10-02 13:10:54 - train: epoch 0250, iter [01050, 01251], lr: 0.000446, loss: 0.4041
2022-10-02 13:11:12 - train: epoch 0250, iter [01060, 01251], lr: 0.000445, loss: 0.3798
2022-10-02 13:11:31 - train: epoch 0250, iter [01070, 01251], lr: 0.000445, loss: 0.4029
2022-10-02 13:11:50 - train: epoch 0250, iter [01080, 01251], lr: 0.000445, loss: 0.4060
2022-10-02 13:12:08 - train: epoch 0250, iter [01090, 01251], lr: 0.000445, loss: 0.4134
2022-10-02 13:12:26 - train: epoch 0250, iter [01100, 01251], lr: 0.000445, loss: 0.4062
2022-10-02 13:12:45 - train: epoch 0250, iter [01110, 01251], lr: 0.000445, loss: 0.4153
2022-10-02 13:13:03 - train: epoch 0250, iter [01120, 01251], lr: 0.000445, loss: 0.4263
2022-10-02 13:13:21 - train: epoch 0250, iter [01130, 01251], lr: 0.000445, loss: 0.4058
2022-10-02 13:13:40 - train: epoch 0250, iter [01140, 01251], lr: 0.000445, loss: 0.4114
2022-10-02 13:13:58 - train: epoch 0250, iter [01150, 01251], lr: 0.000445, loss: 0.4107
2022-10-02 13:14:16 - train: epoch 0250, iter [01160, 01251], lr: 0.000445, loss: 0.4118
2022-10-02 13:14:35 - train: epoch 0250, iter [01170, 01251], lr: 0.000445, loss: 0.4047
2022-10-02 13:14:54 - train: epoch 0250, iter [01180, 01251], lr: 0.000445, loss: 0.4047
2022-10-02 13:15:12 - train: epoch 0250, iter [01190, 01251], lr: 0.000445, loss: 0.3983
2022-10-02 13:15:30 - train: epoch 0250, iter [01200, 01251], lr: 0.000445, loss: 0.4215
2022-10-02 13:15:49 - train: epoch 0250, iter [01210, 01251], lr: 0.000445, loss: 0.4167
2022-10-02 13:16:07 - train: epoch 0250, iter [01220, 01251], lr: 0.000445, loss: 0.4194
2022-10-02 13:16:26 - train: epoch 0250, iter [01230, 01251], lr: 0.000445, loss: 0.4137
2022-10-02 13:16:44 - train: epoch 0250, iter [01240, 01251], lr: 0.000445, loss: 0.3929
2022-10-02 13:17:02 - train: epoch 0250, iter [01250, 01251], lr: 0.000445, loss: 0.4074
2022-10-02 13:17:05 - train: epoch 250, train_loss: 0.4029
2022-10-02 13:17:08 - until epoch: 250, best_loss: 0.4029
2022-10-02 13:17:08 - epoch 251 lr: 0.000445
2022-10-02 13:17:34 - train: epoch 0251, iter [00010, 01251], lr: 0.000445, loss: 0.3932
2022-10-02 13:17:52 - train: epoch 0251, iter [00020, 01251], lr: 0.000445, loss: 0.3972
2022-10-02 13:18:11 - train: epoch 0251, iter [00030, 01251], lr: 0.000445, loss: 0.4079
2022-10-02 13:18:29 - train: epoch 0251, iter [00040, 01251], lr: 0.000445, loss: 0.3946
2022-10-02 13:18:47 - train: epoch 0251, iter [00050, 01251], lr: 0.000445, loss: 0.3971
2022-10-02 13:19:06 - train: epoch 0251, iter [00060, 01251], lr: 0.000444, loss: 0.3991
2022-10-02 13:19:24 - train: epoch 0251, iter [00070, 01251], lr: 0.000444, loss: 0.4100
2022-10-02 13:19:42 - train: epoch 0251, iter [00080, 01251], lr: 0.000444, loss: 0.3875
2022-10-02 13:20:01 - train: epoch 0251, iter [00090, 01251], lr: 0.000444, loss: 0.3946
2022-10-02 13:20:19 - train: epoch 0251, iter [00100, 01251], lr: 0.000444, loss: 0.3798
2022-10-02 13:20:38 - train: epoch 0251, iter [00110, 01251], lr: 0.000444, loss: 0.4071
2022-10-02 13:20:56 - train: epoch 0251, iter [00120, 01251], lr: 0.000444, loss: 0.4077
2022-10-02 13:21:14 - train: epoch 0251, iter [00130, 01251], lr: 0.000444, loss: 0.4147
2022-10-02 13:21:33 - train: epoch 0251, iter [00140, 01251], lr: 0.000444, loss: 0.3980
2022-10-02 13:21:52 - train: epoch 0251, iter [00150, 01251], lr: 0.000444, loss: 0.4212
2022-10-02 13:22:10 - train: epoch 0251, iter [00160, 01251], lr: 0.000444, loss: 0.4156
2022-10-02 13:22:28 - train: epoch 0251, iter [00170, 01251], lr: 0.000444, loss: 0.4045
2022-10-02 13:22:47 - train: epoch 0251, iter [00180, 01251], lr: 0.000444, loss: 0.4181
2022-10-02 13:23:05 - train: epoch 0251, iter [00190, 01251], lr: 0.000444, loss: 0.4204
2022-10-02 13:23:23 - train: epoch 0251, iter [00200, 01251], lr: 0.000444, loss: 0.3955
2022-10-02 13:23:42 - train: epoch 0251, iter [00210, 01251], lr: 0.000444, loss: 0.4058
2022-10-02 13:24:00 - train: epoch 0251, iter [00220, 01251], lr: 0.000444, loss: 0.4068
2022-10-02 13:24:19 - train: epoch 0251, iter [00230, 01251], lr: 0.000444, loss: 0.3726
2022-10-02 13:24:37 - train: epoch 0251, iter [00240, 01251], lr: 0.000444, loss: 0.4221
2022-10-02 13:24:55 - train: epoch 0251, iter [00250, 01251], lr: 0.000444, loss: 0.3947
2022-10-02 13:25:14 - train: epoch 0251, iter [00260, 01251], lr: 0.000444, loss: 0.3954
2022-10-02 13:25:32 - train: epoch 0251, iter [00270, 01251], lr: 0.000444, loss: 0.4030
2022-10-02 13:25:51 - train: epoch 0251, iter [00280, 01251], lr: 0.000444, loss: 0.4000
2022-10-02 13:26:09 - train: epoch 0251, iter [00290, 01251], lr: 0.000444, loss: 0.4030
2022-10-02 13:26:28 - train: epoch 0251, iter [00300, 01251], lr: 0.000443, loss: 0.3998
2022-10-02 13:26:46 - train: epoch 0251, iter [00310, 01251], lr: 0.000443, loss: 0.3989
2022-10-02 13:27:05 - train: epoch 0251, iter [00320, 01251], lr: 0.000443, loss: 0.4086
2022-10-02 13:27:23 - train: epoch 0251, iter [00330, 01251], lr: 0.000443, loss: 0.4162
2022-10-02 13:27:41 - train: epoch 0251, iter [00340, 01251], lr: 0.000443, loss: 0.3925
2022-10-02 13:28:00 - train: epoch 0251, iter [00350, 01251], lr: 0.000443, loss: 0.3846
2022-10-02 13:28:18 - train: epoch 0251, iter [00360, 01251], lr: 0.000443, loss: 0.4121
2022-10-02 13:28:37 - train: epoch 0251, iter [00370, 01251], lr: 0.000443, loss: 0.4006
2022-10-02 13:28:55 - train: epoch 0251, iter [00380, 01251], lr: 0.000443, loss: 0.4021
2022-10-02 13:29:14 - train: epoch 0251, iter [00390, 01251], lr: 0.000443, loss: 0.4302
2022-10-02 13:29:32 - train: epoch 0251, iter [00400, 01251], lr: 0.000443, loss: 0.4069
2022-10-02 13:29:51 - train: epoch 0251, iter [00410, 01251], lr: 0.000443, loss: 0.3937
2022-10-02 13:30:09 - train: epoch 0251, iter [00420, 01251], lr: 0.000443, loss: 0.3922
2022-10-02 13:30:27 - train: epoch 0251, iter [00430, 01251], lr: 0.000443, loss: 0.3948
2022-10-02 13:30:46 - train: epoch 0251, iter [00440, 01251], lr: 0.000443, loss: 0.4135
2022-10-02 13:31:05 - train: epoch 0251, iter [00450, 01251], lr: 0.000443, loss: 0.4064
2022-10-02 13:31:23 - train: epoch 0251, iter [00460, 01251], lr: 0.000443, loss: 0.3847
2022-10-02 13:31:42 - train: epoch 0251, iter [00470, 01251], lr: 0.000443, loss: 0.3884
2022-10-02 13:32:00 - train: epoch 0251, iter [00480, 01251], lr: 0.000443, loss: 0.4007
2022-10-02 13:32:18 - train: epoch 0251, iter [00490, 01251], lr: 0.000443, loss: 0.4012
2022-10-02 13:32:37 - train: epoch 0251, iter [00500, 01251], lr: 0.000443, loss: 0.4073
2022-10-02 13:32:55 - train: epoch 0251, iter [00510, 01251], lr: 0.000443, loss: 0.4069
2022-10-02 13:33:14 - train: epoch 0251, iter [00520, 01251], lr: 0.000443, loss: 0.4040
2022-10-02 13:33:32 - train: epoch 0251, iter [00530, 01251], lr: 0.000443, loss: 0.3988
2022-10-02 13:33:51 - train: epoch 0251, iter [00540, 01251], lr: 0.000443, loss: 0.3996
2022-10-02 13:34:09 - train: epoch 0251, iter [00550, 01251], lr: 0.000442, loss: 0.4105
2022-10-02 13:34:28 - train: epoch 0251, iter [00560, 01251], lr: 0.000442, loss: 0.3852
2022-10-02 13:34:46 - train: epoch 0251, iter [00570, 01251], lr: 0.000442, loss: 0.3976
2022-10-02 13:35:05 - train: epoch 0251, iter [00580, 01251], lr: 0.000442, loss: 0.3902
2022-10-02 13:35:23 - train: epoch 0251, iter [00590, 01251], lr: 0.000442, loss: 0.4093
2022-10-02 13:35:41 - train: epoch 0251, iter [00600, 01251], lr: 0.000442, loss: 0.3932
2022-10-02 13:36:00 - train: epoch 0251, iter [00610, 01251], lr: 0.000442, loss: 0.4079
2022-10-02 13:36:18 - train: epoch 0251, iter [00620, 01251], lr: 0.000442, loss: 0.4138
2022-10-02 13:36:36 - train: epoch 0251, iter [00630, 01251], lr: 0.000442, loss: 0.4002
2022-10-02 13:36:55 - train: epoch 0251, iter [00640, 01251], lr: 0.000442, loss: 0.4017
2022-10-02 13:37:13 - train: epoch 0251, iter [00650, 01251], lr: 0.000442, loss: 0.3974
2022-10-02 13:37:32 - train: epoch 0251, iter [00660, 01251], lr: 0.000442, loss: 0.3978
2022-10-02 13:37:50 - train: epoch 0251, iter [00670, 01251], lr: 0.000442, loss: 0.3982
2022-10-02 13:38:08 - train: epoch 0251, iter [00680, 01251], lr: 0.000442, loss: 0.4199
2022-10-02 13:38:27 - train: epoch 0251, iter [00690, 01251], lr: 0.000442, loss: 0.3999
2022-10-02 13:38:45 - train: epoch 0251, iter [00700, 01251], lr: 0.000442, loss: 0.3881
2022-10-02 13:39:04 - train: epoch 0251, iter [00710, 01251], lr: 0.000442, loss: 0.3936
2022-10-02 13:39:22 - train: epoch 0251, iter [00720, 01251], lr: 0.000442, loss: 0.3989
2022-10-02 13:39:41 - train: epoch 0251, iter [00730, 01251], lr: 0.000442, loss: 0.4005
2022-10-02 13:39:59 - train: epoch 0251, iter [00740, 01251], lr: 0.000442, loss: 0.4035
2022-10-02 13:40:18 - train: epoch 0251, iter [00750, 01251], lr: 0.000442, loss: 0.3861
2022-10-02 13:40:36 - train: epoch 0251, iter [00760, 01251], lr: 0.000442, loss: 0.4066
2022-10-02 13:40:55 - train: epoch 0251, iter [00770, 01251], lr: 0.000442, loss: 0.3971
2022-10-02 13:41:13 - train: epoch 0251, iter [00780, 01251], lr: 0.000442, loss: 0.4029
2022-10-02 13:41:31 - train: epoch 0251, iter [00790, 01251], lr: 0.000442, loss: 0.4186
2022-10-02 13:41:50 - train: epoch 0251, iter [00800, 01251], lr: 0.000441, loss: 0.4012
2022-10-02 13:42:09 - train: epoch 0251, iter [00810, 01251], lr: 0.000441, loss: 0.4134
2022-10-02 13:42:27 - train: epoch 0251, iter [00820, 01251], lr: 0.000441, loss: 0.4054
2022-10-02 13:42:46 - train: epoch 0251, iter [00830, 01251], lr: 0.000441, loss: 0.3993
2022-10-02 13:43:04 - train: epoch 0251, iter [00840, 01251], lr: 0.000441, loss: 0.4159
2022-10-02 13:43:22 - train: epoch 0251, iter [00850, 01251], lr: 0.000441, loss: 0.4153
2022-10-02 13:43:41 - train: epoch 0251, iter [00860, 01251], lr: 0.000441, loss: 0.3967
2022-10-02 13:44:00 - train: epoch 0251, iter [00870, 01251], lr: 0.000441, loss: 0.3948
2022-10-02 13:44:18 - train: epoch 0251, iter [00880, 01251], lr: 0.000441, loss: 0.4024
2022-10-02 13:44:36 - train: epoch 0251, iter [00890, 01251], lr: 0.000441, loss: 0.3999
2022-10-02 13:44:55 - train: epoch 0251, iter [00900, 01251], lr: 0.000441, loss: 0.4045
2022-10-02 13:45:13 - train: epoch 0251, iter [00910, 01251], lr: 0.000441, loss: 0.4073
2022-10-02 13:45:32 - train: epoch 0251, iter [00920, 01251], lr: 0.000441, loss: 0.4135
2022-10-02 13:45:50 - train: epoch 0251, iter [00930, 01251], lr: 0.000441, loss: 0.4126
2022-10-02 13:46:08 - train: epoch 0251, iter [00940, 01251], lr: 0.000441, loss: 0.3915
2022-10-02 13:46:27 - train: epoch 0251, iter [00950, 01251], lr: 0.000441, loss: 0.3951
2022-10-02 13:46:45 - train: epoch 0251, iter [00960, 01251], lr: 0.000441, loss: 0.4229
2022-10-02 13:47:03 - train: epoch 0251, iter [00970, 01251], lr: 0.000441, loss: 0.4236
2022-10-02 13:47:22 - train: epoch 0251, iter [00980, 01251], lr: 0.000441, loss: 0.3979
2022-10-02 13:47:40 - train: epoch 0251, iter [00990, 01251], lr: 0.000441, loss: 0.4163
2022-10-02 13:47:59 - train: epoch 0251, iter [01000, 01251], lr: 0.000441, loss: 0.3841
2022-10-02 13:48:17 - train: epoch 0251, iter [01010, 01251], lr: 0.000441, loss: 0.3848
2022-10-02 13:48:36 - train: epoch 0251, iter [01020, 01251], lr: 0.000441, loss: 0.4035
2022-10-02 13:48:54 - train: epoch 0251, iter [01030, 01251], lr: 0.000441, loss: 0.4095
2022-10-02 13:49:12 - train: epoch 0251, iter [01040, 01251], lr: 0.000441, loss: 0.4077
2022-10-02 13:49:31 - train: epoch 0251, iter [01050, 01251], lr: 0.000440, loss: 0.4025
2022-10-02 13:49:50 - train: epoch 0251, iter [01060, 01251], lr: 0.000440, loss: 0.4039
2022-10-02 13:50:08 - train: epoch 0251, iter [01070, 01251], lr: 0.000440, loss: 0.4081
2022-10-02 13:50:27 - train: epoch 0251, iter [01080, 01251], lr: 0.000440, loss: 0.4006
2022-10-02 13:50:45 - train: epoch 0251, iter [01090, 01251], lr: 0.000440, loss: 0.3912
2022-10-02 13:51:04 - train: epoch 0251, iter [01100, 01251], lr: 0.000440, loss: 0.4081
2022-10-02 13:51:22 - train: epoch 0251, iter [01110, 01251], lr: 0.000440, loss: 0.4105
2022-10-02 13:51:41 - train: epoch 0251, iter [01120, 01251], lr: 0.000440, loss: 0.3810
2022-10-02 13:51:59 - train: epoch 0251, iter [01130, 01251], lr: 0.000440, loss: 0.4040
2022-10-02 13:52:17 - train: epoch 0251, iter [01140, 01251], lr: 0.000440, loss: 0.4163
2022-10-02 13:52:36 - train: epoch 0251, iter [01150, 01251], lr: 0.000440, loss: 0.4079
2022-10-02 13:52:54 - train: epoch 0251, iter [01160, 01251], lr: 0.000440, loss: 0.3975
2022-10-02 13:53:13 - train: epoch 0251, iter [01170, 01251], lr: 0.000440, loss: 0.4244
2022-10-02 13:53:31 - train: epoch 0251, iter [01180, 01251], lr: 0.000440, loss: 0.4017
2022-10-02 13:53:50 - train: epoch 0251, iter [01190, 01251], lr: 0.000440, loss: 0.4029
2022-10-02 13:54:08 - train: epoch 0251, iter [01200, 01251], lr: 0.000440, loss: 0.4067
2022-10-02 13:54:27 - train: epoch 0251, iter [01210, 01251], lr: 0.000440, loss: 0.3981
2022-10-02 13:54:45 - train: epoch 0251, iter [01220, 01251], lr: 0.000440, loss: 0.4035
2022-10-02 13:55:04 - train: epoch 0251, iter [01230, 01251], lr: 0.000440, loss: 0.4005
2022-10-02 13:55:22 - train: epoch 0251, iter [01240, 01251], lr: 0.000440, loss: 0.4173
2022-10-02 13:55:40 - train: epoch 0251, iter [01250, 01251], lr: 0.000440, loss: 0.4238
2022-10-02 13:55:44 - train: epoch 251, train_loss: 0.4028
2022-10-02 13:55:47 - until epoch: 251, best_loss: 0.4028
2022-10-02 13:55:47 - epoch 252 lr: 0.000440
2022-10-02 13:56:13 - train: epoch 0252, iter [00010, 01251], lr: 0.000440, loss: 0.3979
2022-10-02 13:56:31 - train: epoch 0252, iter [00020, 01251], lr: 0.000440, loss: 0.4140
2022-10-02 13:56:49 - train: epoch 0252, iter [00030, 01251], lr: 0.000440, loss: 0.3840
2022-10-02 13:57:08 - train: epoch 0252, iter [00040, 01251], lr: 0.000439, loss: 0.4083
2022-10-02 13:57:26 - train: epoch 0252, iter [00050, 01251], lr: 0.000439, loss: 0.4114
2022-10-02 13:57:45 - train: epoch 0252, iter [00060, 01251], lr: 0.000439, loss: 0.3930
2022-10-02 13:58:04 - train: epoch 0252, iter [00070, 01251], lr: 0.000439, loss: 0.4103
2022-10-02 13:58:22 - train: epoch 0252, iter [00080, 01251], lr: 0.000439, loss: 0.4158
2022-10-02 13:58:40 - train: epoch 0252, iter [00090, 01251], lr: 0.000439, loss: 0.4188
2022-10-02 13:58:59 - train: epoch 0252, iter [00100, 01251], lr: 0.000439, loss: 0.3936
2022-10-02 13:59:18 - train: epoch 0252, iter [00110, 01251], lr: 0.000439, loss: 0.4094
2022-10-02 13:59:36 - train: epoch 0252, iter [00120, 01251], lr: 0.000439, loss: 0.3895
2022-10-02 13:59:54 - train: epoch 0252, iter [00130, 01251], lr: 0.000439, loss: 0.3943
2022-10-02 14:00:13 - train: epoch 0252, iter [00140, 01251], lr: 0.000439, loss: 0.3906
2022-10-02 14:00:32 - train: epoch 0252, iter [00150, 01251], lr: 0.000439, loss: 0.4078
2022-10-02 14:00:50 - train: epoch 0252, iter [00160, 01251], lr: 0.000439, loss: 0.4187
2022-10-02 14:01:08 - train: epoch 0252, iter [00170, 01251], lr: 0.000439, loss: 0.4072
2022-10-02 14:01:27 - train: epoch 0252, iter [00180, 01251], lr: 0.000439, loss: 0.4087
2022-10-02 14:01:45 - train: epoch 0252, iter [00190, 01251], lr: 0.000439, loss: 0.4014
2022-10-02 14:02:04 - train: epoch 0252, iter [00200, 01251], lr: 0.000439, loss: 0.3995
2022-10-02 14:02:22 - train: epoch 0252, iter [00210, 01251], lr: 0.000439, loss: 0.4061
2022-10-02 14:02:41 - train: epoch 0252, iter [00220, 01251], lr: 0.000439, loss: 0.4194
2022-10-02 14:02:59 - train: epoch 0252, iter [00230, 01251], lr: 0.000439, loss: 0.4185
2022-10-02 14:03:18 - train: epoch 0252, iter [00240, 01251], lr: 0.000439, loss: 0.3930
2022-10-02 14:03:36 - train: epoch 0252, iter [00250, 01251], lr: 0.000439, loss: 0.3917
2022-10-02 14:03:55 - train: epoch 0252, iter [00260, 01251], lr: 0.000439, loss: 0.4053
2022-10-02 14:04:13 - train: epoch 0252, iter [00270, 01251], lr: 0.000439, loss: 0.4129
2022-10-02 14:04:31 - train: epoch 0252, iter [00280, 01251], lr: 0.000439, loss: 0.3861
2022-10-02 14:04:50 - train: epoch 0252, iter [00290, 01251], lr: 0.000438, loss: 0.4015
2022-10-02 14:05:08 - train: epoch 0252, iter [00300, 01251], lr: 0.000438, loss: 0.4014
2022-10-02 14:05:27 - train: epoch 0252, iter [00310, 01251], lr: 0.000438, loss: 0.4206
2022-10-02 14:05:45 - train: epoch 0252, iter [00320, 01251], lr: 0.000438, loss: 0.3985
2022-10-02 14:06:04 - train: epoch 0252, iter [00330, 01251], lr: 0.000438, loss: 0.4086
2022-10-02 14:06:22 - train: epoch 0252, iter [00340, 01251], lr: 0.000438, loss: 0.4044
2022-10-02 14:06:41 - train: epoch 0252, iter [00350, 01251], lr: 0.000438, loss: 0.4075
2022-10-02 14:06:59 - train: epoch 0252, iter [00360, 01251], lr: 0.000438, loss: 0.4146
2022-10-02 14:07:18 - train: epoch 0252, iter [00370, 01251], lr: 0.000438, loss: 0.4208
2022-10-02 14:07:36 - train: epoch 0252, iter [00380, 01251], lr: 0.000438, loss: 0.3940
2022-10-02 14:07:55 - train: epoch 0252, iter [00390, 01251], lr: 0.000438, loss: 0.3946
2022-10-02 14:08:13 - train: epoch 0252, iter [00400, 01251], lr: 0.000438, loss: 0.4236
2022-10-02 14:08:32 - train: epoch 0252, iter [00410, 01251], lr: 0.000438, loss: 0.3843
2022-10-02 14:08:50 - train: epoch 0252, iter [00420, 01251], lr: 0.000438, loss: 0.3882
2022-10-02 14:09:08 - train: epoch 0252, iter [00430, 01251], lr: 0.000438, loss: 0.4135
2022-10-02 14:09:27 - train: epoch 0252, iter [00440, 01251], lr: 0.000438, loss: 0.4142
2022-10-02 14:09:46 - train: epoch 0252, iter [00450, 01251], lr: 0.000438, loss: 0.3990
2022-10-02 14:10:04 - train: epoch 0252, iter [00460, 01251], lr: 0.000438, loss: 0.4089
2022-10-02 14:10:23 - train: epoch 0252, iter [00470, 01251], lr: 0.000438, loss: 0.3831
2022-10-02 14:10:41 - train: epoch 0252, iter [00480, 01251], lr: 0.000438, loss: 0.3915
2022-10-02 14:10:59 - train: epoch 0252, iter [00490, 01251], lr: 0.000438, loss: 0.3913
2022-10-02 14:11:18 - train: epoch 0252, iter [00500, 01251], lr: 0.000438, loss: 0.4266
2022-10-02 14:11:36 - train: epoch 0252, iter [00510, 01251], lr: 0.000438, loss: 0.3881
2022-10-02 14:11:55 - train: epoch 0252, iter [00520, 01251], lr: 0.000438, loss: 0.4147
2022-10-02 14:12:13 - train: epoch 0252, iter [00530, 01251], lr: 0.000438, loss: 0.4186
2022-10-02 14:12:32 - train: epoch 0252, iter [00540, 01251], lr: 0.000437, loss: 0.3957
2022-10-02 14:12:50 - train: epoch 0252, iter [00550, 01251], lr: 0.000437, loss: 0.4137
2022-10-02 14:13:09 - train: epoch 0252, iter [00560, 01251], lr: 0.000437, loss: 0.4027
2022-10-02 14:13:27 - train: epoch 0252, iter [00570, 01251], lr: 0.000437, loss: 0.3745
2022-10-02 14:13:45 - train: epoch 0252, iter [00580, 01251], lr: 0.000437, loss: 0.3913
2022-10-02 14:14:04 - train: epoch 0252, iter [00590, 01251], lr: 0.000437, loss: 0.3952
2022-10-02 14:14:23 - train: epoch 0252, iter [00600, 01251], lr: 0.000437, loss: 0.3985
2022-10-02 14:14:41 - train: epoch 0252, iter [00610, 01251], lr: 0.000437, loss: 0.3871
2022-10-02 14:14:59 - train: epoch 0252, iter [00620, 01251], lr: 0.000437, loss: 0.3894
2022-10-02 14:15:18 - train: epoch 0252, iter [00630, 01251], lr: 0.000437, loss: 0.4025
2022-10-02 14:15:36 - train: epoch 0252, iter [00640, 01251], lr: 0.000437, loss: 0.4229
2022-10-02 14:15:55 - train: epoch 0252, iter [00650, 01251], lr: 0.000437, loss: 0.4030
2022-10-02 14:16:13 - train: epoch 0252, iter [00660, 01251], lr: 0.000437, loss: 0.3976
2022-10-02 14:16:32 - train: epoch 0252, iter [00670, 01251], lr: 0.000437, loss: 0.4035
2022-10-02 14:16:50 - train: epoch 0252, iter [00680, 01251], lr: 0.000437, loss: 0.3809
2022-10-02 14:17:08 - train: epoch 0252, iter [00690, 01251], lr: 0.000437, loss: 0.3954
2022-10-02 14:17:27 - train: epoch 0252, iter [00700, 01251], lr: 0.000437, loss: 0.4128
2022-10-02 14:17:45 - train: epoch 0252, iter [00710, 01251], lr: 0.000437, loss: 0.3917
2022-10-02 14:18:03 - train: epoch 0252, iter [00720, 01251], lr: 0.000437, loss: 0.3997
2022-10-02 14:18:22 - train: epoch 0252, iter [00730, 01251], lr: 0.000437, loss: 0.4086
2022-10-02 14:18:40 - train: epoch 0252, iter [00740, 01251], lr: 0.000437, loss: 0.3949
2022-10-02 14:18:59 - train: epoch 0252, iter [00750, 01251], lr: 0.000437, loss: 0.4121
2022-10-02 14:19:18 - train: epoch 0252, iter [00760, 01251], lr: 0.000437, loss: 0.3972
2022-10-02 14:19:36 - train: epoch 0252, iter [00770, 01251], lr: 0.000437, loss: 0.4131
2022-10-02 14:19:55 - train: epoch 0252, iter [00780, 01251], lr: 0.000437, loss: 0.4030
2022-10-02 14:20:13 - train: epoch 0252, iter [00790, 01251], lr: 0.000436, loss: 0.4017
2022-10-02 14:20:32 - train: epoch 0252, iter [00800, 01251], lr: 0.000436, loss: 0.3686
2022-10-02 14:20:51 - train: epoch 0252, iter [00810, 01251], lr: 0.000436, loss: 0.4092
2022-10-02 14:21:09 - train: epoch 0252, iter [00820, 01251], lr: 0.000436, loss: 0.3968
2022-10-02 14:21:27 - train: epoch 0252, iter [00830, 01251], lr: 0.000436, loss: 0.3942
2022-10-02 14:21:46 - train: epoch 0252, iter [00840, 01251], lr: 0.000436, loss: 0.4207
2022-10-02 14:22:04 - train: epoch 0252, iter [00850, 01251], lr: 0.000436, loss: 0.3841
2022-10-02 14:22:23 - train: epoch 0252, iter [00860, 01251], lr: 0.000436, loss: 0.4033
2022-10-02 14:22:41 - train: epoch 0252, iter [00870, 01251], lr: 0.000436, loss: 0.4135
2022-10-02 14:23:00 - train: epoch 0252, iter [00880, 01251], lr: 0.000436, loss: 0.3828
2022-10-02 14:23:18 - train: epoch 0252, iter [00890, 01251], lr: 0.000436, loss: 0.4151
2022-10-02 14:23:37 - train: epoch 0252, iter [00900, 01251], lr: 0.000436, loss: 0.3894
2022-10-02 14:23:55 - train: epoch 0252, iter [00910, 01251], lr: 0.000436, loss: 0.4034
2022-10-02 14:24:14 - train: epoch 0252, iter [00920, 01251], lr: 0.000436, loss: 0.3867
2022-10-02 14:24:32 - train: epoch 0252, iter [00930, 01251], lr: 0.000436, loss: 0.4113
2022-10-02 14:24:50 - train: epoch 0252, iter [00940, 01251], lr: 0.000436, loss: 0.3799
2022-10-02 14:25:09 - train: epoch 0252, iter [00950, 01251], lr: 0.000436, loss: 0.3942
2022-10-02 14:25:28 - train: epoch 0252, iter [00960, 01251], lr: 0.000436, loss: 0.3992
2022-10-02 14:25:46 - train: epoch 0252, iter [00970, 01251], lr: 0.000436, loss: 0.4025
2022-10-02 14:26:04 - train: epoch 0252, iter [00980, 01251], lr: 0.000436, loss: 0.3901
2022-10-02 14:26:23 - train: epoch 0252, iter [00990, 01251], lr: 0.000436, loss: 0.3943
2022-10-02 14:26:42 - train: epoch 0252, iter [01000, 01251], lr: 0.000436, loss: 0.4111
2022-10-02 14:27:00 - train: epoch 0252, iter [01010, 01251], lr: 0.000436, loss: 0.4127
2022-10-02 14:27:18 - train: epoch 0252, iter [01020, 01251], lr: 0.000436, loss: 0.3930
2022-10-02 14:27:37 - train: epoch 0252, iter [01030, 01251], lr: 0.000436, loss: 0.4257
2022-10-02 14:27:55 - train: epoch 0252, iter [01040, 01251], lr: 0.000435, loss: 0.3910
2022-10-02 14:28:14 - train: epoch 0252, iter [01050, 01251], lr: 0.000435, loss: 0.3977
2022-10-02 14:28:32 - train: epoch 0252, iter [01060, 01251], lr: 0.000435, loss: 0.3820
2022-10-02 14:28:51 - train: epoch 0252, iter [01070, 01251], lr: 0.000435, loss: 0.3917
2022-10-02 14:29:09 - train: epoch 0252, iter [01080, 01251], lr: 0.000435, loss: 0.4056
2022-10-02 14:29:28 - train: epoch 0252, iter [01090, 01251], lr: 0.000435, loss: 0.4100
2022-10-02 14:29:46 - train: epoch 0252, iter [01100, 01251], lr: 0.000435, loss: 0.4030
2022-10-02 14:30:05 - train: epoch 0252, iter [01110, 01251], lr: 0.000435, loss: 0.3980
2022-10-02 14:30:24 - train: epoch 0252, iter [01120, 01251], lr: 0.000435, loss: 0.3907
2022-10-02 14:30:42 - train: epoch 0252, iter [01130, 01251], lr: 0.000435, loss: 0.3957
2022-10-02 14:31:00 - train: epoch 0252, iter [01140, 01251], lr: 0.000435, loss: 0.4076
2022-10-02 14:31:18 - train: epoch 0252, iter [01150, 01251], lr: 0.000435, loss: 0.3948
2022-10-02 14:31:37 - train: epoch 0252, iter [01160, 01251], lr: 0.000435, loss: 0.4052
2022-10-02 14:31:55 - train: epoch 0252, iter [01170, 01251], lr: 0.000435, loss: 0.3968
2022-10-02 14:32:14 - train: epoch 0252, iter [01180, 01251], lr: 0.000435, loss: 0.4066
2022-10-02 14:32:32 - train: epoch 0252, iter [01190, 01251], lr: 0.000435, loss: 0.3842
2022-10-02 14:32:51 - train: epoch 0252, iter [01200, 01251], lr: 0.000435, loss: 0.3991
2022-10-02 14:33:09 - train: epoch 0252, iter [01210, 01251], lr: 0.000435, loss: 0.3845
2022-10-02 14:33:28 - train: epoch 0252, iter [01220, 01251], lr: 0.000435, loss: 0.3968
2022-10-02 14:33:46 - train: epoch 0252, iter [01230, 01251], lr: 0.000435, loss: 0.3986
2022-10-02 14:34:04 - train: epoch 0252, iter [01240, 01251], lr: 0.000435, loss: 0.3970
2022-10-02 14:34:22 - train: epoch 0252, iter [01250, 01251], lr: 0.000435, loss: 0.4163
2022-10-02 14:34:26 - train: epoch 252, train_loss: 0.4026
2022-10-02 14:34:29 - until epoch: 252, best_loss: 0.4026
2022-10-02 14:34:29 - epoch 253 lr: 0.000435
2022-10-02 14:34:54 - train: epoch 0253, iter [00010, 01251], lr: 0.000435, loss: 0.4211
2022-10-02 14:35:12 - train: epoch 0253, iter [00020, 01251], lr: 0.000435, loss: 0.4112
2022-10-02 14:35:30 - train: epoch 0253, iter [00030, 01251], lr: 0.000434, loss: 0.4082
2022-10-02 14:35:48 - train: epoch 0253, iter [00040, 01251], lr: 0.000434, loss: 0.4035
2022-10-02 14:36:06 - train: epoch 0253, iter [00050, 01251], lr: 0.000434, loss: 0.4343
2022-10-02 14:36:25 - train: epoch 0253, iter [00060, 01251], lr: 0.000434, loss: 0.4195
2022-10-02 14:36:43 - train: epoch 0253, iter [00070, 01251], lr: 0.000434, loss: 0.4117
2022-10-02 14:37:01 - train: epoch 0253, iter [00080, 01251], lr: 0.000434, loss: 0.3788
2022-10-02 14:37:19 - train: epoch 0253, iter [00090, 01251], lr: 0.000434, loss: 0.3721
2022-10-02 14:37:37 - train: epoch 0253, iter [00100, 01251], lr: 0.000434, loss: 0.4070
2022-10-02 14:37:56 - train: epoch 0253, iter [00110, 01251], lr: 0.000434, loss: 0.3810
2022-10-02 14:38:14 - train: epoch 0253, iter [00120, 01251], lr: 0.000434, loss: 0.3939
2022-10-02 14:38:32 - train: epoch 0253, iter [00130, 01251], lr: 0.000434, loss: 0.4097
2022-10-02 14:38:50 - train: epoch 0253, iter [00140, 01251], lr: 0.000434, loss: 0.3971
2022-10-02 14:39:08 - train: epoch 0253, iter [00150, 01251], lr: 0.000434, loss: 0.3984
2022-10-02 14:39:26 - train: epoch 0253, iter [00160, 01251], lr: 0.000434, loss: 0.4013
2022-10-02 14:39:44 - train: epoch 0253, iter [00170, 01251], lr: 0.000434, loss: 0.3959
2022-10-02 14:40:03 - train: epoch 0253, iter [00180, 01251], lr: 0.000434, loss: 0.3761
2022-10-02 14:40:21 - train: epoch 0253, iter [00190, 01251], lr: 0.000434, loss: 0.3885
2022-10-02 14:40:39 - train: epoch 0253, iter [00200, 01251], lr: 0.000434, loss: 0.4005
2022-10-02 14:40:57 - train: epoch 0253, iter [00210, 01251], lr: 0.000434, loss: 0.3909
2022-10-02 14:41:15 - train: epoch 0253, iter [00220, 01251], lr: 0.000434, loss: 0.4000
2022-10-02 14:41:33 - train: epoch 0253, iter [00230, 01251], lr: 0.000434, loss: 0.3981
2022-10-02 14:41:52 - train: epoch 0253, iter [00240, 01251], lr: 0.000434, loss: 0.4006
2022-10-02 14:42:10 - train: epoch 0253, iter [00250, 01251], lr: 0.000434, loss: 0.4112
2022-10-02 14:42:28 - train: epoch 0253, iter [00260, 01251], lr: 0.000434, loss: 0.3896
2022-10-02 14:42:46 - train: epoch 0253, iter [00270, 01251], lr: 0.000434, loss: 0.4103
2022-10-02 14:43:04 - train: epoch 0253, iter [00280, 01251], lr: 0.000433, loss: 0.3992
2022-10-02 14:43:22 - train: epoch 0253, iter [00290, 01251], lr: 0.000433, loss: 0.4040
2022-10-02 14:43:40 - train: epoch 0253, iter [00300, 01251], lr: 0.000433, loss: 0.3981
2022-10-02 14:43:59 - train: epoch 0253, iter [00310, 01251], lr: 0.000433, loss: 0.4005
2022-10-02 14:44:17 - train: epoch 0253, iter [00320, 01251], lr: 0.000433, loss: 0.3866
2022-10-02 14:44:35 - train: epoch 0253, iter [00330, 01251], lr: 0.000433, loss: 0.3964
2022-10-02 14:44:53 - train: epoch 0253, iter [00340, 01251], lr: 0.000433, loss: 0.3872
2022-10-02 14:45:11 - train: epoch 0253, iter [00350, 01251], lr: 0.000433, loss: 0.3949
2022-10-02 14:45:29 - train: epoch 0253, iter [00360, 01251], lr: 0.000433, loss: 0.4117
2022-10-02 14:45:47 - train: epoch 0253, iter [00370, 01251], lr: 0.000433, loss: 0.4197
2022-10-02 14:46:05 - train: epoch 0253, iter [00380, 01251], lr: 0.000433, loss: 0.3946
2022-10-02 14:46:23 - train: epoch 0253, iter [00390, 01251], lr: 0.000433, loss: 0.3982
2022-10-02 14:46:42 - train: epoch 0253, iter [00400, 01251], lr: 0.000433, loss: 0.4033
2022-10-02 14:47:00 - train: epoch 0253, iter [00410, 01251], lr: 0.000433, loss: 0.4078
2022-10-02 14:47:18 - train: epoch 0253, iter [00420, 01251], lr: 0.000433, loss: 0.4219
2022-10-02 14:47:36 - train: epoch 0253, iter [00430, 01251], lr: 0.000433, loss: 0.4171
2022-10-02 14:47:54 - train: epoch 0253, iter [00440, 01251], lr: 0.000433, loss: 0.3944
2022-10-02 14:48:12 - train: epoch 0253, iter [00450, 01251], lr: 0.000433, loss: 0.3995
2022-10-02 14:48:31 - train: epoch 0253, iter [00460, 01251], lr: 0.000433, loss: 0.4073
2022-10-02 14:48:49 - train: epoch 0253, iter [00470, 01251], lr: 0.000433, loss: 0.3828
2022-10-02 14:49:07 - train: epoch 0253, iter [00480, 01251], lr: 0.000433, loss: 0.4141
2022-10-02 14:49:25 - train: epoch 0253, iter [00490, 01251], lr: 0.000433, loss: 0.4245
2022-10-02 14:49:43 - train: epoch 0253, iter [00500, 01251], lr: 0.000433, loss: 0.4079
2022-10-02 14:50:01 - train: epoch 0253, iter [00510, 01251], lr: 0.000433, loss: 0.3755
2022-10-02 14:50:20 - train: epoch 0253, iter [00520, 01251], lr: 0.000433, loss: 0.3965
2022-10-02 14:50:38 - train: epoch 0253, iter [00530, 01251], lr: 0.000432, loss: 0.3666
2022-10-02 14:50:56 - train: epoch 0253, iter [00540, 01251], lr: 0.000432, loss: 0.4192
2022-10-02 14:51:14 - train: epoch 0253, iter [00550, 01251], lr: 0.000432, loss: 0.4117
2022-10-02 14:51:33 - train: epoch 0253, iter [00560, 01251], lr: 0.000432, loss: 0.4056
2022-10-02 14:51:51 - train: epoch 0253, iter [00570, 01251], lr: 0.000432, loss: 0.4273
2022-10-02 14:52:09 - train: epoch 0253, iter [00580, 01251], lr: 0.000432, loss: 0.3730
2022-10-02 14:52:27 - train: epoch 0253, iter [00590, 01251], lr: 0.000432, loss: 0.4119
2022-10-02 14:52:45 - train: epoch 0253, iter [00600, 01251], lr: 0.000432, loss: 0.3964
2022-10-02 14:53:03 - train: epoch 0253, iter [00610, 01251], lr: 0.000432, loss: 0.3996
2022-10-02 14:53:22 - train: epoch 0253, iter [00620, 01251], lr: 0.000432, loss: 0.4148
2022-10-02 14:53:40 - train: epoch 0253, iter [00630, 01251], lr: 0.000432, loss: 0.4156
2022-10-02 14:53:58 - train: epoch 0253, iter [00640, 01251], lr: 0.000432, loss: 0.4158
2022-10-02 14:54:16 - train: epoch 0253, iter [00650, 01251], lr: 0.000432, loss: 0.3982
2022-10-02 14:54:34 - train: epoch 0253, iter [00660, 01251], lr: 0.000432, loss: 0.3857
2022-10-02 14:54:52 - train: epoch 0253, iter [00670, 01251], lr: 0.000432, loss: 0.4122
2022-10-02 14:55:10 - train: epoch 0253, iter [00680, 01251], lr: 0.000432, loss: 0.4065
2022-10-02 14:55:29 - train: epoch 0253, iter [00690, 01251], lr: 0.000432, loss: 0.3967
2022-10-02 14:55:47 - train: epoch 0253, iter [00700, 01251], lr: 0.000432, loss: 0.3927
2022-10-02 14:56:05 - train: epoch 0253, iter [00710, 01251], lr: 0.000432, loss: 0.3964
2022-10-02 14:56:23 - train: epoch 0253, iter [00720, 01251], lr: 0.000432, loss: 0.3972
2022-10-02 14:56:41 - train: epoch 0253, iter [00730, 01251], lr: 0.000432, loss: 0.3912
2022-10-02 14:56:59 - train: epoch 0253, iter [00740, 01251], lr: 0.000432, loss: 0.3966
2022-10-02 14:57:17 - train: epoch 0253, iter [00750, 01251], lr: 0.000432, loss: 0.4042
2022-10-02 14:57:36 - train: epoch 0253, iter [00760, 01251], lr: 0.000432, loss: 0.4165
2022-10-02 14:57:54 - train: epoch 0253, iter [00770, 01251], lr: 0.000432, loss: 0.4062
2022-10-02 14:58:12 - train: epoch 0253, iter [00780, 01251], lr: 0.000431, loss: 0.4290
2022-10-02 14:58:30 - train: epoch 0253, iter [00790, 01251], lr: 0.000431, loss: 0.4106
2022-10-02 14:58:48 - train: epoch 0253, iter [00800, 01251], lr: 0.000431, loss: 0.4056
2022-10-02 14:59:06 - train: epoch 0253, iter [00810, 01251], lr: 0.000431, loss: 0.3949
2022-10-02 14:59:24 - train: epoch 0253, iter [00820, 01251], lr: 0.000431, loss: 0.4237
2022-10-02 14:59:42 - train: epoch 0253, iter [00830, 01251], lr: 0.000431, loss: 0.4252
2022-10-02 15:00:01 - train: epoch 0253, iter [00840, 01251], lr: 0.000431, loss: 0.4213
2022-10-02 15:00:19 - train: epoch 0253, iter [00850, 01251], lr: 0.000431, loss: 0.3952
2022-10-02 15:00:37 - train: epoch 0253, iter [00860, 01251], lr: 0.000431, loss: 0.4112
2022-10-02 15:00:55 - train: epoch 0253, iter [00870, 01251], lr: 0.000431, loss: 0.4026
2022-10-02 15:01:14 - train: epoch 0253, iter [00880, 01251], lr: 0.000431, loss: 0.4119
2022-10-02 15:01:32 - train: epoch 0253, iter [00890, 01251], lr: 0.000431, loss: 0.3855
2022-10-02 15:01:50 - train: epoch 0253, iter [00900, 01251], lr: 0.000431, loss: 0.4023
2022-10-02 15:02:08 - train: epoch 0253, iter [00910, 01251], lr: 0.000431, loss: 0.3959
2022-10-02 15:02:26 - train: epoch 0253, iter [00920, 01251], lr: 0.000431, loss: 0.4021
2022-10-02 15:02:44 - train: epoch 0253, iter [00930, 01251], lr: 0.000431, loss: 0.4136
2022-10-02 15:03:02 - train: epoch 0253, iter [00940, 01251], lr: 0.000431, loss: 0.4014
2022-10-02 15:03:20 - train: epoch 0253, iter [00950, 01251], lr: 0.000431, loss: 0.3995
2022-10-02 15:03:39 - train: epoch 0253, iter [00960, 01251], lr: 0.000431, loss: 0.4182
2022-10-02 15:03:57 - train: epoch 0253, iter [00970, 01251], lr: 0.000431, loss: 0.3916
2022-10-02 15:04:15 - train: epoch 0253, iter [00980, 01251], lr: 0.000431, loss: 0.3865
2022-10-02 15:04:33 - train: epoch 0253, iter [00990, 01251], lr: 0.000431, loss: 0.3966
2022-10-02 15:04:52 - train: epoch 0253, iter [01000, 01251], lr: 0.000431, loss: 0.3995
2022-10-02 15:05:10 - train: epoch 0253, iter [01010, 01251], lr: 0.000431, loss: 0.4123
2022-10-02 15:05:28 - train: epoch 0253, iter [01020, 01251], lr: 0.000431, loss: 0.4164
2022-10-02 15:05:46 - train: epoch 0253, iter [01030, 01251], lr: 0.000430, loss: 0.4042
2022-10-02 15:06:05 - train: epoch 0253, iter [01040, 01251], lr: 0.000430, loss: 0.4033
2022-10-02 15:06:23 - train: epoch 0253, iter [01050, 01251], lr: 0.000430, loss: 0.4192
2022-10-02 15:06:42 - train: epoch 0253, iter [01060, 01251], lr: 0.000430, loss: 0.3880
2022-10-02 15:07:00 - train: epoch 0253, iter [01070, 01251], lr: 0.000430, loss: 0.3908
2022-10-02 15:07:18 - train: epoch 0253, iter [01080, 01251], lr: 0.000430, loss: 0.3964
2022-10-02 15:07:36 - train: epoch 0253, iter [01090, 01251], lr: 0.000430, loss: 0.3919
2022-10-02 15:07:55 - train: epoch 0253, iter [01100, 01251], lr: 0.000430, loss: 0.3884
2022-10-02 15:08:13 - train: epoch 0253, iter [01110, 01251], lr: 0.000430, loss: 0.4066
2022-10-02 15:08:32 - train: epoch 0253, iter [01120, 01251], lr: 0.000430, loss: 0.4003
2022-10-02 15:08:50 - train: epoch 0253, iter [01130, 01251], lr: 0.000430, loss: 0.3936
2022-10-02 15:09:09 - train: epoch 0253, iter [01140, 01251], lr: 0.000430, loss: 0.4310
2022-10-02 15:09:27 - train: epoch 0253, iter [01150, 01251], lr: 0.000430, loss: 0.3934
2022-10-02 15:09:45 - train: epoch 0253, iter [01160, 01251], lr: 0.000430, loss: 0.4170
2022-10-02 15:10:03 - train: epoch 0253, iter [01170, 01251], lr: 0.000430, loss: 0.3858
2022-10-02 15:10:22 - train: epoch 0253, iter [01180, 01251], lr: 0.000430, loss: 0.4082
2022-10-02 15:10:40 - train: epoch 0253, iter [01190, 01251], lr: 0.000430, loss: 0.4078
2022-10-02 15:10:58 - train: epoch 0253, iter [01200, 01251], lr: 0.000430, loss: 0.4006
2022-10-02 15:11:17 - train: epoch 0253, iter [01210, 01251], lr: 0.000430, loss: 0.4079
2022-10-02 15:11:35 - train: epoch 0253, iter [01220, 01251], lr: 0.000430, loss: 0.4250
2022-10-02 15:11:54 - train: epoch 0253, iter [01230, 01251], lr: 0.000430, loss: 0.4077
2022-10-02 15:12:12 - train: epoch 0253, iter [01240, 01251], lr: 0.000430, loss: 0.4030
2022-10-02 15:12:30 - train: epoch 0253, iter [01250, 01251], lr: 0.000430, loss: 0.4073
2022-10-02 15:12:34 - train: epoch 253, train_loss: 0.4025
2022-10-02 15:12:36 - until epoch: 253, best_loss: 0.4025
2022-10-02 15:12:36 - epoch 254 lr: 0.000430
2022-10-02 15:13:01 - train: epoch 0254, iter [00010, 01251], lr: 0.000430, loss: 0.3957
2022-10-02 15:13:19 - train: epoch 0254, iter [00020, 01251], lr: 0.000430, loss: 0.3947
2022-10-02 15:13:38 - train: epoch 0254, iter [00030, 01251], lr: 0.000429, loss: 0.3998
2022-10-02 15:13:56 - train: epoch 0254, iter [00040, 01251], lr: 0.000429, loss: 0.4100
2022-10-02 15:14:14 - train: epoch 0254, iter [00050, 01251], lr: 0.000429, loss: 0.4003
2022-10-02 15:14:32 - train: epoch 0254, iter [00060, 01251], lr: 0.000429, loss: 0.4191
2022-10-02 15:14:50 - train: epoch 0254, iter [00070, 01251], lr: 0.000429, loss: 0.4160
2022-10-02 15:15:09 - train: epoch 0254, iter [00080, 01251], lr: 0.000429, loss: 0.4201
2022-10-02 15:15:27 - train: epoch 0254, iter [00090, 01251], lr: 0.000429, loss: 0.3893
2022-10-02 15:15:45 - train: epoch 0254, iter [00100, 01251], lr: 0.000429, loss: 0.3808
2022-10-02 15:16:03 - train: epoch 0254, iter [00110, 01251], lr: 0.000429, loss: 0.3827
2022-10-02 15:16:21 - train: epoch 0254, iter [00120, 01251], lr: 0.000429, loss: 0.4005
2022-10-02 15:16:39 - train: epoch 0254, iter [00130, 01251], lr: 0.000429, loss: 0.3845
2022-10-02 15:16:58 - train: epoch 0254, iter [00140, 01251], lr: 0.000429, loss: 0.3928
2022-10-02 15:17:16 - train: epoch 0254, iter [00150, 01251], lr: 0.000429, loss: 0.3911
2022-10-02 15:17:34 - train: epoch 0254, iter [00160, 01251], lr: 0.000429, loss: 0.3905
2022-10-02 15:17:52 - train: epoch 0254, iter [00170, 01251], lr: 0.000429, loss: 0.3968
2022-10-02 15:18:10 - train: epoch 0254, iter [00180, 01251], lr: 0.000429, loss: 0.4224
2022-10-02 15:18:28 - train: epoch 0254, iter [00190, 01251], lr: 0.000429, loss: 0.4009
2022-10-02 15:18:47 - train: epoch 0254, iter [00200, 01251], lr: 0.000429, loss: 0.4212
2022-10-02 15:19:05 - train: epoch 0254, iter [00210, 01251], lr: 0.000429, loss: 0.4043
2022-10-02 15:19:23 - train: epoch 0254, iter [00220, 01251], lr: 0.000429, loss: 0.4075
2022-10-02 15:19:41 - train: epoch 0254, iter [00230, 01251], lr: 0.000429, loss: 0.3994
2022-10-02 15:19:59 - train: epoch 0254, iter [00240, 01251], lr: 0.000429, loss: 0.4119
2022-10-02 15:20:17 - train: epoch 0254, iter [00250, 01251], lr: 0.000429, loss: 0.3981
2022-10-02 15:20:36 - train: epoch 0254, iter [00260, 01251], lr: 0.000429, loss: 0.3960
2022-10-02 15:20:54 - train: epoch 0254, iter [00270, 01251], lr: 0.000429, loss: 0.4090
2022-10-02 15:21:12 - train: epoch 0254, iter [00280, 01251], lr: 0.000428, loss: 0.4064
2022-10-02 15:21:30 - train: epoch 0254, iter [00290, 01251], lr: 0.000428, loss: 0.4084
2022-10-02 15:21:48 - train: epoch 0254, iter [00300, 01251], lr: 0.000428, loss: 0.3795
2022-10-02 15:22:06 - train: epoch 0254, iter [00310, 01251], lr: 0.000428, loss: 0.4001
2022-10-02 15:22:24 - train: epoch 0254, iter [00320, 01251], lr: 0.000428, loss: 0.4061
2022-10-02 15:22:43 - train: epoch 0254, iter [00330, 01251], lr: 0.000428, loss: 0.4075
2022-10-02 15:23:01 - train: epoch 0254, iter [00340, 01251], lr: 0.000428, loss: 0.3965
2022-10-02 15:23:19 - train: epoch 0254, iter [00350, 01251], lr: 0.000428, loss: 0.3837
2022-10-02 15:23:37 - train: epoch 0254, iter [00360, 01251], lr: 0.000428, loss: 0.3966
2022-10-02 15:23:56 - train: epoch 0254, iter [00370, 01251], lr: 0.000428, loss: 0.4040
2022-10-02 15:24:14 - train: epoch 0254, iter [00380, 01251], lr: 0.000428, loss: 0.4016
2022-10-02 15:24:32 - train: epoch 0254, iter [00390, 01251], lr: 0.000428, loss: 0.3778
2022-10-02 15:24:50 - train: epoch 0254, iter [00400, 01251], lr: 0.000428, loss: 0.4058
2022-10-02 15:25:08 - train: epoch 0254, iter [00410, 01251], lr: 0.000428, loss: 0.4083
2022-10-02 15:25:26 - train: epoch 0254, iter [00420, 01251], lr: 0.000428, loss: 0.3909
2022-10-02 15:25:44 - train: epoch 0254, iter [00430, 01251], lr: 0.000428, loss: 0.4093
2022-10-02 15:26:02 - train: epoch 0254, iter [00440, 01251], lr: 0.000428, loss: 0.4091
2022-10-02 15:26:21 - train: epoch 0254, iter [00450, 01251], lr: 0.000428, loss: 0.4012
2022-10-02 15:26:39 - train: epoch 0254, iter [00460, 01251], lr: 0.000428, loss: 0.3894
2022-10-02 15:26:57 - train: epoch 0254, iter [00470, 01251], lr: 0.000428, loss: 0.3846
2022-10-02 15:27:15 - train: epoch 0254, iter [00480, 01251], lr: 0.000428, loss: 0.4066
2022-10-02 15:27:33 - train: epoch 0254, iter [00490, 01251], lr: 0.000428, loss: 0.3893
2022-10-02 15:27:51 - train: epoch 0254, iter [00500, 01251], lr: 0.000428, loss: 0.4006
2022-10-02 15:28:10 - train: epoch 0254, iter [00510, 01251], lr: 0.000428, loss: 0.3945
2022-10-02 15:28:28 - train: epoch 0254, iter [00520, 01251], lr: 0.000428, loss: 0.3905
2022-10-02 15:28:46 - train: epoch 0254, iter [00530, 01251], lr: 0.000427, loss: 0.3941
2022-10-02 15:29:04 - train: epoch 0254, iter [00540, 01251], lr: 0.000427, loss: 0.3954
2022-10-02 15:29:22 - train: epoch 0254, iter [00550, 01251], lr: 0.000427, loss: 0.4077
2022-10-02 15:29:40 - train: epoch 0254, iter [00560, 01251], lr: 0.000427, loss: 0.4033
2022-10-02 15:29:58 - train: epoch 0254, iter [00570, 01251], lr: 0.000427, loss: 0.4044
2022-10-02 15:30:17 - train: epoch 0254, iter [00580, 01251], lr: 0.000427, loss: 0.3913
2022-10-02 15:30:35 - train: epoch 0254, iter [00590, 01251], lr: 0.000427, loss: 0.4012
2022-10-02 15:30:53 - train: epoch 0254, iter [00600, 01251], lr: 0.000427, loss: 0.4023
2022-10-02 15:31:11 - train: epoch 0254, iter [00610, 01251], lr: 0.000427, loss: 0.4102
2022-10-02 15:31:29 - train: epoch 0254, iter [00620, 01251], lr: 0.000427, loss: 0.4067
2022-10-02 15:31:47 - train: epoch 0254, iter [00630, 01251], lr: 0.000427, loss: 0.4183
2022-10-02 15:32:06 - train: epoch 0254, iter [00640, 01251], lr: 0.000427, loss: 0.4054
2022-10-02 15:32:24 - train: epoch 0254, iter [00650, 01251], lr: 0.000427, loss: 0.4065
2022-10-02 15:32:42 - train: epoch 0254, iter [00660, 01251], lr: 0.000427, loss: 0.3879
2022-10-02 15:33:00 - train: epoch 0254, iter [00670, 01251], lr: 0.000427, loss: 0.4037
2022-10-02 15:33:18 - train: epoch 0254, iter [00680, 01251], lr: 0.000427, loss: 0.3941
2022-10-02 15:33:37 - train: epoch 0254, iter [00690, 01251], lr: 0.000427, loss: 0.3949
2022-10-02 15:33:55 - train: epoch 0254, iter [00700, 01251], lr: 0.000427, loss: 0.3906
2022-10-02 15:34:13 - train: epoch 0254, iter [00710, 01251], lr: 0.000427, loss: 0.4077
2022-10-02 15:34:31 - train: epoch 0254, iter [00720, 01251], lr: 0.000427, loss: 0.3932
2022-10-02 15:34:50 - train: epoch 0254, iter [00730, 01251], lr: 0.000427, loss: 0.4087
2022-10-02 15:35:08 - train: epoch 0254, iter [00740, 01251], lr: 0.000427, loss: 0.4045
2022-10-02 15:35:26 - train: epoch 0254, iter [00750, 01251], lr: 0.000427, loss: 0.4102
2022-10-02 15:35:44 - train: epoch 0254, iter [00760, 01251], lr: 0.000427, loss: 0.4074
2022-10-02 15:36:02 - train: epoch 0254, iter [00770, 01251], lr: 0.000427, loss: 0.3948
2022-10-02 15:36:20 - train: epoch 0254, iter [00780, 01251], lr: 0.000426, loss: 0.4052
2022-10-02 15:36:38 - train: epoch 0254, iter [00790, 01251], lr: 0.000426, loss: 0.4005
2022-10-02 15:36:56 - train: epoch 0254, iter [00800, 01251], lr: 0.000426, loss: 0.4056
2022-10-02 15:37:14 - train: epoch 0254, iter [00810, 01251], lr: 0.000426, loss: 0.4062
2022-10-02 15:37:33 - train: epoch 0254, iter [00820, 01251], lr: 0.000426, loss: 0.4016
2022-10-02 15:37:51 - train: epoch 0254, iter [00830, 01251], lr: 0.000426, loss: 0.3929
2022-10-02 15:38:09 - train: epoch 0254, iter [00840, 01251], lr: 0.000426, loss: 0.4083
2022-10-02 15:38:27 - train: epoch 0254, iter [00850, 01251], lr: 0.000426, loss: 0.4093
2022-10-02 15:38:45 - train: epoch 0254, iter [00860, 01251], lr: 0.000426, loss: 0.4136
2022-10-02 15:39:04 - train: epoch 0254, iter [00870, 01251], lr: 0.000426, loss: 0.3882
2022-10-02 15:39:22 - train: epoch 0254, iter [00880, 01251], lr: 0.000426, loss: 0.4155
2022-10-02 15:39:40 - train: epoch 0254, iter [00890, 01251], lr: 0.000426, loss: 0.3972
2022-10-02 15:39:58 - train: epoch 0254, iter [00900, 01251], lr: 0.000426, loss: 0.3915
2022-10-02 15:40:17 - train: epoch 0254, iter [00910, 01251], lr: 0.000426, loss: 0.4159
2022-10-02 15:40:35 - train: epoch 0254, iter [00920, 01251], lr: 0.000426, loss: 0.4161
2022-10-02 15:40:53 - train: epoch 0254, iter [00930, 01251], lr: 0.000426, loss: 0.4103
2022-10-02 15:41:11 - train: epoch 0254, iter [00940, 01251], lr: 0.000426, loss: 0.3912
2022-10-02 15:41:29 - train: epoch 0254, iter [00950, 01251], lr: 0.000426, loss: 0.3995
2022-10-02 15:41:47 - train: epoch 0254, iter [00960, 01251], lr: 0.000426, loss: 0.3787
2022-10-02 15:42:06 - train: epoch 0254, iter [00970, 01251], lr: 0.000426, loss: 0.3968
2022-10-02 15:42:24 - train: epoch 0254, iter [00980, 01251], lr: 0.000426, loss: 0.3900
2022-10-02 15:42:42 - train: epoch 0254, iter [00990, 01251], lr: 0.000426, loss: 0.4104
2022-10-02 15:43:00 - train: epoch 0254, iter [01000, 01251], lr: 0.000426, loss: 0.4115
2022-10-02 15:43:18 - train: epoch 0254, iter [01010, 01251], lr: 0.000426, loss: 0.4232
2022-10-02 15:43:36 - train: epoch 0254, iter [01020, 01251], lr: 0.000426, loss: 0.3981
2022-10-02 15:43:54 - train: epoch 0254, iter [01030, 01251], lr: 0.000425, loss: 0.3831
2022-10-02 15:44:13 - train: epoch 0254, iter [01040, 01251], lr: 0.000425, loss: 0.4033
2022-10-02 15:44:31 - train: epoch 0254, iter [01050, 01251], lr: 0.000425, loss: 0.4061
2022-10-02 15:44:49 - train: epoch 0254, iter [01060, 01251], lr: 0.000425, loss: 0.4081
2022-10-02 15:45:07 - train: epoch 0254, iter [01070, 01251], lr: 0.000425, loss: 0.3934
2022-10-02 15:45:26 - train: epoch 0254, iter [01080, 01251], lr: 0.000425, loss: 0.4022
2022-10-02 15:45:44 - train: epoch 0254, iter [01090, 01251], lr: 0.000425, loss: 0.3906
2022-10-02 15:46:02 - train: epoch 0254, iter [01100, 01251], lr: 0.000425, loss: 0.4241
2022-10-02 15:46:20 - train: epoch 0254, iter [01110, 01251], lr: 0.000425, loss: 0.4259
2022-10-02 15:46:38 - train: epoch 0254, iter [01120, 01251], lr: 0.000425, loss: 0.4055
2022-10-02 15:46:56 - train: epoch 0254, iter [01130, 01251], lr: 0.000425, loss: 0.3993
2022-10-02 15:47:14 - train: epoch 0254, iter [01140, 01251], lr: 0.000425, loss: 0.4184
2022-10-02 15:47:33 - train: epoch 0254, iter [01150, 01251], lr: 0.000425, loss: 0.4053
2022-10-02 15:47:51 - train: epoch 0254, iter [01160, 01251], lr: 0.000425, loss: 0.3961
2022-10-02 15:48:09 - train: epoch 0254, iter [01170, 01251], lr: 0.000425, loss: 0.4080
2022-10-02 15:48:27 - train: epoch 0254, iter [01180, 01251], lr: 0.000425, loss: 0.4150
2022-10-02 15:48:45 - train: epoch 0254, iter [01190, 01251], lr: 0.000425, loss: 0.4218
2022-10-02 15:49:03 - train: epoch 0254, iter [01200, 01251], lr: 0.000425, loss: 0.3904
2022-10-02 15:49:22 - train: epoch 0254, iter [01210, 01251], lr: 0.000425, loss: 0.4004
2022-10-02 15:49:40 - train: epoch 0254, iter [01220, 01251], lr: 0.000425, loss: 0.4050
2022-10-02 15:49:58 - train: epoch 0254, iter [01230, 01251], lr: 0.000425, loss: 0.3873
2022-10-02 15:50:16 - train: epoch 0254, iter [01240, 01251], lr: 0.000425, loss: 0.4114
2022-10-02 15:50:34 - train: epoch 0254, iter [01250, 01251], lr: 0.000425, loss: 0.4050
2022-10-02 15:50:37 - train: epoch 254, train_loss: 0.4024
2022-10-02 15:50:40 - until epoch: 254, best_loss: 0.4024
2022-10-02 15:50:40 - epoch 255 lr: 0.000425
2022-10-02 15:51:05 - train: epoch 0255, iter [00010, 01251], lr: 0.000425, loss: 0.3810
2022-10-02 15:51:23 - train: epoch 0255, iter [00020, 01251], lr: 0.000424, loss: 0.4050
2022-10-02 15:51:41 - train: epoch 0255, iter [00030, 01251], lr: 0.000424, loss: 0.4030
2022-10-02 15:51:59 - train: epoch 0255, iter [00040, 01251], lr: 0.000424, loss: 0.3953
2022-10-02 15:52:17 - train: epoch 0255, iter [00050, 01251], lr: 0.000424, loss: 0.4021
2022-10-02 15:52:36 - train: epoch 0255, iter [00060, 01251], lr: 0.000424, loss: 0.4030
2022-10-02 15:52:54 - train: epoch 0255, iter [00070, 01251], lr: 0.000424, loss: 0.3845
2022-10-02 15:53:12 - train: epoch 0255, iter [00080, 01251], lr: 0.000424, loss: 0.4077
2022-10-02 15:53:30 - train: epoch 0255, iter [00090, 01251], lr: 0.000424, loss: 0.4124
2022-10-02 15:53:48 - train: epoch 0255, iter [00100, 01251], lr: 0.000424, loss: 0.4212
2022-10-02 15:54:06 - train: epoch 0255, iter [00110, 01251], lr: 0.000424, loss: 0.4005
2022-10-02 15:54:25 - train: epoch 0255, iter [00120, 01251], lr: 0.000424, loss: 0.4011
2022-10-02 15:54:43 - train: epoch 0255, iter [00130, 01251], lr: 0.000424, loss: 0.3909
2022-10-02 15:55:01 - train: epoch 0255, iter [00140, 01251], lr: 0.000424, loss: 0.4220
2022-10-02 15:55:19 - train: epoch 0255, iter [00150, 01251], lr: 0.000424, loss: 0.3928
2022-10-02 15:55:37 - train: epoch 0255, iter [00160, 01251], lr: 0.000424, loss: 0.4157
2022-10-02 15:55:55 - train: epoch 0255, iter [00170, 01251], lr: 0.000424, loss: 0.4181
2022-10-02 15:56:13 - train: epoch 0255, iter [00180, 01251], lr: 0.000424, loss: 0.4210
2022-10-02 15:56:32 - train: epoch 0255, iter [00190, 01251], lr: 0.000424, loss: 0.3702
2022-10-02 15:56:50 - train: epoch 0255, iter [00200, 01251], lr: 0.000424, loss: 0.3995
2022-10-02 15:57:08 - train: epoch 0255, iter [00210, 01251], lr: 0.000424, loss: 0.4197
2022-10-02 15:57:26 - train: epoch 0255, iter [00220, 01251], lr: 0.000424, loss: 0.3933
2022-10-02 15:57:44 - train: epoch 0255, iter [00230, 01251], lr: 0.000424, loss: 0.3981
2022-10-02 15:58:02 - train: epoch 0255, iter [00240, 01251], lr: 0.000424, loss: 0.4061
2022-10-02 15:58:20 - train: epoch 0255, iter [00250, 01251], lr: 0.000424, loss: 0.4186
2022-10-02 15:58:39 - train: epoch 0255, iter [00260, 01251], lr: 0.000424, loss: 0.4008
2022-10-02 15:58:57 - train: epoch 0255, iter [00270, 01251], lr: 0.000423, loss: 0.3967
2022-10-02 15:59:15 - train: epoch 0255, iter [00280, 01251], lr: 0.000423, loss: 0.3991
2022-10-02 15:59:33 - train: epoch 0255, iter [00290, 01251], lr: 0.000423, loss: 0.4074
2022-10-02 15:59:51 - train: epoch 0255, iter [00300, 01251], lr: 0.000423, loss: 0.4062
2022-10-02 16:00:09 - train: epoch 0255, iter [00310, 01251], lr: 0.000423, loss: 0.3835
2022-10-02 16:00:27 - train: epoch 0255, iter [00320, 01251], lr: 0.000423, loss: 0.4138
2022-10-02 16:00:45 - train: epoch 0255, iter [00330, 01251], lr: 0.000423, loss: 0.3956
2022-10-02 16:01:03 - train: epoch 0255, iter [00340, 01251], lr: 0.000423, loss: 0.4098
2022-10-02 16:01:22 - train: epoch 0255, iter [00350, 01251], lr: 0.000423, loss: 0.4016
2022-10-02 16:01:40 - train: epoch 0255, iter [00360, 01251], lr: 0.000423, loss: 0.3831
2022-10-02 16:01:58 - train: epoch 0255, iter [00370, 01251], lr: 0.000423, loss: 0.4105
2022-10-02 16:02:16 - train: epoch 0255, iter [00380, 01251], lr: 0.000423, loss: 0.4017
2022-10-02 16:02:34 - train: epoch 0255, iter [00390, 01251], lr: 0.000423, loss: 0.4040
2022-10-02 16:02:52 - train: epoch 0255, iter [00400, 01251], lr: 0.000423, loss: 0.4107
2022-10-02 16:03:10 - train: epoch 0255, iter [00410, 01251], lr: 0.000423, loss: 0.4147
2022-10-02 16:03:28 - train: epoch 0255, iter [00420, 01251], lr: 0.000423, loss: 0.3825
2022-10-02 16:03:46 - train: epoch 0255, iter [00430, 01251], lr: 0.000423, loss: 0.4031
2022-10-02 16:04:04 - train: epoch 0255, iter [00440, 01251], lr: 0.000423, loss: 0.3900
2022-10-02 16:04:23 - train: epoch 0255, iter [00450, 01251], lr: 0.000423, loss: 0.3870
2022-10-02 16:04:41 - train: epoch 0255, iter [00460, 01251], lr: 0.000423, loss: 0.4062
2022-10-02 16:04:59 - train: epoch 0255, iter [00470, 01251], lr: 0.000423, loss: 0.3950
2022-10-02 16:05:17 - train: epoch 0255, iter [00480, 01251], lr: 0.000423, loss: 0.3907
2022-10-02 16:05:35 - train: epoch 0255, iter [00490, 01251], lr: 0.000423, loss: 0.4142
2022-10-02 16:05:53 - train: epoch 0255, iter [00500, 01251], lr: 0.000423, loss: 0.4095
2022-10-02 16:06:11 - train: epoch 0255, iter [00510, 01251], lr: 0.000423, loss: 0.4050
2022-10-02 16:06:29 - train: epoch 0255, iter [00520, 01251], lr: 0.000422, loss: 0.4151
2022-10-02 16:06:47 - train: epoch 0255, iter [00530, 01251], lr: 0.000422, loss: 0.4043
2022-10-02 16:07:05 - train: epoch 0255, iter [00540, 01251], lr: 0.000422, loss: 0.3973
2022-10-02 16:07:23 - train: epoch 0255, iter [00550, 01251], lr: 0.000422, loss: 0.4057
2022-10-02 16:07:42 - train: epoch 0255, iter [00560, 01251], lr: 0.000422, loss: 0.4104
2022-10-02 16:08:00 - train: epoch 0255, iter [00570, 01251], lr: 0.000422, loss: 0.4096
2022-10-02 16:08:18 - train: epoch 0255, iter [00580, 01251], lr: 0.000422, loss: 0.4068
2022-10-02 16:08:36 - train: epoch 0255, iter [00590, 01251], lr: 0.000422, loss: 0.4234
2022-10-02 16:08:55 - train: epoch 0255, iter [00600, 01251], lr: 0.000422, loss: 0.3926
2022-10-02 16:09:13 - train: epoch 0255, iter [00610, 01251], lr: 0.000422, loss: 0.3933
2022-10-02 16:09:31 - train: epoch 0255, iter [00620, 01251], lr: 0.000422, loss: 0.3869
2022-10-02 16:09:49 - train: epoch 0255, iter [00630, 01251], lr: 0.000422, loss: 0.4045
2022-10-02 16:10:07 - train: epoch 0255, iter [00640, 01251], lr: 0.000422, loss: 0.3851
2022-10-02 16:10:25 - train: epoch 0255, iter [00650, 01251], lr: 0.000422, loss: 0.4025
2022-10-02 16:10:44 - train: epoch 0255, iter [00660, 01251], lr: 0.000422, loss: 0.3937
2022-10-02 16:11:02 - train: epoch 0255, iter [00670, 01251], lr: 0.000422, loss: 0.4125
2022-10-02 16:11:20 - train: epoch 0255, iter [00680, 01251], lr: 0.000422, loss: 0.3975
2022-10-02 16:11:38 - train: epoch 0255, iter [00690, 01251], lr: 0.000422, loss: 0.4099
2022-10-02 16:11:56 - train: epoch 0255, iter [00700, 01251], lr: 0.000422, loss: 0.4153
2022-10-02 16:12:14 - train: epoch 0255, iter [00710, 01251], lr: 0.000422, loss: 0.4127
2022-10-02 16:12:32 - train: epoch 0255, iter [00720, 01251], lr: 0.000422, loss: 0.4086
2022-10-02 16:12:51 - train: epoch 0255, iter [00730, 01251], lr: 0.000422, loss: 0.4109
2022-10-02 16:13:09 - train: epoch 0255, iter [00740, 01251], lr: 0.000422, loss: 0.4174
2022-10-02 16:13:27 - train: epoch 0255, iter [00750, 01251], lr: 0.000422, loss: 0.4084
2022-10-02 16:13:45 - train: epoch 0255, iter [00760, 01251], lr: 0.000422, loss: 0.4337
2022-10-02 16:14:03 - train: epoch 0255, iter [00770, 01251], lr: 0.000421, loss: 0.3895
2022-10-02 16:14:21 - train: epoch 0255, iter [00780, 01251], lr: 0.000421, loss: 0.4062
2022-10-02 16:14:39 - train: epoch 0255, iter [00790, 01251], lr: 0.000421, loss: 0.3968
2022-10-02 16:14:57 - train: epoch 0255, iter [00800, 01251], lr: 0.000421, loss: 0.4031
2022-10-02 16:15:15 - train: epoch 0255, iter [00810, 01251], lr: 0.000421, loss: 0.3921
2022-10-02 16:15:34 - train: epoch 0255, iter [00820, 01251], lr: 0.000421, loss: 0.3909
2022-10-02 16:15:52 - train: epoch 0255, iter [00830, 01251], lr: 0.000421, loss: 0.4117
2022-10-02 16:16:10 - train: epoch 0255, iter [00840, 01251], lr: 0.000421, loss: 0.4049
2022-10-02 16:16:28 - train: epoch 0255, iter [00850, 01251], lr: 0.000421, loss: 0.3911
2022-10-02 16:16:46 - train: epoch 0255, iter [00860, 01251], lr: 0.000421, loss: 0.4140
2022-10-02 16:17:05 - train: epoch 0255, iter [00870, 01251], lr: 0.000421, loss: 0.4312
2022-10-02 16:17:23 - train: epoch 0255, iter [00880, 01251], lr: 0.000421, loss: 0.4096
2022-10-02 16:17:41 - train: epoch 0255, iter [00890, 01251], lr: 0.000421, loss: 0.4163
2022-10-02 16:17:59 - train: epoch 0255, iter [00900, 01251], lr: 0.000421, loss: 0.3976
2022-10-02 16:18:17 - train: epoch 0255, iter [00910, 01251], lr: 0.000421, loss: 0.4097
2022-10-02 16:18:35 - train: epoch 0255, iter [00920, 01251], lr: 0.000421, loss: 0.4031
2022-10-02 16:18:53 - train: epoch 0255, iter [00930, 01251], lr: 0.000421, loss: 0.3987
2022-10-02 16:19:12 - train: epoch 0255, iter [00940, 01251], lr: 0.000421, loss: 0.3785
2022-10-02 16:19:30 - train: epoch 0255, iter [00950, 01251], lr: 0.000421, loss: 0.3943
2022-10-02 16:19:48 - train: epoch 0255, iter [00960, 01251], lr: 0.000421, loss: 0.3976
2022-10-02 16:20:06 - train: epoch 0255, iter [00970, 01251], lr: 0.000421, loss: 0.3994
2022-10-02 16:20:24 - train: epoch 0255, iter [00980, 01251], lr: 0.000421, loss: 0.4095
2022-10-02 16:20:42 - train: epoch 0255, iter [00990, 01251], lr: 0.000421, loss: 0.4085
2022-10-02 16:21:00 - train: epoch 0255, iter [01000, 01251], lr: 0.000421, loss: 0.3984
2022-10-02 16:21:19 - train: epoch 0255, iter [01010, 01251], lr: 0.000421, loss: 0.4085
2022-10-02 16:21:37 - train: epoch 0255, iter [01020, 01251], lr: 0.000420, loss: 0.4084
2022-10-02 16:21:55 - train: epoch 0255, iter [01030, 01251], lr: 0.000420, loss: 0.3833
2022-10-02 16:22:13 - train: epoch 0255, iter [01040, 01251], lr: 0.000420, loss: 0.4026
2022-10-02 16:22:31 - train: epoch 0255, iter [01050, 01251], lr: 0.000420, loss: 0.3977
2022-10-02 16:22:49 - train: epoch 0255, iter [01060, 01251], lr: 0.000420, loss: 0.4102
2022-10-02 16:23:07 - train: epoch 0255, iter [01070, 01251], lr: 0.000420, loss: 0.4078
2022-10-02 16:23:25 - train: epoch 0255, iter [01080, 01251], lr: 0.000420, loss: 0.4005
2022-10-02 16:23:43 - train: epoch 0255, iter [01090, 01251], lr: 0.000420, loss: 0.4037
2022-10-02 16:24:01 - train: epoch 0255, iter [01100, 01251], lr: 0.000420, loss: 0.4162
2022-10-02 16:24:20 - train: epoch 0255, iter [01110, 01251], lr: 0.000420, loss: 0.3854
2022-10-02 16:24:38 - train: epoch 0255, iter [01120, 01251], lr: 0.000420, loss: 0.4096
2022-10-02 16:24:56 - train: epoch 0255, iter [01130, 01251], lr: 0.000420, loss: 0.3931
2022-10-02 16:25:14 - train: epoch 0255, iter [01140, 01251], lr: 0.000420, loss: 0.4318
2022-10-02 16:25:32 - train: epoch 0255, iter [01150, 01251], lr: 0.000420, loss: 0.4110
2022-10-02 16:25:50 - train: epoch 0255, iter [01160, 01251], lr: 0.000420, loss: 0.3774
2022-10-02 16:26:09 - train: epoch 0255, iter [01170, 01251], lr: 0.000420, loss: 0.4021
2022-10-02 16:26:27 - train: epoch 0255, iter [01180, 01251], lr: 0.000420, loss: 0.4037
2022-10-02 16:26:45 - train: epoch 0255, iter [01190, 01251], lr: 0.000420, loss: 0.4067
2022-10-02 16:27:03 - train: epoch 0255, iter [01200, 01251], lr: 0.000420, loss: 0.4200
2022-10-02 16:27:21 - train: epoch 0255, iter [01210, 01251], lr: 0.000420, loss: 0.3979
2022-10-02 16:27:40 - train: epoch 0255, iter [01220, 01251], lr: 0.000420, loss: 0.4061
2022-10-02 16:27:58 - train: epoch 0255, iter [01230, 01251], lr: 0.000420, loss: 0.4120
2022-10-02 16:28:16 - train: epoch 0255, iter [01240, 01251], lr: 0.000420, loss: 0.3944
2022-10-02 16:28:34 - train: epoch 0255, iter [01250, 01251], lr: 0.000420, loss: 0.4080
2022-10-02 16:28:37 - train: epoch 255, train_loss: 0.4022
2022-10-02 16:28:40 - until epoch: 255, best_loss: 0.4022
2022-10-02 16:28:40 - epoch 256 lr: 0.000420
2022-10-02 16:29:05 - train: epoch 0256, iter [00010, 01251], lr: 0.000420, loss: 0.4120
2022-10-02 16:29:23 - train: epoch 0256, iter [00020, 01251], lr: 0.000419, loss: 0.4177
2022-10-02 16:29:41 - train: epoch 0256, iter [00030, 01251], lr: 0.000419, loss: 0.4140
2022-10-02 16:29:59 - train: epoch 0256, iter [00040, 01251], lr: 0.000419, loss: 0.4003
2022-10-02 16:30:17 - train: epoch 0256, iter [00050, 01251], lr: 0.000419, loss: 0.3879
2022-10-02 16:30:35 - train: epoch 0256, iter [00060, 01251], lr: 0.000419, loss: 0.4038
2022-10-02 16:30:54 - train: epoch 0256, iter [00070, 01251], lr: 0.000419, loss: 0.3997
2022-10-02 16:31:12 - train: epoch 0256, iter [00080, 01251], lr: 0.000419, loss: 0.4126
2022-10-02 16:31:30 - train: epoch 0256, iter [00090, 01251], lr: 0.000419, loss: 0.4078
2022-10-02 16:31:48 - train: epoch 0256, iter [00100, 01251], lr: 0.000419, loss: 0.4036
2022-10-02 16:32:06 - train: epoch 0256, iter [00110, 01251], lr: 0.000419, loss: 0.4149
2022-10-02 16:32:24 - train: epoch 0256, iter [00120, 01251], lr: 0.000419, loss: 0.3830
2022-10-02 16:32:42 - train: epoch 0256, iter [00130, 01251], lr: 0.000419, loss: 0.3940
2022-10-02 16:33:00 - train: epoch 0256, iter [00140, 01251], lr: 0.000419, loss: 0.3967
2022-10-02 16:33:18 - train: epoch 0256, iter [00150, 01251], lr: 0.000419, loss: 0.4018
2022-10-02 16:33:37 - train: epoch 0256, iter [00160, 01251], lr: 0.000419, loss: 0.4090
2022-10-02 16:33:55 - train: epoch 0256, iter [00170, 01251], lr: 0.000419, loss: 0.4220
2022-10-02 16:34:13 - train: epoch 0256, iter [00180, 01251], lr: 0.000419, loss: 0.3913
2022-10-02 16:34:31 - train: epoch 0256, iter [00190, 01251], lr: 0.000419, loss: 0.3825
2022-10-02 16:34:49 - train: epoch 0256, iter [00200, 01251], lr: 0.000419, loss: 0.3921
2022-10-02 16:35:07 - train: epoch 0256, iter [00210, 01251], lr: 0.000419, loss: 0.3918
2022-10-02 16:35:26 - train: epoch 0256, iter [00220, 01251], lr: 0.000419, loss: 0.4152
2022-10-02 16:35:44 - train: epoch 0256, iter [00230, 01251], lr: 0.000419, loss: 0.4097
2022-10-02 16:36:02 - train: epoch 0256, iter [00240, 01251], lr: 0.000419, loss: 0.3897
2022-10-02 16:36:20 - train: epoch 0256, iter [00250, 01251], lr: 0.000419, loss: 0.3853
2022-10-02 16:36:38 - train: epoch 0256, iter [00260, 01251], lr: 0.000419, loss: 0.3912
2022-10-02 16:36:56 - train: epoch 0256, iter [00270, 01251], lr: 0.000418, loss: 0.4083
2022-10-02 16:37:14 - train: epoch 0256, iter [00280, 01251], lr: 0.000418, loss: 0.4009
2022-10-02 16:37:33 - train: epoch 0256, iter [00290, 01251], lr: 0.000418, loss: 0.4108
2022-10-02 16:37:51 - train: epoch 0256, iter [00300, 01251], lr: 0.000418, loss: 0.4111
2022-10-02 16:38:09 - train: epoch 0256, iter [00310, 01251], lr: 0.000418, loss: 0.3913
2022-10-02 16:38:27 - train: epoch 0256, iter [00320, 01251], lr: 0.000418, loss: 0.3861
2022-10-02 16:38:45 - train: epoch 0256, iter [00330, 01251], lr: 0.000418, loss: 0.4109
2022-10-02 16:39:04 - train: epoch 0256, iter [00340, 01251], lr: 0.000418, loss: 0.4138
2022-10-02 16:39:21 - train: epoch 0256, iter [00350, 01251], lr: 0.000418, loss: 0.3924
2022-10-02 16:39:40 - train: epoch 0256, iter [00360, 01251], lr: 0.000418, loss: 0.4120
2022-10-02 16:39:58 - train: epoch 0256, iter [00370, 01251], lr: 0.000418, loss: 0.4221
2022-10-02 16:40:16 - train: epoch 0256, iter [00380, 01251], lr: 0.000418, loss: 0.3997
2022-10-02 16:40:34 - train: epoch 0256, iter [00390, 01251], lr: 0.000418, loss: 0.3849
2022-10-02 16:40:53 - train: epoch 0256, iter [00400, 01251], lr: 0.000418, loss: 0.3997
2022-10-02 16:41:11 - train: epoch 0256, iter [00410, 01251], lr: 0.000418, loss: 0.4013
2022-10-02 16:41:29 - train: epoch 0256, iter [00420, 01251], lr: 0.000418, loss: 0.4009
2022-10-02 16:41:47 - train: epoch 0256, iter [00430, 01251], lr: 0.000418, loss: 0.4005
2022-10-02 16:42:05 - train: epoch 0256, iter [00440, 01251], lr: 0.000418, loss: 0.3940
2022-10-02 16:42:23 - train: epoch 0256, iter [00450, 01251], lr: 0.000418, loss: 0.4172
2022-10-02 16:42:42 - train: epoch 0256, iter [00460, 01251], lr: 0.000418, loss: 0.3965
2022-10-02 16:43:00 - train: epoch 0256, iter [00470, 01251], lr: 0.000418, loss: 0.3797
2022-10-02 16:43:18 - train: epoch 0256, iter [00480, 01251], lr: 0.000418, loss: 0.4061
2022-10-02 16:43:36 - train: epoch 0256, iter [00490, 01251], lr: 0.000418, loss: 0.3940
2022-10-02 16:43:54 - train: epoch 0256, iter [00500, 01251], lr: 0.000418, loss: 0.3856
2022-10-02 16:44:12 - train: epoch 0256, iter [00510, 01251], lr: 0.000418, loss: 0.4007
2022-10-02 16:44:30 - train: epoch 0256, iter [00520, 01251], lr: 0.000418, loss: 0.4088
2022-10-02 16:44:48 - train: epoch 0256, iter [00530, 01251], lr: 0.000417, loss: 0.3798
2022-10-02 16:45:07 - train: epoch 0256, iter [00540, 01251], lr: 0.000417, loss: 0.3941
2022-10-02 16:45:25 - train: epoch 0256, iter [00550, 01251], lr: 0.000417, loss: 0.3838
2022-10-02 16:45:43 - train: epoch 0256, iter [00560, 01251], lr: 0.000417, loss: 0.3947
2022-10-02 16:46:01 - train: epoch 0256, iter [00570, 01251], lr: 0.000417, loss: 0.4048
2022-10-02 16:46:19 - train: epoch 0256, iter [00580, 01251], lr: 0.000417, loss: 0.3893
2022-10-02 16:46:37 - train: epoch 0256, iter [00590, 01251], lr: 0.000417, loss: 0.3959
2022-10-02 16:46:55 - train: epoch 0256, iter [00600, 01251], lr: 0.000417, loss: 0.4006
2022-10-02 16:47:13 - train: epoch 0256, iter [00610, 01251], lr: 0.000417, loss: 0.4147
2022-10-02 16:47:32 - train: epoch 0256, iter [00620, 01251], lr: 0.000417, loss: 0.4116
2022-10-02 16:47:50 - train: epoch 0256, iter [00630, 01251], lr: 0.000417, loss: 0.3933
2022-10-02 16:48:08 - train: epoch 0256, iter [00640, 01251], lr: 0.000417, loss: 0.3981
2022-10-02 16:48:26 - train: epoch 0256, iter [00650, 01251], lr: 0.000417, loss: 0.4003
2022-10-02 16:48:44 - train: epoch 0256, iter [00660, 01251], lr: 0.000417, loss: 0.3947
2022-10-02 16:49:02 - train: epoch 0256, iter [00670, 01251], lr: 0.000417, loss: 0.3818
2022-10-02 16:49:21 - train: epoch 0256, iter [00680, 01251], lr: 0.000417, loss: 0.4090
2022-10-02 16:49:39 - train: epoch 0256, iter [00690, 01251], lr: 0.000417, loss: 0.4091
2022-10-02 16:49:57 - train: epoch 0256, iter [00700, 01251], lr: 0.000417, loss: 0.3988
2022-10-02 16:50:15 - train: epoch 0256, iter [00710, 01251], lr: 0.000417, loss: 0.3920
2022-10-02 16:50:33 - train: epoch 0256, iter [00720, 01251], lr: 0.000417, loss: 0.4049
2022-10-02 16:50:52 - train: epoch 0256, iter [00730, 01251], lr: 0.000417, loss: 0.4084
2022-10-02 16:51:10 - train: epoch 0256, iter [00740, 01251], lr: 0.000417, loss: 0.4085
2022-10-02 16:51:28 - train: epoch 0256, iter [00750, 01251], lr: 0.000417, loss: 0.4072
2022-10-02 16:51:46 - train: epoch 0256, iter [00760, 01251], lr: 0.000417, loss: 0.3835
2022-10-02 16:52:04 - train: epoch 0256, iter [00770, 01251], lr: 0.000417, loss: 0.4035
2022-10-02 16:52:22 - train: epoch 0256, iter [00780, 01251], lr: 0.000416, loss: 0.3983
2022-10-02 16:52:40 - train: epoch 0256, iter [00790, 01251], lr: 0.000416, loss: 0.3903
2022-10-02 16:52:59 - train: epoch 0256, iter [00800, 01251], lr: 0.000416, loss: 0.4122
2022-10-02 16:53:17 - train: epoch 0256, iter [00810, 01251], lr: 0.000416, loss: 0.4085
2022-10-02 16:53:35 - train: epoch 0256, iter [00820, 01251], lr: 0.000416, loss: 0.4187
2022-10-02 16:53:53 - train: epoch 0256, iter [00830, 01251], lr: 0.000416, loss: 0.4124
2022-10-02 16:54:11 - train: epoch 0256, iter [00840, 01251], lr: 0.000416, loss: 0.4177
2022-10-02 16:54:30 - train: epoch 0256, iter [00850, 01251], lr: 0.000416, loss: 0.4087
2022-10-02 16:54:48 - train: epoch 0256, iter [00860, 01251], lr: 0.000416, loss: 0.3948
2022-10-02 16:55:06 - train: epoch 0256, iter [00870, 01251], lr: 0.000416, loss: 0.3926
2022-10-02 16:55:24 - train: epoch 0256, iter [00880, 01251], lr: 0.000416, loss: 0.3827
2022-10-02 16:55:42 - train: epoch 0256, iter [00890, 01251], lr: 0.000416, loss: 0.4121
2022-10-02 16:56:00 - train: epoch 0256, iter [00900, 01251], lr: 0.000416, loss: 0.3919
2022-10-02 16:56:18 - train: epoch 0256, iter [00910, 01251], lr: 0.000416, loss: 0.3911
2022-10-02 16:56:37 - train: epoch 0256, iter [00920, 01251], lr: 0.000416, loss: 0.4046
2022-10-02 16:56:55 - train: epoch 0256, iter [00930, 01251], lr: 0.000416, loss: 0.3988
2022-10-02 16:57:13 - train: epoch 0256, iter [00940, 01251], lr: 0.000416, loss: 0.4029
2022-10-02 16:57:31 - train: epoch 0256, iter [00950, 01251], lr: 0.000416, loss: 0.4141
2022-10-02 16:57:49 - train: epoch 0256, iter [00960, 01251], lr: 0.000416, loss: 0.4042
2022-10-02 16:58:07 - train: epoch 0256, iter [00970, 01251], lr: 0.000416, loss: 0.4065
2022-10-02 16:58:25 - train: epoch 0256, iter [00980, 01251], lr: 0.000416, loss: 0.4117
2022-10-02 16:58:43 - train: epoch 0256, iter [00990, 01251], lr: 0.000416, loss: 0.4116
2022-10-02 16:59:02 - train: epoch 0256, iter [01000, 01251], lr: 0.000416, loss: 0.4126
2022-10-02 16:59:20 - train: epoch 0256, iter [01010, 01251], lr: 0.000416, loss: 0.4099
2022-10-02 16:59:38 - train: epoch 0256, iter [01020, 01251], lr: 0.000416, loss: 0.3938
2022-10-02 16:59:56 - train: epoch 0256, iter [01030, 01251], lr: 0.000415, loss: 0.3863
2022-10-02 17:00:15 - train: epoch 0256, iter [01040, 01251], lr: 0.000415, loss: 0.3862
2022-10-02 17:00:33 - train: epoch 0256, iter [01050, 01251], lr: 0.000415, loss: 0.3865
2022-10-02 17:00:51 - train: epoch 0256, iter [01060, 01251], lr: 0.000415, loss: 0.4099
2022-10-02 17:01:09 - train: epoch 0256, iter [01070, 01251], lr: 0.000415, loss: 0.4131
2022-10-02 17:01:27 - train: epoch 0256, iter [01080, 01251], lr: 0.000415, loss: 0.4048
2022-10-02 17:01:45 - train: epoch 0256, iter [01090, 01251], lr: 0.000415, loss: 0.3774
2022-10-02 17:02:04 - train: epoch 0256, iter [01100, 01251], lr: 0.000415, loss: 0.3867
2022-10-02 17:02:22 - train: epoch 0256, iter [01110, 01251], lr: 0.000415, loss: 0.4032
2022-10-02 17:02:40 - train: epoch 0256, iter [01120, 01251], lr: 0.000415, loss: 0.4108
2022-10-02 17:02:58 - train: epoch 0256, iter [01130, 01251], lr: 0.000415, loss: 0.3976
2022-10-02 17:03:16 - train: epoch 0256, iter [01140, 01251], lr: 0.000415, loss: 0.4050
2022-10-02 17:03:34 - train: epoch 0256, iter [01150, 01251], lr: 0.000415, loss: 0.4105
2022-10-02 17:03:52 - train: epoch 0256, iter [01160, 01251], lr: 0.000415, loss: 0.3852
2022-10-02 17:04:10 - train: epoch 0256, iter [01170, 01251], lr: 0.000415, loss: 0.4093
2022-10-02 17:04:29 - train: epoch 0256, iter [01180, 01251], lr: 0.000415, loss: 0.3983
2022-10-02 17:04:47 - train: epoch 0256, iter [01190, 01251], lr: 0.000415, loss: 0.4039
2022-10-02 17:05:05 - train: epoch 0256, iter [01200, 01251], lr: 0.000415, loss: 0.3838
2022-10-02 17:05:23 - train: epoch 0256, iter [01210, 01251], lr: 0.000415, loss: 0.4032
2022-10-02 17:05:41 - train: epoch 0256, iter [01220, 01251], lr: 0.000415, loss: 0.3921
2022-10-02 17:05:59 - train: epoch 0256, iter [01230, 01251], lr: 0.000415, loss: 0.3967
2022-10-02 17:06:18 - train: epoch 0256, iter [01240, 01251], lr: 0.000415, loss: 0.4059
2022-10-02 17:06:35 - train: epoch 0256, iter [01250, 01251], lr: 0.000415, loss: 0.4042
2022-10-02 17:06:38 - train: epoch 256, train_loss: 0.4022
2022-10-02 17:06:41 - until epoch: 256, best_loss: 0.4022
2022-10-02 17:06:41 - epoch 257 lr: 0.000415
2022-10-02 17:07:06 - train: epoch 0257, iter [00010, 01251], lr: 0.000415, loss: 0.4162
2022-10-02 17:07:24 - train: epoch 0257, iter [00020, 01251], lr: 0.000415, loss: 0.3935
2022-10-02 17:07:42 - train: epoch 0257, iter [00030, 01251], lr: 0.000414, loss: 0.3904
2022-10-02 17:08:00 - train: epoch 0257, iter [00040, 01251], lr: 0.000414, loss: 0.4225
2022-10-02 17:08:18 - train: epoch 0257, iter [00050, 01251], lr: 0.000414, loss: 0.4070
2022-10-02 17:08:36 - train: epoch 0257, iter [00060, 01251], lr: 0.000414, loss: 0.3942
2022-10-02 17:08:54 - train: epoch 0257, iter [00070, 01251], lr: 0.000414, loss: 0.3945
2022-10-02 17:09:13 - train: epoch 0257, iter [00080, 01251], lr: 0.000414, loss: 0.4042
2022-10-02 17:09:30 - train: epoch 0257, iter [00090, 01251], lr: 0.000414, loss: 0.4011
2022-10-02 17:09:49 - train: epoch 0257, iter [00100, 01251], lr: 0.000414, loss: 0.3987
2022-10-02 17:10:07 - train: epoch 0257, iter [00110, 01251], lr: 0.000414, loss: 0.4142
2022-10-02 17:10:25 - train: epoch 0257, iter [00120, 01251], lr: 0.000414, loss: 0.4130
2022-10-02 17:10:43 - train: epoch 0257, iter [00130, 01251], lr: 0.000414, loss: 0.3736
2022-10-02 17:11:01 - train: epoch 0257, iter [00140, 01251], lr: 0.000414, loss: 0.4072
2022-10-02 17:11:19 - train: epoch 0257, iter [00150, 01251], lr: 0.000414, loss: 0.4132
2022-10-02 17:11:37 - train: epoch 0257, iter [00160, 01251], lr: 0.000414, loss: 0.3998
2022-10-02 17:11:55 - train: epoch 0257, iter [00170, 01251], lr: 0.000414, loss: 0.4061
2022-10-02 17:12:13 - train: epoch 0257, iter [00180, 01251], lr: 0.000414, loss: 0.3894
2022-10-02 17:12:31 - train: epoch 0257, iter [00190, 01251], lr: 0.000414, loss: 0.4277
2022-10-02 17:12:49 - train: epoch 0257, iter [00200, 01251], lr: 0.000414, loss: 0.4039
2022-10-02 17:13:07 - train: epoch 0257, iter [00210, 01251], lr: 0.000414, loss: 0.4066
2022-10-02 17:13:25 - train: epoch 0257, iter [00220, 01251], lr: 0.000414, loss: 0.4158
2022-10-02 17:13:43 - train: epoch 0257, iter [00230, 01251], lr: 0.000414, loss: 0.4172
2022-10-02 17:14:01 - train: epoch 0257, iter [00240, 01251], lr: 0.000414, loss: 0.3926
2022-10-02 17:14:20 - train: epoch 0257, iter [00250, 01251], lr: 0.000414, loss: 0.3946
2022-10-02 17:14:38 - train: epoch 0257, iter [00260, 01251], lr: 0.000414, loss: 0.4077
2022-10-02 17:14:56 - train: epoch 0257, iter [00270, 01251], lr: 0.000414, loss: 0.3826
2022-10-02 17:15:14 - train: epoch 0257, iter [00280, 01251], lr: 0.000413, loss: 0.4174
2022-10-02 17:15:32 - train: epoch 0257, iter [00290, 01251], lr: 0.000413, loss: 0.3793
2022-10-02 17:15:50 - train: epoch 0257, iter [00300, 01251], lr: 0.000413, loss: 0.4015
2022-10-02 17:16:08 - train: epoch 0257, iter [00310, 01251], lr: 0.000413, loss: 0.3966
2022-10-02 17:16:27 - train: epoch 0257, iter [00320, 01251], lr: 0.000413, loss: 0.4178
2022-10-02 17:16:45 - train: epoch 0257, iter [00330, 01251], lr: 0.000413, loss: 0.3954
2022-10-02 17:17:03 - train: epoch 0257, iter [00340, 01251], lr: 0.000413, loss: 0.4155
2022-10-02 17:17:21 - train: epoch 0257, iter [00350, 01251], lr: 0.000413, loss: 0.3957
2022-10-02 17:17:39 - train: epoch 0257, iter [00360, 01251], lr: 0.000413, loss: 0.4013
2022-10-02 17:17:57 - train: epoch 0257, iter [00370, 01251], lr: 0.000413, loss: 0.4097
2022-10-02 17:18:15 - train: epoch 0257, iter [00380, 01251], lr: 0.000413, loss: 0.4022
2022-10-02 17:18:34 - train: epoch 0257, iter [00390, 01251], lr: 0.000413, loss: 0.4094
2022-10-02 17:18:52 - train: epoch 0257, iter [00400, 01251], lr: 0.000413, loss: 0.4044
2022-10-02 17:19:10 - train: epoch 0257, iter [00410, 01251], lr: 0.000413, loss: 0.4073
2022-10-02 17:19:28 - train: epoch 0257, iter [00420, 01251], lr: 0.000413, loss: 0.3919
2022-10-02 17:19:46 - train: epoch 0257, iter [00430, 01251], lr: 0.000413, loss: 0.3980
2022-10-02 17:20:04 - train: epoch 0257, iter [00440, 01251], lr: 0.000413, loss: 0.4017
2022-10-02 17:20:23 - train: epoch 0257, iter [00450, 01251], lr: 0.000413, loss: 0.4050
2022-10-02 17:20:41 - train: epoch 0257, iter [00460, 01251], lr: 0.000413, loss: 0.4059
2022-10-02 17:20:59 - train: epoch 0257, iter [00470, 01251], lr: 0.000413, loss: 0.3868
2022-10-02 17:21:17 - train: epoch 0257, iter [00480, 01251], lr: 0.000413, loss: 0.3879
2022-10-02 17:21:35 - train: epoch 0257, iter [00490, 01251], lr: 0.000413, loss: 0.3906
2022-10-02 17:21:53 - train: epoch 0257, iter [00500, 01251], lr: 0.000413, loss: 0.4013
2022-10-02 17:22:12 - train: epoch 0257, iter [00510, 01251], lr: 0.000413, loss: 0.3837
2022-10-02 17:22:30 - train: epoch 0257, iter [00520, 01251], lr: 0.000413, loss: 0.3817
2022-10-02 17:22:48 - train: epoch 0257, iter [00530, 01251], lr: 0.000412, loss: 0.3992
2022-10-02 17:23:06 - train: epoch 0257, iter [00540, 01251], lr: 0.000412, loss: 0.3867
2022-10-02 17:23:24 - train: epoch 0257, iter [00550, 01251], lr: 0.000412, loss: 0.4125
2022-10-02 17:23:42 - train: epoch 0257, iter [00560, 01251], lr: 0.000412, loss: 0.3874
2022-10-02 17:24:00 - train: epoch 0257, iter [00570, 01251], lr: 0.000412, loss: 0.4137
2022-10-02 17:24:18 - train: epoch 0257, iter [00580, 01251], lr: 0.000412, loss: 0.3959
2022-10-02 17:24:37 - train: epoch 0257, iter [00590, 01251], lr: 0.000412, loss: 0.4240
2022-10-02 17:24:55 - train: epoch 0257, iter [00600, 01251], lr: 0.000412, loss: 0.3950
2022-10-02 17:25:13 - train: epoch 0257, iter [00610, 01251], lr: 0.000412, loss: 0.4103
2022-10-02 17:25:31 - train: epoch 0257, iter [00620, 01251], lr: 0.000412, loss: 0.4021
2022-10-02 17:25:49 - train: epoch 0257, iter [00630, 01251], lr: 0.000412, loss: 0.4055
2022-10-02 17:26:08 - train: epoch 0257, iter [00640, 01251], lr: 0.000412, loss: 0.4194
2022-10-02 17:26:26 - train: epoch 0257, iter [00650, 01251], lr: 0.000412, loss: 0.3911
2022-10-02 17:26:44 - train: epoch 0257, iter [00660, 01251], lr: 0.000412, loss: 0.4098
2022-10-02 17:27:02 - train: epoch 0257, iter [00670, 01251], lr: 0.000412, loss: 0.3966
2022-10-02 17:27:20 - train: epoch 0257, iter [00680, 01251], lr: 0.000412, loss: 0.3932
2022-10-02 17:27:38 - train: epoch 0257, iter [00690, 01251], lr: 0.000412, loss: 0.3912
2022-10-02 17:27:56 - train: epoch 0257, iter [00700, 01251], lr: 0.000412, loss: 0.4129
2022-10-02 17:28:14 - train: epoch 0257, iter [00710, 01251], lr: 0.000412, loss: 0.3873
2022-10-02 17:28:32 - train: epoch 0257, iter [00720, 01251], lr: 0.000412, loss: 0.3855
2022-10-02 17:28:51 - train: epoch 0257, iter [00730, 01251], lr: 0.000412, loss: 0.3766
2022-10-02 17:29:09 - train: epoch 0257, iter [00740, 01251], lr: 0.000412, loss: 0.3951
2022-10-02 17:29:27 - train: epoch 0257, iter [00750, 01251], lr: 0.000412, loss: 0.3952
2022-10-02 17:29:45 - train: epoch 0257, iter [00760, 01251], lr: 0.000412, loss: 0.4068
2022-10-02 17:30:03 - train: epoch 0257, iter [00770, 01251], lr: 0.000412, loss: 0.3977
2022-10-02 17:30:21 - train: epoch 0257, iter [00780, 01251], lr: 0.000411, loss: 0.4093
2022-10-02 17:30:39 - train: epoch 0257, iter [00790, 01251], lr: 0.000411, loss: 0.4098
2022-10-02 17:30:57 - train: epoch 0257, iter [00800, 01251], lr: 0.000411, loss: 0.3978
2022-10-02 17:31:15 - train: epoch 0257, iter [00810, 01251], lr: 0.000411, loss: 0.3938
2022-10-02 17:31:33 - train: epoch 0257, iter [00820, 01251], lr: 0.000411, loss: 0.3951
2022-10-02 17:31:51 - train: epoch 0257, iter [00830, 01251], lr: 0.000411, loss: 0.3877
2022-10-02 17:32:09 - train: epoch 0257, iter [00840, 01251], lr: 0.000411, loss: 0.4153
2022-10-02 17:32:28 - train: epoch 0257, iter [00850, 01251], lr: 0.000411, loss: 0.4154
2022-10-02 17:32:46 - train: epoch 0257, iter [00860, 01251], lr: 0.000411, loss: 0.4020
2022-10-02 17:33:04 - train: epoch 0257, iter [00870, 01251], lr: 0.000411, loss: 0.4046
2022-10-02 17:33:22 - train: epoch 0257, iter [00880, 01251], lr: 0.000411, loss: 0.4337
2022-10-02 17:33:40 - train: epoch 0257, iter [00890, 01251], lr: 0.000411, loss: 0.3847
2022-10-02 17:33:58 - train: epoch 0257, iter [00900, 01251], lr: 0.000411, loss: 0.4057
2022-10-02 17:34:16 - train: epoch 0257, iter [00910, 01251], lr: 0.000411, loss: 0.3900
2022-10-02 17:34:35 - train: epoch 0257, iter [00920, 01251], lr: 0.000411, loss: 0.4107
2022-10-02 17:34:53 - train: epoch 0257, iter [00930, 01251], lr: 0.000411, loss: 0.3797
2022-10-02 17:35:11 - train: epoch 0257, iter [00940, 01251], lr: 0.000411, loss: 0.4031
2022-10-02 17:35:29 - train: epoch 0257, iter [00950, 01251], lr: 0.000411, loss: 0.3986
2022-10-02 17:35:47 - train: epoch 0257, iter [00960, 01251], lr: 0.000411, loss: 0.4014
2022-10-02 17:36:06 - train: epoch 0257, iter [00970, 01251], lr: 0.000411, loss: 0.4059
2022-10-02 17:36:24 - train: epoch 0257, iter [00980, 01251], lr: 0.000411, loss: 0.3949
2022-10-02 17:36:42 - train: epoch 0257, iter [00990, 01251], lr: 0.000411, loss: 0.3951
2022-10-02 17:37:00 - train: epoch 0257, iter [01000, 01251], lr: 0.000411, loss: 0.3985
2022-10-02 17:37:18 - train: epoch 0257, iter [01010, 01251], lr: 0.000411, loss: 0.3993
2022-10-02 17:37:36 - train: epoch 0257, iter [01020, 01251], lr: 0.000411, loss: 0.4084
2022-10-02 17:37:55 - train: epoch 0257, iter [01030, 01251], lr: 0.000410, loss: 0.4103
2022-10-02 17:38:13 - train: epoch 0257, iter [01040, 01251], lr: 0.000410, loss: 0.3816
2022-10-02 17:38:31 - train: epoch 0257, iter [01050, 01251], lr: 0.000410, loss: 0.4006
2022-10-02 17:38:49 - train: epoch 0257, iter [01060, 01251], lr: 0.000410, loss: 0.4198
2022-10-02 17:39:07 - train: epoch 0257, iter [01070, 01251], lr: 0.000410, loss: 0.4025
2022-10-02 17:39:25 - train: epoch 0257, iter [01080, 01251], lr: 0.000410, loss: 0.3959
2022-10-02 17:39:43 - train: epoch 0257, iter [01090, 01251], lr: 0.000410, loss: 0.3957
2022-10-02 17:40:02 - train: epoch 0257, iter [01100, 01251], lr: 0.000410, loss: 0.4036
2022-10-02 17:40:20 - train: epoch 0257, iter [01110, 01251], lr: 0.000410, loss: 0.3978
2022-10-02 17:40:38 - train: epoch 0257, iter [01120, 01251], lr: 0.000410, loss: 0.4358
2022-10-02 17:40:56 - train: epoch 0257, iter [01130, 01251], lr: 0.000410, loss: 0.3999
2022-10-02 17:41:14 - train: epoch 0257, iter [01140, 01251], lr: 0.000410, loss: 0.3932
2022-10-02 17:41:32 - train: epoch 0257, iter [01150, 01251], lr: 0.000410, loss: 0.4018
2022-10-02 17:41:51 - train: epoch 0257, iter [01160, 01251], lr: 0.000410, loss: 0.3900
2022-10-02 17:42:09 - train: epoch 0257, iter [01170, 01251], lr: 0.000410, loss: 0.4102
2022-10-02 17:42:27 - train: epoch 0257, iter [01180, 01251], lr: 0.000410, loss: 0.3856
2022-10-02 17:42:45 - train: epoch 0257, iter [01190, 01251], lr: 0.000410, loss: 0.4255
2022-10-02 17:43:04 - train: epoch 0257, iter [01200, 01251], lr: 0.000410, loss: 0.3939
2022-10-02 17:43:21 - train: epoch 0257, iter [01210, 01251], lr: 0.000410, loss: 0.3957
2022-10-02 17:43:40 - train: epoch 0257, iter [01220, 01251], lr: 0.000410, loss: 0.3978
2022-10-02 17:43:58 - train: epoch 0257, iter [01230, 01251], lr: 0.000410, loss: 0.4458
2022-10-02 17:44:16 - train: epoch 0257, iter [01240, 01251], lr: 0.000410, loss: 0.3864
2022-10-02 17:44:33 - train: epoch 0257, iter [01250, 01251], lr: 0.000410, loss: 0.3796
2022-10-02 17:44:37 - train: epoch 257, train_loss: 0.4021
2022-10-02 17:44:40 - until epoch: 257, best_loss: 0.4021
2022-10-02 17:44:40 - epoch 258 lr: 0.000410
2022-10-02 17:45:04 - train: epoch 0258, iter [00010, 01251], lr: 0.000410, loss: 0.3805
2022-10-02 17:45:23 - train: epoch 0258, iter [00020, 01251], lr: 0.000410, loss: 0.3852
2022-10-02 17:45:41 - train: epoch 0258, iter [00030, 01251], lr: 0.000409, loss: 0.3897
2022-10-02 17:45:59 - train: epoch 0258, iter [00040, 01251], lr: 0.000409, loss: 0.3935
2022-10-02 17:46:17 - train: epoch 0258, iter [00050, 01251], lr: 0.000409, loss: 0.3942
2022-10-02 17:46:35 - train: epoch 0258, iter [00060, 01251], lr: 0.000409, loss: 0.4033
2022-10-02 17:46:53 - train: epoch 0258, iter [00070, 01251], lr: 0.000409, loss: 0.4027
2022-10-02 17:47:11 - train: epoch 0258, iter [00080, 01251], lr: 0.000409, loss: 0.4006
2022-10-02 17:47:29 - train: epoch 0258, iter [00090, 01251], lr: 0.000409, loss: 0.4219
2022-10-02 17:47:47 - train: epoch 0258, iter [00100, 01251], lr: 0.000409, loss: 0.3809
2022-10-02 17:48:05 - train: epoch 0258, iter [00110, 01251], lr: 0.000409, loss: 0.4303
2022-10-02 17:48:23 - train: epoch 0258, iter [00120, 01251], lr: 0.000409, loss: 0.3886
2022-10-02 17:48:41 - train: epoch 0258, iter [00130, 01251], lr: 0.000409, loss: 0.4057
2022-10-02 17:48:59 - train: epoch 0258, iter [00140, 01251], lr: 0.000409, loss: 0.4157
2022-10-02 17:49:18 - train: epoch 0258, iter [00150, 01251], lr: 0.000409, loss: 0.4089
2022-10-02 17:49:36 - train: epoch 0258, iter [00160, 01251], lr: 0.000409, loss: 0.3975
2022-10-02 17:49:54 - train: epoch 0258, iter [00170, 01251], lr: 0.000409, loss: 0.3950
2022-10-02 17:50:12 - train: epoch 0258, iter [00180, 01251], lr: 0.000409, loss: 0.3917
2022-10-02 17:50:30 - train: epoch 0258, iter [00190, 01251], lr: 0.000409, loss: 0.4032
2022-10-02 17:50:48 - train: epoch 0258, iter [00200, 01251], lr: 0.000409, loss: 0.3941
2022-10-02 17:51:06 - train: epoch 0258, iter [00210, 01251], lr: 0.000409, loss: 0.4071
2022-10-02 17:51:25 - train: epoch 0258, iter [00220, 01251], lr: 0.000409, loss: 0.4089
2022-10-02 17:51:43 - train: epoch 0258, iter [00230, 01251], lr: 0.000409, loss: 0.4009
2022-10-02 17:52:01 - train: epoch 0258, iter [00240, 01251], lr: 0.000409, loss: 0.4172
2022-10-02 17:52:19 - train: epoch 0258, iter [00250, 01251], lr: 0.000409, loss: 0.4040
2022-10-02 17:52:38 - train: epoch 0258, iter [00260, 01251], lr: 0.000409, loss: 0.4040
2022-10-02 17:52:56 - train: epoch 0258, iter [00270, 01251], lr: 0.000409, loss: 0.3859
2022-10-02 17:53:14 - train: epoch 0258, iter [00280, 01251], lr: 0.000409, loss: 0.4178
2022-10-02 17:53:32 - train: epoch 0258, iter [00290, 01251], lr: 0.000408, loss: 0.4080
2022-10-02 17:53:50 - train: epoch 0258, iter [00300, 01251], lr: 0.000408, loss: 0.3906
2022-10-02 17:54:08 - train: epoch 0258, iter [00310, 01251], lr: 0.000408, loss: 0.4175
2022-10-02 17:54:26 - train: epoch 0258, iter [00320, 01251], lr: 0.000408, loss: 0.4046
2022-10-02 17:54:45 - train: epoch 0258, iter [00330, 01251], lr: 0.000408, loss: 0.4021
2022-10-02 17:55:03 - train: epoch 0258, iter [00340, 01251], lr: 0.000408, loss: 0.3995
2022-10-02 17:55:21 - train: epoch 0258, iter [00350, 01251], lr: 0.000408, loss: 0.4034
2022-10-02 17:55:39 - train: epoch 0258, iter [00360, 01251], lr: 0.000408, loss: 0.4285
2022-10-02 17:55:57 - train: epoch 0258, iter [00370, 01251], lr: 0.000408, loss: 0.4174
2022-10-02 17:56:15 - train: epoch 0258, iter [00380, 01251], lr: 0.000408, loss: 0.4084
2022-10-02 17:56:33 - train: epoch 0258, iter [00390, 01251], lr: 0.000408, loss: 0.3917
2022-10-02 17:56:52 - train: epoch 0258, iter [00400, 01251], lr: 0.000408, loss: 0.3836
2022-10-02 17:57:10 - train: epoch 0258, iter [00410, 01251], lr: 0.000408, loss: 0.4040
2022-10-02 17:57:28 - train: epoch 0258, iter [00420, 01251], lr: 0.000408, loss: 0.4051
2022-10-02 17:57:46 - train: epoch 0258, iter [00430, 01251], lr: 0.000408, loss: 0.4287
2022-10-02 17:58:04 - train: epoch 0258, iter [00440, 01251], lr: 0.000408, loss: 0.3765
2022-10-02 17:58:22 - train: epoch 0258, iter [00450, 01251], lr: 0.000408, loss: 0.4133
2022-10-02 17:58:40 - train: epoch 0258, iter [00460, 01251], lr: 0.000408, loss: 0.4112
2022-10-02 17:58:58 - train: epoch 0258, iter [00470, 01251], lr: 0.000408, loss: 0.4017
2022-10-02 17:59:16 - train: epoch 0258, iter [00480, 01251], lr: 0.000408, loss: 0.4056
2022-10-02 17:59:34 - train: epoch 0258, iter [00490, 01251], lr: 0.000408, loss: 0.4066
2022-10-02 17:59:52 - train: epoch 0258, iter [00500, 01251], lr: 0.000408, loss: 0.4093
2022-10-02 18:00:10 - train: epoch 0258, iter [00510, 01251], lr: 0.000408, loss: 0.3924
2022-10-02 18:00:29 - train: epoch 0258, iter [00520, 01251], lr: 0.000408, loss: 0.3998
2022-10-02 18:00:47 - train: epoch 0258, iter [00530, 01251], lr: 0.000408, loss: 0.4041
2022-10-02 18:01:05 - train: epoch 0258, iter [00540, 01251], lr: 0.000407, loss: 0.3880
2022-10-02 18:01:23 - train: epoch 0258, iter [00550, 01251], lr: 0.000407, loss: 0.4090
2022-10-02 18:01:41 - train: epoch 0258, iter [00560, 01251], lr: 0.000407, loss: 0.3892
2022-10-02 18:01:59 - train: epoch 0258, iter [00570, 01251], lr: 0.000407, loss: 0.4143
2022-10-02 18:02:17 - train: epoch 0258, iter [00580, 01251], lr: 0.000407, loss: 0.4043
2022-10-02 18:02:35 - train: epoch 0258, iter [00590, 01251], lr: 0.000407, loss: 0.4123
2022-10-02 18:02:54 - train: epoch 0258, iter [00600, 01251], lr: 0.000407, loss: 0.3978
2022-10-02 18:03:12 - train: epoch 0258, iter [00610, 01251], lr: 0.000407, loss: 0.3921
2022-10-02 18:03:30 - train: epoch 0258, iter [00620, 01251], lr: 0.000407, loss: 0.3986
2022-10-02 18:03:48 - train: epoch 0258, iter [00630, 01251], lr: 0.000407, loss: 0.4078
2022-10-02 18:04:06 - train: epoch 0258, iter [00640, 01251], lr: 0.000407, loss: 0.3991
2022-10-02 18:04:24 - train: epoch 0258, iter [00650, 01251], lr: 0.000407, loss: 0.4032
2022-10-02 18:04:42 - train: epoch 0258, iter [00660, 01251], lr: 0.000407, loss: 0.4022
2022-10-02 18:05:01 - train: epoch 0258, iter [00670, 01251], lr: 0.000407, loss: 0.4086
2022-10-02 18:05:19 - train: epoch 0258, iter [00680, 01251], lr: 0.000407, loss: 0.3983
2022-10-02 18:05:37 - train: epoch 0258, iter [00690, 01251], lr: 0.000407, loss: 0.3858
2022-10-02 18:05:55 - train: epoch 0258, iter [00700, 01251], lr: 0.000407, loss: 0.4023
2022-10-02 18:06:13 - train: epoch 0258, iter [00710, 01251], lr: 0.000407, loss: 0.3977
2022-10-02 18:06:32 - train: epoch 0258, iter [00720, 01251], lr: 0.000407, loss: 0.3789
2022-10-02 18:06:50 - train: epoch 0258, iter [00730, 01251], lr: 0.000407, loss: 0.4030
2022-10-02 18:07:08 - train: epoch 0258, iter [00740, 01251], lr: 0.000407, loss: 0.4188
2022-10-02 18:07:26 - train: epoch 0258, iter [00750, 01251], lr: 0.000407, loss: 0.4083
2022-10-02 18:07:44 - train: epoch 0258, iter [00760, 01251], lr: 0.000407, loss: 0.3989
2022-10-02 18:08:02 - train: epoch 0258, iter [00770, 01251], lr: 0.000407, loss: 0.3950
2022-10-02 18:08:20 - train: epoch 0258, iter [00780, 01251], lr: 0.000407, loss: 0.4092
2022-10-02 18:08:39 - train: epoch 0258, iter [00790, 01251], lr: 0.000406, loss: 0.4110
2022-10-02 18:08:57 - train: epoch 0258, iter [00800, 01251], lr: 0.000406, loss: 0.4221
2022-10-02 18:09:15 - train: epoch 0258, iter [00810, 01251], lr: 0.000406, loss: 0.4056
2022-10-02 18:09:33 - train: epoch 0258, iter [00820, 01251], lr: 0.000406, loss: 0.3874
2022-10-02 18:09:51 - train: epoch 0258, iter [00830, 01251], lr: 0.000406, loss: 0.4137
2022-10-02 18:10:09 - train: epoch 0258, iter [00840, 01251], lr: 0.000406, loss: 0.3934
2022-10-02 18:10:27 - train: epoch 0258, iter [00850, 01251], lr: 0.000406, loss: 0.4133
2022-10-02 18:10:45 - train: epoch 0258, iter [00860, 01251], lr: 0.000406, loss: 0.3915
2022-10-02 18:11:03 - train: epoch 0258, iter [00870, 01251], lr: 0.000406, loss: 0.3945
2022-10-02 18:11:21 - train: epoch 0258, iter [00880, 01251], lr: 0.000406, loss: 0.3896
2022-10-02 18:11:40 - train: epoch 0258, iter [00890, 01251], lr: 0.000406, loss: 0.3905
2022-10-02 18:11:58 - train: epoch 0258, iter [00900, 01251], lr: 0.000406, loss: 0.4239
2022-10-02 18:12:16 - train: epoch 0258, iter [00910, 01251], lr: 0.000406, loss: 0.3836
2022-10-02 18:12:34 - train: epoch 0258, iter [00920, 01251], lr: 0.000406, loss: 0.4136
2022-10-02 18:12:52 - train: epoch 0258, iter [00930, 01251], lr: 0.000406, loss: 0.4031
2022-10-02 18:13:10 - train: epoch 0258, iter [00940, 01251], lr: 0.000406, loss: 0.4025
2022-10-02 18:13:28 - train: epoch 0258, iter [00950, 01251], lr: 0.000406, loss: 0.3911
2022-10-02 18:13:46 - train: epoch 0258, iter [00960, 01251], lr: 0.000406, loss: 0.4013
2022-10-02 18:14:05 - train: epoch 0258, iter [00970, 01251], lr: 0.000406, loss: 0.3912
2022-10-02 18:14:23 - train: epoch 0258, iter [00980, 01251], lr: 0.000406, loss: 0.4023
2022-10-02 18:14:41 - train: epoch 0258, iter [00990, 01251], lr: 0.000406, loss: 0.4128
2022-10-02 18:14:59 - train: epoch 0258, iter [01000, 01251], lr: 0.000406, loss: 0.3867
2022-10-02 18:15:17 - train: epoch 0258, iter [01010, 01251], lr: 0.000406, loss: 0.3879
2022-10-02 18:15:36 - train: epoch 0258, iter [01020, 01251], lr: 0.000406, loss: 0.4073
2022-10-02 18:15:54 - train: epoch 0258, iter [01030, 01251], lr: 0.000406, loss: 0.4188
2022-10-02 18:16:12 - train: epoch 0258, iter [01040, 01251], lr: 0.000405, loss: 0.3996
2022-10-02 18:16:30 - train: epoch 0258, iter [01050, 01251], lr: 0.000405, loss: 0.4121
2022-10-02 18:16:48 - train: epoch 0258, iter [01060, 01251], lr: 0.000405, loss: 0.4177
2022-10-02 18:17:07 - train: epoch 0258, iter [01070, 01251], lr: 0.000405, loss: 0.3821
2022-10-02 18:17:25 - train: epoch 0258, iter [01080, 01251], lr: 0.000405, loss: 0.4055
2022-10-02 18:17:43 - train: epoch 0258, iter [01090, 01251], lr: 0.000405, loss: 0.4184
2022-10-02 18:18:01 - train: epoch 0258, iter [01100, 01251], lr: 0.000405, loss: 0.4006
2022-10-02 18:18:19 - train: epoch 0258, iter [01110, 01251], lr: 0.000405, loss: 0.4235
2022-10-02 18:18:37 - train: epoch 0258, iter [01120, 01251], lr: 0.000405, loss: 0.4061
2022-10-02 18:18:55 - train: epoch 0258, iter [01130, 01251], lr: 0.000405, loss: 0.3996
2022-10-02 18:19:13 - train: epoch 0258, iter [01140, 01251], lr: 0.000405, loss: 0.3803
2022-10-02 18:19:31 - train: epoch 0258, iter [01150, 01251], lr: 0.000405, loss: 0.4114
2022-10-02 18:19:49 - train: epoch 0258, iter [01160, 01251], lr: 0.000405, loss: 0.4150
2022-10-02 18:20:07 - train: epoch 0258, iter [01170, 01251], lr: 0.000405, loss: 0.4075
2022-10-02 18:20:25 - train: epoch 0258, iter [01180, 01251], lr: 0.000405, loss: 0.3802
2022-10-02 18:20:44 - train: epoch 0258, iter [01190, 01251], lr: 0.000405, loss: 0.4219
2022-10-02 18:21:02 - train: epoch 0258, iter [01200, 01251], lr: 0.000405, loss: 0.4104
2022-10-02 18:21:20 - train: epoch 0258, iter [01210, 01251], lr: 0.000405, loss: 0.4053
2022-10-02 18:21:38 - train: epoch 0258, iter [01220, 01251], lr: 0.000405, loss: 0.4023
2022-10-02 18:21:56 - train: epoch 0258, iter [01230, 01251], lr: 0.000405, loss: 0.4056
2022-10-02 18:22:14 - train: epoch 0258, iter [01240, 01251], lr: 0.000405, loss: 0.4050
2022-10-02 18:22:32 - train: epoch 0258, iter [01250, 01251], lr: 0.000405, loss: 0.4172
2022-10-02 18:22:35 - train: epoch 258, train_loss: 0.4020
2022-10-02 18:22:38 - until epoch: 258, best_loss: 0.4020
2022-10-02 18:22:38 - epoch 259 lr: 0.000405
2022-10-02 18:23:03 - train: epoch 0259, iter [00010, 01251], lr: 0.000405, loss: 0.4115
2022-10-02 18:23:21 - train: epoch 0259, iter [00020, 01251], lr: 0.000405, loss: 0.4166
2022-10-02 18:23:39 - train: epoch 0259, iter [00030, 01251], lr: 0.000405, loss: 0.4004
2022-10-02 18:23:57 - train: epoch 0259, iter [00040, 01251], lr: 0.000405, loss: 0.4066
2022-10-02 18:24:15 - train: epoch 0259, iter [00050, 01251], lr: 0.000404, loss: 0.4085
2022-10-02 18:24:33 - train: epoch 0259, iter [00060, 01251], lr: 0.000404, loss: 0.3860
2022-10-02 18:24:51 - train: epoch 0259, iter [00070, 01251], lr: 0.000404, loss: 0.4266
2022-10-02 18:25:09 - train: epoch 0259, iter [00080, 01251], lr: 0.000404, loss: 0.3898
2022-10-02 18:25:27 - train: epoch 0259, iter [00090, 01251], lr: 0.000404, loss: 0.4148
2022-10-02 18:25:45 - train: epoch 0259, iter [00100, 01251], lr: 0.000404, loss: 0.4083
2022-10-02 18:26:04 - train: epoch 0259, iter [00110, 01251], lr: 0.000404, loss: 0.3993
2022-10-02 18:26:22 - train: epoch 0259, iter [00120, 01251], lr: 0.000404, loss: 0.3968
2022-10-02 18:26:40 - train: epoch 0259, iter [00130, 01251], lr: 0.000404, loss: 0.4127
2022-10-02 18:26:58 - train: epoch 0259, iter [00140, 01251], lr: 0.000404, loss: 0.4174
2022-10-02 18:27:16 - train: epoch 0259, iter [00150, 01251], lr: 0.000404, loss: 0.3927
2022-10-02 18:27:34 - train: epoch 0259, iter [00160, 01251], lr: 0.000404, loss: 0.3896
2022-10-02 18:27:52 - train: epoch 0259, iter [00170, 01251], lr: 0.000404, loss: 0.4123
2022-10-02 18:28:11 - train: epoch 0259, iter [00180, 01251], lr: 0.000404, loss: 0.3958
2022-10-02 18:28:29 - train: epoch 0259, iter [00190, 01251], lr: 0.000404, loss: 0.3991
2022-10-02 18:28:47 - train: epoch 0259, iter [00200, 01251], lr: 0.000404, loss: 0.3852
2022-10-02 18:29:05 - train: epoch 0259, iter [00210, 01251], lr: 0.000404, loss: 0.4067
2022-10-02 18:29:23 - train: epoch 0259, iter [00220, 01251], lr: 0.000404, loss: 0.4157
2022-10-02 18:29:41 - train: epoch 0259, iter [00230, 01251], lr: 0.000404, loss: 0.4037
2022-10-02 18:29:59 - train: epoch 0259, iter [00240, 01251], lr: 0.000404, loss: 0.4170
2022-10-02 18:30:18 - train: epoch 0259, iter [00250, 01251], lr: 0.000404, loss: 0.4175
2022-10-02 18:30:36 - train: epoch 0259, iter [00260, 01251], lr: 0.000404, loss: 0.3874
2022-10-02 18:30:54 - train: epoch 0259, iter [00270, 01251], lr: 0.000404, loss: 0.4101
2022-10-02 18:31:12 - train: epoch 0259, iter [00280, 01251], lr: 0.000404, loss: 0.4005
2022-10-02 18:31:30 - train: epoch 0259, iter [00290, 01251], lr: 0.000404, loss: 0.4014
2022-10-02 18:31:48 - train: epoch 0259, iter [00300, 01251], lr: 0.000403, loss: 0.3857
2022-10-02 18:32:06 - train: epoch 0259, iter [00310, 01251], lr: 0.000403, loss: 0.4264
2022-10-02 18:32:24 - train: epoch 0259, iter [00320, 01251], lr: 0.000403, loss: 0.3975
2022-10-02 18:32:42 - train: epoch 0259, iter [00330, 01251], lr: 0.000403, loss: 0.4142
2022-10-02 18:33:00 - train: epoch 0259, iter [00340, 01251], lr: 0.000403, loss: 0.4070
2022-10-02 18:33:18 - train: epoch 0259, iter [00350, 01251], lr: 0.000403, loss: 0.3759
2022-10-02 18:33:36 - train: epoch 0259, iter [00360, 01251], lr: 0.000403, loss: 0.3995
2022-10-02 18:33:55 - train: epoch 0259, iter [00370, 01251], lr: 0.000403, loss: 0.3971
2022-10-02 18:34:13 - train: epoch 0259, iter [00380, 01251], lr: 0.000403, loss: 0.4048
2022-10-02 18:34:31 - train: epoch 0259, iter [00390, 01251], lr: 0.000403, loss: 0.4096
2022-10-02 18:34:49 - train: epoch 0259, iter [00400, 01251], lr: 0.000403, loss: 0.4243
2022-10-02 18:35:07 - train: epoch 0259, iter [00410, 01251], lr: 0.000403, loss: 0.3832
2022-10-02 18:35:25 - train: epoch 0259, iter [00420, 01251], lr: 0.000403, loss: 0.4006
2022-10-02 18:35:43 - train: epoch 0259, iter [00430, 01251], lr: 0.000403, loss: 0.4014
2022-10-02 18:36:02 - train: epoch 0259, iter [00440, 01251], lr: 0.000403, loss: 0.4014
2022-10-02 18:36:20 - train: epoch 0259, iter [00450, 01251], lr: 0.000403, loss: 0.3999
2022-10-02 18:36:38 - train: epoch 0259, iter [00460, 01251], lr: 0.000403, loss: 0.4051
2022-10-02 18:36:56 - train: epoch 0259, iter [00470, 01251], lr: 0.000403, loss: 0.4216
2022-10-02 18:37:14 - train: epoch 0259, iter [00480, 01251], lr: 0.000403, loss: 0.4042
2022-10-02 18:37:32 - train: epoch 0259, iter [00490, 01251], lr: 0.000403, loss: 0.4145
2022-10-02 18:37:50 - train: epoch 0259, iter [00500, 01251], lr: 0.000403, loss: 0.3994
2022-10-02 18:38:09 - train: epoch 0259, iter [00510, 01251], lr: 0.000403, loss: 0.3967
2022-10-02 18:38:27 - train: epoch 0259, iter [00520, 01251], lr: 0.000403, loss: 0.4000
2022-10-02 18:38:45 - train: epoch 0259, iter [00530, 01251], lr: 0.000403, loss: 0.4053
2022-10-02 18:39:03 - train: epoch 0259, iter [00540, 01251], lr: 0.000403, loss: 0.4037
2022-10-02 18:39:21 - train: epoch 0259, iter [00550, 01251], lr: 0.000402, loss: 0.4006
2022-10-02 18:39:39 - train: epoch 0259, iter [00560, 01251], lr: 0.000402, loss: 0.3813
2022-10-02 18:39:57 - train: epoch 0259, iter [00570, 01251], lr: 0.000402, loss: 0.4138
2022-10-02 18:40:15 - train: epoch 0259, iter [00580, 01251], lr: 0.000402, loss: 0.3956
2022-10-02 18:40:33 - train: epoch 0259, iter [00590, 01251], lr: 0.000402, loss: 0.4150
2022-10-02 18:40:52 - train: epoch 0259, iter [00600, 01251], lr: 0.000402, loss: 0.4143
2022-10-02 18:41:10 - train: epoch 0259, iter [00610, 01251], lr: 0.000402, loss: 0.3984
2022-10-02 18:41:28 - train: epoch 0259, iter [00620, 01251], lr: 0.000402, loss: 0.4111
2022-10-02 18:41:46 - train: epoch 0259, iter [00630, 01251], lr: 0.000402, loss: 0.3894
2022-10-02 18:42:05 - train: epoch 0259, iter [00640, 01251], lr: 0.000402, loss: 0.4007
2022-10-02 18:42:23 - train: epoch 0259, iter [00650, 01251], lr: 0.000402, loss: 0.3927
2022-10-02 18:42:41 - train: epoch 0259, iter [00660, 01251], lr: 0.000402, loss: 0.4092
2022-10-02 18:42:59 - train: epoch 0259, iter [00670, 01251], lr: 0.000402, loss: 0.4008
2022-10-02 18:43:17 - train: epoch 0259, iter [00680, 01251], lr: 0.000402, loss: 0.4065
2022-10-02 18:43:36 - train: epoch 0259, iter [00690, 01251], lr: 0.000402, loss: 0.3920
2022-10-02 18:43:54 - train: epoch 0259, iter [00700, 01251], lr: 0.000402, loss: 0.3938
2022-10-02 18:44:12 - train: epoch 0259, iter [00710, 01251], lr: 0.000402, loss: 0.4118
2022-10-02 18:44:30 - train: epoch 0259, iter [00720, 01251], lr: 0.000402, loss: 0.3865
2022-10-02 18:44:48 - train: epoch 0259, iter [00730, 01251], lr: 0.000402, loss: 0.4089
2022-10-02 18:45:06 - train: epoch 0259, iter [00740, 01251], lr: 0.000402, loss: 0.4092
2022-10-02 18:45:24 - train: epoch 0259, iter [00750, 01251], lr: 0.000402, loss: 0.4027
2022-10-02 18:45:42 - train: epoch 0259, iter [00760, 01251], lr: 0.000402, loss: 0.3874
2022-10-02 18:46:00 - train: epoch 0259, iter [00770, 01251], lr: 0.000402, loss: 0.3931
2022-10-02 18:46:19 - train: epoch 0259, iter [00780, 01251], lr: 0.000402, loss: 0.4131
2022-10-02 18:46:37 - train: epoch 0259, iter [00790, 01251], lr: 0.000402, loss: 0.4246
2022-10-02 18:46:55 - train: epoch 0259, iter [00800, 01251], lr: 0.000401, loss: 0.4105
2022-10-02 18:47:13 - train: epoch 0259, iter [00810, 01251], lr: 0.000401, loss: 0.3920
2022-10-02 18:47:31 - train: epoch 0259, iter [00820, 01251], lr: 0.000401, loss: 0.3910
2022-10-02 18:47:49 - train: epoch 0259, iter [00830, 01251], lr: 0.000401, loss: 0.4076
2022-10-02 18:48:07 - train: epoch 0259, iter [00840, 01251], lr: 0.000401, loss: 0.4025
2022-10-02 18:48:26 - train: epoch 0259, iter [00850, 01251], lr: 0.000401, loss: 0.4078
2022-10-02 18:48:44 - train: epoch 0259, iter [00860, 01251], lr: 0.000401, loss: 0.4026
2022-10-02 18:49:02 - train: epoch 0259, iter [00870, 01251], lr: 0.000401, loss: 0.4095
2022-10-02 18:49:20 - train: epoch 0259, iter [00880, 01251], lr: 0.000401, loss: 0.3963
2022-10-02 18:49:38 - train: epoch 0259, iter [00890, 01251], lr: 0.000401, loss: 0.3800
2022-10-02 18:49:57 - train: epoch 0259, iter [00900, 01251], lr: 0.000401, loss: 0.4075
2022-10-02 18:50:15 - train: epoch 0259, iter [00910, 01251], lr: 0.000401, loss: 0.3912
2022-10-02 18:50:33 - train: epoch 0259, iter [00920, 01251], lr: 0.000401, loss: 0.4113
2022-10-02 18:50:51 - train: epoch 0259, iter [00930, 01251], lr: 0.000401, loss: 0.4001
2022-10-02 18:51:09 - train: epoch 0259, iter [00940, 01251], lr: 0.000401, loss: 0.3857
2022-10-02 18:51:27 - train: epoch 0259, iter [00950, 01251], lr: 0.000401, loss: 0.4212
2022-10-02 18:51:46 - train: epoch 0259, iter [00960, 01251], lr: 0.000401, loss: 0.4060
2022-10-02 18:52:04 - train: epoch 0259, iter [00970, 01251], lr: 0.000401, loss: 0.3926
2022-10-02 18:52:22 - train: epoch 0259, iter [00980, 01251], lr: 0.000401, loss: 0.4060
2022-10-02 18:52:40 - train: epoch 0259, iter [00990, 01251], lr: 0.000401, loss: 0.4029
2022-10-02 18:52:58 - train: epoch 0259, iter [01000, 01251], lr: 0.000401, loss: 0.4000
2022-10-02 18:53:17 - train: epoch 0259, iter [01010, 01251], lr: 0.000401, loss: 0.4122
2022-10-02 18:53:35 - train: epoch 0259, iter [01020, 01251], lr: 0.000401, loss: 0.4104
2022-10-02 18:53:53 - train: epoch 0259, iter [01030, 01251], lr: 0.000401, loss: 0.4070
2022-10-02 18:54:11 - train: epoch 0259, iter [01040, 01251], lr: 0.000401, loss: 0.3997
2022-10-02 18:54:29 - train: epoch 0259, iter [01050, 01251], lr: 0.000401, loss: 0.4070
2022-10-02 18:54:48 - train: epoch 0259, iter [01060, 01251], lr: 0.000400, loss: 0.3935
2022-10-02 18:55:06 - train: epoch 0259, iter [01070, 01251], lr: 0.000400, loss: 0.4167
2022-10-02 18:55:24 - train: epoch 0259, iter [01080, 01251], lr: 0.000400, loss: 0.4043
2022-10-02 18:55:42 - train: epoch 0259, iter [01090, 01251], lr: 0.000400, loss: 0.4170
2022-10-02 18:56:00 - train: epoch 0259, iter [01100, 01251], lr: 0.000400, loss: 0.3910
2022-10-02 18:56:18 - train: epoch 0259, iter [01110, 01251], lr: 0.000400, loss: 0.3955
2022-10-02 18:56:36 - train: epoch 0259, iter [01120, 01251], lr: 0.000400, loss: 0.4258
2022-10-02 18:56:54 - train: epoch 0259, iter [01130, 01251], lr: 0.000400, loss: 0.4029
2022-10-02 18:57:12 - train: epoch 0259, iter [01140, 01251], lr: 0.000400, loss: 0.3955
2022-10-02 18:57:31 - train: epoch 0259, iter [01150, 01251], lr: 0.000400, loss: 0.4038
2022-10-02 18:57:49 - train: epoch 0259, iter [01160, 01251], lr: 0.000400, loss: 0.3762
2022-10-02 18:58:07 - train: epoch 0259, iter [01170, 01251], lr: 0.000400, loss: 0.4166
2022-10-02 18:58:25 - train: epoch 0259, iter [01180, 01251], lr: 0.000400, loss: 0.4062
2022-10-02 18:58:43 - train: epoch 0259, iter [01190, 01251], lr: 0.000400, loss: 0.3780
2022-10-02 18:59:01 - train: epoch 0259, iter [01200, 01251], lr: 0.000400, loss: 0.4099
2022-10-02 18:59:20 - train: epoch 0259, iter [01210, 01251], lr: 0.000400, loss: 0.4108
2022-10-02 18:59:38 - train: epoch 0259, iter [01220, 01251], lr: 0.000400, loss: 0.3993
2022-10-02 18:59:56 - train: epoch 0259, iter [01230, 01251], lr: 0.000400, loss: 0.4022
2022-10-02 19:00:14 - train: epoch 0259, iter [01240, 01251], lr: 0.000400, loss: 0.3811
2022-10-02 19:00:32 - train: epoch 0259, iter [01250, 01251], lr: 0.000400, loss: 0.3890
2022-10-02 19:00:35 - train: epoch 259, train_loss: 0.4020
2022-10-02 19:00:38 - until epoch: 259, best_loss: 0.4020
2022-10-02 19:00:38 - epoch 260 lr: 0.000400
2022-10-02 19:01:02 - train: epoch 0260, iter [00010, 01251], lr: 0.000400, loss: 0.3974
2022-10-02 19:01:20 - train: epoch 0260, iter [00020, 01251], lr: 0.000400, loss: 0.4043
2022-10-02 19:01:39 - train: epoch 0260, iter [00030, 01251], lr: 0.000400, loss: 0.4147
2022-10-02 19:01:57 - train: epoch 0260, iter [00040, 01251], lr: 0.000400, loss: 0.4075
2022-10-02 19:02:15 - train: epoch 0260, iter [00050, 01251], lr: 0.000400, loss: 0.3986
2022-10-02 19:02:33 - train: epoch 0260, iter [00060, 01251], lr: 0.000399, loss: 0.3906
2022-10-02 19:02:52 - train: epoch 0260, iter [00070, 01251], lr: 0.000399, loss: 0.4091
2022-10-02 19:03:10 - train: epoch 0260, iter [00080, 01251], lr: 0.000399, loss: 0.3855
2022-10-02 19:03:28 - train: epoch 0260, iter [00090, 01251], lr: 0.000399, loss: 0.4021
2022-10-02 19:03:46 - train: epoch 0260, iter [00100, 01251], lr: 0.000399, loss: 0.4123
2022-10-02 19:04:04 - train: epoch 0260, iter [00110, 01251], lr: 0.000399, loss: 0.4097
2022-10-02 19:04:22 - train: epoch 0260, iter [00120, 01251], lr: 0.000399, loss: 0.3965
2022-10-02 19:04:40 - train: epoch 0260, iter [00130, 01251], lr: 0.000399, loss: 0.3948
2022-10-02 19:04:58 - train: epoch 0260, iter [00140, 01251], lr: 0.000399, loss: 0.4073
2022-10-02 19:05:17 - train: epoch 0260, iter [00150, 01251], lr: 0.000399, loss: 0.4074
2022-10-02 19:05:35 - train: epoch 0260, iter [00160, 01251], lr: 0.000399, loss: 0.4083
2022-10-02 19:05:53 - train: epoch 0260, iter [00170, 01251], lr: 0.000399, loss: 0.3972
2022-10-02 19:06:11 - train: epoch 0260, iter [00180, 01251], lr: 0.000399, loss: 0.4208
2022-10-02 19:06:29 - train: epoch 0260, iter [00190, 01251], lr: 0.000399, loss: 0.3988
2022-10-02 19:06:47 - train: epoch 0260, iter [00200, 01251], lr: 0.000399, loss: 0.3832
2022-10-02 19:07:05 - train: epoch 0260, iter [00210, 01251], lr: 0.000399, loss: 0.3848
2022-10-02 19:07:23 - train: epoch 0260, iter [00220, 01251], lr: 0.000399, loss: 0.3958
2022-10-02 19:07:41 - train: epoch 0260, iter [00230, 01251], lr: 0.000399, loss: 0.4055
2022-10-02 19:07:59 - train: epoch 0260, iter [00240, 01251], lr: 0.000399, loss: 0.4067
2022-10-02 19:08:18 - train: epoch 0260, iter [00250, 01251], lr: 0.000399, loss: 0.4202
2022-10-02 19:08:36 - train: epoch 0260, iter [00260, 01251], lr: 0.000399, loss: 0.3992
2022-10-02 19:08:54 - train: epoch 0260, iter [00270, 01251], lr: 0.000399, loss: 0.4129
2022-10-02 19:09:12 - train: epoch 0260, iter [00280, 01251], lr: 0.000399, loss: 0.4198
2022-10-02 19:09:30 - train: epoch 0260, iter [00290, 01251], lr: 0.000399, loss: 0.4067
2022-10-02 19:09:48 - train: epoch 0260, iter [00300, 01251], lr: 0.000399, loss: 0.3938
2022-10-02 19:10:06 - train: epoch 0260, iter [00310, 01251], lr: 0.000398, loss: 0.4119
2022-10-02 19:10:24 - train: epoch 0260, iter [00320, 01251], lr: 0.000398, loss: 0.4073
2022-10-02 19:10:42 - train: epoch 0260, iter [00330, 01251], lr: 0.000398, loss: 0.4010
2022-10-02 19:11:00 - train: epoch 0260, iter [00340, 01251], lr: 0.000398, loss: 0.4127
2022-10-02 19:11:19 - train: epoch 0260, iter [00350, 01251], lr: 0.000398, loss: 0.4075
2022-10-02 19:11:37 - train: epoch 0260, iter [00360, 01251], lr: 0.000398, loss: 0.4123
2022-10-02 19:11:55 - train: epoch 0260, iter [00370, 01251], lr: 0.000398, loss: 0.3850
2022-10-02 19:12:13 - train: epoch 0260, iter [00380, 01251], lr: 0.000398, loss: 0.4189
2022-10-02 19:12:31 - train: epoch 0260, iter [00390, 01251], lr: 0.000398, loss: 0.3852
2022-10-02 19:12:49 - train: epoch 0260, iter [00400, 01251], lr: 0.000398, loss: 0.4176
2022-10-02 19:13:07 - train: epoch 0260, iter [00410, 01251], lr: 0.000398, loss: 0.4096
2022-10-02 19:13:25 - train: epoch 0260, iter [00420, 01251], lr: 0.000398, loss: 0.4074
2022-10-02 19:13:43 - train: epoch 0260, iter [00430, 01251], lr: 0.000398, loss: 0.4241
2022-10-02 19:14:02 - train: epoch 0260, iter [00440, 01251], lr: 0.000398, loss: 0.4157
2022-10-02 19:14:20 - train: epoch 0260, iter [00450, 01251], lr: 0.000398, loss: 0.3872
2022-10-02 19:14:38 - train: epoch 0260, iter [00460, 01251], lr: 0.000398, loss: 0.3990
2022-10-02 19:14:56 - train: epoch 0260, iter [00470, 01251], lr: 0.000398, loss: 0.4110
2022-10-02 19:15:14 - train: epoch 0260, iter [00480, 01251], lr: 0.000398, loss: 0.4003
2022-10-02 19:15:32 - train: epoch 0260, iter [00490, 01251], lr: 0.000398, loss: 0.4014
2022-10-02 19:15:50 - train: epoch 0260, iter [00500, 01251], lr: 0.000398, loss: 0.4073
2022-10-02 19:16:08 - train: epoch 0260, iter [00510, 01251], lr: 0.000398, loss: 0.4183
2022-10-02 19:16:26 - train: epoch 0260, iter [00520, 01251], lr: 0.000398, loss: 0.4035
2022-10-02 19:16:44 - train: epoch 0260, iter [00530, 01251], lr: 0.000398, loss: 0.3972
2022-10-02 19:17:02 - train: epoch 0260, iter [00540, 01251], lr: 0.000398, loss: 0.4024
2022-10-02 19:17:21 - train: epoch 0260, iter [00550, 01251], lr: 0.000398, loss: 0.4117
2022-10-02 19:17:39 - train: epoch 0260, iter [00560, 01251], lr: 0.000398, loss: 0.4091
2022-10-02 19:17:57 - train: epoch 0260, iter [00570, 01251], lr: 0.000397, loss: 0.3897
2022-10-02 19:18:15 - train: epoch 0260, iter [00580, 01251], lr: 0.000397, loss: 0.4134
2022-10-02 19:18:33 - train: epoch 0260, iter [00590, 01251], lr: 0.000397, loss: 0.3928
2022-10-02 19:18:51 - train: epoch 0260, iter [00600, 01251], lr: 0.000397, loss: 0.3970
2022-10-02 19:19:09 - train: epoch 0260, iter [00610, 01251], lr: 0.000397, loss: 0.4131
2022-10-02 19:19:27 - train: epoch 0260, iter [00620, 01251], lr: 0.000397, loss: 0.4049
2022-10-02 19:19:45 - train: epoch 0260, iter [00630, 01251], lr: 0.000397, loss: 0.3947
2022-10-02 19:20:04 - train: epoch 0260, iter [00640, 01251], lr: 0.000397, loss: 0.3936
2022-10-02 19:20:22 - train: epoch 0260, iter [00650, 01251], lr: 0.000397, loss: 0.4146
2022-10-02 19:20:40 - train: epoch 0260, iter [00660, 01251], lr: 0.000397, loss: 0.3950
2022-10-02 19:20:58 - train: epoch 0260, iter [00670, 01251], lr: 0.000397, loss: 0.3982
2022-10-02 19:21:16 - train: epoch 0260, iter [00680, 01251], lr: 0.000397, loss: 0.4087
2022-10-02 19:21:34 - train: epoch 0260, iter [00690, 01251], lr: 0.000397, loss: 0.4076
2022-10-02 19:21:52 - train: epoch 0260, iter [00700, 01251], lr: 0.000397, loss: 0.3983
2022-10-02 19:22:10 - train: epoch 0260, iter [00710, 01251], lr: 0.000397, loss: 0.3728
2022-10-02 19:22:28 - train: epoch 0260, iter [00720, 01251], lr: 0.000397, loss: 0.4007
2022-10-02 19:22:47 - train: epoch 0260, iter [00730, 01251], lr: 0.000397, loss: 0.3889
2022-10-02 19:23:05 - train: epoch 0260, iter [00740, 01251], lr: 0.000397, loss: 0.4077
2022-10-02 19:23:23 - train: epoch 0260, iter [00750, 01251], lr: 0.000397, loss: 0.3993
2022-10-02 19:23:41 - train: epoch 0260, iter [00760, 01251], lr: 0.000397, loss: 0.4003
2022-10-02 19:23:59 - train: epoch 0260, iter [00770, 01251], lr: 0.000397, loss: 0.4033
2022-10-02 19:24:18 - train: epoch 0260, iter [00780, 01251], lr: 0.000397, loss: 0.4165
2022-10-02 19:24:36 - train: epoch 0260, iter [00790, 01251], lr: 0.000397, loss: 0.3911
2022-10-02 19:24:54 - train: epoch 0260, iter [00800, 01251], lr: 0.000397, loss: 0.4074
2022-10-02 19:25:12 - train: epoch 0260, iter [00810, 01251], lr: 0.000397, loss: 0.4068
2022-10-02 19:25:30 - train: epoch 0260, iter [00820, 01251], lr: 0.000396, loss: 0.4085
2022-10-02 19:25:48 - train: epoch 0260, iter [00830, 01251], lr: 0.000396, loss: 0.3960
2022-10-02 19:26:06 - train: epoch 0260, iter [00840, 01251], lr: 0.000396, loss: 0.4319
2022-10-02 19:26:24 - train: epoch 0260, iter [00850, 01251], lr: 0.000396, loss: 0.3819
2022-10-02 19:26:42 - train: epoch 0260, iter [00860, 01251], lr: 0.000396, loss: 0.4040
2022-10-02 19:27:00 - train: epoch 0260, iter [00870, 01251], lr: 0.000396, loss: 0.4000
2022-10-02 19:27:18 - train: epoch 0260, iter [00880, 01251], lr: 0.000396, loss: 0.3752
2022-10-02 19:27:37 - train: epoch 0260, iter [00890, 01251], lr: 0.000396, loss: 0.4002
2022-10-02 19:27:55 - train: epoch 0260, iter [00900, 01251], lr: 0.000396, loss: 0.4111
2022-10-02 19:28:13 - train: epoch 0260, iter [00910, 01251], lr: 0.000396, loss: 0.4001
2022-10-02 19:28:31 - train: epoch 0260, iter [00920, 01251], lr: 0.000396, loss: 0.3927
2022-10-02 19:28:49 - train: epoch 0260, iter [00930, 01251], lr: 0.000396, loss: 0.3940
2022-10-02 19:29:07 - train: epoch 0260, iter [00940, 01251], lr: 0.000396, loss: 0.4067
2022-10-02 19:29:25 - train: epoch 0260, iter [00950, 01251], lr: 0.000396, loss: 0.4057
2022-10-02 19:29:43 - train: epoch 0260, iter [00960, 01251], lr: 0.000396, loss: 0.4150
2022-10-02 19:30:01 - train: epoch 0260, iter [00970, 01251], lr: 0.000396, loss: 0.3990
2022-10-02 19:30:19 - train: epoch 0260, iter [00980, 01251], lr: 0.000396, loss: 0.3833
2022-10-02 19:30:37 - train: epoch 0260, iter [00990, 01251], lr: 0.000396, loss: 0.4210
2022-10-02 19:30:55 - train: epoch 0260, iter [01000, 01251], lr: 0.000396, loss: 0.4234
2022-10-02 19:31:13 - train: epoch 0260, iter [01010, 01251], lr: 0.000396, loss: 0.3772
2022-10-02 19:31:31 - train: epoch 0260, iter [01020, 01251], lr: 0.000396, loss: 0.3829
2022-10-02 19:31:49 - train: epoch 0260, iter [01030, 01251], lr: 0.000396, loss: 0.3948
2022-10-02 19:32:06 - train: epoch 0260, iter [01040, 01251], lr: 0.000396, loss: 0.3891
2022-10-02 19:32:24 - train: epoch 0260, iter [01050, 01251], lr: 0.000396, loss: 0.4089
2022-10-02 19:32:42 - train: epoch 0260, iter [01060, 01251], lr: 0.000396, loss: 0.4132
2022-10-02 19:33:00 - train: epoch 0260, iter [01070, 01251], lr: 0.000395, loss: 0.4009
2022-10-02 19:33:18 - train: epoch 0260, iter [01080, 01251], lr: 0.000395, loss: 0.3975
2022-10-02 19:33:36 - train: epoch 0260, iter [01090, 01251], lr: 0.000395, loss: 0.3979
2022-10-02 19:33:55 - train: epoch 0260, iter [01100, 01251], lr: 0.000395, loss: 0.4125
2022-10-02 19:34:13 - train: epoch 0260, iter [01110, 01251], lr: 0.000395, loss: 0.3989
2022-10-02 19:34:31 - train: epoch 0260, iter [01120, 01251], lr: 0.000395, loss: 0.4189
2022-10-02 19:34:49 - train: epoch 0260, iter [01130, 01251], lr: 0.000395, loss: 0.3982
2022-10-02 19:35:07 - train: epoch 0260, iter [01140, 01251], lr: 0.000395, loss: 0.3908
2022-10-02 19:35:24 - train: epoch 0260, iter [01150, 01251], lr: 0.000395, loss: 0.3996
2022-10-02 19:35:42 - train: epoch 0260, iter [01160, 01251], lr: 0.000395, loss: 0.3975
2022-10-02 19:36:00 - train: epoch 0260, iter [01170, 01251], lr: 0.000395, loss: 0.3970
2022-10-02 19:36:18 - train: epoch 0260, iter [01180, 01251], lr: 0.000395, loss: 0.4047
2022-10-02 19:36:36 - train: epoch 0260, iter [01190, 01251], lr: 0.000395, loss: 0.4141
2022-10-02 19:36:54 - train: epoch 0260, iter [01200, 01251], lr: 0.000395, loss: 0.4107
2022-10-02 19:37:13 - train: epoch 0260, iter [01210, 01251], lr: 0.000395, loss: 0.4112
2022-10-02 19:37:31 - train: epoch 0260, iter [01220, 01251], lr: 0.000395, loss: 0.4027
2022-10-02 19:37:49 - train: epoch 0260, iter [01230, 01251], lr: 0.000395, loss: 0.4039
2022-10-02 19:38:07 - train: epoch 0260, iter [01240, 01251], lr: 0.000395, loss: 0.3999
2022-10-02 19:38:25 - train: epoch 0260, iter [01250, 01251], lr: 0.000395, loss: 0.3867
2022-10-02 19:38:28 - train: epoch 260, train_loss: 0.4018
2022-10-02 19:38:31 - until epoch: 260, best_loss: 0.4018
2022-10-02 19:38:31 - epoch 261 lr: 0.000395
2022-10-02 19:38:56 - train: epoch 0261, iter [00010, 01251], lr: 0.000395, loss: 0.4125
2022-10-02 19:39:15 - train: epoch 0261, iter [00020, 01251], lr: 0.000395, loss: 0.4135
2022-10-02 19:39:34 - train: epoch 0261, iter [00030, 01251], lr: 0.000395, loss: 0.4307
2022-10-02 19:39:52 - train: epoch 0261, iter [00040, 01251], lr: 0.000395, loss: 0.4008
2022-10-02 19:40:11 - train: epoch 0261, iter [00050, 01251], lr: 0.000395, loss: 0.4097
2022-10-02 19:40:29 - train: epoch 0261, iter [00060, 01251], lr: 0.000395, loss: 0.3946
2022-10-02 19:40:48 - train: epoch 0261, iter [00070, 01251], lr: 0.000395, loss: 0.4002
2022-10-02 19:41:06 - train: epoch 0261, iter [00080, 01251], lr: 0.000394, loss: 0.4027
2022-10-02 19:41:25 - train: epoch 0261, iter [00090, 01251], lr: 0.000394, loss: 0.4067
2022-10-02 19:41:43 - train: epoch 0261, iter [00100, 01251], lr: 0.000394, loss: 0.4085
2022-10-02 19:42:01 - train: epoch 0261, iter [00110, 01251], lr: 0.000394, loss: 0.4005
2022-10-02 19:42:20 - train: epoch 0261, iter [00120, 01251], lr: 0.000394, loss: 0.3922
2022-10-02 19:42:38 - train: epoch 0261, iter [00130, 01251], lr: 0.000394, loss: 0.3974
2022-10-02 19:42:57 - train: epoch 0261, iter [00140, 01251], lr: 0.000394, loss: 0.3997
2022-10-02 19:43:15 - train: epoch 0261, iter [00150, 01251], lr: 0.000394, loss: 0.4013
2022-10-02 19:43:33 - train: epoch 0261, iter [00160, 01251], lr: 0.000394, loss: 0.4152
2022-10-02 19:43:52 - train: epoch 0261, iter [00170, 01251], lr: 0.000394, loss: 0.3981
2022-10-02 19:44:10 - train: epoch 0261, iter [00180, 01251], lr: 0.000394, loss: 0.4076
2022-10-02 19:44:28 - train: epoch 0261, iter [00190, 01251], lr: 0.000394, loss: 0.3959
2022-10-02 19:44:47 - train: epoch 0261, iter [00200, 01251], lr: 0.000394, loss: 0.3954
2022-10-02 19:45:05 - train: epoch 0261, iter [00210, 01251], lr: 0.000394, loss: 0.4209
2022-10-02 19:45:24 - train: epoch 0261, iter [00220, 01251], lr: 0.000394, loss: 0.3915
2022-10-02 19:45:42 - train: epoch 0261, iter [00230, 01251], lr: 0.000394, loss: 0.3838
2022-10-02 19:46:01 - train: epoch 0261, iter [00240, 01251], lr: 0.000394, loss: 0.4052
2022-10-02 19:46:19 - train: epoch 0261, iter [00250, 01251], lr: 0.000394, loss: 0.4112
2022-10-02 19:46:37 - train: epoch 0261, iter [00260, 01251], lr: 0.000394, loss: 0.4152
2022-10-02 19:46:56 - train: epoch 0261, iter [00270, 01251], lr: 0.000394, loss: 0.4149
2022-10-02 19:47:14 - train: epoch 0261, iter [00280, 01251], lr: 0.000394, loss: 0.4210
2022-10-02 19:47:32 - train: epoch 0261, iter [00290, 01251], lr: 0.000394, loss: 0.3900
2022-10-02 19:47:51 - train: epoch 0261, iter [00300, 01251], lr: 0.000394, loss: 0.4055
2022-10-02 19:48:09 - train: epoch 0261, iter [00310, 01251], lr: 0.000394, loss: 0.4107
2022-10-02 19:48:27 - train: epoch 0261, iter [00320, 01251], lr: 0.000394, loss: 0.4171
2022-10-02 19:48:46 - train: epoch 0261, iter [00330, 01251], lr: 0.000393, loss: 0.3939
2022-10-02 19:49:04 - train: epoch 0261, iter [00340, 01251], lr: 0.000393, loss: 0.4266
2022-10-02 19:49:23 - train: epoch 0261, iter [00350, 01251], lr: 0.000393, loss: 0.3899
2022-10-02 19:49:41 - train: epoch 0261, iter [00360, 01251], lr: 0.000393, loss: 0.4047
2022-10-02 19:49:59 - train: epoch 0261, iter [00370, 01251], lr: 0.000393, loss: 0.3930
2022-10-02 19:50:18 - train: epoch 0261, iter [00380, 01251], lr: 0.000393, loss: 0.4012
2022-10-02 19:50:36 - train: epoch 0261, iter [00390, 01251], lr: 0.000393, loss: 0.3925
2022-10-02 19:50:54 - train: epoch 0261, iter [00400, 01251], lr: 0.000393, loss: 0.3868
2022-10-02 19:51:13 - train: epoch 0261, iter [00410, 01251], lr: 0.000393, loss: 0.4138
2022-10-02 19:51:31 - train: epoch 0261, iter [00420, 01251], lr: 0.000393, loss: 0.4057
2022-10-02 19:51:49 - train: epoch 0261, iter [00430, 01251], lr: 0.000393, loss: 0.3953
2022-10-02 19:52:08 - train: epoch 0261, iter [00440, 01251], lr: 0.000393, loss: 0.4164
2022-10-02 19:52:26 - train: epoch 0261, iter [00450, 01251], lr: 0.000393, loss: 0.4302
2022-10-02 19:52:44 - train: epoch 0261, iter [00460, 01251], lr: 0.000393, loss: 0.3991
2022-10-02 19:53:02 - train: epoch 0261, iter [00470, 01251], lr: 0.000393, loss: 0.3980
2022-10-02 19:53:21 - train: epoch 0261, iter [00480, 01251], lr: 0.000393, loss: 0.4035
2022-10-02 19:53:39 - train: epoch 0261, iter [00490, 01251], lr: 0.000393, loss: 0.4006
2022-10-02 19:53:57 - train: epoch 0261, iter [00500, 01251], lr: 0.000393, loss: 0.3844
2022-10-02 19:54:15 - train: epoch 0261, iter [00510, 01251], lr: 0.000393, loss: 0.4011
2022-10-02 19:54:33 - train: epoch 0261, iter [00520, 01251], lr: 0.000393, loss: 0.4104
2022-10-02 19:54:52 - train: epoch 0261, iter [00530, 01251], lr: 0.000393, loss: 0.4089
2022-10-02 19:55:10 - train: epoch 0261, iter [00540, 01251], lr: 0.000393, loss: 0.3834
2022-10-02 19:55:28 - train: epoch 0261, iter [00550, 01251], lr: 0.000393, loss: 0.3939
2022-10-02 19:55:47 - train: epoch 0261, iter [00560, 01251], lr: 0.000393, loss: 0.4006
2022-10-02 19:56:05 - train: epoch 0261, iter [00570, 01251], lr: 0.000393, loss: 0.3911
2022-10-02 19:56:23 - train: epoch 0261, iter [00580, 01251], lr: 0.000393, loss: 0.3886
2022-10-02 19:56:41 - train: epoch 0261, iter [00590, 01251], lr: 0.000392, loss: 0.3872
2022-10-02 19:57:00 - train: epoch 0261, iter [00600, 01251], lr: 0.000392, loss: 0.4109
2022-10-02 19:57:18 - train: epoch 0261, iter [00610, 01251], lr: 0.000392, loss: 0.4089
2022-10-02 19:57:37 - train: epoch 0261, iter [00620, 01251], lr: 0.000392, loss: 0.3903
2022-10-02 19:57:55 - train: epoch 0261, iter [00630, 01251], lr: 0.000392, loss: 0.3790
2022-10-02 19:58:13 - train: epoch 0261, iter [00640, 01251], lr: 0.000392, loss: 0.3908
2022-10-02 19:58:31 - train: epoch 0261, iter [00650, 01251], lr: 0.000392, loss: 0.4161
2022-10-02 19:58:50 - train: epoch 0261, iter [00660, 01251], lr: 0.000392, loss: 0.4042
2022-10-02 19:59:08 - train: epoch 0261, iter [00670, 01251], lr: 0.000392, loss: 0.4048
2022-10-02 19:59:26 - train: epoch 0261, iter [00680, 01251], lr: 0.000392, loss: 0.3932
2022-10-02 19:59:44 - train: epoch 0261, iter [00690, 01251], lr: 0.000392, loss: 0.4006
2022-10-02 20:00:02 - train: epoch 0261, iter [00700, 01251], lr: 0.000392, loss: 0.4088
2022-10-02 20:00:21 - train: epoch 0261, iter [00710, 01251], lr: 0.000392, loss: 0.3784
2022-10-02 20:00:39 - train: epoch 0261, iter [00720, 01251], lr: 0.000392, loss: 0.4126
2022-10-02 20:00:57 - train: epoch 0261, iter [00730, 01251], lr: 0.000392, loss: 0.4038
2022-10-02 20:01:15 - train: epoch 0261, iter [00740, 01251], lr: 0.000392, loss: 0.4284
2022-10-02 20:01:34 - train: epoch 0261, iter [00750, 01251], lr: 0.000392, loss: 0.3949
2022-10-02 20:01:52 - train: epoch 0261, iter [00760, 01251], lr: 0.000392, loss: 0.4026
2022-10-02 20:02:10 - train: epoch 0261, iter [00770, 01251], lr: 0.000392, loss: 0.3767
2022-10-02 20:02:28 - train: epoch 0261, iter [00780, 01251], lr: 0.000392, loss: 0.4155
2022-10-02 20:02:46 - train: epoch 0261, iter [00790, 01251], lr: 0.000392, loss: 0.4028
2022-10-02 20:03:05 - train: epoch 0261, iter [00800, 01251], lr: 0.000392, loss: 0.3802
2022-10-02 20:03:23 - train: epoch 0261, iter [00810, 01251], lr: 0.000392, loss: 0.3941
2022-10-02 20:03:41 - train: epoch 0261, iter [00820, 01251], lr: 0.000392, loss: 0.4133
2022-10-02 20:03:59 - train: epoch 0261, iter [00830, 01251], lr: 0.000392, loss: 0.4039
2022-10-02 20:04:18 - train: epoch 0261, iter [00840, 01251], lr: 0.000391, loss: 0.4067
2022-10-02 20:04:36 - train: epoch 0261, iter [00850, 01251], lr: 0.000391, loss: 0.4076
2022-10-02 20:04:54 - train: epoch 0261, iter [00860, 01251], lr: 0.000391, loss: 0.4190
2022-10-02 20:05:12 - train: epoch 0261, iter [00870, 01251], lr: 0.000391, loss: 0.4002
2022-10-02 20:05:31 - train: epoch 0261, iter [00880, 01251], lr: 0.000391, loss: 0.4083
2022-10-02 20:05:49 - train: epoch 0261, iter [00890, 01251], lr: 0.000391, loss: 0.4046
2022-10-02 20:06:07 - train: epoch 0261, iter [00900, 01251], lr: 0.000391, loss: 0.3904
2022-10-02 20:06:25 - train: epoch 0261, iter [00910, 01251], lr: 0.000391, loss: 0.4074
2022-10-02 20:06:44 - train: epoch 0261, iter [00920, 01251], lr: 0.000391, loss: 0.4107
2022-10-02 20:07:02 - train: epoch 0261, iter [00930, 01251], lr: 0.000391, loss: 0.4002
2022-10-02 20:07:20 - train: epoch 0261, iter [00940, 01251], lr: 0.000391, loss: 0.4198
2022-10-02 20:07:38 - train: epoch 0261, iter [00950, 01251], lr: 0.000391, loss: 0.4184
2022-10-02 20:07:56 - train: epoch 0261, iter [00960, 01251], lr: 0.000391, loss: 0.4050
2022-10-02 20:08:15 - train: epoch 0261, iter [00970, 01251], lr: 0.000391, loss: 0.3724
2022-10-02 20:08:33 - train: epoch 0261, iter [00980, 01251], lr: 0.000391, loss: 0.4273
2022-10-02 20:08:51 - train: epoch 0261, iter [00990, 01251], lr: 0.000391, loss: 0.4036
2022-10-02 20:09:09 - train: epoch 0261, iter [01000, 01251], lr: 0.000391, loss: 0.3992
2022-10-02 20:09:28 - train: epoch 0261, iter [01010, 01251], lr: 0.000391, loss: 0.4117
2022-10-02 20:09:46 - train: epoch 0261, iter [01020, 01251], lr: 0.000391, loss: 0.3867
2022-10-02 20:10:04 - train: epoch 0261, iter [01030, 01251], lr: 0.000391, loss: 0.3990
2022-10-02 20:10:22 - train: epoch 0261, iter [01040, 01251], lr: 0.000391, loss: 0.4207
2022-10-02 20:10:40 - train: epoch 0261, iter [01050, 01251], lr: 0.000391, loss: 0.3953
2022-10-02 20:10:59 - train: epoch 0261, iter [01060, 01251], lr: 0.000391, loss: 0.3857
2022-10-02 20:11:17 - train: epoch 0261, iter [01070, 01251], lr: 0.000391, loss: 0.4183
2022-10-02 20:11:35 - train: epoch 0261, iter [01080, 01251], lr: 0.000391, loss: 0.4022
2022-10-02 20:11:53 - train: epoch 0261, iter [01090, 01251], lr: 0.000391, loss: 0.3854
2022-10-02 20:12:12 - train: epoch 0261, iter [01100, 01251], lr: 0.000390, loss: 0.3948
2022-10-02 20:12:30 - train: epoch 0261, iter [01110, 01251], lr: 0.000390, loss: 0.3819
2022-10-02 20:12:48 - train: epoch 0261, iter [01120, 01251], lr: 0.000390, loss: 0.3886
2022-10-02 20:13:06 - train: epoch 0261, iter [01130, 01251], lr: 0.000390, loss: 0.3871
2022-10-02 20:13:25 - train: epoch 0261, iter [01140, 01251], lr: 0.000390, loss: 0.3972
2022-10-02 20:13:43 - train: epoch 0261, iter [01150, 01251], lr: 0.000390, loss: 0.4152
2022-10-02 20:14:01 - train: epoch 0261, iter [01160, 01251], lr: 0.000390, loss: 0.3645
2022-10-02 20:14:19 - train: epoch 0261, iter [01170, 01251], lr: 0.000390, loss: 0.4127
2022-10-02 20:14:38 - train: epoch 0261, iter [01180, 01251], lr: 0.000390, loss: 0.4123
2022-10-02 20:14:56 - train: epoch 0261, iter [01190, 01251], lr: 0.000390, loss: 0.3925
2022-10-02 20:15:14 - train: epoch 0261, iter [01200, 01251], lr: 0.000390, loss: 0.4007
2022-10-02 20:15:32 - train: epoch 0261, iter [01210, 01251], lr: 0.000390, loss: 0.3716
2022-10-02 20:15:51 - train: epoch 0261, iter [01220, 01251], lr: 0.000390, loss: 0.3639
2022-10-02 20:16:09 - train: epoch 0261, iter [01230, 01251], lr: 0.000390, loss: 0.4120
2022-10-02 20:16:27 - train: epoch 0261, iter [01240, 01251], lr: 0.000390, loss: 0.3794
2022-10-02 20:16:45 - train: epoch 0261, iter [01250, 01251], lr: 0.000390, loss: 0.3851
2022-10-02 20:16:48 - train: epoch 261, train_loss: 0.4017
2022-10-02 20:16:51 - until epoch: 261, best_loss: 0.4017
2022-10-02 20:16:51 - epoch 262 lr: 0.000390
2022-10-02 20:17:16 - train: epoch 0262, iter [00010, 01251], lr: 0.000390, loss: 0.4095
2022-10-02 20:17:34 - train: epoch 0262, iter [00020, 01251], lr: 0.000390, loss: 0.4058
2022-10-02 20:17:52 - train: epoch 0262, iter [00030, 01251], lr: 0.000390, loss: 0.3998
2022-10-02 20:18:10 - train: epoch 0262, iter [00040, 01251], lr: 0.000390, loss: 0.4273
2022-10-02 20:18:28 - train: epoch 0262, iter [00050, 01251], lr: 0.000390, loss: 0.3695
2022-10-02 20:18:47 - train: epoch 0262, iter [00060, 01251], lr: 0.000390, loss: 0.4225
2022-10-02 20:19:05 - train: epoch 0262, iter [00070, 01251], lr: 0.000390, loss: 0.3798
2022-10-02 20:19:23 - train: epoch 0262, iter [00080, 01251], lr: 0.000390, loss: 0.4032
2022-10-02 20:19:41 - train: epoch 0262, iter [00090, 01251], lr: 0.000390, loss: 0.4053
2022-10-02 20:19:59 - train: epoch 0262, iter [00100, 01251], lr: 0.000389, loss: 0.3949
2022-10-02 20:20:17 - train: epoch 0262, iter [00110, 01251], lr: 0.000389, loss: 0.3995
2022-10-02 20:20:35 - train: epoch 0262, iter [00120, 01251], lr: 0.000389, loss: 0.4147
2022-10-02 20:20:53 - train: epoch 0262, iter [00130, 01251], lr: 0.000389, loss: 0.3971
2022-10-02 20:21:12 - train: epoch 0262, iter [00140, 01251], lr: 0.000389, loss: 0.4024
2022-10-02 20:21:30 - train: epoch 0262, iter [00150, 01251], lr: 0.000389, loss: 0.3944
2022-10-02 20:21:48 - train: epoch 0262, iter [00160, 01251], lr: 0.000389, loss: 0.3823
2022-10-02 20:22:06 - train: epoch 0262, iter [00170, 01251], lr: 0.000389, loss: 0.3940
2022-10-02 20:22:24 - train: epoch 0262, iter [00180, 01251], lr: 0.000389, loss: 0.4318
2022-10-02 20:22:42 - train: epoch 0262, iter [00190, 01251], lr: 0.000389, loss: 0.4038
2022-10-02 20:23:01 - train: epoch 0262, iter [00200, 01251], lr: 0.000389, loss: 0.3904
2022-10-02 20:23:18 - train: epoch 0262, iter [00210, 01251], lr: 0.000389, loss: 0.4044
2022-10-02 20:23:37 - train: epoch 0262, iter [00220, 01251], lr: 0.000389, loss: 0.4082
2022-10-02 20:23:55 - train: epoch 0262, iter [00230, 01251], lr: 0.000389, loss: 0.3961
2022-10-02 20:24:13 - train: epoch 0262, iter [00240, 01251], lr: 0.000389, loss: 0.3953
2022-10-02 20:24:31 - train: epoch 0262, iter [00250, 01251], lr: 0.000389, loss: 0.3993
2022-10-02 20:24:49 - train: epoch 0262, iter [00260, 01251], lr: 0.000389, loss: 0.3939
2022-10-02 20:25:07 - train: epoch 0262, iter [00270, 01251], lr: 0.000389, loss: 0.4112
2022-10-02 20:25:25 - train: epoch 0262, iter [00280, 01251], lr: 0.000389, loss: 0.4188
2022-10-02 20:25:44 - train: epoch 0262, iter [00290, 01251], lr: 0.000389, loss: 0.4031
2022-10-02 20:26:02 - train: epoch 0262, iter [00300, 01251], lr: 0.000389, loss: 0.4090
2022-10-02 20:26:20 - train: epoch 0262, iter [00310, 01251], lr: 0.000389, loss: 0.3855
2022-10-02 20:26:38 - train: epoch 0262, iter [00320, 01251], lr: 0.000389, loss: 0.4035
2022-10-02 20:26:57 - train: epoch 0262, iter [00330, 01251], lr: 0.000389, loss: 0.4074
2022-10-02 20:27:15 - train: epoch 0262, iter [00340, 01251], lr: 0.000389, loss: 0.3873
2022-10-02 20:27:33 - train: epoch 0262, iter [00350, 01251], lr: 0.000389, loss: 0.4017
2022-10-02 20:27:51 - train: epoch 0262, iter [00360, 01251], lr: 0.000388, loss: 0.3784
2022-10-02 20:28:09 - train: epoch 0262, iter [00370, 01251], lr: 0.000388, loss: 0.3953
2022-10-02 20:28:27 - train: epoch 0262, iter [00380, 01251], lr: 0.000388, loss: 0.4030
2022-10-02 20:28:45 - train: epoch 0262, iter [00390, 01251], lr: 0.000388, loss: 0.3925
2022-10-02 20:29:04 - train: epoch 0262, iter [00400, 01251], lr: 0.000388, loss: 0.4088
2022-10-02 20:29:22 - train: epoch 0262, iter [00410, 01251], lr: 0.000388, loss: 0.3967
2022-10-02 20:29:40 - train: epoch 0262, iter [00420, 01251], lr: 0.000388, loss: 0.4042
2022-10-02 20:29:58 - train: epoch 0262, iter [00430, 01251], lr: 0.000388, loss: 0.4104
2022-10-02 20:30:17 - train: epoch 0262, iter [00440, 01251], lr: 0.000388, loss: 0.4112
2022-10-02 20:30:35 - train: epoch 0262, iter [00450, 01251], lr: 0.000388, loss: 0.4167
2022-10-02 20:30:53 - train: epoch 0262, iter [00460, 01251], lr: 0.000388, loss: 0.4057
2022-10-02 20:31:11 - train: epoch 0262, iter [00470, 01251], lr: 0.000388, loss: 0.4051
2022-10-02 20:31:29 - train: epoch 0262, iter [00480, 01251], lr: 0.000388, loss: 0.3876
2022-10-02 20:31:48 - train: epoch 0262, iter [00490, 01251], lr: 0.000388, loss: 0.3969
2022-10-02 20:32:06 - train: epoch 0262, iter [00500, 01251], lr: 0.000388, loss: 0.3986
2022-10-02 20:32:24 - train: epoch 0262, iter [00510, 01251], lr: 0.000388, loss: 0.3988
2022-10-02 20:32:42 - train: epoch 0262, iter [00520, 01251], lr: 0.000388, loss: 0.3941
2022-10-02 20:33:00 - train: epoch 0262, iter [00530, 01251], lr: 0.000388, loss: 0.3870
2022-10-02 20:33:19 - train: epoch 0262, iter [00540, 01251], lr: 0.000388, loss: 0.3911
2022-10-02 20:33:37 - train: epoch 0262, iter [00550, 01251], lr: 0.000388, loss: 0.4008
2022-10-02 20:33:55 - train: epoch 0262, iter [00560, 01251], lr: 0.000388, loss: 0.3991
2022-10-02 20:34:13 - train: epoch 0262, iter [00570, 01251], lr: 0.000388, loss: 0.3874
2022-10-02 20:34:31 - train: epoch 0262, iter [00580, 01251], lr: 0.000388, loss: 0.3962
2022-10-02 20:34:50 - train: epoch 0262, iter [00590, 01251], lr: 0.000388, loss: 0.3917
2022-10-02 20:35:08 - train: epoch 0262, iter [00600, 01251], lr: 0.000388, loss: 0.3934
2022-10-02 20:35:26 - train: epoch 0262, iter [00610, 01251], lr: 0.000387, loss: 0.3941
2022-10-02 20:35:44 - train: epoch 0262, iter [00620, 01251], lr: 0.000387, loss: 0.3920
2022-10-02 20:36:02 - train: epoch 0262, iter [00630, 01251], lr: 0.000387, loss: 0.3892
2022-10-02 20:36:21 - train: epoch 0262, iter [00640, 01251], lr: 0.000387, loss: 0.3944
2022-10-02 20:36:39 - train: epoch 0262, iter [00650, 01251], lr: 0.000387, loss: 0.4020
2022-10-02 20:36:57 - train: epoch 0262, iter [00660, 01251], lr: 0.000387, loss: 0.4089
2022-10-02 20:37:15 - train: epoch 0262, iter [00670, 01251], lr: 0.000387, loss: 0.4008
2022-10-02 20:37:33 - train: epoch 0262, iter [00680, 01251], lr: 0.000387, loss: 0.3902
2022-10-02 20:37:52 - train: epoch 0262, iter [00690, 01251], lr: 0.000387, loss: 0.4148
2022-10-02 20:38:10 - train: epoch 0262, iter [00700, 01251], lr: 0.000387, loss: 0.3965
2022-10-02 20:38:28 - train: epoch 0262, iter [00710, 01251], lr: 0.000387, loss: 0.4049
2022-10-02 20:38:46 - train: epoch 0262, iter [00720, 01251], lr: 0.000387, loss: 0.4252
2022-10-02 20:39:05 - train: epoch 0262, iter [00730, 01251], lr: 0.000387, loss: 0.4029
2022-10-02 20:39:23 - train: epoch 0262, iter [00740, 01251], lr: 0.000387, loss: 0.4207
2022-10-02 20:39:41 - train: epoch 0262, iter [00750, 01251], lr: 0.000387, loss: 0.4049
2022-10-02 20:39:59 - train: epoch 0262, iter [00760, 01251], lr: 0.000387, loss: 0.3956
2022-10-02 20:40:18 - train: epoch 0262, iter [00770, 01251], lr: 0.000387, loss: 0.4072
2022-10-02 20:40:36 - train: epoch 0262, iter [00780, 01251], lr: 0.000387, loss: 0.4075
2022-10-02 20:40:54 - train: epoch 0262, iter [00790, 01251], lr: 0.000387, loss: 0.4169
2022-10-02 20:41:12 - train: epoch 0262, iter [00800, 01251], lr: 0.000387, loss: 0.3931
2022-10-02 20:41:30 - train: epoch 0262, iter [00810, 01251], lr: 0.000387, loss: 0.3985
2022-10-02 20:41:49 - train: epoch 0262, iter [00820, 01251], lr: 0.000387, loss: 0.4088
2022-10-02 20:42:07 - train: epoch 0262, iter [00830, 01251], lr: 0.000387, loss: 0.4137
2022-10-02 20:42:25 - train: epoch 0262, iter [00840, 01251], lr: 0.000387, loss: 0.4076
2022-10-02 20:42:43 - train: epoch 0262, iter [00850, 01251], lr: 0.000387, loss: 0.3989
2022-10-02 20:43:02 - train: epoch 0262, iter [00860, 01251], lr: 0.000387, loss: 0.3939
2022-10-02 20:43:19 - train: epoch 0262, iter [00870, 01251], lr: 0.000386, loss: 0.4063
2022-10-02 20:43:38 - train: epoch 0262, iter [00880, 01251], lr: 0.000386, loss: 0.4024
2022-10-02 20:43:56 - train: epoch 0262, iter [00890, 01251], lr: 0.000386, loss: 0.4098
2022-10-02 20:44:14 - train: epoch 0262, iter [00900, 01251], lr: 0.000386, loss: 0.4032
2022-10-02 20:44:32 - train: epoch 0262, iter [00910, 01251], lr: 0.000386, loss: 0.3840
2022-10-02 20:44:50 - train: epoch 0262, iter [00920, 01251], lr: 0.000386, loss: 0.4056
2022-10-02 20:45:08 - train: epoch 0262, iter [00930, 01251], lr: 0.000386, loss: 0.4207
2022-10-02 20:45:27 - train: epoch 0262, iter [00940, 01251], lr: 0.000386, loss: 0.3971
2022-10-02 20:45:45 - train: epoch 0262, iter [00950, 01251], lr: 0.000386, loss: 0.3917
2022-10-02 20:46:03 - train: epoch 0262, iter [00960, 01251], lr: 0.000386, loss: 0.4071
2022-10-02 20:46:21 - train: epoch 0262, iter [00970, 01251], lr: 0.000386, loss: 0.4147
2022-10-02 20:46:39 - train: epoch 0262, iter [00980, 01251], lr: 0.000386, loss: 0.3982
2022-10-02 20:46:58 - train: epoch 0262, iter [00990, 01251], lr: 0.000386, loss: 0.4185
2022-10-02 20:47:16 - train: epoch 0262, iter [01000, 01251], lr: 0.000386, loss: 0.4146
2022-10-02 20:47:34 - train: epoch 0262, iter [01010, 01251], lr: 0.000386, loss: 0.4123
2022-10-02 20:47:52 - train: epoch 0262, iter [01020, 01251], lr: 0.000386, loss: 0.4083
2022-10-02 20:48:11 - train: epoch 0262, iter [01030, 01251], lr: 0.000386, loss: 0.4003
2022-10-02 20:48:29 - train: epoch 0262, iter [01040, 01251], lr: 0.000386, loss: 0.3988
2022-10-02 20:48:47 - train: epoch 0262, iter [01050, 01251], lr: 0.000386, loss: 0.3947
2022-10-02 20:49:05 - train: epoch 0262, iter [01060, 01251], lr: 0.000386, loss: 0.4199
2022-10-02 20:49:23 - train: epoch 0262, iter [01070, 01251], lr: 0.000386, loss: 0.4213
2022-10-02 20:49:42 - train: epoch 0262, iter [01080, 01251], lr: 0.000386, loss: 0.3944
2022-10-02 20:50:00 - train: epoch 0262, iter [01090, 01251], lr: 0.000386, loss: 0.4004
2022-10-02 20:50:18 - train: epoch 0262, iter [01100, 01251], lr: 0.000386, loss: 0.3766
2022-10-02 20:50:37 - train: epoch 0262, iter [01110, 01251], lr: 0.000386, loss: 0.3991
2022-10-02 20:50:55 - train: epoch 0262, iter [01120, 01251], lr: 0.000385, loss: 0.3821
2022-10-02 20:51:13 - train: epoch 0262, iter [01130, 01251], lr: 0.000385, loss: 0.4106
2022-10-02 20:51:31 - train: epoch 0262, iter [01140, 01251], lr: 0.000385, loss: 0.3982
2022-10-02 20:51:49 - train: epoch 0262, iter [01150, 01251], lr: 0.000385, loss: 0.4120
2022-10-02 20:52:07 - train: epoch 0262, iter [01160, 01251], lr: 0.000385, loss: 0.3847
2022-10-02 20:52:26 - train: epoch 0262, iter [01170, 01251], lr: 0.000385, loss: 0.3952
2022-10-02 20:52:44 - train: epoch 0262, iter [01180, 01251], lr: 0.000385, loss: 0.4022
2022-10-02 20:53:02 - train: epoch 0262, iter [01190, 01251], lr: 0.000385, loss: 0.3951
2022-10-02 20:53:20 - train: epoch 0262, iter [01200, 01251], lr: 0.000385, loss: 0.3817
2022-10-02 20:53:38 - train: epoch 0262, iter [01210, 01251], lr: 0.000385, loss: 0.4019
2022-10-02 20:53:56 - train: epoch 0262, iter [01220, 01251], lr: 0.000385, loss: 0.4195
2022-10-02 20:54:15 - train: epoch 0262, iter [01230, 01251], lr: 0.000385, loss: 0.3750
2022-10-02 20:54:33 - train: epoch 0262, iter [01240, 01251], lr: 0.000385, loss: 0.4095
2022-10-02 20:54:51 - train: epoch 0262, iter [01250, 01251], lr: 0.000385, loss: 0.4037
2022-10-02 20:54:54 - train: epoch 262, train_loss: 0.4016
2022-10-02 20:54:57 - until epoch: 262, best_loss: 0.4016
2022-10-02 20:54:57 - epoch 263 lr: 0.000385
2022-10-02 20:55:22 - train: epoch 0263, iter [00010, 01251], lr: 0.000385, loss: 0.3920
2022-10-02 20:55:40 - train: epoch 0263, iter [00020, 01251], lr: 0.000385, loss: 0.3992
2022-10-02 20:55:58 - train: epoch 0263, iter [00030, 01251], lr: 0.000385, loss: 0.3831
2022-10-02 20:56:17 - train: epoch 0263, iter [00040, 01251], lr: 0.000385, loss: 0.4133
2022-10-02 20:56:35 - train: epoch 0263, iter [00050, 01251], lr: 0.000385, loss: 0.4076
2022-10-02 20:56:53 - train: epoch 0263, iter [00060, 01251], lr: 0.000385, loss: 0.4018
2022-10-02 20:57:11 - train: epoch 0263, iter [00070, 01251], lr: 0.000385, loss: 0.3800
2022-10-02 20:57:29 - train: epoch 0263, iter [00080, 01251], lr: 0.000385, loss: 0.4083
2022-10-02 20:57:47 - train: epoch 0263, iter [00090, 01251], lr: 0.000385, loss: 0.4192
2022-10-02 20:58:06 - train: epoch 0263, iter [00100, 01251], lr: 0.000385, loss: 0.4004
2022-10-02 20:58:24 - train: epoch 0263, iter [00110, 01251], lr: 0.000385, loss: 0.3890
2022-10-02 20:58:42 - train: epoch 0263, iter [00120, 01251], lr: 0.000385, loss: 0.4043
2022-10-02 20:59:00 - train: epoch 0263, iter [00130, 01251], lr: 0.000384, loss: 0.4159
2022-10-02 20:59:18 - train: epoch 0263, iter [00140, 01251], lr: 0.000384, loss: 0.4029
2022-10-02 20:59:37 - train: epoch 0263, iter [00150, 01251], lr: 0.000384, loss: 0.4153
2022-10-02 20:59:55 - train: epoch 0263, iter [00160, 01251], lr: 0.000384, loss: 0.3975
2022-10-02 21:00:13 - train: epoch 0263, iter [00170, 01251], lr: 0.000384, loss: 0.4015
2022-10-02 21:00:31 - train: epoch 0263, iter [00180, 01251], lr: 0.000384, loss: 0.4047
2022-10-02 21:00:49 - train: epoch 0263, iter [00190, 01251], lr: 0.000384, loss: 0.4086
2022-10-02 21:01:08 - train: epoch 0263, iter [00200, 01251], lr: 0.000384, loss: 0.4120
2022-10-02 21:01:26 - train: epoch 0263, iter [00210, 01251], lr: 0.000384, loss: 0.3911
2022-10-02 21:01:44 - train: epoch 0263, iter [00220, 01251], lr: 0.000384, loss: 0.3958
2022-10-02 21:02:03 - train: epoch 0263, iter [00230, 01251], lr: 0.000384, loss: 0.3961
2022-10-02 21:02:21 - train: epoch 0263, iter [00240, 01251], lr: 0.000384, loss: 0.4068
2022-10-02 21:02:39 - train: epoch 0263, iter [00250, 01251], lr: 0.000384, loss: 0.4004
2022-10-02 21:02:57 - train: epoch 0263, iter [00260, 01251], lr: 0.000384, loss: 0.4196
2022-10-02 21:03:15 - train: epoch 0263, iter [00270, 01251], lr: 0.000384, loss: 0.4102
2022-10-02 21:03:33 - train: epoch 0263, iter [00280, 01251], lr: 0.000384, loss: 0.4012
2022-10-02 21:03:52 - train: epoch 0263, iter [00290, 01251], lr: 0.000384, loss: 0.4099
2022-10-02 21:04:10 - train: epoch 0263, iter [00300, 01251], lr: 0.000384, loss: 0.4026
2022-10-02 21:04:28 - train: epoch 0263, iter [00310, 01251], lr: 0.000384, loss: 0.3867
2022-10-02 21:04:46 - train: epoch 0263, iter [00320, 01251], lr: 0.000384, loss: 0.3876
2022-10-02 21:05:04 - train: epoch 0263, iter [00330, 01251], lr: 0.000384, loss: 0.4018
2022-10-02 21:05:22 - train: epoch 0263, iter [00340, 01251], lr: 0.000384, loss: 0.3924
2022-10-02 21:05:40 - train: epoch 0263, iter [00350, 01251], lr: 0.000384, loss: 0.4009
2022-10-02 21:05:59 - train: epoch 0263, iter [00360, 01251], lr: 0.000384, loss: 0.4183
2022-10-02 21:06:17 - train: epoch 0263, iter [00370, 01251], lr: 0.000384, loss: 0.4013
2022-10-02 21:06:35 - train: epoch 0263, iter [00380, 01251], lr: 0.000383, loss: 0.4088
2022-10-02 21:06:53 - train: epoch 0263, iter [00390, 01251], lr: 0.000383, loss: 0.4134
2022-10-02 21:07:11 - train: epoch 0263, iter [00400, 01251], lr: 0.000383, loss: 0.3982
2022-10-02 21:07:29 - train: epoch 0263, iter [00410, 01251], lr: 0.000383, loss: 0.4057
2022-10-02 21:07:48 - train: epoch 0263, iter [00420, 01251], lr: 0.000383, loss: 0.4088
2022-10-02 21:08:06 - train: epoch 0263, iter [00430, 01251], lr: 0.000383, loss: 0.3898
2022-10-02 21:08:24 - train: epoch 0263, iter [00440, 01251], lr: 0.000383, loss: 0.3800
2022-10-02 21:08:42 - train: epoch 0263, iter [00450, 01251], lr: 0.000383, loss: 0.4215
2022-10-02 21:09:00 - train: epoch 0263, iter [00460, 01251], lr: 0.000383, loss: 0.3956
2022-10-02 21:09:19 - train: epoch 0263, iter [00470, 01251], lr: 0.000383, loss: 0.4159
2022-10-02 21:09:37 - train: epoch 0263, iter [00480, 01251], lr: 0.000383, loss: 0.4237
2022-10-02 21:09:55 - train: epoch 0263, iter [00490, 01251], lr: 0.000383, loss: 0.4025
2022-10-02 21:10:13 - train: epoch 0263, iter [00500, 01251], lr: 0.000383, loss: 0.4015
2022-10-02 21:10:31 - train: epoch 0263, iter [00510, 01251], lr: 0.000383, loss: 0.4031
2022-10-02 21:10:49 - train: epoch 0263, iter [00520, 01251], lr: 0.000383, loss: 0.4141
2022-10-02 21:11:07 - train: epoch 0263, iter [00530, 01251], lr: 0.000383, loss: 0.4067
2022-10-02 21:11:25 - train: epoch 0263, iter [00540, 01251], lr: 0.000383, loss: 0.3940
2022-10-02 21:11:44 - train: epoch 0263, iter [00550, 01251], lr: 0.000383, loss: 0.3857
2022-10-02 21:12:02 - train: epoch 0263, iter [00560, 01251], lr: 0.000383, loss: 0.4139
2022-10-02 21:12:20 - train: epoch 0263, iter [00570, 01251], lr: 0.000383, loss: 0.4020
2022-10-02 21:12:38 - train: epoch 0263, iter [00580, 01251], lr: 0.000383, loss: 0.3981
2022-10-02 21:12:57 - train: epoch 0263, iter [00590, 01251], lr: 0.000383, loss: 0.3989
2022-10-02 21:13:15 - train: epoch 0263, iter [00600, 01251], lr: 0.000383, loss: 0.3959
2022-10-02 21:13:33 - train: epoch 0263, iter [00610, 01251], lr: 0.000383, loss: 0.4250
2022-10-02 21:13:51 - train: epoch 0263, iter [00620, 01251], lr: 0.000383, loss: 0.4053
2022-10-02 21:14:09 - train: epoch 0263, iter [00630, 01251], lr: 0.000383, loss: 0.3945
2022-10-02 21:14:27 - train: epoch 0263, iter [00640, 01251], lr: 0.000382, loss: 0.4068
2022-10-02 21:14:45 - train: epoch 0263, iter [00650, 01251], lr: 0.000382, loss: 0.4192
2022-10-02 21:15:03 - train: epoch 0263, iter [00660, 01251], lr: 0.000382, loss: 0.3824
2022-10-02 21:15:21 - train: epoch 0263, iter [00670, 01251], lr: 0.000382, loss: 0.3968
2022-10-02 21:15:40 - train: epoch 0263, iter [00680, 01251], lr: 0.000382, loss: 0.3853
2022-10-02 21:15:58 - train: epoch 0263, iter [00690, 01251], lr: 0.000382, loss: 0.4101
2022-10-02 21:16:16 - train: epoch 0263, iter [00700, 01251], lr: 0.000382, loss: 0.3772
2022-10-02 21:16:34 - train: epoch 0263, iter [00710, 01251], lr: 0.000382, loss: 0.3812
2022-10-02 21:16:52 - train: epoch 0263, iter [00720, 01251], lr: 0.000382, loss: 0.3916
2022-10-02 21:17:11 - train: epoch 0263, iter [00730, 01251], lr: 0.000382, loss: 0.4067
2022-10-02 21:17:29 - train: epoch 0263, iter [00740, 01251], lr: 0.000382, loss: 0.3934
2022-10-02 21:17:47 - train: epoch 0263, iter [00750, 01251], lr: 0.000382, loss: 0.4035
2022-10-02 21:18:05 - train: epoch 0263, iter [00760, 01251], lr: 0.000382, loss: 0.4121
2022-10-02 21:18:23 - train: epoch 0263, iter [00770, 01251], lr: 0.000382, loss: 0.3955
2022-10-02 21:18:41 - train: epoch 0263, iter [00780, 01251], lr: 0.000382, loss: 0.3962
2022-10-02 21:19:00 - train: epoch 0263, iter [00790, 01251], lr: 0.000382, loss: 0.3945
2022-10-02 21:19:18 - train: epoch 0263, iter [00800, 01251], lr: 0.000382, loss: 0.4148
2022-10-02 21:19:36 - train: epoch 0263, iter [00810, 01251], lr: 0.000382, loss: 0.4144
2022-10-02 21:19:55 - train: epoch 0263, iter [00820, 01251], lr: 0.000382, loss: 0.4168
2022-10-02 21:20:13 - train: epoch 0263, iter [00830, 01251], lr: 0.000382, loss: 0.3856
2022-10-02 21:20:31 - train: epoch 0263, iter [00840, 01251], lr: 0.000382, loss: 0.3915
2022-10-02 21:20:49 - train: epoch 0263, iter [00850, 01251], lr: 0.000382, loss: 0.3845
2022-10-02 21:21:07 - train: epoch 0263, iter [00860, 01251], lr: 0.000382, loss: 0.3935
2022-10-02 21:21:25 - train: epoch 0263, iter [00870, 01251], lr: 0.000382, loss: 0.3954
2022-10-02 21:21:44 - train: epoch 0263, iter [00880, 01251], lr: 0.000382, loss: 0.4106
2022-10-02 21:22:02 - train: epoch 0263, iter [00890, 01251], lr: 0.000382, loss: 0.3843
2022-10-02 21:22:20 - train: epoch 0263, iter [00900, 01251], lr: 0.000381, loss: 0.4070
2022-10-02 21:22:39 - train: epoch 0263, iter [00910, 01251], lr: 0.000381, loss: 0.3651
2022-10-02 21:22:57 - train: epoch 0263, iter [00920, 01251], lr: 0.000381, loss: 0.3923
2022-10-02 21:23:15 - train: epoch 0263, iter [00930, 01251], lr: 0.000381, loss: 0.3797
2022-10-02 21:23:33 - train: epoch 0263, iter [00940, 01251], lr: 0.000381, loss: 0.3963
2022-10-02 21:23:51 - train: epoch 0263, iter [00950, 01251], lr: 0.000381, loss: 0.4128
2022-10-02 21:24:09 - train: epoch 0263, iter [00960, 01251], lr: 0.000381, loss: 0.3916
2022-10-02 21:24:27 - train: epoch 0263, iter [00970, 01251], lr: 0.000381, loss: 0.4202
2022-10-02 21:24:46 - train: epoch 0263, iter [00980, 01251], lr: 0.000381, loss: 0.3943
2022-10-02 21:25:04 - train: epoch 0263, iter [00990, 01251], lr: 0.000381, loss: 0.3839
2022-10-02 21:25:23 - train: epoch 0263, iter [01000, 01251], lr: 0.000381, loss: 0.4290
2022-10-02 21:25:41 - train: epoch 0263, iter [01010, 01251], lr: 0.000381, loss: 0.4134
2022-10-02 21:25:59 - train: epoch 0263, iter [01020, 01251], lr: 0.000381, loss: 0.4088
2022-10-02 21:26:17 - train: epoch 0263, iter [01030, 01251], lr: 0.000381, loss: 0.4143
2022-10-02 21:26:35 - train: epoch 0263, iter [01040, 01251], lr: 0.000381, loss: 0.4020
2022-10-02 21:26:54 - train: epoch 0263, iter [01050, 01251], lr: 0.000381, loss: 0.4046
2022-10-02 21:27:12 - train: epoch 0263, iter [01060, 01251], lr: 0.000381, loss: 0.3877
2022-10-02 21:27:30 - train: epoch 0263, iter [01070, 01251], lr: 0.000381, loss: 0.4018
2022-10-02 21:27:48 - train: epoch 0263, iter [01080, 01251], lr: 0.000381, loss: 0.3935
2022-10-02 21:28:07 - train: epoch 0263, iter [01090, 01251], lr: 0.000381, loss: 0.3765
2022-10-02 21:28:25 - train: epoch 0263, iter [01100, 01251], lr: 0.000381, loss: 0.3751
2022-10-02 21:28:43 - train: epoch 0263, iter [01110, 01251], lr: 0.000381, loss: 0.4223
2022-10-02 21:29:01 - train: epoch 0263, iter [01120, 01251], lr: 0.000381, loss: 0.4095
2022-10-02 21:29:20 - train: epoch 0263, iter [01130, 01251], lr: 0.000381, loss: 0.4016
2022-10-02 21:29:38 - train: epoch 0263, iter [01140, 01251], lr: 0.000381, loss: 0.4088
2022-10-02 21:29:56 - train: epoch 0263, iter [01150, 01251], lr: 0.000380, loss: 0.4123
2022-10-02 21:30:15 - train: epoch 0263, iter [01160, 01251], lr: 0.000380, loss: 0.4122
2022-10-02 21:30:33 - train: epoch 0263, iter [01170, 01251], lr: 0.000380, loss: 0.4069
2022-10-02 21:30:52 - train: epoch 0263, iter [01180, 01251], lr: 0.000380, loss: 0.3799
2022-10-02 21:31:10 - train: epoch 0263, iter [01190, 01251], lr: 0.000380, loss: 0.3944
2022-10-02 21:31:28 - train: epoch 0263, iter [01200, 01251], lr: 0.000380, loss: 0.3978
2022-10-02 21:31:46 - train: epoch 0263, iter [01210, 01251], lr: 0.000380, loss: 0.3956
2022-10-02 21:32:04 - train: epoch 0263, iter [01220, 01251], lr: 0.000380, loss: 0.3923
2022-10-02 21:32:22 - train: epoch 0263, iter [01230, 01251], lr: 0.000380, loss: 0.4068
2022-10-02 21:32:40 - train: epoch 0263, iter [01240, 01251], lr: 0.000380, loss: 0.3885
2022-10-02 21:32:58 - train: epoch 0263, iter [01250, 01251], lr: 0.000380, loss: 0.3987
2022-10-02 21:33:01 - train: epoch 263, train_loss: 0.4014
2022-10-02 21:33:04 - until epoch: 263, best_loss: 0.4014
2022-10-02 21:33:04 - epoch 264 lr: 0.000380
2022-10-02 21:33:29 - train: epoch 0264, iter [00010, 01251], lr: 0.000380, loss: 0.4085
2022-10-02 21:33:47 - train: epoch 0264, iter [00020, 01251], lr: 0.000380, loss: 0.3927
2022-10-02 21:34:06 - train: epoch 0264, iter [00030, 01251], lr: 0.000380, loss: 0.3947
2022-10-02 21:34:24 - train: epoch 0264, iter [00040, 01251], lr: 0.000380, loss: 0.3849
2022-10-02 21:34:42 - train: epoch 0264, iter [00050, 01251], lr: 0.000380, loss: 0.4024
2022-10-02 21:35:00 - train: epoch 0264, iter [00060, 01251], lr: 0.000380, loss: 0.3798
2022-10-02 21:35:18 - train: epoch 0264, iter [00070, 01251], lr: 0.000380, loss: 0.3973
2022-10-02 21:35:36 - train: epoch 0264, iter [00080, 01251], lr: 0.000380, loss: 0.4019
2022-10-02 21:35:54 - train: epoch 0264, iter [00090, 01251], lr: 0.000380, loss: 0.4083
2022-10-02 21:36:12 - train: epoch 0264, iter [00100, 01251], lr: 0.000380, loss: 0.4049
2022-10-02 21:36:31 - train: epoch 0264, iter [00110, 01251], lr: 0.000380, loss: 0.4047
2022-10-02 21:36:49 - train: epoch 0264, iter [00120, 01251], lr: 0.000380, loss: 0.4071
2022-10-02 21:37:07 - train: epoch 0264, iter [00130, 01251], lr: 0.000380, loss: 0.3927
2022-10-02 21:37:25 - train: epoch 0264, iter [00140, 01251], lr: 0.000380, loss: 0.3913
2022-10-02 21:37:43 - train: epoch 0264, iter [00150, 01251], lr: 0.000380, loss: 0.3953
2022-10-02 21:38:01 - train: epoch 0264, iter [00160, 01251], lr: 0.000379, loss: 0.4023
2022-10-02 21:38:19 - train: epoch 0264, iter [00170, 01251], lr: 0.000379, loss: 0.4195
2022-10-02 21:38:38 - train: epoch 0264, iter [00180, 01251], lr: 0.000379, loss: 0.4117
2022-10-02 21:38:56 - train: epoch 0264, iter [00190, 01251], lr: 0.000379, loss: 0.4023
2022-10-02 21:39:14 - train: epoch 0264, iter [00200, 01251], lr: 0.000379, loss: 0.3953
2022-10-02 21:39:32 - train: epoch 0264, iter [00210, 01251], lr: 0.000379, loss: 0.4019
2022-10-02 21:39:50 - train: epoch 0264, iter [00220, 01251], lr: 0.000379, loss: 0.4177
2022-10-02 21:40:09 - train: epoch 0264, iter [00230, 01251], lr: 0.000379, loss: 0.3861
2022-10-02 21:40:27 - train: epoch 0264, iter [00240, 01251], lr: 0.000379, loss: 0.3979
2022-10-02 21:40:45 - train: epoch 0264, iter [00250, 01251], lr: 0.000379, loss: 0.4186
2022-10-02 21:41:03 - train: epoch 0264, iter [00260, 01251], lr: 0.000379, loss: 0.3978
2022-10-02 21:41:22 - train: epoch 0264, iter [00270, 01251], lr: 0.000379, loss: 0.4017
2022-10-02 21:41:40 - train: epoch 0264, iter [00280, 01251], lr: 0.000379, loss: 0.3962
2022-10-02 21:41:58 - train: epoch 0264, iter [00290, 01251], lr: 0.000379, loss: 0.4007
2022-10-02 21:42:16 - train: epoch 0264, iter [00300, 01251], lr: 0.000379, loss: 0.4053
2022-10-02 21:42:34 - train: epoch 0264, iter [00310, 01251], lr: 0.000379, loss: 0.3731
2022-10-02 21:42:52 - train: epoch 0264, iter [00320, 01251], lr: 0.000379, loss: 0.4138
2022-10-02 21:43:11 - train: epoch 0264, iter [00330, 01251], lr: 0.000379, loss: 0.3758
2022-10-02 21:43:29 - train: epoch 0264, iter [00340, 01251], lr: 0.000379, loss: 0.4108
2022-10-02 21:43:47 - train: epoch 0264, iter [00350, 01251], lr: 0.000379, loss: 0.4003
2022-10-02 21:44:05 - train: epoch 0264, iter [00360, 01251], lr: 0.000379, loss: 0.4036
2022-10-02 21:44:24 - train: epoch 0264, iter [00370, 01251], lr: 0.000379, loss: 0.4017
2022-10-02 21:44:42 - train: epoch 0264, iter [00380, 01251], lr: 0.000379, loss: 0.3949
2022-10-02 21:45:00 - train: epoch 0264, iter [00390, 01251], lr: 0.000379, loss: 0.4069
2022-10-02 21:45:18 - train: epoch 0264, iter [00400, 01251], lr: 0.000379, loss: 0.4108
2022-10-02 21:45:37 - train: epoch 0264, iter [00410, 01251], lr: 0.000379, loss: 0.4143
2022-10-02 21:45:55 - train: epoch 0264, iter [00420, 01251], lr: 0.000378, loss: 0.4307
2022-10-02 21:46:13 - train: epoch 0264, iter [00430, 01251], lr: 0.000378, loss: 0.3946
2022-10-02 21:46:32 - train: epoch 0264, iter [00440, 01251], lr: 0.000378, loss: 0.4044
2022-10-02 21:46:50 - train: epoch 0264, iter [00450, 01251], lr: 0.000378, loss: 0.3935
2022-10-02 21:47:08 - train: epoch 0264, iter [00460, 01251], lr: 0.000378, loss: 0.3782
2022-10-02 21:47:26 - train: epoch 0264, iter [00470, 01251], lr: 0.000378, loss: 0.4065
2022-10-02 21:47:44 - train: epoch 0264, iter [00480, 01251], lr: 0.000378, loss: 0.3943
2022-10-02 21:48:02 - train: epoch 0264, iter [00490, 01251], lr: 0.000378, loss: 0.3932
2022-10-02 21:48:21 - train: epoch 0264, iter [00500, 01251], lr: 0.000378, loss: 0.4009
2022-10-02 21:48:39 - train: epoch 0264, iter [00510, 01251], lr: 0.000378, loss: 0.4053
2022-10-02 21:48:57 - train: epoch 0264, iter [00520, 01251], lr: 0.000378, loss: 0.4052
2022-10-02 21:49:15 - train: epoch 0264, iter [00530, 01251], lr: 0.000378, loss: 0.3896
2022-10-02 21:49:33 - train: epoch 0264, iter [00540, 01251], lr: 0.000378, loss: 0.4054
2022-10-02 21:49:51 - train: epoch 0264, iter [00550, 01251], lr: 0.000378, loss: 0.4063
2022-10-02 21:50:10 - train: epoch 0264, iter [00560, 01251], lr: 0.000378, loss: 0.4052
2022-10-02 21:50:28 - train: epoch 0264, iter [00570, 01251], lr: 0.000378, loss: 0.3817
2022-10-02 21:50:46 - train: epoch 0264, iter [00580, 01251], lr: 0.000378, loss: 0.3990
2022-10-02 21:51:04 - train: epoch 0264, iter [00590, 01251], lr: 0.000378, loss: 0.3723
2022-10-02 21:51:22 - train: epoch 0264, iter [00600, 01251], lr: 0.000378, loss: 0.4076
2022-10-02 21:51:41 - train: epoch 0264, iter [00610, 01251], lr: 0.000378, loss: 0.4036
2022-10-02 21:51:59 - train: epoch 0264, iter [00620, 01251], lr: 0.000378, loss: 0.3896
2022-10-02 21:52:17 - train: epoch 0264, iter [00630, 01251], lr: 0.000378, loss: 0.4059
2022-10-02 21:52:35 - train: epoch 0264, iter [00640, 01251], lr: 0.000378, loss: 0.4152
2022-10-02 21:52:53 - train: epoch 0264, iter [00650, 01251], lr: 0.000378, loss: 0.4047
2022-10-02 21:53:11 - train: epoch 0264, iter [00660, 01251], lr: 0.000378, loss: 0.3870
2022-10-02 21:53:29 - train: epoch 0264, iter [00670, 01251], lr: 0.000377, loss: 0.4057
2022-10-02 21:53:48 - train: epoch 0264, iter [00680, 01251], lr: 0.000377, loss: 0.3997
2022-10-02 21:54:06 - train: epoch 0264, iter [00690, 01251], lr: 0.000377, loss: 0.4079
2022-10-02 21:54:24 - train: epoch 0264, iter [00700, 01251], lr: 0.000377, loss: 0.4268
2022-10-02 21:54:43 - train: epoch 0264, iter [00710, 01251], lr: 0.000377, loss: 0.4038
2022-10-02 21:55:01 - train: epoch 0264, iter [00720, 01251], lr: 0.000377, loss: 0.3997
2022-10-02 21:55:19 - train: epoch 0264, iter [00730, 01251], lr: 0.000377, loss: 0.4168
2022-10-02 21:55:37 - train: epoch 0264, iter [00740, 01251], lr: 0.000377, loss: 0.4082
2022-10-02 21:55:55 - train: epoch 0264, iter [00750, 01251], lr: 0.000377, loss: 0.4030
2022-10-02 21:56:13 - train: epoch 0264, iter [00760, 01251], lr: 0.000377, loss: 0.3969
2022-10-02 21:56:32 - train: epoch 0264, iter [00770, 01251], lr: 0.000377, loss: 0.3987
2022-10-02 21:56:50 - train: epoch 0264, iter [00780, 01251], lr: 0.000377, loss: 0.4101
2022-10-02 21:57:08 - train: epoch 0264, iter [00790, 01251], lr: 0.000377, loss: 0.3870
2022-10-02 21:57:27 - train: epoch 0264, iter [00800, 01251], lr: 0.000377, loss: 0.4084
2022-10-02 21:57:45 - train: epoch 0264, iter [00810, 01251], lr: 0.000377, loss: 0.4150
2022-10-02 21:58:03 - train: epoch 0264, iter [00820, 01251], lr: 0.000377, loss: 0.4017
2022-10-02 21:58:21 - train: epoch 0264, iter [00830, 01251], lr: 0.000377, loss: 0.4015
2022-10-02 21:58:40 - train: epoch 0264, iter [00840, 01251], lr: 0.000377, loss: 0.3939
2022-10-02 21:58:58 - train: epoch 0264, iter [00850, 01251], lr: 0.000377, loss: 0.3883
2022-10-02 21:59:16 - train: epoch 0264, iter [00860, 01251], lr: 0.000377, loss: 0.3993
2022-10-02 21:59:34 - train: epoch 0264, iter [00870, 01251], lr: 0.000377, loss: 0.3988
2022-10-02 21:59:52 - train: epoch 0264, iter [00880, 01251], lr: 0.000377, loss: 0.4094
2022-10-02 22:00:10 - train: epoch 0264, iter [00890, 01251], lr: 0.000377, loss: 0.3976
2022-10-02 22:00:29 - train: epoch 0264, iter [00900, 01251], lr: 0.000377, loss: 0.3992
2022-10-02 22:00:47 - train: epoch 0264, iter [00910, 01251], lr: 0.000377, loss: 0.3896
2022-10-02 22:01:06 - train: epoch 0264, iter [00920, 01251], lr: 0.000377, loss: 0.3945
2022-10-02 22:01:24 - train: epoch 0264, iter [00930, 01251], lr: 0.000376, loss: 0.3997
2022-10-02 22:01:42 - train: epoch 0264, iter [00940, 01251], lr: 0.000376, loss: 0.3974
2022-10-02 22:02:00 - train: epoch 0264, iter [00950, 01251], lr: 0.000376, loss: 0.3987
2022-10-02 22:02:18 - train: epoch 0264, iter [00960, 01251], lr: 0.000376, loss: 0.4181
2022-10-02 22:02:37 - train: epoch 0264, iter [00970, 01251], lr: 0.000376, loss: 0.3849
2022-10-02 22:02:55 - train: epoch 0264, iter [00980, 01251], lr: 0.000376, loss: 0.4081
2022-10-02 22:03:13 - train: epoch 0264, iter [00990, 01251], lr: 0.000376, loss: 0.3980
2022-10-02 22:03:32 - train: epoch 0264, iter [01000, 01251], lr: 0.000376, loss: 0.3895
2022-10-02 22:03:50 - train: epoch 0264, iter [01010, 01251], lr: 0.000376, loss: 0.4029
2022-10-02 22:04:08 - train: epoch 0264, iter [01020, 01251], lr: 0.000376, loss: 0.4051
2022-10-02 22:04:26 - train: epoch 0264, iter [01030, 01251], lr: 0.000376, loss: 0.4159
2022-10-02 22:04:44 - train: epoch 0264, iter [01040, 01251], lr: 0.000376, loss: 0.3817
2022-10-02 22:05:02 - train: epoch 0264, iter [01050, 01251], lr: 0.000376, loss: 0.4026
2022-10-02 22:05:21 - train: epoch 0264, iter [01060, 01251], lr: 0.000376, loss: 0.3908
2022-10-02 22:05:39 - train: epoch 0264, iter [01070, 01251], lr: 0.000376, loss: 0.4309
2022-10-02 22:05:57 - train: epoch 0264, iter [01080, 01251], lr: 0.000376, loss: 0.3878
2022-10-02 22:06:15 - train: epoch 0264, iter [01090, 01251], lr: 0.000376, loss: 0.3974
2022-10-02 22:06:34 - train: epoch 0264, iter [01100, 01251], lr: 0.000376, loss: 0.3861
2022-10-02 22:06:52 - train: epoch 0264, iter [01110, 01251], lr: 0.000376, loss: 0.3986
2022-10-02 22:07:10 - train: epoch 0264, iter [01120, 01251], lr: 0.000376, loss: 0.3861
2022-10-02 22:07:29 - train: epoch 0264, iter [01130, 01251], lr: 0.000376, loss: 0.3878
2022-10-02 22:07:47 - train: epoch 0264, iter [01140, 01251], lr: 0.000376, loss: 0.4072
2022-10-02 22:08:05 - train: epoch 0264, iter [01150, 01251], lr: 0.000376, loss: 0.3948
2022-10-02 22:08:24 - train: epoch 0264, iter [01160, 01251], lr: 0.000376, loss: 0.3872
2022-10-02 22:08:42 - train: epoch 0264, iter [01170, 01251], lr: 0.000376, loss: 0.4041
2022-10-02 22:09:00 - train: epoch 0264, iter [01180, 01251], lr: 0.000376, loss: 0.4063
2022-10-02 22:09:19 - train: epoch 0264, iter [01190, 01251], lr: 0.000375, loss: 0.4036
2022-10-02 22:09:37 - train: epoch 0264, iter [01200, 01251], lr: 0.000375, loss: 0.4199
2022-10-02 22:09:55 - train: epoch 0264, iter [01210, 01251], lr: 0.000375, loss: 0.4111
2022-10-02 22:10:13 - train: epoch 0264, iter [01220, 01251], lr: 0.000375, loss: 0.3982
2022-10-02 22:10:32 - train: epoch 0264, iter [01230, 01251], lr: 0.000375, loss: 0.3963
2022-10-02 22:10:50 - train: epoch 0264, iter [01240, 01251], lr: 0.000375, loss: 0.3923
2022-10-02 22:11:08 - train: epoch 0264, iter [01250, 01251], lr: 0.000375, loss: 0.4246
2022-10-02 22:11:11 - train: epoch 264, train_loss: 0.4015
2022-10-02 22:11:13 - until epoch: 264, best_loss: 0.4014
2022-10-02 22:11:13 - epoch 265 lr: 0.000375
2022-10-02 22:11:38 - train: epoch 0265, iter [00010, 01251], lr: 0.000375, loss: 0.3906
2022-10-02 22:11:57 - train: epoch 0265, iter [00020, 01251], lr: 0.000375, loss: 0.3983
2022-10-02 22:12:15 - train: epoch 0265, iter [00030, 01251], lr: 0.000375, loss: 0.3987
2022-10-02 22:12:33 - train: epoch 0265, iter [00040, 01251], lr: 0.000375, loss: 0.3956
2022-10-02 22:12:51 - train: epoch 0265, iter [00050, 01251], lr: 0.000375, loss: 0.3913
2022-10-02 22:13:09 - train: epoch 0265, iter [00060, 01251], lr: 0.000375, loss: 0.4145
2022-10-02 22:13:27 - train: epoch 0265, iter [00070, 01251], lr: 0.000375, loss: 0.3800
2022-10-02 22:13:45 - train: epoch 0265, iter [00080, 01251], lr: 0.000375, loss: 0.4029
2022-10-02 22:14:04 - train: epoch 0265, iter [00090, 01251], lr: 0.000375, loss: 0.4240
2022-10-02 22:14:22 - train: epoch 0265, iter [00100, 01251], lr: 0.000375, loss: 0.3828
2022-10-02 22:14:40 - train: epoch 0265, iter [00110, 01251], lr: 0.000375, loss: 0.4080
2022-10-02 22:14:58 - train: epoch 0265, iter [00120, 01251], lr: 0.000375, loss: 0.4003
2022-10-02 22:15:16 - train: epoch 0265, iter [00130, 01251], lr: 0.000375, loss: 0.3932
2022-10-02 22:15:35 - train: epoch 0265, iter [00140, 01251], lr: 0.000375, loss: 0.3990
2022-10-02 22:15:53 - train: epoch 0265, iter [00150, 01251], lr: 0.000375, loss: 0.3899
2022-10-02 22:16:11 - train: epoch 0265, iter [00160, 01251], lr: 0.000375, loss: 0.3970
2022-10-02 22:16:29 - train: epoch 0265, iter [00170, 01251], lr: 0.000375, loss: 0.4238
2022-10-02 22:16:48 - train: epoch 0265, iter [00180, 01251], lr: 0.000375, loss: 0.4283
2022-10-02 22:17:06 - train: epoch 0265, iter [00190, 01251], lr: 0.000374, loss: 0.4096
2022-10-02 22:17:24 - train: epoch 0265, iter [00200, 01251], lr: 0.000374, loss: 0.4054
2022-10-02 22:17:42 - train: epoch 0265, iter [00210, 01251], lr: 0.000374, loss: 0.4017
2022-10-02 22:18:01 - train: epoch 0265, iter [00220, 01251], lr: 0.000374, loss: 0.3860
2022-10-02 22:18:19 - train: epoch 0265, iter [00230, 01251], lr: 0.000374, loss: 0.4028
2022-10-02 22:18:37 - train: epoch 0265, iter [00240, 01251], lr: 0.000374, loss: 0.4036
2022-10-02 22:18:55 - train: epoch 0265, iter [00250, 01251], lr: 0.000374, loss: 0.4024
2022-10-02 22:19:13 - train: epoch 0265, iter [00260, 01251], lr: 0.000374, loss: 0.3793
2022-10-02 22:19:32 - train: epoch 0265, iter [00270, 01251], lr: 0.000374, loss: 0.4121
2022-10-02 22:19:50 - train: epoch 0265, iter [00280, 01251], lr: 0.000374, loss: 0.3981
2022-10-02 22:20:08 - train: epoch 0265, iter [00290, 01251], lr: 0.000374, loss: 0.3996
2022-10-02 22:20:27 - train: epoch 0265, iter [00300, 01251], lr: 0.000374, loss: 0.3769
2022-10-02 22:20:45 - train: epoch 0265, iter [00310, 01251], lr: 0.000374, loss: 0.4140
2022-10-02 22:21:03 - train: epoch 0265, iter [00320, 01251], lr: 0.000374, loss: 0.3860
2022-10-02 22:21:21 - train: epoch 0265, iter [00330, 01251], lr: 0.000374, loss: 0.4105
2022-10-02 22:21:40 - train: epoch 0265, iter [00340, 01251], lr: 0.000374, loss: 0.3946
2022-10-02 22:21:58 - train: epoch 0265, iter [00350, 01251], lr: 0.000374, loss: 0.4124
2022-10-02 22:22:16 - train: epoch 0265, iter [00360, 01251], lr: 0.000374, loss: 0.3811
2022-10-02 22:22:35 - train: epoch 0265, iter [00370, 01251], lr: 0.000374, loss: 0.4017
2022-10-02 22:22:53 - train: epoch 0265, iter [00380, 01251], lr: 0.000374, loss: 0.4050
2022-10-02 22:23:11 - train: epoch 0265, iter [00390, 01251], lr: 0.000374, loss: 0.3990
2022-10-02 22:23:29 - train: epoch 0265, iter [00400, 01251], lr: 0.000374, loss: 0.3941
2022-10-02 22:23:48 - train: epoch 0265, iter [00410, 01251], lr: 0.000374, loss: 0.3876
2022-10-02 22:24:06 - train: epoch 0265, iter [00420, 01251], lr: 0.000374, loss: 0.4063
2022-10-02 22:24:24 - train: epoch 0265, iter [00430, 01251], lr: 0.000374, loss: 0.4143
2022-10-02 22:24:43 - train: epoch 0265, iter [00440, 01251], lr: 0.000374, loss: 0.3769
2022-10-02 22:25:01 - train: epoch 0265, iter [00450, 01251], lr: 0.000373, loss: 0.3972
2022-10-02 22:25:19 - train: epoch 0265, iter [00460, 01251], lr: 0.000373, loss: 0.4108
2022-10-02 22:25:37 - train: epoch 0265, iter [00470, 01251], lr: 0.000373, loss: 0.3907
2022-10-02 22:25:56 - train: epoch 0265, iter [00480, 01251], lr: 0.000373, loss: 0.3863
2022-10-02 22:26:14 - train: epoch 0265, iter [00490, 01251], lr: 0.000373, loss: 0.4084
2022-10-02 22:26:33 - train: epoch 0265, iter [00500, 01251], lr: 0.000373, loss: 0.4041
2022-10-02 22:26:51 - train: epoch 0265, iter [00510, 01251], lr: 0.000373, loss: 0.3897
2022-10-02 22:27:09 - train: epoch 0265, iter [00520, 01251], lr: 0.000373, loss: 0.3937
2022-10-02 22:27:27 - train: epoch 0265, iter [00530, 01251], lr: 0.000373, loss: 0.3927
2022-10-02 22:27:46 - train: epoch 0265, iter [00540, 01251], lr: 0.000373, loss: 0.3923
2022-10-02 22:28:04 - train: epoch 0265, iter [00550, 01251], lr: 0.000373, loss: 0.4012
2022-10-02 22:28:22 - train: epoch 0265, iter [00560, 01251], lr: 0.000373, loss: 0.4032
2022-10-02 22:28:41 - train: epoch 0265, iter [00570, 01251], lr: 0.000373, loss: 0.3927
2022-10-02 22:29:00 - train: epoch 0265, iter [00580, 01251], lr: 0.000373, loss: 0.4087
2022-10-02 22:29:18 - train: epoch 0265, iter [00590, 01251], lr: 0.000373, loss: 0.3984
2022-10-02 22:29:37 - train: epoch 0265, iter [00600, 01251], lr: 0.000373, loss: 0.4039
2022-10-02 22:29:55 - train: epoch 0265, iter [00610, 01251], lr: 0.000373, loss: 0.3945
2022-10-02 22:30:13 - train: epoch 0265, iter [00620, 01251], lr: 0.000373, loss: 0.4295
2022-10-02 22:30:32 - train: epoch 0265, iter [00630, 01251], lr: 0.000373, loss: 0.3939
2022-10-02 22:30:50 - train: epoch 0265, iter [00640, 01251], lr: 0.000373, loss: 0.3895
2022-10-02 22:31:08 - train: epoch 0265, iter [00650, 01251], lr: 0.000373, loss: 0.3896
2022-10-02 22:31:27 - train: epoch 0265, iter [00660, 01251], lr: 0.000373, loss: 0.4061
2022-10-02 22:31:45 - train: epoch 0265, iter [00670, 01251], lr: 0.000373, loss: 0.3889
2022-10-02 22:32:04 - train: epoch 0265, iter [00680, 01251], lr: 0.000373, loss: 0.3831
2022-10-02 22:32:22 - train: epoch 0265, iter [00690, 01251], lr: 0.000373, loss: 0.3972
2022-10-02 22:32:40 - train: epoch 0265, iter [00700, 01251], lr: 0.000373, loss: 0.4024
2022-10-02 22:32:59 - train: epoch 0265, iter [00710, 01251], lr: 0.000372, loss: 0.4133
2022-10-02 22:33:17 - train: epoch 0265, iter [00720, 01251], lr: 0.000372, loss: 0.3982
2022-10-02 22:33:35 - train: epoch 0265, iter [00730, 01251], lr: 0.000372, loss: 0.3940
2022-10-02 22:33:54 - train: epoch 0265, iter [00740, 01251], lr: 0.000372, loss: 0.3936
2022-10-02 22:34:12 - train: epoch 0265, iter [00750, 01251], lr: 0.000372, loss: 0.4082
2022-10-02 22:34:30 - train: epoch 0265, iter [00760, 01251], lr: 0.000372, loss: 0.3945
2022-10-02 22:34:48 - train: epoch 0265, iter [00770, 01251], lr: 0.000372, loss: 0.4053
2022-10-02 22:35:07 - train: epoch 0265, iter [00780, 01251], lr: 0.000372, loss: 0.3989
2022-10-02 22:35:25 - train: epoch 0265, iter [00790, 01251], lr: 0.000372, loss: 0.4052
2022-10-02 22:35:43 - train: epoch 0265, iter [00800, 01251], lr: 0.000372, loss: 0.3963
2022-10-02 22:36:02 - train: epoch 0265, iter [00810, 01251], lr: 0.000372, loss: 0.4085
2022-10-02 22:36:20 - train: epoch 0265, iter [00820, 01251], lr: 0.000372, loss: 0.3928
2022-10-02 22:36:38 - train: epoch 0265, iter [00830, 01251], lr: 0.000372, loss: 0.4043
2022-10-02 22:36:56 - train: epoch 0265, iter [00840, 01251], lr: 0.000372, loss: 0.3993
2022-10-02 22:37:15 - train: epoch 0265, iter [00850, 01251], lr: 0.000372, loss: 0.3881
2022-10-02 22:37:33 - train: epoch 0265, iter [00860, 01251], lr: 0.000372, loss: 0.3917
2022-10-02 22:37:51 - train: epoch 0265, iter [00870, 01251], lr: 0.000372, loss: 0.4109
2022-10-02 22:38:10 - train: epoch 0265, iter [00880, 01251], lr: 0.000372, loss: 0.4014
2022-10-02 22:38:28 - train: epoch 0265, iter [00890, 01251], lr: 0.000372, loss: 0.4063
2022-10-02 22:38:46 - train: epoch 0265, iter [00900, 01251], lr: 0.000372, loss: 0.4043
2022-10-02 22:39:04 - train: epoch 0265, iter [00910, 01251], lr: 0.000372, loss: 0.4009
2022-10-02 22:39:23 - train: epoch 0265, iter [00920, 01251], lr: 0.000372, loss: 0.4218
2022-10-02 22:39:41 - train: epoch 0265, iter [00930, 01251], lr: 0.000372, loss: 0.4133
2022-10-02 22:39:59 - train: epoch 0265, iter [00940, 01251], lr: 0.000372, loss: 0.3996
2022-10-02 22:40:17 - train: epoch 0265, iter [00950, 01251], lr: 0.000372, loss: 0.3988
2022-10-02 22:40:36 - train: epoch 0265, iter [00960, 01251], lr: 0.000372, loss: 0.4015
2022-10-02 22:40:54 - train: epoch 0265, iter [00970, 01251], lr: 0.000371, loss: 0.3990
2022-10-02 22:41:12 - train: epoch 0265, iter [00980, 01251], lr: 0.000371, loss: 0.3977
2022-10-02 22:41:30 - train: epoch 0265, iter [00990, 01251], lr: 0.000371, loss: 0.3917
2022-10-02 22:41:49 - train: epoch 0265, iter [01000, 01251], lr: 0.000371, loss: 0.4075
2022-10-02 22:42:07 - train: epoch 0265, iter [01010, 01251], lr: 0.000371, loss: 0.4155
2022-10-02 22:42:25 - train: epoch 0265, iter [01020, 01251], lr: 0.000371, loss: 0.3990
2022-10-02 22:42:44 - train: epoch 0265, iter [01030, 01251], lr: 0.000371, loss: 0.3960
2022-10-02 22:43:02 - train: epoch 0265, iter [01040, 01251], lr: 0.000371, loss: 0.3926
2022-10-02 22:43:20 - train: epoch 0265, iter [01050, 01251], lr: 0.000371, loss: 0.3783
2022-10-02 22:43:38 - train: epoch 0265, iter [01060, 01251], lr: 0.000371, loss: 0.4185
2022-10-02 22:43:57 - train: epoch 0265, iter [01070, 01251], lr: 0.000371, loss: 0.3892
2022-10-02 22:44:15 - train: epoch 0265, iter [01080, 01251], lr: 0.000371, loss: 0.4185
2022-10-02 22:44:33 - train: epoch 0265, iter [01090, 01251], lr: 0.000371, loss: 0.3952
2022-10-02 22:44:51 - train: epoch 0265, iter [01100, 01251], lr: 0.000371, loss: 0.3810
2022-10-02 22:45:09 - train: epoch 0265, iter [01110, 01251], lr: 0.000371, loss: 0.4007
2022-10-02 22:45:28 - train: epoch 0265, iter [01120, 01251], lr: 0.000371, loss: 0.4202
2022-10-02 22:45:46 - train: epoch 0265, iter [01130, 01251], lr: 0.000371, loss: 0.3967
2022-10-02 22:46:04 - train: epoch 0265, iter [01140, 01251], lr: 0.000371, loss: 0.3870
2022-10-02 22:46:22 - train: epoch 0265, iter [01150, 01251], lr: 0.000371, loss: 0.3921
2022-10-02 22:46:41 - train: epoch 0265, iter [01160, 01251], lr: 0.000371, loss: 0.4042
2022-10-02 22:46:59 - train: epoch 0265, iter [01170, 01251], lr: 0.000371, loss: 0.4048
2022-10-02 22:47:17 - train: epoch 0265, iter [01180, 01251], lr: 0.000371, loss: 0.4117
2022-10-02 22:47:35 - train: epoch 0265, iter [01190, 01251], lr: 0.000371, loss: 0.4210
2022-10-02 22:47:54 - train: epoch 0265, iter [01200, 01251], lr: 0.000371, loss: 0.3847
2022-10-02 22:48:12 - train: epoch 0265, iter [01210, 01251], lr: 0.000371, loss: 0.4017
2022-10-02 22:48:30 - train: epoch 0265, iter [01220, 01251], lr: 0.000371, loss: 0.3861
2022-10-02 22:48:49 - train: epoch 0265, iter [01230, 01251], lr: 0.000370, loss: 0.3887
2022-10-02 22:49:07 - train: epoch 0265, iter [01240, 01251], lr: 0.000370, loss: 0.4115
2022-10-02 22:49:25 - train: epoch 0265, iter [01250, 01251], lr: 0.000370, loss: 0.3926
2022-10-02 22:49:28 - train: epoch 265, train_loss: 0.4014
2022-10-02 22:49:31 - until epoch: 265, best_loss: 0.4014
2022-10-02 22:49:31 - epoch 266 lr: 0.000370
2022-10-02 22:49:56 - train: epoch 0266, iter [00010, 01251], lr: 0.000370, loss: 0.3980
2022-10-02 22:50:15 - train: epoch 0266, iter [00020, 01251], lr: 0.000370, loss: 0.3999
2022-10-02 22:50:33 - train: epoch 0266, iter [00030, 01251], lr: 0.000370, loss: 0.4151
2022-10-02 22:50:51 - train: epoch 0266, iter [00040, 01251], lr: 0.000370, loss: 0.3963
2022-10-02 22:51:09 - train: epoch 0266, iter [00050, 01251], lr: 0.000370, loss: 0.4073
2022-10-02 22:51:27 - train: epoch 0266, iter [00060, 01251], lr: 0.000370, loss: 0.3741
2022-10-02 22:51:45 - train: epoch 0266, iter [00070, 01251], lr: 0.000370, loss: 0.4035
2022-10-02 22:52:04 - train: epoch 0266, iter [00080, 01251], lr: 0.000370, loss: 0.4023
2022-10-02 22:52:22 - train: epoch 0266, iter [00090, 01251], lr: 0.000370, loss: 0.4148
2022-10-02 22:52:40 - train: epoch 0266, iter [00100, 01251], lr: 0.000370, loss: 0.4094
2022-10-02 22:52:58 - train: epoch 0266, iter [00110, 01251], lr: 0.000370, loss: 0.3995
2022-10-02 22:53:17 - train: epoch 0266, iter [00120, 01251], lr: 0.000370, loss: 0.3839
2022-10-02 22:53:35 - train: epoch 0266, iter [00130, 01251], lr: 0.000370, loss: 0.4018
2022-10-02 22:53:53 - train: epoch 0266, iter [00140, 01251], lr: 0.000370, loss: 0.3928
2022-10-02 22:54:11 - train: epoch 0266, iter [00150, 01251], lr: 0.000370, loss: 0.4079
2022-10-02 22:54:29 - train: epoch 0266, iter [00160, 01251], lr: 0.000370, loss: 0.3782
2022-10-02 22:54:47 - train: epoch 0266, iter [00170, 01251], lr: 0.000370, loss: 0.3829
2022-10-02 22:55:05 - train: epoch 0266, iter [00180, 01251], lr: 0.000370, loss: 0.3888
2022-10-02 22:55:23 - train: epoch 0266, iter [00190, 01251], lr: 0.000370, loss: 0.4053
2022-10-02 22:55:41 - train: epoch 0266, iter [00200, 01251], lr: 0.000370, loss: 0.4079
2022-10-02 22:56:00 - train: epoch 0266, iter [00210, 01251], lr: 0.000370, loss: 0.3919
2022-10-02 22:56:18 - train: epoch 0266, iter [00220, 01251], lr: 0.000370, loss: 0.4093
2022-10-02 22:56:36 - train: epoch 0266, iter [00230, 01251], lr: 0.000370, loss: 0.4015
2022-10-02 22:56:54 - train: epoch 0266, iter [00240, 01251], lr: 0.000369, loss: 0.3910
2022-10-02 22:57:12 - train: epoch 0266, iter [00250, 01251], lr: 0.000369, loss: 0.4066
2022-10-02 22:57:30 - train: epoch 0266, iter [00260, 01251], lr: 0.000369, loss: 0.4119
2022-10-02 22:57:48 - train: epoch 0266, iter [00270, 01251], lr: 0.000369, loss: 0.4165
2022-10-02 22:58:07 - train: epoch 0266, iter [00280, 01251], lr: 0.000369, loss: 0.3787
2022-10-02 22:58:25 - train: epoch 0266, iter [00290, 01251], lr: 0.000369, loss: 0.3990
2022-10-02 22:58:43 - train: epoch 0266, iter [00300, 01251], lr: 0.000369, loss: 0.3964
2022-10-02 22:59:01 - train: epoch 0266, iter [00310, 01251], lr: 0.000369, loss: 0.4001
2022-10-02 22:59:19 - train: epoch 0266, iter [00320, 01251], lr: 0.000369, loss: 0.4043
2022-10-02 22:59:38 - train: epoch 0266, iter [00330, 01251], lr: 0.000369, loss: 0.4135
2022-10-02 22:59:56 - train: epoch 0266, iter [00340, 01251], lr: 0.000369, loss: 0.3846
2022-10-02 23:00:14 - train: epoch 0266, iter [00350, 01251], lr: 0.000369, loss: 0.4229
2022-10-02 23:00:32 - train: epoch 0266, iter [00360, 01251], lr: 0.000369, loss: 0.4232
2022-10-02 23:00:50 - train: epoch 0266, iter [00370, 01251], lr: 0.000369, loss: 0.3842
2022-10-02 23:01:09 - train: epoch 0266, iter [00380, 01251], lr: 0.000369, loss: 0.4054
2022-10-02 23:01:27 - train: epoch 0266, iter [00390, 01251], lr: 0.000369, loss: 0.4161
2022-10-02 23:01:45 - train: epoch 0266, iter [00400, 01251], lr: 0.000369, loss: 0.3810
2022-10-02 23:02:03 - train: epoch 0266, iter [00410, 01251], lr: 0.000369, loss: 0.3926
2022-10-02 23:02:21 - train: epoch 0266, iter [00420, 01251], lr: 0.000369, loss: 0.4058
2022-10-02 23:02:40 - train: epoch 0266, iter [00430, 01251], lr: 0.000369, loss: 0.3991
2022-10-02 23:02:58 - train: epoch 0266, iter [00440, 01251], lr: 0.000369, loss: 0.3966
2022-10-02 23:03:16 - train: epoch 0266, iter [00450, 01251], lr: 0.000369, loss: 0.4035
2022-10-02 23:03:34 - train: epoch 0266, iter [00460, 01251], lr: 0.000369, loss: 0.4010
2022-10-02 23:03:53 - train: epoch 0266, iter [00470, 01251], lr: 0.000369, loss: 0.4095
2022-10-02 23:04:11 - train: epoch 0266, iter [00480, 01251], lr: 0.000369, loss: 0.4071
2022-10-02 23:04:29 - train: epoch 0266, iter [00490, 01251], lr: 0.000368, loss: 0.4007
2022-10-02 23:04:48 - train: epoch 0266, iter [00500, 01251], lr: 0.000368, loss: 0.3893
2022-10-02 23:05:06 - train: epoch 0266, iter [00510, 01251], lr: 0.000368, loss: 0.4130
2022-10-02 23:05:24 - train: epoch 0266, iter [00520, 01251], lr: 0.000368, loss: 0.3965
2022-10-02 23:05:42 - train: epoch 0266, iter [00530, 01251], lr: 0.000368, loss: 0.4075
2022-10-02 23:06:00 - train: epoch 0266, iter [00540, 01251], lr: 0.000368, loss: 0.3751
2022-10-02 23:06:19 - train: epoch 0266, iter [00550, 01251], lr: 0.000368, loss: 0.4062
2022-10-02 23:06:37 - train: epoch 0266, iter [00560, 01251], lr: 0.000368, loss: 0.3946
2022-10-02 23:06:55 - train: epoch 0266, iter [00570, 01251], lr: 0.000368, loss: 0.3986
2022-10-02 23:07:13 - train: epoch 0266, iter [00580, 01251], lr: 0.000368, loss: 0.4023
2022-10-02 23:07:32 - train: epoch 0266, iter [00590, 01251], lr: 0.000368, loss: 0.4257
2022-10-02 23:07:50 - train: epoch 0266, iter [00600, 01251], lr: 0.000368, loss: 0.4298
2022-10-02 23:08:08 - train: epoch 0266, iter [00610, 01251], lr: 0.000368, loss: 0.3941
2022-10-02 23:08:27 - train: epoch 0266, iter [00620, 01251], lr: 0.000368, loss: 0.3912
2022-10-02 23:08:45 - train: epoch 0266, iter [00630, 01251], lr: 0.000368, loss: 0.3872
2022-10-02 23:09:03 - train: epoch 0266, iter [00640, 01251], lr: 0.000368, loss: 0.4026
2022-10-02 23:09:21 - train: epoch 0266, iter [00650, 01251], lr: 0.000368, loss: 0.3755
2022-10-02 23:09:40 - train: epoch 0266, iter [00660, 01251], lr: 0.000368, loss: 0.4076
2022-10-02 23:09:58 - train: epoch 0266, iter [00670, 01251], lr: 0.000368, loss: 0.3892
2022-10-02 23:10:16 - train: epoch 0266, iter [00680, 01251], lr: 0.000368, loss: 0.4071
2022-10-02 23:10:34 - train: epoch 0266, iter [00690, 01251], lr: 0.000368, loss: 0.4302
2022-10-02 23:10:52 - train: epoch 0266, iter [00700, 01251], lr: 0.000368, loss: 0.4035
2022-10-02 23:11:11 - train: epoch 0266, iter [00710, 01251], lr: 0.000368, loss: 0.4075
2022-10-02 23:11:29 - train: epoch 0266, iter [00720, 01251], lr: 0.000368, loss: 0.3944
2022-10-02 23:11:47 - train: epoch 0266, iter [00730, 01251], lr: 0.000368, loss: 0.3943
2022-10-02 23:12:05 - train: epoch 0266, iter [00740, 01251], lr: 0.000368, loss: 0.3923
2022-10-02 23:12:24 - train: epoch 0266, iter [00750, 01251], lr: 0.000367, loss: 0.3928
2022-10-02 23:12:42 - train: epoch 0266, iter [00760, 01251], lr: 0.000367, loss: 0.3950
2022-10-02 23:13:00 - train: epoch 0266, iter [00770, 01251], lr: 0.000367, loss: 0.3902
2022-10-02 23:13:18 - train: epoch 0266, iter [00780, 01251], lr: 0.000367, loss: 0.4019
2022-10-02 23:13:36 - train: epoch 0266, iter [00790, 01251], lr: 0.000367, loss: 0.4032
2022-10-02 23:13:55 - train: epoch 0266, iter [00800, 01251], lr: 0.000367, loss: 0.4065
2022-10-02 23:14:13 - train: epoch 0266, iter [00810, 01251], lr: 0.000367, loss: 0.4011
2022-10-02 23:14:31 - train: epoch 0266, iter [00820, 01251], lr: 0.000367, loss: 0.4160
2022-10-02 23:14:49 - train: epoch 0266, iter [00830, 01251], lr: 0.000367, loss: 0.3859
2022-10-02 23:15:08 - train: epoch 0266, iter [00840, 01251], lr: 0.000367, loss: 0.4235
2022-10-02 23:15:26 - train: epoch 0266, iter [00850, 01251], lr: 0.000367, loss: 0.3910
2022-10-02 23:15:44 - train: epoch 0266, iter [00860, 01251], lr: 0.000367, loss: 0.3992
2022-10-02 23:16:02 - train: epoch 0266, iter [00870, 01251], lr: 0.000367, loss: 0.3765
2022-10-02 23:16:21 - train: epoch 0266, iter [00880, 01251], lr: 0.000367, loss: 0.4216
2022-10-02 23:16:39 - train: epoch 0266, iter [00890, 01251], lr: 0.000367, loss: 0.3975
2022-10-02 23:16:57 - train: epoch 0266, iter [00900, 01251], lr: 0.000367, loss: 0.3852
2022-10-02 23:17:15 - train: epoch 0266, iter [00910, 01251], lr: 0.000367, loss: 0.3884
2022-10-02 23:17:33 - train: epoch 0266, iter [00920, 01251], lr: 0.000367, loss: 0.4024
2022-10-02 23:17:52 - train: epoch 0266, iter [00930, 01251], lr: 0.000367, loss: 0.4161
2022-10-02 23:18:10 - train: epoch 0266, iter [00940, 01251], lr: 0.000367, loss: 0.4146
2022-10-02 23:18:28 - train: epoch 0266, iter [00950, 01251], lr: 0.000367, loss: 0.4049
2022-10-02 23:18:46 - train: epoch 0266, iter [00960, 01251], lr: 0.000367, loss: 0.4061
2022-10-02 23:19:05 - train: epoch 0266, iter [00970, 01251], lr: 0.000367, loss: 0.4015
2022-10-02 23:19:23 - train: epoch 0266, iter [00980, 01251], lr: 0.000367, loss: 0.3651
2022-10-02 23:19:41 - train: epoch 0266, iter [00990, 01251], lr: 0.000367, loss: 0.4003
2022-10-02 23:19:59 - train: epoch 0266, iter [01000, 01251], lr: 0.000367, loss: 0.4146
2022-10-02 23:20:17 - train: epoch 0266, iter [01010, 01251], lr: 0.000366, loss: 0.4098
2022-10-02 23:20:35 - train: epoch 0266, iter [01020, 01251], lr: 0.000366, loss: 0.3856
2022-10-02 23:20:53 - train: epoch 0266, iter [01030, 01251], lr: 0.000366, loss: 0.3729
2022-10-02 23:21:12 - train: epoch 0266, iter [01040, 01251], lr: 0.000366, loss: 0.3989
2022-10-02 23:21:30 - train: epoch 0266, iter [01050, 01251], lr: 0.000366, loss: 0.4179
2022-10-02 23:21:49 - train: epoch 0266, iter [01060, 01251], lr: 0.000366, loss: 0.4052
2022-10-02 23:22:07 - train: epoch 0266, iter [01070, 01251], lr: 0.000366, loss: 0.3937
2022-10-02 23:22:25 - train: epoch 0266, iter [01080, 01251], lr: 0.000366, loss: 0.4033
2022-10-02 23:22:44 - train: epoch 0266, iter [01090, 01251], lr: 0.000366, loss: 0.4067
2022-10-02 23:23:02 - train: epoch 0266, iter [01100, 01251], lr: 0.000366, loss: 0.4030
2022-10-02 23:23:20 - train: epoch 0266, iter [01110, 01251], lr: 0.000366, loss: 0.3975
2022-10-02 23:23:39 - train: epoch 0266, iter [01120, 01251], lr: 0.000366, loss: 0.4109
2022-10-02 23:23:57 - train: epoch 0266, iter [01130, 01251], lr: 0.000366, loss: 0.4037
2022-10-02 23:24:15 - train: epoch 0266, iter [01140, 01251], lr: 0.000366, loss: 0.3927
2022-10-02 23:24:33 - train: epoch 0266, iter [01150, 01251], lr: 0.000366, loss: 0.4177
2022-10-02 23:24:52 - train: epoch 0266, iter [01160, 01251], lr: 0.000366, loss: 0.3995
2022-10-02 23:25:10 - train: epoch 0266, iter [01170, 01251], lr: 0.000366, loss: 0.3986
2022-10-02 23:25:28 - train: epoch 0266, iter [01180, 01251], lr: 0.000366, loss: 0.4025
2022-10-02 23:25:47 - train: epoch 0266, iter [01190, 01251], lr: 0.000366, loss: 0.4094
2022-10-02 23:26:05 - train: epoch 0266, iter [01200, 01251], lr: 0.000366, loss: 0.3878
2022-10-02 23:26:23 - train: epoch 0266, iter [01210, 01251], lr: 0.000366, loss: 0.4072
2022-10-02 23:26:42 - train: epoch 0266, iter [01220, 01251], lr: 0.000366, loss: 0.4059
2022-10-02 23:27:00 - train: epoch 0266, iter [01230, 01251], lr: 0.000366, loss: 0.3808
2022-10-02 23:27:18 - train: epoch 0266, iter [01240, 01251], lr: 0.000366, loss: 0.3889
2022-10-02 23:27:36 - train: epoch 0266, iter [01250, 01251], lr: 0.000366, loss: 0.4168
2022-10-02 23:27:40 - train: epoch 266, train_loss: 0.4013
2022-10-02 23:27:42 - until epoch: 266, best_loss: 0.4013
2022-10-02 23:27:42 - epoch 267 lr: 0.000366
2022-10-02 23:28:07 - train: epoch 0267, iter [00010, 01251], lr: 0.000366, loss: 0.3934
2022-10-02 23:28:25 - train: epoch 0267, iter [00020, 01251], lr: 0.000365, loss: 0.4025
2022-10-02 23:28:43 - train: epoch 0267, iter [00030, 01251], lr: 0.000365, loss: 0.4133
2022-10-02 23:29:01 - train: epoch 0267, iter [00040, 01251], lr: 0.000365, loss: 0.3969
2022-10-02 23:29:20 - train: epoch 0267, iter [00050, 01251], lr: 0.000365, loss: 0.3938
2022-10-02 23:29:38 - train: epoch 0267, iter [00060, 01251], lr: 0.000365, loss: 0.4214
2022-10-02 23:29:56 - train: epoch 0267, iter [00070, 01251], lr: 0.000365, loss: 0.4036
2022-10-02 23:30:14 - train: epoch 0267, iter [00080, 01251], lr: 0.000365, loss: 0.4135
2022-10-02 23:30:33 - train: epoch 0267, iter [00090, 01251], lr: 0.000365, loss: 0.3994
2022-10-02 23:30:51 - train: epoch 0267, iter [00100, 01251], lr: 0.000365, loss: 0.3897
2022-10-02 23:31:09 - train: epoch 0267, iter [00110, 01251], lr: 0.000365, loss: 0.3790
2022-10-02 23:31:27 - train: epoch 0267, iter [00120, 01251], lr: 0.000365, loss: 0.3958
2022-10-02 23:31:45 - train: epoch 0267, iter [00130, 01251], lr: 0.000365, loss: 0.3972
2022-10-02 23:32:03 - train: epoch 0267, iter [00140, 01251], lr: 0.000365, loss: 0.3809
2022-10-02 23:32:22 - train: epoch 0267, iter [00150, 01251], lr: 0.000365, loss: 0.4016
2022-10-02 23:32:40 - train: epoch 0267, iter [00160, 01251], lr: 0.000365, loss: 0.4077
2022-10-02 23:32:58 - train: epoch 0267, iter [00170, 01251], lr: 0.000365, loss: 0.3958
2022-10-02 23:33:16 - train: epoch 0267, iter [00180, 01251], lr: 0.000365, loss: 0.4068
2022-10-02 23:33:35 - train: epoch 0267, iter [00190, 01251], lr: 0.000365, loss: 0.4015
2022-10-02 23:33:53 - train: epoch 0267, iter [00200, 01251], lr: 0.000365, loss: 0.4295
2022-10-02 23:34:11 - train: epoch 0267, iter [00210, 01251], lr: 0.000365, loss: 0.3956
2022-10-02 23:34:29 - train: epoch 0267, iter [00220, 01251], lr: 0.000365, loss: 0.3956
2022-10-02 23:34:48 - train: epoch 0267, iter [00230, 01251], lr: 0.000365, loss: 0.4012
2022-10-02 23:35:06 - train: epoch 0267, iter [00240, 01251], lr: 0.000365, loss: 0.4060
2022-10-02 23:35:24 - train: epoch 0267, iter [00250, 01251], lr: 0.000365, loss: 0.3886
2022-10-02 23:35:42 - train: epoch 0267, iter [00260, 01251], lr: 0.000365, loss: 0.3927
2022-10-02 23:36:00 - train: epoch 0267, iter [00270, 01251], lr: 0.000365, loss: 0.3955
2022-10-02 23:36:19 - train: epoch 0267, iter [00280, 01251], lr: 0.000364, loss: 0.4006
2022-10-02 23:36:37 - train: epoch 0267, iter [00290, 01251], lr: 0.000364, loss: 0.3883
2022-10-02 23:36:55 - train: epoch 0267, iter [00300, 01251], lr: 0.000364, loss: 0.4250
2022-10-02 23:37:13 - train: epoch 0267, iter [00310, 01251], lr: 0.000364, loss: 0.4166
2022-10-02 23:37:31 - train: epoch 0267, iter [00320, 01251], lr: 0.000364, loss: 0.4185
2022-10-02 23:37:50 - train: epoch 0267, iter [00330, 01251], lr: 0.000364, loss: 0.3978
2022-10-02 23:38:08 - train: epoch 0267, iter [00340, 01251], lr: 0.000364, loss: 0.4099
2022-10-02 23:38:26 - train: epoch 0267, iter [00350, 01251], lr: 0.000364, loss: 0.3982
2022-10-02 23:38:45 - train: epoch 0267, iter [00360, 01251], lr: 0.000364, loss: 0.4163
2022-10-02 23:39:03 - train: epoch 0267, iter [00370, 01251], lr: 0.000364, loss: 0.4000
2022-10-02 23:39:21 - train: epoch 0267, iter [00380, 01251], lr: 0.000364, loss: 0.3850
2022-10-02 23:39:39 - train: epoch 0267, iter [00390, 01251], lr: 0.000364, loss: 0.4061
2022-10-02 23:39:57 - train: epoch 0267, iter [00400, 01251], lr: 0.000364, loss: 0.4293
2022-10-02 23:40:16 - train: epoch 0267, iter [00410, 01251], lr: 0.000364, loss: 0.3893
2022-10-02 23:40:34 - train: epoch 0267, iter [00420, 01251], lr: 0.000364, loss: 0.4070
2022-10-02 23:40:52 - train: epoch 0267, iter [00430, 01251], lr: 0.000364, loss: 0.3942
2022-10-02 23:41:10 - train: epoch 0267, iter [00440, 01251], lr: 0.000364, loss: 0.3917
2022-10-02 23:41:28 - train: epoch 0267, iter [00450, 01251], lr: 0.000364, loss: 0.3992
2022-10-02 23:41:47 - train: epoch 0267, iter [00460, 01251], lr: 0.000364, loss: 0.3823
2022-10-02 23:42:05 - train: epoch 0267, iter [00470, 01251], lr: 0.000364, loss: 0.4025
2022-10-02 23:42:23 - train: epoch 0267, iter [00480, 01251], lr: 0.000364, loss: 0.4187
2022-10-02 23:42:41 - train: epoch 0267, iter [00490, 01251], lr: 0.000364, loss: 0.3890
2022-10-02 23:42:59 - train: epoch 0267, iter [00500, 01251], lr: 0.000364, loss: 0.4002
2022-10-02 23:43:17 - train: epoch 0267, iter [00510, 01251], lr: 0.000364, loss: 0.4171
2022-10-02 23:43:35 - train: epoch 0267, iter [00520, 01251], lr: 0.000364, loss: 0.4018
2022-10-02 23:43:54 - train: epoch 0267, iter [00530, 01251], lr: 0.000364, loss: 0.3842
2022-10-02 23:44:12 - train: epoch 0267, iter [00540, 01251], lr: 0.000363, loss: 0.4047
2022-10-02 23:44:30 - train: epoch 0267, iter [00550, 01251], lr: 0.000363, loss: 0.4072
2022-10-02 23:44:48 - train: epoch 0267, iter [00560, 01251], lr: 0.000363, loss: 0.4016
2022-10-02 23:45:06 - train: epoch 0267, iter [00570, 01251], lr: 0.000363, loss: 0.4069
2022-10-02 23:45:24 - train: epoch 0267, iter [00580, 01251], lr: 0.000363, loss: 0.4045
2022-10-02 23:45:43 - train: epoch 0267, iter [00590, 01251], lr: 0.000363, loss: 0.4038
2022-10-02 23:46:01 - train: epoch 0267, iter [00600, 01251], lr: 0.000363, loss: 0.4077
2022-10-02 23:46:19 - train: epoch 0267, iter [00610, 01251], lr: 0.000363, loss: 0.3991
2022-10-02 23:46:37 - train: epoch 0267, iter [00620, 01251], lr: 0.000363, loss: 0.4008
2022-10-02 23:46:55 - train: epoch 0267, iter [00630, 01251], lr: 0.000363, loss: 0.4206
2022-10-02 23:47:13 - train: epoch 0267, iter [00640, 01251], lr: 0.000363, loss: 0.4178
2022-10-02 23:47:31 - train: epoch 0267, iter [00650, 01251], lr: 0.000363, loss: 0.3897
2022-10-02 23:47:50 - train: epoch 0267, iter [00660, 01251], lr: 0.000363, loss: 0.3885
2022-10-02 23:48:08 - train: epoch 0267, iter [00670, 01251], lr: 0.000363, loss: 0.3996
2022-10-02 23:48:26 - train: epoch 0267, iter [00680, 01251], lr: 0.000363, loss: 0.4061
2022-10-02 23:48:44 - train: epoch 0267, iter [00690, 01251], lr: 0.000363, loss: 0.3959
2022-10-02 23:49:03 - train: epoch 0267, iter [00700, 01251], lr: 0.000363, loss: 0.3945
2022-10-02 23:49:21 - train: epoch 0267, iter [00710, 01251], lr: 0.000363, loss: 0.4156
2022-10-02 23:49:39 - train: epoch 0267, iter [00720, 01251], lr: 0.000363, loss: 0.3693
2022-10-02 23:49:57 - train: epoch 0267, iter [00730, 01251], lr: 0.000363, loss: 0.4064
2022-10-02 23:50:15 - train: epoch 0267, iter [00740, 01251], lr: 0.000363, loss: 0.3914
2022-10-02 23:50:33 - train: epoch 0267, iter [00750, 01251], lr: 0.000363, loss: 0.3936
2022-10-02 23:50:52 - train: epoch 0267, iter [00760, 01251], lr: 0.000363, loss: 0.3953
2022-10-02 23:51:10 - train: epoch 0267, iter [00770, 01251], lr: 0.000363, loss: 0.3852
2022-10-02 23:51:28 - train: epoch 0267, iter [00780, 01251], lr: 0.000363, loss: 0.4191
2022-10-02 23:51:46 - train: epoch 0267, iter [00790, 01251], lr: 0.000363, loss: 0.4106
2022-10-02 23:52:04 - train: epoch 0267, iter [00800, 01251], lr: 0.000362, loss: 0.3995
2022-10-02 23:52:22 - train: epoch 0267, iter [00810, 01251], lr: 0.000362, loss: 0.4138
2022-10-02 23:52:41 - train: epoch 0267, iter [00820, 01251], lr: 0.000362, loss: 0.3960
2022-10-02 23:52:59 - train: epoch 0267, iter [00830, 01251], lr: 0.000362, loss: 0.4019
2022-10-02 23:53:17 - train: epoch 0267, iter [00840, 01251], lr: 0.000362, loss: 0.3945
2022-10-02 23:53:35 - train: epoch 0267, iter [00850, 01251], lr: 0.000362, loss: 0.3866
2022-10-02 23:53:53 - train: epoch 0267, iter [00860, 01251], lr: 0.000362, loss: 0.3984
2022-10-02 23:54:12 - train: epoch 0267, iter [00870, 01251], lr: 0.000362, loss: 0.4123
2022-10-02 23:54:30 - train: epoch 0267, iter [00880, 01251], lr: 0.000362, loss: 0.4143
2022-10-02 23:54:48 - train: epoch 0267, iter [00890, 01251], lr: 0.000362, loss: 0.3985
2022-10-02 23:55:06 - train: epoch 0267, iter [00900, 01251], lr: 0.000362, loss: 0.4188
2022-10-02 23:55:24 - train: epoch 0267, iter [00910, 01251], lr: 0.000362, loss: 0.4112
2022-10-02 23:55:42 - train: epoch 0267, iter [00920, 01251], lr: 0.000362, loss: 0.3903
2022-10-02 23:56:01 - train: epoch 0267, iter [00930, 01251], lr: 0.000362, loss: 0.4002
2022-10-02 23:56:19 - train: epoch 0267, iter [00940, 01251], lr: 0.000362, loss: 0.3891
2022-10-02 23:56:37 - train: epoch 0267, iter [00950, 01251], lr: 0.000362, loss: 0.3940
2022-10-02 23:56:55 - train: epoch 0267, iter [00960, 01251], lr: 0.000362, loss: 0.4019
2022-10-02 23:57:13 - train: epoch 0267, iter [00970, 01251], lr: 0.000362, loss: 0.4047
2022-10-02 23:57:32 - train: epoch 0267, iter [00980, 01251], lr: 0.000362, loss: 0.4010
2022-10-02 23:57:50 - train: epoch 0267, iter [00990, 01251], lr: 0.000362, loss: 0.3960
2022-10-02 23:58:08 - train: epoch 0267, iter [01000, 01251], lr: 0.000362, loss: 0.4190
2022-10-02 23:58:26 - train: epoch 0267, iter [01010, 01251], lr: 0.000362, loss: 0.3976
2022-10-02 23:58:44 - train: epoch 0267, iter [01020, 01251], lr: 0.000362, loss: 0.4069
2022-10-02 23:59:03 - train: epoch 0267, iter [01030, 01251], lr: 0.000362, loss: 0.4005
2022-10-02 23:59:21 - train: epoch 0267, iter [01040, 01251], lr: 0.000362, loss: 0.3875
2022-10-02 23:59:39 - train: epoch 0267, iter [01050, 01251], lr: 0.000362, loss: 0.4093
2022-10-02 23:59:58 - train: epoch 0267, iter [01060, 01251], lr: 0.000361, loss: 0.4159
2022-10-03 00:00:16 - train: epoch 0267, iter [01070, 01251], lr: 0.000361, loss: 0.4050
2022-10-03 00:00:34 - train: epoch 0267, iter [01080, 01251], lr: 0.000361, loss: 0.4149
2022-10-03 00:00:52 - train: epoch 0267, iter [01090, 01251], lr: 0.000361, loss: 0.3933
2022-10-03 00:01:11 - train: epoch 0267, iter [01100, 01251], lr: 0.000361, loss: 0.3912
2022-10-03 00:01:29 - train: epoch 0267, iter [01110, 01251], lr: 0.000361, loss: 0.4025
2022-10-03 00:01:47 - train: epoch 0267, iter [01120, 01251], lr: 0.000361, loss: 0.4294
2022-10-03 00:02:05 - train: epoch 0267, iter [01130, 01251], lr: 0.000361, loss: 0.4344
2022-10-03 00:02:24 - train: epoch 0267, iter [01140, 01251], lr: 0.000361, loss: 0.4035
2022-10-03 00:02:42 - train: epoch 0267, iter [01150, 01251], lr: 0.000361, loss: 0.4048
2022-10-03 00:03:00 - train: epoch 0267, iter [01160, 01251], lr: 0.000361, loss: 0.3961
2022-10-03 00:03:18 - train: epoch 0267, iter [01170, 01251], lr: 0.000361, loss: 0.3823
2022-10-03 00:03:37 - train: epoch 0267, iter [01180, 01251], lr: 0.000361, loss: 0.3957
2022-10-03 00:03:55 - train: epoch 0267, iter [01190, 01251], lr: 0.000361, loss: 0.3845
2022-10-03 00:04:13 - train: epoch 0267, iter [01200, 01251], lr: 0.000361, loss: 0.3816
2022-10-03 00:04:31 - train: epoch 0267, iter [01210, 01251], lr: 0.000361, loss: 0.4071
2022-10-03 00:04:49 - train: epoch 0267, iter [01220, 01251], lr: 0.000361, loss: 0.4103
2022-10-03 00:05:08 - train: epoch 0267, iter [01230, 01251], lr: 0.000361, loss: 0.3973
2022-10-03 00:05:26 - train: epoch 0267, iter [01240, 01251], lr: 0.000361, loss: 0.4050
2022-10-03 00:05:43 - train: epoch 0267, iter [01250, 01251], lr: 0.000361, loss: 0.4194
2022-10-03 00:05:47 - train: epoch 267, train_loss: 0.4011
2022-10-03 00:05:49 - until epoch: 267, best_loss: 0.4011
2022-10-03 00:05:49 - epoch 268 lr: 0.000361
2022-10-03 00:06:15 - train: epoch 0268, iter [00010, 01251], lr: 0.000361, loss: 0.3867
2022-10-03 00:06:33 - train: epoch 0268, iter [00020, 01251], lr: 0.000361, loss: 0.3903
2022-10-03 00:06:51 - train: epoch 0268, iter [00030, 01251], lr: 0.000361, loss: 0.3916
2022-10-03 00:07:09 - train: epoch 0268, iter [00040, 01251], lr: 0.000361, loss: 0.3904
2022-10-03 00:07:27 - train: epoch 0268, iter [00050, 01251], lr: 0.000361, loss: 0.4040
2022-10-03 00:07:45 - train: epoch 0268, iter [00060, 01251], lr: 0.000361, loss: 0.3957
2022-10-03 00:08:04 - train: epoch 0268, iter [00070, 01251], lr: 0.000360, loss: 0.4067
2022-10-03 00:08:22 - train: epoch 0268, iter [00080, 01251], lr: 0.000360, loss: 0.4067
2022-10-03 00:08:40 - train: epoch 0268, iter [00090, 01251], lr: 0.000360, loss: 0.3938
2022-10-03 00:08:58 - train: epoch 0268, iter [00100, 01251], lr: 0.000360, loss: 0.3894
2022-10-03 00:09:16 - train: epoch 0268, iter [00110, 01251], lr: 0.000360, loss: 0.4299
2022-10-03 00:09:35 - train: epoch 0268, iter [00120, 01251], lr: 0.000360, loss: 0.4031
2022-10-03 00:09:53 - train: epoch 0268, iter [00130, 01251], lr: 0.000360, loss: 0.4327
2022-10-03 00:10:11 - train: epoch 0268, iter [00140, 01251], lr: 0.000360, loss: 0.3965
2022-10-03 00:10:29 - train: epoch 0268, iter [00150, 01251], lr: 0.000360, loss: 0.4164
2022-10-03 00:10:47 - train: epoch 0268, iter [00160, 01251], lr: 0.000360, loss: 0.3810
2022-10-03 00:11:05 - train: epoch 0268, iter [00170, 01251], lr: 0.000360, loss: 0.4018
2022-10-03 00:11:24 - train: epoch 0268, iter [00180, 01251], lr: 0.000360, loss: 0.4189
2022-10-03 00:11:42 - train: epoch 0268, iter [00190, 01251], lr: 0.000360, loss: 0.3837
2022-10-03 00:12:00 - train: epoch 0268, iter [00200, 01251], lr: 0.000360, loss: 0.3938
2022-10-03 00:12:18 - train: epoch 0268, iter [00210, 01251], lr: 0.000360, loss: 0.4144
2022-10-03 00:12:36 - train: epoch 0268, iter [00220, 01251], lr: 0.000360, loss: 0.3882
2022-10-03 00:12:54 - train: epoch 0268, iter [00230, 01251], lr: 0.000360, loss: 0.4197
2022-10-03 00:13:12 - train: epoch 0268, iter [00240, 01251], lr: 0.000360, loss: 0.4012
2022-10-03 00:13:30 - train: epoch 0268, iter [00250, 01251], lr: 0.000360, loss: 0.4082
2022-10-03 00:13:48 - train: epoch 0268, iter [00260, 01251], lr: 0.000360, loss: 0.4003
2022-10-03 00:14:06 - train: epoch 0268, iter [00270, 01251], lr: 0.000360, loss: 0.4045
2022-10-03 00:14:23 - train: epoch 0268, iter [00280, 01251], lr: 0.000360, loss: 0.3873
2022-10-03 00:14:41 - train: epoch 0268, iter [00290, 01251], lr: 0.000360, loss: 0.4032
2022-10-03 00:14:59 - train: epoch 0268, iter [00300, 01251], lr: 0.000360, loss: 0.3903
2022-10-03 00:15:17 - train: epoch 0268, iter [00310, 01251], lr: 0.000360, loss: 0.3885
2022-10-03 00:15:35 - train: epoch 0268, iter [00320, 01251], lr: 0.000360, loss: 0.3896
2022-10-03 00:15:53 - train: epoch 0268, iter [00330, 01251], lr: 0.000359, loss: 0.3932
2022-10-03 00:16:11 - train: epoch 0268, iter [00340, 01251], lr: 0.000359, loss: 0.4223
2022-10-03 00:16:29 - train: epoch 0268, iter [00350, 01251], lr: 0.000359, loss: 0.3990
2022-10-03 00:16:47 - train: epoch 0268, iter [00360, 01251], lr: 0.000359, loss: 0.4072
2022-10-03 00:17:06 - train: epoch 0268, iter [00370, 01251], lr: 0.000359, loss: 0.4077
2022-10-03 00:17:25 - train: epoch 0268, iter [00380, 01251], lr: 0.000359, loss: 0.3983
2022-10-03 00:17:44 - train: epoch 0268, iter [00390, 01251], lr: 0.000359, loss: 0.4032
2022-10-03 00:18:03 - train: epoch 0268, iter [00400, 01251], lr: 0.000359, loss: 0.3869
2022-10-03 00:18:22 - train: epoch 0268, iter [00410, 01251], lr: 0.000359, loss: 0.4040
2022-10-03 00:18:40 - train: epoch 0268, iter [00420, 01251], lr: 0.000359, loss: 0.4020
2022-10-03 00:18:58 - train: epoch 0268, iter [00430, 01251], lr: 0.000359, loss: 0.3971
2022-10-03 00:19:15 - train: epoch 0268, iter [00440, 01251], lr: 0.000359, loss: 0.3932
2022-10-03 00:19:33 - train: epoch 0268, iter [00450, 01251], lr: 0.000359, loss: 0.3987
2022-10-03 00:19:51 - train: epoch 0268, iter [00460, 01251], lr: 0.000359, loss: 0.3897
2022-10-03 00:20:09 - train: epoch 0268, iter [00470, 01251], lr: 0.000359, loss: 0.4210
2022-10-03 00:20:27 - train: epoch 0268, iter [00480, 01251], lr: 0.000359, loss: 0.4001
2022-10-03 00:20:45 - train: epoch 0268, iter [00490, 01251], lr: 0.000359, loss: 0.4150
2022-10-03 00:21:03 - train: epoch 0268, iter [00500, 01251], lr: 0.000359, loss: 0.4286
2022-10-03 00:21:21 - train: epoch 0268, iter [00510, 01251], lr: 0.000359, loss: 0.3960
2022-10-03 00:21:39 - train: epoch 0268, iter [00520, 01251], lr: 0.000359, loss: 0.4094
2022-10-03 00:21:57 - train: epoch 0268, iter [00530, 01251], lr: 0.000359, loss: 0.3843
2022-10-03 00:22:15 - train: epoch 0268, iter [00540, 01251], lr: 0.000359, loss: 0.4010
2022-10-03 00:22:33 - train: epoch 0268, iter [00550, 01251], lr: 0.000359, loss: 0.3918
2022-10-03 00:22:51 - train: epoch 0268, iter [00560, 01251], lr: 0.000359, loss: 0.3930
2022-10-03 00:23:09 - train: epoch 0268, iter [00570, 01251], lr: 0.000359, loss: 0.4092
2022-10-03 00:23:27 - train: epoch 0268, iter [00580, 01251], lr: 0.000359, loss: 0.4183
2022-10-03 00:23:45 - train: epoch 0268, iter [00590, 01251], lr: 0.000358, loss: 0.3934
2022-10-03 00:24:03 - train: epoch 0268, iter [00600, 01251], lr: 0.000358, loss: 0.4070
2022-10-03 00:24:21 - train: epoch 0268, iter [00610, 01251], lr: 0.000358, loss: 0.3971
2022-10-03 00:24:39 - train: epoch 0268, iter [00620, 01251], lr: 0.000358, loss: 0.3813
2022-10-03 00:24:57 - train: epoch 0268, iter [00630, 01251], lr: 0.000358, loss: 0.3966
2022-10-03 00:25:15 - train: epoch 0268, iter [00640, 01251], lr: 0.000358, loss: 0.4140
2022-10-03 00:25:33 - train: epoch 0268, iter [00650, 01251], lr: 0.000358, loss: 0.3925
2022-10-03 00:25:51 - train: epoch 0268, iter [00660, 01251], lr: 0.000358, loss: 0.3989
2022-10-03 00:26:09 - train: epoch 0268, iter [00670, 01251], lr: 0.000358, loss: 0.4005
2022-10-03 00:26:27 - train: epoch 0268, iter [00680, 01251], lr: 0.000358, loss: 0.4191
2022-10-03 00:26:45 - train: epoch 0268, iter [00690, 01251], lr: 0.000358, loss: 0.3961
2022-10-03 00:27:03 - train: epoch 0268, iter [00700, 01251], lr: 0.000358, loss: 0.3811
2022-10-03 00:27:21 - train: epoch 0268, iter [00710, 01251], lr: 0.000358, loss: 0.4024
2022-10-03 00:27:39 - train: epoch 0268, iter [00720, 01251], lr: 0.000358, loss: 0.3835
2022-10-03 00:27:57 - train: epoch 0268, iter [00730, 01251], lr: 0.000358, loss: 0.4062
2022-10-03 00:28:15 - train: epoch 0268, iter [00740, 01251], lr: 0.000358, loss: 0.3852
2022-10-03 00:28:33 - train: epoch 0268, iter [00750, 01251], lr: 0.000358, loss: 0.4024
2022-10-03 00:28:51 - train: epoch 0268, iter [00760, 01251], lr: 0.000358, loss: 0.3931
2022-10-03 00:29:09 - train: epoch 0268, iter [00770, 01251], lr: 0.000358, loss: 0.4012
2022-10-03 00:29:26 - train: epoch 0268, iter [00780, 01251], lr: 0.000358, loss: 0.3714
2022-10-03 00:29:44 - train: epoch 0268, iter [00790, 01251], lr: 0.000358, loss: 0.4086
2022-10-03 00:30:02 - train: epoch 0268, iter [00800, 01251], lr: 0.000358, loss: 0.4025
2022-10-03 00:30:20 - train: epoch 0268, iter [00810, 01251], lr: 0.000358, loss: 0.3912
2022-10-03 00:30:38 - train: epoch 0268, iter [00820, 01251], lr: 0.000358, loss: 0.3905
2022-10-03 00:30:56 - train: epoch 0268, iter [00830, 01251], lr: 0.000358, loss: 0.3888
2022-10-03 00:31:14 - train: epoch 0268, iter [00840, 01251], lr: 0.000358, loss: 0.3932
2022-10-03 00:31:32 - train: epoch 0268, iter [00850, 01251], lr: 0.000357, loss: 0.4211
2022-10-03 00:31:50 - train: epoch 0268, iter [00860, 01251], lr: 0.000357, loss: 0.3916
2022-10-03 00:32:08 - train: epoch 0268, iter [00870, 01251], lr: 0.000357, loss: 0.4013
2022-10-03 00:32:26 - train: epoch 0268, iter [00880, 01251], lr: 0.000357, loss: 0.4092
2022-10-03 00:32:44 - train: epoch 0268, iter [00890, 01251], lr: 0.000357, loss: 0.4123
2022-10-03 00:33:02 - train: epoch 0268, iter [00900, 01251], lr: 0.000357, loss: 0.4021
2022-10-03 00:33:20 - train: epoch 0268, iter [00910, 01251], lr: 0.000357, loss: 0.4202
2022-10-03 00:33:38 - train: epoch 0268, iter [00920, 01251], lr: 0.000357, loss: 0.3989
2022-10-03 00:33:56 - train: epoch 0268, iter [00930, 01251], lr: 0.000357, loss: 0.3855
2022-10-03 00:34:14 - train: epoch 0268, iter [00940, 01251], lr: 0.000357, loss: 0.4175
2022-10-03 00:34:32 - train: epoch 0268, iter [00950, 01251], lr: 0.000357, loss: 0.4012
2022-10-03 00:34:49 - train: epoch 0268, iter [00960, 01251], lr: 0.000357, loss: 0.3977
2022-10-03 00:35:08 - train: epoch 0268, iter [00970, 01251], lr: 0.000357, loss: 0.3907
2022-10-03 00:35:25 - train: epoch 0268, iter [00980, 01251], lr: 0.000357, loss: 0.3978
2022-10-03 00:35:43 - train: epoch 0268, iter [00990, 01251], lr: 0.000357, loss: 0.4001
2022-10-03 00:36:01 - train: epoch 0268, iter [01000, 01251], lr: 0.000357, loss: 0.4346
2022-10-03 00:36:19 - train: epoch 0268, iter [01010, 01251], lr: 0.000357, loss: 0.3962
2022-10-03 00:36:37 - train: epoch 0268, iter [01020, 01251], lr: 0.000357, loss: 0.4169
2022-10-03 00:36:55 - train: epoch 0268, iter [01030, 01251], lr: 0.000357, loss: 0.4101
2022-10-03 00:37:13 - train: epoch 0268, iter [01040, 01251], lr: 0.000357, loss: 0.3974
2022-10-03 00:37:31 - train: epoch 0268, iter [01050, 01251], lr: 0.000357, loss: 0.4057
2022-10-03 00:37:49 - train: epoch 0268, iter [01060, 01251], lr: 0.000357, loss: 0.4084
2022-10-03 00:38:07 - train: epoch 0268, iter [01070, 01251], lr: 0.000357, loss: 0.4293
2022-10-03 00:38:25 - train: epoch 0268, iter [01080, 01251], lr: 0.000357, loss: 0.4078
2022-10-03 00:38:43 - train: epoch 0268, iter [01090, 01251], lr: 0.000357, loss: 0.3849
2022-10-03 00:39:01 - train: epoch 0268, iter [01100, 01251], lr: 0.000357, loss: 0.4144
2022-10-03 00:39:19 - train: epoch 0268, iter [01110, 01251], lr: 0.000356, loss: 0.4215
2022-10-03 00:39:37 - train: epoch 0268, iter [01120, 01251], lr: 0.000356, loss: 0.4064
2022-10-03 00:39:55 - train: epoch 0268, iter [01130, 01251], lr: 0.000356, loss: 0.4067
2022-10-03 00:40:13 - train: epoch 0268, iter [01140, 01251], lr: 0.000356, loss: 0.3848
2022-10-03 00:40:31 - train: epoch 0268, iter [01150, 01251], lr: 0.000356, loss: 0.3802
2022-10-03 00:40:49 - train: epoch 0268, iter [01160, 01251], lr: 0.000356, loss: 0.4020
2022-10-03 00:41:07 - train: epoch 0268, iter [01170, 01251], lr: 0.000356, loss: 0.4226
2022-10-03 00:41:25 - train: epoch 0268, iter [01180, 01251], lr: 0.000356, loss: 0.3943
2022-10-03 00:41:43 - train: epoch 0268, iter [01190, 01251], lr: 0.000356, loss: 0.3994
2022-10-03 00:42:01 - train: epoch 0268, iter [01200, 01251], lr: 0.000356, loss: 0.3996
2022-10-03 00:42:19 - train: epoch 0268, iter [01210, 01251], lr: 0.000356, loss: 0.4124
2022-10-03 00:42:37 - train: epoch 0268, iter [01220, 01251], lr: 0.000356, loss: 0.3896
2022-10-03 00:42:55 - train: epoch 0268, iter [01230, 01251], lr: 0.000356, loss: 0.4182
2022-10-03 00:43:13 - train: epoch 0268, iter [01240, 01251], lr: 0.000356, loss: 0.3959
2022-10-03 00:43:30 - train: epoch 0268, iter [01250, 01251], lr: 0.000356, loss: 0.4007
2022-10-03 00:43:34 - train: epoch 268, train_loss: 0.4010
2022-10-03 00:43:37 - until epoch: 268, best_loss: 0.4010
2022-10-03 00:43:37 - epoch 269 lr: 0.000356
2022-10-03 00:44:02 - train: epoch 0269, iter [00010, 01251], lr: 0.000356, loss: 0.3865
2022-10-03 00:44:20 - train: epoch 0269, iter [00020, 01251], lr: 0.000356, loss: 0.4072
2022-10-03 00:44:38 - train: epoch 0269, iter [00030, 01251], lr: 0.000356, loss: 0.4190
2022-10-03 00:44:56 - train: epoch 0269, iter [00040, 01251], lr: 0.000356, loss: 0.4113
2022-10-03 00:45:14 - train: epoch 0269, iter [00050, 01251], lr: 0.000356, loss: 0.3842
2022-10-03 00:45:31 - train: epoch 0269, iter [00060, 01251], lr: 0.000356, loss: 0.4002
2022-10-03 00:45:49 - train: epoch 0269, iter [00070, 01251], lr: 0.000356, loss: 0.3918
2022-10-03 00:46:07 - train: epoch 0269, iter [00080, 01251], lr: 0.000356, loss: 0.3758
2022-10-03 00:46:25 - train: epoch 0269, iter [00090, 01251], lr: 0.000356, loss: 0.4013
2022-10-03 00:46:43 - train: epoch 0269, iter [00100, 01251], lr: 0.000356, loss: 0.4078
2022-10-03 00:47:01 - train: epoch 0269, iter [00110, 01251], lr: 0.000356, loss: 0.4036
2022-10-03 00:47:19 - train: epoch 0269, iter [00120, 01251], lr: 0.000355, loss: 0.4220
2022-10-03 00:47:37 - train: epoch 0269, iter [00130, 01251], lr: 0.000355, loss: 0.4113
2022-10-03 00:47:55 - train: epoch 0269, iter [00140, 01251], lr: 0.000355, loss: 0.4011
2022-10-03 00:48:12 - train: epoch 0269, iter [00150, 01251], lr: 0.000355, loss: 0.3894
2022-10-03 00:48:30 - train: epoch 0269, iter [00160, 01251], lr: 0.000355, loss: 0.4214
2022-10-03 00:48:48 - train: epoch 0269, iter [00170, 01251], lr: 0.000355, loss: 0.3953
2022-10-03 00:49:06 - train: epoch 0269, iter [00180, 01251], lr: 0.000355, loss: 0.4018
2022-10-03 00:49:24 - train: epoch 0269, iter [00190, 01251], lr: 0.000355, loss: 0.3949
2022-10-03 00:49:42 - train: epoch 0269, iter [00200, 01251], lr: 0.000355, loss: 0.3939
2022-10-03 00:49:59 - train: epoch 0269, iter [00210, 01251], lr: 0.000355, loss: 0.4269
2022-10-03 00:50:17 - train: epoch 0269, iter [00220, 01251], lr: 0.000355, loss: 0.4115
2022-10-03 00:50:35 - train: epoch 0269, iter [00230, 01251], lr: 0.000355, loss: 0.4122
2022-10-03 00:50:53 - train: epoch 0269, iter [00240, 01251], lr: 0.000355, loss: 0.3839
2022-10-03 00:51:11 - train: epoch 0269, iter [00250, 01251], lr: 0.000355, loss: 0.4069
2022-10-03 00:51:29 - train: epoch 0269, iter [00260, 01251], lr: 0.000355, loss: 0.4087
2022-10-03 00:51:47 - train: epoch 0269, iter [00270, 01251], lr: 0.000355, loss: 0.3940
2022-10-03 00:52:05 - train: epoch 0269, iter [00280, 01251], lr: 0.000355, loss: 0.4078
2022-10-03 00:52:23 - train: epoch 0269, iter [00290, 01251], lr: 0.000355, loss: 0.3914
2022-10-03 00:52:41 - train: epoch 0269, iter [00300, 01251], lr: 0.000355, loss: 0.4009
2022-10-03 00:52:59 - train: epoch 0269, iter [00310, 01251], lr: 0.000355, loss: 0.4121
2022-10-03 00:53:16 - train: epoch 0269, iter [00320, 01251], lr: 0.000355, loss: 0.4220
2022-10-03 00:53:34 - train: epoch 0269, iter [00330, 01251], lr: 0.000355, loss: 0.4044
2022-10-03 00:53:52 - train: epoch 0269, iter [00340, 01251], lr: 0.000355, loss: 0.4099
2022-10-03 00:54:10 - train: epoch 0269, iter [00350, 01251], lr: 0.000355, loss: 0.3745
2022-10-03 00:54:28 - train: epoch 0269, iter [00360, 01251], lr: 0.000355, loss: 0.4067
2022-10-03 00:54:46 - train: epoch 0269, iter [00370, 01251], lr: 0.000355, loss: 0.4086
2022-10-03 00:55:04 - train: epoch 0269, iter [00380, 01251], lr: 0.000355, loss: 0.3924
2022-10-03 00:55:22 - train: epoch 0269, iter [00390, 01251], lr: 0.000354, loss: 0.3747
2022-10-03 00:55:40 - train: epoch 0269, iter [00400, 01251], lr: 0.000354, loss: 0.3840
2022-10-03 00:55:58 - train: epoch 0269, iter [00410, 01251], lr: 0.000354, loss: 0.4048
2022-10-03 00:56:16 - train: epoch 0269, iter [00420, 01251], lr: 0.000354, loss: 0.3881
2022-10-03 00:56:34 - train: epoch 0269, iter [00430, 01251], lr: 0.000354, loss: 0.4089
2022-10-03 00:56:52 - train: epoch 0269, iter [00440, 01251], lr: 0.000354, loss: 0.4043
2022-10-03 00:57:10 - train: epoch 0269, iter [00450, 01251], lr: 0.000354, loss: 0.4257
2022-10-03 00:57:27 - train: epoch 0269, iter [00460, 01251], lr: 0.000354, loss: 0.3878
2022-10-03 00:57:45 - train: epoch 0269, iter [00470, 01251], lr: 0.000354, loss: 0.4201
2022-10-03 00:58:03 - train: epoch 0269, iter [00480, 01251], lr: 0.000354, loss: 0.4030
2022-10-03 00:58:21 - train: epoch 0269, iter [00490, 01251], lr: 0.000354, loss: 0.3882
2022-10-03 00:58:39 - train: epoch 0269, iter [00500, 01251], lr: 0.000354, loss: 0.3993
2022-10-03 00:58:57 - train: epoch 0269, iter [00510, 01251], lr: 0.000354, loss: 0.3979
2022-10-03 00:59:15 - train: epoch 0269, iter [00520, 01251], lr: 0.000354, loss: 0.3974
2022-10-03 00:59:33 - train: epoch 0269, iter [00530, 01251], lr: 0.000354, loss: 0.4072
2022-10-03 00:59:51 - train: epoch 0269, iter [00540, 01251], lr: 0.000354, loss: 0.4019
2022-10-03 01:00:09 - train: epoch 0269, iter [00550, 01251], lr: 0.000354, loss: 0.3971
2022-10-03 01:00:27 - train: epoch 0269, iter [00560, 01251], lr: 0.000354, loss: 0.4084
2022-10-03 01:00:45 - train: epoch 0269, iter [00570, 01251], lr: 0.000354, loss: 0.4162
2022-10-03 01:01:03 - train: epoch 0269, iter [00580, 01251], lr: 0.000354, loss: 0.4107
2022-10-03 01:01:21 - train: epoch 0269, iter [00590, 01251], lr: 0.000354, loss: 0.4031
2022-10-03 01:01:39 - train: epoch 0269, iter [00600, 01251], lr: 0.000354, loss: 0.4034
2022-10-03 01:01:57 - train: epoch 0269, iter [00610, 01251], lr: 0.000354, loss: 0.4162
2022-10-03 01:02:15 - train: epoch 0269, iter [00620, 01251], lr: 0.000354, loss: 0.3975
2022-10-03 01:02:33 - train: epoch 0269, iter [00630, 01251], lr: 0.000354, loss: 0.4141
2022-10-03 01:02:51 - train: epoch 0269, iter [00640, 01251], lr: 0.000354, loss: 0.3814
2022-10-03 01:03:09 - train: epoch 0269, iter [00650, 01251], lr: 0.000353, loss: 0.3937
2022-10-03 01:03:28 - train: epoch 0269, iter [00660, 01251], lr: 0.000353, loss: 0.3934
2022-10-03 01:03:46 - train: epoch 0269, iter [00670, 01251], lr: 0.000353, loss: 0.3974
2022-10-03 01:04:04 - train: epoch 0269, iter [00680, 01251], lr: 0.000353, loss: 0.4065
2022-10-03 01:04:22 - train: epoch 0269, iter [00690, 01251], lr: 0.000353, loss: 0.4020
2022-10-03 01:04:40 - train: epoch 0269, iter [00700, 01251], lr: 0.000353, loss: 0.4036
2022-10-03 01:04:58 - train: epoch 0269, iter [00710, 01251], lr: 0.000353, loss: 0.4071
2022-10-03 01:05:16 - train: epoch 0269, iter [00720, 01251], lr: 0.000353, loss: 0.4050
2022-10-03 01:05:34 - train: epoch 0269, iter [00730, 01251], lr: 0.000353, loss: 0.4132
2022-10-03 01:05:52 - train: epoch 0269, iter [00740, 01251], lr: 0.000353, loss: 0.3986
2022-10-03 01:06:10 - train: epoch 0269, iter [00750, 01251], lr: 0.000353, loss: 0.3984
2022-10-03 01:06:28 - train: epoch 0269, iter [00760, 01251], lr: 0.000353, loss: 0.4121
2022-10-03 01:06:46 - train: epoch 0269, iter [00770, 01251], lr: 0.000353, loss: 0.3997
2022-10-03 01:07:04 - train: epoch 0269, iter [00780, 01251], lr: 0.000353, loss: 0.3972
2022-10-03 01:07:22 - train: epoch 0269, iter [00790, 01251], lr: 0.000353, loss: 0.4061
2022-10-03 01:07:40 - train: epoch 0269, iter [00800, 01251], lr: 0.000353, loss: 0.4180
2022-10-03 01:07:58 - train: epoch 0269, iter [00810, 01251], lr: 0.000353, loss: 0.4126
2022-10-03 01:08:16 - train: epoch 0269, iter [00820, 01251], lr: 0.000353, loss: 0.4128
2022-10-03 01:08:34 - train: epoch 0269, iter [00830, 01251], lr: 0.000353, loss: 0.4018
2022-10-03 01:08:52 - train: epoch 0269, iter [00840, 01251], lr: 0.000353, loss: 0.3948
2022-10-03 01:09:09 - train: epoch 0269, iter [00850, 01251], lr: 0.000353, loss: 0.4135
2022-10-03 01:09:27 - train: epoch 0269, iter [00860, 01251], lr: 0.000353, loss: 0.4000
2022-10-03 01:09:46 - train: epoch 0269, iter [00870, 01251], lr: 0.000353, loss: 0.3883
2022-10-03 01:10:04 - train: epoch 0269, iter [00880, 01251], lr: 0.000353, loss: 0.4093
2022-10-03 01:10:22 - train: epoch 0269, iter [00890, 01251], lr: 0.000353, loss: 0.3971
2022-10-03 01:10:39 - train: epoch 0269, iter [00900, 01251], lr: 0.000353, loss: 0.4025
2022-10-03 01:10:57 - train: epoch 0269, iter [00910, 01251], lr: 0.000352, loss: 0.4043
2022-10-03 01:11:16 - train: epoch 0269, iter [00920, 01251], lr: 0.000352, loss: 0.3843
2022-10-03 01:11:34 - train: epoch 0269, iter [00930, 01251], lr: 0.000352, loss: 0.4192
2022-10-03 01:11:52 - train: epoch 0269, iter [00940, 01251], lr: 0.000352, loss: 0.4237
2022-10-03 01:12:09 - train: epoch 0269, iter [00950, 01251], lr: 0.000352, loss: 0.4084
2022-10-03 01:12:27 - train: epoch 0269, iter [00960, 01251], lr: 0.000352, loss: 0.3888
2022-10-03 01:12:46 - train: epoch 0269, iter [00970, 01251], lr: 0.000352, loss: 0.4060
2022-10-03 01:13:03 - train: epoch 0269, iter [00980, 01251], lr: 0.000352, loss: 0.4154
2022-10-03 01:13:21 - train: epoch 0269, iter [00990, 01251], lr: 0.000352, loss: 0.4093
2022-10-03 01:13:39 - train: epoch 0269, iter [01000, 01251], lr: 0.000352, loss: 0.3994
2022-10-03 01:13:58 - train: epoch 0269, iter [01010, 01251], lr: 0.000352, loss: 0.4079
2022-10-03 01:14:16 - train: epoch 0269, iter [01020, 01251], lr: 0.000352, loss: 0.3913
2022-10-03 01:14:34 - train: epoch 0269, iter [01030, 01251], lr: 0.000352, loss: 0.4044
2022-10-03 01:14:52 - train: epoch 0269, iter [01040, 01251], lr: 0.000352, loss: 0.3948
2022-10-03 01:15:10 - train: epoch 0269, iter [01050, 01251], lr: 0.000352, loss: 0.3721
2022-10-03 01:15:28 - train: epoch 0269, iter [01060, 01251], lr: 0.000352, loss: 0.4145
2022-10-03 01:15:46 - train: epoch 0269, iter [01070, 01251], lr: 0.000352, loss: 0.4043
2022-10-03 01:16:04 - train: epoch 0269, iter [01080, 01251], lr: 0.000352, loss: 0.3920
2022-10-03 01:16:22 - train: epoch 0269, iter [01090, 01251], lr: 0.000352, loss: 0.3711
2022-10-03 01:16:40 - train: epoch 0269, iter [01100, 01251], lr: 0.000352, loss: 0.3956
2022-10-03 01:16:58 - train: epoch 0269, iter [01110, 01251], lr: 0.000352, loss: 0.4089
2022-10-03 01:17:16 - train: epoch 0269, iter [01120, 01251], lr: 0.000352, loss: 0.3862
2022-10-03 01:17:34 - train: epoch 0269, iter [01130, 01251], lr: 0.000352, loss: 0.3944
2022-10-03 01:17:52 - train: epoch 0269, iter [01140, 01251], lr: 0.000352, loss: 0.3948
2022-10-03 01:18:10 - train: epoch 0269, iter [01150, 01251], lr: 0.000352, loss: 0.4113
2022-10-03 01:18:28 - train: epoch 0269, iter [01160, 01251], lr: 0.000352, loss: 0.4147
2022-10-03 01:18:46 - train: epoch 0269, iter [01170, 01251], lr: 0.000351, loss: 0.3996
2022-10-03 01:19:04 - train: epoch 0269, iter [01180, 01251], lr: 0.000351, loss: 0.3954
2022-10-03 01:19:22 - train: epoch 0269, iter [01190, 01251], lr: 0.000351, loss: 0.3936
2022-10-03 01:19:40 - train: epoch 0269, iter [01200, 01251], lr: 0.000351, loss: 0.4072
2022-10-03 01:19:58 - train: epoch 0269, iter [01210, 01251], lr: 0.000351, loss: 0.4016
2022-10-03 01:20:16 - train: epoch 0269, iter [01220, 01251], lr: 0.000351, loss: 0.4108
2022-10-03 01:20:34 - train: epoch 0269, iter [01230, 01251], lr: 0.000351, loss: 0.4067
2022-10-03 01:20:52 - train: epoch 0269, iter [01240, 01251], lr: 0.000351, loss: 0.4044
2022-10-03 01:21:10 - train: epoch 0269, iter [01250, 01251], lr: 0.000351, loss: 0.3868
2022-10-03 01:21:13 - train: epoch 269, train_loss: 0.4010
2022-10-03 01:21:16 - until epoch: 269, best_loss: 0.4010
2022-10-03 01:21:16 - epoch 270 lr: 0.000351
2022-10-03 01:21:41 - train: epoch 0270, iter [00010, 01251], lr: 0.000351, loss: 0.3930
2022-10-03 01:21:59 - train: epoch 0270, iter [00020, 01251], lr: 0.000351, loss: 0.4157
2022-10-03 01:22:17 - train: epoch 0270, iter [00030, 01251], lr: 0.000351, loss: 0.4006
2022-10-03 01:22:35 - train: epoch 0270, iter [00040, 01251], lr: 0.000351, loss: 0.4080
2022-10-03 01:22:53 - train: epoch 0270, iter [00050, 01251], lr: 0.000351, loss: 0.4120
2022-10-03 01:23:10 - train: epoch 0270, iter [00060, 01251], lr: 0.000351, loss: 0.4063
2022-10-03 01:23:28 - train: epoch 0270, iter [00070, 01251], lr: 0.000351, loss: 0.4045
2022-10-03 01:23:46 - train: epoch 0270, iter [00080, 01251], lr: 0.000351, loss: 0.4101
2022-10-03 01:24:04 - train: epoch 0270, iter [00090, 01251], lr: 0.000351, loss: 0.3959
2022-10-03 01:24:22 - train: epoch 0270, iter [00100, 01251], lr: 0.000351, loss: 0.4199
2022-10-03 01:24:40 - train: epoch 0270, iter [00110, 01251], lr: 0.000351, loss: 0.4125
2022-10-03 01:24:58 - train: epoch 0270, iter [00120, 01251], lr: 0.000351, loss: 0.3915
2022-10-03 01:25:16 - train: epoch 0270, iter [00130, 01251], lr: 0.000351, loss: 0.3967
2022-10-03 01:25:34 - train: epoch 0270, iter [00140, 01251], lr: 0.000351, loss: 0.4165
2022-10-03 01:25:52 - train: epoch 0270, iter [00150, 01251], lr: 0.000351, loss: 0.4094
2022-10-03 01:26:10 - train: epoch 0270, iter [00160, 01251], lr: 0.000351, loss: 0.4022
2022-10-03 01:26:28 - train: epoch 0270, iter [00170, 01251], lr: 0.000351, loss: 0.4027
2022-10-03 01:26:46 - train: epoch 0270, iter [00180, 01251], lr: 0.000350, loss: 0.4087
2022-10-03 01:27:04 - train: epoch 0270, iter [00190, 01251], lr: 0.000350, loss: 0.3885
2022-10-03 01:27:22 - train: epoch 0270, iter [00200, 01251], lr: 0.000350, loss: 0.3893
2022-10-03 01:27:40 - train: epoch 0270, iter [00210, 01251], lr: 0.000350, loss: 0.4097
2022-10-03 01:27:58 - train: epoch 0270, iter [00220, 01251], lr: 0.000350, loss: 0.4039
2022-10-03 01:28:15 - train: epoch 0270, iter [00230, 01251], lr: 0.000350, loss: 0.4107
2022-10-03 01:28:33 - train: epoch 0270, iter [00240, 01251], lr: 0.000350, loss: 0.4100
2022-10-03 01:28:51 - train: epoch 0270, iter [00250, 01251], lr: 0.000350, loss: 0.3912
2022-10-03 01:29:09 - train: epoch 0270, iter [00260, 01251], lr: 0.000350, loss: 0.4107
2022-10-03 01:29:27 - train: epoch 0270, iter [00270, 01251], lr: 0.000350, loss: 0.3735
2022-10-03 01:29:45 - train: epoch 0270, iter [00280, 01251], lr: 0.000350, loss: 0.4001
2022-10-03 01:30:03 - train: epoch 0270, iter [00290, 01251], lr: 0.000350, loss: 0.4087
2022-10-03 01:30:21 - train: epoch 0270, iter [00300, 01251], lr: 0.000350, loss: 0.4006
2022-10-03 01:30:39 - train: epoch 0270, iter [00310, 01251], lr: 0.000350, loss: 0.4052
2022-10-03 01:30:57 - train: epoch 0270, iter [00320, 01251], lr: 0.000350, loss: 0.3856
2022-10-03 01:31:15 - train: epoch 0270, iter [00330, 01251], lr: 0.000350, loss: 0.4093
2022-10-03 01:31:33 - train: epoch 0270, iter [00340, 01251], lr: 0.000350, loss: 0.3961
2022-10-03 01:31:50 - train: epoch 0270, iter [00350, 01251], lr: 0.000350, loss: 0.3823
2022-10-03 01:32:08 - train: epoch 0270, iter [00360, 01251], lr: 0.000350, loss: 0.4031
2022-10-03 01:32:26 - train: epoch 0270, iter [00370, 01251], lr: 0.000350, loss: 0.3918
2022-10-03 01:32:44 - train: epoch 0270, iter [00380, 01251], lr: 0.000350, loss: 0.4019
2022-10-03 01:33:02 - train: epoch 0270, iter [00390, 01251], lr: 0.000350, loss: 0.4210
2022-10-03 01:33:20 - train: epoch 0270, iter [00400, 01251], lr: 0.000350, loss: 0.4286
2022-10-03 01:33:38 - train: epoch 0270, iter [00410, 01251], lr: 0.000350, loss: 0.4014
2022-10-03 01:33:56 - train: epoch 0270, iter [00420, 01251], lr: 0.000350, loss: 0.3986
2022-10-03 01:34:14 - train: epoch 0270, iter [00430, 01251], lr: 0.000350, loss: 0.4155
2022-10-03 01:34:32 - train: epoch 0270, iter [00440, 01251], lr: 0.000350, loss: 0.3948
2022-10-03 01:34:50 - train: epoch 0270, iter [00450, 01251], lr: 0.000349, loss: 0.3823
2022-10-03 01:35:08 - train: epoch 0270, iter [00460, 01251], lr: 0.000349, loss: 0.3838
2022-10-03 01:35:26 - train: epoch 0270, iter [00470, 01251], lr: 0.000349, loss: 0.4057
2022-10-03 01:35:44 - train: epoch 0270, iter [00480, 01251], lr: 0.000349, loss: 0.4084
2022-10-03 01:36:02 - train: epoch 0270, iter [00490, 01251], lr: 0.000349, loss: 0.4194
2022-10-03 01:36:20 - train: epoch 0270, iter [00500, 01251], lr: 0.000349, loss: 0.3856
2022-10-03 01:36:38 - train: epoch 0270, iter [00510, 01251], lr: 0.000349, loss: 0.3832
2022-10-03 01:36:56 - train: epoch 0270, iter [00520, 01251], lr: 0.000349, loss: 0.3886
2022-10-03 01:37:14 - train: epoch 0270, iter [00530, 01251], lr: 0.000349, loss: 0.3903
2022-10-03 01:37:32 - train: epoch 0270, iter [00540, 01251], lr: 0.000349, loss: 0.3833
2022-10-03 01:37:50 - train: epoch 0270, iter [00550, 01251], lr: 0.000349, loss: 0.3935
2022-10-03 01:38:08 - train: epoch 0270, iter [00560, 01251], lr: 0.000349, loss: 0.3946
2022-10-03 01:38:25 - train: epoch 0270, iter [00570, 01251], lr: 0.000349, loss: 0.3956
2022-10-03 01:38:43 - train: epoch 0270, iter [00580, 01251], lr: 0.000349, loss: 0.4089
2022-10-03 01:39:01 - train: epoch 0270, iter [00590, 01251], lr: 0.000349, loss: 0.4145
2022-10-03 01:39:19 - train: epoch 0270, iter [00600, 01251], lr: 0.000349, loss: 0.4037
2022-10-03 01:39:37 - train: epoch 0270, iter [00610, 01251], lr: 0.000349, loss: 0.3764
2022-10-03 01:39:56 - train: epoch 0270, iter [00620, 01251], lr: 0.000349, loss: 0.3935
2022-10-03 01:40:14 - train: epoch 0270, iter [00630, 01251], lr: 0.000349, loss: 0.4087
2022-10-03 01:40:32 - train: epoch 0270, iter [00640, 01251], lr: 0.000349, loss: 0.4116
2022-10-03 01:40:50 - train: epoch 0270, iter [00650, 01251], lr: 0.000349, loss: 0.4249
2022-10-03 01:41:08 - train: epoch 0270, iter [00660, 01251], lr: 0.000349, loss: 0.4095
2022-10-03 01:41:26 - train: epoch 0270, iter [00670, 01251], lr: 0.000349, loss: 0.3931
2022-10-03 01:41:44 - train: epoch 0270, iter [00680, 01251], lr: 0.000349, loss: 0.3964
2022-10-03 01:42:02 - train: epoch 0270, iter [00690, 01251], lr: 0.000349, loss: 0.3992
2022-10-03 01:42:20 - train: epoch 0270, iter [00700, 01251], lr: 0.000349, loss: 0.3847
2022-10-03 01:42:38 - train: epoch 0270, iter [00710, 01251], lr: 0.000348, loss: 0.3988
2022-10-03 01:42:56 - train: epoch 0270, iter [00720, 01251], lr: 0.000348, loss: 0.4025
2022-10-03 01:43:14 - train: epoch 0270, iter [00730, 01251], lr: 0.000348, loss: 0.3882
2022-10-03 01:43:32 - train: epoch 0270, iter [00740, 01251], lr: 0.000348, loss: 0.3898
2022-10-03 01:43:51 - train: epoch 0270, iter [00750, 01251], lr: 0.000348, loss: 0.4116
2022-10-03 01:44:09 - train: epoch 0270, iter [00760, 01251], lr: 0.000348, loss: 0.4074
2022-10-03 01:44:27 - train: epoch 0270, iter [00770, 01251], lr: 0.000348, loss: 0.3864
2022-10-03 01:44:45 - train: epoch 0270, iter [00780, 01251], lr: 0.000348, loss: 0.3765
2022-10-03 01:45:03 - train: epoch 0270, iter [00790, 01251], lr: 0.000348, loss: 0.3912
2022-10-03 01:45:21 - train: epoch 0270, iter [00800, 01251], lr: 0.000348, loss: 0.4210
2022-10-03 01:45:39 - train: epoch 0270, iter [00810, 01251], lr: 0.000348, loss: 0.4048
2022-10-03 01:45:57 - train: epoch 0270, iter [00820, 01251], lr: 0.000348, loss: 0.4062
2022-10-03 01:46:15 - train: epoch 0270, iter [00830, 01251], lr: 0.000348, loss: 0.4116
2022-10-03 01:46:33 - train: epoch 0270, iter [00840, 01251], lr: 0.000348, loss: 0.4049
2022-10-03 01:46:51 - train: epoch 0270, iter [00850, 01251], lr: 0.000348, loss: 0.3952
2022-10-03 01:47:09 - train: epoch 0270, iter [00860, 01251], lr: 0.000348, loss: 0.4139
2022-10-03 01:47:27 - train: epoch 0270, iter [00870, 01251], lr: 0.000348, loss: 0.3957
2022-10-03 01:47:45 - train: epoch 0270, iter [00880, 01251], lr: 0.000348, loss: 0.3997
2022-10-03 01:48:02 - train: epoch 0270, iter [00890, 01251], lr: 0.000348, loss: 0.3886
2022-10-03 01:48:20 - train: epoch 0270, iter [00900, 01251], lr: 0.000348, loss: 0.3783
2022-10-03 01:48:38 - train: epoch 0270, iter [00910, 01251], lr: 0.000348, loss: 0.4041
2022-10-03 01:48:56 - train: epoch 0270, iter [00920, 01251], lr: 0.000348, loss: 0.4172
2022-10-03 01:49:14 - train: epoch 0270, iter [00930, 01251], lr: 0.000348, loss: 0.3923
2022-10-03 01:49:32 - train: epoch 0270, iter [00940, 01251], lr: 0.000348, loss: 0.3994
2022-10-03 01:49:50 - train: epoch 0270, iter [00950, 01251], lr: 0.000348, loss: 0.3920
2022-10-03 01:50:08 - train: epoch 0270, iter [00960, 01251], lr: 0.000348, loss: 0.3886
2022-10-03 01:50:27 - train: epoch 0270, iter [00970, 01251], lr: 0.000347, loss: 0.3927
2022-10-03 01:50:44 - train: epoch 0270, iter [00980, 01251], lr: 0.000347, loss: 0.3964
2022-10-03 01:51:03 - train: epoch 0270, iter [00990, 01251], lr: 0.000347, loss: 0.4059
2022-10-03 01:51:21 - train: epoch 0270, iter [01000, 01251], lr: 0.000347, loss: 0.4095
2022-10-03 01:51:39 - train: epoch 0270, iter [01010, 01251], lr: 0.000347, loss: 0.4005
2022-10-03 01:51:57 - train: epoch 0270, iter [01020, 01251], lr: 0.000347, loss: 0.3975
2022-10-03 01:52:15 - train: epoch 0270, iter [01030, 01251], lr: 0.000347, loss: 0.3931
2022-10-03 01:52:33 - train: epoch 0270, iter [01040, 01251], lr: 0.000347, loss: 0.4084
2022-10-03 01:52:51 - train: epoch 0270, iter [01050, 01251], lr: 0.000347, loss: 0.3921
2022-10-03 01:53:09 - train: epoch 0270, iter [01060, 01251], lr: 0.000347, loss: 0.3966
2022-10-03 01:53:26 - train: epoch 0270, iter [01070, 01251], lr: 0.000347, loss: 0.3962
2022-10-03 01:53:45 - train: epoch 0270, iter [01080, 01251], lr: 0.000347, loss: 0.4098
2022-10-03 01:54:03 - train: epoch 0270, iter [01090, 01251], lr: 0.000347, loss: 0.3994
2022-10-03 01:54:20 - train: epoch 0270, iter [01100, 01251], lr: 0.000347, loss: 0.3856
2022-10-03 01:54:38 - train: epoch 0270, iter [01110, 01251], lr: 0.000347, loss: 0.4022
2022-10-03 01:54:56 - train: epoch 0270, iter [01120, 01251], lr: 0.000347, loss: 0.3956
2022-10-03 01:55:14 - train: epoch 0270, iter [01130, 01251], lr: 0.000347, loss: 0.4136
2022-10-03 01:55:32 - train: epoch 0270, iter [01140, 01251], lr: 0.000347, loss: 0.3889
2022-10-03 01:55:51 - train: epoch 0270, iter [01150, 01251], lr: 0.000347, loss: 0.4055
2022-10-03 01:56:09 - train: epoch 0270, iter [01160, 01251], lr: 0.000347, loss: 0.4218
2022-10-03 01:56:26 - train: epoch 0270, iter [01170, 01251], lr: 0.000347, loss: 0.4163
2022-10-03 01:56:45 - train: epoch 0270, iter [01180, 01251], lr: 0.000347, loss: 0.3958
2022-10-03 01:57:03 - train: epoch 0270, iter [01190, 01251], lr: 0.000347, loss: 0.4105
2022-10-03 01:57:20 - train: epoch 0270, iter [01200, 01251], lr: 0.000347, loss: 0.3896
2022-10-03 01:57:38 - train: epoch 0270, iter [01210, 01251], lr: 0.000347, loss: 0.3950
2022-10-03 01:57:56 - train: epoch 0270, iter [01220, 01251], lr: 0.000347, loss: 0.4168
2022-10-03 01:58:14 - train: epoch 0270, iter [01230, 01251], lr: 0.000347, loss: 0.3922
2022-10-03 01:58:33 - train: epoch 0270, iter [01240, 01251], lr: 0.000346, loss: 0.4089
2022-10-03 01:58:50 - train: epoch 0270, iter [01250, 01251], lr: 0.000346, loss: 0.3885
2022-10-03 01:58:54 - train: epoch 270, train_loss: 0.4008
2022-10-03 01:58:56 - until epoch: 270, best_loss: 0.4008
2022-10-03 01:58:56 - epoch 271 lr: 0.000346
2022-10-03 01:59:21 - train: epoch 0271, iter [00010, 01251], lr: 0.000346, loss: 0.3974
2022-10-03 01:59:39 - train: epoch 0271, iter [00020, 01251], lr: 0.000346, loss: 0.4081
2022-10-03 01:59:57 - train: epoch 0271, iter [00030, 01251], lr: 0.000346, loss: 0.3882
2022-10-03 02:00:15 - train: epoch 0271, iter [00040, 01251], lr: 0.000346, loss: 0.3996
2022-10-03 02:00:33 - train: epoch 0271, iter [00050, 01251], lr: 0.000346, loss: 0.4034
2022-10-03 02:00:51 - train: epoch 0271, iter [00060, 01251], lr: 0.000346, loss: 0.3917
2022-10-03 02:01:09 - train: epoch 0271, iter [00070, 01251], lr: 0.000346, loss: 0.3972
2022-10-03 02:01:27 - train: epoch 0271, iter [00080, 01251], lr: 0.000346, loss: 0.3997
2022-10-03 02:01:45 - train: epoch 0271, iter [00090, 01251], lr: 0.000346, loss: 0.3962
2022-10-03 02:02:02 - train: epoch 0271, iter [00100, 01251], lr: 0.000346, loss: 0.3815
2022-10-03 02:02:20 - train: epoch 0271, iter [00110, 01251], lr: 0.000346, loss: 0.3868
2022-10-03 02:02:38 - train: epoch 0271, iter [00120, 01251], lr: 0.000346, loss: 0.3798
2022-10-03 02:02:56 - train: epoch 0271, iter [00130, 01251], lr: 0.000346, loss: 0.3876
2022-10-03 02:03:14 - train: epoch 0271, iter [00140, 01251], lr: 0.000346, loss: 0.4110
2022-10-03 02:03:32 - train: epoch 0271, iter [00150, 01251], lr: 0.000346, loss: 0.4078
2022-10-03 02:03:50 - train: epoch 0271, iter [00160, 01251], lr: 0.000346, loss: 0.4013
2022-10-03 02:04:08 - train: epoch 0271, iter [00170, 01251], lr: 0.000346, loss: 0.3738
2022-10-03 02:04:26 - train: epoch 0271, iter [00180, 01251], lr: 0.000346, loss: 0.3918
2022-10-03 02:04:44 - train: epoch 0271, iter [00190, 01251], lr: 0.000346, loss: 0.4049
2022-10-03 02:05:02 - train: epoch 0271, iter [00200, 01251], lr: 0.000346, loss: 0.3884
2022-10-03 02:05:20 - train: epoch 0271, iter [00210, 01251], lr: 0.000346, loss: 0.4153
2022-10-03 02:05:38 - train: epoch 0271, iter [00220, 01251], lr: 0.000346, loss: 0.3984
2022-10-03 02:05:56 - train: epoch 0271, iter [00230, 01251], lr: 0.000346, loss: 0.3988
2022-10-03 02:06:14 - train: epoch 0271, iter [00240, 01251], lr: 0.000346, loss: 0.4168
2022-10-03 02:06:31 - train: epoch 0271, iter [00250, 01251], lr: 0.000345, loss: 0.4024
2022-10-03 02:06:49 - train: epoch 0271, iter [00260, 01251], lr: 0.000345, loss: 0.4143
2022-10-03 02:07:07 - train: epoch 0271, iter [00270, 01251], lr: 0.000345, loss: 0.3971
2022-10-03 02:07:25 - train: epoch 0271, iter [00280, 01251], lr: 0.000345, loss: 0.3854
2022-10-03 02:07:43 - train: epoch 0271, iter [00290, 01251], lr: 0.000345, loss: 0.4054
2022-10-03 02:08:01 - train: epoch 0271, iter [00300, 01251], lr: 0.000345, loss: 0.3905
2022-10-03 02:08:19 - train: epoch 0271, iter [00310, 01251], lr: 0.000345, loss: 0.4110
2022-10-03 02:08:36 - train: epoch 0271, iter [00320, 01251], lr: 0.000345, loss: 0.3729
2022-10-03 02:08:54 - train: epoch 0271, iter [00330, 01251], lr: 0.000345, loss: 0.4083
2022-10-03 02:09:12 - train: epoch 0271, iter [00340, 01251], lr: 0.000345, loss: 0.4143
2022-10-03 02:09:30 - train: epoch 0271, iter [00350, 01251], lr: 0.000345, loss: 0.3908
2022-10-03 02:09:48 - train: epoch 0271, iter [00360, 01251], lr: 0.000345, loss: 0.3917
2022-10-03 02:10:06 - train: epoch 0271, iter [00370, 01251], lr: 0.000345, loss: 0.3983
2022-10-03 02:10:24 - train: epoch 0271, iter [00380, 01251], lr: 0.000345, loss: 0.3980
2022-10-03 02:10:42 - train: epoch 0271, iter [00390, 01251], lr: 0.000345, loss: 0.3986
2022-10-03 02:11:00 - train: epoch 0271, iter [00400, 01251], lr: 0.000345, loss: 0.4076
2022-10-03 02:11:18 - train: epoch 0271, iter [00410, 01251], lr: 0.000345, loss: 0.3718
2022-10-03 02:11:36 - train: epoch 0271, iter [00420, 01251], lr: 0.000345, loss: 0.3834
2022-10-03 02:11:54 - train: epoch 0271, iter [00430, 01251], lr: 0.000345, loss: 0.4160
2022-10-03 02:12:12 - train: epoch 0271, iter [00440, 01251], lr: 0.000345, loss: 0.4067
2022-10-03 02:12:30 - train: epoch 0271, iter [00450, 01251], lr: 0.000345, loss: 0.3964
2022-10-03 02:12:48 - train: epoch 0271, iter [00460, 01251], lr: 0.000345, loss: 0.3946
2022-10-03 02:13:06 - train: epoch 0271, iter [00470, 01251], lr: 0.000345, loss: 0.4013
2022-10-03 02:13:24 - train: epoch 0271, iter [00480, 01251], lr: 0.000345, loss: 0.4117
2022-10-03 02:13:42 - train: epoch 0271, iter [00490, 01251], lr: 0.000345, loss: 0.3944
2022-10-03 02:14:00 - train: epoch 0271, iter [00500, 01251], lr: 0.000345, loss: 0.3941
2022-10-03 02:14:18 - train: epoch 0271, iter [00510, 01251], lr: 0.000344, loss: 0.3960
2022-10-03 02:14:36 - train: epoch 0271, iter [00520, 01251], lr: 0.000344, loss: 0.4279
2022-10-03 02:14:54 - train: epoch 0271, iter [00530, 01251], lr: 0.000344, loss: 0.3944
2022-10-03 02:15:12 - train: epoch 0271, iter [00540, 01251], lr: 0.000344, loss: 0.3947
2022-10-03 02:15:30 - train: epoch 0271, iter [00550, 01251], lr: 0.000344, loss: 0.4092
2022-10-03 02:15:48 - train: epoch 0271, iter [00560, 01251], lr: 0.000344, loss: 0.4019
2022-10-03 02:16:05 - train: epoch 0271, iter [00570, 01251], lr: 0.000344, loss: 0.4206
2022-10-03 02:16:23 - train: epoch 0271, iter [00580, 01251], lr: 0.000344, loss: 0.4015
2022-10-03 02:16:41 - train: epoch 0271, iter [00590, 01251], lr: 0.000344, loss: 0.4037
2022-10-03 02:16:59 - train: epoch 0271, iter [00600, 01251], lr: 0.000344, loss: 0.4015
2022-10-03 02:17:17 - train: epoch 0271, iter [00610, 01251], lr: 0.000344, loss: 0.4212
2022-10-03 02:17:35 - train: epoch 0271, iter [00620, 01251], lr: 0.000344, loss: 0.3825
2022-10-03 02:17:53 - train: epoch 0271, iter [00630, 01251], lr: 0.000344, loss: 0.3863
2022-10-03 02:18:11 - train: epoch 0271, iter [00640, 01251], lr: 0.000344, loss: 0.4105
2022-10-03 02:18:29 - train: epoch 0271, iter [00650, 01251], lr: 0.000344, loss: 0.3781
2022-10-03 02:18:47 - train: epoch 0271, iter [00660, 01251], lr: 0.000344, loss: 0.3753
2022-10-03 02:19:05 - train: epoch 0271, iter [00670, 01251], lr: 0.000344, loss: 0.4055
2022-10-03 02:19:23 - train: epoch 0271, iter [00680, 01251], lr: 0.000344, loss: 0.4008
2022-10-03 02:19:41 - train: epoch 0271, iter [00690, 01251], lr: 0.000344, loss: 0.4221
2022-10-03 02:19:58 - train: epoch 0271, iter [00700, 01251], lr: 0.000344, loss: 0.3837
2022-10-03 02:20:16 - train: epoch 0271, iter [00710, 01251], lr: 0.000344, loss: 0.3779
2022-10-03 02:20:34 - train: epoch 0271, iter [00720, 01251], lr: 0.000344, loss: 0.4010
2022-10-03 02:20:52 - train: epoch 0271, iter [00730, 01251], lr: 0.000344, loss: 0.4194
2022-10-03 02:21:10 - train: epoch 0271, iter [00740, 01251], lr: 0.000344, loss: 0.4167
2022-10-03 02:21:28 - train: epoch 0271, iter [00750, 01251], lr: 0.000344, loss: 0.4234
2022-10-03 02:21:46 - train: epoch 0271, iter [00760, 01251], lr: 0.000344, loss: 0.4006
2022-10-03 02:22:04 - train: epoch 0271, iter [00770, 01251], lr: 0.000344, loss: 0.4085
2022-10-03 02:22:21 - train: epoch 0271, iter [00780, 01251], lr: 0.000343, loss: 0.3987
2022-10-03 02:22:39 - train: epoch 0271, iter [00790, 01251], lr: 0.000343, loss: 0.4014
2022-10-03 02:22:57 - train: epoch 0271, iter [00800, 01251], lr: 0.000343, loss: 0.3831
2022-10-03 02:23:15 - train: epoch 0271, iter [00810, 01251], lr: 0.000343, loss: 0.3911
2022-10-03 02:23:33 - train: epoch 0271, iter [00820, 01251], lr: 0.000343, loss: 0.4072
2022-10-03 02:23:51 - train: epoch 0271, iter [00830, 01251], lr: 0.000343, loss: 0.4009
2022-10-03 02:24:09 - train: epoch 0271, iter [00840, 01251], lr: 0.000343, loss: 0.3951
2022-10-03 02:24:27 - train: epoch 0271, iter [00850, 01251], lr: 0.000343, loss: 0.4165
2022-10-03 02:24:45 - train: epoch 0271, iter [00860, 01251], lr: 0.000343, loss: 0.4046
2022-10-03 02:25:02 - train: epoch 0271, iter [00870, 01251], lr: 0.000343, loss: 0.3933
2022-10-03 02:25:21 - train: epoch 0271, iter [00880, 01251], lr: 0.000343, loss: 0.4009
2022-10-03 02:25:39 - train: epoch 0271, iter [00890, 01251], lr: 0.000343, loss: 0.4021
2022-10-03 02:25:56 - train: epoch 0271, iter [00900, 01251], lr: 0.000343, loss: 0.3973
2022-10-03 02:26:14 - train: epoch 0271, iter [00910, 01251], lr: 0.000343, loss: 0.4027
2022-10-03 02:26:32 - train: epoch 0271, iter [00920, 01251], lr: 0.000343, loss: 0.3999
2022-10-03 02:26:50 - train: epoch 0271, iter [00930, 01251], lr: 0.000343, loss: 0.3887
2022-10-03 02:27:08 - train: epoch 0271, iter [00940, 01251], lr: 0.000343, loss: 0.4094
2022-10-03 02:27:26 - train: epoch 0271, iter [00950, 01251], lr: 0.000343, loss: 0.4007
2022-10-03 02:27:44 - train: epoch 0271, iter [00960, 01251], lr: 0.000343, loss: 0.4049
2022-10-03 02:28:02 - train: epoch 0271, iter [00970, 01251], lr: 0.000343, loss: 0.3949
2022-10-03 02:28:20 - train: epoch 0271, iter [00980, 01251], lr: 0.000343, loss: 0.4034
2022-10-03 02:28:38 - train: epoch 0271, iter [00990, 01251], lr: 0.000343, loss: 0.3912
2022-10-03 02:28:56 - train: epoch 0271, iter [01000, 01251], lr: 0.000343, loss: 0.3877
2022-10-03 02:29:13 - train: epoch 0271, iter [01010, 01251], lr: 0.000343, loss: 0.4096
2022-10-03 02:29:31 - train: epoch 0271, iter [01020, 01251], lr: 0.000343, loss: 0.3957
2022-10-03 02:29:49 - train: epoch 0271, iter [01030, 01251], lr: 0.000343, loss: 0.4170
2022-10-03 02:30:07 - train: epoch 0271, iter [01040, 01251], lr: 0.000342, loss: 0.3907
2022-10-03 02:30:25 - train: epoch 0271, iter [01050, 01251], lr: 0.000342, loss: 0.4071
2022-10-03 02:30:42 - train: epoch 0271, iter [01060, 01251], lr: 0.000342, loss: 0.3932
2022-10-03 02:31:00 - train: epoch 0271, iter [01070, 01251], lr: 0.000342, loss: 0.3931
2022-10-03 02:31:18 - train: epoch 0271, iter [01080, 01251], lr: 0.000342, loss: 0.4041
2022-10-03 02:31:36 - train: epoch 0271, iter [01090, 01251], lr: 0.000342, loss: 0.4050
2022-10-03 02:31:54 - train: epoch 0271, iter [01100, 01251], lr: 0.000342, loss: 0.3951
2022-10-03 02:32:12 - train: epoch 0271, iter [01110, 01251], lr: 0.000342, loss: 0.3869
2022-10-03 02:32:29 - train: epoch 0271, iter [01120, 01251], lr: 0.000342, loss: 0.4121
2022-10-03 02:32:47 - train: epoch 0271, iter [01130, 01251], lr: 0.000342, loss: 0.4145
2022-10-03 02:33:05 - train: epoch 0271, iter [01140, 01251], lr: 0.000342, loss: 0.3883
2022-10-03 02:33:23 - train: epoch 0271, iter [01150, 01251], lr: 0.000342, loss: 0.4081
2022-10-03 02:33:41 - train: epoch 0271, iter [01160, 01251], lr: 0.000342, loss: 0.4134
2022-10-03 02:33:59 - train: epoch 0271, iter [01170, 01251], lr: 0.000342, loss: 0.3871
2022-10-03 02:34:17 - train: epoch 0271, iter [01180, 01251], lr: 0.000342, loss: 0.3952
2022-10-03 02:34:35 - train: epoch 0271, iter [01190, 01251], lr: 0.000342, loss: 0.4085
2022-10-03 02:34:52 - train: epoch 0271, iter [01200, 01251], lr: 0.000342, loss: 0.3821
2022-10-03 02:35:10 - train: epoch 0271, iter [01210, 01251], lr: 0.000342, loss: 0.3815
2022-10-03 02:35:28 - train: epoch 0271, iter [01220, 01251], lr: 0.000342, loss: 0.3895
2022-10-03 02:35:46 - train: epoch 0271, iter [01230, 01251], lr: 0.000342, loss: 0.3639
2022-10-03 02:36:04 - train: epoch 0271, iter [01240, 01251], lr: 0.000342, loss: 0.3759
2022-10-03 02:36:22 - train: epoch 0271, iter [01250, 01251], lr: 0.000342, loss: 0.3980
2022-10-03 02:36:25 - train: epoch 271, train_loss: 0.4007
2022-10-03 02:36:28 - until epoch: 271, best_loss: 0.4007
2022-10-03 02:36:28 - epoch 272 lr: 0.000342
2022-10-03 02:36:52 - train: epoch 0272, iter [00010, 01251], lr: 0.000342, loss: 0.3966
2022-10-03 02:37:10 - train: epoch 0272, iter [00020, 01251], lr: 0.000342, loss: 0.4143
2022-10-03 02:37:28 - train: epoch 0272, iter [00030, 01251], lr: 0.000342, loss: 0.4090
2022-10-03 02:37:46 - train: epoch 0272, iter [00040, 01251], lr: 0.000342, loss: 0.3802
2022-10-03 02:38:04 - train: epoch 0272, iter [00050, 01251], lr: 0.000342, loss: 0.4041
2022-10-03 02:38:22 - train: epoch 0272, iter [00060, 01251], lr: 0.000341, loss: 0.3971
2022-10-03 02:38:40 - train: epoch 0272, iter [00070, 01251], lr: 0.000341, loss: 0.4092
2022-10-03 02:38:57 - train: epoch 0272, iter [00080, 01251], lr: 0.000341, loss: 0.4172
2022-10-03 02:39:15 - train: epoch 0272, iter [00090, 01251], lr: 0.000341, loss: 0.3971
2022-10-03 02:39:33 - train: epoch 0272, iter [00100, 01251], lr: 0.000341, loss: 0.3889
2022-10-03 02:39:51 - train: epoch 0272, iter [00110, 01251], lr: 0.000341, loss: 0.3943
2022-10-03 02:40:09 - train: epoch 0272, iter [00120, 01251], lr: 0.000341, loss: 0.3867
2022-10-03 02:40:27 - train: epoch 0272, iter [00130, 01251], lr: 0.000341, loss: 0.4090
2022-10-03 02:40:45 - train: epoch 0272, iter [00140, 01251], lr: 0.000341, loss: 0.4019
2022-10-03 02:41:03 - train: epoch 0272, iter [00150, 01251], lr: 0.000341, loss: 0.3913
2022-10-03 02:41:21 - train: epoch 0272, iter [00160, 01251], lr: 0.000341, loss: 0.3881
2022-10-03 02:41:39 - train: epoch 0272, iter [00170, 01251], lr: 0.000341, loss: 0.4085
2022-10-03 02:41:57 - train: epoch 0272, iter [00180, 01251], lr: 0.000341, loss: 0.3877
2022-10-03 02:42:14 - train: epoch 0272, iter [00190, 01251], lr: 0.000341, loss: 0.3945
2022-10-03 02:42:32 - train: epoch 0272, iter [00200, 01251], lr: 0.000341, loss: 0.3931
2022-10-03 02:42:51 - train: epoch 0272, iter [00210, 01251], lr: 0.000341, loss: 0.3894
2022-10-03 02:43:08 - train: epoch 0272, iter [00220, 01251], lr: 0.000341, loss: 0.4203
2022-10-03 02:43:26 - train: epoch 0272, iter [00230, 01251], lr: 0.000341, loss: 0.4052
2022-10-03 02:43:44 - train: epoch 0272, iter [00240, 01251], lr: 0.000341, loss: 0.4005
2022-10-03 02:44:02 - train: epoch 0272, iter [00250, 01251], lr: 0.000341, loss: 0.4200
2022-10-03 02:44:20 - train: epoch 0272, iter [00260, 01251], lr: 0.000341, loss: 0.4121
2022-10-03 02:44:38 - train: epoch 0272, iter [00270, 01251], lr: 0.000341, loss: 0.4089
2022-10-03 02:44:56 - train: epoch 0272, iter [00280, 01251], lr: 0.000341, loss: 0.3977
2022-10-03 02:45:14 - train: epoch 0272, iter [00290, 01251], lr: 0.000341, loss: 0.3961
2022-10-03 02:45:32 - train: epoch 0272, iter [00300, 01251], lr: 0.000341, loss: 0.4169
2022-10-03 02:45:50 - train: epoch 0272, iter [00310, 01251], lr: 0.000341, loss: 0.3847
2022-10-03 02:46:08 - train: epoch 0272, iter [00320, 01251], lr: 0.000340, loss: 0.4261
2022-10-03 02:46:25 - train: epoch 0272, iter [00330, 01251], lr: 0.000340, loss: 0.3991
2022-10-03 02:46:43 - train: epoch 0272, iter [00340, 01251], lr: 0.000340, loss: 0.3991
2022-10-03 02:47:01 - train: epoch 0272, iter [00350, 01251], lr: 0.000340, loss: 0.4138
2022-10-03 02:47:19 - train: epoch 0272, iter [00360, 01251], lr: 0.000340, loss: 0.3982
2022-10-03 02:47:37 - train: epoch 0272, iter [00370, 01251], lr: 0.000340, loss: 0.4145
2022-10-03 02:47:55 - train: epoch 0272, iter [00380, 01251], lr: 0.000340, loss: 0.3973
2022-10-03 02:48:13 - train: epoch 0272, iter [00390, 01251], lr: 0.000340, loss: 0.3803
2022-10-03 02:48:31 - train: epoch 0272, iter [00400, 01251], lr: 0.000340, loss: 0.4115
2022-10-03 02:48:48 - train: epoch 0272, iter [00410, 01251], lr: 0.000340, loss: 0.3947
2022-10-03 02:49:06 - train: epoch 0272, iter [00420, 01251], lr: 0.000340, loss: 0.4001
2022-10-03 02:49:24 - train: epoch 0272, iter [00430, 01251], lr: 0.000340, loss: 0.3980
2022-10-03 02:49:42 - train: epoch 0272, iter [00440, 01251], lr: 0.000340, loss: 0.3955
2022-10-03 02:50:00 - train: epoch 0272, iter [00450, 01251], lr: 0.000340, loss: 0.4093
2022-10-03 02:50:18 - train: epoch 0272, iter [00460, 01251], lr: 0.000340, loss: 0.4179
2022-10-03 02:50:36 - train: epoch 0272, iter [00470, 01251], lr: 0.000340, loss: 0.3979
2022-10-03 02:50:54 - train: epoch 0272, iter [00480, 01251], lr: 0.000340, loss: 0.4152
2022-10-03 02:51:12 - train: epoch 0272, iter [00490, 01251], lr: 0.000340, loss: 0.4087
2022-10-03 02:51:29 - train: epoch 0272, iter [00500, 01251], lr: 0.000340, loss: 0.4160
2022-10-03 02:51:47 - train: epoch 0272, iter [00510, 01251], lr: 0.000340, loss: 0.3945
2022-10-03 02:52:05 - train: epoch 0272, iter [00520, 01251], lr: 0.000340, loss: 0.3854
2022-10-03 02:52:23 - train: epoch 0272, iter [00530, 01251], lr: 0.000340, loss: 0.4128
2022-10-03 02:52:41 - train: epoch 0272, iter [00540, 01251], lr: 0.000340, loss: 0.4009
2022-10-03 02:52:59 - train: epoch 0272, iter [00550, 01251], lr: 0.000340, loss: 0.4035
2022-10-03 02:53:17 - train: epoch 0272, iter [00560, 01251], lr: 0.000340, loss: 0.4193
2022-10-03 02:53:35 - train: epoch 0272, iter [00570, 01251], lr: 0.000340, loss: 0.3733
2022-10-03 02:53:53 - train: epoch 0272, iter [00580, 01251], lr: 0.000340, loss: 0.4114
2022-10-03 02:54:11 - train: epoch 0272, iter [00590, 01251], lr: 0.000339, loss: 0.3936
2022-10-03 02:54:29 - train: epoch 0272, iter [00600, 01251], lr: 0.000339, loss: 0.4072
2022-10-03 02:54:47 - train: epoch 0272, iter [00610, 01251], lr: 0.000339, loss: 0.4036
2022-10-03 02:55:05 - train: epoch 0272, iter [00620, 01251], lr: 0.000339, loss: 0.3897
2022-10-03 02:55:23 - train: epoch 0272, iter [00630, 01251], lr: 0.000339, loss: 0.4014
2022-10-03 02:55:41 - train: epoch 0272, iter [00640, 01251], lr: 0.000339, loss: 0.3972
2022-10-03 02:55:58 - train: epoch 0272, iter [00650, 01251], lr: 0.000339, loss: 0.4006
2022-10-03 02:56:17 - train: epoch 0272, iter [00660, 01251], lr: 0.000339, loss: 0.4035
2022-10-03 02:56:34 - train: epoch 0272, iter [00670, 01251], lr: 0.000339, loss: 0.3965
2022-10-03 02:56:52 - train: epoch 0272, iter [00680, 01251], lr: 0.000339, loss: 0.4070
2022-10-03 02:57:10 - train: epoch 0272, iter [00690, 01251], lr: 0.000339, loss: 0.3896
2022-10-03 02:57:28 - train: epoch 0272, iter [00700, 01251], lr: 0.000339, loss: 0.4055
2022-10-03 02:57:46 - train: epoch 0272, iter [00710, 01251], lr: 0.000339, loss: 0.4059
2022-10-03 02:58:04 - train: epoch 0272, iter [00720, 01251], lr: 0.000339, loss: 0.4075
2022-10-03 02:58:22 - train: epoch 0272, iter [00730, 01251], lr: 0.000339, loss: 0.4092
2022-10-03 02:58:40 - train: epoch 0272, iter [00740, 01251], lr: 0.000339, loss: 0.3931
2022-10-03 02:58:58 - train: epoch 0272, iter [00750, 01251], lr: 0.000339, loss: 0.4098
2022-10-03 02:59:16 - train: epoch 0272, iter [00760, 01251], lr: 0.000339, loss: 0.3959
2022-10-03 02:59:34 - train: epoch 0272, iter [00770, 01251], lr: 0.000339, loss: 0.4187
2022-10-03 02:59:51 - train: epoch 0272, iter [00780, 01251], lr: 0.000339, loss: 0.3835
2022-10-03 03:00:09 - train: epoch 0272, iter [00790, 01251], lr: 0.000339, loss: 0.4246
2022-10-03 03:00:27 - train: epoch 0272, iter [00800, 01251], lr: 0.000339, loss: 0.3975
2022-10-03 03:00:45 - train: epoch 0272, iter [00810, 01251], lr: 0.000339, loss: 0.3693
2022-10-03 03:01:03 - train: epoch 0272, iter [00820, 01251], lr: 0.000339, loss: 0.4081
2022-10-03 03:01:21 - train: epoch 0272, iter [00830, 01251], lr: 0.000339, loss: 0.3734
2022-10-03 03:01:39 - train: epoch 0272, iter [00840, 01251], lr: 0.000339, loss: 0.3856
2022-10-03 03:01:57 - train: epoch 0272, iter [00850, 01251], lr: 0.000338, loss: 0.3909
2022-10-03 03:02:15 - train: epoch 0272, iter [00860, 01251], lr: 0.000338, loss: 0.4052
2022-10-03 03:02:33 - train: epoch 0272, iter [00870, 01251], lr: 0.000338, loss: 0.4087
2022-10-03 03:02:51 - train: epoch 0272, iter [00880, 01251], lr: 0.000338, loss: 0.4035
2022-10-03 03:03:09 - train: epoch 0272, iter [00890, 01251], lr: 0.000338, loss: 0.4056
2022-10-03 03:03:27 - train: epoch 0272, iter [00900, 01251], lr: 0.000338, loss: 0.4239
2022-10-03 03:03:45 - train: epoch 0272, iter [00910, 01251], lr: 0.000338, loss: 0.4116
2022-10-03 03:04:03 - train: epoch 0272, iter [00920, 01251], lr: 0.000338, loss: 0.3879
2022-10-03 03:04:21 - train: epoch 0272, iter [00930, 01251], lr: 0.000338, loss: 0.4114
2022-10-03 03:04:39 - train: epoch 0272, iter [00940, 01251], lr: 0.000338, loss: 0.4103
2022-10-03 03:04:57 - train: epoch 0272, iter [00950, 01251], lr: 0.000338, loss: 0.3802
2022-10-03 03:05:15 - train: epoch 0272, iter [00960, 01251], lr: 0.000338, loss: 0.3873
2022-10-03 03:05:32 - train: epoch 0272, iter [00970, 01251], lr: 0.000338, loss: 0.3839
2022-10-03 03:05:50 - train: epoch 0272, iter [00980, 01251], lr: 0.000338, loss: 0.4002
2022-10-03 03:06:08 - train: epoch 0272, iter [00990, 01251], lr: 0.000338, loss: 0.3875
2022-10-03 03:06:26 - train: epoch 0272, iter [01000, 01251], lr: 0.000338, loss: 0.4008
2022-10-03 03:06:44 - train: epoch 0272, iter [01010, 01251], lr: 0.000338, loss: 0.3989
2022-10-03 03:07:02 - train: epoch 0272, iter [01020, 01251], lr: 0.000338, loss: 0.3842
2022-10-03 03:07:20 - train: epoch 0272, iter [01030, 01251], lr: 0.000338, loss: 0.4163
2022-10-03 03:07:38 - train: epoch 0272, iter [01040, 01251], lr: 0.000338, loss: 0.4126
2022-10-03 03:07:56 - train: epoch 0272, iter [01050, 01251], lr: 0.000338, loss: 0.4065
2022-10-03 03:08:14 - train: epoch 0272, iter [01060, 01251], lr: 0.000338, loss: 0.3925
2022-10-03 03:08:32 - train: epoch 0272, iter [01070, 01251], lr: 0.000338, loss: 0.3964
2022-10-03 03:08:50 - train: epoch 0272, iter [01080, 01251], lr: 0.000338, loss: 0.3980
2022-10-03 03:09:08 - train: epoch 0272, iter [01090, 01251], lr: 0.000338, loss: 0.3858
2022-10-03 03:09:25 - train: epoch 0272, iter [01100, 01251], lr: 0.000338, loss: 0.4081
2022-10-03 03:09:43 - train: epoch 0272, iter [01110, 01251], lr: 0.000338, loss: 0.4016
2022-10-03 03:10:01 - train: epoch 0272, iter [01120, 01251], lr: 0.000337, loss: 0.3920
2022-10-03 03:10:19 - train: epoch 0272, iter [01130, 01251], lr: 0.000337, loss: 0.3948
2022-10-03 03:10:37 - train: epoch 0272, iter [01140, 01251], lr: 0.000337, loss: 0.4093
2022-10-03 03:10:55 - train: epoch 0272, iter [01150, 01251], lr: 0.000337, loss: 0.3926
2022-10-03 03:11:13 - train: epoch 0272, iter [01160, 01251], lr: 0.000337, loss: 0.3801
2022-10-03 03:11:31 - train: epoch 0272, iter [01170, 01251], lr: 0.000337, loss: 0.4134
2022-10-03 03:11:49 - train: epoch 0272, iter [01180, 01251], lr: 0.000337, loss: 0.4216
2022-10-03 03:12:07 - train: epoch 0272, iter [01190, 01251], lr: 0.000337, loss: 0.4104
2022-10-03 03:12:25 - train: epoch 0272, iter [01200, 01251], lr: 0.000337, loss: 0.4125
2022-10-03 03:12:43 - train: epoch 0272, iter [01210, 01251], lr: 0.000337, loss: 0.3993
2022-10-03 03:13:01 - train: epoch 0272, iter [01220, 01251], lr: 0.000337, loss: 0.3988
2022-10-03 03:13:19 - train: epoch 0272, iter [01230, 01251], lr: 0.000337, loss: 0.4201
2022-10-03 03:13:37 - train: epoch 0272, iter [01240, 01251], lr: 0.000337, loss: 0.3973
2022-10-03 03:13:54 - train: epoch 0272, iter [01250, 01251], lr: 0.000337, loss: 0.4036
2022-10-03 03:13:58 - train: epoch 272, train_loss: 0.4007
2022-10-03 03:14:00 - until epoch: 272, best_loss: 0.4007
2022-10-03 03:14:00 - epoch 273 lr: 0.000337
2022-10-03 03:14:26 - train: epoch 0273, iter [00010, 01251], lr: 0.000337, loss: 0.4204
2022-10-03 03:14:43 - train: epoch 0273, iter [00020, 01251], lr: 0.000337, loss: 0.4026
2022-10-03 03:15:01 - train: epoch 0273, iter [00030, 01251], lr: 0.000337, loss: 0.3857
2022-10-03 03:15:19 - train: epoch 0273, iter [00040, 01251], lr: 0.000337, loss: 0.3927
2022-10-03 03:15:37 - train: epoch 0273, iter [00050, 01251], lr: 0.000337, loss: 0.3979
2022-10-03 03:15:55 - train: epoch 0273, iter [00060, 01251], lr: 0.000337, loss: 0.4006
2022-10-03 03:16:13 - train: epoch 0273, iter [00070, 01251], lr: 0.000337, loss: 0.4081
2022-10-03 03:16:31 - train: epoch 0273, iter [00080, 01251], lr: 0.000337, loss: 0.3909
2022-10-03 03:16:49 - train: epoch 0273, iter [00090, 01251], lr: 0.000337, loss: 0.4011
2022-10-03 03:17:07 - train: epoch 0273, iter [00100, 01251], lr: 0.000337, loss: 0.4111
2022-10-03 03:17:25 - train: epoch 0273, iter [00110, 01251], lr: 0.000337, loss: 0.4204
2022-10-03 03:17:42 - train: epoch 0273, iter [00120, 01251], lr: 0.000337, loss: 0.4046
2022-10-03 03:18:00 - train: epoch 0273, iter [00130, 01251], lr: 0.000336, loss: 0.3900
2022-10-03 03:18:18 - train: epoch 0273, iter [00140, 01251], lr: 0.000336, loss: 0.4066
2022-10-03 03:18:36 - train: epoch 0273, iter [00150, 01251], lr: 0.000336, loss: 0.4039
2022-10-03 03:18:54 - train: epoch 0273, iter [00160, 01251], lr: 0.000336, loss: 0.4079
2022-10-03 03:19:12 - train: epoch 0273, iter [00170, 01251], lr: 0.000336, loss: 0.3885
2022-10-03 03:19:30 - train: epoch 0273, iter [00180, 01251], lr: 0.000336, loss: 0.3989
2022-10-03 03:19:48 - train: epoch 0273, iter [00190, 01251], lr: 0.000336, loss: 0.3997
2022-10-03 03:20:05 - train: epoch 0273, iter [00200, 01251], lr: 0.000336, loss: 0.3958
2022-10-03 03:20:23 - train: epoch 0273, iter [00210, 01251], lr: 0.000336, loss: 0.4189
2022-10-03 03:20:41 - train: epoch 0273, iter [00220, 01251], lr: 0.000336, loss: 0.4005
2022-10-03 03:20:59 - train: epoch 0273, iter [00230, 01251], lr: 0.000336, loss: 0.4028
2022-10-03 03:21:17 - train: epoch 0273, iter [00240, 01251], lr: 0.000336, loss: 0.4060
2022-10-03 03:21:35 - train: epoch 0273, iter [00250, 01251], lr: 0.000336, loss: 0.3893
2022-10-03 03:21:53 - train: epoch 0273, iter [00260, 01251], lr: 0.000336, loss: 0.3950
2022-10-03 03:22:10 - train: epoch 0273, iter [00270, 01251], lr: 0.000336, loss: 0.4133
2022-10-03 03:22:28 - train: epoch 0273, iter [00280, 01251], lr: 0.000336, loss: 0.4220
2022-10-03 03:22:46 - train: epoch 0273, iter [00290, 01251], lr: 0.000336, loss: 0.3990
2022-10-03 03:23:03 - train: epoch 0273, iter [00300, 01251], lr: 0.000336, loss: 0.3886
2022-10-03 03:23:21 - train: epoch 0273, iter [00310, 01251], lr: 0.000336, loss: 0.4081
2022-10-03 03:23:39 - train: epoch 0273, iter [00320, 01251], lr: 0.000336, loss: 0.4076
2022-10-03 03:23:57 - train: epoch 0273, iter [00330, 01251], lr: 0.000336, loss: 0.3981
2022-10-03 03:24:15 - train: epoch 0273, iter [00340, 01251], lr: 0.000336, loss: 0.4026
2022-10-03 03:24:33 - train: epoch 0273, iter [00350, 01251], lr: 0.000336, loss: 0.4165
2022-10-03 03:24:51 - train: epoch 0273, iter [00360, 01251], lr: 0.000336, loss: 0.3979
2022-10-03 03:25:09 - train: epoch 0273, iter [00370, 01251], lr: 0.000336, loss: 0.3987
2022-10-03 03:25:27 - train: epoch 0273, iter [00380, 01251], lr: 0.000336, loss: 0.4116
2022-10-03 03:25:45 - train: epoch 0273, iter [00390, 01251], lr: 0.000336, loss: 0.3892
2022-10-03 03:26:03 - train: epoch 0273, iter [00400, 01251], lr: 0.000335, loss: 0.4046
2022-10-03 03:26:21 - train: epoch 0273, iter [00410, 01251], lr: 0.000335, loss: 0.3904
2022-10-03 03:26:38 - train: epoch 0273, iter [00420, 01251], lr: 0.000335, loss: 0.3974
2022-10-03 03:26:56 - train: epoch 0273, iter [00430, 01251], lr: 0.000335, loss: 0.3992
2022-10-03 03:27:14 - train: epoch 0273, iter [00440, 01251], lr: 0.000335, loss: 0.4013
2022-10-03 03:27:32 - train: epoch 0273, iter [00450, 01251], lr: 0.000335, loss: 0.3912
2022-10-03 03:27:50 - train: epoch 0273, iter [00460, 01251], lr: 0.000335, loss: 0.3953
2022-10-03 03:28:08 - train: epoch 0273, iter [00470, 01251], lr: 0.000335, loss: 0.3990
2022-10-03 03:28:26 - train: epoch 0273, iter [00480, 01251], lr: 0.000335, loss: 0.3959
2022-10-03 03:28:44 - train: epoch 0273, iter [00490, 01251], lr: 0.000335, loss: 0.4128
2022-10-03 03:29:02 - train: epoch 0273, iter [00500, 01251], lr: 0.000335, loss: 0.3966
2022-10-03 03:29:20 - train: epoch 0273, iter [00510, 01251], lr: 0.000335, loss: 0.4038
2022-10-03 03:29:38 - train: epoch 0273, iter [00520, 01251], lr: 0.000335, loss: 0.3971
2022-10-03 03:29:56 - train: epoch 0273, iter [00530, 01251], lr: 0.000335, loss: 0.3934
2022-10-03 03:30:14 - train: epoch 0273, iter [00540, 01251], lr: 0.000335, loss: 0.4087
2022-10-03 03:30:32 - train: epoch 0273, iter [00550, 01251], lr: 0.000335, loss: 0.4116
2022-10-03 03:30:50 - train: epoch 0273, iter [00560, 01251], lr: 0.000335, loss: 0.4103
2022-10-03 03:31:08 - train: epoch 0273, iter [00570, 01251], lr: 0.000335, loss: 0.3973
2022-10-03 03:31:26 - train: epoch 0273, iter [00580, 01251], lr: 0.000335, loss: 0.4000
2022-10-03 03:31:44 - train: epoch 0273, iter [00590, 01251], lr: 0.000335, loss: 0.3900
2022-10-03 03:32:02 - train: epoch 0273, iter [00600, 01251], lr: 0.000335, loss: 0.3972
2022-10-03 03:32:20 - train: epoch 0273, iter [00610, 01251], lr: 0.000335, loss: 0.3876
2022-10-03 03:32:38 - train: epoch 0273, iter [00620, 01251], lr: 0.000335, loss: 0.4062
2022-10-03 03:32:56 - train: epoch 0273, iter [00630, 01251], lr: 0.000335, loss: 0.4035
2022-10-03 03:33:14 - train: epoch 0273, iter [00640, 01251], lr: 0.000335, loss: 0.4198
2022-10-03 03:33:31 - train: epoch 0273, iter [00650, 01251], lr: 0.000335, loss: 0.3884
2022-10-03 03:33:49 - train: epoch 0273, iter [00660, 01251], lr: 0.000334, loss: 0.3915
2022-10-03 03:34:07 - train: epoch 0273, iter [00670, 01251], lr: 0.000334, loss: 0.4083
2022-10-03 03:34:25 - train: epoch 0273, iter [00680, 01251], lr: 0.000334, loss: 0.4069
2022-10-03 03:34:43 - train: epoch 0273, iter [00690, 01251], lr: 0.000334, loss: 0.3945
2022-10-03 03:35:01 - train: epoch 0273, iter [00700, 01251], lr: 0.000334, loss: 0.4067
2022-10-03 03:35:19 - train: epoch 0273, iter [00710, 01251], lr: 0.000334, loss: 0.3948
2022-10-03 03:35:37 - train: epoch 0273, iter [00720, 01251], lr: 0.000334, loss: 0.4198
2022-10-03 03:35:55 - train: epoch 0273, iter [00730, 01251], lr: 0.000334, loss: 0.4111
2022-10-03 03:36:13 - train: epoch 0273, iter [00740, 01251], lr: 0.000334, loss: 0.4044
2022-10-03 03:36:31 - train: epoch 0273, iter [00750, 01251], lr: 0.000334, loss: 0.3939
2022-10-03 03:36:49 - train: epoch 0273, iter [00760, 01251], lr: 0.000334, loss: 0.3999
2022-10-03 03:37:07 - train: epoch 0273, iter [00770, 01251], lr: 0.000334, loss: 0.3883
2022-10-03 03:37:25 - train: epoch 0273, iter [00780, 01251], lr: 0.000334, loss: 0.4232
2022-10-03 03:37:43 - train: epoch 0273, iter [00790, 01251], lr: 0.000334, loss: 0.4176
2022-10-03 03:38:01 - train: epoch 0273, iter [00800, 01251], lr: 0.000334, loss: 0.4329
2022-10-03 03:38:18 - train: epoch 0273, iter [00810, 01251], lr: 0.000334, loss: 0.3976
2022-10-03 03:38:36 - train: epoch 0273, iter [00820, 01251], lr: 0.000334, loss: 0.4071
2022-10-03 03:38:54 - train: epoch 0273, iter [00830, 01251], lr: 0.000334, loss: 0.4028
2022-10-03 03:39:12 - train: epoch 0273, iter [00840, 01251], lr: 0.000334, loss: 0.4072
2022-10-03 03:39:30 - train: epoch 0273, iter [00850, 01251], lr: 0.000334, loss: 0.3932
2022-10-03 03:39:48 - train: epoch 0273, iter [00860, 01251], lr: 0.000334, loss: 0.3964
2022-10-03 03:40:06 - train: epoch 0273, iter [00870, 01251], lr: 0.000334, loss: 0.4126
2022-10-03 03:40:24 - train: epoch 0273, iter [00880, 01251], lr: 0.000334, loss: 0.4183
2022-10-03 03:40:41 - train: epoch 0273, iter [00890, 01251], lr: 0.000334, loss: 0.3975
2022-10-03 03:40:59 - train: epoch 0273, iter [00900, 01251], lr: 0.000334, loss: 0.3930
2022-10-03 03:41:17 - train: epoch 0273, iter [00910, 01251], lr: 0.000334, loss: 0.4030
2022-10-03 03:41:35 - train: epoch 0273, iter [00920, 01251], lr: 0.000334, loss: 0.3913
2022-10-03 03:41:53 - train: epoch 0273, iter [00930, 01251], lr: 0.000333, loss: 0.3987
2022-10-03 03:42:11 - train: epoch 0273, iter [00940, 01251], lr: 0.000333, loss: 0.3841
2022-10-03 03:42:29 - train: epoch 0273, iter [00950, 01251], lr: 0.000333, loss: 0.4035
2022-10-03 03:42:47 - train: epoch 0273, iter [00960, 01251], lr: 0.000333, loss: 0.3935
2022-10-03 03:43:05 - train: epoch 0273, iter [00970, 01251], lr: 0.000333, loss: 0.4175
2022-10-03 03:43:23 - train: epoch 0273, iter [00980, 01251], lr: 0.000333, loss: 0.4033
2022-10-03 03:43:41 - train: epoch 0273, iter [00990, 01251], lr: 0.000333, loss: 0.3950
2022-10-03 03:43:58 - train: epoch 0273, iter [01000, 01251], lr: 0.000333, loss: 0.3938
2022-10-03 03:44:16 - train: epoch 0273, iter [01010, 01251], lr: 0.000333, loss: 0.3865
2022-10-03 03:44:34 - train: epoch 0273, iter [01020, 01251], lr: 0.000333, loss: 0.3908
2022-10-03 03:44:52 - train: epoch 0273, iter [01030, 01251], lr: 0.000333, loss: 0.4094
2022-10-03 03:45:10 - train: epoch 0273, iter [01040, 01251], lr: 0.000333, loss: 0.3937
2022-10-03 03:45:28 - train: epoch 0273, iter [01050, 01251], lr: 0.000333, loss: 0.4053
2022-10-03 03:45:46 - train: epoch 0273, iter [01060, 01251], lr: 0.000333, loss: 0.4071
2022-10-03 03:46:04 - train: epoch 0273, iter [01070, 01251], lr: 0.000333, loss: 0.3912
2022-10-03 03:46:22 - train: epoch 0273, iter [01080, 01251], lr: 0.000333, loss: 0.4119
2022-10-03 03:46:39 - train: epoch 0273, iter [01090, 01251], lr: 0.000333, loss: 0.3759
2022-10-03 03:46:57 - train: epoch 0273, iter [01100, 01251], lr: 0.000333, loss: 0.4030
2022-10-03 03:47:15 - train: epoch 0273, iter [01110, 01251], lr: 0.000333, loss: 0.3962
2022-10-03 03:47:33 - train: epoch 0273, iter [01120, 01251], lr: 0.000333, loss: 0.3940
2022-10-03 03:47:51 - train: epoch 0273, iter [01130, 01251], lr: 0.000333, loss: 0.3961
2022-10-03 03:48:09 - train: epoch 0273, iter [01140, 01251], lr: 0.000333, loss: 0.3884
2022-10-03 03:48:27 - train: epoch 0273, iter [01150, 01251], lr: 0.000333, loss: 0.4073
2022-10-03 03:48:45 - train: epoch 0273, iter [01160, 01251], lr: 0.000333, loss: 0.4090
2022-10-03 03:49:03 - train: epoch 0273, iter [01170, 01251], lr: 0.000333, loss: 0.4156
2022-10-03 03:49:20 - train: epoch 0273, iter [01180, 01251], lr: 0.000333, loss: 0.4082
2022-10-03 03:49:38 - train: epoch 0273, iter [01190, 01251], lr: 0.000333, loss: 0.3842
2022-10-03 03:49:56 - train: epoch 0273, iter [01200, 01251], lr: 0.000332, loss: 0.4046
2022-10-03 03:50:14 - train: epoch 0273, iter [01210, 01251], lr: 0.000332, loss: 0.3893
2022-10-03 03:50:32 - train: epoch 0273, iter [01220, 01251], lr: 0.000332, loss: 0.4093
2022-10-03 03:50:50 - train: epoch 0273, iter [01230, 01251], lr: 0.000332, loss: 0.3894
2022-10-03 03:51:08 - train: epoch 0273, iter [01240, 01251], lr: 0.000332, loss: 0.4083
2022-10-03 03:51:25 - train: epoch 0273, iter [01250, 01251], lr: 0.000332, loss: 0.4125
2022-10-03 03:51:28 - train: epoch 273, train_loss: 0.4005
2022-10-03 03:51:31 - until epoch: 273, best_loss: 0.4005
2022-10-03 03:51:31 - epoch 274 lr: 0.000332
2022-10-03 03:51:56 - train: epoch 0274, iter [00010, 01251], lr: 0.000332, loss: 0.3944
2022-10-03 03:52:14 - train: epoch 0274, iter [00020, 01251], lr: 0.000332, loss: 0.4122
2022-10-03 03:52:32 - train: epoch 0274, iter [00030, 01251], lr: 0.000332, loss: 0.4022
2022-10-03 03:52:50 - train: epoch 0274, iter [00040, 01251], lr: 0.000332, loss: 0.4048
2022-10-03 03:53:07 - train: epoch 0274, iter [00050, 01251], lr: 0.000332, loss: 0.4019
2022-10-03 03:53:25 - train: epoch 0274, iter [00060, 01251], lr: 0.000332, loss: 0.3988
2022-10-03 03:53:43 - train: epoch 0274, iter [00070, 01251], lr: 0.000332, loss: 0.4034
2022-10-03 03:54:01 - train: epoch 0274, iter [00080, 01251], lr: 0.000332, loss: 0.3845
2022-10-03 03:54:19 - train: epoch 0274, iter [00090, 01251], lr: 0.000332, loss: 0.3974
2022-10-03 03:54:37 - train: epoch 0274, iter [00100, 01251], lr: 0.000332, loss: 0.4184
2022-10-03 03:54:54 - train: epoch 0274, iter [00110, 01251], lr: 0.000332, loss: 0.4008
2022-10-03 03:55:12 - train: epoch 0274, iter [00120, 01251], lr: 0.000332, loss: 0.4017
2022-10-03 03:55:30 - train: epoch 0274, iter [00130, 01251], lr: 0.000332, loss: 0.4005
2022-10-03 03:55:48 - train: epoch 0274, iter [00140, 01251], lr: 0.000332, loss: 0.3887
2022-10-03 03:56:06 - train: epoch 0274, iter [00150, 01251], lr: 0.000332, loss: 0.4052
2022-10-03 03:56:24 - train: epoch 0274, iter [00160, 01251], lr: 0.000332, loss: 0.3938
2022-10-03 03:56:42 - train: epoch 0274, iter [00170, 01251], lr: 0.000332, loss: 0.3979
2022-10-03 03:57:00 - train: epoch 0274, iter [00180, 01251], lr: 0.000332, loss: 0.4085
2022-10-03 03:57:18 - train: epoch 0274, iter [00190, 01251], lr: 0.000332, loss: 0.3927
2022-10-03 03:57:36 - train: epoch 0274, iter [00200, 01251], lr: 0.000332, loss: 0.3842
2022-10-03 03:57:54 - train: epoch 0274, iter [00210, 01251], lr: 0.000331, loss: 0.4084
2022-10-03 03:58:12 - train: epoch 0274, iter [00220, 01251], lr: 0.000331, loss: 0.4035
2022-10-03 03:58:30 - train: epoch 0274, iter [00230, 01251], lr: 0.000331, loss: 0.4170
2022-10-03 03:58:47 - train: epoch 0274, iter [00240, 01251], lr: 0.000331, loss: 0.3830
2022-10-03 03:59:05 - train: epoch 0274, iter [00250, 01251], lr: 0.000331, loss: 0.4090
2022-10-03 03:59:23 - train: epoch 0274, iter [00260, 01251], lr: 0.000331, loss: 0.3842
2022-10-03 03:59:41 - train: epoch 0274, iter [00270, 01251], lr: 0.000331, loss: 0.4021
2022-10-03 03:59:59 - train: epoch 0274, iter [00280, 01251], lr: 0.000331, loss: 0.4152
2022-10-03 04:00:17 - train: epoch 0274, iter [00290, 01251], lr: 0.000331, loss: 0.3777
2022-10-03 04:00:35 - train: epoch 0274, iter [00300, 01251], lr: 0.000331, loss: 0.4012
2022-10-03 04:00:52 - train: epoch 0274, iter [00310, 01251], lr: 0.000331, loss: 0.4051
2022-10-03 04:01:10 - train: epoch 0274, iter [00320, 01251], lr: 0.000331, loss: 0.4054
2022-10-03 04:01:28 - train: epoch 0274, iter [00330, 01251], lr: 0.000331, loss: 0.3815
2022-10-03 04:01:46 - train: epoch 0274, iter [00340, 01251], lr: 0.000331, loss: 0.3854
2022-10-03 04:02:04 - train: epoch 0274, iter [00350, 01251], lr: 0.000331, loss: 0.4116
2022-10-03 04:02:21 - train: epoch 0274, iter [00360, 01251], lr: 0.000331, loss: 0.4133
2022-10-03 04:02:39 - train: epoch 0274, iter [00370, 01251], lr: 0.000331, loss: 0.3995
2022-10-03 04:02:57 - train: epoch 0274, iter [00380, 01251], lr: 0.000331, loss: 0.3841
2022-10-03 04:03:15 - train: epoch 0274, iter [00390, 01251], lr: 0.000331, loss: 0.3940
2022-10-03 04:03:33 - train: epoch 0274, iter [00400, 01251], lr: 0.000331, loss: 0.3926
2022-10-03 04:03:51 - train: epoch 0274, iter [00410, 01251], lr: 0.000331, loss: 0.3769
2022-10-03 04:04:09 - train: epoch 0274, iter [00420, 01251], lr: 0.000331, loss: 0.4074
2022-10-03 04:04:27 - train: epoch 0274, iter [00430, 01251], lr: 0.000331, loss: 0.4062
2022-10-03 04:04:44 - train: epoch 0274, iter [00440, 01251], lr: 0.000331, loss: 0.3951
2022-10-03 04:05:02 - train: epoch 0274, iter [00450, 01251], lr: 0.000331, loss: 0.4045
2022-10-03 04:05:20 - train: epoch 0274, iter [00460, 01251], lr: 0.000331, loss: 0.3876
2022-10-03 04:05:38 - train: epoch 0274, iter [00470, 01251], lr: 0.000331, loss: 0.3760
2022-10-03 04:05:56 - train: epoch 0274, iter [00480, 01251], lr: 0.000330, loss: 0.4052
2022-10-03 04:06:14 - train: epoch 0274, iter [00490, 01251], lr: 0.000330, loss: 0.3846
2022-10-03 04:06:32 - train: epoch 0274, iter [00500, 01251], lr: 0.000330, loss: 0.4074
2022-10-03 04:06:50 - train: epoch 0274, iter [00510, 01251], lr: 0.000330, loss: 0.3958
2022-10-03 04:07:08 - train: epoch 0274, iter [00520, 01251], lr: 0.000330, loss: 0.3981
2022-10-03 04:07:26 - train: epoch 0274, iter [00530, 01251], lr: 0.000330, loss: 0.4135
2022-10-03 04:07:44 - train: epoch 0274, iter [00540, 01251], lr: 0.000330, loss: 0.4145
2022-10-03 04:08:02 - train: epoch 0274, iter [00550, 01251], lr: 0.000330, loss: 0.3869
2022-10-03 04:08:19 - train: epoch 0274, iter [00560, 01251], lr: 0.000330, loss: 0.4205
2022-10-03 04:08:37 - train: epoch 0274, iter [00570, 01251], lr: 0.000330, loss: 0.4265
2022-10-03 04:08:55 - train: epoch 0274, iter [00580, 01251], lr: 0.000330, loss: 0.3921
2022-10-03 04:09:13 - train: epoch 0274, iter [00590, 01251], lr: 0.000330, loss: 0.3982
2022-10-03 04:09:31 - train: epoch 0274, iter [00600, 01251], lr: 0.000330, loss: 0.3970
2022-10-03 04:09:49 - train: epoch 0274, iter [00610, 01251], lr: 0.000330, loss: 0.4090
2022-10-03 04:10:07 - train: epoch 0274, iter [00620, 01251], lr: 0.000330, loss: 0.4106
2022-10-03 04:10:25 - train: epoch 0274, iter [00630, 01251], lr: 0.000330, loss: 0.3989
2022-10-03 04:10:42 - train: epoch 0274, iter [00640, 01251], lr: 0.000330, loss: 0.3835
2022-10-03 04:11:00 - train: epoch 0274, iter [00650, 01251], lr: 0.000330, loss: 0.3767
2022-10-03 04:11:18 - train: epoch 0274, iter [00660, 01251], lr: 0.000330, loss: 0.3992
2022-10-03 04:11:36 - train: epoch 0274, iter [00670, 01251], lr: 0.000330, loss: 0.3929
2022-10-03 04:11:54 - train: epoch 0274, iter [00680, 01251], lr: 0.000330, loss: 0.4150
2022-10-03 04:12:11 - train: epoch 0274, iter [00690, 01251], lr: 0.000330, loss: 0.3809
2022-10-03 04:12:29 - train: epoch 0274, iter [00700, 01251], lr: 0.000330, loss: 0.4012
2022-10-03 04:12:47 - train: epoch 0274, iter [00710, 01251], lr: 0.000330, loss: 0.4151
2022-10-03 04:13:05 - train: epoch 0274, iter [00720, 01251], lr: 0.000330, loss: 0.3803
2022-10-03 04:13:23 - train: epoch 0274, iter [00730, 01251], lr: 0.000330, loss: 0.4117
2022-10-03 04:13:41 - train: epoch 0274, iter [00740, 01251], lr: 0.000330, loss: 0.3953
2022-10-03 04:13:59 - train: epoch 0274, iter [00750, 01251], lr: 0.000329, loss: 0.3909
2022-10-03 04:14:17 - train: epoch 0274, iter [00760, 01251], lr: 0.000329, loss: 0.4098
2022-10-03 04:14:35 - train: epoch 0274, iter [00770, 01251], lr: 0.000329, loss: 0.4130
2022-10-03 04:14:52 - train: epoch 0274, iter [00780, 01251], lr: 0.000329, loss: 0.4219
2022-10-03 04:15:10 - train: epoch 0274, iter [00790, 01251], lr: 0.000329, loss: 0.4180
2022-10-03 04:15:28 - train: epoch 0274, iter [00800, 01251], lr: 0.000329, loss: 0.4232
2022-10-03 04:15:46 - train: epoch 0274, iter [00810, 01251], lr: 0.000329, loss: 0.4011
2022-10-03 04:16:04 - train: epoch 0274, iter [00820, 01251], lr: 0.000329, loss: 0.3922
2022-10-03 04:16:21 - train: epoch 0274, iter [00830, 01251], lr: 0.000329, loss: 0.3952
2022-10-03 04:16:39 - train: epoch 0274, iter [00840, 01251], lr: 0.000329, loss: 0.4192
2022-10-03 04:16:57 - train: epoch 0274, iter [00850, 01251], lr: 0.000329, loss: 0.4025
2022-10-03 04:17:15 - train: epoch 0274, iter [00860, 01251], lr: 0.000329, loss: 0.3973
2022-10-03 04:17:33 - train: epoch 0274, iter [00870, 01251], lr: 0.000329, loss: 0.4047
2022-10-03 04:17:51 - train: epoch 0274, iter [00880, 01251], lr: 0.000329, loss: 0.4181
2022-10-03 04:18:08 - train: epoch 0274, iter [00890, 01251], lr: 0.000329, loss: 0.4068
2022-10-03 04:18:26 - train: epoch 0274, iter [00900, 01251], lr: 0.000329, loss: 0.3996
2022-10-03 04:18:44 - train: epoch 0274, iter [00910, 01251], lr: 0.000329, loss: 0.4011
2022-10-03 04:19:02 - train: epoch 0274, iter [00920, 01251], lr: 0.000329, loss: 0.4033
2022-10-03 04:19:20 - train: epoch 0274, iter [00930, 01251], lr: 0.000329, loss: 0.4044
2022-10-03 04:19:38 - train: epoch 0274, iter [00940, 01251], lr: 0.000329, loss: 0.4114
2022-10-03 04:19:55 - train: epoch 0274, iter [00950, 01251], lr: 0.000329, loss: 0.3970
2022-10-03 04:20:13 - train: epoch 0274, iter [00960, 01251], lr: 0.000329, loss: 0.3977
2022-10-03 04:20:31 - train: epoch 0274, iter [00970, 01251], lr: 0.000329, loss: 0.3975
2022-10-03 04:20:49 - train: epoch 0274, iter [00980, 01251], lr: 0.000329, loss: 0.3975
2022-10-03 04:21:07 - train: epoch 0274, iter [00990, 01251], lr: 0.000329, loss: 0.4012
2022-10-03 04:21:24 - train: epoch 0274, iter [01000, 01251], lr: 0.000329, loss: 0.3913
2022-10-03 04:21:42 - train: epoch 0274, iter [01010, 01251], lr: 0.000329, loss: 0.3698
2022-10-03 04:22:00 - train: epoch 0274, iter [01020, 01251], lr: 0.000328, loss: 0.3998
2022-10-03 04:22:18 - train: epoch 0274, iter [01030, 01251], lr: 0.000328, loss: 0.4040
2022-10-03 04:22:36 - train: epoch 0274, iter [01040, 01251], lr: 0.000328, loss: 0.4017
2022-10-03 04:22:54 - train: epoch 0274, iter [01050, 01251], lr: 0.000328, loss: 0.3741
2022-10-03 04:23:12 - train: epoch 0274, iter [01060, 01251], lr: 0.000328, loss: 0.4008
2022-10-03 04:23:30 - train: epoch 0274, iter [01070, 01251], lr: 0.000328, loss: 0.3987
2022-10-03 04:23:48 - train: epoch 0274, iter [01080, 01251], lr: 0.000328, loss: 0.3989
2022-10-03 04:24:05 - train: epoch 0274, iter [01090, 01251], lr: 0.000328, loss: 0.4121
2022-10-03 04:24:23 - train: epoch 0274, iter [01100, 01251], lr: 0.000328, loss: 0.3890
2022-10-03 04:24:41 - train: epoch 0274, iter [01110, 01251], lr: 0.000328, loss: 0.4199
2022-10-03 04:24:59 - train: epoch 0274, iter [01120, 01251], lr: 0.000328, loss: 0.3866
2022-10-03 04:25:17 - train: epoch 0274, iter [01130, 01251], lr: 0.000328, loss: 0.3666
2022-10-03 04:25:35 - train: epoch 0274, iter [01140, 01251], lr: 0.000328, loss: 0.3847
2022-10-03 04:25:53 - train: epoch 0274, iter [01150, 01251], lr: 0.000328, loss: 0.3935
2022-10-03 04:26:11 - train: epoch 0274, iter [01160, 01251], lr: 0.000328, loss: 0.4128
2022-10-03 04:26:29 - train: epoch 0274, iter [01170, 01251], lr: 0.000328, loss: 0.3656
2022-10-03 04:26:47 - train: epoch 0274, iter [01180, 01251], lr: 0.000328, loss: 0.4024
2022-10-03 04:27:05 - train: epoch 0274, iter [01190, 01251], lr: 0.000328, loss: 0.4003
2022-10-03 04:27:23 - train: epoch 0274, iter [01200, 01251], lr: 0.000328, loss: 0.3951
2022-10-03 04:27:41 - train: epoch 0274, iter [01210, 01251], lr: 0.000328, loss: 0.3941
2022-10-03 04:27:59 - train: epoch 0274, iter [01220, 01251], lr: 0.000328, loss: 0.3821
2022-10-03 04:28:16 - train: epoch 0274, iter [01230, 01251], lr: 0.000328, loss: 0.3828
2022-10-03 04:28:34 - train: epoch 0274, iter [01240, 01251], lr: 0.000328, loss: 0.3942
2022-10-03 04:28:52 - train: epoch 0274, iter [01250, 01251], lr: 0.000328, loss: 0.4013
2022-10-03 04:28:55 - train: epoch 274, train_loss: 0.4004
2022-10-03 04:28:58 - until epoch: 274, best_loss: 0.4004
2022-10-03 04:28:58 - epoch 275 lr: 0.000328
2022-10-03 04:29:22 - train: epoch 0275, iter [00010, 01251], lr: 0.000328, loss: 0.4031
2022-10-03 04:29:40 - train: epoch 0275, iter [00020, 01251], lr: 0.000328, loss: 0.4001
2022-10-03 04:29:58 - train: epoch 0275, iter [00030, 01251], lr: 0.000327, loss: 0.3892
2022-10-03 04:30:16 - train: epoch 0275, iter [00040, 01251], lr: 0.000327, loss: 0.3943
2022-10-03 04:30:34 - train: epoch 0275, iter [00050, 01251], lr: 0.000327, loss: 0.3799
2022-10-03 04:30:52 - train: epoch 0275, iter [00060, 01251], lr: 0.000327, loss: 0.4080
2022-10-03 04:31:10 - train: epoch 0275, iter [00070, 01251], lr: 0.000327, loss: 0.3988
2022-10-03 04:31:28 - train: epoch 0275, iter [00080, 01251], lr: 0.000327, loss: 0.3910
2022-10-03 04:31:47 - train: epoch 0275, iter [00090, 01251], lr: 0.000327, loss: 0.3864
2022-10-03 04:32:05 - train: epoch 0275, iter [00100, 01251], lr: 0.000327, loss: 0.3989
2022-10-03 04:32:23 - train: epoch 0275, iter [00110, 01251], lr: 0.000327, loss: 0.4039
2022-10-03 04:32:41 - train: epoch 0275, iter [00120, 01251], lr: 0.000327, loss: 0.3956
2022-10-03 04:32:59 - train: epoch 0275, iter [00130, 01251], lr: 0.000327, loss: 0.4153
2022-10-03 04:33:17 - train: epoch 0275, iter [00140, 01251], lr: 0.000327, loss: 0.4196
2022-10-03 04:33:35 - train: epoch 0275, iter [00150, 01251], lr: 0.000327, loss: 0.4139
2022-10-03 04:33:53 - train: epoch 0275, iter [00160, 01251], lr: 0.000327, loss: 0.4080
2022-10-03 04:34:11 - train: epoch 0275, iter [00170, 01251], lr: 0.000327, loss: 0.4088
2022-10-03 04:34:30 - train: epoch 0275, iter [00180, 01251], lr: 0.000327, loss: 0.4107
2022-10-03 04:34:47 - train: epoch 0275, iter [00190, 01251], lr: 0.000327, loss: 0.3977
2022-10-03 04:35:06 - train: epoch 0275, iter [00200, 01251], lr: 0.000327, loss: 0.3942
2022-10-03 04:35:24 - train: epoch 0275, iter [00210, 01251], lr: 0.000327, loss: 0.3957
2022-10-03 04:35:42 - train: epoch 0275, iter [00220, 01251], lr: 0.000327, loss: 0.4008
2022-10-03 04:36:00 - train: epoch 0275, iter [00230, 01251], lr: 0.000327, loss: 0.4178
2022-10-03 04:36:18 - train: epoch 0275, iter [00240, 01251], lr: 0.000327, loss: 0.4104
2022-10-03 04:36:36 - train: epoch 0275, iter [00250, 01251], lr: 0.000327, loss: 0.4118
2022-10-03 04:36:54 - train: epoch 0275, iter [00260, 01251], lr: 0.000327, loss: 0.4173
2022-10-03 04:37:12 - train: epoch 0275, iter [00270, 01251], lr: 0.000327, loss: 0.3998
2022-10-03 04:37:30 - train: epoch 0275, iter [00280, 01251], lr: 0.000327, loss: 0.4234
2022-10-03 04:37:49 - train: epoch 0275, iter [00290, 01251], lr: 0.000327, loss: 0.4035
2022-10-03 04:38:07 - train: epoch 0275, iter [00300, 01251], lr: 0.000326, loss: 0.4107
2022-10-03 04:38:25 - train: epoch 0275, iter [00310, 01251], lr: 0.000326, loss: 0.3994
2022-10-03 04:38:43 - train: epoch 0275, iter [00320, 01251], lr: 0.000326, loss: 0.3838
2022-10-03 04:39:01 - train: epoch 0275, iter [00330, 01251], lr: 0.000326, loss: 0.3990
2022-10-03 04:39:19 - train: epoch 0275, iter [00340, 01251], lr: 0.000326, loss: 0.4080
2022-10-03 04:39:38 - train: epoch 0275, iter [00350, 01251], lr: 0.000326, loss: 0.4050
2022-10-03 04:39:56 - train: epoch 0275, iter [00360, 01251], lr: 0.000326, loss: 0.4000
2022-10-03 04:40:14 - train: epoch 0275, iter [00370, 01251], lr: 0.000326, loss: 0.4074
2022-10-03 04:40:32 - train: epoch 0275, iter [00380, 01251], lr: 0.000326, loss: 0.4148
2022-10-03 04:40:50 - train: epoch 0275, iter [00390, 01251], lr: 0.000326, loss: 0.3929
2022-10-03 04:41:08 - train: epoch 0275, iter [00400, 01251], lr: 0.000326, loss: 0.3974
2022-10-03 04:41:26 - train: epoch 0275, iter [00410, 01251], lr: 0.000326, loss: 0.4137
2022-10-03 04:41:44 - train: epoch 0275, iter [00420, 01251], lr: 0.000326, loss: 0.4065
2022-10-03 04:42:03 - train: epoch 0275, iter [00430, 01251], lr: 0.000326, loss: 0.3907
2022-10-03 04:42:21 - train: epoch 0275, iter [00440, 01251], lr: 0.000326, loss: 0.3933
2022-10-03 04:42:39 - train: epoch 0275, iter [00450, 01251], lr: 0.000326, loss: 0.3956
2022-10-03 04:42:57 - train: epoch 0275, iter [00460, 01251], lr: 0.000326, loss: 0.4064
2022-10-03 04:43:15 - train: epoch 0275, iter [00470, 01251], lr: 0.000326, loss: 0.4024
2022-10-03 04:43:33 - train: epoch 0275, iter [00480, 01251], lr: 0.000326, loss: 0.3968
2022-10-03 04:43:51 - train: epoch 0275, iter [00490, 01251], lr: 0.000326, loss: 0.3902
2022-10-03 04:44:10 - train: epoch 0275, iter [00500, 01251], lr: 0.000326, loss: 0.3913
2022-10-03 04:44:28 - train: epoch 0275, iter [00510, 01251], lr: 0.000326, loss: 0.3929
2022-10-03 04:44:46 - train: epoch 0275, iter [00520, 01251], lr: 0.000326, loss: 0.3966
2022-10-03 04:45:04 - train: epoch 0275, iter [00530, 01251], lr: 0.000326, loss: 0.3955
2022-10-03 04:45:23 - train: epoch 0275, iter [00540, 01251], lr: 0.000326, loss: 0.4114
2022-10-03 04:45:41 - train: epoch 0275, iter [00550, 01251], lr: 0.000326, loss: 0.4087
2022-10-03 04:45:59 - train: epoch 0275, iter [00560, 01251], lr: 0.000326, loss: 0.4064
2022-10-03 04:46:17 - train: epoch 0275, iter [00570, 01251], lr: 0.000325, loss: 0.4020
2022-10-03 04:46:35 - train: epoch 0275, iter [00580, 01251], lr: 0.000325, loss: 0.4161
2022-10-03 04:46:53 - train: epoch 0275, iter [00590, 01251], lr: 0.000325, loss: 0.4126
2022-10-03 04:47:11 - train: epoch 0275, iter [00600, 01251], lr: 0.000325, loss: 0.4048
2022-10-03 04:47:29 - train: epoch 0275, iter [00610, 01251], lr: 0.000325, loss: 0.4126
2022-10-03 04:47:48 - train: epoch 0275, iter [00620, 01251], lr: 0.000325, loss: 0.4069
2022-10-03 04:48:06 - train: epoch 0275, iter [00630, 01251], lr: 0.000325, loss: 0.3908
2022-10-03 04:48:24 - train: epoch 0275, iter [00640, 01251], lr: 0.000325, loss: 0.3909
2022-10-03 04:48:42 - train: epoch 0275, iter [00650, 01251], lr: 0.000325, loss: 0.4018
2022-10-03 04:49:00 - train: epoch 0275, iter [00660, 01251], lr: 0.000325, loss: 0.4228
2022-10-03 04:49:18 - train: epoch 0275, iter [00670, 01251], lr: 0.000325, loss: 0.4032
2022-10-03 04:49:36 - train: epoch 0275, iter [00680, 01251], lr: 0.000325, loss: 0.3967
2022-10-03 04:49:54 - train: epoch 0275, iter [00690, 01251], lr: 0.000325, loss: 0.4166
2022-10-03 04:50:12 - train: epoch 0275, iter [00700, 01251], lr: 0.000325, loss: 0.3859
2022-10-03 04:50:30 - train: epoch 0275, iter [00710, 01251], lr: 0.000325, loss: 0.4043
2022-10-03 04:50:48 - train: epoch 0275, iter [00720, 01251], lr: 0.000325, loss: 0.3928
2022-10-03 04:51:06 - train: epoch 0275, iter [00730, 01251], lr: 0.000325, loss: 0.3888
2022-10-03 04:51:24 - train: epoch 0275, iter [00740, 01251], lr: 0.000325, loss: 0.3964
2022-10-03 04:51:42 - train: epoch 0275, iter [00750, 01251], lr: 0.000325, loss: 0.4071
2022-10-03 04:52:01 - train: epoch 0275, iter [00760, 01251], lr: 0.000325, loss: 0.3974
2022-10-03 04:52:19 - train: epoch 0275, iter [00770, 01251], lr: 0.000325, loss: 0.4019
2022-10-03 04:52:37 - train: epoch 0275, iter [00780, 01251], lr: 0.000325, loss: 0.3908
2022-10-03 04:52:55 - train: epoch 0275, iter [00790, 01251], lr: 0.000325, loss: 0.3929
2022-10-03 04:53:13 - train: epoch 0275, iter [00800, 01251], lr: 0.000325, loss: 0.3964
2022-10-03 04:53:31 - train: epoch 0275, iter [00810, 01251], lr: 0.000325, loss: 0.3849
2022-10-03 04:53:49 - train: epoch 0275, iter [00820, 01251], lr: 0.000325, loss: 0.3799
2022-10-03 04:54:08 - train: epoch 0275, iter [00830, 01251], lr: 0.000325, loss: 0.4182
2022-10-03 04:54:25 - train: epoch 0275, iter [00840, 01251], lr: 0.000324, loss: 0.3816
2022-10-03 04:54:43 - train: epoch 0275, iter [00850, 01251], lr: 0.000324, loss: 0.3845
2022-10-03 04:55:02 - train: epoch 0275, iter [00860, 01251], lr: 0.000324, loss: 0.4071
2022-10-03 04:55:20 - train: epoch 0275, iter [00870, 01251], lr: 0.000324, loss: 0.4021
2022-10-03 04:55:38 - train: epoch 0275, iter [00880, 01251], lr: 0.000324, loss: 0.4208
2022-10-03 04:55:56 - train: epoch 0275, iter [00890, 01251], lr: 0.000324, loss: 0.4061
2022-10-03 04:56:14 - train: epoch 0275, iter [00900, 01251], lr: 0.000324, loss: 0.4152
2022-10-03 04:56:32 - train: epoch 0275, iter [00910, 01251], lr: 0.000324, loss: 0.3901
2022-10-03 04:56:50 - train: epoch 0275, iter [00920, 01251], lr: 0.000324, loss: 0.4125
2022-10-03 04:57:08 - train: epoch 0275, iter [00930, 01251], lr: 0.000324, loss: 0.4053
2022-10-03 04:57:26 - train: epoch 0275, iter [00940, 01251], lr: 0.000324, loss: 0.3957
2022-10-03 04:57:44 - train: epoch 0275, iter [00950, 01251], lr: 0.000324, loss: 0.3980
2022-10-03 04:58:02 - train: epoch 0275, iter [00960, 01251], lr: 0.000324, loss: 0.3870
2022-10-03 04:58:20 - train: epoch 0275, iter [00970, 01251], lr: 0.000324, loss: 0.3865
2022-10-03 04:58:38 - train: epoch 0275, iter [00980, 01251], lr: 0.000324, loss: 0.4290
2022-10-03 04:58:56 - train: epoch 0275, iter [00990, 01251], lr: 0.000324, loss: 0.3799
2022-10-03 04:59:14 - train: epoch 0275, iter [01000, 01251], lr: 0.000324, loss: 0.3939
2022-10-03 04:59:32 - train: epoch 0275, iter [01010, 01251], lr: 0.000324, loss: 0.3746
2022-10-03 04:59:50 - train: epoch 0275, iter [01020, 01251], lr: 0.000324, loss: 0.4114
2022-10-03 05:00:08 - train: epoch 0275, iter [01030, 01251], lr: 0.000324, loss: 0.3977
2022-10-03 05:00:26 - train: epoch 0275, iter [01040, 01251], lr: 0.000324, loss: 0.4053
2022-10-03 05:00:44 - train: epoch 0275, iter [01050, 01251], lr: 0.000324, loss: 0.3983
2022-10-03 05:01:02 - train: epoch 0275, iter [01060, 01251], lr: 0.000324, loss: 0.4012
2022-10-03 05:01:20 - train: epoch 0275, iter [01070, 01251], lr: 0.000324, loss: 0.3835
2022-10-03 05:01:38 - train: epoch 0275, iter [01080, 01251], lr: 0.000324, loss: 0.3927
2022-10-03 05:01:56 - train: epoch 0275, iter [01090, 01251], lr: 0.000324, loss: 0.3934
2022-10-03 05:02:15 - train: epoch 0275, iter [01100, 01251], lr: 0.000324, loss: 0.4080
2022-10-03 05:02:33 - train: epoch 0275, iter [01110, 01251], lr: 0.000323, loss: 0.4012
2022-10-03 05:02:51 - train: epoch 0275, iter [01120, 01251], lr: 0.000323, loss: 0.3812
2022-10-03 05:03:09 - train: epoch 0275, iter [01130, 01251], lr: 0.000323, loss: 0.4079
2022-10-03 05:03:26 - train: epoch 0275, iter [01140, 01251], lr: 0.000323, loss: 0.4034
2022-10-03 05:03:44 - train: epoch 0275, iter [01150, 01251], lr: 0.000323, loss: 0.4247
2022-10-03 05:04:02 - train: epoch 0275, iter [01160, 01251], lr: 0.000323, loss: 0.3972
2022-10-03 05:04:20 - train: epoch 0275, iter [01170, 01251], lr: 0.000323, loss: 0.4088
2022-10-03 05:04:38 - train: epoch 0275, iter [01180, 01251], lr: 0.000323, loss: 0.4100
2022-10-03 05:04:56 - train: epoch 0275, iter [01190, 01251], lr: 0.000323, loss: 0.3912
2022-10-03 05:05:14 - train: epoch 0275, iter [01200, 01251], lr: 0.000323, loss: 0.3934
2022-10-03 05:05:32 - train: epoch 0275, iter [01210, 01251], lr: 0.000323, loss: 0.4108
2022-10-03 05:05:50 - train: epoch 0275, iter [01220, 01251], lr: 0.000323, loss: 0.3941
2022-10-03 05:06:08 - train: epoch 0275, iter [01230, 01251], lr: 0.000323, loss: 0.3830
2022-10-03 05:06:27 - train: epoch 0275, iter [01240, 01251], lr: 0.000323, loss: 0.3824
2022-10-03 05:06:44 - train: epoch 0275, iter [01250, 01251], lr: 0.000323, loss: 0.3879
2022-10-03 05:06:47 - train: epoch 275, train_loss: 0.4002
2022-10-03 05:06:51 - until epoch: 275, best_loss: 0.4002
2022-10-03 05:06:51 - epoch 276 lr: 0.000323
2022-10-03 05:07:15 - train: epoch 0276, iter [00010, 01251], lr: 0.000323, loss: 0.3964
2022-10-03 05:07:33 - train: epoch 0276, iter [00020, 01251], lr: 0.000323, loss: 0.3974
2022-10-03 05:07:51 - train: epoch 0276, iter [00030, 01251], lr: 0.000323, loss: 0.4073
2022-10-03 05:08:09 - train: epoch 0276, iter [00040, 01251], lr: 0.000323, loss: 0.3925
2022-10-03 05:08:27 - train: epoch 0276, iter [00050, 01251], lr: 0.000323, loss: 0.3909
2022-10-03 05:08:45 - train: epoch 0276, iter [00060, 01251], lr: 0.000323, loss: 0.3921
2022-10-03 05:09:03 - train: epoch 0276, iter [00070, 01251], lr: 0.000323, loss: 0.3976
2022-10-03 05:09:21 - train: epoch 0276, iter [00080, 01251], lr: 0.000323, loss: 0.3996
2022-10-03 05:09:39 - train: epoch 0276, iter [00090, 01251], lr: 0.000323, loss: 0.3874
2022-10-03 05:09:57 - train: epoch 0276, iter [00100, 01251], lr: 0.000323, loss: 0.3780
2022-10-03 05:10:16 - train: epoch 0276, iter [00110, 01251], lr: 0.000323, loss: 0.4085
2022-10-03 05:10:34 - train: epoch 0276, iter [00120, 01251], lr: 0.000323, loss: 0.3961
2022-10-03 05:10:52 - train: epoch 0276, iter [00130, 01251], lr: 0.000322, loss: 0.3997
2022-10-03 05:11:10 - train: epoch 0276, iter [00140, 01251], lr: 0.000322, loss: 0.3712
2022-10-03 05:11:28 - train: epoch 0276, iter [00150, 01251], lr: 0.000322, loss: 0.3948
2022-10-03 05:11:46 - train: epoch 0276, iter [00160, 01251], lr: 0.000322, loss: 0.4035
2022-10-03 05:12:04 - train: epoch 0276, iter [00170, 01251], lr: 0.000322, loss: 0.4149
2022-10-03 05:12:22 - train: epoch 0276, iter [00180, 01251], lr: 0.000322, loss: 0.4107
2022-10-03 05:12:40 - train: epoch 0276, iter [00190, 01251], lr: 0.000322, loss: 0.3945
2022-10-03 05:12:58 - train: epoch 0276, iter [00200, 01251], lr: 0.000322, loss: 0.4057
2022-10-03 05:13:15 - train: epoch 0276, iter [00210, 01251], lr: 0.000322, loss: 0.3855
2022-10-03 05:13:33 - train: epoch 0276, iter [00220, 01251], lr: 0.000322, loss: 0.4026
2022-10-03 05:13:51 - train: epoch 0276, iter [00230, 01251], lr: 0.000322, loss: 0.4103
2022-10-03 05:14:10 - train: epoch 0276, iter [00240, 01251], lr: 0.000322, loss: 0.3949
2022-10-03 05:14:28 - train: epoch 0276, iter [00250, 01251], lr: 0.000322, loss: 0.4088
2022-10-03 05:14:46 - train: epoch 0276, iter [00260, 01251], lr: 0.000322, loss: 0.3798
2022-10-03 05:15:04 - train: epoch 0276, iter [00270, 01251], lr: 0.000322, loss: 0.3970
2022-10-03 05:15:22 - train: epoch 0276, iter [00280, 01251], lr: 0.000322, loss: 0.3940
2022-10-03 05:15:40 - train: epoch 0276, iter [00290, 01251], lr: 0.000322, loss: 0.4044
2022-10-03 05:15:58 - train: epoch 0276, iter [00300, 01251], lr: 0.000322, loss: 0.3855
2022-10-03 05:16:16 - train: epoch 0276, iter [00310, 01251], lr: 0.000322, loss: 0.4081
2022-10-03 05:16:34 - train: epoch 0276, iter [00320, 01251], lr: 0.000322, loss: 0.3906
2022-10-03 05:16:52 - train: epoch 0276, iter [00330, 01251], lr: 0.000322, loss: 0.4066
2022-10-03 05:17:11 - train: epoch 0276, iter [00340, 01251], lr: 0.000322, loss: 0.4069
2022-10-03 05:17:29 - train: epoch 0276, iter [00350, 01251], lr: 0.000322, loss: 0.3760
2022-10-03 05:17:47 - train: epoch 0276, iter [00360, 01251], lr: 0.000322, loss: 0.4097
2022-10-03 05:18:05 - train: epoch 0276, iter [00370, 01251], lr: 0.000322, loss: 0.3922
2022-10-03 05:18:23 - train: epoch 0276, iter [00380, 01251], lr: 0.000322, loss: 0.3918
2022-10-03 05:18:41 - train: epoch 0276, iter [00390, 01251], lr: 0.000322, loss: 0.3792
2022-10-03 05:18:59 - train: epoch 0276, iter [00400, 01251], lr: 0.000321, loss: 0.4182
2022-10-03 05:19:17 - train: epoch 0276, iter [00410, 01251], lr: 0.000321, loss: 0.4059
2022-10-03 05:19:36 - train: epoch 0276, iter [00420, 01251], lr: 0.000321, loss: 0.3879
2022-10-03 05:19:54 - train: epoch 0276, iter [00430, 01251], lr: 0.000321, loss: 0.3880
2022-10-03 05:20:12 - train: epoch 0276, iter [00440, 01251], lr: 0.000321, loss: 0.4064
2022-10-03 05:20:30 - train: epoch 0276, iter [00450, 01251], lr: 0.000321, loss: 0.3961
2022-10-03 05:20:48 - train: epoch 0276, iter [00460, 01251], lr: 0.000321, loss: 0.3919
2022-10-03 05:21:07 - train: epoch 0276, iter [00470, 01251], lr: 0.000321, loss: 0.3887
2022-10-03 05:21:25 - train: epoch 0276, iter [00480, 01251], lr: 0.000321, loss: 0.3992
2022-10-03 05:21:43 - train: epoch 0276, iter [00490, 01251], lr: 0.000321, loss: 0.3818
2022-10-03 05:22:02 - train: epoch 0276, iter [00500, 01251], lr: 0.000321, loss: 0.3852
2022-10-03 05:22:20 - train: epoch 0276, iter [00510, 01251], lr: 0.000321, loss: 0.3877
2022-10-03 05:22:38 - train: epoch 0276, iter [00520, 01251], lr: 0.000321, loss: 0.3973
2022-10-03 05:22:56 - train: epoch 0276, iter [00530, 01251], lr: 0.000321, loss: 0.3952
2022-10-03 05:23:15 - train: epoch 0276, iter [00540, 01251], lr: 0.000321, loss: 0.3993
2022-10-03 05:23:33 - train: epoch 0276, iter [00550, 01251], lr: 0.000321, loss: 0.3926
2022-10-03 05:23:51 - train: epoch 0276, iter [00560, 01251], lr: 0.000321, loss: 0.4162
2022-10-03 05:24:09 - train: epoch 0276, iter [00570, 01251], lr: 0.000321, loss: 0.4057
2022-10-03 05:24:27 - train: epoch 0276, iter [00580, 01251], lr: 0.000321, loss: 0.4032
2022-10-03 05:24:45 - train: epoch 0276, iter [00590, 01251], lr: 0.000321, loss: 0.4011
2022-10-03 05:25:03 - train: epoch 0276, iter [00600, 01251], lr: 0.000321, loss: 0.3950
2022-10-03 05:25:22 - train: epoch 0276, iter [00610, 01251], lr: 0.000321, loss: 0.3953
2022-10-03 05:25:40 - train: epoch 0276, iter [00620, 01251], lr: 0.000321, loss: 0.3702
2022-10-03 05:25:58 - train: epoch 0276, iter [00630, 01251], lr: 0.000321, loss: 0.4160
2022-10-03 05:26:16 - train: epoch 0276, iter [00640, 01251], lr: 0.000321, loss: 0.4024
2022-10-03 05:26:34 - train: epoch 0276, iter [00650, 01251], lr: 0.000321, loss: 0.3938
2022-10-03 05:26:52 - train: epoch 0276, iter [00660, 01251], lr: 0.000321, loss: 0.4142
2022-10-03 05:27:11 - train: epoch 0276, iter [00670, 01251], lr: 0.000320, loss: 0.3893
2022-10-03 05:27:29 - train: epoch 0276, iter [00680, 01251], lr: 0.000320, loss: 0.3899
2022-10-03 05:27:47 - train: epoch 0276, iter [00690, 01251], lr: 0.000320, loss: 0.3947
2022-10-03 05:28:05 - train: epoch 0276, iter [00700, 01251], lr: 0.000320, loss: 0.4079
2022-10-03 05:28:24 - train: epoch 0276, iter [00710, 01251], lr: 0.000320, loss: 0.3818
2022-10-03 05:28:42 - train: epoch 0276, iter [00720, 01251], lr: 0.000320, loss: 0.3821
2022-10-03 05:29:00 - train: epoch 0276, iter [00730, 01251], lr: 0.000320, loss: 0.4138
2022-10-03 05:29:18 - train: epoch 0276, iter [00740, 01251], lr: 0.000320, loss: 0.4026
2022-10-03 05:29:36 - train: epoch 0276, iter [00750, 01251], lr: 0.000320, loss: 0.4043
2022-10-03 05:29:54 - train: epoch 0276, iter [00760, 01251], lr: 0.000320, loss: 0.3835
2022-10-03 05:30:12 - train: epoch 0276, iter [00770, 01251], lr: 0.000320, loss: 0.3922
2022-10-03 05:30:30 - train: epoch 0276, iter [00780, 01251], lr: 0.000320, loss: 0.3917
2022-10-03 05:30:49 - train: epoch 0276, iter [00790, 01251], lr: 0.000320, loss: 0.4000
2022-10-03 05:31:07 - train: epoch 0276, iter [00800, 01251], lr: 0.000320, loss: 0.3817
2022-10-03 05:31:25 - train: epoch 0276, iter [00810, 01251], lr: 0.000320, loss: 0.4039
2022-10-03 05:31:43 - train: epoch 0276, iter [00820, 01251], lr: 0.000320, loss: 0.3939
2022-10-03 05:32:01 - train: epoch 0276, iter [00830, 01251], lr: 0.000320, loss: 0.4198
2022-10-03 05:32:19 - train: epoch 0276, iter [00840, 01251], lr: 0.000320, loss: 0.3965
2022-10-03 05:32:38 - train: epoch 0276, iter [00850, 01251], lr: 0.000320, loss: 0.4102
2022-10-03 05:32:56 - train: epoch 0276, iter [00860, 01251], lr: 0.000320, loss: 0.3961
2022-10-03 05:33:14 - train: epoch 0276, iter [00870, 01251], lr: 0.000320, loss: 0.3928
2022-10-03 05:33:32 - train: epoch 0276, iter [00880, 01251], lr: 0.000320, loss: 0.3972
2022-10-03 05:33:50 - train: epoch 0276, iter [00890, 01251], lr: 0.000320, loss: 0.3872
2022-10-03 05:34:08 - train: epoch 0276, iter [00900, 01251], lr: 0.000320, loss: 0.3891
2022-10-03 05:34:26 - train: epoch 0276, iter [00910, 01251], lr: 0.000320, loss: 0.4082
2022-10-03 05:34:44 - train: epoch 0276, iter [00920, 01251], lr: 0.000320, loss: 0.3822
2022-10-03 05:35:02 - train: epoch 0276, iter [00930, 01251], lr: 0.000320, loss: 0.4003
2022-10-03 05:35:21 - train: epoch 0276, iter [00940, 01251], lr: 0.000319, loss: 0.4079
2022-10-03 05:35:39 - train: epoch 0276, iter [00950, 01251], lr: 0.000319, loss: 0.3846
2022-10-03 05:35:57 - train: epoch 0276, iter [00960, 01251], lr: 0.000319, loss: 0.4176
2022-10-03 05:36:15 - train: epoch 0276, iter [00970, 01251], lr: 0.000319, loss: 0.3940
2022-10-03 05:36:33 - train: epoch 0276, iter [00980, 01251], lr: 0.000319, loss: 0.3987
2022-10-03 05:36:51 - train: epoch 0276, iter [00990, 01251], lr: 0.000319, loss: 0.4046
2022-10-03 05:37:09 - train: epoch 0276, iter [01000, 01251], lr: 0.000319, loss: 0.4102
2022-10-03 05:37:27 - train: epoch 0276, iter [01010, 01251], lr: 0.000319, loss: 0.4144
2022-10-03 05:37:45 - train: epoch 0276, iter [01020, 01251], lr: 0.000319, loss: 0.3929
2022-10-03 05:38:03 - train: epoch 0276, iter [01030, 01251], lr: 0.000319, loss: 0.4079
2022-10-03 05:38:22 - train: epoch 0276, iter [01040, 01251], lr: 0.000319, loss: 0.3976
2022-10-03 05:38:40 - train: epoch 0276, iter [01050, 01251], lr: 0.000319, loss: 0.4065
2022-10-03 05:38:58 - train: epoch 0276, iter [01060, 01251], lr: 0.000319, loss: 0.4145
2022-10-03 05:39:16 - train: epoch 0276, iter [01070, 01251], lr: 0.000319, loss: 0.3961
2022-10-03 05:39:34 - train: epoch 0276, iter [01080, 01251], lr: 0.000319, loss: 0.3967
2022-10-03 05:39:52 - train: epoch 0276, iter [01090, 01251], lr: 0.000319, loss: 0.3998
2022-10-03 05:40:10 - train: epoch 0276, iter [01100, 01251], lr: 0.000319, loss: 0.3825
2022-10-03 05:40:29 - train: epoch 0276, iter [01110, 01251], lr: 0.000319, loss: 0.4196
2022-10-03 05:40:47 - train: epoch 0276, iter [01120, 01251], lr: 0.000319, loss: 0.4055
2022-10-03 05:41:05 - train: epoch 0276, iter [01130, 01251], lr: 0.000319, loss: 0.4085
2022-10-03 05:41:23 - train: epoch 0276, iter [01140, 01251], lr: 0.000319, loss: 0.3913
2022-10-03 05:41:41 - train: epoch 0276, iter [01150, 01251], lr: 0.000319, loss: 0.3933
2022-10-03 05:41:59 - train: epoch 0276, iter [01160, 01251], lr: 0.000319, loss: 0.3920
2022-10-03 05:42:17 - train: epoch 0276, iter [01170, 01251], lr: 0.000319, loss: 0.3897
2022-10-03 05:42:35 - train: epoch 0276, iter [01180, 01251], lr: 0.000319, loss: 0.4245
2022-10-03 05:42:53 - train: epoch 0276, iter [01190, 01251], lr: 0.000319, loss: 0.4116
2022-10-03 05:43:11 - train: epoch 0276, iter [01200, 01251], lr: 0.000319, loss: 0.4188
2022-10-03 05:43:29 - train: epoch 0276, iter [01210, 01251], lr: 0.000318, loss: 0.3988
2022-10-03 05:43:48 - train: epoch 0276, iter [01220, 01251], lr: 0.000318, loss: 0.3918
2022-10-03 05:44:06 - train: epoch 0276, iter [01230, 01251], lr: 0.000318, loss: 0.4067
2022-10-03 05:44:24 - train: epoch 0276, iter [01240, 01251], lr: 0.000318, loss: 0.4084
2022-10-03 05:44:41 - train: epoch 0276, iter [01250, 01251], lr: 0.000318, loss: 0.4004
2022-10-03 05:44:45 - train: epoch 276, train_loss: 0.4002
2022-10-03 05:44:47 - until epoch: 276, best_loss: 0.4002
2022-10-03 05:44:47 - epoch 277 lr: 0.000318
2022-10-03 05:45:12 - train: epoch 0277, iter [00010, 01251], lr: 0.000318, loss: 0.4036
2022-10-03 05:45:31 - train: epoch 0277, iter [00020, 01251], lr: 0.000318, loss: 0.3774
2022-10-03 05:45:48 - train: epoch 0277, iter [00030, 01251], lr: 0.000318, loss: 0.4040
2022-10-03 05:46:06 - train: epoch 0277, iter [00040, 01251], lr: 0.000318, loss: 0.4057
2022-10-03 05:46:24 - train: epoch 0277, iter [00050, 01251], lr: 0.000318, loss: 0.4087
2022-10-03 05:46:42 - train: epoch 0277, iter [00060, 01251], lr: 0.000318, loss: 0.3997
2022-10-03 05:47:00 - train: epoch 0277, iter [00070, 01251], lr: 0.000318, loss: 0.4026
2022-10-03 05:47:18 - train: epoch 0277, iter [00080, 01251], lr: 0.000318, loss: 0.4185
2022-10-03 05:47:36 - train: epoch 0277, iter [00090, 01251], lr: 0.000318, loss: 0.3999
2022-10-03 05:47:54 - train: epoch 0277, iter [00100, 01251], lr: 0.000318, loss: 0.3935
2022-10-03 05:48:12 - train: epoch 0277, iter [00110, 01251], lr: 0.000318, loss: 0.3953
2022-10-03 05:48:30 - train: epoch 0277, iter [00120, 01251], lr: 0.000318, loss: 0.4123
2022-10-03 05:48:48 - train: epoch 0277, iter [00130, 01251], lr: 0.000318, loss: 0.3881
2022-10-03 05:49:06 - train: epoch 0277, iter [00140, 01251], lr: 0.000318, loss: 0.4110
2022-10-03 05:49:24 - train: epoch 0277, iter [00150, 01251], lr: 0.000318, loss: 0.3929
2022-10-03 05:49:42 - train: epoch 0277, iter [00160, 01251], lr: 0.000318, loss: 0.4176
2022-10-03 05:50:00 - train: epoch 0277, iter [00170, 01251], lr: 0.000318, loss: 0.3992
2022-10-03 05:50:18 - train: epoch 0277, iter [00180, 01251], lr: 0.000318, loss: 0.4018
2022-10-03 05:50:36 - train: epoch 0277, iter [00190, 01251], lr: 0.000318, loss: 0.3805
2022-10-03 05:50:54 - train: epoch 0277, iter [00200, 01251], lr: 0.000318, loss: 0.3996
2022-10-03 05:51:12 - train: epoch 0277, iter [00210, 01251], lr: 0.000318, loss: 0.4161
2022-10-03 05:51:30 - train: epoch 0277, iter [00220, 01251], lr: 0.000318, loss: 0.4131
2022-10-03 05:51:48 - train: epoch 0277, iter [00230, 01251], lr: 0.000317, loss: 0.3969
2022-10-03 05:52:05 - train: epoch 0277, iter [00240, 01251], lr: 0.000317, loss: 0.3932
2022-10-03 05:52:23 - train: epoch 0277, iter [00250, 01251], lr: 0.000317, loss: 0.3825
2022-10-03 05:52:41 - train: epoch 0277, iter [00260, 01251], lr: 0.000317, loss: 0.3975
2022-10-03 05:52:59 - train: epoch 0277, iter [00270, 01251], lr: 0.000317, loss: 0.3863
2022-10-03 05:53:17 - train: epoch 0277, iter [00280, 01251], lr: 0.000317, loss: 0.4043
2022-10-03 05:53:35 - train: epoch 0277, iter [00290, 01251], lr: 0.000317, loss: 0.3896
2022-10-03 05:53:53 - train: epoch 0277, iter [00300, 01251], lr: 0.000317, loss: 0.3972
2022-10-03 05:54:11 - train: epoch 0277, iter [00310, 01251], lr: 0.000317, loss: 0.3833
2022-10-03 05:54:29 - train: epoch 0277, iter [00320, 01251], lr: 0.000317, loss: 0.4039
2022-10-03 05:54:47 - train: epoch 0277, iter [00330, 01251], lr: 0.000317, loss: 0.4021
2022-10-03 05:55:05 - train: epoch 0277, iter [00340, 01251], lr: 0.000317, loss: 0.4075
2022-10-03 05:55:23 - train: epoch 0277, iter [00350, 01251], lr: 0.000317, loss: 0.4056
2022-10-03 05:55:41 - train: epoch 0277, iter [00360, 01251], lr: 0.000317, loss: 0.4016
2022-10-03 05:55:59 - train: epoch 0277, iter [00370, 01251], lr: 0.000317, loss: 0.4067
2022-10-03 05:56:18 - train: epoch 0277, iter [00380, 01251], lr: 0.000317, loss: 0.3887
2022-10-03 05:56:36 - train: epoch 0277, iter [00390, 01251], lr: 0.000317, loss: 0.3841
2022-10-03 05:56:54 - train: epoch 0277, iter [00400, 01251], lr: 0.000317, loss: 0.4100
2022-10-03 05:57:12 - train: epoch 0277, iter [00410, 01251], lr: 0.000317, loss: 0.3969
2022-10-03 05:57:30 - train: epoch 0277, iter [00420, 01251], lr: 0.000317, loss: 0.3923
2022-10-03 05:57:48 - train: epoch 0277, iter [00430, 01251], lr: 0.000317, loss: 0.3944
2022-10-03 05:58:06 - train: epoch 0277, iter [00440, 01251], lr: 0.000317, loss: 0.4109
2022-10-03 05:58:24 - train: epoch 0277, iter [00450, 01251], lr: 0.000317, loss: 0.4009
2022-10-03 05:58:42 - train: epoch 0277, iter [00460, 01251], lr: 0.000317, loss: 0.4021
2022-10-03 05:59:00 - train: epoch 0277, iter [00470, 01251], lr: 0.000317, loss: 0.4013
2022-10-03 05:59:18 - train: epoch 0277, iter [00480, 01251], lr: 0.000317, loss: 0.3894
2022-10-03 05:59:37 - train: epoch 0277, iter [00490, 01251], lr: 0.000317, loss: 0.3915
2022-10-03 05:59:55 - train: epoch 0277, iter [00500, 01251], lr: 0.000316, loss: 0.4000
2022-10-03 06:00:13 - train: epoch 0277, iter [00510, 01251], lr: 0.000316, loss: 0.4055
2022-10-03 06:00:31 - train: epoch 0277, iter [00520, 01251], lr: 0.000316, loss: 0.3936
2022-10-03 06:00:49 - train: epoch 0277, iter [00530, 01251], lr: 0.000316, loss: 0.4083
2022-10-03 06:01:07 - train: epoch 0277, iter [00540, 01251], lr: 0.000316, loss: 0.4046
2022-10-03 06:01:25 - train: epoch 0277, iter [00550, 01251], lr: 0.000316, loss: 0.3848
2022-10-03 06:01:43 - train: epoch 0277, iter [00560, 01251], lr: 0.000316, loss: 0.3974
2022-10-03 06:02:02 - train: epoch 0277, iter [00570, 01251], lr: 0.000316, loss: 0.3914
2022-10-03 06:02:20 - train: epoch 0277, iter [00580, 01251], lr: 0.000316, loss: 0.3777
2022-10-03 06:02:38 - train: epoch 0277, iter [00590, 01251], lr: 0.000316, loss: 0.4053
2022-10-03 06:02:56 - train: epoch 0277, iter [00600, 01251], lr: 0.000316, loss: 0.4058
2022-10-03 06:03:14 - train: epoch 0277, iter [00610, 01251], lr: 0.000316, loss: 0.3773
2022-10-03 06:03:32 - train: epoch 0277, iter [00620, 01251], lr: 0.000316, loss: 0.3816
2022-10-03 06:03:50 - train: epoch 0277, iter [00630, 01251], lr: 0.000316, loss: 0.3980
2022-10-03 06:04:08 - train: epoch 0277, iter [00640, 01251], lr: 0.000316, loss: 0.3929
2022-10-03 06:04:26 - train: epoch 0277, iter [00650, 01251], lr: 0.000316, loss: 0.4011
2022-10-03 06:04:44 - train: epoch 0277, iter [00660, 01251], lr: 0.000316, loss: 0.3917
2022-10-03 06:05:02 - train: epoch 0277, iter [00670, 01251], lr: 0.000316, loss: 0.3974
2022-10-03 06:05:20 - train: epoch 0277, iter [00680, 01251], lr: 0.000316, loss: 0.4066
2022-10-03 06:05:38 - train: epoch 0277, iter [00690, 01251], lr: 0.000316, loss: 0.4032
2022-10-03 06:05:56 - train: epoch 0277, iter [00700, 01251], lr: 0.000316, loss: 0.4013
2022-10-03 06:06:14 - train: epoch 0277, iter [00710, 01251], lr: 0.000316, loss: 0.4096
2022-10-03 06:06:32 - train: epoch 0277, iter [00720, 01251], lr: 0.000316, loss: 0.3851
2022-10-03 06:06:50 - train: epoch 0277, iter [00730, 01251], lr: 0.000316, loss: 0.4059
2022-10-03 06:07:09 - train: epoch 0277, iter [00740, 01251], lr: 0.000316, loss: 0.3859
2022-10-03 06:07:27 - train: epoch 0277, iter [00750, 01251], lr: 0.000316, loss: 0.3990
2022-10-03 06:07:45 - train: epoch 0277, iter [00760, 01251], lr: 0.000316, loss: 0.4062
2022-10-03 06:08:03 - train: epoch 0277, iter [00770, 01251], lr: 0.000315, loss: 0.4045
2022-10-03 06:08:21 - train: epoch 0277, iter [00780, 01251], lr: 0.000315, loss: 0.3981
2022-10-03 06:08:39 - train: epoch 0277, iter [00790, 01251], lr: 0.000315, loss: 0.3958
2022-10-03 06:08:57 - train: epoch 0277, iter [00800, 01251], lr: 0.000315, loss: 0.3972
2022-10-03 06:09:15 - train: epoch 0277, iter [00810, 01251], lr: 0.000315, loss: 0.4057
2022-10-03 06:09:33 - train: epoch 0277, iter [00820, 01251], lr: 0.000315, loss: 0.4016
2022-10-03 06:09:51 - train: epoch 0277, iter [00830, 01251], lr: 0.000315, loss: 0.3914
2022-10-03 06:10:10 - train: epoch 0277, iter [00840, 01251], lr: 0.000315, loss: 0.3994
2022-10-03 06:10:28 - train: epoch 0277, iter [00850, 01251], lr: 0.000315, loss: 0.3977
2022-10-03 06:10:46 - train: epoch 0277, iter [00860, 01251], lr: 0.000315, loss: 0.3875
2022-10-03 06:11:04 - train: epoch 0277, iter [00870, 01251], lr: 0.000315, loss: 0.3989
2022-10-03 06:11:22 - train: epoch 0277, iter [00880, 01251], lr: 0.000315, loss: 0.3904
2022-10-03 06:11:40 - train: epoch 0277, iter [00890, 01251], lr: 0.000315, loss: 0.3876
2022-10-03 06:11:58 - train: epoch 0277, iter [00900, 01251], lr: 0.000315, loss: 0.4037
2022-10-03 06:12:16 - train: epoch 0277, iter [00910, 01251], lr: 0.000315, loss: 0.4119
2022-10-03 06:12:34 - train: epoch 0277, iter [00920, 01251], lr: 0.000315, loss: 0.4065
2022-10-03 06:12:53 - train: epoch 0277, iter [00930, 01251], lr: 0.000315, loss: 0.4064
2022-10-03 06:13:11 - train: epoch 0277, iter [00940, 01251], lr: 0.000315, loss: 0.3971
2022-10-03 06:13:29 - train: epoch 0277, iter [00950, 01251], lr: 0.000315, loss: 0.4139
2022-10-03 06:13:47 - train: epoch 0277, iter [00960, 01251], lr: 0.000315, loss: 0.3979
2022-10-03 06:14:05 - train: epoch 0277, iter [00970, 01251], lr: 0.000315, loss: 0.3804
2022-10-03 06:14:23 - train: epoch 0277, iter [00980, 01251], lr: 0.000315, loss: 0.3951
2022-10-03 06:14:41 - train: epoch 0277, iter [00990, 01251], lr: 0.000315, loss: 0.3993
2022-10-03 06:14:59 - train: epoch 0277, iter [01000, 01251], lr: 0.000315, loss: 0.4023
2022-10-03 06:15:17 - train: epoch 0277, iter [01010, 01251], lr: 0.000315, loss: 0.4016
2022-10-03 06:15:35 - train: epoch 0277, iter [01020, 01251], lr: 0.000315, loss: 0.3834
2022-10-03 06:15:53 - train: epoch 0277, iter [01030, 01251], lr: 0.000315, loss: 0.4001
2022-10-03 06:16:11 - train: epoch 0277, iter [01040, 01251], lr: 0.000314, loss: 0.3960
2022-10-03 06:16:29 - train: epoch 0277, iter [01050, 01251], lr: 0.000314, loss: 0.3738
2022-10-03 06:16:48 - train: epoch 0277, iter [01060, 01251], lr: 0.000314, loss: 0.4175
2022-10-03 06:17:05 - train: epoch 0277, iter [01070, 01251], lr: 0.000314, loss: 0.3888
2022-10-03 06:17:23 - train: epoch 0277, iter [01080, 01251], lr: 0.000314, loss: 0.3949
2022-10-03 06:17:42 - train: epoch 0277, iter [01090, 01251], lr: 0.000314, loss: 0.3968
2022-10-03 06:18:00 - train: epoch 0277, iter [01100, 01251], lr: 0.000314, loss: 0.4023
2022-10-03 06:18:18 - train: epoch 0277, iter [01110, 01251], lr: 0.000314, loss: 0.3961
2022-10-03 06:18:36 - train: epoch 0277, iter [01120, 01251], lr: 0.000314, loss: 0.4122
2022-10-03 06:18:54 - train: epoch 0277, iter [01130, 01251], lr: 0.000314, loss: 0.3903
2022-10-03 06:19:12 - train: epoch 0277, iter [01140, 01251], lr: 0.000314, loss: 0.3950
2022-10-03 06:19:30 - train: epoch 0277, iter [01150, 01251], lr: 0.000314, loss: 0.3959
2022-10-03 06:19:48 - train: epoch 0277, iter [01160, 01251], lr: 0.000314, loss: 0.3880
2022-10-03 06:20:06 - train: epoch 0277, iter [01170, 01251], lr: 0.000314, loss: 0.3942
2022-10-03 06:20:24 - train: epoch 0277, iter [01180, 01251], lr: 0.000314, loss: 0.4196
2022-10-03 06:20:42 - train: epoch 0277, iter [01190, 01251], lr: 0.000314, loss: 0.4033
2022-10-03 06:21:00 - train: epoch 0277, iter [01200, 01251], lr: 0.000314, loss: 0.3891
2022-10-03 06:21:18 - train: epoch 0277, iter [01210, 01251], lr: 0.000314, loss: 0.4064
2022-10-03 06:21:36 - train: epoch 0277, iter [01220, 01251], lr: 0.000314, loss: 0.3864
2022-10-03 06:21:54 - train: epoch 0277, iter [01230, 01251], lr: 0.000314, loss: 0.4022
2022-10-03 06:22:12 - train: epoch 0277, iter [01240, 01251], lr: 0.000314, loss: 0.3916
2022-10-03 06:22:30 - train: epoch 0277, iter [01250, 01251], lr: 0.000314, loss: 0.4009
2022-10-03 06:22:33 - train: epoch 277, train_loss: 0.4000
2022-10-03 06:22:36 - until epoch: 277, best_loss: 0.4000
2022-10-03 06:22:36 - epoch 278 lr: 0.000314
2022-10-03 06:23:01 - train: epoch 0278, iter [00010, 01251], lr: 0.000314, loss: 0.3784
2022-10-03 06:23:19 - train: epoch 0278, iter [00020, 01251], lr: 0.000314, loss: 0.3758
2022-10-03 06:23:37 - train: epoch 0278, iter [00030, 01251], lr: 0.000314, loss: 0.3979
2022-10-03 06:23:54 - train: epoch 0278, iter [00040, 01251], lr: 0.000314, loss: 0.3909
2022-10-03 06:24:12 - train: epoch 0278, iter [00050, 01251], lr: 0.000314, loss: 0.4062
2022-10-03 06:24:30 - train: epoch 0278, iter [00060, 01251], lr: 0.000313, loss: 0.3844
2022-10-03 06:24:48 - train: epoch 0278, iter [00070, 01251], lr: 0.000313, loss: 0.3986
2022-10-03 06:25:06 - train: epoch 0278, iter [00080, 01251], lr: 0.000313, loss: 0.4223
2022-10-03 06:25:25 - train: epoch 0278, iter [00090, 01251], lr: 0.000313, loss: 0.4098
2022-10-03 06:25:42 - train: epoch 0278, iter [00100, 01251], lr: 0.000313, loss: 0.3990
2022-10-03 06:26:00 - train: epoch 0278, iter [00110, 01251], lr: 0.000313, loss: 0.4023
2022-10-03 06:26:18 - train: epoch 0278, iter [00120, 01251], lr: 0.000313, loss: 0.4012
2022-10-03 06:26:36 - train: epoch 0278, iter [00130, 01251], lr: 0.000313, loss: 0.3928
2022-10-03 06:26:54 - train: epoch 0278, iter [00140, 01251], lr: 0.000313, loss: 0.4092
2022-10-03 06:27:12 - train: epoch 0278, iter [00150, 01251], lr: 0.000313, loss: 0.3982
2022-10-03 06:27:30 - train: epoch 0278, iter [00160, 01251], lr: 0.000313, loss: 0.3922
2022-10-03 06:27:48 - train: epoch 0278, iter [00170, 01251], lr: 0.000313, loss: 0.4074
2022-10-03 06:28:06 - train: epoch 0278, iter [00180, 01251], lr: 0.000313, loss: 0.4214
2022-10-03 06:28:24 - train: epoch 0278, iter [00190, 01251], lr: 0.000313, loss: 0.3979
2022-10-03 06:28:42 - train: epoch 0278, iter [00200, 01251], lr: 0.000313, loss: 0.3833
2022-10-03 06:29:00 - train: epoch 0278, iter [00210, 01251], lr: 0.000313, loss: 0.4014
2022-10-03 06:29:18 - train: epoch 0278, iter [00220, 01251], lr: 0.000313, loss: 0.4082
2022-10-03 06:29:36 - train: epoch 0278, iter [00230, 01251], lr: 0.000313, loss: 0.4049
2022-10-03 06:29:54 - train: epoch 0278, iter [00240, 01251], lr: 0.000313, loss: 0.4141
2022-10-03 06:30:12 - train: epoch 0278, iter [00250, 01251], lr: 0.000313, loss: 0.4261
2022-10-03 06:30:30 - train: epoch 0278, iter [00260, 01251], lr: 0.000313, loss: 0.4062
2022-10-03 06:30:48 - train: epoch 0278, iter [00270, 01251], lr: 0.000313, loss: 0.3924
2022-10-03 06:31:06 - train: epoch 0278, iter [00280, 01251], lr: 0.000313, loss: 0.4042
2022-10-03 06:31:24 - train: epoch 0278, iter [00290, 01251], lr: 0.000313, loss: 0.4044
2022-10-03 06:31:42 - train: epoch 0278, iter [00300, 01251], lr: 0.000313, loss: 0.4020
2022-10-03 06:32:00 - train: epoch 0278, iter [00310, 01251], lr: 0.000313, loss: 0.3969
2022-10-03 06:32:18 - train: epoch 0278, iter [00320, 01251], lr: 0.000313, loss: 0.3979
2022-10-03 06:32:36 - train: epoch 0278, iter [00330, 01251], lr: 0.000312, loss: 0.3946
2022-10-03 06:32:54 - train: epoch 0278, iter [00340, 01251], lr: 0.000312, loss: 0.4121
2022-10-03 06:33:12 - train: epoch 0278, iter [00350, 01251], lr: 0.000312, loss: 0.3858
2022-10-03 06:33:30 - train: epoch 0278, iter [00360, 01251], lr: 0.000312, loss: 0.3945
2022-10-03 06:33:48 - train: epoch 0278, iter [00370, 01251], lr: 0.000312, loss: 0.3873
2022-10-03 06:34:06 - train: epoch 0278, iter [00380, 01251], lr: 0.000312, loss: 0.3903
2022-10-03 06:34:24 - train: epoch 0278, iter [00390, 01251], lr: 0.000312, loss: 0.3813
2022-10-03 06:34:42 - train: epoch 0278, iter [00400, 01251], lr: 0.000312, loss: 0.3981
2022-10-03 06:35:00 - train: epoch 0278, iter [00410, 01251], lr: 0.000312, loss: 0.4003
2022-10-03 06:35:18 - train: epoch 0278, iter [00420, 01251], lr: 0.000312, loss: 0.3907
2022-10-03 06:35:36 - train: epoch 0278, iter [00430, 01251], lr: 0.000312, loss: 0.3971
2022-10-03 06:35:54 - train: epoch 0278, iter [00440, 01251], lr: 0.000312, loss: 0.4019
2022-10-03 06:36:12 - train: epoch 0278, iter [00450, 01251], lr: 0.000312, loss: 0.4103
2022-10-03 06:36:30 - train: epoch 0278, iter [00460, 01251], lr: 0.000312, loss: 0.4042
2022-10-03 06:36:48 - train: epoch 0278, iter [00470, 01251], lr: 0.000312, loss: 0.3962
2022-10-03 06:37:06 - train: epoch 0278, iter [00480, 01251], lr: 0.000312, loss: 0.4061
2022-10-03 06:37:24 - train: epoch 0278, iter [00490, 01251], lr: 0.000312, loss: 0.4012
2022-10-03 06:37:42 - train: epoch 0278, iter [00500, 01251], lr: 0.000312, loss: 0.3795
2022-10-03 06:38:00 - train: epoch 0278, iter [00510, 01251], lr: 0.000312, loss: 0.4071
2022-10-03 06:38:18 - train: epoch 0278, iter [00520, 01251], lr: 0.000312, loss: 0.3857
2022-10-03 06:38:36 - train: epoch 0278, iter [00530, 01251], lr: 0.000312, loss: 0.4040
2022-10-03 06:38:54 - train: epoch 0278, iter [00540, 01251], lr: 0.000312, loss: 0.3873
2022-10-03 06:39:13 - train: epoch 0278, iter [00550, 01251], lr: 0.000312, loss: 0.3874
2022-10-03 06:39:31 - train: epoch 0278, iter [00560, 01251], lr: 0.000312, loss: 0.4243
2022-10-03 06:39:49 - train: epoch 0278, iter [00570, 01251], lr: 0.000312, loss: 0.4045
2022-10-03 06:40:07 - train: epoch 0278, iter [00580, 01251], lr: 0.000312, loss: 0.3908
2022-10-03 06:40:25 - train: epoch 0278, iter [00590, 01251], lr: 0.000312, loss: 0.3879
2022-10-03 06:40:43 - train: epoch 0278, iter [00600, 01251], lr: 0.000312, loss: 0.4058
2022-10-03 06:41:01 - train: epoch 0278, iter [00610, 01251], lr: 0.000311, loss: 0.3710
2022-10-03 06:41:19 - train: epoch 0278, iter [00620, 01251], lr: 0.000311, loss: 0.4063
2022-10-03 06:41:37 - train: epoch 0278, iter [00630, 01251], lr: 0.000311, loss: 0.3961
2022-10-03 06:41:55 - train: epoch 0278, iter [00640, 01251], lr: 0.000311, loss: 0.3827
2022-10-03 06:42:13 - train: epoch 0278, iter [00650, 01251], lr: 0.000311, loss: 0.3684
2022-10-03 06:42:32 - train: epoch 0278, iter [00660, 01251], lr: 0.000311, loss: 0.4066
2022-10-03 06:42:50 - train: epoch 0278, iter [00670, 01251], lr: 0.000311, loss: 0.3964
2022-10-03 06:43:08 - train: epoch 0278, iter [00680, 01251], lr: 0.000311, loss: 0.4057
2022-10-03 06:43:26 - train: epoch 0278, iter [00690, 01251], lr: 0.000311, loss: 0.3939
2022-10-03 06:43:44 - train: epoch 0278, iter [00700, 01251], lr: 0.000311, loss: 0.3925
2022-10-03 06:44:02 - train: epoch 0278, iter [00710, 01251], lr: 0.000311, loss: 0.3925
2022-10-03 06:44:20 - train: epoch 0278, iter [00720, 01251], lr: 0.000311, loss: 0.4062
2022-10-03 06:44:38 - train: epoch 0278, iter [00730, 01251], lr: 0.000311, loss: 0.4059
2022-10-03 06:44:56 - train: epoch 0278, iter [00740, 01251], lr: 0.000311, loss: 0.4172
2022-10-03 06:45:14 - train: epoch 0278, iter [00750, 01251], lr: 0.000311, loss: 0.4010
2022-10-03 06:45:33 - train: epoch 0278, iter [00760, 01251], lr: 0.000311, loss: 0.3952
2022-10-03 06:45:51 - train: epoch 0278, iter [00770, 01251], lr: 0.000311, loss: 0.4035
2022-10-03 06:46:08 - train: epoch 0278, iter [00780, 01251], lr: 0.000311, loss: 0.3861
2022-10-03 06:46:26 - train: epoch 0278, iter [00790, 01251], lr: 0.000311, loss: 0.4007
2022-10-03 06:46:44 - train: epoch 0278, iter [00800, 01251], lr: 0.000311, loss: 0.4238
2022-10-03 06:47:03 - train: epoch 0278, iter [00810, 01251], lr: 0.000311, loss: 0.3773
2022-10-03 06:47:21 - train: epoch 0278, iter [00820, 01251], lr: 0.000311, loss: 0.3984
2022-10-03 06:47:39 - train: epoch 0278, iter [00830, 01251], lr: 0.000311, loss: 0.3899
2022-10-03 06:47:57 - train: epoch 0278, iter [00840, 01251], lr: 0.000311, loss: 0.4118
2022-10-03 06:48:15 - train: epoch 0278, iter [00850, 01251], lr: 0.000311, loss: 0.3965
2022-10-03 06:48:33 - train: epoch 0278, iter [00860, 01251], lr: 0.000311, loss: 0.3961
2022-10-03 06:48:51 - train: epoch 0278, iter [00870, 01251], lr: 0.000311, loss: 0.3890
2022-10-03 06:49:09 - train: epoch 0278, iter [00880, 01251], lr: 0.000310, loss: 0.4028
2022-10-03 06:49:28 - train: epoch 0278, iter [00890, 01251], lr: 0.000310, loss: 0.3723
2022-10-03 06:49:46 - train: epoch 0278, iter [00900, 01251], lr: 0.000310, loss: 0.4130
2022-10-03 06:50:04 - train: epoch 0278, iter [00910, 01251], lr: 0.000310, loss: 0.4128
2022-10-03 06:50:22 - train: epoch 0278, iter [00920, 01251], lr: 0.000310, loss: 0.3938
2022-10-03 06:50:40 - train: epoch 0278, iter [00930, 01251], lr: 0.000310, loss: 0.4066
2022-10-03 06:50:58 - train: epoch 0278, iter [00940, 01251], lr: 0.000310, loss: 0.4164
2022-10-03 06:51:16 - train: epoch 0278, iter [00950, 01251], lr: 0.000310, loss: 0.4064
2022-10-03 06:51:34 - train: epoch 0278, iter [00960, 01251], lr: 0.000310, loss: 0.4134
2022-10-03 06:51:52 - train: epoch 0278, iter [00970, 01251], lr: 0.000310, loss: 0.4094
2022-10-03 06:52:10 - train: epoch 0278, iter [00980, 01251], lr: 0.000310, loss: 0.3882
2022-10-03 06:52:28 - train: epoch 0278, iter [00990, 01251], lr: 0.000310, loss: 0.4009
2022-10-03 06:52:46 - train: epoch 0278, iter [01000, 01251], lr: 0.000310, loss: 0.4079
2022-10-03 06:53:04 - train: epoch 0278, iter [01010, 01251], lr: 0.000310, loss: 0.4044
2022-10-03 06:53:22 - train: epoch 0278, iter [01020, 01251], lr: 0.000310, loss: 0.4164
2022-10-03 06:53:40 - train: epoch 0278, iter [01030, 01251], lr: 0.000310, loss: 0.3881
2022-10-03 06:53:59 - train: epoch 0278, iter [01040, 01251], lr: 0.000310, loss: 0.3697
2022-10-03 06:54:17 - train: epoch 0278, iter [01050, 01251], lr: 0.000310, loss: 0.3984
2022-10-03 06:54:35 - train: epoch 0278, iter [01060, 01251], lr: 0.000310, loss: 0.3880
2022-10-03 06:54:53 - train: epoch 0278, iter [01070, 01251], lr: 0.000310, loss: 0.3830
2022-10-03 06:55:11 - train: epoch 0278, iter [01080, 01251], lr: 0.000310, loss: 0.3975
2022-10-03 06:55:29 - train: epoch 0278, iter [01090, 01251], lr: 0.000310, loss: 0.3699
2022-10-03 06:55:47 - train: epoch 0278, iter [01100, 01251], lr: 0.000310, loss: 0.3909
2022-10-03 06:56:05 - train: epoch 0278, iter [01110, 01251], lr: 0.000310, loss: 0.3974
2022-10-03 06:56:23 - train: epoch 0278, iter [01120, 01251], lr: 0.000310, loss: 0.4181
2022-10-03 06:56:42 - train: epoch 0278, iter [01130, 01251], lr: 0.000310, loss: 0.4143
2022-10-03 06:57:00 - train: epoch 0278, iter [01140, 01251], lr: 0.000310, loss: 0.3870
2022-10-03 06:57:18 - train: epoch 0278, iter [01150, 01251], lr: 0.000309, loss: 0.4004
2022-10-03 06:57:36 - train: epoch 0278, iter [01160, 01251], lr: 0.000309, loss: 0.4139
2022-10-03 06:57:54 - train: epoch 0278, iter [01170, 01251], lr: 0.000309, loss: 0.4066
2022-10-03 06:58:12 - train: epoch 0278, iter [01180, 01251], lr: 0.000309, loss: 0.3941
2022-10-03 06:58:31 - train: epoch 0278, iter [01190, 01251], lr: 0.000309, loss: 0.4020
2022-10-03 06:58:49 - train: epoch 0278, iter [01200, 01251], lr: 0.000309, loss: 0.3967
2022-10-03 06:59:07 - train: epoch 0278, iter [01210, 01251], lr: 0.000309, loss: 0.4078
2022-10-03 06:59:25 - train: epoch 0278, iter [01220, 01251], lr: 0.000309, loss: 0.4022
2022-10-03 06:59:43 - train: epoch 0278, iter [01230, 01251], lr: 0.000309, loss: 0.3999
2022-10-03 07:00:01 - train: epoch 0278, iter [01240, 01251], lr: 0.000309, loss: 0.4026
2022-10-03 07:00:19 - train: epoch 0278, iter [01250, 01251], lr: 0.000309, loss: 0.3999
2022-10-03 07:00:22 - train: epoch 278, train_loss: 0.4000
2022-10-03 07:00:25 - until epoch: 278, best_loss: 0.4000
2022-10-03 07:00:25 - epoch 279 lr: 0.000309
2022-10-03 07:00:50 - train: epoch 0279, iter [00010, 01251], lr: 0.000309, loss: 0.3951
2022-10-03 07:01:08 - train: epoch 0279, iter [00020, 01251], lr: 0.000309, loss: 0.3864
2022-10-03 07:01:26 - train: epoch 0279, iter [00030, 01251], lr: 0.000309, loss: 0.4008
2022-10-03 07:01:44 - train: epoch 0279, iter [00040, 01251], lr: 0.000309, loss: 0.4042
2022-10-03 07:02:02 - train: epoch 0279, iter [00050, 01251], lr: 0.000309, loss: 0.4109
2022-10-03 07:02:20 - train: epoch 0279, iter [00060, 01251], lr: 0.000309, loss: 0.3961
2022-10-03 07:02:38 - train: epoch 0279, iter [00070, 01251], lr: 0.000309, loss: 0.3962
2022-10-03 07:02:56 - train: epoch 0279, iter [00080, 01251], lr: 0.000309, loss: 0.3958
2022-10-03 07:03:14 - train: epoch 0279, iter [00090, 01251], lr: 0.000309, loss: 0.3874
2022-10-03 07:03:32 - train: epoch 0279, iter [00100, 01251], lr: 0.000309, loss: 0.3944
2022-10-03 07:03:50 - train: epoch 0279, iter [00110, 01251], lr: 0.000309, loss: 0.4211
2022-10-03 07:04:08 - train: epoch 0279, iter [00120, 01251], lr: 0.000309, loss: 0.4148
2022-10-03 07:04:26 - train: epoch 0279, iter [00130, 01251], lr: 0.000309, loss: 0.3859
2022-10-03 07:04:44 - train: epoch 0279, iter [00140, 01251], lr: 0.000309, loss: 0.4221
2022-10-03 07:05:02 - train: epoch 0279, iter [00150, 01251], lr: 0.000309, loss: 0.4006
2022-10-03 07:05:20 - train: epoch 0279, iter [00160, 01251], lr: 0.000309, loss: 0.4143
2022-10-03 07:05:39 - train: epoch 0279, iter [00170, 01251], lr: 0.000308, loss: 0.4065
2022-10-03 07:05:57 - train: epoch 0279, iter [00180, 01251], lr: 0.000308, loss: 0.3796
2022-10-03 07:06:15 - train: epoch 0279, iter [00190, 01251], lr: 0.000308, loss: 0.4203
2022-10-03 07:06:33 - train: epoch 0279, iter [00200, 01251], lr: 0.000308, loss: 0.3941
2022-10-03 07:06:51 - train: epoch 0279, iter [00210, 01251], lr: 0.000308, loss: 0.4043
2022-10-03 07:07:09 - train: epoch 0279, iter [00220, 01251], lr: 0.000308, loss: 0.4156
2022-10-03 07:07:27 - train: epoch 0279, iter [00230, 01251], lr: 0.000308, loss: 0.4021
2022-10-03 07:07:45 - train: epoch 0279, iter [00240, 01251], lr: 0.000308, loss: 0.3703
2022-10-03 07:08:03 - train: epoch 0279, iter [00250, 01251], lr: 0.000308, loss: 0.4084
2022-10-03 07:08:21 - train: epoch 0279, iter [00260, 01251], lr: 0.000308, loss: 0.4143
2022-10-03 07:08:39 - train: epoch 0279, iter [00270, 01251], lr: 0.000308, loss: 0.4034
2022-10-03 07:08:57 - train: epoch 0279, iter [00280, 01251], lr: 0.000308, loss: 0.3854
2022-10-03 07:09:16 - train: epoch 0279, iter [00290, 01251], lr: 0.000308, loss: 0.4124
2022-10-03 07:09:33 - train: epoch 0279, iter [00300, 01251], lr: 0.000308, loss: 0.4088
2022-10-03 07:09:52 - train: epoch 0279, iter [00310, 01251], lr: 0.000308, loss: 0.4029
2022-10-03 07:10:10 - train: epoch 0279, iter [00320, 01251], lr: 0.000308, loss: 0.3968
2022-10-03 07:10:28 - train: epoch 0279, iter [00330, 01251], lr: 0.000308, loss: 0.3976
2022-10-03 07:10:46 - train: epoch 0279, iter [00340, 01251], lr: 0.000308, loss: 0.4128
2022-10-03 07:11:04 - train: epoch 0279, iter [00350, 01251], lr: 0.000308, loss: 0.3800
2022-10-03 07:11:22 - train: epoch 0279, iter [00360, 01251], lr: 0.000308, loss: 0.3891
2022-10-03 07:11:41 - train: epoch 0279, iter [00370, 01251], lr: 0.000308, loss: 0.3933
2022-10-03 07:11:59 - train: epoch 0279, iter [00380, 01251], lr: 0.000308, loss: 0.3875
2022-10-03 07:12:17 - train: epoch 0279, iter [00390, 01251], lr: 0.000308, loss: 0.4302
2022-10-03 07:12:35 - train: epoch 0279, iter [00400, 01251], lr: 0.000308, loss: 0.3934
2022-10-03 07:12:53 - train: epoch 0279, iter [00410, 01251], lr: 0.000308, loss: 0.3927
2022-10-03 07:13:11 - train: epoch 0279, iter [00420, 01251], lr: 0.000308, loss: 0.4118
2022-10-03 07:13:29 - train: epoch 0279, iter [00430, 01251], lr: 0.000308, loss: 0.3968
2022-10-03 07:13:47 - train: epoch 0279, iter [00440, 01251], lr: 0.000308, loss: 0.3916
2022-10-03 07:14:05 - train: epoch 0279, iter [00450, 01251], lr: 0.000307, loss: 0.3954
2022-10-03 07:14:23 - train: epoch 0279, iter [00460, 01251], lr: 0.000307, loss: 0.4262
2022-10-03 07:14:41 - train: epoch 0279, iter [00470, 01251], lr: 0.000307, loss: 0.4096
2022-10-03 07:14:59 - train: epoch 0279, iter [00480, 01251], lr: 0.000307, loss: 0.4082
2022-10-03 07:15:17 - train: epoch 0279, iter [00490, 01251], lr: 0.000307, loss: 0.3915
2022-10-03 07:15:36 - train: epoch 0279, iter [00500, 01251], lr: 0.000307, loss: 0.3980
2022-10-03 07:15:54 - train: epoch 0279, iter [00510, 01251], lr: 0.000307, loss: 0.3887
2022-10-03 07:16:11 - train: epoch 0279, iter [00520, 01251], lr: 0.000307, loss: 0.3888
2022-10-03 07:16:30 - train: epoch 0279, iter [00530, 01251], lr: 0.000307, loss: 0.4107
2022-10-03 07:16:48 - train: epoch 0279, iter [00540, 01251], lr: 0.000307, loss: 0.3891
2022-10-03 07:17:06 - train: epoch 0279, iter [00550, 01251], lr: 0.000307, loss: 0.3851
2022-10-03 07:17:24 - train: epoch 0279, iter [00560, 01251], lr: 0.000307, loss: 0.3946
2022-10-03 07:17:42 - train: epoch 0279, iter [00570, 01251], lr: 0.000307, loss: 0.3957
2022-10-03 07:18:00 - train: epoch 0279, iter [00580, 01251], lr: 0.000307, loss: 0.4045
2022-10-03 07:18:18 - train: epoch 0279, iter [00590, 01251], lr: 0.000307, loss: 0.4081
2022-10-03 07:18:37 - train: epoch 0279, iter [00600, 01251], lr: 0.000307, loss: 0.4051
2022-10-03 07:18:55 - train: epoch 0279, iter [00610, 01251], lr: 0.000307, loss: 0.3896
2022-10-03 07:19:13 - train: epoch 0279, iter [00620, 01251], lr: 0.000307, loss: 0.3960
2022-10-03 07:19:31 - train: epoch 0279, iter [00630, 01251], lr: 0.000307, loss: 0.3947
2022-10-03 07:19:49 - train: epoch 0279, iter [00640, 01251], lr: 0.000307, loss: 0.3872
2022-10-03 07:20:07 - train: epoch 0279, iter [00650, 01251], lr: 0.000307, loss: 0.3996
2022-10-03 07:20:26 - train: epoch 0279, iter [00660, 01251], lr: 0.000307, loss: 0.4046
2022-10-03 07:20:44 - train: epoch 0279, iter [00670, 01251], lr: 0.000307, loss: 0.3921
2022-10-03 07:21:02 - train: epoch 0279, iter [00680, 01251], lr: 0.000307, loss: 0.3942
2022-10-03 07:21:20 - train: epoch 0279, iter [00690, 01251], lr: 0.000307, loss: 0.3849
2022-10-03 07:21:38 - train: epoch 0279, iter [00700, 01251], lr: 0.000307, loss: 0.3955
2022-10-03 07:21:56 - train: epoch 0279, iter [00710, 01251], lr: 0.000307, loss: 0.4187
2022-10-03 07:22:14 - train: epoch 0279, iter [00720, 01251], lr: 0.000306, loss: 0.4211
2022-10-03 07:22:32 - train: epoch 0279, iter [00730, 01251], lr: 0.000306, loss: 0.3669
2022-10-03 07:22:50 - train: epoch 0279, iter [00740, 01251], lr: 0.000306, loss: 0.3913
2022-10-03 07:23:09 - train: epoch 0279, iter [00750, 01251], lr: 0.000306, loss: 0.4140
2022-10-03 07:23:27 - train: epoch 0279, iter [00760, 01251], lr: 0.000306, loss: 0.4089
2022-10-03 07:23:45 - train: epoch 0279, iter [00770, 01251], lr: 0.000306, loss: 0.4044
2022-10-03 07:24:03 - train: epoch 0279, iter [00780, 01251], lr: 0.000306, loss: 0.4120
2022-10-03 07:24:21 - train: epoch 0279, iter [00790, 01251], lr: 0.000306, loss: 0.4065
2022-10-03 07:24:39 - train: epoch 0279, iter [00800, 01251], lr: 0.000306, loss: 0.4082
2022-10-03 07:24:57 - train: epoch 0279, iter [00810, 01251], lr: 0.000306, loss: 0.4089
2022-10-03 07:25:15 - train: epoch 0279, iter [00820, 01251], lr: 0.000306, loss: 0.4099
2022-10-03 07:25:33 - train: epoch 0279, iter [00830, 01251], lr: 0.000306, loss: 0.3801
2022-10-03 07:25:51 - train: epoch 0279, iter [00840, 01251], lr: 0.000306, loss: 0.4001
2022-10-03 07:26:10 - train: epoch 0279, iter [00850, 01251], lr: 0.000306, loss: 0.4057
2022-10-03 07:26:28 - train: epoch 0279, iter [00860, 01251], lr: 0.000306, loss: 0.3905
2022-10-03 07:26:46 - train: epoch 0279, iter [00870, 01251], lr: 0.000306, loss: 0.3990
2022-10-03 07:27:04 - train: epoch 0279, iter [00880, 01251], lr: 0.000306, loss: 0.3967
2022-10-03 07:27:22 - train: epoch 0279, iter [00890, 01251], lr: 0.000306, loss: 0.3993
2022-10-03 07:27:40 - train: epoch 0279, iter [00900, 01251], lr: 0.000306, loss: 0.4216
2022-10-03 07:27:58 - train: epoch 0279, iter [00910, 01251], lr: 0.000306, loss: 0.4079
2022-10-03 07:28:16 - train: epoch 0279, iter [00920, 01251], lr: 0.000306, loss: 0.3981
2022-10-03 07:28:34 - train: epoch 0279, iter [00930, 01251], lr: 0.000306, loss: 0.3861
2022-10-03 07:28:52 - train: epoch 0279, iter [00940, 01251], lr: 0.000306, loss: 0.4108
2022-10-03 07:29:11 - train: epoch 0279, iter [00950, 01251], lr: 0.000306, loss: 0.4043
2022-10-03 07:29:29 - train: epoch 0279, iter [00960, 01251], lr: 0.000306, loss: 0.4052
2022-10-03 07:29:47 - train: epoch 0279, iter [00970, 01251], lr: 0.000306, loss: 0.3944
2022-10-03 07:30:05 - train: epoch 0279, iter [00980, 01251], lr: 0.000306, loss: 0.3796
2022-10-03 07:30:23 - train: epoch 0279, iter [00990, 01251], lr: 0.000305, loss: 0.4045
2022-10-03 07:30:41 - train: epoch 0279, iter [01000, 01251], lr: 0.000305, loss: 0.3946
2022-10-03 07:30:59 - train: epoch 0279, iter [01010, 01251], lr: 0.000305, loss: 0.4142
2022-10-03 07:31:17 - train: epoch 0279, iter [01020, 01251], lr: 0.000305, loss: 0.3885
2022-10-03 07:31:35 - train: epoch 0279, iter [01030, 01251], lr: 0.000305, loss: 0.4008
2022-10-03 07:31:53 - train: epoch 0279, iter [01040, 01251], lr: 0.000305, loss: 0.3941
2022-10-03 07:32:11 - train: epoch 0279, iter [01050, 01251], lr: 0.000305, loss: 0.4137
2022-10-03 07:32:29 - train: epoch 0279, iter [01060, 01251], lr: 0.000305, loss: 0.4088
2022-10-03 07:32:47 - train: epoch 0279, iter [01070, 01251], lr: 0.000305, loss: 0.4056
2022-10-03 07:33:05 - train: epoch 0279, iter [01080, 01251], lr: 0.000305, loss: 0.4256
2022-10-03 07:33:24 - train: epoch 0279, iter [01090, 01251], lr: 0.000305, loss: 0.4085
2022-10-03 07:33:42 - train: epoch 0279, iter [01100, 01251], lr: 0.000305, loss: 0.4134
2022-10-03 07:34:00 - train: epoch 0279, iter [01110, 01251], lr: 0.000305, loss: 0.3938
2022-10-03 07:34:18 - train: epoch 0279, iter [01120, 01251], lr: 0.000305, loss: 0.3920
2022-10-03 07:34:36 - train: epoch 0279, iter [01130, 01251], lr: 0.000305, loss: 0.3945
2022-10-03 07:34:54 - train: epoch 0279, iter [01140, 01251], lr: 0.000305, loss: 0.3979
2022-10-03 07:35:12 - train: epoch 0279, iter [01150, 01251], lr: 0.000305, loss: 0.4142
2022-10-03 07:35:30 - train: epoch 0279, iter [01160, 01251], lr: 0.000305, loss: 0.3758
2022-10-03 07:35:48 - train: epoch 0279, iter [01170, 01251], lr: 0.000305, loss: 0.3986
2022-10-03 07:36:06 - train: epoch 0279, iter [01180, 01251], lr: 0.000305, loss: 0.4027
2022-10-03 07:36:24 - train: epoch 0279, iter [01190, 01251], lr: 0.000305, loss: 0.4035
2022-10-03 07:36:43 - train: epoch 0279, iter [01200, 01251], lr: 0.000305, loss: 0.3972
2022-10-03 07:37:01 - train: epoch 0279, iter [01210, 01251], lr: 0.000305, loss: 0.3786
2022-10-03 07:37:19 - train: epoch 0279, iter [01220, 01251], lr: 0.000305, loss: 0.3965
2022-10-03 07:37:37 - train: epoch 0279, iter [01230, 01251], lr: 0.000305, loss: 0.4061
2022-10-03 07:37:55 - train: epoch 0279, iter [01240, 01251], lr: 0.000305, loss: 0.4107
2022-10-03 07:38:13 - train: epoch 0279, iter [01250, 01251], lr: 0.000305, loss: 0.3686
2022-10-03 07:38:16 - train: epoch 279, train_loss: 0.3998
2022-10-03 07:38:19 - until epoch: 279, best_loss: 0.3998
2022-10-03 07:38:19 - epoch 280 lr: 0.000305
2022-10-03 07:38:44 - train: epoch 0280, iter [00010, 01251], lr: 0.000305, loss: 0.4128
2022-10-03 07:39:02 - train: epoch 0280, iter [00020, 01251], lr: 0.000304, loss: 0.3905
2022-10-03 07:39:20 - train: epoch 0280, iter [00030, 01251], lr: 0.000304, loss: 0.4177
2022-10-03 07:39:39 - train: epoch 0280, iter [00040, 01251], lr: 0.000304, loss: 0.3932
2022-10-03 07:39:57 - train: epoch 0280, iter [00050, 01251], lr: 0.000304, loss: 0.3888
2022-10-03 07:40:15 - train: epoch 0280, iter [00060, 01251], lr: 0.000304, loss: 0.3993
2022-10-03 07:40:33 - train: epoch 0280, iter [00070, 01251], lr: 0.000304, loss: 0.4040
2022-10-03 07:40:51 - train: epoch 0280, iter [00080, 01251], lr: 0.000304, loss: 0.4162
2022-10-03 07:41:10 - train: epoch 0280, iter [00090, 01251], lr: 0.000304, loss: 0.3968
2022-10-03 07:41:28 - train: epoch 0280, iter [00100, 01251], lr: 0.000304, loss: 0.3829
2022-10-03 07:41:47 - train: epoch 0280, iter [00110, 01251], lr: 0.000304, loss: 0.3860
2022-10-03 07:42:05 - train: epoch 0280, iter [00120, 01251], lr: 0.000304, loss: 0.4052
2022-10-03 07:42:23 - train: epoch 0280, iter [00130, 01251], lr: 0.000304, loss: 0.3997
2022-10-03 07:42:41 - train: epoch 0280, iter [00140, 01251], lr: 0.000304, loss: 0.4115
2022-10-03 07:42:59 - train: epoch 0280, iter [00150, 01251], lr: 0.000304, loss: 0.4066
2022-10-03 07:43:18 - train: epoch 0280, iter [00160, 01251], lr: 0.000304, loss: 0.3855
2022-10-03 07:43:36 - train: epoch 0280, iter [00170, 01251], lr: 0.000304, loss: 0.3907
2022-10-03 07:43:55 - train: epoch 0280, iter [00180, 01251], lr: 0.000304, loss: 0.3986
2022-10-03 07:44:13 - train: epoch 0280, iter [00190, 01251], lr: 0.000304, loss: 0.4071
2022-10-03 07:44:31 - train: epoch 0280, iter [00200, 01251], lr: 0.000304, loss: 0.4019
2022-10-03 07:44:50 - train: epoch 0280, iter [00210, 01251], lr: 0.000304, loss: 0.4025
2022-10-03 07:45:08 - train: epoch 0280, iter [00220, 01251], lr: 0.000304, loss: 0.3810
2022-10-03 07:45:26 - train: epoch 0280, iter [00230, 01251], lr: 0.000304, loss: 0.4041
2022-10-03 07:45:45 - train: epoch 0280, iter [00240, 01251], lr: 0.000304, loss: 0.3900
2022-10-03 07:46:03 - train: epoch 0280, iter [00250, 01251], lr: 0.000304, loss: 0.4011
2022-10-03 07:46:21 - train: epoch 0280, iter [00260, 01251], lr: 0.000304, loss: 0.4093
2022-10-03 07:46:39 - train: epoch 0280, iter [00270, 01251], lr: 0.000304, loss: 0.3972
2022-10-03 07:46:57 - train: epoch 0280, iter [00280, 01251], lr: 0.000304, loss: 0.3638
2022-10-03 07:47:16 - train: epoch 0280, iter [00290, 01251], lr: 0.000303, loss: 0.4090
2022-10-03 07:47:34 - train: epoch 0280, iter [00300, 01251], lr: 0.000303, loss: 0.4076
2022-10-03 07:47:52 - train: epoch 0280, iter [00310, 01251], lr: 0.000303, loss: 0.3685
2022-10-03 07:48:10 - train: epoch 0280, iter [00320, 01251], lr: 0.000303, loss: 0.4144
2022-10-03 07:48:29 - train: epoch 0280, iter [00330, 01251], lr: 0.000303, loss: 0.3770
2022-10-03 07:48:47 - train: epoch 0280, iter [00340, 01251], lr: 0.000303, loss: 0.4081
2022-10-03 07:49:05 - train: epoch 0280, iter [00350, 01251], lr: 0.000303, loss: 0.4089
2022-10-03 07:49:24 - train: epoch 0280, iter [00360, 01251], lr: 0.000303, loss: 0.3867
2022-10-03 07:49:42 - train: epoch 0280, iter [00370, 01251], lr: 0.000303, loss: 0.3939
2022-10-03 07:50:01 - train: epoch 0280, iter [00380, 01251], lr: 0.000303, loss: 0.3987
2022-10-03 07:50:19 - train: epoch 0280, iter [00390, 01251], lr: 0.000303, loss: 0.4046
2022-10-03 07:50:37 - train: epoch 0280, iter [00400, 01251], lr: 0.000303, loss: 0.3955
2022-10-03 07:50:55 - train: epoch 0280, iter [00410, 01251], lr: 0.000303, loss: 0.4094
2022-10-03 07:51:14 - train: epoch 0280, iter [00420, 01251], lr: 0.000303, loss: 0.4097
2022-10-03 07:51:32 - train: epoch 0280, iter [00430, 01251], lr: 0.000303, loss: 0.3925
2022-10-03 07:51:50 - train: epoch 0280, iter [00440, 01251], lr: 0.000303, loss: 0.4040
2022-10-03 07:52:08 - train: epoch 0280, iter [00450, 01251], lr: 0.000303, loss: 0.3869
2022-10-03 07:52:27 - train: epoch 0280, iter [00460, 01251], lr: 0.000303, loss: 0.3880
2022-10-03 07:52:45 - train: epoch 0280, iter [00470, 01251], lr: 0.000303, loss: 0.3935
2022-10-03 07:53:03 - train: epoch 0280, iter [00480, 01251], lr: 0.000303, loss: 0.4135
2022-10-03 07:53:21 - train: epoch 0280, iter [00490, 01251], lr: 0.000303, loss: 0.4102
2022-10-03 07:53:39 - train: epoch 0280, iter [00500, 01251], lr: 0.000303, loss: 0.4048
2022-10-03 07:53:58 - train: epoch 0280, iter [00510, 01251], lr: 0.000303, loss: 0.4028
2022-10-03 07:54:16 - train: epoch 0280, iter [00520, 01251], lr: 0.000303, loss: 0.3820
2022-10-03 07:54:34 - train: epoch 0280, iter [00530, 01251], lr: 0.000303, loss: 0.3821
2022-10-03 07:54:52 - train: epoch 0280, iter [00540, 01251], lr: 0.000303, loss: 0.4097
2022-10-03 07:55:11 - train: epoch 0280, iter [00550, 01251], lr: 0.000303, loss: 0.4017
2022-10-03 07:55:29 - train: epoch 0280, iter [00560, 01251], lr: 0.000303, loss: 0.4100
2022-10-03 07:55:47 - train: epoch 0280, iter [00570, 01251], lr: 0.000302, loss: 0.4014
2022-10-03 07:56:05 - train: epoch 0280, iter [00580, 01251], lr: 0.000302, loss: 0.4044
2022-10-03 07:56:23 - train: epoch 0280, iter [00590, 01251], lr: 0.000302, loss: 0.4036
2022-10-03 07:56:41 - train: epoch 0280, iter [00600, 01251], lr: 0.000302, loss: 0.4264
2022-10-03 07:56:59 - train: epoch 0280, iter [00610, 01251], lr: 0.000302, loss: 0.4005
2022-10-03 07:57:17 - train: epoch 0280, iter [00620, 01251], lr: 0.000302, loss: 0.3977
2022-10-03 07:57:35 - train: epoch 0280, iter [00630, 01251], lr: 0.000302, loss: 0.4018
2022-10-03 07:57:54 - train: epoch 0280, iter [00640, 01251], lr: 0.000302, loss: 0.3736
2022-10-03 07:58:12 - train: epoch 0280, iter [00650, 01251], lr: 0.000302, loss: 0.4027
2022-10-03 07:58:30 - train: epoch 0280, iter [00660, 01251], lr: 0.000302, loss: 0.4137
2022-10-03 07:58:48 - train: epoch 0280, iter [00670, 01251], lr: 0.000302, loss: 0.4119
2022-10-03 07:59:07 - train: epoch 0280, iter [00680, 01251], lr: 0.000302, loss: 0.3882
2022-10-03 07:59:25 - train: epoch 0280, iter [00690, 01251], lr: 0.000302, loss: 0.3949
2022-10-03 07:59:43 - train: epoch 0280, iter [00700, 01251], lr: 0.000302, loss: 0.3943
2022-10-03 08:00:01 - train: epoch 0280, iter [00710, 01251], lr: 0.000302, loss: 0.3735
2022-10-03 08:00:19 - train: epoch 0280, iter [00720, 01251], lr: 0.000302, loss: 0.4064
2022-10-03 08:00:38 - train: epoch 0280, iter [00730, 01251], lr: 0.000302, loss: 0.4024
2022-10-03 08:00:56 - train: epoch 0280, iter [00740, 01251], lr: 0.000302, loss: 0.4013
2022-10-03 08:01:14 - train: epoch 0280, iter [00750, 01251], lr: 0.000302, loss: 0.4058
2022-10-03 08:01:32 - train: epoch 0280, iter [00760, 01251], lr: 0.000302, loss: 0.4166
2022-10-03 08:01:50 - train: epoch 0280, iter [00770, 01251], lr: 0.000302, loss: 0.3785
2022-10-03 08:02:08 - train: epoch 0280, iter [00780, 01251], lr: 0.000302, loss: 0.4093
2022-10-03 08:02:27 - train: epoch 0280, iter [00790, 01251], lr: 0.000302, loss: 0.3936
2022-10-03 08:02:45 - train: epoch 0280, iter [00800, 01251], lr: 0.000302, loss: 0.4001
2022-10-03 08:03:03 - train: epoch 0280, iter [00810, 01251], lr: 0.000302, loss: 0.3890
2022-10-03 08:03:21 - train: epoch 0280, iter [00820, 01251], lr: 0.000302, loss: 0.4081
2022-10-03 08:03:39 - train: epoch 0280, iter [00830, 01251], lr: 0.000302, loss: 0.4059
2022-10-03 08:03:57 - train: epoch 0280, iter [00840, 01251], lr: 0.000301, loss: 0.4055
2022-10-03 08:04:15 - train: epoch 0280, iter [00850, 01251], lr: 0.000301, loss: 0.3929
2022-10-03 08:04:33 - train: epoch 0280, iter [00860, 01251], lr: 0.000301, loss: 0.4024
2022-10-03 08:04:51 - train: epoch 0280, iter [00870, 01251], lr: 0.000301, loss: 0.4133
2022-10-03 08:05:10 - train: epoch 0280, iter [00880, 01251], lr: 0.000301, loss: 0.4038
2022-10-03 08:05:28 - train: epoch 0280, iter [00890, 01251], lr: 0.000301, loss: 0.4081
2022-10-03 08:05:46 - train: epoch 0280, iter [00900, 01251], lr: 0.000301, loss: 0.4023
2022-10-03 08:06:04 - train: epoch 0280, iter [00910, 01251], lr: 0.000301, loss: 0.4149
2022-10-03 08:06:22 - train: epoch 0280, iter [00920, 01251], lr: 0.000301, loss: 0.4059
2022-10-03 08:06:40 - train: epoch 0280, iter [00930, 01251], lr: 0.000301, loss: 0.3909
2022-10-03 08:06:58 - train: epoch 0280, iter [00940, 01251], lr: 0.000301, loss: 0.4100
2022-10-03 08:07:16 - train: epoch 0280, iter [00950, 01251], lr: 0.000301, loss: 0.4118
2022-10-03 08:07:34 - train: epoch 0280, iter [00960, 01251], lr: 0.000301, loss: 0.4059
2022-10-03 08:07:52 - train: epoch 0280, iter [00970, 01251], lr: 0.000301, loss: 0.3925
2022-10-03 08:08:11 - train: epoch 0280, iter [00980, 01251], lr: 0.000301, loss: 0.3944
2022-10-03 08:08:29 - train: epoch 0280, iter [00990, 01251], lr: 0.000301, loss: 0.3930
2022-10-03 08:08:47 - train: epoch 0280, iter [01000, 01251], lr: 0.000301, loss: 0.4008
2022-10-03 08:09:05 - train: epoch 0280, iter [01010, 01251], lr: 0.000301, loss: 0.3822
2022-10-03 08:09:24 - train: epoch 0280, iter [01020, 01251], lr: 0.000301, loss: 0.4022
2022-10-03 08:09:42 - train: epoch 0280, iter [01030, 01251], lr: 0.000301, loss: 0.3748
2022-10-03 08:10:00 - train: epoch 0280, iter [01040, 01251], lr: 0.000301, loss: 0.3792
2022-10-03 08:10:18 - train: epoch 0280, iter [01050, 01251], lr: 0.000301, loss: 0.3793
2022-10-03 08:10:36 - train: epoch 0280, iter [01060, 01251], lr: 0.000301, loss: 0.4011
2022-10-03 08:10:54 - train: epoch 0280, iter [01070, 01251], lr: 0.000301, loss: 0.4128
2022-10-03 08:11:12 - train: epoch 0280, iter [01080, 01251], lr: 0.000301, loss: 0.4030
2022-10-03 08:11:30 - train: epoch 0280, iter [01090, 01251], lr: 0.000301, loss: 0.4042
2022-10-03 08:11:48 - train: epoch 0280, iter [01100, 01251], lr: 0.000301, loss: 0.3785
2022-10-03 08:12:06 - train: epoch 0280, iter [01110, 01251], lr: 0.000301, loss: 0.4080
2022-10-03 08:12:24 - train: epoch 0280, iter [01120, 01251], lr: 0.000300, loss: 0.3921
2022-10-03 08:12:43 - train: epoch 0280, iter [01130, 01251], lr: 0.000300, loss: 0.3931
2022-10-03 08:13:01 - train: epoch 0280, iter [01140, 01251], lr: 0.000300, loss: 0.3783
2022-10-03 08:13:19 - train: epoch 0280, iter [01150, 01251], lr: 0.000300, loss: 0.3958
2022-10-03 08:13:37 - train: epoch 0280, iter [01160, 01251], lr: 0.000300, loss: 0.4090
2022-10-03 08:13:55 - train: epoch 0280, iter [01170, 01251], lr: 0.000300, loss: 0.4074
2022-10-03 08:14:13 - train: epoch 0280, iter [01180, 01251], lr: 0.000300, loss: 0.3732
2022-10-03 08:14:31 - train: epoch 0280, iter [01190, 01251], lr: 0.000300, loss: 0.3999
2022-10-03 08:14:49 - train: epoch 0280, iter [01200, 01251], lr: 0.000300, loss: 0.3953
2022-10-03 08:15:08 - train: epoch 0280, iter [01210, 01251], lr: 0.000300, loss: 0.3878
2022-10-03 08:15:26 - train: epoch 0280, iter [01220, 01251], lr: 0.000300, loss: 0.3950
2022-10-03 08:15:44 - train: epoch 0280, iter [01230, 01251], lr: 0.000300, loss: 0.4029
2022-10-03 08:16:02 - train: epoch 0280, iter [01240, 01251], lr: 0.000300, loss: 0.3955
2022-10-03 08:16:20 - train: epoch 0280, iter [01250, 01251], lr: 0.000300, loss: 0.4049
2022-10-03 08:16:23 - train: epoch 280, train_loss: 0.3997
2022-10-03 08:16:26 - until epoch: 280, best_loss: 0.3997
2022-10-03 08:16:26 - epoch 281 lr: 0.000300
2022-10-03 08:16:50 - train: epoch 0281, iter [00010, 01251], lr: 0.000300, loss: 0.3982
2022-10-03 08:17:08 - train: epoch 0281, iter [00020, 01251], lr: 0.000300, loss: 0.4053
2022-10-03 08:17:26 - train: epoch 0281, iter [00030, 01251], lr: 0.000300, loss: 0.4014
2022-10-03 08:17:44 - train: epoch 0281, iter [00040, 01251], lr: 0.000300, loss: 0.4052
2022-10-03 08:18:02 - train: epoch 0281, iter [00050, 01251], lr: 0.000300, loss: 0.3957
2022-10-03 08:18:20 - train: epoch 0281, iter [00060, 01251], lr: 0.000300, loss: 0.3929
2022-10-03 08:18:38 - train: epoch 0281, iter [00070, 01251], lr: 0.000300, loss: 0.3854
2022-10-03 08:18:56 - train: epoch 0281, iter [00080, 01251], lr: 0.000300, loss: 0.4063
2022-10-03 08:19:15 - train: epoch 0281, iter [00090, 01251], lr: 0.000300, loss: 0.3865
2022-10-03 08:19:33 - train: epoch 0281, iter [00100, 01251], lr: 0.000300, loss: 0.4103
2022-10-03 08:19:51 - train: epoch 0281, iter [00110, 01251], lr: 0.000300, loss: 0.3985
2022-10-03 08:20:09 - train: epoch 0281, iter [00120, 01251], lr: 0.000300, loss: 0.4196
2022-10-03 08:20:27 - train: epoch 0281, iter [00130, 01251], lr: 0.000300, loss: 0.3993
2022-10-03 08:20:45 - train: epoch 0281, iter [00140, 01251], lr: 0.000299, loss: 0.3930
2022-10-03 08:21:03 - train: epoch 0281, iter [00150, 01251], lr: 0.000299, loss: 0.3986
2022-10-03 08:21:21 - train: epoch 0281, iter [00160, 01251], lr: 0.000299, loss: 0.3903
2022-10-03 08:21:39 - train: epoch 0281, iter [00170, 01251], lr: 0.000299, loss: 0.4103
2022-10-03 08:21:57 - train: epoch 0281, iter [00180, 01251], lr: 0.000299, loss: 0.3898
2022-10-03 08:22:15 - train: epoch 0281, iter [00190, 01251], lr: 0.000299, loss: 0.3973
2022-10-03 08:22:33 - train: epoch 0281, iter [00200, 01251], lr: 0.000299, loss: 0.4101
2022-10-03 08:22:51 - train: epoch 0281, iter [00210, 01251], lr: 0.000299, loss: 0.4198
2022-10-03 08:23:09 - train: epoch 0281, iter [00220, 01251], lr: 0.000299, loss: 0.3955
2022-10-03 08:23:28 - train: epoch 0281, iter [00230, 01251], lr: 0.000299, loss: 0.3890
2022-10-03 08:23:45 - train: epoch 0281, iter [00240, 01251], lr: 0.000299, loss: 0.4061
2022-10-03 08:24:03 - train: epoch 0281, iter [00250, 01251], lr: 0.000299, loss: 0.4068
2022-10-03 08:24:21 - train: epoch 0281, iter [00260, 01251], lr: 0.000299, loss: 0.4067
2022-10-03 08:24:39 - train: epoch 0281, iter [00270, 01251], lr: 0.000299, loss: 0.4271
2022-10-03 08:24:57 - train: epoch 0281, iter [00280, 01251], lr: 0.000299, loss: 0.3910
2022-10-03 08:25:15 - train: epoch 0281, iter [00290, 01251], lr: 0.000299, loss: 0.4109
2022-10-03 08:25:33 - train: epoch 0281, iter [00300, 01251], lr: 0.000299, loss: 0.4038
2022-10-03 08:25:51 - train: epoch 0281, iter [00310, 01251], lr: 0.000299, loss: 0.4135
2022-10-03 08:26:09 - train: epoch 0281, iter [00320, 01251], lr: 0.000299, loss: 0.3860
2022-10-03 08:26:27 - train: epoch 0281, iter [00330, 01251], lr: 0.000299, loss: 0.4186
2022-10-03 08:26:45 - train: epoch 0281, iter [00340, 01251], lr: 0.000299, loss: 0.4001
2022-10-03 08:27:03 - train: epoch 0281, iter [00350, 01251], lr: 0.000299, loss: 0.3774
2022-10-03 08:27:21 - train: epoch 0281, iter [00360, 01251], lr: 0.000299, loss: 0.3908
2022-10-03 08:27:39 - train: epoch 0281, iter [00370, 01251], lr: 0.000299, loss: 0.4028
2022-10-03 08:27:57 - train: epoch 0281, iter [00380, 01251], lr: 0.000299, loss: 0.3914
2022-10-03 08:28:15 - train: epoch 0281, iter [00390, 01251], lr: 0.000299, loss: 0.4237
2022-10-03 08:28:33 - train: epoch 0281, iter [00400, 01251], lr: 0.000299, loss: 0.4044
2022-10-03 08:28:51 - train: epoch 0281, iter [00410, 01251], lr: 0.000299, loss: 0.4075
2022-10-03 08:29:09 - train: epoch 0281, iter [00420, 01251], lr: 0.000298, loss: 0.3717
2022-10-03 08:29:27 - train: epoch 0281, iter [00430, 01251], lr: 0.000298, loss: 0.3984
2022-10-03 08:29:45 - train: epoch 0281, iter [00440, 01251], lr: 0.000298, loss: 0.4024
2022-10-03 08:30:03 - train: epoch 0281, iter [00450, 01251], lr: 0.000298, loss: 0.4105
2022-10-03 08:30:21 - train: epoch 0281, iter [00460, 01251], lr: 0.000298, loss: 0.3918
2022-10-03 08:30:39 - train: epoch 0281, iter [00470, 01251], lr: 0.000298, loss: 0.4271
2022-10-03 08:30:57 - train: epoch 0281, iter [00480, 01251], lr: 0.000298, loss: 0.3998
2022-10-03 08:31:15 - train: epoch 0281, iter [00490, 01251], lr: 0.000298, loss: 0.3937
2022-10-03 08:31:33 - train: epoch 0281, iter [00500, 01251], lr: 0.000298, loss: 0.4165
2022-10-03 08:31:51 - train: epoch 0281, iter [00510, 01251], lr: 0.000298, loss: 0.3773
2022-10-03 08:32:09 - train: epoch 0281, iter [00520, 01251], lr: 0.000298, loss: 0.3748
2022-10-03 08:32:27 - train: epoch 0281, iter [00530, 01251], lr: 0.000298, loss: 0.4156
2022-10-03 08:32:45 - train: epoch 0281, iter [00540, 01251], lr: 0.000298, loss: 0.3805
2022-10-03 08:33:03 - train: epoch 0281, iter [00550, 01251], lr: 0.000298, loss: 0.3838
2022-10-03 08:33:21 - train: epoch 0281, iter [00560, 01251], lr: 0.000298, loss: 0.3757
2022-10-03 08:33:39 - train: epoch 0281, iter [00570, 01251], lr: 0.000298, loss: 0.4123
2022-10-03 08:33:57 - train: epoch 0281, iter [00580, 01251], lr: 0.000298, loss: 0.3869
2022-10-03 08:34:15 - train: epoch 0281, iter [00590, 01251], lr: 0.000298, loss: 0.3976
2022-10-03 08:34:33 - train: epoch 0281, iter [00600, 01251], lr: 0.000298, loss: 0.3993
2022-10-03 08:34:51 - train: epoch 0281, iter [00610, 01251], lr: 0.000298, loss: 0.4035
2022-10-03 08:35:09 - train: epoch 0281, iter [00620, 01251], lr: 0.000298, loss: 0.3917
2022-10-03 08:35:27 - train: epoch 0281, iter [00630, 01251], lr: 0.000298, loss: 0.4066
2022-10-03 08:35:45 - train: epoch 0281, iter [00640, 01251], lr: 0.000298, loss: 0.3793
2022-10-03 08:36:03 - train: epoch 0281, iter [00650, 01251], lr: 0.000298, loss: 0.3922
2022-10-03 08:36:20 - train: epoch 0281, iter [00660, 01251], lr: 0.000298, loss: 0.4032
2022-10-03 08:36:39 - train: epoch 0281, iter [00670, 01251], lr: 0.000298, loss: 0.3916
2022-10-03 08:36:57 - train: epoch 0281, iter [00680, 01251], lr: 0.000298, loss: 0.3966
2022-10-03 08:37:14 - train: epoch 0281, iter [00690, 01251], lr: 0.000298, loss: 0.4017
2022-10-03 08:37:32 - train: epoch 0281, iter [00700, 01251], lr: 0.000297, loss: 0.3960
2022-10-03 08:37:51 - train: epoch 0281, iter [00710, 01251], lr: 0.000297, loss: 0.4205
2022-10-03 08:38:08 - train: epoch 0281, iter [00720, 01251], lr: 0.000297, loss: 0.3961
2022-10-03 08:38:27 - train: epoch 0281, iter [00730, 01251], lr: 0.000297, loss: 0.4050
2022-10-03 08:38:45 - train: epoch 0281, iter [00740, 01251], lr: 0.000297, loss: 0.4171
2022-10-03 08:39:03 - train: epoch 0281, iter [00750, 01251], lr: 0.000297, loss: 0.3991
2022-10-03 08:39:21 - train: epoch 0281, iter [00760, 01251], lr: 0.000297, loss: 0.3994
2022-10-03 08:39:39 - train: epoch 0281, iter [00770, 01251], lr: 0.000297, loss: 0.4069
2022-10-03 08:39:56 - train: epoch 0281, iter [00780, 01251], lr: 0.000297, loss: 0.3966
2022-10-03 08:40:14 - train: epoch 0281, iter [00790, 01251], lr: 0.000297, loss: 0.4094
2022-10-03 08:40:33 - train: epoch 0281, iter [00800, 01251], lr: 0.000297, loss: 0.4106
2022-10-03 08:40:50 - train: epoch 0281, iter [00810, 01251], lr: 0.000297, loss: 0.4052
2022-10-03 08:41:08 - train: epoch 0281, iter [00820, 01251], lr: 0.000297, loss: 0.4189
2022-10-03 08:41:26 - train: epoch 0281, iter [00830, 01251], lr: 0.000297, loss: 0.3990
2022-10-03 08:41:44 - train: epoch 0281, iter [00840, 01251], lr: 0.000297, loss: 0.4078
2022-10-03 08:42:03 - train: epoch 0281, iter [00850, 01251], lr: 0.000297, loss: 0.3983
2022-10-03 08:42:21 - train: epoch 0281, iter [00860, 01251], lr: 0.000297, loss: 0.4189
2022-10-03 08:42:39 - train: epoch 0281, iter [00870, 01251], lr: 0.000297, loss: 0.4001
2022-10-03 08:42:57 - train: epoch 0281, iter [00880, 01251], lr: 0.000297, loss: 0.3827
2022-10-03 08:43:15 - train: epoch 0281, iter [00890, 01251], lr: 0.000297, loss: 0.3871
2022-10-03 08:43:33 - train: epoch 0281, iter [00900, 01251], lr: 0.000297, loss: 0.4006
2022-10-03 08:43:50 - train: epoch 0281, iter [00910, 01251], lr: 0.000297, loss: 0.3863
2022-10-03 08:44:08 - train: epoch 0281, iter [00920, 01251], lr: 0.000297, loss: 0.3826
2022-10-03 08:44:26 - train: epoch 0281, iter [00930, 01251], lr: 0.000297, loss: 0.3699
2022-10-03 08:44:44 - train: epoch 0281, iter [00940, 01251], lr: 0.000297, loss: 0.3840
2022-10-03 08:45:02 - train: epoch 0281, iter [00950, 01251], lr: 0.000297, loss: 0.4193
2022-10-03 08:45:20 - train: epoch 0281, iter [00960, 01251], lr: 0.000297, loss: 0.4008
2022-10-03 08:45:38 - train: epoch 0281, iter [00970, 01251], lr: 0.000296, loss: 0.3878
2022-10-03 08:45:56 - train: epoch 0281, iter [00980, 01251], lr: 0.000296, loss: 0.4018
2022-10-03 08:46:14 - train: epoch 0281, iter [00990, 01251], lr: 0.000296, loss: 0.4065
2022-10-03 08:46:32 - train: epoch 0281, iter [01000, 01251], lr: 0.000296, loss: 0.3951
2022-10-03 08:46:50 - train: epoch 0281, iter [01010, 01251], lr: 0.000296, loss: 0.3842
2022-10-03 08:47:08 - train: epoch 0281, iter [01020, 01251], lr: 0.000296, loss: 0.3987
2022-10-03 08:47:26 - train: epoch 0281, iter [01030, 01251], lr: 0.000296, loss: 0.3587
2022-10-03 08:47:44 - train: epoch 0281, iter [01040, 01251], lr: 0.000296, loss: 0.3993
2022-10-03 08:48:02 - train: epoch 0281, iter [01050, 01251], lr: 0.000296, loss: 0.3982
2022-10-03 08:48:20 - train: epoch 0281, iter [01060, 01251], lr: 0.000296, loss: 0.4179
2022-10-03 08:48:38 - train: epoch 0281, iter [01070, 01251], lr: 0.000296, loss: 0.4138
2022-10-03 08:48:56 - train: epoch 0281, iter [01080, 01251], lr: 0.000296, loss: 0.3825
2022-10-03 08:49:14 - train: epoch 0281, iter [01090, 01251], lr: 0.000296, loss: 0.4041
2022-10-03 08:49:32 - train: epoch 0281, iter [01100, 01251], lr: 0.000296, loss: 0.3874
2022-10-03 08:49:50 - train: epoch 0281, iter [01110, 01251], lr: 0.000296, loss: 0.4010
2022-10-03 08:50:08 - train: epoch 0281, iter [01120, 01251], lr: 0.000296, loss: 0.3979
2022-10-03 08:50:26 - train: epoch 0281, iter [01130, 01251], lr: 0.000296, loss: 0.3902
2022-10-03 08:50:44 - train: epoch 0281, iter [01140, 01251], lr: 0.000296, loss: 0.4111
2022-10-03 08:51:02 - train: epoch 0281, iter [01150, 01251], lr: 0.000296, loss: 0.4016
2022-10-03 08:51:20 - train: epoch 0281, iter [01160, 01251], lr: 0.000296, loss: 0.4099
2022-10-03 08:51:38 - train: epoch 0281, iter [01170, 01251], lr: 0.000296, loss: 0.4134
2022-10-03 08:51:56 - train: epoch 0281, iter [01180, 01251], lr: 0.000296, loss: 0.4133
2022-10-03 08:52:14 - train: epoch 0281, iter [01190, 01251], lr: 0.000296, loss: 0.4034
2022-10-03 08:52:32 - train: epoch 0281, iter [01200, 01251], lr: 0.000296, loss: 0.3956
2022-10-03 08:52:50 - train: epoch 0281, iter [01210, 01251], lr: 0.000296, loss: 0.3824
2022-10-03 08:53:08 - train: epoch 0281, iter [01220, 01251], lr: 0.000296, loss: 0.3804
2022-10-03 08:53:26 - train: epoch 0281, iter [01230, 01251], lr: 0.000296, loss: 0.4181
2022-10-03 08:53:44 - train: epoch 0281, iter [01240, 01251], lr: 0.000296, loss: 0.4064
2022-10-03 08:54:01 - train: epoch 0281, iter [01250, 01251], lr: 0.000295, loss: 0.3977
2022-10-03 08:54:04 - train: epoch 281, train_loss: 0.3995
2022-10-03 08:54:07 - until epoch: 281, best_loss: 0.3995
2022-10-03 08:54:07 - epoch 282 lr: 0.000295
2022-10-03 08:54:32 - train: epoch 0282, iter [00010, 01251], lr: 0.000295, loss: 0.4093
2022-10-03 08:54:50 - train: epoch 0282, iter [00020, 01251], lr: 0.000295, loss: 0.3958
2022-10-03 08:55:08 - train: epoch 0282, iter [00030, 01251], lr: 0.000295, loss: 0.4102
2022-10-03 08:55:26 - train: epoch 0282, iter [00040, 01251], lr: 0.000295, loss: 0.4071
2022-10-03 08:55:44 - train: epoch 0282, iter [00050, 01251], lr: 0.000295, loss: 0.4078
2022-10-03 08:56:02 - train: epoch 0282, iter [00060, 01251], lr: 0.000295, loss: 0.3951
2022-10-03 08:56:20 - train: epoch 0282, iter [00070, 01251], lr: 0.000295, loss: 0.4084
2022-10-03 08:56:38 - train: epoch 0282, iter [00080, 01251], lr: 0.000295, loss: 0.4119
2022-10-03 08:56:56 - train: epoch 0282, iter [00090, 01251], lr: 0.000295, loss: 0.3919
2022-10-03 08:57:14 - train: epoch 0282, iter [00100, 01251], lr: 0.000295, loss: 0.4019
2022-10-03 08:57:32 - train: epoch 0282, iter [00110, 01251], lr: 0.000295, loss: 0.4031
2022-10-03 08:57:50 - train: epoch 0282, iter [00120, 01251], lr: 0.000295, loss: 0.3791
2022-10-03 08:58:08 - train: epoch 0282, iter [00130, 01251], lr: 0.000295, loss: 0.4032
2022-10-03 08:58:26 - train: epoch 0282, iter [00140, 01251], lr: 0.000295, loss: 0.3716
2022-10-03 08:58:44 - train: epoch 0282, iter [00150, 01251], lr: 0.000295, loss: 0.3833
2022-10-03 08:59:02 - train: epoch 0282, iter [00160, 01251], lr: 0.000295, loss: 0.4062
2022-10-03 08:59:20 - train: epoch 0282, iter [00170, 01251], lr: 0.000295, loss: 0.3822
2022-10-03 08:59:38 - train: epoch 0282, iter [00180, 01251], lr: 0.000295, loss: 0.3900
2022-10-03 08:59:56 - train: epoch 0282, iter [00190, 01251], lr: 0.000295, loss: 0.4042
2022-10-03 09:00:15 - train: epoch 0282, iter [00200, 01251], lr: 0.000295, loss: 0.3791
2022-10-03 09:00:33 - train: epoch 0282, iter [00210, 01251], lr: 0.000295, loss: 0.4147
2022-10-03 09:00:51 - train: epoch 0282, iter [00220, 01251], lr: 0.000295, loss: 0.4024
2022-10-03 09:01:09 - train: epoch 0282, iter [00230, 01251], lr: 0.000295, loss: 0.4004
2022-10-03 09:01:27 - train: epoch 0282, iter [00240, 01251], lr: 0.000295, loss: 0.3949
2022-10-03 09:01:45 - train: epoch 0282, iter [00250, 01251], lr: 0.000295, loss: 0.3926
2022-10-03 09:02:03 - train: epoch 0282, iter [00260, 01251], lr: 0.000295, loss: 0.4132
2022-10-03 09:02:21 - train: epoch 0282, iter [00270, 01251], lr: 0.000295, loss: 0.3971
2022-10-03 09:02:39 - train: epoch 0282, iter [00280, 01251], lr: 0.000294, loss: 0.4027
2022-10-03 09:02:57 - train: epoch 0282, iter [00290, 01251], lr: 0.000294, loss: 0.3996
2022-10-03 09:03:15 - train: epoch 0282, iter [00300, 01251], lr: 0.000294, loss: 0.4001
2022-10-03 09:03:32 - train: epoch 0282, iter [00310, 01251], lr: 0.000294, loss: 0.4173
2022-10-03 09:03:50 - train: epoch 0282, iter [00320, 01251], lr: 0.000294, loss: 0.4057
2022-10-03 09:04:08 - train: epoch 0282, iter [00330, 01251], lr: 0.000294, loss: 0.3997
2022-10-03 09:04:26 - train: epoch 0282, iter [00340, 01251], lr: 0.000294, loss: 0.3922
2022-10-03 09:04:43 - train: epoch 0282, iter [00350, 01251], lr: 0.000294, loss: 0.3895
2022-10-03 09:05:01 - train: epoch 0282, iter [00360, 01251], lr: 0.000294, loss: 0.4151
2022-10-03 09:05:19 - train: epoch 0282, iter [00370, 01251], lr: 0.000294, loss: 0.4091
2022-10-03 09:05:37 - train: epoch 0282, iter [00380, 01251], lr: 0.000294, loss: 0.4010
2022-10-03 09:05:55 - train: epoch 0282, iter [00390, 01251], lr: 0.000294, loss: 0.3954
2022-10-03 09:06:13 - train: epoch 0282, iter [00400, 01251], lr: 0.000294, loss: 0.3683
2022-10-03 09:06:30 - train: epoch 0282, iter [00410, 01251], lr: 0.000294, loss: 0.4084
2022-10-03 09:06:48 - train: epoch 0282, iter [00420, 01251], lr: 0.000294, loss: 0.3977
2022-10-03 09:07:06 - train: epoch 0282, iter [00430, 01251], lr: 0.000294, loss: 0.3844
2022-10-03 09:07:23 - train: epoch 0282, iter [00440, 01251], lr: 0.000294, loss: 0.3850
2022-10-03 09:07:41 - train: epoch 0282, iter [00450, 01251], lr: 0.000294, loss: 0.3892
2022-10-03 09:07:59 - train: epoch 0282, iter [00460, 01251], lr: 0.000294, loss: 0.3814
2022-10-03 09:08:17 - train: epoch 0282, iter [00470, 01251], lr: 0.000294, loss: 0.3886
2022-10-03 09:08:34 - train: epoch 0282, iter [00480, 01251], lr: 0.000294, loss: 0.3710
2022-10-03 09:08:52 - train: epoch 0282, iter [00490, 01251], lr: 0.000294, loss: 0.4011
2022-10-03 09:09:10 - train: epoch 0282, iter [00500, 01251], lr: 0.000294, loss: 0.3895
2022-10-03 09:09:27 - train: epoch 0282, iter [00510, 01251], lr: 0.000294, loss: 0.4110
2022-10-03 09:09:45 - train: epoch 0282, iter [00520, 01251], lr: 0.000294, loss: 0.3789
2022-10-03 09:10:03 - train: epoch 0282, iter [00530, 01251], lr: 0.000294, loss: 0.4038
2022-10-03 09:10:20 - train: epoch 0282, iter [00540, 01251], lr: 0.000294, loss: 0.3976
2022-10-03 09:10:38 - train: epoch 0282, iter [00550, 01251], lr: 0.000293, loss: 0.3903
2022-10-03 09:10:56 - train: epoch 0282, iter [00560, 01251], lr: 0.000293, loss: 0.3959
2022-10-03 09:11:14 - train: epoch 0282, iter [00570, 01251], lr: 0.000293, loss: 0.4055
2022-10-03 09:11:32 - train: epoch 0282, iter [00580, 01251], lr: 0.000293, loss: 0.4160
2022-10-03 09:11:50 - train: epoch 0282, iter [00590, 01251], lr: 0.000293, loss: 0.4034
2022-10-03 09:12:08 - train: epoch 0282, iter [00600, 01251], lr: 0.000293, loss: 0.4027
2022-10-03 09:12:25 - train: epoch 0282, iter [00610, 01251], lr: 0.000293, loss: 0.3995
2022-10-03 09:12:43 - train: epoch 0282, iter [00620, 01251], lr: 0.000293, loss: 0.3888
2022-10-03 09:13:01 - train: epoch 0282, iter [00630, 01251], lr: 0.000293, loss: 0.4233
2022-10-03 09:13:19 - train: epoch 0282, iter [00640, 01251], lr: 0.000293, loss: 0.4132
2022-10-03 09:13:37 - train: epoch 0282, iter [00650, 01251], lr: 0.000293, loss: 0.4078
2022-10-03 09:13:54 - train: epoch 0282, iter [00660, 01251], lr: 0.000293, loss: 0.4002
2022-10-03 09:14:12 - train: epoch 0282, iter [00670, 01251], lr: 0.000293, loss: 0.3916
2022-10-03 09:14:30 - train: epoch 0282, iter [00680, 01251], lr: 0.000293, loss: 0.3982
2022-10-03 09:14:48 - train: epoch 0282, iter [00690, 01251], lr: 0.000293, loss: 0.4107
2022-10-03 09:15:05 - train: epoch 0282, iter [00700, 01251], lr: 0.000293, loss: 0.4048
2022-10-03 09:15:23 - train: epoch 0282, iter [00710, 01251], lr: 0.000293, loss: 0.3810
2022-10-03 09:15:41 - train: epoch 0282, iter [00720, 01251], lr: 0.000293, loss: 0.4026
2022-10-03 09:15:59 - train: epoch 0282, iter [00730, 01251], lr: 0.000293, loss: 0.4041
2022-10-03 09:16:17 - train: epoch 0282, iter [00740, 01251], lr: 0.000293, loss: 0.3966
2022-10-03 09:16:34 - train: epoch 0282, iter [00750, 01251], lr: 0.000293, loss: 0.3901
2022-10-03 09:16:52 - train: epoch 0282, iter [00760, 01251], lr: 0.000293, loss: 0.3964
2022-10-03 09:17:10 - train: epoch 0282, iter [00770, 01251], lr: 0.000293, loss: 0.3887
2022-10-03 09:17:28 - train: epoch 0282, iter [00780, 01251], lr: 0.000293, loss: 0.3937
2022-10-03 09:17:46 - train: epoch 0282, iter [00790, 01251], lr: 0.000293, loss: 0.4063
2022-10-03 09:18:03 - train: epoch 0282, iter [00800, 01251], lr: 0.000293, loss: 0.4334
2022-10-03 09:18:21 - train: epoch 0282, iter [00810, 01251], lr: 0.000293, loss: 0.4021
2022-10-03 09:18:39 - train: epoch 0282, iter [00820, 01251], lr: 0.000293, loss: 0.3884
2022-10-03 09:18:56 - train: epoch 0282, iter [00830, 01251], lr: 0.000292, loss: 0.4036
2022-10-03 09:19:14 - train: epoch 0282, iter [00840, 01251], lr: 0.000292, loss: 0.3739
2022-10-03 09:19:32 - train: epoch 0282, iter [00850, 01251], lr: 0.000292, loss: 0.4131
2022-10-03 09:19:50 - train: epoch 0282, iter [00860, 01251], lr: 0.000292, loss: 0.3910
2022-10-03 09:20:08 - train: epoch 0282, iter [00870, 01251], lr: 0.000292, loss: 0.4053
2022-10-03 09:20:25 - train: epoch 0282, iter [00880, 01251], lr: 0.000292, loss: 0.3941
2022-10-03 09:20:43 - train: epoch 0282, iter [00890, 01251], lr: 0.000292, loss: 0.4073
2022-10-03 09:21:01 - train: epoch 0282, iter [00900, 01251], lr: 0.000292, loss: 0.4087
2022-10-03 09:21:18 - train: epoch 0282, iter [00910, 01251], lr: 0.000292, loss: 0.4049
2022-10-03 09:21:36 - train: epoch 0282, iter [00920, 01251], lr: 0.000292, loss: 0.4108
2022-10-03 09:21:54 - train: epoch 0282, iter [00930, 01251], lr: 0.000292, loss: 0.4087
2022-10-03 09:22:11 - train: epoch 0282, iter [00940, 01251], lr: 0.000292, loss: 0.3962
2022-10-03 09:22:29 - train: epoch 0282, iter [00950, 01251], lr: 0.000292, loss: 0.3908
2022-10-03 09:22:47 - train: epoch 0282, iter [00960, 01251], lr: 0.000292, loss: 0.3969
2022-10-03 09:23:04 - train: epoch 0282, iter [00970, 01251], lr: 0.000292, loss: 0.3882
2022-10-03 09:23:22 - train: epoch 0282, iter [00980, 01251], lr: 0.000292, loss: 0.3913
2022-10-03 09:23:40 - train: epoch 0282, iter [00990, 01251], lr: 0.000292, loss: 0.4082
2022-10-03 09:23:57 - train: epoch 0282, iter [01000, 01251], lr: 0.000292, loss: 0.3898
2022-10-03 09:24:15 - train: epoch 0282, iter [01010, 01251], lr: 0.000292, loss: 0.4043
2022-10-03 09:24:33 - train: epoch 0282, iter [01020, 01251], lr: 0.000292, loss: 0.4007
2022-10-03 09:24:50 - train: epoch 0282, iter [01030, 01251], lr: 0.000292, loss: 0.4144
2022-10-03 09:25:08 - train: epoch 0282, iter [01040, 01251], lr: 0.000292, loss: 0.4041
2022-10-03 09:25:25 - train: epoch 0282, iter [01050, 01251], lr: 0.000292, loss: 0.3814
2022-10-03 09:25:43 - train: epoch 0282, iter [01060, 01251], lr: 0.000292, loss: 0.3938
2022-10-03 09:26:01 - train: epoch 0282, iter [01070, 01251], lr: 0.000292, loss: 0.3776
2022-10-03 09:26:19 - train: epoch 0282, iter [01080, 01251], lr: 0.000292, loss: 0.4089
2022-10-03 09:26:36 - train: epoch 0282, iter [01090, 01251], lr: 0.000292, loss: 0.4032
2022-10-03 09:26:54 - train: epoch 0282, iter [01100, 01251], lr: 0.000292, loss: 0.3897
2022-10-03 09:27:11 - train: epoch 0282, iter [01110, 01251], lr: 0.000291, loss: 0.4095
2022-10-03 09:27:29 - train: epoch 0282, iter [01120, 01251], lr: 0.000291, loss: 0.4006
2022-10-03 09:27:46 - train: epoch 0282, iter [01130, 01251], lr: 0.000291, loss: 0.4168
2022-10-03 09:28:04 - train: epoch 0282, iter [01140, 01251], lr: 0.000291, loss: 0.3957
2022-10-03 09:28:22 - train: epoch 0282, iter [01150, 01251], lr: 0.000291, loss: 0.3841
2022-10-03 09:28:40 - train: epoch 0282, iter [01160, 01251], lr: 0.000291, loss: 0.3932
2022-10-03 09:28:58 - train: epoch 0282, iter [01170, 01251], lr: 0.000291, loss: 0.3997
2022-10-03 09:29:15 - train: epoch 0282, iter [01180, 01251], lr: 0.000291, loss: 0.4011
2022-10-03 09:29:33 - train: epoch 0282, iter [01190, 01251], lr: 0.000291, loss: 0.4070
2022-10-03 09:29:51 - train: epoch 0282, iter [01200, 01251], lr: 0.000291, loss: 0.4009
2022-10-03 09:30:09 - train: epoch 0282, iter [01210, 01251], lr: 0.000291, loss: 0.4185
2022-10-03 09:30:26 - train: epoch 0282, iter [01220, 01251], lr: 0.000291, loss: 0.3879
2022-10-03 09:30:44 - train: epoch 0282, iter [01230, 01251], lr: 0.000291, loss: 0.3986
2022-10-03 09:31:02 - train: epoch 0282, iter [01240, 01251], lr: 0.000291, loss: 0.4129
2022-10-03 09:31:19 - train: epoch 0282, iter [01250, 01251], lr: 0.000291, loss: 0.4012
2022-10-03 09:31:22 - train: epoch 282, train_loss: 0.3995
2022-10-03 09:31:23 - until epoch: 282, best_loss: 0.3995
2022-10-03 09:31:23 - epoch 283 lr: 0.000291
2022-10-03 09:31:48 - train: epoch 0283, iter [00010, 01251], lr: 0.000291, loss: 0.4114
2022-10-03 09:32:07 - train: epoch 0283, iter [00020, 01251], lr: 0.000291, loss: 0.3838
2022-10-03 09:32:25 - train: epoch 0283, iter [00030, 01251], lr: 0.000291, loss: 0.4144
2022-10-03 09:32:42 - train: epoch 0283, iter [00040, 01251], lr: 0.000291, loss: 0.4055
2022-10-03 09:32:59 - train: epoch 0283, iter [00050, 01251], lr: 0.000291, loss: 0.3979
2022-10-03 09:33:17 - train: epoch 0283, iter [00060, 01251], lr: 0.000291, loss: 0.3908
2022-10-03 09:33:35 - train: epoch 0283, iter [00070, 01251], lr: 0.000291, loss: 0.4110
2022-10-03 09:33:52 - train: epoch 0283, iter [00080, 01251], lr: 0.000291, loss: 0.3995
2022-10-03 09:34:10 - train: epoch 0283, iter [00090, 01251], lr: 0.000291, loss: 0.4179
2022-10-03 09:34:28 - train: epoch 0283, iter [00100, 01251], lr: 0.000291, loss: 0.4040
2022-10-03 09:34:46 - train: epoch 0283, iter [00110, 01251], lr: 0.000291, loss: 0.4139
2022-10-03 09:35:03 - train: epoch 0283, iter [00120, 01251], lr: 0.000291, loss: 0.4047
2022-10-03 09:35:21 - train: epoch 0283, iter [00130, 01251], lr: 0.000291, loss: 0.3986
2022-10-03 09:35:39 - train: epoch 0283, iter [00140, 01251], lr: 0.000290, loss: 0.4075
2022-10-03 09:35:56 - train: epoch 0283, iter [00150, 01251], lr: 0.000290, loss: 0.3988
2022-10-03 09:36:14 - train: epoch 0283, iter [00160, 01251], lr: 0.000290, loss: 0.4004
2022-10-03 09:36:31 - train: epoch 0283, iter [00170, 01251], lr: 0.000290, loss: 0.4172
2022-10-03 09:36:49 - train: epoch 0283, iter [00180, 01251], lr: 0.000290, loss: 0.4035
2022-10-03 09:37:07 - train: epoch 0283, iter [00190, 01251], lr: 0.000290, loss: 0.4069
2022-10-03 09:37:25 - train: epoch 0283, iter [00200, 01251], lr: 0.000290, loss: 0.3883
2022-10-03 09:37:42 - train: epoch 0283, iter [00210, 01251], lr: 0.000290, loss: 0.4047
2022-10-03 09:38:00 - train: epoch 0283, iter [00220, 01251], lr: 0.000290, loss: 0.3957
2022-10-03 09:38:17 - train: epoch 0283, iter [00230, 01251], lr: 0.000290, loss: 0.3961
2022-10-03 09:38:35 - train: epoch 0283, iter [00240, 01251], lr: 0.000290, loss: 0.3854
2022-10-03 09:38:53 - train: epoch 0283, iter [00250, 01251], lr: 0.000290, loss: 0.4153
2022-10-03 09:39:10 - train: epoch 0283, iter [00260, 01251], lr: 0.000290, loss: 0.3989
2022-10-03 09:39:28 - train: epoch 0283, iter [00270, 01251], lr: 0.000290, loss: 0.3749
2022-10-03 09:39:45 - train: epoch 0283, iter [00280, 01251], lr: 0.000290, loss: 0.4115
2022-10-03 09:40:03 - train: epoch 0283, iter [00290, 01251], lr: 0.000290, loss: 0.4152
2022-10-03 09:40:21 - train: epoch 0283, iter [00300, 01251], lr: 0.000290, loss: 0.4063
2022-10-03 09:40:38 - train: epoch 0283, iter [00310, 01251], lr: 0.000290, loss: 0.3934
2022-10-03 09:40:56 - train: epoch 0283, iter [00320, 01251], lr: 0.000290, loss: 0.4012
2022-10-03 09:41:14 - train: epoch 0283, iter [00330, 01251], lr: 0.000290, loss: 0.4061
2022-10-03 09:41:31 - train: epoch 0283, iter [00340, 01251], lr: 0.000290, loss: 0.3965
2022-10-03 09:41:49 - train: epoch 0283, iter [00350, 01251], lr: 0.000290, loss: 0.4024
2022-10-03 09:42:07 - train: epoch 0283, iter [00360, 01251], lr: 0.000290, loss: 0.4180
2022-10-03 09:42:24 - train: epoch 0283, iter [00370, 01251], lr: 0.000290, loss: 0.3815
2022-10-03 09:42:42 - train: epoch 0283, iter [00380, 01251], lr: 0.000290, loss: 0.3883
2022-10-03 09:43:00 - train: epoch 0283, iter [00390, 01251], lr: 0.000290, loss: 0.4103
2022-10-03 09:43:17 - train: epoch 0283, iter [00400, 01251], lr: 0.000290, loss: 0.4075
2022-10-03 09:43:35 - train: epoch 0283, iter [00410, 01251], lr: 0.000290, loss: 0.4158
2022-10-03 09:43:53 - train: epoch 0283, iter [00420, 01251], lr: 0.000289, loss: 0.4105
2022-10-03 09:44:10 - train: epoch 0283, iter [00430, 01251], lr: 0.000289, loss: 0.3908
2022-10-03 09:44:28 - train: epoch 0283, iter [00440, 01251], lr: 0.000289, loss: 0.3902
2022-10-03 09:44:45 - train: epoch 0283, iter [00450, 01251], lr: 0.000289, loss: 0.3989
2022-10-03 09:45:03 - train: epoch 0283, iter [00460, 01251], lr: 0.000289, loss: 0.4023
2022-10-03 09:45:20 - train: epoch 0283, iter [00470, 01251], lr: 0.000289, loss: 0.3847
2022-10-03 09:45:38 - train: epoch 0283, iter [00480, 01251], lr: 0.000289, loss: 0.4272
2022-10-03 09:45:56 - train: epoch 0283, iter [00490, 01251], lr: 0.000289, loss: 0.4086
2022-10-03 09:46:13 - train: epoch 0283, iter [00500, 01251], lr: 0.000289, loss: 0.3713
2022-10-03 09:46:31 - train: epoch 0283, iter [00510, 01251], lr: 0.000289, loss: 0.3958
2022-10-03 09:46:48 - train: epoch 0283, iter [00520, 01251], lr: 0.000289, loss: 0.3972
2022-10-03 09:47:06 - train: epoch 0283, iter [00530, 01251], lr: 0.000289, loss: 0.3938
2022-10-03 09:47:24 - train: epoch 0283, iter [00540, 01251], lr: 0.000289, loss: 0.3944
2022-10-03 09:47:41 - train: epoch 0283, iter [00550, 01251], lr: 0.000289, loss: 0.3926
2022-10-03 09:47:59 - train: epoch 0283, iter [00560, 01251], lr: 0.000289, loss: 0.4009
2022-10-03 09:48:17 - train: epoch 0283, iter [00570, 01251], lr: 0.000289, loss: 0.4085
2022-10-03 09:48:34 - train: epoch 0283, iter [00580, 01251], lr: 0.000289, loss: 0.4105
2022-10-03 09:48:52 - train: epoch 0283, iter [00590, 01251], lr: 0.000289, loss: 0.3938
2022-10-03 09:49:10 - train: epoch 0283, iter [00600, 01251], lr: 0.000289, loss: 0.3905
2022-10-03 09:49:28 - train: epoch 0283, iter [00610, 01251], lr: 0.000289, loss: 0.3987
2022-10-03 09:49:45 - train: epoch 0283, iter [00620, 01251], lr: 0.000289, loss: 0.3744
2022-10-03 09:50:03 - train: epoch 0283, iter [00630, 01251], lr: 0.000289, loss: 0.4033
2022-10-03 09:50:20 - train: epoch 0283, iter [00640, 01251], lr: 0.000289, loss: 0.3970
2022-10-03 09:50:38 - train: epoch 0283, iter [00650, 01251], lr: 0.000289, loss: 0.4132
2022-10-03 09:50:55 - train: epoch 0283, iter [00660, 01251], lr: 0.000289, loss: 0.4061
2022-10-03 09:51:13 - train: epoch 0283, iter [00670, 01251], lr: 0.000289, loss: 0.3880
2022-10-03 09:51:31 - train: epoch 0283, iter [00680, 01251], lr: 0.000289, loss: 0.4074
2022-10-03 09:51:48 - train: epoch 0283, iter [00690, 01251], lr: 0.000289, loss: 0.3975
2022-10-03 09:52:06 - train: epoch 0283, iter [00700, 01251], lr: 0.000288, loss: 0.3806
2022-10-03 09:52:24 - train: epoch 0283, iter [00710, 01251], lr: 0.000288, loss: 0.4086
2022-10-03 09:52:41 - train: epoch 0283, iter [00720, 01251], lr: 0.000288, loss: 0.4047
2022-10-03 09:52:59 - train: epoch 0283, iter [00730, 01251], lr: 0.000288, loss: 0.3918
2022-10-03 09:53:16 - train: epoch 0283, iter [00740, 01251], lr: 0.000288, loss: 0.3948
2022-10-03 09:53:34 - train: epoch 0283, iter [00750, 01251], lr: 0.000288, loss: 0.3919
2022-10-03 09:53:52 - train: epoch 0283, iter [00760, 01251], lr: 0.000288, loss: 0.3959
2022-10-03 09:54:09 - train: epoch 0283, iter [00770, 01251], lr: 0.000288, loss: 0.4002
2022-10-03 09:54:27 - train: epoch 0283, iter [00780, 01251], lr: 0.000288, loss: 0.3966
2022-10-03 09:54:44 - train: epoch 0283, iter [00790, 01251], lr: 0.000288, loss: 0.3715
2022-10-03 09:55:02 - train: epoch 0283, iter [00800, 01251], lr: 0.000288, loss: 0.3817
2022-10-03 09:55:20 - train: epoch 0283, iter [00810, 01251], lr: 0.000288, loss: 0.3876
2022-10-03 09:55:38 - train: epoch 0283, iter [00820, 01251], lr: 0.000288, loss: 0.3849
2022-10-03 09:55:55 - train: epoch 0283, iter [00830, 01251], lr: 0.000288, loss: 0.3887
2022-10-03 09:56:13 - train: epoch 0283, iter [00840, 01251], lr: 0.000288, loss: 0.4049
2022-10-03 09:56:31 - train: epoch 0283, iter [00850, 01251], lr: 0.000288, loss: 0.3975
2022-10-03 09:56:48 - train: epoch 0283, iter [00860, 01251], lr: 0.000288, loss: 0.4000
2022-10-03 09:57:06 - train: epoch 0283, iter [00870, 01251], lr: 0.000288, loss: 0.3853
2022-10-03 09:57:24 - train: epoch 0283, iter [00880, 01251], lr: 0.000288, loss: 0.4023
2022-10-03 09:57:41 - train: epoch 0283, iter [00890, 01251], lr: 0.000288, loss: 0.4017
2022-10-03 09:57:59 - train: epoch 0283, iter [00900, 01251], lr: 0.000288, loss: 0.3917
2022-10-03 09:58:17 - train: epoch 0283, iter [00910, 01251], lr: 0.000288, loss: 0.3886
2022-10-03 09:58:35 - train: epoch 0283, iter [00920, 01251], lr: 0.000288, loss: 0.3924
2022-10-03 09:58:52 - train: epoch 0283, iter [00930, 01251], lr: 0.000288, loss: 0.3992
2022-10-03 09:59:10 - train: epoch 0283, iter [00940, 01251], lr: 0.000288, loss: 0.4257
2022-10-03 09:59:27 - train: epoch 0283, iter [00950, 01251], lr: 0.000288, loss: 0.4036
2022-10-03 09:59:45 - train: epoch 0283, iter [00960, 01251], lr: 0.000288, loss: 0.4097
2022-10-03 10:00:03 - train: epoch 0283, iter [00970, 01251], lr: 0.000288, loss: 0.3989
2022-10-03 10:00:21 - train: epoch 0283, iter [00980, 01251], lr: 0.000287, loss: 0.3800
2022-10-03 10:00:39 - train: epoch 0283, iter [00990, 01251], lr: 0.000287, loss: 0.4003
2022-10-03 10:00:57 - train: epoch 0283, iter [01000, 01251], lr: 0.000287, loss: 0.3943
2022-10-03 10:01:15 - train: epoch 0283, iter [01010, 01251], lr: 0.000287, loss: 0.4175
2022-10-03 10:01:32 - train: epoch 0283, iter [01020, 01251], lr: 0.000287, loss: 0.3900
2022-10-03 10:01:50 - train: epoch 0283, iter [01030, 01251], lr: 0.000287, loss: 0.4198
2022-10-03 10:02:07 - train: epoch 0283, iter [01040, 01251], lr: 0.000287, loss: 0.3927
2022-10-03 10:02:25 - train: epoch 0283, iter [01050, 01251], lr: 0.000287, loss: 0.3914
2022-10-03 10:02:42 - train: epoch 0283, iter [01060, 01251], lr: 0.000287, loss: 0.3966
2022-10-03 10:03:00 - train: epoch 0283, iter [01070, 01251], lr: 0.000287, loss: 0.4106
2022-10-03 10:03:18 - train: epoch 0283, iter [01080, 01251], lr: 0.000287, loss: 0.3866
2022-10-03 10:03:35 - train: epoch 0283, iter [01090, 01251], lr: 0.000287, loss: 0.4062
2022-10-03 10:03:54 - train: epoch 0283, iter [01100, 01251], lr: 0.000287, loss: 0.3936
2022-10-03 10:04:11 - train: epoch 0283, iter [01110, 01251], lr: 0.000287, loss: 0.3922
2022-10-03 10:04:29 - train: epoch 0283, iter [01120, 01251], lr: 0.000287, loss: 0.3932
2022-10-03 10:04:46 - train: epoch 0283, iter [01130, 01251], lr: 0.000287, loss: 0.4143
2022-10-03 10:05:04 - train: epoch 0283, iter [01140, 01251], lr: 0.000287, loss: 0.3809
2022-10-03 10:05:22 - train: epoch 0283, iter [01150, 01251], lr: 0.000287, loss: 0.4243
2022-10-03 10:05:39 - train: epoch 0283, iter [01160, 01251], lr: 0.000287, loss: 0.3874
2022-10-03 10:05:57 - train: epoch 0283, iter [01170, 01251], lr: 0.000287, loss: 0.4076
2022-10-03 10:06:15 - train: epoch 0283, iter [01180, 01251], lr: 0.000287, loss: 0.3939
2022-10-03 10:06:33 - train: epoch 0283, iter [01190, 01251], lr: 0.000287, loss: 0.4089
2022-10-03 10:06:50 - train: epoch 0283, iter [01200, 01251], lr: 0.000287, loss: 0.4033
2022-10-03 10:07:08 - train: epoch 0283, iter [01210, 01251], lr: 0.000287, loss: 0.4169
2022-10-03 10:07:26 - train: epoch 0283, iter [01220, 01251], lr: 0.000287, loss: 0.4006
2022-10-03 10:07:43 - train: epoch 0283, iter [01230, 01251], lr: 0.000287, loss: 0.4044
2022-10-03 10:08:01 - train: epoch 0283, iter [01240, 01251], lr: 0.000287, loss: 0.4044
2022-10-03 10:08:19 - train: epoch 0283, iter [01250, 01251], lr: 0.000287, loss: 0.3964
2022-10-03 10:08:22 - train: epoch 283, train_loss: 0.3993
2022-10-03 10:08:25 - until epoch: 283, best_loss: 0.3993
2022-10-03 10:08:25 - epoch 284 lr: 0.000287
2022-10-03 10:08:50 - train: epoch 0284, iter [00010, 01251], lr: 0.000286, loss: 0.3821
2022-10-03 10:09:08 - train: epoch 0284, iter [00020, 01251], lr: 0.000286, loss: 0.4180
2022-10-03 10:09:26 - train: epoch 0284, iter [00030, 01251], lr: 0.000286, loss: 0.4064
2022-10-03 10:09:43 - train: epoch 0284, iter [00040, 01251], lr: 0.000286, loss: 0.4127
2022-10-03 10:10:01 - train: epoch 0284, iter [00050, 01251], lr: 0.000286, loss: 0.4035
2022-10-03 10:10:19 - train: epoch 0284, iter [00060, 01251], lr: 0.000286, loss: 0.4154
2022-10-03 10:10:37 - train: epoch 0284, iter [00070, 01251], lr: 0.000286, loss: 0.4079
2022-10-03 10:10:55 - train: epoch 0284, iter [00080, 01251], lr: 0.000286, loss: 0.4192
2022-10-03 10:11:13 - train: epoch 0284, iter [00090, 01251], lr: 0.000286, loss: 0.3996
2022-10-03 10:11:31 - train: epoch 0284, iter [00100, 01251], lr: 0.000286, loss: 0.4065
2022-10-03 10:11:49 - train: epoch 0284, iter [00110, 01251], lr: 0.000286, loss: 0.3948
2022-10-03 10:12:07 - train: epoch 0284, iter [00120, 01251], lr: 0.000286, loss: 0.4105
2022-10-03 10:12:25 - train: epoch 0284, iter [00130, 01251], lr: 0.000286, loss: 0.3983
2022-10-03 10:12:43 - train: epoch 0284, iter [00140, 01251], lr: 0.000286, loss: 0.4092
2022-10-03 10:13:01 - train: epoch 0284, iter [00150, 01251], lr: 0.000286, loss: 0.3930
2022-10-03 10:13:19 - train: epoch 0284, iter [00160, 01251], lr: 0.000286, loss: 0.3893
2022-10-03 10:13:37 - train: epoch 0284, iter [00170, 01251], lr: 0.000286, loss: 0.4039
2022-10-03 10:13:55 - train: epoch 0284, iter [00180, 01251], lr: 0.000286, loss: 0.3819
2022-10-03 10:14:13 - train: epoch 0284, iter [00190, 01251], lr: 0.000286, loss: 0.4041
2022-10-03 10:14:31 - train: epoch 0284, iter [00200, 01251], lr: 0.000286, loss: 0.3968
2022-10-03 10:14:49 - train: epoch 0284, iter [00210, 01251], lr: 0.000286, loss: 0.4134
2022-10-03 10:15:07 - train: epoch 0284, iter [00220, 01251], lr: 0.000286, loss: 0.4145
2022-10-03 10:15:25 - train: epoch 0284, iter [00230, 01251], lr: 0.000286, loss: 0.4027
2022-10-03 10:15:43 - train: epoch 0284, iter [00240, 01251], lr: 0.000286, loss: 0.3883
2022-10-03 10:16:01 - train: epoch 0284, iter [00250, 01251], lr: 0.000286, loss: 0.4191
2022-10-03 10:16:19 - train: epoch 0284, iter [00260, 01251], lr: 0.000286, loss: 0.3833
2022-10-03 10:16:36 - train: epoch 0284, iter [00270, 01251], lr: 0.000286, loss: 0.4096
2022-10-03 10:16:54 - train: epoch 0284, iter [00280, 01251], lr: 0.000286, loss: 0.3816
2022-10-03 10:17:12 - train: epoch 0284, iter [00290, 01251], lr: 0.000285, loss: 0.4141
2022-10-03 10:17:30 - train: epoch 0284, iter [00300, 01251], lr: 0.000285, loss: 0.3867
2022-10-03 10:17:48 - train: epoch 0284, iter [00310, 01251], lr: 0.000285, loss: 0.3917
2022-10-03 10:18:06 - train: epoch 0284, iter [00320, 01251], lr: 0.000285, loss: 0.4147
2022-10-03 10:18:24 - train: epoch 0284, iter [00330, 01251], lr: 0.000285, loss: 0.3709
2022-10-03 10:18:42 - train: epoch 0284, iter [00340, 01251], lr: 0.000285, loss: 0.4075
2022-10-03 10:19:00 - train: epoch 0284, iter [00350, 01251], lr: 0.000285, loss: 0.4028
2022-10-03 10:19:18 - train: epoch 0284, iter [00360, 01251], lr: 0.000285, loss: 0.3731
2022-10-03 10:19:36 - train: epoch 0284, iter [00370, 01251], lr: 0.000285, loss: 0.3953
2022-10-03 10:19:54 - train: epoch 0284, iter [00380, 01251], lr: 0.000285, loss: 0.3859
2022-10-03 10:20:11 - train: epoch 0284, iter [00390, 01251], lr: 0.000285, loss: 0.4003
2022-10-03 10:20:29 - train: epoch 0284, iter [00400, 01251], lr: 0.000285, loss: 0.3762
2022-10-03 10:20:47 - train: epoch 0284, iter [00410, 01251], lr: 0.000285, loss: 0.3804
2022-10-03 10:21:05 - train: epoch 0284, iter [00420, 01251], lr: 0.000285, loss: 0.4185
2022-10-03 10:21:23 - train: epoch 0284, iter [00430, 01251], lr: 0.000285, loss: 0.4106
2022-10-03 10:21:41 - train: epoch 0284, iter [00440, 01251], lr: 0.000285, loss: 0.3985
2022-10-03 10:21:59 - train: epoch 0284, iter [00450, 01251], lr: 0.000285, loss: 0.4246
2022-10-03 10:22:17 - train: epoch 0284, iter [00460, 01251], lr: 0.000285, loss: 0.4020
2022-10-03 10:22:35 - train: epoch 0284, iter [00470, 01251], lr: 0.000285, loss: 0.4076
2022-10-03 10:22:53 - train: epoch 0284, iter [00480, 01251], lr: 0.000285, loss: 0.3862
2022-10-03 10:23:11 - train: epoch 0284, iter [00490, 01251], lr: 0.000285, loss: 0.4061
2022-10-03 10:23:29 - train: epoch 0284, iter [00500, 01251], lr: 0.000285, loss: 0.3948
2022-10-03 10:23:47 - train: epoch 0284, iter [00510, 01251], lr: 0.000285, loss: 0.4047
2022-10-03 10:24:05 - train: epoch 0284, iter [00520, 01251], lr: 0.000285, loss: 0.3978
2022-10-03 10:24:23 - train: epoch 0284, iter [00530, 01251], lr: 0.000285, loss: 0.4045
2022-10-03 10:24:41 - train: epoch 0284, iter [00540, 01251], lr: 0.000285, loss: 0.4031
2022-10-03 10:24:59 - train: epoch 0284, iter [00550, 01251], lr: 0.000285, loss: 0.4091
2022-10-03 10:25:17 - train: epoch 0284, iter [00560, 01251], lr: 0.000285, loss: 0.4176
2022-10-03 10:25:35 - train: epoch 0284, iter [00570, 01251], lr: 0.000284, loss: 0.3660
2022-10-03 10:25:53 - train: epoch 0284, iter [00580, 01251], lr: 0.000284, loss: 0.3914
2022-10-03 10:26:11 - train: epoch 0284, iter [00590, 01251], lr: 0.000284, loss: 0.4101
2022-10-03 10:26:29 - train: epoch 0284, iter [00600, 01251], lr: 0.000284, loss: 0.4059
2022-10-03 10:26:47 - train: epoch 0284, iter [00610, 01251], lr: 0.000284, loss: 0.3725
2022-10-03 10:27:04 - train: epoch 0284, iter [00620, 01251], lr: 0.000284, loss: 0.4019
2022-10-03 10:27:22 - train: epoch 0284, iter [00630, 01251], lr: 0.000284, loss: 0.3838
2022-10-03 10:27:40 - train: epoch 0284, iter [00640, 01251], lr: 0.000284, loss: 0.3963
2022-10-03 10:27:58 - train: epoch 0284, iter [00650, 01251], lr: 0.000284, loss: 0.3947
2022-10-03 10:28:16 - train: epoch 0284, iter [00660, 01251], lr: 0.000284, loss: 0.4138
2022-10-03 10:28:34 - train: epoch 0284, iter [00670, 01251], lr: 0.000284, loss: 0.4030
2022-10-03 10:28:52 - train: epoch 0284, iter [00680, 01251], lr: 0.000284, loss: 0.3973
2022-10-03 10:29:10 - train: epoch 0284, iter [00690, 01251], lr: 0.000284, loss: 0.3843
2022-10-03 10:29:28 - train: epoch 0284, iter [00700, 01251], lr: 0.000284, loss: 0.4034
2022-10-03 10:29:46 - train: epoch 0284, iter [00710, 01251], lr: 0.000284, loss: 0.3854
2022-10-03 10:30:04 - train: epoch 0284, iter [00720, 01251], lr: 0.000284, loss: 0.4087
2022-10-03 10:30:22 - train: epoch 0284, iter [00730, 01251], lr: 0.000284, loss: 0.4019
2022-10-03 10:30:40 - train: epoch 0284, iter [00740, 01251], lr: 0.000284, loss: 0.4097
2022-10-03 10:30:58 - train: epoch 0284, iter [00750, 01251], lr: 0.000284, loss: 0.3863
2022-10-03 10:31:16 - train: epoch 0284, iter [00760, 01251], lr: 0.000284, loss: 0.3861
2022-10-03 10:31:34 - train: epoch 0284, iter [00770, 01251], lr: 0.000284, loss: 0.4006
2022-10-03 10:31:52 - train: epoch 0284, iter [00780, 01251], lr: 0.000284, loss: 0.3764
2022-10-03 10:32:10 - train: epoch 0284, iter [00790, 01251], lr: 0.000284, loss: 0.3939
2022-10-03 10:32:28 - train: epoch 0284, iter [00800, 01251], lr: 0.000284, loss: 0.3941
2022-10-03 10:32:45 - train: epoch 0284, iter [00810, 01251], lr: 0.000284, loss: 0.3922
2022-10-03 10:33:03 - train: epoch 0284, iter [00820, 01251], lr: 0.000284, loss: 0.3936
2022-10-03 10:33:21 - train: epoch 0284, iter [00830, 01251], lr: 0.000284, loss: 0.3876
2022-10-03 10:33:39 - train: epoch 0284, iter [00840, 01251], lr: 0.000284, loss: 0.4029
2022-10-03 10:33:57 - train: epoch 0284, iter [00850, 01251], lr: 0.000283, loss: 0.3942
2022-10-03 10:34:15 - train: epoch 0284, iter [00860, 01251], lr: 0.000283, loss: 0.3948
2022-10-03 10:34:32 - train: epoch 0284, iter [00870, 01251], lr: 0.000283, loss: 0.4020
2022-10-03 10:34:50 - train: epoch 0284, iter [00880, 01251], lr: 0.000283, loss: 0.3861
2022-10-03 10:35:08 - train: epoch 0284, iter [00890, 01251], lr: 0.000283, loss: 0.3823
2022-10-03 10:35:26 - train: epoch 0284, iter [00900, 01251], lr: 0.000283, loss: 0.4077
2022-10-03 10:35:44 - train: epoch 0284, iter [00910, 01251], lr: 0.000283, loss: 0.3889
2022-10-03 10:36:02 - train: epoch 0284, iter [00920, 01251], lr: 0.000283, loss: 0.4070
2022-10-03 10:36:20 - train: epoch 0284, iter [00930, 01251], lr: 0.000283, loss: 0.3987
2022-10-03 10:36:38 - train: epoch 0284, iter [00940, 01251], lr: 0.000283, loss: 0.3995
2022-10-03 10:36:56 - train: epoch 0284, iter [00950, 01251], lr: 0.000283, loss: 0.3755
2022-10-03 10:37:14 - train: epoch 0284, iter [00960, 01251], lr: 0.000283, loss: 0.3988
2022-10-03 10:37:32 - train: epoch 0284, iter [00970, 01251], lr: 0.000283, loss: 0.4095
2022-10-03 10:37:50 - train: epoch 0284, iter [00980, 01251], lr: 0.000283, loss: 0.3992
2022-10-03 10:38:07 - train: epoch 0284, iter [00990, 01251], lr: 0.000283, loss: 0.3874
2022-10-03 10:38:25 - train: epoch 0284, iter [01000, 01251], lr: 0.000283, loss: 0.3906
2022-10-03 10:38:43 - train: epoch 0284, iter [01010, 01251], lr: 0.000283, loss: 0.4012
2022-10-03 10:39:01 - train: epoch 0284, iter [01020, 01251], lr: 0.000283, loss: 0.3879
2022-10-03 10:39:19 - train: epoch 0284, iter [01030, 01251], lr: 0.000283, loss: 0.3820
2022-10-03 10:39:37 - train: epoch 0284, iter [01040, 01251], lr: 0.000283, loss: 0.3751
2022-10-03 10:39:55 - train: epoch 0284, iter [01050, 01251], lr: 0.000283, loss: 0.4134
2022-10-03 10:40:13 - train: epoch 0284, iter [01060, 01251], lr: 0.000283, loss: 0.3917
2022-10-03 10:40:31 - train: epoch 0284, iter [01070, 01251], lr: 0.000283, loss: 0.3970
2022-10-03 10:40:48 - train: epoch 0284, iter [01080, 01251], lr: 0.000283, loss: 0.4011
2022-10-03 10:41:06 - train: epoch 0284, iter [01090, 01251], lr: 0.000283, loss: 0.3833
2022-10-03 10:41:24 - train: epoch 0284, iter [01100, 01251], lr: 0.000283, loss: 0.4043
2022-10-03 10:41:42 - train: epoch 0284, iter [01110, 01251], lr: 0.000283, loss: 0.3976
2022-10-03 10:42:00 - train: epoch 0284, iter [01120, 01251], lr: 0.000283, loss: 0.4081
2022-10-03 10:42:18 - train: epoch 0284, iter [01130, 01251], lr: 0.000282, loss: 0.4312
2022-10-03 10:42:36 - train: epoch 0284, iter [01140, 01251], lr: 0.000282, loss: 0.4008
2022-10-03 10:42:54 - train: epoch 0284, iter [01150, 01251], lr: 0.000282, loss: 0.3712
2022-10-03 10:43:11 - train: epoch 0284, iter [01160, 01251], lr: 0.000282, loss: 0.4009
2022-10-03 10:43:30 - train: epoch 0284, iter [01170, 01251], lr: 0.000282, loss: 0.3907
2022-10-03 10:43:47 - train: epoch 0284, iter [01180, 01251], lr: 0.000282, loss: 0.3952
2022-10-03 10:44:05 - train: epoch 0284, iter [01190, 01251], lr: 0.000282, loss: 0.4006
2022-10-03 10:44:23 - train: epoch 0284, iter [01200, 01251], lr: 0.000282, loss: 0.4050
2022-10-03 10:44:41 - train: epoch 0284, iter [01210, 01251], lr: 0.000282, loss: 0.3892
2022-10-03 10:44:59 - train: epoch 0284, iter [01220, 01251], lr: 0.000282, loss: 0.3991
2022-10-03 10:45:17 - train: epoch 0284, iter [01230, 01251], lr: 0.000282, loss: 0.3848
2022-10-03 10:45:35 - train: epoch 0284, iter [01240, 01251], lr: 0.000282, loss: 0.3795
2022-10-03 10:45:53 - train: epoch 0284, iter [01250, 01251], lr: 0.000282, loss: 0.3975
2022-10-03 10:45:56 - train: epoch 284, train_loss: 0.3992
2022-10-03 10:45:59 - until epoch: 284, best_loss: 0.3992
2022-10-03 10:45:59 - epoch 285 lr: 0.000282
2022-10-03 10:46:24 - train: epoch 0285, iter [00010, 01251], lr: 0.000282, loss: 0.4110
2022-10-03 10:46:42 - train: epoch 0285, iter [00020, 01251], lr: 0.000282, loss: 0.4119
2022-10-03 10:47:00 - train: epoch 0285, iter [00030, 01251], lr: 0.000282, loss: 0.4107
2022-10-03 10:47:18 - train: epoch 0285, iter [00040, 01251], lr: 0.000282, loss: 0.4034
2022-10-03 10:47:35 - train: epoch 0285, iter [00050, 01251], lr: 0.000282, loss: 0.4036
2022-10-03 10:47:54 - train: epoch 0285, iter [00060, 01251], lr: 0.000282, loss: 0.3764
2022-10-03 10:48:12 - train: epoch 0285, iter [00070, 01251], lr: 0.000282, loss: 0.3972
2022-10-03 10:48:30 - train: epoch 0285, iter [00080, 01251], lr: 0.000282, loss: 0.3915
2022-10-03 10:48:48 - train: epoch 0285, iter [00090, 01251], lr: 0.000282, loss: 0.4119
2022-10-03 10:49:05 - train: epoch 0285, iter [00100, 01251], lr: 0.000282, loss: 0.4095
2022-10-03 10:49:23 - train: epoch 0285, iter [00110, 01251], lr: 0.000282, loss: 0.3938
2022-10-03 10:49:41 - train: epoch 0285, iter [00120, 01251], lr: 0.000282, loss: 0.4002
2022-10-03 10:49:59 - train: epoch 0285, iter [00130, 01251], lr: 0.000282, loss: 0.3822
2022-10-03 10:50:17 - train: epoch 0285, iter [00140, 01251], lr: 0.000282, loss: 0.3981
2022-10-03 10:50:35 - train: epoch 0285, iter [00150, 01251], lr: 0.000282, loss: 0.3974
2022-10-03 10:50:52 - train: epoch 0285, iter [00160, 01251], lr: 0.000281, loss: 0.3989
2022-10-03 10:51:10 - train: epoch 0285, iter [00170, 01251], lr: 0.000281, loss: 0.4092
2022-10-03 10:51:29 - train: epoch 0285, iter [00180, 01251], lr: 0.000281, loss: 0.4060
2022-10-03 10:51:47 - train: epoch 0285, iter [00190, 01251], lr: 0.000281, loss: 0.4019
2022-10-03 10:52:05 - train: epoch 0285, iter [00200, 01251], lr: 0.000281, loss: 0.3855
2022-10-03 10:52:23 - train: epoch 0285, iter [00210, 01251], lr: 0.000281, loss: 0.3835
2022-10-03 10:52:41 - train: epoch 0285, iter [00220, 01251], lr: 0.000281, loss: 0.4064
2022-10-03 10:52:59 - train: epoch 0285, iter [00230, 01251], lr: 0.000281, loss: 0.4176
2022-10-03 10:53:17 - train: epoch 0285, iter [00240, 01251], lr: 0.000281, loss: 0.3886
2022-10-03 10:53:35 - train: epoch 0285, iter [00250, 01251], lr: 0.000281, loss: 0.4074
2022-10-03 10:53:53 - train: epoch 0285, iter [00260, 01251], lr: 0.000281, loss: 0.4004
2022-10-03 10:54:11 - train: epoch 0285, iter [00270, 01251], lr: 0.000281, loss: 0.4016
2022-10-03 10:54:29 - train: epoch 0285, iter [00280, 01251], lr: 0.000281, loss: 0.3973
2022-10-03 10:54:47 - train: epoch 0285, iter [00290, 01251], lr: 0.000281, loss: 0.4060
2022-10-03 10:55:05 - train: epoch 0285, iter [00300, 01251], lr: 0.000281, loss: 0.4044
2022-10-03 10:55:24 - train: epoch 0285, iter [00310, 01251], lr: 0.000281, loss: 0.4045
2022-10-03 10:55:42 - train: epoch 0285, iter [00320, 01251], lr: 0.000281, loss: 0.3870
2022-10-03 10:56:00 - train: epoch 0285, iter [00330, 01251], lr: 0.000281, loss: 0.3961
2022-10-03 10:56:18 - train: epoch 0285, iter [00340, 01251], lr: 0.000281, loss: 0.4044
2022-10-03 10:56:36 - train: epoch 0285, iter [00350, 01251], lr: 0.000281, loss: 0.4196
2022-10-03 10:56:54 - train: epoch 0285, iter [00360, 01251], lr: 0.000281, loss: 0.3964
2022-10-03 10:57:12 - train: epoch 0285, iter [00370, 01251], lr: 0.000281, loss: 0.3934
2022-10-03 10:57:31 - train: epoch 0285, iter [00380, 01251], lr: 0.000281, loss: 0.4055
2022-10-03 10:57:49 - train: epoch 0285, iter [00390, 01251], lr: 0.000281, loss: 0.3914
2022-10-03 10:58:07 - train: epoch 0285, iter [00400, 01251], lr: 0.000281, loss: 0.4030
2022-10-03 10:58:25 - train: epoch 0285, iter [00410, 01251], lr: 0.000281, loss: 0.3954
2022-10-03 10:58:43 - train: epoch 0285, iter [00420, 01251], lr: 0.000281, loss: 0.4045
2022-10-03 10:59:01 - train: epoch 0285, iter [00430, 01251], lr: 0.000281, loss: 0.4090
2022-10-03 10:59:19 - train: epoch 0285, iter [00440, 01251], lr: 0.000280, loss: 0.4049
2022-10-03 10:59:38 - train: epoch 0285, iter [00450, 01251], lr: 0.000280, loss: 0.3946
2022-10-03 10:59:56 - train: epoch 0285, iter [00460, 01251], lr: 0.000280, loss: 0.3993
2022-10-03 11:00:13 - train: epoch 0285, iter [00470, 01251], lr: 0.000280, loss: 0.3910
2022-10-03 11:00:31 - train: epoch 0285, iter [00480, 01251], lr: 0.000280, loss: 0.3952
2022-10-03 11:00:50 - train: epoch 0285, iter [00490, 01251], lr: 0.000280, loss: 0.3944
2022-10-03 11:01:08 - train: epoch 0285, iter [00500, 01251], lr: 0.000280, loss: 0.4311
2022-10-03 11:01:26 - train: epoch 0285, iter [00510, 01251], lr: 0.000280, loss: 0.4061
2022-10-03 11:01:44 - train: epoch 0285, iter [00520, 01251], lr: 0.000280, loss: 0.3847
2022-10-03 11:02:02 - train: epoch 0285, iter [00530, 01251], lr: 0.000280, loss: 0.3868
2022-10-03 11:02:20 - train: epoch 0285, iter [00540, 01251], lr: 0.000280, loss: 0.3886
2022-10-03 11:02:38 - train: epoch 0285, iter [00550, 01251], lr: 0.000280, loss: 0.3975
2022-10-03 11:02:56 - train: epoch 0285, iter [00560, 01251], lr: 0.000280, loss: 0.3925
2022-10-03 11:03:14 - train: epoch 0285, iter [00570, 01251], lr: 0.000280, loss: 0.4147
2022-10-03 11:03:32 - train: epoch 0285, iter [00580, 01251], lr: 0.000280, loss: 0.4028
2022-10-03 11:03:50 - train: epoch 0285, iter [00590, 01251], lr: 0.000280, loss: 0.3948
2022-10-03 11:04:08 - train: epoch 0285, iter [00600, 01251], lr: 0.000280, loss: 0.4035
2022-10-03 11:04:26 - train: epoch 0285, iter [00610, 01251], lr: 0.000280, loss: 0.3997
2022-10-03 11:04:45 - train: epoch 0285, iter [00620, 01251], lr: 0.000280, loss: 0.4075
2022-10-03 11:05:02 - train: epoch 0285, iter [00630, 01251], lr: 0.000280, loss: 0.3794
2022-10-03 11:05:21 - train: epoch 0285, iter [00640, 01251], lr: 0.000280, loss: 0.3725
2022-10-03 11:05:38 - train: epoch 0285, iter [00650, 01251], lr: 0.000280, loss: 0.4078
2022-10-03 11:05:56 - train: epoch 0285, iter [00660, 01251], lr: 0.000280, loss: 0.3810
2022-10-03 11:06:15 - train: epoch 0285, iter [00670, 01251], lr: 0.000280, loss: 0.4206
2022-10-03 11:06:33 - train: epoch 0285, iter [00680, 01251], lr: 0.000280, loss: 0.3901
2022-10-03 11:06:51 - train: epoch 0285, iter [00690, 01251], lr: 0.000280, loss: 0.3738
2022-10-03 11:07:09 - train: epoch 0285, iter [00700, 01251], lr: 0.000280, loss: 0.3892
2022-10-03 11:07:27 - train: epoch 0285, iter [00710, 01251], lr: 0.000280, loss: 0.3973
2022-10-03 11:07:45 - train: epoch 0285, iter [00720, 01251], lr: 0.000279, loss: 0.4134
2022-10-03 11:08:03 - train: epoch 0285, iter [00730, 01251], lr: 0.000279, loss: 0.4066
2022-10-03 11:08:21 - train: epoch 0285, iter [00740, 01251], lr: 0.000279, loss: 0.3887
2022-10-03 11:08:40 - train: epoch 0285, iter [00750, 01251], lr: 0.000279, loss: 0.4111
2022-10-03 11:08:58 - train: epoch 0285, iter [00760, 01251], lr: 0.000279, loss: 0.3808
2022-10-03 11:09:16 - train: epoch 0285, iter [00770, 01251], lr: 0.000279, loss: 0.4027
2022-10-03 11:09:34 - train: epoch 0285, iter [00780, 01251], lr: 0.000279, loss: 0.4227
2022-10-03 11:09:52 - train: epoch 0285, iter [00790, 01251], lr: 0.000279, loss: 0.3882
2022-10-03 11:10:10 - train: epoch 0285, iter [00800, 01251], lr: 0.000279, loss: 0.3755
2022-10-03 11:10:28 - train: epoch 0285, iter [00810, 01251], lr: 0.000279, loss: 0.4077
2022-10-03 11:10:46 - train: epoch 0285, iter [00820, 01251], lr: 0.000279, loss: 0.4021
2022-10-03 11:11:04 - train: epoch 0285, iter [00830, 01251], lr: 0.000279, loss: 0.3839
2022-10-03 11:11:22 - train: epoch 0285, iter [00840, 01251], lr: 0.000279, loss: 0.3971
2022-10-03 11:11:40 - train: epoch 0285, iter [00850, 01251], lr: 0.000279, loss: 0.3825
2022-10-03 11:11:58 - train: epoch 0285, iter [00860, 01251], lr: 0.000279, loss: 0.3976
2022-10-03 11:12:17 - train: epoch 0285, iter [00870, 01251], lr: 0.000279, loss: 0.4188
2022-10-03 11:12:35 - train: epoch 0285, iter [00880, 01251], lr: 0.000279, loss: 0.4062
2022-10-03 11:12:53 - train: epoch 0285, iter [00890, 01251], lr: 0.000279, loss: 0.4049
2022-10-03 11:13:11 - train: epoch 0285, iter [00900, 01251], lr: 0.000279, loss: 0.3860
2022-10-03 11:13:29 - train: epoch 0285, iter [00910, 01251], lr: 0.000279, loss: 0.3952
2022-10-03 11:13:47 - train: epoch 0285, iter [00920, 01251], lr: 0.000279, loss: 0.4029
2022-10-03 11:14:05 - train: epoch 0285, iter [00930, 01251], lr: 0.000279, loss: 0.3957
2022-10-03 11:14:23 - train: epoch 0285, iter [00940, 01251], lr: 0.000279, loss: 0.3927
2022-10-03 11:14:41 - train: epoch 0285, iter [00950, 01251], lr: 0.000279, loss: 0.3968
2022-10-03 11:14:59 - train: epoch 0285, iter [00960, 01251], lr: 0.000279, loss: 0.4135
2022-10-03 11:15:17 - train: epoch 0285, iter [00970, 01251], lr: 0.000279, loss: 0.3956
2022-10-03 11:15:35 - train: epoch 0285, iter [00980, 01251], lr: 0.000279, loss: 0.3956
2022-10-03 11:15:53 - train: epoch 0285, iter [00990, 01251], lr: 0.000279, loss: 0.3924
2022-10-03 11:16:11 - train: epoch 0285, iter [01000, 01251], lr: 0.000279, loss: 0.3919
2022-10-03 11:16:30 - train: epoch 0285, iter [01010, 01251], lr: 0.000278, loss: 0.3889
2022-10-03 11:16:48 - train: epoch 0285, iter [01020, 01251], lr: 0.000278, loss: 0.4091
2022-10-03 11:17:06 - train: epoch 0285, iter [01030, 01251], lr: 0.000278, loss: 0.4116
2022-10-03 11:17:24 - train: epoch 0285, iter [01040, 01251], lr: 0.000278, loss: 0.3992
2022-10-03 11:17:42 - train: epoch 0285, iter [01050, 01251], lr: 0.000278, loss: 0.3915
2022-10-03 11:18:01 - train: epoch 0285, iter [01060, 01251], lr: 0.000278, loss: 0.4016
2022-10-03 11:18:19 - train: epoch 0285, iter [01070, 01251], lr: 0.000278, loss: 0.3922
2022-10-03 11:18:37 - train: epoch 0285, iter [01080, 01251], lr: 0.000278, loss: 0.4072
2022-10-03 11:18:55 - train: epoch 0285, iter [01090, 01251], lr: 0.000278, loss: 0.3970
2022-10-03 11:19:13 - train: epoch 0285, iter [01100, 01251], lr: 0.000278, loss: 0.4236
2022-10-03 11:19:31 - train: epoch 0285, iter [01110, 01251], lr: 0.000278, loss: 0.3810
2022-10-03 11:19:49 - train: epoch 0285, iter [01120, 01251], lr: 0.000278, loss: 0.3923
2022-10-03 11:20:07 - train: epoch 0285, iter [01130, 01251], lr: 0.000278, loss: 0.3944
2022-10-03 11:20:25 - train: epoch 0285, iter [01140, 01251], lr: 0.000278, loss: 0.3945
2022-10-03 11:20:43 - train: epoch 0285, iter [01150, 01251], lr: 0.000278, loss: 0.3935
2022-10-03 11:21:02 - train: epoch 0285, iter [01160, 01251], lr: 0.000278, loss: 0.4131
2022-10-03 11:21:20 - train: epoch 0285, iter [01170, 01251], lr: 0.000278, loss: 0.4148
2022-10-03 11:21:38 - train: epoch 0285, iter [01180, 01251], lr: 0.000278, loss: 0.4040
2022-10-03 11:21:56 - train: epoch 0285, iter [01190, 01251], lr: 0.000278, loss: 0.4122
2022-10-03 11:22:14 - train: epoch 0285, iter [01200, 01251], lr: 0.000278, loss: 0.3946
2022-10-03 11:22:32 - train: epoch 0285, iter [01210, 01251], lr: 0.000278, loss: 0.4035
2022-10-03 11:22:50 - train: epoch 0285, iter [01220, 01251], lr: 0.000278, loss: 0.3827
2022-10-03 11:23:08 - train: epoch 0285, iter [01230, 01251], lr: 0.000278, loss: 0.3914
2022-10-03 11:23:27 - train: epoch 0285, iter [01240, 01251], lr: 0.000278, loss: 0.3809
2022-10-03 11:23:45 - train: epoch 0285, iter [01250, 01251], lr: 0.000278, loss: 0.3911
2022-10-03 11:23:48 - train: epoch 285, train_loss: 0.3993
2022-10-03 11:23:49 - until epoch: 285, best_loss: 0.3992
2022-10-03 11:23:49 - epoch 286 lr: 0.000278
2022-10-03 11:24:15 - train: epoch 0286, iter [00010, 01251], lr: 0.000278, loss: 0.4011
2022-10-03 11:24:33 - train: epoch 0286, iter [00020, 01251], lr: 0.000278, loss: 0.3860
2022-10-03 11:24:51 - train: epoch 0286, iter [00030, 01251], lr: 0.000278, loss: 0.4150
2022-10-03 11:25:09 - train: epoch 0286, iter [00040, 01251], lr: 0.000277, loss: 0.3899
2022-10-03 11:25:27 - train: epoch 0286, iter [00050, 01251], lr: 0.000277, loss: 0.3906
2022-10-03 11:25:45 - train: epoch 0286, iter [00060, 01251], lr: 0.000277, loss: 0.4017
2022-10-03 11:26:03 - train: epoch 0286, iter [00070, 01251], lr: 0.000277, loss: 0.4194
2022-10-03 11:26:21 - train: epoch 0286, iter [00080, 01251], lr: 0.000277, loss: 0.3871
2022-10-03 11:26:39 - train: epoch 0286, iter [00090, 01251], lr: 0.000277, loss: 0.3802
2022-10-03 11:26:57 - train: epoch 0286, iter [00100, 01251], lr: 0.000277, loss: 0.3961
2022-10-03 11:27:16 - train: epoch 0286, iter [00110, 01251], lr: 0.000277, loss: 0.4117
2022-10-03 11:27:34 - train: epoch 0286, iter [00120, 01251], lr: 0.000277, loss: 0.4053
2022-10-03 11:27:52 - train: epoch 0286, iter [00130, 01251], lr: 0.000277, loss: 0.4045
2022-10-03 11:28:10 - train: epoch 0286, iter [00140, 01251], lr: 0.000277, loss: 0.3919
2022-10-03 11:28:28 - train: epoch 0286, iter [00150, 01251], lr: 0.000277, loss: 0.4044
2022-10-03 11:28:46 - train: epoch 0286, iter [00160, 01251], lr: 0.000277, loss: 0.4183
2022-10-03 11:29:04 - train: epoch 0286, iter [00170, 01251], lr: 0.000277, loss: 0.4125
2022-10-03 11:29:22 - train: epoch 0286, iter [00180, 01251], lr: 0.000277, loss: 0.3933
2022-10-03 11:29:40 - train: epoch 0286, iter [00190, 01251], lr: 0.000277, loss: 0.4119
2022-10-03 11:29:58 - train: epoch 0286, iter [00200, 01251], lr: 0.000277, loss: 0.4018
2022-10-03 11:30:16 - train: epoch 0286, iter [00210, 01251], lr: 0.000277, loss: 0.4070
2022-10-03 11:30:35 - train: epoch 0286, iter [00220, 01251], lr: 0.000277, loss: 0.3803
2022-10-03 11:30:53 - train: epoch 0286, iter [00230, 01251], lr: 0.000277, loss: 0.3775
2022-10-03 11:31:11 - train: epoch 0286, iter [00240, 01251], lr: 0.000277, loss: 0.4088
2022-10-03 11:31:29 - train: epoch 0286, iter [00250, 01251], lr: 0.000277, loss: 0.4066
2022-10-03 11:31:47 - train: epoch 0286, iter [00260, 01251], lr: 0.000277, loss: 0.3827
2022-10-03 11:32:05 - train: epoch 0286, iter [00270, 01251], lr: 0.000277, loss: 0.3769
2022-10-03 11:32:23 - train: epoch 0286, iter [00280, 01251], lr: 0.000277, loss: 0.4113
2022-10-03 11:32:41 - train: epoch 0286, iter [00290, 01251], lr: 0.000277, loss: 0.4118
2022-10-03 11:33:00 - train: epoch 0286, iter [00300, 01251], lr: 0.000277, loss: 0.4170
2022-10-03 11:33:18 - train: epoch 0286, iter [00310, 01251], lr: 0.000277, loss: 0.3804
2022-10-03 11:33:36 - train: epoch 0286, iter [00320, 01251], lr: 0.000276, loss: 0.3957
2022-10-03 11:33:54 - train: epoch 0286, iter [00330, 01251], lr: 0.000276, loss: 0.3910
2022-10-03 11:34:12 - train: epoch 0286, iter [00340, 01251], lr: 0.000276, loss: 0.4042
2022-10-03 11:34:30 - train: epoch 0286, iter [00350, 01251], lr: 0.000276, loss: 0.4117
2022-10-03 11:34:48 - train: epoch 0286, iter [00360, 01251], lr: 0.000276, loss: 0.4057
2022-10-03 11:35:06 - train: epoch 0286, iter [00370, 01251], lr: 0.000276, loss: 0.3828
2022-10-03 11:35:24 - train: epoch 0286, iter [00380, 01251], lr: 0.000276, loss: 0.3940
2022-10-03 11:35:42 - train: epoch 0286, iter [00390, 01251], lr: 0.000276, loss: 0.4292
2022-10-03 11:36:00 - train: epoch 0286, iter [00400, 01251], lr: 0.000276, loss: 0.3903
2022-10-03 11:36:18 - train: epoch 0286, iter [00410, 01251], lr: 0.000276, loss: 0.4115
2022-10-03 11:36:37 - train: epoch 0286, iter [00420, 01251], lr: 0.000276, loss: 0.4102
2022-10-03 11:36:55 - train: epoch 0286, iter [00430, 01251], lr: 0.000276, loss: 0.4093
2022-10-03 11:37:13 - train: epoch 0286, iter [00440, 01251], lr: 0.000276, loss: 0.4127
2022-10-03 11:37:31 - train: epoch 0286, iter [00450, 01251], lr: 0.000276, loss: 0.3859
2022-10-03 11:37:49 - train: epoch 0286, iter [00460, 01251], lr: 0.000276, loss: 0.3837
2022-10-03 11:38:07 - train: epoch 0286, iter [00470, 01251], lr: 0.000276, loss: 0.4140
2022-10-03 11:38:25 - train: epoch 0286, iter [00480, 01251], lr: 0.000276, loss: 0.3859
2022-10-03 11:38:43 - train: epoch 0286, iter [00490, 01251], lr: 0.000276, loss: 0.3972
2022-10-03 11:39:01 - train: epoch 0286, iter [00500, 01251], lr: 0.000276, loss: 0.3818
2022-10-03 11:39:19 - train: epoch 0286, iter [00510, 01251], lr: 0.000276, loss: 0.4017
2022-10-03 11:39:37 - train: epoch 0286, iter [00520, 01251], lr: 0.000276, loss: 0.3943
2022-10-03 11:39:55 - train: epoch 0286, iter [00530, 01251], lr: 0.000276, loss: 0.4238
2022-10-03 11:40:13 - train: epoch 0286, iter [00540, 01251], lr: 0.000276, loss: 0.3936
2022-10-03 11:40:31 - train: epoch 0286, iter [00550, 01251], lr: 0.000276, loss: 0.3960
2022-10-03 11:40:49 - train: epoch 0286, iter [00560, 01251], lr: 0.000276, loss: 0.3933
2022-10-03 11:41:08 - train: epoch 0286, iter [00570, 01251], lr: 0.000276, loss: 0.4128
2022-10-03 11:41:26 - train: epoch 0286, iter [00580, 01251], lr: 0.000276, loss: 0.3955
2022-10-03 11:41:44 - train: epoch 0286, iter [00590, 01251], lr: 0.000276, loss: 0.3943
2022-10-03 11:42:02 - train: epoch 0286, iter [00600, 01251], lr: 0.000276, loss: 0.3819
2022-10-03 11:42:20 - train: epoch 0286, iter [00610, 01251], lr: 0.000275, loss: 0.4060
2022-10-03 11:42:38 - train: epoch 0286, iter [00620, 01251], lr: 0.000275, loss: 0.3957
2022-10-03 11:42:56 - train: epoch 0286, iter [00630, 01251], lr: 0.000275, loss: 0.3951
2022-10-03 11:43:14 - train: epoch 0286, iter [00640, 01251], lr: 0.000275, loss: 0.4038
2022-10-03 11:43:32 - train: epoch 0286, iter [00650, 01251], lr: 0.000275, loss: 0.3786
2022-10-03 11:43:50 - train: epoch 0286, iter [00660, 01251], lr: 0.000275, loss: 0.3874
2022-10-03 11:44:08 - train: epoch 0286, iter [00670, 01251], lr: 0.000275, loss: 0.3922
2022-10-03 11:44:26 - train: epoch 0286, iter [00680, 01251], lr: 0.000275, loss: 0.4107
2022-10-03 11:44:44 - train: epoch 0286, iter [00690, 01251], lr: 0.000275, loss: 0.3990
2022-10-03 11:45:02 - train: epoch 0286, iter [00700, 01251], lr: 0.000275, loss: 0.3952
2022-10-03 11:45:20 - train: epoch 0286, iter [00710, 01251], lr: 0.000275, loss: 0.4030
2022-10-03 11:45:38 - train: epoch 0286, iter [00720, 01251], lr: 0.000275, loss: 0.3794
2022-10-03 11:45:57 - train: epoch 0286, iter [00730, 01251], lr: 0.000275, loss: 0.3892
2022-10-03 11:46:15 - train: epoch 0286, iter [00740, 01251], lr: 0.000275, loss: 0.3867
2022-10-03 11:46:33 - train: epoch 0286, iter [00750, 01251], lr: 0.000275, loss: 0.3937
2022-10-03 11:46:50 - train: epoch 0286, iter [00760, 01251], lr: 0.000275, loss: 0.4086
2022-10-03 11:47:08 - train: epoch 0286, iter [00770, 01251], lr: 0.000275, loss: 0.3814
2022-10-03 11:47:27 - train: epoch 0286, iter [00780, 01251], lr: 0.000275, loss: 0.4058
2022-10-03 11:47:44 - train: epoch 0286, iter [00790, 01251], lr: 0.000275, loss: 0.3904
2022-10-03 11:48:03 - train: epoch 0286, iter [00800, 01251], lr: 0.000275, loss: 0.4018
2022-10-03 11:48:21 - train: epoch 0286, iter [00810, 01251], lr: 0.000275, loss: 0.3876
2022-10-03 11:48:39 - train: epoch 0286, iter [00820, 01251], lr: 0.000275, loss: 0.3864
2022-10-03 11:48:57 - train: epoch 0286, iter [00830, 01251], lr: 0.000275, loss: 0.3974
2022-10-03 11:49:15 - train: epoch 0286, iter [00840, 01251], lr: 0.000275, loss: 0.3868
2022-10-03 11:49:33 - train: epoch 0286, iter [00850, 01251], lr: 0.000275, loss: 0.4276
2022-10-03 11:49:51 - train: epoch 0286, iter [00860, 01251], lr: 0.000275, loss: 0.4078
2022-10-03 11:50:09 - train: epoch 0286, iter [00870, 01251], lr: 0.000275, loss: 0.3840
2022-10-03 11:50:27 - train: epoch 0286, iter [00880, 01251], lr: 0.000275, loss: 0.3766
2022-10-03 11:50:45 - train: epoch 0286, iter [00890, 01251], lr: 0.000274, loss: 0.4142
2022-10-03 11:51:03 - train: epoch 0286, iter [00900, 01251], lr: 0.000274, loss: 0.3894
2022-10-03 11:51:21 - train: epoch 0286, iter [00910, 01251], lr: 0.000274, loss: 0.3882
2022-10-03 11:51:39 - train: epoch 0286, iter [00920, 01251], lr: 0.000274, loss: 0.3978
2022-10-03 11:51:57 - train: epoch 0286, iter [00930, 01251], lr: 0.000274, loss: 0.4155
2022-10-03 11:52:15 - train: epoch 0286, iter [00940, 01251], lr: 0.000274, loss: 0.4109
2022-10-03 11:52:33 - train: epoch 0286, iter [00950, 01251], lr: 0.000274, loss: 0.4085
2022-10-03 11:52:51 - train: epoch 0286, iter [00960, 01251], lr: 0.000274, loss: 0.3961
2022-10-03 11:53:10 - train: epoch 0286, iter [00970, 01251], lr: 0.000274, loss: 0.3796
2022-10-03 11:53:28 - train: epoch 0286, iter [00980, 01251], lr: 0.000274, loss: 0.3919
2022-10-03 11:53:46 - train: epoch 0286, iter [00990, 01251], lr: 0.000274, loss: 0.4055
2022-10-03 11:54:04 - train: epoch 0286, iter [01000, 01251], lr: 0.000274, loss: 0.3914
2022-10-03 11:54:22 - train: epoch 0286, iter [01010, 01251], lr: 0.000274, loss: 0.4089
2022-10-03 11:54:39 - train: epoch 0286, iter [01020, 01251], lr: 0.000274, loss: 0.4165
2022-10-03 11:54:57 - train: epoch 0286, iter [01030, 01251], lr: 0.000274, loss: 0.4104
2022-10-03 11:55:15 - train: epoch 0286, iter [01040, 01251], lr: 0.000274, loss: 0.4143
2022-10-03 11:55:33 - train: epoch 0286, iter [01050, 01251], lr: 0.000274, loss: 0.4092
2022-10-03 11:55:52 - train: epoch 0286, iter [01060, 01251], lr: 0.000274, loss: 0.3965
2022-10-03 11:56:10 - train: epoch 0286, iter [01070, 01251], lr: 0.000274, loss: 0.3974
2022-10-03 11:56:28 - train: epoch 0286, iter [01080, 01251], lr: 0.000274, loss: 0.3755
2022-10-03 11:56:46 - train: epoch 0286, iter [01090, 01251], lr: 0.000274, loss: 0.4075
2022-10-03 11:57:04 - train: epoch 0286, iter [01100, 01251], lr: 0.000274, loss: 0.4010
2022-10-03 11:57:22 - train: epoch 0286, iter [01110, 01251], lr: 0.000274, loss: 0.3781
2022-10-03 11:57:40 - train: epoch 0286, iter [01120, 01251], lr: 0.000274, loss: 0.3978
2022-10-03 11:57:58 - train: epoch 0286, iter [01130, 01251], lr: 0.000274, loss: 0.4190
2022-10-03 11:58:16 - train: epoch 0286, iter [01140, 01251], lr: 0.000274, loss: 0.4061
2022-10-03 11:58:34 - train: epoch 0286, iter [01150, 01251], lr: 0.000274, loss: 0.3766
2022-10-03 11:58:52 - train: epoch 0286, iter [01160, 01251], lr: 0.000274, loss: 0.3943
2022-10-03 11:59:10 - train: epoch 0286, iter [01170, 01251], lr: 0.000274, loss: 0.4119
2022-10-03 11:59:28 - train: epoch 0286, iter [01180, 01251], lr: 0.000273, loss: 0.3987
2022-10-03 11:59:46 - train: epoch 0286, iter [01190, 01251], lr: 0.000273, loss: 0.4001
2022-10-03 12:00:05 - train: epoch 0286, iter [01200, 01251], lr: 0.000273, loss: 0.3924
2022-10-03 12:00:23 - train: epoch 0286, iter [01210, 01251], lr: 0.000273, loss: 0.4098
2022-10-03 12:00:40 - train: epoch 0286, iter [01220, 01251], lr: 0.000273, loss: 0.3921
2022-10-03 12:00:58 - train: epoch 0286, iter [01230, 01251], lr: 0.000273, loss: 0.4016
2022-10-03 12:01:16 - train: epoch 0286, iter [01240, 01251], lr: 0.000273, loss: 0.3998
2022-10-03 12:01:34 - train: epoch 0286, iter [01250, 01251], lr: 0.000273, loss: 0.4027
2022-10-03 12:01:37 - train: epoch 286, train_loss: 0.3991
2022-10-03 12:01:40 - until epoch: 286, best_loss: 0.3991
2022-10-03 12:01:40 - epoch 287 lr: 0.000273
2022-10-03 12:02:06 - train: epoch 0287, iter [00010, 01251], lr: 0.000273, loss: 0.4103
2022-10-03 12:02:24 - train: epoch 0287, iter [00020, 01251], lr: 0.000273, loss: 0.3973
2022-10-03 12:02:42 - train: epoch 0287, iter [00030, 01251], lr: 0.000273, loss: 0.4125
2022-10-03 12:03:00 - train: epoch 0287, iter [00040, 01251], lr: 0.000273, loss: 0.3848
2022-10-03 12:03:18 - train: epoch 0287, iter [00050, 01251], lr: 0.000273, loss: 0.3820
2022-10-03 12:03:36 - train: epoch 0287, iter [00060, 01251], lr: 0.000273, loss: 0.4028
2022-10-03 12:03:54 - train: epoch 0287, iter [00070, 01251], lr: 0.000273, loss: 0.3877
2022-10-03 12:04:13 - train: epoch 0287, iter [00080, 01251], lr: 0.000273, loss: 0.4215
2022-10-03 12:04:31 - train: epoch 0287, iter [00090, 01251], lr: 0.000273, loss: 0.4232
2022-10-03 12:04:49 - train: epoch 0287, iter [00100, 01251], lr: 0.000273, loss: 0.3960
2022-10-03 12:05:07 - train: epoch 0287, iter [00110, 01251], lr: 0.000273, loss: 0.3836
2022-10-03 12:05:25 - train: epoch 0287, iter [00120, 01251], lr: 0.000273, loss: 0.3934
2022-10-03 12:05:43 - train: epoch 0287, iter [00130, 01251], lr: 0.000273, loss: 0.3995
2022-10-03 12:06:01 - train: epoch 0287, iter [00140, 01251], lr: 0.000273, loss: 0.4005
2022-10-03 12:06:19 - train: epoch 0287, iter [00150, 01251], lr: 0.000273, loss: 0.4064
2022-10-03 12:06:37 - train: epoch 0287, iter [00160, 01251], lr: 0.000273, loss: 0.3983
2022-10-03 12:06:55 - train: epoch 0287, iter [00170, 01251], lr: 0.000273, loss: 0.3703
2022-10-03 12:07:13 - train: epoch 0287, iter [00180, 01251], lr: 0.000273, loss: 0.4090
2022-10-03 12:07:31 - train: epoch 0287, iter [00190, 01251], lr: 0.000273, loss: 0.4003
2022-10-03 12:07:49 - train: epoch 0287, iter [00200, 01251], lr: 0.000273, loss: 0.3891
2022-10-03 12:08:08 - train: epoch 0287, iter [00210, 01251], lr: 0.000272, loss: 0.3784
2022-10-03 12:08:26 - train: epoch 0287, iter [00220, 01251], lr: 0.000272, loss: 0.4025
2022-10-03 12:08:44 - train: epoch 0287, iter [00230, 01251], lr: 0.000272, loss: 0.4173
2022-10-03 12:09:02 - train: epoch 0287, iter [00240, 01251], lr: 0.000272, loss: 0.4081
2022-10-03 12:09:20 - train: epoch 0287, iter [00250, 01251], lr: 0.000272, loss: 0.4039
2022-10-03 12:09:38 - train: epoch 0287, iter [00260, 01251], lr: 0.000272, loss: 0.4089
2022-10-03 12:09:57 - train: epoch 0287, iter [00270, 01251], lr: 0.000272, loss: 0.4252
2022-10-03 12:10:15 - train: epoch 0287, iter [00280, 01251], lr: 0.000272, loss: 0.4017
2022-10-03 12:10:33 - train: epoch 0287, iter [00290, 01251], lr: 0.000272, loss: 0.3920
2022-10-03 12:10:51 - train: epoch 0287, iter [00300, 01251], lr: 0.000272, loss: 0.4023
2022-10-03 12:11:09 - train: epoch 0287, iter [00310, 01251], lr: 0.000272, loss: 0.4027
2022-10-03 12:11:27 - train: epoch 0287, iter [00320, 01251], lr: 0.000272, loss: 0.4014
2022-10-03 12:11:45 - train: epoch 0287, iter [00330, 01251], lr: 0.000272, loss: 0.4189
2022-10-03 12:12:03 - train: epoch 0287, iter [00340, 01251], lr: 0.000272, loss: 0.3962
2022-10-03 12:12:21 - train: epoch 0287, iter [00350, 01251], lr: 0.000272, loss: 0.3873
2022-10-03 12:12:39 - train: epoch 0287, iter [00360, 01251], lr: 0.000272, loss: 0.3884
2022-10-03 12:12:57 - train: epoch 0287, iter [00370, 01251], lr: 0.000272, loss: 0.3977
2022-10-03 12:13:15 - train: epoch 0287, iter [00380, 01251], lr: 0.000272, loss: 0.3915
2022-10-03 12:13:33 - train: epoch 0287, iter [00390, 01251], lr: 0.000272, loss: 0.3975
2022-10-03 12:13:51 - train: epoch 0287, iter [00400, 01251], lr: 0.000272, loss: 0.4198
2022-10-03 12:14:09 - train: epoch 0287, iter [00410, 01251], lr: 0.000272, loss: 0.4068
2022-10-03 12:14:27 - train: epoch 0287, iter [00420, 01251], lr: 0.000272, loss: 0.3932
2022-10-03 12:14:45 - train: epoch 0287, iter [00430, 01251], lr: 0.000272, loss: 0.3876
2022-10-03 12:15:03 - train: epoch 0287, iter [00440, 01251], lr: 0.000272, loss: 0.3847
2022-10-03 12:15:22 - train: epoch 0287, iter [00450, 01251], lr: 0.000272, loss: 0.3891
2022-10-03 12:15:40 - train: epoch 0287, iter [00460, 01251], lr: 0.000272, loss: 0.3718
2022-10-03 12:15:58 - train: epoch 0287, iter [00470, 01251], lr: 0.000272, loss: 0.4154
2022-10-03 12:16:16 - train: epoch 0287, iter [00480, 01251], lr: 0.000272, loss: 0.4059
2022-10-03 12:16:34 - train: epoch 0287, iter [00490, 01251], lr: 0.000271, loss: 0.4178
2022-10-03 12:16:52 - train: epoch 0287, iter [00500, 01251], lr: 0.000271, loss: 0.3890
2022-10-03 12:17:10 - train: epoch 0287, iter [00510, 01251], lr: 0.000271, loss: 0.3955
2022-10-03 12:17:28 - train: epoch 0287, iter [00520, 01251], lr: 0.000271, loss: 0.4063
2022-10-03 12:17:46 - train: epoch 0287, iter [00530, 01251], lr: 0.000271, loss: 0.3982
2022-10-03 12:18:05 - train: epoch 0287, iter [00540, 01251], lr: 0.000271, loss: 0.3980
2022-10-03 12:18:23 - train: epoch 0287, iter [00550, 01251], lr: 0.000271, loss: 0.4012
2022-10-03 12:18:41 - train: epoch 0287, iter [00560, 01251], lr: 0.000271, loss: 0.3931
2022-10-03 12:18:59 - train: epoch 0287, iter [00570, 01251], lr: 0.000271, loss: 0.4119
2022-10-03 12:19:17 - train: epoch 0287, iter [00580, 01251], lr: 0.000271, loss: 0.4013
2022-10-03 12:19:35 - train: epoch 0287, iter [00590, 01251], lr: 0.000271, loss: 0.3890
2022-10-03 12:19:53 - train: epoch 0287, iter [00600, 01251], lr: 0.000271, loss: 0.3876
2022-10-03 12:20:12 - train: epoch 0287, iter [00610, 01251], lr: 0.000271, loss: 0.3904
2022-10-03 12:20:30 - train: epoch 0287, iter [00620, 01251], lr: 0.000271, loss: 0.4214
2022-10-03 12:20:48 - train: epoch 0287, iter [00630, 01251], lr: 0.000271, loss: 0.4036
2022-10-03 12:21:06 - train: epoch 0287, iter [00640, 01251], lr: 0.000271, loss: 0.3937
2022-10-03 12:21:24 - train: epoch 0287, iter [00650, 01251], lr: 0.000271, loss: 0.4111
2022-10-03 12:21:42 - train: epoch 0287, iter [00660, 01251], lr: 0.000271, loss: 0.3978
2022-10-03 12:22:00 - train: epoch 0287, iter [00670, 01251], lr: 0.000271, loss: 0.4174
2022-10-03 12:22:18 - train: epoch 0287, iter [00680, 01251], lr: 0.000271, loss: 0.4058
2022-10-03 12:22:36 - train: epoch 0287, iter [00690, 01251], lr: 0.000271, loss: 0.3728
2022-10-03 12:22:54 - train: epoch 0287, iter [00700, 01251], lr: 0.000271, loss: 0.4176
2022-10-03 12:23:12 - train: epoch 0287, iter [00710, 01251], lr: 0.000271, loss: 0.4019
2022-10-03 12:23:30 - train: epoch 0287, iter [00720, 01251], lr: 0.000271, loss: 0.4236
2022-10-03 12:23:48 - train: epoch 0287, iter [00730, 01251], lr: 0.000271, loss: 0.4004
2022-10-03 12:24:07 - train: epoch 0287, iter [00740, 01251], lr: 0.000271, loss: 0.3862
2022-10-03 12:24:25 - train: epoch 0287, iter [00750, 01251], lr: 0.000271, loss: 0.4059
2022-10-03 12:24:43 - train: epoch 0287, iter [00760, 01251], lr: 0.000271, loss: 0.3967
2022-10-03 12:25:01 - train: epoch 0287, iter [00770, 01251], lr: 0.000271, loss: 0.4059
2022-10-03 12:25:19 - train: epoch 0287, iter [00780, 01251], lr: 0.000270, loss: 0.4197
2022-10-03 12:25:37 - train: epoch 0287, iter [00790, 01251], lr: 0.000270, loss: 0.3911
2022-10-03 12:25:55 - train: epoch 0287, iter [00800, 01251], lr: 0.000270, loss: 0.4061
2022-10-03 12:26:13 - train: epoch 0287, iter [00810, 01251], lr: 0.000270, loss: 0.3982
2022-10-03 12:26:31 - train: epoch 0287, iter [00820, 01251], lr: 0.000270, loss: 0.4133
2022-10-03 12:26:49 - train: epoch 0287, iter [00830, 01251], lr: 0.000270, loss: 0.3968
2022-10-03 12:27:07 - train: epoch 0287, iter [00840, 01251], lr: 0.000270, loss: 0.4096
2022-10-03 12:27:25 - train: epoch 0287, iter [00850, 01251], lr: 0.000270, loss: 0.4083
2022-10-03 12:27:43 - train: epoch 0287, iter [00860, 01251], lr: 0.000270, loss: 0.4050
2022-10-03 12:28:01 - train: epoch 0287, iter [00870, 01251], lr: 0.000270, loss: 0.4080
2022-10-03 12:28:19 - train: epoch 0287, iter [00880, 01251], lr: 0.000270, loss: 0.4073
2022-10-03 12:28:38 - train: epoch 0287, iter [00890, 01251], lr: 0.000270, loss: 0.4045
2022-10-03 12:28:56 - train: epoch 0287, iter [00900, 01251], lr: 0.000270, loss: 0.3943
2022-10-03 12:29:14 - train: epoch 0287, iter [00910, 01251], lr: 0.000270, loss: 0.3951
2022-10-03 12:29:32 - train: epoch 0287, iter [00920, 01251], lr: 0.000270, loss: 0.4125
2022-10-03 12:29:50 - train: epoch 0287, iter [00930, 01251], lr: 0.000270, loss: 0.3985
2022-10-03 12:30:08 - train: epoch 0287, iter [00940, 01251], lr: 0.000270, loss: 0.4105
2022-10-03 12:30:26 - train: epoch 0287, iter [00950, 01251], lr: 0.000270, loss: 0.3935
2022-10-03 12:30:44 - train: epoch 0287, iter [00960, 01251], lr: 0.000270, loss: 0.4069
2022-10-03 12:31:02 - train: epoch 0287, iter [00970, 01251], lr: 0.000270, loss: 0.3839
2022-10-03 12:31:20 - train: epoch 0287, iter [00980, 01251], lr: 0.000270, loss: 0.3932
2022-10-03 12:31:38 - train: epoch 0287, iter [00990, 01251], lr: 0.000270, loss: 0.4019
2022-10-03 12:31:56 - train: epoch 0287, iter [01000, 01251], lr: 0.000270, loss: 0.4232
2022-10-03 12:32:14 - train: epoch 0287, iter [01010, 01251], lr: 0.000270, loss: 0.4024
2022-10-03 12:32:32 - train: epoch 0287, iter [01020, 01251], lr: 0.000270, loss: 0.4051
2022-10-03 12:32:50 - train: epoch 0287, iter [01030, 01251], lr: 0.000270, loss: 0.4156
2022-10-03 12:33:08 - train: epoch 0287, iter [01040, 01251], lr: 0.000270, loss: 0.4305
2022-10-03 12:33:26 - train: epoch 0287, iter [01050, 01251], lr: 0.000270, loss: 0.3921
2022-10-03 12:33:44 - train: epoch 0287, iter [01060, 01251], lr: 0.000270, loss: 0.4317
2022-10-03 12:34:02 - train: epoch 0287, iter [01070, 01251], lr: 0.000269, loss: 0.3878
2022-10-03 12:34:20 - train: epoch 0287, iter [01080, 01251], lr: 0.000269, loss: 0.3908
2022-10-03 12:34:38 - train: epoch 0287, iter [01090, 01251], lr: 0.000269, loss: 0.3998
2022-10-03 12:34:56 - train: epoch 0287, iter [01100, 01251], lr: 0.000269, loss: 0.3950
2022-10-03 12:35:14 - train: epoch 0287, iter [01110, 01251], lr: 0.000269, loss: 0.4016
2022-10-03 12:35:32 - train: epoch 0287, iter [01120, 01251], lr: 0.000269, loss: 0.3891
2022-10-03 12:35:50 - train: epoch 0287, iter [01130, 01251], lr: 0.000269, loss: 0.4101
2022-10-03 12:36:09 - train: epoch 0287, iter [01140, 01251], lr: 0.000269, loss: 0.4094
2022-10-03 12:36:27 - train: epoch 0287, iter [01150, 01251], lr: 0.000269, loss: 0.3885
2022-10-03 12:36:45 - train: epoch 0287, iter [01160, 01251], lr: 0.000269, loss: 0.3869
2022-10-03 12:37:03 - train: epoch 0287, iter [01170, 01251], lr: 0.000269, loss: 0.4075
2022-10-03 12:37:21 - train: epoch 0287, iter [01180, 01251], lr: 0.000269, loss: 0.4085
2022-10-03 12:37:39 - train: epoch 0287, iter [01190, 01251], lr: 0.000269, loss: 0.4027
2022-10-03 12:37:57 - train: epoch 0287, iter [01200, 01251], lr: 0.000269, loss: 0.4108
2022-10-03 12:38:15 - train: epoch 0287, iter [01210, 01251], lr: 0.000269, loss: 0.4015
2022-10-03 12:38:33 - train: epoch 0287, iter [01220, 01251], lr: 0.000269, loss: 0.4149
2022-10-03 12:38:51 - train: epoch 0287, iter [01230, 01251], lr: 0.000269, loss: 0.3919
2022-10-03 12:39:09 - train: epoch 0287, iter [01240, 01251], lr: 0.000269, loss: 0.4043
2022-10-03 12:39:27 - train: epoch 0287, iter [01250, 01251], lr: 0.000269, loss: 0.3822
2022-10-03 12:39:31 - train: epoch 287, train_loss: 0.3989
2022-10-03 12:39:33 - until epoch: 287, best_loss: 0.3989
2022-10-03 12:39:33 - epoch 288 lr: 0.000269
2022-10-03 12:39:58 - train: epoch 0288, iter [00010, 01251], lr: 0.000269, loss: 0.3950
2022-10-03 12:40:16 - train: epoch 0288, iter [00020, 01251], lr: 0.000269, loss: 0.3892
2022-10-03 12:40:34 - train: epoch 0288, iter [00030, 01251], lr: 0.000269, loss: 0.4080
2022-10-03 12:40:52 - train: epoch 0288, iter [00040, 01251], lr: 0.000269, loss: 0.3951
2022-10-03 12:41:11 - train: epoch 0288, iter [00050, 01251], lr: 0.000269, loss: 0.3921
2022-10-03 12:41:29 - train: epoch 0288, iter [00060, 01251], lr: 0.000269, loss: 0.3995
2022-10-03 12:41:47 - train: epoch 0288, iter [00070, 01251], lr: 0.000269, loss: 0.3800
2022-10-03 12:42:05 - train: epoch 0288, iter [00080, 01251], lr: 0.000269, loss: 0.3932
2022-10-03 12:42:23 - train: epoch 0288, iter [00090, 01251], lr: 0.000269, loss: 0.4008
2022-10-03 12:42:41 - train: epoch 0288, iter [00100, 01251], lr: 0.000268, loss: 0.3817
2022-10-03 12:42:59 - train: epoch 0288, iter [00110, 01251], lr: 0.000268, loss: 0.4081
2022-10-03 12:43:18 - train: epoch 0288, iter [00120, 01251], lr: 0.000268, loss: 0.4022
2022-10-03 12:43:36 - train: epoch 0288, iter [00130, 01251], lr: 0.000268, loss: 0.4027
2022-10-03 12:43:54 - train: epoch 0288, iter [00140, 01251], lr: 0.000268, loss: 0.3997
2022-10-03 12:44:12 - train: epoch 0288, iter [00150, 01251], lr: 0.000268, loss: 0.3968
2022-10-03 12:44:30 - train: epoch 0288, iter [00160, 01251], lr: 0.000268, loss: 0.4168
2022-10-03 12:44:48 - train: epoch 0288, iter [00170, 01251], lr: 0.000268, loss: 0.4201
2022-10-03 12:45:06 - train: epoch 0288, iter [00180, 01251], lr: 0.000268, loss: 0.4189
2022-10-03 12:45:24 - train: epoch 0288, iter [00190, 01251], lr: 0.000268, loss: 0.3891
2022-10-03 12:45:42 - train: epoch 0288, iter [00200, 01251], lr: 0.000268, loss: 0.4155
2022-10-03 12:46:00 - train: epoch 0288, iter [00210, 01251], lr: 0.000268, loss: 0.3979
2022-10-03 12:46:18 - train: epoch 0288, iter [00220, 01251], lr: 0.000268, loss: 0.3941
2022-10-03 12:46:36 - train: epoch 0288, iter [00230, 01251], lr: 0.000268, loss: 0.4168
2022-10-03 12:46:54 - train: epoch 0288, iter [00240, 01251], lr: 0.000268, loss: 0.3923
2022-10-03 12:47:13 - train: epoch 0288, iter [00250, 01251], lr: 0.000268, loss: 0.3850
2022-10-03 12:47:31 - train: epoch 0288, iter [00260, 01251], lr: 0.000268, loss: 0.4231
2022-10-03 12:47:49 - train: epoch 0288, iter [00270, 01251], lr: 0.000268, loss: 0.3908
2022-10-03 12:48:07 - train: epoch 0288, iter [00280, 01251], lr: 0.000268, loss: 0.3987
2022-10-03 12:48:25 - train: epoch 0288, iter [00290, 01251], lr: 0.000268, loss: 0.3898
2022-10-03 12:48:43 - train: epoch 0288, iter [00300, 01251], lr: 0.000268, loss: 0.4033
2022-10-03 12:49:01 - train: epoch 0288, iter [00310, 01251], lr: 0.000268, loss: 0.3803
2022-10-03 12:49:19 - train: epoch 0288, iter [00320, 01251], lr: 0.000268, loss: 0.3900
2022-10-03 12:49:37 - train: epoch 0288, iter [00330, 01251], lr: 0.000268, loss: 0.3957
2022-10-03 12:49:55 - train: epoch 0288, iter [00340, 01251], lr: 0.000268, loss: 0.4032
2022-10-03 12:50:13 - train: epoch 0288, iter [00350, 01251], lr: 0.000268, loss: 0.3911
2022-10-03 12:50:31 - train: epoch 0288, iter [00360, 01251], lr: 0.000268, loss: 0.4024
2022-10-03 12:50:49 - train: epoch 0288, iter [00370, 01251], lr: 0.000268, loss: 0.4078
2022-10-03 12:51:07 - train: epoch 0288, iter [00380, 01251], lr: 0.000268, loss: 0.4081
2022-10-03 12:51:25 - train: epoch 0288, iter [00390, 01251], lr: 0.000267, loss: 0.3897
2022-10-03 12:51:43 - train: epoch 0288, iter [00400, 01251], lr: 0.000267, loss: 0.3989
2022-10-03 12:52:01 - train: epoch 0288, iter [00410, 01251], lr: 0.000267, loss: 0.3953
2022-10-03 12:52:19 - train: epoch 0288, iter [00420, 01251], lr: 0.000267, loss: 0.3792
2022-10-03 12:52:37 - train: epoch 0288, iter [00430, 01251], lr: 0.000267, loss: 0.3929
2022-10-03 12:52:56 - train: epoch 0288, iter [00440, 01251], lr: 0.000267, loss: 0.4133
2022-10-03 12:53:14 - train: epoch 0288, iter [00450, 01251], lr: 0.000267, loss: 0.4067
2022-10-03 12:53:32 - train: epoch 0288, iter [00460, 01251], lr: 0.000267, loss: 0.3805
2022-10-03 12:53:50 - train: epoch 0288, iter [00470, 01251], lr: 0.000267, loss: 0.4033
2022-10-03 12:54:08 - train: epoch 0288, iter [00480, 01251], lr: 0.000267, loss: 0.4019
2022-10-03 12:54:26 - train: epoch 0288, iter [00490, 01251], lr: 0.000267, loss: 0.4078
2022-10-03 12:54:44 - train: epoch 0288, iter [00500, 01251], lr: 0.000267, loss: 0.4045
2022-10-03 12:55:02 - train: epoch 0288, iter [00510, 01251], lr: 0.000267, loss: 0.3990
2022-10-03 12:55:20 - train: epoch 0288, iter [00520, 01251], lr: 0.000267, loss: 0.4030
2022-10-03 12:55:38 - train: epoch 0288, iter [00530, 01251], lr: 0.000267, loss: 0.3932
2022-10-03 12:55:56 - train: epoch 0288, iter [00540, 01251], lr: 0.000267, loss: 0.4143
2022-10-03 12:56:14 - train: epoch 0288, iter [00550, 01251], lr: 0.000267, loss: 0.3922
2022-10-03 12:56:32 - train: epoch 0288, iter [00560, 01251], lr: 0.000267, loss: 0.3981
2022-10-03 12:56:50 - train: epoch 0288, iter [00570, 01251], lr: 0.000267, loss: 0.3971
2022-10-03 12:57:08 - train: epoch 0288, iter [00580, 01251], lr: 0.000267, loss: 0.4035
2022-10-03 12:57:26 - train: epoch 0288, iter [00590, 01251], lr: 0.000267, loss: 0.3802
2022-10-03 12:57:44 - train: epoch 0288, iter [00600, 01251], lr: 0.000267, loss: 0.3913
2022-10-03 12:58:02 - train: epoch 0288, iter [00610, 01251], lr: 0.000267, loss: 0.3987
2022-10-03 12:58:20 - train: epoch 0288, iter [00620, 01251], lr: 0.000267, loss: 0.4005
2022-10-03 12:58:38 - train: epoch 0288, iter [00630, 01251], lr: 0.000267, loss: 0.3793
2022-10-03 12:58:56 - train: epoch 0288, iter [00640, 01251], lr: 0.000267, loss: 0.4065
2022-10-03 12:59:14 - train: epoch 0288, iter [00650, 01251], lr: 0.000267, loss: 0.3920
2022-10-03 12:59:33 - train: epoch 0288, iter [00660, 01251], lr: 0.000267, loss: 0.3957
2022-10-03 12:59:51 - train: epoch 0288, iter [00670, 01251], lr: 0.000267, loss: 0.3858
2022-10-03 13:00:09 - train: epoch 0288, iter [00680, 01251], lr: 0.000266, loss: 0.3960
2022-10-03 13:00:27 - train: epoch 0288, iter [00690, 01251], lr: 0.000266, loss: 0.3906
2022-10-03 13:00:45 - train: epoch 0288, iter [00700, 01251], lr: 0.000266, loss: 0.4089
2022-10-03 13:01:03 - train: epoch 0288, iter [00710, 01251], lr: 0.000266, loss: 0.3896
2022-10-03 13:01:21 - train: epoch 0288, iter [00720, 01251], lr: 0.000266, loss: 0.4152
2022-10-03 13:01:39 - train: epoch 0288, iter [00730, 01251], lr: 0.000266, loss: 0.3971
2022-10-03 13:01:57 - train: epoch 0288, iter [00740, 01251], lr: 0.000266, loss: 0.4097
2022-10-03 13:02:15 - train: epoch 0288, iter [00750, 01251], lr: 0.000266, loss: 0.3993
2022-10-03 13:02:34 - train: epoch 0288, iter [00760, 01251], lr: 0.000266, loss: 0.3978
2022-10-03 13:02:52 - train: epoch 0288, iter [00770, 01251], lr: 0.000266, loss: 0.4071
2022-10-03 13:03:09 - train: epoch 0288, iter [00780, 01251], lr: 0.000266, loss: 0.4116
2022-10-03 13:03:27 - train: epoch 0288, iter [00790, 01251], lr: 0.000266, loss: 0.3946
2022-10-03 13:03:45 - train: epoch 0288, iter [00800, 01251], lr: 0.000266, loss: 0.4029
2022-10-03 13:04:03 - train: epoch 0288, iter [00810, 01251], lr: 0.000266, loss: 0.4093
2022-10-03 13:04:21 - train: epoch 0288, iter [00820, 01251], lr: 0.000266, loss: 0.3810
2022-10-03 13:04:40 - train: epoch 0288, iter [00830, 01251], lr: 0.000266, loss: 0.4020
2022-10-03 13:04:58 - train: epoch 0288, iter [00840, 01251], lr: 0.000266, loss: 0.4119
2022-10-03 13:05:16 - train: epoch 0288, iter [00850, 01251], lr: 0.000266, loss: 0.4217
2022-10-03 13:05:34 - train: epoch 0288, iter [00860, 01251], lr: 0.000266, loss: 0.4097
2022-10-03 13:05:52 - train: epoch 0288, iter [00870, 01251], lr: 0.000266, loss: 0.3968
2022-10-03 13:06:10 - train: epoch 0288, iter [00880, 01251], lr: 0.000266, loss: 0.4031
2022-10-03 13:06:28 - train: epoch 0288, iter [00890, 01251], lr: 0.000266, loss: 0.4000
2022-10-03 13:06:46 - train: epoch 0288, iter [00900, 01251], lr: 0.000266, loss: 0.3888
2022-10-03 13:07:04 - train: epoch 0288, iter [00910, 01251], lr: 0.000266, loss: 0.4173
2022-10-03 13:07:22 - train: epoch 0288, iter [00920, 01251], lr: 0.000266, loss: 0.3720
2022-10-03 13:07:40 - train: epoch 0288, iter [00930, 01251], lr: 0.000266, loss: 0.3772
2022-10-03 13:07:58 - train: epoch 0288, iter [00940, 01251], lr: 0.000266, loss: 0.3946
2022-10-03 13:08:16 - train: epoch 0288, iter [00950, 01251], lr: 0.000266, loss: 0.4038
2022-10-03 13:08:34 - train: epoch 0288, iter [00960, 01251], lr: 0.000265, loss: 0.4030
2022-10-03 13:08:52 - train: epoch 0288, iter [00970, 01251], lr: 0.000265, loss: 0.4111
2022-10-03 13:09:10 - train: epoch 0288, iter [00980, 01251], lr: 0.000265, loss: 0.3777
2022-10-03 13:09:28 - train: epoch 0288, iter [00990, 01251], lr: 0.000265, loss: 0.3904
2022-10-03 13:09:46 - train: epoch 0288, iter [01000, 01251], lr: 0.000265, loss: 0.4093
2022-10-03 13:10:04 - train: epoch 0288, iter [01010, 01251], lr: 0.000265, loss: 0.4062
2022-10-03 13:10:22 - train: epoch 0288, iter [01020, 01251], lr: 0.000265, loss: 0.3922
2022-10-03 13:10:40 - train: epoch 0288, iter [01030, 01251], lr: 0.000265, loss: 0.4134
2022-10-03 13:10:58 - train: epoch 0288, iter [01040, 01251], lr: 0.000265, loss: 0.4130
2022-10-03 13:11:16 - train: epoch 0288, iter [01050, 01251], lr: 0.000265, loss: 0.3846
2022-10-03 13:11:34 - train: epoch 0288, iter [01060, 01251], lr: 0.000265, loss: 0.3890
2022-10-03 13:11:52 - train: epoch 0288, iter [01070, 01251], lr: 0.000265, loss: 0.4011
2022-10-03 13:12:10 - train: epoch 0288, iter [01080, 01251], lr: 0.000265, loss: 0.3984
2022-10-03 13:12:29 - train: epoch 0288, iter [01090, 01251], lr: 0.000265, loss: 0.3859
2022-10-03 13:12:47 - train: epoch 0288, iter [01100, 01251], lr: 0.000265, loss: 0.3972
2022-10-03 13:13:05 - train: epoch 0288, iter [01110, 01251], lr: 0.000265, loss: 0.3913
2022-10-03 13:13:23 - train: epoch 0288, iter [01120, 01251], lr: 0.000265, loss: 0.3815
2022-10-03 13:13:41 - train: epoch 0288, iter [01130, 01251], lr: 0.000265, loss: 0.3915
2022-10-03 13:13:59 - train: epoch 0288, iter [01140, 01251], lr: 0.000265, loss: 0.4015
2022-10-03 13:14:17 - train: epoch 0288, iter [01150, 01251], lr: 0.000265, loss: 0.3849
2022-10-03 13:14:35 - train: epoch 0288, iter [01160, 01251], lr: 0.000265, loss: 0.3989
2022-10-03 13:14:53 - train: epoch 0288, iter [01170, 01251], lr: 0.000265, loss: 0.4140
2022-10-03 13:15:11 - train: epoch 0288, iter [01180, 01251], lr: 0.000265, loss: 0.3913
2022-10-03 13:15:29 - train: epoch 0288, iter [01190, 01251], lr: 0.000265, loss: 0.3785
2022-10-03 13:15:47 - train: epoch 0288, iter [01200, 01251], lr: 0.000265, loss: 0.4084
2022-10-03 13:16:05 - train: epoch 0288, iter [01210, 01251], lr: 0.000265, loss: 0.4057
2022-10-03 13:16:23 - train: epoch 0288, iter [01220, 01251], lr: 0.000265, loss: 0.4053
2022-10-03 13:16:41 - train: epoch 0288, iter [01230, 01251], lr: 0.000265, loss: 0.3991
2022-10-03 13:17:00 - train: epoch 0288, iter [01240, 01251], lr: 0.000265, loss: 0.4029
2022-10-03 13:17:17 - train: epoch 0288, iter [01250, 01251], lr: 0.000264, loss: 0.3936
2022-10-03 13:17:20 - train: epoch 288, train_loss: 0.3987
2022-10-03 13:17:23 - until epoch: 288, best_loss: 0.3987
2022-10-03 13:17:23 - epoch 289 lr: 0.000264
2022-10-03 13:17:49 - train: epoch 0289, iter [00010, 01251], lr: 0.000264, loss: 0.4063
2022-10-03 13:18:07 - train: epoch 0289, iter [00020, 01251], lr: 0.000264, loss: 0.3837
2022-10-03 13:18:25 - train: epoch 0289, iter [00030, 01251], lr: 0.000264, loss: 0.3830
2022-10-03 13:18:43 - train: epoch 0289, iter [00040, 01251], lr: 0.000264, loss: 0.3993
2022-10-03 13:19:01 - train: epoch 0289, iter [00050, 01251], lr: 0.000264, loss: 0.3870
2022-10-03 13:19:19 - train: epoch 0289, iter [00060, 01251], lr: 0.000264, loss: 0.3933
2022-10-03 13:19:37 - train: epoch 0289, iter [00070, 01251], lr: 0.000264, loss: 0.3887
2022-10-03 13:19:55 - train: epoch 0289, iter [00080, 01251], lr: 0.000264, loss: 0.4050
2022-10-03 13:20:13 - train: epoch 0289, iter [00090, 01251], lr: 0.000264, loss: 0.4036
2022-10-03 13:20:32 - train: epoch 0289, iter [00100, 01251], lr: 0.000264, loss: 0.4033
2022-10-03 13:20:49 - train: epoch 0289, iter [00110, 01251], lr: 0.000264, loss: 0.3952
2022-10-03 13:21:08 - train: epoch 0289, iter [00120, 01251], lr: 0.000264, loss: 0.3999
2022-10-03 13:21:25 - train: epoch 0289, iter [00130, 01251], lr: 0.000264, loss: 0.3833
2022-10-03 13:21:43 - train: epoch 0289, iter [00140, 01251], lr: 0.000264, loss: 0.4047
2022-10-03 13:22:01 - train: epoch 0289, iter [00150, 01251], lr: 0.000264, loss: 0.3872
2022-10-03 13:22:20 - train: epoch 0289, iter [00160, 01251], lr: 0.000264, loss: 0.4090
2022-10-03 13:22:38 - train: epoch 0289, iter [00170, 01251], lr: 0.000264, loss: 0.4152
2022-10-03 13:22:56 - train: epoch 0289, iter [00180, 01251], lr: 0.000264, loss: 0.4062
2022-10-03 13:23:14 - train: epoch 0289, iter [00190, 01251], lr: 0.000264, loss: 0.4018
2022-10-03 13:23:32 - train: epoch 0289, iter [00200, 01251], lr: 0.000264, loss: 0.3871
2022-10-03 13:23:50 - train: epoch 0289, iter [00210, 01251], lr: 0.000264, loss: 0.3822
2022-10-03 13:24:08 - train: epoch 0289, iter [00220, 01251], lr: 0.000264, loss: 0.4025
2022-10-03 13:24:26 - train: epoch 0289, iter [00230, 01251], lr: 0.000264, loss: 0.4002
2022-10-03 13:24:44 - train: epoch 0289, iter [00240, 01251], lr: 0.000264, loss: 0.4220
2022-10-03 13:25:02 - train: epoch 0289, iter [00250, 01251], lr: 0.000264, loss: 0.3967
2022-10-03 13:25:20 - train: epoch 0289, iter [00260, 01251], lr: 0.000264, loss: 0.3966
2022-10-03 13:25:38 - train: epoch 0289, iter [00270, 01251], lr: 0.000264, loss: 0.4010
2022-10-03 13:25:56 - train: epoch 0289, iter [00280, 01251], lr: 0.000264, loss: 0.4103
2022-10-03 13:26:14 - train: epoch 0289, iter [00290, 01251], lr: 0.000263, loss: 0.3902
2022-10-03 13:26:32 - train: epoch 0289, iter [00300, 01251], lr: 0.000263, loss: 0.3968
2022-10-03 13:26:50 - train: epoch 0289, iter [00310, 01251], lr: 0.000263, loss: 0.4142
2022-10-03 13:27:08 - train: epoch 0289, iter [00320, 01251], lr: 0.000263, loss: 0.3933
2022-10-03 13:27:26 - train: epoch 0289, iter [00330, 01251], lr: 0.000263, loss: 0.3964
2022-10-03 13:27:44 - train: epoch 0289, iter [00340, 01251], lr: 0.000263, loss: 0.3823
2022-10-03 13:28:03 - train: epoch 0289, iter [00350, 01251], lr: 0.000263, loss: 0.4141
2022-10-03 13:28:21 - train: epoch 0289, iter [00360, 01251], lr: 0.000263, loss: 0.3961
2022-10-03 13:28:39 - train: epoch 0289, iter [00370, 01251], lr: 0.000263, loss: 0.3839
2022-10-03 13:28:57 - train: epoch 0289, iter [00380, 01251], lr: 0.000263, loss: 0.3894
2022-10-03 13:29:15 - train: epoch 0289, iter [00390, 01251], lr: 0.000263, loss: 0.4032
2022-10-03 13:29:33 - train: epoch 0289, iter [00400, 01251], lr: 0.000263, loss: 0.4051
2022-10-03 13:29:51 - train: epoch 0289, iter [00410, 01251], lr: 0.000263, loss: 0.4061
2022-10-03 13:30:09 - train: epoch 0289, iter [00420, 01251], lr: 0.000263, loss: 0.4001
2022-10-03 13:30:27 - train: epoch 0289, iter [00430, 01251], lr: 0.000263, loss: 0.3882
2022-10-03 13:30:45 - train: epoch 0289, iter [00440, 01251], lr: 0.000263, loss: 0.3865
2022-10-03 13:31:03 - train: epoch 0289, iter [00450, 01251], lr: 0.000263, loss: 0.3936
2022-10-03 13:31:21 - train: epoch 0289, iter [00460, 01251], lr: 0.000263, loss: 0.4012
2022-10-03 13:31:39 - train: epoch 0289, iter [00470, 01251], lr: 0.000263, loss: 0.3928
2022-10-03 13:31:57 - train: epoch 0289, iter [00480, 01251], lr: 0.000263, loss: 0.4004
2022-10-03 13:32:16 - train: epoch 0289, iter [00490, 01251], lr: 0.000263, loss: 0.4177
2022-10-03 13:32:33 - train: epoch 0289, iter [00500, 01251], lr: 0.000263, loss: 0.4006
2022-10-03 13:32:52 - train: epoch 0289, iter [00510, 01251], lr: 0.000263, loss: 0.3853
2022-10-03 13:33:10 - train: epoch 0289, iter [00520, 01251], lr: 0.000263, loss: 0.4108
2022-10-03 13:33:28 - train: epoch 0289, iter [00530, 01251], lr: 0.000263, loss: 0.3927
2022-10-03 13:33:46 - train: epoch 0289, iter [00540, 01251], lr: 0.000263, loss: 0.4053
2022-10-03 13:34:04 - train: epoch 0289, iter [00550, 01251], lr: 0.000263, loss: 0.4033
2022-10-03 13:34:22 - train: epoch 0289, iter [00560, 01251], lr: 0.000263, loss: 0.3998
2022-10-03 13:34:40 - train: epoch 0289, iter [00570, 01251], lr: 0.000263, loss: 0.3998
2022-10-03 13:34:58 - train: epoch 0289, iter [00580, 01251], lr: 0.000262, loss: 0.4181
2022-10-03 13:35:17 - train: epoch 0289, iter [00590, 01251], lr: 0.000262, loss: 0.4257
2022-10-03 13:35:34 - train: epoch 0289, iter [00600, 01251], lr: 0.000262, loss: 0.3910
2022-10-03 13:35:52 - train: epoch 0289, iter [00610, 01251], lr: 0.000262, loss: 0.3860
2022-10-03 13:36:11 - train: epoch 0289, iter [00620, 01251], lr: 0.000262, loss: 0.4026
2022-10-03 13:36:29 - train: epoch 0289, iter [00630, 01251], lr: 0.000262, loss: 0.3955
2022-10-03 13:36:47 - train: epoch 0289, iter [00640, 01251], lr: 0.000262, loss: 0.3813
2022-10-03 13:37:05 - train: epoch 0289, iter [00650, 01251], lr: 0.000262, loss: 0.3800
2022-10-03 13:37:23 - train: epoch 0289, iter [00660, 01251], lr: 0.000262, loss: 0.3847
2022-10-03 13:37:41 - train: epoch 0289, iter [00670, 01251], lr: 0.000262, loss: 0.4028
2022-10-03 13:37:59 - train: epoch 0289, iter [00680, 01251], lr: 0.000262, loss: 0.3960
2022-10-03 13:38:17 - train: epoch 0289, iter [00690, 01251], lr: 0.000262, loss: 0.3988
2022-10-03 13:38:35 - train: epoch 0289, iter [00700, 01251], lr: 0.000262, loss: 0.4151
2022-10-03 13:38:54 - train: epoch 0289, iter [00710, 01251], lr: 0.000262, loss: 0.3913
2022-10-03 13:39:11 - train: epoch 0289, iter [00720, 01251], lr: 0.000262, loss: 0.3992
2022-10-03 13:39:30 - train: epoch 0289, iter [00730, 01251], lr: 0.000262, loss: 0.3958
2022-10-03 13:39:47 - train: epoch 0289, iter [00740, 01251], lr: 0.000262, loss: 0.3964
2022-10-03 13:40:05 - train: epoch 0289, iter [00750, 01251], lr: 0.000262, loss: 0.4037
2022-10-03 13:40:23 - train: epoch 0289, iter [00760, 01251], lr: 0.000262, loss: 0.3990
2022-10-03 13:40:41 - train: epoch 0289, iter [00770, 01251], lr: 0.000262, loss: 0.3954
2022-10-03 13:40:59 - train: epoch 0289, iter [00780, 01251], lr: 0.000262, loss: 0.3866
2022-10-03 13:41:17 - train: epoch 0289, iter [00790, 01251], lr: 0.000262, loss: 0.4133
2022-10-03 13:41:36 - train: epoch 0289, iter [00800, 01251], lr: 0.000262, loss: 0.4063
2022-10-03 13:41:54 - train: epoch 0289, iter [00810, 01251], lr: 0.000262, loss: 0.4193
2022-10-03 13:42:12 - train: epoch 0289, iter [00820, 01251], lr: 0.000262, loss: 0.4005
2022-10-03 13:42:30 - train: epoch 0289, iter [00830, 01251], lr: 0.000262, loss: 0.3992
2022-10-03 13:42:48 - train: epoch 0289, iter [00840, 01251], lr: 0.000262, loss: 0.3919
2022-10-03 13:43:06 - train: epoch 0289, iter [00850, 01251], lr: 0.000262, loss: 0.4104
2022-10-03 13:43:24 - train: epoch 0289, iter [00860, 01251], lr: 0.000262, loss: 0.4080
2022-10-03 13:43:43 - train: epoch 0289, iter [00870, 01251], lr: 0.000261, loss: 0.4015
2022-10-03 13:44:01 - train: epoch 0289, iter [00880, 01251], lr: 0.000261, loss: 0.4115
2022-10-03 13:44:19 - train: epoch 0289, iter [00890, 01251], lr: 0.000261, loss: 0.4034
2022-10-03 13:44:37 - train: epoch 0289, iter [00900, 01251], lr: 0.000261, loss: 0.4036
2022-10-03 13:44:55 - train: epoch 0289, iter [00910, 01251], lr: 0.000261, loss: 0.3751
2022-10-03 13:45:13 - train: epoch 0289, iter [00920, 01251], lr: 0.000261, loss: 0.3979
2022-10-03 13:45:31 - train: epoch 0289, iter [00930, 01251], lr: 0.000261, loss: 0.3887
2022-10-03 13:45:49 - train: epoch 0289, iter [00940, 01251], lr: 0.000261, loss: 0.4023
2022-10-03 13:46:07 - train: epoch 0289, iter [00950, 01251], lr: 0.000261, loss: 0.3992
2022-10-03 13:46:25 - train: epoch 0289, iter [00960, 01251], lr: 0.000261, loss: 0.4046
2022-10-03 13:46:43 - train: epoch 0289, iter [00970, 01251], lr: 0.000261, loss: 0.3896
2022-10-03 13:47:01 - train: epoch 0289, iter [00980, 01251], lr: 0.000261, loss: 0.3794
2022-10-03 13:47:19 - train: epoch 0289, iter [00990, 01251], lr: 0.000261, loss: 0.4033
2022-10-03 13:47:38 - train: epoch 0289, iter [01000, 01251], lr: 0.000261, loss: 0.4213
2022-10-03 13:47:56 - train: epoch 0289, iter [01010, 01251], lr: 0.000261, loss: 0.3936
2022-10-03 13:48:14 - train: epoch 0289, iter [01020, 01251], lr: 0.000261, loss: 0.4123
2022-10-03 13:48:32 - train: epoch 0289, iter [01030, 01251], lr: 0.000261, loss: 0.3826
2022-10-03 13:48:50 - train: epoch 0289, iter [01040, 01251], lr: 0.000261, loss: 0.3966
2022-10-03 13:49:08 - train: epoch 0289, iter [01050, 01251], lr: 0.000261, loss: 0.3801
2022-10-03 13:49:26 - train: epoch 0289, iter [01060, 01251], lr: 0.000261, loss: 0.3970
2022-10-03 13:49:44 - train: epoch 0289, iter [01070, 01251], lr: 0.000261, loss: 0.3886
2022-10-03 13:50:02 - train: epoch 0289, iter [01080, 01251], lr: 0.000261, loss: 0.3930
2022-10-03 13:50:20 - train: epoch 0289, iter [01090, 01251], lr: 0.000261, loss: 0.3987
2022-10-03 13:50:38 - train: epoch 0289, iter [01100, 01251], lr: 0.000261, loss: 0.3958
2022-10-03 13:50:56 - train: epoch 0289, iter [01110, 01251], lr: 0.000261, loss: 0.4159
2022-10-03 13:51:14 - train: epoch 0289, iter [01120, 01251], lr: 0.000261, loss: 0.3915
2022-10-03 13:51:32 - train: epoch 0289, iter [01130, 01251], lr: 0.000261, loss: 0.4213
2022-10-03 13:51:50 - train: epoch 0289, iter [01140, 01251], lr: 0.000261, loss: 0.4038
2022-10-03 13:52:08 - train: epoch 0289, iter [01150, 01251], lr: 0.000261, loss: 0.3961
2022-10-03 13:52:26 - train: epoch 0289, iter [01160, 01251], lr: 0.000260, loss: 0.3995
2022-10-03 13:52:44 - train: epoch 0289, iter [01170, 01251], lr: 0.000260, loss: 0.3780
2022-10-03 13:53:02 - train: epoch 0289, iter [01180, 01251], lr: 0.000260, loss: 0.3772
2022-10-03 13:53:20 - train: epoch 0289, iter [01190, 01251], lr: 0.000260, loss: 0.3997
2022-10-03 13:53:38 - train: epoch 0289, iter [01200, 01251], lr: 0.000260, loss: 0.4148
2022-10-03 13:53:56 - train: epoch 0289, iter [01210, 01251], lr: 0.000260, loss: 0.3801
2022-10-03 13:54:14 - train: epoch 0289, iter [01220, 01251], lr: 0.000260, loss: 0.4059
2022-10-03 13:54:32 - train: epoch 0289, iter [01230, 01251], lr: 0.000260, loss: 0.4087
2022-10-03 13:54:50 - train: epoch 0289, iter [01240, 01251], lr: 0.000260, loss: 0.3812
2022-10-03 13:55:08 - train: epoch 0289, iter [01250, 01251], lr: 0.000260, loss: 0.4164
2022-10-03 13:55:11 - train: epoch 289, train_loss: 0.3987
2022-10-03 13:55:14 - until epoch: 289, best_loss: 0.3987
2022-10-03 13:55:14 - epoch 290 lr: 0.000260
2022-10-03 13:55:39 - train: epoch 0290, iter [00010, 01251], lr: 0.000260, loss: 0.4076
2022-10-03 13:55:57 - train: epoch 0290, iter [00020, 01251], lr: 0.000260, loss: 0.3997
2022-10-03 13:56:15 - train: epoch 0290, iter [00030, 01251], lr: 0.000260, loss: 0.3961
2022-10-03 13:56:33 - train: epoch 0290, iter [00040, 01251], lr: 0.000260, loss: 0.4020
2022-10-03 13:56:51 - train: epoch 0290, iter [00050, 01251], lr: 0.000260, loss: 0.4196
2022-10-03 13:57:09 - train: epoch 0290, iter [00060, 01251], lr: 0.000260, loss: 0.3974
2022-10-03 13:57:27 - train: epoch 0290, iter [00070, 01251], lr: 0.000260, loss: 0.3758
2022-10-03 13:57:45 - train: epoch 0290, iter [00080, 01251], lr: 0.000260, loss: 0.4072
2022-10-03 13:58:03 - train: epoch 0290, iter [00090, 01251], lr: 0.000260, loss: 0.4178
2022-10-03 13:58:22 - train: epoch 0290, iter [00100, 01251], lr: 0.000260, loss: 0.3948
2022-10-03 13:58:40 - train: epoch 0290, iter [00110, 01251], lr: 0.000260, loss: 0.3927
2022-10-03 13:58:58 - train: epoch 0290, iter [00120, 01251], lr: 0.000260, loss: 0.3837
2022-10-03 13:59:16 - train: epoch 0290, iter [00130, 01251], lr: 0.000260, loss: 0.4014
2022-10-03 13:59:34 - train: epoch 0290, iter [00140, 01251], lr: 0.000260, loss: 0.3794
2022-10-03 13:59:52 - train: epoch 0290, iter [00150, 01251], lr: 0.000260, loss: 0.4129
2022-10-03 14:00:10 - train: epoch 0290, iter [00160, 01251], lr: 0.000260, loss: 0.4242
2022-10-03 14:00:28 - train: epoch 0290, iter [00170, 01251], lr: 0.000260, loss: 0.3897
2022-10-03 14:00:46 - train: epoch 0290, iter [00180, 01251], lr: 0.000260, loss: 0.3949
2022-10-03 14:01:04 - train: epoch 0290, iter [00190, 01251], lr: 0.000260, loss: 0.3972
2022-10-03 14:01:22 - train: epoch 0290, iter [00200, 01251], lr: 0.000259, loss: 0.3778
2022-10-03 14:01:41 - train: epoch 0290, iter [00210, 01251], lr: 0.000259, loss: 0.3905
2022-10-03 14:01:58 - train: epoch 0290, iter [00220, 01251], lr: 0.000259, loss: 0.4015
2022-10-03 14:02:16 - train: epoch 0290, iter [00230, 01251], lr: 0.000259, loss: 0.4017
2022-10-03 14:02:34 - train: epoch 0290, iter [00240, 01251], lr: 0.000259, loss: 0.3890
2022-10-03 14:02:52 - train: epoch 0290, iter [00250, 01251], lr: 0.000259, loss: 0.3931
2022-10-03 14:03:10 - train: epoch 0290, iter [00260, 01251], lr: 0.000259, loss: 0.4068
2022-10-03 14:03:29 - train: epoch 0290, iter [00270, 01251], lr: 0.000259, loss: 0.3746
2022-10-03 14:03:47 - train: epoch 0290, iter [00280, 01251], lr: 0.000259, loss: 0.4249
2022-10-03 14:04:05 - train: epoch 0290, iter [00290, 01251], lr: 0.000259, loss: 0.4083
2022-10-03 14:04:23 - train: epoch 0290, iter [00300, 01251], lr: 0.000259, loss: 0.3789
2022-10-03 14:04:41 - train: epoch 0290, iter [00310, 01251], lr: 0.000259, loss: 0.3952
2022-10-03 14:04:59 - train: epoch 0290, iter [00320, 01251], lr: 0.000259, loss: 0.4086
2022-10-03 14:05:17 - train: epoch 0290, iter [00330, 01251], lr: 0.000259, loss: 0.4134
2022-10-03 14:05:35 - train: epoch 0290, iter [00340, 01251], lr: 0.000259, loss: 0.3988
2022-10-03 14:05:53 - train: epoch 0290, iter [00350, 01251], lr: 0.000259, loss: 0.4063
2022-10-03 14:06:11 - train: epoch 0290, iter [00360, 01251], lr: 0.000259, loss: 0.4026
2022-10-03 14:06:29 - train: epoch 0290, iter [00370, 01251], lr: 0.000259, loss: 0.3988
2022-10-03 14:06:47 - train: epoch 0290, iter [00380, 01251], lr: 0.000259, loss: 0.3975
2022-10-03 14:07:05 - train: epoch 0290, iter [00390, 01251], lr: 0.000259, loss: 0.4117
2022-10-03 14:07:24 - train: epoch 0290, iter [00400, 01251], lr: 0.000259, loss: 0.4107
2022-10-03 14:07:42 - train: epoch 0290, iter [00410, 01251], lr: 0.000259, loss: 0.3903
2022-10-03 14:08:00 - train: epoch 0290, iter [00420, 01251], lr: 0.000259, loss: 0.3821
2022-10-03 14:08:18 - train: epoch 0290, iter [00430, 01251], lr: 0.000259, loss: 0.3961
2022-10-03 14:08:36 - train: epoch 0290, iter [00440, 01251], lr: 0.000259, loss: 0.4010
2022-10-03 14:08:54 - train: epoch 0290, iter [00450, 01251], lr: 0.000259, loss: 0.3930
2022-10-03 14:09:13 - train: epoch 0290, iter [00460, 01251], lr: 0.000259, loss: 0.3988
2022-10-03 14:09:31 - train: epoch 0290, iter [00470, 01251], lr: 0.000259, loss: 0.4170
2022-10-03 14:09:49 - train: epoch 0290, iter [00480, 01251], lr: 0.000259, loss: 0.3919
2022-10-03 14:10:07 - train: epoch 0290, iter [00490, 01251], lr: 0.000258, loss: 0.4155
2022-10-03 14:10:25 - train: epoch 0290, iter [00500, 01251], lr: 0.000258, loss: 0.4096
2022-10-03 14:10:43 - train: epoch 0290, iter [00510, 01251], lr: 0.000258, loss: 0.3876
2022-10-03 14:11:01 - train: epoch 0290, iter [00520, 01251], lr: 0.000258, loss: 0.3804
2022-10-03 14:11:19 - train: epoch 0290, iter [00530, 01251], lr: 0.000258, loss: 0.4182
2022-10-03 14:11:37 - train: epoch 0290, iter [00540, 01251], lr: 0.000258, loss: 0.4123
2022-10-03 14:11:55 - train: epoch 0290, iter [00550, 01251], lr: 0.000258, loss: 0.4165
2022-10-03 14:12:13 - train: epoch 0290, iter [00560, 01251], lr: 0.000258, loss: 0.4131
2022-10-03 14:12:31 - train: epoch 0290, iter [00570, 01251], lr: 0.000258, loss: 0.4075
2022-10-03 14:12:49 - train: epoch 0290, iter [00580, 01251], lr: 0.000258, loss: 0.3768
2022-10-03 14:13:07 - train: epoch 0290, iter [00590, 01251], lr: 0.000258, loss: 0.4082
2022-10-03 14:13:25 - train: epoch 0290, iter [00600, 01251], lr: 0.000258, loss: 0.4231
2022-10-03 14:13:43 - train: epoch 0290, iter [00610, 01251], lr: 0.000258, loss: 0.3815
2022-10-03 14:14:01 - train: epoch 0290, iter [00620, 01251], lr: 0.000258, loss: 0.3922
2022-10-03 14:14:20 - train: epoch 0290, iter [00630, 01251], lr: 0.000258, loss: 0.3874
2022-10-03 14:14:38 - train: epoch 0290, iter [00640, 01251], lr: 0.000258, loss: 0.3782
2022-10-03 14:14:56 - train: epoch 0290, iter [00650, 01251], lr: 0.000258, loss: 0.4176
2022-10-03 14:15:14 - train: epoch 0290, iter [00660, 01251], lr: 0.000258, loss: 0.3889
2022-10-03 14:15:32 - train: epoch 0290, iter [00670, 01251], lr: 0.000258, loss: 0.3913
2022-10-03 14:15:50 - train: epoch 0290, iter [00680, 01251], lr: 0.000258, loss: 0.3883
2022-10-03 14:16:08 - train: epoch 0290, iter [00690, 01251], lr: 0.000258, loss: 0.4130
2022-10-03 14:16:26 - train: epoch 0290, iter [00700, 01251], lr: 0.000258, loss: 0.4103
2022-10-03 14:16:45 - train: epoch 0290, iter [00710, 01251], lr: 0.000258, loss: 0.3940
2022-10-03 14:17:03 - train: epoch 0290, iter [00720, 01251], lr: 0.000258, loss: 0.4212
2022-10-03 14:17:21 - train: epoch 0290, iter [00730, 01251], lr: 0.000258, loss: 0.4079
2022-10-03 14:17:39 - train: epoch 0290, iter [00740, 01251], lr: 0.000258, loss: 0.3871
2022-10-03 14:17:57 - train: epoch 0290, iter [00750, 01251], lr: 0.000258, loss: 0.3845
2022-10-03 14:18:15 - train: epoch 0290, iter [00760, 01251], lr: 0.000258, loss: 0.4025
2022-10-03 14:18:33 - train: epoch 0290, iter [00770, 01251], lr: 0.000258, loss: 0.4092
2022-10-03 14:18:51 - train: epoch 0290, iter [00780, 01251], lr: 0.000257, loss: 0.4137
2022-10-03 14:19:09 - train: epoch 0290, iter [00790, 01251], lr: 0.000257, loss: 0.3682
2022-10-03 14:19:28 - train: epoch 0290, iter [00800, 01251], lr: 0.000257, loss: 0.3890
2022-10-03 14:19:46 - train: epoch 0290, iter [00810, 01251], lr: 0.000257, loss: 0.3843
2022-10-03 14:20:04 - train: epoch 0290, iter [00820, 01251], lr: 0.000257, loss: 0.4042
2022-10-03 14:20:22 - train: epoch 0290, iter [00830, 01251], lr: 0.000257, loss: 0.4087
2022-10-03 14:20:40 - train: epoch 0290, iter [00840, 01251], lr: 0.000257, loss: 0.3876
2022-10-03 14:20:58 - train: epoch 0290, iter [00850, 01251], lr: 0.000257, loss: 0.3979
2022-10-03 14:21:16 - train: epoch 0290, iter [00860, 01251], lr: 0.000257, loss: 0.4141
2022-10-03 14:21:34 - train: epoch 0290, iter [00870, 01251], lr: 0.000257, loss: 0.4097
2022-10-03 14:21:52 - train: epoch 0290, iter [00880, 01251], lr: 0.000257, loss: 0.4100
2022-10-03 14:22:10 - train: epoch 0290, iter [00890, 01251], lr: 0.000257, loss: 0.3903
2022-10-03 14:22:28 - train: epoch 0290, iter [00900, 01251], lr: 0.000257, loss: 0.4166
2022-10-03 14:22:46 - train: epoch 0290, iter [00910, 01251], lr: 0.000257, loss: 0.4073
2022-10-03 14:23:04 - train: epoch 0290, iter [00920, 01251], lr: 0.000257, loss: 0.3915
2022-10-03 14:23:22 - train: epoch 0290, iter [00930, 01251], lr: 0.000257, loss: 0.4067
2022-10-03 14:23:41 - train: epoch 0290, iter [00940, 01251], lr: 0.000257, loss: 0.4174
2022-10-03 14:23:59 - train: epoch 0290, iter [00950, 01251], lr: 0.000257, loss: 0.3990
2022-10-03 14:24:17 - train: epoch 0290, iter [00960, 01251], lr: 0.000257, loss: 0.4082
2022-10-03 14:24:35 - train: epoch 0290, iter [00970, 01251], lr: 0.000257, loss: 0.4147
2022-10-03 14:24:53 - train: epoch 0290, iter [00980, 01251], lr: 0.000257, loss: 0.4004
2022-10-03 14:25:11 - train: epoch 0290, iter [00990, 01251], lr: 0.000257, loss: 0.3888
2022-10-03 14:25:29 - train: epoch 0290, iter [01000, 01251], lr: 0.000257, loss: 0.4029
2022-10-03 14:25:47 - train: epoch 0290, iter [01010, 01251], lr: 0.000257, loss: 0.3993
2022-10-03 14:26:05 - train: epoch 0290, iter [01020, 01251], lr: 0.000257, loss: 0.4067
2022-10-03 14:26:22 - train: epoch 0290, iter [01030, 01251], lr: 0.000257, loss: 0.4111
2022-10-03 14:26:41 - train: epoch 0290, iter [01040, 01251], lr: 0.000257, loss: 0.4084
2022-10-03 14:26:59 - train: epoch 0290, iter [01050, 01251], lr: 0.000257, loss: 0.4171
2022-10-03 14:27:17 - train: epoch 0290, iter [01060, 01251], lr: 0.000257, loss: 0.4182
2022-10-03 14:27:35 - train: epoch 0290, iter [01070, 01251], lr: 0.000256, loss: 0.4104
2022-10-03 14:27:53 - train: epoch 0290, iter [01080, 01251], lr: 0.000256, loss: 0.4113
2022-10-03 14:28:11 - train: epoch 0290, iter [01090, 01251], lr: 0.000256, loss: 0.3776
2022-10-03 14:28:29 - train: epoch 0290, iter [01100, 01251], lr: 0.000256, loss: 0.3966
2022-10-03 14:28:47 - train: epoch 0290, iter [01110, 01251], lr: 0.000256, loss: 0.4050
2022-10-03 14:29:05 - train: epoch 0290, iter [01120, 01251], lr: 0.000256, loss: 0.4018
2022-10-03 14:29:23 - train: epoch 0290, iter [01130, 01251], lr: 0.000256, loss: 0.3936
2022-10-03 14:29:41 - train: epoch 0290, iter [01140, 01251], lr: 0.000256, loss: 0.3967
2022-10-03 14:29:59 - train: epoch 0290, iter [01150, 01251], lr: 0.000256, loss: 0.4093
2022-10-03 14:30:17 - train: epoch 0290, iter [01160, 01251], lr: 0.000256, loss: 0.3837
2022-10-03 14:30:35 - train: epoch 0290, iter [01170, 01251], lr: 0.000256, loss: 0.4078
2022-10-03 14:30:54 - train: epoch 0290, iter [01180, 01251], lr: 0.000256, loss: 0.4112
2022-10-03 14:31:12 - train: epoch 0290, iter [01190, 01251], lr: 0.000256, loss: 0.4123
2022-10-03 14:31:30 - train: epoch 0290, iter [01200, 01251], lr: 0.000256, loss: 0.4036
2022-10-03 14:31:48 - train: epoch 0290, iter [01210, 01251], lr: 0.000256, loss: 0.4183
2022-10-03 14:32:06 - train: epoch 0290, iter [01220, 01251], lr: 0.000256, loss: 0.3736
2022-10-03 14:32:24 - train: epoch 0290, iter [01230, 01251], lr: 0.000256, loss: 0.3963
2022-10-03 14:32:42 - train: epoch 0290, iter [01240, 01251], lr: 0.000256, loss: 0.4138
2022-10-03 14:33:00 - train: epoch 0290, iter [01250, 01251], lr: 0.000256, loss: 0.4052
2022-10-03 14:33:03 - train: epoch 290, train_loss: 0.3986
2022-10-03 14:33:06 - until epoch: 290, best_loss: 0.3986
2022-10-03 14:33:06 - epoch 291 lr: 0.000256
2022-10-03 14:33:31 - train: epoch 0291, iter [00010, 01251], lr: 0.000256, loss: 0.3959
2022-10-03 14:33:49 - train: epoch 0291, iter [00020, 01251], lr: 0.000256, loss: 0.3882
2022-10-03 14:34:08 - train: epoch 0291, iter [00030, 01251], lr: 0.000256, loss: 0.3870
2022-10-03 14:34:26 - train: epoch 0291, iter [00040, 01251], lr: 0.000256, loss: 0.4072
2022-10-03 14:34:44 - train: epoch 0291, iter [00050, 01251], lr: 0.000256, loss: 0.3740
2022-10-03 14:35:02 - train: epoch 0291, iter [00060, 01251], lr: 0.000256, loss: 0.4192
2022-10-03 14:35:20 - train: epoch 0291, iter [00070, 01251], lr: 0.000256, loss: 0.4073
2022-10-03 14:35:38 - train: epoch 0291, iter [00080, 01251], lr: 0.000256, loss: 0.4126
2022-10-03 14:35:56 - train: epoch 0291, iter [00090, 01251], lr: 0.000256, loss: 0.4184
2022-10-03 14:36:14 - train: epoch 0291, iter [00100, 01251], lr: 0.000256, loss: 0.4157
2022-10-03 14:36:32 - train: epoch 0291, iter [00110, 01251], lr: 0.000255, loss: 0.4160
2022-10-03 14:36:50 - train: epoch 0291, iter [00120, 01251], lr: 0.000255, loss: 0.3854
2022-10-03 14:37:09 - train: epoch 0291, iter [00130, 01251], lr: 0.000255, loss: 0.4113
2022-10-03 14:37:27 - train: epoch 0291, iter [00140, 01251], lr: 0.000255, loss: 0.4021
2022-10-03 14:37:45 - train: epoch 0291, iter [00150, 01251], lr: 0.000255, loss: 0.3897
2022-10-03 14:38:03 - train: epoch 0291, iter [00160, 01251], lr: 0.000255, loss: 0.3978
2022-10-03 14:38:21 - train: epoch 0291, iter [00170, 01251], lr: 0.000255, loss: 0.4129
2022-10-03 14:38:39 - train: epoch 0291, iter [00180, 01251], lr: 0.000255, loss: 0.3927
2022-10-03 14:38:57 - train: epoch 0291, iter [00190, 01251], lr: 0.000255, loss: 0.4047
2022-10-03 14:39:15 - train: epoch 0291, iter [00200, 01251], lr: 0.000255, loss: 0.3987
2022-10-03 14:39:33 - train: epoch 0291, iter [00210, 01251], lr: 0.000255, loss: 0.3935
2022-10-03 14:39:51 - train: epoch 0291, iter [00220, 01251], lr: 0.000255, loss: 0.4023
2022-10-03 14:40:09 - train: epoch 0291, iter [00230, 01251], lr: 0.000255, loss: 0.3873
2022-10-03 14:40:27 - train: epoch 0291, iter [00240, 01251], lr: 0.000255, loss: 0.3976
2022-10-03 14:40:45 - train: epoch 0291, iter [00250, 01251], lr: 0.000255, loss: 0.4060
2022-10-03 14:41:03 - train: epoch 0291, iter [00260, 01251], lr: 0.000255, loss: 0.4064
2022-10-03 14:41:21 - train: epoch 0291, iter [00270, 01251], lr: 0.000255, loss: 0.4043
2022-10-03 14:41:39 - train: epoch 0291, iter [00280, 01251], lr: 0.000255, loss: 0.3901
2022-10-03 14:41:57 - train: epoch 0291, iter [00290, 01251], lr: 0.000255, loss: 0.4029
2022-10-03 14:42:16 - train: epoch 0291, iter [00300, 01251], lr: 0.000255, loss: 0.4091
2022-10-03 14:42:34 - train: epoch 0291, iter [00310, 01251], lr: 0.000255, loss: 0.4017
2022-10-03 14:42:52 - train: epoch 0291, iter [00320, 01251], lr: 0.000255, loss: 0.3954
2022-10-03 14:43:10 - train: epoch 0291, iter [00330, 01251], lr: 0.000255, loss: 0.3953
2022-10-03 14:43:28 - train: epoch 0291, iter [00340, 01251], lr: 0.000255, loss: 0.3938
2022-10-03 14:43:46 - train: epoch 0291, iter [00350, 01251], lr: 0.000255, loss: 0.3986
2022-10-03 14:44:04 - train: epoch 0291, iter [00360, 01251], lr: 0.000255, loss: 0.4133
2022-10-03 14:44:22 - train: epoch 0291, iter [00370, 01251], lr: 0.000255, loss: 0.4054
2022-10-03 14:44:40 - train: epoch 0291, iter [00380, 01251], lr: 0.000255, loss: 0.4026
2022-10-03 14:44:58 - train: epoch 0291, iter [00390, 01251], lr: 0.000255, loss: 0.4037
2022-10-03 14:45:16 - train: epoch 0291, iter [00400, 01251], lr: 0.000254, loss: 0.3891
2022-10-03 14:45:34 - train: epoch 0291, iter [00410, 01251], lr: 0.000254, loss: 0.4180
2022-10-03 14:45:52 - train: epoch 0291, iter [00420, 01251], lr: 0.000254, loss: 0.4106
2022-10-03 14:46:11 - train: epoch 0291, iter [00430, 01251], lr: 0.000254, loss: 0.3859
2022-10-03 14:46:29 - train: epoch 0291, iter [00440, 01251], lr: 0.000254, loss: 0.3912
2022-10-03 14:46:47 - train: epoch 0291, iter [00450, 01251], lr: 0.000254, loss: 0.4001
2022-10-03 14:47:05 - train: epoch 0291, iter [00460, 01251], lr: 0.000254, loss: 0.3930
2022-10-03 14:47:23 - train: epoch 0291, iter [00470, 01251], lr: 0.000254, loss: 0.3878
2022-10-03 14:47:41 - train: epoch 0291, iter [00480, 01251], lr: 0.000254, loss: 0.4070
2022-10-03 14:47:59 - train: epoch 0291, iter [00490, 01251], lr: 0.000254, loss: 0.3939
2022-10-03 14:48:17 - train: epoch 0291, iter [00500, 01251], lr: 0.000254, loss: 0.4005
2022-10-03 14:48:35 - train: epoch 0291, iter [00510, 01251], lr: 0.000254, loss: 0.4121
2022-10-03 14:48:54 - train: epoch 0291, iter [00520, 01251], lr: 0.000254, loss: 0.3959
2022-10-03 14:49:12 - train: epoch 0291, iter [00530, 01251], lr: 0.000254, loss: 0.3940
2022-10-03 14:49:30 - train: epoch 0291, iter [00540, 01251], lr: 0.000254, loss: 0.3951
2022-10-03 14:49:48 - train: epoch 0291, iter [00550, 01251], lr: 0.000254, loss: 0.3917
2022-10-03 14:50:06 - train: epoch 0291, iter [00560, 01251], lr: 0.000254, loss: 0.4032
2022-10-03 14:50:24 - train: epoch 0291, iter [00570, 01251], lr: 0.000254, loss: 0.4058
2022-10-03 14:50:42 - train: epoch 0291, iter [00580, 01251], lr: 0.000254, loss: 0.3925
2022-10-03 14:51:00 - train: epoch 0291, iter [00590, 01251], lr: 0.000254, loss: 0.3713
2022-10-03 14:51:18 - train: epoch 0291, iter [00600, 01251], lr: 0.000254, loss: 0.3787
2022-10-03 14:51:36 - train: epoch 0291, iter [00610, 01251], lr: 0.000254, loss: 0.4188
2022-10-03 14:51:54 - train: epoch 0291, iter [00620, 01251], lr: 0.000254, loss: 0.4193
2022-10-03 14:52:12 - train: epoch 0291, iter [00630, 01251], lr: 0.000254, loss: 0.3827
2022-10-03 14:52:30 - train: epoch 0291, iter [00640, 01251], lr: 0.000254, loss: 0.3943
2022-10-03 14:52:49 - train: epoch 0291, iter [00650, 01251], lr: 0.000254, loss: 0.3988
2022-10-03 14:53:07 - train: epoch 0291, iter [00660, 01251], lr: 0.000254, loss: 0.3978
2022-10-03 14:53:25 - train: epoch 0291, iter [00670, 01251], lr: 0.000254, loss: 0.3909
2022-10-03 14:53:43 - train: epoch 0291, iter [00680, 01251], lr: 0.000254, loss: 0.3994
2022-10-03 14:54:01 - train: epoch 0291, iter [00690, 01251], lr: 0.000253, loss: 0.4015
2022-10-03 14:54:19 - train: epoch 0291, iter [00700, 01251], lr: 0.000253, loss: 0.3990
2022-10-03 14:54:37 - train: epoch 0291, iter [00710, 01251], lr: 0.000253, loss: 0.4087
2022-10-03 14:54:55 - train: epoch 0291, iter [00720, 01251], lr: 0.000253, loss: 0.3962
2022-10-03 14:55:14 - train: epoch 0291, iter [00730, 01251], lr: 0.000253, loss: 0.4022
2022-10-03 14:55:32 - train: epoch 0291, iter [00740, 01251], lr: 0.000253, loss: 0.3894
2022-10-03 14:55:50 - train: epoch 0291, iter [00750, 01251], lr: 0.000253, loss: 0.3750
2022-10-03 14:56:08 - train: epoch 0291, iter [00760, 01251], lr: 0.000253, loss: 0.3919
2022-10-03 14:56:26 - train: epoch 0291, iter [00770, 01251], lr: 0.000253, loss: 0.4154
2022-10-03 14:56:44 - train: epoch 0291, iter [00780, 01251], lr: 0.000253, loss: 0.3926
2022-10-03 14:57:02 - train: epoch 0291, iter [00790, 01251], lr: 0.000253, loss: 0.3819
2022-10-03 14:57:20 - train: epoch 0291, iter [00800, 01251], lr: 0.000253, loss: 0.4010
2022-10-03 14:57:39 - train: epoch 0291, iter [00810, 01251], lr: 0.000253, loss: 0.3868
2022-10-03 14:57:57 - train: epoch 0291, iter [00820, 01251], lr: 0.000253, loss: 0.3904
2022-10-03 14:58:15 - train: epoch 0291, iter [00830, 01251], lr: 0.000253, loss: 0.4245
2022-10-03 14:58:33 - train: epoch 0291, iter [00840, 01251], lr: 0.000253, loss: 0.3871
2022-10-03 14:58:51 - train: epoch 0291, iter [00850, 01251], lr: 0.000253, loss: 0.3965
2022-10-03 14:59:09 - train: epoch 0291, iter [00860, 01251], lr: 0.000253, loss: 0.4027
2022-10-03 14:59:27 - train: epoch 0291, iter [00870, 01251], lr: 0.000253, loss: 0.4072
2022-10-03 14:59:45 - train: epoch 0291, iter [00880, 01251], lr: 0.000253, loss: 0.3829
2022-10-03 15:00:03 - train: epoch 0291, iter [00890, 01251], lr: 0.000253, loss: 0.3951
2022-10-03 15:00:22 - train: epoch 0291, iter [00900, 01251], lr: 0.000253, loss: 0.3938
2022-10-03 15:00:39 - train: epoch 0291, iter [00910, 01251], lr: 0.000253, loss: 0.3952
2022-10-03 15:00:58 - train: epoch 0291, iter [00920, 01251], lr: 0.000253, loss: 0.4072
2022-10-03 15:01:16 - train: epoch 0291, iter [00930, 01251], lr: 0.000253, loss: 0.3984
2022-10-03 15:01:34 - train: epoch 0291, iter [00940, 01251], lr: 0.000253, loss: 0.3961
2022-10-03 15:01:52 - train: epoch 0291, iter [00950, 01251], lr: 0.000253, loss: 0.4119
2022-10-03 15:02:10 - train: epoch 0291, iter [00960, 01251], lr: 0.000253, loss: 0.3965
2022-10-03 15:02:28 - train: epoch 0291, iter [00970, 01251], lr: 0.000253, loss: 0.3903
2022-10-03 15:02:46 - train: epoch 0291, iter [00980, 01251], lr: 0.000253, loss: 0.3892
2022-10-03 15:03:04 - train: epoch 0291, iter [00990, 01251], lr: 0.000252, loss: 0.3940
2022-10-03 15:03:22 - train: epoch 0291, iter [01000, 01251], lr: 0.000252, loss: 0.3919
2022-10-03 15:03:40 - train: epoch 0291, iter [01010, 01251], lr: 0.000252, loss: 0.3893
2022-10-03 15:03:59 - train: epoch 0291, iter [01020, 01251], lr: 0.000252, loss: 0.4072
2022-10-03 15:04:17 - train: epoch 0291, iter [01030, 01251], lr: 0.000252, loss: 0.3804
2022-10-03 15:04:35 - train: epoch 0291, iter [01040, 01251], lr: 0.000252, loss: 0.3940
2022-10-03 15:04:53 - train: epoch 0291, iter [01050, 01251], lr: 0.000252, loss: 0.3884
2022-10-03 15:05:11 - train: epoch 0291, iter [01060, 01251], lr: 0.000252, loss: 0.4093
2022-10-03 15:05:29 - train: epoch 0291, iter [01070, 01251], lr: 0.000252, loss: 0.3990
2022-10-03 15:05:47 - train: epoch 0291, iter [01080, 01251], lr: 0.000252, loss: 0.3950
2022-10-03 15:06:05 - train: epoch 0291, iter [01090, 01251], lr: 0.000252, loss: 0.3923
2022-10-03 15:06:23 - train: epoch 0291, iter [01100, 01251], lr: 0.000252, loss: 0.4043
2022-10-03 15:06:41 - train: epoch 0291, iter [01110, 01251], lr: 0.000252, loss: 0.3857
2022-10-03 15:06:59 - train: epoch 0291, iter [01120, 01251], lr: 0.000252, loss: 0.4305
2022-10-03 15:07:17 - train: epoch 0291, iter [01130, 01251], lr: 0.000252, loss: 0.4087
2022-10-03 15:07:36 - train: epoch 0291, iter [01140, 01251], lr: 0.000252, loss: 0.3812
2022-10-03 15:07:54 - train: epoch 0291, iter [01150, 01251], lr: 0.000252, loss: 0.3894
2022-10-03 15:08:12 - train: epoch 0291, iter [01160, 01251], lr: 0.000252, loss: 0.3986
2022-10-03 15:08:30 - train: epoch 0291, iter [01170, 01251], lr: 0.000252, loss: 0.3894
2022-10-03 15:08:48 - train: epoch 0291, iter [01180, 01251], lr: 0.000252, loss: 0.4187
2022-10-03 15:09:06 - train: epoch 0291, iter [01190, 01251], lr: 0.000252, loss: 0.3882
2022-10-03 15:09:24 - train: epoch 0291, iter [01200, 01251], lr: 0.000252, loss: 0.4140
2022-10-03 15:09:42 - train: epoch 0291, iter [01210, 01251], lr: 0.000252, loss: 0.4015
2022-10-03 15:10:01 - train: epoch 0291, iter [01220, 01251], lr: 0.000252, loss: 0.3959
2022-10-03 15:10:19 - train: epoch 0291, iter [01230, 01251], lr: 0.000252, loss: 0.3851
2022-10-03 15:10:37 - train: epoch 0291, iter [01240, 01251], lr: 0.000252, loss: 0.3952
2022-10-03 15:10:54 - train: epoch 0291, iter [01250, 01251], lr: 0.000252, loss: 0.3868
2022-10-03 15:10:58 - train: epoch 291, train_loss: 0.3984
2022-10-03 15:11:00 - until epoch: 291, best_loss: 0.3984
2022-10-03 15:11:00 - epoch 292 lr: 0.000252
2022-10-03 15:11:25 - train: epoch 0292, iter [00010, 01251], lr: 0.000252, loss: 0.3826
2022-10-03 15:11:43 - train: epoch 0292, iter [00020, 01251], lr: 0.000252, loss: 0.3991
2022-10-03 15:12:01 - train: epoch 0292, iter [00030, 01251], lr: 0.000251, loss: 0.3907
2022-10-03 15:12:19 - train: epoch 0292, iter [00040, 01251], lr: 0.000251, loss: 0.3975
2022-10-03 15:12:37 - train: epoch 0292, iter [00050, 01251], lr: 0.000251, loss: 0.4190
2022-10-03 15:12:55 - train: epoch 0292, iter [00060, 01251], lr: 0.000251, loss: 0.3964
2022-10-03 15:13:13 - train: epoch 0292, iter [00070, 01251], lr: 0.000251, loss: 0.4034
2022-10-03 15:13:32 - train: epoch 0292, iter [00080, 01251], lr: 0.000251, loss: 0.4137
2022-10-03 15:13:50 - train: epoch 0292, iter [00090, 01251], lr: 0.000251, loss: 0.3942
2022-10-03 15:14:08 - train: epoch 0292, iter [00100, 01251], lr: 0.000251, loss: 0.3867
2022-10-03 15:14:26 - train: epoch 0292, iter [00110, 01251], lr: 0.000251, loss: 0.3875
2022-10-03 15:14:44 - train: epoch 0292, iter [00120, 01251], lr: 0.000251, loss: 0.3930
2022-10-03 15:15:02 - train: epoch 0292, iter [00130, 01251], lr: 0.000251, loss: 0.3930
2022-10-03 15:15:20 - train: epoch 0292, iter [00140, 01251], lr: 0.000251, loss: 0.4129
2022-10-03 15:15:38 - train: epoch 0292, iter [00150, 01251], lr: 0.000251, loss: 0.3798
2022-10-03 15:15:57 - train: epoch 0292, iter [00160, 01251], lr: 0.000251, loss: 0.3978
2022-10-03 15:16:15 - train: epoch 0292, iter [00170, 01251], lr: 0.000251, loss: 0.3888
2022-10-03 15:16:33 - train: epoch 0292, iter [00180, 01251], lr: 0.000251, loss: 0.3932
2022-10-03 15:16:51 - train: epoch 0292, iter [00190, 01251], lr: 0.000251, loss: 0.4052
2022-10-03 15:17:09 - train: epoch 0292, iter [00200, 01251], lr: 0.000251, loss: 0.3985
2022-10-03 15:17:27 - train: epoch 0292, iter [00210, 01251], lr: 0.000251, loss: 0.4015
2022-10-03 15:17:45 - train: epoch 0292, iter [00220, 01251], lr: 0.000251, loss: 0.4040
2022-10-03 15:18:03 - train: epoch 0292, iter [00230, 01251], lr: 0.000251, loss: 0.4076
2022-10-03 15:18:21 - train: epoch 0292, iter [00240, 01251], lr: 0.000251, loss: 0.4006
2022-10-03 15:18:39 - train: epoch 0292, iter [00250, 01251], lr: 0.000251, loss: 0.4004
2022-10-03 15:18:57 - train: epoch 0292, iter [00260, 01251], lr: 0.000251, loss: 0.4126
2022-10-03 15:19:16 - train: epoch 0292, iter [00270, 01251], lr: 0.000251, loss: 0.4120
2022-10-03 15:19:34 - train: epoch 0292, iter [00280, 01251], lr: 0.000251, loss: 0.4108
2022-10-03 15:19:52 - train: epoch 0292, iter [00290, 01251], lr: 0.000251, loss: 0.4113
2022-10-03 15:20:10 - train: epoch 0292, iter [00300, 01251], lr: 0.000251, loss: 0.3884
2022-10-03 15:20:28 - train: epoch 0292, iter [00310, 01251], lr: 0.000251, loss: 0.3910
2022-10-03 15:20:46 - train: epoch 0292, iter [00320, 01251], lr: 0.000250, loss: 0.4115
2022-10-03 15:21:04 - train: epoch 0292, iter [00330, 01251], lr: 0.000250, loss: 0.3676
2022-10-03 15:21:22 - train: epoch 0292, iter [00340, 01251], lr: 0.000250, loss: 0.4011
2022-10-03 15:21:40 - train: epoch 0292, iter [00350, 01251], lr: 0.000250, loss: 0.4164
2022-10-03 15:21:58 - train: epoch 0292, iter [00360, 01251], lr: 0.000250, loss: 0.4037
2022-10-03 15:22:16 - train: epoch 0292, iter [00370, 01251], lr: 0.000250, loss: 0.3913
2022-10-03 15:22:34 - train: epoch 0292, iter [00380, 01251], lr: 0.000250, loss: 0.4041
2022-10-03 15:22:53 - train: epoch 0292, iter [00390, 01251], lr: 0.000250, loss: 0.3948
2022-10-03 15:23:11 - train: epoch 0292, iter [00400, 01251], lr: 0.000250, loss: 0.4173
2022-10-03 15:23:29 - train: epoch 0292, iter [00410, 01251], lr: 0.000250, loss: 0.3954
2022-10-03 15:23:47 - train: epoch 0292, iter [00420, 01251], lr: 0.000250, loss: 0.4051
2022-10-03 15:24:05 - train: epoch 0292, iter [00430, 01251], lr: 0.000250, loss: 0.4201
2022-10-03 15:24:23 - train: epoch 0292, iter [00440, 01251], lr: 0.000250, loss: 0.4040
2022-10-03 15:24:41 - train: epoch 0292, iter [00450, 01251], lr: 0.000250, loss: 0.4005
2022-10-03 15:24:59 - train: epoch 0292, iter [00460, 01251], lr: 0.000250, loss: 0.3975
2022-10-03 15:25:17 - train: epoch 0292, iter [00470, 01251], lr: 0.000250, loss: 0.3975
2022-10-03 15:25:35 - train: epoch 0292, iter [00480, 01251], lr: 0.000250, loss: 0.3794
2022-10-03 15:25:53 - train: epoch 0292, iter [00490, 01251], lr: 0.000250, loss: 0.4054
2022-10-03 15:26:12 - train: epoch 0292, iter [00500, 01251], lr: 0.000250, loss: 0.4130
2022-10-03 15:26:30 - train: epoch 0292, iter [00510, 01251], lr: 0.000250, loss: 0.3803
2022-10-03 15:26:48 - train: epoch 0292, iter [00520, 01251], lr: 0.000250, loss: 0.4060
2022-10-03 15:27:06 - train: epoch 0292, iter [00530, 01251], lr: 0.000250, loss: 0.3871
2022-10-03 15:27:24 - train: epoch 0292, iter [00540, 01251], lr: 0.000250, loss: 0.3873
2022-10-03 15:27:42 - train: epoch 0292, iter [00550, 01251], lr: 0.000250, loss: 0.4137
2022-10-03 15:28:00 - train: epoch 0292, iter [00560, 01251], lr: 0.000250, loss: 0.3889
2022-10-03 15:28:18 - train: epoch 0292, iter [00570, 01251], lr: 0.000250, loss: 0.3949
2022-10-03 15:28:36 - train: epoch 0292, iter [00580, 01251], lr: 0.000250, loss: 0.3988
2022-10-03 15:28:54 - train: epoch 0292, iter [00590, 01251], lr: 0.000250, loss: 0.4040
2022-10-03 15:29:12 - train: epoch 0292, iter [00600, 01251], lr: 0.000250, loss: 0.3968
2022-10-03 15:29:31 - train: epoch 0292, iter [00610, 01251], lr: 0.000250, loss: 0.3956
2022-10-03 15:29:49 - train: epoch 0292, iter [00620, 01251], lr: 0.000249, loss: 0.4046
2022-10-03 15:30:07 - train: epoch 0292, iter [00630, 01251], lr: 0.000249, loss: 0.3911
2022-10-03 15:30:25 - train: epoch 0292, iter [00640, 01251], lr: 0.000249, loss: 0.3971
2022-10-03 15:30:43 - train: epoch 0292, iter [00650, 01251], lr: 0.000249, loss: 0.3855
2022-10-03 15:31:01 - train: epoch 0292, iter [00660, 01251], lr: 0.000249, loss: 0.4025
2022-10-03 15:31:19 - train: epoch 0292, iter [00670, 01251], lr: 0.000249, loss: 0.4299
2022-10-03 15:31:37 - train: epoch 0292, iter [00680, 01251], lr: 0.000249, loss: 0.4121
2022-10-03 15:31:55 - train: epoch 0292, iter [00690, 01251], lr: 0.000249, loss: 0.3812
2022-10-03 15:32:13 - train: epoch 0292, iter [00700, 01251], lr: 0.000249, loss: 0.4196
2022-10-03 15:32:31 - train: epoch 0292, iter [00710, 01251], lr: 0.000249, loss: 0.3908
2022-10-03 15:32:50 - train: epoch 0292, iter [00720, 01251], lr: 0.000249, loss: 0.3966
2022-10-03 15:33:07 - train: epoch 0292, iter [00730, 01251], lr: 0.000249, loss: 0.3830
2022-10-03 15:33:25 - train: epoch 0292, iter [00740, 01251], lr: 0.000249, loss: 0.4017
2022-10-03 15:33:44 - train: epoch 0292, iter [00750, 01251], lr: 0.000249, loss: 0.4099
2022-10-03 15:34:02 - train: epoch 0292, iter [00760, 01251], lr: 0.000249, loss: 0.3928
2022-10-03 15:34:20 - train: epoch 0292, iter [00770, 01251], lr: 0.000249, loss: 0.3893
2022-10-03 15:34:38 - train: epoch 0292, iter [00780, 01251], lr: 0.000249, loss: 0.4085
2022-10-03 15:34:56 - train: epoch 0292, iter [00790, 01251], lr: 0.000249, loss: 0.3996
2022-10-03 15:35:14 - train: epoch 0292, iter [00800, 01251], lr: 0.000249, loss: 0.4136
2022-10-03 15:35:32 - train: epoch 0292, iter [00810, 01251], lr: 0.000249, loss: 0.3896
2022-10-03 15:35:50 - train: epoch 0292, iter [00820, 01251], lr: 0.000249, loss: 0.4007
2022-10-03 15:36:08 - train: epoch 0292, iter [00830, 01251], lr: 0.000249, loss: 0.3806
2022-10-03 15:36:26 - train: epoch 0292, iter [00840, 01251], lr: 0.000249, loss: 0.3873
2022-10-03 15:36:44 - train: epoch 0292, iter [00850, 01251], lr: 0.000249, loss: 0.4020
2022-10-03 15:37:02 - train: epoch 0292, iter [00860, 01251], lr: 0.000249, loss: 0.3740
2022-10-03 15:37:21 - train: epoch 0292, iter [00870, 01251], lr: 0.000249, loss: 0.4160
2022-10-03 15:37:38 - train: epoch 0292, iter [00880, 01251], lr: 0.000249, loss: 0.3940
2022-10-03 15:37:57 - train: epoch 0292, iter [00890, 01251], lr: 0.000249, loss: 0.4035
2022-10-03 15:38:15 - train: epoch 0292, iter [00900, 01251], lr: 0.000249, loss: 0.3979
2022-10-03 15:38:33 - train: epoch 0292, iter [00910, 01251], lr: 0.000248, loss: 0.4096
2022-10-03 15:38:51 - train: epoch 0292, iter [00920, 01251], lr: 0.000248, loss: 0.4221
2022-10-03 15:39:09 - train: epoch 0292, iter [00930, 01251], lr: 0.000248, loss: 0.3995
2022-10-03 15:39:27 - train: epoch 0292, iter [00940, 01251], lr: 0.000248, loss: 0.3932
2022-10-03 15:39:45 - train: epoch 0292, iter [00950, 01251], lr: 0.000248, loss: 0.3943
2022-10-03 15:40:03 - train: epoch 0292, iter [00960, 01251], lr: 0.000248, loss: 0.3871
2022-10-03 15:40:21 - train: epoch 0292, iter [00970, 01251], lr: 0.000248, loss: 0.4018
2022-10-03 15:40:39 - train: epoch 0292, iter [00980, 01251], lr: 0.000248, loss: 0.3812
2022-10-03 15:40:57 - train: epoch 0292, iter [00990, 01251], lr: 0.000248, loss: 0.3869
2022-10-03 15:41:15 - train: epoch 0292, iter [01000, 01251], lr: 0.000248, loss: 0.3943
2022-10-03 15:41:33 - train: epoch 0292, iter [01010, 01251], lr: 0.000248, loss: 0.3832
2022-10-03 15:41:51 - train: epoch 0292, iter [01020, 01251], lr: 0.000248, loss: 0.4254
2022-10-03 15:42:09 - train: epoch 0292, iter [01030, 01251], lr: 0.000248, loss: 0.4137
2022-10-03 15:42:27 - train: epoch 0292, iter [01040, 01251], lr: 0.000248, loss: 0.3947
2022-10-03 15:42:45 - train: epoch 0292, iter [01050, 01251], lr: 0.000248, loss: 0.3946
2022-10-03 15:43:04 - train: epoch 0292, iter [01060, 01251], lr: 0.000248, loss: 0.3930
2022-10-03 15:43:22 - train: epoch 0292, iter [01070, 01251], lr: 0.000248, loss: 0.3808
2022-10-03 15:43:40 - train: epoch 0292, iter [01080, 01251], lr: 0.000248, loss: 0.4063
2022-10-03 15:43:58 - train: epoch 0292, iter [01090, 01251], lr: 0.000248, loss: 0.4013
2022-10-03 15:44:16 - train: epoch 0292, iter [01100, 01251], lr: 0.000248, loss: 0.3833
2022-10-03 15:44:34 - train: epoch 0292, iter [01110, 01251], lr: 0.000248, loss: 0.3965
2022-10-03 15:44:52 - train: epoch 0292, iter [01120, 01251], lr: 0.000248, loss: 0.4123
2022-10-03 15:45:11 - train: epoch 0292, iter [01130, 01251], lr: 0.000248, loss: 0.3905
2022-10-03 15:45:29 - train: epoch 0292, iter [01140, 01251], lr: 0.000248, loss: 0.3804
2022-10-03 15:45:47 - train: epoch 0292, iter [01150, 01251], lr: 0.000248, loss: 0.3999
2022-10-03 15:46:05 - train: epoch 0292, iter [01160, 01251], lr: 0.000248, loss: 0.4122
2022-10-03 15:46:23 - train: epoch 0292, iter [01170, 01251], lr: 0.000248, loss: 0.4125
2022-10-03 15:46:41 - train: epoch 0292, iter [01180, 01251], lr: 0.000248, loss: 0.3927
2022-10-03 15:46:59 - train: epoch 0292, iter [01190, 01251], lr: 0.000248, loss: 0.4047
2022-10-03 15:47:17 - train: epoch 0292, iter [01200, 01251], lr: 0.000248, loss: 0.3959
2022-10-03 15:47:35 - train: epoch 0292, iter [01210, 01251], lr: 0.000247, loss: 0.3710
2022-10-03 15:47:53 - train: epoch 0292, iter [01220, 01251], lr: 0.000247, loss: 0.3996
2022-10-03 15:48:11 - train: epoch 0292, iter [01230, 01251], lr: 0.000247, loss: 0.3944
2022-10-03 15:48:29 - train: epoch 0292, iter [01240, 01251], lr: 0.000247, loss: 0.4138
2022-10-03 15:48:46 - train: epoch 0292, iter [01250, 01251], lr: 0.000247, loss: 0.3951
2022-10-03 15:48:50 - train: epoch 292, train_loss: 0.3983
2022-10-03 15:48:52 - until epoch: 292, best_loss: 0.3983
2022-10-03 15:48:52 - epoch 293 lr: 0.000247
2022-10-03 15:49:18 - train: epoch 0293, iter [00010, 01251], lr: 0.000247, loss: 0.3747
2022-10-03 15:49:36 - train: epoch 0293, iter [00020, 01251], lr: 0.000247, loss: 0.3956
2022-10-03 15:49:54 - train: epoch 0293, iter [00030, 01251], lr: 0.000247, loss: 0.3883
2022-10-03 15:50:12 - train: epoch 0293, iter [00040, 01251], lr: 0.000247, loss: 0.4174
2022-10-03 15:50:30 - train: epoch 0293, iter [00050, 01251], lr: 0.000247, loss: 0.4010
2022-10-03 15:50:48 - train: epoch 0293, iter [00060, 01251], lr: 0.000247, loss: 0.3940
2022-10-03 15:51:06 - train: epoch 0293, iter [00070, 01251], lr: 0.000247, loss: 0.4112
2022-10-03 15:51:24 - train: epoch 0293, iter [00080, 01251], lr: 0.000247, loss: 0.3968
2022-10-03 15:51:42 - train: epoch 0293, iter [00090, 01251], lr: 0.000247, loss: 0.3866
2022-10-03 15:52:01 - train: epoch 0293, iter [00100, 01251], lr: 0.000247, loss: 0.4039
2022-10-03 15:52:19 - train: epoch 0293, iter [00110, 01251], lr: 0.000247, loss: 0.4025
2022-10-03 15:52:37 - train: epoch 0293, iter [00120, 01251], lr: 0.000247, loss: 0.3955
2022-10-03 15:52:55 - train: epoch 0293, iter [00130, 01251], lr: 0.000247, loss: 0.3992
2022-10-03 15:53:13 - train: epoch 0293, iter [00140, 01251], lr: 0.000247, loss: 0.4022
2022-10-03 15:53:31 - train: epoch 0293, iter [00150, 01251], lr: 0.000247, loss: 0.3882
2022-10-03 15:53:49 - train: epoch 0293, iter [00160, 01251], lr: 0.000247, loss: 0.4118
2022-10-03 15:54:07 - train: epoch 0293, iter [00170, 01251], lr: 0.000247, loss: 0.4244
2022-10-03 15:54:26 - train: epoch 0293, iter [00180, 01251], lr: 0.000247, loss: 0.3893
2022-10-03 15:54:44 - train: epoch 0293, iter [00190, 01251], lr: 0.000247, loss: 0.4019
2022-10-03 15:55:02 - train: epoch 0293, iter [00200, 01251], lr: 0.000247, loss: 0.4051
2022-10-03 15:55:20 - train: epoch 0293, iter [00210, 01251], lr: 0.000247, loss: 0.4069
2022-10-03 15:55:38 - train: epoch 0293, iter [00220, 01251], lr: 0.000247, loss: 0.4051
2022-10-03 15:55:56 - train: epoch 0293, iter [00230, 01251], lr: 0.000247, loss: 0.4030
2022-10-03 15:56:14 - train: epoch 0293, iter [00240, 01251], lr: 0.000247, loss: 0.4194
2022-10-03 15:56:32 - train: epoch 0293, iter [00250, 01251], lr: 0.000246, loss: 0.3812
2022-10-03 15:56:50 - train: epoch 0293, iter [00260, 01251], lr: 0.000246, loss: 0.3811
2022-10-03 15:57:08 - train: epoch 0293, iter [00270, 01251], lr: 0.000246, loss: 0.4124
2022-10-03 15:57:26 - train: epoch 0293, iter [00280, 01251], lr: 0.000246, loss: 0.4031
2022-10-03 15:57:44 - train: epoch 0293, iter [00290, 01251], lr: 0.000246, loss: 0.4067
2022-10-03 15:58:02 - train: epoch 0293, iter [00300, 01251], lr: 0.000246, loss: 0.3744
2022-10-03 15:58:20 - train: epoch 0293, iter [00310, 01251], lr: 0.000246, loss: 0.3881
2022-10-03 15:58:38 - train: epoch 0293, iter [00320, 01251], lr: 0.000246, loss: 0.3944
2022-10-03 15:58:56 - train: epoch 0293, iter [00330, 01251], lr: 0.000246, loss: 0.4126
2022-10-03 15:59:14 - train: epoch 0293, iter [00340, 01251], lr: 0.000246, loss: 0.4045
2022-10-03 15:59:32 - train: epoch 0293, iter [00350, 01251], lr: 0.000246, loss: 0.4059
2022-10-03 15:59:50 - train: epoch 0293, iter [00360, 01251], lr: 0.000246, loss: 0.3910
2022-10-03 16:00:08 - train: epoch 0293, iter [00370, 01251], lr: 0.000246, loss: 0.4139
2022-10-03 16:00:26 - train: epoch 0293, iter [00380, 01251], lr: 0.000246, loss: 0.3695
2022-10-03 16:00:44 - train: epoch 0293, iter [00390, 01251], lr: 0.000246, loss: 0.3998
2022-10-03 16:01:02 - train: epoch 0293, iter [00400, 01251], lr: 0.000246, loss: 0.3933
2022-10-03 16:01:20 - train: epoch 0293, iter [00410, 01251], lr: 0.000246, loss: 0.3916
2022-10-03 16:01:38 - train: epoch 0293, iter [00420, 01251], lr: 0.000246, loss: 0.4065
2022-10-03 16:01:56 - train: epoch 0293, iter [00430, 01251], lr: 0.000246, loss: 0.4080
2022-10-03 16:02:14 - train: epoch 0293, iter [00440, 01251], lr: 0.000246, loss: 0.3825
2022-10-03 16:02:33 - train: epoch 0293, iter [00450, 01251], lr: 0.000246, loss: 0.4123
2022-10-03 16:02:51 - train: epoch 0293, iter [00460, 01251], lr: 0.000246, loss: 0.4027
2022-10-03 16:03:09 - train: epoch 0293, iter [00470, 01251], lr: 0.000246, loss: 0.4109
2022-10-03 16:03:27 - train: epoch 0293, iter [00480, 01251], lr: 0.000246, loss: 0.4029
2022-10-03 16:03:45 - train: epoch 0293, iter [00490, 01251], lr: 0.000246, loss: 0.3907
2022-10-03 16:04:03 - train: epoch 0293, iter [00500, 01251], lr: 0.000246, loss: 0.3904
2022-10-03 16:04:21 - train: epoch 0293, iter [00510, 01251], lr: 0.000246, loss: 0.3995
2022-10-03 16:04:39 - train: epoch 0293, iter [00520, 01251], lr: 0.000246, loss: 0.4190
2022-10-03 16:04:57 - train: epoch 0293, iter [00530, 01251], lr: 0.000246, loss: 0.3870
2022-10-03 16:05:15 - train: epoch 0293, iter [00540, 01251], lr: 0.000246, loss: 0.4122
2022-10-03 16:05:33 - train: epoch 0293, iter [00550, 01251], lr: 0.000245, loss: 0.4083
2022-10-03 16:05:51 - train: epoch 0293, iter [00560, 01251], lr: 0.000245, loss: 0.3889
2022-10-03 16:06:09 - train: epoch 0293, iter [00570, 01251], lr: 0.000245, loss: 0.4209
2022-10-03 16:06:27 - train: epoch 0293, iter [00580, 01251], lr: 0.000245, loss: 0.3881
2022-10-03 16:06:45 - train: epoch 0293, iter [00590, 01251], lr: 0.000245, loss: 0.3773
2022-10-03 16:07:03 - train: epoch 0293, iter [00600, 01251], lr: 0.000245, loss: 0.3955
2022-10-03 16:07:22 - train: epoch 0293, iter [00610, 01251], lr: 0.000245, loss: 0.3892
2022-10-03 16:07:40 - train: epoch 0293, iter [00620, 01251], lr: 0.000245, loss: 0.4157
2022-10-03 16:07:58 - train: epoch 0293, iter [00630, 01251], lr: 0.000245, loss: 0.4103
2022-10-03 16:08:16 - train: epoch 0293, iter [00640, 01251], lr: 0.000245, loss: 0.4242
2022-10-03 16:08:34 - train: epoch 0293, iter [00650, 01251], lr: 0.000245, loss: 0.4060
2022-10-03 16:08:52 - train: epoch 0293, iter [00660, 01251], lr: 0.000245, loss: 0.3988
2022-10-03 16:09:10 - train: epoch 0293, iter [00670, 01251], lr: 0.000245, loss: 0.3978
2022-10-03 16:09:28 - train: epoch 0293, iter [00680, 01251], lr: 0.000245, loss: 0.3992
2022-10-03 16:09:46 - train: epoch 0293, iter [00690, 01251], lr: 0.000245, loss: 0.3877
2022-10-03 16:10:04 - train: epoch 0293, iter [00700, 01251], lr: 0.000245, loss: 0.4019
2022-10-03 16:10:22 - train: epoch 0293, iter [00710, 01251], lr: 0.000245, loss: 0.3983
2022-10-03 16:10:40 - train: epoch 0293, iter [00720, 01251], lr: 0.000245, loss: 0.4159
2022-10-03 16:10:59 - train: epoch 0293, iter [00730, 01251], lr: 0.000245, loss: 0.3936
2022-10-03 16:11:17 - train: epoch 0293, iter [00740, 01251], lr: 0.000245, loss: 0.3807
2022-10-03 16:11:35 - train: epoch 0293, iter [00750, 01251], lr: 0.000245, loss: 0.3973
2022-10-03 16:11:53 - train: epoch 0293, iter [00760, 01251], lr: 0.000245, loss: 0.4099
2022-10-03 16:12:11 - train: epoch 0293, iter [00770, 01251], lr: 0.000245, loss: 0.3997
2022-10-03 16:12:29 - train: epoch 0293, iter [00780, 01251], lr: 0.000245, loss: 0.4018
2022-10-03 16:12:47 - train: epoch 0293, iter [00790, 01251], lr: 0.000245, loss: 0.4008
2022-10-03 16:13:05 - train: epoch 0293, iter [00800, 01251], lr: 0.000245, loss: 0.4241
2022-10-03 16:13:23 - train: epoch 0293, iter [00810, 01251], lr: 0.000245, loss: 0.3887
2022-10-03 16:13:42 - train: epoch 0293, iter [00820, 01251], lr: 0.000245, loss: 0.4196
2022-10-03 16:14:00 - train: epoch 0293, iter [00830, 01251], lr: 0.000245, loss: 0.4003
2022-10-03 16:14:18 - train: epoch 0293, iter [00840, 01251], lr: 0.000244, loss: 0.4178
2022-10-03 16:14:36 - train: epoch 0293, iter [00850, 01251], lr: 0.000244, loss: 0.3952
2022-10-03 16:14:54 - train: epoch 0293, iter [00860, 01251], lr: 0.000244, loss: 0.3967
2022-10-03 16:15:12 - train: epoch 0293, iter [00870, 01251], lr: 0.000244, loss: 0.4075
2022-10-03 16:15:30 - train: epoch 0293, iter [00880, 01251], lr: 0.000244, loss: 0.3827
2022-10-03 16:15:48 - train: epoch 0293, iter [00890, 01251], lr: 0.000244, loss: 0.4039
2022-10-03 16:16:06 - train: epoch 0293, iter [00900, 01251], lr: 0.000244, loss: 0.3926
2022-10-03 16:16:24 - train: epoch 0293, iter [00910, 01251], lr: 0.000244, loss: 0.4118
2022-10-03 16:16:42 - train: epoch 0293, iter [00920, 01251], lr: 0.000244, loss: 0.3934
2022-10-03 16:17:00 - train: epoch 0293, iter [00930, 01251], lr: 0.000244, loss: 0.3936
2022-10-03 16:17:18 - train: epoch 0293, iter [00940, 01251], lr: 0.000244, loss: 0.3962
2022-10-03 16:17:36 - train: epoch 0293, iter [00950, 01251], lr: 0.000244, loss: 0.3814
2022-10-03 16:17:55 - train: epoch 0293, iter [00960, 01251], lr: 0.000244, loss: 0.3603
2022-10-03 16:18:12 - train: epoch 0293, iter [00970, 01251], lr: 0.000244, loss: 0.4004
2022-10-03 16:18:30 - train: epoch 0293, iter [00980, 01251], lr: 0.000244, loss: 0.3986
2022-10-03 16:18:48 - train: epoch 0293, iter [00990, 01251], lr: 0.000244, loss: 0.3831
2022-10-03 16:19:07 - train: epoch 0293, iter [01000, 01251], lr: 0.000244, loss: 0.3959
2022-10-03 16:19:25 - train: epoch 0293, iter [01010, 01251], lr: 0.000244, loss: 0.3967
2022-10-03 16:19:43 - train: epoch 0293, iter [01020, 01251], lr: 0.000244, loss: 0.3953
2022-10-03 16:20:01 - train: epoch 0293, iter [01030, 01251], lr: 0.000244, loss: 0.3914
2022-10-03 16:20:19 - train: epoch 0293, iter [01040, 01251], lr: 0.000244, loss: 0.3880
2022-10-03 16:20:37 - train: epoch 0293, iter [01050, 01251], lr: 0.000244, loss: 0.4048
2022-10-03 16:20:55 - train: epoch 0293, iter [01060, 01251], lr: 0.000244, loss: 0.3941
2022-10-03 16:21:13 - train: epoch 0293, iter [01070, 01251], lr: 0.000244, loss: 0.3935
2022-10-03 16:21:31 - train: epoch 0293, iter [01080, 01251], lr: 0.000244, loss: 0.3970
2022-10-03 16:21:49 - train: epoch 0293, iter [01090, 01251], lr: 0.000244, loss: 0.3947
2022-10-03 16:22:07 - train: epoch 0293, iter [01100, 01251], lr: 0.000244, loss: 0.3990
2022-10-03 16:22:25 - train: epoch 0293, iter [01110, 01251], lr: 0.000244, loss: 0.4010
2022-10-03 16:22:43 - train: epoch 0293, iter [01120, 01251], lr: 0.000244, loss: 0.3828
2022-10-03 16:23:01 - train: epoch 0293, iter [01130, 01251], lr: 0.000244, loss: 0.3873
2022-10-03 16:23:19 - train: epoch 0293, iter [01140, 01251], lr: 0.000243, loss: 0.4146
2022-10-03 16:23:37 - train: epoch 0293, iter [01150, 01251], lr: 0.000243, loss: 0.3929
2022-10-03 16:23:55 - train: epoch 0293, iter [01160, 01251], lr: 0.000243, loss: 0.4009
2022-10-03 16:24:13 - train: epoch 0293, iter [01170, 01251], lr: 0.000243, loss: 0.3865
2022-10-03 16:24:31 - train: epoch 0293, iter [01180, 01251], lr: 0.000243, loss: 0.3880
2022-10-03 16:24:49 - train: epoch 0293, iter [01190, 01251], lr: 0.000243, loss: 0.3948
2022-10-03 16:25:07 - train: epoch 0293, iter [01200, 01251], lr: 0.000243, loss: 0.3808
2022-10-03 16:25:25 - train: epoch 0293, iter [01210, 01251], lr: 0.000243, loss: 0.4134
2022-10-03 16:25:43 - train: epoch 0293, iter [01220, 01251], lr: 0.000243, loss: 0.4129
2022-10-03 16:26:01 - train: epoch 0293, iter [01230, 01251], lr: 0.000243, loss: 0.3989
2022-10-03 16:26:19 - train: epoch 0293, iter [01240, 01251], lr: 0.000243, loss: 0.4016
2022-10-03 16:26:37 - train: epoch 0293, iter [01250, 01251], lr: 0.000243, loss: 0.3834
2022-10-03 16:26:40 - train: epoch 293, train_loss: 0.3983
2022-10-03 16:26:43 - until epoch: 293, best_loss: 0.3983
2022-10-03 16:26:43 - epoch 294 lr: 0.000243
2022-10-03 16:27:09 - train: epoch 0294, iter [00010, 01251], lr: 0.000243, loss: 0.3952
2022-10-03 16:27:27 - train: epoch 0294, iter [00020, 01251], lr: 0.000243, loss: 0.4112
2022-10-03 16:27:45 - train: epoch 0294, iter [00030, 01251], lr: 0.000243, loss: 0.3941
2022-10-03 16:28:03 - train: epoch 0294, iter [00040, 01251], lr: 0.000243, loss: 0.3821
2022-10-03 16:28:21 - train: epoch 0294, iter [00050, 01251], lr: 0.000243, loss: 0.3960
2022-10-03 16:28:39 - train: epoch 0294, iter [00060, 01251], lr: 0.000243, loss: 0.3918
2022-10-03 16:28:57 - train: epoch 0294, iter [00070, 01251], lr: 0.000243, loss: 0.3935
2022-10-03 16:29:15 - train: epoch 0294, iter [00080, 01251], lr: 0.000243, loss: 0.3667
2022-10-03 16:29:33 - train: epoch 0294, iter [00090, 01251], lr: 0.000243, loss: 0.4027
2022-10-03 16:29:51 - train: epoch 0294, iter [00100, 01251], lr: 0.000243, loss: 0.4075
2022-10-03 16:30:09 - train: epoch 0294, iter [00110, 01251], lr: 0.000243, loss: 0.3912
2022-10-03 16:30:27 - train: epoch 0294, iter [00120, 01251], lr: 0.000243, loss: 0.4021
2022-10-03 16:30:46 - train: epoch 0294, iter [00130, 01251], lr: 0.000243, loss: 0.4139
2022-10-03 16:31:04 - train: epoch 0294, iter [00140, 01251], lr: 0.000243, loss: 0.3747
2022-10-03 16:31:22 - train: epoch 0294, iter [00150, 01251], lr: 0.000243, loss: 0.4037
2022-10-03 16:31:40 - train: epoch 0294, iter [00160, 01251], lr: 0.000243, loss: 0.4083
2022-10-03 16:31:58 - train: epoch 0294, iter [00170, 01251], lr: 0.000243, loss: 0.4051
2022-10-03 16:32:16 - train: epoch 0294, iter [00180, 01251], lr: 0.000243, loss: 0.4168
2022-10-03 16:32:34 - train: epoch 0294, iter [00190, 01251], lr: 0.000242, loss: 0.4003
2022-10-03 16:32:52 - train: epoch 0294, iter [00200, 01251], lr: 0.000242, loss: 0.4000
2022-10-03 16:33:10 - train: epoch 0294, iter [00210, 01251], lr: 0.000242, loss: 0.3932
2022-10-03 16:33:28 - train: epoch 0294, iter [00220, 01251], lr: 0.000242, loss: 0.4061
2022-10-03 16:33:46 - train: epoch 0294, iter [00230, 01251], lr: 0.000242, loss: 0.3897
2022-10-03 16:34:04 - train: epoch 0294, iter [00240, 01251], lr: 0.000242, loss: 0.3905
2022-10-03 16:34:22 - train: epoch 0294, iter [00250, 01251], lr: 0.000242, loss: 0.3905
2022-10-03 16:34:40 - train: epoch 0294, iter [00260, 01251], lr: 0.000242, loss: 0.4165
2022-10-03 16:34:58 - train: epoch 0294, iter [00270, 01251], lr: 0.000242, loss: 0.4028
2022-10-03 16:35:16 - train: epoch 0294, iter [00280, 01251], lr: 0.000242, loss: 0.3912
2022-10-03 16:35:34 - train: epoch 0294, iter [00290, 01251], lr: 0.000242, loss: 0.4069
2022-10-03 16:35:52 - train: epoch 0294, iter [00300, 01251], lr: 0.000242, loss: 0.4094
2022-10-03 16:36:10 - train: epoch 0294, iter [00310, 01251], lr: 0.000242, loss: 0.3906
2022-10-03 16:36:28 - train: epoch 0294, iter [00320, 01251], lr: 0.000242, loss: 0.3924
2022-10-03 16:36:46 - train: epoch 0294, iter [00330, 01251], lr: 0.000242, loss: 0.3900
2022-10-03 16:37:04 - train: epoch 0294, iter [00340, 01251], lr: 0.000242, loss: 0.3795
2022-10-03 16:37:22 - train: epoch 0294, iter [00350, 01251], lr: 0.000242, loss: 0.3734
2022-10-03 16:37:40 - train: epoch 0294, iter [00360, 01251], lr: 0.000242, loss: 0.4087
2022-10-03 16:37:58 - train: epoch 0294, iter [00370, 01251], lr: 0.000242, loss: 0.3956
2022-10-03 16:38:16 - train: epoch 0294, iter [00380, 01251], lr: 0.000242, loss: 0.3863
2022-10-03 16:38:34 - train: epoch 0294, iter [00390, 01251], lr: 0.000242, loss: 0.3882
2022-10-03 16:38:52 - train: epoch 0294, iter [00400, 01251], lr: 0.000242, loss: 0.3948
2022-10-03 16:39:10 - train: epoch 0294, iter [00410, 01251], lr: 0.000242, loss: 0.4021
2022-10-03 16:39:28 - train: epoch 0294, iter [00420, 01251], lr: 0.000242, loss: 0.4049
2022-10-03 16:39:47 - train: epoch 0294, iter [00430, 01251], lr: 0.000242, loss: 0.3833
2022-10-03 16:40:05 - train: epoch 0294, iter [00440, 01251], lr: 0.000242, loss: 0.3831
2022-10-03 16:40:23 - train: epoch 0294, iter [00450, 01251], lr: 0.000242, loss: 0.4116
2022-10-03 16:40:41 - train: epoch 0294, iter [00460, 01251], lr: 0.000242, loss: 0.3956
2022-10-03 16:40:59 - train: epoch 0294, iter [00470, 01251], lr: 0.000242, loss: 0.3985
2022-10-03 16:41:17 - train: epoch 0294, iter [00480, 01251], lr: 0.000241, loss: 0.4056
2022-10-03 16:41:35 - train: epoch 0294, iter [00490, 01251], lr: 0.000241, loss: 0.4184
2022-10-03 16:41:53 - train: epoch 0294, iter [00500, 01251], lr: 0.000241, loss: 0.3925
2022-10-03 16:42:11 - train: epoch 0294, iter [00510, 01251], lr: 0.000241, loss: 0.4068
2022-10-03 16:42:29 - train: epoch 0294, iter [00520, 01251], lr: 0.000241, loss: 0.3994
2022-10-03 16:42:47 - train: epoch 0294, iter [00530, 01251], lr: 0.000241, loss: 0.3899
2022-10-03 16:43:05 - train: epoch 0294, iter [00540, 01251], lr: 0.000241, loss: 0.3956
2022-10-03 16:43:24 - train: epoch 0294, iter [00550, 01251], lr: 0.000241, loss: 0.3899
2022-10-03 16:43:42 - train: epoch 0294, iter [00560, 01251], lr: 0.000241, loss: 0.3825
2022-10-03 16:44:00 - train: epoch 0294, iter [00570, 01251], lr: 0.000241, loss: 0.4054
2022-10-03 16:44:18 - train: epoch 0294, iter [00580, 01251], lr: 0.000241, loss: 0.4077
2022-10-03 16:44:36 - train: epoch 0294, iter [00590, 01251], lr: 0.000241, loss: 0.3874
2022-10-03 16:44:54 - train: epoch 0294, iter [00600, 01251], lr: 0.000241, loss: 0.4040
2022-10-03 16:45:12 - train: epoch 0294, iter [00610, 01251], lr: 0.000241, loss: 0.4130
2022-10-03 16:45:30 - train: epoch 0294, iter [00620, 01251], lr: 0.000241, loss: 0.3966
2022-10-03 16:45:48 - train: epoch 0294, iter [00630, 01251], lr: 0.000241, loss: 0.3820
2022-10-03 16:46:06 - train: epoch 0294, iter [00640, 01251], lr: 0.000241, loss: 0.3998
2022-10-03 16:46:24 - train: epoch 0294, iter [00650, 01251], lr: 0.000241, loss: 0.4106
2022-10-03 16:46:43 - train: epoch 0294, iter [00660, 01251], lr: 0.000241, loss: 0.3926
2022-10-03 16:47:01 - train: epoch 0294, iter [00670, 01251], lr: 0.000241, loss: 0.4147
2022-10-03 16:47:19 - train: epoch 0294, iter [00680, 01251], lr: 0.000241, loss: 0.3807
2022-10-03 16:47:37 - train: epoch 0294, iter [00690, 01251], lr: 0.000241, loss: 0.4003
2022-10-03 16:47:55 - train: epoch 0294, iter [00700, 01251], lr: 0.000241, loss: 0.4067
2022-10-03 16:48:13 - train: epoch 0294, iter [00710, 01251], lr: 0.000241, loss: 0.3962
2022-10-03 16:48:31 - train: epoch 0294, iter [00720, 01251], lr: 0.000241, loss: 0.3953
2022-10-03 16:48:49 - train: epoch 0294, iter [00730, 01251], lr: 0.000241, loss: 0.3962
2022-10-03 16:49:07 - train: epoch 0294, iter [00740, 01251], lr: 0.000241, loss: 0.3984
2022-10-03 16:49:25 - train: epoch 0294, iter [00750, 01251], lr: 0.000241, loss: 0.3890
2022-10-03 16:49:43 - train: epoch 0294, iter [00760, 01251], lr: 0.000241, loss: 0.3951
2022-10-03 16:50:01 - train: epoch 0294, iter [00770, 01251], lr: 0.000241, loss: 0.3755
2022-10-03 16:50:19 - train: epoch 0294, iter [00780, 01251], lr: 0.000240, loss: 0.4077
2022-10-03 16:50:37 - train: epoch 0294, iter [00790, 01251], lr: 0.000240, loss: 0.3935
2022-10-03 16:50:55 - train: epoch 0294, iter [00800, 01251], lr: 0.000240, loss: 0.3895
2022-10-03 16:51:13 - train: epoch 0294, iter [00810, 01251], lr: 0.000240, loss: 0.3930
2022-10-03 16:51:31 - train: epoch 0294, iter [00820, 01251], lr: 0.000240, loss: 0.3929
2022-10-03 16:51:49 - train: epoch 0294, iter [00830, 01251], lr: 0.000240, loss: 0.3939
2022-10-03 16:52:07 - train: epoch 0294, iter [00840, 01251], lr: 0.000240, loss: 0.3974
2022-10-03 16:52:25 - train: epoch 0294, iter [00850, 01251], lr: 0.000240, loss: 0.3836
2022-10-03 16:52:44 - train: epoch 0294, iter [00860, 01251], lr: 0.000240, loss: 0.3853
2022-10-03 16:53:02 - train: epoch 0294, iter [00870, 01251], lr: 0.000240, loss: 0.3970
2022-10-03 16:53:20 - train: epoch 0294, iter [00880, 01251], lr: 0.000240, loss: 0.4048
2022-10-03 16:53:38 - train: epoch 0294, iter [00890, 01251], lr: 0.000240, loss: 0.3966
2022-10-03 16:53:56 - train: epoch 0294, iter [00900, 01251], lr: 0.000240, loss: 0.3925
2022-10-03 16:54:14 - train: epoch 0294, iter [00910, 01251], lr: 0.000240, loss: 0.4208
2022-10-03 16:54:32 - train: epoch 0294, iter [00920, 01251], lr: 0.000240, loss: 0.4100
2022-10-03 16:54:50 - train: epoch 0294, iter [00930, 01251], lr: 0.000240, loss: 0.3918
2022-10-03 16:55:08 - train: epoch 0294, iter [00940, 01251], lr: 0.000240, loss: 0.4006
2022-10-03 16:55:26 - train: epoch 0294, iter [00950, 01251], lr: 0.000240, loss: 0.3874
2022-10-03 16:55:44 - train: epoch 0294, iter [00960, 01251], lr: 0.000240, loss: 0.4025
2022-10-03 16:56:03 - train: epoch 0294, iter [00970, 01251], lr: 0.000240, loss: 0.4002
2022-10-03 16:56:21 - train: epoch 0294, iter [00980, 01251], lr: 0.000240, loss: 0.4084
2022-10-03 16:56:39 - train: epoch 0294, iter [00990, 01251], lr: 0.000240, loss: 0.4074
2022-10-03 16:56:57 - train: epoch 0294, iter [01000, 01251], lr: 0.000240, loss: 0.4045
2022-10-03 16:57:15 - train: epoch 0294, iter [01010, 01251], lr: 0.000240, loss: 0.3951
2022-10-03 16:57:33 - train: epoch 0294, iter [01020, 01251], lr: 0.000240, loss: 0.3956
2022-10-03 16:57:51 - train: epoch 0294, iter [01030, 01251], lr: 0.000240, loss: 0.4327
2022-10-03 16:58:09 - train: epoch 0294, iter [01040, 01251], lr: 0.000240, loss: 0.4043
2022-10-03 16:58:27 - train: epoch 0294, iter [01050, 01251], lr: 0.000240, loss: 0.3886
2022-10-03 16:58:45 - train: epoch 0294, iter [01060, 01251], lr: 0.000240, loss: 0.4195
2022-10-03 16:59:03 - train: epoch 0294, iter [01070, 01251], lr: 0.000240, loss: 0.4051
2022-10-03 16:59:22 - train: epoch 0294, iter [01080, 01251], lr: 0.000239, loss: 0.4063
2022-10-03 16:59:39 - train: epoch 0294, iter [01090, 01251], lr: 0.000239, loss: 0.4128
2022-10-03 16:59:57 - train: epoch 0294, iter [01100, 01251], lr: 0.000239, loss: 0.3866
2022-10-03 17:00:15 - train: epoch 0294, iter [01110, 01251], lr: 0.000239, loss: 0.3852
2022-10-03 17:00:33 - train: epoch 0294, iter [01120, 01251], lr: 0.000239, loss: 0.4030
2022-10-03 17:00:52 - train: epoch 0294, iter [01130, 01251], lr: 0.000239, loss: 0.4040
2022-10-03 17:01:10 - train: epoch 0294, iter [01140, 01251], lr: 0.000239, loss: 0.4039
2022-10-03 17:01:28 - train: epoch 0294, iter [01150, 01251], lr: 0.000239, loss: 0.4089
2022-10-03 17:01:46 - train: epoch 0294, iter [01160, 01251], lr: 0.000239, loss: 0.4049
2022-10-03 17:02:04 - train: epoch 0294, iter [01170, 01251], lr: 0.000239, loss: 0.3925
2022-10-03 17:02:22 - train: epoch 0294, iter [01180, 01251], lr: 0.000239, loss: 0.3828
2022-10-03 17:02:40 - train: epoch 0294, iter [01190, 01251], lr: 0.000239, loss: 0.4004
2022-10-03 17:02:58 - train: epoch 0294, iter [01200, 01251], lr: 0.000239, loss: 0.3868
2022-10-03 17:03:16 - train: epoch 0294, iter [01210, 01251], lr: 0.000239, loss: 0.3836
2022-10-03 17:03:34 - train: epoch 0294, iter [01220, 01251], lr: 0.000239, loss: 0.3869
2022-10-03 17:03:52 - train: epoch 0294, iter [01230, 01251], lr: 0.000239, loss: 0.3909
2022-10-03 17:04:10 - train: epoch 0294, iter [01240, 01251], lr: 0.000239, loss: 0.4048
2022-10-03 17:04:28 - train: epoch 0294, iter [01250, 01251], lr: 0.000239, loss: 0.3997
2022-10-03 17:04:32 - train: epoch 294, train_loss: 0.3980
2022-10-03 17:04:34 - until epoch: 294, best_loss: 0.3980
2022-10-03 17:04:34 - epoch 295 lr: 0.000239
2022-10-03 17:04:59 - train: epoch 0295, iter [00010, 01251], lr: 0.000239, loss: 0.4001
2022-10-03 17:05:17 - train: epoch 0295, iter [00020, 01251], lr: 0.000239, loss: 0.3965
2022-10-03 17:05:35 - train: epoch 0295, iter [00030, 01251], lr: 0.000239, loss: 0.3969
2022-10-03 17:05:54 - train: epoch 0295, iter [00040, 01251], lr: 0.000239, loss: 0.4089
2022-10-03 17:06:12 - train: epoch 0295, iter [00050, 01251], lr: 0.000239, loss: 0.3987
2022-10-03 17:06:30 - train: epoch 0295, iter [00060, 01251], lr: 0.000239, loss: 0.3879
2022-10-03 17:06:48 - train: epoch 0295, iter [00070, 01251], lr: 0.000239, loss: 0.3907
2022-10-03 17:07:06 - train: epoch 0295, iter [00080, 01251], lr: 0.000239, loss: 0.4138
2022-10-03 17:07:24 - train: epoch 0295, iter [00090, 01251], lr: 0.000239, loss: 0.4025
2022-10-03 17:07:42 - train: epoch 0295, iter [00100, 01251], lr: 0.000239, loss: 0.3930
2022-10-03 17:08:00 - train: epoch 0295, iter [00110, 01251], lr: 0.000239, loss: 0.4012
2022-10-03 17:08:18 - train: epoch 0295, iter [00120, 01251], lr: 0.000239, loss: 0.3924
2022-10-03 17:08:36 - train: epoch 0295, iter [00130, 01251], lr: 0.000238, loss: 0.3898
2022-10-03 17:08:54 - train: epoch 0295, iter [00140, 01251], lr: 0.000238, loss: 0.3779
2022-10-03 17:09:12 - train: epoch 0295, iter [00150, 01251], lr: 0.000238, loss: 0.3864
2022-10-03 17:09:30 - train: epoch 0295, iter [00160, 01251], lr: 0.000238, loss: 0.3955
2022-10-03 17:09:48 - train: epoch 0295, iter [00170, 01251], lr: 0.000238, loss: 0.4036
2022-10-03 17:10:06 - train: epoch 0295, iter [00180, 01251], lr: 0.000238, loss: 0.3959
2022-10-03 17:10:25 - train: epoch 0295, iter [00190, 01251], lr: 0.000238, loss: 0.3826
2022-10-03 17:10:43 - train: epoch 0295, iter [00200, 01251], lr: 0.000238, loss: 0.4099
2022-10-03 17:11:01 - train: epoch 0295, iter [00210, 01251], lr: 0.000238, loss: 0.4132
2022-10-03 17:11:19 - train: epoch 0295, iter [00220, 01251], lr: 0.000238, loss: 0.3913
2022-10-03 17:11:37 - train: epoch 0295, iter [00230, 01251], lr: 0.000238, loss: 0.3742
2022-10-03 17:11:55 - train: epoch 0295, iter [00240, 01251], lr: 0.000238, loss: 0.3987
2022-10-03 17:12:13 - train: epoch 0295, iter [00250, 01251], lr: 0.000238, loss: 0.4019
2022-10-03 17:12:31 - train: epoch 0295, iter [00260, 01251], lr: 0.000238, loss: 0.4025
2022-10-03 17:12:49 - train: epoch 0295, iter [00270, 01251], lr: 0.000238, loss: 0.4043
2022-10-03 17:13:07 - train: epoch 0295, iter [00280, 01251], lr: 0.000238, loss: 0.3889
2022-10-03 17:13:26 - train: epoch 0295, iter [00290, 01251], lr: 0.000238, loss: 0.3763
2022-10-03 17:13:44 - train: epoch 0295, iter [00300, 01251], lr: 0.000238, loss: 0.3996
2022-10-03 17:14:02 - train: epoch 0295, iter [00310, 01251], lr: 0.000238, loss: 0.4006
2022-10-03 17:14:20 - train: epoch 0295, iter [00320, 01251], lr: 0.000238, loss: 0.3957
2022-10-03 17:14:38 - train: epoch 0295, iter [00330, 01251], lr: 0.000238, loss: 0.3767
2022-10-03 17:14:56 - train: epoch 0295, iter [00340, 01251], lr: 0.000238, loss: 0.3997
2022-10-03 17:15:14 - train: epoch 0295, iter [00350, 01251], lr: 0.000238, loss: 0.4334
2022-10-03 17:15:32 - train: epoch 0295, iter [00360, 01251], lr: 0.000238, loss: 0.4006
2022-10-03 17:15:50 - train: epoch 0295, iter [00370, 01251], lr: 0.000238, loss: 0.4212
2022-10-03 17:16:08 - train: epoch 0295, iter [00380, 01251], lr: 0.000238, loss: 0.3991
2022-10-03 17:16:27 - train: epoch 0295, iter [00390, 01251], lr: 0.000238, loss: 0.3961
2022-10-03 17:16:45 - train: epoch 0295, iter [00400, 01251], lr: 0.000238, loss: 0.3974
2022-10-03 17:17:03 - train: epoch 0295, iter [00410, 01251], lr: 0.000238, loss: 0.3908
2022-10-03 17:17:21 - train: epoch 0295, iter [00420, 01251], lr: 0.000238, loss: 0.3858
2022-10-03 17:17:39 - train: epoch 0295, iter [00430, 01251], lr: 0.000237, loss: 0.3894
2022-10-03 17:17:57 - train: epoch 0295, iter [00440, 01251], lr: 0.000237, loss: 0.3994
2022-10-03 17:18:15 - train: epoch 0295, iter [00450, 01251], lr: 0.000237, loss: 0.4075
2022-10-03 17:18:33 - train: epoch 0295, iter [00460, 01251], lr: 0.000237, loss: 0.4064
2022-10-03 17:18:51 - train: epoch 0295, iter [00470, 01251], lr: 0.000237, loss: 0.3991
2022-10-03 17:19:09 - train: epoch 0295, iter [00480, 01251], lr: 0.000237, loss: 0.3782
2022-10-03 17:19:27 - train: epoch 0295, iter [00490, 01251], lr: 0.000237, loss: 0.4087
2022-10-03 17:19:45 - train: epoch 0295, iter [00500, 01251], lr: 0.000237, loss: 0.4035
2022-10-03 17:20:04 - train: epoch 0295, iter [00510, 01251], lr: 0.000237, loss: 0.4090
2022-10-03 17:20:22 - train: epoch 0295, iter [00520, 01251], lr: 0.000237, loss: 0.3719
2022-10-03 17:20:40 - train: epoch 0295, iter [00530, 01251], lr: 0.000237, loss: 0.3935
2022-10-03 17:20:58 - train: epoch 0295, iter [00540, 01251], lr: 0.000237, loss: 0.4083
2022-10-03 17:21:16 - train: epoch 0295, iter [00550, 01251], lr: 0.000237, loss: 0.4021
2022-10-03 17:21:34 - train: epoch 0295, iter [00560, 01251], lr: 0.000237, loss: 0.3702
2022-10-03 17:21:52 - train: epoch 0295, iter [00570, 01251], lr: 0.000237, loss: 0.4128
2022-10-03 17:22:10 - train: epoch 0295, iter [00580, 01251], lr: 0.000237, loss: 0.3955
2022-10-03 17:22:28 - train: epoch 0295, iter [00590, 01251], lr: 0.000237, loss: 0.4060
2022-10-03 17:22:46 - train: epoch 0295, iter [00600, 01251], lr: 0.000237, loss: 0.3856
2022-10-03 17:23:04 - train: epoch 0295, iter [00610, 01251], lr: 0.000237, loss: 0.3823
2022-10-03 17:23:22 - train: epoch 0295, iter [00620, 01251], lr: 0.000237, loss: 0.4189
2022-10-03 17:23:40 - train: epoch 0295, iter [00630, 01251], lr: 0.000237, loss: 0.3949
2022-10-03 17:23:58 - train: epoch 0295, iter [00640, 01251], lr: 0.000237, loss: 0.3930
2022-10-03 17:24:16 - train: epoch 0295, iter [00650, 01251], lr: 0.000237, loss: 0.4058
2022-10-03 17:24:34 - train: epoch 0295, iter [00660, 01251], lr: 0.000237, loss: 0.4131
2022-10-03 17:24:53 - train: epoch 0295, iter [00670, 01251], lr: 0.000237, loss: 0.4191
2022-10-03 17:25:11 - train: epoch 0295, iter [00680, 01251], lr: 0.000237, loss: 0.4170
2022-10-03 17:25:29 - train: epoch 0295, iter [00690, 01251], lr: 0.000237, loss: 0.4061
2022-10-03 17:25:47 - train: epoch 0295, iter [00700, 01251], lr: 0.000237, loss: 0.4093
2022-10-03 17:26:05 - train: epoch 0295, iter [00710, 01251], lr: 0.000237, loss: 0.3939
2022-10-03 17:26:23 - train: epoch 0295, iter [00720, 01251], lr: 0.000237, loss: 0.3846
2022-10-03 17:26:41 - train: epoch 0295, iter [00730, 01251], lr: 0.000236, loss: 0.3976
2022-10-03 17:26:59 - train: epoch 0295, iter [00740, 01251], lr: 0.000236, loss: 0.4051
2022-10-03 17:27:17 - train: epoch 0295, iter [00750, 01251], lr: 0.000236, loss: 0.3860
2022-10-03 17:27:35 - train: epoch 0295, iter [00760, 01251], lr: 0.000236, loss: 0.3966
2022-10-03 17:27:53 - train: epoch 0295, iter [00770, 01251], lr: 0.000236, loss: 0.4050
2022-10-03 17:28:11 - train: epoch 0295, iter [00780, 01251], lr: 0.000236, loss: 0.3973
2022-10-03 17:28:29 - train: epoch 0295, iter [00790, 01251], lr: 0.000236, loss: 0.4015
2022-10-03 17:28:47 - train: epoch 0295, iter [00800, 01251], lr: 0.000236, loss: 0.3777
2022-10-03 17:29:05 - train: epoch 0295, iter [00810, 01251], lr: 0.000236, loss: 0.3978
2022-10-03 17:29:23 - train: epoch 0295, iter [00820, 01251], lr: 0.000236, loss: 0.3985
2022-10-03 17:29:41 - train: epoch 0295, iter [00830, 01251], lr: 0.000236, loss: 0.4072
2022-10-03 17:29:59 - train: epoch 0295, iter [00840, 01251], lr: 0.000236, loss: 0.3873
2022-10-03 17:30:18 - train: epoch 0295, iter [00850, 01251], lr: 0.000236, loss: 0.3867
2022-10-03 17:30:35 - train: epoch 0295, iter [00860, 01251], lr: 0.000236, loss: 0.4121
2022-10-03 17:30:54 - train: epoch 0295, iter [00870, 01251], lr: 0.000236, loss: 0.3891
2022-10-03 17:31:12 - train: epoch 0295, iter [00880, 01251], lr: 0.000236, loss: 0.4016
2022-10-03 17:31:30 - train: epoch 0295, iter [00890, 01251], lr: 0.000236, loss: 0.4036
2022-10-03 17:31:48 - train: epoch 0295, iter [00900, 01251], lr: 0.000236, loss: 0.3922
2022-10-03 17:32:06 - train: epoch 0295, iter [00910, 01251], lr: 0.000236, loss: 0.3968
2022-10-03 17:32:24 - train: epoch 0295, iter [00920, 01251], lr: 0.000236, loss: 0.4158
2022-10-03 17:32:42 - train: epoch 0295, iter [00930, 01251], lr: 0.000236, loss: 0.4158
2022-10-03 17:33:00 - train: epoch 0295, iter [00940, 01251], lr: 0.000236, loss: 0.4010
2022-10-03 17:33:18 - train: epoch 0295, iter [00950, 01251], lr: 0.000236, loss: 0.4027
2022-10-03 17:33:36 - train: epoch 0295, iter [00960, 01251], lr: 0.000236, loss: 0.3972
2022-10-03 17:33:54 - train: epoch 0295, iter [00970, 01251], lr: 0.000236, loss: 0.3762
2022-10-03 17:34:12 - train: epoch 0295, iter [00980, 01251], lr: 0.000236, loss: 0.3806
2022-10-03 17:34:31 - train: epoch 0295, iter [00990, 01251], lr: 0.000236, loss: 0.3791
2022-10-03 17:34:48 - train: epoch 0295, iter [01000, 01251], lr: 0.000236, loss: 0.4036
2022-10-03 17:35:07 - train: epoch 0295, iter [01010, 01251], lr: 0.000236, loss: 0.4017
2022-10-03 17:35:25 - train: epoch 0295, iter [01020, 01251], lr: 0.000236, loss: 0.3872
2022-10-03 17:35:42 - train: epoch 0295, iter [01030, 01251], lr: 0.000235, loss: 0.4205
2022-10-03 17:36:01 - train: epoch 0295, iter [01040, 01251], lr: 0.000235, loss: 0.3918
2022-10-03 17:36:19 - train: epoch 0295, iter [01050, 01251], lr: 0.000235, loss: 0.3954
2022-10-03 17:36:37 - train: epoch 0295, iter [01060, 01251], lr: 0.000235, loss: 0.4003
2022-10-03 17:36:55 - train: epoch 0295, iter [01070, 01251], lr: 0.000235, loss: 0.4084
2022-10-03 17:37:13 - train: epoch 0295, iter [01080, 01251], lr: 0.000235, loss: 0.3869
2022-10-03 17:37:31 - train: epoch 0295, iter [01090, 01251], lr: 0.000235, loss: 0.4247
2022-10-03 17:37:49 - train: epoch 0295, iter [01100, 01251], lr: 0.000235, loss: 0.4100
2022-10-03 17:38:07 - train: epoch 0295, iter [01110, 01251], lr: 0.000235, loss: 0.4131
2022-10-03 17:38:25 - train: epoch 0295, iter [01120, 01251], lr: 0.000235, loss: 0.3882
2022-10-03 17:38:43 - train: epoch 0295, iter [01130, 01251], lr: 0.000235, loss: 0.3980
2022-10-03 17:39:01 - train: epoch 0295, iter [01140, 01251], lr: 0.000235, loss: 0.3817
2022-10-03 17:39:19 - train: epoch 0295, iter [01150, 01251], lr: 0.000235, loss: 0.3872
2022-10-03 17:39:37 - train: epoch 0295, iter [01160, 01251], lr: 0.000235, loss: 0.3805
2022-10-03 17:39:55 - train: epoch 0295, iter [01170, 01251], lr: 0.000235, loss: 0.4085
2022-10-03 17:40:13 - train: epoch 0295, iter [01180, 01251], lr: 0.000235, loss: 0.4044
2022-10-03 17:40:31 - train: epoch 0295, iter [01190, 01251], lr: 0.000235, loss: 0.4075
2022-10-03 17:40:49 - train: epoch 0295, iter [01200, 01251], lr: 0.000235, loss: 0.4023
2022-10-03 17:41:07 - train: epoch 0295, iter [01210, 01251], lr: 0.000235, loss: 0.3990
2022-10-03 17:41:25 - train: epoch 0295, iter [01220, 01251], lr: 0.000235, loss: 0.4020
2022-10-03 17:41:43 - train: epoch 0295, iter [01230, 01251], lr: 0.000235, loss: 0.4103
2022-10-03 17:42:01 - train: epoch 0295, iter [01240, 01251], lr: 0.000235, loss: 0.4028
2022-10-03 17:42:19 - train: epoch 0295, iter [01250, 01251], lr: 0.000235, loss: 0.3791
2022-10-03 17:42:22 - train: epoch 295, train_loss: 0.3980
2022-10-03 17:42:25 - until epoch: 295, best_loss: 0.3980
2022-10-03 17:42:25 - epoch 296 lr: 0.000235
2022-10-03 17:42:50 - train: epoch 0296, iter [00010, 01251], lr: 0.000235, loss: 0.3929
2022-10-03 17:43:08 - train: epoch 0296, iter [00020, 01251], lr: 0.000235, loss: 0.3923
2022-10-03 17:43:26 - train: epoch 0296, iter [00030, 01251], lr: 0.000235, loss: 0.3895
2022-10-03 17:43:44 - train: epoch 0296, iter [00040, 01251], lr: 0.000235, loss: 0.3816
2022-10-03 17:44:02 - train: epoch 0296, iter [00050, 01251], lr: 0.000235, loss: 0.3847
2022-10-03 17:44:20 - train: epoch 0296, iter [00060, 01251], lr: 0.000235, loss: 0.4027
2022-10-03 17:44:38 - train: epoch 0296, iter [00070, 01251], lr: 0.000235, loss: 0.3998
2022-10-03 17:44:57 - train: epoch 0296, iter [00080, 01251], lr: 0.000234, loss: 0.3970
2022-10-03 17:45:15 - train: epoch 0296, iter [00090, 01251], lr: 0.000234, loss: 0.3906
2022-10-03 17:45:33 - train: epoch 0296, iter [00100, 01251], lr: 0.000234, loss: 0.3801
2022-10-03 17:45:51 - train: epoch 0296, iter [00110, 01251], lr: 0.000234, loss: 0.3931
2022-10-03 17:46:09 - train: epoch 0296, iter [00120, 01251], lr: 0.000234, loss: 0.4235
2022-10-03 17:46:27 - train: epoch 0296, iter [00130, 01251], lr: 0.000234, loss: 0.3854
2022-10-03 17:46:45 - train: epoch 0296, iter [00140, 01251], lr: 0.000234, loss: 0.3929
2022-10-03 17:47:03 - train: epoch 0296, iter [00150, 01251], lr: 0.000234, loss: 0.3987
2022-10-03 17:47:21 - train: epoch 0296, iter [00160, 01251], lr: 0.000234, loss: 0.3982
2022-10-03 17:47:39 - train: epoch 0296, iter [00170, 01251], lr: 0.000234, loss: 0.3943
2022-10-03 17:47:58 - train: epoch 0296, iter [00180, 01251], lr: 0.000234, loss: 0.3876
2022-10-03 17:48:16 - train: epoch 0296, iter [00190, 01251], lr: 0.000234, loss: 0.3925
2022-10-03 17:48:34 - train: epoch 0296, iter [00200, 01251], lr: 0.000234, loss: 0.4009
2022-10-03 17:48:52 - train: epoch 0296, iter [00210, 01251], lr: 0.000234, loss: 0.3935
2022-10-03 17:49:10 - train: epoch 0296, iter [00220, 01251], lr: 0.000234, loss: 0.3771
2022-10-03 17:49:28 - train: epoch 0296, iter [00230, 01251], lr: 0.000234, loss: 0.3840
2022-10-03 17:49:46 - train: epoch 0296, iter [00240, 01251], lr: 0.000234, loss: 0.4066
2022-10-03 17:50:04 - train: epoch 0296, iter [00250, 01251], lr: 0.000234, loss: 0.3858
2022-10-03 17:50:22 - train: epoch 0296, iter [00260, 01251], lr: 0.000234, loss: 0.4047
2022-10-03 17:50:40 - train: epoch 0296, iter [00270, 01251], lr: 0.000234, loss: 0.4140
2022-10-03 17:50:58 - train: epoch 0296, iter [00280, 01251], lr: 0.000234, loss: 0.3933
2022-10-03 17:51:16 - train: epoch 0296, iter [00290, 01251], lr: 0.000234, loss: 0.3866
2022-10-03 17:51:34 - train: epoch 0296, iter [00300, 01251], lr: 0.000234, loss: 0.3926
2022-10-03 17:51:52 - train: epoch 0296, iter [00310, 01251], lr: 0.000234, loss: 0.4024
2022-10-03 17:52:10 - train: epoch 0296, iter [00320, 01251], lr: 0.000234, loss: 0.4029
2022-10-03 17:52:28 - train: epoch 0296, iter [00330, 01251], lr: 0.000234, loss: 0.3988
2022-10-03 17:52:46 - train: epoch 0296, iter [00340, 01251], lr: 0.000234, loss: 0.3977
2022-10-03 17:53:04 - train: epoch 0296, iter [00350, 01251], lr: 0.000234, loss: 0.4044
2022-10-03 17:53:22 - train: epoch 0296, iter [00360, 01251], lr: 0.000234, loss: 0.3906
2022-10-03 17:53:40 - train: epoch 0296, iter [00370, 01251], lr: 0.000234, loss: 0.3890
2022-10-03 17:53:58 - train: epoch 0296, iter [00380, 01251], lr: 0.000233, loss: 0.3839
2022-10-03 17:54:16 - train: epoch 0296, iter [00390, 01251], lr: 0.000233, loss: 0.4033
2022-10-03 17:54:34 - train: epoch 0296, iter [00400, 01251], lr: 0.000233, loss: 0.4054
2022-10-03 17:54:52 - train: epoch 0296, iter [00410, 01251], lr: 0.000233, loss: 0.3875
2022-10-03 17:55:10 - train: epoch 0296, iter [00420, 01251], lr: 0.000233, loss: 0.4101
2022-10-03 17:55:28 - train: epoch 0296, iter [00430, 01251], lr: 0.000233, loss: 0.3916
2022-10-03 17:55:46 - train: epoch 0296, iter [00440, 01251], lr: 0.000233, loss: 0.4132
2022-10-03 17:56:04 - train: epoch 0296, iter [00450, 01251], lr: 0.000233, loss: 0.3970
2022-10-03 17:56:22 - train: epoch 0296, iter [00460, 01251], lr: 0.000233, loss: 0.3784
2022-10-03 17:56:40 - train: epoch 0296, iter [00470, 01251], lr: 0.000233, loss: 0.4055
2022-10-03 17:56:58 - train: epoch 0296, iter [00480, 01251], lr: 0.000233, loss: 0.3798
2022-10-03 17:57:16 - train: epoch 0296, iter [00490, 01251], lr: 0.000233, loss: 0.4031
2022-10-03 17:57:34 - train: epoch 0296, iter [00500, 01251], lr: 0.000233, loss: 0.4204
2022-10-03 17:57:52 - train: epoch 0296, iter [00510, 01251], lr: 0.000233, loss: 0.3788
2022-10-03 17:58:11 - train: epoch 0296, iter [00520, 01251], lr: 0.000233, loss: 0.4058
2022-10-03 17:58:29 - train: epoch 0296, iter [00530, 01251], lr: 0.000233, loss: 0.3929
2022-10-03 17:58:47 - train: epoch 0296, iter [00540, 01251], lr: 0.000233, loss: 0.3928
2022-10-03 17:59:05 - train: epoch 0296, iter [00550, 01251], lr: 0.000233, loss: 0.3882
2022-10-03 17:59:23 - train: epoch 0296, iter [00560, 01251], lr: 0.000233, loss: 0.4015
2022-10-03 17:59:41 - train: epoch 0296, iter [00570, 01251], lr: 0.000233, loss: 0.3994
2022-10-03 17:59:59 - train: epoch 0296, iter [00580, 01251], lr: 0.000233, loss: 0.4016
2022-10-03 18:00:17 - train: epoch 0296, iter [00590, 01251], lr: 0.000233, loss: 0.4115
2022-10-03 18:00:35 - train: epoch 0296, iter [00600, 01251], lr: 0.000233, loss: 0.3847
2022-10-03 18:00:53 - train: epoch 0296, iter [00610, 01251], lr: 0.000233, loss: 0.3859
2022-10-03 18:01:11 - train: epoch 0296, iter [00620, 01251], lr: 0.000233, loss: 0.3989
2022-10-03 18:01:29 - train: epoch 0296, iter [00630, 01251], lr: 0.000233, loss: 0.3974
2022-10-03 18:01:46 - train: epoch 0296, iter [00640, 01251], lr: 0.000233, loss: 0.4012
2022-10-03 18:02:04 - train: epoch 0296, iter [00650, 01251], lr: 0.000233, loss: 0.4137
2022-10-03 18:02:22 - train: epoch 0296, iter [00660, 01251], lr: 0.000233, loss: 0.3972
2022-10-03 18:02:40 - train: epoch 0296, iter [00670, 01251], lr: 0.000233, loss: 0.3862
2022-10-03 18:02:58 - train: epoch 0296, iter [00680, 01251], lr: 0.000232, loss: 0.4105
2022-10-03 18:03:16 - train: epoch 0296, iter [00690, 01251], lr: 0.000232, loss: 0.3945
2022-10-03 18:03:34 - train: epoch 0296, iter [00700, 01251], lr: 0.000232, loss: 0.3829
2022-10-03 18:03:52 - train: epoch 0296, iter [00710, 01251], lr: 0.000232, loss: 0.4048
2022-10-03 18:04:10 - train: epoch 0296, iter [00720, 01251], lr: 0.000232, loss: 0.3846
2022-10-03 18:04:28 - train: epoch 0296, iter [00730, 01251], lr: 0.000232, loss: 0.4036
2022-10-03 18:04:46 - train: epoch 0296, iter [00740, 01251], lr: 0.000232, loss: 0.4015
2022-10-03 18:05:04 - train: epoch 0296, iter [00750, 01251], lr: 0.000232, loss: 0.4022
2022-10-03 18:05:23 - train: epoch 0296, iter [00760, 01251], lr: 0.000232, loss: 0.4170
2022-10-03 18:05:41 - train: epoch 0296, iter [00770, 01251], lr: 0.000232, loss: 0.4087
2022-10-03 18:05:59 - train: epoch 0296, iter [00780, 01251], lr: 0.000232, loss: 0.3885
2022-10-03 18:06:17 - train: epoch 0296, iter [00790, 01251], lr: 0.000232, loss: 0.3690
2022-10-03 18:06:35 - train: epoch 0296, iter [00800, 01251], lr: 0.000232, loss: 0.4089
2022-10-03 18:06:53 - train: epoch 0296, iter [00810, 01251], lr: 0.000232, loss: 0.3864
2022-10-03 18:07:10 - train: epoch 0296, iter [00820, 01251], lr: 0.000232, loss: 0.4065
2022-10-03 18:07:29 - train: epoch 0296, iter [00830, 01251], lr: 0.000232, loss: 0.4042
2022-10-03 18:07:47 - train: epoch 0296, iter [00840, 01251], lr: 0.000232, loss: 0.3970
2022-10-03 18:08:05 - train: epoch 0296, iter [00850, 01251], lr: 0.000232, loss: 0.4069
2022-10-03 18:08:23 - train: epoch 0296, iter [00860, 01251], lr: 0.000232, loss: 0.3994
2022-10-03 18:08:41 - train: epoch 0296, iter [00870, 01251], lr: 0.000232, loss: 0.3935
2022-10-03 18:08:59 - train: epoch 0296, iter [00880, 01251], lr: 0.000232, loss: 0.3937
2022-10-03 18:09:17 - train: epoch 0296, iter [00890, 01251], lr: 0.000232, loss: 0.4056
2022-10-03 18:09:35 - train: epoch 0296, iter [00900, 01251], lr: 0.000232, loss: 0.3889
2022-10-03 18:09:53 - train: epoch 0296, iter [00910, 01251], lr: 0.000232, loss: 0.3951
2022-10-03 18:10:11 - train: epoch 0296, iter [00920, 01251], lr: 0.000232, loss: 0.3915
2022-10-03 18:10:29 - train: epoch 0296, iter [00930, 01251], lr: 0.000232, loss: 0.4175
2022-10-03 18:10:47 - train: epoch 0296, iter [00940, 01251], lr: 0.000232, loss: 0.3885
2022-10-03 18:11:05 - train: epoch 0296, iter [00950, 01251], lr: 0.000232, loss: 0.4122
2022-10-03 18:11:23 - train: epoch 0296, iter [00960, 01251], lr: 0.000232, loss: 0.4046
2022-10-03 18:11:41 - train: epoch 0296, iter [00970, 01251], lr: 0.000232, loss: 0.3797
2022-10-03 18:11:59 - train: epoch 0296, iter [00980, 01251], lr: 0.000231, loss: 0.3959
2022-10-03 18:12:17 - train: epoch 0296, iter [00990, 01251], lr: 0.000231, loss: 0.4000
2022-10-03 18:12:35 - train: epoch 0296, iter [01000, 01251], lr: 0.000231, loss: 0.3986
2022-10-03 18:12:53 - train: epoch 0296, iter [01010, 01251], lr: 0.000231, loss: 0.3985
2022-10-03 18:13:11 - train: epoch 0296, iter [01020, 01251], lr: 0.000231, loss: 0.3763
2022-10-03 18:13:29 - train: epoch 0296, iter [01030, 01251], lr: 0.000231, loss: 0.4145
2022-10-03 18:13:47 - train: epoch 0296, iter [01040, 01251], lr: 0.000231, loss: 0.4229
2022-10-03 18:14:05 - train: epoch 0296, iter [01050, 01251], lr: 0.000231, loss: 0.3991
2022-10-03 18:14:23 - train: epoch 0296, iter [01060, 01251], lr: 0.000231, loss: 0.4084
2022-10-03 18:14:41 - train: epoch 0296, iter [01070, 01251], lr: 0.000231, loss: 0.4138
2022-10-03 18:14:59 - train: epoch 0296, iter [01080, 01251], lr: 0.000231, loss: 0.4030
2022-10-03 18:15:17 - train: epoch 0296, iter [01090, 01251], lr: 0.000231, loss: 0.3780
2022-10-03 18:15:35 - train: epoch 0296, iter [01100, 01251], lr: 0.000231, loss: 0.4007
2022-10-03 18:15:53 - train: epoch 0296, iter [01110, 01251], lr: 0.000231, loss: 0.3933
2022-10-03 18:16:11 - train: epoch 0296, iter [01120, 01251], lr: 0.000231, loss: 0.4096
2022-10-03 18:16:29 - train: epoch 0296, iter [01130, 01251], lr: 0.000231, loss: 0.3987
2022-10-03 18:16:47 - train: epoch 0296, iter [01140, 01251], lr: 0.000231, loss: 0.3887
2022-10-03 18:17:05 - train: epoch 0296, iter [01150, 01251], lr: 0.000231, loss: 0.4019
2022-10-03 18:17:23 - train: epoch 0296, iter [01160, 01251], lr: 0.000231, loss: 0.3866
2022-10-03 18:17:41 - train: epoch 0296, iter [01170, 01251], lr: 0.000231, loss: 0.4000
2022-10-03 18:17:59 - train: epoch 0296, iter [01180, 01251], lr: 0.000231, loss: 0.3832
2022-10-03 18:18:17 - train: epoch 0296, iter [01190, 01251], lr: 0.000231, loss: 0.4057
2022-10-03 18:18:35 - train: epoch 0296, iter [01200, 01251], lr: 0.000231, loss: 0.3919
2022-10-03 18:18:53 - train: epoch 0296, iter [01210, 01251], lr: 0.000231, loss: 0.4014
2022-10-03 18:19:11 - train: epoch 0296, iter [01220, 01251], lr: 0.000231, loss: 0.3961
2022-10-03 18:19:29 - train: epoch 0296, iter [01230, 01251], lr: 0.000231, loss: 0.3543
2022-10-03 18:19:47 - train: epoch 0296, iter [01240, 01251], lr: 0.000231, loss: 0.3952
2022-10-03 18:20:05 - train: epoch 0296, iter [01250, 01251], lr: 0.000231, loss: 0.4155
2022-10-03 18:20:09 - train: epoch 296, train_loss: 0.3979
2022-10-03 18:20:11 - until epoch: 296, best_loss: 0.3979
2022-10-03 18:20:11 - epoch 297 lr: 0.000231
2022-10-03 18:20:37 - train: epoch 0297, iter [00010, 01251], lr: 0.000231, loss: 0.3935
2022-10-03 18:20:55 - train: epoch 0297, iter [00020, 01251], lr: 0.000231, loss: 0.4080
2022-10-03 18:21:13 - train: epoch 0297, iter [00030, 01251], lr: 0.000231, loss: 0.4056
2022-10-03 18:21:31 - train: epoch 0297, iter [00040, 01251], lr: 0.000230, loss: 0.3975
2022-10-03 18:21:49 - train: epoch 0297, iter [00050, 01251], lr: 0.000230, loss: 0.4030
2022-10-03 18:22:07 - train: epoch 0297, iter [00060, 01251], lr: 0.000230, loss: 0.4098
2022-10-03 18:22:25 - train: epoch 0297, iter [00070, 01251], lr: 0.000230, loss: 0.4198
2022-10-03 18:22:43 - train: epoch 0297, iter [00080, 01251], lr: 0.000230, loss: 0.4094
2022-10-03 18:23:01 - train: epoch 0297, iter [00090, 01251], lr: 0.000230, loss: 0.4088
2022-10-03 18:23:19 - train: epoch 0297, iter [00100, 01251], lr: 0.000230, loss: 0.3999
2022-10-03 18:23:37 - train: epoch 0297, iter [00110, 01251], lr: 0.000230, loss: 0.3867
2022-10-03 18:23:55 - train: epoch 0297, iter [00120, 01251], lr: 0.000230, loss: 0.3994
2022-10-03 18:24:13 - train: epoch 0297, iter [00130, 01251], lr: 0.000230, loss: 0.3968
2022-10-03 18:24:31 - train: epoch 0297, iter [00140, 01251], lr: 0.000230, loss: 0.4016
2022-10-03 18:24:49 - train: epoch 0297, iter [00150, 01251], lr: 0.000230, loss: 0.4099
2022-10-03 18:25:07 - train: epoch 0297, iter [00160, 01251], lr: 0.000230, loss: 0.4145
2022-10-03 18:25:25 - train: epoch 0297, iter [00170, 01251], lr: 0.000230, loss: 0.4165
2022-10-03 18:25:43 - train: epoch 0297, iter [00180, 01251], lr: 0.000230, loss: 0.3941
2022-10-03 18:26:01 - train: epoch 0297, iter [00190, 01251], lr: 0.000230, loss: 0.3853
2022-10-03 18:26:19 - train: epoch 0297, iter [00200, 01251], lr: 0.000230, loss: 0.3875
2022-10-03 18:26:37 - train: epoch 0297, iter [00210, 01251], lr: 0.000230, loss: 0.4104
2022-10-03 18:26:56 - train: epoch 0297, iter [00220, 01251], lr: 0.000230, loss: 0.3946
2022-10-03 18:27:14 - train: epoch 0297, iter [00230, 01251], lr: 0.000230, loss: 0.3894
2022-10-03 18:27:32 - train: epoch 0297, iter [00240, 01251], lr: 0.000230, loss: 0.3909
2022-10-03 18:27:50 - train: epoch 0297, iter [00250, 01251], lr: 0.000230, loss: 0.3777
2022-10-03 18:28:08 - train: epoch 0297, iter [00260, 01251], lr: 0.000230, loss: 0.4227
2022-10-03 18:28:26 - train: epoch 0297, iter [00270, 01251], lr: 0.000230, loss: 0.3918
2022-10-03 18:28:44 - train: epoch 0297, iter [00280, 01251], lr: 0.000230, loss: 0.3797
2022-10-03 18:29:03 - train: epoch 0297, iter [00290, 01251], lr: 0.000230, loss: 0.4143
2022-10-03 18:29:21 - train: epoch 0297, iter [00300, 01251], lr: 0.000230, loss: 0.3691
2022-10-03 18:29:39 - train: epoch 0297, iter [00310, 01251], lr: 0.000230, loss: 0.4119
2022-10-03 18:29:58 - train: epoch 0297, iter [00320, 01251], lr: 0.000230, loss: 0.4100
2022-10-03 18:30:16 - train: epoch 0297, iter [00330, 01251], lr: 0.000230, loss: 0.4102
2022-10-03 18:30:35 - train: epoch 0297, iter [00340, 01251], lr: 0.000229, loss: 0.3806
2022-10-03 18:30:53 - train: epoch 0297, iter [00350, 01251], lr: 0.000229, loss: 0.3973
2022-10-03 18:31:12 - train: epoch 0297, iter [00360, 01251], lr: 0.000229, loss: 0.3888
2022-10-03 18:31:30 - train: epoch 0297, iter [00370, 01251], lr: 0.000229, loss: 0.3949
2022-10-03 18:31:49 - train: epoch 0297, iter [00380, 01251], lr: 0.000229, loss: 0.3963
2022-10-03 18:32:07 - train: epoch 0297, iter [00390, 01251], lr: 0.000229, loss: 0.3990
2022-10-03 18:32:26 - train: epoch 0297, iter [00400, 01251], lr: 0.000229, loss: 0.4012
2022-10-03 18:32:44 - train: epoch 0297, iter [00410, 01251], lr: 0.000229, loss: 0.3841
2022-10-03 18:33:03 - train: epoch 0297, iter [00420, 01251], lr: 0.000229, loss: 0.4055
2022-10-03 18:33:21 - train: epoch 0297, iter [00430, 01251], lr: 0.000229, loss: 0.3880
2022-10-03 18:33:40 - train: epoch 0297, iter [00440, 01251], lr: 0.000229, loss: 0.3762
2022-10-03 18:33:58 - train: epoch 0297, iter [00450, 01251], lr: 0.000229, loss: 0.3827
2022-10-03 18:34:17 - train: epoch 0297, iter [00460, 01251], lr: 0.000229, loss: 0.4091
2022-10-03 18:34:35 - train: epoch 0297, iter [00470, 01251], lr: 0.000229, loss: 0.4128
2022-10-03 18:34:54 - train: epoch 0297, iter [00480, 01251], lr: 0.000229, loss: 0.4109
2022-10-03 18:35:13 - train: epoch 0297, iter [00490, 01251], lr: 0.000229, loss: 0.3987
2022-10-03 18:35:31 - train: epoch 0297, iter [00500, 01251], lr: 0.000229, loss: 0.3993
2022-10-03 18:35:50 - train: epoch 0297, iter [00510, 01251], lr: 0.000229, loss: 0.3913
2022-10-03 18:36:08 - train: epoch 0297, iter [00520, 01251], lr: 0.000229, loss: 0.4028
2022-10-03 18:36:27 - train: epoch 0297, iter [00530, 01251], lr: 0.000229, loss: 0.3955
2022-10-03 18:36:45 - train: epoch 0297, iter [00540, 01251], lr: 0.000229, loss: 0.3918
2022-10-03 18:37:04 - train: epoch 0297, iter [00550, 01251], lr: 0.000229, loss: 0.3977
2022-10-03 18:37:22 - train: epoch 0297, iter [00560, 01251], lr: 0.000229, loss: 0.4158
2022-10-03 18:37:41 - train: epoch 0297, iter [00570, 01251], lr: 0.000229, loss: 0.3881
2022-10-03 18:38:00 - train: epoch 0297, iter [00580, 01251], lr: 0.000229, loss: 0.3898
2022-10-03 18:38:18 - train: epoch 0297, iter [00590, 01251], lr: 0.000229, loss: 0.3950
2022-10-03 18:38:37 - train: epoch 0297, iter [00600, 01251], lr: 0.000229, loss: 0.4068
2022-10-03 18:38:55 - train: epoch 0297, iter [00610, 01251], lr: 0.000229, loss: 0.4050
2022-10-03 18:39:14 - train: epoch 0297, iter [00620, 01251], lr: 0.000229, loss: 0.4072
2022-10-03 18:39:32 - train: epoch 0297, iter [00630, 01251], lr: 0.000229, loss: 0.3823
2022-10-03 18:39:51 - train: epoch 0297, iter [00640, 01251], lr: 0.000228, loss: 0.4059
2022-10-03 18:40:09 - train: epoch 0297, iter [00650, 01251], lr: 0.000228, loss: 0.3931
2022-10-03 18:40:28 - train: epoch 0297, iter [00660, 01251], lr: 0.000228, loss: 0.4105
2022-10-03 18:40:47 - train: epoch 0297, iter [00670, 01251], lr: 0.000228, loss: 0.3971
2022-10-03 18:41:05 - train: epoch 0297, iter [00680, 01251], lr: 0.000228, loss: 0.4187
2022-10-03 18:41:24 - train: epoch 0297, iter [00690, 01251], lr: 0.000228, loss: 0.3983
2022-10-03 18:41:42 - train: epoch 0297, iter [00700, 01251], lr: 0.000228, loss: 0.3945
2022-10-03 18:42:01 - train: epoch 0297, iter [00710, 01251], lr: 0.000228, loss: 0.4097
2022-10-03 18:42:19 - train: epoch 0297, iter [00720, 01251], lr: 0.000228, loss: 0.3764
2022-10-03 18:42:38 - train: epoch 0297, iter [00730, 01251], lr: 0.000228, loss: 0.3989
2022-10-03 18:42:57 - train: epoch 0297, iter [00740, 01251], lr: 0.000228, loss: 0.3882
2022-10-03 18:43:15 - train: epoch 0297, iter [00750, 01251], lr: 0.000228, loss: 0.3973
2022-10-03 18:43:34 - train: epoch 0297, iter [00760, 01251], lr: 0.000228, loss: 0.4026
2022-10-03 18:43:52 - train: epoch 0297, iter [00770, 01251], lr: 0.000228, loss: 0.4006
2022-10-03 18:44:11 - train: epoch 0297, iter [00780, 01251], lr: 0.000228, loss: 0.3914
2022-10-03 18:44:29 - train: epoch 0297, iter [00790, 01251], lr: 0.000228, loss: 0.3763
2022-10-03 18:44:48 - train: epoch 0297, iter [00800, 01251], lr: 0.000228, loss: 0.4033
2022-10-03 18:45:07 - train: epoch 0297, iter [00810, 01251], lr: 0.000228, loss: 0.3979
2022-10-03 18:45:25 - train: epoch 0297, iter [00820, 01251], lr: 0.000228, loss: 0.4165
2022-10-03 18:45:44 - train: epoch 0297, iter [00830, 01251], lr: 0.000228, loss: 0.3922
2022-10-03 18:46:02 - train: epoch 0297, iter [00840, 01251], lr: 0.000228, loss: 0.3876
2022-10-03 18:46:21 - train: epoch 0297, iter [00850, 01251], lr: 0.000228, loss: 0.3978
2022-10-03 18:46:39 - train: epoch 0297, iter [00860, 01251], lr: 0.000228, loss: 0.3964
2022-10-03 18:46:58 - train: epoch 0297, iter [00870, 01251], lr: 0.000228, loss: 0.3909
2022-10-03 18:47:17 - train: epoch 0297, iter [00880, 01251], lr: 0.000228, loss: 0.3939
2022-10-03 18:47:35 - train: epoch 0297, iter [00890, 01251], lr: 0.000228, loss: 0.3990
2022-10-03 18:47:54 - train: epoch 0297, iter [00900, 01251], lr: 0.000228, loss: 0.4020
2022-10-03 18:48:12 - train: epoch 0297, iter [00910, 01251], lr: 0.000228, loss: 0.4009
2022-10-03 18:48:31 - train: epoch 0297, iter [00920, 01251], lr: 0.000228, loss: 0.4026
2022-10-03 18:48:50 - train: epoch 0297, iter [00930, 01251], lr: 0.000228, loss: 0.3820
2022-10-03 18:49:08 - train: epoch 0297, iter [00940, 01251], lr: 0.000228, loss: 0.3962
2022-10-03 18:49:27 - train: epoch 0297, iter [00950, 01251], lr: 0.000227, loss: 0.4050
2022-10-03 18:49:45 - train: epoch 0297, iter [00960, 01251], lr: 0.000227, loss: 0.4071
2022-10-03 18:50:04 - train: epoch 0297, iter [00970, 01251], lr: 0.000227, loss: 0.4130
2022-10-03 18:50:22 - train: epoch 0297, iter [00980, 01251], lr: 0.000227, loss: 0.4008
2022-10-03 18:50:41 - train: epoch 0297, iter [00990, 01251], lr: 0.000227, loss: 0.3765
2022-10-03 18:51:00 - train: epoch 0297, iter [01000, 01251], lr: 0.000227, loss: 0.3994
2022-10-03 18:51:18 - train: epoch 0297, iter [01010, 01251], lr: 0.000227, loss: 0.4097
2022-10-03 18:51:37 - train: epoch 0297, iter [01020, 01251], lr: 0.000227, loss: 0.3720
2022-10-03 18:51:55 - train: epoch 0297, iter [01030, 01251], lr: 0.000227, loss: 0.3844
2022-10-03 18:52:14 - train: epoch 0297, iter [01040, 01251], lr: 0.000227, loss: 0.4112
2022-10-03 18:52:33 - train: epoch 0297, iter [01050, 01251], lr: 0.000227, loss: 0.3939
2022-10-03 18:52:51 - train: epoch 0297, iter [01060, 01251], lr: 0.000227, loss: 0.3945
2022-10-03 18:53:10 - train: epoch 0297, iter [01070, 01251], lr: 0.000227, loss: 0.3902
2022-10-03 18:53:28 - train: epoch 0297, iter [01080, 01251], lr: 0.000227, loss: 0.3991
2022-10-03 18:53:47 - train: epoch 0297, iter [01090, 01251], lr: 0.000227, loss: 0.3952
2022-10-03 18:54:06 - train: epoch 0297, iter [01100, 01251], lr: 0.000227, loss: 0.4015
2022-10-03 18:54:24 - train: epoch 0297, iter [01110, 01251], lr: 0.000227, loss: 0.3882
2022-10-03 18:54:43 - train: epoch 0297, iter [01120, 01251], lr: 0.000227, loss: 0.3953
2022-10-03 18:55:01 - train: epoch 0297, iter [01130, 01251], lr: 0.000227, loss: 0.3973
2022-10-03 18:55:20 - train: epoch 0297, iter [01140, 01251], lr: 0.000227, loss: 0.3936
2022-10-03 18:55:39 - train: epoch 0297, iter [01150, 01251], lr: 0.000227, loss: 0.4021
2022-10-03 18:55:57 - train: epoch 0297, iter [01160, 01251], lr: 0.000227, loss: 0.3940
2022-10-03 18:56:16 - train: epoch 0297, iter [01170, 01251], lr: 0.000227, loss: 0.4145
2022-10-03 18:56:35 - train: epoch 0297, iter [01180, 01251], lr: 0.000227, loss: 0.4066
2022-10-03 18:56:53 - train: epoch 0297, iter [01190, 01251], lr: 0.000227, loss: 0.3861
2022-10-03 18:57:12 - train: epoch 0297, iter [01200, 01251], lr: 0.000227, loss: 0.3967
2022-10-03 18:57:30 - train: epoch 0297, iter [01210, 01251], lr: 0.000227, loss: 0.4037
2022-10-03 18:57:49 - train: epoch 0297, iter [01220, 01251], lr: 0.000227, loss: 0.3807
2022-10-03 18:58:07 - train: epoch 0297, iter [01230, 01251], lr: 0.000227, loss: 0.4157
2022-10-03 18:58:26 - train: epoch 0297, iter [01240, 01251], lr: 0.000227, loss: 0.3899
2022-10-03 18:58:44 - train: epoch 0297, iter [01250, 01251], lr: 0.000226, loss: 0.3879
2022-10-03 18:58:47 - train: epoch 297, train_loss: 0.3977
2022-10-03 18:58:50 - until epoch: 297, best_loss: 0.3977
2022-10-03 18:58:50 - epoch 298 lr: 0.000226
2022-10-03 18:59:16 - train: epoch 0298, iter [00010, 01251], lr: 0.000226, loss: 0.4265
2022-10-03 18:59:34 - train: epoch 0298, iter [00020, 01251], lr: 0.000226, loss: 0.3987
2022-10-03 18:59:53 - train: epoch 0298, iter [00030, 01251], lr: 0.000226, loss: 0.4001
2022-10-03 19:00:11 - train: epoch 0298, iter [00040, 01251], lr: 0.000226, loss: 0.4093
2022-10-03 19:00:30 - train: epoch 0298, iter [00050, 01251], lr: 0.000226, loss: 0.4014
2022-10-03 19:00:49 - train: epoch 0298, iter [00060, 01251], lr: 0.000226, loss: 0.4023
2022-10-03 19:01:07 - train: epoch 0298, iter [00070, 01251], lr: 0.000226, loss: 0.3848
2022-10-03 19:01:25 - train: epoch 0298, iter [00080, 01251], lr: 0.000226, loss: 0.3912
2022-10-03 19:01:44 - train: epoch 0298, iter [00090, 01251], lr: 0.000226, loss: 0.4014
2022-10-03 19:02:02 - train: epoch 0298, iter [00100, 01251], lr: 0.000226, loss: 0.3804
2022-10-03 19:02:21 - train: epoch 0298, iter [00110, 01251], lr: 0.000226, loss: 0.3777
2022-10-03 19:02:40 - train: epoch 0298, iter [00120, 01251], lr: 0.000226, loss: 0.3977
2022-10-03 19:02:58 - train: epoch 0298, iter [00130, 01251], lr: 0.000226, loss: 0.4018
2022-10-03 19:03:17 - train: epoch 0298, iter [00140, 01251], lr: 0.000226, loss: 0.4119
2022-10-03 19:03:35 - train: epoch 0298, iter [00150, 01251], lr: 0.000226, loss: 0.3748
2022-10-03 19:03:54 - train: epoch 0298, iter [00160, 01251], lr: 0.000226, loss: 0.4060
2022-10-03 19:04:13 - train: epoch 0298, iter [00170, 01251], lr: 0.000226, loss: 0.3598
2022-10-03 19:04:31 - train: epoch 0298, iter [00180, 01251], lr: 0.000226, loss: 0.3781
2022-10-03 19:04:50 - train: epoch 0298, iter [00190, 01251], lr: 0.000226, loss: 0.3888
2022-10-03 19:05:08 - train: epoch 0298, iter [00200, 01251], lr: 0.000226, loss: 0.4019
2022-10-03 19:05:27 - train: epoch 0298, iter [00210, 01251], lr: 0.000226, loss: 0.4108
2022-10-03 19:05:45 - train: epoch 0298, iter [00220, 01251], lr: 0.000226, loss: 0.4023
2022-10-03 19:06:04 - train: epoch 0298, iter [00230, 01251], lr: 0.000226, loss: 0.3999
2022-10-03 19:06:22 - train: epoch 0298, iter [00240, 01251], lr: 0.000226, loss: 0.3892
2022-10-03 19:06:41 - train: epoch 0298, iter [00250, 01251], lr: 0.000226, loss: 0.4041
2022-10-03 19:06:59 - train: epoch 0298, iter [00260, 01251], lr: 0.000226, loss: 0.3549
2022-10-03 19:07:18 - train: epoch 0298, iter [00270, 01251], lr: 0.000226, loss: 0.4055
2022-10-03 19:07:37 - train: epoch 0298, iter [00280, 01251], lr: 0.000226, loss: 0.4173
2022-10-03 19:07:55 - train: epoch 0298, iter [00290, 01251], lr: 0.000226, loss: 0.3930
2022-10-03 19:08:14 - train: epoch 0298, iter [00300, 01251], lr: 0.000226, loss: 0.4034
2022-10-03 19:08:32 - train: epoch 0298, iter [00310, 01251], lr: 0.000225, loss: 0.4002
2022-10-03 19:08:51 - train: epoch 0298, iter [00320, 01251], lr: 0.000225, loss: 0.3959
2022-10-03 19:09:09 - train: epoch 0298, iter [00330, 01251], lr: 0.000225, loss: 0.3990
2022-10-03 19:09:28 - train: epoch 0298, iter [00340, 01251], lr: 0.000225, loss: 0.4120
2022-10-03 19:09:46 - train: epoch 0298, iter [00350, 01251], lr: 0.000225, loss: 0.3915
2022-10-03 19:10:04 - train: epoch 0298, iter [00360, 01251], lr: 0.000225, loss: 0.3807
2022-10-03 19:10:23 - train: epoch 0298, iter [00370, 01251], lr: 0.000225, loss: 0.3888
2022-10-03 19:10:42 - train: epoch 0298, iter [00380, 01251], lr: 0.000225, loss: 0.4038
2022-10-03 19:11:00 - train: epoch 0298, iter [00390, 01251], lr: 0.000225, loss: 0.3834
2022-10-03 19:11:19 - train: epoch 0298, iter [00400, 01251], lr: 0.000225, loss: 0.4054
2022-10-03 19:11:37 - train: epoch 0298, iter [00410, 01251], lr: 0.000225, loss: 0.3998
2022-10-03 19:11:56 - train: epoch 0298, iter [00420, 01251], lr: 0.000225, loss: 0.3963
2022-10-03 19:12:14 - train: epoch 0298, iter [00430, 01251], lr: 0.000225, loss: 0.4015
2022-10-03 19:12:33 - train: epoch 0298, iter [00440, 01251], lr: 0.000225, loss: 0.3918
2022-10-03 19:12:52 - train: epoch 0298, iter [00450, 01251], lr: 0.000225, loss: 0.3963
2022-10-03 19:13:10 - train: epoch 0298, iter [00460, 01251], lr: 0.000225, loss: 0.3764
2022-10-03 19:13:29 - train: epoch 0298, iter [00470, 01251], lr: 0.000225, loss: 0.3944
2022-10-03 19:13:47 - train: epoch 0298, iter [00480, 01251], lr: 0.000225, loss: 0.3898
2022-10-03 19:14:06 - train: epoch 0298, iter [00490, 01251], lr: 0.000225, loss: 0.3988
2022-10-03 19:14:24 - train: epoch 0298, iter [00500, 01251], lr: 0.000225, loss: 0.4008
2022-10-03 19:14:43 - train: epoch 0298, iter [00510, 01251], lr: 0.000225, loss: 0.3974
2022-10-03 19:15:01 - train: epoch 0298, iter [00520, 01251], lr: 0.000225, loss: 0.4047
2022-10-03 19:15:20 - train: epoch 0298, iter [00530, 01251], lr: 0.000225, loss: 0.4006
2022-10-03 19:15:38 - train: epoch 0298, iter [00540, 01251], lr: 0.000225, loss: 0.4103
2022-10-03 19:15:57 - train: epoch 0298, iter [00550, 01251], lr: 0.000225, loss: 0.3960
2022-10-03 19:16:16 - train: epoch 0298, iter [00560, 01251], lr: 0.000225, loss: 0.3954
2022-10-03 19:16:34 - train: epoch 0298, iter [00570, 01251], lr: 0.000225, loss: 0.4117
2022-10-03 19:16:53 - train: epoch 0298, iter [00580, 01251], lr: 0.000225, loss: 0.4055
2022-10-03 19:17:11 - train: epoch 0298, iter [00590, 01251], lr: 0.000225, loss: 0.3830
2022-10-03 19:17:30 - train: epoch 0298, iter [00600, 01251], lr: 0.000225, loss: 0.3934
2022-10-03 19:17:49 - train: epoch 0298, iter [00610, 01251], lr: 0.000224, loss: 0.4225
2022-10-03 19:18:07 - train: epoch 0298, iter [00620, 01251], lr: 0.000224, loss: 0.4113
2022-10-03 19:18:26 - train: epoch 0298, iter [00630, 01251], lr: 0.000224, loss: 0.3729
2022-10-03 19:18:44 - train: epoch 0298, iter [00640, 01251], lr: 0.000224, loss: 0.3950
2022-10-03 19:19:02 - train: epoch 0298, iter [00650, 01251], lr: 0.000224, loss: 0.3867
2022-10-03 19:19:21 - train: epoch 0298, iter [00660, 01251], lr: 0.000224, loss: 0.4054
2022-10-03 19:19:39 - train: epoch 0298, iter [00670, 01251], lr: 0.000224, loss: 0.4024
2022-10-03 19:19:58 - train: epoch 0298, iter [00680, 01251], lr: 0.000224, loss: 0.4050
2022-10-03 19:20:16 - train: epoch 0298, iter [00690, 01251], lr: 0.000224, loss: 0.3992
2022-10-03 19:20:35 - train: epoch 0298, iter [00700, 01251], lr: 0.000224, loss: 0.3959
2022-10-03 19:20:53 - train: epoch 0298, iter [00710, 01251], lr: 0.000224, loss: 0.4158
2022-10-03 19:21:12 - train: epoch 0298, iter [00720, 01251], lr: 0.000224, loss: 0.3890
2022-10-03 19:21:30 - train: epoch 0298, iter [00730, 01251], lr: 0.000224, loss: 0.3936
2022-10-03 19:21:49 - train: epoch 0298, iter [00740, 01251], lr: 0.000224, loss: 0.3937
2022-10-03 19:22:07 - train: epoch 0298, iter [00750, 01251], lr: 0.000224, loss: 0.4081
2022-10-03 19:22:26 - train: epoch 0298, iter [00760, 01251], lr: 0.000224, loss: 0.3897
2022-10-03 19:22:44 - train: epoch 0298, iter [00770, 01251], lr: 0.000224, loss: 0.3973
2022-10-03 19:23:03 - train: epoch 0298, iter [00780, 01251], lr: 0.000224, loss: 0.3835
2022-10-03 19:23:22 - train: epoch 0298, iter [00790, 01251], lr: 0.000224, loss: 0.3864
2022-10-03 19:23:40 - train: epoch 0298, iter [00800, 01251], lr: 0.000224, loss: 0.3891
2022-10-03 19:23:59 - train: epoch 0298, iter [00810, 01251], lr: 0.000224, loss: 0.3856
2022-10-03 19:24:17 - train: epoch 0298, iter [00820, 01251], lr: 0.000224, loss: 0.3923
2022-10-03 19:24:36 - train: epoch 0298, iter [00830, 01251], lr: 0.000224, loss: 0.4187
2022-10-03 19:24:55 - train: epoch 0298, iter [00840, 01251], lr: 0.000224, loss: 0.3968
2022-10-03 19:25:13 - train: epoch 0298, iter [00850, 01251], lr: 0.000224, loss: 0.3871
2022-10-03 19:25:32 - train: epoch 0298, iter [00860, 01251], lr: 0.000224, loss: 0.3748
2022-10-03 19:25:50 - train: epoch 0298, iter [00870, 01251], lr: 0.000224, loss: 0.4034
2022-10-03 19:26:09 - train: epoch 0298, iter [00880, 01251], lr: 0.000224, loss: 0.4101
2022-10-03 19:26:27 - train: epoch 0298, iter [00890, 01251], lr: 0.000224, loss: 0.3865
2022-10-03 19:26:46 - train: epoch 0298, iter [00900, 01251], lr: 0.000224, loss: 0.3943
2022-10-03 19:27:04 - train: epoch 0298, iter [00910, 01251], lr: 0.000224, loss: 0.3876
2022-10-03 19:27:23 - train: epoch 0298, iter [00920, 01251], lr: 0.000223, loss: 0.3800
2022-10-03 19:27:42 - train: epoch 0298, iter [00930, 01251], lr: 0.000223, loss: 0.4044
2022-10-03 19:28:00 - train: epoch 0298, iter [00940, 01251], lr: 0.000223, loss: 0.3997
2022-10-03 19:28:19 - train: epoch 0298, iter [00950, 01251], lr: 0.000223, loss: 0.3999
2022-10-03 19:28:37 - train: epoch 0298, iter [00960, 01251], lr: 0.000223, loss: 0.3979
2022-10-03 19:28:56 - train: epoch 0298, iter [00970, 01251], lr: 0.000223, loss: 0.3848
2022-10-03 19:29:15 - train: epoch 0298, iter [00980, 01251], lr: 0.000223, loss: 0.3828
2022-10-03 19:29:33 - train: epoch 0298, iter [00990, 01251], lr: 0.000223, loss: 0.3948
2022-10-03 19:29:52 - train: epoch 0298, iter [01000, 01251], lr: 0.000223, loss: 0.3973
2022-10-03 19:30:10 - train: epoch 0298, iter [01010, 01251], lr: 0.000223, loss: 0.4132
2022-10-03 19:30:29 - train: epoch 0298, iter [01020, 01251], lr: 0.000223, loss: 0.3999
2022-10-03 19:30:48 - train: epoch 0298, iter [01030, 01251], lr: 0.000223, loss: 0.3929
2022-10-03 19:31:06 - train: epoch 0298, iter [01040, 01251], lr: 0.000223, loss: 0.4000
2022-10-03 19:31:25 - train: epoch 0298, iter [01050, 01251], lr: 0.000223, loss: 0.4117
2022-10-03 19:31:43 - train: epoch 0298, iter [01060, 01251], lr: 0.000223, loss: 0.4044
2022-10-03 19:32:02 - train: epoch 0298, iter [01070, 01251], lr: 0.000223, loss: 0.3983
2022-10-03 19:32:20 - train: epoch 0298, iter [01080, 01251], lr: 0.000223, loss: 0.3926
2022-10-03 19:32:39 - train: epoch 0298, iter [01090, 01251], lr: 0.000223, loss: 0.3934
2022-10-03 19:32:57 - train: epoch 0298, iter [01100, 01251], lr: 0.000223, loss: 0.3840
2022-10-03 19:33:15 - train: epoch 0298, iter [01110, 01251], lr: 0.000223, loss: 0.3895
2022-10-03 19:33:33 - train: epoch 0298, iter [01120, 01251], lr: 0.000223, loss: 0.4149
2022-10-03 19:33:51 - train: epoch 0298, iter [01130, 01251], lr: 0.000223, loss: 0.4043
2022-10-03 19:34:09 - train: epoch 0298, iter [01140, 01251], lr: 0.000223, loss: 0.4024
2022-10-03 19:34:28 - train: epoch 0298, iter [01150, 01251], lr: 0.000223, loss: 0.4059
2022-10-03 19:34:46 - train: epoch 0298, iter [01160, 01251], lr: 0.000223, loss: 0.4217
2022-10-03 19:35:04 - train: epoch 0298, iter [01170, 01251], lr: 0.000223, loss: 0.3927
2022-10-03 19:35:22 - train: epoch 0298, iter [01180, 01251], lr: 0.000223, loss: 0.4016
2022-10-03 19:35:40 - train: epoch 0298, iter [01190, 01251], lr: 0.000223, loss: 0.3915
2022-10-03 19:35:58 - train: epoch 0298, iter [01200, 01251], lr: 0.000223, loss: 0.4040
2022-10-03 19:36:16 - train: epoch 0298, iter [01210, 01251], lr: 0.000223, loss: 0.3827
2022-10-03 19:36:34 - train: epoch 0298, iter [01220, 01251], lr: 0.000223, loss: 0.3976
2022-10-03 19:36:52 - train: epoch 0298, iter [01230, 01251], lr: 0.000222, loss: 0.4016
2022-10-03 19:37:10 - train: epoch 0298, iter [01240, 01251], lr: 0.000222, loss: 0.3903
2022-10-03 19:37:28 - train: epoch 0298, iter [01250, 01251], lr: 0.000222, loss: 0.3823
2022-10-03 19:37:31 - train: epoch 298, train_loss: 0.3976
2022-10-03 19:37:34 - until epoch: 298, best_loss: 0.3976
2022-10-03 19:37:34 - epoch 299 lr: 0.000222
2022-10-03 19:37:59 - train: epoch 0299, iter [00010, 01251], lr: 0.000222, loss: 0.4056
2022-10-03 19:38:17 - train: epoch 0299, iter [00020, 01251], lr: 0.000222, loss: 0.3978
2022-10-03 19:38:35 - train: epoch 0299, iter [00030, 01251], lr: 0.000222, loss: 0.3870
2022-10-03 19:38:53 - train: epoch 0299, iter [00040, 01251], lr: 0.000222, loss: 0.4004
2022-10-03 19:39:11 - train: epoch 0299, iter [00050, 01251], lr: 0.000222, loss: 0.3918
2022-10-03 19:39:29 - train: epoch 0299, iter [00060, 01251], lr: 0.000222, loss: 0.4109
2022-10-03 19:39:47 - train: epoch 0299, iter [00070, 01251], lr: 0.000222, loss: 0.4060
2022-10-03 19:40:05 - train: epoch 0299, iter [00080, 01251], lr: 0.000222, loss: 0.3999
2022-10-03 19:40:23 - train: epoch 0299, iter [00090, 01251], lr: 0.000222, loss: 0.3938
2022-10-03 19:40:41 - train: epoch 0299, iter [00100, 01251], lr: 0.000222, loss: 0.3875
2022-10-03 19:40:59 - train: epoch 0299, iter [00110, 01251], lr: 0.000222, loss: 0.4112
2022-10-03 19:41:17 - train: epoch 0299, iter [00120, 01251], lr: 0.000222, loss: 0.3986
2022-10-03 19:41:35 - train: epoch 0299, iter [00130, 01251], lr: 0.000222, loss: 0.4062
2022-10-03 19:41:53 - train: epoch 0299, iter [00140, 01251], lr: 0.000222, loss: 0.3849
2022-10-03 19:42:10 - train: epoch 0299, iter [00150, 01251], lr: 0.000222, loss: 0.3807
2022-10-03 19:42:28 - train: epoch 0299, iter [00160, 01251], lr: 0.000222, loss: 0.4065
2022-10-03 19:42:46 - train: epoch 0299, iter [00170, 01251], lr: 0.000222, loss: 0.3778
2022-10-03 19:43:03 - train: epoch 0299, iter [00180, 01251], lr: 0.000222, loss: 0.3964
2022-10-03 19:43:22 - train: epoch 0299, iter [00190, 01251], lr: 0.000222, loss: 0.3972
2022-10-03 19:43:39 - train: epoch 0299, iter [00200, 01251], lr: 0.000222, loss: 0.3812
2022-10-03 19:43:57 - train: epoch 0299, iter [00210, 01251], lr: 0.000222, loss: 0.4107
2022-10-03 19:44:15 - train: epoch 0299, iter [00220, 01251], lr: 0.000222, loss: 0.4107
2022-10-03 19:44:34 - train: epoch 0299, iter [00230, 01251], lr: 0.000222, loss: 0.4002
2022-10-03 19:44:52 - train: epoch 0299, iter [00240, 01251], lr: 0.000222, loss: 0.3936
2022-10-03 19:45:10 - train: epoch 0299, iter [00250, 01251], lr: 0.000222, loss: 0.4075
2022-10-03 19:45:28 - train: epoch 0299, iter [00260, 01251], lr: 0.000222, loss: 0.3955
2022-10-03 19:45:46 - train: epoch 0299, iter [00270, 01251], lr: 0.000222, loss: 0.3899
2022-10-03 19:46:04 - train: epoch 0299, iter [00280, 01251], lr: 0.000221, loss: 0.4142
2022-10-03 19:46:22 - train: epoch 0299, iter [00290, 01251], lr: 0.000221, loss: 0.3850
2022-10-03 19:46:40 - train: epoch 0299, iter [00300, 01251], lr: 0.000221, loss: 0.3953
2022-10-03 19:46:58 - train: epoch 0299, iter [00310, 01251], lr: 0.000221, loss: 0.3824
2022-10-03 19:47:16 - train: epoch 0299, iter [00320, 01251], lr: 0.000221, loss: 0.4059
2022-10-03 19:47:34 - train: epoch 0299, iter [00330, 01251], lr: 0.000221, loss: 0.4030
2022-10-03 19:47:52 - train: epoch 0299, iter [00340, 01251], lr: 0.000221, loss: 0.3870
2022-10-03 19:48:10 - train: epoch 0299, iter [00350, 01251], lr: 0.000221, loss: 0.4040
2022-10-03 19:48:28 - train: epoch 0299, iter [00360, 01251], lr: 0.000221, loss: 0.3963
2022-10-03 19:48:46 - train: epoch 0299, iter [00370, 01251], lr: 0.000221, loss: 0.4125
2022-10-03 19:49:04 - train: epoch 0299, iter [00380, 01251], lr: 0.000221, loss: 0.3964
2022-10-03 19:49:22 - train: epoch 0299, iter [00390, 01251], lr: 0.000221, loss: 0.3895
2022-10-03 19:49:40 - train: epoch 0299, iter [00400, 01251], lr: 0.000221, loss: 0.3968
2022-10-03 19:49:58 - train: epoch 0299, iter [00410, 01251], lr: 0.000221, loss: 0.4025
2022-10-03 19:50:16 - train: epoch 0299, iter [00420, 01251], lr: 0.000221, loss: 0.4070
2022-10-03 19:50:35 - train: epoch 0299, iter [00430, 01251], lr: 0.000221, loss: 0.3954
2022-10-03 19:50:53 - train: epoch 0299, iter [00440, 01251], lr: 0.000221, loss: 0.3973
2022-10-03 19:51:11 - train: epoch 0299, iter [00450, 01251], lr: 0.000221, loss: 0.3776
2022-10-03 19:51:29 - train: epoch 0299, iter [00460, 01251], lr: 0.000221, loss: 0.3911
2022-10-03 19:51:47 - train: epoch 0299, iter [00470, 01251], lr: 0.000221, loss: 0.3893
2022-10-03 19:52:05 - train: epoch 0299, iter [00480, 01251], lr: 0.000221, loss: 0.3903
2022-10-03 19:52:23 - train: epoch 0299, iter [00490, 01251], lr: 0.000221, loss: 0.4105
2022-10-03 19:52:41 - train: epoch 0299, iter [00500, 01251], lr: 0.000221, loss: 0.3935
2022-10-03 19:52:59 - train: epoch 0299, iter [00510, 01251], lr: 0.000221, loss: 0.3915
2022-10-03 19:53:18 - train: epoch 0299, iter [00520, 01251], lr: 0.000221, loss: 0.4171
2022-10-03 19:53:36 - train: epoch 0299, iter [00530, 01251], lr: 0.000221, loss: 0.4027
2022-10-03 19:53:54 - train: epoch 0299, iter [00540, 01251], lr: 0.000221, loss: 0.4071
2022-10-03 19:54:12 - train: epoch 0299, iter [00550, 01251], lr: 0.000221, loss: 0.4036
2022-10-03 19:54:30 - train: epoch 0299, iter [00560, 01251], lr: 0.000221, loss: 0.3899
2022-10-03 19:54:48 - train: epoch 0299, iter [00570, 01251], lr: 0.000221, loss: 0.3960
2022-10-03 19:55:06 - train: epoch 0299, iter [00580, 01251], lr: 0.000221, loss: 0.3775
2022-10-03 19:55:24 - train: epoch 0299, iter [00590, 01251], lr: 0.000220, loss: 0.3909
2022-10-03 19:55:42 - train: epoch 0299, iter [00600, 01251], lr: 0.000220, loss: 0.3834
2022-10-03 19:56:01 - train: epoch 0299, iter [00610, 01251], lr: 0.000220, loss: 0.3904
2022-10-03 19:56:19 - train: epoch 0299, iter [00620, 01251], lr: 0.000220, loss: 0.3955
2022-10-03 19:56:37 - train: epoch 0299, iter [00630, 01251], lr: 0.000220, loss: 0.3945
2022-10-03 19:56:55 - train: epoch 0299, iter [00640, 01251], lr: 0.000220, loss: 0.4000
2022-10-03 19:57:13 - train: epoch 0299, iter [00650, 01251], lr: 0.000220, loss: 0.3844
2022-10-03 19:57:31 - train: epoch 0299, iter [00660, 01251], lr: 0.000220, loss: 0.4001
2022-10-03 19:57:49 - train: epoch 0299, iter [00670, 01251], lr: 0.000220, loss: 0.3780
2022-10-03 19:58:07 - train: epoch 0299, iter [00680, 01251], lr: 0.000220, loss: 0.4089
2022-10-03 19:58:25 - train: epoch 0299, iter [00690, 01251], lr: 0.000220, loss: 0.4012
2022-10-03 19:58:43 - train: epoch 0299, iter [00700, 01251], lr: 0.000220, loss: 0.3844
2022-10-03 19:59:02 - train: epoch 0299, iter [00710, 01251], lr: 0.000220, loss: 0.3926
2022-10-03 19:59:20 - train: epoch 0299, iter [00720, 01251], lr: 0.000220, loss: 0.4040
2022-10-03 19:59:38 - train: epoch 0299, iter [00730, 01251], lr: 0.000220, loss: 0.3913
2022-10-03 19:59:56 - train: epoch 0299, iter [00740, 01251], lr: 0.000220, loss: 0.3772
2022-10-03 20:00:14 - train: epoch 0299, iter [00750, 01251], lr: 0.000220, loss: 0.3968
2022-10-03 20:00:32 - train: epoch 0299, iter [00760, 01251], lr: 0.000220, loss: 0.4041
2022-10-03 20:00:50 - train: epoch 0299, iter [00770, 01251], lr: 0.000220, loss: 0.3983
2022-10-03 20:01:08 - train: epoch 0299, iter [00780, 01251], lr: 0.000220, loss: 0.4088
2022-10-03 20:01:26 - train: epoch 0299, iter [00790, 01251], lr: 0.000220, loss: 0.4044
2022-10-03 20:01:45 - train: epoch 0299, iter [00800, 01251], lr: 0.000220, loss: 0.3829
2022-10-03 20:02:03 - train: epoch 0299, iter [00810, 01251], lr: 0.000220, loss: 0.3973
2022-10-03 20:02:21 - train: epoch 0299, iter [00820, 01251], lr: 0.000220, loss: 0.3962
2022-10-03 20:02:39 - train: epoch 0299, iter [00830, 01251], lr: 0.000220, loss: 0.4096
2022-10-03 20:02:57 - train: epoch 0299, iter [00840, 01251], lr: 0.000220, loss: 0.3834
2022-10-03 20:03:15 - train: epoch 0299, iter [00850, 01251], lr: 0.000220, loss: 0.3916
2022-10-03 20:03:33 - train: epoch 0299, iter [00860, 01251], lr: 0.000220, loss: 0.4134
2022-10-03 20:03:51 - train: epoch 0299, iter [00870, 01251], lr: 0.000220, loss: 0.3861
2022-10-03 20:04:09 - train: epoch 0299, iter [00880, 01251], lr: 0.000220, loss: 0.3970
2022-10-03 20:04:27 - train: epoch 0299, iter [00890, 01251], lr: 0.000220, loss: 0.4011
2022-10-03 20:04:45 - train: epoch 0299, iter [00900, 01251], lr: 0.000219, loss: 0.4016
2022-10-03 20:05:03 - train: epoch 0299, iter [00910, 01251], lr: 0.000219, loss: 0.3921
2022-10-03 20:05:21 - train: epoch 0299, iter [00920, 01251], lr: 0.000219, loss: 0.4109
2022-10-03 20:05:39 - train: epoch 0299, iter [00930, 01251], lr: 0.000219, loss: 0.3968
2022-10-03 20:05:57 - train: epoch 0299, iter [00940, 01251], lr: 0.000219, loss: 0.4042
2022-10-03 20:06:15 - train: epoch 0299, iter [00950, 01251], lr: 0.000219, loss: 0.3874
2022-10-03 20:06:33 - train: epoch 0299, iter [00960, 01251], lr: 0.000219, loss: 0.3975
2022-10-03 20:06:51 - train: epoch 0299, iter [00970, 01251], lr: 0.000219, loss: 0.4192
2022-10-03 20:07:09 - train: epoch 0299, iter [00980, 01251], lr: 0.000219, loss: 0.4218
2022-10-03 20:07:27 - train: epoch 0299, iter [00990, 01251], lr: 0.000219, loss: 0.4098
2022-10-03 20:07:45 - train: epoch 0299, iter [01000, 01251], lr: 0.000219, loss: 0.3928
2022-10-03 20:08:03 - train: epoch 0299, iter [01010, 01251], lr: 0.000219, loss: 0.3963
2022-10-03 20:08:21 - train: epoch 0299, iter [01020, 01251], lr: 0.000219, loss: 0.4034
2022-10-03 20:08:39 - train: epoch 0299, iter [01030, 01251], lr: 0.000219, loss: 0.3955
2022-10-03 20:08:58 - train: epoch 0299, iter [01040, 01251], lr: 0.000219, loss: 0.3889
2022-10-03 20:09:15 - train: epoch 0299, iter [01050, 01251], lr: 0.000219, loss: 0.3902
2022-10-03 20:09:33 - train: epoch 0299, iter [01060, 01251], lr: 0.000219, loss: 0.4026
2022-10-03 20:09:52 - train: epoch 0299, iter [01070, 01251], lr: 0.000219, loss: 0.3861
2022-10-03 20:10:10 - train: epoch 0299, iter [01080, 01251], lr: 0.000219, loss: 0.3837
2022-10-03 20:10:28 - train: epoch 0299, iter [01090, 01251], lr: 0.000219, loss: 0.4052
2022-10-03 20:10:46 - train: epoch 0299, iter [01100, 01251], lr: 0.000219, loss: 0.4052
2022-10-03 20:11:04 - train: epoch 0299, iter [01110, 01251], lr: 0.000219, loss: 0.4009
2022-10-03 20:11:22 - train: epoch 0299, iter [01120, 01251], lr: 0.000219, loss: 0.4225
2022-10-03 20:11:40 - train: epoch 0299, iter [01130, 01251], lr: 0.000219, loss: 0.4004
2022-10-03 20:11:58 - train: epoch 0299, iter [01140, 01251], lr: 0.000219, loss: 0.3823
2022-10-03 20:12:16 - train: epoch 0299, iter [01150, 01251], lr: 0.000219, loss: 0.3955
2022-10-03 20:12:35 - train: epoch 0299, iter [01160, 01251], lr: 0.000219, loss: 0.4052
2022-10-03 20:12:53 - train: epoch 0299, iter [01170, 01251], lr: 0.000219, loss: 0.3818
2022-10-03 20:13:11 - train: epoch 0299, iter [01180, 01251], lr: 0.000219, loss: 0.4142
2022-10-03 20:13:29 - train: epoch 0299, iter [01190, 01251], lr: 0.000219, loss: 0.3954
2022-10-03 20:13:47 - train: epoch 0299, iter [01200, 01251], lr: 0.000219, loss: 0.3738
2022-10-03 20:14:05 - train: epoch 0299, iter [01210, 01251], lr: 0.000218, loss: 0.4068
2022-10-03 20:14:23 - train: epoch 0299, iter [01220, 01251], lr: 0.000218, loss: 0.3983
2022-10-03 20:14:41 - train: epoch 0299, iter [01230, 01251], lr: 0.000218, loss: 0.3935
2022-10-03 20:14:59 - train: epoch 0299, iter [01240, 01251], lr: 0.000218, loss: 0.4015
2022-10-03 20:15:17 - train: epoch 0299, iter [01250, 01251], lr: 0.000218, loss: 0.4214
2022-10-03 20:15:21 - train: epoch 299, train_loss: 0.3974
2022-10-03 20:15:23 - until epoch: 299, best_loss: 0.3974
2022-10-03 20:15:23 - epoch 300 lr: 0.000218
2022-10-03 20:15:49 - train: epoch 0300, iter [00010, 01251], lr: 0.000218, loss: 0.3945
2022-10-03 20:16:07 - train: epoch 0300, iter [00020, 01251], lr: 0.000218, loss: 0.3874
2022-10-03 20:16:25 - train: epoch 0300, iter [00030, 01251], lr: 0.000218, loss: 0.3978
2022-10-03 20:16:43 - train: epoch 0300, iter [00040, 01251], lr: 0.000218, loss: 0.3993
2022-10-03 20:17:01 - train: epoch 0300, iter [00050, 01251], lr: 0.000218, loss: 0.4199
2022-10-03 20:17:19 - train: epoch 0300, iter [00060, 01251], lr: 0.000218, loss: 0.4125
2022-10-03 20:17:37 - train: epoch 0300, iter [00070, 01251], lr: 0.000218, loss: 0.4033
2022-10-03 20:17:55 - train: epoch 0300, iter [00080, 01251], lr: 0.000218, loss: 0.3967
2022-10-03 20:18:13 - train: epoch 0300, iter [00090, 01251], lr: 0.000218, loss: 0.4007
2022-10-03 20:18:32 - train: epoch 0300, iter [00100, 01251], lr: 0.000218, loss: 0.4012
2022-10-03 20:18:50 - train: epoch 0300, iter [00110, 01251], lr: 0.000218, loss: 0.4072
2022-10-03 20:19:08 - train: epoch 0300, iter [00120, 01251], lr: 0.000218, loss: 0.3948
2022-10-03 20:19:26 - train: epoch 0300, iter [00130, 01251], lr: 0.000218, loss: 0.3879
2022-10-03 20:19:44 - train: epoch 0300, iter [00140, 01251], lr: 0.000218, loss: 0.4100
2022-10-03 20:20:02 - train: epoch 0300, iter [00150, 01251], lr: 0.000218, loss: 0.3853
2022-10-03 20:20:20 - train: epoch 0300, iter [00160, 01251], lr: 0.000218, loss: 0.3900
2022-10-03 20:20:38 - train: epoch 0300, iter [00170, 01251], lr: 0.000218, loss: 0.3965
2022-10-03 20:20:56 - train: epoch 0300, iter [00180, 01251], lr: 0.000218, loss: 0.4026
2022-10-03 20:21:14 - train: epoch 0300, iter [00190, 01251], lr: 0.000218, loss: 0.4072
2022-10-03 20:21:32 - train: epoch 0300, iter [00200, 01251], lr: 0.000218, loss: 0.3841
2022-10-03 20:21:50 - train: epoch 0300, iter [00210, 01251], lr: 0.000218, loss: 0.4011
2022-10-03 20:22:08 - train: epoch 0300, iter [00220, 01251], lr: 0.000218, loss: 0.3914
2022-10-03 20:22:26 - train: epoch 0300, iter [00230, 01251], lr: 0.000218, loss: 0.3872
2022-10-03 20:22:44 - train: epoch 0300, iter [00240, 01251], lr: 0.000218, loss: 0.3993
2022-10-03 20:23:02 - train: epoch 0300, iter [00250, 01251], lr: 0.000218, loss: 0.3967
2022-10-03 20:23:20 - train: epoch 0300, iter [00260, 01251], lr: 0.000218, loss: 0.4031
2022-10-03 20:23:38 - train: epoch 0300, iter [00270, 01251], lr: 0.000217, loss: 0.3818
2022-10-03 20:23:56 - train: epoch 0300, iter [00280, 01251], lr: 0.000217, loss: 0.3801
2022-10-03 20:24:15 - train: epoch 0300, iter [00290, 01251], lr: 0.000217, loss: 0.3912
2022-10-03 20:24:33 - train: epoch 0300, iter [00300, 01251], lr: 0.000217, loss: 0.3866
2022-10-03 20:24:51 - train: epoch 0300, iter [00310, 01251], lr: 0.000217, loss: 0.3854
2022-10-03 20:25:09 - train: epoch 0300, iter [00320, 01251], lr: 0.000217, loss: 0.3925
2022-10-03 20:25:27 - train: epoch 0300, iter [00330, 01251], lr: 0.000217, loss: 0.3771
2022-10-03 20:25:45 - train: epoch 0300, iter [00340, 01251], lr: 0.000217, loss: 0.4012
2022-10-03 20:26:03 - train: epoch 0300, iter [00350, 01251], lr: 0.000217, loss: 0.3915
2022-10-03 20:26:21 - train: epoch 0300, iter [00360, 01251], lr: 0.000217, loss: 0.4009
2022-10-03 20:26:40 - train: epoch 0300, iter [00370, 01251], lr: 0.000217, loss: 0.3921
2022-10-03 20:26:58 - train: epoch 0300, iter [00380, 01251], lr: 0.000217, loss: 0.4221
2022-10-03 20:27:16 - train: epoch 0300, iter [00390, 01251], lr: 0.000217, loss: 0.3843
2022-10-03 20:27:34 - train: epoch 0300, iter [00400, 01251], lr: 0.000217, loss: 0.3886
2022-10-03 20:27:52 - train: epoch 0300, iter [00410, 01251], lr: 0.000217, loss: 0.3834
2022-10-03 20:28:10 - train: epoch 0300, iter [00420, 01251], lr: 0.000217, loss: 0.3944
2022-10-03 20:28:28 - train: epoch 0300, iter [00430, 01251], lr: 0.000217, loss: 0.3854
2022-10-03 20:28:46 - train: epoch 0300, iter [00440, 01251], lr: 0.000217, loss: 0.4083
2022-10-03 20:29:04 - train: epoch 0300, iter [00450, 01251], lr: 0.000217, loss: 0.4053
2022-10-03 20:29:22 - train: epoch 0300, iter [00460, 01251], lr: 0.000217, loss: 0.3971
2022-10-03 20:29:40 - train: epoch 0300, iter [00470, 01251], lr: 0.000217, loss: 0.4124
2022-10-03 20:29:59 - train: epoch 0300, iter [00480, 01251], lr: 0.000217, loss: 0.3768
2022-10-03 20:30:17 - train: epoch 0300, iter [00490, 01251], lr: 0.000217, loss: 0.4148
2022-10-03 20:30:35 - train: epoch 0300, iter [00500, 01251], lr: 0.000217, loss: 0.3999
2022-10-03 20:30:53 - train: epoch 0300, iter [00510, 01251], lr: 0.000217, loss: 0.3933
2022-10-03 20:31:11 - train: epoch 0300, iter [00520, 01251], lr: 0.000217, loss: 0.3918
2022-10-03 20:31:29 - train: epoch 0300, iter [00530, 01251], lr: 0.000217, loss: 0.3788
2022-10-03 20:31:47 - train: epoch 0300, iter [00540, 01251], lr: 0.000217, loss: 0.4069
2022-10-03 20:32:05 - train: epoch 0300, iter [00550, 01251], lr: 0.000217, loss: 0.3919
2022-10-03 20:32:23 - train: epoch 0300, iter [00560, 01251], lr: 0.000217, loss: 0.4080
2022-10-03 20:32:41 - train: epoch 0300, iter [00570, 01251], lr: 0.000217, loss: 0.3820
2022-10-03 20:32:59 - train: epoch 0300, iter [00580, 01251], lr: 0.000216, loss: 0.3816
2022-10-03 20:33:18 - train: epoch 0300, iter [00590, 01251], lr: 0.000216, loss: 0.3986
2022-10-03 20:33:35 - train: epoch 0300, iter [00600, 01251], lr: 0.000216, loss: 0.3998
2022-10-03 20:33:53 - train: epoch 0300, iter [00610, 01251], lr: 0.000216, loss: 0.3886
2022-10-03 20:34:11 - train: epoch 0300, iter [00620, 01251], lr: 0.000216, loss: 0.3729
2022-10-03 20:34:29 - train: epoch 0300, iter [00630, 01251], lr: 0.000216, loss: 0.4216
2022-10-03 20:34:47 - train: epoch 0300, iter [00640, 01251], lr: 0.000216, loss: 0.3873
2022-10-03 20:35:06 - train: epoch 0300, iter [00650, 01251], lr: 0.000216, loss: 0.4092
2022-10-03 20:35:24 - train: epoch 0300, iter [00660, 01251], lr: 0.000216, loss: 0.3922
2022-10-03 20:35:41 - train: epoch 0300, iter [00670, 01251], lr: 0.000216, loss: 0.4022
2022-10-03 20:36:00 - train: epoch 0300, iter [00680, 01251], lr: 0.000216, loss: 0.3868
2022-10-03 20:36:18 - train: epoch 0300, iter [00690, 01251], lr: 0.000216, loss: 0.3986
2022-10-03 20:36:36 - train: epoch 0300, iter [00700, 01251], lr: 0.000216, loss: 0.3828
2022-10-03 20:36:54 - train: epoch 0300, iter [00710, 01251], lr: 0.000216, loss: 0.3731
2022-10-03 20:37:12 - train: epoch 0300, iter [00720, 01251], lr: 0.000216, loss: 0.4033
2022-10-03 20:37:30 - train: epoch 0300, iter [00730, 01251], lr: 0.000216, loss: 0.3981
2022-10-03 20:37:48 - train: epoch 0300, iter [00740, 01251], lr: 0.000216, loss: 0.3590
2022-10-03 20:38:06 - train: epoch 0300, iter [00750, 01251], lr: 0.000216, loss: 0.3943
2022-10-03 20:38:25 - train: epoch 0300, iter [00760, 01251], lr: 0.000216, loss: 0.4132
2022-10-03 20:38:43 - train: epoch 0300, iter [00770, 01251], lr: 0.000216, loss: 0.3827
2022-10-03 20:39:01 - train: epoch 0300, iter [00780, 01251], lr: 0.000216, loss: 0.3902
2022-10-03 20:39:19 - train: epoch 0300, iter [00790, 01251], lr: 0.000216, loss: 0.4032
2022-10-03 20:39:37 - train: epoch 0300, iter [00800, 01251], lr: 0.000216, loss: 0.3863
2022-10-03 20:39:55 - train: epoch 0300, iter [00810, 01251], lr: 0.000216, loss: 0.3736
2022-10-03 20:40:13 - train: epoch 0300, iter [00820, 01251], lr: 0.000216, loss: 0.3958
2022-10-03 20:40:31 - train: epoch 0300, iter [00830, 01251], lr: 0.000216, loss: 0.4284
2022-10-03 20:40:49 - train: epoch 0300, iter [00840, 01251], lr: 0.000216, loss: 0.4000
2022-10-03 20:41:07 - train: epoch 0300, iter [00850, 01251], lr: 0.000216, loss: 0.4093
2022-10-03 20:41:25 - train: epoch 0300, iter [00860, 01251], lr: 0.000216, loss: 0.3946
2022-10-03 20:41:43 - train: epoch 0300, iter [00870, 01251], lr: 0.000216, loss: 0.3740
2022-10-03 20:42:01 - train: epoch 0300, iter [00880, 01251], lr: 0.000216, loss: 0.4123
2022-10-03 20:42:19 - train: epoch 0300, iter [00890, 01251], lr: 0.000215, loss: 0.4050
2022-10-03 20:42:37 - train: epoch 0300, iter [00900, 01251], lr: 0.000215, loss: 0.4192
2022-10-03 20:42:55 - train: epoch 0300, iter [00910, 01251], lr: 0.000215, loss: 0.4046
2022-10-03 20:43:13 - train: epoch 0300, iter [00920, 01251], lr: 0.000215, loss: 0.3896
2022-10-03 20:43:31 - train: epoch 0300, iter [00930, 01251], lr: 0.000215, loss: 0.3875
2022-10-03 20:43:49 - train: epoch 0300, iter [00940, 01251], lr: 0.000215, loss: 0.3888
2022-10-03 20:44:07 - train: epoch 0300, iter [00950, 01251], lr: 0.000215, loss: 0.3859
2022-10-03 20:44:25 - train: epoch 0300, iter [00960, 01251], lr: 0.000215, loss: 0.3856
2022-10-03 20:44:44 - train: epoch 0300, iter [00970, 01251], lr: 0.000215, loss: 0.4169
2022-10-03 20:45:02 - train: epoch 0300, iter [00980, 01251], lr: 0.000215, loss: 0.4047
2022-10-03 20:45:20 - train: epoch 0300, iter [00990, 01251], lr: 0.000215, loss: 0.3916
2022-10-03 20:45:38 - train: epoch 0300, iter [01000, 01251], lr: 0.000215, loss: 0.3887
2022-10-03 20:45:56 - train: epoch 0300, iter [01010, 01251], lr: 0.000215, loss: 0.3981
2022-10-03 20:46:14 - train: epoch 0300, iter [01020, 01251], lr: 0.000215, loss: 0.3899
2022-10-03 20:46:32 - train: epoch 0300, iter [01030, 01251], lr: 0.000215, loss: 0.3986
2022-10-03 20:46:50 - train: epoch 0300, iter [01040, 01251], lr: 0.000215, loss: 0.4002
2022-10-03 20:47:08 - train: epoch 0300, iter [01050, 01251], lr: 0.000215, loss: 0.3979
2022-10-03 20:47:26 - train: epoch 0300, iter [01060, 01251], lr: 0.000215, loss: 0.4007
2022-10-03 20:47:44 - train: epoch 0300, iter [01070, 01251], lr: 0.000215, loss: 0.3927
2022-10-03 20:48:02 - train: epoch 0300, iter [01080, 01251], lr: 0.000215, loss: 0.4104
2022-10-03 20:48:20 - train: epoch 0300, iter [01090, 01251], lr: 0.000215, loss: 0.3965
2022-10-03 20:48:38 - train: epoch 0300, iter [01100, 01251], lr: 0.000215, loss: 0.4009
2022-10-03 20:48:56 - train: epoch 0300, iter [01110, 01251], lr: 0.000215, loss: 0.4032
2022-10-03 20:49:14 - train: epoch 0300, iter [01120, 01251], lr: 0.000215, loss: 0.4154
2022-10-03 20:49:33 - train: epoch 0300, iter [01130, 01251], lr: 0.000215, loss: 0.4097
2022-10-03 20:49:51 - train: epoch 0300, iter [01140, 01251], lr: 0.000215, loss: 0.4140
2022-10-03 20:50:09 - train: epoch 0300, iter [01150, 01251], lr: 0.000215, loss: 0.4093
2022-10-03 20:50:27 - train: epoch 0300, iter [01160, 01251], lr: 0.000215, loss: 0.4097
2022-10-03 20:50:45 - train: epoch 0300, iter [01170, 01251], lr: 0.000215, loss: 0.4021
2022-10-03 20:51:03 - train: epoch 0300, iter [01180, 01251], lr: 0.000215, loss: 0.4140
2022-10-03 20:51:21 - train: epoch 0300, iter [01190, 01251], lr: 0.000215, loss: 0.4065
2022-10-03 20:51:39 - train: epoch 0300, iter [01200, 01251], lr: 0.000214, loss: 0.4207
2022-10-03 20:51:58 - train: epoch 0300, iter [01210, 01251], lr: 0.000214, loss: 0.3794
2022-10-03 20:52:16 - train: epoch 0300, iter [01220, 01251], lr: 0.000214, loss: 0.4037
2022-10-03 20:52:34 - train: epoch 0300, iter [01230, 01251], lr: 0.000214, loss: 0.4178
2022-10-03 20:52:52 - train: epoch 0300, iter [01240, 01251], lr: 0.000214, loss: 0.3938
2022-10-03 20:53:10 - train: epoch 0300, iter [01250, 01251], lr: 0.000214, loss: 0.4118
2022-10-03 20:53:13 - train: epoch 300, train_loss: 0.3974
2022-10-03 20:53:16 - until epoch: 300, best_loss: 0.3974
2022-10-03 20:53:16 - epoch 301 lr: 0.000214
2022-10-03 20:53:41 - train: epoch 0301, iter [00010, 01251], lr: 0.000214, loss: 0.4072
2022-10-03 20:53:59 - train: epoch 0301, iter [00020, 01251], lr: 0.000214, loss: 0.4068
2022-10-03 20:54:17 - train: epoch 0301, iter [00030, 01251], lr: 0.000214, loss: 0.3883
2022-10-03 20:54:34 - train: epoch 0301, iter [00040, 01251], lr: 0.000214, loss: 0.3898
2022-10-03 20:54:52 - train: epoch 0301, iter [00050, 01251], lr: 0.000214, loss: 0.3980
2022-10-03 20:55:11 - train: epoch 0301, iter [00060, 01251], lr: 0.000214, loss: 0.3923
2022-10-03 20:55:29 - train: epoch 0301, iter [00070, 01251], lr: 0.000214, loss: 0.3888
2022-10-03 20:55:47 - train: epoch 0301, iter [00080, 01251], lr: 0.000214, loss: 0.3856
2022-10-03 20:56:05 - train: epoch 0301, iter [00090, 01251], lr: 0.000214, loss: 0.3811
2022-10-03 20:56:23 - train: epoch 0301, iter [00100, 01251], lr: 0.000214, loss: 0.4186
2022-10-03 20:56:41 - train: epoch 0301, iter [00110, 01251], lr: 0.000214, loss: 0.3919
2022-10-03 20:56:59 - train: epoch 0301, iter [00120, 01251], lr: 0.000214, loss: 0.4081
2022-10-03 20:57:17 - train: epoch 0301, iter [00130, 01251], lr: 0.000214, loss: 0.4091
2022-10-03 20:57:35 - train: epoch 0301, iter [00140, 01251], lr: 0.000214, loss: 0.3983
2022-10-03 20:57:53 - train: epoch 0301, iter [00150, 01251], lr: 0.000214, loss: 0.4097
2022-10-03 20:58:11 - train: epoch 0301, iter [00160, 01251], lr: 0.000214, loss: 0.3975
2022-10-03 20:58:29 - train: epoch 0301, iter [00170, 01251], lr: 0.000214, loss: 0.4140
2022-10-03 20:58:47 - train: epoch 0301, iter [00180, 01251], lr: 0.000214, loss: 0.3846
2022-10-03 20:59:05 - train: epoch 0301, iter [00190, 01251], lr: 0.000214, loss: 0.4127
2022-10-03 20:59:23 - train: epoch 0301, iter [00200, 01251], lr: 0.000214, loss: 0.3800
2022-10-03 20:59:41 - train: epoch 0301, iter [00210, 01251], lr: 0.000214, loss: 0.4023
2022-10-03 20:59:59 - train: epoch 0301, iter [00220, 01251], lr: 0.000214, loss: 0.4045
2022-10-03 21:00:17 - train: epoch 0301, iter [00230, 01251], lr: 0.000214, loss: 0.4016
2022-10-03 21:00:35 - train: epoch 0301, iter [00240, 01251], lr: 0.000214, loss: 0.4169
2022-10-03 21:00:54 - train: epoch 0301, iter [00250, 01251], lr: 0.000214, loss: 0.3869
2022-10-03 21:01:12 - train: epoch 0301, iter [00260, 01251], lr: 0.000213, loss: 0.4043
2022-10-03 21:01:30 - train: epoch 0301, iter [00270, 01251], lr: 0.000213, loss: 0.3976
2022-10-03 21:01:48 - train: epoch 0301, iter [00280, 01251], lr: 0.000213, loss: 0.3969
2022-10-03 21:02:06 - train: epoch 0301, iter [00290, 01251], lr: 0.000213, loss: 0.4129
2022-10-03 21:02:24 - train: epoch 0301, iter [00300, 01251], lr: 0.000213, loss: 0.3997
2022-10-03 21:02:42 - train: epoch 0301, iter [00310, 01251], lr: 0.000213, loss: 0.4059
2022-10-03 21:03:00 - train: epoch 0301, iter [00320, 01251], lr: 0.000213, loss: 0.3939
2022-10-03 21:03:18 - train: epoch 0301, iter [00330, 01251], lr: 0.000213, loss: 0.3886
2022-10-03 21:03:36 - train: epoch 0301, iter [00340, 01251], lr: 0.000213, loss: 0.3997
2022-10-03 21:03:55 - train: epoch 0301, iter [00350, 01251], lr: 0.000213, loss: 0.4154
2022-10-03 21:04:13 - train: epoch 0301, iter [00360, 01251], lr: 0.000213, loss: 0.3958
2022-10-03 21:04:31 - train: epoch 0301, iter [00370, 01251], lr: 0.000213, loss: 0.4203
2022-10-03 21:04:49 - train: epoch 0301, iter [00380, 01251], lr: 0.000213, loss: 0.4062
2022-10-03 21:05:07 - train: epoch 0301, iter [00390, 01251], lr: 0.000213, loss: 0.3961
2022-10-03 21:05:25 - train: epoch 0301, iter [00400, 01251], lr: 0.000213, loss: 0.3959
2022-10-03 21:05:43 - train: epoch 0301, iter [00410, 01251], lr: 0.000213, loss: 0.4147
2022-10-03 21:06:01 - train: epoch 0301, iter [00420, 01251], lr: 0.000213, loss: 0.3869
2022-10-03 21:06:20 - train: epoch 0301, iter [00430, 01251], lr: 0.000213, loss: 0.4038
2022-10-03 21:06:38 - train: epoch 0301, iter [00440, 01251], lr: 0.000213, loss: 0.3846
2022-10-03 21:06:56 - train: epoch 0301, iter [00450, 01251], lr: 0.000213, loss: 0.3990
2022-10-03 21:07:14 - train: epoch 0301, iter [00460, 01251], lr: 0.000213, loss: 0.4139
2022-10-03 21:07:32 - train: epoch 0301, iter [00470, 01251], lr: 0.000213, loss: 0.3994
2022-10-03 21:07:50 - train: epoch 0301, iter [00480, 01251], lr: 0.000213, loss: 0.4021
2022-10-03 21:08:08 - train: epoch 0301, iter [00490, 01251], lr: 0.000213, loss: 0.3991
2022-10-03 21:08:27 - train: epoch 0301, iter [00500, 01251], lr: 0.000213, loss: 0.3737
2022-10-03 21:08:45 - train: epoch 0301, iter [00510, 01251], lr: 0.000213, loss: 0.4267
2022-10-03 21:09:03 - train: epoch 0301, iter [00520, 01251], lr: 0.000213, loss: 0.4014
2022-10-03 21:09:21 - train: epoch 0301, iter [00530, 01251], lr: 0.000213, loss: 0.4097
2022-10-03 21:09:39 - train: epoch 0301, iter [00540, 01251], lr: 0.000213, loss: 0.4007
2022-10-03 21:09:57 - train: epoch 0301, iter [00550, 01251], lr: 0.000213, loss: 0.3852
2022-10-03 21:10:15 - train: epoch 0301, iter [00560, 01251], lr: 0.000213, loss: 0.3988
2022-10-03 21:10:33 - train: epoch 0301, iter [00570, 01251], lr: 0.000213, loss: 0.4138
2022-10-03 21:10:51 - train: epoch 0301, iter [00580, 01251], lr: 0.000212, loss: 0.4144
2022-10-03 21:11:10 - train: epoch 0301, iter [00590, 01251], lr: 0.000212, loss: 0.3880
2022-10-03 21:11:28 - train: epoch 0301, iter [00600, 01251], lr: 0.000212, loss: 0.4009
2022-10-03 21:11:46 - train: epoch 0301, iter [00610, 01251], lr: 0.000212, loss: 0.3987
2022-10-03 21:12:04 - train: epoch 0301, iter [00620, 01251], lr: 0.000212, loss: 0.3992
2022-10-03 21:12:22 - train: epoch 0301, iter [00630, 01251], lr: 0.000212, loss: 0.4104
2022-10-03 21:12:40 - train: epoch 0301, iter [00640, 01251], lr: 0.000212, loss: 0.4019
2022-10-03 21:12:58 - train: epoch 0301, iter [00650, 01251], lr: 0.000212, loss: 0.4125
2022-10-03 21:13:16 - train: epoch 0301, iter [00660, 01251], lr: 0.000212, loss: 0.3822
2022-10-03 21:13:34 - train: epoch 0301, iter [00670, 01251], lr: 0.000212, loss: 0.3857
2022-10-03 21:13:53 - train: epoch 0301, iter [00680, 01251], lr: 0.000212, loss: 0.3916
2022-10-03 21:14:11 - train: epoch 0301, iter [00690, 01251], lr: 0.000212, loss: 0.4226
2022-10-03 21:14:29 - train: epoch 0301, iter [00700, 01251], lr: 0.000212, loss: 0.4016
2022-10-03 21:14:47 - train: epoch 0301, iter [00710, 01251], lr: 0.000212, loss: 0.3892
2022-10-03 21:15:05 - train: epoch 0301, iter [00720, 01251], lr: 0.000212, loss: 0.3863
2022-10-03 21:15:23 - train: epoch 0301, iter [00730, 01251], lr: 0.000212, loss: 0.4034
2022-10-03 21:15:41 - train: epoch 0301, iter [00740, 01251], lr: 0.000212, loss: 0.3868
2022-10-03 21:15:59 - train: epoch 0301, iter [00750, 01251], lr: 0.000212, loss: 0.4123
2022-10-03 21:16:17 - train: epoch 0301, iter [00760, 01251], lr: 0.000212, loss: 0.4064
2022-10-03 21:16:35 - train: epoch 0301, iter [00770, 01251], lr: 0.000212, loss: 0.4063
2022-10-03 21:16:53 - train: epoch 0301, iter [00780, 01251], lr: 0.000212, loss: 0.4077
2022-10-03 21:17:11 - train: epoch 0301, iter [00790, 01251], lr: 0.000212, loss: 0.3907
2022-10-03 21:17:29 - train: epoch 0301, iter [00800, 01251], lr: 0.000212, loss: 0.4062
2022-10-03 21:17:47 - train: epoch 0301, iter [00810, 01251], lr: 0.000212, loss: 0.3833
2022-10-03 21:18:06 - train: epoch 0301, iter [00820, 01251], lr: 0.000212, loss: 0.4108
2022-10-03 21:18:24 - train: epoch 0301, iter [00830, 01251], lr: 0.000212, loss: 0.3909
2022-10-03 21:18:42 - train: epoch 0301, iter [00840, 01251], lr: 0.000212, loss: 0.4035
2022-10-03 21:19:00 - train: epoch 0301, iter [00850, 01251], lr: 0.000212, loss: 0.3997
2022-10-03 21:19:18 - train: epoch 0301, iter [00860, 01251], lr: 0.000212, loss: 0.4000
2022-10-03 21:19:36 - train: epoch 0301, iter [00870, 01251], lr: 0.000212, loss: 0.4103
2022-10-03 21:19:54 - train: epoch 0301, iter [00880, 01251], lr: 0.000212, loss: 0.3990
2022-10-03 21:20:12 - train: epoch 0301, iter [00890, 01251], lr: 0.000211, loss: 0.4130
2022-10-03 21:20:30 - train: epoch 0301, iter [00900, 01251], lr: 0.000211, loss: 0.3868
2022-10-03 21:20:48 - train: epoch 0301, iter [00910, 01251], lr: 0.000211, loss: 0.3979
2022-10-03 21:21:06 - train: epoch 0301, iter [00920, 01251], lr: 0.000211, loss: 0.3971
2022-10-03 21:21:24 - train: epoch 0301, iter [00930, 01251], lr: 0.000211, loss: 0.3939
2022-10-03 21:21:42 - train: epoch 0301, iter [00940, 01251], lr: 0.000211, loss: 0.4029
2022-10-03 21:22:00 - train: epoch 0301, iter [00950, 01251], lr: 0.000211, loss: 0.3940
2022-10-03 21:22:18 - train: epoch 0301, iter [00960, 01251], lr: 0.000211, loss: 0.3962
2022-10-03 21:22:36 - train: epoch 0301, iter [00970, 01251], lr: 0.000211, loss: 0.4063
2022-10-03 21:22:54 - train: epoch 0301, iter [00980, 01251], lr: 0.000211, loss: 0.4115
2022-10-03 21:23:12 - train: epoch 0301, iter [00990, 01251], lr: 0.000211, loss: 0.3928
2022-10-03 21:23:30 - train: epoch 0301, iter [01000, 01251], lr: 0.000211, loss: 0.3881
2022-10-03 21:23:49 - train: epoch 0301, iter [01010, 01251], lr: 0.000211, loss: 0.3791
2022-10-03 21:24:07 - train: epoch 0301, iter [01020, 01251], lr: 0.000211, loss: 0.3808
2022-10-03 21:24:25 - train: epoch 0301, iter [01030, 01251], lr: 0.000211, loss: 0.3953
2022-10-03 21:24:43 - train: epoch 0301, iter [01040, 01251], lr: 0.000211, loss: 0.4070
2022-10-03 21:25:01 - train: epoch 0301, iter [01050, 01251], lr: 0.000211, loss: 0.3942
2022-10-03 21:25:19 - train: epoch 0301, iter [01060, 01251], lr: 0.000211, loss: 0.4032
2022-10-03 21:25:37 - train: epoch 0301, iter [01070, 01251], lr: 0.000211, loss: 0.3759
2022-10-03 21:25:56 - train: epoch 0301, iter [01080, 01251], lr: 0.000211, loss: 0.3945
2022-10-03 21:26:14 - train: epoch 0301, iter [01090, 01251], lr: 0.000211, loss: 0.3869
2022-10-03 21:26:32 - train: epoch 0301, iter [01100, 01251], lr: 0.000211, loss: 0.4128
2022-10-03 21:26:50 - train: epoch 0301, iter [01110, 01251], lr: 0.000211, loss: 0.3792
2022-10-03 21:27:08 - train: epoch 0301, iter [01120, 01251], lr: 0.000211, loss: 0.3927
2022-10-03 21:27:26 - train: epoch 0301, iter [01130, 01251], lr: 0.000211, loss: 0.3965
2022-10-03 21:27:44 - train: epoch 0301, iter [01140, 01251], lr: 0.000211, loss: 0.4015
2022-10-03 21:28:02 - train: epoch 0301, iter [01150, 01251], lr: 0.000211, loss: 0.3947
2022-10-03 21:28:20 - train: epoch 0301, iter [01160, 01251], lr: 0.000211, loss: 0.3948
2022-10-03 21:28:39 - train: epoch 0301, iter [01170, 01251], lr: 0.000211, loss: 0.3845
2022-10-03 21:28:57 - train: epoch 0301, iter [01180, 01251], lr: 0.000211, loss: 0.4078
2022-10-03 21:29:15 - train: epoch 0301, iter [01190, 01251], lr: 0.000211, loss: 0.4000
2022-10-03 21:29:33 - train: epoch 0301, iter [01200, 01251], lr: 0.000210, loss: 0.4098
2022-10-03 21:29:51 - train: epoch 0301, iter [01210, 01251], lr: 0.000210, loss: 0.4023
2022-10-03 21:30:09 - train: epoch 0301, iter [01220, 01251], lr: 0.000210, loss: 0.3949
2022-10-03 21:30:27 - train: epoch 0301, iter [01230, 01251], lr: 0.000210, loss: 0.4014
2022-10-03 21:30:45 - train: epoch 0301, iter [01240, 01251], lr: 0.000210, loss: 0.3941
2022-10-03 21:31:03 - train: epoch 0301, iter [01250, 01251], lr: 0.000210, loss: 0.3984
2022-10-03 21:31:06 - train: epoch 301, train_loss: 0.3972
2022-10-03 21:31:09 - until epoch: 301, best_loss: 0.3972
2022-10-03 21:31:09 - epoch 302 lr: 0.000210
2022-10-03 21:31:35 - train: epoch 0302, iter [00010, 01251], lr: 0.000210, loss: 0.3889
2022-10-03 21:31:52 - train: epoch 0302, iter [00020, 01251], lr: 0.000210, loss: 0.4060
2022-10-03 21:32:10 - train: epoch 0302, iter [00030, 01251], lr: 0.000210, loss: 0.3898
2022-10-03 21:32:29 - train: epoch 0302, iter [00040, 01251], lr: 0.000210, loss: 0.4149
2022-10-03 21:32:47 - train: epoch 0302, iter [00050, 01251], lr: 0.000210, loss: 0.3940
2022-10-03 21:33:05 - train: epoch 0302, iter [00060, 01251], lr: 0.000210, loss: 0.3874
2022-10-03 21:33:23 - train: epoch 0302, iter [00070, 01251], lr: 0.000210, loss: 0.4015
2022-10-03 21:33:41 - train: epoch 0302, iter [00080, 01251], lr: 0.000210, loss: 0.4103
2022-10-03 21:33:59 - train: epoch 0302, iter [00090, 01251], lr: 0.000210, loss: 0.3958
2022-10-03 21:34:17 - train: epoch 0302, iter [00100, 01251], lr: 0.000210, loss: 0.4072
2022-10-03 21:34:35 - train: epoch 0302, iter [00110, 01251], lr: 0.000210, loss: 0.3924
2022-10-03 21:34:53 - train: epoch 0302, iter [00120, 01251], lr: 0.000210, loss: 0.4061
2022-10-03 21:35:12 - train: epoch 0302, iter [00130, 01251], lr: 0.000210, loss: 0.4018
2022-10-03 21:35:30 - train: epoch 0302, iter [00140, 01251], lr: 0.000210, loss: 0.3913
2022-10-03 21:35:48 - train: epoch 0302, iter [00150, 01251], lr: 0.000210, loss: 0.4088
2022-10-03 21:36:06 - train: epoch 0302, iter [00160, 01251], lr: 0.000210, loss: 0.4120
2022-10-03 21:36:24 - train: epoch 0302, iter [00170, 01251], lr: 0.000210, loss: 0.3977
2022-10-03 21:36:42 - train: epoch 0302, iter [00180, 01251], lr: 0.000210, loss: 0.3980
2022-10-03 21:37:00 - train: epoch 0302, iter [00190, 01251], lr: 0.000210, loss: 0.3874
2022-10-03 21:37:18 - train: epoch 0302, iter [00200, 01251], lr: 0.000210, loss: 0.3916
2022-10-03 21:37:36 - train: epoch 0302, iter [00210, 01251], lr: 0.000210, loss: 0.3884
2022-10-03 21:37:54 - train: epoch 0302, iter [00220, 01251], lr: 0.000210, loss: 0.3996
2022-10-03 21:38:12 - train: epoch 0302, iter [00230, 01251], lr: 0.000210, loss: 0.3922
2022-10-03 21:38:30 - train: epoch 0302, iter [00240, 01251], lr: 0.000210, loss: 0.4052
2022-10-03 21:38:48 - train: epoch 0302, iter [00250, 01251], lr: 0.000210, loss: 0.3850
2022-10-03 21:39:06 - train: epoch 0302, iter [00260, 01251], lr: 0.000210, loss: 0.3865
2022-10-03 21:39:24 - train: epoch 0302, iter [00270, 01251], lr: 0.000209, loss: 0.3793
2022-10-03 21:39:42 - train: epoch 0302, iter [00280, 01251], lr: 0.000209, loss: 0.4173
2022-10-03 21:40:00 - train: epoch 0302, iter [00290, 01251], lr: 0.000209, loss: 0.3879
2022-10-03 21:40:19 - train: epoch 0302, iter [00300, 01251], lr: 0.000209, loss: 0.3874
2022-10-03 21:40:37 - train: epoch 0302, iter [00310, 01251], lr: 0.000209, loss: 0.4000
2022-10-03 21:40:55 - train: epoch 0302, iter [00320, 01251], lr: 0.000209, loss: 0.3846
2022-10-03 21:41:13 - train: epoch 0302, iter [00330, 01251], lr: 0.000209, loss: 0.4149
2022-10-03 21:41:31 - train: epoch 0302, iter [00340, 01251], lr: 0.000209, loss: 0.4157
2022-10-03 21:41:49 - train: epoch 0302, iter [00350, 01251], lr: 0.000209, loss: 0.3895
2022-10-03 21:42:07 - train: epoch 0302, iter [00360, 01251], lr: 0.000209, loss: 0.3866
2022-10-03 21:42:25 - train: epoch 0302, iter [00370, 01251], lr: 0.000209, loss: 0.4021
2022-10-03 21:42:43 - train: epoch 0302, iter [00380, 01251], lr: 0.000209, loss: 0.3863
2022-10-03 21:43:02 - train: epoch 0302, iter [00390, 01251], lr: 0.000209, loss: 0.3950
2022-10-03 21:43:20 - train: epoch 0302, iter [00400, 01251], lr: 0.000209, loss: 0.3843
2022-10-03 21:43:38 - train: epoch 0302, iter [00410, 01251], lr: 0.000209, loss: 0.3981
2022-10-03 21:43:56 - train: epoch 0302, iter [00420, 01251], lr: 0.000209, loss: 0.4040
2022-10-03 21:44:14 - train: epoch 0302, iter [00430, 01251], lr: 0.000209, loss: 0.4084
2022-10-03 21:44:32 - train: epoch 0302, iter [00440, 01251], lr: 0.000209, loss: 0.4001
2022-10-03 21:44:50 - train: epoch 0302, iter [00450, 01251], lr: 0.000209, loss: 0.3790
2022-10-03 21:45:08 - train: epoch 0302, iter [00460, 01251], lr: 0.000209, loss: 0.3843
2022-10-03 21:45:26 - train: epoch 0302, iter [00470, 01251], lr: 0.000209, loss: 0.3921
2022-10-03 21:45:44 - train: epoch 0302, iter [00480, 01251], lr: 0.000209, loss: 0.3881
2022-10-03 21:46:02 - train: epoch 0302, iter [00490, 01251], lr: 0.000209, loss: 0.4263
2022-10-03 21:46:20 - train: epoch 0302, iter [00500, 01251], lr: 0.000209, loss: 0.3799
2022-10-03 21:46:38 - train: epoch 0302, iter [00510, 01251], lr: 0.000209, loss: 0.3960
2022-10-03 21:46:56 - train: epoch 0302, iter [00520, 01251], lr: 0.000209, loss: 0.3857
2022-10-03 21:47:14 - train: epoch 0302, iter [00530, 01251], lr: 0.000209, loss: 0.3853
2022-10-03 21:47:33 - train: epoch 0302, iter [00540, 01251], lr: 0.000209, loss: 0.3951
2022-10-03 21:47:51 - train: epoch 0302, iter [00550, 01251], lr: 0.000209, loss: 0.3951
2022-10-03 21:48:09 - train: epoch 0302, iter [00560, 01251], lr: 0.000209, loss: 0.4105
2022-10-03 21:48:27 - train: epoch 0302, iter [00570, 01251], lr: 0.000209, loss: 0.3941
2022-10-03 21:48:45 - train: epoch 0302, iter [00580, 01251], lr: 0.000208, loss: 0.4076
2022-10-03 21:49:03 - train: epoch 0302, iter [00590, 01251], lr: 0.000208, loss: 0.4085
2022-10-03 21:49:21 - train: epoch 0302, iter [00600, 01251], lr: 0.000208, loss: 0.3761
2022-10-03 21:49:39 - train: epoch 0302, iter [00610, 01251], lr: 0.000208, loss: 0.3917
2022-10-03 21:49:57 - train: epoch 0302, iter [00620, 01251], lr: 0.000208, loss: 0.3872
2022-10-03 21:50:15 - train: epoch 0302, iter [00630, 01251], lr: 0.000208, loss: 0.3906
2022-10-03 21:50:33 - train: epoch 0302, iter [00640, 01251], lr: 0.000208, loss: 0.4122
2022-10-03 21:50:51 - train: epoch 0302, iter [00650, 01251], lr: 0.000208, loss: 0.4013
2022-10-03 21:51:09 - train: epoch 0302, iter [00660, 01251], lr: 0.000208, loss: 0.4073
2022-10-03 21:51:27 - train: epoch 0302, iter [00670, 01251], lr: 0.000208, loss: 0.3894
2022-10-03 21:51:45 - train: epoch 0302, iter [00680, 01251], lr: 0.000208, loss: 0.4036
2022-10-03 21:52:04 - train: epoch 0302, iter [00690, 01251], lr: 0.000208, loss: 0.3903
2022-10-03 21:52:22 - train: epoch 0302, iter [00700, 01251], lr: 0.000208, loss: 0.4153
2022-10-03 21:52:40 - train: epoch 0302, iter [00710, 01251], lr: 0.000208, loss: 0.3994
2022-10-03 21:52:58 - train: epoch 0302, iter [00720, 01251], lr: 0.000208, loss: 0.4013
2022-10-03 21:53:16 - train: epoch 0302, iter [00730, 01251], lr: 0.000208, loss: 0.3938
2022-10-03 21:53:34 - train: epoch 0302, iter [00740, 01251], lr: 0.000208, loss: 0.3913
2022-10-03 21:53:52 - train: epoch 0302, iter [00750, 01251], lr: 0.000208, loss: 0.3985
2022-10-03 21:54:10 - train: epoch 0302, iter [00760, 01251], lr: 0.000208, loss: 0.3892
2022-10-03 21:54:28 - train: epoch 0302, iter [00770, 01251], lr: 0.000208, loss: 0.4166
2022-10-03 21:54:46 - train: epoch 0302, iter [00780, 01251], lr: 0.000208, loss: 0.4092
2022-10-03 21:55:04 - train: epoch 0302, iter [00790, 01251], lr: 0.000208, loss: 0.3893
2022-10-03 21:55:22 - train: epoch 0302, iter [00800, 01251], lr: 0.000208, loss: 0.4069
2022-10-03 21:55:40 - train: epoch 0302, iter [00810, 01251], lr: 0.000208, loss: 0.4006
2022-10-03 21:55:58 - train: epoch 0302, iter [00820, 01251], lr: 0.000208, loss: 0.3922
2022-10-03 21:56:16 - train: epoch 0302, iter [00830, 01251], lr: 0.000208, loss: 0.4062
2022-10-03 21:56:34 - train: epoch 0302, iter [00840, 01251], lr: 0.000208, loss: 0.4089
2022-10-03 21:56:52 - train: epoch 0302, iter [00850, 01251], lr: 0.000208, loss: 0.3890
2022-10-03 21:57:10 - train: epoch 0302, iter [00860, 01251], lr: 0.000208, loss: 0.3870
2022-10-03 21:57:29 - train: epoch 0302, iter [00870, 01251], lr: 0.000208, loss: 0.3908
2022-10-03 21:57:47 - train: epoch 0302, iter [00880, 01251], lr: 0.000208, loss: 0.4003
2022-10-03 21:58:05 - train: epoch 0302, iter [00890, 01251], lr: 0.000208, loss: 0.4230
2022-10-03 21:58:23 - train: epoch 0302, iter [00900, 01251], lr: 0.000207, loss: 0.3944
2022-10-03 21:58:41 - train: epoch 0302, iter [00910, 01251], lr: 0.000207, loss: 0.3960
2022-10-03 21:58:59 - train: epoch 0302, iter [00920, 01251], lr: 0.000207, loss: 0.3832
2022-10-03 21:59:17 - train: epoch 0302, iter [00930, 01251], lr: 0.000207, loss: 0.4019
2022-10-03 21:59:35 - train: epoch 0302, iter [00940, 01251], lr: 0.000207, loss: 0.3845
2022-10-03 21:59:53 - train: epoch 0302, iter [00950, 01251], lr: 0.000207, loss: 0.3897
2022-10-03 22:00:11 - train: epoch 0302, iter [00960, 01251], lr: 0.000207, loss: 0.4207
2022-10-03 22:00:30 - train: epoch 0302, iter [00970, 01251], lr: 0.000207, loss: 0.3880
2022-10-03 22:00:48 - train: epoch 0302, iter [00980, 01251], lr: 0.000207, loss: 0.3778
2022-10-03 22:01:06 - train: epoch 0302, iter [00990, 01251], lr: 0.000207, loss: 0.3984
2022-10-03 22:01:24 - train: epoch 0302, iter [01000, 01251], lr: 0.000207, loss: 0.3854
2022-10-03 22:01:42 - train: epoch 0302, iter [01010, 01251], lr: 0.000207, loss: 0.3832
2022-10-03 22:02:00 - train: epoch 0302, iter [01020, 01251], lr: 0.000207, loss: 0.4080
2022-10-03 22:02:18 - train: epoch 0302, iter [01030, 01251], lr: 0.000207, loss: 0.4158
2022-10-03 22:02:36 - train: epoch 0302, iter [01040, 01251], lr: 0.000207, loss: 0.3744
2022-10-03 22:02:54 - train: epoch 0302, iter [01050, 01251], lr: 0.000207, loss: 0.4019
2022-10-03 22:03:12 - train: epoch 0302, iter [01060, 01251], lr: 0.000207, loss: 0.4006
2022-10-03 22:03:31 - train: epoch 0302, iter [01070, 01251], lr: 0.000207, loss: 0.3943
2022-10-03 22:03:49 - train: epoch 0302, iter [01080, 01251], lr: 0.000207, loss: 0.3920
2022-10-03 22:04:07 - train: epoch 0302, iter [01090, 01251], lr: 0.000207, loss: 0.3984
2022-10-03 22:04:25 - train: epoch 0302, iter [01100, 01251], lr: 0.000207, loss: 0.4044
2022-10-03 22:04:43 - train: epoch 0302, iter [01110, 01251], lr: 0.000207, loss: 0.4051
2022-10-03 22:05:01 - train: epoch 0302, iter [01120, 01251], lr: 0.000207, loss: 0.4195
2022-10-03 22:05:19 - train: epoch 0302, iter [01130, 01251], lr: 0.000207, loss: 0.4028
2022-10-03 22:05:37 - train: epoch 0302, iter [01140, 01251], lr: 0.000207, loss: 0.4258
2022-10-03 22:05:55 - train: epoch 0302, iter [01150, 01251], lr: 0.000207, loss: 0.3894
2022-10-03 22:06:13 - train: epoch 0302, iter [01160, 01251], lr: 0.000207, loss: 0.3977
2022-10-03 22:06:31 - train: epoch 0302, iter [01170, 01251], lr: 0.000207, loss: 0.3973
2022-10-03 22:06:49 - train: epoch 0302, iter [01180, 01251], lr: 0.000207, loss: 0.3963
2022-10-03 22:07:07 - train: epoch 0302, iter [01190, 01251], lr: 0.000207, loss: 0.3990
2022-10-03 22:07:25 - train: epoch 0302, iter [01200, 01251], lr: 0.000207, loss: 0.3901
2022-10-03 22:07:43 - train: epoch 0302, iter [01210, 01251], lr: 0.000206, loss: 0.4237
2022-10-03 22:08:01 - train: epoch 0302, iter [01220, 01251], lr: 0.000206, loss: 0.4159
2022-10-03 22:08:20 - train: epoch 0302, iter [01230, 01251], lr: 0.000206, loss: 0.3790
2022-10-03 22:08:38 - train: epoch 0302, iter [01240, 01251], lr: 0.000206, loss: 0.3813
2022-10-03 22:08:55 - train: epoch 0302, iter [01250, 01251], lr: 0.000206, loss: 0.4110
2022-10-03 22:08:59 - train: epoch 302, train_loss: 0.3972
2022-10-03 22:09:02 - until epoch: 302, best_loss: 0.3972
2022-10-03 22:09:02 - epoch 303 lr: 0.000206
2022-10-03 22:09:27 - train: epoch 0303, iter [00010, 01251], lr: 0.000206, loss: 0.4008
2022-10-03 22:09:45 - train: epoch 0303, iter [00020, 01251], lr: 0.000206, loss: 0.3960
2022-10-03 22:10:03 - train: epoch 0303, iter [00030, 01251], lr: 0.000206, loss: 0.3930
2022-10-03 22:10:21 - train: epoch 0303, iter [00040, 01251], lr: 0.000206, loss: 0.4167
2022-10-03 22:10:39 - train: epoch 0303, iter [00050, 01251], lr: 0.000206, loss: 0.4029
2022-10-03 22:10:58 - train: epoch 0303, iter [00060, 01251], lr: 0.000206, loss: 0.4028
2022-10-03 22:11:16 - train: epoch 0303, iter [00070, 01251], lr: 0.000206, loss: 0.4013
2022-10-03 22:11:34 - train: epoch 0303, iter [00080, 01251], lr: 0.000206, loss: 0.4295
2022-10-03 22:11:52 - train: epoch 0303, iter [00090, 01251], lr: 0.000206, loss: 0.4099
2022-10-03 22:12:10 - train: epoch 0303, iter [00100, 01251], lr: 0.000206, loss: 0.3845
2022-10-03 22:12:28 - train: epoch 0303, iter [00110, 01251], lr: 0.000206, loss: 0.3891
2022-10-03 22:12:46 - train: epoch 0303, iter [00120, 01251], lr: 0.000206, loss: 0.3976
2022-10-03 22:13:04 - train: epoch 0303, iter [00130, 01251], lr: 0.000206, loss: 0.4012
2022-10-03 22:13:22 - train: epoch 0303, iter [00140, 01251], lr: 0.000206, loss: 0.4110
2022-10-03 22:13:41 - train: epoch 0303, iter [00150, 01251], lr: 0.000206, loss: 0.4056
2022-10-03 22:13:59 - train: epoch 0303, iter [00160, 01251], lr: 0.000206, loss: 0.3974
2022-10-03 22:14:17 - train: epoch 0303, iter [00170, 01251], lr: 0.000206, loss: 0.3906
2022-10-03 22:14:35 - train: epoch 0303, iter [00180, 01251], lr: 0.000206, loss: 0.3993
2022-10-03 22:14:53 - train: epoch 0303, iter [00190, 01251], lr: 0.000206, loss: 0.4097
2022-10-03 22:15:11 - train: epoch 0303, iter [00200, 01251], lr: 0.000206, loss: 0.3914
2022-10-03 22:15:29 - train: epoch 0303, iter [00210, 01251], lr: 0.000206, loss: 0.3830
2022-10-03 22:15:47 - train: epoch 0303, iter [00220, 01251], lr: 0.000206, loss: 0.4048
2022-10-03 22:16:05 - train: epoch 0303, iter [00230, 01251], lr: 0.000206, loss: 0.3874
2022-10-03 22:16:23 - train: epoch 0303, iter [00240, 01251], lr: 0.000206, loss: 0.3945
2022-10-03 22:16:41 - train: epoch 0303, iter [00250, 01251], lr: 0.000206, loss: 0.4055
2022-10-03 22:17:00 - train: epoch 0303, iter [00260, 01251], lr: 0.000206, loss: 0.3975
2022-10-03 22:17:18 - train: epoch 0303, iter [00270, 01251], lr: 0.000206, loss: 0.3861
2022-10-03 22:17:36 - train: epoch 0303, iter [00280, 01251], lr: 0.000205, loss: 0.3783
2022-10-03 22:17:54 - train: epoch 0303, iter [00290, 01251], lr: 0.000205, loss: 0.3906
2022-10-03 22:18:12 - train: epoch 0303, iter [00300, 01251], lr: 0.000205, loss: 0.4148
2022-10-03 22:18:30 - train: epoch 0303, iter [00310, 01251], lr: 0.000205, loss: 0.4068
2022-10-03 22:18:48 - train: epoch 0303, iter [00320, 01251], lr: 0.000205, loss: 0.4039
2022-10-03 22:19:06 - train: epoch 0303, iter [00330, 01251], lr: 0.000205, loss: 0.3676
2022-10-03 22:19:24 - train: epoch 0303, iter [00340, 01251], lr: 0.000205, loss: 0.3948
2022-10-03 22:19:42 - train: epoch 0303, iter [00350, 01251], lr: 0.000205, loss: 0.4046
2022-10-03 22:20:01 - train: epoch 0303, iter [00360, 01251], lr: 0.000205, loss: 0.3904
2022-10-03 22:20:19 - train: epoch 0303, iter [00370, 01251], lr: 0.000205, loss: 0.4056
2022-10-03 22:20:37 - train: epoch 0303, iter [00380, 01251], lr: 0.000205, loss: 0.4008
2022-10-03 22:20:55 - train: epoch 0303, iter [00390, 01251], lr: 0.000205, loss: 0.4127
2022-10-03 22:21:13 - train: epoch 0303, iter [00400, 01251], lr: 0.000205, loss: 0.4234
2022-10-03 22:21:31 - train: epoch 0303, iter [00410, 01251], lr: 0.000205, loss: 0.3790
2022-10-03 22:21:49 - train: epoch 0303, iter [00420, 01251], lr: 0.000205, loss: 0.3993
2022-10-03 22:22:07 - train: epoch 0303, iter [00430, 01251], lr: 0.000205, loss: 0.3807
2022-10-03 22:22:25 - train: epoch 0303, iter [00440, 01251], lr: 0.000205, loss: 0.3864
2022-10-03 22:22:43 - train: epoch 0303, iter [00450, 01251], lr: 0.000205, loss: 0.4061
2022-10-03 22:23:01 - train: epoch 0303, iter [00460, 01251], lr: 0.000205, loss: 0.3913
2022-10-03 22:23:19 - train: epoch 0303, iter [00470, 01251], lr: 0.000205, loss: 0.3968
2022-10-03 22:23:37 - train: epoch 0303, iter [00480, 01251], lr: 0.000205, loss: 0.4107
2022-10-03 22:23:55 - train: epoch 0303, iter [00490, 01251], lr: 0.000205, loss: 0.4024
2022-10-03 22:24:13 - train: epoch 0303, iter [00500, 01251], lr: 0.000205, loss: 0.3907
2022-10-03 22:24:32 - train: epoch 0303, iter [00510, 01251], lr: 0.000205, loss: 0.3880
2022-10-03 22:24:50 - train: epoch 0303, iter [00520, 01251], lr: 0.000205, loss: 0.3985
2022-10-03 22:25:08 - train: epoch 0303, iter [00530, 01251], lr: 0.000205, loss: 0.3908
2022-10-03 22:25:26 - train: epoch 0303, iter [00540, 01251], lr: 0.000205, loss: 0.3968
2022-10-03 22:25:44 - train: epoch 0303, iter [00550, 01251], lr: 0.000205, loss: 0.4059
2022-10-03 22:26:02 - train: epoch 0303, iter [00560, 01251], lr: 0.000205, loss: 0.3849
2022-10-03 22:26:20 - train: epoch 0303, iter [00570, 01251], lr: 0.000205, loss: 0.3794
2022-10-03 22:26:38 - train: epoch 0303, iter [00580, 01251], lr: 0.000205, loss: 0.4112
2022-10-03 22:26:56 - train: epoch 0303, iter [00590, 01251], lr: 0.000205, loss: 0.3881
2022-10-03 22:27:14 - train: epoch 0303, iter [00600, 01251], lr: 0.000204, loss: 0.4133
2022-10-03 22:27:32 - train: epoch 0303, iter [00610, 01251], lr: 0.000204, loss: 0.4246
2022-10-03 22:27:50 - train: epoch 0303, iter [00620, 01251], lr: 0.000204, loss: 0.3829
2022-10-03 22:28:09 - train: epoch 0303, iter [00630, 01251], lr: 0.000204, loss: 0.3782
2022-10-03 22:28:27 - train: epoch 0303, iter [00640, 01251], lr: 0.000204, loss: 0.4072
2022-10-03 22:28:45 - train: epoch 0303, iter [00650, 01251], lr: 0.000204, loss: 0.4119
2022-10-03 22:29:03 - train: epoch 0303, iter [00660, 01251], lr: 0.000204, loss: 0.3703
2022-10-03 22:29:21 - train: epoch 0303, iter [00670, 01251], lr: 0.000204, loss: 0.4098
2022-10-03 22:29:39 - train: epoch 0303, iter [00680, 01251], lr: 0.000204, loss: 0.4032
2022-10-03 22:29:57 - train: epoch 0303, iter [00690, 01251], lr: 0.000204, loss: 0.4039
2022-10-03 22:30:15 - train: epoch 0303, iter [00700, 01251], lr: 0.000204, loss: 0.3966
2022-10-03 22:30:33 - train: epoch 0303, iter [00710, 01251], lr: 0.000204, loss: 0.4099
2022-10-03 22:30:51 - train: epoch 0303, iter [00720, 01251], lr: 0.000204, loss: 0.3874
2022-10-03 22:31:10 - train: epoch 0303, iter [00730, 01251], lr: 0.000204, loss: 0.3877
2022-10-03 22:31:27 - train: epoch 0303, iter [00740, 01251], lr: 0.000204, loss: 0.4163
2022-10-03 22:31:45 - train: epoch 0303, iter [00750, 01251], lr: 0.000204, loss: 0.4105
2022-10-03 22:32:04 - train: epoch 0303, iter [00760, 01251], lr: 0.000204, loss: 0.3867
2022-10-03 22:32:22 - train: epoch 0303, iter [00770, 01251], lr: 0.000204, loss: 0.4023
2022-10-03 22:32:40 - train: epoch 0303, iter [00780, 01251], lr: 0.000204, loss: 0.3984
2022-10-03 22:32:58 - train: epoch 0303, iter [00790, 01251], lr: 0.000204, loss: 0.4009
2022-10-03 22:33:16 - train: epoch 0303, iter [00800, 01251], lr: 0.000204, loss: 0.3816
2022-10-03 22:33:34 - train: epoch 0303, iter [00810, 01251], lr: 0.000204, loss: 0.3945
2022-10-03 22:33:52 - train: epoch 0303, iter [00820, 01251], lr: 0.000204, loss: 0.3808
2022-10-03 22:34:10 - train: epoch 0303, iter [00830, 01251], lr: 0.000204, loss: 0.3924
2022-10-03 22:34:28 - train: epoch 0303, iter [00840, 01251], lr: 0.000204, loss: 0.3939
2022-10-03 22:34:46 - train: epoch 0303, iter [00850, 01251], lr: 0.000204, loss: 0.4109
2022-10-03 22:35:04 - train: epoch 0303, iter [00860, 01251], lr: 0.000204, loss: 0.3902
2022-10-03 22:35:22 - train: epoch 0303, iter [00870, 01251], lr: 0.000204, loss: 0.3998
2022-10-03 22:35:41 - train: epoch 0303, iter [00880, 01251], lr: 0.000204, loss: 0.3811
2022-10-03 22:35:59 - train: epoch 0303, iter [00890, 01251], lr: 0.000204, loss: 0.3948
2022-10-03 22:36:17 - train: epoch 0303, iter [00900, 01251], lr: 0.000204, loss: 0.4136
2022-10-03 22:36:35 - train: epoch 0303, iter [00910, 01251], lr: 0.000203, loss: 0.3998
2022-10-03 22:36:53 - train: epoch 0303, iter [00920, 01251], lr: 0.000203, loss: 0.4158
2022-10-03 22:37:11 - train: epoch 0303, iter [00930, 01251], lr: 0.000203, loss: 0.3815
2022-10-03 22:37:29 - train: epoch 0303, iter [00940, 01251], lr: 0.000203, loss: 0.4070
2022-10-03 22:37:47 - train: epoch 0303, iter [00950, 01251], lr: 0.000203, loss: 0.4061
2022-10-03 22:38:06 - train: epoch 0303, iter [00960, 01251], lr: 0.000203, loss: 0.3807
2022-10-03 22:38:24 - train: epoch 0303, iter [00970, 01251], lr: 0.000203, loss: 0.4059
2022-10-03 22:38:42 - train: epoch 0303, iter [00980, 01251], lr: 0.000203, loss: 0.4108
2022-10-03 22:39:00 - train: epoch 0303, iter [00990, 01251], lr: 0.000203, loss: 0.3844
2022-10-03 22:39:18 - train: epoch 0303, iter [01000, 01251], lr: 0.000203, loss: 0.3981
2022-10-03 22:39:36 - train: epoch 0303, iter [01010, 01251], lr: 0.000203, loss: 0.3997
2022-10-03 22:39:54 - train: epoch 0303, iter [01020, 01251], lr: 0.000203, loss: 0.3871
2022-10-03 22:40:12 - train: epoch 0303, iter [01030, 01251], lr: 0.000203, loss: 0.4010
2022-10-03 22:40:30 - train: epoch 0303, iter [01040, 01251], lr: 0.000203, loss: 0.3905
2022-10-03 22:40:48 - train: epoch 0303, iter [01050, 01251], lr: 0.000203, loss: 0.4045
2022-10-03 22:41:07 - train: epoch 0303, iter [01060, 01251], lr: 0.000203, loss: 0.4030
2022-10-03 22:41:25 - train: epoch 0303, iter [01070, 01251], lr: 0.000203, loss: 0.4104
2022-10-03 22:41:43 - train: epoch 0303, iter [01080, 01251], lr: 0.000203, loss: 0.4068
2022-10-03 22:42:01 - train: epoch 0303, iter [01090, 01251], lr: 0.000203, loss: 0.4024
2022-10-03 22:42:19 - train: epoch 0303, iter [01100, 01251], lr: 0.000203, loss: 0.3890
2022-10-03 22:42:37 - train: epoch 0303, iter [01110, 01251], lr: 0.000203, loss: 0.3968
2022-10-03 22:42:55 - train: epoch 0303, iter [01120, 01251], lr: 0.000203, loss: 0.4018
2022-10-03 22:43:13 - train: epoch 0303, iter [01130, 01251], lr: 0.000203, loss: 0.3945
2022-10-03 22:43:31 - train: epoch 0303, iter [01140, 01251], lr: 0.000203, loss: 0.4064
2022-10-03 22:43:49 - train: epoch 0303, iter [01150, 01251], lr: 0.000203, loss: 0.3831
2022-10-03 22:44:07 - train: epoch 0303, iter [01160, 01251], lr: 0.000203, loss: 0.3978
2022-10-03 22:44:25 - train: epoch 0303, iter [01170, 01251], lr: 0.000203, loss: 0.3951
2022-10-03 22:44:43 - train: epoch 0303, iter [01180, 01251], lr: 0.000203, loss: 0.3888
2022-10-03 22:45:01 - train: epoch 0303, iter [01190, 01251], lr: 0.000203, loss: 0.4017
2022-10-03 22:45:20 - train: epoch 0303, iter [01200, 01251], lr: 0.000203, loss: 0.3901
2022-10-03 22:45:38 - train: epoch 0303, iter [01210, 01251], lr: 0.000203, loss: 0.3980
2022-10-03 22:45:56 - train: epoch 0303, iter [01220, 01251], lr: 0.000203, loss: 0.4149
2022-10-03 22:46:14 - train: epoch 0303, iter [01230, 01251], lr: 0.000202, loss: 0.4132
2022-10-03 22:46:32 - train: epoch 0303, iter [01240, 01251], lr: 0.000202, loss: 0.3990
2022-10-03 22:46:50 - train: epoch 0303, iter [01250, 01251], lr: 0.000202, loss: 0.3945
2022-10-03 22:46:53 - train: epoch 303, train_loss: 0.3971
2022-10-03 22:46:56 - until epoch: 303, best_loss: 0.3971
2022-10-03 22:46:56 - epoch 304 lr: 0.000202
2022-10-03 22:47:21 - train: epoch 0304, iter [00010, 01251], lr: 0.000202, loss: 0.4009
2022-10-03 22:47:40 - train: epoch 0304, iter [00020, 01251], lr: 0.000202, loss: 0.4079
2022-10-03 22:47:57 - train: epoch 0304, iter [00030, 01251], lr: 0.000202, loss: 0.4081
2022-10-03 22:48:16 - train: epoch 0304, iter [00040, 01251], lr: 0.000202, loss: 0.4160
2022-10-03 22:48:34 - train: epoch 0304, iter [00050, 01251], lr: 0.000202, loss: 0.3989
2022-10-03 22:48:52 - train: epoch 0304, iter [00060, 01251], lr: 0.000202, loss: 0.4019
2022-10-03 22:49:10 - train: epoch 0304, iter [00070, 01251], lr: 0.000202, loss: 0.4084
2022-10-03 22:49:28 - train: epoch 0304, iter [00080, 01251], lr: 0.000202, loss: 0.3961
2022-10-03 22:49:46 - train: epoch 0304, iter [00090, 01251], lr: 0.000202, loss: 0.3841
2022-10-03 22:50:04 - train: epoch 0304, iter [00100, 01251], lr: 0.000202, loss: 0.4003
2022-10-03 22:50:22 - train: epoch 0304, iter [00110, 01251], lr: 0.000202, loss: 0.4166
2022-10-03 22:50:40 - train: epoch 0304, iter [00120, 01251], lr: 0.000202, loss: 0.4209
2022-10-03 22:50:58 - train: epoch 0304, iter [00130, 01251], lr: 0.000202, loss: 0.4088
2022-10-03 22:51:16 - train: epoch 0304, iter [00140, 01251], lr: 0.000202, loss: 0.4011
2022-10-03 22:51:34 - train: epoch 0304, iter [00150, 01251], lr: 0.000202, loss: 0.3875
2022-10-03 22:51:52 - train: epoch 0304, iter [00160, 01251], lr: 0.000202, loss: 0.3926
2022-10-03 22:52:11 - train: epoch 0304, iter [00170, 01251], lr: 0.000202, loss: 0.4155
2022-10-03 22:52:29 - train: epoch 0304, iter [00180, 01251], lr: 0.000202, loss: 0.3936
2022-10-03 22:52:47 - train: epoch 0304, iter [00190, 01251], lr: 0.000202, loss: 0.3897
2022-10-03 22:53:05 - train: epoch 0304, iter [00200, 01251], lr: 0.000202, loss: 0.3917
2022-10-03 22:53:23 - train: epoch 0304, iter [00210, 01251], lr: 0.000202, loss: 0.3828
2022-10-03 22:53:41 - train: epoch 0304, iter [00220, 01251], lr: 0.000202, loss: 0.4036
2022-10-03 22:53:59 - train: epoch 0304, iter [00230, 01251], lr: 0.000202, loss: 0.3802
2022-10-03 22:54:17 - train: epoch 0304, iter [00240, 01251], lr: 0.000202, loss: 0.4140
2022-10-03 22:54:35 - train: epoch 0304, iter [00250, 01251], lr: 0.000202, loss: 0.3918
2022-10-03 22:54:54 - train: epoch 0304, iter [00260, 01251], lr: 0.000202, loss: 0.3703
2022-10-03 22:55:12 - train: epoch 0304, iter [00270, 01251], lr: 0.000202, loss: 0.4029
2022-10-03 22:55:30 - train: epoch 0304, iter [00280, 01251], lr: 0.000202, loss: 0.3908
2022-10-03 22:55:48 - train: epoch 0304, iter [00290, 01251], lr: 0.000202, loss: 0.4190
2022-10-03 22:56:06 - train: epoch 0304, iter [00300, 01251], lr: 0.000201, loss: 0.4011
2022-10-03 22:56:24 - train: epoch 0304, iter [00310, 01251], lr: 0.000201, loss: 0.3997
2022-10-03 22:56:42 - train: epoch 0304, iter [00320, 01251], lr: 0.000201, loss: 0.4017
2022-10-03 22:57:00 - train: epoch 0304, iter [00330, 01251], lr: 0.000201, loss: 0.3941
2022-10-03 22:57:18 - train: epoch 0304, iter [00340, 01251], lr: 0.000201, loss: 0.3978
2022-10-03 22:57:36 - train: epoch 0304, iter [00350, 01251], lr: 0.000201, loss: 0.4182
2022-10-03 22:57:54 - train: epoch 0304, iter [00360, 01251], lr: 0.000201, loss: 0.4005
2022-10-03 22:58:12 - train: epoch 0304, iter [00370, 01251], lr: 0.000201, loss: 0.3878
2022-10-03 22:58:30 - train: epoch 0304, iter [00380, 01251], lr: 0.000201, loss: 0.3933
2022-10-03 22:58:48 - train: epoch 0304, iter [00390, 01251], lr: 0.000201, loss: 0.3987
2022-10-03 22:59:06 - train: epoch 0304, iter [00400, 01251], lr: 0.000201, loss: 0.3987
2022-10-03 22:59:24 - train: epoch 0304, iter [00410, 01251], lr: 0.000201, loss: 0.3995
2022-10-03 22:59:42 - train: epoch 0304, iter [00420, 01251], lr: 0.000201, loss: 0.3928
2022-10-03 23:00:00 - train: epoch 0304, iter [00430, 01251], lr: 0.000201, loss: 0.3678
2022-10-03 23:00:18 - train: epoch 0304, iter [00440, 01251], lr: 0.000201, loss: 0.3962
2022-10-03 23:00:36 - train: epoch 0304, iter [00450, 01251], lr: 0.000201, loss: 0.3982
2022-10-03 23:00:54 - train: epoch 0304, iter [00460, 01251], lr: 0.000201, loss: 0.4012
2022-10-03 23:01:13 - train: epoch 0304, iter [00470, 01251], lr: 0.000201, loss: 0.3858
2022-10-03 23:01:31 - train: epoch 0304, iter [00480, 01251], lr: 0.000201, loss: 0.3770
2022-10-03 23:01:49 - train: epoch 0304, iter [00490, 01251], lr: 0.000201, loss: 0.3882
2022-10-03 23:02:07 - train: epoch 0304, iter [00500, 01251], lr: 0.000201, loss: 0.3880
2022-10-03 23:02:25 - train: epoch 0304, iter [00510, 01251], lr: 0.000201, loss: 0.3867
2022-10-03 23:02:43 - train: epoch 0304, iter [00520, 01251], lr: 0.000201, loss: 0.3998
2022-10-03 23:03:01 - train: epoch 0304, iter [00530, 01251], lr: 0.000201, loss: 0.3807
2022-10-03 23:03:19 - train: epoch 0304, iter [00540, 01251], lr: 0.000201, loss: 0.3856
2022-10-03 23:03:37 - train: epoch 0304, iter [00550, 01251], lr: 0.000201, loss: 0.3804
2022-10-03 23:03:55 - train: epoch 0304, iter [00560, 01251], lr: 0.000201, loss: 0.3917
2022-10-03 23:04:13 - train: epoch 0304, iter [00570, 01251], lr: 0.000201, loss: 0.4009
2022-10-03 23:04:31 - train: epoch 0304, iter [00580, 01251], lr: 0.000201, loss: 0.4139
2022-10-03 23:04:49 - train: epoch 0304, iter [00590, 01251], lr: 0.000201, loss: 0.3958
2022-10-03 23:05:07 - train: epoch 0304, iter [00600, 01251], lr: 0.000201, loss: 0.3825
2022-10-03 23:05:26 - train: epoch 0304, iter [00610, 01251], lr: 0.000201, loss: 0.4081
2022-10-03 23:05:43 - train: epoch 0304, iter [00620, 01251], lr: 0.000200, loss: 0.3869
2022-10-03 23:06:01 - train: epoch 0304, iter [00630, 01251], lr: 0.000200, loss: 0.3767
2022-10-03 23:06:19 - train: epoch 0304, iter [00640, 01251], lr: 0.000200, loss: 0.3999
2022-10-03 23:06:37 - train: epoch 0304, iter [00650, 01251], lr: 0.000200, loss: 0.4061
2022-10-03 23:06:55 - train: epoch 0304, iter [00660, 01251], lr: 0.000200, loss: 0.4052
2022-10-03 23:07:13 - train: epoch 0304, iter [00670, 01251], lr: 0.000200, loss: 0.3966
2022-10-03 23:07:31 - train: epoch 0304, iter [00680, 01251], lr: 0.000200, loss: 0.4090
2022-10-03 23:07:49 - train: epoch 0304, iter [00690, 01251], lr: 0.000200, loss: 0.3993
2022-10-03 23:08:07 - train: epoch 0304, iter [00700, 01251], lr: 0.000200, loss: 0.4068
2022-10-03 23:08:25 - train: epoch 0304, iter [00710, 01251], lr: 0.000200, loss: 0.4185
2022-10-03 23:08:43 - train: epoch 0304, iter [00720, 01251], lr: 0.000200, loss: 0.3754
2022-10-03 23:09:01 - train: epoch 0304, iter [00730, 01251], lr: 0.000200, loss: 0.3825
2022-10-03 23:09:20 - train: epoch 0304, iter [00740, 01251], lr: 0.000200, loss: 0.4148
2022-10-03 23:09:38 - train: epoch 0304, iter [00750, 01251], lr: 0.000200, loss: 0.3845
2022-10-03 23:09:55 - train: epoch 0304, iter [00760, 01251], lr: 0.000200, loss: 0.3967
2022-10-03 23:10:14 - train: epoch 0304, iter [00770, 01251], lr: 0.000200, loss: 0.3915
2022-10-03 23:10:32 - train: epoch 0304, iter [00780, 01251], lr: 0.000200, loss: 0.3663
2022-10-03 23:10:49 - train: epoch 0304, iter [00790, 01251], lr: 0.000200, loss: 0.3965
2022-10-03 23:11:08 - train: epoch 0304, iter [00800, 01251], lr: 0.000200, loss: 0.3849
2022-10-03 23:11:26 - train: epoch 0304, iter [00810, 01251], lr: 0.000200, loss: 0.4114
2022-10-03 23:11:44 - train: epoch 0304, iter [00820, 01251], lr: 0.000200, loss: 0.3900
2022-10-03 23:12:02 - train: epoch 0304, iter [00830, 01251], lr: 0.000200, loss: 0.4116
2022-10-03 23:12:20 - train: epoch 0304, iter [00840, 01251], lr: 0.000200, loss: 0.3986
2022-10-03 23:12:38 - train: epoch 0304, iter [00850, 01251], lr: 0.000200, loss: 0.3985
2022-10-03 23:12:56 - train: epoch 0304, iter [00860, 01251], lr: 0.000200, loss: 0.4126
2022-10-03 23:13:14 - train: epoch 0304, iter [00870, 01251], lr: 0.000200, loss: 0.4090
2022-10-03 23:13:32 - train: epoch 0304, iter [00880, 01251], lr: 0.000200, loss: 0.3835
2022-10-03 23:13:50 - train: epoch 0304, iter [00890, 01251], lr: 0.000200, loss: 0.3994
2022-10-03 23:14:09 - train: epoch 0304, iter [00900, 01251], lr: 0.000200, loss: 0.3767
2022-10-03 23:14:27 - train: epoch 0304, iter [00910, 01251], lr: 0.000200, loss: 0.3825
2022-10-03 23:14:45 - train: epoch 0304, iter [00920, 01251], lr: 0.000200, loss: 0.3694
2022-10-03 23:15:03 - train: epoch 0304, iter [00930, 01251], lr: 0.000200, loss: 0.3918
2022-10-03 23:15:21 - train: epoch 0304, iter [00940, 01251], lr: 0.000199, loss: 0.4066
2022-10-03 23:15:39 - train: epoch 0304, iter [00950, 01251], lr: 0.000199, loss: 0.3854
2022-10-03 23:15:58 - train: epoch 0304, iter [00960, 01251], lr: 0.000199, loss: 0.3901
2022-10-03 23:16:16 - train: epoch 0304, iter [00970, 01251], lr: 0.000199, loss: 0.4049
2022-10-03 23:16:34 - train: epoch 0304, iter [00980, 01251], lr: 0.000199, loss: 0.3907
2022-10-03 23:16:52 - train: epoch 0304, iter [00990, 01251], lr: 0.000199, loss: 0.4226
2022-10-03 23:17:11 - train: epoch 0304, iter [01000, 01251], lr: 0.000199, loss: 0.4006
2022-10-03 23:17:29 - train: epoch 0304, iter [01010, 01251], lr: 0.000199, loss: 0.4149
2022-10-03 23:17:47 - train: epoch 0304, iter [01020, 01251], lr: 0.000199, loss: 0.4097
2022-10-03 23:18:05 - train: epoch 0304, iter [01030, 01251], lr: 0.000199, loss: 0.3967
2022-10-03 23:18:24 - train: epoch 0304, iter [01040, 01251], lr: 0.000199, loss: 0.4019
2022-10-03 23:18:42 - train: epoch 0304, iter [01050, 01251], lr: 0.000199, loss: 0.4086
2022-10-03 23:19:00 - train: epoch 0304, iter [01060, 01251], lr: 0.000199, loss: 0.3861
2022-10-03 23:19:18 - train: epoch 0304, iter [01070, 01251], lr: 0.000199, loss: 0.3900
2022-10-03 23:19:36 - train: epoch 0304, iter [01080, 01251], lr: 0.000199, loss: 0.4035
2022-10-03 23:19:55 - train: epoch 0304, iter [01090, 01251], lr: 0.000199, loss: 0.4142
2022-10-03 23:20:13 - train: epoch 0304, iter [01100, 01251], lr: 0.000199, loss: 0.3836
2022-10-03 23:20:31 - train: epoch 0304, iter [01110, 01251], lr: 0.000199, loss: 0.3919
2022-10-03 23:20:49 - train: epoch 0304, iter [01120, 01251], lr: 0.000199, loss: 0.3961
2022-10-03 23:21:07 - train: epoch 0304, iter [01130, 01251], lr: 0.000199, loss: 0.4017
2022-10-03 23:21:25 - train: epoch 0304, iter [01140, 01251], lr: 0.000199, loss: 0.3958
2022-10-03 23:21:44 - train: epoch 0304, iter [01150, 01251], lr: 0.000199, loss: 0.4135
2022-10-03 23:22:02 - train: epoch 0304, iter [01160, 01251], lr: 0.000199, loss: 0.3923
2022-10-03 23:22:20 - train: epoch 0304, iter [01170, 01251], lr: 0.000199, loss: 0.3983
2022-10-03 23:22:38 - train: epoch 0304, iter [01180, 01251], lr: 0.000199, loss: 0.3873
2022-10-03 23:22:56 - train: epoch 0304, iter [01190, 01251], lr: 0.000199, loss: 0.3968
2022-10-03 23:23:14 - train: epoch 0304, iter [01200, 01251], lr: 0.000199, loss: 0.3927
2022-10-03 23:23:32 - train: epoch 0304, iter [01210, 01251], lr: 0.000199, loss: 0.4127
2022-10-03 23:23:50 - train: epoch 0304, iter [01220, 01251], lr: 0.000199, loss: 0.3814
2022-10-03 23:24:09 - train: epoch 0304, iter [01230, 01251], lr: 0.000199, loss: 0.3952
2022-10-03 23:24:27 - train: epoch 0304, iter [01240, 01251], lr: 0.000199, loss: 0.4039
2022-10-03 23:24:45 - train: epoch 0304, iter [01250, 01251], lr: 0.000199, loss: 0.3994
2022-10-03 23:24:48 - train: epoch 304, train_loss: 0.3969
2022-10-03 23:24:51 - until epoch: 304, best_loss: 0.3969
2022-10-03 23:24:51 - epoch 305 lr: 0.000199
2022-10-03 23:25:16 - train: epoch 0305, iter [00010, 01251], lr: 0.000198, loss: 0.3899
2022-10-03 23:25:34 - train: epoch 0305, iter [00020, 01251], lr: 0.000198, loss: 0.4185
2022-10-03 23:25:52 - train: epoch 0305, iter [00030, 01251], lr: 0.000198, loss: 0.4038
2022-10-03 23:26:10 - train: epoch 0305, iter [00040, 01251], lr: 0.000198, loss: 0.3848
2022-10-03 23:26:28 - train: epoch 0305, iter [00050, 01251], lr: 0.000198, loss: 0.4083
2022-10-03 23:26:46 - train: epoch 0305, iter [00060, 01251], lr: 0.000198, loss: 0.3899
2022-10-03 23:27:04 - train: epoch 0305, iter [00070, 01251], lr: 0.000198, loss: 0.3970
2022-10-03 23:27:22 - train: epoch 0305, iter [00080, 01251], lr: 0.000198, loss: 0.3798
2022-10-03 23:27:41 - train: epoch 0305, iter [00090, 01251], lr: 0.000198, loss: 0.4002
2022-10-03 23:27:59 - train: epoch 0305, iter [00100, 01251], lr: 0.000198, loss: 0.3992
2022-10-03 23:28:17 - train: epoch 0305, iter [00110, 01251], lr: 0.000198, loss: 0.3853
2022-10-03 23:28:35 - train: epoch 0305, iter [00120, 01251], lr: 0.000198, loss: 0.3975
2022-10-03 23:28:53 - train: epoch 0305, iter [00130, 01251], lr: 0.000198, loss: 0.4017
2022-10-03 23:29:11 - train: epoch 0305, iter [00140, 01251], lr: 0.000198, loss: 0.3932
2022-10-03 23:29:29 - train: epoch 0305, iter [00150, 01251], lr: 0.000198, loss: 0.3707
2022-10-03 23:29:47 - train: epoch 0305, iter [00160, 01251], lr: 0.000198, loss: 0.3990
2022-10-03 23:30:05 - train: epoch 0305, iter [00170, 01251], lr: 0.000198, loss: 0.3766
2022-10-03 23:30:23 - train: epoch 0305, iter [00180, 01251], lr: 0.000198, loss: 0.3798
2022-10-03 23:30:41 - train: epoch 0305, iter [00190, 01251], lr: 0.000198, loss: 0.3906
2022-10-03 23:30:59 - train: epoch 0305, iter [00200, 01251], lr: 0.000198, loss: 0.4256
2022-10-03 23:31:17 - train: epoch 0305, iter [00210, 01251], lr: 0.000198, loss: 0.3913
2022-10-03 23:31:35 - train: epoch 0305, iter [00220, 01251], lr: 0.000198, loss: 0.3869
2022-10-03 23:31:53 - train: epoch 0305, iter [00230, 01251], lr: 0.000198, loss: 0.3974
2022-10-03 23:32:11 - train: epoch 0305, iter [00240, 01251], lr: 0.000198, loss: 0.3908
2022-10-03 23:32:29 - train: epoch 0305, iter [00250, 01251], lr: 0.000198, loss: 0.4108
2022-10-03 23:32:48 - train: epoch 0305, iter [00260, 01251], lr: 0.000198, loss: 0.3937
2022-10-03 23:33:05 - train: epoch 0305, iter [00270, 01251], lr: 0.000198, loss: 0.3995
2022-10-03 23:33:24 - train: epoch 0305, iter [00280, 01251], lr: 0.000198, loss: 0.4081
2022-10-03 23:33:41 - train: epoch 0305, iter [00290, 01251], lr: 0.000198, loss: 0.3962
2022-10-03 23:34:00 - train: epoch 0305, iter [00300, 01251], lr: 0.000198, loss: 0.4048
2022-10-03 23:34:18 - train: epoch 0305, iter [00310, 01251], lr: 0.000198, loss: 0.4148
2022-10-03 23:34:36 - train: epoch 0305, iter [00320, 01251], lr: 0.000198, loss: 0.3907
2022-10-03 23:34:54 - train: epoch 0305, iter [00330, 01251], lr: 0.000197, loss: 0.3908
2022-10-03 23:35:12 - train: epoch 0305, iter [00340, 01251], lr: 0.000197, loss: 0.3803
2022-10-03 23:35:30 - train: epoch 0305, iter [00350, 01251], lr: 0.000197, loss: 0.3700
2022-10-03 23:35:48 - train: epoch 0305, iter [00360, 01251], lr: 0.000197, loss: 0.4040
2022-10-03 23:36:06 - train: epoch 0305, iter [00370, 01251], lr: 0.000197, loss: 0.4096
2022-10-03 23:36:24 - train: epoch 0305, iter [00380, 01251], lr: 0.000197, loss: 0.3977
2022-10-03 23:36:42 - train: epoch 0305, iter [00390, 01251], lr: 0.000197, loss: 0.3870
2022-10-03 23:37:00 - train: epoch 0305, iter [00400, 01251], lr: 0.000197, loss: 0.4187
2022-10-03 23:37:18 - train: epoch 0305, iter [00410, 01251], lr: 0.000197, loss: 0.3882
2022-10-03 23:37:36 - train: epoch 0305, iter [00420, 01251], lr: 0.000197, loss: 0.4110
2022-10-03 23:37:54 - train: epoch 0305, iter [00430, 01251], lr: 0.000197, loss: 0.3970
2022-10-03 23:38:12 - train: epoch 0305, iter [00440, 01251], lr: 0.000197, loss: 0.4015
2022-10-03 23:38:30 - train: epoch 0305, iter [00450, 01251], lr: 0.000197, loss: 0.3754
2022-10-03 23:38:48 - train: epoch 0305, iter [00460, 01251], lr: 0.000197, loss: 0.3872
2022-10-03 23:39:06 - train: epoch 0305, iter [00470, 01251], lr: 0.000197, loss: 0.3899
2022-10-03 23:39:24 - train: epoch 0305, iter [00480, 01251], lr: 0.000197, loss: 0.4182
2022-10-03 23:39:43 - train: epoch 0305, iter [00490, 01251], lr: 0.000197, loss: 0.3929
2022-10-03 23:40:01 - train: epoch 0305, iter [00500, 01251], lr: 0.000197, loss: 0.3948
2022-10-03 23:40:19 - train: epoch 0305, iter [00510, 01251], lr: 0.000197, loss: 0.4010
2022-10-03 23:40:37 - train: epoch 0305, iter [00520, 01251], lr: 0.000197, loss: 0.4010
2022-10-03 23:40:55 - train: epoch 0305, iter [00530, 01251], lr: 0.000197, loss: 0.3988
2022-10-03 23:41:13 - train: epoch 0305, iter [00540, 01251], lr: 0.000197, loss: 0.4143
2022-10-03 23:41:32 - train: epoch 0305, iter [00550, 01251], lr: 0.000197, loss: 0.4025
2022-10-03 23:41:49 - train: epoch 0305, iter [00560, 01251], lr: 0.000197, loss: 0.3853
2022-10-03 23:42:07 - train: epoch 0305, iter [00570, 01251], lr: 0.000197, loss: 0.3958
2022-10-03 23:42:25 - train: epoch 0305, iter [00580, 01251], lr: 0.000197, loss: 0.3878
2022-10-03 23:42:43 - train: epoch 0305, iter [00590, 01251], lr: 0.000197, loss: 0.3882
2022-10-03 23:43:01 - train: epoch 0305, iter [00600, 01251], lr: 0.000197, loss: 0.3989
2022-10-03 23:43:19 - train: epoch 0305, iter [00610, 01251], lr: 0.000197, loss: 0.3971
2022-10-03 23:43:38 - train: epoch 0305, iter [00620, 01251], lr: 0.000197, loss: 0.4004
2022-10-03 23:43:56 - train: epoch 0305, iter [00630, 01251], lr: 0.000197, loss: 0.3938
2022-10-03 23:44:14 - train: epoch 0305, iter [00640, 01251], lr: 0.000197, loss: 0.3745
2022-10-03 23:44:32 - train: epoch 0305, iter [00650, 01251], lr: 0.000197, loss: 0.4022
2022-10-03 23:44:51 - train: epoch 0305, iter [00660, 01251], lr: 0.000196, loss: 0.3959
2022-10-03 23:45:09 - train: epoch 0305, iter [00670, 01251], lr: 0.000196, loss: 0.3929
2022-10-03 23:45:27 - train: epoch 0305, iter [00680, 01251], lr: 0.000196, loss: 0.3897
2022-10-03 23:45:45 - train: epoch 0305, iter [00690, 01251], lr: 0.000196, loss: 0.3927
2022-10-03 23:46:03 - train: epoch 0305, iter [00700, 01251], lr: 0.000196, loss: 0.3913
2022-10-03 23:46:21 - train: epoch 0305, iter [00710, 01251], lr: 0.000196, loss: 0.3927
2022-10-03 23:46:39 - train: epoch 0305, iter [00720, 01251], lr: 0.000196, loss: 0.4009
2022-10-03 23:46:57 - train: epoch 0305, iter [00730, 01251], lr: 0.000196, loss: 0.4114
2022-10-03 23:47:16 - train: epoch 0305, iter [00740, 01251], lr: 0.000196, loss: 0.3857
2022-10-03 23:47:34 - train: epoch 0305, iter [00750, 01251], lr: 0.000196, loss: 0.3774
2022-10-03 23:47:52 - train: epoch 0305, iter [00760, 01251], lr: 0.000196, loss: 0.3863
2022-10-03 23:48:10 - train: epoch 0305, iter [00770, 01251], lr: 0.000196, loss: 0.3863
2022-10-03 23:48:28 - train: epoch 0305, iter [00780, 01251], lr: 0.000196, loss: 0.4206
2022-10-03 23:48:46 - train: epoch 0305, iter [00790, 01251], lr: 0.000196, loss: 0.3859
2022-10-03 23:49:04 - train: epoch 0305, iter [00800, 01251], lr: 0.000196, loss: 0.3941
2022-10-03 23:49:23 - train: epoch 0305, iter [00810, 01251], lr: 0.000196, loss: 0.3813
2022-10-03 23:49:41 - train: epoch 0305, iter [00820, 01251], lr: 0.000196, loss: 0.3796
2022-10-03 23:49:59 - train: epoch 0305, iter [00830, 01251], lr: 0.000196, loss: 0.3988
2022-10-03 23:50:17 - train: epoch 0305, iter [00840, 01251], lr: 0.000196, loss: 0.3989
2022-10-03 23:50:35 - train: epoch 0305, iter [00850, 01251], lr: 0.000196, loss: 0.3883
2022-10-03 23:50:53 - train: epoch 0305, iter [00860, 01251], lr: 0.000196, loss: 0.3963
2022-10-03 23:51:12 - train: epoch 0305, iter [00870, 01251], lr: 0.000196, loss: 0.4118
2022-10-03 23:51:30 - train: epoch 0305, iter [00880, 01251], lr: 0.000196, loss: 0.4096
2022-10-03 23:51:48 - train: epoch 0305, iter [00890, 01251], lr: 0.000196, loss: 0.3817
2022-10-03 23:52:06 - train: epoch 0305, iter [00900, 01251], lr: 0.000196, loss: 0.4131
2022-10-03 23:52:24 - train: epoch 0305, iter [00910, 01251], lr: 0.000196, loss: 0.3850
2022-10-03 23:52:43 - train: epoch 0305, iter [00920, 01251], lr: 0.000196, loss: 0.4001
2022-10-03 23:53:01 - train: epoch 0305, iter [00930, 01251], lr: 0.000196, loss: 0.3818
2022-10-03 23:53:19 - train: epoch 0305, iter [00940, 01251], lr: 0.000196, loss: 0.3948
2022-10-03 23:53:37 - train: epoch 0305, iter [00950, 01251], lr: 0.000196, loss: 0.4012
2022-10-03 23:53:55 - train: epoch 0305, iter [00960, 01251], lr: 0.000196, loss: 0.3977
2022-10-03 23:54:13 - train: epoch 0305, iter [00970, 01251], lr: 0.000196, loss: 0.4137
2022-10-03 23:54:31 - train: epoch 0305, iter [00980, 01251], lr: 0.000195, loss: 0.3760
2022-10-03 23:54:50 - train: epoch 0305, iter [00990, 01251], lr: 0.000195, loss: 0.3993
2022-10-03 23:55:08 - train: epoch 0305, iter [01000, 01251], lr: 0.000195, loss: 0.3902
2022-10-03 23:55:26 - train: epoch 0305, iter [01010, 01251], lr: 0.000195, loss: 0.3986
2022-10-03 23:55:44 - train: epoch 0305, iter [01020, 01251], lr: 0.000195, loss: 0.3967
2022-10-03 23:56:02 - train: epoch 0305, iter [01030, 01251], lr: 0.000195, loss: 0.4057
2022-10-03 23:56:20 - train: epoch 0305, iter [01040, 01251], lr: 0.000195, loss: 0.3961
2022-10-03 23:56:39 - train: epoch 0305, iter [01050, 01251], lr: 0.000195, loss: 0.4012
2022-10-03 23:56:57 - train: epoch 0305, iter [01060, 01251], lr: 0.000195, loss: 0.3672
2022-10-03 23:57:15 - train: epoch 0305, iter [01070, 01251], lr: 0.000195, loss: 0.3991
2022-10-03 23:57:33 - train: epoch 0305, iter [01080, 01251], lr: 0.000195, loss: 0.3907
2022-10-03 23:57:51 - train: epoch 0305, iter [01090, 01251], lr: 0.000195, loss: 0.4134
2022-10-03 23:58:10 - train: epoch 0305, iter [01100, 01251], lr: 0.000195, loss: 0.3926
2022-10-03 23:58:28 - train: epoch 0305, iter [01110, 01251], lr: 0.000195, loss: 0.3896
2022-10-03 23:58:46 - train: epoch 0305, iter [01120, 01251], lr: 0.000195, loss: 0.4181
2022-10-03 23:59:04 - train: epoch 0305, iter [01130, 01251], lr: 0.000195, loss: 0.4087
2022-10-03 23:59:22 - train: epoch 0305, iter [01140, 01251], lr: 0.000195, loss: 0.3973
2022-10-03 23:59:40 - train: epoch 0305, iter [01150, 01251], lr: 0.000195, loss: 0.3766
2022-10-03 23:59:58 - train: epoch 0305, iter [01160, 01251], lr: 0.000195, loss: 0.3818
